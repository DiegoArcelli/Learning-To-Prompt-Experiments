/storagenfs/d.arcelli/Prompting-Based-CL-Methods-Experiments/.env/lib/python3.9/site-packages/torchvision/transforms/transforms.py:329: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.
  warnings.warn(
/storagenfs/d.arcelli/l2p-pytorch/continual_datasets/dataset_utils.py:335: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:199.)
  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)
Namespace(subparser_name='five_datasets_l2p', batch_size=16, epochs=5, model='vit_base_patch16_224', input_size=224, pretrained=True, drop=0.0, drop_path=0.0, opt='adam', opt_eps=1e-08, opt_betas=(0.9, 0.999), clip_grad=1.0, momentum=0.9, weight_decay=0.0, reinit_optimizer=True, sched='constant', lr=0.03, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, unscale_lr=True, color_jitter=None, aa=None, smoothing=0.1, train_interpolation='bicubic', reprob=0.0, remode='pixel', recount=1, data_path='./local_datasets/', dataset='5-datasets', shuffle=False, output_dir='./output_5_datasets_forzen_classifier', device='cuda', seed=42, eval=False, num_workers=4, pin_mem=True, world_size=1, dist_url='env://', num_tasks=5, train_mask=True, task_inc=False, prompt_pool=True, size=20, length=10, top_k=4, initializer='uniform', prompt_key=True, prompt_key_init='uniform', use_prompt_mask=True, shared_prompt_pool=False, shared_prompt_key=False, batchwise_prompt=True, embedding_key='cls', predefined_key='', pull_constraint=True, pull_constraint_coeff=0.5, global_pool='token', head_type='prompt', freeze=['blocks', 'patch_embed', 'cls_token', 'norm', 'pos_embed'], print_freq=10, freeze_head=True, train_type='task_wise', eval_task_id=False, frequency_penalization=False, class_incremental=False, init_class_prompts=False, task_incremental=False, init_tasks_prompts=False, prompts_per_task=4, prompts_per_class=1, freeze_keys=False)
Not using distributed mode
['SVHN', 'MNIST', 'CIFAR10', 'NotMNIST', 'FashionMNIST']
Using downloaded and verified file: ./local_datasets/train_32x32.mat
Using downloaded and verified file: ./local_datasets/train_32x32.mat
Using downloaded and verified file: ./local_datasets/test_32x32.mat
Using downloaded and verified file: ./local_datasets/test_32x32.mat
[1 9 2 3 2 5 9 3 3 1]
tensor([5, 0, 4, 1, 9, 2, 1, 3, 1, 4])
Files already downloaded and verified
Files already downloaded and verified
[6, 9, 9, 4, 1, 1, 2, 7, 8, 3]
File F/Q3Jvc3NvdmVyIEJvbGRPYmxpcXVlLnR0Zg==.png is broken
File A/RGVtb2NyYXRpY2FCb2xkT2xkc3R5bGUgQm9sZC50dGY=.png is broken
[5, 5, 5, 5, 5, 5, 5, 5, 5, 5]
tensor([9, 0, 0, 3, 0, 2, 7, 2, 5, 5])
Creating original model: vit_base_patch16_224
Creating model: vit_base_patch16_224
number of params: 168960
Start training for 5 epochs
Train: Epoch[1/5]  [   0/4579]  eta: 1:53:05  Lr: 0.030000  Loss: 2.3002  Acc@1: 12.5000 (12.5000)  Acc@5: 68.7500 (68.7500)  time: 1.4820  data: 0.3467  max mem: 2497
Train: Epoch[1/5]  [  10/4579]  eta: 0:33:52  Lr: 0.030000  Loss: 1.8609  Acc@1: 12.5000 (12.5000)  Acc@5: 50.0000 (51.1364)  time: 0.4447  data: 0.0317  max mem: 2500
Train: Epoch[1/5]  [  20/4579]  eta: 0:30:01  Lr: 0.030000  Loss: 1.5774  Acc@1: 6.2500 (10.7143)  Acc@5: 50.0000 (50.5952)  time: 0.3409  data: 0.0002  max mem: 2500
Train: Epoch[1/5]  [  30/4579]  eta: 0:28:39  Lr: 0.030000  Loss: 1.1420  Acc@1: 6.2500 (10.4839)  Acc@5: 50.0000 (51.0081)  time: 0.3414  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [  40/4579]  eta: 0:28:00  Lr: 0.030000  Loss: 1.0620  Acc@1: 12.5000 (11.2805)  Acc@5: 56.2500 (54.2683)  time: 0.3439  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [  50/4579]  eta: 0:27:31  Lr: 0.030000  Loss: 0.9849  Acc@1: 12.5000 (12.2549)  Acc@5: 62.5000 (55.5147)  time: 0.3437  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [  60/4579]  eta: 0:27:10  Lr: 0.030000  Loss: 1.0400  Acc@1: 18.7500 (13.0123)  Acc@5: 56.2500 (55.7377)  time: 0.3416  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [  70/4579]  eta: 0:26:56  Lr: 0.030000  Loss: 1.0475  Acc@1: 18.7500 (13.9965)  Acc@5: 56.2500 (57.0423)  time: 0.3428  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [  80/4579]  eta: 0:26:44  Lr: 0.030000  Loss: 0.8792  Acc@1: 25.0000 (15.0463)  Acc@5: 68.7500 (58.0247)  time: 0.3443  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [  90/4579]  eta: 0:26:34  Lr: 0.030000  Loss: 0.9093  Acc@1: 18.7500 (15.5220)  Acc@5: 68.7500 (58.9286)  time: 0.3435  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 100/4579]  eta: 0:26:24  Lr: 0.030000  Loss: 0.9833  Acc@1: 18.7500 (15.9653)  Acc@5: 56.2500 (58.9109)  time: 0.3423  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 110/4579]  eta: 0:26:16  Lr: 0.030000  Loss: 0.8542  Acc@1: 18.7500 (16.2162)  Acc@5: 56.2500 (58.8964)  time: 0.3420  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 120/4579]  eta: 0:26:10  Lr: 0.030000  Loss: 0.9961  Acc@1: 18.7500 (16.3740)  Acc@5: 62.5000 (59.1426)  time: 0.3437  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [ 130/4579]  eta: 0:26:03  Lr: 0.030000  Loss: 0.9162  Acc@1: 18.7500 (16.6031)  Acc@5: 56.2500 (59.1126)  time: 0.3437  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [ 140/4579]  eta: 0:25:57  Lr: 0.030000  Loss: 0.9841  Acc@1: 18.7500 (16.5780)  Acc@5: 56.2500 (59.3972)  time: 0.3422  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [ 150/4579]  eta: 0:25:51  Lr: 0.030000  Loss: 0.8632  Acc@1: 18.7500 (16.8460)  Acc@5: 62.5000 (59.6854)  time: 0.3424  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [ 160/4579]  eta: 0:25:45  Lr: 0.030000  Loss: 0.8221  Acc@1: 18.7500 (17.0807)  Acc@5: 62.5000 (59.8214)  time: 0.3426  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [ 170/4579]  eta: 0:25:40  Lr: 0.030000  Loss: 1.0052  Acc@1: 18.7500 (17.1053)  Acc@5: 62.5000 (60.0146)  time: 0.3428  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [ 180/4579]  eta: 0:25:35  Lr: 0.030000  Loss: 1.0087  Acc@1: 12.5000 (17.3343)  Acc@5: 62.5000 (60.2901)  time: 0.3428  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [ 190/4579]  eta: 0:25:29  Lr: 0.030000  Loss: 0.9890  Acc@1: 18.7500 (17.4084)  Acc@5: 62.5000 (60.5366)  time: 0.3420  data: 0.0002  max mem: 2500
Train: Epoch[1/5]  [ 200/4579]  eta: 0:25:24  Lr: 0.030000  Loss: 0.9923  Acc@1: 18.7500 (17.5684)  Acc@5: 62.5000 (60.4478)  time: 0.3414  data: 0.0002  max mem: 2500
Train: Epoch[1/5]  [ 210/4579]  eta: 0:25:20  Lr: 0.030000  Loss: 0.9435  Acc@1: 18.7500 (17.7133)  Acc@5: 62.5000 (60.6635)  time: 0.3418  data: 0.0002  max mem: 2500
Train: Epoch[1/5]  [ 220/4579]  eta: 0:25:15  Lr: 0.030000  Loss: 0.8679  Acc@1: 18.7500 (17.7319)  Acc@5: 62.5000 (61.0860)  time: 0.3430  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [ 230/4579]  eta: 0:25:11  Lr: 0.030000  Loss: 0.8649  Acc@1: 18.7500 (17.7219)  Acc@5: 68.7500 (61.3366)  time: 0.3435  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 240/4579]  eta: 0:25:07  Lr: 0.030000  Loss: 0.9966  Acc@1: 12.5000 (17.7127)  Acc@5: 56.2500 (61.1774)  time: 0.3433  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 250/4579]  eta: 0:25:03  Lr: 0.030000  Loss: 1.0060  Acc@1: 18.7500 (17.7291)  Acc@5: 56.2500 (61.2301)  time: 0.3437  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 260/4579]  eta: 0:24:59  Lr: 0.030000  Loss: 0.9091  Acc@1: 18.7500 (17.8161)  Acc@5: 56.2500 (61.1111)  time: 0.3438  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [ 270/4579]  eta: 0:24:55  Lr: 0.030000  Loss: 0.9974  Acc@1: 18.7500 (17.8275)  Acc@5: 62.5000 (61.2085)  time: 0.3434  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [ 280/4579]  eta: 0:24:51  Lr: 0.030000  Loss: 0.9041  Acc@1: 18.7500 (17.7936)  Acc@5: 62.5000 (61.0543)  time: 0.3431  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [ 290/4579]  eta: 0:24:47  Lr: 0.030000  Loss: 0.9695  Acc@1: 18.7500 (17.8265)  Acc@5: 62.5000 (61.1899)  time: 0.3436  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [ 300/4579]  eta: 0:24:43  Lr: 0.030000  Loss: 0.9229  Acc@1: 18.7500 (17.7326)  Acc@5: 68.7500 (61.4618)  time: 0.3438  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 310/4579]  eta: 0:24:39  Lr: 0.030000  Loss: 0.8875  Acc@1: 18.7500 (17.9260)  Acc@5: 56.2500 (61.3143)  time: 0.3435  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [ 320/4579]  eta: 0:24:35  Lr: 0.030000  Loss: 0.9360  Acc@1: 25.0000 (18.1075)  Acc@5: 62.5000 (61.4291)  time: 0.3439  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [ 330/4579]  eta: 0:24:32  Lr: 0.030000  Loss: 0.8568  Acc@1: 25.0000 (18.3912)  Acc@5: 62.5000 (61.6503)  time: 0.3451  data: 0.0010  max mem: 2500
Train: Epoch[1/5]  [ 340/4579]  eta: 0:24:28  Lr: 0.030000  Loss: 0.8925  Acc@1: 25.0000 (18.5850)  Acc@5: 68.7500 (61.8768)  time: 0.3442  data: 0.0010  max mem: 2500
Train: Epoch[1/5]  [ 350/4579]  eta: 0:24:24  Lr: 0.030000  Loss: 0.8181  Acc@1: 25.0000 (18.7678)  Acc@5: 62.5000 (61.9124)  time: 0.3421  data: 0.0002  max mem: 2500
Train: Epoch[1/5]  [ 360/4579]  eta: 0:24:20  Lr: 0.030000  Loss: 1.0111  Acc@1: 25.0000 (19.0789)  Acc@5: 62.5000 (62.0325)  time: 0.3422  data: 0.0002  max mem: 2500
Train: Epoch[1/5]  [ 370/4579]  eta: 0:24:16  Lr: 0.030000  Loss: 1.0059  Acc@1: 31.2500 (19.3565)  Acc@5: 62.5000 (62.0788)  time: 0.3424  data: 0.0002  max mem: 2500
Train: Epoch[1/5]  [ 380/4579]  eta: 0:24:12  Lr: 0.030000  Loss: 0.9453  Acc@1: 25.0000 (19.4390)  Acc@5: 62.5000 (62.0243)  time: 0.3423  data: 0.0002  max mem: 2500
Train: Epoch[1/5]  [ 390/4579]  eta: 0:24:08  Lr: 0.030000  Loss: 0.9661  Acc@1: 25.0000 (19.6771)  Acc@5: 62.5000 (62.2922)  time: 0.3422  data: 0.0002  max mem: 2500
Train: Epoch[1/5]  [ 400/4579]  eta: 0:24:04  Lr: 0.030000  Loss: 0.8392  Acc@1: 31.2500 (19.9034)  Acc@5: 68.7500 (62.3597)  time: 0.3426  data: 0.0002  max mem: 2500
Train: Epoch[1/5]  [ 410/4579]  eta: 0:24:00  Lr: 0.030000  Loss: 0.8043  Acc@1: 25.0000 (20.0426)  Acc@5: 68.7500 (62.4240)  time: 0.3424  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [ 420/4579]  eta: 0:23:57  Lr: 0.030000  Loss: 0.8782  Acc@1: 25.0000 (20.1306)  Acc@5: 62.5000 (62.4555)  time: 0.3425  data: 0.0002  max mem: 2500
Train: Epoch[1/5]  [ 430/4579]  eta: 0:23:53  Lr: 0.030000  Loss: 0.9457  Acc@1: 18.7500 (20.2871)  Acc@5: 68.7500 (62.4710)  time: 0.3435  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [ 440/4579]  eta: 0:23:50  Lr: 0.030000  Loss: 0.7877  Acc@1: 25.0000 (20.4932)  Acc@5: 68.7500 (62.5709)  time: 0.3443  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 450/4579]  eta: 0:23:46  Lr: 0.030000  Loss: 0.8233  Acc@1: 25.0000 (20.5931)  Acc@5: 68.7500 (62.7633)  time: 0.3448  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 460/4579]  eta: 0:23:43  Lr: 0.030000  Loss: 0.8505  Acc@1: 25.0000 (20.7701)  Acc@5: 68.7500 (62.9067)  time: 0.3448  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 470/4579]  eta: 0:23:39  Lr: 0.030000  Loss: 0.5859  Acc@1: 25.0000 (20.9660)  Acc@5: 68.7500 (63.0441)  time: 0.3443  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 480/4579]  eta: 0:23:35  Lr: 0.030000  Loss: 0.8114  Acc@1: 25.0000 (20.9979)  Acc@5: 62.5000 (63.1237)  time: 0.3437  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 490/4579]  eta: 0:23:32  Lr: 0.030000  Loss: 0.8174  Acc@1: 25.0000 (21.1431)  Acc@5: 68.7500 (63.1746)  time: 0.3440  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 500/4579]  eta: 0:23:28  Lr: 0.030000  Loss: 1.0380  Acc@1: 25.0000 (21.2949)  Acc@5: 68.7500 (63.2360)  time: 0.3450  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 510/4579]  eta: 0:23:25  Lr: 0.030000  Loss: 0.9699  Acc@1: 25.0000 (21.4286)  Acc@5: 62.5000 (63.1972)  time: 0.3457  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 520/4579]  eta: 0:23:21  Lr: 0.030000  Loss: 0.6603  Acc@1: 25.0000 (21.6291)  Acc@5: 68.7500 (63.3517)  time: 0.3455  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 530/4579]  eta: 0:23:18  Lr: 0.030000  Loss: 0.8855  Acc@1: 25.0000 (21.7632)  Acc@5: 68.7500 (63.3945)  time: 0.3462  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 540/4579]  eta: 0:23:15  Lr: 0.030000  Loss: 1.0443  Acc@1: 31.2500 (21.9385)  Acc@5: 68.7500 (63.5051)  time: 0.3459  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 550/4579]  eta: 0:23:11  Lr: 0.030000  Loss: 0.7063  Acc@1: 31.2500 (22.0848)  Acc@5: 75.0000 (63.6343)  time: 0.3455  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [ 560/4579]  eta: 0:23:08  Lr: 0.030000  Loss: 0.8657  Acc@1: 25.0000 (22.2037)  Acc@5: 68.7500 (63.7032)  time: 0.3459  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [ 570/4579]  eta: 0:23:04  Lr: 0.030000  Loss: 0.8360  Acc@1: 25.0000 (22.3730)  Acc@5: 68.7500 (63.8792)  time: 0.3455  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 580/4579]  eta: 0:23:01  Lr: 0.030000  Loss: 0.9677  Acc@1: 25.0000 (22.3860)  Acc@5: 68.7500 (63.8554)  time: 0.3464  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 590/4579]  eta: 0:22:58  Lr: 0.030000  Loss: 0.9600  Acc@1: 25.0000 (22.5465)  Acc@5: 62.5000 (63.8959)  time: 0.3504  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 600/4579]  eta: 0:22:55  Lr: 0.030000  Loss: 0.7691  Acc@1: 31.2500 (22.7017)  Acc@5: 68.7500 (64.0599)  time: 0.3498  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [ 610/4579]  eta: 0:22:51  Lr: 0.030000  Loss: 0.7587  Acc@1: 31.2500 (22.7803)  Acc@5: 68.7500 (64.1571)  time: 0.3450  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [ 620/4579]  eta: 0:22:48  Lr: 0.030000  Loss: 1.0036  Acc@1: 25.0000 (22.9267)  Acc@5: 68.7500 (64.2613)  time: 0.3442  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [ 630/4579]  eta: 0:22:44  Lr: 0.030000  Loss: 0.9979  Acc@1: 25.0000 (23.0289)  Acc@5: 68.7500 (64.3522)  time: 0.3453  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [ 640/4579]  eta: 0:22:41  Lr: 0.030000  Loss: 0.8684  Acc@1: 25.0000 (23.0987)  Acc@5: 62.5000 (64.3916)  time: 0.3452  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [ 650/4579]  eta: 0:22:37  Lr: 0.030000  Loss: 0.7326  Acc@1: 31.2500 (23.2623)  Acc@5: 68.7500 (64.5257)  time: 0.3444  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [ 660/4579]  eta: 0:22:34  Lr: 0.030000  Loss: 0.9219  Acc@1: 31.2500 (23.3453)  Acc@5: 68.7500 (64.5613)  time: 0.3448  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [ 670/4579]  eta: 0:22:30  Lr: 0.030000  Loss: 1.0084  Acc@1: 25.0000 (23.3420)  Acc@5: 68.7500 (64.6516)  time: 0.3454  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [ 680/4579]  eta: 0:22:27  Lr: 0.030000  Loss: 1.0434  Acc@1: 25.0000 (23.4123)  Acc@5: 68.7500 (64.7485)  time: 0.3444  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [ 690/4579]  eta: 0:22:23  Lr: 0.030000  Loss: 0.9141  Acc@1: 25.0000 (23.4986)  Acc@5: 75.0000 (64.8788)  time: 0.3431  data: 0.0002  max mem: 2500
Train: Epoch[1/5]  [ 700/4579]  eta: 0:22:19  Lr: 0.030000  Loss: 0.8747  Acc@1: 25.0000 (23.5735)  Acc@5: 75.0000 (64.9786)  time: 0.3431  data: 0.0002  max mem: 2500
Train: Epoch[1/5]  [ 710/4579]  eta: 0:22:16  Lr: 0.030000  Loss: 0.7209  Acc@1: 31.2500 (23.6463)  Acc@5: 75.0000 (65.0756)  time: 0.3431  data: 0.0002  max mem: 2500
Train: Epoch[1/5]  [ 720/4579]  eta: 0:22:12  Lr: 0.030000  Loss: 0.6667  Acc@1: 25.0000 (23.7431)  Acc@5: 75.0000 (65.2046)  time: 0.3433  data: 0.0002  max mem: 2500
Train: Epoch[1/5]  [ 730/4579]  eta: 0:22:09  Lr: 0.030000  Loss: 0.8397  Acc@1: 31.2500 (23.8201)  Acc@5: 75.0000 (65.3129)  time: 0.3431  data: 0.0002  max mem: 2500
Train: Epoch[1/5]  [ 740/4579]  eta: 0:22:05  Lr: 0.030000  Loss: 0.8056  Acc@1: 31.2500 (23.9119)  Acc@5: 68.7500 (65.3846)  time: 0.3432  data: 0.0002  max mem: 2500
Train: Epoch[1/5]  [ 750/4579]  eta: 0:22:02  Lr: 0.030000  Loss: 0.8215  Acc@1: 25.0000 (23.8931)  Acc@5: 68.7500 (65.4877)  time: 0.3454  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [ 760/4579]  eta: 0:21:58  Lr: 0.030000  Loss: 0.5244  Acc@1: 25.0000 (23.9323)  Acc@5: 68.7500 (65.5963)  time: 0.3462  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 770/4579]  eta: 0:21:55  Lr: 0.030000  Loss: 0.9997  Acc@1: 25.0000 (23.8975)  Acc@5: 75.0000 (65.7020)  time: 0.3449  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 780/4579]  eta: 0:21:51  Lr: 0.030000  Loss: 0.9572  Acc@1: 25.0000 (23.9597)  Acc@5: 68.7500 (65.6770)  time: 0.3446  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 790/4579]  eta: 0:21:48  Lr: 0.030000  Loss: 1.0101  Acc@1: 25.0000 (23.9728)  Acc@5: 62.5000 (65.6764)  time: 0.3452  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 800/4579]  eta: 0:21:45  Lr: 0.030000  Loss: 0.7319  Acc@1: 25.0000 (24.1027)  Acc@5: 68.7500 (65.8240)  time: 0.3461  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [ 810/4579]  eta: 0:21:41  Lr: 0.030000  Loss: 0.9398  Acc@1: 25.0000 (24.1292)  Acc@5: 75.0000 (65.9448)  time: 0.3455  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 820/4579]  eta: 0:21:38  Lr: 0.030000  Loss: 0.7606  Acc@1: 25.0000 (24.1550)  Acc@5: 75.0000 (66.0018)  time: 0.3453  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 830/4579]  eta: 0:21:34  Lr: 0.030000  Loss: 0.7058  Acc@1: 25.0000 (24.2479)  Acc@5: 75.0000 (66.0951)  time: 0.3452  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 840/4579]  eta: 0:21:31  Lr: 0.030000  Loss: 1.0441  Acc@1: 31.2500 (24.3609)  Acc@5: 75.0000 (66.1787)  time: 0.3446  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [ 850/4579]  eta: 0:21:27  Lr: 0.030000  Loss: 0.7801  Acc@1: 31.2500 (24.4492)  Acc@5: 68.7500 (66.2015)  time: 0.3458  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 860/4579]  eta: 0:21:24  Lr: 0.030000  Loss: 0.8390  Acc@1: 31.2500 (24.5717)  Acc@5: 75.0000 (66.2819)  time: 0.3465  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [ 870/4579]  eta: 0:21:20  Lr: 0.030000  Loss: 0.6210  Acc@1: 31.2500 (24.5766)  Acc@5: 75.0000 (66.3820)  time: 0.3451  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 880/4579]  eta: 0:21:17  Lr: 0.030000  Loss: 1.0826  Acc@1: 25.0000 (24.6098)  Acc@5: 75.0000 (66.4657)  time: 0.3441  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [ 890/4579]  eta: 0:21:13  Lr: 0.030000  Loss: 0.7394  Acc@1: 31.2500 (24.6914)  Acc@5: 75.0000 (66.5264)  time: 0.3440  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [ 900/4579]  eta: 0:21:10  Lr: 0.030000  Loss: 0.8430  Acc@1: 25.0000 (24.7156)  Acc@5: 68.7500 (66.5719)  time: 0.3442  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [ 910/4579]  eta: 0:21:06  Lr: 0.030000  Loss: 0.6402  Acc@1: 25.0000 (24.7667)  Acc@5: 68.7500 (66.6095)  time: 0.3445  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [ 920/4579]  eta: 0:21:03  Lr: 0.030000  Loss: 0.7957  Acc@1: 25.0000 (24.7828)  Acc@5: 75.0000 (66.7006)  time: 0.3446  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [ 930/4579]  eta: 0:20:59  Lr: 0.030000  Loss: 0.9287  Acc@1: 25.0000 (24.8389)  Acc@5: 75.0000 (66.7830)  time: 0.3442  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [ 940/4579]  eta: 0:20:56  Lr: 0.030000  Loss: 0.7537  Acc@1: 25.0000 (24.8804)  Acc@5: 68.7500 (66.8571)  time: 0.3457  data: 0.0009  max mem: 2500
Train: Epoch[1/5]  [ 950/4579]  eta: 0:20:52  Lr: 0.030000  Loss: 0.8835  Acc@1: 25.0000 (24.8948)  Acc@5: 68.7500 (66.9558)  time: 0.3449  data: 0.0009  max mem: 2500
Train: Epoch[1/5]  [ 960/4579]  eta: 0:20:49  Lr: 0.030000  Loss: 0.8170  Acc@1: 25.0000 (24.9220)  Acc@5: 75.0000 (67.0330)  time: 0.3427  data: 0.0002  max mem: 2500
Train: Epoch[1/5]  [ 970/4579]  eta: 0:20:45  Lr: 0.030000  Loss: 0.6239  Acc@1: 25.0000 (24.9614)  Acc@5: 75.0000 (67.0636)  time: 0.3427  data: 0.0002  max mem: 2500
Train: Epoch[1/5]  [ 980/4579]  eta: 0:20:42  Lr: 0.030000  Loss: 0.6849  Acc@1: 31.2500 (25.0382)  Acc@5: 75.0000 (67.1827)  time: 0.3426  data: 0.0002  max mem: 2500
Train: Epoch[1/5]  [ 990/4579]  eta: 0:20:38  Lr: 0.030000  Loss: 0.7060  Acc@1: 31.2500 (25.1135)  Acc@5: 75.0000 (67.2868)  time: 0.3426  data: 0.0002  max mem: 2500
Train: Epoch[1/5]  [1000/4579]  eta: 0:20:35  Lr: 0.030000  Loss: 0.7570  Acc@1: 31.2500 (25.1936)  Acc@5: 75.0000 (67.3826)  time: 0.3427  data: 0.0002  max mem: 2500
Train: Epoch[1/5]  [1010/4579]  eta: 0:20:31  Lr: 0.030000  Loss: 0.8526  Acc@1: 25.0000 (25.1793)  Acc@5: 75.0000 (67.4703)  time: 0.3427  data: 0.0002  max mem: 2500
Train: Epoch[1/5]  [1020/4579]  eta: 0:20:28  Lr: 0.030000  Loss: 0.4961  Acc@1: 31.2500 (25.2693)  Acc@5: 75.0000 (67.5808)  time: 0.3435  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [1030/4579]  eta: 0:20:24  Lr: 0.030000  Loss: 0.8894  Acc@1: 31.2500 (25.2728)  Acc@5: 75.0000 (67.6406)  time: 0.3444  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1040/4579]  eta: 0:20:21  Lr: 0.030000  Loss: 0.9263  Acc@1: 31.2500 (25.3422)  Acc@5: 75.0000 (67.7293)  time: 0.3449  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1050/4579]  eta: 0:20:17  Lr: 0.030000  Loss: 0.8590  Acc@1: 31.2500 (25.3627)  Acc@5: 75.0000 (67.7866)  time: 0.3450  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1060/4579]  eta: 0:20:14  Lr: 0.030000  Loss: 0.7325  Acc@1: 25.0000 (25.4418)  Acc@5: 75.0000 (67.8900)  time: 0.3455  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [1070/4579]  eta: 0:20:10  Lr: 0.030000  Loss: 0.7120  Acc@1: 31.2500 (25.4727)  Acc@5: 75.0000 (67.9739)  time: 0.3459  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1080/4579]  eta: 0:20:07  Lr: 0.030000  Loss: 0.6325  Acc@1: 31.2500 (25.5608)  Acc@5: 75.0000 (68.0446)  time: 0.3454  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1090/4579]  eta: 0:20:04  Lr: 0.030000  Loss: 0.7134  Acc@1: 31.2500 (25.5786)  Acc@5: 75.0000 (68.0797)  time: 0.3452  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1100/4579]  eta: 0:20:00  Lr: 0.030000  Loss: 0.7756  Acc@1: 31.2500 (25.6358)  Acc@5: 75.0000 (68.1710)  time: 0.3463  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1110/4579]  eta: 0:19:57  Lr: 0.030000  Loss: 0.6674  Acc@1: 31.2500 (25.7201)  Acc@5: 75.0000 (68.2099)  time: 0.3467  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1120/4579]  eta: 0:19:53  Lr: 0.030000  Loss: 0.6882  Acc@1: 37.5000 (25.7750)  Acc@5: 75.0000 (68.2649)  time: 0.3460  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1130/4579]  eta: 0:19:50  Lr: 0.030000  Loss: 0.9081  Acc@1: 31.2500 (25.8013)  Acc@5: 75.0000 (68.3632)  time: 0.3453  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1140/4579]  eta: 0:19:46  Lr: 0.030000  Loss: 0.8374  Acc@1: 25.0000 (25.7888)  Acc@5: 75.0000 (68.3720)  time: 0.3446  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1150/4579]  eta: 0:19:43  Lr: 0.030000  Loss: 0.7454  Acc@1: 25.0000 (25.8634)  Acc@5: 75.0000 (68.4676)  time: 0.3444  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [1160/4579]  eta: 0:19:39  Lr: 0.030000  Loss: 0.5414  Acc@1: 31.2500 (25.9205)  Acc@5: 81.2500 (68.5777)  time: 0.3441  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [1170/4579]  eta: 0:19:36  Lr: 0.030000  Loss: 0.7165  Acc@1: 25.0000 (25.9500)  Acc@5: 75.0000 (68.6112)  time: 0.3443  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [1180/4579]  eta: 0:19:33  Lr: 0.030000  Loss: 0.8987  Acc@1: 31.2500 (25.9949)  Acc@5: 68.7500 (68.6547)  time: 0.3451  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1190/4579]  eta: 0:19:29  Lr: 0.030000  Loss: 0.6041  Acc@1: 31.2500 (26.0548)  Acc@5: 68.7500 (68.6818)  time: 0.3450  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1200/4579]  eta: 0:19:26  Lr: 0.030000  Loss: 0.8070  Acc@1: 31.2500 (26.0876)  Acc@5: 75.0000 (68.7500)  time: 0.3444  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [1210/4579]  eta: 0:19:22  Lr: 0.030000  Loss: 0.8533  Acc@1: 31.2500 (26.1922)  Acc@5: 75.0000 (68.8274)  time: 0.3450  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [1220/4579]  eta: 0:19:19  Lr: 0.030000  Loss: 0.8090  Acc@1: 37.5000 (26.2899)  Acc@5: 81.2500 (68.9292)  time: 0.3448  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [1230/4579]  eta: 0:19:15  Lr: 0.030000  Loss: 0.4877  Acc@1: 37.5000 (26.3861)  Acc@5: 75.0000 (69.0089)  time: 0.3435  data: 0.0002  max mem: 2500
Train: Epoch[1/5]  [1240/4579]  eta: 0:19:12  Lr: 0.030000  Loss: 0.7712  Acc@1: 31.2500 (26.4102)  Acc@5: 75.0000 (69.0774)  time: 0.3429  data: 0.0002  max mem: 2500
Train: Epoch[1/5]  [1250/4579]  eta: 0:19:08  Lr: 0.030000  Loss: 0.8710  Acc@1: 31.2500 (26.4588)  Acc@5: 81.2500 (69.1497)  time: 0.3428  data: 0.0002  max mem: 2500
Train: Epoch[1/5]  [1260/4579]  eta: 0:19:05  Lr: 0.030000  Loss: 0.6626  Acc@1: 31.2500 (26.5167)  Acc@5: 75.0000 (69.1614)  time: 0.3428  data: 0.0002  max mem: 2500
Train: Epoch[1/5]  [1270/4579]  eta: 0:19:01  Lr: 0.030000  Loss: 0.7638  Acc@1: 31.2500 (26.5785)  Acc@5: 75.0000 (69.2319)  time: 0.3428  data: 0.0002  max mem: 2500
Train: Epoch[1/5]  [1280/4579]  eta: 0:18:58  Lr: 0.030000  Loss: 0.7558  Acc@1: 37.5000 (26.6637)  Acc@5: 81.2500 (69.2818)  time: 0.3428  data: 0.0002  max mem: 2500
Train: Epoch[1/5]  [1290/4579]  eta: 0:18:54  Lr: 0.030000  Loss: 0.5963  Acc@1: 31.2500 (26.6847)  Acc@5: 81.2500 (69.3794)  time: 0.3429  data: 0.0002  max mem: 2500
Train: Epoch[1/5]  [1300/4579]  eta: 0:18:51  Lr: 0.030000  Loss: 0.5683  Acc@1: 31.2500 (26.7294)  Acc@5: 81.2500 (69.4466)  time: 0.3430  data: 0.0002  max mem: 2500
Train: Epoch[1/5]  [1310/4579]  eta: 0:18:47  Lr: 0.030000  Loss: 0.5198  Acc@1: 31.2500 (26.7592)  Acc@5: 81.2500 (69.5080)  time: 0.3439  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [1320/4579]  eta: 0:18:44  Lr: 0.030000  Loss: 0.6957  Acc@1: 25.0000 (26.7742)  Acc@5: 75.0000 (69.5543)  time: 0.3452  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1330/4579]  eta: 0:18:40  Lr: 0.030000  Loss: 0.4952  Acc@1: 25.0000 (26.7985)  Acc@5: 75.0000 (69.6281)  time: 0.3456  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1340/4579]  eta: 0:18:37  Lr: 0.030000  Loss: 0.7402  Acc@1: 31.2500 (26.8550)  Acc@5: 75.0000 (69.6402)  time: 0.3458  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1350/4579]  eta: 0:18:33  Lr: 0.030000  Loss: 0.8333  Acc@1: 31.2500 (26.8875)  Acc@5: 75.0000 (69.6984)  time: 0.3461  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1360/4579]  eta: 0:18:30  Lr: 0.030000  Loss: 0.6919  Acc@1: 31.2500 (26.9701)  Acc@5: 75.0000 (69.7465)  time: 0.3454  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1370/4579]  eta: 0:18:27  Lr: 0.030000  Loss: 0.5491  Acc@1: 31.2500 (27.0104)  Acc@5: 81.2500 (69.8122)  time: 0.3451  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1380/4579]  eta: 0:18:23  Lr: 0.030000  Loss: 0.5718  Acc@1: 31.2500 (27.0592)  Acc@5: 81.2500 (69.8860)  time: 0.3455  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1390/4579]  eta: 0:18:20  Lr: 0.030000  Loss: 0.6855  Acc@1: 37.5000 (27.1432)  Acc@5: 81.2500 (69.9676)  time: 0.3464  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1400/4579]  eta: 0:18:16  Lr: 0.030000  Loss: 0.8996  Acc@1: 37.5000 (27.1815)  Acc@5: 81.2500 (70.0125)  time: 0.3461  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1410/4579]  eta: 0:18:13  Lr: 0.030000  Loss: 0.7258  Acc@1: 37.5000 (27.1970)  Acc@5: 75.0000 (70.0301)  time: 0.3447  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1420/4579]  eta: 0:18:09  Lr: 0.030000  Loss: 0.8129  Acc@1: 31.2500 (27.2475)  Acc@5: 68.7500 (70.0695)  time: 0.3446  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1430/4579]  eta: 0:18:06  Lr: 0.030000  Loss: 0.7612  Acc@1: 31.2500 (27.2537)  Acc@5: 75.0000 (70.1039)  time: 0.3454  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1440/4579]  eta: 0:18:03  Lr: 0.030000  Loss: 0.6712  Acc@1: 31.2500 (27.2901)  Acc@5: 75.0000 (70.1509)  time: 0.3462  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1450/4579]  eta: 0:17:59  Lr: 0.030000  Loss: 0.6147  Acc@1: 31.2500 (27.3346)  Acc@5: 81.2500 (70.2317)  time: 0.3457  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1460/4579]  eta: 0:17:56  Lr: 0.030000  Loss: 0.7114  Acc@1: 31.2500 (27.3400)  Acc@5: 81.2500 (70.2858)  time: 0.3463  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1470/4579]  eta: 0:17:52  Lr: 0.030000  Loss: 0.7413  Acc@1: 37.5000 (27.4388)  Acc@5: 81.2500 (70.3773)  time: 0.3458  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [1480/4579]  eta: 0:17:49  Lr: 0.030000  Loss: 0.5600  Acc@1: 37.5000 (27.4772)  Acc@5: 81.2500 (70.3916)  time: 0.3440  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [1490/4579]  eta: 0:17:45  Lr: 0.030000  Loss: 0.5603  Acc@1: 31.2500 (27.5109)  Acc@5: 75.0000 (70.4225)  time: 0.3441  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [1500/4579]  eta: 0:17:42  Lr: 0.030000  Loss: 0.6462  Acc@1: 37.5000 (27.5733)  Acc@5: 81.2500 (70.4863)  time: 0.3447  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [1510/4579]  eta: 0:17:38  Lr: 0.030000  Loss: 0.5513  Acc@1: 37.5000 (27.6142)  Acc@5: 81.2500 (70.5617)  time: 0.3438  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [1520/4579]  eta: 0:17:35  Lr: 0.030000  Loss: 0.4709  Acc@1: 37.5000 (27.6833)  Acc@5: 81.2500 (70.6361)  time: 0.3424  data: 0.0002  max mem: 2500
Train: Epoch[1/5]  [1530/4579]  eta: 0:17:31  Lr: 0.030000  Loss: 0.4979  Acc@1: 31.2500 (27.7351)  Acc@5: 81.2500 (70.6809)  time: 0.3422  data: 0.0002  max mem: 2500
Train: Epoch[1/5]  [1540/4579]  eta: 0:17:28  Lr: 0.030000  Loss: 0.2433  Acc@1: 31.2500 (27.7863)  Acc@5: 75.0000 (70.7171)  time: 0.3426  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [1550/4579]  eta: 0:17:24  Lr: 0.030000  Loss: 0.5084  Acc@1: 37.5000 (27.8530)  Acc@5: 75.0000 (70.7568)  time: 0.3445  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1560/4579]  eta: 0:17:21  Lr: 0.030000  Loss: 0.4998  Acc@1: 37.5000 (27.8988)  Acc@5: 75.0000 (70.8280)  time: 0.3445  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1570/4579]  eta: 0:17:17  Lr: 0.030000  Loss: 0.8434  Acc@1: 31.2500 (27.9559)  Acc@5: 81.2500 (70.8824)  time: 0.3431  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1580/4579]  eta: 0:17:14  Lr: 0.030000  Loss: 0.7314  Acc@1: 25.0000 (27.9886)  Acc@5: 75.0000 (70.9243)  time: 0.3427  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [1590/4579]  eta: 0:17:10  Lr: 0.030000  Loss: 0.5723  Acc@1: 25.0000 (27.9973)  Acc@5: 81.2500 (70.9931)  time: 0.3423  data: 0.0002  max mem: 2500
Train: Epoch[1/5]  [1600/4579]  eta: 0:17:07  Lr: 0.030000  Loss: 0.6787  Acc@1: 31.2500 (28.0333)  Acc@5: 81.2500 (71.0220)  time: 0.3426  data: 0.0002  max mem: 2500
Train: Epoch[1/5]  [1610/4579]  eta: 0:17:03  Lr: 0.030000  Loss: 0.7242  Acc@1: 31.2500 (28.0687)  Acc@5: 81.2500 (71.0855)  time: 0.3426  data: 0.0002  max mem: 2500
Train: Epoch[1/5]  [1620/4579]  eta: 0:17:00  Lr: 0.030000  Loss: 0.9011  Acc@1: 31.2500 (28.0652)  Acc@5: 81.2500 (71.1366)  time: 0.3440  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [1630/4579]  eta: 0:16:57  Lr: 0.030000  Loss: 0.4620  Acc@1: 31.2500 (28.1346)  Acc@5: 81.2500 (71.1872)  time: 0.3448  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1640/4579]  eta: 0:16:53  Lr: 0.030000  Loss: 0.8106  Acc@1: 37.5000 (28.1459)  Acc@5: 81.2500 (71.2713)  time: 0.3449  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1650/4579]  eta: 0:16:50  Lr: 0.030000  Loss: 0.6009  Acc@1: 37.5000 (28.1950)  Acc@5: 81.2500 (71.3128)  time: 0.3446  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1660/4579]  eta: 0:16:46  Lr: 0.030000  Loss: 0.7259  Acc@1: 37.5000 (28.2021)  Acc@5: 75.0000 (71.3576)  time: 0.3435  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [1670/4579]  eta: 0:16:43  Lr: 0.030000  Loss: 0.5890  Acc@1: 37.5000 (28.2690)  Acc@5: 81.2500 (71.4280)  time: 0.3439  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [1680/4579]  eta: 0:16:39  Lr: 0.030000  Loss: 0.6023  Acc@1: 31.2500 (28.2942)  Acc@5: 75.0000 (71.4679)  time: 0.3439  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [1690/4579]  eta: 0:16:36  Lr: 0.030000  Loss: 0.4650  Acc@1: 31.2500 (28.3634)  Acc@5: 75.0000 (71.5331)  time: 0.3443  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [1700/4579]  eta: 0:16:32  Lr: 0.030000  Loss: 0.7869  Acc@1: 37.5000 (28.3767)  Acc@5: 81.2500 (71.5866)  time: 0.3439  data: 0.0002  max mem: 2500
Train: Epoch[1/5]  [1710/4579]  eta: 0:16:29  Lr: 0.030000  Loss: 0.8526  Acc@1: 25.0000 (28.3716)  Acc@5: 75.0000 (71.6102)  time: 0.3425  data: 0.0002  max mem: 2500
Train: Epoch[1/5]  [1720/4579]  eta: 0:16:25  Lr: 0.030000  Loss: 0.6633  Acc@1: 31.2500 (28.4210)  Acc@5: 75.0000 (71.6626)  time: 0.3424  data: 0.0002  max mem: 2500
Train: Epoch[1/5]  [1730/4579]  eta: 0:16:22  Lr: 0.030000  Loss: 0.7814  Acc@1: 37.5000 (28.4482)  Acc@5: 81.2500 (71.7324)  time: 0.3424  data: 0.0002  max mem: 2500
Train: Epoch[1/5]  [1740/4579]  eta: 0:16:18  Lr: 0.030000  Loss: 0.6224  Acc@1: 31.2500 (28.4678)  Acc@5: 81.2500 (71.7655)  time: 0.3428  data: 0.0002  max mem: 2500
Train: Epoch[1/5]  [1750/4579]  eta: 0:16:15  Lr: 0.030000  Loss: 0.9066  Acc@1: 37.5000 (28.5337)  Acc@5: 81.2500 (71.8375)  time: 0.3451  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1760/4579]  eta: 0:16:11  Lr: 0.030000  Loss: 0.8115  Acc@1: 37.5000 (28.5704)  Acc@5: 81.2500 (71.8874)  time: 0.3458  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1770/4579]  eta: 0:16:08  Lr: 0.030000  Loss: 0.8182  Acc@1: 37.5000 (28.6208)  Acc@5: 81.2500 (71.9473)  time: 0.3454  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1780/4579]  eta: 0:16:05  Lr: 0.030000  Loss: 0.6026  Acc@1: 37.5000 (28.6672)  Acc@5: 81.2500 (71.9926)  time: 0.3461  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1790/4579]  eta: 0:16:01  Lr: 0.030000  Loss: 0.7331  Acc@1: 37.5000 (28.7060)  Acc@5: 81.2500 (72.0338)  time: 0.3459  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1800/4579]  eta: 0:15:58  Lr: 0.030000  Loss: 0.6387  Acc@1: 31.2500 (28.7479)  Acc@5: 81.2500 (72.0954)  time: 0.3458  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1810/4579]  eta: 0:15:54  Lr: 0.030000  Loss: 0.8270  Acc@1: 31.2500 (28.7755)  Acc@5: 81.2500 (72.1528)  time: 0.3452  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1820/4579]  eta: 0:15:51  Lr: 0.030000  Loss: 0.6760  Acc@1: 31.2500 (28.7823)  Acc@5: 81.2500 (72.1959)  time: 0.3444  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [1830/4579]  eta: 0:15:47  Lr: 0.030000  Loss: 0.6856  Acc@1: 31.2500 (28.8230)  Acc@5: 81.2500 (72.2419)  time: 0.3448  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [1840/4579]  eta: 0:15:44  Lr: 0.030000  Loss: 0.6502  Acc@1: 37.5000 (28.8804)  Acc@5: 81.2500 (72.3045)  time: 0.3448  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [1850/4579]  eta: 0:15:41  Lr: 0.030000  Loss: 0.6858  Acc@1: 37.5000 (28.9067)  Acc@5: 81.2500 (72.3427)  time: 0.3444  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [1860/4579]  eta: 0:15:37  Lr: 0.030000  Loss: 0.7004  Acc@1: 37.5000 (28.9663)  Acc@5: 81.2500 (72.3838)  time: 0.3449  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [1870/4579]  eta: 0:15:34  Lr: 0.030000  Loss: 0.4932  Acc@1: 37.5000 (29.0119)  Acc@5: 81.2500 (72.4345)  time: 0.3448  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [1880/4579]  eta: 0:15:30  Lr: 0.030000  Loss: 0.5374  Acc@1: 37.5000 (29.0404)  Acc@5: 81.2500 (72.4814)  time: 0.3444  data: 0.0002  max mem: 2500
Train: Epoch[1/5]  [1890/4579]  eta: 0:15:27  Lr: 0.030000  Loss: 0.7121  Acc@1: 31.2500 (29.0752)  Acc@5: 81.2500 (72.5311)  time: 0.3450  data: 0.0002  max mem: 2500
Train: Epoch[1/5]  [1900/4579]  eta: 0:15:23  Lr: 0.030000  Loss: 0.6840  Acc@1: 37.5000 (29.1294)  Acc@5: 81.2500 (72.5704)  time: 0.3443  data: 0.0002  max mem: 2500
Train: Epoch[1/5]  [1910/4579]  eta: 0:15:20  Lr: 0.030000  Loss: 0.7368  Acc@1: 37.5000 (29.1438)  Acc@5: 81.2500 (72.6158)  time: 0.3433  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [1920/4579]  eta: 0:15:16  Lr: 0.030000  Loss: 0.5979  Acc@1: 37.5000 (29.1905)  Acc@5: 81.2500 (72.6445)  time: 0.3434  data: 0.0002  max mem: 2500
Train: Epoch[1/5]  [1930/4579]  eta: 0:15:13  Lr: 0.030000  Loss: 0.5674  Acc@1: 37.5000 (29.2433)  Acc@5: 81.2500 (72.7149)  time: 0.3441  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [1940/4579]  eta: 0:15:09  Lr: 0.030000  Loss: 0.7615  Acc@1: 37.5000 (29.2665)  Acc@5: 87.5000 (72.7653)  time: 0.3450  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [1950/4579]  eta: 0:15:06  Lr: 0.030000  Loss: 0.5284  Acc@1: 37.5000 (29.3119)  Acc@5: 87.5000 (72.8152)  time: 0.3470  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1960/4579]  eta: 0:15:03  Lr: 0.030000  Loss: 0.3929  Acc@1: 37.5000 (29.3951)  Acc@5: 87.5000 (72.8774)  time: 0.3475  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [1970/4579]  eta: 0:14:59  Lr: 0.030000  Loss: 0.7206  Acc@1: 37.5000 (29.4077)  Acc@5: 81.2500 (72.9008)  time: 0.3473  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [1980/4579]  eta: 0:14:56  Lr: 0.030000  Loss: 0.6206  Acc@1: 37.5000 (29.4738)  Acc@5: 81.2500 (72.9461)  time: 0.3464  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1990/4579]  eta: 0:14:52  Lr: 0.030000  Loss: 0.6038  Acc@1: 37.5000 (29.4890)  Acc@5: 81.2500 (72.9878)  time: 0.3453  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [2000/4579]  eta: 0:14:49  Lr: 0.030000  Loss: 0.7978  Acc@1: 37.5000 (29.5259)  Acc@5: 81.2500 (73.0229)  time: 0.3453  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [2010/4579]  eta: 0:14:45  Lr: 0.030000  Loss: 0.3952  Acc@1: 37.5000 (29.5779)  Acc@5: 81.2500 (73.0482)  time: 0.3443  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [2020/4579]  eta: 0:14:42  Lr: 0.030000  Loss: 0.7526  Acc@1: 37.5000 (29.6048)  Acc@5: 75.0000 (73.0703)  time: 0.3434  data: 0.0002  max mem: 2500
Train: Epoch[1/5]  [2030/4579]  eta: 0:14:38  Lr: 0.030000  Loss: 0.5717  Acc@1: 37.5000 (29.6683)  Acc@5: 81.2500 (73.1198)  time: 0.3433  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [2040/4579]  eta: 0:14:35  Lr: 0.030000  Loss: 0.6816  Acc@1: 37.5000 (29.7281)  Acc@5: 81.2500 (73.1412)  time: 0.3434  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [2050/4579]  eta: 0:14:32  Lr: 0.030000  Loss: 0.6315  Acc@1: 43.7500 (29.7934)  Acc@5: 87.5000 (73.2082)  time: 0.3447  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2060/4579]  eta: 0:14:28  Lr: 0.030000  Loss: 0.5932  Acc@1: 37.5000 (29.8278)  Acc@5: 87.5000 (73.2563)  time: 0.3453  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2070/4579]  eta: 0:14:25  Lr: 0.030000  Loss: 0.3586  Acc@1: 37.5000 (29.8618)  Acc@5: 81.2500 (73.2979)  time: 0.3449  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2080/4579]  eta: 0:14:21  Lr: 0.030000  Loss: 0.6722  Acc@1: 37.5000 (29.9045)  Acc@5: 81.2500 (73.3451)  time: 0.3452  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [2090/4579]  eta: 0:14:18  Lr: 0.030000  Loss: 0.6244  Acc@1: 37.5000 (29.9468)  Acc@5: 81.2500 (73.3889)  time: 0.3446  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [2100/4579]  eta: 0:14:14  Lr: 0.030000  Loss: 0.9108  Acc@1: 37.5000 (29.9768)  Acc@5: 81.2500 (73.4263)  time: 0.3444  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [2110/4579]  eta: 0:14:11  Lr: 0.030000  Loss: 0.5198  Acc@1: 37.5000 (30.0243)  Acc@5: 81.2500 (73.5019)  time: 0.3446  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [2120/4579]  eta: 0:14:07  Lr: 0.030000  Loss: 0.5747  Acc@1: 37.5000 (30.0743)  Acc@5: 87.5000 (73.5414)  time: 0.3453  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [2130/4579]  eta: 0:14:04  Lr: 0.030000  Loss: 0.7130  Acc@1: 37.5000 (30.1120)  Acc@5: 81.2500 (73.5834)  time: 0.3444  data: 0.0002  max mem: 2500
Train: Epoch[1/5]  [2140/4579]  eta: 0:14:00  Lr: 0.030000  Loss: 0.7654  Acc@1: 31.2500 (30.1290)  Acc@5: 81.2500 (73.6280)  time: 0.3428  data: 0.0002  max mem: 2500
Train: Epoch[1/5]  [2150/4579]  eta: 0:13:57  Lr: 0.030000  Loss: 0.4159  Acc@1: 31.2500 (30.1836)  Acc@5: 81.2500 (73.6605)  time: 0.3426  data: 0.0002  max mem: 2500
Train: Epoch[1/5]  [2160/4579]  eta: 0:13:54  Lr: 0.030000  Loss: 0.5398  Acc@1: 43.7500 (30.2667)  Acc@5: 81.2500 (73.7159)  time: 0.3428  data: 0.0002  max mem: 2500
Train: Epoch[1/5]  [2170/4579]  eta: 0:13:50  Lr: 0.030000  Loss: 0.4903  Acc@1: 43.7500 (30.2942)  Acc@5: 81.2500 (73.7477)  time: 0.3431  data: 0.0002  max mem: 2500
Train: Epoch[1/5]  [2180/4579]  eta: 0:13:47  Lr: 0.030000  Loss: 0.6987  Acc@1: 37.5000 (30.3301)  Acc@5: 81.2500 (73.7764)  time: 0.3430  data: 0.0002  max mem: 2500
Train: Epoch[1/5]  [2190/4579]  eta: 0:13:43  Lr: 0.030000  Loss: 0.5562  Acc@1: 43.7500 (30.3999)  Acc@5: 81.2500 (73.8361)  time: 0.3437  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [2200/4579]  eta: 0:13:40  Lr: 0.030000  Loss: 0.5369  Acc@1: 43.7500 (30.4521)  Acc@5: 87.5000 (73.8670)  time: 0.3440  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2210/4579]  eta: 0:13:36  Lr: 0.030000  Loss: 0.5286  Acc@1: 37.5000 (30.4557)  Acc@5: 87.5000 (73.9089)  time: 0.3443  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2220/4579]  eta: 0:13:33  Lr: 0.030000  Loss: 0.4413  Acc@1: 37.5000 (30.5015)  Acc@5: 81.2500 (73.9391)  time: 0.3464  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2230/4579]  eta: 0:13:29  Lr: 0.030000  Loss: 0.2339  Acc@1: 37.5000 (30.5356)  Acc@5: 81.2500 (73.9915)  time: 0.3470  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [2240/4579]  eta: 0:13:26  Lr: 0.030000  Loss: 0.5512  Acc@1: 31.2500 (30.5583)  Acc@5: 81.2500 (74.0211)  time: 0.3456  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2250/4579]  eta: 0:13:23  Lr: 0.030000  Loss: 0.3227  Acc@1: 37.5000 (30.5920)  Acc@5: 81.2500 (74.0671)  time: 0.3456  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2260/4579]  eta: 0:13:19  Lr: 0.030000  Loss: 0.8154  Acc@1: 37.5000 (30.6280)  Acc@5: 81.2500 (74.0961)  time: 0.3454  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [2270/4579]  eta: 0:13:16  Lr: 0.030000  Loss: 0.4762  Acc@1: 31.2500 (30.6500)  Acc@5: 81.2500 (74.1221)  time: 0.3451  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [2280/4579]  eta: 0:13:12  Lr: 0.030000  Loss: 0.6542  Acc@1: 31.2500 (30.6527)  Acc@5: 81.2500 (74.1588)  time: 0.3458  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [2290/4579]  eta: 0:13:09  Lr: 0.030000  Loss: 0.8387  Acc@1: 37.5000 (30.6853)  Acc@5: 81.2500 (74.1952)  time: 0.3454  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2300/4579]  eta: 0:13:05  Lr: 0.030000  Loss: 0.4808  Acc@1: 37.5000 (30.7231)  Acc@5: 81.2500 (74.2123)  time: 0.3446  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [2310/4579]  eta: 0:13:02  Lr: 0.030000  Loss: 0.3806  Acc@1: 37.5000 (30.7659)  Acc@5: 81.2500 (74.2752)  time: 0.3444  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [2320/4579]  eta: 0:12:58  Lr: 0.030000  Loss: 0.4683  Acc@1: 43.7500 (30.7922)  Acc@5: 87.5000 (74.3295)  time: 0.3441  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [2330/4579]  eta: 0:12:55  Lr: 0.030000  Loss: 0.4872  Acc@1: 43.7500 (30.8451)  Acc@5: 81.2500 (74.3565)  time: 0.3439  data: 0.0002  max mem: 2500
Train: Epoch[1/5]  [2340/4579]  eta: 0:12:51  Lr: 0.030000  Loss: 0.4163  Acc@1: 43.7500 (30.9003)  Acc@5: 87.5000 (74.4153)  time: 0.3435  data: 0.0002  max mem: 2500
Train: Epoch[1/5]  [2350/4579]  eta: 0:12:48  Lr: 0.030000  Loss: 0.4116  Acc@1: 37.5000 (30.9124)  Acc@5: 87.5000 (74.4470)  time: 0.3441  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [2360/4579]  eta: 0:12:45  Lr: 0.030000  Loss: 0.6070  Acc@1: 37.5000 (30.9535)  Acc@5: 87.5000 (74.4891)  time: 0.3471  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2370/4579]  eta: 0:12:41  Lr: 0.030000  Loss: 0.5889  Acc@1: 37.5000 (30.9943)  Acc@5: 87.5000 (74.5150)  time: 0.3471  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2380/4579]  eta: 0:12:38  Lr: 0.030000  Loss: 0.3628  Acc@1: 37.5000 (31.0374)  Acc@5: 87.5000 (74.5669)  time: 0.3448  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [2390/4579]  eta: 0:12:34  Lr: 0.030000  Loss: 0.5765  Acc@1: 37.5000 (31.0749)  Acc@5: 87.5000 (74.5974)  time: 0.3446  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [2400/4579]  eta: 0:12:31  Lr: 0.030000  Loss: 0.3428  Acc@1: 43.7500 (31.1407)  Acc@5: 87.5000 (74.6382)  time: 0.3448  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [2410/4579]  eta: 0:12:27  Lr: 0.030000  Loss: 0.6184  Acc@1: 37.5000 (31.1567)  Acc@5: 87.5000 (74.6630)  time: 0.3446  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [2420/4579]  eta: 0:12:24  Lr: 0.030000  Loss: 0.5379  Acc@1: 37.5000 (31.1984)  Acc@5: 81.2500 (74.6876)  time: 0.3457  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [2430/4579]  eta: 0:12:20  Lr: 0.030000  Loss: 0.6301  Acc@1: 37.5000 (31.2346)  Acc@5: 81.2500 (74.6966)  time: 0.3448  data: 0.0002  max mem: 2500
Train: Epoch[1/5]  [2440/4579]  eta: 0:12:17  Lr: 0.030000  Loss: 0.8227  Acc@1: 31.2500 (31.2372)  Acc@5: 81.2500 (74.7184)  time: 0.3429  data: 0.0002  max mem: 2500
Train: Epoch[1/5]  [2450/4579]  eta: 0:12:14  Lr: 0.030000  Loss: 0.5795  Acc@1: 31.2500 (31.2729)  Acc@5: 81.2500 (74.7654)  time: 0.3429  data: 0.0002  max mem: 2500
Train: Epoch[1/5]  [2460/4579]  eta: 0:12:10  Lr: 0.030000  Loss: 0.4953  Acc@1: 43.7500 (31.3186)  Acc@5: 87.5000 (74.8070)  time: 0.3430  data: 0.0002  max mem: 2500
Train: Epoch[1/5]  [2470/4579]  eta: 0:12:07  Lr: 0.030000  Loss: 0.2191  Acc@1: 43.7500 (31.3841)  Acc@5: 87.5000 (74.8482)  time: 0.3431  data: 0.0002  max mem: 2500
Train: Epoch[1/5]  [2480/4579]  eta: 0:12:03  Lr: 0.030000  Loss: 0.5061  Acc@1: 43.7500 (31.4213)  Acc@5: 81.2500 (74.8791)  time: 0.3431  data: 0.0002  max mem: 2500
Train: Epoch[1/5]  [2490/4579]  eta: 0:12:00  Lr: 0.030000  Loss: 0.7024  Acc@1: 37.5000 (31.4758)  Acc@5: 81.2500 (74.9297)  time: 0.3431  data: 0.0002  max mem: 2500
Train: Epoch[1/5]  [2500/4579]  eta: 0:11:56  Lr: 0.030000  Loss: 0.5682  Acc@1: 37.5000 (31.5124)  Acc@5: 81.2500 (74.9575)  time: 0.3428  data: 0.0002  max mem: 2500
Train: Epoch[1/5]  [2510/4579]  eta: 0:11:53  Lr: 0.030000  Loss: 0.4601  Acc@1: 43.7500 (31.5860)  Acc@5: 87.5000 (75.0100)  time: 0.3429  data: 0.0002  max mem: 2500
Train: Epoch[1/5]  [2520/4579]  eta: 0:11:49  Lr: 0.030000  Loss: 0.4084  Acc@1: 50.0000 (31.6392)  Acc@5: 87.5000 (75.0620)  time: 0.3444  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [2530/4579]  eta: 0:11:46  Lr: 0.030000  Loss: 0.1822  Acc@1: 43.7500 (31.7068)  Acc@5: 87.5000 (75.1062)  time: 0.3455  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [2540/4579]  eta: 0:11:42  Lr: 0.030000  Loss: 0.6238  Acc@1: 43.7500 (31.7444)  Acc@5: 87.5000 (75.1500)  time: 0.3448  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [2550/4579]  eta: 0:11:39  Lr: 0.030000  Loss: 0.5675  Acc@1: 43.7500 (31.7841)  Acc@5: 87.5000 (75.1813)  time: 0.3444  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2560/4579]  eta: 0:11:36  Lr: 0.030000  Loss: 0.7649  Acc@1: 37.5000 (31.8186)  Acc@5: 81.2500 (75.2148)  time: 0.3443  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2570/4579]  eta: 0:11:32  Lr: 0.030000  Loss: 0.5827  Acc@1: 37.5000 (31.8383)  Acc@5: 81.2500 (75.2553)  time: 0.3442  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2580/4579]  eta: 0:11:29  Lr: 0.030000  Loss: 0.2811  Acc@1: 43.7500 (31.8893)  Acc@5: 87.5000 (75.3051)  time: 0.3453  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2590/4579]  eta: 0:11:25  Lr: 0.030000  Loss: 0.5473  Acc@1: 37.5000 (31.9134)  Acc@5: 87.5000 (75.3449)  time: 0.3456  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2600/4579]  eta: 0:11:22  Lr: 0.030000  Loss: 0.4650  Acc@1: 37.5000 (31.9565)  Acc@5: 87.5000 (75.3965)  time: 0.3455  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2610/4579]  eta: 0:11:18  Lr: 0.030000  Loss: 0.6837  Acc@1: 37.5000 (31.9753)  Acc@5: 87.5000 (75.4309)  time: 0.3457  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2620/4579]  eta: 0:11:15  Lr: 0.030000  Loss: 0.4774  Acc@1: 37.5000 (32.0011)  Acc@5: 81.2500 (75.4555)  time: 0.3450  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2630/4579]  eta: 0:11:11  Lr: 0.030000  Loss: 0.5180  Acc@1: 31.2500 (32.0220)  Acc@5: 87.5000 (75.5012)  time: 0.3452  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2640/4579]  eta: 0:11:08  Lr: 0.030000  Loss: 0.8983  Acc@1: 43.7500 (32.0688)  Acc@5: 87.5000 (75.5325)  time: 0.3471  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2650/4579]  eta: 0:11:05  Lr: 0.030000  Loss: 0.6051  Acc@1: 43.7500 (32.0846)  Acc@5: 81.2500 (75.5588)  time: 0.3468  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2660/4579]  eta: 0:11:01  Lr: 0.030000  Loss: 0.2311  Acc@1: 37.5000 (32.1073)  Acc@5: 81.2500 (75.5919)  time: 0.3452  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2670/4579]  eta: 0:10:58  Lr: 0.030000  Loss: 0.5107  Acc@1: 37.5000 (32.1251)  Acc@5: 87.5000 (75.6388)  time: 0.3470  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2680/4579]  eta: 0:10:54  Lr: 0.030000  Loss: 0.4144  Acc@1: 37.5000 (32.1499)  Acc@5: 87.5000 (75.6737)  time: 0.3466  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [2690/4579]  eta: 0:10:51  Lr: 0.030000  Loss: 0.7716  Acc@1: 37.5000 (32.1512)  Acc@5: 81.2500 (75.6968)  time: 0.3442  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [2700/4579]  eta: 0:10:47  Lr: 0.030000  Loss: 0.6711  Acc@1: 31.2500 (32.1733)  Acc@5: 81.2500 (75.7104)  time: 0.3442  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [2710/4579]  eta: 0:10:44  Lr: 0.030000  Loss: 0.6280  Acc@1: 37.5000 (32.2137)  Acc@5: 81.2500 (75.7354)  time: 0.3452  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [2720/4579]  eta: 0:10:40  Lr: 0.030000  Loss: 0.5702  Acc@1: 37.5000 (32.2492)  Acc@5: 81.2500 (75.7603)  time: 0.3451  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [2730/4579]  eta: 0:10:37  Lr: 0.030000  Loss: 0.8426  Acc@1: 37.5000 (32.2570)  Acc@5: 81.2500 (75.7781)  time: 0.3437  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [2740/4579]  eta: 0:10:34  Lr: 0.030000  Loss: 0.8386  Acc@1: 37.5000 (32.2715)  Acc@5: 81.2500 (75.8026)  time: 0.3441  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [2750/4579]  eta: 0:10:30  Lr: 0.030000  Loss: 0.5242  Acc@1: 43.7500 (32.3155)  Acc@5: 81.2500 (75.8111)  time: 0.3435  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [2760/4579]  eta: 0:10:27  Lr: 0.030000  Loss: 0.4735  Acc@1: 43.7500 (32.3683)  Acc@5: 81.2500 (75.8466)  time: 0.3423  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [2770/4579]  eta: 0:10:23  Lr: 0.030000  Loss: 0.5577  Acc@1: 43.7500 (32.3868)  Acc@5: 81.2500 (75.8571)  time: 0.3426  data: 0.0002  max mem: 2500
Train: Epoch[1/5]  [2780/4579]  eta: 0:10:20  Lr: 0.030000  Loss: 0.6979  Acc@1: 43.7500 (32.4231)  Acc@5: 81.2500 (75.8967)  time: 0.3439  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [2790/4579]  eta: 0:10:16  Lr: 0.030000  Loss: 0.3109  Acc@1: 37.5000 (32.4525)  Acc@5: 87.5000 (75.9204)  time: 0.3443  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [2800/4579]  eta: 0:10:13  Lr: 0.030000  Loss: 0.5512  Acc@1: 37.5000 (32.4795)  Acc@5: 81.2500 (75.9394)  time: 0.3448  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2810/4579]  eta: 0:10:09  Lr: 0.030000  Loss: 0.5521  Acc@1: 37.5000 (32.5084)  Acc@5: 81.2500 (75.9583)  time: 0.3448  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2820/4579]  eta: 0:10:06  Lr: 0.030000  Loss: 0.5642  Acc@1: 37.5000 (32.5461)  Acc@5: 87.5000 (75.9970)  time: 0.3449  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2830/4579]  eta: 0:10:02  Lr: 0.030000  Loss: 0.7089  Acc@1: 37.5000 (32.5636)  Acc@5: 87.5000 (76.0155)  time: 0.3451  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2840/4579]  eta: 0:09:59  Lr: 0.030000  Loss: 0.6678  Acc@1: 37.5000 (32.6162)  Acc@5: 87.5000 (76.0560)  time: 0.3442  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2850/4579]  eta: 0:09:56  Lr: 0.030000  Loss: 0.5218  Acc@1: 43.7500 (32.6574)  Acc@5: 87.5000 (76.0851)  time: 0.3436  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2860/4579]  eta: 0:09:52  Lr: 0.030000  Loss: 0.2498  Acc@1: 43.7500 (32.7005)  Acc@5: 81.2500 (76.1207)  time: 0.3435  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [2870/4579]  eta: 0:09:49  Lr: 0.030000  Loss: 0.6777  Acc@1: 43.7500 (32.7325)  Acc@5: 81.2500 (76.1494)  time: 0.3441  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [2880/4579]  eta: 0:09:45  Lr: 0.030000  Loss: 0.1979  Acc@1: 43.7500 (32.7707)  Acc@5: 87.5000 (76.1758)  time: 0.3443  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [2890/4579]  eta: 0:09:42  Lr: 0.030000  Loss: 0.2453  Acc@1: 43.7500 (32.8282)  Acc@5: 81.2500 (76.2085)  time: 0.3445  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [2900/4579]  eta: 0:09:38  Lr: 0.030000  Loss: 0.5572  Acc@1: 43.7500 (32.8744)  Acc@5: 81.2500 (76.2345)  time: 0.3438  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [2910/4579]  eta: 0:09:35  Lr: 0.030000  Loss: 0.2499  Acc@1: 43.7500 (32.9032)  Acc@5: 81.2500 (76.2496)  time: 0.3430  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [2920/4579]  eta: 0:09:31  Lr: 0.030000  Loss: 0.4309  Acc@1: 37.5000 (32.9296)  Acc@5: 81.2500 (76.2795)  time: 0.3430  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [2930/4579]  eta: 0:09:28  Lr: 0.030000  Loss: 0.9215  Acc@1: 37.5000 (32.9303)  Acc@5: 87.5000 (76.3029)  time: 0.3439  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [2940/4579]  eta: 0:09:25  Lr: 0.030000  Loss: 0.6492  Acc@1: 37.5000 (32.9607)  Acc@5: 87.5000 (76.3303)  time: 0.3452  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2950/4579]  eta: 0:09:21  Lr: 0.030000  Loss: 0.3595  Acc@1: 43.7500 (33.0079)  Acc@5: 81.2500 (76.3618)  time: 0.3454  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2960/4579]  eta: 0:09:18  Lr: 0.030000  Loss: 0.6175  Acc@1: 50.0000 (33.0589)  Acc@5: 87.5000 (76.4058)  time: 0.3462  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2970/4579]  eta: 0:09:14  Lr: 0.030000  Loss: 0.6222  Acc@1: 43.7500 (33.1012)  Acc@5: 87.5000 (76.4473)  time: 0.3463  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2980/4579]  eta: 0:09:11  Lr: 0.030000  Loss: 0.7394  Acc@1: 43.7500 (33.1202)  Acc@5: 87.5000 (76.4634)  time: 0.3451  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [2990/4579]  eta: 0:09:07  Lr: 0.030000  Loss: 0.6067  Acc@1: 43.7500 (33.1536)  Acc@5: 81.2500 (76.4941)  time: 0.3452  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [3000/4579]  eta: 0:09:04  Lr: 0.030000  Loss: 0.5679  Acc@1: 43.7500 (33.1848)  Acc@5: 81.2500 (76.5057)  time: 0.3456  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [3010/4579]  eta: 0:09:00  Lr: 0.030000  Loss: 0.4700  Acc@1: 43.7500 (33.2261)  Acc@5: 81.2500 (76.5236)  time: 0.3450  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [3020/4579]  eta: 0:08:57  Lr: 0.030000  Loss: 0.6376  Acc@1: 43.7500 (33.2651)  Acc@5: 81.2500 (76.5620)  time: 0.3439  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [3030/4579]  eta: 0:08:54  Lr: 0.030000  Loss: 0.7548  Acc@1: 43.7500 (33.3058)  Acc@5: 87.5000 (76.5816)  time: 0.3436  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [3040/4579]  eta: 0:08:50  Lr: 0.030000  Loss: 0.4461  Acc@1: 43.7500 (33.3258)  Acc@5: 87.5000 (76.6257)  time: 0.3439  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [3050/4579]  eta: 0:08:47  Lr: 0.030000  Loss: 0.1920  Acc@1: 43.7500 (33.3661)  Acc@5: 87.5000 (76.6531)  time: 0.3442  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [3060/4579]  eta: 0:08:43  Lr: 0.030000  Loss: 0.3839  Acc@1: 50.0000 (33.4266)  Acc@5: 87.5000 (76.7008)  time: 0.3450  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3070/4579]  eta: 0:08:40  Lr: 0.030000  Loss: 0.5953  Acc@1: 50.0000 (33.4582)  Acc@5: 87.5000 (76.7319)  time: 0.3460  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3080/4579]  eta: 0:08:36  Lr: 0.030000  Loss: 0.6727  Acc@1: 43.7500 (33.4713)  Acc@5: 87.5000 (76.7567)  time: 0.3465  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3090/4579]  eta: 0:08:33  Lr: 0.030000  Loss: 0.3378  Acc@1: 43.7500 (33.5106)  Acc@5: 87.5000 (76.7915)  time: 0.3460  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [3100/4579]  eta: 0:08:29  Lr: 0.030000  Loss: 0.2862  Acc@1: 43.7500 (33.5376)  Acc@5: 87.5000 (76.8180)  time: 0.3450  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [3110/4579]  eta: 0:08:26  Lr: 0.030000  Loss: 0.6428  Acc@1: 43.7500 (33.5624)  Acc@5: 81.2500 (76.8242)  time: 0.3445  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [3120/4579]  eta: 0:08:22  Lr: 0.030000  Loss: 0.3620  Acc@1: 43.7500 (33.5890)  Acc@5: 87.5000 (76.8644)  time: 0.3449  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [3130/4579]  eta: 0:08:19  Lr: 0.030000  Loss: 0.4419  Acc@1: 43.7500 (33.6075)  Acc@5: 87.5000 (76.9063)  time: 0.3446  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [3140/4579]  eta: 0:08:16  Lr: 0.030000  Loss: 0.4441  Acc@1: 43.7500 (33.6477)  Acc@5: 87.5000 (76.9281)  time: 0.3439  data: 0.0002  max mem: 2500
Train: Epoch[1/5]  [3150/4579]  eta: 0:08:12  Lr: 0.030000  Loss: 0.6097  Acc@1: 43.7500 (33.6778)  Acc@5: 81.2500 (76.9478)  time: 0.3443  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [3160/4579]  eta: 0:08:09  Lr: 0.030000  Loss: 0.3428  Acc@1: 43.7500 (33.7176)  Acc@5: 87.5000 (76.9911)  time: 0.3441  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [3170/4579]  eta: 0:08:05  Lr: 0.030000  Loss: 0.6647  Acc@1: 50.0000 (33.7532)  Acc@5: 87.5000 (77.0065)  time: 0.3441  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [3180/4579]  eta: 0:08:02  Lr: 0.030000  Loss: 0.2707  Acc@1: 43.7500 (33.7689)  Acc@5: 81.2500 (77.0355)  time: 0.3445  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [3190/4579]  eta: 0:07:58  Lr: 0.030000  Loss: 0.5925  Acc@1: 43.7500 (33.8099)  Acc@5: 87.5000 (77.0781)  time: 0.3441  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [3200/4579]  eta: 0:07:55  Lr: 0.030000  Loss: 0.5826  Acc@1: 37.5000 (33.8234)  Acc@5: 87.5000 (77.0872)  time: 0.3446  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [3210/4579]  eta: 0:07:51  Lr: 0.030000  Loss: 0.6197  Acc@1: 37.5000 (33.8563)  Acc@5: 81.2500 (77.1177)  time: 0.3448  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3220/4579]  eta: 0:07:48  Lr: 0.030000  Loss: 0.4055  Acc@1: 50.0000 (33.9200)  Acc@5: 87.5000 (77.1461)  time: 0.3448  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [3230/4579]  eta: 0:07:45  Lr: 0.030000  Loss: 0.3480  Acc@1: 50.0000 (33.9659)  Acc@5: 87.5000 (77.1897)  time: 0.3450  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [3240/4579]  eta: 0:07:41  Lr: 0.030000  Loss: 0.3761  Acc@1: 43.7500 (34.0019)  Acc@5: 87.5000 (77.2215)  time: 0.3443  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [3250/4579]  eta: 0:07:38  Lr: 0.030000  Loss: 0.5520  Acc@1: 43.7500 (34.0395)  Acc@5: 93.7500 (77.2628)  time: 0.3445  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [3260/4579]  eta: 0:07:34  Lr: 0.030000  Loss: 0.4743  Acc@1: 43.7500 (34.0693)  Acc@5: 93.7500 (77.2903)  time: 0.3447  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [3270/4579]  eta: 0:07:31  Lr: 0.030000  Loss: 0.3927  Acc@1: 43.7500 (34.1085)  Acc@5: 87.5000 (77.3330)  time: 0.3446  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [3280/4579]  eta: 0:07:27  Lr: 0.030000  Loss: 0.7115  Acc@1: 43.7500 (34.1436)  Acc@5: 93.7500 (77.3602)  time: 0.3452  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3290/4579]  eta: 0:07:24  Lr: 0.030000  Loss: 0.3521  Acc@1: 43.7500 (34.1765)  Acc@5: 87.5000 (77.3777)  time: 0.3445  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [3300/4579]  eta: 0:07:20  Lr: 0.030000  Loss: 0.8311  Acc@1: 43.7500 (34.1980)  Acc@5: 81.2500 (77.3913)  time: 0.3433  data: 0.0002  max mem: 2500
Train: Epoch[1/5]  [3310/4579]  eta: 0:07:17  Lr: 0.030000  Loss: 0.4429  Acc@1: 43.7500 (34.2419)  Acc@5: 87.5000 (77.4256)  time: 0.3432  data: 0.0002  max mem: 2500
Train: Epoch[1/5]  [3320/4579]  eta: 0:07:14  Lr: 0.030000  Loss: 0.3404  Acc@1: 43.7500 (34.2743)  Acc@5: 81.2500 (77.4390)  time: 0.3431  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [3330/4579]  eta: 0:07:10  Lr: 0.030000  Loss: 0.2090  Acc@1: 43.7500 (34.3046)  Acc@5: 81.2500 (77.4749)  time: 0.3431  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [3340/4579]  eta: 0:07:07  Lr: 0.030000  Loss: 0.4057  Acc@1: 43.7500 (34.3292)  Acc@5: 87.5000 (77.4787)  time: 0.3430  data: 0.0002  max mem: 2500
Train: Epoch[1/5]  [3350/4579]  eta: 0:07:03  Lr: 0.030000  Loss: 0.3596  Acc@1: 50.0000 (34.3797)  Acc@5: 81.2500 (77.5067)  time: 0.3431  data: 0.0002  max mem: 2500
Train: Epoch[1/5]  [3360/4579]  eta: 0:07:00  Lr: 0.030000  Loss: 0.2834  Acc@1: 50.0000 (34.4206)  Acc@5: 87.5000 (77.5327)  time: 0.3431  data: 0.0002  max mem: 2500
Train: Epoch[1/5]  [3370/4579]  eta: 0:06:56  Lr: 0.030000  Loss: 0.5948  Acc@1: 43.7500 (34.4575)  Acc@5: 81.2500 (77.5493)  time: 0.3429  data: 0.0002  max mem: 2500
Train: Epoch[1/5]  [3380/4579]  eta: 0:06:53  Lr: 0.030000  Loss: 0.6162  Acc@1: 50.0000 (34.4850)  Acc@5: 81.2500 (77.5714)  time: 0.3436  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [3390/4579]  eta: 0:06:49  Lr: 0.030000  Loss: 0.1265  Acc@1: 50.0000 (34.5344)  Acc@5: 87.5000 (77.5951)  time: 0.3447  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3400/4579]  eta: 0:06:46  Lr: 0.030000  Loss: 0.8645  Acc@1: 43.7500 (34.5597)  Acc@5: 87.5000 (77.6224)  time: 0.3447  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3410/4579]  eta: 0:06:42  Lr: 0.030000  Loss: 0.2548  Acc@1: 43.7500 (34.5921)  Acc@5: 87.5000 (77.6477)  time: 0.3443  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3420/4579]  eta: 0:06:39  Lr: 0.030000  Loss: 0.7491  Acc@1: 43.7500 (34.6390)  Acc@5: 87.5000 (77.6710)  time: 0.3446  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3430/4579]  eta: 0:06:36  Lr: 0.030000  Loss: 0.3011  Acc@1: 43.7500 (34.6583)  Acc@5: 87.5000 (77.6997)  time: 0.3448  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3440/4579]  eta: 0:06:32  Lr: 0.030000  Loss: 0.3485  Acc@1: 37.5000 (34.6811)  Acc@5: 81.2500 (77.7100)  time: 0.3441  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [3450/4579]  eta: 0:06:29  Lr: 0.030000  Loss: 0.6333  Acc@1: 43.7500 (34.7218)  Acc@5: 81.2500 (77.7293)  time: 0.3436  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3460/4579]  eta: 0:06:25  Lr: 0.030000  Loss: 0.2853  Acc@1: 43.7500 (34.7226)  Acc@5: 81.2500 (77.7431)  time: 0.3444  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3470/4579]  eta: 0:06:22  Lr: 0.030000  Loss: 0.5742  Acc@1: 37.5000 (34.7486)  Acc@5: 87.5000 (77.7730)  time: 0.3450  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3480/4579]  eta: 0:06:18  Lr: 0.030000  Loss: 0.4197  Acc@1: 43.7500 (34.7781)  Acc@5: 87.5000 (77.7866)  time: 0.3463  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3490/4579]  eta: 0:06:15  Lr: 0.030000  Loss: 0.4076  Acc@1: 43.7500 (34.8163)  Acc@5: 87.5000 (77.8180)  time: 0.3462  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3500/4579]  eta: 0:06:11  Lr: 0.030000  Loss: 0.5020  Acc@1: 50.0000 (34.8508)  Acc@5: 93.7500 (77.8456)  time: 0.3448  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3510/4579]  eta: 0:06:08  Lr: 0.030000  Loss: 0.3286  Acc@1: 50.0000 (34.8939)  Acc@5: 87.5000 (77.8607)  time: 0.3446  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3520/4579]  eta: 0:06:05  Lr: 0.030000  Loss: 0.5425  Acc@1: 50.0000 (34.9226)  Acc@5: 87.5000 (77.8845)  time: 0.3457  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3530/4579]  eta: 0:06:01  Lr: 0.030000  Loss: 0.5849  Acc@1: 43.7500 (34.9458)  Acc@5: 87.5000 (77.9099)  time: 0.3458  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [3540/4579]  eta: 0:05:58  Lr: 0.030000  Loss: 0.4017  Acc@1: 43.7500 (34.9689)  Acc@5: 87.5000 (77.9370)  time: 0.3440  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3550/4579]  eta: 0:05:54  Lr: 0.030000  Loss: 0.5050  Acc@1: 43.7500 (35.0077)  Acc@5: 87.5000 (77.9569)  time: 0.3505  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [3560/4579]  eta: 0:05:51  Lr: 0.030000  Loss: 0.4839  Acc@1: 50.0000 (35.0534)  Acc@5: 87.5000 (77.9749)  time: 0.3510  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [3570/4579]  eta: 0:05:47  Lr: 0.030000  Loss: 0.6823  Acc@1: 43.7500 (35.0725)  Acc@5: 87.5000 (77.9981)  time: 0.3445  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [3580/4579]  eta: 0:05:44  Lr: 0.030000  Loss: 0.2540  Acc@1: 37.5000 (35.0827)  Acc@5: 87.5000 (78.0246)  time: 0.3443  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [3590/4579]  eta: 0:05:40  Lr: 0.030000  Loss: 0.1227  Acc@1: 37.5000 (35.0947)  Acc@5: 87.5000 (78.0388)  time: 0.3449  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [3600/4579]  eta: 0:05:37  Lr: 0.030000  Loss: 0.5609  Acc@1: 43.7500 (35.1170)  Acc@5: 87.5000 (78.0616)  time: 0.3451  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [3610/4579]  eta: 0:05:34  Lr: 0.030000  Loss: 0.6407  Acc@1: 50.0000 (35.1513)  Acc@5: 87.5000 (78.0878)  time: 0.3441  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [3620/4579]  eta: 0:05:30  Lr: 0.030000  Loss: 0.5612  Acc@1: 50.0000 (35.1767)  Acc@5: 87.5000 (78.1069)  time: 0.3437  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [3630/4579]  eta: 0:05:27  Lr: 0.030000  Loss: 0.5774  Acc@1: 43.7500 (35.1918)  Acc@5: 87.5000 (78.1310)  time: 0.3441  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [3640/4579]  eta: 0:05:23  Lr: 0.030000  Loss: 0.5757  Acc@1: 43.7500 (35.2307)  Acc@5: 87.5000 (78.1499)  time: 0.3434  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [3650/4579]  eta: 0:05:20  Lr: 0.030000  Loss: 0.3291  Acc@1: 43.7500 (35.2660)  Acc@5: 87.5000 (78.1823)  time: 0.3424  data: 0.0002  max mem: 2500
Train: Epoch[1/5]  [3660/4579]  eta: 0:05:16  Lr: 0.030000  Loss: 0.3682  Acc@1: 43.7500 (35.3080)  Acc@5: 93.7500 (78.2249)  time: 0.3425  data: 0.0002  max mem: 2500
Train: Epoch[1/5]  [3670/4579]  eta: 0:05:13  Lr: 0.030000  Loss: 0.7609  Acc@1: 50.0000 (35.3548)  Acc@5: 93.7500 (78.2501)  time: 0.3424  data: 0.0002  max mem: 2500
Train: Epoch[1/5]  [3680/4579]  eta: 0:05:09  Lr: 0.030000  Loss: 0.3330  Acc@1: 50.0000 (35.3895)  Acc@5: 87.5000 (78.2787)  time: 0.3428  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [3690/4579]  eta: 0:05:06  Lr: 0.030000  Loss: 0.3295  Acc@1: 50.0000 (35.4223)  Acc@5: 93.7500 (78.3121)  time: 0.3445  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [3700/4579]  eta: 0:05:02  Lr: 0.030000  Loss: 0.5883  Acc@1: 43.7500 (35.4397)  Acc@5: 87.5000 (78.3352)  time: 0.3449  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3710/4579]  eta: 0:04:59  Lr: 0.030000  Loss: 0.5526  Acc@1: 37.5000 (35.4672)  Acc@5: 87.5000 (78.3515)  time: 0.3449  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3720/4579]  eta: 0:04:56  Lr: 0.030000  Loss: 0.3073  Acc@1: 50.0000 (35.5113)  Acc@5: 81.2500 (78.3660)  time: 0.3447  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3730/4579]  eta: 0:04:52  Lr: 0.030000  Loss: 0.8010  Acc@1: 43.7500 (35.5250)  Acc@5: 81.2500 (78.3855)  time: 0.3449  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3740/4579]  eta: 0:04:49  Lr: 0.030000  Loss: 0.4009  Acc@1: 37.5000 (35.5503)  Acc@5: 87.5000 (78.4115)  time: 0.3450  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3750/4579]  eta: 0:04:45  Lr: 0.030000  Loss: 0.4840  Acc@1: 43.7500 (35.5755)  Acc@5: 87.5000 (78.4291)  time: 0.3443  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3760/4579]  eta: 0:04:42  Lr: 0.030000  Loss: 0.4561  Acc@1: 43.7500 (35.5989)  Acc@5: 87.5000 (78.4466)  time: 0.3446  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3770/4579]  eta: 0:04:38  Lr: 0.030000  Loss: 0.3565  Acc@1: 50.0000 (35.6338)  Acc@5: 87.5000 (78.4755)  time: 0.3444  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3780/4579]  eta: 0:04:35  Lr: 0.030000  Loss: 0.5377  Acc@1: 43.7500 (35.6503)  Acc@5: 87.5000 (78.5044)  time: 0.3443  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [3790/4579]  eta: 0:04:31  Lr: 0.030000  Loss: 0.3917  Acc@1: 43.7500 (35.6799)  Acc@5: 87.5000 (78.5297)  time: 0.3441  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [3800/4579]  eta: 0:04:28  Lr: 0.030000  Loss: 0.4775  Acc@1: 43.7500 (35.7094)  Acc@5: 87.5000 (78.5533)  time: 0.3439  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [3810/4579]  eta: 0:04:25  Lr: 0.030000  Loss: 0.6113  Acc@1: 43.7500 (35.7272)  Acc@5: 87.5000 (78.5735)  time: 0.3447  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [3820/4579]  eta: 0:04:21  Lr: 0.030000  Loss: 0.5348  Acc@1: 37.5000 (35.7433)  Acc@5: 87.5000 (78.6018)  time: 0.3447  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [3830/4579]  eta: 0:04:18  Lr: 0.030000  Loss: 0.5353  Acc@1: 43.7500 (35.7691)  Acc@5: 87.5000 (78.6169)  time: 0.3452  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [3840/4579]  eta: 0:04:14  Lr: 0.030000  Loss: 0.3174  Acc@1: 50.0000 (35.8029)  Acc@5: 87.5000 (78.6351)  time: 0.3443  data: 0.0002  max mem: 2500
Train: Epoch[1/5]  [3850/4579]  eta: 0:04:11  Lr: 0.030000  Loss: 0.9575  Acc@1: 50.0000 (35.8348)  Acc@5: 87.5000 (78.6598)  time: 0.3426  data: 0.0002  max mem: 2500
Train: Epoch[1/5]  [3860/4579]  eta: 0:04:07  Lr: 0.030000  Loss: 0.3853  Acc@1: 37.5000 (35.8456)  Acc@5: 87.5000 (78.6697)  time: 0.3427  data: 0.0002  max mem: 2500
Train: Epoch[1/5]  [3870/4579]  eta: 0:04:04  Lr: 0.030000  Loss: 0.3624  Acc@1: 37.5000 (35.8644)  Acc@5: 87.5000 (78.6909)  time: 0.3428  data: 0.0002  max mem: 2500
Train: Epoch[1/5]  [3880/4579]  eta: 0:04:00  Lr: 0.030000  Loss: 0.3968  Acc@1: 43.7500 (35.8928)  Acc@5: 87.5000 (78.7104)  time: 0.3431  data: 0.0002  max mem: 2500
Train: Epoch[1/5]  [3890/4579]  eta: 0:03:57  Lr: 0.030000  Loss: 0.3898  Acc@1: 37.5000 (35.9050)  Acc@5: 87.5000 (78.7314)  time: 0.3430  data: 0.0002  max mem: 2500
Train: Epoch[1/5]  [3900/4579]  eta: 0:03:54  Lr: 0.030000  Loss: 0.4695  Acc@1: 43.7500 (35.9267)  Acc@5: 87.5000 (78.7426)  time: 0.3433  data: 0.0002  max mem: 2500
Train: Epoch[1/5]  [3910/4579]  eta: 0:03:50  Lr: 0.030000  Loss: 0.4105  Acc@1: 43.7500 (35.9579)  Acc@5: 87.5000 (78.7666)  time: 0.3453  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [3920/4579]  eta: 0:03:47  Lr: 0.030000  Loss: 0.3295  Acc@1: 43.7500 (35.9953)  Acc@5: 87.5000 (78.7921)  time: 0.3462  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [3930/4579]  eta: 0:03:43  Lr: 0.030000  Loss: 0.6601  Acc@1: 43.7500 (36.0071)  Acc@5: 87.5000 (78.8142)  time: 0.3463  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3940/4579]  eta: 0:03:40  Lr: 0.030000  Loss: 0.3546  Acc@1: 43.7500 (36.0346)  Acc@5: 87.5000 (78.8410)  time: 0.3465  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3950/4579]  eta: 0:03:36  Lr: 0.030000  Loss: 0.2737  Acc@1: 43.7500 (36.0478)  Acc@5: 87.5000 (78.8519)  time: 0.3455  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3960/4579]  eta: 0:03:33  Lr: 0.030000  Loss: 0.1848  Acc@1: 50.0000 (36.0815)  Acc@5: 87.5000 (78.8800)  time: 0.3458  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [3970/4579]  eta: 0:03:29  Lr: 0.030000  Loss: 0.4775  Acc@1: 50.0000 (36.1102)  Acc@5: 87.5000 (78.9017)  time: 0.3457  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3980/4579]  eta: 0:03:26  Lr: 0.030000  Loss: 0.5523  Acc@1: 43.7500 (36.1357)  Acc@5: 87.5000 (78.9296)  time: 0.3457  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3990/4579]  eta: 0:03:23  Lr: 0.030000  Loss: 0.6387  Acc@1: 43.7500 (36.1595)  Acc@5: 81.2500 (78.9292)  time: 0.3467  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [4000/4579]  eta: 0:03:19  Lr: 0.030000  Loss: 0.2587  Acc@1: 43.7500 (36.1941)  Acc@5: 81.2500 (78.9490)  time: 0.3462  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [4010/4579]  eta: 0:03:16  Lr: 0.030000  Loss: 0.5744  Acc@1: 43.7500 (36.2160)  Acc@5: 87.5000 (78.9641)  time: 0.3452  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [4020/4579]  eta: 0:03:12  Lr: 0.030000  Loss: 0.0825  Acc@1: 50.0000 (36.2550)  Acc@5: 81.2500 (78.9776)  time: 0.3451  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [4030/4579]  eta: 0:03:09  Lr: 0.030000  Loss: 0.2303  Acc@1: 50.0000 (36.2751)  Acc@5: 87.5000 (78.9971)  time: 0.3459  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [4040/4579]  eta: 0:03:05  Lr: 0.030000  Loss: 0.5924  Acc@1: 43.7500 (36.3044)  Acc@5: 93.7500 (79.0306)  time: 0.3462  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [4050/4579]  eta: 0:03:02  Lr: 0.030000  Loss: 0.6400  Acc@1: 43.7500 (36.3336)  Acc@5: 93.7500 (79.0499)  time: 0.3452  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [4060/4579]  eta: 0:02:58  Lr: 0.030000  Loss: 0.6467  Acc@1: 50.0000 (36.3550)  Acc@5: 87.5000 (79.0707)  time: 0.3445  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [4070/4579]  eta: 0:02:55  Lr: 0.030000  Loss: 0.1199  Acc@1: 50.0000 (36.3823)  Acc@5: 87.5000 (79.0945)  time: 0.3447  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [4080/4579]  eta: 0:02:52  Lr: 0.030000  Loss: 0.5955  Acc@1: 50.0000 (36.4096)  Acc@5: 87.5000 (79.1166)  time: 0.3450  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [4090/4579]  eta: 0:02:48  Lr: 0.030000  Loss: 0.3477  Acc@1: 50.0000 (36.4367)  Acc@5: 87.5000 (79.1325)  time: 0.3447  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [4100/4579]  eta: 0:02:45  Lr: 0.030000  Loss: 0.2614  Acc@1: 43.7500 (36.4484)  Acc@5: 87.5000 (79.1575)  time: 0.3445  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [4110/4579]  eta: 0:02:41  Lr: 0.030000  Loss: 0.5688  Acc@1: 43.7500 (36.4738)  Acc@5: 87.5000 (79.1717)  time: 0.3445  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [4120/4579]  eta: 0:02:38  Lr: 0.030000  Loss: 0.5801  Acc@1: 43.7500 (36.4930)  Acc@5: 81.2500 (79.1798)  time: 0.3438  data: 0.0002  max mem: 2500
Train: Epoch[1/5]  [4130/4579]  eta: 0:02:34  Lr: 0.030000  Loss: 0.3556  Acc@1: 43.7500 (36.5181)  Acc@5: 87.5000 (79.2015)  time: 0.3429  data: 0.0002  max mem: 2500
Train: Epoch[1/5]  [4140/4579]  eta: 0:02:31  Lr: 0.030000  Loss: 0.2677  Acc@1: 43.7500 (36.5431)  Acc@5: 87.5000 (79.2275)  time: 0.3431  data: 0.0002  max mem: 2500
Train: Epoch[1/5]  [4150/4579]  eta: 0:02:27  Lr: 0.030000  Loss: 0.6490  Acc@1: 50.0000 (36.5725)  Acc@5: 87.5000 (79.2565)  time: 0.3439  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [4160/4579]  eta: 0:02:24  Lr: 0.030000  Loss: 0.4826  Acc@1: 50.0000 (36.6048)  Acc@5: 87.5000 (79.2673)  time: 0.3445  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [4170/4579]  eta: 0:02:20  Lr: 0.030000  Loss: 0.5523  Acc@1: 43.7500 (36.6174)  Acc@5: 81.2500 (79.2810)  time: 0.3450  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [4180/4579]  eta: 0:02:17  Lr: 0.030000  Loss: 0.4887  Acc@1: 43.7500 (36.6509)  Acc@5: 81.2500 (79.2932)  time: 0.3462  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [4190/4579]  eta: 0:02:14  Lr: 0.030000  Loss: 0.5562  Acc@1: 50.0000 (36.6828)  Acc@5: 81.2500 (79.3158)  time: 0.3456  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [4200/4579]  eta: 0:02:10  Lr: 0.030000  Loss: 0.6612  Acc@1: 50.0000 (36.6922)  Acc@5: 87.5000 (79.3234)  time: 0.3447  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [4210/4579]  eta: 0:02:07  Lr: 0.030000  Loss: 0.9653  Acc@1: 43.7500 (36.7089)  Acc@5: 87.5000 (79.3369)  time: 0.3444  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [4220/4579]  eta: 0:02:03  Lr: 0.030000  Loss: 0.3668  Acc@1: 43.7500 (36.7330)  Acc@5: 87.5000 (79.3680)  time: 0.3438  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [4230/4579]  eta: 0:02:00  Lr: 0.030000  Loss: 0.5043  Acc@1: 43.7500 (36.7570)  Acc@5: 87.5000 (79.3695)  time: 0.3446  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [4240/4579]  eta: 0:01:56  Lr: 0.030000  Loss: 0.7544  Acc@1: 43.7500 (36.7853)  Acc@5: 87.5000 (79.3843)  time: 0.3446  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [4250/4579]  eta: 0:01:53  Lr: 0.030000  Loss: 0.3220  Acc@1: 43.7500 (36.8016)  Acc@5: 87.5000 (79.3960)  time: 0.3444  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [4260/4579]  eta: 0:01:49  Lr: 0.030000  Loss: 0.2956  Acc@1: 43.7500 (36.8297)  Acc@5: 81.2500 (79.4106)  time: 0.3453  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [4270/4579]  eta: 0:01:46  Lr: 0.030000  Loss: 0.2483  Acc@1: 50.0000 (36.8620)  Acc@5: 87.5000 (79.4384)  time: 0.3440  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [4280/4579]  eta: 0:01:43  Lr: 0.030000  Loss: 0.3797  Acc@1: 50.0000 (36.8795)  Acc@5: 93.7500 (79.4630)  time: 0.3420  data: 0.0002  max mem: 2500
Train: Epoch[1/5]  [4290/4579]  eta: 0:01:39  Lr: 0.030000  Loss: 0.5076  Acc@1: 50.0000 (36.9057)  Acc@5: 87.5000 (79.4818)  time: 0.3422  data: 0.0002  max mem: 2500
Train: Epoch[1/5]  [4300/4579]  eta: 0:01:36  Lr: 0.030000  Loss: 0.1277  Acc@1: 43.7500 (36.9246)  Acc@5: 87.5000 (79.5004)  time: 0.3422  data: 0.0002  max mem: 2500
Train: Epoch[1/5]  [4310/4579]  eta: 0:01:32  Lr: 0.030000  Loss: 0.6287  Acc@1: 43.7500 (36.9375)  Acc@5: 87.5000 (79.5190)  time: 0.3422  data: 0.0002  max mem: 2500
Train: Epoch[1/5]  [4320/4579]  eta: 0:01:29  Lr: 0.030000  Loss: 0.6313  Acc@1: 43.7500 (36.9663)  Acc@5: 87.5000 (79.5374)  time: 0.3424  data: 0.0002  max mem: 2500
Train: Epoch[1/5]  [4330/4579]  eta: 0:01:25  Lr: 0.030000  Loss: 0.4437  Acc@1: 50.0000 (36.9964)  Acc@5: 93.7500 (79.5659)  time: 0.3423  data: 0.0002  max mem: 2500
Train: Epoch[1/5]  [4340/4579]  eta: 0:01:22  Lr: 0.030000  Loss: 0.1200  Acc@1: 50.0000 (37.0292)  Acc@5: 93.7500 (79.5856)  time: 0.3423  data: 0.0002  max mem: 2500
Train: Epoch[1/5]  [4350/4579]  eta: 0:01:18  Lr: 0.030000  Loss: 0.5242  Acc@1: 50.0000 (37.0518)  Acc@5: 87.5000 (79.6081)  time: 0.3422  data: 0.0002  max mem: 2500
Train: Epoch[1/5]  [4360/4579]  eta: 0:01:15  Lr: 0.030000  Loss: 0.2504  Acc@1: 50.0000 (37.0873)  Acc@5: 87.5000 (79.6334)  time: 0.3442  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [4370/4579]  eta: 0:01:12  Lr: 0.030000  Loss: 0.3579  Acc@1: 50.0000 (37.0968)  Acc@5: 87.5000 (79.6500)  time: 0.3469  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [4380/4579]  eta: 0:01:08  Lr: 0.030000  Loss: 0.2378  Acc@1: 50.0000 (37.1148)  Acc@5: 87.5000 (79.6650)  time: 0.3469  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [4390/4579]  eta: 0:01:05  Lr: 0.030000  Loss: 0.3751  Acc@1: 50.0000 (37.1527)  Acc@5: 87.5000 (79.6886)  time: 0.3454  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [4400/4579]  eta: 0:01:01  Lr: 0.030000  Loss: 0.4921  Acc@1: 56.2500 (37.1876)  Acc@5: 87.5000 (79.6921)  time: 0.3451  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [4410/4579]  eta: 0:00:58  Lr: 0.030000  Loss: 0.3594  Acc@1: 43.7500 (37.2265)  Acc@5: 81.2500 (79.7041)  time: 0.3457  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [4420/4579]  eta: 0:00:54  Lr: 0.030000  Loss: 0.6617  Acc@1: 50.0000 (37.2568)  Acc@5: 87.5000 (79.7218)  time: 0.3455  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [4430/4579]  eta: 0:00:51  Lr: 0.030000  Loss: 0.5567  Acc@1: 50.0000 (37.2715)  Acc@5: 87.5000 (79.7365)  time: 0.3455  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [4440/4579]  eta: 0:00:47  Lr: 0.030000  Loss: 0.4534  Acc@1: 43.7500 (37.2973)  Acc@5: 87.5000 (79.7540)  time: 0.3453  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [4450/4579]  eta: 0:00:44  Lr: 0.030000  Loss: 0.6036  Acc@1: 50.0000 (37.3371)  Acc@5: 87.5000 (79.7756)  time: 0.3453  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [4460/4579]  eta: 0:00:41  Lr: 0.030000  Loss: 0.6033  Acc@1: 50.0000 (37.3529)  Acc@5: 87.5000 (79.7817)  time: 0.3453  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [4470/4579]  eta: 0:00:37  Lr: 0.030000  Loss: 0.0752  Acc@1: 43.7500 (37.3742)  Acc@5: 81.2500 (79.8004)  time: 0.3450  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [4480/4579]  eta: 0:00:34  Lr: 0.030000  Loss: 0.3252  Acc@1: 43.7500 (37.3954)  Acc@5: 87.5000 (79.8190)  time: 0.3456  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [4490/4579]  eta: 0:00:30  Lr: 0.030000  Loss: 0.3317  Acc@1: 43.7500 (37.4095)  Acc@5: 87.5000 (79.8402)  time: 0.3454  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [4500/4579]  eta: 0:00:27  Lr: 0.030000  Loss: 0.5667  Acc@1: 50.0000 (37.4361)  Acc@5: 87.5000 (79.8586)  time: 0.3457  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [4510/4579]  eta: 0:00:23  Lr: 0.030000  Loss: 0.4734  Acc@1: 43.7500 (37.4557)  Acc@5: 87.5000 (79.8673)  time: 0.3462  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [4520/4579]  eta: 0:00:20  Lr: 0.030000  Loss: 0.5128  Acc@1: 43.7500 (37.4862)  Acc@5: 87.5000 (79.8911)  time: 0.3469  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [4530/4579]  eta: 0:00:16  Lr: 0.030000  Loss: 0.5706  Acc@1: 43.7500 (37.5041)  Acc@5: 87.5000 (79.9051)  time: 0.3463  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [4540/4579]  eta: 0:00:13  Lr: 0.030000  Loss: 0.3530  Acc@1: 43.7500 (37.5275)  Acc@5: 87.5000 (79.9273)  time: 0.3449  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [4550/4579]  eta: 0:00:09  Lr: 0.030000  Loss: 0.4059  Acc@1: 43.7500 (37.5508)  Acc@5: 87.5000 (79.9440)  time: 0.3448  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [4560/4579]  eta: 0:00:06  Lr: 0.030000  Loss: 0.3147  Acc@1: 50.0000 (37.5781)  Acc@5: 87.5000 (79.9551)  time: 0.3455  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [4570/4579]  eta: 0:00:03  Lr: 0.030000  Loss: 0.3690  Acc@1: 43.7500 (37.5875)  Acc@5: 87.5000 (79.9784)  time: 0.3456  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [4578/4579]  eta: 0:00:00  Lr: 0.030000  Loss: 0.9821  Acc@1: 37.5000 (37.5855)  Acc@5: 87.5000 (79.9896)  time: 0.3423  data: 0.0007  max mem: 2500
Train: Epoch[1/5] Total time: 0:26:18 (0.3448 s / it)
{0: {0: 73257, 1: 0, 2: 0, 3: 0, 4: 0}, 1: {0: 73257, 1: 0, 2: 0, 3: 0, 4: 0}, 2: {0: 73257, 1: 0, 2: 0, 3: 0, 4: 0}, 3: {0: 73257, 1: 0, 2: 0, 3: 0, 4: 0}, 4: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 5: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 6: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 7: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 8: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 9: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 10: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 11: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 12: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 13: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 14: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 15: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 16: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 17: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 18: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 19: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}}
Averaged stats: Lr: 0.030000  Loss: 0.9821  Acc@1: 37.5000 (37.5855)  Acc@5: 87.5000 (79.9896)
Train: Epoch[2/5]  [   0/4579]  eta: 0:47:19  Lr: 0.030000  Loss: 0.4307  Acc@1: 62.5000 (62.5000)  Acc@5: 87.5000 (87.5000)  time: 0.6200  data: 0.2686  max mem: 2500
Train: Epoch[2/5]  [  10/4579]  eta: 0:28:08  Lr: 0.030000  Loss: 0.1869  Acc@1: 50.0000 (50.0000)  Acc@5: 87.5000 (85.7955)  time: 0.3696  data: 0.0246  max mem: 2500
Train: Epoch[2/5]  [  20/4579]  eta: 0:27:07  Lr: 0.030000  Loss: 0.3066  Acc@1: 50.0000 (51.1905)  Acc@5: 87.5000 (87.5000)  time: 0.3439  data: 0.0002  max mem: 2500
Train: Epoch[2/5]  [  30/4579]  eta: 0:26:42  Lr: 0.030000  Loss: 0.7173  Acc@1: 50.0000 (50.2016)  Acc@5: 93.7500 (88.9113)  time: 0.3429  data: 0.0002  max mem: 2500
Train: Epoch[2/5]  [  40/4579]  eta: 0:26:29  Lr: 0.030000  Loss: 0.7620  Acc@1: 50.0000 (49.5427)  Acc@5: 87.5000 (87.6524)  time: 0.3429  data: 0.0002  max mem: 2500
Train: Epoch[2/5]  [  50/4579]  eta: 0:26:19  Lr: 0.030000  Loss: 0.4314  Acc@1: 50.0000 (49.5098)  Acc@5: 87.5000 (87.5000)  time: 0.3431  data: 0.0002  max mem: 2500
Train: Epoch[2/5]  [  60/4579]  eta: 0:26:13  Lr: 0.030000  Loss: 0.1793  Acc@1: 50.0000 (49.1803)  Acc@5: 87.5000 (87.6025)  time: 0.3444  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [  70/4579]  eta: 0:26:08  Lr: 0.030000  Loss: 0.3240  Acc@1: 50.0000 (49.6479)  Acc@5: 87.5000 (87.1479)  time: 0.3453  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [  80/4579]  eta: 0:26:03  Lr: 0.030000  Loss: 0.9660  Acc@1: 50.0000 (49.4599)  Acc@5: 87.5000 (86.9599)  time: 0.3451  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [  90/4579]  eta: 0:25:59  Lr: 0.030000  Loss: 0.4810  Acc@1: 50.0000 (49.1758)  Acc@5: 87.5000 (86.9505)  time: 0.3460  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 100/4579]  eta: 0:25:55  Lr: 0.030000  Loss: 0.4576  Acc@1: 50.0000 (49.6287)  Acc@5: 87.5000 (87.1906)  time: 0.3460  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 110/4579]  eta: 0:25:51  Lr: 0.030000  Loss: 0.5351  Acc@1: 50.0000 (49.2680)  Acc@5: 87.5000 (86.8806)  time: 0.3460  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [ 120/4579]  eta: 0:25:47  Lr: 0.030000  Loss: 0.5172  Acc@1: 50.0000 (49.0186)  Acc@5: 87.5000 (86.7769)  time: 0.3459  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 130/4579]  eta: 0:25:43  Lr: 0.030000  Loss: 0.3483  Acc@1: 43.7500 (48.9504)  Acc@5: 87.5000 (86.5458)  time: 0.3453  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [ 140/4579]  eta: 0:25:38  Lr: 0.030000  Loss: 0.3479  Acc@1: 43.7500 (48.5372)  Acc@5: 81.2500 (86.3918)  time: 0.3449  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [ 150/4579]  eta: 0:25:34  Lr: 0.030000  Loss: 0.2138  Acc@1: 43.7500 (48.3858)  Acc@5: 87.5000 (86.7550)  time: 0.3448  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [ 160/4579]  eta: 0:25:30  Lr: 0.030000  Loss: 0.6992  Acc@1: 43.7500 (47.9814)  Acc@5: 93.7500 (86.9953)  time: 0.3448  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 170/4579]  eta: 0:25:27  Lr: 0.030000  Loss: 0.3481  Acc@1: 43.7500 (48.2091)  Acc@5: 87.5000 (86.9152)  time: 0.3455  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [ 180/4579]  eta: 0:25:23  Lr: 0.030000  Loss: 0.5909  Acc@1: 56.2500 (48.6878)  Acc@5: 87.5000 (87.0511)  time: 0.3450  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [ 190/4579]  eta: 0:25:18  Lr: 0.030000  Loss: 0.4757  Acc@1: 43.7500 (48.5602)  Acc@5: 87.5000 (87.1728)  time: 0.3429  data: 0.0002  max mem: 2500
Train: Epoch[2/5]  [ 200/4579]  eta: 0:25:14  Lr: 0.030000  Loss: 0.4693  Acc@1: 43.7500 (48.3831)  Acc@5: 87.5000 (87.2823)  time: 0.3422  data: 0.0002  max mem: 2500
Train: Epoch[2/5]  [ 210/4579]  eta: 0:25:10  Lr: 0.030000  Loss: 0.4499  Acc@1: 50.0000 (48.4893)  Acc@5: 87.5000 (87.4111)  time: 0.3424  data: 0.0002  max mem: 2500
Train: Epoch[2/5]  [ 220/4579]  eta: 0:25:06  Lr: 0.030000  Loss: 0.4198  Acc@1: 50.0000 (48.6425)  Acc@5: 87.5000 (87.3869)  time: 0.3428  data: 0.0002  max mem: 2500
Train: Epoch[2/5]  [ 230/4579]  eta: 0:25:02  Lr: 0.030000  Loss: 0.4025  Acc@1: 50.0000 (48.4037)  Acc@5: 87.5000 (87.4459)  time: 0.3426  data: 0.0002  max mem: 2500
Train: Epoch[2/5]  [ 240/4579]  eta: 0:24:58  Lr: 0.030000  Loss: 0.2464  Acc@1: 50.0000 (48.9108)  Acc@5: 87.5000 (87.5259)  time: 0.3424  data: 0.0002  max mem: 2500
Train: Epoch[2/5]  [ 250/4579]  eta: 0:24:54  Lr: 0.030000  Loss: 0.5113  Acc@1: 50.0000 (48.8048)  Acc@5: 87.5000 (87.6245)  time: 0.3423  data: 0.0002  max mem: 2500
Train: Epoch[2/5]  [ 260/4579]  eta: 0:24:50  Lr: 0.030000  Loss: 0.4156  Acc@1: 50.0000 (48.9943)  Acc@5: 87.5000 (87.7155)  time: 0.3423  data: 0.0002  max mem: 2500
Train: Epoch[2/5]  [ 270/4579]  eta: 0:24:47  Lr: 0.030000  Loss: 0.0953  Acc@1: 56.2500 (49.0544)  Acc@5: 87.5000 (87.6384)  time: 0.3454  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 280/4579]  eta: 0:24:44  Lr: 0.030000  Loss: 0.4547  Acc@1: 50.0000 (49.2660)  Acc@5: 87.5000 (87.7002)  time: 0.3471  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [ 290/4579]  eta: 0:24:41  Lr: 0.030000  Loss: 0.3499  Acc@1: 50.0000 (49.2053)  Acc@5: 87.5000 (87.5859)  time: 0.3472  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [ 300/4579]  eta: 0:24:37  Lr: 0.030000  Loss: 0.0817  Acc@1: 43.7500 (49.2733)  Acc@5: 87.5000 (87.7076)  time: 0.3465  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 310/4579]  eta: 0:24:34  Lr: 0.030000  Loss: 0.3849  Acc@1: 56.2500 (49.5378)  Acc@5: 87.5000 (87.7613)  time: 0.3442  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 320/4579]  eta: 0:24:30  Lr: 0.030000  Loss: 0.4382  Acc@1: 50.0000 (49.5522)  Acc@5: 87.5000 (87.7142)  time: 0.3441  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 330/4579]  eta: 0:24:27  Lr: 0.030000  Loss: 0.3815  Acc@1: 50.0000 (49.5279)  Acc@5: 87.5000 (87.5755)  time: 0.3452  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 340/4579]  eta: 0:24:23  Lr: 0.030000  Loss: 0.5258  Acc@1: 43.7500 (49.4135)  Acc@5: 87.5000 (87.5000)  time: 0.3453  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 350/4579]  eta: 0:24:20  Lr: 0.030000  Loss: 0.5162  Acc@1: 43.7500 (49.3946)  Acc@5: 87.5000 (87.5712)  time: 0.3448  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 360/4579]  eta: 0:24:16  Lr: 0.030000  Loss: 0.8189  Acc@1: 50.0000 (49.4287)  Acc@5: 93.7500 (87.6212)  time: 0.3457  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 370/4579]  eta: 0:24:13  Lr: 0.030000  Loss: 0.5163  Acc@1: 50.0000 (49.6631)  Acc@5: 93.7500 (87.6516)  time: 0.3453  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 380/4579]  eta: 0:24:09  Lr: 0.030000  Loss: 0.6023  Acc@1: 50.0000 (49.7211)  Acc@5: 93.7500 (87.6640)  time: 0.3444  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 390/4579]  eta: 0:24:06  Lr: 0.030000  Loss: 0.4718  Acc@1: 50.0000 (49.5844)  Acc@5: 87.5000 (87.5639)  time: 0.3449  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 400/4579]  eta: 0:24:02  Lr: 0.030000  Loss: 0.0129  Acc@1: 50.0000 (49.6727)  Acc@5: 87.5000 (87.6870)  time: 0.3454  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 410/4579]  eta: 0:23:59  Lr: 0.030000  Loss: 0.5051  Acc@1: 50.0000 (49.7415)  Acc@5: 93.7500 (87.7433)  time: 0.3450  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 420/4579]  eta: 0:23:56  Lr: 0.030000  Loss: 0.1554  Acc@1: 43.7500 (49.6586)  Acc@5: 87.5000 (87.6188)  time: 0.3468  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 430/4579]  eta: 0:23:52  Lr: 0.030000  Loss: 0.4880  Acc@1: 43.7500 (49.6955)  Acc@5: 87.5000 (87.6450)  time: 0.3468  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [ 440/4579]  eta: 0:23:49  Lr: 0.030000  Loss: 0.4029  Acc@1: 50.0000 (49.7307)  Acc@5: 87.5000 (87.6276)  time: 0.3444  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [ 450/4579]  eta: 0:23:45  Lr: 0.030000  Loss: 0.5305  Acc@1: 50.0000 (49.7090)  Acc@5: 87.5000 (87.5970)  time: 0.3446  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [ 460/4579]  eta: 0:23:42  Lr: 0.030000  Loss: 0.3962  Acc@1: 50.0000 (49.7153)  Acc@5: 87.5000 (87.5678)  time: 0.3448  data: 0.0002  max mem: 2500
Train: Epoch[2/5]  [ 470/4579]  eta: 0:23:38  Lr: 0.030000  Loss: 0.5332  Acc@1: 50.0000 (49.7611)  Acc@5: 87.5000 (87.4867)  time: 0.3444  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [ 480/4579]  eta: 0:23:35  Lr: 0.030000  Loss: 0.1881  Acc@1: 50.0000 (49.8571)  Acc@5: 87.5000 (87.6040)  time: 0.3441  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [ 490/4579]  eta: 0:23:31  Lr: 0.030000  Loss: 0.2024  Acc@1: 50.0000 (49.7963)  Acc@5: 93.7500 (87.6655)  time: 0.3443  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [ 500/4579]  eta: 0:23:28  Lr: 0.030000  Loss: 0.3186  Acc@1: 50.0000 (49.7879)  Acc@5: 87.5000 (87.5998)  time: 0.3455  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 510/4579]  eta: 0:23:24  Lr: 0.030000  Loss: 0.3767  Acc@1: 43.7500 (49.7065)  Acc@5: 87.5000 (87.5367)  time: 0.3445  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [ 520/4579]  eta: 0:23:20  Lr: 0.030000  Loss: 0.6602  Acc@1: 43.7500 (49.8081)  Acc@5: 87.5000 (87.5360)  time: 0.3424  data: 0.0002  max mem: 2500
Train: Epoch[2/5]  [ 530/4579]  eta: 0:23:17  Lr: 0.030000  Loss: 0.6949  Acc@1: 50.0000 (49.7293)  Acc@5: 87.5000 (87.4765)  time: 0.3425  data: 0.0002  max mem: 2500
Train: Epoch[2/5]  [ 540/4579]  eta: 0:23:13  Lr: 0.030000  Loss: 0.3611  Acc@1: 50.0000 (49.7112)  Acc@5: 87.5000 (87.4653)  time: 0.3425  data: 0.0002  max mem: 2500
Train: Epoch[2/5]  [ 550/4579]  eta: 0:23:09  Lr: 0.030000  Loss: 0.3516  Acc@1: 43.7500 (49.6711)  Acc@5: 87.5000 (87.5227)  time: 0.3424  data: 0.0002  max mem: 2500
Train: Epoch[2/5]  [ 560/4579]  eta: 0:23:06  Lr: 0.030000  Loss: 0.2408  Acc@1: 43.7500 (49.6324)  Acc@5: 87.5000 (87.4443)  time: 0.3423  data: 0.0002  max mem: 2500
Train: Epoch[2/5]  [ 570/4579]  eta: 0:23:02  Lr: 0.030000  Loss: 0.4756  Acc@1: 50.0000 (49.7264)  Acc@5: 81.2500 (87.4562)  time: 0.3424  data: 0.0002  max mem: 2500
Train: Epoch[2/5]  [ 580/4579]  eta: 0:22:59  Lr: 0.030000  Loss: 0.4660  Acc@1: 50.0000 (49.6665)  Acc@5: 87.5000 (87.4785)  time: 0.3426  data: 0.0002  max mem: 2500
Train: Epoch[2/5]  [ 590/4579]  eta: 0:22:55  Lr: 0.030000  Loss: 0.4210  Acc@1: 50.0000 (49.7039)  Acc@5: 87.5000 (87.4894)  time: 0.3429  data: 0.0002  max mem: 2500
Train: Epoch[2/5]  [ 600/4579]  eta: 0:22:51  Lr: 0.030000  Loss: 0.6002  Acc@1: 50.0000 (49.6880)  Acc@5: 87.5000 (87.4792)  time: 0.3438  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [ 610/4579]  eta: 0:22:48  Lr: 0.030000  Loss: -0.2334  Acc@1: 50.0000 (49.7545)  Acc@5: 87.5000 (87.5307)  time: 0.3450  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 620/4579]  eta: 0:22:45  Lr: 0.030000  Loss: 0.5464  Acc@1: 50.0000 (49.9195)  Acc@5: 93.7500 (87.6006)  time: 0.3452  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [ 630/4579]  eta: 0:22:41  Lr: 0.030000  Loss: 0.2893  Acc@1: 56.2500 (49.9010)  Acc@5: 87.5000 (87.6288)  time: 0.3451  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 640/4579]  eta: 0:22:38  Lr: 0.030000  Loss: 0.3007  Acc@1: 43.7500 (49.9025)  Acc@5: 87.5000 (87.6463)  time: 0.3449  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 650/4579]  eta: 0:22:34  Lr: 0.030000  Loss: 0.4222  Acc@1: 50.0000 (49.8944)  Acc@5: 93.7500 (87.6536)  time: 0.3441  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 660/4579]  eta: 0:22:31  Lr: 0.030000  Loss: 0.5227  Acc@1: 50.0000 (49.7920)  Acc@5: 87.5000 (87.5567)  time: 0.3447  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 670/4579]  eta: 0:22:27  Lr: 0.030000  Loss: 0.6153  Acc@1: 50.0000 (49.9162)  Acc@5: 87.5000 (87.5373)  time: 0.3455  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 680/4579]  eta: 0:22:24  Lr: 0.030000  Loss: 0.4392  Acc@1: 50.0000 (49.9633)  Acc@5: 87.5000 (87.5734)  time: 0.3452  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 690/4579]  eta: 0:22:21  Lr: 0.030000  Loss: 0.0112  Acc@1: 50.0000 (50.0543)  Acc@5: 93.7500 (87.6899)  time: 0.3483  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [ 700/4579]  eta: 0:22:17  Lr: 0.030000  Loss: 0.4476  Acc@1: 56.2500 (50.1070)  Acc@5: 93.7500 (87.6961)  time: 0.3480  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [ 710/4579]  eta: 0:22:14  Lr: 0.030000  Loss: 0.5672  Acc@1: 56.2500 (50.1582)  Acc@5: 87.5000 (87.6846)  time: 0.3456  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [ 720/4579]  eta: 0:22:11  Lr: 0.030000  Loss: 0.3533  Acc@1: 50.0000 (50.1820)  Acc@5: 87.5000 (87.6994)  time: 0.3459  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [ 730/4579]  eta: 0:22:07  Lr: 0.030000  Loss: 0.4297  Acc@1: 50.0000 (50.1966)  Acc@5: 87.5000 (87.6966)  time: 0.3453  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 740/4579]  eta: 0:22:04  Lr: 0.030000  Loss: 0.0101  Acc@1: 50.0000 (50.1603)  Acc@5: 87.5000 (87.6940)  time: 0.3466  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [ 750/4579]  eta: 0:22:00  Lr: 0.030000  Loss: 0.5142  Acc@1: 50.0000 (50.1831)  Acc@5: 87.5000 (87.6997)  time: 0.3461  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [ 760/4579]  eta: 0:21:57  Lr: 0.030000  Loss: 0.1605  Acc@1: 50.0000 (50.1807)  Acc@5: 87.5000 (87.6971)  time: 0.3480  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [ 770/4579]  eta: 0:21:54  Lr: 0.030000  Loss: 0.7925  Acc@1: 50.0000 (50.0973)  Acc@5: 87.5000 (87.7027)  time: 0.3479  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [ 780/4579]  eta: 0:21:50  Lr: 0.030000  Loss: 0.3463  Acc@1: 43.7500 (50.1280)  Acc@5: 87.5000 (87.6841)  time: 0.3442  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [ 790/4579]  eta: 0:21:47  Lr: 0.030000  Loss: 0.2898  Acc@1: 50.0000 (50.1264)  Acc@5: 87.5000 (87.6501)  time: 0.3449  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [ 800/4579]  eta: 0:21:43  Lr: 0.030000  Loss: 0.1589  Acc@1: 50.0000 (50.1561)  Acc@5: 87.5000 (87.6795)  time: 0.3449  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [ 810/4579]  eta: 0:21:40  Lr: 0.030000  Loss: 0.5860  Acc@1: 50.0000 (50.0925)  Acc@5: 87.5000 (87.6310)  time: 0.3445  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [ 820/4579]  eta: 0:21:36  Lr: 0.030000  Loss: 0.3184  Acc@1: 50.0000 (50.1218)  Acc@5: 87.5000 (87.6675)  time: 0.3444  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [ 830/4579]  eta: 0:21:33  Lr: 0.030000  Loss: 0.6038  Acc@1: 43.7500 (50.0903)  Acc@5: 81.2500 (87.5903)  time: 0.3450  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [ 840/4579]  eta: 0:21:30  Lr: 0.030000  Loss: 0.5443  Acc@1: 43.7500 (50.0297)  Acc@5: 81.2500 (87.5966)  time: 0.3443  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [ 850/4579]  eta: 0:21:26  Lr: 0.030000  Loss: 0.5006  Acc@1: 43.7500 (50.0441)  Acc@5: 87.5000 (87.5808)  time: 0.3427  data: 0.0002  max mem: 2500
Train: Epoch[2/5]  [ 860/4579]  eta: 0:21:22  Lr: 0.030000  Loss: 0.4158  Acc@1: 50.0000 (50.0653)  Acc@5: 87.5000 (87.6161)  time: 0.3425  data: 0.0002  max mem: 2500
Train: Epoch[2/5]  [ 870/4579]  eta: 0:21:19  Lr: 0.030000  Loss: 0.5465  Acc@1: 50.0000 (50.0431)  Acc@5: 87.5000 (87.5861)  time: 0.3425  data: 0.0002  max mem: 2500
Train: Epoch[2/5]  [ 880/4579]  eta: 0:21:15  Lr: 0.030000  Loss: 0.5758  Acc@1: 50.0000 (50.0922)  Acc@5: 87.5000 (87.6135)  time: 0.3430  data: 0.0002  max mem: 2500
Train: Epoch[2/5]  [ 890/4579]  eta: 0:21:12  Lr: 0.030000  Loss: 0.4604  Acc@1: 56.2500 (50.1263)  Acc@5: 93.7500 (87.6333)  time: 0.3427  data: 0.0002  max mem: 2500
Train: Epoch[2/5]  [ 900/4579]  eta: 0:21:08  Lr: 0.030000  Loss: 0.2810  Acc@1: 50.0000 (50.1249)  Acc@5: 87.5000 (87.6665)  time: 0.3422  data: 0.0002  max mem: 2500
Train: Epoch[2/5]  [ 910/4579]  eta: 0:21:05  Lr: 0.030000  Loss: 0.2661  Acc@1: 50.0000 (50.1715)  Acc@5: 93.7500 (87.7264)  time: 0.3432  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [ 920/4579]  eta: 0:21:01  Lr: 0.030000  Loss: 0.5997  Acc@1: 50.0000 (50.1697)  Acc@5: 93.7500 (87.7782)  time: 0.3440  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [ 930/4579]  eta: 0:20:58  Lr: 0.030000  Loss: 0.4626  Acc@1: 50.0000 (50.1880)  Acc@5: 93.7500 (87.8021)  time: 0.3442  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 940/4579]  eta: 0:20:54  Lr: 0.030000  Loss: 0.3243  Acc@1: 50.0000 (50.2524)  Acc@5: 93.7500 (87.8188)  time: 0.3454  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 950/4579]  eta: 0:20:51  Lr: 0.030000  Loss: 0.0456  Acc@1: 56.2500 (50.3089)  Acc@5: 93.7500 (87.8483)  time: 0.3460  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 960/4579]  eta: 0:20:48  Lr: 0.030000  Loss: 0.3734  Acc@1: 56.2500 (50.3057)  Acc@5: 87.5000 (87.8187)  time: 0.3466  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [ 970/4579]  eta: 0:20:44  Lr: 0.030000  Loss: 0.2417  Acc@1: 50.0000 (50.2703)  Acc@5: 81.2500 (87.7639)  time: 0.3463  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [ 980/4579]  eta: 0:20:41  Lr: 0.030000  Loss: 0.5354  Acc@1: 50.0000 (50.2803)  Acc@5: 87.5000 (87.8122)  time: 0.3455  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 990/4579]  eta: 0:20:37  Lr: 0.030000  Loss: 0.8104  Acc@1: 50.0000 (50.2712)  Acc@5: 93.7500 (87.8153)  time: 0.3445  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1000/4579]  eta: 0:20:34  Lr: 0.030000  Loss: 0.5726  Acc@1: 50.0000 (50.2060)  Acc@5: 87.5000 (87.7872)  time: 0.3438  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1010/4579]  eta: 0:20:30  Lr: 0.030000  Loss: 0.2096  Acc@1: 50.0000 (50.2287)  Acc@5: 87.5000 (87.7906)  time: 0.3445  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1020/4579]  eta: 0:20:27  Lr: 0.030000  Loss: 0.3210  Acc@1: 56.2500 (50.3122)  Acc@5: 87.5000 (87.8306)  time: 0.3447  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1030/4579]  eta: 0:20:23  Lr: 0.030000  Loss: 0.2545  Acc@1: 56.2500 (50.2970)  Acc@5: 93.7500 (87.7970)  time: 0.3450  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1040/4579]  eta: 0:20:20  Lr: 0.030000  Loss: 0.2712  Acc@1: 50.0000 (50.2882)  Acc@5: 87.5000 (87.8002)  time: 0.3445  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [1050/4579]  eta: 0:20:16  Lr: 0.030000  Loss: 0.4952  Acc@1: 50.0000 (50.2914)  Acc@5: 87.5000 (87.7795)  time: 0.3438  data: 0.0002  max mem: 2500
Train: Epoch[2/5]  [1060/4579]  eta: 0:20:13  Lr: 0.030000  Loss: 0.3449  Acc@1: 50.0000 (50.3593)  Acc@5: 87.5000 (87.7710)  time: 0.3440  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [1070/4579]  eta: 0:20:10  Lr: 0.030000  Loss: 0.3923  Acc@1: 50.0000 (50.3326)  Acc@5: 87.5000 (87.7859)  time: 0.3443  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [1080/4579]  eta: 0:20:06  Lr: 0.030000  Loss: 0.4171  Acc@1: 50.0000 (50.3353)  Acc@5: 87.5000 (87.7833)  time: 0.3440  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [1090/4579]  eta: 0:20:03  Lr: 0.030000  Loss: 0.2020  Acc@1: 50.0000 (50.3093)  Acc@5: 87.5000 (87.7922)  time: 0.3438  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [1100/4579]  eta: 0:19:59  Lr: 0.030000  Loss: 0.3388  Acc@1: 50.0000 (50.3349)  Acc@5: 87.5000 (87.8065)  time: 0.3438  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [1110/4579]  eta: 0:19:56  Lr: 0.030000  Loss: -0.0382  Acc@1: 56.2500 (50.4163)  Acc@5: 93.7500 (87.8488)  time: 0.3432  data: 0.0002  max mem: 2500
Train: Epoch[2/5]  [1120/4579]  eta: 0:19:52  Lr: 0.030000  Loss: 0.4171  Acc@1: 50.0000 (50.4070)  Acc@5: 93.7500 (87.8289)  time: 0.3427  data: 0.0002  max mem: 2500
Train: Epoch[2/5]  [1130/4579]  eta: 0:19:49  Lr: 0.030000  Loss: 0.4770  Acc@1: 43.7500 (50.4089)  Acc@5: 87.5000 (87.7984)  time: 0.3428  data: 0.0002  max mem: 2500
Train: Epoch[2/5]  [1140/4579]  eta: 0:19:45  Lr: 0.030000  Loss: 0.3325  Acc@1: 50.0000 (50.4163)  Acc@5: 87.5000 (87.8341)  time: 0.3438  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [1150/4579]  eta: 0:19:42  Lr: 0.030000  Loss: 0.3863  Acc@1: 50.0000 (50.4561)  Acc@5: 93.7500 (87.8530)  time: 0.3456  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1160/4579]  eta: 0:19:38  Lr: 0.030000  Loss: 0.4710  Acc@1: 50.0000 (50.4683)  Acc@5: 87.5000 (87.8607)  time: 0.3454  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1170/4579]  eta: 0:19:35  Lr: 0.030000  Loss: 0.4828  Acc@1: 50.0000 (50.4857)  Acc@5: 87.5000 (87.8523)  time: 0.3452  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1180/4579]  eta: 0:19:31  Lr: 0.030000  Loss: 0.6505  Acc@1: 50.0000 (50.4922)  Acc@5: 81.2500 (87.8334)  time: 0.3459  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1190/4579]  eta: 0:19:28  Lr: 0.030000  Loss: 0.2952  Acc@1: 56.2500 (50.5458)  Acc@5: 87.5000 (87.8463)  time: 0.3459  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1200/4579]  eta: 0:19:25  Lr: 0.030000  Loss: 0.6063  Acc@1: 56.2500 (50.5828)  Acc@5: 87.5000 (87.8591)  time: 0.3453  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [1210/4579]  eta: 0:19:21  Lr: 0.030000  Loss: 0.2271  Acc@1: 50.0000 (50.5213)  Acc@5: 87.5000 (87.8509)  time: 0.3448  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [1220/4579]  eta: 0:19:18  Lr: 0.030000  Loss: 0.3622  Acc@1: 43.7500 (50.5170)  Acc@5: 87.5000 (87.8788)  time: 0.3450  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [1230/4579]  eta: 0:19:14  Lr: 0.030000  Loss: -0.1195  Acc@1: 50.0000 (50.5788)  Acc@5: 87.5000 (87.8808)  time: 0.3449  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [1240/4579]  eta: 0:19:11  Lr: 0.030000  Loss: 0.2275  Acc@1: 56.2500 (50.5892)  Acc@5: 87.5000 (87.8828)  time: 0.3452  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1250/4579]  eta: 0:19:07  Lr: 0.030000  Loss: 0.3944  Acc@1: 50.0000 (50.6045)  Acc@5: 87.5000 (87.9047)  time: 0.3455  data: 0.0010  max mem: 2500
Train: Epoch[2/5]  [1260/4579]  eta: 0:19:04  Lr: 0.030000  Loss: 0.7045  Acc@1: 50.0000 (50.5452)  Acc@5: 93.7500 (87.8816)  time: 0.3446  data: 0.0009  max mem: 2500
Train: Epoch[2/5]  [1270/4579]  eta: 0:19:00  Lr: 0.030000  Loss: 0.4600  Acc@1: 50.0000 (50.5655)  Acc@5: 93.7500 (87.8934)  time: 0.3432  data: 0.0002  max mem: 2500
Train: Epoch[2/5]  [1280/4579]  eta: 0:18:57  Lr: 0.030000  Loss: 0.5409  Acc@1: 50.0000 (50.5806)  Acc@5: 93.7500 (87.9440)  time: 0.3432  data: 0.0002  max mem: 2500
Train: Epoch[2/5]  [1290/4579]  eta: 0:18:53  Lr: 0.030000  Loss: 0.2822  Acc@1: 56.2500 (50.6294)  Acc@5: 93.7500 (87.9502)  time: 0.3434  data: 0.0002  max mem: 2500
Train: Epoch[2/5]  [1300/4579]  eta: 0:18:50  Lr: 0.030000  Loss: 0.3952  Acc@1: 56.2500 (50.6581)  Acc@5: 87.5000 (87.9900)  time: 0.3441  data: 0.0002  max mem: 2500
Train: Epoch[2/5]  [1310/4579]  eta: 0:18:47  Lr: 0.030000  Loss: 0.4478  Acc@1: 50.0000 (50.6531)  Acc@5: 87.5000 (87.9958)  time: 0.3455  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [1320/4579]  eta: 0:18:43  Lr: 0.030000  Loss: 0.2476  Acc@1: 56.2500 (50.7286)  Acc@5: 87.5000 (87.9873)  time: 0.3471  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1330/4579]  eta: 0:18:40  Lr: 0.030000  Loss: 0.7210  Acc@1: 50.0000 (50.6950)  Acc@5: 87.5000 (87.9790)  time: 0.3470  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1340/4579]  eta: 0:18:36  Lr: 0.030000  Loss: 0.4693  Acc@1: 43.7500 (50.6758)  Acc@5: 87.5000 (87.9661)  time: 0.3459  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1350/4579]  eta: 0:18:33  Lr: 0.030000  Loss: 0.3222  Acc@1: 43.7500 (50.6847)  Acc@5: 87.5000 (87.9626)  time: 0.3464  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1360/4579]  eta: 0:18:30  Lr: 0.030000  Loss: 0.2582  Acc@1: 50.0000 (50.7026)  Acc@5: 87.5000 (87.9409)  time: 0.3471  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1370/4579]  eta: 0:18:26  Lr: 0.030000  Loss: 0.5119  Acc@1: 56.2500 (50.7203)  Acc@5: 87.5000 (87.9422)  time: 0.3466  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1380/4579]  eta: 0:18:23  Lr: 0.030000  Loss: 0.5637  Acc@1: 50.0000 (50.7196)  Acc@5: 87.5000 (87.9345)  time: 0.3479  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [1390/4579]  eta: 0:18:19  Lr: 0.030000  Loss: 0.5073  Acc@1: 50.0000 (50.7459)  Acc@5: 93.7500 (87.9538)  time: 0.3479  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [1400/4579]  eta: 0:18:16  Lr: 0.030000  Loss: 0.2809  Acc@1: 50.0000 (50.7316)  Acc@5: 93.7500 (87.9640)  time: 0.3458  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [1410/4579]  eta: 0:18:13  Lr: 0.030000  Loss: 0.6535  Acc@1: 56.2500 (50.7619)  Acc@5: 87.5000 (87.9518)  time: 0.3457  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [1420/4579]  eta: 0:18:09  Lr: 0.030000  Loss: 0.4933  Acc@1: 56.2500 (50.7653)  Acc@5: 87.5000 (87.9794)  time: 0.3453  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [1430/4579]  eta: 0:18:06  Lr: 0.030000  Loss: 0.5614  Acc@1: 50.0000 (50.7206)  Acc@5: 93.7500 (87.9804)  time: 0.3444  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [1440/4579]  eta: 0:18:02  Lr: 0.030000  Loss: 0.3121  Acc@1: 43.7500 (50.7417)  Acc@5: 87.5000 (87.9424)  time: 0.3441  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [1450/4579]  eta: 0:17:59  Lr: 0.030000  Loss: 0.1240  Acc@1: 43.7500 (50.7193)  Acc@5: 87.5000 (87.9437)  time: 0.3441  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [1460/4579]  eta: 0:17:55  Lr: 0.030000  Loss: 0.4948  Acc@1: 50.0000 (50.7786)  Acc@5: 87.5000 (87.9321)  time: 0.3446  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [1470/4579]  eta: 0:17:52  Lr: 0.030000  Loss: 0.5365  Acc@1: 50.0000 (50.7690)  Acc@5: 87.5000 (87.9419)  time: 0.3447  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1480/4579]  eta: 0:17:48  Lr: 0.030000  Loss: 0.1791  Acc@1: 50.0000 (50.7934)  Acc@5: 87.5000 (87.9220)  time: 0.3457  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [1490/4579]  eta: 0:17:45  Lr: 0.030000  Loss: 0.5019  Acc@1: 50.0000 (50.7881)  Acc@5: 87.5000 (87.9108)  time: 0.3460  data: 0.0002  max mem: 2500
Train: Epoch[2/5]  [1500/4579]  eta: 0:17:41  Lr: 0.030000  Loss: 0.4493  Acc@1: 50.0000 (50.8078)  Acc@5: 87.5000 (87.9289)  time: 0.3448  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [1510/4579]  eta: 0:17:38  Lr: 0.030000  Loss: 0.1926  Acc@1: 50.0000 (50.7983)  Acc@5: 87.5000 (87.9343)  time: 0.3449  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [1520/4579]  eta: 0:17:35  Lr: 0.030000  Loss: 0.4176  Acc@1: 50.0000 (50.8383)  Acc@5: 93.7500 (87.9561)  time: 0.3453  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [1530/4579]  eta: 0:17:31  Lr: 0.030000  Loss: 0.2843  Acc@1: 56.2500 (50.9063)  Acc@5: 93.7500 (87.9613)  time: 0.3452  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [1540/4579]  eta: 0:17:28  Lr: 0.030000  Loss: 0.3011  Acc@1: 56.2500 (50.9247)  Acc@5: 93.7500 (87.9867)  time: 0.3444  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [1550/4579]  eta: 0:17:24  Lr: 0.030000  Loss: 0.2857  Acc@1: 56.2500 (50.9550)  Acc@5: 93.7500 (87.9956)  time: 0.3438  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [1560/4579]  eta: 0:17:21  Lr: 0.030000  Loss: 0.3031  Acc@1: 56.2500 (50.9529)  Acc@5: 87.5000 (88.0005)  time: 0.3434  data: 0.0002  max mem: 2500
Train: Epoch[2/5]  [1570/4579]  eta: 0:17:17  Lr: 0.030000  Loss: 0.2257  Acc@1: 50.0000 (50.9508)  Acc@5: 87.5000 (88.0053)  time: 0.3434  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [1580/4579]  eta: 0:17:14  Lr: 0.030000  Loss: 0.6996  Acc@1: 50.0000 (50.9369)  Acc@5: 87.5000 (88.0139)  time: 0.3441  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [1590/4579]  eta: 0:17:10  Lr: 0.030000  Loss: 0.1919  Acc@1: 50.0000 (50.9664)  Acc@5: 93.7500 (88.0343)  time: 0.3442  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [1600/4579]  eta: 0:17:07  Lr: 0.030000  Loss: 0.1199  Acc@1: 50.0000 (50.9877)  Acc@5: 93.7500 (88.0348)  time: 0.3439  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [1610/4579]  eta: 0:17:03  Lr: 0.030000  Loss: 0.3693  Acc@1: 50.0000 (50.9971)  Acc@5: 87.5000 (88.0237)  time: 0.3448  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [1620/4579]  eta: 0:17:00  Lr: 0.030000  Loss: 0.4590  Acc@1: 56.2500 (51.0256)  Acc@5: 87.5000 (88.0359)  time: 0.3458  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [1630/4579]  eta: 0:16:57  Lr: 0.030000  Loss: 0.4236  Acc@1: 50.0000 (51.0308)  Acc@5: 93.7500 (88.0595)  time: 0.3458  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1640/4579]  eta: 0:16:53  Lr: 0.030000  Loss: 0.3302  Acc@1: 50.0000 (51.0588)  Acc@5: 93.7500 (88.0713)  time: 0.3446  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1650/4579]  eta: 0:16:50  Lr: 0.030000  Loss: 0.4944  Acc@1: 50.0000 (51.0713)  Acc@5: 93.7500 (88.0906)  time: 0.3439  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [1660/4579]  eta: 0:16:46  Lr: 0.030000  Loss: 0.6494  Acc@1: 50.0000 (51.0611)  Acc@5: 93.7500 (88.0870)  time: 0.3442  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1670/4579]  eta: 0:16:43  Lr: 0.030000  Loss: 0.3422  Acc@1: 56.2500 (51.0996)  Acc@5: 87.5000 (88.1059)  time: 0.3439  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1680/4579]  eta: 0:16:39  Lr: 0.030000  Loss: 0.6134  Acc@1: 50.0000 (51.0708)  Acc@5: 87.5000 (88.0837)  time: 0.3448  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1690/4579]  eta: 0:16:36  Lr: 0.030000  Loss: 0.1897  Acc@1: 43.7500 (51.0792)  Acc@5: 87.5000 (88.0803)  time: 0.3448  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1700/4579]  eta: 0:16:32  Lr: 0.030000  Loss: 0.1933  Acc@1: 50.0000 (51.0802)  Acc@5: 87.5000 (88.0769)  time: 0.3440  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1710/4579]  eta: 0:16:29  Lr: 0.030000  Loss: 0.1577  Acc@1: 50.0000 (51.0959)  Acc@5: 87.5000 (88.0918)  time: 0.3438  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1720/4579]  eta: 0:16:25  Lr: 0.030000  Loss: 0.4784  Acc@1: 50.0000 (51.1331)  Acc@5: 87.5000 (88.1028)  time: 0.3438  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [1730/4579]  eta: 0:16:22  Lr: 0.030000  Loss: 0.3438  Acc@1: 50.0000 (51.1626)  Acc@5: 87.5000 (88.1030)  time: 0.3450  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1740/4579]  eta: 0:16:19  Lr: 0.030000  Loss: -0.0308  Acc@1: 50.0000 (51.1667)  Acc@5: 87.5000 (88.1067)  time: 0.3452  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1750/4579]  eta: 0:16:15  Lr: 0.030000  Loss: 0.0747  Acc@1: 50.0000 (51.1743)  Acc@5: 93.7500 (88.1318)  time: 0.3457  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1760/4579]  eta: 0:16:12  Lr: 0.030000  Loss: 0.3452  Acc@1: 56.2500 (51.2351)  Acc@5: 93.7500 (88.1566)  time: 0.3451  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1770/4579]  eta: 0:16:08  Lr: 0.030000  Loss: 0.6527  Acc@1: 56.2500 (51.2599)  Acc@5: 93.7500 (88.1599)  time: 0.3441  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [1780/4579]  eta: 0:16:05  Lr: 0.030000  Loss: -0.0009  Acc@1: 56.2500 (51.2809)  Acc@5: 93.7500 (88.1773)  time: 0.3443  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [1790/4579]  eta: 0:16:01  Lr: 0.030000  Loss: 0.3285  Acc@1: 56.2500 (51.2947)  Acc@5: 93.7500 (88.1840)  time: 0.3442  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [1800/4579]  eta: 0:15:58  Lr: 0.030000  Loss: 0.4367  Acc@1: 50.0000 (51.2771)  Acc@5: 87.5000 (88.1767)  time: 0.3439  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [1810/4579]  eta: 0:15:54  Lr: 0.030000  Loss: 0.5998  Acc@1: 50.0000 (51.2735)  Acc@5: 87.5000 (88.1695)  time: 0.3438  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [1820/4579]  eta: 0:15:51  Lr: 0.030000  Loss: 0.3126  Acc@1: 56.2500 (51.3008)  Acc@5: 87.5000 (88.1796)  time: 0.3446  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [1830/4579]  eta: 0:15:47  Lr: 0.030000  Loss: 0.0225  Acc@1: 56.2500 (51.3415)  Acc@5: 87.5000 (88.1827)  time: 0.3442  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [1840/4579]  eta: 0:15:44  Lr: 0.030000  Loss: 0.3059  Acc@1: 56.2500 (51.3444)  Acc@5: 87.5000 (88.1960)  time: 0.3429  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [1850/4579]  eta: 0:15:40  Lr: 0.030000  Loss: 0.6100  Acc@1: 50.0000 (51.3169)  Acc@5: 87.5000 (88.1854)  time: 0.3429  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [1860/4579]  eta: 0:15:37  Lr: 0.030000  Loss: 0.4790  Acc@1: 50.0000 (51.3165)  Acc@5: 87.5000 (88.1818)  time: 0.3436  data: 0.0002  max mem: 2500
Train: Epoch[2/5]  [1870/4579]  eta: 0:15:34  Lr: 0.030000  Loss: 0.4606  Acc@1: 50.0000 (51.2961)  Acc@5: 87.5000 (88.1815)  time: 0.3439  data: 0.0002  max mem: 2500
Train: Epoch[2/5]  [1880/4579]  eta: 0:15:30  Lr: 0.030000  Loss: 0.4740  Acc@1: 50.0000 (51.3158)  Acc@5: 87.5000 (88.2011)  time: 0.3443  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [1890/4579]  eta: 0:15:27  Lr: 0.030000  Loss: 0.3871  Acc@1: 50.0000 (51.3022)  Acc@5: 87.5000 (88.1941)  time: 0.3442  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [1900/4579]  eta: 0:15:23  Lr: 0.030000  Loss: 0.6375  Acc@1: 50.0000 (51.2888)  Acc@5: 87.5000 (88.1904)  time: 0.3442  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [1910/4579]  eta: 0:15:20  Lr: 0.030000  Loss: 0.3391  Acc@1: 50.0000 (51.3082)  Acc@5: 87.5000 (88.1901)  time: 0.3445  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [1920/4579]  eta: 0:15:16  Lr: 0.030000  Loss: 0.5710  Acc@1: 50.0000 (51.3112)  Acc@5: 87.5000 (88.1735)  time: 0.3447  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [1930/4579]  eta: 0:15:13  Lr: 0.030000  Loss: 0.1987  Acc@1: 50.0000 (51.3011)  Acc@5: 87.5000 (88.1603)  time: 0.3444  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1940/4579]  eta: 0:15:09  Lr: 0.030000  Loss: 0.5403  Acc@1: 56.2500 (51.3299)  Acc@5: 87.5000 (88.1569)  time: 0.3448  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1950/4579]  eta: 0:15:06  Lr: 0.030000  Loss: -0.0522  Acc@1: 50.0000 (51.3294)  Acc@5: 87.5000 (88.1631)  time: 0.3447  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1960/4579]  eta: 0:15:02  Lr: 0.030000  Loss: 0.2694  Acc@1: 50.0000 (51.3609)  Acc@5: 87.5000 (88.1725)  time: 0.3436  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1970/4579]  eta: 0:14:59  Lr: 0.030000  Loss: 0.4338  Acc@1: 50.0000 (51.3508)  Acc@5: 87.5000 (88.1754)  time: 0.3440  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1980/4579]  eta: 0:14:56  Lr: 0.030000  Loss: 0.6418  Acc@1: 50.0000 (51.3282)  Acc@5: 87.5000 (88.1815)  time: 0.3447  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1990/4579]  eta: 0:14:52  Lr: 0.030000  Loss: 0.2127  Acc@1: 50.0000 (51.3655)  Acc@5: 93.7500 (88.2032)  time: 0.3446  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [2000/4579]  eta: 0:14:49  Lr: 0.030000  Loss: 0.0980  Acc@1: 50.0000 (51.3774)  Acc@5: 87.5000 (88.1840)  time: 0.3446  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [2010/4579]  eta: 0:14:45  Lr: 0.030000  Loss: 0.3850  Acc@1: 50.0000 (51.3955)  Acc@5: 87.5000 (88.2024)  time: 0.3448  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [2020/4579]  eta: 0:14:42  Lr: 0.030000  Loss: 0.4942  Acc@1: 50.0000 (51.4102)  Acc@5: 87.5000 (88.2051)  time: 0.3446  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [2030/4579]  eta: 0:14:38  Lr: 0.030000  Loss: 0.5963  Acc@1: 50.0000 (51.4002)  Acc@5: 87.5000 (88.2047)  time: 0.3445  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [2040/4579]  eta: 0:14:35  Lr: 0.030000  Loss: 0.4917  Acc@1: 50.0000 (51.3780)  Acc@5: 87.5000 (88.1951)  time: 0.3449  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [2050/4579]  eta: 0:14:31  Lr: 0.030000  Loss: 0.1952  Acc@1: 43.7500 (51.3896)  Acc@5: 87.5000 (88.2070)  time: 0.3445  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [2060/4579]  eta: 0:14:28  Lr: 0.030000  Loss: 0.4644  Acc@1: 43.7500 (51.3768)  Acc@5: 87.5000 (88.2066)  time: 0.3435  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [2070/4579]  eta: 0:14:24  Lr: 0.030000  Loss: 0.1436  Acc@1: 43.7500 (51.3882)  Acc@5: 87.5000 (88.2122)  time: 0.3434  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [2080/4579]  eta: 0:14:21  Lr: 0.030000  Loss: 0.4011  Acc@1: 50.0000 (51.3876)  Acc@5: 93.7500 (88.2328)  time: 0.3428  data: 0.0002  max mem: 2500
Train: Epoch[2/5]  [2090/4579]  eta: 0:14:18  Lr: 0.030000  Loss: -0.0015  Acc@1: 56.2500 (51.4138)  Acc@5: 93.7500 (88.2473)  time: 0.3425  data: 0.0002  max mem: 2500
Train: Epoch[2/5]  [2100/4579]  eta: 0:14:14  Lr: 0.030000  Loss: -0.0015  Acc@1: 56.2500 (51.4368)  Acc@5: 93.7500 (88.2526)  time: 0.3432  data: 0.0002  max mem: 2500
Train: Epoch[2/5]  [2110/4579]  eta: 0:14:11  Lr: 0.030000  Loss: -0.0328  Acc@1: 62.5000 (51.4626)  Acc@5: 93.7500 (88.2639)  time: 0.3436  data: 0.0002  max mem: 2500
Train: Epoch[2/5]  [2120/4579]  eta: 0:14:07  Lr: 0.030000  Loss: 0.2655  Acc@1: 62.5000 (51.5087)  Acc@5: 93.7500 (88.2838)  time: 0.3455  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [2130/4579]  eta: 0:14:04  Lr: 0.030000  Loss: 0.4558  Acc@1: 56.2500 (51.4958)  Acc@5: 93.7500 (88.2831)  time: 0.3470  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [2140/4579]  eta: 0:14:00  Lr: 0.030000  Loss: 0.2864  Acc@1: 50.0000 (51.5034)  Acc@5: 87.5000 (88.2794)  time: 0.3457  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2150/4579]  eta: 0:13:57  Lr: 0.030000  Loss: 0.1402  Acc@1: 50.0000 (51.4702)  Acc@5: 81.2500 (88.2613)  time: 0.3454  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2160/4579]  eta: 0:13:53  Lr: 0.030000  Loss: 0.5741  Acc@1: 50.0000 (51.4808)  Acc@5: 87.5000 (88.2635)  time: 0.3454  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2170/4579]  eta: 0:13:50  Lr: 0.030000  Loss: 0.4887  Acc@1: 50.0000 (51.4711)  Acc@5: 93.7500 (88.2687)  time: 0.3453  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2180/4579]  eta: 0:13:47  Lr: 0.030000  Loss: 0.3322  Acc@1: 50.0000 (51.4787)  Acc@5: 93.7500 (88.2680)  time: 0.3452  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2190/4579]  eta: 0:13:43  Lr: 0.030000  Loss: 0.2702  Acc@1: 56.2500 (51.4862)  Acc@5: 93.7500 (88.2730)  time: 0.3451  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2200/4579]  eta: 0:13:40  Lr: 0.030000  Loss: 0.2558  Acc@1: 56.2500 (51.5050)  Acc@5: 87.5000 (88.2667)  time: 0.3456  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2210/4579]  eta: 0:13:36  Lr: 0.030000  Loss: 0.4339  Acc@1: 56.2500 (51.5236)  Acc@5: 87.5000 (88.2632)  time: 0.3452  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2220/4579]  eta: 0:13:33  Lr: 0.030000  Loss: 0.7978  Acc@1: 50.0000 (51.4858)  Acc@5: 81.2500 (88.2176)  time: 0.3454  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [2230/4579]  eta: 0:13:29  Lr: 0.030000  Loss: 0.1209  Acc@1: 50.0000 (51.4904)  Acc@5: 81.2500 (88.2032)  time: 0.3454  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2240/4579]  eta: 0:13:26  Lr: 0.030000  Loss: 0.7785  Acc@1: 56.2500 (51.5004)  Acc@5: 87.5000 (88.1833)  time: 0.3448  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [2250/4579]  eta: 0:13:22  Lr: 0.030000  Loss: 0.1311  Acc@1: 56.2500 (51.5021)  Acc@5: 87.5000 (88.1803)  time: 0.3451  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2260/4579]  eta: 0:13:19  Lr: 0.030000  Loss: 0.2682  Acc@1: 56.2500 (51.5176)  Acc@5: 87.5000 (88.1717)  time: 0.3455  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [2270/4579]  eta: 0:13:16  Lr: 0.030000  Loss: 0.0982  Acc@1: 50.0000 (51.5081)  Acc@5: 87.5000 (88.1825)  time: 0.3456  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2280/4579]  eta: 0:13:12  Lr: 0.030000  Loss: 0.1864  Acc@1: 50.0000 (51.5043)  Acc@5: 87.5000 (88.1686)  time: 0.3449  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [2290/4579]  eta: 0:13:09  Lr: 0.030000  Loss: 0.0909  Acc@1: 50.0000 (51.5441)  Acc@5: 93.7500 (88.1766)  time: 0.3448  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [2300/4579]  eta: 0:13:05  Lr: 0.030000  Loss: -0.0495  Acc@1: 56.2500 (51.5428)  Acc@5: 93.7500 (88.1872)  time: 0.3451  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [2310/4579]  eta: 0:13:02  Lr: 0.030000  Loss: 0.0848  Acc@1: 56.2500 (51.5740)  Acc@5: 93.7500 (88.1977)  time: 0.3452  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [2320/4579]  eta: 0:12:58  Lr: 0.030000  Loss: 0.2620  Acc@1: 56.2500 (51.6022)  Acc@5: 87.5000 (88.2028)  time: 0.3451  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [2330/4579]  eta: 0:12:55  Lr: 0.030000  Loss: 0.1003  Acc@1: 56.2500 (51.6195)  Acc@5: 87.5000 (88.1891)  time: 0.3445  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [2340/4579]  eta: 0:12:51  Lr: 0.030000  Loss: 0.5599  Acc@1: 50.0000 (51.6179)  Acc@5: 87.5000 (88.1915)  time: 0.3453  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [2350/4579]  eta: 0:12:48  Lr: 0.030000  Loss: 0.2331  Acc@1: 56.2500 (51.6429)  Acc@5: 87.5000 (88.1939)  time: 0.3446  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [2360/4579]  eta: 0:12:45  Lr: 0.030000  Loss: 0.1281  Acc@1: 56.2500 (51.6757)  Acc@5: 87.5000 (88.2121)  time: 0.3426  data: 0.0002  max mem: 2500
Train: Epoch[2/5]  [2370/4579]  eta: 0:12:41  Lr: 0.030000  Loss: 0.3971  Acc@1: 56.2500 (51.6976)  Acc@5: 87.5000 (88.2223)  time: 0.3421  data: 0.0002  max mem: 2500
Train: Epoch[2/5]  [2380/4579]  eta: 0:12:38  Lr: 0.030000  Loss: 0.6848  Acc@1: 50.0000 (51.6668)  Acc@5: 87.5000 (88.2192)  time: 0.3426  data: 0.0002  max mem: 2500
Train: Epoch[2/5]  [2390/4579]  eta: 0:12:34  Lr: 0.030000  Loss: 0.1092  Acc@1: 50.0000 (51.6834)  Acc@5: 87.5000 (88.2110)  time: 0.3427  data: 0.0002  max mem: 2500
Train: Epoch[2/5]  [2400/4579]  eta: 0:12:31  Lr: 0.030000  Loss: 0.3022  Acc@1: 56.2500 (51.7050)  Acc@5: 87.5000 (88.2158)  time: 0.3432  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [2410/4579]  eta: 0:12:27  Lr: 0.030000  Loss: 0.6274  Acc@1: 56.2500 (51.6979)  Acc@5: 87.5000 (88.2051)  time: 0.3441  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [2420/4579]  eta: 0:12:24  Lr: 0.030000  Loss: 0.3152  Acc@1: 56.2500 (51.7477)  Acc@5: 87.5000 (88.2254)  time: 0.3444  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2430/4579]  eta: 0:12:20  Lr: 0.030000  Loss: 0.4551  Acc@1: 56.2500 (51.7483)  Acc@5: 93.7500 (88.2353)  time: 0.3453  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2440/4579]  eta: 0:12:17  Lr: 0.030000  Loss: 0.4183  Acc@1: 50.0000 (51.7539)  Acc@5: 87.5000 (88.2323)  time: 0.3454  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [2450/4579]  eta: 0:12:13  Lr: 0.030000  Loss: 0.2925  Acc@1: 50.0000 (51.7799)  Acc@5: 87.5000 (88.2420)  time: 0.3447  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2460/4579]  eta: 0:12:10  Lr: 0.030000  Loss: 0.2625  Acc@1: 56.2500 (51.8057)  Acc@5: 93.7500 (88.2619)  time: 0.3446  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2470/4579]  eta: 0:12:07  Lr: 0.030000  Loss: 0.5219  Acc@1: 56.2500 (51.8059)  Acc@5: 87.5000 (88.2664)  time: 0.3442  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [2480/4579]  eta: 0:12:03  Lr: 0.030000  Loss: 0.4739  Acc@1: 50.0000 (51.8213)  Acc@5: 87.5000 (88.2658)  time: 0.3447  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2490/4579]  eta: 0:12:00  Lr: 0.030000  Loss: 0.3114  Acc@1: 56.2500 (51.8416)  Acc@5: 87.5000 (88.2703)  time: 0.3444  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2500/4579]  eta: 0:11:56  Lr: 0.030000  Loss: 0.3800  Acc@1: 56.2500 (51.8842)  Acc@5: 87.5000 (88.2822)  time: 0.3435  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2510/4579]  eta: 0:11:53  Lr: 0.030000  Loss: 0.4270  Acc@1: 56.2500 (51.9016)  Acc@5: 93.7500 (88.2841)  time: 0.3438  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [2520/4579]  eta: 0:11:49  Lr: 0.030000  Loss: 0.3221  Acc@1: 56.2500 (51.9090)  Acc@5: 93.7500 (88.2983)  time: 0.3443  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [2530/4579]  eta: 0:11:46  Lr: 0.030000  Loss: 0.3480  Acc@1: 56.2500 (51.9212)  Acc@5: 93.7500 (88.3100)  time: 0.3444  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [2540/4579]  eta: 0:11:42  Lr: 0.030000  Loss: 0.3143  Acc@1: 56.2500 (51.9431)  Acc@5: 87.5000 (88.3018)  time: 0.3443  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [2550/4579]  eta: 0:11:39  Lr: 0.030000  Loss: 0.6062  Acc@1: 56.2500 (51.9453)  Acc@5: 87.5000 (88.3061)  time: 0.3440  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [2560/4579]  eta: 0:11:35  Lr: 0.030000  Loss: 0.6838  Acc@1: 50.0000 (51.9426)  Acc@5: 87.5000 (88.3053)  time: 0.3431  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [2570/4579]  eta: 0:11:32  Lr: 0.030000  Loss: 0.4183  Acc@1: 50.0000 (51.9229)  Acc@5: 87.5000 (88.3119)  time: 0.3428  data: 0.0002  max mem: 2500
Train: Epoch[2/5]  [2580/4579]  eta: 0:11:29  Lr: 0.030000  Loss: 0.1673  Acc@1: 50.0000 (51.9275)  Acc@5: 87.5000 (88.3161)  time: 0.3429  data: 0.0002  max mem: 2500
Train: Epoch[2/5]  [2590/4579]  eta: 0:11:25  Lr: 0.030000  Loss: 0.3748  Acc@1: 62.5000 (51.9756)  Acc@5: 87.5000 (88.3322)  time: 0.3435  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [2600/4579]  eta: 0:11:22  Lr: 0.030000  Loss: 0.1598  Acc@1: 56.2500 (51.9752)  Acc@5: 93.7500 (88.3386)  time: 0.3445  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [2610/4579]  eta: 0:11:18  Lr: 0.030000  Loss: 0.4848  Acc@1: 56.2500 (51.9796)  Acc@5: 93.7500 (88.3450)  time: 0.3444  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2620/4579]  eta: 0:11:15  Lr: 0.030000  Loss: 0.6214  Acc@1: 50.0000 (51.9864)  Acc@5: 87.5000 (88.3465)  time: 0.3444  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2630/4579]  eta: 0:11:11  Lr: 0.030000  Loss: 0.4500  Acc@1: 50.0000 (51.9836)  Acc@5: 87.5000 (88.3576)  time: 0.3444  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2640/4579]  eta: 0:11:08  Lr: 0.030000  Loss: 0.3855  Acc@1: 50.0000 (51.9808)  Acc@5: 87.5000 (88.3567)  time: 0.3435  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2650/4579]  eta: 0:11:04  Lr: 0.030000  Loss: 0.3064  Acc@1: 50.0000 (51.9733)  Acc@5: 87.5000 (88.3723)  time: 0.3437  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [2660/4579]  eta: 0:11:01  Lr: 0.030000  Loss: 0.3629  Acc@1: 43.7500 (51.9542)  Acc@5: 87.5000 (88.3737)  time: 0.3441  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [2670/4579]  eta: 0:10:57  Lr: 0.030000  Loss: 0.3832  Acc@1: 56.2500 (51.9890)  Acc@5: 87.5000 (88.3728)  time: 0.3443  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [2680/4579]  eta: 0:10:54  Lr: 0.030000  Loss: 0.4018  Acc@1: 56.2500 (51.9862)  Acc@5: 87.5000 (88.3719)  time: 0.3446  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [2690/4579]  eta: 0:10:51  Lr: 0.030000  Loss: 0.3971  Acc@1: 50.0000 (51.9742)  Acc@5: 87.5000 (88.3686)  time: 0.3446  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [2700/4579]  eta: 0:10:47  Lr: 0.030000  Loss: 0.3854  Acc@1: 50.0000 (51.9969)  Acc@5: 87.5000 (88.3724)  time: 0.3448  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [2710/4579]  eta: 0:10:44  Lr: 0.030000  Loss: 0.3843  Acc@1: 56.2500 (51.9988)  Acc@5: 87.5000 (88.3784)  time: 0.3452  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [2720/4579]  eta: 0:10:40  Lr: 0.030000  Loss: 0.2930  Acc@1: 56.2500 (52.0282)  Acc@5: 87.5000 (88.3843)  time: 0.3441  data: 0.0002  max mem: 2500
Train: Epoch[2/5]  [2730/4579]  eta: 0:10:37  Lr: 0.030000  Loss: 0.3295  Acc@1: 56.2500 (52.0437)  Acc@5: 93.7500 (88.3971)  time: 0.3433  data: 0.0002  max mem: 2500
Train: Epoch[2/5]  [2740/4579]  eta: 0:10:33  Lr: 0.030000  Loss: 0.3288  Acc@1: 56.2500 (52.0499)  Acc@5: 87.5000 (88.3779)  time: 0.3438  data: 0.0002  max mem: 2500
Train: Epoch[2/5]  [2750/4579]  eta: 0:10:30  Lr: 0.030000  Loss: 0.6162  Acc@1: 50.0000 (52.0334)  Acc@5: 87.5000 (88.3724)  time: 0.3437  data: 0.0002  max mem: 2500
Train: Epoch[2/5]  [2760/4579]  eta: 0:10:26  Lr: 0.030000  Loss: 0.0852  Acc@1: 56.2500 (52.0532)  Acc@5: 87.5000 (88.3783)  time: 0.3435  data: 0.0002  max mem: 2500
Train: Epoch[2/5]  [2770/4579]  eta: 0:10:23  Lr: 0.030000  Loss: 0.3613  Acc@1: 56.2500 (52.0728)  Acc@5: 87.5000 (88.3774)  time: 0.3434  data: 0.0002  max mem: 2500
Train: Epoch[2/5]  [2780/4579]  eta: 0:10:20  Lr: 0.030000  Loss: 0.4263  Acc@1: 56.2500 (52.0676)  Acc@5: 87.5000 (88.3810)  time: 0.3436  data: 0.0002  max mem: 2500
Train: Epoch[2/5]  [2790/4579]  eta: 0:10:16  Lr: 0.030000  Loss: 0.4424  Acc@1: 56.2500 (52.0871)  Acc@5: 93.7500 (88.3913)  time: 0.3439  data: 0.0002  max mem: 2500
Train: Epoch[2/5]  [2800/4579]  eta: 0:10:13  Lr: 0.030000  Loss: 0.2742  Acc@1: 56.2500 (52.1019)  Acc@5: 93.7500 (88.3925)  time: 0.3449  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [2810/4579]  eta: 0:10:09  Lr: 0.030000  Loss: 0.2153  Acc@1: 56.2500 (52.1122)  Acc@5: 93.7500 (88.4049)  time: 0.3463  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [2820/4579]  eta: 0:10:06  Lr: 0.030000  Loss: 0.3003  Acc@1: 56.2500 (52.1225)  Acc@5: 87.5000 (88.4017)  time: 0.3476  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [2830/4579]  eta: 0:10:02  Lr: 0.030000  Loss: 0.2558  Acc@1: 56.2500 (52.1326)  Acc@5: 87.5000 (88.4162)  time: 0.3476  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [2840/4579]  eta: 0:09:59  Lr: 0.030000  Loss: 0.2390  Acc@1: 56.2500 (52.1339)  Acc@5: 87.5000 (88.4064)  time: 0.3489  data: 0.0011  max mem: 2500
Train: Epoch[2/5]  [2850/4579]  eta: 0:09:55  Lr: 0.030000  Loss: 0.5763  Acc@1: 50.0000 (52.1308)  Acc@5: 87.5000 (88.4054)  time: 0.3489  data: 0.0009  max mem: 2500
Train: Epoch[2/5]  [2860/4579]  eta: 0:09:52  Lr: 0.030000  Loss: 0.5361  Acc@1: 56.2500 (52.1452)  Acc@5: 87.5000 (88.4110)  time: 0.3469  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2870/4579]  eta: 0:09:49  Lr: 0.030000  Loss: 0.6901  Acc@1: 56.2500 (52.1378)  Acc@5: 93.7500 (88.4230)  time: 0.3470  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2880/4579]  eta: 0:09:45  Lr: 0.030000  Loss: 0.4007  Acc@1: 56.2500 (52.1607)  Acc@5: 93.7500 (88.4285)  time: 0.3466  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2890/4579]  eta: 0:09:42  Lr: 0.030000  Loss: 0.1043  Acc@1: 56.2500 (52.1619)  Acc@5: 93.7500 (88.4318)  time: 0.3464  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2900/4579]  eta: 0:09:38  Lr: 0.030000  Loss: 0.4843  Acc@1: 56.2500 (52.1717)  Acc@5: 93.7500 (88.4329)  time: 0.3476  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [2910/4579]  eta: 0:09:35  Lr: 0.030000  Loss: 0.3091  Acc@1: 56.2500 (52.1728)  Acc@5: 87.5000 (88.4275)  time: 0.3478  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [2920/4579]  eta: 0:09:31  Lr: 0.030000  Loss: 0.2062  Acc@1: 56.2500 (52.1803)  Acc@5: 87.5000 (88.4350)  time: 0.3470  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2930/4579]  eta: 0:09:28  Lr: 0.030000  Loss: 0.3114  Acc@1: 50.0000 (52.1963)  Acc@5: 87.5000 (88.4361)  time: 0.3458  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2940/4579]  eta: 0:09:25  Lr: 0.030000  Loss: 0.5994  Acc@1: 43.7500 (52.1825)  Acc@5: 87.5000 (88.4414)  time: 0.3451  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2950/4579]  eta: 0:09:21  Lr: 0.030000  Loss: 0.4796  Acc@1: 43.7500 (52.1793)  Acc@5: 87.5000 (88.4319)  time: 0.3451  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2960/4579]  eta: 0:09:18  Lr: 0.030000  Loss: 0.1930  Acc@1: 50.0000 (52.1910)  Acc@5: 87.5000 (88.4372)  time: 0.3459  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2970/4579]  eta: 0:09:14  Lr: 0.030000  Loss: 0.0414  Acc@1: 56.2500 (52.2173)  Acc@5: 93.7500 (88.4445)  time: 0.3463  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [2980/4579]  eta: 0:09:11  Lr: 0.030000  Loss: 0.3263  Acc@1: 56.2500 (52.1993)  Acc@5: 93.7500 (88.4602)  time: 0.3454  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [2990/4579]  eta: 0:09:07  Lr: 0.030000  Loss: 0.3037  Acc@1: 56.2500 (52.2150)  Acc@5: 93.7500 (88.4654)  time: 0.3454  data: 0.0002  max mem: 2500
Train: Epoch[2/5]  [3000/4579]  eta: 0:09:04  Lr: 0.030000  Loss: 0.1166  Acc@1: 62.5000 (52.2284)  Acc@5: 93.7500 (88.4726)  time: 0.3451  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [3010/4579]  eta: 0:09:00  Lr: 0.030000  Loss: 0.3186  Acc@1: 56.2500 (52.2231)  Acc@5: 93.7500 (88.4777)  time: 0.3457  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [3020/4579]  eta: 0:08:57  Lr: 0.030000  Loss: 0.1409  Acc@1: 56.2500 (52.2364)  Acc@5: 93.7500 (88.4868)  time: 0.3456  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [3030/4579]  eta: 0:08:54  Lr: 0.030000  Loss: 0.3476  Acc@1: 56.2500 (52.2579)  Acc@5: 93.7500 (88.4939)  time: 0.3447  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [3040/4579]  eta: 0:08:50  Lr: 0.030000  Loss: 0.0311  Acc@1: 56.2500 (52.2772)  Acc@5: 93.7500 (88.4988)  time: 0.3457  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [3050/4579]  eta: 0:08:47  Lr: 0.030000  Loss: 0.4380  Acc@1: 50.0000 (52.2738)  Acc@5: 93.7500 (88.5079)  time: 0.3447  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [3060/4579]  eta: 0:08:43  Lr: 0.030000  Loss: 0.3920  Acc@1: 56.2500 (52.2909)  Acc@5: 93.7500 (88.5148)  time: 0.3430  data: 0.0002  max mem: 2500
Train: Epoch[2/5]  [3070/4579]  eta: 0:08:40  Lr: 0.030000  Loss: -0.0055  Acc@1: 56.2500 (52.2835)  Acc@5: 87.5000 (88.5135)  time: 0.3432  data: 0.0002  max mem: 2500
Train: Epoch[2/5]  [3080/4579]  eta: 0:08:36  Lr: 0.030000  Loss: 0.1358  Acc@1: 50.0000 (52.2842)  Acc@5: 93.7500 (88.5143)  time: 0.3433  data: 0.0002  max mem: 2500
Train: Epoch[2/5]  [3090/4579]  eta: 0:08:33  Lr: 0.030000  Loss: 0.5657  Acc@1: 56.2500 (52.2869)  Acc@5: 87.5000 (88.5231)  time: 0.3433  data: 0.0002  max mem: 2500
Train: Epoch[2/5]  [3100/4579]  eta: 0:08:29  Lr: 0.030000  Loss: 0.3642  Acc@1: 56.2500 (52.2876)  Acc@5: 87.5000 (88.5239)  time: 0.3433  data: 0.0002  max mem: 2500
Train: Epoch[2/5]  [3110/4579]  eta: 0:08:26  Lr: 0.030000  Loss: 0.3570  Acc@1: 56.2500 (52.3023)  Acc@5: 93.7500 (88.5306)  time: 0.3434  data: 0.0002  max mem: 2500
Train: Epoch[2/5]  [3120/4579]  eta: 0:08:22  Lr: 0.030000  Loss: 0.4956  Acc@1: 56.2500 (52.2949)  Acc@5: 87.5000 (88.5153)  time: 0.3437  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [3130/4579]  eta: 0:08:19  Lr: 0.030000  Loss: 0.2096  Acc@1: 56.2500 (52.3096)  Acc@5: 87.5000 (88.5081)  time: 0.3450  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [3140/4579]  eta: 0:08:16  Lr: 0.030000  Loss: 0.1977  Acc@1: 56.2500 (52.3321)  Acc@5: 87.5000 (88.5168)  time: 0.3450  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3150/4579]  eta: 0:08:12  Lr: 0.030000  Loss: 0.3276  Acc@1: 56.2500 (52.3346)  Acc@5: 87.5000 (88.5056)  time: 0.3444  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3160/4579]  eta: 0:08:09  Lr: 0.030000  Loss: 0.1640  Acc@1: 50.0000 (52.3391)  Acc@5: 87.5000 (88.5064)  time: 0.3444  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3170/4579]  eta: 0:08:05  Lr: 0.030000  Loss: 0.1417  Acc@1: 56.2500 (52.3514)  Acc@5: 87.5000 (88.5091)  time: 0.3449  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3180/4579]  eta: 0:08:02  Lr: 0.030000  Loss: 0.6116  Acc@1: 56.2500 (52.3617)  Acc@5: 93.7500 (88.5138)  time: 0.3452  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3190/4579]  eta: 0:07:58  Lr: 0.030000  Loss: 0.1671  Acc@1: 56.2500 (52.3719)  Acc@5: 93.7500 (88.5185)  time: 0.3455  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3200/4579]  eta: 0:07:55  Lr: 0.030000  Loss: 0.1853  Acc@1: 62.5000 (52.3977)  Acc@5: 87.5000 (88.5251)  time: 0.3454  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3210/4579]  eta: 0:07:51  Lr: 0.030000  Loss: 0.1998  Acc@1: 56.2500 (52.3941)  Acc@5: 87.5000 (88.5238)  time: 0.3443  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3220/4579]  eta: 0:07:48  Lr: 0.030000  Loss: 0.2317  Acc@1: 56.2500 (52.4100)  Acc@5: 87.5000 (88.5362)  time: 0.3443  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3230/4579]  eta: 0:07:45  Lr: 0.030000  Loss: 0.4242  Acc@1: 56.2500 (52.4160)  Acc@5: 87.5000 (88.5368)  time: 0.3462  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3240/4579]  eta: 0:07:41  Lr: 0.030000  Loss: 0.5950  Acc@1: 56.2500 (52.4317)  Acc@5: 87.5000 (88.5394)  time: 0.3458  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3250/4579]  eta: 0:07:38  Lr: 0.030000  Loss: 0.6769  Acc@1: 56.2500 (52.4377)  Acc@5: 87.5000 (88.5439)  time: 0.3442  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [3260/4579]  eta: 0:07:34  Lr: 0.030000  Loss: 0.1707  Acc@1: 50.0000 (52.4341)  Acc@5: 87.5000 (88.5445)  time: 0.3445  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [3270/4579]  eta: 0:07:31  Lr: 0.030000  Loss: 0.2888  Acc@1: 50.0000 (52.4343)  Acc@5: 87.5000 (88.5471)  time: 0.3450  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [3280/4579]  eta: 0:07:27  Lr: 0.030000  Loss: 0.3024  Acc@1: 50.0000 (52.4402)  Acc@5: 87.5000 (88.5439)  time: 0.3443  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [3290/4579]  eta: 0:07:24  Lr: 0.030000  Loss: 0.3172  Acc@1: 56.2500 (52.4708)  Acc@5: 87.5000 (88.5521)  time: 0.3432  data: 0.0002  max mem: 2500
Train: Epoch[2/5]  [3300/4579]  eta: 0:07:20  Lr: 0.030000  Loss: 0.3326  Acc@1: 56.2500 (52.4822)  Acc@5: 93.7500 (88.5641)  time: 0.3430  data: 0.0002  max mem: 2500
Train: Epoch[2/5]  [3310/4579]  eta: 0:07:17  Lr: 0.030000  Loss: 0.7434  Acc@1: 56.2500 (52.4860)  Acc@5: 93.7500 (88.5627)  time: 0.3431  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [3320/4579]  eta: 0:07:14  Lr: 0.030000  Loss: -0.0212  Acc@1: 56.2500 (52.5162)  Acc@5: 93.7500 (88.5652)  time: 0.3434  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [3330/4579]  eta: 0:07:10  Lr: 0.030000  Loss: 0.0566  Acc@1: 62.5000 (52.5424)  Acc@5: 93.7500 (88.5676)  time: 0.3440  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3340/4579]  eta: 0:07:07  Lr: 0.030000  Loss: 0.3918  Acc@1: 56.2500 (52.5385)  Acc@5: 93.7500 (88.5850)  time: 0.3441  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [3350/4579]  eta: 0:07:03  Lr: 0.030000  Loss: 0.2672  Acc@1: 50.0000 (52.5477)  Acc@5: 93.7500 (88.5911)  time: 0.3444  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [3360/4579]  eta: 0:07:00  Lr: 0.030000  Loss: 0.6354  Acc@1: 50.0000 (52.5439)  Acc@5: 87.5000 (88.5841)  time: 0.3444  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [3370/4579]  eta: 0:06:56  Lr: 0.030000  Loss: 0.4193  Acc@1: 56.2500 (52.5697)  Acc@5: 93.7500 (88.5846)  time: 0.3438  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [3380/4579]  eta: 0:06:53  Lr: 0.030000  Loss: 0.1759  Acc@1: 56.2500 (52.5658)  Acc@5: 87.5000 (88.5703)  time: 0.3439  data: 0.0002  max mem: 2500
Train: Epoch[2/5]  [3390/4579]  eta: 0:06:49  Lr: 0.030000  Loss: 0.3672  Acc@1: 50.0000 (52.5693)  Acc@5: 87.5000 (88.5745)  time: 0.3432  data: 0.0002  max mem: 2500
Train: Epoch[2/5]  [3400/4579]  eta: 0:06:46  Lr: 0.030000  Loss: 0.5543  Acc@1: 50.0000 (52.5654)  Acc@5: 87.5000 (88.5695)  time: 0.3424  data: 0.0002  max mem: 2500
Train: Epoch[2/5]  [3410/4579]  eta: 0:06:42  Lr: 0.030000  Loss: 0.3665  Acc@1: 50.0000 (52.5671)  Acc@5: 87.5000 (88.5774)  time: 0.3428  data: 0.0002  max mem: 2500
Train: Epoch[2/5]  [3420/4579]  eta: 0:06:39  Lr: 0.030000  Loss: 0.2936  Acc@1: 56.2500 (52.5833)  Acc@5: 93.7500 (88.5870)  time: 0.3434  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [3430/4579]  eta: 0:06:36  Lr: 0.030000  Loss: 0.3378  Acc@1: 50.0000 (52.5885)  Acc@5: 87.5000 (88.5802)  time: 0.3442  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3440/4579]  eta: 0:06:32  Lr: 0.030000  Loss: 0.3295  Acc@1: 56.2500 (52.6046)  Acc@5: 87.5000 (88.5880)  time: 0.3445  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3450/4579]  eta: 0:06:29  Lr: 0.030000  Loss: 0.2782  Acc@1: 56.2500 (52.6098)  Acc@5: 87.5000 (88.5921)  time: 0.3446  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3460/4579]  eta: 0:06:25  Lr: 0.030000  Loss: 0.2461  Acc@1: 56.2500 (52.6130)  Acc@5: 87.5000 (88.5943)  time: 0.3447  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3470/4579]  eta: 0:06:22  Lr: 0.030000  Loss: 0.5938  Acc@1: 50.0000 (52.6019)  Acc@5: 87.5000 (88.5894)  time: 0.3449  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [3480/4579]  eta: 0:06:18  Lr: 0.030000  Loss: 0.4628  Acc@1: 50.0000 (52.5980)  Acc@5: 87.5000 (88.5988)  time: 0.3447  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [3490/4579]  eta: 0:06:15  Lr: 0.030000  Loss: 0.1229  Acc@1: 56.2500 (52.6013)  Acc@5: 93.7500 (88.6010)  time: 0.3441  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [3500/4579]  eta: 0:06:11  Lr: 0.030000  Loss: 0.5212  Acc@1: 50.0000 (52.5832)  Acc@5: 93.7500 (88.5997)  time: 0.3444  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [3510/4579]  eta: 0:06:08  Lr: 0.030000  Loss: 0.5124  Acc@1: 50.0000 (52.5936)  Acc@5: 93.7500 (88.6072)  time: 0.3445  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [3520/4579]  eta: 0:06:05  Lr: 0.030000  Loss: 0.4413  Acc@1: 56.2500 (52.5987)  Acc@5: 87.5000 (88.6041)  time: 0.3444  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [3530/4579]  eta: 0:06:01  Lr: 0.030000  Loss: 0.1051  Acc@1: 56.2500 (52.6267)  Acc@5: 87.5000 (88.6045)  time: 0.3445  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [3540/4579]  eta: 0:05:58  Lr: 0.030000  Loss: 0.1973  Acc@1: 62.5000 (52.6493)  Acc@5: 93.7500 (88.6102)  time: 0.3438  data: 0.0002  max mem: 2500
Train: Epoch[2/5]  [3550/4579]  eta: 0:05:54  Lr: 0.030000  Loss: 0.3165  Acc@1: 56.2500 (52.6524)  Acc@5: 87.5000 (88.6141)  time: 0.3431  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [3560/4579]  eta: 0:05:51  Lr: 0.030000  Loss: 0.1542  Acc@1: 56.2500 (52.6731)  Acc@5: 87.5000 (88.6145)  time: 0.3429  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [3570/4579]  eta: 0:05:47  Lr: 0.030000  Loss: 0.2953  Acc@1: 56.2500 (52.6778)  Acc@5: 87.5000 (88.6131)  time: 0.3426  data: 0.0002  max mem: 2500
Train: Epoch[2/5]  [3580/4579]  eta: 0:05:44  Lr: 0.030000  Loss: 0.2425  Acc@1: 56.2500 (52.6826)  Acc@5: 87.5000 (88.6188)  time: 0.3426  data: 0.0002  max mem: 2500
Train: Epoch[2/5]  [3590/4579]  eta: 0:05:40  Lr: 0.030000  Loss: 0.5538  Acc@1: 56.2500 (52.6925)  Acc@5: 93.7500 (88.6243)  time: 0.3428  data: 0.0002  max mem: 2500
Train: Epoch[2/5]  [3600/4579]  eta: 0:05:37  Lr: 0.030000  Loss: 0.6482  Acc@1: 43.7500 (52.6868)  Acc@5: 87.5000 (88.6143)  time: 0.3436  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [3610/4579]  eta: 0:05:33  Lr: 0.030000  Loss: 0.3047  Acc@1: 50.0000 (52.6793)  Acc@5: 87.5000 (88.6164)  time: 0.3450  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3620/4579]  eta: 0:05:30  Lr: 0.030000  Loss: 0.2490  Acc@1: 50.0000 (52.6736)  Acc@5: 87.5000 (88.6116)  time: 0.3453  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3630/4579]  eta: 0:05:27  Lr: 0.030000  Loss: 0.3190  Acc@1: 50.0000 (52.6869)  Acc@5: 87.5000 (88.6171)  time: 0.3452  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [3640/4579]  eta: 0:05:23  Lr: 0.030000  Loss: 0.1790  Acc@1: 62.5000 (52.7122)  Acc@5: 93.7500 (88.6329)  time: 0.3450  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3650/4579]  eta: 0:05:20  Lr: 0.030000  Loss: 0.3545  Acc@1: 62.5000 (52.7219)  Acc@5: 93.7500 (88.6435)  time: 0.3461  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [3660/4579]  eta: 0:05:16  Lr: 0.030000  Loss: 0.7852  Acc@1: 50.0000 (52.7195)  Acc@5: 87.5000 (88.6336)  time: 0.3463  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [3670/4579]  eta: 0:05:13  Lr: 0.030000  Loss: 0.4554  Acc@1: 50.0000 (52.7172)  Acc@5: 87.5000 (88.6373)  time: 0.3459  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3680/4579]  eta: 0:05:09  Lr: 0.030000  Loss: 0.1601  Acc@1: 50.0000 (52.7268)  Acc@5: 87.5000 (88.6393)  time: 0.3453  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3690/4579]  eta: 0:05:06  Lr: 0.030000  Loss: 0.3714  Acc@1: 56.2500 (52.7415)  Acc@5: 87.5000 (88.6396)  time: 0.3443  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3700/4579]  eta: 0:05:02  Lr: 0.030000  Loss: 0.0842  Acc@1: 56.2500 (52.7661)  Acc@5: 87.5000 (88.6399)  time: 0.3458  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3710/4579]  eta: 0:04:59  Lr: 0.030000  Loss: 0.3715  Acc@1: 56.2500 (52.7738)  Acc@5: 87.5000 (88.6436)  time: 0.3461  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3720/4579]  eta: 0:04:56  Lr: 0.030000  Loss: 0.3122  Acc@1: 56.2500 (52.7899)  Acc@5: 87.5000 (88.6455)  time: 0.3450  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3730/4579]  eta: 0:04:52  Lr: 0.030000  Loss: 0.2260  Acc@1: 56.2500 (52.7808)  Acc@5: 93.7500 (88.6575)  time: 0.3443  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3740/4579]  eta: 0:04:49  Lr: 0.030000  Loss: -0.0009  Acc@1: 56.2500 (52.7867)  Acc@5: 87.5000 (88.6594)  time: 0.3441  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [3750/4579]  eta: 0:04:45  Lr: 0.030000  Loss: 0.5020  Acc@1: 56.2500 (52.8109)  Acc@5: 93.7500 (88.6747)  time: 0.3445  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [3760/4579]  eta: 0:04:42  Lr: 0.030000  Loss: 0.5014  Acc@1: 56.2500 (52.8250)  Acc@5: 93.7500 (88.6699)  time: 0.3447  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [3770/4579]  eta: 0:04:38  Lr: 0.030000  Loss: 0.0772  Acc@1: 56.2500 (52.8490)  Acc@5: 93.7500 (88.6850)  time: 0.3446  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [3780/4579]  eta: 0:04:35  Lr: 0.030000  Loss: 0.2951  Acc@1: 50.0000 (52.8465)  Acc@5: 93.7500 (88.6852)  time: 0.3442  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [3790/4579]  eta: 0:04:31  Lr: 0.030000  Loss: 0.4055  Acc@1: 50.0000 (52.8571)  Acc@5: 93.7500 (88.6969)  time: 0.3442  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [3800/4579]  eta: 0:04:28  Lr: 0.030000  Loss: 0.4274  Acc@1: 50.0000 (52.8578)  Acc@5: 93.7500 (88.6987)  time: 0.3437  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [3810/4579]  eta: 0:04:25  Lr: 0.030000  Loss: -0.0431  Acc@1: 50.0000 (52.8536)  Acc@5: 87.5000 (88.6890)  time: 0.3427  data: 0.0002  max mem: 2500
Train: Epoch[2/5]  [3820/4579]  eta: 0:04:21  Lr: 0.030000  Loss: 0.2019  Acc@1: 56.2500 (52.8657)  Acc@5: 87.5000 (88.7039)  time: 0.3425  data: 0.0002  max mem: 2500
Train: Epoch[2/5]  [3830/4579]  eta: 0:04:18  Lr: 0.030000  Loss: 0.2645  Acc@1: 56.2500 (52.8811)  Acc@5: 87.5000 (88.7040)  time: 0.3427  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [3840/4579]  eta: 0:04:14  Lr: 0.030000  Loss: 0.3086  Acc@1: 56.2500 (52.8915)  Acc@5: 87.5000 (88.7074)  time: 0.3432  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [3850/4579]  eta: 0:04:11  Lr: 0.030000  Loss: 0.4436  Acc@1: 56.2500 (52.9148)  Acc@5: 93.7500 (88.7140)  time: 0.3440  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [3860/4579]  eta: 0:04:07  Lr: 0.030000  Loss: 0.7854  Acc@1: 56.2500 (52.9057)  Acc@5: 87.5000 (88.7060)  time: 0.3451  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3870/4579]  eta: 0:04:04  Lr: 0.030000  Loss: 0.1856  Acc@1: 56.2500 (52.9256)  Acc@5: 93.7500 (88.7174)  time: 0.3448  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3880/4579]  eta: 0:04:00  Lr: 0.030000  Loss: 0.4784  Acc@1: 56.2500 (52.9374)  Acc@5: 93.7500 (88.7255)  time: 0.3444  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3890/4579]  eta: 0:03:57  Lr: 0.030000  Loss: 0.3370  Acc@1: 56.2500 (52.9475)  Acc@5: 93.7500 (88.7272)  time: 0.3445  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3900/4579]  eta: 0:03:54  Lr: 0.030000  Loss: 0.2771  Acc@1: 56.2500 (52.9496)  Acc@5: 93.7500 (88.7240)  time: 0.3442  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [3910/4579]  eta: 0:03:50  Lr: 0.030000  Loss: 0.4093  Acc@1: 62.5000 (52.9644)  Acc@5: 93.7500 (88.7193)  time: 0.3440  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [3920/4579]  eta: 0:03:47  Lr: 0.030000  Loss: 0.4090  Acc@1: 56.2500 (52.9584)  Acc@5: 93.7500 (88.7194)  time: 0.3439  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [3930/4579]  eta: 0:03:43  Lr: 0.030000  Loss: 0.1630  Acc@1: 56.2500 (52.9668)  Acc@5: 93.7500 (88.7242)  time: 0.3438  data: 0.0002  max mem: 2500
Train: Epoch[2/5]  [3940/4579]  eta: 0:03:40  Lr: 0.030000  Loss: 0.2740  Acc@1: 56.2500 (52.9831)  Acc@5: 87.5000 (88.7227)  time: 0.3436  data: 0.0002  max mem: 2500
Train: Epoch[2/5]  [3950/4579]  eta: 0:03:36  Lr: 0.030000  Loss: 0.2121  Acc@1: 62.5000 (53.0008)  Acc@5: 93.7500 (88.7260)  time: 0.3431  data: 0.0002  max mem: 2500
Train: Epoch[2/5]  [3960/4579]  eta: 0:03:33  Lr: 0.030000  Loss: 0.3642  Acc@1: 56.2500 (53.0043)  Acc@5: 87.5000 (88.7213)  time: 0.3433  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [3970/4579]  eta: 0:03:29  Lr: 0.030000  Loss: 0.0370  Acc@1: 56.2500 (53.0251)  Acc@5: 87.5000 (88.7308)  time: 0.3443  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [3980/4579]  eta: 0:03:26  Lr: 0.030000  Loss: 0.2482  Acc@1: 56.2500 (53.0332)  Acc@5: 93.7500 (88.7387)  time: 0.3446  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [3990/4579]  eta: 0:03:22  Lr: 0.030000  Loss: 0.3569  Acc@1: 50.0000 (53.0240)  Acc@5: 87.5000 (88.7372)  time: 0.3442  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [4000/4579]  eta: 0:03:19  Lr: 0.030000  Loss: -0.0387  Acc@1: 50.0000 (53.0430)  Acc@5: 87.5000 (88.7434)  time: 0.3441  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [4010/4579]  eta: 0:03:16  Lr: 0.030000  Loss: 0.1173  Acc@1: 62.5000 (53.0619)  Acc@5: 87.5000 (88.7419)  time: 0.3437  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [4020/4579]  eta: 0:03:12  Lr: 0.030000  Loss: 0.7039  Acc@1: 62.5000 (53.0714)  Acc@5: 87.5000 (88.7419)  time: 0.3432  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [4030/4579]  eta: 0:03:09  Lr: 0.030000  Loss: 0.4084  Acc@1: 56.2500 (53.0762)  Acc@5: 93.7500 (88.7481)  time: 0.3432  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [4040/4579]  eta: 0:03:05  Lr: 0.030000  Loss: 0.4207  Acc@1: 56.2500 (53.0871)  Acc@5: 93.7500 (88.7621)  time: 0.3435  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [4050/4579]  eta: 0:03:02  Lr: 0.030000  Loss: 0.2701  Acc@1: 56.2500 (53.0903)  Acc@5: 93.7500 (88.7713)  time: 0.3439  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [4060/4579]  eta: 0:02:58  Lr: 0.030000  Loss: 0.3323  Acc@1: 56.2500 (53.1135)  Acc@5: 93.7500 (88.7851)  time: 0.3437  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [4070/4579]  eta: 0:02:55  Lr: 0.030000  Loss: 0.2774  Acc@1: 62.5000 (53.1334)  Acc@5: 93.7500 (88.7911)  time: 0.3438  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [4080/4579]  eta: 0:02:51  Lr: 0.030000  Loss: 0.0365  Acc@1: 56.2500 (53.1350)  Acc@5: 93.7500 (88.7941)  time: 0.3443  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [4090/4579]  eta: 0:02:48  Lr: 0.030000  Loss: 0.2617  Acc@1: 56.2500 (53.1426)  Acc@5: 87.5000 (88.7955)  time: 0.3444  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [4100/4579]  eta: 0:02:45  Lr: 0.030000  Loss: 0.5104  Acc@1: 56.2500 (53.1441)  Acc@5: 87.5000 (88.7954)  time: 0.3443  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [4110/4579]  eta: 0:02:41  Lr: 0.030000  Loss: 0.4052  Acc@1: 50.0000 (53.1455)  Acc@5: 87.5000 (88.7983)  time: 0.3450  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [4120/4579]  eta: 0:02:38  Lr: 0.030000  Loss: 0.0450  Acc@1: 50.0000 (53.1500)  Acc@5: 93.7500 (88.8104)  time: 0.3440  data: 0.0002  max mem: 2500
Train: Epoch[2/5]  [4130/4579]  eta: 0:02:34  Lr: 0.030000  Loss: 0.3330  Acc@1: 50.0000 (53.1530)  Acc@5: 93.7500 (88.8193)  time: 0.3422  data: 0.0002  max mem: 2500
Train: Epoch[2/5]  [4140/4579]  eta: 0:02:31  Lr: 0.030000  Loss: 0.0061  Acc@1: 56.2500 (53.1725)  Acc@5: 93.7500 (88.8252)  time: 0.3424  data: 0.0002  max mem: 2500
Train: Epoch[2/5]  [4150/4579]  eta: 0:02:27  Lr: 0.030000  Loss: -0.0165  Acc@1: 62.5000 (53.1815)  Acc@5: 93.7500 (88.8325)  time: 0.3426  data: 0.0002  max mem: 2500
Train: Epoch[2/5]  [4160/4579]  eta: 0:02:24  Lr: 0.030000  Loss: 0.0897  Acc@1: 56.2500 (53.1918)  Acc@5: 93.7500 (88.8428)  time: 0.3424  data: 0.0002  max mem: 2500
Train: Epoch[2/5]  [4170/4579]  eta: 0:02:20  Lr: 0.030000  Loss: 0.1765  Acc@1: 56.2500 (53.1902)  Acc@5: 87.5000 (88.8396)  time: 0.3424  data: 0.0002  max mem: 2500
Train: Epoch[2/5]  [4180/4579]  eta: 0:02:17  Lr: 0.030000  Loss: 0.2096  Acc@1: 50.0000 (53.2065)  Acc@5: 87.5000 (88.8439)  time: 0.3424  data: 0.0002  max mem: 2500
Train: Epoch[2/5]  [4190/4579]  eta: 0:02:14  Lr: 0.030000  Loss: 0.2432  Acc@1: 56.2500 (53.2078)  Acc@5: 87.5000 (88.8407)  time: 0.3423  data: 0.0002  max mem: 2500
Train: Epoch[2/5]  [4200/4579]  eta: 0:02:10  Lr: 0.030000  Loss: 0.4172  Acc@1: 50.0000 (53.2016)  Acc@5: 87.5000 (88.8330)  time: 0.3427  data: 0.0002  max mem: 2500
Train: Epoch[2/5]  [4210/4579]  eta: 0:02:07  Lr: 0.030000  Loss: 0.5400  Acc@1: 56.2500 (53.2000)  Acc@5: 87.5000 (88.8224)  time: 0.3439  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [4220/4579]  eta: 0:02:03  Lr: 0.030000  Loss: 0.2630  Acc@1: 56.2500 (53.2072)  Acc@5: 87.5000 (88.8208)  time: 0.3448  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [4230/4579]  eta: 0:02:00  Lr: 0.030000  Loss: 0.4334  Acc@1: 56.2500 (53.2188)  Acc@5: 87.5000 (88.8236)  time: 0.3449  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [4240/4579]  eta: 0:01:56  Lr: 0.030000  Loss: 0.1405  Acc@1: 62.5000 (53.2304)  Acc@5: 87.5000 (88.8234)  time: 0.3451  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [4250/4579]  eta: 0:01:53  Lr: 0.030000  Loss: 0.4812  Acc@1: 50.0000 (53.2198)  Acc@5: 87.5000 (88.8217)  time: 0.3451  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [4260/4579]  eta: 0:01:49  Lr: 0.030000  Loss: 0.3360  Acc@1: 50.0000 (53.2167)  Acc@5: 87.5000 (88.8245)  time: 0.3447  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [4270/4579]  eta: 0:01:46  Lr: 0.030000  Loss: 0.2972  Acc@1: 56.2500 (53.2238)  Acc@5: 87.5000 (88.8302)  time: 0.3445  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [4280/4579]  eta: 0:01:43  Lr: 0.030000  Loss: 0.2395  Acc@1: 62.5000 (53.2352)  Acc@5: 87.5000 (88.8285)  time: 0.3453  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [4290/4579]  eta: 0:01:39  Lr: 0.030000  Loss: -0.1151  Acc@1: 62.5000 (53.2524)  Acc@5: 87.5000 (88.8284)  time: 0.3454  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [4300/4579]  eta: 0:01:36  Lr: 0.030000  Loss: 0.1468  Acc@1: 56.2500 (53.2609)  Acc@5: 87.5000 (88.8296)  time: 0.3453  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [4310/4579]  eta: 0:01:32  Lr: 0.030000  Loss: -0.0213  Acc@1: 50.0000 (53.2606)  Acc@5: 87.5000 (88.8251)  time: 0.3453  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [4320/4579]  eta: 0:01:29  Lr: 0.030000  Loss: -0.0557  Acc@1: 50.0000 (53.2675)  Acc@5: 87.5000 (88.8249)  time: 0.3451  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [4330/4579]  eta: 0:01:25  Lr: 0.030000  Loss: 0.2538  Acc@1: 56.2500 (53.2758)  Acc@5: 87.5000 (88.8219)  time: 0.3452  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [4340/4579]  eta: 0:01:22  Lr: 0.030000  Loss: 0.1454  Acc@1: 62.5000 (53.2913)  Acc@5: 87.5000 (88.8231)  time: 0.3450  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [4350/4579]  eta: 0:01:18  Lr: 0.030000  Loss: 0.1614  Acc@1: 62.5000 (53.3067)  Acc@5: 87.5000 (88.8215)  time: 0.3456  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [4360/4579]  eta: 0:01:15  Lr: 0.030000  Loss: 0.4032  Acc@1: 56.2500 (53.3092)  Acc@5: 87.5000 (88.8142)  time: 0.3468  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [4370/4579]  eta: 0:01:12  Lr: 0.030000  Loss: 0.6232  Acc@1: 56.2500 (53.3288)  Acc@5: 87.5000 (88.8126)  time: 0.3462  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [4380/4579]  eta: 0:01:08  Lr: 0.030000  Loss: 0.3736  Acc@1: 56.2500 (53.3297)  Acc@5: 93.7500 (88.8225)  time: 0.3447  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [4390/4579]  eta: 0:01:05  Lr: 0.030000  Loss: 0.5949  Acc@1: 50.0000 (53.3236)  Acc@5: 93.7500 (88.8252)  time: 0.3446  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [4400/4579]  eta: 0:01:01  Lr: 0.030000  Loss: 0.1519  Acc@1: 50.0000 (53.3359)  Acc@5: 87.5000 (88.8292)  time: 0.3450  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [4410/4579]  eta: 0:00:58  Lr: 0.030000  Loss: 0.0806  Acc@1: 62.5000 (53.3496)  Acc@5: 87.5000 (88.8319)  time: 0.3458  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [4420/4579]  eta: 0:00:54  Lr: 0.030000  Loss: -0.1444  Acc@1: 56.2500 (53.3675)  Acc@5: 87.5000 (88.8430)  time: 0.3457  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [4430/4579]  eta: 0:00:51  Lr: 0.030000  Loss: 0.4283  Acc@1: 62.5000 (53.3810)  Acc@5: 93.7500 (88.8456)  time: 0.3451  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [4440/4579]  eta: 0:00:47  Lr: 0.030000  Loss: -0.1010  Acc@1: 56.2500 (53.3832)  Acc@5: 93.7500 (88.8510)  time: 0.3455  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [4450/4579]  eta: 0:00:44  Lr: 0.030000  Loss: 0.0661  Acc@1: 56.2500 (53.3841)  Acc@5: 87.5000 (88.8522)  time: 0.3449  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [4460/4579]  eta: 0:00:41  Lr: 0.030000  Loss: 0.2287  Acc@1: 62.5000 (53.4143)  Acc@5: 93.7500 (88.8632)  time: 0.3436  data: 0.0002  max mem: 2500
Train: Epoch[2/5]  [4470/4579]  eta: 0:00:37  Lr: 0.030000  Loss: 0.1734  Acc@1: 56.2500 (53.4109)  Acc@5: 93.7500 (88.8727)  time: 0.3433  data: 0.0002  max mem: 2500
Train: Epoch[2/5]  [4480/4579]  eta: 0:00:34  Lr: 0.030000  Loss: 0.2536  Acc@1: 56.2500 (53.4214)  Acc@5: 93.7500 (88.8794)  time: 0.3431  data: 0.0002  max mem: 2500
Train: Epoch[2/5]  [4490/4579]  eta: 0:00:30  Lr: 0.030000  Loss: 0.2884  Acc@1: 62.5000 (53.4374)  Acc@5: 93.7500 (88.8750)  time: 0.3429  data: 0.0002  max mem: 2500
Train: Epoch[2/5]  [4500/4579]  eta: 0:00:27  Lr: 0.030000  Loss: 0.1436  Acc@1: 62.5000 (53.4451)  Acc@5: 87.5000 (88.8705)  time: 0.3428  data: 0.0002  max mem: 2500
Train: Epoch[2/5]  [4510/4579]  eta: 0:00:23  Lr: 0.030000  Loss: 0.2886  Acc@1: 56.2500 (53.4541)  Acc@5: 87.5000 (88.8744)  time: 0.3427  data: 0.0002  max mem: 2500
Train: Epoch[2/5]  [4520/4579]  eta: 0:00:20  Lr: 0.030000  Loss: 0.3994  Acc@1: 62.5000 (53.4630)  Acc@5: 87.5000 (88.8741)  time: 0.3429  data: 0.0002  max mem: 2500
Train: Epoch[2/5]  [4530/4579]  eta: 0:00:16  Lr: 0.030000  Loss: 0.1243  Acc@1: 62.5000 (53.4774)  Acc@5: 87.5000 (88.8752)  time: 0.3432  data: 0.0002  max mem: 2500
Train: Epoch[2/5]  [4540/4579]  eta: 0:00:13  Lr: 0.030000  Loss: 0.2733  Acc@1: 68.7500 (53.4918)  Acc@5: 87.5000 (88.8763)  time: 0.3440  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [4550/4579]  eta: 0:00:09  Lr: 0.030000  Loss: 0.2470  Acc@1: 62.5000 (53.5116)  Acc@5: 87.5000 (88.8774)  time: 0.3447  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [4560/4579]  eta: 0:00:06  Lr: 0.030000  Loss: 0.6014  Acc@1: 56.2500 (53.5176)  Acc@5: 87.5000 (88.8785)  time: 0.3450  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [4570/4579]  eta: 0:00:03  Lr: 0.030000  Loss: -0.0026  Acc@1: 56.2500 (53.5277)  Acc@5: 87.5000 (88.8755)  time: 0.3456  data: 0.0009  max mem: 2500
Train: Epoch[2/5]  [4578/4579]  eta: 0:00:00  Lr: 0.030000  Loss: 0.3009  Acc@1: 56.2500 (53.5335)  Acc@5: 87.5000 (88.8802)  time: 0.3380  data: 0.0008  max mem: 2500
Train: Epoch[2/5] Total time: 0:26:18 (0.3447 s / it)
{0: {0: 146514, 1: 0, 2: 0, 3: 0, 4: 0}, 1: {0: 146514, 1: 0, 2: 0, 3: 0, 4: 0}, 2: {0: 146514, 1: 0, 2: 0, 3: 0, 4: 0}, 3: {0: 146514, 1: 0, 2: 0, 3: 0, 4: 0}, 4: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 5: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 6: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 7: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 8: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 9: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 10: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 11: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 12: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 13: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 14: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 15: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 16: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 17: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 18: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 19: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}}
Averaged stats: Lr: 0.030000  Loss: 0.3009  Acc@1: 56.2500 (53.5335)  Acc@5: 87.5000 (88.8802)
Train: Epoch[3/5]  [   0/4579]  eta: 0:49:26  Lr: 0.030000  Loss: 0.5829  Acc@1: 43.7500 (43.7500)  Acc@5: 75.0000 (75.0000)  time: 0.6479  data: 0.3018  max mem: 2500
Train: Epoch[3/5]  [  10/4579]  eta: 0:28:20  Lr: 0.030000  Loss: -0.0031  Acc@1: 62.5000 (58.5227)  Acc@5: 93.7500 (89.7727)  time: 0.3723  data: 0.0279  max mem: 2500
Train: Epoch[3/5]  [  20/4579]  eta: 0:27:14  Lr: 0.030000  Loss: 0.3044  Acc@1: 62.5000 (57.4405)  Acc@5: 87.5000 (88.3929)  time: 0.3442  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [  30/4579]  eta: 0:26:49  Lr: 0.030000  Loss: 0.6287  Acc@1: 62.5000 (58.6694)  Acc@5: 87.5000 (88.7097)  time: 0.3438  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [  40/4579]  eta: 0:26:34  Lr: 0.030000  Loss: -0.0191  Acc@1: 56.2500 (59.2988)  Acc@5: 93.7500 (89.6341)  time: 0.3438  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [  50/4579]  eta: 0:26:24  Lr: 0.030000  Loss: 0.3789  Acc@1: 50.0000 (56.8627)  Acc@5: 93.7500 (88.9706)  time: 0.3434  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [  60/4579]  eta: 0:26:17  Lr: 0.030000  Loss: 0.3543  Acc@1: 50.0000 (57.1721)  Acc@5: 93.7500 (89.5492)  time: 0.3445  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [  70/4579]  eta: 0:26:10  Lr: 0.030000  Loss: 0.4353  Acc@1: 50.0000 (55.7218)  Acc@5: 93.7500 (88.8204)  time: 0.3446  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [  80/4579]  eta: 0:26:04  Lr: 0.030000  Loss: -0.0083  Acc@1: 50.0000 (56.2500)  Acc@5: 87.5000 (89.0432)  time: 0.3434  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [  90/4579]  eta: 0:25:59  Lr: 0.030000  Loss: 0.1077  Acc@1: 56.2500 (56.4560)  Acc@5: 87.5000 (89.2170)  time: 0.3444  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 100/4579]  eta: 0:25:54  Lr: 0.030000  Loss: 0.1419  Acc@1: 56.2500 (56.6832)  Acc@5: 87.5000 (89.1708)  time: 0.3447  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [ 110/4579]  eta: 0:25:50  Lr: 0.030000  Loss: 0.1203  Acc@1: 62.5000 (56.7568)  Acc@5: 93.7500 (89.4144)  time: 0.3439  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 120/4579]  eta: 0:25:45  Lr: 0.030000  Loss: 0.1774  Acc@1: 62.5000 (57.3864)  Acc@5: 93.7500 (89.7727)  time: 0.3446  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 130/4579]  eta: 0:25:42  Lr: 0.030000  Loss: 0.1376  Acc@1: 56.2500 (57.0134)  Acc@5: 93.7500 (89.8855)  time: 0.3455  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 140/4579]  eta: 0:25:37  Lr: 0.030000  Loss: 0.1940  Acc@1: 62.5000 (57.5355)  Acc@5: 93.7500 (90.0709)  time: 0.3451  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 150/4579]  eta: 0:25:33  Lr: 0.030000  Loss: 0.2499  Acc@1: 62.5000 (57.4089)  Acc@5: 93.7500 (90.1904)  time: 0.3441  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [ 160/4579]  eta: 0:25:29  Lr: 0.030000  Loss: 0.3680  Acc@1: 56.2500 (57.3758)  Acc@5: 93.7500 (90.2562)  time: 0.3441  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [ 170/4579]  eta: 0:25:25  Lr: 0.030000  Loss: 0.3970  Acc@1: 56.2500 (57.2368)  Acc@5: 87.5000 (90.0219)  time: 0.3442  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [ 180/4579]  eta: 0:25:21  Lr: 0.030000  Loss: -0.0475  Acc@1: 56.2500 (57.3895)  Acc@5: 87.5000 (90.1243)  time: 0.3442  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [ 190/4579]  eta: 0:25:18  Lr: 0.030000  Loss: 0.3794  Acc@1: 56.2500 (57.2644)  Acc@5: 87.5000 (89.8560)  time: 0.3444  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [ 200/4579]  eta: 0:25:14  Lr: 0.030000  Loss: -0.0322  Acc@1: 56.2500 (57.3383)  Acc@5: 93.7500 (90.1119)  time: 0.3442  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [ 210/4579]  eta: 0:25:10  Lr: 0.030000  Loss: 0.1951  Acc@1: 56.2500 (57.3756)  Acc@5: 93.7500 (90.1066)  time: 0.3448  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [ 220/4579]  eta: 0:25:06  Lr: 0.030000  Loss: 0.3152  Acc@1: 56.2500 (57.3529)  Acc@5: 87.5000 (90.0170)  time: 0.3439  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [ 230/4579]  eta: 0:25:02  Lr: 0.030000  Loss: 0.1333  Acc@1: 56.2500 (57.1970)  Acc@5: 87.5000 (90.0974)  time: 0.3428  data: 0.0002  max mem: 2500
Train: Epoch[3/5]  [ 240/4579]  eta: 0:24:58  Lr: 0.030000  Loss: 0.1923  Acc@1: 62.5000 (57.6245)  Acc@5: 93.7500 (90.0934)  time: 0.3428  data: 0.0002  max mem: 2500
Train: Epoch[3/5]  [ 250/4579]  eta: 0:24:54  Lr: 0.030000  Loss: 0.3712  Acc@1: 50.0000 (57.2958)  Acc@5: 93.7500 (90.0398)  time: 0.3425  data: 0.0002  max mem: 2500
Train: Epoch[3/5]  [ 260/4579]  eta: 0:24:50  Lr: 0.030000  Loss: -0.1111  Acc@1: 50.0000 (57.4473)  Acc@5: 93.7500 (90.1102)  time: 0.3426  data: 0.0002  max mem: 2500
Train: Epoch[3/5]  [ 270/4579]  eta: 0:24:46  Lr: 0.030000  Loss: 0.4143  Acc@1: 62.5000 (57.5646)  Acc@5: 93.7500 (90.1522)  time: 0.3426  data: 0.0002  max mem: 2500
Train: Epoch[3/5]  [ 280/4579]  eta: 0:24:42  Lr: 0.030000  Loss: 0.1706  Acc@1: 56.2500 (57.4511)  Acc@5: 93.7500 (90.1468)  time: 0.3423  data: 0.0002  max mem: 2500
Train: Epoch[3/5]  [ 290/4579]  eta: 0:24:39  Lr: 0.030000  Loss: 0.0977  Acc@1: 56.2500 (57.5172)  Acc@5: 93.7500 (90.2706)  time: 0.3423  data: 0.0002  max mem: 2500
Train: Epoch[3/5]  [ 300/4579]  eta: 0:24:35  Lr: 0.030000  Loss: 0.1910  Acc@1: 62.5000 (57.6204)  Acc@5: 93.7500 (90.2201)  time: 0.3427  data: 0.0002  max mem: 2500
Train: Epoch[3/5]  [ 310/4579]  eta: 0:24:31  Lr: 0.030000  Loss: 0.3541  Acc@1: 62.5000 (57.6166)  Acc@5: 87.5000 (90.1728)  time: 0.3437  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [ 320/4579]  eta: 0:24:28  Lr: 0.030000  Loss: 0.4440  Acc@1: 56.2500 (57.5740)  Acc@5: 87.5000 (90.1869)  time: 0.3446  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 330/4579]  eta: 0:24:25  Lr: 0.030000  Loss: 0.5278  Acc@1: 56.2500 (57.6850)  Acc@5: 87.5000 (90.1624)  time: 0.3446  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 340/4579]  eta: 0:24:21  Lr: 0.030000  Loss: 0.3683  Acc@1: 56.2500 (57.5330)  Acc@5: 93.7500 (90.1210)  time: 0.3446  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 350/4579]  eta: 0:24:18  Lr: 0.030000  Loss: 0.3517  Acc@1: 50.0000 (57.3184)  Acc@5: 87.5000 (89.9929)  time: 0.3452  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 360/4579]  eta: 0:24:14  Lr: 0.030000  Loss: 0.3551  Acc@1: 50.0000 (57.2542)  Acc@5: 87.5000 (90.0796)  time: 0.3445  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 370/4579]  eta: 0:24:11  Lr: 0.030000  Loss: 0.1612  Acc@1: 56.2500 (57.2776)  Acc@5: 87.5000 (89.9933)  time: 0.3443  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 380/4579]  eta: 0:24:07  Lr: 0.030000  Loss: 0.3922  Acc@1: 56.2500 (57.2835)  Acc@5: 87.5000 (89.9770)  time: 0.3459  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 390/4579]  eta: 0:24:04  Lr: 0.030000  Loss: 0.0039  Acc@1: 56.2500 (57.3689)  Acc@5: 93.7500 (90.0256)  time: 0.3452  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 400/4579]  eta: 0:24:01  Lr: 0.030000  Loss: 0.5928  Acc@1: 56.2500 (57.3099)  Acc@5: 93.7500 (90.0249)  time: 0.3453  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 410/4579]  eta: 0:23:57  Lr: 0.030000  Loss: 0.2086  Acc@1: 56.2500 (57.4057)  Acc@5: 93.7500 (89.9939)  time: 0.3452  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 420/4579]  eta: 0:23:54  Lr: 0.030000  Loss: 0.3721  Acc@1: 56.2500 (57.3337)  Acc@5: 93.7500 (89.9941)  time: 0.3442  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [ 430/4579]  eta: 0:23:50  Lr: 0.030000  Loss: 0.1453  Acc@1: 56.2500 (57.2796)  Acc@5: 93.7500 (90.0667)  time: 0.3451  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 440/4579]  eta: 0:23:47  Lr: 0.030000  Loss: 0.2228  Acc@1: 56.2500 (57.1429)  Acc@5: 93.7500 (90.0794)  time: 0.3459  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [ 450/4579]  eta: 0:23:44  Lr: 0.030000  Loss: 0.2746  Acc@1: 56.2500 (57.1508)  Acc@5: 93.7500 (90.0915)  time: 0.3461  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [ 460/4579]  eta: 0:23:40  Lr: 0.030000  Loss: 0.3785  Acc@1: 56.2500 (57.0363)  Acc@5: 93.7500 (90.1302)  time: 0.3452  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 470/4579]  eta: 0:23:37  Lr: 0.030000  Loss: 0.2518  Acc@1: 56.2500 (57.1125)  Acc@5: 93.7500 (90.1407)  time: 0.3444  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 480/4579]  eta: 0:23:33  Lr: 0.030000  Loss: 0.1492  Acc@1: 56.2500 (57.2245)  Acc@5: 93.7500 (90.1767)  time: 0.3451  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 490/4579]  eta: 0:23:30  Lr: 0.030000  Loss: 0.6135  Acc@1: 56.2500 (57.2047)  Acc@5: 93.7500 (90.1986)  time: 0.3449  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 500/4579]  eta: 0:23:26  Lr: 0.030000  Loss: 0.3050  Acc@1: 56.2500 (57.2355)  Acc@5: 93.7500 (90.2196)  time: 0.3441  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [ 510/4579]  eta: 0:23:23  Lr: 0.030000  Loss: 0.4014  Acc@1: 56.2500 (57.3141)  Acc@5: 93.7500 (90.2886)  time: 0.3443  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [ 520/4579]  eta: 0:23:19  Lr: 0.030000  Loss: 0.4100  Acc@1: 56.2500 (57.2937)  Acc@5: 93.7500 (90.2591)  time: 0.3446  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [ 530/4579]  eta: 0:23:16  Lr: 0.030000  Loss: 0.0456  Acc@1: 56.2500 (57.3799)  Acc@5: 87.5000 (90.2542)  time: 0.3444  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [ 540/4579]  eta: 0:23:12  Lr: 0.030000  Loss: 0.3645  Acc@1: 62.5000 (57.4168)  Acc@5: 87.5000 (90.2957)  time: 0.3442  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [ 550/4579]  eta: 0:23:09  Lr: 0.030000  Loss: 0.2369  Acc@1: 56.2500 (57.3503)  Acc@5: 93.7500 (90.3244)  time: 0.3442  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [ 560/4579]  eta: 0:23:05  Lr: 0.030000  Loss: -0.0190  Acc@1: 50.0000 (57.3195)  Acc@5: 93.7500 (90.3075)  time: 0.3441  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [ 570/4579]  eta: 0:23:02  Lr: 0.030000  Loss: -0.1353  Acc@1: 56.2500 (57.3665)  Acc@5: 93.7500 (90.3787)  time: 0.3436  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [ 580/4579]  eta: 0:22:58  Lr: 0.030000  Loss: 0.1469  Acc@1: 56.2500 (57.3365)  Acc@5: 93.7500 (90.3722)  time: 0.3432  data: 0.0002  max mem: 2500
Train: Epoch[3/5]  [ 590/4579]  eta: 0:22:55  Lr: 0.030000  Loss: 0.1108  Acc@1: 56.2500 (57.3075)  Acc@5: 87.5000 (90.3342)  time: 0.3432  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [ 600/4579]  eta: 0:22:51  Lr: 0.030000  Loss: 0.6724  Acc@1: 56.2500 (57.2587)  Acc@5: 87.5000 (90.2870)  time: 0.3434  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [ 610/4579]  eta: 0:22:48  Lr: 0.030000  Loss: 0.2675  Acc@1: 56.2500 (57.3036)  Acc@5: 87.5000 (90.2721)  time: 0.3435  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [ 620/4579]  eta: 0:22:44  Lr: 0.030000  Loss: 0.5107  Acc@1: 56.2500 (57.1961)  Acc@5: 87.5000 (90.2275)  time: 0.3441  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 630/4579]  eta: 0:22:41  Lr: 0.030000  Loss: 0.4293  Acc@1: 50.0000 (57.1910)  Acc@5: 93.7500 (90.3031)  time: 0.3442  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 640/4579]  eta: 0:22:37  Lr: 0.030000  Loss: 0.0657  Acc@1: 62.5000 (57.2348)  Acc@5: 93.7500 (90.2594)  time: 0.3457  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 650/4579]  eta: 0:22:34  Lr: 0.030000  Loss: 0.0825  Acc@1: 62.5000 (57.2581)  Acc@5: 87.5000 (90.1786)  time: 0.3461  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 660/4579]  eta: 0:22:31  Lr: 0.030000  Loss: 0.0707  Acc@1: 56.2500 (57.2901)  Acc@5: 87.5000 (90.1664)  time: 0.3455  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 670/4579]  eta: 0:22:27  Lr: 0.030000  Loss: 0.4015  Acc@1: 56.2500 (57.2932)  Acc@5: 87.5000 (90.1732)  time: 0.3455  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [ 680/4579]  eta: 0:22:24  Lr: 0.030000  Loss: 0.1813  Acc@1: 56.2500 (57.3513)  Acc@5: 87.5000 (90.1707)  time: 0.3445  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [ 690/4579]  eta: 0:22:20  Lr: 0.030000  Loss: 0.1982  Acc@1: 56.2500 (57.3354)  Acc@5: 93.7500 (90.1863)  time: 0.3444  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [ 700/4579]  eta: 0:22:17  Lr: 0.030000  Loss: 0.2160  Acc@1: 62.5000 (57.3288)  Acc@5: 93.7500 (90.2015)  time: 0.3442  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [ 710/4579]  eta: 0:22:13  Lr: 0.030000  Loss: 0.3079  Acc@1: 56.2500 (57.3400)  Acc@5: 93.7500 (90.2075)  time: 0.3443  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [ 720/4579]  eta: 0:22:10  Lr: 0.030000  Loss: 0.2091  Acc@1: 56.2500 (57.3249)  Acc@5: 93.7500 (90.2566)  time: 0.3440  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [ 730/4579]  eta: 0:22:06  Lr: 0.030000  Loss: 0.3693  Acc@1: 56.2500 (57.2418)  Acc@5: 93.7500 (90.2445)  time: 0.3436  data: 0.0002  max mem: 2500
Train: Epoch[3/5]  [ 740/4579]  eta: 0:22:03  Lr: 0.030000  Loss: 0.0319  Acc@1: 56.2500 (57.2874)  Acc@5: 93.7500 (90.3171)  time: 0.3437  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [ 750/4579]  eta: 0:21:59  Lr: 0.030000  Loss: 0.4478  Acc@1: 62.5000 (57.2903)  Acc@5: 93.7500 (90.3462)  time: 0.3446  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [ 760/4579]  eta: 0:21:56  Lr: 0.030000  Loss: 0.2721  Acc@1: 56.2500 (57.2602)  Acc@5: 93.7500 (90.3334)  time: 0.3455  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 770/4579]  eta: 0:21:53  Lr: 0.030000  Loss: 0.1677  Acc@1: 56.2500 (57.2552)  Acc@5: 93.7500 (90.3696)  time: 0.3466  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [ 780/4579]  eta: 0:21:49  Lr: 0.030000  Loss: 0.2472  Acc@1: 56.2500 (57.3063)  Acc@5: 93.7500 (90.4049)  time: 0.3462  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [ 790/4579]  eta: 0:21:46  Lr: 0.030000  Loss: 0.2916  Acc@1: 62.5000 (57.3641)  Acc@5: 93.7500 (90.4156)  time: 0.3450  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 800/4579]  eta: 0:21:42  Lr: 0.030000  Loss: 0.2105  Acc@1: 62.5000 (57.3814)  Acc@5: 93.7500 (90.4026)  time: 0.3457  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 810/4579]  eta: 0:21:39  Lr: 0.030000  Loss: 0.1474  Acc@1: 56.2500 (57.3983)  Acc@5: 93.7500 (90.4131)  time: 0.3454  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 820/4579]  eta: 0:21:35  Lr: 0.030000  Loss: 0.3806  Acc@1: 56.2500 (57.3995)  Acc@5: 93.7500 (90.4918)  time: 0.3448  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [ 830/4579]  eta: 0:21:32  Lr: 0.030000  Loss: 0.4699  Acc@1: 56.2500 (57.3706)  Acc@5: 93.7500 (90.5310)  time: 0.3449  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [ 840/4579]  eta: 0:21:29  Lr: 0.030000  Loss: 0.3997  Acc@1: 56.2500 (57.3499)  Acc@5: 93.7500 (90.5395)  time: 0.3451  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [ 850/4579]  eta: 0:21:25  Lr: 0.030000  Loss: 0.2256  Acc@1: 62.5000 (57.4398)  Acc@5: 93.7500 (90.5552)  time: 0.3449  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [ 860/4579]  eta: 0:21:22  Lr: 0.030000  Loss: 0.3942  Acc@1: 56.2500 (57.3969)  Acc@5: 93.7500 (90.5923)  time: 0.3451  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [ 870/4579]  eta: 0:21:18  Lr: 0.030000  Loss: 0.2522  Acc@1: 50.0000 (57.3192)  Acc@5: 93.7500 (90.5425)  time: 0.3449  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [ 880/4579]  eta: 0:21:15  Lr: 0.030000  Loss: 0.1037  Acc@1: 50.0000 (57.3283)  Acc@5: 87.5000 (90.5221)  time: 0.3440  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [ 890/4579]  eta: 0:21:11  Lr: 0.030000  Loss: 0.3704  Acc@1: 62.5000 (57.3513)  Acc@5: 87.5000 (90.5233)  time: 0.3440  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [ 900/4579]  eta: 0:21:08  Lr: 0.030000  Loss: 0.1066  Acc@1: 62.5000 (57.4292)  Acc@5: 93.7500 (90.5244)  time: 0.3453  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [ 910/4579]  eta: 0:21:04  Lr: 0.030000  Loss: 0.2226  Acc@1: 62.5000 (57.3957)  Acc@5: 87.5000 (90.5187)  time: 0.3461  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 920/4579]  eta: 0:21:01  Lr: 0.030000  Loss: -0.0790  Acc@1: 56.2500 (57.4647)  Acc@5: 93.7500 (90.5198)  time: 0.3458  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 930/4579]  eta: 0:20:58  Lr: 0.030000  Loss: 0.0948  Acc@1: 62.5000 (57.4450)  Acc@5: 93.7500 (90.5142)  time: 0.3473  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [ 940/4579]  eta: 0:20:54  Lr: 0.030000  Loss: 0.2275  Acc@1: 62.5000 (57.4787)  Acc@5: 93.7500 (90.5221)  time: 0.3485  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [ 950/4579]  eta: 0:20:51  Lr: 0.030000  Loss: 0.2692  Acc@1: 56.2500 (57.4461)  Acc@5: 87.5000 (90.4903)  time: 0.3482  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [ 960/4579]  eta: 0:20:48  Lr: 0.030000  Loss: 0.5065  Acc@1: 50.0000 (57.4142)  Acc@5: 87.5000 (90.5047)  time: 0.3473  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 970/4579]  eta: 0:20:44  Lr: 0.030000  Loss: 0.4675  Acc@1: 56.2500 (57.4279)  Acc@5: 93.7500 (90.5381)  time: 0.3461  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [ 980/4579]  eta: 0:20:41  Lr: 0.030000  Loss: 0.2826  Acc@1: 56.2500 (57.3904)  Acc@5: 93.7500 (90.5262)  time: 0.3460  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [ 990/4579]  eta: 0:20:38  Lr: 0.030000  Loss: 0.2058  Acc@1: 56.2500 (57.3978)  Acc@5: 87.5000 (90.5146)  time: 0.3460  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [1000/4579]  eta: 0:20:34  Lr: 0.030000  Loss: 0.2173  Acc@1: 56.2500 (57.3489)  Acc@5: 87.5000 (90.4908)  time: 0.3458  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [1010/4579]  eta: 0:20:31  Lr: 0.030000  Loss: 0.2566  Acc@1: 50.0000 (57.3133)  Acc@5: 87.5000 (90.4674)  time: 0.3457  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [1020/4579]  eta: 0:20:27  Lr: 0.030000  Loss: 0.3335  Acc@1: 50.0000 (57.2723)  Acc@5: 87.5000 (90.4995)  time: 0.3457  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [1030/4579]  eta: 0:20:24  Lr: 0.030000  Loss: -0.0916  Acc@1: 50.0000 (57.2866)  Acc@5: 93.7500 (90.4886)  time: 0.3449  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [1040/4579]  eta: 0:20:20  Lr: 0.030000  Loss: 0.4697  Acc@1: 62.5000 (57.3187)  Acc@5: 93.7500 (90.5079)  time: 0.3447  data: 0.0002  max mem: 2500
Train: Epoch[3/5]  [1050/4579]  eta: 0:20:17  Lr: 0.030000  Loss: 0.4170  Acc@1: 62.5000 (57.3264)  Acc@5: 93.7500 (90.5328)  time: 0.3451  data: 0.0002  max mem: 2500
Train: Epoch[3/5]  [1060/4579]  eta: 0:20:13  Lr: 0.030000  Loss: 0.2000  Acc@1: 62.5000 (57.3692)  Acc@5: 93.7500 (90.5337)  time: 0.3449  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [1070/4579]  eta: 0:20:10  Lr: 0.030000  Loss: 0.4839  Acc@1: 62.5000 (57.3996)  Acc@5: 93.7500 (90.5696)  time: 0.3446  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [1080/4579]  eta: 0:20:06  Lr: 0.030000  Loss: 0.2952  Acc@1: 56.2500 (57.3774)  Acc@5: 93.7500 (90.5759)  time: 0.3439  data: 0.0002  max mem: 2500
Train: Epoch[3/5]  [1090/4579]  eta: 0:20:03  Lr: 0.030000  Loss: -0.1840  Acc@1: 62.5000 (57.4301)  Acc@5: 93.7500 (90.5706)  time: 0.3450  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [1100/4579]  eta: 0:20:00  Lr: 0.030000  Loss: 0.2508  Acc@1: 62.5000 (57.4648)  Acc@5: 93.7500 (90.5881)  time: 0.3472  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1110/4579]  eta: 0:19:56  Lr: 0.030000  Loss: 0.4146  Acc@1: 56.2500 (57.4482)  Acc@5: 93.7500 (90.5772)  time: 0.3468  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1120/4579]  eta: 0:19:53  Lr: 0.030000  Loss: 0.1552  Acc@1: 50.0000 (57.4208)  Acc@5: 87.5000 (90.5497)  time: 0.3456  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [1130/4579]  eta: 0:19:49  Lr: 0.030000  Loss: 0.0278  Acc@1: 56.2500 (57.4326)  Acc@5: 87.5000 (90.5836)  time: 0.3457  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [1140/4579]  eta: 0:19:46  Lr: 0.030000  Loss: -0.1158  Acc@1: 62.5000 (57.5208)  Acc@5: 100.0000 (90.6387)  time: 0.3457  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1150/4579]  eta: 0:19:43  Lr: 0.030000  Loss: 0.0311  Acc@1: 56.2500 (57.4989)  Acc@5: 93.7500 (90.6440)  time: 0.3463  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1160/4579]  eta: 0:19:39  Lr: 0.030000  Loss: 0.2623  Acc@1: 56.2500 (57.5151)  Acc@5: 93.7500 (90.6869)  time: 0.3469  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1170/4579]  eta: 0:19:36  Lr: 0.030000  Loss: 0.0988  Acc@1: 56.2500 (57.5149)  Acc@5: 93.7500 (90.6597)  time: 0.3465  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1180/4579]  eta: 0:19:32  Lr: 0.030000  Loss: 0.0288  Acc@1: 56.2500 (57.5677)  Acc@5: 87.5000 (90.6541)  time: 0.3457  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1190/4579]  eta: 0:19:29  Lr: 0.030000  Loss: 0.1731  Acc@1: 62.5000 (57.5777)  Acc@5: 93.7500 (90.6539)  time: 0.3447  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1200/4579]  eta: 0:19:25  Lr: 0.030000  Loss: 0.2260  Acc@1: 62.5000 (57.5926)  Acc@5: 93.7500 (90.6536)  time: 0.3446  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1210/4579]  eta: 0:19:22  Lr: 0.030000  Loss: 0.0042  Acc@1: 56.2500 (57.5970)  Acc@5: 93.7500 (90.6585)  time: 0.3455  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1220/4579]  eta: 0:19:19  Lr: 0.030000  Loss: 0.5798  Acc@1: 56.2500 (57.5706)  Acc@5: 93.7500 (90.6378)  time: 0.3457  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1230/4579]  eta: 0:19:15  Lr: 0.030000  Loss: 0.1759  Acc@1: 62.5000 (57.6158)  Acc@5: 93.7500 (90.6428)  time: 0.3493  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1240/4579]  eta: 0:19:12  Lr: 0.030000  Loss: 0.0239  Acc@1: 68.7500 (57.6702)  Acc@5: 93.7500 (90.6376)  time: 0.3488  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1250/4579]  eta: 0:19:08  Lr: 0.030000  Loss: 0.1495  Acc@1: 62.5000 (57.6689)  Acc@5: 87.5000 (90.6275)  time: 0.3449  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [1260/4579]  eta: 0:19:05  Lr: 0.030000  Loss: 0.4646  Acc@1: 56.2500 (57.6031)  Acc@5: 93.7500 (90.6374)  time: 0.3449  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [1270/4579]  eta: 0:19:01  Lr: 0.030000  Loss: 0.2671  Acc@1: 56.2500 (57.5777)  Acc@5: 93.7500 (90.6225)  time: 0.3450  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [1280/4579]  eta: 0:18:58  Lr: 0.030000  Loss: 0.1111  Acc@1: 56.2500 (57.6161)  Acc@5: 87.5000 (90.6226)  time: 0.3446  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [1290/4579]  eta: 0:18:55  Lr: 0.030000  Loss: 0.3231  Acc@1: 62.5000 (57.6782)  Acc@5: 87.5000 (90.6032)  time: 0.3444  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [1300/4579]  eta: 0:18:51  Lr: 0.030000  Loss: 0.4816  Acc@1: 62.5000 (57.6672)  Acc@5: 87.5000 (90.5842)  time: 0.3445  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1310/4579]  eta: 0:18:48  Lr: 0.030000  Loss: 0.6592  Acc@1: 56.2500 (57.6373)  Acc@5: 87.5000 (90.5797)  time: 0.3451  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [1320/4579]  eta: 0:18:44  Lr: 0.030000  Loss: 0.0961  Acc@1: 50.0000 (57.5795)  Acc@5: 87.5000 (90.5280)  time: 0.3443  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [1330/4579]  eta: 0:18:41  Lr: 0.030000  Loss: 0.1855  Acc@1: 56.2500 (57.6118)  Acc@5: 87.5000 (90.5428)  time: 0.3429  data: 0.0002  max mem: 2500
Train: Epoch[3/5]  [1340/4579]  eta: 0:18:37  Lr: 0.030000  Loss: 0.3100  Acc@1: 62.5000 (57.6016)  Acc@5: 93.7500 (90.5714)  time: 0.3428  data: 0.0002  max mem: 2500
Train: Epoch[3/5]  [1350/4579]  eta: 0:18:34  Lr: 0.030000  Loss: 0.6184  Acc@1: 56.2500 (57.5823)  Acc@5: 93.7500 (90.5903)  time: 0.3424  data: 0.0002  max mem: 2500
Train: Epoch[3/5]  [1360/4579]  eta: 0:18:30  Lr: 0.030000  Loss: 0.3147  Acc@1: 50.0000 (57.5863)  Acc@5: 93.7500 (90.5722)  time: 0.3421  data: 0.0002  max mem: 2500
Train: Epoch[3/5]  [1370/4579]  eta: 0:18:27  Lr: 0.030000  Loss: 0.1505  Acc@1: 62.5000 (57.6404)  Acc@5: 93.7500 (90.5726)  time: 0.3421  data: 0.0002  max mem: 2500
Train: Epoch[3/5]  [1380/4579]  eta: 0:18:23  Lr: 0.030000  Loss: 0.3564  Acc@1: 62.5000 (57.6620)  Acc@5: 93.7500 (90.5820)  time: 0.3421  data: 0.0002  max mem: 2500
Train: Epoch[3/5]  [1390/4579]  eta: 0:18:20  Lr: 0.030000  Loss: 0.5174  Acc@1: 56.2500 (57.6339)  Acc@5: 87.5000 (90.5733)  time: 0.3420  data: 0.0002  max mem: 2500
Train: Epoch[3/5]  [1400/4579]  eta: 0:18:16  Lr: 0.030000  Loss: 0.5083  Acc@1: 50.0000 (57.5928)  Acc@5: 87.5000 (90.5559)  time: 0.3420  data: 0.0002  max mem: 2500
Train: Epoch[3/5]  [1410/4579]  eta: 0:18:13  Lr: 0.030000  Loss: 0.2871  Acc@1: 50.0000 (57.5345)  Acc@5: 93.7500 (90.5563)  time: 0.3434  data: 0.0002  max mem: 2500
Train: Epoch[3/5]  [1420/4579]  eta: 0:18:09  Lr: 0.030000  Loss: 0.4543  Acc@1: 50.0000 (57.5211)  Acc@5: 87.5000 (90.5524)  time: 0.3442  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [1430/4579]  eta: 0:18:06  Lr: 0.030000  Loss: 0.1715  Acc@1: 56.2500 (57.5428)  Acc@5: 87.5000 (90.5486)  time: 0.3448  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1440/4579]  eta: 0:18:02  Lr: 0.030000  Loss: 0.3047  Acc@1: 56.2500 (57.5295)  Acc@5: 93.7500 (90.5664)  time: 0.3456  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [1450/4579]  eta: 0:17:59  Lr: 0.030000  Loss: 0.3026  Acc@1: 56.2500 (57.5465)  Acc@5: 93.7500 (90.5669)  time: 0.3451  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1460/4579]  eta: 0:17:55  Lr: 0.030000  Loss: -0.0250  Acc@1: 50.0000 (57.5291)  Acc@5: 93.7500 (90.5801)  time: 0.3444  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1470/4579]  eta: 0:17:52  Lr: 0.030000  Loss: 0.1230  Acc@1: 62.5000 (57.5671)  Acc@5: 93.7500 (90.5719)  time: 0.3449  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1480/4579]  eta: 0:17:48  Lr: 0.030000  Loss: 0.4458  Acc@1: 56.2500 (57.5836)  Acc@5: 93.7500 (90.5638)  time: 0.3450  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1490/4579]  eta: 0:17:45  Lr: 0.030000  Loss: 0.2382  Acc@1: 56.2500 (57.5914)  Acc@5: 93.7500 (90.5684)  time: 0.3443  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1500/4579]  eta: 0:17:42  Lr: 0.030000  Loss: 0.2870  Acc@1: 56.2500 (57.6074)  Acc@5: 93.7500 (90.5730)  time: 0.3455  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1510/4579]  eta: 0:17:38  Lr: 0.030000  Loss: 0.4318  Acc@1: 56.2500 (57.5736)  Acc@5: 87.5000 (90.5568)  time: 0.3451  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [1520/4579]  eta: 0:17:35  Lr: 0.030000  Loss: -0.1411  Acc@1: 56.2500 (57.6183)  Acc@5: 87.5000 (90.5654)  time: 0.3447  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1530/4579]  eta: 0:17:31  Lr: 0.030000  Loss: 0.3777  Acc@1: 56.2500 (57.6176)  Acc@5: 87.5000 (90.5576)  time: 0.3464  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1540/4579]  eta: 0:17:28  Lr: 0.030000  Loss: 0.2454  Acc@1: 56.2500 (57.6128)  Acc@5: 87.5000 (90.5216)  time: 0.3459  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1550/4579]  eta: 0:17:24  Lr: 0.030000  Loss: 0.0970  Acc@1: 62.5000 (57.6564)  Acc@5: 87.5000 (90.5505)  time: 0.3448  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1560/4579]  eta: 0:17:21  Lr: 0.030000  Loss: 0.0097  Acc@1: 62.5000 (57.6634)  Acc@5: 93.7500 (90.5509)  time: 0.3455  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1570/4579]  eta: 0:17:17  Lr: 0.030000  Loss: 0.4606  Acc@1: 56.2500 (57.6663)  Acc@5: 87.5000 (90.5315)  time: 0.3452  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1580/4579]  eta: 0:17:14  Lr: 0.030000  Loss: 0.4239  Acc@1: 56.2500 (57.6534)  Acc@5: 87.5000 (90.5202)  time: 0.3442  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [1590/4579]  eta: 0:17:10  Lr: 0.030000  Loss: 0.0297  Acc@1: 56.2500 (57.6524)  Acc@5: 87.5000 (90.5248)  time: 0.3444  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [1600/4579]  eta: 0:17:07  Lr: 0.030000  Loss: 0.1086  Acc@1: 56.2500 (57.6359)  Acc@5: 87.5000 (90.5059)  time: 0.3445  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [1610/4579]  eta: 0:17:04  Lr: 0.030000  Loss: 0.2135  Acc@1: 50.0000 (57.5962)  Acc@5: 87.5000 (90.4873)  time: 0.3444  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [1620/4579]  eta: 0:17:00  Lr: 0.030000  Loss: 0.1463  Acc@1: 56.2500 (57.6110)  Acc@5: 93.7500 (90.4958)  time: 0.3442  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [1630/4579]  eta: 0:16:57  Lr: 0.030000  Loss: 0.3169  Acc@1: 56.2500 (57.6142)  Acc@5: 93.7500 (90.5005)  time: 0.3445  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [1640/4579]  eta: 0:16:53  Lr: 0.030000  Loss: 0.2185  Acc@1: 56.2500 (57.6287)  Acc@5: 87.5000 (90.4822)  time: 0.3456  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [1650/4579]  eta: 0:16:50  Lr: 0.030000  Loss: 0.3388  Acc@1: 62.5000 (57.6280)  Acc@5: 87.5000 (90.4830)  time: 0.3445  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [1660/4579]  eta: 0:16:46  Lr: 0.030000  Loss: 0.3154  Acc@1: 62.5000 (57.6460)  Acc@5: 87.5000 (90.4839)  time: 0.3426  data: 0.0002  max mem: 2500
Train: Epoch[3/5]  [1670/4579]  eta: 0:16:43  Lr: 0.030000  Loss: 0.2806  Acc@1: 62.5000 (57.6601)  Acc@5: 87.5000 (90.4847)  time: 0.3424  data: 0.0002  max mem: 2500
Train: Epoch[3/5]  [1680/4579]  eta: 0:16:39  Lr: 0.030000  Loss: 0.0320  Acc@1: 56.2500 (57.6591)  Acc@5: 87.5000 (90.4707)  time: 0.3424  data: 0.0002  max mem: 2500
Train: Epoch[3/5]  [1690/4579]  eta: 0:16:36  Lr: 0.030000  Loss: 0.1814  Acc@1: 56.2500 (57.6804)  Acc@5: 93.7500 (90.4827)  time: 0.3426  data: 0.0002  max mem: 2500
Train: Epoch[3/5]  [1700/4579]  eta: 0:16:32  Lr: 0.030000  Loss: -0.1927  Acc@1: 56.2500 (57.6830)  Acc@5: 93.7500 (90.4982)  time: 0.3430  data: 0.0002  max mem: 2500
Train: Epoch[3/5]  [1710/4579]  eta: 0:16:29  Lr: 0.030000  Loss: 0.0572  Acc@1: 56.2500 (57.6563)  Acc@5: 93.7500 (90.4953)  time: 0.3433  data: 0.0002  max mem: 2500
Train: Epoch[3/5]  [1720/4579]  eta: 0:16:25  Lr: 0.030000  Loss: 0.4483  Acc@1: 62.5000 (57.6627)  Acc@5: 87.5000 (90.4924)  time: 0.3440  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [1730/4579]  eta: 0:16:22  Lr: 0.030000  Loss: 0.3063  Acc@1: 62.5000 (57.6943)  Acc@5: 93.7500 (90.5040)  time: 0.3448  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1740/4579]  eta: 0:16:18  Lr: 0.030000  Loss: 0.2317  Acc@1: 62.5000 (57.6860)  Acc@5: 93.7500 (90.4904)  time: 0.3449  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1750/4579]  eta: 0:16:15  Lr: 0.030000  Loss: 0.1512  Acc@1: 56.2500 (57.6956)  Acc@5: 87.5000 (90.4626)  time: 0.3447  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1760/4579]  eta: 0:16:12  Lr: 0.030000  Loss: 0.0920  Acc@1: 62.5000 (57.7122)  Acc@5: 87.5000 (90.4564)  time: 0.3456  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1770/4579]  eta: 0:16:08  Lr: 0.030000  Loss: 0.1253  Acc@1: 62.5000 (57.7146)  Acc@5: 93.7500 (90.4609)  time: 0.3467  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1780/4579]  eta: 0:16:05  Lr: 0.030000  Loss: 0.3133  Acc@1: 56.2500 (57.7204)  Acc@5: 87.5000 (90.4513)  time: 0.3457  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1790/4579]  eta: 0:16:01  Lr: 0.030000  Loss: 0.4562  Acc@1: 56.2500 (57.7296)  Acc@5: 87.5000 (90.4662)  time: 0.3452  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1800/4579]  eta: 0:15:58  Lr: 0.030000  Loss: 0.2641  Acc@1: 56.2500 (57.7110)  Acc@5: 93.7500 (90.4636)  time: 0.3454  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [1810/4579]  eta: 0:15:54  Lr: 0.030000  Loss: 0.2796  Acc@1: 56.2500 (57.7133)  Acc@5: 87.5000 (90.4611)  time: 0.3455  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1820/4579]  eta: 0:15:51  Lr: 0.030000  Loss: 0.7969  Acc@1: 56.2500 (57.7018)  Acc@5: 87.5000 (90.4379)  time: 0.3459  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1830/4579]  eta: 0:15:48  Lr: 0.030000  Loss: 0.0539  Acc@1: 56.2500 (57.7212)  Acc@5: 87.5000 (90.4287)  time: 0.3456  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1840/4579]  eta: 0:15:44  Lr: 0.030000  Loss: 0.4168  Acc@1: 56.2500 (57.6826)  Acc@5: 87.5000 (90.3992)  time: 0.3490  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1850/4579]  eta: 0:15:41  Lr: 0.030000  Loss: 0.3430  Acc@1: 50.0000 (57.6749)  Acc@5: 87.5000 (90.3971)  time: 0.3487  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1860/4579]  eta: 0:15:37  Lr: 0.030000  Loss: 0.1469  Acc@1: 56.2500 (57.6840)  Acc@5: 87.5000 (90.3849)  time: 0.3447  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [1870/4579]  eta: 0:15:34  Lr: 0.030000  Loss: 0.0685  Acc@1: 56.2500 (57.6831)  Acc@5: 87.5000 (90.3728)  time: 0.3449  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [1880/4579]  eta: 0:15:30  Lr: 0.030000  Loss: 0.5005  Acc@1: 56.2500 (57.6754)  Acc@5: 87.5000 (90.3608)  time: 0.3452  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [1890/4579]  eta: 0:15:27  Lr: 0.030000  Loss: 0.2113  Acc@1: 56.2500 (57.6811)  Acc@5: 87.5000 (90.3788)  time: 0.3451  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [1900/4579]  eta: 0:15:24  Lr: 0.030000  Loss: 0.1540  Acc@1: 56.2500 (57.6999)  Acc@5: 93.7500 (90.3735)  time: 0.3447  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [1910/4579]  eta: 0:15:20  Lr: 0.030000  Loss: 0.1274  Acc@1: 62.5000 (57.7119)  Acc@5: 87.5000 (90.3683)  time: 0.3450  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [1920/4579]  eta: 0:15:17  Lr: 0.030000  Loss: 0.1865  Acc@1: 62.5000 (57.7336)  Acc@5: 87.5000 (90.3663)  time: 0.3452  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [1930/4579]  eta: 0:15:13  Lr: 0.030000  Loss: 0.3699  Acc@1: 62.5000 (57.7648)  Acc@5: 93.7500 (90.3839)  time: 0.3441  data: 0.0002  max mem: 2500
Train: Epoch[3/5]  [1940/4579]  eta: 0:15:10  Lr: 0.030000  Loss: 0.0793  Acc@1: 62.5000 (57.7634)  Acc@5: 87.5000 (90.3787)  time: 0.3429  data: 0.0002  max mem: 2500
Train: Epoch[3/5]  [1950/4579]  eta: 0:15:06  Lr: 0.030000  Loss: 0.1627  Acc@1: 62.5000 (57.7620)  Acc@5: 87.5000 (90.3735)  time: 0.3429  data: 0.0002  max mem: 2500
Train: Epoch[3/5]  [1960/4579]  eta: 0:15:03  Lr: 0.030000  Loss: 0.4961  Acc@1: 56.2500 (57.7543)  Acc@5: 93.7500 (90.3621)  time: 0.3429  data: 0.0002  max mem: 2500
Train: Epoch[3/5]  [1970/4579]  eta: 0:14:59  Lr: 0.030000  Loss: 0.3813  Acc@1: 56.2500 (57.7562)  Acc@5: 93.7500 (90.3792)  time: 0.3428  data: 0.0002  max mem: 2500
Train: Epoch[3/5]  [1980/4579]  eta: 0:14:56  Lr: 0.030000  Loss: -0.1571  Acc@1: 62.5000 (57.7612)  Acc@5: 93.7500 (90.3963)  time: 0.3425  data: 0.0002  max mem: 2500
Train: Epoch[3/5]  [1990/4579]  eta: 0:14:52  Lr: 0.030000  Loss: 0.3078  Acc@1: 56.2500 (57.7599)  Acc@5: 93.7500 (90.4037)  time: 0.3427  data: 0.0002  max mem: 2500
Train: Epoch[3/5]  [2000/4579]  eta: 0:14:49  Lr: 0.030000  Loss: 0.7710  Acc@1: 56.2500 (57.7617)  Acc@5: 93.7500 (90.3923)  time: 0.3439  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [2010/4579]  eta: 0:14:45  Lr: 0.030000  Loss: 0.2578  Acc@1: 56.2500 (57.7604)  Acc@5: 93.7500 (90.3904)  time: 0.3442  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2020/4579]  eta: 0:14:42  Lr: 0.030000  Loss: 0.3424  Acc@1: 56.2500 (57.7622)  Acc@5: 93.7500 (90.3977)  time: 0.3442  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2030/4579]  eta: 0:14:38  Lr: 0.030000  Loss: 0.2059  Acc@1: 56.2500 (57.7579)  Acc@5: 93.7500 (90.4050)  time: 0.3444  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2040/4579]  eta: 0:14:35  Lr: 0.030000  Loss: 0.2486  Acc@1: 56.2500 (57.7444)  Acc@5: 93.7500 (90.4183)  time: 0.3442  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2050/4579]  eta: 0:14:32  Lr: 0.030000  Loss: -0.1179  Acc@1: 56.2500 (57.7462)  Acc@5: 93.7500 (90.4254)  time: 0.3444  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2060/4579]  eta: 0:14:28  Lr: 0.030000  Loss: 0.1421  Acc@1: 62.5000 (57.7693)  Acc@5: 87.5000 (90.4142)  time: 0.3440  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [2070/4579]  eta: 0:14:25  Lr: 0.030000  Loss: 0.1240  Acc@1: 62.5000 (57.7951)  Acc@5: 93.7500 (90.4303)  time: 0.3448  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2080/4579]  eta: 0:14:21  Lr: 0.030000  Loss: 0.2237  Acc@1: 62.5000 (57.7907)  Acc@5: 93.7500 (90.4283)  time: 0.3455  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2090/4579]  eta: 0:14:18  Lr: 0.030000  Loss: 0.6112  Acc@1: 62.5000 (57.8103)  Acc@5: 93.7500 (90.4173)  time: 0.3446  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2100/4579]  eta: 0:14:14  Lr: 0.030000  Loss: 0.0765  Acc@1: 62.5000 (57.8326)  Acc@5: 87.5000 (90.4064)  time: 0.3444  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2110/4579]  eta: 0:14:11  Lr: 0.030000  Loss: 0.1964  Acc@1: 62.5000 (57.8517)  Acc@5: 87.5000 (90.4104)  time: 0.3452  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2120/4579]  eta: 0:14:07  Lr: 0.030000  Loss: 0.2236  Acc@1: 62.5000 (57.8648)  Acc@5: 93.7500 (90.4114)  time: 0.3472  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2130/4579]  eta: 0:14:04  Lr: 0.030000  Loss: 0.2567  Acc@1: 56.2500 (57.8572)  Acc@5: 87.5000 (90.4006)  time: 0.3459  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [2140/4579]  eta: 0:14:01  Lr: 0.030000  Loss: -0.0696  Acc@1: 56.2500 (57.8380)  Acc@5: 87.5000 (90.4075)  time: 0.3438  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [2150/4579]  eta: 0:13:57  Lr: 0.030000  Loss: 0.3759  Acc@1: 50.0000 (57.8132)  Acc@5: 93.7500 (90.4056)  time: 0.3441  data: 0.0002  max mem: 2500
Train: Epoch[3/5]  [2160/4579]  eta: 0:13:54  Lr: 0.030000  Loss: 0.2725  Acc@1: 50.0000 (57.8147)  Acc@5: 87.5000 (90.4095)  time: 0.3444  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [2170/4579]  eta: 0:13:50  Lr: 0.030000  Loss: 0.2622  Acc@1: 56.2500 (57.8219)  Acc@5: 93.7500 (90.4249)  time: 0.3443  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [2180/4579]  eta: 0:13:47  Lr: 0.030000  Loss: 0.1924  Acc@1: 56.2500 (57.7831)  Acc@5: 93.7500 (90.4172)  time: 0.3438  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [2190/4579]  eta: 0:13:43  Lr: 0.030000  Loss: 0.2100  Acc@1: 50.0000 (57.7990)  Acc@5: 93.7500 (90.4153)  time: 0.3446  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [2200/4579]  eta: 0:13:40  Lr: 0.030000  Loss: 0.6947  Acc@1: 56.2500 (57.7948)  Acc@5: 93.7500 (90.4106)  time: 0.3443  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [2210/4579]  eta: 0:13:36  Lr: 0.030000  Loss: 0.1408  Acc@1: 56.2500 (57.8132)  Acc@5: 87.5000 (90.4088)  time: 0.3427  data: 0.0002  max mem: 2500
Train: Epoch[3/5]  [2220/4579]  eta: 0:13:33  Lr: 0.030000  Loss: 0.3909  Acc@1: 62.5000 (57.8399)  Acc@5: 93.7500 (90.4182)  time: 0.3425  data: 0.0002  max mem: 2500
Train: Epoch[3/5]  [2230/4579]  eta: 0:13:29  Lr: 0.030000  Loss: 0.1120  Acc@1: 56.2500 (57.8356)  Acc@5: 93.7500 (90.4303)  time: 0.3424  data: 0.0002  max mem: 2500
Train: Epoch[3/5]  [2240/4579]  eta: 0:13:26  Lr: 0.030000  Loss: 0.4623  Acc@1: 56.2500 (57.8313)  Acc@5: 87.5000 (90.4172)  time: 0.3423  data: 0.0002  max mem: 2500
Train: Epoch[3/5]  [2250/4579]  eta: 0:13:22  Lr: 0.030000  Loss: 0.1937  Acc@1: 56.2500 (57.8271)  Acc@5: 93.7500 (90.4293)  time: 0.3424  data: 0.0002  max mem: 2500
Train: Epoch[3/5]  [2260/4579]  eta: 0:13:19  Lr: 0.030000  Loss: 0.0808  Acc@1: 56.2500 (57.8284)  Acc@5: 93.7500 (90.4356)  time: 0.3429  data: 0.0002  max mem: 2500
Train: Epoch[3/5]  [2270/4579]  eta: 0:13:16  Lr: 0.030000  Loss: 0.4787  Acc@1: 56.2500 (57.8104)  Acc@5: 87.5000 (90.4172)  time: 0.3440  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [2280/4579]  eta: 0:13:12  Lr: 0.030000  Loss: 0.3462  Acc@1: 56.2500 (57.8118)  Acc@5: 87.5000 (90.4072)  time: 0.3447  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2290/4579]  eta: 0:13:09  Lr: 0.030000  Loss: 0.2381  Acc@1: 56.2500 (57.8023)  Acc@5: 87.5000 (90.4163)  time: 0.3445  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2300/4579]  eta: 0:13:05  Lr: 0.030000  Loss: 0.1601  Acc@1: 56.2500 (57.8064)  Acc@5: 87.5000 (90.4063)  time: 0.3449  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2310/4579]  eta: 0:13:02  Lr: 0.030000  Loss: -0.1024  Acc@1: 56.2500 (57.8105)  Acc@5: 93.7500 (90.4181)  time: 0.3447  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2320/4579]  eta: 0:12:58  Lr: 0.030000  Loss: 0.1227  Acc@1: 62.5000 (57.8199)  Acc@5: 93.7500 (90.4244)  time: 0.3463  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [2330/4579]  eta: 0:12:55  Lr: 0.030000  Loss: 0.2644  Acc@1: 62.5000 (57.8239)  Acc@5: 93.7500 (90.4199)  time: 0.3471  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [2340/4579]  eta: 0:12:51  Lr: 0.030000  Loss: 0.1928  Acc@1: 56.2500 (57.8305)  Acc@5: 93.7500 (90.4288)  time: 0.3455  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2350/4579]  eta: 0:12:48  Lr: 0.030000  Loss: 0.5117  Acc@1: 62.5000 (57.8610)  Acc@5: 93.7500 (90.4349)  time: 0.3456  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2360/4579]  eta: 0:12:45  Lr: 0.030000  Loss: 0.6818  Acc@1: 62.5000 (57.8780)  Acc@5: 93.7500 (90.4278)  time: 0.3455  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [2370/4579]  eta: 0:12:41  Lr: 0.030000  Loss: 0.2298  Acc@1: 62.5000 (57.9107)  Acc@5: 93.7500 (90.4444)  time: 0.3450  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2380/4579]  eta: 0:12:38  Lr: 0.030000  Loss: 0.3527  Acc@1: 56.2500 (57.9011)  Acc@5: 93.7500 (90.4373)  time: 0.3453  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [2390/4579]  eta: 0:12:34  Lr: 0.030000  Loss: 0.0424  Acc@1: 56.2500 (57.8890)  Acc@5: 87.5000 (90.4355)  time: 0.3461  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [2400/4579]  eta: 0:12:31  Lr: 0.030000  Loss: -0.0068  Acc@1: 56.2500 (57.9186)  Acc@5: 93.7500 (90.4415)  time: 0.3460  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [2410/4579]  eta: 0:12:27  Lr: 0.030000  Loss: 0.4822  Acc@1: 56.2500 (57.9065)  Acc@5: 93.7500 (90.4552)  time: 0.3456  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [2420/4579]  eta: 0:12:24  Lr: 0.030000  Loss: 0.2755  Acc@1: 56.2500 (57.8945)  Acc@5: 87.5000 (90.4430)  time: 0.3457  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [2430/4579]  eta: 0:12:20  Lr: 0.030000  Loss: 0.3641  Acc@1: 56.2500 (57.8980)  Acc@5: 87.5000 (90.4360)  time: 0.3445  data: 0.0002  max mem: 2500
Train: Epoch[3/5]  [2440/4579]  eta: 0:12:17  Lr: 0.030000  Loss: 0.5687  Acc@1: 56.2500 (57.9117)  Acc@5: 87.5000 (90.4342)  time: 0.3439  data: 0.0002  max mem: 2500
Train: Epoch[3/5]  [2450/4579]  eta: 0:12:14  Lr: 0.030000  Loss: 0.3712  Acc@1: 56.2500 (57.9177)  Acc@5: 93.7500 (90.4350)  time: 0.3442  data: 0.0002  max mem: 2500
Train: Epoch[3/5]  [2460/4579]  eta: 0:12:10  Lr: 0.030000  Loss: 0.2557  Acc@1: 56.2500 (57.9109)  Acc@5: 93.7500 (90.4358)  time: 0.3441  data: 0.0002  max mem: 2500
Train: Epoch[3/5]  [2470/4579]  eta: 0:12:07  Lr: 0.030000  Loss: 0.2784  Acc@1: 62.5000 (57.9219)  Acc@5: 93.7500 (90.4366)  time: 0.3446  data: 0.0002  max mem: 2500
Train: Epoch[3/5]  [2480/4579]  eta: 0:12:03  Lr: 0.030000  Loss: 0.3272  Acc@1: 62.5000 (57.9177)  Acc@5: 93.7500 (90.4272)  time: 0.3453  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [2490/4579]  eta: 0:12:00  Lr: 0.030000  Loss: 0.3567  Acc@1: 56.2500 (57.9135)  Acc@5: 87.5000 (90.4055)  time: 0.3459  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2500/4579]  eta: 0:11:56  Lr: 0.030000  Loss: 0.3681  Acc@1: 56.2500 (57.9043)  Acc@5: 87.5000 (90.3988)  time: 0.3458  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [2510/4579]  eta: 0:11:53  Lr: 0.030000  Loss: 0.2695  Acc@1: 56.2500 (57.8878)  Acc@5: 87.5000 (90.4047)  time: 0.3463  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2520/4579]  eta: 0:11:49  Lr: 0.030000  Loss: 0.4999  Acc@1: 56.2500 (57.8962)  Acc@5: 87.5000 (90.4031)  time: 0.3466  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2530/4579]  eta: 0:11:46  Lr: 0.030000  Loss: 0.2487  Acc@1: 62.5000 (57.9193)  Acc@5: 87.5000 (90.4089)  time: 0.3460  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2540/4579]  eta: 0:11:43  Lr: 0.030000  Loss: 0.3498  Acc@1: 62.5000 (57.9275)  Acc@5: 93.7500 (90.4024)  time: 0.3457  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2550/4579]  eta: 0:11:39  Lr: 0.030000  Loss: 0.4458  Acc@1: 62.5000 (57.9479)  Acc@5: 87.5000 (90.3984)  time: 0.3461  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2560/4579]  eta: 0:11:36  Lr: 0.030000  Loss: 0.1216  Acc@1: 62.5000 (57.9437)  Acc@5: 87.5000 (90.3944)  time: 0.3463  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2570/4579]  eta: 0:11:32  Lr: 0.030000  Loss: 0.3719  Acc@1: 56.2500 (57.9711)  Acc@5: 93.7500 (90.3977)  time: 0.3457  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [2580/4579]  eta: 0:11:29  Lr: 0.030000  Loss: 0.1299  Acc@1: 56.2500 (57.9548)  Acc@5: 87.5000 (90.3816)  time: 0.3454  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [2590/4579]  eta: 0:11:25  Lr: 0.030000  Loss: 0.3051  Acc@1: 56.2500 (57.9602)  Acc@5: 93.7500 (90.3946)  time: 0.3456  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [2600/4579]  eta: 0:11:22  Lr: 0.030000  Loss: 0.3079  Acc@1: 56.2500 (57.9825)  Acc@5: 93.7500 (90.4003)  time: 0.3457  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [2610/4579]  eta: 0:11:19  Lr: 0.030000  Loss: 0.5024  Acc@1: 62.5000 (57.9902)  Acc@5: 87.5000 (90.3916)  time: 0.3454  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [2620/4579]  eta: 0:11:15  Lr: 0.030000  Loss: 0.2421  Acc@1: 62.5000 (58.0241)  Acc@5: 93.7500 (90.3997)  time: 0.3464  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [2630/4579]  eta: 0:11:12  Lr: 0.030000  Loss: 0.1262  Acc@1: 68.7500 (58.0506)  Acc@5: 93.7500 (90.4053)  time: 0.3453  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [2640/4579]  eta: 0:11:08  Lr: 0.030000  Loss: 0.2793  Acc@1: 62.5000 (58.0462)  Acc@5: 87.5000 (90.3872)  time: 0.3432  data: 0.0002  max mem: 2500
Train: Epoch[3/5]  [2650/4579]  eta: 0:11:05  Lr: 0.030000  Loss: 0.5533  Acc@1: 56.2500 (58.0512)  Acc@5: 87.5000 (90.3833)  time: 0.3435  data: 0.0002  max mem: 2500
Train: Epoch[3/5]  [2660/4579]  eta: 0:11:01  Lr: 0.030000  Loss: 0.1472  Acc@1: 56.2500 (58.0421)  Acc@5: 93.7500 (90.3913)  time: 0.3435  data: 0.0002  max mem: 2500
Train: Epoch[3/5]  [2670/4579]  eta: 0:10:58  Lr: 0.030000  Loss: 0.1654  Acc@1: 62.5000 (58.0681)  Acc@5: 93.7500 (90.4015)  time: 0.3431  data: 0.0002  max mem: 2500
Train: Epoch[3/5]  [2680/4579]  eta: 0:10:54  Lr: 0.030000  Loss: 0.3810  Acc@1: 62.5000 (58.0590)  Acc@5: 93.7500 (90.4000)  time: 0.3433  data: 0.0002  max mem: 2500
Train: Epoch[3/5]  [2690/4579]  eta: 0:10:51  Lr: 0.030000  Loss: -0.0978  Acc@1: 62.5000 (58.0802)  Acc@5: 87.5000 (90.4055)  time: 0.3433  data: 0.0002  max mem: 2500
Train: Epoch[3/5]  [2700/4579]  eta: 0:10:47  Lr: 0.030000  Loss: 0.2636  Acc@1: 62.5000 (58.0965)  Acc@5: 87.5000 (90.3994)  time: 0.3437  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [2710/4579]  eta: 0:10:44  Lr: 0.030000  Loss: 0.0991  Acc@1: 62.5000 (58.1105)  Acc@5: 87.5000 (90.3864)  time: 0.3455  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [2720/4579]  eta: 0:10:41  Lr: 0.030000  Loss: 0.1397  Acc@1: 62.5000 (58.1174)  Acc@5: 87.5000 (90.3804)  time: 0.3466  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [2730/4579]  eta: 0:10:37  Lr: 0.030000  Loss: 0.4015  Acc@1: 56.2500 (58.1129)  Acc@5: 87.5000 (90.3767)  time: 0.3458  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2740/4579]  eta: 0:10:34  Lr: 0.030000  Loss: 0.0064  Acc@1: 56.2500 (58.1061)  Acc@5: 93.7500 (90.3799)  time: 0.3447  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2750/4579]  eta: 0:10:30  Lr: 0.030000  Loss: 0.5033  Acc@1: 56.2500 (58.0948)  Acc@5: 87.5000 (90.3649)  time: 0.3462  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2760/4579]  eta: 0:10:27  Lr: 0.030000  Loss: 0.5419  Acc@1: 56.2500 (58.0881)  Acc@5: 87.5000 (90.3590)  time: 0.3464  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2770/4579]  eta: 0:10:23  Lr: 0.030000  Loss: 0.3469  Acc@1: 56.2500 (58.0860)  Acc@5: 93.7500 (90.3600)  time: 0.3454  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2780/4579]  eta: 0:10:20  Lr: 0.030000  Loss: 0.3231  Acc@1: 56.2500 (58.0906)  Acc@5: 87.5000 (90.3564)  time: 0.3452  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [2790/4579]  eta: 0:10:16  Lr: 0.030000  Loss: 0.5183  Acc@1: 56.2500 (58.0840)  Acc@5: 87.5000 (90.3507)  time: 0.3448  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [2800/4579]  eta: 0:10:13  Lr: 0.030000  Loss: 0.3451  Acc@1: 56.2500 (58.0953)  Acc@5: 87.5000 (90.3539)  time: 0.3448  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [2810/4579]  eta: 0:10:10  Lr: 0.030000  Loss: 0.1388  Acc@1: 62.5000 (58.1221)  Acc@5: 87.5000 (90.3682)  time: 0.3445  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2820/4579]  eta: 0:10:06  Lr: 0.030000  Loss: 0.4078  Acc@1: 62.5000 (58.1221)  Acc@5: 87.5000 (90.3647)  time: 0.3447  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2830/4579]  eta: 0:10:03  Lr: 0.030000  Loss: 0.5848  Acc@1: 56.2500 (58.1199)  Acc@5: 87.5000 (90.3656)  time: 0.3481  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2840/4579]  eta: 0:09:59  Lr: 0.030000  Loss: -0.1297  Acc@1: 56.2500 (58.1287)  Acc@5: 93.7500 (90.3687)  time: 0.3480  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2850/4579]  eta: 0:09:56  Lr: 0.030000  Loss: 0.2418  Acc@1: 62.5000 (58.1419)  Acc@5: 93.7500 (90.3652)  time: 0.3447  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2860/4579]  eta: 0:09:52  Lr: 0.030000  Loss: 0.1009  Acc@1: 62.5000 (58.1418)  Acc@5: 93.7500 (90.3814)  time: 0.3447  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [2870/4579]  eta: 0:09:49  Lr: 0.030000  Loss: 0.3800  Acc@1: 56.2500 (58.1526)  Acc@5: 93.7500 (90.3823)  time: 0.3445  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [2880/4579]  eta: 0:09:45  Lr: 0.030000  Loss: 0.3735  Acc@1: 56.2500 (58.1417)  Acc@5: 87.5000 (90.3809)  time: 0.3445  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [2890/4579]  eta: 0:09:42  Lr: 0.030000  Loss: 0.0807  Acc@1: 50.0000 (58.1373)  Acc@5: 87.5000 (90.3796)  time: 0.3446  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [2900/4579]  eta: 0:09:39  Lr: 0.030000  Loss: 0.3295  Acc@1: 56.2500 (58.1351)  Acc@5: 87.5000 (90.3762)  time: 0.3444  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [2910/4579]  eta: 0:09:35  Lr: 0.030000  Loss: 0.3741  Acc@1: 50.0000 (58.1179)  Acc@5: 87.5000 (90.3727)  time: 0.3446  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [2920/4579]  eta: 0:09:32  Lr: 0.030000  Loss: 0.4499  Acc@1: 43.7500 (58.0944)  Acc@5: 93.7500 (90.3736)  time: 0.3444  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [2930/4579]  eta: 0:09:28  Lr: 0.030000  Loss: 0.0621  Acc@1: 50.0000 (58.0796)  Acc@5: 87.5000 (90.3680)  time: 0.3433  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [2940/4579]  eta: 0:09:25  Lr: 0.030000  Loss: 0.1322  Acc@1: 56.2500 (58.0967)  Acc@5: 87.5000 (90.3583)  time: 0.3426  data: 0.0002  max mem: 2500
Train: Epoch[3/5]  [2950/4579]  eta: 0:09:21  Lr: 0.030000  Loss: 0.0513  Acc@1: 62.5000 (58.1138)  Acc@5: 87.5000 (90.3656)  time: 0.3427  data: 0.0002  max mem: 2500
Train: Epoch[3/5]  [2960/4579]  eta: 0:09:18  Lr: 0.030000  Loss: 0.4905  Acc@1: 56.2500 (58.1054)  Acc@5: 87.5000 (90.3538)  time: 0.3426  data: 0.0002  max mem: 2500
Train: Epoch[3/5]  [2970/4579]  eta: 0:09:14  Lr: 0.030000  Loss: 0.1220  Acc@1: 56.2500 (58.1244)  Acc@5: 87.5000 (90.3589)  time: 0.3426  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [2980/4579]  eta: 0:09:11  Lr: 0.030000  Loss: 0.2838  Acc@1: 62.5000 (58.1432)  Acc@5: 93.7500 (90.3703)  time: 0.3427  data: 0.0002  max mem: 2500
Train: Epoch[3/5]  [2990/4579]  eta: 0:09:07  Lr: 0.030000  Loss: 0.3444  Acc@1: 62.5000 (58.1432)  Acc@5: 87.5000 (90.3565)  time: 0.3427  data: 0.0002  max mem: 2500
Train: Epoch[3/5]  [3000/4579]  eta: 0:09:04  Lr: 0.030000  Loss: 0.4460  Acc@1: 62.5000 (58.1660)  Acc@5: 87.5000 (90.3678)  time: 0.3429  data: 0.0002  max mem: 2500
Train: Epoch[3/5]  [3010/4579]  eta: 0:09:00  Lr: 0.030000  Loss: 0.5379  Acc@1: 62.5000 (58.1804)  Acc@5: 93.7500 (90.3666)  time: 0.3434  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [3020/4579]  eta: 0:08:57  Lr: 0.030000  Loss: -0.2155  Acc@1: 62.5000 (58.1844)  Acc@5: 93.7500 (90.3716)  time: 0.3444  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3030/4579]  eta: 0:08:54  Lr: 0.030000  Loss: 0.3008  Acc@1: 56.2500 (58.1759)  Acc@5: 87.5000 (90.3621)  time: 0.3451  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3040/4579]  eta: 0:08:50  Lr: 0.030000  Loss: 0.2115  Acc@1: 56.2500 (58.1922)  Acc@5: 93.7500 (90.3712)  time: 0.3452  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [3050/4579]  eta: 0:08:47  Lr: 0.030000  Loss: 0.2600  Acc@1: 62.5000 (58.2063)  Acc@5: 93.7500 (90.3700)  time: 0.3457  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3060/4579]  eta: 0:08:43  Lr: 0.030000  Loss: 0.0946  Acc@1: 62.5000 (58.2020)  Acc@5: 87.5000 (90.3626)  time: 0.3455  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3070/4579]  eta: 0:08:40  Lr: 0.030000  Loss: 0.6692  Acc@1: 62.5000 (58.2099)  Acc@5: 93.7500 (90.3614)  time: 0.3442  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [3080/4579]  eta: 0:08:36  Lr: 0.030000  Loss: 0.1925  Acc@1: 68.7500 (58.2400)  Acc@5: 93.7500 (90.3745)  time: 0.3448  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3090/4579]  eta: 0:08:33  Lr: 0.030000  Loss: -0.1909  Acc@1: 68.7500 (58.2599)  Acc@5: 93.7500 (90.3773)  time: 0.3459  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [3100/4579]  eta: 0:08:29  Lr: 0.030000  Loss: 0.0097  Acc@1: 56.2500 (58.2473)  Acc@5: 93.7500 (90.3821)  time: 0.3458  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [3110/4579]  eta: 0:08:26  Lr: 0.030000  Loss: -0.0299  Acc@1: 56.2500 (58.2590)  Acc@5: 93.7500 (90.3970)  time: 0.3472  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [3120/4579]  eta: 0:08:23  Lr: 0.030000  Loss: -0.0440  Acc@1: 56.2500 (58.2606)  Acc@5: 87.5000 (90.3917)  time: 0.3465  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3130/4579]  eta: 0:08:19  Lr: 0.030000  Loss: 0.2646  Acc@1: 56.2500 (58.2542)  Acc@5: 87.5000 (90.4024)  time: 0.3448  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [3140/4579]  eta: 0:08:16  Lr: 0.030000  Loss: -0.0364  Acc@1: 62.5000 (58.2736)  Acc@5: 93.7500 (90.4151)  time: 0.3453  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [3150/4579]  eta: 0:08:12  Lr: 0.030000  Loss: 0.1715  Acc@1: 62.5000 (58.2652)  Acc@5: 93.7500 (90.4157)  time: 0.3455  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3160/4579]  eta: 0:08:09  Lr: 0.030000  Loss: 0.4600  Acc@1: 56.2500 (58.2687)  Acc@5: 93.7500 (90.4223)  time: 0.3454  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3170/4579]  eta: 0:08:05  Lr: 0.030000  Loss: 0.1383  Acc@1: 56.2500 (58.2565)  Acc@5: 93.7500 (90.4230)  time: 0.3453  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3180/4579]  eta: 0:08:02  Lr: 0.030000  Loss: 0.0088  Acc@1: 62.5000 (58.2816)  Acc@5: 93.7500 (90.4275)  time: 0.3450  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3190/4579]  eta: 0:07:58  Lr: 0.030000  Loss: -0.1750  Acc@1: 62.5000 (58.3046)  Acc@5: 93.7500 (90.4301)  time: 0.3448  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [3200/4579]  eta: 0:07:55  Lr: 0.030000  Loss: -0.0627  Acc@1: 56.2500 (58.3001)  Acc@5: 93.7500 (90.4366)  time: 0.3451  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [3210/4579]  eta: 0:07:52  Lr: 0.030000  Loss: 0.0870  Acc@1: 56.2500 (58.3054)  Acc@5: 87.5000 (90.4255)  time: 0.3454  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [3220/4579]  eta: 0:07:48  Lr: 0.030000  Loss: -0.0162  Acc@1: 62.5000 (58.3146)  Acc@5: 87.5000 (90.4378)  time: 0.3455  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3230/4579]  eta: 0:07:45  Lr: 0.030000  Loss: 0.1468  Acc@1: 62.5000 (58.3430)  Acc@5: 93.7500 (90.4519)  time: 0.3446  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [3240/4579]  eta: 0:07:41  Lr: 0.030000  Loss: 0.3155  Acc@1: 62.5000 (58.3500)  Acc@5: 93.7500 (90.4505)  time: 0.3434  data: 0.0002  max mem: 2500
Train: Epoch[3/5]  [3250/4579]  eta: 0:07:38  Lr: 0.030000  Loss: 0.2984  Acc@1: 56.2500 (58.3570)  Acc@5: 93.7500 (90.4587)  time: 0.3431  data: 0.0002  max mem: 2500
Train: Epoch[3/5]  [3260/4579]  eta: 0:07:34  Lr: 0.030000  Loss: -0.0699  Acc@1: 56.2500 (58.3563)  Acc@5: 93.7500 (90.4650)  time: 0.3445  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3270/4579]  eta: 0:07:31  Lr: 0.030000  Loss: 0.1972  Acc@1: 56.2500 (58.3480)  Acc@5: 93.7500 (90.4693)  time: 0.3449  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3280/4579]  eta: 0:07:27  Lr: 0.030000  Loss: 0.2005  Acc@1: 56.2500 (58.3492)  Acc@5: 87.5000 (90.4678)  time: 0.3440  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3290/4579]  eta: 0:07:24  Lr: 0.030000  Loss: 0.2510  Acc@1: 62.5000 (58.3637)  Acc@5: 87.5000 (90.4569)  time: 0.3436  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [3300/4579]  eta: 0:07:21  Lr: 0.030000  Loss: 0.1378  Acc@1: 62.5000 (58.3706)  Acc@5: 87.5000 (90.4631)  time: 0.3436  data: 0.0002  max mem: 2500
Train: Epoch[3/5]  [3310/4579]  eta: 0:07:17  Lr: 0.030000  Loss: 0.1293  Acc@1: 56.2500 (58.3585)  Acc@5: 87.5000 (90.4466)  time: 0.3441  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [3320/4579]  eta: 0:07:14  Lr: 0.030000  Loss: -0.0015  Acc@1: 56.2500 (58.3672)  Acc@5: 87.5000 (90.4509)  time: 0.3437  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [3330/4579]  eta: 0:07:10  Lr: 0.030000  Loss: 0.3589  Acc@1: 56.2500 (58.3609)  Acc@5: 93.7500 (90.4477)  time: 0.3439  data: 0.0002  max mem: 2500
Train: Epoch[3/5]  [3340/4579]  eta: 0:07:07  Lr: 0.030000  Loss: 0.3137  Acc@1: 62.5000 (58.3751)  Acc@5: 93.7500 (90.4538)  time: 0.3432  data: 0.0002  max mem: 2500
Train: Epoch[3/5]  [3350/4579]  eta: 0:07:03  Lr: 0.030000  Loss: 0.3177  Acc@1: 62.5000 (58.3781)  Acc@5: 93.7500 (90.4562)  time: 0.3425  data: 0.0002  max mem: 2500
Train: Epoch[3/5]  [3360/4579]  eta: 0:07:00  Lr: 0.030000  Loss: 0.4624  Acc@1: 56.2500 (58.3718)  Acc@5: 87.5000 (90.4530)  time: 0.3426  data: 0.0002  max mem: 2500
Train: Epoch[3/5]  [3370/4579]  eta: 0:06:56  Lr: 0.030000  Loss: 0.3619  Acc@1: 68.7500 (58.4044)  Acc@5: 87.5000 (90.4405)  time: 0.3426  data: 0.0002  max mem: 2500
Train: Epoch[3/5]  [3380/4579]  eta: 0:06:53  Lr: 0.030000  Loss: 0.2813  Acc@1: 62.5000 (58.3999)  Acc@5: 87.5000 (90.4411)  time: 0.3431  data: 0.0002  max mem: 2500
Train: Epoch[3/5]  [3390/4579]  eta: 0:06:49  Lr: 0.030000  Loss: 0.1929  Acc@1: 56.2500 (58.4009)  Acc@5: 93.7500 (90.4398)  time: 0.3437  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [3400/4579]  eta: 0:06:46  Lr: 0.030000  Loss: 0.2124  Acc@1: 50.0000 (58.3872)  Acc@5: 87.5000 (90.4293)  time: 0.3453  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3410/4579]  eta: 0:06:43  Lr: 0.030000  Loss: 0.1918  Acc@1: 50.0000 (58.3755)  Acc@5: 87.5000 (90.4189)  time: 0.3458  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3420/4579]  eta: 0:06:39  Lr: 0.030000  Loss: 0.1915  Acc@1: 56.2500 (58.3930)  Acc@5: 93.7500 (90.4249)  time: 0.3446  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3430/4579]  eta: 0:06:36  Lr: 0.030000  Loss: 0.1314  Acc@1: 68.7500 (58.4086)  Acc@5: 93.7500 (90.4346)  time: 0.3440  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3440/4579]  eta: 0:06:32  Lr: 0.030000  Loss: 0.5056  Acc@1: 62.5000 (58.3987)  Acc@5: 93.7500 (90.4316)  time: 0.3442  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3450/4579]  eta: 0:06:29  Lr: 0.030000  Loss: 0.4167  Acc@1: 62.5000 (58.4106)  Acc@5: 87.5000 (90.4357)  time: 0.3447  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3460/4579]  eta: 0:06:25  Lr: 0.030000  Loss: 0.2794  Acc@1: 62.5000 (58.4188)  Acc@5: 93.7500 (90.4435)  time: 0.3446  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3470/4579]  eta: 0:06:22  Lr: 0.030000  Loss: 0.4084  Acc@1: 56.2500 (58.4072)  Acc@5: 93.7500 (90.4404)  time: 0.3445  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3480/4579]  eta: 0:06:18  Lr: 0.030000  Loss: -0.0466  Acc@1: 56.2500 (58.4099)  Acc@5: 93.7500 (90.4446)  time: 0.3443  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [3490/4579]  eta: 0:06:15  Lr: 0.030000  Loss: -0.0919  Acc@1: 62.5000 (58.4234)  Acc@5: 93.7500 (90.4451)  time: 0.3441  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [3500/4579]  eta: 0:06:12  Lr: 0.030000  Loss: 0.5755  Acc@1: 56.2500 (58.3994)  Acc@5: 87.5000 (90.4349)  time: 0.3443  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3510/4579]  eta: 0:06:08  Lr: 0.030000  Loss: 0.3040  Acc@1: 62.5000 (58.4128)  Acc@5: 93.7500 (90.4425)  time: 0.3445  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3520/4579]  eta: 0:06:05  Lr: 0.030000  Loss: 0.1526  Acc@1: 62.5000 (58.4174)  Acc@5: 93.7500 (90.4519)  time: 0.3447  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [3530/4579]  eta: 0:06:01  Lr: 0.030000  Loss: 0.0687  Acc@1: 62.5000 (58.4271)  Acc@5: 93.7500 (90.4507)  time: 0.3447  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [3540/4579]  eta: 0:05:58  Lr: 0.030000  Loss: 0.1393  Acc@1: 56.2500 (58.4139)  Acc@5: 87.5000 (90.4511)  time: 0.3450  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [3550/4579]  eta: 0:05:54  Lr: 0.030000  Loss: 0.4811  Acc@1: 56.2500 (58.4184)  Acc@5: 87.5000 (90.4393)  time: 0.3442  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [3560/4579]  eta: 0:05:51  Lr: 0.030000  Loss: 0.3144  Acc@1: 56.2500 (58.4211)  Acc@5: 87.5000 (90.4416)  time: 0.3429  data: 0.0002  max mem: 2500
Train: Epoch[3/5]  [3570/4579]  eta: 0:05:47  Lr: 0.030000  Loss: 0.5655  Acc@1: 56.2500 (58.4115)  Acc@5: 87.5000 (90.4281)  time: 0.3429  data: 0.0002  max mem: 2500
Train: Epoch[3/5]  [3580/4579]  eta: 0:05:44  Lr: 0.030000  Loss: 0.3974  Acc@1: 56.2500 (58.4194)  Acc@5: 87.5000 (90.4356)  time: 0.3428  data: 0.0002  max mem: 2500
Train: Epoch[3/5]  [3590/4579]  eta: 0:05:40  Lr: 0.030000  Loss: 0.2634  Acc@1: 56.2500 (58.4378)  Acc@5: 93.7500 (90.4449)  time: 0.3428  data: 0.0002  max mem: 2500
Train: Epoch[3/5]  [3600/4579]  eta: 0:05:37  Lr: 0.030000  Loss: 0.2661  Acc@1: 56.2500 (58.4334)  Acc@5: 93.7500 (90.4419)  time: 0.3430  data: 0.0002  max mem: 2500
Train: Epoch[3/5]  [3610/4579]  eta: 0:05:34  Lr: 0.030000  Loss: 0.4094  Acc@1: 56.2500 (58.4343)  Acc@5: 93.7500 (90.4441)  time: 0.3435  data: 0.0002  max mem: 2500
Train: Epoch[3/5]  [3620/4579]  eta: 0:05:30  Lr: 0.030000  Loss: 0.5276  Acc@1: 56.2500 (58.4369)  Acc@5: 93.7500 (90.4533)  time: 0.3435  data: 0.0002  max mem: 2500
Train: Epoch[3/5]  [3630/4579]  eta: 0:05:27  Lr: 0.030000  Loss: -0.0602  Acc@1: 56.2500 (58.4464)  Acc@5: 93.7500 (90.4572)  time: 0.3439  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [3640/4579]  eta: 0:05:23  Lr: 0.030000  Loss: 0.6381  Acc@1: 62.5000 (58.4712)  Acc@5: 93.7500 (90.4559)  time: 0.3457  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [3650/4579]  eta: 0:05:20  Lr: 0.030000  Loss: 0.1591  Acc@1: 62.5000 (58.4617)  Acc@5: 87.5000 (90.4478)  time: 0.3471  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [3660/4579]  eta: 0:05:16  Lr: 0.030000  Loss: 0.0154  Acc@1: 56.2500 (58.4625)  Acc@5: 87.5000 (90.4483)  time: 0.3463  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3670/4579]  eta: 0:05:13  Lr: 0.030000  Loss: 0.5130  Acc@1: 56.2500 (58.4463)  Acc@5: 93.7500 (90.4573)  time: 0.3455  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3680/4579]  eta: 0:05:09  Lr: 0.030000  Loss: 0.4544  Acc@1: 56.2500 (58.4675)  Acc@5: 93.7500 (90.4612)  time: 0.3455  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3690/4579]  eta: 0:05:06  Lr: 0.030000  Loss: 0.0781  Acc@1: 62.5000 (58.4835)  Acc@5: 93.7500 (90.4734)  time: 0.3454  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3700/4579]  eta: 0:05:03  Lr: 0.030000  Loss: 0.4413  Acc@1: 62.5000 (58.4926)  Acc@5: 93.7500 (90.4671)  time: 0.3460  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3710/4579]  eta: 0:04:59  Lr: 0.030000  Loss: 0.0795  Acc@1: 56.2500 (58.4866)  Acc@5: 87.5000 (90.4642)  time: 0.3462  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3720/4579]  eta: 0:04:56  Lr: 0.030000  Loss: 0.0804  Acc@1: 62.5000 (58.5007)  Acc@5: 87.5000 (90.4629)  time: 0.3455  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3730/4579]  eta: 0:04:52  Lr: 0.030000  Loss: -0.0815  Acc@1: 62.5000 (58.5198)  Acc@5: 87.5000 (90.4650)  time: 0.3462  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3740/4579]  eta: 0:04:49  Lr: 0.030000  Loss: 0.5289  Acc@1: 62.5000 (58.5071)  Acc@5: 87.5000 (90.4454)  time: 0.3460  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3750/4579]  eta: 0:04:45  Lr: 0.030000  Loss: -0.0501  Acc@1: 56.2500 (58.5111)  Acc@5: 87.5000 (90.4459)  time: 0.3454  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [3760/4579]  eta: 0:04:42  Lr: 0.030000  Loss: 0.0698  Acc@1: 62.5000 (58.5200)  Acc@5: 93.7500 (90.4380)  time: 0.3460  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [3770/4579]  eta: 0:04:38  Lr: 0.030000  Loss: 0.0089  Acc@1: 62.5000 (58.5272)  Acc@5: 93.7500 (90.4419)  time: 0.3460  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3780/4579]  eta: 0:04:35  Lr: 0.030000  Loss: 0.3434  Acc@1: 56.2500 (58.5212)  Acc@5: 87.5000 (90.4390)  time: 0.3471  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3790/4579]  eta: 0:04:32  Lr: 0.030000  Loss: 0.4579  Acc@1: 62.5000 (58.5317)  Acc@5: 87.5000 (90.4379)  time: 0.3469  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3800/4579]  eta: 0:04:28  Lr: 0.030000  Loss: 0.2247  Acc@1: 62.5000 (58.5405)  Acc@5: 93.7500 (90.4400)  time: 0.3466  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [3810/4579]  eta: 0:04:25  Lr: 0.030000  Loss: 0.2350  Acc@1: 62.5000 (58.5443)  Acc@5: 93.7500 (90.4438)  time: 0.3463  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [3820/4579]  eta: 0:04:21  Lr: 0.030000  Loss: 0.2950  Acc@1: 62.5000 (58.5531)  Acc@5: 93.7500 (90.4410)  time: 0.3452  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3830/4579]  eta: 0:04:18  Lr: 0.030000  Loss: 0.1439  Acc@1: 62.5000 (58.5634)  Acc@5: 93.7500 (90.4496)  time: 0.3452  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [3840/4579]  eta: 0:04:14  Lr: 0.030000  Loss: 0.2127  Acc@1: 56.2500 (58.5541)  Acc@5: 93.7500 (90.4436)  time: 0.3453  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [3850/4579]  eta: 0:04:11  Lr: 0.030000  Loss: 0.1889  Acc@1: 56.2500 (58.5416)  Acc@5: 87.5000 (90.4375)  time: 0.3451  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [3860/4579]  eta: 0:04:07  Lr: 0.030000  Loss: 0.4926  Acc@1: 56.2500 (58.5341)  Acc@5: 87.5000 (90.4316)  time: 0.3446  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [3870/4579]  eta: 0:04:04  Lr: 0.030000  Loss: 0.3714  Acc@1: 56.2500 (58.5395)  Acc@5: 93.7500 (90.4337)  time: 0.3455  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [3880/4579]  eta: 0:04:01  Lr: 0.030000  Loss: 0.1357  Acc@1: 62.5000 (58.5400)  Acc@5: 93.7500 (90.4390)  time: 0.3455  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [3890/4579]  eta: 0:03:57  Lr: 0.030000  Loss: -0.2325  Acc@1: 62.5000 (58.5518)  Acc@5: 93.7500 (90.4379)  time: 0.3441  data: 0.0002  max mem: 2500
Train: Epoch[3/5]  [3900/4579]  eta: 0:03:54  Lr: 0.030000  Loss: -0.0973  Acc@1: 62.5000 (58.5667)  Acc@5: 93.7500 (90.4480)  time: 0.3433  data: 0.0002  max mem: 2500
Train: Epoch[3/5]  [3910/4579]  eta: 0:03:50  Lr: 0.030000  Loss: 0.6034  Acc@1: 62.5000 (58.5704)  Acc@5: 93.7500 (90.4468)  time: 0.3432  data: 0.0002  max mem: 2500
Train: Epoch[3/5]  [3920/4579]  eta: 0:03:47  Lr: 0.030000  Loss: 0.0315  Acc@1: 56.2500 (58.5661)  Acc@5: 87.5000 (90.4457)  time: 0.3435  data: 0.0002  max mem: 2500
Train: Epoch[3/5]  [3930/4579]  eta: 0:03:43  Lr: 0.030000  Loss: 0.3696  Acc@1: 56.2500 (58.5729)  Acc@5: 87.5000 (90.4445)  time: 0.3439  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [3940/4579]  eta: 0:03:40  Lr: 0.030000  Loss: 0.0796  Acc@1: 56.2500 (58.5606)  Acc@5: 93.7500 (90.4434)  time: 0.3439  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [3950/4579]  eta: 0:03:36  Lr: 0.030000  Loss: -0.2022  Acc@1: 62.5000 (58.5817)  Acc@5: 93.7500 (90.4565)  time: 0.3439  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [3960/4579]  eta: 0:03:33  Lr: 0.030000  Loss: 0.4821  Acc@1: 62.5000 (58.5853)  Acc@5: 93.7500 (90.4554)  time: 0.3447  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [3970/4579]  eta: 0:03:29  Lr: 0.030000  Loss: 0.3415  Acc@1: 56.2500 (58.5731)  Acc@5: 93.7500 (90.4684)  time: 0.3460  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [3980/4579]  eta: 0:03:26  Lr: 0.030000  Loss: 0.2898  Acc@1: 56.2500 (58.5845)  Acc@5: 93.7500 (90.4672)  time: 0.3463  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3990/4579]  eta: 0:03:23  Lr: 0.030000  Loss: 0.0797  Acc@1: 56.2500 (58.5802)  Acc@5: 87.5000 (90.4582)  time: 0.3456  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [4000/4579]  eta: 0:03:19  Lr: 0.030000  Loss: 0.4938  Acc@1: 56.2500 (58.5775)  Acc@5: 87.5000 (90.4461)  time: 0.3450  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [4010/4579]  eta: 0:03:16  Lr: 0.030000  Loss: 0.3014  Acc@1: 62.5000 (58.5842)  Acc@5: 87.5000 (90.4466)  time: 0.3451  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [4020/4579]  eta: 0:03:12  Lr: 0.030000  Loss: 0.3704  Acc@1: 56.2500 (58.5939)  Acc@5: 87.5000 (90.4470)  time: 0.3451  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [4030/4579]  eta: 0:03:09  Lr: 0.030000  Loss: 0.5275  Acc@1: 56.2500 (58.5835)  Acc@5: 87.5000 (90.4397)  time: 0.3453  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [4040/4579]  eta: 0:03:05  Lr: 0.030000  Loss: -0.2136  Acc@1: 56.2500 (58.5963)  Acc@5: 93.7500 (90.4479)  time: 0.3450  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [4050/4579]  eta: 0:03:02  Lr: 0.030000  Loss: 0.5698  Acc@1: 56.2500 (58.5874)  Acc@5: 93.7500 (90.4499)  time: 0.3441  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [4060/4579]  eta: 0:02:58  Lr: 0.030000  Loss: 0.1669  Acc@1: 56.2500 (58.5970)  Acc@5: 93.7500 (90.4472)  time: 0.3444  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [4070/4579]  eta: 0:02:55  Lr: 0.030000  Loss: 0.2502  Acc@1: 56.2500 (58.5866)  Acc@5: 87.5000 (90.4507)  time: 0.3447  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [4080/4579]  eta: 0:02:52  Lr: 0.030000  Loss: 0.0611  Acc@1: 62.5000 (58.5978)  Acc@5: 93.7500 (90.4573)  time: 0.3449  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [4090/4579]  eta: 0:02:48  Lr: 0.030000  Loss: 0.3629  Acc@1: 62.5000 (58.6043)  Acc@5: 87.5000 (90.4562)  time: 0.3453  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [4100/4579]  eta: 0:02:45  Lr: 0.030000  Loss: 0.3811  Acc@1: 56.2500 (58.5863)  Acc@5: 87.5000 (90.4581)  time: 0.3446  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [4110/4579]  eta: 0:02:41  Lr: 0.030000  Loss: 0.3621  Acc@1: 56.2500 (58.5761)  Acc@5: 93.7500 (90.4555)  time: 0.3442  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [4120/4579]  eta: 0:02:38  Lr: 0.030000  Loss: 0.2407  Acc@1: 56.2500 (58.5719)  Acc@5: 87.5000 (90.4529)  time: 0.3445  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [4130/4579]  eta: 0:02:34  Lr: 0.030000  Loss: 0.1425  Acc@1: 56.2500 (58.5678)  Acc@5: 87.5000 (90.4548)  time: 0.3446  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [4140/4579]  eta: 0:02:31  Lr: 0.030000  Loss: 0.1205  Acc@1: 62.5000 (58.5773)  Acc@5: 87.5000 (90.4537)  time: 0.3449  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [4150/4579]  eta: 0:02:27  Lr: 0.030000  Loss: -0.0658  Acc@1: 62.5000 (58.5808)  Acc@5: 87.5000 (90.4511)  time: 0.3444  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [4160/4579]  eta: 0:02:24  Lr: 0.030000  Loss: 0.3520  Acc@1: 62.5000 (58.6037)  Acc@5: 87.5000 (90.4530)  time: 0.3442  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [4170/4579]  eta: 0:02:21  Lr: 0.030000  Loss: 0.3401  Acc@1: 62.5000 (58.6085)  Acc@5: 87.5000 (90.4549)  time: 0.3461  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [4180/4579]  eta: 0:02:17  Lr: 0.030000  Loss: 0.1611  Acc@1: 62.5000 (58.6179)  Acc@5: 93.7500 (90.4613)  time: 0.3455  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [4190/4579]  eta: 0:02:14  Lr: 0.030000  Loss: -0.0211  Acc@1: 62.5000 (58.6271)  Acc@5: 93.7500 (90.4617)  time: 0.3433  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [4200/4579]  eta: 0:02:10  Lr: 0.030000  Loss: 0.0226  Acc@1: 62.5000 (58.6319)  Acc@5: 93.7500 (90.4621)  time: 0.3432  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [4210/4579]  eta: 0:02:07  Lr: 0.030000  Loss: 0.3974  Acc@1: 62.5000 (58.6470)  Acc@5: 93.7500 (90.4654)  time: 0.3430  data: 0.0002  max mem: 2500
Train: Epoch[3/5]  [4220/4579]  eta: 0:02:03  Lr: 0.030000  Loss: 0.4131  Acc@1: 62.5000 (58.6487)  Acc@5: 93.7500 (90.4717)  time: 0.3427  data: 0.0002  max mem: 2500
Train: Epoch[3/5]  [4230/4579]  eta: 0:02:00  Lr: 0.030000  Loss: 0.4451  Acc@1: 62.5000 (58.6445)  Acc@5: 87.5000 (90.4662)  time: 0.3424  data: 0.0002  max mem: 2500
Train: Epoch[3/5]  [4240/4579]  eta: 0:01:56  Lr: 0.030000  Loss: 0.5174  Acc@1: 62.5000 (58.6580)  Acc@5: 87.5000 (90.4710)  time: 0.3427  data: 0.0002  max mem: 2500
Train: Epoch[3/5]  [4250/4579]  eta: 0:01:53  Lr: 0.030000  Loss: 0.2059  Acc@1: 62.5000 (58.6583)  Acc@5: 93.7500 (90.4669)  time: 0.3432  data: 0.0002  max mem: 2500
Train: Epoch[3/5]  [4260/4579]  eta: 0:01:49  Lr: 0.030000  Loss: 0.0021  Acc@1: 62.5000 (58.6746)  Acc@5: 93.7500 (90.4703)  time: 0.3432  data: 0.0002  max mem: 2500
Train: Epoch[3/5]  [4270/4579]  eta: 0:01:46  Lr: 0.030000  Loss: 0.5366  Acc@1: 62.5000 (58.6748)  Acc@5: 93.7500 (90.4677)  time: 0.3431  data: 0.0002  max mem: 2500
Train: Epoch[3/5]  [4280/4579]  eta: 0:01:43  Lr: 0.030000  Loss: 0.6728  Acc@1: 56.2500 (58.6647)  Acc@5: 93.7500 (90.4739)  time: 0.3430  data: 0.0002  max mem: 2500
Train: Epoch[3/5]  [4290/4579]  eta: 0:01:39  Lr: 0.030000  Loss: -0.1190  Acc@1: 62.5000 (58.6722)  Acc@5: 93.7500 (90.4728)  time: 0.3439  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [4300/4579]  eta: 0:01:36  Lr: 0.030000  Loss: 0.0959  Acc@1: 62.5000 (58.6927)  Acc@5: 93.7500 (90.4775)  time: 0.3450  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [4310/4579]  eta: 0:01:32  Lr: 0.030000  Loss: 0.3767  Acc@1: 62.5000 (58.6958)  Acc@5: 93.7500 (90.4778)  time: 0.3461  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [4320/4579]  eta: 0:01:29  Lr: 0.030000  Loss: 0.1800  Acc@1: 56.2500 (58.7002)  Acc@5: 87.5000 (90.4782)  time: 0.3467  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [4330/4579]  eta: 0:01:25  Lr: 0.030000  Loss: 0.0888  Acc@1: 56.2500 (58.7004)  Acc@5: 93.7500 (90.4771)  time: 0.3460  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [4340/4579]  eta: 0:01:22  Lr: 0.030000  Loss: 0.3141  Acc@1: 62.5000 (58.7149)  Acc@5: 93.7500 (90.4803)  time: 0.3465  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [4350/4579]  eta: 0:01:18  Lr: 0.030000  Loss: 0.2619  Acc@1: 56.2500 (58.6963)  Acc@5: 93.7500 (90.4806)  time: 0.3469  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [4360/4579]  eta: 0:01:15  Lr: 0.030000  Loss: 0.0883  Acc@1: 56.2500 (58.6978)  Acc@5: 93.7500 (90.4810)  time: 0.3458  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [4370/4579]  eta: 0:01:12  Lr: 0.030000  Loss: 0.2376  Acc@1: 56.2500 (58.6779)  Acc@5: 87.5000 (90.4713)  time: 0.3456  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [4380/4579]  eta: 0:01:08  Lr: 0.030000  Loss: 0.1710  Acc@1: 50.0000 (58.6781)  Acc@5: 87.5000 (90.4617)  time: 0.3465  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [4390/4579]  eta: 0:01:05  Lr: 0.030000  Loss: 0.5670  Acc@1: 56.2500 (58.6768)  Acc@5: 87.5000 (90.4521)  time: 0.3461  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [4400/4579]  eta: 0:01:01  Lr: 0.030000  Loss: 0.2174  Acc@1: 56.2500 (58.6884)  Acc@5: 87.5000 (90.4510)  time: 0.3464  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [4410/4579]  eta: 0:00:58  Lr: 0.030000  Loss: -0.1429  Acc@1: 56.2500 (58.6786)  Acc@5: 87.5000 (90.4429)  time: 0.3473  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [4420/4579]  eta: 0:00:54  Lr: 0.030000  Loss: 0.0305  Acc@1: 56.2500 (58.6759)  Acc@5: 93.7500 (90.4462)  time: 0.3469  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [4430/4579]  eta: 0:00:51  Lr: 0.030000  Loss: 0.2440  Acc@1: 56.2500 (58.6634)  Acc@5: 93.7500 (90.4367)  time: 0.3463  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [4440/4579]  eta: 0:00:47  Lr: 0.030000  Loss: 0.2192  Acc@1: 56.2500 (58.6777)  Acc@5: 87.5000 (90.4343)  time: 0.3465  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [4450/4579]  eta: 0:00:44  Lr: 0.030000  Loss: 0.3121  Acc@1: 68.7500 (58.7003)  Acc@5: 87.5000 (90.4249)  time: 0.3468  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [4460/4579]  eta: 0:00:41  Lr: 0.030000  Loss: 0.0286  Acc@1: 62.5000 (58.7074)  Acc@5: 87.5000 (90.4211)  time: 0.3461  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [4470/4579]  eta: 0:00:37  Lr: 0.030000  Loss: -0.0455  Acc@1: 62.5000 (58.7313)  Acc@5: 93.7500 (90.4314)  time: 0.3462  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [4480/4579]  eta: 0:00:34  Lr: 0.030000  Loss: -0.1390  Acc@1: 68.7500 (58.7383)  Acc@5: 93.7500 (90.4388)  time: 0.3460  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [4490/4579]  eta: 0:00:30  Lr: 0.030000  Loss: 0.3111  Acc@1: 62.5000 (58.7439)  Acc@5: 93.7500 (90.4350)  time: 0.3466  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [4500/4579]  eta: 0:00:27  Lr: 0.030000  Loss: -0.0916  Acc@1: 56.2500 (58.7425)  Acc@5: 93.7500 (90.4382)  time: 0.3466  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [4510/4579]  eta: 0:00:23  Lr: 0.030000  Loss: 0.5984  Acc@1: 56.2500 (58.7342)  Acc@5: 87.5000 (90.4262)  time: 0.3455  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [4520/4579]  eta: 0:00:20  Lr: 0.030000  Loss: -0.2004  Acc@1: 62.5000 (58.7384)  Acc@5: 87.5000 (90.4294)  time: 0.3451  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [4530/4579]  eta: 0:00:16  Lr: 0.030000  Loss: 0.1691  Acc@1: 62.5000 (58.7412)  Acc@5: 93.7500 (90.4367)  time: 0.3448  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [4540/4579]  eta: 0:00:13  Lr: 0.030000  Loss: -0.0488  Acc@1: 62.5000 (58.7522)  Acc@5: 93.7500 (90.4399)  time: 0.3456  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [4550/4579]  eta: 0:00:09  Lr: 0.030000  Loss: 0.2110  Acc@1: 62.5000 (58.7536)  Acc@5: 87.5000 (90.4362)  time: 0.3458  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [4560/4579]  eta: 0:00:06  Lr: 0.030000  Loss: 0.5257  Acc@1: 62.5000 (58.7577)  Acc@5: 87.5000 (90.4366)  time: 0.3451  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [4570/4579]  eta: 0:00:03  Lr: 0.030000  Loss: 0.0310  Acc@1: 56.2500 (58.7481)  Acc@5: 93.7500 (90.4425)  time: 0.3454  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [4578/4579]  eta: 0:00:00  Lr: 0.030000  Loss: -0.1653  Acc@1: 56.2500 (58.7425)  Acc@5: 93.7500 (90.4432)  time: 0.3385  data: 0.0007  max mem: 2500
Train: Epoch[3/5] Total time: 0:26:19 (0.3449 s / it)
{0: {0: 219771, 1: 0, 2: 0, 3: 0, 4: 0}, 1: {0: 219771, 1: 0, 2: 0, 3: 0, 4: 0}, 2: {0: 219771, 1: 0, 2: 0, 3: 0, 4: 0}, 3: {0: 219771, 1: 0, 2: 0, 3: 0, 4: 0}, 4: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 5: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 6: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 7: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 8: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 9: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 10: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 11: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 12: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 13: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 14: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 15: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 16: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 17: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 18: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 19: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}}
Averaged stats: Lr: 0.030000  Loss: -0.1653  Acc@1: 56.2500 (58.7425)  Acc@5: 93.7500 (90.4432)
Train: Epoch[4/5]  [   0/4579]  eta: 0:44:37  Lr: 0.030000  Loss: 0.1164  Acc@1: 75.0000 (75.0000)  Acc@5: 100.0000 (100.0000)  time: 0.5847  data: 0.2370  max mem: 2500
Train: Epoch[4/5]  [  10/4579]  eta: 0:27:49  Lr: 0.030000  Loss: 0.2686  Acc@1: 68.7500 (62.5000)  Acc@5: 93.7500 (90.3409)  time: 0.3655  data: 0.0217  max mem: 2500
Train: Epoch[4/5]  [  20/4579]  eta: 0:26:58  Lr: 0.030000  Loss: -0.0714  Acc@1: 62.5000 (61.0119)  Acc@5: 93.7500 (91.0714)  time: 0.3436  data: 0.0002  max mem: 2500
Train: Epoch[4/5]  [  30/4579]  eta: 0:26:38  Lr: 0.030000  Loss: 0.1981  Acc@1: 62.5000 (61.2903)  Acc@5: 93.7500 (91.9355)  time: 0.3437  data: 0.0002  max mem: 2500
Train: Epoch[4/5]  [  40/4579]  eta: 0:26:26  Lr: 0.030000  Loss: 0.3429  Acc@1: 56.2500 (61.4329)  Acc@5: 93.7500 (91.3110)  time: 0.3436  data: 0.0002  max mem: 2500
Train: Epoch[4/5]  [  50/4579]  eta: 0:26:17  Lr: 0.030000  Loss: 0.0445  Acc@1: 62.5000 (62.3775)  Acc@5: 87.5000 (91.1765)  time: 0.3437  data: 0.0002  max mem: 2500
Train: Epoch[4/5]  [  60/4579]  eta: 0:26:10  Lr: 0.030000  Loss: 0.1682  Acc@1: 62.5000 (62.5000)  Acc@5: 87.5000 (90.9836)  time: 0.3435  data: 0.0002  max mem: 2500
Train: Epoch[4/5]  [  70/4579]  eta: 0:26:04  Lr: 0.030000  Loss: -0.2078  Acc@1: 62.5000 (62.6761)  Acc@5: 87.5000 (90.9331)  time: 0.3436  data: 0.0002  max mem: 2500
Train: Epoch[4/5]  [  80/4579]  eta: 0:25:59  Lr: 0.030000  Loss: 0.6746  Acc@1: 56.2500 (62.3457)  Acc@5: 93.7500 (91.2037)  time: 0.3437  data: 0.0002  max mem: 2500
Train: Epoch[4/5]  [  90/4579]  eta: 0:25:54  Lr: 0.030000  Loss: 0.0793  Acc@1: 56.2500 (62.2253)  Acc@5: 93.7500 (91.1401)  time: 0.3437  data: 0.0002  max mem: 2500
Train: Epoch[4/5]  [ 100/4579]  eta: 0:25:50  Lr: 0.030000  Loss: 0.2371  Acc@1: 62.5000 (62.2525)  Acc@5: 87.5000 (91.0891)  time: 0.3446  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [ 110/4579]  eta: 0:25:46  Lr: 0.030000  Loss: 0.0447  Acc@1: 56.2500 (61.9369)  Acc@5: 87.5000 (90.7658)  time: 0.3452  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 120/4579]  eta: 0:25:43  Lr: 0.030000  Loss: 0.2253  Acc@1: 56.2500 (61.4153)  Acc@5: 87.5000 (90.4959)  time: 0.3456  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 130/4579]  eta: 0:25:39  Lr: 0.030000  Loss: 0.1340  Acc@1: 56.2500 (61.1641)  Acc@5: 87.5000 (90.6966)  time: 0.3457  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 140/4579]  eta: 0:25:35  Lr: 0.030000  Loss: -0.0845  Acc@1: 56.2500 (60.9043)  Acc@5: 93.7500 (90.8688)  time: 0.3452  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [ 150/4579]  eta: 0:25:32  Lr: 0.030000  Loss: 0.2395  Acc@1: 56.2500 (61.0513)  Acc@5: 93.7500 (90.6871)  time: 0.3457  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [ 160/4579]  eta: 0:25:28  Lr: 0.030000  Loss: 0.3936  Acc@1: 62.5000 (61.1025)  Acc@5: 87.5000 (90.5668)  time: 0.3458  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 170/4579]  eta: 0:25:24  Lr: 0.030000  Loss: 0.2693  Acc@1: 62.5000 (61.0380)  Acc@5: 87.5000 (90.4240)  time: 0.3451  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 180/4579]  eta: 0:25:21  Lr: 0.030000  Loss: 0.0368  Acc@1: 62.5000 (61.0843)  Acc@5: 93.7500 (90.6077)  time: 0.3448  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 190/4579]  eta: 0:25:17  Lr: 0.030000  Loss: 0.4401  Acc@1: 62.5000 (61.1257)  Acc@5: 93.7500 (90.4777)  time: 0.3453  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 200/4579]  eta: 0:25:14  Lr: 0.030000  Loss: 0.2577  Acc@1: 62.5000 (61.3495)  Acc@5: 87.5000 (90.4851)  time: 0.3459  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [ 210/4579]  eta: 0:25:10  Lr: 0.030000  Loss: 0.3241  Acc@1: 56.2500 (61.0190)  Acc@5: 87.5000 (90.4917)  time: 0.3455  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [ 220/4579]  eta: 0:25:07  Lr: 0.030000  Loss: 0.4207  Acc@1: 56.2500 (61.1425)  Acc@5: 93.7500 (90.5826)  time: 0.3458  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 230/4579]  eta: 0:25:03  Lr: 0.030000  Loss: 0.2091  Acc@1: 62.5000 (60.9307)  Acc@5: 93.7500 (90.5574)  time: 0.3455  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 240/4579]  eta: 0:25:00  Lr: 0.030000  Loss: 0.2386  Acc@1: 56.2500 (60.8662)  Acc@5: 93.7500 (90.5861)  time: 0.3445  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 250/4579]  eta: 0:24:56  Lr: 0.030000  Loss: 0.6612  Acc@1: 56.2500 (60.8566)  Acc@5: 93.7500 (90.6624)  time: 0.3443  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 260/4579]  eta: 0:24:52  Lr: 0.030000  Loss: 0.0382  Acc@1: 62.5000 (61.0393)  Acc@5: 93.7500 (90.8764)  time: 0.3443  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [ 270/4579]  eta: 0:24:48  Lr: 0.030000  Loss: 0.4049  Acc@1: 56.2500 (60.7472)  Acc@5: 93.7500 (90.7057)  time: 0.3444  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 280/4579]  eta: 0:24:45  Lr: 0.030000  Loss: -0.0201  Acc@1: 56.2500 (60.7874)  Acc@5: 87.5000 (90.8363)  time: 0.3442  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 290/4579]  eta: 0:24:41  Lr: 0.030000  Loss: 0.4610  Acc@1: 56.2500 (60.7174)  Acc@5: 93.7500 (90.8505)  time: 0.3446  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 300/4579]  eta: 0:24:38  Lr: 0.030000  Loss: 0.3221  Acc@1: 56.2500 (60.7558)  Acc@5: 87.5000 (90.8638)  time: 0.3453  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 310/4579]  eta: 0:24:34  Lr: 0.030000  Loss: 0.3347  Acc@1: 56.2500 (60.5707)  Acc@5: 87.5000 (90.7556)  time: 0.3452  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 320/4579]  eta: 0:24:31  Lr: 0.030000  Loss: 0.1408  Acc@1: 62.5000 (60.7282)  Acc@5: 87.5000 (90.8294)  time: 0.3447  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 330/4579]  eta: 0:24:27  Lr: 0.030000  Loss: 0.0531  Acc@1: 62.5000 (60.5551)  Acc@5: 87.5000 (90.6344)  time: 0.3445  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [ 340/4579]  eta: 0:24:24  Lr: 0.030000  Loss: 0.4851  Acc@1: 56.2500 (60.4839)  Acc@5: 87.5000 (90.6158)  time: 0.3445  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [ 350/4579]  eta: 0:24:20  Lr: 0.030000  Loss: 0.1682  Acc@1: 62.5000 (60.5947)  Acc@5: 93.7500 (90.6517)  time: 0.3444  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [ 360/4579]  eta: 0:24:16  Lr: 0.030000  Loss: 0.1557  Acc@1: 62.5000 (60.5090)  Acc@5: 93.7500 (90.5644)  time: 0.3445  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [ 370/4579]  eta: 0:24:13  Lr: 0.030000  Loss: 0.2469  Acc@1: 56.2500 (60.4111)  Acc@5: 87.5000 (90.5997)  time: 0.3446  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [ 380/4579]  eta: 0:24:09  Lr: 0.030000  Loss: 0.1810  Acc@1: 56.2500 (60.3839)  Acc@5: 93.7500 (90.5512)  time: 0.3443  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [ 390/4579]  eta: 0:24:06  Lr: 0.030000  Loss: 0.0923  Acc@1: 56.2500 (60.3101)  Acc@5: 87.5000 (90.5211)  time: 0.3454  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [ 400/4579]  eta: 0:24:02  Lr: 0.030000  Loss: 0.3943  Acc@1: 56.2500 (60.2400)  Acc@5: 87.5000 (90.5081)  time: 0.3445  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [ 410/4579]  eta: 0:23:59  Lr: 0.030000  Loss: 0.1718  Acc@1: 56.2500 (60.2342)  Acc@5: 93.7500 (90.6022)  time: 0.3425  data: 0.0002  max mem: 2500
Train: Epoch[4/5]  [ 420/4579]  eta: 0:23:55  Lr: 0.030000  Loss: 0.0804  Acc@1: 56.2500 (60.2732)  Acc@5: 93.7500 (90.7215)  time: 0.3424  data: 0.0002  max mem: 2500
Train: Epoch[4/5]  [ 430/4579]  eta: 0:23:51  Lr: 0.030000  Loss: 0.3100  Acc@1: 56.2500 (60.3248)  Acc@5: 93.7500 (90.7483)  time: 0.3424  data: 0.0002  max mem: 2500
Train: Epoch[4/5]  [ 440/4579]  eta: 0:23:47  Lr: 0.030000  Loss: 0.2142  Acc@1: 62.5000 (60.4450)  Acc@5: 93.7500 (90.7738)  time: 0.3427  data: 0.0002  max mem: 2500
Train: Epoch[4/5]  [ 450/4579]  eta: 0:23:44  Lr: 0.030000  Loss: 0.2227  Acc@1: 62.5000 (60.4490)  Acc@5: 93.7500 (90.7705)  time: 0.3427  data: 0.0002  max mem: 2500
Train: Epoch[4/5]  [ 460/4579]  eta: 0:23:40  Lr: 0.030000  Loss: -0.0243  Acc@1: 56.2500 (60.4257)  Acc@5: 87.5000 (90.7674)  time: 0.3427  data: 0.0002  max mem: 2500
Train: Epoch[4/5]  [ 470/4579]  eta: 0:23:37  Lr: 0.030000  Loss: 0.4060  Acc@1: 56.2500 (60.2044)  Acc@5: 87.5000 (90.6980)  time: 0.3432  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [ 480/4579]  eta: 0:23:33  Lr: 0.030000  Loss: 0.0510  Acc@1: 56.2500 (60.1481)  Acc@5: 87.5000 (90.6835)  time: 0.3446  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [ 490/4579]  eta: 0:23:30  Lr: 0.030000  Loss: 0.4033  Acc@1: 56.2500 (59.9414)  Acc@5: 93.7500 (90.6823)  time: 0.3454  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [ 500/4579]  eta: 0:23:26  Lr: 0.030000  Loss: 0.1207  Acc@1: 56.2500 (59.8303)  Acc@5: 93.7500 (90.7061)  time: 0.3447  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [ 510/4579]  eta: 0:23:23  Lr: 0.030000  Loss: 0.1324  Acc@1: 56.2500 (59.7236)  Acc@5: 93.7500 (90.7167)  time: 0.3439  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [ 520/4579]  eta: 0:23:19  Lr: 0.030000  Loss: 0.2800  Acc@1: 56.2500 (59.7529)  Acc@5: 93.7500 (90.7270)  time: 0.3446  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 530/4579]  eta: 0:23:16  Lr: 0.030000  Loss: -0.0067  Acc@1: 62.5000 (59.8635)  Acc@5: 93.7500 (90.7721)  time: 0.3454  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 540/4579]  eta: 0:23:12  Lr: 0.030000  Loss: -0.0573  Acc@1: 62.5000 (59.9584)  Acc@5: 93.7500 (90.7810)  time: 0.3449  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 550/4579]  eta: 0:23:09  Lr: 0.030000  Loss: -0.0327  Acc@1: 62.5000 (59.9251)  Acc@5: 93.7500 (90.8008)  time: 0.3455  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 560/4579]  eta: 0:23:06  Lr: 0.030000  Loss: 0.3319  Acc@1: 56.2500 (59.9153)  Acc@5: 87.5000 (90.7308)  time: 0.3458  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 570/4579]  eta: 0:23:02  Lr: 0.030000  Loss: 0.2678  Acc@1: 56.2500 (59.9168)  Acc@5: 87.5000 (90.7290)  time: 0.3445  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 580/4579]  eta: 0:22:59  Lr: 0.030000  Loss: 0.2286  Acc@1: 62.5000 (59.9720)  Acc@5: 87.5000 (90.7272)  time: 0.3445  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [ 590/4579]  eta: 0:22:55  Lr: 0.030000  Loss: 0.1433  Acc@1: 62.5000 (60.0148)  Acc@5: 93.7500 (90.7466)  time: 0.3450  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 600/4579]  eta: 0:22:52  Lr: 0.030000  Loss: -0.0777  Acc@1: 62.5000 (59.9834)  Acc@5: 93.7500 (90.7654)  time: 0.3448  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 610/4579]  eta: 0:22:48  Lr: 0.030000  Loss: 0.2064  Acc@1: 56.2500 (59.9836)  Acc@5: 87.5000 (90.7631)  time: 0.3447  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [ 620/4579]  eta: 0:22:45  Lr: 0.030000  Loss: 0.1830  Acc@1: 56.2500 (59.9134)  Acc@5: 87.5000 (90.6804)  time: 0.3444  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [ 630/4579]  eta: 0:22:41  Lr: 0.030000  Loss: 0.1960  Acc@1: 62.5000 (59.9941)  Acc@5: 93.7500 (90.7092)  time: 0.3443  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [ 640/4579]  eta: 0:22:38  Lr: 0.030000  Loss: 0.0572  Acc@1: 62.5000 (60.0234)  Acc@5: 93.7500 (90.7274)  time: 0.3447  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [ 650/4579]  eta: 0:22:34  Lr: 0.030000  Loss: 0.0982  Acc@1: 56.2500 (59.9846)  Acc@5: 93.7500 (90.7546)  time: 0.3444  data: 0.0002  max mem: 2500
Train: Epoch[4/5]  [ 660/4579]  eta: 0:22:31  Lr: 0.030000  Loss: 0.3051  Acc@1: 62.5000 (60.0416)  Acc@5: 93.7500 (90.7621)  time: 0.3440  data: 0.0002  max mem: 2500
Train: Epoch[4/5]  [ 670/4579]  eta: 0:22:27  Lr: 0.030000  Loss: 0.4011  Acc@1: 68.7500 (60.1062)  Acc@5: 93.7500 (90.8066)  time: 0.3432  data: 0.0002  max mem: 2500
Train: Epoch[4/5]  [ 680/4579]  eta: 0:22:24  Lr: 0.030000  Loss: 0.3512  Acc@1: 56.2500 (60.0496)  Acc@5: 93.7500 (90.7764)  time: 0.3430  data: 0.0002  max mem: 2500
Train: Epoch[4/5]  [ 690/4579]  eta: 0:22:20  Lr: 0.030000  Loss: 0.0860  Acc@1: 56.2500 (60.0398)  Acc@5: 87.5000 (90.7652)  time: 0.3437  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [ 700/4579]  eta: 0:22:17  Lr: 0.030000  Loss: 0.2826  Acc@1: 62.5000 (60.0125)  Acc@5: 87.5000 (90.7275)  time: 0.3460  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 710/4579]  eta: 0:22:14  Lr: 0.030000  Loss: 0.5145  Acc@1: 56.2500 (59.9859)  Acc@5: 93.7500 (90.7261)  time: 0.3461  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 720/4579]  eta: 0:22:10  Lr: 0.030000  Loss: 0.1306  Acc@1: 56.2500 (59.9601)  Acc@5: 93.7500 (90.7247)  time: 0.3439  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [ 730/4579]  eta: 0:22:07  Lr: 0.030000  Loss: 0.2603  Acc@1: 56.2500 (59.9521)  Acc@5: 93.7500 (90.7661)  time: 0.3443  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [ 740/4579]  eta: 0:22:03  Lr: 0.030000  Loss: 0.0721  Acc@1: 56.2500 (59.9865)  Acc@5: 93.7500 (90.8316)  time: 0.3446  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [ 750/4579]  eta: 0:22:00  Lr: 0.030000  Loss: 0.5529  Acc@1: 62.5000 (59.9617)  Acc@5: 93.7500 (90.8372)  time: 0.3450  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [ 760/4579]  eta: 0:21:56  Lr: 0.030000  Loss: 0.1808  Acc@1: 62.5000 (60.0361)  Acc@5: 93.7500 (90.8755)  time: 0.3444  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [ 770/4579]  eta: 0:21:53  Lr: 0.030000  Loss: 0.1449  Acc@1: 62.5000 (59.9546)  Acc@5: 93.7500 (90.9047)  time: 0.3430  data: 0.0002  max mem: 2500
Train: Epoch[4/5]  [ 780/4579]  eta: 0:21:49  Lr: 0.030000  Loss: 0.4274  Acc@1: 50.0000 (59.8992)  Acc@5: 87.5000 (90.8451)  time: 0.3428  data: 0.0002  max mem: 2500
Train: Epoch[4/5]  [ 790/4579]  eta: 0:21:46  Lr: 0.030000  Loss: 0.3421  Acc@1: 56.2500 (59.9399)  Acc@5: 87.5000 (90.8502)  time: 0.3432  data: 0.0002  max mem: 2500
Train: Epoch[4/5]  [ 800/4579]  eta: 0:21:42  Lr: 0.030000  Loss: 0.0384  Acc@1: 62.5000 (59.9719)  Acc@5: 87.5000 (90.8006)  time: 0.3435  data: 0.0002  max mem: 2500
Train: Epoch[4/5]  [ 810/4579]  eta: 0:21:39  Lr: 0.030000  Loss: 0.1638  Acc@1: 62.5000 (60.0185)  Acc@5: 87.5000 (90.7830)  time: 0.3435  data: 0.0002  max mem: 2500
Train: Epoch[4/5]  [ 820/4579]  eta: 0:21:35  Lr: 0.030000  Loss: 0.0956  Acc@1: 62.5000 (60.0868)  Acc@5: 87.5000 (90.7734)  time: 0.3439  data: 0.0002  max mem: 2500
Train: Epoch[4/5]  [ 830/4579]  eta: 0:21:32  Lr: 0.030000  Loss: 0.2909  Acc@1: 62.5000 (60.0632)  Acc@5: 93.7500 (90.7867)  time: 0.3452  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [ 840/4579]  eta: 0:21:28  Lr: 0.030000  Loss: -0.1959  Acc@1: 62.5000 (60.1070)  Acc@5: 93.7500 (90.8219)  time: 0.3470  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 850/4579]  eta: 0:21:25  Lr: 0.030000  Loss: -0.0355  Acc@1: 56.2500 (60.0617)  Acc@5: 93.7500 (90.8196)  time: 0.3472  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 860/4579]  eta: 0:21:22  Lr: 0.030000  Loss: 0.0604  Acc@1: 62.5000 (60.1626)  Acc@5: 93.7500 (90.8464)  time: 0.3459  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 870/4579]  eta: 0:21:18  Lr: 0.030000  Loss: 0.1293  Acc@1: 62.5000 (60.2110)  Acc@5: 93.7500 (90.8941)  time: 0.3465  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 880/4579]  eta: 0:21:15  Lr: 0.030000  Loss: -0.0893  Acc@1: 56.2500 (60.1731)  Acc@5: 93.7500 (90.8839)  time: 0.3466  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 890/4579]  eta: 0:21:12  Lr: 0.030000  Loss: 0.4569  Acc@1: 56.2500 (60.1992)  Acc@5: 93.7500 (90.8880)  time: 0.3456  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [ 900/4579]  eta: 0:21:08  Lr: 0.030000  Loss: 0.6091  Acc@1: 62.5000 (60.2317)  Acc@5: 93.7500 (90.9198)  time: 0.3468  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 910/4579]  eta: 0:21:05  Lr: 0.030000  Loss: -0.1694  Acc@1: 68.7500 (60.3252)  Acc@5: 93.7500 (90.9303)  time: 0.3469  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [ 920/4579]  eta: 0:21:01  Lr: 0.030000  Loss: 0.1155  Acc@1: 62.5000 (60.3488)  Acc@5: 93.7500 (90.9338)  time: 0.3455  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [ 930/4579]  eta: 0:20:58  Lr: 0.030000  Loss: 0.1948  Acc@1: 56.2500 (60.2779)  Acc@5: 87.5000 (90.9036)  time: 0.3453  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [ 940/4579]  eta: 0:20:54  Lr: 0.030000  Loss: 0.1400  Acc@1: 56.2500 (60.2750)  Acc@5: 87.5000 (90.9006)  time: 0.3453  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [ 950/4579]  eta: 0:20:51  Lr: 0.030000  Loss: 0.3455  Acc@1: 56.2500 (60.2524)  Acc@5: 87.5000 (90.8780)  time: 0.3451  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [ 960/4579]  eta: 0:20:48  Lr: 0.030000  Loss: 0.2929  Acc@1: 56.2500 (60.2693)  Acc@5: 87.5000 (90.8689)  time: 0.3452  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [ 970/4579]  eta: 0:20:44  Lr: 0.030000  Loss: 0.1207  Acc@1: 56.2500 (60.2665)  Acc@5: 87.5000 (90.8342)  time: 0.3446  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [ 980/4579]  eta: 0:20:41  Lr: 0.030000  Loss: 0.3583  Acc@1: 62.5000 (60.2574)  Acc@5: 93.7500 (90.8321)  time: 0.3438  data: 0.0002  max mem: 2500
Train: Epoch[4/5]  [ 990/4579]  eta: 0:20:37  Lr: 0.030000  Loss: 0.1921  Acc@1: 62.5000 (60.2674)  Acc@5: 93.7500 (90.8489)  time: 0.3434  data: 0.0002  max mem: 2500
Train: Epoch[4/5]  [1000/4579]  eta: 0:20:34  Lr: 0.030000  Loss: 0.3970  Acc@1: 56.2500 (60.2023)  Acc@5: 87.5000 (90.8342)  time: 0.3433  data: 0.0002  max mem: 2500
Train: Epoch[4/5]  [1010/4579]  eta: 0:20:30  Lr: 0.030000  Loss: 0.4690  Acc@1: 50.0000 (60.1261)  Acc@5: 87.5000 (90.8259)  time: 0.3434  data: 0.0002  max mem: 2500
Train: Epoch[4/5]  [1020/4579]  eta: 0:20:27  Lr: 0.030000  Loss: 0.2793  Acc@1: 56.2500 (60.1432)  Acc@5: 93.7500 (90.8117)  time: 0.3447  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [1030/4579]  eta: 0:20:23  Lr: 0.030000  Loss: 0.0936  Acc@1: 62.5000 (60.1722)  Acc@5: 93.7500 (90.8220)  time: 0.3455  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1040/4579]  eta: 0:20:20  Lr: 0.030000  Loss: 0.3255  Acc@1: 62.5000 (60.1105)  Acc@5: 87.5000 (90.7961)  time: 0.3445  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1050/4579]  eta: 0:20:16  Lr: 0.030000  Loss: 0.5097  Acc@1: 50.0000 (60.0916)  Acc@5: 87.5000 (90.7945)  time: 0.3460  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1060/4579]  eta: 0:20:13  Lr: 0.030000  Loss: 0.4119  Acc@1: 56.2500 (60.0907)  Acc@5: 93.7500 (90.8223)  time: 0.3463  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1070/4579]  eta: 0:20:10  Lr: 0.030000  Loss: 0.1653  Acc@1: 56.2500 (60.0490)  Acc@5: 93.7500 (90.8380)  time: 0.3449  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1080/4579]  eta: 0:20:06  Lr: 0.030000  Loss: -0.0395  Acc@1: 50.0000 (60.0312)  Acc@5: 93.7500 (90.8360)  time: 0.3454  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1090/4579]  eta: 0:20:03  Lr: 0.030000  Loss: 0.1449  Acc@1: 56.2500 (59.9851)  Acc@5: 87.5000 (90.7997)  time: 0.3450  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1100/4579]  eta: 0:19:59  Lr: 0.030000  Loss: 0.0623  Acc@1: 56.2500 (59.9739)  Acc@5: 93.7500 (90.8265)  time: 0.3446  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1110/4579]  eta: 0:19:56  Lr: 0.030000  Loss: 0.1853  Acc@1: 62.5000 (60.0079)  Acc@5: 93.7500 (90.7853)  time: 0.3451  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [1120/4579]  eta: 0:19:52  Lr: 0.030000  Loss: 0.1869  Acc@1: 56.2500 (60.0468)  Acc@5: 93.7500 (90.8118)  time: 0.3460  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1130/4579]  eta: 0:19:49  Lr: 0.030000  Loss: 0.0248  Acc@1: 56.2500 (60.0740)  Acc@5: 93.7500 (90.8101)  time: 0.3461  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1140/4579]  eta: 0:19:46  Lr: 0.030000  Loss: 0.4724  Acc@1: 62.5000 (60.0296)  Acc@5: 93.7500 (90.7866)  time: 0.3451  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [1150/4579]  eta: 0:19:42  Lr: 0.030000  Loss: 0.3008  Acc@1: 56.2500 (60.0619)  Acc@5: 93.7500 (90.8069)  time: 0.3451  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [1160/4579]  eta: 0:19:39  Lr: 0.030000  Loss: 0.3498  Acc@1: 56.2500 (60.0452)  Acc@5: 93.7500 (90.7784)  time: 0.3452  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [1170/4579]  eta: 0:19:35  Lr: 0.030000  Loss: -0.0121  Acc@1: 56.2500 (60.0235)  Acc@5: 87.5000 (90.7558)  time: 0.3453  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [1180/4579]  eta: 0:19:32  Lr: 0.030000  Loss: 0.4871  Acc@1: 56.2500 (60.0021)  Acc@5: 93.7500 (90.7705)  time: 0.3461  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1190/4579]  eta: 0:19:28  Lr: 0.030000  Loss: 0.5191  Acc@1: 62.5000 (60.0178)  Acc@5: 93.7500 (90.7851)  time: 0.3456  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [1200/4579]  eta: 0:19:25  Lr: 0.030000  Loss: 0.1438  Acc@1: 68.7500 (60.0697)  Acc@5: 93.7500 (90.8045)  time: 0.3436  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [1210/4579]  eta: 0:19:21  Lr: 0.030000  Loss: -0.0228  Acc@1: 62.5000 (60.0279)  Acc@5: 93.7500 (90.8031)  time: 0.3434  data: 0.0002  max mem: 2500
Train: Epoch[4/5]  [1220/4579]  eta: 0:19:18  Lr: 0.030000  Loss: 0.1890  Acc@1: 50.0000 (59.9816)  Acc@5: 93.7500 (90.8170)  time: 0.3436  data: 0.0002  max mem: 2500
Train: Epoch[4/5]  [1230/4579]  eta: 0:19:14  Lr: 0.030000  Loss: -0.1138  Acc@1: 56.2500 (60.0477)  Acc@5: 93.7500 (90.8408)  time: 0.3434  data: 0.0002  max mem: 2500
Train: Epoch[4/5]  [1240/4579]  eta: 0:19:11  Lr: 0.030000  Loss: 0.1420  Acc@1: 62.5000 (60.0222)  Acc@5: 93.7500 (90.8290)  time: 0.3433  data: 0.0002  max mem: 2500
Train: Epoch[4/5]  [1250/4579]  eta: 0:19:07  Lr: 0.030000  Loss: 0.3497  Acc@1: 56.2500 (60.0320)  Acc@5: 93.7500 (90.8523)  time: 0.3433  data: 0.0002  max mem: 2500
Train: Epoch[4/5]  [1260/4579]  eta: 0:19:04  Lr: 0.030000  Loss: 0.1742  Acc@1: 56.2500 (60.0416)  Acc@5: 93.7500 (90.8505)  time: 0.3441  data: 0.0002  max mem: 2500
Train: Epoch[4/5]  [1270/4579]  eta: 0:19:01  Lr: 0.030000  Loss: 0.0966  Acc@1: 62.5000 (60.1003)  Acc@5: 87.5000 (90.8487)  time: 0.3452  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1280/4579]  eta: 0:18:57  Lr: 0.030000  Loss: 0.5023  Acc@1: 62.5000 (60.0947)  Acc@5: 87.5000 (90.8372)  time: 0.3458  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1290/4579]  eta: 0:18:54  Lr: 0.030000  Loss: 0.1336  Acc@1: 62.5000 (60.1084)  Acc@5: 87.5000 (90.8114)  time: 0.3456  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [1300/4579]  eta: 0:18:50  Lr: 0.030000  Loss: 0.0724  Acc@1: 56.2500 (60.1076)  Acc@5: 93.7500 (90.8244)  time: 0.3449  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1310/4579]  eta: 0:18:47  Lr: 0.030000  Loss: -0.0548  Acc@1: 56.2500 (60.1688)  Acc@5: 93.7500 (90.8371)  time: 0.3460  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [1320/4579]  eta: 0:18:43  Lr: 0.030000  Loss: 0.0319  Acc@1: 62.5000 (60.1628)  Acc@5: 93.7500 (90.8450)  time: 0.3471  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [1330/4579]  eta: 0:18:40  Lr: 0.030000  Loss: 0.2829  Acc@1: 62.5000 (60.1803)  Acc@5: 93.7500 (90.8480)  time: 0.3474  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1340/4579]  eta: 0:18:37  Lr: 0.030000  Loss: 0.2515  Acc@1: 62.5000 (60.1603)  Acc@5: 87.5000 (90.8324)  time: 0.3460  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1350/4579]  eta: 0:18:33  Lr: 0.030000  Loss: 0.0750  Acc@1: 62.5000 (60.2147)  Acc@5: 93.7500 (90.8586)  time: 0.3446  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1360/4579]  eta: 0:18:30  Lr: 0.030000  Loss: 0.1779  Acc@1: 62.5000 (60.2039)  Acc@5: 93.7500 (90.8707)  time: 0.3451  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1370/4579]  eta: 0:18:26  Lr: 0.030000  Loss: 0.2765  Acc@1: 56.2500 (60.2070)  Acc@5: 87.5000 (90.8598)  time: 0.3449  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1380/4579]  eta: 0:18:23  Lr: 0.030000  Loss: -0.2270  Acc@1: 56.2500 (60.1964)  Acc@5: 87.5000 (90.8581)  time: 0.3443  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1390/4579]  eta: 0:18:19  Lr: 0.030000  Loss: 0.0798  Acc@1: 56.2500 (60.1815)  Acc@5: 87.5000 (90.8384)  time: 0.3445  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1400/4579]  eta: 0:18:16  Lr: 0.030000  Loss: 0.7100  Acc@1: 56.2500 (60.1535)  Acc@5: 87.5000 (90.8191)  time: 0.3449  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [1410/4579]  eta: 0:18:12  Lr: 0.030000  Loss: 0.3678  Acc@1: 56.2500 (60.1568)  Acc@5: 87.5000 (90.8088)  time: 0.3448  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [1420/4579]  eta: 0:18:09  Lr: 0.030000  Loss: 0.1047  Acc@1: 50.0000 (60.1073)  Acc@5: 87.5000 (90.7855)  time: 0.3443  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [1430/4579]  eta: 0:18:05  Lr: 0.030000  Loss: 0.0414  Acc@1: 62.5000 (60.1677)  Acc@5: 87.5000 (90.7932)  time: 0.3437  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [1440/4579]  eta: 0:18:02  Lr: 0.030000  Loss: 0.1858  Acc@1: 68.7500 (60.2446)  Acc@5: 87.5000 (90.7790)  time: 0.3435  data: 0.0002  max mem: 2500
Train: Epoch[4/5]  [1450/4579]  eta: 0:17:59  Lr: 0.030000  Loss: 0.4809  Acc@1: 68.7500 (60.2645)  Acc@5: 87.5000 (90.7564)  time: 0.3436  data: 0.0002  max mem: 2500
Train: Epoch[4/5]  [1460/4579]  eta: 0:17:55  Lr: 0.030000  Loss: -0.0399  Acc@1: 62.5000 (60.2883)  Acc@5: 93.7500 (90.7897)  time: 0.3460  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1470/4579]  eta: 0:17:52  Lr: 0.030000  Loss: 0.3899  Acc@1: 62.5000 (60.2991)  Acc@5: 93.7500 (90.7758)  time: 0.3479  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [1480/4579]  eta: 0:17:48  Lr: 0.030000  Loss: 0.2572  Acc@1: 56.2500 (60.2380)  Acc@5: 87.5000 (90.7453)  time: 0.3468  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [1490/4579]  eta: 0:17:45  Lr: 0.030000  Loss: -0.0582  Acc@1: 56.2500 (60.2783)  Acc@5: 87.5000 (90.7570)  time: 0.3452  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1500/4579]  eta: 0:17:41  Lr: 0.030000  Loss: 0.3780  Acc@1: 62.5000 (60.2723)  Acc@5: 93.7500 (90.7520)  time: 0.3446  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [1510/4579]  eta: 0:17:38  Lr: 0.030000  Loss: 0.2018  Acc@1: 62.5000 (60.2664)  Acc@5: 87.5000 (90.7263)  time: 0.3445  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [1520/4579]  eta: 0:17:35  Lr: 0.030000  Loss: 0.3448  Acc@1: 56.2500 (60.2564)  Acc@5: 87.5000 (90.7257)  time: 0.3443  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [1530/4579]  eta: 0:17:31  Lr: 0.030000  Loss: 0.0866  Acc@1: 56.2500 (60.2588)  Acc@5: 87.5000 (90.7169)  time: 0.3445  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [1540/4579]  eta: 0:17:28  Lr: 0.030000  Loss: -0.2021  Acc@1: 62.5000 (60.2693)  Acc@5: 93.7500 (90.7528)  time: 0.3437  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [1550/4579]  eta: 0:17:24  Lr: 0.030000  Loss: 0.3028  Acc@1: 62.5000 (60.2635)  Acc@5: 93.7500 (90.7681)  time: 0.3427  data: 0.0002  max mem: 2500
Train: Epoch[4/5]  [1560/4579]  eta: 0:17:21  Lr: 0.030000  Loss: 0.6298  Acc@1: 62.5000 (60.2498)  Acc@5: 93.7500 (90.7431)  time: 0.3426  data: 0.0002  max mem: 2500
Train: Epoch[4/5]  [1570/4579]  eta: 0:17:17  Lr: 0.030000  Loss: 0.2308  Acc@1: 56.2500 (60.2363)  Acc@5: 87.5000 (90.7264)  time: 0.3427  data: 0.0002  max mem: 2500
Train: Epoch[4/5]  [1580/4579]  eta: 0:17:14  Lr: 0.030000  Loss: -0.2721  Acc@1: 68.7500 (60.2902)  Acc@5: 87.5000 (90.7456)  time: 0.3428  data: 0.0002  max mem: 2500
Train: Epoch[4/5]  [1590/4579]  eta: 0:17:10  Lr: 0.030000  Loss: 0.3620  Acc@1: 62.5000 (60.2648)  Acc@5: 93.7500 (90.7291)  time: 0.3427  data: 0.0002  max mem: 2500
Train: Epoch[4/5]  [1600/4579]  eta: 0:17:07  Lr: 0.030000  Loss: 0.3250  Acc@1: 56.2500 (60.2670)  Acc@5: 87.5000 (90.7167)  time: 0.3435  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [1610/4579]  eta: 0:17:03  Lr: 0.030000  Loss: 0.2223  Acc@1: 62.5000 (60.2848)  Acc@5: 87.5000 (90.7239)  time: 0.3454  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1620/4579]  eta: 0:17:00  Lr: 0.030000  Loss: -0.0427  Acc@1: 62.5000 (60.3023)  Acc@5: 93.7500 (90.7272)  time: 0.3474  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1630/4579]  eta: 0:16:56  Lr: 0.030000  Loss: 0.3912  Acc@1: 62.5000 (60.3158)  Acc@5: 93.7500 (90.7495)  time: 0.3467  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1640/4579]  eta: 0:16:53  Lr: 0.030000  Loss: -0.0179  Acc@1: 62.5000 (60.2986)  Acc@5: 93.7500 (90.7183)  time: 0.3449  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [1650/4579]  eta: 0:16:50  Lr: 0.030000  Loss: 0.1404  Acc@1: 62.5000 (60.3119)  Acc@5: 87.5000 (90.7253)  time: 0.3453  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1660/4579]  eta: 0:16:46  Lr: 0.030000  Loss: 0.3579  Acc@1: 56.2500 (60.3025)  Acc@5: 93.7500 (90.7247)  time: 0.3455  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1670/4579]  eta: 0:16:43  Lr: 0.030000  Loss: 0.2802  Acc@1: 62.5000 (60.3531)  Acc@5: 93.7500 (90.7353)  time: 0.3458  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1680/4579]  eta: 0:16:39  Lr: 0.030000  Loss: 0.4480  Acc@1: 62.5000 (60.3324)  Acc@5: 87.5000 (90.7124)  time: 0.3459  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1690/4579]  eta: 0:16:36  Lr: 0.030000  Loss: -0.1221  Acc@1: 50.0000 (60.3009)  Acc@5: 87.5000 (90.6823)  time: 0.3452  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1700/4579]  eta: 0:16:32  Lr: 0.030000  Loss: 0.2350  Acc@1: 50.0000 (60.2623)  Acc@5: 87.5000 (90.6856)  time: 0.3464  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1710/4579]  eta: 0:16:29  Lr: 0.030000  Loss: 0.3942  Acc@1: 56.2500 (60.2827)  Acc@5: 93.7500 (90.6926)  time: 0.3466  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1720/4579]  eta: 0:16:26  Lr: 0.030000  Loss: 0.2732  Acc@1: 62.5000 (60.3029)  Acc@5: 93.7500 (90.7031)  time: 0.3455  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1730/4579]  eta: 0:16:22  Lr: 0.030000  Loss: 0.2567  Acc@1: 62.5000 (60.3517)  Acc@5: 93.7500 (90.7098)  time: 0.3458  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [1740/4579]  eta: 0:16:19  Lr: 0.030000  Loss: 0.2846  Acc@1: 62.5000 (60.3317)  Acc@5: 93.7500 (90.7273)  time: 0.3455  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [1750/4579]  eta: 0:16:15  Lr: 0.030000  Loss: -0.1062  Acc@1: 56.2500 (60.3334)  Acc@5: 93.7500 (90.7160)  time: 0.3451  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [1760/4579]  eta: 0:16:12  Lr: 0.030000  Loss: 0.2077  Acc@1: 62.5000 (60.3457)  Acc@5: 87.5000 (90.7261)  time: 0.3452  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [1770/4579]  eta: 0:16:08  Lr: 0.030000  Loss: 0.2496  Acc@1: 62.5000 (60.3755)  Acc@5: 93.7500 (90.7362)  time: 0.3444  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [1780/4579]  eta: 0:16:05  Lr: 0.030000  Loss: 0.3000  Acc@1: 62.5000 (60.4155)  Acc@5: 93.7500 (90.7426)  time: 0.3443  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [1790/4579]  eta: 0:16:01  Lr: 0.030000  Loss: 0.3509  Acc@1: 62.5000 (60.4097)  Acc@5: 93.7500 (90.7454)  time: 0.3439  data: 0.0002  max mem: 2500
Train: Epoch[4/5]  [1800/4579]  eta: 0:15:58  Lr: 0.030000  Loss: 0.2636  Acc@1: 56.2500 (60.3831)  Acc@5: 87.5000 (90.7413)  time: 0.3474  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1810/4579]  eta: 0:15:55  Lr: 0.030000  Loss: 0.1653  Acc@1: 56.2500 (60.3707)  Acc@5: 87.5000 (90.7303)  time: 0.3480  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [1820/4579]  eta: 0:15:51  Lr: 0.030000  Loss: 0.6636  Acc@1: 62.5000 (60.3480)  Acc@5: 93.7500 (90.7194)  time: 0.3452  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1830/4579]  eta: 0:15:48  Lr: 0.030000  Loss: 0.1382  Acc@1: 62.5000 (60.3598)  Acc@5: 93.7500 (90.7223)  time: 0.3449  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [1840/4579]  eta: 0:15:44  Lr: 0.030000  Loss: 0.2409  Acc@1: 62.5000 (60.3612)  Acc@5: 93.7500 (90.7319)  time: 0.3445  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [1850/4579]  eta: 0:15:41  Lr: 0.030000  Loss: 0.3845  Acc@1: 62.5000 (60.3761)  Acc@5: 93.7500 (90.7415)  time: 0.3448  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [1860/4579]  eta: 0:15:37  Lr: 0.030000  Loss: 0.2792  Acc@1: 62.5000 (60.4044)  Acc@5: 93.7500 (90.7577)  time: 0.3452  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [1870/4579]  eta: 0:15:34  Lr: 0.030000  Loss: 0.2522  Acc@1: 62.5000 (60.3788)  Acc@5: 93.7500 (90.7536)  time: 0.3447  data: 0.0002  max mem: 2500
Train: Epoch[4/5]  [1880/4579]  eta: 0:15:30  Lr: 0.030000  Loss: -0.0395  Acc@1: 56.2500 (60.3801)  Acc@5: 93.7500 (90.7629)  time: 0.3434  data: 0.0002  max mem: 2500
Train: Epoch[4/5]  [1890/4579]  eta: 0:15:27  Lr: 0.030000  Loss: 0.0276  Acc@1: 56.2500 (60.3682)  Acc@5: 93.7500 (90.7721)  time: 0.3436  data: 0.0002  max mem: 2500
Train: Epoch[4/5]  [1900/4579]  eta: 0:15:23  Lr: 0.030000  Loss: 0.4050  Acc@1: 62.5000 (60.3893)  Acc@5: 93.7500 (90.7680)  time: 0.3450  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [1910/4579]  eta: 0:15:20  Lr: 0.030000  Loss: 0.2747  Acc@1: 62.5000 (60.3807)  Acc@5: 87.5000 (90.7575)  time: 0.3455  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1920/4579]  eta: 0:15:17  Lr: 0.030000  Loss: 0.2457  Acc@1: 62.5000 (60.3852)  Acc@5: 87.5000 (90.7535)  time: 0.3451  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1930/4579]  eta: 0:15:13  Lr: 0.030000  Loss: 0.1213  Acc@1: 56.2500 (60.3865)  Acc@5: 93.7500 (90.7626)  time: 0.3452  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1940/4579]  eta: 0:15:10  Lr: 0.030000  Loss: 0.5400  Acc@1: 56.2500 (60.3619)  Acc@5: 93.7500 (90.7618)  time: 0.3462  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [1950/4579]  eta: 0:15:06  Lr: 0.030000  Loss: 0.3222  Acc@1: 56.2500 (60.3633)  Acc@5: 93.7500 (90.7708)  time: 0.3460  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1960/4579]  eta: 0:15:03  Lr: 0.030000  Loss: 0.1623  Acc@1: 68.7500 (60.3837)  Acc@5: 93.7500 (90.7828)  time: 0.3447  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [1970/4579]  eta: 0:14:59  Lr: 0.030000  Loss: 0.1491  Acc@1: 56.2500 (60.3596)  Acc@5: 93.7500 (90.7693)  time: 0.3446  data: 0.0002  max mem: 2500
Train: Epoch[4/5]  [1980/4579]  eta: 0:14:56  Lr: 0.030000  Loss: -0.0919  Acc@1: 56.2500 (60.3420)  Acc@5: 87.5000 (90.7591)  time: 0.3453  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [1990/4579]  eta: 0:14:52  Lr: 0.030000  Loss: -0.0681  Acc@1: 56.2500 (60.3591)  Acc@5: 87.5000 (90.7647)  time: 0.3453  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [2000/4579]  eta: 0:14:49  Lr: 0.030000  Loss: 0.2619  Acc@1: 68.7500 (60.3698)  Acc@5: 93.7500 (90.7671)  time: 0.3446  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [2010/4579]  eta: 0:14:46  Lr: 0.030000  Loss: 0.1253  Acc@1: 50.0000 (60.3493)  Acc@5: 87.5000 (90.7602)  time: 0.3445  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [2020/4579]  eta: 0:14:42  Lr: 0.030000  Loss: -0.0057  Acc@1: 56.2500 (60.3476)  Acc@5: 87.5000 (90.7533)  time: 0.3437  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [2030/4579]  eta: 0:14:39  Lr: 0.030000  Loss: -0.1085  Acc@1: 62.5000 (60.3736)  Acc@5: 93.7500 (90.7558)  time: 0.3431  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [2040/4579]  eta: 0:14:35  Lr: 0.030000  Loss: 0.0884  Acc@1: 62.5000 (60.4024)  Acc@5: 93.7500 (90.7643)  time: 0.3433  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [2050/4579]  eta: 0:14:32  Lr: 0.030000  Loss: 0.2399  Acc@1: 62.5000 (60.4126)  Acc@5: 93.7500 (90.7697)  time: 0.3445  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [2060/4579]  eta: 0:14:28  Lr: 0.030000  Loss: -0.1331  Acc@1: 62.5000 (60.4288)  Acc@5: 93.7500 (90.7660)  time: 0.3456  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2070/4579]  eta: 0:14:25  Lr: 0.030000  Loss: 0.2155  Acc@1: 68.7500 (60.4599)  Acc@5: 93.7500 (90.7623)  time: 0.3453  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2080/4579]  eta: 0:14:21  Lr: 0.030000  Loss: 0.1488  Acc@1: 68.7500 (60.4637)  Acc@5: 93.7500 (90.7526)  time: 0.3459  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2090/4579]  eta: 0:14:18  Lr: 0.030000  Loss: 0.4079  Acc@1: 62.5000 (60.4525)  Acc@5: 93.7500 (90.7700)  time: 0.3462  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2100/4579]  eta: 0:14:15  Lr: 0.030000  Loss: 0.5797  Acc@1: 62.5000 (60.4355)  Acc@5: 93.7500 (90.7752)  time: 0.3456  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2110/4579]  eta: 0:14:11  Lr: 0.030000  Loss: 0.0674  Acc@1: 62.5000 (60.4275)  Acc@5: 87.5000 (90.7538)  time: 0.3453  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [2120/4579]  eta: 0:14:08  Lr: 0.030000  Loss: 0.1531  Acc@1: 62.5000 (60.4579)  Acc@5: 87.5000 (90.7502)  time: 0.3453  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [2130/4579]  eta: 0:14:04  Lr: 0.030000  Loss: 0.1799  Acc@1: 62.5000 (60.4616)  Acc@5: 93.7500 (90.7584)  time: 0.3453  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [2140/4579]  eta: 0:14:01  Lr: 0.030000  Loss: -0.2214  Acc@1: 62.5000 (60.4887)  Acc@5: 93.7500 (90.7491)  time: 0.3453  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2150/4579]  eta: 0:13:57  Lr: 0.030000  Loss: 0.1931  Acc@1: 68.7500 (60.4951)  Acc@5: 87.5000 (90.7398)  time: 0.3455  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [2160/4579]  eta: 0:13:54  Lr: 0.030000  Loss: 0.5648  Acc@1: 62.5000 (60.5275)  Acc@5: 87.5000 (90.7479)  time: 0.3465  data: 0.0010  max mem: 2500
Train: Epoch[4/5]  [2170/4579]  eta: 0:13:50  Lr: 0.030000  Loss: 0.2893  Acc@1: 62.5000 (60.5078)  Acc@5: 93.7500 (90.7416)  time: 0.3456  data: 0.0009  max mem: 2500
Train: Epoch[4/5]  [2180/4579]  eta: 0:13:47  Lr: 0.030000  Loss: 0.0997  Acc@1: 56.2500 (60.5026)  Acc@5: 87.5000 (90.7325)  time: 0.3434  data: 0.0002  max mem: 2500
Train: Epoch[4/5]  [2190/4579]  eta: 0:13:43  Lr: 0.030000  Loss: 0.2912  Acc@1: 62.5000 (60.5089)  Acc@5: 87.5000 (90.7405)  time: 0.3435  data: 0.0002  max mem: 2500
Train: Epoch[4/5]  [2200/4579]  eta: 0:13:40  Lr: 0.030000  Loss: -0.0139  Acc@1: 56.2500 (60.5037)  Acc@5: 93.7500 (90.7485)  time: 0.3437  data: 0.0002  max mem: 2500
Train: Epoch[4/5]  [2210/4579]  eta: 0:13:37  Lr: 0.030000  Loss: 0.2974  Acc@1: 62.5000 (60.5354)  Acc@5: 93.7500 (90.7621)  time: 0.3436  data: 0.0002  max mem: 2500
Train: Epoch[4/5]  [2220/4579]  eta: 0:13:33  Lr: 0.030000  Loss: -0.1834  Acc@1: 68.7500 (60.5752)  Acc@5: 93.7500 (90.7727)  time: 0.3437  data: 0.0002  max mem: 2500
Train: Epoch[4/5]  [2230/4579]  eta: 0:13:30  Lr: 0.030000  Loss: 0.0566  Acc@1: 68.7500 (60.5782)  Acc@5: 93.7500 (90.7665)  time: 0.3438  data: 0.0002  max mem: 2500
Train: Epoch[4/5]  [2240/4579]  eta: 0:13:26  Lr: 0.030000  Loss: -0.1151  Acc@1: 56.2500 (60.5728)  Acc@5: 93.7500 (90.7686)  time: 0.3437  data: 0.0002  max mem: 2500
Train: Epoch[4/5]  [2250/4579]  eta: 0:13:23  Lr: 0.030000  Loss: 0.0713  Acc@1: 56.2500 (60.5509)  Acc@5: 87.5000 (90.7513)  time: 0.3445  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [2260/4579]  eta: 0:13:19  Lr: 0.030000  Loss: 0.2093  Acc@1: 56.2500 (60.5567)  Acc@5: 93.7500 (90.7646)  time: 0.3458  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [2270/4579]  eta: 0:13:16  Lr: 0.030000  Loss: -0.0225  Acc@1: 62.5000 (60.5598)  Acc@5: 93.7500 (90.7777)  time: 0.3465  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2280/4579]  eta: 0:13:12  Lr: 0.030000  Loss: 0.1520  Acc@1: 62.5000 (60.5546)  Acc@5: 93.7500 (90.7853)  time: 0.3470  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2290/4579]  eta: 0:13:09  Lr: 0.030000  Loss: 0.1457  Acc@1: 62.5000 (60.5767)  Acc@5: 93.7500 (90.7873)  time: 0.3470  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2300/4579]  eta: 0:13:06  Lr: 0.030000  Loss: 0.1282  Acc@1: 62.5000 (60.5769)  Acc@5: 93.7500 (90.7975)  time: 0.3461  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2310/4579]  eta: 0:13:02  Lr: 0.030000  Loss: 0.1713  Acc@1: 62.5000 (60.5852)  Acc@5: 93.7500 (90.8048)  time: 0.3455  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2320/4579]  eta: 0:12:59  Lr: 0.030000  Loss: -0.0192  Acc@1: 62.5000 (60.6043)  Acc@5: 93.7500 (90.8068)  time: 0.3457  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2330/4579]  eta: 0:12:55  Lr: 0.030000  Loss: -0.1271  Acc@1: 56.2500 (60.5775)  Acc@5: 93.7500 (90.8087)  time: 0.3453  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [2340/4579]  eta: 0:12:52  Lr: 0.030000  Loss: 0.0919  Acc@1: 56.2500 (60.5991)  Acc@5: 93.7500 (90.8186)  time: 0.3461  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2350/4579]  eta: 0:12:48  Lr: 0.030000  Loss: 0.5681  Acc@1: 62.5000 (60.5992)  Acc@5: 93.7500 (90.8284)  time: 0.3465  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2360/4579]  eta: 0:12:45  Lr: 0.030000  Loss: 0.4111  Acc@1: 62.5000 (60.6073)  Acc@5: 93.7500 (90.8487)  time: 0.3459  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2370/4579]  eta: 0:12:41  Lr: 0.030000  Loss: 0.1460  Acc@1: 56.2500 (60.5783)  Acc@5: 93.7500 (90.8319)  time: 0.3455  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2380/4579]  eta: 0:12:38  Lr: 0.030000  Loss: 0.0051  Acc@1: 56.2500 (60.5969)  Acc@5: 93.7500 (90.8416)  time: 0.3460  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2390/4579]  eta: 0:12:35  Lr: 0.030000  Loss: 0.0862  Acc@1: 62.5000 (60.6127)  Acc@5: 93.7500 (90.8511)  time: 0.3468  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2400/4579]  eta: 0:12:31  Lr: 0.030000  Loss: 0.1339  Acc@1: 68.7500 (60.6388)  Acc@5: 93.7500 (90.8632)  time: 0.3476  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2410/4579]  eta: 0:12:28  Lr: 0.030000  Loss: 0.2118  Acc@1: 68.7500 (60.6387)  Acc@5: 87.5000 (90.8415)  time: 0.3471  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2420/4579]  eta: 0:12:24  Lr: 0.030000  Loss: 0.0694  Acc@1: 62.5000 (60.6619)  Acc@5: 87.5000 (90.8586)  time: 0.3449  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [2430/4579]  eta: 0:12:21  Lr: 0.030000  Loss: -0.0090  Acc@1: 68.7500 (60.6643)  Acc@5: 93.7500 (90.8628)  time: 0.3449  data: 0.0002  max mem: 2500
Train: Epoch[4/5]  [2440/4579]  eta: 0:12:17  Lr: 0.030000  Loss: 0.2394  Acc@1: 56.2500 (60.6411)  Acc@5: 93.7500 (90.8593)  time: 0.3459  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [2450/4579]  eta: 0:12:14  Lr: 0.030000  Loss: -0.1168  Acc@1: 62.5000 (60.6589)  Acc@5: 93.7500 (90.8634)  time: 0.3457  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [2460/4579]  eta: 0:12:11  Lr: 0.030000  Loss: 0.1877  Acc@1: 62.5000 (60.6486)  Acc@5: 93.7500 (90.8752)  time: 0.3451  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [2470/4579]  eta: 0:12:07  Lr: 0.030000  Loss: -0.0873  Acc@1: 56.2500 (60.6536)  Acc@5: 93.7500 (90.8767)  time: 0.3452  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [2480/4579]  eta: 0:12:04  Lr: 0.030000  Loss: 0.0377  Acc@1: 62.5000 (60.6509)  Acc@5: 93.7500 (90.8807)  time: 0.3465  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [2490/4579]  eta: 0:12:00  Lr: 0.030000  Loss: 0.1000  Acc@1: 62.5000 (60.6684)  Acc@5: 93.7500 (90.8947)  time: 0.3456  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [2500/4579]  eta: 0:11:57  Lr: 0.030000  Loss: 0.1070  Acc@1: 62.5000 (60.6607)  Acc@5: 93.7500 (90.8986)  time: 0.3429  data: 0.0002  max mem: 2500
Train: Epoch[4/5]  [2510/4579]  eta: 0:11:53  Lr: 0.030000  Loss: 0.2602  Acc@1: 56.2500 (60.6606)  Acc@5: 93.7500 (90.9075)  time: 0.3426  data: 0.0002  max mem: 2500
Train: Epoch[4/5]  [2520/4579]  eta: 0:11:50  Lr: 0.030000  Loss: 0.3514  Acc@1: 62.5000 (60.6580)  Acc@5: 87.5000 (90.8915)  time: 0.3426  data: 0.0002  max mem: 2500
Train: Epoch[4/5]  [2530/4579]  eta: 0:11:46  Lr: 0.030000  Loss: 0.5929  Acc@1: 56.2500 (60.6455)  Acc@5: 87.5000 (90.8855)  time: 0.3425  data: 0.0002  max mem: 2500
Train: Epoch[4/5]  [2540/4579]  eta: 0:11:43  Lr: 0.030000  Loss: 0.1458  Acc@1: 56.2500 (60.6553)  Acc@5: 87.5000 (90.8870)  time: 0.3425  data: 0.0002  max mem: 2500
Train: Epoch[4/5]  [2550/4579]  eta: 0:11:39  Lr: 0.030000  Loss: 0.2229  Acc@1: 62.5000 (60.6772)  Acc@5: 93.7500 (90.9055)  time: 0.3426  data: 0.0002  max mem: 2500
Train: Epoch[4/5]  [2560/4579]  eta: 0:11:36  Lr: 0.030000  Loss: -0.1399  Acc@1: 62.5000 (60.6770)  Acc@5: 93.7500 (90.9166)  time: 0.3426  data: 0.0002  max mem: 2500
Train: Epoch[4/5]  [2570/4579]  eta: 0:11:32  Lr: 0.030000  Loss: 0.0523  Acc@1: 68.7500 (60.6938)  Acc@5: 93.7500 (90.9131)  time: 0.3424  data: 0.0002  max mem: 2500
Train: Epoch[4/5]  [2580/4579]  eta: 0:11:29  Lr: 0.030000  Loss: 0.1097  Acc@1: 68.7500 (60.7177)  Acc@5: 87.5000 (90.9144)  time: 0.3437  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [2590/4579]  eta: 0:11:26  Lr: 0.030000  Loss: 0.1248  Acc@1: 62.5000 (60.7270)  Acc@5: 93.7500 (90.9229)  time: 0.3456  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2600/4579]  eta: 0:11:22  Lr: 0.030000  Loss: 0.1442  Acc@1: 62.5000 (60.7290)  Acc@5: 93.7500 (90.9218)  time: 0.3464  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2610/4579]  eta: 0:11:19  Lr: 0.030000  Loss: -0.0405  Acc@1: 62.5000 (60.7119)  Acc@5: 87.5000 (90.9230)  time: 0.3460  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [2620/4579]  eta: 0:11:15  Lr: 0.030000  Loss: 0.6066  Acc@1: 56.2500 (60.6949)  Acc@5: 87.5000 (90.9147)  time: 0.3458  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [2630/4579]  eta: 0:11:12  Lr: 0.030000  Loss: 0.2426  Acc@1: 62.5000 (60.7065)  Acc@5: 87.5000 (90.9231)  time: 0.3452  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2640/4579]  eta: 0:11:08  Lr: 0.030000  Loss: -0.0680  Acc@1: 62.5000 (60.7346)  Acc@5: 93.7500 (90.9315)  time: 0.3447  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2650/4579]  eta: 0:11:05  Lr: 0.030000  Loss: -0.1927  Acc@1: 62.5000 (60.7601)  Acc@5: 93.7500 (90.9421)  time: 0.3449  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2660/4579]  eta: 0:11:01  Lr: 0.030000  Loss: 0.0651  Acc@1: 62.5000 (60.7666)  Acc@5: 93.7500 (90.9409)  time: 0.3447  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2670/4579]  eta: 0:10:58  Lr: 0.030000  Loss: 0.4343  Acc@1: 62.5000 (60.7591)  Acc@5: 87.5000 (90.9421)  time: 0.3449  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2680/4579]  eta: 0:10:55  Lr: 0.030000  Loss: 0.0440  Acc@1: 56.2500 (60.7516)  Acc@5: 93.7500 (90.9479)  time: 0.3444  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2690/4579]  eta: 0:10:51  Lr: 0.030000  Loss: -0.1552  Acc@1: 62.5000 (60.7651)  Acc@5: 93.7500 (90.9397)  time: 0.3444  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2700/4579]  eta: 0:10:48  Lr: 0.030000  Loss: 0.1863  Acc@1: 62.5000 (60.7692)  Acc@5: 93.7500 (90.9478)  time: 0.3456  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2710/4579]  eta: 0:10:44  Lr: 0.030000  Loss: 0.2336  Acc@1: 62.5000 (60.7617)  Acc@5: 93.7500 (90.9512)  time: 0.3456  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2720/4579]  eta: 0:10:41  Lr: 0.030000  Loss: 0.3701  Acc@1: 56.2500 (60.7543)  Acc@5: 93.7500 (90.9362)  time: 0.3447  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2730/4579]  eta: 0:10:37  Lr: 0.030000  Loss: -0.0586  Acc@1: 56.2500 (60.7378)  Acc@5: 87.5000 (90.9282)  time: 0.3454  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2740/4579]  eta: 0:10:34  Lr: 0.030000  Loss: 0.1410  Acc@1: 56.2500 (60.7283)  Acc@5: 93.7500 (90.9362)  time: 0.3454  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2750/4579]  eta: 0:10:30  Lr: 0.030000  Loss: 0.2760  Acc@1: 56.2500 (60.7302)  Acc@5: 93.7500 (90.9283)  time: 0.3446  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [2760/4579]  eta: 0:10:27  Lr: 0.030000  Loss: 0.4456  Acc@1: 62.5000 (60.7502)  Acc@5: 93.7500 (90.9317)  time: 0.3446  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [2770/4579]  eta: 0:10:23  Lr: 0.030000  Loss: -0.1123  Acc@1: 62.5000 (60.7678)  Acc@5: 93.7500 (90.9374)  time: 0.3445  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [2780/4579]  eta: 0:10:20  Lr: 0.030000  Loss: 0.0565  Acc@1: 62.5000 (60.7875)  Acc@5: 93.7500 (90.9430)  time: 0.3446  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [2790/4579]  eta: 0:10:17  Lr: 0.030000  Loss: -0.0782  Acc@1: 62.5000 (60.7824)  Acc@5: 93.7500 (90.9351)  time: 0.3446  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [2800/4579]  eta: 0:10:13  Lr: 0.030000  Loss: 0.1985  Acc@1: 62.5000 (60.7841)  Acc@5: 87.5000 (90.9296)  time: 0.3443  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [2810/4579]  eta: 0:10:10  Lr: 0.030000  Loss: 0.1828  Acc@1: 62.5000 (60.7835)  Acc@5: 93.7500 (90.9329)  time: 0.3442  data: 0.0002  max mem: 2500
Train: Epoch[4/5]  [2820/4579]  eta: 0:10:06  Lr: 0.030000  Loss: 0.2214  Acc@1: 62.5000 (60.7763)  Acc@5: 93.7500 (90.9363)  time: 0.3437  data: 0.0002  max mem: 2500
Train: Epoch[4/5]  [2830/4579]  eta: 0:10:03  Lr: 0.030000  Loss: 0.0153  Acc@1: 56.2500 (60.7670)  Acc@5: 87.5000 (90.9153)  time: 0.3430  data: 0.0002  max mem: 2500
Train: Epoch[4/5]  [2840/4579]  eta: 0:09:59  Lr: 0.030000  Loss: 0.0489  Acc@1: 62.5000 (60.7819)  Acc@5: 87.5000 (90.9121)  time: 0.3432  data: 0.0002  max mem: 2500
Train: Epoch[4/5]  [2850/4579]  eta: 0:09:56  Lr: 0.030000  Loss: 0.1641  Acc@1: 62.5000 (60.7879)  Acc@5: 93.7500 (90.9177)  time: 0.3434  data: 0.0002  max mem: 2500
Train: Epoch[4/5]  [2860/4579]  eta: 0:09:52  Lr: 0.030000  Loss: -0.0589  Acc@1: 62.5000 (60.7917)  Acc@5: 93.7500 (90.9210)  time: 0.3443  data: 0.0002  max mem: 2500
Train: Epoch[4/5]  [2870/4579]  eta: 0:09:49  Lr: 0.030000  Loss: 0.3307  Acc@1: 56.2500 (60.7846)  Acc@5: 87.5000 (90.9091)  time: 0.3452  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [2880/4579]  eta: 0:09:45  Lr: 0.030000  Loss: 0.0831  Acc@1: 50.0000 (60.7732)  Acc@5: 87.5000 (90.9124)  time: 0.3454  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2890/4579]  eta: 0:09:42  Lr: 0.030000  Loss: -0.0064  Acc@1: 62.5000 (60.7921)  Acc@5: 93.7500 (90.9179)  time: 0.3460  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2900/4579]  eta: 0:09:39  Lr: 0.030000  Loss: 0.1516  Acc@1: 62.5000 (60.8045)  Acc@5: 93.7500 (90.9255)  time: 0.3467  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2910/4579]  eta: 0:09:35  Lr: 0.030000  Loss: 0.4285  Acc@1: 62.5000 (60.8232)  Acc@5: 93.7500 (90.9288)  time: 0.3464  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2920/4579]  eta: 0:09:32  Lr: 0.030000  Loss: 0.0334  Acc@1: 68.7500 (60.8375)  Acc@5: 93.7500 (90.9235)  time: 0.3466  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2930/4579]  eta: 0:09:28  Lr: 0.030000  Loss: 0.2332  Acc@1: 62.5000 (60.8346)  Acc@5: 93.7500 (90.9225)  time: 0.3465  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2940/4579]  eta: 0:09:25  Lr: 0.030000  Loss: 0.3411  Acc@1: 62.5000 (60.8424)  Acc@5: 93.7500 (90.9151)  time: 0.3456  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2950/4579]  eta: 0:09:21  Lr: 0.030000  Loss: 0.0144  Acc@1: 62.5000 (60.8501)  Acc@5: 93.7500 (90.9332)  time: 0.3454  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2960/4579]  eta: 0:09:18  Lr: 0.030000  Loss: 0.0322  Acc@1: 62.5000 (60.8789)  Acc@5: 93.7500 (90.9448)  time: 0.3456  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2970/4579]  eta: 0:09:15  Lr: 0.030000  Loss: 0.0970  Acc@1: 62.5000 (60.8802)  Acc@5: 93.7500 (90.9458)  time: 0.3456  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2980/4579]  eta: 0:09:11  Lr: 0.030000  Loss: -0.1922  Acc@1: 62.5000 (60.8814)  Acc@5: 87.5000 (90.9426)  time: 0.3452  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [2990/4579]  eta: 0:09:08  Lr: 0.030000  Loss: -0.0423  Acc@1: 62.5000 (60.8806)  Acc@5: 87.5000 (90.9437)  time: 0.3460  data: 0.0010  max mem: 2500
Train: Epoch[4/5]  [3000/4579]  eta: 0:09:04  Lr: 0.030000  Loss: 0.1938  Acc@1: 62.5000 (60.8880)  Acc@5: 93.7500 (90.9405)  time: 0.3458  data: 0.0009  max mem: 2500
Train: Epoch[4/5]  [3010/4579]  eta: 0:09:01  Lr: 0.030000  Loss: 0.4711  Acc@1: 62.5000 (60.8913)  Acc@5: 93.7500 (90.9395)  time: 0.3449  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [3020/4579]  eta: 0:08:57  Lr: 0.030000  Loss: 0.0940  Acc@1: 62.5000 (60.8987)  Acc@5: 93.7500 (90.9571)  time: 0.3452  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [3030/4579]  eta: 0:08:54  Lr: 0.030000  Loss: 0.3780  Acc@1: 62.5000 (60.8916)  Acc@5: 93.7500 (90.9477)  time: 0.3449  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [3040/4579]  eta: 0:08:50  Lr: 0.030000  Loss: 0.1228  Acc@1: 62.5000 (60.9051)  Acc@5: 87.5000 (90.9569)  time: 0.3445  data: 0.0002  max mem: 2500
Train: Epoch[4/5]  [3050/4579]  eta: 0:08:47  Lr: 0.030000  Loss: -0.2004  Acc@1: 62.5000 (60.9145)  Acc@5: 93.7500 (90.9599)  time: 0.3443  data: 0.0002  max mem: 2500
Train: Epoch[4/5]  [3060/4579]  eta: 0:08:43  Lr: 0.030000  Loss: -0.3018  Acc@1: 62.5000 (60.9278)  Acc@5: 93.7500 (90.9609)  time: 0.3441  data: 0.0002  max mem: 2500
Train: Epoch[4/5]  [3070/4579]  eta: 0:08:40  Lr: 0.030000  Loss: 0.1468  Acc@1: 56.2500 (60.9227)  Acc@5: 93.7500 (90.9577)  time: 0.3443  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [3080/4579]  eta: 0:08:37  Lr: 0.030000  Loss: 0.1080  Acc@1: 56.2500 (60.9258)  Acc@5: 87.5000 (90.9546)  time: 0.3447  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3090/4579]  eta: 0:08:33  Lr: 0.030000  Loss: 0.4891  Acc@1: 56.2500 (60.9370)  Acc@5: 87.5000 (90.9576)  time: 0.3448  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3100/4579]  eta: 0:08:30  Lr: 0.030000  Loss: 0.1454  Acc@1: 62.5000 (60.9360)  Acc@5: 93.7500 (90.9686)  time: 0.3446  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3110/4579]  eta: 0:08:26  Lr: 0.030000  Loss: -0.3114  Acc@1: 62.5000 (60.9551)  Acc@5: 93.7500 (90.9736)  time: 0.3450  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3120/4579]  eta: 0:08:23  Lr: 0.030000  Loss: 0.0813  Acc@1: 68.7500 (60.9680)  Acc@5: 93.7500 (90.9764)  time: 0.3448  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3130/4579]  eta: 0:08:19  Lr: 0.030000  Loss: -0.1235  Acc@1: 68.7500 (60.9889)  Acc@5: 93.7500 (90.9853)  time: 0.3466  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [3140/4579]  eta: 0:08:16  Lr: 0.030000  Loss: 0.1695  Acc@1: 68.7500 (60.9897)  Acc@5: 93.7500 (90.9881)  time: 0.3471  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [3150/4579]  eta: 0:08:12  Lr: 0.030000  Loss: 0.2394  Acc@1: 56.2500 (60.9866)  Acc@5: 87.5000 (90.9751)  time: 0.3455  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [3160/4579]  eta: 0:08:09  Lr: 0.030000  Loss: 0.2380  Acc@1: 56.2500 (60.9795)  Acc@5: 87.5000 (90.9700)  time: 0.3454  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [3170/4579]  eta: 0:08:06  Lr: 0.030000  Loss: 0.2755  Acc@1: 62.5000 (60.9823)  Acc@5: 93.7500 (90.9808)  time: 0.3454  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [3180/4579]  eta: 0:08:02  Lr: 0.030000  Loss: -0.2046  Acc@1: 62.5000 (60.9851)  Acc@5: 93.7500 (90.9796)  time: 0.3454  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [3190/4579]  eta: 0:07:59  Lr: 0.030000  Loss: -0.1968  Acc@1: 62.5000 (61.0095)  Acc@5: 93.7500 (90.9922)  time: 0.3462  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [3200/4579]  eta: 0:07:55  Lr: 0.030000  Loss: 0.2057  Acc@1: 62.5000 (61.0044)  Acc@5: 93.7500 (90.9872)  time: 0.3455  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [3210/4579]  eta: 0:07:52  Lr: 0.030000  Loss: -0.0192  Acc@1: 56.2500 (60.9974)  Acc@5: 87.5000 (90.9841)  time: 0.3437  data: 0.0002  max mem: 2500
Train: Epoch[4/5]  [3220/4579]  eta: 0:07:48  Lr: 0.030000  Loss: 0.3879  Acc@1: 56.2500 (60.9981)  Acc@5: 87.5000 (90.9714)  time: 0.3436  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [3230/4579]  eta: 0:07:45  Lr: 0.030000  Loss: 0.0600  Acc@1: 62.5000 (60.9970)  Acc@5: 93.7500 (90.9780)  time: 0.3437  data: 0.0002  max mem: 2500
Train: Epoch[4/5]  [3240/4579]  eta: 0:07:41  Lr: 0.030000  Loss: 0.5203  Acc@1: 56.2500 (60.9881)  Acc@5: 93.7500 (90.9673)  time: 0.3437  data: 0.0002  max mem: 2500
Train: Epoch[4/5]  [3250/4579]  eta: 0:07:38  Lr: 0.030000  Loss: 0.2427  Acc@1: 62.5000 (60.9985)  Acc@5: 93.7500 (90.9797)  time: 0.3437  data: 0.0002  max mem: 2500
Train: Epoch[4/5]  [3260/4579]  eta: 0:07:34  Lr: 0.030000  Loss: 0.1996  Acc@1: 56.2500 (60.9744)  Acc@5: 93.7500 (90.9786)  time: 0.3436  data: 0.0002  max mem: 2500
Train: Epoch[4/5]  [3270/4579]  eta: 0:07:31  Lr: 0.030000  Loss: 0.3521  Acc@1: 62.5000 (60.9867)  Acc@5: 87.5000 (90.9661)  time: 0.3437  data: 0.0002  max mem: 2500
Train: Epoch[4/5]  [3280/4579]  eta: 0:07:28  Lr: 0.030000  Loss: 0.1279  Acc@1: 62.5000 (60.9970)  Acc@5: 87.5000 (90.9726)  time: 0.3438  data: 0.0002  max mem: 2500
Train: Epoch[4/5]  [3290/4579]  eta: 0:07:24  Lr: 0.030000  Loss: 0.2704  Acc@1: 62.5000 (60.9902)  Acc@5: 93.7500 (90.9716)  time: 0.3437  data: 0.0002  max mem: 2500
Train: Epoch[4/5]  [3300/4579]  eta: 0:07:21  Lr: 0.030000  Loss: 0.0974  Acc@1: 62.5000 (60.9986)  Acc@5: 93.7500 (90.9724)  time: 0.3452  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [3310/4579]  eta: 0:07:17  Lr: 0.030000  Loss: 0.2548  Acc@1: 62.5000 (61.0012)  Acc@5: 93.7500 (90.9752)  time: 0.3465  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3320/4579]  eta: 0:07:14  Lr: 0.030000  Loss: 0.3111  Acc@1: 62.5000 (60.9982)  Acc@5: 93.7500 (90.9760)  time: 0.3456  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3330/4579]  eta: 0:07:10  Lr: 0.030000  Loss: 0.4583  Acc@1: 62.5000 (60.9989)  Acc@5: 93.7500 (90.9806)  time: 0.3451  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3340/4579]  eta: 0:07:07  Lr: 0.030000  Loss: 0.0729  Acc@1: 68.7500 (61.0109)  Acc@5: 93.7500 (90.9814)  time: 0.3455  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3350/4579]  eta: 0:07:03  Lr: 0.030000  Loss: 0.0084  Acc@1: 62.5000 (61.0004)  Acc@5: 87.5000 (90.9598)  time: 0.3453  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3360/4579]  eta: 0:07:00  Lr: 0.030000  Loss: 0.2858  Acc@1: 62.5000 (61.0105)  Acc@5: 87.5000 (90.9532)  time: 0.3453  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3370/4579]  eta: 0:06:57  Lr: 0.030000  Loss: 0.5363  Acc@1: 62.5000 (61.0056)  Acc@5: 93.7500 (90.9522)  time: 0.3451  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [3380/4579]  eta: 0:06:53  Lr: 0.030000  Loss: -0.2050  Acc@1: 62.5000 (61.0119)  Acc@5: 93.7500 (90.9513)  time: 0.3449  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [3390/4579]  eta: 0:06:50  Lr: 0.030000  Loss: 0.3518  Acc@1: 62.5000 (61.0237)  Acc@5: 93.7500 (90.9540)  time: 0.3455  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3400/4579]  eta: 0:06:46  Lr: 0.030000  Loss: 0.5549  Acc@1: 62.5000 (61.0078)  Acc@5: 93.7500 (90.9475)  time: 0.3451  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3410/4579]  eta: 0:06:43  Lr: 0.030000  Loss: 0.0235  Acc@1: 62.5000 (61.0122)  Acc@5: 93.7500 (90.9557)  time: 0.3448  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3420/4579]  eta: 0:06:39  Lr: 0.030000  Loss: -0.0029  Acc@1: 62.5000 (61.0110)  Acc@5: 87.5000 (90.9529)  time: 0.3455  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3430/4579]  eta: 0:06:36  Lr: 0.030000  Loss: 0.0567  Acc@1: 62.5000 (61.0190)  Acc@5: 87.5000 (90.9429)  time: 0.3458  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [3440/4579]  eta: 0:06:32  Lr: 0.030000  Loss: 0.0924  Acc@1: 62.5000 (61.0251)  Acc@5: 93.7500 (90.9456)  time: 0.3456  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3450/4579]  eta: 0:06:29  Lr: 0.030000  Loss: 0.3800  Acc@1: 62.5000 (61.0330)  Acc@5: 93.7500 (90.9338)  time: 0.3458  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3460/4579]  eta: 0:06:25  Lr: 0.030000  Loss: 0.3341  Acc@1: 62.5000 (61.0228)  Acc@5: 87.5000 (90.9365)  time: 0.3458  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [3470/4579]  eta: 0:06:22  Lr: 0.030000  Loss: 0.5871  Acc@1: 62.5000 (61.0307)  Acc@5: 93.7500 (90.9302)  time: 0.3455  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [3480/4579]  eta: 0:06:19  Lr: 0.030000  Loss: -0.0350  Acc@1: 62.5000 (61.0529)  Acc@5: 93.7500 (90.9293)  time: 0.3450  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3490/4579]  eta: 0:06:15  Lr: 0.030000  Loss: 0.4284  Acc@1: 68.7500 (61.0713)  Acc@5: 87.5000 (90.9267)  time: 0.3446  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [3500/4579]  eta: 0:06:12  Lr: 0.030000  Loss: 0.2049  Acc@1: 68.7500 (61.0843)  Acc@5: 87.5000 (90.9294)  time: 0.3452  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [3510/4579]  eta: 0:06:08  Lr: 0.030000  Loss: 0.3579  Acc@1: 62.5000 (61.0795)  Acc@5: 93.7500 (90.9321)  time: 0.3451  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [3520/4579]  eta: 0:06:05  Lr: 0.030000  Loss: -0.1088  Acc@1: 56.2500 (61.0835)  Acc@5: 93.7500 (90.9294)  time: 0.3443  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [3530/4579]  eta: 0:06:01  Lr: 0.030000  Loss: -0.0682  Acc@1: 62.5000 (61.0911)  Acc@5: 93.7500 (90.9321)  time: 0.3444  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [3540/4579]  eta: 0:05:58  Lr: 0.030000  Loss: 0.0971  Acc@1: 62.5000 (61.1003)  Acc@5: 93.7500 (90.9295)  time: 0.3450  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [3550/4579]  eta: 0:05:54  Lr: 0.030000  Loss: 0.0478  Acc@1: 68.7500 (61.1148)  Acc@5: 93.7500 (90.9286)  time: 0.3444  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [3560/4579]  eta: 0:05:51  Lr: 0.030000  Loss: 0.3880  Acc@1: 62.5000 (61.1082)  Acc@5: 87.5000 (90.9172)  time: 0.3432  data: 0.0002  max mem: 2500
Train: Epoch[4/5]  [3570/4579]  eta: 0:05:48  Lr: 0.030000  Loss: 0.1271  Acc@1: 56.2500 (61.0911)  Acc@5: 87.5000 (90.9042)  time: 0.3433  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [3580/4579]  eta: 0:05:44  Lr: 0.030000  Loss: 0.0572  Acc@1: 62.5000 (61.1020)  Acc@5: 87.5000 (90.9139)  time: 0.3432  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [3590/4579]  eta: 0:05:41  Lr: 0.030000  Loss: -0.0114  Acc@1: 68.7500 (61.1181)  Acc@5: 93.7500 (90.9148)  time: 0.3434  data: 0.0002  max mem: 2500
Train: Epoch[4/5]  [3600/4579]  eta: 0:05:37  Lr: 0.030000  Loss: 0.2594  Acc@1: 62.5000 (61.1115)  Acc@5: 87.5000 (90.9122)  time: 0.3442  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3610/4579]  eta: 0:05:34  Lr: 0.030000  Loss: 0.2655  Acc@1: 56.2500 (61.0998)  Acc@5: 87.5000 (90.9115)  time: 0.3452  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [3620/4579]  eta: 0:05:30  Lr: 0.030000  Loss: -0.1358  Acc@1: 62.5000 (61.1054)  Acc@5: 93.7500 (90.9193)  time: 0.3459  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3630/4579]  eta: 0:05:27  Lr: 0.030000  Loss: -0.0159  Acc@1: 62.5000 (61.1264)  Acc@5: 93.7500 (90.9254)  time: 0.3461  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3640/4579]  eta: 0:05:23  Lr: 0.030000  Loss: 0.1424  Acc@1: 62.5000 (61.1250)  Acc@5: 93.7500 (90.9331)  time: 0.3459  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [3650/4579]  eta: 0:05:20  Lr: 0.030000  Loss: 0.3015  Acc@1: 56.2500 (61.1254)  Acc@5: 93.7500 (90.9237)  time: 0.3453  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3660/4579]  eta: 0:05:16  Lr: 0.030000  Loss: 0.2418  Acc@1: 56.2500 (61.1308)  Acc@5: 87.5000 (90.9280)  time: 0.3450  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3670/4579]  eta: 0:05:13  Lr: 0.030000  Loss: 0.1794  Acc@1: 62.5000 (61.1312)  Acc@5: 93.7500 (90.9306)  time: 0.3449  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [3680/4579]  eta: 0:05:10  Lr: 0.030000  Loss: 0.0791  Acc@1: 56.2500 (61.1213)  Acc@5: 93.7500 (90.9332)  time: 0.3447  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [3690/4579]  eta: 0:05:06  Lr: 0.030000  Loss: 0.4294  Acc@1: 56.2500 (61.1267)  Acc@5: 93.7500 (90.9374)  time: 0.3447  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3700/4579]  eta: 0:05:03  Lr: 0.030000  Loss: -0.0592  Acc@1: 62.5000 (61.1389)  Acc@5: 93.7500 (90.9383)  time: 0.3451  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3710/4579]  eta: 0:04:59  Lr: 0.030000  Loss: 0.4824  Acc@1: 62.5000 (61.1358)  Acc@5: 93.7500 (90.9340)  time: 0.3448  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [3720/4579]  eta: 0:04:56  Lr: 0.030000  Loss: 0.2843  Acc@1: 62.5000 (61.1529)  Acc@5: 93.7500 (90.9366)  time: 0.3451  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [3730/4579]  eta: 0:04:52  Lr: 0.030000  Loss: 0.3490  Acc@1: 62.5000 (61.1448)  Acc@5: 87.5000 (90.9324)  time: 0.3448  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [3740/4579]  eta: 0:04:49  Lr: 0.030000  Loss: -0.1927  Acc@1: 62.5000 (61.1518)  Acc@5: 87.5000 (90.9282)  time: 0.3439  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [3750/4579]  eta: 0:04:45  Lr: 0.030000  Loss: 0.3789  Acc@1: 56.2500 (61.1387)  Acc@5: 93.7500 (90.9341)  time: 0.3433  data: 0.0002  max mem: 2500
Train: Epoch[4/5]  [3760/4579]  eta: 0:04:42  Lr: 0.030000  Loss: 0.2854  Acc@1: 56.2500 (61.1257)  Acc@5: 93.7500 (90.9283)  time: 0.3430  data: 0.0002  max mem: 2500
Train: Epoch[4/5]  [3770/4579]  eta: 0:04:39  Lr: 0.030000  Loss: 0.3537  Acc@1: 62.5000 (61.1327)  Acc@5: 87.5000 (90.9208)  time: 0.3444  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3780/4579]  eta: 0:04:35  Lr: 0.030000  Loss: 0.1485  Acc@1: 62.5000 (61.1297)  Acc@5: 87.5000 (90.9234)  time: 0.3454  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [3790/4579]  eta: 0:04:32  Lr: 0.030000  Loss: 0.2244  Acc@1: 62.5000 (61.1283)  Acc@5: 93.7500 (90.9242)  time: 0.3447  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3800/4579]  eta: 0:04:28  Lr: 0.030000  Loss: 0.2043  Acc@1: 62.5000 (61.1402)  Acc@5: 93.7500 (90.9267)  time: 0.3441  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [3810/4579]  eta: 0:04:25  Lr: 0.030000  Loss: -0.0150  Acc@1: 62.5000 (61.1486)  Acc@5: 93.7500 (90.9341)  time: 0.3444  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [3820/4579]  eta: 0:04:21  Lr: 0.030000  Loss: -0.0442  Acc@1: 62.5000 (61.1505)  Acc@5: 93.7500 (90.9317)  time: 0.3444  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [3830/4579]  eta: 0:04:18  Lr: 0.030000  Loss: -0.1448  Acc@1: 62.5000 (61.1410)  Acc@5: 93.7500 (90.9260)  time: 0.3442  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [3840/4579]  eta: 0:04:14  Lr: 0.030000  Loss: 0.0946  Acc@1: 62.5000 (61.1413)  Acc@5: 87.5000 (90.9106)  time: 0.3434  data: 0.0002  max mem: 2500
Train: Epoch[4/5]  [3850/4579]  eta: 0:04:11  Lr: 0.030000  Loss: -0.0434  Acc@1: 62.5000 (61.1546)  Acc@5: 87.5000 (90.9179)  time: 0.3427  data: 0.0002  max mem: 2500
Train: Epoch[4/5]  [3860/4579]  eta: 0:04:07  Lr: 0.030000  Loss: 0.2441  Acc@1: 62.5000 (61.1483)  Acc@5: 93.7500 (90.9107)  time: 0.3428  data: 0.0002  max mem: 2500
Train: Epoch[4/5]  [3870/4579]  eta: 0:04:04  Lr: 0.030000  Loss: 0.4019  Acc@1: 56.2500 (61.1470)  Acc@5: 87.5000 (90.9035)  time: 0.3431  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [3880/4579]  eta: 0:04:01  Lr: 0.030000  Loss: 0.5816  Acc@1: 56.2500 (61.1392)  Acc@5: 87.5000 (90.8899)  time: 0.3444  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3890/4579]  eta: 0:03:57  Lr: 0.030000  Loss: 0.1438  Acc@1: 62.5000 (61.1427)  Acc@5: 87.5000 (90.8908)  time: 0.3451  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3900/4579]  eta: 0:03:54  Lr: 0.030000  Loss: 0.1602  Acc@1: 62.5000 (61.1382)  Acc@5: 93.7500 (90.8982)  time: 0.3456  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3910/4579]  eta: 0:03:50  Lr: 0.030000  Loss: 0.3940  Acc@1: 62.5000 (61.1464)  Acc@5: 93.7500 (90.9039)  time: 0.3453  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3920/4579]  eta: 0:03:47  Lr: 0.030000  Loss: 0.1289  Acc@1: 62.5000 (61.1563)  Acc@5: 93.7500 (90.9000)  time: 0.3446  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3930/4579]  eta: 0:03:43  Lr: 0.030000  Loss: 0.3513  Acc@1: 62.5000 (61.1517)  Acc@5: 93.7500 (90.8993)  time: 0.3450  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [3940/4579]  eta: 0:03:40  Lr: 0.030000  Loss: 0.0421  Acc@1: 62.5000 (61.1536)  Acc@5: 93.7500 (90.9002)  time: 0.3449  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [3950/4579]  eta: 0:03:36  Lr: 0.030000  Loss: 0.5568  Acc@1: 56.2500 (61.1396)  Acc@5: 87.5000 (90.8979)  time: 0.3453  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [3960/4579]  eta: 0:03:33  Lr: 0.030000  Loss: 0.0693  Acc@1: 62.5000 (61.1414)  Acc@5: 87.5000 (90.9003)  time: 0.3454  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [3970/4579]  eta: 0:03:30  Lr: 0.030000  Loss: 0.2893  Acc@1: 62.5000 (61.1449)  Acc@5: 93.7500 (90.9044)  time: 0.3448  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [3980/4579]  eta: 0:03:26  Lr: 0.030000  Loss: 0.3558  Acc@1: 62.5000 (61.1561)  Acc@5: 93.7500 (90.9021)  time: 0.3451  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [3990/4579]  eta: 0:03:23  Lr: 0.030000  Loss: 0.1793  Acc@1: 62.5000 (61.1423)  Acc@5: 87.5000 (90.8983)  time: 0.3447  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [4000/4579]  eta: 0:03:19  Lr: 0.030000  Loss: 0.2286  Acc@1: 56.2500 (61.1316)  Acc@5: 87.5000 (90.8992)  time: 0.3436  data: 0.0002  max mem: 2500
Train: Epoch[4/5]  [4010/4579]  eta: 0:03:16  Lr: 0.030000  Loss: 0.2192  Acc@1: 56.2500 (61.1303)  Acc@5: 93.7500 (90.8954)  time: 0.3436  data: 0.0002  max mem: 2500
Train: Epoch[4/5]  [4020/4579]  eta: 0:03:12  Lr: 0.030000  Loss: 0.1372  Acc@1: 56.2500 (61.1275)  Acc@5: 93.7500 (90.9040)  time: 0.3436  data: 0.0002  max mem: 2500
Train: Epoch[4/5]  [4030/4579]  eta: 0:03:09  Lr: 0.030000  Loss: 0.1748  Acc@1: 62.5000 (61.1294)  Acc@5: 93.7500 (90.9111)  time: 0.3438  data: 0.0002  max mem: 2500
Train: Epoch[4/5]  [4040/4579]  eta: 0:03:05  Lr: 0.030000  Loss: 0.3370  Acc@1: 62.5000 (61.1281)  Acc@5: 93.7500 (90.9150)  time: 0.3448  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [4050/4579]  eta: 0:03:02  Lr: 0.030000  Loss: 0.0177  Acc@1: 62.5000 (61.1331)  Acc@5: 93.7500 (90.9158)  time: 0.3456  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [4060/4579]  eta: 0:02:58  Lr: 0.030000  Loss: 0.1575  Acc@1: 62.5000 (61.1395)  Acc@5: 93.7500 (90.9136)  time: 0.3455  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [4070/4579]  eta: 0:02:55  Lr: 0.030000  Loss: 0.2733  Acc@1: 62.5000 (61.1260)  Acc@5: 87.5000 (90.9021)  time: 0.3457  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [4080/4579]  eta: 0:02:52  Lr: 0.030000  Loss: 0.4164  Acc@1: 56.2500 (61.1278)  Acc@5: 87.5000 (90.9076)  time: 0.3455  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [4090/4579]  eta: 0:02:48  Lr: 0.030000  Loss: 0.2842  Acc@1: 56.2500 (61.1342)  Acc@5: 93.7500 (90.9099)  time: 0.3453  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [4100/4579]  eta: 0:02:45  Lr: 0.030000  Loss: 0.1795  Acc@1: 62.5000 (61.1360)  Acc@5: 93.7500 (90.9138)  time: 0.3458  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [4110/4579]  eta: 0:02:41  Lr: 0.030000  Loss: 0.1566  Acc@1: 62.5000 (61.1348)  Acc@5: 93.7500 (90.9116)  time: 0.3456  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [4120/4579]  eta: 0:02:38  Lr: 0.030000  Loss: -0.2939  Acc@1: 62.5000 (61.1396)  Acc@5: 93.7500 (90.9139)  time: 0.3447  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [4130/4579]  eta: 0:02:34  Lr: 0.030000  Loss: 0.2819  Acc@1: 62.5000 (61.1323)  Acc@5: 87.5000 (90.9102)  time: 0.3446  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [4140/4579]  eta: 0:02:31  Lr: 0.030000  Loss: -0.1215  Acc@1: 56.2500 (61.1265)  Acc@5: 93.7500 (90.9125)  time: 0.3451  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [4150/4579]  eta: 0:02:27  Lr: 0.030000  Loss: 0.3538  Acc@1: 56.2500 (61.1073)  Acc@5: 93.7500 (90.9163)  time: 0.3454  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [4160/4579]  eta: 0:02:24  Lr: 0.030000  Loss: 0.3012  Acc@1: 62.5000 (61.1151)  Acc@5: 93.7500 (90.9186)  time: 0.3445  data: 0.0002  max mem: 2500
Train: Epoch[4/5]  [4170/4579]  eta: 0:02:21  Lr: 0.030000  Loss: 0.0879  Acc@1: 68.7500 (61.1319)  Acc@5: 93.7500 (90.9239)  time: 0.3434  data: 0.0002  max mem: 2500
Train: Epoch[4/5]  [4180/4579]  eta: 0:02:17  Lr: 0.030000  Loss: 0.0534  Acc@1: 68.7500 (61.1367)  Acc@5: 93.7500 (90.9262)  time: 0.3434  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [4190/4579]  eta: 0:02:14  Lr: 0.030000  Loss: 0.0220  Acc@1: 62.5000 (61.1340)  Acc@5: 87.5000 (90.9210)  time: 0.3445  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [4200/4579]  eta: 0:02:10  Lr: 0.030000  Loss: 0.2468  Acc@1: 62.5000 (61.1402)  Acc@5: 93.7500 (90.9218)  time: 0.3459  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [4210/4579]  eta: 0:02:07  Lr: 0.030000  Loss: 0.1506  Acc@1: 62.5000 (61.1375)  Acc@5: 87.5000 (90.9152)  time: 0.3453  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [4220/4579]  eta: 0:02:03  Lr: 0.030000  Loss: 0.3147  Acc@1: 62.5000 (61.1407)  Acc@5: 87.5000 (90.9145)  time: 0.3438  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [4230/4579]  eta: 0:02:00  Lr: 0.030000  Loss: -0.0508  Acc@1: 62.5000 (61.1336)  Acc@5: 93.7500 (90.9197)  time: 0.3435  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [4240/4579]  eta: 0:01:56  Lr: 0.030000  Loss: 0.1826  Acc@1: 62.5000 (61.1309)  Acc@5: 87.5000 (90.9087)  time: 0.3440  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [4250/4579]  eta: 0:01:53  Lr: 0.030000  Loss: 0.2088  Acc@1: 62.5000 (61.1297)  Acc@5: 87.5000 (90.9051)  time: 0.3440  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [4260/4579]  eta: 0:01:50  Lr: 0.030000  Loss: 0.1654  Acc@1: 62.5000 (61.1374)  Acc@5: 93.7500 (90.9059)  time: 0.3441  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [4270/4579]  eta: 0:01:46  Lr: 0.030000  Loss: -0.0039  Acc@1: 68.7500 (61.1493)  Acc@5: 93.7500 (90.9052)  time: 0.3434  data: 0.0002  max mem: 2500
Train: Epoch[4/5]  [4280/4579]  eta: 0:01:43  Lr: 0.030000  Loss: 0.0780  Acc@1: 62.5000 (61.1291)  Acc@5: 87.5000 (90.9075)  time: 0.3425  data: 0.0002  max mem: 2500
Train: Epoch[4/5]  [4290/4579]  eta: 0:01:39  Lr: 0.030000  Loss: 0.2012  Acc@1: 50.0000 (61.1236)  Acc@5: 93.7500 (90.9068)  time: 0.3423  data: 0.0002  max mem: 2500
Train: Epoch[4/5]  [4300/4579]  eta: 0:01:36  Lr: 0.030000  Loss: 0.5650  Acc@1: 62.5000 (61.1297)  Acc@5: 87.5000 (90.9004)  time: 0.3423  data: 0.0002  max mem: 2500
Train: Epoch[4/5]  [4310/4579]  eta: 0:01:32  Lr: 0.030000  Loss: 0.1240  Acc@1: 62.5000 (61.1140)  Acc@5: 87.5000 (90.8925)  time: 0.3435  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [4320/4579]  eta: 0:01:29  Lr: 0.030000  Loss: 0.0414  Acc@1: 56.2500 (61.1085)  Acc@5: 87.5000 (90.8890)  time: 0.3443  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [4330/4579]  eta: 0:01:25  Lr: 0.030000  Loss: 0.3686  Acc@1: 56.2500 (61.1146)  Acc@5: 87.5000 (90.8884)  time: 0.3439  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [4340/4579]  eta: 0:01:22  Lr: 0.030000  Loss: 0.2472  Acc@1: 62.5000 (61.1078)  Acc@5: 87.5000 (90.8834)  time: 0.3438  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [4350/4579]  eta: 0:01:18  Lr: 0.030000  Loss: 0.3784  Acc@1: 62.5000 (61.1124)  Acc@5: 87.5000 (90.8872)  time: 0.3452  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [4360/4579]  eta: 0:01:15  Lr: 0.030000  Loss: 0.3481  Acc@1: 68.7500 (61.1170)  Acc@5: 87.5000 (90.8837)  time: 0.3461  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [4370/4579]  eta: 0:01:12  Lr: 0.030000  Loss: 0.0387  Acc@1: 68.7500 (61.1159)  Acc@5: 87.5000 (90.8831)  time: 0.3456  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [4380/4579]  eta: 0:01:08  Lr: 0.030000  Loss: 0.0408  Acc@1: 68.7500 (61.1419)  Acc@5: 87.5000 (90.8825)  time: 0.3450  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [4390/4579]  eta: 0:01:05  Lr: 0.030000  Loss: -0.1684  Acc@1: 68.7500 (61.1478)  Acc@5: 87.5000 (90.8833)  time: 0.3452  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [4400/4579]  eta: 0:01:01  Lr: 0.030000  Loss: -0.0649  Acc@1: 62.5000 (61.1381)  Acc@5: 87.5000 (90.8799)  time: 0.3456  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [4410/4579]  eta: 0:00:58  Lr: 0.030000  Loss: 0.3028  Acc@1: 56.2500 (61.1327)  Acc@5: 87.5000 (90.8779)  time: 0.3448  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [4420/4579]  eta: 0:00:54  Lr: 0.030000  Loss: 0.0520  Acc@1: 56.2500 (61.1216)  Acc@5: 87.5000 (90.8745)  time: 0.3444  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [4430/4579]  eta: 0:00:51  Lr: 0.030000  Loss: 0.2833  Acc@1: 62.5000 (61.1332)  Acc@5: 93.7500 (90.8754)  time: 0.3444  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [4440/4579]  eta: 0:00:47  Lr: 0.030000  Loss: 0.3191  Acc@1: 62.5000 (61.1405)  Acc@5: 93.7500 (90.8762)  time: 0.3443  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [4450/4579]  eta: 0:00:44  Lr: 0.030000  Loss: 0.4518  Acc@1: 62.5000 (61.1394)  Acc@5: 87.5000 (90.8714)  time: 0.3444  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [4460/4579]  eta: 0:00:41  Lr: 0.030000  Loss: 0.2614  Acc@1: 68.7500 (61.1522)  Acc@5: 87.5000 (90.8765)  time: 0.3443  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [4470/4579]  eta: 0:00:37  Lr: 0.030000  Loss: 0.1135  Acc@1: 68.7500 (61.1580)  Acc@5: 93.7500 (90.8787)  time: 0.3434  data: 0.0002  max mem: 2500
Train: Epoch[4/5]  [4480/4579]  eta: 0:00:34  Lr: 0.030000  Loss: -0.0817  Acc@1: 62.5000 (61.1708)  Acc@5: 93.7500 (90.8851)  time: 0.3429  data: 0.0002  max mem: 2500
Train: Epoch[4/5]  [4490/4579]  eta: 0:00:30  Lr: 0.030000  Loss: 0.1265  Acc@1: 62.5000 (61.1807)  Acc@5: 93.7500 (90.8859)  time: 0.3431  data: 0.0002  max mem: 2500
Train: Epoch[4/5]  [4500/4579]  eta: 0:00:27  Lr: 0.030000  Loss: 0.1337  Acc@1: 62.5000 (61.1892)  Acc@5: 93.7500 (90.8854)  time: 0.3440  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [4510/4579]  eta: 0:00:23  Lr: 0.030000  Loss: 0.0414  Acc@1: 62.5000 (61.1949)  Acc@5: 87.5000 (90.8792)  time: 0.3458  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [4520/4579]  eta: 0:00:20  Lr: 0.030000  Loss: 0.0564  Acc@1: 62.5000 (61.1964)  Acc@5: 87.5000 (90.8718)  time: 0.3454  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [4530/4579]  eta: 0:00:16  Lr: 0.030000  Loss: 0.3052  Acc@1: 62.5000 (61.2061)  Acc@5: 87.5000 (90.8643)  time: 0.3444  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [4540/4579]  eta: 0:00:13  Lr: 0.030000  Loss: 0.0860  Acc@1: 62.5000 (61.2145)  Acc@5: 87.5000 (90.8542)  time: 0.3445  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [4550/4579]  eta: 0:00:10  Lr: 0.030000  Loss: 0.2875  Acc@1: 62.5000 (61.2228)  Acc@5: 87.5000 (90.8537)  time: 0.3446  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [4560/4579]  eta: 0:00:06  Lr: 0.030000  Loss: 0.2316  Acc@1: 62.5000 (61.2215)  Acc@5: 87.5000 (90.8532)  time: 0.3452  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [4570/4579]  eta: 0:00:03  Lr: 0.030000  Loss: 0.4995  Acc@1: 62.5000 (61.2120)  Acc@5: 87.5000 (90.8499)  time: 0.3456  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [4578/4579]  eta: 0:00:00  Lr: 0.030000  Loss: 0.3867  Acc@1: 62.5000 (61.2119)  Acc@5: 87.5000 (90.8405)  time: 0.3377  data: 0.0005  max mem: 2500
Train: Epoch[4/5] Total time: 0:26:19 (0.3449 s / it)
{0: {0: 293028, 1: 0, 2: 0, 3: 0, 4: 0}, 1: {0: 293028, 1: 0, 2: 0, 3: 0, 4: 0}, 2: {0: 293028, 1: 0, 2: 0, 3: 0, 4: 0}, 3: {0: 293028, 1: 0, 2: 0, 3: 0, 4: 0}, 4: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 5: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 6: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 7: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 8: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 9: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 10: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 11: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 12: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 13: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 14: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 15: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 16: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 17: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 18: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 19: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}}
Averaged stats: Lr: 0.030000  Loss: 0.3867  Acc@1: 62.5000 (61.2119)  Acc@5: 87.5000 (90.8405)
Train: Epoch[5/5]  [   0/4579]  eta: 0:46:14  Lr: 0.030000  Loss: -0.0287  Acc@1: 62.5000 (62.5000)  Acc@5: 100.0000 (100.0000)  time: 0.6060  data: 0.2640  max mem: 2500
Train: Epoch[5/5]  [  10/4579]  eta: 0:28:03  Lr: 0.030000  Loss: 0.0885  Acc@1: 50.0000 (50.0000)  Acc@5: 93.7500 (91.4773)  time: 0.3685  data: 0.0242  max mem: 2500
Train: Epoch[5/5]  [  20/4579]  eta: 0:27:04  Lr: 0.030000  Loss: 0.2061  Acc@1: 56.2500 (55.3571)  Acc@5: 93.7500 (91.3690)  time: 0.3439  data: 0.0002  max mem: 2500
Train: Epoch[5/5]  [  30/4579]  eta: 0:26:48  Lr: 0.030000  Loss: -0.0005  Acc@1: 62.5000 (55.8468)  Acc@5: 93.7500 (91.3306)  time: 0.3454  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [  40/4579]  eta: 0:26:34  Lr: 0.030000  Loss: -0.1060  Acc@1: 68.7500 (58.6890)  Acc@5: 93.7500 (92.2256)  time: 0.3461  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [  50/4579]  eta: 0:26:26  Lr: 0.030000  Loss: -0.1692  Acc@1: 68.7500 (60.0490)  Acc@5: 93.7500 (92.0343)  time: 0.3454  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [  60/4579]  eta: 0:26:19  Lr: 0.030000  Loss: 0.3289  Acc@1: 62.5000 (60.0410)  Acc@5: 87.5000 (91.4959)  time: 0.3456  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [  70/4579]  eta: 0:26:12  Lr: 0.030000  Loss: 0.4262  Acc@1: 62.5000 (60.5634)  Acc@5: 87.5000 (91.2852)  time: 0.3447  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [  80/4579]  eta: 0:26:07  Lr: 0.030000  Loss: 0.0968  Acc@1: 62.5000 (60.9568)  Acc@5: 87.5000 (91.0494)  time: 0.3449  data: 0.0002  max mem: 2500
Train: Epoch[5/5]  [  90/4579]  eta: 0:26:02  Lr: 0.030000  Loss: 0.3402  Acc@1: 62.5000 (61.0577)  Acc@5: 87.5000 (91.0027)  time: 0.3451  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [ 100/4579]  eta: 0:25:57  Lr: 0.030000  Loss: 0.3547  Acc@1: 62.5000 (61.5099)  Acc@5: 87.5000 (90.7797)  time: 0.3452  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [ 110/4579]  eta: 0:25:52  Lr: 0.030000  Loss: -0.0241  Acc@1: 68.7500 (62.0495)  Acc@5: 93.7500 (90.8221)  time: 0.3445  data: 0.0002  max mem: 2500
Train: Epoch[5/5]  [ 120/4579]  eta: 0:25:47  Lr: 0.030000  Loss: 0.0504  Acc@1: 62.5000 (61.6736)  Acc@5: 87.5000 (90.4959)  time: 0.3434  data: 0.0002  max mem: 2500
Train: Epoch[5/5]  [ 130/4579]  eta: 0:25:42  Lr: 0.030000  Loss: 0.3315  Acc@1: 56.2500 (61.1641)  Acc@5: 87.5000 (90.3149)  time: 0.3436  data: 0.0002  max mem: 2500
Train: Epoch[5/5]  [ 140/4579]  eta: 0:25:38  Lr: 0.030000  Loss: 0.2895  Acc@1: 50.0000 (60.9929)  Acc@5: 87.5000 (90.1596)  time: 0.3439  data: 0.0002  max mem: 2500
Train: Epoch[5/5]  [ 150/4579]  eta: 0:25:34  Lr: 0.030000  Loss: 0.4610  Acc@1: 56.2500 (60.8858)  Acc@5: 87.5000 (90.3560)  time: 0.3451  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [ 160/4579]  eta: 0:25:31  Lr: 0.030000  Loss: 0.1011  Acc@1: 56.2500 (60.8307)  Acc@5: 93.7500 (90.2950)  time: 0.3459  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 170/4579]  eta: 0:25:27  Lr: 0.030000  Loss: 0.0078  Acc@1: 68.7500 (61.3670)  Acc@5: 93.7500 (90.4240)  time: 0.3453  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [ 180/4579]  eta: 0:25:23  Lr: 0.030000  Loss: 0.3887  Acc@1: 62.5000 (61.1533)  Acc@5: 87.5000 (90.1934)  time: 0.3460  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 190/4579]  eta: 0:25:20  Lr: 0.030000  Loss: 0.5769  Acc@1: 62.5000 (61.3547)  Acc@5: 87.5000 (90.2814)  time: 0.3461  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 200/4579]  eta: 0:25:16  Lr: 0.030000  Loss: 0.3733  Acc@1: 62.5000 (61.2873)  Acc@5: 93.7500 (90.2363)  time: 0.3458  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 210/4579]  eta: 0:25:13  Lr: 0.030000  Loss: 0.2550  Acc@1: 62.5000 (61.1374)  Acc@5: 87.5000 (90.1659)  time: 0.3460  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [ 220/4579]  eta: 0:25:09  Lr: 0.030000  Loss: 0.2204  Acc@1: 56.2500 (61.0577)  Acc@5: 93.7500 (90.2432)  time: 0.3456  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [ 230/4579]  eta: 0:25:05  Lr: 0.030000  Loss: 0.0621  Acc@1: 62.5000 (61.3636)  Acc@5: 93.7500 (90.1515)  time: 0.3455  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [ 240/4579]  eta: 0:25:02  Lr: 0.030000  Loss: 0.1751  Acc@1: 68.7500 (61.4627)  Acc@5: 87.5000 (90.2230)  time: 0.3461  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [ 250/4579]  eta: 0:24:58  Lr: 0.030000  Loss: 0.0872  Acc@1: 62.5000 (61.7530)  Acc@5: 93.7500 (90.3635)  time: 0.3458  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [ 260/4579]  eta: 0:24:55  Lr: 0.030000  Loss: -0.0753  Acc@1: 62.5000 (61.8295)  Acc@5: 93.7500 (90.3736)  time: 0.3453  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [ 270/4579]  eta: 0:24:51  Lr: 0.030000  Loss: 0.0394  Acc@1: 62.5000 (61.7620)  Acc@5: 93.7500 (90.4290)  time: 0.3449  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [ 280/4579]  eta: 0:24:47  Lr: 0.030000  Loss: 0.1602  Acc@1: 56.2500 (61.7438)  Acc@5: 93.7500 (90.4359)  time: 0.3440  data: 0.0002  max mem: 2500
Train: Epoch[5/5]  [ 290/4579]  eta: 0:24:43  Lr: 0.030000  Loss: -0.0533  Acc@1: 56.2500 (61.7053)  Acc@5: 93.7500 (90.5284)  time: 0.3438  data: 0.0002  max mem: 2500
Train: Epoch[5/5]  [ 300/4579]  eta: 0:24:40  Lr: 0.030000  Loss: 0.2152  Acc@1: 62.5000 (61.8978)  Acc@5: 93.7500 (90.7184)  time: 0.3439  data: 0.0002  max mem: 2500
Train: Epoch[5/5]  [ 310/4579]  eta: 0:24:36  Lr: 0.030000  Loss: -0.2001  Acc@1: 62.5000 (61.9373)  Acc@5: 93.7500 (90.6953)  time: 0.3441  data: 0.0002  max mem: 2500
Train: Epoch[5/5]  [ 320/4579]  eta: 0:24:32  Lr: 0.030000  Loss: 0.0982  Acc@1: 62.5000 (61.9548)  Acc@5: 93.7500 (90.7516)  time: 0.3441  data: 0.0002  max mem: 2500
Train: Epoch[5/5]  [ 330/4579]  eta: 0:24:29  Lr: 0.030000  Loss: 0.3657  Acc@1: 62.5000 (61.9902)  Acc@5: 93.7500 (90.7666)  time: 0.3442  data: 0.0002  max mem: 2500
Train: Epoch[5/5]  [ 340/4579]  eta: 0:24:25  Lr: 0.030000  Loss: -0.2186  Acc@1: 56.2500 (61.8402)  Acc@5: 93.7500 (90.7441)  time: 0.3456  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [ 350/4579]  eta: 0:24:22  Lr: 0.030000  Loss: 0.2293  Acc@1: 62.5000 (61.8768)  Acc@5: 93.7500 (90.7229)  time: 0.3468  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 360/4579]  eta: 0:24:18  Lr: 0.030000  Loss: 0.2506  Acc@1: 68.7500 (61.9287)  Acc@5: 87.5000 (90.6683)  time: 0.3464  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 370/4579]  eta: 0:24:15  Lr: 0.030000  Loss: -0.1154  Acc@1: 56.2500 (61.7251)  Acc@5: 87.5000 (90.5829)  time: 0.3459  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 380/4579]  eta: 0:24:12  Lr: 0.030000  Loss: 0.3453  Acc@1: 56.2500 (61.6634)  Acc@5: 87.5000 (90.6332)  time: 0.3462  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 390/4579]  eta: 0:24:08  Lr: 0.030000  Loss: 0.1026  Acc@1: 68.7500 (61.7008)  Acc@5: 87.5000 (90.5691)  time: 0.3455  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 400/4579]  eta: 0:24:05  Lr: 0.030000  Loss: -0.3870  Acc@1: 68.7500 (61.8610)  Acc@5: 87.5000 (90.6016)  time: 0.3460  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 410/4579]  eta: 0:24:01  Lr: 0.030000  Loss: 0.1137  Acc@1: 68.7500 (61.9982)  Acc@5: 93.7500 (90.5414)  time: 0.3466  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 420/4579]  eta: 0:23:58  Lr: 0.030000  Loss: -0.0786  Acc@1: 62.5000 (61.9359)  Acc@5: 87.5000 (90.4097)  time: 0.3456  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [ 430/4579]  eta: 0:23:54  Lr: 0.030000  Loss: 0.0422  Acc@1: 62.5000 (62.0215)  Acc@5: 87.5000 (90.4147)  time: 0.3451  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 440/4579]  eta: 0:23:51  Lr: 0.030000  Loss: 0.1660  Acc@1: 68.7500 (62.0607)  Acc@5: 93.7500 (90.4904)  time: 0.3457  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 450/4579]  eta: 0:23:48  Lr: 0.030000  Loss: 0.0271  Acc@1: 62.5000 (62.1951)  Acc@5: 93.7500 (90.5626)  time: 0.3513  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [ 460/4579]  eta: 0:23:45  Lr: 0.030000  Loss: 0.2078  Acc@1: 62.5000 (62.1068)  Acc@5: 93.7500 (90.5640)  time: 0.3505  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 470/4579]  eta: 0:23:41  Lr: 0.030000  Loss: 0.0872  Acc@1: 56.2500 (61.9559)  Acc@5: 93.7500 (90.5387)  time: 0.3453  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [ 480/4579]  eta: 0:23:38  Lr: 0.030000  Loss: 0.2161  Acc@1: 62.5000 (62.0582)  Acc@5: 93.7500 (90.5925)  time: 0.3452  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [ 490/4579]  eta: 0:23:34  Lr: 0.030000  Loss: 0.3092  Acc@1: 62.5000 (61.9526)  Acc@5: 93.7500 (90.6441)  time: 0.3456  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [ 500/4579]  eta: 0:23:31  Lr: 0.030000  Loss: 0.0916  Acc@1: 62.5000 (61.9636)  Acc@5: 87.5000 (90.5564)  time: 0.3455  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [ 510/4579]  eta: 0:23:27  Lr: 0.030000  Loss: 0.2367  Acc@1: 56.2500 (61.7417)  Acc@5: 87.5000 (90.5455)  time: 0.3448  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [ 520/4579]  eta: 0:23:24  Lr: 0.030000  Loss: -0.0252  Acc@1: 50.0000 (61.7202)  Acc@5: 87.5000 (90.5230)  time: 0.3450  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [ 530/4579]  eta: 0:23:20  Lr: 0.030000  Loss: 0.3309  Acc@1: 62.5000 (61.7114)  Acc@5: 87.5000 (90.5014)  time: 0.3456  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [ 540/4579]  eta: 0:23:17  Lr: 0.030000  Loss: 0.3325  Acc@1: 62.5000 (61.6451)  Acc@5: 93.7500 (90.5268)  time: 0.3445  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [ 550/4579]  eta: 0:23:13  Lr: 0.030000  Loss: -0.1229  Acc@1: 62.5000 (61.6720)  Acc@5: 93.7500 (90.5059)  time: 0.3431  data: 0.0002  max mem: 2500
Train: Epoch[5/5]  [ 560/4579]  eta: 0:23:09  Lr: 0.030000  Loss: -0.0980  Acc@1: 68.7500 (61.7647)  Acc@5: 87.5000 (90.4635)  time: 0.3432  data: 0.0002  max mem: 2500
Train: Epoch[5/5]  [ 570/4579]  eta: 0:23:06  Lr: 0.030000  Loss: 0.2594  Acc@1: 62.5000 (61.7447)  Acc@5: 87.5000 (90.4882)  time: 0.3431  data: 0.0002  max mem: 2500
Train: Epoch[5/5]  [ 580/4579]  eta: 0:23:02  Lr: 0.030000  Loss: 0.0711  Acc@1: 62.5000 (61.7470)  Acc@5: 93.7500 (90.4905)  time: 0.3430  data: 0.0002  max mem: 2500
Train: Epoch[5/5]  [ 590/4579]  eta: 0:22:58  Lr: 0.030000  Loss: 0.1388  Acc@1: 62.5000 (61.7069)  Acc@5: 87.5000 (90.4717)  time: 0.3431  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [ 600/4579]  eta: 0:22:55  Lr: 0.030000  Loss: 0.0680  Acc@1: 56.2500 (61.6577)  Acc@5: 87.5000 (90.4638)  time: 0.3431  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [ 610/4579]  eta: 0:22:51  Lr: 0.030000  Loss: 0.3094  Acc@1: 56.2500 (61.6817)  Acc@5: 93.7500 (90.4460)  time: 0.3431  data: 0.0002  max mem: 2500
Train: Epoch[5/5]  [ 620/4579]  eta: 0:22:47  Lr: 0.030000  Loss: -0.0499  Acc@1: 68.7500 (61.8056)  Acc@5: 93.7500 (90.4791)  time: 0.3436  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [ 630/4579]  eta: 0:22:44  Lr: 0.030000  Loss: 0.2182  Acc@1: 62.5000 (61.7670)  Acc@5: 87.5000 (90.4517)  time: 0.3450  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 640/4579]  eta: 0:22:41  Lr: 0.030000  Loss: 0.3056  Acc@1: 62.5000 (61.8955)  Acc@5: 93.7500 (90.4934)  time: 0.3455  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 650/4579]  eta: 0:22:37  Lr: 0.030000  Loss: 0.2873  Acc@1: 62.5000 (61.9336)  Acc@5: 93.7500 (90.5338)  time: 0.3453  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 660/4579]  eta: 0:22:34  Lr: 0.030000  Loss: 0.2526  Acc@1: 56.2500 (61.8949)  Acc@5: 87.5000 (90.4974)  time: 0.3462  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 670/4579]  eta: 0:22:30  Lr: 0.030000  Loss: 0.5357  Acc@1: 56.2500 (61.9318)  Acc@5: 87.5000 (90.5272)  time: 0.3461  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 680/4579]  eta: 0:22:27  Lr: 0.030000  Loss: -0.1793  Acc@1: 62.5000 (61.8484)  Acc@5: 93.7500 (90.5378)  time: 0.3454  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 690/4579]  eta: 0:22:23  Lr: 0.030000  Loss: 0.3030  Acc@1: 50.0000 (61.7855)  Acc@5: 87.5000 (90.4848)  time: 0.3451  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [ 700/4579]  eta: 0:22:20  Lr: 0.030000  Loss: 0.2370  Acc@1: 56.2500 (61.8046)  Acc@5: 93.7500 (90.5136)  time: 0.3469  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [ 710/4579]  eta: 0:22:17  Lr: 0.030000  Loss: -0.0670  Acc@1: 62.5000 (61.8143)  Acc@5: 93.7500 (90.5591)  time: 0.3471  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [ 720/4579]  eta: 0:22:13  Lr: 0.030000  Loss: -0.0017  Acc@1: 62.5000 (61.8499)  Acc@5: 93.7500 (90.5773)  time: 0.3456  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 730/4579]  eta: 0:22:10  Lr: 0.030000  Loss: 0.4475  Acc@1: 56.2500 (61.7904)  Acc@5: 87.5000 (90.5523)  time: 0.3454  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 740/4579]  eta: 0:22:06  Lr: 0.030000  Loss: -0.1280  Acc@1: 62.5000 (61.8843)  Acc@5: 87.5000 (90.5617)  time: 0.3450  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 750/4579]  eta: 0:22:03  Lr: 0.030000  Loss: 0.2620  Acc@1: 62.5000 (61.8842)  Acc@5: 87.5000 (90.5459)  time: 0.3456  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 760/4579]  eta: 0:21:59  Lr: 0.030000  Loss: 0.3768  Acc@1: 62.5000 (61.9005)  Acc@5: 87.5000 (90.5552)  time: 0.3462  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 770/4579]  eta: 0:21:56  Lr: 0.030000  Loss: -0.0603  Acc@1: 62.5000 (61.9244)  Acc@5: 93.7500 (90.5723)  time: 0.3462  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 780/4579]  eta: 0:21:52  Lr: 0.030000  Loss: 0.4081  Acc@1: 62.5000 (61.9558)  Acc@5: 93.7500 (90.6050)  time: 0.3460  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 790/4579]  eta: 0:21:49  Lr: 0.030000  Loss: 0.3345  Acc@1: 56.2500 (61.8916)  Acc@5: 93.7500 (90.5657)  time: 0.3455  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 800/4579]  eta: 0:21:46  Lr: 0.030000  Loss: 0.1324  Acc@1: 56.2500 (61.8758)  Acc@5: 93.7500 (90.5743)  time: 0.3453  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 810/4579]  eta: 0:21:42  Lr: 0.030000  Loss: 0.1926  Acc@1: 56.2500 (61.8141)  Acc@5: 87.5000 (90.5133)  time: 0.3455  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [ 820/4579]  eta: 0:21:39  Lr: 0.030000  Loss: -0.2124  Acc@1: 56.2500 (61.8301)  Acc@5: 87.5000 (90.4994)  time: 0.3452  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [ 830/4579]  eta: 0:21:35  Lr: 0.030000  Loss: 0.2699  Acc@1: 62.5000 (61.8306)  Acc@5: 87.5000 (90.5159)  time: 0.3456  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [ 840/4579]  eta: 0:21:32  Lr: 0.030000  Loss: -0.1094  Acc@1: 62.5000 (61.8089)  Acc@5: 87.5000 (90.5321)  time: 0.3454  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [ 850/4579]  eta: 0:21:28  Lr: 0.030000  Loss: -0.0771  Acc@1: 62.5000 (61.8684)  Acc@5: 87.5000 (90.5405)  time: 0.3450  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [ 860/4579]  eta: 0:21:25  Lr: 0.030000  Loss: 0.1261  Acc@1: 62.5000 (61.8539)  Acc@5: 93.7500 (90.5778)  time: 0.3458  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [ 870/4579]  eta: 0:21:21  Lr: 0.030000  Loss: 0.2560  Acc@1: 56.2500 (61.7537)  Acc@5: 93.7500 (90.5712)  time: 0.3457  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [ 880/4579]  eta: 0:21:18  Lr: 0.030000  Loss: 0.3380  Acc@1: 56.2500 (61.6984)  Acc@5: 87.5000 (90.5009)  time: 0.3442  data: 0.0002  max mem: 2500
Train: Epoch[5/5]  [ 890/4579]  eta: 0:21:14  Lr: 0.030000  Loss: 0.0313  Acc@1: 62.5000 (61.7354)  Acc@5: 87.5000 (90.4602)  time: 0.3433  data: 0.0002  max mem: 2500
Train: Epoch[5/5]  [ 900/4579]  eta: 0:21:11  Lr: 0.030000  Loss: 0.4051  Acc@1: 62.5000 (61.6398)  Acc@5: 87.5000 (90.4550)  time: 0.3432  data: 0.0002  max mem: 2500
Train: Epoch[5/5]  [ 910/4579]  eta: 0:21:07  Lr: 0.030000  Loss: 0.1848  Acc@1: 62.5000 (61.7248)  Acc@5: 93.7500 (90.5049)  time: 0.3431  data: 0.0002  max mem: 2500
Train: Epoch[5/5]  [ 920/4579]  eta: 0:21:04  Lr: 0.030000  Loss: 0.1485  Acc@1: 62.5000 (61.6857)  Acc@5: 93.7500 (90.5062)  time: 0.3433  data: 0.0002  max mem: 2500
Train: Epoch[5/5]  [ 930/4579]  eta: 0:21:00  Lr: 0.030000  Loss: -0.0261  Acc@1: 62.5000 (61.7548)  Acc@5: 93.7500 (90.5344)  time: 0.3434  data: 0.0002  max mem: 2500
Train: Epoch[5/5]  [ 940/4579]  eta: 0:20:56  Lr: 0.030000  Loss: 0.2202  Acc@1: 68.7500 (61.7694)  Acc@5: 87.5000 (90.5021)  time: 0.3432  data: 0.0002  max mem: 2500
Train: Epoch[5/5]  [ 950/4579]  eta: 0:20:53  Lr: 0.030000  Loss: 0.3610  Acc@1: 62.5000 (61.7902)  Acc@5: 87.5000 (90.4837)  time: 0.3434  data: 0.0002  max mem: 2500
Train: Epoch[5/5]  [ 960/4579]  eta: 0:20:49  Lr: 0.030000  Loss: -0.2040  Acc@1: 62.5000 (61.8561)  Acc@5: 93.7500 (90.5047)  time: 0.3447  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [ 970/4579]  eta: 0:20:46  Lr: 0.030000  Loss: -0.2347  Acc@1: 62.5000 (61.8306)  Acc@5: 93.7500 (90.4866)  time: 0.3460  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [ 980/4579]  eta: 0:20:43  Lr: 0.030000  Loss: 0.2457  Acc@1: 62.5000 (61.8438)  Acc@5: 93.7500 (90.5071)  time: 0.3457  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 990/4579]  eta: 0:20:39  Lr: 0.030000  Loss: 0.3465  Acc@1: 62.5000 (61.8315)  Acc@5: 93.7500 (90.5146)  time: 0.3452  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1000/4579]  eta: 0:20:36  Lr: 0.030000  Loss: 0.0363  Acc@1: 56.2500 (61.7632)  Acc@5: 87.5000 (90.4783)  time: 0.3450  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1010/4579]  eta: 0:20:32  Lr: 0.030000  Loss: 0.2454  Acc@1: 56.2500 (61.7582)  Acc@5: 87.5000 (90.4735)  time: 0.3448  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1020/4579]  eta: 0:20:29  Lr: 0.030000  Loss: -0.0382  Acc@1: 56.2500 (61.7471)  Acc@5: 87.5000 (90.4689)  time: 0.3444  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1030/4579]  eta: 0:20:25  Lr: 0.030000  Loss: 0.2854  Acc@1: 56.2500 (61.7544)  Acc@5: 87.5000 (90.4583)  time: 0.3451  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1040/4579]  eta: 0:20:22  Lr: 0.030000  Loss: 0.3692  Acc@1: 56.2500 (61.7135)  Acc@5: 87.5000 (90.4659)  time: 0.3455  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1050/4579]  eta: 0:20:18  Lr: 0.030000  Loss: -0.0184  Acc@1: 56.2500 (61.7031)  Acc@5: 87.5000 (90.4377)  time: 0.3458  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1060/4579]  eta: 0:20:15  Lr: 0.030000  Loss: 0.2729  Acc@1: 62.5000 (61.7637)  Acc@5: 93.7500 (90.4807)  time: 0.3460  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [1070/4579]  eta: 0:20:11  Lr: 0.030000  Loss: -0.0635  Acc@1: 68.7500 (61.8289)  Acc@5: 93.7500 (90.5229)  time: 0.3454  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1080/4579]  eta: 0:20:08  Lr: 0.030000  Loss: 0.2002  Acc@1: 62.5000 (61.8582)  Acc@5: 93.7500 (90.5296)  time: 0.3456  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [1090/4579]  eta: 0:20:05  Lr: 0.030000  Loss: 0.3514  Acc@1: 56.2500 (61.8297)  Acc@5: 87.5000 (90.5018)  time: 0.3464  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [1100/4579]  eta: 0:20:01  Lr: 0.030000  Loss: -0.0371  Acc@1: 56.2500 (61.8245)  Acc@5: 87.5000 (90.4916)  time: 0.3464  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [1110/4579]  eta: 0:19:58  Lr: 0.030000  Loss: -0.0031  Acc@1: 68.7500 (61.8868)  Acc@5: 93.7500 (90.5097)  time: 0.3454  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1120/4579]  eta: 0:19:55  Lr: 0.030000  Loss: -0.0603  Acc@1: 62.5000 (61.9034)  Acc@5: 93.7500 (90.5442)  time: 0.3495  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1130/4579]  eta: 0:19:51  Lr: 0.030000  Loss: 0.4299  Acc@1: 56.2500 (61.8369)  Acc@5: 93.7500 (90.5228)  time: 0.3495  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [1140/4579]  eta: 0:19:48  Lr: 0.030000  Loss: 0.3004  Acc@1: 56.2500 (61.8865)  Acc@5: 93.7500 (90.5291)  time: 0.3450  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [1150/4579]  eta: 0:19:44  Lr: 0.030000  Loss: -0.1038  Acc@1: 68.7500 (61.8973)  Acc@5: 93.7500 (90.5463)  time: 0.3448  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [1160/4579]  eta: 0:19:41  Lr: 0.030000  Loss: 0.2754  Acc@1: 56.2500 (61.8271)  Acc@5: 87.5000 (90.5254)  time: 0.3456  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [1170/4579]  eta: 0:19:37  Lr: 0.030000  Loss: 0.1593  Acc@1: 56.2500 (61.8382)  Acc@5: 87.5000 (90.5209)  time: 0.3459  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [1180/4579]  eta: 0:19:34  Lr: 0.030000  Loss: 0.1234  Acc@1: 62.5000 (61.8491)  Acc@5: 93.7500 (90.5483)  time: 0.3450  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [1190/4579]  eta: 0:19:30  Lr: 0.030000  Loss: 0.3689  Acc@1: 56.2500 (61.7916)  Acc@5: 87.5000 (90.5437)  time: 0.3445  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [1200/4579]  eta: 0:19:27  Lr: 0.030000  Loss: 0.3055  Acc@1: 56.2500 (61.7923)  Acc@5: 87.5000 (90.5704)  time: 0.3459  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [1210/4579]  eta: 0:19:23  Lr: 0.030000  Loss: 0.4842  Acc@1: 56.2500 (61.7671)  Acc@5: 93.7500 (90.5605)  time: 0.3449  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [1220/4579]  eta: 0:19:20  Lr: 0.030000  Loss: 0.0898  Acc@1: 56.2500 (61.7680)  Acc@5: 87.5000 (90.5252)  time: 0.3425  data: 0.0002  max mem: 2500
Train: Epoch[5/5]  [1230/4579]  eta: 0:19:16  Lr: 0.030000  Loss: 0.0943  Acc@1: 56.2500 (61.7790)  Acc@5: 93.7500 (90.5615)  time: 0.3425  data: 0.0002  max mem: 2500
Train: Epoch[5/5]  [1240/4579]  eta: 0:19:13  Lr: 0.030000  Loss: 0.0605  Acc@1: 62.5000 (61.7899)  Acc@5: 93.7500 (90.6074)  time: 0.3426  data: 0.0002  max mem: 2500
Train: Epoch[5/5]  [1250/4579]  eta: 0:19:09  Lr: 0.030000  Loss: -0.1390  Acc@1: 62.5000 (61.7806)  Acc@5: 93.7500 (90.5825)  time: 0.3425  data: 0.0002  max mem: 2500
Train: Epoch[5/5]  [1260/4579]  eta: 0:19:06  Lr: 0.030000  Loss: -0.0580  Acc@1: 62.5000 (61.7615)  Acc@5: 93.7500 (90.6176)  time: 0.3423  data: 0.0002  max mem: 2500
Train: Epoch[5/5]  [1270/4579]  eta: 0:19:02  Lr: 0.030000  Loss: 0.2289  Acc@1: 62.5000 (61.7722)  Acc@5: 93.7500 (90.6373)  time: 0.3425  data: 0.0002  max mem: 2500
Train: Epoch[5/5]  [1280/4579]  eta: 0:18:59  Lr: 0.030000  Loss: 0.0739  Acc@1: 56.2500 (61.7486)  Acc@5: 93.7500 (90.6421)  time: 0.3425  data: 0.0002  max mem: 2500
Train: Epoch[5/5]  [1290/4579]  eta: 0:18:55  Lr: 0.030000  Loss: 0.2037  Acc@1: 56.2500 (61.7690)  Acc@5: 93.7500 (90.6565)  time: 0.3428  data: 0.0002  max mem: 2500
Train: Epoch[5/5]  [1300/4579]  eta: 0:18:52  Lr: 0.030000  Loss: 0.3975  Acc@1: 62.5000 (61.7938)  Acc@5: 93.7500 (90.6802)  time: 0.3442  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [1310/4579]  eta: 0:18:48  Lr: 0.030000  Loss: 0.0840  Acc@1: 68.7500 (61.8087)  Acc@5: 93.7500 (90.6846)  time: 0.3455  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1320/4579]  eta: 0:18:45  Lr: 0.030000  Loss: 0.2221  Acc@1: 62.5000 (61.8092)  Acc@5: 93.7500 (90.6747)  time: 0.3450  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1330/4579]  eta: 0:18:41  Lr: 0.030000  Loss: 0.2539  Acc@1: 62.5000 (61.7722)  Acc@5: 93.7500 (90.6931)  time: 0.3451  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1340/4579]  eta: 0:18:38  Lr: 0.030000  Loss: 0.0878  Acc@1: 62.5000 (61.7962)  Acc@5: 93.7500 (90.7019)  time: 0.3457  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1350/4579]  eta: 0:18:34  Lr: 0.030000  Loss: 0.1265  Acc@1: 62.5000 (61.7459)  Acc@5: 93.7500 (90.7013)  time: 0.3456  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1360/4579]  eta: 0:18:31  Lr: 0.030000  Loss: -0.3039  Acc@1: 62.5000 (61.7836)  Acc@5: 93.7500 (90.7283)  time: 0.3462  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1370/4579]  eta: 0:18:28  Lr: 0.030000  Loss: 0.1618  Acc@1: 62.5000 (61.7843)  Acc@5: 93.7500 (90.6820)  time: 0.3462  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1380/4579]  eta: 0:18:24  Lr: 0.030000  Loss: 0.1572  Acc@1: 62.5000 (61.8030)  Acc@5: 87.5000 (90.6997)  time: 0.3462  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1390/4579]  eta: 0:18:21  Lr: 0.030000  Loss: -0.1740  Acc@1: 62.5000 (61.7811)  Acc@5: 93.7500 (90.6722)  time: 0.3460  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1400/4579]  eta: 0:18:17  Lr: 0.030000  Loss: -0.0351  Acc@1: 62.5000 (61.8130)  Acc@5: 87.5000 (90.6852)  time: 0.3451  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1410/4579]  eta: 0:18:14  Lr: 0.030000  Loss: 0.0452  Acc@1: 68.7500 (61.8533)  Acc@5: 93.7500 (90.6892)  time: 0.3452  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [1420/4579]  eta: 0:18:10  Lr: 0.030000  Loss: 0.2416  Acc@1: 62.5000 (61.8315)  Acc@5: 93.7500 (90.7020)  time: 0.3454  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1430/4579]  eta: 0:18:07  Lr: 0.030000  Loss: 0.1765  Acc@1: 56.2500 (61.8187)  Acc@5: 93.7500 (90.7276)  time: 0.3453  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1440/4579]  eta: 0:18:03  Lr: 0.030000  Loss: 0.0691  Acc@1: 62.5000 (61.8668)  Acc@5: 93.7500 (90.7269)  time: 0.3453  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1450/4579]  eta: 0:18:00  Lr: 0.030000  Loss: 0.0677  Acc@1: 62.5000 (61.8797)  Acc@5: 93.7500 (90.7348)  time: 0.3454  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1460/4579]  eta: 0:17:56  Lr: 0.030000  Loss: 0.1646  Acc@1: 62.5000 (61.8455)  Acc@5: 87.5000 (90.7255)  time: 0.3454  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1470/4579]  eta: 0:17:53  Lr: 0.030000  Loss: 0.0870  Acc@1: 56.2500 (61.8117)  Acc@5: 87.5000 (90.6951)  time: 0.3494  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1480/4579]  eta: 0:17:50  Lr: 0.030000  Loss: -0.0281  Acc@1: 62.5000 (61.8754)  Acc@5: 93.7500 (90.7200)  time: 0.3492  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [1490/4579]  eta: 0:17:46  Lr: 0.030000  Loss: 0.0833  Acc@1: 62.5000 (61.8545)  Acc@5: 93.7500 (90.6900)  time: 0.3453  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [1500/4579]  eta: 0:17:43  Lr: 0.030000  Loss: 0.0394  Acc@1: 62.5000 (61.8629)  Acc@5: 93.7500 (90.7145)  time: 0.3456  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [1510/4579]  eta: 0:17:39  Lr: 0.030000  Loss: 0.0477  Acc@1: 62.5000 (61.8382)  Acc@5: 93.7500 (90.7263)  time: 0.3461  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1520/4579]  eta: 0:17:36  Lr: 0.030000  Loss: 0.3762  Acc@1: 62.5000 (61.8466)  Acc@5: 93.7500 (90.7421)  time: 0.3461  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1530/4579]  eta: 0:17:33  Lr: 0.030000  Loss: 0.3975  Acc@1: 68.7500 (61.8591)  Acc@5: 93.7500 (90.7536)  time: 0.3455  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [1540/4579]  eta: 0:17:29  Lr: 0.030000  Loss: -0.0910  Acc@1: 68.7500 (61.8997)  Acc@5: 93.7500 (90.7852)  time: 0.3457  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [1550/4579]  eta: 0:17:26  Lr: 0.030000  Loss: 0.1802  Acc@1: 68.7500 (61.9036)  Acc@5: 93.7500 (90.8003)  time: 0.3457  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [1560/4579]  eta: 0:17:22  Lr: 0.030000  Loss: 0.3351  Acc@1: 56.2500 (61.8314)  Acc@5: 93.7500 (90.7992)  time: 0.3444  data: 0.0002  max mem: 2500
Train: Epoch[5/5]  [1570/4579]  eta: 0:17:19  Lr: 0.030000  Loss: 0.4878  Acc@1: 56.2500 (61.8117)  Acc@5: 87.5000 (90.7782)  time: 0.3432  data: 0.0002  max mem: 2500
Train: Epoch[5/5]  [1580/4579]  eta: 0:17:15  Lr: 0.030000  Loss: 0.2062  Acc@1: 62.5000 (61.7924)  Acc@5: 87.5000 (90.7653)  time: 0.3435  data: 0.0002  max mem: 2500
Train: Epoch[5/5]  [1590/4579]  eta: 0:17:12  Lr: 0.030000  Loss: 0.3954  Acc@1: 56.2500 (61.7536)  Acc@5: 87.5000 (90.7645)  time: 0.3438  data: 0.0002  max mem: 2500
Train: Epoch[5/5]  [1600/4579]  eta: 0:17:08  Lr: 0.030000  Loss: 0.4958  Acc@1: 56.2500 (61.7309)  Acc@5: 87.5000 (90.7636)  time: 0.3437  data: 0.0002  max mem: 2500
Train: Epoch[5/5]  [1610/4579]  eta: 0:17:05  Lr: 0.030000  Loss: 0.0176  Acc@1: 62.5000 (61.7474)  Acc@5: 87.5000 (90.7627)  time: 0.3435  data: 0.0002  max mem: 2500
Train: Epoch[5/5]  [1620/4579]  eta: 0:17:01  Lr: 0.030000  Loss: 0.2229  Acc@1: 62.5000 (61.7404)  Acc@5: 87.5000 (90.7580)  time: 0.3452  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [1630/4579]  eta: 0:16:58  Lr: 0.030000  Loss: 0.3126  Acc@1: 62.5000 (61.7566)  Acc@5: 87.5000 (90.7419)  time: 0.3466  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1640/4579]  eta: 0:16:54  Lr: 0.030000  Loss: -0.0872  Acc@1: 68.7500 (61.7802)  Acc@5: 93.7500 (90.7526)  time: 0.3460  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1650/4579]  eta: 0:16:51  Lr: 0.030000  Loss: 0.1402  Acc@1: 62.5000 (61.7997)  Acc@5: 93.7500 (90.7821)  time: 0.3458  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [1660/4579]  eta: 0:16:48  Lr: 0.030000  Loss: 0.2239  Acc@1: 62.5000 (61.8114)  Acc@5: 93.7500 (90.7774)  time: 0.3463  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1670/4579]  eta: 0:16:44  Lr: 0.030000  Loss: 0.2199  Acc@1: 68.7500 (61.8268)  Acc@5: 87.5000 (90.7840)  time: 0.3461  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1680/4579]  eta: 0:16:41  Lr: 0.030000  Loss: 0.1339  Acc@1: 62.5000 (61.8122)  Acc@5: 93.7500 (90.7867)  time: 0.3450  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1690/4579]  eta: 0:16:37  Lr: 0.030000  Loss: 0.3826  Acc@1: 62.5000 (61.7904)  Acc@5: 93.7500 (90.7858)  time: 0.3459  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1700/4579]  eta: 0:16:34  Lr: 0.030000  Loss: 0.1479  Acc@1: 62.5000 (61.8166)  Acc@5: 93.7500 (90.7959)  time: 0.3454  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1710/4579]  eta: 0:16:30  Lr: 0.030000  Loss: -0.0972  Acc@1: 62.5000 (61.8169)  Acc@5: 93.7500 (90.8168)  time: 0.3441  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1720/4579]  eta: 0:16:27  Lr: 0.030000  Loss: 0.4197  Acc@1: 62.5000 (61.8027)  Acc@5: 93.7500 (90.8193)  time: 0.3446  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1730/4579]  eta: 0:16:23  Lr: 0.030000  Loss: 0.4145  Acc@1: 56.2500 (61.7598)  Acc@5: 87.5000 (90.8001)  time: 0.3455  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1740/4579]  eta: 0:16:20  Lr: 0.030000  Loss: 0.0936  Acc@1: 62.5000 (61.7892)  Acc@5: 87.5000 (90.7919)  time: 0.3460  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1750/4579]  eta: 0:16:16  Lr: 0.030000  Loss: -0.0548  Acc@1: 68.7500 (61.8004)  Acc@5: 93.7500 (90.7945)  time: 0.3449  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [1760/4579]  eta: 0:16:13  Lr: 0.030000  Loss: 0.0258  Acc@1: 68.7500 (61.8328)  Acc@5: 87.5000 (90.7971)  time: 0.3439  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1770/4579]  eta: 0:16:09  Lr: 0.030000  Loss: -0.1407  Acc@1: 68.7500 (61.8295)  Acc@5: 87.5000 (90.7962)  time: 0.3440  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [1780/4579]  eta: 0:16:06  Lr: 0.030000  Loss: 0.2224  Acc@1: 62.5000 (61.8683)  Acc@5: 93.7500 (90.8233)  time: 0.3442  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [1790/4579]  eta: 0:16:03  Lr: 0.030000  Loss: -0.1726  Acc@1: 62.5000 (61.8649)  Acc@5: 93.7500 (90.8082)  time: 0.3453  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [1800/4579]  eta: 0:15:59  Lr: 0.030000  Loss: 0.1666  Acc@1: 62.5000 (61.8892)  Acc@5: 93.7500 (90.8211)  time: 0.3454  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [1810/4579]  eta: 0:15:56  Lr: 0.030000  Loss: 0.1850  Acc@1: 56.2500 (61.8615)  Acc@5: 87.5000 (90.7958)  time: 0.3445  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [1820/4579]  eta: 0:15:52  Lr: 0.030000  Loss: 0.2793  Acc@1: 62.5000 (61.8788)  Acc@5: 87.5000 (90.7983)  time: 0.3446  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [1830/4579]  eta: 0:15:49  Lr: 0.030000  Loss: 0.1986  Acc@1: 62.5000 (61.8890)  Acc@5: 87.5000 (90.8008)  time: 0.3443  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [1840/4579]  eta: 0:15:45  Lr: 0.030000  Loss: 0.1812  Acc@1: 62.5000 (61.8719)  Acc@5: 93.7500 (90.7930)  time: 0.3438  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [1850/4579]  eta: 0:15:42  Lr: 0.030000  Loss: 0.1089  Acc@1: 62.5000 (61.8686)  Acc@5: 93.7500 (90.8023)  time: 0.3433  data: 0.0002  max mem: 2500
Train: Epoch[5/5]  [1860/4579]  eta: 0:15:38  Lr: 0.030000  Loss: -0.2042  Acc@1: 62.5000 (61.8988)  Acc@5: 93.7500 (90.8215)  time: 0.3432  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [1870/4579]  eta: 0:15:35  Lr: 0.030000  Loss: 0.1230  Acc@1: 68.7500 (61.9355)  Acc@5: 93.7500 (90.8371)  time: 0.3432  data: 0.0002  max mem: 2500
Train: Epoch[5/5]  [1880/4579]  eta: 0:15:31  Lr: 0.030000  Loss: -0.1160  Acc@1: 62.5000 (61.9152)  Acc@5: 93.7500 (90.8426)  time: 0.3432  data: 0.0002  max mem: 2500
Train: Epoch[5/5]  [1890/4579]  eta: 0:15:28  Lr: 0.030000  Loss: 0.2975  Acc@1: 62.5000 (61.9282)  Acc@5: 93.7500 (90.8349)  time: 0.3457  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [1900/4579]  eta: 0:15:24  Lr: 0.030000  Loss: -0.0058  Acc@1: 68.7500 (61.9509)  Acc@5: 87.5000 (90.8239)  time: 0.3475  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1910/4579]  eta: 0:15:21  Lr: 0.030000  Loss: -0.0525  Acc@1: 62.5000 (61.9375)  Acc@5: 87.5000 (90.8131)  time: 0.3460  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1920/4579]  eta: 0:15:18  Lr: 0.030000  Loss: 0.6448  Acc@1: 62.5000 (61.9469)  Acc@5: 87.5000 (90.8023)  time: 0.3448  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1930/4579]  eta: 0:15:14  Lr: 0.030000  Loss: 0.0242  Acc@1: 62.5000 (61.9562)  Acc@5: 87.5000 (90.8046)  time: 0.3462  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1940/4579]  eta: 0:15:11  Lr: 0.030000  Loss: 0.3607  Acc@1: 62.5000 (61.9558)  Acc@5: 93.7500 (90.8069)  time: 0.3463  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1950/4579]  eta: 0:15:07  Lr: 0.030000  Loss: 0.2501  Acc@1: 62.5000 (61.9202)  Acc@5: 93.7500 (90.8220)  time: 0.3448  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [1960/4579]  eta: 0:15:04  Lr: 0.030000  Loss: 0.1755  Acc@1: 62.5000 (61.9454)  Acc@5: 93.7500 (90.8178)  time: 0.3445  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [1970/4579]  eta: 0:15:00  Lr: 0.030000  Loss: 0.0768  Acc@1: 62.5000 (61.9641)  Acc@5: 93.7500 (90.8264)  time: 0.3443  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1980/4579]  eta: 0:14:57  Lr: 0.030000  Loss: -0.0570  Acc@1: 68.7500 (61.9637)  Acc@5: 87.5000 (90.8064)  time: 0.3448  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1990/4579]  eta: 0:14:53  Lr: 0.030000  Loss: -0.0860  Acc@1: 62.5000 (61.9789)  Acc@5: 93.7500 (90.8149)  time: 0.3449  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [2000/4579]  eta: 0:14:50  Lr: 0.030000  Loss: 0.3477  Acc@1: 62.5000 (61.9784)  Acc@5: 93.7500 (90.8140)  time: 0.3445  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [2010/4579]  eta: 0:14:46  Lr: 0.030000  Loss: 0.1363  Acc@1: 62.5000 (62.0214)  Acc@5: 93.7500 (90.8192)  time: 0.3445  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [2020/4579]  eta: 0:14:43  Lr: 0.030000  Loss: -0.1353  Acc@1: 62.5000 (62.0392)  Acc@5: 93.7500 (90.8368)  time: 0.3446  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [2030/4579]  eta: 0:14:39  Lr: 0.030000  Loss: 0.2399  Acc@1: 62.5000 (62.0076)  Acc@5: 93.7500 (90.8266)  time: 0.3443  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [2040/4579]  eta: 0:14:36  Lr: 0.030000  Loss: 0.3098  Acc@1: 62.5000 (62.0254)  Acc@5: 93.7500 (90.8439)  time: 0.3447  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [2050/4579]  eta: 0:14:33  Lr: 0.030000  Loss: -0.0501  Acc@1: 62.5000 (62.0094)  Acc@5: 93.7500 (90.8520)  time: 0.3444  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [2060/4579]  eta: 0:14:29  Lr: 0.030000  Loss: 0.0248  Acc@1: 62.5000 (62.0027)  Acc@5: 93.7500 (90.8661)  time: 0.3439  data: 0.0002  max mem: 2500
Train: Epoch[5/5]  [2070/4579]  eta: 0:14:26  Lr: 0.030000  Loss: 0.1697  Acc@1: 62.5000 (61.9900)  Acc@5: 93.7500 (90.8649)  time: 0.3439  data: 0.0002  max mem: 2500
Train: Epoch[5/5]  [2080/4579]  eta: 0:14:22  Lr: 0.030000  Loss: 0.1837  Acc@1: 56.2500 (61.9864)  Acc@5: 87.5000 (90.8548)  time: 0.3446  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [2090/4579]  eta: 0:14:19  Lr: 0.030000  Loss: 0.0042  Acc@1: 62.5000 (61.9829)  Acc@5: 93.7500 (90.8686)  time: 0.3460  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2100/4579]  eta: 0:14:15  Lr: 0.030000  Loss: 0.2390  Acc@1: 62.5000 (61.9735)  Acc@5: 93.7500 (90.8734)  time: 0.3455  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2110/4579]  eta: 0:14:12  Lr: 0.030000  Loss: 0.7782  Acc@1: 62.5000 (61.9789)  Acc@5: 93.7500 (90.8604)  time: 0.3460  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [2120/4579]  eta: 0:14:08  Lr: 0.030000  Loss: 0.2097  Acc@1: 62.5000 (61.9784)  Acc@5: 93.7500 (90.8681)  time: 0.3459  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [2130/4579]  eta: 0:14:05  Lr: 0.030000  Loss: 0.3529  Acc@1: 62.5000 (61.9838)  Acc@5: 93.7500 (90.8728)  time: 0.3466  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [2140/4579]  eta: 0:14:02  Lr: 0.030000  Loss: -0.0581  Acc@1: 62.5000 (61.9833)  Acc@5: 87.5000 (90.8571)  time: 0.3468  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [2150/4579]  eta: 0:13:58  Lr: 0.030000  Loss: 0.0503  Acc@1: 62.5000 (61.9857)  Acc@5: 93.7500 (90.8792)  time: 0.3450  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [2160/4579]  eta: 0:13:55  Lr: 0.030000  Loss: -0.1037  Acc@1: 62.5000 (61.9852)  Acc@5: 93.7500 (90.8954)  time: 0.3454  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [2170/4579]  eta: 0:13:51  Lr: 0.030000  Loss: 0.3157  Acc@1: 62.5000 (61.9847)  Acc@5: 93.7500 (90.8942)  time: 0.3454  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [2180/4579]  eta: 0:13:48  Lr: 0.030000  Loss: 0.0763  Acc@1: 62.5000 (61.9756)  Acc@5: 93.7500 (90.8987)  time: 0.3453  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [2190/4579]  eta: 0:13:44  Lr: 0.030000  Loss: 0.6570  Acc@1: 56.2500 (61.9609)  Acc@5: 87.5000 (90.8917)  time: 0.3457  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [2200/4579]  eta: 0:13:41  Lr: 0.030000  Loss: 0.1779  Acc@1: 62.5000 (61.9690)  Acc@5: 87.5000 (90.8877)  time: 0.3448  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [2210/4579]  eta: 0:13:37  Lr: 0.030000  Loss: 0.0974  Acc@1: 62.5000 (61.9233)  Acc@5: 87.5000 (90.8667)  time: 0.3437  data: 0.0002  max mem: 2500
Train: Epoch[5/5]  [2220/4579]  eta: 0:13:34  Lr: 0.030000  Loss: 0.0033  Acc@1: 56.2500 (61.9203)  Acc@5: 87.5000 (90.8572)  time: 0.3439  data: 0.0002  max mem: 2500
Train: Epoch[5/5]  [2230/4579]  eta: 0:13:30  Lr: 0.030000  Loss: 0.1196  Acc@1: 62.5000 (61.9369)  Acc@5: 87.5000 (90.8505)  time: 0.3441  data: 0.0002  max mem: 2500
Train: Epoch[5/5]  [2240/4579]  eta: 0:13:27  Lr: 0.030000  Loss: 0.0307  Acc@1: 62.5000 (61.9450)  Acc@5: 87.5000 (90.8523)  time: 0.3444  data: 0.0002  max mem: 2500
Train: Epoch[5/5]  [2250/4579]  eta: 0:13:23  Lr: 0.030000  Loss: 0.5781  Acc@1: 62.5000 (61.9419)  Acc@5: 93.7500 (90.8485)  time: 0.3442  data: 0.0002  max mem: 2500
Train: Epoch[5/5]  [2260/4579]  eta: 0:13:20  Lr: 0.030000  Loss: 0.1599  Acc@1: 62.5000 (61.9582)  Acc@5: 87.5000 (90.8503)  time: 0.3442  data: 0.0002  max mem: 2500
Train: Epoch[5/5]  [2270/4579]  eta: 0:13:17  Lr: 0.030000  Loss: 0.1521  Acc@1: 62.5000 (61.9358)  Acc@5: 87.5000 (90.8383)  time: 0.3463  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2280/4579]  eta: 0:13:13  Lr: 0.030000  Loss: 0.1504  Acc@1: 56.2500 (61.9356)  Acc@5: 87.5000 (90.8456)  time: 0.3480  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [2290/4579]  eta: 0:13:10  Lr: 0.030000  Loss: 0.4815  Acc@1: 56.2500 (61.9080)  Acc@5: 93.7500 (90.8473)  time: 0.3475  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2300/4579]  eta: 0:13:06  Lr: 0.030000  Loss: 0.5208  Acc@1: 62.5000 (61.9079)  Acc@5: 93.7500 (90.8545)  time: 0.3472  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2310/4579]  eta: 0:13:03  Lr: 0.030000  Loss: -0.2130  Acc@1: 62.5000 (61.9294)  Acc@5: 93.7500 (90.8589)  time: 0.3468  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2320/4579]  eta: 0:12:59  Lr: 0.030000  Loss: -0.0213  Acc@1: 62.5000 (61.9480)  Acc@5: 93.7500 (90.8606)  time: 0.3456  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2330/4579]  eta: 0:12:56  Lr: 0.030000  Loss: 0.2468  Acc@1: 68.7500 (61.9664)  Acc@5: 87.5000 (90.8623)  time: 0.3453  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2340/4579]  eta: 0:12:53  Lr: 0.030000  Loss: 0.1223  Acc@1: 68.7500 (61.9981)  Acc@5: 93.7500 (90.8693)  time: 0.3459  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2350/4579]  eta: 0:12:49  Lr: 0.030000  Loss: 0.1236  Acc@1: 62.5000 (61.9683)  Acc@5: 87.5000 (90.8523)  time: 0.3459  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2360/4579]  eta: 0:12:46  Lr: 0.030000  Loss: 0.1675  Acc@1: 56.2500 (61.9600)  Acc@5: 87.5000 (90.8566)  time: 0.3455  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2370/4579]  eta: 0:12:42  Lr: 0.030000  Loss: 0.2187  Acc@1: 62.5000 (61.9728)  Acc@5: 93.7500 (90.8530)  time: 0.3456  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2380/4579]  eta: 0:12:39  Lr: 0.030000  Loss: -0.0002  Acc@1: 62.5000 (61.9671)  Acc@5: 93.7500 (90.8494)  time: 0.3457  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2390/4579]  eta: 0:12:35  Lr: 0.030000  Loss: -0.0297  Acc@1: 62.5000 (61.9746)  Acc@5: 87.5000 (90.8511)  time: 0.3455  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [2400/4579]  eta: 0:12:32  Lr: 0.030000  Loss: -0.1359  Acc@1: 62.5000 (61.9820)  Acc@5: 93.7500 (90.8476)  time: 0.3462  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2410/4579]  eta: 0:12:28  Lr: 0.030000  Loss: 0.0564  Acc@1: 62.5000 (61.9660)  Acc@5: 93.7500 (90.8440)  time: 0.3462  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [2420/4579]  eta: 0:12:25  Lr: 0.030000  Loss: -0.1594  Acc@1: 62.5000 (61.9708)  Acc@5: 93.7500 (90.8457)  time: 0.3454  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [2430/4579]  eta: 0:12:21  Lr: 0.030000  Loss: 0.1806  Acc@1: 56.2500 (61.9832)  Acc@5: 87.5000 (90.8448)  time: 0.3453  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [2440/4579]  eta: 0:12:18  Lr: 0.030000  Loss: -0.0999  Acc@1: 68.7500 (62.0110)  Acc@5: 93.7500 (90.8567)  time: 0.3457  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2450/4579]  eta: 0:12:15  Lr: 0.030000  Loss: 0.0569  Acc@1: 62.5000 (62.0053)  Acc@5: 93.7500 (90.8481)  time: 0.3459  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [2460/4579]  eta: 0:12:11  Lr: 0.030000  Loss: -0.0908  Acc@1: 62.5000 (62.0352)  Acc@5: 87.5000 (90.8421)  time: 0.3452  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [2470/4579]  eta: 0:12:08  Lr: 0.030000  Loss: 0.1861  Acc@1: 68.7500 (62.0523)  Acc@5: 87.5000 (90.8337)  time: 0.3446  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [2480/4579]  eta: 0:12:04  Lr: 0.030000  Loss: -0.1877  Acc@1: 68.7500 (62.0591)  Acc@5: 93.7500 (90.8404)  time: 0.3449  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [2490/4579]  eta: 0:12:01  Lr: 0.030000  Loss: -0.0885  Acc@1: 62.5000 (62.0609)  Acc@5: 93.7500 (90.8445)  time: 0.3452  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2500/4579]  eta: 0:11:57  Lr: 0.030000  Loss: -0.1357  Acc@1: 62.5000 (62.0677)  Acc@5: 93.7500 (90.8487)  time: 0.3456  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2510/4579]  eta: 0:11:54  Lr: 0.030000  Loss: 0.5985  Acc@1: 62.5000 (62.0594)  Acc@5: 93.7500 (90.8552)  time: 0.3454  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2520/4579]  eta: 0:11:50  Lr: 0.030000  Loss: 0.1383  Acc@1: 62.5000 (62.0860)  Acc@5: 93.7500 (90.8618)  time: 0.3449  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [2530/4579]  eta: 0:11:47  Lr: 0.030000  Loss: 0.2515  Acc@1: 62.5000 (62.0827)  Acc@5: 87.5000 (90.8485)  time: 0.3447  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [2540/4579]  eta: 0:11:43  Lr: 0.030000  Loss: 0.1658  Acc@1: 62.5000 (62.0819)  Acc@5: 87.5000 (90.8451)  time: 0.3442  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [2550/4579]  eta: 0:11:40  Lr: 0.030000  Loss: 0.1856  Acc@1: 62.5000 (62.0884)  Acc@5: 87.5000 (90.8345)  time: 0.3442  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [2560/4579]  eta: 0:11:37  Lr: 0.030000  Loss: 0.0059  Acc@1: 62.5000 (62.1022)  Acc@5: 87.5000 (90.8434)  time: 0.3451  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [2570/4579]  eta: 0:11:33  Lr: 0.030000  Loss: -0.1272  Acc@1: 68.7500 (62.1086)  Acc@5: 93.7500 (90.8474)  time: 0.3453  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2580/4579]  eta: 0:11:30  Lr: 0.030000  Loss: 0.0405  Acc@1: 68.7500 (62.1295)  Acc@5: 93.7500 (90.8538)  time: 0.3460  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2590/4579]  eta: 0:11:26  Lr: 0.030000  Loss: 0.0313  Acc@1: 62.5000 (62.1044)  Acc@5: 93.7500 (90.8409)  time: 0.3460  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [2600/4579]  eta: 0:11:23  Lr: 0.030000  Loss: 0.1669  Acc@1: 56.2500 (62.0915)  Acc@5: 93.7500 (90.8425)  time: 0.3445  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [2610/4579]  eta: 0:11:19  Lr: 0.030000  Loss: 0.3153  Acc@1: 62.5000 (62.0883)  Acc@5: 93.7500 (90.8440)  time: 0.3444  data: 0.0002  max mem: 2500
Train: Epoch[5/5]  [2620/4579]  eta: 0:11:16  Lr: 0.030000  Loss: -0.0857  Acc@1: 62.5000 (62.0827)  Acc@5: 87.5000 (90.8360)  time: 0.3443  data: 0.0002  max mem: 2500
Train: Epoch[5/5]  [2630/4579]  eta: 0:11:12  Lr: 0.030000  Loss: -0.1291  Acc@1: 62.5000 (62.0962)  Acc@5: 93.7500 (90.8519)  time: 0.3449  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [2640/4579]  eta: 0:11:09  Lr: 0.030000  Loss: 0.1328  Acc@1: 68.7500 (62.1261)  Acc@5: 93.7500 (90.8605)  time: 0.3450  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [2650/4579]  eta: 0:11:06  Lr: 0.030000  Loss: 0.2146  Acc@1: 68.7500 (62.1511)  Acc@5: 93.7500 (90.8643)  time: 0.3454  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2660/4579]  eta: 0:11:02  Lr: 0.030000  Loss: 0.2543  Acc@1: 62.5000 (62.1477)  Acc@5: 87.5000 (90.8587)  time: 0.3450  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2670/4579]  eta: 0:10:59  Lr: 0.030000  Loss: -0.3306  Acc@1: 62.5000 (62.1818)  Acc@5: 93.7500 (90.8789)  time: 0.3438  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [2680/4579]  eta: 0:10:55  Lr: 0.030000  Loss: 0.0354  Acc@1: 56.2500 (62.1526)  Acc@5: 93.7500 (90.8616)  time: 0.3442  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [2690/4579]  eta: 0:10:52  Lr: 0.030000  Loss: 0.5558  Acc@1: 56.2500 (62.1702)  Acc@5: 87.5000 (90.8607)  time: 0.3447  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [2700/4579]  eta: 0:10:48  Lr: 0.030000  Loss: 0.1437  Acc@1: 62.5000 (62.1622)  Acc@5: 93.7500 (90.8645)  time: 0.3456  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [2710/4579]  eta: 0:10:45  Lr: 0.030000  Loss: 0.1621  Acc@1: 56.2500 (62.1542)  Acc@5: 93.7500 (90.8728)  time: 0.3449  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [2720/4579]  eta: 0:10:41  Lr: 0.030000  Loss: 0.1825  Acc@1: 62.5000 (62.1715)  Acc@5: 93.7500 (90.8834)  time: 0.3436  data: 0.0002  max mem: 2500
Train: Epoch[5/5]  [2730/4579]  eta: 0:10:38  Lr: 0.030000  Loss: 0.0800  Acc@1: 62.5000 (62.1430)  Acc@5: 93.7500 (90.8779)  time: 0.3433  data: 0.0002  max mem: 2500
Train: Epoch[5/5]  [2740/4579]  eta: 0:10:34  Lr: 0.030000  Loss: 0.2098  Acc@1: 62.5000 (62.1511)  Acc@5: 93.7500 (90.8838)  time: 0.3432  data: 0.0002  max mem: 2500
Train: Epoch[5/5]  [2750/4579]  eta: 0:10:31  Lr: 0.030000  Loss: -0.0078  Acc@1: 62.5000 (62.1479)  Acc@5: 87.5000 (90.8738)  time: 0.3433  data: 0.0002  max mem: 2500
Train: Epoch[5/5]  [2760/4579]  eta: 0:10:27  Lr: 0.030000  Loss: 0.0271  Acc@1: 62.5000 (62.1423)  Acc@5: 87.5000 (90.8797)  time: 0.3434  data: 0.0002  max mem: 2500
Train: Epoch[5/5]  [2770/4579]  eta: 0:10:24  Lr: 0.030000  Loss: -0.1805  Acc@1: 56.2500 (62.1504)  Acc@5: 87.5000 (90.8855)  time: 0.3438  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [2780/4579]  eta: 0:10:21  Lr: 0.030000  Loss: 0.1149  Acc@1: 68.7500 (62.1472)  Acc@5: 87.5000 (90.8846)  time: 0.3443  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [2790/4579]  eta: 0:10:17  Lr: 0.030000  Loss: 0.3394  Acc@1: 62.5000 (62.1462)  Acc@5: 93.7500 (90.8859)  time: 0.3446  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2800/4579]  eta: 0:10:14  Lr: 0.030000  Loss: 0.2938  Acc@1: 62.5000 (62.1564)  Acc@5: 93.7500 (90.8805)  time: 0.3451  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2810/4579]  eta: 0:10:10  Lr: 0.030000  Loss: 0.3853  Acc@1: 62.5000 (62.1554)  Acc@5: 87.5000 (90.8863)  time: 0.3455  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2820/4579]  eta: 0:10:07  Lr: 0.030000  Loss: 0.2977  Acc@1: 68.7500 (62.1787)  Acc@5: 93.7500 (90.8920)  time: 0.3458  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2830/4579]  eta: 0:10:03  Lr: 0.030000  Loss: 0.4136  Acc@1: 68.7500 (62.1843)  Acc@5: 93.7500 (90.8888)  time: 0.3455  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2840/4579]  eta: 0:10:00  Lr: 0.030000  Loss: 0.2796  Acc@1: 62.5000 (62.1744)  Acc@5: 93.7500 (90.8857)  time: 0.3449  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [2850/4579]  eta: 0:09:56  Lr: 0.030000  Loss: 0.1536  Acc@1: 62.5000 (62.1690)  Acc@5: 93.7500 (90.8914)  time: 0.3459  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2860/4579]  eta: 0:09:53  Lr: 0.030000  Loss: -0.0899  Acc@1: 56.2500 (62.1592)  Acc@5: 93.7500 (90.8882)  time: 0.3459  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [2870/4579]  eta: 0:09:49  Lr: 0.030000  Loss: 0.3487  Acc@1: 56.2500 (62.1539)  Acc@5: 93.7500 (90.8873)  time: 0.3450  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [2880/4579]  eta: 0:09:46  Lr: 0.030000  Loss: 0.2966  Acc@1: 56.2500 (62.1355)  Acc@5: 93.7500 (90.8821)  time: 0.3452  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [2890/4579]  eta: 0:09:43  Lr: 0.030000  Loss: 0.0668  Acc@1: 56.2500 (62.1238)  Acc@5: 87.5000 (90.8833)  time: 0.3454  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [2900/4579]  eta: 0:09:39  Lr: 0.030000  Loss: -0.1512  Acc@1: 62.5000 (62.1337)  Acc@5: 93.7500 (90.9018)  time: 0.3451  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [2910/4579]  eta: 0:09:36  Lr: 0.030000  Loss: -0.0256  Acc@1: 62.5000 (62.1479)  Acc@5: 93.7500 (90.9052)  time: 0.3451  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [2920/4579]  eta: 0:09:32  Lr: 0.030000  Loss: 0.0795  Acc@1: 62.5000 (62.1512)  Acc@5: 93.7500 (90.9171)  time: 0.3449  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [2930/4579]  eta: 0:09:29  Lr: 0.030000  Loss: 0.1243  Acc@1: 56.2500 (62.1268)  Acc@5: 93.7500 (90.9139)  time: 0.3439  data: 0.0002  max mem: 2500
Train: Epoch[5/5]  [2940/4579]  eta: 0:09:25  Lr: 0.030000  Loss: 0.1967  Acc@1: 56.2500 (62.1111)  Acc@5: 93.7500 (90.9172)  time: 0.3438  data: 0.0002  max mem: 2500
Train: Epoch[5/5]  [2950/4579]  eta: 0:09:22  Lr: 0.030000  Loss: 0.2290  Acc@1: 56.2500 (62.1209)  Acc@5: 93.7500 (90.9247)  time: 0.3438  data: 0.0002  max mem: 2500
Train: Epoch[5/5]  [2960/4579]  eta: 0:09:18  Lr: 0.030000  Loss: 0.5981  Acc@1: 62.5000 (62.1053)  Acc@5: 93.7500 (90.9237)  time: 0.3443  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [2970/4579]  eta: 0:09:15  Lr: 0.030000  Loss: 0.1276  Acc@1: 56.2500 (62.1066)  Acc@5: 87.5000 (90.9248)  time: 0.3450  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [2980/4579]  eta: 0:09:11  Lr: 0.030000  Loss: 0.2752  Acc@1: 62.5000 (62.1121)  Acc@5: 93.7500 (90.9259)  time: 0.3450  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2990/4579]  eta: 0:09:08  Lr: 0.030000  Loss: 0.2906  Acc@1: 62.5000 (62.1030)  Acc@5: 93.7500 (90.9311)  time: 0.3451  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3000/4579]  eta: 0:09:05  Lr: 0.030000  Loss: 0.3409  Acc@1: 56.2500 (62.0981)  Acc@5: 87.5000 (90.9218)  time: 0.3451  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [3010/4579]  eta: 0:09:01  Lr: 0.030000  Loss: -0.0388  Acc@1: 62.5000 (62.0952)  Acc@5: 93.7500 (90.9374)  time: 0.3458  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [3020/4579]  eta: 0:08:58  Lr: 0.030000  Loss: 0.0197  Acc@1: 62.5000 (62.1173)  Acc@5: 93.7500 (90.9426)  time: 0.3457  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [3030/4579]  eta: 0:08:54  Lr: 0.030000  Loss: 0.1623  Acc@1: 62.5000 (62.1206)  Acc@5: 93.7500 (90.9395)  time: 0.3454  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [3040/4579]  eta: 0:08:51  Lr: 0.030000  Loss: 0.5441  Acc@1: 56.2500 (62.1013)  Acc@5: 87.5000 (90.9261)  time: 0.3457  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [3050/4579]  eta: 0:08:47  Lr: 0.030000  Loss: 0.2070  Acc@1: 56.2500 (62.0903)  Acc@5: 87.5000 (90.9190)  time: 0.3454  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [3060/4579]  eta: 0:08:44  Lr: 0.030000  Loss: 0.2770  Acc@1: 62.5000 (62.0916)  Acc@5: 93.7500 (90.9282)  time: 0.3453  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [3070/4579]  eta: 0:08:40  Lr: 0.030000  Loss: -0.0108  Acc@1: 62.5000 (62.0950)  Acc@5: 93.7500 (90.9211)  time: 0.3456  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [3080/4579]  eta: 0:08:37  Lr: 0.030000  Loss: 0.2867  Acc@1: 62.5000 (62.0923)  Acc@5: 93.7500 (90.9161)  time: 0.3449  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [3090/4579]  eta: 0:08:33  Lr: 0.030000  Loss: -0.0782  Acc@1: 62.5000 (62.0956)  Acc@5: 87.5000 (90.9071)  time: 0.3438  data: 0.0002  max mem: 2500
Train: Epoch[5/5]  [3100/4579]  eta: 0:08:30  Lr: 0.030000  Loss: 0.1657  Acc@1: 62.5000 (62.0888)  Acc@5: 87.5000 (90.8961)  time: 0.3436  data: 0.0002  max mem: 2500
Train: Epoch[5/5]  [3110/4579]  eta: 0:08:27  Lr: 0.030000  Loss: 0.2509  Acc@1: 62.5000 (62.0922)  Acc@5: 87.5000 (90.8892)  time: 0.3436  data: 0.0002  max mem: 2500
Train: Epoch[5/5]  [3120/4579]  eta: 0:08:23  Lr: 0.030000  Loss: 0.1106  Acc@1: 62.5000 (62.0915)  Acc@5: 87.5000 (90.8843)  time: 0.3440  data: 0.0002  max mem: 2500
Train: Epoch[5/5]  [3130/4579]  eta: 0:08:20  Lr: 0.030000  Loss: 0.3268  Acc@1: 62.5000 (62.0948)  Acc@5: 87.5000 (90.8875)  time: 0.3452  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [3140/4579]  eta: 0:08:16  Lr: 0.030000  Loss: 0.2328  Acc@1: 62.5000 (62.1140)  Acc@5: 93.7500 (90.8926)  time: 0.3467  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3150/4579]  eta: 0:08:13  Lr: 0.030000  Loss: 0.3177  Acc@1: 62.5000 (62.1112)  Acc@5: 93.7500 (90.8878)  time: 0.3465  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3160/4579]  eta: 0:08:09  Lr: 0.030000  Loss: -0.1154  Acc@1: 62.5000 (62.1342)  Acc@5: 87.5000 (90.8890)  time: 0.3460  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3170/4579]  eta: 0:08:06  Lr: 0.030000  Loss: 0.2399  Acc@1: 62.5000 (62.1235)  Acc@5: 93.7500 (90.8862)  time: 0.3461  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [3180/4579]  eta: 0:08:02  Lr: 0.030000  Loss: 0.0554  Acc@1: 56.2500 (62.1228)  Acc@5: 93.7500 (90.8991)  time: 0.3456  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [3190/4579]  eta: 0:07:59  Lr: 0.030000  Loss: 0.2511  Acc@1: 56.2500 (62.1161)  Acc@5: 93.7500 (90.8845)  time: 0.3450  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3200/4579]  eta: 0:07:56  Lr: 0.030000  Loss: 0.2046  Acc@1: 62.5000 (62.1212)  Acc@5: 87.5000 (90.8759)  time: 0.3453  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [3210/4579]  eta: 0:07:52  Lr: 0.030000  Loss: -0.0100  Acc@1: 62.5000 (62.1282)  Acc@5: 87.5000 (90.8829)  time: 0.3457  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3220/4579]  eta: 0:07:49  Lr: 0.030000  Loss: -0.0280  Acc@1: 68.7500 (62.1294)  Acc@5: 93.7500 (90.8802)  time: 0.3453  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [3230/4579]  eta: 0:07:45  Lr: 0.030000  Loss: 0.2664  Acc@1: 56.2500 (62.1131)  Acc@5: 87.5000 (90.8813)  time: 0.3450  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [3240/4579]  eta: 0:07:42  Lr: 0.030000  Loss: 0.5021  Acc@1: 56.2500 (62.1124)  Acc@5: 93.7500 (90.8824)  time: 0.3455  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [3250/4579]  eta: 0:07:38  Lr: 0.030000  Loss: 0.0617  Acc@1: 62.5000 (62.1040)  Acc@5: 87.5000 (90.8740)  time: 0.3449  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [3260/4579]  eta: 0:07:35  Lr: 0.030000  Loss: 0.0323  Acc@1: 56.2500 (62.0918)  Acc@5: 87.5000 (90.8559)  time: 0.3440  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [3270/4579]  eta: 0:07:31  Lr: 0.030000  Loss: 0.1106  Acc@1: 62.5000 (62.1045)  Acc@5: 93.7500 (90.8667)  time: 0.3441  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [3280/4579]  eta: 0:07:28  Lr: 0.030000  Loss: 0.2944  Acc@1: 62.5000 (62.1114)  Acc@5: 93.7500 (90.8736)  time: 0.3448  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3290/4579]  eta: 0:07:24  Lr: 0.030000  Loss: 0.0545  Acc@1: 56.2500 (62.1107)  Acc@5: 93.7500 (90.8747)  time: 0.3455  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3300/4579]  eta: 0:07:21  Lr: 0.030000  Loss: -0.2090  Acc@1: 68.7500 (62.1327)  Acc@5: 93.7500 (90.8853)  time: 0.3469  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3310/4579]  eta: 0:07:18  Lr: 0.030000  Loss: 0.3150  Acc@1: 68.7500 (62.1357)  Acc@5: 93.7500 (90.8827)  time: 0.3462  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3320/4579]  eta: 0:07:14  Lr: 0.030000  Loss: -0.0422  Acc@1: 68.7500 (62.1500)  Acc@5: 93.7500 (90.8932)  time: 0.3443  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [3330/4579]  eta: 0:07:11  Lr: 0.030000  Loss: 0.1719  Acc@1: 62.5000 (62.1454)  Acc@5: 93.7500 (90.8905)  time: 0.3441  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [3340/4579]  eta: 0:07:07  Lr: 0.030000  Loss: 0.0065  Acc@1: 62.5000 (62.1502)  Acc@5: 87.5000 (90.8860)  time: 0.3434  data: 0.0002  max mem: 2500
Train: Epoch[5/5]  [3350/4579]  eta: 0:07:04  Lr: 0.030000  Loss: -0.0958  Acc@1: 68.7500 (62.1717)  Acc@5: 93.7500 (90.8964)  time: 0.3442  data: 0.0002  max mem: 2500
Train: Epoch[5/5]  [3360/4579]  eta: 0:07:00  Lr: 0.030000  Loss: -0.0507  Acc@1: 68.7500 (62.1727)  Acc@5: 93.7500 (90.9011)  time: 0.3451  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [3370/4579]  eta: 0:06:57  Lr: 0.030000  Loss: 0.2727  Acc@1: 62.5000 (62.1607)  Acc@5: 93.7500 (90.8966)  time: 0.3466  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3380/4579]  eta: 0:06:53  Lr: 0.030000  Loss: 0.1610  Acc@1: 62.5000 (62.1673)  Acc@5: 87.5000 (90.8903)  time: 0.3463  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [3390/4579]  eta: 0:06:50  Lr: 0.030000  Loss: 0.2384  Acc@1: 62.5000 (62.1646)  Acc@5: 87.5000 (90.8913)  time: 0.3441  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [3400/4579]  eta: 0:06:46  Lr: 0.030000  Loss: -0.0347  Acc@1: 68.7500 (62.1839)  Acc@5: 87.5000 (90.8924)  time: 0.3440  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [3410/4579]  eta: 0:06:43  Lr: 0.030000  Loss: 0.2399  Acc@1: 68.7500 (62.1885)  Acc@5: 93.7500 (90.8934)  time: 0.3436  data: 0.0002  max mem: 2500
Train: Epoch[5/5]  [3420/4579]  eta: 0:06:40  Lr: 0.030000  Loss: 0.4361  Acc@1: 62.5000 (62.1912)  Acc@5: 93.7500 (90.8981)  time: 0.3434  data: 0.0002  max mem: 2500
Train: Epoch[5/5]  [3430/4579]  eta: 0:06:36  Lr: 0.030000  Loss: 0.4639  Acc@1: 62.5000 (62.1885)  Acc@5: 93.7500 (90.9028)  time: 0.3449  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [3440/4579]  eta: 0:06:33  Lr: 0.030000  Loss: 0.0623  Acc@1: 62.5000 (62.1912)  Acc@5: 93.7500 (90.9020)  time: 0.3458  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3450/4579]  eta: 0:06:29  Lr: 0.030000  Loss: 0.2318  Acc@1: 68.7500 (62.2048)  Acc@5: 93.7500 (90.9084)  time: 0.3458  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3460/4579]  eta: 0:06:26  Lr: 0.030000  Loss: -0.1436  Acc@1: 68.7500 (62.2075)  Acc@5: 93.7500 (90.9130)  time: 0.3450  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [3470/4579]  eta: 0:06:22  Lr: 0.030000  Loss: 0.4784  Acc@1: 62.5000 (62.2155)  Acc@5: 93.7500 (90.9068)  time: 0.3448  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [3480/4579]  eta: 0:06:19  Lr: 0.030000  Loss: -0.0313  Acc@1: 68.7500 (62.2343)  Acc@5: 93.7500 (90.9132)  time: 0.3454  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [3490/4579]  eta: 0:06:15  Lr: 0.030000  Loss: 0.1043  Acc@1: 68.7500 (62.2440)  Acc@5: 93.7500 (90.9159)  time: 0.3459  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [3500/4579]  eta: 0:06:12  Lr: 0.030000  Loss: 0.2768  Acc@1: 56.2500 (62.2376)  Acc@5: 87.5000 (90.9151)  time: 0.3452  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [3510/4579]  eta: 0:06:08  Lr: 0.030000  Loss: 0.3662  Acc@1: 56.2500 (62.2348)  Acc@5: 87.5000 (90.9089)  time: 0.3435  data: 0.0002  max mem: 2500
Train: Epoch[5/5]  [3520/4579]  eta: 0:06:05  Lr: 0.030000  Loss: 0.2887  Acc@1: 62.5000 (62.2426)  Acc@5: 87.5000 (90.9010)  time: 0.3436  data: 0.0002  max mem: 2500
Train: Epoch[5/5]  [3530/4579]  eta: 0:06:02  Lr: 0.030000  Loss: 0.0510  Acc@1: 62.5000 (62.2504)  Acc@5: 93.7500 (90.9038)  time: 0.3444  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [3540/4579]  eta: 0:05:58  Lr: 0.030000  Loss: -0.2322  Acc@1: 62.5000 (62.2335)  Acc@5: 93.7500 (90.8924)  time: 0.3447  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3550/4579]  eta: 0:05:55  Lr: 0.030000  Loss: 0.2578  Acc@1: 56.2500 (62.2307)  Acc@5: 87.5000 (90.8793)  time: 0.3450  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3560/4579]  eta: 0:05:51  Lr: 0.030000  Loss: 0.3983  Acc@1: 62.5000 (62.2122)  Acc@5: 87.5000 (90.8716)  time: 0.3459  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3570/4579]  eta: 0:05:48  Lr: 0.030000  Loss: 0.1808  Acc@1: 56.2500 (62.2095)  Acc@5: 93.7500 (90.8797)  time: 0.3463  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3580/4579]  eta: 0:05:44  Lr: 0.030000  Loss: 0.0314  Acc@1: 56.2500 (62.1998)  Acc@5: 93.7500 (90.8894)  time: 0.3461  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3590/4579]  eta: 0:05:41  Lr: 0.030000  Loss: 0.2313  Acc@1: 56.2500 (62.1972)  Acc@5: 87.5000 (90.8782)  time: 0.3459  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3600/4579]  eta: 0:05:37  Lr: 0.030000  Loss: 0.0141  Acc@1: 56.2500 (62.1945)  Acc@5: 87.5000 (90.8810)  time: 0.3461  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [3610/4579]  eta: 0:05:34  Lr: 0.030000  Loss: 0.1736  Acc@1: 68.7500 (62.2058)  Acc@5: 87.5000 (90.8838)  time: 0.3459  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [3620/4579]  eta: 0:05:31  Lr: 0.030000  Loss: 0.1542  Acc@1: 62.5000 (62.1910)  Acc@5: 87.5000 (90.8848)  time: 0.3457  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [3630/4579]  eta: 0:05:27  Lr: 0.030000  Loss: -0.0004  Acc@1: 62.5000 (62.2039)  Acc@5: 93.7500 (90.8841)  time: 0.3456  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [3640/4579]  eta: 0:05:24  Lr: 0.030000  Loss: -0.1601  Acc@1: 62.5000 (62.2030)  Acc@5: 93.7500 (90.8902)  time: 0.3454  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [3650/4579]  eta: 0:05:20  Lr: 0.030000  Loss: 0.3217  Acc@1: 56.2500 (62.1850)  Acc@5: 93.7500 (90.8792)  time: 0.3473  data: 0.0011  max mem: 2500
Train: Epoch[5/5]  [3660/4579]  eta: 0:05:17  Lr: 0.030000  Loss: 0.3407  Acc@1: 56.2500 (62.1859)  Acc@5: 87.5000 (90.8734)  time: 0.3465  data: 0.0011  max mem: 2500
Train: Epoch[5/5]  [3670/4579]  eta: 0:05:13  Lr: 0.030000  Loss: 0.1051  Acc@1: 62.5000 (62.1901)  Acc@5: 87.5000 (90.8727)  time: 0.3434  data: 0.0002  max mem: 2500
Train: Epoch[5/5]  [3680/4579]  eta: 0:05:10  Lr: 0.030000  Loss: 0.1309  Acc@1: 62.5000 (62.2012)  Acc@5: 87.5000 (90.8720)  time: 0.3434  data: 0.0002  max mem: 2500
Train: Epoch[5/5]  [3690/4579]  eta: 0:05:06  Lr: 0.030000  Loss: 0.1985  Acc@1: 68.7500 (62.2121)  Acc@5: 93.7500 (90.8765)  time: 0.3436  data: 0.0002  max mem: 2500
Train: Epoch[5/5]  [3700/4579]  eta: 0:05:03  Lr: 0.030000  Loss: 0.4453  Acc@1: 62.5000 (62.2264)  Acc@5: 93.7500 (90.8690)  time: 0.3437  data: 0.0002  max mem: 2500
Train: Epoch[5/5]  [3710/4579]  eta: 0:04:59  Lr: 0.030000  Loss: -0.0991  Acc@1: 62.5000 (62.2255)  Acc@5: 93.7500 (90.8768)  time: 0.3438  data: 0.0002  max mem: 2500
Train: Epoch[5/5]  [3720/4579]  eta: 0:04:56  Lr: 0.030000  Loss: 0.4640  Acc@1: 62.5000 (62.2111)  Acc@5: 93.7500 (90.8761)  time: 0.3437  data: 0.0002  max mem: 2500
Train: Epoch[5/5]  [3730/4579]  eta: 0:04:53  Lr: 0.030000  Loss: -0.0209  Acc@1: 62.5000 (62.2068)  Acc@5: 93.7500 (90.8704)  time: 0.3437  data: 0.0002  max mem: 2500
Train: Epoch[5/5]  [3740/4579]  eta: 0:04:49  Lr: 0.030000  Loss: 0.4166  Acc@1: 62.5000 (62.2009)  Acc@5: 87.5000 (90.8664)  time: 0.3438  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [3750/4579]  eta: 0:04:46  Lr: 0.030000  Loss: 0.2285  Acc@1: 62.5000 (62.2201)  Acc@5: 87.5000 (90.8591)  time: 0.3445  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3760/4579]  eta: 0:04:42  Lr: 0.030000  Loss: 0.4295  Acc@1: 62.5000 (62.2092)  Acc@5: 87.5000 (90.8651)  time: 0.3463  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3770/4579]  eta: 0:04:39  Lr: 0.030000  Loss: 0.0046  Acc@1: 62.5000 (62.2149)  Acc@5: 87.5000 (90.8545)  time: 0.3472  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3780/4579]  eta: 0:04:35  Lr: 0.030000  Loss: -0.0002  Acc@1: 68.7500 (62.2173)  Acc@5: 87.5000 (90.8539)  time: 0.3471  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3790/4579]  eta: 0:04:32  Lr: 0.030000  Loss: 0.1013  Acc@1: 68.7500 (62.2181)  Acc@5: 93.7500 (90.8583)  time: 0.3471  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3800/4579]  eta: 0:04:28  Lr: 0.030000  Loss: -0.0128  Acc@1: 68.7500 (62.2320)  Acc@5: 93.7500 (90.8577)  time: 0.3469  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3810/4579]  eta: 0:04:25  Lr: 0.030000  Loss: 0.0027  Acc@1: 68.7500 (62.2458)  Acc@5: 93.7500 (90.8620)  time: 0.3462  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3820/4579]  eta: 0:04:21  Lr: 0.030000  Loss: 0.2206  Acc@1: 68.7500 (62.2432)  Acc@5: 87.5000 (90.8565)  time: 0.3460  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3830/4579]  eta: 0:04:18  Lr: 0.030000  Loss: 0.2656  Acc@1: 62.5000 (62.2341)  Acc@5: 87.5000 (90.8607)  time: 0.3477  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [3840/4579]  eta: 0:04:15  Lr: 0.030000  Loss: 0.1087  Acc@1: 62.5000 (62.2348)  Acc@5: 93.7500 (90.8699)  time: 0.3481  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [3850/4579]  eta: 0:04:11  Lr: 0.030000  Loss: 0.0233  Acc@1: 62.5000 (62.2371)  Acc@5: 93.7500 (90.8741)  time: 0.3459  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3860/4579]  eta: 0:04:08  Lr: 0.030000  Loss: 0.1861  Acc@1: 68.7500 (62.2459)  Acc@5: 93.7500 (90.8719)  time: 0.3459  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3870/4579]  eta: 0:04:04  Lr: 0.030000  Loss: 0.3412  Acc@1: 68.7500 (62.2578)  Acc@5: 93.7500 (90.8858)  time: 0.3462  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3880/4579]  eta: 0:04:01  Lr: 0.030000  Loss: -0.0982  Acc@1: 62.5000 (62.2600)  Acc@5: 93.7500 (90.8851)  time: 0.3464  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3890/4579]  eta: 0:03:57  Lr: 0.030000  Loss: 0.1408  Acc@1: 62.5000 (62.2591)  Acc@5: 93.7500 (90.8924)  time: 0.3469  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3900/4579]  eta: 0:03:54  Lr: 0.030000  Loss: 0.2740  Acc@1: 62.5000 (62.2773)  Acc@5: 93.7500 (90.8998)  time: 0.3476  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3910/4579]  eta: 0:03:50  Lr: 0.030000  Loss: 0.1322  Acc@1: 62.5000 (62.2731)  Acc@5: 93.7500 (90.8991)  time: 0.3470  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [3920/4579]  eta: 0:03:47  Lr: 0.030000  Loss: 0.3253  Acc@1: 62.5000 (62.2832)  Acc@5: 93.7500 (90.9016)  time: 0.3452  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [3930/4579]  eta: 0:03:44  Lr: 0.030000  Loss: 0.2475  Acc@1: 62.5000 (62.2838)  Acc@5: 93.7500 (90.9024)  time: 0.3456  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [3940/4579]  eta: 0:03:40  Lr: 0.030000  Loss: 0.0202  Acc@1: 62.5000 (62.2716)  Acc@5: 93.7500 (90.9049)  time: 0.3456  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [3950/4579]  eta: 0:03:37  Lr: 0.030000  Loss: -0.0210  Acc@1: 62.5000 (62.2754)  Acc@5: 93.7500 (90.9074)  time: 0.3447  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [3960/4579]  eta: 0:03:33  Lr: 0.030000  Loss: 0.0534  Acc@1: 62.5000 (62.2807)  Acc@5: 93.7500 (90.9130)  time: 0.3447  data: 0.0002  max mem: 2500
Train: Epoch[5/5]  [3970/4579]  eta: 0:03:30  Lr: 0.030000  Loss: -0.1124  Acc@1: 62.5000 (62.2749)  Acc@5: 93.7500 (90.9170)  time: 0.3450  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [3980/4579]  eta: 0:03:26  Lr: 0.030000  Loss: 0.2674  Acc@1: 68.7500 (62.2833)  Acc@5: 93.7500 (90.9147)  time: 0.3444  data: 0.0002  max mem: 2500
Train: Epoch[5/5]  [3990/4579]  eta: 0:03:23  Lr: 0.030000  Loss: 0.5673  Acc@1: 56.2500 (62.2714)  Acc@5: 87.5000 (90.9030)  time: 0.3433  data: 0.0002  max mem: 2500
Train: Epoch[5/5]  [4000/4579]  eta: 0:03:19  Lr: 0.030000  Loss: 0.1237  Acc@1: 56.2500 (62.2704)  Acc@5: 87.5000 (90.8992)  time: 0.3433  data: 0.0002  max mem: 2500
Train: Epoch[5/5]  [4010/4579]  eta: 0:03:16  Lr: 0.030000  Loss: -0.1083  Acc@1: 62.5000 (62.2818)  Acc@5: 93.7500 (90.9078)  time: 0.3435  data: 0.0002  max mem: 2500
Train: Epoch[5/5]  [4020/4579]  eta: 0:03:12  Lr: 0.030000  Loss: 0.0084  Acc@1: 68.7500 (62.2886)  Acc@5: 93.7500 (90.9118)  time: 0.3441  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [4030/4579]  eta: 0:03:09  Lr: 0.030000  Loss: 0.3457  Acc@1: 62.5000 (62.2845)  Acc@5: 93.7500 (90.9080)  time: 0.3450  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [4040/4579]  eta: 0:03:06  Lr: 0.030000  Loss: 0.1064  Acc@1: 62.5000 (62.2773)  Acc@5: 87.5000 (90.9057)  time: 0.3448  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [4050/4579]  eta: 0:03:02  Lr: 0.030000  Loss: 0.0383  Acc@1: 62.5000 (62.2840)  Acc@5: 93.7500 (90.9127)  time: 0.3448  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [4060/4579]  eta: 0:02:59  Lr: 0.030000  Loss: 0.2899  Acc@1: 68.7500 (62.2968)  Acc@5: 93.7500 (90.9120)  time: 0.3461  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [4070/4579]  eta: 0:02:55  Lr: 0.030000  Loss: 0.0968  Acc@1: 68.7500 (62.3035)  Acc@5: 93.7500 (90.9205)  time: 0.3456  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [4080/4579]  eta: 0:02:52  Lr: 0.030000  Loss: 0.1080  Acc@1: 68.7500 (62.3101)  Acc@5: 93.7500 (90.9290)  time: 0.3446  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [4090/4579]  eta: 0:02:48  Lr: 0.030000  Loss: 0.1994  Acc@1: 62.5000 (62.3029)  Acc@5: 93.7500 (90.9298)  time: 0.3445  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [4100/4579]  eta: 0:02:45  Lr: 0.030000  Loss: 0.3181  Acc@1: 62.5000 (62.3095)  Acc@5: 87.5000 (90.9306)  time: 0.3443  data: 0.0002  max mem: 2500
Train: Epoch[5/5]  [4110/4579]  eta: 0:02:41  Lr: 0.030000  Loss: 0.1629  Acc@1: 62.5000 (62.3160)  Acc@5: 93.7500 (90.9374)  time: 0.3444  data: 0.0002  max mem: 2500
Train: Epoch[5/5]  [4120/4579]  eta: 0:02:38  Lr: 0.030000  Loss: 0.0390  Acc@1: 68.7500 (62.3241)  Acc@5: 93.7500 (90.9351)  time: 0.3438  data: 0.0002  max mem: 2500
Train: Epoch[5/5]  [4130/4579]  eta: 0:02:34  Lr: 0.030000  Loss: 0.2748  Acc@1: 68.7500 (62.3321)  Acc@5: 93.7500 (90.9389)  time: 0.3446  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [4140/4579]  eta: 0:02:31  Lr: 0.030000  Loss: 0.0165  Acc@1: 68.7500 (62.3491)  Acc@5: 93.7500 (90.9487)  time: 0.3451  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [4150/4579]  eta: 0:02:28  Lr: 0.030000  Loss: 0.0226  Acc@1: 68.7500 (62.3479)  Acc@5: 93.7500 (90.9540)  time: 0.3442  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [4160/4579]  eta: 0:02:24  Lr: 0.030000  Loss: 0.0618  Acc@1: 62.5000 (62.3528)  Acc@5: 93.7500 (90.9577)  time: 0.3442  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [4170/4579]  eta: 0:02:21  Lr: 0.030000  Loss: 0.3024  Acc@1: 62.5000 (62.3502)  Acc@5: 93.7500 (90.9569)  time: 0.3449  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [4180/4579]  eta: 0:02:17  Lr: 0.030000  Loss: 0.5056  Acc@1: 56.2500 (62.3221)  Acc@5: 87.5000 (90.9442)  time: 0.3453  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [4190/4579]  eta: 0:02:14  Lr: 0.030000  Loss: 0.2444  Acc@1: 56.2500 (62.3210)  Acc@5: 87.5000 (90.9464)  time: 0.3451  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [4200/4579]  eta: 0:02:10  Lr: 0.030000  Loss: 0.0997  Acc@1: 62.5000 (62.3215)  Acc@5: 93.7500 (90.9560)  time: 0.3462  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [4210/4579]  eta: 0:02:07  Lr: 0.030000  Loss: 0.2444  Acc@1: 56.2500 (62.3189)  Acc@5: 93.7500 (90.9567)  time: 0.3456  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [4220/4579]  eta: 0:02:03  Lr: 0.030000  Loss: 0.2514  Acc@1: 62.5000 (62.3223)  Acc@5: 93.7500 (90.9515)  time: 0.3439  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [4230/4579]  eta: 0:02:00  Lr: 0.030000  Loss: 0.0635  Acc@1: 68.7500 (62.3375)  Acc@5: 93.7500 (90.9552)  time: 0.3437  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [4240/4579]  eta: 0:01:57  Lr: 0.030000  Loss: 0.2632  Acc@1: 62.5000 (62.3349)  Acc@5: 93.7500 (90.9514)  time: 0.3434  data: 0.0002  max mem: 2500
Train: Epoch[5/5]  [4250/4579]  eta: 0:01:53  Lr: 0.030000  Loss: 0.0955  Acc@1: 62.5000 (62.3265)  Acc@5: 87.5000 (90.9507)  time: 0.3432  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [4260/4579]  eta: 0:01:50  Lr: 0.030000  Loss: -0.2375  Acc@1: 62.5000 (62.3357)  Acc@5: 93.7500 (90.9572)  time: 0.3434  data: 0.0002  max mem: 2500
Train: Epoch[5/5]  [4270/4579]  eta: 0:01:46  Lr: 0.030000  Loss: -0.1027  Acc@1: 68.7500 (62.3376)  Acc@5: 93.7500 (90.9652)  time: 0.3434  data: 0.0002  max mem: 2500
Train: Epoch[5/5]  [4280/4579]  eta: 0:01:43  Lr: 0.030000  Loss: 0.4279  Acc@1: 62.5000 (62.3394)  Acc@5: 93.7500 (90.9601)  time: 0.3432  data: 0.0002  max mem: 2500
Train: Epoch[5/5]  [4290/4579]  eta: 0:01:39  Lr: 0.030000  Loss: 0.2131  Acc@1: 56.2500 (62.3267)  Acc@5: 87.5000 (90.9622)  time: 0.3435  data: 0.0002  max mem: 2500
Train: Epoch[5/5]  [4300/4579]  eta: 0:01:36  Lr: 0.030000  Loss: 0.1251  Acc@1: 56.2500 (62.3184)  Acc@5: 93.7500 (90.9629)  time: 0.3436  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [4310/4579]  eta: 0:01:32  Lr: 0.030000  Loss: 0.2674  Acc@1: 56.2500 (62.3014)  Acc@5: 87.5000 (90.9476)  time: 0.3435  data: 0.0002  max mem: 2500
Train: Epoch[5/5]  [4320/4579]  eta: 0:01:29  Lr: 0.030000  Loss: 0.1504  Acc@1: 56.2500 (62.3018)  Acc@5: 87.5000 (90.9439)  time: 0.3444  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [4330/4579]  eta: 0:01:25  Lr: 0.030000  Loss: -0.0440  Acc@1: 68.7500 (62.3196)  Acc@5: 93.7500 (90.9490)  time: 0.3463  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [4340/4579]  eta: 0:01:22  Lr: 0.030000  Loss: 0.1853  Acc@1: 62.5000 (62.3071)  Acc@5: 93.7500 (90.9511)  time: 0.3471  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [4350/4579]  eta: 0:01:19  Lr: 0.030000  Loss: 0.0363  Acc@1: 62.5000 (62.3176)  Acc@5: 93.7500 (90.9532)  time: 0.3470  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [4360/4579]  eta: 0:01:15  Lr: 0.030000  Loss: -0.0569  Acc@1: 68.7500 (62.3180)  Acc@5: 87.5000 (90.9453)  time: 0.3463  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [4370/4579]  eta: 0:01:12  Lr: 0.030000  Loss: -0.0447  Acc@1: 62.5000 (62.3298)  Acc@5: 93.7500 (90.9532)  time: 0.3457  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [4380/4579]  eta: 0:01:08  Lr: 0.030000  Loss: 0.0527  Acc@1: 62.5000 (62.3416)  Acc@5: 93.7500 (90.9595)  time: 0.3455  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [4390/4579]  eta: 0:01:05  Lr: 0.030000  Loss: 0.0143  Acc@1: 62.5000 (62.3392)  Acc@5: 93.7500 (90.9673)  time: 0.3450  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [4400/4579]  eta: 0:01:01  Lr: 0.030000  Loss: 0.2627  Acc@1: 56.2500 (62.3282)  Acc@5: 93.7500 (90.9609)  time: 0.3450  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [4410/4579]  eta: 0:00:58  Lr: 0.030000  Loss: -0.0933  Acc@1: 56.2500 (62.3201)  Acc@5: 87.5000 (90.9516)  time: 0.3450  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [4420/4579]  eta: 0:00:54  Lr: 0.030000  Loss: 0.2438  Acc@1: 56.2500 (62.3219)  Acc@5: 87.5000 (90.9565)  time: 0.3453  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [4430/4579]  eta: 0:00:51  Lr: 0.030000  Loss: 0.4536  Acc@1: 62.5000 (62.3307)  Acc@5: 93.7500 (90.9586)  time: 0.3450  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [4440/4579]  eta: 0:00:47  Lr: 0.030000  Loss: 0.5886  Acc@1: 62.5000 (62.3297)  Acc@5: 93.7500 (90.9550)  time: 0.3444  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [4450/4579]  eta: 0:00:44  Lr: 0.030000  Loss: 0.1686  Acc@1: 56.2500 (62.3273)  Acc@5: 87.5000 (90.9515)  time: 0.3446  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [4460/4579]  eta: 0:00:41  Lr: 0.030000  Loss: -0.1129  Acc@1: 62.5000 (62.3291)  Acc@5: 87.5000 (90.9493)  time: 0.3445  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [4470/4579]  eta: 0:00:37  Lr: 0.030000  Loss: 0.3325  Acc@1: 62.5000 (62.3197)  Acc@5: 93.7500 (90.9500)  time: 0.3453  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [4480/4579]  eta: 0:00:34  Lr: 0.030000  Loss: 0.0536  Acc@1: 62.5000 (62.3340)  Acc@5: 93.7500 (90.9521)  time: 0.3464  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [4490/4579]  eta: 0:00:30  Lr: 0.030000  Loss: -0.0389  Acc@1: 62.5000 (62.3233)  Acc@5: 93.7500 (90.9500)  time: 0.3462  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [4500/4579]  eta: 0:00:27  Lr: 0.030000  Loss: -0.0810  Acc@1: 56.2500 (62.3209)  Acc@5: 87.5000 (90.9437)  time: 0.3457  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [4510/4579]  eta: 0:00:23  Lr: 0.030000  Loss: -0.0419  Acc@1: 56.2500 (62.3171)  Acc@5: 87.5000 (90.9416)  time: 0.3449  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [4520/4579]  eta: 0:00:20  Lr: 0.030000  Loss: 0.4525  Acc@1: 62.5000 (62.3258)  Acc@5: 93.7500 (90.9450)  time: 0.3446  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [4530/4579]  eta: 0:00:16  Lr: 0.030000  Loss: -0.1096  Acc@1: 56.2500 (62.3124)  Acc@5: 93.7500 (90.9429)  time: 0.3445  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [4540/4579]  eta: 0:00:13  Lr: 0.030000  Loss: 0.1995  Acc@1: 56.2500 (62.2991)  Acc@5: 87.5000 (90.9312)  time: 0.3450  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [4550/4579]  eta: 0:00:10  Lr: 0.030000  Loss: 0.3643  Acc@1: 62.5000 (62.2995)  Acc@5: 87.5000 (90.9333)  time: 0.3453  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [4560/4579]  eta: 0:00:06  Lr: 0.030000  Loss: -0.0836  Acc@1: 62.5000 (62.2958)  Acc@5: 87.5000 (90.9299)  time: 0.3449  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [4570/4579]  eta: 0:00:03  Lr: 0.030000  Loss: 0.0740  Acc@1: 62.5000 (62.2908)  Acc@5: 87.5000 (90.9292)  time: 0.3454  data: 0.0010  max mem: 2500
Train: Epoch[5/5]  [4578/4579]  eta: 0:00:00  Lr: 0.030000  Loss: 0.3105  Acc@1: 62.5000 (62.2998)  Acc@5: 93.7500 (90.9237)  time: 0.3385  data: 0.0009  max mem: 2500
Train: Epoch[5/5] Total time: 0:26:20 (0.3453 s / it)
{0: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 1: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 2: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 3: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 4: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 5: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 6: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 7: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 8: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 9: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 10: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 11: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 12: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 13: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 14: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 15: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 16: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 17: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 18: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 19: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}}
Averaged stats: Lr: 0.030000  Loss: 0.3105  Acc@1: 62.5000 (62.2998)  Acc@5: 93.7500 (90.9237)
Test: [Task 1]  [   0/1627]  eta: 0:11:45  Loss: 2.5126 (2.5126)  Acc@1: 87.5000 (87.5000)  Acc@5: 93.7500 (93.7500)  time: 0.4335  data: 0.2190  max mem: 2500
Test: [Task 1]  [  10/1627]  eta: 0:06:16  Loss: 2.4349 (2.4199)  Acc@1: 87.5000 (84.0909)  Acc@5: 93.7500 (96.0227)  time: 0.2331  data: 0.0201  max mem: 2500
Test: [Task 1]  [  20/1627]  eta: 0:05:59  Loss: 2.4324 (2.4459)  Acc@1: 81.2500 (83.0357)  Acc@5: 93.7500 (95.2381)  time: 0.2129  data: 0.0002  max mem: 2500
Test: [Task 1]  [  30/1627]  eta: 0:05:51  Loss: 2.4842 (2.4571)  Acc@1: 81.2500 (82.6613)  Acc@5: 100.0000 (96.1694)  time: 0.2126  data: 0.0002  max mem: 2500
Test: [Task 1]  [  40/1627]  eta: 0:05:46  Loss: 2.5051 (2.4725)  Acc@1: 81.2500 (81.5549)  Acc@5: 100.0000 (96.0366)  time: 0.2126  data: 0.0002  max mem: 2500
Test: [Task 1]  [  50/1627]  eta: 0:05:42  Loss: 2.4413 (2.4654)  Acc@1: 81.2500 (81.7402)  Acc@5: 100.0000 (96.0784)  time: 0.2128  data: 0.0002  max mem: 2500
Test: [Task 1]  [  60/1627]  eta: 0:05:39  Loss: 2.4418 (2.4694)  Acc@1: 81.2500 (81.5574)  Acc@5: 93.7500 (95.5943)  time: 0.2128  data: 0.0002  max mem: 2500
Test: [Task 1]  [  70/1627]  eta: 0:05:36  Loss: 2.4554 (2.4720)  Acc@1: 81.2500 (81.1620)  Acc@5: 93.7500 (95.9507)  time: 0.2128  data: 0.0002  max mem: 2500
Test: [Task 1]  [  80/1627]  eta: 0:05:33  Loss: 2.4176 (2.4695)  Acc@1: 81.2500 (81.4043)  Acc@5: 100.0000 (96.2963)  time: 0.2128  data: 0.0002  max mem: 2500
Test: [Task 1]  [  90/1627]  eta: 0:05:30  Loss: 2.4323 (2.4701)  Acc@1: 81.2500 (80.9753)  Acc@5: 100.0000 (96.0852)  time: 0.2129  data: 0.0002  max mem: 2500
Test: [Task 1]  [ 100/1627]  eta: 0:05:28  Loss: 2.4924 (2.4785)  Acc@1: 75.0000 (80.4455)  Acc@5: 93.7500 (95.8540)  time: 0.2130  data: 0.0002  max mem: 2500
Test: [Task 1]  [ 110/1627]  eta: 0:05:25  Loss: 2.4729 (2.4782)  Acc@1: 81.2500 (80.5743)  Acc@5: 93.7500 (96.0023)  time: 0.2128  data: 0.0002  max mem: 2500
Test: [Task 1]  [ 120/1627]  eta: 0:05:23  Loss: 2.4378 (2.4785)  Acc@1: 87.5000 (80.5785)  Acc@5: 100.0000 (96.0744)  time: 0.2128  data: 0.0002  max mem: 2500
Test: [Task 1]  [ 130/1627]  eta: 0:05:21  Loss: 2.4438 (2.4751)  Acc@1: 87.5000 (80.7252)  Acc@5: 100.0000 (96.0401)  time: 0.2129  data: 0.0002  max mem: 2500
Test: [Task 1]  [ 140/1627]  eta: 0:05:18  Loss: 2.4429 (2.4737)  Acc@1: 81.2500 (80.7624)  Acc@5: 100.0000 (96.1436)  time: 0.2131  data: 0.0002  max mem: 2500
Test: [Task 1]  [ 150/1627]  eta: 0:05:16  Loss: 2.3393 (2.4658)  Acc@1: 87.5000 (81.0430)  Acc@5: 100.0000 (96.1507)  time: 0.2136  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 160/1627]  eta: 0:05:14  Loss: 2.3532 (2.4654)  Acc@1: 87.5000 (81.1724)  Acc@5: 100.0000 (96.3121)  time: 0.2134  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 170/1627]  eta: 0:05:12  Loss: 2.4277 (2.4628)  Acc@1: 87.5000 (81.3596)  Acc@5: 100.0000 (96.4547)  time: 0.2135  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 180/1627]  eta: 0:05:10  Loss: 2.4277 (2.4647)  Acc@1: 81.2500 (81.2155)  Acc@5: 100.0000 (96.4434)  time: 0.2142  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 190/1627]  eta: 0:05:07  Loss: 2.4591 (2.4632)  Acc@1: 81.2500 (81.2500)  Acc@5: 93.7500 (96.4005)  time: 0.2147  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 200/1627]  eta: 0:05:05  Loss: 2.4596 (2.4624)  Acc@1: 81.2500 (81.1256)  Acc@5: 100.0000 (96.4863)  time: 0.2145  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 210/1627]  eta: 0:05:03  Loss: 2.4437 (2.4602)  Acc@1: 81.2500 (81.2796)  Acc@5: 100.0000 (96.4751)  time: 0.2140  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 220/1627]  eta: 0:05:01  Loss: 2.4087 (2.4608)  Acc@1: 81.2500 (81.1086)  Acc@5: 100.0000 (96.5498)  time: 0.2138  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 230/1627]  eta: 0:04:59  Loss: 2.4383 (2.4606)  Acc@1: 81.2500 (81.2771)  Acc@5: 100.0000 (96.4827)  time: 0.2140  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 240/1627]  eta: 0:04:57  Loss: 2.4047 (2.4598)  Acc@1: 81.2500 (81.3537)  Acc@5: 93.7500 (96.4990)  time: 0.2138  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 250/1627]  eta: 0:04:54  Loss: 2.3868 (2.4577)  Acc@1: 81.2500 (81.2749)  Acc@5: 100.0000 (96.4890)  time: 0.2137  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 260/1627]  eta: 0:04:52  Loss: 2.4136 (2.4588)  Acc@1: 81.2500 (81.2979)  Acc@5: 100.0000 (96.4320)  time: 0.2146  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 270/1627]  eta: 0:04:50  Loss: 2.4249 (2.4560)  Acc@1: 87.5000 (81.4345)  Acc@5: 100.0000 (96.4714)  time: 0.2150  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 280/1627]  eta: 0:04:48  Loss: 2.4239 (2.4564)  Acc@1: 81.2500 (81.3167)  Acc@5: 100.0000 (96.4635)  time: 0.2141  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 290/1627]  eta: 0:04:46  Loss: 2.4239 (2.4558)  Acc@1: 81.2500 (81.3789)  Acc@5: 93.7500 (96.4777)  time: 0.2141  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 300/1627]  eta: 0:04:44  Loss: 2.4292 (2.4554)  Acc@1: 81.2500 (81.3331)  Acc@5: 100.0000 (96.4909)  time: 0.2152  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 310/1627]  eta: 0:04:42  Loss: 2.4535 (2.4544)  Acc@1: 81.2500 (81.3907)  Acc@5: 100.0000 (96.4630)  time: 0.2152  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 320/1627]  eta: 0:04:40  Loss: 2.4509 (2.4555)  Acc@1: 81.2500 (81.3863)  Acc@5: 100.0000 (96.5343)  time: 0.2143  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 330/1627]  eta: 0:04:37  Loss: 2.4209 (2.4559)  Acc@1: 81.2500 (81.3444)  Acc@5: 100.0000 (96.5446)  time: 0.2143  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 340/1627]  eta: 0:04:35  Loss: 2.4481 (2.4576)  Acc@1: 81.2500 (81.3600)  Acc@5: 100.0000 (96.5543)  time: 0.2145  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 350/1627]  eta: 0:04:33  Loss: 2.4751 (2.4577)  Acc@1: 81.2500 (81.3568)  Acc@5: 100.0000 (96.5634)  time: 0.2142  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 360/1627]  eta: 0:04:31  Loss: 2.4751 (2.4594)  Acc@1: 81.2500 (81.2327)  Acc@5: 100.0000 (96.5547)  time: 0.2143  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 370/1627]  eta: 0:04:29  Loss: 2.4163 (2.4577)  Acc@1: 81.2500 (81.3342)  Acc@5: 100.0000 (96.5633)  time: 0.2145  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 380/1627]  eta: 0:04:27  Loss: 2.4105 (2.4574)  Acc@1: 81.2500 (81.3812)  Acc@5: 93.7500 (96.5059)  time: 0.2146  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 390/1627]  eta: 0:04:25  Loss: 2.4341 (2.4575)  Acc@1: 81.2500 (81.2500)  Acc@5: 93.7500 (96.4514)  time: 0.2149  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 400/1627]  eta: 0:04:23  Loss: 2.4480 (2.4567)  Acc@1: 75.0000 (81.2812)  Acc@5: 93.7500 (96.4620)  time: 0.2152  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 410/1627]  eta: 0:04:20  Loss: 2.4071 (2.4563)  Acc@1: 81.2500 (81.3260)  Acc@5: 100.0000 (96.4416)  time: 0.2148  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 420/1627]  eta: 0:04:18  Loss: 2.4206 (2.4557)  Acc@1: 81.2500 (81.3836)  Acc@5: 100.0000 (96.4667)  time: 0.2142  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 430/1627]  eta: 0:04:16  Loss: 2.4032 (2.4543)  Acc@1: 81.2500 (81.4240)  Acc@5: 100.0000 (96.4907)  time: 0.2141  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 440/1627]  eta: 0:04:14  Loss: 2.3840 (2.4537)  Acc@1: 81.2500 (81.4059)  Acc@5: 100.0000 (96.4994)  time: 0.2143  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 450/1627]  eta: 0:04:12  Loss: 2.4329 (2.4552)  Acc@1: 81.2500 (81.3193)  Acc@5: 93.7500 (96.4385)  time: 0.2143  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 460/1627]  eta: 0:04:10  Loss: 2.4374 (2.4553)  Acc@1: 81.2500 (81.3313)  Acc@5: 100.0000 (96.4479)  time: 0.2139  data: 0.0002  max mem: 2500
Test: [Task 1]  [ 470/1627]  eta: 0:04:08  Loss: 2.3902 (2.4544)  Acc@1: 87.5000 (81.3827)  Acc@5: 100.0000 (96.4437)  time: 0.2144  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 480/1627]  eta: 0:04:05  Loss: 2.3677 (2.4547)  Acc@1: 81.2500 (81.2630)  Acc@5: 100.0000 (96.4657)  time: 0.2144  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 490/1627]  eta: 0:04:03  Loss: 2.5082 (2.4555)  Acc@1: 81.2500 (81.2755)  Acc@5: 93.7500 (96.4486)  time: 0.2139  data: 0.0002  max mem: 2500
Test: [Task 1]  [ 500/1627]  eta: 0:04:01  Loss: 2.5003 (2.4561)  Acc@1: 81.2500 (81.2375)  Acc@5: 93.7500 (96.3947)  time: 0.2142  data: 0.0002  max mem: 2500
Test: [Task 1]  [ 510/1627]  eta: 0:03:59  Loss: 2.4660 (2.4574)  Acc@1: 81.2500 (81.1766)  Acc@5: 93.7500 (96.3185)  time: 0.2140  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 520/1627]  eta: 0:03:57  Loss: 2.4538 (2.4581)  Acc@1: 81.2500 (81.1780)  Acc@5: 93.7500 (96.3052)  time: 0.2144  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 530/1627]  eta: 0:03:55  Loss: 2.3895 (2.4559)  Acc@1: 87.5000 (81.2500)  Acc@5: 100.0000 (96.3395)  time: 0.2142  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 540/1627]  eta: 0:03:52  Loss: 2.3841 (2.4566)  Acc@1: 81.2500 (81.2038)  Acc@5: 100.0000 (96.3494)  time: 0.2132  data: 0.0002  max mem: 2500
Test: [Task 1]  [ 550/1627]  eta: 0:03:50  Loss: 2.4845 (2.4578)  Acc@1: 75.0000 (81.1139)  Acc@5: 100.0000 (96.3475)  time: 0.2132  data: 0.0002  max mem: 2500
Test: [Task 1]  [ 560/1627]  eta: 0:03:48  Loss: 2.4627 (2.4585)  Acc@1: 75.0000 (81.0606)  Acc@5: 93.7500 (96.3347)  time: 0.2133  data: 0.0002  max mem: 2500
Test: [Task 1]  [ 570/1627]  eta: 0:03:46  Loss: 2.4061 (2.4571)  Acc@1: 81.2500 (81.1843)  Acc@5: 93.7500 (96.3660)  time: 0.2131  data: 0.0002  max mem: 2500
Test: [Task 1]  [ 580/1627]  eta: 0:03:44  Loss: 2.3787 (2.4566)  Acc@1: 87.5000 (81.2177)  Acc@5: 100.0000 (96.3640)  time: 0.2133  data: 0.0002  max mem: 2500
Test: [Task 1]  [ 590/1627]  eta: 0:03:42  Loss: 2.4212 (2.4565)  Acc@1: 81.2500 (81.2288)  Acc@5: 100.0000 (96.4044)  time: 0.2134  data: 0.0002  max mem: 2500
Test: [Task 1]  [ 600/1627]  eta: 0:03:39  Loss: 2.4350 (2.4564)  Acc@1: 81.2500 (81.2500)  Acc@5: 100.0000 (96.4226)  time: 0.2131  data: 0.0002  max mem: 2500
Test: [Task 1]  [ 610/1627]  eta: 0:03:37  Loss: 2.3802 (2.4548)  Acc@1: 81.2500 (81.3114)  Acc@5: 100.0000 (96.4403)  time: 0.2130  data: 0.0002  max mem: 2500
Test: [Task 1]  [ 620/1627]  eta: 0:03:35  Loss: 2.3802 (2.4554)  Acc@1: 81.2500 (81.2097)  Acc@5: 100.0000 (96.4372)  time: 0.2138  data: 0.0002  max mem: 2500
Test: [Task 1]  [ 630/1627]  eta: 0:03:33  Loss: 2.4806 (2.4555)  Acc@1: 75.0000 (81.2005)  Acc@5: 100.0000 (96.4342)  time: 0.2143  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 640/1627]  eta: 0:03:31  Loss: 2.4205 (2.4551)  Acc@1: 81.2500 (81.2110)  Acc@5: 100.0000 (96.4314)  time: 0.2143  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 650/1627]  eta: 0:03:29  Loss: 2.4801 (2.4548)  Acc@1: 81.2500 (81.1732)  Acc@5: 100.0000 (96.4478)  time: 0.2141  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 660/1627]  eta: 0:03:27  Loss: 2.4515 (2.4540)  Acc@1: 81.2500 (81.1933)  Acc@5: 100.0000 (96.4259)  time: 0.2143  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 670/1627]  eta: 0:03:24  Loss: 2.4242 (2.4542)  Acc@1: 81.2500 (81.1755)  Acc@5: 100.0000 (96.4232)  time: 0.2148  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 680/1627]  eta: 0:03:22  Loss: 2.4305 (2.4536)  Acc@1: 81.2500 (81.1949)  Acc@5: 100.0000 (96.4391)  time: 0.2143  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 690/1627]  eta: 0:03:20  Loss: 2.4074 (2.4521)  Acc@1: 81.2500 (81.2590)  Acc@5: 100.0000 (96.4725)  time: 0.2137  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 700/1627]  eta: 0:03:18  Loss: 2.4074 (2.4524)  Acc@1: 87.5000 (81.3035)  Acc@5: 100.0000 (96.4426)  time: 0.2141  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 710/1627]  eta: 0:03:16  Loss: 2.4062 (2.4517)  Acc@1: 81.2500 (81.3379)  Acc@5: 100.0000 (96.4662)  time: 0.2144  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 720/1627]  eta: 0:03:14  Loss: 2.4042 (2.4515)  Acc@1: 81.2500 (81.3540)  Acc@5: 100.0000 (96.4632)  time: 0.2144  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 730/1627]  eta: 0:03:12  Loss: 2.4063 (2.4522)  Acc@1: 81.2500 (81.3098)  Acc@5: 100.0000 (96.4603)  time: 0.2141  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 740/1627]  eta: 0:03:10  Loss: 2.5025 (2.4528)  Acc@1: 81.2500 (81.2500)  Acc@5: 93.7500 (96.4491)  time: 0.2149  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 750/1627]  eta: 0:03:07  Loss: 2.4755 (2.4526)  Acc@1: 81.2500 (81.2916)  Acc@5: 100.0000 (96.4714)  time: 0.2152  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 760/1627]  eta: 0:03:05  Loss: 2.4295 (2.4529)  Acc@1: 81.2500 (81.2993)  Acc@5: 100.0000 (96.4356)  time: 0.2141  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 770/1627]  eta: 0:03:03  Loss: 2.4295 (2.4522)  Acc@1: 81.2500 (81.3149)  Acc@5: 100.0000 (96.4656)  time: 0.2141  data: 0.0002  max mem: 2500
Test: [Task 1]  [ 780/1627]  eta: 0:03:01  Loss: 2.3639 (2.4509)  Acc@1: 87.5000 (81.4020)  Acc@5: 100.0000 (96.4869)  time: 0.2142  data: 0.0002  max mem: 2500
Test: [Task 1]  [ 790/1627]  eta: 0:02:59  Loss: 2.3472 (2.4515)  Acc@1: 87.5000 (81.3764)  Acc@5: 100.0000 (96.4681)  time: 0.2141  data: 0.0002  max mem: 2500
Test: [Task 1]  [ 800/1627]  eta: 0:02:57  Loss: 2.4363 (2.4514)  Acc@1: 87.5000 (81.4217)  Acc@5: 93.7500 (96.4654)  time: 0.2145  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 810/1627]  eta: 0:02:55  Loss: 2.4113 (2.4513)  Acc@1: 87.5000 (81.4273)  Acc@5: 100.0000 (96.4704)  time: 0.2145  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 820/1627]  eta: 0:02:52  Loss: 2.4162 (2.4510)  Acc@1: 87.5000 (81.4860)  Acc@5: 100.0000 (96.5058)  time: 0.2142  data: 0.0002  max mem: 2500
Test: [Task 1]  [ 830/1627]  eta: 0:02:50  Loss: 2.4284 (2.4517)  Acc@1: 81.2500 (81.4230)  Acc@5: 100.0000 (96.4877)  time: 0.2141  data: 0.0002  max mem: 2500
Test: [Task 1]  [ 840/1627]  eta: 0:02:48  Loss: 2.3809 (2.4506)  Acc@1: 87.5000 (81.4952)  Acc@5: 100.0000 (96.5071)  time: 0.2142  data: 0.0002  max mem: 2500
Test: [Task 1]  [ 850/1627]  eta: 0:02:46  Loss: 2.4268 (2.4509)  Acc@1: 87.5000 (81.4777)  Acc@5: 100.0000 (96.5115)  time: 0.2148  data: 0.0002  max mem: 2500
Test: [Task 1]  [ 860/1627]  eta: 0:02:44  Loss: 2.4649 (2.4511)  Acc@1: 81.2500 (81.5041)  Acc@5: 100.0000 (96.5302)  time: 0.2144  data: 0.0002  max mem: 2500
Test: [Task 1]  [ 870/1627]  eta: 0:02:42  Loss: 2.3700 (2.4499)  Acc@1: 87.5000 (81.5801)  Acc@5: 100.0000 (96.5485)  time: 0.2136  data: 0.0002  max mem: 2500
Test: [Task 1]  [ 880/1627]  eta: 0:02:40  Loss: 2.4060 (2.4510)  Acc@1: 81.2500 (81.5409)  Acc@5: 100.0000 (96.5309)  time: 0.2137  data: 0.0002  max mem: 2500
Test: [Task 1]  [ 890/1627]  eta: 0:02:37  Loss: 2.4927 (2.4514)  Acc@1: 81.2500 (81.5236)  Acc@5: 93.7500 (96.5067)  time: 0.2137  data: 0.0002  max mem: 2500
Test: [Task 1]  [ 900/1627]  eta: 0:02:35  Loss: 2.4495 (2.4521)  Acc@1: 81.2500 (81.5136)  Acc@5: 100.0000 (96.4831)  time: 0.2138  data: 0.0002  max mem: 2500
Test: [Task 1]  [ 910/1627]  eta: 0:02:33  Loss: 2.4717 (2.4528)  Acc@1: 81.2500 (81.4627)  Acc@5: 100.0000 (96.4531)  time: 0.2139  data: 0.0002  max mem: 2500
Test: [Task 1]  [ 920/1627]  eta: 0:02:31  Loss: 2.4587 (2.4526)  Acc@1: 81.2500 (81.4739)  Acc@5: 100.0000 (96.4509)  time: 0.2137  data: 0.0002  max mem: 2500
Test: [Task 1]  [ 930/1627]  eta: 0:02:29  Loss: 2.4029 (2.4519)  Acc@1: 81.2500 (81.5118)  Acc@5: 93.7500 (96.4487)  time: 0.2136  data: 0.0002  max mem: 2500
Test: [Task 1]  [ 940/1627]  eta: 0:02:27  Loss: 2.3763 (2.4507)  Acc@1: 81.2500 (81.5622)  Acc@5: 100.0000 (96.4865)  time: 0.2138  data: 0.0002  max mem: 2500
Test: [Task 1]  [ 950/1627]  eta: 0:02:25  Loss: 2.3904 (2.4504)  Acc@1: 81.2500 (81.5457)  Acc@5: 100.0000 (96.5037)  time: 0.2150  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 960/1627]  eta: 0:02:22  Loss: 2.4233 (2.4505)  Acc@1: 81.2500 (81.5687)  Acc@5: 100.0000 (96.5075)  time: 0.2156  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 970/1627]  eta: 0:02:20  Loss: 2.4639 (2.4507)  Acc@1: 81.2500 (81.5783)  Acc@5: 100.0000 (96.5049)  time: 0.2150  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 980/1627]  eta: 0:02:18  Loss: 2.3924 (2.4504)  Acc@1: 87.5000 (81.5877)  Acc@5: 93.7500 (96.4959)  time: 0.2155  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 990/1627]  eta: 0:02:16  Loss: 2.4888 (2.4518)  Acc@1: 81.2500 (81.5464)  Acc@5: 93.7500 (96.4682)  time: 0.2157  data: 0.0004  max mem: 2500
Test: [Task 1]  [1000/1627]  eta: 0:02:14  Loss: 2.5366 (2.4520)  Acc@1: 81.2500 (81.5247)  Acc@5: 93.7500 (96.4723)  time: 0.2151  data: 0.0004  max mem: 2500
Test: [Task 1]  [1010/1627]  eta: 0:02:12  Loss: 2.3760 (2.4519)  Acc@1: 81.2500 (81.5467)  Acc@5: 93.7500 (96.4639)  time: 0.2147  data: 0.0003  max mem: 2500
Test: [Task 1]  [1020/1627]  eta: 0:02:10  Loss: 2.4068 (2.4519)  Acc@1: 81.2500 (81.5500)  Acc@5: 100.0000 (96.4863)  time: 0.2146  data: 0.0003  max mem: 2500
Test: [Task 1]  [1030/1627]  eta: 0:02:07  Loss: 2.3885 (2.4514)  Acc@1: 81.2500 (81.5713)  Acc@5: 100.0000 (96.4901)  time: 0.2160  data: 0.0004  max mem: 2500
Test: [Task 1]  [1040/1627]  eta: 0:02:05  Loss: 2.3775 (2.4507)  Acc@1: 81.2500 (81.5802)  Acc@5: 100.0000 (96.4998)  time: 0.2158  data: 0.0004  max mem: 2500
Test: [Task 1]  [1050/1627]  eta: 0:02:03  Loss: 2.4279 (2.4502)  Acc@1: 81.2500 (81.6009)  Acc@5: 100.0000 (96.5212)  time: 0.2144  data: 0.0003  max mem: 2500
Test: [Task 1]  [1060/1627]  eta: 0:02:01  Loss: 2.4648 (2.4507)  Acc@1: 81.2500 (81.5681)  Acc@5: 100.0000 (96.5068)  time: 0.2146  data: 0.0003  max mem: 2500
Test: [Task 1]  [1070/1627]  eta: 0:01:59  Loss: 2.4657 (2.4506)  Acc@1: 81.2500 (81.5768)  Acc@5: 93.7500 (96.4986)  time: 0.2146  data: 0.0003  max mem: 2500
Test: [Task 1]  [1080/1627]  eta: 0:01:57  Loss: 2.3901 (2.4507)  Acc@1: 81.2500 (81.5738)  Acc@5: 100.0000 (96.4963)  time: 0.2146  data: 0.0004  max mem: 2500
Test: [Task 1]  [1090/1627]  eta: 0:01:55  Loss: 2.4094 (2.4510)  Acc@1: 81.2500 (81.5536)  Acc@5: 100.0000 (96.4940)  time: 0.2147  data: 0.0004  max mem: 2500
Test: [Task 1]  [1100/1627]  eta: 0:01:52  Loss: 2.3871 (2.4503)  Acc@1: 81.2500 (81.6076)  Acc@5: 100.0000 (96.5145)  time: 0.2147  data: 0.0003  max mem: 2500
Test: [Task 1]  [1110/1627]  eta: 0:01:50  Loss: 2.3987 (2.4501)  Acc@1: 81.2500 (81.5932)  Acc@5: 100.0000 (96.5347)  time: 0.2146  data: 0.0003  max mem: 2500
Test: [Task 1]  [1120/1627]  eta: 0:01:48  Loss: 2.4701 (2.4507)  Acc@1: 75.0000 (81.5566)  Acc@5: 100.0000 (96.5210)  time: 0.2144  data: 0.0003  max mem: 2500
Test: [Task 1]  [1130/1627]  eta: 0:01:46  Loss: 2.4593 (2.4510)  Acc@1: 75.0000 (81.5429)  Acc@5: 100.0000 (96.5241)  time: 0.2144  data: 0.0003  max mem: 2500
Test: [Task 1]  [1140/1627]  eta: 0:01:44  Loss: 2.4593 (2.4515)  Acc@1: 81.2500 (81.5239)  Acc@5: 100.0000 (96.5217)  time: 0.2146  data: 0.0003  max mem: 2500
Test: [Task 1]  [1150/1627]  eta: 0:01:42  Loss: 2.4871 (2.4516)  Acc@1: 81.2500 (81.5324)  Acc@5: 100.0000 (96.5030)  time: 0.2146  data: 0.0003  max mem: 2500
Test: [Task 1]  [1160/1627]  eta: 0:01:40  Loss: 2.4128 (2.4514)  Acc@1: 81.2500 (81.5676)  Acc@5: 100.0000 (96.5062)  time: 0.2145  data: 0.0003  max mem: 2500
Test: [Task 1]  [1170/1627]  eta: 0:01:37  Loss: 2.3861 (2.4514)  Acc@1: 81.2500 (81.5756)  Acc@5: 100.0000 (96.5201)  time: 0.2140  data: 0.0003  max mem: 2500
Test: [Task 1]  [1180/1627]  eta: 0:01:35  Loss: 2.4596 (2.4516)  Acc@1: 81.2500 (81.5622)  Acc@5: 100.0000 (96.5284)  time: 0.2139  data: 0.0003  max mem: 2500
Test: [Task 1]  [1190/1627]  eta: 0:01:33  Loss: 2.4807 (2.4518)  Acc@1: 81.2500 (81.5491)  Acc@5: 100.0000 (96.5418)  time: 0.2140  data: 0.0002  max mem: 2500
Test: [Task 1]  [1200/1627]  eta: 0:01:31  Loss: 2.4755 (2.4516)  Acc@1: 81.2500 (81.5570)  Acc@5: 100.0000 (96.5341)  time: 0.2140  data: 0.0003  max mem: 2500
Test: [Task 1]  [1210/1627]  eta: 0:01:29  Loss: 2.4574 (2.4526)  Acc@1: 81.2500 (81.5184)  Acc@5: 93.7500 (96.5060)  time: 0.2140  data: 0.0003  max mem: 2500
Test: [Task 1]  [1220/1627]  eta: 0:01:27  Loss: 2.4799 (2.4525)  Acc@1: 81.2500 (81.5162)  Acc@5: 93.7500 (96.5090)  time: 0.2135  data: 0.0003  max mem: 2500
Test: [Task 1]  [1230/1627]  eta: 0:01:25  Loss: 2.4799 (2.4530)  Acc@1: 81.2500 (81.4734)  Acc@5: 93.7500 (96.5018)  time: 0.2134  data: 0.0002  max mem: 2500
Test: [Task 1]  [1240/1627]  eta: 0:01:22  Loss: 2.4493 (2.4530)  Acc@1: 81.2500 (81.4565)  Acc@5: 100.0000 (96.5099)  time: 0.2133  data: 0.0002  max mem: 2500
Test: [Task 1]  [1250/1627]  eta: 0:01:20  Loss: 2.4493 (2.4532)  Acc@1: 81.2500 (81.4648)  Acc@5: 100.0000 (96.4978)  time: 0.2132  data: 0.0002  max mem: 2500
Test: [Task 1]  [1260/1627]  eta: 0:01:18  Loss: 2.4314 (2.4532)  Acc@1: 87.5000 (81.4681)  Acc@5: 93.7500 (96.4958)  time: 0.2135  data: 0.0002  max mem: 2500
Test: [Task 1]  [1270/1627]  eta: 0:01:16  Loss: 2.4309 (2.4533)  Acc@1: 81.2500 (81.4319)  Acc@5: 100.0000 (96.5136)  time: 0.2142  data: 0.0003  max mem: 2500
Test: [Task 1]  [1280/1627]  eta: 0:01:14  Loss: 2.4309 (2.4529)  Acc@1: 81.2500 (81.4305)  Acc@5: 100.0000 (96.5115)  time: 0.2146  data: 0.0003  max mem: 2500
Test: [Task 1]  [1290/1627]  eta: 0:01:12  Loss: 2.4429 (2.4533)  Acc@1: 81.2500 (81.4194)  Acc@5: 100.0000 (96.5046)  time: 0.2148  data: 0.0004  max mem: 2500
Test: [Task 1]  [1300/1627]  eta: 0:01:10  Loss: 2.4429 (2.4527)  Acc@1: 81.2500 (81.4614)  Acc@5: 93.7500 (96.5075)  time: 0.2148  data: 0.0004  max mem: 2500
Test: [Task 1]  [1310/1627]  eta: 0:01:07  Loss: 2.3444 (2.4522)  Acc@1: 81.2500 (81.4788)  Acc@5: 93.7500 (96.5008)  time: 0.2142  data: 0.0004  max mem: 2500
Test: [Task 1]  [1320/1627]  eta: 0:01:05  Loss: 2.3723 (2.4515)  Acc@1: 81.2500 (81.5102)  Acc@5: 100.0000 (96.5225)  time: 0.2145  data: 0.0004  max mem: 2500
Test: [Task 1]  [1330/1627]  eta: 0:01:03  Loss: 2.4241 (2.4517)  Acc@1: 81.2500 (81.4942)  Acc@5: 100.0000 (96.5111)  time: 0.2151  data: 0.0004  max mem: 2500
Test: [Task 1]  [1340/1627]  eta: 0:01:01  Loss: 2.4641 (2.4520)  Acc@1: 81.2500 (81.4597)  Acc@5: 93.7500 (96.5045)  time: 0.2144  data: 0.0004  max mem: 2500
Test: [Task 1]  [1350/1627]  eta: 0:00:59  Loss: 2.4423 (2.4520)  Acc@1: 81.2500 (81.4906)  Acc@5: 100.0000 (96.5165)  time: 0.2153  data: 0.0003  max mem: 2500
Test: [Task 1]  [1360/1627]  eta: 0:00:57  Loss: 2.4102 (2.4519)  Acc@1: 87.5000 (81.5072)  Acc@5: 100.0000 (96.5145)  time: 0.2154  data: 0.0003  max mem: 2500
Test: [Task 1]  [1370/1627]  eta: 0:00:55  Loss: 2.3771 (2.4516)  Acc@1: 87.5000 (81.5235)  Acc@5: 93.7500 (96.5126)  time: 0.2141  data: 0.0003  max mem: 2500
Test: [Task 1]  [1380/1627]  eta: 0:00:52  Loss: 2.3771 (2.4513)  Acc@1: 87.5000 (81.5306)  Acc@5: 100.0000 (96.5197)  time: 0.2142  data: 0.0003  max mem: 2500
Test: [Task 1]  [1390/1627]  eta: 0:00:50  Loss: 2.4175 (2.4514)  Acc@1: 81.2500 (81.5196)  Acc@5: 100.0000 (96.5088)  time: 0.2142  data: 0.0003  max mem: 2500
Test: [Task 1]  [1400/1627]  eta: 0:00:48  Loss: 2.4182 (2.4516)  Acc@1: 81.2500 (81.4909)  Acc@5: 93.7500 (96.5025)  time: 0.2142  data: 0.0003  max mem: 2500
Test: [Task 1]  [1410/1627]  eta: 0:00:46  Loss: 2.3744 (2.4513)  Acc@1: 81.2500 (81.4715)  Acc@5: 100.0000 (96.5184)  time: 0.2140  data: 0.0003  max mem: 2500
Test: [Task 1]  [1420/1627]  eta: 0:00:44  Loss: 2.4154 (2.4510)  Acc@1: 81.2500 (81.4919)  Acc@5: 100.0000 (96.5209)  time: 0.2139  data: 0.0002  max mem: 2500
Test: [Task 1]  [1430/1627]  eta: 0:00:42  Loss: 2.5056 (2.4519)  Acc@1: 75.0000 (81.4378)  Acc@5: 93.7500 (96.4928)  time: 0.2140  data: 0.0002  max mem: 2500
Test: [Task 1]  [1440/1627]  eta: 0:00:40  Loss: 2.5056 (2.4520)  Acc@1: 75.0000 (81.4148)  Acc@5: 93.7500 (96.4781)  time: 0.2141  data: 0.0002  max mem: 2500
Test: [Task 1]  [1450/1627]  eta: 0:00:37  Loss: 2.5122 (2.4525)  Acc@1: 81.2500 (81.3921)  Acc@5: 100.0000 (96.4809)  time: 0.2138  data: 0.0002  max mem: 2500
Test: [Task 1]  [1460/1627]  eta: 0:00:35  Loss: 2.5119 (2.4525)  Acc@1: 81.2500 (81.3698)  Acc@5: 100.0000 (96.4793)  time: 0.2137  data: 0.0002  max mem: 2500
Test: [Task 1]  [1470/1627]  eta: 0:00:33  Loss: 2.3918 (2.4527)  Acc@1: 81.2500 (81.3605)  Acc@5: 100.0000 (96.4820)  time: 0.2136  data: 0.0002  max mem: 2500
Test: [Task 1]  [1480/1627]  eta: 0:00:31  Loss: 2.3694 (2.4526)  Acc@1: 81.2500 (81.3724)  Acc@5: 100.0000 (96.4889)  time: 0.2137  data: 0.0002  max mem: 2500
Test: [Task 1]  [1490/1627]  eta: 0:00:29  Loss: 2.4132 (2.4529)  Acc@1: 81.2500 (81.3716)  Acc@5: 100.0000 (96.4831)  time: 0.2137  data: 0.0002  max mem: 2500
Test: [Task 1]  [1500/1627]  eta: 0:00:27  Loss: 2.4453 (2.4532)  Acc@1: 81.2500 (81.3666)  Acc@5: 93.7500 (96.4690)  time: 0.2138  data: 0.0002  max mem: 2500
Test: [Task 1]  [1510/1627]  eta: 0:00:25  Loss: 2.4303 (2.4530)  Acc@1: 81.2500 (81.3906)  Acc@5: 93.7500 (96.4593)  time: 0.2145  data: 0.0003  max mem: 2500
Test: [Task 1]  [1520/1627]  eta: 0:00:22  Loss: 2.3964 (2.4525)  Acc@1: 81.2500 (81.4061)  Acc@5: 100.0000 (96.4620)  time: 0.2145  data: 0.0003  max mem: 2500
Test: [Task 1]  [1530/1627]  eta: 0:00:20  Loss: 2.3763 (2.4522)  Acc@1: 87.5000 (81.4337)  Acc@5: 100.0000 (96.4688)  time: 0.2150  data: 0.0004  max mem: 2500
Test: [Task 1]  [1540/1627]  eta: 0:00:18  Loss: 2.3489 (2.4519)  Acc@1: 93.7500 (81.4650)  Acc@5: 100.0000 (96.4836)  time: 0.2151  data: 0.0004  max mem: 2500
Test: [Task 1]  [1550/1627]  eta: 0:00:16  Loss: 2.4004 (2.4519)  Acc@1: 87.5000 (81.4676)  Acc@5: 100.0000 (96.4821)  time: 0.2148  data: 0.0003  max mem: 2500
Test: [Task 1]  [1560/1627]  eta: 0:00:14  Loss: 2.4103 (2.4514)  Acc@1: 81.2500 (81.4862)  Acc@5: 100.0000 (96.4846)  time: 0.2153  data: 0.0004  max mem: 2500
Test: [Task 1]  [1570/1627]  eta: 0:00:12  Loss: 2.4103 (2.4516)  Acc@1: 81.2500 (81.4927)  Acc@5: 100.0000 (96.4911)  time: 0.2148  data: 0.0003  max mem: 2500
Test: [Task 1]  [1580/1627]  eta: 0:00:10  Loss: 2.4116 (2.4513)  Acc@1: 81.2500 (81.4753)  Acc@5: 100.0000 (96.4896)  time: 0.2143  data: 0.0003  max mem: 2500
Test: [Task 1]  [1590/1627]  eta: 0:00:07  Loss: 2.4256 (2.4514)  Acc@1: 75.0000 (81.4661)  Acc@5: 100.0000 (96.4959)  time: 0.2144  data: 0.0003  max mem: 2500
Test: [Task 1]  [1600/1627]  eta: 0:00:05  Loss: 2.4609 (2.4521)  Acc@1: 75.0000 (81.4374)  Acc@5: 93.7500 (96.4788)  time: 0.2145  data: 0.0003  max mem: 2500
Test: [Task 1]  [1610/1627]  eta: 0:00:03  Loss: 2.4488 (2.4517)  Acc@1: 81.2500 (81.4711)  Acc@5: 100.0000 (96.4929)  time: 0.2145  data: 0.0003  max mem: 2500
Test: [Task 1]  [1620/1627]  eta: 0:00:01  Loss: 2.4235 (2.4516)  Acc@1: 87.5000 (81.4852)  Acc@5: 100.0000 (96.4914)  time: 0.2146  data: 0.0002  max mem: 2500
Test: [Task 1]  [1626/1627]  eta: 0:00:00  Loss: 2.4235 (2.4513)  Acc@1: 87.5000 (81.4959)  Acc@5: 100.0000 (96.4966)  time: 0.2144  data: 0.0002  max mem: 2500
Test: [Task 1] Total time: 0:05:48 (0.2144 s / it)
* Acc@1 81.496 Acc@5 96.497 loss 2.451
{0: {0: 26032, 1: 26032, 2: 26032, 3: 26032, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0, 10: 0, 11: 0, 12: 0, 13: 0, 14: 0, 15: 0, 16: 0, 17: 0, 18: 0, 19: 0}}
[Average accuracy till task1]	Acc@1: 81.4959	Acc@5: 96.4966	Loss: 2.4513
Train: Epoch[1/5]  [   0/3750]  eta: 0:39:12  Lr: 0.030000  Loss: 2.3074  Acc@1: 18.7500 (18.7500)  Acc@5: 56.2500 (56.2500)  time: 0.6274  data: 0.2722  max mem: 2500
Train: Epoch[1/5]  [  10/3750]  eta: 0:23:01  Lr: 0.030000  Loss: 1.7756  Acc@1: 12.5000 (13.6364)  Acc@5: 56.2500 (50.5682)  time: 0.3694  data: 0.0250  max mem: 2500
Train: Epoch[1/5]  [  20/3750]  eta: 0:22:11  Lr: 0.030000  Loss: 1.3751  Acc@1: 12.5000 (12.7976)  Acc@5: 50.0000 (50.5952)  time: 0.3435  data: 0.0002  max mem: 2500
Train: Epoch[1/5]  [  30/3750]  eta: 0:21:53  Lr: 0.030000  Loss: 1.1418  Acc@1: 12.5000 (13.3065)  Acc@5: 50.0000 (51.8145)  time: 0.3440  data: 0.0002  max mem: 2500
Train: Epoch[1/5]  [  40/3750]  eta: 0:21:42  Lr: 0.030000  Loss: 0.9605  Acc@1: 12.5000 (12.6524)  Acc@5: 50.0000 (51.2195)  time: 0.3447  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [  50/3750]  eta: 0:21:38  Lr: 0.030000  Loss: 0.8864  Acc@1: 6.2500 (11.8873)  Acc@5: 50.0000 (51.8382)  time: 0.3477  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [  60/3750]  eta: 0:21:31  Lr: 0.030000  Loss: 0.7740  Acc@1: 12.5000 (12.1926)  Acc@5: 50.0000 (52.0492)  time: 0.3477  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [  70/3750]  eta: 0:21:25  Lr: 0.030000  Loss: 0.8509  Acc@1: 12.5000 (12.0599)  Acc@5: 56.2500 (52.6408)  time: 0.3449  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [  80/3750]  eta: 0:21:20  Lr: 0.030000  Loss: 0.7596  Acc@1: 12.5000 (12.3457)  Acc@5: 56.2500 (53.9352)  time: 0.3453  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [  90/3750]  eta: 0:21:15  Lr: 0.030000  Loss: 0.7611  Acc@1: 18.7500 (12.7060)  Acc@5: 56.2500 (54.6016)  time: 0.3454  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [ 100/3750]  eta: 0:21:10  Lr: 0.030000  Loss: 0.8217  Acc@1: 12.5000 (12.6856)  Acc@5: 56.2500 (55.1980)  time: 0.3454  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [ 110/3750]  eta: 0:21:06  Lr: 0.030000  Loss: 0.7053  Acc@1: 12.5000 (13.3446)  Acc@5: 62.5000 (56.1937)  time: 0.3461  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [ 120/3750]  eta: 0:21:02  Lr: 0.030000  Loss: 0.7859  Acc@1: 18.7500 (13.6364)  Acc@5: 68.7500 (57.2831)  time: 0.3456  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [ 130/3750]  eta: 0:20:57  Lr: 0.030000  Loss: 0.7545  Acc@1: 18.7500 (14.3607)  Acc@5: 68.7500 (58.0630)  time: 0.3443  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [ 140/3750]  eta: 0:20:53  Lr: 0.030000  Loss: 0.7494  Acc@1: 25.0000 (15.1152)  Acc@5: 68.7500 (58.8652)  time: 0.3443  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [ 150/3750]  eta: 0:20:49  Lr: 0.030000  Loss: 0.7537  Acc@1: 25.0000 (15.7285)  Acc@5: 62.5000 (59.1474)  time: 0.3442  data: 0.0002  max mem: 2500
Train: Epoch[1/5]  [ 160/3750]  eta: 0:20:45  Lr: 0.030000  Loss: 0.7312  Acc@1: 25.0000 (16.4208)  Acc@5: 68.7500 (59.9767)  time: 0.3443  data: 0.0002  max mem: 2500
Train: Epoch[1/5]  [ 170/3750]  eta: 0:20:41  Lr: 0.030000  Loss: 0.7315  Acc@1: 18.7500 (16.6301)  Acc@5: 68.7500 (60.3436)  time: 0.3450  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [ 180/3750]  eta: 0:20:37  Lr: 0.030000  Loss: 0.7831  Acc@1: 18.7500 (16.9199)  Acc@5: 68.7500 (60.9461)  time: 0.3451  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [ 190/3750]  eta: 0:20:33  Lr: 0.030000  Loss: 0.8179  Acc@1: 25.0000 (17.5720)  Acc@5: 68.7500 (61.4529)  time: 0.3446  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [ 200/3750]  eta: 0:20:29  Lr: 0.030000  Loss: 0.7683  Acc@1: 31.2500 (18.3458)  Acc@5: 68.7500 (62.0647)  time: 0.3445  data: 0.0002  max mem: 2500
Train: Epoch[1/5]  [ 210/3750]  eta: 0:20:26  Lr: 0.030000  Loss: 0.7714  Acc@1: 31.2500 (18.9277)  Acc@5: 75.0000 (62.6185)  time: 0.3464  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [ 220/3750]  eta: 0:20:23  Lr: 0.030000  Loss: 0.7437  Acc@1: 31.2500 (19.4853)  Acc@5: 75.0000 (63.4050)  time: 0.3481  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [ 230/3750]  eta: 0:20:20  Lr: 0.030000  Loss: 0.7006  Acc@1: 37.5000 (20.1299)  Acc@5: 75.0000 (63.9069)  time: 0.3475  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 240/3750]  eta: 0:20:16  Lr: 0.030000  Loss: 0.7959  Acc@1: 31.2500 (20.8247)  Acc@5: 75.0000 (64.4450)  time: 0.3471  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [ 250/3750]  eta: 0:20:13  Lr: 0.030000  Loss: 0.6947  Acc@1: 31.2500 (21.4890)  Acc@5: 81.2500 (65.0896)  time: 0.3469  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [ 260/3750]  eta: 0:20:09  Lr: 0.030000  Loss: 0.6809  Acc@1: 37.5000 (22.1025)  Acc@5: 81.2500 (65.7328)  time: 0.3457  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 270/3750]  eta: 0:20:06  Lr: 0.030000  Loss: 0.7067  Acc@1: 37.5000 (22.5784)  Acc@5: 81.2500 (66.1439)  time: 0.3466  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 280/3750]  eta: 0:20:02  Lr: 0.030000  Loss: 0.7040  Acc@1: 31.2500 (22.7313)  Acc@5: 75.0000 (66.4591)  time: 0.3472  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 290/3750]  eta: 0:19:59  Lr: 0.030000  Loss: 0.6854  Acc@1: 37.5000 (23.3033)  Acc@5: 81.2500 (66.9888)  time: 0.3459  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 300/3750]  eta: 0:19:55  Lr: 0.030000  Loss: 0.6522  Acc@1: 37.5000 (23.8372)  Acc@5: 81.2500 (67.6287)  time: 0.3451  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 310/3750]  eta: 0:19:51  Lr: 0.030000  Loss: 0.5989  Acc@1: 37.5000 (24.4976)  Acc@5: 81.2500 (68.1471)  time: 0.3453  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [ 320/3750]  eta: 0:19:48  Lr: 0.030000  Loss: 0.6279  Acc@1: 43.7500 (25.1363)  Acc@5: 81.2500 (68.4774)  time: 0.3463  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [ 330/3750]  eta: 0:19:44  Lr: 0.030000  Loss: 0.6897  Acc@1: 37.5000 (25.4154)  Acc@5: 81.2500 (68.9388)  time: 0.3460  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 340/3750]  eta: 0:19:41  Lr: 0.030000  Loss: 0.6304  Acc@1: 31.2500 (25.5682)  Acc@5: 81.2500 (69.2265)  time: 0.3459  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 350/3750]  eta: 0:19:37  Lr: 0.030000  Loss: 0.7434  Acc@1: 31.2500 (25.7657)  Acc@5: 81.2500 (69.4979)  time: 0.3452  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 360/3750]  eta: 0:19:34  Lr: 0.030000  Loss: 0.6950  Acc@1: 31.2500 (26.1253)  Acc@5: 81.2500 (69.9446)  time: 0.3447  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [ 370/3750]  eta: 0:19:30  Lr: 0.030000  Loss: 0.6999  Acc@1: 43.7500 (26.6846)  Acc@5: 87.5000 (70.3841)  time: 0.3453  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 380/3750]  eta: 0:19:27  Lr: 0.030000  Loss: 0.6786  Acc@1: 43.7500 (27.1490)  Acc@5: 87.5000 (70.8005)  time: 0.3457  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 390/3750]  eta: 0:19:23  Lr: 0.030000  Loss: 0.4813  Acc@1: 43.7500 (27.6375)  Acc@5: 81.2500 (71.1957)  time: 0.3453  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [ 400/3750]  eta: 0:19:19  Lr: 0.030000  Loss: 0.6215  Acc@1: 43.7500 (27.9925)  Acc@5: 81.2500 (71.4776)  time: 0.3449  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [ 410/3750]  eta: 0:19:16  Lr: 0.030000  Loss: 0.6201  Acc@1: 31.2500 (28.2847)  Acc@5: 81.2500 (71.8218)  time: 0.3450  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [ 420/3750]  eta: 0:19:12  Lr: 0.030000  Loss: 0.6701  Acc@1: 37.5000 (28.6817)  Acc@5: 87.5000 (72.1051)  time: 0.3457  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [ 430/3750]  eta: 0:19:09  Lr: 0.030000  Loss: 0.5958  Acc@1: 43.7500 (28.9443)  Acc@5: 81.2500 (72.2738)  time: 0.3452  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [ 440/3750]  eta: 0:19:05  Lr: 0.030000  Loss: 0.6049  Acc@1: 43.7500 (29.2092)  Acc@5: 87.5000 (72.6049)  time: 0.3441  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [ 450/3750]  eta: 0:19:02  Lr: 0.030000  Loss: 0.5836  Acc@1: 37.5000 (29.4207)  Acc@5: 87.5000 (72.9074)  time: 0.3454  data: 0.0009  max mem: 2500
Train: Epoch[1/5]  [ 460/3750]  eta: 0:18:58  Lr: 0.030000  Loss: 0.5908  Acc@1: 37.5000 (29.7044)  Acc@5: 87.5000 (73.3053)  time: 0.3450  data: 0.0009  max mem: 2500
Train: Epoch[1/5]  [ 470/3750]  eta: 0:18:54  Lr: 0.030000  Loss: 0.6808  Acc@1: 50.0000 (30.1221)  Acc@5: 87.5000 (73.5005)  time: 0.3431  data: 0.0002  max mem: 2500
Train: Epoch[1/5]  [ 480/3750]  eta: 0:18:51  Lr: 0.030000  Loss: 0.6275  Acc@1: 50.0000 (30.4704)  Acc@5: 87.5000 (73.8436)  time: 0.3427  data: 0.0002  max mem: 2500
Train: Epoch[1/5]  [ 490/3750]  eta: 0:18:47  Lr: 0.030000  Loss: 0.6249  Acc@1: 50.0000 (30.8936)  Acc@5: 87.5000 (74.1217)  time: 0.3432  data: 0.0002  max mem: 2500
Train: Epoch[1/5]  [ 500/3750]  eta: 0:18:44  Lr: 0.030000  Loss: 0.5241  Acc@1: 50.0000 (31.1627)  Acc@5: 87.5000 (74.4261)  time: 0.3444  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [ 510/3750]  eta: 0:18:40  Lr: 0.030000  Loss: 0.5467  Acc@1: 43.7500 (31.4457)  Acc@5: 87.5000 (74.7676)  time: 0.3444  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [ 520/3750]  eta: 0:18:36  Lr: 0.030000  Loss: 0.5151  Acc@1: 43.7500 (31.8498)  Acc@5: 93.7500 (75.0720)  time: 0.3443  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 530/3750]  eta: 0:18:33  Lr: 0.030000  Loss: 0.5499  Acc@1: 50.0000 (32.1328)  Acc@5: 93.7500 (75.4355)  time: 0.3446  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [ 540/3750]  eta: 0:18:30  Lr: 0.030000  Loss: 0.6741  Acc@1: 50.0000 (32.5670)  Acc@5: 93.7500 (75.6932)  time: 0.3466  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 550/3750]  eta: 0:18:26  Lr: 0.030000  Loss: 0.5306  Acc@1: 43.7500 (32.7926)  Acc@5: 87.5000 (75.8848)  time: 0.3464  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 560/3750]  eta: 0:18:23  Lr: 0.030000  Loss: 0.4676  Acc@1: 50.0000 (33.1439)  Acc@5: 93.7500 (76.2032)  time: 0.3443  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [ 570/3750]  eta: 0:18:19  Lr: 0.030000  Loss: 0.4275  Acc@1: 56.2500 (33.5048)  Acc@5: 93.7500 (76.4996)  time: 0.3448  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [ 580/3750]  eta: 0:18:16  Lr: 0.030000  Loss: 0.6327  Acc@1: 50.0000 (33.7887)  Acc@5: 87.5000 (76.6889)  time: 0.3445  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [ 590/3750]  eta: 0:18:12  Lr: 0.030000  Loss: 0.6088  Acc@1: 56.2500 (34.1899)  Acc@5: 87.5000 (76.8401)  time: 0.3447  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [ 600/3750]  eta: 0:18:08  Lr: 0.030000  Loss: 0.5107  Acc@1: 50.0000 (34.4010)  Acc@5: 87.5000 (77.0487)  time: 0.3441  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [ 610/3750]  eta: 0:18:05  Lr: 0.030000  Loss: 0.6042  Acc@1: 50.0000 (34.6563)  Acc@5: 87.5000 (77.1788)  time: 0.3431  data: 0.0002  max mem: 2500
Train: Epoch[1/5]  [ 620/3750]  eta: 0:18:01  Lr: 0.030000  Loss: 0.4643  Acc@1: 50.0000 (34.9134)  Acc@5: 87.5000 (77.3551)  time: 0.3431  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [ 630/3750]  eta: 0:17:58  Lr: 0.030000  Loss: 0.5457  Acc@1: 50.0000 (35.2318)  Acc@5: 87.5000 (77.5753)  time: 0.3429  data: 0.0002  max mem: 2500
Train: Epoch[1/5]  [ 640/3750]  eta: 0:17:54  Lr: 0.030000  Loss: 0.5634  Acc@1: 50.0000 (35.5109)  Acc@5: 87.5000 (77.6619)  time: 0.3429  data: 0.0002  max mem: 2500
Train: Epoch[1/5]  [ 650/3750]  eta: 0:17:51  Lr: 0.030000  Loss: 0.4495  Acc@1: 50.0000 (35.7527)  Acc@5: 87.5000 (77.8226)  time: 0.3431  data: 0.0002  max mem: 2500
Train: Epoch[1/5]  [ 660/3750]  eta: 0:17:47  Lr: 0.030000  Loss: 0.4973  Acc@1: 50.0000 (36.1101)  Acc@5: 87.5000 (78.0163)  time: 0.3434  data: 0.0002  max mem: 2500
Train: Epoch[1/5]  [ 670/3750]  eta: 0:17:43  Lr: 0.030000  Loss: 0.4625  Acc@1: 50.0000 (36.3264)  Acc@5: 87.5000 (78.1762)  time: 0.3442  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [ 680/3750]  eta: 0:17:40  Lr: 0.030000  Loss: 0.4734  Acc@1: 50.0000 (36.5547)  Acc@5: 87.5000 (78.3590)  time: 0.3450  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 690/3750]  eta: 0:17:37  Lr: 0.030000  Loss: 0.5520  Acc@1: 50.0000 (36.8397)  Acc@5: 93.7500 (78.5185)  time: 0.3457  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 700/3750]  eta: 0:17:33  Lr: 0.030000  Loss: 0.3497  Acc@1: 56.2500 (37.1255)  Acc@5: 93.7500 (78.7001)  time: 0.3461  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 710/3750]  eta: 0:17:30  Lr: 0.030000  Loss: 0.4205  Acc@1: 56.2500 (37.4560)  Acc@5: 93.7500 (78.9030)  time: 0.3459  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 720/3750]  eta: 0:17:26  Lr: 0.030000  Loss: 0.5310  Acc@1: 56.2500 (37.7167)  Acc@5: 93.7500 (79.0655)  time: 0.3457  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 730/3750]  eta: 0:17:23  Lr: 0.030000  Loss: 0.4164  Acc@1: 56.2500 (37.9873)  Acc@5: 93.7500 (79.2493)  time: 0.3461  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 740/3750]  eta: 0:17:19  Lr: 0.030000  Loss: 0.3548  Acc@1: 56.2500 (38.2254)  Acc@5: 93.7500 (79.4281)  time: 0.3466  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 750/3750]  eta: 0:17:16  Lr: 0.030000  Loss: 0.3524  Acc@1: 56.2500 (38.4321)  Acc@5: 87.5000 (79.5356)  time: 0.3459  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 760/3750]  eta: 0:17:13  Lr: 0.030000  Loss: 0.2755  Acc@1: 50.0000 (38.6580)  Acc@5: 87.5000 (79.6321)  time: 0.3455  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [ 770/3750]  eta: 0:17:09  Lr: 0.030000  Loss: 0.4241  Acc@1: 56.2500 (38.8943)  Acc@5: 87.5000 (79.7827)  time: 0.3453  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [ 780/3750]  eta: 0:17:06  Lr: 0.030000  Loss: 0.4601  Acc@1: 56.2500 (39.0925)  Acc@5: 93.7500 (79.9456)  time: 0.3456  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [ 790/3750]  eta: 0:17:02  Lr: 0.030000  Loss: 0.4173  Acc@1: 56.2500 (39.3568)  Acc@5: 93.7500 (80.0727)  time: 0.3455  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [ 800/3750]  eta: 0:16:59  Lr: 0.030000  Loss: 0.1945  Acc@1: 62.5000 (39.6067)  Acc@5: 93.7500 (80.2278)  time: 0.3453  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [ 810/3750]  eta: 0:16:55  Lr: 0.030000  Loss: 0.4379  Acc@1: 62.5000 (39.8505)  Acc@5: 93.7500 (80.3715)  time: 0.3460  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [ 820/3750]  eta: 0:16:52  Lr: 0.030000  Loss: 0.2850  Acc@1: 56.2500 (40.0731)  Acc@5: 93.7500 (80.4963)  time: 0.3450  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [ 830/3750]  eta: 0:16:48  Lr: 0.030000  Loss: 0.2446  Acc@1: 56.2500 (40.2903)  Acc@5: 93.7500 (80.6182)  time: 0.3436  data: 0.0002  max mem: 2500
Train: Epoch[1/5]  [ 840/3750]  eta: 0:16:45  Lr: 0.030000  Loss: 0.5047  Acc@1: 56.2500 (40.4652)  Acc@5: 87.5000 (80.7298)  time: 0.3436  data: 0.0002  max mem: 2500
Train: Epoch[1/5]  [ 850/3750]  eta: 0:16:41  Lr: 0.030000  Loss: 0.3080  Acc@1: 56.2500 (40.6801)  Acc@5: 87.5000 (80.8461)  time: 0.3438  data: 0.0002  max mem: 2500
Train: Epoch[1/5]  [ 860/3750]  eta: 0:16:38  Lr: 0.030000  Loss: 0.4742  Acc@1: 50.0000 (40.8246)  Acc@5: 93.7500 (80.9669)  time: 0.3438  data: 0.0002  max mem: 2500
Train: Epoch[1/5]  [ 870/3750]  eta: 0:16:34  Lr: 0.030000  Loss: 0.4242  Acc@1: 50.0000 (40.9443)  Acc@5: 87.5000 (81.0491)  time: 0.3436  data: 0.0002  max mem: 2500
Train: Epoch[1/5]  [ 880/3750]  eta: 0:16:31  Lr: 0.030000  Loss: 0.3368  Acc@1: 50.0000 (41.1039)  Acc@5: 87.5000 (81.1436)  time: 0.3437  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [ 890/3750]  eta: 0:16:27  Lr: 0.030000  Loss: 0.2907  Acc@1: 62.5000 (41.3580)  Acc@5: 93.7500 (81.2921)  time: 0.3449  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [ 900/3750]  eta: 0:16:24  Lr: 0.030000  Loss: 0.3366  Acc@1: 62.5000 (41.5441)  Acc@5: 93.7500 (81.4234)  time: 0.3477  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [ 910/3750]  eta: 0:16:21  Lr: 0.030000  Loss: 0.2788  Acc@1: 62.5000 (41.7879)  Acc@5: 93.7500 (81.5724)  time: 0.3492  data: 0.0010  max mem: 2500
Train: Epoch[1/5]  [ 920/3750]  eta: 0:16:17  Lr: 0.030000  Loss: 0.5194  Acc@1: 62.5000 (41.9449)  Acc@5: 93.7500 (81.6911)  time: 0.3479  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [ 930/3750]  eta: 0:16:14  Lr: 0.030000  Loss: 0.2766  Acc@1: 62.5000 (42.1791)  Acc@5: 93.7500 (81.8139)  time: 0.3464  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [ 940/3750]  eta: 0:16:10  Lr: 0.030000  Loss: 0.2616  Acc@1: 62.5000 (42.4283)  Acc@5: 93.7500 (81.9009)  time: 0.3470  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [ 950/3750]  eta: 0:16:07  Lr: 0.030000  Loss: 0.4263  Acc@1: 62.5000 (42.5999)  Acc@5: 87.5000 (81.9861)  time: 0.3467  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 960/3750]  eta: 0:16:03  Lr: 0.030000  Loss: 0.4585  Acc@1: 62.5000 (42.8655)  Acc@5: 93.7500 (82.1280)  time: 0.3451  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 970/3750]  eta: 0:16:00  Lr: 0.030000  Loss: 0.4165  Acc@1: 62.5000 (43.0355)  Acc@5: 93.7500 (82.2541)  time: 0.3456  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 980/3750]  eta: 0:15:57  Lr: 0.030000  Loss: 0.3069  Acc@1: 56.2500 (43.2276)  Acc@5: 93.7500 (82.3904)  time: 0.3461  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 990/3750]  eta: 0:15:53  Lr: 0.030000  Loss: 0.1924  Acc@1: 62.5000 (43.4536)  Acc@5: 93.7500 (82.5050)  time: 0.3455  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1000/3750]  eta: 0:15:50  Lr: 0.030000  Loss: 0.2774  Acc@1: 62.5000 (43.6189)  Acc@5: 93.7500 (82.6049)  time: 0.3452  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1010/3750]  eta: 0:15:46  Lr: 0.030000  Loss: 0.2681  Acc@1: 56.2500 (43.6758)  Acc@5: 93.7500 (82.7028)  time: 0.3477  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [1020/3750]  eta: 0:15:43  Lr: 0.030000  Loss: 0.4353  Acc@1: 56.2500 (43.8296)  Acc@5: 93.7500 (82.7926)  time: 0.3477  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1030/3750]  eta: 0:15:39  Lr: 0.030000  Loss: 0.2871  Acc@1: 62.5000 (44.0167)  Acc@5: 93.7500 (82.9231)  time: 0.3450  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [1040/3750]  eta: 0:15:36  Lr: 0.030000  Loss: 0.3168  Acc@1: 68.7500 (44.2063)  Acc@5: 93.7500 (83.0211)  time: 0.3448  data: 0.0002  max mem: 2500
Train: Epoch[1/5]  [1050/3750]  eta: 0:15:32  Lr: 0.030000  Loss: 0.2132  Acc@1: 62.5000 (44.3744)  Acc@5: 93.7500 (83.1173)  time: 0.3452  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [1060/3750]  eta: 0:15:29  Lr: 0.030000  Loss: 0.3834  Acc@1: 62.5000 (44.5393)  Acc@5: 93.7500 (83.1762)  time: 0.3455  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [1070/3750]  eta: 0:15:26  Lr: 0.030000  Loss: 0.1852  Acc@1: 62.5000 (44.6837)  Acc@5: 87.5000 (83.2633)  time: 0.3452  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [1080/3750]  eta: 0:15:22  Lr: 0.030000  Loss: 0.1843  Acc@1: 56.2500 (44.8080)  Acc@5: 93.7500 (83.3545)  time: 0.3453  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [1090/3750]  eta: 0:15:19  Lr: 0.030000  Loss: 0.0414  Acc@1: 62.5000 (45.0160)  Acc@5: 93.7500 (83.4441)  time: 0.3463  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [1100/3750]  eta: 0:15:15  Lr: 0.030000  Loss: 0.2106  Acc@1: 62.5000 (45.1521)  Acc@5: 93.7500 (83.5263)  time: 0.3450  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [1110/3750]  eta: 0:15:12  Lr: 0.030000  Loss: 0.2263  Acc@1: 62.5000 (45.3364)  Acc@5: 93.7500 (83.6184)  time: 0.3429  data: 0.0002  max mem: 2500
Train: Epoch[1/5]  [1120/3750]  eta: 0:15:08  Lr: 0.030000  Loss: 0.3905  Acc@1: 68.7500 (45.5676)  Acc@5: 93.7500 (83.6809)  time: 0.3430  data: 0.0002  max mem: 2500
Train: Epoch[1/5]  [1130/3750]  eta: 0:15:05  Lr: 0.030000  Loss: 0.1967  Acc@1: 68.7500 (45.7725)  Acc@5: 93.7500 (83.7865)  time: 0.3426  data: 0.0002  max mem: 2500
Train: Epoch[1/5]  [1140/3750]  eta: 0:15:01  Lr: 0.030000  Loss: 0.2726  Acc@1: 68.7500 (45.9575)  Acc@5: 93.7500 (83.8848)  time: 0.3423  data: 0.0002  max mem: 2500
Train: Epoch[1/5]  [1150/3750]  eta: 0:14:58  Lr: 0.030000  Loss: 0.4478  Acc@1: 62.5000 (46.0904)  Acc@5: 93.7500 (83.9650)  time: 0.3424  data: 0.0002  max mem: 2500
Train: Epoch[1/5]  [1160/3750]  eta: 0:14:54  Lr: 0.030000  Loss: 0.2922  Acc@1: 62.5000 (46.1886)  Acc@5: 93.7500 (84.0116)  time: 0.3424  data: 0.0002  max mem: 2500
Train: Epoch[1/5]  [1170/3750]  eta: 0:14:50  Lr: 0.030000  Loss: 0.2115  Acc@1: 56.2500 (46.2906)  Acc@5: 93.7500 (84.0734)  time: 0.3424  data: 0.0002  max mem: 2500
Train: Epoch[1/5]  [1180/3750]  eta: 0:14:47  Lr: 0.030000  Loss: 0.2551  Acc@1: 62.5000 (46.4437)  Acc@5: 93.7500 (84.1448)  time: 0.3427  data: 0.0002  max mem: 2500
Train: Epoch[1/5]  [1190/3750]  eta: 0:14:43  Lr: 0.030000  Loss: 0.5111  Acc@1: 68.7500 (46.5995)  Acc@5: 93.7500 (84.2097)  time: 0.3438  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [1200/3750]  eta: 0:14:40  Lr: 0.030000  Loss: 0.3421  Acc@1: 68.7500 (46.7423)  Acc@5: 93.7500 (84.2891)  time: 0.3445  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1210/3750]  eta: 0:14:37  Lr: 0.030000  Loss: 0.1605  Acc@1: 56.2500 (46.8363)  Acc@5: 93.7500 (84.3415)  time: 0.3448  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [1220/3750]  eta: 0:14:33  Lr: 0.030000  Loss: 0.1834  Acc@1: 62.5000 (46.9902)  Acc@5: 93.7500 (84.4236)  time: 0.3457  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1230/3750]  eta: 0:14:30  Lr: 0.030000  Loss: 0.2943  Acc@1: 62.5000 (47.0451)  Acc@5: 93.7500 (84.4588)  time: 0.3455  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1240/3750]  eta: 0:14:26  Lr: 0.030000  Loss: 0.1753  Acc@1: 62.5000 (47.1898)  Acc@5: 93.7500 (84.5236)  time: 0.3451  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1250/3750]  eta: 0:14:23  Lr: 0.030000  Loss: 0.4360  Acc@1: 56.2500 (47.2422)  Acc@5: 93.7500 (84.5973)  time: 0.3451  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [1260/3750]  eta: 0:14:19  Lr: 0.030000  Loss: 0.3027  Acc@1: 56.2500 (47.3434)  Acc@5: 93.7500 (84.6749)  time: 0.3459  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1270/3750]  eta: 0:14:16  Lr: 0.030000  Loss: 0.1947  Acc@1: 56.2500 (47.4725)  Acc@5: 93.7500 (84.7315)  time: 0.3456  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1280/3750]  eta: 0:14:12  Lr: 0.030000  Loss: 0.1907  Acc@1: 62.5000 (47.6386)  Acc@5: 93.7500 (84.8019)  time: 0.3457  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1290/3750]  eta: 0:14:09  Lr: 0.030000  Loss: 0.3254  Acc@1: 68.7500 (47.7488)  Acc@5: 93.7500 (84.8857)  time: 0.3457  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1300/3750]  eta: 0:14:06  Lr: 0.030000  Loss: 0.3896  Acc@1: 68.7500 (47.9007)  Acc@5: 93.7500 (84.9347)  time: 0.3449  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1310/3750]  eta: 0:14:02  Lr: 0.030000  Loss: 0.1348  Acc@1: 68.7500 (48.0215)  Acc@5: 93.7500 (84.9924)  time: 0.3462  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1320/3750]  eta: 0:13:59  Lr: 0.030000  Loss: 0.0837  Acc@1: 68.7500 (48.1785)  Acc@5: 87.5000 (85.0445)  time: 0.3462  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1330/3750]  eta: 0:13:55  Lr: 0.030000  Loss: 0.4036  Acc@1: 62.5000 (48.2767)  Acc@5: 87.5000 (85.0958)  time: 0.3449  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1340/3750]  eta: 0:13:52  Lr: 0.030000  Loss: 0.2271  Acc@1: 62.5000 (48.3594)  Acc@5: 87.5000 (85.1277)  time: 0.3455  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1350/3750]  eta: 0:13:48  Lr: 0.030000  Loss: 0.2591  Acc@1: 56.2500 (48.4502)  Acc@5: 93.7500 (85.2054)  time: 0.3452  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [1360/3750]  eta: 0:13:45  Lr: 0.030000  Loss: 0.1992  Acc@1: 62.5000 (48.5948)  Acc@5: 93.7500 (85.2774)  time: 0.3441  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [1370/3750]  eta: 0:13:41  Lr: 0.030000  Loss: 0.2721  Acc@1: 68.7500 (48.7509)  Acc@5: 93.7500 (85.3437)  time: 0.3445  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [1380/3750]  eta: 0:13:38  Lr: 0.030000  Loss: 0.1160  Acc@1: 62.5000 (48.8731)  Acc@5: 93.7500 (85.4046)  time: 0.3445  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [1390/3750]  eta: 0:13:34  Lr: 0.030000  Loss: 0.2700  Acc@1: 62.5000 (48.9486)  Acc@5: 93.7500 (85.4736)  time: 0.3443  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [1400/3750]  eta: 0:13:31  Lr: 0.030000  Loss: 0.0319  Acc@1: 62.5000 (49.0409)  Acc@5: 93.7500 (85.5148)  time: 0.3441  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [1410/3750]  eta: 0:13:27  Lr: 0.030000  Loss: 0.3027  Acc@1: 62.5000 (49.1495)  Acc@5: 93.7500 (85.5687)  time: 0.3448  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [1420/3750]  eta: 0:13:24  Lr: 0.030000  Loss: 0.3232  Acc@1: 62.5000 (49.2259)  Acc@5: 93.7500 (85.6043)  time: 0.3441  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [1430/3750]  eta: 0:13:20  Lr: 0.030000  Loss: 0.2556  Acc@1: 62.5000 (49.3361)  Acc@5: 93.7500 (85.6656)  time: 0.3426  data: 0.0002  max mem: 2500
Train: Epoch[1/5]  [1440/3750]  eta: 0:13:17  Lr: 0.030000  Loss: 0.2606  Acc@1: 62.5000 (49.3841)  Acc@5: 93.7500 (85.7391)  time: 0.3423  data: 0.0002  max mem: 2500
Train: Epoch[1/5]  [1450/3750]  eta: 0:13:13  Lr: 0.030000  Loss: -0.0112  Acc@1: 62.5000 (49.5305)  Acc@5: 100.0000 (85.8072)  time: 0.3423  data: 0.0002  max mem: 2500
Train: Epoch[1/5]  [1460/3750]  eta: 0:13:10  Lr: 0.030000  Loss: 0.1297  Acc@1: 68.7500 (49.6706)  Acc@5: 100.0000 (85.8787)  time: 0.3423  data: 0.0002  max mem: 2500
Train: Epoch[1/5]  [1470/3750]  eta: 0:13:07  Lr: 0.030000  Loss: 0.1404  Acc@1: 68.7500 (49.7833)  Acc@5: 93.7500 (85.9322)  time: 0.3443  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [1480/3750]  eta: 0:13:03  Lr: 0.030000  Loss: 0.2762  Acc@1: 68.7500 (49.8776)  Acc@5: 93.7500 (85.9681)  time: 0.3456  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1490/3750]  eta: 0:13:00  Lr: 0.030000  Loss: 0.2704  Acc@1: 68.7500 (50.0168)  Acc@5: 93.7500 (86.0371)  time: 0.3445  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1500/3750]  eta: 0:12:56  Lr: 0.030000  Loss: 0.3447  Acc@1: 68.7500 (50.1416)  Acc@5: 93.7500 (86.0926)  time: 0.3452  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1510/3750]  eta: 0:12:53  Lr: 0.030000  Loss: 0.2577  Acc@1: 62.5000 (50.2482)  Acc@5: 93.7500 (86.1226)  time: 0.3449  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [1520/3750]  eta: 0:12:49  Lr: 0.030000  Loss: 0.4424  Acc@1: 62.5000 (50.3534)  Acc@5: 93.7500 (86.1645)  time: 0.3440  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [1530/3750]  eta: 0:12:46  Lr: 0.030000  Loss: 0.3452  Acc@1: 62.5000 (50.4041)  Acc@5: 93.7500 (86.2059)  time: 0.3442  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1540/3750]  eta: 0:12:42  Lr: 0.030000  Loss: 0.0557  Acc@1: 56.2500 (50.4543)  Acc@5: 93.7500 (86.2711)  time: 0.3446  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1550/3750]  eta: 0:12:39  Lr: 0.030000  Loss: 0.1312  Acc@1: 62.5000 (50.5561)  Acc@5: 93.7500 (86.3113)  time: 0.3452  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1560/3750]  eta: 0:12:35  Lr: 0.030000  Loss: 0.0834  Acc@1: 68.7500 (50.6807)  Acc@5: 93.7500 (86.3669)  time: 0.3451  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [1570/3750]  eta: 0:12:32  Lr: 0.030000  Loss: -0.0062  Acc@1: 68.7500 (50.7877)  Acc@5: 93.7500 (86.4219)  time: 0.3443  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [1580/3750]  eta: 0:12:28  Lr: 0.030000  Loss: 0.1442  Acc@1: 68.7500 (50.8618)  Acc@5: 93.7500 (86.4603)  time: 0.3442  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [1590/3750]  eta: 0:12:25  Lr: 0.030000  Loss: 0.0528  Acc@1: 68.7500 (50.9899)  Acc@5: 93.7500 (86.5022)  time: 0.3439  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [1600/3750]  eta: 0:12:22  Lr: 0.030000  Loss: 0.2617  Acc@1: 68.7500 (51.0775)  Acc@5: 93.7500 (86.5475)  time: 0.3438  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [1610/3750]  eta: 0:12:18  Lr: 0.030000  Loss: 0.1799  Acc@1: 68.7500 (51.2065)  Acc@5: 93.7500 (86.6077)  time: 0.3443  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1620/3750]  eta: 0:12:15  Lr: 0.030000  Loss: 0.3491  Acc@1: 62.5000 (51.2724)  Acc@5: 93.7500 (86.6633)  time: 0.3437  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1630/3750]  eta: 0:12:11  Lr: 0.030000  Loss: 0.4072  Acc@1: 62.5000 (51.3680)  Acc@5: 93.7500 (86.7106)  time: 0.3426  data: 0.0002  max mem: 2500
Train: Epoch[1/5]  [1640/3750]  eta: 0:12:08  Lr: 0.030000  Loss: 0.0951  Acc@1: 68.7500 (51.4778)  Acc@5: 93.7500 (86.7535)  time: 0.3426  data: 0.0002  max mem: 2500
Train: Epoch[1/5]  [1650/3750]  eta: 0:12:04  Lr: 0.030000  Loss: 0.1861  Acc@1: 68.7500 (51.5634)  Acc@5: 93.7500 (86.8035)  time: 0.3434  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [1660/3750]  eta: 0:12:01  Lr: 0.030000  Loss: 0.0214  Acc@1: 62.5000 (51.6443)  Acc@5: 93.7500 (86.8377)  time: 0.3447  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1670/3750]  eta: 0:11:57  Lr: 0.030000  Loss: 0.0634  Acc@1: 56.2500 (51.6831)  Acc@5: 93.7500 (86.8642)  time: 0.3452  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1680/3750]  eta: 0:11:54  Lr: 0.030000  Loss: -0.0077  Acc@1: 56.2500 (51.7438)  Acc@5: 93.7500 (86.8977)  time: 0.3460  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1690/3750]  eta: 0:11:50  Lr: 0.030000  Loss: 0.0906  Acc@1: 62.5000 (51.8369)  Acc@5: 93.7500 (86.9493)  time: 0.3464  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1700/3750]  eta: 0:11:47  Lr: 0.030000  Loss: 0.0997  Acc@1: 68.7500 (51.9327)  Acc@5: 93.7500 (86.9966)  time: 0.3451  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [1710/3750]  eta: 0:11:43  Lr: 0.030000  Loss: 0.0429  Acc@1: 68.7500 (52.0492)  Acc@5: 93.7500 (87.0507)  time: 0.3446  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [1720/3750]  eta: 0:11:40  Lr: 0.030000  Loss: 0.0881  Acc@1: 68.7500 (52.1499)  Acc@5: 93.7500 (87.0933)  time: 0.3447  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [1730/3750]  eta: 0:11:37  Lr: 0.030000  Loss: 0.1873  Acc@1: 68.7500 (52.2530)  Acc@5: 93.7500 (87.1245)  time: 0.3448  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [1740/3750]  eta: 0:11:33  Lr: 0.030000  Loss: 0.0548  Acc@1: 68.7500 (52.3657)  Acc@5: 93.7500 (87.1446)  time: 0.3449  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [1750/3750]  eta: 0:11:30  Lr: 0.030000  Loss: 0.1275  Acc@1: 75.0000 (52.4843)  Acc@5: 93.7500 (87.2002)  time: 0.3451  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [1760/3750]  eta: 0:11:26  Lr: 0.030000  Loss: -0.1326  Acc@1: 68.7500 (52.5305)  Acc@5: 93.7500 (87.2267)  time: 0.3465  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [1770/3750]  eta: 0:11:23  Lr: 0.030000  Loss: 0.1137  Acc@1: 62.5000 (52.6080)  Acc@5: 93.7500 (87.2424)  time: 0.3457  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [1780/3750]  eta: 0:11:19  Lr: 0.030000  Loss: -0.0688  Acc@1: 68.7500 (52.6881)  Acc@5: 93.7500 (87.2789)  time: 0.3432  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [1790/3750]  eta: 0:11:16  Lr: 0.030000  Loss: 0.0574  Acc@1: 68.7500 (52.7952)  Acc@5: 100.0000 (87.3395)  time: 0.3432  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [1800/3750]  eta: 0:11:12  Lr: 0.030000  Loss: -0.0853  Acc@1: 75.0000 (52.8873)  Acc@5: 100.0000 (87.3924)  time: 0.3437  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [1810/3750]  eta: 0:11:09  Lr: 0.030000  Loss: -0.0119  Acc@1: 68.7500 (52.9611)  Acc@5: 93.7500 (87.4103)  time: 0.3439  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [1820/3750]  eta: 0:11:05  Lr: 0.030000  Loss: 0.0580  Acc@1: 68.7500 (53.0512)  Acc@5: 93.7500 (87.4451)  time: 0.3441  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [1830/3750]  eta: 0:11:02  Lr: 0.030000  Loss: -0.0879  Acc@1: 68.7500 (53.1335)  Acc@5: 93.7500 (87.4829)  time: 0.3441  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [1840/3750]  eta: 0:10:59  Lr: 0.030000  Loss: 0.0465  Acc@1: 68.7500 (53.2082)  Acc@5: 93.7500 (87.5136)  time: 0.3441  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [1850/3750]  eta: 0:10:55  Lr: 0.030000  Loss: 0.2201  Acc@1: 62.5000 (53.2719)  Acc@5: 93.7500 (87.5506)  time: 0.3443  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [1860/3750]  eta: 0:10:52  Lr: 0.030000  Loss: 0.3194  Acc@1: 62.5000 (53.3013)  Acc@5: 87.5000 (87.5571)  time: 0.3440  data: 0.0002  max mem: 2500
Train: Epoch[1/5]  [1870/3750]  eta: 0:10:48  Lr: 0.030000  Loss: 0.1982  Acc@1: 62.5000 (53.4006)  Acc@5: 87.5000 (87.5935)  time: 0.3462  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [1880/3750]  eta: 0:10:45  Lr: 0.030000  Loss: 0.0291  Acc@1: 62.5000 (53.4755)  Acc@5: 93.7500 (87.6329)  time: 0.3480  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1890/3750]  eta: 0:10:41  Lr: 0.030000  Loss: 0.2852  Acc@1: 62.5000 (53.5233)  Acc@5: 93.7500 (87.6620)  time: 0.3468  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1900/3750]  eta: 0:10:38  Lr: 0.030000  Loss: 0.0080  Acc@1: 68.7500 (53.6395)  Acc@5: 93.7500 (87.7006)  time: 0.3460  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1910/3750]  eta: 0:10:34  Lr: 0.030000  Loss: 0.0437  Acc@1: 68.7500 (53.6761)  Acc@5: 93.7500 (87.7224)  time: 0.3461  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1920/3750]  eta: 0:10:31  Lr: 0.030000  Loss: 0.3497  Acc@1: 62.5000 (53.7285)  Acc@5: 93.7500 (87.7375)  time: 0.3459  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1930/3750]  eta: 0:10:28  Lr: 0.030000  Loss: 0.2193  Acc@1: 62.5000 (53.7642)  Acc@5: 93.7500 (87.7784)  time: 0.3454  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1940/3750]  eta: 0:10:24  Lr: 0.030000  Loss: 0.0697  Acc@1: 62.5000 (53.8157)  Acc@5: 93.7500 (87.8123)  time: 0.3469  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1950/3750]  eta: 0:10:21  Lr: 0.030000  Loss: 0.0590  Acc@1: 68.7500 (53.8922)  Acc@5: 93.7500 (87.8492)  time: 0.3472  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1960/3750]  eta: 0:10:17  Lr: 0.030000  Loss: 0.0097  Acc@1: 68.7500 (53.9807)  Acc@5: 93.7500 (87.8920)  time: 0.3467  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1970/3750]  eta: 0:10:14  Lr: 0.030000  Loss: 0.0925  Acc@1: 75.0000 (54.0969)  Acc@5: 93.7500 (87.9281)  time: 0.3471  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1980/3750]  eta: 0:10:10  Lr: 0.030000  Loss: 0.2219  Acc@1: 75.0000 (54.1740)  Acc@5: 93.7500 (87.9449)  time: 0.3457  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1990/3750]  eta: 0:10:07  Lr: 0.030000  Loss: 0.2631  Acc@1: 62.5000 (54.2033)  Acc@5: 93.7500 (87.9615)  time: 0.3447  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2000/3750]  eta: 0:10:03  Lr: 0.030000  Loss: 0.2627  Acc@1: 62.5000 (54.2791)  Acc@5: 93.7500 (87.9966)  time: 0.3447  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2010/3750]  eta: 0:10:00  Lr: 0.030000  Loss: 0.0922  Acc@1: 68.7500 (54.3386)  Acc@5: 93.7500 (88.0346)  time: 0.3460  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2020/3750]  eta: 0:09:57  Lr: 0.030000  Loss: -0.0146  Acc@1: 68.7500 (54.4285)  Acc@5: 100.0000 (88.0814)  time: 0.3461  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2030/3750]  eta: 0:09:53  Lr: 0.030000  Loss: 0.1935  Acc@1: 68.7500 (54.4744)  Acc@5: 100.0000 (88.1093)  time: 0.3453  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2040/3750]  eta: 0:09:50  Lr: 0.030000  Loss: 0.3446  Acc@1: 62.5000 (54.5290)  Acc@5: 93.7500 (88.1461)  time: 0.3464  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2050/3750]  eta: 0:09:46  Lr: 0.030000  Loss: 0.0410  Acc@1: 68.7500 (54.6106)  Acc@5: 100.0000 (88.1826)  time: 0.3459  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2060/3750]  eta: 0:09:43  Lr: 0.030000  Loss: 0.1282  Acc@1: 62.5000 (54.6367)  Acc@5: 93.7500 (88.1944)  time: 0.3448  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [2070/3750]  eta: 0:09:39  Lr: 0.030000  Loss: 0.1928  Acc@1: 62.5000 (54.7230)  Acc@5: 93.7500 (88.2394)  time: 0.3447  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [2080/3750]  eta: 0:09:36  Lr: 0.030000  Loss: -0.0299  Acc@1: 68.7500 (54.7904)  Acc@5: 93.7500 (88.2689)  time: 0.3448  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [2090/3750]  eta: 0:09:32  Lr: 0.030000  Loss: 0.0374  Acc@1: 68.7500 (54.8751)  Acc@5: 93.7500 (88.2771)  time: 0.3444  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [2100/3750]  eta: 0:09:29  Lr: 0.030000  Loss: 0.0822  Acc@1: 68.7500 (54.9381)  Acc@5: 93.7500 (88.3002)  time: 0.3431  data: 0.0002  max mem: 2500
Train: Epoch[1/5]  [2110/3750]  eta: 0:09:25  Lr: 0.030000  Loss: 0.0328  Acc@1: 68.7500 (55.0272)  Acc@5: 93.7500 (88.3349)  time: 0.3426  data: 0.0002  max mem: 2500
Train: Epoch[1/5]  [2120/3750]  eta: 0:09:22  Lr: 0.030000  Loss: 0.3221  Acc@1: 75.0000 (55.0890)  Acc@5: 93.7500 (88.3516)  time: 0.3432  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [2130/3750]  eta: 0:09:19  Lr: 0.030000  Loss: 0.2321  Acc@1: 68.7500 (55.1560)  Acc@5: 93.7500 (88.3681)  time: 0.3445  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2140/3750]  eta: 0:09:15  Lr: 0.030000  Loss: 0.1921  Acc@1: 68.7500 (55.2137)  Acc@5: 93.7500 (88.3933)  time: 0.3447  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2150/3750]  eta: 0:09:12  Lr: 0.030000  Loss: 0.0466  Acc@1: 68.7500 (55.2650)  Acc@5: 93.7500 (88.4211)  time: 0.3437  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [2160/3750]  eta: 0:09:08  Lr: 0.030000  Loss: 0.0838  Acc@1: 68.7500 (55.3447)  Acc@5: 93.7500 (88.4515)  time: 0.3434  data: 0.0002  max mem: 2500
Train: Epoch[1/5]  [2170/3750]  eta: 0:09:05  Lr: 0.030000  Loss: -0.0686  Acc@1: 75.0000 (55.4266)  Acc@5: 93.7500 (88.4846)  time: 0.3435  data: 0.0002  max mem: 2500
Train: Epoch[1/5]  [2180/3750]  eta: 0:09:01  Lr: 0.030000  Loss: 0.0117  Acc@1: 75.0000 (55.5049)  Acc@5: 93.7500 (88.5144)  time: 0.3428  data: 0.0002  max mem: 2500
Train: Epoch[1/5]  [2190/3750]  eta: 0:08:58  Lr: 0.030000  Loss: -0.2476  Acc@1: 75.0000 (55.5796)  Acc@5: 93.7500 (88.5469)  time: 0.3425  data: 0.0002  max mem: 2500
Train: Epoch[1/5]  [2200/3750]  eta: 0:08:54  Lr: 0.030000  Loss: 0.1206  Acc@1: 75.0000 (55.6508)  Acc@5: 93.7500 (88.5705)  time: 0.3435  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [2210/3750]  eta: 0:08:51  Lr: 0.030000  Loss: -0.0415  Acc@1: 68.7500 (55.7270)  Acc@5: 93.7500 (88.5968)  time: 0.3441  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [2220/3750]  eta: 0:08:47  Lr: 0.030000  Loss: -0.0461  Acc@1: 68.7500 (55.7913)  Acc@5: 93.7500 (88.6228)  time: 0.3437  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [2230/3750]  eta: 0:08:44  Lr: 0.030000  Loss: 0.1645  Acc@1: 62.5000 (55.8326)  Acc@5: 93.7500 (88.6402)  time: 0.3447  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [2240/3750]  eta: 0:08:41  Lr: 0.030000  Loss: 0.1728  Acc@1: 68.7500 (55.9125)  Acc@5: 93.7500 (88.6630)  time: 0.3451  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [2250/3750]  eta: 0:08:37  Lr: 0.030000  Loss: -0.0297  Acc@1: 68.7500 (55.9696)  Acc@5: 100.0000 (88.7050)  time: 0.3448  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [2260/3750]  eta: 0:08:34  Lr: 0.030000  Loss: 0.1325  Acc@1: 68.7500 (56.0344)  Acc@5: 93.7500 (88.7273)  time: 0.3452  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [2270/3750]  eta: 0:08:30  Lr: 0.030000  Loss: 0.1546  Acc@1: 68.7500 (56.0959)  Acc@5: 93.7500 (88.7577)  time: 0.3448  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [2280/3750]  eta: 0:08:27  Lr: 0.030000  Loss: 0.1060  Acc@1: 68.7500 (56.1705)  Acc@5: 93.7500 (88.7741)  time: 0.3433  data: 0.0002  max mem: 2500
Train: Epoch[1/5]  [2290/3750]  eta: 0:08:23  Lr: 0.030000  Loss: 0.1497  Acc@1: 68.7500 (56.2500)  Acc@5: 93.7500 (88.7876)  time: 0.3424  data: 0.0002  max mem: 2500
Train: Epoch[1/5]  [2300/3750]  eta: 0:08:20  Lr: 0.030000  Loss: -0.0470  Acc@1: 68.7500 (56.3098)  Acc@5: 93.7500 (88.8174)  time: 0.3425  data: 0.0002  max mem: 2500
Train: Epoch[1/5]  [2310/3750]  eta: 0:08:16  Lr: 0.030000  Loss: 0.0326  Acc@1: 68.7500 (56.3825)  Acc@5: 93.7500 (88.8387)  time: 0.3433  data: 0.0002  max mem: 2500
Train: Epoch[1/5]  [2320/3750]  eta: 0:08:13  Lr: 0.030000  Loss: -0.1286  Acc@1: 68.7500 (56.4466)  Acc@5: 93.7500 (88.8706)  time: 0.3434  data: 0.0002  max mem: 2500
Train: Epoch[1/5]  [2330/3750]  eta: 0:08:09  Lr: 0.030000  Loss: 0.0050  Acc@1: 75.0000 (56.5315)  Acc@5: 93.7500 (88.9050)  time: 0.3432  data: 0.0002  max mem: 2500
Train: Epoch[1/5]  [2340/3750]  eta: 0:08:06  Lr: 0.030000  Loss: 0.1107  Acc@1: 75.0000 (56.6104)  Acc@5: 93.7500 (88.9230)  time: 0.3444  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [2350/3750]  eta: 0:08:02  Lr: 0.030000  Loss: -0.0812  Acc@1: 81.2500 (56.6940)  Acc@5: 93.7500 (88.9489)  time: 0.3466  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2360/3750]  eta: 0:07:59  Lr: 0.030000  Loss: 0.0452  Acc@1: 75.0000 (56.7688)  Acc@5: 93.7500 (88.9718)  time: 0.3476  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2370/3750]  eta: 0:07:56  Lr: 0.030000  Loss: -0.1451  Acc@1: 68.7500 (56.8326)  Acc@5: 93.7500 (88.9973)  time: 0.3471  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2380/3750]  eta: 0:07:52  Lr: 0.030000  Loss: 0.0870  Acc@1: 68.7500 (56.8747)  Acc@5: 93.7500 (89.0198)  time: 0.3459  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2390/3750]  eta: 0:07:49  Lr: 0.030000  Loss: -0.0103  Acc@1: 68.7500 (56.9270)  Acc@5: 93.7500 (89.0396)  time: 0.3459  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [2400/3750]  eta: 0:07:45  Lr: 0.030000  Loss: 0.0839  Acc@1: 75.0000 (57.0049)  Acc@5: 93.7500 (89.0645)  time: 0.3451  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [2410/3750]  eta: 0:07:42  Lr: 0.030000  Loss: 0.2034  Acc@1: 75.0000 (57.0640)  Acc@5: 100.0000 (89.0994)  time: 0.3447  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2420/3750]  eta: 0:07:38  Lr: 0.030000  Loss: 0.5132  Acc@1: 68.7500 (57.1071)  Acc@5: 93.7500 (89.1057)  time: 0.3454  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2430/3750]  eta: 0:07:35  Lr: 0.030000  Loss: -0.0320  Acc@1: 68.7500 (57.1421)  Acc@5: 93.7500 (89.1171)  time: 0.3449  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2440/3750]  eta: 0:07:31  Lr: 0.030000  Loss: 0.3782  Acc@1: 68.7500 (57.1743)  Acc@5: 93.7500 (89.1412)  time: 0.3449  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2450/3750]  eta: 0:07:28  Lr: 0.030000  Loss: -0.0263  Acc@1: 68.7500 (57.2445)  Acc@5: 100.0000 (89.1779)  time: 0.3466  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2460/3750]  eta: 0:07:25  Lr: 0.030000  Loss: 0.4582  Acc@1: 68.7500 (57.2506)  Acc@5: 93.7500 (89.1761)  time: 0.3463  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2470/3750]  eta: 0:07:21  Lr: 0.030000  Loss: 0.1236  Acc@1: 68.7500 (57.3098)  Acc@5: 93.7500 (89.1997)  time: 0.3452  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2480/3750]  eta: 0:07:18  Lr: 0.030000  Loss: -0.0219  Acc@1: 75.0000 (57.3811)  Acc@5: 93.7500 (89.2105)  time: 0.3452  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2490/3750]  eta: 0:07:14  Lr: 0.030000  Loss: 0.1186  Acc@1: 75.0000 (57.4418)  Acc@5: 93.7500 (89.2413)  time: 0.3457  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2500/3750]  eta: 0:07:11  Lr: 0.030000  Loss: 0.2213  Acc@1: 75.0000 (57.5095)  Acc@5: 93.7500 (89.2618)  time: 0.3456  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [2510/3750]  eta: 0:07:07  Lr: 0.030000  Loss: -0.1216  Acc@1: 75.0000 (57.5667)  Acc@5: 93.7500 (89.2871)  time: 0.3442  data: 0.0002  max mem: 2500
Train: Epoch[1/5]  [2520/3750]  eta: 0:07:04  Lr: 0.030000  Loss: 0.0165  Acc@1: 75.0000 (57.6160)  Acc@5: 93.7500 (89.3098)  time: 0.3436  data: 0.0002  max mem: 2500
Train: Epoch[1/5]  [2530/3750]  eta: 0:07:00  Lr: 0.030000  Loss: 0.0934  Acc@1: 68.7500 (57.6526)  Acc@5: 93.7500 (89.3199)  time: 0.3447  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [2540/3750]  eta: 0:06:57  Lr: 0.030000  Loss: 0.1091  Acc@1: 68.7500 (57.7135)  Acc@5: 93.7500 (89.3447)  time: 0.3464  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2550/3750]  eta: 0:06:54  Lr: 0.030000  Loss: -0.0564  Acc@1: 68.7500 (57.7617)  Acc@5: 93.7500 (89.3571)  time: 0.3462  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2560/3750]  eta: 0:06:50  Lr: 0.030000  Loss: 0.1791  Acc@1: 68.7500 (57.8241)  Acc@5: 93.7500 (89.3816)  time: 0.3457  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2570/3750]  eta: 0:06:47  Lr: 0.030000  Loss: 0.1084  Acc@1: 68.7500 (57.8739)  Acc@5: 93.7500 (89.3986)  time: 0.3453  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [2580/3750]  eta: 0:06:43  Lr: 0.030000  Loss: -0.0421  Acc@1: 68.7500 (57.9160)  Acc@5: 93.7500 (89.4179)  time: 0.3449  data: 0.0002  max mem: 2500
Train: Epoch[1/5]  [2590/3750]  eta: 0:06:40  Lr: 0.030000  Loss: -0.0365  Acc@1: 68.7500 (57.9458)  Acc@5: 93.7500 (89.4322)  time: 0.3449  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [2600/3750]  eta: 0:06:36  Lr: 0.030000  Loss: 0.0660  Acc@1: 68.7500 (58.0089)  Acc@5: 93.7500 (89.4608)  time: 0.3454  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [2610/3750]  eta: 0:06:33  Lr: 0.030000  Loss: 0.2496  Acc@1: 75.0000 (58.0597)  Acc@5: 100.0000 (89.4916)  time: 0.3453  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [2620/3750]  eta: 0:06:29  Lr: 0.030000  Loss: -0.0492  Acc@1: 68.7500 (58.0885)  Acc@5: 93.7500 (89.5078)  time: 0.3447  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [2630/3750]  eta: 0:06:26  Lr: 0.030000  Loss: 0.1560  Acc@1: 68.7500 (58.1290)  Acc@5: 93.7500 (89.5192)  time: 0.3438  data: 0.0002  max mem: 2500
Train: Epoch[1/5]  [2640/3750]  eta: 0:06:22  Lr: 0.030000  Loss: 0.0898  Acc@1: 68.7500 (58.1645)  Acc@5: 93.7500 (89.5376)  time: 0.3431  data: 0.0002  max mem: 2500
Train: Epoch[1/5]  [2650/3750]  eta: 0:06:19  Lr: 0.030000  Loss: -0.0595  Acc@1: 68.7500 (58.2139)  Acc@5: 93.7500 (89.5535)  time: 0.3436  data: 0.0002  max mem: 2500
Train: Epoch[1/5]  [2660/3750]  eta: 0:06:16  Lr: 0.030000  Loss: -0.2413  Acc@1: 68.7500 (58.2676)  Acc@5: 93.7500 (89.5833)  time: 0.3439  data: 0.0002  max mem: 2500
Train: Epoch[1/5]  [2670/3750]  eta: 0:06:12  Lr: 0.030000  Loss: -0.0477  Acc@1: 68.7500 (58.3232)  Acc@5: 93.7500 (89.5872)  time: 0.3437  data: 0.0002  max mem: 2500
Train: Epoch[1/5]  [2680/3750]  eta: 0:06:09  Lr: 0.030000  Loss: 0.1490  Acc@1: 68.7500 (58.3574)  Acc@5: 93.7500 (89.6051)  time: 0.3440  data: 0.0002  max mem: 2500
Train: Epoch[1/5]  [2690/3750]  eta: 0:06:05  Lr: 0.030000  Loss: -0.1728  Acc@1: 62.5000 (58.3937)  Acc@5: 93.7500 (89.6205)  time: 0.3450  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2700/3750]  eta: 0:06:02  Lr: 0.030000  Loss: -0.1307  Acc@1: 68.7500 (58.4367)  Acc@5: 93.7500 (89.6335)  time: 0.3460  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2710/3750]  eta: 0:05:58  Lr: 0.030000  Loss: 0.1355  Acc@1: 68.7500 (58.4770)  Acc@5: 93.7500 (89.6510)  time: 0.3480  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [2720/3750]  eta: 0:05:55  Lr: 0.030000  Loss: -0.1205  Acc@1: 68.7500 (58.5171)  Acc@5: 93.7500 (89.6614)  time: 0.3480  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2730/3750]  eta: 0:05:51  Lr: 0.030000  Loss: 0.1188  Acc@1: 75.0000 (58.5729)  Acc@5: 93.7500 (89.6718)  time: 0.3483  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2740/3750]  eta: 0:05:48  Lr: 0.030000  Loss: -0.1006  Acc@1: 75.0000 (58.6214)  Acc@5: 93.7500 (89.6890)  time: 0.3488  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [2750/3750]  eta: 0:05:45  Lr: 0.030000  Loss: 0.0047  Acc@1: 62.5000 (58.6537)  Acc@5: 93.7500 (89.7060)  time: 0.3464  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2760/3750]  eta: 0:05:41  Lr: 0.030000  Loss: -0.0701  Acc@1: 68.7500 (58.7242)  Acc@5: 93.7500 (89.7342)  time: 0.3452  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2770/3750]  eta: 0:05:38  Lr: 0.030000  Loss: -0.0841  Acc@1: 68.7500 (58.7468)  Acc@5: 93.7500 (89.7510)  time: 0.3451  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [2780/3750]  eta: 0:05:34  Lr: 0.030000  Loss: -0.0474  Acc@1: 62.5000 (58.8008)  Acc@5: 93.7500 (89.7676)  time: 0.3454  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2790/3750]  eta: 0:05:31  Lr: 0.030000  Loss: 0.0325  Acc@1: 75.0000 (58.8454)  Acc@5: 93.7500 (89.7908)  time: 0.3459  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2800/3750]  eta: 0:05:27  Lr: 0.030000  Loss: -0.1900  Acc@1: 75.0000 (58.9165)  Acc@5: 100.0000 (89.8139)  time: 0.3455  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2810/3750]  eta: 0:05:24  Lr: 0.030000  Loss: -0.2843  Acc@1: 81.2500 (58.9692)  Acc@5: 93.7500 (89.8212)  time: 0.3476  data: 0.0009  max mem: 2500
Train: Epoch[1/5]  [2820/3750]  eta: 0:05:20  Lr: 0.030000  Loss: 0.0432  Acc@1: 75.0000 (59.0128)  Acc@5: 93.7500 (89.8418)  time: 0.3486  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [2830/3750]  eta: 0:05:17  Lr: 0.030000  Loss: -0.0193  Acc@1: 68.7500 (59.0472)  Acc@5: 100.0000 (89.8600)  time: 0.3464  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2840/3750]  eta: 0:05:14  Lr: 0.030000  Loss: -0.0547  Acc@1: 68.7500 (59.1011)  Acc@5: 93.7500 (89.8803)  time: 0.3457  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [2850/3750]  eta: 0:05:10  Lr: 0.030000  Loss: 0.1245  Acc@1: 75.0000 (59.1525)  Acc@5: 93.7500 (89.8851)  time: 0.3463  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [2860/3750]  eta: 0:05:07  Lr: 0.030000  Loss: -0.1555  Acc@1: 75.0000 (59.2210)  Acc@5: 93.7500 (89.9074)  time: 0.3463  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [2870/3750]  eta: 0:05:03  Lr: 0.030000  Loss: -0.0787  Acc@1: 75.0000 (59.2716)  Acc@5: 93.7500 (89.9273)  time: 0.3455  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [2880/3750]  eta: 0:05:00  Lr: 0.030000  Loss: 0.0104  Acc@1: 75.0000 (59.3175)  Acc@5: 93.7500 (89.9319)  time: 0.3459  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [2890/3750]  eta: 0:04:56  Lr: 0.030000  Loss: 0.2372  Acc@1: 68.7500 (59.3501)  Acc@5: 93.7500 (89.9364)  time: 0.3468  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [2900/3750]  eta: 0:04:53  Lr: 0.030000  Loss: 0.2076  Acc@1: 68.7500 (59.3718)  Acc@5: 93.7500 (89.9496)  time: 0.3459  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [2910/3750]  eta: 0:04:49  Lr: 0.030000  Loss: -0.1734  Acc@1: 75.0000 (59.4362)  Acc@5: 93.7500 (89.9712)  time: 0.3443  data: 0.0002  max mem: 2500
Train: Epoch[1/5]  [2920/3750]  eta: 0:04:46  Lr: 0.030000  Loss: -0.0571  Acc@1: 81.2500 (59.4895)  Acc@5: 93.7500 (89.9927)  time: 0.3438  data: 0.0002  max mem: 2500
Train: Epoch[1/5]  [2930/3750]  eta: 0:04:42  Lr: 0.030000  Loss: 0.1162  Acc@1: 75.0000 (59.5296)  Acc@5: 93.7500 (89.9991)  time: 0.3440  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [2940/3750]  eta: 0:04:39  Lr: 0.030000  Loss: 0.0223  Acc@1: 68.7500 (59.5588)  Acc@5: 93.7500 (90.0055)  time: 0.3439  data: 0.0002  max mem: 2500
Train: Epoch[1/5]  [2950/3750]  eta: 0:04:36  Lr: 0.030000  Loss: -0.1206  Acc@1: 68.7500 (59.6133)  Acc@5: 93.7500 (90.0161)  time: 0.3438  data: 0.0002  max mem: 2500
Train: Epoch[1/5]  [2960/3750]  eta: 0:04:32  Lr: 0.030000  Loss: 0.0631  Acc@1: 68.7500 (59.6441)  Acc@5: 93.7500 (90.0308)  time: 0.3449  data: 0.0002  max mem: 2500
Train: Epoch[1/5]  [2970/3750]  eta: 0:04:29  Lr: 0.030000  Loss: -0.0866  Acc@1: 68.7500 (59.6685)  Acc@5: 93.7500 (90.0349)  time: 0.3465  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2980/3750]  eta: 0:04:25  Lr: 0.030000  Loss: 0.1366  Acc@1: 68.7500 (59.7094)  Acc@5: 93.7500 (90.0474)  time: 0.3462  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2990/3750]  eta: 0:04:22  Lr: 0.030000  Loss: -0.2191  Acc@1: 75.0000 (59.7647)  Acc@5: 93.7500 (90.0535)  time: 0.3456  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3000/3750]  eta: 0:04:18  Lr: 0.030000  Loss: -0.1443  Acc@1: 75.0000 (59.8134)  Acc@5: 93.7500 (90.0658)  time: 0.3454  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [3010/3750]  eta: 0:04:15  Lr: 0.030000  Loss: -0.0140  Acc@1: 68.7500 (59.8452)  Acc@5: 93.7500 (90.0780)  time: 0.3457  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [3020/3750]  eta: 0:04:11  Lr: 0.030000  Loss: 0.0522  Acc@1: 68.7500 (59.8932)  Acc@5: 93.7500 (90.0923)  time: 0.3460  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3030/3750]  eta: 0:04:08  Lr: 0.030000  Loss: -0.1280  Acc@1: 68.7500 (59.9225)  Acc@5: 93.7500 (90.0982)  time: 0.3451  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3040/3750]  eta: 0:04:05  Lr: 0.030000  Loss: -0.2776  Acc@1: 75.0000 (59.9741)  Acc@5: 93.7500 (90.1184)  time: 0.3453  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3050/3750]  eta: 0:04:01  Lr: 0.030000  Loss: 0.0259  Acc@1: 75.0000 (59.9988)  Acc@5: 93.7500 (90.1221)  time: 0.3447  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3060/3750]  eta: 0:03:58  Lr: 0.030000  Loss: 0.0767  Acc@1: 62.5000 (60.0253)  Acc@5: 93.7500 (90.1401)  time: 0.3447  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3070/3750]  eta: 0:03:54  Lr: 0.030000  Loss: 0.3542  Acc@1: 68.7500 (60.0578)  Acc@5: 100.0000 (90.1600)  time: 0.3449  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3080/3750]  eta: 0:03:51  Lr: 0.030000  Loss: 0.2756  Acc@1: 75.0000 (60.1022)  Acc@5: 93.7500 (90.1696)  time: 0.3456  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3090/3750]  eta: 0:03:47  Lr: 0.030000  Loss: -0.0163  Acc@1: 68.7500 (60.1343)  Acc@5: 93.7500 (90.1771)  time: 0.3456  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3100/3750]  eta: 0:03:44  Lr: 0.030000  Loss: -0.2574  Acc@1: 75.0000 (60.1822)  Acc@5: 93.7500 (90.1967)  time: 0.3452  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [3110/3750]  eta: 0:03:40  Lr: 0.030000  Loss: -0.2761  Acc@1: 75.0000 (60.2238)  Acc@5: 100.0000 (90.2162)  time: 0.3458  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [3120/3750]  eta: 0:03:37  Lr: 0.030000  Loss: 0.1656  Acc@1: 68.7500 (60.2591)  Acc@5: 93.7500 (90.2315)  time: 0.3453  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [3130/3750]  eta: 0:03:33  Lr: 0.030000  Loss: 0.2169  Acc@1: 68.7500 (60.2942)  Acc@5: 93.7500 (90.2407)  time: 0.3457  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [3140/3750]  eta: 0:03:30  Lr: 0.030000  Loss: -0.0537  Acc@1: 68.7500 (60.3231)  Acc@5: 93.7500 (90.2599)  time: 0.3459  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [3150/3750]  eta: 0:03:27  Lr: 0.030000  Loss: 0.0707  Acc@1: 68.7500 (60.3638)  Acc@5: 93.7500 (90.2709)  time: 0.3452  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [3160/3750]  eta: 0:03:23  Lr: 0.030000  Loss: -0.0487  Acc@1: 68.7500 (60.3863)  Acc@5: 93.7500 (90.2879)  time: 0.3450  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [3170/3750]  eta: 0:03:20  Lr: 0.030000  Loss: -0.1724  Acc@1: 68.7500 (60.4403)  Acc@5: 93.7500 (90.2949)  time: 0.3444  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [3180/3750]  eta: 0:03:16  Lr: 0.030000  Loss: -0.0813  Acc@1: 75.0000 (60.4782)  Acc@5: 93.7500 (90.3077)  time: 0.3440  data: 0.0002  max mem: 2500
Train: Epoch[1/5]  [3190/3750]  eta: 0:03:13  Lr: 0.030000  Loss: 0.1399  Acc@1: 68.7500 (60.5022)  Acc@5: 93.7500 (90.3146)  time: 0.3443  data: 0.0002  max mem: 2500
Train: Epoch[1/5]  [3200/3750]  eta: 0:03:09  Lr: 0.030000  Loss: -0.3264  Acc@1: 68.7500 (60.5397)  Acc@5: 100.0000 (90.3390)  time: 0.3448  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [3210/3750]  eta: 0:03:06  Lr: 0.030000  Loss: 0.0174  Acc@1: 75.0000 (60.5886)  Acc@5: 100.0000 (90.3476)  time: 0.3461  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3220/3750]  eta: 0:03:02  Lr: 0.030000  Loss: 0.0268  Acc@1: 68.7500 (60.6004)  Acc@5: 93.7500 (90.3524)  time: 0.3459  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3230/3750]  eta: 0:02:59  Lr: 0.030000  Loss: 0.3475  Acc@1: 68.7500 (60.6333)  Acc@5: 93.7500 (90.3610)  time: 0.3459  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3240/3750]  eta: 0:02:56  Lr: 0.030000  Loss: 0.1828  Acc@1: 68.7500 (60.6796)  Acc@5: 93.7500 (90.3733)  time: 0.3459  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3250/3750]  eta: 0:02:52  Lr: 0.030000  Loss: -0.2926  Acc@1: 81.2500 (60.7313)  Acc@5: 93.7500 (90.3895)  time: 0.3479  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3260/3750]  eta: 0:02:49  Lr: 0.030000  Loss: -0.1764  Acc@1: 81.2500 (60.7808)  Acc@5: 93.7500 (90.4075)  time: 0.3482  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [3270/3750]  eta: 0:02:45  Lr: 0.030000  Loss: -0.0968  Acc@1: 75.0000 (60.8147)  Acc@5: 93.7500 (90.4158)  time: 0.3454  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [3280/3750]  eta: 0:02:42  Lr: 0.030000  Loss: -0.1321  Acc@1: 75.0000 (60.8580)  Acc@5: 93.7500 (90.4278)  time: 0.3452  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [3290/3750]  eta: 0:02:38  Lr: 0.030000  Loss: -0.1326  Acc@1: 75.0000 (60.8933)  Acc@5: 93.7500 (90.4398)  time: 0.3451  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [3300/3750]  eta: 0:02:35  Lr: 0.030000  Loss: -0.0494  Acc@1: 75.0000 (60.9437)  Acc@5: 93.7500 (90.4499)  time: 0.3451  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [3310/3750]  eta: 0:02:31  Lr: 0.030000  Loss: 0.0916  Acc@1: 75.0000 (60.9823)  Acc@5: 93.7500 (90.4617)  time: 0.3451  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [3320/3750]  eta: 0:02:28  Lr: 0.030000  Loss: 0.1227  Acc@1: 75.0000 (61.0189)  Acc@5: 93.7500 (90.4735)  time: 0.3444  data: 0.0002  max mem: 2500
Train: Epoch[1/5]  [3330/3750]  eta: 0:02:24  Lr: 0.030000  Loss: -0.0939  Acc@1: 68.7500 (61.0496)  Acc@5: 93.7500 (90.4890)  time: 0.3437  data: 0.0002  max mem: 2500
Train: Epoch[1/5]  [3340/3750]  eta: 0:02:21  Lr: 0.030000  Loss: -0.0746  Acc@1: 68.7500 (61.0633)  Acc@5: 93.7500 (90.4950)  time: 0.3441  data: 0.0002  max mem: 2500
Train: Epoch[1/5]  [3350/3750]  eta: 0:02:18  Lr: 0.030000  Loss: -0.1565  Acc@1: 68.7500 (61.1179)  Acc@5: 93.7500 (90.5084)  time: 0.3440  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [3360/3750]  eta: 0:02:14  Lr: 0.030000  Loss: -0.1242  Acc@1: 75.0000 (61.1518)  Acc@5: 93.7500 (90.5237)  time: 0.3438  data: 0.0002  max mem: 2500
Train: Epoch[1/5]  [3370/3750]  eta: 0:02:11  Lr: 0.030000  Loss: -0.3435  Acc@1: 75.0000 (61.1892)  Acc@5: 93.7500 (90.5369)  time: 0.3441  data: 0.0002  max mem: 2500
Train: Epoch[1/5]  [3380/3750]  eta: 0:02:07  Lr: 0.030000  Loss: 0.0098  Acc@1: 75.0000 (61.2374)  Acc@5: 100.0000 (90.5575)  time: 0.3443  data: 0.0002  max mem: 2500
Train: Epoch[1/5]  [3390/3750]  eta: 0:02:04  Lr: 0.030000  Loss: -0.1527  Acc@1: 75.0000 (61.2780)  Acc@5: 93.7500 (90.5725)  time: 0.3447  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [3400/3750]  eta: 0:02:00  Lr: 0.030000  Loss: 0.2520  Acc@1: 75.0000 (61.3055)  Acc@5: 93.7500 (90.5855)  time: 0.3460  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3410/3750]  eta: 0:01:57  Lr: 0.030000  Loss: -0.0651  Acc@1: 68.7500 (61.3420)  Acc@5: 93.7500 (90.5984)  time: 0.3462  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3420/3750]  eta: 0:01:53  Lr: 0.030000  Loss: -0.1218  Acc@1: 75.0000 (61.3892)  Acc@5: 100.0000 (90.6241)  time: 0.3460  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3430/3750]  eta: 0:01:50  Lr: 0.030000  Loss: 0.0915  Acc@1: 75.0000 (61.4289)  Acc@5: 100.0000 (90.6387)  time: 0.3469  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [3440/3750]  eta: 0:01:46  Lr: 0.030000  Loss: -0.0969  Acc@1: 75.0000 (61.4611)  Acc@5: 100.0000 (90.6532)  time: 0.3470  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [3450/3750]  eta: 0:01:43  Lr: 0.030000  Loss: -0.0876  Acc@1: 75.0000 (61.5039)  Acc@5: 93.7500 (90.6639)  time: 0.3469  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [3460/3750]  eta: 0:01:40  Lr: 0.030000  Loss: -0.1895  Acc@1: 75.0000 (61.5248)  Acc@5: 93.7500 (90.6674)  time: 0.3467  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [3470/3750]  eta: 0:01:36  Lr: 0.030000  Loss: -0.1300  Acc@1: 68.7500 (61.5583)  Acc@5: 93.7500 (90.6745)  time: 0.3466  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3480/3750]  eta: 0:01:33  Lr: 0.030000  Loss: -0.0247  Acc@1: 75.0000 (61.5789)  Acc@5: 93.7500 (90.6780)  time: 0.3465  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [3490/3750]  eta: 0:01:29  Lr: 0.030000  Loss: -0.2478  Acc@1: 75.0000 (61.6210)  Acc@5: 93.7500 (90.6921)  time: 0.3459  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [3500/3750]  eta: 0:01:26  Lr: 0.030000  Loss: -0.0818  Acc@1: 75.0000 (61.6574)  Acc@5: 100.0000 (90.7080)  time: 0.3457  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [3510/3750]  eta: 0:01:22  Lr: 0.030000  Loss: -0.3640  Acc@1: 75.0000 (61.7061)  Acc@5: 100.0000 (90.7309)  time: 0.3498  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [3520/3750]  eta: 0:01:19  Lr: 0.030000  Loss: -0.2240  Acc@1: 81.2500 (61.7598)  Acc@5: 100.0000 (90.7466)  time: 0.3499  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3530/3750]  eta: 0:01:15  Lr: 0.030000  Loss: 0.2631  Acc@1: 68.7500 (61.7707)  Acc@5: 93.7500 (90.7516)  time: 0.3451  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [3540/3750]  eta: 0:01:12  Lr: 0.030000  Loss: -0.0961  Acc@1: 68.7500 (61.7975)  Acc@5: 93.7500 (90.7671)  time: 0.3445  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [3550/3750]  eta: 0:01:09  Lr: 0.030000  Loss: 0.2095  Acc@1: 68.7500 (61.8153)  Acc@5: 100.0000 (90.7790)  time: 0.3449  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [3560/3750]  eta: 0:01:05  Lr: 0.030000  Loss: -0.2725  Acc@1: 75.0000 (61.8383)  Acc@5: 100.0000 (90.7961)  time: 0.3452  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [3570/3750]  eta: 0:01:02  Lr: 0.030000  Loss: -0.2223  Acc@1: 75.0000 (61.8909)  Acc@5: 100.0000 (90.8131)  time: 0.3449  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [3580/3750]  eta: 0:00:58  Lr: 0.030000  Loss: -0.0244  Acc@1: 81.2500 (61.9293)  Acc@5: 100.0000 (90.8248)  time: 0.3448  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [3590/3750]  eta: 0:00:55  Lr: 0.030000  Loss: -0.0365  Acc@1: 75.0000 (61.9744)  Acc@5: 93.7500 (90.8417)  time: 0.3458  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [3600/3750]  eta: 0:00:51  Lr: 0.030000  Loss: 0.1443  Acc@1: 75.0000 (62.0123)  Acc@5: 100.0000 (90.8550)  time: 0.3452  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [3610/3750]  eta: 0:00:48  Lr: 0.030000  Loss: -0.1780  Acc@1: 81.2500 (62.0552)  Acc@5: 93.7500 (90.8630)  time: 0.3433  data: 0.0002  max mem: 2500
Train: Epoch[1/5]  [3620/3750]  eta: 0:00:44  Lr: 0.030000  Loss: 0.0290  Acc@1: 75.0000 (62.0875)  Acc@5: 93.7500 (90.8779)  time: 0.3433  data: 0.0002  max mem: 2500
Train: Epoch[1/5]  [3630/3750]  eta: 0:00:41  Lr: 0.030000  Loss: -0.1341  Acc@1: 75.0000 (62.1196)  Acc@5: 93.7500 (90.8875)  time: 0.3434  data: 0.0002  max mem: 2500
Train: Epoch[1/5]  [3640/3750]  eta: 0:00:37  Lr: 0.030000  Loss: -0.1943  Acc@1: 68.7500 (62.1327)  Acc@5: 93.7500 (90.8833)  time: 0.3434  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [3650/3750]  eta: 0:00:34  Lr: 0.030000  Loss: -0.2856  Acc@1: 68.7500 (62.1628)  Acc@5: 93.7500 (90.8929)  time: 0.3435  data: 0.0002  max mem: 2500
Train: Epoch[1/5]  [3660/3750]  eta: 0:00:31  Lr: 0.030000  Loss: -0.1387  Acc@1: 75.0000 (62.1910)  Acc@5: 100.0000 (90.9058)  time: 0.3436  data: 0.0002  max mem: 2500
Train: Epoch[1/5]  [3670/3750]  eta: 0:00:27  Lr: 0.030000  Loss: 0.3503  Acc@1: 75.0000 (62.2140)  Acc@5: 93.7500 (90.9068)  time: 0.3435  data: 0.0002  max mem: 2500
Train: Epoch[1/5]  [3680/3750]  eta: 0:00:24  Lr: 0.030000  Loss: 0.2168  Acc@1: 68.7500 (62.2266)  Acc@5: 93.7500 (90.9111)  time: 0.3434  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [3690/3750]  eta: 0:00:20  Lr: 0.030000  Loss: -0.1236  Acc@1: 68.7500 (62.2528)  Acc@5: 93.7500 (90.9222)  time: 0.3433  data: 0.0002  max mem: 2500
Train: Epoch[1/5]  [3700/3750]  eta: 0:00:17  Lr: 0.030000  Loss: -0.1940  Acc@1: 75.0000 (62.2872)  Acc@5: 93.7500 (90.9366)  time: 0.3453  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [3710/3750]  eta: 0:00:13  Lr: 0.030000  Loss: -0.1505  Acc@1: 75.0000 (62.3215)  Acc@5: 93.7500 (90.9526)  time: 0.3470  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3720/3750]  eta: 0:00:10  Lr: 0.030000  Loss: -0.2480  Acc@1: 75.0000 (62.3472)  Acc@5: 93.7500 (90.9483)  time: 0.3467  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [3730/3750]  eta: 0:00:06  Lr: 0.030000  Loss: -0.2172  Acc@1: 68.7500 (62.3710)  Acc@5: 93.7500 (90.9642)  time: 0.3467  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [3740/3750]  eta: 0:00:03  Lr: 0.030000  Loss: 0.0313  Acc@1: 75.0000 (62.4014)  Acc@5: 93.7500 (90.9733)  time: 0.3457  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [3749/3750]  eta: 0:00:00  Lr: 0.030000  Loss: 0.0690  Acc@1: 75.0000 (62.4400)  Acc@5: 93.7500 (90.9817)  time: 0.3455  data: 0.0009  max mem: 2500
Train: Epoch[1/5] Total time: 0:21:34 (0.3453 s / it)
{0: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 1: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 2: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 3: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 4: {0: 0, 1: 60000, 2: 0, 3: 0, 4: 0}, 5: {0: 0, 1: 60000, 2: 0, 3: 0, 4: 0}, 6: {0: 0, 1: 60000, 2: 0, 3: 0, 4: 0}, 7: {0: 0, 1: 60000, 2: 0, 3: 0, 4: 0}, 8: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 9: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 10: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 11: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 12: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 13: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 14: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 15: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 16: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 17: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 18: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 19: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}}
Averaged stats: Lr: 0.030000  Loss: 0.0690  Acc@1: 75.0000 (62.4400)  Acc@5: 93.7500 (90.9817)
Train: Epoch[2/5]  [   0/3750]  eta: 0:44:47  Lr: 0.030000  Loss: -0.2910  Acc@1: 68.7500 (68.7500)  Acc@5: 100.0000 (100.0000)  time: 0.7165  data: 0.3646  max mem: 2500
Train: Epoch[2/5]  [  10/3750]  eta: 0:23:39  Lr: 0.030000  Loss: -0.1476  Acc@1: 75.0000 (75.5682)  Acc@5: 93.7500 (96.0227)  time: 0.3794  data: 0.0335  max mem: 2500
Train: Epoch[2/5]  [  20/3750]  eta: 0:22:32  Lr: 0.030000  Loss: 0.0512  Acc@1: 75.0000 (77.9762)  Acc@5: 93.7500 (96.1310)  time: 0.3450  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [  30/3750]  eta: 0:22:10  Lr: 0.030000  Loss: -0.1891  Acc@1: 81.2500 (78.4274)  Acc@5: 93.7500 (94.9597)  time: 0.3456  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [  40/3750]  eta: 0:21:54  Lr: 0.030000  Loss: -0.2043  Acc@1: 75.0000 (78.5061)  Acc@5: 93.7500 (94.6646)  time: 0.3457  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [  50/3750]  eta: 0:21:44  Lr: 0.030000  Loss: 0.0696  Acc@1: 75.0000 (78.5539)  Acc@5: 93.7500 (94.8529)  time: 0.3447  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [  60/3750]  eta: 0:21:36  Lr: 0.030000  Loss: 0.1347  Acc@1: 75.0000 (77.6639)  Acc@5: 93.7500 (94.5697)  time: 0.3451  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [  70/3750]  eta: 0:21:30  Lr: 0.030000  Loss: -0.2852  Acc@1: 75.0000 (77.7289)  Acc@5: 93.7500 (94.7183)  time: 0.3456  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [  80/3750]  eta: 0:21:24  Lr: 0.030000  Loss: -0.1315  Acc@1: 75.0000 (77.5463)  Acc@5: 93.7500 (94.8302)  time: 0.3454  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [  90/3750]  eta: 0:21:19  Lr: 0.030000  Loss: -0.1451  Acc@1: 75.0000 (77.4725)  Acc@5: 93.7500 (94.4368)  time: 0.3462  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 100/3750]  eta: 0:21:17  Lr: 0.030000  Loss: -0.0082  Acc@1: 75.0000 (77.1040)  Acc@5: 93.7500 (94.6782)  time: 0.3505  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 110/3750]  eta: 0:21:12  Lr: 0.030000  Loss: -0.0059  Acc@1: 68.7500 (76.1824)  Acc@5: 93.7500 (94.5946)  time: 0.3492  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [ 120/3750]  eta: 0:21:07  Lr: 0.030000  Loss: -0.0368  Acc@1: 68.7500 (75.9814)  Acc@5: 93.7500 (94.5764)  time: 0.3445  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [ 130/3750]  eta: 0:21:02  Lr: 0.030000  Loss: -0.1261  Acc@1: 75.0000 (75.8588)  Acc@5: 93.7500 (94.7042)  time: 0.3443  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [ 140/3750]  eta: 0:20:57  Lr: 0.030000  Loss: 0.0915  Acc@1: 62.5000 (74.8227)  Acc@5: 93.7500 (94.5035)  time: 0.3444  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [ 150/3750]  eta: 0:20:53  Lr: 0.030000  Loss: -0.0003  Acc@1: 62.5000 (74.7103)  Acc@5: 93.7500 (94.4950)  time: 0.3440  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [ 160/3750]  eta: 0:20:48  Lr: 0.030000  Loss: -0.1670  Acc@1: 75.0000 (74.7671)  Acc@5: 100.0000 (94.7205)  time: 0.3435  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [ 170/3750]  eta: 0:20:44  Lr: 0.030000  Loss: -0.0315  Acc@1: 81.2500 (75.1096)  Acc@5: 93.7500 (94.7003)  time: 0.3435  data: 0.0002  max mem: 2500
Train: Epoch[2/5]  [ 180/3750]  eta: 0:20:40  Lr: 0.030000  Loss: -0.2548  Acc@1: 75.0000 (74.8619)  Acc@5: 93.7500 (94.6478)  time: 0.3439  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [ 190/3750]  eta: 0:20:36  Lr: 0.030000  Loss: -0.2774  Acc@1: 75.0000 (75.1309)  Acc@5: 93.7500 (94.7317)  time: 0.3449  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 200/3750]  eta: 0:20:32  Lr: 0.030000  Loss: -0.4025  Acc@1: 81.2500 (75.2799)  Acc@5: 100.0000 (94.8072)  time: 0.3458  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 210/3750]  eta: 0:20:28  Lr: 0.030000  Loss: -0.2789  Acc@1: 75.0000 (75.0889)  Acc@5: 93.7500 (94.8164)  time: 0.3453  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [ 220/3750]  eta: 0:20:24  Lr: 0.030000  Loss: -0.2248  Acc@1: 75.0000 (75.1697)  Acc@5: 93.7500 (94.6550)  time: 0.3444  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [ 230/3750]  eta: 0:20:21  Lr: 0.030000  Loss: -0.1435  Acc@1: 75.0000 (75.0812)  Acc@5: 93.7500 (94.5887)  time: 0.3447  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [ 240/3750]  eta: 0:20:17  Lr: 0.030000  Loss: -0.2995  Acc@1: 75.0000 (74.9481)  Acc@5: 93.7500 (94.5539)  time: 0.3446  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [ 250/3750]  eta: 0:20:13  Lr: 0.030000  Loss: -0.0977  Acc@1: 75.0000 (74.8506)  Acc@5: 93.7500 (94.6464)  time: 0.3460  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [ 260/3750]  eta: 0:20:09  Lr: 0.030000  Loss: -0.2638  Acc@1: 75.0000 (74.8563)  Acc@5: 93.7500 (94.5642)  time: 0.3452  data: 0.0002  max mem: 2500
Train: Epoch[2/5]  [ 270/3750]  eta: 0:20:05  Lr: 0.030000  Loss: -0.1265  Acc@1: 68.7500 (74.7463)  Acc@5: 93.7500 (94.5341)  time: 0.3427  data: 0.0002  max mem: 2500
Train: Epoch[2/5]  [ 280/3750]  eta: 0:20:01  Lr: 0.030000  Loss: -0.1725  Acc@1: 68.7500 (74.7998)  Acc@5: 93.7500 (94.6397)  time: 0.3426  data: 0.0002  max mem: 2500
Train: Epoch[2/5]  [ 290/3750]  eta: 0:19:58  Lr: 0.030000  Loss: -0.0910  Acc@1: 75.0000 (74.7423)  Acc@5: 93.7500 (94.6735)  time: 0.3425  data: 0.0002  max mem: 2500
Train: Epoch[2/5]  [ 300/3750]  eta: 0:19:54  Lr: 0.030000  Loss: -0.3052  Acc@1: 75.0000 (74.8339)  Acc@5: 93.7500 (94.7051)  time: 0.3426  data: 0.0002  max mem: 2500
Train: Epoch[2/5]  [ 310/3750]  eta: 0:19:50  Lr: 0.030000  Loss: -0.1456  Acc@1: 75.0000 (74.7990)  Acc@5: 93.7500 (94.7146)  time: 0.3426  data: 0.0002  max mem: 2500
Train: Epoch[2/5]  [ 320/3750]  eta: 0:19:46  Lr: 0.030000  Loss: 0.0920  Acc@1: 68.7500 (74.5911)  Acc@5: 93.7500 (94.5093)  time: 0.3427  data: 0.0002  max mem: 2500
Train: Epoch[2/5]  [ 330/3750]  eta: 0:19:42  Lr: 0.030000  Loss: -0.1971  Acc@1: 68.7500 (74.6035)  Acc@5: 93.7500 (94.5242)  time: 0.3440  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [ 340/3750]  eta: 0:19:39  Lr: 0.030000  Loss: -0.0237  Acc@1: 75.0000 (74.6151)  Acc@5: 93.7500 (94.5015)  time: 0.3449  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 350/3750]  eta: 0:19:35  Lr: 0.030000  Loss: -0.2244  Acc@1: 75.0000 (74.4480)  Acc@5: 93.7500 (94.5157)  time: 0.3448  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 360/3750]  eta: 0:19:32  Lr: 0.030000  Loss: 0.1191  Acc@1: 68.7500 (74.2729)  Acc@5: 93.7500 (94.4598)  time: 0.3444  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 370/3750]  eta: 0:19:28  Lr: 0.030000  Loss: -0.4907  Acc@1: 75.0000 (74.2756)  Acc@5: 93.7500 (94.4575)  time: 0.3449  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 380/3750]  eta: 0:19:25  Lr: 0.030000  Loss: -0.2894  Acc@1: 75.0000 (74.3602)  Acc@5: 93.7500 (94.5046)  time: 0.3458  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 390/3750]  eta: 0:19:21  Lr: 0.030000  Loss: -0.2985  Acc@1: 75.0000 (74.3766)  Acc@5: 93.7500 (94.5013)  time: 0.3466  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [ 400/3750]  eta: 0:19:18  Lr: 0.030000  Loss: -0.2760  Acc@1: 75.0000 (74.4545)  Acc@5: 93.7500 (94.5137)  time: 0.3469  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [ 410/3750]  eta: 0:19:14  Lr: 0.030000  Loss: 0.0147  Acc@1: 75.0000 (74.4069)  Acc@5: 93.7500 (94.5712)  time: 0.3456  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 420/3750]  eta: 0:19:11  Lr: 0.030000  Loss: -0.0294  Acc@1: 68.7500 (74.3468)  Acc@5: 93.7500 (94.5517)  time: 0.3452  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [ 430/3750]  eta: 0:19:08  Lr: 0.030000  Loss: 0.0866  Acc@1: 75.0000 (74.3039)  Acc@5: 93.7500 (94.6056)  time: 0.3453  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [ 440/3750]  eta: 0:19:05  Lr: 0.030000  Loss: -0.3097  Acc@1: 75.0000 (74.3197)  Acc@5: 100.0000 (94.6003)  time: 0.3487  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 450/3750]  eta: 0:19:01  Lr: 0.030000  Loss: 0.0083  Acc@1: 75.0000 (74.3487)  Acc@5: 93.7500 (94.5399)  time: 0.3484  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 460/3750]  eta: 0:18:57  Lr: 0.030000  Loss: -0.3926  Acc@1: 75.0000 (74.4577)  Acc@5: 100.0000 (94.6177)  time: 0.3449  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [ 470/3750]  eta: 0:18:54  Lr: 0.030000  Loss: -0.3329  Acc@1: 75.0000 (74.4559)  Acc@5: 100.0000 (94.5727)  time: 0.3449  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [ 480/3750]  eta: 0:18:50  Lr: 0.030000  Loss: -0.0724  Acc@1: 75.0000 (74.5842)  Acc@5: 93.7500 (94.6076)  time: 0.3455  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [ 490/3750]  eta: 0:18:47  Lr: 0.030000  Loss: 0.1666  Acc@1: 75.0000 (74.5036)  Acc@5: 93.7500 (94.5901)  time: 0.3455  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [ 500/3750]  eta: 0:18:43  Lr: 0.030000  Loss: -0.3751  Acc@1: 75.0000 (74.5634)  Acc@5: 100.0000 (94.6357)  time: 0.3448  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [ 510/3750]  eta: 0:18:40  Lr: 0.030000  Loss: 0.0419  Acc@1: 75.0000 (74.5597)  Acc@5: 100.0000 (94.6184)  time: 0.3459  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 520/3750]  eta: 0:18:36  Lr: 0.030000  Loss: -0.1828  Acc@1: 81.2500 (74.6641)  Acc@5: 93.7500 (94.6497)  time: 0.3449  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 530/3750]  eta: 0:18:33  Lr: 0.030000  Loss: 0.0434  Acc@1: 81.2500 (74.6234)  Acc@5: 93.7500 (94.5975)  time: 0.3429  data: 0.0002  max mem: 2500
Train: Epoch[2/5]  [ 540/3750]  eta: 0:18:29  Lr: 0.030000  Loss: -0.3383  Acc@1: 75.0000 (74.6996)  Acc@5: 93.7500 (94.6280)  time: 0.3431  data: 0.0002  max mem: 2500
Train: Epoch[2/5]  [ 550/3750]  eta: 0:18:26  Lr: 0.030000  Loss: -0.0749  Acc@1: 75.0000 (74.7164)  Acc@5: 93.7500 (94.6348)  time: 0.3431  data: 0.0002  max mem: 2500
Train: Epoch[2/5]  [ 560/3750]  eta: 0:18:22  Lr: 0.030000  Loss: -0.0284  Acc@1: 75.0000 (74.7772)  Acc@5: 93.7500 (94.6524)  time: 0.3430  data: 0.0002  max mem: 2500
Train: Epoch[2/5]  [ 570/3750]  eta: 0:18:19  Lr: 0.030000  Loss: -0.3195  Acc@1: 75.0000 (74.6607)  Acc@5: 93.7500 (94.6366)  time: 0.3450  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [ 580/3750]  eta: 0:18:15  Lr: 0.030000  Loss: -0.2363  Acc@1: 68.7500 (74.7096)  Acc@5: 93.7500 (94.6644)  time: 0.3463  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 590/3750]  eta: 0:18:12  Lr: 0.030000  Loss: -0.3492  Acc@1: 68.7500 (74.6087)  Acc@5: 93.7500 (94.6383)  time: 0.3452  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 600/3750]  eta: 0:18:08  Lr: 0.030000  Loss: -0.1495  Acc@1: 68.7500 (74.5528)  Acc@5: 93.7500 (94.6443)  time: 0.3460  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 610/3750]  eta: 0:18:05  Lr: 0.030000  Loss: -0.3882  Acc@1: 68.7500 (74.5295)  Acc@5: 93.7500 (94.6706)  time: 0.3459  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 620/3750]  eta: 0:18:01  Lr: 0.030000  Loss: -0.2328  Acc@1: 68.7500 (74.4565)  Acc@5: 93.7500 (94.6759)  time: 0.3450  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 630/3750]  eta: 0:17:58  Lr: 0.030000  Loss: -0.0809  Acc@1: 68.7500 (74.4156)  Acc@5: 93.7500 (94.6315)  time: 0.3448  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [ 640/3750]  eta: 0:17:54  Lr: 0.030000  Loss: -0.2814  Acc@1: 75.0000 (74.4247)  Acc@5: 93.7500 (94.6568)  time: 0.3448  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [ 650/3750]  eta: 0:17:51  Lr: 0.030000  Loss: -0.1018  Acc@1: 75.0000 (74.4048)  Acc@5: 93.7500 (94.6525)  time: 0.3453  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [ 660/3750]  eta: 0:17:47  Lr: 0.030000  Loss: -0.2882  Acc@1: 81.2500 (74.4894)  Acc@5: 100.0000 (94.6955)  time: 0.3453  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [ 670/3750]  eta: 0:17:44  Lr: 0.030000  Loss: -0.4124  Acc@1: 75.0000 (74.5436)  Acc@5: 100.0000 (94.7280)  time: 0.3447  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [ 680/3750]  eta: 0:17:40  Lr: 0.030000  Loss: -0.0508  Acc@1: 75.0000 (74.4952)  Acc@5: 93.7500 (94.6678)  time: 0.3447  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [ 690/3750]  eta: 0:17:37  Lr: 0.030000  Loss: -0.0665  Acc@1: 68.7500 (74.4935)  Acc@5: 93.7500 (94.6274)  time: 0.3448  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [ 700/3750]  eta: 0:17:33  Lr: 0.030000  Loss: -0.4079  Acc@1: 81.2500 (74.5988)  Acc@5: 93.7500 (94.6683)  time: 0.3441  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [ 710/3750]  eta: 0:17:30  Lr: 0.030000  Loss: -0.3148  Acc@1: 81.2500 (74.6835)  Acc@5: 100.0000 (94.6906)  time: 0.3432  data: 0.0002  max mem: 2500
Train: Epoch[2/5]  [ 720/3750]  eta: 0:17:26  Lr: 0.030000  Loss: -0.0045  Acc@1: 75.0000 (74.6186)  Acc@5: 93.7500 (94.6602)  time: 0.3434  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [ 730/3750]  eta: 0:17:23  Lr: 0.030000  Loss: -0.1792  Acc@1: 75.0000 (74.6580)  Acc@5: 93.7500 (94.6477)  time: 0.3437  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [ 740/3750]  eta: 0:17:19  Lr: 0.030000  Loss: -0.1491  Acc@1: 75.0000 (74.6289)  Acc@5: 93.7500 (94.6188)  time: 0.3445  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 750/3750]  eta: 0:17:16  Lr: 0.030000  Loss: -0.1990  Acc@1: 75.0000 (74.6255)  Acc@5: 93.7500 (94.6072)  time: 0.3449  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [ 760/3750]  eta: 0:17:12  Lr: 0.030000  Loss: -0.0717  Acc@1: 75.0000 (74.6633)  Acc@5: 93.7500 (94.6041)  time: 0.3433  data: 0.0002  max mem: 2500
Train: Epoch[2/5]  [ 770/3750]  eta: 0:17:09  Lr: 0.030000  Loss: -0.2335  Acc@1: 75.0000 (74.6595)  Acc@5: 93.7500 (94.6012)  time: 0.3428  data: 0.0002  max mem: 2500
Train: Epoch[2/5]  [ 780/3750]  eta: 0:17:05  Lr: 0.030000  Loss: -0.3468  Acc@1: 75.0000 (74.7359)  Acc@5: 93.7500 (94.6223)  time: 0.3424  data: 0.0002  max mem: 2500
Train: Epoch[2/5]  [ 790/3750]  eta: 0:17:01  Lr: 0.030000  Loss: -0.2948  Acc@1: 75.0000 (74.7551)  Acc@5: 93.7500 (94.6271)  time: 0.3424  data: 0.0002  max mem: 2500
Train: Epoch[2/5]  [ 800/3750]  eta: 0:16:58  Lr: 0.030000  Loss: 0.0074  Acc@1: 75.0000 (74.7503)  Acc@5: 93.7500 (94.6395)  time: 0.3436  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 810/3750]  eta: 0:16:54  Lr: 0.030000  Loss: -0.2315  Acc@1: 75.0000 (74.7611)  Acc@5: 93.7500 (94.6208)  time: 0.3442  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 820/3750]  eta: 0:16:51  Lr: 0.030000  Loss: -0.0839  Acc@1: 75.0000 (74.7183)  Acc@5: 93.7500 (94.6026)  time: 0.3443  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [ 830/3750]  eta: 0:16:48  Lr: 0.030000  Loss: 0.0440  Acc@1: 68.7500 (74.6916)  Acc@5: 93.7500 (94.5773)  time: 0.3443  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [ 840/3750]  eta: 0:16:44  Lr: 0.030000  Loss: -0.3050  Acc@1: 68.7500 (74.6730)  Acc@5: 93.7500 (94.5675)  time: 0.3443  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [ 850/3750]  eta: 0:16:41  Lr: 0.030000  Loss: -0.2807  Acc@1: 75.0000 (74.6328)  Acc@5: 93.7500 (94.5799)  time: 0.3445  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [ 860/3750]  eta: 0:16:37  Lr: 0.030000  Loss: 0.1936  Acc@1: 75.0000 (74.5862)  Acc@5: 100.0000 (94.5703)  time: 0.3445  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [ 870/3750]  eta: 0:16:34  Lr: 0.030000  Loss: -0.1686  Acc@1: 75.0000 (74.6269)  Acc@5: 100.0000 (94.6039)  time: 0.3453  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [ 880/3750]  eta: 0:16:30  Lr: 0.030000  Loss: -0.2682  Acc@1: 75.0000 (74.6240)  Acc@5: 100.0000 (94.6155)  time: 0.3443  data: 0.0002  max mem: 2500
Train: Epoch[2/5]  [ 890/3750]  eta: 0:16:27  Lr: 0.030000  Loss: -0.3797  Acc@1: 75.0000 (74.6352)  Acc@5: 93.7500 (94.6198)  time: 0.3425  data: 0.0002  max mem: 2500
Train: Epoch[2/5]  [ 900/3750]  eta: 0:16:23  Lr: 0.030000  Loss: 0.0644  Acc@1: 68.7500 (74.4728)  Acc@5: 93.7500 (94.6240)  time: 0.3427  data: 0.0002  max mem: 2500
Train: Epoch[2/5]  [ 910/3750]  eta: 0:16:20  Lr: 0.030000  Loss: -0.1821  Acc@1: 62.5000 (74.4374)  Acc@5: 100.0000 (94.6556)  time: 0.3428  data: 0.0002  max mem: 2500
Train: Epoch[2/5]  [ 920/3750]  eta: 0:16:16  Lr: 0.030000  Loss: -0.4145  Acc@1: 68.7500 (74.3757)  Acc@5: 100.0000 (94.6526)  time: 0.3426  data: 0.0002  max mem: 2500
Train: Epoch[2/5]  [ 930/3750]  eta: 0:16:13  Lr: 0.030000  Loss: -0.1956  Acc@1: 68.7500 (74.3757)  Acc@5: 93.7500 (94.6697)  time: 0.3427  data: 0.0002  max mem: 2500
Train: Epoch[2/5]  [ 940/3750]  eta: 0:16:09  Lr: 0.030000  Loss: -0.1134  Acc@1: 68.7500 (74.3358)  Acc@5: 100.0000 (94.6931)  time: 0.3428  data: 0.0002  max mem: 2500
Train: Epoch[2/5]  [ 950/3750]  eta: 0:16:05  Lr: 0.030000  Loss: -0.4230  Acc@1: 68.7500 (74.3231)  Acc@5: 93.7500 (94.6898)  time: 0.3427  data: 0.0002  max mem: 2500
Train: Epoch[2/5]  [ 960/3750]  eta: 0:16:02  Lr: 0.030000  Loss: -0.4228  Acc@1: 68.7500 (74.3106)  Acc@5: 93.7500 (94.6995)  time: 0.3432  data: 0.0002  max mem: 2500
Train: Epoch[2/5]  [ 970/3750]  eta: 0:15:59  Lr: 0.030000  Loss: -0.3863  Acc@1: 75.0000 (74.3499)  Acc@5: 93.7500 (94.7091)  time: 0.3447  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [ 980/3750]  eta: 0:15:55  Lr: 0.030000  Loss: -0.1671  Acc@1: 75.0000 (74.3502)  Acc@5: 93.7500 (94.6993)  time: 0.3470  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 990/3750]  eta: 0:15:52  Lr: 0.030000  Loss: 0.0582  Acc@1: 75.0000 (74.3441)  Acc@5: 93.7500 (94.7275)  time: 0.3476  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1000/3750]  eta: 0:15:48  Lr: 0.030000  Loss: -0.4451  Acc@1: 68.7500 (74.3819)  Acc@5: 100.0000 (94.7178)  time: 0.3462  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [1010/3750]  eta: 0:15:45  Lr: 0.030000  Loss: -0.2485  Acc@1: 75.0000 (74.3942)  Acc@5: 93.7500 (94.7268)  time: 0.3452  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [1020/3750]  eta: 0:15:41  Lr: 0.030000  Loss: -0.2067  Acc@1: 75.0000 (74.3695)  Acc@5: 93.7500 (94.7172)  time: 0.3452  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1030/3750]  eta: 0:15:38  Lr: 0.030000  Loss: -0.0352  Acc@1: 68.7500 (74.3635)  Acc@5: 93.7500 (94.7260)  time: 0.3454  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1040/3750]  eta: 0:15:35  Lr: 0.030000  Loss: -0.1669  Acc@1: 75.0000 (74.4116)  Acc@5: 93.7500 (94.6926)  time: 0.3457  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [1050/3750]  eta: 0:15:31  Lr: 0.030000  Loss: 0.0407  Acc@1: 81.2500 (74.4410)  Acc@5: 93.7500 (94.6717)  time: 0.3456  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1060/3750]  eta: 0:15:28  Lr: 0.030000  Loss: -0.3697  Acc@1: 75.0000 (74.4875)  Acc@5: 93.7500 (94.6689)  time: 0.3459  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1070/3750]  eta: 0:15:24  Lr: 0.030000  Loss: -0.1378  Acc@1: 75.0000 (74.4690)  Acc@5: 93.7500 (94.6662)  time: 0.3453  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1080/3750]  eta: 0:15:21  Lr: 0.030000  Loss: -0.1665  Acc@1: 75.0000 (74.4970)  Acc@5: 93.7500 (94.6346)  time: 0.3456  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1090/3750]  eta: 0:15:17  Lr: 0.030000  Loss: 0.1260  Acc@1: 75.0000 (74.4443)  Acc@5: 93.7500 (94.6494)  time: 0.3477  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1100/3750]  eta: 0:15:14  Lr: 0.030000  Loss: -0.2696  Acc@1: 75.0000 (74.4323)  Acc@5: 93.7500 (94.6412)  time: 0.3471  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1110/3750]  eta: 0:15:11  Lr: 0.030000  Loss: -0.2534  Acc@1: 75.0000 (74.4318)  Acc@5: 93.7500 (94.6445)  time: 0.3467  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1120/3750]  eta: 0:15:07  Lr: 0.030000  Loss: -0.2285  Acc@1: 75.0000 (74.4536)  Acc@5: 93.7500 (94.6309)  time: 0.3473  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1130/3750]  eta: 0:15:04  Lr: 0.030000  Loss: -0.0617  Acc@1: 75.0000 (74.4695)  Acc@5: 93.7500 (94.6342)  time: 0.3466  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [1140/3750]  eta: 0:15:00  Lr: 0.030000  Loss: -0.4551  Acc@1: 75.0000 (74.4851)  Acc@5: 93.7500 (94.6538)  time: 0.3456  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [1150/3750]  eta: 0:14:57  Lr: 0.030000  Loss: -0.4444  Acc@1: 81.2500 (74.5656)  Acc@5: 100.0000 (94.6731)  time: 0.3458  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [1160/3750]  eta: 0:14:54  Lr: 0.030000  Loss: -0.3207  Acc@1: 81.2500 (74.6070)  Acc@5: 93.7500 (94.6652)  time: 0.3459  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [1170/3750]  eta: 0:14:50  Lr: 0.030000  Loss: -0.0331  Acc@1: 75.0000 (74.6104)  Acc@5: 93.7500 (94.6520)  time: 0.3452  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [1180/3750]  eta: 0:14:47  Lr: 0.030000  Loss: -0.0762  Acc@1: 75.0000 (74.5872)  Acc@5: 93.7500 (94.6497)  time: 0.3456  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [1190/3750]  eta: 0:14:43  Lr: 0.030000  Loss: -0.1346  Acc@1: 75.0000 (74.5854)  Acc@5: 93.7500 (94.6579)  time: 0.3464  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [1200/3750]  eta: 0:14:40  Lr: 0.030000  Loss: -0.4024  Acc@1: 75.0000 (74.6201)  Acc@5: 93.7500 (94.6711)  time: 0.3452  data: 0.0002  max mem: 2500
Train: Epoch[2/5]  [1210/3750]  eta: 0:14:36  Lr: 0.030000  Loss: -0.2701  Acc@1: 81.2500 (74.6491)  Acc@5: 93.7500 (94.6790)  time: 0.3434  data: 0.0002  max mem: 2500
Train: Epoch[2/5]  [1220/3750]  eta: 0:14:33  Lr: 0.030000  Loss: -0.5476  Acc@1: 81.2500 (74.6673)  Acc@5: 93.7500 (94.6816)  time: 0.3437  data: 0.0002  max mem: 2500
Train: Epoch[2/5]  [1230/3750]  eta: 0:14:29  Lr: 0.030000  Loss: -0.3825  Acc@1: 75.0000 (74.6903)  Acc@5: 100.0000 (94.7045)  time: 0.3437  data: 0.0002  max mem: 2500
Train: Epoch[2/5]  [1240/3750]  eta: 0:14:26  Lr: 0.030000  Loss: -0.2399  Acc@1: 81.2500 (74.7129)  Acc@5: 100.0000 (94.7170)  time: 0.3433  data: 0.0002  max mem: 2500
Train: Epoch[2/5]  [1250/3750]  eta: 0:14:22  Lr: 0.030000  Loss: -0.4888  Acc@1: 75.0000 (74.7002)  Acc@5: 93.7500 (94.7292)  time: 0.3434  data: 0.0002  max mem: 2500
Train: Epoch[2/5]  [1260/3750]  eta: 0:14:19  Lr: 0.030000  Loss: -0.2404  Acc@1: 75.0000 (74.6927)  Acc@5: 100.0000 (94.7314)  time: 0.3438  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [1270/3750]  eta: 0:14:15  Lr: 0.030000  Loss: -0.0132  Acc@1: 75.0000 (74.6902)  Acc@5: 93.7500 (94.7187)  time: 0.3455  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [1280/3750]  eta: 0:14:12  Lr: 0.030000  Loss: -0.3261  Acc@1: 75.0000 (74.7170)  Acc@5: 93.7500 (94.7160)  time: 0.3468  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1290/3750]  eta: 0:14:09  Lr: 0.030000  Loss: -0.2330  Acc@1: 81.2500 (74.7434)  Acc@5: 93.7500 (94.7279)  time: 0.3467  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [1300/3750]  eta: 0:14:05  Lr: 0.030000  Loss: -0.1572  Acc@1: 75.0000 (74.7310)  Acc@5: 93.7500 (94.7252)  time: 0.3460  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [1310/3750]  eta: 0:14:02  Lr: 0.030000  Loss: -0.0612  Acc@1: 68.7500 (74.6949)  Acc@5: 93.7500 (94.7130)  time: 0.3453  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1320/3750]  eta: 0:13:58  Lr: 0.030000  Loss: -0.1124  Acc@1: 68.7500 (74.6735)  Acc@5: 93.7500 (94.7104)  time: 0.3448  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [1330/3750]  eta: 0:13:55  Lr: 0.030000  Loss: 0.1195  Acc@1: 68.7500 (74.6666)  Acc@5: 93.7500 (94.6938)  time: 0.3449  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [1340/3750]  eta: 0:13:51  Lr: 0.030000  Loss: -0.1878  Acc@1: 75.0000 (74.7017)  Acc@5: 93.7500 (94.7054)  time: 0.3449  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1350/3750]  eta: 0:13:48  Lr: 0.030000  Loss: 0.0223  Acc@1: 75.0000 (74.7502)  Acc@5: 93.7500 (94.7123)  time: 0.3439  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [1360/3750]  eta: 0:13:44  Lr: 0.030000  Loss: -0.2802  Acc@1: 75.0000 (74.7658)  Acc@5: 93.7500 (94.7052)  time: 0.3447  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [1370/3750]  eta: 0:13:41  Lr: 0.030000  Loss: -0.3269  Acc@1: 75.0000 (74.7903)  Acc@5: 93.7500 (94.7073)  time: 0.3459  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [1380/3750]  eta: 0:13:38  Lr: 0.030000  Loss: -0.1080  Acc@1: 75.0000 (74.7511)  Acc@5: 93.7500 (94.7094)  time: 0.3467  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1390/3750]  eta: 0:13:34  Lr: 0.030000  Loss: -0.1437  Acc@1: 75.0000 (74.7574)  Acc@5: 93.7500 (94.7070)  time: 0.3457  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1400/3750]  eta: 0:13:31  Lr: 0.030000  Loss: 0.1246  Acc@1: 68.7500 (74.7457)  Acc@5: 93.7500 (94.7047)  time: 0.3441  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [1410/3750]  eta: 0:13:27  Lr: 0.030000  Loss: -0.4214  Acc@1: 75.0000 (74.7830)  Acc@5: 100.0000 (94.7245)  time: 0.3441  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [1420/3750]  eta: 0:13:24  Lr: 0.030000  Loss: -0.5598  Acc@1: 75.0000 (74.8329)  Acc@5: 100.0000 (94.7308)  time: 0.3447  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [1430/3750]  eta: 0:13:20  Lr: 0.030000  Loss: -0.0415  Acc@1: 87.5000 (74.8864)  Acc@5: 100.0000 (94.7371)  time: 0.3446  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [1440/3750]  eta: 0:13:17  Lr: 0.030000  Loss: -0.2629  Acc@1: 75.0000 (74.9046)  Acc@5: 93.7500 (94.7476)  time: 0.3442  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [1450/3750]  eta: 0:13:13  Lr: 0.030000  Loss: -0.2657  Acc@1: 75.0000 (74.9225)  Acc@5: 100.0000 (94.7579)  time: 0.3451  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [1460/3750]  eta: 0:13:10  Lr: 0.030000  Loss: -0.2602  Acc@1: 75.0000 (74.9358)  Acc@5: 100.0000 (94.7810)  time: 0.3441  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [1470/3750]  eta: 0:13:06  Lr: 0.030000  Loss: -0.0847  Acc@1: 75.0000 (74.9448)  Acc@5: 100.0000 (94.7825)  time: 0.3423  data: 0.0002  max mem: 2500
Train: Epoch[2/5]  [1480/3750]  eta: 0:13:03  Lr: 0.030000  Loss: -0.2617  Acc@1: 75.0000 (74.9240)  Acc@5: 93.7500 (94.7839)  time: 0.3423  data: 0.0002  max mem: 2500
Train: Epoch[2/5]  [1490/3750]  eta: 0:12:59  Lr: 0.030000  Loss: -0.3426  Acc@1: 68.7500 (74.9120)  Acc@5: 93.7500 (94.7896)  time: 0.3425  data: 0.0002  max mem: 2500
Train: Epoch[2/5]  [1500/3750]  eta: 0:12:56  Lr: 0.030000  Loss: -0.3430  Acc@1: 75.0000 (74.9417)  Acc@5: 93.7500 (94.7951)  time: 0.3425  data: 0.0002  max mem: 2500
Train: Epoch[2/5]  [1510/3750]  eta: 0:12:52  Lr: 0.030000  Loss: -0.1785  Acc@1: 81.2500 (74.9669)  Acc@5: 93.7500 (94.7882)  time: 0.3426  data: 0.0002  max mem: 2500
Train: Epoch[2/5]  [1520/3750]  eta: 0:12:49  Lr: 0.030000  Loss: -0.0145  Acc@1: 81.2500 (74.9753)  Acc@5: 93.7500 (94.7773)  time: 0.3426  data: 0.0002  max mem: 2500
Train: Epoch[2/5]  [1530/3750]  eta: 0:12:45  Lr: 0.030000  Loss: -0.4652  Acc@1: 75.0000 (74.9306)  Acc@5: 93.7500 (94.7542)  time: 0.3441  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [1540/3750]  eta: 0:12:42  Lr: 0.030000  Loss: -0.2561  Acc@1: 68.7500 (74.9270)  Acc@5: 93.7500 (94.7599)  time: 0.3449  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1550/3750]  eta: 0:12:39  Lr: 0.030000  Loss: -0.1714  Acc@1: 75.0000 (74.9516)  Acc@5: 93.7500 (94.7614)  time: 0.3448  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1560/3750]  eta: 0:12:35  Lr: 0.030000  Loss: -0.1207  Acc@1: 75.0000 (74.9520)  Acc@5: 93.7500 (94.7670)  time: 0.3451  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1570/3750]  eta: 0:12:32  Lr: 0.030000  Loss: -0.1299  Acc@1: 75.0000 (74.9642)  Acc@5: 93.7500 (94.7565)  time: 0.3456  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1580/3750]  eta: 0:12:28  Lr: 0.030000  Loss: -0.3789  Acc@1: 75.0000 (74.9605)  Acc@5: 93.7500 (94.7620)  time: 0.3458  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1590/3750]  eta: 0:12:25  Lr: 0.030000  Loss: -0.0943  Acc@1: 75.0000 (74.9764)  Acc@5: 93.7500 (94.7753)  time: 0.3454  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1600/3750]  eta: 0:12:21  Lr: 0.030000  Loss: -0.1134  Acc@1: 75.0000 (74.9883)  Acc@5: 93.7500 (94.7728)  time: 0.3454  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1610/3750]  eta: 0:12:18  Lr: 0.030000  Loss: -0.3916  Acc@1: 75.0000 (74.9690)  Acc@5: 100.0000 (94.7936)  time: 0.3447  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1620/3750]  eta: 0:12:14  Lr: 0.030000  Loss: -0.2866  Acc@1: 75.0000 (75.0116)  Acc@5: 93.7500 (94.7717)  time: 0.3452  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1630/3750]  eta: 0:12:11  Lr: 0.030000  Loss: 0.0344  Acc@1: 68.7500 (74.9464)  Acc@5: 93.7500 (94.7578)  time: 0.3458  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1640/3750]  eta: 0:12:08  Lr: 0.030000  Loss: -0.2993  Acc@1: 68.7500 (74.9619)  Acc@5: 93.7500 (94.7593)  time: 0.3473  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [1650/3750]  eta: 0:12:04  Lr: 0.030000  Loss: -0.2169  Acc@1: 75.0000 (74.9735)  Acc@5: 93.7500 (94.7532)  time: 0.3465  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [1660/3750]  eta: 0:12:01  Lr: 0.030000  Loss: 0.1166  Acc@1: 68.7500 (74.9661)  Acc@5: 93.7500 (94.7622)  time: 0.3439  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1670/3750]  eta: 0:11:57  Lr: 0.030000  Loss: -0.2737  Acc@1: 81.2500 (74.9963)  Acc@5: 93.7500 (94.7599)  time: 0.3442  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [1680/3750]  eta: 0:11:54  Lr: 0.030000  Loss: -0.2968  Acc@1: 75.0000 (74.9851)  Acc@5: 93.7500 (94.7687)  time: 0.3444  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [1690/3750]  eta: 0:11:50  Lr: 0.030000  Loss: -0.2859  Acc@1: 75.0000 (74.9741)  Acc@5: 100.0000 (94.7664)  time: 0.3445  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [1700/3750]  eta: 0:11:47  Lr: 0.030000  Loss: -0.0625  Acc@1: 68.7500 (74.9669)  Acc@5: 93.7500 (94.7604)  time: 0.3443  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1710/3750]  eta: 0:11:43  Lr: 0.030000  Loss: -0.4073  Acc@1: 75.0000 (74.9708)  Acc@5: 93.7500 (94.7545)  time: 0.3444  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [1720/3750]  eta: 0:11:40  Lr: 0.030000  Loss: -0.0079  Acc@1: 75.0000 (74.9818)  Acc@5: 93.7500 (94.7487)  time: 0.3452  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [1730/3750]  eta: 0:11:36  Lr: 0.030000  Loss: -0.4604  Acc@1: 81.2500 (75.0036)  Acc@5: 93.7500 (94.7465)  time: 0.3440  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [1740/3750]  eta: 0:11:33  Lr: 0.030000  Loss: -0.1900  Acc@1: 75.0000 (74.9713)  Acc@5: 93.7500 (94.7480)  time: 0.3423  data: 0.0002  max mem: 2500
Train: Epoch[2/5]  [1750/3750]  eta: 0:11:29  Lr: 0.030000  Loss: -0.4974  Acc@1: 68.7500 (74.9393)  Acc@5: 93.7500 (94.7601)  time: 0.3424  data: 0.0002  max mem: 2500
Train: Epoch[2/5]  [1760/3750]  eta: 0:11:26  Lr: 0.030000  Loss: 0.1424  Acc@1: 68.7500 (74.9219)  Acc@5: 93.7500 (94.7473)  time: 0.3426  data: 0.0002  max mem: 2500
Train: Epoch[2/5]  [1770/3750]  eta: 0:11:22  Lr: 0.030000  Loss: -0.4122  Acc@1: 68.7500 (74.8977)  Acc@5: 93.7500 (94.7452)  time: 0.3426  data: 0.0002  max mem: 2500
Train: Epoch[2/5]  [1780/3750]  eta: 0:11:19  Lr: 0.030000  Loss: -0.0573  Acc@1: 68.7500 (74.9052)  Acc@5: 93.7500 (94.7361)  time: 0.3423  data: 0.0002  max mem: 2500
Train: Epoch[2/5]  [1790/3750]  eta: 0:11:16  Lr: 0.030000  Loss: -0.3332  Acc@1: 81.2500 (74.9581)  Acc@5: 93.7500 (94.7480)  time: 0.3423  data: 0.0002  max mem: 2500
Train: Epoch[2/5]  [1800/3750]  eta: 0:11:12  Lr: 0.030000  Loss: -0.0606  Acc@1: 81.2500 (74.9896)  Acc@5: 100.0000 (94.7633)  time: 0.3424  data: 0.0002  max mem: 2500
Train: Epoch[2/5]  [1810/3750]  eta: 0:11:09  Lr: 0.030000  Loss: -0.3151  Acc@1: 81.2500 (75.0173)  Acc@5: 100.0000 (94.7819)  time: 0.3434  data: 0.0002  max mem: 2500
Train: Epoch[2/5]  [1820/3750]  eta: 0:11:05  Lr: 0.030000  Loss: -0.2055  Acc@1: 81.2500 (75.0275)  Acc@5: 100.0000 (94.7934)  time: 0.3449  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [1830/3750]  eta: 0:11:02  Lr: 0.030000  Loss: -0.4725  Acc@1: 75.0000 (75.0239)  Acc@5: 93.7500 (94.7877)  time: 0.3452  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1840/3750]  eta: 0:10:58  Lr: 0.030000  Loss: -0.2759  Acc@1: 75.0000 (75.0407)  Acc@5: 93.7500 (94.7820)  time: 0.3452  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1850/3750]  eta: 0:10:55  Lr: 0.030000  Loss: -0.4554  Acc@1: 81.2500 (75.0473)  Acc@5: 93.7500 (94.7832)  time: 0.3448  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1860/3750]  eta: 0:10:51  Lr: 0.030000  Loss: -0.0407  Acc@1: 75.0000 (75.0336)  Acc@5: 93.7500 (94.7575)  time: 0.3442  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1870/3750]  eta: 0:10:48  Lr: 0.030000  Loss: -0.2879  Acc@1: 68.7500 (75.0100)  Acc@5: 93.7500 (94.7521)  time: 0.3441  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1880/3750]  eta: 0:10:44  Lr: 0.030000  Loss: -0.4672  Acc@1: 75.0000 (75.0033)  Acc@5: 93.7500 (94.7468)  time: 0.3445  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1890/3750]  eta: 0:10:41  Lr: 0.030000  Loss: -0.1766  Acc@1: 75.0000 (74.9934)  Acc@5: 93.7500 (94.7415)  time: 0.3443  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1900/3750]  eta: 0:10:38  Lr: 0.030000  Loss: 0.1923  Acc@1: 75.0000 (74.9868)  Acc@5: 93.7500 (94.7462)  time: 0.3444  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1910/3750]  eta: 0:10:34  Lr: 0.030000  Loss: -0.0503  Acc@1: 75.0000 (74.9673)  Acc@5: 93.7500 (94.7214)  time: 0.3447  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1920/3750]  eta: 0:10:31  Lr: 0.030000  Loss: -0.0057  Acc@1: 75.0000 (74.9675)  Acc@5: 93.7500 (94.7326)  time: 0.3446  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [1930/3750]  eta: 0:10:27  Lr: 0.030000  Loss: -0.0725  Acc@1: 75.0000 (74.9741)  Acc@5: 93.7500 (94.7307)  time: 0.3446  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1940/3750]  eta: 0:10:24  Lr: 0.030000  Loss: -0.3511  Acc@1: 81.2500 (75.0064)  Acc@5: 93.7500 (94.7257)  time: 0.3446  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1950/3750]  eta: 0:10:20  Lr: 0.030000  Loss: -0.1157  Acc@1: 75.0000 (75.0000)  Acc@5: 93.7500 (94.7239)  time: 0.3458  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1960/3750]  eta: 0:10:17  Lr: 0.030000  Loss: -0.1411  Acc@1: 75.0000 (74.9873)  Acc@5: 93.7500 (94.7157)  time: 0.3464  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1970/3750]  eta: 0:10:13  Lr: 0.030000  Loss: -0.3381  Acc@1: 75.0000 (74.9841)  Acc@5: 93.7500 (94.7108)  time: 0.3457  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1980/3750]  eta: 0:10:10  Lr: 0.030000  Loss: -0.0873  Acc@1: 81.2500 (75.0221)  Acc@5: 93.7500 (94.7091)  time: 0.3446  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [1990/3750]  eta: 0:10:07  Lr: 0.030000  Loss: -0.2164  Acc@1: 81.2500 (75.0502)  Acc@5: 93.7500 (94.7012)  time: 0.3442  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [2000/3750]  eta: 0:10:03  Lr: 0.030000  Loss: -0.1943  Acc@1: 75.0000 (75.0406)  Acc@5: 93.7500 (94.7058)  time: 0.3444  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [2010/3750]  eta: 0:10:00  Lr: 0.030000  Loss: -0.1987  Acc@1: 75.0000 (75.0497)  Acc@5: 100.0000 (94.7135)  time: 0.3452  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [2020/3750]  eta: 0:09:56  Lr: 0.030000  Loss: -0.1472  Acc@1: 81.2500 (75.0649)  Acc@5: 93.7500 (94.7087)  time: 0.3453  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [2030/3750]  eta: 0:09:53  Lr: 0.030000  Loss: -0.2875  Acc@1: 75.0000 (75.0769)  Acc@5: 93.7500 (94.7132)  time: 0.3448  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [2040/3750]  eta: 0:09:49  Lr: 0.030000  Loss: -0.2795  Acc@1: 75.0000 (75.0704)  Acc@5: 93.7500 (94.7268)  time: 0.3461  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2050/3750]  eta: 0:09:46  Lr: 0.030000  Loss: 0.1001  Acc@1: 75.0000 (75.0670)  Acc@5: 93.7500 (94.7129)  time: 0.3450  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2060/3750]  eta: 0:09:42  Lr: 0.030000  Loss: -0.2213  Acc@1: 75.0000 (75.0728)  Acc@5: 93.7500 (94.7234)  time: 0.3429  data: 0.0002  max mem: 2500
Train: Epoch[2/5]  [2070/3750]  eta: 0:09:39  Lr: 0.030000  Loss: -0.0407  Acc@1: 75.0000 (75.0664)  Acc@5: 93.7500 (94.7248)  time: 0.3430  data: 0.0002  max mem: 2500
Train: Epoch[2/5]  [2080/3750]  eta: 0:09:35  Lr: 0.030000  Loss: -0.4480  Acc@1: 75.0000 (75.0781)  Acc@5: 93.7500 (94.7291)  time: 0.3434  data: 0.0002  max mem: 2500
Train: Epoch[2/5]  [2090/3750]  eta: 0:09:32  Lr: 0.030000  Loss: -0.3592  Acc@1: 75.0000 (75.0837)  Acc@5: 93.7500 (94.7154)  time: 0.3437  data: 0.0002  max mem: 2500
Train: Epoch[2/5]  [2100/3750]  eta: 0:09:29  Lr: 0.030000  Loss: -0.0816  Acc@1: 68.7500 (75.0625)  Acc@5: 93.7500 (94.7168)  time: 0.3435  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [2110/3750]  eta: 0:09:25  Lr: 0.030000  Loss: -0.1570  Acc@1: 75.0000 (75.0888)  Acc@5: 93.7500 (94.7211)  time: 0.3437  data: 0.0002  max mem: 2500
Train: Epoch[2/5]  [2120/3750]  eta: 0:09:22  Lr: 0.030000  Loss: -0.4509  Acc@1: 81.2500 (75.1149)  Acc@5: 100.0000 (94.7372)  time: 0.3457  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [2130/3750]  eta: 0:09:18  Lr: 0.030000  Loss: -0.1147  Acc@1: 81.2500 (75.1320)  Acc@5: 100.0000 (94.7384)  time: 0.3470  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [2140/3750]  eta: 0:09:15  Lr: 0.030000  Loss: -0.2698  Acc@1: 75.0000 (75.1460)  Acc@5: 93.7500 (94.7367)  time: 0.3458  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2150/3750]  eta: 0:09:11  Lr: 0.030000  Loss: -0.3408  Acc@1: 81.2500 (75.1801)  Acc@5: 93.7500 (94.7263)  time: 0.3450  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [2160/3750]  eta: 0:09:08  Lr: 0.030000  Loss: -0.1044  Acc@1: 75.0000 (75.1533)  Acc@5: 93.7500 (94.7247)  time: 0.3448  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [2170/3750]  eta: 0:09:04  Lr: 0.030000  Loss: -0.1823  Acc@1: 68.7500 (75.1583)  Acc@5: 93.7500 (94.7259)  time: 0.3456  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2180/3750]  eta: 0:09:01  Lr: 0.030000  Loss: 0.1550  Acc@1: 75.0000 (75.1490)  Acc@5: 93.7500 (94.7301)  time: 0.3464  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2190/3750]  eta: 0:08:58  Lr: 0.030000  Loss: -0.3942  Acc@1: 81.2500 (75.1569)  Acc@5: 93.7500 (94.7284)  time: 0.3462  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2200/3750]  eta: 0:08:54  Lr: 0.030000  Loss: -0.3961  Acc@1: 75.0000 (75.1335)  Acc@5: 93.7500 (94.7268)  time: 0.3458  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2210/3750]  eta: 0:08:51  Lr: 0.030000  Loss: -0.2076  Acc@1: 75.0000 (75.1329)  Acc@5: 93.7500 (94.7337)  time: 0.3461  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2220/3750]  eta: 0:08:47  Lr: 0.030000  Loss: 0.1861  Acc@1: 75.0000 (75.1294)  Acc@5: 93.7500 (94.7237)  time: 0.3464  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2230/3750]  eta: 0:08:44  Lr: 0.030000  Loss: -0.2154  Acc@1: 75.0000 (75.1345)  Acc@5: 93.7500 (94.7333)  time: 0.3466  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2240/3750]  eta: 0:08:40  Lr: 0.030000  Loss: -0.2275  Acc@1: 75.0000 (75.1311)  Acc@5: 100.0000 (94.7484)  time: 0.3461  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2250/3750]  eta: 0:08:37  Lr: 0.030000  Loss: -0.0416  Acc@1: 75.0000 (75.1249)  Acc@5: 100.0000 (94.7523)  time: 0.3452  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2260/3750]  eta: 0:08:33  Lr: 0.030000  Loss: 0.0831  Acc@1: 75.0000 (75.1133)  Acc@5: 93.7500 (94.7562)  time: 0.3450  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [2270/3750]  eta: 0:08:30  Lr: 0.030000  Loss: -0.1241  Acc@1: 75.0000 (75.1128)  Acc@5: 93.7500 (94.7518)  time: 0.3451  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [2280/3750]  eta: 0:08:27  Lr: 0.030000  Loss: -0.0633  Acc@1: 75.0000 (75.1123)  Acc@5: 93.7500 (94.7446)  time: 0.3450  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [2290/3750]  eta: 0:08:23  Lr: 0.030000  Loss: -0.3437  Acc@1: 75.0000 (75.1200)  Acc@5: 93.7500 (94.7485)  time: 0.3450  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [2300/3750]  eta: 0:08:20  Lr: 0.030000  Loss: -0.1025  Acc@1: 75.0000 (75.1195)  Acc@5: 93.7500 (94.7523)  time: 0.3454  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [2310/3750]  eta: 0:08:16  Lr: 0.030000  Loss: 0.0948  Acc@1: 75.0000 (75.1244)  Acc@5: 93.7500 (94.7534)  time: 0.3447  data: 0.0002  max mem: 2500
Train: Epoch[2/5]  [2320/3750]  eta: 0:08:13  Lr: 0.030000  Loss: -0.0425  Acc@1: 75.0000 (75.0942)  Acc@5: 93.7500 (94.7598)  time: 0.3436  data: 0.0002  max mem: 2500
Train: Epoch[2/5]  [2330/3750]  eta: 0:08:09  Lr: 0.030000  Loss: -0.2151  Acc@1: 68.7500 (75.0509)  Acc@5: 93.7500 (94.7582)  time: 0.3432  data: 0.0002  max mem: 2500
Train: Epoch[2/5]  [2340/3750]  eta: 0:08:06  Lr: 0.030000  Loss: -0.2714  Acc@1: 75.0000 (75.0587)  Acc@5: 93.7500 (94.7512)  time: 0.3430  data: 0.0002  max mem: 2500
Train: Epoch[2/5]  [2350/3750]  eta: 0:08:02  Lr: 0.030000  Loss: -0.2475  Acc@1: 75.0000 (75.0452)  Acc@5: 93.7500 (94.7443)  time: 0.3430  data: 0.0002  max mem: 2500
Train: Epoch[2/5]  [2360/3750]  eta: 0:07:59  Lr: 0.030000  Loss: -0.1536  Acc@1: 75.0000 (75.0503)  Acc@5: 93.7500 (94.7400)  time: 0.3439  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [2370/3750]  eta: 0:07:55  Lr: 0.030000  Loss: -0.4485  Acc@1: 75.0000 (75.0527)  Acc@5: 93.7500 (94.7359)  time: 0.3447  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2380/3750]  eta: 0:07:52  Lr: 0.030000  Loss: -0.3237  Acc@1: 81.2500 (75.0840)  Acc@5: 93.7500 (94.7422)  time: 0.3451  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2390/3750]  eta: 0:07:49  Lr: 0.030000  Loss: 0.1118  Acc@1: 81.2500 (75.0758)  Acc@5: 93.7500 (94.7459)  time: 0.3467  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2400/3750]  eta: 0:07:45  Lr: 0.030000  Loss: -0.1365  Acc@1: 75.0000 (75.0937)  Acc@5: 93.7500 (94.7418)  time: 0.3464  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2410/3750]  eta: 0:07:42  Lr: 0.030000  Loss: -0.0046  Acc@1: 75.0000 (75.1037)  Acc@5: 93.7500 (94.7454)  time: 0.3453  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [2420/3750]  eta: 0:07:38  Lr: 0.030000  Loss: -0.1352  Acc@1: 75.0000 (75.0904)  Acc@5: 93.7500 (94.7465)  time: 0.3450  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [2430/3750]  eta: 0:07:35  Lr: 0.030000  Loss: -0.1256  Acc@1: 75.0000 (75.0977)  Acc@5: 93.7500 (94.7527)  time: 0.3441  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2440/3750]  eta: 0:07:31  Lr: 0.030000  Loss: -0.1704  Acc@1: 75.0000 (75.1075)  Acc@5: 100.0000 (94.7614)  time: 0.3450  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2450/3750]  eta: 0:07:28  Lr: 0.030000  Loss: -0.0468  Acc@1: 75.0000 (75.1045)  Acc@5: 100.0000 (94.7623)  time: 0.3448  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2460/3750]  eta: 0:07:24  Lr: 0.030000  Loss: -0.2775  Acc@1: 75.0000 (75.1067)  Acc@5: 93.7500 (94.7633)  time: 0.3440  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [2470/3750]  eta: 0:07:21  Lr: 0.030000  Loss: -0.2992  Acc@1: 75.0000 (75.1315)  Acc@5: 93.7500 (94.7744)  time: 0.3448  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [2480/3750]  eta: 0:07:18  Lr: 0.030000  Loss: -0.5365  Acc@1: 81.2500 (75.1335)  Acc@5: 93.7500 (94.7703)  time: 0.3450  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [2490/3750]  eta: 0:07:14  Lr: 0.030000  Loss: -0.4550  Acc@1: 75.0000 (75.1355)  Acc@5: 100.0000 (94.7787)  time: 0.3441  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [2500/3750]  eta: 0:07:11  Lr: 0.030000  Loss: -0.1565  Acc@1: 81.2500 (75.1649)  Acc@5: 100.0000 (94.7846)  time: 0.3435  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [2510/3750]  eta: 0:07:07  Lr: 0.030000  Loss: -0.2401  Acc@1: 81.2500 (75.1668)  Acc@5: 93.7500 (94.7755)  time: 0.3435  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [2520/3750]  eta: 0:07:04  Lr: 0.030000  Loss: -0.5210  Acc@1: 68.7500 (75.1364)  Acc@5: 93.7500 (94.7640)  time: 0.3442  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2530/3750]  eta: 0:07:00  Lr: 0.030000  Loss: -0.2462  Acc@1: 75.0000 (75.1457)  Acc@5: 93.7500 (94.7674)  time: 0.3447  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2540/3750]  eta: 0:06:57  Lr: 0.030000  Loss: -0.2209  Acc@1: 75.0000 (75.1451)  Acc@5: 93.7500 (94.7560)  time: 0.3444  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [2550/3750]  eta: 0:06:53  Lr: 0.030000  Loss: -0.3270  Acc@1: 75.0000 (75.1519)  Acc@5: 93.7500 (94.7668)  time: 0.3436  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [2560/3750]  eta: 0:06:50  Lr: 0.030000  Loss: -0.2344  Acc@1: 75.0000 (75.1611)  Acc@5: 100.0000 (94.7725)  time: 0.3434  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [2570/3750]  eta: 0:06:46  Lr: 0.030000  Loss: -0.0447  Acc@1: 81.2500 (75.1896)  Acc@5: 93.7500 (94.7734)  time: 0.3436  data: 0.0002  max mem: 2500
Train: Epoch[2/5]  [2580/3750]  eta: 0:06:43  Lr: 0.030000  Loss: -0.4396  Acc@1: 75.0000 (75.1865)  Acc@5: 100.0000 (94.7792)  time: 0.3448  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [2590/3750]  eta: 0:06:40  Lr: 0.030000  Loss: -0.2632  Acc@1: 75.0000 (75.1930)  Acc@5: 100.0000 (94.7921)  time: 0.3442  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [2600/3750]  eta: 0:06:36  Lr: 0.030000  Loss: -0.4524  Acc@1: 75.0000 (75.1898)  Acc@5: 100.0000 (94.7929)  time: 0.3424  data: 0.0002  max mem: 2500
Train: Epoch[2/5]  [2610/3750]  eta: 0:06:33  Lr: 0.030000  Loss: -0.3069  Acc@1: 81.2500 (75.2106)  Acc@5: 93.7500 (94.7913)  time: 0.3424  data: 0.0002  max mem: 2500
Train: Epoch[2/5]  [2620/3750]  eta: 0:06:29  Lr: 0.030000  Loss: -0.5284  Acc@1: 81.2500 (75.2337)  Acc@5: 93.7500 (94.7873)  time: 0.3424  data: 0.0002  max mem: 2500
Train: Epoch[2/5]  [2630/3750]  eta: 0:06:26  Lr: 0.030000  Loss: -0.1655  Acc@1: 81.2500 (75.2423)  Acc@5: 93.7500 (94.7786)  time: 0.3424  data: 0.0002  max mem: 2500
Train: Epoch[2/5]  [2640/3750]  eta: 0:06:22  Lr: 0.030000  Loss: -0.0674  Acc@1: 81.2500 (75.2603)  Acc@5: 93.7500 (94.7794)  time: 0.3432  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [2650/3750]  eta: 0:06:19  Lr: 0.030000  Loss: -0.2600  Acc@1: 81.2500 (75.2735)  Acc@5: 93.7500 (94.7803)  time: 0.3437  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [2660/3750]  eta: 0:06:15  Lr: 0.030000  Loss: -0.2465  Acc@1: 75.0000 (75.2701)  Acc@5: 93.7500 (94.7858)  time: 0.3441  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2670/3750]  eta: 0:06:12  Lr: 0.030000  Loss: -0.0282  Acc@1: 68.7500 (75.2574)  Acc@5: 100.0000 (94.7843)  time: 0.3448  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2680/3750]  eta: 0:06:08  Lr: 0.030000  Loss: -0.0734  Acc@1: 68.7500 (75.2494)  Acc@5: 93.7500 (94.7874)  time: 0.3448  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [2690/3750]  eta: 0:06:05  Lr: 0.030000  Loss: -0.3119  Acc@1: 75.0000 (75.2508)  Acc@5: 93.7500 (94.7812)  time: 0.3477  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [2700/3750]  eta: 0:06:02  Lr: 0.030000  Loss: -0.1022  Acc@1: 68.7500 (75.2106)  Acc@5: 93.7500 (94.7705)  time: 0.3483  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [2710/3750]  eta: 0:05:58  Lr: 0.030000  Loss: -0.3545  Acc@1: 68.7500 (75.2075)  Acc@5: 93.7500 (94.7667)  time: 0.3454  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2720/3750]  eta: 0:05:55  Lr: 0.030000  Loss: -0.4268  Acc@1: 75.0000 (75.1975)  Acc@5: 93.7500 (94.7607)  time: 0.3449  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2730/3750]  eta: 0:05:51  Lr: 0.030000  Loss: -0.1868  Acc@1: 75.0000 (75.2128)  Acc@5: 93.7500 (94.7547)  time: 0.3444  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [2740/3750]  eta: 0:05:48  Lr: 0.030000  Loss: -0.0619  Acc@1: 75.0000 (75.2166)  Acc@5: 93.7500 (94.7464)  time: 0.3442  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [2750/3750]  eta: 0:05:44  Lr: 0.030000  Loss: -0.4611  Acc@1: 75.0000 (75.2136)  Acc@5: 93.7500 (94.7474)  time: 0.3448  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [2760/3750]  eta: 0:05:41  Lr: 0.030000  Loss: 0.1077  Acc@1: 68.7500 (75.1947)  Acc@5: 93.7500 (94.7460)  time: 0.3444  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [2770/3750]  eta: 0:05:37  Lr: 0.030000  Loss: 0.0016  Acc@1: 68.7500 (75.1895)  Acc@5: 93.7500 (94.7492)  time: 0.3434  data: 0.0002  max mem: 2500
Train: Epoch[2/5]  [2780/3750]  eta: 0:05:34  Lr: 0.030000  Loss: -0.2496  Acc@1: 75.0000 (75.1888)  Acc@5: 93.7500 (94.7389)  time: 0.3430  data: 0.0002  max mem: 2500
Train: Epoch[2/5]  [2790/3750]  eta: 0:05:31  Lr: 0.030000  Loss: -0.2152  Acc@1: 81.2500 (75.2060)  Acc@5: 93.7500 (94.7353)  time: 0.3437  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [2800/3750]  eta: 0:05:27  Lr: 0.030000  Loss: -0.1620  Acc@1: 75.0000 (75.2031)  Acc@5: 93.7500 (94.7363)  time: 0.3446  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2810/3750]  eta: 0:05:24  Lr: 0.030000  Loss: -0.3023  Acc@1: 75.0000 (75.2134)  Acc@5: 93.7500 (94.7416)  time: 0.3445  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2820/3750]  eta: 0:05:20  Lr: 0.030000  Loss: -0.3245  Acc@1: 75.0000 (75.2216)  Acc@5: 100.0000 (94.7492)  time: 0.3446  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [2830/3750]  eta: 0:05:17  Lr: 0.030000  Loss: -0.1997  Acc@1: 75.0000 (75.2186)  Acc@5: 93.7500 (94.7435)  time: 0.3443  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [2840/3750]  eta: 0:05:13  Lr: 0.030000  Loss: -0.4107  Acc@1: 75.0000 (75.2420)  Acc@5: 93.7500 (94.7576)  time: 0.3437  data: 0.0002  max mem: 2500
Train: Epoch[2/5]  [2850/3750]  eta: 0:05:10  Lr: 0.030000  Loss: -0.3105  Acc@1: 81.2500 (75.2499)  Acc@5: 100.0000 (94.7584)  time: 0.3433  data: 0.0002  max mem: 2500
Train: Epoch[2/5]  [2860/3750]  eta: 0:05:06  Lr: 0.030000  Loss: -0.5514  Acc@1: 75.0000 (75.2578)  Acc@5: 93.7500 (94.7593)  time: 0.3431  data: 0.0002  max mem: 2500
Train: Epoch[2/5]  [2870/3750]  eta: 0:05:03  Lr: 0.030000  Loss: -0.4886  Acc@1: 81.2500 (75.2808)  Acc@5: 93.7500 (94.7666)  time: 0.3440  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [2880/3750]  eta: 0:04:59  Lr: 0.030000  Loss: -0.3244  Acc@1: 75.0000 (75.2690)  Acc@5: 93.7500 (94.7696)  time: 0.3447  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2890/3750]  eta: 0:04:56  Lr: 0.030000  Loss: -0.3259  Acc@1: 75.0000 (75.2702)  Acc@5: 93.7500 (94.7682)  time: 0.3444  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2900/3750]  eta: 0:04:53  Lr: 0.030000  Loss: -0.2769  Acc@1: 81.2500 (75.2758)  Acc@5: 93.7500 (94.7626)  time: 0.3443  data: 0.0002  max mem: 2500
Train: Epoch[2/5]  [2910/3750]  eta: 0:04:49  Lr: 0.030000  Loss: -0.1536  Acc@1: 75.0000 (75.2727)  Acc@5: 93.7500 (94.7505)  time: 0.3445  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [2920/3750]  eta: 0:04:46  Lr: 0.030000  Loss: -0.3471  Acc@1: 75.0000 (75.2782)  Acc@5: 93.7500 (94.7407)  time: 0.3447  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [2930/3750]  eta: 0:04:42  Lr: 0.030000  Loss: -0.0935  Acc@1: 75.0000 (75.2793)  Acc@5: 93.7500 (94.7330)  time: 0.3461  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [2940/3750]  eta: 0:04:39  Lr: 0.030000  Loss: -0.0971  Acc@1: 75.0000 (75.2720)  Acc@5: 93.7500 (94.7276)  time: 0.3453  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [2950/3750]  eta: 0:04:35  Lr: 0.030000  Loss: -0.5209  Acc@1: 75.0000 (75.2880)  Acc@5: 93.7500 (94.7264)  time: 0.3433  data: 0.0002  max mem: 2500
Train: Epoch[2/5]  [2960/3750]  eta: 0:04:32  Lr: 0.030000  Loss: -0.1095  Acc@1: 75.0000 (75.2786)  Acc@5: 93.7500 (94.7252)  time: 0.3433  data: 0.0002  max mem: 2500
Train: Epoch[2/5]  [2970/3750]  eta: 0:04:28  Lr: 0.030000  Loss: -0.3354  Acc@1: 68.7500 (75.2735)  Acc@5: 93.7500 (94.7219)  time: 0.3433  data: 0.0002  max mem: 2500
Train: Epoch[2/5]  [2980/3750]  eta: 0:04:25  Lr: 0.030000  Loss: -0.2963  Acc@1: 75.0000 (75.2851)  Acc@5: 93.7500 (94.7270)  time: 0.3433  data: 0.0002  max mem: 2500
Train: Epoch[2/5]  [2990/3750]  eta: 0:04:22  Lr: 0.030000  Loss: -0.5477  Acc@1: 75.0000 (75.2821)  Acc@5: 93.7500 (94.7300)  time: 0.3432  data: 0.0002  max mem: 2500
Train: Epoch[2/5]  [3000/3750]  eta: 0:04:18  Lr: 0.030000  Loss: -0.4490  Acc@1: 75.0000 (75.3020)  Acc@5: 93.7500 (94.7330)  time: 0.3433  data: 0.0002  max mem: 2500
Train: Epoch[2/5]  [3010/3750]  eta: 0:04:15  Lr: 0.030000  Loss: -0.3144  Acc@1: 81.2500 (75.3051)  Acc@5: 93.7500 (94.7235)  time: 0.3434  data: 0.0002  max mem: 2500
Train: Epoch[2/5]  [3020/3750]  eta: 0:04:11  Lr: 0.030000  Loss: 0.0035  Acc@1: 81.2500 (75.3041)  Acc@5: 93.7500 (94.7244)  time: 0.3466  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3030/3750]  eta: 0:04:08  Lr: 0.030000  Loss: -0.2580  Acc@1: 81.2500 (75.3196)  Acc@5: 93.7500 (94.7274)  time: 0.3478  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [3040/3750]  eta: 0:04:04  Lr: 0.030000  Loss: -0.4328  Acc@1: 75.0000 (75.3206)  Acc@5: 93.7500 (94.7262)  time: 0.3465  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3050/3750]  eta: 0:04:01  Lr: 0.030000  Loss: -0.0526  Acc@1: 81.2500 (75.3462)  Acc@5: 93.7500 (94.7230)  time: 0.3465  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3060/3750]  eta: 0:03:57  Lr: 0.030000  Loss: -0.5404  Acc@1: 81.2500 (75.3410)  Acc@5: 93.7500 (94.7219)  time: 0.3463  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3070/3750]  eta: 0:03:54  Lr: 0.030000  Loss: -0.3434  Acc@1: 75.0000 (75.3419)  Acc@5: 93.7500 (94.7289)  time: 0.3459  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3080/3750]  eta: 0:03:51  Lr: 0.030000  Loss: -0.5419  Acc@1: 75.0000 (75.3489)  Acc@5: 100.0000 (94.7318)  time: 0.3454  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3090/3750]  eta: 0:03:47  Lr: 0.030000  Loss: -0.2775  Acc@1: 81.2500 (75.3579)  Acc@5: 93.7500 (94.7307)  time: 0.3452  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3100/3750]  eta: 0:03:44  Lr: 0.030000  Loss: -0.0749  Acc@1: 75.0000 (75.3527)  Acc@5: 93.7500 (94.7315)  time: 0.3451  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [3110/3750]  eta: 0:03:40  Lr: 0.030000  Loss: -0.1600  Acc@1: 75.0000 (75.3737)  Acc@5: 93.7500 (94.7384)  time: 0.3454  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [3120/3750]  eta: 0:03:37  Lr: 0.030000  Loss: -0.0335  Acc@1: 75.0000 (75.3785)  Acc@5: 93.7500 (94.7353)  time: 0.3457  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3130/3750]  eta: 0:03:33  Lr: 0.030000  Loss: -0.4263  Acc@1: 75.0000 (75.3753)  Acc@5: 93.7500 (94.7361)  time: 0.3460  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3140/3750]  eta: 0:03:30  Lr: 0.030000  Loss: -0.1681  Acc@1: 75.0000 (75.3880)  Acc@5: 93.7500 (94.7389)  time: 0.3459  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3150/3750]  eta: 0:03:26  Lr: 0.030000  Loss: -0.2961  Acc@1: 75.0000 (75.3828)  Acc@5: 93.7500 (94.7417)  time: 0.3450  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [3160/3750]  eta: 0:03:23  Lr: 0.030000  Loss: -0.2726  Acc@1: 75.0000 (75.3856)  Acc@5: 93.7500 (94.7445)  time: 0.3446  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [3170/3750]  eta: 0:03:19  Lr: 0.030000  Loss: -0.3082  Acc@1: 81.2500 (75.3922)  Acc@5: 93.7500 (94.7453)  time: 0.3452  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [3180/3750]  eta: 0:03:16  Lr: 0.030000  Loss: -0.3537  Acc@1: 75.0000 (75.3989)  Acc@5: 93.7500 (94.7481)  time: 0.3455  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [3190/3750]  eta: 0:03:13  Lr: 0.030000  Loss: -0.3512  Acc@1: 75.0000 (75.4133)  Acc@5: 100.0000 (94.7567)  time: 0.3453  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [3200/3750]  eta: 0:03:09  Lr: 0.030000  Loss: -0.2949  Acc@1: 75.0000 (75.4139)  Acc@5: 93.7500 (94.7555)  time: 0.3451  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [3210/3750]  eta: 0:03:06  Lr: 0.030000  Loss: -0.0620  Acc@1: 81.2500 (75.4224)  Acc@5: 93.7500 (94.7544)  time: 0.3451  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [3220/3750]  eta: 0:03:02  Lr: 0.030000  Loss: -0.2587  Acc@1: 81.2500 (75.4346)  Acc@5: 93.7500 (94.7590)  time: 0.3453  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [3230/3750]  eta: 0:02:59  Lr: 0.030000  Loss: -0.2265  Acc@1: 75.0000 (75.4236)  Acc@5: 93.7500 (94.7559)  time: 0.3447  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [3240/3750]  eta: 0:02:55  Lr: 0.030000  Loss: -0.1515  Acc@1: 75.0000 (75.4262)  Acc@5: 93.7500 (94.7412)  time: 0.3438  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [3250/3750]  eta: 0:02:52  Lr: 0.030000  Loss: -0.1895  Acc@1: 75.0000 (75.4210)  Acc@5: 93.7500 (94.7324)  time: 0.3440  data: 0.0002  max mem: 2500
Train: Epoch[2/5]  [3260/3750]  eta: 0:02:48  Lr: 0.030000  Loss: -0.1375  Acc@1: 75.0000 (75.4197)  Acc@5: 93.7500 (94.7255)  time: 0.3439  data: 0.0002  max mem: 2500
Train: Epoch[2/5]  [3270/3750]  eta: 0:02:45  Lr: 0.030000  Loss: -0.4747  Acc@1: 75.0000 (75.4051)  Acc@5: 93.7500 (94.7245)  time: 0.3439  data: 0.0002  max mem: 2500
Train: Epoch[2/5]  [3280/3750]  eta: 0:02:42  Lr: 0.030000  Loss: -0.2256  Acc@1: 68.7500 (75.3962)  Acc@5: 93.7500 (94.7215)  time: 0.3453  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [3290/3750]  eta: 0:02:38  Lr: 0.030000  Loss: -0.3644  Acc@1: 68.7500 (75.3912)  Acc@5: 93.7500 (94.7280)  time: 0.3468  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [3300/3750]  eta: 0:02:35  Lr: 0.030000  Loss: -0.1634  Acc@1: 75.0000 (75.3938)  Acc@5: 93.7500 (94.7327)  time: 0.3459  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3310/3750]  eta: 0:02:31  Lr: 0.030000  Loss: -0.6353  Acc@1: 75.0000 (75.3964)  Acc@5: 93.7500 (94.7354)  time: 0.3453  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3320/3750]  eta: 0:02:28  Lr: 0.030000  Loss: -0.2289  Acc@1: 75.0000 (75.3896)  Acc@5: 93.7500 (94.7399)  time: 0.3457  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3330/3750]  eta: 0:02:24  Lr: 0.030000  Loss: -0.2453  Acc@1: 75.0000 (75.3828)  Acc@5: 93.7500 (94.7407)  time: 0.3455  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3340/3750]  eta: 0:02:21  Lr: 0.030000  Loss: -0.1987  Acc@1: 75.0000 (75.3854)  Acc@5: 93.7500 (94.7415)  time: 0.3455  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [3350/3750]  eta: 0:02:17  Lr: 0.030000  Loss: -0.0162  Acc@1: 75.0000 (75.3879)  Acc@5: 93.7500 (94.7404)  time: 0.3468  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [3360/3750]  eta: 0:02:14  Lr: 0.030000  Loss: -0.4763  Acc@1: 81.2500 (75.4091)  Acc@5: 93.7500 (94.7411)  time: 0.3467  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3370/3750]  eta: 0:02:11  Lr: 0.030000  Loss: -0.3904  Acc@1: 81.2500 (75.3931)  Acc@5: 93.7500 (94.7382)  time: 0.3460  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [3380/3750]  eta: 0:02:07  Lr: 0.030000  Loss: -0.3001  Acc@1: 81.2500 (75.4104)  Acc@5: 100.0000 (94.7427)  time: 0.3457  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [3390/3750]  eta: 0:02:04  Lr: 0.030000  Loss: 0.1213  Acc@1: 81.2500 (75.4073)  Acc@5: 93.7500 (94.7342)  time: 0.3456  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [3400/3750]  eta: 0:02:00  Lr: 0.030000  Loss: -0.0100  Acc@1: 75.0000 (75.3988)  Acc@5: 93.7500 (94.7332)  time: 0.3454  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [3410/3750]  eta: 0:01:57  Lr: 0.030000  Loss: -0.0461  Acc@1: 75.0000 (75.3994)  Acc@5: 93.7500 (94.7413)  time: 0.3446  data: 0.0002  max mem: 2500
Train: Epoch[2/5]  [3420/3750]  eta: 0:01:53  Lr: 0.030000  Loss: -0.1118  Acc@1: 75.0000 (75.4092)  Acc@5: 100.0000 (94.7457)  time: 0.3441  data: 0.0002  max mem: 2500
Train: Epoch[2/5]  [3430/3750]  eta: 0:01:50  Lr: 0.030000  Loss: 0.0145  Acc@1: 75.0000 (75.3971)  Acc@5: 100.0000 (94.7483)  time: 0.3446  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [3440/3750]  eta: 0:01:46  Lr: 0.030000  Loss: -0.3982  Acc@1: 75.0000 (75.4123)  Acc@5: 93.7500 (94.7508)  time: 0.3454  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3450/3750]  eta: 0:01:43  Lr: 0.030000  Loss: -0.2745  Acc@1: 81.2500 (75.4184)  Acc@5: 93.7500 (94.7570)  time: 0.3449  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3460/3750]  eta: 0:01:40  Lr: 0.030000  Loss: -0.3656  Acc@1: 81.2500 (75.4352)  Acc@5: 93.7500 (94.7595)  time: 0.3442  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [3470/3750]  eta: 0:01:36  Lr: 0.030000  Loss: -0.2495  Acc@1: 75.0000 (75.4231)  Acc@5: 93.7500 (94.7566)  time: 0.3447  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [3480/3750]  eta: 0:01:33  Lr: 0.030000  Loss: -0.2772  Acc@1: 75.0000 (75.4327)  Acc@5: 93.7500 (94.7555)  time: 0.3450  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [3490/3750]  eta: 0:01:29  Lr: 0.030000  Loss: -0.5594  Acc@1: 81.2500 (75.4565)  Acc@5: 93.7500 (94.7633)  time: 0.3444  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [3500/3750]  eta: 0:01:26  Lr: 0.030000  Loss: -0.3248  Acc@1: 81.2500 (75.4588)  Acc@5: 93.7500 (94.7640)  time: 0.3444  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [3510/3750]  eta: 0:01:22  Lr: 0.030000  Loss: -0.1594  Acc@1: 75.0000 (75.4611)  Acc@5: 93.7500 (94.7647)  time: 0.3440  data: 0.0002  max mem: 2500
Train: Epoch[2/5]  [3520/3750]  eta: 0:01:19  Lr: 0.030000  Loss: 0.0482  Acc@1: 75.0000 (75.4526)  Acc@5: 93.7500 (94.7689)  time: 0.3430  data: 0.0002  max mem: 2500
Train: Epoch[2/5]  [3530/3750]  eta: 0:01:15  Lr: 0.030000  Loss: -0.5640  Acc@1: 75.0000 (75.4637)  Acc@5: 100.0000 (94.7713)  time: 0.3428  data: 0.0002  max mem: 2500
Train: Epoch[2/5]  [3540/3750]  eta: 0:01:12  Lr: 0.030000  Loss: -0.5160  Acc@1: 81.2500 (75.4801)  Acc@5: 100.0000 (94.7808)  time: 0.3431  data: 0.0002  max mem: 2500
Train: Epoch[2/5]  [3550/3750]  eta: 0:01:08  Lr: 0.030000  Loss: -0.4737  Acc@1: 81.2500 (75.4735)  Acc@5: 100.0000 (94.7884)  time: 0.3433  data: 0.0002  max mem: 2500
Train: Epoch[2/5]  [3560/3750]  eta: 0:01:05  Lr: 0.030000  Loss: -0.5598  Acc@1: 75.0000 (75.4756)  Acc@5: 100.0000 (94.7978)  time: 0.3436  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [3570/3750]  eta: 0:01:02  Lr: 0.030000  Loss: -0.2564  Acc@1: 75.0000 (75.4761)  Acc@5: 100.0000 (94.8054)  time: 0.3447  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [3580/3750]  eta: 0:00:58  Lr: 0.030000  Loss: -0.4237  Acc@1: 75.0000 (75.4835)  Acc@5: 100.0000 (94.8129)  time: 0.3453  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3590/3750]  eta: 0:00:55  Lr: 0.030000  Loss: -0.0013  Acc@1: 75.0000 (75.4873)  Acc@5: 100.0000 (94.8134)  time: 0.3449  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3600/3750]  eta: 0:00:51  Lr: 0.030000  Loss: -0.1088  Acc@1: 75.0000 (75.4773)  Acc@5: 93.7500 (94.8070)  time: 0.3441  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3610/3750]  eta: 0:00:48  Lr: 0.030000  Loss: -0.2287  Acc@1: 81.2500 (75.5002)  Acc@5: 93.7500 (94.8110)  time: 0.3438  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3620/3750]  eta: 0:00:44  Lr: 0.030000  Loss: -0.2341  Acc@1: 81.2500 (75.5092)  Acc@5: 93.7500 (94.8029)  time: 0.3443  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3630/3750]  eta: 0:00:41  Lr: 0.030000  Loss: -0.3360  Acc@1: 75.0000 (75.5061)  Acc@5: 93.7500 (94.8034)  time: 0.3444  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3640/3750]  eta: 0:00:37  Lr: 0.030000  Loss: -0.2419  Acc@1: 75.0000 (75.5064)  Acc@5: 93.7500 (94.8108)  time: 0.3442  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [3650/3750]  eta: 0:00:34  Lr: 0.030000  Loss: -0.4784  Acc@1: 81.2500 (75.5118)  Acc@5: 100.0000 (94.8114)  time: 0.3447  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3660/3750]  eta: 0:00:31  Lr: 0.030000  Loss: -0.3738  Acc@1: 75.0000 (75.5002)  Acc@5: 93.7500 (94.8033)  time: 0.3448  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3670/3750]  eta: 0:00:27  Lr: 0.030000  Loss: -0.1552  Acc@1: 75.0000 (75.5159)  Acc@5: 93.7500 (94.8005)  time: 0.3442  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [3680/3750]  eta: 0:00:24  Lr: 0.030000  Loss: -0.1028  Acc@1: 81.2500 (75.5280)  Acc@5: 93.7500 (94.8027)  time: 0.3447  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [3690/3750]  eta: 0:00:20  Lr: 0.030000  Loss: -0.5737  Acc@1: 81.2500 (75.5300)  Acc@5: 93.7500 (94.8015)  time: 0.3446  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [3700/3750]  eta: 0:00:17  Lr: 0.030000  Loss: -0.2934  Acc@1: 75.0000 (75.5320)  Acc@5: 93.7500 (94.7987)  time: 0.3444  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [3710/3750]  eta: 0:00:13  Lr: 0.030000  Loss: -0.3007  Acc@1: 75.0000 (75.5271)  Acc@5: 93.7500 (94.7942)  time: 0.3446  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [3720/3750]  eta: 0:00:10  Lr: 0.030000  Loss: -0.2228  Acc@1: 68.7500 (75.5241)  Acc@5: 93.7500 (94.8031)  time: 0.3457  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [3730/3750]  eta: 0:00:06  Lr: 0.030000  Loss: -0.4083  Acc@1: 81.2500 (75.5394)  Acc@5: 100.0000 (94.8087)  time: 0.3446  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [3740/3750]  eta: 0:00:03  Lr: 0.030000  Loss: -0.3279  Acc@1: 81.2500 (75.5363)  Acc@5: 93.7500 (94.8075)  time: 0.3425  data: 0.0002  max mem: 2500
Train: Epoch[2/5]  [3749/3750]  eta: 0:00:00  Lr: 0.030000  Loss: -0.3995  Acc@1: 81.2500 (75.5483)  Acc@5: 93.7500 (94.8083)  time: 0.3430  data: 0.0006  max mem: 2500
Train: Epoch[2/5] Total time: 0:21:33 (0.3449 s / it)
{0: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 1: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 2: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 3: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 4: {0: 0, 1: 120000, 2: 0, 3: 0, 4: 0}, 5: {0: 0, 1: 120000, 2: 0, 3: 0, 4: 0}, 6: {0: 0, 1: 120000, 2: 0, 3: 0, 4: 0}, 7: {0: 0, 1: 120000, 2: 0, 3: 0, 4: 0}, 8: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 9: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 10: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 11: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 12: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 13: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 14: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 15: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 16: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 17: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 18: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 19: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}}
Averaged stats: Lr: 0.030000  Loss: -0.3995  Acc@1: 81.2500 (75.5483)  Acc@5: 93.7500 (94.8083)
Train: Epoch[3/5]  [   0/3750]  eta: 0:35:15  Lr: 0.030000  Loss: -0.2284  Acc@1: 75.0000 (75.0000)  Acc@5: 100.0000 (100.0000)  time: 0.5641  data: 0.2208  max mem: 2500
Train: Epoch[3/5]  [  10/3750]  eta: 0:22:36  Lr: 0.030000  Loss: -0.6886  Acc@1: 81.2500 (81.8182)  Acc@5: 100.0000 (96.0227)  time: 0.3627  data: 0.0203  max mem: 2500
Train: Epoch[3/5]  [  20/3750]  eta: 0:21:56  Lr: 0.030000  Loss: -0.2316  Acc@1: 75.0000 (76.7857)  Acc@5: 93.7500 (95.5357)  time: 0.3424  data: 0.0002  max mem: 2500
Train: Epoch[3/5]  [  30/3750]  eta: 0:21:41  Lr: 0.030000  Loss: -0.1782  Acc@1: 68.7500 (75.4032)  Acc@5: 93.7500 (94.9597)  time: 0.3426  data: 0.0002  max mem: 2500
Train: Epoch[3/5]  [  40/3750]  eta: 0:21:31  Lr: 0.030000  Loss: -0.2352  Acc@1: 68.7500 (74.6951)  Acc@5: 93.7500 (94.3598)  time: 0.3429  data: 0.0002  max mem: 2500
Train: Epoch[3/5]  [  50/3750]  eta: 0:21:26  Lr: 0.030000  Loss: -0.3286  Acc@1: 75.0000 (75.3676)  Acc@5: 93.7500 (94.4853)  time: 0.3442  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [  60/3750]  eta: 0:21:20  Lr: 0.030000  Loss: -0.4503  Acc@1: 75.0000 (75.4098)  Acc@5: 93.7500 (94.6721)  time: 0.3450  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [  70/3750]  eta: 0:21:15  Lr: 0.030000  Loss: -0.6049  Acc@1: 81.2500 (76.4965)  Acc@5: 93.7500 (94.8944)  time: 0.3446  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [  80/3750]  eta: 0:21:11  Lr: 0.030000  Loss: -0.4379  Acc@1: 81.2500 (76.8519)  Acc@5: 93.7500 (94.6759)  time: 0.3443  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [  90/3750]  eta: 0:21:07  Lr: 0.030000  Loss: -0.3342  Acc@1: 81.2500 (76.9918)  Acc@5: 93.7500 (94.5742)  time: 0.3448  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 100/3750]  eta: 0:21:03  Lr: 0.030000  Loss: -0.1474  Acc@1: 75.0000 (77.0421)  Acc@5: 93.7500 (94.6163)  time: 0.3449  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [ 110/3750]  eta: 0:20:59  Lr: 0.030000  Loss: -0.4808  Acc@1: 75.0000 (77.6464)  Acc@5: 93.7500 (94.9324)  time: 0.3454  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 120/3750]  eta: 0:20:56  Lr: 0.030000  Loss: -0.5724  Acc@1: 75.0000 (77.6343)  Acc@5: 100.0000 (95.0930)  time: 0.3458  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 130/3750]  eta: 0:20:52  Lr: 0.030000  Loss: -0.3945  Acc@1: 75.0000 (77.6240)  Acc@5: 100.0000 (95.1813)  time: 0.3450  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 140/3750]  eta: 0:20:48  Lr: 0.030000  Loss: -0.4571  Acc@1: 75.0000 (77.5266)  Acc@5: 93.7500 (95.2571)  time: 0.3454  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 150/3750]  eta: 0:20:45  Lr: 0.030000  Loss: -0.4126  Acc@1: 75.0000 (77.3179)  Acc@5: 93.7500 (95.1573)  time: 0.3455  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 160/3750]  eta: 0:20:41  Lr: 0.030000  Loss: -0.6044  Acc@1: 81.2500 (77.7562)  Acc@5: 93.7500 (95.1863)  time: 0.3457  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 170/3750]  eta: 0:20:38  Lr: 0.030000  Loss: -0.1152  Acc@1: 75.0000 (77.3757)  Acc@5: 93.7500 (95.1023)  time: 0.3456  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [ 180/3750]  eta: 0:20:34  Lr: 0.030000  Loss: -0.2327  Acc@1: 75.0000 (77.4171)  Acc@5: 93.7500 (95.0622)  time: 0.3452  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [ 190/3750]  eta: 0:20:30  Lr: 0.030000  Loss: -0.2959  Acc@1: 75.0000 (77.3560)  Acc@5: 93.7500 (95.0916)  time: 0.3450  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [ 200/3750]  eta: 0:20:27  Lr: 0.030000  Loss: -0.2291  Acc@1: 75.0000 (77.2077)  Acc@5: 93.7500 (95.1803)  time: 0.3451  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [ 210/3750]  eta: 0:20:23  Lr: 0.030000  Loss: -0.2994  Acc@1: 75.0000 (77.1623)  Acc@5: 93.7500 (95.0533)  time: 0.3454  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [ 220/3750]  eta: 0:20:20  Lr: 0.030000  Loss: -0.4899  Acc@1: 75.0000 (77.1493)  Acc@5: 93.7500 (94.9943)  time: 0.3448  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [ 230/3750]  eta: 0:20:16  Lr: 0.030000  Loss: -0.1342  Acc@1: 75.0000 (77.0292)  Acc@5: 93.7500 (94.9675)  time: 0.3456  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [ 240/3750]  eta: 0:20:13  Lr: 0.030000  Loss: -0.4120  Acc@1: 75.0000 (76.9191)  Acc@5: 93.7500 (94.9429)  time: 0.3452  data: 0.0002  max mem: 2500
Train: Epoch[3/5]  [ 250/3750]  eta: 0:20:09  Lr: 0.030000  Loss: -0.4674  Acc@1: 81.2500 (77.0916)  Acc@5: 93.7500 (94.8456)  time: 0.3436  data: 0.0002  max mem: 2500
Train: Epoch[3/5]  [ 260/3750]  eta: 0:20:05  Lr: 0.030000  Loss: -0.3464  Acc@1: 81.2500 (77.1552)  Acc@5: 93.7500 (94.9473)  time: 0.3435  data: 0.0002  max mem: 2500
Train: Epoch[3/5]  [ 270/3750]  eta: 0:20:02  Lr: 0.030000  Loss: -0.0180  Acc@1: 81.2500 (77.3524)  Acc@5: 93.7500 (94.9262)  time: 0.3436  data: 0.0002  max mem: 2500
Train: Epoch[3/5]  [ 280/3750]  eta: 0:19:58  Lr: 0.030000  Loss: -0.3953  Acc@1: 81.2500 (77.1352)  Acc@5: 93.7500 (94.9733)  time: 0.3438  data: 0.0002  max mem: 2500
Train: Epoch[3/5]  [ 290/3750]  eta: 0:19:55  Lr: 0.030000  Loss: -0.2722  Acc@1: 81.2500 (77.3411)  Acc@5: 100.0000 (95.1460)  time: 0.3455  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [ 300/3750]  eta: 0:19:51  Lr: 0.030000  Loss: -0.2243  Acc@1: 81.2500 (77.2633)  Acc@5: 100.0000 (95.1620)  time: 0.3464  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 310/3750]  eta: 0:19:48  Lr: 0.030000  Loss: -0.3313  Acc@1: 75.0000 (77.1905)  Acc@5: 93.7500 (95.1768)  time: 0.3460  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 320/3750]  eta: 0:19:44  Lr: 0.030000  Loss: -0.5170  Acc@1: 75.0000 (76.9276)  Acc@5: 93.7500 (95.0740)  time: 0.3457  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 330/3750]  eta: 0:19:41  Lr: 0.030000  Loss: -0.3521  Acc@1: 68.7500 (76.7749)  Acc@5: 93.7500 (95.0340)  time: 0.3455  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 340/3750]  eta: 0:19:38  Lr: 0.030000  Loss: -0.6865  Acc@1: 81.2500 (76.9978)  Acc@5: 93.7500 (95.0513)  time: 0.3458  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 350/3750]  eta: 0:19:34  Lr: 0.030000  Loss: -0.4801  Acc@1: 81.2500 (77.1011)  Acc@5: 100.0000 (95.1033)  time: 0.3451  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 360/3750]  eta: 0:19:31  Lr: 0.030000  Loss: -0.4123  Acc@1: 81.2500 (77.1988)  Acc@5: 93.7500 (95.1177)  time: 0.3450  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 370/3750]  eta: 0:19:27  Lr: 0.030000  Loss: -0.4687  Acc@1: 81.2500 (77.2911)  Acc@5: 93.7500 (95.0977)  time: 0.3455  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 380/3750]  eta: 0:19:24  Lr: 0.030000  Loss: 0.1516  Acc@1: 75.0000 (77.1654)  Acc@5: 93.7500 (95.0951)  time: 0.3452  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [ 390/3750]  eta: 0:19:20  Lr: 0.030000  Loss: -0.2291  Acc@1: 75.0000 (77.0780)  Acc@5: 93.7500 (94.9968)  time: 0.3453  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [ 400/3750]  eta: 0:19:17  Lr: 0.030000  Loss: -0.2172  Acc@1: 75.0000 (76.8859)  Acc@5: 93.7500 (95.0125)  time: 0.3451  data: 0.0002  max mem: 2500
Train: Epoch[3/5]  [ 410/3750]  eta: 0:19:13  Lr: 0.030000  Loss: -0.0126  Acc@1: 68.7500 (76.7640)  Acc@5: 93.7500 (94.9818)  time: 0.3448  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [ 420/3750]  eta: 0:19:10  Lr: 0.030000  Loss: -0.0468  Acc@1: 68.7500 (76.7072)  Acc@5: 93.7500 (94.9822)  time: 0.3447  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [ 430/3750]  eta: 0:19:06  Lr: 0.030000  Loss: -0.3273  Acc@1: 75.0000 (76.8416)  Acc@5: 93.7500 (94.9971)  time: 0.3447  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [ 440/3750]  eta: 0:19:03  Lr: 0.030000  Loss: -0.5586  Acc@1: 81.2500 (76.9416)  Acc@5: 93.7500 (95.0255)  time: 0.3442  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [ 450/3750]  eta: 0:18:59  Lr: 0.030000  Loss: -0.3302  Acc@1: 81.2500 (76.9678)  Acc@5: 93.7500 (95.0527)  time: 0.3432  data: 0.0002  max mem: 2500
Train: Epoch[3/5]  [ 460/3750]  eta: 0:18:55  Lr: 0.030000  Loss: -0.4121  Acc@1: 81.2500 (77.0879)  Acc@5: 100.0000 (95.1193)  time: 0.3431  data: 0.0002  max mem: 2500
Train: Epoch[3/5]  [ 470/3750]  eta: 0:18:52  Lr: 0.030000  Loss: -0.4841  Acc@1: 81.2500 (77.0966)  Acc@5: 100.0000 (95.1300)  time: 0.3431  data: 0.0002  max mem: 2500
Train: Epoch[3/5]  [ 480/3750]  eta: 0:18:48  Lr: 0.030000  Loss: -0.3139  Acc@1: 75.0000 (77.0790)  Acc@5: 93.7500 (95.1273)  time: 0.3431  data: 0.0002  max mem: 2500
Train: Epoch[3/5]  [ 490/3750]  eta: 0:18:44  Lr: 0.030000  Loss: -0.5699  Acc@1: 75.0000 (77.1640)  Acc@5: 93.7500 (95.0993)  time: 0.3430  data: 0.0002  max mem: 2500
Train: Epoch[3/5]  [ 500/3750]  eta: 0:18:41  Lr: 0.030000  Loss: -0.0295  Acc@1: 81.2500 (77.1707)  Acc@5: 100.0000 (95.1472)  time: 0.3437  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [ 510/3750]  eta: 0:18:38  Lr: 0.030000  Loss: -0.0863  Acc@1: 75.0000 (77.0059)  Acc@5: 93.7500 (95.1199)  time: 0.3445  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [ 520/3750]  eta: 0:18:34  Lr: 0.030000  Loss: -0.4629  Acc@1: 75.0000 (77.0274)  Acc@5: 93.7500 (95.0936)  time: 0.3448  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 530/3750]  eta: 0:18:31  Lr: 0.030000  Loss: 0.1594  Acc@1: 81.2500 (77.0009)  Acc@5: 93.7500 (95.0565)  time: 0.3452  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 540/3750]  eta: 0:18:27  Lr: 0.030000  Loss: -0.3678  Acc@1: 75.0000 (76.9755)  Acc@5: 93.7500 (95.0670)  time: 0.3449  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 550/3750]  eta: 0:18:24  Lr: 0.030000  Loss: -0.4227  Acc@1: 75.0000 (77.0191)  Acc@5: 93.7500 (95.0431)  time: 0.3448  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 560/3750]  eta: 0:18:20  Lr: 0.030000  Loss: -0.5297  Acc@1: 81.2500 (77.0499)  Acc@5: 93.7500 (95.0312)  time: 0.3448  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 570/3750]  eta: 0:18:17  Lr: 0.030000  Loss: -0.1763  Acc@1: 75.0000 (77.0359)  Acc@5: 93.7500 (95.0744)  time: 0.3454  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [ 580/3750]  eta: 0:18:13  Lr: 0.030000  Loss: -0.3897  Acc@1: 75.0000 (77.0439)  Acc@5: 100.0000 (95.0731)  time: 0.3466  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 590/3750]  eta: 0:18:10  Lr: 0.030000  Loss: -0.3641  Acc@1: 75.0000 (77.0728)  Acc@5: 93.7500 (95.0719)  time: 0.3459  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 600/3750]  eta: 0:18:07  Lr: 0.030000  Loss: -0.1359  Acc@1: 75.0000 (77.0695)  Acc@5: 93.7500 (95.0811)  time: 0.3449  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [ 610/3750]  eta: 0:18:03  Lr: 0.030000  Loss: -0.2969  Acc@1: 75.0000 (77.0561)  Acc@5: 100.0000 (95.1002)  time: 0.3456  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [ 620/3750]  eta: 0:18:00  Lr: 0.030000  Loss: -0.5396  Acc@1: 75.0000 (77.0733)  Acc@5: 100.0000 (95.1490)  time: 0.3451  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [ 630/3750]  eta: 0:17:56  Lr: 0.030000  Loss: -0.0164  Acc@1: 81.2500 (77.1296)  Acc@5: 100.0000 (95.1763)  time: 0.3439  data: 0.0002  max mem: 2500
Train: Epoch[3/5]  [ 640/3750]  eta: 0:17:53  Lr: 0.030000  Loss: -0.2069  Acc@1: 75.0000 (77.0573)  Acc@5: 93.7500 (95.1638)  time: 0.3435  data: 0.0002  max mem: 2500
Train: Epoch[3/5]  [ 650/3750]  eta: 0:17:49  Lr: 0.030000  Loss: -0.5356  Acc@1: 75.0000 (77.0833)  Acc@5: 93.7500 (95.1517)  time: 0.3452  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [ 660/3750]  eta: 0:17:46  Lr: 0.030000  Loss: -0.2792  Acc@1: 81.2500 (77.1369)  Acc@5: 100.0000 (95.1967)  time: 0.3458  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 670/3750]  eta: 0:17:42  Lr: 0.030000  Loss: 0.1640  Acc@1: 75.0000 (77.0958)  Acc@5: 100.0000 (95.1751)  time: 0.3448  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 680/3750]  eta: 0:17:39  Lr: 0.030000  Loss: -0.5020  Acc@1: 75.0000 (77.0650)  Acc@5: 93.7500 (95.1817)  time: 0.3444  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [ 690/3750]  eta: 0:17:35  Lr: 0.030000  Loss: -0.3781  Acc@1: 75.0000 (77.0713)  Acc@5: 93.7500 (95.1881)  time: 0.3442  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [ 700/3750]  eta: 0:17:32  Lr: 0.030000  Loss: -0.7034  Acc@1: 75.0000 (77.0774)  Acc@5: 100.0000 (95.1944)  time: 0.3454  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 710/3750]  eta: 0:17:28  Lr: 0.030000  Loss: -0.1736  Acc@1: 75.0000 (77.0042)  Acc@5: 100.0000 (95.1916)  time: 0.3454  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 720/3750]  eta: 0:17:25  Lr: 0.030000  Loss: -0.0588  Acc@1: 75.0000 (77.0198)  Acc@5: 100.0000 (95.1890)  time: 0.3458  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [ 730/3750]  eta: 0:17:22  Lr: 0.030000  Loss: -0.4179  Acc@1: 75.0000 (76.9750)  Acc@5: 100.0000 (95.1607)  time: 0.3448  data: 0.0002  max mem: 2500
Train: Epoch[3/5]  [ 740/3750]  eta: 0:17:18  Lr: 0.030000  Loss: -0.2108  Acc@1: 75.0000 (76.9399)  Acc@5: 93.7500 (95.1164)  time: 0.3428  data: 0.0002  max mem: 2500
Train: Epoch[3/5]  [ 750/3750]  eta: 0:17:14  Lr: 0.030000  Loss: -0.5177  Acc@1: 81.2500 (77.0057)  Acc@5: 93.7500 (95.1565)  time: 0.3429  data: 0.0002  max mem: 2500
Train: Epoch[3/5]  [ 760/3750]  eta: 0:17:11  Lr: 0.030000  Loss: -0.4052  Acc@1: 81.2500 (76.9793)  Acc@5: 100.0000 (95.1626)  time: 0.3432  data: 0.0002  max mem: 2500
Train: Epoch[3/5]  [ 770/3750]  eta: 0:17:07  Lr: 0.030000  Loss: -0.3043  Acc@1: 75.0000 (77.0509)  Acc@5: 100.0000 (95.1929)  time: 0.3433  data: 0.0002  max mem: 2500
Train: Epoch[3/5]  [ 780/3750]  eta: 0:17:04  Lr: 0.030000  Loss: -0.3886  Acc@1: 81.2500 (77.0887)  Acc@5: 93.7500 (95.2065)  time: 0.3431  data: 0.0002  max mem: 2500
Train: Epoch[3/5]  [ 790/3750]  eta: 0:17:00  Lr: 0.030000  Loss: -0.2892  Acc@1: 81.2500 (77.0702)  Acc@5: 100.0000 (95.2513)  time: 0.3430  data: 0.0002  max mem: 2500
Train: Epoch[3/5]  [ 800/3750]  eta: 0:16:57  Lr: 0.030000  Loss: -0.2981  Acc@1: 68.7500 (76.9975)  Acc@5: 100.0000 (95.2403)  time: 0.3441  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [ 810/3750]  eta: 0:16:54  Lr: 0.030000  Loss: -0.0240  Acc@1: 68.7500 (76.9575)  Acc@5: 93.7500 (95.2528)  time: 0.3459  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 820/3750]  eta: 0:16:50  Lr: 0.030000  Loss: -0.3676  Acc@1: 75.0000 (76.9717)  Acc@5: 93.7500 (95.2573)  time: 0.3459  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 830/3750]  eta: 0:16:47  Lr: 0.030000  Loss: -0.3307  Acc@1: 75.0000 (76.9480)  Acc@5: 100.0000 (95.2843)  time: 0.3445  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 840/3750]  eta: 0:16:43  Lr: 0.030000  Loss: -0.1449  Acc@1: 75.0000 (76.9174)  Acc@5: 100.0000 (95.2958)  time: 0.3450  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 850/3750]  eta: 0:16:40  Lr: 0.030000  Loss: -0.3116  Acc@1: 75.0000 (76.9169)  Acc@5: 100.0000 (95.3217)  time: 0.3454  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 860/3750]  eta: 0:16:36  Lr: 0.030000  Loss: -0.4227  Acc@1: 75.0000 (76.8946)  Acc@5: 93.7500 (95.3107)  time: 0.3454  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 870/3750]  eta: 0:16:33  Lr: 0.030000  Loss: -0.3644  Acc@1: 81.2500 (76.9159)  Acc@5: 93.7500 (95.3215)  time: 0.3458  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 880/3750]  eta: 0:16:30  Lr: 0.030000  Loss: -0.2070  Acc@1: 75.0000 (76.8729)  Acc@5: 100.0000 (95.3178)  time: 0.3459  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 890/3750]  eta: 0:16:26  Lr: 0.030000  Loss: -0.3845  Acc@1: 68.7500 (76.7817)  Acc@5: 93.7500 (95.2792)  time: 0.3468  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 900/3750]  eta: 0:16:23  Lr: 0.030000  Loss: 0.0465  Acc@1: 75.0000 (76.7689)  Acc@5: 93.7500 (95.3108)  time: 0.3459  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 910/3750]  eta: 0:16:19  Lr: 0.030000  Loss: -0.3393  Acc@1: 75.0000 (76.7563)  Acc@5: 100.0000 (95.3211)  time: 0.3447  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 920/3750]  eta: 0:16:16  Lr: 0.030000  Loss: -0.3590  Acc@1: 75.0000 (76.7847)  Acc@5: 100.0000 (95.3379)  time: 0.3452  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 930/3750]  eta: 0:16:12  Lr: 0.030000  Loss: -0.5465  Acc@1: 75.0000 (76.7454)  Acc@5: 100.0000 (95.3612)  time: 0.3450  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 940/3750]  eta: 0:16:09  Lr: 0.030000  Loss: -0.3676  Acc@1: 75.0000 (76.7335)  Acc@5: 93.7500 (95.3440)  time: 0.3451  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [ 950/3750]  eta: 0:16:05  Lr: 0.030000  Loss: -0.1742  Acc@1: 75.0000 (76.7087)  Acc@5: 93.7500 (95.3207)  time: 0.3455  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [ 960/3750]  eta: 0:16:02  Lr: 0.030000  Loss: -0.2673  Acc@1: 75.0000 (76.7365)  Acc@5: 93.7500 (95.3109)  time: 0.3455  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [ 970/3750]  eta: 0:15:59  Lr: 0.030000  Loss: -0.5451  Acc@1: 75.0000 (76.7701)  Acc@5: 93.7500 (95.3205)  time: 0.3448  data: 0.0002  max mem: 2500
Train: Epoch[3/5]  [ 980/3750]  eta: 0:15:55  Lr: 0.030000  Loss: -0.5485  Acc@1: 75.0000 (76.7266)  Acc@5: 100.0000 (95.3428)  time: 0.3437  data: 0.0002  max mem: 2500
Train: Epoch[3/5]  [ 990/3750]  eta: 0:15:52  Lr: 0.030000  Loss: -0.3679  Acc@1: 75.0000 (76.7659)  Acc@5: 100.0000 (95.3456)  time: 0.3439  data: 0.0002  max mem: 2500
Train: Epoch[3/5]  [1000/3750]  eta: 0:15:48  Lr: 0.030000  Loss: -0.4199  Acc@1: 81.2500 (76.7295)  Acc@5: 93.7500 (95.3297)  time: 0.3446  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [1010/3750]  eta: 0:15:45  Lr: 0.030000  Loss: -0.2090  Acc@1: 75.0000 (76.7248)  Acc@5: 93.7500 (95.3326)  time: 0.3451  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [1020/3750]  eta: 0:15:41  Lr: 0.030000  Loss: -0.0935  Acc@1: 81.2500 (76.7446)  Acc@5: 93.7500 (95.3416)  time: 0.3456  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1030/3750]  eta: 0:15:38  Lr: 0.030000  Loss: -0.3300  Acc@1: 75.0000 (76.7216)  Acc@5: 93.7500 (95.3443)  time: 0.3454  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [1040/3750]  eta: 0:15:34  Lr: 0.030000  Loss: -0.1770  Acc@1: 75.0000 (76.7051)  Acc@5: 93.7500 (95.3230)  time: 0.3452  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [1050/3750]  eta: 0:15:31  Lr: 0.030000  Loss: -0.4171  Acc@1: 75.0000 (76.6889)  Acc@5: 93.7500 (95.3199)  time: 0.3461  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [1060/3750]  eta: 0:15:28  Lr: 0.030000  Loss: -0.4523  Acc@1: 81.2500 (76.7319)  Acc@5: 100.0000 (95.3405)  time: 0.3461  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [1070/3750]  eta: 0:15:24  Lr: 0.030000  Loss: -0.3219  Acc@1: 81.2500 (76.7390)  Acc@5: 93.7500 (95.3315)  time: 0.3463  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1080/3750]  eta: 0:15:21  Lr: 0.030000  Loss: -0.4195  Acc@1: 75.0000 (76.7576)  Acc@5: 93.7500 (95.3400)  time: 0.3458  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1090/3750]  eta: 0:15:17  Lr: 0.030000  Loss: -0.3924  Acc@1: 75.0000 (76.7587)  Acc@5: 100.0000 (95.3368)  time: 0.3445  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [1100/3750]  eta: 0:15:14  Lr: 0.030000  Loss: -0.2102  Acc@1: 75.0000 (76.7654)  Acc@5: 93.7500 (95.3451)  time: 0.3442  data: 0.0002  max mem: 2500
Train: Epoch[3/5]  [1110/3750]  eta: 0:15:10  Lr: 0.030000  Loss: -0.3552  Acc@1: 75.0000 (76.7439)  Acc@5: 93.7500 (95.3645)  time: 0.3445  data: 0.0002  max mem: 2500
Train: Epoch[3/5]  [1120/3750]  eta: 0:15:07  Lr: 0.030000  Loss: -0.1527  Acc@1: 75.0000 (76.7841)  Acc@5: 100.0000 (95.3780)  time: 0.3445  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [1130/3750]  eta: 0:15:03  Lr: 0.030000  Loss: -0.1930  Acc@1: 75.0000 (76.8015)  Acc@5: 100.0000 (95.3747)  time: 0.3442  data: 0.0002  max mem: 2500
Train: Epoch[3/5]  [1140/3750]  eta: 0:15:00  Lr: 0.030000  Loss: -0.4532  Acc@1: 75.0000 (76.8076)  Acc@5: 93.7500 (95.3769)  time: 0.3434  data: 0.0002  max mem: 2500
Train: Epoch[3/5]  [1150/3750]  eta: 0:14:56  Lr: 0.030000  Loss: -0.4937  Acc@1: 81.2500 (76.7974)  Acc@5: 93.7500 (95.3790)  time: 0.3440  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [1160/3750]  eta: 0:14:53  Lr: 0.030000  Loss: -0.4595  Acc@1: 75.0000 (76.7980)  Acc@5: 100.0000 (95.3758)  time: 0.3452  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [1170/3750]  eta: 0:14:50  Lr: 0.030000  Loss: -0.1121  Acc@1: 75.0000 (76.8094)  Acc@5: 93.7500 (95.3565)  time: 0.3449  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1180/3750]  eta: 0:14:46  Lr: 0.030000  Loss: -0.4420  Acc@1: 81.2500 (76.8417)  Acc@5: 100.0000 (95.3800)  time: 0.3448  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1190/3750]  eta: 0:14:43  Lr: 0.030000  Loss: -0.4185  Acc@1: 81.2500 (76.8419)  Acc@5: 93.7500 (95.3558)  time: 0.3453  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [1200/3750]  eta: 0:14:39  Lr: 0.030000  Loss: -0.5948  Acc@1: 81.2500 (76.8838)  Acc@5: 93.7500 (95.3632)  time: 0.3455  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [1210/3750]  eta: 0:14:36  Lr: 0.030000  Loss: -0.1270  Acc@1: 75.0000 (76.8735)  Acc@5: 100.0000 (95.3757)  time: 0.3456  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1220/3750]  eta: 0:14:32  Lr: 0.030000  Loss: -0.4657  Acc@1: 75.0000 (76.8837)  Acc@5: 93.7500 (95.3726)  time: 0.3450  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1230/3750]  eta: 0:14:29  Lr: 0.030000  Loss: -0.3799  Acc@1: 75.0000 (76.8481)  Acc@5: 93.7500 (95.3442)  time: 0.3454  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1240/3750]  eta: 0:14:25  Lr: 0.030000  Loss: -0.5857  Acc@1: 75.0000 (76.8634)  Acc@5: 93.7500 (95.3314)  time: 0.3456  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1250/3750]  eta: 0:14:22  Lr: 0.030000  Loss: -0.2256  Acc@1: 75.0000 (76.8485)  Acc@5: 93.7500 (95.3137)  time: 0.3444  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1260/3750]  eta: 0:14:18  Lr: 0.030000  Loss: -0.4293  Acc@1: 75.0000 (76.8933)  Acc@5: 93.7500 (95.3261)  time: 0.3443  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1270/3750]  eta: 0:14:15  Lr: 0.030000  Loss: -0.3991  Acc@1: 81.2500 (76.9178)  Acc@5: 100.0000 (95.3285)  time: 0.3447  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [1280/3750]  eta: 0:14:12  Lr: 0.030000  Loss: -0.6350  Acc@1: 75.0000 (76.9272)  Acc@5: 100.0000 (95.3357)  time: 0.3453  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1290/3750]  eta: 0:14:08  Lr: 0.030000  Loss: -0.0878  Acc@1: 75.0000 (76.9268)  Acc@5: 93.7500 (95.3282)  time: 0.3451  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1300/3750]  eta: 0:14:05  Lr: 0.030000  Loss: -0.3614  Acc@1: 75.0000 (76.8784)  Acc@5: 93.7500 (95.2921)  time: 0.3447  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1310/3750]  eta: 0:14:01  Lr: 0.030000  Loss: -0.1341  Acc@1: 75.0000 (76.8974)  Acc@5: 93.7500 (95.3089)  time: 0.3448  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [1320/3750]  eta: 0:13:58  Lr: 0.030000  Loss: -0.0028  Acc@1: 75.0000 (76.8830)  Acc@5: 93.7500 (95.3066)  time: 0.3447  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [1330/3750]  eta: 0:13:54  Lr: 0.030000  Loss: -0.0839  Acc@1: 81.2500 (76.9065)  Acc@5: 93.7500 (95.2902)  time: 0.3449  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [1340/3750]  eta: 0:13:51  Lr: 0.030000  Loss: -0.5119  Acc@1: 75.0000 (76.8922)  Acc@5: 93.7500 (95.2974)  time: 0.3448  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [1350/3750]  eta: 0:13:47  Lr: 0.030000  Loss: -0.2666  Acc@1: 75.0000 (76.9199)  Acc@5: 100.0000 (95.3137)  time: 0.3443  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [1360/3750]  eta: 0:13:44  Lr: 0.030000  Loss: -0.1054  Acc@1: 75.0000 (76.9058)  Acc@5: 100.0000 (95.3251)  time: 0.3444  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [1370/3750]  eta: 0:13:41  Lr: 0.030000  Loss: -0.2048  Acc@1: 75.0000 (76.9648)  Acc@5: 100.0000 (95.3410)  time: 0.3448  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [1380/3750]  eta: 0:13:37  Lr: 0.030000  Loss: -0.0890  Acc@1: 75.0000 (76.9642)  Acc@5: 100.0000 (95.3295)  time: 0.3450  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [1390/3750]  eta: 0:13:34  Lr: 0.030000  Loss: -0.4697  Acc@1: 75.0000 (76.9635)  Acc@5: 100.0000 (95.3496)  time: 0.3434  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [1400/3750]  eta: 0:13:30  Lr: 0.030000  Loss: -0.4941  Acc@1: 75.0000 (76.9540)  Acc@5: 93.7500 (95.3337)  time: 0.3424  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [1410/3750]  eta: 0:13:27  Lr: 0.030000  Loss: -0.3442  Acc@1: 75.0000 (76.9578)  Acc@5: 93.7500 (95.3269)  time: 0.3425  data: 0.0002  max mem: 2500
Train: Epoch[3/5]  [1420/3750]  eta: 0:13:23  Lr: 0.030000  Loss: -0.3657  Acc@1: 75.0000 (76.9836)  Acc@5: 93.7500 (95.3158)  time: 0.3425  data: 0.0002  max mem: 2500
Train: Epoch[3/5]  [1430/3750]  eta: 0:13:20  Lr: 0.030000  Loss: -0.3164  Acc@1: 81.2500 (77.0309)  Acc@5: 93.7500 (95.3267)  time: 0.3426  data: 0.0002  max mem: 2500
Train: Epoch[3/5]  [1440/3750]  eta: 0:13:16  Lr: 0.030000  Loss: -0.3787  Acc@1: 81.2500 (77.0429)  Acc@5: 100.0000 (95.3548)  time: 0.3425  data: 0.0002  max mem: 2500
Train: Epoch[3/5]  [1450/3750]  eta: 0:13:13  Lr: 0.030000  Loss: -0.4136  Acc@1: 81.2500 (77.0331)  Acc@5: 100.0000 (95.3567)  time: 0.3425  data: 0.0002  max mem: 2500
Train: Epoch[3/5]  [1460/3750]  eta: 0:13:09  Lr: 0.030000  Loss: -0.4561  Acc@1: 75.0000 (77.0662)  Acc@5: 93.7500 (95.3628)  time: 0.3426  data: 0.0002  max mem: 2500
Train: Epoch[3/5]  [1470/3750]  eta: 0:13:06  Lr: 0.030000  Loss: 0.2527  Acc@1: 75.0000 (77.0437)  Acc@5: 100.0000 (95.3688)  time: 0.3436  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [1480/3750]  eta: 0:13:02  Lr: 0.030000  Loss: -0.3987  Acc@1: 75.0000 (77.0636)  Acc@5: 100.0000 (95.3747)  time: 0.3445  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [1490/3750]  eta: 0:12:59  Lr: 0.030000  Loss: -0.3080  Acc@1: 75.0000 (77.0288)  Acc@5: 93.7500 (95.3680)  time: 0.3446  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [1500/3750]  eta: 0:12:55  Lr: 0.030000  Loss: -0.2048  Acc@1: 68.7500 (76.9903)  Acc@5: 93.7500 (95.3739)  time: 0.3451  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [1510/3750]  eta: 0:12:52  Lr: 0.030000  Loss: -0.5278  Acc@1: 68.7500 (76.9896)  Acc@5: 93.7500 (95.3632)  time: 0.3450  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [1520/3750]  eta: 0:12:48  Lr: 0.030000  Loss: -0.2947  Acc@1: 75.0000 (77.0012)  Acc@5: 93.7500 (95.3526)  time: 0.3444  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [1530/3750]  eta: 0:12:45  Lr: 0.030000  Loss: 0.0266  Acc@1: 75.0000 (76.9881)  Acc@5: 93.7500 (95.3421)  time: 0.3436  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [1540/3750]  eta: 0:12:42  Lr: 0.030000  Loss: -0.1842  Acc@1: 75.0000 (76.9914)  Acc@5: 93.7500 (95.3520)  time: 0.3441  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1550/3750]  eta: 0:12:38  Lr: 0.030000  Loss: -0.5300  Acc@1: 75.0000 (76.9947)  Acc@5: 93.7500 (95.3377)  time: 0.3441  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1560/3750]  eta: 0:12:35  Lr: 0.030000  Loss: -0.4319  Acc@1: 75.0000 (77.0099)  Acc@5: 93.7500 (95.3355)  time: 0.3435  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1570/3750]  eta: 0:12:31  Lr: 0.030000  Loss: -0.0345  Acc@1: 81.2500 (77.0170)  Acc@5: 93.7500 (95.3334)  time: 0.3444  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1580/3750]  eta: 0:12:28  Lr: 0.030000  Loss: -0.1757  Acc@1: 81.2500 (77.0517)  Acc@5: 93.7500 (95.3510)  time: 0.3444  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1590/3750]  eta: 0:12:24  Lr: 0.030000  Loss: 0.0234  Acc@1: 81.2500 (77.0467)  Acc@5: 100.0000 (95.3449)  time: 0.3442  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1600/3750]  eta: 0:12:21  Lr: 0.030000  Loss: -0.2824  Acc@1: 75.0000 (77.0378)  Acc@5: 100.0000 (95.3506)  time: 0.3452  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1610/3750]  eta: 0:12:17  Lr: 0.030000  Loss: -0.7234  Acc@1: 75.0000 (77.0290)  Acc@5: 93.7500 (95.3484)  time: 0.3461  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1620/3750]  eta: 0:12:14  Lr: 0.030000  Loss: -0.0170  Acc@1: 81.2500 (77.0358)  Acc@5: 93.7500 (95.3578)  time: 0.3463  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1630/3750]  eta: 0:12:11  Lr: 0.030000  Loss: -0.3607  Acc@1: 81.2500 (77.0425)  Acc@5: 93.7500 (95.3211)  time: 0.3462  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1640/3750]  eta: 0:12:07  Lr: 0.030000  Loss: -0.3581  Acc@1: 75.0000 (77.0186)  Acc@5: 87.5000 (95.2963)  time: 0.3453  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1650/3750]  eta: 0:12:04  Lr: 0.030000  Loss: -0.4310  Acc@1: 75.0000 (77.0253)  Acc@5: 93.7500 (95.3172)  time: 0.3443  data: 0.0002  max mem: 2500
Train: Epoch[3/5]  [1660/3750]  eta: 0:12:00  Lr: 0.030000  Loss: -0.1423  Acc@1: 75.0000 (77.0319)  Acc@5: 100.0000 (95.3153)  time: 0.3447  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [1670/3750]  eta: 0:11:57  Lr: 0.030000  Loss: -0.2917  Acc@1: 81.2500 (77.0572)  Acc@5: 100.0000 (95.3284)  time: 0.3449  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [1680/3750]  eta: 0:11:53  Lr: 0.030000  Loss: -0.5681  Acc@1: 81.2500 (77.0970)  Acc@5: 100.0000 (95.3488)  time: 0.3447  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [1690/3750]  eta: 0:11:50  Lr: 0.030000  Loss: -0.2965  Acc@1: 81.2500 (77.0920)  Acc@5: 100.0000 (95.3467)  time: 0.3447  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [1700/3750]  eta: 0:11:46  Lr: 0.030000  Loss: -0.2111  Acc@1: 75.0000 (77.0944)  Acc@5: 93.7500 (95.3373)  time: 0.3449  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [1710/3750]  eta: 0:11:43  Lr: 0.030000  Loss: -0.0656  Acc@1: 75.0000 (77.1223)  Acc@5: 93.7500 (95.3426)  time: 0.3461  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [1720/3750]  eta: 0:11:39  Lr: 0.030000  Loss: -0.6324  Acc@1: 81.2500 (77.1499)  Acc@5: 93.7500 (95.3298)  time: 0.3450  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [1730/3750]  eta: 0:11:36  Lr: 0.030000  Loss: -0.2151  Acc@1: 75.0000 (77.1267)  Acc@5: 93.7500 (95.3387)  time: 0.3428  data: 0.0002  max mem: 2500
Train: Epoch[3/5]  [1740/3750]  eta: 0:11:33  Lr: 0.030000  Loss: -0.1497  Acc@1: 75.0000 (77.1216)  Acc@5: 93.7500 (95.3152)  time: 0.3428  data: 0.0002  max mem: 2500
Train: Epoch[3/5]  [1750/3750]  eta: 0:11:29  Lr: 0.030000  Loss: -0.1901  Acc@1: 81.2500 (77.1095)  Acc@5: 93.7500 (95.3134)  time: 0.3434  data: 0.0002  max mem: 2500
Train: Epoch[3/5]  [1760/3750]  eta: 0:11:26  Lr: 0.030000  Loss: -0.3925  Acc@1: 75.0000 (77.1188)  Acc@5: 100.0000 (95.3152)  time: 0.3433  data: 0.0002  max mem: 2500
Train: Epoch[3/5]  [1770/3750]  eta: 0:11:22  Lr: 0.030000  Loss: -0.4158  Acc@1: 75.0000 (77.1280)  Acc@5: 100.0000 (95.3204)  time: 0.3432  data: 0.0002  max mem: 2500
Train: Epoch[3/5]  [1780/3750]  eta: 0:11:19  Lr: 0.030000  Loss: -0.1127  Acc@1: 75.0000 (77.1056)  Acc@5: 100.0000 (95.3186)  time: 0.3433  data: 0.0002  max mem: 2500
Train: Epoch[3/5]  [1790/3750]  eta: 0:11:15  Lr: 0.030000  Loss: -0.1308  Acc@1: 75.0000 (77.1392)  Acc@5: 93.7500 (95.3273)  time: 0.3433  data: 0.0002  max mem: 2500
Train: Epoch[3/5]  [1800/3750]  eta: 0:11:12  Lr: 0.030000  Loss: -0.1792  Acc@1: 81.2500 (77.1620)  Acc@5: 93.7500 (95.3220)  time: 0.3441  data: 0.0002  max mem: 2500
Train: Epoch[3/5]  [1810/3750]  eta: 0:11:08  Lr: 0.030000  Loss: -0.2543  Acc@1: 81.2500 (77.1708)  Acc@5: 93.7500 (95.3134)  time: 0.3452  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [1820/3750]  eta: 0:11:05  Lr: 0.030000  Loss: -0.2718  Acc@1: 81.2500 (77.1897)  Acc@5: 100.0000 (95.3254)  time: 0.3464  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1830/3750]  eta: 0:11:01  Lr: 0.030000  Loss: -0.5222  Acc@1: 81.2500 (77.2256)  Acc@5: 100.0000 (95.3441)  time: 0.3465  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [1840/3750]  eta: 0:10:58  Lr: 0.030000  Loss: -0.4851  Acc@1: 81.2500 (77.2203)  Acc@5: 100.0000 (95.3422)  time: 0.3458  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [1850/3750]  eta: 0:10:55  Lr: 0.030000  Loss: -0.4043  Acc@1: 75.0000 (77.2285)  Acc@5: 93.7500 (95.3471)  time: 0.3459  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1860/3750]  eta: 0:10:51  Lr: 0.030000  Loss: -0.3482  Acc@1: 75.0000 (77.1998)  Acc@5: 93.7500 (95.3452)  time: 0.3456  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1870/3750]  eta: 0:10:48  Lr: 0.030000  Loss: -0.3381  Acc@1: 75.0000 (77.2014)  Acc@5: 93.7500 (95.3467)  time: 0.3460  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1880/3750]  eta: 0:10:44  Lr: 0.030000  Loss: -0.1839  Acc@1: 75.0000 (77.1730)  Acc@5: 93.7500 (95.3316)  time: 0.3462  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1890/3750]  eta: 0:10:41  Lr: 0.030000  Loss: -0.2217  Acc@1: 75.0000 (77.1781)  Acc@5: 93.7500 (95.3299)  time: 0.3468  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1900/3750]  eta: 0:10:37  Lr: 0.030000  Loss: -0.0515  Acc@1: 75.0000 (77.1535)  Acc@5: 100.0000 (95.3281)  time: 0.3462  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1910/3750]  eta: 0:10:34  Lr: 0.030000  Loss: -0.2029  Acc@1: 75.0000 (77.1422)  Acc@5: 100.0000 (95.3362)  time: 0.3447  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [1920/3750]  eta: 0:10:31  Lr: 0.030000  Loss: -0.4741  Acc@1: 75.0000 (77.1245)  Acc@5: 100.0000 (95.3475)  time: 0.3452  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [1930/3750]  eta: 0:10:27  Lr: 0.030000  Loss: -0.4265  Acc@1: 81.2500 (77.1394)  Acc@5: 100.0000 (95.3521)  time: 0.3452  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1940/3750]  eta: 0:10:24  Lr: 0.030000  Loss: -0.5581  Acc@1: 81.2500 (77.1413)  Acc@5: 100.0000 (95.3632)  time: 0.3452  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1950/3750]  eta: 0:10:20  Lr: 0.030000  Loss: -0.4610  Acc@1: 81.2500 (77.1527)  Acc@5: 100.0000 (95.3549)  time: 0.3462  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1960/3750]  eta: 0:10:17  Lr: 0.030000  Loss: -0.4371  Acc@1: 81.2500 (77.1481)  Acc@5: 93.7500 (95.3468)  time: 0.3462  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1970/3750]  eta: 0:10:13  Lr: 0.030000  Loss: -0.3070  Acc@1: 81.2500 (77.1404)  Acc@5: 93.7500 (95.3418)  time: 0.3453  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1980/3750]  eta: 0:10:10  Lr: 0.030000  Loss: -0.0193  Acc@1: 75.0000 (77.1265)  Acc@5: 93.7500 (95.3306)  time: 0.3506  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1990/3750]  eta: 0:10:07  Lr: 0.030000  Loss: -0.3281  Acc@1: 75.0000 (77.1189)  Acc@5: 93.7500 (95.3227)  time: 0.3506  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2000/3750]  eta: 0:10:03  Lr: 0.030000  Loss: -0.4032  Acc@1: 75.0000 (77.1239)  Acc@5: 93.7500 (95.3148)  time: 0.3451  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [2010/3750]  eta: 0:10:00  Lr: 0.030000  Loss: -0.5172  Acc@1: 75.0000 (77.1009)  Acc@5: 93.7500 (95.3164)  time: 0.3448  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [2020/3750]  eta: 0:09:56  Lr: 0.030000  Loss: -0.4622  Acc@1: 75.0000 (77.0936)  Acc@5: 100.0000 (95.3117)  time: 0.3451  data: 0.0002  max mem: 2500
Train: Epoch[3/5]  [2030/3750]  eta: 0:09:53  Lr: 0.030000  Loss: -0.3820  Acc@1: 81.2500 (77.1172)  Acc@5: 93.7500 (95.3225)  time: 0.3451  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [2040/3750]  eta: 0:09:49  Lr: 0.030000  Loss: -0.3565  Acc@1: 81.2500 (77.1068)  Acc@5: 93.7500 (95.3148)  time: 0.3446  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [2050/3750]  eta: 0:09:46  Lr: 0.030000  Loss: -0.1833  Acc@1: 81.2500 (77.1301)  Acc@5: 93.7500 (95.3133)  time: 0.3451  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [2060/3750]  eta: 0:09:42  Lr: 0.030000  Loss: -0.1812  Acc@1: 81.2500 (77.1440)  Acc@5: 93.7500 (95.3208)  time: 0.3444  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [2070/3750]  eta: 0:09:39  Lr: 0.030000  Loss: -0.4902  Acc@1: 81.2500 (77.1517)  Acc@5: 93.7500 (95.3072)  time: 0.3431  data: 0.0002  max mem: 2500
Train: Epoch[3/5]  [2080/3750]  eta: 0:09:35  Lr: 0.030000  Loss: -0.2273  Acc@1: 75.0000 (77.1504)  Acc@5: 93.7500 (95.2967)  time: 0.3431  data: 0.0002  max mem: 2500
Train: Epoch[3/5]  [2090/3750]  eta: 0:09:32  Lr: 0.030000  Loss: -0.2871  Acc@1: 81.2500 (77.1670)  Acc@5: 93.7500 (95.3013)  time: 0.3437  data: 0.0002  max mem: 2500
Train: Epoch[3/5]  [2100/3750]  eta: 0:09:29  Lr: 0.030000  Loss: -0.0864  Acc@1: 75.0000 (77.1418)  Acc@5: 93.7500 (95.3058)  time: 0.3449  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [2110/3750]  eta: 0:09:25  Lr: 0.030000  Loss: -0.2399  Acc@1: 75.0000 (77.1435)  Acc@5: 93.7500 (95.3014)  time: 0.3455  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2120/3750]  eta: 0:09:22  Lr: 0.030000  Loss: -0.7781  Acc@1: 75.0000 (77.1452)  Acc@5: 100.0000 (95.3059)  time: 0.3450  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2130/3750]  eta: 0:09:18  Lr: 0.030000  Loss: -0.1719  Acc@1: 75.0000 (77.1351)  Acc@5: 100.0000 (95.3103)  time: 0.3446  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2140/3750]  eta: 0:09:15  Lr: 0.030000  Loss: -0.2009  Acc@1: 75.0000 (77.1223)  Acc@5: 93.7500 (95.2972)  time: 0.3459  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2150/3750]  eta: 0:09:11  Lr: 0.030000  Loss: -0.2993  Acc@1: 81.2500 (77.1444)  Acc@5: 93.7500 (95.2987)  time: 0.3458  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [2160/3750]  eta: 0:09:08  Lr: 0.030000  Loss: -0.1892  Acc@1: 81.2500 (77.1547)  Acc@5: 93.7500 (95.3031)  time: 0.3445  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [2170/3750]  eta: 0:09:04  Lr: 0.030000  Loss: -0.4510  Acc@1: 81.2500 (77.1591)  Acc@5: 93.7500 (95.3017)  time: 0.3447  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [2180/3750]  eta: 0:09:01  Lr: 0.030000  Loss: -0.4586  Acc@1: 81.2500 (77.1865)  Acc@5: 93.7500 (95.3118)  time: 0.3441  data: 0.0002  max mem: 2500
Train: Epoch[3/5]  [2190/3750]  eta: 0:08:58  Lr: 0.030000  Loss: -0.1648  Acc@1: 81.2500 (77.1965)  Acc@5: 93.7500 (95.3075)  time: 0.3437  data: 0.0002  max mem: 2500
Train: Epoch[3/5]  [2200/3750]  eta: 0:08:54  Lr: 0.030000  Loss: -0.6876  Acc@1: 81.2500 (77.1979)  Acc@5: 93.7500 (95.3090)  time: 0.3443  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [2210/3750]  eta: 0:08:51  Lr: 0.030000  Loss: -0.2888  Acc@1: 75.0000 (77.1936)  Acc@5: 93.7500 (95.3019)  time: 0.3469  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2220/3750]  eta: 0:08:47  Lr: 0.030000  Loss: -0.2265  Acc@1: 81.2500 (77.2090)  Acc@5: 93.7500 (95.3005)  time: 0.3470  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [2230/3750]  eta: 0:08:44  Lr: 0.030000  Loss: -0.5416  Acc@1: 81.2500 (77.2075)  Acc@5: 93.7500 (95.2964)  time: 0.3448  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2240/3750]  eta: 0:08:40  Lr: 0.030000  Loss: -0.0030  Acc@1: 75.0000 (77.1642)  Acc@5: 93.7500 (95.2867)  time: 0.3441  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [2250/3750]  eta: 0:08:37  Lr: 0.030000  Loss: -0.3860  Acc@1: 68.7500 (77.1602)  Acc@5: 93.7500 (95.2854)  time: 0.3438  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [2260/3750]  eta: 0:08:33  Lr: 0.030000  Loss: -0.5729  Acc@1: 75.0000 (77.1561)  Acc@5: 100.0000 (95.2980)  time: 0.3441  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [2270/3750]  eta: 0:08:30  Lr: 0.030000  Loss: -0.2008  Acc@1: 75.0000 (77.1686)  Acc@5: 100.0000 (95.3049)  time: 0.3445  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [2280/3750]  eta: 0:08:26  Lr: 0.030000  Loss: -0.2659  Acc@1: 81.2500 (77.1728)  Acc@5: 93.7500 (95.3009)  time: 0.3445  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [2290/3750]  eta: 0:08:23  Lr: 0.030000  Loss: -0.4935  Acc@1: 81.2500 (77.1852)  Acc@5: 93.7500 (95.2968)  time: 0.3433  data: 0.0002  max mem: 2500
Train: Epoch[3/5]  [2300/3750]  eta: 0:08:20  Lr: 0.030000  Loss: -0.0524  Acc@1: 81.2500 (77.1947)  Acc@5: 93.7500 (95.2901)  time: 0.3426  data: 0.0002  max mem: 2500
Train: Epoch[3/5]  [2310/3750]  eta: 0:08:16  Lr: 0.030000  Loss: -0.3151  Acc@1: 75.0000 (77.1798)  Acc@5: 93.7500 (95.2888)  time: 0.3427  data: 0.0002  max mem: 2500
Train: Epoch[3/5]  [2320/3750]  eta: 0:08:13  Lr: 0.030000  Loss: -0.3575  Acc@1: 81.2500 (77.1973)  Acc@5: 93.7500 (95.2849)  time: 0.3427  data: 0.0002  max mem: 2500
Train: Epoch[3/5]  [2330/3750]  eta: 0:08:09  Lr: 0.030000  Loss: -0.6225  Acc@1: 81.2500 (77.1825)  Acc@5: 93.7500 (95.2730)  time: 0.3427  data: 0.0002  max mem: 2500
Train: Epoch[3/5]  [2340/3750]  eta: 0:08:06  Lr: 0.030000  Loss: -0.3874  Acc@1: 75.0000 (77.1892)  Acc@5: 93.7500 (95.2771)  time: 0.3429  data: 0.0002  max mem: 2500
Train: Epoch[3/5]  [2350/3750]  eta: 0:08:02  Lr: 0.030000  Loss: -0.5662  Acc@1: 81.2500 (77.1959)  Acc@5: 93.7500 (95.2839)  time: 0.3433  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [2360/3750]  eta: 0:07:59  Lr: 0.030000  Loss: -0.4832  Acc@1: 81.2500 (77.2263)  Acc@5: 100.0000 (95.2960)  time: 0.3443  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [2370/3750]  eta: 0:07:55  Lr: 0.030000  Loss: -0.4513  Acc@1: 81.2500 (77.2353)  Acc@5: 100.0000 (95.2973)  time: 0.3453  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [2380/3750]  eta: 0:07:52  Lr: 0.030000  Loss: 0.0095  Acc@1: 75.0000 (77.2260)  Acc@5: 93.7500 (95.2961)  time: 0.3444  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2390/3750]  eta: 0:07:48  Lr: 0.030000  Loss: -0.4469  Acc@1: 81.2500 (77.2323)  Acc@5: 100.0000 (95.3027)  time: 0.3436  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2400/3750]  eta: 0:07:45  Lr: 0.030000  Loss: -0.2221  Acc@1: 81.2500 (77.2256)  Acc@5: 93.7500 (95.2988)  time: 0.3443  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2410/3750]  eta: 0:07:42  Lr: 0.030000  Loss: -0.1416  Acc@1: 75.0000 (77.2060)  Acc@5: 93.7500 (95.2743)  time: 0.3451  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2420/3750]  eta: 0:07:38  Lr: 0.030000  Loss: -0.5534  Acc@1: 75.0000 (77.2279)  Acc@5: 93.7500 (95.2783)  time: 0.3461  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [2430/3750]  eta: 0:07:35  Lr: 0.030000  Loss: -0.6058  Acc@1: 75.0000 (77.2187)  Acc@5: 93.7500 (95.2746)  time: 0.3461  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2440/3750]  eta: 0:07:31  Lr: 0.030000  Loss: -0.4962  Acc@1: 68.7500 (77.2148)  Acc@5: 93.7500 (95.2683)  time: 0.3454  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [2450/3750]  eta: 0:07:28  Lr: 0.030000  Loss: -0.5586  Acc@1: 75.0000 (77.2210)  Acc@5: 93.7500 (95.2621)  time: 0.3453  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2460/3750]  eta: 0:07:24  Lr: 0.030000  Loss: -0.0171  Acc@1: 75.0000 (77.2196)  Acc@5: 93.7500 (95.2611)  time: 0.3457  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2470/3750]  eta: 0:07:21  Lr: 0.030000  Loss: -0.1964  Acc@1: 75.0000 (77.2208)  Acc@5: 93.7500 (95.2600)  time: 0.3460  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2480/3750]  eta: 0:07:17  Lr: 0.030000  Loss: -0.3884  Acc@1: 81.2500 (77.2168)  Acc@5: 93.7500 (95.2590)  time: 0.3453  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [2490/3750]  eta: 0:07:14  Lr: 0.030000  Loss: -0.5112  Acc@1: 75.0000 (77.2130)  Acc@5: 93.7500 (95.2554)  time: 0.3449  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [2500/3750]  eta: 0:07:11  Lr: 0.030000  Loss: -0.4076  Acc@1: 75.0000 (77.2166)  Acc@5: 93.7500 (95.2569)  time: 0.3446  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [2510/3750]  eta: 0:07:07  Lr: 0.030000  Loss: -0.6920  Acc@1: 81.2500 (77.2401)  Acc@5: 93.7500 (95.2484)  time: 0.3447  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [2520/3750]  eta: 0:07:04  Lr: 0.030000  Loss: -0.1644  Acc@1: 81.2500 (77.2437)  Acc@5: 93.7500 (95.2499)  time: 0.3448  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [2530/3750]  eta: 0:07:00  Lr: 0.030000  Loss: -0.5794  Acc@1: 75.0000 (77.2545)  Acc@5: 93.7500 (95.2489)  time: 0.3449  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [2540/3750]  eta: 0:06:57  Lr: 0.030000  Loss: -0.1729  Acc@1: 75.0000 (77.2457)  Acc@5: 93.7500 (95.2479)  time: 0.3458  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [2550/3750]  eta: 0:06:53  Lr: 0.030000  Loss: -0.3419  Acc@1: 75.0000 (77.2344)  Acc@5: 93.7500 (95.2445)  time: 0.3451  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [2560/3750]  eta: 0:06:50  Lr: 0.030000  Loss: -0.4095  Acc@1: 75.0000 (77.2135)  Acc@5: 93.7500 (95.2362)  time: 0.3436  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [2570/3750]  eta: 0:06:46  Lr: 0.030000  Loss: -0.2509  Acc@1: 75.0000 (77.2170)  Acc@5: 93.7500 (95.2329)  time: 0.3435  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [2580/3750]  eta: 0:06:43  Lr: 0.030000  Loss: -0.4237  Acc@1: 81.2500 (77.2157)  Acc@5: 93.7500 (95.2320)  time: 0.3435  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [2590/3750]  eta: 0:06:39  Lr: 0.030000  Loss: -0.2781  Acc@1: 81.2500 (77.2144)  Acc@5: 100.0000 (95.2407)  time: 0.3436  data: 0.0002  max mem: 2500
Train: Epoch[3/5]  [2600/3750]  eta: 0:06:36  Lr: 0.030000  Loss: -0.5318  Acc@1: 75.0000 (77.2083)  Acc@5: 100.0000 (95.2374)  time: 0.3446  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [2610/3750]  eta: 0:06:33  Lr: 0.030000  Loss: -0.4675  Acc@1: 75.0000 (77.2070)  Acc@5: 93.7500 (95.2389)  time: 0.3457  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2620/3750]  eta: 0:06:29  Lr: 0.030000  Loss: -0.5707  Acc@1: 75.0000 (77.2200)  Acc@5: 93.7500 (95.2380)  time: 0.3455  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2630/3750]  eta: 0:06:26  Lr: 0.030000  Loss: -0.3946  Acc@1: 75.0000 (77.2092)  Acc@5: 93.7500 (95.2228)  time: 0.3462  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2640/3750]  eta: 0:06:22  Lr: 0.030000  Loss: -0.1253  Acc@1: 75.0000 (77.2080)  Acc@5: 93.7500 (95.2196)  time: 0.3465  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2650/3750]  eta: 0:06:19  Lr: 0.030000  Loss: -0.5282  Acc@1: 81.2500 (77.2114)  Acc@5: 100.0000 (95.2282)  time: 0.3460  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2660/3750]  eta: 0:06:15  Lr: 0.030000  Loss: -0.4988  Acc@1: 81.2500 (77.2243)  Acc@5: 100.0000 (95.2297)  time: 0.3462  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2670/3750]  eta: 0:06:12  Lr: 0.030000  Loss: -0.4309  Acc@1: 81.2500 (77.2159)  Acc@5: 100.0000 (95.2335)  time: 0.3460  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [2680/3750]  eta: 0:06:09  Lr: 0.030000  Loss: -0.5389  Acc@1: 81.2500 (77.2286)  Acc@5: 100.0000 (95.2350)  time: 0.3460  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2690/3750]  eta: 0:06:05  Lr: 0.030000  Loss: -0.4564  Acc@1: 81.2500 (77.2529)  Acc@5: 100.0000 (95.2364)  time: 0.3454  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [2700/3750]  eta: 0:06:02  Lr: 0.030000  Loss: -0.3615  Acc@1: 75.0000 (77.2492)  Acc@5: 93.7500 (95.2309)  time: 0.3449  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [2710/3750]  eta: 0:05:58  Lr: 0.030000  Loss: -0.2280  Acc@1: 75.0000 (77.2501)  Acc@5: 93.7500 (95.2255)  time: 0.3449  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [2720/3750]  eta: 0:05:55  Lr: 0.030000  Loss: -0.4422  Acc@1: 75.0000 (77.2441)  Acc@5: 93.7500 (95.2315)  time: 0.3455  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [2730/3750]  eta: 0:05:51  Lr: 0.030000  Loss: -0.4169  Acc@1: 81.2500 (77.2679)  Acc@5: 100.0000 (95.2398)  time: 0.3453  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [2740/3750]  eta: 0:05:48  Lr: 0.030000  Loss: -0.5302  Acc@1: 81.2500 (77.2802)  Acc@5: 100.0000 (95.2435)  time: 0.3446  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [2750/3750]  eta: 0:05:44  Lr: 0.030000  Loss: -0.3175  Acc@1: 81.2500 (77.2923)  Acc@5: 100.0000 (95.2426)  time: 0.3446  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [2760/3750]  eta: 0:05:41  Lr: 0.030000  Loss: -0.0271  Acc@1: 75.0000 (77.2840)  Acc@5: 100.0000 (95.2486)  time: 0.3442  data: 0.0002  max mem: 2500
Train: Epoch[3/5]  [2770/3750]  eta: 0:05:37  Lr: 0.030000  Loss: -0.1759  Acc@1: 75.0000 (77.2938)  Acc@5: 100.0000 (95.2477)  time: 0.3438  data: 0.0002  max mem: 2500
Train: Epoch[3/5]  [2780/3750]  eta: 0:05:34  Lr: 0.030000  Loss: -0.2379  Acc@1: 81.2500 (77.3058)  Acc@5: 100.0000 (95.2535)  time: 0.3437  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [2790/3750]  eta: 0:05:31  Lr: 0.030000  Loss: -0.1835  Acc@1: 75.0000 (77.3155)  Acc@5: 100.0000 (95.2571)  time: 0.3438  data: 0.0002  max mem: 2500
Train: Epoch[3/5]  [2800/3750]  eta: 0:05:27  Lr: 0.030000  Loss: -0.5080  Acc@1: 75.0000 (77.3027)  Acc@5: 93.7500 (95.2472)  time: 0.3442  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [2810/3750]  eta: 0:05:24  Lr: 0.030000  Loss: -0.2614  Acc@1: 75.0000 (77.2990)  Acc@5: 93.7500 (95.2508)  time: 0.3452  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2820/3750]  eta: 0:05:20  Lr: 0.030000  Loss: -0.5099  Acc@1: 81.2500 (77.3064)  Acc@5: 93.7500 (95.2543)  time: 0.3457  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [2830/3750]  eta: 0:05:17  Lr: 0.030000  Loss: -0.2748  Acc@1: 81.2500 (77.3026)  Acc@5: 93.7500 (95.2512)  time: 0.3460  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2840/3750]  eta: 0:05:13  Lr: 0.030000  Loss: -0.4089  Acc@1: 75.0000 (77.3011)  Acc@5: 93.7500 (95.2438)  time: 0.3456  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [2850/3750]  eta: 0:05:10  Lr: 0.030000  Loss: -0.6268  Acc@1: 81.2500 (77.3303)  Acc@5: 93.7500 (95.2539)  time: 0.3453  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2860/3750]  eta: 0:05:06  Lr: 0.030000  Loss: -0.3765  Acc@1: 81.2500 (77.3397)  Acc@5: 100.0000 (95.2552)  time: 0.3456  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2870/3750]  eta: 0:05:03  Lr: 0.030000  Loss: -0.4081  Acc@1: 81.2500 (77.3576)  Acc@5: 93.7500 (95.2564)  time: 0.3452  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [2880/3750]  eta: 0:05:00  Lr: 0.030000  Loss: -0.2878  Acc@1: 81.2500 (77.3603)  Acc@5: 93.7500 (95.2599)  time: 0.3452  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [2890/3750]  eta: 0:04:56  Lr: 0.030000  Loss: -0.3638  Acc@1: 81.2500 (77.3846)  Acc@5: 93.7500 (95.2547)  time: 0.3451  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [2900/3750]  eta: 0:04:53  Lr: 0.030000  Loss: -0.3581  Acc@1: 81.2500 (77.4108)  Acc@5: 93.7500 (95.2559)  time: 0.3449  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [2910/3750]  eta: 0:04:49  Lr: 0.030000  Loss: -0.0533  Acc@1: 81.2500 (77.4068)  Acc@5: 93.7500 (95.2551)  time: 0.3453  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [2920/3750]  eta: 0:04:46  Lr: 0.030000  Loss: -0.4320  Acc@1: 75.0000 (77.3964)  Acc@5: 93.7500 (95.2499)  time: 0.3447  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [2930/3750]  eta: 0:04:42  Lr: 0.030000  Loss: -0.1549  Acc@1: 75.0000 (77.3947)  Acc@5: 93.7500 (95.2533)  time: 0.3435  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [2940/3750]  eta: 0:04:39  Lr: 0.030000  Loss: -0.0216  Acc@1: 75.0000 (77.4099)  Acc@5: 100.0000 (95.2588)  time: 0.3437  data: 0.0002  max mem: 2500
Train: Epoch[3/5]  [2950/3750]  eta: 0:04:35  Lr: 0.030000  Loss: -0.4647  Acc@1: 75.0000 (77.4166)  Acc@5: 100.0000 (95.2664)  time: 0.3438  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [2960/3750]  eta: 0:04:32  Lr: 0.030000  Loss: -0.2959  Acc@1: 75.0000 (77.4105)  Acc@5: 93.7500 (95.2613)  time: 0.3439  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [2970/3750]  eta: 0:04:28  Lr: 0.030000  Loss: -0.2057  Acc@1: 75.0000 (77.4108)  Acc@5: 93.7500 (95.2541)  time: 0.3438  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [2980/3750]  eta: 0:04:25  Lr: 0.030000  Loss: -0.3401  Acc@1: 81.2500 (77.4153)  Acc@5: 93.7500 (95.2512)  time: 0.3437  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [2990/3750]  eta: 0:04:22  Lr: 0.030000  Loss: -0.5286  Acc@1: 75.0000 (77.4072)  Acc@5: 93.7500 (95.2399)  time: 0.3453  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [3000/3750]  eta: 0:04:18  Lr: 0.030000  Loss: -0.6354  Acc@1: 75.0000 (77.4117)  Acc@5: 93.7500 (95.2433)  time: 0.3464  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [3010/3750]  eta: 0:04:15  Lr: 0.030000  Loss: -0.4283  Acc@1: 75.0000 (77.4099)  Acc@5: 100.0000 (95.2487)  time: 0.3462  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [3020/3750]  eta: 0:04:11  Lr: 0.030000  Loss: -0.3273  Acc@1: 75.0000 (77.4102)  Acc@5: 93.7500 (95.2416)  time: 0.3453  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [3030/3750]  eta: 0:04:08  Lr: 0.030000  Loss: -0.2692  Acc@1: 75.0000 (77.4043)  Acc@5: 93.7500 (95.2408)  time: 0.3450  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [3040/3750]  eta: 0:04:04  Lr: 0.030000  Loss: -0.5052  Acc@1: 75.0000 (77.4067)  Acc@5: 93.7500 (95.2442)  time: 0.3473  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3050/3750]  eta: 0:04:01  Lr: 0.030000  Loss: -0.2704  Acc@1: 81.2500 (77.4152)  Acc@5: 93.7500 (95.2434)  time: 0.3471  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3060/3750]  eta: 0:03:57  Lr: 0.030000  Loss: -0.1430  Acc@1: 75.0000 (77.4134)  Acc@5: 93.7500 (95.2446)  time: 0.3477  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [3070/3750]  eta: 0:03:54  Lr: 0.030000  Loss: -0.4113  Acc@1: 81.2500 (77.4300)  Acc@5: 93.7500 (95.2520)  time: 0.3484  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [3080/3750]  eta: 0:03:51  Lr: 0.030000  Loss: -0.0360  Acc@1: 81.2500 (77.4201)  Acc@5: 100.0000 (95.2552)  time: 0.3461  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3090/3750]  eta: 0:03:47  Lr: 0.030000  Loss: -0.4465  Acc@1: 68.7500 (77.3961)  Acc@5: 100.0000 (95.2604)  time: 0.3457  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3100/3750]  eta: 0:03:44  Lr: 0.030000  Loss: -0.5229  Acc@1: 75.0000 (77.4085)  Acc@5: 93.7500 (95.2556)  time: 0.3459  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3110/3750]  eta: 0:03:40  Lr: 0.030000  Loss: -0.3485  Acc@1: 81.2500 (77.4168)  Acc@5: 93.7500 (95.2527)  time: 0.3466  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3120/3750]  eta: 0:03:37  Lr: 0.030000  Loss: -0.0518  Acc@1: 75.0000 (77.4011)  Acc@5: 93.7500 (95.2519)  time: 0.3464  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3130/3750]  eta: 0:03:33  Lr: 0.030000  Loss: -0.1505  Acc@1: 68.7500 (77.3814)  Acc@5: 93.7500 (95.2431)  time: 0.3450  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [3140/3750]  eta: 0:03:30  Lr: 0.030000  Loss: -0.5332  Acc@1: 75.0000 (77.3818)  Acc@5: 93.7500 (95.2463)  time: 0.3449  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [3150/3750]  eta: 0:03:26  Lr: 0.030000  Loss: -0.1372  Acc@1: 81.2500 (77.3762)  Acc@5: 93.7500 (95.2456)  time: 0.3455  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [3160/3750]  eta: 0:03:23  Lr: 0.030000  Loss: -0.3630  Acc@1: 75.0000 (77.3648)  Acc@5: 93.7500 (95.2507)  time: 0.3450  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [3170/3750]  eta: 0:03:20  Lr: 0.030000  Loss: -0.6494  Acc@1: 81.2500 (77.3829)  Acc@5: 100.0000 (95.2539)  time: 0.3445  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [3180/3750]  eta: 0:03:16  Lr: 0.030000  Loss: -0.6180  Acc@1: 81.2500 (77.3912)  Acc@5: 93.7500 (95.2511)  time: 0.3451  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [3190/3750]  eta: 0:03:13  Lr: 0.030000  Loss: -0.2244  Acc@1: 81.2500 (77.4032)  Acc@5: 93.7500 (95.2562)  time: 0.3441  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [3200/3750]  eta: 0:03:09  Lr: 0.030000  Loss: -0.5729  Acc@1: 81.2500 (77.3996)  Acc@5: 93.7500 (95.2554)  time: 0.3431  data: 0.0002  max mem: 2500
Train: Epoch[3/5]  [3210/3750]  eta: 0:03:06  Lr: 0.030000  Loss: -0.2089  Acc@1: 75.0000 (77.3941)  Acc@5: 93.7500 (95.2449)  time: 0.3434  data: 0.0002  max mem: 2500
Train: Epoch[3/5]  [3220/3750]  eta: 0:03:02  Lr: 0.030000  Loss: -0.4009  Acc@1: 75.0000 (77.3653)  Acc@5: 93.7500 (95.2422)  time: 0.3438  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [3230/3750]  eta: 0:02:59  Lr: 0.030000  Loss: -0.1794  Acc@1: 75.0000 (77.3735)  Acc@5: 93.7500 (95.2375)  time: 0.3448  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [3240/3750]  eta: 0:02:55  Lr: 0.030000  Loss: -0.2511  Acc@1: 81.2500 (77.3623)  Acc@5: 93.7500 (95.2387)  time: 0.3457  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3250/3750]  eta: 0:02:52  Lr: 0.030000  Loss: -0.1982  Acc@1: 75.0000 (77.3723)  Acc@5: 93.7500 (95.2418)  time: 0.3453  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3260/3750]  eta: 0:02:49  Lr: 0.030000  Loss: -0.2655  Acc@1: 75.0000 (77.3555)  Acc@5: 93.7500 (95.2392)  time: 0.3453  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [3270/3750]  eta: 0:02:45  Lr: 0.030000  Loss: -0.4313  Acc@1: 75.0000 (77.3502)  Acc@5: 93.7500 (95.2442)  time: 0.3455  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3280/3750]  eta: 0:02:42  Lr: 0.030000  Loss: -0.4407  Acc@1: 75.0000 (77.3430)  Acc@5: 93.7500 (95.2339)  time: 0.3451  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [3290/3750]  eta: 0:02:38  Lr: 0.030000  Loss: -0.1915  Acc@1: 68.7500 (77.3226)  Acc@5: 93.7500 (95.2237)  time: 0.3450  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [3300/3750]  eta: 0:02:35  Lr: 0.030000  Loss: -0.4195  Acc@1: 75.0000 (77.3345)  Acc@5: 93.7500 (95.2268)  time: 0.3448  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [3310/3750]  eta: 0:02:31  Lr: 0.030000  Loss: -0.5116  Acc@1: 81.2500 (77.3426)  Acc@5: 100.0000 (95.2280)  time: 0.3446  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [3320/3750]  eta: 0:02:28  Lr: 0.030000  Loss: -0.4925  Acc@1: 75.0000 (77.3318)  Acc@5: 93.7500 (95.2255)  time: 0.3446  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [3330/3750]  eta: 0:02:24  Lr: 0.030000  Loss: -0.3698  Acc@1: 75.0000 (77.3285)  Acc@5: 93.7500 (95.2267)  time: 0.3447  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [3340/3750]  eta: 0:02:21  Lr: 0.030000  Loss: -0.4793  Acc@1: 75.0000 (77.3309)  Acc@5: 93.7500 (95.2279)  time: 0.3444  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [3350/3750]  eta: 0:02:17  Lr: 0.030000  Loss: -0.3131  Acc@1: 75.0000 (77.2960)  Acc@5: 93.7500 (95.2197)  time: 0.3437  data: 0.0002  max mem: 2500
Train: Epoch[3/5]  [3360/3750]  eta: 0:02:14  Lr: 0.030000  Loss: -0.3906  Acc@1: 75.0000 (77.3096)  Acc@5: 93.7500 (95.2265)  time: 0.3436  data: 0.0002  max mem: 2500
Train: Epoch[3/5]  [3370/3750]  eta: 0:02:11  Lr: 0.030000  Loss: -0.4513  Acc@1: 75.0000 (77.2972)  Acc@5: 100.0000 (95.2221)  time: 0.3448  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [3380/3750]  eta: 0:02:07  Lr: 0.030000  Loss: -0.4763  Acc@1: 75.0000 (77.2922)  Acc@5: 93.7500 (95.2270)  time: 0.3465  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3390/3750]  eta: 0:02:04  Lr: 0.030000  Loss: -0.4392  Acc@1: 75.0000 (77.2947)  Acc@5: 93.7500 (95.2282)  time: 0.3471  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3400/3750]  eta: 0:02:00  Lr: 0.030000  Loss: -0.3096  Acc@1: 81.2500 (77.2898)  Acc@5: 93.7500 (95.2257)  time: 0.3462  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3410/3750]  eta: 0:01:57  Lr: 0.030000  Loss: -0.1772  Acc@1: 75.0000 (77.2757)  Acc@5: 93.7500 (95.2213)  time: 0.3460  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3420/3750]  eta: 0:01:53  Lr: 0.030000  Loss: -0.0823  Acc@1: 75.0000 (77.2800)  Acc@5: 93.7500 (95.2243)  time: 0.3463  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3430/3750]  eta: 0:01:50  Lr: 0.030000  Loss: -0.1036  Acc@1: 81.2500 (77.2861)  Acc@5: 100.0000 (95.2237)  time: 0.3453  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3440/3750]  eta: 0:01:46  Lr: 0.030000  Loss: -0.4666  Acc@1: 81.2500 (77.2958)  Acc@5: 100.0000 (95.2267)  time: 0.3445  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [3450/3750]  eta: 0:01:43  Lr: 0.030000  Loss: -0.4127  Acc@1: 75.0000 (77.2693)  Acc@5: 93.7500 (95.2152)  time: 0.3441  data: 0.0002  max mem: 2500
Train: Epoch[3/5]  [3460/3750]  eta: 0:01:40  Lr: 0.030000  Loss: -0.1936  Acc@1: 75.0000 (77.2754)  Acc@5: 93.7500 (95.2200)  time: 0.3440  data: 0.0002  max mem: 2500
Train: Epoch[3/5]  [3470/3750]  eta: 0:01:36  Lr: 0.030000  Loss: -0.2909  Acc@1: 75.0000 (77.2814)  Acc@5: 100.0000 (95.2211)  time: 0.3440  data: 0.0002  max mem: 2500
Train: Epoch[3/5]  [3480/3750]  eta: 0:01:33  Lr: 0.030000  Loss: -0.3343  Acc@1: 75.0000 (77.2838)  Acc@5: 93.7500 (95.2169)  time: 0.3439  data: 0.0002  max mem: 2500
Train: Epoch[3/5]  [3490/3750]  eta: 0:01:29  Lr: 0.030000  Loss: -0.5750  Acc@1: 75.0000 (77.2880)  Acc@5: 93.7500 (95.2234)  time: 0.3445  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [3500/3750]  eta: 0:01:26  Lr: 0.030000  Loss: -0.3391  Acc@1: 81.2500 (77.2833)  Acc@5: 100.0000 (95.2281)  time: 0.3456  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3510/3750]  eta: 0:01:22  Lr: 0.030000  Loss: -0.4446  Acc@1: 75.0000 (77.2750)  Acc@5: 93.7500 (95.2222)  time: 0.3463  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3520/3750]  eta: 0:01:19  Lr: 0.030000  Loss: -0.1400  Acc@1: 75.0000 (77.2863)  Acc@5: 93.7500 (95.2251)  time: 0.3458  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [3530/3750]  eta: 0:01:15  Lr: 0.030000  Loss: -0.0296  Acc@1: 75.0000 (77.2780)  Acc@5: 100.0000 (95.2191)  time: 0.3453  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [3540/3750]  eta: 0:01:12  Lr: 0.030000  Loss: -0.3297  Acc@1: 75.0000 (77.2804)  Acc@5: 93.7500 (95.2167)  time: 0.3456  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3550/3750]  eta: 0:01:08  Lr: 0.030000  Loss: -0.2307  Acc@1: 81.2500 (77.2916)  Acc@5: 93.7500 (95.2161)  time: 0.3459  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [3560/3750]  eta: 0:01:05  Lr: 0.030000  Loss: -0.5353  Acc@1: 75.0000 (77.2799)  Acc@5: 100.0000 (95.2225)  time: 0.3460  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [3570/3750]  eta: 0:01:02  Lr: 0.030000  Loss: -0.3459  Acc@1: 75.0000 (77.2893)  Acc@5: 100.0000 (95.2307)  time: 0.3450  data: 0.0002  max mem: 2500
Train: Epoch[3/5]  [3580/3750]  eta: 0:00:58  Lr: 0.030000  Loss: -0.3452  Acc@1: 81.2500 (77.2934)  Acc@5: 100.0000 (95.2300)  time: 0.3439  data: 0.0002  max mem: 2500
Train: Epoch[3/5]  [3590/3750]  eta: 0:00:55  Lr: 0.030000  Loss: 0.2488  Acc@1: 75.0000 (77.2887)  Acc@5: 100.0000 (95.2329)  time: 0.3440  data: 0.0002  max mem: 2500
Train: Epoch[3/5]  [3600/3750]  eta: 0:00:51  Lr: 0.030000  Loss: -0.4685  Acc@1: 81.2500 (77.3067)  Acc@5: 100.0000 (95.2392)  time: 0.3442  data: 0.0002  max mem: 2500
Train: Epoch[3/5]  [3610/3750]  eta: 0:00:48  Lr: 0.030000  Loss: -0.2128  Acc@1: 81.2500 (77.3106)  Acc@5: 100.0000 (95.2350)  time: 0.3437  data: 0.0002  max mem: 2500
Train: Epoch[3/5]  [3620/3750]  eta: 0:00:44  Lr: 0.030000  Loss: -0.3325  Acc@1: 81.2500 (77.3094)  Acc@5: 93.7500 (95.2309)  time: 0.3438  data: 0.0002  max mem: 2500
Train: Epoch[3/5]  [3630/3750]  eta: 0:00:41  Lr: 0.030000  Loss: -0.1846  Acc@1: 81.2500 (77.3134)  Acc@5: 93.7500 (95.2269)  time: 0.3444  data: 0.0002  max mem: 2500
Train: Epoch[3/5]  [3640/3750]  eta: 0:00:37  Lr: 0.030000  Loss: -0.2669  Acc@1: 81.2500 (77.3174)  Acc@5: 93.7500 (95.2297)  time: 0.3454  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3650/3750]  eta: 0:00:34  Lr: 0.030000  Loss: -0.1354  Acc@1: 81.2500 (77.3316)  Acc@5: 100.0000 (95.2308)  time: 0.3463  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3660/3750]  eta: 0:00:31  Lr: 0.030000  Loss: -0.4174  Acc@1: 75.0000 (77.3184)  Acc@5: 93.7500 (95.2165)  time: 0.3460  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3670/3750]  eta: 0:00:27  Lr: 0.030000  Loss: -0.2436  Acc@1: 75.0000 (77.3206)  Acc@5: 93.7500 (95.2227)  time: 0.3454  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3680/3750]  eta: 0:00:24  Lr: 0.030000  Loss: -0.4401  Acc@1: 81.2500 (77.3397)  Acc@5: 100.0000 (95.2255)  time: 0.3455  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [3690/3750]  eta: 0:00:20  Lr: 0.030000  Loss: -0.4063  Acc@1: 81.2500 (77.3368)  Acc@5: 93.7500 (95.2300)  time: 0.3450  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3700/3750]  eta: 0:00:17  Lr: 0.030000  Loss: -0.6409  Acc@1: 75.0000 (77.3473)  Acc@5: 100.0000 (95.2378)  time: 0.3460  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3710/3750]  eta: 0:00:13  Lr: 0.030000  Loss: -0.4340  Acc@1: 81.2500 (77.3562)  Acc@5: 100.0000 (95.2422)  time: 0.3469  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3720/3750]  eta: 0:00:10  Lr: 0.030000  Loss: -0.3065  Acc@1: 81.2500 (77.3549)  Acc@5: 93.7500 (95.2432)  time: 0.3455  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3730/3750]  eta: 0:00:06  Lr: 0.030000  Loss: -0.5605  Acc@1: 81.2500 (77.3670)  Acc@5: 100.0000 (95.2476)  time: 0.3462  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3740/3750]  eta: 0:00:03  Lr: 0.030000  Loss: -0.4350  Acc@1: 81.2500 (77.3790)  Acc@5: 100.0000 (95.2503)  time: 0.3473  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3749/3750]  eta: 0:00:00  Lr: 0.030000  Loss: -0.0103  Acc@1: 81.2500 (77.3800)  Acc@5: 93.7500 (95.2483)  time: 0.3475  data: 0.0009  max mem: 2500
Train: Epoch[3/5] Total time: 0:21:34 (0.3451 s / it)
{0: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 1: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 2: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 3: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 4: {0: 0, 1: 180000, 2: 0, 3: 0, 4: 0}, 5: {0: 0, 1: 180000, 2: 0, 3: 0, 4: 0}, 6: {0: 0, 1: 180000, 2: 0, 3: 0, 4: 0}, 7: {0: 0, 1: 180000, 2: 0, 3: 0, 4: 0}, 8: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 9: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 10: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 11: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 12: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 13: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 14: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 15: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 16: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 17: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 18: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 19: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}}
Averaged stats: Lr: 0.030000  Loss: -0.0103  Acc@1: 81.2500 (77.3800)  Acc@5: 93.7500 (95.2483)
Train: Epoch[4/5]  [   0/3750]  eta: 0:35:34  Lr: 0.030000  Loss: -0.0502  Acc@1: 62.5000 (62.5000)  Acc@5: 93.7500 (93.7500)  time: 0.5691  data: 0.2269  max mem: 2500
Train: Epoch[4/5]  [  10/3750]  eta: 0:22:48  Lr: 0.030000  Loss: -0.2807  Acc@1: 75.0000 (71.5909)  Acc@5: 93.7500 (93.7500)  time: 0.3658  data: 0.0209  max mem: 2500
Train: Epoch[4/5]  [  20/3750]  eta: 0:22:07  Lr: 0.030000  Loss: -0.1584  Acc@1: 75.0000 (75.5952)  Acc@5: 93.7500 (93.1548)  time: 0.3451  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [  30/3750]  eta: 0:21:51  Lr: 0.030000  Loss: -0.2940  Acc@1: 81.2500 (77.2177)  Acc@5: 93.7500 (93.5484)  time: 0.3453  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [  40/3750]  eta: 0:21:40  Lr: 0.030000  Loss: -0.0442  Acc@1: 75.0000 (75.9146)  Acc@5: 93.7500 (94.3598)  time: 0.3451  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [  50/3750]  eta: 0:21:33  Lr: 0.030000  Loss: -0.4835  Acc@1: 75.0000 (75.1225)  Acc@5: 93.7500 (94.4853)  time: 0.3450  data: 0.0002  max mem: 2500
Train: Epoch[4/5]  [  60/3750]  eta: 0:21:27  Lr: 0.030000  Loss: -0.3474  Acc@1: 75.0000 (74.8975)  Acc@5: 93.7500 (94.6721)  time: 0.3454  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [  70/3750]  eta: 0:21:22  Lr: 0.030000  Loss: -0.4044  Acc@1: 81.2500 (75.2641)  Acc@5: 93.7500 (94.8944)  time: 0.3459  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [  80/3750]  eta: 0:21:16  Lr: 0.030000  Loss: -0.3910  Acc@1: 81.2500 (75.4630)  Acc@5: 93.7500 (94.9074)  time: 0.3449  data: 0.0002  max mem: 2500
Train: Epoch[4/5]  [  90/3750]  eta: 0:21:11  Lr: 0.030000  Loss: -0.5162  Acc@1: 81.2500 (75.9615)  Acc@5: 93.7500 (94.8489)  time: 0.3432  data: 0.0002  max mem: 2500
Train: Epoch[4/5]  [ 100/3750]  eta: 0:21:06  Lr: 0.030000  Loss: -0.6593  Acc@1: 81.2500 (76.4233)  Acc@5: 93.7500 (94.9257)  time: 0.3430  data: 0.0002  max mem: 2500
Train: Epoch[4/5]  [ 110/3750]  eta: 0:21:01  Lr: 0.030000  Loss: -0.5762  Acc@1: 81.2500 (76.6892)  Acc@5: 93.7500 (95.1014)  time: 0.3432  data: 0.0002  max mem: 2500
Train: Epoch[4/5]  [ 120/3750]  eta: 0:20:57  Lr: 0.030000  Loss: 0.1137  Acc@1: 81.2500 (77.0145)  Acc@5: 93.7500 (94.9380)  time: 0.3432  data: 0.0002  max mem: 2500
Train: Epoch[4/5]  [ 130/3750]  eta: 0:20:52  Lr: 0.030000  Loss: -0.3272  Acc@1: 75.0000 (76.9084)  Acc@5: 93.7500 (95.0382)  time: 0.3432  data: 0.0002  max mem: 2500
Train: Epoch[4/5]  [ 140/3750]  eta: 0:20:48  Lr: 0.030000  Loss: -0.6385  Acc@1: 81.2500 (77.3493)  Acc@5: 100.0000 (95.1684)  time: 0.3435  data: 0.0002  max mem: 2500
Train: Epoch[4/5]  [ 150/3750]  eta: 0:20:45  Lr: 0.030000  Loss: -0.2876  Acc@1: 81.2500 (77.3593)  Acc@5: 100.0000 (95.2401)  time: 0.3444  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 160/3750]  eta: 0:20:41  Lr: 0.030000  Loss: -0.3423  Acc@1: 75.0000 (77.4457)  Acc@5: 100.0000 (95.3028)  time: 0.3455  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 170/3750]  eta: 0:20:38  Lr: 0.030000  Loss: -0.3655  Acc@1: 75.0000 (77.5950)  Acc@5: 93.7500 (95.2120)  time: 0.3452  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 180/3750]  eta: 0:20:34  Lr: 0.030000  Loss: -0.4972  Acc@1: 81.2500 (77.6243)  Acc@5: 93.7500 (95.2693)  time: 0.3452  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 190/3750]  eta: 0:20:31  Lr: 0.030000  Loss: -0.4000  Acc@1: 81.2500 (77.7487)  Acc@5: 93.7500 (95.3207)  time: 0.3456  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 200/3750]  eta: 0:20:27  Lr: 0.030000  Loss: -0.3979  Acc@1: 81.2500 (77.7674)  Acc@5: 93.7500 (95.3358)  time: 0.3461  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 210/3750]  eta: 0:20:24  Lr: 0.030000  Loss: -0.1186  Acc@1: 81.2500 (77.9028)  Acc@5: 93.7500 (95.3199)  time: 0.3461  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 220/3750]  eta: 0:20:20  Lr: 0.030000  Loss: -0.3147  Acc@1: 81.2500 (77.9412)  Acc@5: 93.7500 (95.3620)  time: 0.3449  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 230/3750]  eta: 0:20:16  Lr: 0.030000  Loss: -0.4957  Acc@1: 75.0000 (77.7056)  Acc@5: 93.7500 (95.2110)  time: 0.3444  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 240/3750]  eta: 0:20:13  Lr: 0.030000  Loss: -0.3933  Acc@1: 81.2500 (77.8527)  Acc@5: 93.7500 (95.2801)  time: 0.3450  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [ 250/3750]  eta: 0:20:09  Lr: 0.030000  Loss: -0.2933  Acc@1: 81.2500 (77.8635)  Acc@5: 100.0000 (95.3436)  time: 0.3450  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [ 260/3750]  eta: 0:20:06  Lr: 0.030000  Loss: -0.5903  Acc@1: 81.2500 (77.8496)  Acc@5: 93.7500 (95.3065)  time: 0.3449  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 270/3750]  eta: 0:20:02  Lr: 0.030000  Loss: -0.1870  Acc@1: 75.0000 (77.6061)  Acc@5: 93.7500 (95.2260)  time: 0.3442  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [ 280/3750]  eta: 0:19:58  Lr: 0.030000  Loss: -0.2389  Acc@1: 68.7500 (77.6246)  Acc@5: 93.7500 (95.2402)  time: 0.3436  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [ 290/3750]  eta: 0:19:55  Lr: 0.030000  Loss: -0.2170  Acc@1: 75.0000 (77.4914)  Acc@5: 93.7500 (95.1031)  time: 0.3446  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [ 300/3750]  eta: 0:19:51  Lr: 0.030000  Loss: -0.5184  Acc@1: 81.2500 (77.6993)  Acc@5: 93.7500 (95.1204)  time: 0.3450  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [ 310/3750]  eta: 0:19:48  Lr: 0.030000  Loss: -0.1109  Acc@1: 75.0000 (77.5322)  Acc@5: 93.7500 (95.1166)  time: 0.3441  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [ 320/3750]  eta: 0:19:44  Lr: 0.030000  Loss: -0.5286  Acc@1: 75.0000 (77.6480)  Acc@5: 100.0000 (95.1713)  time: 0.3433  data: 0.0002  max mem: 2500
Train: Epoch[4/5]  [ 330/3750]  eta: 0:19:40  Lr: 0.030000  Loss: -0.5022  Acc@1: 81.2500 (77.8134)  Acc@5: 100.0000 (95.2039)  time: 0.3432  data: 0.0002  max mem: 2500
Train: Epoch[4/5]  [ 340/3750]  eta: 0:19:37  Lr: 0.030000  Loss: -0.5297  Acc@1: 81.2500 (77.8776)  Acc@5: 100.0000 (95.2163)  time: 0.3435  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [ 350/3750]  eta: 0:19:33  Lr: 0.030000  Loss: 0.0991  Acc@1: 75.0000 (77.6887)  Acc@5: 100.0000 (95.1923)  time: 0.3445  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 360/3750]  eta: 0:19:30  Lr: 0.030000  Loss: -0.6246  Acc@1: 75.0000 (77.6662)  Acc@5: 100.0000 (95.2562)  time: 0.3451  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 370/3750]  eta: 0:19:26  Lr: 0.030000  Loss: -0.5148  Acc@1: 81.2500 (77.8470)  Acc@5: 100.0000 (95.2999)  time: 0.3446  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 380/3750]  eta: 0:19:23  Lr: 0.030000  Loss: -0.5352  Acc@1: 81.2500 (77.8379)  Acc@5: 93.7500 (95.3248)  time: 0.3439  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [ 390/3750]  eta: 0:19:19  Lr: 0.030000  Loss: -0.1017  Acc@1: 75.0000 (77.7174)  Acc@5: 93.7500 (95.3165)  time: 0.3436  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [ 400/3750]  eta: 0:19:15  Lr: 0.030000  Loss: -0.3634  Acc@1: 75.0000 (77.7743)  Acc@5: 93.7500 (95.3086)  time: 0.3440  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [ 410/3750]  eta: 0:19:12  Lr: 0.030000  Loss: -0.1591  Acc@1: 75.0000 (77.7981)  Acc@5: 93.7500 (95.3315)  time: 0.3443  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [ 420/3750]  eta: 0:19:08  Lr: 0.030000  Loss: -0.3608  Acc@1: 75.0000 (77.6574)  Acc@5: 93.7500 (95.3533)  time: 0.3437  data: 0.0002  max mem: 2500
Train: Epoch[4/5]  [ 430/3750]  eta: 0:19:05  Lr: 0.030000  Loss: -0.3796  Acc@1: 75.0000 (77.7552)  Acc@5: 93.7500 (95.3306)  time: 0.3426  data: 0.0002  max mem: 2500
Train: Epoch[4/5]  [ 440/3750]  eta: 0:19:01  Lr: 0.030000  Loss: -0.5794  Acc@1: 81.2500 (77.8345)  Acc@5: 93.7500 (95.3798)  time: 0.3425  data: 0.0002  max mem: 2500
Train: Epoch[4/5]  [ 450/3750]  eta: 0:18:58  Lr: 0.030000  Loss: -0.2370  Acc@1: 75.0000 (77.7716)  Acc@5: 100.0000 (95.3575)  time: 0.3434  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [ 460/3750]  eta: 0:18:54  Lr: 0.030000  Loss: -0.2528  Acc@1: 68.7500 (77.6979)  Acc@5: 93.7500 (95.3633)  time: 0.3442  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 470/3750]  eta: 0:18:51  Lr: 0.030000  Loss: -0.4164  Acc@1: 75.0000 (77.7070)  Acc@5: 93.7500 (95.3954)  time: 0.3442  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 480/3750]  eta: 0:18:47  Lr: 0.030000  Loss: -0.4656  Acc@1: 81.2500 (77.6897)  Acc@5: 93.7500 (95.3093)  time: 0.3446  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 490/3750]  eta: 0:18:44  Lr: 0.030000  Loss: -0.5553  Acc@1: 81.2500 (77.7622)  Acc@5: 93.7500 (95.3157)  time: 0.3449  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 500/3750]  eta: 0:18:40  Lr: 0.030000  Loss: -0.3243  Acc@1: 75.0000 (77.6946)  Acc@5: 93.7500 (95.2969)  time: 0.3449  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 510/3750]  eta: 0:18:37  Lr: 0.030000  Loss: -0.3873  Acc@1: 75.0000 (77.7642)  Acc@5: 93.7500 (95.3156)  time: 0.3447  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [ 520/3750]  eta: 0:18:33  Lr: 0.030000  Loss: -0.3521  Acc@1: 81.2500 (77.7231)  Acc@5: 100.0000 (95.3215)  time: 0.3449  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [ 530/3750]  eta: 0:18:30  Lr: 0.030000  Loss: -0.3653  Acc@1: 75.0000 (77.6954)  Acc@5: 100.0000 (95.3272)  time: 0.3448  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [ 540/3750]  eta: 0:18:26  Lr: 0.030000  Loss: -0.3895  Acc@1: 75.0000 (77.6340)  Acc@5: 93.7500 (95.2865)  time: 0.3443  data: 0.0002  max mem: 2500
Train: Epoch[4/5]  [ 550/3750]  eta: 0:18:23  Lr: 0.030000  Loss: -0.3152  Acc@1: 75.0000 (77.6996)  Acc@5: 93.7500 (95.2700)  time: 0.3438  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [ 560/3750]  eta: 0:18:20  Lr: 0.030000  Loss: -0.0932  Acc@1: 81.2500 (77.6961)  Acc@5: 100.0000 (95.3209)  time: 0.3446  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [ 570/3750]  eta: 0:18:16  Lr: 0.030000  Loss: 0.0406  Acc@1: 75.0000 (77.6598)  Acc@5: 100.0000 (95.3262)  time: 0.3454  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [ 580/3750]  eta: 0:18:13  Lr: 0.030000  Loss: -0.6715  Acc@1: 75.0000 (77.6248)  Acc@5: 100.0000 (95.3636)  time: 0.3455  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 590/3750]  eta: 0:18:09  Lr: 0.030000  Loss: -0.3023  Acc@1: 75.0000 (77.6332)  Acc@5: 100.0000 (95.3574)  time: 0.3454  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [ 600/3750]  eta: 0:18:06  Lr: 0.030000  Loss: -0.4028  Acc@1: 81.2500 (77.7142)  Acc@5: 93.7500 (95.3931)  time: 0.3447  data: 0.0002  max mem: 2500
Train: Epoch[4/5]  [ 610/3750]  eta: 0:18:02  Lr: 0.030000  Loss: -0.4365  Acc@1: 81.2500 (77.6800)  Acc@5: 93.7500 (95.3355)  time: 0.3449  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [ 620/3750]  eta: 0:17:59  Lr: 0.030000  Loss: -0.2955  Acc@1: 75.0000 (77.6570)  Acc@5: 93.7500 (95.3301)  time: 0.3454  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [ 630/3750]  eta: 0:17:56  Lr: 0.030000  Loss: -0.4580  Acc@1: 75.0000 (77.7536)  Acc@5: 93.7500 (95.3744)  time: 0.3462  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [ 640/3750]  eta: 0:17:52  Lr: 0.030000  Loss: -0.5607  Acc@1: 81.2500 (77.7789)  Acc@5: 100.0000 (95.4173)  time: 0.3452  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [ 650/3750]  eta: 0:17:49  Lr: 0.030000  Loss: -0.2103  Acc@1: 81.2500 (77.8130)  Acc@5: 93.7500 (95.4013)  time: 0.3440  data: 0.0002  max mem: 2500
Train: Epoch[4/5]  [ 660/3750]  eta: 0:17:45  Lr: 0.030000  Loss: -0.6393  Acc@1: 81.2500 (77.8366)  Acc@5: 93.7500 (95.3763)  time: 0.3439  data: 0.0002  max mem: 2500
Train: Epoch[4/5]  [ 670/3750]  eta: 0:17:42  Lr: 0.030000  Loss: -0.3135  Acc@1: 81.2500 (77.8037)  Acc@5: 93.7500 (95.3335)  time: 0.3437  data: 0.0002  max mem: 2500
Train: Epoch[4/5]  [ 680/3750]  eta: 0:17:38  Lr: 0.030000  Loss: -0.5813  Acc@1: 75.0000 (77.7625)  Acc@5: 93.7500 (95.2919)  time: 0.3441  data: 0.0002  max mem: 2500
Train: Epoch[4/5]  [ 690/3750]  eta: 0:17:35  Lr: 0.030000  Loss: -0.4066  Acc@1: 75.0000 (77.8310)  Acc@5: 93.7500 (95.3148)  time: 0.3444  data: 0.0002  max mem: 2500
Train: Epoch[4/5]  [ 700/3750]  eta: 0:17:31  Lr: 0.030000  Loss: -0.4296  Acc@1: 81.2500 (77.8442)  Acc@5: 100.0000 (95.3370)  time: 0.3445  data: 0.0002  max mem: 2500
Train: Epoch[4/5]  [ 710/3750]  eta: 0:17:28  Lr: 0.030000  Loss: -0.3023  Acc@1: 75.0000 (77.7514)  Acc@5: 93.7500 (95.3235)  time: 0.3461  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [ 720/3750]  eta: 0:17:24  Lr: 0.030000  Loss: -0.3965  Acc@1: 75.0000 (77.7653)  Acc@5: 93.7500 (95.3017)  time: 0.3469  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 730/3750]  eta: 0:17:21  Lr: 0.030000  Loss: -0.3384  Acc@1: 75.0000 (77.7702)  Acc@5: 93.7500 (95.2975)  time: 0.3468  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [ 740/3750]  eta: 0:17:18  Lr: 0.030000  Loss: -0.6888  Acc@1: 81.2500 (77.7665)  Acc@5: 93.7500 (95.3020)  time: 0.3469  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 750/3750]  eta: 0:17:14  Lr: 0.030000  Loss: -0.1274  Acc@1: 75.0000 (77.7047)  Acc@5: 93.7500 (95.3063)  time: 0.3464  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 760/3750]  eta: 0:17:11  Lr: 0.030000  Loss: -0.4482  Acc@1: 75.0000 (77.6938)  Acc@5: 93.7500 (95.2858)  time: 0.3466  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [ 770/3750]  eta: 0:17:08  Lr: 0.030000  Loss: -0.1911  Acc@1: 75.0000 (77.6994)  Acc@5: 93.7500 (95.2902)  time: 0.3465  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [ 780/3750]  eta: 0:17:04  Lr: 0.030000  Loss: -0.4767  Acc@1: 81.2500 (77.7049)  Acc@5: 100.0000 (95.3345)  time: 0.3461  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 790/3750]  eta: 0:17:01  Lr: 0.030000  Loss: -0.4130  Acc@1: 81.2500 (77.7023)  Acc@5: 100.0000 (95.3461)  time: 0.3459  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 800/3750]  eta: 0:16:57  Lr: 0.030000  Loss: -0.5072  Acc@1: 81.2500 (77.7232)  Acc@5: 93.7500 (95.3418)  time: 0.3452  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 810/3750]  eta: 0:16:54  Lr: 0.030000  Loss: -0.2744  Acc@1: 81.2500 (77.7281)  Acc@5: 100.0000 (95.3761)  time: 0.3447  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 820/3750]  eta: 0:16:50  Lr: 0.030000  Loss: -0.6324  Acc@1: 81.2500 (77.8091)  Acc@5: 100.0000 (95.3715)  time: 0.3454  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 830/3750]  eta: 0:16:47  Lr: 0.030000  Loss: -0.5066  Acc@1: 81.2500 (77.7978)  Acc@5: 93.7500 (95.3896)  time: 0.3461  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 840/3750]  eta: 0:16:44  Lr: 0.030000  Loss: -0.4971  Acc@1: 75.0000 (77.7720)  Acc@5: 93.7500 (95.3775)  time: 0.3454  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [ 850/3750]  eta: 0:16:40  Lr: 0.030000  Loss: -0.1926  Acc@1: 75.0000 (77.7468)  Acc@5: 93.7500 (95.3804)  time: 0.3449  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [ 860/3750]  eta: 0:16:37  Lr: 0.030000  Loss: -0.5374  Acc@1: 75.0000 (77.7076)  Acc@5: 100.0000 (95.3978)  time: 0.3448  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [ 870/3750]  eta: 0:16:33  Lr: 0.030000  Loss: -0.5744  Acc@1: 75.0000 (77.7555)  Acc@5: 100.0000 (95.3861)  time: 0.3458  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [ 880/3750]  eta: 0:16:30  Lr: 0.030000  Loss: -0.5555  Acc@1: 81.2500 (77.7526)  Acc@5: 93.7500 (95.3604)  time: 0.3457  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [ 890/3750]  eta: 0:16:26  Lr: 0.030000  Loss: -0.0884  Acc@1: 81.2500 (77.7708)  Acc@5: 93.7500 (95.3563)  time: 0.3447  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [ 900/3750]  eta: 0:16:23  Lr: 0.030000  Loss: 0.1092  Acc@1: 81.2500 (77.8441)  Acc@5: 100.0000 (95.3732)  time: 0.3456  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [ 910/3750]  eta: 0:16:19  Lr: 0.030000  Loss: -0.5464  Acc@1: 81.2500 (77.8197)  Acc@5: 93.7500 (95.3554)  time: 0.3447  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [ 920/3750]  eta: 0:16:16  Lr: 0.030000  Loss: -0.7262  Acc@1: 75.0000 (77.8094)  Acc@5: 93.7500 (95.3447)  time: 0.3431  data: 0.0002  max mem: 2500
Train: Epoch[4/5]  [ 930/3750]  eta: 0:16:12  Lr: 0.030000  Loss: -0.3092  Acc@1: 75.0000 (77.8330)  Acc@5: 93.7500 (95.3477)  time: 0.3431  data: 0.0002  max mem: 2500
Train: Epoch[4/5]  [ 940/3750]  eta: 0:16:09  Lr: 0.030000  Loss: -0.1692  Acc@1: 81.2500 (77.8494)  Acc@5: 93.7500 (95.3640)  time: 0.3428  data: 0.0002  max mem: 2500
Train: Epoch[4/5]  [ 950/3750]  eta: 0:16:05  Lr: 0.030000  Loss: -0.4760  Acc@1: 81.2500 (77.8917)  Acc@5: 100.0000 (95.3799)  time: 0.3427  data: 0.0002  max mem: 2500
Train: Epoch[4/5]  [ 960/3750]  eta: 0:16:02  Lr: 0.030000  Loss: -0.2522  Acc@1: 81.2500 (77.9201)  Acc@5: 100.0000 (95.3954)  time: 0.3426  data: 0.0002  max mem: 2500
Train: Epoch[4/5]  [ 970/3750]  eta: 0:15:58  Lr: 0.030000  Loss: -0.4153  Acc@1: 81.2500 (77.9802)  Acc@5: 100.0000 (95.4171)  time: 0.3425  data: 0.0002  max mem: 2500
Train: Epoch[4/5]  [ 980/3750]  eta: 0:15:55  Lr: 0.030000  Loss: -0.3692  Acc@1: 81.2500 (77.9817)  Acc@5: 93.7500 (95.4256)  time: 0.3432  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [ 990/3750]  eta: 0:15:51  Lr: 0.030000  Loss: -0.4310  Acc@1: 81.2500 (77.9768)  Acc@5: 93.7500 (95.4150)  time: 0.3451  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1000/3750]  eta: 0:15:48  Lr: 0.030000  Loss: -0.2205  Acc@1: 75.0000 (77.9408)  Acc@5: 93.7500 (95.4233)  time: 0.3468  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [1010/3750]  eta: 0:15:45  Lr: 0.030000  Loss: -0.2446  Acc@1: 75.0000 (77.9303)  Acc@5: 93.7500 (95.4315)  time: 0.3464  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [1020/3750]  eta: 0:15:41  Lr: 0.030000  Loss: -0.3936  Acc@1: 81.2500 (77.9750)  Acc@5: 93.7500 (95.4273)  time: 0.3460  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1030/3750]  eta: 0:15:38  Lr: 0.030000  Loss: -0.1852  Acc@1: 81.2500 (77.9947)  Acc@5: 93.7500 (95.4292)  time: 0.3466  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1040/3750]  eta: 0:15:34  Lr: 0.030000  Loss: -0.6744  Acc@1: 81.2500 (78.0139)  Acc@5: 100.0000 (95.4371)  time: 0.3460  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1050/3750]  eta: 0:15:31  Lr: 0.030000  Loss: -0.7325  Acc@1: 81.2500 (78.0685)  Acc@5: 93.7500 (95.4329)  time: 0.3455  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1060/3750]  eta: 0:15:27  Lr: 0.030000  Loss: -0.1775  Acc@1: 81.2500 (78.1103)  Acc@5: 93.7500 (95.4465)  time: 0.3452  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1070/3750]  eta: 0:15:24  Lr: 0.030000  Loss: -0.4306  Acc@1: 87.5000 (78.1746)  Acc@5: 100.0000 (95.4715)  time: 0.3449  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1080/3750]  eta: 0:15:21  Lr: 0.030000  Loss: -0.5155  Acc@1: 81.2500 (78.1799)  Acc@5: 100.0000 (95.4787)  time: 0.3455  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1090/3750]  eta: 0:15:17  Lr: 0.030000  Loss: -0.3803  Acc@1: 75.0000 (78.1164)  Acc@5: 93.7500 (95.4285)  time: 0.3469  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1100/3750]  eta: 0:15:14  Lr: 0.030000  Loss: 0.0357  Acc@1: 68.7500 (78.0484)  Acc@5: 93.7500 (95.4133)  time: 0.3460  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1110/3750]  eta: 0:15:10  Lr: 0.030000  Loss: -0.4363  Acc@1: 75.0000 (78.0547)  Acc@5: 93.7500 (95.4095)  time: 0.3442  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [1120/3750]  eta: 0:15:07  Lr: 0.030000  Loss: -0.2527  Acc@1: 75.0000 (78.0163)  Acc@5: 93.7500 (95.3836)  time: 0.3440  data: 0.0002  max mem: 2500
Train: Epoch[4/5]  [1130/3750]  eta: 0:15:03  Lr: 0.030000  Loss: -0.5201  Acc@1: 75.0000 (78.0338)  Acc@5: 93.7500 (95.3857)  time: 0.3443  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [1140/3750]  eta: 0:15:00  Lr: 0.030000  Loss: -0.3200  Acc@1: 75.0000 (77.9963)  Acc@5: 100.0000 (95.4207)  time: 0.3438  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [1150/3750]  eta: 0:14:56  Lr: 0.030000  Loss: -0.3345  Acc@1: 75.0000 (78.0028)  Acc@5: 100.0000 (95.4170)  time: 0.3431  data: 0.0002  max mem: 2500
Train: Epoch[4/5]  [1160/3750]  eta: 0:14:53  Lr: 0.030000  Loss: -0.5924  Acc@1: 81.2500 (78.0093)  Acc@5: 93.7500 (95.4242)  time: 0.3428  data: 0.0002  max mem: 2500
Train: Epoch[4/5]  [1170/3750]  eta: 0:14:49  Lr: 0.030000  Loss: -0.5649  Acc@1: 81.2500 (78.0316)  Acc@5: 100.0000 (95.4526)  time: 0.3436  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [1180/3750]  eta: 0:14:46  Lr: 0.030000  Loss: -0.5527  Acc@1: 81.2500 (78.0430)  Acc@5: 100.0000 (95.4594)  time: 0.3446  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1190/3750]  eta: 0:14:43  Lr: 0.030000  Loss: -0.3658  Acc@1: 75.0000 (78.0227)  Acc@5: 100.0000 (95.4765)  time: 0.3456  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [1200/3750]  eta: 0:14:39  Lr: 0.030000  Loss: -0.7696  Acc@1: 75.0000 (78.0183)  Acc@5: 100.0000 (95.4933)  time: 0.3452  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1210/3750]  eta: 0:14:36  Lr: 0.030000  Loss: -0.3032  Acc@1: 81.2500 (78.0605)  Acc@5: 100.0000 (95.5151)  time: 0.3435  data: 0.0002  max mem: 2500
Train: Epoch[4/5]  [1220/3750]  eta: 0:14:32  Lr: 0.030000  Loss: -0.1170  Acc@1: 75.0000 (78.0508)  Acc@5: 100.0000 (95.5057)  time: 0.3439  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [1230/3750]  eta: 0:14:29  Lr: 0.030000  Loss: -0.3195  Acc@1: 75.0000 (78.0057)  Acc@5: 93.7500 (95.4813)  time: 0.3443  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [1240/3750]  eta: 0:14:25  Lr: 0.030000  Loss: -0.0408  Acc@1: 75.0000 (78.0218)  Acc@5: 93.7500 (95.4825)  time: 0.3451  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [1250/3750]  eta: 0:14:22  Lr: 0.030000  Loss: -0.1449  Acc@1: 75.0000 (78.0176)  Acc@5: 93.7500 (95.4836)  time: 0.3442  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [1260/3750]  eta: 0:14:18  Lr: 0.030000  Loss: -0.5843  Acc@1: 81.2500 (78.0482)  Acc@5: 93.7500 (95.4946)  time: 0.3425  data: 0.0002  max mem: 2500
Train: Epoch[4/5]  [1270/3750]  eta: 0:14:15  Lr: 0.030000  Loss: -0.6330  Acc@1: 81.2500 (78.0488)  Acc@5: 100.0000 (95.5104)  time: 0.3424  data: 0.0002  max mem: 2500
Train: Epoch[4/5]  [1280/3750]  eta: 0:14:11  Lr: 0.030000  Loss: -0.2616  Acc@1: 75.0000 (78.0835)  Acc@5: 100.0000 (95.5162)  time: 0.3423  data: 0.0002  max mem: 2500
Train: Epoch[4/5]  [1290/3750]  eta: 0:14:08  Lr: 0.030000  Loss: -0.5911  Acc@1: 81.2500 (78.0693)  Acc@5: 93.7500 (95.4977)  time: 0.3426  data: 0.0002  max mem: 2500
Train: Epoch[4/5]  [1300/3750]  eta: 0:14:04  Lr: 0.030000  Loss: -0.3859  Acc@1: 81.2500 (78.0746)  Acc@5: 93.7500 (95.5035)  time: 0.3425  data: 0.0002  max mem: 2500
Train: Epoch[4/5]  [1310/3750]  eta: 0:14:01  Lr: 0.030000  Loss: -0.2123  Acc@1: 81.2500 (78.0892)  Acc@5: 100.0000 (95.5092)  time: 0.3426  data: 0.0002  max mem: 2500
Train: Epoch[4/5]  [1320/3750]  eta: 0:13:57  Lr: 0.030000  Loss: -0.0378  Acc@1: 81.2500 (78.0753)  Acc@5: 93.7500 (95.5053)  time: 0.3445  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [1330/3750]  eta: 0:13:54  Lr: 0.030000  Loss: -0.2561  Acc@1: 81.2500 (78.0804)  Acc@5: 100.0000 (95.5156)  time: 0.3463  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1340/3750]  eta: 0:13:50  Lr: 0.030000  Loss: -0.4898  Acc@1: 81.2500 (78.0994)  Acc@5: 100.0000 (95.5397)  time: 0.3457  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [1350/3750]  eta: 0:13:47  Lr: 0.030000  Loss: -0.0828  Acc@1: 81.2500 (78.1134)  Acc@5: 100.0000 (95.5311)  time: 0.3455  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1360/3750]  eta: 0:13:44  Lr: 0.030000  Loss: -0.4422  Acc@1: 81.2500 (78.1135)  Acc@5: 93.7500 (95.5318)  time: 0.3464  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1370/3750]  eta: 0:13:40  Lr: 0.030000  Loss: -0.2326  Acc@1: 75.0000 (78.0954)  Acc@5: 93.7500 (95.5279)  time: 0.3463  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1380/3750]  eta: 0:13:37  Lr: 0.030000  Loss: -0.2546  Acc@1: 75.0000 (78.0820)  Acc@5: 100.0000 (95.5422)  time: 0.3459  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1390/3750]  eta: 0:13:33  Lr: 0.030000  Loss: -0.3648  Acc@1: 75.0000 (78.0598)  Acc@5: 93.7500 (95.5248)  time: 0.3464  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1400/3750]  eta: 0:13:30  Lr: 0.030000  Loss: -0.4600  Acc@1: 75.0000 (78.0335)  Acc@5: 93.7500 (95.4988)  time: 0.3468  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [1410/3750]  eta: 0:13:26  Lr: 0.030000  Loss: -0.3428  Acc@1: 81.2500 (78.0386)  Acc@5: 93.7500 (95.4864)  time: 0.3459  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [1420/3750]  eta: 0:13:23  Lr: 0.030000  Loss: -0.0873  Acc@1: 75.0000 (78.0260)  Acc@5: 93.7500 (95.4829)  time: 0.3454  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1430/3750]  eta: 0:13:20  Lr: 0.030000  Loss: -0.3321  Acc@1: 75.0000 (78.0005)  Acc@5: 93.7500 (95.4883)  time: 0.3451  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1440/3750]  eta: 0:13:16  Lr: 0.030000  Loss: -0.5249  Acc@1: 81.2500 (78.0361)  Acc@5: 93.7500 (95.4892)  time: 0.3490  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1450/3750]  eta: 0:13:13  Lr: 0.030000  Loss: -0.0112  Acc@1: 81.2500 (78.0539)  Acc@5: 93.7500 (95.4945)  time: 0.3488  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [1460/3750]  eta: 0:13:09  Lr: 0.030000  Loss: -0.2206  Acc@1: 81.2500 (78.0672)  Acc@5: 93.7500 (95.4997)  time: 0.3445  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [1470/3750]  eta: 0:13:06  Lr: 0.030000  Loss: -0.5049  Acc@1: 81.2500 (78.0761)  Acc@5: 93.7500 (95.5005)  time: 0.3448  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [1480/3750]  eta: 0:13:02  Lr: 0.030000  Loss: -0.2322  Acc@1: 75.0000 (78.0638)  Acc@5: 93.7500 (95.4971)  time: 0.3451  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [1490/3750]  eta: 0:12:59  Lr: 0.030000  Loss: -0.3650  Acc@1: 75.0000 (78.0433)  Acc@5: 93.7500 (95.4770)  time: 0.3452  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [1500/3750]  eta: 0:12:56  Lr: 0.030000  Loss: -0.6138  Acc@1: 81.2500 (78.0813)  Acc@5: 93.7500 (95.4822)  time: 0.3451  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [1510/3750]  eta: 0:12:52  Lr: 0.030000  Loss: -0.2440  Acc@1: 81.2500 (78.0816)  Acc@5: 100.0000 (95.4790)  time: 0.3458  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [1520/3750]  eta: 0:12:49  Lr: 0.030000  Loss: -0.3136  Acc@1: 81.2500 (78.0983)  Acc@5: 100.0000 (95.4882)  time: 0.3469  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [1530/3750]  eta: 0:12:45  Lr: 0.030000  Loss: -0.5355  Acc@1: 81.2500 (78.1230)  Acc@5: 93.7500 (95.4768)  time: 0.3464  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [1540/3750]  eta: 0:12:42  Lr: 0.030000  Loss: -0.3835  Acc@1: 81.2500 (78.1230)  Acc@5: 93.7500 (95.4656)  time: 0.3441  data: 0.0002  max mem: 2500
Train: Epoch[4/5]  [1550/3750]  eta: 0:12:38  Lr: 0.030000  Loss: -0.2861  Acc@1: 81.2500 (78.1069)  Acc@5: 93.7500 (95.4666)  time: 0.3429  data: 0.0002  max mem: 2500
Train: Epoch[4/5]  [1560/3750]  eta: 0:12:35  Lr: 0.030000  Loss: -0.5686  Acc@1: 75.0000 (78.0990)  Acc@5: 93.7500 (95.4676)  time: 0.3428  data: 0.0002  max mem: 2500
Train: Epoch[4/5]  [1570/3750]  eta: 0:12:31  Lr: 0.030000  Loss: -0.1396  Acc@1: 68.7500 (78.0792)  Acc@5: 93.7500 (95.4607)  time: 0.3430  data: 0.0002  max mem: 2500
Train: Epoch[4/5]  [1580/3750]  eta: 0:12:28  Lr: 0.030000  Loss: -0.4115  Acc@1: 75.0000 (78.0914)  Acc@5: 93.7500 (95.4538)  time: 0.3432  data: 0.0002  max mem: 2500
Train: Epoch[4/5]  [1590/3750]  eta: 0:12:24  Lr: 0.030000  Loss: -0.2340  Acc@1: 81.2500 (78.1034)  Acc@5: 93.7500 (95.4510)  time: 0.3432  data: 0.0002  max mem: 2500
Train: Epoch[4/5]  [1600/3750]  eta: 0:12:21  Lr: 0.030000  Loss: -0.5343  Acc@1: 81.2500 (78.1152)  Acc@5: 93.7500 (95.4521)  time: 0.3431  data: 0.0002  max mem: 2500
Train: Epoch[4/5]  [1610/3750]  eta: 0:12:18  Lr: 0.030000  Loss: -0.4728  Acc@1: 75.0000 (78.1153)  Acc@5: 93.7500 (95.4570)  time: 0.3430  data: 0.0002  max mem: 2500
Train: Epoch[4/5]  [1620/3750]  eta: 0:12:14  Lr: 0.030000  Loss: -0.4804  Acc@1: 81.2500 (78.1771)  Acc@5: 100.0000 (95.4619)  time: 0.3441  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [1630/3750]  eta: 0:12:11  Lr: 0.030000  Loss: -0.6132  Acc@1: 87.5000 (78.2074)  Acc@5: 93.7500 (95.4629)  time: 0.3458  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1640/3750]  eta: 0:12:07  Lr: 0.030000  Loss: -0.1400  Acc@1: 81.2500 (78.2031)  Acc@5: 93.7500 (95.4601)  time: 0.3459  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1650/3750]  eta: 0:12:04  Lr: 0.030000  Loss: -0.6720  Acc@1: 81.2500 (78.2215)  Acc@5: 100.0000 (95.4687)  time: 0.3457  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1660/3750]  eta: 0:12:00  Lr: 0.030000  Loss: -0.4177  Acc@1: 81.2500 (78.2398)  Acc@5: 100.0000 (95.4696)  time: 0.3457  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1670/3750]  eta: 0:11:57  Lr: 0.030000  Loss: 0.0486  Acc@1: 75.0000 (78.2054)  Acc@5: 93.7500 (95.4593)  time: 0.3451  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1680/3750]  eta: 0:11:53  Lr: 0.030000  Loss: -0.5932  Acc@1: 75.0000 (78.2049)  Acc@5: 93.7500 (95.4677)  time: 0.3452  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1690/3750]  eta: 0:11:50  Lr: 0.030000  Loss: -0.2147  Acc@1: 75.0000 (78.1786)  Acc@5: 100.0000 (95.4650)  time: 0.3448  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1700/3750]  eta: 0:11:47  Lr: 0.030000  Loss: -0.7955  Acc@1: 75.0000 (78.1856)  Acc@5: 93.7500 (95.4696)  time: 0.3444  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1710/3750]  eta: 0:11:43  Lr: 0.030000  Loss: -0.3253  Acc@1: 81.2500 (78.2072)  Acc@5: 93.7500 (95.4705)  time: 0.3444  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1720/3750]  eta: 0:11:40  Lr: 0.030000  Loss: -0.3554  Acc@1: 81.2500 (78.1886)  Acc@5: 100.0000 (95.4823)  time: 0.3444  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1730/3750]  eta: 0:11:36  Lr: 0.030000  Loss: -0.2766  Acc@1: 75.0000 (78.1990)  Acc@5: 100.0000 (95.4831)  time: 0.3447  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1740/3750]  eta: 0:11:33  Lr: 0.030000  Loss: -0.3797  Acc@1: 75.0000 (78.1806)  Acc@5: 93.7500 (95.4624)  time: 0.3449  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1750/3750]  eta: 0:11:29  Lr: 0.030000  Loss: -0.4717  Acc@1: 81.2500 (78.1946)  Acc@5: 93.7500 (95.4704)  time: 0.3451  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1760/3750]  eta: 0:11:26  Lr: 0.030000  Loss: -0.2998  Acc@1: 81.2500 (78.1942)  Acc@5: 100.0000 (95.4749)  time: 0.3458  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1770/3750]  eta: 0:11:22  Lr: 0.030000  Loss: -0.5636  Acc@1: 81.2500 (78.2256)  Acc@5: 100.0000 (95.4969)  time: 0.3488  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1780/3750]  eta: 0:11:19  Lr: 0.030000  Loss: -0.3954  Acc@1: 81.2500 (78.2285)  Acc@5: 100.0000 (95.5011)  time: 0.3482  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [1790/3750]  eta: 0:11:16  Lr: 0.030000  Loss: -0.3455  Acc@1: 75.0000 (78.2175)  Acc@5: 93.7500 (95.5018)  time: 0.3449  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [1800/3750]  eta: 0:11:12  Lr: 0.030000  Loss: -0.4475  Acc@1: 75.0000 (78.2170)  Acc@5: 93.7500 (95.4747)  time: 0.3449  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [1810/3750]  eta: 0:11:09  Lr: 0.030000  Loss: -0.0525  Acc@1: 81.2500 (78.2441)  Acc@5: 93.7500 (95.4756)  time: 0.3452  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [1820/3750]  eta: 0:11:05  Lr: 0.030000  Loss: -0.4403  Acc@1: 81.2500 (78.2640)  Acc@5: 93.7500 (95.4833)  time: 0.3450  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [1830/3750]  eta: 0:11:02  Lr: 0.030000  Loss: -0.1890  Acc@1: 81.2500 (78.2837)  Acc@5: 93.7500 (95.4806)  time: 0.3447  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [1840/3750]  eta: 0:10:58  Lr: 0.030000  Loss: -0.4597  Acc@1: 81.2500 (78.2863)  Acc@5: 93.7500 (95.4644)  time: 0.3452  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [1850/3750]  eta: 0:10:55  Lr: 0.030000  Loss: -0.1745  Acc@1: 75.0000 (78.2753)  Acc@5: 93.7500 (95.4687)  time: 0.3445  data: 0.0002  max mem: 2500
Train: Epoch[4/5]  [1860/3750]  eta: 0:10:51  Lr: 0.030000  Loss: -0.4445  Acc@1: 75.0000 (78.2744)  Acc@5: 100.0000 (95.4661)  time: 0.3430  data: 0.0002  max mem: 2500
Train: Epoch[4/5]  [1870/3750]  eta: 0:10:48  Lr: 0.030000  Loss: -0.4818  Acc@1: 81.2500 (78.2937)  Acc@5: 93.7500 (95.4670)  time: 0.3430  data: 0.0002  max mem: 2500
Train: Epoch[4/5]  [1880/3750]  eta: 0:10:44  Lr: 0.030000  Loss: -0.3584  Acc@1: 75.0000 (78.2596)  Acc@5: 93.7500 (95.4678)  time: 0.3431  data: 0.0002  max mem: 2500
Train: Epoch[4/5]  [1890/3750]  eta: 0:10:41  Lr: 0.030000  Loss: -0.3813  Acc@1: 75.0000 (78.2787)  Acc@5: 93.7500 (95.4588)  time: 0.3429  data: 0.0002  max mem: 2500
Train: Epoch[4/5]  [1900/3750]  eta: 0:10:38  Lr: 0.030000  Loss: -0.5990  Acc@1: 81.2500 (78.3075)  Acc@5: 93.7500 (95.4662)  time: 0.3430  data: 0.0002  max mem: 2500
Train: Epoch[4/5]  [1910/3750]  eta: 0:10:34  Lr: 0.030000  Loss: -0.4312  Acc@1: 81.2500 (78.3000)  Acc@5: 93.7500 (95.4670)  time: 0.3432  data: 0.0002  max mem: 2500
Train: Epoch[4/5]  [1920/3750]  eta: 0:10:31  Lr: 0.030000  Loss: -0.4429  Acc@1: 75.0000 (78.2795)  Acc@5: 100.0000 (95.4744)  time: 0.3434  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [1930/3750]  eta: 0:10:27  Lr: 0.030000  Loss: -0.2082  Acc@1: 75.0000 (78.2690)  Acc@5: 100.0000 (95.4913)  time: 0.3441  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1940/3750]  eta: 0:10:24  Lr: 0.030000  Loss: -0.1980  Acc@1: 75.0000 (78.2329)  Acc@5: 100.0000 (95.5017)  time: 0.3447  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1950/3750]  eta: 0:10:20  Lr: 0.030000  Loss: -0.1799  Acc@1: 75.0000 (78.2323)  Acc@5: 100.0000 (95.5023)  time: 0.3446  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1960/3750]  eta: 0:10:17  Lr: 0.030000  Loss: -0.2641  Acc@1: 81.2500 (78.2700)  Acc@5: 93.7500 (95.5093)  time: 0.3449  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1970/3750]  eta: 0:10:13  Lr: 0.030000  Loss: -0.2711  Acc@1: 81.2500 (78.2725)  Acc@5: 93.7500 (95.5099)  time: 0.3449  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1980/3750]  eta: 0:10:10  Lr: 0.030000  Loss: -0.5614  Acc@1: 81.2500 (78.3096)  Acc@5: 100.0000 (95.5262)  time: 0.3444  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [1990/3750]  eta: 0:10:06  Lr: 0.030000  Loss: -0.3753  Acc@1: 81.2500 (78.3118)  Acc@5: 100.0000 (95.5267)  time: 0.3443  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2000/3750]  eta: 0:10:03  Lr: 0.030000  Loss: -0.2673  Acc@1: 75.0000 (78.3077)  Acc@5: 93.7500 (95.5304)  time: 0.3443  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2010/3750]  eta: 0:10:00  Lr: 0.030000  Loss: -0.2207  Acc@1: 75.0000 (78.3037)  Acc@5: 100.0000 (95.5370)  time: 0.3454  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2020/3750]  eta: 0:09:56  Lr: 0.030000  Loss: -0.4741  Acc@1: 75.0000 (78.2935)  Acc@5: 100.0000 (95.5406)  time: 0.3468  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2030/3750]  eta: 0:09:53  Lr: 0.030000  Loss: -0.4531  Acc@1: 75.0000 (78.3050)  Acc@5: 100.0000 (95.5441)  time: 0.3463  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2040/3750]  eta: 0:09:49  Lr: 0.030000  Loss: -0.2791  Acc@1: 75.0000 (78.3072)  Acc@5: 93.7500 (95.5383)  time: 0.3455  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2050/3750]  eta: 0:09:46  Lr: 0.030000  Loss: -0.3530  Acc@1: 81.2500 (78.3002)  Acc@5: 93.7500 (95.5235)  time: 0.3459  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2060/3750]  eta: 0:09:42  Lr: 0.030000  Loss: -0.6260  Acc@1: 81.2500 (78.3115)  Acc@5: 93.7500 (95.5210)  time: 0.3455  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [2070/3750]  eta: 0:09:39  Lr: 0.030000  Loss: -0.6141  Acc@1: 81.2500 (78.3227)  Acc@5: 93.7500 (95.5185)  time: 0.3449  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [2080/3750]  eta: 0:09:35  Lr: 0.030000  Loss: -0.5777  Acc@1: 81.2500 (78.3127)  Acc@5: 93.7500 (95.5190)  time: 0.3451  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [2090/3750]  eta: 0:09:32  Lr: 0.030000  Loss: -0.0864  Acc@1: 75.0000 (78.2969)  Acc@5: 93.7500 (95.5225)  time: 0.3453  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [2100/3750]  eta: 0:09:29  Lr: 0.030000  Loss: 0.1102  Acc@1: 75.0000 (78.3079)  Acc@5: 100.0000 (95.5230)  time: 0.3447  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [2110/3750]  eta: 0:09:25  Lr: 0.030000  Loss: -0.4868  Acc@1: 81.2500 (78.3367)  Acc@5: 100.0000 (95.5294)  time: 0.3441  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [2120/3750]  eta: 0:09:22  Lr: 0.030000  Loss: -0.4800  Acc@1: 81.2500 (78.3386)  Acc@5: 100.0000 (95.5387)  time: 0.3454  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [2130/3750]  eta: 0:09:18  Lr: 0.030000  Loss: -0.2840  Acc@1: 75.0000 (78.3112)  Acc@5: 93.7500 (95.5303)  time: 0.3445  data: 0.0002  max mem: 2500
Train: Epoch[4/5]  [2140/3750]  eta: 0:09:15  Lr: 0.030000  Loss: -0.6824  Acc@1: 75.0000 (78.3250)  Acc@5: 93.7500 (95.5307)  time: 0.3422  data: 0.0002  max mem: 2500
Train: Epoch[4/5]  [2150/3750]  eta: 0:09:11  Lr: 0.030000  Loss: -0.4460  Acc@1: 81.2500 (78.3269)  Acc@5: 93.7500 (95.5137)  time: 0.3422  data: 0.0002  max mem: 2500
Train: Epoch[4/5]  [2160/3750]  eta: 0:09:08  Lr: 0.030000  Loss: -0.3239  Acc@1: 75.0000 (78.3029)  Acc@5: 93.7500 (95.5171)  time: 0.3426  data: 0.0002  max mem: 2500
Train: Epoch[4/5]  [2170/3750]  eta: 0:09:04  Lr: 0.030000  Loss: -0.3410  Acc@1: 75.0000 (78.3078)  Acc@5: 100.0000 (95.5263)  time: 0.3426  data: 0.0002  max mem: 2500
Train: Epoch[4/5]  [2180/3750]  eta: 0:09:01  Lr: 0.030000  Loss: -0.3057  Acc@1: 81.2500 (78.3270)  Acc@5: 100.0000 (95.5267)  time: 0.3423  data: 0.0002  max mem: 2500
Train: Epoch[4/5]  [2190/3750]  eta: 0:08:57  Lr: 0.030000  Loss: -0.5788  Acc@1: 81.2500 (78.3290)  Acc@5: 93.7500 (95.5186)  time: 0.3423  data: 0.0002  max mem: 2500
Train: Epoch[4/5]  [2200/3750]  eta: 0:08:54  Lr: 0.030000  Loss: -0.4928  Acc@1: 75.0000 (78.3167)  Acc@5: 93.7500 (95.5191)  time: 0.3424  data: 0.0002  max mem: 2500
Train: Epoch[4/5]  [2210/3750]  eta: 0:08:50  Lr: 0.030000  Loss: -0.4592  Acc@1: 81.2500 (78.3299)  Acc@5: 93.7500 (95.5139)  time: 0.3426  data: 0.0002  max mem: 2500
Train: Epoch[4/5]  [2220/3750]  eta: 0:08:47  Lr: 0.030000  Loss: -0.0828  Acc@1: 81.2500 (78.3515)  Acc@5: 93.7500 (95.5088)  time: 0.3437  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [2230/3750]  eta: 0:08:44  Lr: 0.030000  Loss: -0.7183  Acc@1: 81.2500 (78.3505)  Acc@5: 93.7500 (95.5093)  time: 0.3445  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2240/3750]  eta: 0:08:40  Lr: 0.030000  Loss: -0.7472  Acc@1: 81.2500 (78.3495)  Acc@5: 100.0000 (95.5126)  time: 0.3443  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2250/3750]  eta: 0:08:37  Lr: 0.030000  Loss: -0.5868  Acc@1: 81.2500 (78.3457)  Acc@5: 100.0000 (95.5131)  time: 0.3442  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2260/3750]  eta: 0:08:33  Lr: 0.030000  Loss: -0.5854  Acc@1: 81.2500 (78.3448)  Acc@5: 93.7500 (95.5136)  time: 0.3450  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2270/3750]  eta: 0:08:30  Lr: 0.030000  Loss: -0.3528  Acc@1: 75.0000 (78.3218)  Acc@5: 93.7500 (95.5113)  time: 0.3448  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2280/3750]  eta: 0:08:26  Lr: 0.030000  Loss: -0.4197  Acc@1: 81.2500 (78.3291)  Acc@5: 100.0000 (95.5146)  time: 0.3442  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2290/3750]  eta: 0:08:23  Lr: 0.030000  Loss: -0.5013  Acc@1: 81.2500 (78.3282)  Acc@5: 100.0000 (95.5123)  time: 0.3450  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2300/3750]  eta: 0:08:19  Lr: 0.030000  Loss: -0.4226  Acc@1: 75.0000 (78.3274)  Acc@5: 93.7500 (95.5128)  time: 0.3445  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2310/3750]  eta: 0:08:16  Lr: 0.030000  Loss: -0.4612  Acc@1: 75.0000 (78.3211)  Acc@5: 93.7500 (95.5133)  time: 0.3446  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2320/3750]  eta: 0:08:13  Lr: 0.030000  Loss: -0.3082  Acc@1: 75.0000 (78.3337)  Acc@5: 100.0000 (95.5192)  time: 0.3448  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2330/3750]  eta: 0:08:09  Lr: 0.030000  Loss: -0.0784  Acc@1: 75.0000 (78.3140)  Acc@5: 93.7500 (95.5062)  time: 0.3440  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [2340/3750]  eta: 0:08:06  Lr: 0.030000  Loss: -0.6497  Acc@1: 75.0000 (78.3239)  Acc@5: 93.7500 (95.5174)  time: 0.3439  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [2350/3750]  eta: 0:08:02  Lr: 0.030000  Loss: -0.5288  Acc@1: 81.2500 (78.3257)  Acc@5: 100.0000 (95.5205)  time: 0.3444  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2360/3750]  eta: 0:07:59  Lr: 0.030000  Loss: -0.2039  Acc@1: 81.2500 (78.3249)  Acc@5: 93.7500 (95.5024)  time: 0.3446  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2370/3750]  eta: 0:07:55  Lr: 0.030000  Loss: -0.6615  Acc@1: 81.2500 (78.3346)  Acc@5: 93.7500 (95.5082)  time: 0.3450  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [2380/3750]  eta: 0:07:52  Lr: 0.030000  Loss: -0.3955  Acc@1: 81.2500 (78.3337)  Acc@5: 93.7500 (95.5008)  time: 0.3453  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2390/3750]  eta: 0:07:48  Lr: 0.030000  Loss: -0.3000  Acc@1: 81.2500 (78.3485)  Acc@5: 93.7500 (95.4987)  time: 0.3451  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2400/3750]  eta: 0:07:45  Lr: 0.030000  Loss: -0.5861  Acc@1: 81.2500 (78.3450)  Acc@5: 93.7500 (95.4993)  time: 0.3456  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2410/3750]  eta: 0:07:41  Lr: 0.030000  Loss: -0.5823  Acc@1: 75.0000 (78.3337)  Acc@5: 93.7500 (95.4946)  time: 0.3453  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2420/3750]  eta: 0:07:38  Lr: 0.030000  Loss: -0.6461  Acc@1: 81.2500 (78.3535)  Acc@5: 93.7500 (95.5003)  time: 0.3446  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [2430/3750]  eta: 0:07:35  Lr: 0.030000  Loss: -0.5314  Acc@1: 81.2500 (78.3474)  Acc@5: 93.7500 (95.4957)  time: 0.3445  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [2440/3750]  eta: 0:07:31  Lr: 0.030000  Loss: -0.7111  Acc@1: 81.2500 (78.3721)  Acc@5: 93.7500 (95.5013)  time: 0.3448  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2450/3750]  eta: 0:07:28  Lr: 0.030000  Loss: -0.4939  Acc@1: 81.2500 (78.3609)  Acc@5: 100.0000 (95.5069)  time: 0.3452  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2460/3750]  eta: 0:07:24  Lr: 0.030000  Loss: -0.3308  Acc@1: 81.2500 (78.3777)  Acc@5: 100.0000 (95.5176)  time: 0.3448  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [2470/3750]  eta: 0:07:21  Lr: 0.030000  Loss: -0.5562  Acc@1: 87.5000 (78.4045)  Acc@5: 100.0000 (95.5231)  time: 0.3446  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [2480/3750]  eta: 0:07:17  Lr: 0.030000  Loss: -0.7414  Acc@1: 87.5000 (78.4210)  Acc@5: 93.7500 (95.5184)  time: 0.3452  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [2490/3750]  eta: 0:07:14  Lr: 0.030000  Loss: -0.4021  Acc@1: 81.2500 (78.4298)  Acc@5: 93.7500 (95.5189)  time: 0.3444  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [2500/3750]  eta: 0:07:10  Lr: 0.030000  Loss: -0.4908  Acc@1: 81.2500 (78.4236)  Acc@5: 100.0000 (95.5293)  time: 0.3435  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [2510/3750]  eta: 0:07:07  Lr: 0.030000  Loss: -0.7043  Acc@1: 81.2500 (78.4349)  Acc@5: 100.0000 (95.5247)  time: 0.3434  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [2520/3750]  eta: 0:07:04  Lr: 0.030000  Loss: -0.2519  Acc@1: 75.0000 (78.4113)  Acc@5: 93.7500 (95.5276)  time: 0.3435  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [2530/3750]  eta: 0:07:00  Lr: 0.030000  Loss: -0.2037  Acc@1: 75.0000 (78.4028)  Acc@5: 93.7500 (95.5304)  time: 0.3429  data: 0.0002  max mem: 2500
Train: Epoch[4/5]  [2540/3750]  eta: 0:06:57  Lr: 0.030000  Loss: -0.6236  Acc@1: 75.0000 (78.3919)  Acc@5: 93.7500 (95.5210)  time: 0.3438  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [2550/3750]  eta: 0:06:53  Lr: 0.030000  Loss: -0.3599  Acc@1: 75.0000 (78.3957)  Acc@5: 93.7500 (95.5189)  time: 0.3452  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2560/3750]  eta: 0:06:50  Lr: 0.030000  Loss: -0.3589  Acc@1: 81.2500 (78.3825)  Acc@5: 93.7500 (95.5071)  time: 0.3443  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [2570/3750]  eta: 0:06:46  Lr: 0.030000  Loss: -0.6279  Acc@1: 75.0000 (78.3790)  Acc@5: 93.7500 (95.5100)  time: 0.3443  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2580/3750]  eta: 0:06:43  Lr: 0.030000  Loss: -0.3755  Acc@1: 75.0000 (78.3877)  Acc@5: 100.0000 (95.5105)  time: 0.3453  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2590/3750]  eta: 0:06:39  Lr: 0.030000  Loss: -0.5186  Acc@1: 75.0000 (78.3819)  Acc@5: 93.7500 (95.5061)  time: 0.3449  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2600/3750]  eta: 0:06:36  Lr: 0.030000  Loss: -0.2446  Acc@1: 81.2500 (78.3881)  Acc@5: 93.7500 (95.5161)  time: 0.3442  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2610/3750]  eta: 0:06:33  Lr: 0.030000  Loss: -0.4301  Acc@1: 81.2500 (78.3775)  Acc@5: 100.0000 (95.5118)  time: 0.3446  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2620/3750]  eta: 0:06:29  Lr: 0.030000  Loss: -0.4015  Acc@1: 75.0000 (78.3480)  Acc@5: 93.7500 (95.5051)  time: 0.3472  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2630/3750]  eta: 0:06:26  Lr: 0.030000  Loss: -0.7269  Acc@1: 68.7500 (78.3471)  Acc@5: 100.0000 (95.5055)  time: 0.3470  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [2640/3750]  eta: 0:06:22  Lr: 0.030000  Loss: -0.4088  Acc@1: 81.2500 (78.3652)  Acc@5: 100.0000 (95.5083)  time: 0.3442  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [2650/3750]  eta: 0:06:19  Lr: 0.030000  Loss: -0.3615  Acc@1: 81.2500 (78.3855)  Acc@5: 93.7500 (95.5041)  time: 0.3442  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [2660/3750]  eta: 0:06:15  Lr: 0.030000  Loss: -0.5205  Acc@1: 81.2500 (78.3916)  Acc@5: 93.7500 (95.5092)  time: 0.3441  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [2670/3750]  eta: 0:06:12  Lr: 0.030000  Loss: -0.3969  Acc@1: 81.2500 (78.3999)  Acc@5: 100.0000 (95.5190)  time: 0.3439  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [2680/3750]  eta: 0:06:08  Lr: 0.030000  Loss: -0.3993  Acc@1: 81.2500 (78.4129)  Acc@5: 100.0000 (95.5241)  time: 0.3440  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [2690/3750]  eta: 0:06:05  Lr: 0.030000  Loss: -0.4181  Acc@1: 81.2500 (78.4234)  Acc@5: 100.0000 (95.5291)  time: 0.3445  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [2700/3750]  eta: 0:06:01  Lr: 0.030000  Loss: -0.5724  Acc@1: 81.2500 (78.4455)  Acc@5: 93.7500 (95.5294)  time: 0.3441  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [2710/3750]  eta: 0:05:58  Lr: 0.030000  Loss: -0.2472  Acc@1: 87.5000 (78.4604)  Acc@5: 93.7500 (95.5298)  time: 0.3432  data: 0.0002  max mem: 2500
Train: Epoch[4/5]  [2720/3750]  eta: 0:05:55  Lr: 0.030000  Loss: -0.2729  Acc@1: 81.2500 (78.4500)  Acc@5: 93.7500 (95.5278)  time: 0.3432  data: 0.0002  max mem: 2500
Train: Epoch[4/5]  [2730/3750]  eta: 0:05:51  Lr: 0.030000  Loss: -0.4968  Acc@1: 75.0000 (78.4328)  Acc@5: 93.7500 (95.5259)  time: 0.3431  data: 0.0002  max mem: 2500
Train: Epoch[4/5]  [2740/3750]  eta: 0:05:48  Lr: 0.030000  Loss: -0.4216  Acc@1: 75.0000 (78.4476)  Acc@5: 100.0000 (95.5354)  time: 0.3432  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [2750/3750]  eta: 0:05:44  Lr: 0.030000  Loss: -0.6204  Acc@1: 81.2500 (78.4419)  Acc@5: 100.0000 (95.5425)  time: 0.3428  data: 0.0002  max mem: 2500
Train: Epoch[4/5]  [2760/3750]  eta: 0:05:41  Lr: 0.030000  Loss: -0.5992  Acc@1: 81.2500 (78.4476)  Acc@5: 93.7500 (95.5406)  time: 0.3423  data: 0.0002  max mem: 2500
Train: Epoch[4/5]  [2770/3750]  eta: 0:05:37  Lr: 0.030000  Loss: -0.2943  Acc@1: 81.2500 (78.4419)  Acc@5: 93.7500 (95.5431)  time: 0.3442  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [2780/3750]  eta: 0:05:34  Lr: 0.030000  Loss: -0.5798  Acc@1: 81.2500 (78.4655)  Acc@5: 100.0000 (95.5502)  time: 0.3463  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2790/3750]  eta: 0:05:30  Lr: 0.030000  Loss: -0.4718  Acc@1: 81.2500 (78.4732)  Acc@5: 100.0000 (95.5594)  time: 0.3462  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2800/3750]  eta: 0:05:27  Lr: 0.030000  Loss: -0.6717  Acc@1: 81.2500 (78.4965)  Acc@5: 100.0000 (95.5619)  time: 0.3452  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2810/3750]  eta: 0:05:24  Lr: 0.030000  Loss: -0.2264  Acc@1: 81.2500 (78.4974)  Acc@5: 93.7500 (95.5621)  time: 0.3452  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2820/3750]  eta: 0:05:20  Lr: 0.030000  Loss: -0.4216  Acc@1: 81.2500 (78.4917)  Acc@5: 93.7500 (95.5645)  time: 0.3454  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2830/3750]  eta: 0:05:17  Lr: 0.030000  Loss: -0.3642  Acc@1: 81.2500 (78.5058)  Acc@5: 93.7500 (95.5625)  time: 0.3455  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2840/3750]  eta: 0:05:13  Lr: 0.030000  Loss: -0.6420  Acc@1: 81.2500 (78.5111)  Acc@5: 93.7500 (95.5649)  time: 0.3461  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2850/3750]  eta: 0:05:10  Lr: 0.030000  Loss: -0.5156  Acc@1: 81.2500 (78.5207)  Acc@5: 100.0000 (95.5717)  time: 0.3461  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2860/3750]  eta: 0:05:06  Lr: 0.030000  Loss: -0.4055  Acc@1: 81.2500 (78.5324)  Acc@5: 93.7500 (95.5697)  time: 0.3456  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2870/3750]  eta: 0:05:03  Lr: 0.030000  Loss: -0.3248  Acc@1: 81.2500 (78.5245)  Acc@5: 93.7500 (95.5743)  time: 0.3460  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2880/3750]  eta: 0:04:59  Lr: 0.030000  Loss: -0.2227  Acc@1: 75.0000 (78.5231)  Acc@5: 93.7500 (95.5701)  time: 0.3475  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2890/3750]  eta: 0:04:56  Lr: 0.030000  Loss: -0.3934  Acc@1: 81.2500 (78.5239)  Acc@5: 93.7500 (95.5746)  time: 0.3471  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2900/3750]  eta: 0:04:53  Lr: 0.030000  Loss: -0.1762  Acc@1: 75.0000 (78.5203)  Acc@5: 100.0000 (95.5726)  time: 0.3452  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [2910/3750]  eta: 0:04:49  Lr: 0.030000  Loss: -0.8717  Acc@1: 75.0000 (78.5233)  Acc@5: 100.0000 (95.5793)  time: 0.3448  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [2920/3750]  eta: 0:04:46  Lr: 0.030000  Loss: -0.4187  Acc@1: 75.0000 (78.5112)  Acc@5: 93.7500 (95.5751)  time: 0.3449  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [2930/3750]  eta: 0:04:42  Lr: 0.030000  Loss: -0.7331  Acc@1: 75.0000 (78.5184)  Acc@5: 93.7500 (95.5817)  time: 0.3449  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [2940/3750]  eta: 0:04:39  Lr: 0.030000  Loss: -0.4122  Acc@1: 87.5000 (78.5362)  Acc@5: 100.0000 (95.5882)  time: 0.3449  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [2950/3750]  eta: 0:04:35  Lr: 0.030000  Loss: -0.6522  Acc@1: 81.2500 (78.5369)  Acc@5: 100.0000 (95.5968)  time: 0.3450  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [2960/3750]  eta: 0:04:32  Lr: 0.030000  Loss: -0.4256  Acc@1: 81.2500 (78.5398)  Acc@5: 100.0000 (95.5990)  time: 0.3448  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [2970/3750]  eta: 0:04:28  Lr: 0.030000  Loss: -0.4464  Acc@1: 81.2500 (78.5363)  Acc@5: 93.7500 (95.5991)  time: 0.3442  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [2980/3750]  eta: 0:04:25  Lr: 0.030000  Loss: -0.5757  Acc@1: 81.2500 (78.5412)  Acc@5: 93.7500 (95.5992)  time: 0.3439  data: 0.0002  max mem: 2500
Train: Epoch[4/5]  [2990/3750]  eta: 0:04:22  Lr: 0.030000  Loss: -0.3152  Acc@1: 75.0000 (78.5252)  Acc@5: 93.7500 (95.5993)  time: 0.3438  data: 0.0002  max mem: 2500
Train: Epoch[4/5]  [3000/3750]  eta: 0:04:18  Lr: 0.030000  Loss: -0.2522  Acc@1: 75.0000 (78.5155)  Acc@5: 93.7500 (95.5973)  time: 0.3437  data: 0.0002  max mem: 2500
Train: Epoch[4/5]  [3010/3750]  eta: 0:04:15  Lr: 0.030000  Loss: -0.0686  Acc@1: 75.0000 (78.5163)  Acc@5: 93.7500 (95.5974)  time: 0.3436  data: 0.0002  max mem: 2500
Train: Epoch[4/5]  [3020/3750]  eta: 0:04:11  Lr: 0.030000  Loss: -0.5349  Acc@1: 81.2500 (78.5129)  Acc@5: 93.7500 (95.5933)  time: 0.3433  data: 0.0002  max mem: 2500
Train: Epoch[4/5]  [3030/3750]  eta: 0:04:08  Lr: 0.030000  Loss: -0.3582  Acc@1: 75.0000 (78.4931)  Acc@5: 93.7500 (95.5914)  time: 0.3435  data: 0.0002  max mem: 2500
Train: Epoch[4/5]  [3040/3750]  eta: 0:04:04  Lr: 0.030000  Loss: -0.1551  Acc@1: 75.0000 (78.4939)  Acc@5: 93.7500 (95.5833)  time: 0.3438  data: 0.0002  max mem: 2500
Train: Epoch[4/5]  [3050/3750]  eta: 0:04:01  Lr: 0.030000  Loss: -0.1236  Acc@1: 81.2500 (78.4866)  Acc@5: 93.7500 (95.5855)  time: 0.3440  data: 0.0002  max mem: 2500
Train: Epoch[4/5]  [3060/3750]  eta: 0:03:57  Lr: 0.030000  Loss: -0.3912  Acc@1: 75.0000 (78.4813)  Acc@5: 93.7500 (95.5836)  time: 0.3449  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [3070/3750]  eta: 0:03:54  Lr: 0.030000  Loss: -0.3809  Acc@1: 81.2500 (78.4985)  Acc@5: 93.7500 (95.5755)  time: 0.3461  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3080/3750]  eta: 0:03:50  Lr: 0.030000  Loss: -0.3824  Acc@1: 81.2500 (78.5094)  Acc@5: 93.7500 (95.5757)  time: 0.3461  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3090/3750]  eta: 0:03:47  Lr: 0.030000  Loss: -0.2621  Acc@1: 81.2500 (78.5284)  Acc@5: 100.0000 (95.5799)  time: 0.3457  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3100/3750]  eta: 0:03:44  Lr: 0.030000  Loss: -0.6590  Acc@1: 87.5000 (78.5452)  Acc@5: 100.0000 (95.5760)  time: 0.3455  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3110/3750]  eta: 0:03:40  Lr: 0.030000  Loss: 0.0766  Acc@1: 87.5000 (78.5599)  Acc@5: 93.7500 (95.5762)  time: 0.3451  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3120/3750]  eta: 0:03:37  Lr: 0.030000  Loss: -0.3691  Acc@1: 81.2500 (78.5606)  Acc@5: 93.7500 (95.5763)  time: 0.3455  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3130/3750]  eta: 0:03:33  Lr: 0.030000  Loss: -0.2508  Acc@1: 75.0000 (78.5432)  Acc@5: 93.7500 (95.5705)  time: 0.3456  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3140/3750]  eta: 0:03:30  Lr: 0.030000  Loss: -0.2008  Acc@1: 68.7500 (78.5160)  Acc@5: 93.7500 (95.5627)  time: 0.3450  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3150/3750]  eta: 0:03:26  Lr: 0.030000  Loss: -0.1534  Acc@1: 75.0000 (78.5267)  Acc@5: 93.7500 (95.5669)  time: 0.3447  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3160/3750]  eta: 0:03:23  Lr: 0.030000  Loss: -0.5471  Acc@1: 81.2500 (78.5353)  Acc@5: 100.0000 (95.5690)  time: 0.3446  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3170/3750]  eta: 0:03:19  Lr: 0.030000  Loss: 0.0128  Acc@1: 75.0000 (78.5222)  Acc@5: 100.0000 (95.5732)  time: 0.3445  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3180/3750]  eta: 0:03:16  Lr: 0.030000  Loss: -0.3719  Acc@1: 81.2500 (78.5347)  Acc@5: 100.0000 (95.5792)  time: 0.3446  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3190/3750]  eta: 0:03:13  Lr: 0.030000  Loss: -0.5294  Acc@1: 81.2500 (78.5471)  Acc@5: 100.0000 (95.5872)  time: 0.3445  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3200/3750]  eta: 0:03:09  Lr: 0.030000  Loss: -0.2253  Acc@1: 75.0000 (78.5380)  Acc@5: 100.0000 (95.5893)  time: 0.3446  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3210/3750]  eta: 0:03:06  Lr: 0.030000  Loss: -0.6045  Acc@1: 81.2500 (78.5522)  Acc@5: 93.7500 (95.5933)  time: 0.3451  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3220/3750]  eta: 0:03:02  Lr: 0.030000  Loss: -0.2736  Acc@1: 81.2500 (78.5529)  Acc@5: 93.7500 (95.5914)  time: 0.3454  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3230/3750]  eta: 0:02:59  Lr: 0.030000  Loss: -0.4379  Acc@1: 81.2500 (78.5496)  Acc@5: 93.7500 (95.5954)  time: 0.3453  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3240/3750]  eta: 0:02:55  Lr: 0.030000  Loss: -0.5614  Acc@1: 75.0000 (78.5425)  Acc@5: 100.0000 (95.5994)  time: 0.3459  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3250/3750]  eta: 0:02:52  Lr: 0.030000  Loss: -0.4119  Acc@1: 75.0000 (78.5374)  Acc@5: 93.7500 (95.5860)  time: 0.3454  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3260/3750]  eta: 0:02:48  Lr: 0.030000  Loss: -0.1999  Acc@1: 75.0000 (78.5419)  Acc@5: 93.7500 (95.5918)  time: 0.3444  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [3270/3750]  eta: 0:02:45  Lr: 0.030000  Loss: -0.1811  Acc@1: 75.0000 (78.5387)  Acc@5: 100.0000 (95.5977)  time: 0.3449  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [3280/3750]  eta: 0:02:42  Lr: 0.030000  Loss: -0.4778  Acc@1: 81.2500 (78.5469)  Acc@5: 100.0000 (95.6016)  time: 0.3451  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [3290/3750]  eta: 0:02:38  Lr: 0.030000  Loss: 0.0169  Acc@1: 75.0000 (78.5210)  Acc@5: 93.7500 (95.5902)  time: 0.3447  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3300/3750]  eta: 0:02:35  Lr: 0.030000  Loss: -0.6395  Acc@1: 75.0000 (78.5141)  Acc@5: 93.7500 (95.5847)  time: 0.3441  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [3310/3750]  eta: 0:02:31  Lr: 0.030000  Loss: -0.5944  Acc@1: 75.0000 (78.5242)  Acc@5: 93.7500 (95.5829)  time: 0.3443  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [3320/3750]  eta: 0:02:28  Lr: 0.030000  Loss: -0.4586  Acc@1: 81.2500 (78.5437)  Acc@5: 100.0000 (95.5943)  time: 0.3434  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [3330/3750]  eta: 0:02:24  Lr: 0.030000  Loss: -0.7432  Acc@1: 81.2500 (78.5500)  Acc@5: 100.0000 (95.5907)  time: 0.3422  data: 0.0002  max mem: 2500
Train: Epoch[4/5]  [3340/3750]  eta: 0:02:21  Lr: 0.030000  Loss: -0.1969  Acc@1: 75.0000 (78.5300)  Acc@5: 93.7500 (95.5908)  time: 0.3422  data: 0.0002  max mem: 2500
Train: Epoch[4/5]  [3350/3750]  eta: 0:02:17  Lr: 0.030000  Loss: -0.7282  Acc@1: 75.0000 (78.5512)  Acc@5: 100.0000 (95.5965)  time: 0.3421  data: 0.0002  max mem: 2500
Train: Epoch[4/5]  [3360/3750]  eta: 0:02:14  Lr: 0.030000  Loss: -0.6210  Acc@1: 87.5000 (78.5592)  Acc@5: 93.7500 (95.5928)  time: 0.3422  data: 0.0002  max mem: 2500
Train: Epoch[4/5]  [3370/3750]  eta: 0:02:10  Lr: 0.030000  Loss: -0.5209  Acc@1: 81.2500 (78.5598)  Acc@5: 93.7500 (95.5929)  time: 0.3427  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [3380/3750]  eta: 0:02:07  Lr: 0.030000  Loss: -0.3785  Acc@1: 68.7500 (78.5437)  Acc@5: 93.7500 (95.5930)  time: 0.3445  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3390/3750]  eta: 0:02:04  Lr: 0.030000  Loss: -0.6703  Acc@1: 75.0000 (78.5498)  Acc@5: 93.7500 (95.5950)  time: 0.3456  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3400/3750]  eta: 0:02:00  Lr: 0.030000  Loss: -0.4667  Acc@1: 81.2500 (78.5670)  Acc@5: 93.7500 (95.5932)  time: 0.3453  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3410/3750]  eta: 0:01:57  Lr: 0.030000  Loss: -0.1559  Acc@1: 81.2500 (78.5583)  Acc@5: 93.7500 (95.5933)  time: 0.3449  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3420/3750]  eta: 0:01:53  Lr: 0.030000  Loss: -0.3875  Acc@1: 75.0000 (78.5461)  Acc@5: 93.7500 (95.5897)  time: 0.3451  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3430/3750]  eta: 0:01:50  Lr: 0.030000  Loss: -0.3077  Acc@1: 75.0000 (78.5431)  Acc@5: 100.0000 (95.5953)  time: 0.3448  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3440/3750]  eta: 0:01:46  Lr: 0.030000  Loss: -0.7207  Acc@1: 81.2500 (78.5564)  Acc@5: 100.0000 (95.5990)  time: 0.3440  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3450/3750]  eta: 0:01:43  Lr: 0.030000  Loss: -0.2402  Acc@1: 81.2500 (78.5588)  Acc@5: 100.0000 (95.6027)  time: 0.3441  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3460/3750]  eta: 0:01:39  Lr: 0.030000  Loss: -0.5137  Acc@1: 81.2500 (78.5629)  Acc@5: 93.7500 (95.6010)  time: 0.3444  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3470/3750]  eta: 0:01:36  Lr: 0.030000  Loss: -0.1644  Acc@1: 81.2500 (78.5617)  Acc@5: 93.7500 (95.5975)  time: 0.3444  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [3480/3750]  eta: 0:01:33  Lr: 0.030000  Loss: -0.3621  Acc@1: 75.0000 (78.5586)  Acc@5: 93.7500 (95.5939)  time: 0.3440  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [3490/3750]  eta: 0:01:29  Lr: 0.030000  Loss: -0.1901  Acc@1: 81.2500 (78.5735)  Acc@5: 93.7500 (95.5994)  time: 0.3442  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [3500/3750]  eta: 0:01:26  Lr: 0.030000  Loss: -0.5984  Acc@1: 75.0000 (78.5597)  Acc@5: 100.0000 (95.5995)  time: 0.3452  data: 0.0010  max mem: 2500
Train: Epoch[4/5]  [3510/3750]  eta: 0:01:22  Lr: 0.030000  Loss: -0.4074  Acc@1: 75.0000 (78.5496)  Acc@5: 93.7500 (95.5995)  time: 0.3450  data: 0.0010  max mem: 2500
Train: Epoch[4/5]  [3520/3750]  eta: 0:01:19  Lr: 0.030000  Loss: -0.3193  Acc@1: 75.0000 (78.5501)  Acc@5: 100.0000 (95.6067)  time: 0.3443  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [3530/3750]  eta: 0:01:15  Lr: 0.030000  Loss: -0.3284  Acc@1: 81.2500 (78.5613)  Acc@5: 100.0000 (95.6050)  time: 0.3446  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [3540/3750]  eta: 0:01:12  Lr: 0.030000  Loss: -0.6019  Acc@1: 81.2500 (78.5354)  Acc@5: 93.7500 (95.5927)  time: 0.3438  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [3550/3750]  eta: 0:01:08  Lr: 0.030000  Loss: -0.0945  Acc@1: 75.0000 (78.5289)  Acc@5: 87.5000 (95.5805)  time: 0.3427  data: 0.0002  max mem: 2500
Train: Epoch[4/5]  [3560/3750]  eta: 0:01:05  Lr: 0.030000  Loss: -0.3673  Acc@1: 75.0000 (78.5208)  Acc@5: 93.7500 (95.5771)  time: 0.3425  data: 0.0002  max mem: 2500
Train: Epoch[4/5]  [3570/3750]  eta: 0:01:02  Lr: 0.030000  Loss: -0.5604  Acc@1: 75.0000 (78.5214)  Acc@5: 93.7500 (95.5772)  time: 0.3425  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [3580/3750]  eta: 0:00:58  Lr: 0.030000  Loss: -0.4749  Acc@1: 81.2500 (78.5151)  Acc@5: 93.7500 (95.5791)  time: 0.3427  data: 0.0002  max mem: 2500
Train: Epoch[4/5]  [3590/3750]  eta: 0:00:55  Lr: 0.030000  Loss: -0.2727  Acc@1: 81.2500 (78.5157)  Acc@5: 93.7500 (95.5792)  time: 0.3432  data: 0.0002  max mem: 2500
Train: Epoch[4/5]  [3600/3750]  eta: 0:00:51  Lr: 0.030000  Loss: -0.0381  Acc@1: 75.0000 (78.5077)  Acc@5: 93.7500 (95.5689)  time: 0.3437  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [3610/3750]  eta: 0:00:48  Lr: 0.030000  Loss: -0.6219  Acc@1: 81.2500 (78.5170)  Acc@5: 93.7500 (95.5691)  time: 0.3449  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3620/3750]  eta: 0:00:44  Lr: 0.030000  Loss: -0.5190  Acc@1: 81.2500 (78.5246)  Acc@5: 100.0000 (95.5762)  time: 0.3453  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3630/3750]  eta: 0:00:41  Lr: 0.030000  Loss: -0.3423  Acc@1: 81.2500 (78.5252)  Acc@5: 100.0000 (95.5780)  time: 0.3457  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3640/3750]  eta: 0:00:37  Lr: 0.030000  Loss: -0.4584  Acc@1: 81.2500 (78.5293)  Acc@5: 93.7500 (95.5816)  time: 0.3464  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3650/3750]  eta: 0:00:34  Lr: 0.030000  Loss: -0.0600  Acc@1: 81.2500 (78.5281)  Acc@5: 93.7500 (95.5680)  time: 0.3458  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [3660/3750]  eta: 0:00:31  Lr: 0.030000  Loss: -0.5738  Acc@1: 81.2500 (78.5356)  Acc@5: 93.7500 (95.5613)  time: 0.3454  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3670/3750]  eta: 0:00:27  Lr: 0.030000  Loss: -0.3309  Acc@1: 81.2500 (78.5345)  Acc@5: 93.7500 (95.5632)  time: 0.3459  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3680/3750]  eta: 0:00:24  Lr: 0.030000  Loss: -0.2437  Acc@1: 75.0000 (78.5266)  Acc@5: 100.0000 (95.5617)  time: 0.3471  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3690/3750]  eta: 0:00:20  Lr: 0.030000  Loss: -0.1474  Acc@1: 75.0000 (78.5102)  Acc@5: 93.7500 (95.5551)  time: 0.3478  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3700/3750]  eta: 0:00:17  Lr: 0.030000  Loss: -0.2372  Acc@1: 75.0000 (78.5143)  Acc@5: 93.7500 (95.5519)  time: 0.3464  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [3710/3750]  eta: 0:00:13  Lr: 0.030000  Loss: -0.0636  Acc@1: 81.2500 (78.5199)  Acc@5: 93.7500 (95.5470)  time: 0.3449  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [3720/3750]  eta: 0:00:10  Lr: 0.030000  Loss: -0.6951  Acc@1: 81.2500 (78.5306)  Acc@5: 93.7500 (95.5472)  time: 0.3454  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [3730/3750]  eta: 0:00:06  Lr: 0.030000  Loss: -0.5309  Acc@1: 81.2500 (78.5480)  Acc@5: 100.0000 (95.5541)  time: 0.3449  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [3740/3750]  eta: 0:00:03  Lr: 0.030000  Loss: -0.5050  Acc@1: 81.2500 (78.5468)  Acc@5: 100.0000 (95.5560)  time: 0.3437  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [3749/3750]  eta: 0:00:00  Lr: 0.030000  Loss: -0.3064  Acc@1: 81.2500 (78.5467)  Acc@5: 100.0000 (95.5567)  time: 0.3437  data: 0.0006  max mem: 2500
Train: Epoch[4/5] Total time: 0:21:33 (0.3449 s / it)
{0: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 1: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 2: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 3: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 4: {0: 0, 1: 240000, 2: 0, 3: 0, 4: 0}, 5: {0: 0, 1: 240000, 2: 0, 3: 0, 4: 0}, 6: {0: 0, 1: 240000, 2: 0, 3: 0, 4: 0}, 7: {0: 0, 1: 240000, 2: 0, 3: 0, 4: 0}, 8: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 9: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 10: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 11: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 12: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 13: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 14: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 15: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 16: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 17: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 18: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 19: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}}
Averaged stats: Lr: 0.030000  Loss: -0.3064  Acc@1: 81.2500 (78.5467)  Acc@5: 100.0000 (95.5567)
Train: Epoch[5/5]  [   0/3750]  eta: 0:36:27  Lr: 0.030000  Loss: -0.3748  Acc@1: 81.2500 (81.2500)  Acc@5: 93.7500 (93.7500)  time: 0.5834  data: 0.2421  max mem: 2500
Train: Epoch[5/5]  [  10/3750]  eta: 0:22:52  Lr: 0.030000  Loss: -0.4612  Acc@1: 75.0000 (77.8409)  Acc@5: 93.7500 (94.8864)  time: 0.3669  data: 0.0223  max mem: 2500
Train: Epoch[5/5]  [  20/3750]  eta: 0:22:08  Lr: 0.030000  Loss: -0.6606  Acc@1: 81.2500 (79.1667)  Acc@5: 93.7500 (95.2381)  time: 0.3448  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [  30/3750]  eta: 0:21:52  Lr: 0.030000  Loss: -0.4491  Acc@1: 81.2500 (78.6290)  Acc@5: 93.7500 (94.9597)  time: 0.3450  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [  40/3750]  eta: 0:21:41  Lr: 0.030000  Loss: -0.5035  Acc@1: 81.2500 (79.8780)  Acc@5: 93.7500 (95.4268)  time: 0.3450  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [  50/3750]  eta: 0:21:33  Lr: 0.030000  Loss: -0.2078  Acc@1: 81.2500 (79.9020)  Acc@5: 93.7500 (95.2206)  time: 0.3449  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [  60/3750]  eta: 0:21:27  Lr: 0.030000  Loss: -0.3618  Acc@1: 75.0000 (79.6107)  Acc@5: 93.7500 (94.9795)  time: 0.3450  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [  70/3750]  eta: 0:21:21  Lr: 0.030000  Loss: -0.4114  Acc@1: 75.0000 (79.1373)  Acc@5: 93.7500 (94.9824)  time: 0.3447  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [  80/3750]  eta: 0:21:16  Lr: 0.030000  Loss: -0.6782  Acc@1: 75.0000 (78.9352)  Acc@5: 93.7500 (94.8302)  time: 0.3445  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [  90/3750]  eta: 0:21:10  Lr: 0.030000  Loss: -0.3232  Acc@1: 75.0000 (78.6401)  Acc@5: 93.7500 (94.7802)  time: 0.3436  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [ 100/3750]  eta: 0:21:05  Lr: 0.030000  Loss: -0.4091  Acc@1: 75.0000 (79.2079)  Acc@5: 93.7500 (94.6782)  time: 0.3430  data: 0.0002  max mem: 2500
Train: Epoch[5/5]  [ 110/3750]  eta: 0:21:01  Lr: 0.030000  Loss: -0.3352  Acc@1: 75.0000 (78.7162)  Acc@5: 93.7500 (94.7635)  time: 0.3431  data: 0.0002  max mem: 2500
Train: Epoch[5/5]  [ 120/3750]  eta: 0:20:56  Lr: 0.030000  Loss: -0.5515  Acc@1: 75.0000 (78.7707)  Acc@5: 93.7500 (94.8864)  time: 0.3431  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [ 130/3750]  eta: 0:20:52  Lr: 0.030000  Loss: -0.3910  Acc@1: 81.2500 (78.5782)  Acc@5: 100.0000 (95.0382)  time: 0.3431  data: 0.0002  max mem: 2500
Train: Epoch[5/5]  [ 140/3750]  eta: 0:20:48  Lr: 0.030000  Loss: -0.7394  Acc@1: 81.2500 (78.9007)  Acc@5: 100.0000 (95.2571)  time: 0.3439  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 150/3750]  eta: 0:20:44  Lr: 0.030000  Loss: -0.5339  Acc@1: 81.2500 (78.9321)  Acc@5: 93.7500 (95.1159)  time: 0.3449  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 160/3750]  eta: 0:20:41  Lr: 0.030000  Loss: -0.8207  Acc@1: 81.2500 (78.9208)  Acc@5: 93.7500 (95.1863)  time: 0.3453  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 170/3750]  eta: 0:20:38  Lr: 0.030000  Loss: -0.4555  Acc@1: 75.0000 (78.7281)  Acc@5: 100.0000 (95.3582)  time: 0.3458  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 180/3750]  eta: 0:20:34  Lr: 0.030000  Loss: -0.4876  Acc@1: 75.0000 (78.5566)  Acc@5: 100.0000 (95.4075)  time: 0.3453  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 190/3750]  eta: 0:20:30  Lr: 0.030000  Loss: -0.4663  Acc@1: 81.2500 (78.8613)  Acc@5: 100.0000 (95.4516)  time: 0.3450  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 200/3750]  eta: 0:20:27  Lr: 0.030000  Loss: -0.1346  Acc@1: 75.0000 (78.8557)  Acc@5: 100.0000 (95.4913)  time: 0.3449  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 210/3750]  eta: 0:20:23  Lr: 0.030000  Loss: -0.3844  Acc@1: 75.0000 (78.9396)  Acc@5: 100.0000 (95.4680)  time: 0.3454  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [ 220/3750]  eta: 0:20:20  Lr: 0.030000  Loss: -0.3704  Acc@1: 81.2500 (78.8462)  Acc@5: 93.7500 (95.3620)  time: 0.3458  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [ 230/3750]  eta: 0:20:16  Lr: 0.030000  Loss: -0.2537  Acc@1: 75.0000 (78.7608)  Acc@5: 93.7500 (95.2652)  time: 0.3450  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [ 240/3750]  eta: 0:20:13  Lr: 0.030000  Loss: -0.4213  Acc@1: 75.0000 (78.6826)  Acc@5: 93.7500 (95.1763)  time: 0.3445  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [ 250/3750]  eta: 0:20:09  Lr: 0.030000  Loss: -0.4328  Acc@1: 75.0000 (78.7102)  Acc@5: 100.0000 (95.2938)  time: 0.3455  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [ 260/3750]  eta: 0:20:06  Lr: 0.030000  Loss: -0.4375  Acc@1: 75.0000 (78.6638)  Acc@5: 100.0000 (95.3065)  time: 0.3456  data: 0.0002  max mem: 2500
Train: Epoch[5/5]  [ 270/3750]  eta: 0:20:02  Lr: 0.030000  Loss: -0.3027  Acc@1: 81.2500 (78.8284)  Acc@5: 100.0000 (95.3644)  time: 0.3445  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [ 280/3750]  eta: 0:19:58  Lr: 0.030000  Loss: -0.2739  Acc@1: 81.2500 (78.6477)  Acc@5: 100.0000 (95.3959)  time: 0.3442  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [ 290/3750]  eta: 0:19:55  Lr: 0.030000  Loss: -0.4793  Acc@1: 75.0000 (78.6297)  Acc@5: 93.7500 (95.3608)  time: 0.3433  data: 0.0002  max mem: 2500
Train: Epoch[5/5]  [ 300/3750]  eta: 0:19:51  Lr: 0.030000  Loss: 0.1061  Acc@1: 75.0000 (78.4468)  Acc@5: 93.7500 (95.3281)  time: 0.3428  data: 0.0002  max mem: 2500
Train: Epoch[5/5]  [ 310/3750]  eta: 0:19:47  Lr: 0.030000  Loss: -0.6090  Acc@1: 81.2500 (78.5571)  Acc@5: 93.7500 (95.2974)  time: 0.3433  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [ 320/3750]  eta: 0:19:44  Lr: 0.030000  Loss: -0.3360  Acc@1: 81.2500 (78.4268)  Acc@5: 93.7500 (95.2687)  time: 0.3444  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [ 330/3750]  eta: 0:19:40  Lr: 0.030000  Loss: -0.2869  Acc@1: 75.0000 (78.4554)  Acc@5: 93.7500 (95.2039)  time: 0.3453  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 340/3750]  eta: 0:19:37  Lr: 0.030000  Loss: -0.7092  Acc@1: 75.0000 (78.4274)  Acc@5: 93.7500 (95.2163)  time: 0.3448  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 350/3750]  eta: 0:19:33  Lr: 0.030000  Loss: -0.4901  Acc@1: 81.2500 (78.4722)  Acc@5: 93.7500 (95.1567)  time: 0.3447  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 360/3750]  eta: 0:19:30  Lr: 0.030000  Loss: -0.4832  Acc@1: 81.2500 (78.4626)  Acc@5: 93.7500 (95.1524)  time: 0.3464  data: 0.0011  max mem: 2500
Train: Epoch[5/5]  [ 370/3750]  eta: 0:19:27  Lr: 0.030000  Loss: -0.2070  Acc@1: 75.0000 (78.4367)  Acc@5: 93.7500 (95.1988)  time: 0.3460  data: 0.0011  max mem: 2500
Train: Epoch[5/5]  [ 380/3750]  eta: 0:19:23  Lr: 0.030000  Loss: -0.3593  Acc@1: 75.0000 (78.3301)  Acc@5: 93.7500 (95.1608)  time: 0.3447  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [ 390/3750]  eta: 0:19:20  Lr: 0.030000  Loss: 0.0257  Acc@1: 75.0000 (78.3728)  Acc@5: 93.7500 (95.0767)  time: 0.3445  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [ 400/3750]  eta: 0:19:16  Lr: 0.030000  Loss: -0.6843  Acc@1: 81.2500 (78.3978)  Acc@5: 93.7500 (95.1060)  time: 0.3446  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [ 410/3750]  eta: 0:19:13  Lr: 0.030000  Loss: -0.4866  Acc@1: 81.2500 (78.5280)  Acc@5: 93.7500 (95.1490)  time: 0.3447  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [ 420/3750]  eta: 0:19:09  Lr: 0.030000  Loss: -0.2320  Acc@1: 81.2500 (78.5926)  Acc@5: 100.0000 (95.2049)  time: 0.3449  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [ 430/3750]  eta: 0:19:05  Lr: 0.030000  Loss: -0.3552  Acc@1: 75.0000 (78.5093)  Acc@5: 100.0000 (95.2146)  time: 0.3444  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [ 440/3750]  eta: 0:19:02  Lr: 0.030000  Loss: -0.5714  Acc@1: 75.0000 (78.4439)  Acc@5: 93.7500 (95.1956)  time: 0.3435  data: 0.0002  max mem: 2500
Train: Epoch[5/5]  [ 450/3750]  eta: 0:18:58  Lr: 0.030000  Loss: -0.4223  Acc@1: 75.0000 (78.4368)  Acc@5: 93.7500 (95.2051)  time: 0.3433  data: 0.0002  max mem: 2500
Train: Epoch[5/5]  [ 460/3750]  eta: 0:18:55  Lr: 0.030000  Loss: -0.5042  Acc@1: 81.2500 (78.5385)  Acc@5: 100.0000 (95.2684)  time: 0.3431  data: 0.0002  max mem: 2500
Train: Epoch[5/5]  [ 470/3750]  eta: 0:18:51  Lr: 0.030000  Loss: -0.4070  Acc@1: 81.2500 (78.5695)  Acc@5: 100.0000 (95.2495)  time: 0.3432  data: 0.0002  max mem: 2500
Train: Epoch[5/5]  [ 480/3750]  eta: 0:18:48  Lr: 0.030000  Loss: -0.3987  Acc@1: 75.0000 (78.5473)  Acc@5: 93.7500 (95.3093)  time: 0.3431  data: 0.0002  max mem: 2500
Train: Epoch[5/5]  [ 490/3750]  eta: 0:18:44  Lr: 0.030000  Loss: -0.0960  Acc@1: 81.2500 (78.5896)  Acc@5: 100.0000 (95.3666)  time: 0.3435  data: 0.0002  max mem: 2500
Train: Epoch[5/5]  [ 500/3750]  eta: 0:18:40  Lr: 0.030000  Loss: -0.0727  Acc@1: 75.0000 (78.4431)  Acc@5: 100.0000 (95.4341)  time: 0.3434  data: 0.0002  max mem: 2500
Train: Epoch[5/5]  [ 510/3750]  eta: 0:18:37  Lr: 0.030000  Loss: -0.4606  Acc@1: 75.0000 (78.4614)  Acc@5: 100.0000 (95.4746)  time: 0.3434  data: 0.0002  max mem: 2500
Train: Epoch[5/5]  [ 520/3750]  eta: 0:18:33  Lr: 0.030000  Loss: -0.8538  Acc@1: 75.0000 (78.4909)  Acc@5: 100.0000 (95.4774)  time: 0.3442  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [ 530/3750]  eta: 0:18:30  Lr: 0.030000  Loss: -0.4629  Acc@1: 75.0000 (78.5546)  Acc@5: 93.7500 (95.4920)  time: 0.3455  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 540/3750]  eta: 0:18:27  Lr: 0.030000  Loss: -0.5539  Acc@1: 75.0000 (78.5813)  Acc@5: 100.0000 (95.5060)  time: 0.3462  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [ 550/3750]  eta: 0:18:23  Lr: 0.030000  Loss: -0.1991  Acc@1: 75.0000 (78.5617)  Acc@5: 93.7500 (95.4174)  time: 0.3456  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [ 560/3750]  eta: 0:18:20  Lr: 0.030000  Loss: -0.5414  Acc@1: 75.0000 (78.5316)  Acc@5: 93.7500 (95.3877)  time: 0.3453  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 570/3750]  eta: 0:18:16  Lr: 0.030000  Loss: 0.0484  Acc@1: 75.0000 (78.4479)  Acc@5: 93.7500 (95.3700)  time: 0.3457  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 580/3750]  eta: 0:18:13  Lr: 0.030000  Loss: -0.2769  Acc@1: 75.0000 (78.4316)  Acc@5: 93.7500 (95.3528)  time: 0.3457  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 590/3750]  eta: 0:18:10  Lr: 0.030000  Loss: -0.2750  Acc@1: 81.2500 (78.5216)  Acc@5: 100.0000 (95.3469)  time: 0.3457  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 600/3750]  eta: 0:18:06  Lr: 0.030000  Loss: -0.3801  Acc@1: 75.0000 (78.4006)  Acc@5: 100.0000 (95.3723)  time: 0.3460  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 610/3750]  eta: 0:18:03  Lr: 0.030000  Loss: -0.3359  Acc@1: 75.0000 (78.3858)  Acc@5: 100.0000 (95.4071)  time: 0.3458  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 620/3750]  eta: 0:17:59  Lr: 0.030000  Loss: -0.4200  Acc@1: 75.0000 (78.4018)  Acc@5: 100.0000 (95.4106)  time: 0.3458  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 630/3750]  eta: 0:17:57  Lr: 0.030000  Loss: -0.4289  Acc@1: 81.2500 (78.4073)  Acc@5: 100.0000 (95.4437)  time: 0.3507  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 640/3750]  eta: 0:17:53  Lr: 0.030000  Loss: -0.6546  Acc@1: 81.2500 (78.4711)  Acc@5: 100.0000 (95.4563)  time: 0.3501  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [ 650/3750]  eta: 0:17:50  Lr: 0.030000  Loss: -0.3072  Acc@1: 75.0000 (78.4466)  Acc@5: 93.7500 (95.4301)  time: 0.3453  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [ 660/3750]  eta: 0:17:46  Lr: 0.030000  Loss: -0.3388  Acc@1: 75.0000 (78.4039)  Acc@5: 100.0000 (95.4520)  time: 0.3455  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [ 670/3750]  eta: 0:17:43  Lr: 0.030000  Loss: -0.6189  Acc@1: 75.0000 (78.4370)  Acc@5: 93.7500 (95.4359)  time: 0.3455  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [ 680/3750]  eta: 0:17:39  Lr: 0.030000  Loss: -0.3152  Acc@1: 75.0000 (78.4325)  Acc@5: 93.7500 (95.4112)  time: 0.3455  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [ 690/3750]  eta: 0:17:36  Lr: 0.030000  Loss: -0.4769  Acc@1: 75.0000 (78.4190)  Acc@5: 100.0000 (95.4595)  time: 0.3451  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [ 700/3750]  eta: 0:17:32  Lr: 0.030000  Loss: -0.4799  Acc@1: 75.0000 (78.3880)  Acc@5: 100.0000 (95.4440)  time: 0.3456  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [ 710/3750]  eta: 0:17:29  Lr: 0.030000  Loss: 0.0001  Acc@1: 75.0000 (78.3228)  Acc@5: 100.0000 (95.4641)  time: 0.3463  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [ 720/3750]  eta: 0:17:25  Lr: 0.030000  Loss: -0.5457  Acc@1: 81.2500 (78.3981)  Acc@5: 100.0000 (95.5010)  time: 0.3449  data: 0.0002  max mem: 2500
Train: Epoch[5/5]  [ 730/3750]  eta: 0:17:22  Lr: 0.030000  Loss: -0.6200  Acc@1: 81.2500 (78.4200)  Acc@5: 100.0000 (95.5113)  time: 0.3431  data: 0.0002  max mem: 2500
Train: Epoch[5/5]  [ 740/3750]  eta: 0:17:18  Lr: 0.030000  Loss: -0.2909  Acc@1: 81.2500 (78.4329)  Acc@5: 93.7500 (95.5044)  time: 0.3432  data: 0.0002  max mem: 2500
Train: Epoch[5/5]  [ 750/3750]  eta: 0:17:15  Lr: 0.030000  Loss: -0.3905  Acc@1: 81.2500 (78.4454)  Acc@5: 93.7500 (95.5143)  time: 0.3433  data: 0.0002  max mem: 2500
Train: Epoch[5/5]  [ 760/3750]  eta: 0:17:11  Lr: 0.030000  Loss: -0.2859  Acc@1: 81.2500 (78.5069)  Acc@5: 93.7500 (95.5322)  time: 0.3431  data: 0.0002  max mem: 2500
Train: Epoch[5/5]  [ 770/3750]  eta: 0:17:08  Lr: 0.030000  Loss: -0.4123  Acc@1: 75.0000 (78.5101)  Acc@5: 100.0000 (95.5415)  time: 0.3431  data: 0.0002  max mem: 2500
Train: Epoch[5/5]  [ 780/3750]  eta: 0:17:04  Lr: 0.030000  Loss: -0.3477  Acc@1: 75.0000 (78.4971)  Acc@5: 93.7500 (95.5346)  time: 0.3430  data: 0.0002  max mem: 2500
Train: Epoch[5/5]  [ 790/3750]  eta: 0:17:01  Lr: 0.030000  Loss: -0.3482  Acc@1: 75.0000 (78.4766)  Acc@5: 93.7500 (95.5436)  time: 0.3430  data: 0.0002  max mem: 2500
Train: Epoch[5/5]  [ 800/3750]  eta: 0:16:57  Lr: 0.030000  Loss: -0.6497  Acc@1: 75.0000 (78.4488)  Acc@5: 100.0000 (95.5290)  time: 0.3437  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [ 810/3750]  eta: 0:16:54  Lr: 0.030000  Loss: -0.0642  Acc@1: 81.2500 (78.4063)  Acc@5: 100.0000 (95.5456)  time: 0.3445  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [ 820/3750]  eta: 0:16:50  Lr: 0.030000  Loss: -0.3091  Acc@1: 75.0000 (78.3876)  Acc@5: 93.7500 (95.5238)  time: 0.3454  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 830/3750]  eta: 0:16:47  Lr: 0.030000  Loss: -0.2393  Acc@1: 75.0000 (78.3770)  Acc@5: 93.7500 (95.5325)  time: 0.3468  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [ 840/3750]  eta: 0:16:44  Lr: 0.030000  Loss: -0.5764  Acc@1: 81.2500 (78.4185)  Acc@5: 100.0000 (95.5410)  time: 0.3470  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 850/3750]  eta: 0:16:40  Lr: 0.030000  Loss: -0.7680  Acc@1: 81.2500 (78.4518)  Acc@5: 100.0000 (95.5567)  time: 0.3458  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 860/3750]  eta: 0:16:37  Lr: 0.030000  Loss: -0.2216  Acc@1: 81.2500 (78.4698)  Acc@5: 93.7500 (95.5502)  time: 0.3451  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 870/3750]  eta: 0:16:33  Lr: 0.030000  Loss: -0.6658  Acc@1: 75.0000 (78.4874)  Acc@5: 93.7500 (95.5583)  time: 0.3459  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 880/3750]  eta: 0:16:30  Lr: 0.030000  Loss: -0.3408  Acc@1: 75.0000 (78.4762)  Acc@5: 93.7500 (95.5448)  time: 0.3457  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 890/3750]  eta: 0:16:26  Lr: 0.030000  Loss: -0.2877  Acc@1: 81.2500 (78.4933)  Acc@5: 93.7500 (95.5177)  time: 0.3456  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 900/3750]  eta: 0:16:23  Lr: 0.030000  Loss: -0.6386  Acc@1: 81.2500 (78.4753)  Acc@5: 93.7500 (95.5258)  time: 0.3460  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 910/3750]  eta: 0:16:20  Lr: 0.030000  Loss: -0.0518  Acc@1: 81.2500 (78.4783)  Acc@5: 93.7500 (95.5200)  time: 0.3449  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 920/3750]  eta: 0:16:16  Lr: 0.030000  Loss: -0.6734  Acc@1: 81.2500 (78.4813)  Acc@5: 93.7500 (95.5347)  time: 0.3443  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 930/3750]  eta: 0:16:13  Lr: 0.030000  Loss: -0.5520  Acc@1: 81.2500 (78.5446)  Acc@5: 100.0000 (95.5491)  time: 0.3453  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [ 940/3750]  eta: 0:16:09  Lr: 0.030000  Loss: -0.4478  Acc@1: 81.2500 (78.5468)  Acc@5: 100.0000 (95.5632)  time: 0.3452  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 950/3750]  eta: 0:16:06  Lr: 0.030000  Loss: -0.5043  Acc@1: 75.0000 (78.4832)  Acc@5: 93.7500 (95.5310)  time: 0.3447  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 960/3750]  eta: 0:16:03  Lr: 0.030000  Loss: -0.4104  Acc@1: 75.0000 (78.4404)  Acc@5: 93.7500 (95.5320)  time: 0.3492  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 970/3750]  eta: 0:15:59  Lr: 0.030000  Loss: -0.1897  Acc@1: 75.0000 (78.4179)  Acc@5: 93.7500 (95.5201)  time: 0.3488  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 980/3750]  eta: 0:15:56  Lr: 0.030000  Loss: -0.6341  Acc@1: 75.0000 (78.3830)  Acc@5: 93.7500 (95.4893)  time: 0.3444  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [ 990/3750]  eta: 0:15:52  Lr: 0.030000  Loss: -0.1380  Acc@1: 75.0000 (78.3678)  Acc@5: 93.7500 (95.4844)  time: 0.3441  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [1000/3750]  eta: 0:15:49  Lr: 0.030000  Loss: -0.4776  Acc@1: 75.0000 (78.4153)  Acc@5: 93.7500 (95.4983)  time: 0.3445  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [1010/3750]  eta: 0:15:45  Lr: 0.030000  Loss: -0.0883  Acc@1: 75.0000 (78.4125)  Acc@5: 93.7500 (95.4995)  time: 0.3450  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [1020/3750]  eta: 0:15:42  Lr: 0.030000  Loss: -0.5100  Acc@1: 81.2500 (78.4647)  Acc@5: 93.7500 (95.5007)  time: 0.3452  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1030/3750]  eta: 0:15:38  Lr: 0.030000  Loss: -0.3869  Acc@1: 81.2500 (78.4311)  Acc@5: 93.7500 (95.4838)  time: 0.3457  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1040/3750]  eta: 0:15:35  Lr: 0.030000  Loss: -0.2273  Acc@1: 68.7500 (78.3742)  Acc@5: 93.7500 (95.4371)  time: 0.3444  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1050/3750]  eta: 0:15:31  Lr: 0.030000  Loss: -0.5937  Acc@1: 75.0000 (78.3777)  Acc@5: 93.7500 (95.4508)  time: 0.3426  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [1060/3750]  eta: 0:15:28  Lr: 0.030000  Loss: -0.3461  Acc@1: 81.2500 (78.4166)  Acc@5: 100.0000 (95.4701)  time: 0.3424  data: 0.0002  max mem: 2500
Train: Epoch[5/5]  [1070/3750]  eta: 0:15:24  Lr: 0.030000  Loss: -0.2732  Acc@1: 81.2500 (78.4139)  Acc@5: 100.0000 (95.4774)  time: 0.3423  data: 0.0002  max mem: 2500
Train: Epoch[5/5]  [1080/3750]  eta: 0:15:21  Lr: 0.030000  Loss: -0.7352  Acc@1: 75.0000 (78.4343)  Acc@5: 100.0000 (95.4787)  time: 0.3428  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [1090/3750]  eta: 0:15:17  Lr: 0.030000  Loss: -0.3462  Acc@1: 75.0000 (78.4028)  Acc@5: 100.0000 (95.4686)  time: 0.3444  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1100/3750]  eta: 0:15:14  Lr: 0.030000  Loss: -0.3046  Acc@1: 81.2500 (78.4117)  Acc@5: 93.7500 (95.4757)  time: 0.3451  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1110/3750]  eta: 0:15:10  Lr: 0.030000  Loss: -0.4153  Acc@1: 81.2500 (78.3810)  Acc@5: 93.7500 (95.4883)  time: 0.3442  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [1120/3750]  eta: 0:15:07  Lr: 0.030000  Loss: 0.1662  Acc@1: 75.0000 (78.3731)  Acc@5: 100.0000 (95.5007)  time: 0.3443  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1130/3750]  eta: 0:15:03  Lr: 0.030000  Loss: -0.4584  Acc@1: 75.0000 (78.3764)  Acc@5: 93.7500 (95.5018)  time: 0.3445  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1140/3750]  eta: 0:15:00  Lr: 0.030000  Loss: -0.1511  Acc@1: 81.2500 (78.3852)  Acc@5: 93.7500 (95.5138)  time: 0.3441  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1150/3750]  eta: 0:14:57  Lr: 0.030000  Loss: -0.5283  Acc@1: 81.2500 (78.4318)  Acc@5: 100.0000 (95.5311)  time: 0.3444  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [1160/3750]  eta: 0:14:53  Lr: 0.030000  Loss: -0.6969  Acc@1: 81.2500 (78.4345)  Acc@5: 100.0000 (95.5319)  time: 0.3443  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1170/3750]  eta: 0:14:50  Lr: 0.030000  Loss: -0.7123  Acc@1: 75.0000 (78.4426)  Acc@5: 93.7500 (95.5380)  time: 0.3443  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1180/3750]  eta: 0:14:46  Lr: 0.030000  Loss: -0.6324  Acc@1: 81.2500 (78.4663)  Acc@5: 93.7500 (95.5387)  time: 0.3441  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [1190/3750]  eta: 0:14:43  Lr: 0.030000  Loss: -0.4094  Acc@1: 81.2500 (78.4372)  Acc@5: 93.7500 (95.5500)  time: 0.3441  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [1200/3750]  eta: 0:14:39  Lr: 0.030000  Loss: -0.7816  Acc@1: 81.2500 (78.4607)  Acc@5: 100.0000 (95.5714)  time: 0.3451  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [1210/3750]  eta: 0:14:36  Lr: 0.030000  Loss: -0.4753  Acc@1: 81.2500 (78.4218)  Acc@5: 93.7500 (95.5357)  time: 0.3452  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [1220/3750]  eta: 0:14:32  Lr: 0.030000  Loss: -0.4437  Acc@1: 68.7500 (78.3579)  Acc@5: 93.7500 (95.4904)  time: 0.3444  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [1230/3750]  eta: 0:14:29  Lr: 0.030000  Loss: -0.5170  Acc@1: 75.0000 (78.4119)  Acc@5: 93.7500 (95.5067)  time: 0.3450  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [1240/3750]  eta: 0:14:25  Lr: 0.030000  Loss: -0.4829  Acc@1: 81.2500 (78.3844)  Acc@5: 100.0000 (95.5177)  time: 0.3443  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [1250/3750]  eta: 0:14:22  Lr: 0.030000  Loss: -0.6946  Acc@1: 81.2500 (78.4273)  Acc@5: 100.0000 (95.5336)  time: 0.3427  data: 0.0002  max mem: 2500
Train: Epoch[5/5]  [1260/3750]  eta: 0:14:18  Lr: 0.030000  Loss: -0.7674  Acc@1: 81.2500 (78.4596)  Acc@5: 100.0000 (95.5393)  time: 0.3428  data: 0.0002  max mem: 2500
Train: Epoch[5/5]  [1270/3750]  eta: 0:14:15  Lr: 0.030000  Loss: -0.2234  Acc@1: 81.2500 (78.4766)  Acc@5: 100.0000 (95.5547)  time: 0.3429  data: 0.0002  max mem: 2500
Train: Epoch[5/5]  [1280/3750]  eta: 0:14:11  Lr: 0.030000  Loss: -0.2924  Acc@1: 81.2500 (78.4885)  Acc@5: 100.0000 (95.5699)  time: 0.3428  data: 0.0002  max mem: 2500
Train: Epoch[5/5]  [1290/3750]  eta: 0:14:08  Lr: 0.030000  Loss: -0.7068  Acc@1: 81.2500 (78.5002)  Acc@5: 93.7500 (95.5606)  time: 0.3436  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [1300/3750]  eta: 0:14:04  Lr: 0.030000  Loss: 0.0081  Acc@1: 81.2500 (78.4925)  Acc@5: 93.7500 (95.5707)  time: 0.3448  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1310/3750]  eta: 0:14:01  Lr: 0.030000  Loss: -0.1690  Acc@1: 75.0000 (78.4706)  Acc@5: 100.0000 (95.5711)  time: 0.3455  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1320/3750]  eta: 0:13:58  Lr: 0.030000  Loss: -0.4026  Acc@1: 75.0000 (78.4633)  Acc@5: 100.0000 (95.5857)  time: 0.3458  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1330/3750]  eta: 0:13:54  Lr: 0.030000  Loss: -0.5927  Acc@1: 75.0000 (78.4560)  Acc@5: 100.0000 (95.6001)  time: 0.3450  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1340/3750]  eta: 0:13:51  Lr: 0.030000  Loss: -0.5640  Acc@1: 75.0000 (78.4815)  Acc@5: 100.0000 (95.5956)  time: 0.3447  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1350/3750]  eta: 0:13:47  Lr: 0.030000  Loss: -0.7044  Acc@1: 81.2500 (78.5113)  Acc@5: 100.0000 (95.6144)  time: 0.3449  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1360/3750]  eta: 0:13:44  Lr: 0.030000  Loss: -0.3757  Acc@1: 81.2500 (78.5039)  Acc@5: 93.7500 (95.6098)  time: 0.3446  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1370/3750]  eta: 0:13:40  Lr: 0.030000  Loss: -0.3407  Acc@1: 81.2500 (78.5376)  Acc@5: 93.7500 (95.6145)  time: 0.3452  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1380/3750]  eta: 0:13:37  Lr: 0.030000  Loss: -0.5307  Acc@1: 75.0000 (78.5029)  Acc@5: 100.0000 (95.6236)  time: 0.3451  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1390/3750]  eta: 0:13:33  Lr: 0.030000  Loss: -0.4018  Acc@1: 75.0000 (78.5226)  Acc@5: 100.0000 (95.6281)  time: 0.3446  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [1400/3750]  eta: 0:13:30  Lr: 0.030000  Loss: 0.0755  Acc@1: 75.0000 (78.4841)  Acc@5: 93.7500 (95.6103)  time: 0.3457  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [1410/3750]  eta: 0:13:27  Lr: 0.030000  Loss: -0.3774  Acc@1: 75.0000 (78.4860)  Acc@5: 93.7500 (95.6060)  time: 0.3458  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [1420/3750]  eta: 0:13:23  Lr: 0.030000  Loss: 0.0184  Acc@1: 81.2500 (78.4923)  Acc@5: 93.7500 (95.6149)  time: 0.3450  data: 0.0002  max mem: 2500
Train: Epoch[5/5]  [1430/3750]  eta: 0:13:20  Lr: 0.030000  Loss: -0.6080  Acc@1: 81.2500 (78.5028)  Acc@5: 100.0000 (95.6193)  time: 0.3450  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [1440/3750]  eta: 0:13:16  Lr: 0.030000  Loss: -0.5607  Acc@1: 81.2500 (78.4958)  Acc@5: 100.0000 (95.6280)  time: 0.3450  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [1450/3750]  eta: 0:13:13  Lr: 0.030000  Loss: -0.5568  Acc@1: 81.2500 (78.5019)  Acc@5: 100.0000 (95.6323)  time: 0.3446  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [1460/3750]  eta: 0:13:09  Lr: 0.030000  Loss: -0.3925  Acc@1: 81.2500 (78.5293)  Acc@5: 100.0000 (95.6451)  time: 0.3436  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [1470/3750]  eta: 0:13:06  Lr: 0.030000  Loss: -0.7308  Acc@1: 81.2500 (78.5350)  Acc@5: 100.0000 (95.6662)  time: 0.3434  data: 0.0002  max mem: 2500
Train: Epoch[5/5]  [1480/3750]  eta: 0:13:02  Lr: 0.030000  Loss: -0.2010  Acc@1: 81.2500 (78.5365)  Acc@5: 100.0000 (95.6533)  time: 0.3440  data: 0.0002  max mem: 2500
Train: Epoch[5/5]  [1490/3750]  eta: 0:12:59  Lr: 0.030000  Loss: -0.4865  Acc@1: 81.2500 (78.5337)  Acc@5: 93.7500 (95.6489)  time: 0.3438  data: 0.0002  max mem: 2500
Train: Epoch[5/5]  [1500/3750]  eta: 0:12:55  Lr: 0.030000  Loss: -0.3526  Acc@1: 75.0000 (78.5268)  Acc@5: 93.7500 (95.6446)  time: 0.3435  data: 0.0002  max mem: 2500
Train: Epoch[5/5]  [1510/3750]  eta: 0:12:52  Lr: 0.030000  Loss: -0.3600  Acc@1: 81.2500 (78.5159)  Acc@5: 93.7500 (95.6362)  time: 0.3436  data: 0.0002  max mem: 2500
Train: Epoch[5/5]  [1520/3750]  eta: 0:12:49  Lr: 0.030000  Loss: -0.4398  Acc@1: 81.2500 (78.5010)  Acc@5: 93.7500 (95.6279)  time: 0.3431  data: 0.0002  max mem: 2500
Train: Epoch[5/5]  [1530/3750]  eta: 0:12:45  Lr: 0.030000  Loss: -0.2131  Acc@1: 75.0000 (78.5067)  Acc@5: 100.0000 (95.6401)  time: 0.3435  data: 0.0002  max mem: 2500
Train: Epoch[5/5]  [1540/3750]  eta: 0:12:42  Lr: 0.030000  Loss: -0.3927  Acc@1: 81.2500 (78.5204)  Acc@5: 100.0000 (95.6441)  time: 0.3456  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1550/3750]  eta: 0:12:38  Lr: 0.030000  Loss: -0.1903  Acc@1: 81.2500 (78.5461)  Acc@5: 93.7500 (95.6319)  time: 0.3464  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1560/3750]  eta: 0:12:35  Lr: 0.030000  Loss: -0.5804  Acc@1: 81.2500 (78.5794)  Acc@5: 100.0000 (95.6518)  time: 0.3452  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1570/3750]  eta: 0:12:31  Lr: 0.030000  Loss: -0.3118  Acc@1: 81.2500 (78.6004)  Acc@5: 100.0000 (95.6556)  time: 0.3454  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1580/3750]  eta: 0:12:28  Lr: 0.030000  Loss: -0.5417  Acc@1: 81.2500 (78.5974)  Acc@5: 93.7500 (95.6436)  time: 0.3458  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1590/3750]  eta: 0:12:24  Lr: 0.030000  Loss: -0.7465  Acc@1: 75.0000 (78.5748)  Acc@5: 93.7500 (95.6356)  time: 0.3458  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1600/3750]  eta: 0:12:21  Lr: 0.030000  Loss: -0.5336  Acc@1: 75.0000 (78.5447)  Acc@5: 93.7500 (95.6277)  time: 0.3464  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1610/3750]  eta: 0:12:18  Lr: 0.030000  Loss: -0.3670  Acc@1: 75.0000 (78.5459)  Acc@5: 93.7500 (95.6355)  time: 0.3464  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1620/3750]  eta: 0:12:14  Lr: 0.030000  Loss: -0.3618  Acc@1: 81.2500 (78.5703)  Acc@5: 100.0000 (95.6431)  time: 0.3456  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1630/3750]  eta: 0:12:11  Lr: 0.030000  Loss: -0.1037  Acc@1: 81.2500 (78.5523)  Acc@5: 100.0000 (95.6468)  time: 0.3452  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [1640/3750]  eta: 0:12:07  Lr: 0.030000  Loss: -0.3603  Acc@1: 75.0000 (78.5344)  Acc@5: 100.0000 (95.6467)  time: 0.3451  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1650/3750]  eta: 0:12:04  Lr: 0.030000  Loss: -0.7124  Acc@1: 81.2500 (78.5509)  Acc@5: 93.7500 (95.6541)  time: 0.3452  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1660/3750]  eta: 0:12:00  Lr: 0.030000  Loss: -0.5473  Acc@1: 81.2500 (78.5446)  Acc@5: 93.7500 (95.6540)  time: 0.3486  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1670/3750]  eta: 0:11:57  Lr: 0.030000  Loss: -0.6025  Acc@1: 75.0000 (78.5458)  Acc@5: 93.7500 (95.6314)  time: 0.3482  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1680/3750]  eta: 0:11:54  Lr: 0.030000  Loss: -0.1159  Acc@1: 81.2500 (78.5619)  Acc@5: 93.7500 (95.6313)  time: 0.3451  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [1690/3750]  eta: 0:11:50  Lr: 0.030000  Loss: -0.0884  Acc@1: 75.0000 (78.5445)  Acc@5: 93.7500 (95.6202)  time: 0.3452  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [1700/3750]  eta: 0:11:47  Lr: 0.030000  Loss: -0.3160  Acc@1: 75.0000 (78.5016)  Acc@5: 93.7500 (95.6092)  time: 0.3461  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [1710/3750]  eta: 0:11:43  Lr: 0.030000  Loss: -0.4208  Acc@1: 75.0000 (78.5177)  Acc@5: 93.7500 (95.6203)  time: 0.3461  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [1720/3750]  eta: 0:11:40  Lr: 0.030000  Loss: -0.6962  Acc@1: 81.2500 (78.5154)  Acc@5: 93.7500 (95.6239)  time: 0.3448  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [1730/3750]  eta: 0:11:36  Lr: 0.030000  Loss: -0.1529  Acc@1: 75.0000 (78.5023)  Acc@5: 93.7500 (95.6023)  time: 0.3452  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [1740/3750]  eta: 0:11:33  Lr: 0.030000  Loss: -0.2539  Acc@1: 75.0000 (78.4786)  Acc@5: 93.7500 (95.6060)  time: 0.3443  data: 0.0002  max mem: 2500
Train: Epoch[5/5]  [1750/3750]  eta: 0:11:29  Lr: 0.030000  Loss: -0.4270  Acc@1: 81.2500 (78.5016)  Acc@5: 100.0000 (95.6132)  time: 0.3432  data: 0.0002  max mem: 2500
Train: Epoch[5/5]  [1760/3750]  eta: 0:11:26  Lr: 0.030000  Loss: -0.4477  Acc@1: 81.2500 (78.4888)  Acc@5: 93.7500 (95.6097)  time: 0.3433  data: 0.0002  max mem: 2500
Train: Epoch[5/5]  [1770/3750]  eta: 0:11:22  Lr: 0.030000  Loss: -0.4195  Acc@1: 75.0000 (78.4938)  Acc@5: 93.7500 (95.5992)  time: 0.3443  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [1780/3750]  eta: 0:11:19  Lr: 0.030000  Loss: -0.3163  Acc@1: 81.2500 (78.5128)  Acc@5: 93.7500 (95.6064)  time: 0.3452  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1790/3750]  eta: 0:11:16  Lr: 0.030000  Loss: -0.5430  Acc@1: 81.2500 (78.5385)  Acc@5: 100.0000 (95.6170)  time: 0.3460  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1800/3750]  eta: 0:11:12  Lr: 0.030000  Loss: -0.3298  Acc@1: 81.2500 (78.5328)  Acc@5: 100.0000 (95.6135)  time: 0.3468  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [1810/3750]  eta: 0:11:09  Lr: 0.030000  Loss: 0.0541  Acc@1: 81.2500 (78.5616)  Acc@5: 93.7500 (95.6067)  time: 0.3462  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [1820/3750]  eta: 0:11:05  Lr: 0.030000  Loss: -0.4593  Acc@1: 81.2500 (78.5351)  Acc@5: 93.7500 (95.6102)  time: 0.3455  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [1830/3750]  eta: 0:11:02  Lr: 0.030000  Loss: -0.5389  Acc@1: 81.2500 (78.5739)  Acc@5: 100.0000 (95.6274)  time: 0.3446  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [1840/3750]  eta: 0:10:58  Lr: 0.030000  Loss: -0.5643  Acc@1: 81.2500 (78.5748)  Acc@5: 100.0000 (95.6240)  time: 0.3439  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [1850/3750]  eta: 0:10:55  Lr: 0.030000  Loss: -0.0773  Acc@1: 75.0000 (78.5420)  Acc@5: 93.7500 (95.6206)  time: 0.3439  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [1860/3750]  eta: 0:10:51  Lr: 0.030000  Loss: -0.4545  Acc@1: 75.0000 (78.5263)  Acc@5: 93.7500 (95.6240)  time: 0.3440  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [1870/3750]  eta: 0:10:48  Lr: 0.030000  Loss: -0.4274  Acc@1: 75.0000 (78.5108)  Acc@5: 93.7500 (95.6140)  time: 0.3450  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [1880/3750]  eta: 0:10:45  Lr: 0.030000  Loss: -0.1377  Acc@1: 75.0000 (78.5021)  Acc@5: 93.7500 (95.6140)  time: 0.3443  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [1890/3750]  eta: 0:10:41  Lr: 0.030000  Loss: -0.5129  Acc@1: 81.2500 (78.5067)  Acc@5: 93.7500 (95.6174)  time: 0.3428  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [1900/3750]  eta: 0:10:38  Lr: 0.030000  Loss: -0.2258  Acc@1: 81.2500 (78.5113)  Acc@5: 93.7500 (95.6109)  time: 0.3427  data: 0.0002  max mem: 2500
Train: Epoch[5/5]  [1910/3750]  eta: 0:10:34  Lr: 0.030000  Loss: -0.2044  Acc@1: 81.2500 (78.5027)  Acc@5: 93.7500 (95.6077)  time: 0.3427  data: 0.0002  max mem: 2500
Train: Epoch[5/5]  [1920/3750]  eta: 0:10:31  Lr: 0.030000  Loss: -0.6188  Acc@1: 81.2500 (78.5073)  Acc@5: 93.7500 (95.6078)  time: 0.3425  data: 0.0002  max mem: 2500
Train: Epoch[5/5]  [1930/3750]  eta: 0:10:27  Lr: 0.030000  Loss: -0.4745  Acc@1: 75.0000 (78.5021)  Acc@5: 100.0000 (95.6208)  time: 0.3431  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [1940/3750]  eta: 0:10:24  Lr: 0.030000  Loss: -0.3231  Acc@1: 75.0000 (78.5033)  Acc@5: 100.0000 (95.6176)  time: 0.3438  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [1950/3750]  eta: 0:10:20  Lr: 0.030000  Loss: -0.4069  Acc@1: 81.2500 (78.5110)  Acc@5: 100.0000 (95.6304)  time: 0.3441  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1960/3750]  eta: 0:10:17  Lr: 0.030000  Loss: -0.4566  Acc@1: 81.2500 (78.5282)  Acc@5: 100.0000 (95.6304)  time: 0.3441  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1970/3750]  eta: 0:10:13  Lr: 0.030000  Loss: -0.4003  Acc@1: 81.2500 (78.5293)  Acc@5: 93.7500 (95.6272)  time: 0.3443  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1980/3750]  eta: 0:10:10  Lr: 0.030000  Loss: -0.5331  Acc@1: 81.2500 (78.5241)  Acc@5: 100.0000 (95.6335)  time: 0.3446  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1990/3750]  eta: 0:10:06  Lr: 0.030000  Loss: -0.4287  Acc@1: 81.2500 (78.5033)  Acc@5: 100.0000 (95.6366)  time: 0.3447  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2000/3750]  eta: 0:10:03  Lr: 0.030000  Loss: -0.4891  Acc@1: 81.2500 (78.5389)  Acc@5: 93.7500 (95.6397)  time: 0.3460  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2010/3750]  eta: 0:10:00  Lr: 0.030000  Loss: -0.2735  Acc@1: 81.2500 (78.5275)  Acc@5: 93.7500 (95.6458)  time: 0.3511  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [2020/3750]  eta: 0:09:56  Lr: 0.030000  Loss: -0.1994  Acc@1: 81.2500 (78.5502)  Acc@5: 100.0000 (95.6581)  time: 0.3499  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [2030/3750]  eta: 0:09:53  Lr: 0.030000  Loss: -0.5319  Acc@1: 81.2500 (78.5512)  Acc@5: 100.0000 (95.6702)  time: 0.3446  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [2040/3750]  eta: 0:09:49  Lr: 0.030000  Loss: -0.5968  Acc@1: 81.2500 (78.5767)  Acc@5: 100.0000 (95.6792)  time: 0.3447  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [2050/3750]  eta: 0:09:46  Lr: 0.030000  Loss: -0.3149  Acc@1: 81.2500 (78.5867)  Acc@5: 100.0000 (95.6667)  time: 0.3447  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [2060/3750]  eta: 0:09:42  Lr: 0.030000  Loss: -0.3755  Acc@1: 81.2500 (78.5844)  Acc@5: 93.7500 (95.6665)  time: 0.3441  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [2070/3750]  eta: 0:09:39  Lr: 0.030000  Loss: -0.2634  Acc@1: 81.2500 (78.5822)  Acc@5: 93.7500 (95.6663)  time: 0.3448  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [2080/3750]  eta: 0:09:36  Lr: 0.030000  Loss: -0.2446  Acc@1: 75.0000 (78.5590)  Acc@5: 100.0000 (95.6661)  time: 0.3443  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [2090/3750]  eta: 0:09:32  Lr: 0.030000  Loss: -0.5219  Acc@1: 75.0000 (78.5270)  Acc@5: 93.7500 (95.6540)  time: 0.3432  data: 0.0002  max mem: 2500
Train: Epoch[5/5]  [2100/3750]  eta: 0:09:29  Lr: 0.030000  Loss: -0.4400  Acc@1: 75.0000 (78.5221)  Acc@5: 93.7500 (95.6568)  time: 0.3433  data: 0.0002  max mem: 2500
Train: Epoch[5/5]  [2110/3750]  eta: 0:09:25  Lr: 0.030000  Loss: -0.1186  Acc@1: 81.2500 (78.5173)  Acc@5: 100.0000 (95.6537)  time: 0.3433  data: 0.0002  max mem: 2500
Train: Epoch[5/5]  [2120/3750]  eta: 0:09:22  Lr: 0.030000  Loss: -0.5211  Acc@1: 75.0000 (78.5125)  Acc@5: 93.7500 (95.6418)  time: 0.3437  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [2130/3750]  eta: 0:09:18  Lr: 0.030000  Loss: 0.0387  Acc@1: 81.2500 (78.5077)  Acc@5: 93.7500 (95.6417)  time: 0.3454  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2140/3750]  eta: 0:09:15  Lr: 0.030000  Loss: -0.3973  Acc@1: 75.0000 (78.4943)  Acc@5: 93.7500 (95.6270)  time: 0.3456  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2150/3750]  eta: 0:09:11  Lr: 0.030000  Loss: -0.4517  Acc@1: 75.0000 (78.5100)  Acc@5: 100.0000 (95.6241)  time: 0.3447  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2160/3750]  eta: 0:09:08  Lr: 0.030000  Loss: -0.2391  Acc@1: 75.0000 (78.4966)  Acc@5: 100.0000 (95.6299)  time: 0.3448  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2170/3750]  eta: 0:09:04  Lr: 0.030000  Loss: -0.3624  Acc@1: 75.0000 (78.5151)  Acc@5: 93.7500 (95.6328)  time: 0.3448  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [2180/3750]  eta: 0:09:01  Lr: 0.030000  Loss: -0.4130  Acc@1: 81.2500 (78.5104)  Acc@5: 93.7500 (95.6241)  time: 0.3449  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [2190/3750]  eta: 0:08:58  Lr: 0.030000  Loss: -0.6305  Acc@1: 75.0000 (78.5144)  Acc@5: 93.7500 (95.6298)  time: 0.3452  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [2200/3750]  eta: 0:08:54  Lr: 0.030000  Loss: -0.4428  Acc@1: 81.2500 (78.5353)  Acc@5: 100.0000 (95.6270)  time: 0.3454  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2210/3750]  eta: 0:08:51  Lr: 0.030000  Loss: -0.5002  Acc@1: 81.2500 (78.5419)  Acc@5: 93.7500 (95.6213)  time: 0.3452  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [2220/3750]  eta: 0:08:47  Lr: 0.030000  Loss: -0.5836  Acc@1: 81.2500 (78.5485)  Acc@5: 100.0000 (95.6270)  time: 0.3458  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [2230/3750]  eta: 0:08:44  Lr: 0.030000  Loss: -0.7456  Acc@1: 81.2500 (78.5438)  Acc@5: 93.7500 (95.6214)  time: 0.3455  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [2240/3750]  eta: 0:08:40  Lr: 0.030000  Loss: -0.5670  Acc@1: 81.2500 (78.5615)  Acc@5: 100.0000 (95.6270)  time: 0.3443  data: 0.0002  max mem: 2500
Train: Epoch[5/5]  [2250/3750]  eta: 0:08:37  Lr: 0.030000  Loss: -0.6759  Acc@1: 81.2500 (78.5817)  Acc@5: 100.0000 (95.6242)  time: 0.3442  data: 0.0002  max mem: 2500
Train: Epoch[5/5]  [2260/3750]  eta: 0:08:33  Lr: 0.030000  Loss: -0.1737  Acc@1: 81.2500 (78.5852)  Acc@5: 93.7500 (95.6297)  time: 0.3443  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [2270/3750]  eta: 0:08:30  Lr: 0.030000  Loss: -0.4186  Acc@1: 81.2500 (78.5887)  Acc@5: 93.7500 (95.6269)  time: 0.3441  data: 0.0002  max mem: 2500
Train: Epoch[5/5]  [2280/3750]  eta: 0:08:26  Lr: 0.030000  Loss: -0.0256  Acc@1: 75.0000 (78.5703)  Acc@5: 93.7500 (95.6269)  time: 0.3439  data: 0.0002  max mem: 2500
Train: Epoch[5/5]  [2290/3750]  eta: 0:08:23  Lr: 0.030000  Loss: -0.1067  Acc@1: 75.0000 (78.5629)  Acc@5: 93.7500 (95.6160)  time: 0.3440  data: 0.0002  max mem: 2500
Train: Epoch[5/5]  [2300/3750]  eta: 0:08:20  Lr: 0.030000  Loss: -0.3555  Acc@1: 75.0000 (78.5610)  Acc@5: 93.7500 (95.6242)  time: 0.3443  data: 0.0002  max mem: 2500
Train: Epoch[5/5]  [2310/3750]  eta: 0:08:16  Lr: 0.030000  Loss: -0.4410  Acc@1: 75.0000 (78.5455)  Acc@5: 100.0000 (95.6242)  time: 0.3466  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [2320/3750]  eta: 0:08:13  Lr: 0.030000  Loss: -0.6520  Acc@1: 81.2500 (78.5680)  Acc@5: 100.0000 (95.6377)  time: 0.3477  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2330/3750]  eta: 0:08:09  Lr: 0.030000  Loss: -0.5522  Acc@1: 81.2500 (78.5741)  Acc@5: 100.0000 (95.6403)  time: 0.3473  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2340/3750]  eta: 0:08:06  Lr: 0.030000  Loss: -0.4061  Acc@1: 81.2500 (78.5935)  Acc@5: 100.0000 (95.6482)  time: 0.3480  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2350/3750]  eta: 0:08:02  Lr: 0.030000  Loss: -0.3199  Acc@1: 81.2500 (78.5862)  Acc@5: 93.7500 (95.6455)  time: 0.3481  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [2360/3750]  eta: 0:07:59  Lr: 0.030000  Loss: -0.2414  Acc@1: 81.2500 (78.5975)  Acc@5: 93.7500 (95.6480)  time: 0.3483  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [2370/3750]  eta: 0:07:56  Lr: 0.030000  Loss: -0.3365  Acc@1: 81.2500 (78.6087)  Acc@5: 100.0000 (95.6558)  time: 0.3469  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2380/3750]  eta: 0:07:52  Lr: 0.030000  Loss: -0.5670  Acc@1: 75.0000 (78.5804)  Acc@5: 93.7500 (95.6478)  time: 0.3462  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2390/3750]  eta: 0:07:49  Lr: 0.030000  Loss: -0.5922  Acc@1: 75.0000 (78.5602)  Acc@5: 93.7500 (95.6504)  time: 0.3470  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [2400/3750]  eta: 0:07:45  Lr: 0.030000  Loss: -0.1381  Acc@1: 75.0000 (78.5454)  Acc@5: 93.7500 (95.6502)  time: 0.3470  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2410/3750]  eta: 0:07:42  Lr: 0.030000  Loss: -0.6180  Acc@1: 81.2500 (78.5437)  Acc@5: 93.7500 (95.6476)  time: 0.3471  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2420/3750]  eta: 0:07:38  Lr: 0.030000  Loss: -0.6819  Acc@1: 81.2500 (78.5497)  Acc@5: 100.0000 (95.6500)  time: 0.3478  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2430/3750]  eta: 0:07:35  Lr: 0.030000  Loss: -0.2700  Acc@1: 81.2500 (78.5556)  Acc@5: 100.0000 (95.6654)  time: 0.3471  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2440/3750]  eta: 0:07:31  Lr: 0.030000  Loss: -0.1362  Acc@1: 75.0000 (78.5334)  Acc@5: 100.0000 (95.6524)  time: 0.3456  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [2450/3750]  eta: 0:07:28  Lr: 0.030000  Loss: -0.3706  Acc@1: 68.7500 (78.5190)  Acc@5: 93.7500 (95.6472)  time: 0.3453  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [2460/3750]  eta: 0:07:25  Lr: 0.030000  Loss: -0.7820  Acc@1: 75.0000 (78.5174)  Acc@5: 93.7500 (95.6496)  time: 0.3452  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [2470/3750]  eta: 0:07:21  Lr: 0.030000  Loss: -0.7590  Acc@1: 81.2500 (78.5310)  Acc@5: 100.0000 (95.6571)  time: 0.3454  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [2480/3750]  eta: 0:07:18  Lr: 0.030000  Loss: -0.3204  Acc@1: 81.2500 (78.5318)  Acc@5: 100.0000 (95.6570)  time: 0.3448  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [2490/3750]  eta: 0:07:14  Lr: 0.030000  Loss: -0.2519  Acc@1: 81.2500 (78.5126)  Acc@5: 93.7500 (95.6493)  time: 0.3438  data: 0.0002  max mem: 2500
Train: Epoch[5/5]  [2500/3750]  eta: 0:07:11  Lr: 0.030000  Loss: -0.4492  Acc@1: 75.0000 (78.5011)  Acc@5: 93.7500 (95.6517)  time: 0.3435  data: 0.0002  max mem: 2500
Train: Epoch[5/5]  [2510/3750]  eta: 0:07:07  Lr: 0.030000  Loss: -0.6455  Acc@1: 75.0000 (78.5096)  Acc@5: 93.7500 (95.6541)  time: 0.3450  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [2520/3750]  eta: 0:07:04  Lr: 0.030000  Loss: -0.4566  Acc@1: 81.2500 (78.4981)  Acc@5: 93.7500 (95.6515)  time: 0.3461  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2530/3750]  eta: 0:07:00  Lr: 0.030000  Loss: -0.5522  Acc@1: 75.0000 (78.5016)  Acc@5: 93.7500 (95.6490)  time: 0.3456  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [2540/3750]  eta: 0:06:57  Lr: 0.030000  Loss: -0.3971  Acc@1: 75.0000 (78.4903)  Acc@5: 93.7500 (95.6464)  time: 0.3448  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [2550/3750]  eta: 0:06:54  Lr: 0.030000  Loss: -0.6563  Acc@1: 81.2500 (78.4986)  Acc@5: 93.7500 (95.6537)  time: 0.3443  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [2560/3750]  eta: 0:06:50  Lr: 0.030000  Loss: -0.7552  Acc@1: 81.2500 (78.5069)  Acc@5: 100.0000 (95.6536)  time: 0.3442  data: 0.0002  max mem: 2500
Train: Epoch[5/5]  [2570/3750]  eta: 0:06:47  Lr: 0.030000  Loss: -0.2691  Acc@1: 75.0000 (78.4909)  Acc@5: 100.0000 (95.6534)  time: 0.3440  data: 0.0002  max mem: 2500
Train: Epoch[5/5]  [2580/3750]  eta: 0:06:43  Lr: 0.030000  Loss: -0.5581  Acc@1: 81.2500 (78.5015)  Acc@5: 100.0000 (95.6558)  time: 0.3441  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [2590/3750]  eta: 0:06:40  Lr: 0.030000  Loss: -0.3546  Acc@1: 81.2500 (78.5146)  Acc@5: 100.0000 (95.6629)  time: 0.3446  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2600/3750]  eta: 0:06:36  Lr: 0.030000  Loss: -0.2473  Acc@1: 75.0000 (78.4818)  Acc@5: 93.7500 (95.6555)  time: 0.3467  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2610/3750]  eta: 0:06:33  Lr: 0.030000  Loss: -0.4281  Acc@1: 81.2500 (78.4996)  Acc@5: 93.7500 (95.6626)  time: 0.3465  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2620/3750]  eta: 0:06:29  Lr: 0.030000  Loss: -0.5624  Acc@1: 81.2500 (78.5006)  Acc@5: 100.0000 (95.6672)  time: 0.3446  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [2630/3750]  eta: 0:06:26  Lr: 0.030000  Loss: -0.1593  Acc@1: 81.2500 (78.5086)  Acc@5: 100.0000 (95.6718)  time: 0.3448  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2640/3750]  eta: 0:06:22  Lr: 0.030000  Loss: -0.4455  Acc@1: 75.0000 (78.4859)  Acc@5: 100.0000 (95.6716)  time: 0.3447  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2650/3750]  eta: 0:06:19  Lr: 0.030000  Loss: -0.3882  Acc@1: 75.0000 (78.4610)  Acc@5: 93.7500 (95.6597)  time: 0.3445  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [2660/3750]  eta: 0:06:16  Lr: 0.030000  Loss: -0.4865  Acc@1: 75.0000 (78.4879)  Acc@5: 93.7500 (95.6642)  time: 0.3449  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [2670/3750]  eta: 0:06:12  Lr: 0.030000  Loss: -0.5471  Acc@1: 81.2500 (78.4725)  Acc@5: 93.7500 (95.6571)  time: 0.3444  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [2680/3750]  eta: 0:06:09  Lr: 0.030000  Loss: -0.5272  Acc@1: 75.0000 (78.4782)  Acc@5: 93.7500 (95.6546)  time: 0.3433  data: 0.0002  max mem: 2500
Train: Epoch[5/5]  [2690/3750]  eta: 0:06:05  Lr: 0.030000  Loss: 0.1232  Acc@1: 81.2500 (78.4769)  Acc@5: 93.7500 (95.6545)  time: 0.3432  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [2700/3750]  eta: 0:06:02  Lr: 0.030000  Loss: -0.5349  Acc@1: 81.2500 (78.4964)  Acc@5: 93.7500 (95.6567)  time: 0.3433  data: 0.0002  max mem: 2500
Train: Epoch[5/5]  [2710/3750]  eta: 0:05:58  Lr: 0.030000  Loss: -0.4935  Acc@1: 81.2500 (78.4904)  Acc@5: 93.7500 (95.6520)  time: 0.3433  data: 0.0002  max mem: 2500
Train: Epoch[5/5]  [2720/3750]  eta: 0:05:55  Lr: 0.030000  Loss: -0.6492  Acc@1: 75.0000 (78.4983)  Acc@5: 100.0000 (95.6542)  time: 0.3431  data: 0.0002  max mem: 2500
Train: Epoch[5/5]  [2730/3750]  eta: 0:05:51  Lr: 0.030000  Loss: -0.4666  Acc@1: 81.2500 (78.5060)  Acc@5: 93.7500 (95.6541)  time: 0.3430  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [2740/3750]  eta: 0:05:48  Lr: 0.030000  Loss: -0.3674  Acc@1: 81.2500 (78.5092)  Acc@5: 93.7500 (95.6494)  time: 0.3442  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [2750/3750]  eta: 0:05:44  Lr: 0.030000  Loss: -0.5799  Acc@1: 81.2500 (78.5214)  Acc@5: 100.0000 (95.6539)  time: 0.3470  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [2760/3750]  eta: 0:05:41  Lr: 0.030000  Loss: -0.5679  Acc@1: 81.2500 (78.5245)  Acc@5: 100.0000 (95.6447)  time: 0.3466  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [2770/3750]  eta: 0:05:38  Lr: 0.030000  Loss: -0.5752  Acc@1: 75.0000 (78.5096)  Acc@5: 93.7500 (95.6401)  time: 0.3443  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [2780/3750]  eta: 0:05:34  Lr: 0.030000  Loss: -0.2047  Acc@1: 75.0000 (78.5217)  Acc@5: 93.7500 (95.6423)  time: 0.3446  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [2790/3750]  eta: 0:05:31  Lr: 0.030000  Loss: -0.5475  Acc@1: 81.2500 (78.5292)  Acc@5: 100.0000 (95.6467)  time: 0.3446  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2800/3750]  eta: 0:05:27  Lr: 0.030000  Loss: -0.4308  Acc@1: 75.0000 (78.5278)  Acc@5: 100.0000 (95.6489)  time: 0.3442  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2810/3750]  eta: 0:05:24  Lr: 0.030000  Loss: -0.4308  Acc@1: 81.2500 (78.5263)  Acc@5: 100.0000 (95.6510)  time: 0.3448  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [2820/3750]  eta: 0:05:20  Lr: 0.030000  Loss: -0.8115  Acc@1: 81.2500 (78.5338)  Acc@5: 100.0000 (95.6598)  time: 0.3446  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2830/3750]  eta: 0:05:17  Lr: 0.030000  Loss: -0.6326  Acc@1: 75.0000 (78.5257)  Acc@5: 100.0000 (95.6597)  time: 0.3439  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [2840/3750]  eta: 0:05:13  Lr: 0.030000  Loss: -0.4497  Acc@1: 75.0000 (78.5419)  Acc@5: 93.7500 (95.6551)  time: 0.3437  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [2850/3750]  eta: 0:05:10  Lr: 0.030000  Loss: -0.3806  Acc@1: 81.2500 (78.5580)  Acc@5: 93.7500 (95.6594)  time: 0.3439  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [2860/3750]  eta: 0:05:07  Lr: 0.030000  Loss: -0.2398  Acc@1: 81.2500 (78.5608)  Acc@5: 93.7500 (95.6549)  time: 0.3440  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [2870/3750]  eta: 0:05:03  Lr: 0.030000  Loss: -0.4490  Acc@1: 75.0000 (78.5549)  Acc@5: 93.7500 (95.6483)  time: 0.3444  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [2880/3750]  eta: 0:05:00  Lr: 0.030000  Loss: -0.0341  Acc@1: 81.2500 (78.5578)  Acc@5: 93.7500 (95.6482)  time: 0.3446  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2890/3750]  eta: 0:04:56  Lr: 0.030000  Loss: -0.5192  Acc@1: 81.2500 (78.5606)  Acc@5: 93.7500 (95.6438)  time: 0.3446  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [2900/3750]  eta: 0:04:53  Lr: 0.030000  Loss: -0.3550  Acc@1: 81.2500 (78.5742)  Acc@5: 93.7500 (95.6373)  time: 0.3447  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [2910/3750]  eta: 0:04:49  Lr: 0.030000  Loss: -0.5983  Acc@1: 81.2500 (78.5855)  Acc@5: 93.7500 (95.6329)  time: 0.3444  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [2920/3750]  eta: 0:04:46  Lr: 0.030000  Loss: -0.2861  Acc@1: 81.2500 (78.5882)  Acc@5: 93.7500 (95.6179)  time: 0.3448  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [2930/3750]  eta: 0:04:42  Lr: 0.030000  Loss: -0.4979  Acc@1: 81.2500 (78.5717)  Acc@5: 93.7500 (95.6094)  time: 0.3448  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [2940/3750]  eta: 0:04:39  Lr: 0.030000  Loss: -0.7905  Acc@1: 81.2500 (78.5787)  Acc@5: 93.7500 (95.6159)  time: 0.3442  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [2950/3750]  eta: 0:04:35  Lr: 0.030000  Loss: -0.6704  Acc@1: 87.5000 (78.5941)  Acc@5: 100.0000 (95.6180)  time: 0.3441  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [2960/3750]  eta: 0:04:32  Lr: 0.030000  Loss: -0.4971  Acc@1: 81.2500 (78.5883)  Acc@5: 100.0000 (95.6201)  time: 0.3442  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [2970/3750]  eta: 0:04:29  Lr: 0.030000  Loss: -0.7039  Acc@1: 75.0000 (78.5804)  Acc@5: 93.7500 (95.6160)  time: 0.3434  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [2980/3750]  eta: 0:04:25  Lr: 0.030000  Loss: -0.1361  Acc@1: 75.0000 (78.5768)  Acc@5: 93.7500 (95.6160)  time: 0.3423  data: 0.0002  max mem: 2500
Train: Epoch[5/5]  [2990/3750]  eta: 0:04:22  Lr: 0.030000  Loss: -0.0857  Acc@1: 75.0000 (78.5711)  Acc@5: 100.0000 (95.6160)  time: 0.3426  data: 0.0002  max mem: 2500
Train: Epoch[5/5]  [3000/3750]  eta: 0:04:18  Lr: 0.030000  Loss: -0.4667  Acc@1: 81.2500 (78.5905)  Acc@5: 93.7500 (95.6140)  time: 0.3427  data: 0.0002  max mem: 2500
Train: Epoch[5/5]  [3010/3750]  eta: 0:04:15  Lr: 0.030000  Loss: -0.6211  Acc@1: 81.2500 (78.5931)  Acc@5: 93.7500 (95.6078)  time: 0.3429  data: 0.0002  max mem: 2500
Train: Epoch[5/5]  [3020/3750]  eta: 0:04:11  Lr: 0.030000  Loss: -0.4848  Acc@1: 81.2500 (78.6019)  Acc@5: 93.7500 (95.6099)  time: 0.3442  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [3030/3750]  eta: 0:04:08  Lr: 0.030000  Loss: -0.6888  Acc@1: 81.2500 (78.6127)  Acc@5: 93.7500 (95.6120)  time: 0.3448  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3040/3750]  eta: 0:04:04  Lr: 0.030000  Loss: -0.4482  Acc@1: 81.2500 (78.6378)  Acc@5: 93.7500 (95.6162)  time: 0.3443  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3050/3750]  eta: 0:04:01  Lr: 0.030000  Loss: -0.7300  Acc@1: 81.2500 (78.6361)  Acc@5: 93.7500 (95.6141)  time: 0.3443  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3060/3750]  eta: 0:03:57  Lr: 0.030000  Loss: -0.4000  Acc@1: 81.2500 (78.6406)  Acc@5: 93.7500 (95.6060)  time: 0.3441  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3070/3750]  eta: 0:03:54  Lr: 0.030000  Loss: -0.3248  Acc@1: 81.2500 (78.6307)  Acc@5: 93.7500 (95.5878)  time: 0.3451  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3080/3750]  eta: 0:03:51  Lr: 0.030000  Loss: -0.6477  Acc@1: 81.2500 (78.6392)  Acc@5: 93.7500 (95.5899)  time: 0.3466  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [3090/3750]  eta: 0:03:47  Lr: 0.030000  Loss: -0.4666  Acc@1: 81.2500 (78.6315)  Acc@5: 100.0000 (95.5941)  time: 0.3461  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3100/3750]  eta: 0:03:44  Lr: 0.030000  Loss: -0.5280  Acc@1: 81.2500 (78.6480)  Acc@5: 100.0000 (95.6042)  time: 0.3453  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3110/3750]  eta: 0:03:40  Lr: 0.030000  Loss: -0.2013  Acc@1: 81.2500 (78.6504)  Acc@5: 100.0000 (95.6043)  time: 0.3450  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3120/3750]  eta: 0:03:37  Lr: 0.030000  Loss: -0.2615  Acc@1: 81.2500 (78.6527)  Acc@5: 93.7500 (95.6104)  time: 0.3445  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [3130/3750]  eta: 0:03:33  Lr: 0.030000  Loss: -0.6176  Acc@1: 81.2500 (78.6630)  Acc@5: 93.7500 (95.6084)  time: 0.3444  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [3140/3750]  eta: 0:03:30  Lr: 0.030000  Loss: -0.4862  Acc@1: 81.2500 (78.6613)  Acc@5: 93.7500 (95.6125)  time: 0.3448  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [3150/3750]  eta: 0:03:26  Lr: 0.030000  Loss: -0.4973  Acc@1: 81.2500 (78.6576)  Acc@5: 100.0000 (95.6085)  time: 0.3446  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [3160/3750]  eta: 0:03:23  Lr: 0.030000  Loss: -0.0659  Acc@1: 81.2500 (78.6579)  Acc@5: 100.0000 (95.6125)  time: 0.3440  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [3170/3750]  eta: 0:03:20  Lr: 0.030000  Loss: -0.3281  Acc@1: 81.2500 (78.6503)  Acc@5: 93.7500 (95.6027)  time: 0.3443  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [3180/3750]  eta: 0:03:16  Lr: 0.030000  Loss: -0.2629  Acc@1: 75.0000 (78.6447)  Acc@5: 93.7500 (95.6048)  time: 0.3436  data: 0.0002  max mem: 2500
Train: Epoch[5/5]  [3190/3750]  eta: 0:03:13  Lr: 0.030000  Loss: 0.0060  Acc@1: 75.0000 (78.6450)  Acc@5: 93.7500 (95.5990)  time: 0.3426  data: 0.0002  max mem: 2500
Train: Epoch[5/5]  [3200/3750]  eta: 0:03:09  Lr: 0.030000  Loss: -0.4463  Acc@1: 81.2500 (78.6493)  Acc@5: 93.7500 (95.5990)  time: 0.3427  data: 0.0002  max mem: 2500
Train: Epoch[5/5]  [3210/3750]  eta: 0:03:06  Lr: 0.030000  Loss: -0.7945  Acc@1: 75.0000 (78.6554)  Acc@5: 93.7500 (95.5952)  time: 0.3427  data: 0.0002  max mem: 2500
Train: Epoch[5/5]  [3220/3750]  eta: 0:03:02  Lr: 0.030000  Loss: -0.4174  Acc@1: 75.0000 (78.6518)  Acc@5: 93.7500 (95.5934)  time: 0.3433  data: 0.0002  max mem: 2500
Train: Epoch[5/5]  [3230/3750]  eta: 0:02:59  Lr: 0.030000  Loss: -0.8261  Acc@1: 81.2500 (78.6637)  Acc@5: 93.7500 (95.5935)  time: 0.3450  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [3240/3750]  eta: 0:02:55  Lr: 0.030000  Loss: -0.5322  Acc@1: 81.2500 (78.6736)  Acc@5: 93.7500 (95.5955)  time: 0.3454  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3250/3750]  eta: 0:02:52  Lr: 0.030000  Loss: -0.7581  Acc@1: 81.2500 (78.6835)  Acc@5: 100.0000 (95.6033)  time: 0.3447  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3260/3750]  eta: 0:02:48  Lr: 0.030000  Loss: -0.5318  Acc@1: 81.2500 (78.6856)  Acc@5: 100.0000 (95.6091)  time: 0.3451  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3270/3750]  eta: 0:02:45  Lr: 0.030000  Loss: -0.1794  Acc@1: 81.2500 (78.6839)  Acc@5: 100.0000 (95.6072)  time: 0.3453  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3280/3750]  eta: 0:02:42  Lr: 0.030000  Loss: -0.5155  Acc@1: 81.2500 (78.6936)  Acc@5: 100.0000 (95.6054)  time: 0.3466  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3290/3750]  eta: 0:02:38  Lr: 0.030000  Loss: -0.3910  Acc@1: 81.2500 (78.6938)  Acc@5: 100.0000 (95.6073)  time: 0.3465  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3300/3750]  eta: 0:02:35  Lr: 0.030000  Loss: -0.4098  Acc@1: 81.2500 (78.7015)  Acc@5: 100.0000 (95.6150)  time: 0.3450  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3310/3750]  eta: 0:02:31  Lr: 0.030000  Loss: -0.6757  Acc@1: 81.2500 (78.7017)  Acc@5: 100.0000 (95.6093)  time: 0.3451  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3320/3750]  eta: 0:02:28  Lr: 0.030000  Loss: -0.6685  Acc@1: 81.2500 (78.7018)  Acc@5: 93.7500 (95.6075)  time: 0.3458  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3330/3750]  eta: 0:02:24  Lr: 0.030000  Loss: -0.2698  Acc@1: 81.2500 (78.7001)  Acc@5: 93.7500 (95.6000)  time: 0.3457  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3340/3750]  eta: 0:02:21  Lr: 0.030000  Loss: -0.7888  Acc@1: 75.0000 (78.6946)  Acc@5: 93.7500 (95.5982)  time: 0.3454  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [3350/3750]  eta: 0:02:17  Lr: 0.030000  Loss: -0.4659  Acc@1: 75.0000 (78.6948)  Acc@5: 93.7500 (95.5983)  time: 0.3455  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [3360/3750]  eta: 0:02:14  Lr: 0.030000  Loss: -0.6410  Acc@1: 75.0000 (78.6968)  Acc@5: 100.0000 (95.6003)  time: 0.3456  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [3370/3750]  eta: 0:02:11  Lr: 0.030000  Loss: -0.2946  Acc@1: 75.0000 (78.6933)  Acc@5: 93.7500 (95.6040)  time: 0.3456  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [3380/3750]  eta: 0:02:07  Lr: 0.030000  Loss: -0.4941  Acc@1: 81.2500 (78.7008)  Acc@5: 100.0000 (95.6060)  time: 0.3457  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [3390/3750]  eta: 0:02:04  Lr: 0.030000  Loss: -0.3413  Acc@1: 81.2500 (78.6973)  Acc@5: 100.0000 (95.6097)  time: 0.3481  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [3400/3750]  eta: 0:02:00  Lr: 0.030000  Loss: -0.1537  Acc@1: 81.2500 (78.7030)  Acc@5: 100.0000 (95.6189)  time: 0.3469  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [3410/3750]  eta: 0:01:57  Lr: 0.030000  Loss: -0.3323  Acc@1: 81.2500 (78.6903)  Acc@5: 100.0000 (95.6153)  time: 0.3439  data: 0.0002  max mem: 2500
Train: Epoch[5/5]  [3420/3750]  eta: 0:01:53  Lr: 0.030000  Loss: -0.7709  Acc@1: 81.2500 (78.7032)  Acc@5: 93.7500 (95.6153)  time: 0.3437  data: 0.0002  max mem: 2500
Train: Epoch[5/5]  [3430/3750]  eta: 0:01:50  Lr: 0.030000  Loss: -0.1634  Acc@1: 75.0000 (78.6833)  Acc@5: 100.0000 (95.6135)  time: 0.3438  data: 0.0002  max mem: 2500
Train: Epoch[5/5]  [3440/3750]  eta: 0:01:46  Lr: 0.030000  Loss: -0.5539  Acc@1: 75.0000 (78.6926)  Acc@5: 100.0000 (95.6190)  time: 0.3437  data: 0.0002  max mem: 2500
Train: Epoch[5/5]  [3450/3750]  eta: 0:01:43  Lr: 0.030000  Loss: -0.2967  Acc@1: 81.2500 (78.6891)  Acc@5: 93.7500 (95.6136)  time: 0.3437  data: 0.0002  max mem: 2500
Train: Epoch[5/5]  [3460/3750]  eta: 0:01:40  Lr: 0.030000  Loss: -0.6390  Acc@1: 75.0000 (78.6929)  Acc@5: 93.7500 (95.6154)  time: 0.3436  data: 0.0002  max mem: 2500
Train: Epoch[5/5]  [3470/3750]  eta: 0:01:36  Lr: 0.030000  Loss: -0.3363  Acc@1: 81.2500 (78.7003)  Acc@5: 93.7500 (95.6137)  time: 0.3439  data: 0.0002  max mem: 2500
Train: Epoch[5/5]  [3480/3750]  eta: 0:01:33  Lr: 0.030000  Loss: -0.1546  Acc@1: 81.2500 (78.6933)  Acc@5: 93.7500 (95.6083)  time: 0.3443  data: 0.0002  max mem: 2500
Train: Epoch[5/5]  [3490/3750]  eta: 0:01:29  Lr: 0.030000  Loss: -0.5135  Acc@1: 75.0000 (78.6916)  Acc@5: 100.0000 (95.6137)  time: 0.3460  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [3500/3750]  eta: 0:01:26  Lr: 0.030000  Loss: -0.5117  Acc@1: 87.5000 (78.7186)  Acc@5: 100.0000 (95.6209)  time: 0.3469  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3510/3750]  eta: 0:01:22  Lr: 0.030000  Loss: -0.7717  Acc@1: 81.2500 (78.7080)  Acc@5: 100.0000 (95.6245)  time: 0.3464  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3520/3750]  eta: 0:01:19  Lr: 0.030000  Loss: -0.5013  Acc@1: 75.0000 (78.7134)  Acc@5: 93.7500 (95.6227)  time: 0.3461  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3530/3750]  eta: 0:01:15  Lr: 0.030000  Loss: -0.5898  Acc@1: 81.2500 (78.7259)  Acc@5: 93.7500 (95.6209)  time: 0.3454  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [3540/3750]  eta: 0:01:12  Lr: 0.030000  Loss: -0.3148  Acc@1: 75.0000 (78.7013)  Acc@5: 93.7500 (95.6174)  time: 0.3459  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3550/3750]  eta: 0:01:08  Lr: 0.030000  Loss: -0.2044  Acc@1: 75.0000 (78.6944)  Acc@5: 93.7500 (95.6192)  time: 0.3458  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3560/3750]  eta: 0:01:05  Lr: 0.030000  Loss: -0.3794  Acc@1: 75.0000 (78.6963)  Acc@5: 93.7500 (95.6210)  time: 0.3453  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3570/3750]  eta: 0:01:02  Lr: 0.030000  Loss: -0.5258  Acc@1: 81.2500 (78.6999)  Acc@5: 93.7500 (95.6157)  time: 0.3458  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [3580/3750]  eta: 0:00:58  Lr: 0.030000  Loss: -0.4445  Acc@1: 81.2500 (78.7071)  Acc@5: 93.7500 (95.6175)  time: 0.3453  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3590/3750]  eta: 0:00:55  Lr: 0.030000  Loss: -0.6007  Acc@1: 81.2500 (78.7072)  Acc@5: 93.7500 (95.6193)  time: 0.3454  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3600/3750]  eta: 0:00:51  Lr: 0.030000  Loss: -0.5859  Acc@1: 81.2500 (78.7247)  Acc@5: 100.0000 (95.6280)  time: 0.3458  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3610/3750]  eta: 0:00:48  Lr: 0.030000  Loss: -0.5037  Acc@1: 81.2500 (78.7265)  Acc@5: 100.0000 (95.6245)  time: 0.3455  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3620/3750]  eta: 0:00:44  Lr: 0.030000  Loss: -0.3597  Acc@1: 81.2500 (78.7421)  Acc@5: 93.7500 (95.6262)  time: 0.3457  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3630/3750]  eta: 0:00:41  Lr: 0.030000  Loss: -0.6238  Acc@1: 87.5000 (78.7696)  Acc@5: 93.7500 (95.6279)  time: 0.3456  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3640/3750]  eta: 0:00:37  Lr: 0.030000  Loss: -0.4685  Acc@1: 87.5000 (78.7524)  Acc@5: 93.7500 (95.6314)  time: 0.3450  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3650/3750]  eta: 0:00:34  Lr: 0.030000  Loss: -0.7008  Acc@1: 75.0000 (78.7558)  Acc@5: 100.0000 (95.6330)  time: 0.3446  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3660/3750]  eta: 0:00:31  Lr: 0.030000  Loss: -0.3068  Acc@1: 75.0000 (78.7524)  Acc@5: 100.0000 (95.6347)  time: 0.3449  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3670/3750]  eta: 0:00:27  Lr: 0.030000  Loss: -0.4503  Acc@1: 81.2500 (78.7694)  Acc@5: 100.0000 (95.6415)  time: 0.3452  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3680/3750]  eta: 0:00:24  Lr: 0.030000  Loss: -0.6340  Acc@1: 87.5000 (78.7931)  Acc@5: 100.0000 (95.6466)  time: 0.3477  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3690/3750]  eta: 0:00:20  Lr: 0.030000  Loss: -0.0989  Acc@1: 87.5000 (78.7947)  Acc@5: 100.0000 (95.6431)  time: 0.3472  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3700/3750]  eta: 0:00:17  Lr: 0.030000  Loss: -0.3072  Acc@1: 81.2500 (78.7980)  Acc@5: 93.7500 (95.6397)  time: 0.3447  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [3710/3750]  eta: 0:00:13  Lr: 0.030000  Loss: -0.5932  Acc@1: 81.2500 (78.7894)  Acc@5: 100.0000 (95.6430)  time: 0.3445  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [3720/3750]  eta: 0:00:10  Lr: 0.030000  Loss: -0.6165  Acc@1: 75.0000 (78.7893)  Acc@5: 93.7500 (95.6396)  time: 0.3450  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3730/3750]  eta: 0:00:06  Lr: 0.030000  Loss: -0.7212  Acc@1: 75.0000 (78.7808)  Acc@5: 93.7500 (95.6412)  time: 0.3455  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3740/3750]  eta: 0:00:03  Lr: 0.030000  Loss: 0.0489  Acc@1: 75.0000 (78.7590)  Acc@5: 93.7500 (95.6295)  time: 0.3446  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [3749/3750]  eta: 0:00:00  Lr: 0.030000  Loss: -0.3570  Acc@1: 75.0000 (78.7667)  Acc@5: 93.7500 (95.6333)  time: 0.3450  data: 0.0008  max mem: 2500
Train: Epoch[5/5] Total time: 0:21:34 (0.3451 s / it)
{0: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 1: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 2: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 3: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 4: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 5: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 6: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 7: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 8: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 9: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 10: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 11: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 12: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 13: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 14: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 15: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 16: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 17: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 18: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 19: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}}
Averaged stats: Lr: 0.030000  Loss: -0.3570  Acc@1: 75.0000 (78.7667)  Acc@5: 93.7500 (95.6333)
Test: [Task 1]  [   0/1627]  eta: 0:13:20  Loss: 2.5126 (2.5126)  Acc@1: 87.5000 (87.5000)  Acc@5: 93.7500 (93.7500)  time: 0.4920  data: 0.2778  max mem: 2500
Test: [Task 1]  [  10/1627]  eta: 0:06:28  Loss: 2.4349 (2.4199)  Acc@1: 87.5000 (84.0909)  Acc@5: 93.7500 (96.0227)  time: 0.2404  data: 0.0255  max mem: 2500
Test: [Task 1]  [  20/1627]  eta: 0:06:05  Loss: 2.4324 (2.4459)  Acc@1: 81.2500 (83.0357)  Acc@5: 93.7500 (95.2381)  time: 0.2141  data: 0.0003  max mem: 2500
Test: [Task 1]  [  30/1627]  eta: 0:05:55  Loss: 2.4842 (2.4571)  Acc@1: 81.2500 (82.6613)  Acc@5: 100.0000 (96.1694)  time: 0.2128  data: 0.0002  max mem: 2500
Test: [Task 1]  [  40/1627]  eta: 0:05:49  Loss: 2.5051 (2.4725)  Acc@1: 81.2500 (81.5549)  Acc@5: 100.0000 (96.0366)  time: 0.2126  data: 0.0002  max mem: 2500
Test: [Task 1]  [  50/1627]  eta: 0:05:44  Loss: 2.4413 (2.4654)  Acc@1: 81.2500 (81.7402)  Acc@5: 100.0000 (96.0784)  time: 0.2127  data: 0.0002  max mem: 2500
Test: [Task 1]  [  60/1627]  eta: 0:05:41  Loss: 2.4418 (2.4694)  Acc@1: 81.2500 (81.5574)  Acc@5: 93.7500 (95.5943)  time: 0.2128  data: 0.0002  max mem: 2500
Test: [Task 1]  [  70/1627]  eta: 0:05:37  Loss: 2.4554 (2.4720)  Acc@1: 81.2500 (81.1620)  Acc@5: 93.7500 (95.9507)  time: 0.2128  data: 0.0002  max mem: 2500
Test: [Task 1]  [  80/1627]  eta: 0:05:34  Loss: 2.4176 (2.4695)  Acc@1: 81.2500 (81.4043)  Acc@5: 100.0000 (96.2963)  time: 0.2129  data: 0.0002  max mem: 2500
Test: [Task 1]  [  90/1627]  eta: 0:05:32  Loss: 2.4323 (2.4701)  Acc@1: 81.2500 (80.9753)  Acc@5: 100.0000 (96.0852)  time: 0.2130  data: 0.0002  max mem: 2500
Test: [Task 1]  [ 100/1627]  eta: 0:05:29  Loss: 2.4924 (2.4785)  Acc@1: 75.0000 (80.4455)  Acc@5: 93.7500 (95.8540)  time: 0.2127  data: 0.0002  max mem: 2500
Test: [Task 1]  [ 110/1627]  eta: 0:05:26  Loss: 2.4729 (2.4782)  Acc@1: 81.2500 (80.5743)  Acc@5: 93.7500 (96.0023)  time: 0.2126  data: 0.0002  max mem: 2500
Test: [Task 1]  [ 120/1627]  eta: 0:05:24  Loss: 2.4378 (2.4785)  Acc@1: 87.5000 (80.5785)  Acc@5: 100.0000 (96.0744)  time: 0.2128  data: 0.0002  max mem: 2500
Test: [Task 1]  [ 130/1627]  eta: 0:05:21  Loss: 2.4438 (2.4751)  Acc@1: 87.5000 (80.7252)  Acc@5: 100.0000 (96.0401)  time: 0.2126  data: 0.0002  max mem: 2500
Test: [Task 1]  [ 140/1627]  eta: 0:05:19  Loss: 2.4429 (2.4737)  Acc@1: 81.2500 (80.7624)  Acc@5: 100.0000 (96.1436)  time: 0.2128  data: 0.0002  max mem: 2500
Test: [Task 1]  [ 150/1627]  eta: 0:05:17  Loss: 2.3393 (2.4658)  Acc@1: 87.5000 (81.0430)  Acc@5: 100.0000 (96.1507)  time: 0.2128  data: 0.0002  max mem: 2500
Test: [Task 1]  [ 160/1627]  eta: 0:05:14  Loss: 2.3532 (2.4654)  Acc@1: 87.5000 (81.1724)  Acc@5: 100.0000 (96.3121)  time: 0.2132  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 170/1627]  eta: 0:05:12  Loss: 2.4277 (2.4628)  Acc@1: 87.5000 (81.3596)  Acc@5: 100.0000 (96.4547)  time: 0.2136  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 180/1627]  eta: 0:05:10  Loss: 2.4277 (2.4647)  Acc@1: 81.2500 (81.2155)  Acc@5: 100.0000 (96.4434)  time: 0.2137  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 190/1627]  eta: 0:05:08  Loss: 2.4591 (2.4632)  Acc@1: 81.2500 (81.2500)  Acc@5: 93.7500 (96.4005)  time: 0.2139  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 200/1627]  eta: 0:05:06  Loss: 2.4596 (2.4624)  Acc@1: 81.2500 (81.1256)  Acc@5: 100.0000 (96.4863)  time: 0.2140  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 210/1627]  eta: 0:05:03  Loss: 2.4437 (2.4602)  Acc@1: 81.2500 (81.2796)  Acc@5: 100.0000 (96.4751)  time: 0.2142  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 220/1627]  eta: 0:05:01  Loss: 2.4087 (2.4608)  Acc@1: 81.2500 (81.1086)  Acc@5: 100.0000 (96.5498)  time: 0.2142  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 230/1627]  eta: 0:04:59  Loss: 2.4383 (2.4606)  Acc@1: 81.2500 (81.2771)  Acc@5: 100.0000 (96.4827)  time: 0.2142  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 240/1627]  eta: 0:04:57  Loss: 2.4047 (2.4598)  Acc@1: 81.2500 (81.3537)  Acc@5: 93.7500 (96.4990)  time: 0.2143  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 250/1627]  eta: 0:04:55  Loss: 2.3868 (2.4577)  Acc@1: 81.2500 (81.2749)  Acc@5: 100.0000 (96.4890)  time: 0.2138  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 260/1627]  eta: 0:04:53  Loss: 2.4136 (2.4588)  Acc@1: 81.2500 (81.2979)  Acc@5: 100.0000 (96.4320)  time: 0.2140  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 270/1627]  eta: 0:04:50  Loss: 2.4249 (2.4560)  Acc@1: 87.5000 (81.4345)  Acc@5: 100.0000 (96.4714)  time: 0.2142  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 280/1627]  eta: 0:04:48  Loss: 2.4239 (2.4564)  Acc@1: 81.2500 (81.3167)  Acc@5: 100.0000 (96.4635)  time: 0.2139  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 290/1627]  eta: 0:04:46  Loss: 2.4239 (2.4558)  Acc@1: 81.2500 (81.3789)  Acc@5: 93.7500 (96.4777)  time: 0.2138  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 300/1627]  eta: 0:04:44  Loss: 2.4292 (2.4554)  Acc@1: 81.2500 (81.3331)  Acc@5: 100.0000 (96.4909)  time: 0.2140  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 310/1627]  eta: 0:04:42  Loss: 2.4535 (2.4544)  Acc@1: 81.2500 (81.3907)  Acc@5: 100.0000 (96.4630)  time: 0.2142  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 320/1627]  eta: 0:04:40  Loss: 2.4509 (2.4555)  Acc@1: 81.2500 (81.3863)  Acc@5: 100.0000 (96.5343)  time: 0.2141  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 330/1627]  eta: 0:04:38  Loss: 2.4209 (2.4559)  Acc@1: 81.2500 (81.3444)  Acc@5: 100.0000 (96.5446)  time: 0.2141  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 340/1627]  eta: 0:04:35  Loss: 2.4481 (2.4576)  Acc@1: 81.2500 (81.3600)  Acc@5: 100.0000 (96.5543)  time: 0.2139  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 350/1627]  eta: 0:04:33  Loss: 2.4751 (2.4577)  Acc@1: 81.2500 (81.3568)  Acc@5: 100.0000 (96.5634)  time: 0.2140  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 360/1627]  eta: 0:04:31  Loss: 2.4751 (2.4594)  Acc@1: 81.2500 (81.2327)  Acc@5: 100.0000 (96.5547)  time: 0.2144  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 370/1627]  eta: 0:04:29  Loss: 2.4163 (2.4577)  Acc@1: 81.2500 (81.3342)  Acc@5: 100.0000 (96.5633)  time: 0.2146  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 380/1627]  eta: 0:04:27  Loss: 2.4105 (2.4574)  Acc@1: 81.2500 (81.3812)  Acc@5: 93.7500 (96.5059)  time: 0.2145  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 390/1627]  eta: 0:04:25  Loss: 2.4341 (2.4575)  Acc@1: 81.2500 (81.2500)  Acc@5: 93.7500 (96.4514)  time: 0.2145  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 400/1627]  eta: 0:04:23  Loss: 2.4480 (2.4567)  Acc@1: 75.0000 (81.2812)  Acc@5: 93.7500 (96.4620)  time: 0.2146  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 410/1627]  eta: 0:04:20  Loss: 2.4071 (2.4563)  Acc@1: 81.2500 (81.3260)  Acc@5: 100.0000 (96.4416)  time: 0.2148  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 420/1627]  eta: 0:04:18  Loss: 2.4206 (2.4557)  Acc@1: 81.2500 (81.3836)  Acc@5: 100.0000 (96.4667)  time: 0.2146  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 430/1627]  eta: 0:04:16  Loss: 2.4032 (2.4543)  Acc@1: 81.2500 (81.4240)  Acc@5: 100.0000 (96.4907)  time: 0.2149  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 440/1627]  eta: 0:04:14  Loss: 2.3840 (2.4537)  Acc@1: 81.2500 (81.4059)  Acc@5: 100.0000 (96.4994)  time: 0.2145  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 450/1627]  eta: 0:04:12  Loss: 2.4329 (2.4552)  Acc@1: 81.2500 (81.3193)  Acc@5: 93.7500 (96.4385)  time: 0.2138  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 460/1627]  eta: 0:04:10  Loss: 2.4374 (2.4553)  Acc@1: 81.2500 (81.3313)  Acc@5: 100.0000 (96.4479)  time: 0.2141  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 470/1627]  eta: 0:04:08  Loss: 2.3902 (2.4544)  Acc@1: 87.5000 (81.3827)  Acc@5: 100.0000 (96.4437)  time: 0.2141  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 480/1627]  eta: 0:04:05  Loss: 2.3677 (2.4547)  Acc@1: 81.2500 (81.2630)  Acc@5: 100.0000 (96.4657)  time: 0.2141  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 490/1627]  eta: 0:04:03  Loss: 2.5082 (2.4555)  Acc@1: 81.2500 (81.2755)  Acc@5: 93.7500 (96.4486)  time: 0.2144  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 500/1627]  eta: 0:04:01  Loss: 2.5003 (2.4561)  Acc@1: 81.2500 (81.2375)  Acc@5: 93.7500 (96.3947)  time: 0.2144  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 510/1627]  eta: 0:03:59  Loss: 2.4660 (2.4574)  Acc@1: 81.2500 (81.1766)  Acc@5: 93.7500 (96.3185)  time: 0.2141  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 520/1627]  eta: 0:03:57  Loss: 2.4538 (2.4581)  Acc@1: 81.2500 (81.1780)  Acc@5: 93.7500 (96.3052)  time: 0.2142  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 530/1627]  eta: 0:03:55  Loss: 2.3895 (2.4559)  Acc@1: 87.5000 (81.2500)  Acc@5: 100.0000 (96.3395)  time: 0.2142  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 540/1627]  eta: 0:03:52  Loss: 2.3841 (2.4566)  Acc@1: 81.2500 (81.2038)  Acc@5: 100.0000 (96.3494)  time: 0.2142  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 550/1627]  eta: 0:03:50  Loss: 2.4845 (2.4578)  Acc@1: 75.0000 (81.1139)  Acc@5: 100.0000 (96.3475)  time: 0.2149  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 560/1627]  eta: 0:03:48  Loss: 2.4627 (2.4585)  Acc@1: 75.0000 (81.0606)  Acc@5: 93.7500 (96.3347)  time: 0.2147  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 570/1627]  eta: 0:03:46  Loss: 2.4061 (2.4571)  Acc@1: 81.2500 (81.1843)  Acc@5: 93.7500 (96.3660)  time: 0.2136  data: 0.0002  max mem: 2500
Test: [Task 1]  [ 580/1627]  eta: 0:03:44  Loss: 2.3787 (2.4566)  Acc@1: 87.5000 (81.2177)  Acc@5: 100.0000 (96.3640)  time: 0.2130  data: 0.0002  max mem: 2500
Test: [Task 1]  [ 590/1627]  eta: 0:03:42  Loss: 2.4212 (2.4565)  Acc@1: 81.2500 (81.2288)  Acc@5: 100.0000 (96.4044)  time: 0.2131  data: 0.0002  max mem: 2500
Test: [Task 1]  [ 600/1627]  eta: 0:03:40  Loss: 2.4350 (2.4564)  Acc@1: 81.2500 (81.2500)  Acc@5: 100.0000 (96.4226)  time: 0.2133  data: 0.0002  max mem: 2500
Test: [Task 1]  [ 610/1627]  eta: 0:03:37  Loss: 2.3802 (2.4548)  Acc@1: 81.2500 (81.3114)  Acc@5: 100.0000 (96.4403)  time: 0.2133  data: 0.0002  max mem: 2500
Test: [Task 1]  [ 620/1627]  eta: 0:03:35  Loss: 2.3802 (2.4554)  Acc@1: 81.2500 (81.2097)  Acc@5: 100.0000 (96.4372)  time: 0.2134  data: 0.0002  max mem: 2500
Test: [Task 1]  [ 630/1627]  eta: 0:03:33  Loss: 2.4806 (2.4555)  Acc@1: 75.0000 (81.2005)  Acc@5: 100.0000 (96.4342)  time: 0.2132  data: 0.0002  max mem: 2500
Test: [Task 1]  [ 640/1627]  eta: 0:03:31  Loss: 2.4205 (2.4551)  Acc@1: 81.2500 (81.2110)  Acc@5: 100.0000 (96.4314)  time: 0.2131  data: 0.0002  max mem: 2500
Test: [Task 1]  [ 650/1627]  eta: 0:03:29  Loss: 2.4801 (2.4548)  Acc@1: 81.2500 (81.1732)  Acc@5: 100.0000 (96.4478)  time: 0.2133  data: 0.0002  max mem: 2500
Test: [Task 1]  [ 660/1627]  eta: 0:03:27  Loss: 2.4515 (2.4540)  Acc@1: 81.2500 (81.1933)  Acc@5: 100.0000 (96.4259)  time: 0.2132  data: 0.0002  max mem: 2500
Test: [Task 1]  [ 670/1627]  eta: 0:03:24  Loss: 2.4242 (2.4542)  Acc@1: 81.2500 (81.1755)  Acc@5: 100.0000 (96.4232)  time: 0.2132  data: 0.0002  max mem: 2500
Test: [Task 1]  [ 680/1627]  eta: 0:03:22  Loss: 2.4305 (2.4536)  Acc@1: 81.2500 (81.1949)  Acc@5: 100.0000 (96.4391)  time: 0.2133  data: 0.0002  max mem: 2500
Test: [Task 1]  [ 690/1627]  eta: 0:03:20  Loss: 2.4074 (2.4521)  Acc@1: 81.2500 (81.2590)  Acc@5: 100.0000 (96.4725)  time: 0.2134  data: 0.0002  max mem: 2500
Test: [Task 1]  [ 700/1627]  eta: 0:03:18  Loss: 2.4074 (2.4524)  Acc@1: 87.5000 (81.3035)  Acc@5: 100.0000 (96.4426)  time: 0.2136  data: 0.0002  max mem: 2500
Test: [Task 1]  [ 710/1627]  eta: 0:03:16  Loss: 2.4062 (2.4517)  Acc@1: 81.2500 (81.3379)  Acc@5: 100.0000 (96.4662)  time: 0.2141  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 720/1627]  eta: 0:03:14  Loss: 2.4042 (2.4515)  Acc@1: 81.2500 (81.3540)  Acc@5: 100.0000 (96.4632)  time: 0.2145  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 730/1627]  eta: 0:03:12  Loss: 2.4063 (2.4522)  Acc@1: 81.2500 (81.3098)  Acc@5: 100.0000 (96.4603)  time: 0.2147  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 740/1627]  eta: 0:03:09  Loss: 2.5025 (2.4528)  Acc@1: 81.2500 (81.2500)  Acc@5: 93.7500 (96.4491)  time: 0.2151  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 750/1627]  eta: 0:03:07  Loss: 2.4755 (2.4526)  Acc@1: 81.2500 (81.2916)  Acc@5: 100.0000 (96.4714)  time: 0.2151  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 760/1627]  eta: 0:03:05  Loss: 2.4295 (2.4529)  Acc@1: 81.2500 (81.2993)  Acc@5: 100.0000 (96.4356)  time: 0.2145  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 770/1627]  eta: 0:03:03  Loss: 2.4295 (2.4522)  Acc@1: 81.2500 (81.3149)  Acc@5: 100.0000 (96.4656)  time: 0.2145  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 780/1627]  eta: 0:03:01  Loss: 2.3639 (2.4509)  Acc@1: 87.5000 (81.4020)  Acc@5: 100.0000 (96.4869)  time: 0.2147  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 790/1627]  eta: 0:02:59  Loss: 2.3472 (2.4515)  Acc@1: 87.5000 (81.3764)  Acc@5: 100.0000 (96.4681)  time: 0.2149  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 800/1627]  eta: 0:02:57  Loss: 2.4363 (2.4514)  Acc@1: 87.5000 (81.4217)  Acc@5: 93.7500 (96.4654)  time: 0.2153  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 810/1627]  eta: 0:02:55  Loss: 2.4113 (2.4513)  Acc@1: 87.5000 (81.4273)  Acc@5: 100.0000 (96.4704)  time: 0.2153  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 820/1627]  eta: 0:02:52  Loss: 2.4162 (2.4510)  Acc@1: 87.5000 (81.4860)  Acc@5: 100.0000 (96.5058)  time: 0.2151  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 830/1627]  eta: 0:02:50  Loss: 2.4284 (2.4517)  Acc@1: 81.2500 (81.4230)  Acc@5: 100.0000 (96.4877)  time: 0.2150  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 840/1627]  eta: 0:02:48  Loss: 2.3809 (2.4506)  Acc@1: 87.5000 (81.4952)  Acc@5: 100.0000 (96.5071)  time: 0.2148  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 850/1627]  eta: 0:02:46  Loss: 2.4268 (2.4509)  Acc@1: 87.5000 (81.4777)  Acc@5: 100.0000 (96.5115)  time: 0.2144  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 860/1627]  eta: 0:02:44  Loss: 2.4649 (2.4511)  Acc@1: 81.2500 (81.5041)  Acc@5: 100.0000 (96.5302)  time: 0.2154  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 870/1627]  eta: 0:02:42  Loss: 2.3700 (2.4499)  Acc@1: 87.5000 (81.5801)  Acc@5: 100.0000 (96.5485)  time: 0.2159  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 880/1627]  eta: 0:02:40  Loss: 2.4060 (2.4510)  Acc@1: 81.2500 (81.5409)  Acc@5: 100.0000 (96.5309)  time: 0.2151  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 890/1627]  eta: 0:02:37  Loss: 2.4927 (2.4514)  Acc@1: 81.2500 (81.5236)  Acc@5: 93.7500 (96.5067)  time: 0.2146  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 900/1627]  eta: 0:02:35  Loss: 2.4495 (2.4521)  Acc@1: 81.2500 (81.5136)  Acc@5: 100.0000 (96.4831)  time: 0.2148  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 910/1627]  eta: 0:02:33  Loss: 2.4717 (2.4528)  Acc@1: 81.2500 (81.4627)  Acc@5: 100.0000 (96.4531)  time: 0.2153  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 920/1627]  eta: 0:02:31  Loss: 2.4587 (2.4526)  Acc@1: 81.2500 (81.4739)  Acc@5: 100.0000 (96.4509)  time: 0.2153  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 930/1627]  eta: 0:02:29  Loss: 2.4029 (2.4519)  Acc@1: 81.2500 (81.5118)  Acc@5: 93.7500 (96.4487)  time: 0.2152  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 940/1627]  eta: 0:02:27  Loss: 2.3763 (2.4507)  Acc@1: 81.2500 (81.5622)  Acc@5: 100.0000 (96.4865)  time: 0.2154  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 950/1627]  eta: 0:02:25  Loss: 2.3904 (2.4504)  Acc@1: 81.2500 (81.5457)  Acc@5: 100.0000 (96.5037)  time: 0.2152  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 960/1627]  eta: 0:02:22  Loss: 2.4233 (2.4505)  Acc@1: 81.2500 (81.5687)  Acc@5: 100.0000 (96.5075)  time: 0.2152  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 970/1627]  eta: 0:02:20  Loss: 2.4639 (2.4507)  Acc@1: 81.2500 (81.5783)  Acc@5: 100.0000 (96.5049)  time: 0.2152  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 980/1627]  eta: 0:02:18  Loss: 2.3924 (2.4504)  Acc@1: 87.5000 (81.5877)  Acc@5: 93.7500 (96.4959)  time: 0.2151  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 990/1627]  eta: 0:02:16  Loss: 2.4888 (2.4518)  Acc@1: 81.2500 (81.5464)  Acc@5: 93.7500 (96.4682)  time: 0.2156  data: 0.0004  max mem: 2500
Test: [Task 1]  [1000/1627]  eta: 0:02:14  Loss: 2.5366 (2.4520)  Acc@1: 81.2500 (81.5247)  Acc@5: 93.7500 (96.4723)  time: 0.2152  data: 0.0003  max mem: 2500
Test: [Task 1]  [1010/1627]  eta: 0:02:12  Loss: 2.3760 (2.4519)  Acc@1: 81.2500 (81.5467)  Acc@5: 93.7500 (96.4639)  time: 0.2145  data: 0.0003  max mem: 2500
Test: [Task 1]  [1020/1627]  eta: 0:02:10  Loss: 2.4068 (2.4519)  Acc@1: 81.2500 (81.5500)  Acc@5: 100.0000 (96.4863)  time: 0.2146  data: 0.0003  max mem: 2500
Test: [Task 1]  [1030/1627]  eta: 0:02:08  Loss: 2.3885 (2.4514)  Acc@1: 81.2500 (81.5713)  Acc@5: 100.0000 (96.4901)  time: 0.2146  data: 0.0003  max mem: 2500
Test: [Task 1]  [1040/1627]  eta: 0:02:05  Loss: 2.3775 (2.4507)  Acc@1: 81.2500 (81.5802)  Acc@5: 100.0000 (96.4998)  time: 0.2150  data: 0.0003  max mem: 2500
Test: [Task 1]  [1050/1627]  eta: 0:02:03  Loss: 2.4279 (2.4502)  Acc@1: 81.2500 (81.6009)  Acc@5: 100.0000 (96.5212)  time: 0.2149  data: 0.0002  max mem: 2500
Test: [Task 1]  [1060/1627]  eta: 0:02:01  Loss: 2.4648 (2.4507)  Acc@1: 81.2500 (81.5681)  Acc@5: 100.0000 (96.5068)  time: 0.2145  data: 0.0003  max mem: 2500
Test: [Task 1]  [1070/1627]  eta: 0:01:59  Loss: 2.4657 (2.4506)  Acc@1: 81.2500 (81.5768)  Acc@5: 93.7500 (96.4986)  time: 0.2145  data: 0.0003  max mem: 2500
Test: [Task 1]  [1080/1627]  eta: 0:01:57  Loss: 2.3901 (2.4507)  Acc@1: 81.2500 (81.5738)  Acc@5: 100.0000 (96.4963)  time: 0.2142  data: 0.0003  max mem: 2500
Test: [Task 1]  [1090/1627]  eta: 0:01:55  Loss: 2.4094 (2.4510)  Acc@1: 81.2500 (81.5536)  Acc@5: 100.0000 (96.4940)  time: 0.2144  data: 0.0003  max mem: 2500
Test: [Task 1]  [1100/1627]  eta: 0:01:52  Loss: 2.3871 (2.4503)  Acc@1: 81.2500 (81.6076)  Acc@5: 100.0000 (96.5145)  time: 0.2140  data: 0.0002  max mem: 2500
Test: [Task 1]  [1110/1627]  eta: 0:01:50  Loss: 2.3987 (2.4501)  Acc@1: 81.2500 (81.5932)  Acc@5: 100.0000 (96.5347)  time: 0.2135  data: 0.0002  max mem: 2500
Test: [Task 1]  [1120/1627]  eta: 0:01:48  Loss: 2.4701 (2.4507)  Acc@1: 75.0000 (81.5566)  Acc@5: 100.0000 (96.5210)  time: 0.2133  data: 0.0002  max mem: 2500
Test: [Task 1]  [1130/1627]  eta: 0:01:46  Loss: 2.4593 (2.4510)  Acc@1: 75.0000 (81.5429)  Acc@5: 100.0000 (96.5241)  time: 0.2133  data: 0.0002  max mem: 2500
Test: [Task 1]  [1140/1627]  eta: 0:01:44  Loss: 2.4593 (2.4515)  Acc@1: 81.2500 (81.5239)  Acc@5: 100.0000 (96.5217)  time: 0.2134  data: 0.0002  max mem: 2500
Test: [Task 1]  [1150/1627]  eta: 0:01:42  Loss: 2.4871 (2.4516)  Acc@1: 81.2500 (81.5324)  Acc@5: 100.0000 (96.5030)  time: 0.2131  data: 0.0002  max mem: 2500
Test: [Task 1]  [1160/1627]  eta: 0:01:40  Loss: 2.4128 (2.4514)  Acc@1: 81.2500 (81.5676)  Acc@5: 100.0000 (96.5062)  time: 0.2132  data: 0.0002  max mem: 2500
Test: [Task 1]  [1170/1627]  eta: 0:01:37  Loss: 2.3861 (2.4514)  Acc@1: 81.2500 (81.5756)  Acc@5: 100.0000 (96.5201)  time: 0.2134  data: 0.0002  max mem: 2500
Test: [Task 1]  [1180/1627]  eta: 0:01:35  Loss: 2.4596 (2.4516)  Acc@1: 81.2500 (81.5622)  Acc@5: 100.0000 (96.5284)  time: 0.2133  data: 0.0002  max mem: 2500
Test: [Task 1]  [1190/1627]  eta: 0:01:33  Loss: 2.4807 (2.4518)  Acc@1: 81.2500 (81.5491)  Acc@5: 100.0000 (96.5418)  time: 0.2137  data: 0.0003  max mem: 2500
Test: [Task 1]  [1200/1627]  eta: 0:01:31  Loss: 2.4755 (2.4516)  Acc@1: 81.2500 (81.5570)  Acc@5: 100.0000 (96.5341)  time: 0.2143  data: 0.0004  max mem: 2500
Test: [Task 1]  [1210/1627]  eta: 0:01:29  Loss: 2.4574 (2.4526)  Acc@1: 81.2500 (81.5184)  Acc@5: 93.7500 (96.5060)  time: 0.2145  data: 0.0004  max mem: 2500
Test: [Task 1]  [1220/1627]  eta: 0:01:27  Loss: 2.4799 (2.4525)  Acc@1: 81.2500 (81.5162)  Acc@5: 93.7500 (96.5090)  time: 0.2141  data: 0.0003  max mem: 2500
Test: [Task 1]  [1230/1627]  eta: 0:01:25  Loss: 2.4799 (2.4530)  Acc@1: 81.2500 (81.4734)  Acc@5: 93.7500 (96.5018)  time: 0.2139  data: 0.0003  max mem: 2500
Test: [Task 1]  [1240/1627]  eta: 0:01:22  Loss: 2.4493 (2.4530)  Acc@1: 81.2500 (81.4565)  Acc@5: 100.0000 (96.5099)  time: 0.2140  data: 0.0003  max mem: 2500
Test: [Task 1]  [1250/1627]  eta: 0:01:20  Loss: 2.4493 (2.4532)  Acc@1: 81.2500 (81.4648)  Acc@5: 100.0000 (96.4978)  time: 0.2137  data: 0.0003  max mem: 2500
Test: [Task 1]  [1260/1627]  eta: 0:01:18  Loss: 2.4314 (2.4532)  Acc@1: 87.5000 (81.4681)  Acc@5: 93.7500 (96.4958)  time: 0.2136  data: 0.0003  max mem: 2500
Test: [Task 1]  [1270/1627]  eta: 0:01:16  Loss: 2.4309 (2.4533)  Acc@1: 81.2500 (81.4319)  Acc@5: 100.0000 (96.5136)  time: 0.2138  data: 0.0003  max mem: 2500
Test: [Task 1]  [1280/1627]  eta: 0:01:14  Loss: 2.4309 (2.4529)  Acc@1: 81.2500 (81.4305)  Acc@5: 100.0000 (96.5115)  time: 0.2137  data: 0.0003  max mem: 2500
Test: [Task 1]  [1290/1627]  eta: 0:01:12  Loss: 2.4429 (2.4533)  Acc@1: 81.2500 (81.4194)  Acc@5: 100.0000 (96.5046)  time: 0.2141  data: 0.0003  max mem: 2500
Test: [Task 1]  [1300/1627]  eta: 0:01:10  Loss: 2.4429 (2.4527)  Acc@1: 81.2500 (81.4614)  Acc@5: 93.7500 (96.5075)  time: 0.2146  data: 0.0004  max mem: 2500
Test: [Task 1]  [1310/1627]  eta: 0:01:07  Loss: 2.3444 (2.4522)  Acc@1: 81.2500 (81.4788)  Acc@5: 93.7500 (96.5008)  time: 0.2145  data: 0.0004  max mem: 2500
Test: [Task 1]  [1320/1627]  eta: 0:01:05  Loss: 2.3723 (2.4515)  Acc@1: 81.2500 (81.5102)  Acc@5: 100.0000 (96.5225)  time: 0.2144  data: 0.0003  max mem: 2500
Test: [Task 1]  [1330/1627]  eta: 0:01:03  Loss: 2.4241 (2.4517)  Acc@1: 81.2500 (81.4942)  Acc@5: 100.0000 (96.5111)  time: 0.2138  data: 0.0003  max mem: 2500
Test: [Task 1]  [1340/1627]  eta: 0:01:01  Loss: 2.4641 (2.4520)  Acc@1: 81.2500 (81.4597)  Acc@5: 93.7500 (96.5045)  time: 0.2140  data: 0.0003  max mem: 2500
Test: [Task 1]  [1350/1627]  eta: 0:00:59  Loss: 2.4423 (2.4520)  Acc@1: 81.2500 (81.4906)  Acc@5: 100.0000 (96.5165)  time: 0.2142  data: 0.0003  max mem: 2500
Test: [Task 1]  [1360/1627]  eta: 0:00:57  Loss: 2.4102 (2.4519)  Acc@1: 87.5000 (81.5072)  Acc@5: 100.0000 (96.5145)  time: 0.2141  data: 0.0003  max mem: 2500
Test: [Task 1]  [1370/1627]  eta: 0:00:55  Loss: 2.3771 (2.4516)  Acc@1: 87.5000 (81.5235)  Acc@5: 93.7500 (96.5126)  time: 0.2140  data: 0.0003  max mem: 2500
Test: [Task 1]  [1380/1627]  eta: 0:00:52  Loss: 2.3771 (2.4513)  Acc@1: 87.5000 (81.5306)  Acc@5: 100.0000 (96.5197)  time: 0.2137  data: 0.0003  max mem: 2500
Test: [Task 1]  [1390/1627]  eta: 0:00:50  Loss: 2.4175 (2.4514)  Acc@1: 81.2500 (81.5196)  Acc@5: 100.0000 (96.5088)  time: 0.2139  data: 0.0003  max mem: 2500
Test: [Task 1]  [1400/1627]  eta: 0:00:48  Loss: 2.4182 (2.4516)  Acc@1: 81.2500 (81.4909)  Acc@5: 93.7500 (96.5025)  time: 0.2139  data: 0.0002  max mem: 2500
Test: [Task 1]  [1410/1627]  eta: 0:00:46  Loss: 2.3744 (2.4513)  Acc@1: 81.2500 (81.4715)  Acc@5: 100.0000 (96.5184)  time: 0.2144  data: 0.0002  max mem: 2500
Test: [Task 1]  [1420/1627]  eta: 0:00:44  Loss: 2.4154 (2.4510)  Acc@1: 81.2500 (81.4919)  Acc@5: 100.0000 (96.5209)  time: 0.2141  data: 0.0002  max mem: 2500
Test: [Task 1]  [1430/1627]  eta: 0:00:42  Loss: 2.5056 (2.4519)  Acc@1: 75.0000 (81.4378)  Acc@5: 93.7500 (96.4928)  time: 0.2130  data: 0.0002  max mem: 2500
Test: [Task 1]  [1440/1627]  eta: 0:00:40  Loss: 2.5056 (2.4520)  Acc@1: 75.0000 (81.4148)  Acc@5: 93.7500 (96.4781)  time: 0.2131  data: 0.0002  max mem: 2500
Test: [Task 1]  [1450/1627]  eta: 0:00:37  Loss: 2.5122 (2.4525)  Acc@1: 81.2500 (81.3921)  Acc@5: 100.0000 (96.4809)  time: 0.2130  data: 0.0002  max mem: 2500
Test: [Task 1]  [1460/1627]  eta: 0:00:35  Loss: 2.5119 (2.4525)  Acc@1: 81.2500 (81.3698)  Acc@5: 100.0000 (96.4793)  time: 0.2129  data: 0.0002  max mem: 2500
Test: [Task 1]  [1470/1627]  eta: 0:00:33  Loss: 2.3918 (2.4527)  Acc@1: 81.2500 (81.3605)  Acc@5: 100.0000 (96.4820)  time: 0.2131  data: 0.0002  max mem: 2500
Test: [Task 1]  [1480/1627]  eta: 0:00:31  Loss: 2.3694 (2.4526)  Acc@1: 81.2500 (81.3724)  Acc@5: 100.0000 (96.4889)  time: 0.2133  data: 0.0002  max mem: 2500
Test: [Task 1]  [1490/1627]  eta: 0:00:29  Loss: 2.4132 (2.4529)  Acc@1: 81.2500 (81.3716)  Acc@5: 100.0000 (96.4831)  time: 0.2132  data: 0.0002  max mem: 2500
Test: [Task 1]  [1500/1627]  eta: 0:00:27  Loss: 2.4453 (2.4532)  Acc@1: 81.2500 (81.3666)  Acc@5: 93.7500 (96.4690)  time: 0.2133  data: 0.0002  max mem: 2500
Test: [Task 1]  [1510/1627]  eta: 0:00:25  Loss: 2.4303 (2.4530)  Acc@1: 81.2500 (81.3906)  Acc@5: 93.7500 (96.4593)  time: 0.2140  data: 0.0003  max mem: 2500
Test: [Task 1]  [1520/1627]  eta: 0:00:22  Loss: 2.3964 (2.4525)  Acc@1: 81.2500 (81.4061)  Acc@5: 100.0000 (96.4620)  time: 0.2147  data: 0.0004  max mem: 2500
Test: [Task 1]  [1530/1627]  eta: 0:00:20  Loss: 2.3763 (2.4522)  Acc@1: 87.5000 (81.4337)  Acc@5: 100.0000 (96.4688)  time: 0.2142  data: 0.0003  max mem: 2500
Test: [Task 1]  [1540/1627]  eta: 0:00:18  Loss: 2.3489 (2.4519)  Acc@1: 93.7500 (81.4650)  Acc@5: 100.0000 (96.4836)  time: 0.2136  data: 0.0003  max mem: 2500
Test: [Task 1]  [1550/1627]  eta: 0:00:16  Loss: 2.4004 (2.4519)  Acc@1: 87.5000 (81.4676)  Acc@5: 100.0000 (96.4821)  time: 0.2146  data: 0.0004  max mem: 2500
Test: [Task 1]  [1560/1627]  eta: 0:00:14  Loss: 2.4103 (2.4514)  Acc@1: 81.2500 (81.4862)  Acc@5: 100.0000 (96.4846)  time: 0.2147  data: 0.0004  max mem: 2500
Test: [Task 1]  [1570/1627]  eta: 0:00:12  Loss: 2.4103 (2.4516)  Acc@1: 81.2500 (81.4927)  Acc@5: 100.0000 (96.4911)  time: 0.2139  data: 0.0003  max mem: 2500
Test: [Task 1]  [1580/1627]  eta: 0:00:10  Loss: 2.4116 (2.4513)  Acc@1: 81.2500 (81.4753)  Acc@5: 100.0000 (96.4896)  time: 0.2140  data: 0.0003  max mem: 2500
Test: [Task 1]  [1590/1627]  eta: 0:00:07  Loss: 2.4256 (2.4514)  Acc@1: 75.0000 (81.4661)  Acc@5: 100.0000 (96.4959)  time: 0.2141  data: 0.0003  max mem: 2500
Test: [Task 1]  [1600/1627]  eta: 0:00:05  Loss: 2.4609 (2.4521)  Acc@1: 75.0000 (81.4374)  Acc@5: 93.7500 (96.4788)  time: 0.2142  data: 0.0003  max mem: 2500
Test: [Task 1]  [1610/1627]  eta: 0:00:03  Loss: 2.4488 (2.4517)  Acc@1: 81.2500 (81.4711)  Acc@5: 100.0000 (96.4929)  time: 0.2142  data: 0.0003  max mem: 2500
Test: [Task 1]  [1620/1627]  eta: 0:00:01  Loss: 2.4235 (2.4516)  Acc@1: 87.5000 (81.4852)  Acc@5: 100.0000 (96.4914)  time: 0.2142  data: 0.0003  max mem: 2500
Test: [Task 1]  [1626/1627]  eta: 0:00:00  Loss: 2.4235 (2.4513)  Acc@1: 87.5000 (81.4959)  Acc@5: 100.0000 (96.4966)  time: 0.2142  data: 0.0002  max mem: 2500
Test: [Task 1] Total time: 0:05:48 (0.2144 s / it)
* Acc@1 81.496 Acc@5 96.497 loss 2.451
Test: [Task 2]  [  0/625]  eta: 0:05:35  Loss: 1.8539 (1.8539)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)  time: 0.5363  data: 0.3225  max mem: 2500
Test: [Task 2]  [ 10/625]  eta: 0:02:29  Loss: 2.0367 (2.0633)  Acc@1: 93.7500 (93.7500)  Acc@5: 100.0000 (97.7273)  time: 0.2437  data: 0.0296  max mem: 2500
Test: [Task 2]  [ 20/625]  eta: 0:02:18  Loss: 2.0334 (2.0533)  Acc@1: 93.7500 (94.3452)  Acc@5: 100.0000 (98.8095)  time: 0.2144  data: 0.0003  max mem: 2500
Test: [Task 2]  [ 30/625]  eta: 0:02:13  Loss: 2.0144 (2.0507)  Acc@1: 93.7500 (94.1532)  Acc@5: 100.0000 (98.9919)  time: 0.2141  data: 0.0002  max mem: 2500
Test: [Task 2]  [ 40/625]  eta: 0:02:09  Loss: 2.0529 (2.0598)  Acc@1: 93.7500 (93.4451)  Acc@5: 100.0000 (99.2378)  time: 0.2142  data: 0.0002  max mem: 2500
Test: [Task 2]  [ 50/625]  eta: 0:02:06  Loss: 2.0553 (2.0709)  Acc@1: 93.7500 (92.8922)  Acc@5: 100.0000 (99.1422)  time: 0.2144  data: 0.0002  max mem: 2500
Test: [Task 2]  [ 60/625]  eta: 0:02:04  Loss: 2.0553 (2.0697)  Acc@1: 93.7500 (92.9303)  Acc@5: 100.0000 (99.0779)  time: 0.2148  data: 0.0003  max mem: 2500
Test: [Task 2]  [ 70/625]  eta: 0:02:01  Loss: 2.0429 (2.0730)  Acc@1: 93.7500 (92.6056)  Acc@5: 100.0000 (99.1197)  time: 0.2146  data: 0.0003  max mem: 2500
Test: [Task 2]  [ 80/625]  eta: 0:01:59  Loss: 2.1008 (2.0771)  Acc@1: 87.5000 (92.2840)  Acc@5: 100.0000 (98.7654)  time: 0.2144  data: 0.0003  max mem: 2500
Test: [Task 2]  [ 90/625]  eta: 0:01:56  Loss: 2.1322 (2.0803)  Acc@1: 87.5000 (92.1016)  Acc@5: 100.0000 (98.9011)  time: 0.2143  data: 0.0002  max mem: 2500
Test: [Task 2]  [100/625]  eta: 0:01:54  Loss: 2.1050 (2.0834)  Acc@1: 93.7500 (92.1411)  Acc@5: 100.0000 (98.8243)  time: 0.2144  data: 0.0002  max mem: 2500
Test: [Task 2]  [110/625]  eta: 0:01:51  Loss: 2.0814 (2.0823)  Acc@1: 93.7500 (92.1171)  Acc@5: 100.0000 (98.8176)  time: 0.2144  data: 0.0002  max mem: 2500
Test: [Task 2]  [120/625]  eta: 0:01:49  Loss: 2.0317 (2.0839)  Acc@1: 87.5000 (91.7872)  Acc@5: 100.0000 (98.8636)  time: 0.2139  data: 0.0002  max mem: 2500
Test: [Task 2]  [130/625]  eta: 0:01:47  Loss: 2.1014 (2.0849)  Acc@1: 87.5000 (91.8893)  Acc@5: 100.0000 (98.9027)  time: 0.2137  data: 0.0002  max mem: 2500
Test: [Task 2]  [140/625]  eta: 0:01:45  Loss: 2.1014 (2.0857)  Acc@1: 93.7500 (91.8883)  Acc@5: 100.0000 (98.7589)  time: 0.2136  data: 0.0002  max mem: 2500
Test: [Task 2]  [150/625]  eta: 0:01:42  Loss: 2.0709 (2.0881)  Acc@1: 87.5000 (91.7632)  Acc@5: 100.0000 (98.6755)  time: 0.2138  data: 0.0002  max mem: 2500
Test: [Task 2]  [160/625]  eta: 0:01:40  Loss: 2.0709 (2.0892)  Acc@1: 87.5000 (91.8090)  Acc@5: 100.0000 (98.6801)  time: 0.2139  data: 0.0002  max mem: 2500
Test: [Task 2]  [170/625]  eta: 0:01:38  Loss: 2.0971 (2.0886)  Acc@1: 93.7500 (91.8494)  Acc@5: 100.0000 (98.6477)  time: 0.2143  data: 0.0002  max mem: 2500
Test: [Task 2]  [180/625]  eta: 0:01:36  Loss: 2.0625 (2.0884)  Acc@1: 93.7500 (91.8508)  Acc@5: 100.0000 (98.6878)  time: 0.2145  data: 0.0003  max mem: 2500
Test: [Task 2]  [190/625]  eta: 0:01:33  Loss: 2.0544 (2.0879)  Acc@1: 93.7500 (91.9175)  Acc@5: 100.0000 (98.7238)  time: 0.2148  data: 0.0003  max mem: 2500
Test: [Task 2]  [200/625]  eta: 0:01:31  Loss: 2.0709 (2.0891)  Acc@1: 93.7500 (91.9154)  Acc@5: 100.0000 (98.6940)  time: 0.2150  data: 0.0003  max mem: 2500
Test: [Task 2]  [210/625]  eta: 0:01:29  Loss: 2.0363 (2.0885)  Acc@1: 93.7500 (91.8839)  Acc@5: 100.0000 (98.6374)  time: 0.2145  data: 0.0003  max mem: 2500
Test: [Task 2]  [220/625]  eta: 0:01:27  Loss: 2.0281 (2.0875)  Acc@1: 93.7500 (91.9966)  Acc@5: 100.0000 (98.6425)  time: 0.2150  data: 0.0003  max mem: 2500
Test: [Task 2]  [230/625]  eta: 0:01:25  Loss: 2.0301 (2.0866)  Acc@1: 93.7500 (92.0455)  Acc@5: 100.0000 (98.6742)  time: 0.2157  data: 0.0004  max mem: 2500
Test: [Task 2]  [240/625]  eta: 0:01:23  Loss: 2.0592 (2.0871)  Acc@1: 93.7500 (91.9865)  Acc@5: 100.0000 (98.7033)  time: 0.2152  data: 0.0003  max mem: 2500
Test: [Task 2]  [250/625]  eta: 0:01:20  Loss: 2.0940 (2.0879)  Acc@1: 93.7500 (91.9572)  Acc@5: 100.0000 (98.6305)  time: 0.2153  data: 0.0003  max mem: 2500
Test: [Task 2]  [260/625]  eta: 0:01:18  Loss: 2.0825 (2.0876)  Acc@1: 93.7500 (91.9780)  Acc@5: 100.0000 (98.6351)  time: 0.2152  data: 0.0003  max mem: 2500
Test: [Task 2]  [270/625]  eta: 0:01:16  Loss: 2.0799 (2.0884)  Acc@1: 93.7500 (91.9050)  Acc@5: 100.0000 (98.6162)  time: 0.2146  data: 0.0003  max mem: 2500
Test: [Task 2]  [280/625]  eta: 0:01:14  Loss: 2.0858 (2.0885)  Acc@1: 93.7500 (91.9262)  Acc@5: 100.0000 (98.6210)  time: 0.2145  data: 0.0003  max mem: 2500
Test: [Task 2]  [290/625]  eta: 0:01:12  Loss: 2.0858 (2.0888)  Acc@1: 93.7500 (91.8814)  Acc@5: 100.0000 (98.6254)  time: 0.2146  data: 0.0003  max mem: 2500
Test: [Task 2]  [300/625]  eta: 0:01:10  Loss: 2.0782 (2.0890)  Acc@1: 93.7500 (91.7982)  Acc@5: 100.0000 (98.6296)  time: 0.2147  data: 0.0003  max mem: 2500
Test: [Task 2]  [310/625]  eta: 0:01:07  Loss: 2.0395 (2.0880)  Acc@1: 93.7500 (91.8609)  Acc@5: 100.0000 (98.6133)  time: 0.2147  data: 0.0003  max mem: 2500
Test: [Task 2]  [320/625]  eta: 0:01:05  Loss: 1.9933 (2.0826)  Acc@1: 100.0000 (92.0950)  Acc@5: 100.0000 (98.6565)  time: 0.2147  data: 0.0003  max mem: 2500
Test: [Task 2]  [330/625]  eta: 0:01:03  Loss: 1.9438 (2.0800)  Acc@1: 100.0000 (92.2394)  Acc@5: 100.0000 (98.6782)  time: 0.2146  data: 0.0003  max mem: 2500
Test: [Task 2]  [340/625]  eta: 0:01:01  Loss: 1.9244 (2.0749)  Acc@1: 100.0000 (92.4487)  Acc@5: 100.0000 (98.7170)  time: 0.2147  data: 0.0003  max mem: 2500
Test: [Task 2]  [350/625]  eta: 0:00:59  Loss: 1.9059 (2.0715)  Acc@1: 100.0000 (92.5748)  Acc@5: 100.0000 (98.7358)  time: 0.2152  data: 0.0003  max mem: 2500
Test: [Task 2]  [360/625]  eta: 0:00:57  Loss: 2.0257 (2.0726)  Acc@1: 93.7500 (92.5554)  Acc@5: 100.0000 (98.7015)  time: 0.2146  data: 0.0003  max mem: 2500
Test: [Task 2]  [370/625]  eta: 0:00:54  Loss: 2.0375 (2.0711)  Acc@1: 93.7500 (92.5876)  Acc@5: 100.0000 (98.7365)  time: 0.2137  data: 0.0002  max mem: 2500
Test: [Task 2]  [380/625]  eta: 0:00:52  Loss: 2.0411 (2.0724)  Acc@1: 93.7500 (92.5197)  Acc@5: 100.0000 (98.7205)  time: 0.2137  data: 0.0002  max mem: 2500
Test: [Task 2]  [390/625]  eta: 0:00:50  Loss: 2.0411 (2.0718)  Acc@1: 93.7500 (92.5192)  Acc@5: 100.0000 (98.6093)  time: 0.2135  data: 0.0002  max mem: 2500
Test: [Task 2]  [400/625]  eta: 0:00:48  Loss: 1.9101 (2.0682)  Acc@1: 100.0000 (92.6901)  Acc@5: 100.0000 (98.6284)  time: 0.2133  data: 0.0002  max mem: 2500
Test: [Task 2]  [410/625]  eta: 0:00:46  Loss: 1.9029 (2.0657)  Acc@1: 100.0000 (92.7920)  Acc@5: 100.0000 (98.6466)  time: 0.2133  data: 0.0002  max mem: 2500
Test: [Task 2]  [420/625]  eta: 0:00:44  Loss: 1.9283 (2.0640)  Acc@1: 100.0000 (92.9186)  Acc@5: 100.0000 (98.6639)  time: 0.2135  data: 0.0002  max mem: 2500
Test: [Task 2]  [430/625]  eta: 0:00:41  Loss: 1.9865 (2.0623)  Acc@1: 100.0000 (92.9959)  Acc@5: 100.0000 (98.6804)  time: 0.2130  data: 0.0002  max mem: 2500
Test: [Task 2]  [440/625]  eta: 0:00:39  Loss: 1.9062 (2.0584)  Acc@1: 100.0000 (93.1548)  Acc@5: 100.0000 (98.7103)  time: 0.2130  data: 0.0002  max mem: 2500
Test: [Task 2]  [450/625]  eta: 0:00:37  Loss: 1.8898 (2.0559)  Acc@1: 100.0000 (93.2373)  Acc@5: 100.0000 (98.7389)  time: 0.2135  data: 0.0002  max mem: 2500
Test: [Task 2]  [460/625]  eta: 0:00:35  Loss: 1.9112 (2.0540)  Acc@1: 100.0000 (93.3026)  Acc@5: 100.0000 (98.7663)  time: 0.2135  data: 0.0002  max mem: 2500
Test: [Task 2]  [470/625]  eta: 0:00:33  Loss: 1.9628 (2.0529)  Acc@1: 100.0000 (93.3652)  Acc@5: 100.0000 (98.7659)  time: 0.2131  data: 0.0002  max mem: 2500
Test: [Task 2]  [480/625]  eta: 0:00:31  Loss: 1.9687 (2.0512)  Acc@1: 100.0000 (93.4511)  Acc@5: 100.0000 (98.7916)  time: 0.2131  data: 0.0002  max mem: 2500
Test: [Task 2]  [490/625]  eta: 0:00:29  Loss: 1.9464 (2.0493)  Acc@1: 100.0000 (93.5336)  Acc@5: 100.0000 (98.8162)  time: 0.2132  data: 0.0002  max mem: 2500
Test: [Task 2]  [500/625]  eta: 0:00:26  Loss: 1.9491 (2.0479)  Acc@1: 100.0000 (93.6252)  Acc@5: 100.0000 (98.8398)  time: 0.2138  data: 0.0003  max mem: 2500
Test: [Task 2]  [510/625]  eta: 0:00:24  Loss: 1.9883 (2.0476)  Acc@1: 100.0000 (93.6399)  Acc@5: 100.0000 (98.8503)  time: 0.2145  data: 0.0003  max mem: 2500
Test: [Task 2]  [520/625]  eta: 0:00:22  Loss: 1.9951 (2.0471)  Acc@1: 93.7500 (93.6780)  Acc@5: 100.0000 (98.8604)  time: 0.2144  data: 0.0003  max mem: 2500
Test: [Task 2]  [530/625]  eta: 0:00:20  Loss: 1.9471 (2.0448)  Acc@1: 100.0000 (93.7971)  Acc@5: 100.0000 (98.8818)  time: 0.2140  data: 0.0003  max mem: 2500
Test: [Task 2]  [540/625]  eta: 0:00:18  Loss: 1.9066 (2.0427)  Acc@1: 100.0000 (93.8886)  Acc@5: 100.0000 (98.8909)  time: 0.2142  data: 0.0003  max mem: 2500
Test: [Task 2]  [550/625]  eta: 0:00:16  Loss: 1.9045 (2.0402)  Acc@1: 100.0000 (93.9882)  Acc@5: 100.0000 (98.9111)  time: 0.2143  data: 0.0003  max mem: 2500
Test: [Task 2]  [560/625]  eta: 0:00:13  Loss: 1.8972 (2.0377)  Acc@1: 100.0000 (94.0954)  Acc@5: 100.0000 (98.9305)  time: 0.2138  data: 0.0003  max mem: 2500
Test: [Task 2]  [570/625]  eta: 0:00:11  Loss: 1.9107 (2.0377)  Acc@1: 100.0000 (94.0784)  Acc@5: 100.0000 (98.9492)  time: 0.2137  data: 0.0003  max mem: 2500
Test: [Task 2]  [580/625]  eta: 0:00:09  Loss: 1.9232 (2.0357)  Acc@1: 100.0000 (94.1695)  Acc@5: 100.0000 (98.9673)  time: 0.2141  data: 0.0003  max mem: 2500
Test: [Task 2]  [590/625]  eta: 0:00:07  Loss: 1.9156 (2.0337)  Acc@1: 100.0000 (94.2365)  Acc@5: 100.0000 (98.9848)  time: 0.2143  data: 0.0003  max mem: 2500
Test: [Task 2]  [600/625]  eta: 0:00:05  Loss: 1.9434 (2.0330)  Acc@1: 100.0000 (94.2908)  Acc@5: 100.0000 (99.0017)  time: 0.2143  data: 0.0004  max mem: 2500
Test: [Task 2]  [610/625]  eta: 0:00:03  Loss: 2.0062 (2.0338)  Acc@1: 93.7500 (94.2717)  Acc@5: 100.0000 (99.0078)  time: 0.2147  data: 0.0004  max mem: 2500
Test: [Task 2]  [620/625]  eta: 0:00:01  Loss: 2.0055 (2.0329)  Acc@1: 93.7500 (94.3136)  Acc@5: 100.0000 (99.0238)  time: 0.2141  data: 0.0003  max mem: 2500
Test: [Task 2]  [624/625]  eta: 0:00:00  Loss: 1.9709 (2.0324)  Acc@1: 100.0000 (94.3400)  Acc@5: 100.0000 (99.0300)  time: 0.2137  data: 0.0003  max mem: 2500
Test: [Task 2] Total time: 0:02:14 (0.2149 s / it)
* Acc@1 94.340 Acc@5 99.030 loss 2.032
{0: {0: 26032, 1: 26032, 2: 26032, 3: 26032, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0, 10: 0, 11: 0, 12: 0, 13: 0, 14: 0, 15: 0, 16: 0, 17: 0, 18: 0, 19: 0}, 1: {0: 0, 1: 0, 2: 0, 3: 0, 4: 10000, 5: 10000, 6: 10000, 7: 10000, 8: 0, 9: 0, 10: 0, 11: 0, 12: 0, 13: 0, 14: 0, 15: 0, 16: 0, 17: 0, 18: 0, 19: 0}}
[Average accuracy till task2]	Acc@1: 87.9179	Acc@5: 97.7633	Loss: 2.2418	Forgetting: 0.0000	Backward: 0.0000
Train: Epoch[1/5]  [   0/3125]  eta: 0:43:00  Lr: 0.030000  Loss: 2.2953  Acc@1: 12.5000 (12.5000)  Acc@5: 43.7500 (43.7500)  time: 0.8258  data: 0.4638  max mem: 2500
Train: Epoch[1/5]  [  10/3125]  eta: 0:20:08  Lr: 0.030000  Loss: 1.9701  Acc@1: 6.2500 (9.0909)  Acc@5: 50.0000 (51.1364)  time: 0.3880  data: 0.0424  max mem: 2500
Train: Epoch[1/5]  [  20/3125]  eta: 0:19:04  Lr: 0.030000  Loss: 1.7359  Acc@1: 6.2500 (9.2262)  Acc@5: 50.0000 (51.1905)  time: 0.3456  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [  30/3125]  eta: 0:18:37  Lr: 0.030000  Loss: 1.6075  Acc@1: 12.5000 (12.2984)  Acc@5: 50.0000 (53.2258)  time: 0.3462  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [  40/3125]  eta: 0:18:22  Lr: 0.030000  Loss: 1.4731  Acc@1: 18.7500 (13.5671)  Acc@5: 62.5000 (55.7927)  time: 0.3454  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [  50/3125]  eta: 0:18:10  Lr: 0.030000  Loss: 1.4451  Acc@1: 18.7500 (13.8480)  Acc@5: 62.5000 (56.3725)  time: 0.3450  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [  60/3125]  eta: 0:18:07  Lr: 0.030000  Loss: 1.3874  Acc@1: 18.7500 (15.0615)  Acc@5: 62.5000 (58.0943)  time: 0.3503  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [  70/3125]  eta: 0:17:59  Lr: 0.030000  Loss: 1.3651  Acc@1: 18.7500 (15.8451)  Acc@5: 62.5000 (59.4190)  time: 0.3501  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [  80/3125]  eta: 0:17:52  Lr: 0.030000  Loss: 1.3890  Acc@1: 18.7500 (16.3580)  Acc@5: 68.7500 (60.4938)  time: 0.3440  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [  90/3125]  eta: 0:17:46  Lr: 0.030000  Loss: 1.2977  Acc@1: 18.7500 (17.1016)  Acc@5: 68.7500 (61.0577)  time: 0.3440  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [ 100/3125]  eta: 0:17:40  Lr: 0.030000  Loss: 1.4683  Acc@1: 18.7500 (17.8837)  Acc@5: 62.5000 (61.0149)  time: 0.3438  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [ 110/3125]  eta: 0:17:34  Lr: 0.030000  Loss: 1.3317  Acc@1: 18.7500 (17.5113)  Acc@5: 62.5000 (61.4302)  time: 0.3432  data: 0.0002  max mem: 2500
Train: Epoch[1/5]  [ 120/3125]  eta: 0:17:29  Lr: 0.030000  Loss: 1.4051  Acc@1: 12.5000 (17.2521)  Acc@5: 62.5000 (61.6736)  time: 0.3428  data: 0.0002  max mem: 2500
Train: Epoch[1/5]  [ 130/3125]  eta: 0:17:24  Lr: 0.030000  Loss: 1.2645  Acc@1: 12.5000 (17.5573)  Acc@5: 62.5000 (61.9752)  time: 0.3427  data: 0.0002  max mem: 2500
Train: Epoch[1/5]  [ 140/3125]  eta: 0:17:20  Lr: 0.030000  Loss: 1.4129  Acc@1: 18.7500 (17.6862)  Acc@5: 68.7500 (62.3227)  time: 0.3438  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [ 150/3125]  eta: 0:17:15  Lr: 0.030000  Loss: 1.3388  Acc@1: 18.7500 (17.8394)  Acc@5: 68.7500 (63.2036)  time: 0.3443  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 160/3125]  eta: 0:17:11  Lr: 0.030000  Loss: 1.4025  Acc@1: 18.7500 (17.9348)  Acc@5: 68.7500 (63.5481)  time: 0.3438  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [ 170/3125]  eta: 0:17:07  Lr: 0.030000  Loss: 1.2812  Acc@1: 18.7500 (18.1287)  Acc@5: 75.0000 (64.4371)  time: 0.3436  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [ 180/3125]  eta: 0:17:03  Lr: 0.030000  Loss: 1.3290  Acc@1: 25.0000 (18.6119)  Acc@5: 75.0000 (65.0898)  time: 0.3436  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [ 190/3125]  eta: 0:16:59  Lr: 0.030000  Loss: 1.2910  Acc@1: 25.0000 (19.0118)  Acc@5: 75.0000 (65.6086)  time: 0.3440  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [ 200/3125]  eta: 0:16:55  Lr: 0.030000  Loss: 1.1936  Acc@1: 25.0000 (19.3719)  Acc@5: 75.0000 (66.2002)  time: 0.3443  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [ 210/3125]  eta: 0:16:51  Lr: 0.030000  Loss: 1.2631  Acc@1: 18.7500 (19.4017)  Acc@5: 81.2500 (66.7358)  time: 0.3437  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [ 220/3125]  eta: 0:16:47  Lr: 0.030000  Loss: 1.3032  Acc@1: 25.0000 (19.9095)  Acc@5: 81.2500 (67.5905)  time: 0.3426  data: 0.0002  max mem: 2500
Train: Epoch[1/5]  [ 230/3125]  eta: 0:16:43  Lr: 0.030000  Loss: 1.2382  Acc@1: 25.0000 (20.0758)  Acc@5: 81.2500 (68.2089)  time: 0.3423  data: 0.0002  max mem: 2500
Train: Epoch[1/5]  [ 240/3125]  eta: 0:16:39  Lr: 0.030000  Loss: 1.2549  Acc@1: 25.0000 (20.3320)  Acc@5: 81.2500 (68.8278)  time: 0.3428  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [ 250/3125]  eta: 0:16:35  Lr: 0.030000  Loss: 1.2954  Acc@1: 25.0000 (20.7171)  Acc@5: 87.5000 (69.5717)  time: 0.3433  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [ 260/3125]  eta: 0:16:31  Lr: 0.030000  Loss: 1.2423  Acc@1: 25.0000 (21.0249)  Acc@5: 81.2500 (69.8994)  time: 0.3442  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 270/3125]  eta: 0:16:28  Lr: 0.030000  Loss: 1.2260  Acc@1: 25.0000 (21.1716)  Acc@5: 81.2500 (70.2721)  time: 0.3448  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 280/3125]  eta: 0:16:24  Lr: 0.030000  Loss: 1.2338  Acc@1: 25.0000 (21.4190)  Acc@5: 81.2500 (70.7740)  time: 0.3447  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 290/3125]  eta: 0:16:21  Lr: 0.030000  Loss: 1.3109  Acc@1: 25.0000 (21.4991)  Acc@5: 81.2500 (71.1340)  time: 0.3449  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 300/3125]  eta: 0:16:17  Lr: 0.030000  Loss: 1.3129  Acc@1: 25.0000 (21.6570)  Acc@5: 81.2500 (71.3870)  time: 0.3448  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 310/3125]  eta: 0:16:13  Lr: 0.030000  Loss: 1.2640  Acc@1: 25.0000 (21.9051)  Acc@5: 81.2500 (71.7042)  time: 0.3445  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [ 320/3125]  eta: 0:16:10  Lr: 0.030000  Loss: 1.3380  Acc@1: 25.0000 (22.0405)  Acc@5: 81.2500 (72.0405)  time: 0.3443  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [ 330/3125]  eta: 0:16:06  Lr: 0.030000  Loss: 1.2539  Acc@1: 25.0000 (22.2243)  Acc@5: 87.5000 (72.4509)  time: 0.3440  data: 0.0002  max mem: 2500
Train: Epoch[1/5]  [ 340/3125]  eta: 0:16:03  Lr: 0.030000  Loss: 1.3052  Acc@1: 31.2500 (22.5806)  Acc@5: 87.5000 (72.6723)  time: 0.3436  data: 0.0002  max mem: 2500
Train: Epoch[1/5]  [ 350/3125]  eta: 0:15:59  Lr: 0.030000  Loss: 1.1703  Acc@1: 31.2500 (22.6852)  Acc@5: 81.2500 (72.9879)  time: 0.3432  data: 0.0002  max mem: 2500
Train: Epoch[1/5]  [ 360/3125]  eta: 0:15:55  Lr: 0.030000  Loss: 1.1652  Acc@1: 31.2500 (22.9051)  Acc@5: 81.2500 (73.2687)  time: 0.3443  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [ 370/3125]  eta: 0:15:52  Lr: 0.030000  Loss: 1.3217  Acc@1: 25.0000 (23.0458)  Acc@5: 81.2500 (73.5681)  time: 0.3451  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 380/3125]  eta: 0:15:48  Lr: 0.030000  Loss: 1.2835  Acc@1: 25.0000 (23.1955)  Acc@5: 87.5000 (73.8845)  time: 0.3456  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 390/3125]  eta: 0:15:45  Lr: 0.030000  Loss: 1.2172  Acc@1: 25.0000 (23.3376)  Acc@5: 87.5000 (74.2967)  time: 0.3452  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [ 400/3125]  eta: 0:15:41  Lr: 0.030000  Loss: 1.2389  Acc@1: 31.2500 (23.4882)  Acc@5: 87.5000 (74.5324)  time: 0.3439  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [ 410/3125]  eta: 0:15:38  Lr: 0.030000  Loss: 1.1804  Acc@1: 31.2500 (23.5706)  Acc@5: 81.2500 (74.7567)  time: 0.3442  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [ 420/3125]  eta: 0:15:34  Lr: 0.030000  Loss: 1.2113  Acc@1: 25.0000 (23.6045)  Acc@5: 81.2500 (74.9852)  time: 0.3448  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [ 430/3125]  eta: 0:15:31  Lr: 0.030000  Loss: 1.2375  Acc@1: 31.2500 (23.9124)  Acc@5: 87.5000 (75.2610)  time: 0.3443  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [ 440/3125]  eta: 0:15:27  Lr: 0.030000  Loss: 1.3806  Acc@1: 37.5000 (24.1355)  Acc@5: 87.5000 (75.4393)  time: 0.3435  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [ 450/3125]  eta: 0:15:23  Lr: 0.030000  Loss: 1.1571  Acc@1: 31.2500 (24.3071)  Acc@5: 87.5000 (75.6098)  time: 0.3432  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [ 460/3125]  eta: 0:15:20  Lr: 0.030000  Loss: 1.0653  Acc@1: 31.2500 (24.4441)  Acc@5: 87.5000 (75.8270)  time: 0.3430  data: 0.0002  max mem: 2500
Train: Epoch[1/5]  [ 470/3125]  eta: 0:15:16  Lr: 0.030000  Loss: 1.1100  Acc@1: 31.2500 (24.5223)  Acc@5: 87.5000 (76.0350)  time: 0.3436  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [ 480/3125]  eta: 0:15:13  Lr: 0.030000  Loss: 1.2490  Acc@1: 25.0000 (24.4802)  Acc@5: 81.2500 (76.1045)  time: 0.3449  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 490/3125]  eta: 0:15:10  Lr: 0.030000  Loss: 1.0867  Acc@1: 25.0000 (24.5927)  Acc@5: 87.5000 (76.3620)  time: 0.3457  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 500/3125]  eta: 0:15:06  Lr: 0.030000  Loss: 1.1304  Acc@1: 31.2500 (24.6881)  Acc@5: 87.5000 (76.5095)  time: 0.3459  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 510/3125]  eta: 0:15:03  Lr: 0.030000  Loss: 1.2409  Acc@1: 31.2500 (24.7309)  Acc@5: 87.5000 (76.7368)  time: 0.3459  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 520/3125]  eta: 0:14:59  Lr: 0.030000  Loss: 1.2001  Acc@1: 31.2500 (25.0120)  Acc@5: 87.5000 (76.9194)  time: 0.3457  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [ 530/3125]  eta: 0:14:56  Lr: 0.030000  Loss: 1.0692  Acc@1: 31.2500 (25.0942)  Acc@5: 87.5000 (77.1186)  time: 0.3455  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [ 540/3125]  eta: 0:14:52  Lr: 0.030000  Loss: 1.2652  Acc@1: 25.0000 (25.1617)  Acc@5: 87.5000 (77.2990)  time: 0.3455  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [ 550/3125]  eta: 0:14:49  Lr: 0.030000  Loss: 1.2213  Acc@1: 31.2500 (25.2609)  Acc@5: 87.5000 (77.4274)  time: 0.3459  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [ 560/3125]  eta: 0:14:45  Lr: 0.030000  Loss: 1.0728  Acc@1: 37.5000 (25.5013)  Acc@5: 87.5000 (77.6404)  time: 0.3457  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [ 570/3125]  eta: 0:14:42  Lr: 0.030000  Loss: 1.1658  Acc@1: 37.5000 (25.6239)  Acc@5: 87.5000 (77.7583)  time: 0.3452  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [ 580/3125]  eta: 0:14:39  Lr: 0.030000  Loss: 1.1597  Acc@1: 31.2500 (25.7960)  Acc@5: 87.5000 (77.8937)  time: 0.3457  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [ 590/3125]  eta: 0:14:35  Lr: 0.030000  Loss: 1.0553  Acc@1: 31.2500 (25.8672)  Acc@5: 87.5000 (77.9611)  time: 0.3452  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [ 600/3125]  eta: 0:14:32  Lr: 0.030000  Loss: 1.0618  Acc@1: 31.2500 (26.0191)  Acc@5: 87.5000 (78.1198)  time: 0.3438  data: 0.0002  max mem: 2500
Train: Epoch[1/5]  [ 610/3125]  eta: 0:14:28  Lr: 0.030000  Loss: 1.1810  Acc@1: 31.2500 (26.1457)  Acc@5: 87.5000 (78.2426)  time: 0.3439  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [ 620/3125]  eta: 0:14:25  Lr: 0.030000  Loss: 1.1535  Acc@1: 31.2500 (26.2782)  Acc@5: 81.2500 (78.3816)  time: 0.3442  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [ 630/3125]  eta: 0:14:21  Lr: 0.030000  Loss: 1.1067  Acc@1: 31.2500 (26.3074)  Acc@5: 87.5000 (78.4667)  time: 0.3444  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [ 640/3125]  eta: 0:14:18  Lr: 0.030000  Loss: 1.1571  Acc@1: 37.5000 (26.4918)  Acc@5: 81.2500 (78.5979)  time: 0.3444  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [ 650/3125]  eta: 0:14:14  Lr: 0.030000  Loss: 1.0629  Acc@1: 31.2500 (26.5265)  Acc@5: 87.5000 (78.7154)  time: 0.3445  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [ 660/3125]  eta: 0:14:11  Lr: 0.030000  Loss: 0.9955  Acc@1: 31.2500 (26.5696)  Acc@5: 87.5000 (78.8389)  time: 0.3470  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [ 670/3125]  eta: 0:14:07  Lr: 0.030000  Loss: 1.1764  Acc@1: 25.0000 (26.6673)  Acc@5: 87.5000 (78.9680)  time: 0.3484  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [ 680/3125]  eta: 0:14:04  Lr: 0.030000  Loss: 1.2069  Acc@1: 25.0000 (26.7896)  Acc@5: 87.5000 (79.0657)  time: 0.3479  data: 0.0010  max mem: 2500
Train: Epoch[1/5]  [ 690/3125]  eta: 0:14:01  Lr: 0.030000  Loss: 1.1747  Acc@1: 31.2500 (26.8452)  Acc@5: 87.5000 (79.1606)  time: 0.3486  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [ 700/3125]  eta: 0:13:57  Lr: 0.030000  Loss: 1.1357  Acc@1: 31.2500 (26.8812)  Acc@5: 87.5000 (79.2796)  time: 0.3495  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [ 710/3125]  eta: 0:13:54  Lr: 0.030000  Loss: 1.0320  Acc@1: 25.0000 (26.9251)  Acc@5: 87.5000 (79.4040)  time: 0.3492  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [ 720/3125]  eta: 0:13:51  Lr: 0.030000  Loss: 1.1214  Acc@1: 25.0000 (26.9938)  Acc@5: 87.5000 (79.4903)  time: 0.3478  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 730/3125]  eta: 0:13:47  Lr: 0.030000  Loss: 0.9527  Acc@1: 31.2500 (27.0776)  Acc@5: 87.5000 (79.6597)  time: 0.3464  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 740/3125]  eta: 0:13:44  Lr: 0.030000  Loss: 1.0823  Acc@1: 31.2500 (27.2267)  Acc@5: 93.7500 (79.8077)  time: 0.3458  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 750/3125]  eta: 0:13:40  Lr: 0.030000  Loss: 1.1857  Acc@1: 31.2500 (27.3053)  Acc@5: 87.5000 (79.9101)  time: 0.3459  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 760/3125]  eta: 0:13:37  Lr: 0.030000  Loss: 1.1767  Acc@1: 25.0000 (27.2914)  Acc@5: 81.2500 (79.9195)  time: 0.3458  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 770/3125]  eta: 0:13:33  Lr: 0.030000  Loss: 1.2210  Acc@1: 31.2500 (27.4157)  Acc@5: 81.2500 (79.9692)  time: 0.3462  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [ 780/3125]  eta: 0:13:30  Lr: 0.030000  Loss: 1.1236  Acc@1: 37.5000 (27.5368)  Acc@5: 87.5000 (80.0976)  time: 0.3464  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [ 790/3125]  eta: 0:13:27  Lr: 0.030000  Loss: 0.9993  Acc@1: 37.5000 (27.6549)  Acc@5: 93.7500 (80.2465)  time: 0.3468  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [ 800/3125]  eta: 0:13:23  Lr: 0.030000  Loss: 1.0993  Acc@1: 43.7500 (27.9026)  Acc@5: 93.7500 (80.3527)  time: 0.3466  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 810/3125]  eta: 0:13:20  Lr: 0.030000  Loss: 1.1108  Acc@1: 43.7500 (28.0133)  Acc@5: 87.5000 (80.4562)  time: 0.3455  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [ 820/3125]  eta: 0:13:16  Lr: 0.030000  Loss: 1.1502  Acc@1: 37.5000 (28.1136)  Acc@5: 87.5000 (80.5420)  time: 0.3450  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [ 830/3125]  eta: 0:13:13  Lr: 0.030000  Loss: 1.0021  Acc@1: 31.2500 (28.1513)  Acc@5: 87.5000 (80.6408)  time: 0.3450  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [ 840/3125]  eta: 0:13:09  Lr: 0.030000  Loss: 0.9002  Acc@1: 31.2500 (28.2625)  Acc@5: 87.5000 (80.7744)  time: 0.3455  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [ 850/3125]  eta: 0:13:06  Lr: 0.030000  Loss: 1.0025  Acc@1: 37.5000 (28.3270)  Acc@5: 87.5000 (80.8314)  time: 0.3457  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [ 860/3125]  eta: 0:13:02  Lr: 0.030000  Loss: 0.9762  Acc@1: 37.5000 (28.3972)  Acc@5: 87.5000 (80.9451)  time: 0.3451  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [ 870/3125]  eta: 0:12:59  Lr: 0.030000  Loss: 1.2636  Acc@1: 31.2500 (28.4371)  Acc@5: 87.5000 (80.9701)  time: 0.3457  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [ 880/3125]  eta: 0:12:55  Lr: 0.030000  Loss: 1.0889  Acc@1: 31.2500 (28.5471)  Acc@5: 87.5000 (81.0797)  time: 0.3457  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [ 890/3125]  eta: 0:12:52  Lr: 0.030000  Loss: 1.0631  Acc@1: 37.5000 (28.6406)  Acc@5: 87.5000 (81.1378)  time: 0.3443  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [ 900/3125]  eta: 0:12:48  Lr: 0.030000  Loss: 1.1616  Acc@1: 37.5000 (28.7042)  Acc@5: 87.5000 (81.2153)  time: 0.3437  data: 0.0002  max mem: 2500
Train: Epoch[1/5]  [ 910/3125]  eta: 0:12:45  Lr: 0.030000  Loss: 1.0425  Acc@1: 31.2500 (28.7733)  Acc@5: 87.5000 (81.3323)  time: 0.3436  data: 0.0002  max mem: 2500
Train: Epoch[1/5]  [ 920/3125]  eta: 0:12:41  Lr: 0.030000  Loss: 1.1399  Acc@1: 31.2500 (28.8613)  Acc@5: 87.5000 (81.4197)  time: 0.3434  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [ 930/3125]  eta: 0:12:38  Lr: 0.030000  Loss: 0.8351  Acc@1: 43.7500 (29.0615)  Acc@5: 87.5000 (81.5185)  time: 0.3432  data: 0.0002  max mem: 2500
Train: Epoch[1/5]  [ 940/3125]  eta: 0:12:34  Lr: 0.030000  Loss: 0.9813  Acc@1: 37.5000 (29.0848)  Acc@5: 87.5000 (81.5356)  time: 0.3435  data: 0.0002  max mem: 2500
Train: Epoch[1/5]  [ 950/3125]  eta: 0:12:31  Lr: 0.030000  Loss: 1.0537  Acc@1: 37.5000 (29.2324)  Acc@5: 87.5000 (81.6115)  time: 0.3441  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [ 960/3125]  eta: 0:12:27  Lr: 0.030000  Loss: 0.9491  Acc@1: 37.5000 (29.3379)  Acc@5: 87.5000 (81.7118)  time: 0.3445  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [ 970/3125]  eta: 0:12:24  Lr: 0.030000  Loss: 1.0315  Acc@1: 37.5000 (29.4477)  Acc@5: 87.5000 (81.7521)  time: 0.3465  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 980/3125]  eta: 0:12:21  Lr: 0.030000  Loss: 0.8332  Acc@1: 37.5000 (29.5107)  Acc@5: 87.5000 (81.8043)  time: 0.3470  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 990/3125]  eta: 0:12:17  Lr: 0.030000  Loss: 0.9933  Acc@1: 37.5000 (29.6733)  Acc@5: 93.7500 (81.8996)  time: 0.3455  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1000/3125]  eta: 0:12:14  Lr: 0.030000  Loss: 1.2901  Acc@1: 43.7500 (29.7453)  Acc@5: 93.7500 (81.9618)  time: 0.3450  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1010/3125]  eta: 0:12:10  Lr: 0.030000  Loss: 0.9501  Acc@1: 37.5000 (29.8591)  Acc@5: 87.5000 (82.0351)  time: 0.3452  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1020/3125]  eta: 0:12:07  Lr: 0.030000  Loss: 1.0403  Acc@1: 43.7500 (30.0073)  Acc@5: 87.5000 (82.1070)  time: 0.3461  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1030/3125]  eta: 0:12:03  Lr: 0.030000  Loss: 0.9915  Acc@1: 43.7500 (30.0740)  Acc@5: 87.5000 (82.1896)  time: 0.3460  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1040/3125]  eta: 0:12:00  Lr: 0.030000  Loss: 0.9972  Acc@1: 37.5000 (30.1453)  Acc@5: 93.7500 (82.3067)  time: 0.3447  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1050/3125]  eta: 0:11:56  Lr: 0.030000  Loss: 1.0042  Acc@1: 37.5000 (30.2866)  Acc@5: 93.7500 (82.3620)  time: 0.3442  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1060/3125]  eta: 0:11:53  Lr: 0.030000  Loss: 1.0529  Acc@1: 43.7500 (30.3900)  Acc@5: 87.5000 (82.4399)  time: 0.3442  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1070/3125]  eta: 0:11:49  Lr: 0.030000  Loss: 1.0153  Acc@1: 43.7500 (30.4855)  Acc@5: 93.7500 (82.5222)  time: 0.3451  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [1080/3125]  eta: 0:11:46  Lr: 0.030000  Loss: 0.9841  Acc@1: 37.5000 (30.5273)  Acc@5: 93.7500 (82.6203)  time: 0.3450  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1090/3125]  eta: 0:11:42  Lr: 0.030000  Loss: 0.8591  Acc@1: 37.5000 (30.5912)  Acc@5: 87.5000 (82.6363)  time: 0.3437  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1100/3125]  eta: 0:11:39  Lr: 0.030000  Loss: 0.8783  Acc@1: 37.5000 (30.6483)  Acc@5: 87.5000 (82.6578)  time: 0.3438  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1110/3125]  eta: 0:11:36  Lr: 0.030000  Loss: 1.1702  Acc@1: 37.5000 (30.7156)  Acc@5: 87.5000 (82.6789)  time: 0.3441  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [1120/3125]  eta: 0:11:32  Lr: 0.030000  Loss: 0.9923  Acc@1: 37.5000 (30.8263)  Acc@5: 87.5000 (82.7107)  time: 0.3444  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [1130/3125]  eta: 0:11:29  Lr: 0.030000  Loss: 0.9676  Acc@1: 37.5000 (30.8908)  Acc@5: 87.5000 (82.7365)  time: 0.3447  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [1140/3125]  eta: 0:11:25  Lr: 0.030000  Loss: 0.8561  Acc@1: 37.5000 (30.9926)  Acc@5: 87.5000 (82.8057)  time: 0.3442  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [1150/3125]  eta: 0:11:22  Lr: 0.030000  Loss: 1.0221  Acc@1: 37.5000 (30.9839)  Acc@5: 87.5000 (82.8247)  time: 0.3434  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [1160/3125]  eta: 0:11:18  Lr: 0.030000  Loss: 0.9993  Acc@1: 37.5000 (31.0885)  Acc@5: 87.5000 (82.8919)  time: 0.3431  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [1170/3125]  eta: 0:11:15  Lr: 0.030000  Loss: 1.0518  Acc@1: 31.2500 (31.0792)  Acc@5: 93.7500 (82.9686)  time: 0.3427  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [1180/3125]  eta: 0:11:11  Lr: 0.030000  Loss: 0.9889  Acc@1: 31.2500 (31.1177)  Acc@5: 87.5000 (83.0017)  time: 0.3438  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [1190/3125]  eta: 0:11:08  Lr: 0.030000  Loss: 1.0323  Acc@1: 43.7500 (31.2343)  Acc@5: 87.5000 (83.0762)  time: 0.3447  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1200/3125]  eta: 0:11:04  Lr: 0.030000  Loss: 0.8973  Acc@1: 43.7500 (31.3333)  Acc@5: 87.5000 (83.1130)  time: 0.3439  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1210/3125]  eta: 0:11:01  Lr: 0.030000  Loss: 1.0405  Acc@1: 37.5000 (31.3893)  Acc@5: 87.5000 (83.1647)  time: 0.3433  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [1220/3125]  eta: 0:10:57  Lr: 0.030000  Loss: 0.8512  Acc@1: 37.5000 (31.4803)  Acc@5: 93.7500 (83.2361)  time: 0.3432  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [1230/3125]  eta: 0:10:54  Lr: 0.030000  Loss: 0.8476  Acc@1: 43.7500 (31.5648)  Acc@5: 93.7500 (83.3113)  time: 0.3433  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [1240/3125]  eta: 0:10:50  Lr: 0.030000  Loss: 0.9729  Acc@1: 37.5000 (31.6227)  Acc@5: 93.7500 (83.3552)  time: 0.3427  data: 0.0002  max mem: 2500
Train: Epoch[1/5]  [1250/3125]  eta: 0:10:47  Lr: 0.030000  Loss: 1.0058  Acc@1: 37.5000 (31.6747)  Acc@5: 93.7500 (83.4183)  time: 0.3433  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [1260/3125]  eta: 0:10:43  Lr: 0.030000  Loss: 0.8566  Acc@1: 37.5000 (31.7506)  Acc@5: 93.7500 (83.4754)  time: 0.3443  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [1270/3125]  eta: 0:10:40  Lr: 0.030000  Loss: 0.8090  Acc@1: 43.7500 (31.8745)  Acc@5: 93.7500 (83.5513)  time: 0.3439  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1280/3125]  eta: 0:10:36  Lr: 0.030000  Loss: 0.7709  Acc@1: 37.5000 (31.9087)  Acc@5: 93.7500 (83.6066)  time: 0.3436  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [1290/3125]  eta: 0:10:33  Lr: 0.030000  Loss: 0.9211  Acc@1: 37.5000 (31.9955)  Acc@5: 93.7500 (83.6803)  time: 0.3439  data: 0.0002  max mem: 2500
Train: Epoch[1/5]  [1300/3125]  eta: 0:10:29  Lr: 0.030000  Loss: 0.9203  Acc@1: 43.7500 (32.0907)  Acc@5: 93.7500 (83.7433)  time: 0.3446  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [1310/3125]  eta: 0:10:26  Lr: 0.030000  Loss: 0.8979  Acc@1: 43.7500 (32.1701)  Acc@5: 87.5000 (83.7862)  time: 0.3447  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [1320/3125]  eta: 0:10:23  Lr: 0.030000  Loss: 0.7508  Acc@1: 43.7500 (32.2909)  Acc@5: 87.5000 (83.8380)  time: 0.3446  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [1330/3125]  eta: 0:10:19  Lr: 0.030000  Loss: 0.6977  Acc@1: 43.7500 (32.4098)  Acc@5: 93.7500 (83.8984)  time: 0.3452  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [1340/3125]  eta: 0:10:16  Lr: 0.030000  Loss: 0.7554  Acc@1: 43.7500 (32.5037)  Acc@5: 93.7500 (83.9765)  time: 0.3445  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [1350/3125]  eta: 0:10:12  Lr: 0.030000  Loss: 0.8991  Acc@1: 43.7500 (32.5870)  Acc@5: 93.7500 (84.0211)  time: 0.3432  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [1360/3125]  eta: 0:10:09  Lr: 0.030000  Loss: 0.9683  Acc@1: 43.7500 (32.6598)  Acc@5: 87.5000 (84.0604)  time: 0.3429  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [1370/3125]  eta: 0:10:05  Lr: 0.030000  Loss: 0.8579  Acc@1: 43.7500 (32.7544)  Acc@5: 93.7500 (84.1129)  time: 0.3426  data: 0.0002  max mem: 2500
Train: Epoch[1/5]  [1380/3125]  eta: 0:10:02  Lr: 0.030000  Loss: 0.7808  Acc@1: 43.7500 (32.8928)  Acc@5: 93.7500 (84.1827)  time: 0.3426  data: 0.0002  max mem: 2500
Train: Epoch[1/5]  [1390/3125]  eta: 0:09:58  Lr: 0.030000  Loss: 0.7991  Acc@1: 43.7500 (32.9574)  Acc@5: 93.7500 (84.2425)  time: 0.3425  data: 0.0002  max mem: 2500
Train: Epoch[1/5]  [1400/3125]  eta: 0:09:55  Lr: 0.030000  Loss: 0.8459  Acc@1: 43.7500 (33.0077)  Acc@5: 93.7500 (84.3059)  time: 0.3425  data: 0.0002  max mem: 2500
Train: Epoch[1/5]  [1410/3125]  eta: 0:09:51  Lr: 0.030000  Loss: 1.0780  Acc@1: 43.7500 (33.0705)  Acc@5: 93.7500 (84.3285)  time: 0.3426  data: 0.0002  max mem: 2500
Train: Epoch[1/5]  [1420/3125]  eta: 0:09:48  Lr: 0.030000  Loss: 0.8432  Acc@1: 43.7500 (33.1545)  Acc@5: 93.7500 (84.3772)  time: 0.3426  data: 0.0002  max mem: 2500
Train: Epoch[1/5]  [1430/3125]  eta: 0:09:44  Lr: 0.030000  Loss: 0.8102  Acc@1: 43.7500 (33.2023)  Acc@5: 87.5000 (84.3859)  time: 0.3426  data: 0.0002  max mem: 2500
Train: Epoch[1/5]  [1440/3125]  eta: 0:09:41  Lr: 0.030000  Loss: 0.9599  Acc@1: 37.5000 (33.2408)  Acc@5: 87.5000 (84.4249)  time: 0.3435  data: 0.0002  max mem: 2500
Train: Epoch[1/5]  [1450/3125]  eta: 0:09:37  Lr: 0.030000  Loss: 1.0056  Acc@1: 37.5000 (33.3348)  Acc@5: 87.5000 (84.4676)  time: 0.3444  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [1460/3125]  eta: 0:09:34  Lr: 0.030000  Loss: 0.9174  Acc@1: 43.7500 (33.4103)  Acc@5: 93.7500 (84.5311)  time: 0.3455  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1470/3125]  eta: 0:09:30  Lr: 0.030000  Loss: 0.7982  Acc@1: 43.7500 (33.5061)  Acc@5: 93.7500 (84.5981)  time: 0.3459  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1480/3125]  eta: 0:09:27  Lr: 0.030000  Loss: 0.9426  Acc@1: 50.0000 (33.6006)  Acc@5: 93.7500 (84.6430)  time: 0.3453  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [1490/3125]  eta: 0:09:24  Lr: 0.030000  Loss: 0.8247  Acc@1: 50.0000 (33.6771)  Acc@5: 87.5000 (84.6621)  time: 0.3450  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1500/3125]  eta: 0:09:20  Lr: 0.030000  Loss: 0.8129  Acc@1: 43.7500 (33.7317)  Acc@5: 87.5000 (84.7102)  time: 0.3445  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1510/3125]  eta: 0:09:17  Lr: 0.030000  Loss: 0.7688  Acc@1: 50.0000 (33.8642)  Acc@5: 93.7500 (84.7783)  time: 0.3449  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1520/3125]  eta: 0:09:13  Lr: 0.030000  Loss: 0.9432  Acc@1: 43.7500 (33.9086)  Acc@5: 93.7500 (84.8126)  time: 0.3447  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1530/3125]  eta: 0:09:10  Lr: 0.030000  Loss: 1.0090  Acc@1: 43.7500 (33.9892)  Acc@5: 93.7500 (84.8465)  time: 0.3449  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1540/3125]  eta: 0:09:06  Lr: 0.030000  Loss: 1.0761  Acc@1: 43.7500 (34.0201)  Acc@5: 87.5000 (84.8718)  time: 0.3452  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1550/3125]  eta: 0:09:03  Lr: 0.030000  Loss: 0.7903  Acc@1: 43.7500 (34.1030)  Acc@5: 93.7500 (84.9250)  time: 0.3448  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1560/3125]  eta: 0:08:59  Lr: 0.030000  Loss: 0.8459  Acc@1: 43.7500 (34.1728)  Acc@5: 93.7500 (84.9736)  time: 0.3448  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1570/3125]  eta: 0:08:56  Lr: 0.030000  Loss: 0.9746  Acc@1: 43.7500 (34.2417)  Acc@5: 93.7500 (85.0175)  time: 0.3460  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1580/3125]  eta: 0:08:53  Lr: 0.030000  Loss: 0.7754  Acc@1: 43.7500 (34.3374)  Acc@5: 87.5000 (85.0451)  time: 0.3463  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1590/3125]  eta: 0:08:49  Lr: 0.030000  Loss: 0.8186  Acc@1: 50.0000 (34.4791)  Acc@5: 93.7500 (85.0998)  time: 0.3466  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1600/3125]  eta: 0:08:46  Lr: 0.030000  Loss: 0.6281  Acc@1: 50.0000 (34.5487)  Acc@5: 93.7500 (85.1499)  time: 0.3489  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1610/3125]  eta: 0:08:42  Lr: 0.030000  Loss: 0.8850  Acc@1: 43.7500 (34.5864)  Acc@5: 93.7500 (85.1878)  time: 0.3472  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [1620/3125]  eta: 0:08:39  Lr: 0.030000  Loss: 0.7838  Acc@1: 43.7500 (34.6700)  Acc@5: 93.7500 (85.2367)  time: 0.3447  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [1630/3125]  eta: 0:08:35  Lr: 0.030000  Loss: 0.7132  Acc@1: 43.7500 (34.7218)  Acc@5: 93.7500 (85.2506)  time: 0.3455  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [1640/3125]  eta: 0:08:32  Lr: 0.030000  Loss: 0.9532  Acc@1: 43.7500 (34.8073)  Acc@5: 87.5000 (85.2719)  time: 0.3460  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [1650/3125]  eta: 0:08:28  Lr: 0.030000  Loss: 0.6648  Acc@1: 43.7500 (34.8690)  Acc@5: 87.5000 (85.2968)  time: 0.3457  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [1660/3125]  eta: 0:08:25  Lr: 0.030000  Loss: 0.7497  Acc@1: 50.0000 (35.0128)  Acc@5: 93.7500 (85.3364)  time: 0.3454  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [1670/3125]  eta: 0:08:22  Lr: 0.030000  Loss: 0.8168  Acc@1: 50.0000 (35.0838)  Acc@5: 93.7500 (85.3867)  time: 0.3458  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [1680/3125]  eta: 0:08:18  Lr: 0.030000  Loss: 0.8474  Acc@1: 43.7500 (35.1391)  Acc@5: 93.7500 (85.4179)  time: 0.3447  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [1690/3125]  eta: 0:08:15  Lr: 0.030000  Loss: 1.0026  Acc@1: 43.7500 (35.2195)  Acc@5: 93.7500 (85.4746)  time: 0.3434  data: 0.0002  max mem: 2500
Train: Epoch[1/5]  [1700/3125]  eta: 0:08:11  Lr: 0.030000  Loss: 0.8461  Acc@1: 50.0000 (35.2734)  Acc@5: 93.7500 (85.4938)  time: 0.3436  data: 0.0002  max mem: 2500
Train: Epoch[1/5]  [1710/3125]  eta: 0:08:08  Lr: 0.030000  Loss: 0.8685  Acc@1: 43.7500 (35.2973)  Acc@5: 87.5000 (85.5019)  time: 0.3435  data: 0.0002  max mem: 2500
Train: Epoch[1/5]  [1720/3125]  eta: 0:08:04  Lr: 0.030000  Loss: 1.0490  Acc@1: 37.5000 (35.2920)  Acc@5: 87.5000 (85.5171)  time: 0.3436  data: 0.0002  max mem: 2500
Train: Epoch[1/5]  [1730/3125]  eta: 0:08:01  Lr: 0.030000  Loss: 0.9806  Acc@1: 43.7500 (35.4058)  Acc@5: 93.7500 (85.5611)  time: 0.3450  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [1740/3125]  eta: 0:07:57  Lr: 0.030000  Loss: 0.9198  Acc@1: 50.0000 (35.4430)  Acc@5: 93.7500 (85.5830)  time: 0.3461  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [1750/3125]  eta: 0:07:54  Lr: 0.030000  Loss: 1.0594  Acc@1: 43.7500 (35.5261)  Acc@5: 93.7500 (85.6189)  time: 0.3458  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [1760/3125]  eta: 0:07:50  Lr: 0.030000  Loss: 0.9349  Acc@1: 43.7500 (35.5941)  Acc@5: 93.7500 (85.6438)  time: 0.3456  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1770/3125]  eta: 0:07:47  Lr: 0.030000  Loss: 0.8383  Acc@1: 50.0000 (35.6931)  Acc@5: 93.7500 (85.6755)  time: 0.3457  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1780/3125]  eta: 0:07:44  Lr: 0.030000  Loss: 0.8680  Acc@1: 50.0000 (35.7348)  Acc@5: 93.7500 (85.7173)  time: 0.3457  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1790/3125]  eta: 0:07:40  Lr: 0.030000  Loss: 0.7183  Acc@1: 43.7500 (35.7936)  Acc@5: 93.7500 (85.7726)  time: 0.3456  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1800/3125]  eta: 0:07:37  Lr: 0.030000  Loss: 0.9066  Acc@1: 43.7500 (35.8724)  Acc@5: 93.7500 (85.7996)  time: 0.3451  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1810/3125]  eta: 0:07:33  Lr: 0.030000  Loss: 0.6773  Acc@1: 50.0000 (35.9504)  Acc@5: 93.7500 (85.8504)  time: 0.3448  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1820/3125]  eta: 0:07:30  Lr: 0.030000  Loss: 0.9297  Acc@1: 50.0000 (36.0104)  Acc@5: 93.7500 (85.8663)  time: 0.3449  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [1830/3125]  eta: 0:07:26  Lr: 0.030000  Loss: 0.9166  Acc@1: 43.7500 (36.0698)  Acc@5: 87.5000 (85.8718)  time: 0.3451  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [1840/3125]  eta: 0:07:23  Lr: 0.030000  Loss: 0.9866  Acc@1: 43.7500 (36.1454)  Acc@5: 93.7500 (85.9146)  time: 0.3452  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [1850/3125]  eta: 0:07:19  Lr: 0.030000  Loss: 0.8263  Acc@1: 50.0000 (36.2405)  Acc@5: 93.7500 (85.9603)  time: 0.3451  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [1860/3125]  eta: 0:07:16  Lr: 0.030000  Loss: 0.8846  Acc@1: 56.2500 (36.3313)  Acc@5: 93.7500 (85.9921)  time: 0.3448  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [1870/3125]  eta: 0:07:13  Lr: 0.030000  Loss: 0.9806  Acc@1: 43.7500 (36.3743)  Acc@5: 93.7500 (86.0235)  time: 0.3454  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [1880/3125]  eta: 0:07:09  Lr: 0.030000  Loss: 1.0629  Acc@1: 43.7500 (36.4500)  Acc@5: 93.7500 (86.0579)  time: 0.3449  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [1890/3125]  eta: 0:07:06  Lr: 0.030000  Loss: 0.7819  Acc@1: 50.0000 (36.5217)  Acc@5: 93.7500 (86.0887)  time: 0.3434  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [1900/3125]  eta: 0:07:02  Lr: 0.030000  Loss: 0.9857  Acc@1: 50.0000 (36.5696)  Acc@5: 93.7500 (86.1126)  time: 0.3433  data: 0.0002  max mem: 2500
Train: Epoch[1/5]  [1910/3125]  eta: 0:06:59  Lr: 0.030000  Loss: 0.7415  Acc@1: 43.7500 (36.6170)  Acc@5: 93.7500 (86.1362)  time: 0.3433  data: 0.0002  max mem: 2500
Train: Epoch[1/5]  [1920/3125]  eta: 0:06:55  Lr: 0.030000  Loss: 0.9912  Acc@1: 50.0000 (36.6801)  Acc@5: 93.7500 (86.1726)  time: 0.3434  data: 0.0002  max mem: 2500
Train: Epoch[1/5]  [1930/3125]  eta: 0:06:52  Lr: 0.030000  Loss: 0.8396  Acc@1: 50.0000 (36.7167)  Acc@5: 93.7500 (86.2150)  time: 0.3443  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [1940/3125]  eta: 0:06:48  Lr: 0.030000  Loss: 0.9139  Acc@1: 50.0000 (36.7884)  Acc@5: 93.7500 (86.2378)  time: 0.3449  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1950/3125]  eta: 0:06:45  Lr: 0.030000  Loss: 0.7217  Acc@1: 50.0000 (36.8593)  Acc@5: 93.7500 (86.2731)  time: 0.3446  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1960/3125]  eta: 0:06:41  Lr: 0.030000  Loss: 0.7904  Acc@1: 50.0000 (36.8976)  Acc@5: 93.7500 (86.3112)  time: 0.3446  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1970/3125]  eta: 0:06:38  Lr: 0.030000  Loss: 0.7803  Acc@1: 50.0000 (36.9482)  Acc@5: 93.7500 (86.3584)  time: 0.3445  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1980/3125]  eta: 0:06:35  Lr: 0.030000  Loss: 0.7285  Acc@1: 50.0000 (37.0299)  Acc@5: 93.7500 (86.3989)  time: 0.3443  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [1990/3125]  eta: 0:06:31  Lr: 0.030000  Loss: 0.8988  Acc@1: 43.7500 (37.0605)  Acc@5: 93.7500 (86.4044)  time: 0.3451  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [2000/3125]  eta: 0:06:28  Lr: 0.030000  Loss: 0.7385  Acc@1: 43.7500 (37.1314)  Acc@5: 93.7500 (86.4536)  time: 0.3456  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2010/3125]  eta: 0:06:24  Lr: 0.030000  Loss: 0.7649  Acc@1: 50.0000 (37.1861)  Acc@5: 93.7500 (86.4651)  time: 0.3455  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2020/3125]  eta: 0:06:21  Lr: 0.030000  Loss: 0.8917  Acc@1: 43.7500 (37.2155)  Acc@5: 87.5000 (86.4857)  time: 0.3455  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [2030/3125]  eta: 0:06:17  Lr: 0.030000  Loss: 0.7826  Acc@1: 50.0000 (37.2969)  Acc@5: 93.7500 (86.5306)  time: 0.3452  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [2040/3125]  eta: 0:06:14  Lr: 0.030000  Loss: 0.6360  Acc@1: 50.0000 (37.3469)  Acc@5: 93.7500 (86.5660)  time: 0.3450  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [2050/3125]  eta: 0:06:10  Lr: 0.030000  Loss: 0.7995  Acc@1: 50.0000 (37.4177)  Acc@5: 93.7500 (86.6041)  time: 0.3451  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [2060/3125]  eta: 0:06:07  Lr: 0.030000  Loss: 0.8035  Acc@1: 50.0000 (37.4666)  Acc@5: 93.7500 (86.6054)  time: 0.3452  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [2070/3125]  eta: 0:06:03  Lr: 0.030000  Loss: 0.6938  Acc@1: 50.0000 (37.5272)  Acc@5: 93.7500 (86.6399)  time: 0.3453  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [2080/3125]  eta: 0:06:00  Lr: 0.030000  Loss: 0.8953  Acc@1: 56.2500 (37.5781)  Acc@5: 93.7500 (86.6831)  time: 0.3453  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [2090/3125]  eta: 0:05:57  Lr: 0.030000  Loss: 0.7030  Acc@1: 37.5000 (37.5986)  Acc@5: 93.7500 (86.7199)  time: 0.3439  data: 0.0002  max mem: 2500
Train: Epoch[1/5]  [2100/3125]  eta: 0:05:53  Lr: 0.030000  Loss: 0.7430  Acc@1: 50.0000 (37.6963)  Acc@5: 93.7500 (86.7504)  time: 0.3428  data: 0.0002  max mem: 2500
Train: Epoch[1/5]  [2110/3125]  eta: 0:05:50  Lr: 0.030000  Loss: 0.7696  Acc@1: 50.0000 (37.7398)  Acc@5: 93.7500 (86.7687)  time: 0.3429  data: 0.0002  max mem: 2500
Train: Epoch[1/5]  [2120/3125]  eta: 0:05:46  Lr: 0.030000  Loss: 0.6759  Acc@1: 50.0000 (37.8124)  Acc@5: 93.7500 (86.8046)  time: 0.3429  data: 0.0002  max mem: 2500
Train: Epoch[1/5]  [2130/3125]  eta: 0:05:43  Lr: 0.030000  Loss: 0.6403  Acc@1: 56.2500 (37.8842)  Acc@5: 93.7500 (86.8342)  time: 0.3431  data: 0.0002  max mem: 2500
Train: Epoch[1/5]  [2140/3125]  eta: 0:05:39  Lr: 0.030000  Loss: 0.7077  Acc@1: 50.0000 (37.9642)  Acc@5: 93.7500 (86.8665)  time: 0.3430  data: 0.0002  max mem: 2500
Train: Epoch[1/5]  [2150/3125]  eta: 0:05:36  Lr: 0.030000  Loss: 0.5938  Acc@1: 50.0000 (38.0288)  Acc@5: 93.7500 (86.9131)  time: 0.3428  data: 0.0002  max mem: 2500
Train: Epoch[1/5]  [2160/3125]  eta: 0:05:32  Lr: 0.030000  Loss: 0.7657  Acc@1: 43.7500 (38.0669)  Acc@5: 93.7500 (86.9100)  time: 0.3431  data: 0.0002  max mem: 2500
Train: Epoch[1/5]  [2170/3125]  eta: 0:05:29  Lr: 0.030000  Loss: 0.9898  Acc@1: 43.7500 (38.1017)  Acc@5: 87.5000 (86.9415)  time: 0.3434  data: 0.0002  max mem: 2500
Train: Epoch[1/5]  [2180/3125]  eta: 0:05:25  Lr: 0.030000  Loss: 1.0973  Acc@1: 43.7500 (38.1792)  Acc@5: 93.7500 (86.9727)  time: 0.3454  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2190/3125]  eta: 0:05:22  Lr: 0.030000  Loss: 0.5022  Acc@1: 56.2500 (38.2645)  Acc@5: 100.0000 (87.0179)  time: 0.3467  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2200/3125]  eta: 0:05:19  Lr: 0.030000  Loss: 0.6692  Acc@1: 50.0000 (38.3206)  Acc@5: 93.7500 (87.0428)  time: 0.3462  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2210/3125]  eta: 0:05:15  Lr: 0.030000  Loss: 0.7149  Acc@1: 50.0000 (38.3650)  Acc@5: 87.5000 (87.0647)  time: 0.3463  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2220/3125]  eta: 0:05:12  Lr: 0.030000  Loss: 0.6056  Acc@1: 50.0000 (38.3977)  Acc@5: 87.5000 (87.0666)  time: 0.3462  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2230/3125]  eta: 0:05:08  Lr: 0.030000  Loss: 0.6717  Acc@1: 43.7500 (38.4301)  Acc@5: 87.5000 (87.0910)  time: 0.3459  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2240/3125]  eta: 0:05:05  Lr: 0.030000  Loss: 0.7926  Acc@1: 43.7500 (38.4789)  Acc@5: 87.5000 (87.1068)  time: 0.3460  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2250/3125]  eta: 0:05:01  Lr: 0.030000  Loss: 0.8076  Acc@1: 50.0000 (38.5440)  Acc@5: 93.7500 (87.1335)  time: 0.3455  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2260/3125]  eta: 0:04:58  Lr: 0.030000  Loss: 0.9003  Acc@1: 56.2500 (38.6029)  Acc@5: 93.7500 (87.1655)  time: 0.3455  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2270/3125]  eta: 0:04:54  Lr: 0.030000  Loss: 0.6249  Acc@1: 50.0000 (38.6641)  Acc@5: 93.7500 (87.2000)  time: 0.3453  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2280/3125]  eta: 0:04:51  Lr: 0.030000  Loss: 0.6102  Acc@1: 56.2500 (38.7467)  Acc@5: 93.7500 (87.2342)  time: 0.3448  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2290/3125]  eta: 0:04:48  Lr: 0.030000  Loss: 0.7111  Acc@1: 56.2500 (38.7876)  Acc@5: 93.7500 (87.2545)  time: 0.3451  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2300/3125]  eta: 0:04:44  Lr: 0.030000  Loss: 0.6828  Acc@1: 50.0000 (38.8554)  Acc@5: 93.7500 (87.2881)  time: 0.3454  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2310/3125]  eta: 0:04:41  Lr: 0.030000  Loss: 1.0591  Acc@1: 50.0000 (38.9334)  Acc@5: 93.7500 (87.3107)  time: 0.3462  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2320/3125]  eta: 0:04:37  Lr: 0.030000  Loss: 0.5170  Acc@1: 56.2500 (38.9837)  Acc@5: 93.7500 (87.3196)  time: 0.3463  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2330/3125]  eta: 0:04:34  Lr: 0.030000  Loss: 0.7550  Acc@1: 56.2500 (39.0766)  Acc@5: 93.7500 (87.3445)  time: 0.3459  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2340/3125]  eta: 0:04:30  Lr: 0.030000  Loss: 0.5838  Acc@1: 56.2500 (39.1446)  Acc@5: 93.7500 (87.3665)  time: 0.3454  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2350/3125]  eta: 0:04:27  Lr: 0.030000  Loss: 0.8543  Acc@1: 50.0000 (39.1881)  Acc@5: 93.7500 (87.4016)  time: 0.3449  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [2360/3125]  eta: 0:04:23  Lr: 0.030000  Loss: 0.8502  Acc@1: 50.0000 (39.2366)  Acc@5: 93.7500 (87.4312)  time: 0.3448  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [2370/3125]  eta: 0:04:20  Lr: 0.030000  Loss: 0.7343  Acc@1: 50.0000 (39.3030)  Acc@5: 93.7500 (87.4552)  time: 0.3450  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [2380/3125]  eta: 0:04:17  Lr: 0.030000  Loss: 0.8413  Acc@1: 50.0000 (39.3611)  Acc@5: 93.7500 (87.4843)  time: 0.3445  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [2390/3125]  eta: 0:04:13  Lr: 0.030000  Loss: 0.6498  Acc@1: 56.2500 (39.4213)  Acc@5: 93.7500 (87.4948)  time: 0.3440  data: 0.0002  max mem: 2500
Train: Epoch[1/5]  [2400/3125]  eta: 0:04:10  Lr: 0.030000  Loss: 0.5844  Acc@1: 50.0000 (39.4601)  Acc@5: 93.7500 (87.5260)  time: 0.3437  data: 0.0002  max mem: 2500
Train: Epoch[1/5]  [2410/3125]  eta: 0:04:06  Lr: 0.030000  Loss: 0.7332  Acc@1: 50.0000 (39.5012)  Acc@5: 93.7500 (87.5389)  time: 0.3440  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [2420/3125]  eta: 0:04:03  Lr: 0.030000  Loss: 0.7534  Acc@1: 50.0000 (39.5498)  Acc@5: 93.7500 (87.5723)  time: 0.3444  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2430/3125]  eta: 0:03:59  Lr: 0.030000  Loss: 0.9295  Acc@1: 43.7500 (39.5671)  Acc@5: 93.7500 (87.5951)  time: 0.3449  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2440/3125]  eta: 0:03:56  Lr: 0.030000  Loss: 0.8771  Acc@1: 43.7500 (39.6149)  Acc@5: 93.7500 (87.6152)  time: 0.3447  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2450/3125]  eta: 0:03:52  Lr: 0.030000  Loss: 0.6146  Acc@1: 50.0000 (39.6675)  Acc@5: 93.7500 (87.6351)  time: 0.3443  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [2460/3125]  eta: 0:03:49  Lr: 0.030000  Loss: 0.7631  Acc@1: 50.0000 (39.7095)  Acc@5: 93.7500 (87.6549)  time: 0.3446  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [2470/3125]  eta: 0:03:45  Lr: 0.030000  Loss: 0.7997  Acc@1: 50.0000 (39.7511)  Acc@5: 93.7500 (87.6821)  time: 0.3444  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [2480/3125]  eta: 0:03:42  Lr: 0.030000  Loss: 0.7159  Acc@1: 50.0000 (39.8050)  Acc@5: 93.7500 (87.7015)  time: 0.3466  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [2490/3125]  eta: 0:03:39  Lr: 0.030000  Loss: 0.7159  Acc@1: 50.0000 (39.8510)  Acc@5: 93.7500 (87.7183)  time: 0.3455  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [2500/3125]  eta: 0:03:35  Lr: 0.030000  Loss: 0.8679  Acc@1: 56.2500 (39.9190)  Acc@5: 93.7500 (87.7474)  time: 0.3423  data: 0.0002  max mem: 2500
Train: Epoch[1/5]  [2510/3125]  eta: 0:03:32  Lr: 0.030000  Loss: 0.6113  Acc@1: 56.2500 (39.9965)  Acc@5: 100.0000 (87.7862)  time: 0.3423  data: 0.0002  max mem: 2500
Train: Epoch[1/5]  [2520/3125]  eta: 0:03:28  Lr: 0.030000  Loss: 0.6120  Acc@1: 56.2500 (40.0610)  Acc@5: 93.7500 (87.7975)  time: 0.3423  data: 0.0002  max mem: 2500
Train: Epoch[1/5]  [2530/3125]  eta: 0:03:25  Lr: 0.030000  Loss: 0.8093  Acc@1: 50.0000 (40.0904)  Acc@5: 93.7500 (87.8334)  time: 0.3423  data: 0.0002  max mem: 2500
Train: Epoch[1/5]  [2540/3125]  eta: 0:03:21  Lr: 0.030000  Loss: 0.7195  Acc@1: 50.0000 (40.1466)  Acc@5: 100.0000 (87.8665)  time: 0.3424  data: 0.0002  max mem: 2500
Train: Epoch[1/5]  [2550/3125]  eta: 0:03:18  Lr: 0.030000  Loss: 0.9405  Acc@1: 56.2500 (40.1901)  Acc@5: 93.7500 (87.8920)  time: 0.3425  data: 0.0002  max mem: 2500
Train: Epoch[1/5]  [2560/3125]  eta: 0:03:14  Lr: 0.030000  Loss: 0.6714  Acc@1: 56.2500 (40.2797)  Acc@5: 93.7500 (87.9173)  time: 0.3441  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [2570/3125]  eta: 0:03:11  Lr: 0.030000  Loss: 0.5068  Acc@1: 56.2500 (40.3223)  Acc@5: 93.7500 (87.9424)  time: 0.3457  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2580/3125]  eta: 0:03:07  Lr: 0.030000  Loss: 0.6396  Acc@1: 50.0000 (40.3768)  Acc@5: 93.7500 (87.9601)  time: 0.3458  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [2590/3125]  eta: 0:03:04  Lr: 0.030000  Loss: 0.8217  Acc@1: 50.0000 (40.4356)  Acc@5: 93.7500 (87.9873)  time: 0.3452  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2600/3125]  eta: 0:03:01  Lr: 0.030000  Loss: 0.6457  Acc@1: 56.2500 (40.5037)  Acc@5: 93.7500 (88.0238)  time: 0.3453  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2610/3125]  eta: 0:02:57  Lr: 0.030000  Loss: 0.8712  Acc@1: 56.2500 (40.5544)  Acc@5: 100.0000 (88.0482)  time: 0.3458  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2620/3125]  eta: 0:02:54  Lr: 0.030000  Loss: 0.7023  Acc@1: 50.0000 (40.5761)  Acc@5: 93.7500 (88.0604)  time: 0.3450  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2630/3125]  eta: 0:02:50  Lr: 0.030000  Loss: 0.8079  Acc@1: 50.0000 (40.6167)  Acc@5: 93.7500 (88.0844)  time: 0.3452  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2640/3125]  eta: 0:02:47  Lr: 0.030000  Loss: 0.5518  Acc@1: 50.0000 (40.6830)  Acc@5: 93.7500 (88.1082)  time: 0.3457  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2650/3125]  eta: 0:02:43  Lr: 0.030000  Loss: 0.5435  Acc@1: 56.2500 (40.7441)  Acc@5: 93.7500 (88.1413)  time: 0.3451  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2660/3125]  eta: 0:02:40  Lr: 0.030000  Loss: 0.5020  Acc@1: 56.2500 (40.7906)  Acc@5: 93.7500 (88.1530)  time: 0.3447  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2670/3125]  eta: 0:02:36  Lr: 0.030000  Loss: 0.7086  Acc@1: 56.2500 (40.8438)  Acc@5: 93.7500 (88.1809)  time: 0.3449  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2680/3125]  eta: 0:02:33  Lr: 0.030000  Loss: 0.7894  Acc@1: 56.2500 (40.8989)  Acc@5: 93.7500 (88.2040)  time: 0.3452  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2690/3125]  eta: 0:02:30  Lr: 0.030000  Loss: 0.7998  Acc@1: 50.0000 (40.9304)  Acc@5: 93.7500 (88.2293)  time: 0.3448  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2700/3125]  eta: 0:02:26  Lr: 0.030000  Loss: 0.8631  Acc@1: 43.7500 (40.9733)  Acc@5: 93.7500 (88.2451)  time: 0.3446  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [2710/3125]  eta: 0:02:23  Lr: 0.030000  Loss: 0.8661  Acc@1: 56.2500 (41.0342)  Acc@5: 93.7500 (88.2631)  time: 0.3446  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [2720/3125]  eta: 0:02:19  Lr: 0.030000  Loss: 0.6717  Acc@1: 56.2500 (41.0786)  Acc@5: 93.7500 (88.2924)  time: 0.3444  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [2730/3125]  eta: 0:02:16  Lr: 0.030000  Loss: 0.4581  Acc@1: 56.2500 (41.1250)  Acc@5: 93.7500 (88.3147)  time: 0.3442  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [2740/3125]  eta: 0:02:12  Lr: 0.030000  Loss: 0.6895  Acc@1: 50.0000 (41.1620)  Acc@5: 93.7500 (88.3345)  time: 0.3443  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [2750/3125]  eta: 0:02:09  Lr: 0.030000  Loss: 0.7283  Acc@1: 50.0000 (41.1918)  Acc@5: 93.7500 (88.3520)  time: 0.3453  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [2760/3125]  eta: 0:02:05  Lr: 0.030000  Loss: 0.4484  Acc@1: 56.2500 (41.2600)  Acc@5: 93.7500 (88.3670)  time: 0.3446  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [2770/3125]  eta: 0:02:02  Lr: 0.030000  Loss: 0.8145  Acc@1: 50.0000 (41.2870)  Acc@5: 93.7500 (88.3909)  time: 0.3429  data: 0.0002  max mem: 2500
Train: Epoch[1/5]  [2780/3125]  eta: 0:01:58  Lr: 0.030000  Loss: 0.6595  Acc@1: 43.7500 (41.3385)  Acc@5: 93.7500 (88.4169)  time: 0.3429  data: 0.0002  max mem: 2500
Train: Epoch[1/5]  [2790/3125]  eta: 0:01:55  Lr: 0.030000  Loss: 0.7758  Acc@1: 56.2500 (41.3920)  Acc@5: 93.7500 (88.4360)  time: 0.3433  data: 0.0002  max mem: 2500
Train: Epoch[1/5]  [2800/3125]  eta: 0:01:52  Lr: 0.030000  Loss: 0.6448  Acc@1: 56.2500 (41.4428)  Acc@5: 93.7500 (88.4572)  time: 0.3433  data: 0.0002  max mem: 2500
Train: Epoch[1/5]  [2810/3125]  eta: 0:01:48  Lr: 0.030000  Loss: 0.5812  Acc@1: 62.5000 (41.5066)  Acc@5: 93.7500 (88.4761)  time: 0.3434  data: 0.0002  max mem: 2500
Train: Epoch[1/5]  [2820/3125]  eta: 0:01:45  Lr: 0.030000  Loss: 0.6823  Acc@1: 56.2500 (41.5611)  Acc@5: 100.0000 (88.5103)  time: 0.3435  data: 0.0002  max mem: 2500
Train: Epoch[1/5]  [2830/3125]  eta: 0:01:41  Lr: 0.030000  Loss: 0.6860  Acc@1: 56.2500 (41.6152)  Acc@5: 100.0000 (88.5244)  time: 0.3443  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [2840/3125]  eta: 0:01:38  Lr: 0.030000  Loss: 0.9819  Acc@1: 50.0000 (41.6469)  Acc@5: 93.7500 (88.5318)  time: 0.3455  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [2850/3125]  eta: 0:01:34  Lr: 0.030000  Loss: 0.8479  Acc@1: 50.0000 (41.6915)  Acc@5: 93.7500 (88.5457)  time: 0.3457  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2860/3125]  eta: 0:01:31  Lr: 0.030000  Loss: 0.6666  Acc@1: 50.0000 (41.7424)  Acc@5: 93.7500 (88.5682)  time: 0.3459  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2870/3125]  eta: 0:01:27  Lr: 0.030000  Loss: 0.5866  Acc@1: 50.0000 (41.7995)  Acc@5: 93.7500 (88.5863)  time: 0.3460  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2880/3125]  eta: 0:01:24  Lr: 0.030000  Loss: 0.5753  Acc@1: 62.5000 (41.8496)  Acc@5: 93.7500 (88.6042)  time: 0.3457  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2890/3125]  eta: 0:01:21  Lr: 0.030000  Loss: 0.7046  Acc@1: 50.0000 (41.8929)  Acc@5: 93.7500 (88.6242)  time: 0.3462  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2900/3125]  eta: 0:01:17  Lr: 0.030000  Loss: 0.5992  Acc@1: 50.0000 (41.9338)  Acc@5: 93.7500 (88.6462)  time: 0.3465  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2910/3125]  eta: 0:01:14  Lr: 0.030000  Loss: 1.0200  Acc@1: 56.2500 (41.9830)  Acc@5: 93.7500 (88.6658)  time: 0.3457  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2920/3125]  eta: 0:01:10  Lr: 0.030000  Loss: 0.7253  Acc@1: 56.2500 (42.0383)  Acc@5: 93.7500 (88.6790)  time: 0.3459  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [2930/3125]  eta: 0:01:07  Lr: 0.030000  Loss: 0.6468  Acc@1: 56.2500 (42.0782)  Acc@5: 93.7500 (88.6984)  time: 0.3458  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2940/3125]  eta: 0:01:03  Lr: 0.030000  Loss: 0.9091  Acc@1: 50.0000 (42.1222)  Acc@5: 93.7500 (88.7007)  time: 0.3461  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2950/3125]  eta: 0:01:00  Lr: 0.030000  Loss: 0.4913  Acc@1: 56.2500 (42.1743)  Acc@5: 93.7500 (88.7242)  time: 0.3459  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2960/3125]  eta: 0:00:56  Lr: 0.030000  Loss: 0.7663  Acc@1: 56.2500 (42.2345)  Acc@5: 100.0000 (88.7538)  time: 0.3453  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [2970/3125]  eta: 0:00:53  Lr: 0.030000  Loss: 0.5150  Acc@1: 62.5000 (42.2985)  Acc@5: 100.0000 (88.7706)  time: 0.3453  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [2980/3125]  eta: 0:00:50  Lr: 0.030000  Loss: 0.6976  Acc@1: 62.5000 (42.3495)  Acc@5: 93.7500 (88.7894)  time: 0.3452  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [2990/3125]  eta: 0:00:46  Lr: 0.030000  Loss: 0.5742  Acc@1: 62.5000 (42.4168)  Acc@5: 100.0000 (88.8227)  time: 0.3456  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [3000/3125]  eta: 0:00:43  Lr: 0.030000  Loss: 0.6679  Acc@1: 62.5000 (42.4879)  Acc@5: 100.0000 (88.8558)  time: 0.3452  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [3010/3125]  eta: 0:00:39  Lr: 0.030000  Loss: 0.7662  Acc@1: 56.2500 (42.5066)  Acc@5: 100.0000 (88.8700)  time: 0.3448  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [3020/3125]  eta: 0:00:36  Lr: 0.030000  Loss: 0.8924  Acc@1: 50.0000 (42.5397)  Acc@5: 93.7500 (88.8779)  time: 0.3448  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [3030/3125]  eta: 0:00:32  Lr: 0.030000  Loss: 0.6425  Acc@1: 56.2500 (42.5870)  Acc@5: 93.7500 (88.8857)  time: 0.3442  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [3040/3125]  eta: 0:00:29  Lr: 0.030000  Loss: 0.6619  Acc@1: 56.2500 (42.6196)  Acc@5: 87.5000 (88.8955)  time: 0.3433  data: 0.0002  max mem: 2500
Train: Epoch[1/5]  [3050/3125]  eta: 0:00:25  Lr: 0.030000  Loss: 0.5656  Acc@1: 56.2500 (42.6766)  Acc@5: 93.7500 (88.9258)  time: 0.3431  data: 0.0002  max mem: 2500
Train: Epoch[1/5]  [3060/3125]  eta: 0:00:22  Lr: 0.030000  Loss: 0.8754  Acc@1: 62.5000 (42.7128)  Acc@5: 100.0000 (88.9415)  time: 0.3430  data: 0.0002  max mem: 2500
Train: Epoch[1/5]  [3070/3125]  eta: 0:00:18  Lr: 0.030000  Loss: 0.4637  Acc@1: 56.2500 (42.7711)  Acc@5: 93.7500 (88.9613)  time: 0.3429  data: 0.0002  max mem: 2500
Train: Epoch[1/5]  [3080/3125]  eta: 0:00:15  Lr: 0.030000  Loss: 0.4782  Acc@1: 62.5000 (42.8371)  Acc@5: 93.7500 (88.9788)  time: 0.3429  data: 0.0002  max mem: 2500
Train: Epoch[1/5]  [3090/3125]  eta: 0:00:12  Lr: 0.030000  Loss: 0.6053  Acc@1: 62.5000 (42.8785)  Acc@5: 100.0000 (89.0125)  time: 0.3429  data: 0.0002  max mem: 2500
Train: Epoch[1/5]  [3100/3125]  eta: 0:00:08  Lr: 0.030000  Loss: 0.7812  Acc@1: 56.2500 (42.9257)  Acc@5: 100.0000 (89.0318)  time: 0.3443  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [3110/3125]  eta: 0:00:05  Lr: 0.030000  Loss: 0.6808  Acc@1: 50.0000 (42.9564)  Acc@5: 93.7500 (89.0429)  time: 0.3459  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3120/3125]  eta: 0:00:01  Lr: 0.030000  Loss: 0.8167  Acc@1: 50.0000 (42.9610)  Acc@5: 93.7500 (89.0620)  time: 0.3462  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [3124/3125]  eta: 0:00:00  Lr: 0.030000  Loss: 0.6597  Acc@1: 50.0000 (42.9720)  Acc@5: 93.7500 (89.0720)  time: 0.3466  data: 0.0008  max mem: 2500
Train: Epoch[1/5] Total time: 0:17:58 (0.3450 s / it)
{0: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 1: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 2: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 3: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 4: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 5: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 6: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 7: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 8: {0: 0, 1: 0, 2: 50000, 3: 0, 4: 0}, 9: {0: 0, 1: 0, 2: 50000, 3: 0, 4: 0}, 10: {0: 0, 1: 0, 2: 50000, 3: 0, 4: 0}, 11: {0: 0, 1: 0, 2: 50000, 3: 0, 4: 0}, 12: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 13: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 14: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 15: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 16: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 17: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 18: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 19: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}}
Averaged stats: Lr: 0.030000  Loss: 0.6597  Acc@1: 50.0000 (42.9720)  Acc@5: 93.7500 (89.0720)
Train: Epoch[2/5]  [   0/3125]  eta: 0:35:38  Lr: 0.030000  Loss: 0.5058  Acc@1: 68.7500 (68.7500)  Acc@5: 93.7500 (93.7500)  time: 0.6844  data: 0.3324  max mem: 2500
Train: Epoch[2/5]  [  10/3125]  eta: 0:19:31  Lr: 0.030000  Loss: 0.5804  Acc@1: 56.2500 (52.2727)  Acc@5: 93.7500 (93.1818)  time: 0.3761  data: 0.0305  max mem: 2500
Train: Epoch[2/5]  [  20/3125]  eta: 0:18:41  Lr: 0.030000  Loss: 0.5423  Acc@1: 56.2500 (55.6548)  Acc@5: 93.7500 (95.2381)  time: 0.3450  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [  30/3125]  eta: 0:18:20  Lr: 0.030000  Loss: 0.5885  Acc@1: 56.2500 (56.6532)  Acc@5: 93.7500 (94.5565)  time: 0.3445  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [  40/3125]  eta: 0:18:08  Lr: 0.030000  Loss: 0.8498  Acc@1: 62.5000 (58.0793)  Acc@5: 93.7500 (95.1220)  time: 0.3443  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [  50/3125]  eta: 0:18:00  Lr: 0.030000  Loss: 0.6346  Acc@1: 62.5000 (57.9657)  Acc@5: 100.0000 (95.3431)  time: 0.3445  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [  60/3125]  eta: 0:17:52  Lr: 0.030000  Loss: 0.8786  Acc@1: 56.2500 (58.0943)  Acc@5: 93.7500 (95.0820)  time: 0.3442  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [  70/3125]  eta: 0:17:47  Lr: 0.030000  Loss: 0.7127  Acc@1: 50.0000 (57.2183)  Acc@5: 93.7500 (95.1585)  time: 0.3447  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [  80/3125]  eta: 0:17:42  Lr: 0.030000  Loss: 0.6845  Acc@1: 50.0000 (56.2500)  Acc@5: 93.7500 (94.7531)  time: 0.3450  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [  90/3125]  eta: 0:17:37  Lr: 0.030000  Loss: 0.5846  Acc@1: 50.0000 (56.5247)  Acc@5: 93.7500 (94.5742)  time: 0.3444  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 100/3125]  eta: 0:17:32  Lr: 0.030000  Loss: 0.6752  Acc@1: 50.0000 (56.0025)  Acc@5: 93.7500 (94.4926)  time: 0.3445  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 110/3125]  eta: 0:17:27  Lr: 0.030000  Loss: 1.0424  Acc@1: 50.0000 (55.4054)  Acc@5: 93.7500 (94.4257)  time: 0.3442  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [ 120/3125]  eta: 0:17:23  Lr: 0.030000  Loss: 0.6209  Acc@1: 56.2500 (55.5269)  Acc@5: 93.7500 (94.3698)  time: 0.3442  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [ 130/3125]  eta: 0:17:20  Lr: 0.030000  Loss: 0.6426  Acc@1: 62.5000 (55.6775)  Acc@5: 93.7500 (94.2748)  time: 0.3453  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [ 140/3125]  eta: 0:17:15  Lr: 0.030000  Loss: 0.8635  Acc@1: 62.5000 (55.6738)  Acc@5: 93.7500 (94.3262)  time: 0.3454  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [ 150/3125]  eta: 0:17:12  Lr: 0.030000  Loss: 0.6752  Acc@1: 56.2500 (55.6705)  Acc@5: 93.7500 (94.3709)  time: 0.3447  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [ 160/3125]  eta: 0:17:08  Lr: 0.030000  Loss: 0.7567  Acc@1: 56.2500 (55.5512)  Acc@5: 93.7500 (94.2547)  time: 0.3446  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [ 170/3125]  eta: 0:17:04  Lr: 0.030000  Loss: 0.6486  Acc@1: 56.2500 (55.5190)  Acc@5: 93.7500 (94.1520)  time: 0.3445  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [ 180/3125]  eta: 0:17:00  Lr: 0.030000  Loss: 0.6071  Acc@1: 56.2500 (55.5939)  Acc@5: 93.7500 (94.2334)  time: 0.3435  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [ 190/3125]  eta: 0:16:56  Lr: 0.030000  Loss: 0.6241  Acc@1: 56.2500 (55.4647)  Acc@5: 93.7500 (94.0772)  time: 0.3425  data: 0.0002  max mem: 2500
Train: Epoch[2/5]  [ 200/3125]  eta: 0:16:52  Lr: 0.030000  Loss: 0.5536  Acc@1: 56.2500 (55.5659)  Acc@5: 93.7500 (94.0299)  time: 0.3427  data: 0.0002  max mem: 2500
Train: Epoch[2/5]  [ 210/3125]  eta: 0:16:48  Lr: 0.030000  Loss: 0.7761  Acc@1: 62.5000 (55.7168)  Acc@5: 100.0000 (94.2536)  time: 0.3428  data: 0.0002  max mem: 2500
Train: Epoch[2/5]  [ 220/3125]  eta: 0:16:44  Lr: 0.030000  Loss: 0.6471  Acc@1: 56.2500 (55.7692)  Acc@5: 100.0000 (94.3156)  time: 0.3428  data: 0.0002  max mem: 2500
Train: Epoch[2/5]  [ 230/3125]  eta: 0:16:40  Lr: 0.030000  Loss: 0.4967  Acc@1: 56.2500 (55.8983)  Acc@5: 93.7500 (94.2911)  time: 0.3425  data: 0.0002  max mem: 2500
Train: Epoch[2/5]  [ 240/3125]  eta: 0:16:36  Lr: 0.030000  Loss: 0.5784  Acc@1: 56.2500 (55.8869)  Acc@5: 93.7500 (94.3724)  time: 0.3425  data: 0.0002  max mem: 2500
Train: Epoch[2/5]  [ 250/3125]  eta: 0:16:32  Lr: 0.030000  Loss: 0.7606  Acc@1: 62.5000 (56.0508)  Acc@5: 93.7500 (94.3974)  time: 0.3426  data: 0.0002  max mem: 2500
Train: Epoch[2/5]  [ 260/3125]  eta: 0:16:29  Lr: 0.030000  Loss: 0.5299  Acc@1: 62.5000 (56.1782)  Acc@5: 93.7500 (94.2768)  time: 0.3436  data: 0.0002  max mem: 2500
Train: Epoch[2/5]  [ 270/3125]  eta: 0:16:25  Lr: 0.030000  Loss: 0.6108  Acc@1: 62.5000 (56.4114)  Acc@5: 100.0000 (94.3958)  time: 0.3453  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [ 280/3125]  eta: 0:16:22  Lr: 0.030000  Loss: 0.6284  Acc@1: 62.5000 (56.6726)  Acc@5: 100.0000 (94.4617)  time: 0.3460  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 290/3125]  eta: 0:16:19  Lr: 0.030000  Loss: 0.4452  Acc@1: 56.2500 (56.8299)  Acc@5: 93.7500 (94.4588)  time: 0.3456  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 300/3125]  eta: 0:16:15  Lr: 0.030000  Loss: 0.6535  Acc@1: 56.2500 (56.8106)  Acc@5: 93.7500 (94.3729)  time: 0.3458  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 310/3125]  eta: 0:16:12  Lr: 0.030000  Loss: 0.6732  Acc@1: 62.5000 (56.9534)  Acc@5: 93.7500 (94.3730)  time: 0.3465  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 320/3125]  eta: 0:16:08  Lr: 0.030000  Loss: 0.4291  Acc@1: 68.7500 (57.3014)  Acc@5: 93.7500 (94.4509)  time: 0.3454  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 330/3125]  eta: 0:16:05  Lr: 0.030000  Loss: 0.6582  Acc@1: 62.5000 (57.3640)  Acc@5: 100.0000 (94.5431)  time: 0.3454  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [ 340/3125]  eta: 0:16:01  Lr: 0.030000  Loss: 0.4126  Acc@1: 62.5000 (57.4780)  Acc@5: 93.7500 (94.5565)  time: 0.3456  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 350/3125]  eta: 0:15:58  Lr: 0.030000  Loss: 0.6022  Acc@1: 62.5000 (57.5321)  Acc@5: 93.7500 (94.5335)  time: 0.3455  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 360/3125]  eta: 0:15:55  Lr: 0.030000  Loss: 0.4629  Acc@1: 56.2500 (57.5658)  Acc@5: 100.0000 (94.5291)  time: 0.3464  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 370/3125]  eta: 0:15:51  Lr: 0.030000  Loss: 0.5421  Acc@1: 62.5000 (57.7830)  Acc@5: 100.0000 (94.5923)  time: 0.3456  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 380/3125]  eta: 0:15:48  Lr: 0.030000  Loss: 0.6364  Acc@1: 62.5000 (57.7920)  Acc@5: 93.7500 (94.6194)  time: 0.3451  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 390/3125]  eta: 0:15:44  Lr: 0.030000  Loss: 0.5840  Acc@1: 56.2500 (57.9284)  Acc@5: 93.7500 (94.6611)  time: 0.3458  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 400/3125]  eta: 0:15:41  Lr: 0.030000  Loss: 0.5146  Acc@1: 56.2500 (57.8554)  Acc@5: 100.0000 (94.7163)  time: 0.3464  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 410/3125]  eta: 0:15:38  Lr: 0.030000  Loss: 0.4291  Acc@1: 56.2500 (57.8619)  Acc@5: 93.7500 (94.7536)  time: 0.3468  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 420/3125]  eta: 0:15:34  Lr: 0.030000  Loss: 0.6929  Acc@1: 56.2500 (57.8682)  Acc@5: 93.7500 (94.7595)  time: 0.3466  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [ 430/3125]  eta: 0:15:31  Lr: 0.030000  Loss: 0.6773  Acc@1: 43.7500 (57.4826)  Acc@5: 93.7500 (94.6636)  time: 0.3455  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 440/3125]  eta: 0:15:27  Lr: 0.030000  Loss: 0.5640  Acc@1: 43.7500 (57.3980)  Acc@5: 93.7500 (94.6712)  time: 0.3446  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [ 450/3125]  eta: 0:15:24  Lr: 0.030000  Loss: 0.6778  Acc@1: 56.2500 (57.4141)  Acc@5: 93.7500 (94.6646)  time: 0.3450  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [ 460/3125]  eta: 0:15:20  Lr: 0.030000  Loss: 0.5841  Acc@1: 56.2500 (57.4837)  Acc@5: 93.7500 (94.6855)  time: 0.3453  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [ 470/3125]  eta: 0:15:17  Lr: 0.030000  Loss: 0.5752  Acc@1: 56.2500 (57.5637)  Acc@5: 93.7500 (94.6656)  time: 0.3448  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [ 480/3125]  eta: 0:15:13  Lr: 0.030000  Loss: 0.4659  Acc@1: 56.2500 (57.5624)  Acc@5: 93.7500 (94.6985)  time: 0.3445  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [ 490/3125]  eta: 0:15:10  Lr: 0.030000  Loss: 0.4266  Acc@1: 56.2500 (57.5738)  Acc@5: 100.0000 (94.7811)  time: 0.3445  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [ 500/3125]  eta: 0:15:06  Lr: 0.030000  Loss: 0.5510  Acc@1: 56.2500 (57.6223)  Acc@5: 100.0000 (94.7979)  time: 0.3447  data: 0.0002  max mem: 2500
Train: Epoch[2/5]  [ 510/3125]  eta: 0:15:03  Lr: 0.030000  Loss: 0.7417  Acc@1: 56.2500 (57.5954)  Acc@5: 100.0000 (94.8508)  time: 0.3439  data: 0.0002  max mem: 2500
Train: Epoch[2/5]  [ 520/3125]  eta: 0:14:59  Lr: 0.030000  Loss: 0.3410  Acc@1: 56.2500 (57.7135)  Acc@5: 100.0000 (94.9136)  time: 0.3430  data: 0.0002  max mem: 2500
Train: Epoch[2/5]  [ 530/3125]  eta: 0:14:56  Lr: 0.030000  Loss: 0.5321  Acc@1: 56.2500 (57.6742)  Acc@5: 100.0000 (94.9153)  time: 0.3431  data: 0.0002  max mem: 2500
Train: Epoch[2/5]  [ 540/3125]  eta: 0:14:52  Lr: 0.030000  Loss: 0.4987  Acc@1: 62.5000 (57.7750)  Acc@5: 93.7500 (94.9630)  time: 0.3428  data: 0.0002  max mem: 2500
Train: Epoch[2/5]  [ 550/3125]  eta: 0:14:48  Lr: 0.030000  Loss: 0.7214  Acc@1: 62.5000 (57.8607)  Acc@5: 93.7500 (94.9410)  time: 0.3435  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [ 560/3125]  eta: 0:14:45  Lr: 0.030000  Loss: 0.6280  Acc@1: 62.5000 (57.9768)  Acc@5: 93.7500 (94.9198)  time: 0.3449  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [ 570/3125]  eta: 0:14:42  Lr: 0.030000  Loss: 0.6936  Acc@1: 62.5000 (58.0560)  Acc@5: 93.7500 (94.8336)  time: 0.3452  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 580/3125]  eta: 0:14:38  Lr: 0.030000  Loss: 0.6038  Acc@1: 56.2500 (57.9604)  Acc@5: 93.7500 (94.7827)  time: 0.3452  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 590/3125]  eta: 0:14:35  Lr: 0.030000  Loss: 0.7346  Acc@1: 50.0000 (57.9315)  Acc@5: 93.7500 (94.8075)  time: 0.3446  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 600/3125]  eta: 0:14:31  Lr: 0.030000  Loss: 0.7127  Acc@1: 50.0000 (57.8723)  Acc@5: 93.7500 (94.8003)  time: 0.3443  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [ 610/3125]  eta: 0:14:28  Lr: 0.030000  Loss: 0.7346  Acc@1: 56.2500 (57.8969)  Acc@5: 100.0000 (94.8445)  time: 0.3452  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [ 620/3125]  eta: 0:14:24  Lr: 0.030000  Loss: 0.5767  Acc@1: 62.5000 (57.9911)  Acc@5: 100.0000 (94.8671)  time: 0.3454  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 630/3125]  eta: 0:14:21  Lr: 0.030000  Loss: 0.4022  Acc@1: 62.5000 (57.9338)  Acc@5: 93.7500 (94.8693)  time: 0.3452  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 640/3125]  eta: 0:14:17  Lr: 0.030000  Loss: 0.7792  Acc@1: 56.2500 (57.9368)  Acc@5: 93.7500 (94.8518)  time: 0.3451  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [ 650/3125]  eta: 0:14:14  Lr: 0.030000  Loss: 0.5554  Acc@1: 62.5000 (58.0165)  Acc@5: 100.0000 (94.9021)  time: 0.3449  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [ 660/3125]  eta: 0:14:10  Lr: 0.030000  Loss: 0.6481  Acc@1: 62.5000 (58.0654)  Acc@5: 100.0000 (94.9319)  time: 0.3451  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [ 670/3125]  eta: 0:14:07  Lr: 0.030000  Loss: 0.4319  Acc@1: 56.2500 (58.0663)  Acc@5: 100.0000 (94.9888)  time: 0.3450  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [ 680/3125]  eta: 0:14:03  Lr: 0.030000  Loss: 0.6286  Acc@1: 62.5000 (58.1406)  Acc@5: 100.0000 (95.0165)  time: 0.3446  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [ 690/3125]  eta: 0:14:00  Lr: 0.030000  Loss: 0.4446  Acc@1: 62.5000 (58.1585)  Acc@5: 100.0000 (95.0434)  time: 0.3449  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [ 700/3125]  eta: 0:13:57  Lr: 0.030000  Loss: 0.5602  Acc@1: 62.5000 (58.1758)  Acc@5: 100.0000 (95.0339)  time: 0.3445  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [ 710/3125]  eta: 0:13:53  Lr: 0.030000  Loss: 0.7570  Acc@1: 56.2500 (58.1839)  Acc@5: 93.7500 (94.9895)  time: 0.3438  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [ 720/3125]  eta: 0:13:50  Lr: 0.030000  Loss: 0.4858  Acc@1: 62.5000 (58.2351)  Acc@5: 93.7500 (94.9809)  time: 0.3439  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [ 730/3125]  eta: 0:13:46  Lr: 0.030000  Loss: 0.7597  Acc@1: 62.5000 (58.2165)  Acc@5: 93.7500 (94.9726)  time: 0.3447  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [ 740/3125]  eta: 0:13:43  Lr: 0.030000  Loss: 0.4287  Acc@1: 56.2500 (58.2068)  Acc@5: 93.7500 (94.9814)  time: 0.3452  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 750/3125]  eta: 0:13:39  Lr: 0.030000  Loss: 0.6068  Acc@1: 62.5000 (58.2557)  Acc@5: 100.0000 (95.0067)  time: 0.3451  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 760/3125]  eta: 0:13:36  Lr: 0.030000  Loss: 0.6010  Acc@1: 62.5000 (58.2950)  Acc@5: 93.7500 (95.0148)  time: 0.3456  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [ 770/3125]  eta: 0:13:32  Lr: 0.030000  Loss: 0.6802  Acc@1: 62.5000 (58.4225)  Acc@5: 93.7500 (95.0308)  time: 0.3455  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 780/3125]  eta: 0:13:29  Lr: 0.030000  Loss: 0.7550  Acc@1: 62.5000 (58.4427)  Acc@5: 93.7500 (95.0384)  time: 0.3459  data: 0.0010  max mem: 2500
Train: Epoch[2/5]  [ 790/3125]  eta: 0:13:25  Lr: 0.030000  Loss: 0.5033  Acc@1: 56.2500 (58.3992)  Acc@5: 93.7500 (95.0379)  time: 0.3456  data: 0.0010  max mem: 2500
Train: Epoch[2/5]  [ 800/3125]  eta: 0:13:22  Lr: 0.030000  Loss: 0.6472  Acc@1: 56.2500 (58.3958)  Acc@5: 93.7500 (95.0375)  time: 0.3454  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [ 810/3125]  eta: 0:13:19  Lr: 0.030000  Loss: 0.5731  Acc@1: 56.2500 (58.3770)  Acc@5: 93.7500 (95.0447)  time: 0.3454  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [ 820/3125]  eta: 0:13:15  Lr: 0.030000  Loss: 0.5225  Acc@1: 56.2500 (58.3739)  Acc@5: 93.7500 (95.0213)  time: 0.3449  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [ 830/3125]  eta: 0:13:12  Lr: 0.030000  Loss: 0.6353  Acc@1: 56.2500 (58.3634)  Acc@5: 93.7500 (95.0135)  time: 0.3448  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [ 840/3125]  eta: 0:13:08  Lr: 0.030000  Loss: 0.6937  Acc@1: 56.2500 (58.3977)  Acc@5: 93.7500 (95.0282)  time: 0.3464  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 850/3125]  eta: 0:13:05  Lr: 0.030000  Loss: 0.5324  Acc@1: 56.2500 (58.4239)  Acc@5: 100.0000 (95.0426)  time: 0.3464  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 860/3125]  eta: 0:13:01  Lr: 0.030000  Loss: 0.8097  Acc@1: 56.2500 (58.4495)  Acc@5: 93.7500 (95.0494)  time: 0.3441  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [ 870/3125]  eta: 0:12:58  Lr: 0.030000  Loss: 0.4934  Acc@1: 56.2500 (58.4745)  Acc@5: 93.7500 (95.0560)  time: 0.3436  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [ 880/3125]  eta: 0:12:54  Lr: 0.030000  Loss: 0.4830  Acc@1: 62.5000 (58.5131)  Acc@5: 100.0000 (95.0624)  time: 0.3433  data: 0.0002  max mem: 2500
Train: Epoch[2/5]  [ 890/3125]  eta: 0:12:51  Lr: 0.030000  Loss: 0.7957  Acc@1: 68.7500 (58.6139)  Acc@5: 100.0000 (95.0968)  time: 0.3433  data: 0.0002  max mem: 2500
Train: Epoch[2/5]  [ 900/3125]  eta: 0:12:47  Lr: 0.030000  Loss: 0.7101  Acc@1: 62.5000 (58.6779)  Acc@5: 100.0000 (95.1027)  time: 0.3436  data: 0.0002  max mem: 2500
Train: Epoch[2/5]  [ 910/3125]  eta: 0:12:44  Lr: 0.030000  Loss: 0.7503  Acc@1: 62.5000 (58.7473)  Acc@5: 93.7500 (95.0947)  time: 0.3438  data: 0.0002  max mem: 2500
Train: Epoch[2/5]  [ 920/3125]  eta: 0:12:40  Lr: 0.030000  Loss: 0.3658  Acc@1: 68.7500 (58.7744)  Acc@5: 93.7500 (95.1208)  time: 0.3438  data: 0.0002  max mem: 2500
Train: Epoch[2/5]  [ 930/3125]  eta: 0:12:37  Lr: 0.030000  Loss: 0.4170  Acc@1: 62.5000 (58.8413)  Acc@5: 100.0000 (95.1329)  time: 0.3439  data: 0.0002  max mem: 2500
Train: Epoch[2/5]  [ 940/3125]  eta: 0:12:33  Lr: 0.030000  Loss: 0.6230  Acc@1: 62.5000 (58.7938)  Acc@5: 93.7500 (95.1182)  time: 0.3439  data: 0.0002  max mem: 2500
Train: Epoch[2/5]  [ 950/3125]  eta: 0:12:30  Lr: 0.030000  Loss: 0.5015  Acc@1: 62.5000 (58.8065)  Acc@5: 93.7500 (95.1170)  time: 0.3450  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 960/3125]  eta: 0:12:27  Lr: 0.030000  Loss: 0.6298  Acc@1: 62.5000 (58.8840)  Acc@5: 93.7500 (95.1158)  time: 0.3467  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [ 970/3125]  eta: 0:12:23  Lr: 0.030000  Loss: 0.6283  Acc@1: 68.7500 (58.9598)  Acc@5: 93.7500 (95.1210)  time: 0.3469  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 980/3125]  eta: 0:12:20  Lr: 0.030000  Loss: 0.3833  Acc@1: 62.5000 (58.9577)  Acc@5: 93.7500 (95.1198)  time: 0.3470  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 990/3125]  eta: 0:12:16  Lr: 0.030000  Loss: 0.5402  Acc@1: 62.5000 (58.9997)  Acc@5: 93.7500 (95.1312)  time: 0.3466  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1000/3125]  eta: 0:12:13  Lr: 0.030000  Loss: 0.5105  Acc@1: 62.5000 (58.9723)  Acc@5: 100.0000 (95.1361)  time: 0.3457  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1010/3125]  eta: 0:12:09  Lr: 0.030000  Loss: 0.7523  Acc@1: 56.2500 (58.9701)  Acc@5: 93.7500 (95.1224)  time: 0.3458  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1020/3125]  eta: 0:12:06  Lr: 0.030000  Loss: 0.6968  Acc@1: 56.2500 (58.9802)  Acc@5: 93.7500 (95.1151)  time: 0.3462  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1030/3125]  eta: 0:12:03  Lr: 0.030000  Loss: 0.5665  Acc@1: 62.5000 (58.9901)  Acc@5: 100.0000 (95.1443)  time: 0.3463  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1040/3125]  eta: 0:11:59  Lr: 0.030000  Loss: 0.5123  Acc@1: 56.2500 (58.9637)  Acc@5: 93.7500 (95.1369)  time: 0.3460  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1050/3125]  eta: 0:11:56  Lr: 0.030000  Loss: 0.4989  Acc@1: 50.0000 (58.9617)  Acc@5: 93.7500 (95.1475)  time: 0.3458  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1060/3125]  eta: 0:11:52  Lr: 0.030000  Loss: 0.5532  Acc@1: 50.0000 (58.9185)  Acc@5: 93.7500 (95.1166)  time: 0.3462  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1070/3125]  eta: 0:11:49  Lr: 0.030000  Loss: 0.3572  Acc@1: 62.5000 (58.9577)  Acc@5: 93.7500 (95.1447)  time: 0.3460  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1080/3125]  eta: 0:11:45  Lr: 0.030000  Loss: 0.4722  Acc@1: 62.5000 (58.9327)  Acc@5: 100.0000 (95.1376)  time: 0.3478  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1090/3125]  eta: 0:11:42  Lr: 0.030000  Loss: 0.4813  Acc@1: 56.2500 (58.9482)  Acc@5: 93.7500 (95.1421)  time: 0.3486  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1100/3125]  eta: 0:11:39  Lr: 0.030000  Loss: 0.6648  Acc@1: 62.5000 (58.9521)  Acc@5: 100.0000 (95.1578)  time: 0.3474  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1110/3125]  eta: 0:11:35  Lr: 0.030000  Loss: 0.6507  Acc@1: 62.5000 (58.9334)  Acc@5: 93.7500 (95.1395)  time: 0.3468  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1120/3125]  eta: 0:11:32  Lr: 0.030000  Loss: 0.5772  Acc@1: 56.2500 (58.9541)  Acc@5: 93.7500 (95.1327)  time: 0.3453  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1130/3125]  eta: 0:11:28  Lr: 0.030000  Loss: 0.5288  Acc@1: 62.5000 (59.0075)  Acc@5: 100.0000 (95.1647)  time: 0.3447  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [1140/3125]  eta: 0:11:25  Lr: 0.030000  Loss: 0.6516  Acc@1: 56.2500 (59.0326)  Acc@5: 93.7500 (95.1632)  time: 0.3454  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [1150/3125]  eta: 0:11:21  Lr: 0.030000  Loss: 0.4659  Acc@1: 56.2500 (59.0139)  Acc@5: 93.7500 (95.1455)  time: 0.3455  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [1160/3125]  eta: 0:11:18  Lr: 0.030000  Loss: 0.5750  Acc@1: 62.5000 (59.0816)  Acc@5: 93.7500 (95.1658)  time: 0.3449  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [1170/3125]  eta: 0:11:14  Lr: 0.030000  Loss: 0.7924  Acc@1: 56.2500 (58.9880)  Acc@5: 93.7500 (95.1324)  time: 0.3449  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [1180/3125]  eta: 0:11:11  Lr: 0.030000  Loss: 0.8020  Acc@1: 50.0000 (58.9754)  Acc@5: 93.7500 (95.1524)  time: 0.3449  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [1190/3125]  eta: 0:11:08  Lr: 0.030000  Loss: 0.5641  Acc@1: 62.5000 (59.0575)  Acc@5: 93.7500 (95.1406)  time: 0.3444  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [1200/3125]  eta: 0:11:04  Lr: 0.030000  Loss: 0.4249  Acc@1: 62.5000 (59.0758)  Acc@5: 93.7500 (95.1395)  time: 0.3440  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [1210/3125]  eta: 0:11:01  Lr: 0.030000  Loss: 0.4926  Acc@1: 62.5000 (59.0628)  Acc@5: 93.7500 (95.1280)  time: 0.3440  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [1220/3125]  eta: 0:10:57  Lr: 0.030000  Loss: 0.6093  Acc@1: 56.2500 (59.0500)  Acc@5: 93.7500 (95.1321)  time: 0.3450  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [1230/3125]  eta: 0:10:54  Lr: 0.030000  Loss: 0.4597  Acc@1: 56.2500 (59.0526)  Acc@5: 93.7500 (95.1462)  time: 0.3462  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1240/3125]  eta: 0:10:50  Lr: 0.030000  Loss: 0.4807  Acc@1: 62.5000 (59.0502)  Acc@5: 100.0000 (95.1551)  time: 0.3453  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [1250/3125]  eta: 0:10:47  Lr: 0.030000  Loss: 0.4767  Acc@1: 56.2500 (59.0977)  Acc@5: 100.0000 (95.1789)  time: 0.3444  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [1260/3125]  eta: 0:10:43  Lr: 0.030000  Loss: 0.6151  Acc@1: 62.5000 (59.1148)  Acc@5: 100.0000 (95.2072)  time: 0.3449  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1270/3125]  eta: 0:10:40  Lr: 0.030000  Loss: 0.3637  Acc@1: 62.5000 (59.1414)  Acc@5: 100.0000 (95.1957)  time: 0.3449  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1280/3125]  eta: 0:10:36  Lr: 0.030000  Loss: 0.6059  Acc@1: 62.5000 (59.1579)  Acc@5: 93.7500 (95.2088)  time: 0.3444  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1290/3125]  eta: 0:10:33  Lr: 0.030000  Loss: 0.6604  Acc@1: 56.2500 (59.1354)  Acc@5: 100.0000 (95.2169)  time: 0.3447  data: 0.0002  max mem: 2500
Train: Epoch[2/5]  [1300/3125]  eta: 0:10:30  Lr: 0.030000  Loss: 0.3111  Acc@1: 62.5000 (59.1900)  Acc@5: 93.7500 (95.2200)  time: 0.3450  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [1310/3125]  eta: 0:10:26  Lr: 0.030000  Loss: 0.6100  Acc@1: 62.5000 (59.2105)  Acc@5: 93.7500 (95.2231)  time: 0.3448  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [1320/3125]  eta: 0:10:23  Lr: 0.030000  Loss: 0.3864  Acc@1: 62.5000 (59.2212)  Acc@5: 100.0000 (95.2403)  time: 0.3449  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [1330/3125]  eta: 0:10:19  Lr: 0.030000  Loss: 0.7115  Acc@1: 56.2500 (59.2224)  Acc@5: 100.0000 (95.2245)  time: 0.3465  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [1340/3125]  eta: 0:10:16  Lr: 0.030000  Loss: 0.4897  Acc@1: 56.2500 (59.2562)  Acc@5: 93.7500 (95.2274)  time: 0.3459  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [1350/3125]  eta: 0:10:12  Lr: 0.030000  Loss: 0.5412  Acc@1: 56.2500 (59.2339)  Acc@5: 93.7500 (95.2258)  time: 0.3434  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [1360/3125]  eta: 0:10:09  Lr: 0.030000  Loss: 0.5674  Acc@1: 56.2500 (59.2258)  Acc@5: 100.0000 (95.2425)  time: 0.3434  data: 0.0002  max mem: 2500
Train: Epoch[2/5]  [1370/3125]  eta: 0:10:05  Lr: 0.030000  Loss: 0.5945  Acc@1: 56.2500 (59.2086)  Acc@5: 100.0000 (95.2589)  time: 0.3438  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [1380/3125]  eta: 0:10:02  Lr: 0.030000  Loss: 0.5171  Acc@1: 62.5000 (59.2279)  Acc@5: 100.0000 (95.2797)  time: 0.3440  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [1390/3125]  eta: 0:09:58  Lr: 0.030000  Loss: 0.6857  Acc@1: 56.2500 (59.1661)  Acc@5: 100.0000 (95.2597)  time: 0.3439  data: 0.0002  max mem: 2500
Train: Epoch[2/5]  [1400/3125]  eta: 0:09:55  Lr: 0.030000  Loss: 0.5446  Acc@1: 56.2500 (59.1720)  Acc@5: 93.7500 (95.2489)  time: 0.3437  data: 0.0002  max mem: 2500
Train: Epoch[2/5]  [1410/3125]  eta: 0:09:51  Lr: 0.030000  Loss: 0.4987  Acc@1: 62.5000 (59.1646)  Acc@5: 100.0000 (95.2605)  time: 0.3439  data: 0.0002  max mem: 2500
Train: Epoch[2/5]  [1420/3125]  eta: 0:09:48  Lr: 0.030000  Loss: 0.5700  Acc@1: 62.5000 (59.1969)  Acc@5: 93.7500 (95.2630)  time: 0.3438  data: 0.0002  max mem: 2500
Train: Epoch[2/5]  [1430/3125]  eta: 0:09:44  Lr: 0.030000  Loss: 0.5702  Acc@1: 62.5000 (59.2200)  Acc@5: 93.7500 (95.2787)  time: 0.3442  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [1440/3125]  eta: 0:09:41  Lr: 0.030000  Loss: 0.5468  Acc@1: 62.5000 (59.2340)  Acc@5: 100.0000 (95.2811)  time: 0.3471  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1450/3125]  eta: 0:09:38  Lr: 0.030000  Loss: 0.3538  Acc@1: 62.5000 (59.2953)  Acc@5: 93.7500 (95.2705)  time: 0.3488  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1460/3125]  eta: 0:09:34  Lr: 0.030000  Loss: 0.5724  Acc@1: 68.7500 (59.3472)  Acc@5: 93.7500 (95.2687)  time: 0.3473  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1470/3125]  eta: 0:09:31  Lr: 0.030000  Loss: 0.5350  Acc@1: 68.7500 (59.3899)  Acc@5: 93.7500 (95.2668)  time: 0.3464  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1480/3125]  eta: 0:09:27  Lr: 0.030000  Loss: 0.4950  Acc@1: 56.2500 (59.3771)  Acc@5: 93.7500 (95.2524)  time: 0.3463  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1490/3125]  eta: 0:09:24  Lr: 0.030000  Loss: 0.6462  Acc@1: 56.2500 (59.3645)  Acc@5: 93.7500 (95.2381)  time: 0.3454  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1500/3125]  eta: 0:09:20  Lr: 0.030000  Loss: 0.6006  Acc@1: 62.5000 (59.4104)  Acc@5: 93.7500 (95.2490)  time: 0.3457  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1510/3125]  eta: 0:09:17  Lr: 0.030000  Loss: 0.2911  Acc@1: 68.7500 (59.4515)  Acc@5: 100.0000 (95.2598)  time: 0.3459  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1520/3125]  eta: 0:09:14  Lr: 0.030000  Loss: 0.2821  Acc@1: 62.5000 (59.4551)  Acc@5: 100.0000 (95.2704)  time: 0.3463  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1530/3125]  eta: 0:09:10  Lr: 0.030000  Loss: 0.6707  Acc@1: 56.2500 (59.4424)  Acc@5: 100.0000 (95.2809)  time: 0.3467  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1540/3125]  eta: 0:09:07  Lr: 0.030000  Loss: 0.4561  Acc@1: 56.2500 (59.4581)  Acc@5: 100.0000 (95.2831)  time: 0.3459  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1550/3125]  eta: 0:09:03  Lr: 0.030000  Loss: 0.7379  Acc@1: 56.2500 (59.4173)  Acc@5: 100.0000 (95.2813)  time: 0.3456  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1560/3125]  eta: 0:09:00  Lr: 0.030000  Loss: 0.6520  Acc@1: 56.2500 (59.4250)  Acc@5: 93.7500 (95.2795)  time: 0.3459  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1570/3125]  eta: 0:08:56  Lr: 0.030000  Loss: 0.4099  Acc@1: 62.5000 (59.4566)  Acc@5: 93.7500 (95.2896)  time: 0.3473  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1580/3125]  eta: 0:08:53  Lr: 0.030000  Loss: 0.4800  Acc@1: 68.7500 (59.5193)  Acc@5: 93.7500 (95.2957)  time: 0.3476  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1590/3125]  eta: 0:08:50  Lr: 0.030000  Loss: 0.2574  Acc@1: 62.5000 (59.4830)  Acc@5: 93.7500 (95.2860)  time: 0.3487  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1600/3125]  eta: 0:08:46  Lr: 0.030000  Loss: 0.3389  Acc@1: 56.2500 (59.4863)  Acc@5: 93.7500 (95.2959)  time: 0.3479  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [1610/3125]  eta: 0:08:43  Lr: 0.030000  Loss: 0.4793  Acc@1: 56.2500 (59.5050)  Acc@5: 100.0000 (95.3096)  time: 0.3452  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [1620/3125]  eta: 0:08:39  Lr: 0.030000  Loss: 0.4095  Acc@1: 56.2500 (59.5080)  Acc@5: 93.7500 (95.3077)  time: 0.3449  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [1630/3125]  eta: 0:08:36  Lr: 0.030000  Loss: 0.4103  Acc@1: 56.2500 (59.4919)  Acc@5: 93.7500 (95.3173)  time: 0.3454  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [1640/3125]  eta: 0:08:32  Lr: 0.030000  Loss: 0.3655  Acc@1: 56.2500 (59.5293)  Acc@5: 100.0000 (95.3154)  time: 0.3456  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [1650/3125]  eta: 0:08:29  Lr: 0.030000  Loss: 0.5194  Acc@1: 68.7500 (59.5397)  Acc@5: 93.7500 (95.3210)  time: 0.3449  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [1660/3125]  eta: 0:08:25  Lr: 0.030000  Loss: 0.4734  Acc@1: 62.5000 (59.5613)  Acc@5: 100.0000 (95.3379)  time: 0.3455  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [1670/3125]  eta: 0:08:22  Lr: 0.030000  Loss: 0.7378  Acc@1: 56.2500 (59.5564)  Acc@5: 100.0000 (95.3359)  time: 0.3444  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [1680/3125]  eta: 0:08:18  Lr: 0.030000  Loss: 0.5919  Acc@1: 56.2500 (59.5814)  Acc@5: 93.7500 (95.3413)  time: 0.3428  data: 0.0002  max mem: 2500
Train: Epoch[2/5]  [1690/3125]  eta: 0:08:15  Lr: 0.030000  Loss: 0.4447  Acc@1: 62.5000 (59.6134)  Acc@5: 100.0000 (95.3467)  time: 0.3432  data: 0.0002  max mem: 2500
Train: Epoch[2/5]  [1700/3125]  eta: 0:08:11  Lr: 0.030000  Loss: 0.5018  Acc@1: 62.5000 (59.6451)  Acc@5: 100.0000 (95.3593)  time: 0.3432  data: 0.0002  max mem: 2500
Train: Epoch[2/5]  [1710/3125]  eta: 0:08:08  Lr: 0.030000  Loss: 0.5916  Acc@1: 62.5000 (59.6289)  Acc@5: 93.7500 (95.3463)  time: 0.3434  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [1720/3125]  eta: 0:08:05  Lr: 0.030000  Loss: 0.4857  Acc@1: 56.2500 (59.6456)  Acc@5: 93.7500 (95.3588)  time: 0.3444  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [1730/3125]  eta: 0:08:01  Lr: 0.030000  Loss: 0.4624  Acc@1: 62.5000 (59.6945)  Acc@5: 100.0000 (95.3712)  time: 0.3452  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [1740/3125]  eta: 0:07:58  Lr: 0.030000  Loss: 0.4506  Acc@1: 68.7500 (59.7214)  Acc@5: 100.0000 (95.3798)  time: 0.3453  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1750/3125]  eta: 0:07:54  Lr: 0.030000  Loss: 0.6231  Acc@1: 68.7500 (59.7766)  Acc@5: 100.0000 (95.3919)  time: 0.3450  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1760/3125]  eta: 0:07:51  Lr: 0.030000  Loss: 0.3931  Acc@1: 62.5000 (59.7565)  Acc@5: 100.0000 (95.4003)  time: 0.3447  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [1770/3125]  eta: 0:07:47  Lr: 0.030000  Loss: 0.7465  Acc@1: 56.2500 (59.7614)  Acc@5: 100.0000 (95.3946)  time: 0.3451  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1780/3125]  eta: 0:07:44  Lr: 0.030000  Loss: 0.4555  Acc@1: 56.2500 (59.7733)  Acc@5: 93.7500 (95.3888)  time: 0.3449  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1790/3125]  eta: 0:07:40  Lr: 0.030000  Loss: 0.7155  Acc@1: 62.5000 (59.7606)  Acc@5: 100.0000 (95.4076)  time: 0.3456  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [1800/3125]  eta: 0:07:37  Lr: 0.030000  Loss: 0.4254  Acc@1: 62.5000 (59.7689)  Acc@5: 100.0000 (95.4088)  time: 0.3463  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1810/3125]  eta: 0:07:33  Lr: 0.030000  Loss: 0.4086  Acc@1: 62.5000 (59.8288)  Acc@5: 100.0000 (95.4100)  time: 0.3457  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1820/3125]  eta: 0:07:30  Lr: 0.030000  Loss: 0.4878  Acc@1: 62.5000 (59.8572)  Acc@5: 100.0000 (95.4112)  time: 0.3452  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [1830/3125]  eta: 0:07:27  Lr: 0.030000  Loss: 0.3794  Acc@1: 62.5000 (59.8955)  Acc@5: 93.7500 (95.4089)  time: 0.3451  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [1840/3125]  eta: 0:07:23  Lr: 0.030000  Loss: 0.6825  Acc@1: 62.5000 (59.9267)  Acc@5: 100.0000 (95.4271)  time: 0.3451  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [1850/3125]  eta: 0:07:20  Lr: 0.030000  Loss: 0.6028  Acc@1: 56.2500 (59.9034)  Acc@5: 100.0000 (95.4450)  time: 0.3450  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [1860/3125]  eta: 0:07:16  Lr: 0.030000  Loss: 0.4876  Acc@1: 56.2500 (59.9107)  Acc@5: 100.0000 (95.4426)  time: 0.3451  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [1870/3125]  eta: 0:07:13  Lr: 0.030000  Loss: 0.3065  Acc@1: 56.2500 (59.8978)  Acc@5: 93.7500 (95.4470)  time: 0.3453  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1880/3125]  eta: 0:07:09  Lr: 0.030000  Loss: 0.4089  Acc@1: 62.5000 (59.9149)  Acc@5: 100.0000 (95.4579)  time: 0.3447  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1890/3125]  eta: 0:07:06  Lr: 0.030000  Loss: 0.3027  Acc@1: 68.7500 (59.9517)  Acc@5: 100.0000 (95.4654)  time: 0.3433  data: 0.0002  max mem: 2500
Train: Epoch[2/5]  [1900/3125]  eta: 0:07:02  Lr: 0.030000  Loss: 0.7119  Acc@1: 62.5000 (59.9487)  Acc@5: 93.7500 (95.4662)  time: 0.3431  data: 0.0002  max mem: 2500
Train: Epoch[2/5]  [1910/3125]  eta: 0:06:59  Lr: 0.030000  Loss: 0.6134  Acc@1: 62.5000 (59.9621)  Acc@5: 93.7500 (95.4736)  time: 0.3432  data: 0.0002  max mem: 2500
Train: Epoch[2/5]  [1920/3125]  eta: 0:06:55  Lr: 0.030000  Loss: 0.5166  Acc@1: 68.7500 (59.9948)  Acc@5: 93.7500 (95.4711)  time: 0.3432  data: 0.0002  max mem: 2500
Train: Epoch[2/5]  [1930/3125]  eta: 0:06:52  Lr: 0.030000  Loss: 0.8084  Acc@1: 62.5000 (60.0045)  Acc@5: 93.7500 (95.4687)  time: 0.3436  data: 0.0002  max mem: 2500
Train: Epoch[2/5]  [1940/3125]  eta: 0:06:49  Lr: 0.030000  Loss: 0.6093  Acc@1: 62.5000 (60.0142)  Acc@5: 100.0000 (95.4791)  time: 0.3437  data: 0.0002  max mem: 2500
Train: Epoch[2/5]  [1950/3125]  eta: 0:06:45  Lr: 0.030000  Loss: 0.6232  Acc@1: 62.5000 (60.0461)  Acc@5: 100.0000 (95.4799)  time: 0.3450  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [1960/3125]  eta: 0:06:42  Lr: 0.030000  Loss: 0.2268  Acc@1: 62.5000 (60.0778)  Acc@5: 100.0000 (95.4902)  time: 0.3464  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1970/3125]  eta: 0:06:38  Lr: 0.030000  Loss: 0.4592  Acc@1: 68.7500 (60.1218)  Acc@5: 100.0000 (95.5004)  time: 0.3458  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1980/3125]  eta: 0:06:35  Lr: 0.030000  Loss: 0.6435  Acc@1: 68.7500 (60.1306)  Acc@5: 100.0000 (95.5073)  time: 0.3453  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1990/3125]  eta: 0:06:31  Lr: 0.030000  Loss: 0.6105  Acc@1: 62.5000 (60.1551)  Acc@5: 93.7500 (95.5079)  time: 0.3458  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2000/3125]  eta: 0:06:28  Lr: 0.030000  Loss: 0.2441  Acc@1: 62.5000 (60.1699)  Acc@5: 100.0000 (95.5241)  time: 0.3458  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2010/3125]  eta: 0:06:24  Lr: 0.030000  Loss: 0.7172  Acc@1: 62.5000 (60.1753)  Acc@5: 100.0000 (95.5184)  time: 0.3463  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2020/3125]  eta: 0:06:21  Lr: 0.030000  Loss: 0.5160  Acc@1: 62.5000 (60.1775)  Acc@5: 93.7500 (95.5251)  time: 0.3463  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2030/3125]  eta: 0:06:17  Lr: 0.030000  Loss: 0.5534  Acc@1: 62.5000 (60.1982)  Acc@5: 100.0000 (95.5410)  time: 0.3451  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2040/3125]  eta: 0:06:14  Lr: 0.030000  Loss: 0.6880  Acc@1: 62.5000 (60.2003)  Acc@5: 100.0000 (95.5383)  time: 0.3458  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2050/3125]  eta: 0:06:11  Lr: 0.030000  Loss: 0.2455  Acc@1: 62.5000 (60.2480)  Acc@5: 100.0000 (95.5479)  time: 0.3462  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2060/3125]  eta: 0:06:07  Lr: 0.030000  Loss: 0.1637  Acc@1: 68.7500 (60.2772)  Acc@5: 100.0000 (95.5665)  time: 0.3453  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2070/3125]  eta: 0:06:04  Lr: 0.030000  Loss: 0.7247  Acc@1: 68.7500 (60.2909)  Acc@5: 100.0000 (95.5758)  time: 0.3458  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2080/3125]  eta: 0:06:00  Lr: 0.030000  Loss: 0.4928  Acc@1: 62.5000 (60.3136)  Acc@5: 100.0000 (95.5821)  time: 0.3456  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [2090/3125]  eta: 0:05:57  Lr: 0.030000  Loss: 0.6162  Acc@1: 62.5000 (60.3330)  Acc@5: 100.0000 (95.5793)  time: 0.3452  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [2100/3125]  eta: 0:05:53  Lr: 0.030000  Loss: 0.5702  Acc@1: 68.7500 (60.3730)  Acc@5: 100.0000 (95.5884)  time: 0.3454  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [2110/3125]  eta: 0:05:50  Lr: 0.030000  Loss: 0.3916  Acc@1: 68.7500 (60.4038)  Acc@5: 100.0000 (95.6004)  time: 0.3455  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [2120/3125]  eta: 0:05:46  Lr: 0.030000  Loss: 0.5579  Acc@1: 68.7500 (60.4432)  Acc@5: 100.0000 (95.6123)  time: 0.3451  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [2130/3125]  eta: 0:05:43  Lr: 0.030000  Loss: 0.3838  Acc@1: 68.7500 (60.4616)  Acc@5: 100.0000 (95.6153)  time: 0.3444  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [2140/3125]  eta: 0:05:40  Lr: 0.030000  Loss: 0.2572  Acc@1: 62.5000 (60.4828)  Acc@5: 100.0000 (95.6212)  time: 0.3440  data: 0.0002  max mem: 2500
Train: Epoch[2/5]  [2150/3125]  eta: 0:05:36  Lr: 0.030000  Loss: 0.2232  Acc@1: 62.5000 (60.5155)  Acc@5: 100.0000 (95.6328)  time: 0.3446  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [2160/3125]  eta: 0:05:33  Lr: 0.030000  Loss: 0.3754  Acc@1: 62.5000 (60.5217)  Acc@5: 100.0000 (95.6328)  time: 0.3450  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2170/3125]  eta: 0:05:29  Lr: 0.030000  Loss: 0.5103  Acc@1: 62.5000 (60.5280)  Acc@5: 93.7500 (95.6357)  time: 0.3457  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2180/3125]  eta: 0:05:26  Lr: 0.030000  Loss: 0.3735  Acc@1: 62.5000 (60.5428)  Acc@5: 100.0000 (95.6385)  time: 0.3457  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [2190/3125]  eta: 0:05:22  Lr: 0.030000  Loss: 0.1853  Acc@1: 68.7500 (60.5774)  Acc@5: 100.0000 (95.6384)  time: 0.3448  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [2200/3125]  eta: 0:05:19  Lr: 0.030000  Loss: 0.2462  Acc@1: 62.5000 (60.5918)  Acc@5: 93.7500 (95.6327)  time: 0.3451  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [2210/3125]  eta: 0:05:15  Lr: 0.030000  Loss: 0.5015  Acc@1: 62.5000 (60.6032)  Acc@5: 93.7500 (95.6355)  time: 0.3450  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [2220/3125]  eta: 0:05:12  Lr: 0.030000  Loss: 0.3429  Acc@1: 62.5000 (60.6230)  Acc@5: 100.0000 (95.6410)  time: 0.3462  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2230/3125]  eta: 0:05:08  Lr: 0.030000  Loss: 0.3865  Acc@1: 62.5000 (60.6567)  Acc@5: 100.0000 (95.6522)  time: 0.3453  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2240/3125]  eta: 0:05:05  Lr: 0.030000  Loss: 0.3953  Acc@1: 62.5000 (60.6481)  Acc@5: 100.0000 (95.6521)  time: 0.3430  data: 0.0002  max mem: 2500
Train: Epoch[2/5]  [2250/3125]  eta: 0:05:02  Lr: 0.030000  Loss: 0.4335  Acc@1: 56.2500 (60.6369)  Acc@5: 93.7500 (95.6436)  time: 0.3431  data: 0.0002  max mem: 2500
Train: Epoch[2/5]  [2260/3125]  eta: 0:04:58  Lr: 0.030000  Loss: 0.6303  Acc@1: 62.5000 (60.6811)  Acc@5: 93.7500 (95.6490)  time: 0.3432  data: 0.0002  max mem: 2500
Train: Epoch[2/5]  [2270/3125]  eta: 0:04:55  Lr: 0.030000  Loss: 0.5054  Acc@1: 68.7500 (60.7029)  Acc@5: 93.7500 (95.6434)  time: 0.3432  data: 0.0002  max mem: 2500
Train: Epoch[2/5]  [2280/3125]  eta: 0:04:51  Lr: 0.030000  Loss: 0.3172  Acc@1: 62.5000 (60.7053)  Acc@5: 93.7500 (95.6461)  time: 0.3431  data: 0.0002  max mem: 2500
Train: Epoch[2/5]  [2290/3125]  eta: 0:04:48  Lr: 0.030000  Loss: 0.3925  Acc@1: 68.7500 (60.7349)  Acc@5: 100.0000 (95.6542)  time: 0.3430  data: 0.0002  max mem: 2500
Train: Epoch[2/5]  [2300/3125]  eta: 0:04:44  Lr: 0.030000  Loss: 0.5606  Acc@1: 68.7500 (60.7589)  Acc@5: 100.0000 (95.6622)  time: 0.3431  data: 0.0002  max mem: 2500
Train: Epoch[2/5]  [2310/3125]  eta: 0:04:41  Lr: 0.030000  Loss: 0.5811  Acc@1: 62.5000 (60.8016)  Acc@5: 100.0000 (95.6621)  time: 0.3438  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [2320/3125]  eta: 0:04:37  Lr: 0.030000  Loss: 0.4517  Acc@1: 62.5000 (60.7874)  Acc@5: 93.7500 (95.6619)  time: 0.3451  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [2330/3125]  eta: 0:04:34  Lr: 0.030000  Loss: 0.6918  Acc@1: 62.5000 (60.8242)  Acc@5: 93.7500 (95.6537)  time: 0.3457  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [2340/3125]  eta: 0:04:30  Lr: 0.030000  Loss: 0.5295  Acc@1: 62.5000 (60.8421)  Acc@5: 100.0000 (95.6589)  time: 0.3453  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2350/3125]  eta: 0:04:27  Lr: 0.030000  Loss: 0.3564  Acc@1: 62.5000 (60.8730)  Acc@5: 100.0000 (95.6747)  time: 0.3450  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2360/3125]  eta: 0:04:24  Lr: 0.030000  Loss: 0.3177  Acc@1: 62.5000 (60.8879)  Acc@5: 100.0000 (95.6771)  time: 0.3447  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2370/3125]  eta: 0:04:20  Lr: 0.030000  Loss: 0.4799  Acc@1: 62.5000 (60.8999)  Acc@5: 93.7500 (95.6690)  time: 0.3451  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2380/3125]  eta: 0:04:17  Lr: 0.030000  Loss: 0.4201  Acc@1: 62.5000 (60.9119)  Acc@5: 93.7500 (95.6741)  time: 0.3449  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2390/3125]  eta: 0:04:13  Lr: 0.030000  Loss: 0.3915  Acc@1: 62.5000 (60.9159)  Acc@5: 100.0000 (95.6817)  time: 0.3443  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2400/3125]  eta: 0:04:10  Lr: 0.030000  Loss: 0.4099  Acc@1: 68.7500 (60.9121)  Acc@5: 100.0000 (95.6867)  time: 0.3448  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2410/3125]  eta: 0:04:06  Lr: 0.030000  Loss: 0.4190  Acc@1: 62.5000 (60.9317)  Acc@5: 100.0000 (95.6761)  time: 0.3451  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2420/3125]  eta: 0:04:03  Lr: 0.030000  Loss: 0.4261  Acc@1: 62.5000 (60.9511)  Acc@5: 100.0000 (95.6810)  time: 0.3444  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2430/3125]  eta: 0:03:59  Lr: 0.030000  Loss: 0.5159  Acc@1: 62.5000 (60.9549)  Acc@5: 100.0000 (95.6859)  time: 0.3442  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2440/3125]  eta: 0:03:56  Lr: 0.030000  Loss: 0.5515  Acc@1: 56.2500 (60.9535)  Acc@5: 93.7500 (95.6754)  time: 0.3447  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2450/3125]  eta: 0:03:52  Lr: 0.030000  Loss: 0.4082  Acc@1: 62.5000 (60.9751)  Acc@5: 93.7500 (95.6778)  time: 0.3454  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2460/3125]  eta: 0:03:49  Lr: 0.030000  Loss: 0.2277  Acc@1: 62.5000 (61.0067)  Acc@5: 100.0000 (95.6852)  time: 0.3457  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2470/3125]  eta: 0:03:46  Lr: 0.030000  Loss: 0.7420  Acc@1: 62.5000 (61.0077)  Acc@5: 100.0000 (95.6849)  time: 0.3532  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2480/3125]  eta: 0:03:42  Lr: 0.030000  Loss: 0.6148  Acc@1: 62.5000 (61.0389)  Acc@5: 100.0000 (95.6872)  time: 0.3524  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [2490/3125]  eta: 0:03:39  Lr: 0.030000  Loss: 0.5119  Acc@1: 68.7500 (61.0623)  Acc@5: 100.0000 (95.6945)  time: 0.3444  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [2500/3125]  eta: 0:03:35  Lr: 0.030000  Loss: 0.5988  Acc@1: 68.7500 (61.0831)  Acc@5: 100.0000 (95.6992)  time: 0.3447  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [2510/3125]  eta: 0:03:32  Lr: 0.030000  Loss: 0.4026  Acc@1: 68.7500 (61.0962)  Acc@5: 100.0000 (95.7039)  time: 0.3454  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [2520/3125]  eta: 0:03:28  Lr: 0.030000  Loss: 0.4865  Acc@1: 68.7500 (61.1092)  Acc@5: 100.0000 (95.7085)  time: 0.3453  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [2530/3125]  eta: 0:03:25  Lr: 0.030000  Loss: 0.6946  Acc@1: 62.5000 (61.1147)  Acc@5: 100.0000 (95.7082)  time: 0.3449  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [2540/3125]  eta: 0:03:21  Lr: 0.030000  Loss: 0.5126  Acc@1: 62.5000 (61.1324)  Acc@5: 93.7500 (95.7104)  time: 0.3449  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [2550/3125]  eta: 0:03:18  Lr: 0.030000  Loss: 0.4744  Acc@1: 68.7500 (61.1647)  Acc@5: 93.7500 (95.7051)  time: 0.3464  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2560/3125]  eta: 0:03:15  Lr: 0.030000  Loss: 0.2285  Acc@1: 75.0000 (61.2041)  Acc@5: 93.7500 (95.7170)  time: 0.3455  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [2570/3125]  eta: 0:03:11  Lr: 0.030000  Loss: 0.1184  Acc@1: 75.0000 (61.2529)  Acc@5: 100.0000 (95.7166)  time: 0.3431  data: 0.0002  max mem: 2500
Train: Epoch[2/5]  [2580/3125]  eta: 0:03:08  Lr: 0.030000  Loss: 0.3933  Acc@1: 68.7500 (61.2941)  Acc@5: 100.0000 (95.7211)  time: 0.3431  data: 0.0002  max mem: 2500
Train: Epoch[2/5]  [2590/3125]  eta: 0:03:04  Lr: 0.030000  Loss: 0.7024  Acc@1: 68.7500 (61.3228)  Acc@5: 100.0000 (95.7208)  time: 0.3429  data: 0.0002  max mem: 2500
Train: Epoch[2/5]  [2600/3125]  eta: 0:03:01  Lr: 0.030000  Loss: 0.3820  Acc@1: 68.7500 (61.3538)  Acc@5: 100.0000 (95.7300)  time: 0.3429  data: 0.0002  max mem: 2500
Train: Epoch[2/5]  [2610/3125]  eta: 0:02:57  Lr: 0.030000  Loss: 0.5999  Acc@1: 62.5000 (61.3534)  Acc@5: 93.7500 (95.7272)  time: 0.3431  data: 0.0002  max mem: 2500
Train: Epoch[2/5]  [2620/3125]  eta: 0:02:54  Lr: 0.030000  Loss: 0.3272  Acc@1: 62.5000 (61.3578)  Acc@5: 93.7500 (95.7292)  time: 0.3432  data: 0.0002  max mem: 2500
Train: Epoch[2/5]  [2630/3125]  eta: 0:02:50  Lr: 0.030000  Loss: 0.4624  Acc@1: 62.5000 (61.3740)  Acc@5: 93.7500 (95.7264)  time: 0.3433  data: 0.0002  max mem: 2500
Train: Epoch[2/5]  [2640/3125]  eta: 0:02:47  Lr: 0.030000  Loss: 0.4458  Acc@1: 68.7500 (61.4138)  Acc@5: 100.0000 (95.7284)  time: 0.3433  data: 0.0002  max mem: 2500
Train: Epoch[2/5]  [2650/3125]  eta: 0:02:43  Lr: 0.030000  Loss: 0.6439  Acc@1: 68.7500 (61.4108)  Acc@5: 93.7500 (95.7210)  time: 0.3442  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [2660/3125]  eta: 0:02:40  Lr: 0.030000  Loss: 0.2430  Acc@1: 68.7500 (61.4431)  Acc@5: 93.7500 (95.7300)  time: 0.3458  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2670/3125]  eta: 0:02:37  Lr: 0.030000  Loss: 0.5162  Acc@1: 62.5000 (61.4377)  Acc@5: 100.0000 (95.7319)  time: 0.3460  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2680/3125]  eta: 0:02:33  Lr: 0.030000  Loss: 0.4448  Acc@1: 62.5000 (61.4719)  Acc@5: 100.0000 (95.7385)  time: 0.3455  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [2690/3125]  eta: 0:02:30  Lr: 0.030000  Loss: 0.5265  Acc@1: 75.0000 (61.4943)  Acc@5: 100.0000 (95.7404)  time: 0.3453  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [2700/3125]  eta: 0:02:26  Lr: 0.030000  Loss: 0.4588  Acc@1: 68.7500 (61.5050)  Acc@5: 100.0000 (95.7469)  time: 0.3448  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [2710/3125]  eta: 0:02:23  Lr: 0.030000  Loss: 0.6952  Acc@1: 62.5000 (61.5248)  Acc@5: 100.0000 (95.7419)  time: 0.3448  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [2720/3125]  eta: 0:02:19  Lr: 0.030000  Loss: 0.5692  Acc@1: 62.5000 (61.5353)  Acc@5: 93.7500 (95.7392)  time: 0.3447  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2730/3125]  eta: 0:02:16  Lr: 0.030000  Loss: 0.3463  Acc@1: 68.7500 (61.5594)  Acc@5: 93.7500 (95.7433)  time: 0.3449  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2740/3125]  eta: 0:02:12  Lr: 0.030000  Loss: 0.5239  Acc@1: 62.5000 (61.5492)  Acc@5: 93.7500 (95.7338)  time: 0.3452  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2750/3125]  eta: 0:02:09  Lr: 0.030000  Loss: 0.6817  Acc@1: 62.5000 (61.5594)  Acc@5: 100.0000 (95.7447)  time: 0.3448  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [2760/3125]  eta: 0:02:05  Lr: 0.030000  Loss: 0.4188  Acc@1: 62.5000 (61.5583)  Acc@5: 100.0000 (95.7420)  time: 0.3450  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [2770/3125]  eta: 0:02:02  Lr: 0.030000  Loss: 0.2163  Acc@1: 62.5000 (61.5730)  Acc@5: 93.7500 (95.7416)  time: 0.3461  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2780/3125]  eta: 0:01:59  Lr: 0.030000  Loss: 0.3448  Acc@1: 62.5000 (61.6010)  Acc@5: 100.0000 (95.7502)  time: 0.3465  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2790/3125]  eta: 0:01:55  Lr: 0.030000  Loss: 0.3479  Acc@1: 62.5000 (61.5931)  Acc@5: 100.0000 (95.7542)  time: 0.3457  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2800/3125]  eta: 0:01:52  Lr: 0.030000  Loss: 0.4088  Acc@1: 62.5000 (61.6253)  Acc@5: 93.7500 (95.7537)  time: 0.3456  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2810/3125]  eta: 0:01:48  Lr: 0.030000  Loss: 0.3668  Acc@1: 68.7500 (61.6484)  Acc@5: 100.0000 (95.7622)  time: 0.3464  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2820/3125]  eta: 0:01:45  Lr: 0.030000  Loss: 0.3862  Acc@1: 68.7500 (61.6913)  Acc@5: 100.0000 (95.7706)  time: 0.3461  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [2830/3125]  eta: 0:01:41  Lr: 0.030000  Loss: 0.3277  Acc@1: 68.7500 (61.6832)  Acc@5: 93.7500 (95.7700)  time: 0.3449  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2840/3125]  eta: 0:01:38  Lr: 0.030000  Loss: 0.2410  Acc@1: 62.5000 (61.7080)  Acc@5: 93.7500 (95.7761)  time: 0.3448  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2850/3125]  eta: 0:01:34  Lr: 0.030000  Loss: 0.4992  Acc@1: 62.5000 (61.6933)  Acc@5: 100.0000 (95.7800)  time: 0.3451  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [2860/3125]  eta: 0:01:31  Lr: 0.030000  Loss: 0.6114  Acc@1: 62.5000 (61.7267)  Acc@5: 100.0000 (95.7816)  time: 0.3445  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [2870/3125]  eta: 0:01:28  Lr: 0.030000  Loss: 0.3924  Acc@1: 68.7500 (61.7337)  Acc@5: 93.7500 (95.7789)  time: 0.3435  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [2880/3125]  eta: 0:01:24  Lr: 0.030000  Loss: 0.6637  Acc@1: 62.5000 (61.7472)  Acc@5: 93.7500 (95.7719)  time: 0.3443  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [2890/3125]  eta: 0:01:21  Lr: 0.030000  Loss: 0.4424  Acc@1: 62.5000 (61.7585)  Acc@5: 93.7500 (95.7714)  time: 0.3440  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [2900/3125]  eta: 0:01:17  Lr: 0.030000  Loss: 0.4509  Acc@1: 68.7500 (61.7632)  Acc@5: 100.0000 (95.7773)  time: 0.3428  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [2910/3125]  eta: 0:01:14  Lr: 0.030000  Loss: 0.2478  Acc@1: 68.7500 (61.7936)  Acc@5: 100.0000 (95.7768)  time: 0.3426  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [2920/3125]  eta: 0:01:10  Lr: 0.030000  Loss: 0.4274  Acc@1: 68.7500 (61.8132)  Acc@5: 100.0000 (95.7870)  time: 0.3425  data: 0.0002  max mem: 2500
Train: Epoch[2/5]  [2930/3125]  eta: 0:01:07  Lr: 0.030000  Loss: 0.3217  Acc@1: 68.7500 (61.8368)  Acc@5: 100.0000 (95.7907)  time: 0.3435  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [2940/3125]  eta: 0:01:03  Lr: 0.030000  Loss: 0.7923  Acc@1: 68.7500 (61.8412)  Acc@5: 93.7500 (95.7880)  time: 0.3445  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2950/3125]  eta: 0:01:00  Lr: 0.030000  Loss: 0.1729  Acc@1: 68.7500 (61.8773)  Acc@5: 93.7500 (95.7874)  time: 0.3444  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2960/3125]  eta: 0:00:56  Lr: 0.030000  Loss: 0.4617  Acc@1: 68.7500 (61.8942)  Acc@5: 100.0000 (95.7953)  time: 0.3449  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2970/3125]  eta: 0:00:53  Lr: 0.030000  Loss: 0.4924  Acc@1: 62.5000 (61.9110)  Acc@5: 93.7500 (95.7927)  time: 0.3449  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2980/3125]  eta: 0:00:50  Lr: 0.030000  Loss: 0.1811  Acc@1: 62.5000 (61.9213)  Acc@5: 93.7500 (95.7963)  time: 0.3443  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2990/3125]  eta: 0:00:46  Lr: 0.030000  Loss: 0.4923  Acc@1: 62.5000 (61.9212)  Acc@5: 100.0000 (95.7936)  time: 0.3444  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3000/3125]  eta: 0:00:43  Lr: 0.030000  Loss: 0.5397  Acc@1: 62.5000 (61.9481)  Acc@5: 100.0000 (95.7972)  time: 0.3448  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [3010/3125]  eta: 0:00:39  Lr: 0.030000  Loss: 0.4754  Acc@1: 68.7500 (61.9582)  Acc@5: 100.0000 (95.7946)  time: 0.3445  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [3020/3125]  eta: 0:00:36  Lr: 0.030000  Loss: 0.5444  Acc@1: 62.5000 (61.9642)  Acc@5: 100.0000 (95.8023)  time: 0.3441  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [3030/3125]  eta: 0:00:32  Lr: 0.030000  Loss: 0.2970  Acc@1: 62.5000 (61.9639)  Acc@5: 100.0000 (95.8079)  time: 0.3453  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [3040/3125]  eta: 0:00:29  Lr: 0.030000  Loss: 0.6142  Acc@1: 68.7500 (61.9882)  Acc@5: 93.7500 (95.8073)  time: 0.3445  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [3050/3125]  eta: 0:00:25  Lr: 0.030000  Loss: 0.4532  Acc@1: 68.7500 (62.0084)  Acc@5: 100.0000 (95.8169)  time: 0.3428  data: 0.0002  max mem: 2500
Train: Epoch[2/5]  [3060/3125]  eta: 0:00:22  Lr: 0.030000  Loss: 0.3422  Acc@1: 68.7500 (62.0222)  Acc@5: 100.0000 (95.8204)  time: 0.3428  data: 0.0002  max mem: 2500
Train: Epoch[2/5]  [3070/3125]  eta: 0:00:18  Lr: 0.030000  Loss: 0.3824  Acc@1: 68.7500 (62.0299)  Acc@5: 100.0000 (95.8198)  time: 0.3427  data: 0.0002  max mem: 2500
Train: Epoch[2/5]  [3080/3125]  eta: 0:00:15  Lr: 0.030000  Loss: 0.3584  Acc@1: 62.5000 (62.0294)  Acc@5: 93.7500 (95.8212)  time: 0.3428  data: 0.0002  max mem: 2500
Train: Epoch[2/5]  [3090/3125]  eta: 0:00:12  Lr: 0.030000  Loss: 0.4502  Acc@1: 62.5000 (62.0289)  Acc@5: 100.0000 (95.8286)  time: 0.3434  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [3100/3125]  eta: 0:00:08  Lr: 0.030000  Loss: 0.7261  Acc@1: 62.5000 (62.0284)  Acc@5: 100.0000 (95.8280)  time: 0.3448  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3110/3125]  eta: 0:00:05  Lr: 0.030000  Loss: 0.5222  Acc@1: 62.5000 (62.0219)  Acc@5: 93.7500 (95.8293)  time: 0.3457  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3120/3125]  eta: 0:00:01  Lr: 0.030000  Loss: 0.4274  Acc@1: 62.5000 (62.0294)  Acc@5: 100.0000 (95.8347)  time: 0.3467  data: 0.0010  max mem: 2500
Train: Epoch[2/5]  [3124/3125]  eta: 0:00:00  Lr: 0.030000  Loss: 0.4336  Acc@1: 62.5000 (62.0220)  Acc@5: 93.7500 (95.8300)  time: 0.3463  data: 0.0010  max mem: 2500
Train: Epoch[2/5] Total time: 0:17:58 (0.3452 s / it)
{0: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 1: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 2: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 3: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 4: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 5: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 6: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 7: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 8: {0: 0, 1: 0, 2: 100000, 3: 0, 4: 0}, 9: {0: 0, 1: 0, 2: 100000, 3: 0, 4: 0}, 10: {0: 0, 1: 0, 2: 100000, 3: 0, 4: 0}, 11: {0: 0, 1: 0, 2: 100000, 3: 0, 4: 0}, 12: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 13: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 14: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 15: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 16: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 17: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 18: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 19: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}}
Averaged stats: Lr: 0.030000  Loss: 0.4336  Acc@1: 62.5000 (62.0220)  Acc@5: 93.7500 (95.8300)
Train: Epoch[3/5]  [   0/3125]  eta: 0:32:25  Lr: 0.030000  Loss: 0.5002  Acc@1: 62.5000 (62.5000)  Acc@5: 100.0000 (100.0000)  time: 0.6225  data: 0.2788  max mem: 2500
Train: Epoch[3/5]  [  10/3125]  eta: 0:19:14  Lr: 0.030000  Loss: 0.5475  Acc@1: 62.5000 (65.3409)  Acc@5: 100.0000 (97.1591)  time: 0.3705  data: 0.0257  max mem: 2500
Train: Epoch[3/5]  [  20/3125]  eta: 0:18:35  Lr: 0.030000  Loss: 0.2163  Acc@1: 62.5000 (65.7738)  Acc@5: 100.0000 (97.9167)  time: 0.3459  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [  30/3125]  eta: 0:18:17  Lr: 0.030000  Loss: 0.3703  Acc@1: 62.5000 (64.3145)  Acc@5: 100.0000 (98.1855)  time: 0.3460  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [  40/3125]  eta: 0:18:10  Lr: 0.030000  Loss: 0.2769  Acc@1: 68.7500 (66.4634)  Acc@5: 100.0000 (97.8659)  time: 0.3479  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [  50/3125]  eta: 0:18:02  Lr: 0.030000  Loss: 0.4064  Acc@1: 75.0000 (67.6471)  Acc@5: 100.0000 (97.9167)  time: 0.3481  data: 0.0009  max mem: 2500
Train: Epoch[3/5]  [  60/3125]  eta: 0:17:55  Lr: 0.030000  Loss: 0.3640  Acc@1: 68.7500 (67.8279)  Acc@5: 100.0000 (98.0533)  time: 0.3456  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [  70/3125]  eta: 0:17:49  Lr: 0.030000  Loss: 0.2904  Acc@1: 62.5000 (67.3415)  Acc@5: 100.0000 (98.0634)  time: 0.3455  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [  80/3125]  eta: 0:17:44  Lr: 0.030000  Loss: 0.6135  Acc@1: 62.5000 (66.9753)  Acc@5: 100.0000 (97.7623)  time: 0.3453  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [  90/3125]  eta: 0:17:39  Lr: 0.030000  Loss: 0.4165  Acc@1: 62.5000 (66.7582)  Acc@5: 100.0000 (97.8709)  time: 0.3454  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [ 100/3125]  eta: 0:17:35  Lr: 0.030000  Loss: 0.3987  Acc@1: 68.7500 (66.7079)  Acc@5: 100.0000 (97.7104)  time: 0.3458  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [ 110/3125]  eta: 0:17:30  Lr: 0.030000  Loss: 0.4475  Acc@1: 62.5000 (66.4414)  Acc@5: 93.7500 (97.4662)  time: 0.3450  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [ 120/3125]  eta: 0:17:25  Lr: 0.030000  Loss: 0.4352  Acc@1: 62.5000 (66.5806)  Acc@5: 93.7500 (97.1591)  time: 0.3438  data: 0.0002  max mem: 2500
Train: Epoch[3/5]  [ 130/3125]  eta: 0:17:21  Lr: 0.030000  Loss: 0.2040  Acc@1: 68.7500 (66.8893)  Acc@5: 100.0000 (97.3760)  time: 0.3437  data: 0.0002  max mem: 2500
Train: Epoch[3/5]  [ 140/3125]  eta: 0:17:17  Lr: 0.030000  Loss: 0.2505  Acc@1: 68.7500 (66.8883)  Acc@5: 100.0000 (97.3848)  time: 0.3442  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [ 150/3125]  eta: 0:17:13  Lr: 0.030000  Loss: 0.3804  Acc@1: 68.7500 (66.8874)  Acc@5: 100.0000 (97.4752)  time: 0.3451  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [ 160/3125]  eta: 0:17:09  Lr: 0.030000  Loss: 0.3635  Acc@1: 68.7500 (67.1196)  Acc@5: 100.0000 (97.3991)  time: 0.3464  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 170/3125]  eta: 0:17:06  Lr: 0.030000  Loss: 0.1919  Acc@1: 68.7500 (67.3246)  Acc@5: 100.0000 (97.3319)  time: 0.3467  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 180/3125]  eta: 0:17:02  Lr: 0.030000  Loss: 0.4370  Acc@1: 75.0000 (67.5414)  Acc@5: 100.0000 (97.3412)  time: 0.3458  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 190/3125]  eta: 0:16:58  Lr: 0.030000  Loss: 0.3264  Acc@1: 75.0000 (67.7356)  Acc@5: 100.0000 (97.4149)  time: 0.3452  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [ 200/3125]  eta: 0:16:55  Lr: 0.030000  Loss: 0.3435  Acc@1: 68.7500 (67.7550)  Acc@5: 100.0000 (97.4502)  time: 0.3456  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [ 210/3125]  eta: 0:16:51  Lr: 0.030000  Loss: 0.4857  Acc@1: 62.5000 (67.8318)  Acc@5: 100.0000 (97.4230)  time: 0.3458  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [ 220/3125]  eta: 0:16:47  Lr: 0.030000  Loss: 0.4362  Acc@1: 68.7500 (67.9864)  Acc@5: 100.0000 (97.4548)  time: 0.3450  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [ 230/3125]  eta: 0:16:43  Lr: 0.030000  Loss: 0.5677  Acc@1: 68.7500 (67.9924)  Acc@5: 100.0000 (97.4026)  time: 0.3447  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [ 240/3125]  eta: 0:16:39  Lr: 0.030000  Loss: 0.2528  Acc@1: 62.5000 (67.8942)  Acc@5: 100.0000 (97.4326)  time: 0.3441  data: 0.0002  max mem: 2500
Train: Epoch[3/5]  [ 250/3125]  eta: 0:16:36  Lr: 0.030000  Loss: 0.5090  Acc@1: 62.5000 (67.8038)  Acc@5: 100.0000 (97.3357)  time: 0.3443  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [ 260/3125]  eta: 0:16:32  Lr: 0.030000  Loss: 0.6198  Acc@1: 62.5000 (67.7921)  Acc@5: 100.0000 (97.3180)  time: 0.3459  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 270/3125]  eta: 0:16:29  Lr: 0.030000  Loss: 0.3517  Acc@1: 68.7500 (67.8044)  Acc@5: 100.0000 (97.3017)  time: 0.3465  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 280/3125]  eta: 0:16:25  Lr: 0.030000  Loss: 0.3719  Acc@1: 68.7500 (67.8381)  Acc@5: 100.0000 (97.3310)  time: 0.3456  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 290/3125]  eta: 0:16:22  Lr: 0.030000  Loss: 0.3142  Acc@1: 62.5000 (67.6117)  Acc@5: 100.0000 (97.2938)  time: 0.3449  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [ 300/3125]  eta: 0:16:18  Lr: 0.030000  Loss: 0.6123  Acc@1: 62.5000 (67.3173)  Acc@5: 100.0000 (97.2591)  time: 0.3450  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [ 310/3125]  eta: 0:16:14  Lr: 0.030000  Loss: 0.4370  Acc@1: 62.5000 (67.3834)  Acc@5: 100.0000 (97.2669)  time: 0.3452  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [ 320/3125]  eta: 0:16:11  Lr: 0.030000  Loss: 0.4049  Acc@1: 68.7500 (67.4260)  Acc@5: 100.0000 (97.3326)  time: 0.3456  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [ 330/3125]  eta: 0:16:07  Lr: 0.030000  Loss: 0.2671  Acc@1: 62.5000 (67.3338)  Acc@5: 100.0000 (97.2998)  time: 0.3458  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [ 340/3125]  eta: 0:16:04  Lr: 0.030000  Loss: 0.5171  Acc@1: 68.7500 (67.3021)  Acc@5: 100.0000 (97.2691)  time: 0.3448  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [ 350/3125]  eta: 0:16:00  Lr: 0.030000  Loss: 0.3915  Acc@1: 68.7500 (67.3077)  Acc@5: 93.7500 (97.1866)  time: 0.3433  data: 0.0002  max mem: 2500
Train: Epoch[3/5]  [ 360/3125]  eta: 0:15:56  Lr: 0.030000  Loss: 0.4561  Acc@1: 68.7500 (67.2957)  Acc@5: 93.7500 (97.1607)  time: 0.3431  data: 0.0002  max mem: 2500
Train: Epoch[3/5]  [ 370/3125]  eta: 0:15:53  Lr: 0.030000  Loss: 0.2513  Acc@1: 68.7500 (67.4865)  Acc@5: 100.0000 (97.1698)  time: 0.3431  data: 0.0002  max mem: 2500
Train: Epoch[3/5]  [ 380/3125]  eta: 0:15:49  Lr: 0.030000  Loss: 0.4634  Acc@1: 68.7500 (67.4869)  Acc@5: 100.0000 (97.1949)  time: 0.3431  data: 0.0002  max mem: 2500
Train: Epoch[3/5]  [ 390/3125]  eta: 0:15:45  Lr: 0.030000  Loss: 0.4916  Acc@1: 68.7500 (67.5032)  Acc@5: 100.0000 (97.2347)  time: 0.3435  data: 0.0002  max mem: 2500
Train: Epoch[3/5]  [ 400/3125]  eta: 0:15:42  Lr: 0.030000  Loss: 0.4964  Acc@1: 62.5000 (67.2693)  Acc@5: 100.0000 (97.1478)  time: 0.3436  data: 0.0002  max mem: 2500
Train: Epoch[3/5]  [ 410/3125]  eta: 0:15:38  Lr: 0.030000  Loss: 0.4091  Acc@1: 68.7500 (67.3510)  Acc@5: 93.7500 (97.1411)  time: 0.3433  data: 0.0002  max mem: 2500
Train: Epoch[3/5]  [ 420/3125]  eta: 0:15:35  Lr: 0.030000  Loss: 0.5652  Acc@1: 68.7500 (67.3545)  Acc@5: 100.0000 (97.1496)  time: 0.3434  data: 0.0002  max mem: 2500
Train: Epoch[3/5]  [ 430/3125]  eta: 0:15:31  Lr: 0.030000  Loss: 0.3319  Acc@1: 68.7500 (67.3869)  Acc@5: 100.0000 (97.1723)  time: 0.3449  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 440/3125]  eta: 0:15:28  Lr: 0.030000  Loss: 0.4680  Acc@1: 62.5000 (67.4320)  Acc@5: 100.0000 (97.1514)  time: 0.3457  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 450/3125]  eta: 0:15:24  Lr: 0.030000  Loss: 0.2464  Acc@1: 68.7500 (67.4612)  Acc@5: 100.0000 (97.1452)  time: 0.3459  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 460/3125]  eta: 0:15:21  Lr: 0.030000  Loss: 0.1798  Acc@1: 68.7500 (67.5841)  Acc@5: 100.0000 (97.1800)  time: 0.3459  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 470/3125]  eta: 0:15:17  Lr: 0.030000  Loss: 0.4291  Acc@1: 75.0000 (67.6486)  Acc@5: 100.0000 (97.2134)  time: 0.3450  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 480/3125]  eta: 0:15:14  Lr: 0.030000  Loss: 0.5825  Acc@1: 68.7500 (67.6845)  Acc@5: 100.0000 (97.1674)  time: 0.3449  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 490/3125]  eta: 0:15:10  Lr: 0.030000  Loss: 0.5378  Acc@1: 68.7500 (67.6808)  Acc@5: 100.0000 (97.1741)  time: 0.3453  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 500/3125]  eta: 0:15:07  Lr: 0.030000  Loss: 0.5008  Acc@1: 68.7500 (67.6272)  Acc@5: 100.0000 (97.1432)  time: 0.3447  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 510/3125]  eta: 0:15:03  Lr: 0.030000  Loss: 0.4526  Acc@1: 68.7500 (67.7348)  Acc@5: 100.0000 (97.1624)  time: 0.3453  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 520/3125]  eta: 0:15:00  Lr: 0.030000  Loss: 0.2702  Acc@1: 75.0000 (67.8623)  Acc@5: 100.0000 (97.1809)  time: 0.3458  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 530/3125]  eta: 0:14:56  Lr: 0.030000  Loss: 0.5833  Acc@1: 62.5000 (67.7848)  Acc@5: 100.0000 (97.1516)  time: 0.3449  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [ 540/3125]  eta: 0:14:53  Lr: 0.030000  Loss: 0.6565  Acc@1: 62.5000 (67.6756)  Acc@5: 100.0000 (97.1696)  time: 0.3451  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [ 550/3125]  eta: 0:14:49  Lr: 0.030000  Loss: 0.4996  Acc@1: 62.5000 (67.7291)  Acc@5: 100.0000 (97.1983)  time: 0.3449  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 560/3125]  eta: 0:14:46  Lr: 0.030000  Loss: 0.3860  Acc@1: 62.5000 (67.6248)  Acc@5: 100.0000 (97.2037)  time: 0.3450  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 570/3125]  eta: 0:14:43  Lr: 0.030000  Loss: 0.6547  Acc@1: 68.7500 (67.7211)  Acc@5: 100.0000 (97.2198)  time: 0.3488  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 580/3125]  eta: 0:14:39  Lr: 0.030000  Loss: 0.2692  Acc@1: 75.0000 (67.7818)  Acc@5: 100.0000 (97.2354)  time: 0.3482  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 590/3125]  eta: 0:14:36  Lr: 0.030000  Loss: 0.2483  Acc@1: 62.5000 (67.7348)  Acc@5: 100.0000 (97.1975)  time: 0.3447  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [ 600/3125]  eta: 0:14:32  Lr: 0.030000  Loss: 0.3815  Acc@1: 62.5000 (67.7933)  Acc@5: 100.0000 (97.2026)  time: 0.3451  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [ 610/3125]  eta: 0:14:29  Lr: 0.030000  Loss: 0.4634  Acc@1: 68.7500 (67.7475)  Acc@5: 100.0000 (97.1972)  time: 0.3462  data: 0.0010  max mem: 2500
Train: Epoch[3/5]  [ 620/3125]  eta: 0:14:25  Lr: 0.030000  Loss: 0.4760  Acc@1: 68.7500 (67.7134)  Acc@5: 100.0000 (97.1618)  time: 0.3451  data: 0.0010  max mem: 2500
Train: Epoch[3/5]  [ 630/3125]  eta: 0:14:22  Lr: 0.030000  Loss: 0.4372  Acc@1: 68.7500 (67.6506)  Acc@5: 100.0000 (97.1573)  time: 0.3432  data: 0.0002  max mem: 2500
Train: Epoch[3/5]  [ 640/3125]  eta: 0:14:18  Lr: 0.030000  Loss: 0.5365  Acc@1: 68.7500 (67.6092)  Acc@5: 100.0000 (97.1334)  time: 0.3431  data: 0.0002  max mem: 2500
Train: Epoch[3/5]  [ 650/3125]  eta: 0:14:15  Lr: 0.030000  Loss: 0.3159  Acc@1: 62.5000 (67.5979)  Acc@5: 100.0000 (97.1390)  time: 0.3441  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [ 660/3125]  eta: 0:14:11  Lr: 0.030000  Loss: 0.4543  Acc@1: 68.7500 (67.6532)  Acc@5: 100.0000 (97.1256)  time: 0.3452  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 670/3125]  eta: 0:14:08  Lr: 0.030000  Loss: 0.3324  Acc@1: 68.7500 (67.6602)  Acc@5: 93.7500 (97.1032)  time: 0.3453  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 680/3125]  eta: 0:14:04  Lr: 0.030000  Loss: 0.5721  Acc@1: 62.5000 (67.5569)  Acc@5: 93.7500 (97.0907)  time: 0.3449  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 690/3125]  eta: 0:14:01  Lr: 0.030000  Loss: 0.3471  Acc@1: 62.5000 (67.5470)  Acc@5: 100.0000 (97.0876)  time: 0.3444  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [ 700/3125]  eta: 0:13:57  Lr: 0.030000  Loss: 0.6055  Acc@1: 68.7500 (67.5642)  Acc@5: 100.0000 (97.0934)  time: 0.3446  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [ 710/3125]  eta: 0:13:54  Lr: 0.030000  Loss: 0.5085  Acc@1: 62.5000 (67.5545)  Acc@5: 100.0000 (97.1079)  time: 0.3443  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [ 720/3125]  eta: 0:13:50  Lr: 0.030000  Loss: 0.4713  Acc@1: 62.5000 (67.5624)  Acc@5: 100.0000 (97.1134)  time: 0.3436  data: 0.0002  max mem: 2500
Train: Epoch[3/5]  [ 730/3125]  eta: 0:13:47  Lr: 0.030000  Loss: 0.3242  Acc@1: 62.5000 (67.5445)  Acc@5: 100.0000 (97.1272)  time: 0.3453  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [ 740/3125]  eta: 0:13:44  Lr: 0.030000  Loss: 0.2491  Acc@1: 68.7500 (67.6366)  Acc@5: 100.0000 (97.1407)  time: 0.3472  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [ 750/3125]  eta: 0:13:40  Lr: 0.030000  Loss: 0.4683  Acc@1: 75.0000 (67.7097)  Acc@5: 100.0000 (97.1538)  time: 0.3462  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 760/3125]  eta: 0:13:37  Lr: 0.030000  Loss: 0.6253  Acc@1: 68.7500 (67.6495)  Acc@5: 100.0000 (97.1501)  time: 0.3450  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [ 770/3125]  eta: 0:13:33  Lr: 0.030000  Loss: 0.4938  Acc@1: 68.7500 (67.6962)  Acc@5: 93.7500 (97.1385)  time: 0.3450  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [ 780/3125]  eta: 0:13:30  Lr: 0.030000  Loss: 0.1855  Acc@1: 68.7500 (67.7337)  Acc@5: 93.7500 (97.1271)  time: 0.3452  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [ 790/3125]  eta: 0:13:26  Lr: 0.030000  Loss: 0.4043  Acc@1: 68.7500 (67.7228)  Acc@5: 100.0000 (97.1397)  time: 0.3459  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [ 800/3125]  eta: 0:13:23  Lr: 0.030000  Loss: 0.1643  Acc@1: 68.7500 (67.7122)  Acc@5: 100.0000 (97.1364)  time: 0.3457  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [ 810/3125]  eta: 0:13:19  Lr: 0.030000  Loss: 0.2660  Acc@1: 68.7500 (67.7404)  Acc@5: 100.0000 (97.1255)  time: 0.3441  data: 0.0002  max mem: 2500
Train: Epoch[3/5]  [ 820/3125]  eta: 0:13:16  Lr: 0.030000  Loss: 0.2721  Acc@1: 68.7500 (67.7680)  Acc@5: 100.0000 (97.1300)  time: 0.3431  data: 0.0002  max mem: 2500
Train: Epoch[3/5]  [ 830/3125]  eta: 0:13:12  Lr: 0.030000  Loss: 0.5099  Acc@1: 68.7500 (67.7723)  Acc@5: 100.0000 (97.1420)  time: 0.3436  data: 0.0002  max mem: 2500
Train: Epoch[3/5]  [ 840/3125]  eta: 0:13:09  Lr: 0.030000  Loss: 0.4706  Acc@1: 68.7500 (67.7690)  Acc@5: 100.0000 (97.1537)  time: 0.3438  data: 0.0002  max mem: 2500
Train: Epoch[3/5]  [ 850/3125]  eta: 0:13:05  Lr: 0.030000  Loss: 0.1926  Acc@1: 68.7500 (67.8320)  Acc@5: 100.0000 (97.1651)  time: 0.3437  data: 0.0002  max mem: 2500
Train: Epoch[3/5]  [ 860/3125]  eta: 0:13:02  Lr: 0.030000  Loss: 0.4215  Acc@1: 68.7500 (67.8644)  Acc@5: 100.0000 (97.1835)  time: 0.3439  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [ 870/3125]  eta: 0:12:58  Lr: 0.030000  Loss: 0.2027  Acc@1: 68.7500 (67.8674)  Acc@5: 100.0000 (97.1800)  time: 0.3447  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [ 880/3125]  eta: 0:12:55  Lr: 0.030000  Loss: 0.6217  Acc@1: 68.7500 (67.8632)  Acc@5: 100.0000 (97.1907)  time: 0.3455  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 890/3125]  eta: 0:12:51  Lr: 0.030000  Loss: 0.5975  Acc@1: 68.7500 (67.9082)  Acc@5: 100.0000 (97.2012)  time: 0.3462  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 900/3125]  eta: 0:12:48  Lr: 0.030000  Loss: 0.4632  Acc@1: 68.7500 (67.8690)  Acc@5: 100.0000 (97.2045)  time: 0.3459  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 910/3125]  eta: 0:12:45  Lr: 0.030000  Loss: 0.4499  Acc@1: 68.7500 (67.8787)  Acc@5: 100.0000 (97.2009)  time: 0.3461  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 920/3125]  eta: 0:12:41  Lr: 0.030000  Loss: 0.6397  Acc@1: 68.7500 (67.9289)  Acc@5: 100.0000 (97.2041)  time: 0.3462  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 930/3125]  eta: 0:12:38  Lr: 0.030000  Loss: 0.3806  Acc@1: 68.7500 (67.9377)  Acc@5: 100.0000 (97.2006)  time: 0.3454  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 940/3125]  eta: 0:12:34  Lr: 0.030000  Loss: 0.3217  Acc@1: 68.7500 (67.9530)  Acc@5: 100.0000 (97.1838)  time: 0.3452  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 950/3125]  eta: 0:12:31  Lr: 0.030000  Loss: 0.3237  Acc@1: 68.7500 (67.8956)  Acc@5: 100.0000 (97.1937)  time: 0.3449  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 960/3125]  eta: 0:12:27  Lr: 0.030000  Loss: 0.4310  Acc@1: 62.5000 (67.8525)  Acc@5: 100.0000 (97.1904)  time: 0.3460  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [ 970/3125]  eta: 0:12:24  Lr: 0.030000  Loss: 0.4795  Acc@1: 68.7500 (67.8424)  Acc@5: 100.0000 (97.2001)  time: 0.3463  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [ 980/3125]  eta: 0:12:20  Lr: 0.030000  Loss: 0.2565  Acc@1: 68.7500 (67.8772)  Acc@5: 100.0000 (97.1840)  time: 0.3456  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 990/3125]  eta: 0:12:17  Lr: 0.030000  Loss: 0.2898  Acc@1: 68.7500 (67.9049)  Acc@5: 100.0000 (97.1935)  time: 0.3456  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1000/3125]  eta: 0:12:14  Lr: 0.030000  Loss: 0.4306  Acc@1: 68.7500 (67.9446)  Acc@5: 100.0000 (97.2028)  time: 0.3461  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1010/3125]  eta: 0:12:10  Lr: 0.030000  Loss: 0.3449  Acc@1: 68.7500 (67.9278)  Acc@5: 100.0000 (97.1996)  time: 0.3502  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1020/3125]  eta: 0:12:07  Lr: 0.030000  Loss: 0.3550  Acc@1: 62.5000 (67.8624)  Acc@5: 93.7500 (97.1719)  time: 0.3491  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [1030/3125]  eta: 0:12:03  Lr: 0.030000  Loss: 0.5884  Acc@1: 62.5000 (67.8528)  Acc@5: 100.0000 (97.1811)  time: 0.3448  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [1040/3125]  eta: 0:12:00  Lr: 0.030000  Loss: 0.2540  Acc@1: 68.7500 (67.8854)  Acc@5: 100.0000 (97.1782)  time: 0.3449  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [1050/3125]  eta: 0:11:56  Lr: 0.030000  Loss: 0.2496  Acc@1: 68.7500 (67.8996)  Acc@5: 100.0000 (97.1753)  time: 0.3451  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1060/3125]  eta: 0:11:53  Lr: 0.030000  Loss: 0.3909  Acc@1: 68.7500 (67.8900)  Acc@5: 100.0000 (97.1960)  time: 0.3449  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1070/3125]  eta: 0:11:49  Lr: 0.030000  Loss: 0.5904  Acc@1: 68.7500 (67.8980)  Acc@5: 100.0000 (97.2047)  time: 0.3445  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [1080/3125]  eta: 0:11:46  Lr: 0.030000  Loss: 0.4453  Acc@1: 68.7500 (67.9174)  Acc@5: 100.0000 (97.1785)  time: 0.3449  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [1090/3125]  eta: 0:11:42  Lr: 0.030000  Loss: 0.3585  Acc@1: 68.7500 (67.8964)  Acc@5: 100.0000 (97.1700)  time: 0.3445  data: 0.0002  max mem: 2500
Train: Epoch[3/5]  [1100/3125]  eta: 0:11:39  Lr: 0.030000  Loss: 0.3453  Acc@1: 68.7500 (67.8871)  Acc@5: 100.0000 (97.1673)  time: 0.3438  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [1110/3125]  eta: 0:11:36  Lr: 0.030000  Loss: 0.4014  Acc@1: 68.7500 (67.8443)  Acc@5: 93.7500 (97.1478)  time: 0.3439  data: 0.0002  max mem: 2500
Train: Epoch[3/5]  [1120/3125]  eta: 0:11:32  Lr: 0.030000  Loss: 0.3491  Acc@1: 68.7500 (67.9025)  Acc@5: 100.0000 (97.1566)  time: 0.3446  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [1130/3125]  eta: 0:11:29  Lr: 0.030000  Loss: 0.6161  Acc@1: 68.7500 (67.8990)  Acc@5: 100.0000 (97.1485)  time: 0.3447  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [1140/3125]  eta: 0:11:25  Lr: 0.030000  Loss: 0.7316  Acc@1: 62.5000 (67.8571)  Acc@5: 93.7500 (97.1188)  time: 0.3444  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [1150/3125]  eta: 0:11:22  Lr: 0.030000  Loss: 0.4348  Acc@1: 68.7500 (67.8540)  Acc@5: 93.7500 (97.1221)  time: 0.3452  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1160/3125]  eta: 0:11:18  Lr: 0.030000  Loss: 0.2921  Acc@1: 62.5000 (67.7918)  Acc@5: 100.0000 (97.1307)  time: 0.3457  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1170/3125]  eta: 0:11:15  Lr: 0.030000  Loss: 0.3913  Acc@1: 62.5000 (67.8106)  Acc@5: 100.0000 (97.1392)  time: 0.3450  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1180/3125]  eta: 0:11:11  Lr: 0.030000  Loss: 0.3062  Acc@1: 68.7500 (67.8398)  Acc@5: 100.0000 (97.1423)  time: 0.3447  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [1190/3125]  eta: 0:11:08  Lr: 0.030000  Loss: 0.3166  Acc@1: 68.7500 (67.8631)  Acc@5: 100.0000 (97.1400)  time: 0.3449  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [1200/3125]  eta: 0:11:04  Lr: 0.030000  Loss: 0.1331  Acc@1: 68.7500 (67.8497)  Acc@5: 100.0000 (97.1378)  time: 0.3449  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [1210/3125]  eta: 0:11:01  Lr: 0.030000  Loss: 0.2547  Acc@1: 68.7500 (67.8313)  Acc@5: 100.0000 (97.1356)  time: 0.3446  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [1220/3125]  eta: 0:10:57  Lr: 0.030000  Loss: 0.4343  Acc@1: 62.5000 (67.7774)  Acc@5: 100.0000 (97.1335)  time: 0.3445  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [1230/3125]  eta: 0:10:54  Lr: 0.030000  Loss: 0.3077  Acc@1: 68.7500 (67.8260)  Acc@5: 100.0000 (97.1517)  time: 0.3447  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [1240/3125]  eta: 0:10:50  Lr: 0.030000  Loss: 0.3507  Acc@1: 75.0000 (67.8435)  Acc@5: 100.0000 (97.1495)  time: 0.3442  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [1250/3125]  eta: 0:10:47  Lr: 0.030000  Loss: 0.4720  Acc@1: 68.7500 (67.8357)  Acc@5: 100.0000 (97.1673)  time: 0.3438  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [1260/3125]  eta: 0:10:44  Lr: 0.030000  Loss: 0.3991  Acc@1: 68.7500 (67.8727)  Acc@5: 100.0000 (97.1699)  time: 0.3439  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [1270/3125]  eta: 0:10:40  Lr: 0.030000  Loss: 0.5390  Acc@1: 75.0000 (67.8747)  Acc@5: 100.0000 (97.1577)  time: 0.3438  data: 0.0002  max mem: 2500
Train: Epoch[3/5]  [1280/3125]  eta: 0:10:37  Lr: 0.030000  Loss: 0.4100  Acc@1: 62.5000 (67.8327)  Acc@5: 93.7500 (97.1507)  time: 0.3439  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [1290/3125]  eta: 0:10:33  Lr: 0.030000  Loss: 0.2715  Acc@1: 68.7500 (67.8447)  Acc@5: 93.7500 (97.1340)  time: 0.3448  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [1300/3125]  eta: 0:10:30  Lr: 0.030000  Loss: 0.3635  Acc@1: 68.7500 (67.8084)  Acc@5: 93.7500 (97.1320)  time: 0.3452  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1310/3125]  eta: 0:10:26  Lr: 0.030000  Loss: 0.2972  Acc@1: 68.7500 (67.7965)  Acc@5: 93.7500 (97.1158)  time: 0.3454  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1320/3125]  eta: 0:10:23  Lr: 0.030000  Loss: 0.4707  Acc@1: 62.5000 (67.8037)  Acc@5: 93.7500 (97.0950)  time: 0.3451  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1330/3125]  eta: 0:10:19  Lr: 0.030000  Loss: 0.4094  Acc@1: 68.7500 (67.7592)  Acc@5: 93.7500 (97.0887)  time: 0.3465  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1340/3125]  eta: 0:10:16  Lr: 0.030000  Loss: 0.7971  Acc@1: 68.7500 (67.7386)  Acc@5: 100.0000 (97.0731)  time: 0.3470  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [1350/3125]  eta: 0:10:12  Lr: 0.030000  Loss: 0.7258  Acc@1: 68.7500 (67.7507)  Acc@5: 100.0000 (97.0716)  time: 0.3450  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [1360/3125]  eta: 0:10:09  Lr: 0.030000  Loss: 0.2319  Acc@1: 68.7500 (67.7994)  Acc@5: 100.0000 (97.0794)  time: 0.3454  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1370/3125]  eta: 0:10:06  Lr: 0.030000  Loss: 0.4046  Acc@1: 68.7500 (67.7972)  Acc@5: 100.0000 (97.0824)  time: 0.3458  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1380/3125]  eta: 0:10:02  Lr: 0.030000  Loss: 0.3742  Acc@1: 68.7500 (67.8177)  Acc@5: 100.0000 (97.0945)  time: 0.3451  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [1390/3125]  eta: 0:09:59  Lr: 0.030000  Loss: 0.3556  Acc@1: 75.0000 (67.8559)  Acc@5: 100.0000 (97.0929)  time: 0.3452  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [1400/3125]  eta: 0:09:55  Lr: 0.030000  Loss: 0.5124  Acc@1: 68.7500 (67.8622)  Acc@5: 100.0000 (97.0869)  time: 0.3455  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [1410/3125]  eta: 0:09:52  Lr: 0.030000  Loss: 0.2018  Acc@1: 68.7500 (67.8508)  Acc@5: 100.0000 (97.1031)  time: 0.3466  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1420/3125]  eta: 0:09:48  Lr: 0.030000  Loss: 0.4448  Acc@1: 68.7500 (67.8659)  Acc@5: 100.0000 (97.1015)  time: 0.3469  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [1430/3125]  eta: 0:09:45  Lr: 0.030000  Loss: 0.6160  Acc@1: 68.7500 (67.8590)  Acc@5: 93.7500 (97.0868)  time: 0.3464  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1440/3125]  eta: 0:09:41  Lr: 0.030000  Loss: 0.3336  Acc@1: 75.0000 (67.8695)  Acc@5: 93.7500 (97.0767)  time: 0.3454  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [1450/3125]  eta: 0:09:38  Lr: 0.030000  Loss: 0.4119  Acc@1: 75.0000 (67.9101)  Acc@5: 93.7500 (97.0710)  time: 0.3438  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [1460/3125]  eta: 0:09:34  Lr: 0.030000  Loss: 0.3398  Acc@1: 68.7500 (67.9073)  Acc@5: 100.0000 (97.0696)  time: 0.3437  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [1470/3125]  eta: 0:09:31  Lr: 0.030000  Loss: 0.2773  Acc@1: 75.0000 (67.9597)  Acc@5: 100.0000 (97.0641)  time: 0.3441  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [1480/3125]  eta: 0:09:28  Lr: 0.030000  Loss: 0.2171  Acc@1: 75.0000 (67.9651)  Acc@5: 100.0000 (97.0755)  time: 0.3443  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [1490/3125]  eta: 0:09:24  Lr: 0.030000  Loss: 0.2907  Acc@1: 68.7500 (68.0122)  Acc@5: 100.0000 (97.0615)  time: 0.3444  data: 0.0002  max mem: 2500
Train: Epoch[3/5]  [1500/3125]  eta: 0:09:21  Lr: 0.030000  Loss: 0.3429  Acc@1: 68.7500 (68.0005)  Acc@5: 93.7500 (97.0436)  time: 0.3445  data: 0.0002  max mem: 2500
Train: Epoch[3/5]  [1510/3125]  eta: 0:09:17  Lr: 0.030000  Loss: 0.4569  Acc@1: 62.5000 (67.9806)  Acc@5: 93.7500 (97.0425)  time: 0.3451  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [1520/3125]  eta: 0:09:14  Lr: 0.030000  Loss: 0.0893  Acc@1: 68.7500 (68.0186)  Acc@5: 100.0000 (97.0455)  time: 0.3470  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [1530/3125]  eta: 0:09:10  Lr: 0.030000  Loss: 0.3731  Acc@1: 68.7500 (68.0560)  Acc@5: 100.0000 (97.0607)  time: 0.3484  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [1540/3125]  eta: 0:09:07  Lr: 0.030000  Loss: 0.6795  Acc@1: 62.5000 (68.0078)  Acc@5: 100.0000 (97.0636)  time: 0.3482  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [1550/3125]  eta: 0:09:03  Lr: 0.030000  Loss: 0.3055  Acc@1: 62.5000 (67.9965)  Acc@5: 100.0000 (97.0825)  time: 0.3462  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [1560/3125]  eta: 0:09:00  Lr: 0.030000  Loss: 0.4378  Acc@1: 68.7500 (67.9813)  Acc@5: 100.0000 (97.0772)  time: 0.3456  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1570/3125]  eta: 0:08:57  Lr: 0.030000  Loss: 0.5917  Acc@1: 68.7500 (67.9822)  Acc@5: 100.0000 (97.0839)  time: 0.3460  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1580/3125]  eta: 0:08:53  Lr: 0.030000  Loss: 0.3426  Acc@1: 68.7500 (67.9673)  Acc@5: 100.0000 (97.0904)  time: 0.3461  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1590/3125]  eta: 0:08:50  Lr: 0.030000  Loss: 0.4908  Acc@1: 68.7500 (67.9604)  Acc@5: 100.0000 (97.0970)  time: 0.3468  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1600/3125]  eta: 0:08:46  Lr: 0.030000  Loss: 0.3515  Acc@1: 68.7500 (67.9966)  Acc@5: 100.0000 (97.0995)  time: 0.3467  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1610/3125]  eta: 0:08:43  Lr: 0.030000  Loss: 0.3538  Acc@1: 68.7500 (67.9896)  Acc@5: 100.0000 (97.1097)  time: 0.3472  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [1620/3125]  eta: 0:08:39  Lr: 0.030000  Loss: 0.3954  Acc@1: 68.7500 (67.9750)  Acc@5: 100.0000 (97.1083)  time: 0.3512  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [1630/3125]  eta: 0:08:36  Lr: 0.030000  Loss: 0.6897  Acc@1: 62.5000 (67.9414)  Acc@5: 100.0000 (97.1068)  time: 0.3517  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1640/3125]  eta: 0:08:33  Lr: 0.030000  Loss: 0.4042  Acc@1: 68.7500 (67.9768)  Acc@5: 100.0000 (97.1130)  time: 0.3468  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [1650/3125]  eta: 0:08:29  Lr: 0.030000  Loss: 0.4860  Acc@1: 68.7500 (67.9702)  Acc@5: 100.0000 (97.1192)  time: 0.3454  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [1660/3125]  eta: 0:08:26  Lr: 0.030000  Loss: 0.4549  Acc@1: 68.7500 (67.9485)  Acc@5: 100.0000 (97.1177)  time: 0.3464  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [1670/3125]  eta: 0:08:22  Lr: 0.030000  Loss: 0.6783  Acc@1: 68.7500 (67.9197)  Acc@5: 93.7500 (97.1125)  time: 0.3461  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [1680/3125]  eta: 0:08:19  Lr: 0.030000  Loss: 0.2079  Acc@1: 68.7500 (67.9358)  Acc@5: 93.7500 (97.1074)  time: 0.3453  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [1690/3125]  eta: 0:08:15  Lr: 0.030000  Loss: 0.3743  Acc@1: 68.7500 (67.9295)  Acc@5: 100.0000 (97.1097)  time: 0.3453  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [1700/3125]  eta: 0:08:12  Lr: 0.030000  Loss: 0.4302  Acc@1: 62.5000 (67.9123)  Acc@5: 100.0000 (97.1120)  time: 0.3457  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [1710/3125]  eta: 0:08:08  Lr: 0.030000  Loss: 0.4222  Acc@1: 68.7500 (67.9172)  Acc@5: 100.0000 (97.1106)  time: 0.3450  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [1720/3125]  eta: 0:08:05  Lr: 0.030000  Loss: 0.4288  Acc@1: 68.7500 (67.9293)  Acc@5: 100.0000 (97.1165)  time: 0.3436  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [1730/3125]  eta: 0:08:01  Lr: 0.030000  Loss: 0.4858  Acc@1: 68.7500 (67.9232)  Acc@5: 100.0000 (97.1259)  time: 0.3435  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [1740/3125]  eta: 0:07:58  Lr: 0.030000  Loss: 0.7295  Acc@1: 68.7500 (67.9459)  Acc@5: 100.0000 (97.1137)  time: 0.3437  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [1750/3125]  eta: 0:07:54  Lr: 0.030000  Loss: 0.5934  Acc@1: 68.7500 (67.9683)  Acc@5: 93.7500 (97.1052)  time: 0.3436  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [1760/3125]  eta: 0:07:51  Lr: 0.030000  Loss: 0.1673  Acc@1: 68.7500 (68.0011)  Acc@5: 100.0000 (97.1039)  time: 0.3438  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [1770/3125]  eta: 0:07:48  Lr: 0.030000  Loss: 0.3360  Acc@1: 68.7500 (68.0089)  Acc@5: 100.0000 (97.1097)  time: 0.3438  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [1780/3125]  eta: 0:07:44  Lr: 0.030000  Loss: 0.4891  Acc@1: 68.7500 (68.0060)  Acc@5: 100.0000 (97.1049)  time: 0.3439  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [1790/3125]  eta: 0:07:41  Lr: 0.030000  Loss: 0.2974  Acc@1: 62.5000 (67.9997)  Acc@5: 100.0000 (97.1140)  time: 0.3453  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1800/3125]  eta: 0:07:37  Lr: 0.030000  Loss: 0.3564  Acc@1: 62.5000 (67.9900)  Acc@5: 100.0000 (97.1092)  time: 0.3467  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1810/3125]  eta: 0:07:34  Lr: 0.030000  Loss: 0.4980  Acc@1: 62.5000 (67.9838)  Acc@5: 93.7500 (97.1010)  time: 0.3463  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1820/3125]  eta: 0:07:30  Lr: 0.030000  Loss: 0.3142  Acc@1: 68.7500 (67.9949)  Acc@5: 93.7500 (97.0929)  time: 0.3452  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [1830/3125]  eta: 0:07:27  Lr: 0.030000  Loss: 0.4032  Acc@1: 68.7500 (67.9990)  Acc@5: 100.0000 (97.1020)  time: 0.3446  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [1840/3125]  eta: 0:07:23  Lr: 0.030000  Loss: 0.2573  Acc@1: 68.7500 (68.0235)  Acc@5: 100.0000 (97.1076)  time: 0.3448  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [1850/3125]  eta: 0:07:20  Lr: 0.030000  Loss: 0.1250  Acc@1: 75.0000 (68.0544)  Acc@5: 100.0000 (97.1130)  time: 0.3459  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1860/3125]  eta: 0:07:16  Lr: 0.030000  Loss: 0.7338  Acc@1: 68.7500 (68.0380)  Acc@5: 100.0000 (97.1051)  time: 0.3464  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1870/3125]  eta: 0:07:13  Lr: 0.030000  Loss: 0.3078  Acc@1: 68.7500 (68.0351)  Acc@5: 93.7500 (97.1038)  time: 0.3460  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1880/3125]  eta: 0:07:10  Lr: 0.030000  Loss: 0.2473  Acc@1: 75.0000 (68.0888)  Acc@5: 100.0000 (97.1093)  time: 0.3456  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1890/3125]  eta: 0:07:06  Lr: 0.030000  Loss: 0.3852  Acc@1: 75.0000 (68.0923)  Acc@5: 100.0000 (97.1146)  time: 0.3492  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [1900/3125]  eta: 0:07:03  Lr: 0.030000  Loss: 0.2488  Acc@1: 62.5000 (68.0990)  Acc@5: 100.0000 (97.1101)  time: 0.3490  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [1910/3125]  eta: 0:06:59  Lr: 0.030000  Loss: 0.3790  Acc@1: 68.7500 (68.0926)  Acc@5: 93.7500 (97.1023)  time: 0.3450  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1920/3125]  eta: 0:06:56  Lr: 0.030000  Loss: 0.1755  Acc@1: 68.7500 (68.0993)  Acc@5: 100.0000 (97.0979)  time: 0.3449  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [1930/3125]  eta: 0:06:52  Lr: 0.030000  Loss: 0.2840  Acc@1: 75.0000 (68.1189)  Acc@5: 93.7500 (97.0967)  time: 0.3450  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [1940/3125]  eta: 0:06:49  Lr: 0.030000  Loss: 0.3625  Acc@1: 75.0000 (68.1221)  Acc@5: 100.0000 (97.0988)  time: 0.3453  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [1950/3125]  eta: 0:06:45  Lr: 0.030000  Loss: 0.0735  Acc@1: 68.7500 (68.1317)  Acc@5: 100.0000 (97.1040)  time: 0.3453  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [1960/3125]  eta: 0:06:42  Lr: 0.030000  Loss: 0.3868  Acc@1: 62.5000 (68.1062)  Acc@5: 100.0000 (97.1093)  time: 0.3453  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [1970/3125]  eta: 0:06:39  Lr: 0.030000  Loss: 0.2350  Acc@1: 68.7500 (68.1253)  Acc@5: 100.0000 (97.1208)  time: 0.3462  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [1980/3125]  eta: 0:06:35  Lr: 0.030000  Loss: 0.2813  Acc@1: 68.7500 (68.1064)  Acc@5: 100.0000 (97.1195)  time: 0.3452  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [1990/3125]  eta: 0:06:32  Lr: 0.030000  Loss: 0.1836  Acc@1: 68.7500 (68.1222)  Acc@5: 93.7500 (97.0994)  time: 0.3432  data: 0.0002  max mem: 2500
Train: Epoch[3/5]  [2000/3125]  eta: 0:06:28  Lr: 0.030000  Loss: 0.3235  Acc@1: 68.7500 (68.1159)  Acc@5: 93.7500 (97.0983)  time: 0.3431  data: 0.0002  max mem: 2500
Train: Epoch[3/5]  [2010/3125]  eta: 0:06:25  Lr: 0.030000  Loss: 0.4515  Acc@1: 62.5000 (68.0880)  Acc@5: 93.7500 (97.0941)  time: 0.3433  data: 0.0002  max mem: 2500
Train: Epoch[3/5]  [2020/3125]  eta: 0:06:21  Lr: 0.030000  Loss: 0.5097  Acc@1: 62.5000 (68.1068)  Acc@5: 93.7500 (97.0899)  time: 0.3434  data: 0.0002  max mem: 2500
Train: Epoch[3/5]  [2030/3125]  eta: 0:06:18  Lr: 0.030000  Loss: 0.3654  Acc@1: 75.0000 (68.1192)  Acc@5: 100.0000 (97.0889)  time: 0.3434  data: 0.0002  max mem: 2500
Train: Epoch[3/5]  [2040/3125]  eta: 0:06:14  Lr: 0.030000  Loss: 0.5823  Acc@1: 75.0000 (68.1345)  Acc@5: 100.0000 (97.0939)  time: 0.3433  data: 0.0002  max mem: 2500
Train: Epoch[3/5]  [2050/3125]  eta: 0:06:11  Lr: 0.030000  Loss: 0.2556  Acc@1: 68.7500 (68.1558)  Acc@5: 100.0000 (97.0990)  time: 0.3430  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [2060/3125]  eta: 0:06:07  Lr: 0.030000  Loss: 0.4244  Acc@1: 68.7500 (68.1617)  Acc@5: 100.0000 (97.1040)  time: 0.3435  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [2070/3125]  eta: 0:06:04  Lr: 0.030000  Loss: 0.3737  Acc@1: 68.7500 (68.1676)  Acc@5: 100.0000 (97.1028)  time: 0.3454  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2080/3125]  eta: 0:06:00  Lr: 0.030000  Loss: 0.3802  Acc@1: 68.7500 (68.1764)  Acc@5: 93.7500 (97.0988)  time: 0.3458  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [2090/3125]  eta: 0:05:57  Lr: 0.030000  Loss: 0.4918  Acc@1: 75.0000 (68.2030)  Acc@5: 100.0000 (97.1037)  time: 0.3450  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [2100/3125]  eta: 0:05:54  Lr: 0.030000  Loss: 0.2477  Acc@1: 68.7500 (68.1967)  Acc@5: 100.0000 (97.1055)  time: 0.3452  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2110/3125]  eta: 0:05:50  Lr: 0.030000  Loss: 0.4900  Acc@1: 68.7500 (68.2141)  Acc@5: 100.0000 (97.1045)  time: 0.3449  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2120/3125]  eta: 0:05:47  Lr: 0.030000  Loss: 0.3806  Acc@1: 68.7500 (68.2137)  Acc@5: 100.0000 (97.1004)  time: 0.3445  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2130/3125]  eta: 0:05:43  Lr: 0.030000  Loss: 0.5905  Acc@1: 68.7500 (68.2103)  Acc@5: 100.0000 (97.1052)  time: 0.3447  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2140/3125]  eta: 0:05:40  Lr: 0.030000  Loss: 0.5424  Acc@1: 68.7500 (68.2070)  Acc@5: 100.0000 (97.1071)  time: 0.3448  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2150/3125]  eta: 0:05:36  Lr: 0.030000  Loss: 0.2208  Acc@1: 68.7500 (68.2008)  Acc@5: 100.0000 (97.1060)  time: 0.3449  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2160/3125]  eta: 0:05:33  Lr: 0.030000  Loss: 0.2738  Acc@1: 68.7500 (68.2294)  Acc@5: 100.0000 (97.0991)  time: 0.3455  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2170/3125]  eta: 0:05:29  Lr: 0.030000  Loss: 0.2040  Acc@1: 75.0000 (68.2491)  Acc@5: 93.7500 (97.0952)  time: 0.3453  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2180/3125]  eta: 0:05:26  Lr: 0.030000  Loss: 0.4679  Acc@1: 75.0000 (68.2829)  Acc@5: 100.0000 (97.1000)  time: 0.3446  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2190/3125]  eta: 0:05:22  Lr: 0.030000  Loss: 0.2048  Acc@1: 68.7500 (68.2822)  Acc@5: 100.0000 (97.0932)  time: 0.3453  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2200/3125]  eta: 0:05:19  Lr: 0.030000  Loss: 0.2640  Acc@1: 62.5000 (68.2644)  Acc@5: 93.7500 (97.0922)  time: 0.3455  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2210/3125]  eta: 0:05:16  Lr: 0.030000  Loss: 0.4192  Acc@1: 68.7500 (68.2977)  Acc@5: 93.7500 (97.0884)  time: 0.3453  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [2220/3125]  eta: 0:05:12  Lr: 0.030000  Loss: 0.1405  Acc@1: 68.7500 (68.3054)  Acc@5: 93.7500 (97.0762)  time: 0.3452  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2230/3125]  eta: 0:05:09  Lr: 0.030000  Loss: 0.3741  Acc@1: 68.7500 (68.3074)  Acc@5: 93.7500 (97.0669)  time: 0.3451  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2240/3125]  eta: 0:05:05  Lr: 0.030000  Loss: 0.3872  Acc@1: 68.7500 (68.2954)  Acc@5: 93.7500 (97.0605)  time: 0.3459  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2250/3125]  eta: 0:05:02  Lr: 0.030000  Loss: 0.2758  Acc@1: 68.7500 (68.2891)  Acc@5: 100.0000 (97.0680)  time: 0.3460  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2260/3125]  eta: 0:04:58  Lr: 0.030000  Loss: 0.4953  Acc@1: 68.7500 (68.3077)  Acc@5: 100.0000 (97.0699)  time: 0.3452  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [2270/3125]  eta: 0:04:55  Lr: 0.030000  Loss: 0.3202  Acc@1: 68.7500 (68.3069)  Acc@5: 100.0000 (97.0745)  time: 0.3447  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [2280/3125]  eta: 0:04:51  Lr: 0.030000  Loss: 0.2899  Acc@1: 68.7500 (68.3417)  Acc@5: 100.0000 (97.0874)  time: 0.3458  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [2290/3125]  eta: 0:04:48  Lr: 0.030000  Loss: 0.2047  Acc@1: 75.0000 (68.3626)  Acc@5: 100.0000 (97.0892)  time: 0.3458  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [2300/3125]  eta: 0:04:44  Lr: 0.030000  Loss: 0.4792  Acc@1: 75.0000 (68.3887)  Acc@5: 100.0000 (97.0937)  time: 0.3449  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [2310/3125]  eta: 0:04:41  Lr: 0.030000  Loss: 0.3100  Acc@1: 75.0000 (68.4092)  Acc@5: 100.0000 (97.0981)  time: 0.3450  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [2320/3125]  eta: 0:04:38  Lr: 0.030000  Loss: 0.2864  Acc@1: 75.0000 (68.4322)  Acc@5: 100.0000 (97.0972)  time: 0.3456  data: 0.0010  max mem: 2500
Train: Epoch[3/5]  [2330/3125]  eta: 0:04:34  Lr: 0.030000  Loss: 0.5102  Acc@1: 68.7500 (68.4095)  Acc@5: 100.0000 (97.0989)  time: 0.3447  data: 0.0009  max mem: 2500
Train: Epoch[3/5]  [2340/3125]  eta: 0:04:31  Lr: 0.030000  Loss: 0.3222  Acc@1: 68.7500 (68.4296)  Acc@5: 100.0000 (97.1033)  time: 0.3429  data: 0.0002  max mem: 2500
Train: Epoch[3/5]  [2350/3125]  eta: 0:04:27  Lr: 0.030000  Loss: 0.4889  Acc@1: 62.5000 (68.4124)  Acc@5: 100.0000 (97.1076)  time: 0.3428  data: 0.0002  max mem: 2500
Train: Epoch[3/5]  [2360/3125]  eta: 0:04:24  Lr: 0.030000  Loss: 0.3297  Acc@1: 62.5000 (68.4138)  Acc@5: 100.0000 (97.1146)  time: 0.3428  data: 0.0002  max mem: 2500
Train: Epoch[3/5]  [2370/3125]  eta: 0:04:20  Lr: 0.030000  Loss: 0.4458  Acc@1: 68.7500 (68.4126)  Acc@5: 100.0000 (97.1162)  time: 0.3430  data: 0.0002  max mem: 2500
Train: Epoch[3/5]  [2380/3125]  eta: 0:04:17  Lr: 0.030000  Loss: 0.3328  Acc@1: 68.7500 (68.4350)  Acc@5: 100.0000 (97.1231)  time: 0.3435  data: 0.0002  max mem: 2500
Train: Epoch[3/5]  [2390/3125]  eta: 0:04:13  Lr: 0.030000  Loss: 0.6810  Acc@1: 68.7500 (68.4102)  Acc@5: 100.0000 (97.1142)  time: 0.3437  data: 0.0002  max mem: 2500
Train: Epoch[3/5]  [2400/3125]  eta: 0:04:10  Lr: 0.030000  Loss: 0.3173  Acc@1: 62.5000 (68.3934)  Acc@5: 100.0000 (97.1184)  time: 0.3448  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [2410/3125]  eta: 0:04:06  Lr: 0.030000  Loss: 0.3974  Acc@1: 62.5000 (68.3793)  Acc@5: 100.0000 (97.1070)  time: 0.3456  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2420/3125]  eta: 0:04:03  Lr: 0.030000  Loss: 0.3547  Acc@1: 68.7500 (68.3808)  Acc@5: 100.0000 (97.1138)  time: 0.3454  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [2430/3125]  eta: 0:03:59  Lr: 0.030000  Loss: 0.1903  Acc@1: 68.7500 (68.3849)  Acc@5: 100.0000 (97.1051)  time: 0.3454  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2440/3125]  eta: 0:03:56  Lr: 0.030000  Loss: 0.1991  Acc@1: 68.7500 (68.3864)  Acc@5: 93.7500 (97.0990)  time: 0.3448  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2450/3125]  eta: 0:03:53  Lr: 0.030000  Loss: 0.1058  Acc@1: 62.5000 (68.3650)  Acc@5: 100.0000 (97.0956)  time: 0.3448  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2460/3125]  eta: 0:03:49  Lr: 0.030000  Loss: 0.3966  Acc@1: 62.5000 (68.3691)  Acc@5: 100.0000 (97.0998)  time: 0.3451  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2470/3125]  eta: 0:03:46  Lr: 0.030000  Loss: 0.2703  Acc@1: 68.7500 (68.3681)  Acc@5: 100.0000 (97.1039)  time: 0.3461  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [2480/3125]  eta: 0:03:42  Lr: 0.030000  Loss: 0.5051  Acc@1: 68.7500 (68.3545)  Acc@5: 100.0000 (97.1105)  time: 0.3462  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2490/3125]  eta: 0:03:39  Lr: 0.030000  Loss: 0.4849  Acc@1: 68.7500 (68.3435)  Acc@5: 100.0000 (97.1021)  time: 0.3455  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2500/3125]  eta: 0:03:35  Lr: 0.030000  Loss: 0.2672  Acc@1: 68.7500 (68.3352)  Acc@5: 100.0000 (97.1012)  time: 0.3458  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [2510/3125]  eta: 0:03:32  Lr: 0.030000  Loss: 0.2693  Acc@1: 68.7500 (68.3418)  Acc@5: 100.0000 (97.1027)  time: 0.3460  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2520/3125]  eta: 0:03:28  Lr: 0.030000  Loss: 0.2396  Acc@1: 68.7500 (68.3756)  Acc@5: 100.0000 (97.1068)  time: 0.3498  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2530/3125]  eta: 0:03:25  Lr: 0.030000  Loss: 0.2436  Acc@1: 68.7500 (68.3845)  Acc@5: 100.0000 (97.1084)  time: 0.3496  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [2540/3125]  eta: 0:03:22  Lr: 0.030000  Loss: 0.2664  Acc@1: 75.0000 (68.4204)  Acc@5: 100.0000 (97.1173)  time: 0.3456  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [2550/3125]  eta: 0:03:18  Lr: 0.030000  Loss: 0.1646  Acc@1: 75.0000 (68.4241)  Acc@5: 100.0000 (97.1163)  time: 0.3452  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [2560/3125]  eta: 0:03:15  Lr: 0.030000  Loss: 0.4908  Acc@1: 68.7500 (68.4425)  Acc@5: 100.0000 (97.1227)  time: 0.3449  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [2570/3125]  eta: 0:03:11  Lr: 0.030000  Loss: 0.4431  Acc@1: 68.7500 (68.4267)  Acc@5: 100.0000 (97.1144)  time: 0.3439  data: 0.0002  max mem: 2500
Train: Epoch[3/5]  [2580/3125]  eta: 0:03:08  Lr: 0.030000  Loss: 0.3091  Acc@1: 68.7500 (68.4425)  Acc@5: 100.0000 (97.1184)  time: 0.3434  data: 0.0002  max mem: 2500
Train: Epoch[3/5]  [2590/3125]  eta: 0:03:04  Lr: 0.030000  Loss: 0.6361  Acc@1: 68.7500 (68.4509)  Acc@5: 100.0000 (97.1174)  time: 0.3435  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [2600/3125]  eta: 0:03:01  Lr: 0.030000  Loss: 0.4977  Acc@1: 68.7500 (68.4592)  Acc@5: 100.0000 (97.1165)  time: 0.3445  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [2610/3125]  eta: 0:02:57  Lr: 0.030000  Loss: 0.3110  Acc@1: 68.7500 (68.4460)  Acc@5: 100.0000 (97.1204)  time: 0.3454  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2620/3125]  eta: 0:02:54  Lr: 0.030000  Loss: 0.4144  Acc@1: 68.7500 (68.4519)  Acc@5: 93.7500 (97.1147)  time: 0.3457  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2630/3125]  eta: 0:02:50  Lr: 0.030000  Loss: 0.4121  Acc@1: 68.7500 (68.4507)  Acc@5: 100.0000 (97.1232)  time: 0.3453  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [2640/3125]  eta: 0:02:47  Lr: 0.030000  Loss: 0.3770  Acc@1: 68.7500 (68.4471)  Acc@5: 100.0000 (97.1247)  time: 0.3448  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [2650/3125]  eta: 0:02:44  Lr: 0.030000  Loss: 0.4928  Acc@1: 62.5000 (68.4152)  Acc@5: 100.0000 (97.1190)  time: 0.3450  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [2660/3125]  eta: 0:02:40  Lr: 0.030000  Loss: 0.5442  Acc@1: 62.5000 (68.4235)  Acc@5: 100.0000 (97.1251)  time: 0.3451  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [2670/3125]  eta: 0:02:37  Lr: 0.030000  Loss: 0.3102  Acc@1: 68.7500 (68.4341)  Acc@5: 100.0000 (97.1219)  time: 0.3459  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [2680/3125]  eta: 0:02:33  Lr: 0.030000  Loss: 0.5711  Acc@1: 68.7500 (68.4563)  Acc@5: 100.0000 (97.1279)  time: 0.3448  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [2690/3125]  eta: 0:02:30  Lr: 0.030000  Loss: 0.4505  Acc@1: 68.7500 (68.4620)  Acc@5: 100.0000 (97.1270)  time: 0.3432  data: 0.0002  max mem: 2500
Train: Epoch[3/5]  [2700/3125]  eta: 0:02:26  Lr: 0.030000  Loss: 0.4242  Acc@1: 68.7500 (68.4515)  Acc@5: 100.0000 (97.1284)  time: 0.3432  data: 0.0002  max mem: 2500
Train: Epoch[3/5]  [2710/3125]  eta: 0:02:23  Lr: 0.030000  Loss: 0.2672  Acc@1: 68.7500 (68.4526)  Acc@5: 100.0000 (97.1297)  time: 0.3433  data: 0.0002  max mem: 2500
Train: Epoch[3/5]  [2720/3125]  eta: 0:02:19  Lr: 0.030000  Loss: 0.3267  Acc@1: 68.7500 (68.4698)  Acc@5: 100.0000 (97.1311)  time: 0.3435  data: 0.0002  max mem: 2500
Train: Epoch[3/5]  [2730/3125]  eta: 0:02:16  Lr: 0.030000  Loss: 0.4147  Acc@1: 75.0000 (68.4937)  Acc@5: 100.0000 (97.1279)  time: 0.3434  data: 0.0002  max mem: 2500
Train: Epoch[3/5]  [2740/3125]  eta: 0:02:12  Lr: 0.030000  Loss: 0.1235  Acc@1: 75.0000 (68.4969)  Acc@5: 93.7500 (97.1247)  time: 0.3437  data: 0.0002  max mem: 2500
Train: Epoch[3/5]  [2750/3125]  eta: 0:02:09  Lr: 0.030000  Loss: 0.2483  Acc@1: 68.7500 (68.5024)  Acc@5: 100.0000 (97.1260)  time: 0.3439  data: 0.0002  max mem: 2500
Train: Epoch[3/5]  [2760/3125]  eta: 0:02:06  Lr: 0.030000  Loss: 0.2508  Acc@1: 68.7500 (68.5078)  Acc@5: 100.0000 (97.1297)  time: 0.3435  data: 0.0002  max mem: 2500
Train: Epoch[3/5]  [2770/3125]  eta: 0:02:02  Lr: 0.030000  Loss: 0.2529  Acc@1: 75.0000 (68.5425)  Acc@5: 100.0000 (97.1333)  time: 0.3442  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [2780/3125]  eta: 0:01:59  Lr: 0.030000  Loss: 0.2299  Acc@1: 75.0000 (68.5387)  Acc@5: 100.0000 (97.1301)  time: 0.3456  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2790/3125]  eta: 0:01:55  Lr: 0.030000  Loss: 0.3871  Acc@1: 75.0000 (68.5619)  Acc@5: 100.0000 (97.1359)  time: 0.3463  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2800/3125]  eta: 0:01:52  Lr: 0.030000  Loss: 0.3400  Acc@1: 68.7500 (68.5536)  Acc@5: 100.0000 (97.1350)  time: 0.3462  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2810/3125]  eta: 0:01:48  Lr: 0.030000  Loss: 0.2581  Acc@1: 62.5000 (68.5254)  Acc@5: 100.0000 (97.1274)  time: 0.3468  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2820/3125]  eta: 0:01:45  Lr: 0.030000  Loss: 0.1186  Acc@1: 68.7500 (68.5351)  Acc@5: 100.0000 (97.1287)  time: 0.3465  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2830/3125]  eta: 0:01:41  Lr: 0.030000  Loss: 0.5797  Acc@1: 68.7500 (68.5359)  Acc@5: 100.0000 (97.1300)  time: 0.3458  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2840/3125]  eta: 0:01:38  Lr: 0.030000  Loss: 0.5130  Acc@1: 62.5000 (68.5278)  Acc@5: 100.0000 (97.1335)  time: 0.3468  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2850/3125]  eta: 0:01:34  Lr: 0.030000  Loss: 0.3606  Acc@1: 75.0000 (68.5637)  Acc@5: 100.0000 (97.1414)  time: 0.3465  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2860/3125]  eta: 0:01:31  Lr: 0.030000  Loss: 0.5477  Acc@1: 68.7500 (68.5578)  Acc@5: 100.0000 (97.1404)  time: 0.3464  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2870/3125]  eta: 0:01:28  Lr: 0.030000  Loss: 0.1556  Acc@1: 68.7500 (68.5780)  Acc@5: 100.0000 (97.1439)  time: 0.3466  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2880/3125]  eta: 0:01:24  Lr: 0.030000  Loss: 0.5531  Acc@1: 68.7500 (68.5721)  Acc@5: 100.0000 (97.1451)  time: 0.3453  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2890/3125]  eta: 0:01:21  Lr: 0.030000  Loss: 0.1640  Acc@1: 75.0000 (68.5965)  Acc@5: 100.0000 (97.1463)  time: 0.3448  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2900/3125]  eta: 0:01:17  Lr: 0.030000  Loss: 0.4376  Acc@1: 68.7500 (68.5970)  Acc@5: 100.0000 (97.1389)  time: 0.3453  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [2910/3125]  eta: 0:01:14  Lr: 0.030000  Loss: 0.3469  Acc@1: 68.7500 (68.5976)  Acc@5: 100.0000 (97.1423)  time: 0.3457  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2920/3125]  eta: 0:01:10  Lr: 0.030000  Loss: 0.3687  Acc@1: 68.7500 (68.6066)  Acc@5: 100.0000 (97.1393)  time: 0.3459  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2930/3125]  eta: 0:01:07  Lr: 0.030000  Loss: 0.3541  Acc@1: 62.5000 (68.6007)  Acc@5: 100.0000 (97.1426)  time: 0.3459  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2940/3125]  eta: 0:01:03  Lr: 0.030000  Loss: 0.2540  Acc@1: 62.5000 (68.5970)  Acc@5: 100.0000 (97.1396)  time: 0.3454  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2950/3125]  eta: 0:01:00  Lr: 0.030000  Loss: 0.3057  Acc@1: 68.7500 (68.6123)  Acc@5: 93.7500 (97.1366)  time: 0.3450  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [2960/3125]  eta: 0:00:56  Lr: 0.030000  Loss: 0.4544  Acc@1: 75.0000 (68.6191)  Acc@5: 93.7500 (97.1293)  time: 0.3458  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [2970/3125]  eta: 0:00:53  Lr: 0.030000  Loss: 0.6311  Acc@1: 62.5000 (68.6070)  Acc@5: 93.7500 (97.1264)  time: 0.3456  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [2980/3125]  eta: 0:00:50  Lr: 0.030000  Loss: 0.4177  Acc@1: 68.7500 (68.6179)  Acc@5: 100.0000 (97.1297)  time: 0.3447  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [2990/3125]  eta: 0:00:46  Lr: 0.030000  Loss: 0.4324  Acc@1: 68.7500 (68.6225)  Acc@5: 100.0000 (97.1289)  time: 0.3446  data: 0.0002  max mem: 2500
Train: Epoch[3/5]  [3000/3125]  eta: 0:00:43  Lr: 0.030000  Loss: 0.1393  Acc@1: 62.5000 (68.6105)  Acc@5: 100.0000 (97.1280)  time: 0.3445  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [3010/3125]  eta: 0:00:39  Lr: 0.030000  Loss: 0.2570  Acc@1: 68.7500 (68.6275)  Acc@5: 100.0000 (97.1272)  time: 0.3440  data: 0.0002  max mem: 2500
Train: Epoch[3/5]  [3020/3125]  eta: 0:00:36  Lr: 0.030000  Loss: 0.1376  Acc@1: 75.0000 (68.6466)  Acc@5: 100.0000 (97.1367)  time: 0.3434  data: 0.0002  max mem: 2500
Train: Epoch[3/5]  [3030/3125]  eta: 0:00:32  Lr: 0.030000  Loss: 0.3135  Acc@1: 75.0000 (68.6593)  Acc@5: 100.0000 (97.1379)  time: 0.3437  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [3040/3125]  eta: 0:00:29  Lr: 0.030000  Loss: 0.4813  Acc@1: 68.7500 (68.6637)  Acc@5: 100.0000 (97.1391)  time: 0.3442  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [3050/3125]  eta: 0:00:25  Lr: 0.030000  Loss: 0.4061  Acc@1: 68.7500 (68.6722)  Acc@5: 100.0000 (97.1464)  time: 0.3450  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3060/3125]  eta: 0:00:22  Lr: 0.030000  Loss: 0.3921  Acc@1: 68.7500 (68.6683)  Acc@5: 100.0000 (97.1476)  time: 0.3452  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3070/3125]  eta: 0:00:18  Lr: 0.030000  Loss: 0.1869  Acc@1: 68.7500 (68.6666)  Acc@5: 100.0000 (97.1487)  time: 0.3457  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3080/3125]  eta: 0:00:15  Lr: 0.030000  Loss: 0.3032  Acc@1: 68.7500 (68.6749)  Acc@5: 100.0000 (97.1519)  time: 0.3458  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3090/3125]  eta: 0:00:12  Lr: 0.030000  Loss: 0.4345  Acc@1: 68.7500 (68.6631)  Acc@5: 100.0000 (97.1530)  time: 0.3452  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [3100/3125]  eta: 0:00:08  Lr: 0.030000  Loss: 0.4782  Acc@1: 68.7500 (68.6835)  Acc@5: 100.0000 (97.1562)  time: 0.3450  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [3110/3125]  eta: 0:00:05  Lr: 0.030000  Loss: 0.2321  Acc@1: 68.7500 (68.6917)  Acc@5: 100.0000 (97.1553)  time: 0.3446  data: 0.0002  max mem: 2500
Train: Epoch[3/5]  [3120/3125]  eta: 0:00:01  Lr: 0.030000  Loss: 0.4022  Acc@1: 68.7500 (68.6839)  Acc@5: 100.0000 (97.1564)  time: 0.3442  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3124/3125]  eta: 0:00:00  Lr: 0.030000  Loss: 0.3523  Acc@1: 68.7500 (68.6780)  Acc@5: 100.0000 (97.1580)  time: 0.3435  data: 0.0004  max mem: 2500
Train: Epoch[3/5] Total time: 0:17:59 (0.3454 s / it)
{0: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 1: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 2: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 3: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 4: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 5: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 6: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 7: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 8: {0: 0, 1: 0, 2: 150000, 3: 0, 4: 0}, 9: {0: 0, 1: 0, 2: 150000, 3: 0, 4: 0}, 10: {0: 0, 1: 0, 2: 150000, 3: 0, 4: 0}, 11: {0: 0, 1: 0, 2: 150000, 3: 0, 4: 0}, 12: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 13: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 14: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 15: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 16: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 17: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 18: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 19: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}}
Averaged stats: Lr: 0.030000  Loss: 0.3523  Acc@1: 68.7500 (68.6780)  Acc@5: 100.0000 (97.1580)
Train: Epoch[4/5]  [   0/3125]  eta: 0:29:31  Lr: 0.030000  Loss: 0.5160  Acc@1: 62.5000 (62.5000)  Acc@5: 93.7500 (93.7500)  time: 0.5669  data: 0.2228  max mem: 2500
Train: Epoch[4/5]  [  10/3125]  eta: 0:18:51  Lr: 0.030000  Loss: 0.0808  Acc@1: 75.0000 (71.5909)  Acc@5: 100.0000 (97.1591)  time: 0.3633  data: 0.0204  max mem: 2500
Train: Epoch[4/5]  [  20/3125]  eta: 0:18:19  Lr: 0.030000  Loss: 0.2992  Acc@1: 75.0000 (74.7024)  Acc@5: 100.0000 (97.3214)  time: 0.3435  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [  30/3125]  eta: 0:18:06  Lr: 0.030000  Loss: 0.4043  Acc@1: 68.7500 (72.5806)  Acc@5: 100.0000 (97.5806)  time: 0.3442  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [  40/3125]  eta: 0:17:57  Lr: 0.030000  Loss: 0.3216  Acc@1: 75.0000 (73.6280)  Acc@5: 100.0000 (98.0183)  time: 0.3443  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [  50/3125]  eta: 0:17:50  Lr: 0.030000  Loss: 0.2744  Acc@1: 75.0000 (73.4069)  Acc@5: 100.0000 (97.9167)  time: 0.3437  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [  60/3125]  eta: 0:17:45  Lr: 0.030000  Loss: 0.1915  Acc@1: 68.7500 (72.6434)  Acc@5: 100.0000 (97.9508)  time: 0.3440  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [  70/3125]  eta: 0:17:40  Lr: 0.030000  Loss: 0.2404  Acc@1: 68.7500 (72.4472)  Acc@5: 100.0000 (97.7113)  time: 0.3445  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [  80/3125]  eta: 0:17:35  Lr: 0.030000  Loss: 0.2758  Acc@1: 68.7500 (71.9136)  Acc@5: 93.7500 (97.5309)  time: 0.3440  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [  90/3125]  eta: 0:17:31  Lr: 0.030000  Loss: 0.4896  Acc@1: 68.7500 (71.4286)  Acc@5: 93.7500 (97.1154)  time: 0.3439  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [ 100/3125]  eta: 0:17:26  Lr: 0.030000  Loss: 0.3829  Acc@1: 68.7500 (71.6584)  Acc@5: 93.7500 (97.0916)  time: 0.3434  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [ 110/3125]  eta: 0:17:22  Lr: 0.030000  Loss: 0.4837  Acc@1: 68.7500 (71.3964)  Acc@5: 100.0000 (97.1284)  time: 0.3428  data: 0.0002  max mem: 2500
Train: Epoch[4/5]  [ 120/3125]  eta: 0:17:18  Lr: 0.030000  Loss: 0.3867  Acc@1: 68.7500 (71.3843)  Acc@5: 100.0000 (97.0558)  time: 0.3430  data: 0.0002  max mem: 2500
Train: Epoch[4/5]  [ 130/3125]  eta: 0:17:14  Lr: 0.030000  Loss: 0.1649  Acc@1: 75.0000 (71.5649)  Acc@5: 100.0000 (97.1851)  time: 0.3435  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [ 140/3125]  eta: 0:17:10  Lr: 0.030000  Loss: 0.1717  Acc@1: 68.7500 (71.4096)  Acc@5: 100.0000 (97.2074)  time: 0.3439  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 150/3125]  eta: 0:17:07  Lr: 0.030000  Loss: 0.2840  Acc@1: 68.7500 (71.6060)  Acc@5: 100.0000 (97.3096)  time: 0.3447  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 160/3125]  eta: 0:17:03  Lr: 0.030000  Loss: 0.2155  Acc@1: 75.0000 (71.5062)  Acc@5: 100.0000 (97.2826)  time: 0.3455  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [ 170/3125]  eta: 0:17:00  Lr: 0.030000  Loss: 0.3211  Acc@1: 75.0000 (71.4547)  Acc@5: 100.0000 (97.2588)  time: 0.3454  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 180/3125]  eta: 0:16:56  Lr: 0.030000  Loss: 0.3417  Acc@1: 68.7500 (71.2362)  Acc@5: 100.0000 (97.2030)  time: 0.3449  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [ 190/3125]  eta: 0:16:53  Lr: 0.030000  Loss: 0.0169  Acc@1: 75.0000 (71.3351)  Acc@5: 100.0000 (97.3168)  time: 0.3447  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [ 200/3125]  eta: 0:16:49  Lr: 0.030000  Loss: 0.3184  Acc@1: 75.0000 (71.4241)  Acc@5: 100.0000 (97.3259)  time: 0.3448  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [ 210/3125]  eta: 0:16:46  Lr: 0.030000  Loss: 0.1380  Acc@1: 75.0000 (71.5344)  Acc@5: 100.0000 (97.4230)  time: 0.3450  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [ 220/3125]  eta: 0:16:42  Lr: 0.030000  Loss: 0.2959  Acc@1: 75.0000 (71.7195)  Acc@5: 100.0000 (97.4265)  time: 0.3450  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [ 230/3125]  eta: 0:16:39  Lr: 0.030000  Loss: 0.4555  Acc@1: 75.0000 (71.8074)  Acc@5: 100.0000 (97.3485)  time: 0.3451  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [ 240/3125]  eta: 0:16:36  Lr: 0.030000  Loss: 0.5590  Acc@1: 68.7500 (71.7064)  Acc@5: 93.7500 (97.3288)  time: 0.3457  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [ 250/3125]  eta: 0:16:32  Lr: 0.030000  Loss: 0.2787  Acc@1: 68.7500 (71.7878)  Acc@5: 100.0000 (97.3108)  time: 0.3449  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [ 260/3125]  eta: 0:16:28  Lr: 0.030000  Loss: 0.3831  Acc@1: 68.7500 (71.5757)  Acc@5: 100.0000 (97.2701)  time: 0.3439  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [ 270/3125]  eta: 0:16:25  Lr: 0.030000  Loss: 0.5851  Acc@1: 68.7500 (71.4253)  Acc@5: 93.7500 (97.2094)  time: 0.3438  data: 0.0002  max mem: 2500
Train: Epoch[4/5]  [ 280/3125]  eta: 0:16:21  Lr: 0.030000  Loss: 0.3655  Acc@1: 68.7500 (71.4190)  Acc@5: 93.7500 (97.2198)  time: 0.3435  data: 0.0002  max mem: 2500
Train: Epoch[4/5]  [ 290/3125]  eta: 0:16:18  Lr: 0.030000  Loss: 0.2758  Acc@1: 75.0000 (71.6280)  Acc@5: 100.0000 (97.2294)  time: 0.3434  data: 0.0002  max mem: 2500
Train: Epoch[4/5]  [ 300/3125]  eta: 0:16:14  Lr: 0.030000  Loss: 0.0186  Acc@1: 75.0000 (71.6570)  Acc@5: 93.7500 (97.1968)  time: 0.3434  data: 0.0002  max mem: 2500
Train: Epoch[4/5]  [ 310/3125]  eta: 0:16:10  Lr: 0.030000  Loss: 0.2983  Acc@1: 75.0000 (71.7243)  Acc@5: 93.7500 (97.1865)  time: 0.3438  data: 0.0002  max mem: 2500
Train: Epoch[4/5]  [ 320/3125]  eta: 0:16:07  Lr: 0.030000  Loss: 0.0960  Acc@1: 75.0000 (71.8653)  Acc@5: 100.0000 (97.1768)  time: 0.3437  data: 0.0002  max mem: 2500
Train: Epoch[4/5]  [ 330/3125]  eta: 0:16:03  Lr: 0.030000  Loss: 0.2649  Acc@1: 75.0000 (72.1110)  Acc@5: 100.0000 (97.2054)  time: 0.3439  data: 0.0002  max mem: 2500
Train: Epoch[4/5]  [ 340/3125]  eta: 0:16:00  Lr: 0.030000  Loss: 0.4512  Acc@1: 75.0000 (72.1041)  Acc@5: 100.0000 (97.2141)  time: 0.3442  data: 0.0002  max mem: 2500
Train: Epoch[4/5]  [ 350/3125]  eta: 0:15:56  Lr: 0.030000  Loss: 0.2744  Acc@1: 68.7500 (72.1154)  Acc@5: 100.0000 (97.1688)  time: 0.3439  data: 0.0002  max mem: 2500
Train: Epoch[4/5]  [ 360/3125]  eta: 0:15:53  Lr: 0.030000  Loss: 0.0908  Acc@1: 75.0000 (72.1780)  Acc@5: 100.0000 (97.1953)  time: 0.3450  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [ 370/3125]  eta: 0:15:50  Lr: 0.030000  Loss: 0.1951  Acc@1: 75.0000 (72.1361)  Acc@5: 100.0000 (97.2035)  time: 0.3472  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 380/3125]  eta: 0:15:46  Lr: 0.030000  Loss: 0.2063  Acc@1: 75.0000 (72.1457)  Acc@5: 100.0000 (97.1785)  time: 0.3474  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 390/3125]  eta: 0:15:43  Lr: 0.030000  Loss: 0.1898  Acc@1: 75.0000 (72.2347)  Acc@5: 100.0000 (97.2506)  time: 0.3462  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 400/3125]  eta: 0:15:40  Lr: 0.030000  Loss: 0.2650  Acc@1: 75.0000 (72.2569)  Acc@5: 100.0000 (97.2569)  time: 0.3474  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 410/3125]  eta: 0:15:36  Lr: 0.030000  Loss: 0.2655  Acc@1: 68.7500 (72.2019)  Acc@5: 100.0000 (97.2932)  time: 0.3477  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 420/3125]  eta: 0:15:33  Lr: 0.030000  Loss: 0.3165  Acc@1: 68.7500 (72.2090)  Acc@5: 100.0000 (97.3278)  time: 0.3461  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 430/3125]  eta: 0:15:30  Lr: 0.030000  Loss: 0.3787  Acc@1: 75.0000 (72.2448)  Acc@5: 100.0000 (97.2883)  time: 0.3462  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 440/3125]  eta: 0:15:26  Lr: 0.030000  Loss: 0.4621  Acc@1: 68.7500 (71.9955)  Acc@5: 93.7500 (97.2080)  time: 0.3462  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 450/3125]  eta: 0:15:23  Lr: 0.030000  Loss: 0.1913  Acc@1: 68.7500 (72.0482)  Acc@5: 100.0000 (97.2422)  time: 0.3460  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 460/3125]  eta: 0:15:19  Lr: 0.030000  Loss: 0.3302  Acc@1: 68.7500 (71.9631)  Acc@5: 100.0000 (97.2614)  time: 0.3460  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [ 470/3125]  eta: 0:15:16  Lr: 0.030000  Loss: 0.3322  Acc@1: 62.5000 (71.8286)  Acc@5: 100.0000 (97.2665)  time: 0.3458  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 480/3125]  eta: 0:15:13  Lr: 0.030000  Loss: 0.4246  Acc@1: 68.7500 (71.8555)  Acc@5: 100.0000 (97.2973)  time: 0.3463  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 490/3125]  eta: 0:15:09  Lr: 0.030000  Loss: 0.2207  Acc@1: 75.0000 (71.7923)  Acc@5: 100.0000 (97.3014)  time: 0.3462  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 500/3125]  eta: 0:15:06  Lr: 0.030000  Loss: 0.3221  Acc@1: 68.7500 (71.7440)  Acc@5: 100.0000 (97.3179)  time: 0.3459  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 510/3125]  eta: 0:15:03  Lr: 0.030000  Loss: 0.3107  Acc@1: 68.7500 (71.7343)  Acc@5: 100.0000 (97.3092)  time: 0.3468  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 520/3125]  eta: 0:14:59  Lr: 0.030000  Loss: 0.2835  Acc@1: 68.7500 (71.7250)  Acc@5: 100.0000 (97.3249)  time: 0.3462  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [ 530/3125]  eta: 0:14:56  Lr: 0.030000  Loss: 0.2898  Acc@1: 68.7500 (71.6337)  Acc@5: 100.0000 (97.3164)  time: 0.3449  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [ 540/3125]  eta: 0:14:52  Lr: 0.030000  Loss: 0.2636  Acc@1: 68.7500 (71.5111)  Acc@5: 100.0000 (97.3198)  time: 0.3450  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [ 550/3125]  eta: 0:14:49  Lr: 0.030000  Loss: 0.4090  Acc@1: 68.7500 (71.4950)  Acc@5: 100.0000 (97.3344)  time: 0.3452  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [ 560/3125]  eta: 0:14:45  Lr: 0.030000  Loss: 0.7178  Acc@1: 68.7500 (71.4461)  Acc@5: 100.0000 (97.2816)  time: 0.3450  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [ 570/3125]  eta: 0:14:42  Lr: 0.030000  Loss: 0.3207  Acc@1: 75.0000 (71.5302)  Acc@5: 100.0000 (97.3074)  time: 0.3448  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [ 580/3125]  eta: 0:14:38  Lr: 0.030000  Loss: 0.3150  Acc@1: 75.0000 (71.5361)  Acc@5: 100.0000 (97.3214)  time: 0.3449  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [ 590/3125]  eta: 0:14:35  Lr: 0.030000  Loss: 0.0406  Acc@1: 75.0000 (71.5207)  Acc@5: 100.0000 (97.3139)  time: 0.3441  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [ 600/3125]  eta: 0:14:31  Lr: 0.030000  Loss: 0.1053  Acc@1: 75.0000 (71.5370)  Acc@5: 93.7500 (97.2650)  time: 0.3434  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [ 610/3125]  eta: 0:14:28  Lr: 0.030000  Loss: 0.5367  Acc@1: 68.7500 (71.5119)  Acc@5: 93.7500 (97.2484)  time: 0.3434  data: 0.0002  max mem: 2500
Train: Epoch[4/5]  [ 620/3125]  eta: 0:14:24  Lr: 0.030000  Loss: 0.2810  Acc@1: 68.7500 (71.4674)  Acc@5: 100.0000 (97.2424)  time: 0.3442  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [ 630/3125]  eta: 0:14:21  Lr: 0.030000  Loss: 0.4325  Acc@1: 62.5000 (71.3550)  Acc@5: 100.0000 (97.2068)  time: 0.3448  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [ 640/3125]  eta: 0:14:17  Lr: 0.030000  Loss: 0.4453  Acc@1: 62.5000 (71.3534)  Acc@5: 100.0000 (97.1724)  time: 0.3447  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [ 650/3125]  eta: 0:14:14  Lr: 0.030000  Loss: 0.3900  Acc@1: 68.7500 (71.3902)  Acc@5: 93.7500 (97.1486)  time: 0.3462  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 660/3125]  eta: 0:14:10  Lr: 0.030000  Loss: 0.5101  Acc@1: 75.0000 (71.3880)  Acc@5: 93.7500 (97.1256)  time: 0.3459  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 670/3125]  eta: 0:14:07  Lr: 0.030000  Loss: 0.4034  Acc@1: 75.0000 (71.4791)  Acc@5: 100.0000 (97.1405)  time: 0.3448  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [ 680/3125]  eta: 0:14:03  Lr: 0.030000  Loss: 0.2648  Acc@1: 75.0000 (71.5217)  Acc@5: 100.0000 (97.1733)  time: 0.3452  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [ 690/3125]  eta: 0:14:00  Lr: 0.030000  Loss: 0.4320  Acc@1: 75.0000 (71.5449)  Acc@5: 100.0000 (97.1780)  time: 0.3450  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [ 700/3125]  eta: 0:13:57  Lr: 0.030000  Loss: 0.2157  Acc@1: 75.0000 (71.5585)  Acc@5: 100.0000 (97.1648)  time: 0.3453  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [ 710/3125]  eta: 0:13:53  Lr: 0.030000  Loss: 0.1648  Acc@1: 75.0000 (71.5366)  Acc@5: 100.0000 (97.1783)  time: 0.3453  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [ 720/3125]  eta: 0:13:50  Lr: 0.030000  Loss: 0.1581  Acc@1: 68.7500 (71.4806)  Acc@5: 100.0000 (97.1654)  time: 0.3459  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [ 730/3125]  eta: 0:13:46  Lr: 0.030000  Loss: 0.5675  Acc@1: 68.7500 (71.4432)  Acc@5: 100.0000 (97.1785)  time: 0.3452  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [ 740/3125]  eta: 0:13:43  Lr: 0.030000  Loss: 0.3375  Acc@1: 75.0000 (71.4659)  Acc@5: 100.0000 (97.1829)  time: 0.3435  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [ 750/3125]  eta: 0:13:39  Lr: 0.030000  Loss: 0.3722  Acc@1: 75.0000 (71.4714)  Acc@5: 93.7500 (97.1621)  time: 0.3432  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [ 760/3125]  eta: 0:13:36  Lr: 0.030000  Loss: 0.5662  Acc@1: 75.0000 (71.4274)  Acc@5: 93.7500 (97.1583)  time: 0.3430  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [ 770/3125]  eta: 0:13:32  Lr: 0.030000  Loss: 0.4865  Acc@1: 68.7500 (71.4008)  Acc@5: 100.0000 (97.1466)  time: 0.3431  data: 0.0002  max mem: 2500
Train: Epoch[4/5]  [ 780/3125]  eta: 0:13:29  Lr: 0.030000  Loss: 0.2928  Acc@1: 68.7500 (71.3988)  Acc@5: 100.0000 (97.1671)  time: 0.3433  data: 0.0002  max mem: 2500
Train: Epoch[4/5]  [ 790/3125]  eta: 0:13:25  Lr: 0.030000  Loss: 0.3171  Acc@1: 68.7500 (71.4207)  Acc@5: 100.0000 (97.1634)  time: 0.3434  data: 0.0002  max mem: 2500
Train: Epoch[4/5]  [ 800/3125]  eta: 0:13:22  Lr: 0.030000  Loss: 0.4757  Acc@1: 75.0000 (71.4888)  Acc@5: 100.0000 (97.1598)  time: 0.3452  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 810/3125]  eta: 0:13:18  Lr: 0.030000  Loss: 0.2607  Acc@1: 75.0000 (71.5244)  Acc@5: 100.0000 (97.1640)  time: 0.3462  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 820/3125]  eta: 0:13:15  Lr: 0.030000  Loss: 0.2860  Acc@1: 75.0000 (71.5210)  Acc@5: 100.0000 (97.1833)  time: 0.3462  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 830/3125]  eta: 0:13:11  Lr: 0.030000  Loss: 0.2574  Acc@1: 75.0000 (71.5403)  Acc@5: 100.0000 (97.2097)  time: 0.3458  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 840/3125]  eta: 0:13:08  Lr: 0.030000  Loss: 0.6910  Acc@1: 75.0000 (71.5146)  Acc@5: 100.0000 (97.1685)  time: 0.3454  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 850/3125]  eta: 0:13:05  Lr: 0.030000  Loss: 0.3239  Acc@1: 68.7500 (71.4894)  Acc@5: 93.7500 (97.1724)  time: 0.3463  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 860/3125]  eta: 0:13:01  Lr: 0.030000  Loss: 0.3241  Acc@1: 75.0000 (71.5084)  Acc@5: 100.0000 (97.1617)  time: 0.3461  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 870/3125]  eta: 0:12:58  Lr: 0.030000  Loss: 0.3997  Acc@1: 75.0000 (71.5198)  Acc@5: 100.0000 (97.1656)  time: 0.3459  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 880/3125]  eta: 0:12:54  Lr: 0.030000  Loss: 0.1124  Acc@1: 75.0000 (71.5167)  Acc@5: 100.0000 (97.1907)  time: 0.3457  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [ 890/3125]  eta: 0:12:51  Lr: 0.030000  Loss: 0.2746  Acc@1: 75.0000 (71.5348)  Acc@5: 100.0000 (97.1942)  time: 0.3450  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [ 900/3125]  eta: 0:12:47  Lr: 0.030000  Loss: 0.2434  Acc@1: 75.0000 (71.5178)  Acc@5: 100.0000 (97.2114)  time: 0.3456  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [ 910/3125]  eta: 0:12:44  Lr: 0.030000  Loss: 0.4581  Acc@1: 62.5000 (71.4256)  Acc@5: 100.0000 (97.2352)  time: 0.3460  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [ 920/3125]  eta: 0:12:41  Lr: 0.030000  Loss: 0.2451  Acc@1: 75.0000 (71.5052)  Acc@5: 100.0000 (97.2245)  time: 0.3451  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [ 930/3125]  eta: 0:12:37  Lr: 0.030000  Loss: 0.5070  Acc@1: 75.0000 (71.5158)  Acc@5: 93.7500 (97.2140)  time: 0.3464  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [ 940/3125]  eta: 0:12:34  Lr: 0.030000  Loss: 0.6613  Acc@1: 68.7500 (71.4997)  Acc@5: 100.0000 (97.2237)  time: 0.3460  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [ 950/3125]  eta: 0:12:30  Lr: 0.030000  Loss: 0.3531  Acc@1: 68.7500 (71.5365)  Acc@5: 100.0000 (97.2463)  time: 0.3435  data: 0.0002  max mem: 2500
Train: Epoch[4/5]  [ 960/3125]  eta: 0:12:27  Lr: 0.030000  Loss: 0.5551  Acc@1: 75.0000 (71.5726)  Acc@5: 100.0000 (97.2490)  time: 0.3432  data: 0.0002  max mem: 2500
Train: Epoch[4/5]  [ 970/3125]  eta: 0:12:23  Lr: 0.030000  Loss: 0.1026  Acc@1: 75.0000 (71.5628)  Acc@5: 100.0000 (97.2451)  time: 0.3436  data: 0.0002  max mem: 2500
Train: Epoch[4/5]  [ 980/3125]  eta: 0:12:20  Lr: 0.030000  Loss: 0.3016  Acc@1: 81.2500 (71.6616)  Acc@5: 100.0000 (97.2604)  time: 0.3443  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [ 990/3125]  eta: 0:12:16  Lr: 0.030000  Loss: 0.3785  Acc@1: 75.0000 (71.6763)  Acc@5: 100.0000 (97.2629)  time: 0.3449  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1000/3125]  eta: 0:12:13  Lr: 0.030000  Loss: 0.2572  Acc@1: 75.0000 (71.6908)  Acc@5: 100.0000 (97.2590)  time: 0.3469  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1010/3125]  eta: 0:12:09  Lr: 0.030000  Loss: 0.3160  Acc@1: 68.7500 (71.6926)  Acc@5: 100.0000 (97.2799)  time: 0.3469  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1020/3125]  eta: 0:12:06  Lr: 0.030000  Loss: 0.2688  Acc@1: 68.7500 (71.6516)  Acc@5: 100.0000 (97.2698)  time: 0.3456  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [1030/3125]  eta: 0:12:03  Lr: 0.030000  Loss: 0.3893  Acc@1: 68.7500 (71.6174)  Acc@5: 100.0000 (97.2903)  time: 0.3455  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1040/3125]  eta: 0:11:59  Lr: 0.030000  Loss: 0.4360  Acc@1: 68.7500 (71.6378)  Acc@5: 100.0000 (97.2923)  time: 0.3451  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [1050/3125]  eta: 0:11:56  Lr: 0.030000  Loss: 0.2869  Acc@1: 75.0000 (71.6223)  Acc@5: 100.0000 (97.2824)  time: 0.3456  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [1060/3125]  eta: 0:11:52  Lr: 0.030000  Loss: 0.4140  Acc@1: 68.7500 (71.6364)  Acc@5: 100.0000 (97.2903)  time: 0.3461  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [1070/3125]  eta: 0:11:49  Lr: 0.030000  Loss: 0.1760  Acc@1: 68.7500 (71.6270)  Acc@5: 100.0000 (97.3039)  time: 0.3456  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [1080/3125]  eta: 0:11:45  Lr: 0.030000  Loss: 0.4538  Acc@1: 68.7500 (71.6351)  Acc@5: 100.0000 (97.2942)  time: 0.3472  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [1090/3125]  eta: 0:11:42  Lr: 0.030000  Loss: 0.3936  Acc@1: 68.7500 (71.6430)  Acc@5: 100.0000 (97.2961)  time: 0.3467  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [1100/3125]  eta: 0:11:38  Lr: 0.030000  Loss: 0.5597  Acc@1: 68.7500 (71.6508)  Acc@5: 100.0000 (97.2922)  time: 0.3437  data: 0.0002  max mem: 2500
Train: Epoch[4/5]  [1110/3125]  eta: 0:11:35  Lr: 0.030000  Loss: 0.2905  Acc@1: 68.7500 (71.6022)  Acc@5: 93.7500 (97.2660)  time: 0.3436  data: 0.0002  max mem: 2500
Train: Epoch[4/5]  [1120/3125]  eta: 0:11:32  Lr: 0.030000  Loss: 0.2160  Acc@1: 68.7500 (71.5934)  Acc@5: 93.7500 (97.2625)  time: 0.3436  data: 0.0002  max mem: 2500
Train: Epoch[4/5]  [1130/3125]  eta: 0:11:28  Lr: 0.030000  Loss: 0.4948  Acc@1: 68.7500 (71.5904)  Acc@5: 100.0000 (97.2425)  time: 0.3435  data: 0.0002  max mem: 2500
Train: Epoch[4/5]  [1140/3125]  eta: 0:11:25  Lr: 0.030000  Loss: 0.2785  Acc@1: 68.7500 (71.6148)  Acc@5: 100.0000 (97.2612)  time: 0.3434  data: 0.0002  max mem: 2500
Train: Epoch[4/5]  [1150/3125]  eta: 0:11:21  Lr: 0.030000  Loss: 0.3674  Acc@1: 68.7500 (71.6008)  Acc@5: 100.0000 (97.2307)  time: 0.3432  data: 0.0002  max mem: 2500
Train: Epoch[4/5]  [1160/3125]  eta: 0:11:18  Lr: 0.030000  Loss: 0.6069  Acc@1: 68.7500 (71.6031)  Acc@5: 93.7500 (97.2330)  time: 0.3436  data: 0.0002  max mem: 2500
Train: Epoch[4/5]  [1170/3125]  eta: 0:11:14  Lr: 0.030000  Loss: 0.1520  Acc@1: 75.0000 (71.6642)  Acc@5: 100.0000 (97.2406)  time: 0.3434  data: 0.0002  max mem: 2500
Train: Epoch[4/5]  [1180/3125]  eta: 0:11:11  Lr: 0.030000  Loss: 0.3926  Acc@1: 75.0000 (71.6130)  Acc@5: 100.0000 (97.2428)  time: 0.3434  data: 0.0002  max mem: 2500
Train: Epoch[4/5]  [1190/3125]  eta: 0:11:07  Lr: 0.030000  Loss: 0.2952  Acc@1: 68.7500 (71.5942)  Acc@5: 100.0000 (97.2345)  time: 0.3443  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [1200/3125]  eta: 0:11:04  Lr: 0.030000  Loss: 0.1146  Acc@1: 68.7500 (71.5862)  Acc@5: 93.7500 (97.2055)  time: 0.3449  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1210/3125]  eta: 0:11:00  Lr: 0.030000  Loss: 0.0772  Acc@1: 68.7500 (71.6299)  Acc@5: 100.0000 (97.2285)  time: 0.3449  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1220/3125]  eta: 0:10:57  Lr: 0.030000  Loss: 0.1831  Acc@1: 68.7500 (71.5909)  Acc@5: 100.0000 (97.2154)  time: 0.3454  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1230/3125]  eta: 0:10:53  Lr: 0.030000  Loss: 0.2566  Acc@1: 68.7500 (71.5678)  Acc@5: 93.7500 (97.2126)  time: 0.3455  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1240/3125]  eta: 0:10:50  Lr: 0.030000  Loss: 0.3607  Acc@1: 68.7500 (71.5401)  Acc@5: 100.0000 (97.2099)  time: 0.3451  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1250/3125]  eta: 0:10:47  Lr: 0.030000  Loss: 0.2317  Acc@1: 68.7500 (71.4928)  Acc@5: 93.7500 (97.1972)  time: 0.3450  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1260/3125]  eta: 0:10:43  Lr: 0.030000  Loss: 0.4437  Acc@1: 68.7500 (71.4909)  Acc@5: 100.0000 (97.2096)  time: 0.3458  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1270/3125]  eta: 0:10:40  Lr: 0.030000  Loss: 0.2015  Acc@1: 75.0000 (71.4890)  Acc@5: 100.0000 (97.2118)  time: 0.3459  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1280/3125]  eta: 0:10:36  Lr: 0.030000  Loss: 0.2221  Acc@1: 75.0000 (71.5262)  Acc@5: 100.0000 (97.2141)  time: 0.3458  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1290/3125]  eta: 0:10:33  Lr: 0.030000  Loss: 0.0795  Acc@1: 68.7500 (71.4901)  Acc@5: 93.7500 (97.2066)  time: 0.3454  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1300/3125]  eta: 0:10:29  Lr: 0.030000  Loss: 0.3962  Acc@1: 68.7500 (71.5219)  Acc@5: 93.7500 (97.1993)  time: 0.3447  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1310/3125]  eta: 0:10:26  Lr: 0.030000  Loss: 0.2000  Acc@1: 75.0000 (71.5484)  Acc@5: 100.0000 (97.2063)  time: 0.3456  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1320/3125]  eta: 0:10:22  Lr: 0.030000  Loss: 0.4528  Acc@1: 68.7500 (71.5131)  Acc@5: 100.0000 (97.2038)  time: 0.3458  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1330/3125]  eta: 0:10:19  Lr: 0.030000  Loss: 0.3433  Acc@1: 68.7500 (71.5299)  Acc@5: 100.0000 (97.2107)  time: 0.3456  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1340/3125]  eta: 0:10:16  Lr: 0.030000  Loss: 0.1949  Acc@1: 75.0000 (71.5418)  Acc@5: 100.0000 (97.2082)  time: 0.3460  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1350/3125]  eta: 0:10:12  Lr: 0.030000  Loss: 0.1319  Acc@1: 68.7500 (71.5072)  Acc@5: 100.0000 (97.2104)  time: 0.3474  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [1360/3125]  eta: 0:10:09  Lr: 0.030000  Loss: 0.4997  Acc@1: 68.7500 (71.5099)  Acc@5: 100.0000 (97.2171)  time: 0.3468  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [1370/3125]  eta: 0:10:05  Lr: 0.030000  Loss: 0.1169  Acc@1: 68.7500 (71.5354)  Acc@5: 100.0000 (97.2329)  time: 0.3449  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [1380/3125]  eta: 0:10:02  Lr: 0.030000  Loss: 0.0845  Acc@1: 75.0000 (71.5424)  Acc@5: 100.0000 (97.2122)  time: 0.3448  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [1390/3125]  eta: 0:09:58  Lr: 0.030000  Loss: 0.4333  Acc@1: 68.7500 (71.5268)  Acc@5: 100.0000 (97.2142)  time: 0.3459  data: 0.0009  max mem: 2500
Train: Epoch[4/5]  [1400/3125]  eta: 0:09:55  Lr: 0.030000  Loss: 0.3482  Acc@1: 68.7500 (71.5293)  Acc@5: 100.0000 (97.2252)  time: 0.3451  data: 0.0009  max mem: 2500
Train: Epoch[4/5]  [1410/3125]  eta: 0:09:51  Lr: 0.030000  Loss: 0.4572  Acc@1: 75.0000 (71.5361)  Acc@5: 100.0000 (97.2271)  time: 0.3433  data: 0.0002  max mem: 2500
Train: Epoch[4/5]  [1420/3125]  eta: 0:09:48  Lr: 0.030000  Loss: 0.1460  Acc@1: 75.0000 (71.5649)  Acc@5: 100.0000 (97.2379)  time: 0.3436  data: 0.0002  max mem: 2500
Train: Epoch[4/5]  [1430/3125]  eta: 0:09:44  Lr: 0.030000  Loss: 0.3906  Acc@1: 75.0000 (71.5496)  Acc@5: 100.0000 (97.2353)  time: 0.3446  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [1440/3125]  eta: 0:09:41  Lr: 0.030000  Loss: 0.4033  Acc@1: 68.7500 (71.5432)  Acc@5: 100.0000 (97.2458)  time: 0.3452  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1450/3125]  eta: 0:09:38  Lr: 0.030000  Loss: 0.2911  Acc@1: 75.0000 (71.5369)  Acc@5: 100.0000 (97.2347)  time: 0.3455  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1460/3125]  eta: 0:09:34  Lr: 0.030000  Loss: 0.4103  Acc@1: 68.7500 (71.5221)  Acc@5: 100.0000 (97.2365)  time: 0.3451  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [1470/3125]  eta: 0:09:31  Lr: 0.030000  Loss: 0.3141  Acc@1: 68.7500 (71.5287)  Acc@5: 93.7500 (97.2213)  time: 0.3443  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [1480/3125]  eta: 0:09:27  Lr: 0.030000  Loss: 0.3651  Acc@1: 68.7500 (71.5437)  Acc@5: 93.7500 (97.2189)  time: 0.3445  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [1490/3125]  eta: 0:09:24  Lr: 0.030000  Loss: 0.4445  Acc@1: 75.0000 (71.5669)  Acc@5: 100.0000 (97.2208)  time: 0.3444  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [1500/3125]  eta: 0:09:20  Lr: 0.030000  Loss: 0.3470  Acc@1: 75.0000 (71.5898)  Acc@5: 100.0000 (97.2310)  time: 0.3442  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [1510/3125]  eta: 0:09:17  Lr: 0.030000  Loss: 0.3777  Acc@1: 75.0000 (71.6454)  Acc@5: 100.0000 (97.2328)  time: 0.3452  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1520/3125]  eta: 0:09:13  Lr: 0.030000  Loss: 0.0612  Acc@1: 75.0000 (71.6387)  Acc@5: 100.0000 (97.2387)  time: 0.3458  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1530/3125]  eta: 0:09:10  Lr: 0.030000  Loss: 0.3631  Acc@1: 68.7500 (71.6403)  Acc@5: 100.0000 (97.2404)  time: 0.3448  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1540/3125]  eta: 0:09:06  Lr: 0.030000  Loss: 0.2612  Acc@1: 75.0000 (71.6702)  Acc@5: 100.0000 (97.2461)  time: 0.3448  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [1550/3125]  eta: 0:09:03  Lr: 0.030000  Loss: 0.1372  Acc@1: 75.0000 (71.6675)  Acc@5: 100.0000 (97.2518)  time: 0.3454  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [1560/3125]  eta: 0:09:00  Lr: 0.030000  Loss: 0.2694  Acc@1: 68.7500 (71.6528)  Acc@5: 100.0000 (97.2494)  time: 0.3453  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [1570/3125]  eta: 0:08:56  Lr: 0.030000  Loss: 0.3729  Acc@1: 68.7500 (71.6184)  Acc@5: 100.0000 (97.2510)  time: 0.3453  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [1580/3125]  eta: 0:08:53  Lr: 0.030000  Loss: 0.3018  Acc@1: 62.5000 (71.5963)  Acc@5: 93.7500 (97.2407)  time: 0.3451  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [1590/3125]  eta: 0:08:49  Lr: 0.030000  Loss: 0.2364  Acc@1: 68.7500 (71.6098)  Acc@5: 93.7500 (97.2423)  time: 0.3443  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [1600/3125]  eta: 0:08:46  Lr: 0.030000  Loss: 0.2924  Acc@1: 68.7500 (71.6115)  Acc@5: 100.0000 (97.2478)  time: 0.3439  data: 0.0002  max mem: 2500
Train: Epoch[4/5]  [1610/3125]  eta: 0:08:42  Lr: 0.030000  Loss: 0.3278  Acc@1: 75.0000 (71.6364)  Acc@5: 100.0000 (97.2533)  time: 0.3436  data: 0.0002  max mem: 2500
Train: Epoch[4/5]  [1620/3125]  eta: 0:08:39  Lr: 0.030000  Loss: 0.2588  Acc@1: 68.7500 (71.5839)  Acc@5: 100.0000 (97.2432)  time: 0.3432  data: 0.0002  max mem: 2500
Train: Epoch[4/5]  [1630/3125]  eta: 0:08:35  Lr: 0.030000  Loss: 0.3001  Acc@1: 68.7500 (71.5435)  Acc@5: 100.0000 (97.2371)  time: 0.3435  data: 0.0002  max mem: 2500
Train: Epoch[4/5]  [1640/3125]  eta: 0:08:32  Lr: 0.030000  Loss: 0.4030  Acc@1: 68.7500 (71.5265)  Acc@5: 100.0000 (97.2273)  time: 0.3440  data: 0.0002  max mem: 2500
Train: Epoch[4/5]  [1650/3125]  eta: 0:08:28  Lr: 0.030000  Loss: 0.1224  Acc@1: 68.7500 (71.5135)  Acc@5: 100.0000 (97.2252)  time: 0.3440  data: 0.0002  max mem: 2500
Train: Epoch[4/5]  [1660/3125]  eta: 0:08:25  Lr: 0.030000  Loss: 0.4348  Acc@1: 68.7500 (71.5044)  Acc@5: 100.0000 (97.2343)  time: 0.3454  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [1670/3125]  eta: 0:08:22  Lr: 0.030000  Loss: 0.3491  Acc@1: 68.7500 (71.4729)  Acc@5: 100.0000 (97.2322)  time: 0.3465  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1680/3125]  eta: 0:08:18  Lr: 0.030000  Loss: 0.3950  Acc@1: 68.7500 (71.4827)  Acc@5: 100.0000 (97.2301)  time: 0.3469  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [1690/3125]  eta: 0:08:15  Lr: 0.030000  Loss: 0.3391  Acc@1: 75.0000 (71.4925)  Acc@5: 100.0000 (97.2391)  time: 0.3464  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1700/3125]  eta: 0:08:11  Lr: 0.030000  Loss: 0.6153  Acc@1: 75.0000 (71.4947)  Acc@5: 100.0000 (97.2296)  time: 0.3455  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [1710/3125]  eta: 0:08:08  Lr: 0.030000  Loss: 0.3496  Acc@1: 75.0000 (71.5225)  Acc@5: 100.0000 (97.2348)  time: 0.3459  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1720/3125]  eta: 0:08:04  Lr: 0.030000  Loss: 0.2963  Acc@1: 75.0000 (71.5209)  Acc@5: 100.0000 (97.2291)  time: 0.3461  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1730/3125]  eta: 0:08:01  Lr: 0.030000  Loss: 0.2271  Acc@1: 68.7500 (71.5049)  Acc@5: 100.0000 (97.2234)  time: 0.3459  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1740/3125]  eta: 0:07:57  Lr: 0.030000  Loss: 0.4118  Acc@1: 62.5000 (71.4999)  Acc@5: 93.7500 (97.2035)  time: 0.3462  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1750/3125]  eta: 0:07:54  Lr: 0.030000  Loss: 0.2504  Acc@1: 68.7500 (71.5056)  Acc@5: 100.0000 (97.2159)  time: 0.3473  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1760/3125]  eta: 0:07:51  Lr: 0.030000  Loss: 0.4323  Acc@1: 68.7500 (71.5396)  Acc@5: 100.0000 (97.2175)  time: 0.3477  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [1770/3125]  eta: 0:07:47  Lr: 0.030000  Loss: 0.1390  Acc@1: 68.7500 (71.5415)  Acc@5: 100.0000 (97.2120)  time: 0.3477  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1780/3125]  eta: 0:07:44  Lr: 0.030000  Loss: 0.2782  Acc@1: 68.7500 (71.5644)  Acc@5: 93.7500 (97.1961)  time: 0.3468  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1790/3125]  eta: 0:07:40  Lr: 0.030000  Loss: 0.4153  Acc@1: 68.7500 (71.5592)  Acc@5: 93.7500 (97.1978)  time: 0.3458  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [1800/3125]  eta: 0:07:37  Lr: 0.030000  Loss: 0.2632  Acc@1: 68.7500 (71.5471)  Acc@5: 100.0000 (97.1960)  time: 0.3459  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [1810/3125]  eta: 0:07:33  Lr: 0.030000  Loss: 0.7016  Acc@1: 68.7500 (71.5316)  Acc@5: 100.0000 (97.2011)  time: 0.3460  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [1820/3125]  eta: 0:07:30  Lr: 0.030000  Loss: 0.3454  Acc@1: 68.7500 (71.5232)  Acc@5: 100.0000 (97.2131)  time: 0.3459  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [1830/3125]  eta: 0:07:26  Lr: 0.030000  Loss: 0.1828  Acc@1: 75.0000 (71.5524)  Acc@5: 100.0000 (97.2181)  time: 0.3455  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [1840/3125]  eta: 0:07:23  Lr: 0.030000  Loss: 0.3645  Acc@1: 75.0000 (71.5508)  Acc@5: 100.0000 (97.2230)  time: 0.3465  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [1850/3125]  eta: 0:07:20  Lr: 0.030000  Loss: 0.2332  Acc@1: 75.0000 (71.5796)  Acc@5: 100.0000 (97.2211)  time: 0.3463  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [1860/3125]  eta: 0:07:16  Lr: 0.030000  Loss: 0.3483  Acc@1: 81.2500 (71.6046)  Acc@5: 100.0000 (97.2327)  time: 0.3450  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [1870/3125]  eta: 0:07:13  Lr: 0.030000  Loss: 0.1862  Acc@1: 75.0000 (71.6195)  Acc@5: 100.0000 (97.2374)  time: 0.3450  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [1880/3125]  eta: 0:07:09  Lr: 0.030000  Loss: 0.2858  Acc@1: 68.7500 (71.6142)  Acc@5: 100.0000 (97.2422)  time: 0.3440  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [1890/3125]  eta: 0:07:06  Lr: 0.030000  Loss: 0.1952  Acc@1: 68.7500 (71.5990)  Acc@5: 100.0000 (97.2369)  time: 0.3433  data: 0.0002  max mem: 2500
Train: Epoch[4/5]  [1900/3125]  eta: 0:07:02  Lr: 0.030000  Loss: 0.0457  Acc@1: 68.7500 (71.6038)  Acc@5: 100.0000 (97.2449)  time: 0.3432  data: 0.0002  max mem: 2500
Train: Epoch[4/5]  [1910/3125]  eta: 0:06:59  Lr: 0.030000  Loss: 0.1653  Acc@1: 68.7500 (71.5986)  Acc@5: 100.0000 (97.2462)  time: 0.3437  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [1920/3125]  eta: 0:06:55  Lr: 0.030000  Loss: 0.2645  Acc@1: 75.0000 (71.6066)  Acc@5: 100.0000 (97.2508)  time: 0.3440  data: 0.0002  max mem: 2500
Train: Epoch[4/5]  [1930/3125]  eta: 0:06:52  Lr: 0.030000  Loss: 0.3028  Acc@1: 68.7500 (71.5400)  Acc@5: 100.0000 (97.2553)  time: 0.3441  data: 0.0002  max mem: 2500
Train: Epoch[4/5]  [1940/3125]  eta: 0:06:48  Lr: 0.030000  Loss: 0.2347  Acc@1: 68.7500 (71.5643)  Acc@5: 100.0000 (97.2501)  time: 0.3444  data: 0.0002  max mem: 2500
Train: Epoch[4/5]  [1950/3125]  eta: 0:06:45  Lr: 0.030000  Loss: 0.3050  Acc@1: 75.0000 (71.5563)  Acc@5: 100.0000 (97.2482)  time: 0.3460  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1960/3125]  eta: 0:06:42  Lr: 0.030000  Loss: 0.4571  Acc@1: 75.0000 (71.5674)  Acc@5: 100.0000 (97.2495)  time: 0.3478  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1970/3125]  eta: 0:06:38  Lr: 0.030000  Loss: 0.2369  Acc@1: 68.7500 (71.5658)  Acc@5: 100.0000 (97.2412)  time: 0.3475  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1980/3125]  eta: 0:06:35  Lr: 0.030000  Loss: 0.3991  Acc@1: 68.7500 (71.5516)  Acc@5: 100.0000 (97.2426)  time: 0.3466  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1990/3125]  eta: 0:06:31  Lr: 0.030000  Loss: 0.3525  Acc@1: 75.0000 (71.5689)  Acc@5: 100.0000 (97.2501)  time: 0.3457  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2000/3125]  eta: 0:06:28  Lr: 0.030000  Loss: 0.3511  Acc@1: 75.0000 (71.5892)  Acc@5: 100.0000 (97.2514)  time: 0.3452  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2010/3125]  eta: 0:06:24  Lr: 0.030000  Loss: 0.4005  Acc@1: 68.7500 (71.5751)  Acc@5: 100.0000 (97.2588)  time: 0.3455  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2020/3125]  eta: 0:06:21  Lr: 0.030000  Loss: 0.2203  Acc@1: 68.7500 (71.5982)  Acc@5: 100.0000 (97.2569)  time: 0.3455  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2030/3125]  eta: 0:06:17  Lr: 0.030000  Loss: 0.2271  Acc@1: 81.2500 (71.6581)  Acc@5: 100.0000 (97.2581)  time: 0.3456  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2040/3125]  eta: 0:06:14  Lr: 0.030000  Loss: 0.2281  Acc@1: 75.0000 (71.6407)  Acc@5: 100.0000 (97.2471)  time: 0.3454  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2050/3125]  eta: 0:06:11  Lr: 0.030000  Loss: 0.2602  Acc@1: 75.0000 (71.6419)  Acc@5: 100.0000 (97.2513)  time: 0.3454  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2060/3125]  eta: 0:06:07  Lr: 0.030000  Loss: 0.3711  Acc@1: 75.0000 (71.6430)  Acc@5: 100.0000 (97.2556)  time: 0.3456  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2070/3125]  eta: 0:06:04  Lr: 0.030000  Loss: 0.4896  Acc@1: 68.7500 (71.6230)  Acc@5: 93.7500 (97.2447)  time: 0.3450  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [2080/3125]  eta: 0:06:00  Lr: 0.030000  Loss: 0.4013  Acc@1: 68.7500 (71.6452)  Acc@5: 100.0000 (97.2489)  time: 0.3449  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [2090/3125]  eta: 0:05:57  Lr: 0.030000  Loss: 0.5366  Acc@1: 75.0000 (71.6344)  Acc@5: 100.0000 (97.2501)  time: 0.3457  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2100/3125]  eta: 0:05:53  Lr: 0.030000  Loss: 0.2986  Acc@1: 75.0000 (71.6534)  Acc@5: 100.0000 (97.2424)  time: 0.3457  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2110/3125]  eta: 0:05:50  Lr: 0.030000  Loss: 0.2473  Acc@1: 75.0000 (71.6574)  Acc@5: 100.0000 (97.2406)  time: 0.3453  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [2120/3125]  eta: 0:05:46  Lr: 0.030000  Loss: 0.3291  Acc@1: 68.7500 (71.6555)  Acc@5: 100.0000 (97.2419)  time: 0.3455  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2130/3125]  eta: 0:05:43  Lr: 0.030000  Loss: 0.1267  Acc@1: 68.7500 (71.6653)  Acc@5: 100.0000 (97.2372)  time: 0.3462  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2140/3125]  eta: 0:05:40  Lr: 0.030000  Loss: 0.0643  Acc@1: 81.2500 (71.6926)  Acc@5: 100.0000 (97.2355)  time: 0.3453  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [2150/3125]  eta: 0:05:36  Lr: 0.030000  Loss: 0.4802  Acc@1: 75.0000 (71.6963)  Acc@5: 100.0000 (97.2426)  time: 0.3435  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [2160/3125]  eta: 0:05:33  Lr: 0.030000  Loss: 0.3976  Acc@1: 75.0000 (71.7058)  Acc@5: 100.0000 (97.2409)  time: 0.3434  data: 0.0002  max mem: 2500
Train: Epoch[4/5]  [2170/3125]  eta: 0:05:29  Lr: 0.030000  Loss: 0.2683  Acc@1: 75.0000 (71.7354)  Acc@5: 100.0000 (97.2536)  time: 0.3435  data: 0.0002  max mem: 2500
Train: Epoch[4/5]  [2180/3125]  eta: 0:05:26  Lr: 0.030000  Loss: 0.3077  Acc@1: 75.0000 (71.7102)  Acc@5: 100.0000 (97.2346)  time: 0.3434  data: 0.0002  max mem: 2500
Train: Epoch[4/5]  [2190/3125]  eta: 0:05:22  Lr: 0.030000  Loss: 0.2737  Acc@1: 68.7500 (71.7252)  Acc@5: 100.0000 (97.2416)  time: 0.3429  data: 0.0002  max mem: 2500
Train: Epoch[4/5]  [2200/3125]  eta: 0:05:19  Lr: 0.030000  Loss: 0.3138  Acc@1: 75.0000 (71.7543)  Acc@5: 100.0000 (97.2371)  time: 0.3430  data: 0.0002  max mem: 2500
Train: Epoch[4/5]  [2210/3125]  eta: 0:05:15  Lr: 0.030000  Loss: 0.1828  Acc@1: 75.0000 (71.7549)  Acc@5: 93.7500 (97.2298)  time: 0.3437  data: 0.0002  max mem: 2500
Train: Epoch[4/5]  [2220/3125]  eta: 0:05:12  Lr: 0.030000  Loss: 0.1778  Acc@1: 68.7500 (71.7526)  Acc@5: 93.7500 (97.2253)  time: 0.3440  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [2230/3125]  eta: 0:05:08  Lr: 0.030000  Loss: 0.1697  Acc@1: 68.7500 (71.7475)  Acc@5: 100.0000 (97.2294)  time: 0.3440  data: 0.0002  max mem: 2500
Train: Epoch[4/5]  [2240/3125]  eta: 0:05:05  Lr: 0.030000  Loss: 0.2654  Acc@1: 68.7500 (71.7453)  Acc@5: 100.0000 (97.2306)  time: 0.3458  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2250/3125]  eta: 0:05:01  Lr: 0.030000  Loss: 0.1223  Acc@1: 75.0000 (71.7570)  Acc@5: 100.0000 (97.2235)  time: 0.3475  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2260/3125]  eta: 0:04:58  Lr: 0.030000  Loss: 0.3662  Acc@1: 68.7500 (71.7271)  Acc@5: 93.7500 (97.2164)  time: 0.3467  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2270/3125]  eta: 0:04:55  Lr: 0.030000  Loss: 0.2857  Acc@1: 68.7500 (71.7168)  Acc@5: 100.0000 (97.2231)  time: 0.3457  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2280/3125]  eta: 0:04:51  Lr: 0.030000  Loss: 0.3534  Acc@1: 75.0000 (71.7366)  Acc@5: 100.0000 (97.2298)  time: 0.3455  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2290/3125]  eta: 0:04:48  Lr: 0.030000  Loss: 0.2270  Acc@1: 75.0000 (71.7209)  Acc@5: 100.0000 (97.2310)  time: 0.3452  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2300/3125]  eta: 0:04:44  Lr: 0.030000  Loss: 0.2238  Acc@1: 75.0000 (71.7324)  Acc@5: 100.0000 (97.2349)  time: 0.3449  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [2310/3125]  eta: 0:04:41  Lr: 0.030000  Loss: 0.2039  Acc@1: 75.0000 (71.7492)  Acc@5: 100.0000 (97.2442)  time: 0.3448  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2320/3125]  eta: 0:04:37  Lr: 0.030000  Loss: 0.7130  Acc@1: 75.0000 (71.7471)  Acc@5: 100.0000 (97.2372)  time: 0.3455  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2330/3125]  eta: 0:04:34  Lr: 0.030000  Loss: 0.0815  Acc@1: 75.0000 (71.7637)  Acc@5: 100.0000 (97.2383)  time: 0.3454  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2340/3125]  eta: 0:04:30  Lr: 0.030000  Loss: 0.5084  Acc@1: 75.0000 (71.7428)  Acc@5: 100.0000 (97.2341)  time: 0.3446  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2350/3125]  eta: 0:04:27  Lr: 0.030000  Loss: 0.2955  Acc@1: 75.0000 (71.7780)  Acc@5: 100.0000 (97.2432)  time: 0.3454  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2360/3125]  eta: 0:04:24  Lr: 0.030000  Loss: 0.2351  Acc@1: 75.0000 (71.7969)  Acc@5: 100.0000 (97.2496)  time: 0.3459  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2370/3125]  eta: 0:04:20  Lr: 0.030000  Loss: 0.3533  Acc@1: 75.0000 (71.8051)  Acc@5: 100.0000 (97.2506)  time: 0.3458  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2380/3125]  eta: 0:04:17  Lr: 0.030000  Loss: 0.3139  Acc@1: 75.0000 (71.8264)  Acc@5: 100.0000 (97.2517)  time: 0.3461  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2390/3125]  eta: 0:04:13  Lr: 0.030000  Loss: 0.2968  Acc@1: 81.2500 (71.8554)  Acc@5: 100.0000 (97.2579)  time: 0.3453  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2400/3125]  eta: 0:04:10  Lr: 0.030000  Loss: 0.2303  Acc@1: 75.0000 (71.8659)  Acc@5: 100.0000 (97.2537)  time: 0.3448  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [2410/3125]  eta: 0:04:06  Lr: 0.030000  Loss: 0.3588  Acc@1: 75.0000 (71.8737)  Acc@5: 100.0000 (97.2548)  time: 0.3451  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [2420/3125]  eta: 0:04:03  Lr: 0.030000  Loss: 0.2720  Acc@1: 62.5000 (71.8608)  Acc@5: 100.0000 (97.2532)  time: 0.3459  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [2430/3125]  eta: 0:03:59  Lr: 0.030000  Loss: 0.4426  Acc@1: 75.0000 (71.8891)  Acc@5: 100.0000 (97.2568)  time: 0.3459  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [2440/3125]  eta: 0:03:56  Lr: 0.030000  Loss: 0.2779  Acc@1: 75.0000 (71.9121)  Acc@5: 100.0000 (97.2629)  time: 0.3450  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [2450/3125]  eta: 0:03:52  Lr: 0.030000  Loss: 0.4775  Acc@1: 75.0000 (71.9349)  Acc@5: 100.0000 (97.2715)  time: 0.3454  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [2460/3125]  eta: 0:03:49  Lr: 0.030000  Loss: 0.3841  Acc@1: 75.0000 (71.9525)  Acc@5: 100.0000 (97.2725)  time: 0.3445  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [2470/3125]  eta: 0:03:46  Lr: 0.030000  Loss: 0.3588  Acc@1: 75.0000 (71.9420)  Acc@5: 100.0000 (97.2784)  time: 0.3433  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [2480/3125]  eta: 0:03:42  Lr: 0.030000  Loss: 0.1304  Acc@1: 68.7500 (71.9342)  Acc@5: 100.0000 (97.2768)  time: 0.3433  data: 0.0002  max mem: 2500
Train: Epoch[4/5]  [2490/3125]  eta: 0:03:39  Lr: 0.030000  Loss: 0.2622  Acc@1: 75.0000 (71.9691)  Acc@5: 100.0000 (97.2827)  time: 0.3434  data: 0.0002  max mem: 2500
Train: Epoch[4/5]  [2500/3125]  eta: 0:03:35  Lr: 0.030000  Loss: 0.4035  Acc@1: 75.0000 (71.9812)  Acc@5: 100.0000 (97.2761)  time: 0.3433  data: 0.0002  max mem: 2500
Train: Epoch[4/5]  [2510/3125]  eta: 0:03:32  Lr: 0.030000  Loss: 0.3129  Acc@1: 75.0000 (72.0057)  Acc@5: 93.7500 (97.2695)  time: 0.3450  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [2520/3125]  eta: 0:03:28  Lr: 0.030000  Loss: 0.5404  Acc@1: 75.0000 (72.0076)  Acc@5: 100.0000 (97.2679)  time: 0.3460  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2530/3125]  eta: 0:03:25  Lr: 0.030000  Loss: 0.0753  Acc@1: 75.0000 (72.0121)  Acc@5: 100.0000 (97.2615)  time: 0.3449  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2540/3125]  eta: 0:03:21  Lr: 0.030000  Loss: 0.1341  Acc@1: 75.0000 (72.0263)  Acc@5: 100.0000 (97.2649)  time: 0.3452  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2550/3125]  eta: 0:03:18  Lr: 0.030000  Loss: 0.3680  Acc@1: 75.0000 (72.0208)  Acc@5: 100.0000 (97.2731)  time: 0.3452  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2560/3125]  eta: 0:03:14  Lr: 0.030000  Loss: 0.3676  Acc@1: 75.0000 (72.0324)  Acc@5: 100.0000 (97.2740)  time: 0.3447  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2570/3125]  eta: 0:03:11  Lr: 0.030000  Loss: 0.0953  Acc@1: 75.0000 (72.0391)  Acc@5: 100.0000 (97.2749)  time: 0.3452  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2580/3125]  eta: 0:03:08  Lr: 0.030000  Loss: 0.5520  Acc@1: 68.7500 (72.0336)  Acc@5: 100.0000 (97.2758)  time: 0.3457  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2590/3125]  eta: 0:03:04  Lr: 0.030000  Loss: 0.2504  Acc@1: 68.7500 (72.0330)  Acc@5: 100.0000 (97.2766)  time: 0.3497  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [2600/3125]  eta: 0:03:01  Lr: 0.030000  Loss: 0.1470  Acc@1: 75.0000 (72.0468)  Acc@5: 100.0000 (97.2799)  time: 0.3491  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [2610/3125]  eta: 0:02:57  Lr: 0.030000  Loss: 0.2383  Acc@1: 75.0000 (72.0533)  Acc@5: 100.0000 (97.2807)  time: 0.3452  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [2620/3125]  eta: 0:02:54  Lr: 0.030000  Loss: 0.5536  Acc@1: 68.7500 (72.0383)  Acc@5: 100.0000 (97.2816)  time: 0.3458  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [2630/3125]  eta: 0:02:50  Lr: 0.030000  Loss: 0.3641  Acc@1: 68.7500 (72.0425)  Acc@5: 100.0000 (97.2872)  time: 0.3455  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [2640/3125]  eta: 0:02:47  Lr: 0.030000  Loss: 0.1530  Acc@1: 75.0000 (72.0797)  Acc@5: 100.0000 (97.2927)  time: 0.3451  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [2650/3125]  eta: 0:02:43  Lr: 0.030000  Loss: 0.0693  Acc@1: 75.0000 (72.0624)  Acc@5: 100.0000 (97.2911)  time: 0.3457  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [2660/3125]  eta: 0:02:40  Lr: 0.030000  Loss: 0.2517  Acc@1: 75.0000 (72.0899)  Acc@5: 100.0000 (97.2966)  time: 0.3447  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [2670/3125]  eta: 0:02:37  Lr: 0.030000  Loss: 0.2599  Acc@1: 75.0000 (72.0751)  Acc@5: 100.0000 (97.3020)  time: 0.3432  data: 0.0002  max mem: 2500
Train: Epoch[4/5]  [2680/3125]  eta: 0:02:33  Lr: 0.030000  Loss: 0.2840  Acc@1: 68.7500 (72.0790)  Acc@5: 100.0000 (97.2935)  time: 0.3432  data: 0.0002  max mem: 2500
Train: Epoch[4/5]  [2690/3125]  eta: 0:02:30  Lr: 0.030000  Loss: 0.3570  Acc@1: 75.0000 (72.0875)  Acc@5: 100.0000 (97.2989)  time: 0.3429  data: 0.0002  max mem: 2500
Train: Epoch[4/5]  [2700/3125]  eta: 0:02:26  Lr: 0.030000  Loss: 0.4957  Acc@1: 68.7500 (72.0728)  Acc@5: 100.0000 (97.2973)  time: 0.3432  data: 0.0002  max mem: 2500
Train: Epoch[4/5]  [2710/3125]  eta: 0:02:23  Lr: 0.030000  Loss: 0.4952  Acc@1: 68.7500 (72.0675)  Acc@5: 100.0000 (97.2934)  time: 0.3434  data: 0.0002  max mem: 2500
Train: Epoch[4/5]  [2720/3125]  eta: 0:02:19  Lr: 0.030000  Loss: 0.5687  Acc@1: 75.0000 (72.0668)  Acc@5: 100.0000 (97.2896)  time: 0.3433  data: 0.0002  max mem: 2500
Train: Epoch[4/5]  [2730/3125]  eta: 0:02:16  Lr: 0.030000  Loss: 0.3671  Acc@1: 75.0000 (72.0775)  Acc@5: 100.0000 (97.2927)  time: 0.3441  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [2740/3125]  eta: 0:02:12  Lr: 0.030000  Loss: 0.3657  Acc@1: 75.0000 (72.0905)  Acc@5: 100.0000 (97.2980)  time: 0.3469  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2750/3125]  eta: 0:02:09  Lr: 0.030000  Loss: 0.2126  Acc@1: 75.0000 (72.0852)  Acc@5: 100.0000 (97.2987)  time: 0.3479  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2760/3125]  eta: 0:02:05  Lr: 0.030000  Loss: 0.3712  Acc@1: 68.7500 (72.0912)  Acc@5: 100.0000 (97.2994)  time: 0.3461  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2770/3125]  eta: 0:02:02  Lr: 0.030000  Loss: 0.3260  Acc@1: 75.0000 (72.0972)  Acc@5: 100.0000 (97.3069)  time: 0.3467  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2780/3125]  eta: 0:01:59  Lr: 0.030000  Loss: 0.3190  Acc@1: 68.7500 (72.0851)  Acc@5: 100.0000 (97.3031)  time: 0.3477  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2790/3125]  eta: 0:01:55  Lr: 0.030000  Loss: 0.2393  Acc@1: 68.7500 (72.0933)  Acc@5: 93.7500 (97.2994)  time: 0.3467  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2800/3125]  eta: 0:01:52  Lr: 0.030000  Loss: 0.2092  Acc@1: 75.0000 (72.0948)  Acc@5: 93.7500 (97.2956)  time: 0.3454  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2810/3125]  eta: 0:01:48  Lr: 0.030000  Loss: 0.0905  Acc@1: 75.0000 (72.1029)  Acc@5: 100.0000 (97.3008)  time: 0.3448  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [2820/3125]  eta: 0:01:45  Lr: 0.030000  Loss: 0.3109  Acc@1: 75.0000 (72.1198)  Acc@5: 100.0000 (97.3037)  time: 0.3456  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [2830/3125]  eta: 0:01:41  Lr: 0.030000  Loss: 0.2258  Acc@1: 75.0000 (72.1366)  Acc@5: 100.0000 (97.3066)  time: 0.3469  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2840/3125]  eta: 0:01:38  Lr: 0.030000  Loss: 0.2904  Acc@1: 81.2500 (72.1467)  Acc@5: 100.0000 (97.3051)  time: 0.3500  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2850/3125]  eta: 0:01:34  Lr: 0.030000  Loss: 0.2944  Acc@1: 75.0000 (72.1523)  Acc@5: 93.7500 (97.2992)  time: 0.3490  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2860/3125]  eta: 0:01:31  Lr: 0.030000  Loss: 0.1729  Acc@1: 75.0000 (72.1426)  Acc@5: 100.0000 (97.3021)  time: 0.3452  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [2870/3125]  eta: 0:01:28  Lr: 0.030000  Loss: 0.1641  Acc@1: 75.0000 (72.1373)  Acc@5: 100.0000 (97.3093)  time: 0.3449  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [2880/3125]  eta: 0:01:24  Lr: 0.030000  Loss: 0.5092  Acc@1: 68.7500 (72.1299)  Acc@5: 100.0000 (97.3078)  time: 0.3455  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [2890/3125]  eta: 0:01:21  Lr: 0.030000  Loss: 0.3335  Acc@1: 75.0000 (72.1312)  Acc@5: 100.0000 (97.3149)  time: 0.3456  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [2900/3125]  eta: 0:01:17  Lr: 0.030000  Loss: 0.2365  Acc@1: 75.0000 (72.1691)  Acc@5: 100.0000 (97.3177)  time: 0.3452  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [2910/3125]  eta: 0:01:14  Lr: 0.030000  Loss: 0.1861  Acc@1: 81.2500 (72.1852)  Acc@5: 100.0000 (97.3205)  time: 0.3452  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [2920/3125]  eta: 0:01:10  Lr: 0.030000  Loss: 0.1638  Acc@1: 75.0000 (72.1885)  Acc@5: 100.0000 (97.3190)  time: 0.3454  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [2930/3125]  eta: 0:01:07  Lr: 0.030000  Loss: 0.4656  Acc@1: 68.7500 (72.1639)  Acc@5: 100.0000 (97.3175)  time: 0.3444  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [2940/3125]  eta: 0:01:03  Lr: 0.030000  Loss: 0.2904  Acc@1: 68.7500 (72.1608)  Acc@5: 100.0000 (97.3223)  time: 0.3431  data: 0.0002  max mem: 2500
Train: Epoch[4/5]  [2950/3125]  eta: 0:01:00  Lr: 0.030000  Loss: 0.4826  Acc@1: 68.7500 (72.1472)  Acc@5: 100.0000 (97.3229)  time: 0.3431  data: 0.0002  max mem: 2500
Train: Epoch[4/5]  [2960/3125]  eta: 0:00:56  Lr: 0.030000  Loss: 0.0800  Acc@1: 68.7500 (72.1631)  Acc@5: 100.0000 (97.3214)  time: 0.3432  data: 0.0002  max mem: 2500
Train: Epoch[4/5]  [2970/3125]  eta: 0:00:53  Lr: 0.030000  Loss: 0.2856  Acc@1: 81.2500 (72.1874)  Acc@5: 100.0000 (97.3262)  time: 0.3432  data: 0.0002  max mem: 2500
Train: Epoch[4/5]  [2980/3125]  eta: 0:00:50  Lr: 0.030000  Loss: 0.4061  Acc@1: 75.0000 (72.1822)  Acc@5: 100.0000 (97.3226)  time: 0.3435  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [2990/3125]  eta: 0:00:46  Lr: 0.030000  Loss: 0.2074  Acc@1: 75.0000 (72.1937)  Acc@5: 100.0000 (97.3232)  time: 0.3449  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3000/3125]  eta: 0:00:43  Lr: 0.030000  Loss: 0.3483  Acc@1: 75.0000 (72.2030)  Acc@5: 100.0000 (97.3217)  time: 0.3459  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3010/3125]  eta: 0:00:39  Lr: 0.030000  Loss: 0.2644  Acc@1: 75.0000 (72.2310)  Acc@5: 100.0000 (97.3223)  time: 0.3456  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [3020/3125]  eta: 0:00:36  Lr: 0.030000  Loss: 0.4668  Acc@1: 75.0000 (72.2422)  Acc@5: 100.0000 (97.3208)  time: 0.3449  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3030/3125]  eta: 0:00:32  Lr: 0.030000  Loss: 0.0924  Acc@1: 68.7500 (72.2493)  Acc@5: 100.0000 (97.3214)  time: 0.3447  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3040/3125]  eta: 0:00:29  Lr: 0.030000  Loss: 0.1976  Acc@1: 81.2500 (72.2624)  Acc@5: 100.0000 (97.3200)  time: 0.3454  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3050/3125]  eta: 0:00:25  Lr: 0.030000  Loss: 0.3351  Acc@1: 68.7500 (72.2591)  Acc@5: 93.7500 (97.3083)  time: 0.3454  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3060/3125]  eta: 0:00:22  Lr: 0.030000  Loss: 0.4147  Acc@1: 68.7500 (72.2395)  Acc@5: 93.7500 (97.3028)  time: 0.3454  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3070/3125]  eta: 0:00:18  Lr: 0.030000  Loss: 0.2518  Acc@1: 75.0000 (72.2607)  Acc@5: 100.0000 (97.3014)  time: 0.3453  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3080/3125]  eta: 0:00:15  Lr: 0.030000  Loss: 0.0672  Acc@1: 75.0000 (72.2756)  Acc@5: 100.0000 (97.3040)  time: 0.3448  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3090/3125]  eta: 0:00:12  Lr: 0.030000  Loss: 0.2747  Acc@1: 75.0000 (72.2925)  Acc@5: 100.0000 (97.3027)  time: 0.3444  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3100/3125]  eta: 0:00:08  Lr: 0.030000  Loss: 0.1295  Acc@1: 75.0000 (72.3033)  Acc@5: 100.0000 (97.3093)  time: 0.3459  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3110/3125]  eta: 0:00:05  Lr: 0.030000  Loss: 0.4941  Acc@1: 68.7500 (72.3019)  Acc@5: 100.0000 (97.3079)  time: 0.3458  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [3120/3125]  eta: 0:00:01  Lr: 0.030000  Loss: 0.1489  Acc@1: 68.7500 (72.3025)  Acc@5: 100.0000 (97.3086)  time: 0.3440  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [3124/3125]  eta: 0:00:00  Lr: 0.030000  Loss: 0.1981  Acc@1: 68.7500 (72.3080)  Acc@5: 100.0000 (97.3060)  time: 0.3441  data: 0.0005  max mem: 2500
Train: Epoch[4/5] Total time: 0:17:59 (0.3453 s / it)
{0: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 1: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 2: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 3: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 4: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 5: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 6: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 7: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 8: {0: 0, 1: 0, 2: 200000, 3: 0, 4: 0}, 9: {0: 0, 1: 0, 2: 200000, 3: 0, 4: 0}, 10: {0: 0, 1: 0, 2: 200000, 3: 0, 4: 0}, 11: {0: 0, 1: 0, 2: 200000, 3: 0, 4: 0}, 12: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 13: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 14: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 15: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 16: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 17: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 18: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 19: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}}
Averaged stats: Lr: 0.030000  Loss: 0.1981  Acc@1: 68.7500 (72.3080)  Acc@5: 100.0000 (97.3060)
Train: Epoch[5/5]  [   0/3125]  eta: 0:31:37  Lr: 0.030000  Loss: 0.4795  Acc@1: 56.2500 (56.2500)  Acc@5: 100.0000 (100.0000)  time: 0.6073  data: 0.2637  max mem: 2500
Train: Epoch[5/5]  [  10/3125]  eta: 0:19:08  Lr: 0.030000  Loss: 0.4526  Acc@1: 68.7500 (69.3182)  Acc@5: 100.0000 (97.7273)  time: 0.3689  data: 0.0242  max mem: 2500
Train: Epoch[5/5]  [  20/3125]  eta: 0:18:28  Lr: 0.030000  Loss: 0.4130  Acc@1: 68.7500 (69.9405)  Acc@5: 100.0000 (97.6190)  time: 0.3444  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [  30/3125]  eta: 0:18:12  Lr: 0.030000  Loss: 0.1698  Acc@1: 75.0000 (73.3871)  Acc@5: 100.0000 (97.9839)  time: 0.3441  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [  40/3125]  eta: 0:18:02  Lr: 0.030000  Loss: 0.3539  Acc@1: 75.0000 (73.0183)  Acc@5: 100.0000 (98.1707)  time: 0.3447  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [  50/3125]  eta: 0:17:54  Lr: 0.030000  Loss: 0.1724  Acc@1: 75.0000 (73.1618)  Acc@5: 100.0000 (98.0392)  time: 0.3439  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [  60/3125]  eta: 0:17:47  Lr: 0.030000  Loss: 0.1100  Acc@1: 75.0000 (74.0779)  Acc@5: 100.0000 (97.9508)  time: 0.3426  data: 0.0002  max mem: 2500
Train: Epoch[5/5]  [  70/3125]  eta: 0:17:41  Lr: 0.030000  Loss: 0.3488  Acc@1: 75.0000 (74.2958)  Acc@5: 100.0000 (97.9754)  time: 0.3427  data: 0.0002  max mem: 2500
Train: Epoch[5/5]  [  80/3125]  eta: 0:17:36  Lr: 0.030000  Loss: 0.0227  Acc@1: 68.7500 (73.9198)  Acc@5: 100.0000 (97.6852)  time: 0.3429  data: 0.0002  max mem: 2500
Train: Epoch[5/5]  [  90/3125]  eta: 0:17:31  Lr: 0.030000  Loss: 0.1691  Acc@1: 75.0000 (74.2445)  Acc@5: 100.0000 (97.7335)  time: 0.3427  data: 0.0002  max mem: 2500
Train: Epoch[5/5]  [ 100/3125]  eta: 0:17:27  Lr: 0.030000  Loss: 0.0217  Acc@1: 81.2500 (74.6287)  Acc@5: 100.0000 (97.7723)  time: 0.3433  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [ 110/3125]  eta: 0:17:23  Lr: 0.030000  Loss: 0.4589  Acc@1: 75.0000 (74.3243)  Acc@5: 100.0000 (97.7477)  time: 0.3438  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 120/3125]  eta: 0:17:19  Lr: 0.030000  Loss: 0.3546  Acc@1: 68.7500 (74.3285)  Acc@5: 100.0000 (97.7789)  time: 0.3439  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 130/3125]  eta: 0:17:15  Lr: 0.030000  Loss: 0.1390  Acc@1: 75.0000 (74.3798)  Acc@5: 100.0000 (97.9008)  time: 0.3443  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 140/3125]  eta: 0:17:11  Lr: 0.030000  Loss: 0.2573  Acc@1: 75.0000 (74.4238)  Acc@5: 100.0000 (97.9167)  time: 0.3450  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 150/3125]  eta: 0:17:08  Lr: 0.030000  Loss: 0.3574  Acc@1: 75.0000 (74.4619)  Acc@5: 93.7500 (97.6821)  time: 0.3456  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 160/3125]  eta: 0:17:04  Lr: 0.030000  Loss: 0.1566  Acc@1: 75.0000 (74.3789)  Acc@5: 93.7500 (97.7096)  time: 0.3450  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 170/3125]  eta: 0:17:01  Lr: 0.030000  Loss: 0.2123  Acc@1: 75.0000 (74.4518)  Acc@5: 100.0000 (97.7339)  time: 0.3448  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 180/3125]  eta: 0:16:57  Lr: 0.030000  Loss: 0.4211  Acc@1: 68.7500 (73.9296)  Acc@5: 100.0000 (97.7210)  time: 0.3452  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 190/3125]  eta: 0:16:54  Lr: 0.030000  Loss: 0.4586  Acc@1: 68.7500 (73.8220)  Acc@5: 93.7500 (97.5785)  time: 0.3455  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [ 200/3125]  eta: 0:16:50  Lr: 0.030000  Loss: 0.3084  Acc@1: 75.0000 (74.0983)  Acc@5: 100.0000 (97.6368)  time: 0.3455  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [ 210/3125]  eta: 0:16:47  Lr: 0.030000  Loss: 0.2214  Acc@1: 75.0000 (73.9040)  Acc@5: 100.0000 (97.6600)  time: 0.3452  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [ 220/3125]  eta: 0:16:43  Lr: 0.030000  Loss: 0.0850  Acc@1: 68.7500 (73.6708)  Acc@5: 100.0000 (97.7376)  time: 0.3450  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [ 230/3125]  eta: 0:16:40  Lr: 0.030000  Loss: 0.1993  Acc@1: 68.7500 (73.6201)  Acc@5: 100.0000 (97.7814)  time: 0.3449  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [ 240/3125]  eta: 0:16:36  Lr: 0.030000  Loss: 0.3446  Acc@1: 75.0000 (73.5477)  Acc@5: 100.0000 (97.7178)  time: 0.3454  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [ 250/3125]  eta: 0:16:33  Lr: 0.030000  Loss: 0.1094  Acc@1: 75.0000 (73.6305)  Acc@5: 100.0000 (97.7590)  time: 0.3445  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [ 260/3125]  eta: 0:16:29  Lr: 0.030000  Loss: 0.2433  Acc@1: 75.0000 (73.7548)  Acc@5: 100.0000 (97.7490)  time: 0.3435  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [ 270/3125]  eta: 0:16:25  Lr: 0.030000  Loss: 0.3820  Acc@1: 75.0000 (73.8699)  Acc@5: 100.0000 (97.7399)  time: 0.3435  data: 0.0002  max mem: 2500
Train: Epoch[5/5]  [ 280/3125]  eta: 0:16:22  Lr: 0.030000  Loss: 0.5916  Acc@1: 75.0000 (73.8212)  Acc@5: 100.0000 (97.7536)  time: 0.3433  data: 0.0002  max mem: 2500
Train: Epoch[5/5]  [ 290/3125]  eta: 0:16:18  Lr: 0.030000  Loss: 0.1781  Acc@1: 68.7500 (73.6899)  Acc@5: 100.0000 (97.7234)  time: 0.3434  data: 0.0002  max mem: 2500
Train: Epoch[5/5]  [ 300/3125]  eta: 0:16:15  Lr: 0.030000  Loss: 0.2163  Acc@1: 75.0000 (73.7749)  Acc@5: 100.0000 (97.7575)  time: 0.3444  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [ 310/3125]  eta: 0:16:11  Lr: 0.030000  Loss: 0.5547  Acc@1: 75.0000 (73.6736)  Acc@5: 100.0000 (97.7492)  time: 0.3451  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [ 320/3125]  eta: 0:16:08  Lr: 0.030000  Loss: 0.2129  Acc@1: 75.0000 (73.7344)  Acc@5: 100.0000 (97.7220)  time: 0.3447  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 330/3125]  eta: 0:16:04  Lr: 0.030000  Loss: 0.5848  Acc@1: 75.0000 (73.7349)  Acc@5: 100.0000 (97.7341)  time: 0.3456  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 340/3125]  eta: 0:16:01  Lr: 0.030000  Loss: 0.2037  Acc@1: 75.0000 (73.8636)  Acc@5: 100.0000 (97.7273)  time: 0.3468  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 350/3125]  eta: 0:15:58  Lr: 0.030000  Loss: 0.3974  Acc@1: 75.0000 (73.7179)  Acc@5: 100.0000 (97.7386)  time: 0.3473  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 360/3125]  eta: 0:15:54  Lr: 0.030000  Loss: 0.2911  Acc@1: 62.5000 (73.5111)  Acc@5: 100.0000 (97.6974)  time: 0.3462  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 370/3125]  eta: 0:15:51  Lr: 0.030000  Loss: 0.2659  Acc@1: 75.0000 (73.6018)  Acc@5: 100.0000 (97.7257)  time: 0.3462  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 380/3125]  eta: 0:15:48  Lr: 0.030000  Loss: 0.2826  Acc@1: 75.0000 (73.5564)  Acc@5: 100.0000 (97.6870)  time: 0.3476  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 390/3125]  eta: 0:15:44  Lr: 0.030000  Loss: 0.2702  Acc@1: 75.0000 (73.6093)  Acc@5: 100.0000 (97.6503)  time: 0.3469  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [ 400/3125]  eta: 0:15:41  Lr: 0.030000  Loss: 0.3145  Acc@1: 75.0000 (73.7064)  Acc@5: 100.0000 (97.6933)  time: 0.3463  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [ 410/3125]  eta: 0:15:37  Lr: 0.030000  Loss: 0.0885  Acc@1: 75.0000 (73.7682)  Acc@5: 100.0000 (97.7190)  time: 0.3463  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [ 420/3125]  eta: 0:15:34  Lr: 0.030000  Loss: 0.2671  Acc@1: 75.0000 (73.8569)  Acc@5: 100.0000 (97.7435)  time: 0.3461  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [ 430/3125]  eta: 0:15:31  Lr: 0.030000  Loss: 0.3494  Acc@1: 75.0000 (73.9559)  Acc@5: 100.0000 (97.7378)  time: 0.3462  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [ 440/3125]  eta: 0:15:27  Lr: 0.030000  Loss: 0.4025  Acc@1: 75.0000 (73.8946)  Acc@5: 100.0000 (97.7324)  time: 0.3462  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [ 450/3125]  eta: 0:15:24  Lr: 0.030000  Loss: 0.1711  Acc@1: 75.0000 (73.9329)  Acc@5: 100.0000 (97.7134)  time: 0.3469  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [ 460/3125]  eta: 0:15:20  Lr: 0.030000  Loss: 0.1302  Acc@1: 75.0000 (73.9018)  Acc@5: 100.0000 (97.7359)  time: 0.3456  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [ 470/3125]  eta: 0:15:17  Lr: 0.030000  Loss: 0.1974  Acc@1: 75.0000 (73.8986)  Acc@5: 100.0000 (97.7707)  time: 0.3441  data: 0.0002  max mem: 2500
Train: Epoch[5/5]  [ 480/3125]  eta: 0:15:13  Lr: 0.030000  Loss: 0.1178  Acc@1: 68.7500 (73.7916)  Acc@5: 100.0000 (97.7651)  time: 0.3443  data: 0.0002  max mem: 2500
Train: Epoch[5/5]  [ 490/3125]  eta: 0:15:10  Lr: 0.030000  Loss: 0.4025  Acc@1: 68.7500 (73.7907)  Acc@5: 100.0000 (97.7851)  time: 0.3443  data: 0.0002  max mem: 2500
Train: Epoch[5/5]  [ 500/3125]  eta: 0:15:06  Lr: 0.030000  Loss: 0.2861  Acc@1: 75.0000 (73.7899)  Acc@5: 100.0000 (97.7670)  time: 0.3440  data: 0.0002  max mem: 2500
Train: Epoch[5/5]  [ 510/3125]  eta: 0:15:03  Lr: 0.030000  Loss: 0.4854  Acc@1: 75.0000 (73.7158)  Acc@5: 93.7500 (97.7373)  time: 0.3438  data: 0.0002  max mem: 2500
Train: Epoch[5/5]  [ 520/3125]  eta: 0:14:59  Lr: 0.030000  Loss: 0.1194  Acc@1: 75.0000 (73.7644)  Acc@5: 100.0000 (97.6847)  time: 0.3440  data: 0.0002  max mem: 2500
Train: Epoch[5/5]  [ 530/3125]  eta: 0:14:56  Lr: 0.030000  Loss: 0.2170  Acc@1: 68.7500 (73.6464)  Acc@5: 100.0000 (97.6930)  time: 0.3438  data: 0.0002  max mem: 2500
Train: Epoch[5/5]  [ 540/3125]  eta: 0:14:52  Lr: 0.030000  Loss: 0.1383  Acc@1: 68.7500 (73.7177)  Acc@5: 100.0000 (97.7010)  time: 0.3447  data: 0.0002  max mem: 2500
Train: Epoch[5/5]  [ 550/3125]  eta: 0:14:49  Lr: 0.030000  Loss: 0.4464  Acc@1: 75.0000 (73.7409)  Acc@5: 100.0000 (97.7087)  time: 0.3463  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 560/3125]  eta: 0:14:45  Lr: 0.030000  Loss: 0.2616  Acc@1: 75.0000 (73.7077)  Acc@5: 100.0000 (97.7273)  time: 0.3465  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 570/3125]  eta: 0:14:42  Lr: 0.030000  Loss: 0.3710  Acc@1: 68.7500 (73.6208)  Acc@5: 100.0000 (97.7342)  time: 0.3464  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 580/3125]  eta: 0:14:39  Lr: 0.030000  Loss: 0.2819  Acc@1: 75.0000 (73.6553)  Acc@5: 100.0000 (97.6979)  time: 0.3462  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 590/3125]  eta: 0:14:35  Lr: 0.030000  Loss: 0.4804  Acc@1: 75.0000 (73.5618)  Acc@5: 93.7500 (97.6840)  time: 0.3455  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 600/3125]  eta: 0:14:32  Lr: 0.030000  Loss: 0.4200  Acc@1: 68.7500 (73.5961)  Acc@5: 100.0000 (97.6913)  time: 0.3453  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 610/3125]  eta: 0:14:28  Lr: 0.030000  Loss: -0.0244  Acc@1: 75.0000 (73.5884)  Acc@5: 100.0000 (97.6984)  time: 0.3452  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [ 620/3125]  eta: 0:14:25  Lr: 0.030000  Loss: 0.1906  Acc@1: 75.0000 (73.5809)  Acc@5: 100.0000 (97.6952)  time: 0.3444  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [ 630/3125]  eta: 0:14:21  Lr: 0.030000  Loss: 0.3323  Acc@1: 75.0000 (73.6331)  Acc@5: 100.0000 (97.7219)  time: 0.3444  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [ 640/3125]  eta: 0:14:18  Lr: 0.030000  Loss: 0.1443  Acc@1: 75.0000 (73.5472)  Acc@5: 100.0000 (97.7184)  time: 0.3446  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [ 650/3125]  eta: 0:14:14  Lr: 0.030000  Loss: 0.3258  Acc@1: 68.7500 (73.4735)  Acc@5: 100.0000 (97.7247)  time: 0.3451  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 660/3125]  eta: 0:14:11  Lr: 0.030000  Loss: 0.2450  Acc@1: 81.2500 (73.5628)  Acc@5: 100.0000 (97.7402)  time: 0.3457  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 670/3125]  eta: 0:14:07  Lr: 0.030000  Loss: 0.1653  Acc@1: 81.2500 (73.6028)  Acc@5: 100.0000 (97.7366)  time: 0.3457  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [ 680/3125]  eta: 0:14:04  Lr: 0.030000  Loss: 0.1189  Acc@1: 75.0000 (73.6784)  Acc@5: 100.0000 (97.7698)  time: 0.3464  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [ 690/3125]  eta: 0:14:01  Lr: 0.030000  Loss: 0.1552  Acc@1: 75.0000 (73.6885)  Acc@5: 100.0000 (97.7388)  time: 0.3483  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 700/3125]  eta: 0:13:57  Lr: 0.030000  Loss: 0.3131  Acc@1: 75.0000 (73.7161)  Acc@5: 100.0000 (97.7265)  time: 0.3474  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 710/3125]  eta: 0:13:54  Lr: 0.030000  Loss: -0.0539  Acc@1: 68.7500 (73.7342)  Acc@5: 100.0000 (97.7145)  time: 0.3450  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [ 720/3125]  eta: 0:13:50  Lr: 0.030000  Loss: 0.2216  Acc@1: 68.7500 (73.6737)  Acc@5: 100.0000 (97.7288)  time: 0.3449  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [ 730/3125]  eta: 0:13:47  Lr: 0.030000  Loss: 0.3190  Acc@1: 68.7500 (73.6748)  Acc@5: 100.0000 (97.7172)  time: 0.3454  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [ 740/3125]  eta: 0:13:43  Lr: 0.030000  Loss: 0.0980  Acc@1: 75.0000 (73.6420)  Acc@5: 93.7500 (97.6805)  time: 0.3456  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [ 750/3125]  eta: 0:13:40  Lr: 0.030000  Loss: 0.0211  Acc@1: 75.0000 (73.6601)  Acc@5: 100.0000 (97.6947)  time: 0.3456  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [ 760/3125]  eta: 0:13:36  Lr: 0.030000  Loss: 0.1788  Acc@1: 75.0000 (73.6777)  Acc@5: 100.0000 (97.7004)  time: 0.3457  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [ 770/3125]  eta: 0:13:33  Lr: 0.030000  Loss: 0.0369  Acc@1: 68.7500 (73.6138)  Acc@5: 100.0000 (97.6978)  time: 0.3460  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [ 780/3125]  eta: 0:13:29  Lr: 0.030000  Loss: 0.2925  Acc@1: 68.7500 (73.6076)  Acc@5: 100.0000 (97.6953)  time: 0.3449  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [ 790/3125]  eta: 0:13:26  Lr: 0.030000  Loss: 0.4428  Acc@1: 75.0000 (73.6647)  Acc@5: 100.0000 (97.7086)  time: 0.3430  data: 0.0002  max mem: 2500
Train: Epoch[5/5]  [ 800/3125]  eta: 0:13:22  Lr: 0.030000  Loss: 0.3162  Acc@1: 75.0000 (73.6657)  Acc@5: 100.0000 (97.6904)  time: 0.3430  data: 0.0002  max mem: 2500
Train: Epoch[5/5]  [ 810/3125]  eta: 0:13:19  Lr: 0.030000  Loss: 0.1669  Acc@1: 75.0000 (73.6976)  Acc@5: 100.0000 (97.6726)  time: 0.3427  data: 0.0002  max mem: 2500
Train: Epoch[5/5]  [ 820/3125]  eta: 0:13:15  Lr: 0.030000  Loss: 0.3072  Acc@1: 81.2500 (73.7591)  Acc@5: 100.0000 (97.6705)  time: 0.3426  data: 0.0002  max mem: 2500
Train: Epoch[5/5]  [ 830/3125]  eta: 0:13:12  Lr: 0.030000  Loss: 0.1016  Acc@1: 81.2500 (73.8192)  Acc@5: 93.7500 (97.6384)  time: 0.3429  data: 0.0002  max mem: 2500
Train: Epoch[5/5]  [ 840/3125]  eta: 0:13:08  Lr: 0.030000  Loss: 0.3006  Acc@1: 75.0000 (73.7961)  Acc@5: 93.7500 (97.6070)  time: 0.3429  data: 0.0002  max mem: 2500
Train: Epoch[5/5]  [ 850/3125]  eta: 0:13:05  Lr: 0.030000  Loss: 0.4777  Acc@1: 68.7500 (73.8323)  Acc@5: 93.7500 (97.5984)  time: 0.3429  data: 0.0002  max mem: 2500
Train: Epoch[5/5]  [ 860/3125]  eta: 0:13:01  Lr: 0.030000  Loss: 0.1898  Acc@1: 75.0000 (73.8240)  Acc@5: 93.7500 (97.5828)  time: 0.3430  data: 0.0002  max mem: 2500
Train: Epoch[5/5]  [ 870/3125]  eta: 0:12:58  Lr: 0.030000  Loss: 0.0108  Acc@1: 75.0000 (73.8232)  Acc@5: 100.0000 (97.5818)  time: 0.3441  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [ 880/3125]  eta: 0:12:54  Lr: 0.030000  Loss: 0.0544  Acc@1: 75.0000 (73.8224)  Acc@5: 100.0000 (97.5454)  time: 0.3459  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [ 890/3125]  eta: 0:12:51  Lr: 0.030000  Loss: 0.2133  Acc@1: 75.0000 (73.8145)  Acc@5: 100.0000 (97.5659)  time: 0.3456  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [ 900/3125]  eta: 0:12:48  Lr: 0.030000  Loss: 0.0740  Acc@1: 81.2500 (73.8554)  Acc@5: 100.0000 (97.5721)  time: 0.3455  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 910/3125]  eta: 0:12:44  Lr: 0.030000  Loss: -0.0101  Acc@1: 87.5000 (73.9572)  Acc@5: 100.0000 (97.5714)  time: 0.3459  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [ 920/3125]  eta: 0:12:41  Lr: 0.030000  Loss: 0.2789  Acc@1: 81.2500 (73.9821)  Acc@5: 100.0000 (97.5774)  time: 0.3454  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 930/3125]  eta: 0:12:37  Lr: 0.030000  Loss: 0.3401  Acc@1: 75.0000 (73.9729)  Acc@5: 100.0000 (97.5631)  time: 0.3459  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 940/3125]  eta: 0:12:34  Lr: 0.030000  Loss: 0.4475  Acc@1: 75.0000 (73.9639)  Acc@5: 93.7500 (97.5558)  time: 0.3455  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 950/3125]  eta: 0:12:30  Lr: 0.030000  Loss: 0.0678  Acc@1: 68.7500 (73.9419)  Acc@5: 100.0000 (97.5618)  time: 0.3463  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 960/3125]  eta: 0:12:27  Lr: 0.030000  Loss: 0.0943  Acc@1: 68.7500 (73.9594)  Acc@5: 100.0000 (97.5481)  time: 0.3466  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 970/3125]  eta: 0:12:23  Lr: 0.030000  Loss: 0.3697  Acc@1: 75.0000 (73.9573)  Acc@5: 100.0000 (97.5605)  time: 0.3446  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 980/3125]  eta: 0:12:20  Lr: 0.030000  Loss: 0.1267  Acc@1: 75.0000 (73.9806)  Acc@5: 100.0000 (97.5535)  time: 0.3443  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 990/3125]  eta: 0:12:17  Lr: 0.030000  Loss: 0.2025  Acc@1: 75.0000 (73.9972)  Acc@5: 100.0000 (97.5782)  time: 0.3448  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1000/3125]  eta: 0:12:13  Lr: 0.030000  Loss: 0.0586  Acc@1: 68.7500 (73.9760)  Acc@5: 100.0000 (97.5899)  time: 0.3453  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1010/3125]  eta: 0:12:10  Lr: 0.030000  Loss: 0.1417  Acc@1: 68.7500 (73.9614)  Acc@5: 100.0000 (97.5705)  time: 0.3456  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1020/3125]  eta: 0:12:06  Lr: 0.030000  Loss: 0.0637  Acc@1: 75.0000 (73.9594)  Acc@5: 100.0000 (97.5575)  time: 0.3458  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1030/3125]  eta: 0:12:03  Lr: 0.030000  Loss: 0.2142  Acc@1: 75.0000 (73.9331)  Acc@5: 100.0000 (97.5570)  time: 0.3499  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1040/3125]  eta: 0:11:59  Lr: 0.030000  Loss: 0.2541  Acc@1: 75.0000 (73.9013)  Acc@5: 100.0000 (97.5504)  time: 0.3493  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [1050/3125]  eta: 0:11:56  Lr: 0.030000  Loss: 0.3764  Acc@1: 68.7500 (73.9118)  Acc@5: 100.0000 (97.5559)  time: 0.3447  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [1060/3125]  eta: 0:11:53  Lr: 0.030000  Loss: 0.2562  Acc@1: 75.0000 (73.9220)  Acc@5: 100.0000 (97.5672)  time: 0.3457  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [1070/3125]  eta: 0:11:49  Lr: 0.030000  Loss: 0.2419  Acc@1: 75.0000 (73.9321)  Acc@5: 100.0000 (97.5724)  time: 0.3456  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [1080/3125]  eta: 0:11:46  Lr: 0.030000  Loss: 0.3138  Acc@1: 75.0000 (73.9304)  Acc@5: 100.0000 (97.5890)  time: 0.3446  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [1090/3125]  eta: 0:11:42  Lr: 0.030000  Loss: 0.4137  Acc@1: 75.0000 (73.9459)  Acc@5: 100.0000 (97.5940)  time: 0.3445  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [1100/3125]  eta: 0:11:39  Lr: 0.030000  Loss: 0.2030  Acc@1: 75.0000 (73.9668)  Acc@5: 100.0000 (97.6045)  time: 0.3443  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [1110/3125]  eta: 0:11:35  Lr: 0.030000  Loss: 0.2536  Acc@1: 75.0000 (73.9761)  Acc@5: 100.0000 (97.5866)  time: 0.3440  data: 0.0002  max mem: 2500
Train: Epoch[5/5]  [1120/3125]  eta: 0:11:32  Lr: 0.030000  Loss: 0.3137  Acc@1: 75.0000 (73.9741)  Acc@5: 100.0000 (97.5914)  time: 0.3436  data: 0.0002  max mem: 2500
Train: Epoch[5/5]  [1130/3125]  eta: 0:11:28  Lr: 0.030000  Loss: 0.0213  Acc@1: 68.7500 (73.9887)  Acc@5: 100.0000 (97.5962)  time: 0.3441  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [1140/3125]  eta: 0:11:25  Lr: 0.030000  Loss: 0.3226  Acc@1: 68.7500 (73.9264)  Acc@5: 100.0000 (97.5734)  time: 0.3444  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [1150/3125]  eta: 0:11:21  Lr: 0.030000  Loss: 0.3578  Acc@1: 68.7500 (73.9194)  Acc@5: 100.0000 (97.5673)  time: 0.3448  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1160/3125]  eta: 0:11:18  Lr: 0.030000  Loss: 0.0791  Acc@1: 75.0000 (73.9072)  Acc@5: 100.0000 (97.5775)  time: 0.3449  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1170/3125]  eta: 0:11:14  Lr: 0.030000  Loss: 0.0978  Acc@1: 75.0000 (73.9592)  Acc@5: 100.0000 (97.5822)  time: 0.3444  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1180/3125]  eta: 0:11:11  Lr: 0.030000  Loss: 0.0925  Acc@1: 75.0000 (73.9680)  Acc@5: 100.0000 (97.5709)  time: 0.3465  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1190/3125]  eta: 0:11:08  Lr: 0.030000  Loss: 0.3365  Acc@1: 75.0000 (73.9977)  Acc@5: 100.0000 (97.5756)  time: 0.3468  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [1200/3125]  eta: 0:11:04  Lr: 0.030000  Loss: 0.2059  Acc@1: 75.0000 (74.0112)  Acc@5: 100.0000 (97.5749)  time: 0.3448  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [1210/3125]  eta: 0:11:01  Lr: 0.030000  Loss: 0.1613  Acc@1: 75.0000 (74.0246)  Acc@5: 100.0000 (97.5898)  time: 0.3450  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [1220/3125]  eta: 0:10:57  Lr: 0.030000  Loss: 0.2132  Acc@1: 75.0000 (73.9916)  Acc@5: 100.0000 (97.5891)  time: 0.3455  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [1230/3125]  eta: 0:10:54  Lr: 0.030000  Loss: 0.0440  Acc@1: 75.0000 (74.0607)  Acc@5: 100.0000 (97.5934)  time: 0.3455  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [1240/3125]  eta: 0:10:50  Lr: 0.030000  Loss: 0.1917  Acc@1: 75.0000 (74.0532)  Acc@5: 100.0000 (97.5977)  time: 0.3454  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [1250/3125]  eta: 0:10:47  Lr: 0.030000  Loss: 0.2550  Acc@1: 68.7500 (73.9808)  Acc@5: 93.7500 (97.5669)  time: 0.3445  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [1260/3125]  eta: 0:10:43  Lr: 0.030000  Loss: 0.4521  Acc@1: 75.0000 (74.0186)  Acc@5: 93.7500 (97.5615)  time: 0.3433  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [1270/3125]  eta: 0:10:40  Lr: 0.030000  Loss: 0.2513  Acc@1: 75.0000 (73.9969)  Acc@5: 100.0000 (97.5610)  time: 0.3433  data: 0.0002  max mem: 2500
Train: Epoch[5/5]  [1280/3125]  eta: 0:10:36  Lr: 0.030000  Loss: 0.2692  Acc@1: 75.0000 (73.9949)  Acc@5: 100.0000 (97.5556)  time: 0.3433  data: 0.0002  max mem: 2500
Train: Epoch[5/5]  [1290/3125]  eta: 0:10:33  Lr: 0.030000  Loss: 0.3824  Acc@1: 75.0000 (74.0124)  Acc@5: 100.0000 (97.5503)  time: 0.3434  data: 0.0002  max mem: 2500
Train: Epoch[5/5]  [1300/3125]  eta: 0:10:29  Lr: 0.030000  Loss: 0.1130  Acc@1: 75.0000 (74.0200)  Acc@5: 100.0000 (97.5596)  time: 0.3452  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1310/3125]  eta: 0:10:26  Lr: 0.030000  Loss: 0.0907  Acc@1: 75.0000 (74.0179)  Acc@5: 100.0000 (97.5686)  time: 0.3462  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1320/3125]  eta: 0:10:23  Lr: 0.030000  Loss: 0.2079  Acc@1: 75.0000 (74.0206)  Acc@5: 100.0000 (97.5681)  time: 0.3453  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1330/3125]  eta: 0:10:19  Lr: 0.030000  Loss: 0.1912  Acc@1: 68.7500 (74.0045)  Acc@5: 100.0000 (97.5817)  time: 0.3451  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1340/3125]  eta: 0:10:16  Lr: 0.030000  Loss: 0.1140  Acc@1: 75.0000 (74.0399)  Acc@5: 100.0000 (97.5764)  time: 0.3453  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1350/3125]  eta: 0:10:12  Lr: 0.030000  Loss: 0.1275  Acc@1: 81.2500 (74.0701)  Acc@5: 100.0000 (97.5712)  time: 0.3455  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1360/3125]  eta: 0:10:09  Lr: 0.030000  Loss: 0.2556  Acc@1: 75.0000 (74.0632)  Acc@5: 100.0000 (97.5799)  time: 0.3454  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [1370/3125]  eta: 0:10:05  Lr: 0.030000  Loss: 0.4703  Acc@1: 75.0000 (74.0928)  Acc@5: 100.0000 (97.5839)  time: 0.3454  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [1380/3125]  eta: 0:10:02  Lr: 0.030000  Loss: 0.1806  Acc@1: 81.2500 (74.0994)  Acc@5: 100.0000 (97.5969)  time: 0.3453  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1390/3125]  eta: 0:09:58  Lr: 0.030000  Loss: 0.2648  Acc@1: 75.0000 (74.0834)  Acc@5: 100.0000 (97.6051)  time: 0.3451  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [1400/3125]  eta: 0:09:55  Lr: 0.030000  Loss: 0.1530  Acc@1: 75.0000 (74.1033)  Acc@5: 100.0000 (97.6044)  time: 0.3451  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [1410/3125]  eta: 0:09:52  Lr: 0.030000  Loss: 0.2714  Acc@1: 75.0000 (74.0875)  Acc@5: 100.0000 (97.6036)  time: 0.3452  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1420/3125]  eta: 0:09:48  Lr: 0.030000  Loss: 0.1917  Acc@1: 68.7500 (74.0720)  Acc@5: 100.0000 (97.6073)  time: 0.3454  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [1430/3125]  eta: 0:09:45  Lr: 0.030000  Loss: 0.1819  Acc@1: 75.0000 (74.0872)  Acc@5: 100.0000 (97.6066)  time: 0.3454  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [1440/3125]  eta: 0:09:41  Lr: 0.030000  Loss: 0.2944  Acc@1: 75.0000 (74.0892)  Acc@5: 100.0000 (97.6102)  time: 0.3452  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [1450/3125]  eta: 0:09:38  Lr: 0.030000  Loss: 0.1462  Acc@1: 75.0000 (74.0825)  Acc@5: 100.0000 (97.6137)  time: 0.3445  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [1460/3125]  eta: 0:09:34  Lr: 0.030000  Loss: 0.2064  Acc@1: 68.7500 (74.0375)  Acc@5: 100.0000 (97.6129)  time: 0.3435  data: 0.0002  max mem: 2500
Train: Epoch[5/5]  [1470/3125]  eta: 0:09:31  Lr: 0.030000  Loss: 0.1839  Acc@1: 68.7500 (74.0398)  Acc@5: 100.0000 (97.6122)  time: 0.3435  data: 0.0002  max mem: 2500
Train: Epoch[5/5]  [1480/3125]  eta: 0:09:27  Lr: 0.030000  Loss: 0.2266  Acc@1: 75.0000 (74.0294)  Acc@5: 100.0000 (97.6156)  time: 0.3438  data: 0.0002  max mem: 2500
Train: Epoch[5/5]  [1490/3125]  eta: 0:09:24  Lr: 0.030000  Loss: 0.2597  Acc@1: 68.7500 (74.0065)  Acc@5: 100.0000 (97.6149)  time: 0.3437  data: 0.0002  max mem: 2500
Train: Epoch[5/5]  [1500/3125]  eta: 0:09:20  Lr: 0.030000  Loss: 0.3694  Acc@1: 75.0000 (74.0256)  Acc@5: 100.0000 (97.6016)  time: 0.3438  data: 0.0002  max mem: 2500
Train: Epoch[5/5]  [1510/3125]  eta: 0:09:17  Lr: 0.030000  Loss: 0.0296  Acc@1: 75.0000 (74.0486)  Acc@5: 100.0000 (97.6051)  time: 0.3441  data: 0.0002  max mem: 2500
Train: Epoch[5/5]  [1520/3125]  eta: 0:09:13  Lr: 0.030000  Loss: 0.3521  Acc@1: 75.0000 (74.0426)  Acc@5: 100.0000 (97.6044)  time: 0.3454  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1530/3125]  eta: 0:09:10  Lr: 0.030000  Loss: 0.3010  Acc@1: 68.7500 (74.0202)  Acc@5: 100.0000 (97.6078)  time: 0.3467  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1540/3125]  eta: 0:09:07  Lr: 0.030000  Loss: 0.2506  Acc@1: 68.7500 (74.0144)  Acc@5: 100.0000 (97.6030)  time: 0.3475  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1550/3125]  eta: 0:09:03  Lr: 0.030000  Loss: 0.3637  Acc@1: 75.0000 (74.0571)  Acc@5: 100.0000 (97.5903)  time: 0.3465  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1560/3125]  eta: 0:09:00  Lr: 0.030000  Loss: 0.1020  Acc@1: 75.0000 (74.0591)  Acc@5: 93.7500 (97.5857)  time: 0.3451  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [1570/3125]  eta: 0:08:56  Lr: 0.030000  Loss: 0.3277  Acc@1: 75.0000 (74.0611)  Acc@5: 100.0000 (97.5732)  time: 0.3458  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1580/3125]  eta: 0:08:53  Lr: 0.030000  Loss: 0.4440  Acc@1: 68.7500 (74.0236)  Acc@5: 100.0000 (97.5767)  time: 0.3467  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1590/3125]  eta: 0:08:49  Lr: 0.030000  Loss: 0.4233  Acc@1: 68.7500 (74.0140)  Acc@5: 100.0000 (97.5723)  time: 0.3461  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1600/3125]  eta: 0:08:46  Lr: 0.030000  Loss: 0.1350  Acc@1: 75.0000 (74.0045)  Acc@5: 100.0000 (97.5562)  time: 0.3453  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1610/3125]  eta: 0:08:42  Lr: 0.030000  Loss: 0.1304  Acc@1: 81.2500 (74.0301)  Acc@5: 100.0000 (97.5714)  time: 0.3454  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1620/3125]  eta: 0:08:39  Lr: 0.030000  Loss: 0.0960  Acc@1: 75.0000 (74.0515)  Acc@5: 100.0000 (97.5748)  time: 0.3460  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1630/3125]  eta: 0:08:36  Lr: 0.030000  Loss: 0.0681  Acc@1: 75.0000 (74.0842)  Acc@5: 100.0000 (97.5820)  time: 0.3471  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1640/3125]  eta: 0:08:32  Lr: 0.030000  Loss: 0.2464  Acc@1: 75.0000 (74.1088)  Acc@5: 100.0000 (97.5815)  time: 0.3460  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1650/3125]  eta: 0:08:29  Lr: 0.030000  Loss: 0.0521  Acc@1: 75.0000 (74.1293)  Acc@5: 100.0000 (97.5886)  time: 0.3449  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [1660/3125]  eta: 0:08:25  Lr: 0.030000  Loss: 0.0235  Acc@1: 75.0000 (74.1120)  Acc@5: 100.0000 (97.5880)  time: 0.3449  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [1670/3125]  eta: 0:08:22  Lr: 0.030000  Loss: 0.0503  Acc@1: 75.0000 (74.1397)  Acc@5: 100.0000 (97.5875)  time: 0.3448  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [1680/3125]  eta: 0:08:18  Lr: 0.030000  Loss: 0.3250  Acc@1: 75.0000 (74.1151)  Acc@5: 100.0000 (97.5796)  time: 0.3446  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [1690/3125]  eta: 0:08:15  Lr: 0.030000  Loss: 0.3213  Acc@1: 75.0000 (74.1240)  Acc@5: 100.0000 (97.5754)  time: 0.3441  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [1700/3125]  eta: 0:08:11  Lr: 0.030000  Loss: 0.2279  Acc@1: 75.0000 (74.1402)  Acc@5: 100.0000 (97.5750)  time: 0.3441  data: 0.0002  max mem: 2500
Train: Epoch[5/5]  [1710/3125]  eta: 0:08:08  Lr: 0.030000  Loss: 0.3397  Acc@1: 75.0000 (74.1416)  Acc@5: 100.0000 (97.5782)  time: 0.3440  data: 0.0002  max mem: 2500
Train: Epoch[5/5]  [1720/3125]  eta: 0:08:04  Lr: 0.030000  Loss: 0.3250  Acc@1: 75.0000 (74.1684)  Acc@5: 100.0000 (97.5850)  time: 0.3448  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [1730/3125]  eta: 0:08:01  Lr: 0.030000  Loss: 0.0319  Acc@1: 75.0000 (74.1551)  Acc@5: 100.0000 (97.5773)  time: 0.3455  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1740/3125]  eta: 0:07:58  Lr: 0.030000  Loss: 0.3487  Acc@1: 75.0000 (74.1707)  Acc@5: 100.0000 (97.5804)  time: 0.3450  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1750/3125]  eta: 0:07:54  Lr: 0.030000  Loss: 0.2219  Acc@1: 75.0000 (74.1862)  Acc@5: 100.0000 (97.5907)  time: 0.3450  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [1760/3125]  eta: 0:07:51  Lr: 0.030000  Loss: 0.1466  Acc@1: 81.2500 (74.1943)  Acc@5: 100.0000 (97.5937)  time: 0.3450  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [1770/3125]  eta: 0:07:47  Lr: 0.030000  Loss: 0.1135  Acc@1: 81.2500 (74.1989)  Acc@5: 100.0000 (97.5896)  time: 0.3449  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [1780/3125]  eta: 0:07:44  Lr: 0.030000  Loss: 0.1743  Acc@1: 81.2500 (74.2385)  Acc@5: 100.0000 (97.5926)  time: 0.3451  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [1790/3125]  eta: 0:07:40  Lr: 0.030000  Loss: 0.3810  Acc@1: 81.2500 (74.2532)  Acc@5: 100.0000 (97.5956)  time: 0.3453  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [1800/3125]  eta: 0:07:37  Lr: 0.030000  Loss: 0.2971  Acc@1: 75.0000 (74.2365)  Acc@5: 100.0000 (97.5951)  time: 0.3451  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [1810/3125]  eta: 0:07:33  Lr: 0.030000  Loss: 0.1658  Acc@1: 75.0000 (74.2580)  Acc@5: 100.0000 (97.6015)  time: 0.3444  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [1820/3125]  eta: 0:07:30  Lr: 0.030000  Loss: 0.3270  Acc@1: 75.0000 (74.2381)  Acc@5: 100.0000 (97.5872)  time: 0.3436  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [1830/3125]  eta: 0:07:26  Lr: 0.030000  Loss: 0.4660  Acc@1: 68.7500 (74.2217)  Acc@5: 93.7500 (97.5867)  time: 0.3437  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [1840/3125]  eta: 0:07:23  Lr: 0.030000  Loss: 0.4390  Acc@1: 75.0000 (74.2463)  Acc@5: 100.0000 (97.5828)  time: 0.3436  data: 0.0002  max mem: 2500
Train: Epoch[5/5]  [1850/3125]  eta: 0:07:20  Lr: 0.030000  Loss: 0.1381  Acc@1: 81.2500 (74.2639)  Acc@5: 100.0000 (97.5891)  time: 0.3446  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [1860/3125]  eta: 0:07:16  Lr: 0.030000  Loss: 0.1687  Acc@1: 75.0000 (74.2712)  Acc@5: 100.0000 (97.5853)  time: 0.3460  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1870/3125]  eta: 0:07:13  Lr: 0.030000  Loss: 0.2471  Acc@1: 75.0000 (74.2885)  Acc@5: 100.0000 (97.5815)  time: 0.3454  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1880/3125]  eta: 0:07:09  Lr: 0.030000  Loss: 0.2036  Acc@1: 75.0000 (74.3022)  Acc@5: 100.0000 (97.5778)  time: 0.3451  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1890/3125]  eta: 0:07:06  Lr: 0.030000  Loss: 0.0001  Acc@1: 75.0000 (74.2960)  Acc@5: 100.0000 (97.5773)  time: 0.3454  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1900/3125]  eta: 0:07:02  Lr: 0.030000  Loss: -0.1114  Acc@1: 68.7500 (74.3030)  Acc@5: 100.0000 (97.5835)  time: 0.3457  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1910/3125]  eta: 0:06:59  Lr: 0.030000  Loss: 0.2367  Acc@1: 75.0000 (74.3034)  Acc@5: 100.0000 (97.5798)  time: 0.3462  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1920/3125]  eta: 0:06:55  Lr: 0.030000  Loss: 0.1702  Acc@1: 75.0000 (74.2972)  Acc@5: 100.0000 (97.5761)  time: 0.3457  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1930/3125]  eta: 0:06:52  Lr: 0.030000  Loss: 0.2753  Acc@1: 75.0000 (74.3106)  Acc@5: 100.0000 (97.5790)  time: 0.3451  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [1940/3125]  eta: 0:06:49  Lr: 0.030000  Loss: 0.1470  Acc@1: 81.2500 (74.3496)  Acc@5: 100.0000 (97.5882)  time: 0.3450  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [1950/3125]  eta: 0:06:45  Lr: 0.030000  Loss: 0.2695  Acc@1: 81.2500 (74.3657)  Acc@5: 100.0000 (97.5814)  time: 0.3451  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [1960/3125]  eta: 0:06:42  Lr: 0.030000  Loss: 0.3667  Acc@1: 75.0000 (74.3243)  Acc@5: 93.7500 (97.5746)  time: 0.3454  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [1970/3125]  eta: 0:06:38  Lr: 0.030000  Loss: 0.3556  Acc@1: 62.5000 (74.3182)  Acc@5: 93.7500 (97.5710)  time: 0.3454  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1980/3125]  eta: 0:06:35  Lr: 0.030000  Loss: 0.4091  Acc@1: 75.0000 (74.3059)  Acc@5: 100.0000 (97.5675)  time: 0.3454  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [1990/3125]  eta: 0:06:31  Lr: 0.030000  Loss: -0.0748  Acc@1: 75.0000 (74.3345)  Acc@5: 100.0000 (97.5703)  time: 0.3454  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [2000/3125]  eta: 0:06:28  Lr: 0.030000  Loss: 0.3325  Acc@1: 75.0000 (74.3378)  Acc@5: 100.0000 (97.5606)  time: 0.3460  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [2010/3125]  eta: 0:06:24  Lr: 0.030000  Loss: 0.4658  Acc@1: 68.7500 (74.3380)  Acc@5: 100.0000 (97.5634)  time: 0.3454  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [2020/3125]  eta: 0:06:21  Lr: 0.030000  Loss: 0.0671  Acc@1: 68.7500 (74.3506)  Acc@5: 100.0000 (97.5693)  time: 0.3441  data: 0.0002  max mem: 2500
Train: Epoch[5/5]  [2030/3125]  eta: 0:06:17  Lr: 0.030000  Loss: 0.6172  Acc@1: 81.2500 (74.3661)  Acc@5: 100.0000 (97.5659)  time: 0.3441  data: 0.0002  max mem: 2500
Train: Epoch[5/5]  [2040/3125]  eta: 0:06:14  Lr: 0.030000  Loss: 0.0106  Acc@1: 75.0000 (74.3845)  Acc@5: 100.0000 (97.5655)  time: 0.3439  data: 0.0002  max mem: 2500
Train: Epoch[5/5]  [2050/3125]  eta: 0:06:11  Lr: 0.030000  Loss: 0.2212  Acc@1: 75.0000 (74.3905)  Acc@5: 100.0000 (97.5683)  time: 0.3440  data: 0.0002  max mem: 2500
Train: Epoch[5/5]  [2060/3125]  eta: 0:06:07  Lr: 0.030000  Loss: 0.2778  Acc@1: 75.0000 (74.3905)  Acc@5: 100.0000 (97.5710)  time: 0.3442  data: 0.0002  max mem: 2500
Train: Epoch[5/5]  [2070/3125]  eta: 0:06:04  Lr: 0.030000  Loss: 0.1097  Acc@1: 75.0000 (74.3632)  Acc@5: 100.0000 (97.5676)  time: 0.3440  data: 0.0002  max mem: 2500
Train: Epoch[5/5]  [2080/3125]  eta: 0:06:00  Lr: 0.030000  Loss: 0.0466  Acc@1: 75.0000 (74.3693)  Acc@5: 100.0000 (97.5673)  time: 0.3444  data: 0.0002  max mem: 2500
Train: Epoch[5/5]  [2090/3125]  eta: 0:05:57  Lr: 0.030000  Loss: -0.0389  Acc@1: 75.0000 (74.3962)  Acc@5: 100.0000 (97.5699)  time: 0.3445  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [2100/3125]  eta: 0:05:53  Lr: 0.030000  Loss: 0.0663  Acc@1: 75.0000 (74.3812)  Acc@5: 100.0000 (97.5726)  time: 0.3461  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [2110/3125]  eta: 0:05:50  Lr: 0.030000  Loss: 0.2968  Acc@1: 75.0000 (74.3842)  Acc@5: 100.0000 (97.5811)  time: 0.3481  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2120/3125]  eta: 0:05:46  Lr: 0.030000  Loss: 0.1946  Acc@1: 75.0000 (74.3930)  Acc@5: 100.0000 (97.5837)  time: 0.3489  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [2130/3125]  eta: 0:05:43  Lr: 0.030000  Loss: 0.3257  Acc@1: 75.0000 (74.3929)  Acc@5: 100.0000 (97.5833)  time: 0.3485  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [2140/3125]  eta: 0:05:40  Lr: 0.030000  Loss: 0.3083  Acc@1: 75.0000 (74.3957)  Acc@5: 100.0000 (97.5946)  time: 0.3472  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [2150/3125]  eta: 0:05:36  Lr: 0.030000  Loss: 0.1915  Acc@1: 75.0000 (74.3898)  Acc@5: 100.0000 (97.5912)  time: 0.3463  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2160/3125]  eta: 0:05:33  Lr: 0.030000  Loss: 0.2360  Acc@1: 75.0000 (74.3984)  Acc@5: 100.0000 (97.5966)  time: 0.3464  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2170/3125]  eta: 0:05:29  Lr: 0.030000  Loss: 0.1614  Acc@1: 75.0000 (74.4041)  Acc@5: 100.0000 (97.5933)  time: 0.3467  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2180/3125]  eta: 0:05:26  Lr: 0.030000  Loss: 0.3190  Acc@1: 68.7500 (74.3810)  Acc@5: 100.0000 (97.5928)  time: 0.3460  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2190/3125]  eta: 0:05:22  Lr: 0.030000  Loss: 0.4249  Acc@1: 68.7500 (74.3696)  Acc@5: 100.0000 (97.5953)  time: 0.3459  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2200/3125]  eta: 0:05:19  Lr: 0.030000  Loss: -0.0342  Acc@1: 75.0000 (74.3895)  Acc@5: 100.0000 (97.5977)  time: 0.3467  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2210/3125]  eta: 0:05:15  Lr: 0.030000  Loss: 0.1717  Acc@1: 81.2500 (74.3979)  Acc@5: 100.0000 (97.5888)  time: 0.3473  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [2220/3125]  eta: 0:05:12  Lr: 0.030000  Loss: 0.3923  Acc@1: 75.0000 (74.3781)  Acc@5: 100.0000 (97.5884)  time: 0.3471  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2230/3125]  eta: 0:05:09  Lr: 0.030000  Loss: 0.0200  Acc@1: 75.0000 (74.4005)  Acc@5: 100.0000 (97.5880)  time: 0.3462  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2240/3125]  eta: 0:05:05  Lr: 0.030000  Loss: -0.0745  Acc@1: 75.0000 (74.3948)  Acc@5: 100.0000 (97.5876)  time: 0.3471  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [2250/3125]  eta: 0:05:02  Lr: 0.030000  Loss: 0.1685  Acc@1: 75.0000 (74.4141)  Acc@5: 100.0000 (97.5900)  time: 0.3472  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [2260/3125]  eta: 0:04:58  Lr: 0.030000  Loss: 0.0333  Acc@1: 81.2500 (74.4389)  Acc@5: 100.0000 (97.5923)  time: 0.3456  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2270/3125]  eta: 0:04:55  Lr: 0.030000  Loss: 0.2391  Acc@1: 75.0000 (74.4441)  Acc@5: 100.0000 (97.5947)  time: 0.3449  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [2280/3125]  eta: 0:04:51  Lr: 0.030000  Loss: 0.6550  Acc@1: 75.0000 (74.4547)  Acc@5: 100.0000 (97.5860)  time: 0.3447  data: 0.0002  max mem: 2500
Train: Epoch[5/5]  [2290/3125]  eta: 0:04:48  Lr: 0.030000  Loss: 0.4726  Acc@1: 81.2500 (74.4735)  Acc@5: 100.0000 (97.5911)  time: 0.3454  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [2300/3125]  eta: 0:04:44  Lr: 0.030000  Loss: 0.1110  Acc@1: 75.0000 (74.4595)  Acc@5: 100.0000 (97.5826)  time: 0.3454  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [2310/3125]  eta: 0:04:41  Lr: 0.030000  Loss: 0.0539  Acc@1: 75.0000 (74.4916)  Acc@5: 93.7500 (97.5795)  time: 0.3450  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [2320/3125]  eta: 0:04:37  Lr: 0.030000  Loss: -0.0003  Acc@1: 81.2500 (74.5072)  Acc@5: 100.0000 (97.5819)  time: 0.3448  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [2330/3125]  eta: 0:04:34  Lr: 0.030000  Loss: 0.1125  Acc@1: 75.0000 (74.4825)  Acc@5: 100.0000 (97.5815)  time: 0.3444  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [2340/3125]  eta: 0:04:31  Lr: 0.030000  Loss: 0.2309  Acc@1: 75.0000 (74.5034)  Acc@5: 100.0000 (97.5758)  time: 0.3439  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [2350/3125]  eta: 0:04:27  Lr: 0.030000  Loss: 0.0212  Acc@1: 81.2500 (74.5188)  Acc@5: 100.0000 (97.5782)  time: 0.3437  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [2360/3125]  eta: 0:04:24  Lr: 0.030000  Loss: 0.3494  Acc@1: 75.0000 (74.5341)  Acc@5: 100.0000 (97.5805)  time: 0.3447  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [2370/3125]  eta: 0:04:20  Lr: 0.030000  Loss: 0.0500  Acc@1: 75.0000 (74.5334)  Acc@5: 100.0000 (97.5828)  time: 0.3453  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [2380/3125]  eta: 0:04:17  Lr: 0.030000  Loss: 0.0409  Acc@1: 81.2500 (74.5616)  Acc@5: 100.0000 (97.5903)  time: 0.3447  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2390/3125]  eta: 0:04:13  Lr: 0.030000  Loss: 0.0985  Acc@1: 81.2500 (74.5556)  Acc@5: 100.0000 (97.5951)  time: 0.3445  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [2400/3125]  eta: 0:04:10  Lr: 0.030000  Loss: 0.4116  Acc@1: 68.7500 (74.5393)  Acc@5: 100.0000 (97.6026)  time: 0.3445  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [2410/3125]  eta: 0:04:06  Lr: 0.030000  Loss: 0.2842  Acc@1: 68.7500 (74.5282)  Acc@5: 100.0000 (97.5944)  time: 0.3450  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [2420/3125]  eta: 0:04:03  Lr: 0.030000  Loss: 0.1171  Acc@1: 75.0000 (74.5405)  Acc@5: 100.0000 (97.6017)  time: 0.3453  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [2430/3125]  eta: 0:03:59  Lr: 0.030000  Loss: -0.0127  Acc@1: 81.2500 (74.5398)  Acc@5: 100.0000 (97.6013)  time: 0.3452  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [2440/3125]  eta: 0:03:56  Lr: 0.030000  Loss: 0.6573  Acc@1: 81.2500 (74.5417)  Acc@5: 100.0000 (97.6086)  time: 0.3452  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [2450/3125]  eta: 0:03:53  Lr: 0.030000  Loss: 0.1967  Acc@1: 75.0000 (74.5232)  Acc@5: 100.0000 (97.6081)  time: 0.3448  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [2460/3125]  eta: 0:03:49  Lr: 0.030000  Loss: 0.6302  Acc@1: 68.7500 (74.5302)  Acc@5: 100.0000 (97.6026)  time: 0.3449  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [2470/3125]  eta: 0:03:46  Lr: 0.030000  Loss: 0.3553  Acc@1: 75.0000 (74.5295)  Acc@5: 100.0000 (97.6022)  time: 0.3446  data: 0.0002  max mem: 2500
Train: Epoch[5/5]  [2480/3125]  eta: 0:03:42  Lr: 0.030000  Loss: 0.4466  Acc@1: 75.0000 (74.5062)  Acc@5: 100.0000 (97.5967)  time: 0.3436  data: 0.0002  max mem: 2500
Train: Epoch[5/5]  [2490/3125]  eta: 0:03:39  Lr: 0.030000  Loss: 0.2195  Acc@1: 75.0000 (74.5183)  Acc@5: 100.0000 (97.5963)  time: 0.3433  data: 0.0002  max mem: 2500
Train: Epoch[5/5]  [2500/3125]  eta: 0:03:35  Lr: 0.030000  Loss: -0.0223  Acc@1: 75.0000 (74.5277)  Acc@5: 100.0000 (97.6010)  time: 0.3440  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [2510/3125]  eta: 0:03:32  Lr: 0.030000  Loss: 0.1471  Acc@1: 75.0000 (74.5321)  Acc@5: 100.0000 (97.6006)  time: 0.3447  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [2520/3125]  eta: 0:03:28  Lr: 0.030000  Loss: 0.2454  Acc@1: 75.0000 (74.5290)  Acc@5: 100.0000 (97.6002)  time: 0.3448  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2530/3125]  eta: 0:03:25  Lr: 0.030000  Loss: 0.3102  Acc@1: 75.0000 (74.5555)  Acc@5: 100.0000 (97.6072)  time: 0.3452  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2540/3125]  eta: 0:03:21  Lr: 0.030000  Loss: 0.2937  Acc@1: 75.0000 (74.5573)  Acc@5: 100.0000 (97.6117)  time: 0.3465  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2550/3125]  eta: 0:03:18  Lr: 0.030000  Loss: 0.2774  Acc@1: 81.2500 (74.5884)  Acc@5: 100.0000 (97.6088)  time: 0.3460  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2560/3125]  eta: 0:03:15  Lr: 0.030000  Loss: 0.3037  Acc@1: 81.2500 (74.5900)  Acc@5: 100.0000 (97.6035)  time: 0.3447  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [2570/3125]  eta: 0:03:11  Lr: 0.030000  Loss: 0.1889  Acc@1: 75.0000 (74.5892)  Acc@5: 100.0000 (97.5982)  time: 0.3452  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [2580/3125]  eta: 0:03:08  Lr: 0.030000  Loss: 0.2563  Acc@1: 75.0000 (74.6174)  Acc@5: 100.0000 (97.6051)  time: 0.3455  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [2590/3125]  eta: 0:03:04  Lr: 0.030000  Loss: -0.0141  Acc@1: 75.0000 (74.6285)  Acc@5: 100.0000 (97.5950)  time: 0.3453  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2600/3125]  eta: 0:03:01  Lr: 0.030000  Loss: 0.3880  Acc@1: 75.0000 (74.6275)  Acc@5: 93.7500 (97.5923)  time: 0.3453  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [2610/3125]  eta: 0:02:57  Lr: 0.030000  Loss: 0.4478  Acc@1: 75.0000 (74.6290)  Acc@5: 100.0000 (97.5847)  time: 0.3468  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [2620/3125]  eta: 0:02:54  Lr: 0.030000  Loss: 0.3728  Acc@1: 75.0000 (74.6375)  Acc@5: 100.0000 (97.5820)  time: 0.3458  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [2630/3125]  eta: 0:02:50  Lr: 0.030000  Loss: 0.2667  Acc@1: 75.0000 (74.6365)  Acc@5: 93.7500 (97.5746)  time: 0.3436  data: 0.0002  max mem: 2500
Train: Epoch[5/5]  [2640/3125]  eta: 0:02:47  Lr: 0.030000  Loss: 0.2219  Acc@1: 75.0000 (74.6166)  Acc@5: 93.7500 (97.5719)  time: 0.3437  data: 0.0002  max mem: 2500
Train: Epoch[5/5]  [2650/3125]  eta: 0:02:43  Lr: 0.030000  Loss: 0.2130  Acc@1: 68.7500 (74.5803)  Acc@5: 100.0000 (97.5622)  time: 0.3435  data: 0.0002  max mem: 2500
Train: Epoch[5/5]  [2660/3125]  eta: 0:02:40  Lr: 0.030000  Loss: 0.4966  Acc@1: 68.7500 (74.5702)  Acc@5: 100.0000 (97.5644)  time: 0.3434  data: 0.0002  max mem: 2500
Train: Epoch[5/5]  [2670/3125]  eta: 0:02:37  Lr: 0.030000  Loss: 0.1540  Acc@1: 68.7500 (74.5624)  Acc@5: 100.0000 (97.5688)  time: 0.3435  data: 0.0002  max mem: 2500
Train: Epoch[5/5]  [2680/3125]  eta: 0:02:33  Lr: 0.030000  Loss: 0.2519  Acc@1: 75.0000 (74.5664)  Acc@5: 100.0000 (97.5685)  time: 0.3435  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [2690/3125]  eta: 0:02:30  Lr: 0.030000  Loss: 0.1261  Acc@1: 75.0000 (74.5680)  Acc@5: 100.0000 (97.5706)  time: 0.3437  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [2700/3125]  eta: 0:02:26  Lr: 0.030000  Loss: 0.2498  Acc@1: 75.0000 (74.5673)  Acc@5: 100.0000 (97.5611)  time: 0.3436  data: 0.0002  max mem: 2500
Train: Epoch[5/5]  [2710/3125]  eta: 0:02:23  Lr: 0.030000  Loss: 0.1069  Acc@1: 75.0000 (74.5919)  Acc@5: 100.0000 (97.5609)  time: 0.3440  data: 0.0002  max mem: 2500
Train: Epoch[5/5]  [2720/3125]  eta: 0:02:19  Lr: 0.030000  Loss: 0.1339  Acc@1: 81.2500 (74.6049)  Acc@5: 100.0000 (97.5629)  time: 0.3460  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2730/3125]  eta: 0:02:16  Lr: 0.030000  Loss: 0.0485  Acc@1: 75.0000 (74.5995)  Acc@5: 100.0000 (97.5673)  time: 0.3468  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2740/3125]  eta: 0:02:12  Lr: 0.030000  Loss: 0.3185  Acc@1: 81.2500 (74.6146)  Acc@5: 100.0000 (97.5716)  time: 0.3463  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2750/3125]  eta: 0:02:09  Lr: 0.030000  Loss: 0.3850  Acc@1: 81.2500 (74.6160)  Acc@5: 100.0000 (97.5759)  time: 0.3465  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [2760/3125]  eta: 0:02:05  Lr: 0.030000  Loss: 0.4670  Acc@1: 75.0000 (74.6129)  Acc@5: 100.0000 (97.5824)  time: 0.3465  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [2770/3125]  eta: 0:02:02  Lr: 0.030000  Loss: 0.1623  Acc@1: 75.0000 (74.6233)  Acc@5: 100.0000 (97.5821)  time: 0.3457  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2780/3125]  eta: 0:01:59  Lr: 0.030000  Loss: 0.2132  Acc@1: 75.0000 (74.6269)  Acc@5: 93.7500 (97.5751)  time: 0.3454  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2790/3125]  eta: 0:01:55  Lr: 0.030000  Loss: 0.2206  Acc@1: 75.0000 (74.6372)  Acc@5: 100.0000 (97.5770)  time: 0.3456  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [2800/3125]  eta: 0:01:52  Lr: 0.030000  Loss: -0.0223  Acc@1: 81.2500 (74.6586)  Acc@5: 100.0000 (97.5745)  time: 0.3460  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2810/3125]  eta: 0:01:48  Lr: 0.030000  Loss: 0.2236  Acc@1: 75.0000 (74.6398)  Acc@5: 100.0000 (97.5720)  time: 0.3460  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2820/3125]  eta: 0:01:45  Lr: 0.030000  Loss: 0.0395  Acc@1: 75.0000 (74.6522)  Acc@5: 100.0000 (97.5696)  time: 0.3459  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2830/3125]  eta: 0:01:41  Lr: 0.030000  Loss: 0.0704  Acc@1: 75.0000 (74.6600)  Acc@5: 100.0000 (97.5737)  time: 0.3460  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2840/3125]  eta: 0:01:38  Lr: 0.030000  Loss: 0.0511  Acc@1: 75.0000 (74.6458)  Acc@5: 100.0000 (97.5735)  time: 0.3463  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2850/3125]  eta: 0:01:34  Lr: 0.030000  Loss: 0.3008  Acc@1: 68.7500 (74.6229)  Acc@5: 100.0000 (97.5732)  time: 0.3466  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2860/3125]  eta: 0:01:31  Lr: 0.030000  Loss: 0.2887  Acc@1: 68.7500 (74.6155)  Acc@5: 100.0000 (97.5730)  time: 0.3464  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2870/3125]  eta: 0:01:28  Lr: 0.030000  Loss: 0.2520  Acc@1: 75.0000 (74.6234)  Acc@5: 100.0000 (97.5727)  time: 0.3464  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [2880/3125]  eta: 0:01:24  Lr: 0.030000  Loss: 0.2500  Acc@1: 75.0000 (74.6312)  Acc@5: 100.0000 (97.5725)  time: 0.3462  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [2890/3125]  eta: 0:01:21  Lr: 0.030000  Loss: 0.2467  Acc@1: 75.0000 (74.6368)  Acc@5: 100.0000 (97.5765)  time: 0.3452  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [2900/3125]  eta: 0:01:17  Lr: 0.030000  Loss: 0.3149  Acc@1: 75.0000 (74.6510)  Acc@5: 100.0000 (97.5806)  time: 0.3458  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [2910/3125]  eta: 0:01:14  Lr: 0.030000  Loss: 0.1933  Acc@1: 75.0000 (74.6307)  Acc@5: 100.0000 (97.5739)  time: 0.3461  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [2920/3125]  eta: 0:01:10  Lr: 0.030000  Loss: 0.0742  Acc@1: 75.0000 (74.6470)  Acc@5: 93.7500 (97.5715)  time: 0.3450  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [2930/3125]  eta: 0:01:07  Lr: 0.030000  Loss: 0.0148  Acc@1: 75.0000 (74.6439)  Acc@5: 100.0000 (97.5712)  time: 0.3453  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [2940/3125]  eta: 0:01:03  Lr: 0.030000  Loss: 0.1310  Acc@1: 75.0000 (74.6409)  Acc@5: 100.0000 (97.5752)  time: 0.3446  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [2950/3125]  eta: 0:01:00  Lr: 0.030000  Loss: 0.3350  Acc@1: 75.0000 (74.6527)  Acc@5: 100.0000 (97.5729)  time: 0.3436  data: 0.0002  max mem: 2500
Train: Epoch[5/5]  [2960/3125]  eta: 0:00:56  Lr: 0.030000  Loss: 0.0427  Acc@1: 75.0000 (74.6559)  Acc@5: 100.0000 (97.5705)  time: 0.3436  data: 0.0002  max mem: 2500
Train: Epoch[5/5]  [2970/3125]  eta: 0:00:53  Lr: 0.030000  Loss: 0.1334  Acc@1: 75.0000 (74.6781)  Acc@5: 100.0000 (97.5703)  time: 0.3439  data: 0.0002  max mem: 2500
Train: Epoch[5/5]  [2980/3125]  eta: 0:00:50  Lr: 0.030000  Loss: 0.0856  Acc@1: 81.2500 (74.6708)  Acc@5: 100.0000 (97.5763)  time: 0.3445  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [2990/3125]  eta: 0:00:46  Lr: 0.030000  Loss: 0.2167  Acc@1: 75.0000 (74.6552)  Acc@5: 100.0000 (97.5719)  time: 0.3457  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3000/3125]  eta: 0:00:43  Lr: 0.030000  Loss: 0.2314  Acc@1: 75.0000 (74.6543)  Acc@5: 93.7500 (97.5675)  time: 0.3464  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3010/3125]  eta: 0:00:39  Lr: 0.030000  Loss: 0.1192  Acc@1: 68.7500 (74.6492)  Acc@5: 100.0000 (97.5652)  time: 0.3463  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3020/3125]  eta: 0:00:36  Lr: 0.030000  Loss: 0.2097  Acc@1: 75.0000 (74.6524)  Acc@5: 100.0000 (97.5608)  time: 0.3458  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3030/3125]  eta: 0:00:32  Lr: 0.030000  Loss: 0.5258  Acc@1: 75.0000 (74.6330)  Acc@5: 100.0000 (97.5606)  time: 0.3452  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [3040/3125]  eta: 0:00:29  Lr: 0.030000  Loss: 0.2758  Acc@1: 75.0000 (74.6444)  Acc@5: 100.0000 (97.5604)  time: 0.3447  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [3050/3125]  eta: 0:00:25  Lr: 0.030000  Loss: 0.1659  Acc@1: 75.0000 (74.6415)  Acc@5: 100.0000 (97.5623)  time: 0.3445  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [3060/3125]  eta: 0:00:22  Lr: 0.030000  Loss: -0.0617  Acc@1: 75.0000 (74.6570)  Acc@5: 100.0000 (97.5600)  time: 0.3449  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [3070/3125]  eta: 0:00:18  Lr: 0.030000  Loss: 0.3708  Acc@1: 75.0000 (74.6540)  Acc@5: 100.0000 (97.5680)  time: 0.3454  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [3080/3125]  eta: 0:00:15  Lr: 0.030000  Loss: 0.0989  Acc@1: 75.0000 (74.6491)  Acc@5: 100.0000 (97.5738)  time: 0.3456  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [3090/3125]  eta: 0:00:12  Lr: 0.030000  Loss: 0.2198  Acc@1: 75.0000 (74.6603)  Acc@5: 100.0000 (97.5776)  time: 0.3459  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [3100/3125]  eta: 0:00:08  Lr: 0.030000  Loss: 0.3093  Acc@1: 75.0000 (74.6453)  Acc@5: 100.0000 (97.5814)  time: 0.3447  data: 0.0002  max mem: 2500
Train: Epoch[5/5]  [3110/3125]  eta: 0:00:05  Lr: 0.030000  Loss: 0.5489  Acc@1: 68.7500 (74.6364)  Acc@5: 100.0000 (97.5852)  time: 0.3430  data: 0.0002  max mem: 2500
Train: Epoch[5/5]  [3120/3125]  eta: 0:00:01  Lr: 0.030000  Loss: 0.1600  Acc@1: 75.0000 (74.6375)  Acc@5: 100.0000 (97.5889)  time: 0.3434  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [3124/3125]  eta: 0:00:00  Lr: 0.030000  Loss: 0.1881  Acc@1: 75.0000 (74.6580)  Acc@5: 100.0000 (97.5900)  time: 0.3433  data: 0.0005  max mem: 2500
Train: Epoch[5/5] Total time: 0:17:59 (0.3453 s / it)
{0: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 1: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 2: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 3: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 4: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 5: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 6: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 7: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 8: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 9: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 10: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 11: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 12: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 13: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 14: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 15: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 16: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 17: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 18: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 19: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}}
Averaged stats: Lr: 0.030000  Loss: 0.1881  Acc@1: 75.0000 (74.6580)  Acc@5: 100.0000 (97.5900)
Test: [Task 1]  [   0/1627]  eta: 0:11:21  Loss: 2.5126 (2.5126)  Acc@1: 87.5000 (87.5000)  Acc@5: 93.7500 (93.7500)  time: 0.4187  data: 0.2063  max mem: 2500
Test: [Task 1]  [  10/1627]  eta: 0:06:14  Loss: 2.4349 (2.4199)  Acc@1: 87.5000 (84.0909)  Acc@5: 93.7500 (96.0227)  time: 0.2316  data: 0.0189  max mem: 2500
Test: [Task 1]  [  20/1627]  eta: 0:05:58  Loss: 2.4324 (2.4459)  Acc@1: 81.2500 (83.0357)  Acc@5: 93.7500 (95.2381)  time: 0.2132  data: 0.0002  max mem: 2500
Test: [Task 1]  [  30/1627]  eta: 0:05:51  Loss: 2.4842 (2.4571)  Acc@1: 81.2500 (82.6613)  Acc@5: 100.0000 (96.1694)  time: 0.2133  data: 0.0002  max mem: 2500
Test: [Task 1]  [  40/1627]  eta: 0:05:46  Loss: 2.5051 (2.4725)  Acc@1: 81.2500 (81.5549)  Acc@5: 100.0000 (96.0366)  time: 0.2131  data: 0.0002  max mem: 2500
Test: [Task 1]  [  50/1627]  eta: 0:05:42  Loss: 2.4413 (2.4654)  Acc@1: 81.2500 (81.7402)  Acc@5: 100.0000 (96.0784)  time: 0.2131  data: 0.0002  max mem: 2500
Test: [Task 1]  [  60/1627]  eta: 0:05:39  Loss: 2.4418 (2.4694)  Acc@1: 81.2500 (81.5574)  Acc@5: 93.7500 (95.5943)  time: 0.2132  data: 0.0002  max mem: 2500
Test: [Task 1]  [  70/1627]  eta: 0:05:36  Loss: 2.4554 (2.4720)  Acc@1: 81.2500 (81.1620)  Acc@5: 93.7500 (95.9507)  time: 0.2131  data: 0.0002  max mem: 2500
Test: [Task 1]  [  80/1627]  eta: 0:05:33  Loss: 2.4176 (2.4695)  Acc@1: 81.2500 (81.4043)  Acc@5: 100.0000 (96.2963)  time: 0.2131  data: 0.0002  max mem: 2500
Test: [Task 1]  [  90/1627]  eta: 0:05:31  Loss: 2.4323 (2.4701)  Acc@1: 81.2500 (80.9753)  Acc@5: 100.0000 (96.0852)  time: 0.2136  data: 0.0002  max mem: 2500
Test: [Task 1]  [ 100/1627]  eta: 0:05:29  Loss: 2.4924 (2.4785)  Acc@1: 75.0000 (80.4455)  Acc@5: 93.7500 (95.8540)  time: 0.2146  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 110/1627]  eta: 0:05:26  Loss: 2.4729 (2.4782)  Acc@1: 81.2500 (80.5743)  Acc@5: 93.7500 (96.0023)  time: 0.2147  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 120/1627]  eta: 0:05:24  Loss: 2.4378 (2.4785)  Acc@1: 87.5000 (80.5785)  Acc@5: 100.0000 (96.0744)  time: 0.2144  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 130/1627]  eta: 0:05:22  Loss: 2.4438 (2.4751)  Acc@1: 87.5000 (80.7252)  Acc@5: 100.0000 (96.0401)  time: 0.2143  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 140/1627]  eta: 0:05:19  Loss: 2.4429 (2.4737)  Acc@1: 81.2500 (80.7624)  Acc@5: 100.0000 (96.1436)  time: 0.2142  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 150/1627]  eta: 0:05:17  Loss: 2.3393 (2.4658)  Acc@1: 87.5000 (81.0430)  Acc@5: 100.0000 (96.1507)  time: 0.2141  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 160/1627]  eta: 0:05:15  Loss: 2.3532 (2.4654)  Acc@1: 87.5000 (81.1724)  Acc@5: 100.0000 (96.3121)  time: 0.2141  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 170/1627]  eta: 0:05:13  Loss: 2.4277 (2.4628)  Acc@1: 87.5000 (81.3596)  Acc@5: 100.0000 (96.4547)  time: 0.2140  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 180/1627]  eta: 0:05:10  Loss: 2.4277 (2.4647)  Acc@1: 81.2500 (81.2155)  Acc@5: 100.0000 (96.4434)  time: 0.2140  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 190/1627]  eta: 0:05:08  Loss: 2.4591 (2.4632)  Acc@1: 81.2500 (81.2500)  Acc@5: 93.7500 (96.4005)  time: 0.2141  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 200/1627]  eta: 0:05:06  Loss: 2.4596 (2.4624)  Acc@1: 81.2500 (81.1256)  Acc@5: 100.0000 (96.4863)  time: 0.2151  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 210/1627]  eta: 0:05:04  Loss: 2.4437 (2.4602)  Acc@1: 81.2500 (81.2796)  Acc@5: 100.0000 (96.4751)  time: 0.2151  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 220/1627]  eta: 0:05:02  Loss: 2.4087 (2.4608)  Acc@1: 81.2500 (81.1086)  Acc@5: 100.0000 (96.5498)  time: 0.2142  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 230/1627]  eta: 0:05:00  Loss: 2.4383 (2.4606)  Acc@1: 81.2500 (81.2771)  Acc@5: 100.0000 (96.4827)  time: 0.2143  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 240/1627]  eta: 0:04:58  Loss: 2.4047 (2.4598)  Acc@1: 81.2500 (81.3537)  Acc@5: 93.7500 (96.4990)  time: 0.2156  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 250/1627]  eta: 0:04:55  Loss: 2.3868 (2.4577)  Acc@1: 81.2500 (81.2749)  Acc@5: 100.0000 (96.4890)  time: 0.2156  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 260/1627]  eta: 0:04:53  Loss: 2.4136 (2.4588)  Acc@1: 81.2500 (81.2979)  Acc@5: 100.0000 (96.4320)  time: 0.2145  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 270/1627]  eta: 0:04:51  Loss: 2.4249 (2.4560)  Acc@1: 87.5000 (81.4345)  Acc@5: 100.0000 (96.4714)  time: 0.2146  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 280/1627]  eta: 0:04:49  Loss: 2.4239 (2.4564)  Acc@1: 81.2500 (81.3167)  Acc@5: 100.0000 (96.4635)  time: 0.2149  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 290/1627]  eta: 0:04:47  Loss: 2.4239 (2.4558)  Acc@1: 81.2500 (81.3789)  Acc@5: 93.7500 (96.4777)  time: 0.2152  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 300/1627]  eta: 0:04:45  Loss: 2.4292 (2.4554)  Acc@1: 81.2500 (81.3331)  Acc@5: 100.0000 (96.4909)  time: 0.2149  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 310/1627]  eta: 0:04:42  Loss: 2.4535 (2.4544)  Acc@1: 81.2500 (81.3907)  Acc@5: 100.0000 (96.4630)  time: 0.2145  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 320/1627]  eta: 0:04:40  Loss: 2.4509 (2.4555)  Acc@1: 81.2500 (81.3863)  Acc@5: 100.0000 (96.5343)  time: 0.2149  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 330/1627]  eta: 0:04:38  Loss: 2.4209 (2.4559)  Acc@1: 81.2500 (81.3444)  Acc@5: 100.0000 (96.5446)  time: 0.2151  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 340/1627]  eta: 0:04:36  Loss: 2.4481 (2.4576)  Acc@1: 81.2500 (81.3600)  Acc@5: 100.0000 (96.5543)  time: 0.2150  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 350/1627]  eta: 0:04:34  Loss: 2.4751 (2.4577)  Acc@1: 81.2500 (81.3568)  Acc@5: 100.0000 (96.5634)  time: 0.2149  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 360/1627]  eta: 0:04:32  Loss: 2.4751 (2.4594)  Acc@1: 81.2500 (81.2327)  Acc@5: 100.0000 (96.5547)  time: 0.2146  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 370/1627]  eta: 0:04:30  Loss: 2.4163 (2.4577)  Acc@1: 81.2500 (81.3342)  Acc@5: 100.0000 (96.5633)  time: 0.2146  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 380/1627]  eta: 0:04:27  Loss: 2.4105 (2.4574)  Acc@1: 81.2500 (81.3812)  Acc@5: 93.7500 (96.5059)  time: 0.2145  data: 0.0002  max mem: 2500
Test: [Task 1]  [ 390/1627]  eta: 0:04:25  Loss: 2.4341 (2.4575)  Acc@1: 81.2500 (81.2500)  Acc@5: 93.7500 (96.4514)  time: 0.2145  data: 0.0002  max mem: 2500
Test: [Task 1]  [ 400/1627]  eta: 0:04:23  Loss: 2.4480 (2.4567)  Acc@1: 75.0000 (81.2812)  Acc@5: 93.7500 (96.4620)  time: 0.2147  data: 0.0002  max mem: 2500
Test: [Task 1]  [ 410/1627]  eta: 0:04:21  Loss: 2.4071 (2.4563)  Acc@1: 81.2500 (81.3260)  Acc@5: 100.0000 (96.4416)  time: 0.2144  data: 0.0002  max mem: 2500
Test: [Task 1]  [ 420/1627]  eta: 0:04:19  Loss: 2.4206 (2.4557)  Acc@1: 81.2500 (81.3836)  Acc@5: 100.0000 (96.4667)  time: 0.2139  data: 0.0002  max mem: 2500
Test: [Task 1]  [ 430/1627]  eta: 0:04:17  Loss: 2.4032 (2.4543)  Acc@1: 81.2500 (81.4240)  Acc@5: 100.0000 (96.4907)  time: 0.2139  data: 0.0002  max mem: 2500
Test: [Task 1]  [ 440/1627]  eta: 0:04:14  Loss: 2.3840 (2.4537)  Acc@1: 81.2500 (81.4059)  Acc@5: 100.0000 (96.4994)  time: 0.2139  data: 0.0002  max mem: 2500
Test: [Task 1]  [ 450/1627]  eta: 0:04:12  Loss: 2.4329 (2.4552)  Acc@1: 81.2500 (81.3193)  Acc@5: 93.7500 (96.4385)  time: 0.2137  data: 0.0002  max mem: 2500
Test: [Task 1]  [ 460/1627]  eta: 0:04:10  Loss: 2.4374 (2.4553)  Acc@1: 81.2500 (81.3313)  Acc@5: 100.0000 (96.4479)  time: 0.2136  data: 0.0002  max mem: 2500
Test: [Task 1]  [ 470/1627]  eta: 0:04:08  Loss: 2.3902 (2.4544)  Acc@1: 87.5000 (81.3827)  Acc@5: 100.0000 (96.4437)  time: 0.2142  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 480/1627]  eta: 0:04:06  Loss: 2.3677 (2.4547)  Acc@1: 81.2500 (81.2630)  Acc@5: 100.0000 (96.4657)  time: 0.2145  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 490/1627]  eta: 0:04:04  Loss: 2.5082 (2.4555)  Acc@1: 81.2500 (81.2755)  Acc@5: 93.7500 (96.4486)  time: 0.2140  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 500/1627]  eta: 0:04:01  Loss: 2.5003 (2.4561)  Acc@1: 81.2500 (81.2375)  Acc@5: 93.7500 (96.3947)  time: 0.2145  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 510/1627]  eta: 0:03:59  Loss: 2.4660 (2.4574)  Acc@1: 81.2500 (81.1766)  Acc@5: 93.7500 (96.3185)  time: 0.2153  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 520/1627]  eta: 0:03:57  Loss: 2.4538 (2.4581)  Acc@1: 81.2500 (81.1780)  Acc@5: 93.7500 (96.3052)  time: 0.2148  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 530/1627]  eta: 0:03:55  Loss: 2.3895 (2.4559)  Acc@1: 87.5000 (81.2500)  Acc@5: 100.0000 (96.3395)  time: 0.2143  data: 0.0002  max mem: 2500
Test: [Task 1]  [ 540/1627]  eta: 0:03:53  Loss: 2.3841 (2.4566)  Acc@1: 81.2500 (81.2038)  Acc@5: 100.0000 (96.3494)  time: 0.2143  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 550/1627]  eta: 0:03:51  Loss: 2.4845 (2.4578)  Acc@1: 75.0000 (81.1139)  Acc@5: 100.0000 (96.3475)  time: 0.2145  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 560/1627]  eta: 0:03:49  Loss: 2.4627 (2.4585)  Acc@1: 75.0000 (81.0606)  Acc@5: 93.7500 (96.3347)  time: 0.2144  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 570/1627]  eta: 0:03:46  Loss: 2.4061 (2.4571)  Acc@1: 81.2500 (81.1843)  Acc@5: 93.7500 (96.3660)  time: 0.2146  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 580/1627]  eta: 0:03:44  Loss: 2.3787 (2.4566)  Acc@1: 87.5000 (81.2177)  Acc@5: 100.0000 (96.3640)  time: 0.2150  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 590/1627]  eta: 0:03:42  Loss: 2.4212 (2.4565)  Acc@1: 81.2500 (81.2288)  Acc@5: 100.0000 (96.4044)  time: 0.2143  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 600/1627]  eta: 0:03:40  Loss: 2.4350 (2.4564)  Acc@1: 81.2500 (81.2500)  Acc@5: 100.0000 (96.4226)  time: 0.2138  data: 0.0002  max mem: 2500
Test: [Task 1]  [ 610/1627]  eta: 0:03:38  Loss: 2.3802 (2.4548)  Acc@1: 81.2500 (81.3114)  Acc@5: 100.0000 (96.4403)  time: 0.2140  data: 0.0002  max mem: 2500
Test: [Task 1]  [ 620/1627]  eta: 0:03:36  Loss: 2.3802 (2.4554)  Acc@1: 81.2500 (81.2097)  Acc@5: 100.0000 (96.4372)  time: 0.2136  data: 0.0002  max mem: 2500
Test: [Task 1]  [ 630/1627]  eta: 0:03:33  Loss: 2.4806 (2.4555)  Acc@1: 75.0000 (81.2005)  Acc@5: 100.0000 (96.4342)  time: 0.2138  data: 0.0002  max mem: 2500
Test: [Task 1]  [ 640/1627]  eta: 0:03:31  Loss: 2.4205 (2.4551)  Acc@1: 81.2500 (81.2110)  Acc@5: 100.0000 (96.4314)  time: 0.2139  data: 0.0002  max mem: 2500
Test: [Task 1]  [ 650/1627]  eta: 0:03:29  Loss: 2.4801 (2.4548)  Acc@1: 81.2500 (81.1732)  Acc@5: 100.0000 (96.4478)  time: 0.2138  data: 0.0002  max mem: 2500
Test: [Task 1]  [ 660/1627]  eta: 0:03:27  Loss: 2.4515 (2.4540)  Acc@1: 81.2500 (81.1933)  Acc@5: 100.0000 (96.4259)  time: 0.2140  data: 0.0002  max mem: 2500
Test: [Task 1]  [ 670/1627]  eta: 0:03:25  Loss: 2.4242 (2.4542)  Acc@1: 81.2500 (81.1755)  Acc@5: 100.0000 (96.4232)  time: 0.2140  data: 0.0002  max mem: 2500
Test: [Task 1]  [ 680/1627]  eta: 0:03:23  Loss: 2.4305 (2.4536)  Acc@1: 81.2500 (81.1949)  Acc@5: 100.0000 (96.4391)  time: 0.2142  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 690/1627]  eta: 0:03:21  Loss: 2.4074 (2.4521)  Acc@1: 81.2500 (81.2590)  Acc@5: 100.0000 (96.4725)  time: 0.2144  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 700/1627]  eta: 0:03:18  Loss: 2.4074 (2.4524)  Acc@1: 87.5000 (81.3035)  Acc@5: 100.0000 (96.4426)  time: 0.2144  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 710/1627]  eta: 0:03:16  Loss: 2.4062 (2.4517)  Acc@1: 81.2500 (81.3379)  Acc@5: 100.0000 (96.4662)  time: 0.2144  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 720/1627]  eta: 0:03:14  Loss: 2.4042 (2.4515)  Acc@1: 81.2500 (81.3540)  Acc@5: 100.0000 (96.4632)  time: 0.2146  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 730/1627]  eta: 0:03:12  Loss: 2.4063 (2.4522)  Acc@1: 81.2500 (81.3098)  Acc@5: 100.0000 (96.4603)  time: 0.2148  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 740/1627]  eta: 0:03:10  Loss: 2.5025 (2.4528)  Acc@1: 81.2500 (81.2500)  Acc@5: 93.7500 (96.4491)  time: 0.2144  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 750/1627]  eta: 0:03:08  Loss: 2.4755 (2.4526)  Acc@1: 81.2500 (81.2916)  Acc@5: 100.0000 (96.4714)  time: 0.2145  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 760/1627]  eta: 0:03:06  Loss: 2.4295 (2.4529)  Acc@1: 81.2500 (81.2993)  Acc@5: 100.0000 (96.4356)  time: 0.2149  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 770/1627]  eta: 0:03:03  Loss: 2.4295 (2.4522)  Acc@1: 81.2500 (81.3149)  Acc@5: 100.0000 (96.4656)  time: 0.2148  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 780/1627]  eta: 0:03:01  Loss: 2.3639 (2.4509)  Acc@1: 87.5000 (81.4020)  Acc@5: 100.0000 (96.4869)  time: 0.2145  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 790/1627]  eta: 0:02:59  Loss: 2.3472 (2.4515)  Acc@1: 87.5000 (81.3764)  Acc@5: 100.0000 (96.4681)  time: 0.2146  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 800/1627]  eta: 0:02:57  Loss: 2.4363 (2.4514)  Acc@1: 87.5000 (81.4217)  Acc@5: 93.7500 (96.4654)  time: 0.2146  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 810/1627]  eta: 0:02:55  Loss: 2.4113 (2.4513)  Acc@1: 87.5000 (81.4273)  Acc@5: 100.0000 (96.4704)  time: 0.2143  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 820/1627]  eta: 0:02:53  Loss: 2.4162 (2.4510)  Acc@1: 87.5000 (81.4860)  Acc@5: 100.0000 (96.5058)  time: 0.2149  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 830/1627]  eta: 0:02:51  Loss: 2.4284 (2.4517)  Acc@1: 81.2500 (81.4230)  Acc@5: 100.0000 (96.4877)  time: 0.2150  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 840/1627]  eta: 0:02:48  Loss: 2.3809 (2.4506)  Acc@1: 87.5000 (81.4952)  Acc@5: 100.0000 (96.5071)  time: 0.2146  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 850/1627]  eta: 0:02:46  Loss: 2.4268 (2.4509)  Acc@1: 87.5000 (81.4777)  Acc@5: 100.0000 (96.5115)  time: 0.2144  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 860/1627]  eta: 0:02:44  Loss: 2.4649 (2.4511)  Acc@1: 81.2500 (81.5041)  Acc@5: 100.0000 (96.5302)  time: 0.2144  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 870/1627]  eta: 0:02:42  Loss: 2.3700 (2.4499)  Acc@1: 87.5000 (81.5801)  Acc@5: 100.0000 (96.5485)  time: 0.2146  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 880/1627]  eta: 0:02:40  Loss: 2.4060 (2.4510)  Acc@1: 81.2500 (81.5409)  Acc@5: 100.0000 (96.5309)  time: 0.2145  data: 0.0002  max mem: 2500
Test: [Task 1]  [ 890/1627]  eta: 0:02:38  Loss: 2.4927 (2.4514)  Acc@1: 81.2500 (81.5236)  Acc@5: 93.7500 (96.5067)  time: 0.2139  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 900/1627]  eta: 0:02:35  Loss: 2.4495 (2.4521)  Acc@1: 81.2500 (81.5136)  Acc@5: 100.0000 (96.4831)  time: 0.2142  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 910/1627]  eta: 0:02:33  Loss: 2.4717 (2.4528)  Acc@1: 81.2500 (81.4627)  Acc@5: 100.0000 (96.4531)  time: 0.2143  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 920/1627]  eta: 0:02:31  Loss: 2.4587 (2.4526)  Acc@1: 81.2500 (81.4739)  Acc@5: 100.0000 (96.4509)  time: 0.2143  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 930/1627]  eta: 0:02:29  Loss: 2.4029 (2.4519)  Acc@1: 81.2500 (81.5118)  Acc@5: 93.7500 (96.4487)  time: 0.2138  data: 0.0002  max mem: 2500
Test: [Task 1]  [ 940/1627]  eta: 0:02:27  Loss: 2.3763 (2.4507)  Acc@1: 81.2500 (81.5622)  Acc@5: 100.0000 (96.4865)  time: 0.2132  data: 0.0002  max mem: 2500
Test: [Task 1]  [ 950/1627]  eta: 0:02:25  Loss: 2.3904 (2.4504)  Acc@1: 81.2500 (81.5457)  Acc@5: 100.0000 (96.5037)  time: 0.2135  data: 0.0002  max mem: 2500
Test: [Task 1]  [ 960/1627]  eta: 0:02:23  Loss: 2.4233 (2.4505)  Acc@1: 81.2500 (81.5687)  Acc@5: 100.0000 (96.5075)  time: 0.2132  data: 0.0002  max mem: 2500
Test: [Task 1]  [ 970/1627]  eta: 0:02:20  Loss: 2.4639 (2.4507)  Acc@1: 81.2500 (81.5783)  Acc@5: 100.0000 (96.5049)  time: 0.2133  data: 0.0002  max mem: 2500
Test: [Task 1]  [ 980/1627]  eta: 0:02:18  Loss: 2.3924 (2.4504)  Acc@1: 87.5000 (81.5877)  Acc@5: 93.7500 (96.4959)  time: 0.2134  data: 0.0002  max mem: 2500
Test: [Task 1]  [ 990/1627]  eta: 0:02:16  Loss: 2.4888 (2.4518)  Acc@1: 81.2500 (81.5464)  Acc@5: 93.7500 (96.4682)  time: 0.2138  data: 0.0003  max mem: 2500
Test: [Task 1]  [1000/1627]  eta: 0:02:14  Loss: 2.5366 (2.4520)  Acc@1: 81.2500 (81.5247)  Acc@5: 93.7500 (96.4723)  time: 0.2143  data: 0.0003  max mem: 2500
Test: [Task 1]  [1010/1627]  eta: 0:02:12  Loss: 2.3760 (2.4519)  Acc@1: 81.2500 (81.5467)  Acc@5: 93.7500 (96.4639)  time: 0.2140  data: 0.0004  max mem: 2500
Test: [Task 1]  [1020/1627]  eta: 0:02:10  Loss: 2.4068 (2.4519)  Acc@1: 81.2500 (81.5500)  Acc@5: 100.0000 (96.4863)  time: 0.2140  data: 0.0004  max mem: 2500
Test: [Task 1]  [1030/1627]  eta: 0:02:08  Loss: 2.3885 (2.4514)  Acc@1: 81.2500 (81.5713)  Acc@5: 100.0000 (96.4901)  time: 0.2139  data: 0.0003  max mem: 2500
Test: [Task 1]  [1040/1627]  eta: 0:02:05  Loss: 2.3775 (2.4507)  Acc@1: 81.2500 (81.5802)  Acc@5: 100.0000 (96.4998)  time: 0.2140  data: 0.0004  max mem: 2500
Test: [Task 1]  [1050/1627]  eta: 0:02:03  Loss: 2.4279 (2.4502)  Acc@1: 81.2500 (81.6009)  Acc@5: 100.0000 (96.5212)  time: 0.2142  data: 0.0003  max mem: 2500
Test: [Task 1]  [1060/1627]  eta: 0:02:01  Loss: 2.4648 (2.4507)  Acc@1: 81.2500 (81.5681)  Acc@5: 100.0000 (96.5068)  time: 0.2140  data: 0.0003  max mem: 2500
Test: [Task 1]  [1070/1627]  eta: 0:01:59  Loss: 2.4657 (2.4506)  Acc@1: 81.2500 (81.5768)  Acc@5: 93.7500 (96.4986)  time: 0.2140  data: 0.0003  max mem: 2500
Test: [Task 1]  [1080/1627]  eta: 0:01:57  Loss: 2.3901 (2.4507)  Acc@1: 81.2500 (81.5738)  Acc@5: 100.0000 (96.4963)  time: 0.2139  data: 0.0003  max mem: 2500
Test: [Task 1]  [1090/1627]  eta: 0:01:55  Loss: 2.4094 (2.4510)  Acc@1: 81.2500 (81.5536)  Acc@5: 100.0000 (96.4940)  time: 0.2140  data: 0.0003  max mem: 2500
Test: [Task 1]  [1100/1627]  eta: 0:01:53  Loss: 2.3871 (2.4503)  Acc@1: 81.2500 (81.6076)  Acc@5: 100.0000 (96.5145)  time: 0.2141  data: 0.0003  max mem: 2500
Test: [Task 1]  [1110/1627]  eta: 0:01:50  Loss: 2.3987 (2.4501)  Acc@1: 81.2500 (81.5932)  Acc@5: 100.0000 (96.5347)  time: 0.2140  data: 0.0003  max mem: 2500
Test: [Task 1]  [1120/1627]  eta: 0:01:48  Loss: 2.4701 (2.4507)  Acc@1: 75.0000 (81.5566)  Acc@5: 100.0000 (96.5210)  time: 0.2141  data: 0.0003  max mem: 2500
Test: [Task 1]  [1130/1627]  eta: 0:01:46  Loss: 2.4593 (2.4510)  Acc@1: 75.0000 (81.5429)  Acc@5: 100.0000 (96.5241)  time: 0.2140  data: 0.0002  max mem: 2500
Test: [Task 1]  [1140/1627]  eta: 0:01:44  Loss: 2.4593 (2.4515)  Acc@1: 81.2500 (81.5239)  Acc@5: 100.0000 (96.5217)  time: 0.2140  data: 0.0002  max mem: 2500
Test: [Task 1]  [1150/1627]  eta: 0:01:42  Loss: 2.4871 (2.4516)  Acc@1: 81.2500 (81.5324)  Acc@5: 100.0000 (96.5030)  time: 0.2142  data: 0.0003  max mem: 2500
Test: [Task 1]  [1160/1627]  eta: 0:01:40  Loss: 2.4128 (2.4514)  Acc@1: 81.2500 (81.5676)  Acc@5: 100.0000 (96.5062)  time: 0.2141  data: 0.0003  max mem: 2500
Test: [Task 1]  [1170/1627]  eta: 0:01:37  Loss: 2.3861 (2.4514)  Acc@1: 81.2500 (81.5756)  Acc@5: 100.0000 (96.5201)  time: 0.2137  data: 0.0002  max mem: 2500
Test: [Task 1]  [1180/1627]  eta: 0:01:35  Loss: 2.4596 (2.4516)  Acc@1: 81.2500 (81.5622)  Acc@5: 100.0000 (96.5284)  time: 0.2133  data: 0.0002  max mem: 2500
Test: [Task 1]  [1190/1627]  eta: 0:01:33  Loss: 2.4807 (2.4518)  Acc@1: 81.2500 (81.5491)  Acc@5: 100.0000 (96.5418)  time: 0.2133  data: 0.0002  max mem: 2500
Test: [Task 1]  [1200/1627]  eta: 0:01:31  Loss: 2.4755 (2.4516)  Acc@1: 81.2500 (81.5570)  Acc@5: 100.0000 (96.5341)  time: 0.2135  data: 0.0002  max mem: 2500
Test: [Task 1]  [1210/1627]  eta: 0:01:29  Loss: 2.4574 (2.4526)  Acc@1: 81.2500 (81.5184)  Acc@5: 93.7500 (96.5060)  time: 0.2134  data: 0.0002  max mem: 2500
Test: [Task 1]  [1220/1627]  eta: 0:01:27  Loss: 2.4799 (2.4525)  Acc@1: 81.2500 (81.5162)  Acc@5: 93.7500 (96.5090)  time: 0.2134  data: 0.0002  max mem: 2500
Test: [Task 1]  [1230/1627]  eta: 0:01:25  Loss: 2.4799 (2.4530)  Acc@1: 81.2500 (81.4734)  Acc@5: 93.7500 (96.5018)  time: 0.2134  data: 0.0002  max mem: 2500
Test: [Task 1]  [1240/1627]  eta: 0:01:22  Loss: 2.4493 (2.4530)  Acc@1: 81.2500 (81.4565)  Acc@5: 100.0000 (96.5099)  time: 0.2134  data: 0.0002  max mem: 2500
Test: [Task 1]  [1250/1627]  eta: 0:01:20  Loss: 2.4493 (2.4532)  Acc@1: 81.2500 (81.4648)  Acc@5: 100.0000 (96.4978)  time: 0.2141  data: 0.0003  max mem: 2500
Test: [Task 1]  [1260/1627]  eta: 0:01:18  Loss: 2.4314 (2.4532)  Acc@1: 87.5000 (81.4681)  Acc@5: 93.7500 (96.4958)  time: 0.2148  data: 0.0004  max mem: 2500
Test: [Task 1]  [1270/1627]  eta: 0:01:16  Loss: 2.4309 (2.4533)  Acc@1: 81.2500 (81.4319)  Acc@5: 100.0000 (96.5136)  time: 0.2144  data: 0.0003  max mem: 2500
Test: [Task 1]  [1280/1627]  eta: 0:01:14  Loss: 2.4309 (2.4529)  Acc@1: 81.2500 (81.4305)  Acc@5: 100.0000 (96.5115)  time: 0.2139  data: 0.0003  max mem: 2500
Test: [Task 1]  [1290/1627]  eta: 0:01:12  Loss: 2.4429 (2.4533)  Acc@1: 81.2500 (81.4194)  Acc@5: 100.0000 (96.5046)  time: 0.2143  data: 0.0003  max mem: 2500
Test: [Task 1]  [1300/1627]  eta: 0:01:10  Loss: 2.4429 (2.4527)  Acc@1: 81.2500 (81.4614)  Acc@5: 93.7500 (96.5075)  time: 0.2147  data: 0.0003  max mem: 2500
Test: [Task 1]  [1310/1627]  eta: 0:01:07  Loss: 2.3444 (2.4522)  Acc@1: 81.2500 (81.4788)  Acc@5: 93.7500 (96.5008)  time: 0.2142  data: 0.0003  max mem: 2500
Test: [Task 1]  [1320/1627]  eta: 0:01:05  Loss: 2.3723 (2.4515)  Acc@1: 81.2500 (81.5102)  Acc@5: 100.0000 (96.5225)  time: 0.2143  data: 0.0003  max mem: 2500
Test: [Task 1]  [1330/1627]  eta: 0:01:03  Loss: 2.4241 (2.4517)  Acc@1: 81.2500 (81.4942)  Acc@5: 100.0000 (96.5111)  time: 0.2147  data: 0.0004  max mem: 2500
Test: [Task 1]  [1340/1627]  eta: 0:01:01  Loss: 2.4641 (2.4520)  Acc@1: 81.2500 (81.4597)  Acc@5: 93.7500 (96.5045)  time: 0.2146  data: 0.0003  max mem: 2500
Test: [Task 1]  [1350/1627]  eta: 0:00:59  Loss: 2.4423 (2.4520)  Acc@1: 81.2500 (81.4906)  Acc@5: 100.0000 (96.5165)  time: 0.2150  data: 0.0003  max mem: 2500
Test: [Task 1]  [1360/1627]  eta: 0:00:57  Loss: 2.4102 (2.4519)  Acc@1: 87.5000 (81.5072)  Acc@5: 100.0000 (96.5145)  time: 0.2155  data: 0.0004  max mem: 2500
Test: [Task 1]  [1370/1627]  eta: 0:00:55  Loss: 2.3771 (2.4516)  Acc@1: 87.5000 (81.5235)  Acc@5: 93.7500 (96.5126)  time: 0.2151  data: 0.0004  max mem: 2500
Test: [Task 1]  [1380/1627]  eta: 0:00:52  Loss: 2.3771 (2.4513)  Acc@1: 87.5000 (81.5306)  Acc@5: 100.0000 (96.5197)  time: 0.2147  data: 0.0003  max mem: 2500
Test: [Task 1]  [1390/1627]  eta: 0:00:50  Loss: 2.4175 (2.4514)  Acc@1: 81.2500 (81.5196)  Acc@5: 100.0000 (96.5088)  time: 0.2146  data: 0.0003  max mem: 2500
Test: [Task 1]  [1400/1627]  eta: 0:00:48  Loss: 2.4182 (2.4516)  Acc@1: 81.2500 (81.4909)  Acc@5: 93.7500 (96.5025)  time: 0.2148  data: 0.0003  max mem: 2500
Test: [Task 1]  [1410/1627]  eta: 0:00:46  Loss: 2.3744 (2.4513)  Acc@1: 81.2500 (81.4715)  Acc@5: 100.0000 (96.5184)  time: 0.2148  data: 0.0003  max mem: 2500
Test: [Task 1]  [1420/1627]  eta: 0:00:44  Loss: 2.4154 (2.4510)  Acc@1: 81.2500 (81.4919)  Acc@5: 100.0000 (96.5209)  time: 0.2152  data: 0.0003  max mem: 2500
Test: [Task 1]  [1430/1627]  eta: 0:00:42  Loss: 2.5056 (2.4519)  Acc@1: 75.0000 (81.4378)  Acc@5: 93.7500 (96.4928)  time: 0.2149  data: 0.0002  max mem: 2500
Test: [Task 1]  [1440/1627]  eta: 0:00:40  Loss: 2.5056 (2.4520)  Acc@1: 75.0000 (81.4148)  Acc@5: 93.7500 (96.4781)  time: 0.2141  data: 0.0002  max mem: 2500
Test: [Task 1]  [1450/1627]  eta: 0:00:37  Loss: 2.5122 (2.4525)  Acc@1: 81.2500 (81.3921)  Acc@5: 100.0000 (96.4809)  time: 0.2140  data: 0.0002  max mem: 2500
Test: [Task 1]  [1460/1627]  eta: 0:00:35  Loss: 2.5119 (2.4525)  Acc@1: 81.2500 (81.3698)  Acc@5: 100.0000 (96.4793)  time: 0.2142  data: 0.0002  max mem: 2500
Test: [Task 1]  [1470/1627]  eta: 0:00:33  Loss: 2.3918 (2.4527)  Acc@1: 81.2500 (81.3605)  Acc@5: 100.0000 (96.4820)  time: 0.2142  data: 0.0002  max mem: 2500
Test: [Task 1]  [1480/1627]  eta: 0:00:31  Loss: 2.3694 (2.4526)  Acc@1: 81.2500 (81.3724)  Acc@5: 100.0000 (96.4889)  time: 0.2139  data: 0.0002  max mem: 2500
Test: [Task 1]  [1490/1627]  eta: 0:00:29  Loss: 2.4132 (2.4529)  Acc@1: 81.2500 (81.3716)  Acc@5: 100.0000 (96.4831)  time: 0.2142  data: 0.0003  max mem: 2500
Test: [Task 1]  [1500/1627]  eta: 0:00:27  Loss: 2.4453 (2.4532)  Acc@1: 81.2500 (81.3666)  Acc@5: 93.7500 (96.4690)  time: 0.2148  data: 0.0003  max mem: 2500
Test: [Task 1]  [1510/1627]  eta: 0:00:25  Loss: 2.4303 (2.4530)  Acc@1: 81.2500 (81.3906)  Acc@5: 93.7500 (96.4593)  time: 0.2149  data: 0.0003  max mem: 2500
Test: [Task 1]  [1520/1627]  eta: 0:00:22  Loss: 2.3964 (2.4525)  Acc@1: 81.2500 (81.4061)  Acc@5: 100.0000 (96.4620)  time: 0.2151  data: 0.0003  max mem: 2500
Test: [Task 1]  [1530/1627]  eta: 0:00:20  Loss: 2.3763 (2.4522)  Acc@1: 87.5000 (81.4337)  Acc@5: 100.0000 (96.4688)  time: 0.2149  data: 0.0003  max mem: 2500
Test: [Task 1]  [1540/1627]  eta: 0:00:18  Loss: 2.3489 (2.4519)  Acc@1: 93.7500 (81.4650)  Acc@5: 100.0000 (96.4836)  time: 0.2143  data: 0.0003  max mem: 2500
Test: [Task 1]  [1550/1627]  eta: 0:00:16  Loss: 2.4004 (2.4519)  Acc@1: 87.5000 (81.4676)  Acc@5: 100.0000 (96.4821)  time: 0.2152  data: 0.0003  max mem: 2500
Test: [Task 1]  [1560/1627]  eta: 0:00:14  Loss: 2.4103 (2.4514)  Acc@1: 81.2500 (81.4862)  Acc@5: 100.0000 (96.4846)  time: 0.2155  data: 0.0003  max mem: 2500
Test: [Task 1]  [1570/1627]  eta: 0:00:12  Loss: 2.4103 (2.4516)  Acc@1: 81.2500 (81.4927)  Acc@5: 100.0000 (96.4911)  time: 0.2148  data: 0.0003  max mem: 2500
Test: [Task 1]  [1580/1627]  eta: 0:00:10  Loss: 2.4116 (2.4513)  Acc@1: 81.2500 (81.4753)  Acc@5: 100.0000 (96.4896)  time: 0.2147  data: 0.0003  max mem: 2500
Test: [Task 1]  [1590/1627]  eta: 0:00:07  Loss: 2.4256 (2.4514)  Acc@1: 75.0000 (81.4661)  Acc@5: 100.0000 (96.4959)  time: 0.2147  data: 0.0003  max mem: 2500
Test: [Task 1]  [1600/1627]  eta: 0:00:05  Loss: 2.4609 (2.4521)  Acc@1: 75.0000 (81.4374)  Acc@5: 93.7500 (96.4788)  time: 0.2149  data: 0.0003  max mem: 2500
Test: [Task 1]  [1610/1627]  eta: 0:00:03  Loss: 2.4488 (2.4517)  Acc@1: 81.2500 (81.4711)  Acc@5: 100.0000 (96.4929)  time: 0.2144  data: 0.0003  max mem: 2500
Test: [Task 1]  [1620/1627]  eta: 0:00:01  Loss: 2.4235 (2.4516)  Acc@1: 87.5000 (81.4852)  Acc@5: 100.0000 (96.4914)  time: 0.2136  data: 0.0002  max mem: 2500
Test: [Task 1]  [1626/1627]  eta: 0:00:00  Loss: 2.4235 (2.4513)  Acc@1: 87.5000 (81.4959)  Acc@5: 100.0000 (96.4966)  time: 0.2134  data: 0.0002  max mem: 2500
Test: [Task 1] Total time: 0:05:49 (0.2145 s / it)
* Acc@1 81.496 Acc@5 96.497 loss 2.451
Test: [Task 2]  [  0/625]  eta: 0:04:32  Loss: 1.8539 (1.8539)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)  time: 0.4355  data: 0.2221  max mem: 2500
Test: [Task 2]  [ 10/625]  eta: 0:02:23  Loss: 2.0367 (2.0633)  Acc@1: 93.7500 (93.7500)  Acc@5: 100.0000 (97.7273)  time: 0.2338  data: 0.0204  max mem: 2500
Test: [Task 2]  [ 20/625]  eta: 0:02:15  Loss: 2.0334 (2.0533)  Acc@1: 93.7500 (94.3452)  Acc@5: 100.0000 (98.8095)  time: 0.2136  data: 0.0002  max mem: 2500
Test: [Task 2]  [ 30/625]  eta: 0:02:11  Loss: 2.0144 (2.0507)  Acc@1: 93.7500 (94.1532)  Acc@5: 100.0000 (98.9919)  time: 0.2133  data: 0.0002  max mem: 2500
Test: [Task 2]  [ 40/625]  eta: 0:02:08  Loss: 2.0529 (2.0598)  Acc@1: 93.7500 (93.4451)  Acc@5: 100.0000 (99.2378)  time: 0.2134  data: 0.0002  max mem: 2500
Test: [Task 2]  [ 50/625]  eta: 0:02:05  Loss: 2.0553 (2.0709)  Acc@1: 93.7500 (92.8922)  Acc@5: 100.0000 (99.1422)  time: 0.2135  data: 0.0002  max mem: 2500
Test: [Task 2]  [ 60/625]  eta: 0:02:02  Loss: 2.0553 (2.0697)  Acc@1: 93.7500 (92.9303)  Acc@5: 100.0000 (99.0779)  time: 0.2132  data: 0.0002  max mem: 2500
Test: [Task 2]  [ 70/625]  eta: 0:02:00  Loss: 2.0429 (2.0730)  Acc@1: 93.7500 (92.6056)  Acc@5: 100.0000 (99.1197)  time: 0.2132  data: 0.0002  max mem: 2500
Test: [Task 2]  [ 80/625]  eta: 0:01:57  Loss: 2.1008 (2.0771)  Acc@1: 87.5000 (92.2840)  Acc@5: 100.0000 (98.7654)  time: 0.2135  data: 0.0002  max mem: 2500
Test: [Task 2]  [ 90/625]  eta: 0:01:55  Loss: 2.1322 (2.0803)  Acc@1: 87.5000 (92.1016)  Acc@5: 100.0000 (98.9011)  time: 0.2135  data: 0.0002  max mem: 2500
Test: [Task 2]  [100/625]  eta: 0:01:53  Loss: 2.1050 (2.0834)  Acc@1: 93.7500 (92.1411)  Acc@5: 100.0000 (98.8243)  time: 0.2132  data: 0.0002  max mem: 2500
Test: [Task 2]  [110/625]  eta: 0:01:50  Loss: 2.0814 (2.0823)  Acc@1: 93.7500 (92.1171)  Acc@5: 100.0000 (98.8176)  time: 0.2134  data: 0.0002  max mem: 2500
Test: [Task 2]  [120/625]  eta: 0:01:48  Loss: 2.0317 (2.0839)  Acc@1: 87.5000 (91.7872)  Acc@5: 100.0000 (98.8636)  time: 0.2140  data: 0.0002  max mem: 2500
Test: [Task 2]  [130/625]  eta: 0:01:46  Loss: 2.1014 (2.0849)  Acc@1: 87.5000 (91.8893)  Acc@5: 100.0000 (98.9027)  time: 0.2147  data: 0.0003  max mem: 2500
Test: [Task 2]  [140/625]  eta: 0:01:44  Loss: 2.1014 (2.0857)  Acc@1: 93.7500 (91.8883)  Acc@5: 100.0000 (98.7589)  time: 0.2148  data: 0.0004  max mem: 2500
Test: [Task 2]  [150/625]  eta: 0:01:42  Loss: 2.0709 (2.0881)  Acc@1: 87.5000 (91.7632)  Acc@5: 100.0000 (98.6755)  time: 0.2150  data: 0.0004  max mem: 2500
Test: [Task 2]  [160/625]  eta: 0:01:40  Loss: 2.0709 (2.0892)  Acc@1: 87.5000 (91.8090)  Acc@5: 100.0000 (98.6801)  time: 0.2150  data: 0.0003  max mem: 2500
Test: [Task 2]  [170/625]  eta: 0:01:37  Loss: 2.0971 (2.0886)  Acc@1: 93.7500 (91.8494)  Acc@5: 100.0000 (98.6477)  time: 0.2148  data: 0.0003  max mem: 2500
Test: [Task 2]  [180/625]  eta: 0:01:35  Loss: 2.0625 (2.0884)  Acc@1: 93.7500 (91.8508)  Acc@5: 100.0000 (98.6878)  time: 0.2151  data: 0.0003  max mem: 2500
Test: [Task 2]  [190/625]  eta: 0:01:33  Loss: 2.0544 (2.0879)  Acc@1: 93.7500 (91.9175)  Acc@5: 100.0000 (98.7238)  time: 0.2151  data: 0.0003  max mem: 2500
Test: [Task 2]  [200/625]  eta: 0:01:31  Loss: 2.0709 (2.0891)  Acc@1: 93.7500 (91.9154)  Acc@5: 100.0000 (98.6940)  time: 0.2148  data: 0.0003  max mem: 2500
Test: [Task 2]  [210/625]  eta: 0:01:29  Loss: 2.0363 (2.0885)  Acc@1: 93.7500 (91.8839)  Acc@5: 100.0000 (98.6374)  time: 0.2145  data: 0.0003  max mem: 2500
Test: [Task 2]  [220/625]  eta: 0:01:27  Loss: 2.0281 (2.0875)  Acc@1: 93.7500 (91.9966)  Acc@5: 100.0000 (98.6425)  time: 0.2148  data: 0.0003  max mem: 2500
Test: [Task 2]  [230/625]  eta: 0:01:24  Loss: 2.0301 (2.0866)  Acc@1: 93.7500 (92.0455)  Acc@5: 100.0000 (98.6742)  time: 0.2152  data: 0.0004  max mem: 2500
Test: [Task 2]  [240/625]  eta: 0:01:22  Loss: 2.0592 (2.0871)  Acc@1: 93.7500 (91.9865)  Acc@5: 100.0000 (98.7033)  time: 0.2149  data: 0.0004  max mem: 2500
Test: [Task 2]  [250/625]  eta: 0:01:20  Loss: 2.0940 (2.0879)  Acc@1: 93.7500 (91.9572)  Acc@5: 100.0000 (98.6305)  time: 0.2145  data: 0.0003  max mem: 2500
Test: [Task 2]  [260/625]  eta: 0:01:18  Loss: 2.0825 (2.0876)  Acc@1: 93.7500 (91.9780)  Acc@5: 100.0000 (98.6351)  time: 0.2150  data: 0.0004  max mem: 2500
Test: [Task 2]  [270/625]  eta: 0:01:16  Loss: 2.0799 (2.0884)  Acc@1: 93.7500 (91.9050)  Acc@5: 100.0000 (98.6162)  time: 0.2155  data: 0.0004  max mem: 2500
Test: [Task 2]  [280/625]  eta: 0:01:14  Loss: 2.0858 (2.0885)  Acc@1: 93.7500 (91.9262)  Acc@5: 100.0000 (98.6210)  time: 0.2151  data: 0.0004  max mem: 2500
Test: [Task 2]  [290/625]  eta: 0:01:12  Loss: 2.0858 (2.0888)  Acc@1: 93.7500 (91.8814)  Acc@5: 100.0000 (98.6254)  time: 0.2145  data: 0.0003  max mem: 2500
Test: [Task 2]  [300/625]  eta: 0:01:09  Loss: 2.0782 (2.0890)  Acc@1: 93.7500 (91.7982)  Acc@5: 100.0000 (98.6296)  time: 0.2149  data: 0.0003  max mem: 2500
Test: [Task 2]  [310/625]  eta: 0:01:07  Loss: 2.0395 (2.0880)  Acc@1: 93.7500 (91.8609)  Acc@5: 100.0000 (98.6133)  time: 0.2148  data: 0.0003  max mem: 2500
Test: [Task 2]  [320/625]  eta: 0:01:05  Loss: 1.9933 (2.0826)  Acc@1: 100.0000 (92.0950)  Acc@5: 100.0000 (98.6565)  time: 0.2153  data: 0.0004  max mem: 2500
Test: [Task 2]  [330/625]  eta: 0:01:03  Loss: 1.9438 (2.0800)  Acc@1: 100.0000 (92.2394)  Acc@5: 100.0000 (98.6782)  time: 0.2158  data: 0.0004  max mem: 2500
Test: [Task 2]  [340/625]  eta: 0:01:01  Loss: 1.9244 (2.0749)  Acc@1: 100.0000 (92.4487)  Acc@5: 100.0000 (98.7170)  time: 0.2152  data: 0.0004  max mem: 2500
Test: [Task 2]  [350/625]  eta: 0:00:59  Loss: 1.9059 (2.0715)  Acc@1: 100.0000 (92.5748)  Acc@5: 100.0000 (98.7358)  time: 0.2147  data: 0.0003  max mem: 2500
Test: [Task 2]  [360/625]  eta: 0:00:56  Loss: 2.0257 (2.0726)  Acc@1: 93.7500 (92.5554)  Acc@5: 100.0000 (98.7015)  time: 0.2148  data: 0.0003  max mem: 2500
Test: [Task 2]  [370/625]  eta: 0:00:54  Loss: 2.0375 (2.0711)  Acc@1: 93.7500 (92.5876)  Acc@5: 100.0000 (98.7365)  time: 0.2149  data: 0.0003  max mem: 2500
Test: [Task 2]  [380/625]  eta: 0:00:52  Loss: 2.0411 (2.0724)  Acc@1: 93.7500 (92.5197)  Acc@5: 100.0000 (98.7205)  time: 0.2144  data: 0.0003  max mem: 2500
Test: [Task 2]  [390/625]  eta: 0:00:50  Loss: 2.0411 (2.0718)  Acc@1: 93.7500 (92.5192)  Acc@5: 100.0000 (98.6093)  time: 0.2141  data: 0.0003  max mem: 2500
Test: [Task 2]  [400/625]  eta: 0:00:48  Loss: 1.9101 (2.0682)  Acc@1: 100.0000 (92.6901)  Acc@5: 100.0000 (98.6284)  time: 0.2144  data: 0.0003  max mem: 2500
Test: [Task 2]  [410/625]  eta: 0:00:46  Loss: 1.9029 (2.0657)  Acc@1: 100.0000 (92.7920)  Acc@5: 100.0000 (98.6466)  time: 0.2145  data: 0.0003  max mem: 2500
Test: [Task 2]  [420/625]  eta: 0:00:44  Loss: 1.9283 (2.0640)  Acc@1: 100.0000 (92.9186)  Acc@5: 100.0000 (98.6639)  time: 0.2143  data: 0.0003  max mem: 2500
Test: [Task 2]  [430/625]  eta: 0:00:41  Loss: 1.9865 (2.0623)  Acc@1: 100.0000 (92.9959)  Acc@5: 100.0000 (98.6804)  time: 0.2142  data: 0.0003  max mem: 2500
Test: [Task 2]  [440/625]  eta: 0:00:39  Loss: 1.9062 (2.0584)  Acc@1: 100.0000 (93.1548)  Acc@5: 100.0000 (98.7103)  time: 0.2140  data: 0.0003  max mem: 2500
Test: [Task 2]  [450/625]  eta: 0:00:37  Loss: 1.8898 (2.0559)  Acc@1: 100.0000 (93.2373)  Acc@5: 100.0000 (98.7389)  time: 0.2139  data: 0.0003  max mem: 2500
Test: [Task 2]  [460/625]  eta: 0:00:35  Loss: 1.9112 (2.0540)  Acc@1: 100.0000 (93.3026)  Acc@5: 100.0000 (98.7663)  time: 0.2140  data: 0.0003  max mem: 2500
Test: [Task 2]  [470/625]  eta: 0:00:33  Loss: 1.9628 (2.0529)  Acc@1: 100.0000 (93.3652)  Acc@5: 100.0000 (98.7659)  time: 0.2141  data: 0.0003  max mem: 2500
Test: [Task 2]  [480/625]  eta: 0:00:31  Loss: 1.9687 (2.0512)  Acc@1: 100.0000 (93.4511)  Acc@5: 100.0000 (98.7916)  time: 0.2147  data: 0.0003  max mem: 2500
Test: [Task 2]  [490/625]  eta: 0:00:29  Loss: 1.9464 (2.0493)  Acc@1: 100.0000 (93.5336)  Acc@5: 100.0000 (98.8162)  time: 0.2143  data: 0.0002  max mem: 2500
Test: [Task 2]  [500/625]  eta: 0:00:26  Loss: 1.9491 (2.0479)  Acc@1: 100.0000 (93.6252)  Acc@5: 100.0000 (98.8398)  time: 0.2136  data: 0.0002  max mem: 2500
Test: [Task 2]  [510/625]  eta: 0:00:24  Loss: 1.9883 (2.0476)  Acc@1: 100.0000 (93.6399)  Acc@5: 100.0000 (98.8503)  time: 0.2137  data: 0.0002  max mem: 2500
Test: [Task 2]  [520/625]  eta: 0:00:22  Loss: 1.9951 (2.0471)  Acc@1: 93.7500 (93.6780)  Acc@5: 100.0000 (98.8604)  time: 0.2135  data: 0.0002  max mem: 2500
Test: [Task 2]  [530/625]  eta: 0:00:20  Loss: 1.9471 (2.0448)  Acc@1: 100.0000 (93.7971)  Acc@5: 100.0000 (98.8818)  time: 0.2134  data: 0.0002  max mem: 2500
Test: [Task 2]  [540/625]  eta: 0:00:18  Loss: 1.9066 (2.0427)  Acc@1: 100.0000 (93.8886)  Acc@5: 100.0000 (98.8909)  time: 0.2135  data: 0.0002  max mem: 2500
Test: [Task 2]  [550/625]  eta: 0:00:16  Loss: 1.9045 (2.0402)  Acc@1: 100.0000 (93.9882)  Acc@5: 100.0000 (98.9111)  time: 0.2137  data: 0.0002  max mem: 2500
Test: [Task 2]  [560/625]  eta: 0:00:13  Loss: 1.8972 (2.0377)  Acc@1: 100.0000 (94.0954)  Acc@5: 100.0000 (98.9305)  time: 0.2134  data: 0.0002  max mem: 2500
Test: [Task 2]  [570/625]  eta: 0:00:11  Loss: 1.9107 (2.0377)  Acc@1: 100.0000 (94.0784)  Acc@5: 100.0000 (98.9492)  time: 0.2132  data: 0.0002  max mem: 2500
Test: [Task 2]  [580/625]  eta: 0:00:09  Loss: 1.9232 (2.0357)  Acc@1: 100.0000 (94.1695)  Acc@5: 100.0000 (98.9673)  time: 0.2136  data: 0.0003  max mem: 2500
Test: [Task 2]  [590/625]  eta: 0:00:07  Loss: 1.9156 (2.0337)  Acc@1: 100.0000 (94.2365)  Acc@5: 100.0000 (98.9848)  time: 0.2140  data: 0.0003  max mem: 2500
Test: [Task 2]  [600/625]  eta: 0:00:05  Loss: 1.9434 (2.0330)  Acc@1: 100.0000 (94.2908)  Acc@5: 100.0000 (99.0017)  time: 0.2138  data: 0.0003  max mem: 2500
Test: [Task 2]  [610/625]  eta: 0:00:03  Loss: 2.0062 (2.0338)  Acc@1: 93.7500 (94.2717)  Acc@5: 100.0000 (99.0078)  time: 0.2140  data: 0.0003  max mem: 2500
Test: [Task 2]  [620/625]  eta: 0:00:01  Loss: 2.0055 (2.0329)  Acc@1: 93.7500 (94.3136)  Acc@5: 100.0000 (99.0238)  time: 0.2142  data: 0.0003  max mem: 2500
Test: [Task 2]  [624/625]  eta: 0:00:00  Loss: 1.9709 (2.0324)  Acc@1: 100.0000 (94.3400)  Acc@5: 100.0000 (99.0300)  time: 0.2140  data: 0.0002  max mem: 2500
Test: [Task 2] Total time: 0:02:14 (0.2148 s / it)
* Acc@1 94.340 Acc@5 99.030 loss 2.032
Test: [Task 3]  [  0/625]  eta: 0:05:04  Loss: 2.3920 (2.3920)  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (100.0000)  time: 0.4874  data: 0.2743  max mem: 2500
Test: [Task 3]  [ 10/625]  eta: 0:02:27  Loss: 2.3246 (2.3390)  Acc@1: 87.5000 (88.0682)  Acc@5: 100.0000 (99.4318)  time: 0.2406  data: 0.0253  max mem: 2500
Test: [Task 3]  [ 20/625]  eta: 0:02:18  Loss: 2.3246 (2.3489)  Acc@1: 87.5000 (87.2024)  Acc@5: 100.0000 (99.4048)  time: 0.2156  data: 0.0004  max mem: 2500
Test: [Task 3]  [ 30/625]  eta: 0:02:13  Loss: 2.3652 (2.3556)  Acc@1: 81.2500 (85.8871)  Acc@5: 100.0000 (99.1935)  time: 0.2147  data: 0.0004  max mem: 2500
Test: [Task 3]  [ 40/625]  eta: 0:02:09  Loss: 2.3238 (2.3422)  Acc@1: 87.5000 (87.0427)  Acc@5: 100.0000 (99.2378)  time: 0.2145  data: 0.0004  max mem: 2500
Test: [Task 3]  [ 50/625]  eta: 0:02:06  Loss: 2.3238 (2.3367)  Acc@1: 87.5000 (87.2549)  Acc@5: 100.0000 (99.1422)  time: 0.2153  data: 0.0005  max mem: 2500
Test: [Task 3]  [ 60/625]  eta: 0:02:04  Loss: 2.3250 (2.3357)  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (99.2828)  time: 0.2154  data: 0.0004  max mem: 2500
Test: [Task 3]  [ 70/625]  eta: 0:02:01  Loss: 2.3245 (2.3300)  Acc@1: 93.7500 (87.6761)  Acc@5: 100.0000 (99.1197)  time: 0.2143  data: 0.0003  max mem: 2500
Test: [Task 3]  [ 80/625]  eta: 0:01:58  Loss: 2.2697 (2.3242)  Acc@1: 93.7500 (88.1944)  Acc@5: 100.0000 (99.1512)  time: 0.2136  data: 0.0003  max mem: 2500
Test: [Task 3]  [ 90/625]  eta: 0:01:56  Loss: 2.2686 (2.3198)  Acc@1: 93.7500 (88.8736)  Acc@5: 100.0000 (99.1071)  time: 0.2139  data: 0.0003  max mem: 2500
Test: [Task 3]  [100/625]  eta: 0:01:54  Loss: 2.2991 (2.3222)  Acc@1: 93.7500 (88.8614)  Acc@5: 100.0000 (99.0718)  time: 0.2142  data: 0.0004  max mem: 2500
Test: [Task 3]  [110/625]  eta: 0:01:51  Loss: 2.3062 (2.3191)  Acc@1: 93.7500 (88.8514)  Acc@5: 100.0000 (99.1554)  time: 0.2143  data: 0.0004  max mem: 2500
Test: [Task 3]  [120/625]  eta: 0:01:49  Loss: 2.2908 (2.3181)  Acc@1: 87.5000 (88.7397)  Acc@5: 100.0000 (99.2252)  time: 0.2141  data: 0.0003  max mem: 2500
Test: [Task 3]  [130/625]  eta: 0:01:47  Loss: 2.3211 (2.3204)  Acc@1: 87.5000 (88.4065)  Acc@5: 100.0000 (99.1889)  time: 0.2139  data: 0.0003  max mem: 2500
Test: [Task 3]  [140/625]  eta: 0:01:44  Loss: 2.3211 (2.3210)  Acc@1: 87.5000 (88.3865)  Acc@5: 100.0000 (99.0691)  time: 0.2140  data: 0.0003  max mem: 2500
Test: [Task 3]  [150/625]  eta: 0:01:42  Loss: 2.3037 (2.3215)  Acc@1: 87.5000 (88.4106)  Acc@5: 100.0000 (99.0066)  time: 0.2139  data: 0.0003  max mem: 2500
Test: [Task 3]  [160/625]  eta: 0:01:40  Loss: 2.3037 (2.3241)  Acc@1: 93.7500 (88.3152)  Acc@5: 100.0000 (98.9130)  time: 0.2142  data: 0.0003  max mem: 2500
Test: [Task 3]  [170/625]  eta: 0:01:38  Loss: 2.2918 (2.3243)  Acc@1: 87.5000 (88.3406)  Acc@5: 100.0000 (98.9401)  time: 0.2144  data: 0.0003  max mem: 2500
Test: [Task 3]  [180/625]  eta: 0:01:36  Loss: 2.3033 (2.3246)  Acc@1: 93.7500 (88.5359)  Acc@5: 100.0000 (98.9641)  time: 0.2142  data: 0.0003  max mem: 2500
Test: [Task 3]  [190/625]  eta: 0:01:33  Loss: 2.3057 (2.3244)  Acc@1: 93.7500 (88.6453)  Acc@5: 100.0000 (98.9856)  time: 0.2142  data: 0.0003  max mem: 2500
Test: [Task 3]  [200/625]  eta: 0:01:31  Loss: 2.3057 (2.3243)  Acc@1: 87.5000 (88.6194)  Acc@5: 100.0000 (98.9428)  time: 0.2143  data: 0.0003  max mem: 2500
Test: [Task 3]  [210/625]  eta: 0:01:29  Loss: 2.2994 (2.3232)  Acc@1: 87.5000 (88.6552)  Acc@5: 100.0000 (98.9929)  time: 0.2142  data: 0.0003  max mem: 2500
Test: [Task 3]  [220/625]  eta: 0:01:27  Loss: 2.3294 (2.3261)  Acc@1: 87.5000 (88.3767)  Acc@5: 100.0000 (98.9819)  time: 0.2143  data: 0.0003  max mem: 2500
Test: [Task 3]  [230/625]  eta: 0:01:25  Loss: 2.3580 (2.3273)  Acc@1: 81.2500 (88.1223)  Acc@5: 100.0000 (98.9177)  time: 0.2140  data: 0.0003  max mem: 2500
Test: [Task 3]  [240/625]  eta: 0:01:22  Loss: 2.3536 (2.3291)  Acc@1: 81.2500 (87.9149)  Acc@5: 100.0000 (98.8589)  time: 0.2134  data: 0.0002  max mem: 2500
Test: [Task 3]  [250/625]  eta: 0:01:20  Loss: 2.2981 (2.3261)  Acc@1: 87.5000 (88.0976)  Acc@5: 100.0000 (98.8795)  time: 0.2132  data: 0.0002  max mem: 2500
Test: [Task 3]  [260/625]  eta: 0:01:18  Loss: 2.2764 (2.3255)  Acc@1: 93.7500 (88.1705)  Acc@5: 100.0000 (98.8266)  time: 0.2134  data: 0.0002  max mem: 2500
Test: [Task 3]  [270/625]  eta: 0:01:16  Loss: 2.2907 (2.3237)  Acc@1: 87.5000 (88.2841)  Acc@5: 100.0000 (98.8699)  time: 0.2133  data: 0.0002  max mem: 2500
Test: [Task 3]  [280/625]  eta: 0:01:14  Loss: 2.3001 (2.3239)  Acc@1: 87.5000 (88.2340)  Acc@5: 100.0000 (98.8434)  time: 0.2131  data: 0.0002  max mem: 2500
Test: [Task 3]  [290/625]  eta: 0:01:12  Loss: 2.3267 (2.3250)  Acc@1: 87.5000 (88.1658)  Acc@5: 100.0000 (98.8402)  time: 0.2132  data: 0.0002  max mem: 2500
Test: [Task 3]  [300/625]  eta: 0:01:09  Loss: 2.3070 (2.3290)  Acc@1: 87.5000 (87.9153)  Acc@5: 100.0000 (98.5465)  time: 0.2135  data: 0.0002  max mem: 2500
Test: [Task 3]  [310/625]  eta: 0:01:07  Loss: 2.3070 (2.3299)  Acc@1: 87.5000 (87.8617)  Acc@5: 100.0000 (98.5732)  time: 0.2136  data: 0.0002  max mem: 2500
Test: [Task 3]  [320/625]  eta: 0:01:05  Loss: 2.3159 (2.3300)  Acc@1: 87.5000 (87.8505)  Acc@5: 100.0000 (98.5592)  time: 0.2134  data: 0.0002  max mem: 2500
Test: [Task 3]  [330/625]  eta: 0:01:03  Loss: 2.3052 (2.3305)  Acc@1: 87.5000 (87.8210)  Acc@5: 100.0000 (98.5650)  time: 0.2132  data: 0.0002  max mem: 2500
Test: [Task 3]  [340/625]  eta: 0:01:01  Loss: 2.3052 (2.3300)  Acc@1: 87.5000 (87.7383)  Acc@5: 100.0000 (98.5887)  time: 0.2133  data: 0.0002  max mem: 2500
Test: [Task 3]  [350/625]  eta: 0:00:59  Loss: 2.2835 (2.3293)  Acc@1: 87.5000 (87.8205)  Acc@5: 100.0000 (98.6289)  time: 0.2135  data: 0.0002  max mem: 2500
Test: [Task 3]  [360/625]  eta: 0:00:56  Loss: 2.3154 (2.3312)  Acc@1: 87.5000 (87.7424)  Acc@5: 100.0000 (98.5803)  time: 0.2132  data: 0.0002  max mem: 2500
Test: [Task 3]  [370/625]  eta: 0:00:54  Loss: 2.3427 (2.3328)  Acc@1: 87.5000 (87.7358)  Acc@5: 100.0000 (98.5681)  time: 0.2135  data: 0.0002  max mem: 2500
Test: [Task 3]  [380/625]  eta: 0:00:52  Loss: 2.3602 (2.3332)  Acc@1: 87.5000 (87.6148)  Acc@5: 100.0000 (98.5728)  time: 0.2143  data: 0.0003  max mem: 2500
Test: [Task 3]  [390/625]  eta: 0:00:50  Loss: 2.3731 (2.3348)  Acc@1: 81.2500 (87.5320)  Acc@5: 100.0000 (98.5454)  time: 0.2151  data: 0.0003  max mem: 2500
Test: [Task 3]  [400/625]  eta: 0:00:48  Loss: 2.3408 (2.3337)  Acc@1: 87.5000 (87.6403)  Acc@5: 100.0000 (98.5661)  time: 0.2149  data: 0.0003  max mem: 2500
Test: [Task 3]  [410/625]  eta: 0:00:46  Loss: 2.3172 (2.3349)  Acc@1: 87.5000 (87.5912)  Acc@5: 100.0000 (98.5554)  time: 0.2148  data: 0.0003  max mem: 2500
Test: [Task 3]  [420/625]  eta: 0:00:44  Loss: 2.3371 (2.3349)  Acc@1: 87.5000 (87.6781)  Acc@5: 100.0000 (98.5748)  time: 0.2146  data: 0.0003  max mem: 2500
Test: [Task 3]  [430/625]  eta: 0:00:41  Loss: 2.3246 (2.3351)  Acc@1: 87.5000 (87.6160)  Acc@5: 100.0000 (98.5934)  time: 0.2145  data: 0.0003  max mem: 2500
Test: [Task 3]  [440/625]  eta: 0:00:39  Loss: 2.3347 (2.3360)  Acc@1: 87.5000 (87.5992)  Acc@5: 100.0000 (98.5544)  time: 0.2154  data: 0.0004  max mem: 2500
Test: [Task 3]  [450/625]  eta: 0:00:37  Loss: 2.3331 (2.3352)  Acc@1: 87.5000 (87.6524)  Acc@5: 100.0000 (98.5726)  time: 0.2156  data: 0.0004  max mem: 2500
Test: [Task 3]  [460/625]  eta: 0:00:35  Loss: 2.3298 (2.3345)  Acc@1: 93.7500 (87.7034)  Acc@5: 100.0000 (98.5900)  time: 0.2147  data: 0.0004  max mem: 2500
Test: [Task 3]  [470/625]  eta: 0:00:33  Loss: 2.3340 (2.3347)  Acc@1: 87.5000 (87.6327)  Acc@5: 100.0000 (98.5934)  time: 0.2144  data: 0.0003  max mem: 2500
Test: [Task 3]  [480/625]  eta: 0:00:31  Loss: 2.3240 (2.3349)  Acc@1: 81.2500 (87.5260)  Acc@5: 100.0000 (98.5967)  time: 0.2151  data: 0.0004  max mem: 2500
Test: [Task 3]  [490/625]  eta: 0:00:28  Loss: 2.3240 (2.3352)  Acc@1: 87.5000 (87.5382)  Acc@5: 100.0000 (98.5871)  time: 0.2154  data: 0.0004  max mem: 2500
Test: [Task 3]  [500/625]  eta: 0:00:26  Loss: 2.3060 (2.3346)  Acc@1: 87.5000 (87.5998)  Acc@5: 100.0000 (98.6028)  time: 0.2150  data: 0.0004  max mem: 2500
Test: [Task 3]  [510/625]  eta: 0:00:24  Loss: 2.3038 (2.3342)  Acc@1: 93.7500 (87.6468)  Acc@5: 100.0000 (98.6057)  time: 0.2154  data: 0.0004  max mem: 2500
Test: [Task 3]  [520/625]  eta: 0:00:22  Loss: 2.3233 (2.3346)  Acc@1: 87.5000 (87.6560)  Acc@5: 100.0000 (98.6324)  time: 0.2158  data: 0.0004  max mem: 2500
Test: [Task 3]  [530/625]  eta: 0:00:20  Loss: 2.3490 (2.3354)  Acc@1: 87.5000 (87.6059)  Acc@5: 100.0000 (98.6347)  time: 0.2151  data: 0.0003  max mem: 2500
Test: [Task 3]  [540/625]  eta: 0:00:18  Loss: 2.3282 (2.3350)  Acc@1: 87.5000 (87.6040)  Acc@5: 100.0000 (98.6599)  time: 0.2148  data: 0.0003  max mem: 2500
Test: [Task 3]  [550/625]  eta: 0:00:16  Loss: 2.3253 (2.3353)  Acc@1: 87.5000 (87.6134)  Acc@5: 100.0000 (98.6615)  time: 0.2152  data: 0.0003  max mem: 2500
Test: [Task 3]  [560/625]  eta: 0:00:13  Loss: 2.3485 (2.3352)  Acc@1: 87.5000 (87.6003)  Acc@5: 100.0000 (98.6631)  time: 0.2157  data: 0.0003  max mem: 2500
Test: [Task 3]  [570/625]  eta: 0:00:11  Loss: 2.3283 (2.3352)  Acc@1: 87.5000 (87.6532)  Acc@5: 100.0000 (98.6756)  time: 0.2163  data: 0.0004  max mem: 2500
Test: [Task 3]  [580/625]  eta: 0:00:09  Loss: 2.3244 (2.3350)  Acc@1: 87.5000 (87.6076)  Acc@5: 100.0000 (98.6876)  time: 0.2161  data: 0.0004  max mem: 2500
Test: [Task 3]  [590/625]  eta: 0:00:07  Loss: 2.3052 (2.3349)  Acc@1: 87.5000 (87.6058)  Acc@5: 100.0000 (98.6992)  time: 0.2157  data: 0.0004  max mem: 2500
Test: [Task 3]  [600/625]  eta: 0:00:05  Loss: 2.2829 (2.3339)  Acc@1: 87.5000 (87.6144)  Acc@5: 100.0000 (98.7209)  time: 0.2157  data: 0.0004  max mem: 2500
Test: [Task 3]  [610/625]  eta: 0:00:03  Loss: 2.2464 (2.3327)  Acc@1: 93.7500 (87.6841)  Acc@5: 100.0000 (98.7418)  time: 0.2155  data: 0.0004  max mem: 2500
Test: [Task 3]  [620/625]  eta: 0:00:01  Loss: 2.2797 (2.3332)  Acc@1: 87.5000 (87.6912)  Acc@5: 100.0000 (98.7118)  time: 0.2185  data: 0.0004  max mem: 2500
Test: [Task 3]  [624/625]  eta: 0:00:00  Loss: 2.2981 (2.3333)  Acc@1: 87.5000 (87.6900)  Acc@5: 100.0000 (98.7200)  time: 0.2181  data: 0.0003  max mem: 2500
Test: [Task 3] Total time: 0:02:14 (0.2153 s / it)
* Acc@1 87.690 Acc@5 98.720 loss 2.333
{0: {0: 26032, 1: 26032, 2: 26032, 3: 26032, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0, 10: 0, 11: 0, 12: 0, 13: 0, 14: 0, 15: 0, 16: 0, 17: 0, 18: 0, 19: 0}, 1: {0: 0, 1: 0, 2: 0, 3: 0, 4: 10000, 5: 10000, 6: 10000, 7: 10000, 8: 0, 9: 0, 10: 0, 11: 0, 12: 0, 13: 0, 14: 0, 15: 0, 16: 0, 17: 0, 18: 0, 19: 0}, 2: {0: 16, 1: 16, 2: 16, 3: 16, 4: 0, 5: 0, 6: 0, 7: 0, 8: 9984, 9: 9984, 10: 9984, 11: 9984, 12: 0, 13: 0, 14: 0, 15: 0, 16: 0, 17: 0, 18: 0, 19: 0}}
[Average accuracy till task3]	Acc@1: 87.8420	Acc@5: 98.0822	Loss: 2.2723	Forgetting: 0.0000	Backward: 0.0000
Train: Epoch[1/5]  [   0/1142]  eta: 0:13:19  Lr: 0.030000  Loss: 2.2761  Acc@1: 6.2500 (6.2500)  Acc@5: 43.7500 (43.7500)  time: 0.6997  data: 0.3405  max mem: 2500
Train: Epoch[1/5]  [  10/1142]  eta: 0:07:07  Lr: 0.030000  Loss: 1.7394  Acc@1: 18.7500 (18.1818)  Acc@5: 62.5000 (56.8182)  time: 0.3774  data: 0.0312  max mem: 2500
Train: Epoch[1/5]  [  20/1142]  eta: 0:06:46  Lr: 0.030000  Loss: 1.2989  Acc@1: 18.7500 (19.3452)  Acc@5: 62.5000 (61.6071)  time: 0.3452  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [  30/1142]  eta: 0:06:37  Lr: 0.030000  Loss: 1.1373  Acc@1: 18.7500 (18.5484)  Acc@5: 62.5000 (62.0968)  time: 0.3460  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [  40/1142]  eta: 0:06:30  Lr: 0.030000  Loss: 0.9945  Acc@1: 18.7500 (19.8171)  Acc@5: 62.5000 (63.7195)  time: 0.3460  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [  50/1142]  eta: 0:06:24  Lr: 0.030000  Loss: 0.9528  Acc@1: 25.0000 (20.3431)  Acc@5: 62.5000 (63.9706)  time: 0.3452  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [  60/1142]  eta: 0:06:20  Lr: 0.030000  Loss: 0.9143  Acc@1: 25.0000 (20.9016)  Acc@5: 68.7500 (64.7541)  time: 0.3456  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [  70/1142]  eta: 0:06:15  Lr: 0.030000  Loss: 0.9198  Acc@1: 18.7500 (20.5106)  Acc@5: 68.7500 (65.6690)  time: 0.3454  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [  80/1142]  eta: 0:06:11  Lr: 0.030000  Loss: 0.8407  Acc@1: 18.7500 (20.6019)  Acc@5: 68.7500 (65.8951)  time: 0.3443  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [  90/1142]  eta: 0:06:07  Lr: 0.030000  Loss: 0.8064  Acc@1: 25.0000 (21.7720)  Acc@5: 68.7500 (66.8956)  time: 0.3437  data: 0.0002  max mem: 2500
Train: Epoch[1/5]  [ 100/1142]  eta: 0:06:03  Lr: 0.030000  Loss: 0.8772  Acc@1: 25.0000 (22.4010)  Acc@5: 68.7500 (67.2649)  time: 0.3438  data: 0.0002  max mem: 2500
Train: Epoch[1/5]  [ 110/1142]  eta: 0:05:59  Lr: 0.030000  Loss: 0.8297  Acc@1: 25.0000 (22.6914)  Acc@5: 68.7500 (67.6239)  time: 0.3437  data: 0.0002  max mem: 2500
Train: Epoch[1/5]  [ 120/1142]  eta: 0:05:55  Lr: 0.030000  Loss: 0.8626  Acc@1: 25.0000 (23.0888)  Acc@5: 68.7500 (67.6653)  time: 0.3437  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [ 130/1142]  eta: 0:05:51  Lr: 0.030000  Loss: 0.7272  Acc@1: 25.0000 (23.5210)  Acc@5: 75.0000 (68.2252)  time: 0.3441  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [ 140/1142]  eta: 0:05:47  Lr: 0.030000  Loss: 0.7735  Acc@1: 25.0000 (23.9805)  Acc@5: 75.0000 (68.9273)  time: 0.3443  data: 0.0002  max mem: 2500
Train: Epoch[1/5]  [ 150/1142]  eta: 0:05:44  Lr: 0.030000  Loss: 0.8561  Acc@1: 37.5000 (24.9586)  Acc@5: 75.0000 (69.2467)  time: 0.3439  data: 0.0002  max mem: 2500
Train: Epoch[1/5]  [ 160/1142]  eta: 0:05:40  Lr: 0.030000  Loss: 0.8438  Acc@1: 37.5000 (25.1941)  Acc@5: 75.0000 (69.8370)  time: 0.3452  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [ 170/1142]  eta: 0:05:37  Lr: 0.030000  Loss: 0.7429  Acc@1: 25.0000 (25.0731)  Acc@5: 81.2500 (70.7237)  time: 0.3463  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 180/1142]  eta: 0:05:33  Lr: 0.030000  Loss: 0.7922  Acc@1: 18.7500 (24.9655)  Acc@5: 81.2500 (71.3052)  time: 0.3465  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 190/1142]  eta: 0:05:30  Lr: 0.030000  Loss: 0.9713  Acc@1: 18.7500 (25.2291)  Acc@5: 81.2500 (71.5641)  time: 0.3470  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 200/1142]  eta: 0:05:26  Lr: 0.030000  Loss: 0.7510  Acc@1: 37.5000 (25.8706)  Acc@5: 75.0000 (72.0149)  time: 0.3461  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 210/1142]  eta: 0:05:23  Lr: 0.030000  Loss: 0.7241  Acc@1: 31.2500 (26.2441)  Acc@5: 81.2500 (72.4230)  time: 0.3454  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 220/1142]  eta: 0:05:19  Lr: 0.030000  Loss: 0.7919  Acc@1: 37.5000 (26.6120)  Acc@5: 81.2500 (72.9638)  time: 0.3462  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 230/1142]  eta: 0:05:16  Lr: 0.030000  Loss: 0.8159  Acc@1: 37.5000 (27.1374)  Acc@5: 81.2500 (73.2955)  time: 0.3472  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 240/1142]  eta: 0:05:12  Lr: 0.030000  Loss: 0.7106  Acc@1: 37.5000 (27.4896)  Acc@5: 75.0000 (73.4699)  time: 0.3465  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 250/1142]  eta: 0:05:09  Lr: 0.030000  Loss: 0.7740  Acc@1: 37.5000 (27.8137)  Acc@5: 81.2500 (73.8297)  time: 0.3459  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 260/1142]  eta: 0:05:05  Lr: 0.030000  Loss: 0.9148  Acc@1: 37.5000 (28.1370)  Acc@5: 81.2500 (74.1619)  time: 0.3464  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 270/1142]  eta: 0:05:02  Lr: 0.030000  Loss: 0.7330  Acc@1: 31.2500 (28.3441)  Acc@5: 81.2500 (74.4926)  time: 0.3463  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 280/1142]  eta: 0:04:58  Lr: 0.030000  Loss: 0.8314  Acc@1: 31.2500 (28.5365)  Acc@5: 81.2500 (74.6664)  time: 0.3461  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 290/1142]  eta: 0:04:55  Lr: 0.030000  Loss: 0.7656  Acc@1: 31.2500 (28.5438)  Acc@5: 81.2500 (74.7208)  time: 0.3461  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [ 300/1142]  eta: 0:04:51  Lr: 0.030000  Loss: 0.8275  Acc@1: 31.2500 (28.8206)  Acc@5: 81.2500 (75.0000)  time: 0.3457  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [ 310/1142]  eta: 0:04:48  Lr: 0.030000  Loss: 0.6791  Acc@1: 37.5000 (29.0193)  Acc@5: 81.2500 (75.3416)  time: 0.3460  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [ 320/1142]  eta: 0:04:44  Lr: 0.030000  Loss: 0.8478  Acc@1: 31.2500 (29.0109)  Acc@5: 81.2500 (75.3894)  time: 0.3469  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [ 330/1142]  eta: 0:04:41  Lr: 0.030000  Loss: 0.7211  Acc@1: 31.2500 (29.1163)  Acc@5: 75.0000 (75.4909)  time: 0.3465  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 340/1142]  eta: 0:04:37  Lr: 0.030000  Loss: 0.7797  Acc@1: 31.2500 (29.4172)  Acc@5: 87.5000 (75.7698)  time: 0.3456  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 350/1142]  eta: 0:04:34  Lr: 0.030000  Loss: 0.7964  Acc@1: 37.5000 (29.6474)  Acc@5: 87.5000 (76.0506)  time: 0.3451  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [ 360/1142]  eta: 0:04:30  Lr: 0.030000  Loss: 0.8235  Acc@1: 37.5000 (29.9688)  Acc@5: 81.2500 (76.1773)  time: 0.3458  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [ 370/1142]  eta: 0:04:27  Lr: 0.030000  Loss: 0.8489  Acc@1: 37.5000 (30.1381)  Acc@5: 81.2500 (76.4151)  time: 0.3457  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [ 380/1142]  eta: 0:04:23  Lr: 0.030000  Loss: 0.8009  Acc@1: 37.5000 (30.3970)  Acc@5: 81.2500 (76.5748)  time: 0.3451  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [ 390/1142]  eta: 0:04:20  Lr: 0.030000  Loss: 0.7318  Acc@1: 37.5000 (30.5946)  Acc@5: 87.5000 (76.8223)  time: 0.3454  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [ 400/1142]  eta: 0:04:17  Lr: 0.030000  Loss: 0.7130  Acc@1: 37.5000 (30.9071)  Acc@5: 87.5000 (76.9638)  time: 0.3469  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [ 410/1142]  eta: 0:04:13  Lr: 0.030000  Loss: 0.7453  Acc@1: 43.7500 (31.1131)  Acc@5: 87.5000 (77.2202)  time: 0.3460  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [ 420/1142]  eta: 0:04:10  Lr: 0.030000  Loss: 0.7461  Acc@1: 31.2500 (31.1758)  Acc@5: 87.5000 (77.3901)  time: 0.3439  data: 0.0002  max mem: 2500
Train: Epoch[1/5]  [ 430/1142]  eta: 0:04:06  Lr: 0.030000  Loss: 0.7569  Acc@1: 31.2500 (31.3080)  Acc@5: 87.5000 (77.5522)  time: 0.3438  data: 0.0002  max mem: 2500
Train: Epoch[1/5]  [ 440/1142]  eta: 0:04:03  Lr: 0.030000  Loss: 0.6732  Acc@1: 37.5000 (31.4342)  Acc@5: 81.2500 (77.6502)  time: 0.3436  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [ 450/1142]  eta: 0:03:59  Lr: 0.030000  Loss: 0.6587  Acc@1: 37.5000 (31.6380)  Acc@5: 81.2500 (77.8963)  time: 0.3437  data: 0.0002  max mem: 2500
Train: Epoch[1/5]  [ 460/1142]  eta: 0:03:56  Lr: 0.030000  Loss: 0.7428  Acc@1: 37.5000 (31.6838)  Acc@5: 87.5000 (77.9962)  time: 0.3437  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [ 470/1142]  eta: 0:03:52  Lr: 0.030000  Loss: 0.6556  Acc@1: 37.5000 (31.8206)  Acc@5: 87.5000 (78.1582)  time: 0.3435  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [ 480/1142]  eta: 0:03:49  Lr: 0.030000  Loss: 0.9120  Acc@1: 37.5000 (31.9906)  Acc@5: 87.5000 (78.2874)  time: 0.3436  data: 0.0002  max mem: 2500
Train: Epoch[1/5]  [ 490/1142]  eta: 0:03:45  Lr: 0.030000  Loss: 0.7192  Acc@1: 37.5000 (32.0647)  Acc@5: 87.5000 (78.3223)  time: 0.3435  data: 0.0002  max mem: 2500
Train: Epoch[1/5]  [ 500/1142]  eta: 0:03:42  Lr: 0.030000  Loss: 0.7099  Acc@1: 37.5000 (32.2730)  Acc@5: 81.2500 (78.3932)  time: 0.3431  data: 0.0002  max mem: 2500
Train: Epoch[1/5]  [ 510/1142]  eta: 0:03:38  Lr: 0.030000  Loss: 0.5879  Acc@1: 43.7500 (32.4976)  Acc@5: 81.2500 (78.5103)  time: 0.3449  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 520/1142]  eta: 0:03:35  Lr: 0.030000  Loss: 0.7497  Acc@1: 37.5000 (32.5696)  Acc@5: 81.2500 (78.5629)  time: 0.3471  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [ 530/1142]  eta: 0:03:31  Lr: 0.030000  Loss: 0.7422  Acc@1: 37.5000 (32.7919)  Acc@5: 87.5000 (78.7312)  time: 0.3468  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 540/1142]  eta: 0:03:28  Lr: 0.030000  Loss: 0.6805  Acc@1: 37.5000 (33.0522)  Acc@5: 87.5000 (78.8817)  time: 0.3462  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 550/1142]  eta: 0:03:24  Lr: 0.030000  Loss: 0.6035  Acc@1: 37.5000 (33.1670)  Acc@5: 87.5000 (79.0268)  time: 0.3464  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 560/1142]  eta: 0:03:21  Lr: 0.030000  Loss: 0.5210  Acc@1: 37.5000 (33.3445)  Acc@5: 87.5000 (79.1332)  time: 0.3461  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 570/1142]  eta: 0:03:17  Lr: 0.030000  Loss: 0.6057  Acc@1: 43.7500 (33.5595)  Acc@5: 87.5000 (79.2360)  time: 0.3461  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 580/1142]  eta: 0:03:14  Lr: 0.030000  Loss: 0.6920  Acc@1: 43.7500 (33.6919)  Acc@5: 87.5000 (79.3782)  time: 0.3468  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [ 590/1142]  eta: 0:03:10  Lr: 0.030000  Loss: 0.7543  Acc@1: 43.7500 (33.7775)  Acc@5: 87.5000 (79.5157)  time: 0.3462  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 600/1142]  eta: 0:03:07  Lr: 0.030000  Loss: 0.5416  Acc@1: 43.7500 (34.0162)  Acc@5: 87.5000 (79.6589)  time: 0.3470  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [ 610/1142]  eta: 0:03:04  Lr: 0.030000  Loss: 0.6876  Acc@1: 43.7500 (34.2574)  Acc@5: 87.5000 (79.8179)  time: 0.3481  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 620/1142]  eta: 0:03:00  Lr: 0.030000  Loss: 0.5698  Acc@1: 50.0000 (34.4002)  Acc@5: 87.5000 (79.9014)  time: 0.3478  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [ 630/1142]  eta: 0:02:57  Lr: 0.030000  Loss: 0.5461  Acc@1: 43.7500 (34.5285)  Acc@5: 87.5000 (80.0515)  time: 0.3474  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [ 640/1142]  eta: 0:02:53  Lr: 0.030000  Loss: 0.5635  Acc@1: 43.7500 (34.6041)  Acc@5: 87.5000 (80.1580)  time: 0.3467  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [ 650/1142]  eta: 0:02:50  Lr: 0.030000  Loss: 0.6025  Acc@1: 43.7500 (34.8502)  Acc@5: 87.5000 (80.2419)  time: 0.3485  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [ 660/1142]  eta: 0:02:46  Lr: 0.030000  Loss: 0.5897  Acc@1: 43.7500 (34.9754)  Acc@5: 81.2500 (80.2950)  time: 0.3504  data: 0.0009  max mem: 2500
Train: Epoch[1/5]  [ 670/1142]  eta: 0:02:43  Lr: 0.030000  Loss: 0.5343  Acc@1: 37.5000 (35.0876)  Acc@5: 87.5000 (80.4024)  time: 0.3497  data: 0.0009  max mem: 2500
Train: Epoch[1/5]  [ 680/1142]  eta: 0:02:39  Lr: 0.030000  Loss: 0.5572  Acc@1: 43.7500 (35.1964)  Acc@5: 87.5000 (80.5066)  time: 0.3487  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [ 690/1142]  eta: 0:02:36  Lr: 0.030000  Loss: 0.5830  Acc@1: 43.7500 (35.2569)  Acc@5: 87.5000 (80.5897)  time: 0.3474  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [ 700/1142]  eta: 0:02:33  Lr: 0.030000  Loss: 0.3487  Acc@1: 37.5000 (35.3691)  Acc@5: 87.5000 (80.6972)  time: 0.3458  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 710/1142]  eta: 0:02:29  Lr: 0.030000  Loss: 0.6211  Acc@1: 43.7500 (35.4782)  Acc@5: 87.5000 (80.8632)  time: 0.3453  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [ 720/1142]  eta: 0:02:26  Lr: 0.030000  Loss: 0.5879  Acc@1: 43.7500 (35.5583)  Acc@5: 87.5000 (80.9553)  time: 0.3458  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [ 730/1142]  eta: 0:02:22  Lr: 0.030000  Loss: 0.6692  Acc@1: 37.5000 (35.6190)  Acc@5: 87.5000 (81.0705)  time: 0.3458  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [ 740/1142]  eta: 0:02:19  Lr: 0.030000  Loss: 0.6553  Acc@1: 43.7500 (35.7372)  Acc@5: 87.5000 (81.1488)  time: 0.3451  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [ 750/1142]  eta: 0:02:15  Lr: 0.030000  Loss: 0.5567  Acc@1: 43.7500 (35.9354)  Acc@5: 87.5000 (81.2750)  time: 0.3454  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [ 760/1142]  eta: 0:02:12  Lr: 0.030000  Loss: 0.5480  Acc@1: 43.7500 (36.0545)  Acc@5: 87.5000 (81.3568)  time: 0.3454  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [ 770/1142]  eta: 0:02:08  Lr: 0.030000  Loss: 0.5553  Acc@1: 43.7500 (36.1787)  Acc@5: 87.5000 (81.4446)  time: 0.3450  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [ 780/1142]  eta: 0:02:05  Lr: 0.030000  Loss: 0.3978  Acc@1: 43.7500 (36.2836)  Acc@5: 87.5000 (81.5461)  time: 0.3447  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [ 790/1142]  eta: 0:02:01  Lr: 0.030000  Loss: 0.5990  Acc@1: 43.7500 (36.4728)  Acc@5: 87.5000 (81.6767)  time: 0.3445  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [ 800/1142]  eta: 0:01:58  Lr: 0.030000  Loss: 0.5255  Acc@1: 43.7500 (36.6417)  Acc@5: 87.5000 (81.7026)  time: 0.3443  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [ 810/1142]  eta: 0:01:54  Lr: 0.030000  Loss: 0.5266  Acc@1: 43.7500 (36.7679)  Acc@5: 87.5000 (81.7586)  time: 0.3443  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [ 820/1142]  eta: 0:01:51  Lr: 0.030000  Loss: 0.5295  Acc@1: 50.0000 (36.9443)  Acc@5: 87.5000 (81.8362)  time: 0.3445  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [ 830/1142]  eta: 0:01:47  Lr: 0.030000  Loss: 0.5763  Acc@1: 43.7500 (37.0563)  Acc@5: 87.5000 (81.8742)  time: 0.3441  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [ 840/1142]  eta: 0:01:44  Lr: 0.030000  Loss: 0.3769  Acc@1: 50.0000 (37.2622)  Acc@5: 87.5000 (81.9634)  time: 0.3442  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [ 850/1142]  eta: 0:01:41  Lr: 0.030000  Loss: 0.3121  Acc@1: 56.2500 (37.4559)  Acc@5: 93.7500 (82.0652)  time: 0.3459  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 860/1142]  eta: 0:01:37  Lr: 0.030000  Loss: 0.5556  Acc@1: 50.0000 (37.5581)  Acc@5: 87.5000 (82.1138)  time: 0.3465  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [ 870/1142]  eta: 0:01:34  Lr: 0.030000  Loss: 0.5238  Acc@1: 43.7500 (37.6937)  Acc@5: 87.5000 (82.2115)  time: 0.3460  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 880/1142]  eta: 0:01:30  Lr: 0.030000  Loss: 0.4470  Acc@1: 43.7500 (37.7341)  Acc@5: 93.7500 (82.2999)  time: 0.3458  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 890/1142]  eta: 0:01:27  Lr: 0.030000  Loss: 0.5552  Acc@1: 43.7500 (37.7806)  Acc@5: 93.7500 (82.3443)  time: 0.3472  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 900/1142]  eta: 0:01:23  Lr: 0.030000  Loss: 0.5134  Acc@1: 43.7500 (37.9370)  Acc@5: 87.5000 (82.4084)  time: 0.3484  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [ 910/1142]  eta: 0:01:20  Lr: 0.030000  Loss: 0.7323  Acc@1: 43.7500 (37.9802)  Acc@5: 87.5000 (82.4712)  time: 0.3484  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [ 920/1142]  eta: 0:01:16  Lr: 0.030000  Loss: 0.5139  Acc@1: 37.5000 (38.1040)  Acc@5: 87.5000 (82.5461)  time: 0.3490  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [ 930/1142]  eta: 0:01:13  Lr: 0.030000  Loss: 0.4748  Acc@1: 50.0000 (38.2385)  Acc@5: 87.5000 (82.5792)  time: 0.3474  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [ 940/1142]  eta: 0:01:09  Lr: 0.030000  Loss: 0.5012  Acc@1: 50.0000 (38.3369)  Acc@5: 87.5000 (82.6382)  time: 0.3457  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 950/1142]  eta: 0:01:06  Lr: 0.030000  Loss: 0.4284  Acc@1: 50.0000 (38.4464)  Acc@5: 87.5000 (82.7287)  time: 0.3458  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 960/1142]  eta: 0:01:03  Lr: 0.030000  Loss: 0.5271  Acc@1: 50.0000 (38.5796)  Acc@5: 87.5000 (82.7849)  time: 0.3467  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [ 970/1142]  eta: 0:00:59  Lr: 0.030000  Loss: 0.5966  Acc@1: 43.7500 (38.7230)  Acc@5: 87.5000 (82.8913)  time: 0.3483  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [ 980/1142]  eta: 0:00:56  Lr: 0.030000  Loss: 0.4492  Acc@1: 43.7500 (38.8124)  Acc@5: 87.5000 (82.9447)  time: 0.3475  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 990/1142]  eta: 0:00:52  Lr: 0.030000  Loss: 0.4351  Acc@1: 43.7500 (38.8875)  Acc@5: 87.5000 (82.9654)  time: 0.3458  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [1000/1142]  eta: 0:00:49  Lr: 0.030000  Loss: 0.4942  Acc@1: 43.7500 (38.9423)  Acc@5: 87.5000 (83.0295)  time: 0.3460  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [1010/1142]  eta: 0:00:45  Lr: 0.030000  Loss: 0.4669  Acc@1: 50.0000 (39.0393)  Acc@5: 87.5000 (83.0428)  time: 0.3456  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [1020/1142]  eta: 0:00:42  Lr: 0.030000  Loss: 0.2881  Acc@1: 50.0000 (39.1405)  Acc@5: 87.5000 (83.0926)  time: 0.3449  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1030/1142]  eta: 0:00:38  Lr: 0.030000  Loss: 0.3421  Acc@1: 50.0000 (39.2641)  Acc@5: 87.5000 (83.1596)  time: 0.3449  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [1040/1142]  eta: 0:00:35  Lr: 0.030000  Loss: 0.6018  Acc@1: 50.0000 (39.3732)  Acc@5: 87.5000 (83.2073)  time: 0.3446  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [1050/1142]  eta: 0:00:31  Lr: 0.030000  Loss: 0.4882  Acc@1: 43.7500 (39.4386)  Acc@5: 87.5000 (83.2362)  time: 0.3438  data: 0.0002  max mem: 2500
Train: Epoch[1/5]  [1060/1142]  eta: 0:00:28  Lr: 0.030000  Loss: 0.4864  Acc@1: 43.7500 (39.5617)  Acc@5: 87.5000 (83.2528)  time: 0.3436  data: 0.0002  max mem: 2500
Train: Epoch[1/5]  [1070/1142]  eta: 0:00:24  Lr: 0.030000  Loss: 0.2497  Acc@1: 50.0000 (39.6534)  Acc@5: 87.5000 (83.2983)  time: 0.3438  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [1080/1142]  eta: 0:00:21  Lr: 0.030000  Loss: 0.5750  Acc@1: 56.2500 (39.8127)  Acc@5: 87.5000 (83.3488)  time: 0.3448  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1090/1142]  eta: 0:00:17  Lr: 0.030000  Loss: 0.4857  Acc@1: 50.0000 (39.8946)  Acc@5: 87.5000 (83.3925)  time: 0.3462  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1100/1142]  eta: 0:00:14  Lr: 0.030000  Loss: 0.4428  Acc@1: 50.0000 (40.0091)  Acc@5: 87.5000 (83.4525)  time: 0.3462  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1110/1142]  eta: 0:00:11  Lr: 0.030000  Loss: 0.2623  Acc@1: 50.0000 (40.1159)  Acc@5: 87.5000 (83.5115)  time: 0.3468  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1120/1142]  eta: 0:00:07  Lr: 0.030000  Loss: 0.4074  Acc@1: 50.0000 (40.2431)  Acc@5: 87.5000 (83.5694)  time: 0.3460  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1130/1142]  eta: 0:00:04  Lr: 0.030000  Loss: 0.3546  Acc@1: 56.2500 (40.3570)  Acc@5: 93.7500 (83.6428)  time: 0.3448  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [1140/1142]  eta: 0:00:00  Lr: 0.030000  Loss: 0.2928  Acc@1: 56.2500 (40.4634)  Acc@5: 87.5000 (83.6876)  time: 0.3450  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [1141/1142]  eta: 0:00:00  Lr: 0.030000  Loss: 0.7574  Acc@1: 50.0000 (40.4599)  Acc@5: 87.5000 (83.6846)  time: 0.3372  data: 0.0003  max mem: 2500
Train: Epoch[1/5] Total time: 0:06:35 (0.3461 s / it)
{0: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 1: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 2: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 3: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 4: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 5: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 6: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 7: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 8: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 9: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 10: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 11: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 12: {0: 0, 1: 0, 2: 0, 3: 18265, 4: 0}, 13: {0: 0, 1: 0, 2: 0, 3: 18265, 4: 0}, 14: {0: 0, 1: 0, 2: 0, 3: 18265, 4: 0}, 15: {0: 0, 1: 0, 2: 0, 3: 18265, 4: 0}, 16: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 17: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 18: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 19: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}}
Averaged stats: Lr: 0.030000  Loss: 0.7574  Acc@1: 50.0000 (40.4599)  Acc@5: 87.5000 (83.6846)
Train: Epoch[2/5]  [   0/1142]  eta: 0:11:49  Lr: 0.030000  Loss: 0.2643  Acc@1: 68.7500 (68.7500)  Acc@5: 93.7500 (93.7500)  time: 0.6208  data: 0.2764  max mem: 2500
Train: Epoch[2/5]  [  10/1142]  eta: 0:06:59  Lr: 0.030000  Loss: 0.2781  Acc@1: 56.2500 (56.2500)  Acc@5: 93.7500 (89.2045)  time: 0.3706  data: 0.0254  max mem: 2500
Train: Epoch[2/5]  [  20/1142]  eta: 0:06:41  Lr: 0.030000  Loss: 0.5515  Acc@1: 50.0000 (51.1905)  Acc@5: 93.7500 (89.2857)  time: 0.3450  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [  30/1142]  eta: 0:06:33  Lr: 0.030000  Loss: 0.4265  Acc@1: 50.0000 (51.8145)  Acc@5: 87.5000 (88.5081)  time: 0.3446  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [  40/1142]  eta: 0:06:27  Lr: 0.030000  Loss: 0.6084  Acc@1: 56.2500 (51.9817)  Acc@5: 87.5000 (88.2622)  time: 0.3454  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [  50/1142]  eta: 0:06:22  Lr: 0.030000  Loss: 0.2689  Acc@1: 56.2500 (52.4510)  Acc@5: 87.5000 (88.7255)  time: 0.3457  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [  60/1142]  eta: 0:06:18  Lr: 0.030000  Loss: 0.4171  Acc@1: 56.2500 (52.5615)  Acc@5: 87.5000 (88.5246)  time: 0.3442  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [  70/1142]  eta: 0:06:13  Lr: 0.030000  Loss: 0.3018  Acc@1: 56.2500 (53.4331)  Acc@5: 87.5000 (88.8204)  time: 0.3428  data: 0.0002  max mem: 2500
Train: Epoch[2/5]  [  80/1142]  eta: 0:06:09  Lr: 0.030000  Loss: 0.3924  Acc@1: 56.2500 (53.1636)  Acc@5: 93.7500 (88.9660)  time: 0.3424  data: 0.0002  max mem: 2500
Train: Epoch[2/5]  [  90/1142]  eta: 0:06:05  Lr: 0.030000  Loss: 0.5083  Acc@1: 50.0000 (52.8159)  Acc@5: 87.5000 (88.8736)  time: 0.3423  data: 0.0002  max mem: 2500
Train: Epoch[2/5]  [ 100/1142]  eta: 0:06:01  Lr: 0.030000  Loss: 0.4346  Acc@1: 50.0000 (52.9084)  Acc@5: 87.5000 (88.9851)  time: 0.3424  data: 0.0002  max mem: 2500
Train: Epoch[2/5]  [ 110/1142]  eta: 0:05:57  Lr: 0.030000  Loss: 0.3764  Acc@1: 50.0000 (52.7590)  Acc@5: 87.5000 (88.7950)  time: 0.3421  data: 0.0002  max mem: 2500
Train: Epoch[2/5]  [ 120/1142]  eta: 0:05:53  Lr: 0.030000  Loss: 0.5453  Acc@1: 56.2500 (53.3574)  Acc@5: 87.5000 (88.3781)  time: 0.3421  data: 0.0002  max mem: 2500
Train: Epoch[2/5]  [ 130/1142]  eta: 0:05:49  Lr: 0.030000  Loss: 0.2302  Acc@1: 62.5000 (53.6260)  Acc@5: 87.5000 (88.2634)  time: 0.3424  data: 0.0002  max mem: 2500
Train: Epoch[2/5]  [ 140/1142]  eta: 0:05:46  Lr: 0.030000  Loss: 0.4688  Acc@1: 56.2500 (53.5904)  Acc@5: 87.5000 (88.2535)  time: 0.3424  data: 0.0002  max mem: 2500
Train: Epoch[2/5]  [ 150/1142]  eta: 0:05:42  Lr: 0.030000  Loss: 0.6678  Acc@1: 56.2500 (53.6424)  Acc@5: 87.5000 (88.4106)  time: 0.3424  data: 0.0002  max mem: 2500
Train: Epoch[2/5]  [ 160/1142]  eta: 0:05:39  Lr: 0.030000  Loss: 0.0740  Acc@1: 56.2500 (54.1149)  Acc@5: 93.7500 (88.7422)  time: 0.3443  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 170/1142]  eta: 0:05:35  Lr: 0.030000  Loss: 0.4359  Acc@1: 56.2500 (54.2398)  Acc@5: 93.7500 (88.7792)  time: 0.3455  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [ 180/1142]  eta: 0:05:32  Lr: 0.030000  Loss: 0.3090  Acc@1: 56.2500 (54.3163)  Acc@5: 87.5000 (88.8812)  time: 0.3453  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 190/1142]  eta: 0:05:28  Lr: 0.030000  Loss: 0.2841  Acc@1: 56.2500 (54.6466)  Acc@5: 87.5000 (88.8416)  time: 0.3455  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 200/1142]  eta: 0:05:25  Lr: 0.030000  Loss: 0.2379  Acc@1: 62.5000 (54.7886)  Acc@5: 87.5000 (88.9614)  time: 0.3446  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 210/1142]  eta: 0:05:21  Lr: 0.030000  Loss: 0.5531  Acc@1: 56.2500 (54.7097)  Acc@5: 93.7500 (88.8626)  time: 0.3442  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [ 220/1142]  eta: 0:05:18  Lr: 0.030000  Loss: 0.5219  Acc@1: 50.0000 (54.4966)  Acc@5: 87.5000 (88.7726)  time: 0.3445  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 230/1142]  eta: 0:05:14  Lr: 0.030000  Loss: 0.2339  Acc@1: 50.0000 (54.5996)  Acc@5: 87.5000 (88.9069)  time: 0.3446  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 240/1142]  eta: 0:05:11  Lr: 0.030000  Loss: 0.4585  Acc@1: 50.0000 (54.2272)  Acc@5: 93.7500 (89.1598)  time: 0.3451  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 250/1142]  eta: 0:05:07  Lr: 0.030000  Loss: 0.1908  Acc@1: 50.0000 (54.1335)  Acc@5: 93.7500 (89.2928)  time: 0.3454  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 260/1142]  eta: 0:05:04  Lr: 0.030000  Loss: 0.4725  Acc@1: 50.0000 (54.0948)  Acc@5: 93.7500 (89.4636)  time: 0.3451  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [ 270/1142]  eta: 0:05:00  Lr: 0.030000  Loss: 0.4070  Acc@1: 50.0000 (54.1052)  Acc@5: 93.7500 (89.5065)  time: 0.3457  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [ 280/1142]  eta: 0:04:57  Lr: 0.030000  Loss: 0.6435  Acc@1: 56.2500 (54.2260)  Acc@5: 87.5000 (89.5240)  time: 0.3458  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 290/1142]  eta: 0:04:54  Lr: 0.030000  Loss: 0.3595  Acc@1: 56.2500 (54.3385)  Acc@5: 93.7500 (89.5833)  time: 0.3451  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 300/1142]  eta: 0:04:50  Lr: 0.030000  Loss: 0.2102  Acc@1: 56.2500 (54.2774)  Acc@5: 93.7500 (89.5556)  time: 0.3450  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 310/1142]  eta: 0:04:47  Lr: 0.030000  Loss: 0.3882  Acc@1: 50.0000 (54.1600)  Acc@5: 93.7500 (89.6101)  time: 0.3444  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 320/1142]  eta: 0:04:43  Lr: 0.030000  Loss: 0.2551  Acc@1: 50.0000 (54.0888)  Acc@5: 87.5000 (89.5249)  time: 0.3441  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [ 330/1142]  eta: 0:04:40  Lr: 0.030000  Loss: 0.2529  Acc@1: 56.2500 (54.0974)  Acc@5: 87.5000 (89.4826)  time: 0.3445  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [ 340/1142]  eta: 0:04:36  Lr: 0.030000  Loss: 0.5159  Acc@1: 50.0000 (54.0872)  Acc@5: 93.7500 (89.4795)  time: 0.3448  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [ 350/1142]  eta: 0:04:33  Lr: 0.030000  Loss: 0.5171  Acc@1: 50.0000 (54.0598)  Acc@5: 93.7500 (89.5299)  time: 0.3446  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [ 360/1142]  eta: 0:04:29  Lr: 0.030000  Loss: 0.4635  Acc@1: 56.2500 (53.9820)  Acc@5: 93.7500 (89.5776)  time: 0.3445  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [ 370/1142]  eta: 0:04:26  Lr: 0.030000  Loss: 0.4902  Acc@1: 56.2500 (54.0431)  Acc@5: 93.7500 (89.6395)  time: 0.3437  data: 0.0002  max mem: 2500
Train: Epoch[2/5]  [ 380/1142]  eta: 0:04:22  Lr: 0.030000  Loss: 0.2526  Acc@1: 50.0000 (53.8058)  Acc@5: 93.7500 (89.6654)  time: 0.3436  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [ 390/1142]  eta: 0:04:19  Lr: 0.030000  Loss: 0.5345  Acc@1: 50.0000 (53.9003)  Acc@5: 93.7500 (89.6739)  time: 0.3441  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [ 400/1142]  eta: 0:04:15  Lr: 0.030000  Loss: 0.2320  Acc@1: 50.0000 (53.8498)  Acc@5: 87.5000 (89.6665)  time: 0.3452  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [ 410/1142]  eta: 0:04:12  Lr: 0.030000  Loss: 0.5667  Acc@1: 50.0000 (53.8321)  Acc@5: 87.5000 (89.6594)  time: 0.3452  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [ 420/1142]  eta: 0:04:09  Lr: 0.030000  Loss: 0.3090  Acc@1: 50.0000 (53.7262)  Acc@5: 93.7500 (89.6823)  time: 0.3444  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [ 430/1142]  eta: 0:04:05  Lr: 0.030000  Loss: 0.4021  Acc@1: 50.0000 (53.7993)  Acc@5: 93.7500 (89.7767)  time: 0.3450  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [ 440/1142]  eta: 0:04:02  Lr: 0.030000  Loss: 0.2844  Acc@1: 56.2500 (53.9116)  Acc@5: 93.7500 (89.7534)  time: 0.3448  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [ 450/1142]  eta: 0:03:58  Lr: 0.030000  Loss: 0.2552  Acc@1: 56.2500 (53.8525)  Acc@5: 87.5000 (89.7450)  time: 0.3460  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [ 460/1142]  eta: 0:03:55  Lr: 0.030000  Loss: 0.3504  Acc@1: 50.0000 (53.7961)  Acc@5: 87.5000 (89.7370)  time: 0.3448  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [ 470/1142]  eta: 0:03:51  Lr: 0.030000  Loss: 0.1085  Acc@1: 50.0000 (53.7818)  Acc@5: 93.7500 (89.8355)  time: 0.3427  data: 0.0002  max mem: 2500
Train: Epoch[2/5]  [ 480/1142]  eta: 0:03:48  Lr: 0.030000  Loss: 0.1940  Acc@1: 50.0000 (53.8332)  Acc@5: 93.7500 (89.9168)  time: 0.3428  data: 0.0002  max mem: 2500
Train: Epoch[2/5]  [ 490/1142]  eta: 0:03:44  Lr: 0.030000  Loss: 0.2507  Acc@1: 56.2500 (53.8824)  Acc@5: 93.7500 (89.9313)  time: 0.3427  data: 0.0002  max mem: 2500
Train: Epoch[2/5]  [ 500/1142]  eta: 0:03:41  Lr: 0.030000  Loss: 0.0914  Acc@1: 56.2500 (53.8922)  Acc@5: 87.5000 (89.9077)  time: 0.3426  data: 0.0002  max mem: 2500
Train: Epoch[2/5]  [ 510/1142]  eta: 0:03:37  Lr: 0.030000  Loss: 0.2684  Acc@1: 56.2500 (53.8772)  Acc@5: 93.7500 (89.8728)  time: 0.3427  data: 0.0002  max mem: 2500
Train: Epoch[2/5]  [ 520/1142]  eta: 0:03:34  Lr: 0.030000  Loss: 0.1437  Acc@1: 56.2500 (53.9467)  Acc@5: 93.7500 (89.8872)  time: 0.3426  data: 0.0002  max mem: 2500
Train: Epoch[2/5]  [ 530/1142]  eta: 0:03:30  Lr: 0.030000  Loss: 0.3954  Acc@1: 50.0000 (53.9666)  Acc@5: 93.7500 (89.9718)  time: 0.3426  data: 0.0002  max mem: 2500
Train: Epoch[2/5]  [ 540/1142]  eta: 0:03:27  Lr: 0.030000  Loss: 0.4310  Acc@1: 50.0000 (53.9395)  Acc@5: 93.7500 (90.0185)  time: 0.3430  data: 0.0002  max mem: 2500
Train: Epoch[2/5]  [ 550/1142]  eta: 0:03:24  Lr: 0.030000  Loss: 0.1256  Acc@1: 50.0000 (54.0041)  Acc@5: 93.7500 (90.0295)  time: 0.3456  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [ 560/1142]  eta: 0:03:20  Lr: 0.030000  Loss: 0.2513  Acc@1: 56.2500 (54.0441)  Acc@5: 93.7500 (90.0512)  time: 0.3459  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 570/1142]  eta: 0:03:17  Lr: 0.030000  Loss: 0.4422  Acc@1: 56.2500 (54.1046)  Acc@5: 87.5000 (90.0613)  time: 0.3442  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 580/1142]  eta: 0:03:13  Lr: 0.030000  Loss: 0.2679  Acc@1: 56.2500 (54.0232)  Acc@5: 93.7500 (90.1033)  time: 0.3449  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [ 590/1142]  eta: 0:03:10  Lr: 0.030000  Loss: 0.1989  Acc@1: 50.0000 (53.9657)  Acc@5: 93.7500 (90.0592)  time: 0.3450  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 600/1142]  eta: 0:03:06  Lr: 0.030000  Loss: 0.4131  Acc@1: 56.2500 (54.0453)  Acc@5: 93.7500 (90.0998)  time: 0.3449  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [ 610/1142]  eta: 0:03:03  Lr: 0.030000  Loss: 0.4685  Acc@1: 56.2500 (54.0712)  Acc@5: 93.7500 (90.0777)  time: 0.3454  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 620/1142]  eta: 0:02:59  Lr: 0.030000  Loss: 0.1190  Acc@1: 50.0000 (54.0157)  Acc@5: 87.5000 (90.0765)  time: 0.3451  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 630/1142]  eta: 0:02:56  Lr: 0.030000  Loss: 0.2010  Acc@1: 50.0000 (54.0313)  Acc@5: 87.5000 (90.0555)  time: 0.3447  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 640/1142]  eta: 0:02:53  Lr: 0.030000  Loss: 0.1217  Acc@1: 56.2500 (54.0464)  Acc@5: 87.5000 (90.0546)  time: 0.3450  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 650/1142]  eta: 0:02:49  Lr: 0.030000  Loss: 0.3020  Acc@1: 56.2500 (54.0803)  Acc@5: 93.7500 (90.0922)  time: 0.3453  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [ 660/1142]  eta: 0:02:46  Lr: 0.030000  Loss: 0.3241  Acc@1: 50.0000 (54.0091)  Acc@5: 87.5000 (90.0624)  time: 0.3454  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 670/1142]  eta: 0:02:42  Lr: 0.030000  Loss: 0.2412  Acc@1: 50.0000 (54.0238)  Acc@5: 93.7500 (90.0615)  time: 0.3452  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 680/1142]  eta: 0:02:39  Lr: 0.030000  Loss: 0.4991  Acc@1: 50.0000 (54.0198)  Acc@5: 87.5000 (90.0789)  time: 0.3452  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 690/1142]  eta: 0:02:35  Lr: 0.030000  Loss: 0.3273  Acc@1: 56.2500 (53.9707)  Acc@5: 87.5000 (90.0145)  time: 0.3461  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 700/1142]  eta: 0:02:32  Lr: 0.030000  Loss: 0.1663  Acc@1: 56.2500 (54.0121)  Acc@5: 87.5000 (90.0232)  time: 0.3462  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [ 710/1142]  eta: 0:02:28  Lr: 0.030000  Loss: 0.5087  Acc@1: 62.5000 (54.1051)  Acc@5: 87.5000 (89.9877)  time: 0.3448  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [ 720/1142]  eta: 0:02:25  Lr: 0.030000  Loss: 0.1431  Acc@1: 56.2500 (54.1696)  Acc@5: 93.7500 (90.0312)  time: 0.3443  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [ 730/1142]  eta: 0:02:22  Lr: 0.030000  Loss: 0.3098  Acc@1: 56.2500 (54.2322)  Acc@5: 87.5000 (90.0222)  time: 0.3454  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [ 740/1142]  eta: 0:02:18  Lr: 0.030000  Loss: 0.4160  Acc@1: 56.2500 (54.3101)  Acc@5: 87.5000 (89.9882)  time: 0.3452  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [ 750/1142]  eta: 0:02:15  Lr: 0.030000  Loss: 0.2972  Acc@1: 56.2500 (54.2360)  Acc@5: 87.5000 (89.9717)  time: 0.3441  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [ 760/1142]  eta: 0:02:11  Lr: 0.030000  Loss: 0.1022  Acc@1: 56.2500 (54.3693)  Acc@5: 93.7500 (90.0214)  time: 0.3450  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [ 770/1142]  eta: 0:02:08  Lr: 0.030000  Loss: 0.5137  Acc@1: 56.2500 (54.3855)  Acc@5: 93.7500 (90.0454)  time: 0.3441  data: 0.0002  max mem: 2500
Train: Epoch[2/5]  [ 780/1142]  eta: 0:02:04  Lr: 0.030000  Loss: 0.3584  Acc@1: 56.2500 (54.4094)  Acc@5: 87.5000 (89.9968)  time: 0.3424  data: 0.0002  max mem: 2500
Train: Epoch[2/5]  [ 790/1142]  eta: 0:02:01  Lr: 0.030000  Loss: 0.4508  Acc@1: 56.2500 (54.3695)  Acc@5: 81.2500 (89.9415)  time: 0.3425  data: 0.0002  max mem: 2500
Train: Epoch[2/5]  [ 800/1142]  eta: 0:01:57  Lr: 0.030000  Loss: 0.1748  Acc@1: 56.2500 (54.3617)  Acc@5: 87.5000 (89.8954)  time: 0.3426  data: 0.0002  max mem: 2500
Train: Epoch[2/5]  [ 810/1142]  eta: 0:01:54  Lr: 0.030000  Loss: 0.3493  Acc@1: 56.2500 (54.3850)  Acc@5: 93.7500 (89.9199)  time: 0.3426  data: 0.0002  max mem: 2500
Train: Epoch[2/5]  [ 820/1142]  eta: 0:01:50  Lr: 0.030000  Loss: 0.4503  Acc@1: 56.2500 (54.4153)  Acc@5: 93.7500 (89.9132)  time: 0.3430  data: 0.0002  max mem: 2500
Train: Epoch[2/5]  [ 830/1142]  eta: 0:01:47  Lr: 0.030000  Loss: 0.4156  Acc@1: 56.2500 (54.4449)  Acc@5: 93.7500 (89.9143)  time: 0.3438  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [ 840/1142]  eta: 0:01:44  Lr: 0.030000  Loss: 0.3924  Acc@1: 56.2500 (54.3847)  Acc@5: 93.7500 (89.9376)  time: 0.3437  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 850/1142]  eta: 0:01:40  Lr: 0.030000  Loss: 0.2287  Acc@1: 56.2500 (54.4727)  Acc@5: 93.7500 (90.0044)  time: 0.3439  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [ 860/1142]  eta: 0:01:37  Lr: 0.030000  Loss: 0.2959  Acc@1: 56.2500 (54.4280)  Acc@5: 93.7500 (89.9826)  time: 0.3440  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 870/1142]  eta: 0:01:33  Lr: 0.030000  Loss: 0.2384  Acc@1: 56.2500 (54.5063)  Acc@5: 87.5000 (90.0187)  time: 0.3438  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 880/1142]  eta: 0:01:30  Lr: 0.030000  Loss: 0.2442  Acc@1: 62.5000 (54.5545)  Acc@5: 93.7500 (90.0114)  time: 0.3441  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 890/1142]  eta: 0:01:26  Lr: 0.030000  Loss: 0.3983  Acc@1: 56.2500 (54.5174)  Acc@5: 87.5000 (90.0042)  time: 0.3447  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 900/1142]  eta: 0:01:23  Lr: 0.030000  Loss: 0.4495  Acc@1: 56.2500 (54.5574)  Acc@5: 87.5000 (89.9972)  time: 0.3490  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [ 910/1142]  eta: 0:01:19  Lr: 0.030000  Loss: 0.1462  Acc@1: 56.2500 (54.5897)  Acc@5: 87.5000 (90.0384)  time: 0.3489  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [ 920/1142]  eta: 0:01:16  Lr: 0.030000  Loss: 0.3033  Acc@1: 56.2500 (54.6417)  Acc@5: 93.7500 (90.0312)  time: 0.3446  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [ 930/1142]  eta: 0:01:13  Lr: 0.030000  Loss: 0.2874  Acc@1: 62.5000 (54.6992)  Acc@5: 87.5000 (90.0242)  time: 0.3444  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [ 940/1142]  eta: 0:01:09  Lr: 0.030000  Loss: 0.2034  Acc@1: 56.2500 (54.6493)  Acc@5: 87.5000 (90.0040)  time: 0.3441  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [ 950/1142]  eta: 0:01:06  Lr: 0.030000  Loss: 0.2920  Acc@1: 50.0000 (54.6596)  Acc@5: 87.5000 (90.0171)  time: 0.3438  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [ 960/1142]  eta: 0:01:02  Lr: 0.030000  Loss: 0.4060  Acc@1: 56.2500 (54.6761)  Acc@5: 93.7500 (90.0104)  time: 0.3437  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [ 970/1142]  eta: 0:00:59  Lr: 0.030000  Loss: 0.3338  Acc@1: 50.0000 (54.6408)  Acc@5: 87.5000 (89.9910)  time: 0.3447  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 980/1142]  eta: 0:00:55  Lr: 0.030000  Loss: 0.1866  Acc@1: 50.0000 (54.6955)  Acc@5: 93.7500 (90.0357)  time: 0.3453  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 990/1142]  eta: 0:00:52  Lr: 0.030000  Loss: 0.4382  Acc@1: 56.2500 (54.6985)  Acc@5: 93.7500 (90.0605)  time: 0.3460  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1000/1142]  eta: 0:00:48  Lr: 0.030000  Loss: 0.1908  Acc@1: 56.2500 (54.7015)  Acc@5: 93.7500 (90.0787)  time: 0.3458  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1010/1142]  eta: 0:00:45  Lr: 0.030000  Loss: 0.2445  Acc@1: 56.2500 (54.7849)  Acc@5: 93.7500 (90.0964)  time: 0.3437  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [1020/1142]  eta: 0:00:42  Lr: 0.030000  Loss: 0.1502  Acc@1: 62.5000 (54.8543)  Acc@5: 93.7500 (90.1200)  time: 0.3437  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [1030/1142]  eta: 0:00:38  Lr: 0.030000  Loss: 0.2793  Acc@1: 62.5000 (54.9224)  Acc@5: 93.7500 (90.1431)  time: 0.3435  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [1040/1142]  eta: 0:00:35  Lr: 0.030000  Loss: 0.3885  Acc@1: 62.5000 (54.9412)  Acc@5: 93.7500 (90.1537)  time: 0.3430  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [1050/1142]  eta: 0:00:31  Lr: 0.030000  Loss: 0.2252  Acc@1: 56.2500 (54.9596)  Acc@5: 93.7500 (90.1760)  time: 0.3437  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [1060/1142]  eta: 0:00:28  Lr: 0.030000  Loss: 0.4499  Acc@1: 56.2500 (54.9599)  Acc@5: 93.7500 (90.1861)  time: 0.3451  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1070/1142]  eta: 0:00:24  Lr: 0.030000  Loss: 0.4583  Acc@1: 56.2500 (54.9545)  Acc@5: 93.7500 (90.1902)  time: 0.3447  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [1080/1142]  eta: 0:00:21  Lr: 0.030000  Loss: -0.0587  Acc@1: 56.2500 (54.9491)  Acc@5: 87.5000 (90.1654)  time: 0.3440  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [1090/1142]  eta: 0:00:17  Lr: 0.030000  Loss: 0.3206  Acc@1: 56.2500 (54.9610)  Acc@5: 87.5000 (90.1467)  time: 0.3443  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [1100/1142]  eta: 0:00:14  Lr: 0.030000  Loss: 0.1337  Acc@1: 62.5000 (55.0409)  Acc@5: 87.5000 (90.2021)  time: 0.3447  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [1110/1142]  eta: 0:00:11  Lr: 0.030000  Loss: 0.3647  Acc@1: 62.5000 (55.0630)  Acc@5: 93.7500 (90.1778)  time: 0.3459  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [1120/1142]  eta: 0:00:07  Lr: 0.030000  Loss: 0.1061  Acc@1: 50.0000 (55.0569)  Acc@5: 87.5000 (90.1706)  time: 0.3451  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [1130/1142]  eta: 0:00:04  Lr: 0.030000  Loss: -0.0789  Acc@1: 56.2500 (55.1061)  Acc@5: 93.7500 (90.1912)  time: 0.3432  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [1140/1142]  eta: 0:00:00  Lr: 0.030000  Loss: -0.1309  Acc@1: 56.2500 (55.1435)  Acc@5: 93.7500 (90.2060)  time: 0.3432  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [1141/1142]  eta: 0:00:00  Lr: 0.030000  Loss: -0.1077  Acc@1: 62.5000 (55.1601)  Acc@5: 93.7500 (90.2108)  time: 0.3359  data: 0.0002  max mem: 2500
Train: Epoch[2/5] Total time: 0:06:33 (0.3446 s / it)
{0: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 1: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 2: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 3: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 4: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 5: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 6: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 7: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 8: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 9: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 10: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 11: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 12: {0: 0, 1: 0, 2: 0, 3: 36530, 4: 0}, 13: {0: 0, 1: 0, 2: 0, 3: 36530, 4: 0}, 14: {0: 0, 1: 0, 2: 0, 3: 36530, 4: 0}, 15: {0: 0, 1: 0, 2: 0, 3: 36530, 4: 0}, 16: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 17: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 18: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 19: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}}
Averaged stats: Lr: 0.030000  Loss: -0.1077  Acc@1: 62.5000 (55.1601)  Acc@5: 93.7500 (90.2108)
Train: Epoch[3/5]  [   0/1142]  eta: 0:11:11  Lr: 0.030000  Loss: 0.1933  Acc@1: 62.5000 (62.5000)  Acc@5: 87.5000 (87.5000)  time: 0.5881  data: 0.2412  max mem: 2500
Train: Epoch[3/5]  [  10/1142]  eta: 0:06:53  Lr: 0.030000  Loss: 0.2622  Acc@1: 56.2500 (60.7955)  Acc@5: 93.7500 (91.4773)  time: 0.3652  data: 0.0222  max mem: 2500
Train: Epoch[3/5]  [  20/1142]  eta: 0:06:37  Lr: 0.030000  Loss: 0.0667  Acc@1: 56.2500 (57.7381)  Acc@5: 93.7500 (91.9643)  time: 0.3430  data: 0.0002  max mem: 2500
Train: Epoch[3/5]  [  30/1142]  eta: 0:06:30  Lr: 0.030000  Loss: 0.0296  Acc@1: 50.0000 (57.0565)  Acc@5: 93.7500 (91.3306)  time: 0.3429  data: 0.0002  max mem: 2500
Train: Epoch[3/5]  [  40/1142]  eta: 0:06:24  Lr: 0.030000  Loss: 0.2905  Acc@1: 56.2500 (57.4695)  Acc@5: 93.7500 (91.4634)  time: 0.3436  data: 0.0002  max mem: 2500
Train: Epoch[3/5]  [  50/1142]  eta: 0:06:20  Lr: 0.030000  Loss: 0.1056  Acc@1: 56.2500 (58.0882)  Acc@5: 93.7500 (92.2794)  time: 0.3457  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [  60/1142]  eta: 0:06:16  Lr: 0.030000  Loss: 0.2394  Acc@1: 56.2500 (57.3770)  Acc@5: 93.7500 (92.1107)  time: 0.3466  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [  70/1142]  eta: 0:06:13  Lr: 0.030000  Loss: 0.3816  Acc@1: 56.2500 (58.0106)  Acc@5: 87.5000 (91.4613)  time: 0.3465  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [  80/1142]  eta: 0:06:09  Lr: 0.030000  Loss: 0.2450  Acc@1: 56.2500 (58.1019)  Acc@5: 87.5000 (91.2809)  time: 0.3466  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [  90/1142]  eta: 0:06:05  Lr: 0.030000  Loss: 0.2122  Acc@1: 56.2500 (57.9670)  Acc@5: 87.5000 (91.1401)  time: 0.3468  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [ 100/1142]  eta: 0:06:02  Lr: 0.030000  Loss: 0.4128  Acc@1: 56.2500 (57.7351)  Acc@5: 93.7500 (91.2748)  time: 0.3464  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 110/1142]  eta: 0:05:58  Lr: 0.030000  Loss: 0.3941  Acc@1: 56.2500 (57.6577)  Acc@5: 93.7500 (91.3288)  time: 0.3465  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 120/1142]  eta: 0:05:55  Lr: 0.030000  Loss: 0.0522  Acc@1: 56.2500 (57.6446)  Acc@5: 93.7500 (91.5289)  time: 0.3473  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 130/1142]  eta: 0:05:51  Lr: 0.030000  Loss: 0.1879  Acc@1: 56.2500 (57.9676)  Acc@5: 93.7500 (91.5076)  time: 0.3463  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 140/1142]  eta: 0:05:48  Lr: 0.030000  Loss: 0.4342  Acc@1: 56.2500 (57.7571)  Acc@5: 93.7500 (91.7110)  time: 0.3472  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 150/1142]  eta: 0:05:44  Lr: 0.030000  Loss: 0.2143  Acc@1: 50.0000 (57.4503)  Acc@5: 93.7500 (91.6391)  time: 0.3485  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 160/1142]  eta: 0:05:41  Lr: 0.030000  Loss: -0.0443  Acc@1: 56.2500 (57.4534)  Acc@5: 93.7500 (91.6149)  time: 0.3501  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 170/1142]  eta: 0:05:37  Lr: 0.030000  Loss: 0.1969  Acc@1: 62.5000 (57.6754)  Acc@5: 93.7500 (91.6667)  time: 0.3487  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [ 180/1142]  eta: 0:05:34  Lr: 0.030000  Loss: 0.1522  Acc@1: 62.5000 (57.6657)  Acc@5: 93.7500 (91.6091)  time: 0.3452  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [ 190/1142]  eta: 0:05:30  Lr: 0.030000  Loss: 0.3523  Acc@1: 56.2500 (57.6243)  Acc@5: 93.7500 (91.5903)  time: 0.3453  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [ 200/1142]  eta: 0:05:27  Lr: 0.030000  Loss: 0.2423  Acc@1: 56.2500 (57.6182)  Acc@5: 93.7500 (91.5734)  time: 0.3453  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [ 210/1142]  eta: 0:05:23  Lr: 0.030000  Loss: 0.3072  Acc@1: 56.2500 (57.5237)  Acc@5: 87.5000 (91.2915)  time: 0.3453  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [ 220/1142]  eta: 0:05:20  Lr: 0.030000  Loss: 0.1394  Acc@1: 56.2500 (57.4943)  Acc@5: 87.5000 (91.2330)  time: 0.3453  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [ 230/1142]  eta: 0:05:16  Lr: 0.030000  Loss: 0.2763  Acc@1: 62.5000 (57.6028)  Acc@5: 93.7500 (91.2067)  time: 0.3451  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [ 240/1142]  eta: 0:05:12  Lr: 0.030000  Loss: 0.6028  Acc@1: 62.5000 (57.7541)  Acc@5: 93.7500 (91.2604)  time: 0.3453  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [ 250/1142]  eta: 0:05:09  Lr: 0.030000  Loss: 0.1255  Acc@1: 56.2500 (57.7689)  Acc@5: 93.7500 (91.1355)  time: 0.3447  data: 0.0002  max mem: 2500
Train: Epoch[3/5]  [ 260/1142]  eta: 0:05:05  Lr: 0.030000  Loss: 0.1445  Acc@1: 56.2500 (57.7586)  Acc@5: 93.7500 (91.1877)  time: 0.3433  data: 0.0002  max mem: 2500
Train: Epoch[3/5]  [ 270/1142]  eta: 0:05:02  Lr: 0.030000  Loss: 0.2565  Acc@1: 56.2500 (57.7491)  Acc@5: 93.7500 (91.1208)  time: 0.3431  data: 0.0002  max mem: 2500
Train: Epoch[3/5]  [ 280/1142]  eta: 0:04:58  Lr: 0.030000  Loss: 0.3398  Acc@1: 56.2500 (57.7625)  Acc@5: 87.5000 (91.1477)  time: 0.3428  data: 0.0002  max mem: 2500
Train: Epoch[3/5]  [ 290/1142]  eta: 0:04:55  Lr: 0.030000  Loss: 0.2996  Acc@1: 56.2500 (57.6890)  Acc@5: 87.5000 (91.1512)  time: 0.3426  data: 0.0002  max mem: 2500
Train: Epoch[3/5]  [ 300/1142]  eta: 0:04:51  Lr: 0.030000  Loss: 0.2869  Acc@1: 50.0000 (57.3297)  Acc@5: 93.7500 (91.2583)  time: 0.3425  data: 0.0002  max mem: 2500
Train: Epoch[3/5]  [ 310/1142]  eta: 0:04:47  Lr: 0.030000  Loss: 0.4662  Acc@1: 50.0000 (57.4156)  Acc@5: 93.7500 (91.2982)  time: 0.3437  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [ 320/1142]  eta: 0:04:44  Lr: 0.030000  Loss: -0.0362  Acc@1: 56.2500 (57.3988)  Acc@5: 93.7500 (91.2383)  time: 0.3457  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 330/1142]  eta: 0:04:41  Lr: 0.030000  Loss: 0.0445  Acc@1: 62.5000 (57.4773)  Acc@5: 87.5000 (91.2387)  time: 0.3455  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 340/1142]  eta: 0:04:37  Lr: 0.030000  Loss: 0.2069  Acc@1: 62.5000 (57.4963)  Acc@5: 87.5000 (91.2023)  time: 0.3448  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [ 350/1142]  eta: 0:04:34  Lr: 0.030000  Loss: 0.4864  Acc@1: 56.2500 (57.4430)  Acc@5: 93.7500 (91.2393)  time: 0.3448  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 360/1142]  eta: 0:04:30  Lr: 0.030000  Loss: 0.2331  Acc@1: 56.2500 (57.3753)  Acc@5: 93.7500 (91.2396)  time: 0.3450  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 370/1142]  eta: 0:04:27  Lr: 0.030000  Loss: -0.0144  Acc@1: 56.2500 (57.6819)  Acc@5: 93.7500 (91.3241)  time: 0.3453  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 380/1142]  eta: 0:04:23  Lr: 0.030000  Loss: 0.2159  Acc@1: 56.2500 (57.7920)  Acc@5: 93.7500 (91.3714)  time: 0.3450  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 390/1142]  eta: 0:04:20  Lr: 0.030000  Loss: -0.0786  Acc@1: 62.5000 (57.9124)  Acc@5: 93.7500 (91.3843)  time: 0.3450  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 400/1142]  eta: 0:04:16  Lr: 0.030000  Loss: 0.4469  Acc@1: 56.2500 (57.8086)  Acc@5: 93.7500 (91.3342)  time: 0.3450  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 410/1142]  eta: 0:04:13  Lr: 0.030000  Loss: 0.4459  Acc@1: 50.0000 (57.6794)  Acc@5: 87.5000 (91.2105)  time: 0.3457  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 420/1142]  eta: 0:04:09  Lr: 0.030000  Loss: 0.2980  Acc@1: 62.5000 (57.9127)  Acc@5: 87.5000 (91.2262)  time: 0.3462  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 430/1142]  eta: 0:04:06  Lr: 0.030000  Loss: 0.4039  Acc@1: 62.5000 (57.9611)  Acc@5: 93.7500 (91.1978)  time: 0.3467  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 440/1142]  eta: 0:04:02  Lr: 0.030000  Loss: 0.3083  Acc@1: 56.2500 (57.9365)  Acc@5: 93.7500 (91.2273)  time: 0.3457  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [ 450/1142]  eta: 0:03:59  Lr: 0.030000  Loss: 0.0891  Acc@1: 62.5000 (58.1901)  Acc@5: 93.7500 (91.2417)  time: 0.3443  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [ 460/1142]  eta: 0:03:55  Lr: 0.030000  Loss: 0.1361  Acc@1: 62.5000 (58.2430)  Acc@5: 93.7500 (91.3097)  time: 0.3447  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [ 470/1142]  eta: 0:03:52  Lr: 0.030000  Loss: -0.1464  Acc@1: 62.5000 (58.4528)  Acc@5: 93.7500 (91.3084)  time: 0.3449  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [ 480/1142]  eta: 0:03:48  Lr: 0.030000  Loss: 0.0217  Acc@1: 56.2500 (58.4200)  Acc@5: 93.7500 (91.3981)  time: 0.3444  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [ 490/1142]  eta: 0:03:45  Lr: 0.030000  Loss: 0.3225  Acc@1: 50.0000 (58.3885)  Acc@5: 93.7500 (91.3569)  time: 0.3430  data: 0.0002  max mem: 2500
Train: Epoch[3/5]  [ 500/1142]  eta: 0:03:41  Lr: 0.030000  Loss: 0.4191  Acc@1: 50.0000 (58.1712)  Acc@5: 93.7500 (91.2675)  time: 0.3427  data: 0.0002  max mem: 2500
Train: Epoch[3/5]  [ 510/1142]  eta: 0:03:38  Lr: 0.030000  Loss: 0.0136  Acc@1: 56.2500 (58.1947)  Acc@5: 87.5000 (91.2549)  time: 0.3430  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [ 520/1142]  eta: 0:03:34  Lr: 0.030000  Loss: 0.3603  Acc@1: 56.2500 (58.1574)  Acc@5: 87.5000 (91.2188)  time: 0.3447  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 530/1142]  eta: 0:03:31  Lr: 0.030000  Loss: 0.3106  Acc@1: 56.2500 (58.2627)  Acc@5: 87.5000 (91.2665)  time: 0.3456  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 540/1142]  eta: 0:03:28  Lr: 0.030000  Loss: 0.4480  Acc@1: 62.5000 (58.3526)  Acc@5: 93.7500 (91.3239)  time: 0.3446  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 550/1142]  eta: 0:03:24  Lr: 0.030000  Loss: -0.1086  Acc@1: 62.5000 (58.3711)  Acc@5: 93.7500 (91.2999)  time: 0.3440  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [ 560/1142]  eta: 0:03:21  Lr: 0.030000  Loss: 0.1194  Acc@1: 62.5000 (58.4225)  Acc@5: 93.7500 (91.3102)  time: 0.3438  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [ 570/1142]  eta: 0:03:17  Lr: 0.030000  Loss: 0.4127  Acc@1: 56.2500 (58.3297)  Acc@5: 93.7500 (91.2434)  time: 0.3441  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [ 580/1142]  eta: 0:03:14  Lr: 0.030000  Loss: 0.2241  Acc@1: 50.0000 (58.1110)  Acc@5: 87.5000 (91.2328)  time: 0.3445  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [ 590/1142]  eta: 0:03:10  Lr: 0.030000  Loss: 0.0272  Acc@1: 56.2500 (58.1747)  Acc@5: 93.7500 (91.2331)  time: 0.3439  data: 0.0002  max mem: 2500
Train: Epoch[3/5]  [ 600/1142]  eta: 0:03:07  Lr: 0.030000  Loss: 0.1621  Acc@1: 56.2500 (58.1531)  Acc@5: 93.7500 (91.2438)  time: 0.3426  data: 0.0002  max mem: 2500
Train: Epoch[3/5]  [ 610/1142]  eta: 0:03:03  Lr: 0.030000  Loss: -0.0800  Acc@1: 56.2500 (58.2549)  Acc@5: 93.7500 (91.3155)  time: 0.3426  data: 0.0002  max mem: 2500
Train: Epoch[3/5]  [ 620/1142]  eta: 0:03:00  Lr: 0.030000  Loss: 0.2731  Acc@1: 62.5000 (58.1824)  Acc@5: 93.7500 (91.3144)  time: 0.3444  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [ 630/1142]  eta: 0:02:56  Lr: 0.030000  Loss: 0.4390  Acc@1: 56.2500 (58.2112)  Acc@5: 93.7500 (91.3629)  time: 0.3455  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 640/1142]  eta: 0:02:53  Lr: 0.030000  Loss: 0.4122  Acc@1: 56.2500 (58.1513)  Acc@5: 87.5000 (91.3124)  time: 0.3449  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 650/1142]  eta: 0:02:49  Lr: 0.030000  Loss: 0.0803  Acc@1: 56.2500 (58.1221)  Acc@5: 87.5000 (91.2922)  time: 0.3451  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 660/1142]  eta: 0:02:46  Lr: 0.030000  Loss: 0.1840  Acc@1: 56.2500 (58.2167)  Acc@5: 93.7500 (91.3105)  time: 0.3448  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 670/1142]  eta: 0:02:43  Lr: 0.030000  Loss: 0.1728  Acc@1: 56.2500 (58.1967)  Acc@5: 93.7500 (91.2817)  time: 0.3467  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [ 680/1142]  eta: 0:02:39  Lr: 0.030000  Loss: 0.0958  Acc@1: 56.2500 (58.2232)  Acc@5: 87.5000 (91.2261)  time: 0.3467  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [ 690/1142]  eta: 0:02:36  Lr: 0.030000  Loss: 0.1446  Acc@1: 62.5000 (58.3575)  Acc@5: 93.7500 (91.2536)  time: 0.3441  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [ 700/1142]  eta: 0:02:32  Lr: 0.030000  Loss: 0.1636  Acc@1: 56.2500 (58.2650)  Acc@5: 93.7500 (91.2803)  time: 0.3442  data: 0.0002  max mem: 2500
Train: Epoch[3/5]  [ 710/1142]  eta: 0:02:29  Lr: 0.030000  Loss: 0.0706  Acc@1: 56.2500 (58.2191)  Acc@5: 93.7500 (91.2799)  time: 0.3442  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [ 720/1142]  eta: 0:02:25  Lr: 0.030000  Loss: 0.3401  Acc@1: 62.5000 (58.3131)  Acc@5: 93.7500 (91.3228)  time: 0.3442  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [ 730/1142]  eta: 0:02:22  Lr: 0.030000  Loss: 0.1069  Acc@1: 62.5000 (58.3618)  Acc@5: 93.7500 (91.3047)  time: 0.3446  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [ 740/1142]  eta: 0:02:18  Lr: 0.030000  Loss: 0.0907  Acc@1: 56.2500 (58.3502)  Acc@5: 93.7500 (91.3040)  time: 0.3439  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [ 750/1142]  eta: 0:02:15  Lr: 0.030000  Loss: 0.1846  Acc@1: 56.2500 (58.3222)  Acc@5: 93.7500 (91.3366)  time: 0.3430  data: 0.0002  max mem: 2500
Train: Epoch[3/5]  [ 760/1142]  eta: 0:02:11  Lr: 0.030000  Loss: 0.1608  Acc@1: 56.2500 (58.3196)  Acc@5: 93.7500 (91.3601)  time: 0.3430  data: 0.0002  max mem: 2500
Train: Epoch[3/5]  [ 770/1142]  eta: 0:02:08  Lr: 0.030000  Loss: -0.0455  Acc@1: 50.0000 (58.2523)  Acc@5: 87.5000 (91.3100)  time: 0.3429  data: 0.0002  max mem: 2500
Train: Epoch[3/5]  [ 780/1142]  eta: 0:02:04  Lr: 0.030000  Loss: 0.2470  Acc@1: 50.0000 (58.2026)  Acc@5: 87.5000 (91.3012)  time: 0.3429  data: 0.0002  max mem: 2500
Train: Epoch[3/5]  [ 790/1142]  eta: 0:02:01  Lr: 0.030000  Loss: 0.2460  Acc@1: 56.2500 (58.1147)  Acc@5: 87.5000 (91.2532)  time: 0.3452  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [ 800/1142]  eta: 0:01:58  Lr: 0.030000  Loss: -0.2149  Acc@1: 56.2500 (58.2397)  Acc@5: 87.5000 (91.2843)  time: 0.3467  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 810/1142]  eta: 0:01:54  Lr: 0.030000  Loss: 0.1281  Acc@1: 62.5000 (58.2768)  Acc@5: 93.7500 (91.3147)  time: 0.3457  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 820/1142]  eta: 0:01:51  Lr: 0.030000  Loss: 0.1282  Acc@1: 62.5000 (58.3511)  Acc@5: 93.7500 (91.3063)  time: 0.3457  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 830/1142]  eta: 0:01:47  Lr: 0.030000  Loss: -0.0236  Acc@1: 62.5000 (58.3785)  Acc@5: 93.7500 (91.3282)  time: 0.3459  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [ 840/1142]  eta: 0:01:44  Lr: 0.030000  Loss: -0.0510  Acc@1: 62.5000 (58.4126)  Acc@5: 93.7500 (91.3199)  time: 0.3463  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 850/1142]  eta: 0:01:40  Lr: 0.030000  Loss: 0.0941  Acc@1: 62.5000 (58.4459)  Acc@5: 93.7500 (91.3264)  time: 0.3464  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 860/1142]  eta: 0:01:37  Lr: 0.030000  Loss: 0.1574  Acc@1: 62.5000 (58.4785)  Acc@5: 87.5000 (91.2965)  time: 0.3464  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [ 870/1142]  eta: 0:01:33  Lr: 0.030000  Loss: 0.2337  Acc@1: 62.5000 (58.5534)  Acc@5: 87.5000 (91.2816)  time: 0.3464  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [ 880/1142]  eta: 0:01:30  Lr: 0.030000  Loss: 0.1975  Acc@1: 68.7500 (58.6762)  Acc@5: 93.7500 (91.3309)  time: 0.3458  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [ 890/1142]  eta: 0:01:27  Lr: 0.030000  Loss: -0.0126  Acc@1: 62.5000 (58.6420)  Acc@5: 93.7500 (91.3440)  time: 0.3455  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [ 900/1142]  eta: 0:01:23  Lr: 0.030000  Loss: 0.0125  Acc@1: 56.2500 (58.5946)  Acc@5: 93.7500 (91.3430)  time: 0.3456  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [ 910/1142]  eta: 0:01:20  Lr: 0.030000  Loss: 0.3126  Acc@1: 56.2500 (58.6306)  Acc@5: 93.7500 (91.3419)  time: 0.3454  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [ 920/1142]  eta: 0:01:16  Lr: 0.030000  Loss: 0.2360  Acc@1: 62.5000 (58.6116)  Acc@5: 93.7500 (91.3477)  time: 0.3450  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [ 930/1142]  eta: 0:01:13  Lr: 0.030000  Loss: 0.1193  Acc@1: 62.5000 (58.6869)  Acc@5: 93.7500 (91.3668)  time: 0.3462  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [ 940/1142]  eta: 0:01:09  Lr: 0.030000  Loss: 0.1040  Acc@1: 62.5000 (58.6942)  Acc@5: 93.7500 (91.3921)  time: 0.3453  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [ 950/1142]  eta: 0:01:06  Lr: 0.030000  Loss: 0.2702  Acc@1: 56.2500 (58.6751)  Acc@5: 93.7500 (91.3775)  time: 0.3432  data: 0.0002  max mem: 2500
Train: Epoch[3/5]  [ 960/1142]  eta: 0:01:02  Lr: 0.030000  Loss: 0.3078  Acc@1: 56.2500 (58.6043)  Acc@5: 93.7500 (91.3697)  time: 0.3433  data: 0.0002  max mem: 2500
Train: Epoch[3/5]  [ 970/1142]  eta: 0:00:59  Lr: 0.030000  Loss: 0.0683  Acc@1: 62.5000 (58.6509)  Acc@5: 93.7500 (91.3749)  time: 0.3432  data: 0.0002  max mem: 2500
Train: Epoch[3/5]  [ 980/1142]  eta: 0:00:55  Lr: 0.030000  Loss: 0.1610  Acc@1: 62.5000 (58.6646)  Acc@5: 93.7500 (91.4118)  time: 0.3431  data: 0.0002  max mem: 2500
Train: Epoch[3/5]  [ 990/1142]  eta: 0:00:52  Lr: 0.030000  Loss: -0.0477  Acc@1: 62.5000 (58.6213)  Acc@5: 93.7500 (91.3976)  time: 0.3431  data: 0.0002  max mem: 2500
Train: Epoch[3/5]  [1000/1142]  eta: 0:00:49  Lr: 0.030000  Loss: -0.0643  Acc@1: 50.0000 (58.5914)  Acc@5: 93.7500 (91.4086)  time: 0.3428  data: 0.0002  max mem: 2500
Train: Epoch[3/5]  [1010/1142]  eta: 0:00:45  Lr: 0.030000  Loss: 0.5799  Acc@1: 56.2500 (58.6177)  Acc@5: 93.7500 (91.3823)  time: 0.3437  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [1020/1142]  eta: 0:00:42  Lr: 0.030000  Loss: 0.2240  Acc@1: 56.2500 (58.5639)  Acc@5: 93.7500 (91.3871)  time: 0.3452  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1030/1142]  eta: 0:00:38  Lr: 0.030000  Loss: 0.4819  Acc@1: 56.2500 (58.5233)  Acc@5: 93.7500 (91.3737)  time: 0.3459  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [1040/1142]  eta: 0:00:35  Lr: 0.030000  Loss: -0.1273  Acc@1: 56.2500 (58.5255)  Acc@5: 93.7500 (91.4085)  time: 0.3461  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [1050/1142]  eta: 0:00:31  Lr: 0.030000  Loss: 0.2347  Acc@1: 56.2500 (58.5514)  Acc@5: 93.7500 (91.4189)  time: 0.3453  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1060/1142]  eta: 0:00:28  Lr: 0.030000  Loss: -0.2306  Acc@1: 56.2500 (58.5768)  Acc@5: 93.7500 (91.4350)  time: 0.3452  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [1070/1142]  eta: 0:00:24  Lr: 0.030000  Loss: 0.2584  Acc@1: 56.2500 (58.6076)  Acc@5: 93.7500 (91.4332)  time: 0.3449  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1080/1142]  eta: 0:00:21  Lr: 0.030000  Loss: 0.2675  Acc@1: 56.2500 (58.6031)  Acc@5: 93.7500 (91.4373)  time: 0.3460  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1090/1142]  eta: 0:00:17  Lr: 0.030000  Loss: -0.0069  Acc@1: 56.2500 (58.6102)  Acc@5: 93.7500 (91.4757)  time: 0.3464  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1100/1142]  eta: 0:00:14  Lr: 0.030000  Loss: 0.0865  Acc@1: 62.5000 (58.6399)  Acc@5: 93.7500 (91.4793)  time: 0.3454  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1110/1142]  eta: 0:00:11  Lr: 0.030000  Loss: 0.2213  Acc@1: 62.5000 (58.6859)  Acc@5: 93.7500 (91.4773)  time: 0.3459  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [1120/1142]  eta: 0:00:07  Lr: 0.030000  Loss: 0.1707  Acc@1: 62.5000 (58.6809)  Acc@5: 93.7500 (91.4864)  time: 0.3454  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1130/1142]  eta: 0:00:04  Lr: 0.030000  Loss: 0.1888  Acc@1: 62.5000 (58.6981)  Acc@5: 93.7500 (91.4843)  time: 0.3446  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1140/1142]  eta: 0:00:00  Lr: 0.030000  Loss: 0.1549  Acc@1: 62.5000 (58.6985)  Acc@5: 93.7500 (91.5316)  time: 0.3441  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1141/1142]  eta: 0:00:00  Lr: 0.030000  Loss: -0.4190  Acc@1: 62.5000 (58.7189)  Acc@5: 93.7500 (91.5357)  time: 0.3368  data: 0.0003  max mem: 2500
Train: Epoch[3/5] Total time: 0:06:34 (0.3452 s / it)
{0: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 1: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 2: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 3: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 4: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 5: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 6: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 7: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 8: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 9: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 10: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 11: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 12: {0: 0, 1: 0, 2: 0, 3: 54795, 4: 0}, 13: {0: 0, 1: 0, 2: 0, 3: 54795, 4: 0}, 14: {0: 0, 1: 0, 2: 0, 3: 54795, 4: 0}, 15: {0: 0, 1: 0, 2: 0, 3: 54795, 4: 0}, 16: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 17: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 18: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 19: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}}
Averaged stats: Lr: 0.030000  Loss: -0.4190  Acc@1: 62.5000 (58.7189)  Acc@5: 93.7500 (91.5357)
Train: Epoch[4/5]  [   0/1142]  eta: 0:11:38  Lr: 0.030000  Loss: 0.0221  Acc@1: 62.5000 (62.5000)  Acc@5: 100.0000 (100.0000)  time: 0.6113  data: 0.2656  max mem: 2500
Train: Epoch[4/5]  [  10/1142]  eta: 0:06:56  Lr: 0.030000  Loss: 0.3072  Acc@1: 62.5000 (60.7955)  Acc@5: 87.5000 (88.0682)  time: 0.3683  data: 0.0244  max mem: 2500
Train: Epoch[4/5]  [  20/1142]  eta: 0:06:41  Lr: 0.030000  Loss: 0.0834  Acc@1: 62.5000 (63.3929)  Acc@5: 93.7500 (91.9643)  time: 0.3447  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [  30/1142]  eta: 0:06:32  Lr: 0.030000  Loss: -0.0918  Acc@1: 62.5000 (60.8871)  Acc@5: 93.7500 (91.5323)  time: 0.3443  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [  40/1142]  eta: 0:06:26  Lr: 0.030000  Loss: 0.3434  Acc@1: 62.5000 (61.1280)  Acc@5: 93.7500 (91.9207)  time: 0.3428  data: 0.0002  max mem: 2500
Train: Epoch[4/5]  [  50/1142]  eta: 0:06:20  Lr: 0.030000  Loss: 0.2173  Acc@1: 62.5000 (61.3971)  Acc@5: 93.7500 (91.9118)  time: 0.3424  data: 0.0002  max mem: 2500
Train: Epoch[4/5]  [  60/1142]  eta: 0:06:16  Lr: 0.030000  Loss: 0.0934  Acc@1: 56.2500 (60.6557)  Acc@5: 93.7500 (91.8033)  time: 0.3433  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [  70/1142]  eta: 0:06:12  Lr: 0.030000  Loss: 0.1543  Acc@1: 56.2500 (60.0352)  Acc@5: 93.7500 (92.0775)  time: 0.3450  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [  80/1142]  eta: 0:06:09  Lr: 0.030000  Loss: 0.0856  Acc@1: 56.2500 (60.0309)  Acc@5: 93.7500 (92.5154)  time: 0.3461  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [  90/1142]  eta: 0:06:05  Lr: 0.030000  Loss: 0.0526  Acc@1: 62.5000 (60.3022)  Acc@5: 93.7500 (92.5137)  time: 0.3454  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 100/1142]  eta: 0:06:01  Lr: 0.030000  Loss: 0.1846  Acc@1: 56.2500 (59.6535)  Acc@5: 93.7500 (92.3886)  time: 0.3439  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [ 110/1142]  eta: 0:05:57  Lr: 0.030000  Loss: 0.0126  Acc@1: 62.5000 (60.5293)  Acc@5: 93.7500 (92.6802)  time: 0.3437  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [ 120/1142]  eta: 0:05:54  Lr: 0.030000  Loss: -0.1478  Acc@1: 68.7500 (61.3120)  Acc@5: 93.7500 (92.9752)  time: 0.3445  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [ 130/1142]  eta: 0:05:50  Lr: 0.030000  Loss: 0.0769  Acc@1: 56.2500 (60.3531)  Acc@5: 93.7500 (92.8435)  time: 0.3444  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [ 140/1142]  eta: 0:05:46  Lr: 0.030000  Loss: 0.0046  Acc@1: 56.2500 (60.5496)  Acc@5: 93.7500 (92.7748)  time: 0.3449  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [ 150/1142]  eta: 0:05:43  Lr: 0.030000  Loss: 0.2783  Acc@1: 62.5000 (60.5960)  Acc@5: 93.7500 (92.7152)  time: 0.3443  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [ 160/1142]  eta: 0:05:39  Lr: 0.030000  Loss: -0.3940  Acc@1: 62.5000 (60.7143)  Acc@5: 93.7500 (92.7795)  time: 0.3427  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [ 170/1142]  eta: 0:05:35  Lr: 0.030000  Loss: 0.1948  Acc@1: 62.5000 (60.9649)  Acc@5: 93.7500 (92.8728)  time: 0.3427  data: 0.0002  max mem: 2500
Train: Epoch[4/5]  [ 180/1142]  eta: 0:05:32  Lr: 0.030000  Loss: 0.2584  Acc@1: 62.5000 (60.8771)  Acc@5: 93.7500 (92.9558)  time: 0.3427  data: 0.0002  max mem: 2500
Train: Epoch[4/5]  [ 190/1142]  eta: 0:05:28  Lr: 0.030000  Loss: 0.3779  Acc@1: 50.0000 (60.2421)  Acc@5: 93.7500 (92.8665)  time: 0.3428  data: 0.0002  max mem: 2500
Train: Epoch[4/5]  [ 200/1142]  eta: 0:05:25  Lr: 0.030000  Loss: 0.0551  Acc@1: 56.2500 (60.2923)  Acc@5: 93.7500 (92.9104)  time: 0.3428  data: 0.0002  max mem: 2500
Train: Epoch[4/5]  [ 210/1142]  eta: 0:05:21  Lr: 0.030000  Loss: 0.0027  Acc@1: 62.5000 (60.3081)  Acc@5: 93.7500 (92.9502)  time: 0.3431  data: 0.0002  max mem: 2500
Train: Epoch[4/5]  [ 220/1142]  eta: 0:05:18  Lr: 0.030000  Loss: 0.0186  Acc@1: 56.2500 (60.1527)  Acc@5: 93.7500 (92.9299)  time: 0.3451  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [ 230/1142]  eta: 0:05:14  Lr: 0.030000  Loss: 0.1964  Acc@1: 56.2500 (60.0108)  Acc@5: 93.7500 (92.7760)  time: 0.3459  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 240/1142]  eta: 0:05:11  Lr: 0.030000  Loss: -0.2984  Acc@1: 62.5000 (60.1919)  Acc@5: 87.5000 (92.7386)  time: 0.3452  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [ 250/1142]  eta: 0:05:07  Lr: 0.030000  Loss: 0.4080  Acc@1: 62.5000 (60.1594)  Acc@5: 93.7500 (92.7042)  time: 0.3456  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [ 260/1142]  eta: 0:05:04  Lr: 0.030000  Loss: 0.0509  Acc@1: 62.5000 (60.0096)  Acc@5: 93.7500 (92.6245)  time: 0.3465  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 270/1142]  eta: 0:05:01  Lr: 0.030000  Loss: 0.0609  Acc@1: 56.2500 (59.8939)  Acc@5: 93.7500 (92.5507)  time: 0.3462  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 280/1142]  eta: 0:04:57  Lr: 0.030000  Loss: -0.1286  Acc@1: 56.2500 (60.0089)  Acc@5: 93.7500 (92.5712)  time: 0.3458  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 290/1142]  eta: 0:04:54  Lr: 0.030000  Loss: -0.0264  Acc@1: 62.5000 (60.1375)  Acc@5: 93.7500 (92.6332)  time: 0.3459  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [ 300/1142]  eta: 0:04:50  Lr: 0.030000  Loss: 0.5624  Acc@1: 56.2500 (59.9252)  Acc@5: 93.7500 (92.5664)  time: 0.3457  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 310/1142]  eta: 0:04:47  Lr: 0.030000  Loss: 0.0117  Acc@1: 56.2500 (59.7870)  Acc@5: 93.7500 (92.5442)  time: 0.3462  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 320/1142]  eta: 0:04:43  Lr: 0.030000  Loss: 0.1422  Acc@1: 56.2500 (59.5989)  Acc@5: 93.7500 (92.4455)  time: 0.3467  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 330/1142]  eta: 0:04:40  Lr: 0.030000  Loss: 0.0983  Acc@1: 56.2500 (59.6677)  Acc@5: 93.7500 (92.3905)  time: 0.3475  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 340/1142]  eta: 0:04:37  Lr: 0.030000  Loss: -0.2653  Acc@1: 62.5000 (59.7324)  Acc@5: 93.7500 (92.4487)  time: 0.3473  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 350/1142]  eta: 0:04:33  Lr: 0.030000  Loss: 0.1383  Acc@1: 68.7500 (60.0249)  Acc@5: 93.7500 (92.4323)  time: 0.3467  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [ 360/1142]  eta: 0:04:30  Lr: 0.030000  Loss: 0.4587  Acc@1: 62.5000 (59.8511)  Acc@5: 93.7500 (92.3996)  time: 0.3459  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [ 370/1142]  eta: 0:04:26  Lr: 0.030000  Loss: -0.0015  Acc@1: 56.2500 (59.8551)  Acc@5: 93.7500 (92.4697)  time: 0.3457  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [ 380/1142]  eta: 0:04:23  Lr: 0.030000  Loss: 0.1849  Acc@1: 56.2500 (59.8261)  Acc@5: 93.7500 (92.4869)  time: 0.3460  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [ 390/1142]  eta: 0:04:19  Lr: 0.030000  Loss: 0.3926  Acc@1: 56.2500 (59.7666)  Acc@5: 93.7500 (92.4073)  time: 0.3448  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [ 400/1142]  eta: 0:04:16  Lr: 0.030000  Loss: 0.1722  Acc@1: 56.2500 (59.6166)  Acc@5: 87.5000 (92.2693)  time: 0.3443  data: 0.0002  max mem: 2500
Train: Epoch[4/5]  [ 410/1142]  eta: 0:04:12  Lr: 0.030000  Loss: 0.1255  Acc@1: 56.2500 (59.6715)  Acc@5: 93.7500 (92.3206)  time: 0.3445  data: 0.0002  max mem: 2500
Train: Epoch[4/5]  [ 420/1142]  eta: 0:04:09  Lr: 0.030000  Loss: -0.2836  Acc@1: 56.2500 (59.5457)  Acc@5: 93.7500 (92.3248)  time: 0.3461  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 430/1142]  eta: 0:04:06  Lr: 0.030000  Loss: 0.1485  Acc@1: 56.2500 (59.5128)  Acc@5: 93.7500 (92.2854)  time: 0.3477  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [ 440/1142]  eta: 0:04:02  Lr: 0.030000  Loss: 0.1082  Acc@1: 62.5000 (59.6655)  Acc@5: 93.7500 (92.3044)  time: 0.3482  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [ 450/1142]  eta: 0:03:59  Lr: 0.030000  Loss: 0.0133  Acc@1: 56.2500 (59.5067)  Acc@5: 93.7500 (92.3226)  time: 0.3463  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [ 460/1142]  eta: 0:03:55  Lr: 0.030000  Loss: 0.2044  Acc@1: 56.2500 (59.5851)  Acc@5: 93.7500 (92.2587)  time: 0.3445  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [ 470/1142]  eta: 0:03:52  Lr: 0.030000  Loss: 0.3080  Acc@1: 56.2500 (59.4347)  Acc@5: 87.5000 (92.1709)  time: 0.3451  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [ 480/1142]  eta: 0:03:48  Lr: 0.030000  Loss: 0.2145  Acc@1: 56.2500 (59.4205)  Acc@5: 93.7500 (92.2557)  time: 0.3445  data: 0.0002  max mem: 2500
Train: Epoch[4/5]  [ 490/1142]  eta: 0:03:45  Lr: 0.030000  Loss: -0.0226  Acc@1: 56.2500 (59.3941)  Acc@5: 93.7500 (92.2480)  time: 0.3437  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [ 500/1142]  eta: 0:03:41  Lr: 0.030000  Loss: -0.1691  Acc@1: 56.2500 (59.3937)  Acc@5: 93.7500 (92.2530)  time: 0.3446  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [ 510/1142]  eta: 0:03:38  Lr: 0.030000  Loss: -0.0239  Acc@1: 56.2500 (59.3933)  Acc@5: 93.7500 (92.2456)  time: 0.3462  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 520/1142]  eta: 0:03:34  Lr: 0.030000  Loss: 0.4906  Acc@1: 62.5000 (59.5010)  Acc@5: 93.7500 (92.2385)  time: 0.3462  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 530/1142]  eta: 0:03:31  Lr: 0.030000  Loss: 0.0165  Acc@1: 62.5000 (59.5692)  Acc@5: 93.7500 (92.2199)  time: 0.3449  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [ 540/1142]  eta: 0:03:27  Lr: 0.030000  Loss: 0.2265  Acc@1: 62.5000 (59.6927)  Acc@5: 93.7500 (92.2597)  time: 0.3447  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [ 550/1142]  eta: 0:03:24  Lr: 0.030000  Loss: 0.3801  Acc@1: 62.5000 (59.7436)  Acc@5: 93.7500 (92.2414)  time: 0.3448  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [ 560/1142]  eta: 0:03:21  Lr: 0.030000  Loss: 0.2937  Acc@1: 56.2500 (59.6591)  Acc@5: 93.7500 (92.2126)  time: 0.3445  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [ 570/1142]  eta: 0:03:17  Lr: 0.030000  Loss: 0.0933  Acc@1: 56.2500 (59.6541)  Acc@5: 93.7500 (92.2504)  time: 0.3452  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [ 580/1142]  eta: 0:03:14  Lr: 0.030000  Loss: 0.4644  Acc@1: 56.2500 (59.6601)  Acc@5: 93.7500 (92.2762)  time: 0.3445  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [ 590/1142]  eta: 0:03:10  Lr: 0.030000  Loss: 0.0801  Acc@1: 56.2500 (59.6552)  Acc@5: 93.7500 (92.2695)  time: 0.3431  data: 0.0002  max mem: 2500
Train: Epoch[4/5]  [ 600/1142]  eta: 0:03:07  Lr: 0.030000  Loss: 0.6183  Acc@1: 56.2500 (59.6194)  Acc@5: 87.5000 (92.2109)  time: 0.3430  data: 0.0002  max mem: 2500
Train: Epoch[4/5]  [ 610/1142]  eta: 0:03:03  Lr: 0.030000  Loss: 0.3912  Acc@1: 56.2500 (59.4926)  Acc@5: 87.5000 (92.1031)  time: 0.3429  data: 0.0002  max mem: 2500
Train: Epoch[4/5]  [ 620/1142]  eta: 0:03:00  Lr: 0.030000  Loss: 0.0328  Acc@1: 56.2500 (59.4706)  Acc@5: 87.5000 (92.0793)  time: 0.3430  data: 0.0002  max mem: 2500
Train: Epoch[4/5]  [ 630/1142]  eta: 0:02:56  Lr: 0.030000  Loss: 0.4337  Acc@1: 62.5000 (59.5880)  Acc@5: 87.5000 (92.0860)  time: 0.3431  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [ 640/1142]  eta: 0:02:53  Lr: 0.030000  Loss: 0.1286  Acc@1: 62.5000 (59.5456)  Acc@5: 87.5000 (92.0144)  time: 0.3429  data: 0.0002  max mem: 2500
Train: Epoch[4/5]  [ 650/1142]  eta: 0:02:49  Lr: 0.030000  Loss: 0.0554  Acc@1: 62.5000 (59.6198)  Acc@5: 93.7500 (92.0507)  time: 0.3446  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [ 660/1142]  eta: 0:02:46  Lr: 0.030000  Loss: 0.1608  Acc@1: 62.5000 (59.5121)  Acc@5: 93.7500 (92.0291)  time: 0.3459  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [ 670/1142]  eta: 0:02:42  Lr: 0.030000  Loss: 0.1899  Acc@1: 50.0000 (59.5287)  Acc@5: 93.7500 (92.0268)  time: 0.3451  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 680/1142]  eta: 0:02:39  Lr: 0.030000  Loss: 0.1151  Acc@1: 68.7500 (59.6366)  Acc@5: 93.7500 (92.0705)  time: 0.3452  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 690/1142]  eta: 0:02:36  Lr: 0.030000  Loss: 0.0485  Acc@1: 68.7500 (59.7594)  Acc@5: 93.7500 (92.0586)  time: 0.3451  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [ 700/1142]  eta: 0:02:32  Lr: 0.030000  Loss: 0.0798  Acc@1: 68.7500 (59.8074)  Acc@5: 93.7500 (92.0738)  time: 0.3456  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 710/1142]  eta: 0:02:29  Lr: 0.030000  Loss: -0.0394  Acc@1: 56.2500 (59.8101)  Acc@5: 93.7500 (92.0534)  time: 0.3460  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [ 720/1142]  eta: 0:02:25  Lr: 0.030000  Loss: 0.2465  Acc@1: 56.2500 (59.8041)  Acc@5: 93.7500 (92.0423)  time: 0.3467  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [ 730/1142]  eta: 0:02:22  Lr: 0.030000  Loss: 0.0142  Acc@1: 56.2500 (59.7555)  Acc@5: 93.7500 (91.9802)  time: 0.3458  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [ 740/1142]  eta: 0:02:18  Lr: 0.030000  Loss: -0.2159  Acc@1: 62.5000 (59.7841)  Acc@5: 93.7500 (91.9787)  time: 0.3446  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 750/1142]  eta: 0:02:15  Lr: 0.030000  Loss: 0.4930  Acc@1: 62.5000 (59.8286)  Acc@5: 93.7500 (91.9940)  time: 0.3458  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 760/1142]  eta: 0:02:11  Lr: 0.030000  Loss: 0.1991  Acc@1: 56.2500 (59.7651)  Acc@5: 93.7500 (91.9432)  time: 0.3459  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 770/1142]  eta: 0:02:08  Lr: 0.030000  Loss: -0.0914  Acc@1: 56.2500 (59.7925)  Acc@5: 87.5000 (91.9585)  time: 0.3459  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [ 780/1142]  eta: 0:02:04  Lr: 0.030000  Loss: 0.1385  Acc@1: 62.5000 (59.8111)  Acc@5: 93.7500 (91.9654)  time: 0.3457  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 790/1142]  eta: 0:02:01  Lr: 0.030000  Loss: 0.2123  Acc@1: 56.2500 (59.7345)  Acc@5: 93.7500 (91.9406)  time: 0.3447  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [ 800/1142]  eta: 0:01:58  Lr: 0.030000  Loss: 0.2675  Acc@1: 50.0000 (59.7768)  Acc@5: 93.7500 (91.9554)  time: 0.3443  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [ 810/1142]  eta: 0:01:54  Lr: 0.030000  Loss: 0.0364  Acc@1: 56.2500 (59.7334)  Acc@5: 93.7500 (91.9236)  time: 0.3444  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [ 820/1142]  eta: 0:01:51  Lr: 0.030000  Loss: 0.2946  Acc@1: 56.2500 (59.6833)  Acc@5: 87.5000 (91.8544)  time: 0.3444  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [ 830/1142]  eta: 0:01:47  Lr: 0.030000  Loss: 0.0751  Acc@1: 56.2500 (59.7022)  Acc@5: 87.5000 (91.8547)  time: 0.3446  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [ 840/1142]  eta: 0:01:44  Lr: 0.030000  Loss: -0.0345  Acc@1: 62.5000 (59.6908)  Acc@5: 93.7500 (91.8624)  time: 0.3453  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [ 850/1142]  eta: 0:01:40  Lr: 0.030000  Loss: 0.2173  Acc@1: 56.2500 (59.5990)  Acc@5: 87.5000 (91.8405)  time: 0.3445  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [ 860/1142]  eta: 0:01:37  Lr: 0.030000  Loss: -0.0359  Acc@1: 56.2500 (59.5819)  Acc@5: 93.7500 (91.8481)  time: 0.3434  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [ 870/1142]  eta: 0:01:33  Lr: 0.030000  Loss: 0.0583  Acc@1: 56.2500 (59.5867)  Acc@5: 93.7500 (91.8628)  time: 0.3428  data: 0.0002  max mem: 2500
Train: Epoch[4/5]  [ 880/1142]  eta: 0:01:30  Lr: 0.030000  Loss: 0.5963  Acc@1: 56.2500 (59.5062)  Acc@5: 93.7500 (91.8275)  time: 0.3428  data: 0.0002  max mem: 2500
Train: Epoch[4/5]  [ 890/1142]  eta: 0:01:26  Lr: 0.030000  Loss: 0.0214  Acc@1: 56.2500 (59.5258)  Acc@5: 93.7500 (91.8280)  time: 0.3430  data: 0.0002  max mem: 2500
Train: Epoch[4/5]  [ 900/1142]  eta: 0:01:23  Lr: 0.030000  Loss: 0.4693  Acc@1: 56.2500 (59.4340)  Acc@5: 93.7500 (91.8077)  time: 0.3428  data: 0.0002  max mem: 2500
Train: Epoch[4/5]  [ 910/1142]  eta: 0:01:20  Lr: 0.030000  Loss: 0.1012  Acc@1: 56.2500 (59.4470)  Acc@5: 87.5000 (91.7947)  time: 0.3447  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [ 920/1142]  eta: 0:01:16  Lr: 0.030000  Loss: -0.1178  Acc@1: 56.2500 (59.4055)  Acc@5: 87.5000 (91.7956)  time: 0.3458  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [ 930/1142]  eta: 0:01:13  Lr: 0.030000  Loss: 0.2746  Acc@1: 56.2500 (59.4119)  Acc@5: 93.7500 (91.8032)  time: 0.3449  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [ 940/1142]  eta: 0:01:09  Lr: 0.030000  Loss: 0.2338  Acc@1: 62.5000 (59.4248)  Acc@5: 93.7500 (91.7774)  time: 0.3454  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 950/1142]  eta: 0:01:06  Lr: 0.030000  Loss: 0.0486  Acc@1: 62.5000 (59.4440)  Acc@5: 87.5000 (91.7718)  time: 0.3454  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 960/1142]  eta: 0:01:02  Lr: 0.030000  Loss: 0.0353  Acc@1: 62.5000 (59.4628)  Acc@5: 93.7500 (91.7534)  time: 0.3459  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 970/1142]  eta: 0:00:59  Lr: 0.030000  Loss: -0.0417  Acc@1: 62.5000 (59.5391)  Acc@5: 93.7500 (91.7868)  time: 0.3457  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 980/1142]  eta: 0:00:55  Lr: 0.030000  Loss: 0.1122  Acc@1: 68.7500 (59.6139)  Acc@5: 93.7500 (91.8259)  time: 0.3446  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [ 990/1142]  eta: 0:00:52  Lr: 0.030000  Loss: 0.1669  Acc@1: 68.7500 (59.6872)  Acc@5: 93.7500 (91.8264)  time: 0.3449  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1000/1142]  eta: 0:00:49  Lr: 0.030000  Loss: -0.0494  Acc@1: 62.5000 (59.7465)  Acc@5: 93.7500 (91.8644)  time: 0.3487  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1010/1142]  eta: 0:00:45  Lr: 0.030000  Loss: -0.1082  Acc@1: 62.5000 (59.7552)  Acc@5: 93.7500 (91.8707)  time: 0.3485  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [1020/1142]  eta: 0:00:42  Lr: 0.030000  Loss: 0.2595  Acc@1: 62.5000 (59.7453)  Acc@5: 93.7500 (91.8462)  time: 0.3446  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [1030/1142]  eta: 0:00:38  Lr: 0.030000  Loss: -0.0725  Acc@1: 56.2500 (59.7296)  Acc@5: 93.7500 (91.8344)  time: 0.3448  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [1040/1142]  eta: 0:00:35  Lr: 0.030000  Loss: -0.0677  Acc@1: 62.5000 (59.7562)  Acc@5: 93.7500 (91.8648)  time: 0.3449  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [1050/1142]  eta: 0:00:31  Lr: 0.030000  Loss: 0.2139  Acc@1: 62.5000 (59.8002)  Acc@5: 93.7500 (91.8887)  time: 0.3446  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [1060/1142]  eta: 0:00:28  Lr: 0.030000  Loss: 0.1290  Acc@1: 62.5000 (59.7667)  Acc@5: 93.7500 (91.8414)  time: 0.3454  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1070/1142]  eta: 0:00:24  Lr: 0.030000  Loss: 0.3228  Acc@1: 56.2500 (59.7747)  Acc@5: 87.5000 (91.8417)  time: 0.3449  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [1080/1142]  eta: 0:00:21  Lr: 0.030000  Loss: -0.2069  Acc@1: 62.5000 (59.8693)  Acc@5: 93.7500 (91.8652)  time: 0.3435  data: 0.0002  max mem: 2500
Train: Epoch[4/5]  [1090/1142]  eta: 0:00:17  Lr: 0.030000  Loss: 0.0056  Acc@1: 62.5000 (59.8705)  Acc@5: 93.7500 (91.8538)  time: 0.3436  data: 0.0002  max mem: 2500
Train: Epoch[4/5]  [1100/1142]  eta: 0:00:14  Lr: 0.030000  Loss: 0.1935  Acc@1: 62.5000 (59.8944)  Acc@5: 87.5000 (91.8426)  time: 0.3437  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [1110/1142]  eta: 0:00:11  Lr: 0.030000  Loss: 0.4764  Acc@1: 56.2500 (59.8335)  Acc@5: 87.5000 (91.8092)  time: 0.3439  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [1120/1142]  eta: 0:00:07  Lr: 0.030000  Loss: 0.2445  Acc@1: 56.2500 (59.8517)  Acc@5: 93.7500 (91.8265)  time: 0.3439  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [1130/1142]  eta: 0:00:04  Lr: 0.030000  Loss: -0.2137  Acc@1: 62.5000 (59.8420)  Acc@5: 93.7500 (91.8159)  time: 0.3439  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [1140/1142]  eta: 0:00:00  Lr: 0.030000  Loss: 0.0116  Acc@1: 62.5000 (59.8652)  Acc@5: 93.7500 (91.8328)  time: 0.3449  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [1141/1142]  eta: 0:00:00  Lr: 0.030000  Loss: 0.1791  Acc@1: 62.5000 (59.8577)  Acc@5: 93.7500 (91.8314)  time: 0.3377  data: 0.0003  max mem: 2500
Train: Epoch[4/5] Total time: 0:06:34 (0.3452 s / it)
{0: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 1: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 2: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 3: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 4: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 5: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 6: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 7: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 8: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 9: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 10: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 11: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 12: {0: 0, 1: 0, 2: 0, 3: 73060, 4: 0}, 13: {0: 0, 1: 0, 2: 0, 3: 73060, 4: 0}, 14: {0: 0, 1: 0, 2: 0, 3: 73060, 4: 0}, 15: {0: 0, 1: 0, 2: 0, 3: 73060, 4: 0}, 16: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 17: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 18: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 19: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}}
Averaged stats: Lr: 0.030000  Loss: 0.1791  Acc@1: 62.5000 (59.8577)  Acc@5: 93.7500 (91.8314)
Train: Epoch[5/5]  [   0/1142]  eta: 0:13:04  Lr: 0.030000  Loss: 0.2003  Acc@1: 56.2500 (56.2500)  Acc@5: 87.5000 (87.5000)  time: 0.6871  data: 0.3244  max mem: 2500
Train: Epoch[5/5]  [  10/1142]  eta: 0:07:06  Lr: 0.030000  Loss: -0.0028  Acc@1: 62.5000 (63.6364)  Acc@5: 87.5000 (92.0455)  time: 0.3771  data: 0.0299  max mem: 2500
Train: Epoch[5/5]  [  20/1142]  eta: 0:06:47  Lr: 0.030000  Loss: 0.1089  Acc@1: 62.5000 (64.2857)  Acc@5: 87.5000 (91.3690)  time: 0.3466  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [  30/1142]  eta: 0:06:38  Lr: 0.030000  Loss: 0.4448  Acc@1: 62.5000 (62.0968)  Acc@5: 93.7500 (91.3306)  time: 0.3476  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [  40/1142]  eta: 0:06:31  Lr: 0.030000  Loss: 0.2159  Acc@1: 50.0000 (59.7561)  Acc@5: 93.7500 (91.1585)  time: 0.3479  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [  50/1142]  eta: 0:06:26  Lr: 0.030000  Loss: 0.0861  Acc@1: 50.0000 (59.5588)  Acc@5: 87.5000 (91.4216)  time: 0.3478  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [  60/1142]  eta: 0:06:21  Lr: 0.030000  Loss: 0.1085  Acc@1: 56.2500 (59.4262)  Acc@5: 93.7500 (91.3934)  time: 0.3472  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [  70/1142]  eta: 0:06:17  Lr: 0.030000  Loss: -0.3276  Acc@1: 56.2500 (60.2113)  Acc@5: 93.7500 (91.4613)  time: 0.3469  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [  80/1142]  eta: 0:06:12  Lr: 0.030000  Loss: -0.0574  Acc@1: 68.7500 (60.1080)  Acc@5: 93.7500 (91.5123)  time: 0.3461  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [  90/1142]  eta: 0:06:08  Lr: 0.030000  Loss: -0.1085  Acc@1: 62.5000 (60.5769)  Acc@5: 93.7500 (92.0330)  time: 0.3452  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 100/1142]  eta: 0:06:04  Lr: 0.030000  Loss: 0.2077  Acc@1: 62.5000 (60.5817)  Acc@5: 93.7500 (92.1411)  time: 0.3467  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 110/1142]  eta: 0:06:01  Lr: 0.030000  Loss: 0.1267  Acc@1: 56.2500 (59.9099)  Acc@5: 93.7500 (92.1171)  time: 0.3469  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 120/1142]  eta: 0:05:57  Lr: 0.030000  Loss: 0.2841  Acc@1: 56.2500 (59.6074)  Acc@5: 93.7500 (92.0455)  time: 0.3465  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [ 130/1142]  eta: 0:05:53  Lr: 0.030000  Loss: 0.1679  Acc@1: 62.5000 (59.5897)  Acc@5: 93.7500 (92.0802)  time: 0.3459  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 140/1142]  eta: 0:05:49  Lr: 0.030000  Loss: 0.2273  Acc@1: 62.5000 (59.7074)  Acc@5: 93.7500 (92.2429)  time: 0.3452  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [ 150/1142]  eta: 0:05:45  Lr: 0.030000  Loss: 0.0608  Acc@1: 56.2500 (59.2715)  Acc@5: 93.7500 (92.3013)  time: 0.3454  data: 0.0002  max mem: 2500
Train: Epoch[5/5]  [ 160/1142]  eta: 0:05:42  Lr: 0.030000  Loss: 0.2850  Acc@1: 56.2500 (58.8509)  Acc@5: 93.7500 (92.1196)  time: 0.3461  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [ 170/1142]  eta: 0:05:38  Lr: 0.030000  Loss: 0.0876  Acc@1: 56.2500 (58.6623)  Acc@5: 93.7500 (92.1784)  time: 0.3459  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [ 180/1142]  eta: 0:05:34  Lr: 0.030000  Loss: -0.1189  Acc@1: 56.2500 (58.8052)  Acc@5: 93.7500 (92.1271)  time: 0.3446  data: 0.0002  max mem: 2500
Train: Epoch[5/5]  [ 190/1142]  eta: 0:05:31  Lr: 0.030000  Loss: -0.0790  Acc@1: 56.2500 (58.9005)  Acc@5: 93.7500 (92.2775)  time: 0.3453  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [ 200/1142]  eta: 0:05:27  Lr: 0.030000  Loss: 0.3119  Acc@1: 62.5000 (58.9863)  Acc@5: 93.7500 (92.1020)  time: 0.3447  data: 0.0002  max mem: 2500
Train: Epoch[5/5]  [ 210/1142]  eta: 0:05:24  Lr: 0.030000  Loss: -0.0847  Acc@1: 62.5000 (59.2417)  Acc@5: 93.7500 (92.2393)  time: 0.3436  data: 0.0002  max mem: 2500
Train: Epoch[5/5]  [ 220/1142]  eta: 0:05:20  Lr: 0.030000  Loss: 0.0599  Acc@1: 68.7500 (59.5871)  Acc@5: 93.7500 (92.2229)  time: 0.3437  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [ 230/1142]  eta: 0:05:16  Lr: 0.030000  Loss: 0.1929  Acc@1: 62.5000 (59.7132)  Acc@5: 93.7500 (92.3160)  time: 0.3446  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [ 240/1142]  eta: 0:05:13  Lr: 0.030000  Loss: 0.0712  Acc@1: 62.5000 (59.7770)  Acc@5: 93.7500 (92.4015)  time: 0.3455  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [ 250/1142]  eta: 0:05:09  Lr: 0.030000  Loss: -0.0483  Acc@1: 62.5000 (59.6863)  Acc@5: 93.7500 (92.3058)  time: 0.3454  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 260/1142]  eta: 0:05:06  Lr: 0.030000  Loss: 0.2481  Acc@1: 62.5000 (59.6504)  Acc@5: 87.5000 (92.3372)  time: 0.3458  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 270/1142]  eta: 0:05:02  Lr: 0.030000  Loss: -0.0401  Acc@1: 62.5000 (59.9631)  Acc@5: 93.7500 (92.5046)  time: 0.3458  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 280/1142]  eta: 0:04:59  Lr: 0.030000  Loss: 0.1376  Acc@1: 68.7500 (60.1868)  Acc@5: 100.0000 (92.6379)  time: 0.3454  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 290/1142]  eta: 0:04:55  Lr: 0.030000  Loss: -0.1611  Acc@1: 62.5000 (60.3308)  Acc@5: 93.7500 (92.6976)  time: 0.3450  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [ 300/1142]  eta: 0:04:52  Lr: 0.030000  Loss: -0.0929  Acc@1: 62.5000 (60.3405)  Acc@5: 93.7500 (92.6080)  time: 0.3443  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [ 310/1142]  eta: 0:04:48  Lr: 0.030000  Loss: 0.0693  Acc@1: 62.5000 (60.3095)  Acc@5: 93.7500 (92.5844)  time: 0.3442  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [ 320/1142]  eta: 0:04:45  Lr: 0.030000  Loss: 0.1051  Acc@1: 56.2500 (60.2609)  Acc@5: 93.7500 (92.5818)  time: 0.3442  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [ 330/1142]  eta: 0:04:41  Lr: 0.030000  Loss: 0.0986  Acc@1: 56.2500 (60.1586)  Acc@5: 93.7500 (92.5604)  time: 0.3444  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [ 340/1142]  eta: 0:04:37  Lr: 0.030000  Loss: 0.0745  Acc@1: 62.5000 (60.1906)  Acc@5: 93.7500 (92.5403)  time: 0.3437  data: 0.0002  max mem: 2500
Train: Epoch[5/5]  [ 350/1142]  eta: 0:04:34  Lr: 0.030000  Loss: 0.1036  Acc@1: 62.5000 (60.2742)  Acc@5: 93.7500 (92.5036)  time: 0.3425  data: 0.0002  max mem: 2500
Train: Epoch[5/5]  [ 360/1142]  eta: 0:04:30  Lr: 0.030000  Loss: -0.0929  Acc@1: 62.5000 (60.5090)  Acc@5: 93.7500 (92.5381)  time: 0.3426  data: 0.0002  max mem: 2500
Train: Epoch[5/5]  [ 370/1142]  eta: 0:04:27  Lr: 0.030000  Loss: 0.0700  Acc@1: 68.7500 (60.6132)  Acc@5: 93.7500 (92.5708)  time: 0.3430  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [ 380/1142]  eta: 0:04:23  Lr: 0.030000  Loss: 0.0038  Acc@1: 62.5000 (60.6463)  Acc@5: 93.7500 (92.5853)  time: 0.3439  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 390/1142]  eta: 0:04:20  Lr: 0.030000  Loss: -0.1304  Acc@1: 62.5000 (60.8696)  Acc@5: 93.7500 (92.6950)  time: 0.3444  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 400/1142]  eta: 0:04:16  Lr: 0.030000  Loss: 0.1874  Acc@1: 62.5000 (60.8946)  Acc@5: 93.7500 (92.6590)  time: 0.3447  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 410/1142]  eta: 0:04:13  Lr: 0.030000  Loss: 0.1714  Acc@1: 62.5000 (60.9185)  Acc@5: 87.5000 (92.6095)  time: 0.3453  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 420/1142]  eta: 0:04:09  Lr: 0.030000  Loss: 0.2271  Acc@1: 56.2500 (60.7631)  Acc@5: 93.7500 (92.6663)  time: 0.3448  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [ 430/1142]  eta: 0:04:06  Lr: 0.030000  Loss: 0.1105  Acc@1: 56.2500 (60.8469)  Acc@5: 93.7500 (92.6769)  time: 0.3440  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [ 440/1142]  eta: 0:04:02  Lr: 0.030000  Loss: 0.1281  Acc@1: 62.5000 (60.7993)  Acc@5: 93.7500 (92.6446)  time: 0.3445  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [ 450/1142]  eta: 0:03:59  Lr: 0.030000  Loss: 0.1185  Acc@1: 62.5000 (60.7677)  Acc@5: 93.7500 (92.6414)  time: 0.3451  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [ 460/1142]  eta: 0:03:55  Lr: 0.030000  Loss: -0.0566  Acc@1: 62.5000 (60.7104)  Acc@5: 93.7500 (92.6383)  time: 0.3451  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 470/1142]  eta: 0:03:52  Lr: 0.030000  Loss: 0.1653  Acc@1: 62.5000 (60.7617)  Acc@5: 87.5000 (92.5690)  time: 0.3448  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [ 480/1142]  eta: 0:03:49  Lr: 0.030000  Loss: 0.2613  Acc@1: 62.5000 (60.8238)  Acc@5: 87.5000 (92.5676)  time: 0.3453  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [ 490/1142]  eta: 0:03:45  Lr: 0.030000  Loss: -0.0872  Acc@1: 62.5000 (60.9725)  Acc@5: 93.7500 (92.6171)  time: 0.3445  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [ 500/1142]  eta: 0:03:42  Lr: 0.030000  Loss: 0.3116  Acc@1: 62.5000 (60.8658)  Acc@5: 93.7500 (92.5649)  time: 0.3430  data: 0.0002  max mem: 2500
Train: Epoch[5/5]  [ 510/1142]  eta: 0:03:38  Lr: 0.030000  Loss: -0.0877  Acc@1: 56.2500 (60.8855)  Acc@5: 93.7500 (92.6003)  time: 0.3429  data: 0.0002  max mem: 2500
Train: Epoch[5/5]  [ 520/1142]  eta: 0:03:35  Lr: 0.030000  Loss: -0.2390  Acc@1: 62.5000 (60.9645)  Acc@5: 93.7500 (92.6344)  time: 0.3429  data: 0.0002  max mem: 2500
Train: Epoch[5/5]  [ 530/1142]  eta: 0:03:31  Lr: 0.030000  Loss: 0.0548  Acc@1: 62.5000 (60.9581)  Acc@5: 93.7500 (92.6318)  time: 0.3428  data: 0.0002  max mem: 2500
Train: Epoch[5/5]  [ 540/1142]  eta: 0:03:28  Lr: 0.030000  Loss: -0.1621  Acc@1: 56.2500 (60.9866)  Acc@5: 93.7500 (92.6294)  time: 0.3426  data: 0.0002  max mem: 2500
Train: Epoch[5/5]  [ 550/1142]  eta: 0:03:24  Lr: 0.030000  Loss: -0.0911  Acc@1: 56.2500 (60.9687)  Acc@5: 93.7500 (92.6044)  time: 0.3429  data: 0.0002  max mem: 2500
Train: Epoch[5/5]  [ 560/1142]  eta: 0:03:21  Lr: 0.030000  Loss: 0.2217  Acc@1: 62.5000 (61.0740)  Acc@5: 87.5000 (92.5802)  time: 0.3430  data: 0.0002  max mem: 2500
Train: Epoch[5/5]  [ 570/1142]  eta: 0:03:17  Lr: 0.030000  Loss: 0.0418  Acc@1: 68.7500 (61.1427)  Acc@5: 93.7500 (92.5788)  time: 0.3433  data: 0.0002  max mem: 2500
Train: Epoch[5/5]  [ 580/1142]  eta: 0:03:14  Lr: 0.030000  Loss: 0.1150  Acc@1: 62.5000 (61.1661)  Acc@5: 93.7500 (92.6420)  time: 0.3452  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [ 590/1142]  eta: 0:03:10  Lr: 0.030000  Loss: -0.0126  Acc@1: 62.5000 (61.1464)  Acc@5: 93.7500 (92.6079)  time: 0.3459  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 600/1142]  eta: 0:03:07  Lr: 0.030000  Loss: 0.1516  Acc@1: 56.2500 (61.0961)  Acc@5: 93.7500 (92.5437)  time: 0.3454  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [ 610/1142]  eta: 0:03:03  Lr: 0.030000  Loss: 0.4478  Acc@1: 56.2500 (61.0475)  Acc@5: 93.7500 (92.5225)  time: 0.3466  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 620/1142]  eta: 0:03:00  Lr: 0.030000  Loss: 0.0590  Acc@1: 62.5000 (61.0507)  Acc@5: 93.7500 (92.5121)  time: 0.3460  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [ 630/1142]  eta: 0:02:56  Lr: 0.030000  Loss: 0.4241  Acc@1: 68.7500 (61.1727)  Acc@5: 93.7500 (92.5416)  time: 0.3466  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [ 640/1142]  eta: 0:02:53  Lr: 0.030000  Loss: -0.2403  Acc@1: 68.7500 (61.2129)  Acc@5: 93.7500 (92.5507)  time: 0.3481  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 650/1142]  eta: 0:02:50  Lr: 0.030000  Loss: -0.1903  Acc@1: 62.5000 (61.2327)  Acc@5: 93.7500 (92.5595)  time: 0.3461  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [ 660/1142]  eta: 0:02:46  Lr: 0.030000  Loss: 0.0521  Acc@1: 62.5000 (61.1952)  Acc@5: 93.7500 (92.5492)  time: 0.3463  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [ 670/1142]  eta: 0:02:43  Lr: 0.030000  Loss: 0.3043  Acc@1: 62.5000 (61.2612)  Acc@5: 93.7500 (92.5671)  time: 0.3473  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [ 680/1142]  eta: 0:02:39  Lr: 0.030000  Loss: -0.2459  Acc@1: 62.5000 (61.2794)  Acc@5: 93.7500 (92.5294)  time: 0.3463  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 690/1142]  eta: 0:02:36  Lr: 0.030000  Loss: -0.1332  Acc@1: 62.5000 (61.3603)  Acc@5: 93.7500 (92.6013)  time: 0.3454  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [ 700/1142]  eta: 0:02:32  Lr: 0.030000  Loss: 0.0827  Acc@1: 68.7500 (61.3855)  Acc@5: 93.7500 (92.6177)  time: 0.3452  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [ 710/1142]  eta: 0:02:29  Lr: 0.030000  Loss: 0.0811  Acc@1: 62.5000 (61.4100)  Acc@5: 93.7500 (92.5721)  time: 0.3460  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [ 720/1142]  eta: 0:02:25  Lr: 0.030000  Loss: -0.0366  Acc@1: 62.5000 (61.4424)  Acc@5: 93.7500 (92.6058)  time: 0.3458  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [ 730/1142]  eta: 0:02:22  Lr: 0.030000  Loss: 0.2676  Acc@1: 56.2500 (61.3800)  Acc@5: 93.7500 (92.5445)  time: 0.3502  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 740/1142]  eta: 0:02:18  Lr: 0.030000  Loss: 0.0994  Acc@1: 62.5000 (61.3951)  Acc@5: 87.5000 (92.5692)  time: 0.3496  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [ 750/1142]  eta: 0:02:15  Lr: 0.030000  Loss: 0.1972  Acc@1: 68.7500 (61.3765)  Acc@5: 93.7500 (92.5599)  time: 0.3444  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [ 760/1142]  eta: 0:02:12  Lr: 0.030000  Loss: -0.0145  Acc@1: 56.2500 (61.3338)  Acc@5: 93.7500 (92.5920)  time: 0.3445  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [ 770/1142]  eta: 0:02:08  Lr: 0.030000  Loss: -0.1250  Acc@1: 56.2500 (61.3489)  Acc@5: 93.7500 (92.6151)  time: 0.3452  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [ 780/1142]  eta: 0:02:05  Lr: 0.030000  Loss: -0.0558  Acc@1: 62.5000 (61.3476)  Acc@5: 93.7500 (92.6617)  time: 0.3456  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [ 790/1142]  eta: 0:02:01  Lr: 0.030000  Loss: 0.1849  Acc@1: 62.5000 (61.3543)  Acc@5: 93.7500 (92.6359)  time: 0.3450  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [ 800/1142]  eta: 0:01:58  Lr: 0.030000  Loss: 0.0407  Acc@1: 62.5000 (61.3062)  Acc@5: 93.7500 (92.6498)  time: 0.3449  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [ 810/1142]  eta: 0:01:54  Lr: 0.030000  Loss: 0.1620  Acc@1: 62.5000 (61.2978)  Acc@5: 93.7500 (92.6788)  time: 0.3458  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [ 820/1142]  eta: 0:01:51  Lr: 0.030000  Loss: 0.0324  Acc@1: 62.5000 (61.3124)  Acc@5: 93.7500 (92.6538)  time: 0.3449  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [ 830/1142]  eta: 0:01:47  Lr: 0.030000  Loss: 0.2422  Acc@1: 62.5000 (61.2966)  Acc@5: 87.5000 (92.6218)  time: 0.3428  data: 0.0002  max mem: 2500
Train: Epoch[5/5]  [ 840/1142]  eta: 0:01:44  Lr: 0.030000  Loss: -0.0355  Acc@1: 62.5000 (61.3332)  Acc@5: 93.7500 (92.6130)  time: 0.3428  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [ 850/1142]  eta: 0:01:40  Lr: 0.030000  Loss: -0.0447  Acc@1: 68.7500 (61.4424)  Acc@5: 93.7500 (92.6043)  time: 0.3430  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [ 860/1142]  eta: 0:01:37  Lr: 0.030000  Loss: 0.0091  Acc@1: 68.7500 (61.5128)  Acc@5: 93.7500 (92.6031)  time: 0.3430  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [ 870/1142]  eta: 0:01:33  Lr: 0.030000  Loss: -0.0051  Acc@1: 62.5000 (61.5528)  Acc@5: 93.7500 (92.6162)  time: 0.3428  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [ 880/1142]  eta: 0:01:30  Lr: 0.030000  Loss: -0.1652  Acc@1: 62.5000 (61.5919)  Acc@5: 93.7500 (92.6220)  time: 0.3428  data: 0.0002  max mem: 2500
Train: Epoch[5/5]  [ 890/1142]  eta: 0:01:27  Lr: 0.030000  Loss: 0.3106  Acc@1: 62.5000 (61.5741)  Acc@5: 93.7500 (92.6277)  time: 0.3430  data: 0.0002  max mem: 2500
Train: Epoch[5/5]  [ 900/1142]  eta: 0:01:23  Lr: 0.030000  Loss: 0.4459  Acc@1: 56.2500 (61.5913)  Acc@5: 93.7500 (92.6540)  time: 0.3433  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [ 910/1142]  eta: 0:01:20  Lr: 0.030000  Loss: 0.2651  Acc@1: 56.2500 (61.5875)  Acc@5: 93.7500 (92.6592)  time: 0.3449  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 920/1142]  eta: 0:01:16  Lr: 0.030000  Loss: -0.0911  Acc@1: 62.5000 (61.6178)  Acc@5: 93.7500 (92.6371)  time: 0.3459  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 930/1142]  eta: 0:01:13  Lr: 0.030000  Loss: -0.0986  Acc@1: 62.5000 (61.6340)  Acc@5: 93.7500 (92.6222)  time: 0.3457  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 940/1142]  eta: 0:01:09  Lr: 0.030000  Loss: 0.0953  Acc@1: 62.5000 (61.6698)  Acc@5: 93.7500 (92.6408)  time: 0.3454  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 950/1142]  eta: 0:01:06  Lr: 0.030000  Loss: -0.3048  Acc@1: 62.5000 (61.6522)  Acc@5: 93.7500 (92.6919)  time: 0.3444  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 960/1142]  eta: 0:01:02  Lr: 0.030000  Loss: 0.2475  Acc@1: 62.5000 (61.6675)  Acc@5: 93.7500 (92.7029)  time: 0.3440  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 970/1142]  eta: 0:00:59  Lr: 0.030000  Loss: 0.2181  Acc@1: 62.5000 (61.6825)  Acc@5: 93.7500 (92.7073)  time: 0.3448  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 980/1142]  eta: 0:00:55  Lr: 0.030000  Loss: 0.1186  Acc@1: 68.7500 (61.7546)  Acc@5: 93.7500 (92.7115)  time: 0.3457  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [ 990/1142]  eta: 0:00:52  Lr: 0.030000  Loss: 0.2414  Acc@1: 62.5000 (61.6864)  Acc@5: 87.5000 (92.6715)  time: 0.3459  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1000/1142]  eta: 0:00:49  Lr: 0.030000  Loss: 0.2951  Acc@1: 50.0000 (61.6196)  Acc@5: 93.7500 (92.6823)  time: 0.3454  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1010/1142]  eta: 0:00:45  Lr: 0.030000  Loss: 0.1315  Acc@1: 62.5000 (61.6345)  Acc@5: 93.7500 (92.6311)  time: 0.3455  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1020/1142]  eta: 0:00:42  Lr: 0.030000  Loss: -0.2661  Acc@1: 62.5000 (61.6797)  Acc@5: 93.7500 (92.6420)  time: 0.3456  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1030/1142]  eta: 0:00:38  Lr: 0.030000  Loss: 0.0758  Acc@1: 62.5000 (61.6998)  Acc@5: 93.7500 (92.6164)  time: 0.3471  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1040/1142]  eta: 0:00:35  Lr: 0.030000  Loss: 0.2765  Acc@1: 62.5000 (61.6895)  Acc@5: 87.5000 (92.5853)  time: 0.3485  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1050/1142]  eta: 0:00:31  Lr: 0.030000  Loss: -0.0796  Acc@1: 62.5000 (61.6615)  Acc@5: 87.5000 (92.5607)  time: 0.3464  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1060/1142]  eta: 0:00:28  Lr: 0.030000  Loss: -0.1085  Acc@1: 62.5000 (61.6989)  Acc@5: 93.7500 (92.5483)  time: 0.3454  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1070/1142]  eta: 0:00:24  Lr: 0.030000  Loss: 0.0630  Acc@1: 68.7500 (61.7297)  Acc@5: 93.7500 (92.5595)  time: 0.3451  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [1080/1142]  eta: 0:00:21  Lr: 0.030000  Loss: 0.3039  Acc@1: 62.5000 (61.6906)  Acc@5: 93.7500 (92.5590)  time: 0.3445  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [1090/1142]  eta: 0:00:17  Lr: 0.030000  Loss: -0.1248  Acc@1: 62.5000 (61.6923)  Acc@5: 93.7500 (92.5527)  time: 0.3449  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [1100/1142]  eta: 0:00:14  Lr: 0.030000  Loss: -0.1833  Acc@1: 62.5000 (61.7393)  Acc@5: 93.7500 (92.5693)  time: 0.3449  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [1110/1142]  eta: 0:00:11  Lr: 0.030000  Loss: -0.0149  Acc@1: 62.5000 (61.7068)  Acc@5: 93.7500 (92.5743)  time: 0.3445  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [1120/1142]  eta: 0:00:07  Lr: 0.030000  Loss: 0.2162  Acc@1: 62.5000 (61.6971)  Acc@5: 93.7500 (92.5847)  time: 0.3442  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [1130/1142]  eta: 0:00:04  Lr: 0.030000  Loss: 0.0542  Acc@1: 62.5000 (61.6600)  Acc@5: 93.7500 (92.5950)  time: 0.3445  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [1140/1142]  eta: 0:00:00  Lr: 0.030000  Loss: 0.3118  Acc@1: 62.5000 (61.6729)  Acc@5: 93.7500 (92.5833)  time: 0.3446  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1141/1142]  eta: 0:00:00  Lr: 0.030000  Loss: -0.2798  Acc@1: 62.5000 (61.6863)  Acc@5: 93.7500 (92.5869)  time: 0.3371  data: 0.0004  max mem: 2500
Train: Epoch[5/5] Total time: 0:06:34 (0.3454 s / it)
{0: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 1: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 2: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 3: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 4: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 5: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 6: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 7: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 8: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 9: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 10: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 11: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 12: {0: 0, 1: 0, 2: 0, 3: 91325, 4: 0}, 13: {0: 0, 1: 0, 2: 0, 3: 91325, 4: 0}, 14: {0: 0, 1: 0, 2: 0, 3: 91325, 4: 0}, 15: {0: 0, 1: 0, 2: 0, 3: 91325, 4: 0}, 16: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 17: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 18: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 19: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}}
Averaged stats: Lr: 0.030000  Loss: -0.2798  Acc@1: 62.5000 (61.6863)  Acc@5: 93.7500 (92.5869)
Test: [Task 1]  [   0/1627]  eta: 0:11:28  Loss: 2.5126 (2.5126)  Acc@1: 87.5000 (87.5000)  Acc@5: 93.7500 (93.7500)  time: 0.4233  data: 0.2100  max mem: 2500
Test: [Task 1]  [  10/1627]  eta: 0:06:15  Loss: 2.4349 (2.4199)  Acc@1: 87.5000 (84.0909)  Acc@5: 93.7500 (96.0227)  time: 0.2321  data: 0.0193  max mem: 2500
Test: [Task 1]  [  20/1627]  eta: 0:05:58  Loss: 2.4324 (2.4459)  Acc@1: 81.2500 (83.0357)  Acc@5: 93.7500 (95.2381)  time: 0.2129  data: 0.0002  max mem: 2500
Test: [Task 1]  [  30/1627]  eta: 0:05:50  Loss: 2.4842 (2.4571)  Acc@1: 81.2500 (82.6613)  Acc@5: 100.0000 (96.1694)  time: 0.2130  data: 0.0002  max mem: 2500
Test: [Task 1]  [  40/1627]  eta: 0:05:46  Loss: 2.5051 (2.4725)  Acc@1: 81.2500 (81.5549)  Acc@5: 100.0000 (96.0366)  time: 0.2129  data: 0.0002  max mem: 2500
Test: [Task 1]  [  50/1627]  eta: 0:05:42  Loss: 2.4413 (2.4654)  Acc@1: 81.2500 (81.7402)  Acc@5: 100.0000 (96.0784)  time: 0.2130  data: 0.0002  max mem: 2500
Test: [Task 1]  [  60/1627]  eta: 0:05:39  Loss: 2.4418 (2.4694)  Acc@1: 81.2500 (81.5574)  Acc@5: 93.7500 (95.5943)  time: 0.2131  data: 0.0003  max mem: 2500
Test: [Task 1]  [  70/1627]  eta: 0:05:36  Loss: 2.4554 (2.4720)  Acc@1: 81.2500 (81.1620)  Acc@5: 93.7500 (95.9507)  time: 0.2128  data: 0.0002  max mem: 2500
Test: [Task 1]  [  80/1627]  eta: 0:05:33  Loss: 2.4176 (2.4695)  Acc@1: 81.2500 (81.4043)  Acc@5: 100.0000 (96.2963)  time: 0.2137  data: 0.0003  max mem: 2500
Test: [Task 1]  [  90/1627]  eta: 0:05:31  Loss: 2.4323 (2.4701)  Acc@1: 81.2500 (80.9753)  Acc@5: 100.0000 (96.0852)  time: 0.2145  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 100/1627]  eta: 0:05:29  Loss: 2.4924 (2.4785)  Acc@1: 75.0000 (80.4455)  Acc@5: 93.7500 (95.8540)  time: 0.2143  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 110/1627]  eta: 0:05:26  Loss: 2.4729 (2.4782)  Acc@1: 81.2500 (80.5743)  Acc@5: 93.7500 (96.0023)  time: 0.2140  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 120/1627]  eta: 0:05:24  Loss: 2.4378 (2.4785)  Acc@1: 87.5000 (80.5785)  Acc@5: 100.0000 (96.0744)  time: 0.2140  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 130/1627]  eta: 0:05:22  Loss: 2.4438 (2.4751)  Acc@1: 87.5000 (80.7252)  Acc@5: 100.0000 (96.0401)  time: 0.2151  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 140/1627]  eta: 0:05:20  Loss: 2.4429 (2.4737)  Acc@1: 81.2500 (80.7624)  Acc@5: 100.0000 (96.1436)  time: 0.2159  data: 0.0005  max mem: 2500
Test: [Task 1]  [ 150/1627]  eta: 0:05:17  Loss: 2.3393 (2.4658)  Acc@1: 87.5000 (81.0430)  Acc@5: 100.0000 (96.1507)  time: 0.2149  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 160/1627]  eta: 0:05:15  Loss: 2.3532 (2.4654)  Acc@1: 87.5000 (81.1724)  Acc@5: 100.0000 (96.3121)  time: 0.2141  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 170/1627]  eta: 0:05:13  Loss: 2.4277 (2.4628)  Acc@1: 87.5000 (81.3596)  Acc@5: 100.0000 (96.4547)  time: 0.2146  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 180/1627]  eta: 0:05:11  Loss: 2.4277 (2.4647)  Acc@1: 81.2500 (81.2155)  Acc@5: 100.0000 (96.4434)  time: 0.2147  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 190/1627]  eta: 0:05:09  Loss: 2.4591 (2.4632)  Acc@1: 81.2500 (81.2500)  Acc@5: 93.7500 (96.4005)  time: 0.2141  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 200/1627]  eta: 0:05:06  Loss: 2.4596 (2.4624)  Acc@1: 81.2500 (81.1256)  Acc@5: 100.0000 (96.4863)  time: 0.2140  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 210/1627]  eta: 0:05:04  Loss: 2.4437 (2.4602)  Acc@1: 81.2500 (81.2796)  Acc@5: 100.0000 (96.4751)  time: 0.2144  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 220/1627]  eta: 0:05:02  Loss: 2.4087 (2.4608)  Acc@1: 81.2500 (81.1086)  Acc@5: 100.0000 (96.5498)  time: 0.2144  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 230/1627]  eta: 0:05:00  Loss: 2.4383 (2.4606)  Acc@1: 81.2500 (81.2771)  Acc@5: 100.0000 (96.4827)  time: 0.2139  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 240/1627]  eta: 0:04:57  Loss: 2.4047 (2.4598)  Acc@1: 81.2500 (81.3537)  Acc@5: 93.7500 (96.4990)  time: 0.2138  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 250/1627]  eta: 0:04:55  Loss: 2.3868 (2.4577)  Acc@1: 81.2500 (81.2749)  Acc@5: 100.0000 (96.4890)  time: 0.2138  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 260/1627]  eta: 0:04:53  Loss: 2.4136 (2.4588)  Acc@1: 81.2500 (81.2979)  Acc@5: 100.0000 (96.4320)  time: 0.2139  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 270/1627]  eta: 0:04:51  Loss: 2.4249 (2.4560)  Acc@1: 87.5000 (81.4345)  Acc@5: 100.0000 (96.4714)  time: 0.2142  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 280/1627]  eta: 0:04:49  Loss: 2.4239 (2.4564)  Acc@1: 81.2500 (81.3167)  Acc@5: 100.0000 (96.4635)  time: 0.2140  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 290/1627]  eta: 0:04:47  Loss: 2.4239 (2.4558)  Acc@1: 81.2500 (81.3789)  Acc@5: 93.7500 (96.4777)  time: 0.2139  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 300/1627]  eta: 0:04:44  Loss: 2.4292 (2.4554)  Acc@1: 81.2500 (81.3331)  Acc@5: 100.0000 (96.4909)  time: 0.2140  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 310/1627]  eta: 0:04:42  Loss: 2.4535 (2.4544)  Acc@1: 81.2500 (81.3907)  Acc@5: 100.0000 (96.4630)  time: 0.2139  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 320/1627]  eta: 0:04:40  Loss: 2.4509 (2.4555)  Acc@1: 81.2500 (81.3863)  Acc@5: 100.0000 (96.5343)  time: 0.2144  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 330/1627]  eta: 0:04:38  Loss: 2.4209 (2.4559)  Acc@1: 81.2500 (81.3444)  Acc@5: 100.0000 (96.5446)  time: 0.2139  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 340/1627]  eta: 0:04:36  Loss: 2.4481 (2.4576)  Acc@1: 81.2500 (81.3600)  Acc@5: 100.0000 (96.5543)  time: 0.2129  data: 0.0002  max mem: 2500
Test: [Task 1]  [ 350/1627]  eta: 0:04:33  Loss: 2.4751 (2.4577)  Acc@1: 81.2500 (81.3568)  Acc@5: 100.0000 (96.5634)  time: 0.2130  data: 0.0002  max mem: 2500
Test: [Task 1]  [ 360/1627]  eta: 0:04:31  Loss: 2.4751 (2.4594)  Acc@1: 81.2500 (81.2327)  Acc@5: 100.0000 (96.5547)  time: 0.2129  data: 0.0002  max mem: 2500
Test: [Task 1]  [ 370/1627]  eta: 0:04:29  Loss: 2.4163 (2.4577)  Acc@1: 81.2500 (81.3342)  Acc@5: 100.0000 (96.5633)  time: 0.2128  data: 0.0002  max mem: 2500
Test: [Task 1]  [ 380/1627]  eta: 0:04:27  Loss: 2.4105 (2.4574)  Acc@1: 81.2500 (81.3812)  Acc@5: 93.7500 (96.5059)  time: 0.2128  data: 0.0002  max mem: 2500
Test: [Task 1]  [ 390/1627]  eta: 0:04:25  Loss: 2.4341 (2.4575)  Acc@1: 81.2500 (81.2500)  Acc@5: 93.7500 (96.4514)  time: 0.2129  data: 0.0002  max mem: 2500
Test: [Task 1]  [ 400/1627]  eta: 0:04:22  Loss: 2.4480 (2.4567)  Acc@1: 75.0000 (81.2812)  Acc@5: 93.7500 (96.4620)  time: 0.2130  data: 0.0002  max mem: 2500
Test: [Task 1]  [ 410/1627]  eta: 0:04:20  Loss: 2.4071 (2.4563)  Acc@1: 81.2500 (81.3260)  Acc@5: 100.0000 (96.4416)  time: 0.2130  data: 0.0002  max mem: 2500
Test: [Task 1]  [ 420/1627]  eta: 0:04:18  Loss: 2.4206 (2.4557)  Acc@1: 81.2500 (81.3836)  Acc@5: 100.0000 (96.4667)  time: 0.2130  data: 0.0002  max mem: 2500
Test: [Task 1]  [ 430/1627]  eta: 0:04:16  Loss: 2.4032 (2.4543)  Acc@1: 81.2500 (81.4240)  Acc@5: 100.0000 (96.4907)  time: 0.2131  data: 0.0002  max mem: 2500
Test: [Task 1]  [ 440/1627]  eta: 0:04:14  Loss: 2.3840 (2.4537)  Acc@1: 81.2500 (81.4059)  Acc@5: 100.0000 (96.4994)  time: 0.2132  data: 0.0002  max mem: 2500
Test: [Task 1]  [ 450/1627]  eta: 0:04:12  Loss: 2.4329 (2.4552)  Acc@1: 81.2500 (81.3193)  Acc@5: 93.7500 (96.4385)  time: 0.2131  data: 0.0002  max mem: 2500
Test: [Task 1]  [ 460/1627]  eta: 0:04:09  Loss: 2.4374 (2.4553)  Acc@1: 81.2500 (81.3313)  Acc@5: 100.0000 (96.4479)  time: 0.2129  data: 0.0002  max mem: 2500
Test: [Task 1]  [ 470/1627]  eta: 0:04:07  Loss: 2.3902 (2.4544)  Acc@1: 87.5000 (81.3827)  Acc@5: 100.0000 (96.4437)  time: 0.2127  data: 0.0002  max mem: 2500
Test: [Task 1]  [ 480/1627]  eta: 0:04:05  Loss: 2.3677 (2.4547)  Acc@1: 81.2500 (81.2630)  Acc@5: 100.0000 (96.4657)  time: 0.2129  data: 0.0002  max mem: 2500
Test: [Task 1]  [ 490/1627]  eta: 0:04:03  Loss: 2.5082 (2.4555)  Acc@1: 81.2500 (81.2755)  Acc@5: 93.7500 (96.4486)  time: 0.2130  data: 0.0002  max mem: 2500
Test: [Task 1]  [ 500/1627]  eta: 0:04:01  Loss: 2.5003 (2.4561)  Acc@1: 81.2500 (81.2375)  Acc@5: 93.7500 (96.3947)  time: 0.2134  data: 0.0002  max mem: 2500
Test: [Task 1]  [ 510/1627]  eta: 0:03:59  Loss: 2.4660 (2.4574)  Acc@1: 81.2500 (81.1766)  Acc@5: 93.7500 (96.3185)  time: 0.2138  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 520/1627]  eta: 0:03:56  Loss: 2.4538 (2.4581)  Acc@1: 81.2500 (81.1780)  Acc@5: 93.7500 (96.3052)  time: 0.2141  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 530/1627]  eta: 0:03:54  Loss: 2.3895 (2.4559)  Acc@1: 87.5000 (81.2500)  Acc@5: 100.0000 (96.3395)  time: 0.2141  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 540/1627]  eta: 0:03:52  Loss: 2.3841 (2.4566)  Acc@1: 81.2500 (81.2038)  Acc@5: 100.0000 (96.3494)  time: 0.2139  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 550/1627]  eta: 0:03:50  Loss: 2.4845 (2.4578)  Acc@1: 75.0000 (81.1139)  Acc@5: 100.0000 (96.3475)  time: 0.2139  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 560/1627]  eta: 0:03:48  Loss: 2.4627 (2.4585)  Acc@1: 75.0000 (81.0606)  Acc@5: 93.7500 (96.3347)  time: 0.2141  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 570/1627]  eta: 0:03:46  Loss: 2.4061 (2.4571)  Acc@1: 81.2500 (81.1843)  Acc@5: 93.7500 (96.3660)  time: 0.2143  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 580/1627]  eta: 0:03:44  Loss: 2.3787 (2.4566)  Acc@1: 87.5000 (81.2177)  Acc@5: 100.0000 (96.3640)  time: 0.2141  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 590/1627]  eta: 0:03:41  Loss: 2.4212 (2.4565)  Acc@1: 81.2500 (81.2288)  Acc@5: 100.0000 (96.4044)  time: 0.2141  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 600/1627]  eta: 0:03:39  Loss: 2.4350 (2.4564)  Acc@1: 81.2500 (81.2500)  Acc@5: 100.0000 (96.4226)  time: 0.2145  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 610/1627]  eta: 0:03:37  Loss: 2.3802 (2.4548)  Acc@1: 81.2500 (81.3114)  Acc@5: 100.0000 (96.4403)  time: 0.2152  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 620/1627]  eta: 0:03:35  Loss: 2.3802 (2.4554)  Acc@1: 81.2500 (81.2097)  Acc@5: 100.0000 (96.4372)  time: 0.2150  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 630/1627]  eta: 0:03:33  Loss: 2.4806 (2.4555)  Acc@1: 75.0000 (81.2005)  Acc@5: 100.0000 (96.4342)  time: 0.2146  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 640/1627]  eta: 0:03:31  Loss: 2.4205 (2.4551)  Acc@1: 81.2500 (81.2110)  Acc@5: 100.0000 (96.4314)  time: 0.2153  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 650/1627]  eta: 0:03:29  Loss: 2.4801 (2.4548)  Acc@1: 81.2500 (81.1732)  Acc@5: 100.0000 (96.4478)  time: 0.2154  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 660/1627]  eta: 0:03:27  Loss: 2.4515 (2.4540)  Acc@1: 81.2500 (81.1933)  Acc@5: 100.0000 (96.4259)  time: 0.2149  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 670/1627]  eta: 0:03:24  Loss: 2.4242 (2.4542)  Acc@1: 81.2500 (81.1755)  Acc@5: 100.0000 (96.4232)  time: 0.2148  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 680/1627]  eta: 0:03:22  Loss: 2.4305 (2.4536)  Acc@1: 81.2500 (81.1949)  Acc@5: 100.0000 (96.4391)  time: 0.2148  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 690/1627]  eta: 0:03:20  Loss: 2.4074 (2.4521)  Acc@1: 81.2500 (81.2590)  Acc@5: 100.0000 (96.4725)  time: 0.2147  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 700/1627]  eta: 0:03:18  Loss: 2.4074 (2.4524)  Acc@1: 87.5000 (81.3035)  Acc@5: 100.0000 (96.4426)  time: 0.2147  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 710/1627]  eta: 0:03:16  Loss: 2.4062 (2.4517)  Acc@1: 81.2500 (81.3379)  Acc@5: 100.0000 (96.4662)  time: 0.2153  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 720/1627]  eta: 0:03:14  Loss: 2.4042 (2.4515)  Acc@1: 81.2500 (81.3540)  Acc@5: 100.0000 (96.4632)  time: 0.2153  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 730/1627]  eta: 0:03:12  Loss: 2.4063 (2.4522)  Acc@1: 81.2500 (81.3098)  Acc@5: 100.0000 (96.4603)  time: 0.2149  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 740/1627]  eta: 0:03:10  Loss: 2.5025 (2.4528)  Acc@1: 81.2500 (81.2500)  Acc@5: 93.7500 (96.4491)  time: 0.2148  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 750/1627]  eta: 0:03:07  Loss: 2.4755 (2.4526)  Acc@1: 81.2500 (81.2916)  Acc@5: 100.0000 (96.4714)  time: 0.2154  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 760/1627]  eta: 0:03:05  Loss: 2.4295 (2.4529)  Acc@1: 81.2500 (81.2993)  Acc@5: 100.0000 (96.4356)  time: 0.2154  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 770/1627]  eta: 0:03:03  Loss: 2.4295 (2.4522)  Acc@1: 81.2500 (81.3149)  Acc@5: 100.0000 (96.4656)  time: 0.2146  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 780/1627]  eta: 0:03:01  Loss: 2.3639 (2.4509)  Acc@1: 87.5000 (81.4020)  Acc@5: 100.0000 (96.4869)  time: 0.2147  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 790/1627]  eta: 0:02:59  Loss: 2.3472 (2.4515)  Acc@1: 87.5000 (81.3764)  Acc@5: 100.0000 (96.4681)  time: 0.2148  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 800/1627]  eta: 0:02:57  Loss: 2.4363 (2.4514)  Acc@1: 87.5000 (81.4217)  Acc@5: 93.7500 (96.4654)  time: 0.2148  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 810/1627]  eta: 0:02:55  Loss: 2.4113 (2.4513)  Acc@1: 87.5000 (81.4273)  Acc@5: 100.0000 (96.4704)  time: 0.2150  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 820/1627]  eta: 0:02:52  Loss: 2.4162 (2.4510)  Acc@1: 87.5000 (81.4860)  Acc@5: 100.0000 (96.5058)  time: 0.2149  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 830/1627]  eta: 0:02:50  Loss: 2.4284 (2.4517)  Acc@1: 81.2500 (81.4230)  Acc@5: 100.0000 (96.4877)  time: 0.2145  data: 0.0002  max mem: 2500
Test: [Task 1]  [ 840/1627]  eta: 0:02:48  Loss: 2.3809 (2.4506)  Acc@1: 87.5000 (81.4952)  Acc@5: 100.0000 (96.5071)  time: 0.2145  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 850/1627]  eta: 0:02:46  Loss: 2.4268 (2.4509)  Acc@1: 87.5000 (81.4777)  Acc@5: 100.0000 (96.5115)  time: 0.2147  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 860/1627]  eta: 0:02:44  Loss: 2.4649 (2.4511)  Acc@1: 81.2500 (81.5041)  Acc@5: 100.0000 (96.5302)  time: 0.2146  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 870/1627]  eta: 0:02:42  Loss: 2.3700 (2.4499)  Acc@1: 87.5000 (81.5801)  Acc@5: 100.0000 (96.5485)  time: 0.2148  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 880/1627]  eta: 0:02:40  Loss: 2.4060 (2.4510)  Acc@1: 81.2500 (81.5409)  Acc@5: 100.0000 (96.5309)  time: 0.2148  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 890/1627]  eta: 0:02:37  Loss: 2.4927 (2.4514)  Acc@1: 81.2500 (81.5236)  Acc@5: 93.7500 (96.5067)  time: 0.2140  data: 0.0002  max mem: 2500
Test: [Task 1]  [ 900/1627]  eta: 0:02:35  Loss: 2.4495 (2.4521)  Acc@1: 81.2500 (81.5136)  Acc@5: 100.0000 (96.4831)  time: 0.2135  data: 0.0002  max mem: 2500
Test: [Task 1]  [ 910/1627]  eta: 0:02:33  Loss: 2.4717 (2.4528)  Acc@1: 81.2500 (81.4627)  Acc@5: 100.0000 (96.4531)  time: 0.2134  data: 0.0002  max mem: 2500
Test: [Task 1]  [ 920/1627]  eta: 0:02:31  Loss: 2.4587 (2.4526)  Acc@1: 81.2500 (81.4739)  Acc@5: 100.0000 (96.4509)  time: 0.2138  data: 0.0002  max mem: 2500
Test: [Task 1]  [ 930/1627]  eta: 0:02:29  Loss: 2.4029 (2.4519)  Acc@1: 81.2500 (81.5118)  Acc@5: 93.7500 (96.4487)  time: 0.2137  data: 0.0002  max mem: 2500
Test: [Task 1]  [ 940/1627]  eta: 0:02:27  Loss: 2.3763 (2.4507)  Acc@1: 81.2500 (81.5622)  Acc@5: 100.0000 (96.4865)  time: 0.2135  data: 0.0002  max mem: 2500
Test: [Task 1]  [ 950/1627]  eta: 0:02:25  Loss: 2.3904 (2.4504)  Acc@1: 81.2500 (81.5457)  Acc@5: 100.0000 (96.5037)  time: 0.2135  data: 0.0002  max mem: 2500
Test: [Task 1]  [ 960/1627]  eta: 0:02:22  Loss: 2.4233 (2.4505)  Acc@1: 81.2500 (81.5687)  Acc@5: 100.0000 (96.5075)  time: 0.2133  data: 0.0002  max mem: 2500
Test: [Task 1]  [ 970/1627]  eta: 0:02:20  Loss: 2.4639 (2.4507)  Acc@1: 81.2500 (81.5783)  Acc@5: 100.0000 (96.5049)  time: 0.2133  data: 0.0002  max mem: 2500
Test: [Task 1]  [ 980/1627]  eta: 0:02:18  Loss: 2.3924 (2.4504)  Acc@1: 87.5000 (81.5877)  Acc@5: 93.7500 (96.4959)  time: 0.2133  data: 0.0002  max mem: 2500
Test: [Task 1]  [ 990/1627]  eta: 0:02:16  Loss: 2.4888 (2.4518)  Acc@1: 81.2500 (81.5464)  Acc@5: 93.7500 (96.4682)  time: 0.2137  data: 0.0002  max mem: 2500
Test: [Task 1]  [1000/1627]  eta: 0:02:14  Loss: 2.5366 (2.4520)  Acc@1: 81.2500 (81.5247)  Acc@5: 93.7500 (96.4723)  time: 0.2143  data: 0.0003  max mem: 2500
Test: [Task 1]  [1010/1627]  eta: 0:02:12  Loss: 2.3760 (2.4519)  Acc@1: 81.2500 (81.5467)  Acc@5: 93.7500 (96.4639)  time: 0.2145  data: 0.0004  max mem: 2500
Test: [Task 1]  [1020/1627]  eta: 0:02:10  Loss: 2.4068 (2.4519)  Acc@1: 81.2500 (81.5500)  Acc@5: 100.0000 (96.4863)  time: 0.2145  data: 0.0004  max mem: 2500
Test: [Task 1]  [1030/1627]  eta: 0:02:07  Loss: 2.3885 (2.4514)  Acc@1: 81.2500 (81.5713)  Acc@5: 100.0000 (96.4901)  time: 0.2146  data: 0.0004  max mem: 2500
Test: [Task 1]  [1040/1627]  eta: 0:02:05  Loss: 2.3775 (2.4507)  Acc@1: 81.2500 (81.5802)  Acc@5: 100.0000 (96.4998)  time: 0.2146  data: 0.0004  max mem: 2500
Test: [Task 1]  [1050/1627]  eta: 0:02:03  Loss: 2.4279 (2.4502)  Acc@1: 81.2500 (81.6009)  Acc@5: 100.0000 (96.5212)  time: 0.2145  data: 0.0004  max mem: 2500
Test: [Task 1]  [1060/1627]  eta: 0:02:01  Loss: 2.4648 (2.4507)  Acc@1: 81.2500 (81.5681)  Acc@5: 100.0000 (96.5068)  time: 0.2145  data: 0.0004  max mem: 2500
Test: [Task 1]  [1070/1627]  eta: 0:01:59  Loss: 2.4657 (2.4506)  Acc@1: 81.2500 (81.5768)  Acc@5: 93.7500 (96.4986)  time: 0.2148  data: 0.0004  max mem: 2500
Test: [Task 1]  [1080/1627]  eta: 0:01:57  Loss: 2.3901 (2.4507)  Acc@1: 81.2500 (81.5738)  Acc@5: 100.0000 (96.4963)  time: 0.2147  data: 0.0004  max mem: 2500
Test: [Task 1]  [1090/1627]  eta: 0:01:55  Loss: 2.4094 (2.4510)  Acc@1: 81.2500 (81.5536)  Acc@5: 100.0000 (96.4940)  time: 0.2145  data: 0.0004  max mem: 2500
Test: [Task 1]  [1100/1627]  eta: 0:01:52  Loss: 2.3871 (2.4503)  Acc@1: 81.2500 (81.6076)  Acc@5: 100.0000 (96.5145)  time: 0.2148  data: 0.0004  max mem: 2500
Test: [Task 1]  [1110/1627]  eta: 0:01:50  Loss: 2.3987 (2.4501)  Acc@1: 81.2500 (81.5932)  Acc@5: 100.0000 (96.5347)  time: 0.2152  data: 0.0004  max mem: 2500
Test: [Task 1]  [1120/1627]  eta: 0:01:48  Loss: 2.4701 (2.4507)  Acc@1: 75.0000 (81.5566)  Acc@5: 100.0000 (96.5210)  time: 0.2150  data: 0.0004  max mem: 2500
Test: [Task 1]  [1130/1627]  eta: 0:01:46  Loss: 2.4593 (2.4510)  Acc@1: 75.0000 (81.5429)  Acc@5: 100.0000 (96.5241)  time: 0.2143  data: 0.0003  max mem: 2500
Test: [Task 1]  [1140/1627]  eta: 0:01:44  Loss: 2.4593 (2.4515)  Acc@1: 81.2500 (81.5239)  Acc@5: 100.0000 (96.5217)  time: 0.2142  data: 0.0004  max mem: 2500
Test: [Task 1]  [1150/1627]  eta: 0:01:42  Loss: 2.4871 (2.4516)  Acc@1: 81.2500 (81.5324)  Acc@5: 100.0000 (96.5030)  time: 0.2143  data: 0.0004  max mem: 2500
Test: [Task 1]  [1160/1627]  eta: 0:01:40  Loss: 2.4128 (2.4514)  Acc@1: 81.2500 (81.5676)  Acc@5: 100.0000 (96.5062)  time: 0.2142  data: 0.0004  max mem: 2500
Test: [Task 1]  [1170/1627]  eta: 0:01:37  Loss: 2.3861 (2.4514)  Acc@1: 81.2500 (81.5756)  Acc@5: 100.0000 (96.5201)  time: 0.2144  data: 0.0003  max mem: 2500
Test: [Task 1]  [1180/1627]  eta: 0:01:35  Loss: 2.4596 (2.4516)  Acc@1: 81.2500 (81.5622)  Acc@5: 100.0000 (96.5284)  time: 0.2144  data: 0.0003  max mem: 2500
Test: [Task 1]  [1190/1627]  eta: 0:01:33  Loss: 2.4807 (2.4518)  Acc@1: 81.2500 (81.5491)  Acc@5: 100.0000 (96.5418)  time: 0.2146  data: 0.0003  max mem: 2500
Test: [Task 1]  [1200/1627]  eta: 0:01:31  Loss: 2.4755 (2.4516)  Acc@1: 81.2500 (81.5570)  Acc@5: 100.0000 (96.5341)  time: 0.2151  data: 0.0004  max mem: 2500
Test: [Task 1]  [1210/1627]  eta: 0:01:29  Loss: 2.4574 (2.4526)  Acc@1: 81.2500 (81.5184)  Acc@5: 93.7500 (96.5060)  time: 0.2145  data: 0.0004  max mem: 2500
Test: [Task 1]  [1220/1627]  eta: 0:01:27  Loss: 2.4799 (2.4525)  Acc@1: 81.2500 (81.5162)  Acc@5: 93.7500 (96.5090)  time: 0.2140  data: 0.0003  max mem: 2500
Test: [Task 1]  [1230/1627]  eta: 0:01:25  Loss: 2.4799 (2.4530)  Acc@1: 81.2500 (81.4734)  Acc@5: 93.7500 (96.5018)  time: 0.2141  data: 0.0003  max mem: 2500
Test: [Task 1]  [1240/1627]  eta: 0:01:22  Loss: 2.4493 (2.4530)  Acc@1: 81.2500 (81.4565)  Acc@5: 100.0000 (96.5099)  time: 0.2139  data: 0.0003  max mem: 2500
Test: [Task 1]  [1250/1627]  eta: 0:01:20  Loss: 2.4493 (2.4532)  Acc@1: 81.2500 (81.4648)  Acc@5: 100.0000 (96.4978)  time: 0.2139  data: 0.0003  max mem: 2500
Test: [Task 1]  [1260/1627]  eta: 0:01:18  Loss: 2.4314 (2.4532)  Acc@1: 87.5000 (81.4681)  Acc@5: 93.7500 (96.4958)  time: 0.2142  data: 0.0003  max mem: 2500
Test: [Task 1]  [1270/1627]  eta: 0:01:16  Loss: 2.4309 (2.4533)  Acc@1: 81.2500 (81.4319)  Acc@5: 100.0000 (96.5136)  time: 0.2140  data: 0.0003  max mem: 2500
Test: [Task 1]  [1280/1627]  eta: 0:01:14  Loss: 2.4309 (2.4529)  Acc@1: 81.2500 (81.4305)  Acc@5: 100.0000 (96.5115)  time: 0.2139  data: 0.0003  max mem: 2500
Test: [Task 1]  [1290/1627]  eta: 0:01:12  Loss: 2.4429 (2.4533)  Acc@1: 81.2500 (81.4194)  Acc@5: 100.0000 (96.5046)  time: 0.2141  data: 0.0003  max mem: 2500
Test: [Task 1]  [1300/1627]  eta: 0:01:10  Loss: 2.4429 (2.4527)  Acc@1: 81.2500 (81.4614)  Acc@5: 93.7500 (96.5075)  time: 0.2141  data: 0.0003  max mem: 2500
Test: [Task 1]  [1310/1627]  eta: 0:01:07  Loss: 2.3444 (2.4522)  Acc@1: 81.2500 (81.4788)  Acc@5: 93.7500 (96.5008)  time: 0.2142  data: 0.0003  max mem: 2500
Test: [Task 1]  [1320/1627]  eta: 0:01:05  Loss: 2.3723 (2.4515)  Acc@1: 81.2500 (81.5102)  Acc@5: 100.0000 (96.5225)  time: 0.2148  data: 0.0003  max mem: 2500
Test: [Task 1]  [1330/1627]  eta: 0:01:03  Loss: 2.4241 (2.4517)  Acc@1: 81.2500 (81.4942)  Acc@5: 100.0000 (96.5111)  time: 0.2140  data: 0.0003  max mem: 2500
Test: [Task 1]  [1340/1627]  eta: 0:01:01  Loss: 2.4641 (2.4520)  Acc@1: 81.2500 (81.4597)  Acc@5: 93.7500 (96.5045)  time: 0.2132  data: 0.0002  max mem: 2500
Test: [Task 1]  [1350/1627]  eta: 0:00:59  Loss: 2.4423 (2.4520)  Acc@1: 81.2500 (81.4906)  Acc@5: 100.0000 (96.5165)  time: 0.2133  data: 0.0002  max mem: 2500
Test: [Task 1]  [1360/1627]  eta: 0:00:57  Loss: 2.4102 (2.4519)  Acc@1: 87.5000 (81.5072)  Acc@5: 100.0000 (96.5145)  time: 0.2131  data: 0.0002  max mem: 2500
Test: [Task 1]  [1370/1627]  eta: 0:00:55  Loss: 2.3771 (2.4516)  Acc@1: 87.5000 (81.5235)  Acc@5: 93.7500 (96.5126)  time: 0.2131  data: 0.0002  max mem: 2500
Test: [Task 1]  [1380/1627]  eta: 0:00:52  Loss: 2.3771 (2.4513)  Acc@1: 87.5000 (81.5306)  Acc@5: 100.0000 (96.5197)  time: 0.2129  data: 0.0002  max mem: 2500
Test: [Task 1]  [1390/1627]  eta: 0:00:50  Loss: 2.4175 (2.4514)  Acc@1: 81.2500 (81.5196)  Acc@5: 100.0000 (96.5088)  time: 0.2135  data: 0.0002  max mem: 2500
Test: [Task 1]  [1400/1627]  eta: 0:00:48  Loss: 2.4182 (2.4516)  Acc@1: 81.2500 (81.4909)  Acc@5: 93.7500 (96.5025)  time: 0.2137  data: 0.0002  max mem: 2500
Test: [Task 1]  [1410/1627]  eta: 0:00:46  Loss: 2.3744 (2.4513)  Acc@1: 81.2500 (81.4715)  Acc@5: 100.0000 (96.5184)  time: 0.2133  data: 0.0002  max mem: 2500
Test: [Task 1]  [1420/1627]  eta: 0:00:44  Loss: 2.4154 (2.4510)  Acc@1: 81.2500 (81.4919)  Acc@5: 100.0000 (96.5209)  time: 0.2130  data: 0.0002  max mem: 2500
Test: [Task 1]  [1430/1627]  eta: 0:00:42  Loss: 2.5056 (2.4519)  Acc@1: 75.0000 (81.4378)  Acc@5: 93.7500 (96.4928)  time: 0.2131  data: 0.0002  max mem: 2500
Test: [Task 1]  [1440/1627]  eta: 0:00:40  Loss: 2.5056 (2.4520)  Acc@1: 75.0000 (81.4148)  Acc@5: 93.7500 (96.4781)  time: 0.2136  data: 0.0002  max mem: 2500
Test: [Task 1]  [1450/1627]  eta: 0:00:37  Loss: 2.5122 (2.4525)  Acc@1: 81.2500 (81.3921)  Acc@5: 100.0000 (96.4809)  time: 0.2142  data: 0.0003  max mem: 2500
Test: [Task 1]  [1460/1627]  eta: 0:00:35  Loss: 2.5119 (2.4525)  Acc@1: 81.2500 (81.3698)  Acc@5: 100.0000 (96.4793)  time: 0.2143  data: 0.0004  max mem: 2500
Test: [Task 1]  [1470/1627]  eta: 0:00:33  Loss: 2.3918 (2.4527)  Acc@1: 81.2500 (81.3605)  Acc@5: 100.0000 (96.4820)  time: 0.2144  data: 0.0004  max mem: 2500
Test: [Task 1]  [1480/1627]  eta: 0:00:31  Loss: 2.3694 (2.4526)  Acc@1: 81.2500 (81.3724)  Acc@5: 100.0000 (96.4889)  time: 0.2143  data: 0.0004  max mem: 2500
Test: [Task 1]  [1490/1627]  eta: 0:00:29  Loss: 2.4132 (2.4529)  Acc@1: 81.2500 (81.3716)  Acc@5: 100.0000 (96.4831)  time: 0.2144  data: 0.0004  max mem: 2500
Test: [Task 1]  [1500/1627]  eta: 0:00:27  Loss: 2.4453 (2.4532)  Acc@1: 81.2500 (81.3666)  Acc@5: 93.7500 (96.4690)  time: 0.2145  data: 0.0003  max mem: 2500
Test: [Task 1]  [1510/1627]  eta: 0:00:25  Loss: 2.4303 (2.4530)  Acc@1: 81.2500 (81.3906)  Acc@5: 93.7500 (96.4593)  time: 0.2140  data: 0.0003  max mem: 2500
Test: [Task 1]  [1520/1627]  eta: 0:00:22  Loss: 2.3964 (2.4525)  Acc@1: 81.2500 (81.4061)  Acc@5: 100.0000 (96.4620)  time: 0.2141  data: 0.0004  max mem: 2500
Test: [Task 1]  [1530/1627]  eta: 0:00:20  Loss: 2.3763 (2.4522)  Acc@1: 87.5000 (81.4337)  Acc@5: 100.0000 (96.4688)  time: 0.2148  data: 0.0004  max mem: 2500
Test: [Task 1]  [1540/1627]  eta: 0:00:18  Loss: 2.3489 (2.4519)  Acc@1: 93.7500 (81.4650)  Acc@5: 100.0000 (96.4836)  time: 0.2145  data: 0.0004  max mem: 2500
Test: [Task 1]  [1550/1627]  eta: 0:00:16  Loss: 2.4004 (2.4519)  Acc@1: 87.5000 (81.4676)  Acc@5: 100.0000 (96.4821)  time: 0.2144  data: 0.0004  max mem: 2500
Test: [Task 1]  [1560/1627]  eta: 0:00:14  Loss: 2.4103 (2.4514)  Acc@1: 81.2500 (81.4862)  Acc@5: 100.0000 (96.4846)  time: 0.2157  data: 0.0005  max mem: 2500
Test: [Task 1]  [1570/1627]  eta: 0:00:12  Loss: 2.4103 (2.4516)  Acc@1: 81.2500 (81.4927)  Acc@5: 100.0000 (96.4911)  time: 0.2154  data: 0.0004  max mem: 2500
Test: [Task 1]  [1580/1627]  eta: 0:00:10  Loss: 2.4116 (2.4513)  Acc@1: 81.2500 (81.4753)  Acc@5: 100.0000 (96.4896)  time: 0.2148  data: 0.0004  max mem: 2500
Test: [Task 1]  [1590/1627]  eta: 0:00:07  Loss: 2.4256 (2.4514)  Acc@1: 75.0000 (81.4661)  Acc@5: 100.0000 (96.4959)  time: 0.2145  data: 0.0004  max mem: 2500
Test: [Task 1]  [1600/1627]  eta: 0:00:05  Loss: 2.4609 (2.4521)  Acc@1: 75.0000 (81.4374)  Acc@5: 93.7500 (96.4788)  time: 0.2140  data: 0.0003  max mem: 2500
Test: [Task 1]  [1610/1627]  eta: 0:00:03  Loss: 2.4488 (2.4517)  Acc@1: 81.2500 (81.4711)  Acc@5: 100.0000 (96.4929)  time: 0.2143  data: 0.0003  max mem: 2500
Test: [Task 1]  [1620/1627]  eta: 0:00:01  Loss: 2.4235 (2.4516)  Acc@1: 87.5000 (81.4852)  Acc@5: 100.0000 (96.4914)  time: 0.2141  data: 0.0003  max mem: 2500
Test: [Task 1]  [1626/1627]  eta: 0:00:00  Loss: 2.4235 (2.4513)  Acc@1: 87.5000 (81.4959)  Acc@5: 100.0000 (96.4966)  time: 0.2140  data: 0.0003  max mem: 2500
Test: [Task 1] Total time: 0:05:48 (0.2144 s / it)
* Acc@1 81.496 Acc@5 96.497 loss 2.451
Test: [Task 2]  [  0/625]  eta: 0:05:43  Loss: 1.8539 (1.8539)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)  time: 0.5502  data: 0.3360  max mem: 2500
Test: [Task 2]  [ 10/625]  eta: 0:02:30  Loss: 2.0367 (2.0633)  Acc@1: 93.7500 (93.7500)  Acc@5: 100.0000 (97.7273)  time: 0.2440  data: 0.0308  max mem: 2500
Test: [Task 2]  [ 20/625]  eta: 0:02:18  Loss: 2.0334 (2.0533)  Acc@1: 93.7500 (94.3452)  Acc@5: 100.0000 (98.8095)  time: 0.2136  data: 0.0003  max mem: 2500
Test: [Task 2]  [ 30/625]  eta: 0:02:13  Loss: 2.0144 (2.0507)  Acc@1: 93.7500 (94.1532)  Acc@5: 100.0000 (98.9919)  time: 0.2135  data: 0.0003  max mem: 2500
Test: [Task 2]  [ 40/625]  eta: 0:02:09  Loss: 2.0529 (2.0598)  Acc@1: 93.7500 (93.4451)  Acc@5: 100.0000 (99.2378)  time: 0.2134  data: 0.0003  max mem: 2500
Test: [Task 2]  [ 50/625]  eta: 0:02:06  Loss: 2.0553 (2.0709)  Acc@1: 93.7500 (92.8922)  Acc@5: 100.0000 (99.1422)  time: 0.2132  data: 0.0003  max mem: 2500
Test: [Task 2]  [ 60/625]  eta: 0:02:03  Loss: 2.0553 (2.0697)  Acc@1: 93.7500 (92.9303)  Acc@5: 100.0000 (99.0779)  time: 0.2135  data: 0.0003  max mem: 2500
Test: [Task 2]  [ 70/625]  eta: 0:02:01  Loss: 2.0429 (2.0730)  Acc@1: 93.7500 (92.6056)  Acc@5: 100.0000 (99.1197)  time: 0.2137  data: 0.0003  max mem: 2500
Test: [Task 2]  [ 80/625]  eta: 0:01:58  Loss: 2.1008 (2.0771)  Acc@1: 87.5000 (92.2840)  Acc@5: 100.0000 (98.7654)  time: 0.2133  data: 0.0002  max mem: 2500
Test: [Task 2]  [ 90/625]  eta: 0:01:56  Loss: 2.1322 (2.0803)  Acc@1: 87.5000 (92.1016)  Acc@5: 100.0000 (98.9011)  time: 0.2131  data: 0.0002  max mem: 2500
Test: [Task 2]  [100/625]  eta: 0:01:53  Loss: 2.1050 (2.0834)  Acc@1: 93.7500 (92.1411)  Acc@5: 100.0000 (98.8243)  time: 0.2134  data: 0.0002  max mem: 2500
Test: [Task 2]  [110/625]  eta: 0:01:51  Loss: 2.0814 (2.0823)  Acc@1: 93.7500 (92.1171)  Acc@5: 100.0000 (98.8176)  time: 0.2140  data: 0.0003  max mem: 2500
Test: [Task 2]  [120/625]  eta: 0:01:49  Loss: 2.0317 (2.0839)  Acc@1: 87.5000 (91.7872)  Acc@5: 100.0000 (98.8636)  time: 0.2135  data: 0.0003  max mem: 2500
Test: [Task 2]  [130/625]  eta: 0:01:46  Loss: 2.1014 (2.0849)  Acc@1: 87.5000 (91.8893)  Acc@5: 100.0000 (98.9027)  time: 0.2126  data: 0.0002  max mem: 2500
Test: [Task 2]  [140/625]  eta: 0:01:44  Loss: 2.1014 (2.0857)  Acc@1: 93.7500 (91.8883)  Acc@5: 100.0000 (98.7589)  time: 0.2127  data: 0.0002  max mem: 2500
Test: [Task 2]  [150/625]  eta: 0:01:42  Loss: 2.0709 (2.0881)  Acc@1: 87.5000 (91.7632)  Acc@5: 100.0000 (98.6755)  time: 0.2127  data: 0.0002  max mem: 2500
Test: [Task 2]  [160/625]  eta: 0:01:40  Loss: 2.0709 (2.0892)  Acc@1: 87.5000 (91.8090)  Acc@5: 100.0000 (98.6801)  time: 0.2128  data: 0.0002  max mem: 2500
Test: [Task 2]  [170/625]  eta: 0:01:37  Loss: 2.0971 (2.0886)  Acc@1: 93.7500 (91.8494)  Acc@5: 100.0000 (98.6477)  time: 0.2125  data: 0.0002  max mem: 2500
Test: [Task 2]  [180/625]  eta: 0:01:35  Loss: 2.0625 (2.0884)  Acc@1: 93.7500 (91.8508)  Acc@5: 100.0000 (98.6878)  time: 0.2126  data: 0.0002  max mem: 2500
Test: [Task 2]  [190/625]  eta: 0:01:33  Loss: 2.0544 (2.0879)  Acc@1: 93.7500 (91.9175)  Acc@5: 100.0000 (98.7238)  time: 0.2128  data: 0.0002  max mem: 2500
Test: [Task 2]  [200/625]  eta: 0:01:31  Loss: 2.0709 (2.0891)  Acc@1: 93.7500 (91.9154)  Acc@5: 100.0000 (98.6940)  time: 0.2131  data: 0.0002  max mem: 2500
Test: [Task 2]  [210/625]  eta: 0:01:29  Loss: 2.0363 (2.0885)  Acc@1: 93.7500 (91.8839)  Acc@5: 100.0000 (98.6374)  time: 0.2138  data: 0.0003  max mem: 2500
Test: [Task 2]  [220/625]  eta: 0:01:26  Loss: 2.0281 (2.0875)  Acc@1: 93.7500 (91.9966)  Acc@5: 100.0000 (98.6425)  time: 0.2138  data: 0.0004  max mem: 2500
Test: [Task 2]  [230/625]  eta: 0:01:24  Loss: 2.0301 (2.0866)  Acc@1: 93.7500 (92.0455)  Acc@5: 100.0000 (98.6742)  time: 0.2136  data: 0.0003  max mem: 2500
Test: [Task 2]  [240/625]  eta: 0:01:22  Loss: 2.0592 (2.0871)  Acc@1: 93.7500 (91.9865)  Acc@5: 100.0000 (98.7033)  time: 0.2137  data: 0.0003  max mem: 2500
Test: [Task 2]  [250/625]  eta: 0:01:20  Loss: 2.0940 (2.0879)  Acc@1: 93.7500 (91.9572)  Acc@5: 100.0000 (98.6305)  time: 0.2136  data: 0.0004  max mem: 2500
Test: [Task 2]  [260/625]  eta: 0:01:18  Loss: 2.0825 (2.0876)  Acc@1: 93.7500 (91.9780)  Acc@5: 100.0000 (98.6351)  time: 0.2137  data: 0.0004  max mem: 2500
Test: [Task 2]  [270/625]  eta: 0:01:16  Loss: 2.0799 (2.0884)  Acc@1: 93.7500 (91.9050)  Acc@5: 100.0000 (98.6162)  time: 0.2136  data: 0.0003  max mem: 2500
Test: [Task 2]  [280/625]  eta: 0:01:14  Loss: 2.0858 (2.0885)  Acc@1: 93.7500 (91.9262)  Acc@5: 100.0000 (98.6210)  time: 0.2136  data: 0.0003  max mem: 2500
Test: [Task 2]  [290/625]  eta: 0:01:11  Loss: 2.0858 (2.0888)  Acc@1: 93.7500 (91.8814)  Acc@5: 100.0000 (98.6254)  time: 0.2137  data: 0.0003  max mem: 2500
Test: [Task 2]  [300/625]  eta: 0:01:09  Loss: 2.0782 (2.0890)  Acc@1: 93.7500 (91.7982)  Acc@5: 100.0000 (98.6296)  time: 0.2136  data: 0.0003  max mem: 2500
Test: [Task 2]  [310/625]  eta: 0:01:07  Loss: 2.0395 (2.0880)  Acc@1: 93.7500 (91.8609)  Acc@5: 100.0000 (98.6133)  time: 0.2136  data: 0.0003  max mem: 2500
Test: [Task 2]  [320/625]  eta: 0:01:05  Loss: 1.9933 (2.0826)  Acc@1: 100.0000 (92.0950)  Acc@5: 100.0000 (98.6565)  time: 0.2135  data: 0.0003  max mem: 2500
Test: [Task 2]  [330/625]  eta: 0:01:03  Loss: 1.9438 (2.0800)  Acc@1: 100.0000 (92.2394)  Acc@5: 100.0000 (98.6782)  time: 0.2137  data: 0.0003  max mem: 2500
Test: [Task 2]  [340/625]  eta: 0:01:01  Loss: 1.9244 (2.0749)  Acc@1: 100.0000 (92.4487)  Acc@5: 100.0000 (98.7170)  time: 0.2190  data: 0.0005  max mem: 2500
Test: [Task 2]  [350/625]  eta: 0:00:59  Loss: 1.9059 (2.0715)  Acc@1: 100.0000 (92.5748)  Acc@5: 100.0000 (98.7358)  time: 0.2188  data: 0.0004  max mem: 2500
Test: [Task 2]  [360/625]  eta: 0:00:56  Loss: 2.0257 (2.0726)  Acc@1: 93.7500 (92.5554)  Acc@5: 100.0000 (98.7015)  time: 0.2135  data: 0.0002  max mem: 2500
Test: [Task 2]  [370/625]  eta: 0:00:54  Loss: 2.0375 (2.0711)  Acc@1: 93.7500 (92.5876)  Acc@5: 100.0000 (98.7365)  time: 0.2135  data: 0.0002  max mem: 2500
Test: [Task 2]  [380/625]  eta: 0:00:52  Loss: 2.0411 (2.0724)  Acc@1: 93.7500 (92.5197)  Acc@5: 100.0000 (98.7205)  time: 0.2138  data: 0.0002  max mem: 2500
Test: [Task 2]  [390/625]  eta: 0:00:50  Loss: 2.0411 (2.0718)  Acc@1: 93.7500 (92.5192)  Acc@5: 100.0000 (98.6093)  time: 0.2138  data: 0.0003  max mem: 2500
Test: [Task 2]  [400/625]  eta: 0:00:48  Loss: 1.9101 (2.0682)  Acc@1: 100.0000 (92.6901)  Acc@5: 100.0000 (98.6284)  time: 0.2138  data: 0.0003  max mem: 2500
Test: [Task 2]  [410/625]  eta: 0:00:46  Loss: 1.9029 (2.0657)  Acc@1: 100.0000 (92.7920)  Acc@5: 100.0000 (98.6466)  time: 0.2139  data: 0.0003  max mem: 2500
Test: [Task 2]  [420/625]  eta: 0:00:43  Loss: 1.9283 (2.0640)  Acc@1: 100.0000 (92.9186)  Acc@5: 100.0000 (98.6639)  time: 0.2139  data: 0.0003  max mem: 2500
Test: [Task 2]  [430/625]  eta: 0:00:41  Loss: 1.9865 (2.0623)  Acc@1: 100.0000 (92.9959)  Acc@5: 100.0000 (98.6804)  time: 0.2138  data: 0.0003  max mem: 2500
Test: [Task 2]  [440/625]  eta: 0:00:39  Loss: 1.9062 (2.0584)  Acc@1: 100.0000 (93.1548)  Acc@5: 100.0000 (98.7103)  time: 0.2137  data: 0.0003  max mem: 2500
Test: [Task 2]  [450/625]  eta: 0:00:37  Loss: 1.8898 (2.0559)  Acc@1: 100.0000 (93.2373)  Acc@5: 100.0000 (98.7389)  time: 0.2144  data: 0.0003  max mem: 2500
Test: [Task 2]  [460/625]  eta: 0:00:35  Loss: 1.9112 (2.0540)  Acc@1: 100.0000 (93.3026)  Acc@5: 100.0000 (98.7663)  time: 0.2139  data: 0.0002  max mem: 2500
Test: [Task 2]  [470/625]  eta: 0:00:33  Loss: 1.9628 (2.0529)  Acc@1: 100.0000 (93.3652)  Acc@5: 100.0000 (98.7659)  time: 0.2128  data: 0.0002  max mem: 2500
Test: [Task 2]  [480/625]  eta: 0:00:31  Loss: 1.9687 (2.0512)  Acc@1: 100.0000 (93.4511)  Acc@5: 100.0000 (98.7916)  time: 0.2129  data: 0.0002  max mem: 2500
Test: [Task 2]  [490/625]  eta: 0:00:28  Loss: 1.9464 (2.0493)  Acc@1: 100.0000 (93.5336)  Acc@5: 100.0000 (98.8162)  time: 0.2131  data: 0.0002  max mem: 2500
Test: [Task 2]  [500/625]  eta: 0:00:26  Loss: 1.9491 (2.0479)  Acc@1: 100.0000 (93.6252)  Acc@5: 100.0000 (98.8398)  time: 0.2130  data: 0.0002  max mem: 2500
Test: [Task 2]  [510/625]  eta: 0:00:24  Loss: 1.9883 (2.0476)  Acc@1: 100.0000 (93.6399)  Acc@5: 100.0000 (98.8503)  time: 0.2130  data: 0.0002  max mem: 2500
Test: [Task 2]  [520/625]  eta: 0:00:22  Loss: 1.9951 (2.0471)  Acc@1: 93.7500 (93.6780)  Acc@5: 100.0000 (98.8604)  time: 0.2131  data: 0.0002  max mem: 2500
Test: [Task 2]  [530/625]  eta: 0:00:20  Loss: 1.9471 (2.0448)  Acc@1: 100.0000 (93.7971)  Acc@5: 100.0000 (98.8818)  time: 0.2130  data: 0.0002  max mem: 2500
Test: [Task 2]  [540/625]  eta: 0:00:18  Loss: 1.9066 (2.0427)  Acc@1: 100.0000 (93.8886)  Acc@5: 100.0000 (98.8909)  time: 0.2134  data: 0.0002  max mem: 2500
Test: [Task 2]  [550/625]  eta: 0:00:16  Loss: 1.9045 (2.0402)  Acc@1: 100.0000 (93.9882)  Acc@5: 100.0000 (98.9111)  time: 0.2137  data: 0.0002  max mem: 2500
Test: [Task 2]  [560/625]  eta: 0:00:13  Loss: 1.8972 (2.0377)  Acc@1: 100.0000 (94.0954)  Acc@5: 100.0000 (98.9305)  time: 0.2135  data: 0.0002  max mem: 2500
Test: [Task 2]  [570/625]  eta: 0:00:11  Loss: 1.9107 (2.0377)  Acc@1: 100.0000 (94.0784)  Acc@5: 100.0000 (98.9492)  time: 0.2136  data: 0.0002  max mem: 2500
Test: [Task 2]  [580/625]  eta: 0:00:09  Loss: 1.9232 (2.0357)  Acc@1: 100.0000 (94.1695)  Acc@5: 100.0000 (98.9673)  time: 0.2139  data: 0.0002  max mem: 2500
Test: [Task 2]  [590/625]  eta: 0:00:07  Loss: 1.9156 (2.0337)  Acc@1: 100.0000 (94.2365)  Acc@5: 100.0000 (98.9848)  time: 0.2140  data: 0.0002  max mem: 2500
Test: [Task 2]  [600/625]  eta: 0:00:05  Loss: 1.9434 (2.0330)  Acc@1: 100.0000 (94.2908)  Acc@5: 100.0000 (99.0017)  time: 0.2141  data: 0.0002  max mem: 2500
Test: [Task 2]  [610/625]  eta: 0:00:03  Loss: 2.0062 (2.0338)  Acc@1: 93.7500 (94.2717)  Acc@5: 100.0000 (99.0078)  time: 0.2148  data: 0.0003  max mem: 2500
Test: [Task 2]  [620/625]  eta: 0:00:01  Loss: 2.0055 (2.0329)  Acc@1: 93.7500 (94.3136)  Acc@5: 100.0000 (99.0238)  time: 0.2149  data: 0.0003  max mem: 2500
Test: [Task 2]  [624/625]  eta: 0:00:00  Loss: 1.9709 (2.0324)  Acc@1: 100.0000 (94.3400)  Acc@5: 100.0000 (99.0300)  time: 0.2151  data: 0.0003  max mem: 2500
Test: [Task 2] Total time: 0:02:14 (0.2145 s / it)
* Acc@1 94.340 Acc@5 99.030 loss 2.032
Test: [Task 3]  [  0/625]  eta: 0:05:04  Loss: 2.3920 (2.3920)  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (100.0000)  time: 0.4880  data: 0.2666  max mem: 2500
Test: [Task 3]  [ 10/625]  eta: 0:02:27  Loss: 2.3246 (2.3390)  Acc@1: 87.5000 (88.0682)  Acc@5: 100.0000 (99.4318)  time: 0.2397  data: 0.0246  max mem: 2500
Test: [Task 3]  [ 20/625]  eta: 0:02:17  Loss: 2.3246 (2.3489)  Acc@1: 87.5000 (87.2024)  Acc@5: 100.0000 (99.4048)  time: 0.2149  data: 0.0004  max mem: 2500
Test: [Task 3]  [ 30/625]  eta: 0:02:13  Loss: 2.3652 (2.3556)  Acc@1: 81.2500 (85.8871)  Acc@5: 100.0000 (99.1935)  time: 0.2152  data: 0.0004  max mem: 2500
Test: [Task 3]  [ 40/625]  eta: 0:02:09  Loss: 2.3238 (2.3422)  Acc@1: 87.5000 (87.0427)  Acc@5: 100.0000 (99.2378)  time: 0.2153  data: 0.0003  max mem: 2500
Test: [Task 3]  [ 50/625]  eta: 0:02:06  Loss: 2.3238 (2.3367)  Acc@1: 87.5000 (87.2549)  Acc@5: 100.0000 (99.1422)  time: 0.2151  data: 0.0004  max mem: 2500
Test: [Task 3]  [ 60/625]  eta: 0:02:04  Loss: 2.3250 (2.3357)  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (99.2828)  time: 0.2152  data: 0.0004  max mem: 2500
Test: [Task 3]  [ 70/625]  eta: 0:02:01  Loss: 2.3245 (2.3300)  Acc@1: 93.7500 (87.6761)  Acc@5: 100.0000 (99.1197)  time: 0.2149  data: 0.0003  max mem: 2500
Test: [Task 3]  [ 80/625]  eta: 0:01:59  Loss: 2.2697 (2.3242)  Acc@1: 93.7500 (88.1944)  Acc@5: 100.0000 (99.1512)  time: 0.2147  data: 0.0003  max mem: 2500
Test: [Task 3]  [ 90/625]  eta: 0:01:56  Loss: 2.2686 (2.3198)  Acc@1: 93.7500 (88.8736)  Acc@5: 100.0000 (99.1071)  time: 0.2150  data: 0.0003  max mem: 2500
Test: [Task 3]  [100/625]  eta: 0:01:54  Loss: 2.2991 (2.3222)  Acc@1: 93.7500 (88.8614)  Acc@5: 100.0000 (99.0718)  time: 0.2155  data: 0.0004  max mem: 2500
Test: [Task 3]  [110/625]  eta: 0:01:52  Loss: 2.3062 (2.3191)  Acc@1: 93.7500 (88.8514)  Acc@5: 100.0000 (99.1554)  time: 0.2154  data: 0.0004  max mem: 2500
Test: [Task 3]  [120/625]  eta: 0:01:49  Loss: 2.2908 (2.3181)  Acc@1: 87.5000 (88.7397)  Acc@5: 100.0000 (99.2252)  time: 0.2148  data: 0.0003  max mem: 2500
Test: [Task 3]  [130/625]  eta: 0:01:47  Loss: 2.3211 (2.3204)  Acc@1: 87.5000 (88.4065)  Acc@5: 100.0000 (99.1889)  time: 0.2153  data: 0.0004  max mem: 2500
Test: [Task 3]  [140/625]  eta: 0:01:45  Loss: 2.3211 (2.3210)  Acc@1: 87.5000 (88.3865)  Acc@5: 100.0000 (99.0691)  time: 0.2154  data: 0.0004  max mem: 2500
Test: [Task 3]  [150/625]  eta: 0:01:43  Loss: 2.3037 (2.3215)  Acc@1: 87.5000 (88.4106)  Acc@5: 100.0000 (99.0066)  time: 0.2149  data: 0.0003  max mem: 2500
Test: [Task 3]  [160/625]  eta: 0:01:40  Loss: 2.3037 (2.3241)  Acc@1: 93.7500 (88.3152)  Acc@5: 100.0000 (98.9130)  time: 0.2152  data: 0.0004  max mem: 2500
Test: [Task 3]  [170/625]  eta: 0:01:38  Loss: 2.2918 (2.3243)  Acc@1: 87.5000 (88.3406)  Acc@5: 100.0000 (98.9401)  time: 0.2153  data: 0.0004  max mem: 2500
Test: [Task 3]  [180/625]  eta: 0:01:36  Loss: 2.3033 (2.3246)  Acc@1: 93.7500 (88.5359)  Acc@5: 100.0000 (98.9641)  time: 0.2152  data: 0.0003  max mem: 2500
Test: [Task 3]  [190/625]  eta: 0:01:34  Loss: 2.3057 (2.3244)  Acc@1: 93.7500 (88.6453)  Acc@5: 100.0000 (98.9856)  time: 0.2157  data: 0.0004  max mem: 2500
Test: [Task 3]  [200/625]  eta: 0:01:32  Loss: 2.3057 (2.3243)  Acc@1: 87.5000 (88.6194)  Acc@5: 100.0000 (98.9428)  time: 0.2162  data: 0.0004  max mem: 2500
Test: [Task 3]  [210/625]  eta: 0:01:29  Loss: 2.2994 (2.3232)  Acc@1: 87.5000 (88.6552)  Acc@5: 100.0000 (98.9929)  time: 0.2164  data: 0.0004  max mem: 2500
Test: [Task 3]  [220/625]  eta: 0:01:27  Loss: 2.3294 (2.3261)  Acc@1: 87.5000 (88.3767)  Acc@5: 100.0000 (98.9819)  time: 0.2163  data: 0.0004  max mem: 2500
Test: [Task 3]  [230/625]  eta: 0:01:25  Loss: 2.3580 (2.3273)  Acc@1: 81.2500 (88.1223)  Acc@5: 100.0000 (98.9177)  time: 0.2156  data: 0.0004  max mem: 2500
Test: [Task 3]  [240/625]  eta: 0:01:23  Loss: 2.3536 (2.3291)  Acc@1: 81.2500 (87.9149)  Acc@5: 100.0000 (98.8589)  time: 0.2154  data: 0.0004  max mem: 2500
Test: [Task 3]  [250/625]  eta: 0:01:21  Loss: 2.2981 (2.3261)  Acc@1: 87.5000 (88.0976)  Acc@5: 100.0000 (98.8795)  time: 0.2153  data: 0.0003  max mem: 2500
Test: [Task 3]  [260/625]  eta: 0:01:18  Loss: 2.2764 (2.3255)  Acc@1: 93.7500 (88.1705)  Acc@5: 100.0000 (98.8266)  time: 0.2150  data: 0.0003  max mem: 2500
Test: [Task 3]  [270/625]  eta: 0:01:16  Loss: 2.2907 (2.3237)  Acc@1: 87.5000 (88.2841)  Acc@5: 100.0000 (98.8699)  time: 0.2148  data: 0.0003  max mem: 2500
Test: [Task 3]  [280/625]  eta: 0:01:14  Loss: 2.3001 (2.3239)  Acc@1: 87.5000 (88.2340)  Acc@5: 100.0000 (98.8434)  time: 0.2147  data: 0.0002  max mem: 2500
Test: [Task 3]  [290/625]  eta: 0:01:12  Loss: 2.3267 (2.3250)  Acc@1: 87.5000 (88.1658)  Acc@5: 100.0000 (98.8402)  time: 0.2146  data: 0.0002  max mem: 2500
Test: [Task 3]  [300/625]  eta: 0:01:10  Loss: 2.3070 (2.3290)  Acc@1: 87.5000 (87.9153)  Acc@5: 100.0000 (98.5465)  time: 0.2152  data: 0.0003  max mem: 2500
Test: [Task 3]  [310/625]  eta: 0:01:08  Loss: 2.3070 (2.3299)  Acc@1: 87.5000 (87.8617)  Acc@5: 100.0000 (98.5732)  time: 0.2152  data: 0.0003  max mem: 2500
Test: [Task 3]  [320/625]  eta: 0:01:05  Loss: 2.3159 (2.3300)  Acc@1: 87.5000 (87.8505)  Acc@5: 100.0000 (98.5592)  time: 0.2143  data: 0.0002  max mem: 2500
Test: [Task 3]  [330/625]  eta: 0:01:03  Loss: 2.3052 (2.3305)  Acc@1: 87.5000 (87.8210)  Acc@5: 100.0000 (98.5650)  time: 0.2143  data: 0.0002  max mem: 2500
Test: [Task 3]  [340/625]  eta: 0:01:01  Loss: 2.3052 (2.3300)  Acc@1: 87.5000 (87.7383)  Acc@5: 100.0000 (98.5887)  time: 0.2144  data: 0.0002  max mem: 2500
Test: [Task 3]  [350/625]  eta: 0:00:59  Loss: 2.2835 (2.3293)  Acc@1: 87.5000 (87.8205)  Acc@5: 100.0000 (98.6289)  time: 0.2149  data: 0.0003  max mem: 2500
Test: [Task 3]  [360/625]  eta: 0:00:57  Loss: 2.3154 (2.3312)  Acc@1: 87.5000 (87.7424)  Acc@5: 100.0000 (98.5803)  time: 0.2148  data: 0.0003  max mem: 2500
Test: [Task 3]  [370/625]  eta: 0:00:55  Loss: 2.3427 (2.3328)  Acc@1: 87.5000 (87.7358)  Acc@5: 100.0000 (98.5681)  time: 0.2141  data: 0.0003  max mem: 2500
Test: [Task 3]  [380/625]  eta: 0:00:52  Loss: 2.3602 (2.3332)  Acc@1: 87.5000 (87.6148)  Acc@5: 100.0000 (98.5728)  time: 0.2138  data: 0.0002  max mem: 2500
Test: [Task 3]  [390/625]  eta: 0:00:50  Loss: 2.3731 (2.3348)  Acc@1: 81.2500 (87.5320)  Acc@5: 100.0000 (98.5454)  time: 0.2138  data: 0.0003  max mem: 2500
Test: [Task 3]  [400/625]  eta: 0:00:48  Loss: 2.3408 (2.3337)  Acc@1: 87.5000 (87.6403)  Acc@5: 100.0000 (98.5661)  time: 0.2140  data: 0.0002  max mem: 2500
Test: [Task 3]  [410/625]  eta: 0:00:46  Loss: 2.3172 (2.3349)  Acc@1: 87.5000 (87.5912)  Acc@5: 100.0000 (98.5554)  time: 0.2138  data: 0.0002  max mem: 2500
Test: [Task 3]  [420/625]  eta: 0:00:44  Loss: 2.3371 (2.3349)  Acc@1: 87.5000 (87.6781)  Acc@5: 100.0000 (98.5748)  time: 0.2136  data: 0.0002  max mem: 2500
Test: [Task 3]  [430/625]  eta: 0:00:42  Loss: 2.3246 (2.3351)  Acc@1: 87.5000 (87.6160)  Acc@5: 100.0000 (98.5934)  time: 0.2138  data: 0.0002  max mem: 2500
Test: [Task 3]  [440/625]  eta: 0:00:39  Loss: 2.3347 (2.3360)  Acc@1: 87.5000 (87.5992)  Acc@5: 100.0000 (98.5544)  time: 0.2138  data: 0.0002  max mem: 2500
Test: [Task 3]  [450/625]  eta: 0:00:37  Loss: 2.3331 (2.3352)  Acc@1: 87.5000 (87.6524)  Acc@5: 100.0000 (98.5726)  time: 0.2142  data: 0.0003  max mem: 2500
Test: [Task 3]  [460/625]  eta: 0:00:35  Loss: 2.3298 (2.3345)  Acc@1: 93.7500 (87.7034)  Acc@5: 100.0000 (98.5900)  time: 0.2144  data: 0.0003  max mem: 2500
Test: [Task 3]  [470/625]  eta: 0:00:33  Loss: 2.3340 (2.3347)  Acc@1: 87.5000 (87.6327)  Acc@5: 100.0000 (98.5934)  time: 0.2142  data: 0.0004  max mem: 2500
Test: [Task 3]  [480/625]  eta: 0:00:31  Loss: 2.3240 (2.3349)  Acc@1: 81.2500 (87.5260)  Acc@5: 100.0000 (98.5967)  time: 0.2145  data: 0.0004  max mem: 2500
Test: [Task 3]  [490/625]  eta: 0:00:29  Loss: 2.3240 (2.3352)  Acc@1: 87.5000 (87.5382)  Acc@5: 100.0000 (98.5871)  time: 0.2145  data: 0.0004  max mem: 2500
Test: [Task 3]  [500/625]  eta: 0:00:26  Loss: 2.3060 (2.3346)  Acc@1: 87.5000 (87.5998)  Acc@5: 100.0000 (98.6028)  time: 0.2148  data: 0.0003  max mem: 2500
Test: [Task 3]  [510/625]  eta: 0:00:24  Loss: 2.3038 (2.3342)  Acc@1: 93.7500 (87.6468)  Acc@5: 100.0000 (98.6057)  time: 0.2149  data: 0.0003  max mem: 2500
Test: [Task 3]  [520/625]  eta: 0:00:22  Loss: 2.3233 (2.3346)  Acc@1: 87.5000 (87.6560)  Acc@5: 100.0000 (98.6324)  time: 0.2141  data: 0.0003  max mem: 2500
Test: [Task 3]  [530/625]  eta: 0:00:20  Loss: 2.3490 (2.3354)  Acc@1: 87.5000 (87.6059)  Acc@5: 100.0000 (98.6347)  time: 0.2145  data: 0.0003  max mem: 2500
Test: [Task 3]  [540/625]  eta: 0:00:18  Loss: 2.3282 (2.3350)  Acc@1: 87.5000 (87.6040)  Acc@5: 100.0000 (98.6599)  time: 0.2149  data: 0.0004  max mem: 2500
Test: [Task 3]  [550/625]  eta: 0:00:16  Loss: 2.3253 (2.3353)  Acc@1: 87.5000 (87.6134)  Acc@5: 100.0000 (98.6615)  time: 0.2145  data: 0.0004  max mem: 2500
Test: [Task 3]  [560/625]  eta: 0:00:13  Loss: 2.3485 (2.3352)  Acc@1: 87.5000 (87.6003)  Acc@5: 100.0000 (98.6631)  time: 0.2147  data: 0.0004  max mem: 2500
Test: [Task 3]  [570/625]  eta: 0:00:11  Loss: 2.3283 (2.3352)  Acc@1: 87.5000 (87.6532)  Acc@5: 100.0000 (98.6756)  time: 0.2153  data: 0.0004  max mem: 2500
Test: [Task 3]  [580/625]  eta: 0:00:09  Loss: 2.3244 (2.3350)  Acc@1: 87.5000 (87.6076)  Acc@5: 100.0000 (98.6876)  time: 0.2152  data: 0.0004  max mem: 2500
Test: [Task 3]  [590/625]  eta: 0:00:07  Loss: 2.3052 (2.3349)  Acc@1: 87.5000 (87.6058)  Acc@5: 100.0000 (98.6992)  time: 0.2144  data: 0.0003  max mem: 2500
Test: [Task 3]  [600/625]  eta: 0:00:05  Loss: 2.2829 (2.3339)  Acc@1: 87.5000 (87.6144)  Acc@5: 100.0000 (98.7209)  time: 0.2139  data: 0.0003  max mem: 2500
Test: [Task 3]  [610/625]  eta: 0:00:03  Loss: 2.2464 (2.3327)  Acc@1: 93.7500 (87.6841)  Acc@5: 100.0000 (98.7418)  time: 0.2141  data: 0.0003  max mem: 2500
Test: [Task 3]  [620/625]  eta: 0:00:01  Loss: 2.2797 (2.3332)  Acc@1: 87.5000 (87.6912)  Acc@5: 100.0000 (98.7118)  time: 0.2141  data: 0.0002  max mem: 2500
Test: [Task 3]  [624/625]  eta: 0:00:00  Loss: 2.2981 (2.3333)  Acc@1: 87.5000 (87.6900)  Acc@5: 100.0000 (98.7200)  time: 0.2138  data: 0.0002  max mem: 2500
Test: [Task 3] Total time: 0:02:14 (0.2154 s / it)
* Acc@1 87.690 Acc@5 98.720 loss 2.333
Test: [Task 4]  [ 0/29]  eta: 0:00:13  Loss: 4.0239 (4.0239)  Acc@1: 0.0000 (0.0000)  Acc@5: 0.0000 (0.0000)  time: 0.4723  data: 0.2588  max mem: 2500
Test: [Task 4]  [10/29]  eta: 0:00:04  Loss: 3.9816 (3.6458)  Acc@1: 0.0000 (19.8864)  Acc@5: 0.0000 (22.7273)  time: 0.2371  data: 0.0238  max mem: 2500
Test: [Task 4]  [20/29]  eta: 0:00:02  Loss: 2.7644 (3.3034)  Acc@1: 0.0000 (39.2857)  Acc@5: 6.2500 (42.8571)  time: 0.2136  data: 0.0003  max mem: 2500
Test: [Task 4]  [28/29]  eta: 0:00:00  Loss: 2.6618 (3.1049)  Acc@1: 75.0000 (44.4444)  Acc@5: 93.7500 (56.8627)  time: 0.2164  data: 0.0002  max mem: 2500
Test: [Task 4] Total time: 0:00:06 (0.2274 s / it)
* Acc@1 44.444 Acc@5 56.863 loss 3.105
{0: {0: 26032, 1: 26032, 2: 26032, 3: 26032, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0, 10: 0, 11: 0, 12: 0, 13: 0, 14: 0, 15: 0, 16: 0, 17: 0, 18: 0, 19: 0}, 1: {0: 0, 1: 0, 2: 0, 3: 0, 4: 10000, 5: 10000, 6: 10000, 7: 10000, 8: 0, 9: 0, 10: 0, 11: 0, 12: 0, 13: 0, 14: 0, 15: 0, 16: 0, 17: 0, 18: 0, 19: 0}, 2: {0: 16, 1: 16, 2: 16, 3: 16, 4: 0, 5: 0, 6: 0, 7: 0, 8: 9984, 9: 9984, 10: 9984, 11: 9984, 12: 0, 13: 0, 14: 0, 15: 0, 16: 0, 17: 0, 18: 0, 19: 0}, 3: {0: 0, 1: 0, 2: 0, 3: 0, 4: 176, 5: 176, 6: 176, 7: 176, 8: 0, 9: 0, 10: 0, 11: 0, 12: 283, 13: 283, 14: 283, 15: 283, 16: 0, 17: 0, 18: 0, 19: 0}}
[Average accuracy till task4]	Acc@1: 76.9926	Acc@5: 87.7773	Loss: 2.4804	Forgetting: 0.0000	Backward: 0.0000
Train: Epoch[1/5]  [   0/3750]  eta: 0:40:15  Lr: 0.030000  Loss: 2.2920  Acc@1: 6.2500 (6.2500)  Acc@5: 31.2500 (31.2500)  time: 0.6441  data: 0.2770  max mem: 2500
Train: Epoch[1/5]  [  10/3750]  eta: 0:23:13  Lr: 0.030000  Loss: 1.8363  Acc@1: 12.5000 (12.5000)  Acc@5: 56.2500 (53.4091)  time: 0.3727  data: 0.0254  max mem: 2502
Train: Epoch[1/5]  [  20/3750]  eta: 0:22:17  Lr: 0.030000  Loss: 1.5389  Acc@1: 12.5000 (11.3095)  Acc@5: 56.2500 (53.8690)  time: 0.3443  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [  30/3750]  eta: 0:21:55  Lr: 0.030000  Loss: 1.3464  Acc@1: 6.2500 (9.4758)  Acc@5: 56.2500 (55.8468)  time: 0.3430  data: 0.0002  max mem: 2502
Train: Epoch[1/5]  [  40/3750]  eta: 0:21:42  Lr: 0.030000  Loss: 1.1947  Acc@1: 6.2500 (10.2134)  Acc@5: 56.2500 (56.5549)  time: 0.3430  data: 0.0002  max mem: 2502
Train: Epoch[1/5]  [  50/3750]  eta: 0:21:32  Lr: 0.030000  Loss: 1.1255  Acc@1: 18.7500 (12.1324)  Acc@5: 62.5000 (58.7010)  time: 0.3426  data: 0.0002  max mem: 2502
Train: Epoch[1/5]  [  60/3750]  eta: 0:21:24  Lr: 0.030000  Loss: 1.0582  Acc@1: 18.7500 (13.8320)  Acc@5: 68.7500 (60.7582)  time: 0.3425  data: 0.0002  max mem: 2502
Train: Epoch[1/5]  [  70/3750]  eta: 0:21:18  Lr: 0.030000  Loss: 1.1301  Acc@1: 18.7500 (14.8768)  Acc@5: 62.5000 (60.3873)  time: 0.3431  data: 0.0002  max mem: 2502
Train: Epoch[1/5]  [  80/3750]  eta: 0:21:13  Lr: 0.030000  Loss: 1.0456  Acc@1: 25.0000 (16.5123)  Acc@5: 62.5000 (62.0370)  time: 0.3431  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [  90/3750]  eta: 0:21:08  Lr: 0.030000  Loss: 1.0509  Acc@1: 18.7500 (16.8269)  Acc@5: 75.0000 (63.1868)  time: 0.3433  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [ 100/3750]  eta: 0:21:05  Lr: 0.030000  Loss: 0.9871  Acc@1: 18.7500 (17.6980)  Acc@5: 75.0000 (64.3564)  time: 0.3454  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [ 110/3750]  eta: 0:21:01  Lr: 0.030000  Loss: 1.1027  Acc@1: 25.0000 (18.6374)  Acc@5: 75.0000 (65.3153)  time: 0.3464  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [ 120/3750]  eta: 0:20:57  Lr: 0.030000  Loss: 1.0494  Acc@1: 31.2500 (19.9380)  Acc@5: 75.0000 (66.2190)  time: 0.3453  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [ 130/3750]  eta: 0:20:53  Lr: 0.030000  Loss: 1.0424  Acc@1: 31.2500 (20.9924)  Acc@5: 75.0000 (66.8416)  time: 0.3452  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [ 140/3750]  eta: 0:20:50  Lr: 0.030000  Loss: 1.0333  Acc@1: 31.2500 (21.8085)  Acc@5: 75.0000 (67.7748)  time: 0.3460  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [ 150/3750]  eta: 0:20:46  Lr: 0.030000  Loss: 1.0147  Acc@1: 31.2500 (22.3510)  Acc@5: 75.0000 (68.2119)  time: 0.3452  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [ 160/3750]  eta: 0:20:42  Lr: 0.030000  Loss: 1.0326  Acc@1: 31.2500 (22.6708)  Acc@5: 81.2500 (69.0606)  time: 0.3448  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [ 170/3750]  eta: 0:20:38  Lr: 0.030000  Loss: 1.0442  Acc@1: 25.0000 (22.7705)  Acc@5: 81.2500 (69.7003)  time: 0.3444  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [ 180/3750]  eta: 0:20:35  Lr: 0.030000  Loss: 1.0021  Acc@1: 31.2500 (23.6878)  Acc@5: 87.5000 (70.6837)  time: 0.3443  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [ 190/3750]  eta: 0:20:31  Lr: 0.030000  Loss: 0.9906  Acc@1: 31.2500 (24.1492)  Acc@5: 87.5000 (71.2042)  time: 0.3462  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [ 200/3750]  eta: 0:20:28  Lr: 0.030000  Loss: 1.0029  Acc@1: 31.2500 (24.6891)  Acc@5: 87.5000 (71.7351)  time: 0.3462  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [ 210/3750]  eta: 0:20:24  Lr: 0.030000  Loss: 0.9701  Acc@1: 31.2500 (25.1481)  Acc@5: 81.2500 (72.2156)  time: 0.3462  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [ 220/3750]  eta: 0:20:21  Lr: 0.030000  Loss: 0.9852  Acc@1: 31.2500 (25.4808)  Acc@5: 81.2500 (72.8507)  time: 0.3455  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [ 230/3750]  eta: 0:20:17  Lr: 0.030000  Loss: 0.9860  Acc@1: 31.2500 (25.7846)  Acc@5: 87.5000 (73.3225)  time: 0.3442  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [ 240/3750]  eta: 0:20:13  Lr: 0.030000  Loss: 0.9196  Acc@1: 31.2500 (25.9077)  Acc@5: 87.5000 (73.8589)  time: 0.3440  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [ 250/3750]  eta: 0:20:10  Lr: 0.030000  Loss: 0.8953  Acc@1: 37.5000 (26.6185)  Acc@5: 87.5000 (74.5020)  time: 0.3449  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [ 260/3750]  eta: 0:20:06  Lr: 0.030000  Loss: 0.8988  Acc@1: 43.7500 (27.2510)  Acc@5: 87.5000 (75.1437)  time: 0.3450  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [ 270/3750]  eta: 0:20:02  Lr: 0.030000  Loss: 0.9413  Acc@1: 37.5000 (27.5369)  Acc@5: 87.5000 (75.6919)  time: 0.3438  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [ 280/3750]  eta: 0:19:59  Lr: 0.030000  Loss: 0.9243  Acc@1: 37.5000 (27.9359)  Acc@5: 87.5000 (76.1788)  time: 0.3446  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [ 290/3750]  eta: 0:19:55  Lr: 0.030000  Loss: 0.8741  Acc@1: 37.5000 (28.3290)  Acc@5: 93.7500 (76.8041)  time: 0.3446  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [ 300/3750]  eta: 0:19:51  Lr: 0.030000  Loss: 0.9465  Acc@1: 37.5000 (28.6960)  Acc@5: 93.7500 (77.3048)  time: 0.3431  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [ 310/3750]  eta: 0:19:48  Lr: 0.030000  Loss: 0.9036  Acc@1: 37.5000 (28.9791)  Acc@5: 87.5000 (77.6125)  time: 0.3427  data: 0.0002  max mem: 2502
Train: Epoch[1/5]  [ 320/3750]  eta: 0:19:44  Lr: 0.030000  Loss: 0.8269  Acc@1: 37.5000 (29.4003)  Acc@5: 93.7500 (78.1347)  time: 0.3427  data: 0.0002  max mem: 2502
Train: Epoch[1/5]  [ 330/3750]  eta: 0:19:40  Lr: 0.030000  Loss: 0.8874  Acc@1: 37.5000 (29.5695)  Acc@5: 93.7500 (78.5687)  time: 0.3429  data: 0.0002  max mem: 2502
Train: Epoch[1/5]  [ 340/3750]  eta: 0:19:37  Lr: 0.030000  Loss: 0.8939  Acc@1: 37.5000 (29.8937)  Acc@5: 93.7500 (78.8673)  time: 0.3432  data: 0.0002  max mem: 2502
Train: Epoch[1/5]  [ 350/3750]  eta: 0:19:33  Lr: 0.030000  Loss: 0.8787  Acc@1: 37.5000 (30.1104)  Acc@5: 93.7500 (79.3447)  time: 0.3432  data: 0.0002  max mem: 2502
Train: Epoch[1/5]  [ 360/3750]  eta: 0:19:29  Lr: 0.030000  Loss: 0.9001  Acc@1: 31.2500 (30.1766)  Acc@5: 93.7500 (79.6053)  time: 0.3439  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [ 370/3750]  eta: 0:19:26  Lr: 0.030000  Loss: 0.8585  Acc@1: 37.5000 (30.5761)  Acc@5: 93.7500 (79.9697)  time: 0.3452  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [ 380/3750]  eta: 0:19:23  Lr: 0.030000  Loss: 0.8674  Acc@1: 43.7500 (30.9383)  Acc@5: 93.7500 (80.3970)  time: 0.3469  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [ 390/3750]  eta: 0:19:19  Lr: 0.030000  Loss: 0.9151  Acc@1: 37.5000 (31.2020)  Acc@5: 93.7500 (80.5946)  time: 0.3463  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [ 400/3750]  eta: 0:19:16  Lr: 0.030000  Loss: 0.8318  Acc@1: 37.5000 (31.4838)  Acc@5: 87.5000 (80.8448)  time: 0.3451  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [ 410/3750]  eta: 0:19:12  Lr: 0.030000  Loss: 0.9054  Acc@1: 43.7500 (31.6454)  Acc@5: 93.7500 (81.2196)  time: 0.3452  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [ 420/3750]  eta: 0:19:09  Lr: 0.030000  Loss: 0.8628  Acc@1: 43.7500 (31.8141)  Acc@5: 93.7500 (81.4430)  time: 0.3451  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [ 430/3750]  eta: 0:19:06  Lr: 0.030000  Loss: 0.8770  Acc@1: 37.5000 (31.9751)  Acc@5: 87.5000 (81.6415)  time: 0.3457  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [ 440/3750]  eta: 0:19:02  Lr: 0.030000  Loss: 0.9399  Acc@1: 43.7500 (32.2562)  Acc@5: 87.5000 (81.8878)  time: 0.3464  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [ 450/3750]  eta: 0:18:59  Lr: 0.030000  Loss: 0.9108  Acc@1: 43.7500 (32.4972)  Acc@5: 93.7500 (82.1092)  time: 0.3453  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [ 460/3750]  eta: 0:18:55  Lr: 0.030000  Loss: 0.8290  Acc@1: 43.7500 (32.8227)  Acc@5: 93.7500 (82.2939)  time: 0.3441  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [ 470/3750]  eta: 0:18:52  Lr: 0.030000  Loss: 0.9191  Acc@1: 50.0000 (33.2006)  Acc@5: 93.7500 (82.5504)  time: 0.3443  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [ 480/3750]  eta: 0:18:48  Lr: 0.030000  Loss: 0.7977  Acc@1: 43.7500 (33.4330)  Acc@5: 93.7500 (82.7703)  time: 0.3443  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [ 490/3750]  eta: 0:18:45  Lr: 0.030000  Loss: 0.8652  Acc@1: 43.7500 (33.6049)  Acc@5: 93.7500 (82.9684)  time: 0.3443  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [ 500/3750]  eta: 0:18:41  Lr: 0.030000  Loss: 0.6579  Acc@1: 43.7500 (33.7949)  Acc@5: 93.7500 (83.1088)  time: 0.3451  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [ 510/3750]  eta: 0:18:38  Lr: 0.030000  Loss: 0.6662  Acc@1: 43.7500 (33.9897)  Acc@5: 93.7500 (83.3537)  time: 0.3445  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [ 520/3750]  eta: 0:18:34  Lr: 0.030000  Loss: 0.6854  Acc@1: 37.5000 (34.1291)  Acc@5: 93.7500 (83.5653)  time: 0.3434  data: 0.0002  max mem: 2502
Train: Epoch[1/5]  [ 530/3750]  eta: 0:18:31  Lr: 0.030000  Loss: 0.8254  Acc@1: 37.5000 (34.2985)  Acc@5: 93.7500 (83.8041)  time: 0.3433  data: 0.0002  max mem: 2502
Train: Epoch[1/5]  [ 540/3750]  eta: 0:18:27  Lr: 0.030000  Loss: 0.7951  Acc@1: 43.7500 (34.5541)  Acc@5: 93.7500 (84.0226)  time: 0.3442  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [ 550/3750]  eta: 0:18:24  Lr: 0.030000  Loss: 0.7524  Acc@1: 43.7500 (34.8230)  Acc@5: 93.7500 (84.1652)  time: 0.3455  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [ 560/3750]  eta: 0:18:20  Lr: 0.030000  Loss: 0.8650  Acc@1: 43.7500 (35.0267)  Acc@5: 87.5000 (84.2580)  time: 0.3467  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [ 570/3750]  eta: 0:18:17  Lr: 0.030000  Loss: 0.7733  Acc@1: 43.7500 (35.2342)  Acc@5: 93.7500 (84.4133)  time: 0.3473  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [ 580/3750]  eta: 0:18:14  Lr: 0.030000  Loss: 0.7311  Acc@1: 43.7500 (35.4669)  Acc@5: 93.7500 (84.5740)  time: 0.3469  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [ 590/3750]  eta: 0:18:10  Lr: 0.030000  Loss: 0.7462  Acc@1: 50.0000 (35.6070)  Acc@5: 93.7500 (84.7187)  time: 0.3459  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [ 600/3750]  eta: 0:18:07  Lr: 0.030000  Loss: 0.8166  Acc@1: 50.0000 (36.0129)  Acc@5: 93.7500 (84.9106)  time: 0.3466  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [ 610/3750]  eta: 0:18:04  Lr: 0.030000  Loss: 0.8377  Acc@1: 50.0000 (36.1395)  Acc@5: 93.7500 (85.0348)  time: 0.3470  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [ 620/3750]  eta: 0:18:00  Lr: 0.030000  Loss: 0.6834  Acc@1: 43.7500 (36.3728)  Acc@5: 93.7500 (85.1550)  time: 0.3455  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [ 630/3750]  eta: 0:17:57  Lr: 0.030000  Loss: 0.7629  Acc@1: 37.5000 (36.4105)  Acc@5: 93.7500 (85.3011)  time: 0.3449  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [ 640/3750]  eta: 0:17:53  Lr: 0.030000  Loss: 0.7385  Acc@1: 37.5000 (36.5347)  Acc@5: 93.7500 (85.4037)  time: 0.3442  data: 0.0002  max mem: 2502
Train: Epoch[1/5]  [ 650/3750]  eta: 0:17:50  Lr: 0.030000  Loss: 0.7448  Acc@1: 43.7500 (36.6839)  Acc@5: 93.7500 (85.5127)  time: 0.3438  data: 0.0002  max mem: 2502
Train: Epoch[1/5]  [ 660/3750]  eta: 0:17:46  Lr: 0.030000  Loss: 0.6897  Acc@1: 43.7500 (36.9232)  Acc@5: 93.7500 (85.6278)  time: 0.3470  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [ 670/3750]  eta: 0:17:43  Lr: 0.030000  Loss: 0.6809  Acc@1: 43.7500 (37.0529)  Acc@5: 93.7500 (85.6837)  time: 0.3479  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [ 680/3750]  eta: 0:17:40  Lr: 0.030000  Loss: 0.6504  Acc@1: 50.0000 (37.2522)  Acc@5: 93.7500 (85.8113)  time: 0.3463  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [ 690/3750]  eta: 0:17:36  Lr: 0.030000  Loss: 0.7037  Acc@1: 50.0000 (37.3734)  Acc@5: 93.7500 (85.9171)  time: 0.3456  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [ 700/3750]  eta: 0:17:33  Lr: 0.030000  Loss: 0.6860  Acc@1: 50.0000 (37.6427)  Acc@5: 93.7500 (86.0200)  time: 0.3441  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [ 710/3750]  eta: 0:17:29  Lr: 0.030000  Loss: 0.7447  Acc@1: 56.2500 (37.8252)  Acc@5: 93.7500 (86.1463)  time: 0.3439  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [ 720/3750]  eta: 0:17:25  Lr: 0.030000  Loss: 0.8335  Acc@1: 50.0000 (37.9854)  Acc@5: 100.0000 (86.3124)  time: 0.3438  data: 0.0002  max mem: 2502
Train: Epoch[1/5]  [ 730/3750]  eta: 0:17:22  Lr: 0.030000  Loss: 0.7589  Acc@1: 50.0000 (38.1583)  Acc@5: 100.0000 (86.4313)  time: 0.3445  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [ 740/3750]  eta: 0:17:19  Lr: 0.030000  Loss: 0.6272  Acc@1: 50.0000 (38.4362)  Acc@5: 93.7500 (86.5638)  time: 0.3455  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [ 750/3750]  eta: 0:17:15  Lr: 0.030000  Loss: 0.8519  Acc@1: 50.0000 (38.5819)  Acc@5: 93.7500 (86.6595)  time: 0.3458  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [ 760/3750]  eta: 0:17:12  Lr: 0.030000  Loss: 0.7036  Acc@1: 50.0000 (38.7073)  Acc@5: 93.7500 (86.7280)  time: 0.3455  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [ 770/3750]  eta: 0:17:08  Lr: 0.030000  Loss: 0.7638  Acc@1: 43.7500 (38.6916)  Acc@5: 93.7500 (86.8029)  time: 0.3447  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [ 780/3750]  eta: 0:17:05  Lr: 0.030000  Loss: 0.7137  Acc@1: 43.7500 (38.8204)  Acc@5: 93.7500 (86.8838)  time: 0.3448  data: 0.0002  max mem: 2502
Train: Epoch[1/5]  [ 790/3750]  eta: 0:17:01  Lr: 0.030000  Loss: 0.6933  Acc@1: 50.0000 (38.9776)  Acc@5: 93.7500 (86.9943)  time: 0.3454  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [ 800/3750]  eta: 0:16:58  Lr: 0.030000  Loss: 0.7405  Acc@1: 50.0000 (39.1074)  Acc@5: 93.7500 (87.1021)  time: 0.3452  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [ 810/3750]  eta: 0:16:54  Lr: 0.030000  Loss: 0.6982  Acc@1: 50.0000 (39.2879)  Acc@5: 93.7500 (87.1994)  time: 0.3457  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [ 820/3750]  eta: 0:16:51  Lr: 0.030000  Loss: 0.5559  Acc@1: 56.2500 (39.4488)  Acc@5: 93.7500 (87.2640)  time: 0.3450  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [ 830/3750]  eta: 0:16:47  Lr: 0.030000  Loss: 0.6543  Acc@1: 56.2500 (39.6285)  Acc@5: 93.7500 (87.3345)  time: 0.3433  data: 0.0002  max mem: 2502
Train: Epoch[1/5]  [ 840/3750]  eta: 0:16:44  Lr: 0.030000  Loss: 0.6276  Acc@1: 56.2500 (39.7295)  Acc@5: 93.7500 (87.4108)  time: 0.3430  data: 0.0002  max mem: 2502
Train: Epoch[1/5]  [ 850/3750]  eta: 0:16:40  Lr: 0.030000  Loss: 0.6730  Acc@1: 43.7500 (39.8208)  Acc@5: 93.7500 (87.4706)  time: 0.3430  data: 0.0002  max mem: 2502
Train: Epoch[1/5]  [ 860/3750]  eta: 0:16:37  Lr: 0.030000  Loss: 0.6670  Acc@1: 43.7500 (39.8737)  Acc@5: 93.7500 (87.5363)  time: 0.3432  data: 0.0002  max mem: 2502
Train: Epoch[1/5]  [ 870/3750]  eta: 0:16:33  Lr: 0.030000  Loss: 0.5576  Acc@1: 50.0000 (40.0904)  Acc@5: 93.7500 (87.6292)  time: 0.3433  data: 0.0002  max mem: 2502
Train: Epoch[1/5]  [ 880/3750]  eta: 0:16:30  Lr: 0.030000  Loss: 0.5493  Acc@1: 50.0000 (40.2738)  Acc@5: 100.0000 (87.7625)  time: 0.3431  data: 0.0002  max mem: 2502
Train: Epoch[1/5]  [ 890/3750]  eta: 0:16:26  Lr: 0.030000  Loss: 0.6537  Acc@1: 50.0000 (40.4251)  Acc@5: 100.0000 (87.8367)  time: 0.3431  data: 0.0002  max mem: 2502
Train: Epoch[1/5]  [ 900/3750]  eta: 0:16:23  Lr: 0.030000  Loss: 0.6976  Acc@1: 50.0000 (40.5036)  Acc@5: 93.7500 (87.9231)  time: 0.3443  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [ 910/3750]  eta: 0:16:19  Lr: 0.030000  Loss: 0.6358  Acc@1: 50.0000 (40.6353)  Acc@5: 93.7500 (87.9871)  time: 0.3456  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [ 920/3750]  eta: 0:16:16  Lr: 0.030000  Loss: 0.5356  Acc@1: 56.2500 (40.8252)  Acc@5: 93.7500 (88.0700)  time: 0.3459  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [ 930/3750]  eta: 0:16:13  Lr: 0.030000  Loss: 0.6101  Acc@1: 56.2500 (40.9036)  Acc@5: 93.7500 (88.1310)  time: 0.3465  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [ 940/3750]  eta: 0:16:09  Lr: 0.030000  Loss: 0.5460  Acc@1: 56.2500 (41.0667)  Acc@5: 100.0000 (88.2372)  time: 0.3462  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [ 950/3750]  eta: 0:16:06  Lr: 0.030000  Loss: 0.7892  Acc@1: 56.2500 (41.1606)  Acc@5: 93.7500 (88.2886)  time: 0.3455  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [ 960/3750]  eta: 0:16:02  Lr: 0.030000  Loss: 0.5165  Acc@1: 50.0000 (41.3371)  Acc@5: 93.7500 (88.3910)  time: 0.3457  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [ 970/3750]  eta: 0:15:59  Lr: 0.030000  Loss: 0.6103  Acc@1: 56.2500 (41.4779)  Acc@5: 93.7500 (88.4462)  time: 0.3454  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [ 980/3750]  eta: 0:15:56  Lr: 0.030000  Loss: 0.6013  Acc@1: 50.0000 (41.5902)  Acc@5: 93.7500 (88.5130)  time: 0.3463  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [ 990/3750]  eta: 0:15:52  Lr: 0.030000  Loss: 0.5607  Acc@1: 50.0000 (41.7318)  Acc@5: 93.7500 (88.5848)  time: 0.3462  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [1000/3750]  eta: 0:15:49  Lr: 0.030000  Loss: 0.5597  Acc@1: 56.2500 (41.8894)  Acc@5: 93.7500 (88.6239)  time: 0.3462  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [1010/3750]  eta: 0:15:45  Lr: 0.030000  Loss: 0.4220  Acc@1: 56.2500 (42.0190)  Acc@5: 93.7500 (88.6993)  time: 0.3467  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [1020/3750]  eta: 0:15:42  Lr: 0.030000  Loss: 0.4178  Acc@1: 56.2500 (42.1462)  Acc@5: 100.0000 (88.7733)  time: 0.3451  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [1030/3750]  eta: 0:15:38  Lr: 0.030000  Loss: 0.5724  Acc@1: 56.2500 (42.2587)  Acc@5: 93.7500 (88.8397)  time: 0.3446  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [1040/3750]  eta: 0:15:35  Lr: 0.030000  Loss: 0.5393  Acc@1: 56.2500 (42.3331)  Acc@5: 93.7500 (88.9049)  time: 0.3447  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [1050/3750]  eta: 0:15:31  Lr: 0.030000  Loss: 0.5049  Acc@1: 50.0000 (42.3882)  Acc@5: 93.7500 (88.9510)  time: 0.3449  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [1060/3750]  eta: 0:15:28  Lr: 0.030000  Loss: 0.4522  Acc@1: 56.2500 (42.5836)  Acc@5: 93.7500 (89.0080)  time: 0.3458  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [1070/3750]  eta: 0:15:25  Lr: 0.030000  Loss: 0.5287  Acc@1: 62.5000 (42.7638)  Acc@5: 100.0000 (89.0815)  time: 0.3458  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [1080/3750]  eta: 0:15:21  Lr: 0.030000  Loss: 0.5337  Acc@1: 56.2500 (42.8943)  Acc@5: 100.0000 (89.1478)  time: 0.3460  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [1090/3750]  eta: 0:15:18  Lr: 0.030000  Loss: 0.5521  Acc@1: 56.2500 (43.0626)  Acc@5: 93.7500 (89.2071)  time: 0.3457  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [1100/3750]  eta: 0:15:14  Lr: 0.030000  Loss: 0.6138  Acc@1: 56.2500 (43.1540)  Acc@5: 100.0000 (89.2825)  time: 0.3447  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [1110/3750]  eta: 0:15:11  Lr: 0.030000  Loss: 0.4181  Acc@1: 56.2500 (43.2775)  Acc@5: 93.7500 (89.3227)  time: 0.3446  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [1120/3750]  eta: 0:15:07  Lr: 0.030000  Loss: 0.6327  Acc@1: 56.2500 (43.3932)  Acc@5: 93.7500 (89.3733)  time: 0.3447  data: 0.0002  max mem: 2502
Train: Epoch[1/5]  [1130/3750]  eta: 0:15:04  Lr: 0.030000  Loss: 0.4669  Acc@1: 50.0000 (43.5124)  Acc@5: 93.7500 (89.4231)  time: 0.3443  data: 0.0002  max mem: 2502
Train: Epoch[1/5]  [1140/3750]  eta: 0:15:00  Lr: 0.030000  Loss: 0.6335  Acc@1: 50.0000 (43.6404)  Acc@5: 93.7500 (89.4774)  time: 0.3430  data: 0.0002  max mem: 2502
Train: Epoch[1/5]  [1150/3750]  eta: 0:14:57  Lr: 0.030000  Loss: 0.5042  Acc@1: 56.2500 (43.7609)  Acc@5: 93.7500 (89.5200)  time: 0.3426  data: 0.0002  max mem: 2502
Train: Epoch[1/5]  [1160/3750]  eta: 0:14:53  Lr: 0.030000  Loss: 0.4150  Acc@1: 56.2500 (43.9223)  Acc@5: 100.0000 (89.5780)  time: 0.3442  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [1170/3750]  eta: 0:14:50  Lr: 0.030000  Loss: 0.5984  Acc@1: 56.2500 (44.0115)  Acc@5: 93.7500 (89.6082)  time: 0.3452  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [1180/3750]  eta: 0:14:46  Lr: 0.030000  Loss: 0.5826  Acc@1: 50.0000 (44.0517)  Acc@5: 93.7500 (89.6433)  time: 0.3447  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [1190/3750]  eta: 0:14:43  Lr: 0.030000  Loss: 0.4682  Acc@1: 56.2500 (44.1646)  Acc@5: 93.7500 (89.6883)  time: 0.3442  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [1200/3750]  eta: 0:14:39  Lr: 0.030000  Loss: 0.3655  Acc@1: 56.2500 (44.2704)  Acc@5: 93.7500 (89.7221)  time: 0.3448  data: 0.0007  max mem: 2502
Train: Epoch[1/5]  [1210/3750]  eta: 0:14:36  Lr: 0.030000  Loss: 0.5373  Acc@1: 56.2500 (44.3538)  Acc@5: 93.7500 (89.7347)  time: 0.3454  data: 0.0007  max mem: 2502
Train: Epoch[1/5]  [1220/3750]  eta: 0:14:33  Lr: 0.030000  Loss: 0.4045  Acc@1: 56.2500 (44.4769)  Acc@5: 93.7500 (89.7932)  time: 0.3445  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [1230/3750]  eta: 0:14:29  Lr: 0.030000  Loss: 0.6227  Acc@1: 56.2500 (44.5827)  Acc@5: 100.0000 (89.8406)  time: 0.3447  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [1240/3750]  eta: 0:14:26  Lr: 0.030000  Loss: 0.4551  Acc@1: 56.2500 (44.6968)  Acc@5: 93.7500 (89.8822)  time: 0.3440  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [1250/3750]  eta: 0:14:22  Lr: 0.030000  Loss: 0.5852  Acc@1: 56.2500 (44.7742)  Acc@5: 93.7500 (89.9231)  time: 0.3429  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [1260/3750]  eta: 0:14:19  Lr: 0.030000  Loss: 0.5198  Acc@1: 50.0000 (44.8701)  Acc@5: 93.7500 (89.9683)  time: 0.3428  data: 0.0002  max mem: 2502
Train: Epoch[1/5]  [1270/3750]  eta: 0:14:15  Lr: 0.030000  Loss: 0.5001  Acc@1: 56.2500 (45.0089)  Acc@5: 100.0000 (90.0275)  time: 0.3430  data: 0.0002  max mem: 2502
Train: Epoch[1/5]  [1280/3750]  eta: 0:14:12  Lr: 0.030000  Loss: 0.3759  Acc@1: 62.5000 (45.1454)  Acc@5: 100.0000 (90.0810)  time: 0.3434  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [1290/3750]  eta: 0:14:08  Lr: 0.030000  Loss: 0.3913  Acc@1: 62.5000 (45.2895)  Acc@5: 100.0000 (90.1385)  time: 0.3437  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [1300/3750]  eta: 0:14:05  Lr: 0.030000  Loss: 0.2657  Acc@1: 62.5000 (45.3930)  Acc@5: 100.0000 (90.1710)  time: 0.3443  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [1310/3750]  eta: 0:14:01  Lr: 0.030000  Loss: 0.3967  Acc@1: 56.2500 (45.4901)  Acc@5: 100.0000 (90.2222)  time: 0.3443  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [1320/3750]  eta: 0:13:58  Lr: 0.030000  Loss: 0.5156  Acc@1: 62.5000 (45.5857)  Acc@5: 93.7500 (90.2489)  time: 0.3446  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [1330/3750]  eta: 0:13:54  Lr: 0.030000  Loss: 0.4628  Acc@1: 62.5000 (45.6659)  Acc@5: 93.7500 (90.2799)  time: 0.3453  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [1340/3750]  eta: 0:13:51  Lr: 0.030000  Loss: 0.5055  Acc@1: 56.2500 (45.7261)  Acc@5: 93.7500 (90.3430)  time: 0.3449  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [1350/3750]  eta: 0:13:47  Lr: 0.030000  Loss: 0.5981  Acc@1: 56.2500 (45.7855)  Acc@5: 100.0000 (90.3682)  time: 0.3451  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [1360/3750]  eta: 0:13:44  Lr: 0.030000  Loss: 0.6548  Acc@1: 50.0000 (45.8303)  Acc@5: 93.7500 (90.3885)  time: 0.3459  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [1370/3750]  eta: 0:13:41  Lr: 0.030000  Loss: 0.5438  Acc@1: 56.2500 (45.9291)  Acc@5: 93.7500 (90.4313)  time: 0.3458  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [1380/3750]  eta: 0:13:37  Lr: 0.030000  Loss: 0.4670  Acc@1: 62.5000 (46.0626)  Acc@5: 100.0000 (90.4870)  time: 0.3456  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [1390/3750]  eta: 0:13:34  Lr: 0.030000  Loss: 0.5622  Acc@1: 62.5000 (46.1449)  Acc@5: 100.0000 (90.5329)  time: 0.3457  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [1400/3750]  eta: 0:13:30  Lr: 0.030000  Loss: 0.5920  Acc@1: 56.2500 (46.2393)  Acc@5: 93.7500 (90.5648)  time: 0.3452  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [1410/3750]  eta: 0:13:27  Lr: 0.030000  Loss: 0.4768  Acc@1: 56.2500 (46.3545)  Acc@5: 93.7500 (90.6006)  time: 0.3450  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [1420/3750]  eta: 0:13:23  Lr: 0.030000  Loss: 0.3473  Acc@1: 56.2500 (46.4242)  Acc@5: 93.7500 (90.6360)  time: 0.3444  data: 0.0002  max mem: 2502
Train: Epoch[1/5]  [1430/3750]  eta: 0:13:20  Lr: 0.030000  Loss: 0.3430  Acc@1: 50.0000 (46.5059)  Acc@5: 93.7500 (90.6796)  time: 0.3443  data: 0.0002  max mem: 2502
Train: Epoch[1/5]  [1440/3750]  eta: 0:13:16  Lr: 0.030000  Loss: 0.5105  Acc@1: 50.0000 (46.5649)  Acc@5: 100.0000 (90.7226)  time: 0.3440  data: 0.0002  max mem: 2502
Train: Epoch[1/5]  [1450/3750]  eta: 0:13:13  Lr: 0.030000  Loss: 0.4725  Acc@1: 56.2500 (46.6532)  Acc@5: 93.7500 (90.7564)  time: 0.3449  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [1460/3750]  eta: 0:13:10  Lr: 0.030000  Loss: 0.4601  Acc@1: 62.5000 (46.7616)  Acc@5: 100.0000 (90.7897)  time: 0.3463  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [1470/3750]  eta: 0:13:06  Lr: 0.030000  Loss: 0.2804  Acc@1: 62.5000 (46.8601)  Acc@5: 100.0000 (90.8183)  time: 0.3462  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [1480/3750]  eta: 0:13:03  Lr: 0.030000  Loss: 0.7018  Acc@1: 62.5000 (46.9446)  Acc@5: 100.0000 (90.8508)  time: 0.3453  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [1490/3750]  eta: 0:12:59  Lr: 0.030000  Loss: 0.4729  Acc@1: 62.5000 (47.0448)  Acc@5: 93.7500 (90.8660)  time: 0.3443  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [1500/3750]  eta: 0:12:56  Lr: 0.030000  Loss: 0.6191  Acc@1: 62.5000 (47.1269)  Acc@5: 100.0000 (90.9102)  time: 0.3444  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [1510/3750]  eta: 0:12:52  Lr: 0.030000  Loss: 0.4570  Acc@1: 62.5000 (47.1914)  Acc@5: 100.0000 (90.9580)  time: 0.3456  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [1520/3750]  eta: 0:12:49  Lr: 0.030000  Loss: 0.4069  Acc@1: 56.2500 (47.2962)  Acc@5: 100.0000 (91.0051)  time: 0.3449  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [1530/3750]  eta: 0:12:45  Lr: 0.030000  Loss: 0.3816  Acc@1: 62.5000 (47.4118)  Acc@5: 100.0000 (91.0516)  time: 0.3431  data: 0.0002  max mem: 2502
Train: Epoch[1/5]  [1540/3750]  eta: 0:12:42  Lr: 0.030000  Loss: 0.3700  Acc@1: 56.2500 (47.4611)  Acc@5: 100.0000 (91.0691)  time: 0.3430  data: 0.0002  max mem: 2502
Train: Epoch[1/5]  [1550/3750]  eta: 0:12:38  Lr: 0.030000  Loss: 0.3714  Acc@1: 56.2500 (47.5177)  Acc@5: 93.7500 (91.1025)  time: 0.3444  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [1560/3750]  eta: 0:12:35  Lr: 0.030000  Loss: 0.4784  Acc@1: 62.5000 (47.6017)  Acc@5: 100.0000 (91.1395)  time: 0.3459  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [1570/3750]  eta: 0:12:32  Lr: 0.030000  Loss: 0.4935  Acc@1: 62.5000 (47.6806)  Acc@5: 100.0000 (91.1800)  time: 0.3452  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [1580/3750]  eta: 0:12:28  Lr: 0.030000  Loss: 0.5629  Acc@1: 56.2500 (47.7427)  Acc@5: 100.0000 (91.2160)  time: 0.3447  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [1590/3750]  eta: 0:12:25  Lr: 0.030000  Loss: 0.3449  Acc@1: 56.2500 (47.8041)  Acc@5: 100.0000 (91.2516)  time: 0.3446  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [1600/3750]  eta: 0:12:21  Lr: 0.030000  Loss: 0.4161  Acc@1: 62.5000 (47.9154)  Acc@5: 100.0000 (91.2867)  time: 0.3442  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [1610/3750]  eta: 0:12:18  Lr: 0.030000  Loss: 0.4812  Acc@1: 62.5000 (47.9865)  Acc@5: 93.7500 (91.3020)  time: 0.3441  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [1620/3750]  eta: 0:12:14  Lr: 0.030000  Loss: 0.5325  Acc@1: 56.2500 (48.0606)  Acc@5: 93.7500 (91.3325)  time: 0.3442  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [1630/3750]  eta: 0:12:11  Lr: 0.030000  Loss: 0.3455  Acc@1: 56.2500 (48.0993)  Acc@5: 100.0000 (91.3665)  time: 0.3440  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [1640/3750]  eta: 0:12:07  Lr: 0.030000  Loss: 0.4957  Acc@1: 62.5000 (48.2290)  Acc@5: 100.0000 (91.4039)  time: 0.3441  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [1650/3750]  eta: 0:12:04  Lr: 0.030000  Loss: 0.2955  Acc@1: 75.0000 (48.3608)  Acc@5: 100.0000 (91.4408)  time: 0.3447  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [1660/3750]  eta: 0:12:00  Lr: 0.030000  Loss: 0.2879  Acc@1: 68.7500 (48.4723)  Acc@5: 100.0000 (91.4660)  time: 0.3440  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [1670/3750]  eta: 0:11:57  Lr: 0.030000  Loss: 0.3833  Acc@1: 68.7500 (48.5974)  Acc@5: 100.0000 (91.5021)  time: 0.3427  data: 0.0002  max mem: 2502
Train: Epoch[1/5]  [1680/3750]  eta: 0:11:53  Lr: 0.030000  Loss: 0.2248  Acc@1: 68.7500 (48.6913)  Acc@5: 100.0000 (91.5378)  time: 0.3424  data: 0.0002  max mem: 2502
Train: Epoch[1/5]  [1690/3750]  eta: 0:11:50  Lr: 0.030000  Loss: 0.2755  Acc@1: 68.7500 (48.7840)  Acc@5: 93.7500 (91.5546)  time: 0.3425  data: 0.0002  max mem: 2502
Train: Epoch[1/5]  [1700/3750]  eta: 0:11:47  Lr: 0.030000  Loss: 0.4713  Acc@1: 56.2500 (48.8389)  Acc@5: 93.7500 (91.5895)  time: 0.3427  data: 0.0002  max mem: 2502
Train: Epoch[1/5]  [1710/3750]  eta: 0:11:43  Lr: 0.030000  Loss: 0.4364  Acc@1: 56.2500 (48.9151)  Acc@5: 100.0000 (91.6167)  time: 0.3441  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [1720/3750]  eta: 0:11:40  Lr: 0.030000  Loss: 0.3481  Acc@1: 56.2500 (48.9904)  Acc@5: 93.7500 (91.6473)  time: 0.3450  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [1730/3750]  eta: 0:11:36  Lr: 0.030000  Loss: 0.5543  Acc@1: 56.2500 (49.0576)  Acc@5: 93.7500 (91.6703)  time: 0.3451  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [1740/3750]  eta: 0:11:33  Lr: 0.030000  Loss: 0.2924  Acc@1: 62.5000 (49.1277)  Acc@5: 93.7500 (91.7038)  time: 0.3453  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [1750/3750]  eta: 0:11:29  Lr: 0.030000  Loss: 0.4201  Acc@1: 56.2500 (49.1862)  Acc@5: 93.7500 (91.7190)  time: 0.3445  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [1760/3750]  eta: 0:11:26  Lr: 0.030000  Loss: 0.4265  Acc@1: 56.2500 (49.2547)  Acc@5: 93.7500 (91.7412)  time: 0.3441  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [1770/3750]  eta: 0:11:22  Lr: 0.030000  Loss: 0.3845  Acc@1: 56.2500 (49.2977)  Acc@5: 93.7500 (91.7561)  time: 0.3444  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [1780/3750]  eta: 0:11:19  Lr: 0.030000  Loss: 0.4337  Acc@1: 50.0000 (49.2981)  Acc@5: 93.7500 (91.7848)  time: 0.3439  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [1790/3750]  eta: 0:11:15  Lr: 0.030000  Loss: 0.4116  Acc@1: 50.0000 (49.3405)  Acc@5: 100.0000 (91.8132)  time: 0.3438  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [1800/3750]  eta: 0:11:12  Lr: 0.030000  Loss: 0.4920  Acc@1: 56.2500 (49.3927)  Acc@5: 100.0000 (91.8275)  time: 0.3442  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [1810/3750]  eta: 0:11:09  Lr: 0.030000  Loss: 0.5140  Acc@1: 56.2500 (49.4513)  Acc@5: 93.7500 (91.8553)  time: 0.3453  data: 0.0011  max mem: 2502
Train: Epoch[1/5]  [1820/3750]  eta: 0:11:05  Lr: 0.030000  Loss: 0.4911  Acc@1: 56.2500 (49.5298)  Acc@5: 100.0000 (91.8898)  time: 0.3445  data: 0.0011  max mem: 2502
Train: Epoch[1/5]  [1830/3750]  eta: 0:11:02  Lr: 0.030000  Loss: 0.3715  Acc@1: 62.5000 (49.6075)  Acc@5: 100.0000 (91.9341)  time: 0.3425  data: 0.0002  max mem: 2502
Train: Epoch[1/5]  [1840/3750]  eta: 0:10:58  Lr: 0.030000  Loss: 0.2802  Acc@1: 62.5000 (49.6877)  Acc@5: 100.0000 (91.9643)  time: 0.3424  data: 0.0002  max mem: 2502
Train: Epoch[1/5]  [1850/3750]  eta: 0:10:55  Lr: 0.030000  Loss: 0.4373  Acc@1: 62.5000 (49.7029)  Acc@5: 100.0000 (91.9841)  time: 0.3426  data: 0.0002  max mem: 2502
Train: Epoch[1/5]  [1860/3750]  eta: 0:10:51  Lr: 0.030000  Loss: 0.3490  Acc@1: 56.2500 (49.7884)  Acc@5: 100.0000 (92.0171)  time: 0.3431  data: 0.0002  max mem: 2502
Train: Epoch[1/5]  [1870/3750]  eta: 0:10:48  Lr: 0.030000  Loss: 0.4223  Acc@1: 56.2500 (49.8196)  Acc@5: 100.0000 (92.0430)  time: 0.3440  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [1880/3750]  eta: 0:10:44  Lr: 0.030000  Loss: 0.3726  Acc@1: 56.2500 (49.8604)  Acc@5: 93.7500 (92.0554)  time: 0.3443  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [1890/3750]  eta: 0:10:41  Lr: 0.030000  Loss: 0.4630  Acc@1: 56.2500 (49.9207)  Acc@5: 93.7500 (92.0809)  time: 0.3445  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [1900/3750]  eta: 0:10:37  Lr: 0.030000  Loss: 0.2222  Acc@1: 62.5000 (49.9868)  Acc@5: 93.7500 (92.0864)  time: 0.3451  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [1910/3750]  eta: 0:10:34  Lr: 0.030000  Loss: 0.1835  Acc@1: 62.5000 (50.0556)  Acc@5: 100.0000 (92.1147)  time: 0.3456  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [1920/3750]  eta: 0:10:31  Lr: 0.030000  Loss: 0.4343  Acc@1: 62.5000 (50.1139)  Acc@5: 100.0000 (92.1232)  time: 0.3459  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [1930/3750]  eta: 0:10:27  Lr: 0.030000  Loss: 0.3011  Acc@1: 62.5000 (50.2039)  Acc@5: 93.7500 (92.1381)  time: 0.3453  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [1940/3750]  eta: 0:10:24  Lr: 0.030000  Loss: 0.2715  Acc@1: 62.5000 (50.2608)  Acc@5: 93.7500 (92.1658)  time: 0.3442  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [1950/3750]  eta: 0:10:20  Lr: 0.030000  Loss: 0.3142  Acc@1: 62.5000 (50.3171)  Acc@5: 100.0000 (92.1835)  time: 0.3454  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [1960/3750]  eta: 0:10:17  Lr: 0.030000  Loss: 0.3002  Acc@1: 62.5000 (50.3793)  Acc@5: 100.0000 (92.2074)  time: 0.3460  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [1970/3750]  eta: 0:10:13  Lr: 0.030000  Loss: 0.2790  Acc@1: 62.5000 (50.4281)  Acc@5: 100.0000 (92.2279)  time: 0.3449  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [1980/3750]  eta: 0:10:10  Lr: 0.030000  Loss: 0.4267  Acc@1: 56.2500 (50.4732)  Acc@5: 100.0000 (92.2609)  time: 0.3451  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [1990/3750]  eta: 0:10:06  Lr: 0.030000  Loss: 0.4017  Acc@1: 62.5000 (50.5431)  Acc@5: 100.0000 (92.2872)  time: 0.3453  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [2000/3750]  eta: 0:10:03  Lr: 0.030000  Loss: 0.2690  Acc@1: 62.5000 (50.5778)  Acc@5: 100.0000 (92.3038)  time: 0.3452  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [2010/3750]  eta: 0:10:00  Lr: 0.030000  Loss: 0.2852  Acc@1: 62.5000 (50.6651)  Acc@5: 100.0000 (92.3359)  time: 0.3452  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [2020/3750]  eta: 0:09:56  Lr: 0.030000  Loss: 0.3515  Acc@1: 68.7500 (50.7360)  Acc@5: 100.0000 (92.3676)  time: 0.3459  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [2030/3750]  eta: 0:09:53  Lr: 0.030000  Loss: 0.3764  Acc@1: 68.7500 (50.8093)  Acc@5: 100.0000 (92.3898)  time: 0.3450  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [2040/3750]  eta: 0:09:49  Lr: 0.030000  Loss: 0.4970  Acc@1: 62.5000 (50.8574)  Acc@5: 100.0000 (92.3996)  time: 0.3434  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [2050/3750]  eta: 0:09:46  Lr: 0.030000  Loss: 0.6293  Acc@1: 62.5000 (50.9142)  Acc@5: 100.0000 (92.4183)  time: 0.3433  data: 0.0002  max mem: 2502
Train: Epoch[1/5]  [2060/3750]  eta: 0:09:42  Lr: 0.030000  Loss: 0.4357  Acc@1: 62.5000 (50.9643)  Acc@5: 93.7500 (92.4248)  time: 0.3436  data: 0.0002  max mem: 2502
Train: Epoch[1/5]  [2070/3750]  eta: 0:09:39  Lr: 0.030000  Loss: 0.3568  Acc@1: 62.5000 (51.0381)  Acc@5: 100.0000 (92.4553)  time: 0.3437  data: 0.0002  max mem: 2502
Train: Epoch[1/5]  [2080/3750]  eta: 0:09:35  Lr: 0.030000  Loss: 0.4315  Acc@1: 62.5000 (51.0962)  Acc@5: 100.0000 (92.4826)  time: 0.3438  data: 0.0002  max mem: 2502
Train: Epoch[1/5]  [2090/3750]  eta: 0:09:32  Lr: 0.030000  Loss: 0.4198  Acc@1: 62.5000 (51.1388)  Acc@5: 100.0000 (92.5066)  time: 0.3440  data: 0.0002  max mem: 2502
Train: Epoch[1/5]  [2100/3750]  eta: 0:09:28  Lr: 0.030000  Loss: 0.2801  Acc@1: 62.5000 (51.2078)  Acc@5: 100.0000 (92.5363)  time: 0.3451  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [2110/3750]  eta: 0:09:25  Lr: 0.030000  Loss: 0.3193  Acc@1: 68.7500 (51.2642)  Acc@5: 100.0000 (92.5539)  time: 0.3458  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [2120/3750]  eta: 0:09:22  Lr: 0.030000  Loss: 0.3011  Acc@1: 56.2500 (51.2966)  Acc@5: 93.7500 (92.5684)  time: 0.3461  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [2130/3750]  eta: 0:09:18  Lr: 0.030000  Loss: 0.4539  Acc@1: 56.2500 (51.3139)  Acc@5: 93.7500 (92.5856)  time: 0.3459  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [2140/3750]  eta: 0:09:15  Lr: 0.030000  Loss: 0.5032  Acc@1: 56.2500 (51.3662)  Acc@5: 93.7500 (92.5998)  time: 0.3459  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [2150/3750]  eta: 0:09:11  Lr: 0.030000  Loss: 0.1335  Acc@1: 68.7500 (51.4557)  Acc@5: 93.7500 (92.6168)  time: 0.3462  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [2160/3750]  eta: 0:09:08  Lr: 0.030000  Loss: 0.2768  Acc@1: 62.5000 (51.4692)  Acc@5: 100.0000 (92.6394)  time: 0.3462  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [2170/3750]  eta: 0:09:04  Lr: 0.030000  Loss: 0.2196  Acc@1: 62.5000 (51.5229)  Acc@5: 100.0000 (92.6589)  time: 0.3459  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [2180/3750]  eta: 0:09:01  Lr: 0.030000  Loss: 0.3248  Acc@1: 62.5000 (51.5847)  Acc@5: 100.0000 (92.6754)  time: 0.3454  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [2190/3750]  eta: 0:08:57  Lr: 0.030000  Loss: 0.2527  Acc@1: 68.7500 (51.6830)  Acc@5: 100.0000 (92.6974)  time: 0.3460  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [2200/3750]  eta: 0:08:54  Lr: 0.030000  Loss: 0.0599  Acc@1: 68.7500 (51.7577)  Acc@5: 100.0000 (92.7164)  time: 0.3459  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [2210/3750]  eta: 0:08:51  Lr: 0.030000  Loss: 0.4499  Acc@1: 62.5000 (51.8063)  Acc@5: 100.0000 (92.7352)  time: 0.3525  data: 0.0007  max mem: 2502
Train: Epoch[1/5]  [2220/3750]  eta: 0:08:47  Lr: 0.030000  Loss: 0.2790  Acc@1: 62.5000 (51.8713)  Acc@5: 100.0000 (92.7595)  time: 0.3522  data: 0.0007  max mem: 2502
Train: Epoch[1/5]  [2230/3750]  eta: 0:08:44  Lr: 0.030000  Loss: 0.2666  Acc@1: 62.5000 (51.9246)  Acc@5: 100.0000 (92.7723)  time: 0.3448  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [2240/3750]  eta: 0:08:40  Lr: 0.030000  Loss: 0.2021  Acc@1: 68.7500 (51.9829)  Acc@5: 93.7500 (92.7850)  time: 0.3450  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [2250/3750]  eta: 0:08:37  Lr: 0.030000  Loss: 0.3957  Acc@1: 62.5000 (52.0158)  Acc@5: 100.0000 (92.8060)  time: 0.3454  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [2260/3750]  eta: 0:08:33  Lr: 0.030000  Loss: 0.4729  Acc@1: 62.5000 (52.0483)  Acc@5: 100.0000 (92.8323)  time: 0.3455  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [2270/3750]  eta: 0:08:30  Lr: 0.030000  Loss: 0.2882  Acc@1: 62.5000 (52.1219)  Acc@5: 100.0000 (92.8528)  time: 0.3455  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [2280/3750]  eta: 0:08:27  Lr: 0.030000  Loss: 0.4840  Acc@1: 68.7500 (52.1756)  Acc@5: 93.7500 (92.8622)  time: 0.3461  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [2290/3750]  eta: 0:08:23  Lr: 0.030000  Loss: 0.1571  Acc@1: 62.5000 (52.2316)  Acc@5: 93.7500 (92.8825)  time: 0.3458  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [2300/3750]  eta: 0:08:20  Lr: 0.030000  Loss: 0.2435  Acc@1: 68.7500 (52.3115)  Acc@5: 100.0000 (92.8998)  time: 0.3440  data: 0.0002  max mem: 2502
Train: Epoch[1/5]  [2310/3750]  eta: 0:08:16  Lr: 0.030000  Loss: 0.4544  Acc@1: 68.7500 (52.3772)  Acc@5: 100.0000 (92.9116)  time: 0.3430  data: 0.0002  max mem: 2502
Train: Epoch[1/5]  [2320/3750]  eta: 0:08:13  Lr: 0.030000  Loss: 0.2632  Acc@1: 62.5000 (52.4424)  Acc@5: 100.0000 (92.9233)  time: 0.3427  data: 0.0002  max mem: 2502
Train: Epoch[1/5]  [2330/3750]  eta: 0:08:09  Lr: 0.030000  Loss: 0.3776  Acc@1: 62.5000 (52.4802)  Acc@5: 100.0000 (92.9403)  time: 0.3428  data: 0.0002  max mem: 2502
Train: Epoch[1/5]  [2340/3750]  eta: 0:08:06  Lr: 0.030000  Loss: 0.2635  Acc@1: 62.5000 (52.5256)  Acc@5: 93.7500 (92.9491)  time: 0.3428  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [2350/3750]  eta: 0:08:02  Lr: 0.030000  Loss: 0.4129  Acc@1: 62.5000 (52.5760)  Acc@5: 93.7500 (92.9658)  time: 0.3428  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [2360/3750]  eta: 0:07:59  Lr: 0.030000  Loss: 0.3222  Acc@1: 62.5000 (52.6287)  Acc@5: 100.0000 (92.9903)  time: 0.3428  data: 0.0002  max mem: 2502
Train: Epoch[1/5]  [2370/3750]  eta: 0:07:55  Lr: 0.030000  Loss: 0.4020  Acc@1: 62.5000 (52.6703)  Acc@5: 100.0000 (93.0014)  time: 0.3429  data: 0.0002  max mem: 2502
Train: Epoch[1/5]  [2380/3750]  eta: 0:07:52  Lr: 0.030000  Loss: 0.2675  Acc@1: 68.7500 (52.7404)  Acc@5: 100.0000 (93.0255)  time: 0.3449  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [2390/3750]  eta: 0:07:49  Lr: 0.030000  Loss: 0.3353  Acc@1: 68.7500 (52.8100)  Acc@5: 100.0000 (93.0416)  time: 0.3457  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [2400/3750]  eta: 0:07:45  Lr: 0.030000  Loss: 0.4364  Acc@1: 62.5000 (52.8348)  Acc@5: 100.0000 (93.0576)  time: 0.3448  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [2410/3750]  eta: 0:07:42  Lr: 0.030000  Loss: 0.2454  Acc@1: 62.5000 (52.8878)  Acc@5: 100.0000 (93.0734)  time: 0.3449  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [2420/3750]  eta: 0:07:38  Lr: 0.030000  Loss: 0.1710  Acc@1: 68.7500 (52.9637)  Acc@5: 100.0000 (93.0891)  time: 0.3448  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [2430/3750]  eta: 0:07:35  Lr: 0.030000  Loss: 0.2791  Acc@1: 68.7500 (53.0055)  Acc@5: 100.0000 (93.1047)  time: 0.3438  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [2440/3750]  eta: 0:07:31  Lr: 0.030000  Loss: 0.2352  Acc@1: 62.5000 (53.0597)  Acc@5: 100.0000 (93.1253)  time: 0.3440  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [2450/3750]  eta: 0:07:28  Lr: 0.030000  Loss: -0.0174  Acc@1: 68.7500 (53.1237)  Acc@5: 100.0000 (93.1431)  time: 0.3446  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [2460/3750]  eta: 0:07:24  Lr: 0.030000  Loss: 0.1634  Acc@1: 68.7500 (53.1567)  Acc@5: 93.7500 (93.1507)  time: 0.3444  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [2470/3750]  eta: 0:07:21  Lr: 0.030000  Loss: 0.3289  Acc@1: 56.2500 (53.1819)  Acc@5: 93.7500 (93.1632)  time: 0.3443  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [2480/3750]  eta: 0:07:17  Lr: 0.030000  Loss: 0.1785  Acc@1: 68.7500 (53.2497)  Acc@5: 100.0000 (93.1832)  time: 0.3445  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [2490/3750]  eta: 0:07:14  Lr: 0.030000  Loss: 0.2846  Acc@1: 68.7500 (53.2893)  Acc@5: 100.0000 (93.2080)  time: 0.3446  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [2500/3750]  eta: 0:07:11  Lr: 0.030000  Loss: 0.4486  Acc@1: 62.5000 (53.3162)  Acc@5: 100.0000 (93.2327)  time: 0.3440  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [2510/3750]  eta: 0:07:07  Lr: 0.030000  Loss: 0.2015  Acc@1: 62.5000 (53.3826)  Acc@5: 100.0000 (93.2447)  time: 0.3443  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [2520/3750]  eta: 0:07:04  Lr: 0.030000  Loss: 0.2687  Acc@1: 62.5000 (53.4287)  Acc@5: 100.0000 (93.2591)  time: 0.3446  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [2530/3750]  eta: 0:07:00  Lr: 0.030000  Loss: 0.3644  Acc@1: 62.5000 (53.4818)  Acc@5: 100.0000 (93.2783)  time: 0.3483  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [2540/3750]  eta: 0:06:57  Lr: 0.030000  Loss: 0.3456  Acc@1: 62.5000 (53.5395)  Acc@5: 100.0000 (93.2974)  time: 0.3481  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [2550/3750]  eta: 0:06:53  Lr: 0.030000  Loss: 0.3657  Acc@1: 62.5000 (53.5868)  Acc@5: 100.0000 (93.3114)  time: 0.3440  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [2560/3750]  eta: 0:06:50  Lr: 0.030000  Loss: 0.0833  Acc@1: 62.5000 (53.6143)  Acc@5: 100.0000 (93.3229)  time: 0.3441  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [2570/3750]  eta: 0:06:46  Lr: 0.030000  Loss: 0.2729  Acc@1: 62.5000 (53.6586)  Acc@5: 100.0000 (93.3367)  time: 0.3441  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [2580/3750]  eta: 0:06:43  Lr: 0.030000  Loss: 0.2136  Acc@1: 62.5000 (53.6904)  Acc@5: 100.0000 (93.3577)  time: 0.3442  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [2590/3750]  eta: 0:06:40  Lr: 0.030000  Loss: -0.0125  Acc@1: 62.5000 (53.7317)  Acc@5: 100.0000 (93.3737)  time: 0.3442  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [2600/3750]  eta: 0:06:36  Lr: 0.030000  Loss: 0.3114  Acc@1: 62.5000 (53.7846)  Acc@5: 100.0000 (93.3920)  time: 0.3450  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [2610/3750]  eta: 0:06:33  Lr: 0.030000  Loss: 0.4556  Acc@1: 62.5000 (53.8108)  Acc@5: 100.0000 (93.4005)  time: 0.3443  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [2620/3750]  eta: 0:06:29  Lr: 0.030000  Loss: 0.4981  Acc@1: 56.2500 (53.8344)  Acc@5: 100.0000 (93.4209)  time: 0.3426  data: 0.0002  max mem: 2502
Train: Epoch[1/5]  [2630/3750]  eta: 0:06:26  Lr: 0.030000  Loss: 0.3852  Acc@1: 62.5000 (53.8911)  Acc@5: 100.0000 (93.4269)  time: 0.3424  data: 0.0002  max mem: 2502
Train: Epoch[1/5]  [2640/3750]  eta: 0:06:22  Lr: 0.030000  Loss: 0.2206  Acc@1: 62.5000 (53.9308)  Acc@5: 93.7500 (93.4400)  time: 0.3424  data: 0.0002  max mem: 2502
Train: Epoch[1/5]  [2650/3750]  eta: 0:06:19  Lr: 0.030000  Loss: 0.2535  Acc@1: 68.7500 (53.9985)  Acc@5: 100.0000 (93.4529)  time: 0.3425  data: 0.0002  max mem: 2502
Train: Epoch[1/5]  [2660/3750]  eta: 0:06:15  Lr: 0.030000  Loss: 0.3348  Acc@1: 68.7500 (54.0023)  Acc@5: 100.0000 (93.4635)  time: 0.3425  data: 0.0002  max mem: 2502
Train: Epoch[1/5]  [2670/3750]  eta: 0:06:12  Lr: 0.030000  Loss: 0.1533  Acc@1: 56.2500 (54.0200)  Acc@5: 100.0000 (93.4762)  time: 0.3425  data: 0.0002  max mem: 2502
Train: Epoch[1/5]  [2680/3750]  eta: 0:06:08  Lr: 0.030000  Loss: 0.1089  Acc@1: 56.2500 (54.0493)  Acc@5: 100.0000 (93.4842)  time: 0.3436  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [2690/3750]  eta: 0:06:05  Lr: 0.030000  Loss: 0.1829  Acc@1: 56.2500 (54.0622)  Acc@5: 100.0000 (93.4992)  time: 0.3448  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [2700/3750]  eta: 0:06:02  Lr: 0.030000  Loss: 0.4014  Acc@1: 62.5000 (54.1050)  Acc@5: 100.0000 (93.5163)  time: 0.3454  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [2710/3750]  eta: 0:05:58  Lr: 0.030000  Loss: 0.3701  Acc@1: 62.5000 (54.1475)  Acc@5: 100.0000 (93.5287)  time: 0.3456  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [2720/3750]  eta: 0:05:55  Lr: 0.030000  Loss: 0.3006  Acc@1: 62.5000 (54.1782)  Acc@5: 93.7500 (93.5318)  time: 0.3448  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [2730/3750]  eta: 0:05:51  Lr: 0.030000  Loss: 0.4128  Acc@1: 56.2500 (54.2040)  Acc@5: 93.7500 (93.5395)  time: 0.3447  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [2740/3750]  eta: 0:05:48  Lr: 0.030000  Loss: 0.4495  Acc@1: 62.5000 (54.2503)  Acc@5: 100.0000 (93.5562)  time: 0.3446  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [2750/3750]  eta: 0:05:44  Lr: 0.030000  Loss: 0.2010  Acc@1: 68.7500 (54.2848)  Acc@5: 93.7500 (93.5592)  time: 0.3446  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [2760/3750]  eta: 0:05:41  Lr: 0.030000  Loss: 0.1906  Acc@1: 68.7500 (54.3372)  Acc@5: 93.7500 (93.5757)  time: 0.3444  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [2770/3750]  eta: 0:05:37  Lr: 0.030000  Loss: 0.1098  Acc@1: 68.7500 (54.3915)  Acc@5: 100.0000 (93.5876)  time: 0.3441  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [2780/3750]  eta: 0:05:34  Lr: 0.030000  Loss: 0.1791  Acc@1: 68.7500 (54.4116)  Acc@5: 100.0000 (93.6017)  time: 0.3453  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [2790/3750]  eta: 0:05:31  Lr: 0.030000  Loss: 0.6016  Acc@1: 62.5000 (54.4518)  Acc@5: 93.7500 (93.6112)  time: 0.3455  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [2800/3750]  eta: 0:05:27  Lr: 0.030000  Loss: 0.3245  Acc@1: 68.7500 (54.4984)  Acc@5: 100.0000 (93.6273)  time: 0.3446  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [2810/3750]  eta: 0:05:24  Lr: 0.030000  Loss: 0.3490  Acc@1: 68.7500 (54.5402)  Acc@5: 100.0000 (93.6433)  time: 0.3440  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [2820/3750]  eta: 0:05:20  Lr: 0.030000  Loss: 0.2925  Acc@1: 62.5000 (54.5928)  Acc@5: 100.0000 (93.6614)  time: 0.3442  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [2830/3750]  eta: 0:05:17  Lr: 0.030000  Loss: 0.0892  Acc@1: 62.5000 (54.6229)  Acc@5: 100.0000 (93.6771)  time: 0.3443  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [2840/3750]  eta: 0:05:13  Lr: 0.030000  Loss: 0.2474  Acc@1: 68.7500 (54.6661)  Acc@5: 100.0000 (93.6862)  time: 0.3444  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [2850/3750]  eta: 0:05:10  Lr: 0.030000  Loss: 0.0451  Acc@1: 62.5000 (54.6979)  Acc@5: 100.0000 (93.6952)  time: 0.3444  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [2860/3750]  eta: 0:05:06  Lr: 0.030000  Loss: 0.1175  Acc@1: 62.5000 (54.7317)  Acc@5: 100.0000 (93.7129)  time: 0.3439  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [2870/3750]  eta: 0:05:03  Lr: 0.030000  Loss: 0.1569  Acc@1: 68.7500 (54.7936)  Acc@5: 100.0000 (93.7261)  time: 0.3440  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [2880/3750]  eta: 0:04:59  Lr: 0.030000  Loss: 0.3064  Acc@1: 68.7500 (54.8160)  Acc@5: 100.0000 (93.7413)  time: 0.3443  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [2890/3750]  eta: 0:04:56  Lr: 0.030000  Loss: 0.1534  Acc@1: 62.5000 (54.8426)  Acc@5: 100.0000 (93.7565)  time: 0.3435  data: 0.0002  max mem: 2502
Train: Epoch[1/5]  [2900/3750]  eta: 0:04:53  Lr: 0.030000  Loss: 0.2050  Acc@1: 62.5000 (54.8690)  Acc@5: 100.0000 (93.7715)  time: 0.3427  data: 0.0002  max mem: 2502
Train: Epoch[1/5]  [2910/3750]  eta: 0:04:49  Lr: 0.030000  Loss: 0.0547  Acc@1: 62.5000 (54.9103)  Acc@5: 100.0000 (93.7715)  time: 0.3428  data: 0.0002  max mem: 2502
Train: Epoch[1/5]  [2920/3750]  eta: 0:04:46  Lr: 0.030000  Loss: 0.3143  Acc@1: 68.7500 (54.9662)  Acc@5: 93.7500 (93.7800)  time: 0.3427  data: 0.0002  max mem: 2502
Train: Epoch[1/5]  [2930/3750]  eta: 0:04:42  Lr: 0.030000  Loss: 0.1801  Acc@1: 56.2500 (54.9578)  Acc@5: 100.0000 (93.7926)  time: 0.3431  data: 0.0002  max mem: 2502
Train: Epoch[1/5]  [2940/3750]  eta: 0:04:39  Lr: 0.030000  Loss: 0.0669  Acc@1: 56.2500 (54.9983)  Acc@5: 100.0000 (93.8010)  time: 0.3437  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [2950/3750]  eta: 0:04:35  Lr: 0.030000  Loss: 0.2532  Acc@1: 62.5000 (55.0216)  Acc@5: 93.7500 (93.8051)  time: 0.3439  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [2960/3750]  eta: 0:04:32  Lr: 0.030000  Loss: 0.0221  Acc@1: 62.5000 (55.0426)  Acc@5: 100.0000 (93.8197)  time: 0.3441  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [2970/3750]  eta: 0:04:28  Lr: 0.030000  Loss: 0.6393  Acc@1: 56.2500 (55.0719)  Acc@5: 100.0000 (93.8236)  time: 0.3444  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [2980/3750]  eta: 0:04:25  Lr: 0.030000  Loss: 0.2587  Acc@1: 62.5000 (55.0927)  Acc@5: 100.0000 (93.8339)  time: 0.3442  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [2990/3750]  eta: 0:04:22  Lr: 0.030000  Loss: 0.3405  Acc@1: 62.5000 (55.1153)  Acc@5: 100.0000 (93.8399)  time: 0.3444  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [3000/3750]  eta: 0:04:18  Lr: 0.030000  Loss: 0.0903  Acc@1: 62.5000 (55.1670)  Acc@5: 100.0000 (93.8520)  time: 0.3445  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [3010/3750]  eta: 0:04:15  Lr: 0.030000  Loss: 0.1241  Acc@1: 68.7500 (55.2287)  Acc@5: 100.0000 (93.8662)  time: 0.3436  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [3020/3750]  eta: 0:04:11  Lr: 0.030000  Loss: 0.1922  Acc@1: 68.7500 (55.2714)  Acc@5: 100.0000 (93.8824)  time: 0.3435  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [3030/3750]  eta: 0:04:08  Lr: 0.030000  Loss: 0.2336  Acc@1: 68.7500 (55.3159)  Acc@5: 100.0000 (93.9026)  time: 0.3441  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [3040/3750]  eta: 0:04:04  Lr: 0.030000  Loss: 0.2137  Acc@1: 68.7500 (55.3436)  Acc@5: 100.0000 (93.9062)  time: 0.3447  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [3050/3750]  eta: 0:04:01  Lr: 0.030000  Loss: 0.4402  Acc@1: 62.5000 (55.3937)  Acc@5: 93.7500 (93.9139)  time: 0.3446  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [3060/3750]  eta: 0:03:57  Lr: 0.030000  Loss: 0.1430  Acc@1: 75.0000 (55.4394)  Acc@5: 100.0000 (93.9276)  time: 0.3444  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [3070/3750]  eta: 0:03:54  Lr: 0.030000  Loss: 0.1108  Acc@1: 68.7500 (55.4766)  Acc@5: 100.0000 (93.9332)  time: 0.3450  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [3080/3750]  eta: 0:03:50  Lr: 0.030000  Loss: 0.3618  Acc@1: 62.5000 (55.4933)  Acc@5: 100.0000 (93.9366)  time: 0.3449  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [3090/3750]  eta: 0:03:47  Lr: 0.030000  Loss: 0.3429  Acc@1: 62.5000 (55.5180)  Acc@5: 100.0000 (93.9482)  time: 0.3442  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [3100/3750]  eta: 0:03:44  Lr: 0.030000  Loss: 0.0655  Acc@1: 62.5000 (55.5486)  Acc@5: 100.0000 (93.9616)  time: 0.3443  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [3110/3750]  eta: 0:03:40  Lr: 0.030000  Loss: 0.1082  Acc@1: 62.5000 (55.5669)  Acc@5: 100.0000 (93.9710)  time: 0.3449  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [3120/3750]  eta: 0:03:37  Lr: 0.030000  Loss: 0.1289  Acc@1: 62.5000 (55.5912)  Acc@5: 100.0000 (93.9783)  time: 0.3443  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [3130/3750]  eta: 0:03:33  Lr: 0.030000  Loss: 0.1678  Acc@1: 62.5000 (55.6072)  Acc@5: 100.0000 (93.9915)  time: 0.3429  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [3140/3750]  eta: 0:03:30  Lr: 0.030000  Loss: 0.2905  Acc@1: 62.5000 (55.6371)  Acc@5: 100.0000 (94.0027)  time: 0.3429  data: 0.0002  max mem: 2502
Train: Epoch[1/5]  [3150/3750]  eta: 0:03:26  Lr: 0.030000  Loss: 0.3552  Acc@1: 68.7500 (55.6768)  Acc@5: 100.0000 (94.0118)  time: 0.3432  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [3160/3750]  eta: 0:03:23  Lr: 0.030000  Loss: 0.1334  Acc@1: 68.7500 (55.7181)  Acc@5: 100.0000 (94.0248)  time: 0.3434  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [3170/3750]  eta: 0:03:19  Lr: 0.030000  Loss: 0.1112  Acc@1: 68.7500 (55.7730)  Acc@5: 100.0000 (94.0358)  time: 0.3433  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [3180/3750]  eta: 0:03:16  Lr: 0.030000  Loss: 0.2358  Acc@1: 68.7500 (55.8236)  Acc@5: 100.0000 (94.0467)  time: 0.3432  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [3190/3750]  eta: 0:03:13  Lr: 0.030000  Loss: 0.4629  Acc@1: 68.7500 (55.8779)  Acc@5: 100.0000 (94.0555)  time: 0.3444  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [3200/3750]  eta: 0:03:09  Lr: 0.030000  Loss: 0.1882  Acc@1: 68.7500 (55.9161)  Acc@5: 100.0000 (94.0644)  time: 0.3463  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [3210/3750]  eta: 0:03:06  Lr: 0.030000  Loss: 0.2560  Acc@1: 68.7500 (55.9425)  Acc@5: 100.0000 (94.0692)  time: 0.3466  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [3220/3750]  eta: 0:03:02  Lr: 0.030000  Loss: 0.3640  Acc@1: 62.5000 (55.9589)  Acc@5: 93.7500 (94.0721)  time: 0.3453  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [3230/3750]  eta: 0:02:59  Lr: 0.030000  Loss: 0.0085  Acc@1: 68.7500 (56.0101)  Acc@5: 93.7500 (94.0808)  time: 0.3450  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [3240/3750]  eta: 0:02:55  Lr: 0.030000  Loss: 0.2722  Acc@1: 62.5000 (56.0282)  Acc@5: 100.0000 (94.0933)  time: 0.3456  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [3250/3750]  eta: 0:02:52  Lr: 0.030000  Loss: 0.2004  Acc@1: 62.5000 (56.0635)  Acc@5: 100.0000 (94.1018)  time: 0.3477  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [3260/3750]  eta: 0:02:48  Lr: 0.030000  Loss: 0.2870  Acc@1: 68.7500 (56.0948)  Acc@5: 93.7500 (94.1065)  time: 0.3469  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [3270/3750]  eta: 0:02:45  Lr: 0.030000  Loss: 0.3008  Acc@1: 62.5000 (56.1162)  Acc@5: 100.0000 (94.1188)  time: 0.3447  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [3280/3750]  eta: 0:02:42  Lr: 0.030000  Loss: 0.2091  Acc@1: 62.5000 (56.1338)  Acc@5: 100.0000 (94.1291)  time: 0.3459  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [3290/3750]  eta: 0:02:38  Lr: 0.030000  Loss: 0.3145  Acc@1: 62.5000 (56.1645)  Acc@5: 100.0000 (94.1412)  time: 0.3459  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [3300/3750]  eta: 0:02:35  Lr: 0.030000  Loss: 0.2722  Acc@1: 68.7500 (56.1970)  Acc@5: 100.0000 (94.1495)  time: 0.3457  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [3310/3750]  eta: 0:02:31  Lr: 0.030000  Loss: 0.2210  Acc@1: 68.7500 (56.2292)  Acc@5: 100.0000 (94.1596)  time: 0.3450  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [3320/3750]  eta: 0:02:28  Lr: 0.030000  Loss: 0.4185  Acc@1: 62.5000 (56.2481)  Acc@5: 100.0000 (94.1678)  time: 0.3443  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [3330/3750]  eta: 0:02:24  Lr: 0.030000  Loss: 0.2297  Acc@1: 62.5000 (56.2594)  Acc@5: 100.0000 (94.1797)  time: 0.3444  data: 0.0002  max mem: 2502
Train: Epoch[1/5]  [3340/3750]  eta: 0:02:21  Lr: 0.030000  Loss: 0.4511  Acc@1: 62.5000 (56.2949)  Acc@5: 100.0000 (94.1896)  time: 0.3444  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [3350/3750]  eta: 0:02:17  Lr: 0.030000  Loss: 0.1381  Acc@1: 68.7500 (56.3321)  Acc@5: 100.0000 (94.1976)  time: 0.3444  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [3360/3750]  eta: 0:02:14  Lr: 0.030000  Loss: 0.2144  Acc@1: 62.5000 (56.3430)  Acc@5: 93.7500 (94.2019)  time: 0.3442  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [3370/3750]  eta: 0:02:11  Lr: 0.030000  Loss: 0.0583  Acc@1: 62.5000 (56.3891)  Acc@5: 100.0000 (94.2154)  time: 0.3444  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [3380/3750]  eta: 0:02:07  Lr: 0.030000  Loss: 0.0302  Acc@1: 75.0000 (56.4386)  Acc@5: 100.0000 (94.2251)  time: 0.3437  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [3390/3750]  eta: 0:02:04  Lr: 0.030000  Loss: 0.1326  Acc@1: 68.7500 (56.4546)  Acc@5: 93.7500 (94.2255)  time: 0.3429  data: 0.0002  max mem: 2502
Train: Epoch[1/5]  [3400/3750]  eta: 0:02:00  Lr: 0.030000  Loss: 0.1886  Acc@1: 62.5000 (56.4815)  Acc@5: 100.0000 (94.2407)  time: 0.3428  data: 0.0002  max mem: 2502
Train: Epoch[1/5]  [3410/3750]  eta: 0:01:57  Lr: 0.030000  Loss: 0.1650  Acc@1: 68.7500 (56.5230)  Acc@5: 100.0000 (94.2466)  time: 0.3433  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [3420/3750]  eta: 0:01:53  Lr: 0.030000  Loss: 0.2449  Acc@1: 62.5000 (56.5368)  Acc@5: 100.0000 (94.2597)  time: 0.3448  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [3430/3750]  eta: 0:01:50  Lr: 0.030000  Loss: 0.2142  Acc@1: 56.2500 (56.5487)  Acc@5: 100.0000 (94.2692)  time: 0.3451  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [3440/3750]  eta: 0:01:46  Lr: 0.030000  Loss: 0.2103  Acc@1: 68.7500 (56.5860)  Acc@5: 100.0000 (94.2804)  time: 0.3457  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [3450/3750]  eta: 0:01:43  Lr: 0.030000  Loss: 0.2854  Acc@1: 62.5000 (56.6032)  Acc@5: 100.0000 (94.2825)  time: 0.3462  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [3460/3750]  eta: 0:01:39  Lr: 0.030000  Loss: 0.2709  Acc@1: 62.5000 (56.6057)  Acc@5: 93.7500 (94.2899)  time: 0.3458  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [3470/3750]  eta: 0:01:36  Lr: 0.030000  Loss: 0.4642  Acc@1: 56.2500 (56.6281)  Acc@5: 100.0000 (94.2992)  time: 0.3453  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [3480/3750]  eta: 0:01:33  Lr: 0.030000  Loss: 0.0757  Acc@1: 68.7500 (56.6648)  Acc@5: 100.0000 (94.3102)  time: 0.3442  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [3490/3750]  eta: 0:01:29  Lr: 0.030000  Loss: 0.2782  Acc@1: 68.7500 (56.6940)  Acc@5: 100.0000 (94.3211)  time: 0.3442  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [3500/3750]  eta: 0:01:26  Lr: 0.030000  Loss: 0.3082  Acc@1: 62.5000 (56.7017)  Acc@5: 93.7500 (94.3195)  time: 0.3444  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [3510/3750]  eta: 0:01:22  Lr: 0.030000  Loss: 0.2991  Acc@1: 56.2500 (56.7253)  Acc@5: 93.7500 (94.3268)  time: 0.3443  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [3520/3750]  eta: 0:01:19  Lr: 0.030000  Loss: 0.0605  Acc@1: 56.2500 (56.7435)  Acc@5: 93.7500 (94.3322)  time: 0.3454  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [3530/3750]  eta: 0:01:15  Lr: 0.030000  Loss: 0.0171  Acc@1: 62.5000 (56.7775)  Acc@5: 100.0000 (94.3430)  time: 0.3449  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [3540/3750]  eta: 0:01:12  Lr: 0.030000  Loss: 0.0430  Acc@1: 68.7500 (56.8060)  Acc@5: 100.0000 (94.3554)  time: 0.3430  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [3550/3750]  eta: 0:01:08  Lr: 0.030000  Loss: 0.2426  Acc@1: 68.7500 (56.8502)  Acc@5: 100.0000 (94.3625)  time: 0.3428  data: 0.0002  max mem: 2502
Train: Epoch[1/5]  [3560/3750]  eta: 0:01:05  Lr: 0.030000  Loss: 0.1386  Acc@1: 68.7500 (56.8889)  Acc@5: 100.0000 (94.3748)  time: 0.3428  data: 0.0002  max mem: 2502
Train: Epoch[1/5]  [3570/3750]  eta: 0:01:02  Lr: 0.030000  Loss: 0.4668  Acc@1: 62.5000 (56.9011)  Acc@5: 100.0000 (94.3783)  time: 0.3430  data: 0.0002  max mem: 2502
Train: Epoch[1/5]  [3580/3750]  eta: 0:00:58  Lr: 0.030000  Loss: 0.2867  Acc@1: 62.5000 (56.9237)  Acc@5: 100.0000 (94.3888)  time: 0.3435  data: 0.0002  max mem: 2502
Train: Epoch[1/5]  [3590/3750]  eta: 0:00:55  Lr: 0.030000  Loss: -0.0580  Acc@1: 68.7500 (56.9618)  Acc@5: 100.0000 (94.4009)  time: 0.3434  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [3600/3750]  eta: 0:00:51  Lr: 0.030000  Loss: 0.0555  Acc@1: 62.5000 (56.9824)  Acc@5: 100.0000 (94.4095)  time: 0.3432  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [3610/3750]  eta: 0:00:48  Lr: 0.030000  Loss: 0.0939  Acc@1: 68.7500 (57.0202)  Acc@5: 100.0000 (94.4198)  time: 0.3448  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [3620/3750]  eta: 0:00:44  Lr: 0.030000  Loss: 0.3184  Acc@1: 68.7500 (57.0388)  Acc@5: 100.0000 (94.4283)  time: 0.3471  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [3630/3750]  eta: 0:00:41  Lr: 0.030000  Loss: 0.2567  Acc@1: 62.5000 (57.0711)  Acc@5: 100.0000 (94.4420)  time: 0.3465  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [3640/3750]  eta: 0:00:37  Lr: 0.030000  Loss: 0.3681  Acc@1: 62.5000 (57.0928)  Acc@5: 100.0000 (94.4435)  time: 0.3455  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [3650/3750]  eta: 0:00:34  Lr: 0.030000  Loss: 0.3099  Acc@1: 62.5000 (57.1196)  Acc@5: 93.7500 (94.4519)  time: 0.3452  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [3660/3750]  eta: 0:00:31  Lr: 0.030000  Loss: 0.2740  Acc@1: 62.5000 (57.1275)  Acc@5: 100.0000 (94.4602)  time: 0.3454  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [3670/3750]  eta: 0:00:27  Lr: 0.030000  Loss: 0.2211  Acc@1: 62.5000 (57.1660)  Acc@5: 100.0000 (94.4702)  time: 0.3454  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [3680/3750]  eta: 0:00:24  Lr: 0.030000  Loss: 0.1778  Acc@1: 68.7500 (57.1940)  Acc@5: 100.0000 (94.4801)  time: 0.3457  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [3690/3750]  eta: 0:00:20  Lr: 0.030000  Loss: 0.2190  Acc@1: 68.7500 (57.2135)  Acc@5: 100.0000 (94.4832)  time: 0.3456  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [3700/3750]  eta: 0:00:17  Lr: 0.030000  Loss: 0.0847  Acc@1: 68.7500 (57.2413)  Acc@5: 100.0000 (94.4914)  time: 0.3442  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [3710/3750]  eta: 0:00:13  Lr: 0.030000  Loss: 0.4059  Acc@1: 68.7500 (57.2639)  Acc@5: 100.0000 (94.4995)  time: 0.3444  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [3720/3750]  eta: 0:00:10  Lr: 0.030000  Loss: 0.2263  Acc@1: 68.7500 (57.2998)  Acc@5: 100.0000 (94.5092)  time: 0.3452  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [3730/3750]  eta: 0:00:06  Lr: 0.030000  Loss: 0.1713  Acc@1: 75.0000 (57.3422)  Acc@5: 100.0000 (94.5155)  time: 0.3460  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [3740/3750]  eta: 0:00:03  Lr: 0.030000  Loss: 0.1716  Acc@1: 75.0000 (57.3760)  Acc@5: 100.0000 (94.5202)  time: 0.3467  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [3749/3750]  eta: 0:00:00  Lr: 0.030000  Loss: 0.4123  Acc@1: 68.7500 (57.3933)  Acc@5: 100.0000 (94.5283)  time: 0.3460  data: 0.0007  max mem: 2502
Train: Epoch[1/5] Total time: 0:21:33 (0.3449 s / it)
{0: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 1: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 2: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 3: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 4: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 5: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 6: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 7: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 8: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 9: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 10: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 11: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 12: {0: 0, 1: 0, 2: 0, 3: 91325, 4: 0}, 13: {0: 0, 1: 0, 2: 0, 3: 91325, 4: 0}, 14: {0: 0, 1: 0, 2: 0, 3: 91325, 4: 0}, 15: {0: 0, 1: 0, 2: 0, 3: 91325, 4: 0}, 16: {0: 0, 1: 0, 2: 0, 3: 0, 4: 60000}, 17: {0: 0, 1: 0, 2: 0, 3: 0, 4: 60000}, 18: {0: 0, 1: 0, 2: 0, 3: 0, 4: 60000}, 19: {0: 0, 1: 0, 2: 0, 3: 0, 4: 60000}}
Averaged stats: Lr: 0.030000  Loss: 0.4123  Acc@1: 68.7500 (57.3933)  Acc@5: 100.0000 (94.5283)
Train: Epoch[2/5]  [   0/3750]  eta: 0:39:02  Lr: 0.030000  Loss: 0.0990  Acc@1: 68.7500 (68.7500)  Acc@5: 100.0000 (100.0000)  time: 0.6246  data: 0.2756  max mem: 2502
Train: Epoch[2/5]  [  10/3750]  eta: 0:23:04  Lr: 0.030000  Loss: 0.1423  Acc@1: 62.5000 (65.9091)  Acc@5: 100.0000 (97.1591)  time: 0.3703  data: 0.0253  max mem: 2502
Train: Epoch[2/5]  [  20/3750]  eta: 0:22:16  Lr: 0.030000  Loss: 0.2016  Acc@1: 62.5000 (63.6905)  Acc@5: 93.7500 (97.0238)  time: 0.3451  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [  30/3750]  eta: 0:21:57  Lr: 0.030000  Loss: 0.0109  Acc@1: 62.5000 (65.5242)  Acc@5: 100.0000 (97.5806)  time: 0.3451  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [  40/3750]  eta: 0:21:45  Lr: 0.030000  Loss: 0.2777  Acc@1: 62.5000 (64.0244)  Acc@5: 100.0000 (97.2561)  time: 0.3449  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [  50/3750]  eta: 0:21:36  Lr: 0.030000  Loss: 0.3553  Acc@1: 62.5000 (63.9706)  Acc@5: 100.0000 (97.1814)  time: 0.3447  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [  60/3750]  eta: 0:21:30  Lr: 0.030000  Loss: 0.1519  Acc@1: 75.0000 (65.1639)  Acc@5: 100.0000 (97.1311)  time: 0.3455  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [  70/3750]  eta: 0:21:23  Lr: 0.030000  Loss: -0.0900  Acc@1: 75.0000 (65.4930)  Acc@5: 100.0000 (97.1831)  time: 0.3450  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [  80/3750]  eta: 0:21:17  Lr: 0.030000  Loss: 0.0687  Acc@1: 68.7500 (66.0494)  Acc@5: 100.0000 (97.2994)  time: 0.3434  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [  90/3750]  eta: 0:21:12  Lr: 0.030000  Loss: -0.0686  Acc@1: 68.7500 (66.3462)  Acc@5: 100.0000 (97.2527)  time: 0.3434  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [ 100/3750]  eta: 0:21:07  Lr: 0.030000  Loss: 0.0482  Acc@1: 68.7500 (66.4604)  Acc@5: 100.0000 (97.4010)  time: 0.3433  data: 0.0002  max mem: 2502
Train: Epoch[2/5]  [ 110/3750]  eta: 0:21:02  Lr: 0.030000  Loss: 0.2619  Acc@1: 68.7500 (66.7230)  Acc@5: 100.0000 (97.3536)  time: 0.3431  data: 0.0002  max mem: 2502
Train: Epoch[2/5]  [ 120/3750]  eta: 0:20:58  Lr: 0.030000  Loss: 0.0195  Acc@1: 68.7500 (67.2004)  Acc@5: 100.0000 (97.4174)  time: 0.3435  data: 0.0002  max mem: 2502
Train: Epoch[2/5]  [ 130/3750]  eta: 0:20:53  Lr: 0.030000  Loss: 0.1824  Acc@1: 68.7500 (67.2710)  Acc@5: 100.0000 (97.3760)  time: 0.3436  data: 0.0002  max mem: 2502
Train: Epoch[2/5]  [ 140/3750]  eta: 0:20:49  Lr: 0.030000  Loss: 0.2555  Acc@1: 68.7500 (67.3759)  Acc@5: 100.0000 (97.4734)  time: 0.3434  data: 0.0002  max mem: 2502
Train: Epoch[2/5]  [ 150/3750]  eta: 0:20:46  Lr: 0.030000  Loss: 0.2942  Acc@1: 62.5000 (67.3427)  Acc@5: 100.0000 (97.4752)  time: 0.3449  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [ 160/3750]  eta: 0:20:42  Lr: 0.030000  Loss: 0.1476  Acc@1: 68.7500 (67.6630)  Acc@5: 93.7500 (97.3602)  time: 0.3469  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [ 170/3750]  eta: 0:20:39  Lr: 0.030000  Loss: 0.3247  Acc@1: 62.5000 (67.6901)  Acc@5: 100.0000 (97.4050)  time: 0.3462  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [ 180/3750]  eta: 0:20:35  Lr: 0.030000  Loss: 0.1705  Acc@1: 62.5000 (67.4724)  Acc@5: 100.0000 (97.3757)  time: 0.3450  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [ 190/3750]  eta: 0:20:32  Lr: 0.030000  Loss: -0.0535  Acc@1: 62.5000 (67.4738)  Acc@5: 100.0000 (97.3822)  time: 0.3456  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [ 200/3750]  eta: 0:20:28  Lr: 0.030000  Loss: 0.0499  Acc@1: 62.5000 (67.2886)  Acc@5: 100.0000 (97.4192)  time: 0.3454  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [ 210/3750]  eta: 0:20:25  Lr: 0.030000  Loss: 0.1039  Acc@1: 68.7500 (67.3578)  Acc@5: 100.0000 (97.3045)  time: 0.3457  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [ 220/3750]  eta: 0:20:21  Lr: 0.030000  Loss: 0.1017  Acc@1: 68.7500 (67.3360)  Acc@5: 93.7500 (97.2568)  time: 0.3459  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [ 230/3750]  eta: 0:20:17  Lr: 0.030000  Loss: 0.1368  Acc@1: 68.7500 (67.2890)  Acc@5: 100.0000 (97.2673)  time: 0.3453  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [ 240/3750]  eta: 0:20:14  Lr: 0.030000  Loss: -0.0152  Acc@1: 68.7500 (67.6608)  Acc@5: 100.0000 (97.2510)  time: 0.3455  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [ 250/3750]  eta: 0:20:10  Lr: 0.030000  Loss: -0.0629  Acc@1: 81.2500 (67.9034)  Acc@5: 93.7500 (97.2361)  time: 0.3455  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [ 260/3750]  eta: 0:20:07  Lr: 0.030000  Loss: 0.2352  Acc@1: 68.7500 (67.6724)  Acc@5: 100.0000 (97.3180)  time: 0.3458  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [ 270/3750]  eta: 0:20:03  Lr: 0.030000  Loss: 0.2620  Acc@1: 62.5000 (67.6199)  Acc@5: 100.0000 (97.3017)  time: 0.3454  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [ 280/3750]  eta: 0:20:00  Lr: 0.030000  Loss: 0.4499  Acc@1: 62.5000 (67.5489)  Acc@5: 100.0000 (97.3532)  time: 0.3444  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [ 290/3750]  eta: 0:19:56  Lr: 0.030000  Loss: 0.3409  Acc@1: 62.5000 (67.5473)  Acc@5: 100.0000 (97.3368)  time: 0.3442  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [ 300/3750]  eta: 0:19:52  Lr: 0.030000  Loss: 0.2905  Acc@1: 62.5000 (67.1512)  Acc@5: 100.0000 (97.2591)  time: 0.3448  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [ 310/3750]  eta: 0:19:49  Lr: 0.030000  Loss: 0.3621  Acc@1: 62.5000 (67.1624)  Acc@5: 93.7500 (97.1664)  time: 0.3450  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [ 320/3750]  eta: 0:19:45  Lr: 0.030000  Loss: 0.0139  Acc@1: 68.7500 (67.1729)  Acc@5: 100.0000 (97.2157)  time: 0.3442  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [ 330/3750]  eta: 0:19:42  Lr: 0.030000  Loss: 0.2187  Acc@1: 68.7500 (67.1828)  Acc@5: 100.0000 (97.2243)  time: 0.3439  data: 0.0002  max mem: 2502
Train: Epoch[2/5]  [ 340/3750]  eta: 0:19:38  Lr: 0.030000  Loss: -0.1400  Acc@1: 68.7500 (67.2471)  Acc@5: 100.0000 (97.2507)  time: 0.3433  data: 0.0002  max mem: 2502
Train: Epoch[2/5]  [ 350/3750]  eta: 0:19:34  Lr: 0.030000  Loss: 0.3923  Acc@1: 68.7500 (67.3077)  Acc@5: 100.0000 (97.2400)  time: 0.3426  data: 0.0002  max mem: 2502
Train: Epoch[2/5]  [ 360/3750]  eta: 0:19:30  Lr: 0.030000  Loss: 0.2564  Acc@1: 68.7500 (67.4515)  Acc@5: 100.0000 (97.2645)  time: 0.3425  data: 0.0002  max mem: 2502
Train: Epoch[2/5]  [ 370/3750]  eta: 0:19:27  Lr: 0.030000  Loss: 0.1968  Acc@1: 68.7500 (67.4865)  Acc@5: 100.0000 (97.2877)  time: 0.3434  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [ 380/3750]  eta: 0:19:23  Lr: 0.030000  Loss: 0.2920  Acc@1: 68.7500 (67.4869)  Acc@5: 100.0000 (97.2933)  time: 0.3454  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [ 390/3750]  eta: 0:19:20  Lr: 0.030000  Loss: 0.0308  Acc@1: 68.7500 (67.5352)  Acc@5: 100.0000 (97.2986)  time: 0.3455  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [ 400/3750]  eta: 0:19:16  Lr: 0.030000  Loss: -0.0122  Acc@1: 68.7500 (67.7369)  Acc@5: 100.0000 (97.3348)  time: 0.3449  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [ 410/3750]  eta: 0:19:13  Lr: 0.030000  Loss: 0.1088  Acc@1: 68.7500 (67.7159)  Acc@5: 100.0000 (97.3236)  time: 0.3446  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [ 420/3750]  eta: 0:19:09  Lr: 0.030000  Loss: 0.0707  Acc@1: 68.7500 (67.6663)  Acc@5: 100.0000 (97.3278)  time: 0.3441  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [ 430/3750]  eta: 0:19:06  Lr: 0.030000  Loss: 0.1661  Acc@1: 68.7500 (67.6914)  Acc@5: 100.0000 (97.2593)  time: 0.3440  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [ 440/3750]  eta: 0:19:02  Lr: 0.030000  Loss: 0.3009  Acc@1: 68.7500 (67.6871)  Acc@5: 100.0000 (97.2647)  time: 0.3436  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [ 450/3750]  eta: 0:18:59  Lr: 0.030000  Loss: 0.2481  Acc@1: 68.7500 (67.6414)  Acc@5: 100.0000 (97.2838)  time: 0.3440  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [ 460/3750]  eta: 0:18:55  Lr: 0.030000  Loss: -0.0720  Acc@1: 68.7500 (67.8010)  Acc@5: 100.0000 (97.2749)  time: 0.3443  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [ 470/3750]  eta: 0:18:52  Lr: 0.030000  Loss: 0.0201  Acc@1: 75.0000 (67.8211)  Acc@5: 100.0000 (97.2930)  time: 0.3443  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [ 480/3750]  eta: 0:18:48  Lr: 0.030000  Loss: 0.3101  Acc@1: 62.5000 (67.7755)  Acc@5: 100.0000 (97.2843)  time: 0.3450  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [ 490/3750]  eta: 0:18:45  Lr: 0.030000  Loss: 0.1870  Acc@1: 62.5000 (67.6298)  Acc@5: 100.0000 (97.3014)  time: 0.3438  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [ 500/3750]  eta: 0:18:41  Lr: 0.030000  Loss: 0.2733  Acc@1: 62.5000 (67.7146)  Acc@5: 100.0000 (97.2555)  time: 0.3424  data: 0.0002  max mem: 2502
Train: Epoch[2/5]  [ 510/3750]  eta: 0:18:37  Lr: 0.030000  Loss: 0.2391  Acc@1: 68.7500 (67.7838)  Acc@5: 93.7500 (97.2480)  time: 0.3426  data: 0.0002  max mem: 2502
Train: Epoch[2/5]  [ 520/3750]  eta: 0:18:34  Lr: 0.030000  Loss: 0.1648  Acc@1: 68.7500 (67.7663)  Acc@5: 100.0000 (97.3009)  time: 0.3426  data: 0.0002  max mem: 2502
Train: Epoch[2/5]  [ 530/3750]  eta: 0:18:30  Lr: 0.030000  Loss: -0.0876  Acc@1: 62.5000 (67.6907)  Acc@5: 100.0000 (97.3046)  time: 0.3425  data: 0.0002  max mem: 2502
Train: Epoch[2/5]  [ 540/3750]  eta: 0:18:27  Lr: 0.030000  Loss: 0.4219  Acc@1: 62.5000 (67.6872)  Acc@5: 100.0000 (97.3313)  time: 0.3422  data: 0.0002  max mem: 2502
Train: Epoch[2/5]  [ 550/3750]  eta: 0:18:23  Lr: 0.030000  Loss: 0.3328  Acc@1: 62.5000 (67.6611)  Acc@5: 100.0000 (97.3004)  time: 0.3430  data: 0.0002  max mem: 2502
Train: Epoch[2/5]  [ 560/3750]  eta: 0:18:20  Lr: 0.030000  Loss: 0.0265  Acc@1: 68.7500 (67.6471)  Acc@5: 100.0000 (97.2928)  time: 0.3449  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [ 570/3750]  eta: 0:18:16  Lr: 0.030000  Loss: 0.0808  Acc@1: 68.7500 (67.5898)  Acc@5: 100.0000 (97.2964)  time: 0.3457  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [ 580/3750]  eta: 0:18:13  Lr: 0.030000  Loss: 0.2185  Acc@1: 56.2500 (67.5129)  Acc@5: 100.0000 (97.2569)  time: 0.3455  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [ 590/3750]  eta: 0:18:09  Lr: 0.030000  Loss: 0.2790  Acc@1: 62.5000 (67.5127)  Acc@5: 100.0000 (97.2610)  time: 0.3453  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [ 600/3750]  eta: 0:18:06  Lr: 0.030000  Loss: 0.1743  Acc@1: 68.7500 (67.4813)  Acc@5: 100.0000 (97.2650)  time: 0.3452  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [ 610/3750]  eta: 0:18:02  Lr: 0.030000  Loss: 0.1348  Acc@1: 62.5000 (67.4304)  Acc@5: 100.0000 (97.2893)  time: 0.3448  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [ 620/3750]  eta: 0:17:59  Lr: 0.030000  Loss: 0.2212  Acc@1: 62.5000 (67.3410)  Acc@5: 100.0000 (97.2725)  time: 0.3452  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [ 630/3750]  eta: 0:17:56  Lr: 0.030000  Loss: 0.2608  Acc@1: 68.7500 (67.3138)  Acc@5: 100.0000 (97.2761)  time: 0.3454  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [ 640/3750]  eta: 0:17:52  Lr: 0.030000  Loss: 0.1720  Acc@1: 68.7500 (67.3362)  Acc@5: 100.0000 (97.2601)  time: 0.3446  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [ 650/3750]  eta: 0:17:49  Lr: 0.030000  Loss: 0.3156  Acc@1: 68.7500 (67.3195)  Acc@5: 100.0000 (97.2542)  time: 0.3459  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [ 660/3750]  eta: 0:17:45  Lr: 0.030000  Loss: 0.1492  Acc@1: 68.7500 (67.4168)  Acc@5: 100.0000 (97.2674)  time: 0.3460  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [ 670/3750]  eta: 0:17:42  Lr: 0.030000  Loss: 0.0318  Acc@1: 68.7500 (67.3621)  Acc@5: 100.0000 (97.2057)  time: 0.3453  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [ 680/3750]  eta: 0:17:39  Lr: 0.030000  Loss: 0.0613  Acc@1: 68.7500 (67.4101)  Acc@5: 100.0000 (97.2100)  time: 0.3456  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [ 690/3750]  eta: 0:17:35  Lr: 0.030000  Loss: 0.2535  Acc@1: 75.0000 (67.3933)  Acc@5: 100.0000 (97.1961)  time: 0.3454  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [ 700/3750]  eta: 0:17:32  Lr: 0.030000  Loss: 0.0945  Acc@1: 68.7500 (67.4126)  Acc@5: 100.0000 (97.2183)  time: 0.3455  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [ 710/3750]  eta: 0:17:28  Lr: 0.030000  Loss: 0.3064  Acc@1: 68.7500 (67.3875)  Acc@5: 100.0000 (97.2310)  time: 0.3457  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [ 720/3750]  eta: 0:17:25  Lr: 0.030000  Loss: 0.4102  Acc@1: 62.5000 (67.3024)  Acc@5: 100.0000 (97.2001)  time: 0.3450  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [ 730/3750]  eta: 0:17:21  Lr: 0.030000  Loss: 0.1378  Acc@1: 62.5000 (67.2367)  Acc@5: 93.7500 (97.1700)  time: 0.3447  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [ 740/3750]  eta: 0:17:18  Lr: 0.030000  Loss: 0.0705  Acc@1: 62.5000 (67.2233)  Acc@5: 93.7500 (97.1576)  time: 0.3451  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [ 750/3750]  eta: 0:17:14  Lr: 0.030000  Loss: 0.3679  Acc@1: 68.7500 (67.2270)  Acc@5: 93.7500 (97.1538)  time: 0.3442  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [ 760/3750]  eta: 0:17:11  Lr: 0.030000  Loss: 0.1027  Acc@1: 62.5000 (67.1731)  Acc@5: 100.0000 (97.1583)  time: 0.3433  data: 0.0002  max mem: 2502
Train: Epoch[2/5]  [ 770/3750]  eta: 0:17:07  Lr: 0.030000  Loss: -0.0168  Acc@1: 62.5000 (67.2017)  Acc@5: 100.0000 (97.1952)  time: 0.3439  data: 0.0002  max mem: 2502
Train: Epoch[2/5]  [ 780/3750]  eta: 0:17:04  Lr: 0.030000  Loss: 0.1944  Acc@1: 68.7500 (67.1735)  Acc@5: 100.0000 (97.1911)  time: 0.3446  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [ 790/3750]  eta: 0:17:00  Lr: 0.030000  Loss: 0.2889  Acc@1: 68.7500 (67.1618)  Acc@5: 100.0000 (97.2029)  time: 0.3453  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [ 800/3750]  eta: 0:16:57  Lr: 0.030000  Loss: 0.0644  Acc@1: 68.7500 (67.1973)  Acc@5: 100.0000 (97.1988)  time: 0.3452  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [ 810/3750]  eta: 0:16:54  Lr: 0.030000  Loss: 0.4206  Acc@1: 68.7500 (67.1239)  Acc@5: 100.0000 (97.2025)  time: 0.3456  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [ 820/3750]  eta: 0:16:50  Lr: 0.030000  Loss: 0.3027  Acc@1: 68.7500 (67.1590)  Acc@5: 100.0000 (97.1909)  time: 0.3462  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [ 830/3750]  eta: 0:16:47  Lr: 0.030000  Loss: 0.0832  Acc@1: 75.0000 (67.1931)  Acc@5: 100.0000 (97.2247)  time: 0.3453  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [ 840/3750]  eta: 0:16:43  Lr: 0.030000  Loss: 0.0957  Acc@1: 68.7500 (67.2339)  Acc@5: 100.0000 (97.2429)  time: 0.3449  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [ 850/3750]  eta: 0:16:40  Lr: 0.030000  Loss: 0.1360  Acc@1: 68.7500 (67.1710)  Acc@5: 100.0000 (97.2532)  time: 0.3451  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [ 860/3750]  eta: 0:16:36  Lr: 0.030000  Loss: 0.2386  Acc@1: 62.5000 (67.1893)  Acc@5: 100.0000 (97.2561)  time: 0.3453  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [ 870/3750]  eta: 0:16:33  Lr: 0.030000  Loss: 0.1567  Acc@1: 68.7500 (67.2001)  Acc@5: 100.0000 (97.2661)  time: 0.3454  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [ 880/3750]  eta: 0:16:30  Lr: 0.030000  Loss: 0.0422  Acc@1: 68.7500 (67.2673)  Acc@5: 100.0000 (97.2616)  time: 0.3451  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [ 890/3750]  eta: 0:16:26  Lr: 0.030000  Loss: 0.2092  Acc@1: 68.7500 (67.2699)  Acc@5: 100.0000 (97.2643)  time: 0.3458  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [ 900/3750]  eta: 0:16:23  Lr: 0.030000  Loss: 0.1424  Acc@1: 62.5000 (67.2863)  Acc@5: 93.7500 (97.2461)  time: 0.3449  data: 0.0002  max mem: 2502
Train: Epoch[2/5]  [ 910/3750]  eta: 0:16:19  Lr: 0.030000  Loss: 0.1625  Acc@1: 68.7500 (67.3093)  Acc@5: 93.7500 (97.2558)  time: 0.3433  data: 0.0002  max mem: 2502
Train: Epoch[2/5]  [ 920/3750]  eta: 0:16:16  Lr: 0.030000  Loss: 0.2394  Acc@1: 68.7500 (67.2774)  Acc@5: 100.0000 (97.2652)  time: 0.3434  data: 0.0002  max mem: 2502
Train: Epoch[2/5]  [ 930/3750]  eta: 0:16:12  Lr: 0.030000  Loss: 0.1173  Acc@1: 62.5000 (67.3067)  Acc@5: 100.0000 (97.2610)  time: 0.3433  data: 0.0002  max mem: 2502
Train: Epoch[2/5]  [ 940/3750]  eta: 0:16:09  Lr: 0.030000  Loss: 0.4314  Acc@1: 68.7500 (67.3353)  Acc@5: 100.0000 (97.2569)  time: 0.3433  data: 0.0002  max mem: 2502
Train: Epoch[2/5]  [ 950/3750]  eta: 0:16:05  Lr: 0.030000  Loss: 0.1094  Acc@1: 68.7500 (67.3173)  Acc@5: 100.0000 (97.2529)  time: 0.3433  data: 0.0002  max mem: 2502
Train: Epoch[2/5]  [ 960/3750]  eta: 0:16:02  Lr: 0.030000  Loss: 0.3458  Acc@1: 68.7500 (67.3257)  Acc@5: 100.0000 (97.2620)  time: 0.3433  data: 0.0002  max mem: 2502
Train: Epoch[2/5]  [ 970/3750]  eta: 0:15:58  Lr: 0.030000  Loss: 0.0132  Acc@1: 68.7500 (67.3082)  Acc@5: 100.0000 (97.2580)  time: 0.3434  data: 0.0002  max mem: 2502
Train: Epoch[2/5]  [ 980/3750]  eta: 0:15:55  Lr: 0.030000  Loss: 0.1574  Acc@1: 68.7500 (67.2974)  Acc@5: 100.0000 (97.2541)  time: 0.3442  data: 0.0002  max mem: 2502
Train: Epoch[2/5]  [ 990/3750]  eta: 0:15:51  Lr: 0.030000  Loss: 0.1701  Acc@1: 68.7500 (67.3688)  Acc@5: 100.0000 (97.2692)  time: 0.3456  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [1000/3750]  eta: 0:15:48  Lr: 0.030000  Loss: 0.1004  Acc@1: 68.7500 (67.3202)  Acc@5: 100.0000 (97.2715)  time: 0.3461  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [1010/3750]  eta: 0:15:44  Lr: 0.030000  Loss: 0.1082  Acc@1: 62.5000 (67.2849)  Acc@5: 100.0000 (97.2552)  time: 0.3458  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [1020/3750]  eta: 0:15:41  Lr: 0.030000  Loss: 0.0357  Acc@1: 62.5000 (67.2870)  Acc@5: 100.0000 (97.2698)  time: 0.3459  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [1030/3750]  eta: 0:15:38  Lr: 0.030000  Loss: 0.2344  Acc@1: 68.7500 (67.3375)  Acc@5: 100.0000 (97.2721)  time: 0.3460  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [1040/3750]  eta: 0:15:34  Lr: 0.030000  Loss: -0.0228  Acc@1: 75.0000 (67.3631)  Acc@5: 100.0000 (97.2562)  time: 0.3457  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [1050/3750]  eta: 0:15:31  Lr: 0.030000  Loss: 0.2178  Acc@1: 68.7500 (67.3525)  Acc@5: 93.7500 (97.2407)  time: 0.3451  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [1060/3750]  eta: 0:15:27  Lr: 0.030000  Loss: 0.2764  Acc@1: 62.5000 (67.3127)  Acc@5: 93.7500 (97.2373)  time: 0.3451  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [1070/3750]  eta: 0:15:24  Lr: 0.030000  Loss: -0.0162  Acc@1: 68.7500 (67.3203)  Acc@5: 100.0000 (97.2397)  time: 0.3451  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [1080/3750]  eta: 0:15:20  Lr: 0.030000  Loss: 0.1968  Acc@1: 68.7500 (67.3740)  Acc@5: 100.0000 (97.2421)  time: 0.3459  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [1090/3750]  eta: 0:15:17  Lr: 0.030000  Loss: 0.1885  Acc@1: 68.7500 (67.3293)  Acc@5: 100.0000 (97.2445)  time: 0.3465  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [1100/3750]  eta: 0:15:14  Lr: 0.030000  Loss: 0.2230  Acc@1: 62.5000 (67.3422)  Acc@5: 100.0000 (97.2355)  time: 0.3456  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [1110/3750]  eta: 0:15:10  Lr: 0.030000  Loss: 0.1814  Acc@1: 62.5000 (67.2592)  Acc@5: 93.7500 (97.2153)  time: 0.3470  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [1120/3750]  eta: 0:15:07  Lr: 0.030000  Loss: -0.1719  Acc@1: 68.7500 (67.3004)  Acc@5: 100.0000 (97.2235)  time: 0.3471  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [1130/3750]  eta: 0:15:03  Lr: 0.030000  Loss: 0.2343  Acc@1: 68.7500 (67.3077)  Acc@5: 100.0000 (97.2314)  time: 0.3461  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [1140/3750]  eta: 0:15:00  Lr: 0.030000  Loss: 0.0576  Acc@1: 75.0000 (67.3477)  Acc@5: 100.0000 (97.2393)  time: 0.3455  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [1150/3750]  eta: 0:14:56  Lr: 0.030000  Loss: 0.2475  Acc@1: 75.0000 (67.3599)  Acc@5: 100.0000 (97.2524)  time: 0.3447  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [1160/3750]  eta: 0:14:53  Lr: 0.030000  Loss: 0.1397  Acc@1: 75.0000 (67.4419)  Acc@5: 100.0000 (97.2707)  time: 0.3471  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [1170/3750]  eta: 0:14:50  Lr: 0.030000  Loss: 0.2498  Acc@1: 68.7500 (67.4424)  Acc@5: 100.0000 (97.2726)  time: 0.3468  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [1180/3750]  eta: 0:14:46  Lr: 0.030000  Loss: -0.0091  Acc@1: 68.7500 (67.4376)  Acc@5: 100.0000 (97.2851)  time: 0.3444  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [1190/3750]  eta: 0:14:43  Lr: 0.030000  Loss: 0.1960  Acc@1: 68.7500 (67.4643)  Acc@5: 100.0000 (97.2974)  time: 0.3445  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [1200/3750]  eta: 0:14:39  Lr: 0.030000  Loss: -0.0133  Acc@1: 68.7500 (67.4750)  Acc@5: 100.0000 (97.3095)  time: 0.3455  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [1210/3750]  eta: 0:14:36  Lr: 0.030000  Loss: 0.1460  Acc@1: 68.7500 (67.4597)  Acc@5: 100.0000 (97.3008)  time: 0.3448  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [1220/3750]  eta: 0:14:32  Lr: 0.030000  Loss: 0.3488  Acc@1: 62.5000 (67.4140)  Acc@5: 93.7500 (97.2768)  time: 0.3431  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [1230/3750]  eta: 0:14:29  Lr: 0.030000  Loss: 0.1300  Acc@1: 62.5000 (67.4147)  Acc@5: 93.7500 (97.2736)  time: 0.3430  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [1240/3750]  eta: 0:14:25  Lr: 0.030000  Loss: 0.1362  Acc@1: 68.7500 (67.4053)  Acc@5: 100.0000 (97.2703)  time: 0.3426  data: 0.0002  max mem: 2502
Train: Epoch[2/5]  [1250/3750]  eta: 0:14:22  Lr: 0.030000  Loss: 0.0178  Acc@1: 68.7500 (67.3861)  Acc@5: 100.0000 (97.2722)  time: 0.3424  data: 0.0002  max mem: 2502
Train: Epoch[2/5]  [1260/3750]  eta: 0:14:18  Lr: 0.030000  Loss: -0.0963  Acc@1: 68.7500 (67.4663)  Acc@5: 100.0000 (97.2740)  time: 0.3424  data: 0.0002  max mem: 2502
Train: Epoch[2/5]  [1270/3750]  eta: 0:14:15  Lr: 0.030000  Loss: 0.1523  Acc@1: 75.0000 (67.4813)  Acc@5: 100.0000 (97.2708)  time: 0.3426  data: 0.0002  max mem: 2502
Train: Epoch[2/5]  [1280/3750]  eta: 0:14:11  Lr: 0.030000  Loss: 0.0471  Acc@1: 68.7500 (67.4961)  Acc@5: 100.0000 (97.2629)  time: 0.3426  data: 0.0002  max mem: 2502
Train: Epoch[2/5]  [1290/3750]  eta: 0:14:08  Lr: 0.030000  Loss: 0.0897  Acc@1: 62.5000 (67.4719)  Acc@5: 100.0000 (97.2599)  time: 0.3429  data: 0.0002  max mem: 2502
Train: Epoch[2/5]  [1300/3750]  eta: 0:14:04  Lr: 0.030000  Loss: -0.0245  Acc@1: 68.7500 (67.5346)  Acc@5: 100.0000 (97.2569)  time: 0.3445  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [1310/3750]  eta: 0:14:01  Lr: 0.030000  Loss: 0.0920  Acc@1: 68.7500 (67.5772)  Acc@5: 100.0000 (97.2540)  time: 0.3458  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [1320/3750]  eta: 0:13:58  Lr: 0.030000  Loss: -0.0188  Acc@1: 68.7500 (67.6192)  Acc@5: 100.0000 (97.2464)  time: 0.3458  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [1330/3750]  eta: 0:13:54  Lr: 0.030000  Loss: 0.3814  Acc@1: 68.7500 (67.6277)  Acc@5: 93.7500 (97.2295)  time: 0.3451  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [1340/3750]  eta: 0:13:51  Lr: 0.030000  Loss: 0.1422  Acc@1: 68.7500 (67.5988)  Acc@5: 93.7500 (97.2176)  time: 0.3451  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [1350/3750]  eta: 0:13:47  Lr: 0.030000  Loss: 0.1410  Acc@1: 68.7500 (67.6397)  Acc@5: 100.0000 (97.2243)  time: 0.3450  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [1360/3750]  eta: 0:13:44  Lr: 0.030000  Loss: 0.0675  Acc@1: 75.0000 (67.6662)  Acc@5: 100.0000 (97.2309)  time: 0.3449  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [1370/3750]  eta: 0:13:40  Lr: 0.030000  Loss: 0.0088  Acc@1: 68.7500 (67.6878)  Acc@5: 100.0000 (97.2329)  time: 0.3448  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [1380/3750]  eta: 0:13:37  Lr: 0.030000  Loss: 0.2282  Acc@1: 68.7500 (67.6955)  Acc@5: 100.0000 (97.2348)  time: 0.3445  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [1390/3750]  eta: 0:13:33  Lr: 0.030000  Loss: 0.3283  Acc@1: 68.7500 (67.7076)  Acc@5: 100.0000 (97.2412)  time: 0.3454  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [1400/3750]  eta: 0:13:30  Lr: 0.030000  Loss: 0.2623  Acc@1: 68.7500 (67.7329)  Acc@5: 100.0000 (97.2475)  time: 0.3465  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [1410/3750]  eta: 0:13:27  Lr: 0.030000  Loss: 0.1172  Acc@1: 68.7500 (67.7312)  Acc@5: 100.0000 (97.2449)  time: 0.3487  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [1420/3750]  eta: 0:13:23  Lr: 0.030000  Loss: 0.1170  Acc@1: 68.7500 (67.7604)  Acc@5: 100.0000 (97.2467)  time: 0.3470  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [1430/3750]  eta: 0:13:20  Lr: 0.030000  Loss: 0.3632  Acc@1: 68.7500 (67.7717)  Acc@5: 100.0000 (97.2528)  time: 0.3439  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [1440/3750]  eta: 0:13:16  Lr: 0.030000  Loss: 0.2012  Acc@1: 68.7500 (67.7524)  Acc@5: 100.0000 (97.2588)  time: 0.3443  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [1450/3750]  eta: 0:13:13  Lr: 0.030000  Loss: 0.3360  Acc@1: 62.5000 (67.6904)  Acc@5: 100.0000 (97.2304)  time: 0.3443  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [1460/3750]  eta: 0:13:09  Lr: 0.030000  Loss: 0.1098  Acc@1: 62.5000 (67.6934)  Acc@5: 93.7500 (97.2194)  time: 0.3442  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [1470/3750]  eta: 0:13:06  Lr: 0.030000  Loss: 0.2116  Acc@1: 62.5000 (67.6283)  Acc@5: 93.7500 (97.2170)  time: 0.3442  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [1480/3750]  eta: 0:13:02  Lr: 0.030000  Loss: 0.1854  Acc@1: 62.5000 (67.6106)  Acc@5: 100.0000 (97.2189)  time: 0.3447  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [1490/3750]  eta: 0:12:59  Lr: 0.030000  Loss: 0.2069  Acc@1: 62.5000 (67.5469)  Acc@5: 100.0000 (97.2250)  time: 0.3440  data: 0.0002  max mem: 2502
Train: Epoch[2/5]  [1500/3750]  eta: 0:12:55  Lr: 0.030000  Loss: 0.2415  Acc@1: 62.5000 (67.5425)  Acc@5: 100.0000 (97.2268)  time: 0.3426  data: 0.0002  max mem: 2502
Train: Epoch[2/5]  [1510/3750]  eta: 0:12:52  Lr: 0.030000  Loss: 0.0294  Acc@1: 68.7500 (67.5381)  Acc@5: 100.0000 (97.2328)  time: 0.3426  data: 0.0002  max mem: 2502
Train: Epoch[2/5]  [1520/3750]  eta: 0:12:49  Lr: 0.030000  Loss: 0.1256  Acc@1: 62.5000 (67.4762)  Acc@5: 100.0000 (97.2345)  time: 0.3427  data: 0.0002  max mem: 2502
Train: Epoch[2/5]  [1530/3750]  eta: 0:12:45  Lr: 0.030000  Loss: 0.1648  Acc@1: 56.2500 (67.4559)  Acc@5: 100.0000 (97.2322)  time: 0.3427  data: 0.0002  max mem: 2502
Train: Epoch[2/5]  [1540/3750]  eta: 0:12:42  Lr: 0.030000  Loss: 0.0259  Acc@1: 62.5000 (67.4481)  Acc@5: 100.0000 (97.2421)  time: 0.3433  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [1550/3750]  eta: 0:12:38  Lr: 0.030000  Loss: 0.0667  Acc@1: 62.5000 (67.4363)  Acc@5: 100.0000 (97.2477)  time: 0.3447  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [1560/3750]  eta: 0:12:35  Lr: 0.030000  Loss: 0.2837  Acc@1: 68.7500 (67.4407)  Acc@5: 100.0000 (97.2534)  time: 0.3453  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [1570/3750]  eta: 0:12:31  Lr: 0.030000  Loss: 0.0245  Acc@1: 68.7500 (67.4173)  Acc@5: 100.0000 (97.2510)  time: 0.3447  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [1580/3750]  eta: 0:12:28  Lr: 0.030000  Loss: 0.0248  Acc@1: 68.7500 (67.4178)  Acc@5: 100.0000 (97.2565)  time: 0.3450  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [1590/3750]  eta: 0:12:24  Lr: 0.030000  Loss: 0.1705  Acc@1: 68.7500 (67.4104)  Acc@5: 100.0000 (97.2541)  time: 0.3448  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [1600/3750]  eta: 0:12:21  Lr: 0.030000  Loss: 0.0233  Acc@1: 62.5000 (67.4071)  Acc@5: 100.0000 (97.2595)  time: 0.3446  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [1610/3750]  eta: 0:12:17  Lr: 0.030000  Loss: 0.3586  Acc@1: 56.2500 (67.3456)  Acc@5: 100.0000 (97.2455)  time: 0.3445  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [1620/3750]  eta: 0:12:14  Lr: 0.030000  Loss: 0.3318  Acc@1: 62.5000 (67.3388)  Acc@5: 100.0000 (97.2509)  time: 0.3446  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [1630/3750]  eta: 0:12:11  Lr: 0.030000  Loss: 0.3259  Acc@1: 68.7500 (67.3398)  Acc@5: 100.0000 (97.2563)  time: 0.3448  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [1640/3750]  eta: 0:12:07  Lr: 0.030000  Loss: 0.1673  Acc@1: 68.7500 (67.3713)  Acc@5: 100.0000 (97.2578)  time: 0.3443  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [1650/3750]  eta: 0:12:04  Lr: 0.030000  Loss: 0.1930  Acc@1: 68.7500 (67.3872)  Acc@5: 100.0000 (97.2592)  time: 0.3443  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [1660/3750]  eta: 0:12:00  Lr: 0.030000  Loss: 0.2123  Acc@1: 68.7500 (67.3879)  Acc@5: 100.0000 (97.2644)  time: 0.3443  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [1670/3750]  eta: 0:11:57  Lr: 0.030000  Loss: 0.0483  Acc@1: 68.7500 (67.4297)  Acc@5: 100.0000 (97.2659)  time: 0.3443  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [1680/3750]  eta: 0:11:53  Lr: 0.030000  Loss: 0.3205  Acc@1: 62.5000 (67.4115)  Acc@5: 100.0000 (97.2673)  time: 0.3443  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [1690/3750]  eta: 0:11:50  Lr: 0.030000  Loss: 0.2082  Acc@1: 62.5000 (67.4120)  Acc@5: 100.0000 (97.2649)  time: 0.3447  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [1700/3750]  eta: 0:11:46  Lr: 0.030000  Loss: 0.0108  Acc@1: 68.7500 (67.4199)  Acc@5: 100.0000 (97.2700)  time: 0.3438  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [1710/3750]  eta: 0:11:43  Lr: 0.030000  Loss: 0.1552  Acc@1: 68.7500 (67.4204)  Acc@5: 100.0000 (97.2640)  time: 0.3426  data: 0.0002  max mem: 2502
Train: Epoch[2/5]  [1720/3750]  eta: 0:11:39  Lr: 0.030000  Loss: 0.1474  Acc@1: 62.5000 (67.3845)  Acc@5: 100.0000 (97.2690)  time: 0.3427  data: 0.0002  max mem: 2502
Train: Epoch[2/5]  [1730/3750]  eta: 0:11:36  Lr: 0.030000  Loss: 0.3931  Acc@1: 62.5000 (67.3491)  Acc@5: 100.0000 (97.2740)  time: 0.3428  data: 0.0002  max mem: 2502
Train: Epoch[2/5]  [1740/3750]  eta: 0:11:32  Lr: 0.030000  Loss: 0.1550  Acc@1: 68.7500 (67.3715)  Acc@5: 100.0000 (97.2717)  time: 0.3428  data: 0.0002  max mem: 2502
Train: Epoch[2/5]  [1750/3750]  eta: 0:11:29  Lr: 0.030000  Loss: 0.2334  Acc@1: 68.7500 (67.3579)  Acc@5: 100.0000 (97.2730)  time: 0.3437  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [1760/3750]  eta: 0:11:26  Lr: 0.030000  Loss: 0.2569  Acc@1: 62.5000 (67.3410)  Acc@5: 100.0000 (97.2814)  time: 0.3448  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [1770/3750]  eta: 0:11:22  Lr: 0.030000  Loss: 0.0049  Acc@1: 68.7500 (67.3772)  Acc@5: 100.0000 (97.2932)  time: 0.3448  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [1780/3750]  eta: 0:11:19  Lr: 0.030000  Loss: 0.1703  Acc@1: 68.7500 (67.3954)  Acc@5: 100.0000 (97.2944)  time: 0.3439  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [1790/3750]  eta: 0:11:15  Lr: 0.030000  Loss: -0.0087  Acc@1: 68.7500 (67.4100)  Acc@5: 100.0000 (97.2850)  time: 0.3438  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [1800/3750]  eta: 0:11:12  Lr: 0.030000  Loss: 0.0541  Acc@1: 68.7500 (67.4035)  Acc@5: 100.0000 (97.2828)  time: 0.3440  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [1810/3750]  eta: 0:11:08  Lr: 0.030000  Loss: 0.0965  Acc@1: 68.7500 (67.4248)  Acc@5: 100.0000 (97.2909)  time: 0.3445  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [1820/3750]  eta: 0:11:05  Lr: 0.030000  Loss: 0.1850  Acc@1: 68.7500 (67.4149)  Acc@5: 100.0000 (97.2920)  time: 0.3450  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [1830/3750]  eta: 0:11:01  Lr: 0.030000  Loss: 0.3282  Acc@1: 62.5000 (67.3880)  Acc@5: 100.0000 (97.3000)  time: 0.3445  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [1840/3750]  eta: 0:10:58  Lr: 0.030000  Loss: 0.0828  Acc@1: 68.7500 (67.3853)  Acc@5: 100.0000 (97.3078)  time: 0.3443  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [1850/3750]  eta: 0:10:55  Lr: 0.030000  Loss: 0.1920  Acc@1: 68.7500 (67.4095)  Acc@5: 100.0000 (97.3156)  time: 0.3449  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [1860/3750]  eta: 0:10:51  Lr: 0.030000  Loss: 0.0575  Acc@1: 68.7500 (67.4268)  Acc@5: 100.0000 (97.3267)  time: 0.3447  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [1870/3750]  eta: 0:10:48  Lr: 0.030000  Loss: 0.2155  Acc@1: 68.7500 (67.4506)  Acc@5: 100.0000 (97.3310)  time: 0.3441  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [1880/3750]  eta: 0:10:44  Lr: 0.030000  Loss: 0.1845  Acc@1: 68.7500 (67.4608)  Acc@5: 100.0000 (97.3418)  time: 0.3440  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [1890/3750]  eta: 0:10:41  Lr: 0.030000  Loss: 0.0730  Acc@1: 68.7500 (67.4676)  Acc@5: 100.0000 (97.3394)  time: 0.3442  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [1900/3750]  eta: 0:10:37  Lr: 0.030000  Loss: 0.1584  Acc@1: 68.7500 (67.4842)  Acc@5: 100.0000 (97.3402)  time: 0.3433  data: 0.0002  max mem: 2502
Train: Epoch[2/5]  [1910/3750]  eta: 0:10:34  Lr: 0.030000  Loss: 0.2214  Acc@1: 62.5000 (67.4647)  Acc@5: 100.0000 (97.3443)  time: 0.3423  data: 0.0002  max mem: 2502
Train: Epoch[2/5]  [1920/3750]  eta: 0:10:30  Lr: 0.030000  Loss: 0.0684  Acc@1: 62.5000 (67.4779)  Acc@5: 100.0000 (97.3484)  time: 0.3424  data: 0.0002  max mem: 2502
Train: Epoch[2/5]  [1930/3750]  eta: 0:10:27  Lr: 0.030000  Loss: -0.0002  Acc@1: 62.5000 (67.4618)  Acc@5: 100.0000 (97.3556)  time: 0.3423  data: 0.0002  max mem: 2502
Train: Epoch[2/5]  [1940/3750]  eta: 0:10:23  Lr: 0.030000  Loss: 0.0222  Acc@1: 68.7500 (67.4910)  Acc@5: 100.0000 (97.3435)  time: 0.3422  data: 0.0002  max mem: 2502
Train: Epoch[2/5]  [1950/3750]  eta: 0:10:20  Lr: 0.030000  Loss: -0.1117  Acc@1: 68.7500 (67.4910)  Acc@5: 100.0000 (97.3411)  time: 0.3423  data: 0.0002  max mem: 2502
Train: Epoch[2/5]  [1960/3750]  eta: 0:10:16  Lr: 0.030000  Loss: 0.0352  Acc@1: 68.7500 (67.5198)  Acc@5: 100.0000 (97.3483)  time: 0.3424  data: 0.0002  max mem: 2502
Train: Epoch[2/5]  [1970/3750]  eta: 0:10:13  Lr: 0.030000  Loss: 0.0897  Acc@1: 75.0000 (67.5228)  Acc@5: 100.0000 (97.3427)  time: 0.3434  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [1980/3750]  eta: 0:10:10  Lr: 0.030000  Loss: 0.1313  Acc@1: 75.0000 (67.5574)  Acc@5: 100.0000 (97.3435)  time: 0.3443  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [1990/3750]  eta: 0:10:06  Lr: 0.030000  Loss: 0.2139  Acc@1: 68.7500 (67.5665)  Acc@5: 93.7500 (97.3317)  time: 0.3442  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [2000/3750]  eta: 0:10:03  Lr: 0.030000  Loss: 0.1739  Acc@1: 68.7500 (67.5631)  Acc@5: 100.0000 (97.3357)  time: 0.3442  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [2010/3750]  eta: 0:09:59  Lr: 0.030000  Loss: 0.3610  Acc@1: 62.5000 (67.5317)  Acc@5: 100.0000 (97.3272)  time: 0.3450  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [2020/3750]  eta: 0:09:56  Lr: 0.030000  Loss: 0.0851  Acc@1: 62.5000 (67.5346)  Acc@5: 93.7500 (97.3281)  time: 0.3458  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [2030/3750]  eta: 0:09:52  Lr: 0.030000  Loss: 0.2238  Acc@1: 68.7500 (67.5098)  Acc@5: 100.0000 (97.3166)  time: 0.3468  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [2040/3750]  eta: 0:09:49  Lr: 0.030000  Loss: 0.0738  Acc@1: 68.7500 (67.5190)  Acc@5: 100.0000 (97.3206)  time: 0.3460  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [2050/3750]  eta: 0:09:45  Lr: 0.030000  Loss: 0.4520  Acc@1: 62.5000 (67.4732)  Acc@5: 100.0000 (97.3092)  time: 0.3445  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [2060/3750]  eta: 0:09:42  Lr: 0.030000  Loss: 0.2224  Acc@1: 62.5000 (67.4642)  Acc@5: 93.7500 (97.2980)  time: 0.3443  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [2070/3750]  eta: 0:09:39  Lr: 0.030000  Loss: 0.1118  Acc@1: 68.7500 (67.4644)  Acc@5: 93.7500 (97.2990)  time: 0.3444  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [2080/3750]  eta: 0:09:35  Lr: 0.030000  Loss: 0.1506  Acc@1: 68.7500 (67.4556)  Acc@5: 100.0000 (97.2970)  time: 0.3456  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [2090/3750]  eta: 0:09:32  Lr: 0.030000  Loss: 0.0970  Acc@1: 68.7500 (67.4647)  Acc@5: 100.0000 (97.2920)  time: 0.3461  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [2100/3750]  eta: 0:09:28  Lr: 0.030000  Loss: 0.0523  Acc@1: 68.7500 (67.4619)  Acc@5: 100.0000 (97.2930)  time: 0.3453  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [2110/3750]  eta: 0:09:25  Lr: 0.030000  Loss: -0.0772  Acc@1: 68.7500 (67.5184)  Acc@5: 100.0000 (97.2939)  time: 0.3447  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [2120/3750]  eta: 0:09:21  Lr: 0.030000  Loss: 0.1333  Acc@1: 75.0000 (67.5035)  Acc@5: 100.0000 (97.3008)  time: 0.3454  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [2130/3750]  eta: 0:09:18  Lr: 0.030000  Loss: 0.0987  Acc@1: 68.7500 (67.5211)  Acc@5: 100.0000 (97.2988)  time: 0.3450  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [2140/3750]  eta: 0:09:14  Lr: 0.030000  Loss: 0.3444  Acc@1: 68.7500 (67.5123)  Acc@5: 100.0000 (97.2910)  time: 0.3442  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [2150/3750]  eta: 0:09:11  Lr: 0.030000  Loss: 0.1751  Acc@1: 62.5000 (67.5064)  Acc@5: 100.0000 (97.2949)  time: 0.3444  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [2160/3750]  eta: 0:09:08  Lr: 0.030000  Loss: 0.2503  Acc@1: 68.7500 (67.5237)  Acc@5: 100.0000 (97.2987)  time: 0.3440  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [2170/3750]  eta: 0:09:04  Lr: 0.030000  Loss: -0.0020  Acc@1: 68.7500 (67.5438)  Acc@5: 100.0000 (97.2939)  time: 0.3431  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [2180/3750]  eta: 0:09:01  Lr: 0.030000  Loss: 0.1786  Acc@1: 68.7500 (67.5321)  Acc@5: 100.0000 (97.2920)  time: 0.3425  data: 0.0002  max mem: 2502
Train: Epoch[2/5]  [2190/3750]  eta: 0:08:57  Lr: 0.030000  Loss: 0.0705  Acc@1: 62.5000 (67.5491)  Acc@5: 100.0000 (97.3015)  time: 0.3425  data: 0.0002  max mem: 2502
Train: Epoch[2/5]  [2200/3750]  eta: 0:08:54  Lr: 0.030000  Loss: 0.2710  Acc@1: 68.7500 (67.5346)  Acc@5: 100.0000 (97.3080)  time: 0.3423  data: 0.0002  max mem: 2502
Train: Epoch[2/5]  [2210/3750]  eta: 0:08:50  Lr: 0.030000  Loss: -0.0100  Acc@1: 68.7500 (67.5543)  Acc@5: 100.0000 (97.3146)  time: 0.3426  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [2220/3750]  eta: 0:08:47  Lr: 0.030000  Loss: -0.0907  Acc@1: 68.7500 (67.5597)  Acc@5: 100.0000 (97.3210)  time: 0.3448  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [2230/3750]  eta: 0:08:43  Lr: 0.030000  Loss: 0.0484  Acc@1: 68.7500 (67.5622)  Acc@5: 100.0000 (97.3190)  time: 0.3455  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [2240/3750]  eta: 0:08:40  Lr: 0.030000  Loss: 0.1607  Acc@1: 68.7500 (67.5396)  Acc@5: 100.0000 (97.3170)  time: 0.3450  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [2250/3750]  eta: 0:08:36  Lr: 0.030000  Loss: 0.1877  Acc@1: 62.5000 (67.5172)  Acc@5: 100.0000 (97.3206)  time: 0.3453  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [2260/3750]  eta: 0:08:33  Lr: 0.030000  Loss: 0.0463  Acc@1: 68.7500 (67.5310)  Acc@5: 100.0000 (97.3187)  time: 0.3446  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [2270/3750]  eta: 0:08:30  Lr: 0.030000  Loss: 0.0090  Acc@1: 75.0000 (67.5226)  Acc@5: 100.0000 (97.3140)  time: 0.3449  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [2280/3750]  eta: 0:08:26  Lr: 0.030000  Loss: 0.3007  Acc@1: 68.7500 (67.5197)  Acc@5: 100.0000 (97.3120)  time: 0.3449  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [2290/3750]  eta: 0:08:23  Lr: 0.030000  Loss: 0.1447  Acc@1: 68.7500 (67.5306)  Acc@5: 100.0000 (97.3210)  time: 0.3442  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [2300/3750]  eta: 0:08:19  Lr: 0.030000  Loss: 0.2666  Acc@1: 68.7500 (67.5304)  Acc@5: 100.0000 (97.3245)  time: 0.3443  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [2310/3750]  eta: 0:08:16  Lr: 0.030000  Loss: 0.0498  Acc@1: 68.7500 (67.5519)  Acc@5: 100.0000 (97.3253)  time: 0.3443  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [2320/3750]  eta: 0:08:12  Lr: 0.030000  Loss: 0.2139  Acc@1: 75.0000 (67.5759)  Acc@5: 100.0000 (97.3260)  time: 0.3442  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [2330/3750]  eta: 0:08:09  Lr: 0.030000  Loss: 0.1127  Acc@1: 68.7500 (67.5676)  Acc@5: 100.0000 (97.3214)  time: 0.3442  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [2340/3750]  eta: 0:08:05  Lr: 0.030000  Loss: 0.0395  Acc@1: 68.7500 (67.5753)  Acc@5: 100.0000 (97.3249)  time: 0.3443  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [2350/3750]  eta: 0:08:02  Lr: 0.030000  Loss: 0.3164  Acc@1: 62.5000 (67.5324)  Acc@5: 100.0000 (97.3256)  time: 0.3445  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [2360/3750]  eta: 0:07:59  Lr: 0.030000  Loss: 0.2433  Acc@1: 62.5000 (67.5085)  Acc@5: 100.0000 (97.3237)  time: 0.3448  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [2370/3750]  eta: 0:07:55  Lr: 0.030000  Loss: 0.2763  Acc@1: 68.7500 (67.5190)  Acc@5: 100.0000 (97.3165)  time: 0.3439  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [2380/3750]  eta: 0:07:52  Lr: 0.030000  Loss: 0.0582  Acc@1: 68.7500 (67.5241)  Acc@5: 100.0000 (97.3199)  time: 0.3425  data: 0.0002  max mem: 2502
Train: Epoch[2/5]  [2390/3750]  eta: 0:07:48  Lr: 0.030000  Loss: 0.0088  Acc@1: 68.7500 (67.5267)  Acc@5: 100.0000 (97.3259)  time: 0.3425  data: 0.0002  max mem: 2502
Train: Epoch[2/5]  [2400/3750]  eta: 0:07:45  Lr: 0.030000  Loss: 0.0893  Acc@1: 68.7500 (67.5292)  Acc@5: 100.0000 (97.3292)  time: 0.3425  data: 0.0002  max mem: 2502
Train: Epoch[2/5]  [2410/3750]  eta: 0:07:41  Lr: 0.030000  Loss: 0.1977  Acc@1: 75.0000 (67.5575)  Acc@5: 100.0000 (97.3222)  time: 0.3426  data: 0.0002  max mem: 2502
Train: Epoch[2/5]  [2420/3750]  eta: 0:07:38  Lr: 0.030000  Loss: 0.1300  Acc@1: 75.0000 (67.5676)  Acc@5: 100.0000 (97.3281)  time: 0.3427  data: 0.0002  max mem: 2502
Train: Epoch[2/5]  [2430/3750]  eta: 0:07:34  Lr: 0.030000  Loss: 0.1239  Acc@1: 68.7500 (67.5468)  Acc@5: 93.7500 (97.3056)  time: 0.3425  data: 0.0002  max mem: 2502
Train: Epoch[2/5]  [2440/3750]  eta: 0:07:31  Lr: 0.030000  Loss: -0.0181  Acc@1: 68.7500 (67.5645)  Acc@5: 93.7500 (97.3064)  time: 0.3423  data: 0.0002  max mem: 2502
Train: Epoch[2/5]  [2450/3750]  eta: 0:07:27  Lr: 0.030000  Loss: 0.1523  Acc@1: 68.7500 (67.5821)  Acc@5: 100.0000 (97.3047)  time: 0.3424  data: 0.0002  max mem: 2502
Train: Epoch[2/5]  [2460/3750]  eta: 0:07:24  Lr: 0.030000  Loss: -0.0021  Acc@1: 68.7500 (67.5767)  Acc@5: 100.0000 (97.3055)  time: 0.3432  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [2470/3750]  eta: 0:07:21  Lr: 0.030000  Loss: -0.0592  Acc@1: 68.7500 (67.5966)  Acc@5: 100.0000 (97.3063)  time: 0.3458  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [2480/3750]  eta: 0:07:17  Lr: 0.030000  Loss: -0.0023  Acc@1: 68.7500 (67.6063)  Acc@5: 100.0000 (97.3096)  time: 0.3465  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [2490/3750]  eta: 0:07:14  Lr: 0.030000  Loss: 0.2525  Acc@1: 68.7500 (67.5933)  Acc@5: 100.0000 (97.3053)  time: 0.3450  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [2500/3750]  eta: 0:07:10  Lr: 0.030000  Loss: 0.0216  Acc@1: 68.7500 (67.6055)  Acc@5: 100.0000 (97.3136)  time: 0.3451  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [2510/3750]  eta: 0:07:07  Lr: 0.030000  Loss: -0.0293  Acc@1: 68.7500 (67.5976)  Acc@5: 100.0000 (97.3143)  time: 0.3451  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [2520/3750]  eta: 0:07:03  Lr: 0.030000  Loss: 0.2256  Acc@1: 68.7500 (67.6021)  Acc@5: 100.0000 (97.3175)  time: 0.3453  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [2530/3750]  eta: 0:07:00  Lr: 0.030000  Loss: 0.4888  Acc@1: 68.7500 (67.6042)  Acc@5: 100.0000 (97.3183)  time: 0.3448  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [2540/3750]  eta: 0:06:56  Lr: 0.030000  Loss: -0.0178  Acc@1: 68.7500 (67.6259)  Acc@5: 100.0000 (97.3214)  time: 0.3445  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [2550/3750]  eta: 0:06:53  Lr: 0.030000  Loss: 0.1321  Acc@1: 75.0000 (67.6475)  Acc@5: 100.0000 (97.3295)  time: 0.3447  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [2560/3750]  eta: 0:06:50  Lr: 0.030000  Loss: 0.0312  Acc@1: 68.7500 (67.6396)  Acc@5: 100.0000 (97.3179)  time: 0.3450  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [2570/3750]  eta: 0:06:46  Lr: 0.030000  Loss: -0.0124  Acc@1: 68.7500 (67.6585)  Acc@5: 100.0000 (97.3187)  time: 0.3457  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [2580/3750]  eta: 0:06:43  Lr: 0.030000  Loss: 0.2992  Acc@1: 68.7500 (67.6579)  Acc@5: 100.0000 (97.3194)  time: 0.3453  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [2590/3750]  eta: 0:06:39  Lr: 0.030000  Loss: 0.0991  Acc@1: 62.5000 (67.6500)  Acc@5: 100.0000 (97.3225)  time: 0.3455  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [2600/3750]  eta: 0:06:36  Lr: 0.030000  Loss: 0.3370  Acc@1: 62.5000 (67.6399)  Acc@5: 100.0000 (97.3159)  time: 0.3450  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [2610/3750]  eta: 0:06:32  Lr: 0.030000  Loss: 0.1084  Acc@1: 62.5000 (67.6369)  Acc@5: 100.0000 (97.3071)  time: 0.3447  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [2620/3750]  eta: 0:06:29  Lr: 0.030000  Loss: 0.0078  Acc@1: 62.5000 (67.6436)  Acc@5: 100.0000 (97.3030)  time: 0.3446  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [2630/3750]  eta: 0:06:25  Lr: 0.030000  Loss: -0.0905  Acc@1: 68.7500 (67.6668)  Acc@5: 100.0000 (97.3062)  time: 0.3441  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [2640/3750]  eta: 0:06:22  Lr: 0.030000  Loss: 0.0386  Acc@1: 75.0000 (67.6661)  Acc@5: 100.0000 (97.3069)  time: 0.3445  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [2650/3750]  eta: 0:06:19  Lr: 0.030000  Loss: 0.2723  Acc@1: 62.5000 (67.6490)  Acc@5: 100.0000 (97.3076)  time: 0.3449  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [2660/3750]  eta: 0:06:15  Lr: 0.030000  Loss: 0.0690  Acc@1: 62.5000 (67.6672)  Acc@5: 100.0000 (97.3060)  time: 0.3446  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [2670/3750]  eta: 0:06:12  Lr: 0.030000  Loss: 0.1091  Acc@1: 68.7500 (67.6572)  Acc@5: 100.0000 (97.3020)  time: 0.3441  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [2680/3750]  eta: 0:06:08  Lr: 0.030000  Loss: 0.0950  Acc@1: 68.7500 (67.6683)  Acc@5: 100.0000 (97.3098)  time: 0.3446  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [2690/3750]  eta: 0:06:05  Lr: 0.030000  Loss: 0.1150  Acc@1: 62.5000 (67.6468)  Acc@5: 100.0000 (97.2989)  time: 0.3440  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [2700/3750]  eta: 0:06:01  Lr: 0.030000  Loss: 0.1884  Acc@1: 62.5000 (67.6462)  Acc@5: 93.7500 (97.2950)  time: 0.3428  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [2710/3750]  eta: 0:05:58  Lr: 0.030000  Loss: -0.0246  Acc@1: 68.7500 (67.6665)  Acc@5: 100.0000 (97.3004)  time: 0.3428  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [2720/3750]  eta: 0:05:54  Lr: 0.030000  Loss: -0.0644  Acc@1: 75.0000 (67.6865)  Acc@5: 100.0000 (97.3034)  time: 0.3428  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [2730/3750]  eta: 0:05:51  Lr: 0.030000  Loss: 0.0987  Acc@1: 68.7500 (67.6813)  Acc@5: 100.0000 (97.3041)  time: 0.3426  data: 0.0002  max mem: 2502
Train: Epoch[2/5]  [2740/3750]  eta: 0:05:47  Lr: 0.030000  Loss: -0.0083  Acc@1: 68.7500 (67.6715)  Acc@5: 100.0000 (97.3071)  time: 0.3439  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [2750/3750]  eta: 0:05:44  Lr: 0.030000  Loss: 0.2445  Acc@1: 68.7500 (67.6708)  Acc@5: 100.0000 (97.3055)  time: 0.3456  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [2760/3750]  eta: 0:05:41  Lr: 0.030000  Loss: 0.2451  Acc@1: 68.7500 (67.6929)  Acc@5: 100.0000 (97.3040)  time: 0.3452  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [2770/3750]  eta: 0:05:37  Lr: 0.030000  Loss: 0.1364  Acc@1: 68.7500 (67.6877)  Acc@5: 100.0000 (97.2979)  time: 0.3447  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [2780/3750]  eta: 0:05:34  Lr: 0.030000  Loss: 0.2952  Acc@1: 62.5000 (67.6825)  Acc@5: 100.0000 (97.2941)  time: 0.3447  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [2790/3750]  eta: 0:05:30  Lr: 0.030000  Loss: -0.1978  Acc@1: 68.7500 (67.6997)  Acc@5: 100.0000 (97.2926)  time: 0.3449  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [2800/3750]  eta: 0:05:27  Lr: 0.030000  Loss: 0.1374  Acc@1: 68.7500 (67.6968)  Acc@5: 100.0000 (97.2978)  time: 0.3452  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [2810/3750]  eta: 0:05:23  Lr: 0.030000  Loss: 0.0916  Acc@1: 68.7500 (67.7117)  Acc@5: 100.0000 (97.2941)  time: 0.3446  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [2820/3750]  eta: 0:05:20  Lr: 0.030000  Loss: 0.0011  Acc@1: 68.7500 (67.7153)  Acc@5: 93.7500 (97.2860)  time: 0.3442  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [2830/3750]  eta: 0:05:16  Lr: 0.030000  Loss: 0.0233  Acc@1: 68.7500 (67.7477)  Acc@5: 100.0000 (97.2889)  time: 0.3443  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [2840/3750]  eta: 0:05:13  Lr: 0.030000  Loss: 0.0751  Acc@1: 68.7500 (67.7446)  Acc@5: 100.0000 (97.2897)  time: 0.3439  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [2850/3750]  eta: 0:05:10  Lr: 0.030000  Loss: 0.2006  Acc@1: 68.7500 (67.7460)  Acc@5: 100.0000 (97.2926)  time: 0.3440  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [2860/3750]  eta: 0:05:06  Lr: 0.030000  Loss: -0.0670  Acc@1: 68.7500 (67.7429)  Acc@5: 100.0000 (97.2955)  time: 0.3447  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [2870/3750]  eta: 0:05:03  Lr: 0.030000  Loss: 0.1115  Acc@1: 62.5000 (67.7355)  Acc@5: 100.0000 (97.2941)  time: 0.3448  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [2880/3750]  eta: 0:04:59  Lr: 0.030000  Loss: 0.0808  Acc@1: 62.5000 (67.7282)  Acc@5: 100.0000 (97.2926)  time: 0.3443  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [2890/3750]  eta: 0:04:56  Lr: 0.030000  Loss: 0.3582  Acc@1: 68.7500 (67.7296)  Acc@5: 100.0000 (97.2933)  time: 0.3446  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [2900/3750]  eta: 0:04:52  Lr: 0.030000  Loss: -0.0464  Acc@1: 56.2500 (67.7116)  Acc@5: 100.0000 (97.2811)  time: 0.3440  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [2910/3750]  eta: 0:04:49  Lr: 0.030000  Loss: 0.1364  Acc@1: 62.5000 (67.7044)  Acc@5: 93.7500 (97.2776)  time: 0.3432  data: 0.0002  max mem: 2502
Train: Epoch[2/5]  [2920/3750]  eta: 0:04:45  Lr: 0.030000  Loss: 0.1995  Acc@1: 62.5000 (67.6951)  Acc@5: 93.7500 (97.2698)  time: 0.3433  data: 0.0002  max mem: 2502
Train: Epoch[2/5]  [2930/3750]  eta: 0:04:42  Lr: 0.030000  Loss: -0.0439  Acc@1: 62.5000 (67.6923)  Acc@5: 93.7500 (97.2620)  time: 0.3434  data: 0.0002  max mem: 2502
Train: Epoch[2/5]  [2940/3750]  eta: 0:04:39  Lr: 0.030000  Loss: -0.0864  Acc@1: 68.7500 (67.7066)  Acc@5: 93.7500 (97.2607)  time: 0.3432  data: 0.0002  max mem: 2502
Train: Epoch[2/5]  [2950/3750]  eta: 0:04:35  Lr: 0.030000  Loss: 0.0927  Acc@1: 68.7500 (67.6995)  Acc@5: 100.0000 (97.2594)  time: 0.3432  data: 0.0002  max mem: 2502
Train: Epoch[2/5]  [2960/3750]  eta: 0:04:32  Lr: 0.030000  Loss: 0.4057  Acc@1: 62.5000 (67.6798)  Acc@5: 100.0000 (97.2581)  time: 0.3432  data: 0.0002  max mem: 2502
Train: Epoch[2/5]  [2970/3750]  eta: 0:04:28  Lr: 0.030000  Loss: 0.2450  Acc@1: 68.7500 (67.6982)  Acc@5: 100.0000 (97.2652)  time: 0.3432  data: 0.0002  max mem: 2502
Train: Epoch[2/5]  [2980/3750]  eta: 0:04:25  Lr: 0.030000  Loss: 0.0176  Acc@1: 68.7500 (67.7122)  Acc@5: 100.0000 (97.2597)  time: 0.3435  data: 0.0002  max mem: 2502
Train: Epoch[2/5]  [2990/3750]  eta: 0:04:21  Lr: 0.030000  Loss: -0.0844  Acc@1: 68.7500 (67.7282)  Acc@5: 100.0000 (97.2626)  time: 0.3438  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [3000/3750]  eta: 0:04:18  Lr: 0.030000  Loss: 0.0962  Acc@1: 68.7500 (67.7212)  Acc@5: 100.0000 (97.2634)  time: 0.3448  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [3010/3750]  eta: 0:04:14  Lr: 0.030000  Loss: -0.1445  Acc@1: 68.7500 (67.7391)  Acc@5: 100.0000 (97.2663)  time: 0.3455  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [3020/3750]  eta: 0:04:11  Lr: 0.030000  Loss: 0.2325  Acc@1: 68.7500 (67.7445)  Acc@5: 100.0000 (97.2712)  time: 0.3457  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [3030/3750]  eta: 0:04:08  Lr: 0.030000  Loss: 0.4389  Acc@1: 68.7500 (67.7314)  Acc@5: 100.0000 (97.2699)  time: 0.3469  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [3040/3750]  eta: 0:04:04  Lr: 0.030000  Loss: 0.0592  Acc@1: 62.5000 (67.7121)  Acc@5: 93.7500 (97.2604)  time: 0.3477  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [3050/3750]  eta: 0:04:01  Lr: 0.030000  Loss: 0.1066  Acc@1: 62.5000 (67.7012)  Acc@5: 93.7500 (97.2529)  time: 0.3467  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [3060/3750]  eta: 0:03:57  Lr: 0.030000  Loss: -0.0088  Acc@1: 62.5000 (67.7046)  Acc@5: 93.7500 (97.2517)  time: 0.3461  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [3070/3750]  eta: 0:03:54  Lr: 0.030000  Loss: 0.0742  Acc@1: 68.7500 (67.7121)  Acc@5: 100.0000 (97.2525)  time: 0.3465  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [3080/3750]  eta: 0:03:50  Lr: 0.030000  Loss: 0.1305  Acc@1: 68.7500 (67.7195)  Acc@5: 100.0000 (97.2574)  time: 0.3468  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [3090/3750]  eta: 0:03:47  Lr: 0.030000  Loss: 0.1057  Acc@1: 68.7500 (67.7188)  Acc@5: 100.0000 (97.2602)  time: 0.3458  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [3100/3750]  eta: 0:03:43  Lr: 0.030000  Loss: 0.0142  Acc@1: 68.7500 (67.7282)  Acc@5: 100.0000 (97.2529)  time: 0.3452  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [3110/3750]  eta: 0:03:40  Lr: 0.030000  Loss: 0.0690  Acc@1: 68.7500 (67.7294)  Acc@5: 100.0000 (97.2577)  time: 0.3470  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [3120/3750]  eta: 0:03:37  Lr: 0.030000  Loss: 0.0578  Acc@1: 68.7500 (67.7467)  Acc@5: 100.0000 (97.2605)  time: 0.3468  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [3130/3750]  eta: 0:03:33  Lr: 0.030000  Loss: 0.0792  Acc@1: 68.7500 (67.7340)  Acc@5: 100.0000 (97.2613)  time: 0.3460  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [3140/3750]  eta: 0:03:30  Lr: 0.030000  Loss: -0.1057  Acc@1: 62.5000 (67.7451)  Acc@5: 100.0000 (97.2600)  time: 0.3465  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [3150/3750]  eta: 0:03:26  Lr: 0.030000  Loss: -0.1130  Acc@1: 68.7500 (67.7563)  Acc@5: 100.0000 (97.2628)  time: 0.3468  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [3160/3750]  eta: 0:03:23  Lr: 0.030000  Loss: 0.1920  Acc@1: 68.7500 (67.7515)  Acc@5: 100.0000 (97.2655)  time: 0.3459  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [3170/3750]  eta: 0:03:19  Lr: 0.030000  Loss: 0.2460  Acc@1: 68.7500 (67.7586)  Acc@5: 100.0000 (97.2682)  time: 0.3449  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [3180/3750]  eta: 0:03:16  Lr: 0.030000  Loss: 0.0449  Acc@1: 68.7500 (67.7558)  Acc@5: 100.0000 (97.2689)  time: 0.3450  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [3190/3750]  eta: 0:03:12  Lr: 0.030000  Loss: 0.3700  Acc@1: 68.7500 (67.7648)  Acc@5: 93.7500 (97.2657)  time: 0.3458  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [3200/3750]  eta: 0:03:09  Lr: 0.030000  Loss: 0.2725  Acc@1: 68.7500 (67.7581)  Acc@5: 93.7500 (97.2645)  time: 0.3460  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [3210/3750]  eta: 0:03:06  Lr: 0.030000  Loss: 0.1073  Acc@1: 68.7500 (67.7612)  Acc@5: 100.0000 (97.2653)  time: 0.3454  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [3220/3750]  eta: 0:03:02  Lr: 0.030000  Loss: -0.0642  Acc@1: 68.7500 (67.7779)  Acc@5: 100.0000 (97.2679)  time: 0.3455  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [3230/3750]  eta: 0:02:59  Lr: 0.030000  Loss: -0.1132  Acc@1: 68.7500 (67.7751)  Acc@5: 100.0000 (97.2706)  time: 0.3458  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [3240/3750]  eta: 0:02:55  Lr: 0.030000  Loss: -0.0296  Acc@1: 68.7500 (67.7781)  Acc@5: 100.0000 (97.2694)  time: 0.3449  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [3250/3750]  eta: 0:02:52  Lr: 0.030000  Loss: 0.1044  Acc@1: 68.7500 (67.7753)  Acc@5: 100.0000 (97.2681)  time: 0.3438  data: 0.0002  max mem: 2502
Train: Epoch[2/5]  [3260/3750]  eta: 0:02:48  Lr: 0.030000  Loss: 0.0076  Acc@1: 68.7500 (67.7975)  Acc@5: 100.0000 (97.2765)  time: 0.3440  data: 0.0002  max mem: 2502
Train: Epoch[2/5]  [3270/3750]  eta: 0:02:45  Lr: 0.030000  Loss: -0.2598  Acc@1: 75.0000 (67.8080)  Acc@5: 100.0000 (97.2810)  time: 0.3439  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [3280/3750]  eta: 0:02:41  Lr: 0.030000  Loss: 0.0736  Acc@1: 68.7500 (67.7995)  Acc@5: 100.0000 (97.2741)  time: 0.3441  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [3290/3750]  eta: 0:02:38  Lr: 0.030000  Loss: -0.1332  Acc@1: 62.5000 (67.7947)  Acc@5: 100.0000 (97.2767)  time: 0.3438  data: 0.0002  max mem: 2502
Train: Epoch[2/5]  [3300/3750]  eta: 0:02:35  Lr: 0.030000  Loss: 0.0767  Acc@1: 68.7500 (67.7995)  Acc@5: 100.0000 (97.2679)  time: 0.3433  data: 0.0002  max mem: 2502
Train: Epoch[2/5]  [3310/3750]  eta: 0:02:31  Lr: 0.030000  Loss: -0.0210  Acc@1: 68.7500 (67.7986)  Acc@5: 100.0000 (97.2648)  time: 0.3438  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [3320/3750]  eta: 0:02:28  Lr: 0.030000  Loss: 0.0783  Acc@1: 68.7500 (67.7940)  Acc@5: 100.0000 (97.2655)  time: 0.3450  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [3330/3750]  eta: 0:02:24  Lr: 0.030000  Loss: 0.0095  Acc@1: 75.0000 (67.8025)  Acc@5: 100.0000 (97.2681)  time: 0.3465  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [3340/3750]  eta: 0:02:21  Lr: 0.030000  Loss: 0.3770  Acc@1: 68.7500 (67.7903)  Acc@5: 100.0000 (97.2725)  time: 0.3463  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [3350/3750]  eta: 0:02:17  Lr: 0.030000  Loss: 0.1667  Acc@1: 68.7500 (67.7783)  Acc@5: 100.0000 (97.2751)  time: 0.3456  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [3360/3750]  eta: 0:02:14  Lr: 0.030000  Loss: -0.1094  Acc@1: 68.7500 (67.7905)  Acc@5: 100.0000 (97.2720)  time: 0.3457  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [3370/3750]  eta: 0:02:10  Lr: 0.030000  Loss: -0.2484  Acc@1: 75.0000 (67.8063)  Acc@5: 93.7500 (97.2708)  time: 0.3454  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [3380/3750]  eta: 0:02:07  Lr: 0.030000  Loss: 0.0689  Acc@1: 68.7500 (67.8091)  Acc@5: 93.7500 (97.2678)  time: 0.3463  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [3390/3750]  eta: 0:02:04  Lr: 0.030000  Loss: -0.0893  Acc@1: 68.7500 (67.8082)  Acc@5: 100.0000 (97.2703)  time: 0.3462  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [3400/3750]  eta: 0:02:00  Lr: 0.030000  Loss: -0.1002  Acc@1: 68.7500 (67.8293)  Acc@5: 100.0000 (97.2710)  time: 0.3443  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [3410/3750]  eta: 0:01:57  Lr: 0.030000  Loss: 0.1149  Acc@1: 68.7500 (67.8192)  Acc@5: 100.0000 (97.2717)  time: 0.3450  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [3420/3750]  eta: 0:01:53  Lr: 0.030000  Loss: -0.0209  Acc@1: 68.7500 (67.8347)  Acc@5: 100.0000 (97.2669)  time: 0.3465  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [3430/3750]  eta: 0:01:50  Lr: 0.030000  Loss: 0.4545  Acc@1: 68.7500 (67.8319)  Acc@5: 100.0000 (97.2639)  time: 0.3500  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [3440/3750]  eta: 0:01:46  Lr: 0.030000  Loss: -0.0822  Acc@1: 68.7500 (67.8527)  Acc@5: 100.0000 (97.2682)  time: 0.3488  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [3450/3750]  eta: 0:01:43  Lr: 0.030000  Loss: 0.0533  Acc@1: 75.0000 (67.8608)  Acc@5: 100.0000 (97.2725)  time: 0.3442  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [3460/3750]  eta: 0:01:39  Lr: 0.030000  Loss: 0.0971  Acc@1: 68.7500 (67.8742)  Acc@5: 100.0000 (97.2714)  time: 0.3442  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [3470/3750]  eta: 0:01:36  Lr: 0.030000  Loss: 0.0312  Acc@1: 68.7500 (67.8785)  Acc@5: 100.0000 (97.2756)  time: 0.3448  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [3480/3750]  eta: 0:01:33  Lr: 0.030000  Loss: 0.3582  Acc@1: 68.7500 (67.8882)  Acc@5: 100.0000 (97.2763)  time: 0.3447  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [3490/3750]  eta: 0:01:29  Lr: 0.030000  Loss: 0.0603  Acc@1: 75.0000 (67.8942)  Acc@5: 100.0000 (97.2769)  time: 0.3442  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [3500/3750]  eta: 0:01:26  Lr: 0.030000  Loss: -0.0191  Acc@1: 68.7500 (67.8788)  Acc@5: 100.0000 (97.2811)  time: 0.3446  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [3510/3750]  eta: 0:01:22  Lr: 0.030000  Loss: 0.0889  Acc@1: 68.7500 (67.8884)  Acc@5: 100.0000 (97.2853)  time: 0.3438  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [3520/3750]  eta: 0:01:19  Lr: 0.030000  Loss: 0.2165  Acc@1: 68.7500 (67.8909)  Acc@5: 100.0000 (97.2824)  time: 0.3427  data: 0.0002  max mem: 2502
Train: Epoch[2/5]  [3530/3750]  eta: 0:01:15  Lr: 0.030000  Loss: 0.0742  Acc@1: 68.7500 (67.8951)  Acc@5: 100.0000 (97.2812)  time: 0.3433  data: 0.0002  max mem: 2502
Train: Epoch[2/5]  [3540/3750]  eta: 0:01:12  Lr: 0.030000  Loss: 0.0571  Acc@1: 75.0000 (67.9151)  Acc@5: 100.0000 (97.2818)  time: 0.3433  data: 0.0002  max mem: 2502
Train: Epoch[2/5]  [3550/3750]  eta: 0:01:08  Lr: 0.030000  Loss: -0.0152  Acc@1: 75.0000 (67.9263)  Acc@5: 100.0000 (97.2842)  time: 0.3432  data: 0.0002  max mem: 2502
Train: Epoch[2/5]  [3560/3750]  eta: 0:01:05  Lr: 0.030000  Loss: -0.1540  Acc@1: 68.7500 (67.9339)  Acc@5: 100.0000 (97.2813)  time: 0.3442  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [3570/3750]  eta: 0:01:02  Lr: 0.030000  Loss: 0.1724  Acc@1: 68.7500 (67.9397)  Acc@5: 100.0000 (97.2837)  time: 0.3450  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [3580/3750]  eta: 0:00:58  Lr: 0.030000  Loss: 0.2585  Acc@1: 68.7500 (67.9489)  Acc@5: 100.0000 (97.2790)  time: 0.3450  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [3590/3750]  eta: 0:00:55  Lr: 0.030000  Loss: 0.1517  Acc@1: 68.7500 (67.9581)  Acc@5: 100.0000 (97.2831)  time: 0.3457  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [3600/3750]  eta: 0:00:51  Lr: 0.030000  Loss: -0.1119  Acc@1: 68.7500 (67.9655)  Acc@5: 100.0000 (97.2785)  time: 0.3458  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [3610/3750]  eta: 0:00:48  Lr: 0.030000  Loss: -0.0196  Acc@1: 68.7500 (67.9711)  Acc@5: 100.0000 (97.2843)  time: 0.3455  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [3620/3750]  eta: 0:00:44  Lr: 0.030000  Loss: -0.0165  Acc@1: 68.7500 (67.9836)  Acc@5: 100.0000 (97.2884)  time: 0.3454  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [3630/3750]  eta: 0:00:41  Lr: 0.030000  Loss: 0.0625  Acc@1: 68.7500 (67.9806)  Acc@5: 100.0000 (97.2890)  time: 0.3460  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [3640/3750]  eta: 0:00:37  Lr: 0.030000  Loss: 0.1310  Acc@1: 62.5000 (67.9690)  Acc@5: 100.0000 (97.2844)  time: 0.3463  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [3650/3750]  eta: 0:00:34  Lr: 0.030000  Loss: 0.0634  Acc@1: 62.5000 (67.9608)  Acc@5: 100.0000 (97.2901)  time: 0.3453  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [3660/3750]  eta: 0:00:31  Lr: 0.030000  Loss: 0.0723  Acc@1: 62.5000 (67.9425)  Acc@5: 100.0000 (97.2958)  time: 0.3448  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [3670/3750]  eta: 0:00:27  Lr: 0.030000  Loss: -0.0228  Acc@1: 62.5000 (67.9413)  Acc@5: 100.0000 (97.2981)  time: 0.3450  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [3680/3750]  eta: 0:00:24  Lr: 0.030000  Loss: -0.2563  Acc@1: 68.7500 (67.9486)  Acc@5: 100.0000 (97.2952)  time: 0.3450  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [3690/3750]  eta: 0:00:20  Lr: 0.030000  Loss: 0.2663  Acc@1: 68.7500 (67.9440)  Acc@5: 100.0000 (97.2992)  time: 0.3445  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [3700/3750]  eta: 0:00:17  Lr: 0.030000  Loss: 0.1534  Acc@1: 68.7500 (67.9479)  Acc@5: 100.0000 (97.3065)  time: 0.3451  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [3710/3750]  eta: 0:00:13  Lr: 0.030000  Loss: 0.2066  Acc@1: 68.7500 (67.9534)  Acc@5: 100.0000 (97.3104)  time: 0.3446  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [3720/3750]  eta: 0:00:10  Lr: 0.030000  Loss: -0.0524  Acc@1: 68.7500 (67.9572)  Acc@5: 100.0000 (97.3075)  time: 0.3439  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [3730/3750]  eta: 0:00:06  Lr: 0.030000  Loss: 0.0468  Acc@1: 68.7500 (67.9577)  Acc@5: 93.7500 (97.3047)  time: 0.3443  data: 0.0002  max mem: 2502
Train: Epoch[2/5]  [3740/3750]  eta: 0:00:03  Lr: 0.030000  Loss: 0.0429  Acc@1: 62.5000 (67.9548)  Acc@5: 100.0000 (97.3085)  time: 0.3446  data: 0.0002  max mem: 2502
Train: Epoch[2/5]  [3749/3750]  eta: 0:00:00  Lr: 0.030000  Loss: -0.2570  Acc@1: 68.7500 (67.9583)  Acc@5: 100.0000 (97.3133)  time: 0.3451  data: 0.0006  max mem: 2502
Train: Epoch[2/5] Total time: 0:21:33 (0.3448 s / it)
{0: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 1: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 2: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 3: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 4: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 5: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 6: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 7: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 8: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 9: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 10: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 11: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 12: {0: 0, 1: 0, 2: 0, 3: 91325, 4: 0}, 13: {0: 0, 1: 0, 2: 0, 3: 91325, 4: 0}, 14: {0: 0, 1: 0, 2: 0, 3: 91325, 4: 0}, 15: {0: 0, 1: 0, 2: 0, 3: 91325, 4: 0}, 16: {0: 0, 1: 0, 2: 0, 3: 0, 4: 120000}, 17: {0: 0, 1: 0, 2: 0, 3: 0, 4: 120000}, 18: {0: 0, 1: 0, 2: 0, 3: 0, 4: 120000}, 19: {0: 0, 1: 0, 2: 0, 3: 0, 4: 120000}}
Averaged stats: Lr: 0.030000  Loss: -0.2570  Acc@1: 68.7500 (67.9583)  Acc@5: 100.0000 (97.3133)
Train: Epoch[3/5]  [   0/3750]  eta: 0:36:57  Lr: 0.030000  Loss: -0.2618  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (100.0000)  time: 0.5913  data: 0.2400  max mem: 2502
Train: Epoch[3/5]  [  10/3750]  eta: 0:22:59  Lr: 0.030000  Loss: 0.1685  Acc@1: 68.7500 (71.5909)  Acc@5: 100.0000 (97.7273)  time: 0.3688  data: 0.0222  max mem: 2502
Train: Epoch[3/5]  [  20/3750]  eta: 0:22:14  Lr: 0.030000  Loss: -0.0185  Acc@1: 68.7500 (72.3214)  Acc@5: 100.0000 (96.7262)  time: 0.3462  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [  30/3750]  eta: 0:21:58  Lr: 0.030000  Loss: -0.0052  Acc@1: 68.7500 (71.9758)  Acc@5: 93.7500 (96.5726)  time: 0.3464  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [  40/3750]  eta: 0:21:47  Lr: 0.030000  Loss: 0.1839  Acc@1: 68.7500 (70.2744)  Acc@5: 100.0000 (97.1037)  time: 0.3465  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [  50/3750]  eta: 0:21:39  Lr: 0.030000  Loss: 0.0307  Acc@1: 68.7500 (70.4657)  Acc@5: 100.0000 (97.3039)  time: 0.3461  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [  60/3750]  eta: 0:21:32  Lr: 0.030000  Loss: 0.2061  Acc@1: 68.7500 (69.6721)  Acc@5: 100.0000 (97.2336)  time: 0.3458  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [  70/3750]  eta: 0:21:26  Lr: 0.030000  Loss: 0.0028  Acc@1: 68.7500 (69.7183)  Acc@5: 100.0000 (97.3592)  time: 0.3457  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [  80/3750]  eta: 0:21:20  Lr: 0.030000  Loss: 0.0257  Acc@1: 68.7500 (69.7531)  Acc@5: 100.0000 (97.5309)  time: 0.3453  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [  90/3750]  eta: 0:21:15  Lr: 0.030000  Loss: -0.0333  Acc@1: 75.0000 (70.3984)  Acc@5: 100.0000 (97.3214)  time: 0.3448  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [ 100/3750]  eta: 0:21:11  Lr: 0.030000  Loss: -0.0341  Acc@1: 75.0000 (70.1114)  Acc@5: 100.0000 (97.4010)  time: 0.3452  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [ 110/3750]  eta: 0:21:06  Lr: 0.030000  Loss: 0.1882  Acc@1: 62.5000 (70.0450)  Acc@5: 100.0000 (97.2973)  time: 0.3445  data: 0.0002  max mem: 2502
Train: Epoch[3/5]  [ 120/3750]  eta: 0:21:01  Lr: 0.030000  Loss: 0.0455  Acc@1: 75.0000 (70.5579)  Acc@5: 100.0000 (97.3657)  time: 0.3431  data: 0.0002  max mem: 2502
Train: Epoch[3/5]  [ 130/3750]  eta: 0:20:56  Lr: 0.030000  Loss: 0.3242  Acc@1: 68.7500 (70.1336)  Acc@5: 100.0000 (97.3760)  time: 0.3430  data: 0.0002  max mem: 2502
Train: Epoch[3/5]  [ 140/3750]  eta: 0:20:52  Lr: 0.030000  Loss: 0.0484  Acc@1: 62.5000 (70.0798)  Acc@5: 100.0000 (97.4734)  time: 0.3434  data: 0.0002  max mem: 2502
Train: Epoch[3/5]  [ 150/3750]  eta: 0:20:47  Lr: 0.030000  Loss: -0.0159  Acc@1: 68.7500 (70.0745)  Acc@5: 100.0000 (97.5993)  time: 0.3435  data: 0.0002  max mem: 2502
Train: Epoch[3/5]  [ 160/3750]  eta: 0:20:44  Lr: 0.030000  Loss: -0.0532  Acc@1: 68.7500 (70.0699)  Acc@5: 100.0000 (97.6708)  time: 0.3451  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [ 170/3750]  eta: 0:20:40  Lr: 0.030000  Loss: 0.2323  Acc@1: 62.5000 (69.8465)  Acc@5: 100.0000 (97.5877)  time: 0.3454  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [ 180/3750]  eta: 0:20:36  Lr: 0.030000  Loss: 0.0453  Acc@1: 68.7500 (69.8204)  Acc@5: 100.0000 (97.6174)  time: 0.3443  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [ 190/3750]  eta: 0:20:32  Lr: 0.030000  Loss: 0.3220  Acc@1: 68.7500 (70.0589)  Acc@5: 100.0000 (97.6113)  time: 0.3448  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [ 200/3750]  eta: 0:20:29  Lr: 0.030000  Loss: 0.1628  Acc@1: 68.7500 (69.6828)  Acc@5: 100.0000 (97.6057)  time: 0.3459  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [ 210/3750]  eta: 0:20:25  Lr: 0.030000  Loss: -0.0337  Acc@1: 68.7500 (69.5794)  Acc@5: 100.0000 (97.6303)  time: 0.3458  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [ 220/3750]  eta: 0:20:22  Lr: 0.030000  Loss: 0.0515  Acc@1: 68.7500 (69.6550)  Acc@5: 100.0000 (97.6244)  time: 0.3451  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [ 230/3750]  eta: 0:20:18  Lr: 0.030000  Loss: 0.0719  Acc@1: 68.7500 (69.6970)  Acc@5: 100.0000 (97.6190)  time: 0.3445  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [ 240/3750]  eta: 0:20:14  Lr: 0.030000  Loss: -0.1606  Acc@1: 68.7500 (69.7095)  Acc@5: 100.0000 (97.6141)  time: 0.3454  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [ 250/3750]  eta: 0:20:11  Lr: 0.030000  Loss: 0.0292  Acc@1: 68.7500 (69.8207)  Acc@5: 93.7500 (97.5349)  time: 0.3453  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [ 260/3750]  eta: 0:20:07  Lr: 0.030000  Loss: 0.0026  Acc@1: 68.7500 (69.8036)  Acc@5: 93.7500 (97.5096)  time: 0.3441  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [ 270/3750]  eta: 0:20:03  Lr: 0.030000  Loss: 0.1122  Acc@1: 68.7500 (69.7878)  Acc@5: 100.0000 (97.5092)  time: 0.3446  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [ 280/3750]  eta: 0:20:00  Lr: 0.030000  Loss: -0.0354  Acc@1: 68.7500 (69.7064)  Acc@5: 100.0000 (97.5311)  time: 0.3446  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [ 290/3750]  eta: 0:19:56  Lr: 0.030000  Loss: -0.0403  Acc@1: 75.0000 (69.8239)  Acc@5: 100.0000 (97.4656)  time: 0.3442  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [ 300/3750]  eta: 0:19:52  Lr: 0.030000  Loss: 0.0027  Acc@1: 75.0000 (69.9128)  Acc@5: 100.0000 (97.4875)  time: 0.3445  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [ 310/3750]  eta: 0:19:49  Lr: 0.030000  Loss: -0.1098  Acc@1: 68.7500 (69.8151)  Acc@5: 100.0000 (97.4879)  time: 0.3437  data: 0.0002  max mem: 2502
Train: Epoch[3/5]  [ 320/3750]  eta: 0:19:45  Lr: 0.030000  Loss: 0.0759  Acc@1: 68.7500 (69.7625)  Acc@5: 100.0000 (97.4688)  time: 0.3423  data: 0.0002  max mem: 2502
Train: Epoch[3/5]  [ 330/3750]  eta: 0:19:41  Lr: 0.030000  Loss: 0.1312  Acc@1: 68.7500 (69.6563)  Acc@5: 100.0000 (97.5076)  time: 0.3423  data: 0.0002  max mem: 2502
Train: Epoch[3/5]  [ 340/3750]  eta: 0:19:37  Lr: 0.030000  Loss: 0.0425  Acc@1: 68.7500 (69.7764)  Acc@5: 100.0000 (97.5440)  time: 0.3424  data: 0.0002  max mem: 2502
Train: Epoch[3/5]  [ 350/3750]  eta: 0:19:34  Lr: 0.030000  Loss: 0.0984  Acc@1: 68.7500 (69.6047)  Acc@5: 100.0000 (97.5427)  time: 0.3425  data: 0.0002  max mem: 2502
Train: Epoch[3/5]  [ 360/3750]  eta: 0:19:30  Lr: 0.030000  Loss: 0.0383  Acc@1: 68.7500 (69.7368)  Acc@5: 100.0000 (97.5762)  time: 0.3426  data: 0.0002  max mem: 2502
Train: Epoch[3/5]  [ 370/3750]  eta: 0:19:26  Lr: 0.030000  Loss: 0.2305  Acc@1: 68.7500 (69.6429)  Acc@5: 100.0000 (97.5910)  time: 0.3425  data: 0.0002  max mem: 2502
Train: Epoch[3/5]  [ 380/3750]  eta: 0:19:23  Lr: 0.030000  Loss: -0.1968  Acc@1: 62.5000 (69.3898)  Acc@5: 100.0000 (97.6050)  time: 0.3436  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [ 390/3750]  eta: 0:19:19  Lr: 0.030000  Loss: -0.0243  Acc@1: 62.5000 (69.4373)  Acc@5: 100.0000 (97.6343)  time: 0.3445  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [ 400/3750]  eta: 0:19:16  Lr: 0.030000  Loss: 0.1206  Acc@1: 75.0000 (69.4358)  Acc@5: 100.0000 (97.6621)  time: 0.3466  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [ 410/3750]  eta: 0:19:13  Lr: 0.030000  Loss: -0.0256  Acc@1: 68.7500 (69.4191)  Acc@5: 100.0000 (97.6734)  time: 0.3475  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [ 420/3750]  eta: 0:19:09  Lr: 0.030000  Loss: -0.0219  Acc@1: 68.7500 (69.4923)  Acc@5: 100.0000 (97.6692)  time: 0.3459  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [ 430/3750]  eta: 0:19:06  Lr: 0.030000  Loss: 0.0187  Acc@1: 75.0000 (69.5476)  Acc@5: 100.0000 (97.7088)  time: 0.3456  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [ 440/3750]  eta: 0:19:02  Lr: 0.030000  Loss: -0.0457  Acc@1: 68.7500 (69.4161)  Acc@5: 100.0000 (97.7041)  time: 0.3452  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [ 450/3750]  eta: 0:18:59  Lr: 0.030000  Loss: 0.0025  Acc@1: 68.7500 (69.4013)  Acc@5: 93.7500 (97.6303)  time: 0.3453  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [ 460/3750]  eta: 0:18:55  Lr: 0.030000  Loss: -0.0979  Acc@1: 68.7500 (69.4143)  Acc@5: 93.7500 (97.6274)  time: 0.3462  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [ 470/3750]  eta: 0:18:52  Lr: 0.030000  Loss: 0.0424  Acc@1: 62.5000 (69.2941)  Acc@5: 100.0000 (97.6247)  time: 0.3454  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [ 480/3750]  eta: 0:18:49  Lr: 0.030000  Loss: 0.2632  Acc@1: 62.5000 (69.2438)  Acc@5: 100.0000 (97.6611)  time: 0.3449  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [ 490/3750]  eta: 0:18:45  Lr: 0.030000  Loss: -0.0537  Acc@1: 68.7500 (69.1446)  Acc@5: 100.0000 (97.6578)  time: 0.3455  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [ 500/3750]  eta: 0:18:42  Lr: 0.030000  Loss: 0.0357  Acc@1: 68.7500 (69.2241)  Acc@5: 100.0000 (97.6796)  time: 0.3480  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [ 510/3750]  eta: 0:18:38  Lr: 0.030000  Loss: 0.1601  Acc@1: 68.7500 (69.2392)  Acc@5: 100.0000 (97.6150)  time: 0.3479  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [ 520/3750]  eta: 0:18:35  Lr: 0.030000  Loss: 0.1130  Acc@1: 68.7500 (69.3138)  Acc@5: 100.0000 (97.6368)  time: 0.3444  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [ 530/3750]  eta: 0:18:31  Lr: 0.030000  Loss: 0.2605  Acc@1: 75.0000 (69.3032)  Acc@5: 100.0000 (97.6460)  time: 0.3439  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [ 540/3750]  eta: 0:18:28  Lr: 0.030000  Loss: 0.2675  Acc@1: 62.5000 (69.1428)  Acc@5: 100.0000 (97.6548)  time: 0.3448  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [ 550/3750]  eta: 0:18:24  Lr: 0.030000  Loss: -0.1736  Acc@1: 62.5000 (69.0903)  Acc@5: 100.0000 (97.6520)  time: 0.3450  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [ 560/3750]  eta: 0:18:21  Lr: 0.030000  Loss: 0.1634  Acc@1: 62.5000 (69.0062)  Acc@5: 100.0000 (97.6381)  time: 0.3443  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [ 570/3750]  eta: 0:18:17  Lr: 0.030000  Loss: 0.1157  Acc@1: 62.5000 (69.0565)  Acc@5: 100.0000 (97.6248)  time: 0.3446  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [ 580/3750]  eta: 0:18:14  Lr: 0.030000  Loss: 0.1653  Acc@1: 68.7500 (69.0942)  Acc@5: 100.0000 (97.6334)  time: 0.3457  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [ 590/3750]  eta: 0:18:10  Lr: 0.030000  Loss: 0.1592  Acc@1: 68.7500 (69.0990)  Acc@5: 100.0000 (97.6100)  time: 0.3444  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [ 600/3750]  eta: 0:18:07  Lr: 0.030000  Loss: 0.1005  Acc@1: 68.7500 (69.0516)  Acc@5: 93.7500 (97.5458)  time: 0.3424  data: 0.0002  max mem: 2502
Train: Epoch[3/5]  [ 610/3750]  eta: 0:18:03  Lr: 0.030000  Loss: 0.1027  Acc@1: 68.7500 (69.1489)  Acc@5: 100.0000 (97.5859)  time: 0.3424  data: 0.0002  max mem: 2502
Train: Epoch[3/5]  [ 620/3750]  eta: 0:18:00  Lr: 0.030000  Loss: 0.2196  Acc@1: 68.7500 (69.0117)  Acc@5: 100.0000 (97.5644)  time: 0.3423  data: 0.0002  max mem: 2502
Train: Epoch[3/5]  [ 630/3750]  eta: 0:17:56  Lr: 0.030000  Loss: 0.0321  Acc@1: 68.7500 (69.0273)  Acc@5: 100.0000 (97.5832)  time: 0.3423  data: 0.0002  max mem: 2502
Train: Epoch[3/5]  [ 640/3750]  eta: 0:17:53  Lr: 0.030000  Loss: -0.0250  Acc@1: 68.7500 (68.9840)  Acc@5: 100.0000 (97.5429)  time: 0.3424  data: 0.0002  max mem: 2502
Train: Epoch[3/5]  [ 650/3750]  eta: 0:17:49  Lr: 0.030000  Loss: 0.0172  Acc@1: 68.7500 (69.0284)  Acc@5: 100.0000 (97.5710)  time: 0.3423  data: 0.0002  max mem: 2502
Train: Epoch[3/5]  [ 660/3750]  eta: 0:17:45  Lr: 0.030000  Loss: 0.0258  Acc@1: 75.0000 (69.0715)  Acc@5: 100.0000 (97.5794)  time: 0.3423  data: 0.0002  max mem: 2502
Train: Epoch[3/5]  [ 670/3750]  eta: 0:17:42  Lr: 0.030000  Loss: 0.0233  Acc@1: 75.0000 (69.1319)  Acc@5: 100.0000 (97.5969)  time: 0.3423  data: 0.0002  max mem: 2502
Train: Epoch[3/5]  [ 680/3750]  eta: 0:17:38  Lr: 0.030000  Loss: 0.3725  Acc@1: 68.7500 (69.0896)  Acc@5: 100.0000 (97.5587)  time: 0.3448  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [ 690/3750]  eta: 0:17:35  Lr: 0.030000  Loss: 0.1342  Acc@1: 68.7500 (69.1480)  Acc@5: 93.7500 (97.5488)  time: 0.3462  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [ 700/3750]  eta: 0:17:32  Lr: 0.030000  Loss: 0.0959  Acc@1: 75.0000 (69.1690)  Acc@5: 100.0000 (97.5571)  time: 0.3456  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [ 710/3750]  eta: 0:17:28  Lr: 0.030000  Loss: -0.0996  Acc@1: 68.7500 (69.2071)  Acc@5: 100.0000 (97.5738)  time: 0.3461  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [ 720/3750]  eta: 0:17:25  Lr: 0.030000  Loss: -0.0329  Acc@1: 75.0000 (69.2788)  Acc@5: 100.0000 (97.5902)  time: 0.3463  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [ 730/3750]  eta: 0:17:21  Lr: 0.030000  Loss: 0.1688  Acc@1: 75.0000 (69.2630)  Acc@5: 100.0000 (97.5804)  time: 0.3460  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [ 740/3750]  eta: 0:17:18  Lr: 0.030000  Loss: 0.0156  Acc@1: 68.7500 (69.2982)  Acc@5: 100.0000 (97.5793)  time: 0.3467  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [ 750/3750]  eta: 0:17:15  Lr: 0.030000  Loss: 0.1414  Acc@1: 68.7500 (69.2993)  Acc@5: 100.0000 (97.5533)  time: 0.3463  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [ 760/3750]  eta: 0:17:11  Lr: 0.030000  Loss: -0.1634  Acc@1: 68.7500 (69.2838)  Acc@5: 100.0000 (97.5690)  time: 0.3447  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [ 770/3750]  eta: 0:17:08  Lr: 0.030000  Loss: 0.1798  Acc@1: 68.7500 (69.2607)  Acc@5: 100.0000 (97.5519)  time: 0.3451  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [ 780/3750]  eta: 0:17:04  Lr: 0.030000  Loss: -0.1469  Acc@1: 68.7500 (69.1981)  Acc@5: 100.0000 (97.5592)  time: 0.3452  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [ 790/3750]  eta: 0:17:01  Lr: 0.030000  Loss: -0.0120  Acc@1: 62.5000 (69.0977)  Acc@5: 100.0000 (97.5664)  time: 0.3451  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [ 800/3750]  eta: 0:16:57  Lr: 0.030000  Loss: 0.3007  Acc@1: 62.5000 (69.0465)  Acc@5: 100.0000 (97.5499)  time: 0.3464  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [ 810/3750]  eta: 0:16:54  Lr: 0.030000  Loss: 0.0269  Acc@1: 68.7500 (69.1045)  Acc@5: 100.0000 (97.5647)  time: 0.3461  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [ 820/3750]  eta: 0:16:51  Lr: 0.030000  Loss: -0.0550  Acc@1: 68.7500 (69.1535)  Acc@5: 100.0000 (97.5716)  time: 0.3461  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [ 830/3750]  eta: 0:16:47  Lr: 0.030000  Loss: 0.0676  Acc@1: 75.0000 (69.1937)  Acc@5: 100.0000 (97.5857)  time: 0.3465  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [ 840/3750]  eta: 0:16:44  Lr: 0.030000  Loss: -0.0389  Acc@1: 75.0000 (69.2182)  Acc@5: 100.0000 (97.6070)  time: 0.3473  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [ 850/3750]  eta: 0:16:40  Lr: 0.030000  Loss: 0.0848  Acc@1: 68.7500 (69.2347)  Acc@5: 100.0000 (97.6278)  time: 0.3465  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [ 860/3750]  eta: 0:16:37  Lr: 0.030000  Loss: -0.0021  Acc@1: 75.0000 (69.2799)  Acc@5: 100.0000 (97.6408)  time: 0.3446  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [ 870/3750]  eta: 0:16:33  Lr: 0.030000  Loss: 0.1717  Acc@1: 75.0000 (69.2666)  Acc@5: 100.0000 (97.6392)  time: 0.3446  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [ 880/3750]  eta: 0:16:30  Lr: 0.030000  Loss: 0.2307  Acc@1: 68.7500 (69.2679)  Acc@5: 100.0000 (97.6589)  time: 0.3455  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [ 890/3750]  eta: 0:16:27  Lr: 0.030000  Loss: 0.1939  Acc@1: 68.7500 (69.2340)  Acc@5: 100.0000 (97.6641)  time: 0.3454  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [ 900/3750]  eta: 0:16:23  Lr: 0.030000  Loss: 0.1095  Acc@1: 68.7500 (69.1593)  Acc@5: 100.0000 (97.6831)  time: 0.3446  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [ 910/3750]  eta: 0:16:20  Lr: 0.030000  Loss: 0.0767  Acc@1: 68.7500 (69.1959)  Acc@5: 100.0000 (97.7017)  time: 0.3449  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [ 920/3750]  eta: 0:16:16  Lr: 0.030000  Loss: 0.0294  Acc@1: 75.0000 (69.2522)  Acc@5: 100.0000 (97.6995)  time: 0.3440  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [ 930/3750]  eta: 0:16:13  Lr: 0.030000  Loss: -0.1011  Acc@1: 75.0000 (69.2669)  Acc@5: 100.0000 (97.7041)  time: 0.3428  data: 0.0002  max mem: 2502
Train: Epoch[3/5]  [ 940/3750]  eta: 0:16:09  Lr: 0.030000  Loss: 0.1853  Acc@1: 75.0000 (69.3544)  Acc@5: 100.0000 (97.6886)  time: 0.3428  data: 0.0002  max mem: 2502
Train: Epoch[3/5]  [ 950/3750]  eta: 0:16:06  Lr: 0.030000  Loss: 0.0277  Acc@1: 75.0000 (69.3349)  Acc@5: 100.0000 (97.6866)  time: 0.3426  data: 0.0002  max mem: 2502
Train: Epoch[3/5]  [ 960/3750]  eta: 0:16:02  Lr: 0.030000  Loss: 0.0032  Acc@1: 68.7500 (69.3158)  Acc@5: 100.0000 (97.6847)  time: 0.3426  data: 0.0002  max mem: 2502
Train: Epoch[3/5]  [ 970/3750]  eta: 0:15:59  Lr: 0.030000  Loss: 0.0988  Acc@1: 68.7500 (69.3293)  Acc@5: 100.0000 (97.6699)  time: 0.3425  data: 0.0002  max mem: 2502
Train: Epoch[3/5]  [ 980/3750]  eta: 0:15:55  Lr: 0.030000  Loss: 0.1887  Acc@1: 68.7500 (69.3298)  Acc@5: 100.0000 (97.6809)  time: 0.3424  data: 0.0002  max mem: 2502
Train: Epoch[3/5]  [ 990/3750]  eta: 0:15:52  Lr: 0.030000  Loss: 0.1055  Acc@1: 68.7500 (69.3176)  Acc@5: 100.0000 (97.6665)  time: 0.3436  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [1000/3750]  eta: 0:15:48  Lr: 0.030000  Loss: -0.1579  Acc@1: 68.7500 (69.3681)  Acc@5: 100.0000 (97.6711)  time: 0.3448  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [1010/3750]  eta: 0:15:45  Lr: 0.030000  Loss: 0.2541  Acc@1: 68.7500 (69.3497)  Acc@5: 100.0000 (97.6756)  time: 0.3447  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [1020/3750]  eta: 0:15:41  Lr: 0.030000  Loss: 0.1163  Acc@1: 68.7500 (69.3744)  Acc@5: 100.0000 (97.6738)  time: 0.3443  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [1030/3750]  eta: 0:15:38  Lr: 0.030000  Loss: 0.0684  Acc@1: 68.7500 (69.3441)  Acc@5: 100.0000 (97.6722)  time: 0.3442  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [1040/3750]  eta: 0:15:34  Lr: 0.030000  Loss: 0.1543  Acc@1: 68.7500 (69.3444)  Acc@5: 93.7500 (97.6525)  time: 0.3450  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [1050/3750]  eta: 0:15:31  Lr: 0.030000  Loss: 0.0044  Acc@1: 68.7500 (69.3566)  Acc@5: 100.0000 (97.6629)  time: 0.3452  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [1060/3750]  eta: 0:15:27  Lr: 0.030000  Loss: 0.0648  Acc@1: 68.7500 (69.3567)  Acc@5: 93.7500 (97.6320)  time: 0.3449  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [1070/3750]  eta: 0:15:24  Lr: 0.030000  Loss: 0.0936  Acc@1: 75.0000 (69.4211)  Acc@5: 93.7500 (97.6424)  time: 0.3454  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [1080/3750]  eta: 0:15:20  Lr: 0.030000  Loss: 0.0567  Acc@1: 68.7500 (69.3975)  Acc@5: 100.0000 (97.6411)  time: 0.3452  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [1090/3750]  eta: 0:15:17  Lr: 0.030000  Loss: 0.1967  Acc@1: 62.5000 (69.3401)  Acc@5: 100.0000 (97.6111)  time: 0.3447  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [1100/3750]  eta: 0:15:14  Lr: 0.030000  Loss: 0.1096  Acc@1: 68.7500 (69.4312)  Acc@5: 100.0000 (97.6158)  time: 0.3452  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [1110/3750]  eta: 0:15:10  Lr: 0.030000  Loss: 0.1351  Acc@1: 81.2500 (69.4588)  Acc@5: 100.0000 (97.6148)  time: 0.3493  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [1120/3750]  eta: 0:15:07  Lr: 0.030000  Loss: 0.0570  Acc@1: 68.7500 (69.4469)  Acc@5: 100.0000 (97.6137)  time: 0.3483  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [1130/3750]  eta: 0:15:03  Lr: 0.030000  Loss: 0.0848  Acc@1: 68.7500 (69.4408)  Acc@5: 100.0000 (97.6127)  time: 0.3437  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [1140/3750]  eta: 0:15:00  Lr: 0.030000  Loss: 0.1867  Acc@1: 68.7500 (69.4511)  Acc@5: 100.0000 (97.6172)  time: 0.3441  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [1150/3750]  eta: 0:14:56  Lr: 0.030000  Loss: 0.1970  Acc@1: 68.7500 (69.4668)  Acc@5: 100.0000 (97.6216)  time: 0.3451  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [1160/3750]  eta: 0:14:53  Lr: 0.030000  Loss: -0.0218  Acc@1: 68.7500 (69.4121)  Acc@5: 100.0000 (97.6044)  time: 0.3447  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [1170/3750]  eta: 0:14:50  Lr: 0.030000  Loss: 0.2548  Acc@1: 62.5000 (69.3424)  Acc@5: 100.0000 (97.6089)  time: 0.3435  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [1180/3750]  eta: 0:14:46  Lr: 0.030000  Loss: 0.1402  Acc@1: 68.7500 (69.3956)  Acc@5: 100.0000 (97.6027)  time: 0.3431  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [1190/3750]  eta: 0:14:43  Lr: 0.030000  Loss: -0.0641  Acc@1: 75.0000 (69.4112)  Acc@5: 100.0000 (97.6071)  time: 0.3443  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [1200/3750]  eta: 0:14:39  Lr: 0.030000  Loss: -0.0188  Acc@1: 68.7500 (69.4421)  Acc@5: 100.0000 (97.6010)  time: 0.3486  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [1210/3750]  eta: 0:14:36  Lr: 0.030000  Loss: -0.2867  Acc@1: 68.7500 (69.4932)  Acc@5: 100.0000 (97.6053)  time: 0.3496  data: 0.0006  max mem: 2502
Train: Epoch[3/5]  [1220/3750]  eta: 0:14:32  Lr: 0.030000  Loss: 0.0124  Acc@1: 75.0000 (69.5434)  Acc@5: 100.0000 (97.6044)  time: 0.3457  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [1230/3750]  eta: 0:14:29  Lr: 0.030000  Loss: 0.0408  Acc@1: 75.0000 (69.5776)  Acc@5: 100.0000 (97.6036)  time: 0.3437  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [1240/3750]  eta: 0:14:25  Lr: 0.030000  Loss: 0.0609  Acc@1: 75.0000 (69.5659)  Acc@5: 100.0000 (97.6027)  time: 0.3442  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [1250/3750]  eta: 0:14:22  Lr: 0.030000  Loss: -0.0363  Acc@1: 75.0000 (69.5643)  Acc@5: 100.0000 (97.6069)  time: 0.3444  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [1260/3750]  eta: 0:14:19  Lr: 0.030000  Loss: 0.1871  Acc@1: 68.7500 (69.5480)  Acc@5: 100.0000 (97.6209)  time: 0.3446  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [1270/3750]  eta: 0:14:15  Lr: 0.030000  Loss: 0.1742  Acc@1: 68.7500 (69.5220)  Acc@5: 100.0000 (97.6249)  time: 0.3436  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [1280/3750]  eta: 0:14:12  Lr: 0.030000  Loss: 0.2508  Acc@1: 68.7500 (69.4916)  Acc@5: 100.0000 (97.6239)  time: 0.3427  data: 0.0002  max mem: 2502
Train: Epoch[3/5]  [1290/3750]  eta: 0:14:08  Lr: 0.030000  Loss: 0.2352  Acc@1: 62.5000 (69.4568)  Acc@5: 100.0000 (97.6230)  time: 0.3426  data: 0.0002  max mem: 2502
Train: Epoch[3/5]  [1300/3750]  eta: 0:14:05  Lr: 0.030000  Loss: 0.3698  Acc@1: 62.5000 (69.3889)  Acc@5: 100.0000 (97.5980)  time: 0.3427  data: 0.0002  max mem: 2502
Train: Epoch[3/5]  [1310/3750]  eta: 0:14:01  Lr: 0.030000  Loss: 0.2842  Acc@1: 62.5000 (69.3841)  Acc@5: 93.7500 (97.5782)  time: 0.3428  data: 0.0002  max mem: 2502
Train: Epoch[3/5]  [1320/3750]  eta: 0:13:58  Lr: 0.030000  Loss: 0.0554  Acc@1: 75.0000 (69.4218)  Acc@5: 100.0000 (97.5871)  time: 0.3443  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [1330/3750]  eta: 0:13:54  Lr: 0.030000  Loss: 0.0349  Acc@1: 75.0000 (69.4731)  Acc@5: 100.0000 (97.6052)  time: 0.3457  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [1340/3750]  eta: 0:13:51  Lr: 0.030000  Loss: 0.0729  Acc@1: 68.7500 (69.4584)  Acc@5: 100.0000 (97.5904)  time: 0.3450  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [1350/3750]  eta: 0:13:47  Lr: 0.030000  Loss: 0.0314  Acc@1: 68.7500 (69.4254)  Acc@5: 100.0000 (97.6036)  time: 0.3448  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [1360/3750]  eta: 0:13:44  Lr: 0.030000  Loss: 0.0055  Acc@1: 68.7500 (69.4296)  Acc@5: 100.0000 (97.5983)  time: 0.3447  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [1370/3750]  eta: 0:13:40  Lr: 0.030000  Loss: -0.1585  Acc@1: 68.7500 (69.4657)  Acc@5: 100.0000 (97.5976)  time: 0.3459  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [1380/3750]  eta: 0:13:37  Lr: 0.030000  Loss: 0.1284  Acc@1: 75.0000 (69.4334)  Acc@5: 100.0000 (97.5923)  time: 0.3460  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [1390/3750]  eta: 0:13:34  Lr: 0.030000  Loss: 0.2452  Acc@1: 68.7500 (69.4419)  Acc@5: 100.0000 (97.5917)  time: 0.3455  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [1400/3750]  eta: 0:13:30  Lr: 0.030000  Loss: -0.0045  Acc@1: 68.7500 (69.4504)  Acc@5: 100.0000 (97.5955)  time: 0.3453  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [1410/3750]  eta: 0:13:27  Lr: 0.030000  Loss: 0.2543  Acc@1: 68.7500 (69.4011)  Acc@5: 100.0000 (97.6081)  time: 0.3447  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [1420/3750]  eta: 0:13:23  Lr: 0.030000  Loss: 0.0714  Acc@1: 62.5000 (69.3702)  Acc@5: 100.0000 (97.5985)  time: 0.3445  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [1430/3750]  eta: 0:13:20  Lr: 0.030000  Loss: 0.0645  Acc@1: 62.5000 (69.3702)  Acc@5: 93.7500 (97.5847)  time: 0.3442  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [1440/3750]  eta: 0:13:16  Lr: 0.030000  Loss: 0.0759  Acc@1: 68.7500 (69.4093)  Acc@5: 93.7500 (97.5841)  time: 0.3441  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [1450/3750]  eta: 0:13:13  Lr: 0.030000  Loss: 0.1285  Acc@1: 68.7500 (69.3875)  Acc@5: 93.7500 (97.5620)  time: 0.3439  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [1460/3750]  eta: 0:13:09  Lr: 0.030000  Loss: 0.2505  Acc@1: 62.5000 (69.3532)  Acc@5: 100.0000 (97.5702)  time: 0.3439  data: 0.0002  max mem: 2502
Train: Epoch[3/5]  [1470/3750]  eta: 0:13:06  Lr: 0.030000  Loss: 0.1911  Acc@1: 75.0000 (69.3831)  Acc@5: 100.0000 (97.5697)  time: 0.3430  data: 0.0002  max mem: 2502
Train: Epoch[3/5]  [1480/3750]  eta: 0:13:02  Lr: 0.030000  Loss: 0.2135  Acc@1: 75.0000 (69.3535)  Acc@5: 100.0000 (97.5650)  time: 0.3423  data: 0.0002  max mem: 2502
Train: Epoch[3/5]  [1490/3750]  eta: 0:12:59  Lr: 0.030000  Loss: 0.0409  Acc@1: 62.5000 (69.3452)  Acc@5: 100.0000 (97.5604)  time: 0.3430  data: 0.0002  max mem: 2502
Train: Epoch[3/5]  [1500/3750]  eta: 0:12:55  Lr: 0.030000  Loss: -0.1895  Acc@1: 75.0000 (69.4037)  Acc@5: 100.0000 (97.5641)  time: 0.3446  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [1510/3750]  eta: 0:12:52  Lr: 0.030000  Loss: 0.1892  Acc@1: 75.0000 (69.4159)  Acc@5: 100.0000 (97.5678)  time: 0.3457  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [1520/3750]  eta: 0:12:49  Lr: 0.030000  Loss: 0.0515  Acc@1: 68.7500 (69.4157)  Acc@5: 100.0000 (97.5756)  time: 0.3449  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [1530/3750]  eta: 0:12:45  Lr: 0.030000  Loss: -0.0574  Acc@1: 68.7500 (69.4154)  Acc@5: 100.0000 (97.5833)  time: 0.3450  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [1540/3750]  eta: 0:12:42  Lr: 0.030000  Loss: 0.0128  Acc@1: 68.7500 (69.4314)  Acc@5: 100.0000 (97.5706)  time: 0.3451  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [1550/3750]  eta: 0:12:38  Lr: 0.030000  Loss: 0.2808  Acc@1: 68.7500 (69.4350)  Acc@5: 93.7500 (97.5621)  time: 0.3457  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [1560/3750]  eta: 0:12:35  Lr: 0.030000  Loss: -0.0636  Acc@1: 62.5000 (69.4066)  Acc@5: 100.0000 (97.5537)  time: 0.3455  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [1570/3750]  eta: 0:12:31  Lr: 0.030000  Loss: 0.5507  Acc@1: 62.5000 (69.3945)  Acc@5: 100.0000 (97.5454)  time: 0.3443  data: 0.0002  max mem: 2502
Train: Epoch[3/5]  [1580/3750]  eta: 0:12:28  Lr: 0.030000  Loss: -0.1077  Acc@1: 68.7500 (69.3746)  Acc@5: 100.0000 (97.5490)  time: 0.3439  data: 0.0002  max mem: 2502
Train: Epoch[3/5]  [1590/3750]  eta: 0:12:24  Lr: 0.030000  Loss: 0.2963  Acc@1: 62.5000 (69.3746)  Acc@5: 100.0000 (97.5487)  time: 0.3432  data: 0.0002  max mem: 2502
Train: Epoch[3/5]  [1600/3750]  eta: 0:12:21  Lr: 0.030000  Loss: -0.1667  Acc@1: 68.7500 (69.3980)  Acc@5: 100.0000 (97.5484)  time: 0.3427  data: 0.0002  max mem: 2502
Train: Epoch[3/5]  [1610/3750]  eta: 0:12:17  Lr: 0.030000  Loss: 0.1177  Acc@1: 75.0000 (69.4134)  Acc@5: 100.0000 (97.5597)  time: 0.3435  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [1620/3750]  eta: 0:12:14  Lr: 0.030000  Loss: 0.1133  Acc@1: 75.0000 (69.4247)  Acc@5: 100.0000 (97.5671)  time: 0.3444  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [1630/3750]  eta: 0:12:11  Lr: 0.030000  Loss: 0.0333  Acc@1: 68.7500 (69.4129)  Acc@5: 100.0000 (97.5667)  time: 0.3461  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [1640/3750]  eta: 0:12:07  Lr: 0.030000  Loss: 0.0636  Acc@1: 68.7500 (69.4279)  Acc@5: 100.0000 (97.5625)  time: 0.3457  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [1650/3750]  eta: 0:12:04  Lr: 0.030000  Loss: -0.1346  Acc@1: 81.2500 (69.4882)  Acc@5: 100.0000 (97.5621)  time: 0.3437  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [1660/3750]  eta: 0:12:00  Lr: 0.030000  Loss: -0.1062  Acc@1: 75.0000 (69.5251)  Acc@5: 100.0000 (97.5617)  time: 0.3435  data: 0.0002  max mem: 2502
Train: Epoch[3/5]  [1670/3750]  eta: 0:11:57  Lr: 0.030000  Loss: -0.0058  Acc@1: 75.0000 (69.5429)  Acc@5: 100.0000 (97.5576)  time: 0.3437  data: 0.0002  max mem: 2502
Train: Epoch[3/5]  [1680/3750]  eta: 0:11:53  Lr: 0.030000  Loss: 0.2068  Acc@1: 75.0000 (69.5345)  Acc@5: 100.0000 (97.5610)  time: 0.3437  data: 0.0002  max mem: 2502
Train: Epoch[3/5]  [1690/3750]  eta: 0:11:50  Lr: 0.030000  Loss: -0.0193  Acc@1: 68.7500 (69.5336)  Acc@5: 100.0000 (97.5643)  time: 0.3459  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [1700/3750]  eta: 0:11:46  Lr: 0.030000  Loss: 0.1765  Acc@1: 68.7500 (69.5437)  Acc@5: 100.0000 (97.5676)  time: 0.3466  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [1710/3750]  eta: 0:11:43  Lr: 0.030000  Loss: -0.2674  Acc@1: 68.7500 (69.5427)  Acc@5: 100.0000 (97.5709)  time: 0.3450  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [1720/3750]  eta: 0:11:40  Lr: 0.030000  Loss: -0.0524  Acc@1: 75.0000 (69.5925)  Acc@5: 100.0000 (97.5668)  time: 0.3453  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [1730/3750]  eta: 0:11:36  Lr: 0.030000  Loss: 0.1567  Acc@1: 75.0000 (69.6057)  Acc@5: 100.0000 (97.5664)  time: 0.3451  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [1740/3750]  eta: 0:11:33  Lr: 0.030000  Loss: 0.0093  Acc@1: 75.0000 (69.6188)  Acc@5: 100.0000 (97.5696)  time: 0.3451  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [1750/3750]  eta: 0:11:29  Lr: 0.030000  Loss: 0.1040  Acc@1: 68.7500 (69.6102)  Acc@5: 100.0000 (97.5657)  time: 0.3454  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [1760/3750]  eta: 0:11:26  Lr: 0.030000  Loss: -0.0137  Acc@1: 68.7500 (69.5982)  Acc@5: 100.0000 (97.5760)  time: 0.3446  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [1770/3750]  eta: 0:11:22  Lr: 0.030000  Loss: -0.0982  Acc@1: 75.0000 (69.6005)  Acc@5: 100.0000 (97.5755)  time: 0.3433  data: 0.0002  max mem: 2502
Train: Epoch[3/5]  [1780/3750]  eta: 0:11:19  Lr: 0.030000  Loss: -0.3038  Acc@1: 75.0000 (69.6133)  Acc@5: 93.7500 (97.5681)  time: 0.3433  data: 0.0002  max mem: 2502
Train: Epoch[3/5]  [1790/3750]  eta: 0:11:15  Lr: 0.030000  Loss: 0.0584  Acc@1: 68.7500 (69.6085)  Acc@5: 100.0000 (97.5712)  time: 0.3439  data: 0.0002  max mem: 2502
Train: Epoch[3/5]  [1800/3750]  eta: 0:11:12  Lr: 0.030000  Loss: -0.0592  Acc@1: 68.7500 (69.6141)  Acc@5: 100.0000 (97.5743)  time: 0.3449  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [1810/3750]  eta: 0:11:08  Lr: 0.030000  Loss: -0.0000  Acc@1: 75.0000 (69.6300)  Acc@5: 100.0000 (97.5773)  time: 0.3454  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [1820/3750]  eta: 0:11:05  Lr: 0.030000  Loss: 0.0225  Acc@1: 68.7500 (69.6149)  Acc@5: 100.0000 (97.5769)  time: 0.3460  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [1830/3750]  eta: 0:11:02  Lr: 0.030000  Loss: -0.0409  Acc@1: 68.7500 (69.6204)  Acc@5: 100.0000 (97.5765)  time: 0.3458  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [1840/3750]  eta: 0:10:58  Lr: 0.030000  Loss: 0.2172  Acc@1: 62.5000 (69.5648)  Acc@5: 93.7500 (97.5625)  time: 0.3447  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [1850/3750]  eta: 0:10:55  Lr: 0.030000  Loss: -0.1631  Acc@1: 62.5000 (69.5469)  Acc@5: 93.7500 (97.5554)  time: 0.3447  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [1860/3750]  eta: 0:10:51  Lr: 0.030000  Loss: -0.1304  Acc@1: 68.7500 (69.5560)  Acc@5: 100.0000 (97.5551)  time: 0.3450  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [1870/3750]  eta: 0:10:48  Lr: 0.030000  Loss: 0.1037  Acc@1: 75.0000 (69.5684)  Acc@5: 100.0000 (97.5548)  time: 0.3450  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [1880/3750]  eta: 0:10:44  Lr: 0.030000  Loss: 0.3639  Acc@1: 75.0000 (69.5840)  Acc@5: 100.0000 (97.5445)  time: 0.3450  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [1890/3750]  eta: 0:10:41  Lr: 0.030000  Loss: 0.2080  Acc@1: 75.0000 (69.6027)  Acc@5: 93.7500 (97.5344)  time: 0.3451  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [1900/3750]  eta: 0:10:37  Lr: 0.030000  Loss: -0.1182  Acc@1: 75.0000 (69.6278)  Acc@5: 93.7500 (97.5375)  time: 0.3457  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [1910/3750]  eta: 0:10:34  Lr: 0.030000  Loss: 0.0786  Acc@1: 75.0000 (69.6036)  Acc@5: 100.0000 (97.5275)  time: 0.3446  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [1920/3750]  eta: 0:10:31  Lr: 0.030000  Loss: 0.1455  Acc@1: 75.0000 (69.6415)  Acc@5: 100.0000 (97.5306)  time: 0.3432  data: 0.0002  max mem: 2502
Train: Epoch[3/5]  [1930/3750]  eta: 0:10:27  Lr: 0.030000  Loss: -0.0291  Acc@1: 75.0000 (69.6207)  Acc@5: 100.0000 (97.5175)  time: 0.3430  data: 0.0002  max mem: 2502
Train: Epoch[3/5]  [1940/3750]  eta: 0:10:24  Lr: 0.030000  Loss: 0.1698  Acc@1: 68.7500 (69.6130)  Acc@5: 93.7500 (97.5077)  time: 0.3431  data: 0.0002  max mem: 2502
Train: Epoch[3/5]  [1950/3750]  eta: 0:10:20  Lr: 0.030000  Loss: -0.1432  Acc@1: 68.7500 (69.6406)  Acc@5: 93.7500 (97.5045)  time: 0.3432  data: 0.0002  max mem: 2502
Train: Epoch[3/5]  [1960/3750]  eta: 0:10:17  Lr: 0.030000  Loss: 0.0783  Acc@1: 75.0000 (69.6456)  Acc@5: 100.0000 (97.5172)  time: 0.3430  data: 0.0002  max mem: 2502
Train: Epoch[3/5]  [1970/3750]  eta: 0:10:13  Lr: 0.030000  Loss: 0.0069  Acc@1: 75.0000 (69.6664)  Acc@5: 100.0000 (97.5108)  time: 0.3431  data: 0.0002  max mem: 2502
Train: Epoch[3/5]  [1980/3750]  eta: 0:10:10  Lr: 0.030000  Loss: 0.0621  Acc@1: 68.7500 (69.6586)  Acc@5: 100.0000 (97.5076)  time: 0.3444  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [1990/3750]  eta: 0:10:06  Lr: 0.030000  Loss: 0.0151  Acc@1: 62.5000 (69.6258)  Acc@5: 100.0000 (97.5138)  time: 0.3451  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [2000/3750]  eta: 0:10:03  Lr: 0.030000  Loss: 0.1902  Acc@1: 62.5000 (69.6214)  Acc@5: 100.0000 (97.5044)  time: 0.3451  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [2010/3750]  eta: 0:09:59  Lr: 0.030000  Loss: 0.1641  Acc@1: 75.0000 (69.6513)  Acc@5: 100.0000 (97.5106)  time: 0.3450  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [2020/3750]  eta: 0:09:56  Lr: 0.030000  Loss: 0.0444  Acc@1: 68.7500 (69.6252)  Acc@5: 100.0000 (97.5105)  time: 0.3446  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [2030/3750]  eta: 0:09:53  Lr: 0.030000  Loss: 0.0359  Acc@1: 68.7500 (69.6209)  Acc@5: 100.0000 (97.5197)  time: 0.3449  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [2040/3750]  eta: 0:09:49  Lr: 0.030000  Loss: -0.0587  Acc@1: 62.5000 (69.5829)  Acc@5: 100.0000 (97.5227)  time: 0.3446  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [2050/3750]  eta: 0:09:46  Lr: 0.030000  Loss: -0.0685  Acc@1: 62.5000 (69.6063)  Acc@5: 100.0000 (97.5195)  time: 0.3445  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [2060/3750]  eta: 0:09:42  Lr: 0.030000  Loss: -0.0634  Acc@1: 68.7500 (69.5839)  Acc@5: 100.0000 (97.5224)  time: 0.3443  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [2070/3750]  eta: 0:09:39  Lr: 0.030000  Loss: 0.2188  Acc@1: 62.5000 (69.5709)  Acc@5: 100.0000 (97.5163)  time: 0.3450  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [2080/3750]  eta: 0:09:35  Lr: 0.030000  Loss: -0.1722  Acc@1: 75.0000 (69.5969)  Acc@5: 100.0000 (97.5192)  time: 0.3457  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [2090/3750]  eta: 0:09:32  Lr: 0.030000  Loss: 0.1056  Acc@1: 75.0000 (69.5989)  Acc@5: 100.0000 (97.5161)  time: 0.3468  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [2100/3750]  eta: 0:09:28  Lr: 0.030000  Loss: 0.1405  Acc@1: 62.5000 (69.5621)  Acc@5: 100.0000 (97.5131)  time: 0.3465  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [2110/3750]  eta: 0:09:25  Lr: 0.030000  Loss: -0.2820  Acc@1: 68.7500 (69.5997)  Acc@5: 100.0000 (97.5160)  time: 0.3443  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [2120/3750]  eta: 0:09:22  Lr: 0.030000  Loss: 0.0928  Acc@1: 68.7500 (69.5869)  Acc@5: 100.0000 (97.5159)  time: 0.3442  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [2130/3750]  eta: 0:09:18  Lr: 0.030000  Loss: 0.1525  Acc@1: 68.7500 (69.6005)  Acc@5: 100.0000 (97.5246)  time: 0.3446  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [2140/3750]  eta: 0:09:15  Lr: 0.030000  Loss: -0.0739  Acc@1: 68.7500 (69.6112)  Acc@5: 100.0000 (97.5216)  time: 0.3450  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [2150/3750]  eta: 0:09:11  Lr: 0.030000  Loss: 0.2326  Acc@1: 68.7500 (69.5868)  Acc@5: 100.0000 (97.5157)  time: 0.3448  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [2160/3750]  eta: 0:09:08  Lr: 0.030000  Loss: -0.0631  Acc@1: 68.7500 (69.5858)  Acc@5: 100.0000 (97.5156)  time: 0.3445  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [2170/3750]  eta: 0:09:04  Lr: 0.030000  Loss: 0.1503  Acc@1: 68.7500 (69.5762)  Acc@5: 100.0000 (97.5155)  time: 0.3459  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [2180/3750]  eta: 0:09:01  Lr: 0.030000  Loss: 0.0401  Acc@1: 68.7500 (69.5925)  Acc@5: 100.0000 (97.5126)  time: 0.3447  data: 0.0002  max mem: 2502
Train: Epoch[3/5]  [2190/3750]  eta: 0:08:57  Lr: 0.030000  Loss: 0.0834  Acc@1: 68.7500 (69.5715)  Acc@5: 100.0000 (97.5097)  time: 0.3424  data: 0.0002  max mem: 2502
Train: Epoch[3/5]  [2200/3750]  eta: 0:08:54  Lr: 0.030000  Loss: -0.1112  Acc@1: 68.7500 (69.5820)  Acc@5: 100.0000 (97.5153)  time: 0.3424  data: 0.0002  max mem: 2502
Train: Epoch[3/5]  [2210/3750]  eta: 0:08:50  Lr: 0.030000  Loss: 0.0523  Acc@1: 68.7500 (69.5782)  Acc@5: 100.0000 (97.5011)  time: 0.3423  data: 0.0002  max mem: 2502
Train: Epoch[3/5]  [2220/3750]  eta: 0:08:47  Lr: 0.030000  Loss: 0.0976  Acc@1: 68.7500 (69.5914)  Acc@5: 93.7500 (97.4983)  time: 0.3424  data: 0.0002  max mem: 2502
Train: Epoch[3/5]  [2230/3750]  eta: 0:08:44  Lr: 0.030000  Loss: 0.1144  Acc@1: 68.7500 (69.5904)  Acc@5: 100.0000 (97.5067)  time: 0.3425  data: 0.0002  max mem: 2502
Train: Epoch[3/5]  [2240/3750]  eta: 0:08:40  Lr: 0.030000  Loss: -0.0031  Acc@1: 68.7500 (69.5672)  Acc@5: 100.0000 (97.5095)  time: 0.3424  data: 0.0002  max mem: 2502
Train: Epoch[3/5]  [2250/3750]  eta: 0:08:37  Lr: 0.030000  Loss: 0.1902  Acc@1: 68.7500 (69.5691)  Acc@5: 100.0000 (97.5178)  time: 0.3425  data: 0.0002  max mem: 2502
Train: Epoch[3/5]  [2260/3750]  eta: 0:08:33  Lr: 0.030000  Loss: 0.1166  Acc@1: 62.5000 (69.5544)  Acc@5: 100.0000 (97.5177)  time: 0.3425  data: 0.0002  max mem: 2502
Train: Epoch[3/5]  [2270/3750]  eta: 0:08:30  Lr: 0.030000  Loss: 0.1267  Acc@1: 62.5000 (69.5454)  Acc@5: 100.0000 (97.5204)  time: 0.3438  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [2280/3750]  eta: 0:08:26  Lr: 0.030000  Loss: 0.0390  Acc@1: 68.7500 (69.5309)  Acc@5: 100.0000 (97.5175)  time: 0.3449  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [2290/3750]  eta: 0:08:23  Lr: 0.030000  Loss: 0.2075  Acc@1: 68.7500 (69.5302)  Acc@5: 100.0000 (97.5256)  time: 0.3453  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [2300/3750]  eta: 0:08:19  Lr: 0.030000  Loss: -0.0535  Acc@1: 68.7500 (69.5431)  Acc@5: 100.0000 (97.5228)  time: 0.3458  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [2310/3750]  eta: 0:08:16  Lr: 0.030000  Loss: -0.0236  Acc@1: 75.0000 (69.5451)  Acc@5: 100.0000 (97.5227)  time: 0.3452  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [2320/3750]  eta: 0:08:12  Lr: 0.030000  Loss: 0.0731  Acc@1: 68.7500 (69.5632)  Acc@5: 100.0000 (97.5307)  time: 0.3454  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [2330/3750]  eta: 0:08:09  Lr: 0.030000  Loss: 0.1115  Acc@1: 68.7500 (69.5463)  Acc@5: 100.0000 (97.5332)  time: 0.3451  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [2340/3750]  eta: 0:08:06  Lr: 0.030000  Loss: -0.0802  Acc@1: 75.0000 (69.5696)  Acc@5: 100.0000 (97.5438)  time: 0.3453  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [2350/3750]  eta: 0:08:02  Lr: 0.030000  Loss: 0.2374  Acc@1: 75.0000 (69.5635)  Acc@5: 100.0000 (97.5463)  time: 0.3461  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [2360/3750]  eta: 0:07:59  Lr: 0.030000  Loss: 0.0162  Acc@1: 68.7500 (69.5759)  Acc@5: 100.0000 (97.5434)  time: 0.3460  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [2370/3750]  eta: 0:07:55  Lr: 0.030000  Loss: 0.0753  Acc@1: 68.7500 (69.5883)  Acc@5: 100.0000 (97.5406)  time: 0.3451  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [2380/3750]  eta: 0:07:52  Lr: 0.030000  Loss: -0.0022  Acc@1: 68.7500 (69.5769)  Acc@5: 100.0000 (97.5378)  time: 0.3452  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [2390/3750]  eta: 0:07:48  Lr: 0.030000  Loss: 0.0771  Acc@1: 68.7500 (69.5812)  Acc@5: 100.0000 (97.5376)  time: 0.3461  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [2400/3750]  eta: 0:07:45  Lr: 0.030000  Loss: -0.0704  Acc@1: 75.0000 (69.6168)  Acc@5: 100.0000 (97.5401)  time: 0.3476  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [2410/3750]  eta: 0:07:42  Lr: 0.030000  Loss: 0.3979  Acc@1: 75.0000 (69.6080)  Acc@5: 100.0000 (97.5399)  time: 0.3477  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [2420/3750]  eta: 0:07:38  Lr: 0.030000  Loss: 0.0641  Acc@1: 75.0000 (69.6226)  Acc@5: 100.0000 (97.5398)  time: 0.3470  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [2430/3750]  eta: 0:07:35  Lr: 0.030000  Loss: -0.1246  Acc@1: 75.0000 (69.6138)  Acc@5: 100.0000 (97.5396)  time: 0.3461  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [2440/3750]  eta: 0:07:31  Lr: 0.030000  Loss: -0.0579  Acc@1: 68.7500 (69.6180)  Acc@5: 100.0000 (97.5471)  time: 0.3445  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [2450/3750]  eta: 0:07:28  Lr: 0.030000  Loss: -0.0875  Acc@1: 68.7500 (69.5940)  Acc@5: 100.0000 (97.5418)  time: 0.3448  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [2460/3750]  eta: 0:07:24  Lr: 0.030000  Loss: -0.1279  Acc@1: 68.7500 (69.6109)  Acc@5: 100.0000 (97.5493)  time: 0.3450  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [2470/3750]  eta: 0:07:21  Lr: 0.030000  Loss: -0.3441  Acc@1: 75.0000 (69.6176)  Acc@5: 100.0000 (97.5491)  time: 0.3450  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [2480/3750]  eta: 0:07:17  Lr: 0.030000  Loss: -0.0238  Acc@1: 75.0000 (69.6569)  Acc@5: 100.0000 (97.5514)  time: 0.3446  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [2490/3750]  eta: 0:07:14  Lr: 0.030000  Loss: 0.0604  Acc@1: 68.7500 (69.6558)  Acc@5: 100.0000 (97.5562)  time: 0.3445  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [2500/3750]  eta: 0:07:11  Lr: 0.030000  Loss: 0.1583  Acc@1: 68.7500 (69.6521)  Acc@5: 100.0000 (97.5610)  time: 0.3459  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [2510/3750]  eta: 0:07:07  Lr: 0.030000  Loss: -0.1315  Acc@1: 75.0000 (69.6759)  Acc@5: 100.0000 (97.5632)  time: 0.3447  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [2520/3750]  eta: 0:07:04  Lr: 0.030000  Loss: -0.0425  Acc@1: 75.0000 (69.6772)  Acc@5: 100.0000 (97.5655)  time: 0.3423  data: 0.0002  max mem: 2502
Train: Epoch[3/5]  [2530/3750]  eta: 0:07:00  Lr: 0.030000  Loss: 0.0297  Acc@1: 75.0000 (69.6785)  Acc@5: 100.0000 (97.5677)  time: 0.3425  data: 0.0002  max mem: 2502
Train: Epoch[3/5]  [2540/3750]  eta: 0:06:57  Lr: 0.030000  Loss: -0.2710  Acc@1: 68.7500 (69.6798)  Acc@5: 100.0000 (97.5748)  time: 0.3425  data: 0.0002  max mem: 2502
Train: Epoch[3/5]  [2550/3750]  eta: 0:06:53  Lr: 0.030000  Loss: -0.2357  Acc@1: 62.5000 (69.6614)  Acc@5: 100.0000 (97.5769)  time: 0.3423  data: 0.0002  max mem: 2502
Train: Epoch[3/5]  [2560/3750]  eta: 0:06:50  Lr: 0.030000  Loss: 0.1753  Acc@1: 62.5000 (69.6505)  Acc@5: 100.0000 (97.5742)  time: 0.3421  data: 0.0002  max mem: 2502
Train: Epoch[3/5]  [2570/3750]  eta: 0:06:46  Lr: 0.030000  Loss: 0.1114  Acc@1: 68.7500 (69.6567)  Acc@5: 100.0000 (97.5812)  time: 0.3424  data: 0.0002  max mem: 2502
Train: Epoch[3/5]  [2580/3750]  eta: 0:06:43  Lr: 0.030000  Loss: -0.1558  Acc@1: 75.0000 (69.6678)  Acc@5: 100.0000 (97.5857)  time: 0.3425  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [2590/3750]  eta: 0:06:39  Lr: 0.030000  Loss: 0.0302  Acc@1: 75.0000 (69.6546)  Acc@5: 100.0000 (97.5830)  time: 0.3429  data: 0.0002  max mem: 2502
Train: Epoch[3/5]  [2600/3750]  eta: 0:06:36  Lr: 0.030000  Loss: 0.2287  Acc@1: 62.5000 (69.6463)  Acc@5: 100.0000 (97.5803)  time: 0.3439  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [2610/3750]  eta: 0:06:32  Lr: 0.030000  Loss: 0.1536  Acc@1: 75.0000 (69.6644)  Acc@5: 100.0000 (97.5847)  time: 0.3451  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [2620/3750]  eta: 0:06:29  Lr: 0.030000  Loss: 0.2302  Acc@1: 68.7500 (69.6585)  Acc@5: 100.0000 (97.5773)  time: 0.3456  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [2630/3750]  eta: 0:06:26  Lr: 0.030000  Loss: -0.1258  Acc@1: 68.7500 (69.6812)  Acc@5: 100.0000 (97.5722)  time: 0.3446  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [2640/3750]  eta: 0:06:22  Lr: 0.030000  Loss: 0.1358  Acc@1: 75.0000 (69.6895)  Acc@5: 100.0000 (97.5719)  time: 0.3446  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [2650/3750]  eta: 0:06:19  Lr: 0.030000  Loss: 0.0478  Acc@1: 68.7500 (69.6647)  Acc@5: 100.0000 (97.5622)  time: 0.3456  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [2660/3750]  eta: 0:06:15  Lr: 0.030000  Loss: 0.2707  Acc@1: 68.7500 (69.6566)  Acc@5: 100.0000 (97.5644)  time: 0.3454  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [2670/3750]  eta: 0:06:12  Lr: 0.030000  Loss: -0.1249  Acc@1: 68.7500 (69.6205)  Acc@5: 100.0000 (97.5594)  time: 0.3450  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [2680/3750]  eta: 0:06:08  Lr: 0.030000  Loss: -0.3954  Acc@1: 68.7500 (69.6452)  Acc@5: 100.0000 (97.5592)  time: 0.3447  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [2690/3750]  eta: 0:06:05  Lr: 0.030000  Loss: -0.0571  Acc@1: 75.0000 (69.6651)  Acc@5: 100.0000 (97.5590)  time: 0.3445  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [2700/3750]  eta: 0:06:01  Lr: 0.030000  Loss: 0.2233  Acc@1: 68.7500 (69.6548)  Acc@5: 100.0000 (97.5611)  time: 0.3455  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [2710/3750]  eta: 0:05:58  Lr: 0.030000  Loss: -0.1625  Acc@1: 68.7500 (69.6560)  Acc@5: 100.0000 (97.5609)  time: 0.3469  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [2720/3750]  eta: 0:05:55  Lr: 0.030000  Loss: 0.1686  Acc@1: 62.5000 (69.6297)  Acc@5: 100.0000 (97.5629)  time: 0.3459  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [2730/3750]  eta: 0:05:51  Lr: 0.030000  Loss: -0.0076  Acc@1: 68.7500 (69.6585)  Acc@5: 100.0000 (97.5673)  time: 0.3448  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [2740/3750]  eta: 0:05:48  Lr: 0.030000  Loss: -0.1916  Acc@1: 75.0000 (69.6712)  Acc@5: 100.0000 (97.5648)  time: 0.3458  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [2750/3750]  eta: 0:05:44  Lr: 0.030000  Loss: 0.3928  Acc@1: 75.0000 (69.6883)  Acc@5: 100.0000 (97.5623)  time: 0.3511  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [2760/3750]  eta: 0:05:41  Lr: 0.030000  Loss: -0.1774  Acc@1: 75.0000 (69.7075)  Acc@5: 100.0000 (97.5666)  time: 0.3501  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [2770/3750]  eta: 0:05:37  Lr: 0.030000  Loss: 0.1141  Acc@1: 75.0000 (69.7154)  Acc@5: 100.0000 (97.5708)  time: 0.3442  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [2780/3750]  eta: 0:05:34  Lr: 0.030000  Loss: -0.0118  Acc@1: 75.0000 (69.7231)  Acc@5: 100.0000 (97.5728)  time: 0.3442  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [2790/3750]  eta: 0:05:30  Lr: 0.030000  Loss: 0.1076  Acc@1: 75.0000 (69.7532)  Acc@5: 100.0000 (97.5748)  time: 0.3445  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [2800/3750]  eta: 0:05:27  Lr: 0.030000  Loss: -0.1695  Acc@1: 75.0000 (69.7653)  Acc@5: 100.0000 (97.5723)  time: 0.3442  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [2810/3750]  eta: 0:05:24  Lr: 0.030000  Loss: -0.0722  Acc@1: 75.0000 (69.7750)  Acc@5: 100.0000 (97.5787)  time: 0.3438  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [2820/3750]  eta: 0:05:20  Lr: 0.030000  Loss: 0.0271  Acc@1: 75.0000 (69.7979)  Acc@5: 100.0000 (97.5806)  time: 0.3435  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [2830/3750]  eta: 0:05:17  Lr: 0.030000  Loss: 0.3801  Acc@1: 75.0000 (69.8141)  Acc@5: 100.0000 (97.5782)  time: 0.3437  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [2840/3750]  eta: 0:05:13  Lr: 0.030000  Loss: -0.1287  Acc@1: 68.7500 (69.8060)  Acc@5: 100.0000 (97.5757)  time: 0.3461  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [2850/3750]  eta: 0:05:10  Lr: 0.030000  Loss: 0.2156  Acc@1: 62.5000 (69.7847)  Acc@5: 100.0000 (97.5776)  time: 0.3461  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [2860/3750]  eta: 0:05:06  Lr: 0.030000  Loss: 0.2912  Acc@1: 62.5000 (69.7877)  Acc@5: 100.0000 (97.5795)  time: 0.3444  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [2870/3750]  eta: 0:05:03  Lr: 0.030000  Loss: 0.1171  Acc@1: 68.7500 (69.7862)  Acc@5: 100.0000 (97.5771)  time: 0.3442  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [2880/3750]  eta: 0:04:59  Lr: 0.030000  Loss: 0.1511  Acc@1: 68.7500 (69.7891)  Acc@5: 100.0000 (97.5811)  time: 0.3440  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [2890/3750]  eta: 0:04:56  Lr: 0.030000  Loss: -0.1043  Acc@1: 68.7500 (69.7812)  Acc@5: 100.0000 (97.5852)  time: 0.3437  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [2900/3750]  eta: 0:04:53  Lr: 0.030000  Loss: -0.0833  Acc@1: 68.7500 (69.7884)  Acc@5: 100.0000 (97.5849)  time: 0.3436  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [2910/3750]  eta: 0:04:49  Lr: 0.030000  Loss: 0.0775  Acc@1: 68.7500 (69.7806)  Acc@5: 100.0000 (97.5760)  time: 0.3459  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [2920/3750]  eta: 0:04:46  Lr: 0.030000  Loss: -0.1595  Acc@1: 75.0000 (69.8070)  Acc@5: 100.0000 (97.5757)  time: 0.3466  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [2930/3750]  eta: 0:04:42  Lr: 0.030000  Loss: 0.0796  Acc@1: 68.7500 (69.7757)  Acc@5: 100.0000 (97.5776)  time: 0.3469  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [2940/3750]  eta: 0:04:39  Lr: 0.030000  Loss: 0.0766  Acc@1: 68.7500 (69.7807)  Acc@5: 100.0000 (97.5795)  time: 0.3464  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [2950/3750]  eta: 0:04:35  Lr: 0.030000  Loss: -0.0029  Acc@1: 68.7500 (69.7793)  Acc@5: 100.0000 (97.5834)  time: 0.3442  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [2960/3750]  eta: 0:04:32  Lr: 0.030000  Loss: 0.0596  Acc@1: 62.5000 (69.7505)  Acc@5: 100.0000 (97.5895)  time: 0.3441  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [2970/3750]  eta: 0:04:28  Lr: 0.030000  Loss: 0.2365  Acc@1: 62.5000 (69.7577)  Acc@5: 100.0000 (97.5871)  time: 0.3438  data: 0.0002  max mem: 2502
Train: Epoch[3/5]  [2980/3750]  eta: 0:04:25  Lr: 0.030000  Loss: -0.1691  Acc@1: 81.2500 (69.7920)  Acc@5: 100.0000 (97.5889)  time: 0.3436  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [2990/3750]  eta: 0:04:22  Lr: 0.030000  Loss: 0.2375  Acc@1: 75.0000 (69.7844)  Acc@5: 100.0000 (97.5761)  time: 0.3449  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [3000/3750]  eta: 0:04:18  Lr: 0.030000  Loss: -0.1848  Acc@1: 75.0000 (69.7913)  Acc@5: 93.7500 (97.5696)  time: 0.3457  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [3010/3750]  eta: 0:04:15  Lr: 0.030000  Loss: -0.1488  Acc@1: 68.7500 (69.7858)  Acc@5: 93.7500 (97.5652)  time: 0.3465  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [3020/3750]  eta: 0:04:11  Lr: 0.030000  Loss: 0.2646  Acc@1: 62.5000 (69.7658)  Acc@5: 100.0000 (97.5629)  time: 0.3461  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [3030/3750]  eta: 0:04:08  Lr: 0.030000  Loss: 0.0314  Acc@1: 68.7500 (69.7707)  Acc@5: 100.0000 (97.5647)  time: 0.3446  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [3040/3750]  eta: 0:04:04  Lr: 0.030000  Loss: -0.1142  Acc@1: 68.7500 (69.7530)  Acc@5: 100.0000 (97.5625)  time: 0.3449  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [3050/3750]  eta: 0:04:01  Lr: 0.030000  Loss: 0.0864  Acc@1: 62.5000 (69.7497)  Acc@5: 93.7500 (97.5582)  time: 0.3457  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [3060/3750]  eta: 0:03:57  Lr: 0.030000  Loss: -0.0431  Acc@1: 75.0000 (69.7627)  Acc@5: 100.0000 (97.5621)  time: 0.3450  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [3070/3750]  eta: 0:03:54  Lr: 0.030000  Loss: -0.0124  Acc@1: 75.0000 (69.7676)  Acc@5: 100.0000 (97.5639)  time: 0.3444  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [3080/3750]  eta: 0:03:51  Lr: 0.030000  Loss: -0.1336  Acc@1: 68.7500 (69.7724)  Acc@5: 100.0000 (97.5657)  time: 0.3455  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [3090/3750]  eta: 0:03:47  Lr: 0.030000  Loss: 0.0612  Acc@1: 68.7500 (69.7812)  Acc@5: 100.0000 (97.5696)  time: 0.3463  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [3100/3750]  eta: 0:03:44  Lr: 0.030000  Loss: -0.1711  Acc@1: 68.7500 (69.7900)  Acc@5: 100.0000 (97.5774)  time: 0.3458  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [3110/3750]  eta: 0:03:40  Lr: 0.030000  Loss: 0.2726  Acc@1: 68.7500 (69.7826)  Acc@5: 100.0000 (97.5771)  time: 0.3450  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [3120/3750]  eta: 0:03:37  Lr: 0.030000  Loss: -0.0615  Acc@1: 62.5000 (69.7913)  Acc@5: 100.0000 (97.5809)  time: 0.3460  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [3130/3750]  eta: 0:03:33  Lr: 0.030000  Loss: 0.2991  Acc@1: 68.7500 (69.7900)  Acc@5: 100.0000 (97.5767)  time: 0.3477  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [3140/3750]  eta: 0:03:30  Lr: 0.030000  Loss: -0.0960  Acc@1: 68.7500 (69.7887)  Acc@5: 93.7500 (97.5665)  time: 0.3472  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [3150/3750]  eta: 0:03:26  Lr: 0.030000  Loss: -0.1449  Acc@1: 68.7500 (69.7973)  Acc@5: 100.0000 (97.5742)  time: 0.3497  data: 0.0006  max mem: 2502
Train: Epoch[3/5]  [3160/3750]  eta: 0:03:23  Lr: 0.030000  Loss: -0.0615  Acc@1: 75.0000 (69.8137)  Acc@5: 100.0000 (97.5799)  time: 0.3509  data: 0.0007  max mem: 2502
Train: Epoch[3/5]  [3170/3750]  eta: 0:03:20  Lr: 0.030000  Loss: 0.1372  Acc@1: 68.7500 (69.8104)  Acc@5: 100.0000 (97.5816)  time: 0.3503  data: 0.0007  max mem: 2502
Train: Epoch[3/5]  [3180/3750]  eta: 0:03:16  Lr: 0.030000  Loss: -0.3550  Acc@1: 68.7500 (69.8149)  Acc@5: 100.0000 (97.5833)  time: 0.3494  data: 0.0006  max mem: 2502
Train: Epoch[3/5]  [3190/3750]  eta: 0:03:13  Lr: 0.030000  Loss: 0.2508  Acc@1: 68.7500 (69.8096)  Acc@5: 100.0000 (97.5830)  time: 0.3473  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [3200/3750]  eta: 0:03:09  Lr: 0.030000  Loss: 0.1772  Acc@1: 62.5000 (69.8044)  Acc@5: 100.0000 (97.5789)  time: 0.3488  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [3210/3750]  eta: 0:03:06  Lr: 0.030000  Loss: -0.1229  Acc@1: 68.7500 (69.8225)  Acc@5: 100.0000 (97.5767)  time: 0.3485  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [3220/3750]  eta: 0:03:02  Lr: 0.030000  Loss: 0.1309  Acc@1: 68.7500 (69.8269)  Acc@5: 100.0000 (97.5784)  time: 0.3467  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [3230/3750]  eta: 0:02:59  Lr: 0.030000  Loss: -0.0303  Acc@1: 68.7500 (69.8255)  Acc@5: 100.0000 (97.5762)  time: 0.3460  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [3240/3750]  eta: 0:02:55  Lr: 0.030000  Loss: -0.1588  Acc@1: 68.7500 (69.8261)  Acc@5: 100.0000 (97.5741)  time: 0.3455  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [3250/3750]  eta: 0:02:52  Lr: 0.030000  Loss: -0.0180  Acc@1: 75.0000 (69.8439)  Acc@5: 100.0000 (97.5757)  time: 0.3454  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [3260/3750]  eta: 0:02:49  Lr: 0.030000  Loss: 0.0480  Acc@1: 75.0000 (69.8616)  Acc@5: 100.0000 (97.5717)  time: 0.3459  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [3270/3750]  eta: 0:02:45  Lr: 0.030000  Loss: 0.1018  Acc@1: 75.0000 (69.8601)  Acc@5: 100.0000 (97.5734)  time: 0.3456  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [3280/3750]  eta: 0:02:42  Lr: 0.030000  Loss: -0.0963  Acc@1: 68.7500 (69.8625)  Acc@5: 100.0000 (97.5693)  time: 0.3449  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [3290/3750]  eta: 0:02:38  Lr: 0.030000  Loss: 0.4801  Acc@1: 62.5000 (69.8458)  Acc@5: 93.7500 (97.5634)  time: 0.3448  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [3300/3750]  eta: 0:02:35  Lr: 0.030000  Loss: 0.0042  Acc@1: 62.5000 (69.8292)  Acc@5: 100.0000 (97.5651)  time: 0.3447  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [3310/3750]  eta: 0:02:31  Lr: 0.030000  Loss: 0.1607  Acc@1: 68.7500 (69.8354)  Acc@5: 100.0000 (97.5668)  time: 0.3458  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [3320/3750]  eta: 0:02:28  Lr: 0.030000  Loss: -0.0558  Acc@1: 75.0000 (69.8453)  Acc@5: 100.0000 (97.5666)  time: 0.3488  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [3330/3750]  eta: 0:02:24  Lr: 0.030000  Loss: -0.1513  Acc@1: 68.7500 (69.8233)  Acc@5: 100.0000 (97.5664)  time: 0.3496  data: 0.0006  max mem: 2502
Train: Epoch[3/5]  [3340/3750]  eta: 0:02:21  Lr: 0.030000  Loss: 0.1947  Acc@1: 68.7500 (69.8331)  Acc@5: 100.0000 (97.5681)  time: 0.3476  data: 0.0006  max mem: 2502
Train: Epoch[3/5]  [3350/3750]  eta: 0:02:17  Lr: 0.030000  Loss: 0.0524  Acc@1: 68.7500 (69.8355)  Acc@5: 100.0000 (97.5642)  time: 0.3481  data: 0.0007  max mem: 2502
Train: Epoch[3/5]  [3360/3750]  eta: 0:02:14  Lr: 0.030000  Loss: 0.0475  Acc@1: 68.7500 (69.8378)  Acc@5: 100.0000 (97.5658)  time: 0.3488  data: 0.0006  max mem: 2502
Train: Epoch[3/5]  [3370/3750]  eta: 0:02:11  Lr: 0.030000  Loss: 0.0940  Acc@1: 68.7500 (69.8253)  Acc@5: 100.0000 (97.5582)  time: 0.3468  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [3380/3750]  eta: 0:02:07  Lr: 0.030000  Loss: 0.0046  Acc@1: 68.7500 (69.8092)  Acc@5: 93.7500 (97.5525)  time: 0.3455  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [3390/3750]  eta: 0:02:04  Lr: 0.030000  Loss: -0.0402  Acc@1: 68.7500 (69.8043)  Acc@5: 100.0000 (97.5542)  time: 0.3453  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [3400/3750]  eta: 0:02:00  Lr: 0.030000  Loss: 0.1348  Acc@1: 68.7500 (69.8048)  Acc@5: 100.0000 (97.5540)  time: 0.3455  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [3410/3750]  eta: 0:01:57  Lr: 0.030000  Loss: -0.1218  Acc@1: 75.0000 (69.8311)  Acc@5: 100.0000 (97.5520)  time: 0.3451  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [3420/3750]  eta: 0:01:53  Lr: 0.030000  Loss: 0.3478  Acc@1: 75.0000 (69.8242)  Acc@5: 100.0000 (97.5555)  time: 0.3453  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [3430/3750]  eta: 0:01:50  Lr: 0.030000  Loss: -0.1283  Acc@1: 68.7500 (69.8266)  Acc@5: 100.0000 (97.5517)  time: 0.3448  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [3440/3750]  eta: 0:01:46  Lr: 0.030000  Loss: -0.0601  Acc@1: 68.7500 (69.8198)  Acc@5: 100.0000 (97.5516)  time: 0.3431  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [3450/3750]  eta: 0:01:43  Lr: 0.030000  Loss: -0.1238  Acc@1: 68.7500 (69.8185)  Acc@5: 100.0000 (97.5496)  time: 0.3430  data: 0.0002  max mem: 2502
Train: Epoch[3/5]  [3460/3750]  eta: 0:01:40  Lr: 0.030000  Loss: 0.0525  Acc@1: 68.7500 (69.8191)  Acc@5: 100.0000 (97.5495)  time: 0.3430  data: 0.0002  max mem: 2502
Train: Epoch[3/5]  [3470/3750]  eta: 0:01:36  Lr: 0.030000  Loss: -0.0046  Acc@1: 75.0000 (69.8412)  Acc@5: 100.0000 (97.5547)  time: 0.3428  data: 0.0002  max mem: 2502
Train: Epoch[3/5]  [3480/3750]  eta: 0:01:33  Lr: 0.030000  Loss: 0.0985  Acc@1: 75.0000 (69.8380)  Acc@5: 100.0000 (97.5564)  time: 0.3425  data: 0.0002  max mem: 2502
Train: Epoch[3/5]  [3490/3750]  eta: 0:01:29  Lr: 0.030000  Loss: 0.0011  Acc@1: 68.7500 (69.8349)  Acc@5: 100.0000 (97.5580)  time: 0.3426  data: 0.0002  max mem: 2502
Train: Epoch[3/5]  [3500/3750]  eta: 0:01:26  Lr: 0.030000  Loss: -0.3964  Acc@1: 68.7500 (69.8497)  Acc@5: 100.0000 (97.5632)  time: 0.3428  data: 0.0002  max mem: 2502
Train: Epoch[3/5]  [3510/3750]  eta: 0:01:22  Lr: 0.030000  Loss: -0.0265  Acc@1: 68.7500 (69.8412)  Acc@5: 100.0000 (97.5630)  time: 0.3439  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [3520/3750]  eta: 0:01:19  Lr: 0.030000  Loss: -0.2103  Acc@1: 68.7500 (69.8505)  Acc@5: 100.0000 (97.5593)  time: 0.3449  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [3530/3750]  eta: 0:01:15  Lr: 0.030000  Loss: -0.0980  Acc@1: 75.0000 (69.8492)  Acc@5: 100.0000 (97.5573)  time: 0.3450  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [3540/3750]  eta: 0:01:12  Lr: 0.030000  Loss: -0.1764  Acc@1: 68.7500 (69.8479)  Acc@5: 100.0000 (97.5501)  time: 0.3456  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [3550/3750]  eta: 0:01:08  Lr: 0.030000  Loss: -0.1986  Acc@1: 68.7500 (69.8624)  Acc@5: 100.0000 (97.5517)  time: 0.3458  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [3560/3750]  eta: 0:01:05  Lr: 0.030000  Loss: -0.2016  Acc@1: 68.7500 (69.8592)  Acc@5: 100.0000 (97.5498)  time: 0.3453  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [3570/3750]  eta: 0:01:02  Lr: 0.030000  Loss: -0.0589  Acc@1: 75.0000 (69.8841)  Acc@5: 100.0000 (97.5515)  time: 0.3453  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [3580/3750]  eta: 0:00:58  Lr: 0.030000  Loss: -0.3248  Acc@1: 75.0000 (69.8827)  Acc@5: 100.0000 (97.5548)  time: 0.3451  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [3590/3750]  eta: 0:00:55  Lr: 0.030000  Loss: -0.2577  Acc@1: 68.7500 (69.8883)  Acc@5: 100.0000 (97.5564)  time: 0.3446  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [3600/3750]  eta: 0:00:51  Lr: 0.030000  Loss: 0.1407  Acc@1: 68.7500 (69.8920)  Acc@5: 100.0000 (97.5528)  time: 0.3442  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [3610/3750]  eta: 0:00:48  Lr: 0.030000  Loss: 0.2344  Acc@1: 68.7500 (69.8923)  Acc@5: 100.0000 (97.5509)  time: 0.3451  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [3620/3750]  eta: 0:00:44  Lr: 0.030000  Loss: -0.0972  Acc@1: 75.0000 (69.9064)  Acc@5: 100.0000 (97.5507)  time: 0.3463  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [3630/3750]  eta: 0:00:41  Lr: 0.030000  Loss: 0.0729  Acc@1: 75.0000 (69.9067)  Acc@5: 100.0000 (97.5489)  time: 0.3450  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [3640/3750]  eta: 0:00:37  Lr: 0.030000  Loss: 0.0107  Acc@1: 75.0000 (69.9207)  Acc@5: 100.0000 (97.5522)  time: 0.3440  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [3650/3750]  eta: 0:00:34  Lr: 0.030000  Loss: 0.1049  Acc@1: 75.0000 (69.9278)  Acc@5: 100.0000 (97.5486)  time: 0.3443  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [3660/3750]  eta: 0:00:31  Lr: 0.030000  Loss: 0.1496  Acc@1: 68.7500 (69.9245)  Acc@5: 100.0000 (97.5468)  time: 0.3445  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [3670/3750]  eta: 0:00:27  Lr: 0.030000  Loss: 0.1655  Acc@1: 68.7500 (69.9145)  Acc@5: 100.0000 (97.5432)  time: 0.3447  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [3680/3750]  eta: 0:00:24  Lr: 0.030000  Loss: -0.1398  Acc@1: 68.7500 (69.9216)  Acc@5: 100.0000 (97.5448)  time: 0.3445  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [3690/3750]  eta: 0:00:20  Lr: 0.030000  Loss: -0.1514  Acc@1: 75.0000 (69.9353)  Acc@5: 100.0000 (97.5481)  time: 0.3444  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [3700/3750]  eta: 0:00:17  Lr: 0.030000  Loss: 0.0641  Acc@1: 68.7500 (69.9152)  Acc@5: 100.0000 (97.5513)  time: 0.3447  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [3710/3750]  eta: 0:00:13  Lr: 0.030000  Loss: 0.1110  Acc@1: 68.7500 (69.9104)  Acc@5: 100.0000 (97.5495)  time: 0.3435  data: 0.0002  max mem: 2502
Train: Epoch[3/5]  [3720/3750]  eta: 0:00:10  Lr: 0.030000  Loss: -0.2719  Acc@1: 68.7500 (69.9123)  Acc@5: 100.0000 (97.5494)  time: 0.3420  data: 0.0002  max mem: 2502
Train: Epoch[3/5]  [3730/3750]  eta: 0:00:06  Lr: 0.030000  Loss: -0.1675  Acc@1: 68.7500 (69.9293)  Acc@5: 100.0000 (97.5526)  time: 0.3421  data: 0.0002  max mem: 2502
Train: Epoch[3/5]  [3740/3750]  eta: 0:00:03  Lr: 0.030000  Loss: 0.4128  Acc@1: 68.7500 (69.9161)  Acc@5: 100.0000 (97.5558)  time: 0.3418  data: 0.0002  max mem: 2502
Train: Epoch[3/5]  [3749/3750]  eta: 0:00:00  Lr: 0.030000  Loss: 0.4497  Acc@1: 68.7500 (69.9067)  Acc@5: 100.0000 (97.5500)  time: 0.3419  data: 0.0004  max mem: 2502
Train: Epoch[3/5] Total time: 0:21:34 (0.3451 s / it)
{0: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 1: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 2: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 3: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 4: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 5: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 6: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 7: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 8: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 9: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 10: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 11: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 12: {0: 0, 1: 0, 2: 0, 3: 91325, 4: 0}, 13: {0: 0, 1: 0, 2: 0, 3: 91325, 4: 0}, 14: {0: 0, 1: 0, 2: 0, 3: 91325, 4: 0}, 15: {0: 0, 1: 0, 2: 0, 3: 91325, 4: 0}, 16: {0: 0, 1: 0, 2: 0, 3: 0, 4: 180000}, 17: {0: 0, 1: 0, 2: 0, 3: 0, 4: 180000}, 18: {0: 0, 1: 0, 2: 0, 3: 0, 4: 180000}, 19: {0: 0, 1: 0, 2: 0, 3: 0, 4: 180000}}
Averaged stats: Lr: 0.030000  Loss: 0.4497  Acc@1: 68.7500 (69.9067)  Acc@5: 100.0000 (97.5500)
Train: Epoch[4/5]  [   0/3750]  eta: 0:35:03  Lr: 0.030000  Loss: -0.0402  Acc@1: 81.2500 (81.2500)  Acc@5: 87.5000 (87.5000)  time: 0.5610  data: 0.2181  max mem: 2502
Train: Epoch[4/5]  [  10/3750]  eta: 0:22:34  Lr: 0.030000  Loss: 0.0593  Acc@1: 68.7500 (69.8864)  Acc@5: 93.7500 (96.0227)  time: 0.3621  data: 0.0200  max mem: 2502
Train: Epoch[4/5]  [  20/3750]  eta: 0:21:55  Lr: 0.030000  Loss: -0.0832  Acc@1: 68.7500 (72.0238)  Acc@5: 100.0000 (97.3214)  time: 0.3422  data: 0.0002  max mem: 2502
Train: Epoch[4/5]  [  30/3750]  eta: 0:21:39  Lr: 0.030000  Loss: 0.0843  Acc@1: 68.7500 (70.9677)  Acc@5: 100.0000 (96.9758)  time: 0.3422  data: 0.0002  max mem: 2502
Train: Epoch[4/5]  [  40/3750]  eta: 0:21:30  Lr: 0.030000  Loss: -0.1664  Acc@1: 68.7500 (70.7317)  Acc@5: 100.0000 (97.5610)  time: 0.3426  data: 0.0002  max mem: 2502
Train: Epoch[4/5]  [  50/3750]  eta: 0:21:25  Lr: 0.030000  Loss: -0.0797  Acc@1: 68.7500 (70.4657)  Acc@5: 100.0000 (97.5490)  time: 0.3447  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [  60/3750]  eta: 0:21:20  Lr: 0.030000  Loss: 0.0905  Acc@1: 62.5000 (69.4672)  Acc@5: 100.0000 (97.5410)  time: 0.3457  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [  70/3750]  eta: 0:21:16  Lr: 0.030000  Loss: 0.2611  Acc@1: 68.7500 (70.3345)  Acc@5: 100.0000 (97.7993)  time: 0.3455  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [  80/3750]  eta: 0:21:13  Lr: 0.030000  Loss: 0.2936  Acc@1: 75.0000 (69.6759)  Acc@5: 100.0000 (97.6852)  time: 0.3472  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [  90/3750]  eta: 0:21:09  Lr: 0.030000  Loss: -0.2158  Acc@1: 68.7500 (69.7115)  Acc@5: 93.7500 (97.5962)  time: 0.3468  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [ 100/3750]  eta: 0:21:05  Lr: 0.030000  Loss: 0.0289  Acc@1: 68.7500 (69.7401)  Acc@5: 100.0000 (97.5866)  time: 0.3450  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [ 110/3750]  eta: 0:21:01  Lr: 0.030000  Loss: -0.1037  Acc@1: 68.7500 (69.9887)  Acc@5: 100.0000 (97.6351)  time: 0.3448  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [ 120/3750]  eta: 0:20:57  Lr: 0.030000  Loss: 0.2838  Acc@1: 68.7500 (69.7314)  Acc@5: 100.0000 (97.7273)  time: 0.3451  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [ 130/3750]  eta: 0:20:54  Lr: 0.030000  Loss: 0.1122  Acc@1: 68.7500 (69.7519)  Acc@5: 100.0000 (97.7099)  time: 0.3459  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [ 140/3750]  eta: 0:20:50  Lr: 0.030000  Loss: 0.0756  Acc@1: 75.0000 (69.9468)  Acc@5: 100.0000 (97.7394)  time: 0.3466  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [ 150/3750]  eta: 0:20:47  Lr: 0.030000  Loss: 0.1545  Acc@1: 68.7500 (69.5778)  Acc@5: 100.0000 (97.5993)  time: 0.3466  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [ 160/3750]  eta: 0:20:43  Lr: 0.030000  Loss: 0.2202  Acc@1: 68.7500 (69.6817)  Acc@5: 93.7500 (97.5155)  time: 0.3463  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [ 170/3750]  eta: 0:20:39  Lr: 0.030000  Loss: -0.1306  Acc@1: 75.0000 (70.1023)  Acc@5: 100.0000 (97.5146)  time: 0.3457  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [ 180/3750]  eta: 0:20:36  Lr: 0.030000  Loss: 0.0777  Acc@1: 68.7500 (69.8204)  Acc@5: 100.0000 (97.5483)  time: 0.3452  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [ 190/3750]  eta: 0:20:32  Lr: 0.030000  Loss: 0.2023  Acc@1: 68.7500 (69.7971)  Acc@5: 100.0000 (97.5458)  time: 0.3453  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [ 200/3750]  eta: 0:20:29  Lr: 0.030000  Loss: 0.1261  Acc@1: 68.7500 (69.9938)  Acc@5: 100.0000 (97.6057)  time: 0.3468  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [ 210/3750]  eta: 0:20:25  Lr: 0.030000  Loss: -0.1504  Acc@1: 68.7500 (70.0237)  Acc@5: 100.0000 (97.5711)  time: 0.3463  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [ 220/3750]  eta: 0:20:22  Lr: 0.030000  Loss: 0.3881  Acc@1: 68.7500 (69.8812)  Acc@5: 100.0000 (97.6527)  time: 0.3446  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [ 230/3750]  eta: 0:20:18  Lr: 0.030000  Loss: 0.0725  Acc@1: 68.7500 (69.9134)  Acc@5: 100.0000 (97.6732)  time: 0.3443  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [ 240/3750]  eta: 0:20:14  Lr: 0.030000  Loss: -0.1738  Acc@1: 75.0000 (70.2282)  Acc@5: 100.0000 (97.6919)  time: 0.3443  data: 0.0002  max mem: 2502
Train: Epoch[4/5]  [ 250/3750]  eta: 0:20:10  Lr: 0.030000  Loss: -0.2443  Acc@1: 75.0000 (70.3436)  Acc@5: 100.0000 (97.7590)  time: 0.3445  data: 0.0002  max mem: 2502
Train: Epoch[4/5]  [ 260/3750]  eta: 0:20:07  Lr: 0.030000  Loss: 0.2173  Acc@1: 75.0000 (70.5460)  Acc@5: 100.0000 (97.7490)  time: 0.3442  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [ 270/3750]  eta: 0:20:03  Lr: 0.030000  Loss: -0.1467  Acc@1: 75.0000 (70.5720)  Acc@5: 100.0000 (97.7629)  time: 0.3453  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [ 280/3750]  eta: 0:19:59  Lr: 0.030000  Loss: -0.0076  Acc@1: 68.7500 (70.3959)  Acc@5: 100.0000 (97.7758)  time: 0.3445  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [ 290/3750]  eta: 0:19:56  Lr: 0.030000  Loss: -0.1407  Acc@1: 62.5000 (70.2964)  Acc@5: 100.0000 (97.7234)  time: 0.3425  data: 0.0002  max mem: 2502
Train: Epoch[4/5]  [ 300/3750]  eta: 0:19:52  Lr: 0.030000  Loss: 0.3386  Acc@1: 68.7500 (70.2450)  Acc@5: 100.0000 (97.6952)  time: 0.3422  data: 0.0002  max mem: 2502
Train: Epoch[4/5]  [ 310/3750]  eta: 0:19:48  Lr: 0.030000  Loss: -0.0348  Acc@1: 68.7500 (70.3979)  Acc@5: 100.0000 (97.6286)  time: 0.3422  data: 0.0002  max mem: 2502
Train: Epoch[4/5]  [ 320/3750]  eta: 0:19:44  Lr: 0.030000  Loss: 0.0210  Acc@1: 75.0000 (70.5218)  Acc@5: 100.0000 (97.6830)  time: 0.3422  data: 0.0002  max mem: 2502
Train: Epoch[4/5]  [ 330/3750]  eta: 0:19:40  Lr: 0.030000  Loss: 0.0024  Acc@1: 68.7500 (70.2417)  Acc@5: 100.0000 (97.6964)  time: 0.3423  data: 0.0002  max mem: 2502
Train: Epoch[4/5]  [ 340/3750]  eta: 0:19:37  Lr: 0.030000  Loss: 0.0583  Acc@1: 68.7500 (70.3446)  Acc@5: 100.0000 (97.7456)  time: 0.3424  data: 0.0002  max mem: 2502
Train: Epoch[4/5]  [ 350/3750]  eta: 0:19:33  Lr: 0.030000  Loss: -0.0849  Acc@1: 68.7500 (70.2457)  Acc@5: 100.0000 (97.7564)  time: 0.3435  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [ 360/3750]  eta: 0:19:29  Lr: 0.030000  Loss: -0.0192  Acc@1: 68.7500 (70.2389)  Acc@5: 100.0000 (97.7320)  time: 0.3442  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [ 370/3750]  eta: 0:19:26  Lr: 0.030000  Loss: 0.0521  Acc@1: 68.7500 (70.3336)  Acc@5: 100.0000 (97.7594)  time: 0.3445  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [ 380/3750]  eta: 0:19:23  Lr: 0.030000  Loss: 0.2634  Acc@1: 68.7500 (70.0131)  Acc@5: 100.0000 (97.7526)  time: 0.3454  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [ 390/3750]  eta: 0:19:19  Lr: 0.030000  Loss: -0.0125  Acc@1: 62.5000 (69.9488)  Acc@5: 100.0000 (97.7462)  time: 0.3449  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [ 400/3750]  eta: 0:19:16  Lr: 0.030000  Loss: -0.0231  Acc@1: 68.7500 (69.9813)  Acc@5: 100.0000 (97.7556)  time: 0.3448  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [ 410/3750]  eta: 0:19:12  Lr: 0.030000  Loss: 0.4457  Acc@1: 75.0000 (69.9361)  Acc@5: 100.0000 (97.7646)  time: 0.3452  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [ 420/3750]  eta: 0:19:09  Lr: 0.030000  Loss: -0.0333  Acc@1: 68.7500 (69.9970)  Acc@5: 100.0000 (97.7583)  time: 0.3456  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [ 430/3750]  eta: 0:19:05  Lr: 0.030000  Loss: 0.0342  Acc@1: 68.7500 (70.0261)  Acc@5: 100.0000 (97.7813)  time: 0.3462  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [ 440/3750]  eta: 0:19:02  Lr: 0.030000  Loss: -0.0541  Acc@1: 68.7500 (70.0255)  Acc@5: 100.0000 (97.7749)  time: 0.3464  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [ 450/3750]  eta: 0:18:59  Lr: 0.030000  Loss: 0.1390  Acc@1: 75.0000 (70.1635)  Acc@5: 100.0000 (97.8104)  time: 0.3460  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [ 460/3750]  eta: 0:18:55  Lr: 0.030000  Loss: 0.0080  Acc@1: 75.0000 (70.3227)  Acc@5: 100.0000 (97.8444)  time: 0.3450  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [ 470/3750]  eta: 0:18:52  Lr: 0.030000  Loss: -0.0582  Acc@1: 75.0000 (70.3291)  Acc@5: 100.0000 (97.8370)  time: 0.3447  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [ 480/3750]  eta: 0:18:48  Lr: 0.030000  Loss: -0.0156  Acc@1: 75.0000 (70.4782)  Acc@5: 100.0000 (97.8690)  time: 0.3457  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [ 490/3750]  eta: 0:18:45  Lr: 0.030000  Loss: -0.1242  Acc@1: 75.0000 (70.5830)  Acc@5: 100.0000 (97.8488)  time: 0.3460  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [ 500/3750]  eta: 0:18:41  Lr: 0.030000  Loss: 0.1463  Acc@1: 75.0000 (70.5464)  Acc@5: 100.0000 (97.8418)  time: 0.3446  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [ 510/3750]  eta: 0:18:38  Lr: 0.030000  Loss: 0.0141  Acc@1: 68.7500 (70.4501)  Acc@5: 100.0000 (97.8596)  time: 0.3445  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [ 520/3750]  eta: 0:18:34  Lr: 0.030000  Loss: 0.0174  Acc@1: 68.7500 (70.4415)  Acc@5: 100.0000 (97.8527)  time: 0.3442  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [ 530/3750]  eta: 0:18:31  Lr: 0.030000  Loss: -0.1982  Acc@1: 75.0000 (70.5273)  Acc@5: 100.0000 (97.8107)  time: 0.3433  data: 0.0002  max mem: 2502
Train: Epoch[4/5]  [ 540/3750]  eta: 0:18:27  Lr: 0.030000  Loss: 0.2711  Acc@1: 68.7500 (70.5176)  Acc@5: 93.7500 (97.7819)  time: 0.3432  data: 0.0002  max mem: 2502
Train: Epoch[4/5]  [ 550/3750]  eta: 0:18:24  Lr: 0.030000  Loss: 0.1207  Acc@1: 68.7500 (70.4968)  Acc@5: 100.0000 (97.7995)  time: 0.3442  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [ 560/3750]  eta: 0:18:20  Lr: 0.030000  Loss: 0.3735  Acc@1: 68.7500 (70.5214)  Acc@5: 100.0000 (97.7718)  time: 0.3451  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [ 570/3750]  eta: 0:18:17  Lr: 0.030000  Loss: -0.0395  Acc@1: 68.7500 (70.5342)  Acc@5: 100.0000 (97.7999)  time: 0.3462  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [ 580/3750]  eta: 0:18:13  Lr: 0.030000  Loss: 0.0514  Acc@1: 68.7500 (70.5572)  Acc@5: 100.0000 (97.8270)  time: 0.3456  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [ 590/3750]  eta: 0:18:10  Lr: 0.030000  Loss: -0.1224  Acc@1: 75.0000 (70.5478)  Acc@5: 100.0000 (97.7898)  time: 0.3438  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [ 600/3750]  eta: 0:18:06  Lr: 0.030000  Loss: -0.0220  Acc@1: 75.0000 (70.6219)  Acc@5: 100.0000 (97.8057)  time: 0.3442  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [ 610/3750]  eta: 0:18:03  Lr: 0.030000  Loss: 0.1439  Acc@1: 68.7500 (70.5912)  Acc@5: 100.0000 (97.7905)  time: 0.3445  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [ 620/3750]  eta: 0:17:59  Lr: 0.030000  Loss: -0.2966  Acc@1: 68.7500 (70.6522)  Acc@5: 100.0000 (97.7858)  time: 0.3444  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [ 630/3750]  eta: 0:17:56  Lr: 0.030000  Loss: -0.0868  Acc@1: 75.0000 (70.6815)  Acc@5: 100.0000 (97.7516)  time: 0.3446  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [ 640/3750]  eta: 0:17:52  Lr: 0.030000  Loss: 0.1009  Acc@1: 68.7500 (70.6903)  Acc@5: 100.0000 (97.7769)  time: 0.3437  data: 0.0002  max mem: 2502
Train: Epoch[4/5]  [ 650/3750]  eta: 0:17:49  Lr: 0.030000  Loss: -0.0126  Acc@1: 68.7500 (70.6317)  Acc@5: 100.0000 (97.7727)  time: 0.3422  data: 0.0002  max mem: 2502
Train: Epoch[4/5]  [ 660/3750]  eta: 0:17:45  Lr: 0.030000  Loss: -0.2385  Acc@1: 75.0000 (70.7356)  Acc@5: 100.0000 (97.8064)  time: 0.3423  data: 0.0002  max mem: 2502
Train: Epoch[4/5]  [ 670/3750]  eta: 0:17:42  Lr: 0.030000  Loss: -0.1632  Acc@1: 75.0000 (70.7247)  Acc@5: 100.0000 (97.7832)  time: 0.3424  data: 0.0002  max mem: 2502
Train: Epoch[4/5]  [ 680/3750]  eta: 0:17:38  Lr: 0.030000  Loss: -0.0640  Acc@1: 68.7500 (70.7599)  Acc@5: 100.0000 (97.8157)  time: 0.3424  data: 0.0002  max mem: 2502
Train: Epoch[4/5]  [ 690/3750]  eta: 0:17:35  Lr: 0.030000  Loss: -0.1173  Acc@1: 75.0000 (70.8755)  Acc@5: 100.0000 (97.8292)  time: 0.3425  data: 0.0002  max mem: 2502
Train: Epoch[4/5]  [ 700/3750]  eta: 0:17:31  Lr: 0.030000  Loss: 0.0846  Acc@1: 75.0000 (70.8363)  Acc@5: 100.0000 (97.8513)  time: 0.3425  data: 0.0002  max mem: 2502
Train: Epoch[4/5]  [ 710/3750]  eta: 0:17:27  Lr: 0.030000  Loss: 0.0065  Acc@1: 68.7500 (70.8158)  Acc@5: 100.0000 (97.8551)  time: 0.3424  data: 0.0002  max mem: 2502
Train: Epoch[4/5]  [ 720/3750]  eta: 0:17:24  Lr: 0.030000  Loss: 0.2605  Acc@1: 68.7500 (70.7958)  Acc@5: 100.0000 (97.8415)  time: 0.3427  data: 0.0002  max mem: 2502
Train: Epoch[4/5]  [ 730/3750]  eta: 0:17:21  Lr: 0.030000  Loss: 0.1741  Acc@1: 75.0000 (70.8020)  Acc@5: 100.0000 (97.8369)  time: 0.3448  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [ 740/3750]  eta: 0:17:17  Lr: 0.030000  Loss: -0.2264  Acc@1: 75.0000 (70.8586)  Acc@5: 100.0000 (97.8155)  time: 0.3457  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [ 750/3750]  eta: 0:17:14  Lr: 0.030000  Loss: -0.0015  Acc@1: 68.7500 (70.8722)  Acc@5: 100.0000 (97.8279)  time: 0.3456  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [ 760/3750]  eta: 0:17:10  Lr: 0.030000  Loss: 0.1241  Acc@1: 68.7500 (70.8196)  Acc@5: 100.0000 (97.8482)  time: 0.3466  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [ 770/3750]  eta: 0:17:07  Lr: 0.030000  Loss: -0.1075  Acc@1: 75.0000 (70.8414)  Acc@5: 100.0000 (97.8599)  time: 0.3455  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [ 780/3750]  eta: 0:17:03  Lr: 0.030000  Loss: -0.0056  Acc@1: 75.0000 (70.8547)  Acc@5: 100.0000 (97.8873)  time: 0.3440  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [ 790/3750]  eta: 0:17:00  Lr: 0.030000  Loss: 0.0803  Acc@1: 68.7500 (70.8281)  Acc@5: 100.0000 (97.8903)  time: 0.3457  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [ 800/3750]  eta: 0:16:57  Lr: 0.030000  Loss: -0.2615  Acc@1: 68.7500 (70.9816)  Acc@5: 100.0000 (97.9089)  time: 0.3464  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [ 810/3750]  eta: 0:16:53  Lr: 0.030000  Loss: 0.0085  Acc@1: 81.2500 (71.0080)  Acc@5: 100.0000 (97.9192)  time: 0.3454  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [ 820/3750]  eta: 0:16:50  Lr: 0.030000  Loss: 0.1254  Acc@1: 68.7500 (70.9577)  Acc@5: 100.0000 (97.8913)  time: 0.3449  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [ 830/3750]  eta: 0:16:46  Lr: 0.030000  Loss: 0.2226  Acc@1: 62.5000 (70.8860)  Acc@5: 93.7500 (97.8565)  time: 0.3453  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [ 840/3750]  eta: 0:16:43  Lr: 0.030000  Loss: 0.1930  Acc@1: 68.7500 (70.8829)  Acc@5: 100.0000 (97.8746)  time: 0.3464  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [ 850/3750]  eta: 0:16:40  Lr: 0.030000  Loss: 0.2240  Acc@1: 68.7500 (70.9092)  Acc@5: 100.0000 (97.8848)  time: 0.3457  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [ 860/3750]  eta: 0:16:36  Lr: 0.030000  Loss: -0.0341  Acc@1: 75.0000 (70.9277)  Acc@5: 100.0000 (97.8659)  time: 0.3455  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [ 870/3750]  eta: 0:16:33  Lr: 0.030000  Loss: -0.1690  Acc@1: 75.0000 (70.9529)  Acc@5: 93.7500 (97.8545)  time: 0.3471  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [ 880/3750]  eta: 0:16:29  Lr: 0.030000  Loss: -0.0599  Acc@1: 75.0000 (70.9492)  Acc@5: 100.0000 (97.8505)  time: 0.3483  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [ 890/3750]  eta: 0:16:26  Lr: 0.030000  Loss: -0.0893  Acc@1: 62.5000 (70.8544)  Acc@5: 100.0000 (97.8395)  time: 0.3464  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [ 900/3750]  eta: 0:16:23  Lr: 0.030000  Loss: 0.2232  Acc@1: 62.5000 (70.8241)  Acc@5: 100.0000 (97.8427)  time: 0.3444  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [ 910/3750]  eta: 0:16:19  Lr: 0.030000  Loss: 0.1248  Acc@1: 68.7500 (70.7739)  Acc@5: 100.0000 (97.8458)  time: 0.3451  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [ 920/3750]  eta: 0:16:16  Lr: 0.030000  Loss: -0.1982  Acc@1: 68.7500 (70.7790)  Acc@5: 100.0000 (97.8420)  time: 0.3450  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [ 930/3750]  eta: 0:16:12  Lr: 0.030000  Loss: 0.0785  Acc@1: 75.0000 (70.7908)  Acc@5: 100.0000 (97.8451)  time: 0.3443  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [ 940/3750]  eta: 0:16:09  Lr: 0.030000  Loss: 0.1028  Acc@1: 62.5000 (70.6828)  Acc@5: 100.0000 (97.8480)  time: 0.3441  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [ 950/3750]  eta: 0:16:05  Lr: 0.030000  Loss: -0.0441  Acc@1: 68.7500 (70.7019)  Acc@5: 100.0000 (97.8641)  time: 0.3440  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [ 960/3750]  eta: 0:16:02  Lr: 0.030000  Loss: 0.0234  Acc@1: 68.7500 (70.6296)  Acc@5: 100.0000 (97.8538)  time: 0.3432  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [ 970/3750]  eta: 0:15:58  Lr: 0.030000  Loss: 0.1700  Acc@1: 62.5000 (70.5651)  Acc@5: 93.7500 (97.8373)  time: 0.3426  data: 0.0002  max mem: 2502
Train: Epoch[4/5]  [ 980/3750]  eta: 0:15:55  Lr: 0.030000  Loss: -0.1206  Acc@1: 68.7500 (70.5594)  Acc@5: 93.7500 (97.8275)  time: 0.3427  data: 0.0002  max mem: 2502
Train: Epoch[4/5]  [ 990/3750]  eta: 0:15:51  Lr: 0.030000  Loss: -0.0383  Acc@1: 68.7500 (70.5474)  Acc@5: 100.0000 (97.8305)  time: 0.3433  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [1000/3750]  eta: 0:15:48  Lr: 0.030000  Loss: -0.1338  Acc@1: 68.7500 (70.4858)  Acc@5: 100.0000 (97.8022)  time: 0.3458  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [1010/3750]  eta: 0:15:44  Lr: 0.030000  Loss: 0.0351  Acc@1: 68.7500 (70.5490)  Acc@5: 100.0000 (97.8116)  time: 0.3465  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [1020/3750]  eta: 0:15:41  Lr: 0.030000  Loss: 0.0687  Acc@1: 75.0000 (70.5803)  Acc@5: 100.0000 (97.8146)  time: 0.3456  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [1030/3750]  eta: 0:15:38  Lr: 0.030000  Loss: 0.2092  Acc@1: 75.0000 (70.5989)  Acc@5: 100.0000 (97.8116)  time: 0.3449  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [1040/3750]  eta: 0:15:34  Lr: 0.030000  Loss: -0.2832  Acc@1: 75.0000 (70.6652)  Acc@5: 100.0000 (97.8206)  time: 0.3444  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [1050/3750]  eta: 0:15:31  Lr: 0.030000  Loss: 0.0511  Acc@1: 68.7500 (70.6292)  Acc@5: 100.0000 (97.8176)  time: 0.3447  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [1060/3750]  eta: 0:15:27  Lr: 0.030000  Loss: -0.1262  Acc@1: 68.7500 (70.6409)  Acc@5: 93.7500 (97.7792)  time: 0.3443  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [1070/3750]  eta: 0:15:24  Lr: 0.030000  Loss: 0.1830  Acc@1: 68.7500 (70.5999)  Acc@5: 93.7500 (97.7766)  time: 0.3435  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [1080/3750]  eta: 0:15:20  Lr: 0.030000  Loss: -0.0733  Acc@1: 75.0000 (70.6464)  Acc@5: 100.0000 (97.7856)  time: 0.3431  data: 0.0002  max mem: 2502
Train: Epoch[4/5]  [1090/3750]  eta: 0:15:17  Lr: 0.030000  Loss: -0.0749  Acc@1: 68.7500 (70.6519)  Acc@5: 100.0000 (97.7830)  time: 0.3429  data: 0.0002  max mem: 2502
Train: Epoch[4/5]  [1100/3750]  eta: 0:15:13  Lr: 0.030000  Loss: -0.2862  Acc@1: 68.7500 (70.6517)  Acc@5: 100.0000 (97.7861)  time: 0.3434  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [1110/3750]  eta: 0:15:10  Lr: 0.030000  Loss: 0.0651  Acc@1: 68.7500 (70.6571)  Acc@5: 100.0000 (97.7779)  time: 0.3442  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [1120/3750]  eta: 0:15:06  Lr: 0.030000  Loss: 0.2430  Acc@1: 68.7500 (70.6178)  Acc@5: 100.0000 (97.7698)  time: 0.3446  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [1130/3750]  eta: 0:15:03  Lr: 0.030000  Loss: 0.1092  Acc@1: 62.5000 (70.5791)  Acc@5: 100.0000 (97.7785)  time: 0.3441  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [1140/3750]  eta: 0:14:59  Lr: 0.030000  Loss: 0.0155  Acc@1: 68.7500 (70.5521)  Acc@5: 100.0000 (97.7816)  time: 0.3440  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [1150/3750]  eta: 0:14:56  Lr: 0.030000  Loss: -0.1815  Acc@1: 62.5000 (70.5093)  Acc@5: 100.0000 (97.7737)  time: 0.3445  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [1160/3750]  eta: 0:14:52  Lr: 0.030000  Loss: -0.2177  Acc@1: 62.5000 (70.5265)  Acc@5: 100.0000 (97.7659)  time: 0.3445  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [1170/3750]  eta: 0:14:49  Lr: 0.030000  Loss: -0.0549  Acc@1: 68.7500 (70.5380)  Acc@5: 100.0000 (97.7797)  time: 0.3452  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [1180/3750]  eta: 0:14:46  Lr: 0.030000  Loss: 0.2167  Acc@1: 68.7500 (70.5440)  Acc@5: 100.0000 (97.7932)  time: 0.3441  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [1190/3750]  eta: 0:14:42  Lr: 0.030000  Loss: 0.0880  Acc@1: 68.7500 (70.5132)  Acc@5: 100.0000 (97.7750)  time: 0.3425  data: 0.0002  max mem: 2502
Train: Epoch[4/5]  [1200/3750]  eta: 0:14:39  Lr: 0.030000  Loss: 0.2320  Acc@1: 68.7500 (70.4777)  Acc@5: 93.7500 (97.7623)  time: 0.3424  data: 0.0002  max mem: 2502
Train: Epoch[4/5]  [1210/3750]  eta: 0:14:35  Lr: 0.030000  Loss: 0.0861  Acc@1: 68.7500 (70.4480)  Acc@5: 100.0000 (97.7653)  time: 0.3421  data: 0.0002  max mem: 2502
Train: Epoch[4/5]  [1220/3750]  eta: 0:14:32  Lr: 0.030000  Loss: -0.0055  Acc@1: 68.7500 (70.4290)  Acc@5: 100.0000 (97.7631)  time: 0.3422  data: 0.0002  max mem: 2502
Train: Epoch[4/5]  [1230/3750]  eta: 0:14:28  Lr: 0.030000  Loss: -0.0109  Acc@1: 68.7500 (70.4356)  Acc@5: 100.0000 (97.7711)  time: 0.3425  data: 0.0002  max mem: 2502
Train: Epoch[4/5]  [1240/3750]  eta: 0:14:25  Lr: 0.030000  Loss: 0.0252  Acc@1: 68.7500 (70.4170)  Acc@5: 100.0000 (97.7689)  time: 0.3425  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [1250/3750]  eta: 0:14:21  Lr: 0.030000  Loss: -0.0380  Acc@1: 75.0000 (70.4536)  Acc@5: 100.0000 (97.7768)  time: 0.3432  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [1260/3750]  eta: 0:14:18  Lr: 0.030000  Loss: -0.0990  Acc@1: 75.0000 (70.4500)  Acc@5: 100.0000 (97.7795)  time: 0.3447  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [1270/3750]  eta: 0:14:14  Lr: 0.030000  Loss: 0.2514  Acc@1: 75.0000 (70.5055)  Acc@5: 100.0000 (97.7872)  time: 0.3453  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [1280/3750]  eta: 0:14:11  Lr: 0.030000  Loss: -0.2978  Acc@1: 75.0000 (70.4967)  Acc@5: 100.0000 (97.7849)  time: 0.3458  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [1290/3750]  eta: 0:14:07  Lr: 0.030000  Loss: -0.0776  Acc@1: 68.7500 (70.5267)  Acc@5: 100.0000 (97.7779)  time: 0.3452  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [1300/3750]  eta: 0:14:04  Lr: 0.030000  Loss: -0.0532  Acc@1: 68.7500 (70.5179)  Acc@5: 93.7500 (97.7517)  time: 0.3449  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [1310/3750]  eta: 0:14:00  Lr: 0.030000  Loss: 0.0431  Acc@1: 75.0000 (70.5807)  Acc@5: 100.0000 (97.7689)  time: 0.3455  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [1320/3750]  eta: 0:13:57  Lr: 0.030000  Loss: -0.1832  Acc@1: 75.0000 (70.6047)  Acc@5: 100.0000 (97.7763)  time: 0.3473  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [1330/3750]  eta: 0:13:54  Lr: 0.030000  Loss: -0.0454  Acc@1: 75.0000 (70.6283)  Acc@5: 100.0000 (97.7742)  time: 0.3470  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [1340/3750]  eta: 0:13:50  Lr: 0.030000  Loss: -0.1188  Acc@1: 75.0000 (70.6655)  Acc@5: 100.0000 (97.7722)  time: 0.3449  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [1350/3750]  eta: 0:13:47  Lr: 0.030000  Loss: 0.0125  Acc@1: 68.7500 (70.6005)  Acc@5: 100.0000 (97.7748)  time: 0.3452  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [1360/3750]  eta: 0:13:43  Lr: 0.030000  Loss: 0.0402  Acc@1: 62.5000 (70.6236)  Acc@5: 100.0000 (97.7682)  time: 0.3459  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [1370/3750]  eta: 0:13:40  Lr: 0.030000  Loss: -0.2698  Acc@1: 75.0000 (70.6419)  Acc@5: 100.0000 (97.7799)  time: 0.3484  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [1380/3750]  eta: 0:13:37  Lr: 0.030000  Loss: 0.2826  Acc@1: 62.5000 (70.5512)  Acc@5: 100.0000 (97.7824)  time: 0.3476  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [1390/3750]  eta: 0:13:33  Lr: 0.030000  Loss: 0.0454  Acc@1: 62.5000 (70.5697)  Acc@5: 100.0000 (97.7804)  time: 0.3445  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [1400/3750]  eta: 0:13:30  Lr: 0.030000  Loss: 0.2047  Acc@1: 68.7500 (70.5166)  Acc@5: 100.0000 (97.7784)  time: 0.3450  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [1410/3750]  eta: 0:13:26  Lr: 0.030000  Loss: 0.0014  Acc@1: 68.7500 (70.5351)  Acc@5: 100.0000 (97.7808)  time: 0.3448  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [1420/3750]  eta: 0:13:23  Lr: 0.030000  Loss: 0.0495  Acc@1: 75.0000 (70.5621)  Acc@5: 100.0000 (97.7789)  time: 0.3443  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [1430/3750]  eta: 0:13:19  Lr: 0.030000  Loss: 0.0059  Acc@1: 75.0000 (70.5844)  Acc@5: 100.0000 (97.7856)  time: 0.3447  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [1440/3750]  eta: 0:13:16  Lr: 0.030000  Loss: -0.0885  Acc@1: 75.0000 (70.5500)  Acc@5: 100.0000 (97.7880)  time: 0.3443  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [1450/3750]  eta: 0:13:12  Lr: 0.030000  Loss: -0.2234  Acc@1: 62.5000 (70.5203)  Acc@5: 100.0000 (97.7903)  time: 0.3432  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [1460/3750]  eta: 0:13:09  Lr: 0.030000  Loss: 0.0584  Acc@1: 68.7500 (70.5168)  Acc@5: 100.0000 (97.7969)  time: 0.3425  data: 0.0002  max mem: 2502
Train: Epoch[4/5]  [1470/3750]  eta: 0:13:05  Lr: 0.030000  Loss: -0.0685  Acc@1: 68.7500 (70.5303)  Acc@5: 100.0000 (97.8034)  time: 0.3427  data: 0.0002  max mem: 2502
Train: Epoch[4/5]  [1480/3750]  eta: 0:13:02  Lr: 0.030000  Loss: 0.0850  Acc@1: 68.7500 (70.5056)  Acc@5: 100.0000 (97.8013)  time: 0.3433  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [1490/3750]  eta: 0:12:59  Lr: 0.030000  Loss: 0.2354  Acc@1: 68.7500 (70.4770)  Acc@5: 100.0000 (97.7951)  time: 0.3445  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [1500/3750]  eta: 0:12:55  Lr: 0.030000  Loss: -0.2324  Acc@1: 68.7500 (70.4863)  Acc@5: 93.7500 (97.7848)  time: 0.3448  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [1510/3750]  eta: 0:12:52  Lr: 0.030000  Loss: -0.0465  Acc@1: 75.0000 (70.5286)  Acc@5: 100.0000 (97.7953)  time: 0.3443  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [1520/3750]  eta: 0:12:48  Lr: 0.030000  Loss: 0.1636  Acc@1: 75.0000 (70.5539)  Acc@5: 100.0000 (97.7893)  time: 0.3457  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [1530/3750]  eta: 0:12:45  Lr: 0.030000  Loss: 0.0317  Acc@1: 75.0000 (70.5625)  Acc@5: 100.0000 (97.7915)  time: 0.3459  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [1540/3750]  eta: 0:12:41  Lr: 0.030000  Loss: 0.1108  Acc@1: 68.7500 (70.5508)  Acc@5: 100.0000 (97.7977)  time: 0.3458  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [1550/3750]  eta: 0:12:38  Lr: 0.030000  Loss: -0.0444  Acc@1: 68.7500 (70.5230)  Acc@5: 100.0000 (97.7877)  time: 0.3456  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [1560/3750]  eta: 0:12:34  Lr: 0.030000  Loss: -0.1011  Acc@1: 68.7500 (70.5117)  Acc@5: 100.0000 (97.7859)  time: 0.3445  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [1570/3750]  eta: 0:12:31  Lr: 0.030000  Loss: -0.0044  Acc@1: 68.7500 (70.5323)  Acc@5: 100.0000 (97.7801)  time: 0.3445  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [1580/3750]  eta: 0:12:28  Lr: 0.030000  Loss: 0.0714  Acc@1: 68.7500 (70.5368)  Acc@5: 93.7500 (97.7664)  time: 0.3444  data: 0.0002  max mem: 2502
Train: Epoch[4/5]  [1590/3750]  eta: 0:12:24  Lr: 0.030000  Loss: -0.3750  Acc@1: 75.0000 (70.5453)  Acc@5: 93.7500 (97.7608)  time: 0.3433  data: 0.0002  max mem: 2502
Train: Epoch[4/5]  [1600/3750]  eta: 0:12:21  Lr: 0.030000  Loss: 0.0692  Acc@1: 75.0000 (70.5418)  Acc@5: 100.0000 (97.7514)  time: 0.3450  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [1610/3750]  eta: 0:12:17  Lr: 0.030000  Loss: 0.0119  Acc@1: 62.5000 (70.5074)  Acc@5: 100.0000 (97.7537)  time: 0.3467  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [1620/3750]  eta: 0:12:14  Lr: 0.030000  Loss: 0.0267  Acc@1: 62.5000 (70.5197)  Acc@5: 100.0000 (97.7560)  time: 0.3455  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [1630/3750]  eta: 0:12:10  Lr: 0.030000  Loss: 0.2656  Acc@1: 62.5000 (70.4859)  Acc@5: 100.0000 (97.7276)  time: 0.3445  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [1640/3750]  eta: 0:12:07  Lr: 0.030000  Loss: -0.2190  Acc@1: 62.5000 (70.4944)  Acc@5: 93.7500 (97.7148)  time: 0.3435  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [1650/3750]  eta: 0:12:03  Lr: 0.030000  Loss: -0.2135  Acc@1: 81.2500 (70.5330)  Acc@5: 100.0000 (97.7135)  time: 0.3435  data: 0.0002  max mem: 2502
Train: Epoch[4/5]  [1660/3750]  eta: 0:12:00  Lr: 0.030000  Loss: 0.0255  Acc@1: 75.0000 (70.5185)  Acc@5: 100.0000 (97.7122)  time: 0.3437  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [1670/3750]  eta: 0:11:56  Lr: 0.030000  Loss: -0.1311  Acc@1: 75.0000 (70.5640)  Acc@5: 100.0000 (97.6997)  time: 0.3436  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [1680/3750]  eta: 0:11:53  Lr: 0.030000  Loss: -0.1134  Acc@1: 75.0000 (70.5681)  Acc@5: 100.0000 (97.6985)  time: 0.3433  data: 0.0002  max mem: 2502
Train: Epoch[4/5]  [1690/3750]  eta: 0:11:50  Lr: 0.030000  Loss: 0.0970  Acc@1: 68.7500 (70.5500)  Acc@5: 100.0000 (97.7011)  time: 0.3427  data: 0.0002  max mem: 2502
Train: Epoch[4/5]  [1700/3750]  eta: 0:11:46  Lr: 0.030000  Loss: -0.1681  Acc@1: 75.0000 (70.5725)  Acc@5: 100.0000 (97.7072)  time: 0.3426  data: 0.0002  max mem: 2502
Train: Epoch[4/5]  [1710/3750]  eta: 0:11:43  Lr: 0.030000  Loss: 0.1583  Acc@1: 75.0000 (70.6129)  Acc@5: 100.0000 (97.7060)  time: 0.3435  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [1720/3750]  eta: 0:11:39  Lr: 0.030000  Loss: 0.1049  Acc@1: 75.0000 (70.6130)  Acc@5: 100.0000 (97.7012)  time: 0.3438  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [1730/3750]  eta: 0:11:36  Lr: 0.030000  Loss: -0.0216  Acc@1: 68.7500 (70.6023)  Acc@5: 100.0000 (97.6928)  time: 0.3436  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [1740/3750]  eta: 0:11:32  Lr: 0.030000  Loss: -0.0492  Acc@1: 75.0000 (70.6455)  Acc@5: 100.0000 (97.7025)  time: 0.3445  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [1750/3750]  eta: 0:11:29  Lr: 0.030000  Loss: 0.0782  Acc@1: 75.0000 (70.6775)  Acc@5: 100.0000 (97.7085)  time: 0.3446  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [1760/3750]  eta: 0:11:25  Lr: 0.030000  Loss: -0.1215  Acc@1: 75.0000 (70.6985)  Acc@5: 100.0000 (97.7144)  time: 0.3439  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [1770/3750]  eta: 0:11:22  Lr: 0.030000  Loss: -0.0575  Acc@1: 75.0000 (70.6839)  Acc@5: 100.0000 (97.7167)  time: 0.3435  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [1780/3750]  eta: 0:11:18  Lr: 0.030000  Loss: -0.2058  Acc@1: 75.0000 (70.7117)  Acc@5: 100.0000 (97.7260)  time: 0.3433  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [1790/3750]  eta: 0:11:15  Lr: 0.030000  Loss: -0.0891  Acc@1: 75.0000 (70.7286)  Acc@5: 100.0000 (97.7282)  time: 0.3432  data: 0.0002  max mem: 2502
Train: Epoch[4/5]  [1800/3750]  eta: 0:11:11  Lr: 0.030000  Loss: 0.1037  Acc@1: 68.7500 (70.7315)  Acc@5: 100.0000 (97.7374)  time: 0.3428  data: 0.0002  max mem: 2502
Train: Epoch[4/5]  [1810/3750]  eta: 0:11:08  Lr: 0.030000  Loss: 0.0708  Acc@1: 68.7500 (70.7344)  Acc@5: 100.0000 (97.7326)  time: 0.3426  data: 0.0002  max mem: 2502
Train: Epoch[4/5]  [1820/3750]  eta: 0:11:05  Lr: 0.030000  Loss: -0.1492  Acc@1: 75.0000 (70.7407)  Acc@5: 100.0000 (97.7313)  time: 0.3442  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [1830/3750]  eta: 0:11:01  Lr: 0.030000  Loss: -0.1531  Acc@1: 75.0000 (70.7503)  Acc@5: 100.0000 (97.7301)  time: 0.3448  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [1840/3750]  eta: 0:10:58  Lr: 0.030000  Loss: -0.2186  Acc@1: 75.0000 (70.7801)  Acc@5: 100.0000 (97.7356)  time: 0.3445  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [1850/3750]  eta: 0:10:54  Lr: 0.030000  Loss: -0.0073  Acc@1: 81.2500 (70.8131)  Acc@5: 100.0000 (97.7411)  time: 0.3450  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [1860/3750]  eta: 0:10:51  Lr: 0.030000  Loss: 0.0863  Acc@1: 75.0000 (70.8020)  Acc@5: 100.0000 (97.7398)  time: 0.3442  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [1870/3750]  eta: 0:10:47  Lr: 0.030000  Loss: -0.0857  Acc@1: 68.7500 (70.8111)  Acc@5: 100.0000 (97.7352)  time: 0.3440  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [1880/3750]  eta: 0:10:44  Lr: 0.030000  Loss: 0.2410  Acc@1: 68.7500 (70.7935)  Acc@5: 100.0000 (97.7439)  time: 0.3443  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [1890/3750]  eta: 0:10:40  Lr: 0.030000  Loss: 0.1706  Acc@1: 68.7500 (70.7827)  Acc@5: 100.0000 (97.7360)  time: 0.3456  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [1900/3750]  eta: 0:10:37  Lr: 0.030000  Loss: 0.0012  Acc@1: 68.7500 (70.7687)  Acc@5: 93.7500 (97.7183)  time: 0.3445  data: 0.0002  max mem: 2502
Train: Epoch[4/5]  [1910/3750]  eta: 0:10:34  Lr: 0.030000  Loss: 0.0643  Acc@1: 68.7500 (70.7843)  Acc@5: 100.0000 (97.7302)  time: 0.3424  data: 0.0002  max mem: 2502
Train: Epoch[4/5]  [1920/3750]  eta: 0:10:30  Lr: 0.030000  Loss: 0.0722  Acc@1: 75.0000 (70.7867)  Acc@5: 100.0000 (97.7356)  time: 0.3426  data: 0.0002  max mem: 2502
Train: Epoch[4/5]  [1930/3750]  eta: 0:10:27  Lr: 0.030000  Loss: 0.1574  Acc@1: 68.7500 (70.7535)  Acc@5: 100.0000 (97.7246)  time: 0.3426  data: 0.0002  max mem: 2502
Train: Epoch[4/5]  [1940/3750]  eta: 0:10:23  Lr: 0.030000  Loss: -0.0701  Acc@1: 68.7500 (70.7561)  Acc@5: 100.0000 (97.7299)  time: 0.3426  data: 0.0002  max mem: 2502
Train: Epoch[4/5]  [1950/3750]  eta: 0:10:20  Lr: 0.030000  Loss: 0.3591  Acc@1: 68.7500 (70.7490)  Acc@5: 100.0000 (97.7255)  time: 0.3425  data: 0.0002  max mem: 2502
Train: Epoch[4/5]  [1960/3750]  eta: 0:10:16  Lr: 0.030000  Loss: -0.0290  Acc@1: 68.7500 (70.7324)  Acc@5: 100.0000 (97.7276)  time: 0.3427  data: 0.0002  max mem: 2502
Train: Epoch[4/5]  [1970/3750]  eta: 0:10:13  Lr: 0.030000  Loss: 0.2805  Acc@1: 68.7500 (70.6970)  Acc@5: 100.0000 (97.7201)  time: 0.3426  data: 0.0002  max mem: 2502
Train: Epoch[4/5]  [1980/3750]  eta: 0:10:09  Lr: 0.030000  Loss: 0.0092  Acc@1: 68.7500 (70.7124)  Acc@5: 100.0000 (97.7190)  time: 0.3425  data: 0.0002  max mem: 2502
Train: Epoch[4/5]  [1990/3750]  eta: 0:10:06  Lr: 0.030000  Loss: 0.1448  Acc@1: 75.0000 (70.7402)  Acc@5: 100.0000 (97.7147)  time: 0.3440  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [2000/3750]  eta: 0:10:02  Lr: 0.030000  Loss: -0.0479  Acc@1: 81.2500 (70.7677)  Acc@5: 100.0000 (97.7168)  time: 0.3455  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [2010/3750]  eta: 0:09:59  Lr: 0.030000  Loss: 0.2074  Acc@1: 75.0000 (70.7453)  Acc@5: 100.0000 (97.7001)  time: 0.3456  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [2020/3750]  eta: 0:09:56  Lr: 0.030000  Loss: -0.0511  Acc@1: 62.5000 (70.7261)  Acc@5: 100.0000 (97.7023)  time: 0.3457  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [2030/3750]  eta: 0:09:52  Lr: 0.030000  Loss: 0.2440  Acc@1: 68.7500 (70.7226)  Acc@5: 100.0000 (97.7074)  time: 0.3459  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [2040/3750]  eta: 0:09:49  Lr: 0.030000  Loss: -0.1357  Acc@1: 68.7500 (70.7404)  Acc@5: 100.0000 (97.7033)  time: 0.3450  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [2050/3750]  eta: 0:09:45  Lr: 0.030000  Loss: -0.1519  Acc@1: 68.7500 (70.7003)  Acc@5: 100.0000 (97.7084)  time: 0.3447  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [2060/3750]  eta: 0:09:42  Lr: 0.030000  Loss: 0.1031  Acc@1: 68.7500 (70.7181)  Acc@5: 100.0000 (97.7135)  time: 0.3453  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [2070/3750]  eta: 0:09:38  Lr: 0.030000  Loss: -0.0164  Acc@1: 75.0000 (70.7267)  Acc@5: 100.0000 (97.7155)  time: 0.3451  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [2080/3750]  eta: 0:09:35  Lr: 0.030000  Loss: 0.0669  Acc@1: 68.7500 (70.7322)  Acc@5: 100.0000 (97.7174)  time: 0.3454  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [2090/3750]  eta: 0:09:31  Lr: 0.030000  Loss: -0.0755  Acc@1: 68.7500 (70.7287)  Acc@5: 100.0000 (97.7254)  time: 0.3470  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [2100/3750]  eta: 0:09:28  Lr: 0.030000  Loss: -0.0291  Acc@1: 68.7500 (70.7461)  Acc@5: 100.0000 (97.7213)  time: 0.3459  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [2110/3750]  eta: 0:09:25  Lr: 0.030000  Loss: -0.4178  Acc@1: 68.7500 (70.7514)  Acc@5: 100.0000 (97.7203)  time: 0.3453  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [2120/3750]  eta: 0:09:21  Lr: 0.030000  Loss: 0.0115  Acc@1: 75.0000 (70.7715)  Acc@5: 100.0000 (97.7251)  time: 0.3460  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [2130/3750]  eta: 0:09:18  Lr: 0.030000  Loss: -0.0239  Acc@1: 75.0000 (70.7972)  Acc@5: 100.0000 (97.7211)  time: 0.3456  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [2140/3750]  eta: 0:09:14  Lr: 0.030000  Loss: 0.2122  Acc@1: 75.0000 (70.8022)  Acc@5: 100.0000 (97.7230)  time: 0.3454  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [2150/3750]  eta: 0:09:11  Lr: 0.030000  Loss: -0.0298  Acc@1: 68.7500 (70.7897)  Acc@5: 100.0000 (97.7249)  time: 0.3452  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [2160/3750]  eta: 0:09:07  Lr: 0.030000  Loss: 0.2136  Acc@1: 68.7500 (70.7832)  Acc@5: 100.0000 (97.7267)  time: 0.3483  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [2170/3750]  eta: 0:09:04  Lr: 0.030000  Loss: -0.0972  Acc@1: 68.7500 (70.7796)  Acc@5: 100.0000 (97.7257)  time: 0.3482  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [2180/3750]  eta: 0:09:01  Lr: 0.030000  Loss: -0.0166  Acc@1: 68.7500 (70.7732)  Acc@5: 100.0000 (97.7275)  time: 0.3449  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [2190/3750]  eta: 0:08:57  Lr: 0.030000  Loss: 0.0401  Acc@1: 68.7500 (70.7725)  Acc@5: 100.0000 (97.7236)  time: 0.3448  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [2200/3750]  eta: 0:08:54  Lr: 0.030000  Loss: 0.0065  Acc@1: 68.7500 (70.7661)  Acc@5: 100.0000 (97.7283)  time: 0.3453  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [2210/3750]  eta: 0:08:50  Lr: 0.030000  Loss: -0.1595  Acc@1: 75.0000 (70.8079)  Acc@5: 100.0000 (97.7329)  time: 0.3453  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [2220/3750]  eta: 0:08:47  Lr: 0.030000  Loss: 0.2401  Acc@1: 75.0000 (70.8127)  Acc@5: 100.0000 (97.7403)  time: 0.3449  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [2230/3750]  eta: 0:08:43  Lr: 0.030000  Loss: 0.0318  Acc@1: 68.7500 (70.8231)  Acc@5: 100.0000 (97.7364)  time: 0.3449  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [2240/3750]  eta: 0:08:40  Lr: 0.030000  Loss: 0.1725  Acc@1: 68.7500 (70.8082)  Acc@5: 93.7500 (97.7270)  time: 0.3440  data: 0.0002  max mem: 2502
Train: Epoch[4/5]  [2250/3750]  eta: 0:08:36  Lr: 0.030000  Loss: 0.0365  Acc@1: 68.7500 (70.8102)  Acc@5: 100.0000 (97.7316)  time: 0.3431  data: 0.0002  max mem: 2502
Train: Epoch[4/5]  [2260/3750]  eta: 0:08:33  Lr: 0.030000  Loss: 0.0372  Acc@1: 75.0000 (70.8149)  Acc@5: 100.0000 (97.7305)  time: 0.3434  data: 0.0002  max mem: 2502
Train: Epoch[4/5]  [2270/3750]  eta: 0:08:30  Lr: 0.030000  Loss: 0.3842  Acc@1: 68.7500 (70.8003)  Acc@5: 100.0000 (97.7240)  time: 0.3446  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [2280/3750]  eta: 0:08:26  Lr: 0.030000  Loss: 0.2471  Acc@1: 68.7500 (70.8215)  Acc@5: 100.0000 (97.7313)  time: 0.3459  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [2290/3750]  eta: 0:08:23  Lr: 0.030000  Loss: -0.1879  Acc@1: 68.7500 (70.8179)  Acc@5: 100.0000 (97.7275)  time: 0.3453  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [2300/3750]  eta: 0:08:19  Lr: 0.030000  Loss: 0.1951  Acc@1: 68.7500 (70.8360)  Acc@5: 100.0000 (97.7320)  time: 0.3453  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [2310/3750]  eta: 0:08:16  Lr: 0.030000  Loss: 0.2084  Acc@1: 68.7500 (70.8000)  Acc@5: 100.0000 (97.7283)  time: 0.3458  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [2320/3750]  eta: 0:08:12  Lr: 0.030000  Loss: 0.1131  Acc@1: 68.7500 (70.7992)  Acc@5: 100.0000 (97.7327)  time: 0.3454  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [2330/3750]  eta: 0:08:09  Lr: 0.030000  Loss: 0.2099  Acc@1: 68.7500 (70.7931)  Acc@5: 100.0000 (97.7343)  time: 0.3453  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [2340/3750]  eta: 0:08:05  Lr: 0.030000  Loss: -0.2425  Acc@1: 68.7500 (70.7977)  Acc@5: 100.0000 (97.7280)  time: 0.3458  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [2350/3750]  eta: 0:08:02  Lr: 0.030000  Loss: 0.0184  Acc@1: 75.0000 (70.8183)  Acc@5: 100.0000 (97.7297)  time: 0.3455  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [2360/3750]  eta: 0:07:59  Lr: 0.030000  Loss: 0.0939  Acc@1: 75.0000 (70.8148)  Acc@5: 100.0000 (97.7261)  time: 0.3445  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [2370/3750]  eta: 0:07:55  Lr: 0.030000  Loss: -0.0508  Acc@1: 68.7500 (70.8193)  Acc@5: 100.0000 (97.7330)  time: 0.3442  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [2380/3750]  eta: 0:07:52  Lr: 0.030000  Loss: 0.0595  Acc@1: 68.7500 (70.8211)  Acc@5: 100.0000 (97.7347)  time: 0.3438  data: 0.0002  max mem: 2502
Train: Epoch[4/5]  [2390/3750]  eta: 0:07:48  Lr: 0.030000  Loss: 0.1875  Acc@1: 68.7500 (70.8072)  Acc@5: 100.0000 (97.7311)  time: 0.3450  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [2400/3750]  eta: 0:07:45  Lr: 0.030000  Loss: 0.0940  Acc@1: 68.7500 (70.8090)  Acc@5: 100.0000 (97.7249)  time: 0.3458  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [2410/3750]  eta: 0:07:41  Lr: 0.030000  Loss: 0.0517  Acc@1: 68.7500 (70.7901)  Acc@5: 100.0000 (97.7266)  time: 0.3455  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [2420/3750]  eta: 0:07:38  Lr: 0.030000  Loss: -0.2573  Acc@1: 68.7500 (70.7869)  Acc@5: 100.0000 (97.7308)  time: 0.3460  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [2430/3750]  eta: 0:07:34  Lr: 0.030000  Loss: -0.0021  Acc@1: 68.7500 (70.7733)  Acc@5: 100.0000 (97.7273)  time: 0.3457  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [2440/3750]  eta: 0:07:31  Lr: 0.030000  Loss: -0.1080  Acc@1: 75.0000 (70.7932)  Acc@5: 100.0000 (97.7263)  time: 0.3449  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [2450/3750]  eta: 0:07:28  Lr: 0.030000  Loss: 0.4136  Acc@1: 75.0000 (70.7900)  Acc@5: 93.7500 (97.7178)  time: 0.3445  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [2460/3750]  eta: 0:07:24  Lr: 0.030000  Loss: 0.2114  Acc@1: 68.7500 (70.7792)  Acc@5: 100.0000 (97.7220)  time: 0.3460  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [2470/3750]  eta: 0:07:21  Lr: 0.030000  Loss: -0.3037  Acc@1: 68.7500 (70.7912)  Acc@5: 100.0000 (97.7236)  time: 0.3467  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [2480/3750]  eta: 0:07:17  Lr: 0.030000  Loss: 0.1179  Acc@1: 68.7500 (70.7779)  Acc@5: 100.0000 (97.7277)  time: 0.3461  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [2490/3750]  eta: 0:07:14  Lr: 0.030000  Loss: 0.0190  Acc@1: 68.7500 (70.7648)  Acc@5: 100.0000 (97.7293)  time: 0.3462  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [2500/3750]  eta: 0:07:10  Lr: 0.030000  Loss: -0.1213  Acc@1: 68.7500 (70.7667)  Acc@5: 100.0000 (97.7309)  time: 0.3457  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [2510/3750]  eta: 0:07:07  Lr: 0.030000  Loss: 0.2838  Acc@1: 75.0000 (70.7761)  Acc@5: 100.0000 (97.7350)  time: 0.3453  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [2520/3750]  eta: 0:07:03  Lr: 0.030000  Loss: 0.1883  Acc@1: 75.0000 (70.7780)  Acc@5: 100.0000 (97.7291)  time: 0.3456  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [2530/3750]  eta: 0:07:00  Lr: 0.030000  Loss: 0.2235  Acc@1: 68.7500 (70.7675)  Acc@5: 100.0000 (97.7282)  time: 0.3460  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [2540/3750]  eta: 0:06:57  Lr: 0.030000  Loss: -0.1510  Acc@1: 68.7500 (70.7743)  Acc@5: 100.0000 (97.7322)  time: 0.3449  data: 0.0002  max mem: 2502
Train: Epoch[4/5]  [2550/3750]  eta: 0:06:53  Lr: 0.030000  Loss: 0.3596  Acc@1: 75.0000 (70.7811)  Acc@5: 100.0000 (97.7288)  time: 0.3437  data: 0.0002  max mem: 2502
Train: Epoch[4/5]  [2560/3750]  eta: 0:06:50  Lr: 0.030000  Loss: 0.2233  Acc@1: 68.7500 (70.7780)  Acc@5: 100.0000 (97.7255)  time: 0.3439  data: 0.0002  max mem: 2502
Train: Epoch[4/5]  [2570/3750]  eta: 0:06:46  Lr: 0.030000  Loss: -0.0432  Acc@1: 68.7500 (70.7823)  Acc@5: 100.0000 (97.7295)  time: 0.3443  data: 0.0002  max mem: 2502
Train: Epoch[4/5]  [2580/3750]  eta: 0:06:43  Lr: 0.030000  Loss: 0.0221  Acc@1: 68.7500 (70.7599)  Acc@5: 100.0000 (97.7359)  time: 0.3447  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [2590/3750]  eta: 0:06:39  Lr: 0.030000  Loss: -0.0247  Acc@1: 68.7500 (70.7545)  Acc@5: 100.0000 (97.7398)  time: 0.3457  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [2600/3750]  eta: 0:06:36  Lr: 0.030000  Loss: -0.1326  Acc@1: 75.0000 (70.7781)  Acc@5: 100.0000 (97.7413)  time: 0.3460  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [2610/3750]  eta: 0:06:32  Lr: 0.030000  Loss: -0.1008  Acc@1: 75.0000 (70.7535)  Acc@5: 100.0000 (97.7427)  time: 0.3455  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [2620/3750]  eta: 0:06:29  Lr: 0.030000  Loss: -0.0212  Acc@1: 68.7500 (70.7578)  Acc@5: 100.0000 (97.7370)  time: 0.3457  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [2630/3750]  eta: 0:06:26  Lr: 0.030000  Loss: -0.2590  Acc@1: 75.0000 (70.7929)  Acc@5: 100.0000 (97.7361)  time: 0.3461  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [2640/3750]  eta: 0:06:22  Lr: 0.030000  Loss: -0.0223  Acc@1: 75.0000 (70.7852)  Acc@5: 100.0000 (97.7305)  time: 0.3464  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [2650/3750]  eta: 0:06:19  Lr: 0.030000  Loss: 0.1065  Acc@1: 75.0000 (70.7917)  Acc@5: 100.0000 (97.7296)  time: 0.3463  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [2660/3750]  eta: 0:06:15  Lr: 0.030000  Loss: -0.1958  Acc@1: 75.0000 (70.7864)  Acc@5: 100.0000 (97.7241)  time: 0.3462  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [2670/3750]  eta: 0:06:12  Lr: 0.030000  Loss: 0.0986  Acc@1: 68.7500 (70.7764)  Acc@5: 100.0000 (97.7256)  time: 0.3461  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [2680/3750]  eta: 0:06:08  Lr: 0.030000  Loss: -0.2106  Acc@1: 75.0000 (70.8015)  Acc@5: 100.0000 (97.7294)  time: 0.3451  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [2690/3750]  eta: 0:06:05  Lr: 0.030000  Loss: 0.1065  Acc@1: 68.7500 (70.7892)  Acc@5: 100.0000 (97.7262)  time: 0.3445  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [2700/3750]  eta: 0:06:01  Lr: 0.030000  Loss: -0.0042  Acc@1: 68.7500 (70.7724)  Acc@5: 93.7500 (97.7208)  time: 0.3447  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [2710/3750]  eta: 0:05:58  Lr: 0.030000  Loss: 0.2010  Acc@1: 68.7500 (70.7557)  Acc@5: 100.0000 (97.7222)  time: 0.3446  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [2720/3750]  eta: 0:05:55  Lr: 0.030000  Loss: 0.0678  Acc@1: 68.7500 (70.7415)  Acc@5: 100.0000 (97.7260)  time: 0.3445  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [2730/3750]  eta: 0:05:51  Lr: 0.030000  Loss: -0.1316  Acc@1: 68.7500 (70.7342)  Acc@5: 100.0000 (97.7298)  time: 0.3450  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [2740/3750]  eta: 0:05:48  Lr: 0.030000  Loss: -0.2102  Acc@1: 75.0000 (70.7566)  Acc@5: 100.0000 (97.7335)  time: 0.3443  data: 0.0002  max mem: 2502
Train: Epoch[4/5]  [2750/3750]  eta: 0:05:44  Lr: 0.030000  Loss: 0.2123  Acc@1: 75.0000 (70.7379)  Acc@5: 100.0000 (97.7258)  time: 0.3437  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [2760/3750]  eta: 0:05:41  Lr: 0.030000  Loss: -0.1961  Acc@1: 62.5000 (70.7149)  Acc@5: 100.0000 (97.7205)  time: 0.3439  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [2770/3750]  eta: 0:05:37  Lr: 0.030000  Loss: -0.0964  Acc@1: 68.7500 (70.7168)  Acc@5: 100.0000 (97.7174)  time: 0.3435  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [2780/3750]  eta: 0:05:34  Lr: 0.030000  Loss: -0.0361  Acc@1: 75.0000 (70.7210)  Acc@5: 100.0000 (97.7144)  time: 0.3434  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [2790/3750]  eta: 0:05:30  Lr: 0.030000  Loss: -0.0091  Acc@1: 75.0000 (70.7139)  Acc@5: 93.7500 (97.7047)  time: 0.3431  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [2800/3750]  eta: 0:05:27  Lr: 0.030000  Loss: 0.1394  Acc@1: 68.7500 (70.7158)  Acc@5: 93.7500 (97.7039)  time: 0.3432  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [2810/3750]  eta: 0:05:24  Lr: 0.030000  Loss: 0.1967  Acc@1: 75.0000 (70.7199)  Acc@5: 100.0000 (97.6988)  time: 0.3429  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [2820/3750]  eta: 0:05:20  Lr: 0.030000  Loss: 0.2417  Acc@1: 75.0000 (70.7130)  Acc@5: 100.0000 (97.7003)  time: 0.3424  data: 0.0002  max mem: 2502
Train: Epoch[4/5]  [2830/3750]  eta: 0:05:17  Lr: 0.030000  Loss: -0.0327  Acc@1: 68.7500 (70.6906)  Acc@5: 100.0000 (97.6996)  time: 0.3437  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [2840/3750]  eta: 0:05:13  Lr: 0.030000  Loss: 0.2318  Acc@1: 68.7500 (70.6793)  Acc@5: 100.0000 (97.6989)  time: 0.3449  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [2850/3750]  eta: 0:05:10  Lr: 0.030000  Loss: 0.0665  Acc@1: 75.0000 (70.6879)  Acc@5: 100.0000 (97.6960)  time: 0.3446  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [2860/3750]  eta: 0:05:06  Lr: 0.030000  Loss: -0.0961  Acc@1: 81.2500 (70.7052)  Acc@5: 93.7500 (97.6909)  time: 0.3441  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [2870/3750]  eta: 0:05:03  Lr: 0.030000  Loss: -0.1816  Acc@1: 68.7500 (70.7071)  Acc@5: 100.0000 (97.6903)  time: 0.3445  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [2880/3750]  eta: 0:04:59  Lr: 0.030000  Loss: -0.0138  Acc@1: 68.7500 (70.7155)  Acc@5: 100.0000 (97.6853)  time: 0.3469  data: 0.0006  max mem: 2502
Train: Epoch[4/5]  [2890/3750]  eta: 0:04:56  Lr: 0.030000  Loss: -0.0280  Acc@1: 68.7500 (70.7152)  Acc@5: 100.0000 (97.6868)  time: 0.3469  data: 0.0006  max mem: 2502
Train: Epoch[4/5]  [2900/3750]  eta: 0:04:53  Lr: 0.030000  Loss: 0.0420  Acc@1: 75.0000 (70.7299)  Acc@5: 100.0000 (97.6797)  time: 0.3465  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [2910/3750]  eta: 0:04:49  Lr: 0.030000  Loss: -0.0654  Acc@1: 75.0000 (70.7317)  Acc@5: 100.0000 (97.6812)  time: 0.3465  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [2920/3750]  eta: 0:04:46  Lr: 0.030000  Loss: 0.3795  Acc@1: 68.7500 (70.7292)  Acc@5: 100.0000 (97.6806)  time: 0.3450  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [2930/3750]  eta: 0:04:42  Lr: 0.030000  Loss: 0.1030  Acc@1: 68.7500 (70.7288)  Acc@5: 100.0000 (97.6757)  time: 0.3446  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [2940/3750]  eta: 0:04:39  Lr: 0.030000  Loss: 0.0907  Acc@1: 68.7500 (70.7221)  Acc@5: 100.0000 (97.6751)  time: 0.3449  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [2950/3750]  eta: 0:04:35  Lr: 0.030000  Loss: 0.1000  Acc@1: 68.7500 (70.7218)  Acc@5: 100.0000 (97.6766)  time: 0.3451  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [2960/3750]  eta: 0:04:32  Lr: 0.030000  Loss: -0.0205  Acc@1: 68.7500 (70.7278)  Acc@5: 100.0000 (97.6824)  time: 0.3445  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [2970/3750]  eta: 0:04:28  Lr: 0.030000  Loss: 0.1423  Acc@1: 68.7500 (70.7317)  Acc@5: 100.0000 (97.6818)  time: 0.3442  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [2980/3750]  eta: 0:04:25  Lr: 0.030000  Loss: -0.0744  Acc@1: 75.0000 (70.7313)  Acc@5: 100.0000 (97.6791)  time: 0.3443  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [2990/3750]  eta: 0:04:21  Lr: 0.030000  Loss: 0.0108  Acc@1: 68.7500 (70.7268)  Acc@5: 100.0000 (97.6805)  time: 0.3447  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [3000/3750]  eta: 0:04:18  Lr: 0.030000  Loss: 0.0316  Acc@1: 68.7500 (70.7160)  Acc@5: 100.0000 (97.6820)  time: 0.3447  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [3010/3750]  eta: 0:04:15  Lr: 0.030000  Loss: -0.0054  Acc@1: 68.7500 (70.7074)  Acc@5: 100.0000 (97.6814)  time: 0.3443  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [3020/3750]  eta: 0:04:11  Lr: 0.030000  Loss: -0.1869  Acc@1: 68.7500 (70.6844)  Acc@5: 100.0000 (97.6808)  time: 0.3447  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [3030/3750]  eta: 0:04:08  Lr: 0.030000  Loss: -0.0943  Acc@1: 68.7500 (70.6801)  Acc@5: 100.0000 (97.6823)  time: 0.3443  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [3040/3750]  eta: 0:04:04  Lr: 0.030000  Loss: -0.1998  Acc@1: 75.0000 (70.6840)  Acc@5: 100.0000 (97.6878)  time: 0.3433  data: 0.0002  max mem: 2502
Train: Epoch[4/5]  [3050/3750]  eta: 0:04:01  Lr: 0.030000  Loss: -0.2191  Acc@1: 68.7500 (70.6879)  Acc@5: 100.0000 (97.6893)  time: 0.3430  data: 0.0002  max mem: 2502
Train: Epoch[4/5]  [3060/3750]  eta: 0:03:57  Lr: 0.030000  Loss: -0.2833  Acc@1: 68.7500 (70.6836)  Acc@5: 100.0000 (97.6907)  time: 0.3428  data: 0.0002  max mem: 2502
Train: Epoch[4/5]  [3070/3750]  eta: 0:03:54  Lr: 0.030000  Loss: -0.1501  Acc@1: 68.7500 (70.7038)  Acc@5: 100.0000 (97.6962)  time: 0.3428  data: 0.0002  max mem: 2502
Train: Epoch[4/5]  [3080/3750]  eta: 0:03:50  Lr: 0.030000  Loss: 0.1432  Acc@1: 68.7500 (70.7015)  Acc@5: 100.0000 (97.6956)  time: 0.3436  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [3090/3750]  eta: 0:03:47  Lr: 0.030000  Loss: 0.0075  Acc@1: 68.7500 (70.7235)  Acc@5: 100.0000 (97.6990)  time: 0.3459  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [3100/3750]  eta: 0:03:44  Lr: 0.030000  Loss: -0.2779  Acc@1: 81.2500 (70.7534)  Acc@5: 100.0000 (97.7024)  time: 0.3456  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [3110/3750]  eta: 0:03:40  Lr: 0.030000  Loss: -0.0494  Acc@1: 81.2500 (70.7670)  Acc@5: 100.0000 (97.6957)  time: 0.3446  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [3120/3750]  eta: 0:03:37  Lr: 0.030000  Loss: 0.3741  Acc@1: 75.0000 (70.7586)  Acc@5: 100.0000 (97.6971)  time: 0.3454  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [3130/3750]  eta: 0:03:33  Lr: 0.030000  Loss: -0.0757  Acc@1: 68.7500 (70.7502)  Acc@5: 100.0000 (97.6984)  time: 0.3449  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [3140/3750]  eta: 0:03:30  Lr: 0.030000  Loss: -0.2228  Acc@1: 68.7500 (70.7597)  Acc@5: 100.0000 (97.6998)  time: 0.3444  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [3150/3750]  eta: 0:03:26  Lr: 0.030000  Loss: 0.0809  Acc@1: 68.7500 (70.7494)  Acc@5: 100.0000 (97.6991)  time: 0.3448  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [3160/3750]  eta: 0:03:23  Lr: 0.030000  Loss: 0.2228  Acc@1: 68.7500 (70.7529)  Acc@5: 100.0000 (97.7005)  time: 0.3455  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [3170/3750]  eta: 0:03:19  Lr: 0.030000  Loss: 0.1605  Acc@1: 68.7500 (70.7584)  Acc@5: 100.0000 (97.6959)  time: 0.3466  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [3180/3750]  eta: 0:03:16  Lr: 0.030000  Loss: 0.2137  Acc@1: 68.7500 (70.7403)  Acc@5: 100.0000 (97.6973)  time: 0.3459  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [3190/3750]  eta: 0:03:13  Lr: 0.030000  Loss: -0.0206  Acc@1: 68.7500 (70.7380)  Acc@5: 100.0000 (97.6986)  time: 0.3445  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [3200/3750]  eta: 0:03:09  Lr: 0.030000  Loss: -0.0117  Acc@1: 68.7500 (70.7338)  Acc@5: 100.0000 (97.7019)  time: 0.3448  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [3210/3750]  eta: 0:03:06  Lr: 0.030000  Loss: -0.0732  Acc@1: 68.7500 (70.7393)  Acc@5: 100.0000 (97.7052)  time: 0.3448  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [3220/3750]  eta: 0:03:02  Lr: 0.030000  Loss: 0.3750  Acc@1: 68.7500 (70.7214)  Acc@5: 100.0000 (97.7045)  time: 0.3445  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [3230/3750]  eta: 0:02:59  Lr: 0.030000  Loss: -0.0494  Acc@1: 68.7500 (70.7192)  Acc@5: 100.0000 (97.7039)  time: 0.3451  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [3240/3750]  eta: 0:02:55  Lr: 0.030000  Loss: -0.0930  Acc@1: 75.0000 (70.7208)  Acc@5: 93.7500 (97.6955)  time: 0.3442  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [3250/3750]  eta: 0:02:52  Lr: 0.030000  Loss: 0.0663  Acc@1: 75.0000 (70.7436)  Acc@5: 100.0000 (97.6969)  time: 0.3425  data: 0.0002  max mem: 2502
Train: Epoch[4/5]  [3260/3750]  eta: 0:02:48  Lr: 0.030000  Loss: -0.2893  Acc@1: 68.7500 (70.7145)  Acc@5: 100.0000 (97.7001)  time: 0.3425  data: 0.0002  max mem: 2502
Train: Epoch[4/5]  [3270/3750]  eta: 0:02:45  Lr: 0.030000  Loss: 0.1103  Acc@1: 62.5000 (70.7009)  Acc@5: 100.0000 (97.7033)  time: 0.3428  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [3280/3750]  eta: 0:02:42  Lr: 0.030000  Loss: 0.0251  Acc@1: 68.7500 (70.6968)  Acc@5: 100.0000 (97.7046)  time: 0.3430  data: 0.0002  max mem: 2502
Train: Epoch[4/5]  [3290/3750]  eta: 0:02:38  Lr: 0.030000  Loss: 0.1664  Acc@1: 68.7500 (70.6928)  Acc@5: 100.0000 (97.6907)  time: 0.3436  data: 0.0002  max mem: 2502
Train: Epoch[4/5]  [3300/3750]  eta: 0:02:35  Lr: 0.030000  Loss: -0.0121  Acc@1: 68.7500 (70.6926)  Acc@5: 100.0000 (97.6939)  time: 0.3442  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [3310/3750]  eta: 0:02:31  Lr: 0.030000  Loss: -0.1568  Acc@1: 75.0000 (70.7169)  Acc@5: 100.0000 (97.6990)  time: 0.3443  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [3320/3750]  eta: 0:02:28  Lr: 0.030000  Loss: 0.0214  Acc@1: 75.0000 (70.7129)  Acc@5: 100.0000 (97.6927)  time: 0.3462  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [3330/3750]  eta: 0:02:24  Lr: 0.030000  Loss: 0.0026  Acc@1: 68.7500 (70.7183)  Acc@5: 100.0000 (97.6940)  time: 0.3474  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [3340/3750]  eta: 0:02:21  Lr: 0.030000  Loss: -0.1226  Acc@1: 68.7500 (70.7124)  Acc@5: 100.0000 (97.6990)  time: 0.3477  data: 0.0006  max mem: 2502
Train: Epoch[4/5]  [3350/3750]  eta: 0:02:17  Lr: 0.030000  Loss: 0.0915  Acc@1: 68.7500 (70.7028)  Acc@5: 100.0000 (97.6984)  time: 0.3468  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [3360/3750]  eta: 0:02:14  Lr: 0.030000  Loss: 0.0887  Acc@1: 68.7500 (70.7025)  Acc@5: 100.0000 (97.7053)  time: 0.3453  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [3370/3750]  eta: 0:02:10  Lr: 0.030000  Loss: -0.0868  Acc@1: 68.7500 (70.7042)  Acc@5: 100.0000 (97.7028)  time: 0.3458  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [3380/3750]  eta: 0:02:07  Lr: 0.030000  Loss: -0.0766  Acc@1: 75.0000 (70.7243)  Acc@5: 93.7500 (97.6967)  time: 0.3454  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [3390/3750]  eta: 0:02:04  Lr: 0.030000  Loss: 0.0514  Acc@1: 75.0000 (70.7203)  Acc@5: 100.0000 (97.6998)  time: 0.3448  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [3400/3750]  eta: 0:02:00  Lr: 0.030000  Loss: 0.0510  Acc@1: 75.0000 (70.7274)  Acc@5: 100.0000 (97.7029)  time: 0.3459  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [3410/3750]  eta: 0:01:57  Lr: 0.030000  Loss: -0.1361  Acc@1: 68.7500 (70.7252)  Acc@5: 100.0000 (97.7041)  time: 0.3458  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [3420/3750]  eta: 0:01:53  Lr: 0.030000  Loss: 0.2003  Acc@1: 68.7500 (70.7140)  Acc@5: 100.0000 (97.7017)  time: 0.3451  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [3430/3750]  eta: 0:01:50  Lr: 0.030000  Loss: -0.1428  Acc@1: 68.7500 (70.7265)  Acc@5: 100.0000 (97.7029)  time: 0.3463  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [3440/3750]  eta: 0:01:46  Lr: 0.030000  Loss: -0.0729  Acc@1: 75.0000 (70.7353)  Acc@5: 100.0000 (97.7042)  time: 0.3453  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [3450/3750]  eta: 0:01:43  Lr: 0.030000  Loss: -0.1069  Acc@1: 68.7500 (70.7241)  Acc@5: 100.0000 (97.7036)  time: 0.3435  data: 0.0002  max mem: 2502
Train: Epoch[4/5]  [3460/3750]  eta: 0:01:39  Lr: 0.030000  Loss: -0.0114  Acc@1: 68.7500 (70.7256)  Acc@5: 100.0000 (97.7084)  time: 0.3434  data: 0.0002  max mem: 2502
Train: Epoch[4/5]  [3470/3750]  eta: 0:01:36  Lr: 0.030000  Loss: 0.1310  Acc@1: 68.7500 (70.7127)  Acc@5: 100.0000 (97.7096)  time: 0.3435  data: 0.0002  max mem: 2502
Train: Epoch[4/5]  [3480/3750]  eta: 0:01:33  Lr: 0.030000  Loss: -0.0118  Acc@1: 62.5000 (70.7053)  Acc@5: 100.0000 (97.7162)  time: 0.3437  data: 0.0002  max mem: 2502
Train: Epoch[4/5]  [3490/3750]  eta: 0:01:29  Lr: 0.030000  Loss: 0.0446  Acc@1: 68.7500 (70.6997)  Acc@5: 100.0000 (97.7156)  time: 0.3446  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [3500/3750]  eta: 0:01:26  Lr: 0.030000  Loss: 0.0100  Acc@1: 68.7500 (70.6869)  Acc@5: 100.0000 (97.7149)  time: 0.3467  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [3510/3750]  eta: 0:01:22  Lr: 0.030000  Loss: 0.0744  Acc@1: 75.0000 (70.7010)  Acc@5: 100.0000 (97.7179)  time: 0.3475  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [3520/3750]  eta: 0:01:19  Lr: 0.030000  Loss: 0.0274  Acc@1: 75.0000 (70.7061)  Acc@5: 100.0000 (97.7208)  time: 0.3467  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [3530/3750]  eta: 0:01:15  Lr: 0.030000  Loss: -0.1185  Acc@1: 75.0000 (70.7254)  Acc@5: 100.0000 (97.7167)  time: 0.3463  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [3540/3750]  eta: 0:01:12  Lr: 0.030000  Loss: 0.0659  Acc@1: 68.7500 (70.7110)  Acc@5: 100.0000 (97.7143)  time: 0.3466  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [3550/3750]  eta: 0:01:08  Lr: 0.030000  Loss: -0.1021  Acc@1: 75.0000 (70.7195)  Acc@5: 100.0000 (97.7172)  time: 0.3459  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [3560/3750]  eta: 0:01:05  Lr: 0.030000  Loss: -0.0329  Acc@1: 68.7500 (70.7087)  Acc@5: 100.0000 (97.7148)  time: 0.3451  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [3570/3750]  eta: 0:01:02  Lr: 0.030000  Loss: 0.1841  Acc@1: 68.7500 (70.7102)  Acc@5: 100.0000 (97.7107)  time: 0.3472  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [3580/3750]  eta: 0:00:58  Lr: 0.030000  Loss: -0.1874  Acc@1: 68.7500 (70.7152)  Acc@5: 100.0000 (97.7066)  time: 0.3469  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [3590/3750]  eta: 0:00:55  Lr: 0.030000  Loss: -0.1227  Acc@1: 75.0000 (70.7237)  Acc@5: 100.0000 (97.7096)  time: 0.3449  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [3600/3750]  eta: 0:00:51  Lr: 0.030000  Loss: -0.0768  Acc@1: 75.0000 (70.7338)  Acc@5: 100.0000 (97.7142)  time: 0.3453  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [3610/3750]  eta: 0:00:48  Lr: 0.030000  Loss: -0.0074  Acc@1: 75.0000 (70.7335)  Acc@5: 100.0000 (97.7153)  time: 0.3445  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [3620/3750]  eta: 0:00:44  Lr: 0.030000  Loss: -0.0784  Acc@1: 68.7500 (70.7315)  Acc@5: 100.0000 (97.7199)  time: 0.3438  data: 0.0002  max mem: 2502
Train: Epoch[4/5]  [3630/3750]  eta: 0:00:41  Lr: 0.030000  Loss: -0.1409  Acc@1: 68.7500 (70.7415)  Acc@5: 100.0000 (97.7227)  time: 0.3435  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [3640/3750]  eta: 0:00:37  Lr: 0.030000  Loss: -0.1603  Acc@1: 75.0000 (70.7464)  Acc@5: 100.0000 (97.7238)  time: 0.3439  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [3650/3750]  eta: 0:00:34  Lr: 0.030000  Loss: -0.0154  Acc@1: 68.7500 (70.7512)  Acc@5: 100.0000 (97.7249)  time: 0.3450  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [3660/3750]  eta: 0:00:31  Lr: 0.030000  Loss: -0.2927  Acc@1: 68.7500 (70.7576)  Acc@5: 100.0000 (97.7260)  time: 0.3454  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [3670/3750]  eta: 0:00:27  Lr: 0.030000  Loss: -0.1267  Acc@1: 68.7500 (70.7505)  Acc@5: 100.0000 (97.7271)  time: 0.3454  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [3680/3750]  eta: 0:00:24  Lr: 0.030000  Loss: 0.2552  Acc@1: 68.7500 (70.7535)  Acc@5: 100.0000 (97.7333)  time: 0.3438  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [3690/3750]  eta: 0:00:20  Lr: 0.030000  Loss: 0.0288  Acc@1: 68.7500 (70.7379)  Acc@5: 100.0000 (97.7259)  time: 0.3438  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [3700/3750]  eta: 0:00:17  Lr: 0.030000  Loss: -0.2171  Acc@1: 62.5000 (70.7326)  Acc@5: 100.0000 (97.7253)  time: 0.3447  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [3710/3750]  eta: 0:00:13  Lr: 0.030000  Loss: 0.0241  Acc@1: 68.7500 (70.7323)  Acc@5: 100.0000 (97.7297)  time: 0.3447  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [3720/3750]  eta: 0:00:10  Lr: 0.030000  Loss: 0.1093  Acc@1: 68.7500 (70.7404)  Acc@5: 100.0000 (97.7274)  time: 0.3451  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [3730/3750]  eta: 0:00:06  Lr: 0.030000  Loss: -0.0405  Acc@1: 75.0000 (70.7535)  Acc@5: 100.0000 (97.7318)  time: 0.3439  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [3740/3750]  eta: 0:00:03  Lr: 0.030000  Loss: 0.0393  Acc@1: 75.0000 (70.7582)  Acc@5: 100.0000 (97.7296)  time: 0.3424  data: 0.0002  max mem: 2502
Train: Epoch[4/5]  [3749/3750]  eta: 0:00:00  Lr: 0.030000  Loss: -0.0890  Acc@1: 75.0000 (70.7617)  Acc@5: 100.0000 (97.7317)  time: 0.3426  data: 0.0005  max mem: 2502
Train: Epoch[4/5] Total time: 0:21:33 (0.3449 s / it)
{0: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 1: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 2: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 3: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 4: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 5: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 6: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 7: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 8: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 9: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 10: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 11: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 12: {0: 0, 1: 0, 2: 0, 3: 91325, 4: 0}, 13: {0: 0, 1: 0, 2: 0, 3: 91325, 4: 0}, 14: {0: 0, 1: 0, 2: 0, 3: 91325, 4: 0}, 15: {0: 0, 1: 0, 2: 0, 3: 91325, 4: 0}, 16: {0: 0, 1: 0, 2: 0, 3: 0, 4: 240000}, 17: {0: 0, 1: 0, 2: 0, 3: 0, 4: 240000}, 18: {0: 0, 1: 0, 2: 0, 3: 0, 4: 240000}, 19: {0: 0, 1: 0, 2: 0, 3: 0, 4: 240000}}
Averaged stats: Lr: 0.030000  Loss: -0.0890  Acc@1: 75.0000 (70.7617)  Acc@5: 100.0000 (97.7317)
Train: Epoch[5/5]  [   0/3750]  eta: 0:36:51  Lr: 0.030000  Loss: -0.1854  Acc@1: 68.7500 (68.7500)  Acc@5: 100.0000 (100.0000)  time: 0.5898  data: 0.2463  max mem: 2502
Train: Epoch[5/5]  [  10/3750]  eta: 0:22:45  Lr: 0.030000  Loss: 0.2333  Acc@1: 68.7500 (69.3182)  Acc@5: 100.0000 (97.1591)  time: 0.3652  data: 0.0226  max mem: 2502
Train: Epoch[5/5]  [  20/3750]  eta: 0:22:01  Lr: 0.030000  Loss: 0.4354  Acc@1: 68.7500 (67.2619)  Acc@5: 93.7500 (95.8333)  time: 0.3425  data: 0.0002  max mem: 2502
Train: Epoch[5/5]  [  30/3750]  eta: 0:21:43  Lr: 0.030000  Loss: 0.1006  Acc@1: 68.7500 (67.7419)  Acc@5: 100.0000 (96.9758)  time: 0.3423  data: 0.0002  max mem: 2502
Train: Epoch[5/5]  [  40/3750]  eta: 0:21:32  Lr: 0.030000  Loss: 0.0251  Acc@1: 68.7500 (69.0549)  Acc@5: 100.0000 (97.2561)  time: 0.3425  data: 0.0002  max mem: 2502
Train: Epoch[5/5]  [  50/3750]  eta: 0:21:26  Lr: 0.030000  Loss: -0.2514  Acc@1: 68.7500 (69.7304)  Acc@5: 100.0000 (97.6716)  time: 0.3437  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [  60/3750]  eta: 0:21:21  Lr: 0.030000  Loss: 0.2318  Acc@1: 68.7500 (70.6967)  Acc@5: 100.0000 (97.6434)  time: 0.3452  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [  70/3750]  eta: 0:21:17  Lr: 0.030000  Loss: 0.0350  Acc@1: 68.7500 (69.8063)  Acc@5: 93.7500 (97.4472)  time: 0.3456  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [  80/3750]  eta: 0:21:13  Lr: 0.030000  Loss: -0.1952  Acc@1: 62.5000 (69.6759)  Acc@5: 100.0000 (97.5309)  time: 0.3453  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [  90/3750]  eta: 0:21:10  Lr: 0.030000  Loss: 0.0325  Acc@1: 68.7500 (70.2610)  Acc@5: 100.0000 (97.6648)  time: 0.3466  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [ 100/3750]  eta: 0:21:05  Lr: 0.030000  Loss: -0.1656  Acc@1: 75.0000 (70.8540)  Acc@5: 100.0000 (97.6485)  time: 0.3464  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [ 110/3750]  eta: 0:21:01  Lr: 0.030000  Loss: -0.2387  Acc@1: 75.0000 (71.4527)  Acc@5: 100.0000 (97.6914)  time: 0.3449  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [ 120/3750]  eta: 0:20:57  Lr: 0.030000  Loss: -0.0362  Acc@1: 75.0000 (71.7975)  Acc@5: 100.0000 (97.7273)  time: 0.3451  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [ 130/3750]  eta: 0:20:54  Lr: 0.030000  Loss: 0.0499  Acc@1: 75.0000 (71.4695)  Acc@5: 100.0000 (97.7576)  time: 0.3458  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [ 140/3750]  eta: 0:20:50  Lr: 0.030000  Loss: 0.0779  Acc@1: 68.7500 (71.4096)  Acc@5: 100.0000 (97.6507)  time: 0.3461  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [ 150/3750]  eta: 0:20:47  Lr: 0.030000  Loss: 0.2455  Acc@1: 68.7500 (71.3576)  Acc@5: 100.0000 (97.6407)  time: 0.3457  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [ 160/3750]  eta: 0:20:43  Lr: 0.030000  Loss: 0.1138  Acc@1: 68.7500 (71.3509)  Acc@5: 100.0000 (97.5932)  time: 0.3458  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [ 170/3750]  eta: 0:20:39  Lr: 0.030000  Loss: 0.1009  Acc@1: 75.0000 (71.6740)  Acc@5: 100.0000 (97.6243)  time: 0.3450  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [ 180/3750]  eta: 0:20:35  Lr: 0.030000  Loss: 0.0050  Acc@1: 75.0000 (71.7196)  Acc@5: 100.0000 (97.7210)  time: 0.3443  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [ 190/3750]  eta: 0:20:31  Lr: 0.030000  Loss: -0.0021  Acc@1: 75.0000 (71.6623)  Acc@5: 100.0000 (97.7094)  time: 0.3442  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [ 200/3750]  eta: 0:20:28  Lr: 0.030000  Loss: 0.0116  Acc@1: 68.7500 (71.7662)  Acc@5: 100.0000 (97.6990)  time: 0.3445  data: 0.0002  max mem: 2502
Train: Epoch[5/5]  [ 210/3750]  eta: 0:20:24  Lr: 0.030000  Loss: -0.2636  Acc@1: 68.7500 (71.6232)  Acc@5: 100.0000 (97.7784)  time: 0.3439  data: 0.0002  max mem: 2502
Train: Epoch[5/5]  [ 220/3750]  eta: 0:20:20  Lr: 0.030000  Loss: -0.3077  Acc@1: 68.7500 (71.4367)  Acc@5: 100.0000 (97.7376)  time: 0.3426  data: 0.0002  max mem: 2502
Train: Epoch[5/5]  [ 230/3750]  eta: 0:20:16  Lr: 0.030000  Loss: -0.0581  Acc@1: 68.7500 (71.3745)  Acc@5: 100.0000 (97.7002)  time: 0.3423  data: 0.0002  max mem: 2502
Train: Epoch[5/5]  [ 240/3750]  eta: 0:20:12  Lr: 0.030000  Loss: -0.0583  Acc@1: 68.7500 (71.4730)  Acc@5: 93.7500 (97.6141)  time: 0.3432  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [ 250/3750]  eta: 0:20:08  Lr: 0.030000  Loss: 0.0923  Acc@1: 68.7500 (71.5886)  Acc@5: 100.0000 (97.6594)  time: 0.3441  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [ 260/3750]  eta: 0:20:05  Lr: 0.030000  Loss: 0.0743  Acc@1: 75.0000 (71.8151)  Acc@5: 100.0000 (97.6772)  time: 0.3450  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [ 270/3750]  eta: 0:20:01  Lr: 0.030000  Loss: 0.1058  Acc@1: 75.0000 (71.7020)  Acc@5: 100.0000 (97.6707)  time: 0.3442  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [ 280/3750]  eta: 0:19:58  Lr: 0.030000  Loss: -0.1155  Acc@1: 68.7500 (71.7082)  Acc@5: 100.0000 (97.7091)  time: 0.3432  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [ 290/3750]  eta: 0:19:54  Lr: 0.030000  Loss: -0.3168  Acc@1: 68.7500 (71.8643)  Acc@5: 100.0000 (97.7234)  time: 0.3441  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [ 300/3750]  eta: 0:19:51  Lr: 0.030000  Loss: -0.2494  Acc@1: 75.0000 (71.9684)  Acc@5: 100.0000 (97.6952)  time: 0.3446  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [ 310/3750]  eta: 0:19:47  Lr: 0.030000  Loss: -0.1191  Acc@1: 75.0000 (71.9654)  Acc@5: 100.0000 (97.7090)  time: 0.3451  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [ 320/3750]  eta: 0:19:43  Lr: 0.030000  Loss: -0.2215  Acc@1: 75.0000 (71.9237)  Acc@5: 100.0000 (97.7220)  time: 0.3441  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [ 330/3750]  eta: 0:19:40  Lr: 0.030000  Loss: -0.0815  Acc@1: 68.7500 (71.8467)  Acc@5: 100.0000 (97.7153)  time: 0.3430  data: 0.0002  max mem: 2502
Train: Epoch[5/5]  [ 340/3750]  eta: 0:19:36  Lr: 0.030000  Loss: -0.0110  Acc@1: 68.7500 (71.7925)  Acc@5: 100.0000 (97.6723)  time: 0.3428  data: 0.0002  max mem: 2502
Train: Epoch[5/5]  [ 350/3750]  eta: 0:19:32  Lr: 0.030000  Loss: -0.0618  Acc@1: 68.7500 (71.8305)  Acc@5: 100.0000 (97.6674)  time: 0.3425  data: 0.0002  max mem: 2502
Train: Epoch[5/5]  [ 360/3750]  eta: 0:19:29  Lr: 0.030000  Loss: -0.2755  Acc@1: 68.7500 (71.9010)  Acc@5: 100.0000 (97.6974)  time: 0.3425  data: 0.0002  max mem: 2502
Train: Epoch[5/5]  [ 370/3750]  eta: 0:19:25  Lr: 0.030000  Loss: -0.1323  Acc@1: 68.7500 (71.9677)  Acc@5: 100.0000 (97.7089)  time: 0.3425  data: 0.0002  max mem: 2502
Train: Epoch[5/5]  [ 380/3750]  eta: 0:19:21  Lr: 0.030000  Loss: 0.1708  Acc@1: 68.7500 (71.8340)  Acc@5: 100.0000 (97.7198)  time: 0.3425  data: 0.0002  max mem: 2502
Train: Epoch[5/5]  [ 390/3750]  eta: 0:19:18  Lr: 0.030000  Loss: 0.0233  Acc@1: 68.7500 (71.8670)  Acc@5: 100.0000 (97.7621)  time: 0.3426  data: 0.0002  max mem: 2502
Train: Epoch[5/5]  [ 400/3750]  eta: 0:19:14  Lr: 0.030000  Loss: 0.2717  Acc@1: 68.7500 (71.7113)  Acc@5: 100.0000 (97.7556)  time: 0.3430  data: 0.0002  max mem: 2502
Train: Epoch[5/5]  [ 410/3750]  eta: 0:19:11  Lr: 0.030000  Loss: 0.1600  Acc@1: 68.7500 (71.8370)  Acc@5: 100.0000 (97.7798)  time: 0.3445  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [ 420/3750]  eta: 0:19:07  Lr: 0.030000  Loss: -0.2592  Acc@1: 75.0000 (71.8082)  Acc@5: 100.0000 (97.7732)  time: 0.3449  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [ 430/3750]  eta: 0:19:04  Lr: 0.030000  Loss: -0.0548  Acc@1: 68.7500 (71.7807)  Acc@5: 100.0000 (97.7958)  time: 0.3452  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [ 440/3750]  eta: 0:19:01  Lr: 0.030000  Loss: -0.0167  Acc@1: 68.7500 (71.7545)  Acc@5: 100.0000 (97.7041)  time: 0.3456  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [ 450/3750]  eta: 0:18:57  Lr: 0.030000  Loss: 0.2224  Acc@1: 75.0000 (71.8126)  Acc@5: 100.0000 (97.7134)  time: 0.3452  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [ 460/3750]  eta: 0:18:54  Lr: 0.030000  Loss: 0.1835  Acc@1: 75.0000 (71.8275)  Acc@5: 100.0000 (97.7088)  time: 0.3459  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [ 470/3750]  eta: 0:18:50  Lr: 0.030000  Loss: -0.1267  Acc@1: 75.0000 (71.9480)  Acc@5: 100.0000 (97.7176)  time: 0.3455  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [ 480/3750]  eta: 0:18:47  Lr: 0.030000  Loss: -0.2542  Acc@1: 81.2500 (72.0634)  Acc@5: 100.0000 (97.7261)  time: 0.3463  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [ 490/3750]  eta: 0:18:44  Lr: 0.030000  Loss: -0.2288  Acc@1: 75.0000 (72.0341)  Acc@5: 100.0000 (97.7597)  time: 0.3472  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [ 500/3750]  eta: 0:18:41  Lr: 0.030000  Loss: 0.1033  Acc@1: 68.7500 (72.0684)  Acc@5: 100.0000 (97.7919)  time: 0.3474  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [ 510/3750]  eta: 0:18:37  Lr: 0.030000  Loss: -0.0865  Acc@1: 75.0000 (72.0401)  Acc@5: 100.0000 (97.7617)  time: 0.3479  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [ 520/3750]  eta: 0:18:34  Lr: 0.030000  Loss: 0.2473  Acc@1: 75.0000 (72.0609)  Acc@5: 100.0000 (97.7927)  time: 0.3475  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [ 530/3750]  eta: 0:18:31  Lr: 0.030000  Loss: -0.0772  Acc@1: 75.0000 (72.1163)  Acc@5: 100.0000 (97.8107)  time: 0.3461  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [ 540/3750]  eta: 0:18:27  Lr: 0.030000  Loss: -0.0443  Acc@1: 75.0000 (72.1003)  Acc@5: 100.0000 (97.8396)  time: 0.3451  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [ 550/3750]  eta: 0:18:24  Lr: 0.030000  Loss: 0.1071  Acc@1: 68.7500 (72.0395)  Acc@5: 100.0000 (97.8562)  time: 0.3454  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [ 560/3750]  eta: 0:18:20  Lr: 0.030000  Loss: 0.1677  Acc@1: 75.0000 (72.0254)  Acc@5: 100.0000 (97.8610)  time: 0.3457  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [ 570/3750]  eta: 0:18:17  Lr: 0.030000  Loss: -0.0655  Acc@1: 75.0000 (72.0994)  Acc@5: 100.0000 (97.8875)  time: 0.3454  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [ 580/3750]  eta: 0:18:13  Lr: 0.030000  Loss: -0.0825  Acc@1: 75.0000 (72.1601)  Acc@5: 100.0000 (97.9131)  time: 0.3454  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [ 590/3750]  eta: 0:18:10  Lr: 0.030000  Loss: -0.0804  Acc@1: 68.7500 (72.1447)  Acc@5: 100.0000 (97.9061)  time: 0.3470  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [ 600/3750]  eta: 0:18:07  Lr: 0.030000  Loss: -0.0947  Acc@1: 68.7500 (72.1922)  Acc@5: 100.0000 (97.9097)  time: 0.3456  data: 0.0002  max mem: 2502
Train: Epoch[5/5]  [ 610/3750]  eta: 0:18:03  Lr: 0.030000  Loss: -0.1432  Acc@1: 75.0000 (72.2586)  Acc@5: 100.0000 (97.9235)  time: 0.3431  data: 0.0002  max mem: 2502
Train: Epoch[5/5]  [ 620/3750]  eta: 0:17:59  Lr: 0.030000  Loss: -0.3439  Acc@1: 75.0000 (72.2122)  Acc@5: 100.0000 (97.8965)  time: 0.3435  data: 0.0002  max mem: 2502
Train: Epoch[5/5]  [ 630/3750]  eta: 0:17:56  Lr: 0.030000  Loss: -0.0127  Acc@1: 68.7500 (72.1771)  Acc@5: 100.0000 (97.8803)  time: 0.3437  data: 0.0002  max mem: 2502
Train: Epoch[5/5]  [ 640/3750]  eta: 0:17:52  Lr: 0.030000  Loss: 0.0869  Acc@1: 68.7500 (72.1139)  Acc@5: 93.7500 (97.8549)  time: 0.3433  data: 0.0002  max mem: 2502
Train: Epoch[5/5]  [ 650/3750]  eta: 0:17:49  Lr: 0.030000  Loss: -0.0746  Acc@1: 75.0000 (72.2158)  Acc@5: 100.0000 (97.8591)  time: 0.3446  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [ 660/3750]  eta: 0:17:46  Lr: 0.030000  Loss: -0.1069  Acc@1: 75.0000 (72.1634)  Acc@5: 100.0000 (97.8725)  time: 0.3466  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [ 670/3750]  eta: 0:17:42  Lr: 0.030000  Loss: 0.1317  Acc@1: 68.7500 (72.0846)  Acc@5: 100.0000 (97.8763)  time: 0.3467  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [ 680/3750]  eta: 0:17:39  Lr: 0.030000  Loss: 0.2079  Acc@1: 62.5000 (72.0081)  Acc@5: 100.0000 (97.8524)  time: 0.3460  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [ 690/3750]  eta: 0:17:36  Lr: 0.030000  Loss: -0.1251  Acc@1: 68.7500 (72.0514)  Acc@5: 100.0000 (97.8383)  time: 0.3468  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [ 700/3750]  eta: 0:17:32  Lr: 0.030000  Loss: 0.0634  Acc@1: 75.0000 (72.0399)  Acc@5: 100.0000 (97.8424)  time: 0.3467  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [ 710/3750]  eta: 0:17:29  Lr: 0.030000  Loss: -0.1540  Acc@1: 68.7500 (72.0113)  Acc@5: 100.0000 (97.8551)  time: 0.3449  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [ 720/3750]  eta: 0:17:25  Lr: 0.030000  Loss: 0.0782  Acc@1: 68.7500 (71.9574)  Acc@5: 100.0000 (97.8502)  time: 0.3453  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [ 730/3750]  eta: 0:17:22  Lr: 0.030000  Loss: -0.1397  Acc@1: 68.7500 (71.9049)  Acc@5: 100.0000 (97.8711)  time: 0.3481  data: 0.0007  max mem: 2502
Train: Epoch[5/5]  [ 740/3750]  eta: 0:17:19  Lr: 0.030000  Loss: 0.3083  Acc@1: 68.7500 (71.9214)  Acc@5: 100.0000 (97.8745)  time: 0.3477  data: 0.0006  max mem: 2502
Train: Epoch[5/5]  [ 750/3750]  eta: 0:17:15  Lr: 0.030000  Loss: -0.1170  Acc@1: 75.0000 (72.0206)  Acc@5: 100.0000 (97.8862)  time: 0.3452  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [ 760/3750]  eta: 0:17:12  Lr: 0.030000  Loss: -0.0115  Acc@1: 75.0000 (72.0023)  Acc@5: 100.0000 (97.8811)  time: 0.3454  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [ 770/3750]  eta: 0:17:08  Lr: 0.030000  Loss: -0.0384  Acc@1: 68.7500 (71.9115)  Acc@5: 100.0000 (97.8761)  time: 0.3451  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [ 780/3750]  eta: 0:17:05  Lr: 0.030000  Loss: 0.2841  Acc@1: 68.7500 (71.9030)  Acc@5: 100.0000 (97.8793)  time: 0.3447  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [ 790/3750]  eta: 0:17:01  Lr: 0.030000  Loss: -0.0639  Acc@1: 75.0000 (71.9580)  Acc@5: 100.0000 (97.8982)  time: 0.3448  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [ 800/3750]  eta: 0:16:58  Lr: 0.030000  Loss: 0.2365  Acc@1: 68.7500 (71.9179)  Acc@5: 100.0000 (97.9089)  time: 0.3440  data: 0.0002  max mem: 2502
Train: Epoch[5/5]  [ 810/3750]  eta: 0:16:54  Lr: 0.030000  Loss: -0.0749  Acc@1: 75.0000 (71.9405)  Acc@5: 100.0000 (97.9269)  time: 0.3430  data: 0.0002  max mem: 2502
Train: Epoch[5/5]  [ 820/3750]  eta: 0:16:51  Lr: 0.030000  Loss: -0.1414  Acc@1: 68.7500 (71.8560)  Acc@5: 100.0000 (97.9065)  time: 0.3431  data: 0.0002  max mem: 2502
Train: Epoch[5/5]  [ 830/3750]  eta: 0:16:47  Lr: 0.030000  Loss: -0.0369  Acc@1: 68.7500 (71.7960)  Acc@5: 100.0000 (97.9016)  time: 0.3437  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [ 840/3750]  eta: 0:16:44  Lr: 0.030000  Loss: -0.0724  Acc@1: 68.7500 (71.8267)  Acc@5: 93.7500 (97.8820)  time: 0.3442  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [ 850/3750]  eta: 0:16:40  Lr: 0.030000  Loss: 0.1459  Acc@1: 75.0000 (71.8713)  Acc@5: 100.0000 (97.8775)  time: 0.3445  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [ 860/3750]  eta: 0:16:37  Lr: 0.030000  Loss: 0.1335  Acc@1: 75.0000 (71.8496)  Acc@5: 100.0000 (97.8586)  time: 0.3451  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [ 870/3750]  eta: 0:16:33  Lr: 0.030000  Loss: -0.0067  Acc@1: 68.7500 (71.8714)  Acc@5: 93.7500 (97.8473)  time: 0.3449  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [ 880/3750]  eta: 0:16:30  Lr: 0.030000  Loss: 0.0408  Acc@1: 75.0000 (71.8998)  Acc@5: 100.0000 (97.8575)  time: 0.3451  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [ 890/3750]  eta: 0:16:26  Lr: 0.030000  Loss: 0.0856  Acc@1: 68.7500 (71.8645)  Acc@5: 100.0000 (97.8676)  time: 0.3450  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [ 900/3750]  eta: 0:16:23  Lr: 0.030000  Loss: -0.0957  Acc@1: 68.7500 (71.8923)  Acc@5: 100.0000 (97.8635)  time: 0.3441  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [ 910/3750]  eta: 0:16:19  Lr: 0.030000  Loss: -0.0957  Acc@1: 75.0000 (71.9539)  Acc@5: 100.0000 (97.8732)  time: 0.3446  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [ 920/3750]  eta: 0:16:16  Lr: 0.030000  Loss: 0.0789  Acc@1: 75.0000 (71.9734)  Acc@5: 100.0000 (97.8624)  time: 0.3446  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [ 930/3750]  eta: 0:16:12  Lr: 0.030000  Loss: 0.0038  Acc@1: 75.0000 (72.0193)  Acc@5: 100.0000 (97.8652)  time: 0.3441  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [ 940/3750]  eta: 0:16:09  Lr: 0.030000  Loss: -0.0526  Acc@1: 68.7500 (72.0178)  Acc@5: 100.0000 (97.8746)  time: 0.3443  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [ 950/3750]  eta: 0:16:05  Lr: 0.030000  Loss: -0.0807  Acc@1: 68.7500 (72.0623)  Acc@5: 100.0000 (97.8707)  time: 0.3433  data: 0.0002  max mem: 2502
Train: Epoch[5/5]  [ 960/3750]  eta: 0:16:02  Lr: 0.030000  Loss: 0.0978  Acc@1: 75.0000 (72.0799)  Acc@5: 100.0000 (97.8668)  time: 0.3422  data: 0.0002  max mem: 2502
Train: Epoch[5/5]  [ 970/3750]  eta: 0:15:58  Lr: 0.030000  Loss: 0.0930  Acc@1: 75.0000 (72.0520)  Acc@5: 100.0000 (97.8502)  time: 0.3425  data: 0.0002  max mem: 2502
Train: Epoch[5/5]  [ 980/3750]  eta: 0:15:55  Lr: 0.030000  Loss: -0.4169  Acc@1: 68.7500 (72.0502)  Acc@5: 100.0000 (97.8466)  time: 0.3425  data: 0.0002  max mem: 2502
Train: Epoch[5/5]  [ 990/3750]  eta: 0:15:51  Lr: 0.030000  Loss: -0.3326  Acc@1: 68.7500 (72.0547)  Acc@5: 100.0000 (97.8368)  time: 0.3432  data: 0.0002  max mem: 2502
Train: Epoch[5/5]  [1000/3750]  eta: 0:15:48  Lr: 0.030000  Loss: -0.1225  Acc@1: 75.0000 (72.0842)  Acc@5: 100.0000 (97.8459)  time: 0.3447  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [1010/3750]  eta: 0:15:45  Lr: 0.030000  Loss: 0.0443  Acc@1: 68.7500 (72.0141)  Acc@5: 100.0000 (97.8487)  time: 0.3447  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [1020/3750]  eta: 0:15:41  Lr: 0.030000  Loss: -0.0735  Acc@1: 68.7500 (72.0556)  Acc@5: 100.0000 (97.8575)  time: 0.3447  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [1030/3750]  eta: 0:15:38  Lr: 0.030000  Loss: -0.0294  Acc@1: 81.2500 (72.0841)  Acc@5: 100.0000 (97.8601)  time: 0.3451  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [1040/3750]  eta: 0:15:34  Lr: 0.030000  Loss: -0.3605  Acc@1: 81.2500 (72.1182)  Acc@5: 100.0000 (97.8446)  time: 0.3449  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [1050/3750]  eta: 0:15:31  Lr: 0.030000  Loss: -0.2391  Acc@1: 75.0000 (72.1039)  Acc@5: 100.0000 (97.8592)  time: 0.3445  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [1060/3750]  eta: 0:15:27  Lr: 0.030000  Loss: -0.0204  Acc@1: 75.0000 (72.1018)  Acc@5: 100.0000 (97.8676)  time: 0.3452  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [1070/3750]  eta: 0:15:24  Lr: 0.030000  Loss: 0.1036  Acc@1: 75.0000 (72.1289)  Acc@5: 100.0000 (97.8583)  time: 0.3458  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [1080/3750]  eta: 0:15:21  Lr: 0.030000  Loss: 0.0840  Acc@1: 68.7500 (72.0860)  Acc@5: 100.0000 (97.8550)  time: 0.3500  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [1090/3750]  eta: 0:15:17  Lr: 0.030000  Loss: 0.0044  Acc@1: 75.0000 (72.1185)  Acc@5: 100.0000 (97.8575)  time: 0.3495  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [1100/3750]  eta: 0:15:14  Lr: 0.030000  Loss: -0.0400  Acc@1: 75.0000 (72.1163)  Acc@5: 100.0000 (97.8599)  time: 0.3444  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [1110/3750]  eta: 0:15:10  Lr: 0.030000  Loss: -0.0547  Acc@1: 75.0000 (72.1760)  Acc@5: 100.0000 (97.8679)  time: 0.3443  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [1120/3750]  eta: 0:15:07  Lr: 0.030000  Loss: -0.1011  Acc@1: 81.2500 (72.2346)  Acc@5: 100.0000 (97.8758)  time: 0.3442  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [1130/3750]  eta: 0:15:03  Lr: 0.030000  Loss: -0.3276  Acc@1: 75.0000 (72.2259)  Acc@5: 100.0000 (97.8835)  time: 0.3440  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [1140/3750]  eta: 0:15:00  Lr: 0.030000  Loss: 0.0955  Acc@1: 68.7500 (72.1900)  Acc@5: 100.0000 (97.8966)  time: 0.3444  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [1150/3750]  eta: 0:14:56  Lr: 0.030000  Loss: 0.1577  Acc@1: 62.5000 (72.1275)  Acc@5: 100.0000 (97.8931)  time: 0.3436  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [1160/3750]  eta: 0:14:53  Lr: 0.030000  Loss: -0.0488  Acc@1: 68.7500 (72.1469)  Acc@5: 100.0000 (97.8951)  time: 0.3424  data: 0.0002  max mem: 2502
Train: Epoch[5/5]  [1170/3750]  eta: 0:14:49  Lr: 0.030000  Loss: -0.2360  Acc@1: 75.0000 (72.1392)  Acc@5: 100.0000 (97.8971)  time: 0.3424  data: 0.0002  max mem: 2502
Train: Epoch[5/5]  [1180/3750]  eta: 0:14:46  Lr: 0.030000  Loss: -0.2723  Acc@1: 68.7500 (72.1475)  Acc@5: 100.0000 (97.8990)  time: 0.3425  data: 0.0002  max mem: 2502
Train: Epoch[5/5]  [1190/3750]  eta: 0:14:42  Lr: 0.030000  Loss: 0.0322  Acc@1: 75.0000 (72.1872)  Acc@5: 100.0000 (97.8852)  time: 0.3436  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [1200/3750]  eta: 0:14:39  Lr: 0.030000  Loss: -0.0466  Acc@1: 75.0000 (72.1690)  Acc@5: 93.7500 (97.8716)  time: 0.3450  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [1210/3750]  eta: 0:14:36  Lr: 0.030000  Loss: 0.0298  Acc@1: 68.7500 (72.1305)  Acc@5: 100.0000 (97.8737)  time: 0.3449  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [1220/3750]  eta: 0:14:32  Lr: 0.030000  Loss: 0.1278  Acc@1: 68.7500 (72.1028)  Acc@5: 100.0000 (97.8757)  time: 0.3451  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [1230/3750]  eta: 0:14:29  Lr: 0.030000  Loss: -0.2966  Acc@1: 68.7500 (72.1517)  Acc@5: 100.0000 (97.8727)  time: 0.3453  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [1240/3750]  eta: 0:14:25  Lr: 0.030000  Loss: -0.2325  Acc@1: 75.0000 (72.1193)  Acc@5: 100.0000 (97.8747)  time: 0.3480  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [1250/3750]  eta: 0:14:22  Lr: 0.030000  Loss: -0.1528  Acc@1: 75.0000 (72.1523)  Acc@5: 100.0000 (97.8867)  time: 0.3478  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [1260/3750]  eta: 0:14:18  Lr: 0.030000  Loss: -0.0977  Acc@1: 75.0000 (72.1501)  Acc@5: 100.0000 (97.8935)  time: 0.3445  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [1270/3750]  eta: 0:14:15  Lr: 0.030000  Loss: 0.0033  Acc@1: 75.0000 (72.1774)  Acc@5: 100.0000 (97.8954)  time: 0.3440  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [1280/3750]  eta: 0:14:11  Lr: 0.030000  Loss: -0.0945  Acc@1: 75.0000 (72.1751)  Acc@5: 100.0000 (97.9069)  time: 0.3435  data: 0.0002  max mem: 2502
Train: Epoch[5/5]  [1290/3750]  eta: 0:14:08  Lr: 0.030000  Loss: -0.2144  Acc@1: 75.0000 (72.1631)  Acc@5: 100.0000 (97.8989)  time: 0.3430  data: 0.0002  max mem: 2502
Train: Epoch[5/5]  [1300/3750]  eta: 0:14:04  Lr: 0.030000  Loss: -0.1522  Acc@1: 68.7500 (72.1272)  Acc@5: 100.0000 (97.9103)  time: 0.3428  data: 0.0002  max mem: 2502
Train: Epoch[5/5]  [1310/3750]  eta: 0:14:01  Lr: 0.030000  Loss: -0.0025  Acc@1: 68.7500 (72.0967)  Acc@5: 100.0000 (97.9024)  time: 0.3439  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [1320/3750]  eta: 0:13:58  Lr: 0.030000  Loss: 0.2576  Acc@1: 68.7500 (72.1139)  Acc@5: 100.0000 (97.9088)  time: 0.3454  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [1330/3750]  eta: 0:13:54  Lr: 0.030000  Loss: -0.0340  Acc@1: 75.0000 (72.1356)  Acc@5: 100.0000 (97.9010)  time: 0.3456  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [1340/3750]  eta: 0:13:51  Lr: 0.030000  Loss: -0.1469  Acc@1: 75.0000 (72.1337)  Acc@5: 100.0000 (97.8980)  time: 0.3443  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [1350/3750]  eta: 0:13:47  Lr: 0.030000  Loss: -0.2132  Acc@1: 75.0000 (72.1826)  Acc@5: 100.0000 (97.9043)  time: 0.3441  data: 0.0002  max mem: 2502
Train: Epoch[5/5]  [1360/3750]  eta: 0:13:44  Lr: 0.030000  Loss: -0.0092  Acc@1: 81.2500 (72.2171)  Acc@5: 100.0000 (97.9151)  time: 0.3447  data: 0.0002  max mem: 2502
Train: Epoch[5/5]  [1370/3750]  eta: 0:13:40  Lr: 0.030000  Loss: -0.0681  Acc@1: 75.0000 (72.1918)  Acc@5: 100.0000 (97.9303)  time: 0.3439  data: 0.0002  max mem: 2502
Train: Epoch[5/5]  [1380/3750]  eta: 0:13:37  Lr: 0.030000  Loss: 0.0439  Acc@1: 68.7500 (72.1760)  Acc@5: 100.0000 (97.9363)  time: 0.3439  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [1390/3750]  eta: 0:13:33  Lr: 0.030000  Loss: -0.0718  Acc@1: 68.7500 (72.1244)  Acc@5: 100.0000 (97.9197)  time: 0.3452  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [1400/3750]  eta: 0:13:30  Lr: 0.030000  Loss: -0.2192  Acc@1: 68.7500 (72.1226)  Acc@5: 100.0000 (97.9300)  time: 0.3461  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [1410/3750]  eta: 0:13:27  Lr: 0.030000  Loss: 0.1303  Acc@1: 68.7500 (72.1297)  Acc@5: 100.0000 (97.9359)  time: 0.3464  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [1420/3750]  eta: 0:13:23  Lr: 0.030000  Loss: -0.2259  Acc@1: 68.7500 (72.0971)  Acc@5: 100.0000 (97.9196)  time: 0.3460  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [1430/3750]  eta: 0:13:20  Lr: 0.030000  Loss: -0.2322  Acc@1: 68.7500 (72.1087)  Acc@5: 100.0000 (97.9254)  time: 0.3458  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [1440/3750]  eta: 0:13:16  Lr: 0.030000  Loss: 0.0615  Acc@1: 68.7500 (72.0810)  Acc@5: 100.0000 (97.9268)  time: 0.3460  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [1450/3750]  eta: 0:13:13  Lr: 0.030000  Loss: 0.3059  Acc@1: 68.7500 (72.0925)  Acc@5: 100.0000 (97.9325)  time: 0.3453  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [1460/3750]  eta: 0:13:09  Lr: 0.030000  Loss: 0.0146  Acc@1: 68.7500 (72.0696)  Acc@5: 100.0000 (97.9252)  time: 0.3442  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [1470/3750]  eta: 0:13:06  Lr: 0.030000  Loss: -0.1243  Acc@1: 75.0000 (72.0981)  Acc@5: 100.0000 (97.9351)  time: 0.3439  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [1480/3750]  eta: 0:13:02  Lr: 0.030000  Loss: -0.0402  Acc@1: 75.0000 (72.0544)  Acc@5: 100.0000 (97.9237)  time: 0.3438  data: 0.0002  max mem: 2502
Train: Epoch[5/5]  [1490/3750]  eta: 0:12:59  Lr: 0.030000  Loss: -0.2166  Acc@1: 75.0000 (72.0951)  Acc@5: 100.0000 (97.9376)  time: 0.3438  data: 0.0002  max mem: 2502
Train: Epoch[5/5]  [1500/3750]  eta: 0:12:55  Lr: 0.030000  Loss: -0.0672  Acc@1: 75.0000 (72.0936)  Acc@5: 100.0000 (97.9472)  time: 0.3437  data: 0.0002  max mem: 2502
Train: Epoch[5/5]  [1510/3750]  eta: 0:12:52  Lr: 0.030000  Loss: -0.0434  Acc@1: 68.7500 (72.0922)  Acc@5: 100.0000 (97.9525)  time: 0.3441  data: 0.0002  max mem: 2502
Train: Epoch[5/5]  [1520/3750]  eta: 0:12:49  Lr: 0.030000  Loss: 0.2813  Acc@1: 68.7500 (72.0620)  Acc@5: 100.0000 (97.9495)  time: 0.3457  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [1530/3750]  eta: 0:12:45  Lr: 0.030000  Loss: 0.2361  Acc@1: 68.7500 (72.0322)  Acc@5: 100.0000 (97.9507)  time: 0.3470  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [1540/3750]  eta: 0:12:42  Lr: 0.030000  Loss: 0.2524  Acc@1: 68.7500 (72.0474)  Acc@5: 100.0000 (97.9194)  time: 0.3469  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [1550/3750]  eta: 0:12:38  Lr: 0.030000  Loss: 0.3398  Acc@1: 75.0000 (72.0422)  Acc@5: 93.7500 (97.9167)  time: 0.3461  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [1560/3750]  eta: 0:12:35  Lr: 0.030000  Loss: 0.1213  Acc@1: 75.0000 (72.0492)  Acc@5: 100.0000 (97.9140)  time: 0.3467  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [1570/3750]  eta: 0:12:31  Lr: 0.030000  Loss: -0.1208  Acc@1: 68.7500 (72.0043)  Acc@5: 100.0000 (97.8954)  time: 0.3472  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [1580/3750]  eta: 0:12:28  Lr: 0.030000  Loss: -0.0551  Acc@1: 68.7500 (72.0193)  Acc@5: 100.0000 (97.9088)  time: 0.3458  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [1590/3750]  eta: 0:12:25  Lr: 0.030000  Loss: -0.0707  Acc@1: 68.7500 (72.0027)  Acc@5: 100.0000 (97.9101)  time: 0.3460  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [1600/3750]  eta: 0:12:21  Lr: 0.030000  Loss: -0.2099  Acc@1: 68.7500 (71.9980)  Acc@5: 100.0000 (97.9154)  time: 0.3463  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [1610/3750]  eta: 0:12:18  Lr: 0.030000  Loss: 0.0009  Acc@1: 68.7500 (71.9778)  Acc@5: 100.0000 (97.9244)  time: 0.3454  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [1620/3750]  eta: 0:12:14  Lr: 0.030000  Loss: 0.0729  Acc@1: 68.7500 (71.9386)  Acc@5: 100.0000 (97.9218)  time: 0.3449  data: 0.0002  max mem: 2502
Train: Epoch[5/5]  [1630/3750]  eta: 0:12:11  Lr: 0.030000  Loss: 0.0719  Acc@1: 68.7500 (71.9191)  Acc@5: 100.0000 (97.9192)  time: 0.3446  data: 0.0002  max mem: 2502
Train: Epoch[5/5]  [1640/3750]  eta: 0:12:07  Lr: 0.030000  Loss: 0.0725  Acc@1: 75.0000 (71.9264)  Acc@5: 100.0000 (97.9129)  time: 0.3445  data: 0.0002  max mem: 2502
Train: Epoch[5/5]  [1650/3750]  eta: 0:12:04  Lr: 0.030000  Loss: 0.2963  Acc@1: 75.0000 (71.9261)  Acc@5: 100.0000 (97.9217)  time: 0.3449  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [1660/3750]  eta: 0:12:00  Lr: 0.030000  Loss: 0.0679  Acc@1: 75.0000 (71.9484)  Acc@5: 100.0000 (97.9229)  time: 0.3449  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [1670/3750]  eta: 0:11:57  Lr: 0.030000  Loss: -0.0959  Acc@1: 75.0000 (71.9629)  Acc@5: 100.0000 (97.9204)  time: 0.3439  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [1680/3750]  eta: 0:11:54  Lr: 0.030000  Loss: -0.1537  Acc@1: 75.0000 (71.9810)  Acc@5: 100.0000 (97.9291)  time: 0.3427  data: 0.0002  max mem: 2502
Train: Epoch[5/5]  [1690/3750]  eta: 0:11:50  Lr: 0.030000  Loss: -0.3017  Acc@1: 75.0000 (72.0284)  Acc@5: 100.0000 (97.9339)  time: 0.3426  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [1700/3750]  eta: 0:11:47  Lr: 0.030000  Loss: -0.0178  Acc@1: 75.0000 (72.0312)  Acc@5: 100.0000 (97.9350)  time: 0.3430  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [1710/3750]  eta: 0:11:43  Lr: 0.030000  Loss: -0.2194  Acc@1: 75.0000 (72.0193)  Acc@5: 100.0000 (97.9215)  time: 0.3442  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [1720/3750]  eta: 0:11:40  Lr: 0.030000  Loss: -0.3264  Acc@1: 75.0000 (72.0402)  Acc@5: 100.0000 (97.9300)  time: 0.3463  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [1730/3750]  eta: 0:11:36  Lr: 0.030000  Loss: -0.0536  Acc@1: 75.0000 (72.0429)  Acc@5: 100.0000 (97.9383)  time: 0.3459  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [1740/3750]  eta: 0:11:33  Lr: 0.030000  Loss: -0.0353  Acc@1: 68.7500 (72.0060)  Acc@5: 100.0000 (97.9394)  time: 0.3461  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [1750/3750]  eta: 0:11:29  Lr: 0.030000  Loss: -0.0788  Acc@1: 75.0000 (72.0445)  Acc@5: 100.0000 (97.9369)  time: 0.3462  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [1760/3750]  eta: 0:11:26  Lr: 0.030000  Loss: -0.1526  Acc@1: 75.0000 (72.0400)  Acc@5: 100.0000 (97.9344)  time: 0.3443  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [1770/3750]  eta: 0:11:22  Lr: 0.030000  Loss: -0.0783  Acc@1: 75.0000 (72.0285)  Acc@5: 100.0000 (97.9355)  time: 0.3439  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [1780/3750]  eta: 0:11:19  Lr: 0.030000  Loss: 0.0404  Acc@1: 75.0000 (72.0312)  Acc@5: 100.0000 (97.9366)  time: 0.3439  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [1790/3750]  eta: 0:11:16  Lr: 0.030000  Loss: 0.0317  Acc@1: 68.7500 (72.0268)  Acc@5: 100.0000 (97.9481)  time: 0.3445  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [1800/3750]  eta: 0:11:12  Lr: 0.030000  Loss: 0.0368  Acc@1: 75.0000 (72.0190)  Acc@5: 100.0000 (97.9456)  time: 0.3446  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [1810/3750]  eta: 0:11:09  Lr: 0.030000  Loss: 0.0383  Acc@1: 68.7500 (71.9941)  Acc@5: 100.0000 (97.9362)  time: 0.3445  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [1820/3750]  eta: 0:11:05  Lr: 0.030000  Loss: -0.2954  Acc@1: 68.7500 (72.0003)  Acc@5: 100.0000 (97.9373)  time: 0.3450  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [1830/3750]  eta: 0:11:02  Lr: 0.030000  Loss: -0.1063  Acc@1: 75.0000 (72.0132)  Acc@5: 100.0000 (97.9417)  time: 0.3441  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [1840/3750]  eta: 0:10:58  Lr: 0.030000  Loss: 0.3402  Acc@1: 75.0000 (72.0091)  Acc@5: 93.7500 (97.9155)  time: 0.3430  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [1850/3750]  eta: 0:10:55  Lr: 0.030000  Loss: -0.1059  Acc@1: 75.0000 (72.0354)  Acc@5: 93.7500 (97.9200)  time: 0.3432  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [1860/3750]  eta: 0:10:51  Lr: 0.030000  Loss: -0.0353  Acc@1: 68.7500 (72.0077)  Acc@5: 100.0000 (97.9312)  time: 0.3427  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [1870/3750]  eta: 0:10:48  Lr: 0.030000  Loss: -0.2388  Acc@1: 75.0000 (72.0337)  Acc@5: 100.0000 (97.9189)  time: 0.3422  data: 0.0002  max mem: 2502
Train: Epoch[5/5]  [1880/3750]  eta: 0:10:44  Lr: 0.030000  Loss: -0.3683  Acc@1: 75.0000 (72.0727)  Acc@5: 100.0000 (97.9300)  time: 0.3422  data: 0.0002  max mem: 2502
Train: Epoch[5/5]  [1890/3750]  eta: 0:10:41  Lr: 0.030000  Loss: -0.1286  Acc@1: 75.0000 (72.0783)  Acc@5: 100.0000 (97.9376)  time: 0.3422  data: 0.0002  max mem: 2502
Train: Epoch[5/5]  [1900/3750]  eta: 0:10:37  Lr: 0.030000  Loss: 0.0541  Acc@1: 75.0000 (72.0739)  Acc@5: 100.0000 (97.9386)  time: 0.3429  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [1910/3750]  eta: 0:10:34  Lr: 0.030000  Loss: 0.0008  Acc@1: 68.7500 (72.0304)  Acc@5: 100.0000 (97.9396)  time: 0.3441  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [1920/3750]  eta: 0:10:31  Lr: 0.030000  Loss: -0.1110  Acc@1: 68.7500 (72.0556)  Acc@5: 100.0000 (97.9405)  time: 0.3448  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [1930/3750]  eta: 0:10:27  Lr: 0.030000  Loss: -0.1702  Acc@1: 68.7500 (72.0482)  Acc@5: 100.0000 (97.9415)  time: 0.3450  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [1940/3750]  eta: 0:10:24  Lr: 0.030000  Loss: -0.3932  Acc@1: 68.7500 (72.0634)  Acc@5: 100.0000 (97.9456)  time: 0.3447  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [1950/3750]  eta: 0:10:20  Lr: 0.030000  Loss: -0.1888  Acc@1: 68.7500 (72.0688)  Acc@5: 100.0000 (97.9530)  time: 0.3451  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [1960/3750]  eta: 0:10:17  Lr: 0.030000  Loss: -0.1838  Acc@1: 62.5000 (72.0391)  Acc@5: 100.0000 (97.9539)  time: 0.3455  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [1970/3750]  eta: 0:10:13  Lr: 0.030000  Loss: -0.1233  Acc@1: 75.0000 (72.0510)  Acc@5: 100.0000 (97.9547)  time: 0.3462  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [1980/3750]  eta: 0:10:10  Lr: 0.030000  Loss: -0.1438  Acc@1: 75.0000 (72.0533)  Acc@5: 100.0000 (97.9524)  time: 0.3463  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [1990/3750]  eta: 0:10:06  Lr: 0.030000  Loss: -0.1390  Acc@1: 68.7500 (72.0398)  Acc@5: 100.0000 (97.9502)  time: 0.3457  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [2000/3750]  eta: 0:10:03  Lr: 0.030000  Loss: 0.1768  Acc@1: 68.7500 (72.0484)  Acc@5: 93.7500 (97.9417)  time: 0.3458  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [2010/3750]  eta: 0:10:00  Lr: 0.030000  Loss: 0.0125  Acc@1: 75.0000 (72.0382)  Acc@5: 100.0000 (97.9395)  time: 0.3451  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [2020/3750]  eta: 0:09:56  Lr: 0.030000  Loss: 0.1103  Acc@1: 75.0000 (72.0559)  Acc@5: 100.0000 (97.9342)  time: 0.3500  data: 0.0009  max mem: 2502
Train: Epoch[5/5]  [2030/3750]  eta: 0:09:53  Lr: 0.030000  Loss: 0.0645  Acc@1: 75.0000 (72.0704)  Acc@5: 100.0000 (97.9351)  time: 0.3503  data: 0.0008  max mem: 2502
Train: Epoch[5/5]  [2040/3750]  eta: 0:09:49  Lr: 0.030000  Loss: 0.0684  Acc@1: 68.7500 (72.0541)  Acc@5: 100.0000 (97.9391)  time: 0.3446  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [2050/3750]  eta: 0:09:46  Lr: 0.030000  Loss: -0.2607  Acc@1: 75.0000 (72.0685)  Acc@5: 100.0000 (97.9400)  time: 0.3443  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [2060/3750]  eta: 0:09:42  Lr: 0.030000  Loss: -0.2014  Acc@1: 81.2500 (72.1161)  Acc@5: 100.0000 (97.9500)  time: 0.3447  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [2070/3750]  eta: 0:09:39  Lr: 0.030000  Loss: 0.0695  Acc@1: 75.0000 (72.0938)  Acc@5: 100.0000 (97.9448)  time: 0.3451  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [2080/3750]  eta: 0:09:35  Lr: 0.030000  Loss: -0.1636  Acc@1: 68.7500 (72.1018)  Acc@5: 100.0000 (97.9457)  time: 0.3450  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [2090/3750]  eta: 0:09:32  Lr: 0.030000  Loss: -0.2837  Acc@1: 75.0000 (72.1276)  Acc@5: 100.0000 (97.9495)  time: 0.3449  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [2100/3750]  eta: 0:09:29  Lr: 0.030000  Loss: 0.2310  Acc@1: 75.0000 (72.1026)  Acc@5: 100.0000 (97.9474)  time: 0.3458  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [2110/3750]  eta: 0:09:25  Lr: 0.030000  Loss: -0.2883  Acc@1: 68.7500 (72.0896)  Acc@5: 100.0000 (97.9334)  time: 0.3452  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [2120/3750]  eta: 0:09:22  Lr: 0.030000  Loss: 0.1620  Acc@1: 68.7500 (72.0857)  Acc@5: 93.7500 (97.9255)  time: 0.3436  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [2130/3750]  eta: 0:09:18  Lr: 0.030000  Loss: -0.2873  Acc@1: 68.7500 (72.0847)  Acc@5: 100.0000 (97.9294)  time: 0.3437  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [2140/3750]  eta: 0:09:15  Lr: 0.030000  Loss: -0.1337  Acc@1: 68.7500 (72.0837)  Acc@5: 100.0000 (97.9245)  time: 0.3437  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [2150/3750]  eta: 0:09:11  Lr: 0.030000  Loss: 0.0327  Acc@1: 81.2500 (72.1118)  Acc@5: 100.0000 (97.9312)  time: 0.3434  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [2160/3750]  eta: 0:09:08  Lr: 0.030000  Loss: -0.2693  Acc@1: 81.2500 (72.1281)  Acc@5: 100.0000 (97.9379)  time: 0.3434  data: 0.0002  max mem: 2502
Train: Epoch[5/5]  [2170/3750]  eta: 0:09:04  Lr: 0.030000  Loss: 0.4341  Acc@1: 75.0000 (72.0924)  Acc@5: 100.0000 (97.9330)  time: 0.3436  data: 0.0002  max mem: 2502
Train: Epoch[5/5]  [2180/3750]  eta: 0:09:01  Lr: 0.030000  Loss: 0.0278  Acc@1: 68.7500 (72.1057)  Acc@5: 100.0000 (97.9310)  time: 0.3438  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [2190/3750]  eta: 0:08:57  Lr: 0.030000  Loss: -0.0848  Acc@1: 75.0000 (72.1046)  Acc@5: 100.0000 (97.9233)  time: 0.3436  data: 0.0002  max mem: 2502
Train: Epoch[5/5]  [2200/3750]  eta: 0:08:54  Lr: 0.030000  Loss: -0.0987  Acc@1: 68.7500 (72.0837)  Acc@5: 100.0000 (97.9214)  time: 0.3446  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [2210/3750]  eta: 0:08:51  Lr: 0.030000  Loss: -0.1644  Acc@1: 62.5000 (72.0573)  Acc@5: 100.0000 (97.9251)  time: 0.3457  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [2220/3750]  eta: 0:08:47  Lr: 0.030000  Loss: 0.1473  Acc@1: 75.0000 (72.0762)  Acc@5: 100.0000 (97.9232)  time: 0.3451  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [2230/3750]  eta: 0:08:44  Lr: 0.030000  Loss: -0.0590  Acc@1: 75.0000 (72.0669)  Acc@5: 100.0000 (97.9241)  time: 0.3457  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [2240/3750]  eta: 0:08:40  Lr: 0.030000  Loss: -0.1227  Acc@1: 68.7500 (72.0577)  Acc@5: 100.0000 (97.9222)  time: 0.3467  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [2250/3750]  eta: 0:08:37  Lr: 0.030000  Loss: 0.1125  Acc@1: 68.7500 (72.0402)  Acc@5: 100.0000 (97.9204)  time: 0.3459  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [2260/3750]  eta: 0:08:33  Lr: 0.030000  Loss: -0.2327  Acc@1: 68.7500 (72.0505)  Acc@5: 100.0000 (97.9268)  time: 0.3451  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [2270/3750]  eta: 0:08:30  Lr: 0.030000  Loss: 0.2667  Acc@1: 68.7500 (72.0387)  Acc@5: 100.0000 (97.9167)  time: 0.3457  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [2280/3750]  eta: 0:08:26  Lr: 0.030000  Loss: -0.2800  Acc@1: 75.0000 (72.0627)  Acc@5: 100.0000 (97.9231)  time: 0.3454  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [2290/3750]  eta: 0:08:23  Lr: 0.030000  Loss: -0.0526  Acc@1: 75.0000 (72.0673)  Acc@5: 100.0000 (97.9267)  time: 0.3456  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [2300/3750]  eta: 0:08:20  Lr: 0.030000  Loss: -0.1995  Acc@1: 75.0000 (72.0719)  Acc@5: 100.0000 (97.9221)  time: 0.3458  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [2310/3750]  eta: 0:08:16  Lr: 0.030000  Loss: -0.0546  Acc@1: 68.7500 (72.0576)  Acc@5: 100.0000 (97.9230)  time: 0.3457  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [2320/3750]  eta: 0:08:13  Lr: 0.030000  Loss: -0.0348  Acc@1: 68.7500 (72.0675)  Acc@5: 100.0000 (97.9238)  time: 0.3468  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [2330/3750]  eta: 0:08:09  Lr: 0.030000  Loss: -0.0438  Acc@1: 75.0000 (72.0694)  Acc@5: 100.0000 (97.9193)  time: 0.3459  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [2340/3750]  eta: 0:08:06  Lr: 0.030000  Loss: 0.1540  Acc@1: 68.7500 (72.0472)  Acc@5: 100.0000 (97.9202)  time: 0.3448  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [2350/3750]  eta: 0:08:02  Lr: 0.030000  Loss: -0.1297  Acc@1: 68.7500 (72.0225)  Acc@5: 100.0000 (97.9211)  time: 0.3456  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [2360/3750]  eta: 0:07:59  Lr: 0.030000  Loss: -0.0739  Acc@1: 75.0000 (72.0431)  Acc@5: 100.0000 (97.9220)  time: 0.3462  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [2370/3750]  eta: 0:07:55  Lr: 0.030000  Loss: 0.1223  Acc@1: 75.0000 (72.0239)  Acc@5: 100.0000 (97.9255)  time: 0.3453  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [2380/3750]  eta: 0:07:52  Lr: 0.030000  Loss: 0.1407  Acc@1: 75.0000 (72.0417)  Acc@5: 100.0000 (97.9315)  time: 0.3446  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [2390/3750]  eta: 0:07:49  Lr: 0.030000  Loss: -0.0647  Acc@1: 75.0000 (72.0776)  Acc@5: 100.0000 (97.9350)  time: 0.3445  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [2400/3750]  eta: 0:07:45  Lr: 0.030000  Loss: -0.1276  Acc@1: 75.0000 (72.0689)  Acc@5: 100.0000 (97.9305)  time: 0.3449  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [2410/3750]  eta: 0:07:42  Lr: 0.030000  Loss: 0.1152  Acc@1: 75.0000 (72.0733)  Acc@5: 100.0000 (97.9314)  time: 0.3445  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [2420/3750]  eta: 0:07:38  Lr: 0.030000  Loss: -0.1822  Acc@1: 75.0000 (72.0777)  Acc@5: 100.0000 (97.9373)  time: 0.3438  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [2430/3750]  eta: 0:07:35  Lr: 0.030000  Loss: 0.0387  Acc@1: 75.0000 (72.0897)  Acc@5: 100.0000 (97.9407)  time: 0.3435  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [2440/3750]  eta: 0:07:31  Lr: 0.030000  Loss: -0.0431  Acc@1: 68.7500 (72.0837)  Acc@5: 100.0000 (97.9414)  time: 0.3452  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [2450/3750]  eta: 0:07:28  Lr: 0.030000  Loss: 0.0211  Acc@1: 68.7500 (72.0701)  Acc@5: 100.0000 (97.9396)  time: 0.3461  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [2460/3750]  eta: 0:07:24  Lr: 0.030000  Loss: -0.0776  Acc@1: 62.5000 (72.0464)  Acc@5: 100.0000 (97.9404)  time: 0.3458  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [2470/3750]  eta: 0:07:21  Lr: 0.030000  Loss: -0.1770  Acc@1: 68.7500 (72.0634)  Acc@5: 100.0000 (97.9335)  time: 0.3447  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [2480/3750]  eta: 0:07:18  Lr: 0.030000  Loss: 0.0159  Acc@1: 68.7500 (72.0551)  Acc@5: 100.0000 (97.9293)  time: 0.3432  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [2490/3750]  eta: 0:07:14  Lr: 0.030000  Loss: -0.1889  Acc@1: 68.7500 (72.0519)  Acc@5: 100.0000 (97.9250)  time: 0.3441  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [2500/3750]  eta: 0:07:11  Lr: 0.030000  Loss: -0.0078  Acc@1: 75.0000 (72.0762)  Acc@5: 100.0000 (97.9283)  time: 0.3446  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [2510/3750]  eta: 0:07:07  Lr: 0.030000  Loss: -0.2183  Acc@1: 75.0000 (72.0530)  Acc@5: 100.0000 (97.9341)  time: 0.3454  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [2520/3750]  eta: 0:07:04  Lr: 0.030000  Loss: -0.0363  Acc@1: 68.7500 (72.0423)  Acc@5: 100.0000 (97.9373)  time: 0.3445  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [2530/3750]  eta: 0:07:00  Lr: 0.030000  Loss: -0.1025  Acc@1: 68.7500 (72.0466)  Acc@5: 100.0000 (97.9331)  time: 0.3432  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [2540/3750]  eta: 0:06:57  Lr: 0.030000  Loss: 0.0151  Acc@1: 68.7500 (72.0287)  Acc@5: 100.0000 (97.9314)  time: 0.3434  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [2550/3750]  eta: 0:06:53  Lr: 0.030000  Loss: 0.3618  Acc@1: 68.7500 (72.0232)  Acc@5: 100.0000 (97.9273)  time: 0.3435  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [2560/3750]  eta: 0:06:50  Lr: 0.030000  Loss: -0.0343  Acc@1: 68.7500 (72.0226)  Acc@5: 100.0000 (97.9281)  time: 0.3434  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [2570/3750]  eta: 0:06:46  Lr: 0.030000  Loss: 0.1000  Acc@1: 68.7500 (72.0099)  Acc@5: 100.0000 (97.9288)  time: 0.3435  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [2580/3750]  eta: 0:06:43  Lr: 0.030000  Loss: -0.0825  Acc@1: 68.7500 (71.9900)  Acc@5: 100.0000 (97.9296)  time: 0.3435  data: 0.0002  max mem: 2502
Train: Epoch[5/5]  [2590/3750]  eta: 0:06:40  Lr: 0.030000  Loss: -0.0094  Acc@1: 68.7500 (71.9823)  Acc@5: 100.0000 (97.9279)  time: 0.3442  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [2600/3750]  eta: 0:06:36  Lr: 0.030000  Loss: -0.1820  Acc@1: 68.7500 (71.9843)  Acc@5: 100.0000 (97.9239)  time: 0.3464  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [2610/3750]  eta: 0:06:33  Lr: 0.030000  Loss: 0.0572  Acc@1: 68.7500 (71.9624)  Acc@5: 100.0000 (97.9223)  time: 0.3464  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [2620/3750]  eta: 0:06:29  Lr: 0.030000  Loss: 0.0296  Acc@1: 68.7500 (71.9668)  Acc@5: 100.0000 (97.9183)  time: 0.3453  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [2630/3750]  eta: 0:06:26  Lr: 0.030000  Loss: -0.1569  Acc@1: 68.7500 (71.9641)  Acc@5: 100.0000 (97.9238)  time: 0.3457  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [2640/3750]  eta: 0:06:22  Lr: 0.030000  Loss: -0.0353  Acc@1: 68.7500 (71.9377)  Acc@5: 100.0000 (97.9222)  time: 0.3456  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [2650/3750]  eta: 0:06:19  Lr: 0.030000  Loss: 0.1690  Acc@1: 62.5000 (71.9115)  Acc@5: 100.0000 (97.9230)  time: 0.3452  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [2660/3750]  eta: 0:06:15  Lr: 0.030000  Loss: -0.2434  Acc@1: 68.7500 (71.9185)  Acc@5: 100.0000 (97.9190)  time: 0.3457  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [2670/3750]  eta: 0:06:12  Lr: 0.030000  Loss: -0.2341  Acc@1: 75.0000 (71.9230)  Acc@5: 100.0000 (97.9221)  time: 0.3458  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [2680/3750]  eta: 0:06:09  Lr: 0.030000  Loss: -0.1230  Acc@1: 75.0000 (71.9065)  Acc@5: 100.0000 (97.9275)  time: 0.3448  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [2690/3750]  eta: 0:06:05  Lr: 0.030000  Loss: -0.0919  Acc@1: 75.0000 (71.9156)  Acc@5: 100.0000 (97.9283)  time: 0.3442  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [2700/3750]  eta: 0:06:02  Lr: 0.030000  Loss: -0.2617  Acc@1: 75.0000 (71.9317)  Acc@5: 100.0000 (97.9313)  time: 0.3443  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [2710/3750]  eta: 0:05:58  Lr: 0.030000  Loss: -0.3516  Acc@1: 75.0000 (71.9522)  Acc@5: 100.0000 (97.9366)  time: 0.3454  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [2720/3750]  eta: 0:05:55  Lr: 0.030000  Loss: 0.0970  Acc@1: 75.0000 (71.9519)  Acc@5: 100.0000 (97.9350)  time: 0.3460  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [2730/3750]  eta: 0:05:51  Lr: 0.030000  Loss: 0.0158  Acc@1: 68.7500 (71.9471)  Acc@5: 100.0000 (97.9334)  time: 0.3492  data: 0.0006  max mem: 2502
Train: Epoch[5/5]  [2740/3750]  eta: 0:05:48  Lr: 0.030000  Loss: -0.0009  Acc@1: 68.7500 (71.9491)  Acc@5: 100.0000 (97.9341)  time: 0.3487  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [2750/3750]  eta: 0:05:44  Lr: 0.030000  Loss: 0.0986  Acc@1: 68.7500 (71.9443)  Acc@5: 100.0000 (97.9371)  time: 0.3445  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [2760/3750]  eta: 0:05:41  Lr: 0.030000  Loss: -0.1122  Acc@1: 68.7500 (71.9418)  Acc@5: 100.0000 (97.9333)  time: 0.3451  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [2770/3750]  eta: 0:05:38  Lr: 0.030000  Loss: -0.1982  Acc@1: 75.0000 (71.9573)  Acc@5: 100.0000 (97.9340)  time: 0.3451  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [2780/3750]  eta: 0:05:34  Lr: 0.030000  Loss: -0.2424  Acc@1: 75.0000 (71.9683)  Acc@5: 100.0000 (97.9391)  time: 0.3442  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [2790/3750]  eta: 0:05:31  Lr: 0.030000  Loss: -0.0122  Acc@1: 75.0000 (71.9635)  Acc@5: 100.0000 (97.9353)  time: 0.3442  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [2800/3750]  eta: 0:05:27  Lr: 0.030000  Loss: -0.0266  Acc@1: 68.7500 (71.9654)  Acc@5: 100.0000 (97.9405)  time: 0.3448  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [2810/3750]  eta: 0:05:24  Lr: 0.030000  Loss: -0.1947  Acc@1: 68.7500 (71.9606)  Acc@5: 100.0000 (97.9367)  time: 0.3443  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [2820/3750]  eta: 0:05:20  Lr: 0.030000  Loss: -0.1040  Acc@1: 68.7500 (71.9647)  Acc@5: 100.0000 (97.9307)  time: 0.3433  data: 0.0002  max mem: 2502
Train: Epoch[5/5]  [2830/3750]  eta: 0:05:17  Lr: 0.030000  Loss: -0.1871  Acc@1: 68.7500 (71.9600)  Acc@5: 100.0000 (97.9336)  time: 0.3434  data: 0.0002  max mem: 2502
Train: Epoch[5/5]  [2840/3750]  eta: 0:05:13  Lr: 0.030000  Loss: 0.0485  Acc@1: 68.7500 (71.9531)  Acc@5: 100.0000 (97.9387)  time: 0.3434  data: 0.0002  max mem: 2502
Train: Epoch[5/5]  [2850/3750]  eta: 0:05:10  Lr: 0.030000  Loss: 0.1699  Acc@1: 68.7500 (71.9309)  Acc@5: 100.0000 (97.9349)  time: 0.3432  data: 0.0002  max mem: 2502
Train: Epoch[5/5]  [2860/3750]  eta: 0:05:06  Lr: 0.030000  Loss: 0.1849  Acc@1: 62.5000 (71.9089)  Acc@5: 100.0000 (97.9269)  time: 0.3432  data: 0.0002  max mem: 2502
Train: Epoch[5/5]  [2870/3750]  eta: 0:05:03  Lr: 0.030000  Loss: 0.1344  Acc@1: 68.7500 (71.9087)  Acc@5: 100.0000 (97.9276)  time: 0.3432  data: 0.0002  max mem: 2502
Train: Epoch[5/5]  [2880/3750]  eta: 0:05:00  Lr: 0.030000  Loss: -0.1466  Acc@1: 75.0000 (71.9195)  Acc@5: 93.7500 (97.9152)  time: 0.3438  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [2890/3750]  eta: 0:04:56  Lr: 0.030000  Loss: -0.3492  Acc@1: 75.0000 (71.9280)  Acc@5: 93.7500 (97.9181)  time: 0.3460  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [2900/3750]  eta: 0:04:53  Lr: 0.030000  Loss: 0.2689  Acc@1: 81.2500 (71.9450)  Acc@5: 100.0000 (97.9188)  time: 0.3466  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [2910/3750]  eta: 0:04:49  Lr: 0.030000  Loss: 0.0637  Acc@1: 81.2500 (71.9555)  Acc@5: 100.0000 (97.9238)  time: 0.3450  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [2920/3750]  eta: 0:04:46  Lr: 0.030000  Loss: -0.2704  Acc@1: 68.7500 (71.9574)  Acc@5: 100.0000 (97.9245)  time: 0.3448  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [2930/3750]  eta: 0:04:42  Lr: 0.030000  Loss: 0.2115  Acc@1: 68.7500 (71.9443)  Acc@5: 100.0000 (97.9252)  time: 0.3445  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [2940/3750]  eta: 0:04:39  Lr: 0.030000  Loss: 0.1931  Acc@1: 68.7500 (71.9377)  Acc@5: 100.0000 (97.9195)  time: 0.3444  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [2950/3750]  eta: 0:04:35  Lr: 0.030000  Loss: -0.1426  Acc@1: 75.0000 (71.9650)  Acc@5: 100.0000 (97.9202)  time: 0.3457  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [2960/3750]  eta: 0:04:32  Lr: 0.030000  Loss: -0.2391  Acc@1: 81.2500 (71.9647)  Acc@5: 100.0000 (97.9251)  time: 0.3462  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [2970/3750]  eta: 0:04:29  Lr: 0.030000  Loss: -0.1048  Acc@1: 68.7500 (71.9413)  Acc@5: 100.0000 (97.9258)  time: 0.3455  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [2980/3750]  eta: 0:04:25  Lr: 0.030000  Loss: -0.2979  Acc@1: 68.7500 (71.9473)  Acc@5: 100.0000 (97.9265)  time: 0.3447  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [2990/3750]  eta: 0:04:22  Lr: 0.030000  Loss: -0.0532  Acc@1: 75.0000 (71.9596)  Acc@5: 100.0000 (97.9292)  time: 0.3448  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [3000/3750]  eta: 0:04:18  Lr: 0.030000  Loss: -0.0914  Acc@1: 75.0000 (71.9531)  Acc@5: 100.0000 (97.9319)  time: 0.3456  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [3010/3750]  eta: 0:04:15  Lr: 0.030000  Loss: -0.0643  Acc@1: 75.0000 (71.9611)  Acc@5: 100.0000 (97.9305)  time: 0.3460  data: 0.0006  max mem: 2502
Train: Epoch[5/5]  [3020/3750]  eta: 0:04:11  Lr: 0.030000  Loss: 0.2003  Acc@1: 75.0000 (71.9381)  Acc@5: 100.0000 (97.9332)  time: 0.3455  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [3030/3750]  eta: 0:04:08  Lr: 0.030000  Loss: -0.1463  Acc@1: 68.7500 (71.9296)  Acc@5: 100.0000 (97.9359)  time: 0.3450  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [3040/3750]  eta: 0:04:04  Lr: 0.030000  Loss: -0.1732  Acc@1: 68.7500 (71.9130)  Acc@5: 100.0000 (97.9365)  time: 0.3443  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [3050/3750]  eta: 0:04:01  Lr: 0.030000  Loss: 0.2481  Acc@1: 75.0000 (71.9231)  Acc@5: 100.0000 (97.9392)  time: 0.3444  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [3060/3750]  eta: 0:03:57  Lr: 0.030000  Loss: -0.2548  Acc@1: 75.0000 (71.9434)  Acc@5: 100.0000 (97.9418)  time: 0.3440  data: 0.0002  max mem: 2502
Train: Epoch[5/5]  [3070/3750]  eta: 0:03:54  Lr: 0.030000  Loss: -0.1278  Acc@1: 75.0000 (71.9411)  Acc@5: 100.0000 (97.9404)  time: 0.3430  data: 0.0002  max mem: 2502
Train: Epoch[5/5]  [3080/3750]  eta: 0:03:51  Lr: 0.030000  Loss: -0.1888  Acc@1: 75.0000 (71.9531)  Acc@5: 100.0000 (97.9430)  time: 0.3428  data: 0.0002  max mem: 2502
Train: Epoch[5/5]  [3090/3750]  eta: 0:03:47  Lr: 0.030000  Loss: 0.2251  Acc@1: 68.7500 (71.9306)  Acc@5: 100.0000 (97.9436)  time: 0.3432  data: 0.0002  max mem: 2502
Train: Epoch[5/5]  [3100/3750]  eta: 0:03:44  Lr: 0.030000  Loss: -0.0628  Acc@1: 68.7500 (71.9425)  Acc@5: 100.0000 (97.9382)  time: 0.3440  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [3110/3750]  eta: 0:03:40  Lr: 0.030000  Loss: -0.1014  Acc@1: 75.0000 (71.9523)  Acc@5: 100.0000 (97.9347)  time: 0.3444  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [3120/3750]  eta: 0:03:37  Lr: 0.030000  Loss: 0.1334  Acc@1: 68.7500 (71.9381)  Acc@5: 100.0000 (97.9314)  time: 0.3440  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [3130/3750]  eta: 0:03:33  Lr: 0.030000  Loss: -0.0921  Acc@1: 68.7500 (71.9419)  Acc@5: 100.0000 (97.9320)  time: 0.3436  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [3140/3750]  eta: 0:03:30  Lr: 0.030000  Loss: 0.1552  Acc@1: 75.0000 (71.9496)  Acc@5: 100.0000 (97.9346)  time: 0.3435  data: 0.0002  max mem: 2502
Train: Epoch[5/5]  [3150/3750]  eta: 0:03:26  Lr: 0.030000  Loss: -0.0175  Acc@1: 68.7500 (71.9335)  Acc@5: 100.0000 (97.9253)  time: 0.3434  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [3160/3750]  eta: 0:03:23  Lr: 0.030000  Loss: -0.1511  Acc@1: 68.7500 (71.9215)  Acc@5: 100.0000 (97.9259)  time: 0.3431  data: 0.0002  max mem: 2502
Train: Epoch[5/5]  [3170/3750]  eta: 0:03:20  Lr: 0.030000  Loss: 0.0882  Acc@1: 68.7500 (71.9016)  Acc@5: 100.0000 (97.9226)  time: 0.3433  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [3180/3750]  eta: 0:03:16  Lr: 0.030000  Loss: 0.0532  Acc@1: 68.7500 (71.9055)  Acc@5: 93.7500 (97.9193)  time: 0.3442  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [3190/3750]  eta: 0:03:13  Lr: 0.030000  Loss: -0.1883  Acc@1: 75.0000 (71.9054)  Acc@5: 100.0000 (97.9180)  time: 0.3447  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [3200/3750]  eta: 0:03:09  Lr: 0.030000  Loss: 0.0762  Acc@1: 68.7500 (71.9072)  Acc@5: 100.0000 (97.9167)  time: 0.3444  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [3210/3750]  eta: 0:03:06  Lr: 0.030000  Loss: -0.1081  Acc@1: 75.0000 (71.9130)  Acc@5: 100.0000 (97.9173)  time: 0.3439  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [3220/3750]  eta: 0:03:02  Lr: 0.030000  Loss: 0.0640  Acc@1: 75.0000 (71.9051)  Acc@5: 100.0000 (97.9218)  time: 0.3441  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [3230/3750]  eta: 0:02:59  Lr: 0.030000  Loss: -0.1838  Acc@1: 75.0000 (71.9089)  Acc@5: 100.0000 (97.9225)  time: 0.3438  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [3240/3750]  eta: 0:02:55  Lr: 0.030000  Loss: -0.2031  Acc@1: 75.0000 (71.9242)  Acc@5: 100.0000 (97.9270)  time: 0.3442  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [3250/3750]  eta: 0:02:52  Lr: 0.030000  Loss: -0.0436  Acc@1: 81.2500 (71.9317)  Acc@5: 100.0000 (97.9314)  time: 0.3435  data: 0.0002  max mem: 2502
Train: Epoch[5/5]  [3260/3750]  eta: 0:02:48  Lr: 0.030000  Loss: 0.1994  Acc@1: 75.0000 (71.9143)  Acc@5: 100.0000 (97.9301)  time: 0.3427  data: 0.0002  max mem: 2502
Train: Epoch[5/5]  [3270/3750]  eta: 0:02:45  Lr: 0.030000  Loss: -0.3211  Acc@1: 75.0000 (71.9390)  Acc@5: 100.0000 (97.9345)  time: 0.3431  data: 0.0002  max mem: 2502
Train: Epoch[5/5]  [3280/3750]  eta: 0:02:42  Lr: 0.030000  Loss: -0.0660  Acc@1: 81.2500 (71.9560)  Acc@5: 100.0000 (97.9351)  time: 0.3429  data: 0.0002  max mem: 2502
Train: Epoch[5/5]  [3290/3750]  eta: 0:02:38  Lr: 0.030000  Loss: 0.1725  Acc@1: 75.0000 (71.9500)  Acc@5: 100.0000 (97.9338)  time: 0.3433  data: 0.0002  max mem: 2502
Train: Epoch[5/5]  [3300/3750]  eta: 0:02:35  Lr: 0.030000  Loss: -0.0758  Acc@1: 75.0000 (71.9460)  Acc@5: 100.0000 (97.9343)  time: 0.3444  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [3310/3750]  eta: 0:02:31  Lr: 0.030000  Loss: 0.0427  Acc@1: 62.5000 (71.9231)  Acc@5: 100.0000 (97.9255)  time: 0.3449  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [3320/3750]  eta: 0:02:28  Lr: 0.030000  Loss: -0.1347  Acc@1: 68.7500 (71.9362)  Acc@5: 100.0000 (97.9242)  time: 0.3450  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [3330/3750]  eta: 0:02:24  Lr: 0.030000  Loss: 0.0359  Acc@1: 75.0000 (71.9266)  Acc@5: 100.0000 (97.9248)  time: 0.3450  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [3340/3750]  eta: 0:02:21  Lr: 0.030000  Loss: -0.2274  Acc@1: 75.0000 (71.9395)  Acc@5: 100.0000 (97.9273)  time: 0.3453  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [3350/3750]  eta: 0:02:17  Lr: 0.030000  Loss: -0.1210  Acc@1: 68.7500 (71.9170)  Acc@5: 100.0000 (97.9279)  time: 0.3458  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [3360/3750]  eta: 0:02:14  Lr: 0.030000  Loss: 0.1698  Acc@1: 68.7500 (71.9280)  Acc@5: 100.0000 (97.9340)  time: 0.3451  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [3370/3750]  eta: 0:02:11  Lr: 0.030000  Loss: -0.0671  Acc@1: 75.0000 (71.9408)  Acc@5: 100.0000 (97.9327)  time: 0.3454  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [3380/3750]  eta: 0:02:07  Lr: 0.030000  Loss: 0.2665  Acc@1: 68.7500 (71.9295)  Acc@5: 100.0000 (97.9278)  time: 0.3467  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [3390/3750]  eta: 0:02:04  Lr: 0.030000  Loss: -0.1282  Acc@1: 68.7500 (71.9294)  Acc@5: 100.0000 (97.9302)  time: 0.3463  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [3400/3750]  eta: 0:02:00  Lr: 0.030000  Loss: -0.2158  Acc@1: 75.0000 (71.9347)  Acc@5: 100.0000 (97.9344)  time: 0.3454  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [3410/3750]  eta: 0:01:57  Lr: 0.030000  Loss: -0.0600  Acc@1: 75.0000 (71.9217)  Acc@5: 100.0000 (97.9332)  time: 0.3459  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [3420/3750]  eta: 0:01:53  Lr: 0.030000  Loss: -0.1267  Acc@1: 75.0000 (71.9161)  Acc@5: 100.0000 (97.9301)  time: 0.3462  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [3430/3750]  eta: 0:01:50  Lr: 0.030000  Loss: -0.0715  Acc@1: 75.0000 (71.9196)  Acc@5: 100.0000 (97.9252)  time: 0.3452  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [3440/3750]  eta: 0:01:46  Lr: 0.030000  Loss: 0.0419  Acc@1: 75.0000 (71.9213)  Acc@5: 100.0000 (97.9312)  time: 0.3455  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [3450/3750]  eta: 0:01:43  Lr: 0.030000  Loss: -0.1809  Acc@1: 75.0000 (71.9429)  Acc@5: 100.0000 (97.9336)  time: 0.3464  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [3460/3750]  eta: 0:01:40  Lr: 0.030000  Loss: 0.0444  Acc@1: 75.0000 (71.9355)  Acc@5: 100.0000 (97.9323)  time: 0.3450  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [3470/3750]  eta: 0:01:36  Lr: 0.030000  Loss: -0.1350  Acc@1: 68.7500 (71.9371)  Acc@5: 100.0000 (97.9293)  time: 0.3432  data: 0.0002  max mem: 2502
Train: Epoch[5/5]  [3480/3750]  eta: 0:01:33  Lr: 0.030000  Loss: -0.0720  Acc@1: 68.7500 (71.9280)  Acc@5: 100.0000 (97.9316)  time: 0.3435  data: 0.0002  max mem: 2502
Train: Epoch[5/5]  [3490/3750]  eta: 0:01:29  Lr: 0.030000  Loss: -0.1277  Acc@1: 68.7500 (71.9260)  Acc@5: 100.0000 (97.9358)  time: 0.3437  data: 0.0002  max mem: 2502
Train: Epoch[5/5]  [3500/3750]  eta: 0:01:26  Lr: 0.030000  Loss: -0.0363  Acc@1: 68.7500 (71.9134)  Acc@5: 100.0000 (97.9327)  time: 0.3435  data: 0.0002  max mem: 2502
Train: Epoch[5/5]  [3510/3750]  eta: 0:01:22  Lr: 0.030000  Loss: -0.2355  Acc@1: 68.7500 (71.9151)  Acc@5: 100.0000 (97.9333)  time: 0.3435  data: 0.0002  max mem: 2502
Train: Epoch[5/5]  [3520/3750]  eta: 0:01:19  Lr: 0.030000  Loss: 0.0277  Acc@1: 75.0000 (71.9203)  Acc@5: 100.0000 (97.9392)  time: 0.3435  data: 0.0002  max mem: 2502
Train: Epoch[5/5]  [3530/3750]  eta: 0:01:15  Lr: 0.030000  Loss: -0.0862  Acc@1: 81.2500 (71.9290)  Acc@5: 100.0000 (97.9361)  time: 0.3447  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [3540/3750]  eta: 0:01:12  Lr: 0.030000  Loss: -0.2528  Acc@1: 75.0000 (71.9200)  Acc@5: 100.0000 (97.9278)  time: 0.3456  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [3550/3750]  eta: 0:01:08  Lr: 0.030000  Loss: -0.2247  Acc@1: 75.0000 (71.9234)  Acc@5: 100.0000 (97.9249)  time: 0.3455  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [3560/3750]  eta: 0:01:05  Lr: 0.030000  Loss: 0.1573  Acc@1: 75.0000 (71.9408)  Acc@5: 100.0000 (97.9237)  time: 0.3455  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [3570/3750]  eta: 0:01:02  Lr: 0.030000  Loss: -0.0999  Acc@1: 75.0000 (71.9354)  Acc@5: 100.0000 (97.9173)  time: 0.3452  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [3580/3750]  eta: 0:00:58  Lr: 0.030000  Loss: 0.2817  Acc@1: 68.7500 (71.9247)  Acc@5: 100.0000 (97.9161)  time: 0.3461  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [3590/3750]  eta: 0:00:55  Lr: 0.030000  Loss: 0.4476  Acc@1: 68.7500 (71.9281)  Acc@5: 100.0000 (97.9184)  time: 0.3466  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [3600/3750]  eta: 0:00:51  Lr: 0.030000  Loss: -0.0646  Acc@1: 75.0000 (71.9106)  Acc@5: 100.0000 (97.9190)  time: 0.3464  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [3610/3750]  eta: 0:00:48  Lr: 0.030000  Loss: -0.0918  Acc@1: 68.7500 (71.9122)  Acc@5: 100.0000 (97.9213)  time: 0.3461  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [3620/3750]  eta: 0:00:44  Lr: 0.030000  Loss: -0.0253  Acc@1: 68.7500 (71.8914)  Acc@5: 100.0000 (97.9184)  time: 0.3462  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [3630/3750]  eta: 0:00:41  Lr: 0.030000  Loss: -0.1028  Acc@1: 75.0000 (71.8982)  Acc@5: 100.0000 (97.9224)  time: 0.3466  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [3640/3750]  eta: 0:00:37  Lr: 0.030000  Loss: 0.0762  Acc@1: 68.7500 (71.8982)  Acc@5: 100.0000 (97.9247)  time: 0.3459  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [3650/3750]  eta: 0:00:34  Lr: 0.030000  Loss: -0.2283  Acc@1: 68.7500 (71.8913)  Acc@5: 100.0000 (97.9252)  time: 0.3473  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [3660/3750]  eta: 0:00:31  Lr: 0.030000  Loss: 0.1853  Acc@1: 68.7500 (71.8741)  Acc@5: 100.0000 (97.9224)  time: 0.3470  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [3670/3750]  eta: 0:00:27  Lr: 0.030000  Loss: -0.0271  Acc@1: 68.7500 (71.8776)  Acc@5: 100.0000 (97.9280)  time: 0.3445  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [3680/3750]  eta: 0:00:24  Lr: 0.030000  Loss: -0.2071  Acc@1: 75.0000 (71.8758)  Acc@5: 100.0000 (97.9286)  time: 0.3442  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [3690/3750]  eta: 0:00:20  Lr: 0.030000  Loss: 0.2091  Acc@1: 75.0000 (71.8826)  Acc@5: 100.0000 (97.9291)  time: 0.3445  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [3700/3750]  eta: 0:00:17  Lr: 0.030000  Loss: -0.0497  Acc@1: 75.0000 (71.8894)  Acc@5: 100.0000 (97.9279)  time: 0.3446  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [3710/3750]  eta: 0:00:13  Lr: 0.030000  Loss: -0.0178  Acc@1: 68.7500 (71.8758)  Acc@5: 100.0000 (97.9217)  time: 0.3440  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [3720/3750]  eta: 0:00:10  Lr: 0.030000  Loss: -0.0610  Acc@1: 68.7500 (71.8859)  Acc@5: 100.0000 (97.9206)  time: 0.3442  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [3730/3750]  eta: 0:00:06  Lr: 0.030000  Loss: -0.0964  Acc@1: 68.7500 (71.8641)  Acc@5: 100.0000 (97.9144)  time: 0.3446  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [3740/3750]  eta: 0:00:03  Lr: 0.030000  Loss: 0.2009  Acc@1: 68.7500 (71.8675)  Acc@5: 100.0000 (97.9150)  time: 0.3438  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [3749/3750]  eta: 0:00:00  Lr: 0.030000  Loss: -0.2096  Acc@1: 75.0000 (71.8900)  Acc@5: 100.0000 (97.9150)  time: 0.3435  data: 0.0008  max mem: 2502
Train: Epoch[5/5] Total time: 0:21:33 (0.3450 s / it)
{0: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 1: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 2: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 3: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 4: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 5: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 6: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 7: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 8: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 9: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 10: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 11: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 12: {0: 0, 1: 0, 2: 0, 3: 91325, 4: 0}, 13: {0: 0, 1: 0, 2: 0, 3: 91325, 4: 0}, 14: {0: 0, 1: 0, 2: 0, 3: 91325, 4: 0}, 15: {0: 0, 1: 0, 2: 0, 3: 91325, 4: 0}, 16: {0: 0, 1: 0, 2: 0, 3: 0, 4: 300000}, 17: {0: 0, 1: 0, 2: 0, 3: 0, 4: 300000}, 18: {0: 0, 1: 0, 2: 0, 3: 0, 4: 300000}, 19: {0: 0, 1: 0, 2: 0, 3: 0, 4: 300000}}
Averaged stats: Lr: 0.030000  Loss: -0.2096  Acc@1: 75.0000 (71.8900)  Acc@5: 100.0000 (97.9150)
Test: [Task 1]  [   0/1627]  eta: 0:12:15  Loss: 2.5126 (2.5126)  Acc@1: 87.5000 (87.5000)  Acc@5: 93.7500 (93.7500)  time: 0.4521  data: 0.2391  max mem: 2502
Test: [Task 1]  [  10/1627]  eta: 0:06:18  Loss: 2.4349 (2.4199)  Acc@1: 87.5000 (84.0909)  Acc@5: 93.7500 (96.0227)  time: 0.2344  data: 0.0219  max mem: 2502
Test: [Task 1]  [  20/1627]  eta: 0:06:00  Loss: 2.4324 (2.4459)  Acc@1: 81.2500 (83.0357)  Acc@5: 93.7500 (95.2381)  time: 0.2126  data: 0.0002  max mem: 2502
Test: [Task 1]  [  30/1627]  eta: 0:05:52  Loss: 2.4842 (2.4571)  Acc@1: 81.2500 (82.6613)  Acc@5: 100.0000 (96.1694)  time: 0.2128  data: 0.0002  max mem: 2502
Test: [Task 1]  [  40/1627]  eta: 0:05:46  Loss: 2.5051 (2.4725)  Acc@1: 81.2500 (81.5549)  Acc@5: 100.0000 (96.0366)  time: 0.2129  data: 0.0002  max mem: 2502
Test: [Task 1]  [  50/1627]  eta: 0:05:42  Loss: 2.4413 (2.4654)  Acc@1: 81.2500 (81.7402)  Acc@5: 100.0000 (96.0784)  time: 0.2126  data: 0.0002  max mem: 2502
Test: [Task 1]  [  60/1627]  eta: 0:05:39  Loss: 2.4418 (2.4694)  Acc@1: 81.2500 (81.5574)  Acc@5: 93.7500 (95.5943)  time: 0.2126  data: 0.0002  max mem: 2502
Test: [Task 1]  [  70/1627]  eta: 0:05:36  Loss: 2.4554 (2.4720)  Acc@1: 81.2500 (81.1620)  Acc@5: 93.7500 (95.9507)  time: 0.2128  data: 0.0002  max mem: 2502
Test: [Task 1]  [  80/1627]  eta: 0:05:33  Loss: 2.4176 (2.4695)  Acc@1: 81.2500 (81.4043)  Acc@5: 100.0000 (96.2963)  time: 0.2130  data: 0.0002  max mem: 2502
Test: [Task 1]  [  90/1627]  eta: 0:05:31  Loss: 2.4323 (2.4701)  Acc@1: 81.2500 (80.9753)  Acc@5: 100.0000 (96.0852)  time: 0.2129  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 100/1627]  eta: 0:05:28  Loss: 2.4924 (2.4785)  Acc@1: 75.0000 (80.4455)  Acc@5: 93.7500 (95.8540)  time: 0.2133  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 110/1627]  eta: 0:05:26  Loss: 2.4729 (2.4782)  Acc@1: 81.2500 (80.5743)  Acc@5: 93.7500 (96.0023)  time: 0.2141  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 120/1627]  eta: 0:05:24  Loss: 2.4378 (2.4785)  Acc@1: 87.5000 (80.5785)  Acc@5: 100.0000 (96.0744)  time: 0.2141  data: 0.0004  max mem: 2502
Test: [Task 1]  [ 130/1627]  eta: 0:05:21  Loss: 2.4438 (2.4751)  Acc@1: 87.5000 (80.7252)  Acc@5: 100.0000 (96.0401)  time: 0.2141  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 140/1627]  eta: 0:05:19  Loss: 2.4429 (2.4737)  Acc@1: 81.2500 (80.7624)  Acc@5: 100.0000 (96.1436)  time: 0.2139  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 150/1627]  eta: 0:05:17  Loss: 2.3393 (2.4658)  Acc@1: 87.5000 (81.0430)  Acc@5: 100.0000 (96.1507)  time: 0.2142  data: 0.0004  max mem: 2502
Test: [Task 1]  [ 160/1627]  eta: 0:05:15  Loss: 2.3532 (2.4654)  Acc@1: 87.5000 (81.1724)  Acc@5: 100.0000 (96.3121)  time: 0.2142  data: 0.0004  max mem: 2502
Test: [Task 1]  [ 170/1627]  eta: 0:05:12  Loss: 2.4277 (2.4628)  Acc@1: 87.5000 (81.3596)  Acc@5: 100.0000 (96.4547)  time: 0.2142  data: 0.0004  max mem: 2502
Test: [Task 1]  [ 180/1627]  eta: 0:05:10  Loss: 2.4277 (2.4647)  Acc@1: 81.2500 (81.2155)  Acc@5: 100.0000 (96.4434)  time: 0.2142  data: 0.0004  max mem: 2502
Test: [Task 1]  [ 190/1627]  eta: 0:05:08  Loss: 2.4591 (2.4632)  Acc@1: 81.2500 (81.2500)  Acc@5: 93.7500 (96.4005)  time: 0.2140  data: 0.0004  max mem: 2502
Test: [Task 1]  [ 200/1627]  eta: 0:05:06  Loss: 2.4596 (2.4624)  Acc@1: 81.2500 (81.1256)  Acc@5: 100.0000 (96.4863)  time: 0.2139  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 210/1627]  eta: 0:05:04  Loss: 2.4437 (2.4602)  Acc@1: 81.2500 (81.2796)  Acc@5: 100.0000 (96.4751)  time: 0.2140  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 220/1627]  eta: 0:05:01  Loss: 2.4087 (2.4608)  Acc@1: 81.2500 (81.1086)  Acc@5: 100.0000 (96.5498)  time: 0.2144  data: 0.0004  max mem: 2502
Test: [Task 1]  [ 230/1627]  eta: 0:04:59  Loss: 2.4383 (2.4606)  Acc@1: 81.2500 (81.2771)  Acc@5: 100.0000 (96.4827)  time: 0.2142  data: 0.0004  max mem: 2502
Test: [Task 1]  [ 240/1627]  eta: 0:04:57  Loss: 2.4047 (2.4598)  Acc@1: 81.2500 (81.3537)  Acc@5: 93.7500 (96.4990)  time: 0.2139  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 250/1627]  eta: 0:04:55  Loss: 2.3868 (2.4577)  Acc@1: 81.2500 (81.2749)  Acc@5: 100.0000 (96.4890)  time: 0.2142  data: 0.0004  max mem: 2502
Test: [Task 1]  [ 260/1627]  eta: 0:04:53  Loss: 2.4136 (2.4588)  Acc@1: 81.2500 (81.2979)  Acc@5: 100.0000 (96.4320)  time: 0.2141  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 270/1627]  eta: 0:04:51  Loss: 2.4249 (2.4560)  Acc@1: 87.5000 (81.4345)  Acc@5: 100.0000 (96.4714)  time: 0.2139  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 280/1627]  eta: 0:04:48  Loss: 2.4239 (2.4564)  Acc@1: 81.2500 (81.3167)  Acc@5: 100.0000 (96.4635)  time: 0.2140  data: 0.0004  max mem: 2502
Test: [Task 1]  [ 290/1627]  eta: 0:04:46  Loss: 2.4239 (2.4558)  Acc@1: 81.2500 (81.3789)  Acc@5: 93.7500 (96.4777)  time: 0.2144  data: 0.0004  max mem: 2502
Test: [Task 1]  [ 300/1627]  eta: 0:04:44  Loss: 2.4292 (2.4554)  Acc@1: 81.2500 (81.3331)  Acc@5: 100.0000 (96.4909)  time: 0.2144  data: 0.0004  max mem: 2502
Test: [Task 1]  [ 310/1627]  eta: 0:04:42  Loss: 2.4535 (2.4544)  Acc@1: 81.2500 (81.3907)  Acc@5: 100.0000 (96.4630)  time: 0.2138  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 320/1627]  eta: 0:04:40  Loss: 2.4509 (2.4555)  Acc@1: 81.2500 (81.3863)  Acc@5: 100.0000 (96.5343)  time: 0.2132  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 330/1627]  eta: 0:04:38  Loss: 2.4209 (2.4559)  Acc@1: 81.2500 (81.3444)  Acc@5: 100.0000 (96.5446)  time: 0.2133  data: 0.0002  max mem: 2502
Test: [Task 1]  [ 340/1627]  eta: 0:04:35  Loss: 2.4481 (2.4576)  Acc@1: 81.2500 (81.3600)  Acc@5: 100.0000 (96.5543)  time: 0.2136  data: 0.0002  max mem: 2502
Test: [Task 1]  [ 350/1627]  eta: 0:04:33  Loss: 2.4751 (2.4577)  Acc@1: 81.2500 (81.3568)  Acc@5: 100.0000 (96.5634)  time: 0.2137  data: 0.0002  max mem: 2502
Test: [Task 1]  [ 360/1627]  eta: 0:04:31  Loss: 2.4751 (2.4594)  Acc@1: 81.2500 (81.2327)  Acc@5: 100.0000 (96.5547)  time: 0.2137  data: 0.0002  max mem: 2502
Test: [Task 1]  [ 370/1627]  eta: 0:04:29  Loss: 2.4163 (2.4577)  Acc@1: 81.2500 (81.3342)  Acc@5: 100.0000 (96.5633)  time: 0.2136  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 380/1627]  eta: 0:04:27  Loss: 2.4105 (2.4574)  Acc@1: 81.2500 (81.3812)  Acc@5: 93.7500 (96.5059)  time: 0.2135  data: 0.0002  max mem: 2502
Test: [Task 1]  [ 390/1627]  eta: 0:04:25  Loss: 2.4341 (2.4575)  Acc@1: 81.2500 (81.2500)  Acc@5: 93.7500 (96.4514)  time: 0.2135  data: 0.0002  max mem: 2502
Test: [Task 1]  [ 400/1627]  eta: 0:04:22  Loss: 2.4480 (2.4567)  Acc@1: 75.0000 (81.2812)  Acc@5: 93.7500 (96.4620)  time: 0.2134  data: 0.0002  max mem: 2502
Test: [Task 1]  [ 410/1627]  eta: 0:04:20  Loss: 2.4071 (2.4563)  Acc@1: 81.2500 (81.3260)  Acc@5: 100.0000 (96.4416)  time: 0.2135  data: 0.0002  max mem: 2502
Test: [Task 1]  [ 420/1627]  eta: 0:04:18  Loss: 2.4206 (2.4557)  Acc@1: 81.2500 (81.3836)  Acc@5: 100.0000 (96.4667)  time: 0.2138  data: 0.0002  max mem: 2502
Test: [Task 1]  [ 430/1627]  eta: 0:04:16  Loss: 2.4032 (2.4543)  Acc@1: 81.2500 (81.4240)  Acc@5: 100.0000 (96.4907)  time: 0.2134  data: 0.0002  max mem: 2502
Test: [Task 1]  [ 440/1627]  eta: 0:04:14  Loss: 2.3840 (2.4537)  Acc@1: 81.2500 (81.4059)  Acc@5: 100.0000 (96.4994)  time: 0.2128  data: 0.0002  max mem: 2502
Test: [Task 1]  [ 450/1627]  eta: 0:04:12  Loss: 2.4329 (2.4552)  Acc@1: 81.2500 (81.3193)  Acc@5: 93.7500 (96.4385)  time: 0.2129  data: 0.0002  max mem: 2502
Test: [Task 1]  [ 460/1627]  eta: 0:04:09  Loss: 2.4374 (2.4553)  Acc@1: 81.2500 (81.3313)  Acc@5: 100.0000 (96.4479)  time: 0.2130  data: 0.0002  max mem: 2502
Test: [Task 1]  [ 470/1627]  eta: 0:04:07  Loss: 2.3902 (2.4544)  Acc@1: 87.5000 (81.3827)  Acc@5: 100.0000 (96.4437)  time: 0.2129  data: 0.0002  max mem: 2502
Test: [Task 1]  [ 480/1627]  eta: 0:04:05  Loss: 2.3677 (2.4547)  Acc@1: 81.2500 (81.2630)  Acc@5: 100.0000 (96.4657)  time: 0.2135  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 490/1627]  eta: 0:04:03  Loss: 2.5082 (2.4555)  Acc@1: 81.2500 (81.2755)  Acc@5: 93.7500 (96.4486)  time: 0.2140  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 500/1627]  eta: 0:04:01  Loss: 2.5003 (2.4561)  Acc@1: 81.2500 (81.2375)  Acc@5: 93.7500 (96.3947)  time: 0.2138  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 510/1627]  eta: 0:03:59  Loss: 2.4660 (2.4574)  Acc@1: 81.2500 (81.1766)  Acc@5: 93.7500 (96.3185)  time: 0.2136  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 520/1627]  eta: 0:03:56  Loss: 2.4538 (2.4581)  Acc@1: 81.2500 (81.1780)  Acc@5: 93.7500 (96.3052)  time: 0.2135  data: 0.0004  max mem: 2502
Test: [Task 1]  [ 530/1627]  eta: 0:03:54  Loss: 2.3895 (2.4559)  Acc@1: 87.5000 (81.2500)  Acc@5: 100.0000 (96.3395)  time: 0.2139  data: 0.0004  max mem: 2502
Test: [Task 1]  [ 540/1627]  eta: 0:03:52  Loss: 2.3841 (2.4566)  Acc@1: 81.2500 (81.2038)  Acc@5: 100.0000 (96.3494)  time: 0.2150  data: 0.0004  max mem: 2502
Test: [Task 1]  [ 550/1627]  eta: 0:03:50  Loss: 2.4845 (2.4578)  Acc@1: 75.0000 (81.1139)  Acc@5: 100.0000 (96.3475)  time: 0.2147  data: 0.0004  max mem: 2502
Test: [Task 1]  [ 560/1627]  eta: 0:03:48  Loss: 2.4627 (2.4585)  Acc@1: 75.0000 (81.0606)  Acc@5: 93.7500 (96.3347)  time: 0.2134  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 570/1627]  eta: 0:03:46  Loss: 2.4061 (2.4571)  Acc@1: 81.2500 (81.1843)  Acc@5: 93.7500 (96.3660)  time: 0.2137  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 580/1627]  eta: 0:03:44  Loss: 2.3787 (2.4566)  Acc@1: 87.5000 (81.2177)  Acc@5: 100.0000 (96.3640)  time: 0.2144  data: 0.0004  max mem: 2502
Test: [Task 1]  [ 590/1627]  eta: 0:03:41  Loss: 2.4212 (2.4565)  Acc@1: 81.2500 (81.2288)  Acc@5: 100.0000 (96.4044)  time: 0.2140  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 600/1627]  eta: 0:03:39  Loss: 2.4350 (2.4564)  Acc@1: 81.2500 (81.2500)  Acc@5: 100.0000 (96.4226)  time: 0.2136  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 610/1627]  eta: 0:03:37  Loss: 2.3802 (2.4548)  Acc@1: 81.2500 (81.3114)  Acc@5: 100.0000 (96.4403)  time: 0.2136  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 620/1627]  eta: 0:03:35  Loss: 2.3802 (2.4554)  Acc@1: 81.2500 (81.2097)  Acc@5: 100.0000 (96.4372)  time: 0.2138  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 630/1627]  eta: 0:03:33  Loss: 2.4806 (2.4555)  Acc@1: 75.0000 (81.2005)  Acc@5: 100.0000 (96.4342)  time: 0.2138  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 640/1627]  eta: 0:03:31  Loss: 2.4205 (2.4551)  Acc@1: 81.2500 (81.2110)  Acc@5: 100.0000 (96.4314)  time: 0.2135  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 650/1627]  eta: 0:03:29  Loss: 2.4801 (2.4548)  Acc@1: 81.2500 (81.1732)  Acc@5: 100.0000 (96.4478)  time: 0.2135  data: 0.0002  max mem: 2502
Test: [Task 1]  [ 660/1627]  eta: 0:03:26  Loss: 2.4515 (2.4540)  Acc@1: 81.2500 (81.1933)  Acc@5: 100.0000 (96.4259)  time: 0.2143  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 670/1627]  eta: 0:03:24  Loss: 2.4242 (2.4542)  Acc@1: 81.2500 (81.1755)  Acc@5: 100.0000 (96.4232)  time: 0.2141  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 680/1627]  eta: 0:03:22  Loss: 2.4305 (2.4536)  Acc@1: 81.2500 (81.1949)  Acc@5: 100.0000 (96.4391)  time: 0.2130  data: 0.0002  max mem: 2502
Test: [Task 1]  [ 690/1627]  eta: 0:03:20  Loss: 2.4074 (2.4521)  Acc@1: 81.2500 (81.2590)  Acc@5: 100.0000 (96.4725)  time: 0.2127  data: 0.0002  max mem: 2502
Test: [Task 1]  [ 700/1627]  eta: 0:03:18  Loss: 2.4074 (2.4524)  Acc@1: 87.5000 (81.3035)  Acc@5: 100.0000 (96.4426)  time: 0.2128  data: 0.0002  max mem: 2502
Test: [Task 1]  [ 710/1627]  eta: 0:03:16  Loss: 2.4062 (2.4517)  Acc@1: 81.2500 (81.3379)  Acc@5: 100.0000 (96.4662)  time: 0.2130  data: 0.0002  max mem: 2502
Test: [Task 1]  [ 720/1627]  eta: 0:03:14  Loss: 2.4042 (2.4515)  Acc@1: 81.2500 (81.3540)  Acc@5: 100.0000 (96.4632)  time: 0.2132  data: 0.0002  max mem: 2502
Test: [Task 1]  [ 730/1627]  eta: 0:03:11  Loss: 2.4063 (2.4522)  Acc@1: 81.2500 (81.3098)  Acc@5: 100.0000 (96.4603)  time: 0.2132  data: 0.0002  max mem: 2502
Test: [Task 1]  [ 740/1627]  eta: 0:03:09  Loss: 2.5025 (2.4528)  Acc@1: 81.2500 (81.2500)  Acc@5: 93.7500 (96.4491)  time: 0.2130  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 750/1627]  eta: 0:03:07  Loss: 2.4755 (2.4526)  Acc@1: 81.2500 (81.2916)  Acc@5: 100.0000 (96.4714)  time: 0.2129  data: 0.0002  max mem: 2502
Test: [Task 1]  [ 760/1627]  eta: 0:03:05  Loss: 2.4295 (2.4529)  Acc@1: 81.2500 (81.2993)  Acc@5: 100.0000 (96.4356)  time: 0.2130  data: 0.0002  max mem: 2502
Test: [Task 1]  [ 770/1627]  eta: 0:03:03  Loss: 2.4295 (2.4522)  Acc@1: 81.2500 (81.3149)  Acc@5: 100.0000 (96.4656)  time: 0.2132  data: 0.0002  max mem: 2502
Test: [Task 1]  [ 780/1627]  eta: 0:03:01  Loss: 2.3639 (2.4509)  Acc@1: 87.5000 (81.4020)  Acc@5: 100.0000 (96.4869)  time: 0.2135  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 790/1627]  eta: 0:02:59  Loss: 2.3472 (2.4515)  Acc@1: 87.5000 (81.3764)  Acc@5: 100.0000 (96.4681)  time: 0.2144  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 800/1627]  eta: 0:02:56  Loss: 2.4363 (2.4514)  Acc@1: 87.5000 (81.4217)  Acc@5: 93.7500 (96.4654)  time: 0.2147  data: 0.0004  max mem: 2502
Test: [Task 1]  [ 810/1627]  eta: 0:02:54  Loss: 2.4113 (2.4513)  Acc@1: 87.5000 (81.4273)  Acc@5: 100.0000 (96.4704)  time: 0.2145  data: 0.0004  max mem: 2502
Test: [Task 1]  [ 820/1627]  eta: 0:02:52  Loss: 2.4162 (2.4510)  Acc@1: 87.5000 (81.4860)  Acc@5: 100.0000 (96.5058)  time: 0.2150  data: 0.0004  max mem: 2502
Test: [Task 1]  [ 830/1627]  eta: 0:02:50  Loss: 2.4284 (2.4517)  Acc@1: 81.2500 (81.4230)  Acc@5: 100.0000 (96.4877)  time: 0.2154  data: 0.0005  max mem: 2502
Test: [Task 1]  [ 840/1627]  eta: 0:02:48  Loss: 2.3809 (2.4506)  Acc@1: 87.5000 (81.4952)  Acc@5: 100.0000 (96.5071)  time: 0.2147  data: 0.0004  max mem: 2502
Test: [Task 1]  [ 850/1627]  eta: 0:02:46  Loss: 2.4268 (2.4509)  Acc@1: 87.5000 (81.4777)  Acc@5: 100.0000 (96.5115)  time: 0.2149  data: 0.0005  max mem: 2502
Test: [Task 1]  [ 860/1627]  eta: 0:02:44  Loss: 2.4649 (2.4511)  Acc@1: 81.2500 (81.5041)  Acc@5: 100.0000 (96.5302)  time: 0.2179  data: 0.0007  max mem: 2502
Test: [Task 1]  [ 870/1627]  eta: 0:02:42  Loss: 2.3700 (2.4499)  Acc@1: 87.5000 (81.5801)  Acc@5: 100.0000 (96.5485)  time: 0.2170  data: 0.0006  max mem: 2502
Test: [Task 1]  [ 880/1627]  eta: 0:02:39  Loss: 2.4060 (2.4510)  Acc@1: 81.2500 (81.5409)  Acc@5: 100.0000 (96.5309)  time: 0.2149  data: 0.0004  max mem: 2502
Test: [Task 1]  [ 890/1627]  eta: 0:02:37  Loss: 2.4927 (2.4514)  Acc@1: 81.2500 (81.5236)  Acc@5: 93.7500 (96.5067)  time: 0.2154  data: 0.0005  max mem: 2502
Test: [Task 1]  [ 900/1627]  eta: 0:02:35  Loss: 2.4495 (2.4521)  Acc@1: 81.2500 (81.5136)  Acc@5: 100.0000 (96.4831)  time: 0.2148  data: 0.0004  max mem: 2502
Test: [Task 1]  [ 910/1627]  eta: 0:02:33  Loss: 2.4717 (2.4528)  Acc@1: 81.2500 (81.4627)  Acc@5: 100.0000 (96.4531)  time: 0.2144  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 920/1627]  eta: 0:02:31  Loss: 2.4587 (2.4526)  Acc@1: 81.2500 (81.4739)  Acc@5: 100.0000 (96.4509)  time: 0.2151  data: 0.0004  max mem: 2502
Test: [Task 1]  [ 930/1627]  eta: 0:02:29  Loss: 2.4029 (2.4519)  Acc@1: 81.2500 (81.5118)  Acc@5: 93.7500 (96.4487)  time: 0.2155  data: 0.0004  max mem: 2502
Test: [Task 1]  [ 940/1627]  eta: 0:02:27  Loss: 2.3763 (2.4507)  Acc@1: 81.2500 (81.5622)  Acc@5: 100.0000 (96.4865)  time: 0.2150  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 950/1627]  eta: 0:02:24  Loss: 2.3904 (2.4504)  Acc@1: 81.2500 (81.5457)  Acc@5: 100.0000 (96.5037)  time: 0.2149  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 960/1627]  eta: 0:02:22  Loss: 2.4233 (2.4505)  Acc@1: 81.2500 (81.5687)  Acc@5: 100.0000 (96.5075)  time: 0.2146  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 970/1627]  eta: 0:02:20  Loss: 2.4639 (2.4507)  Acc@1: 81.2500 (81.5783)  Acc@5: 100.0000 (96.5049)  time: 0.2145  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 980/1627]  eta: 0:02:18  Loss: 2.3924 (2.4504)  Acc@1: 87.5000 (81.5877)  Acc@5: 93.7500 (96.4959)  time: 0.2145  data: 0.0002  max mem: 2502
Test: [Task 1]  [ 990/1627]  eta: 0:02:16  Loss: 2.4888 (2.4518)  Acc@1: 81.2500 (81.5464)  Acc@5: 93.7500 (96.4682)  time: 0.2145  data: 0.0002  max mem: 2502
Test: [Task 1]  [1000/1627]  eta: 0:02:14  Loss: 2.5366 (2.4520)  Acc@1: 81.2500 (81.5247)  Acc@5: 93.7500 (96.4723)  time: 0.2147  data: 0.0002  max mem: 2502
Test: [Task 1]  [1010/1627]  eta: 0:02:12  Loss: 2.3760 (2.4519)  Acc@1: 81.2500 (81.5467)  Acc@5: 93.7500 (96.4639)  time: 0.2149  data: 0.0002  max mem: 2502
Test: [Task 1]  [1020/1627]  eta: 0:02:09  Loss: 2.4068 (2.4519)  Acc@1: 81.2500 (81.5500)  Acc@5: 100.0000 (96.4863)  time: 0.2146  data: 0.0002  max mem: 2502
Test: [Task 1]  [1030/1627]  eta: 0:02:07  Loss: 2.3885 (2.4514)  Acc@1: 81.2500 (81.5713)  Acc@5: 100.0000 (96.4901)  time: 0.2141  data: 0.0002  max mem: 2502
Test: [Task 1]  [1040/1627]  eta: 0:02:05  Loss: 2.3775 (2.4507)  Acc@1: 81.2500 (81.5802)  Acc@5: 100.0000 (96.4998)  time: 0.2140  data: 0.0002  max mem: 2502
Test: [Task 1]  [1050/1627]  eta: 0:02:03  Loss: 2.4279 (2.4502)  Acc@1: 81.2500 (81.6009)  Acc@5: 100.0000 (96.5212)  time: 0.2139  data: 0.0002  max mem: 2502
Test: [Task 1]  [1060/1627]  eta: 0:02:01  Loss: 2.4648 (2.4507)  Acc@1: 81.2500 (81.5681)  Acc@5: 100.0000 (96.5068)  time: 0.2138  data: 0.0002  max mem: 2502
Test: [Task 1]  [1070/1627]  eta: 0:01:59  Loss: 2.4657 (2.4506)  Acc@1: 81.2500 (81.5768)  Acc@5: 93.7500 (96.4986)  time: 0.2138  data: 0.0002  max mem: 2502
Test: [Task 1]  [1080/1627]  eta: 0:01:57  Loss: 2.3901 (2.4507)  Acc@1: 81.2500 (81.5738)  Acc@5: 100.0000 (96.4963)  time: 0.2143  data: 0.0003  max mem: 2502
Test: [Task 1]  [1090/1627]  eta: 0:01:55  Loss: 2.4094 (2.4510)  Acc@1: 81.2500 (81.5536)  Acc@5: 100.0000 (96.4940)  time: 0.2148  data: 0.0003  max mem: 2502
Test: [Task 1]  [1100/1627]  eta: 0:01:52  Loss: 2.3871 (2.4503)  Acc@1: 81.2500 (81.6076)  Acc@5: 100.0000 (96.5145)  time: 0.2150  data: 0.0003  max mem: 2502
Test: [Task 1]  [1110/1627]  eta: 0:01:50  Loss: 2.3987 (2.4501)  Acc@1: 81.2500 (81.5932)  Acc@5: 100.0000 (96.5347)  time: 0.2153  data: 0.0004  max mem: 2502
Test: [Task 1]  [1120/1627]  eta: 0:01:48  Loss: 2.4701 (2.4507)  Acc@1: 75.0000 (81.5566)  Acc@5: 100.0000 (96.5210)  time: 0.2151  data: 0.0004  max mem: 2502
Test: [Task 1]  [1130/1627]  eta: 0:01:46  Loss: 2.4593 (2.4510)  Acc@1: 75.0000 (81.5429)  Acc@5: 100.0000 (96.5241)  time: 0.2148  data: 0.0004  max mem: 2502
Test: [Task 1]  [1140/1627]  eta: 0:01:44  Loss: 2.4593 (2.4515)  Acc@1: 81.2500 (81.5239)  Acc@5: 100.0000 (96.5217)  time: 0.2152  data: 0.0004  max mem: 2502
Test: [Task 1]  [1150/1627]  eta: 0:01:42  Loss: 2.4871 (2.4516)  Acc@1: 81.2500 (81.5324)  Acc@5: 100.0000 (96.5030)  time: 0.2151  data: 0.0004  max mem: 2502
Test: [Task 1]  [1160/1627]  eta: 0:01:40  Loss: 2.4128 (2.4514)  Acc@1: 81.2500 (81.5676)  Acc@5: 100.0000 (96.5062)  time: 0.2150  data: 0.0003  max mem: 2502
Test: [Task 1]  [1170/1627]  eta: 0:01:37  Loss: 2.3861 (2.4514)  Acc@1: 81.2500 (81.5756)  Acc@5: 100.0000 (96.5201)  time: 0.2159  data: 0.0003  max mem: 2502
Test: [Task 1]  [1180/1627]  eta: 0:01:35  Loss: 2.4596 (2.4516)  Acc@1: 81.2500 (81.5622)  Acc@5: 100.0000 (96.5284)  time: 0.2157  data: 0.0003  max mem: 2502
Test: [Task 1]  [1190/1627]  eta: 0:01:33  Loss: 2.4807 (2.4518)  Acc@1: 81.2500 (81.5491)  Acc@5: 100.0000 (96.5418)  time: 0.2145  data: 0.0003  max mem: 2502
Test: [Task 1]  [1200/1627]  eta: 0:01:31  Loss: 2.4755 (2.4516)  Acc@1: 81.2500 (81.5570)  Acc@5: 100.0000 (96.5341)  time: 0.2144  data: 0.0002  max mem: 2502
Test: [Task 1]  [1210/1627]  eta: 0:01:29  Loss: 2.4574 (2.4526)  Acc@1: 81.2500 (81.5184)  Acc@5: 93.7500 (96.5060)  time: 0.2144  data: 0.0002  max mem: 2502
Test: [Task 1]  [1220/1627]  eta: 0:01:27  Loss: 2.4799 (2.4525)  Acc@1: 81.2500 (81.5162)  Acc@5: 93.7500 (96.5090)  time: 0.2145  data: 0.0002  max mem: 2502
Test: [Task 1]  [1230/1627]  eta: 0:01:25  Loss: 2.4799 (2.4530)  Acc@1: 81.2500 (81.4734)  Acc@5: 93.7500 (96.5018)  time: 0.2147  data: 0.0002  max mem: 2502
Test: [Task 1]  [1240/1627]  eta: 0:01:22  Loss: 2.4493 (2.4530)  Acc@1: 81.2500 (81.4565)  Acc@5: 100.0000 (96.5099)  time: 0.2145  data: 0.0002  max mem: 2502
Test: [Task 1]  [1250/1627]  eta: 0:01:20  Loss: 2.4493 (2.4532)  Acc@1: 81.2500 (81.4648)  Acc@5: 100.0000 (96.4978)  time: 0.2146  data: 0.0002  max mem: 2502
Test: [Task 1]  [1260/1627]  eta: 0:01:18  Loss: 2.4314 (2.4532)  Acc@1: 87.5000 (81.4681)  Acc@5: 93.7500 (96.4958)  time: 0.2146  data: 0.0002  max mem: 2502
Test: [Task 1]  [1270/1627]  eta: 0:01:16  Loss: 2.4309 (2.4533)  Acc@1: 81.2500 (81.4319)  Acc@5: 100.0000 (96.5136)  time: 0.2139  data: 0.0002  max mem: 2502
Test: [Task 1]  [1280/1627]  eta: 0:01:14  Loss: 2.4309 (2.4529)  Acc@1: 81.2500 (81.4305)  Acc@5: 100.0000 (96.5115)  time: 0.2138  data: 0.0002  max mem: 2502
Test: [Task 1]  [1290/1627]  eta: 0:01:12  Loss: 2.4429 (2.4533)  Acc@1: 81.2500 (81.4194)  Acc@5: 100.0000 (96.5046)  time: 0.2138  data: 0.0002  max mem: 2502
Test: [Task 1]  [1300/1627]  eta: 0:01:10  Loss: 2.4429 (2.4527)  Acc@1: 81.2500 (81.4614)  Acc@5: 93.7500 (96.5075)  time: 0.2137  data: 0.0002  max mem: 2502
Test: [Task 1]  [1310/1627]  eta: 0:01:07  Loss: 2.3444 (2.4522)  Acc@1: 81.2500 (81.4788)  Acc@5: 93.7500 (96.5008)  time: 0.2138  data: 0.0002  max mem: 2502
Test: [Task 1]  [1320/1627]  eta: 0:01:05  Loss: 2.3723 (2.4515)  Acc@1: 81.2500 (81.5102)  Acc@5: 100.0000 (96.5225)  time: 0.2139  data: 0.0003  max mem: 2502
Test: [Task 1]  [1330/1627]  eta: 0:01:03  Loss: 2.4241 (2.4517)  Acc@1: 81.2500 (81.4942)  Acc@5: 100.0000 (96.5111)  time: 0.2143  data: 0.0004  max mem: 2502
Test: [Task 1]  [1340/1627]  eta: 0:01:01  Loss: 2.4641 (2.4520)  Acc@1: 81.2500 (81.4597)  Acc@5: 93.7500 (96.5045)  time: 0.2147  data: 0.0003  max mem: 2502
Test: [Task 1]  [1350/1627]  eta: 0:00:59  Loss: 2.4423 (2.4520)  Acc@1: 81.2500 (81.4906)  Acc@5: 100.0000 (96.5165)  time: 0.2151  data: 0.0003  max mem: 2502
Test: [Task 1]  [1360/1627]  eta: 0:00:57  Loss: 2.4102 (2.4519)  Acc@1: 87.5000 (81.5072)  Acc@5: 100.0000 (96.5145)  time: 0.2146  data: 0.0004  max mem: 2502
Test: [Task 1]  [1370/1627]  eta: 0:00:55  Loss: 2.3771 (2.4516)  Acc@1: 87.5000 (81.5235)  Acc@5: 93.7500 (96.5126)  time: 0.2143  data: 0.0004  max mem: 2502
Test: [Task 1]  [1380/1627]  eta: 0:00:52  Loss: 2.3771 (2.4513)  Acc@1: 87.5000 (81.5306)  Acc@5: 100.0000 (96.5197)  time: 0.2146  data: 0.0004  max mem: 2502
Test: [Task 1]  [1390/1627]  eta: 0:00:50  Loss: 2.4175 (2.4514)  Acc@1: 81.2500 (81.5196)  Acc@5: 100.0000 (96.5088)  time: 0.2149  data: 0.0004  max mem: 2502
Test: [Task 1]  [1400/1627]  eta: 0:00:48  Loss: 2.4182 (2.4516)  Acc@1: 81.2500 (81.4909)  Acc@5: 93.7500 (96.5025)  time: 0.2154  data: 0.0004  max mem: 2502
Test: [Task 1]  [1410/1627]  eta: 0:00:46  Loss: 2.3744 (2.4513)  Acc@1: 81.2500 (81.4715)  Acc@5: 100.0000 (96.5184)  time: 0.2152  data: 0.0004  max mem: 2502
Test: [Task 1]  [1420/1627]  eta: 0:00:44  Loss: 2.4154 (2.4510)  Acc@1: 81.2500 (81.4919)  Acc@5: 100.0000 (96.5209)  time: 0.2145  data: 0.0004  max mem: 2502
Test: [Task 1]  [1430/1627]  eta: 0:00:42  Loss: 2.5056 (2.4519)  Acc@1: 75.0000 (81.4378)  Acc@5: 93.7500 (96.4928)  time: 0.2147  data: 0.0004  max mem: 2502
Test: [Task 1]  [1440/1627]  eta: 0:00:40  Loss: 2.5056 (2.4520)  Acc@1: 75.0000 (81.4148)  Acc@5: 93.7500 (96.4781)  time: 0.2146  data: 0.0003  max mem: 2502
Test: [Task 1]  [1450/1627]  eta: 0:00:37  Loss: 2.5122 (2.4525)  Acc@1: 81.2500 (81.3921)  Acc@5: 100.0000 (96.4809)  time: 0.2142  data: 0.0002  max mem: 2502
Test: [Task 1]  [1460/1627]  eta: 0:00:35  Loss: 2.5119 (2.4525)  Acc@1: 81.2500 (81.3698)  Acc@5: 100.0000 (96.4793)  time: 0.2142  data: 0.0002  max mem: 2502
Test: [Task 1]  [1470/1627]  eta: 0:00:33  Loss: 2.3918 (2.4527)  Acc@1: 81.2500 (81.3605)  Acc@5: 100.0000 (96.4820)  time: 0.2143  data: 0.0003  max mem: 2502
Test: [Task 1]  [1480/1627]  eta: 0:00:31  Loss: 2.3694 (2.4526)  Acc@1: 81.2500 (81.3724)  Acc@5: 100.0000 (96.4889)  time: 0.2143  data: 0.0002  max mem: 2502
Test: [Task 1]  [1490/1627]  eta: 0:00:29  Loss: 2.4132 (2.4529)  Acc@1: 81.2500 (81.3716)  Acc@5: 100.0000 (96.4831)  time: 0.2140  data: 0.0002  max mem: 2502
Test: [Task 1]  [1500/1627]  eta: 0:00:27  Loss: 2.4453 (2.4532)  Acc@1: 81.2500 (81.3666)  Acc@5: 93.7500 (96.4690)  time: 0.2141  data: 0.0002  max mem: 2502
Test: [Task 1]  [1510/1627]  eta: 0:00:25  Loss: 2.4303 (2.4530)  Acc@1: 81.2500 (81.3906)  Acc@5: 93.7500 (96.4593)  time: 0.2141  data: 0.0002  max mem: 2502
Test: [Task 1]  [1520/1627]  eta: 0:00:22  Loss: 2.3964 (2.4525)  Acc@1: 81.2500 (81.4061)  Acc@5: 100.0000 (96.4620)  time: 0.2143  data: 0.0003  max mem: 2502
Test: [Task 1]  [1530/1627]  eta: 0:00:20  Loss: 2.3763 (2.4522)  Acc@1: 87.5000 (81.4337)  Acc@5: 100.0000 (96.4688)  time: 0.2141  data: 0.0003  max mem: 2502
Test: [Task 1]  [1540/1627]  eta: 0:00:18  Loss: 2.3489 (2.4519)  Acc@1: 93.7500 (81.4650)  Acc@5: 100.0000 (96.4836)  time: 0.2137  data: 0.0002  max mem: 2502
Test: [Task 1]  [1550/1627]  eta: 0:00:16  Loss: 2.4004 (2.4519)  Acc@1: 87.5000 (81.4676)  Acc@5: 100.0000 (96.4821)  time: 0.2135  data: 0.0002  max mem: 2502
Test: [Task 1]  [1560/1627]  eta: 0:00:14  Loss: 2.4103 (2.4514)  Acc@1: 81.2500 (81.4862)  Acc@5: 100.0000 (96.4846)  time: 0.2133  data: 0.0002  max mem: 2502
Test: [Task 1]  [1570/1627]  eta: 0:00:12  Loss: 2.4103 (2.4516)  Acc@1: 81.2500 (81.4927)  Acc@5: 100.0000 (96.4911)  time: 0.2135  data: 0.0002  max mem: 2502
Test: [Task 1]  [1580/1627]  eta: 0:00:10  Loss: 2.4116 (2.4513)  Acc@1: 81.2500 (81.4753)  Acc@5: 100.0000 (96.4896)  time: 0.2135  data: 0.0002  max mem: 2502
Test: [Task 1]  [1590/1627]  eta: 0:00:07  Loss: 2.4256 (2.4514)  Acc@1: 75.0000 (81.4661)  Acc@5: 100.0000 (96.4959)  time: 0.2135  data: 0.0002  max mem: 2502
Test: [Task 1]  [1600/1627]  eta: 0:00:05  Loss: 2.4609 (2.4521)  Acc@1: 75.0000 (81.4374)  Acc@5: 93.7500 (96.4788)  time: 0.2137  data: 0.0002  max mem: 2502
Test: [Task 1]  [1610/1627]  eta: 0:00:03  Loss: 2.4488 (2.4517)  Acc@1: 81.2500 (81.4711)  Acc@5: 100.0000 (96.4929)  time: 0.2138  data: 0.0002  max mem: 2502
Test: [Task 1]  [1620/1627]  eta: 0:00:01  Loss: 2.4235 (2.4516)  Acc@1: 87.5000 (81.4852)  Acc@5: 100.0000 (96.4914)  time: 0.2138  data: 0.0002  max mem: 2502
Test: [Task 1]  [1626/1627]  eta: 0:00:00  Loss: 2.4235 (2.4513)  Acc@1: 87.5000 (81.4959)  Acc@5: 100.0000 (96.4966)  time: 0.2137  data: 0.0002  max mem: 2502
Test: [Task 1] Total time: 0:05:48 (0.2144 s / it)
* Acc@1 81.496 Acc@5 96.497 loss 2.451
Test: [Task 2]  [  0/625]  eta: 0:04:50  Loss: 1.8539 (1.8539)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)  time: 0.4644  data: 0.2481  max mem: 2502
Test: [Task 2]  [ 10/625]  eta: 0:02:25  Loss: 2.0367 (2.0633)  Acc@1: 93.7500 (93.7500)  Acc@5: 100.0000 (97.7273)  time: 0.2365  data: 0.0227  max mem: 2502
Test: [Task 2]  [ 20/625]  eta: 0:02:16  Loss: 2.0334 (2.0533)  Acc@1: 93.7500 (94.3452)  Acc@5: 100.0000 (98.8095)  time: 0.2143  data: 0.0002  max mem: 2502
Test: [Task 2]  [ 30/625]  eta: 0:02:12  Loss: 2.0144 (2.0507)  Acc@1: 93.7500 (94.1532)  Acc@5: 100.0000 (98.9919)  time: 0.2147  data: 0.0003  max mem: 2502
Test: [Task 2]  [ 40/625]  eta: 0:02:09  Loss: 2.0529 (2.0598)  Acc@1: 93.7500 (93.4451)  Acc@5: 100.0000 (99.2378)  time: 0.2149  data: 0.0003  max mem: 2502
Test: [Task 2]  [ 50/625]  eta: 0:02:06  Loss: 2.0553 (2.0709)  Acc@1: 93.7500 (92.8922)  Acc@5: 100.0000 (99.1422)  time: 0.2151  data: 0.0004  max mem: 2502
Test: [Task 2]  [ 60/625]  eta: 0:02:03  Loss: 2.0553 (2.0697)  Acc@1: 93.7500 (92.9303)  Acc@5: 100.0000 (99.0779)  time: 0.2149  data: 0.0003  max mem: 2502
Test: [Task 2]  [ 70/625]  eta: 0:02:01  Loss: 2.0429 (2.0730)  Acc@1: 93.7500 (92.6056)  Acc@5: 100.0000 (99.1197)  time: 0.2151  data: 0.0003  max mem: 2502
Test: [Task 2]  [ 80/625]  eta: 0:01:58  Loss: 2.1008 (2.0771)  Acc@1: 87.5000 (92.2840)  Acc@5: 100.0000 (98.7654)  time: 0.2155  data: 0.0004  max mem: 2502
Test: [Task 2]  [ 90/625]  eta: 0:01:56  Loss: 2.1322 (2.0803)  Acc@1: 87.5000 (92.1016)  Acc@5: 100.0000 (98.9011)  time: 0.2151  data: 0.0004  max mem: 2502
Test: [Task 2]  [100/625]  eta: 0:01:54  Loss: 2.1050 (2.0834)  Acc@1: 93.7500 (92.1411)  Acc@5: 100.0000 (98.8243)  time: 0.2145  data: 0.0004  max mem: 2502
Test: [Task 2]  [110/625]  eta: 0:01:51  Loss: 2.0814 (2.0823)  Acc@1: 93.7500 (92.1171)  Acc@5: 100.0000 (98.8176)  time: 0.2147  data: 0.0003  max mem: 2502
Test: [Task 2]  [120/625]  eta: 0:01:49  Loss: 2.0317 (2.0839)  Acc@1: 87.5000 (91.7872)  Acc@5: 100.0000 (98.8636)  time: 0.2151  data: 0.0004  max mem: 2502
Test: [Task 2]  [130/625]  eta: 0:01:47  Loss: 2.1014 (2.0849)  Acc@1: 87.5000 (91.8893)  Acc@5: 100.0000 (98.9027)  time: 0.2151  data: 0.0004  max mem: 2502
Test: [Task 2]  [140/625]  eta: 0:01:45  Loss: 2.1014 (2.0857)  Acc@1: 93.7500 (91.8883)  Acc@5: 100.0000 (98.7589)  time: 0.2152  data: 0.0004  max mem: 2502
Test: [Task 2]  [150/625]  eta: 0:01:42  Loss: 2.0709 (2.0881)  Acc@1: 87.5000 (91.7632)  Acc@5: 100.0000 (98.6755)  time: 0.2153  data: 0.0003  max mem: 2502
Test: [Task 2]  [160/625]  eta: 0:01:40  Loss: 2.0709 (2.0892)  Acc@1: 87.5000 (91.8090)  Acc@5: 100.0000 (98.6801)  time: 0.2163  data: 0.0004  max mem: 2502
Test: [Task 2]  [170/625]  eta: 0:01:38  Loss: 2.0971 (2.0886)  Acc@1: 93.7500 (91.8494)  Acc@5: 100.0000 (98.6477)  time: 0.2163  data: 0.0004  max mem: 2502
Test: [Task 2]  [180/625]  eta: 0:01:36  Loss: 2.0625 (2.0884)  Acc@1: 93.7500 (91.8508)  Acc@5: 100.0000 (98.6878)  time: 0.2149  data: 0.0003  max mem: 2502
Test: [Task 2]  [190/625]  eta: 0:01:34  Loss: 2.0544 (2.0879)  Acc@1: 93.7500 (91.9175)  Acc@5: 100.0000 (98.7238)  time: 0.2149  data: 0.0003  max mem: 2502
Test: [Task 2]  [200/625]  eta: 0:01:31  Loss: 2.0709 (2.0891)  Acc@1: 93.7500 (91.9154)  Acc@5: 100.0000 (98.6940)  time: 0.2149  data: 0.0003  max mem: 2502
Test: [Task 2]  [210/625]  eta: 0:01:29  Loss: 2.0363 (2.0885)  Acc@1: 93.7500 (91.8839)  Acc@5: 100.0000 (98.6374)  time: 0.2146  data: 0.0003  max mem: 2502
Test: [Task 2]  [220/625]  eta: 0:01:27  Loss: 2.0281 (2.0875)  Acc@1: 93.7500 (91.9966)  Acc@5: 100.0000 (98.6425)  time: 0.2152  data: 0.0004  max mem: 2502
Test: [Task 2]  [230/625]  eta: 0:01:25  Loss: 2.0301 (2.0866)  Acc@1: 93.7500 (92.0455)  Acc@5: 100.0000 (98.6742)  time: 0.2153  data: 0.0004  max mem: 2502
Test: [Task 2]  [240/625]  eta: 0:01:23  Loss: 2.0592 (2.0871)  Acc@1: 93.7500 (91.9865)  Acc@5: 100.0000 (98.7033)  time: 0.2152  data: 0.0003  max mem: 2502
Test: [Task 2]  [250/625]  eta: 0:01:21  Loss: 2.0940 (2.0879)  Acc@1: 93.7500 (91.9572)  Acc@5: 100.0000 (98.6305)  time: 0.2159  data: 0.0004  max mem: 2502
Test: [Task 2]  [260/625]  eta: 0:01:18  Loss: 2.0825 (2.0876)  Acc@1: 93.7500 (91.9780)  Acc@5: 100.0000 (98.6351)  time: 0.2154  data: 0.0004  max mem: 2502
Test: [Task 2]  [270/625]  eta: 0:01:16  Loss: 2.0799 (2.0884)  Acc@1: 93.7500 (91.9050)  Acc@5: 100.0000 (98.6162)  time: 0.2153  data: 0.0003  max mem: 2502
Test: [Task 2]  [280/625]  eta: 0:01:14  Loss: 2.0858 (2.0885)  Acc@1: 93.7500 (91.9262)  Acc@5: 100.0000 (98.6210)  time: 0.2153  data: 0.0003  max mem: 2502
Test: [Task 2]  [290/625]  eta: 0:01:12  Loss: 2.0858 (2.0888)  Acc@1: 93.7500 (91.8814)  Acc@5: 100.0000 (98.6254)  time: 0.2147  data: 0.0003  max mem: 2502
Test: [Task 2]  [300/625]  eta: 0:01:10  Loss: 2.0782 (2.0890)  Acc@1: 93.7500 (91.7982)  Acc@5: 100.0000 (98.6296)  time: 0.2147  data: 0.0003  max mem: 2502
Test: [Task 2]  [310/625]  eta: 0:01:08  Loss: 2.0395 (2.0880)  Acc@1: 93.7500 (91.8609)  Acc@5: 100.0000 (98.6133)  time: 0.2149  data: 0.0003  max mem: 2502
Test: [Task 2]  [320/625]  eta: 0:01:05  Loss: 1.9933 (2.0826)  Acc@1: 100.0000 (92.0950)  Acc@5: 100.0000 (98.6565)  time: 0.2148  data: 0.0002  max mem: 2502
Test: [Task 2]  [330/625]  eta: 0:01:03  Loss: 1.9438 (2.0800)  Acc@1: 100.0000 (92.2394)  Acc@5: 100.0000 (98.6782)  time: 0.2147  data: 0.0002  max mem: 2502
Test: [Task 2]  [340/625]  eta: 0:01:01  Loss: 1.9244 (2.0749)  Acc@1: 100.0000 (92.4487)  Acc@5: 100.0000 (98.7170)  time: 0.2148  data: 0.0003  max mem: 2502
Test: [Task 2]  [350/625]  eta: 0:00:59  Loss: 1.9059 (2.0715)  Acc@1: 100.0000 (92.5748)  Acc@5: 100.0000 (98.7358)  time: 0.2147  data: 0.0002  max mem: 2502
Test: [Task 2]  [360/625]  eta: 0:00:57  Loss: 2.0257 (2.0726)  Acc@1: 93.7500 (92.5554)  Acc@5: 100.0000 (98.7015)  time: 0.2146  data: 0.0002  max mem: 2502
Test: [Task 2]  [370/625]  eta: 0:00:55  Loss: 2.0375 (2.0711)  Acc@1: 93.7500 (92.5876)  Acc@5: 100.0000 (98.7365)  time: 0.2151  data: 0.0003  max mem: 2502
Test: [Task 2]  [380/625]  eta: 0:00:52  Loss: 2.0411 (2.0724)  Acc@1: 93.7500 (92.5197)  Acc@5: 100.0000 (98.7205)  time: 0.2146  data: 0.0003  max mem: 2502
Test: [Task 2]  [390/625]  eta: 0:00:50  Loss: 2.0411 (2.0718)  Acc@1: 93.7500 (92.5192)  Acc@5: 100.0000 (98.6093)  time: 0.2138  data: 0.0002  max mem: 2502
Test: [Task 2]  [400/625]  eta: 0:00:48  Loss: 1.9101 (2.0682)  Acc@1: 100.0000 (92.6901)  Acc@5: 100.0000 (98.6284)  time: 0.2139  data: 0.0002  max mem: 2502
Test: [Task 2]  [410/625]  eta: 0:00:46  Loss: 1.9029 (2.0657)  Acc@1: 100.0000 (92.7920)  Acc@5: 100.0000 (98.6466)  time: 0.2141  data: 0.0002  max mem: 2502
Test: [Task 2]  [420/625]  eta: 0:00:44  Loss: 1.9283 (2.0640)  Acc@1: 100.0000 (92.9186)  Acc@5: 100.0000 (98.6639)  time: 0.2141  data: 0.0002  max mem: 2502
Test: [Task 2]  [430/625]  eta: 0:00:42  Loss: 1.9865 (2.0623)  Acc@1: 100.0000 (92.9959)  Acc@5: 100.0000 (98.6804)  time: 0.2140  data: 0.0002  max mem: 2502
Test: [Task 2]  [440/625]  eta: 0:00:39  Loss: 1.9062 (2.0584)  Acc@1: 100.0000 (93.1548)  Acc@5: 100.0000 (98.7103)  time: 0.2139  data: 0.0002  max mem: 2502
Test: [Task 2]  [450/625]  eta: 0:00:37  Loss: 1.8898 (2.0559)  Acc@1: 100.0000 (93.2373)  Acc@5: 100.0000 (98.7389)  time: 0.2138  data: 0.0002  max mem: 2502
Test: [Task 2]  [460/625]  eta: 0:00:35  Loss: 1.9112 (2.0540)  Acc@1: 100.0000 (93.3026)  Acc@5: 100.0000 (98.7663)  time: 0.2137  data: 0.0002  max mem: 2502
Test: [Task 2]  [470/625]  eta: 0:00:33  Loss: 1.9628 (2.0529)  Acc@1: 100.0000 (93.3652)  Acc@5: 100.0000 (98.7659)  time: 0.2135  data: 0.0002  max mem: 2502
Test: [Task 2]  [480/625]  eta: 0:00:31  Loss: 1.9687 (2.0512)  Acc@1: 100.0000 (93.4511)  Acc@5: 100.0000 (98.7916)  time: 0.2136  data: 0.0002  max mem: 2502
Test: [Task 2]  [490/625]  eta: 0:00:29  Loss: 1.9464 (2.0493)  Acc@1: 100.0000 (93.5336)  Acc@5: 100.0000 (98.8162)  time: 0.2144  data: 0.0003  max mem: 2502
Test: [Task 2]  [500/625]  eta: 0:00:26  Loss: 1.9491 (2.0479)  Acc@1: 100.0000 (93.6252)  Acc@5: 100.0000 (98.8398)  time: 0.2148  data: 0.0003  max mem: 2502
Test: [Task 2]  [510/625]  eta: 0:00:24  Loss: 1.9883 (2.0476)  Acc@1: 100.0000 (93.6399)  Acc@5: 100.0000 (98.8503)  time: 0.2147  data: 0.0003  max mem: 2502
Test: [Task 2]  [520/625]  eta: 0:00:22  Loss: 1.9951 (2.0471)  Acc@1: 93.7500 (93.6780)  Acc@5: 100.0000 (98.8604)  time: 0.2147  data: 0.0003  max mem: 2502
Test: [Task 2]  [530/625]  eta: 0:00:20  Loss: 1.9471 (2.0448)  Acc@1: 100.0000 (93.7971)  Acc@5: 100.0000 (98.8818)  time: 0.2143  data: 0.0003  max mem: 2502
Test: [Task 2]  [540/625]  eta: 0:00:18  Loss: 1.9066 (2.0427)  Acc@1: 100.0000 (93.8886)  Acc@5: 100.0000 (98.8909)  time: 0.2148  data: 0.0003  max mem: 2502
Test: [Task 2]  [550/625]  eta: 0:00:16  Loss: 1.9045 (2.0402)  Acc@1: 100.0000 (93.9882)  Acc@5: 100.0000 (98.9111)  time: 0.2148  data: 0.0003  max mem: 2502
Test: [Task 2]  [560/625]  eta: 0:00:13  Loss: 1.8972 (2.0377)  Acc@1: 100.0000 (94.0954)  Acc@5: 100.0000 (98.9305)  time: 0.2144  data: 0.0003  max mem: 2502
Test: [Task 2]  [570/625]  eta: 0:00:11  Loss: 1.9107 (2.0377)  Acc@1: 100.0000 (94.0784)  Acc@5: 100.0000 (98.9492)  time: 0.2144  data: 0.0004  max mem: 2502
Test: [Task 2]  [580/625]  eta: 0:00:09  Loss: 1.9232 (2.0357)  Acc@1: 100.0000 (94.1695)  Acc@5: 100.0000 (98.9673)  time: 0.2142  data: 0.0004  max mem: 2502
Test: [Task 2]  [590/625]  eta: 0:00:07  Loss: 1.9156 (2.0337)  Acc@1: 100.0000 (94.2365)  Acc@5: 100.0000 (98.9848)  time: 0.2143  data: 0.0004  max mem: 2502
Test: [Task 2]  [600/625]  eta: 0:00:05  Loss: 1.9434 (2.0330)  Acc@1: 100.0000 (94.2908)  Acc@5: 100.0000 (99.0017)  time: 0.2143  data: 0.0004  max mem: 2502
Test: [Task 2]  [610/625]  eta: 0:00:03  Loss: 2.0062 (2.0338)  Acc@1: 93.7500 (94.2717)  Acc@5: 100.0000 (99.0078)  time: 0.2141  data: 0.0003  max mem: 2502
Test: [Task 2]  [620/625]  eta: 0:00:01  Loss: 2.0055 (2.0329)  Acc@1: 93.7500 (94.3136)  Acc@5: 100.0000 (99.0238)  time: 0.2136  data: 0.0003  max mem: 2502
Test: [Task 2]  [624/625]  eta: 0:00:00  Loss: 1.9709 (2.0324)  Acc@1: 100.0000 (94.3400)  Acc@5: 100.0000 (99.0300)  time: 0.2135  data: 0.0002  max mem: 2502
Test: [Task 2] Total time: 0:02:14 (0.2153 s / it)
* Acc@1 94.340 Acc@5 99.030 loss 2.032
Test: [Task 3]  [  0/625]  eta: 0:05:34  Loss: 2.3920 (2.3920)  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (100.0000)  time: 0.5358  data: 0.3216  max mem: 2502
Test: [Task 3]  [ 10/625]  eta: 0:02:29  Loss: 2.3246 (2.3390)  Acc@1: 87.5000 (88.0682)  Acc@5: 100.0000 (99.4318)  time: 0.2433  data: 0.0296  max mem: 2502
Test: [Task 3]  [ 20/625]  eta: 0:02:18  Loss: 2.3246 (2.3489)  Acc@1: 87.5000 (87.2024)  Acc@5: 100.0000 (99.4048)  time: 0.2141  data: 0.0004  max mem: 2502
Test: [Task 3]  [ 30/625]  eta: 0:02:13  Loss: 2.3652 (2.3556)  Acc@1: 81.2500 (85.8871)  Acc@5: 100.0000 (99.1935)  time: 0.2138  data: 0.0004  max mem: 2502
Test: [Task 3]  [ 40/625]  eta: 0:02:09  Loss: 2.3238 (2.3422)  Acc@1: 87.5000 (87.0427)  Acc@5: 100.0000 (99.2378)  time: 0.2136  data: 0.0003  max mem: 2502
Test: [Task 3]  [ 50/625]  eta: 0:02:06  Loss: 2.3238 (2.3367)  Acc@1: 87.5000 (87.2549)  Acc@5: 100.0000 (99.1422)  time: 0.2138  data: 0.0003  max mem: 2502
Test: [Task 3]  [ 60/625]  eta: 0:02:03  Loss: 2.3250 (2.3357)  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (99.2828)  time: 0.2144  data: 0.0004  max mem: 2502
Test: [Task 3]  [ 70/625]  eta: 0:02:01  Loss: 2.3245 (2.3300)  Acc@1: 93.7500 (87.6761)  Acc@5: 100.0000 (99.1197)  time: 0.2142  data: 0.0004  max mem: 2502
Test: [Task 3]  [ 80/625]  eta: 0:01:58  Loss: 2.2697 (2.3242)  Acc@1: 93.7500 (88.1944)  Acc@5: 100.0000 (99.1512)  time: 0.2132  data: 0.0003  max mem: 2502
Test: [Task 3]  [ 90/625]  eta: 0:01:56  Loss: 2.2686 (2.3198)  Acc@1: 93.7500 (88.8736)  Acc@5: 100.0000 (99.1071)  time: 0.2136  data: 0.0003  max mem: 2502
Test: [Task 3]  [100/625]  eta: 0:01:53  Loss: 2.2991 (2.3222)  Acc@1: 93.7500 (88.8614)  Acc@5: 100.0000 (99.0718)  time: 0.2136  data: 0.0003  max mem: 2502
Test: [Task 3]  [110/625]  eta: 0:01:51  Loss: 2.3062 (2.3191)  Acc@1: 93.7500 (88.8514)  Acc@5: 100.0000 (99.1554)  time: 0.2135  data: 0.0003  max mem: 2502
Test: [Task 3]  [120/625]  eta: 0:01:49  Loss: 2.2908 (2.3181)  Acc@1: 87.5000 (88.7397)  Acc@5: 100.0000 (99.2252)  time: 0.2136  data: 0.0002  max mem: 2502
Test: [Task 3]  [130/625]  eta: 0:01:47  Loss: 2.3211 (2.3204)  Acc@1: 87.5000 (88.4065)  Acc@5: 100.0000 (99.1889)  time: 0.2135  data: 0.0002  max mem: 2502
Test: [Task 3]  [140/625]  eta: 0:01:44  Loss: 2.3211 (2.3210)  Acc@1: 87.5000 (88.3865)  Acc@5: 100.0000 (99.0691)  time: 0.2136  data: 0.0002  max mem: 2502
Test: [Task 3]  [150/625]  eta: 0:01:42  Loss: 2.3037 (2.3215)  Acc@1: 87.5000 (88.4106)  Acc@5: 100.0000 (99.0066)  time: 0.2138  data: 0.0002  max mem: 2502
Test: [Task 3]  [160/625]  eta: 0:01:40  Loss: 2.3037 (2.3241)  Acc@1: 93.7500 (88.3152)  Acc@5: 100.0000 (98.9130)  time: 0.2136  data: 0.0003  max mem: 2502
Test: [Task 3]  [170/625]  eta: 0:01:38  Loss: 2.2918 (2.3243)  Acc@1: 87.5000 (88.3406)  Acc@5: 100.0000 (98.9401)  time: 0.2133  data: 0.0003  max mem: 2502
Test: [Task 3]  [180/625]  eta: 0:01:35  Loss: 2.3033 (2.3246)  Acc@1: 93.7500 (88.5359)  Acc@5: 100.0000 (98.9641)  time: 0.2138  data: 0.0003  max mem: 2502
Test: [Task 3]  [190/625]  eta: 0:01:33  Loss: 2.3057 (2.3244)  Acc@1: 93.7500 (88.6453)  Acc@5: 100.0000 (98.9856)  time: 0.2140  data: 0.0003  max mem: 2502
Test: [Task 3]  [200/625]  eta: 0:01:31  Loss: 2.3057 (2.3243)  Acc@1: 87.5000 (88.6194)  Acc@5: 100.0000 (98.9428)  time: 0.2139  data: 0.0003  max mem: 2502
Test: [Task 3]  [210/625]  eta: 0:01:29  Loss: 2.2994 (2.3232)  Acc@1: 87.5000 (88.6552)  Acc@5: 100.0000 (98.9929)  time: 0.2132  data: 0.0003  max mem: 2502
Test: [Task 3]  [220/625]  eta: 0:01:27  Loss: 2.3294 (2.3261)  Acc@1: 87.5000 (88.3767)  Acc@5: 100.0000 (98.9819)  time: 0.2126  data: 0.0002  max mem: 2502
Test: [Task 3]  [230/625]  eta: 0:01:24  Loss: 2.3580 (2.3273)  Acc@1: 81.2500 (88.1223)  Acc@5: 100.0000 (98.9177)  time: 0.2127  data: 0.0002  max mem: 2502
Test: [Task 3]  [240/625]  eta: 0:01:22  Loss: 2.3536 (2.3291)  Acc@1: 81.2500 (87.9149)  Acc@5: 100.0000 (98.8589)  time: 0.2128  data: 0.0002  max mem: 2502
Test: [Task 3]  [250/625]  eta: 0:01:20  Loss: 2.2981 (2.3261)  Acc@1: 87.5000 (88.0976)  Acc@5: 100.0000 (98.8795)  time: 0.2126  data: 0.0002  max mem: 2502
Test: [Task 3]  [260/625]  eta: 0:01:18  Loss: 2.2764 (2.3255)  Acc@1: 93.7500 (88.1705)  Acc@5: 100.0000 (98.8266)  time: 0.2126  data: 0.0002  max mem: 2502
Test: [Task 3]  [270/625]  eta: 0:01:16  Loss: 2.2907 (2.3237)  Acc@1: 87.5000 (88.2841)  Acc@5: 100.0000 (98.8699)  time: 0.2127  data: 0.0002  max mem: 2502
Test: [Task 3]  [280/625]  eta: 0:01:14  Loss: 2.3001 (2.3239)  Acc@1: 87.5000 (88.2340)  Acc@5: 100.0000 (98.8434)  time: 0.2127  data: 0.0002  max mem: 2502
Test: [Task 3]  [290/625]  eta: 0:01:11  Loss: 2.3267 (2.3250)  Acc@1: 87.5000 (88.1658)  Acc@5: 100.0000 (98.8402)  time: 0.2129  data: 0.0002  max mem: 2502
Test: [Task 3]  [300/625]  eta: 0:01:09  Loss: 2.3070 (2.3290)  Acc@1: 87.5000 (87.9153)  Acc@5: 100.0000 (98.5465)  time: 0.2129  data: 0.0003  max mem: 2502
Test: [Task 3]  [310/625]  eta: 0:01:07  Loss: 2.3070 (2.3299)  Acc@1: 87.5000 (87.8617)  Acc@5: 100.0000 (98.5732)  time: 0.2129  data: 0.0002  max mem: 2502
Test: [Task 3]  [320/625]  eta: 0:01:05  Loss: 2.3159 (2.3300)  Acc@1: 87.5000 (87.8505)  Acc@5: 100.0000 (98.5592)  time: 0.2129  data: 0.0002  max mem: 2502
Test: [Task 3]  [330/625]  eta: 0:01:03  Loss: 2.3052 (2.3305)  Acc@1: 87.5000 (87.8210)  Acc@5: 100.0000 (98.5650)  time: 0.2128  data: 0.0002  max mem: 2502
Test: [Task 3]  [340/625]  eta: 0:01:01  Loss: 2.3052 (2.3300)  Acc@1: 87.5000 (87.7383)  Acc@5: 100.0000 (98.5887)  time: 0.2127  data: 0.0002  max mem: 2502
Test: [Task 3]  [350/625]  eta: 0:00:58  Loss: 2.2835 (2.3293)  Acc@1: 87.5000 (87.8205)  Acc@5: 100.0000 (98.6289)  time: 0.2133  data: 0.0003  max mem: 2502
Test: [Task 3]  [360/625]  eta: 0:00:56  Loss: 2.3154 (2.3312)  Acc@1: 87.5000 (87.7424)  Acc@5: 100.0000 (98.5803)  time: 0.2139  data: 0.0004  max mem: 2502
Test: [Task 3]  [370/625]  eta: 0:00:54  Loss: 2.3427 (2.3328)  Acc@1: 87.5000 (87.7358)  Acc@5: 100.0000 (98.5681)  time: 0.2139  data: 0.0004  max mem: 2502
Test: [Task 3]  [380/625]  eta: 0:00:52  Loss: 2.3602 (2.3332)  Acc@1: 87.5000 (87.6148)  Acc@5: 100.0000 (98.5728)  time: 0.2138  data: 0.0003  max mem: 2502
Test: [Task 3]  [390/625]  eta: 0:00:50  Loss: 2.3731 (2.3348)  Acc@1: 81.2500 (87.5320)  Acc@5: 100.0000 (98.5454)  time: 0.2140  data: 0.0004  max mem: 2502
Test: [Task 3]  [400/625]  eta: 0:00:48  Loss: 2.3408 (2.3337)  Acc@1: 87.5000 (87.6403)  Acc@5: 100.0000 (98.5661)  time: 0.2142  data: 0.0004  max mem: 2502
Test: [Task 3]  [410/625]  eta: 0:00:46  Loss: 2.3172 (2.3349)  Acc@1: 87.5000 (87.5912)  Acc@5: 100.0000 (98.5554)  time: 0.2136  data: 0.0004  max mem: 2502
Test: [Task 3]  [420/625]  eta: 0:00:43  Loss: 2.3371 (2.3349)  Acc@1: 87.5000 (87.6781)  Acc@5: 100.0000 (98.5748)  time: 0.2134  data: 0.0003  max mem: 2502
Test: [Task 3]  [430/625]  eta: 0:00:41  Loss: 2.3246 (2.3351)  Acc@1: 87.5000 (87.6160)  Acc@5: 100.0000 (98.5934)  time: 0.2139  data: 0.0004  max mem: 2502
Test: [Task 3]  [440/625]  eta: 0:00:39  Loss: 2.3347 (2.3360)  Acc@1: 87.5000 (87.5992)  Acc@5: 100.0000 (98.5544)  time: 0.2139  data: 0.0004  max mem: 2502
Test: [Task 3]  [450/625]  eta: 0:00:37  Loss: 2.3331 (2.3352)  Acc@1: 87.5000 (87.6524)  Acc@5: 100.0000 (98.5726)  time: 0.2138  data: 0.0003  max mem: 2502
Test: [Task 3]  [460/625]  eta: 0:00:35  Loss: 2.3298 (2.3345)  Acc@1: 93.7500 (87.7034)  Acc@5: 100.0000 (98.5900)  time: 0.2138  data: 0.0003  max mem: 2502
Test: [Task 3]  [470/625]  eta: 0:00:33  Loss: 2.3340 (2.3347)  Acc@1: 87.5000 (87.6327)  Acc@5: 100.0000 (98.5934)  time: 0.2138  data: 0.0004  max mem: 2502
Test: [Task 3]  [480/625]  eta: 0:00:31  Loss: 2.3240 (2.3349)  Acc@1: 81.2500 (87.5260)  Acc@5: 100.0000 (98.5967)  time: 0.2136  data: 0.0004  max mem: 2502
Test: [Task 3]  [490/625]  eta: 0:00:28  Loss: 2.3240 (2.3352)  Acc@1: 87.5000 (87.5382)  Acc@5: 100.0000 (98.5871)  time: 0.2136  data: 0.0003  max mem: 2502
Test: [Task 3]  [500/625]  eta: 0:00:26  Loss: 2.3060 (2.3346)  Acc@1: 87.5000 (87.5998)  Acc@5: 100.0000 (98.6028)  time: 0.2140  data: 0.0004  max mem: 2502
Test: [Task 3]  [510/625]  eta: 0:00:24  Loss: 2.3038 (2.3342)  Acc@1: 93.7500 (87.6468)  Acc@5: 100.0000 (98.6057)  time: 0.2138  data: 0.0004  max mem: 2502
Test: [Task 3]  [520/625]  eta: 0:00:22  Loss: 2.3233 (2.3346)  Acc@1: 87.5000 (87.6560)  Acc@5: 100.0000 (98.6324)  time: 0.2136  data: 0.0004  max mem: 2502
Test: [Task 3]  [530/625]  eta: 0:00:20  Loss: 2.3490 (2.3354)  Acc@1: 87.5000 (87.6059)  Acc@5: 100.0000 (98.6347)  time: 0.2139  data: 0.0004  max mem: 2502
Test: [Task 3]  [540/625]  eta: 0:00:18  Loss: 2.3282 (2.3350)  Acc@1: 87.5000 (87.6040)  Acc@5: 100.0000 (98.6599)  time: 0.2144  data: 0.0004  max mem: 2502
Test: [Task 3]  [550/625]  eta: 0:00:16  Loss: 2.3253 (2.3353)  Acc@1: 87.5000 (87.6134)  Acc@5: 100.0000 (98.6615)  time: 0.2143  data: 0.0004  max mem: 2502
Test: [Task 3]  [560/625]  eta: 0:00:13  Loss: 2.3485 (2.3352)  Acc@1: 87.5000 (87.6003)  Acc@5: 100.0000 (98.6631)  time: 0.2138  data: 0.0003  max mem: 2502
Test: [Task 3]  [570/625]  eta: 0:00:11  Loss: 2.3283 (2.3352)  Acc@1: 87.5000 (87.6532)  Acc@5: 100.0000 (98.6756)  time: 0.2138  data: 0.0003  max mem: 2502
Test: [Task 3]  [580/625]  eta: 0:00:09  Loss: 2.3244 (2.3350)  Acc@1: 87.5000 (87.6076)  Acc@5: 100.0000 (98.6876)  time: 0.2141  data: 0.0004  max mem: 2502
Test: [Task 3]  [590/625]  eta: 0:00:07  Loss: 2.3052 (2.3349)  Acc@1: 87.5000 (87.6058)  Acc@5: 100.0000 (98.6992)  time: 0.2143  data: 0.0003  max mem: 2502
Test: [Task 3]  [600/625]  eta: 0:00:05  Loss: 2.2829 (2.3339)  Acc@1: 87.5000 (87.6144)  Acc@5: 100.0000 (98.7209)  time: 0.2144  data: 0.0004  max mem: 2502
Test: [Task 3]  [610/625]  eta: 0:00:03  Loss: 2.2464 (2.3327)  Acc@1: 93.7500 (87.6841)  Acc@5: 100.0000 (98.7418)  time: 0.2143  data: 0.0004  max mem: 2502
Test: [Task 3]  [620/625]  eta: 0:00:01  Loss: 2.2797 (2.3332)  Acc@1: 87.5000 (87.6912)  Acc@5: 100.0000 (98.7118)  time: 0.2141  data: 0.0003  max mem: 2502
Test: [Task 3]  [624/625]  eta: 0:00:00  Loss: 2.2981 (2.3333)  Acc@1: 87.5000 (87.6900)  Acc@5: 100.0000 (98.7200)  time: 0.2141  data: 0.0003  max mem: 2502
Test: [Task 3] Total time: 0:02:13 (0.2144 s / it)
* Acc@1 87.690 Acc@5 98.720 loss 2.333
Test: [Task 4]  [ 0/29]  eta: 0:00:15  Loss: 4.0239 (4.0239)  Acc@1: 0.0000 (0.0000)  Acc@5: 0.0000 (0.0000)  time: 0.5279  data: 0.3129  max mem: 2502
Test: [Task 4]  [10/29]  eta: 0:00:04  Loss: 3.9816 (3.6458)  Acc@1: 0.0000 (19.8864)  Acc@5: 0.0000 (22.7273)  time: 0.2439  data: 0.0289  max mem: 2502
Test: [Task 4]  [20/29]  eta: 0:00:02  Loss: 2.7644 (3.3034)  Acc@1: 0.0000 (39.2857)  Acc@5: 6.2500 (42.8571)  time: 0.2146  data: 0.0004  max mem: 2502
Test: [Task 4]  [28/29]  eta: 0:00:00  Loss: 2.6618 (3.1049)  Acc@1: 75.0000 (44.4444)  Acc@5: 93.7500 (56.8627)  time: 0.2107  data: 0.0003  max mem: 2502
Test: [Task 4] Total time: 0:00:06 (0.2319 s / it)
* Acc@1 44.444 Acc@5 56.863 loss 3.105
Test: [Task 5]  [  0/625]  eta: 0:04:59  Loss: 2.1105 (2.1105)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)  time: 0.4800  data: 0.2630  max mem: 2502
Test: [Task 5]  [ 10/625]  eta: 0:02:26  Loss: 2.2065 (2.2350)  Acc@1: 81.2500 (82.3864)  Acc@5: 100.0000 (99.4318)  time: 0.2383  data: 0.0241  max mem: 2502
Test: [Task 5]  [ 20/625]  eta: 0:02:17  Loss: 2.2065 (2.2333)  Acc@1: 81.2500 (83.6310)  Acc@5: 100.0000 (99.7024)  time: 0.2139  data: 0.0003  max mem: 2502
Test: [Task 5]  [ 30/625]  eta: 0:02:12  Loss: 2.2080 (2.2368)  Acc@1: 87.5000 (83.6694)  Acc@5: 100.0000 (99.3952)  time: 0.2136  data: 0.0003  max mem: 2502
Test: [Task 5]  [ 40/625]  eta: 0:02:08  Loss: 2.2217 (2.2436)  Acc@1: 81.2500 (83.5366)  Acc@5: 100.0000 (99.3902)  time: 0.2139  data: 0.0003  max mem: 2502
Test: [Task 5]  [ 50/625]  eta: 0:02:06  Loss: 2.1887 (2.2445)  Acc@1: 81.2500 (83.4559)  Acc@5: 100.0000 (99.0196)  time: 0.2142  data: 0.0003  max mem: 2502
Test: [Task 5]  [ 60/625]  eta: 0:02:03  Loss: 2.1841 (2.2424)  Acc@1: 81.2500 (82.7869)  Acc@5: 100.0000 (98.9754)  time: 0.2139  data: 0.0003  max mem: 2502
Test: [Task 5]  [ 70/625]  eta: 0:02:00  Loss: 2.2628 (2.2467)  Acc@1: 81.2500 (82.9225)  Acc@5: 100.0000 (98.9437)  time: 0.2135  data: 0.0003  max mem: 2502
Test: [Task 5]  [ 80/625]  eta: 0:01:58  Loss: 2.2743 (2.2564)  Acc@1: 81.2500 (82.4846)  Acc@5: 100.0000 (98.7654)  time: 0.2135  data: 0.0003  max mem: 2502
Test: [Task 5]  [ 90/625]  eta: 0:01:55  Loss: 2.2555 (2.2522)  Acc@1: 81.2500 (82.5549)  Acc@5: 100.0000 (98.8324)  time: 0.2137  data: 0.0003  max mem: 2502
Test: [Task 5]  [100/625]  eta: 0:01:53  Loss: 2.2557 (2.2571)  Acc@1: 81.2500 (81.9926)  Acc@5: 100.0000 (98.7005)  time: 0.2139  data: 0.0003  max mem: 2502
Test: [Task 5]  [110/625]  eta: 0:01:51  Loss: 2.2871 (2.2657)  Acc@1: 75.0000 (81.3626)  Acc@5: 100.0000 (98.7050)  time: 0.2135  data: 0.0003  max mem: 2502
Test: [Task 5]  [120/625]  eta: 0:01:49  Loss: 2.1778 (2.2587)  Acc@1: 81.2500 (81.9215)  Acc@5: 100.0000 (98.7603)  time: 0.2131  data: 0.0003  max mem: 2502
Test: [Task 5]  [130/625]  eta: 0:01:46  Loss: 2.1781 (2.2644)  Acc@1: 81.2500 (81.3454)  Acc@5: 100.0000 (98.6641)  time: 0.2130  data: 0.0002  max mem: 2502
Test: [Task 5]  [140/625]  eta: 0:01:44  Loss: 2.2286 (2.2603)  Acc@1: 81.2500 (81.6046)  Acc@5: 100.0000 (98.6259)  time: 0.2131  data: 0.0002  max mem: 2502
Test: [Task 5]  [150/625]  eta: 0:01:42  Loss: 2.2255 (2.2605)  Acc@1: 81.2500 (81.5811)  Acc@5: 100.0000 (98.6341)  time: 0.2135  data: 0.0002  max mem: 2502
Test: [Task 5]  [160/625]  eta: 0:01:40  Loss: 2.2559 (2.2629)  Acc@1: 81.2500 (81.5217)  Acc@5: 100.0000 (98.6413)  time: 0.2137  data: 0.0003  max mem: 2502
Test: [Task 5]  [170/625]  eta: 0:01:37  Loss: 2.2661 (2.2651)  Acc@1: 81.2500 (81.3231)  Acc@5: 100.0000 (98.6111)  time: 0.2142  data: 0.0003  max mem: 2502
Test: [Task 5]  [180/625]  eta: 0:01:35  Loss: 2.2420 (2.2636)  Acc@1: 81.2500 (81.3536)  Acc@5: 100.0000 (98.6188)  time: 0.2142  data: 0.0003  max mem: 2502
Test: [Task 5]  [190/625]  eta: 0:01:33  Loss: 2.2025 (2.2691)  Acc@1: 81.2500 (81.1191)  Acc@5: 100.0000 (98.3639)  time: 0.2139  data: 0.0003  max mem: 2502
Test: [Task 5]  [200/625]  eta: 0:01:31  Loss: 2.2754 (2.2690)  Acc@1: 75.0000 (80.8769)  Acc@5: 100.0000 (98.3520)  time: 0.2145  data: 0.0004  max mem: 2502
Test: [Task 5]  [210/625]  eta: 0:01:29  Loss: 2.2755 (2.2710)  Acc@1: 75.0000 (80.7761)  Acc@5: 100.0000 (98.2524)  time: 0.2146  data: 0.0004  max mem: 2502
Test: [Task 5]  [220/625]  eta: 0:01:27  Loss: 2.2755 (2.2725)  Acc@1: 75.0000 (80.7127)  Acc@5: 100.0000 (98.2466)  time: 0.2143  data: 0.0003  max mem: 2502
Test: [Task 5]  [230/625]  eta: 0:01:24  Loss: 2.2528 (2.2707)  Acc@1: 81.2500 (80.7089)  Acc@5: 100.0000 (98.2684)  time: 0.2146  data: 0.0004  max mem: 2502
Test: [Task 5]  [240/625]  eta: 0:01:22  Loss: 2.2564 (2.2720)  Acc@1: 81.2500 (80.7054)  Acc@5: 100.0000 (98.1846)  time: 0.2150  data: 0.0003  max mem: 2502
Test: [Task 5]  [250/625]  eta: 0:01:20  Loss: 2.2956 (2.2725)  Acc@1: 81.2500 (80.6275)  Acc@5: 100.0000 (98.1574)  time: 0.2150  data: 0.0003  max mem: 2502
Test: [Task 5]  [260/625]  eta: 0:01:18  Loss: 2.3083 (2.2758)  Acc@1: 75.0000 (80.5556)  Acc@5: 100.0000 (98.1561)  time: 0.2146  data: 0.0003  max mem: 2502
Test: [Task 5]  [270/625]  eta: 0:01:16  Loss: 2.2971 (2.2745)  Acc@1: 75.0000 (80.6042)  Acc@5: 100.0000 (98.1780)  time: 0.2145  data: 0.0003  max mem: 2502
Test: [Task 5]  [280/625]  eta: 0:01:14  Loss: 2.1757 (2.2728)  Acc@1: 81.2500 (80.7162)  Acc@5: 100.0000 (98.1762)  time: 0.2153  data: 0.0004  max mem: 2502
Test: [Task 5]  [290/625]  eta: 0:01:12  Loss: 2.1821 (2.2701)  Acc@1: 81.2500 (80.8204)  Acc@5: 100.0000 (98.2388)  time: 0.2154  data: 0.0003  max mem: 2502
Test: [Task 5]  [300/625]  eta: 0:01:09  Loss: 2.2071 (2.2688)  Acc@1: 81.2500 (81.0008)  Acc@5: 100.0000 (98.2973)  time: 0.2147  data: 0.0003  max mem: 2502
Test: [Task 5]  [310/625]  eta: 0:01:07  Loss: 2.2442 (2.2695)  Acc@1: 87.5000 (81.0289)  Acc@5: 100.0000 (98.2918)  time: 0.2147  data: 0.0003  max mem: 2502
Test: [Task 5]  [320/625]  eta: 0:01:05  Loss: 2.3273 (2.2713)  Acc@1: 81.2500 (80.9190)  Acc@5: 100.0000 (98.2866)  time: 0.2150  data: 0.0003  max mem: 2502
Test: [Task 5]  [330/625]  eta: 0:01:03  Loss: 2.3102 (2.2710)  Acc@1: 81.2500 (80.8535)  Acc@5: 100.0000 (98.2628)  time: 0.2149  data: 0.0003  max mem: 2502
Test: [Task 5]  [340/625]  eta: 0:01:01  Loss: 2.2071 (2.2679)  Acc@1: 87.5000 (81.0850)  Acc@5: 100.0000 (98.2771)  time: 0.2149  data: 0.0003  max mem: 2502
Test: [Task 5]  [350/625]  eta: 0:00:59  Loss: 2.2194 (2.2706)  Acc@1: 81.2500 (80.9117)  Acc@5: 100.0000 (98.2728)  time: 0.2149  data: 0.0003  max mem: 2502
Test: [Task 5]  [360/625]  eta: 0:00:56  Loss: 2.3106 (2.2698)  Acc@1: 75.0000 (80.8864)  Acc@5: 100.0000 (98.2860)  time: 0.2148  data: 0.0003  max mem: 2502
Test: [Task 5]  [370/625]  eta: 0:00:54  Loss: 2.2464 (2.2698)  Acc@1: 75.0000 (80.7783)  Acc@5: 100.0000 (98.2985)  time: 0.2150  data: 0.0003  max mem: 2502
Test: [Task 5]  [380/625]  eta: 0:00:52  Loss: 2.2322 (2.2698)  Acc@1: 81.2500 (80.7579)  Acc@5: 100.0000 (98.2940)  time: 0.2152  data: 0.0003  max mem: 2502
Test: [Task 5]  [390/625]  eta: 0:00:50  Loss: 2.2834 (2.2717)  Acc@1: 81.2500 (80.5946)  Acc@5: 100.0000 (98.2577)  time: 0.2148  data: 0.0003  max mem: 2502
Test: [Task 5]  [400/625]  eta: 0:00:48  Loss: 2.2892 (2.2713)  Acc@1: 75.0000 (80.5954)  Acc@5: 100.0000 (98.2855)  time: 0.2143  data: 0.0002  max mem: 2502
Test: [Task 5]  [410/625]  eta: 0:00:46  Loss: 2.2420 (2.2710)  Acc@1: 81.2500 (80.6113)  Acc@5: 100.0000 (98.2968)  time: 0.2144  data: 0.0003  max mem: 2502
Test: [Task 5]  [420/625]  eta: 0:00:44  Loss: 2.2666 (2.2718)  Acc@1: 81.2500 (80.5671)  Acc@5: 100.0000 (98.3076)  time: 0.2143  data: 0.0003  max mem: 2502
Test: [Task 5]  [430/625]  eta: 0:00:41  Loss: 2.2778 (2.2703)  Acc@1: 75.0000 (80.6410)  Acc@5: 100.0000 (98.3324)  time: 0.2140  data: 0.0002  max mem: 2502
Test: [Task 5]  [440/625]  eta: 0:00:39  Loss: 2.2603 (2.2706)  Acc@1: 81.2500 (80.6122)  Acc@5: 100.0000 (98.3702)  time: 0.2141  data: 0.0002  max mem: 2502
Test: [Task 5]  [450/625]  eta: 0:00:37  Loss: 2.2529 (2.2698)  Acc@1: 81.2500 (80.6402)  Acc@5: 100.0000 (98.3925)  time: 0.2143  data: 0.0002  max mem: 2502
Test: [Task 5]  [460/625]  eta: 0:00:35  Loss: 2.2680 (2.2705)  Acc@1: 81.2500 (80.6128)  Acc@5: 100.0000 (98.3460)  time: 0.2143  data: 0.0003  max mem: 2502
Test: [Task 5]  [470/625]  eta: 0:00:33  Loss: 2.2409 (2.2694)  Acc@1: 81.2500 (80.6661)  Acc@5: 100.0000 (98.3811)  time: 0.2143  data: 0.0002  max mem: 2502
Test: [Task 5]  [480/625]  eta: 0:00:31  Loss: 2.1887 (2.2682)  Acc@1: 81.2500 (80.7562)  Acc@5: 100.0000 (98.3888)  time: 0.2143  data: 0.0002  max mem: 2502
Test: [Task 5]  [490/625]  eta: 0:00:29  Loss: 2.1887 (2.2670)  Acc@1: 81.2500 (80.8172)  Acc@5: 100.0000 (98.4216)  time: 0.2144  data: 0.0002  max mem: 2502
Test: [Task 5]  [500/625]  eta: 0:00:26  Loss: 2.2289 (2.2676)  Acc@1: 81.2500 (80.7385)  Acc@5: 100.0000 (98.4157)  time: 0.2144  data: 0.0003  max mem: 2502
Test: [Task 5]  [510/625]  eta: 0:00:24  Loss: 2.2891 (2.2679)  Acc@1: 75.0000 (80.7118)  Acc@5: 100.0000 (98.3611)  time: 0.2145  data: 0.0003  max mem: 2502
Test: [Task 5]  [520/625]  eta: 0:00:22  Loss: 2.2891 (2.2678)  Acc@1: 81.2500 (80.7941)  Acc@5: 100.0000 (98.3805)  time: 0.2144  data: 0.0002  max mem: 2502
Test: [Task 5]  [530/625]  eta: 0:00:20  Loss: 2.1450 (2.2654)  Acc@1: 87.5000 (80.9204)  Acc@5: 100.0000 (98.4110)  time: 0.2141  data: 0.0002  max mem: 2502
Test: [Task 5]  [540/625]  eta: 0:00:18  Loss: 2.1646 (2.2646)  Acc@1: 87.5000 (80.9265)  Acc@5: 100.0000 (98.4057)  time: 0.2144  data: 0.0002  max mem: 2502
Test: [Task 5]  [550/625]  eta: 0:00:16  Loss: 2.2171 (2.2651)  Acc@1: 75.0000 (80.8757)  Acc@5: 100.0000 (98.3666)  time: 0.2148  data: 0.0003  max mem: 2502
Test: [Task 5]  [560/625]  eta: 0:00:13  Loss: 2.2214 (2.2647)  Acc@1: 81.2500 (80.8935)  Acc@5: 100.0000 (98.3289)  time: 0.2148  data: 0.0004  max mem: 2502
Test: [Task 5]  [570/625]  eta: 0:00:11  Loss: 2.2214 (2.2651)  Acc@1: 81.2500 (80.8669)  Acc@5: 100.0000 (98.3253)  time: 0.2150  data: 0.0003  max mem: 2502
Test: [Task 5]  [580/625]  eta: 0:00:09  Loss: 2.3187 (2.2665)  Acc@1: 81.2500 (80.7982)  Acc@5: 100.0000 (98.3219)  time: 0.2152  data: 0.0004  max mem: 2502
Test: [Task 5]  [590/625]  eta: 0:00:07  Loss: 2.3479 (2.2673)  Acc@1: 75.0000 (80.7212)  Acc@5: 100.0000 (98.2974)  time: 0.2148  data: 0.0003  max mem: 2502
Test: [Task 5]  [600/625]  eta: 0:00:05  Loss: 2.2804 (2.2675)  Acc@1: 81.2500 (80.7300)  Acc@5: 100.0000 (98.2945)  time: 0.2149  data: 0.0003  max mem: 2502
Test: [Task 5]  [610/625]  eta: 0:00:03  Loss: 2.2347 (2.2666)  Acc@1: 81.2500 (80.7999)  Acc@5: 100.0000 (98.2917)  time: 0.2153  data: 0.0003  max mem: 2502
Test: [Task 5]  [620/625]  eta: 0:00:01  Loss: 2.1792 (2.2652)  Acc@1: 87.5000 (80.8877)  Acc@5: 100.0000 (98.2991)  time: 0.2149  data: 0.0003  max mem: 2502
Test: [Task 5]  [624/625]  eta: 0:00:00  Loss: 2.2347 (2.2656)  Acc@1: 81.2500 (80.8600)  Acc@5: 100.0000 (98.3000)  time: 0.2148  data: 0.0002  max mem: 2502
Test: [Task 5] Total time: 0:02:14 (0.2151 s / it)
* Acc@1 80.860 Acc@5 98.300 loss 2.266
{0: {0: 26032, 1: 26032, 2: 26032, 3: 26032, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0, 10: 0, 11: 0, 12: 0, 13: 0, 14: 0, 15: 0, 16: 0, 17: 0, 18: 0, 19: 0}, 1: {0: 0, 1: 0, 2: 0, 3: 0, 4: 10000, 5: 10000, 6: 10000, 7: 10000, 8: 0, 9: 0, 10: 0, 11: 0, 12: 0, 13: 0, 14: 0, 15: 0, 16: 0, 17: 0, 18: 0, 19: 0}, 2: {0: 16, 1: 16, 2: 16, 3: 16, 4: 0, 5: 0, 6: 0, 7: 0, 8: 9984, 9: 9984, 10: 9984, 11: 9984, 12: 0, 13: 0, 14: 0, 15: 0, 16: 0, 17: 0, 18: 0, 19: 0}, 3: {0: 0, 1: 0, 2: 0, 3: 0, 4: 176, 5: 176, 6: 176, 7: 176, 8: 0, 9: 0, 10: 0, 11: 0, 12: 283, 13: 283, 14: 283, 15: 283, 16: 0, 17: 0, 18: 0, 19: 0}, 4: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0, 10: 0, 11: 0, 12: 0, 13: 0, 14: 0, 15: 0, 16: 10000, 17: 10000, 18: 10000, 19: 10000}}
[Average accuracy till task5]	Acc@1: 77.7661	Acc@5: 89.8819	Loss: 2.4375	Forgetting: 0.0000	Backward: 0.0000
Total training time: 8:37:33
