/storagenfs/d.arcelli/Prompting-Based-CL-Methods-Experiments/.env/lib/python3.9/site-packages/torchvision/transforms/transforms.py:329: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.
  warnings.warn(
Namespace(subparser_name='cifar100_l2p', train_type='l2p', batch_size=16, epochs=5, model='vit_base_patch16_224', input_size=224, pretrained=True, drop=0.0, drop_path=0.0, opt='adam', opt_eps=1e-08, opt_betas=(0.9, 0.999), clip_grad=1.0, momentum=0.9, weight_decay=0.0, reinit_optimizer=True, sched='constant', lr=0.03, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, unscale_lr=True, color_jitter=None, aa=None, smoothing=0.1, train_interpolation='bicubic', reprob=0.0, remode='pixel', recount=1, data_path='./local_datasets/', dataset='Split-CIFAR100', shuffle=False, output_dir='./test_dir', device='cuda', seed=42, eval=False, num_workers=4, pin_mem=True, world_size=1, dist_url='env://', num_tasks=10, train_mask=True, task_inc=False, prompt_pool=True, size=50, length=5, top_k=5, initializer='uniform', prompt_key=True, prompt_key_init='uniform', use_prompt_mask=True, shared_prompt_pool=False, shared_prompt_key=False, batchwise_prompt=True, embedding_key='cls', predefined_key='', pull_constraint=True, pull_constraint_coeff=0.5, global_pool='token', head_type='prompt', freeze=['blocks', 'patch_embed', 'cls_token', 'norm', 'pos_embed'], freeze_head=False, print_freq=10, eval_task_id=False, frequency_penalization=False, class_incremental=False, init_class_prompts=False, task_incremental=True, init_tasks_prompts=True)
Not using distributed mode
Files already downloaded and verified
Files already downloaded and verified
Creating original model: vit_base_patch16_224
Creating model: vit_base_patch16_224
number of params: 307300
Start training for 5 epochs
Train: Epoch[1/5]  [  0/313]  eta: 0:08:17  Lr: 0.001875  Loss: 1.4827  Acc@1: 0.0000 (0.0000)  Acc@5: 43.7500 (43.7500)  time: 1.5902  data: 0.2781  max mem: 2355
Train: Epoch[1/5]  [ 10/313]  eta: 0:02:13  Lr: 0.001875  Loss: 1.1238  Acc@1: 31.2500 (30.1136)  Acc@5: 81.2500 (77.2727)  time: 0.4398  data: 0.0256  max mem: 2359
Train: Epoch[1/5]  [ 20/313]  eta: 0:01:52  Lr: 0.001875  Loss: 0.7482  Acc@1: 43.7500 (44.0476)  Acc@5: 87.5000 (82.1429)  time: 0.3248  data: 0.0003  max mem: 2359
Train: Epoch[1/5]  [ 30/313]  eta: 0:01:43  Lr: 0.001875  Loss: 0.5542  Acc@1: 62.5000 (53.2258)  Acc@5: 87.5000 (85.6855)  time: 0.3255  data: 0.0018  max mem: 2359
Train: Epoch[1/5]  [ 40/313]  eta: 0:01:37  Lr: 0.001875  Loss: 0.4279  Acc@1: 68.7500 (57.4695)  Acc@5: 100.0000 (88.4146)  time: 0.3259  data: 0.0027  max mem: 2359
Train: Epoch[1/5]  [ 50/313]  eta: 0:01:32  Lr: 0.001875  Loss: 0.0098  Acc@1: 75.0000 (60.6618)  Acc@5: 93.7500 (89.8284)  time: 0.3249  data: 0.0012  max mem: 2359
Train: Epoch[1/5]  [ 60/313]  eta: 0:01:27  Lr: 0.001875  Loss: -0.0713  Acc@1: 75.0000 (63.3197)  Acc@5: 93.7500 (90.5738)  time: 0.3251  data: 0.0003  max mem: 2359
Train: Epoch[1/5]  [ 70/313]  eta: 0:01:23  Lr: 0.001875  Loss: 0.1116  Acc@1: 75.0000 (65.0528)  Acc@5: 100.0000 (91.4613)  time: 0.3265  data: 0.0002  max mem: 2359
Train: Epoch[1/5]  [ 80/313]  eta: 0:01:19  Lr: 0.001875  Loss: 0.2134  Acc@1: 75.0000 (66.0494)  Acc@5: 100.0000 (92.0525)  time: 0.3264  data: 0.0002  max mem: 2359
Train: Epoch[1/5]  [ 90/313]  eta: 0:01:15  Lr: 0.001875  Loss: 0.0426  Acc@1: 75.0000 (67.3077)  Acc@5: 93.7500 (92.3077)  time: 0.3258  data: 0.0002  max mem: 2359
Train: Epoch[1/5]  [100/313]  eta: 0:01:12  Lr: 0.001875  Loss: -0.1812  Acc@1: 81.2500 (68.8738)  Acc@5: 93.7500 (92.7599)  time: 0.3262  data: 0.0002  max mem: 2359
Train: Epoch[1/5]  [110/313]  eta: 0:01:08  Lr: 0.001875  Loss: -0.1746  Acc@1: 81.2500 (69.6509)  Acc@5: 100.0000 (93.0180)  time: 0.3259  data: 0.0003  max mem: 2359
Train: Epoch[1/5]  [120/313]  eta: 0:01:04  Lr: 0.001875  Loss: -0.2423  Acc@1: 75.0000 (70.5062)  Acc@5: 100.0000 (93.4917)  time: 0.3271  data: 0.0016  max mem: 2359
Train: Epoch[1/5]  [130/313]  eta: 0:01:01  Lr: 0.001875  Loss: -0.4709  Acc@1: 81.2500 (71.0878)  Acc@5: 100.0000 (93.7977)  time: 0.3277  data: 0.0016  max mem: 2359
Train: Epoch[1/5]  [140/313]  eta: 0:00:57  Lr: 0.001875  Loss: -0.2378  Acc@1: 81.2500 (71.8528)  Acc@5: 100.0000 (94.1046)  time: 0.3256  data: 0.0003  max mem: 2359
Train: Epoch[1/5]  [150/313]  eta: 0:00:54  Lr: 0.001875  Loss: -0.3400  Acc@1: 81.2500 (72.4752)  Acc@5: 100.0000 (94.2881)  time: 0.3255  data: 0.0003  max mem: 2359
Train: Epoch[1/5]  [160/313]  eta: 0:00:51  Lr: 0.001875  Loss: -0.4886  Acc@1: 81.2500 (73.2143)  Acc@5: 93.7500 (94.4099)  time: 0.3259  data: 0.0002  max mem: 2359
Train: Epoch[1/5]  [170/313]  eta: 0:00:47  Lr: 0.001875  Loss: -0.3666  Acc@1: 81.2500 (73.3553)  Acc@5: 93.7500 (94.5541)  time: 0.3257  data: 0.0002  max mem: 2359
Train: Epoch[1/5]  [180/313]  eta: 0:00:44  Lr: 0.001875  Loss: -0.3920  Acc@1: 81.2500 (74.0677)  Acc@5: 93.7500 (94.6823)  time: 0.3259  data: 0.0002  max mem: 2359
Train: Epoch[1/5]  [190/313]  eta: 0:00:40  Lr: 0.001875  Loss: -0.5635  Acc@1: 87.5000 (74.6728)  Acc@5: 100.0000 (94.8953)  time: 0.3261  data: 0.0003  max mem: 2359
Train: Epoch[1/5]  [200/313]  eta: 0:00:37  Lr: 0.001875  Loss: 0.1752  Acc@1: 87.5000 (74.9067)  Acc@5: 100.0000 (95.0560)  time: 0.3258  data: 0.0003  max mem: 2359
Train: Epoch[1/5]  [210/313]  eta: 0:00:34  Lr: 0.001875  Loss: -0.8535  Acc@1: 87.5000 (75.2073)  Acc@5: 100.0000 (95.2310)  time: 0.3265  data: 0.0002  max mem: 2359
Train: Epoch[1/5]  [220/313]  eta: 0:00:30  Lr: 0.001875  Loss: -0.2958  Acc@1: 81.2500 (75.5939)  Acc@5: 100.0000 (95.4468)  time: 0.3270  data: 0.0002  max mem: 2359
Train: Epoch[1/5]  [230/313]  eta: 0:00:27  Lr: 0.001875  Loss: -0.6068  Acc@1: 81.2500 (75.8929)  Acc@5: 100.0000 (95.4816)  time: 0.3267  data: 0.0003  max mem: 2359
Train: Epoch[1/5]  [240/313]  eta: 0:00:24  Lr: 0.001875  Loss: -0.3342  Acc@1: 81.2500 (76.2448)  Acc@5: 93.7500 (95.5135)  time: 0.3271  data: 0.0005  max mem: 2359
Train: Epoch[1/5]  [250/313]  eta: 0:00:20  Lr: 0.001875  Loss: -0.0539  Acc@1: 81.2500 (76.4193)  Acc@5: 100.0000 (95.5926)  time: 0.3272  data: 0.0004  max mem: 2359
Train: Epoch[1/5]  [260/313]  eta: 0:00:17  Lr: 0.001875  Loss: -0.5055  Acc@1: 81.2500 (76.7960)  Acc@5: 100.0000 (95.7136)  time: 0.3278  data: 0.0002  max mem: 2359
Train: Epoch[1/5]  [270/313]  eta: 0:00:14  Lr: 0.001875  Loss: -0.4693  Acc@1: 87.5000 (77.2140)  Acc@5: 100.0000 (95.8256)  time: 0.3279  data: 0.0002  max mem: 2359
Train: Epoch[1/5]  [280/313]  eta: 0:00:10  Lr: 0.001875  Loss: -0.4157  Acc@1: 87.5000 (77.4911)  Acc@5: 100.0000 (95.9075)  time: 0.3273  data: 0.0002  max mem: 2359
Train: Epoch[1/5]  [290/313]  eta: 0:00:07  Lr: 0.001875  Loss: -0.2688  Acc@1: 87.5000 (77.6847)  Acc@5: 100.0000 (96.0266)  time: 0.3276  data: 0.0007  max mem: 2359
Train: Epoch[1/5]  [300/313]  eta: 0:00:04  Lr: 0.001875  Loss: -0.6024  Acc@1: 81.2500 (77.9485)  Acc@5: 100.0000 (96.0548)  time: 0.3277  data: 0.0007  max mem: 2359
Train: Epoch[1/5]  [310/313]  eta: 0:00:00  Lr: 0.001875  Loss: -0.2876  Acc@1: 81.2500 (78.0547)  Acc@5: 93.7500 (96.0611)  time: 0.3274  data: 0.0002  max mem: 2359
Train: Epoch[1/5]  [312/313]  eta: 0:00:00  Lr: 0.001875  Loss: 0.0787  Acc@1: 81.2500 (78.0200)  Acc@5: 93.7500 (96.0400)  time: 0.3239  data: 0.0002  max mem: 2359
Train: Epoch[1/5] Total time: 0:01:43 (0.3305 s / it)
Averaged stats: Lr: 0.001875  Loss: 0.0787  Acc@1: 81.2500 (78.0200)  Acc@5: 93.7500 (96.0400)
Train: Epoch[2/5]  [  0/313]  eta: 0:02:51  Lr: 0.001875  Loss: -0.7654  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)  time: 0.5473  data: 0.2192  max mem: 2359
Train: Epoch[2/5]  [ 10/313]  eta: 0:01:45  Lr: 0.001875  Loss: -0.7264  Acc@1: 87.5000 (88.0682)  Acc@5: 100.0000 (98.2955)  time: 0.3488  data: 0.0206  max mem: 2359
Train: Epoch[2/5]  [ 20/313]  eta: 0:01:39  Lr: 0.001875  Loss: -0.3597  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (98.2143)  time: 0.3278  data: 0.0005  max mem: 2359
Train: Epoch[2/5]  [ 30/313]  eta: 0:01:34  Lr: 0.001875  Loss: -0.5489  Acc@1: 87.5000 (87.2984)  Acc@5: 100.0000 (98.5887)  time: 0.3273  data: 0.0002  max mem: 2359
Train: Epoch[2/5]  [ 40/313]  eta: 0:01:30  Lr: 0.001875  Loss: -0.8466  Acc@1: 87.5000 (85.9756)  Acc@5: 100.0000 (98.6280)  time: 0.3281  data: 0.0002  max mem: 2359
Train: Epoch[2/5]  [ 50/313]  eta: 0:01:27  Lr: 0.001875  Loss: -0.5084  Acc@1: 81.2500 (85.2941)  Acc@5: 100.0000 (98.4069)  time: 0.3293  data: 0.0002  max mem: 2359
Train: Epoch[2/5]  [ 60/313]  eta: 0:01:24  Lr: 0.001875  Loss: -0.6617  Acc@1: 87.5000 (86.0656)  Acc@5: 100.0000 (98.2582)  time: 0.3302  data: 0.0003  max mem: 2359
Train: Epoch[2/5]  [ 70/313]  eta: 0:01:20  Lr: 0.001875  Loss: -0.6759  Acc@1: 87.5000 (85.1232)  Acc@5: 100.0000 (98.0634)  time: 0.3290  data: 0.0003  max mem: 2359
Train: Epoch[2/5]  [ 80/313]  eta: 0:01:17  Lr: 0.001875  Loss: -0.6193  Acc@1: 87.5000 (85.3395)  Acc@5: 100.0000 (98.2253)  time: 0.3282  data: 0.0002  max mem: 2359
Train: Epoch[2/5]  [ 90/313]  eta: 0:01:13  Lr: 0.001875  Loss: -0.7004  Acc@1: 87.5000 (85.5769)  Acc@5: 100.0000 (98.2830)  time: 0.3295  data: 0.0007  max mem: 2359
Train: Epoch[2/5]  [100/313]  eta: 0:01:10  Lr: 0.001875  Loss: -0.7229  Acc@1: 87.5000 (85.7673)  Acc@5: 100.0000 (98.1436)  time: 0.3305  data: 0.0007  max mem: 2359
Train: Epoch[2/5]  [110/313]  eta: 0:01:07  Lr: 0.001875  Loss: -0.6479  Acc@1: 87.5000 (85.6982)  Acc@5: 100.0000 (98.2545)  time: 0.3298  data: 0.0003  max mem: 2359
Train: Epoch[2/5]  [120/313]  eta: 0:01:03  Lr: 0.001875  Loss: -0.4812  Acc@1: 87.5000 (85.5888)  Acc@5: 100.0000 (98.1921)  time: 0.3294  data: 0.0002  max mem: 2359
Train: Epoch[2/5]  [130/313]  eta: 0:01:00  Lr: 0.001875  Loss: -0.1748  Acc@1: 87.5000 (84.9237)  Acc@5: 100.0000 (98.1870)  time: 0.3294  data: 0.0002  max mem: 2359
Train: Epoch[2/5]  [140/313]  eta: 0:00:57  Lr: 0.001875  Loss: -0.5732  Acc@1: 81.2500 (84.8848)  Acc@5: 100.0000 (98.3156)  time: 0.3286  data: 0.0002  max mem: 2359
Train: Epoch[2/5]  [150/313]  eta: 0:00:53  Lr: 0.001875  Loss: -0.8044  Acc@1: 87.5000 (85.1407)  Acc@5: 100.0000 (98.3444)  time: 0.3289  data: 0.0002  max mem: 2359
Train: Epoch[2/5]  [160/313]  eta: 0:00:50  Lr: 0.001875  Loss: -0.7028  Acc@1: 87.5000 (85.2873)  Acc@5: 100.0000 (98.4084)  time: 0.3289  data: 0.0002  max mem: 2359
Train: Epoch[2/5]  [170/313]  eta: 0:00:47  Lr: 0.001875  Loss: -0.4370  Acc@1: 81.2500 (85.0512)  Acc@5: 100.0000 (98.4649)  time: 0.3288  data: 0.0004  max mem: 2359
Train: Epoch[2/5]  [180/313]  eta: 0:00:43  Lr: 0.001875  Loss: -0.6357  Acc@1: 81.2500 (84.8757)  Acc@5: 100.0000 (98.4807)  time: 0.3291  data: 0.0004  max mem: 2359
Train: Epoch[2/5]  [190/313]  eta: 0:00:40  Lr: 0.001875  Loss: -0.4105  Acc@1: 81.2500 (84.8822)  Acc@5: 100.0000 (98.4620)  time: 0.3296  data: 0.0002  max mem: 2359
Train: Epoch[2/5]  [200/313]  eta: 0:00:37  Lr: 0.001875  Loss: -0.4088  Acc@1: 87.5000 (84.9813)  Acc@5: 100.0000 (98.4453)  time: 0.3301  data: 0.0002  max mem: 2359
Train: Epoch[2/5]  [210/313]  eta: 0:00:34  Lr: 0.001875  Loss: -0.7085  Acc@1: 87.5000 (85.1600)  Acc@5: 100.0000 (98.4597)  time: 0.3307  data: 0.0009  max mem: 2359
Train: Epoch[2/5]  [220/313]  eta: 0:00:30  Lr: 0.001875  Loss: -0.8679  Acc@1: 87.5000 (85.3507)  Acc@5: 100.0000 (98.4729)  time: 0.3305  data: 0.0009  max mem: 2359
Train: Epoch[2/5]  [230/313]  eta: 0:00:27  Lr: 0.001875  Loss: -0.6206  Acc@1: 87.5000 (85.2543)  Acc@5: 100.0000 (98.4578)  time: 0.3293  data: 0.0002  max mem: 2359
Train: Epoch[2/5]  [240/313]  eta: 0:00:24  Lr: 0.001875  Loss: -0.6967  Acc@1: 87.5000 (85.1660)  Acc@5: 100.0000 (98.4440)  time: 0.3291  data: 0.0002  max mem: 2359
Train: Epoch[2/5]  [250/313]  eta: 0:00:20  Lr: 0.001875  Loss: -0.4069  Acc@1: 87.5000 (85.1594)  Acc@5: 100.0000 (98.4064)  time: 0.3296  data: 0.0003  max mem: 2359
Train: Epoch[2/5]  [260/313]  eta: 0:00:17  Lr: 0.001875  Loss: -0.5444  Acc@1: 87.5000 (85.2011)  Acc@5: 100.0000 (98.3956)  time: 0.3303  data: 0.0003  max mem: 2359
Train: Epoch[2/5]  [270/313]  eta: 0:00:14  Lr: 0.001875  Loss: -0.7824  Acc@1: 87.5000 (85.1476)  Acc@5: 100.0000 (98.3856)  time: 0.3310  data: 0.0009  max mem: 2359
Train: Epoch[2/5]  [280/313]  eta: 0:00:10  Lr: 0.001875  Loss: -0.7602  Acc@1: 87.5000 (85.3648)  Acc@5: 100.0000 (98.4431)  time: 0.3303  data: 0.0009  max mem: 2359
Train: Epoch[2/5]  [290/313]  eta: 0:00:07  Lr: 0.001875  Loss: -0.8417  Acc@1: 87.5000 (85.1589)  Acc@5: 100.0000 (98.4107)  time: 0.3300  data: 0.0002  max mem: 2359
Train: Epoch[2/5]  [300/313]  eta: 0:00:04  Lr: 0.001875  Loss: -0.8137  Acc@1: 81.2500 (85.1329)  Acc@5: 100.0000 (98.4427)  time: 0.3313  data: 0.0002  max mem: 2359
Train: Epoch[2/5]  [310/313]  eta: 0:00:00  Lr: 0.001875  Loss: -0.6867  Acc@1: 87.5000 (85.1889)  Acc@5: 100.0000 (98.4727)  time: 0.3309  data: 0.0002  max mem: 2359
Train: Epoch[2/5]  [312/313]  eta: 0:00:00  Lr: 0.001875  Loss: -0.9134  Acc@1: 87.5000 (85.2000)  Acc@5: 100.0000 (98.4800)  time: 0.3229  data: 0.0002  max mem: 2359
Train: Epoch[2/5] Total time: 0:01:43 (0.3300 s / it)
Averaged stats: Lr: 0.001875  Loss: -0.9134  Acc@1: 87.5000 (85.2000)  Acc@5: 100.0000 (98.4800)
Train: Epoch[3/5]  [  0/313]  eta: 0:02:54  Lr: 0.001875  Loss: -0.5635  Acc@1: 81.2500 (81.2500)  Acc@5: 100.0000 (100.0000)  time: 0.5561  data: 0.2262  max mem: 2359
Train: Epoch[3/5]  [ 10/313]  eta: 0:01:46  Lr: 0.001875  Loss: -0.8927  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (98.8636)  time: 0.3521  data: 0.0216  max mem: 2359
Train: Epoch[3/5]  [ 20/313]  eta: 0:01:40  Lr: 0.001875  Loss: -0.5784  Acc@1: 87.5000 (86.9048)  Acc@5: 100.0000 (98.8095)  time: 0.3311  data: 0.0007  max mem: 2359
Train: Epoch[3/5]  [ 30/313]  eta: 0:01:35  Lr: 0.001875  Loss: -0.3823  Acc@1: 81.2500 (84.4758)  Acc@5: 100.0000 (98.5887)  time: 0.3304  data: 0.0003  max mem: 2359
Train: Epoch[3/5]  [ 40/313]  eta: 0:01:31  Lr: 0.001875  Loss: -0.6700  Acc@1: 81.2500 (84.2988)  Acc@5: 100.0000 (98.3232)  time: 0.3308  data: 0.0003  max mem: 2359
Train: Epoch[3/5]  [ 50/313]  eta: 0:01:28  Lr: 0.001875  Loss: -0.5244  Acc@1: 87.5000 (84.8039)  Acc@5: 100.0000 (98.5294)  time: 0.3309  data: 0.0002  max mem: 2359
Train: Epoch[3/5]  [ 60/313]  eta: 0:01:24  Lr: 0.001875  Loss: -0.6481  Acc@1: 81.2500 (84.5287)  Acc@5: 100.0000 (98.3607)  time: 0.3305  data: 0.0002  max mem: 2359
Train: Epoch[3/5]  [ 70/313]  eta: 0:01:21  Lr: 0.001875  Loss: -0.5627  Acc@1: 81.2500 (84.7711)  Acc@5: 100.0000 (98.2394)  time: 0.3302  data: 0.0002  max mem: 2359
Train: Epoch[3/5]  [ 80/313]  eta: 0:01:17  Lr: 0.001875  Loss: -0.5458  Acc@1: 81.2500 (84.7222)  Acc@5: 100.0000 (98.3796)  time: 0.3299  data: 0.0002  max mem: 2359
Train: Epoch[3/5]  [ 90/313]  eta: 0:01:14  Lr: 0.001875  Loss: -0.7447  Acc@1: 87.5000 (85.5769)  Acc@5: 100.0000 (98.4890)  time: 0.3301  data: 0.0002  max mem: 2359
Train: Epoch[3/5]  [100/313]  eta: 0:01:10  Lr: 0.001875  Loss: -0.6152  Acc@1: 87.5000 (85.4579)  Acc@5: 100.0000 (98.4530)  time: 0.3308  data: 0.0002  max mem: 2359
Train: Epoch[3/5]  [110/313]  eta: 0:01:07  Lr: 0.001875  Loss: -0.8033  Acc@1: 87.5000 (85.0788)  Acc@5: 100.0000 (98.4234)  time: 0.3316  data: 0.0002  max mem: 2359
Train: Epoch[3/5]  [120/313]  eta: 0:01:04  Lr: 0.001875  Loss: -0.7766  Acc@1: 81.2500 (85.0723)  Acc@5: 100.0000 (98.4504)  time: 0.3310  data: 0.0002  max mem: 2359
Train: Epoch[3/5]  [130/313]  eta: 0:01:00  Lr: 0.001875  Loss: -0.6570  Acc@1: 81.2500 (84.7328)  Acc@5: 100.0000 (98.4256)  time: 0.3305  data: 0.0002  max mem: 2359
Train: Epoch[3/5]  [140/313]  eta: 0:00:57  Lr: 0.001875  Loss: -0.4432  Acc@1: 81.2500 (84.7518)  Acc@5: 100.0000 (98.4486)  time: 0.3309  data: 0.0003  max mem: 2359
Train: Epoch[3/5]  [150/313]  eta: 0:00:54  Lr: 0.001875  Loss: -0.5859  Acc@1: 81.2500 (84.7268)  Acc@5: 100.0000 (98.5099)  time: 0.3303  data: 0.0003  max mem: 2359
Train: Epoch[3/5]  [160/313]  eta: 0:00:50  Lr: 0.001875  Loss: -0.2942  Acc@1: 87.5000 (84.8991)  Acc@5: 100.0000 (98.4472)  time: 0.3304  data: 0.0002  max mem: 2359
Train: Epoch[3/5]  [170/313]  eta: 0:00:47  Lr: 0.001875  Loss: -0.8796  Acc@1: 93.7500 (85.1608)  Acc@5: 100.0000 (98.5015)  time: 0.3317  data: 0.0008  max mem: 2359
Train: Epoch[3/5]  [180/313]  eta: 0:00:44  Lr: 0.001875  Loss: -0.9179  Acc@1: 87.5000 (85.2901)  Acc@5: 100.0000 (98.5843)  time: 0.3334  data: 0.0009  max mem: 2359
Train: Epoch[3/5]  [190/313]  eta: 0:00:40  Lr: 0.001875  Loss: -0.6425  Acc@1: 87.5000 (85.6021)  Acc@5: 100.0000 (98.6257)  time: 0.3333  data: 0.0003  max mem: 2359
Train: Epoch[3/5]  [200/313]  eta: 0:00:37  Lr: 0.001875  Loss: -0.3142  Acc@1: 87.5000 (85.4167)  Acc@5: 100.0000 (98.6318)  time: 0.3311  data: 0.0003  max mem: 2359
Train: Epoch[3/5]  [210/313]  eta: 0:00:34  Lr: 0.001875  Loss: -0.7225  Acc@1: 87.5000 (85.4562)  Acc@5: 100.0000 (98.5486)  time: 0.3298  data: 0.0002  max mem: 2359
Train: Epoch[3/5]  [220/313]  eta: 0:00:30  Lr: 0.001875  Loss: -0.6373  Acc@1: 87.5000 (85.5769)  Acc@5: 100.0000 (98.6143)  time: 0.3302  data: 0.0005  max mem: 2359
Train: Epoch[3/5]  [230/313]  eta: 0:00:27  Lr: 0.001875  Loss: -0.7863  Acc@1: 87.5000 (85.5519)  Acc@5: 100.0000 (98.5931)  time: 0.3315  data: 0.0005  max mem: 2359
Train: Epoch[3/5]  [240/313]  eta: 0:00:24  Lr: 0.001875  Loss: -0.7401  Acc@1: 81.2500 (85.5290)  Acc@5: 100.0000 (98.5477)  time: 0.3322  data: 0.0002  max mem: 2359
Train: Epoch[3/5]  [250/313]  eta: 0:00:20  Lr: 0.001875  Loss: -0.6935  Acc@1: 87.5000 (85.6325)  Acc@5: 100.0000 (98.5309)  time: 0.3320  data: 0.0002  max mem: 2359
Train: Epoch[3/5]  [260/313]  eta: 0:00:17  Lr: 0.001875  Loss: -0.8629  Acc@1: 93.7500 (85.7759)  Acc@5: 100.0000 (98.5393)  time: 0.3310  data: 0.0006  max mem: 2359
Train: Epoch[3/5]  [270/313]  eta: 0:00:14  Lr: 0.001875  Loss: -1.0104  Acc@1: 87.5000 (85.8164)  Acc@5: 100.0000 (98.5009)  time: 0.3308  data: 0.0006  max mem: 2359
Train: Epoch[3/5]  [280/313]  eta: 0:00:10  Lr: 0.001875  Loss: -0.5706  Acc@1: 81.2500 (85.7874)  Acc@5: 100.0000 (98.5098)  time: 0.3320  data: 0.0010  max mem: 2359
Train: Epoch[3/5]  [290/313]  eta: 0:00:07  Lr: 0.001875  Loss: -0.6572  Acc@1: 81.2500 (85.7603)  Acc@5: 100.0000 (98.5395)  time: 0.3326  data: 0.0010  max mem: 2359
Train: Epoch[3/5]  [300/313]  eta: 0:00:04  Lr: 0.001875  Loss: 0.0795  Acc@1: 81.2500 (85.7973)  Acc@5: 100.0000 (98.4842)  time: 0.3317  data: 0.0006  max mem: 2359
Train: Epoch[3/5]  [310/313]  eta: 0:00:00  Lr: 0.001875  Loss: -0.7298  Acc@1: 87.5000 (85.8722)  Acc@5: 100.0000 (98.4928)  time: 0.3304  data: 0.0005  max mem: 2359
Train: Epoch[3/5]  [312/313]  eta: 0:00:00  Lr: 0.001875  Loss: -0.5125  Acc@1: 87.5000 (85.8400)  Acc@5: 100.0000 (98.4800)  time: 0.3220  data: 0.0005  max mem: 2359
Train: Epoch[3/5] Total time: 0:01:43 (0.3316 s / it)
Averaged stats: Lr: 0.001875  Loss: -0.5125  Acc@1: 87.5000 (85.8400)  Acc@5: 100.0000 (98.4800)
Train: Epoch[4/5]  [  0/313]  eta: 0:03:17  Lr: 0.001875  Loss: -0.8616  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)  time: 0.6304  data: 0.3002  max mem: 2359
Train: Epoch[4/5]  [ 10/313]  eta: 0:01:48  Lr: 0.001875  Loss: -0.6924  Acc@1: 87.5000 (89.2045)  Acc@5: 100.0000 (99.4318)  time: 0.3569  data: 0.0275  max mem: 2359
Train: Epoch[4/5]  [ 20/313]  eta: 0:01:41  Lr: 0.001875  Loss: -0.5930  Acc@1: 87.5000 (86.9048)  Acc@5: 100.0000 (97.6190)  time: 0.3305  data: 0.0002  max mem: 2359
Train: Epoch[4/5]  [ 30/313]  eta: 0:01:36  Lr: 0.001875  Loss: -0.8262  Acc@1: 87.5000 (86.6935)  Acc@5: 100.0000 (98.1855)  time: 0.3317  data: 0.0010  max mem: 2359
Train: Epoch[4/5]  [ 40/313]  eta: 0:01:32  Lr: 0.001875  Loss: -0.7441  Acc@1: 87.5000 (87.3476)  Acc@5: 100.0000 (98.3232)  time: 0.3310  data: 0.0010  max mem: 2359
Train: Epoch[4/5]  [ 50/313]  eta: 0:01:28  Lr: 0.001875  Loss: -0.6198  Acc@1: 87.5000 (88.1127)  Acc@5: 100.0000 (98.5294)  time: 0.3301  data: 0.0002  max mem: 2359
Train: Epoch[4/5]  [ 60/313]  eta: 0:01:24  Lr: 0.001875  Loss: -0.9928  Acc@1: 93.7500 (88.2172)  Acc@5: 100.0000 (98.4631)  time: 0.3297  data: 0.0002  max mem: 2359
Train: Epoch[4/5]  [ 70/313]  eta: 0:01:21  Lr: 0.001875  Loss: -0.9610  Acc@1: 93.7500 (88.4683)  Acc@5: 100.0000 (98.5035)  time: 0.3295  data: 0.0003  max mem: 2359
Train: Epoch[4/5]  [ 80/313]  eta: 0:01:17  Lr: 0.001875  Loss: -0.7666  Acc@1: 87.5000 (88.1173)  Acc@5: 100.0000 (98.4568)  time: 0.3300  data: 0.0003  max mem: 2359
Train: Epoch[4/5]  [ 90/313]  eta: 0:01:14  Lr: 0.001875  Loss: -0.7828  Acc@1: 87.5000 (88.1181)  Acc@5: 100.0000 (98.5577)  time: 0.3299  data: 0.0002  max mem: 2359
Train: Epoch[4/5]  [100/313]  eta: 0:01:10  Lr: 0.001875  Loss: -0.7013  Acc@1: 87.5000 (88.0569)  Acc@5: 100.0000 (98.5149)  time: 0.3298  data: 0.0002  max mem: 2359
Train: Epoch[4/5]  [110/313]  eta: 0:01:07  Lr: 0.001875  Loss: -0.0546  Acc@1: 87.5000 (87.5563)  Acc@5: 100.0000 (98.4797)  time: 0.3300  data: 0.0003  max mem: 2359
Train: Epoch[4/5]  [120/313]  eta: 0:01:04  Lr: 0.001875  Loss: -0.5852  Acc@1: 87.5000 (87.2417)  Acc@5: 100.0000 (98.5021)  time: 0.3298  data: 0.0003  max mem: 2359
Train: Epoch[4/5]  [130/313]  eta: 0:01:00  Lr: 0.001875  Loss: -0.7150  Acc@1: 87.5000 (87.0706)  Acc@5: 100.0000 (98.4256)  time: 0.3297  data: 0.0003  max mem: 2359
Train: Epoch[4/5]  [140/313]  eta: 0:00:57  Lr: 0.001875  Loss: -0.7410  Acc@1: 87.5000 (87.1897)  Acc@5: 100.0000 (98.3599)  time: 0.3310  data: 0.0003  max mem: 2359
Train: Epoch[4/5]  [150/313]  eta: 0:00:54  Lr: 0.001875  Loss: -0.1101  Acc@1: 87.5000 (87.0033)  Acc@5: 100.0000 (98.3444)  time: 0.3316  data: 0.0003  max mem: 2359
Train: Epoch[4/5]  [160/313]  eta: 0:00:50  Lr: 0.001875  Loss: -0.8408  Acc@1: 87.5000 (87.1118)  Acc@5: 100.0000 (98.4084)  time: 0.3307  data: 0.0002  max mem: 2359
Train: Epoch[4/5]  [170/313]  eta: 0:00:47  Lr: 0.001875  Loss: -0.6738  Acc@1: 93.7500 (87.3538)  Acc@5: 100.0000 (98.4284)  time: 0.3310  data: 0.0003  max mem: 2359
Train: Epoch[4/5]  [180/313]  eta: 0:00:44  Lr: 0.001875  Loss: -0.9467  Acc@1: 87.5000 (87.1892)  Acc@5: 100.0000 (98.3771)  time: 0.3313  data: 0.0003  max mem: 2359
Train: Epoch[4/5]  [190/313]  eta: 0:00:40  Lr: 0.001875  Loss: -0.5649  Acc@1: 81.2500 (87.2709)  Acc@5: 100.0000 (98.3312)  time: 0.3307  data: 0.0002  max mem: 2359
Train: Epoch[4/5]  [200/313]  eta: 0:00:37  Lr: 0.001875  Loss: -0.5319  Acc@1: 81.2500 (87.1269)  Acc@5: 100.0000 (98.3520)  time: 0.3308  data: 0.0002  max mem: 2359
Train: Epoch[4/5]  [210/313]  eta: 0:00:34  Lr: 0.001875  Loss: -0.7319  Acc@1: 87.5000 (87.1149)  Acc@5: 100.0000 (98.3412)  time: 0.3311  data: 0.0003  max mem: 2359
Train: Epoch[4/5]  [220/313]  eta: 0:00:30  Lr: 0.001875  Loss: -0.8873  Acc@1: 87.5000 (87.1324)  Acc@5: 100.0000 (98.3597)  time: 0.3314  data: 0.0003  max mem: 2359
Train: Epoch[4/5]  [230/313]  eta: 0:00:27  Lr: 0.001875  Loss: -0.6850  Acc@1: 87.5000 (87.1753)  Acc@5: 100.0000 (98.3766)  time: 0.3309  data: 0.0003  max mem: 2359
Train: Epoch[4/5]  [240/313]  eta: 0:00:24  Lr: 0.001875  Loss: -0.7681  Acc@1: 87.5000 (87.2147)  Acc@5: 100.0000 (98.3921)  time: 0.3308  data: 0.0003  max mem: 2359
Train: Epoch[4/5]  [250/313]  eta: 0:00:20  Lr: 0.001875  Loss: -0.6863  Acc@1: 87.5000 (87.1763)  Acc@5: 100.0000 (98.4313)  time: 0.3314  data: 0.0003  max mem: 2359
Train: Epoch[4/5]  [260/313]  eta: 0:00:17  Lr: 0.001875  Loss: -0.6539  Acc@1: 87.5000 (87.2605)  Acc@5: 100.0000 (98.4435)  time: 0.3320  data: 0.0003  max mem: 2359
Train: Epoch[4/5]  [270/313]  eta: 0:00:14  Lr: 0.001875  Loss: -0.7062  Acc@1: 87.5000 (87.1541)  Acc@5: 100.0000 (98.4548)  time: 0.3323  data: 0.0003  max mem: 2359
Train: Epoch[4/5]  [280/313]  eta: 0:00:10  Lr: 0.001875  Loss: -0.7443  Acc@1: 87.5000 (87.3665)  Acc@5: 100.0000 (98.4875)  time: 0.3318  data: 0.0003  max mem: 2359
Train: Epoch[4/5]  [290/313]  eta: 0:00:07  Lr: 0.001875  Loss: -0.7116  Acc@1: 93.7500 (87.5000)  Acc@5: 100.0000 (98.5180)  time: 0.3315  data: 0.0002  max mem: 2359
Train: Epoch[4/5]  [300/313]  eta: 0:00:04  Lr: 0.001875  Loss: -0.6268  Acc@1: 93.7500 (87.6038)  Acc@5: 100.0000 (98.5257)  time: 0.3310  data: 0.0002  max mem: 2359
Train: Epoch[4/5]  [310/313]  eta: 0:00:00  Lr: 0.001875  Loss: -0.5646  Acc@1: 87.5000 (87.5201)  Acc@5: 100.0000 (98.4727)  time: 0.3314  data: 0.0003  max mem: 2359
Train: Epoch[4/5]  [312/313]  eta: 0:00:00  Lr: 0.001875  Loss: -0.2547  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (98.4600)  time: 0.3237  data: 0.0003  max mem: 2359
Train: Epoch[4/5] Total time: 0:01:43 (0.3316 s / it)
Averaged stats: Lr: 0.001875  Loss: -0.2547  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (98.4600)
Train: Epoch[5/5]  [  0/313]  eta: 0:02:47  Lr: 0.001875  Loss: -0.5009  Acc@1: 87.5000 (87.5000)  Acc@5: 93.7500 (93.7500)  time: 0.5346  data: 0.2030  max mem: 2359
Train: Epoch[5/5]  [ 10/313]  eta: 0:01:46  Lr: 0.001875  Loss: -0.8286  Acc@1: 87.5000 (85.7955)  Acc@5: 100.0000 (98.2955)  time: 0.3500  data: 0.0187  max mem: 2359
Train: Epoch[5/5]  [ 20/313]  eta: 0:01:39  Lr: 0.001875  Loss: -0.3360  Acc@1: 81.2500 (84.8214)  Acc@5: 100.0000 (97.9167)  time: 0.3314  data: 0.0002  max mem: 2359
Train: Epoch[5/5]  [ 30/313]  eta: 0:01:35  Lr: 0.001875  Loss: -0.6985  Acc@1: 81.2500 (85.0806)  Acc@5: 100.0000 (97.9839)  time: 0.3319  data: 0.0002  max mem: 2359
Train: Epoch[5/5]  [ 40/313]  eta: 0:01:31  Lr: 0.001875  Loss: -0.5403  Acc@1: 87.5000 (85.9756)  Acc@5: 100.0000 (98.4756)  time: 0.3320  data: 0.0003  max mem: 2359
Train: Epoch[5/5]  [ 50/313]  eta: 0:01:28  Lr: 0.001875  Loss: -0.8070  Acc@1: 87.5000 (86.8873)  Acc@5: 100.0000 (98.6520)  time: 0.3315  data: 0.0003  max mem: 2359
Train: Epoch[5/5]  [ 60/313]  eta: 0:01:24  Lr: 0.001875  Loss: -0.6985  Acc@1: 87.5000 (86.2705)  Acc@5: 100.0000 (98.3607)  time: 0.3310  data: 0.0003  max mem: 2359
Train: Epoch[5/5]  [ 70/313]  eta: 0:01:21  Lr: 0.001875  Loss: -0.6233  Acc@1: 81.2500 (85.9155)  Acc@5: 100.0000 (98.3275)  time: 0.3303  data: 0.0002  max mem: 2359
Train: Epoch[5/5]  [ 80/313]  eta: 0:01:17  Lr: 0.001875  Loss: -0.8696  Acc@1: 81.2500 (85.8796)  Acc@5: 100.0000 (98.2253)  time: 0.3311  data: 0.0002  max mem: 2359
Train: Epoch[5/5]  [ 90/313]  eta: 0:01:14  Lr: 0.001875  Loss: -0.9355  Acc@1: 87.5000 (85.9890)  Acc@5: 100.0000 (98.2143)  time: 0.3320  data: 0.0002  max mem: 2359
Train: Epoch[5/5]  [100/313]  eta: 0:01:11  Lr: 0.001875  Loss: -1.0008  Acc@1: 87.5000 (86.3861)  Acc@5: 100.0000 (98.3292)  time: 0.3313  data: 0.0003  max mem: 2359
Train: Epoch[5/5]  [110/313]  eta: 0:01:07  Lr: 0.001875  Loss: -0.8274  Acc@1: 87.5000 (86.6554)  Acc@5: 100.0000 (98.4797)  time: 0.3308  data: 0.0003  max mem: 2359
Train: Epoch[5/5]  [120/313]  eta: 0:01:04  Lr: 0.001875  Loss: -0.8057  Acc@1: 87.5000 (87.1384)  Acc@5: 100.0000 (98.5537)  time: 0.3312  data: 0.0003  max mem: 2359
Train: Epoch[5/5]  [130/313]  eta: 0:01:00  Lr: 0.001875  Loss: -0.1646  Acc@1: 87.5000 (87.2137)  Acc@5: 100.0000 (98.5687)  time: 0.3310  data: 0.0003  max mem: 2359
Train: Epoch[5/5]  [140/313]  eta: 0:00:57  Lr: 0.001875  Loss: -0.9411  Acc@1: 93.7500 (87.5887)  Acc@5: 100.0000 (98.6702)  time: 0.3309  data: 0.0003  max mem: 2359
Train: Epoch[5/5]  [150/313]  eta: 0:00:54  Lr: 0.001875  Loss: -0.8321  Acc@1: 93.7500 (87.7070)  Acc@5: 100.0000 (98.6755)  time: 0.3310  data: 0.0003  max mem: 2359
Train: Epoch[5/5]  [160/313]  eta: 0:00:50  Lr: 0.001875  Loss: -0.6393  Acc@1: 87.5000 (87.9270)  Acc@5: 100.0000 (98.7578)  time: 0.3310  data: 0.0002  max mem: 2359
Train: Epoch[5/5]  [170/313]  eta: 0:00:47  Lr: 0.001875  Loss: -0.8099  Acc@1: 87.5000 (88.0117)  Acc@5: 100.0000 (98.8304)  time: 0.3311  data: 0.0003  max mem: 2359
Train: Epoch[5/5]  [180/313]  eta: 0:00:44  Lr: 0.001875  Loss: -0.8511  Acc@1: 87.5000 (87.9489)  Acc@5: 100.0000 (98.7224)  time: 0.3315  data: 0.0003  max mem: 2359
Train: Epoch[5/5]  [190/313]  eta: 0:00:40  Lr: 0.001875  Loss: -0.6359  Acc@1: 87.5000 (88.0563)  Acc@5: 100.0000 (98.7565)  time: 0.3314  data: 0.0002  max mem: 2359
Train: Epoch[5/5]  [200/313]  eta: 0:00:37  Lr: 0.001875  Loss: -0.7693  Acc@1: 87.5000 (87.9975)  Acc@5: 100.0000 (98.7251)  time: 0.3306  data: 0.0002  max mem: 2359
Train: Epoch[5/5]  [210/313]  eta: 0:00:34  Lr: 0.001875  Loss: -0.8233  Acc@1: 87.5000 (87.9147)  Acc@5: 100.0000 (98.7263)  time: 0.3306  data: 0.0002  max mem: 2359
Train: Epoch[5/5]  [220/313]  eta: 0:00:30  Lr: 0.001875  Loss: -0.7978  Acc@1: 87.5000 (87.8959)  Acc@5: 100.0000 (98.6991)  time: 0.3305  data: 0.0002  max mem: 2359
Train: Epoch[5/5]  [230/313]  eta: 0:00:27  Lr: 0.001875  Loss: -0.2912  Acc@1: 87.5000 (87.6353)  Acc@5: 100.0000 (98.6742)  time: 0.3302  data: 0.0003  max mem: 2359
Train: Epoch[5/5]  [240/313]  eta: 0:00:24  Lr: 0.001875  Loss: -0.9680  Acc@1: 81.2500 (87.4741)  Acc@5: 100.0000 (98.6255)  time: 0.3310  data: 0.0009  max mem: 2359
Train: Epoch[5/5]  [250/313]  eta: 0:00:20  Lr: 0.001875  Loss: -0.8636  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (98.6554)  time: 0.3308  data: 0.0009  max mem: 2359
Train: Epoch[5/5]  [260/313]  eta: 0:00:17  Lr: 0.001875  Loss: -0.7935  Acc@1: 87.5000 (87.7155)  Acc@5: 100.0000 (98.6590)  time: 0.3309  data: 0.0002  max mem: 2359
Train: Epoch[5/5]  [270/313]  eta: 0:00:14  Lr: 0.001875  Loss: -0.9159  Acc@1: 93.7500 (87.7306)  Acc@5: 100.0000 (98.6624)  time: 0.3320  data: 0.0009  max mem: 2359
Train: Epoch[5/5]  [280/313]  eta: 0:00:10  Lr: 0.001875  Loss: -0.5330  Acc@1: 87.5000 (87.7447)  Acc@5: 100.0000 (98.6432)  time: 0.3316  data: 0.0009  max mem: 2359
Train: Epoch[5/5]  [290/313]  eta: 0:00:07  Lr: 0.001875  Loss: -0.8742  Acc@1: 87.5000 (87.7148)  Acc@5: 100.0000 (98.6254)  time: 0.3314  data: 0.0004  max mem: 2359
Train: Epoch[5/5]  [300/313]  eta: 0:00:04  Lr: 0.001875  Loss: -0.9793  Acc@1: 87.5000 (87.7907)  Acc@5: 100.0000 (98.6711)  time: 0.3311  data: 0.0005  max mem: 2359
Train: Epoch[5/5]  [310/313]  eta: 0:00:00  Lr: 0.001875  Loss: -0.8434  Acc@1: 93.7500 (87.8818)  Acc@5: 100.0000 (98.6736)  time: 0.3315  data: 0.0003  max mem: 2359
Train: Epoch[5/5]  [312/313]  eta: 0:00:00  Lr: 0.001875  Loss: -0.7278  Acc@1: 93.7500 (87.8800)  Acc@5: 100.0000 (98.6600)  time: 0.3235  data: 0.0003  max mem: 2359
Train: Epoch[5/5] Total time: 0:01:43 (0.3316 s / it)
Averaged stats: Lr: 0.001875  Loss: -0.7278  Acc@1: 93.7500 (87.8800)  Acc@5: 100.0000 (98.6600)
Test: [Task 1]  [ 0/63]  eta: 0:00:29  Loss: 0.4495 (0.4495)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)  time: 0.4686  data: 0.2590  max mem: 2359
Test: [Task 1]  [10/63]  eta: 0:00:12  Loss: 0.3606 (0.3779)  Acc@1: 100.0000 (97.7273)  Acc@5: 100.0000 (100.0000)  time: 0.2325  data: 0.0238  max mem: 2359
Test: [Task 1]  [20/63]  eta: 0:00:09  Loss: 0.3606 (0.4580)  Acc@1: 93.7500 (96.1310)  Acc@5: 100.0000 (99.7024)  time: 0.2091  data: 0.0003  max mem: 2359
Test: [Task 1]  [30/63]  eta: 0:00:07  Loss: 0.3522 (0.4094)  Acc@1: 100.0000 (97.3790)  Acc@5: 100.0000 (99.7984)  time: 0.2089  data: 0.0003  max mem: 2359
Test: [Task 1]  [40/63]  eta: 0:00:04  Loss: 0.3059 (0.3970)  Acc@1: 100.0000 (97.5610)  Acc@5: 100.0000 (99.8476)  time: 0.2091  data: 0.0003  max mem: 2359
Test: [Task 1]  [50/63]  eta: 0:00:02  Loss: 0.3470 (0.3846)  Acc@1: 100.0000 (97.5490)  Acc@5: 100.0000 (99.7549)  time: 0.2092  data: 0.0003  max mem: 2359
Test: [Task 1]  [60/63]  eta: 0:00:00  Loss: 0.3509 (0.3828)  Acc@1: 100.0000 (97.6434)  Acc@5: 100.0000 (99.7951)  time: 0.2089  data: 0.0002  max mem: 2359
Test: [Task 1]  [62/63]  eta: 0:00:00  Loss: 0.3231 (0.3832)  Acc@1: 100.0000 (97.7000)  Acc@5: 100.0000 (99.8000)  time: 0.2038  data: 0.0002  max mem: 2359
Test: [Task 1] Total time: 0:00:13 (0.2126 s / it)
* Acc@1 97.700 Acc@5 99.800 loss 0.383
{0: {0: 1000, 1: 1000, 2: 1000, 3: 1000, 4: 1000, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0, 10: 0, 11: 0, 12: 0, 13: 0, 14: 0, 15: 0, 16: 0, 17: 0, 18: 0, 19: 0, 20: 0, 21: 0, 22: 0, 23: 0, 24: 0, 25: 0, 26: 0, 27: 0, 28: 0, 29: 0, 30: 0, 31: 0, 32: 0, 33: 0, 34: 0, 35: 0, 36: 0, 37: 0, 38: 0, 39: 0, 40: 0, 41: 0, 42: 0, 43: 0, 44: 0, 45: 0, 46: 0, 47: 0, 48: 0, 49: 0}}
[Average accuracy till task1]	Acc@1: 97.7000	Acc@5: 99.8000	Loss: 0.3832
Train: Epoch[1/5]  [  0/313]  eta: 0:03:31  Lr: 0.001875  Loss: 1.1867  Acc@1: 25.0000 (25.0000)  Acc@5: 43.7500 (43.7500)  time: 0.6760  data: 0.3427  max mem: 2359
Train: Epoch[1/5]  [ 10/313]  eta: 0:01:50  Lr: 0.001875  Loss: 0.9856  Acc@1: 31.2500 (39.2045)  Acc@5: 75.0000 (72.7273)  time: 0.3640  data: 0.0315  max mem: 2360
Train: Epoch[1/5]  [ 20/313]  eta: 0:01:42  Lr: 0.001875  Loss: 0.8015  Acc@1: 56.2500 (50.2976)  Acc@5: 81.2500 (79.4643)  time: 0.3326  data: 0.0004  max mem: 2360
Train: Epoch[1/5]  [ 30/313]  eta: 0:01:37  Lr: 0.001875  Loss: 0.6289  Acc@1: 68.7500 (57.4597)  Acc@5: 93.7500 (84.2742)  time: 0.3325  data: 0.0004  max mem: 2360
Train: Epoch[1/5]  [ 40/313]  eta: 0:01:32  Lr: 0.001875  Loss: 0.2197  Acc@1: 75.0000 (63.1098)  Acc@5: 93.7500 (87.1951)  time: 0.3315  data: 0.0003  max mem: 2360
Train: Epoch[1/5]  [ 50/313]  eta: 0:01:29  Lr: 0.001875  Loss: 0.2971  Acc@1: 81.2500 (66.5441)  Acc@5: 100.0000 (88.8480)  time: 0.3312  data: 0.0003  max mem: 2360
Train: Epoch[1/5]  [ 60/313]  eta: 0:01:25  Lr: 0.001875  Loss: 0.0467  Acc@1: 81.2500 (68.1352)  Acc@5: 100.0000 (90.3689)  time: 0.3317  data: 0.0003  max mem: 2360
Train: Epoch[1/5]  [ 70/313]  eta: 0:01:21  Lr: 0.001875  Loss: -0.0637  Acc@1: 81.2500 (69.7183)  Acc@5: 100.0000 (91.1972)  time: 0.3319  data: 0.0003  max mem: 2360
Train: Epoch[1/5]  [ 80/313]  eta: 0:01:18  Lr: 0.001875  Loss: -0.2591  Acc@1: 81.2500 (71.5278)  Acc@5: 93.7500 (91.8210)  time: 0.3323  data: 0.0003  max mem: 2360
Train: Epoch[1/5]  [ 90/313]  eta: 0:01:14  Lr: 0.001875  Loss: -0.3018  Acc@1: 87.5000 (72.5275)  Acc@5: 93.7500 (92.2390)  time: 0.3321  data: 0.0003  max mem: 2360
Train: Epoch[1/5]  [100/313]  eta: 0:01:11  Lr: 0.001875  Loss: -0.2600  Acc@1: 75.0000 (72.8960)  Acc@5: 100.0000 (92.6361)  time: 0.3320  data: 0.0003  max mem: 2360
Train: Epoch[1/5]  [110/313]  eta: 0:01:08  Lr: 0.001875  Loss: -0.7947  Acc@1: 75.0000 (73.6486)  Acc@5: 100.0000 (93.0743)  time: 0.3323  data: 0.0002  max mem: 2360
Train: Epoch[1/5]  [120/313]  eta: 0:01:04  Lr: 0.001875  Loss: -0.4039  Acc@1: 81.2500 (74.4835)  Acc@5: 100.0000 (93.3884)  time: 0.3327  data: 0.0003  max mem: 2360
Train: Epoch[1/5]  [130/313]  eta: 0:01:01  Lr: 0.001875  Loss: -0.3002  Acc@1: 81.2500 (74.8092)  Acc@5: 93.7500 (93.3206)  time: 0.3321  data: 0.0003  max mem: 2360
Train: Epoch[1/5]  [140/313]  eta: 0:00:57  Lr: 0.001875  Loss: -0.7706  Acc@1: 81.2500 (75.1773)  Acc@5: 93.7500 (93.5727)  time: 0.3322  data: 0.0009  max mem: 2360
Train: Epoch[1/5]  [150/313]  eta: 0:00:54  Lr: 0.001875  Loss: -0.5359  Acc@1: 81.2500 (75.7036)  Acc@5: 100.0000 (93.7500)  time: 0.3330  data: 0.0009  max mem: 2360
Train: Epoch[1/5]  [160/313]  eta: 0:00:51  Lr: 0.001875  Loss: -0.4097  Acc@1: 81.2500 (75.9705)  Acc@5: 93.7500 (93.9441)  time: 0.3327  data: 0.0003  max mem: 2360
Train: Epoch[1/5]  [170/313]  eta: 0:00:47  Lr: 0.001875  Loss: -0.7303  Acc@1: 81.2500 (76.4254)  Acc@5: 100.0000 (94.1155)  time: 0.3337  data: 0.0007  max mem: 2360
Train: Epoch[1/5]  [180/313]  eta: 0:00:44  Lr: 0.001875  Loss: -0.3154  Acc@1: 81.2500 (76.8646)  Acc@5: 100.0000 (94.3370)  time: 0.3337  data: 0.0007  max mem: 2360
Train: Epoch[1/5]  [190/313]  eta: 0:00:41  Lr: 0.001875  Loss: -0.3049  Acc@1: 81.2500 (76.9634)  Acc@5: 100.0000 (94.4699)  time: 0.3318  data: 0.0003  max mem: 2360
Train: Epoch[1/5]  [200/313]  eta: 0:00:37  Lr: 0.001875  Loss: -0.2600  Acc@1: 81.2500 (77.1144)  Acc@5: 100.0000 (94.6206)  time: 0.3315  data: 0.0003  max mem: 2360
Train: Epoch[1/5]  [210/313]  eta: 0:00:34  Lr: 0.001875  Loss: -0.7212  Acc@1: 87.5000 (77.8436)  Acc@5: 100.0000 (94.8460)  time: 0.3314  data: 0.0003  max mem: 2360
Train: Epoch[1/5]  [220/313]  eta: 0:00:31  Lr: 0.001875  Loss: -0.2782  Acc@1: 87.5000 (78.0826)  Acc@5: 100.0000 (95.0226)  time: 0.3308  data: 0.0003  max mem: 2360
Train: Epoch[1/5]  [230/313]  eta: 0:00:27  Lr: 0.001875  Loss: -0.3095  Acc@1: 81.2500 (78.1926)  Acc@5: 100.0000 (94.9675)  time: 0.3307  data: 0.0002  max mem: 2360
Train: Epoch[1/5]  [240/313]  eta: 0:00:24  Lr: 0.001875  Loss: -0.7312  Acc@1: 81.2500 (78.2936)  Acc@5: 93.7500 (95.0726)  time: 0.3319  data: 0.0003  max mem: 2360
Train: Epoch[1/5]  [250/313]  eta: 0:00:21  Lr: 0.001875  Loss: -0.7316  Acc@1: 81.2500 (78.4861)  Acc@5: 100.0000 (95.1942)  time: 0.3322  data: 0.0003  max mem: 2360
Train: Epoch[1/5]  [260/313]  eta: 0:00:17  Lr: 0.001875  Loss: -0.7501  Acc@1: 81.2500 (78.5680)  Acc@5: 100.0000 (95.2586)  time: 0.3321  data: 0.0003  max mem: 2360
Train: Epoch[1/5]  [270/313]  eta: 0:00:14  Lr: 0.001875  Loss: -0.7005  Acc@1: 81.2500 (78.5747)  Acc@5: 100.0000 (95.2721)  time: 0.3325  data: 0.0003  max mem: 2360
Train: Epoch[1/5]  [280/313]  eta: 0:00:10  Lr: 0.001875  Loss: -0.7748  Acc@1: 81.2500 (78.6699)  Acc@5: 100.0000 (95.3737)  time: 0.3316  data: 0.0003  max mem: 2360
Train: Epoch[1/5]  [290/313]  eta: 0:00:07  Lr: 0.001875  Loss: -0.1586  Acc@1: 81.2500 (78.8015)  Acc@5: 100.0000 (95.3608)  time: 0.3308  data: 0.0002  max mem: 2360
Train: Epoch[1/5]  [300/313]  eta: 0:00:04  Lr: 0.001875  Loss: -0.7024  Acc@1: 87.5000 (79.0075)  Acc@5: 93.7500 (95.3904)  time: 0.3324  data: 0.0002  max mem: 2360
Train: Epoch[1/5]  [310/313]  eta: 0:00:00  Lr: 0.001875  Loss: -0.6110  Acc@1: 87.5000 (79.3810)  Acc@5: 100.0000 (95.4381)  time: 0.3336  data: 0.0002  max mem: 2360
Train: Epoch[1/5]  [312/313]  eta: 0:00:00  Lr: 0.001875  Loss: -0.7306  Acc@1: 87.5000 (79.4600)  Acc@5: 100.0000 (95.4600)  time: 0.3251  data: 0.0002  max mem: 2360
Train: Epoch[1/5] Total time: 0:01:44 (0.3332 s / it)
Averaged stats: Lr: 0.001875  Loss: -0.7306  Acc@1: 87.5000 (79.4600)  Acc@5: 100.0000 (95.4600)
Train: Epoch[2/5]  [  0/313]  eta: 0:03:05  Lr: 0.001875  Loss: -0.7194  Acc@1: 87.5000 (87.5000)  Acc@5: 93.7500 (93.7500)  time: 0.5923  data: 0.2589  max mem: 2360
Train: Epoch[2/5]  [ 10/313]  eta: 0:01:48  Lr: 0.001875  Loss: -0.2174  Acc@1: 87.5000 (85.2273)  Acc@5: 93.7500 (95.4545)  time: 0.3568  data: 0.0250  max mem: 2360
Train: Epoch[2/5]  [ 20/313]  eta: 0:01:41  Lr: 0.001875  Loss: -0.8701  Acc@1: 87.5000 (86.6071)  Acc@5: 100.0000 (96.1310)  time: 0.3325  data: 0.0010  max mem: 2360
Train: Epoch[2/5]  [ 30/313]  eta: 0:01:36  Lr: 0.001875  Loss: -0.6704  Acc@1: 87.5000 (86.8952)  Acc@5: 100.0000 (97.1774)  time: 0.3321  data: 0.0003  max mem: 2360
Train: Epoch[2/5]  [ 40/313]  eta: 0:01:32  Lr: 0.001875  Loss: -0.9584  Acc@1: 87.5000 (86.7378)  Acc@5: 100.0000 (96.9512)  time: 0.3317  data: 0.0003  max mem: 2360
Train: Epoch[2/5]  [ 50/313]  eta: 0:01:28  Lr: 0.001875  Loss: -0.6969  Acc@1: 81.2500 (85.6618)  Acc@5: 93.7500 (96.8137)  time: 0.3309  data: 0.0002  max mem: 2360
Train: Epoch[2/5]  [ 60/313]  eta: 0:01:25  Lr: 0.001875  Loss: -0.3714  Acc@1: 81.2500 (85.6557)  Acc@5: 100.0000 (97.2336)  time: 0.3319  data: 0.0009  max mem: 2360
Train: Epoch[2/5]  [ 70/313]  eta: 0:01:21  Lr: 0.001875  Loss: -0.6612  Acc@1: 81.2500 (85.5634)  Acc@5: 100.0000 (97.0951)  time: 0.3319  data: 0.0009  max mem: 2360
Train: Epoch[2/5]  [ 80/313]  eta: 0:01:18  Lr: 0.001875  Loss: -0.3539  Acc@1: 81.2500 (85.3395)  Acc@5: 100.0000 (97.1451)  time: 0.3316  data: 0.0009  max mem: 2360
Train: Epoch[2/5]  [ 90/313]  eta: 0:01:14  Lr: 0.001875  Loss: -0.4898  Acc@1: 81.2500 (84.7527)  Acc@5: 100.0000 (97.1154)  time: 0.3314  data: 0.0010  max mem: 2360
Train: Epoch[2/5]  [100/313]  eta: 0:01:11  Lr: 0.001875  Loss: -0.7194  Acc@1: 81.2500 (84.5297)  Acc@5: 100.0000 (97.0916)  time: 0.3316  data: 0.0002  max mem: 2360
Train: Epoch[2/5]  [110/313]  eta: 0:01:07  Lr: 0.001875  Loss: -0.6968  Acc@1: 87.5000 (84.4595)  Acc@5: 100.0000 (97.0721)  time: 0.3326  data: 0.0008  max mem: 2360
Train: Epoch[2/5]  [120/313]  eta: 0:01:04  Lr: 0.001875  Loss: -0.9638  Acc@1: 81.2500 (84.4008)  Acc@5: 100.0000 (97.1591)  time: 0.3320  data: 0.0009  max mem: 2360
Train: Epoch[2/5]  [130/313]  eta: 0:01:01  Lr: 0.001875  Loss: -0.5109  Acc@1: 81.2500 (84.3989)  Acc@5: 100.0000 (97.0420)  time: 0.3311  data: 0.0004  max mem: 2360
Train: Epoch[2/5]  [140/313]  eta: 0:00:57  Lr: 0.001875  Loss: -0.5370  Acc@1: 87.5000 (84.5745)  Acc@5: 100.0000 (97.0301)  time: 0.3313  data: 0.0004  max mem: 2360
Train: Epoch[2/5]  [150/313]  eta: 0:00:54  Lr: 0.001875  Loss: -0.8399  Acc@1: 87.5000 (84.7682)  Acc@5: 100.0000 (97.0613)  time: 0.3316  data: 0.0003  max mem: 2360
Train: Epoch[2/5]  [160/313]  eta: 0:00:50  Lr: 0.001875  Loss: -0.3741  Acc@1: 87.5000 (84.6661)  Acc@5: 100.0000 (97.1661)  time: 0.3302  data: 0.0003  max mem: 2360
Train: Epoch[2/5]  [170/313]  eta: 0:00:47  Lr: 0.001875  Loss: -0.3719  Acc@1: 81.2500 (84.5029)  Acc@5: 100.0000 (97.0760)  time: 0.3302  data: 0.0003  max mem: 2360
Train: Epoch[2/5]  [180/313]  eta: 0:00:44  Lr: 0.001875  Loss: -0.7046  Acc@1: 81.2500 (84.6685)  Acc@5: 100.0000 (97.2376)  time: 0.3306  data: 0.0003  max mem: 2360
Train: Epoch[2/5]  [190/313]  eta: 0:00:40  Lr: 0.001875  Loss: -0.6132  Acc@1: 81.2500 (84.6859)  Acc@5: 100.0000 (97.2186)  time: 0.3300  data: 0.0003  max mem: 2360
Train: Epoch[2/5]  [200/313]  eta: 0:00:37  Lr: 0.001875  Loss: -0.3331  Acc@1: 81.2500 (84.4216)  Acc@5: 100.0000 (97.2015)  time: 0.3293  data: 0.0002  max mem: 2360
Train: Epoch[2/5]  [210/313]  eta: 0:00:34  Lr: 0.001875  Loss: -0.2314  Acc@1: 81.2500 (84.3602)  Acc@5: 100.0000 (97.1860)  time: 0.3293  data: 0.0002  max mem: 2360
Train: Epoch[2/5]  [220/313]  eta: 0:00:30  Lr: 0.001875  Loss: -0.6803  Acc@1: 81.2500 (84.2477)  Acc@5: 100.0000 (97.3133)  time: 0.3294  data: 0.0003  max mem: 2360
Train: Epoch[2/5]  [230/313]  eta: 0:00:27  Lr: 0.001875  Loss: -0.5152  Acc@1: 87.5000 (84.3344)  Acc@5: 100.0000 (97.2403)  time: 0.3292  data: 0.0002  max mem: 2360
Train: Epoch[2/5]  [240/313]  eta: 0:00:24  Lr: 0.001875  Loss: -0.1685  Acc@1: 87.5000 (84.3361)  Acc@5: 100.0000 (97.2510)  time: 0.3292  data: 0.0003  max mem: 2360
Train: Epoch[2/5]  [250/313]  eta: 0:00:20  Lr: 0.001875  Loss: 0.0128  Acc@1: 87.5000 (84.3875)  Acc@5: 100.0000 (97.2112)  time: 0.3296  data: 0.0003  max mem: 2360
Train: Epoch[2/5]  [260/313]  eta: 0:00:17  Lr: 0.001875  Loss: -1.0902  Acc@1: 87.5000 (84.4588)  Acc@5: 100.0000 (97.2701)  time: 0.3297  data: 0.0003  max mem: 2360
Train: Epoch[2/5]  [270/313]  eta: 0:00:14  Lr: 0.001875  Loss: -0.9370  Acc@1: 87.5000 (84.4327)  Acc@5: 100.0000 (97.2555)  time: 0.3285  data: 0.0003  max mem: 2360
Train: Epoch[2/5]  [280/313]  eta: 0:00:10  Lr: 0.001875  Loss: -0.6249  Acc@1: 81.2500 (84.4528)  Acc@5: 100.0000 (97.3310)  time: 0.3285  data: 0.0004  max mem: 2360
Train: Epoch[2/5]  [290/313]  eta: 0:00:07  Lr: 0.001875  Loss: -0.5816  Acc@1: 87.5000 (84.5790)  Acc@5: 100.0000 (97.3582)  time: 0.3302  data: 0.0003  max mem: 2360
Train: Epoch[2/5]  [300/313]  eta: 0:00:04  Lr: 0.001875  Loss: -0.5242  Acc@1: 81.2500 (84.3854)  Acc@5: 100.0000 (97.3214)  time: 0.3300  data: 0.0007  max mem: 2360
Train: Epoch[2/5]  [310/313]  eta: 0:00:00  Lr: 0.001875  Loss: -0.2370  Acc@1: 81.2500 (84.4252)  Acc@5: 93.7500 (97.2468)  time: 0.3290  data: 0.0007  max mem: 2360
Train: Epoch[2/5]  [312/313]  eta: 0:00:00  Lr: 0.001875  Loss: -0.6226  Acc@1: 81.2500 (84.4200)  Acc@5: 93.7500 (97.2400)  time: 0.3210  data: 0.0007  max mem: 2360
Train: Epoch[2/5] Total time: 0:01:43 (0.3312 s / it)
Averaged stats: Lr: 0.001875  Loss: -0.6226  Acc@1: 81.2500 (84.4200)  Acc@5: 93.7500 (97.2400)
Train: Epoch[3/5]  [  0/313]  eta: 0:02:56  Lr: 0.001875  Loss: -0.7490  Acc@1: 75.0000 (75.0000)  Acc@5: 100.0000 (100.0000)  time: 0.5649  data: 0.2362  max mem: 2360
Train: Epoch[3/5]  [ 10/313]  eta: 0:01:45  Lr: 0.001875  Loss: -0.3641  Acc@1: 81.2500 (84.0909)  Acc@5: 100.0000 (97.7273)  time: 0.3495  data: 0.0216  max mem: 2360
Train: Epoch[3/5]  [ 20/313]  eta: 0:01:39  Lr: 0.001875  Loss: -0.4798  Acc@1: 81.2500 (84.8214)  Acc@5: 100.0000 (98.2143)  time: 0.3290  data: 0.0002  max mem: 2360
Train: Epoch[3/5]  [ 30/313]  eta: 0:01:35  Lr: 0.001875  Loss: -0.8078  Acc@1: 87.5000 (85.8871)  Acc@5: 100.0000 (98.1855)  time: 0.3291  data: 0.0002  max mem: 2360
Train: Epoch[3/5]  [ 40/313]  eta: 0:01:31  Lr: 0.001875  Loss: -0.6181  Acc@1: 87.5000 (85.6707)  Acc@5: 100.0000 (98.1707)  time: 0.3289  data: 0.0002  max mem: 2360
Train: Epoch[3/5]  [ 50/313]  eta: 0:01:27  Lr: 0.001875  Loss: -0.6608  Acc@1: 87.5000 (85.9069)  Acc@5: 100.0000 (98.2843)  time: 0.3299  data: 0.0003  max mem: 2360
Train: Epoch[3/5]  [ 60/313]  eta: 0:01:24  Lr: 0.001875  Loss: -0.6842  Acc@1: 87.5000 (85.5533)  Acc@5: 100.0000 (98.2582)  time: 0.3288  data: 0.0003  max mem: 2360
Train: Epoch[3/5]  [ 70/313]  eta: 0:01:20  Lr: 0.001875  Loss: -0.6669  Acc@1: 87.5000 (85.2113)  Acc@5: 100.0000 (98.5035)  time: 0.3279  data: 0.0003  max mem: 2360
Train: Epoch[3/5]  [ 80/313]  eta: 0:01:17  Lr: 0.001875  Loss: -0.7833  Acc@1: 87.5000 (85.1852)  Acc@5: 100.0000 (98.4568)  time: 0.3279  data: 0.0003  max mem: 2360
Train: Epoch[3/5]  [ 90/313]  eta: 0:01:13  Lr: 0.001875  Loss: -0.5809  Acc@1: 87.5000 (85.3022)  Acc@5: 100.0000 (98.2830)  time: 0.3286  data: 0.0010  max mem: 2360
Train: Epoch[3/5]  [100/313]  eta: 0:01:10  Lr: 0.001875  Loss: -0.5643  Acc@1: 87.5000 (85.3960)  Acc@5: 100.0000 (98.3292)  time: 0.3295  data: 0.0010  max mem: 2360
Train: Epoch[3/5]  [110/313]  eta: 0:01:07  Lr: 0.001875  Loss: -0.5415  Acc@1: 87.5000 (85.4730)  Acc@5: 100.0000 (98.3671)  time: 0.3293  data: 0.0003  max mem: 2360
Train: Epoch[3/5]  [120/313]  eta: 0:01:03  Lr: 0.001875  Loss: -0.6956  Acc@1: 87.5000 (85.6405)  Acc@5: 100.0000 (98.3471)  time: 0.3288  data: 0.0003  max mem: 2360
Train: Epoch[3/5]  [130/313]  eta: 0:01:00  Lr: 0.001875  Loss: -0.7764  Acc@1: 87.5000 (85.6393)  Acc@5: 100.0000 (98.3302)  time: 0.3284  data: 0.0003  max mem: 2360
Train: Epoch[3/5]  [140/313]  eta: 0:00:57  Lr: 0.001875  Loss: -0.9382  Acc@1: 81.2500 (85.4610)  Acc@5: 100.0000 (98.4486)  time: 0.3281  data: 0.0005  max mem: 2360
Train: Epoch[3/5]  [150/313]  eta: 0:00:53  Lr: 0.001875  Loss: -0.4962  Acc@1: 87.5000 (85.5546)  Acc@5: 100.0000 (98.3444)  time: 0.3278  data: 0.0004  max mem: 2360
Train: Epoch[3/5]  [160/313]  eta: 0:00:50  Lr: 0.001875  Loss: -0.7211  Acc@1: 87.5000 (85.7143)  Acc@5: 100.0000 (98.3307)  time: 0.3271  data: 0.0003  max mem: 2360
Train: Epoch[3/5]  [170/313]  eta: 0:00:47  Lr: 0.001875  Loss: -0.2809  Acc@1: 87.5000 (85.6725)  Acc@5: 100.0000 (98.2091)  time: 0.3273  data: 0.0003  max mem: 2360
Train: Epoch[3/5]  [180/313]  eta: 0:00:43  Lr: 0.001875  Loss: -0.5125  Acc@1: 87.5000 (85.5663)  Acc@5: 93.7500 (98.1008)  time: 0.3291  data: 0.0002  max mem: 2360
Train: Epoch[3/5]  [190/313]  eta: 0:00:40  Lr: 0.001875  Loss: -0.8103  Acc@1: 81.2500 (85.5039)  Acc@5: 100.0000 (98.1021)  time: 0.3299  data: 0.0003  max mem: 2360
Train: Epoch[3/5]  [200/313]  eta: 0:00:37  Lr: 0.001875  Loss: -0.7416  Acc@1: 87.5000 (85.6032)  Acc@5: 100.0000 (98.1654)  time: 0.3291  data: 0.0003  max mem: 2360
Train: Epoch[3/5]  [210/313]  eta: 0:00:33  Lr: 0.001875  Loss: -0.5521  Acc@1: 87.5000 (85.6339)  Acc@5: 100.0000 (98.1043)  time: 0.3282  data: 0.0004  max mem: 2360
Train: Epoch[3/5]  [220/313]  eta: 0:00:30  Lr: 0.001875  Loss: -0.8577  Acc@1: 87.5000 (85.6618)  Acc@5: 100.0000 (98.1052)  time: 0.3284  data: 0.0004  max mem: 2360
Train: Epoch[3/5]  [230/313]  eta: 0:00:27  Lr: 0.001875  Loss: -0.7701  Acc@1: 87.5000 (85.7143)  Acc@5: 100.0000 (98.0519)  time: 0.3285  data: 0.0003  max mem: 2360
Train: Epoch[3/5]  [240/313]  eta: 0:00:24  Lr: 0.001875  Loss: -0.8407  Acc@1: 87.5000 (85.8402)  Acc@5: 100.0000 (98.0809)  time: 0.3285  data: 0.0005  max mem: 2360
Train: Epoch[3/5]  [250/313]  eta: 0:00:20  Lr: 0.001875  Loss: -0.6077  Acc@1: 87.5000 (85.7321)  Acc@5: 100.0000 (98.1076)  time: 0.3292  data: 0.0005  max mem: 2360
Train: Epoch[3/5]  [260/313]  eta: 0:00:17  Lr: 0.001875  Loss: -0.7408  Acc@1: 87.5000 (85.8956)  Acc@5: 100.0000 (98.1801)  time: 0.3289  data: 0.0003  max mem: 2360
Train: Epoch[3/5]  [270/313]  eta: 0:00:14  Lr: 0.001875  Loss: -0.1427  Acc@1: 87.5000 (85.7472)  Acc@5: 100.0000 (98.1550)  time: 0.3289  data: 0.0003  max mem: 2360
Train: Epoch[3/5]  [280/313]  eta: 0:00:10  Lr: 0.001875  Loss: -0.9374  Acc@1: 87.5000 (85.7651)  Acc@5: 100.0000 (98.1094)  time: 0.3302  data: 0.0003  max mem: 2360
Train: Epoch[3/5]  [290/313]  eta: 0:00:07  Lr: 0.001875  Loss: -0.9822  Acc@1: 87.5000 (85.7174)  Acc@5: 100.0000 (98.1100)  time: 0.3310  data: 0.0003  max mem: 2360
Train: Epoch[3/5]  [300/313]  eta: 0:00:04  Lr: 0.001875  Loss: -0.6126  Acc@1: 87.5000 (85.7558)  Acc@5: 100.0000 (98.0482)  time: 0.3296  data: 0.0003  max mem: 2360
Train: Epoch[3/5]  [310/313]  eta: 0:00:00  Lr: 0.001875  Loss: -0.7360  Acc@1: 81.2500 (85.7516)  Acc@5: 100.0000 (98.0305)  time: 0.3289  data: 0.0002  max mem: 2360
Train: Epoch[3/5]  [312/313]  eta: 0:00:00  Lr: 0.001875  Loss: -0.5259  Acc@1: 81.2500 (85.7600)  Acc@5: 100.0000 (98.0400)  time: 0.3211  data: 0.0002  max mem: 2360
Train: Epoch[3/5] Total time: 0:01:43 (0.3294 s / it)
Averaged stats: Lr: 0.001875  Loss: -0.5259  Acc@1: 81.2500 (85.7600)  Acc@5: 100.0000 (98.0400)
Train: Epoch[4/5]  [  0/313]  eta: 0:02:53  Lr: 0.001875  Loss: -0.4497  Acc@1: 81.2500 (81.2500)  Acc@5: 100.0000 (100.0000)  time: 0.5550  data: 0.2239  max mem: 2360
Train: Epoch[4/5]  [ 10/313]  eta: 0:01:45  Lr: 0.001875  Loss: -0.6622  Acc@1: 81.2500 (80.1136)  Acc@5: 100.0000 (97.1591)  time: 0.3496  data: 0.0215  max mem: 2360
Train: Epoch[4/5]  [ 20/313]  eta: 0:01:39  Lr: 0.001875  Loss: -0.8423  Acc@1: 81.2500 (81.2500)  Acc@5: 100.0000 (97.9167)  time: 0.3293  data: 0.0007  max mem: 2360
Train: Epoch[4/5]  [ 30/313]  eta: 0:01:35  Lr: 0.001875  Loss: -0.6048  Acc@1: 81.2500 (81.6532)  Acc@5: 100.0000 (97.5806)  time: 0.3291  data: 0.0002  max mem: 2360
Train: Epoch[4/5]  [ 40/313]  eta: 0:01:31  Lr: 0.001875  Loss: -0.7894  Acc@1: 87.5000 (83.2317)  Acc@5: 100.0000 (97.8659)  time: 0.3294  data: 0.0002  max mem: 2360
Train: Epoch[4/5]  [ 50/313]  eta: 0:01:27  Lr: 0.001875  Loss: -0.7354  Acc@1: 87.5000 (84.1912)  Acc@5: 100.0000 (98.1618)  time: 0.3307  data: 0.0002  max mem: 2360
Train: Epoch[4/5]  [ 60/313]  eta: 0:01:24  Lr: 0.001875  Loss: -0.7139  Acc@1: 87.5000 (84.1189)  Acc@5: 100.0000 (97.9508)  time: 0.3313  data: 0.0002  max mem: 2360
Train: Epoch[4/5]  [ 70/313]  eta: 0:01:21  Lr: 0.001875  Loss: -0.9242  Acc@1: 81.2500 (83.8908)  Acc@5: 100.0000 (98.2394)  time: 0.3316  data: 0.0002  max mem: 2360
Train: Epoch[4/5]  [ 80/313]  eta: 0:01:17  Lr: 0.001875  Loss: -0.8479  Acc@1: 81.2500 (84.1049)  Acc@5: 100.0000 (98.3025)  time: 0.3312  data: 0.0002  max mem: 2360
Train: Epoch[4/5]  [ 90/313]  eta: 0:01:14  Lr: 0.001875  Loss: -0.7882  Acc@1: 87.5000 (84.8214)  Acc@5: 100.0000 (98.2143)  time: 0.3308  data: 0.0002  max mem: 2360
Train: Epoch[4/5]  [100/313]  eta: 0:01:10  Lr: 0.001875  Loss: -0.9779  Acc@1: 93.7500 (85.2104)  Acc@5: 100.0000 (98.2054)  time: 0.3308  data: 0.0002  max mem: 2360
Train: Epoch[4/5]  [110/313]  eta: 0:01:07  Lr: 0.001875  Loss: -0.7243  Acc@1: 87.5000 (85.4730)  Acc@5: 100.0000 (98.1982)  time: 0.3303  data: 0.0002  max mem: 2360
Train: Epoch[4/5]  [120/313]  eta: 0:01:04  Lr: 0.001875  Loss: -0.7481  Acc@1: 87.5000 (85.6405)  Acc@5: 100.0000 (98.1405)  time: 0.3311  data: 0.0003  max mem: 2360
Train: Epoch[4/5]  [130/313]  eta: 0:01:00  Lr: 0.001875  Loss: -0.8509  Acc@1: 87.5000 (85.7347)  Acc@5: 100.0000 (98.1393)  time: 0.3320  data: 0.0002  max mem: 2360
Train: Epoch[4/5]  [140/313]  eta: 0:00:57  Lr: 0.001875  Loss: -1.0422  Acc@1: 81.2500 (85.4610)  Acc@5: 100.0000 (98.0496)  time: 0.3319  data: 0.0002  max mem: 2360
Train: Epoch[4/5]  [150/313]  eta: 0:00:54  Lr: 0.001875  Loss: -0.7070  Acc@1: 81.2500 (85.4305)  Acc@5: 100.0000 (97.9719)  time: 0.3315  data: 0.0002  max mem: 2360
Train: Epoch[4/5]  [160/313]  eta: 0:00:50  Lr: 0.001875  Loss: -0.5492  Acc@1: 87.5000 (85.8696)  Acc@5: 100.0000 (98.0590)  time: 0.3310  data: 0.0002  max mem: 2360
Train: Epoch[4/5]  [170/313]  eta: 0:00:47  Lr: 0.001875  Loss: -0.7362  Acc@1: 93.7500 (85.9649)  Acc@5: 100.0000 (98.0994)  time: 0.3317  data: 0.0002  max mem: 2360
Train: Epoch[4/5]  [180/313]  eta: 0:00:44  Lr: 0.001875  Loss: -0.5856  Acc@1: 87.5000 (86.1533)  Acc@5: 100.0000 (98.1008)  time: 0.3329  data: 0.0002  max mem: 2360
Train: Epoch[4/5]  [190/313]  eta: 0:00:40  Lr: 0.001875  Loss: -0.5848  Acc@1: 87.5000 (85.7984)  Acc@5: 100.0000 (98.0039)  time: 0.3326  data: 0.0002  max mem: 2360
Train: Epoch[4/5]  [200/313]  eta: 0:00:37  Lr: 0.001875  Loss: -1.0445  Acc@1: 81.2500 (85.6965)  Acc@5: 100.0000 (97.9478)  time: 0.3319  data: 0.0002  max mem: 2360
Train: Epoch[4/5]  [210/313]  eta: 0:00:34  Lr: 0.001875  Loss: -0.5949  Acc@1: 87.5000 (85.8116)  Acc@5: 100.0000 (97.9265)  time: 0.3325  data: 0.0008  max mem: 2360
Train: Epoch[4/5]  [220/313]  eta: 0:00:30  Lr: 0.001875  Loss: -0.6212  Acc@1: 87.5000 (85.8032)  Acc@5: 100.0000 (97.8790)  time: 0.3329  data: 0.0008  max mem: 2360
Train: Epoch[4/5]  [230/313]  eta: 0:00:27  Lr: 0.001875  Loss: -0.9534  Acc@1: 87.5000 (85.9307)  Acc@5: 100.0000 (97.8355)  time: 0.3321  data: 0.0002  max mem: 2360
Train: Epoch[4/5]  [240/313]  eta: 0:00:24  Lr: 0.001875  Loss: -0.7365  Acc@1: 87.5000 (85.8402)  Acc@5: 100.0000 (97.8734)  time: 0.3314  data: 0.0002  max mem: 2360
Train: Epoch[4/5]  [250/313]  eta: 0:00:20  Lr: 0.001875  Loss: -0.8296  Acc@1: 81.2500 (85.7321)  Acc@5: 100.0000 (97.9333)  time: 0.3315  data: 0.0002  max mem: 2360
Train: Epoch[4/5]  [260/313]  eta: 0:00:17  Lr: 0.001875  Loss: -0.7853  Acc@1: 87.5000 (85.9435)  Acc@5: 100.0000 (97.9646)  time: 0.3312  data: 0.0002  max mem: 2360
Train: Epoch[4/5]  [270/313]  eta: 0:00:14  Lr: 0.001875  Loss: -0.9443  Acc@1: 87.5000 (85.9087)  Acc@5: 100.0000 (97.9244)  time: 0.3307  data: 0.0002  max mem: 2360
Train: Epoch[4/5]  [280/313]  eta: 0:00:10  Lr: 0.001875  Loss: -0.9226  Acc@1: 87.5000 (85.8763)  Acc@5: 100.0000 (97.9093)  time: 0.3305  data: 0.0002  max mem: 2360
Train: Epoch[4/5]  [290/313]  eta: 0:00:07  Lr: 0.001875  Loss: -0.6058  Acc@1: 87.5000 (85.8677)  Acc@5: 100.0000 (97.9167)  time: 0.3304  data: 0.0003  max mem: 2360
Train: Epoch[4/5]  [300/313]  eta: 0:00:04  Lr: 0.001875  Loss: -0.4857  Acc@1: 87.5000 (85.8389)  Acc@5: 100.0000 (97.9651)  time: 0.3301  data: 0.0003  max mem: 2360
Train: Epoch[4/5]  [310/313]  eta: 0:00:00  Lr: 0.001875  Loss: -0.1694  Acc@1: 87.5000 (85.8320)  Acc@5: 100.0000 (97.9502)  time: 0.3302  data: 0.0002  max mem: 2360
Train: Epoch[4/5]  [312/313]  eta: 0:00:00  Lr: 0.001875  Loss: -0.5251  Acc@1: 87.5000 (85.7800)  Acc@5: 100.0000 (97.9600)  time: 0.3220  data: 0.0002  max mem: 2360
Train: Epoch[4/5] Total time: 0:01:43 (0.3316 s / it)
Averaged stats: Lr: 0.001875  Loss: -0.5251  Acc@1: 87.5000 (85.7800)  Acc@5: 100.0000 (97.9600)
Train: Epoch[5/5]  [  0/313]  eta: 0:03:23  Lr: 0.001875  Loss: -0.6237  Acc@1: 75.0000 (75.0000)  Acc@5: 93.7500 (93.7500)  time: 0.6489  data: 0.3191  max mem: 2360
Train: Epoch[5/5]  [ 10/313]  eta: 0:01:49  Lr: 0.001875  Loss: -0.7140  Acc@1: 87.5000 (88.6364)  Acc@5: 100.0000 (97.7273)  time: 0.3602  data: 0.0292  max mem: 2360
Train: Epoch[5/5]  [ 20/313]  eta: 0:01:41  Lr: 0.001875  Loss: -0.8756  Acc@1: 87.5000 (86.6071)  Acc@5: 100.0000 (96.4286)  time: 0.3314  data: 0.0007  max mem: 2360
Train: Epoch[5/5]  [ 30/313]  eta: 0:01:36  Lr: 0.001875  Loss: -0.8473  Acc@1: 87.5000 (84.8790)  Acc@5: 93.7500 (95.7661)  time: 0.3311  data: 0.0011  max mem: 2360
Train: Epoch[5/5]  [ 40/313]  eta: 0:01:32  Lr: 0.001875  Loss: -0.9393  Acc@1: 87.5000 (86.1280)  Acc@5: 93.7500 (96.3415)  time: 0.3312  data: 0.0006  max mem: 2360
Train: Epoch[5/5]  [ 50/313]  eta: 0:01:28  Lr: 0.001875  Loss: -0.5120  Acc@1: 93.7500 (86.1520)  Acc@5: 100.0000 (96.8137)  time: 0.3308  data: 0.0003  max mem: 2360
Train: Epoch[5/5]  [ 60/313]  eta: 0:01:25  Lr: 0.001875  Loss: -0.7649  Acc@1: 87.5000 (86.5779)  Acc@5: 100.0000 (97.1311)  time: 0.3299  data: 0.0003  max mem: 2360
Train: Epoch[5/5]  [ 70/313]  eta: 0:01:21  Lr: 0.001875  Loss: -0.8404  Acc@1: 87.5000 (86.9718)  Acc@5: 100.0000 (97.2711)  time: 0.3306  data: 0.0003  max mem: 2360
Train: Epoch[5/5]  [ 80/313]  eta: 0:01:17  Lr: 0.001875  Loss: -0.8865  Acc@1: 87.5000 (87.0370)  Acc@5: 100.0000 (97.3765)  time: 0.3303  data: 0.0003  max mem: 2360
Train: Epoch[5/5]  [ 90/313]  eta: 0:01:14  Lr: 0.001875  Loss: -0.6088  Acc@1: 87.5000 (86.8819)  Acc@5: 100.0000 (97.5275)  time: 0.3292  data: 0.0002  max mem: 2360
Train: Epoch[5/5]  [100/313]  eta: 0:01:11  Lr: 0.001875  Loss: -0.1619  Acc@1: 87.5000 (86.5718)  Acc@5: 100.0000 (97.5866)  time: 0.3299  data: 0.0007  max mem: 2360
Train: Epoch[5/5]  [110/313]  eta: 0:01:07  Lr: 0.001875  Loss: -0.9704  Acc@1: 87.5000 (86.6554)  Acc@5: 100.0000 (97.8041)  time: 0.3312  data: 0.0007  max mem: 2360
Train: Epoch[5/5]  [120/313]  eta: 0:01:04  Lr: 0.001875  Loss: -0.7726  Acc@1: 87.5000 (86.9318)  Acc@5: 100.0000 (97.8306)  time: 0.3310  data: 0.0005  max mem: 2360
Train: Epoch[5/5]  [130/313]  eta: 0:01:00  Lr: 0.001875  Loss: -0.6845  Acc@1: 87.5000 (86.8321)  Acc@5: 100.0000 (97.8053)  time: 0.3303  data: 0.0005  max mem: 2360
Train: Epoch[5/5]  [140/313]  eta: 0:00:57  Lr: 0.001875  Loss: -0.5293  Acc@1: 81.2500 (86.5248)  Acc@5: 100.0000 (97.9167)  time: 0.3294  data: 0.0002  max mem: 2360
Train: Epoch[5/5]  [150/313]  eta: 0:00:54  Lr: 0.001875  Loss: -0.6653  Acc@1: 81.2500 (86.3825)  Acc@5: 100.0000 (98.0546)  time: 0.3286  data: 0.0002  max mem: 2360
Train: Epoch[5/5]  [160/313]  eta: 0:00:50  Lr: 0.001875  Loss: -0.8558  Acc@1: 87.5000 (86.4130)  Acc@5: 100.0000 (98.0978)  time: 0.3295  data: 0.0003  max mem: 2360
Train: Epoch[5/5]  [170/313]  eta: 0:00:47  Lr: 0.001875  Loss: -0.8805  Acc@1: 87.5000 (86.4401)  Acc@5: 100.0000 (97.9898)  time: 0.3297  data: 0.0003  max mem: 2360
Train: Epoch[5/5]  [180/313]  eta: 0:00:44  Lr: 0.001875  Loss: -0.8511  Acc@1: 87.5000 (86.3605)  Acc@5: 93.7500 (97.9282)  time: 0.3289  data: 0.0003  max mem: 2360
Train: Epoch[5/5]  [190/313]  eta: 0:00:40  Lr: 0.001875  Loss: -0.9192  Acc@1: 87.5000 (86.4202)  Acc@5: 100.0000 (98.0366)  time: 0.3291  data: 0.0002  max mem: 2360
Train: Epoch[5/5]  [200/313]  eta: 0:00:37  Lr: 0.001875  Loss: -0.6264  Acc@1: 87.5000 (86.3495)  Acc@5: 100.0000 (98.0721)  time: 0.3289  data: 0.0002  max mem: 2360
Train: Epoch[5/5]  [210/313]  eta: 0:00:34  Lr: 0.001875  Loss: -0.8795  Acc@1: 87.5000 (86.5225)  Acc@5: 100.0000 (98.1043)  time: 0.3282  data: 0.0002  max mem: 2360
Train: Epoch[5/5]  [220/313]  eta: 0:00:30  Lr: 0.001875  Loss: -0.8644  Acc@1: 87.5000 (86.6799)  Acc@5: 100.0000 (98.1335)  time: 0.3285  data: 0.0002  max mem: 2360
Train: Epoch[5/5]  [230/313]  eta: 0:00:27  Lr: 0.001875  Loss: -0.7763  Acc@1: 87.5000 (86.8236)  Acc@5: 100.0000 (98.2143)  time: 0.3291  data: 0.0002  max mem: 2360
Train: Epoch[5/5]  [240/313]  eta: 0:00:24  Lr: 0.001875  Loss: -0.9854  Acc@1: 87.5000 (86.8776)  Acc@5: 100.0000 (98.1587)  time: 0.3294  data: 0.0003  max mem: 2360
Train: Epoch[5/5]  [250/313]  eta: 0:00:20  Lr: 0.001875  Loss: -0.7284  Acc@1: 87.5000 (86.7032)  Acc@5: 100.0000 (98.2072)  time: 0.3294  data: 0.0003  max mem: 2360
Train: Epoch[5/5]  [260/313]  eta: 0:00:17  Lr: 0.001875  Loss: -0.7580  Acc@1: 81.2500 (86.7577)  Acc@5: 100.0000 (98.2280)  time: 0.3284  data: 0.0003  max mem: 2360
Train: Epoch[5/5]  [270/313]  eta: 0:00:14  Lr: 0.001875  Loss: -0.4692  Acc@1: 93.7500 (87.0157)  Acc@5: 100.0000 (98.2472)  time: 0.3286  data: 0.0002  max mem: 2360
Train: Epoch[5/5]  [280/313]  eta: 0:00:10  Lr: 0.001875  Loss: -0.8655  Acc@1: 87.5000 (87.0329)  Acc@5: 100.0000 (98.1984)  time: 0.3296  data: 0.0002  max mem: 2360
Train: Epoch[5/5]  [290/313]  eta: 0:00:07  Lr: 0.001875  Loss: -0.7734  Acc@1: 87.5000 (86.9845)  Acc@5: 100.0000 (98.2174)  time: 0.3297  data: 0.0002  max mem: 2360
Train: Epoch[5/5]  [300/313]  eta: 0:00:04  Lr: 0.001875  Loss: -0.7543  Acc@1: 81.2500 (86.8771)  Acc@5: 100.0000 (98.1935)  time: 0.3294  data: 0.0003  max mem: 2360
Train: Epoch[5/5]  [310/313]  eta: 0:00:00  Lr: 0.001875  Loss: -1.0817  Acc@1: 87.5000 (86.8770)  Acc@5: 100.0000 (98.2315)  time: 0.3290  data: 0.0003  max mem: 2360
Train: Epoch[5/5]  [312/313]  eta: 0:00:00  Lr: 0.001875  Loss: -0.3146  Acc@1: 87.5000 (86.8800)  Acc@5: 100.0000 (98.2200)  time: 0.3208  data: 0.0003  max mem: 2360
Train: Epoch[5/5] Total time: 0:01:43 (0.3304 s / it)
Averaged stats: Lr: 0.001875  Loss: -0.3146  Acc@1: 87.5000 (86.8800)  Acc@5: 100.0000 (98.2200)
Test: [Task 1]  [ 0/63]  eta: 0:00:32  Loss: 0.4415 (0.4415)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)  time: 0.5205  data: 0.3145  max mem: 2360
Test: [Task 1]  [10/63]  eta: 0:00:12  Loss: 0.4115 (0.4169)  Acc@1: 93.7500 (93.7500)  Acc@5: 100.0000 (99.4318)  time: 0.2364  data: 0.0288  max mem: 2360
Test: [Task 1]  [20/63]  eta: 0:00:09  Loss: 0.3897 (0.4787)  Acc@1: 93.7500 (92.2619)  Acc@5: 100.0000 (99.7024)  time: 0.2079  data: 0.0003  max mem: 2360
Test: [Task 1]  [30/63]  eta: 0:00:07  Loss: 0.3854 (0.4460)  Acc@1: 93.7500 (92.9435)  Acc@5: 100.0000 (99.7984)  time: 0.2078  data: 0.0003  max mem: 2360
Test: [Task 1]  [40/63]  eta: 0:00:04  Loss: 0.3854 (0.4296)  Acc@1: 93.7500 (93.7500)  Acc@5: 100.0000 (99.8476)  time: 0.2085  data: 0.0003  max mem: 2360
Test: [Task 1]  [50/63]  eta: 0:00:02  Loss: 0.3966 (0.4140)  Acc@1: 93.7500 (94.2402)  Acc@5: 100.0000 (99.7549)  time: 0.2087  data: 0.0003  max mem: 2360
Test: [Task 1]  [60/63]  eta: 0:00:00  Loss: 0.3966 (0.4156)  Acc@1: 93.7500 (94.3648)  Acc@5: 100.0000 (99.7951)  time: 0.2081  data: 0.0002  max mem: 2360
Test: [Task 1]  [62/63]  eta: 0:00:00  Loss: 0.3856 (0.4145)  Acc@1: 93.7500 (94.4000)  Acc@5: 100.0000 (99.8000)  time: 0.2032  data: 0.0002  max mem: 2360
Test: [Task 1] Total time: 0:00:13 (0.2125 s / it)
* Acc@1 94.400 Acc@5 99.800 loss 0.414
Test: [Task 2]  [ 0/63]  eta: 0:00:28  Loss: 0.6016 (0.6016)  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (100.0000)  time: 0.4496  data: 0.2410  max mem: 2360
Test: [Task 2]  [10/63]  eta: 0:00:12  Loss: 0.4998 (0.5423)  Acc@1: 93.7500 (93.1818)  Acc@5: 100.0000 (100.0000)  time: 0.2308  data: 0.0222  max mem: 2360
Test: [Task 2]  [20/63]  eta: 0:00:09  Loss: 0.5032 (0.5982)  Acc@1: 93.7500 (93.1548)  Acc@5: 100.0000 (100.0000)  time: 0.2086  data: 0.0002  max mem: 2360
Test: [Task 2]  [30/63]  eta: 0:00:07  Loss: 0.5648 (0.5978)  Acc@1: 93.7500 (92.7419)  Acc@5: 100.0000 (99.5968)  time: 0.2088  data: 0.0002  max mem: 2360
Test: [Task 2]  [40/63]  eta: 0:00:04  Loss: 0.5621 (0.5835)  Acc@1: 93.7500 (92.9878)  Acc@5: 100.0000 (99.5427)  time: 0.2099  data: 0.0010  max mem: 2360
Test: [Task 2]  [50/63]  eta: 0:00:02  Loss: 0.4938 (0.5767)  Acc@1: 93.7500 (92.5245)  Acc@5: 100.0000 (99.5098)  time: 0.2098  data: 0.0010  max mem: 2360
Test: [Task 2]  [60/63]  eta: 0:00:00  Loss: 0.4707 (0.5554)  Acc@1: 93.7500 (93.2377)  Acc@5: 100.0000 (99.5902)  time: 0.2089  data: 0.0002  max mem: 2360
Test: [Task 2]  [62/63]  eta: 0:00:00  Loss: 0.4613 (0.5486)  Acc@1: 93.7500 (93.3000)  Acc@5: 100.0000 (99.6000)  time: 0.2039  data: 0.0002  max mem: 2360
Test: [Task 2] Total time: 0:00:13 (0.2141 s / it)
* Acc@1 93.300 Acc@5 99.600 loss 0.549
{0: {0: 616, 1: 616, 2: 616, 3: 616, 4: 616, 5: 384, 6: 384, 7: 384, 8: 384, 9: 384, 10: 0, 11: 0, 12: 0, 13: 0, 14: 0, 15: 0, 16: 0, 17: 0, 18: 0, 19: 0, 20: 0, 21: 0, 22: 0, 23: 0, 24: 0, 25: 0, 26: 0, 27: 0, 28: 0, 29: 0, 30: 0, 31: 0, 32: 0, 33: 0, 34: 0, 35: 0, 36: 0, 37: 0, 38: 0, 39: 0, 40: 0, 41: 0, 42: 0, 43: 0, 44: 0, 45: 0, 46: 0, 47: 0, 48: 0, 49: 0}, 1: {0: 952, 1: 952, 2: 952, 3: 952, 4: 952, 5: 48, 6: 48, 7: 48, 8: 48, 9: 48, 10: 0, 11: 0, 12: 0, 13: 0, 14: 0, 15: 0, 16: 0, 17: 0, 18: 0, 19: 0, 20: 0, 21: 0, 22: 0, 23: 0, 24: 0, 25: 0, 26: 0, 27: 0, 28: 0, 29: 0, 30: 0, 31: 0, 32: 0, 33: 0, 34: 0, 35: 0, 36: 0, 37: 0, 38: 0, 39: 0, 40: 0, 41: 0, 42: 0, 43: 0, 44: 0, 45: 0, 46: 0, 47: 0, 48: 0, 49: 0}}
[Average accuracy till task2]	Acc@1: 93.8500	Acc@5: 99.7000	Loss: 0.4816	Forgetting: 3.3000	Backward: -3.3000
Train: Epoch[1/5]  [  0/313]  eta: 0:03:01  Lr: 0.001875  Loss: 1.3632  Acc@1: 0.0000 (0.0000)  Acc@5: 31.2500 (31.2500)  time: 0.5810  data: 0.2315  max mem: 2360
Train: Epoch[1/5]  [ 10/313]  eta: 0:01:47  Lr: 0.001875  Loss: 0.9198  Acc@1: 50.0000 (44.8864)  Acc@5: 81.2500 (80.6818)  time: 0.3551  data: 0.0214  max mem: 2362
Train: Epoch[1/5]  [ 20/313]  eta: 0:01:41  Lr: 0.001875  Loss: 0.5962  Acc@1: 68.7500 (60.7143)  Acc@5: 93.7500 (86.9048)  time: 0.3331  data: 0.0003  max mem: 2362
Train: Epoch[1/5]  [ 30/313]  eta: 0:01:36  Lr: 0.001875  Loss: 0.5590  Acc@1: 75.0000 (65.9274)  Acc@5: 93.7500 (89.5161)  time: 0.3321  data: 0.0003  max mem: 2362
Train: Epoch[1/5]  [ 40/313]  eta: 0:01:32  Lr: 0.001875  Loss: 0.1741  Acc@1: 75.0000 (67.9878)  Acc@5: 93.7500 (91.0061)  time: 0.3312  data: 0.0003  max mem: 2362
Train: Epoch[1/5]  [ 50/313]  eta: 0:01:28  Lr: 0.001875  Loss: 0.0603  Acc@1: 75.0000 (70.0980)  Acc@5: 93.7500 (91.6667)  time: 0.3317  data: 0.0003  max mem: 2362
Train: Epoch[1/5]  [ 60/313]  eta: 0:01:25  Lr: 0.001875  Loss: -0.2304  Acc@1: 81.2500 (72.2336)  Acc@5: 93.7500 (92.7254)  time: 0.3316  data: 0.0003  max mem: 2362
Train: Epoch[1/5]  [ 70/313]  eta: 0:01:21  Lr: 0.001875  Loss: -0.2516  Acc@1: 81.2500 (73.4155)  Acc@5: 100.0000 (93.7500)  time: 0.3318  data: 0.0002  max mem: 2362
Train: Epoch[1/5]  [ 80/313]  eta: 0:01:18  Lr: 0.001875  Loss: -0.1474  Acc@1: 87.5000 (74.9228)  Acc@5: 100.0000 (94.2901)  time: 0.3317  data: 0.0003  max mem: 2362
Train: Epoch[1/5]  [ 90/313]  eta: 0:01:14  Lr: 0.001875  Loss: -0.3901  Acc@1: 87.5000 (75.9615)  Acc@5: 100.0000 (94.5742)  time: 0.3311  data: 0.0003  max mem: 2362
Train: Epoch[1/5]  [100/313]  eta: 0:01:11  Lr: 0.001875  Loss: -0.3394  Acc@1: 81.2500 (76.6708)  Acc@5: 100.0000 (94.6782)  time: 0.3308  data: 0.0002  max mem: 2362
Train: Epoch[1/5]  [110/313]  eta: 0:01:07  Lr: 0.001875  Loss: -0.3252  Acc@1: 87.5000 (77.7590)  Acc@5: 100.0000 (95.0450)  time: 0.3313  data: 0.0008  max mem: 2362
Train: Epoch[1/5]  [120/313]  eta: 0:01:04  Lr: 0.001875  Loss: -0.5695  Acc@1: 87.5000 (78.5640)  Acc@5: 100.0000 (95.3512)  time: 0.3323  data: 0.0014  max mem: 2362
Train: Epoch[1/5]  [130/313]  eta: 0:01:01  Lr: 0.001875  Loss: -0.3058  Acc@1: 87.5000 (79.1031)  Acc@5: 100.0000 (95.4198)  time: 0.3317  data: 0.0009  max mem: 2362
Train: Epoch[1/5]  [140/313]  eta: 0:00:57  Lr: 0.001875  Loss: -0.4276  Acc@1: 87.5000 (79.4326)  Acc@5: 100.0000 (95.6117)  time: 0.3304  data: 0.0002  max mem: 2362
Train: Epoch[1/5]  [150/313]  eta: 0:00:54  Lr: 0.001875  Loss: -0.4199  Acc@1: 81.2500 (79.7185)  Acc@5: 100.0000 (95.8195)  time: 0.3304  data: 0.0003  max mem: 2362
Train: Epoch[1/5]  [160/313]  eta: 0:00:50  Lr: 0.001875  Loss: -0.6535  Acc@1: 81.2500 (79.9689)  Acc@5: 100.0000 (95.9239)  time: 0.3328  data: 0.0003  max mem: 2362
Train: Epoch[1/5]  [170/313]  eta: 0:00:47  Lr: 0.001875  Loss: -0.5345  Acc@1: 87.5000 (80.4459)  Acc@5: 100.0000 (96.0161)  time: 0.3333  data: 0.0003  max mem: 2362
Train: Epoch[1/5]  [180/313]  eta: 0:00:44  Lr: 0.001875  Loss: -0.5186  Acc@1: 81.2500 (80.5249)  Acc@5: 93.7500 (96.0290)  time: 0.3320  data: 0.0009  max mem: 2362
Train: Epoch[1/5]  [190/313]  eta: 0:00:40  Lr: 0.001875  Loss: -0.4240  Acc@1: 81.2500 (80.8573)  Acc@5: 100.0000 (96.1715)  time: 0.3317  data: 0.0009  max mem: 2362
Train: Epoch[1/5]  [200/313]  eta: 0:00:37  Lr: 0.001875  Loss: -0.6011  Acc@1: 87.5000 (81.0634)  Acc@5: 100.0000 (96.2998)  time: 0.3304  data: 0.0004  max mem: 2362
Train: Epoch[1/5]  [210/313]  eta: 0:00:34  Lr: 0.001875  Loss: -0.6293  Acc@1: 81.2500 (81.1611)  Acc@5: 100.0000 (96.3566)  time: 0.3299  data: 0.0004  max mem: 2362
Train: Epoch[1/5]  [220/313]  eta: 0:00:30  Lr: 0.001875  Loss: -0.7035  Acc@1: 81.2500 (81.2783)  Acc@5: 100.0000 (96.4084)  time: 0.3296  data: 0.0002  max mem: 2362
Train: Epoch[1/5]  [230/313]  eta: 0:00:27  Lr: 0.001875  Loss: -0.3886  Acc@1: 87.5000 (81.5747)  Acc@5: 100.0000 (96.5097)  time: 0.3296  data: 0.0003  max mem: 2362
Train: Epoch[1/5]  [240/313]  eta: 0:00:24  Lr: 0.001875  Loss: -0.5159  Acc@1: 87.5000 (81.6649)  Acc@5: 100.0000 (96.6546)  time: 0.3295  data: 0.0003  max mem: 2362
Train: Epoch[1/5]  [250/313]  eta: 0:00:20  Lr: 0.001875  Loss: -0.2767  Acc@1: 87.5000 (81.8227)  Acc@5: 100.0000 (96.7131)  time: 0.3289  data: 0.0002  max mem: 2362
Train: Epoch[1/5]  [260/313]  eta: 0:00:17  Lr: 0.001875  Loss: -0.7107  Acc@1: 87.5000 (82.0402)  Acc@5: 100.0000 (96.7672)  time: 0.3293  data: 0.0006  max mem: 2362
Train: Epoch[1/5]  [270/313]  eta: 0:00:14  Lr: 0.001875  Loss: -0.6493  Acc@1: 93.7500 (82.3801)  Acc@5: 100.0000 (96.8404)  time: 0.3297  data: 0.0006  max mem: 2362
Train: Epoch[1/5]  [280/313]  eta: 0:00:10  Lr: 0.001875  Loss: -0.6066  Acc@1: 87.5000 (82.5623)  Acc@5: 100.0000 (96.8639)  time: 0.3292  data: 0.0002  max mem: 2362
Train: Epoch[1/5]  [290/313]  eta: 0:00:07  Lr: 0.001875  Loss: -0.5854  Acc@1: 87.5000 (82.7320)  Acc@5: 100.0000 (96.8857)  time: 0.3293  data: 0.0005  max mem: 2362
Train: Epoch[1/5]  [300/313]  eta: 0:00:04  Lr: 0.001875  Loss: -0.6241  Acc@1: 87.5000 (82.8281)  Acc@5: 100.0000 (96.8646)  time: 0.3310  data: 0.0011  max mem: 2362
Train: Epoch[1/5]  [310/313]  eta: 0:00:00  Lr: 0.001875  Loss: -0.7567  Acc@1: 87.5000 (82.8577)  Acc@5: 100.0000 (96.8650)  time: 0.3319  data: 0.0009  max mem: 2362
Train: Epoch[1/5]  [312/313]  eta: 0:00:00  Lr: 0.001875  Loss: -0.8476  Acc@1: 87.5000 (82.9000)  Acc@5: 100.0000 (96.8800)  time: 0.3237  data: 0.0008  max mem: 2362
Train: Epoch[1/5] Total time: 0:01:43 (0.3315 s / it)
Averaged stats: Lr: 0.001875  Loss: -0.8476  Acc@1: 87.5000 (82.9000)  Acc@5: 100.0000 (96.8800)
Train: Epoch[2/5]  [  0/313]  eta: 0:03:07  Lr: 0.001875  Loss: -0.7586  Acc@1: 93.7500 (93.7500)  Acc@5: 100.0000 (100.0000)  time: 0.5977  data: 0.2653  max mem: 2362
Train: Epoch[2/5]  [ 10/313]  eta: 0:01:47  Lr: 0.001875  Loss: -0.5355  Acc@1: 93.7500 (89.7727)  Acc@5: 100.0000 (98.8636)  time: 0.3535  data: 0.0243  max mem: 2362
Train: Epoch[2/5]  [ 20/313]  eta: 0:01:40  Lr: 0.001875  Loss: -0.8020  Acc@1: 87.5000 (88.3929)  Acc@5: 100.0000 (99.1071)  time: 0.3289  data: 0.0004  max mem: 2362
Train: Epoch[2/5]  [ 30/313]  eta: 0:01:35  Lr: 0.001875  Loss: -0.7978  Acc@1: 87.5000 (87.7016)  Acc@5: 100.0000 (98.5887)  time: 0.3285  data: 0.0004  max mem: 2362
Train: Epoch[2/5]  [ 40/313]  eta: 0:01:31  Lr: 0.001875  Loss: -0.7469  Acc@1: 81.2500 (86.4329)  Acc@5: 100.0000 (98.4756)  time: 0.3283  data: 0.0002  max mem: 2362
Train: Epoch[2/5]  [ 50/313]  eta: 0:01:27  Lr: 0.001875  Loss: -0.6870  Acc@1: 81.2500 (86.1520)  Acc@5: 100.0000 (98.6520)  time: 0.3294  data: 0.0009  max mem: 2362
Train: Epoch[2/5]  [ 60/313]  eta: 0:01:24  Lr: 0.001875  Loss: -0.7622  Acc@1: 87.5000 (86.3730)  Acc@5: 100.0000 (98.3607)  time: 0.3318  data: 0.0024  max mem: 2362
Train: Epoch[2/5]  [ 70/313]  eta: 0:01:21  Lr: 0.001875  Loss: -0.6175  Acc@1: 87.5000 (86.0915)  Acc@5: 100.0000 (98.1514)  time: 0.3316  data: 0.0020  max mem: 2362
Train: Epoch[2/5]  [ 80/313]  eta: 0:01:17  Lr: 0.001875  Loss: -0.8027  Acc@1: 87.5000 (86.5741)  Acc@5: 100.0000 (98.3025)  time: 0.3296  data: 0.0005  max mem: 2362
Train: Epoch[2/5]  [ 90/313]  eta: 0:01:14  Lr: 0.001875  Loss: -0.4191  Acc@1: 93.7500 (86.8132)  Acc@5: 100.0000 (98.3516)  time: 0.3297  data: 0.0002  max mem: 2362
Train: Epoch[2/5]  [100/313]  eta: 0:01:10  Lr: 0.001875  Loss: -0.3419  Acc@1: 87.5000 (86.5718)  Acc@5: 100.0000 (98.3292)  time: 0.3298  data: 0.0003  max mem: 2362
Train: Epoch[2/5]  [110/313]  eta: 0:01:07  Lr: 0.001875  Loss: -0.5097  Acc@1: 87.5000 (86.9932)  Acc@5: 100.0000 (98.3671)  time: 0.3288  data: 0.0003  max mem: 2362
Train: Epoch[2/5]  [120/313]  eta: 0:01:04  Lr: 0.001875  Loss: -0.5455  Acc@1: 87.5000 (87.1384)  Acc@5: 100.0000 (98.3988)  time: 0.3293  data: 0.0006  max mem: 2362
Train: Epoch[2/5]  [130/313]  eta: 0:01:00  Lr: 0.001875  Loss: -0.8206  Acc@1: 87.5000 (87.0229)  Acc@5: 100.0000 (98.3779)  time: 0.3301  data: 0.0006  max mem: 2362
Train: Epoch[2/5]  [140/313]  eta: 0:00:57  Lr: 0.001875  Loss: -0.8586  Acc@1: 93.7500 (87.7216)  Acc@5: 100.0000 (98.4486)  time: 0.3308  data: 0.0003  max mem: 2362
Train: Epoch[2/5]  [150/313]  eta: 0:00:54  Lr: 0.001875  Loss: -0.9067  Acc@1: 93.7500 (87.4172)  Acc@5: 100.0000 (98.5513)  time: 0.3301  data: 0.0006  max mem: 2362
Train: Epoch[2/5]  [160/313]  eta: 0:00:50  Lr: 0.001875  Loss: -0.6424  Acc@1: 87.5000 (87.4224)  Acc@5: 100.0000 (98.4860)  time: 0.3291  data: 0.0005  max mem: 2362
Train: Epoch[2/5]  [170/313]  eta: 0:00:47  Lr: 0.001875  Loss: -1.0053  Acc@1: 87.5000 (87.3538)  Acc@5: 100.0000 (98.4649)  time: 0.3297  data: 0.0002  max mem: 2362
Train: Epoch[2/5]  [180/313]  eta: 0:00:44  Lr: 0.001875  Loss: -0.5225  Acc@1: 87.5000 (87.0511)  Acc@5: 100.0000 (98.4116)  time: 0.3299  data: 0.0002  max mem: 2362
Train: Epoch[2/5]  [190/313]  eta: 0:00:40  Lr: 0.001875  Loss: -0.5179  Acc@1: 87.5000 (87.0092)  Acc@5: 100.0000 (98.3639)  time: 0.3300  data: 0.0002  max mem: 2362
Train: Epoch[2/5]  [200/313]  eta: 0:00:37  Lr: 0.001875  Loss: -0.6480  Acc@1: 81.2500 (86.6915)  Acc@5: 100.0000 (98.2587)  time: 0.3308  data: 0.0002  max mem: 2362
Train: Epoch[2/5]  [210/313]  eta: 0:00:34  Lr: 0.001875  Loss: -0.5644  Acc@1: 81.2500 (86.7891)  Acc@5: 100.0000 (98.2820)  time: 0.3301  data: 0.0003  max mem: 2362
Train: Epoch[2/5]  [220/313]  eta: 0:00:30  Lr: 0.001875  Loss: -0.8715  Acc@1: 87.5000 (86.7364)  Acc@5: 100.0000 (98.3032)  time: 0.3291  data: 0.0003  max mem: 2362
Train: Epoch[2/5]  [230/313]  eta: 0:00:27  Lr: 0.001875  Loss: -0.2900  Acc@1: 87.5000 (86.6342)  Acc@5: 100.0000 (98.2684)  time: 0.3299  data: 0.0002  max mem: 2362
Train: Epoch[2/5]  [240/313]  eta: 0:00:24  Lr: 0.001875  Loss: -0.5336  Acc@1: 87.5000 (86.7998)  Acc@5: 100.0000 (98.2884)  time: 0.3303  data: 0.0005  max mem: 2362
Train: Epoch[2/5]  [250/313]  eta: 0:00:20  Lr: 0.001875  Loss: -0.8871  Acc@1: 93.7500 (87.0020)  Acc@5: 100.0000 (98.2819)  time: 0.3299  data: 0.0009  max mem: 2362
Train: Epoch[2/5]  [260/313]  eta: 0:00:17  Lr: 0.001875  Loss: -0.6223  Acc@1: 87.5000 (86.9732)  Acc@5: 100.0000 (98.2519)  time: 0.3299  data: 0.0007  max mem: 2362
Train: Epoch[2/5]  [270/313]  eta: 0:00:14  Lr: 0.001875  Loss: -0.7503  Acc@1: 87.5000 (86.9926)  Acc@5: 100.0000 (98.2934)  time: 0.3298  data: 0.0003  max mem: 2362
Train: Epoch[2/5]  [280/313]  eta: 0:00:10  Lr: 0.001875  Loss: -0.5392  Acc@1: 87.5000 (87.0329)  Acc@5: 100.0000 (98.2651)  time: 0.3302  data: 0.0003  max mem: 2362
Train: Epoch[2/5]  [290/313]  eta: 0:00:07  Lr: 0.001875  Loss: -0.6862  Acc@1: 87.5000 (86.9201)  Acc@5: 100.0000 (98.3033)  time: 0.3301  data: 0.0003  max mem: 2362
Train: Epoch[2/5]  [300/313]  eta: 0:00:04  Lr: 0.001875  Loss: -1.0005  Acc@1: 87.5000 (87.0017)  Acc@5: 100.0000 (98.3389)  time: 0.3304  data: 0.0006  max mem: 2362
Train: Epoch[2/5]  [310/313]  eta: 0:00:00  Lr: 0.001875  Loss: -0.7080  Acc@1: 87.5000 (87.1383)  Acc@5: 100.0000 (98.3923)  time: 0.3313  data: 0.0005  max mem: 2362
Train: Epoch[2/5]  [312/313]  eta: 0:00:00  Lr: 0.001875  Loss: -0.8012  Acc@1: 87.5000 (87.1800)  Acc@5: 100.0000 (98.3800)  time: 0.3227  data: 0.0002  max mem: 2362
Train: Epoch[2/5] Total time: 0:01:43 (0.3305 s / it)
Averaged stats: Lr: 0.001875  Loss: -0.8012  Acc@1: 87.5000 (87.1800)  Acc@5: 100.0000 (98.3800)
Train: Epoch[3/5]  [  0/313]  eta: 0:03:21  Lr: 0.001875  Loss: -0.3181  Acc@1: 68.7500 (68.7500)  Acc@5: 93.7500 (93.7500)  time: 0.6437  data: 0.3157  max mem: 2362
Train: Epoch[3/5]  [ 10/313]  eta: 0:01:49  Lr: 0.001875  Loss: -0.9315  Acc@1: 87.5000 (84.0909)  Acc@5: 100.0000 (97.7273)  time: 0.3607  data: 0.0298  max mem: 2362
Train: Epoch[3/5]  [ 20/313]  eta: 0:01:41  Lr: 0.001875  Loss: -0.6109  Acc@1: 87.5000 (85.1190)  Acc@5: 100.0000 (98.5119)  time: 0.3325  data: 0.0007  max mem: 2362
Train: Epoch[3/5]  [ 30/313]  eta: 0:01:36  Lr: 0.001875  Loss: -0.7162  Acc@1: 87.5000 (85.2823)  Acc@5: 100.0000 (98.7903)  time: 0.3317  data: 0.0003  max mem: 2362
Train: Epoch[3/5]  [ 40/313]  eta: 0:01:32  Lr: 0.001875  Loss: -0.7328  Acc@1: 87.5000 (85.5183)  Acc@5: 100.0000 (98.6280)  time: 0.3315  data: 0.0003  max mem: 2362
Train: Epoch[3/5]  [ 50/313]  eta: 0:01:28  Lr: 0.001875  Loss: -0.7368  Acc@1: 87.5000 (85.9069)  Acc@5: 100.0000 (98.7745)  time: 0.3320  data: 0.0003  max mem: 2362
Train: Epoch[3/5]  [ 60/313]  eta: 0:01:25  Lr: 0.001875  Loss: -0.4548  Acc@1: 87.5000 (86.0656)  Acc@5: 100.0000 (98.5656)  time: 0.3317  data: 0.0002  max mem: 2362
Train: Epoch[3/5]  [ 70/313]  eta: 0:01:21  Lr: 0.001875  Loss: -0.7698  Acc@1: 87.5000 (85.6514)  Acc@5: 100.0000 (98.5035)  time: 0.3324  data: 0.0002  max mem: 2362
Train: Epoch[3/5]  [ 80/313]  eta: 0:01:18  Lr: 0.001875  Loss: -0.5235  Acc@1: 87.5000 (85.5710)  Acc@5: 100.0000 (98.5340)  time: 0.3337  data: 0.0011  max mem: 2362
Train: Epoch[3/5]  [ 90/313]  eta: 0:01:14  Lr: 0.001875  Loss: -0.5229  Acc@1: 87.5000 (86.1264)  Acc@5: 100.0000 (98.6951)  time: 0.3334  data: 0.0011  max mem: 2362
Train: Epoch[3/5]  [100/313]  eta: 0:01:11  Lr: 0.001875  Loss: -0.3623  Acc@1: 93.7500 (86.4480)  Acc@5: 100.0000 (98.6386)  time: 0.3326  data: 0.0005  max mem: 2362
Train: Epoch[3/5]  [110/313]  eta: 0:01:08  Lr: 0.001875  Loss: -0.7663  Acc@1: 87.5000 (86.7680)  Acc@5: 100.0000 (98.7613)  time: 0.3319  data: 0.0005  max mem: 2362
Train: Epoch[3/5]  [120/313]  eta: 0:01:04  Lr: 0.001875  Loss: -0.6346  Acc@1: 87.5000 (86.3120)  Acc@5: 100.0000 (98.6570)  time: 0.3313  data: 0.0003  max mem: 2362
Train: Epoch[3/5]  [130/313]  eta: 0:01:01  Lr: 0.001875  Loss: -0.6522  Acc@1: 81.2500 (86.2118)  Acc@5: 100.0000 (98.5210)  time: 0.3321  data: 0.0002  max mem: 2362
Train: Epoch[3/5]  [140/313]  eta: 0:00:57  Lr: 0.001875  Loss: -0.8825  Acc@1: 87.5000 (86.3918)  Acc@5: 100.0000 (98.6259)  time: 0.3323  data: 0.0002  max mem: 2362
Train: Epoch[3/5]  [150/313]  eta: 0:00:54  Lr: 0.001875  Loss: -0.8709  Acc@1: 93.7500 (86.6308)  Acc@5: 100.0000 (98.6341)  time: 0.3322  data: 0.0002  max mem: 2362
Train: Epoch[3/5]  [160/313]  eta: 0:00:51  Lr: 0.001875  Loss: -0.9526  Acc@1: 93.7500 (86.7236)  Acc@5: 100.0000 (98.5637)  time: 0.3328  data: 0.0008  max mem: 2362
Train: Epoch[3/5]  [170/313]  eta: 0:00:47  Lr: 0.001875  Loss: -0.6951  Acc@1: 87.5000 (86.9152)  Acc@5: 100.0000 (98.6111)  time: 0.3332  data: 0.0013  max mem: 2362
Train: Epoch[3/5]  [180/313]  eta: 0:00:44  Lr: 0.001875  Loss: -0.8926  Acc@1: 87.5000 (86.8439)  Acc@5: 100.0000 (98.6878)  time: 0.3326  data: 0.0011  max mem: 2362
Train: Epoch[3/5]  [190/313]  eta: 0:00:41  Lr: 0.001875  Loss: -0.8544  Acc@1: 87.5000 (87.0092)  Acc@5: 100.0000 (98.6911)  time: 0.3316  data: 0.0006  max mem: 2362
Train: Epoch[3/5]  [200/313]  eta: 0:00:37  Lr: 0.001875  Loss: -0.9121  Acc@1: 87.5000 (86.8781)  Acc@5: 100.0000 (98.6007)  time: 0.3315  data: 0.0002  max mem: 2362
Train: Epoch[3/5]  [210/313]  eta: 0:00:34  Lr: 0.001875  Loss: -0.7964  Acc@1: 81.2500 (86.7891)  Acc@5: 100.0000 (98.6078)  time: 0.3330  data: 0.0002  max mem: 2362
Train: Epoch[3/5]  [220/313]  eta: 0:00:31  Lr: 0.001875  Loss: -0.8357  Acc@1: 87.5000 (86.8495)  Acc@5: 100.0000 (98.6708)  time: 0.3341  data: 0.0002  max mem: 2362
Train: Epoch[3/5]  [230/313]  eta: 0:00:27  Lr: 0.001875  Loss: -0.8128  Acc@1: 87.5000 (86.7154)  Acc@5: 100.0000 (98.6472)  time: 0.3342  data: 0.0003  max mem: 2362
Train: Epoch[3/5]  [240/313]  eta: 0:00:24  Lr: 0.001875  Loss: -1.0084  Acc@1: 87.5000 (86.8257)  Acc@5: 100.0000 (98.7033)  time: 0.3345  data: 0.0003  max mem: 2362
Train: Epoch[3/5]  [250/313]  eta: 0:00:21  Lr: 0.001875  Loss: -0.7523  Acc@1: 87.5000 (86.9024)  Acc@5: 100.0000 (98.7301)  time: 0.3351  data: 0.0003  max mem: 2362
Train: Epoch[3/5]  [260/313]  eta: 0:00:17  Lr: 0.001875  Loss: -0.7767  Acc@1: 93.7500 (87.0690)  Acc@5: 100.0000 (98.7787)  time: 0.3349  data: 0.0003  max mem: 2362
Train: Epoch[3/5]  [270/313]  eta: 0:00:14  Lr: 0.001875  Loss: -0.8291  Acc@1: 87.5000 (87.0387)  Acc@5: 100.0000 (98.7777)  time: 0.3338  data: 0.0003  max mem: 2362
Train: Epoch[3/5]  [280/313]  eta: 0:00:11  Lr: 0.001875  Loss: -0.8778  Acc@1: 87.5000 (87.0329)  Acc@5: 100.0000 (98.7767)  time: 0.3326  data: 0.0003  max mem: 2362
Train: Epoch[3/5]  [290/313]  eta: 0:00:07  Lr: 0.001875  Loss: -0.7598  Acc@1: 87.5000 (87.0060)  Acc@5: 100.0000 (98.7758)  time: 0.3319  data: 0.0003  max mem: 2362
Train: Epoch[3/5]  [300/313]  eta: 0:00:04  Lr: 0.001875  Loss: -0.7110  Acc@1: 87.5000 (87.0432)  Acc@5: 100.0000 (98.7749)  time: 0.3328  data: 0.0002  max mem: 2362
Train: Epoch[3/5]  [310/313]  eta: 0:00:01  Lr: 0.001875  Loss: -0.9175  Acc@1: 87.5000 (87.0579)  Acc@5: 100.0000 (98.7942)  time: 0.3339  data: 0.0004  max mem: 2362
Train: Epoch[3/5]  [312/313]  eta: 0:00:00  Lr: 0.001875  Loss: -0.6044  Acc@1: 87.5000 (87.0400)  Acc@5: 100.0000 (98.8000)  time: 0.3249  data: 0.0003  max mem: 2362
Train: Epoch[3/5] Total time: 0:01:44 (0.3335 s / it)
Averaged stats: Lr: 0.001875  Loss: -0.6044  Acc@1: 87.5000 (87.0400)  Acc@5: 100.0000 (98.8000)
Train: Epoch[4/5]  [  0/313]  eta: 0:03:25  Lr: 0.001875  Loss: -0.6601  Acc@1: 75.0000 (75.0000)  Acc@5: 100.0000 (100.0000)  time: 0.6560  data: 0.3201  max mem: 2362
Train: Epoch[4/5]  [ 10/313]  eta: 0:01:49  Lr: 0.001875  Loss: -0.9403  Acc@1: 81.2500 (82.3864)  Acc@5: 100.0000 (98.2955)  time: 0.3610  data: 0.0299  max mem: 2362
Train: Epoch[4/5]  [ 20/313]  eta: 0:01:41  Lr: 0.001875  Loss: -0.9218  Acc@1: 87.5000 (84.5238)  Acc@5: 100.0000 (98.5119)  time: 0.3314  data: 0.0005  max mem: 2362
Train: Epoch[4/5]  [ 30/313]  eta: 0:01:36  Lr: 0.001875  Loss: -0.7360  Acc@1: 87.5000 (85.2823)  Acc@5: 100.0000 (98.7903)  time: 0.3315  data: 0.0002  max mem: 2362
Train: Epoch[4/5]  [ 40/313]  eta: 0:01:32  Lr: 0.001875  Loss: -0.5641  Acc@1: 87.5000 (86.4329)  Acc@5: 100.0000 (98.4756)  time: 0.3323  data: 0.0005  max mem: 2362
Train: Epoch[4/5]  [ 50/313]  eta: 0:01:28  Lr: 0.001875  Loss: -0.3031  Acc@1: 87.5000 (86.6422)  Acc@5: 100.0000 (98.5294)  time: 0.3329  data: 0.0005  max mem: 2362
Train: Epoch[4/5]  [ 60/313]  eta: 0:01:25  Lr: 0.001875  Loss: -0.5932  Acc@1: 93.7500 (87.7049)  Acc@5: 100.0000 (98.2582)  time: 0.3326  data: 0.0003  max mem: 2362
Train: Epoch[4/5]  [ 70/313]  eta: 0:01:21  Lr: 0.001875  Loss: -0.6716  Acc@1: 93.7500 (88.2042)  Acc@5: 100.0000 (98.1514)  time: 0.3314  data: 0.0002  max mem: 2362
Train: Epoch[4/5]  [ 80/313]  eta: 0:01:18  Lr: 0.001875  Loss: -0.7263  Acc@1: 93.7500 (88.5031)  Acc@5: 100.0000 (98.3025)  time: 0.3305  data: 0.0002  max mem: 2362
Train: Epoch[4/5]  [ 90/313]  eta: 0:01:14  Lr: 0.001875  Loss: -0.6997  Acc@1: 93.7500 (88.6676)  Acc@5: 100.0000 (98.4890)  time: 0.3315  data: 0.0002  max mem: 2362
Train: Epoch[4/5]  [100/313]  eta: 0:01:11  Lr: 0.001875  Loss: -0.7662  Acc@1: 87.5000 (88.8614)  Acc@5: 100.0000 (98.5767)  time: 0.3321  data: 0.0002  max mem: 2362
Train: Epoch[4/5]  [110/313]  eta: 0:01:07  Lr: 0.001875  Loss: -0.7049  Acc@1: 87.5000 (88.7950)  Acc@5: 100.0000 (98.7050)  time: 0.3312  data: 0.0002  max mem: 2362
Train: Epoch[4/5]  [120/313]  eta: 0:01:04  Lr: 0.001875  Loss: -0.8211  Acc@1: 87.5000 (88.7397)  Acc@5: 100.0000 (98.6570)  time: 0.3310  data: 0.0003  max mem: 2362
Train: Epoch[4/5]  [130/313]  eta: 0:01:01  Lr: 0.001875  Loss: -0.9699  Acc@1: 87.5000 (88.9313)  Acc@5: 100.0000 (98.6641)  time: 0.3312  data: 0.0003  max mem: 2362
Train: Epoch[4/5]  [140/313]  eta: 0:00:57  Lr: 0.001875  Loss: -0.8621  Acc@1: 93.7500 (89.2287)  Acc@5: 100.0000 (98.7145)  time: 0.3312  data: 0.0002  max mem: 2362
Train: Epoch[4/5]  [150/313]  eta: 0:00:54  Lr: 0.001875  Loss: -0.5030  Acc@1: 93.7500 (89.3212)  Acc@5: 100.0000 (98.7997)  time: 0.3316  data: 0.0002  max mem: 2362
Train: Epoch[4/5]  [160/313]  eta: 0:00:51  Lr: 0.001875  Loss: -0.9220  Acc@1: 87.5000 (89.2081)  Acc@5: 100.0000 (98.7966)  time: 0.3313  data: 0.0002  max mem: 2362
Train: Epoch[4/5]  [170/313]  eta: 0:00:47  Lr: 0.001875  Loss: -0.4616  Acc@1: 87.5000 (88.9254)  Acc@5: 100.0000 (98.6477)  time: 0.3301  data: 0.0002  max mem: 2362
Train: Epoch[4/5]  [180/313]  eta: 0:00:44  Lr: 0.001875  Loss: -0.7025  Acc@1: 87.5000 (88.7086)  Acc@5: 100.0000 (98.5843)  time: 0.3297  data: 0.0002  max mem: 2362
Train: Epoch[4/5]  [190/313]  eta: 0:00:40  Lr: 0.001875  Loss: -1.0645  Acc@1: 87.5000 (88.6780)  Acc@5: 100.0000 (98.4948)  time: 0.3297  data: 0.0002  max mem: 2362
Train: Epoch[4/5]  [200/313]  eta: 0:00:37  Lr: 0.001875  Loss: -0.8001  Acc@1: 87.5000 (88.6505)  Acc@5: 100.0000 (98.5075)  time: 0.3294  data: 0.0002  max mem: 2362
Train: Epoch[4/5]  [210/313]  eta: 0:00:34  Lr: 0.001875  Loss: -0.5098  Acc@1: 93.7500 (88.7145)  Acc@5: 100.0000 (98.5782)  time: 0.3291  data: 0.0002  max mem: 2362
Train: Epoch[4/5]  [220/313]  eta: 0:00:30  Lr: 0.001875  Loss: -0.6797  Acc@1: 87.5000 (88.5464)  Acc@5: 100.0000 (98.5860)  time: 0.3284  data: 0.0003  max mem: 2362
Train: Epoch[4/5]  [230/313]  eta: 0:00:27  Lr: 0.001875  Loss: -0.5951  Acc@1: 87.5000 (88.6364)  Acc@5: 100.0000 (98.6201)  time: 0.3285  data: 0.0004  max mem: 2362
Train: Epoch[4/5]  [240/313]  eta: 0:00:24  Lr: 0.001875  Loss: -0.9097  Acc@1: 93.7500 (88.5114)  Acc@5: 100.0000 (98.6774)  time: 0.3299  data: 0.0007  max mem: 2362
Train: Epoch[4/5]  [250/313]  eta: 0:00:20  Lr: 0.001875  Loss: -0.7337  Acc@1: 87.5000 (88.3466)  Acc@5: 100.0000 (98.6554)  time: 0.3297  data: 0.0007  max mem: 2362
Train: Epoch[4/5]  [260/313]  eta: 0:00:17  Lr: 0.001875  Loss: -0.8835  Acc@1: 87.5000 (88.4100)  Acc@5: 100.0000 (98.6830)  time: 0.3294  data: 0.0003  max mem: 2362
Train: Epoch[4/5]  [270/313]  eta: 0:00:14  Lr: 0.001875  Loss: -0.6042  Acc@1: 87.5000 (88.2841)  Acc@5: 100.0000 (98.6624)  time: 0.3298  data: 0.0005  max mem: 2362
Train: Epoch[4/5]  [280/313]  eta: 0:00:10  Lr: 0.001875  Loss: -0.9292  Acc@1: 87.5000 (88.3452)  Acc@5: 100.0000 (98.6877)  time: 0.3292  data: 0.0006  max mem: 2362
Train: Epoch[4/5]  [290/313]  eta: 0:00:07  Lr: 0.001875  Loss: -0.9794  Acc@1: 93.7500 (88.4235)  Acc@5: 100.0000 (98.6899)  time: 0.3287  data: 0.0003  max mem: 2362
Train: Epoch[4/5]  [300/313]  eta: 0:00:04  Lr: 0.001875  Loss: -0.8699  Acc@1: 93.7500 (88.4759)  Acc@5: 100.0000 (98.7334)  time: 0.3286  data: 0.0002  max mem: 2362
Train: Epoch[4/5]  [310/313]  eta: 0:00:00  Lr: 0.001875  Loss: -0.4342  Acc@1: 87.5000 (88.4244)  Acc@5: 100.0000 (98.7540)  time: 0.3286  data: 0.0002  max mem: 2362
Train: Epoch[4/5]  [312/313]  eta: 0:00:00  Lr: 0.001875  Loss: -0.7716  Acc@1: 87.5000 (88.4600)  Acc@5: 100.0000 (98.7600)  time: 0.3205  data: 0.0002  max mem: 2362
Train: Epoch[4/5] Total time: 0:01:43 (0.3312 s / it)
Averaged stats: Lr: 0.001875  Loss: -0.7716  Acc@1: 87.5000 (88.4600)  Acc@5: 100.0000 (98.7600)
Train: Epoch[5/5]  [  0/313]  eta: 0:02:39  Lr: 0.001875  Loss: -0.7770  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (100.0000)  time: 0.5103  data: 0.1784  max mem: 2362
Train: Epoch[5/5]  [ 10/313]  eta: 0:01:44  Lr: 0.001875  Loss: -0.8344  Acc@1: 87.5000 (89.7727)  Acc@5: 100.0000 (99.4318)  time: 0.3458  data: 0.0164  max mem: 2362
Train: Epoch[5/5]  [ 20/313]  eta: 0:01:38  Lr: 0.001875  Loss: -0.7163  Acc@1: 87.5000 (88.6905)  Acc@5: 100.0000 (99.7024)  time: 0.3288  data: 0.0002  max mem: 2362
Train: Epoch[5/5]  [ 30/313]  eta: 0:01:34  Lr: 0.001875  Loss: -0.6346  Acc@1: 81.2500 (87.7016)  Acc@5: 100.0000 (99.5968)  time: 0.3279  data: 0.0002  max mem: 2362
Train: Epoch[5/5]  [ 40/313]  eta: 0:01:30  Lr: 0.001875  Loss: -0.9072  Acc@1: 87.5000 (88.4146)  Acc@5: 100.0000 (99.3902)  time: 0.3279  data: 0.0002  max mem: 2362
Train: Epoch[5/5]  [ 50/313]  eta: 0:01:27  Lr: 0.001875  Loss: -0.9872  Acc@1: 93.7500 (88.4804)  Acc@5: 100.0000 (99.2647)  time: 0.3284  data: 0.0003  max mem: 2362
Train: Epoch[5/5]  [ 60/313]  eta: 0:01:23  Lr: 0.001875  Loss: -0.5965  Acc@1: 93.7500 (88.8320)  Acc@5: 100.0000 (99.1803)  time: 0.3284  data: 0.0002  max mem: 2362
Train: Epoch[5/5]  [ 70/313]  eta: 0:01:20  Lr: 0.001875  Loss: -0.8807  Acc@1: 87.5000 (88.8204)  Acc@5: 100.0000 (99.0317)  time: 0.3282  data: 0.0002  max mem: 2362
Train: Epoch[5/5]  [ 80/313]  eta: 0:01:17  Lr: 0.001875  Loss: -0.7201  Acc@1: 87.5000 (88.2716)  Acc@5: 100.0000 (98.9969)  time: 0.3282  data: 0.0002  max mem: 2362
Train: Epoch[5/5]  [ 90/313]  eta: 0:01:13  Lr: 0.001875  Loss: -0.9002  Acc@1: 87.5000 (88.2555)  Acc@5: 100.0000 (98.9011)  time: 0.3283  data: 0.0002  max mem: 2362
Train: Epoch[5/5]  [100/313]  eta: 0:01:10  Lr: 0.001875  Loss: -0.4970  Acc@1: 87.5000 (88.4901)  Acc@5: 100.0000 (98.8243)  time: 0.3288  data: 0.0003  max mem: 2362
Train: Epoch[5/5]  [110/313]  eta: 0:01:07  Lr: 0.001875  Loss: -0.7259  Acc@1: 87.5000 (88.4009)  Acc@5: 100.0000 (98.5360)  time: 0.3294  data: 0.0002  max mem: 2362
Train: Epoch[5/5]  [120/313]  eta: 0:01:03  Lr: 0.001875  Loss: -0.9511  Acc@1: 87.5000 (88.3264)  Acc@5: 100.0000 (98.6054)  time: 0.3291  data: 0.0002  max mem: 2362
Train: Epoch[5/5]  [130/313]  eta: 0:01:00  Lr: 0.001875  Loss: -0.8570  Acc@1: 93.7500 (88.5496)  Acc@5: 100.0000 (98.7118)  time: 0.3297  data: 0.0003  max mem: 2362
Train: Epoch[5/5]  [140/313]  eta: 0:00:57  Lr: 0.001875  Loss: -0.8865  Acc@1: 87.5000 (88.3865)  Acc@5: 100.0000 (98.7145)  time: 0.3303  data: 0.0003  max mem: 2362
Train: Epoch[5/5]  [150/313]  eta: 0:00:53  Lr: 0.001875  Loss: -0.8877  Acc@1: 87.5000 (88.2450)  Acc@5: 100.0000 (98.6755)  time: 0.3300  data: 0.0002  max mem: 2362
Train: Epoch[5/5]  [160/313]  eta: 0:00:50  Lr: 0.001875  Loss: -1.0710  Acc@1: 87.5000 (88.1211)  Acc@5: 100.0000 (98.6801)  time: 0.3295  data: 0.0003  max mem: 2362
Train: Epoch[5/5]  [170/313]  eta: 0:00:47  Lr: 0.001875  Loss: -0.2942  Acc@1: 87.5000 (87.9386)  Acc@5: 100.0000 (98.7208)  time: 0.3301  data: 0.0002  max mem: 2362
Train: Epoch[5/5]  [180/313]  eta: 0:00:43  Lr: 0.001875  Loss: -0.5141  Acc@1: 87.5000 (87.8453)  Acc@5: 100.0000 (98.7224)  time: 0.3306  data: 0.0003  max mem: 2362
Train: Epoch[5/5]  [190/313]  eta: 0:00:40  Lr: 0.001875  Loss: -0.8600  Acc@1: 87.5000 (87.9254)  Acc@5: 100.0000 (98.7565)  time: 0.3298  data: 0.0003  max mem: 2362
Train: Epoch[5/5]  [200/313]  eta: 0:00:37  Lr: 0.001875  Loss: -0.7901  Acc@1: 87.5000 (87.8109)  Acc@5: 100.0000 (98.6940)  time: 0.3308  data: 0.0009  max mem: 2362
Train: Epoch[5/5]  [210/313]  eta: 0:00:34  Lr: 0.001875  Loss: -0.9009  Acc@1: 87.5000 (87.5889)  Acc@5: 100.0000 (98.7263)  time: 0.3316  data: 0.0009  max mem: 2362
Train: Epoch[5/5]  [220/313]  eta: 0:00:30  Lr: 0.001875  Loss: -0.7088  Acc@1: 87.5000 (87.5566)  Acc@5: 100.0000 (98.6708)  time: 0.3312  data: 0.0002  max mem: 2362
Train: Epoch[5/5]  [230/313]  eta: 0:00:27  Lr: 0.001875  Loss: -0.8182  Acc@1: 87.5000 (87.5812)  Acc@5: 100.0000 (98.7013)  time: 0.3312  data: 0.0003  max mem: 2362
Train: Epoch[5/5]  [240/313]  eta: 0:00:24  Lr: 0.001875  Loss: -0.9658  Acc@1: 93.7500 (87.5778)  Acc@5: 100.0000 (98.7293)  time: 0.3309  data: 0.0003  max mem: 2362
Train: Epoch[5/5]  [250/313]  eta: 0:00:20  Lr: 0.001875  Loss: -0.7627  Acc@1: 93.7500 (87.6245)  Acc@5: 100.0000 (98.7550)  time: 0.3312  data: 0.0003  max mem: 2362
Train: Epoch[5/5]  [260/313]  eta: 0:00:17  Lr: 0.001875  Loss: -0.7797  Acc@1: 87.5000 (87.5718)  Acc@5: 100.0000 (98.7308)  time: 0.3318  data: 0.0007  max mem: 2362
Train: Epoch[5/5]  [270/313]  eta: 0:00:14  Lr: 0.001875  Loss: -0.8130  Acc@1: 87.5000 (87.5923)  Acc@5: 100.0000 (98.6393)  time: 0.3314  data: 0.0007  max mem: 2362
Train: Epoch[5/5]  [280/313]  eta: 0:00:10  Lr: 0.001875  Loss: -0.9788  Acc@1: 87.5000 (87.6335)  Acc@5: 100.0000 (98.6210)  time: 0.3317  data: 0.0003  max mem: 2362
Train: Epoch[5/5]  [290/313]  eta: 0:00:07  Lr: 0.001875  Loss: -0.8477  Acc@1: 93.7500 (87.7363)  Acc@5: 100.0000 (98.6684)  time: 0.3325  data: 0.0003  max mem: 2362
Train: Epoch[5/5]  [300/313]  eta: 0:00:04  Lr: 0.001875  Loss: -0.7036  Acc@1: 87.5000 (87.7284)  Acc@5: 100.0000 (98.6919)  time: 0.3326  data: 0.0002  max mem: 2362
Train: Epoch[5/5]  [310/313]  eta: 0:00:00  Lr: 0.001875  Loss: -0.8143  Acc@1: 87.5000 (87.6809)  Acc@5: 100.0000 (98.6937)  time: 0.3321  data: 0.0002  max mem: 2362
Train: Epoch[5/5]  [312/313]  eta: 0:00:00  Lr: 0.001875  Loss: -0.6463  Acc@1: 87.5000 (87.6600)  Acc@5: 100.0000 (98.7000)  time: 0.3239  data: 0.0002  max mem: 2362
Train: Epoch[5/5] Total time: 0:01:43 (0.3304 s / it)
Averaged stats: Lr: 0.001875  Loss: -0.6463  Acc@1: 87.5000 (87.6600)  Acc@5: 100.0000 (98.7000)
Test: [Task 1]  [ 0/63]  eta: 0:00:29  Loss: 0.5917 (0.5917)  Acc@1: 81.2500 (81.2500)  Acc@5: 100.0000 (100.0000)  time: 0.4761  data: 0.2658  max mem: 2362
Test: [Task 1]  [10/63]  eta: 0:00:12  Loss: 0.4825 (0.5032)  Acc@1: 87.5000 (88.0682)  Acc@5: 100.0000 (99.4318)  time: 0.2339  data: 0.0245  max mem: 2362
Test: [Task 1]  [20/63]  eta: 0:00:09  Loss: 0.5053 (0.5624)  Acc@1: 87.5000 (88.0952)  Acc@5: 100.0000 (99.4048)  time: 0.2098  data: 0.0003  max mem: 2362
Test: [Task 1]  [30/63]  eta: 0:00:07  Loss: 0.4583 (0.5256)  Acc@1: 93.7500 (89.1129)  Acc@5: 100.0000 (99.3952)  time: 0.2099  data: 0.0003  max mem: 2362
Test: [Task 1]  [40/63]  eta: 0:00:04  Loss: 0.3857 (0.5017)  Acc@1: 93.7500 (90.0915)  Acc@5: 100.0000 (99.5427)  time: 0.2098  data: 0.0002  max mem: 2362
Test: [Task 1]  [50/63]  eta: 0:00:02  Loss: 0.4295 (0.4817)  Acc@1: 93.7500 (91.0539)  Acc@5: 100.0000 (99.5098)  time: 0.2097  data: 0.0003  max mem: 2362
Test: [Task 1]  [60/63]  eta: 0:00:00  Loss: 0.4452 (0.4795)  Acc@1: 93.7500 (91.0861)  Acc@5: 100.0000 (99.5902)  time: 0.2096  data: 0.0002  max mem: 2362
Test: [Task 1]  [62/63]  eta: 0:00:00  Loss: 0.4452 (0.4788)  Acc@1: 93.7500 (91.3000)  Acc@5: 100.0000 (99.6000)  time: 0.2046  data: 0.0002  max mem: 2362
Test: [Task 1] Total time: 0:00:13 (0.2141 s / it)
* Acc@1 91.300 Acc@5 99.600 loss 0.479
Test: [Task 2]  [ 0/63]  eta: 0:00:30  Loss: 0.6536 (0.6536)  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (100.0000)  time: 0.4771  data: 0.2650  max mem: 2362
Test: [Task 2]  [10/63]  eta: 0:00:12  Loss: 0.5641 (0.6242)  Acc@1: 93.7500 (93.7500)  Acc@5: 100.0000 (98.8636)  time: 0.2337  data: 0.0244  max mem: 2362
Test: [Task 2]  [20/63]  eta: 0:00:09  Loss: 0.5667 (0.6941)  Acc@1: 93.7500 (91.6667)  Acc@5: 100.0000 (98.5119)  time: 0.2095  data: 0.0003  max mem: 2362
Test: [Task 2]  [30/63]  eta: 0:00:07  Loss: 0.6947 (0.6892)  Acc@1: 87.5000 (91.1290)  Acc@5: 100.0000 (97.9839)  time: 0.2100  data: 0.0003  max mem: 2362
Test: [Task 2]  [40/63]  eta: 0:00:04  Loss: 0.6561 (0.6715)  Acc@1: 87.5000 (91.0061)  Acc@5: 100.0000 (98.0183)  time: 0.2100  data: 0.0003  max mem: 2362
Test: [Task 2]  [50/63]  eta: 0:00:02  Loss: 0.5828 (0.6644)  Acc@1: 87.5000 (90.6863)  Acc@5: 100.0000 (98.1618)  time: 0.2101  data: 0.0003  max mem: 2362
Test: [Task 2]  [60/63]  eta: 0:00:00  Loss: 0.5341 (0.6366)  Acc@1: 93.7500 (91.3934)  Acc@5: 100.0000 (98.4631)  time: 0.2102  data: 0.0003  max mem: 2362
Test: [Task 2]  [62/63]  eta: 0:00:00  Loss: 0.5230 (0.6287)  Acc@1: 93.7500 (91.5000)  Acc@5: 100.0000 (98.5000)  time: 0.2051  data: 0.0002  max mem: 2362
Test: [Task 2] Total time: 0:00:13 (0.2137 s / it)
* Acc@1 91.500 Acc@5 98.500 loss 0.629
Test: [Task 3]  [ 0/63]  eta: 0:00:29  Loss: 0.3283 (0.3283)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)  time: 0.4678  data: 0.2567  max mem: 2362
Test: [Task 3]  [10/63]  eta: 0:00:12  Loss: 0.5272 (0.5436)  Acc@1: 93.7500 (89.2045)  Acc@5: 100.0000 (98.8636)  time: 0.2331  data: 0.0235  max mem: 2362
Test: [Task 3]  [20/63]  eta: 0:00:09  Loss: 0.5519 (0.5308)  Acc@1: 87.5000 (89.8810)  Acc@5: 100.0000 (98.5119)  time: 0.2095  data: 0.0002  max mem: 2362
Test: [Task 3]  [30/63]  eta: 0:00:07  Loss: 0.4960 (0.5211)  Acc@1: 87.5000 (90.7258)  Acc@5: 100.0000 (98.9919)  time: 0.2097  data: 0.0003  max mem: 2362
Test: [Task 3]  [40/63]  eta: 0:00:04  Loss: 0.4960 (0.5193)  Acc@1: 93.7500 (91.0061)  Acc@5: 100.0000 (99.0854)  time: 0.2105  data: 0.0003  max mem: 2362
Test: [Task 3]  [50/63]  eta: 0:00:02  Loss: 0.4646 (0.5146)  Acc@1: 93.7500 (91.5441)  Acc@5: 100.0000 (99.0196)  time: 0.2104  data: 0.0003  max mem: 2362
Test: [Task 3]  [60/63]  eta: 0:00:00  Loss: 0.5421 (0.5263)  Acc@1: 93.7500 (91.1885)  Acc@5: 100.0000 (99.1803)  time: 0.2093  data: 0.0002  max mem: 2362
Test: [Task 3]  [62/63]  eta: 0:00:00  Loss: 0.5576 (0.5340)  Acc@1: 87.5000 (91.0000)  Acc@5: 100.0000 (99.1000)  time: 0.2043  data: 0.0002  max mem: 2362
Test: [Task 3] Total time: 0:00:13 (0.2133 s / it)
* Acc@1 91.000 Acc@5 99.100 loss 0.534
{0: {0: 856, 1: 856, 2: 856, 3: 856, 4: 856, 5: 112, 6: 112, 7: 112, 8: 112, 9: 112, 10: 32, 11: 32, 12: 32, 13: 32, 14: 32, 15: 0, 16: 0, 17: 0, 18: 0, 19: 0, 20: 0, 21: 0, 22: 0, 23: 0, 24: 0, 25: 0, 26: 0, 27: 0, 28: 0, 29: 0, 30: 0, 31: 0, 32: 0, 33: 0, 34: 0, 35: 0, 36: 0, 37: 0, 38: 0, 39: 0, 40: 0, 41: 0, 42: 0, 43: 0, 44: 0, 45: 0, 46: 0, 47: 0, 48: 0, 49: 0}, 1: {0: 968, 1: 968, 2: 968, 3: 968, 4: 968, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0, 10: 32, 11: 32, 12: 32, 13: 32, 14: 32, 15: 0, 16: 0, 17: 0, 18: 0, 19: 0, 20: 0, 21: 0, 22: 0, 23: 0, 24: 0, 25: 0, 26: 0, 27: 0, 28: 0, 29: 0, 30: 0, 31: 0, 32: 0, 33: 0, 34: 0, 35: 0, 36: 0, 37: 0, 38: 0, 39: 0, 40: 0, 41: 0, 42: 0, 43: 0, 44: 0, 45: 0, 46: 0, 47: 0, 48: 0, 49: 0}, 2: {0: 504, 1: 504, 2: 504, 3: 504, 4: 504, 5: 432, 6: 432, 7: 432, 8: 432, 9: 432, 10: 64, 11: 64, 12: 64, 13: 64, 14: 64, 15: 0, 16: 0, 17: 0, 18: 0, 19: 0, 20: 0, 21: 0, 22: 0, 23: 0, 24: 0, 25: 0, 26: 0, 27: 0, 28: 0, 29: 0, 30: 0, 31: 0, 32: 0, 33: 0, 34: 0, 35: 0, 36: 0, 37: 0, 38: 0, 39: 0, 40: 0, 41: 0, 42: 0, 43: 0, 44: 0, 45: 0, 46: 0, 47: 0, 48: 0, 49: 0}}
[Average accuracy till task3]	Acc@1: 91.2667	Acc@5: 99.0667	Loss: 0.5472	Forgetting: 4.1000	Backward: -4.1000
Train: Epoch[1/5]  [  0/313]  eta: 0:02:59  Lr: 0.001875  Loss: 1.1786  Acc@1: 12.5000 (12.5000)  Acc@5: 43.7500 (43.7500)  time: 0.5748  data: 0.2339  max mem: 2362
Train: Epoch[1/5]  [ 10/313]  eta: 0:01:47  Lr: 0.001875  Loss: 0.9163  Acc@1: 43.7500 (43.1818)  Acc@5: 81.2500 (77.8409)  time: 0.3550  data: 0.0229  max mem: 2362
Train: Epoch[1/5]  [ 20/313]  eta: 0:01:40  Lr: 0.001875  Loss: 0.5722  Acc@1: 56.2500 (55.3571)  Acc@5: 81.2500 (84.5238)  time: 0.3330  data: 0.0014  max mem: 2362
Train: Epoch[1/5]  [ 30/313]  eta: 0:01:36  Lr: 0.001875  Loss: 0.1336  Acc@1: 68.7500 (61.6935)  Acc@5: 93.7500 (88.5081)  time: 0.3320  data: 0.0007  max mem: 2362
Train: Epoch[1/5]  [ 40/313]  eta: 0:01:32  Lr: 0.001875  Loss: -0.0002  Acc@1: 75.0000 (66.4634)  Acc@5: 100.0000 (90.7012)  time: 0.3310  data: 0.0004  max mem: 2362
Train: Epoch[1/5]  [ 50/313]  eta: 0:01:28  Lr: 0.001875  Loss: -0.1268  Acc@1: 81.2500 (69.4853)  Acc@5: 100.0000 (91.9118)  time: 0.3314  data: 0.0003  max mem: 2362
Train: Epoch[1/5]  [ 60/313]  eta: 0:01:24  Lr: 0.001875  Loss: 0.0643  Acc@1: 81.2500 (71.6189)  Acc@5: 100.0000 (92.4180)  time: 0.3309  data: 0.0003  max mem: 2362
Train: Epoch[1/5]  [ 70/313]  eta: 0:01:21  Lr: 0.001875  Loss: -0.2925  Acc@1: 81.2500 (72.7113)  Acc@5: 93.7500 (92.8697)  time: 0.3304  data: 0.0003  max mem: 2362
Train: Epoch[1/5]  [ 80/313]  eta: 0:01:18  Lr: 0.001875  Loss: -0.4955  Acc@1: 81.2500 (74.3056)  Acc@5: 100.0000 (93.5957)  time: 0.3325  data: 0.0010  max mem: 2362
Train: Epoch[1/5]  [ 90/313]  eta: 0:01:14  Lr: 0.001875  Loss: -0.2242  Acc@1: 87.5000 (75.5495)  Acc@5: 100.0000 (93.8874)  time: 0.3331  data: 0.0010  max mem: 2362
Train: Epoch[1/5]  [100/313]  eta: 0:01:11  Lr: 0.001875  Loss: -0.6391  Acc@1: 87.5000 (76.7946)  Acc@5: 100.0000 (94.2450)  time: 0.3321  data: 0.0003  max mem: 2362
Train: Epoch[1/5]  [110/313]  eta: 0:01:07  Lr: 0.001875  Loss: -0.2342  Acc@1: 87.5000 (77.5338)  Acc@5: 100.0000 (94.6509)  time: 0.3310  data: 0.0003  max mem: 2362
Train: Epoch[1/5]  [120/313]  eta: 0:01:04  Lr: 0.001875  Loss: -0.7591  Acc@1: 87.5000 (78.0475)  Acc@5: 100.0000 (95.0413)  time: 0.3312  data: 0.0005  max mem: 2362
Train: Epoch[1/5]  [130/313]  eta: 0:01:01  Lr: 0.001875  Loss: -0.6442  Acc@1: 81.2500 (78.3397)  Acc@5: 100.0000 (95.3244)  time: 0.3315  data: 0.0004  max mem: 2362
Train: Epoch[1/5]  [140/313]  eta: 0:00:57  Lr: 0.001875  Loss: -0.3401  Acc@1: 81.2500 (78.6791)  Acc@5: 100.0000 (95.5230)  time: 0.3313  data: 0.0002  max mem: 2362
Train: Epoch[1/5]  [150/313]  eta: 0:00:54  Lr: 0.001875  Loss: -0.6868  Acc@1: 81.2500 (78.8907)  Acc@5: 100.0000 (95.6954)  time: 0.3307  data: 0.0003  max mem: 2362
Train: Epoch[1/5]  [160/313]  eta: 0:00:50  Lr: 0.001875  Loss: -0.4710  Acc@1: 87.5000 (79.3866)  Acc@5: 100.0000 (95.8851)  time: 0.3290  data: 0.0002  max mem: 2362
Train: Epoch[1/5]  [170/313]  eta: 0:00:47  Lr: 0.001875  Loss: -0.3845  Acc@1: 81.2500 (79.4956)  Acc@5: 100.0000 (95.9064)  time: 0.3296  data: 0.0006  max mem: 2362
Train: Epoch[1/5]  [180/313]  eta: 0:00:44  Lr: 0.001875  Loss: -0.7665  Acc@1: 81.2500 (79.9378)  Acc@5: 100.0000 (96.0290)  time: 0.3307  data: 0.0007  max mem: 2362
Train: Epoch[1/5]  [190/313]  eta: 0:00:40  Lr: 0.001875  Loss: -0.6920  Acc@1: 87.5000 (80.2683)  Acc@5: 100.0000 (96.1387)  time: 0.3299  data: 0.0003  max mem: 2362
Train: Epoch[1/5]  [200/313]  eta: 0:00:37  Lr: 0.001875  Loss: -0.6268  Acc@1: 87.5000 (80.5348)  Acc@5: 100.0000 (96.2687)  time: 0.3301  data: 0.0003  max mem: 2362
Train: Epoch[1/5]  [210/313]  eta: 0:00:34  Lr: 0.001875  Loss: -0.9188  Acc@1: 87.5000 (80.9538)  Acc@5: 100.0000 (96.3270)  time: 0.3310  data: 0.0002  max mem: 2362
Train: Epoch[1/5]  [220/313]  eta: 0:00:30  Lr: 0.001875  Loss: -0.7858  Acc@1: 87.5000 (81.2217)  Acc@5: 100.0000 (96.3801)  time: 0.3310  data: 0.0003  max mem: 2362
Train: Epoch[1/5]  [230/313]  eta: 0:00:27  Lr: 0.001875  Loss: -0.6454  Acc@1: 87.5000 (81.5476)  Acc@5: 100.0000 (96.4827)  time: 0.3304  data: 0.0003  max mem: 2362
Train: Epoch[1/5]  [240/313]  eta: 0:00:24  Lr: 0.001875  Loss: -0.8039  Acc@1: 87.5000 (81.8205)  Acc@5: 100.0000 (96.6027)  time: 0.3293  data: 0.0003  max mem: 2362
Train: Epoch[1/5]  [250/313]  eta: 0:00:20  Lr: 0.001875  Loss: -0.9440  Acc@1: 87.5000 (82.1215)  Acc@5: 100.0000 (96.6384)  time: 0.3293  data: 0.0003  max mem: 2362
Train: Epoch[1/5]  [260/313]  eta: 0:00:17  Lr: 0.001875  Loss: -0.7596  Acc@1: 93.7500 (82.4713)  Acc@5: 100.0000 (96.7193)  time: 0.3292  data: 0.0003  max mem: 2362
Train: Epoch[1/5]  [270/313]  eta: 0:00:14  Lr: 0.001875  Loss: -0.8969  Acc@1: 87.5000 (82.4262)  Acc@5: 100.0000 (96.7712)  time: 0.3294  data: 0.0002  max mem: 2362
Train: Epoch[1/5]  [280/313]  eta: 0:00:10  Lr: 0.001875  Loss: -0.1319  Acc@1: 81.2500 (82.4066)  Acc@5: 100.0000 (96.7972)  time: 0.3294  data: 0.0002  max mem: 2362
Train: Epoch[1/5]  [290/313]  eta: 0:00:07  Lr: 0.001875  Loss: -0.6852  Acc@1: 87.5000 (82.7105)  Acc@5: 100.0000 (96.9072)  time: 0.3286  data: 0.0002  max mem: 2362
Train: Epoch[1/5]  [300/313]  eta: 0:00:04  Lr: 0.001875  Loss: -0.8832  Acc@1: 87.5000 (82.8696)  Acc@5: 100.0000 (96.9477)  time: 0.3286  data: 0.0003  max mem: 2362
Train: Epoch[1/5]  [310/313]  eta: 0:00:00  Lr: 0.001875  Loss: -0.8384  Acc@1: 87.5000 (83.0386)  Acc@5: 100.0000 (96.9855)  time: 0.3291  data: 0.0003  max mem: 2362
Train: Epoch[1/5]  [312/313]  eta: 0:00:00  Lr: 0.001875  Loss: -0.7556  Acc@1: 87.5000 (83.0800)  Acc@5: 100.0000 (97.0000)  time: 0.3211  data: 0.0003  max mem: 2362
Train: Epoch[1/5] Total time: 0:01:43 (0.3311 s / it)
Averaged stats: Lr: 0.001875  Loss: -0.7556  Acc@1: 87.5000 (83.0800)  Acc@5: 100.0000 (97.0000)
Train: Epoch[2/5]  [  0/313]  eta: 0:02:54  Lr: 0.001875  Loss: -0.6049  Acc@1: 87.5000 (87.5000)  Acc@5: 93.7500 (93.7500)  time: 0.5580  data: 0.2235  max mem: 2362
Train: Epoch[2/5]  [ 10/313]  eta: 0:01:46  Lr: 0.001875  Loss: -0.7928  Acc@1: 87.5000 (88.0682)  Acc@5: 100.0000 (98.8636)  time: 0.3501  data: 0.0206  max mem: 2362
Train: Epoch[2/5]  [ 20/313]  eta: 0:01:39  Lr: 0.001875  Loss: -0.5587  Acc@1: 87.5000 (88.0952)  Acc@5: 100.0000 (99.1071)  time: 0.3296  data: 0.0002  max mem: 2362
Train: Epoch[2/5]  [ 30/313]  eta: 0:01:35  Lr: 0.001875  Loss: -0.7207  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (98.5887)  time: 0.3292  data: 0.0003  max mem: 2362
Train: Epoch[2/5]  [ 40/313]  eta: 0:01:31  Lr: 0.001875  Loss: -0.8777  Acc@1: 87.5000 (87.8049)  Acc@5: 100.0000 (98.7805)  time: 0.3295  data: 0.0008  max mem: 2362
Train: Epoch[2/5]  [ 50/313]  eta: 0:01:27  Lr: 0.001875  Loss: -0.9613  Acc@1: 87.5000 (87.9902)  Acc@5: 100.0000 (98.6520)  time: 0.3305  data: 0.0007  max mem: 2362
Train: Epoch[2/5]  [ 60/313]  eta: 0:01:24  Lr: 0.001875  Loss: -0.5318  Acc@1: 93.7500 (88.5246)  Acc@5: 100.0000 (98.7705)  time: 0.3296  data: 0.0003  max mem: 2362
Train: Epoch[2/5]  [ 70/313]  eta: 0:01:20  Lr: 0.001875  Loss: -0.8033  Acc@1: 93.7500 (88.8204)  Acc@5: 100.0000 (98.6796)  time: 0.3291  data: 0.0003  max mem: 2362
Train: Epoch[2/5]  [ 80/313]  eta: 0:01:17  Lr: 0.001875  Loss: -0.5239  Acc@1: 87.5000 (88.5031)  Acc@5: 100.0000 (98.4568)  time: 0.3299  data: 0.0006  max mem: 2362
Train: Epoch[2/5]  [ 90/313]  eta: 0:01:14  Lr: 0.001875  Loss: -0.2021  Acc@1: 87.5000 (88.2555)  Acc@5: 100.0000 (98.2143)  time: 0.3299  data: 0.0005  max mem: 2362
Train: Epoch[2/5]  [100/313]  eta: 0:01:10  Lr: 0.001875  Loss: -0.5615  Acc@1: 87.5000 (88.1807)  Acc@5: 100.0000 (98.2054)  time: 0.3295  data: 0.0003  max mem: 2362
Train: Epoch[2/5]  [110/313]  eta: 0:01:07  Lr: 0.001875  Loss: -0.7150  Acc@1: 87.5000 (88.1194)  Acc@5: 100.0000 (98.1419)  time: 0.3305  data: 0.0003  max mem: 2362
Train: Epoch[2/5]  [120/313]  eta: 0:01:04  Lr: 0.001875  Loss: -0.7577  Acc@1: 87.5000 (88.0682)  Acc@5: 100.0000 (98.2955)  time: 0.3319  data: 0.0003  max mem: 2362
Train: Epoch[2/5]  [130/313]  eta: 0:01:00  Lr: 0.001875  Loss: -0.7284  Acc@1: 87.5000 (88.0725)  Acc@5: 100.0000 (98.3302)  time: 0.3322  data: 0.0003  max mem: 2362
Train: Epoch[2/5]  [140/313]  eta: 0:00:57  Lr: 0.001875  Loss: -0.7934  Acc@1: 87.5000 (88.0762)  Acc@5: 100.0000 (98.3599)  time: 0.3314  data: 0.0003  max mem: 2362
Train: Epoch[2/5]  [150/313]  eta: 0:00:54  Lr: 0.001875  Loss: -0.8657  Acc@1: 87.5000 (88.2036)  Acc@5: 100.0000 (98.3444)  time: 0.3296  data: 0.0003  max mem: 2362
Train: Epoch[2/5]  [160/313]  eta: 0:00:50  Lr: 0.001875  Loss: -0.4003  Acc@1: 87.5000 (87.8494)  Acc@5: 100.0000 (98.3307)  time: 0.3297  data: 0.0003  max mem: 2362
Train: Epoch[2/5]  [170/313]  eta: 0:00:47  Lr: 0.001875  Loss: -0.7473  Acc@1: 81.2500 (87.8655)  Acc@5: 100.0000 (98.2822)  time: 0.3308  data: 0.0003  max mem: 2362
Train: Epoch[2/5]  [180/313]  eta: 0:00:44  Lr: 0.001875  Loss: -0.9138  Acc@1: 93.7500 (88.1215)  Acc@5: 100.0000 (98.3771)  time: 0.3304  data: 0.0003  max mem: 2362
Train: Epoch[2/5]  [190/313]  eta: 0:00:40  Lr: 0.001875  Loss: -0.7548  Acc@1: 87.5000 (88.0890)  Acc@5: 100.0000 (98.3966)  time: 0.3301  data: 0.0003  max mem: 2362
Train: Epoch[2/5]  [200/313]  eta: 0:00:37  Lr: 0.001875  Loss: -0.9769  Acc@1: 87.5000 (88.0908)  Acc@5: 100.0000 (98.2898)  time: 0.3305  data: 0.0003  max mem: 2362
Train: Epoch[2/5]  [210/313]  eta: 0:00:34  Lr: 0.001875  Loss: -0.5120  Acc@1: 87.5000 (88.1517)  Acc@5: 100.0000 (98.3116)  time: 0.3319  data: 0.0002  max mem: 2362
Train: Epoch[2/5]  [220/313]  eta: 0:00:30  Lr: 0.001875  Loss: -0.9857  Acc@1: 87.5000 (88.1505)  Acc@5: 100.0000 (98.3314)  time: 0.3325  data: 0.0004  max mem: 2362
Train: Epoch[2/5]  [230/313]  eta: 0:00:27  Lr: 0.001875  Loss: -0.8373  Acc@1: 93.7500 (88.2576)  Acc@5: 100.0000 (98.3225)  time: 0.3318  data: 0.0005  max mem: 2362
Train: Epoch[2/5]  [240/313]  eta: 0:00:24  Lr: 0.001875  Loss: -0.3846  Acc@1: 87.5000 (88.1224)  Acc@5: 100.0000 (98.3662)  time: 0.3313  data: 0.0002  max mem: 2362
Train: Epoch[2/5]  [250/313]  eta: 0:00:20  Lr: 0.001875  Loss: -0.6002  Acc@1: 87.5000 (88.0478)  Acc@5: 100.0000 (98.3317)  time: 0.3310  data: 0.0002  max mem: 2362
Train: Epoch[2/5]  [260/313]  eta: 0:00:17  Lr: 0.001875  Loss: -0.7360  Acc@1: 81.2500 (87.8352)  Acc@5: 100.0000 (98.3716)  time: 0.3309  data: 0.0002  max mem: 2362
Train: Epoch[2/5]  [270/313]  eta: 0:00:14  Lr: 0.001875  Loss: -0.2894  Acc@1: 87.5000 (87.9151)  Acc@5: 100.0000 (98.3625)  time: 0.3315  data: 0.0003  max mem: 2362
Train: Epoch[2/5]  [280/313]  eta: 0:00:10  Lr: 0.001875  Loss: -0.5545  Acc@1: 93.7500 (87.9004)  Acc@5: 100.0000 (98.3763)  time: 0.3325  data: 0.0003  max mem: 2362
Train: Epoch[2/5]  [290/313]  eta: 0:00:07  Lr: 0.001875  Loss: -0.7172  Acc@1: 87.5000 (87.7577)  Acc@5: 100.0000 (98.3462)  time: 0.3320  data: 0.0002  max mem: 2362
Train: Epoch[2/5]  [300/313]  eta: 0:00:04  Lr: 0.001875  Loss: -0.8937  Acc@1: 87.5000 (87.8530)  Acc@5: 100.0000 (98.3389)  time: 0.3316  data: 0.0005  max mem: 2362
Train: Epoch[2/5]  [310/313]  eta: 0:00:00  Lr: 0.001875  Loss: -0.5264  Acc@1: 87.5000 (87.8416)  Acc@5: 100.0000 (98.3722)  time: 0.3317  data: 0.0005  max mem: 2362
Train: Epoch[2/5]  [312/313]  eta: 0:00:00  Lr: 0.001875  Loss: -0.6077  Acc@1: 87.5000 (87.8800)  Acc@5: 100.0000 (98.3800)  time: 0.3234  data: 0.0005  max mem: 2362
Train: Epoch[2/5] Total time: 0:01:43 (0.3312 s / it)
Averaged stats: Lr: 0.001875  Loss: -0.6077  Acc@1: 87.5000 (87.8800)  Acc@5: 100.0000 (98.3800)
Train: Epoch[3/5]  [  0/313]  eta: 0:02:41  Lr: 0.001875  Loss: -0.9033  Acc@1: 93.7500 (93.7500)  Acc@5: 100.0000 (100.0000)  time: 0.5175  data: 0.1831  max mem: 2362
Train: Epoch[3/5]  [ 10/313]  eta: 0:01:45  Lr: 0.001875  Loss: -0.5334  Acc@1: 87.5000 (84.6591)  Acc@5: 100.0000 (99.4318)  time: 0.3488  data: 0.0169  max mem: 2362
Train: Epoch[3/5]  [ 20/313]  eta: 0:01:39  Lr: 0.001875  Loss: 0.0214  Acc@1: 87.5000 (84.8214)  Acc@5: 100.0000 (97.9167)  time: 0.3323  data: 0.0002  max mem: 2362
Train: Epoch[3/5]  [ 30/313]  eta: 0:01:35  Lr: 0.001875  Loss: -0.5336  Acc@1: 87.5000 (85.6855)  Acc@5: 100.0000 (97.5806)  time: 0.3325  data: 0.0002  max mem: 2362
Train: Epoch[3/5]  [ 40/313]  eta: 0:01:32  Lr: 0.001875  Loss: -0.7318  Acc@1: 87.5000 (86.5854)  Acc@5: 100.0000 (98.1707)  time: 0.3327  data: 0.0002  max mem: 2362
Train: Epoch[3/5]  [ 50/313]  eta: 0:01:28  Lr: 0.001875  Loss: -0.3854  Acc@1: 87.5000 (86.1520)  Acc@5: 100.0000 (97.9167)  time: 0.3331  data: 0.0002  max mem: 2362
Train: Epoch[3/5]  [ 60/313]  eta: 0:01:24  Lr: 0.001875  Loss: -0.6886  Acc@1: 87.5000 (86.5779)  Acc@5: 100.0000 (98.1557)  time: 0.3326  data: 0.0002  max mem: 2362
Train: Epoch[3/5]  [ 70/313]  eta: 0:01:21  Lr: 0.001875  Loss: -0.8755  Acc@1: 87.5000 (86.8838)  Acc@5: 100.0000 (98.2394)  time: 0.3323  data: 0.0006  max mem: 2362
Train: Epoch[3/5]  [ 80/313]  eta: 0:01:18  Lr: 0.001875  Loss: -0.8866  Acc@1: 87.5000 (87.3457)  Acc@5: 100.0000 (98.2253)  time: 0.3324  data: 0.0006  max mem: 2362
Train: Epoch[3/5]  [ 90/313]  eta: 0:01:14  Lr: 0.001875  Loss: -0.8970  Acc@1: 87.5000 (87.4313)  Acc@5: 100.0000 (98.2143)  time: 0.3321  data: 0.0002  max mem: 2362
Train: Epoch[3/5]  [100/313]  eta: 0:01:11  Lr: 0.001875  Loss: -0.7359  Acc@1: 87.5000 (87.3762)  Acc@5: 100.0000 (98.1436)  time: 0.3320  data: 0.0003  max mem: 2362
Train: Epoch[3/5]  [110/313]  eta: 0:01:07  Lr: 0.001875  Loss: -0.6543  Acc@1: 87.5000 (87.6689)  Acc@5: 100.0000 (98.2545)  time: 0.3332  data: 0.0004  max mem: 2362
Train: Epoch[3/5]  [120/313]  eta: 0:01:04  Lr: 0.001875  Loss: -0.8585  Acc@1: 93.7500 (88.0165)  Acc@5: 100.0000 (98.2438)  time: 0.3341  data: 0.0004  max mem: 2362
Train: Epoch[3/5]  [130/313]  eta: 0:01:01  Lr: 0.001875  Loss: -1.0196  Acc@1: 93.7500 (88.1202)  Acc@5: 100.0000 (98.2824)  time: 0.3344  data: 0.0003  max mem: 2362
Train: Epoch[3/5]  [140/313]  eta: 0:00:57  Lr: 0.001875  Loss: -0.4879  Acc@1: 87.5000 (88.1649)  Acc@5: 100.0000 (98.3156)  time: 0.3337  data: 0.0003  max mem: 2362
Train: Epoch[3/5]  [150/313]  eta: 0:00:54  Lr: 0.001875  Loss: -0.7197  Acc@1: 87.5000 (88.0795)  Acc@5: 100.0000 (98.3858)  time: 0.3324  data: 0.0003  max mem: 2362
Train: Epoch[3/5]  [160/313]  eta: 0:00:51  Lr: 0.001875  Loss: -1.0300  Acc@1: 87.5000 (88.0435)  Acc@5: 100.0000 (98.3696)  time: 0.3330  data: 0.0006  max mem: 2362
Train: Epoch[3/5]  [170/313]  eta: 0:00:47  Lr: 0.001875  Loss: -0.6383  Acc@1: 87.5000 (87.7558)  Acc@5: 100.0000 (98.3187)  time: 0.3330  data: 0.0006  max mem: 2362
Train: Epoch[3/5]  [180/313]  eta: 0:00:44  Lr: 0.001875  Loss: -0.5006  Acc@1: 87.5000 (88.0180)  Acc@5: 100.0000 (98.3425)  time: 0.3322  data: 0.0004  max mem: 2362
Train: Epoch[3/5]  [190/313]  eta: 0:00:41  Lr: 0.001875  Loss: -0.6926  Acc@1: 87.5000 (88.0890)  Acc@5: 100.0000 (98.2984)  time: 0.3324  data: 0.0004  max mem: 2362
Train: Epoch[3/5]  [200/313]  eta: 0:00:37  Lr: 0.001875  Loss: -0.5178  Acc@1: 87.5000 (87.9664)  Acc@5: 100.0000 (98.3520)  time: 0.3335  data: 0.0002  max mem: 2362
Train: Epoch[3/5]  [210/313]  eta: 0:00:34  Lr: 0.001875  Loss: -0.8089  Acc@1: 87.5000 (87.9739)  Acc@5: 100.0000 (98.3116)  time: 0.3340  data: 0.0002  max mem: 2362
Train: Epoch[3/5]  [220/313]  eta: 0:00:31  Lr: 0.001875  Loss: -1.0075  Acc@1: 87.5000 (88.0373)  Acc@5: 100.0000 (98.3597)  time: 0.3331  data: 0.0002  max mem: 2362
Train: Epoch[3/5]  [230/313]  eta: 0:00:27  Lr: 0.001875  Loss: -0.5001  Acc@1: 87.5000 (87.9600)  Acc@5: 100.0000 (98.3766)  time: 0.3322  data: 0.0002  max mem: 2362
Train: Epoch[3/5]  [240/313]  eta: 0:00:24  Lr: 0.001875  Loss: -0.8078  Acc@1: 87.5000 (88.0187)  Acc@5: 100.0000 (98.4180)  time: 0.3321  data: 0.0002  max mem: 2362
Train: Epoch[3/5]  [250/313]  eta: 0:00:21  Lr: 0.001875  Loss: -0.3264  Acc@1: 87.5000 (88.0229)  Acc@5: 100.0000 (98.4313)  time: 0.3329  data: 0.0002  max mem: 2362
Train: Epoch[3/5]  [260/313]  eta: 0:00:17  Lr: 0.001875  Loss: -0.9748  Acc@1: 87.5000 (88.0747)  Acc@5: 100.0000 (98.3716)  time: 0.3333  data: 0.0002  max mem: 2362
Train: Epoch[3/5]  [270/313]  eta: 0:00:14  Lr: 0.001875  Loss: -0.8389  Acc@1: 87.5000 (87.9613)  Acc@5: 100.0000 (98.3856)  time: 0.3320  data: 0.0002  max mem: 2362
Train: Epoch[3/5]  [280/313]  eta: 0:00:11  Lr: 0.001875  Loss: -0.8229  Acc@1: 87.5000 (87.9004)  Acc@5: 100.0000 (98.3986)  time: 0.3310  data: 0.0002  max mem: 2362
Train: Epoch[3/5]  [290/313]  eta: 0:00:07  Lr: 0.001875  Loss: -0.6864  Acc@1: 87.5000 (87.9725)  Acc@5: 100.0000 (98.4321)  time: 0.3311  data: 0.0002  max mem: 2362
Train: Epoch[3/5]  [300/313]  eta: 0:00:04  Lr: 0.001875  Loss: -0.8846  Acc@1: 87.5000 (87.9568)  Acc@5: 100.0000 (98.4219)  time: 0.3306  data: 0.0002  max mem: 2362
Train: Epoch[3/5]  [310/313]  eta: 0:00:00  Lr: 0.001875  Loss: -0.8437  Acc@1: 87.5000 (88.0024)  Acc@5: 100.0000 (98.3923)  time: 0.3298  data: 0.0003  max mem: 2362
Train: Epoch[3/5]  [312/313]  eta: 0:00:00  Lr: 0.001875  Loss: -0.9804  Acc@1: 87.5000 (88.0400)  Acc@5: 100.0000 (98.4000)  time: 0.3216  data: 0.0002  max mem: 2362
Train: Epoch[3/5] Total time: 0:01:44 (0.3328 s / it)
Averaged stats: Lr: 0.001875  Loss: -0.9804  Acc@1: 87.5000 (88.0400)  Acc@5: 100.0000 (98.4000)
Train: Epoch[4/5]  [  0/313]  eta: 0:03:24  Lr: 0.001875  Loss: -0.8402  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (100.0000)  time: 0.6535  data: 0.3220  max mem: 2362
Train: Epoch[4/5]  [ 10/313]  eta: 0:01:48  Lr: 0.001875  Loss: -0.7587  Acc@1: 87.5000 (86.3636)  Acc@5: 100.0000 (98.8636)  time: 0.3596  data: 0.0295  max mem: 2362
Train: Epoch[4/5]  [ 20/313]  eta: 0:01:41  Lr: 0.001875  Loss: -0.6842  Acc@1: 87.5000 (88.9881)  Acc@5: 100.0000 (98.8095)  time: 0.3308  data: 0.0002  max mem: 2362
Train: Epoch[4/5]  [ 30/313]  eta: 0:01:36  Lr: 0.001875  Loss: -0.6145  Acc@1: 93.7500 (89.5161)  Acc@5: 100.0000 (99.1935)  time: 0.3308  data: 0.0002  max mem: 2362
Train: Epoch[4/5]  [ 40/313]  eta: 0:01:32  Lr: 0.001875  Loss: -0.8051  Acc@1: 93.7500 (90.0915)  Acc@5: 100.0000 (99.2378)  time: 0.3306  data: 0.0002  max mem: 2362
Train: Epoch[4/5]  [ 50/313]  eta: 0:01:28  Lr: 0.001875  Loss: -1.0755  Acc@1: 93.7500 (90.3186)  Acc@5: 100.0000 (99.2647)  time: 0.3317  data: 0.0007  max mem: 2362
Train: Epoch[4/5]  [ 60/313]  eta: 0:01:25  Lr: 0.001875  Loss: -0.7093  Acc@1: 87.5000 (89.9590)  Acc@5: 100.0000 (99.1803)  time: 0.3308  data: 0.0007  max mem: 2362
Train: Epoch[4/5]  [ 70/313]  eta: 0:01:21  Lr: 0.001875  Loss: -0.7325  Acc@1: 81.2500 (88.9085)  Acc@5: 100.0000 (99.0317)  time: 0.3287  data: 0.0002  max mem: 2362
Train: Epoch[4/5]  [ 80/313]  eta: 0:01:17  Lr: 0.001875  Loss: -0.4892  Acc@1: 81.2500 (88.0401)  Acc@5: 100.0000 (98.8426)  time: 0.3291  data: 0.0003  max mem: 2362
Train: Epoch[4/5]  [ 90/313]  eta: 0:01:14  Lr: 0.001875  Loss: -0.2658  Acc@1: 87.5000 (87.9808)  Acc@5: 100.0000 (98.6264)  time: 0.3298  data: 0.0003  max mem: 2362
Train: Epoch[4/5]  [100/313]  eta: 0:01:10  Lr: 0.001875  Loss: -1.1102  Acc@1: 87.5000 (88.3663)  Acc@5: 100.0000 (98.7624)  time: 0.3286  data: 0.0002  max mem: 2362
Train: Epoch[4/5]  [110/313]  eta: 0:01:07  Lr: 0.001875  Loss: -0.8914  Acc@1: 93.7500 (88.6261)  Acc@5: 100.0000 (98.7613)  time: 0.3285  data: 0.0002  max mem: 2362
Train: Epoch[4/5]  [120/313]  eta: 0:01:04  Lr: 0.001875  Loss: -0.9848  Acc@1: 93.7500 (88.3264)  Acc@5: 100.0000 (98.7603)  time: 0.3287  data: 0.0003  max mem: 2362
Train: Epoch[4/5]  [130/313]  eta: 0:01:00  Lr: 0.001875  Loss: -0.8277  Acc@1: 93.7500 (88.5496)  Acc@5: 100.0000 (98.7118)  time: 0.3287  data: 0.0003  max mem: 2362
Train: Epoch[4/5]  [140/313]  eta: 0:00:57  Lr: 0.001875  Loss: -1.0308  Acc@1: 87.5000 (88.6082)  Acc@5: 100.0000 (98.6259)  time: 0.3289  data: 0.0004  max mem: 2362
Train: Epoch[4/5]  [150/313]  eta: 0:00:54  Lr: 0.001875  Loss: -0.7791  Acc@1: 87.5000 (88.4106)  Acc@5: 100.0000 (98.6755)  time: 0.3284  data: 0.0003  max mem: 2362
Train: Epoch[4/5]  [160/313]  eta: 0:00:50  Lr: 0.001875  Loss: -0.7471  Acc@1: 87.5000 (88.3540)  Acc@5: 100.0000 (98.6413)  time: 0.3282  data: 0.0002  max mem: 2362
Train: Epoch[4/5]  [170/313]  eta: 0:00:47  Lr: 0.001875  Loss: -0.5480  Acc@1: 81.2500 (88.1213)  Acc@5: 100.0000 (98.6842)  time: 0.3283  data: 0.0002  max mem: 2362
Train: Epoch[4/5]  [180/313]  eta: 0:00:44  Lr: 0.001875  Loss: -1.0066  Acc@1: 87.5000 (88.1215)  Acc@5: 100.0000 (98.5843)  time: 0.3282  data: 0.0002  max mem: 2362
Train: Epoch[4/5]  [190/313]  eta: 0:00:40  Lr: 0.001875  Loss: -1.0077  Acc@1: 87.5000 (88.1545)  Acc@5: 100.0000 (98.6257)  time: 0.3286  data: 0.0002  max mem: 2362
Train: Epoch[4/5]  [200/313]  eta: 0:00:37  Lr: 0.001875  Loss: -0.7720  Acc@1: 87.5000 (88.2152)  Acc@5: 100.0000 (98.5386)  time: 0.3296  data: 0.0002  max mem: 2362
Train: Epoch[4/5]  [210/313]  eta: 0:00:34  Lr: 0.001875  Loss: -0.9088  Acc@1: 87.5000 (88.3886)  Acc@5: 100.0000 (98.5782)  time: 0.3290  data: 0.0002  max mem: 2362
Train: Epoch[4/5]  [220/313]  eta: 0:00:30  Lr: 0.001875  Loss: -0.3826  Acc@1: 87.5000 (88.1505)  Acc@5: 100.0000 (98.5860)  time: 0.3294  data: 0.0004  max mem: 2362
Train: Epoch[4/5]  [230/313]  eta: 0:00:27  Lr: 0.001875  Loss: -1.0307  Acc@1: 87.5000 (88.2035)  Acc@5: 100.0000 (98.5660)  time: 0.3298  data: 0.0003  max mem: 2362
Train: Epoch[4/5]  [240/313]  eta: 0:00:24  Lr: 0.001875  Loss: -0.8694  Acc@1: 87.5000 (88.2261)  Acc@5: 100.0000 (98.5477)  time: 0.3287  data: 0.0002  max mem: 2362
Train: Epoch[4/5]  [250/313]  eta: 0:00:20  Lr: 0.001875  Loss: -0.4809  Acc@1: 81.2500 (87.9980)  Acc@5: 100.0000 (98.5558)  time: 0.3286  data: 0.0002  max mem: 2362
Train: Epoch[4/5]  [260/313]  eta: 0:00:17  Lr: 0.001875  Loss: -0.8722  Acc@1: 87.5000 (88.1226)  Acc@5: 100.0000 (98.6111)  time: 0.3288  data: 0.0002  max mem: 2362
Train: Epoch[4/5]  [270/313]  eta: 0:00:14  Lr: 0.001875  Loss: -1.0604  Acc@1: 87.5000 (88.0535)  Acc@5: 100.0000 (98.6624)  time: 0.3284  data: 0.0002  max mem: 2362
Train: Epoch[4/5]  [280/313]  eta: 0:00:10  Lr: 0.001875  Loss: -1.0279  Acc@1: 87.5000 (88.0338)  Acc@5: 100.0000 (98.6432)  time: 0.3301  data: 0.0007  max mem: 2362
Train: Epoch[4/5]  [290/313]  eta: 0:00:07  Lr: 0.001875  Loss: -1.0153  Acc@1: 87.5000 (88.1658)  Acc@5: 100.0000 (98.6254)  time: 0.3310  data: 0.0007  max mem: 2362
Train: Epoch[4/5]  [300/313]  eta: 0:00:04  Lr: 0.001875  Loss: -0.8408  Acc@1: 93.7500 (88.2890)  Acc@5: 100.0000 (98.6711)  time: 0.3292  data: 0.0002  max mem: 2362
Train: Epoch[4/5]  [310/313]  eta: 0:00:00  Lr: 0.001875  Loss: -0.9116  Acc@1: 93.7500 (88.4244)  Acc@5: 100.0000 (98.6937)  time: 0.3291  data: 0.0002  max mem: 2362
Train: Epoch[4/5]  [312/313]  eta: 0:00:00  Lr: 0.001875  Loss: -0.8637  Acc@1: 93.7500 (88.3800)  Acc@5: 100.0000 (98.7000)  time: 0.3211  data: 0.0002  max mem: 2362
Train: Epoch[4/5] Total time: 0:01:43 (0.3302 s / it)
Averaged stats: Lr: 0.001875  Loss: -0.8637  Acc@1: 93.7500 (88.3800)  Acc@5: 100.0000 (98.7000)
Train: Epoch[5/5]  [  0/313]  eta: 0:02:42  Lr: 0.001875  Loss: -0.9347  Acc@1: 93.7500 (93.7500)  Acc@5: 100.0000 (100.0000)  time: 0.5204  data: 0.1889  max mem: 2362
Train: Epoch[5/5]  [ 10/313]  eta: 0:01:44  Lr: 0.001875  Loss: -0.4472  Acc@1: 93.7500 (91.4773)  Acc@5: 100.0000 (98.8636)  time: 0.3465  data: 0.0174  max mem: 2362
Train: Epoch[5/5]  [ 20/313]  eta: 0:01:39  Lr: 0.001875  Loss: -0.6996  Acc@1: 87.5000 (89.8810)  Acc@5: 100.0000 (98.2143)  time: 0.3297  data: 0.0002  max mem: 2362
Train: Epoch[5/5]  [ 30/313]  eta: 0:01:35  Lr: 0.001875  Loss: -0.2796  Acc@1: 87.5000 (87.0968)  Acc@5: 100.0000 (98.3871)  time: 0.3305  data: 0.0002  max mem: 2362
Train: Epoch[5/5]  [ 40/313]  eta: 0:01:31  Lr: 0.001875  Loss: -0.7449  Acc@1: 87.5000 (87.6524)  Acc@5: 100.0000 (98.4756)  time: 0.3306  data: 0.0003  max mem: 2362
Train: Epoch[5/5]  [ 50/313]  eta: 0:01:27  Lr: 0.001875  Loss: -0.8974  Acc@1: 87.5000 (87.7451)  Acc@5: 100.0000 (98.5294)  time: 0.3301  data: 0.0003  max mem: 2362
Train: Epoch[5/5]  [ 60/313]  eta: 0:01:24  Lr: 0.001875  Loss: -0.2509  Acc@1: 87.5000 (86.8852)  Acc@5: 100.0000 (98.2582)  time: 0.3298  data: 0.0003  max mem: 2362
Train: Epoch[5/5]  [ 70/313]  eta: 0:01:20  Lr: 0.001875  Loss: -0.9769  Acc@1: 87.5000 (87.3239)  Acc@5: 100.0000 (98.5035)  time: 0.3306  data: 0.0003  max mem: 2362
Train: Epoch[5/5]  [ 80/313]  eta: 0:01:17  Lr: 0.001875  Loss: -0.8491  Acc@1: 93.7500 (87.5772)  Acc@5: 100.0000 (98.4568)  time: 0.3309  data: 0.0003  max mem: 2362
Train: Epoch[5/5]  [ 90/313]  eta: 0:01:14  Lr: 0.001875  Loss: -0.6032  Acc@1: 87.5000 (87.6374)  Acc@5: 100.0000 (98.4203)  time: 0.3320  data: 0.0010  max mem: 2362
Train: Epoch[5/5]  [100/313]  eta: 0:01:10  Lr: 0.001875  Loss: -0.8018  Acc@1: 93.7500 (87.9950)  Acc@5: 100.0000 (98.4530)  time: 0.3322  data: 0.0009  max mem: 2362
Train: Epoch[5/5]  [110/313]  eta: 0:01:07  Lr: 0.001875  Loss: -0.9723  Acc@1: 93.7500 (88.0631)  Acc@5: 100.0000 (98.4234)  time: 0.3307  data: 0.0002  max mem: 2362
Train: Epoch[5/5]  [120/313]  eta: 0:01:04  Lr: 0.001875  Loss: -0.6099  Acc@1: 87.5000 (88.2748)  Acc@5: 100.0000 (98.3988)  time: 0.3310  data: 0.0002  max mem: 2362
Train: Epoch[5/5]  [130/313]  eta: 0:01:00  Lr: 0.001875  Loss: -0.8067  Acc@1: 87.5000 (88.2634)  Acc@5: 100.0000 (98.3779)  time: 0.3323  data: 0.0002  max mem: 2362
Train: Epoch[5/5]  [140/313]  eta: 0:00:57  Lr: 0.001875  Loss: -0.8540  Acc@1: 87.5000 (88.4309)  Acc@5: 100.0000 (98.3599)  time: 0.3326  data: 0.0003  max mem: 2362
Train: Epoch[5/5]  [150/313]  eta: 0:00:54  Lr: 0.001875  Loss: -0.7154  Acc@1: 87.5000 (88.4520)  Acc@5: 100.0000 (98.4685)  time: 0.3322  data: 0.0002  max mem: 2362
Train: Epoch[5/5]  [160/313]  eta: 0:00:50  Lr: 0.001875  Loss: -1.0924  Acc@1: 93.7500 (88.8199)  Acc@5: 100.0000 (98.5637)  time: 0.3317  data: 0.0002  max mem: 2362
Train: Epoch[5/5]  [170/313]  eta: 0:00:47  Lr: 0.001875  Loss: -0.4711  Acc@1: 93.7500 (88.9620)  Acc@5: 100.0000 (98.5380)  time: 0.3316  data: 0.0003  max mem: 2362
Train: Epoch[5/5]  [180/313]  eta: 0:00:44  Lr: 0.001875  Loss: -0.6471  Acc@1: 87.5000 (88.8812)  Acc@5: 100.0000 (98.5152)  time: 0.3320  data: 0.0003  max mem: 2362
Train: Epoch[5/5]  [190/313]  eta: 0:00:40  Lr: 0.001875  Loss: -0.7182  Acc@1: 87.5000 (88.8416)  Acc@5: 100.0000 (98.4948)  time: 0.3321  data: 0.0002  max mem: 2362
Train: Epoch[5/5]  [200/313]  eta: 0:00:37  Lr: 0.001875  Loss: -1.1455  Acc@1: 93.7500 (88.9614)  Acc@5: 100.0000 (98.5697)  time: 0.3326  data: 0.0010  max mem: 2362
Train: Epoch[5/5]  [210/313]  eta: 0:00:34  Lr: 0.001875  Loss: -0.8687  Acc@1: 87.5000 (88.7441)  Acc@5: 100.0000 (98.5782)  time: 0.3326  data: 0.0010  max mem: 2362
Train: Epoch[5/5]  [220/313]  eta: 0:00:30  Lr: 0.001875  Loss: -0.9926  Acc@1: 87.5000 (88.9706)  Acc@5: 100.0000 (98.6143)  time: 0.3324  data: 0.0004  max mem: 2362
Train: Epoch[5/5]  [230/313]  eta: 0:00:27  Lr: 0.001875  Loss: -0.3107  Acc@1: 93.7500 (88.9069)  Acc@5: 100.0000 (98.6472)  time: 0.3317  data: 0.0004  max mem: 2362
Train: Epoch[5/5]  [240/313]  eta: 0:00:24  Lr: 0.001875  Loss: -0.9543  Acc@1: 87.5000 (88.9004)  Acc@5: 100.0000 (98.6255)  time: 0.3324  data: 0.0010  max mem: 2362
Train: Epoch[5/5]  [250/313]  eta: 0:00:20  Lr: 0.001875  Loss: -0.5288  Acc@1: 87.5000 (88.9193)  Acc@5: 100.0000 (98.6056)  time: 0.3337  data: 0.0010  max mem: 2362
Train: Epoch[5/5]  [260/313]  eta: 0:00:17  Lr: 0.001875  Loss: -0.7306  Acc@1: 87.5000 (88.9128)  Acc@5: 100.0000 (98.6111)  time: 0.3324  data: 0.0002  max mem: 2362
Train: Epoch[5/5]  [270/313]  eta: 0:00:14  Lr: 0.001875  Loss: -1.1087  Acc@1: 93.7500 (88.9991)  Acc@5: 100.0000 (98.6162)  time: 0.3329  data: 0.0003  max mem: 2362
Train: Epoch[5/5]  [280/313]  eta: 0:00:10  Lr: 0.001875  Loss: -0.9496  Acc@1: 87.5000 (88.7900)  Acc@5: 100.0000 (98.6210)  time: 0.3338  data: 0.0004  max mem: 2362
Train: Epoch[5/5]  [290/313]  eta: 0:00:07  Lr: 0.001875  Loss: -1.0886  Acc@1: 87.5000 (88.7887)  Acc@5: 100.0000 (98.6684)  time: 0.3355  data: 0.0025  max mem: 2362
Train: Epoch[5/5]  [300/313]  eta: 0:00:04  Lr: 0.001875  Loss: -0.2093  Acc@1: 87.5000 (88.6420)  Acc@5: 100.0000 (98.6503)  time: 0.3349  data: 0.0024  max mem: 2362
Train: Epoch[5/5]  [310/313]  eta: 0:00:00  Lr: 0.001875  Loss: -0.9909  Acc@1: 87.5000 (88.6656)  Acc@5: 100.0000 (98.6535)  time: 0.3324  data: 0.0002  max mem: 2362
Train: Epoch[5/5]  [312/313]  eta: 0:00:00  Lr: 0.001875  Loss: -1.1079  Acc@1: 87.5000 (88.6800)  Acc@5: 100.0000 (98.6400)  time: 0.3241  data: 0.0002  max mem: 2362
Train: Epoch[5/5] Total time: 0:01:44 (0.3323 s / it)
Averaged stats: Lr: 0.001875  Loss: -1.1079  Acc@1: 87.5000 (88.6800)  Acc@5: 100.0000 (98.6400)
Test: [Task 1]  [ 0/63]  eta: 0:00:27  Loss: 0.5805 (0.5805)  Acc@1: 81.2500 (81.2500)  Acc@5: 100.0000 (100.0000)  time: 0.4442  data: 0.2344  max mem: 2362
Test: [Task 1]  [10/63]  eta: 0:00:12  Loss: 0.4493 (0.4649)  Acc@1: 93.7500 (90.9091)  Acc@5: 100.0000 (99.4318)  time: 0.2300  data: 0.0215  max mem: 2362
Test: [Task 1]  [20/63]  eta: 0:00:09  Loss: 0.4493 (0.5280)  Acc@1: 93.7500 (88.3929)  Acc@5: 100.0000 (99.4048)  time: 0.2087  data: 0.0003  max mem: 2362
Test: [Task 1]  [30/63]  eta: 0:00:07  Loss: 0.4002 (0.5017)  Acc@1: 87.5000 (89.1129)  Acc@5: 100.0000 (99.3952)  time: 0.2090  data: 0.0003  max mem: 2362
Test: [Task 1]  [40/63]  eta: 0:00:04  Loss: 0.4002 (0.4961)  Acc@1: 87.5000 (89.4817)  Acc@5: 100.0000 (99.5427)  time: 0.2098  data: 0.0004  max mem: 2362
Test: [Task 1]  [50/63]  eta: 0:00:02  Loss: 0.4480 (0.4741)  Acc@1: 93.7500 (90.4412)  Acc@5: 100.0000 (99.5098)  time: 0.2096  data: 0.0004  max mem: 2362
Test: [Task 1]  [60/63]  eta: 0:00:00  Loss: 0.4480 (0.4730)  Acc@1: 93.7500 (90.2664)  Acc@5: 100.0000 (99.2828)  time: 0.2085  data: 0.0002  max mem: 2362
Test: [Task 1]  [62/63]  eta: 0:00:00  Loss: 0.4110 (0.4724)  Acc@1: 93.7500 (90.4000)  Acc@5: 100.0000 (99.3000)  time: 0.2035  data: 0.0002  max mem: 2362
Test: [Task 1] Total time: 0:00:13 (0.2123 s / it)
* Acc@1 90.400 Acc@5 99.300 loss 0.472
Test: [Task 2]  [ 0/63]  eta: 0:00:26  Loss: 0.7359 (0.7359)  Acc@1: 93.7500 (93.7500)  Acc@5: 100.0000 (100.0000)  time: 0.4175  data: 0.2054  max mem: 2362
Test: [Task 2]  [10/63]  eta: 0:00:12  Loss: 0.5733 (0.6482)  Acc@1: 93.7500 (90.9091)  Acc@5: 100.0000 (98.2955)  time: 0.2277  data: 0.0189  max mem: 2362
Test: [Task 2]  [20/63]  eta: 0:00:09  Loss: 0.6151 (0.6917)  Acc@1: 87.5000 (88.9881)  Acc@5: 100.0000 (97.9167)  time: 0.2089  data: 0.0003  max mem: 2362
Test: [Task 2]  [30/63]  eta: 0:00:07  Loss: 0.6897 (0.6770)  Acc@1: 87.5000 (88.9113)  Acc@5: 100.0000 (97.5806)  time: 0.2087  data: 0.0002  max mem: 2362
Test: [Task 2]  [40/63]  eta: 0:00:04  Loss: 0.6159 (0.6592)  Acc@1: 93.7500 (89.3293)  Acc@5: 100.0000 (97.7134)  time: 0.2093  data: 0.0009  max mem: 2362
Test: [Task 2]  [50/63]  eta: 0:00:02  Loss: 0.5938 (0.6524)  Acc@1: 87.5000 (89.2157)  Acc@5: 100.0000 (97.7941)  time: 0.2095  data: 0.0009  max mem: 2362
Test: [Task 2]  [60/63]  eta: 0:00:00  Loss: 0.5068 (0.6302)  Acc@1: 87.5000 (89.6516)  Acc@5: 100.0000 (98.0533)  time: 0.2086  data: 0.0002  max mem: 2362
Test: [Task 2]  [62/63]  eta: 0:00:00  Loss: 0.4911 (0.6230)  Acc@1: 87.5000 (89.6000)  Acc@5: 100.0000 (98.1000)  time: 0.2035  data: 0.0002  max mem: 2362
Test: [Task 2] Total time: 0:00:13 (0.2120 s / it)
* Acc@1 89.600 Acc@5 98.100 loss 0.623
Test: [Task 3]  [ 0/63]  eta: 0:00:27  Loss: 0.2540 (0.2540)  Acc@1: 93.7500 (93.7500)  Acc@5: 100.0000 (100.0000)  time: 0.4433  data: 0.2336  max mem: 2362
Test: [Task 3]  [10/63]  eta: 0:00:12  Loss: 0.4896 (0.4975)  Acc@1: 93.7500 (89.2045)  Acc@5: 100.0000 (98.8636)  time: 0.2295  data: 0.0214  max mem: 2362
Test: [Task 3]  [20/63]  eta: 0:00:09  Loss: 0.5238 (0.5159)  Acc@1: 87.5000 (88.6905)  Acc@5: 100.0000 (98.8095)  time: 0.2081  data: 0.0002  max mem: 2362
Test: [Task 3]  [30/63]  eta: 0:00:07  Loss: 0.4746 (0.5069)  Acc@1: 87.5000 (89.1129)  Acc@5: 100.0000 (98.9919)  time: 0.2091  data: 0.0003  max mem: 2362
Test: [Task 3]  [40/63]  eta: 0:00:04  Loss: 0.4686 (0.4997)  Acc@1: 93.7500 (89.7866)  Acc@5: 100.0000 (99.0854)  time: 0.2089  data: 0.0004  max mem: 2362
Test: [Task 3]  [50/63]  eta: 0:00:02  Loss: 0.4568 (0.5015)  Acc@1: 93.7500 (90.3186)  Acc@5: 100.0000 (98.7745)  time: 0.2077  data: 0.0002  max mem: 2362
Test: [Task 3]  [60/63]  eta: 0:00:00  Loss: 0.5156 (0.5127)  Acc@1: 93.7500 (90.0615)  Acc@5: 100.0000 (98.9754)  time: 0.2078  data: 0.0002  max mem: 2362
Test: [Task 3]  [62/63]  eta: 0:00:00  Loss: 0.5443 (0.5152)  Acc@1: 87.5000 (89.9000)  Acc@5: 100.0000 (98.9000)  time: 0.2028  data: 0.0002  max mem: 2362
Test: [Task 3] Total time: 0:00:13 (0.2113 s / it)
* Acc@1 89.900 Acc@5 98.900 loss 0.515
Test: [Task 4]  [ 0/63]  eta: 0:00:27  Loss: 0.9703 (0.9703)  Acc@1: 87.5000 (87.5000)  Acc@5: 93.7500 (93.7500)  time: 0.4424  data: 0.2340  max mem: 2362
Test: [Task 4]  [10/63]  eta: 0:00:12  Loss: 0.5883 (0.5595)  Acc@1: 87.5000 (86.9318)  Acc@5: 100.0000 (98.2955)  time: 0.2290  data: 0.0215  max mem: 2362
Test: [Task 4]  [20/63]  eta: 0:00:09  Loss: 0.4708 (0.5432)  Acc@1: 87.5000 (87.7976)  Acc@5: 100.0000 (97.9167)  time: 0.2081  data: 0.0004  max mem: 2362
Test: [Task 4]  [30/63]  eta: 0:00:07  Loss: 0.4170 (0.5160)  Acc@1: 93.7500 (88.9113)  Acc@5: 100.0000 (97.9839)  time: 0.2081  data: 0.0004  max mem: 2362
Test: [Task 4]  [40/63]  eta: 0:00:04  Loss: 0.3272 (0.4882)  Acc@1: 93.7500 (89.6341)  Acc@5: 100.0000 (98.3232)  time: 0.2077  data: 0.0002  max mem: 2362
Test: [Task 4]  [50/63]  eta: 0:00:02  Loss: 0.3585 (0.4995)  Acc@1: 93.7500 (89.8284)  Acc@5: 100.0000 (98.2843)  time: 0.2074  data: 0.0002  max mem: 2362
Test: [Task 4]  [60/63]  eta: 0:00:00  Loss: 0.4891 (0.5144)  Acc@1: 87.5000 (89.3443)  Acc@5: 100.0000 (98.0533)  time: 0.2075  data: 0.0002  max mem: 2362
Test: [Task 4]  [62/63]  eta: 0:00:00  Loss: 0.4679 (0.5080)  Acc@1: 93.7500 (89.6000)  Acc@5: 100.0000 (98.1000)  time: 0.2028  data: 0.0002  max mem: 2362
Test: [Task 4] Total time: 0:00:13 (0.2112 s / it)
* Acc@1 89.600 Acc@5 98.100 loss 0.508
{0: {0: 392, 1: 392, 2: 392, 3: 392, 4: 392, 5: 224, 6: 224, 7: 224, 8: 224, 9: 224, 10: 64, 11: 64, 12: 64, 13: 64, 14: 64, 15: 320, 16: 320, 17: 320, 18: 320, 19: 320, 20: 0, 21: 0, 22: 0, 23: 0, 24: 0, 25: 0, 26: 0, 27: 0, 28: 0, 29: 0, 30: 0, 31: 0, 32: 0, 33: 0, 34: 0, 35: 0, 36: 0, 37: 0, 38: 0, 39: 0, 40: 0, 41: 0, 42: 0, 43: 0, 44: 0, 45: 0, 46: 0, 47: 0, 48: 0, 49: 0}, 1: {0: 824, 1: 824, 2: 824, 3: 824, 4: 824, 5: 128, 6: 128, 7: 128, 8: 128, 9: 128, 10: 0, 11: 0, 12: 0, 13: 0, 14: 0, 15: 48, 16: 48, 17: 48, 18: 48, 19: 48, 20: 0, 21: 0, 22: 0, 23: 0, 24: 0, 25: 0, 26: 0, 27: 0, 28: 0, 29: 0, 30: 0, 31: 0, 32: 0, 33: 0, 34: 0, 35: 0, 36: 0, 37: 0, 38: 0, 39: 0, 40: 0, 41: 0, 42: 0, 43: 0, 44: 0, 45: 0, 46: 0, 47: 0, 48: 0, 49: 0}, 2: {0: 248, 1: 248, 2: 248, 3: 248, 4: 248, 5: 736, 6: 736, 7: 736, 8: 736, 9: 736, 10: 16, 11: 16, 12: 16, 13: 16, 14: 16, 15: 0, 16: 0, 17: 0, 18: 0, 19: 0, 20: 0, 21: 0, 22: 0, 23: 0, 24: 0, 25: 0, 26: 0, 27: 0, 28: 0, 29: 0, 30: 0, 31: 0, 32: 0, 33: 0, 34: 0, 35: 0, 36: 0, 37: 0, 38: 0, 39: 0, 40: 0, 41: 0, 42: 0, 43: 0, 44: 0, 45: 0, 46: 0, 47: 0, 48: 0, 49: 0}, 3: {0: 680, 1: 680, 2: 680, 3: 680, 4: 680, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0, 10: 16, 11: 16, 12: 16, 13: 16, 14: 16, 15: 304, 16: 304, 17: 304, 18: 304, 19: 304, 20: 0, 21: 0, 22: 0, 23: 0, 24: 0, 25: 0, 26: 0, 27: 0, 28: 0, 29: 0, 30: 0, 31: 0, 32: 0, 33: 0, 34: 0, 35: 0, 36: 0, 37: 0, 38: 0, 39: 0, 40: 0, 41: 0, 42: 0, 43: 0, 44: 0, 45: 0, 46: 0, 47: 0, 48: 0, 49: 0}}
[Average accuracy till task4]	Acc@1: 89.8750	Acc@5: 98.6000	Loss: 0.5297	Forgetting: 4.0333	Backward: -4.0333
Train: Epoch[1/5]  [  0/313]  eta: 0:02:58  Lr: 0.001875  Loss: 1.1601  Acc@1: 0.0000 (0.0000)  Acc@5: 25.0000 (25.0000)  time: 0.5692  data: 0.2323  max mem: 2362
Train: Epoch[1/5]  [ 10/313]  eta: 0:01:47  Lr: 0.001875  Loss: 0.8882  Acc@1: 37.5000 (44.3182)  Acc@5: 81.2500 (74.4318)  time: 0.3539  data: 0.0226  max mem: 2362
Train: Epoch[1/5]  [ 20/313]  eta: 0:01:40  Lr: 0.001875  Loss: 0.6520  Acc@1: 56.2500 (53.5714)  Acc@5: 81.2500 (81.8452)  time: 0.3314  data: 0.0010  max mem: 2362
Train: Epoch[1/5]  [ 30/313]  eta: 0:01:35  Lr: 0.001875  Loss: 0.4080  Acc@1: 68.7500 (61.4919)  Acc@5: 93.7500 (86.4919)  time: 0.3309  data: 0.0009  max mem: 2362
Train: Epoch[1/5]  [ 40/313]  eta: 0:01:31  Lr: 0.001875  Loss: 0.3831  Acc@1: 75.0000 (66.3110)  Acc@5: 100.0000 (89.1768)  time: 0.3304  data: 0.0009  max mem: 2362
Train: Epoch[1/5]  [ 50/313]  eta: 0:01:28  Lr: 0.001875  Loss: -0.0819  Acc@1: 81.2500 (69.9755)  Acc@5: 100.0000 (90.5637)  time: 0.3302  data: 0.0002  max mem: 2362
Train: Epoch[1/5]  [ 60/313]  eta: 0:01:24  Lr: 0.001875  Loss: -0.1380  Acc@1: 87.5000 (72.2336)  Acc@5: 100.0000 (91.8033)  time: 0.3305  data: 0.0003  max mem: 2362
Train: Epoch[1/5]  [ 70/313]  eta: 0:01:21  Lr: 0.001875  Loss: -0.1520  Acc@1: 87.5000 (73.8556)  Acc@5: 100.0000 (92.6056)  time: 0.3296  data: 0.0005  max mem: 2362
Train: Epoch[1/5]  [ 80/313]  eta: 0:01:17  Lr: 0.001875  Loss: -0.3790  Acc@1: 87.5000 (75.2315)  Acc@5: 100.0000 (93.4414)  time: 0.3298  data: 0.0004  max mem: 2362
Train: Epoch[1/5]  [ 90/313]  eta: 0:01:14  Lr: 0.001875  Loss: -0.4654  Acc@1: 87.5000 (76.3736)  Acc@5: 100.0000 (94.0247)  time: 0.3299  data: 0.0003  max mem: 2362
Train: Epoch[1/5]  [100/313]  eta: 0:01:10  Lr: 0.001875  Loss: -0.5130  Acc@1: 87.5000 (77.4134)  Acc@5: 100.0000 (94.2450)  time: 0.3288  data: 0.0003  max mem: 2362
Train: Epoch[1/5]  [110/313]  eta: 0:01:07  Lr: 0.001875  Loss: -0.4728  Acc@1: 87.5000 (78.2095)  Acc@5: 100.0000 (94.5946)  time: 0.3282  data: 0.0003  max mem: 2362
Train: Epoch[1/5]  [120/313]  eta: 0:01:04  Lr: 0.001875  Loss: -0.5378  Acc@1: 87.5000 (78.6674)  Acc@5: 100.0000 (94.6798)  time: 0.3301  data: 0.0011  max mem: 2362
Train: Epoch[1/5]  [130/313]  eta: 0:01:00  Lr: 0.001875  Loss: -0.5108  Acc@1: 81.2500 (78.5305)  Acc@5: 100.0000 (94.7996)  time: 0.3300  data: 0.0011  max mem: 2362
Train: Epoch[1/5]  [140/313]  eta: 0:00:57  Lr: 0.001875  Loss: -0.3255  Acc@1: 81.2500 (79.0337)  Acc@5: 100.0000 (95.0355)  time: 0.3281  data: 0.0002  max mem: 2362
Train: Epoch[1/5]  [150/313]  eta: 0:00:54  Lr: 0.001875  Loss: -0.1836  Acc@1: 81.2500 (79.3046)  Acc@5: 100.0000 (95.0745)  time: 0.3288  data: 0.0003  max mem: 2362
Train: Epoch[1/5]  [160/313]  eta: 0:00:50  Lr: 0.001875  Loss: -0.2614  Acc@1: 81.2500 (79.5807)  Acc@5: 100.0000 (95.2640)  time: 0.3289  data: 0.0003  max mem: 2362
Train: Epoch[1/5]  [170/313]  eta: 0:00:47  Lr: 0.001875  Loss: -0.3043  Acc@1: 87.5000 (79.9708)  Acc@5: 100.0000 (95.3216)  time: 0.3299  data: 0.0010  max mem: 2362
Train: Epoch[1/5]  [180/313]  eta: 0:00:44  Lr: 0.001875  Loss: -0.6358  Acc@1: 87.5000 (80.3522)  Acc@5: 100.0000 (95.5456)  time: 0.3305  data: 0.0010  max mem: 2362
Train: Epoch[1/5]  [190/313]  eta: 0:00:40  Lr: 0.001875  Loss: -0.7217  Acc@1: 81.2500 (80.4647)  Acc@5: 100.0000 (95.6806)  time: 0.3300  data: 0.0003  max mem: 2362
Train: Epoch[1/5]  [200/313]  eta: 0:00:37  Lr: 0.001875  Loss: -0.7654  Acc@1: 81.2500 (80.5037)  Acc@5: 100.0000 (95.7711)  time: 0.3310  data: 0.0007  max mem: 2362
Train: Epoch[1/5]  [210/313]  eta: 0:00:34  Lr: 0.001875  Loss: -0.8467  Acc@1: 87.5000 (80.8353)  Acc@5: 100.0000 (95.9716)  time: 0.3309  data: 0.0019  max mem: 2362
Train: Epoch[1/5]  [220/313]  eta: 0:00:30  Lr: 0.001875  Loss: -0.5935  Acc@1: 87.5000 (81.3066)  Acc@5: 100.0000 (96.1256)  time: 0.3295  data: 0.0015  max mem: 2362
Train: Epoch[1/5]  [230/313]  eta: 0:00:27  Lr: 0.001875  Loss: -0.2890  Acc@1: 87.5000 (81.1688)  Acc@5: 100.0000 (96.1851)  time: 0.3290  data: 0.0003  max mem: 2362
Train: Epoch[1/5]  [240/313]  eta: 0:00:24  Lr: 0.001875  Loss: -0.8015  Acc@1: 81.2500 (81.4575)  Acc@5: 100.0000 (96.3174)  time: 0.3294  data: 0.0002  max mem: 2362
Train: Epoch[1/5]  [250/313]  eta: 0:00:20  Lr: 0.001875  Loss: -0.7753  Acc@1: 87.5000 (81.8227)  Acc@5: 100.0000 (96.4143)  time: 0.3289  data: 0.0002  max mem: 2362
Train: Epoch[1/5]  [260/313]  eta: 0:00:17  Lr: 0.001875  Loss: -0.6331  Acc@1: 87.5000 (82.0881)  Acc@5: 100.0000 (96.5278)  time: 0.3284  data: 0.0002  max mem: 2362
Train: Epoch[1/5]  [270/313]  eta: 0:00:14  Lr: 0.001875  Loss: -0.6298  Acc@1: 87.5000 (82.2417)  Acc@5: 100.0000 (96.6328)  time: 0.3294  data: 0.0003  max mem: 2362
Train: Epoch[1/5]  [280/313]  eta: 0:00:10  Lr: 0.001875  Loss: -0.3780  Acc@1: 81.2500 (82.1619)  Acc@5: 100.0000 (96.6859)  time: 0.3299  data: 0.0003  max mem: 2362
Train: Epoch[1/5]  [290/313]  eta: 0:00:07  Lr: 0.001875  Loss: -0.8028  Acc@1: 81.2500 (82.2809)  Acc@5: 100.0000 (96.7569)  time: 0.3295  data: 0.0003  max mem: 2362
Train: Epoch[1/5]  [300/313]  eta: 0:00:04  Lr: 0.001875  Loss: -0.6608  Acc@1: 87.5000 (82.2467)  Acc@5: 100.0000 (96.8439)  time: 0.3304  data: 0.0004  max mem: 2362
Train: Epoch[1/5]  [310/313]  eta: 0:00:00  Lr: 0.001875  Loss: -0.8658  Acc@1: 87.5000 (82.3553)  Acc@5: 100.0000 (96.9051)  time: 0.3306  data: 0.0004  max mem: 2362
Train: Epoch[1/5]  [312/313]  eta: 0:00:00  Lr: 0.001875  Loss: -0.4503  Acc@1: 87.5000 (82.3600)  Acc@5: 100.0000 (96.9000)  time: 0.3217  data: 0.0003  max mem: 2362
Train: Epoch[1/5] Total time: 0:01:43 (0.3303 s / it)
Averaged stats: Lr: 0.001875  Loss: -0.4503  Acc@1: 87.5000 (82.3600)  Acc@5: 100.0000 (96.9000)
Train: Epoch[2/5]  [  0/313]  eta: 0:03:18  Lr: 0.001875  Loss: -0.5479  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (100.0000)  time: 0.6347  data: 0.3030  max mem: 2362
Train: Epoch[2/5]  [ 10/313]  eta: 0:01:48  Lr: 0.001875  Loss: -0.6118  Acc@1: 87.5000 (86.9318)  Acc@5: 100.0000 (99.4318)  time: 0.3567  data: 0.0278  max mem: 2362
Train: Epoch[2/5]  [ 20/313]  eta: 0:01:40  Lr: 0.001875  Loss: -0.6579  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (99.4048)  time: 0.3297  data: 0.0004  max mem: 2362
Train: Epoch[2/5]  [ 30/313]  eta: 0:01:36  Lr: 0.001875  Loss: -0.8910  Acc@1: 87.5000 (88.1048)  Acc@5: 100.0000 (99.3952)  time: 0.3301  data: 0.0004  max mem: 2362
Train: Epoch[2/5]  [ 40/313]  eta: 0:01:32  Lr: 0.001875  Loss: -0.6268  Acc@1: 87.5000 (88.1098)  Acc@5: 100.0000 (99.2378)  time: 0.3302  data: 0.0002  max mem: 2362
Train: Epoch[2/5]  [ 50/313]  eta: 0:01:28  Lr: 0.001875  Loss: -0.4244  Acc@1: 87.5000 (87.7451)  Acc@5: 100.0000 (99.1422)  time: 0.3304  data: 0.0003  max mem: 2362
Train: Epoch[2/5]  [ 60/313]  eta: 0:01:24  Lr: 0.001875  Loss: -0.8830  Acc@1: 87.5000 (87.1926)  Acc@5: 100.0000 (99.2828)  time: 0.3302  data: 0.0003  max mem: 2362
Train: Epoch[2/5]  [ 70/313]  eta: 0:01:21  Lr: 0.001875  Loss: -0.6891  Acc@1: 87.5000 (87.6761)  Acc@5: 100.0000 (99.2077)  time: 0.3303  data: 0.0002  max mem: 2362
Train: Epoch[2/5]  [ 80/313]  eta: 0:01:17  Lr: 0.001875  Loss: -0.8320  Acc@1: 87.5000 (86.9599)  Acc@5: 100.0000 (99.1512)  time: 0.3305  data: 0.0007  max mem: 2362
Train: Epoch[2/5]  [ 90/313]  eta: 0:01:14  Lr: 0.001875  Loss: -0.6517  Acc@1: 81.2500 (86.7445)  Acc@5: 100.0000 (99.1071)  time: 0.3308  data: 0.0007  max mem: 2362
Train: Epoch[2/5]  [100/313]  eta: 0:01:10  Lr: 0.001875  Loss: -0.8572  Acc@1: 87.5000 (86.7574)  Acc@5: 100.0000 (99.0718)  time: 0.3309  data: 0.0002  max mem: 2362
Train: Epoch[2/5]  [110/313]  eta: 0:01:07  Lr: 0.001875  Loss: -0.6506  Acc@1: 87.5000 (86.7680)  Acc@5: 100.0000 (98.9302)  time: 0.3313  data: 0.0002  max mem: 2362
Train: Epoch[2/5]  [120/313]  eta: 0:01:04  Lr: 0.001875  Loss: -0.8644  Acc@1: 81.2500 (86.3636)  Acc@5: 100.0000 (99.0186)  time: 0.3304  data: 0.0002  max mem: 2362
Train: Epoch[2/5]  [130/313]  eta: 0:01:00  Lr: 0.001875  Loss: -0.5561  Acc@1: 87.5000 (86.5935)  Acc@5: 100.0000 (98.9504)  time: 0.3296  data: 0.0006  max mem: 2362
Train: Epoch[2/5]  [140/313]  eta: 0:00:57  Lr: 0.001875  Loss: -0.7481  Acc@1: 87.5000 (86.7465)  Acc@5: 100.0000 (98.9805)  time: 0.3301  data: 0.0007  max mem: 2362
Train: Epoch[2/5]  [150/313]  eta: 0:00:54  Lr: 0.001875  Loss: -0.7262  Acc@1: 87.5000 (86.7964)  Acc@5: 100.0000 (99.0480)  time: 0.3304  data: 0.0006  max mem: 2362
Train: Epoch[2/5]  [160/313]  eta: 0:00:50  Lr: 0.001875  Loss: -0.7376  Acc@1: 87.5000 (86.8789)  Acc@5: 100.0000 (99.0295)  time: 0.3303  data: 0.0007  max mem: 2362
Train: Epoch[2/5]  [170/313]  eta: 0:00:47  Lr: 0.001875  Loss: -0.6669  Acc@1: 87.5000 (86.6594)  Acc@5: 100.0000 (98.9766)  time: 0.3306  data: 0.0004  max mem: 2362
Train: Epoch[2/5]  [180/313]  eta: 0:00:44  Lr: 0.001875  Loss: -0.6961  Acc@1: 87.5000 (86.6022)  Acc@5: 100.0000 (98.9986)  time: 0.3306  data: 0.0002  max mem: 2362
Train: Epoch[2/5]  [190/313]  eta: 0:00:40  Lr: 0.001875  Loss: -0.9688  Acc@1: 87.5000 (86.7474)  Acc@5: 100.0000 (99.0183)  time: 0.3308  data: 0.0003  max mem: 2362
Train: Epoch[2/5]  [200/313]  eta: 0:00:37  Lr: 0.001875  Loss: -0.3192  Acc@1: 87.5000 (86.7226)  Acc@5: 100.0000 (98.9428)  time: 0.3304  data: 0.0002  max mem: 2362
Train: Epoch[2/5]  [210/313]  eta: 0:00:34  Lr: 0.001875  Loss: -0.8872  Acc@1: 87.5000 (86.7299)  Acc@5: 100.0000 (98.9929)  time: 0.3307  data: 0.0002  max mem: 2362
Train: Epoch[2/5]  [220/313]  eta: 0:00:30  Lr: 0.001875  Loss: -0.7482  Acc@1: 87.5000 (86.7364)  Acc@5: 100.0000 (98.9536)  time: 0.3317  data: 0.0007  max mem: 2362
Train: Epoch[2/5]  [230/313]  eta: 0:00:27  Lr: 0.001875  Loss: -0.8268  Acc@1: 87.5000 (86.8506)  Acc@5: 100.0000 (98.9989)  time: 0.3312  data: 0.0007  max mem: 2362
Train: Epoch[2/5]  [240/313]  eta: 0:00:24  Lr: 0.001875  Loss: -0.5738  Acc@1: 93.7500 (87.0851)  Acc@5: 100.0000 (99.0145)  time: 0.3306  data: 0.0006  max mem: 2362
Train: Epoch[2/5]  [250/313]  eta: 0:00:20  Lr: 0.001875  Loss: -0.8895  Acc@1: 93.7500 (87.2012)  Acc@5: 100.0000 (98.9791)  time: 0.3299  data: 0.0006  max mem: 2362
Train: Epoch[2/5]  [260/313]  eta: 0:00:17  Lr: 0.001875  Loss: -0.7889  Acc@1: 93.7500 (87.3084)  Acc@5: 100.0000 (98.9224)  time: 0.3296  data: 0.0003  max mem: 2362
Train: Epoch[2/5]  [270/313]  eta: 0:00:14  Lr: 0.001875  Loss: -0.4812  Acc@1: 87.5000 (87.3155)  Acc@5: 100.0000 (98.9391)  time: 0.3297  data: 0.0002  max mem: 2362
Train: Epoch[2/5]  [280/313]  eta: 0:00:10  Lr: 0.001875  Loss: -0.7715  Acc@1: 87.5000 (87.2776)  Acc@5: 100.0000 (98.9101)  time: 0.3292  data: 0.0002  max mem: 2362
Train: Epoch[2/5]  [290/313]  eta: 0:00:07  Lr: 0.001875  Loss: -0.5112  Acc@1: 93.7500 (87.3067)  Acc@5: 100.0000 (98.9261)  time: 0.3300  data: 0.0002  max mem: 2362
Train: Epoch[2/5]  [300/313]  eta: 0:00:04  Lr: 0.001875  Loss: -0.8582  Acc@1: 87.5000 (87.2924)  Acc@5: 100.0000 (98.9410)  time: 0.3308  data: 0.0006  max mem: 2362
Train: Epoch[2/5]  [310/313]  eta: 0:00:00  Lr: 0.001875  Loss: -0.9229  Acc@1: 87.5000 (87.2588)  Acc@5: 100.0000 (98.9349)  time: 0.3301  data: 0.0006  max mem: 2362
Train: Epoch[2/5]  [312/313]  eta: 0:00:00  Lr: 0.001875  Loss: -0.1989  Acc@1: 87.5000 (87.2200)  Acc@5: 100.0000 (98.9400)  time: 0.3216  data: 0.0002  max mem: 2362
Train: Epoch[2/5] Total time: 0:01:43 (0.3310 s / it)
Averaged stats: Lr: 0.001875  Loss: -0.1989  Acc@1: 87.5000 (87.2200)  Acc@5: 100.0000 (98.9400)
Train: Epoch[3/5]  [  0/313]  eta: 0:03:21  Lr: 0.001875  Loss: -0.8713  Acc@1: 93.7500 (93.7500)  Acc@5: 100.0000 (100.0000)  time: 0.6423  data: 0.3096  max mem: 2362
Train: Epoch[3/5]  [ 10/313]  eta: 0:01:48  Lr: 0.001875  Loss: -0.6917  Acc@1: 87.5000 (89.7727)  Acc@5: 100.0000 (98.2955)  time: 0.3578  data: 0.0284  max mem: 2362
Train: Epoch[3/5]  [ 20/313]  eta: 0:01:40  Lr: 0.001875  Loss: -0.7422  Acc@1: 87.5000 (87.7976)  Acc@5: 100.0000 (98.8095)  time: 0.3296  data: 0.0002  max mem: 2362
Train: Epoch[3/5]  [ 30/313]  eta: 0:01:36  Lr: 0.001875  Loss: -0.3956  Acc@1: 87.5000 (88.3065)  Acc@5: 100.0000 (98.5887)  time: 0.3292  data: 0.0002  max mem: 2362
Train: Epoch[3/5]  [ 40/313]  eta: 0:01:32  Lr: 0.001875  Loss: -0.9618  Acc@1: 87.5000 (88.2622)  Acc@5: 100.0000 (98.4756)  time: 0.3303  data: 0.0002  max mem: 2362
Train: Epoch[3/5]  [ 50/313]  eta: 0:01:28  Lr: 0.001875  Loss: -0.6942  Acc@1: 87.5000 (88.1127)  Acc@5: 100.0000 (98.5294)  time: 0.3314  data: 0.0003  max mem: 2362
Train: Epoch[3/5]  [ 60/313]  eta: 0:01:24  Lr: 0.001875  Loss: -0.7332  Acc@1: 87.5000 (87.7049)  Acc@5: 100.0000 (98.4631)  time: 0.3308  data: 0.0003  max mem: 2362
Train: Epoch[3/5]  [ 70/313]  eta: 0:01:21  Lr: 0.001875  Loss: -0.9224  Acc@1: 87.5000 (87.0599)  Acc@5: 100.0000 (98.5035)  time: 0.3310  data: 0.0002  max mem: 2362
Train: Epoch[3/5]  [ 80/313]  eta: 0:01:17  Lr: 0.001875  Loss: -0.9193  Acc@1: 87.5000 (87.1142)  Acc@5: 100.0000 (98.6883)  time: 0.3307  data: 0.0003  max mem: 2362
Train: Epoch[3/5]  [ 90/313]  eta: 0:01:14  Lr: 0.001875  Loss: -0.9798  Acc@1: 87.5000 (87.0192)  Acc@5: 100.0000 (98.4203)  time: 0.3301  data: 0.0003  max mem: 2362
Train: Epoch[3/5]  [100/313]  eta: 0:01:10  Lr: 0.001875  Loss: -0.9264  Acc@1: 87.5000 (87.1287)  Acc@5: 100.0000 (98.4530)  time: 0.3293  data: 0.0002  max mem: 2362
Train: Epoch[3/5]  [110/313]  eta: 0:01:07  Lr: 0.001875  Loss: -0.8684  Acc@1: 87.5000 (87.2748)  Acc@5: 100.0000 (98.5923)  time: 0.3290  data: 0.0003  max mem: 2362
Train: Epoch[3/5]  [120/313]  eta: 0:01:04  Lr: 0.001875  Loss: -0.6019  Acc@1: 87.5000 (87.0868)  Acc@5: 100.0000 (98.5537)  time: 0.3290  data: 0.0003  max mem: 2362
Train: Epoch[3/5]  [130/313]  eta: 0:01:00  Lr: 0.001875  Loss: -0.8970  Acc@1: 87.5000 (87.0706)  Acc@5: 100.0000 (98.5210)  time: 0.3293  data: 0.0008  max mem: 2362
Train: Epoch[3/5]  [140/313]  eta: 0:00:57  Lr: 0.001875  Loss: -0.5283  Acc@1: 87.5000 (87.1897)  Acc@5: 100.0000 (98.5372)  time: 0.3294  data: 0.0008  max mem: 2362
Train: Epoch[3/5]  [150/313]  eta: 0:00:54  Lr: 0.001875  Loss: -1.0626  Acc@1: 87.5000 (87.1689)  Acc@5: 100.0000 (98.6341)  time: 0.3296  data: 0.0003  max mem: 2362
Train: Epoch[3/5]  [160/313]  eta: 0:00:50  Lr: 0.001875  Loss: -0.6332  Acc@1: 87.5000 (87.4612)  Acc@5: 100.0000 (98.6025)  time: 0.3298  data: 0.0004  max mem: 2362
Train: Epoch[3/5]  [170/313]  eta: 0:00:47  Lr: 0.001875  Loss: -0.4754  Acc@1: 87.5000 (87.4269)  Acc@5: 100.0000 (98.5015)  time: 0.3289  data: 0.0003  max mem: 2362
Train: Epoch[3/5]  [180/313]  eta: 0:00:44  Lr: 0.001875  Loss: -0.2672  Acc@1: 87.5000 (87.6036)  Acc@5: 100.0000 (98.5843)  time: 0.3289  data: 0.0002  max mem: 2362
Train: Epoch[3/5]  [190/313]  eta: 0:00:40  Lr: 0.001875  Loss: -0.3477  Acc@1: 87.5000 (87.4673)  Acc@5: 100.0000 (98.5929)  time: 0.3289  data: 0.0003  max mem: 2362
Train: Epoch[3/5]  [200/313]  eta: 0:00:37  Lr: 0.001875  Loss: -0.7203  Acc@1: 87.5000 (87.5311)  Acc@5: 100.0000 (98.6007)  time: 0.3292  data: 0.0002  max mem: 2362
Train: Epoch[3/5]  [210/313]  eta: 0:00:34  Lr: 0.001875  Loss: -0.7450  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (98.6078)  time: 0.3290  data: 0.0002  max mem: 2362
Train: Epoch[3/5]  [220/313]  eta: 0:00:30  Lr: 0.001875  Loss: -0.7422  Acc@1: 87.5000 (87.5848)  Acc@5: 100.0000 (98.5577)  time: 0.3282  data: 0.0005  max mem: 2362
Train: Epoch[3/5]  [230/313]  eta: 0:00:27  Lr: 0.001875  Loss: -0.7269  Acc@1: 87.5000 (87.5541)  Acc@5: 100.0000 (98.5931)  time: 0.3280  data: 0.0005  max mem: 2362
Train: Epoch[3/5]  [240/313]  eta: 0:00:24  Lr: 0.001875  Loss: -0.6853  Acc@1: 87.5000 (87.6037)  Acc@5: 100.0000 (98.5477)  time: 0.3293  data: 0.0011  max mem: 2362
Train: Epoch[3/5]  [250/313]  eta: 0:00:20  Lr: 0.001875  Loss: -0.8099  Acc@1: 87.5000 (87.6494)  Acc@5: 100.0000 (98.6056)  time: 0.3303  data: 0.0011  max mem: 2362
Train: Epoch[3/5]  [260/313]  eta: 0:00:17  Lr: 0.001875  Loss: -0.3648  Acc@1: 87.5000 (87.6197)  Acc@5: 100.0000 (98.5872)  time: 0.3289  data: 0.0002  max mem: 2362
Train: Epoch[3/5]  [270/313]  eta: 0:00:14  Lr: 0.001875  Loss: -0.8892  Acc@1: 87.5000 (87.5692)  Acc@5: 100.0000 (98.5932)  time: 0.3282  data: 0.0004  max mem: 2362
Train: Epoch[3/5]  [280/313]  eta: 0:00:10  Lr: 0.001875  Loss: -0.6853  Acc@1: 87.5000 (87.6335)  Acc@5: 100.0000 (98.5988)  time: 0.3287  data: 0.0004  max mem: 2362
Train: Epoch[3/5]  [290/313]  eta: 0:00:07  Lr: 0.001875  Loss: -0.8132  Acc@1: 87.5000 (87.6503)  Acc@5: 100.0000 (98.6040)  time: 0.3288  data: 0.0003  max mem: 2362
Train: Epoch[3/5]  [300/313]  eta: 0:00:04  Lr: 0.001875  Loss: -0.6917  Acc@1: 87.5000 (87.5415)  Acc@5: 100.0000 (98.6296)  time: 0.3292  data: 0.0002  max mem: 2362
Train: Epoch[3/5]  [310/313]  eta: 0:00:00  Lr: 0.001875  Loss: -0.8772  Acc@1: 87.5000 (87.5201)  Acc@5: 100.0000 (98.6535)  time: 0.3291  data: 0.0002  max mem: 2362
Train: Epoch[3/5]  [312/313]  eta: 0:00:00  Lr: 0.001875  Loss: -0.3743  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (98.6600)  time: 0.3207  data: 0.0002  max mem: 2362
Train: Epoch[3/5] Total time: 0:01:43 (0.3301 s / it)
Averaged stats: Lr: 0.001875  Loss: -0.3743  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (98.6600)
Train: Epoch[4/5]  [  0/313]  eta: 0:02:56  Lr: 0.001875  Loss: -0.8694  Acc@1: 81.2500 (81.2500)  Acc@5: 100.0000 (100.0000)  time: 0.5628  data: 0.2325  max mem: 2362
Train: Epoch[4/5]  [ 10/313]  eta: 0:01:46  Lr: 0.001875  Loss: -0.9372  Acc@1: 87.5000 (88.6364)  Acc@5: 100.0000 (98.8636)  time: 0.3505  data: 0.0214  max mem: 2362
Train: Epoch[4/5]  [ 20/313]  eta: 0:01:39  Lr: 0.001875  Loss: -0.7877  Acc@1: 93.7500 (89.2857)  Acc@5: 100.0000 (98.8095)  time: 0.3299  data: 0.0003  max mem: 2362
Train: Epoch[4/5]  [ 30/313]  eta: 0:01:35  Lr: 0.001875  Loss: -0.5968  Acc@1: 87.5000 (88.1048)  Acc@5: 100.0000 (98.3871)  time: 0.3304  data: 0.0003  max mem: 2362
Train: Epoch[4/5]  [ 40/313]  eta: 0:01:31  Lr: 0.001875  Loss: -0.8804  Acc@1: 87.5000 (87.9573)  Acc@5: 100.0000 (98.4756)  time: 0.3295  data: 0.0003  max mem: 2362
Train: Epoch[4/5]  [ 50/313]  eta: 0:01:27  Lr: 0.001875  Loss: -0.5596  Acc@1: 87.5000 (88.1127)  Acc@5: 100.0000 (98.4069)  time: 0.3293  data: 0.0002  max mem: 2362
Train: Epoch[4/5]  [ 60/313]  eta: 0:01:24  Lr: 0.001875  Loss: -0.7301  Acc@1: 87.5000 (88.4221)  Acc@5: 100.0000 (98.4631)  time: 0.3305  data: 0.0006  max mem: 2362
Train: Epoch[4/5]  [ 70/313]  eta: 0:01:21  Lr: 0.001875  Loss: -0.6802  Acc@1: 87.5000 (88.2923)  Acc@5: 100.0000 (98.5915)  time: 0.3311  data: 0.0006  max mem: 2362
Train: Epoch[4/5]  [ 80/313]  eta: 0:01:17  Lr: 0.001875  Loss: -0.5997  Acc@1: 87.5000 (88.8889)  Acc@5: 100.0000 (98.6883)  time: 0.3306  data: 0.0005  max mem: 2362
Train: Epoch[4/5]  [ 90/313]  eta: 0:01:14  Lr: 0.001875  Loss: -0.8897  Acc@1: 87.5000 (88.4615)  Acc@5: 100.0000 (98.6951)  time: 0.3314  data: 0.0005  max mem: 2362
Train: Epoch[4/5]  [100/313]  eta: 0:01:10  Lr: 0.001875  Loss: -0.7492  Acc@1: 87.5000 (88.1807)  Acc@5: 100.0000 (98.7624)  time: 0.3321  data: 0.0002  max mem: 2362
Train: Epoch[4/5]  [110/313]  eta: 0:01:07  Lr: 0.001875  Loss: -0.5403  Acc@1: 87.5000 (88.2883)  Acc@5: 100.0000 (98.8739)  time: 0.3314  data: 0.0002  max mem: 2362
Train: Epoch[4/5]  [120/313]  eta: 0:01:04  Lr: 0.001875  Loss: -0.5148  Acc@1: 87.5000 (87.9132)  Acc@5: 100.0000 (98.6054)  time: 0.3319  data: 0.0010  max mem: 2362
Train: Epoch[4/5]  [130/313]  eta: 0:01:00  Lr: 0.001875  Loss: -0.8074  Acc@1: 87.5000 (87.9771)  Acc@5: 100.0000 (98.6641)  time: 0.3317  data: 0.0010  max mem: 2362
Train: Epoch[4/5]  [140/313]  eta: 0:00:57  Lr: 0.001875  Loss: -0.8208  Acc@1: 87.5000 (88.0319)  Acc@5: 100.0000 (98.6259)  time: 0.3303  data: 0.0003  max mem: 2362
Train: Epoch[4/5]  [150/313]  eta: 0:00:54  Lr: 0.001875  Loss: -0.2295  Acc@1: 87.5000 (87.7483)  Acc@5: 100.0000 (98.6341)  time: 0.3309  data: 0.0003  max mem: 2362
Train: Epoch[4/5]  [160/313]  eta: 0:00:50  Lr: 0.001875  Loss: -0.7608  Acc@1: 87.5000 (87.7717)  Acc@5: 100.0000 (98.6025)  time: 0.3319  data: 0.0005  max mem: 2362
Train: Epoch[4/5]  [170/313]  eta: 0:00:47  Lr: 0.001875  Loss: -0.6700  Acc@1: 93.7500 (88.0117)  Acc@5: 100.0000 (98.6477)  time: 0.3327  data: 0.0009  max mem: 2362
Train: Epoch[4/5]  [180/313]  eta: 0:00:44  Lr: 0.001875  Loss: -0.8476  Acc@1: 93.7500 (88.0870)  Acc@5: 100.0000 (98.6533)  time: 0.3325  data: 0.0007  max mem: 2362
Train: Epoch[4/5]  [190/313]  eta: 0:00:40  Lr: 0.001875  Loss: -0.7407  Acc@1: 93.7500 (88.2199)  Acc@5: 100.0000 (98.6911)  time: 0.3316  data: 0.0006  max mem: 2362
Train: Epoch[4/5]  [200/313]  eta: 0:00:37  Lr: 0.001875  Loss: -0.8480  Acc@1: 93.7500 (88.1841)  Acc@5: 100.0000 (98.7251)  time: 0.3318  data: 0.0006  max mem: 2362
Train: Epoch[4/5]  [210/313]  eta: 0:00:34  Lr: 0.001875  Loss: -0.8245  Acc@1: 93.7500 (88.3590)  Acc@5: 100.0000 (98.6671)  time: 0.3315  data: 0.0002  max mem: 2362
Train: Epoch[4/5]  [220/313]  eta: 0:00:30  Lr: 0.001875  Loss: -0.5367  Acc@1: 87.5000 (88.2636)  Acc@5: 100.0000 (98.6991)  time: 0.3323  data: 0.0016  max mem: 2362
Train: Epoch[4/5]  [230/313]  eta: 0:00:27  Lr: 0.001875  Loss: -0.7487  Acc@1: 87.5000 (88.3117)  Acc@5: 100.0000 (98.7013)  time: 0.3334  data: 0.0017  max mem: 2362
Train: Epoch[4/5]  [240/313]  eta: 0:00:24  Lr: 0.001875  Loss: -0.9655  Acc@1: 87.5000 (88.1743)  Acc@5: 100.0000 (98.7293)  time: 0.3333  data: 0.0003  max mem: 2362
Train: Epoch[4/5]  [250/313]  eta: 0:00:20  Lr: 0.001875  Loss: -0.9377  Acc@1: 87.5000 (88.0727)  Acc@5: 100.0000 (98.7301)  time: 0.3331  data: 0.0002  max mem: 2362
Train: Epoch[4/5]  [260/313]  eta: 0:00:17  Lr: 0.001875  Loss: -0.6703  Acc@1: 93.7500 (88.2663)  Acc@5: 100.0000 (98.7548)  time: 0.3325  data: 0.0002  max mem: 2362
Train: Epoch[4/5]  [270/313]  eta: 0:00:14  Lr: 0.001875  Loss: -0.6694  Acc@1: 87.5000 (88.1458)  Acc@5: 100.0000 (98.7546)  time: 0.3327  data: 0.0002  max mem: 2362
Train: Epoch[4/5]  [280/313]  eta: 0:00:10  Lr: 0.001875  Loss: -0.4418  Acc@1: 87.5000 (87.9448)  Acc@5: 100.0000 (98.7322)  time: 0.3331  data: 0.0007  max mem: 2362
Train: Epoch[4/5]  [290/313]  eta: 0:00:07  Lr: 0.001875  Loss: -0.8740  Acc@1: 87.5000 (87.8651)  Acc@5: 100.0000 (98.7543)  time: 0.3339  data: 0.0020  max mem: 2362
Train: Epoch[4/5]  [300/313]  eta: 0:00:04  Lr: 0.001875  Loss: -0.7571  Acc@1: 87.5000 (87.7907)  Acc@5: 100.0000 (98.7749)  time: 0.3329  data: 0.0016  max mem: 2362
Train: Epoch[4/5]  [310/313]  eta: 0:00:00  Lr: 0.001875  Loss: -0.9196  Acc@1: 87.5000 (87.6809)  Acc@5: 100.0000 (98.7741)  time: 0.3319  data: 0.0002  max mem: 2362
Train: Epoch[4/5]  [312/313]  eta: 0:00:00  Lr: 0.001875  Loss: -1.1580  Acc@1: 87.5000 (87.7400)  Acc@5: 100.0000 (98.7800)  time: 0.3235  data: 0.0002  max mem: 2362
Train: Epoch[4/5] Total time: 0:01:43 (0.3322 s / it)
Averaged stats: Lr: 0.001875  Loss: -1.1580  Acc@1: 87.5000 (87.7400)  Acc@5: 100.0000 (98.7800)
Train: Epoch[5/5]  [  0/313]  eta: 0:03:29  Lr: 0.001875  Loss: -0.9102  Acc@1: 93.7500 (93.7500)  Acc@5: 100.0000 (100.0000)  time: 0.6682  data: 0.3364  max mem: 2362
Train: Epoch[5/5]  [ 10/313]  eta: 0:01:49  Lr: 0.001875  Loss: -0.7450  Acc@1: 87.5000 (88.0682)  Acc@5: 100.0000 (99.4318)  time: 0.3617  data: 0.0307  max mem: 2362
Train: Epoch[5/5]  [ 20/313]  eta: 0:01:41  Lr: 0.001875  Loss: -0.4029  Acc@1: 87.5000 (88.6905)  Acc@5: 100.0000 (98.8095)  time: 0.3314  data: 0.0002  max mem: 2362
Train: Epoch[5/5]  [ 30/313]  eta: 0:01:36  Lr: 0.001875  Loss: -0.8685  Acc@1: 87.5000 (88.9113)  Acc@5: 100.0000 (99.1935)  time: 0.3316  data: 0.0002  max mem: 2362
Train: Epoch[5/5]  [ 40/313]  eta: 0:01:32  Lr: 0.001875  Loss: -0.8444  Acc@1: 87.5000 (87.9573)  Acc@5: 100.0000 (99.2378)  time: 0.3315  data: 0.0004  max mem: 2362
Train: Epoch[5/5]  [ 50/313]  eta: 0:01:28  Lr: 0.001875  Loss: -0.9625  Acc@1: 87.5000 (88.3578)  Acc@5: 100.0000 (99.1422)  time: 0.3313  data: 0.0004  max mem: 2362
Train: Epoch[5/5]  [ 60/313]  eta: 0:01:25  Lr: 0.001875  Loss: -0.8129  Acc@1: 87.5000 (88.3197)  Acc@5: 100.0000 (99.1803)  time: 0.3309  data: 0.0002  max mem: 2362
Train: Epoch[5/5]  [ 70/313]  eta: 0:01:21  Lr: 0.001875  Loss: -0.7672  Acc@1: 87.5000 (87.4120)  Acc@5: 100.0000 (99.0317)  time: 0.3320  data: 0.0002  max mem: 2362
Train: Epoch[5/5]  [ 80/313]  eta: 0:01:18  Lr: 0.001875  Loss: -0.8992  Acc@1: 87.5000 (88.2716)  Acc@5: 100.0000 (98.9969)  time: 0.3335  data: 0.0003  max mem: 2362
Train: Epoch[5/5]  [ 90/313]  eta: 0:01:14  Lr: 0.001875  Loss: -0.7539  Acc@1: 93.7500 (88.2555)  Acc@5: 100.0000 (99.1071)  time: 0.3327  data: 0.0003  max mem: 2362
Train: Epoch[5/5]  [100/313]  eta: 0:01:11  Lr: 0.001875  Loss: -0.9470  Acc@1: 87.5000 (87.9332)  Acc@5: 100.0000 (99.1337)  time: 0.3317  data: 0.0002  max mem: 2362
Train: Epoch[5/5]  [110/313]  eta: 0:01:07  Lr: 0.001875  Loss: -0.8110  Acc@1: 87.5000 (88.0068)  Acc@5: 100.0000 (99.0991)  time: 0.3321  data: 0.0003  max mem: 2362
Train: Epoch[5/5]  [120/313]  eta: 0:01:04  Lr: 0.001875  Loss: -0.6745  Acc@1: 87.5000 (88.1715)  Acc@5: 100.0000 (99.0702)  time: 0.3321  data: 0.0003  max mem: 2362
Train: Epoch[5/5]  [130/313]  eta: 0:01:01  Lr: 0.001875  Loss: -0.7612  Acc@1: 87.5000 (87.7863)  Acc@5: 100.0000 (99.0935)  time: 0.3316  data: 0.0003  max mem: 2362
Train: Epoch[5/5]  [140/313]  eta: 0:00:57  Lr: 0.001875  Loss: -0.7556  Acc@1: 87.5000 (87.9433)  Acc@5: 100.0000 (99.1135)  time: 0.3318  data: 0.0003  max mem: 2362
Train: Epoch[5/5]  [150/313]  eta: 0:00:54  Lr: 0.001875  Loss: -0.8325  Acc@1: 87.5000 (87.9967)  Acc@5: 100.0000 (99.1308)  time: 0.3323  data: 0.0003  max mem: 2362
Train: Epoch[5/5]  [160/313]  eta: 0:00:51  Lr: 0.001875  Loss: -0.3303  Acc@1: 87.5000 (88.0047)  Acc@5: 100.0000 (99.1460)  time: 0.3329  data: 0.0003  max mem: 2362
Train: Epoch[5/5]  [170/313]  eta: 0:00:47  Lr: 0.001875  Loss: -1.0263  Acc@1: 87.5000 (88.1213)  Acc@5: 100.0000 (99.1228)  time: 0.3322  data: 0.0002  max mem: 2362
Train: Epoch[5/5]  [180/313]  eta: 0:00:44  Lr: 0.001875  Loss: -0.7630  Acc@1: 87.5000 (88.0525)  Acc@5: 100.0000 (99.0677)  time: 0.3319  data: 0.0010  max mem: 2362
Train: Epoch[5/5]  [190/313]  eta: 0:00:41  Lr: 0.001875  Loss: -0.9728  Acc@1: 87.5000 (88.1217)  Acc@5: 100.0000 (99.0510)  time: 0.3332  data: 0.0013  max mem: 2362
Train: Epoch[5/5]  [200/313]  eta: 0:00:37  Lr: 0.001875  Loss: -1.0925  Acc@1: 93.7500 (88.2463)  Acc@5: 100.0000 (99.0672)  time: 0.3331  data: 0.0006  max mem: 2362
Train: Epoch[5/5]  [210/313]  eta: 0:00:34  Lr: 0.001875  Loss: -0.8819  Acc@1: 93.7500 (88.3294)  Acc@5: 100.0000 (99.0818)  time: 0.3321  data: 0.0002  max mem: 2362
Train: Epoch[5/5]  [220/313]  eta: 0:00:31  Lr: 0.001875  Loss: -1.0895  Acc@1: 87.5000 (88.2919)  Acc@5: 100.0000 (99.0667)  time: 0.3315  data: 0.0004  max mem: 2362
Train: Epoch[5/5]  [230/313]  eta: 0:00:27  Lr: 0.001875  Loss: -0.7358  Acc@1: 87.5000 (88.3929)  Acc@5: 100.0000 (99.1071)  time: 0.3326  data: 0.0004  max mem: 2362
Train: Epoch[5/5]  [240/313]  eta: 0:00:24  Lr: 0.001875  Loss: -0.7943  Acc@1: 93.7500 (88.4336)  Acc@5: 100.0000 (99.0664)  time: 0.3329  data: 0.0003  max mem: 2362
Train: Epoch[5/5]  [250/313]  eta: 0:00:21  Lr: 0.001875  Loss: -0.7407  Acc@1: 87.5000 (88.4711)  Acc@5: 100.0000 (99.1036)  time: 0.3328  data: 0.0011  max mem: 2362
Train: Epoch[5/5]  [260/313]  eta: 0:00:17  Lr: 0.001875  Loss: -0.8149  Acc@1: 93.7500 (88.6015)  Acc@5: 100.0000 (99.1379)  time: 0.3319  data: 0.0011  max mem: 2362
Train: Epoch[5/5]  [270/313]  eta: 0:00:14  Lr: 0.001875  Loss: -0.7750  Acc@1: 87.5000 (88.4225)  Acc@5: 100.0000 (99.1006)  time: 0.3308  data: 0.0002  max mem: 2362
Train: Epoch[5/5]  [280/313]  eta: 0:00:10  Lr: 0.001875  Loss: -1.0372  Acc@1: 87.5000 (88.5454)  Acc@5: 100.0000 (98.9991)  time: 0.3313  data: 0.0002  max mem: 2362
Train: Epoch[5/5]  [290/313]  eta: 0:00:07  Lr: 0.001875  Loss: -1.0160  Acc@1: 87.5000 (88.4450)  Acc@5: 100.0000 (99.0120)  time: 0.3318  data: 0.0003  max mem: 2362
Train: Epoch[5/5]  [300/313]  eta: 0:00:04  Lr: 0.001875  Loss: -0.8819  Acc@1: 87.5000 (88.4551)  Acc@5: 100.0000 (99.0241)  time: 0.3308  data: 0.0003  max mem: 2362
Train: Epoch[5/5]  [310/313]  eta: 0:00:00  Lr: 0.001875  Loss: -1.0817  Acc@1: 87.5000 (88.5048)  Acc@5: 100.0000 (99.0555)  time: 0.3299  data: 0.0002  max mem: 2362
Train: Epoch[5/5]  [312/313]  eta: 0:00:00  Lr: 0.001875  Loss: -0.8237  Acc@1: 87.5000 (88.4400)  Acc@5: 100.0000 (99.0600)  time: 0.3218  data: 0.0002  max mem: 2362
Train: Epoch[5/5] Total time: 0:01:44 (0.3327 s / it)
Averaged stats: Lr: 0.001875  Loss: -0.8237  Acc@1: 87.5000 (88.4400)  Acc@5: 100.0000 (99.0600)
Test: [Task 1]  [ 0/63]  eta: 0:00:28  Loss: 0.7315 (0.7315)  Acc@1: 81.2500 (81.2500)  Acc@5: 100.0000 (100.0000)  time: 0.4498  data: 0.2393  max mem: 2362
Test: [Task 1]  [10/63]  eta: 0:00:12  Loss: 0.5168 (0.5096)  Acc@1: 93.7500 (89.7727)  Acc@5: 100.0000 (99.4318)  time: 0.2303  data: 0.0220  max mem: 2362
Test: [Task 1]  [20/63]  eta: 0:00:09  Loss: 0.5168 (0.5702)  Acc@1: 87.5000 (87.2024)  Acc@5: 100.0000 (99.1071)  time: 0.2088  data: 0.0006  max mem: 2362
Test: [Task 1]  [30/63]  eta: 0:00:07  Loss: 0.4407 (0.5385)  Acc@1: 87.5000 (88.5081)  Acc@5: 100.0000 (98.9919)  time: 0.2079  data: 0.0005  max mem: 2362
Test: [Task 1]  [40/63]  eta: 0:00:04  Loss: 0.4368 (0.5199)  Acc@1: 93.7500 (89.1768)  Acc@5: 100.0000 (99.2378)  time: 0.2073  data: 0.0003  max mem: 2362
Test: [Task 1]  [50/63]  eta: 0:00:02  Loss: 0.4711 (0.5047)  Acc@1: 93.7500 (89.7059)  Acc@5: 100.0000 (99.1422)  time: 0.2075  data: 0.0003  max mem: 2362
Test: [Task 1]  [60/63]  eta: 0:00:00  Loss: 0.4788 (0.5017)  Acc@1: 93.7500 (89.7541)  Acc@5: 100.0000 (98.8730)  time: 0.2070  data: 0.0002  max mem: 2362
Test: [Task 1]  [62/63]  eta: 0:00:00  Loss: 0.4711 (0.5013)  Acc@1: 93.7500 (90.0000)  Acc@5: 100.0000 (98.9000)  time: 0.2022  data: 0.0002  max mem: 2362
Test: [Task 1] Total time: 0:00:13 (0.2114 s / it)
* Acc@1 90.000 Acc@5 98.900 loss 0.501
Test: [Task 2]  [ 0/63]  eta: 0:00:27  Loss: 0.8221 (0.8221)  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (100.0000)  time: 0.4353  data: 0.2272  max mem: 2362
Test: [Task 2]  [10/63]  eta: 0:00:12  Loss: 0.6361 (0.7188)  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (98.2955)  time: 0.2271  data: 0.0208  max mem: 2362
Test: [Task 2]  [20/63]  eta: 0:00:09  Loss: 0.7050 (0.7880)  Acc@1: 81.2500 (84.8214)  Acc@5: 100.0000 (97.9167)  time: 0.2062  data: 0.0002  max mem: 2362
Test: [Task 2]  [30/63]  eta: 0:00:07  Loss: 0.8142 (0.7646)  Acc@1: 81.2500 (85.4839)  Acc@5: 100.0000 (97.5806)  time: 0.2061  data: 0.0003  max mem: 2362
Test: [Task 2]  [40/63]  eta: 0:00:04  Loss: 0.7020 (0.7505)  Acc@1: 87.5000 (85.8232)  Acc@5: 100.0000 (97.7134)  time: 0.2058  data: 0.0002  max mem: 2362
Test: [Task 2]  [50/63]  eta: 0:00:02  Loss: 0.6944 (0.7405)  Acc@1: 87.5000 (85.7843)  Acc@5: 100.0000 (97.5490)  time: 0.2058  data: 0.0003  max mem: 2362
Test: [Task 2]  [60/63]  eta: 0:00:00  Loss: 0.5675 (0.7092)  Acc@1: 87.5000 (85.9631)  Acc@5: 100.0000 (97.8484)  time: 0.2061  data: 0.0002  max mem: 2362
Test: [Task 2]  [62/63]  eta: 0:00:00  Loss: 0.5599 (0.6997)  Acc@1: 87.5000 (86.1000)  Acc@5: 100.0000 (97.9000)  time: 0.2011  data: 0.0002  max mem: 2362
Test: [Task 2] Total time: 0:00:13 (0.2100 s / it)
* Acc@1 86.100 Acc@5 97.900 loss 0.700
Test: [Task 3]  [ 0/63]  eta: 0:00:28  Loss: 0.3605 (0.3605)  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (100.0000)  time: 0.4472  data: 0.2397  max mem: 2362
Test: [Task 3]  [10/63]  eta: 0:00:12  Loss: 0.5330 (0.5709)  Acc@1: 87.5000 (86.3636)  Acc@5: 100.0000 (98.2955)  time: 0.2278  data: 0.0220  max mem: 2362
Test: [Task 3]  [20/63]  eta: 0:00:09  Loss: 0.6116 (0.5851)  Acc@1: 81.2500 (85.1190)  Acc@5: 100.0000 (98.2143)  time: 0.2060  data: 0.0002  max mem: 2362
Test: [Task 3]  [30/63]  eta: 0:00:07  Loss: 0.6116 (0.5796)  Acc@1: 81.2500 (85.2823)  Acc@5: 100.0000 (98.5887)  time: 0.2057  data: 0.0002  max mem: 2362
Test: [Task 3]  [40/63]  eta: 0:00:04  Loss: 0.4929 (0.5698)  Acc@1: 87.5000 (86.5854)  Acc@5: 100.0000 (98.9329)  time: 0.2053  data: 0.0002  max mem: 2362
Test: [Task 3]  [50/63]  eta: 0:00:02  Loss: 0.5452 (0.5714)  Acc@1: 87.5000 (86.8873)  Acc@5: 100.0000 (98.6520)  time: 0.2056  data: 0.0002  max mem: 2362
Test: [Task 3]  [60/63]  eta: 0:00:00  Loss: 0.5530 (0.5738)  Acc@1: 87.5000 (86.8852)  Acc@5: 100.0000 (98.8730)  time: 0.2054  data: 0.0002  max mem: 2362
Test: [Task 3]  [62/63]  eta: 0:00:00  Loss: 0.5530 (0.5758)  Acc@1: 87.5000 (86.6000)  Acc@5: 100.0000 (98.9000)  time: 0.2005  data: 0.0002  max mem: 2362
Test: [Task 3] Total time: 0:00:13 (0.2089 s / it)
* Acc@1 86.600 Acc@5 98.900 loss 0.576
Test: [Task 4]  [ 0/63]  eta: 0:00:30  Loss: 0.9927 (0.9927)  Acc@1: 87.5000 (87.5000)  Acc@5: 93.7500 (93.7500)  time: 0.4835  data: 0.2756  max mem: 2362
Test: [Task 4]  [10/63]  eta: 0:00:12  Loss: 0.6665 (0.6510)  Acc@1: 81.2500 (84.6591)  Acc@5: 100.0000 (98.2955)  time: 0.2309  data: 0.0253  max mem: 2362
Test: [Task 4]  [20/63]  eta: 0:00:09  Loss: 0.5595 (0.6436)  Acc@1: 81.2500 (83.9286)  Acc@5: 100.0000 (97.9167)  time: 0.2059  data: 0.0002  max mem: 2362
Test: [Task 4]  [30/63]  eta: 0:00:07  Loss: 0.5595 (0.6221)  Acc@1: 87.5000 (84.4758)  Acc@5: 100.0000 (97.9839)  time: 0.2056  data: 0.0002  max mem: 2362
Test: [Task 4]  [40/63]  eta: 0:00:04  Loss: 0.3706 (0.5806)  Acc@1: 87.5000 (85.8232)  Acc@5: 100.0000 (98.1707)  time: 0.2058  data: 0.0004  max mem: 2362
Test: [Task 4]  [50/63]  eta: 0:00:02  Loss: 0.5056 (0.5977)  Acc@1: 87.5000 (85.7843)  Acc@5: 100.0000 (98.0392)  time: 0.2064  data: 0.0004  max mem: 2362
Test: [Task 4]  [60/63]  eta: 0:00:00  Loss: 0.5722 (0.6281)  Acc@1: 87.5000 (85.2459)  Acc@5: 100.0000 (97.5410)  time: 0.2063  data: 0.0003  max mem: 2362
Test: [Task 4]  [62/63]  eta: 0:00:00  Loss: 0.5631 (0.6256)  Acc@1: 87.5000 (85.5000)  Acc@5: 100.0000 (97.6000)  time: 0.2015  data: 0.0002  max mem: 2362
Test: [Task 4] Total time: 0:00:13 (0.2100 s / it)
* Acc@1 85.500 Acc@5 97.600 loss 0.626
Test: [Task 5]  [ 0/63]  eta: 0:00:32  Loss: 0.2222 (0.2222)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)  time: 0.5157  data: 0.3067  max mem: 2362
Test: [Task 5]  [10/63]  eta: 0:00:12  Loss: 0.4531 (0.5614)  Acc@1: 93.7500 (90.3409)  Acc@5: 100.0000 (98.2955)  time: 0.2345  data: 0.0282  max mem: 2362
Test: [Task 5]  [20/63]  eta: 0:00:09  Loss: 0.4531 (0.5270)  Acc@1: 93.7500 (90.7738)  Acc@5: 100.0000 (98.5119)  time: 0.2061  data: 0.0003  max mem: 2362
Test: [Task 5]  [30/63]  eta: 0:00:07  Loss: 0.4409 (0.5149)  Acc@1: 93.7500 (91.1290)  Acc@5: 100.0000 (98.5887)  time: 0.2065  data: 0.0003  max mem: 2362
Test: [Task 5]  [40/63]  eta: 0:00:04  Loss: 0.4028 (0.4836)  Acc@1: 93.7500 (92.2256)  Acc@5: 100.0000 (98.7805)  time: 0.2065  data: 0.0002  max mem: 2362
Test: [Task 5]  [50/63]  eta: 0:00:02  Loss: 0.4452 (0.4882)  Acc@1: 93.7500 (92.4020)  Acc@5: 100.0000 (98.7745)  time: 0.2062  data: 0.0003  max mem: 2362
Test: [Task 5]  [60/63]  eta: 0:00:00  Loss: 0.4986 (0.5054)  Acc@1: 87.5000 (91.4959)  Acc@5: 100.0000 (98.5656)  time: 0.2060  data: 0.0002  max mem: 2362
Test: [Task 5]  [62/63]  eta: 0:00:00  Loss: 0.5027 (0.5232)  Acc@1: 87.5000 (91.1000)  Acc@5: 100.0000 (98.4000)  time: 0.2012  data: 0.0002  max mem: 2362
Test: [Task 5] Total time: 0:00:13 (0.2106 s / it)
* Acc@1 91.100 Acc@5 98.400 loss 0.523
{0: {0: 424, 1: 424, 2: 424, 3: 424, 4: 424, 5: 160, 6: 160, 7: 160, 8: 160, 9: 160, 10: 80, 11: 80, 12: 80, 13: 80, 14: 80, 15: 64, 16: 64, 17: 64, 18: 64, 19: 64, 20: 272, 21: 272, 22: 272, 23: 272, 24: 272, 25: 0, 26: 0, 27: 0, 28: 0, 29: 0, 30: 0, 31: 0, 32: 0, 33: 0, 34: 0, 35: 0, 36: 0, 37: 0, 38: 0, 39: 0, 40: 0, 41: 0, 42: 0, 43: 0, 44: 0, 45: 0, 46: 0, 47: 0, 48: 0, 49: 0}, 1: {0: 632, 1: 632, 2: 632, 3: 632, 4: 632, 5: 48, 6: 48, 7: 48, 8: 48, 9: 48, 10: 0, 11: 0, 12: 0, 13: 0, 14: 0, 15: 320, 16: 320, 17: 320, 18: 320, 19: 320, 20: 0, 21: 0, 22: 0, 23: 0, 24: 0, 25: 0, 26: 0, 27: 0, 28: 0, 29: 0, 30: 0, 31: 0, 32: 0, 33: 0, 34: 0, 35: 0, 36: 0, 37: 0, 38: 0, 39: 0, 40: 0, 41: 0, 42: 0, 43: 0, 44: 0, 45: 0, 46: 0, 47: 0, 48: 0, 49: 0}, 2: {0: 328, 1: 328, 2: 328, 3: 328, 4: 328, 5: 256, 6: 256, 7: 256, 8: 256, 9: 256, 10: 320, 11: 320, 12: 320, 13: 320, 14: 320, 15: 32, 16: 32, 17: 32, 18: 32, 19: 32, 20: 64, 21: 64, 22: 64, 23: 64, 24: 64, 25: 0, 26: 0, 27: 0, 28: 0, 29: 0, 30: 0, 31: 0, 32: 0, 33: 0, 34: 0, 35: 0, 36: 0, 37: 0, 38: 0, 39: 0, 40: 0, 41: 0, 42: 0, 43: 0, 44: 0, 45: 0, 46: 0, 47: 0, 48: 0, 49: 0}, 3: {0: 80, 1: 80, 2: 80, 3: 80, 4: 80, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0, 10: 0, 11: 0, 12: 0, 13: 0, 14: 0, 15: 0, 16: 0, 17: 0, 18: 0, 19: 0, 20: 920, 21: 920, 22: 920, 23: 920, 24: 920, 25: 0, 26: 0, 27: 0, 28: 0, 29: 0, 30: 0, 31: 0, 32: 0, 33: 0, 34: 0, 35: 0, 36: 0, 37: 0, 38: 0, 39: 0, 40: 0, 41: 0, 42: 0, 43: 0, 44: 0, 45: 0, 46: 0, 47: 0, 48: 0, 49: 0}, 4: {0: 840, 1: 840, 2: 840, 3: 840, 4: 840, 5: 128, 6: 128, 7: 128, 8: 128, 9: 128, 10: 16, 11: 16, 12: 16, 13: 16, 14: 16, 15: 16, 16: 16, 17: 16, 18: 16, 19: 16, 20: 0, 21: 0, 22: 0, 23: 0, 24: 0, 25: 0, 26: 0, 27: 0, 28: 0, 29: 0, 30: 0, 31: 0, 32: 0, 33: 0, 34: 0, 35: 0, 36: 0, 37: 0, 38: 0, 39: 0, 40: 0, 41: 0, 42: 0, 43: 0, 44: 0, 45: 0, 46: 0, 47: 0, 48: 0, 49: 0}}
[Average accuracy till task5]	Acc@1: 87.8600	Acc@5: 98.3400	Loss: 0.5851	Forgetting: 5.8500	Backward: -5.8500
