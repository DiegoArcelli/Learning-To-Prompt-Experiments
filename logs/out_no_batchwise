/storagenfs/d.arcelli/Prompting-Based-CL-Methods-Experiments/.env/lib/python3.9/site-packages/torchvision/transforms/transforms.py:329: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.
  warnings.warn(
Namespace(subparser_name='cifar100_l2p', train_type='l2p', batch_size=16, epochs=5, model='vit_base_patch16_224', input_size=224, pretrained=True, drop=0.0, drop_path=0.0, opt='adam', opt_eps=1e-08, opt_betas=(0.9, 0.999), clip_grad=1.0, momentum=0.9, weight_decay=0.0, reinit_optimizer=True, sched='constant', lr=0.03, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, unscale_lr=True, color_jitter=None, aa=None, smoothing=0.1, train_interpolation='bicubic', reprob=0.0, remode='pixel', recount=1, data_path='./local_datasets/', dataset='Split-CIFAR100', shuffle=False, output_dir='./output_sel_pen', device='cuda', seed=42, eval=False, num_workers=4, pin_mem=True, world_size=1, dist_url='env://', num_tasks=10, train_mask=True, task_inc=False, prompt_pool=True, size=10, length=5, top_k=5, initializer='uniform', prompt_key=True, prompt_key_init='uniform', use_prompt_mask=False, shared_prompt_pool=False, shared_prompt_key=False, batchwise_prompt=False, embedding_key='cls', predefined_key='', pull_constraint=True, pull_constraint_coeff=0.1, global_pool='token', head_type='prompt', freeze=['blocks', 'patch_embed', 'cls_token', 'norm', 'pos_embed'], freeze_head=False, print_freq=10, eval_task_id=False, frequency_penalization=False, class_incremental=False, init_class_prompts=False, task_incremental=False, init_tasks_prompts=False, prompts_per_task=5, prompts_per_class=1, freeze_keys=False)
Not using distributed mode
Files already downloaded and verified
Files already downloaded and verified
Creating original model: vit_base_patch16_224
Creating model: vit_base_patch16_224
number of params: 122980
Start training for 5 epochs
Train: Epoch[1/5]  [  0/313]  eta: 0:09:17  Lr: 0.001875  Loss: 2.3120  Acc@1: 18.7500 (18.7500)  Acc@5: 43.7500 (43.7500)  time: 1.7807  data: 0.3660  max mem: 2354
Train: Epoch[1/5]  [ 10/313]  eta: 0:02:19  Lr: 0.001875  Loss: 2.0258  Acc@1: 43.7500 (42.0455)  Acc@5: 75.0000 (73.8636)  time: 0.4614  data: 0.0336  max mem: 2356
Train: Epoch[1/5]  [ 20/313]  eta: 0:01:56  Lr: 0.001875  Loss: 1.8788  Acc@1: 56.2500 (52.0833)  Acc@5: 87.5000 (80.0595)  time: 0.3299  data: 0.0004  max mem: 2356
Train: Epoch[1/5]  [ 30/313]  eta: 0:01:46  Lr: 0.001875  Loss: 1.7244  Acc@1: 62.5000 (56.6532)  Acc@5: 93.7500 (84.4758)  time: 0.3307  data: 0.0014  max mem: 2356
Train: Epoch[1/5]  [ 40/313]  eta: 0:01:39  Lr: 0.001875  Loss: 1.3361  Acc@1: 68.7500 (60.8232)  Acc@5: 93.7500 (87.0427)  time: 0.3305  data: 0.0014  max mem: 2356
Train: Epoch[1/5]  [ 50/313]  eta: 0:01:34  Lr: 0.001875  Loss: 1.2825  Acc@1: 75.0000 (62.9902)  Acc@5: 93.7500 (88.4804)  time: 0.3325  data: 0.0004  max mem: 2356
Train: Epoch[1/5]  [ 60/313]  eta: 0:01:29  Lr: 0.001875  Loss: 1.3730  Acc@1: 68.7500 (63.8320)  Acc@5: 93.7500 (89.1393)  time: 0.3315  data: 0.0004  max mem: 2356
Train: Epoch[1/5]  [ 70/313]  eta: 0:01:25  Lr: 0.001875  Loss: 1.1220  Acc@1: 68.7500 (65.4930)  Acc@5: 93.7500 (89.8768)  time: 0.3286  data: 0.0003  max mem: 2356
Train: Epoch[1/5]  [ 80/313]  eta: 0:01:21  Lr: 0.001875  Loss: 0.9963  Acc@1: 75.0000 (67.1296)  Acc@5: 93.7500 (90.6636)  time: 0.3286  data: 0.0004  max mem: 2356
Train: Epoch[1/5]  [ 90/313]  eta: 0:01:17  Lr: 0.001875  Loss: 0.9191  Acc@1: 75.0000 (67.9258)  Acc@5: 93.7500 (91.2775)  time: 0.3287  data: 0.0007  max mem: 2356
Train: Epoch[1/5]  [100/313]  eta: 0:01:13  Lr: 0.001875  Loss: 0.9628  Acc@1: 81.2500 (69.4926)  Acc@5: 93.7500 (91.8317)  time: 0.3293  data: 0.0006  max mem: 2356
Train: Epoch[1/5]  [110/313]  eta: 0:01:09  Lr: 0.001875  Loss: 1.1825  Acc@1: 81.2500 (70.1014)  Acc@5: 93.7500 (92.1171)  time: 0.3286  data: 0.0003  max mem: 2356
Train: Epoch[1/5]  [120/313]  eta: 0:01:05  Lr: 0.001875  Loss: 0.9458  Acc@1: 75.0000 (70.6612)  Acc@5: 100.0000 (92.6653)  time: 0.3282  data: 0.0003  max mem: 2356
Train: Epoch[1/5]  [130/313]  eta: 0:01:02  Lr: 0.001875  Loss: 0.7219  Acc@1: 75.0000 (71.2309)  Acc@5: 100.0000 (93.1298)  time: 0.3305  data: 0.0015  max mem: 2356
Train: Epoch[1/5]  [140/313]  eta: 0:00:58  Lr: 0.001875  Loss: 0.3485  Acc@1: 81.2500 (71.9415)  Acc@5: 100.0000 (93.4840)  time: 0.3320  data: 0.0016  max mem: 2356
Train: Epoch[1/5]  [150/313]  eta: 0:00:55  Lr: 0.001875  Loss: 0.5523  Acc@1: 81.2500 (72.6407)  Acc@5: 100.0000 (93.7086)  time: 0.3330  data: 0.0008  max mem: 2356
Train: Epoch[1/5]  [160/313]  eta: 0:00:51  Lr: 0.001875  Loss: 0.6932  Acc@1: 81.2500 (73.0590)  Acc@5: 100.0000 (93.9829)  time: 0.3345  data: 0.0008  max mem: 2356
Train: Epoch[1/5]  [170/313]  eta: 0:00:48  Lr: 0.001875  Loss: 0.7098  Acc@1: 81.2500 (73.7573)  Acc@5: 100.0000 (94.2251)  time: 0.3387  data: 0.0016  max mem: 2356
Train: Epoch[1/5]  [180/313]  eta: 0:00:45  Lr: 0.001875  Loss: 0.8305  Acc@1: 81.2500 (73.8950)  Acc@5: 100.0000 (94.3370)  time: 0.3409  data: 0.0044  max mem: 2356
Train: Epoch[1/5]  [190/313]  eta: 0:00:41  Lr: 0.001875  Loss: 0.8233  Acc@1: 81.2500 (74.4764)  Acc@5: 100.0000 (94.4699)  time: 0.3366  data: 0.0038  max mem: 2356
Train: Epoch[1/5]  [200/313]  eta: 0:00:38  Lr: 0.001875  Loss: 0.8268  Acc@1: 81.2500 (74.7201)  Acc@5: 93.7500 (94.4030)  time: 0.3338  data: 0.0018  max mem: 2356
Train: Epoch[1/5]  [210/313]  eta: 0:00:34  Lr: 0.001875  Loss: 0.6556  Acc@1: 81.2500 (74.9111)  Acc@5: 100.0000 (94.6090)  time: 0.3341  data: 0.0014  max mem: 2356
Train: Epoch[1/5]  [220/313]  eta: 0:00:31  Lr: 0.001875  Loss: 0.5738  Acc@1: 81.2500 (75.2545)  Acc@5: 100.0000 (94.7681)  time: 0.3383  data: 0.0007  max mem: 2356
Train: Epoch[1/5]  [230/313]  eta: 0:00:28  Lr: 0.001875  Loss: 0.8046  Acc@1: 81.2500 (75.4870)  Acc@5: 100.0000 (94.9946)  time: 0.3396  data: 0.0006  max mem: 2356
Train: Epoch[1/5]  [240/313]  eta: 0:00:24  Lr: 0.001875  Loss: 0.5042  Acc@1: 87.5000 (76.0633)  Acc@5: 100.0000 (95.1245)  time: 0.3359  data: 0.0009  max mem: 2356
Train: Epoch[1/5]  [250/313]  eta: 0:00:21  Lr: 0.001875  Loss: 0.2275  Acc@1: 81.2500 (76.1952)  Acc@5: 100.0000 (95.2191)  time: 0.3352  data: 0.0013  max mem: 2356
Train: Epoch[1/5]  [260/313]  eta: 0:00:17  Lr: 0.001875  Loss: 0.2905  Acc@1: 81.2500 (76.5086)  Acc@5: 100.0000 (95.3305)  time: 0.3390  data: 0.0009  max mem: 2356
Train: Epoch[1/5]  [270/313]  eta: 0:00:14  Lr: 0.001875  Loss: 0.0850  Acc@1: 81.2500 (76.6605)  Acc@5: 100.0000 (95.4566)  time: 0.3416  data: 0.0006  max mem: 2356
Train: Epoch[1/5]  [280/313]  eta: 0:00:11  Lr: 0.001875  Loss: 0.1794  Acc@1: 81.2500 (77.0240)  Acc@5: 100.0000 (95.6183)  time: 0.3395  data: 0.0011  max mem: 2356
Train: Epoch[1/5]  [290/313]  eta: 0:00:07  Lr: 0.001875  Loss: 0.2898  Acc@1: 81.2500 (77.1263)  Acc@5: 100.0000 (95.6186)  time: 0.3374  data: 0.0020  max mem: 2356
Train: Epoch[1/5]  [300/313]  eta: 0:00:04  Lr: 0.001875  Loss: 0.7251  Acc@1: 81.2500 (77.4086)  Acc@5: 100.0000 (95.7018)  time: 0.3385  data: 0.0016  max mem: 2356
Train: Epoch[1/5]  [310/313]  eta: 0:00:01  Lr: 0.001875  Loss: 0.4509  Acc@1: 81.2500 (77.4920)  Acc@5: 100.0000 (95.7395)  time: 0.3379  data: 0.0005  max mem: 2356
Train: Epoch[1/5]  [312/313]  eta: 0:00:00  Lr: 0.001875  Loss: 0.7918  Acc@1: 81.2500 (77.4200)  Acc@5: 100.0000 (95.7400)  time: 0.3341  data: 0.0004  max mem: 2356
Train: Epoch[1/5] Total time: 0:01:46 (0.3388 s / it)
{0: {0: 3620, 1: 0, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}, 1: {0: 770, 1: 0, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}, 2: {0: 1482, 1: 0, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}, 3: {0: 2436, 1: 0, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}, 4: {0: 3287, 1: 0, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}, 5: {0: 4220, 1: 0, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}, 6: {0: 2236, 1: 0, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}, 7: {0: 737, 1: 0, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}, 8: {0: 4393, 1: 0, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}, 9: {0: 1819, 1: 0, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}}
Averaged stats: Lr: 0.001875  Loss: 0.7918  Acc@1: 81.2500 (77.4200)  Acc@5: 100.0000 (95.7400)
Train: Epoch[2/5]  [  0/313]  eta: 0:03:18  Lr: 0.001875  Loss: 0.2973  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (100.0000)  time: 0.6331  data: 0.2998  max mem: 2356
Train: Epoch[2/5]  [ 10/313]  eta: 0:01:48  Lr: 0.001875  Loss: 0.6940  Acc@1: 75.0000 (75.0000)  Acc@5: 100.0000 (96.5909)  time: 0.3593  data: 0.0276  max mem: 2356
Train: Epoch[2/5]  [ 20/313]  eta: 0:01:41  Lr: 0.001875  Loss: 0.2778  Acc@1: 81.2500 (80.6548)  Acc@5: 100.0000 (97.0238)  time: 0.3313  data: 0.0004  max mem: 2356
Train: Epoch[2/5]  [ 30/313]  eta: 0:01:36  Lr: 0.001875  Loss: 0.4441  Acc@1: 87.5000 (81.6532)  Acc@5: 100.0000 (97.1774)  time: 0.3308  data: 0.0004  max mem: 2356
Train: Epoch[2/5]  [ 40/313]  eta: 0:01:32  Lr: 0.001875  Loss: 0.3979  Acc@1: 87.5000 (83.2317)  Acc@5: 100.0000 (97.2561)  time: 0.3317  data: 0.0003  max mem: 2356
Train: Epoch[2/5]  [ 50/313]  eta: 0:01:28  Lr: 0.001875  Loss: 0.0996  Acc@1: 87.5000 (83.7010)  Acc@5: 100.0000 (97.4265)  time: 0.3320  data: 0.0004  max mem: 2356
Train: Epoch[2/5]  [ 60/313]  eta: 0:01:25  Lr: 0.001875  Loss: 0.2384  Acc@1: 87.5000 (84.2213)  Acc@5: 100.0000 (97.3361)  time: 0.3315  data: 0.0005  max mem: 2356
Train: Epoch[2/5]  [ 70/313]  eta: 0:01:21  Lr: 0.001875  Loss: 0.6077  Acc@1: 87.5000 (83.9789)  Acc@5: 100.0000 (97.6232)  time: 0.3317  data: 0.0008  max mem: 2356
Train: Epoch[2/5]  [ 80/313]  eta: 0:01:18  Lr: 0.001875  Loss: 0.1728  Acc@1: 81.2500 (83.7191)  Acc@5: 100.0000 (97.6852)  time: 0.3322  data: 0.0007  max mem: 2356
Train: Epoch[2/5]  [ 90/313]  eta: 0:01:14  Lr: 0.001875  Loss: 0.3257  Acc@1: 81.2500 (83.7225)  Acc@5: 100.0000 (97.6648)  time: 0.3316  data: 0.0005  max mem: 2356
Train: Epoch[2/5]  [100/313]  eta: 0:01:11  Lr: 0.001875  Loss: 0.1695  Acc@1: 87.5000 (83.8490)  Acc@5: 100.0000 (97.7723)  time: 0.3318  data: 0.0004  max mem: 2356
Train: Epoch[2/5]  [110/313]  eta: 0:01:07  Lr: 0.001875  Loss: 0.3789  Acc@1: 87.5000 (84.0090)  Acc@5: 100.0000 (97.8604)  time: 0.3341  data: 0.0003  max mem: 2356
Train: Epoch[2/5]  [120/313]  eta: 0:01:04  Lr: 0.001875  Loss: 0.3400  Acc@1: 87.5000 (83.8843)  Acc@5: 100.0000 (97.8306)  time: 0.3335  data: 0.0011  max mem: 2356
Train: Epoch[2/5]  [130/313]  eta: 0:01:01  Lr: 0.001875  Loss: -0.0044  Acc@1: 87.5000 (84.1603)  Acc@5: 100.0000 (97.7099)  time: 0.3307  data: 0.0017  max mem: 2356
Train: Epoch[2/5]  [140/313]  eta: 0:00:57  Lr: 0.001875  Loss: 0.6662  Acc@1: 87.5000 (83.9982)  Acc@5: 93.7500 (97.5621)  time: 0.3305  data: 0.0009  max mem: 2356
Train: Epoch[2/5]  [150/313]  eta: 0:00:54  Lr: 0.001875  Loss: 0.4852  Acc@1: 81.2500 (84.0232)  Acc@5: 100.0000 (97.5993)  time: 0.3314  data: 0.0011  max mem: 2356
Train: Epoch[2/5]  [160/313]  eta: 0:00:51  Lr: 0.001875  Loss: 0.0833  Acc@1: 87.5000 (83.9286)  Acc@5: 100.0000 (97.5155)  time: 0.3309  data: 0.0011  max mem: 2356
Train: Epoch[2/5]  [170/313]  eta: 0:00:47  Lr: 0.001875  Loss: 0.1550  Acc@1: 87.5000 (83.9912)  Acc@5: 93.7500 (97.5146)  time: 0.3309  data: 0.0010  max mem: 2356
Train: Epoch[2/5]  [180/313]  eta: 0:00:44  Lr: 0.001875  Loss: 0.1068  Acc@1: 81.2500 (83.8743)  Acc@5: 100.0000 (97.4793)  time: 0.3310  data: 0.0010  max mem: 2356
Train: Epoch[2/5]  [190/313]  eta: 0:00:40  Lr: 0.001875  Loss: 0.2753  Acc@1: 81.2500 (83.9332)  Acc@5: 100.0000 (97.5785)  time: 0.3307  data: 0.0007  max mem: 2356
Train: Epoch[2/5]  [200/313]  eta: 0:00:37  Lr: 0.001875  Loss: 0.2360  Acc@1: 81.2500 (83.8930)  Acc@5: 100.0000 (97.6057)  time: 0.3350  data: 0.0010  max mem: 2356
Train: Epoch[2/5]  [210/313]  eta: 0:00:34  Lr: 0.001875  Loss: 0.4108  Acc@1: 87.5000 (84.0936)  Acc@5: 100.0000 (97.6007)  time: 0.3399  data: 0.0009  max mem: 2356
Train: Epoch[2/5]  [220/313]  eta: 0:00:31  Lr: 0.001875  Loss: 0.3889  Acc@1: 81.2500 (83.8518)  Acc@5: 100.0000 (97.5679)  time: 0.3373  data: 0.0007  max mem: 2356
Train: Epoch[2/5]  [230/313]  eta: 0:00:27  Lr: 0.001875  Loss: 0.0279  Acc@1: 81.2500 (84.0639)  Acc@5: 100.0000 (97.6732)  time: 0.3365  data: 0.0013  max mem: 2356
Train: Epoch[2/5]  [240/313]  eta: 0:00:24  Lr: 0.001875  Loss: 0.0266  Acc@1: 87.5000 (84.1286)  Acc@5: 100.0000 (97.7697)  time: 0.3392  data: 0.0011  max mem: 2356
Train: Epoch[2/5]  [250/313]  eta: 0:00:21  Lr: 0.001875  Loss: 0.7357  Acc@1: 81.2500 (84.0637)  Acc@5: 100.0000 (97.7341)  time: 0.3380  data: 0.0011  max mem: 2356
Train: Epoch[2/5]  [260/313]  eta: 0:00:17  Lr: 0.001875  Loss: 0.6945  Acc@1: 81.2500 (83.8841)  Acc@5: 100.0000 (97.7251)  time: 0.3351  data: 0.0012  max mem: 2356
Train: Epoch[2/5]  [270/313]  eta: 0:00:14  Lr: 0.001875  Loss: 0.2231  Acc@1: 81.2500 (83.8561)  Acc@5: 100.0000 (97.7629)  time: 0.3334  data: 0.0009  max mem: 2356
Train: Epoch[2/5]  [280/313]  eta: 0:00:11  Lr: 0.001875  Loss: 0.5347  Acc@1: 81.2500 (83.8078)  Acc@5: 100.0000 (97.7313)  time: 0.3357  data: 0.0015  max mem: 2356
Train: Epoch[2/5]  [290/313]  eta: 0:00:07  Lr: 0.001875  Loss: 0.4556  Acc@1: 81.2500 (83.8273)  Acc@5: 100.0000 (97.7448)  time: 0.3359  data: 0.0019  max mem: 2356
Train: Epoch[2/5]  [300/313]  eta: 0:00:04  Lr: 0.001875  Loss: 0.3095  Acc@1: 87.5000 (83.9078)  Acc@5: 100.0000 (97.7782)  time: 0.3382  data: 0.0016  max mem: 2356
Train: Epoch[2/5]  [310/313]  eta: 0:00:01  Lr: 0.001875  Loss: 0.4226  Acc@1: 87.5000 (84.0032)  Acc@5: 100.0000 (97.8095)  time: 0.3386  data: 0.0008  max mem: 2356
Train: Epoch[2/5]  [312/313]  eta: 0:00:00  Lr: 0.001875  Loss: -0.1592  Acc@1: 87.5000 (84.0600)  Acc@5: 100.0000 (97.8200)  time: 0.3301  data: 0.0007  max mem: 2356
Train: Epoch[2/5] Total time: 0:01:44 (0.3345 s / it)
{0: {0: 8435, 1: 0, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}, 1: {0: 850, 1: 0, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}, 2: {0: 1967, 1: 0, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}, 3: {0: 6645, 1: 0, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}, 4: {0: 6849, 1: 0, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}, 5: {0: 8998, 1: 0, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}, 6: {0: 4222, 1: 0, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}, 7: {0: 751, 1: 0, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}, 8: {0: 9295, 1: 0, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}, 9: {0: 1988, 1: 0, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}}
Averaged stats: Lr: 0.001875  Loss: -0.1592  Acc@1: 87.5000 (84.0600)  Acc@5: 100.0000 (97.8200)
Train: Epoch[3/5]  [  0/313]  eta: 0:03:50  Lr: 0.001875  Loss: 0.1271  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)  time: 0.7368  data: 0.4012  max mem: 2356
Train: Epoch[3/5]  [ 10/313]  eta: 0:01:54  Lr: 0.001875  Loss: 0.7554  Acc@1: 87.5000 (89.2045)  Acc@5: 100.0000 (98.2955)  time: 0.3768  data: 0.0376  max mem: 2356
Train: Epoch[3/5]  [ 20/313]  eta: 0:01:44  Lr: 0.001875  Loss: 0.4759  Acc@1: 87.5000 (84.5238)  Acc@5: 100.0000 (98.5119)  time: 0.3392  data: 0.0017  max mem: 2356
Train: Epoch[3/5]  [ 30/313]  eta: 0:01:39  Lr: 0.001875  Loss: 0.0915  Acc@1: 87.5000 (85.4839)  Acc@5: 100.0000 (98.9919)  time: 0.3367  data: 0.0019  max mem: 2356
Train: Epoch[3/5]  [ 40/313]  eta: 0:01:35  Lr: 0.001875  Loss: 0.0322  Acc@1: 87.5000 (86.4329)  Acc@5: 100.0000 (98.7805)  time: 0.3391  data: 0.0017  max mem: 2356
Train: Epoch[3/5]  [ 50/313]  eta: 0:01:31  Lr: 0.001875  Loss: 0.1817  Acc@1: 87.5000 (86.7647)  Acc@5: 100.0000 (98.8971)  time: 0.3392  data: 0.0023  max mem: 2356
Train: Epoch[3/5]  [ 60/313]  eta: 0:01:27  Lr: 0.001875  Loss: 0.5491  Acc@1: 87.5000 (85.7582)  Acc@5: 100.0000 (98.6680)  time: 0.3350  data: 0.0021  max mem: 2356
Train: Epoch[3/5]  [ 70/313]  eta: 0:01:23  Lr: 0.001875  Loss: 0.6543  Acc@1: 87.5000 (86.3556)  Acc@5: 100.0000 (98.6796)  time: 0.3361  data: 0.0009  max mem: 2356
Train: Epoch[3/5]  [ 80/313]  eta: 0:01:19  Lr: 0.001875  Loss: 0.2778  Acc@1: 87.5000 (86.4198)  Acc@5: 100.0000 (98.6111)  time: 0.3355  data: 0.0004  max mem: 2356
Train: Epoch[3/5]  [ 90/313]  eta: 0:01:16  Lr: 0.001875  Loss: 0.0303  Acc@1: 87.5000 (86.1951)  Acc@5: 100.0000 (98.5577)  time: 0.3325  data: 0.0004  max mem: 2356
Train: Epoch[3/5]  [100/313]  eta: 0:01:12  Lr: 0.001875  Loss: 0.2362  Acc@1: 81.2500 (85.8911)  Acc@5: 100.0000 (98.6386)  time: 0.3336  data: 0.0004  max mem: 2356
Train: Epoch[3/5]  [110/313]  eta: 0:01:09  Lr: 0.001875  Loss: 0.0243  Acc@1: 81.2500 (86.2613)  Acc@5: 100.0000 (98.7050)  time: 0.3354  data: 0.0016  max mem: 2356
Train: Epoch[3/5]  [120/313]  eta: 0:01:05  Lr: 0.001875  Loss: 0.6327  Acc@1: 81.2500 (85.6921)  Acc@5: 100.0000 (98.7603)  time: 0.3341  data: 0.0016  max mem: 2356
Train: Epoch[3/5]  [130/313]  eta: 0:01:02  Lr: 0.001875  Loss: 0.2015  Acc@1: 87.5000 (86.2595)  Acc@5: 100.0000 (98.6641)  time: 0.3324  data: 0.0004  max mem: 2356
Train: Epoch[3/5]  [140/313]  eta: 0:00:58  Lr: 0.001875  Loss: 0.2736  Acc@1: 87.5000 (86.3475)  Acc@5: 100.0000 (98.6702)  time: 0.3326  data: 0.0004  max mem: 2356
Train: Epoch[3/5]  [150/313]  eta: 0:00:55  Lr: 0.001875  Loss: 0.3120  Acc@1: 87.5000 (86.1755)  Acc@5: 100.0000 (98.6341)  time: 0.3329  data: 0.0004  max mem: 2356
Train: Epoch[3/5]  [160/313]  eta: 0:00:51  Lr: 0.001875  Loss: 0.1348  Acc@1: 87.5000 (86.2966)  Acc@5: 100.0000 (98.7189)  time: 0.3327  data: 0.0003  max mem: 2356
Train: Epoch[3/5]  [170/313]  eta: 0:00:48  Lr: 0.001875  Loss: 0.3824  Acc@1: 87.5000 (86.2939)  Acc@5: 100.0000 (98.7208)  time: 0.3328  data: 0.0004  max mem: 2356
Train: Epoch[3/5]  [180/313]  eta: 0:00:44  Lr: 0.001875  Loss: -0.1074  Acc@1: 87.5000 (86.2224)  Acc@5: 100.0000 (98.6878)  time: 0.3335  data: 0.0004  max mem: 2356
Train: Epoch[3/5]  [190/313]  eta: 0:00:41  Lr: 0.001875  Loss: 0.0949  Acc@1: 87.5000 (86.2565)  Acc@5: 100.0000 (98.7238)  time: 0.3323  data: 0.0004  max mem: 2356
Train: Epoch[3/5]  [200/313]  eta: 0:00:38  Lr: 0.001875  Loss: 0.2382  Acc@1: 87.5000 (86.2873)  Acc@5: 100.0000 (98.7251)  time: 0.3310  data: 0.0004  max mem: 2356
Train: Epoch[3/5]  [210/313]  eta: 0:00:34  Lr: 0.001875  Loss: 0.1320  Acc@1: 87.5000 (86.1967)  Acc@5: 100.0000 (98.6967)  time: 0.3313  data: 0.0005  max mem: 2356
Train: Epoch[3/5]  [220/313]  eta: 0:00:31  Lr: 0.001875  Loss: 0.1225  Acc@1: 87.5000 (86.2557)  Acc@5: 100.0000 (98.6425)  time: 0.3311  data: 0.0004  max mem: 2356
Train: Epoch[3/5]  [230/313]  eta: 0:00:27  Lr: 0.001875  Loss: 0.3416  Acc@1: 87.5000 (86.2554)  Acc@5: 100.0000 (98.6472)  time: 0.3310  data: 0.0004  max mem: 2356
Train: Epoch[3/5]  [240/313]  eta: 0:00:24  Lr: 0.001875  Loss: 0.3537  Acc@1: 87.5000 (86.1515)  Acc@5: 100.0000 (98.5996)  time: 0.3320  data: 0.0006  max mem: 2356
Train: Epoch[3/5]  [250/313]  eta: 0:00:21  Lr: 0.001875  Loss: 0.1820  Acc@1: 81.2500 (86.1554)  Acc@5: 100.0000 (98.5558)  time: 0.3324  data: 0.0006  max mem: 2356
Train: Epoch[3/5]  [260/313]  eta: 0:00:17  Lr: 0.001875  Loss: 0.2698  Acc@1: 87.5000 (86.2548)  Acc@5: 100.0000 (98.5393)  time: 0.3311  data: 0.0004  max mem: 2356
Train: Epoch[3/5]  [270/313]  eta: 0:00:14  Lr: 0.001875  Loss: -0.0500  Acc@1: 87.5000 (86.2777)  Acc@5: 100.0000 (98.5240)  time: 0.3322  data: 0.0003  max mem: 2356
Train: Epoch[3/5]  [280/313]  eta: 0:00:11  Lr: 0.001875  Loss: -0.0695  Acc@1: 87.5000 (86.3434)  Acc@5: 100.0000 (98.5543)  time: 0.3352  data: 0.0005  max mem: 2356
Train: Epoch[3/5]  [290/313]  eta: 0:00:07  Lr: 0.001875  Loss: 0.4254  Acc@1: 87.5000 (86.4046)  Acc@5: 100.0000 (98.5395)  time: 0.3412  data: 0.0006  max mem: 2356
Train: Epoch[3/5]  [300/313]  eta: 0:00:04  Lr: 0.001875  Loss: 0.0956  Acc@1: 87.5000 (86.4826)  Acc@5: 100.0000 (98.5465)  time: 0.3457  data: 0.0013  max mem: 2356
Train: Epoch[3/5]  [310/313]  eta: 0:00:01  Lr: 0.001875  Loss: 0.1741  Acc@1: 87.5000 (86.5555)  Acc@5: 100.0000 (98.5531)  time: 0.3403  data: 0.0012  max mem: 2356
Train: Epoch[3/5]  [312/313]  eta: 0:00:00  Lr: 0.001875  Loss: 0.9258  Acc@1: 87.5000 (86.5200)  Acc@5: 100.0000 (98.5000)  time: 0.3332  data: 0.0011  max mem: 2356
Train: Epoch[3/5] Total time: 0:01:45 (0.3360 s / it)
{0: {0: 13252, 1: 0, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}, 1: {0: 954, 1: 0, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}, 2: {0: 2307, 1: 0, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}, 3: {0: 11510, 1: 0, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}, 4: {0: 10265, 1: 0, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}, 5: {0: 13985, 1: 0, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}, 6: {0: 5713, 1: 0, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}, 7: {0: 752, 1: 0, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}, 8: {0: 14274, 1: 0, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}, 9: {0: 1988, 1: 0, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}}
Averaged stats: Lr: 0.001875  Loss: 0.9258  Acc@1: 87.5000 (86.5200)  Acc@5: 100.0000 (98.5000)
Train: Epoch[4/5]  [  0/313]  eta: 0:03:41  Lr: 0.001875  Loss: 0.1039  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (100.0000)  time: 0.7083  data: 0.3755  max mem: 2356
Train: Epoch[4/5]  [ 10/313]  eta: 0:01:52  Lr: 0.001875  Loss: 0.3334  Acc@1: 87.5000 (88.6364)  Acc@5: 100.0000 (98.2955)  time: 0.3707  data: 0.0358  max mem: 2356
Train: Epoch[4/5]  [ 20/313]  eta: 0:01:43  Lr: 0.001875  Loss: 0.1463  Acc@1: 87.5000 (87.7976)  Acc@5: 100.0000 (98.5119)  time: 0.3357  data: 0.0018  max mem: 2356
Train: Epoch[4/5]  [ 30/313]  eta: 0:01:38  Lr: 0.001875  Loss: 0.0913  Acc@1: 87.5000 (87.0968)  Acc@5: 100.0000 (98.5887)  time: 0.3360  data: 0.0021  max mem: 2356
Train: Epoch[4/5]  [ 40/313]  eta: 0:01:34  Lr: 0.001875  Loss: 0.0355  Acc@1: 87.5000 (86.7378)  Acc@5: 100.0000 (98.4756)  time: 0.3360  data: 0.0021  max mem: 2356
Train: Epoch[4/5]  [ 50/313]  eta: 0:01:30  Lr: 0.001875  Loss: 0.0017  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (98.4069)  time: 0.3339  data: 0.0012  max mem: 2356
Train: Epoch[4/5]  [ 60/313]  eta: 0:01:26  Lr: 0.001875  Loss: 0.2279  Acc@1: 87.5000 (86.8852)  Acc@5: 100.0000 (98.1557)  time: 0.3357  data: 0.0019  max mem: 2356
Train: Epoch[4/5]  [ 70/313]  eta: 0:01:22  Lr: 0.001875  Loss: 0.3897  Acc@1: 87.5000 (86.2676)  Acc@5: 100.0000 (98.0634)  time: 0.3364  data: 0.0020  max mem: 2356
Train: Epoch[4/5]  [ 80/313]  eta: 0:01:19  Lr: 0.001875  Loss: -0.1850  Acc@1: 81.2500 (86.0340)  Acc@5: 100.0000 (98.0710)  time: 0.3359  data: 0.0011  max mem: 2356
Train: Epoch[4/5]  [ 90/313]  eta: 0:01:15  Lr: 0.001875  Loss: -0.0513  Acc@1: 87.5000 (86.2637)  Acc@5: 100.0000 (98.1456)  time: 0.3358  data: 0.0010  max mem: 2356
Train: Epoch[4/5]  [100/313]  eta: 0:01:12  Lr: 0.001875  Loss: -0.0851  Acc@1: 87.5000 (86.4480)  Acc@5: 100.0000 (98.2673)  time: 0.3345  data: 0.0006  max mem: 2356
Train: Epoch[4/5]  [110/313]  eta: 0:01:08  Lr: 0.001875  Loss: 0.1511  Acc@1: 87.5000 (86.3739)  Acc@5: 100.0000 (98.3108)  time: 0.3404  data: 0.0013  max mem: 2356
Train: Epoch[4/5]  [120/313]  eta: 0:01:05  Lr: 0.001875  Loss: 0.2517  Acc@1: 81.2500 (86.0537)  Acc@5: 100.0000 (98.2438)  time: 0.3391  data: 0.0012  max mem: 2356
Train: Epoch[4/5]  [130/313]  eta: 0:01:01  Lr: 0.001875  Loss: -0.0818  Acc@1: 87.5000 (86.2118)  Acc@5: 100.0000 (98.2347)  time: 0.3328  data: 0.0006  max mem: 2356
Train: Epoch[4/5]  [140/313]  eta: 0:00:58  Lr: 0.001875  Loss: 0.0572  Acc@1: 87.5000 (86.5248)  Acc@5: 100.0000 (98.2713)  time: 0.3351  data: 0.0012  max mem: 2356
Train: Epoch[4/5]  [150/313]  eta: 0:00:55  Lr: 0.001875  Loss: 0.6407  Acc@1: 87.5000 (86.8377)  Acc@5: 100.0000 (98.3030)  time: 0.3466  data: 0.0011  max mem: 2356
Train: Epoch[4/5]  [160/313]  eta: 0:00:51  Lr: 0.001875  Loss: 0.0521  Acc@1: 87.5000 (86.8012)  Acc@5: 100.0000 (98.3307)  time: 0.3444  data: 0.0006  max mem: 2356
Train: Epoch[4/5]  [170/313]  eta: 0:00:48  Lr: 0.001875  Loss: -0.0582  Acc@1: 87.5000 (86.6228)  Acc@5: 100.0000 (98.3187)  time: 0.3331  data: 0.0004  max mem: 2356
Train: Epoch[4/5]  [180/313]  eta: 0:00:45  Lr: 0.001875  Loss: 0.1822  Acc@1: 87.5000 (86.8439)  Acc@5: 100.0000 (98.3771)  time: 0.3330  data: 0.0004  max mem: 2356
Train: Epoch[4/5]  [190/313]  eta: 0:00:41  Lr: 0.001875  Loss: 0.0734  Acc@1: 93.7500 (86.9437)  Acc@5: 100.0000 (98.3312)  time: 0.3326  data: 0.0004  max mem: 2356
Train: Epoch[4/5]  [200/313]  eta: 0:00:38  Lr: 0.001875  Loss: 0.3734  Acc@1: 93.7500 (87.1580)  Acc@5: 100.0000 (98.3520)  time: 0.3334  data: 0.0011  max mem: 2356
Train: Epoch[4/5]  [210/313]  eta: 0:00:34  Lr: 0.001875  Loss: 0.5066  Acc@1: 87.5000 (87.0261)  Acc@5: 100.0000 (98.3709)  time: 0.3335  data: 0.0010  max mem: 2356
Train: Epoch[4/5]  [220/313]  eta: 0:00:31  Lr: 0.001875  Loss: 0.4170  Acc@1: 87.5000 (87.1324)  Acc@5: 100.0000 (98.3880)  time: 0.3335  data: 0.0011  max mem: 2356
Train: Epoch[4/5]  [230/313]  eta: 0:00:28  Lr: 0.001875  Loss: 0.0580  Acc@1: 87.5000 (87.2024)  Acc@5: 100.0000 (98.4037)  time: 0.3329  data: 0.0012  max mem: 2356
Train: Epoch[4/5]  [240/313]  eta: 0:00:24  Lr: 0.001875  Loss: 0.0133  Acc@1: 87.5000 (87.3444)  Acc@5: 100.0000 (98.3662)  time: 0.3333  data: 0.0005  max mem: 2356
Train: Epoch[4/5]  [250/313]  eta: 0:00:21  Lr: 0.001875  Loss: 0.2221  Acc@1: 87.5000 (87.2759)  Acc@5: 100.0000 (98.4064)  time: 0.3334  data: 0.0004  max mem: 2356
Train: Epoch[4/5]  [260/313]  eta: 0:00:17  Lr: 0.001875  Loss: 0.2520  Acc@1: 87.5000 (87.3084)  Acc@5: 100.0000 (98.3716)  time: 0.3327  data: 0.0004  max mem: 2356
Train: Epoch[4/5]  [270/313]  eta: 0:00:14  Lr: 0.001875  Loss: 0.5802  Acc@1: 87.5000 (87.1541)  Acc@5: 100.0000 (98.2934)  time: 0.3327  data: 0.0007  max mem: 2356
Train: Epoch[4/5]  [280/313]  eta: 0:00:11  Lr: 0.001875  Loss: -0.0432  Acc@1: 81.2500 (87.0774)  Acc@5: 100.0000 (98.3319)  time: 0.3322  data: 0.0007  max mem: 2356
Train: Epoch[4/5]  [290/313]  eta: 0:00:07  Lr: 0.001875  Loss: 0.2725  Acc@1: 87.5000 (87.0060)  Acc@5: 100.0000 (98.3462)  time: 0.3320  data: 0.0004  max mem: 2356
Train: Epoch[4/5]  [300/313]  eta: 0:00:04  Lr: 0.001875  Loss: 0.2658  Acc@1: 87.5000 (87.0847)  Acc@5: 100.0000 (98.3804)  time: 0.3312  data: 0.0004  max mem: 2356
Train: Epoch[4/5]  [310/313]  eta: 0:00:01  Lr: 0.001875  Loss: 0.3166  Acc@1: 87.5000 (87.0780)  Acc@5: 100.0000 (98.3722)  time: 0.3303  data: 0.0004  max mem: 2356
Train: Epoch[4/5]  [312/313]  eta: 0:00:00  Lr: 0.001875  Loss: 0.1031  Acc@1: 87.5000 (87.1000)  Acc@5: 100.0000 (98.3600)  time: 0.3220  data: 0.0003  max mem: 2356
Train: Epoch[4/5] Total time: 0:01:45 (0.3359 s / it)
{0: {0: 17874, 1: 0, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}, 1: {0: 1220, 1: 0, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}, 2: {0: 2832, 1: 0, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}, 3: {0: 16502, 1: 0, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}, 4: {0: 13249, 1: 0, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}, 5: {0: 18757, 1: 0, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}, 6: {0: 7554, 1: 0, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}, 7: {0: 752, 1: 0, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}, 8: {0: 19272, 1: 0, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}, 9: {0: 1988, 1: 0, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}}
Averaged stats: Lr: 0.001875  Loss: 0.1031  Acc@1: 87.5000 (87.1000)  Acc@5: 100.0000 (98.3600)
Train: Epoch[5/5]  [  0/313]  eta: 0:02:54  Lr: 0.001875  Loss: 0.2231  Acc@1: 87.5000 (87.5000)  Acc@5: 93.7500 (93.7500)  time: 0.5575  data: 0.2269  max mem: 2356
Train: Epoch[5/5]  [ 10/313]  eta: 0:01:45  Lr: 0.001875  Loss: 0.2328  Acc@1: 87.5000 (88.0682)  Acc@5: 100.0000 (98.2955)  time: 0.3494  data: 0.0209  max mem: 2356
Train: Epoch[5/5]  [ 20/313]  eta: 0:01:39  Lr: 0.001875  Loss: 0.3292  Acc@1: 87.5000 (88.6905)  Acc@5: 100.0000 (97.6190)  time: 0.3291  data: 0.0003  max mem: 2356
Train: Epoch[5/5]  [ 30/313]  eta: 0:01:35  Lr: 0.001875  Loss: 0.4750  Acc@1: 87.5000 (87.2984)  Acc@5: 100.0000 (97.5806)  time: 0.3310  data: 0.0003  max mem: 2356
Train: Epoch[5/5]  [ 40/313]  eta: 0:01:32  Lr: 0.001875  Loss: 0.4338  Acc@1: 87.5000 (86.2805)  Acc@5: 100.0000 (97.8659)  time: 0.3353  data: 0.0015  max mem: 2356
Train: Epoch[5/5]  [ 50/313]  eta: 0:01:28  Lr: 0.001875  Loss: -0.0010  Acc@1: 87.5000 (86.6422)  Acc@5: 100.0000 (98.0392)  time: 0.3381  data: 0.0024  max mem: 2356
Train: Epoch[5/5]  [ 60/313]  eta: 0:01:25  Lr: 0.001875  Loss: 0.3130  Acc@1: 81.2500 (85.5533)  Acc@5: 100.0000 (97.9508)  time: 0.3392  data: 0.0013  max mem: 2356
Train: Epoch[5/5]  [ 70/313]  eta: 0:01:22  Lr: 0.001875  Loss: -0.0437  Acc@1: 87.5000 (85.7394)  Acc@5: 100.0000 (97.9754)  time: 0.3375  data: 0.0006  max mem: 2356
Train: Epoch[5/5]  [ 80/313]  eta: 0:01:18  Lr: 0.001875  Loss: 0.6500  Acc@1: 87.5000 (85.8025)  Acc@5: 100.0000 (98.0710)  time: 0.3349  data: 0.0008  max mem: 2356
Train: Epoch[5/5]  [ 90/313]  eta: 0:01:15  Lr: 0.001875  Loss: 0.1619  Acc@1: 87.5000 (85.5769)  Acc@5: 100.0000 (98.1456)  time: 0.3349  data: 0.0012  max mem: 2356
Train: Epoch[5/5]  [100/313]  eta: 0:01:11  Lr: 0.001875  Loss: 0.1862  Acc@1: 87.5000 (85.5817)  Acc@5: 100.0000 (98.2673)  time: 0.3370  data: 0.0011  max mem: 2356
Train: Epoch[5/5]  [110/313]  eta: 0:01:08  Lr: 0.001875  Loss: 0.1129  Acc@1: 87.5000 (85.4730)  Acc@5: 100.0000 (98.2545)  time: 0.3391  data: 0.0006  max mem: 2356
Train: Epoch[5/5]  [120/313]  eta: 0:01:05  Lr: 0.001875  Loss: 0.0960  Acc@1: 87.5000 (85.6405)  Acc@5: 100.0000 (98.3471)  time: 0.3378  data: 0.0006  max mem: 2356
Train: Epoch[5/5]  [130/313]  eta: 0:01:01  Lr: 0.001875  Loss: 0.2411  Acc@1: 87.5000 (85.4485)  Acc@5: 100.0000 (98.3302)  time: 0.3411  data: 0.0007  max mem: 2356
Train: Epoch[5/5]  [140/313]  eta: 0:00:58  Lr: 0.001875  Loss: -0.0334  Acc@1: 87.5000 (85.6826)  Acc@5: 100.0000 (98.4486)  time: 0.3470  data: 0.0016  max mem: 2356
Train: Epoch[5/5]  [150/313]  eta: 0:00:55  Lr: 0.001875  Loss: 0.0852  Acc@1: 87.5000 (85.6374)  Acc@5: 100.0000 (98.4272)  time: 0.3417  data: 0.0022  max mem: 2356
Train: Epoch[5/5]  [160/313]  eta: 0:00:51  Lr: 0.001875  Loss: 0.2329  Acc@1: 87.5000 (85.6366)  Acc@5: 100.0000 (98.3696)  time: 0.3364  data: 0.0025  max mem: 2356
Train: Epoch[5/5]  [170/313]  eta: 0:00:48  Lr: 0.001875  Loss: 0.3033  Acc@1: 87.5000 (85.9649)  Acc@5: 100.0000 (98.4649)  time: 0.3354  data: 0.0018  max mem: 2356
Train: Epoch[5/5]  [180/313]  eta: 0:00:44  Lr: 0.001875  Loss: 0.1736  Acc@1: 87.5000 (85.9807)  Acc@5: 100.0000 (98.4461)  time: 0.3355  data: 0.0005  max mem: 2356
Train: Epoch[5/5]  [190/313]  eta: 0:00:41  Lr: 0.001875  Loss: 0.3152  Acc@1: 87.5000 (86.1911)  Acc@5: 100.0000 (98.4293)  time: 0.3418  data: 0.0011  max mem: 2356
Train: Epoch[5/5]  [200/313]  eta: 0:00:38  Lr: 0.001875  Loss: -0.1351  Acc@1: 87.5000 (86.3495)  Acc@5: 100.0000 (98.4453)  time: 0.3477  data: 0.0025  max mem: 2356
Train: Epoch[5/5]  [210/313]  eta: 0:00:34  Lr: 0.001875  Loss: 0.1548  Acc@1: 87.5000 (86.1967)  Acc@5: 100.0000 (98.4301)  time: 0.3437  data: 0.0023  max mem: 2356
Train: Epoch[5/5]  [220/313]  eta: 0:00:31  Lr: 0.001875  Loss: -0.0543  Acc@1: 87.5000 (86.3122)  Acc@5: 100.0000 (98.4729)  time: 0.3391  data: 0.0014  max mem: 2356
Train: Epoch[5/5]  [230/313]  eta: 0:00:28  Lr: 0.001875  Loss: 0.0557  Acc@1: 87.5000 (86.4177)  Acc@5: 100.0000 (98.4578)  time: 0.3370  data: 0.0010  max mem: 2356
Train: Epoch[5/5]  [240/313]  eta: 0:00:24  Lr: 0.001875  Loss: 0.1742  Acc@1: 87.5000 (86.4367)  Acc@5: 100.0000 (98.4959)  time: 0.3329  data: 0.0004  max mem: 2356
Train: Epoch[5/5]  [250/313]  eta: 0:00:21  Lr: 0.001875  Loss: 0.2620  Acc@1: 87.5000 (86.5289)  Acc@5: 100.0000 (98.5309)  time: 0.3330  data: 0.0004  max mem: 2356
Train: Epoch[5/5]  [260/313]  eta: 0:00:17  Lr: 0.001875  Loss: -0.0401  Acc@1: 87.5000 (86.6379)  Acc@5: 100.0000 (98.4914)  time: 0.3330  data: 0.0004  max mem: 2356
Train: Epoch[5/5]  [270/313]  eta: 0:00:14  Lr: 0.001875  Loss: 0.2453  Acc@1: 87.5000 (86.6697)  Acc@5: 100.0000 (98.4548)  time: 0.3339  data: 0.0005  max mem: 2356
Train: Epoch[5/5]  [280/313]  eta: 0:00:11  Lr: 0.001875  Loss: 0.1073  Acc@1: 87.5000 (86.6993)  Acc@5: 100.0000 (98.4653)  time: 0.3342  data: 0.0005  max mem: 2356
Train: Epoch[5/5]  [290/313]  eta: 0:00:07  Lr: 0.001875  Loss: -0.1112  Acc@1: 87.5000 (86.8557)  Acc@5: 100.0000 (98.4966)  time: 0.3326  data: 0.0004  max mem: 2356
Train: Epoch[5/5]  [300/313]  eta: 0:00:04  Lr: 0.001875  Loss: 0.2103  Acc@1: 87.5000 (86.8148)  Acc@5: 100.0000 (98.4842)  time: 0.3325  data: 0.0004  max mem: 2356
Train: Epoch[5/5]  [310/313]  eta: 0:00:01  Lr: 0.001875  Loss: 0.0716  Acc@1: 87.5000 (86.8770)  Acc@5: 100.0000 (98.5129)  time: 0.3333  data: 0.0003  max mem: 2356
Train: Epoch[5/5]  [312/313]  eta: 0:00:00  Lr: 0.001875  Loss: -0.0366  Acc@1: 87.5000 (86.9000)  Acc@5: 100.0000 (98.5200)  time: 0.3252  data: 0.0003  max mem: 2356
Train: Epoch[5/5] Total time: 0:01:45 (0.3372 s / it)
{0: {0: 22412, 1: 0, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}, 1: {0: 1577, 1: 0, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}, 2: {0: 3518, 1: 0, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}, 3: {0: 21486, 1: 0, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}, 4: {0: 16124, 1: 0, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}, 5: {0: 23402, 1: 0, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}, 6: {0: 9472, 1: 0, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}, 7: {0: 752, 1: 0, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}, 8: {0: 24269, 1: 0, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}, 9: {0: 1988, 1: 0, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}}
Averaged stats: Lr: 0.001875  Loss: -0.0366  Acc@1: 87.5000 (86.9000)  Acc@5: 100.0000 (98.5200)
Test: [Task 1]  [ 0/63]  eta: 0:00:34  Loss: 0.4038 (0.4038)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)  time: 0.5537  data: 0.3442  max mem: 2356
Test: [Task 1]  [10/63]  eta: 0:00:12  Loss: 0.3961 (0.4025)  Acc@1: 100.0000 (97.7273)  Acc@5: 100.0000 (99.4318)  time: 0.2377  data: 0.0316  max mem: 2356
Test: [Task 1]  [20/63]  eta: 0:00:09  Loss: 0.3662 (0.4763)  Acc@1: 93.7500 (95.8333)  Acc@5: 100.0000 (99.7024)  time: 0.2054  data: 0.0003  max mem: 2356
Test: [Task 1]  [30/63]  eta: 0:00:07  Loss: 0.3416 (0.4220)  Acc@1: 100.0000 (96.9758)  Acc@5: 100.0000 (99.7984)  time: 0.2049  data: 0.0003  max mem: 2356
Test: [Task 1]  [40/63]  eta: 0:00:04  Loss: 0.3171 (0.4214)  Acc@1: 100.0000 (97.1037)  Acc@5: 100.0000 (99.8476)  time: 0.2051  data: 0.0003  max mem: 2356
Test: [Task 1]  [50/63]  eta: 0:00:02  Loss: 0.3647 (0.4125)  Acc@1: 100.0000 (97.0588)  Acc@5: 100.0000 (99.7549)  time: 0.2055  data: 0.0005  max mem: 2356
Test: [Task 1]  [60/63]  eta: 0:00:00  Loss: 0.3814 (0.4088)  Acc@1: 100.0000 (97.2336)  Acc@5: 100.0000 (99.7951)  time: 0.2058  data: 0.0005  max mem: 2356
Test: [Task 1]  [62/63]  eta: 0:00:00  Loss: 0.3647 (0.4080)  Acc@1: 100.0000 (97.3000)  Acc@5: 100.0000 (99.8000)  time: 0.2009  data: 0.0005  max mem: 2356
Test: [Task 1] Total time: 0:00:13 (0.2104 s / it)
* Acc@1 97.300 Acc@5 99.800 loss 0.408
{0: {0: 882, 1: 103, 2: 225, 3: 980, 4: 594, 5: 887, 6: 299, 7: 8, 8: 962, 9: 60}}
[Average accuracy till task1]	Acc@1: 97.3000	Acc@5: 99.8000	Loss: 0.4080
Train: Epoch[1/5]  [  0/313]  eta: 0:03:08  Lr: 0.001875  Loss: 2.0904  Acc@1: 18.7500 (18.7500)  Acc@5: 43.7500 (43.7500)  time: 0.6009  data: 0.2493  max mem: 2356
Train: Epoch[1/5]  [ 10/313]  eta: 0:01:47  Lr: 0.001875  Loss: 1.9182  Acc@1: 37.5000 (36.3636)  Acc@5: 75.0000 (72.1591)  time: 0.3538  data: 0.0238  max mem: 2356
Train: Epoch[1/5]  [ 20/313]  eta: 0:01:40  Lr: 0.001875  Loss: 1.7628  Acc@1: 56.2500 (52.3810)  Acc@5: 87.5000 (83.6310)  time: 0.3297  data: 0.0008  max mem: 2356
Train: Epoch[1/5]  [ 30/313]  eta: 0:01:35  Lr: 0.001875  Loss: 1.5108  Acc@1: 75.0000 (60.4839)  Acc@5: 100.0000 (87.7016)  time: 0.3305  data: 0.0004  max mem: 2356
Train: Epoch[1/5]  [ 40/313]  eta: 0:01:31  Lr: 0.001875  Loss: 1.1699  Acc@1: 75.0000 (62.5000)  Acc@5: 93.7500 (89.3293)  time: 0.3307  data: 0.0004  max mem: 2356
Train: Epoch[1/5]  [ 50/313]  eta: 0:01:28  Lr: 0.001875  Loss: 1.2443  Acc@1: 75.0000 (64.8284)  Acc@5: 93.7500 (90.4412)  time: 0.3304  data: 0.0006  max mem: 2356
Train: Epoch[1/5]  [ 60/313]  eta: 0:01:24  Lr: 0.001875  Loss: 0.7500  Acc@1: 75.0000 (66.7008)  Acc@5: 100.0000 (91.2910)  time: 0.3299  data: 0.0006  max mem: 2356
Train: Epoch[1/5]  [ 70/313]  eta: 0:01:21  Lr: 0.001875  Loss: 0.7700  Acc@1: 75.0000 (68.2218)  Acc@5: 93.7500 (91.7254)  time: 0.3317  data: 0.0008  max mem: 2356
Train: Epoch[1/5]  [ 80/313]  eta: 0:01:17  Lr: 0.001875  Loss: 0.6922  Acc@1: 81.2500 (70.2932)  Acc@5: 100.0000 (92.5926)  time: 0.3348  data: 0.0009  max mem: 2356
Train: Epoch[1/5]  [ 90/313]  eta: 0:01:14  Lr: 0.001875  Loss: 0.6015  Acc@1: 81.2500 (71.2912)  Acc@5: 100.0000 (93.0632)  time: 0.3385  data: 0.0010  max mem: 2356
Train: Epoch[1/5]  [100/313]  eta: 0:01:11  Lr: 0.001875  Loss: 0.4780  Acc@1: 81.2500 (72.3391)  Acc@5: 100.0000 (93.3787)  time: 0.3394  data: 0.0017  max mem: 2356
Train: Epoch[1/5]  [110/313]  eta: 0:01:08  Lr: 0.001875  Loss: 0.6643  Acc@1: 87.5000 (73.5360)  Acc@5: 100.0000 (93.8626)  time: 0.3373  data: 0.0015  max mem: 2356
Train: Epoch[1/5]  [120/313]  eta: 0:01:04  Lr: 0.001875  Loss: 0.4291  Acc@1: 87.5000 (74.5351)  Acc@5: 100.0000 (94.2149)  time: 0.3354  data: 0.0008  max mem: 2356
Train: Epoch[1/5]  [130/313]  eta: 0:01:01  Lr: 0.001875  Loss: 0.9681  Acc@1: 81.2500 (74.7615)  Acc@5: 100.0000 (94.3702)  time: 0.3378  data: 0.0005  max mem: 2356
Train: Epoch[1/5]  [140/313]  eta: 0:00:58  Lr: 0.001875  Loss: 0.6476  Acc@1: 75.0000 (75.0887)  Acc@5: 100.0000 (94.7252)  time: 0.3406  data: 0.0009  max mem: 2356
Train: Epoch[1/5]  [150/313]  eta: 0:00:54  Lr: 0.001875  Loss: 0.6133  Acc@1: 81.2500 (75.8278)  Acc@5: 100.0000 (94.9917)  time: 0.3414  data: 0.0024  max mem: 2356
Train: Epoch[1/5]  [160/313]  eta: 0:00:51  Lr: 0.001875  Loss: 0.2964  Acc@1: 87.5000 (76.4752)  Acc@5: 100.0000 (95.1475)  time: 0.3375  data: 0.0023  max mem: 2356
Train: Epoch[1/5]  [170/313]  eta: 0:00:48  Lr: 0.001875  Loss: 0.3577  Acc@1: 81.2500 (76.7909)  Acc@5: 100.0000 (95.3947)  time: 0.3350  data: 0.0011  max mem: 2356
Train: Epoch[1/5]  [180/313]  eta: 0:00:44  Lr: 0.001875  Loss: 0.2892  Acc@1: 81.2500 (77.2099)  Acc@5: 100.0000 (95.3384)  time: 0.3380  data: 0.0009  max mem: 2356
Train: Epoch[1/5]  [190/313]  eta: 0:00:41  Lr: 0.001875  Loss: 0.3457  Acc@1: 87.5000 (77.6178)  Acc@5: 100.0000 (95.4843)  time: 0.3363  data: 0.0010  max mem: 2356
Train: Epoch[1/5]  [200/313]  eta: 0:00:38  Lr: 0.001875  Loss: 0.4745  Acc@1: 81.2500 (77.6430)  Acc@5: 100.0000 (95.6157)  time: 0.3418  data: 0.0016  max mem: 2356
Train: Epoch[1/5]  [210/313]  eta: 0:00:34  Lr: 0.001875  Loss: 0.3003  Acc@1: 81.2500 (77.9325)  Acc@5: 100.0000 (95.7050)  time: 0.3478  data: 0.0034  max mem: 2356
Train: Epoch[1/5]  [220/313]  eta: 0:00:31  Lr: 0.001875  Loss: 0.4414  Acc@1: 81.2500 (78.2240)  Acc@5: 100.0000 (95.7296)  time: 0.3411  data: 0.0034  max mem: 2356
Train: Epoch[1/5]  [230/313]  eta: 0:00:28  Lr: 0.001875  Loss: 0.3514  Acc@1: 81.2500 (78.4903)  Acc@5: 93.7500 (95.7251)  time: 0.3370  data: 0.0011  max mem: 2356
Train: Epoch[1/5]  [240/313]  eta: 0:00:24  Lr: 0.001875  Loss: 0.7879  Acc@1: 87.5000 (78.6048)  Acc@5: 93.7500 (95.8247)  time: 0.3368  data: 0.0011  max mem: 2356
Train: Epoch[1/5]  [250/313]  eta: 0:00:21  Lr: 0.001875  Loss: 0.2400  Acc@1: 81.2500 (78.7351)  Acc@5: 100.0000 (95.9163)  time: 0.3340  data: 0.0012  max mem: 2356
Train: Epoch[1/5]  [260/313]  eta: 0:00:17  Lr: 0.001875  Loss: 0.3633  Acc@1: 81.2500 (78.9272)  Acc@5: 100.0000 (95.9531)  time: 0.3329  data: 0.0004  max mem: 2356
Train: Epoch[1/5]  [270/313]  eta: 0:00:14  Lr: 0.001875  Loss: 0.0534  Acc@1: 81.2500 (78.9437)  Acc@5: 100.0000 (95.9640)  time: 0.3333  data: 0.0003  max mem: 2356
Train: Epoch[1/5]  [280/313]  eta: 0:00:11  Lr: 0.001875  Loss: 0.1595  Acc@1: 81.2500 (79.2260)  Acc@5: 100.0000 (96.0187)  time: 0.3337  data: 0.0003  max mem: 2356
Train: Epoch[1/5]  [290/313]  eta: 0:00:07  Lr: 0.001875  Loss: 0.2668  Acc@1: 87.5000 (79.2311)  Acc@5: 100.0000 (96.0696)  time: 0.3358  data: 0.0008  max mem: 2356
Train: Epoch[1/5]  [300/313]  eta: 0:00:04  Lr: 0.001875  Loss: 0.4868  Acc@1: 81.2500 (79.2982)  Acc@5: 100.0000 (96.1379)  time: 0.3351  data: 0.0008  max mem: 2356
Train: Epoch[1/5]  [310/313]  eta: 0:00:01  Lr: 0.001875  Loss: 0.4793  Acc@1: 81.2500 (79.3207)  Acc@5: 100.0000 (96.1214)  time: 0.3326  data: 0.0004  max mem: 2356
Train: Epoch[1/5]  [312/313]  eta: 0:00:00  Lr: 0.001875  Loss: 0.3130  Acc@1: 81.2500 (79.3400)  Acc@5: 100.0000 (96.1200)  time: 0.3244  data: 0.0004  max mem: 2356
Train: Epoch[1/5] Total time: 0:01:45 (0.3364 s / it)
{0: {0: 22412, 1: 4967, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}, 1: {0: 1577, 1: 11, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}, 2: {0: 3518, 1: 747, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}, 3: {0: 21486, 1: 4985, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}, 4: {0: 16124, 1: 2209, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}, 5: {0: 23402, 1: 4992, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}, 6: {0: 9472, 1: 2098, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}, 7: {0: 752, 1: 0, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}, 8: {0: 24269, 1: 4991, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}, 9: {0: 1988, 1: 0, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}}
Averaged stats: Lr: 0.001875  Loss: 0.3130  Acc@1: 81.2500 (79.3400)  Acc@5: 100.0000 (96.1200)
Train: Epoch[2/5]  [  0/313]  eta: 0:03:22  Lr: 0.001875  Loss: 0.5634  Acc@1: 75.0000 (75.0000)  Acc@5: 93.7500 (93.7500)  time: 0.6457  data: 0.3018  max mem: 2356
Train: Epoch[2/5]  [ 10/313]  eta: 0:01:49  Lr: 0.001875  Loss: 0.1055  Acc@1: 81.2500 (81.8182)  Acc@5: 100.0000 (96.0227)  time: 0.3608  data: 0.0278  max mem: 2356
Train: Epoch[2/5]  [ 20/313]  eta: 0:01:42  Lr: 0.001875  Loss: 0.3331  Acc@1: 81.2500 (83.0357)  Acc@5: 100.0000 (96.7262)  time: 0.3333  data: 0.0004  max mem: 2356
Train: Epoch[2/5]  [ 30/313]  eta: 0:01:37  Lr: 0.001875  Loss: 0.4018  Acc@1: 81.2500 (82.2581)  Acc@5: 100.0000 (96.9758)  time: 0.3349  data: 0.0004  max mem: 2356
Train: Epoch[2/5]  [ 40/313]  eta: 0:01:33  Lr: 0.001875  Loss: 0.0320  Acc@1: 81.2500 (84.1463)  Acc@5: 100.0000 (97.2561)  time: 0.3337  data: 0.0008  max mem: 2356
Train: Epoch[2/5]  [ 50/313]  eta: 0:01:29  Lr: 0.001875  Loss: 0.5046  Acc@1: 87.5000 (84.3137)  Acc@5: 100.0000 (97.3039)  time: 0.3310  data: 0.0008  max mem: 2356
Train: Epoch[2/5]  [ 60/313]  eta: 0:01:25  Lr: 0.001875  Loss: 0.5178  Acc@1: 81.2500 (83.1967)  Acc@5: 100.0000 (97.4385)  time: 0.3307  data: 0.0007  max mem: 2356
Train: Epoch[2/5]  [ 70/313]  eta: 0:01:21  Lr: 0.001875  Loss: 0.3535  Acc@1: 81.2500 (82.8345)  Acc@5: 100.0000 (97.3592)  time: 0.3323  data: 0.0008  max mem: 2356
Train: Epoch[2/5]  [ 80/313]  eta: 0:01:18  Lr: 0.001875  Loss: 0.2763  Acc@1: 87.5000 (83.5648)  Acc@5: 100.0000 (97.3765)  time: 0.3318  data: 0.0006  max mem: 2356
Train: Epoch[2/5]  [ 90/313]  eta: 0:01:14  Lr: 0.001875  Loss: 0.6056  Acc@1: 81.2500 (83.1731)  Acc@5: 100.0000 (97.4588)  time: 0.3305  data: 0.0010  max mem: 2356
Train: Epoch[2/5]  [100/313]  eta: 0:01:11  Lr: 0.001875  Loss: 0.3952  Acc@1: 75.0000 (82.8589)  Acc@5: 100.0000 (97.5248)  time: 0.3311  data: 0.0009  max mem: 2356
Train: Epoch[2/5]  [110/313]  eta: 0:01:08  Lr: 0.001875  Loss: 0.3923  Acc@1: 81.2500 (83.2770)  Acc@5: 100.0000 (97.5225)  time: 0.3326  data: 0.0011  max mem: 2356
Train: Epoch[2/5]  [120/313]  eta: 0:01:04  Lr: 0.001875  Loss: 0.4412  Acc@1: 87.5000 (83.1612)  Acc@5: 100.0000 (97.4174)  time: 0.3349  data: 0.0012  max mem: 2356
Train: Epoch[2/5]  [130/313]  eta: 0:01:01  Lr: 0.001875  Loss: 0.1929  Acc@1: 81.2500 (83.1584)  Acc@5: 100.0000 (97.3282)  time: 0.3397  data: 0.0022  max mem: 2356
Train: Epoch[2/5]  [140/313]  eta: 0:00:58  Lr: 0.001875  Loss: 0.1973  Acc@1: 81.2500 (83.2004)  Acc@5: 100.0000 (97.3848)  time: 0.3424  data: 0.0032  max mem: 2356
Train: Epoch[2/5]  [150/313]  eta: 0:00:54  Lr: 0.001875  Loss: 0.4565  Acc@1: 87.5000 (83.5265)  Acc@5: 100.0000 (97.4338)  time: 0.3410  data: 0.0023  max mem: 2356
Train: Epoch[2/5]  [160/313]  eta: 0:00:51  Lr: 0.001875  Loss: -0.0061  Acc@1: 87.5000 (83.6568)  Acc@5: 100.0000 (97.4379)  time: 0.3408  data: 0.0015  max mem: 2356
Train: Epoch[2/5]  [170/313]  eta: 0:00:48  Lr: 0.001875  Loss: 0.2755  Acc@1: 81.2500 (83.5526)  Acc@5: 100.0000 (97.5146)  time: 0.3398  data: 0.0012  max mem: 2356
Train: Epoch[2/5]  [180/313]  eta: 0:00:44  Lr: 0.001875  Loss: 0.1678  Acc@1: 75.0000 (83.2528)  Acc@5: 100.0000 (97.5483)  time: 0.3423  data: 0.0013  max mem: 2356
Train: Epoch[2/5]  [190/313]  eta: 0:00:41  Lr: 0.001875  Loss: -0.0640  Acc@1: 81.2500 (83.4424)  Acc@5: 100.0000 (97.6113)  time: 0.3397  data: 0.0017  max mem: 2356
Train: Epoch[2/5]  [200/313]  eta: 0:00:38  Lr: 0.001875  Loss: -0.0265  Acc@1: 87.5000 (83.6754)  Acc@5: 100.0000 (97.6368)  time: 0.3362  data: 0.0021  max mem: 2356
Train: Epoch[2/5]  [210/313]  eta: 0:00:34  Lr: 0.001875  Loss: 0.2757  Acc@1: 87.5000 (83.8863)  Acc@5: 100.0000 (97.6007)  time: 0.3375  data: 0.0014  max mem: 2356
Train: Epoch[2/5]  [220/313]  eta: 0:00:31  Lr: 0.001875  Loss: 0.2311  Acc@1: 87.5000 (83.7952)  Acc@5: 100.0000 (97.5962)  time: 0.3371  data: 0.0005  max mem: 2356
Train: Epoch[2/5]  [230/313]  eta: 0:00:27  Lr: 0.001875  Loss: 0.2707  Acc@1: 87.5000 (84.0909)  Acc@5: 100.0000 (97.6461)  time: 0.3380  data: 0.0013  max mem: 2356
Train: Epoch[2/5]  [240/313]  eta: 0:00:24  Lr: 0.001875  Loss: 0.3807  Acc@1: 87.5000 (83.9990)  Acc@5: 100.0000 (97.5882)  time: 0.3421  data: 0.0014  max mem: 2356
Train: Epoch[2/5]  [250/313]  eta: 0:00:21  Lr: 0.001875  Loss: 0.7111  Acc@1: 81.2500 (83.8645)  Acc@5: 100.0000 (97.6096)  time: 0.3409  data: 0.0009  max mem: 2356
Train: Epoch[2/5]  [260/313]  eta: 0:00:17  Lr: 0.001875  Loss: 0.5188  Acc@1: 87.5000 (84.0038)  Acc@5: 100.0000 (97.6054)  time: 0.3393  data: 0.0009  max mem: 2356
Train: Epoch[2/5]  [270/313]  eta: 0:00:14  Lr: 0.001875  Loss: 0.1973  Acc@1: 81.2500 (83.9253)  Acc@5: 100.0000 (97.6245)  time: 0.3455  data: 0.0024  max mem: 2356
Train: Epoch[2/5]  [280/313]  eta: 0:00:11  Lr: 0.001875  Loss: 0.2943  Acc@1: 81.2500 (83.8968)  Acc@5: 100.0000 (97.6201)  time: 0.3455  data: 0.0037  max mem: 2356
Train: Epoch[2/5]  [290/313]  eta: 0:00:07  Lr: 0.001875  Loss: 0.4434  Acc@1: 81.2500 (83.8918)  Acc@5: 100.0000 (97.6375)  time: 0.3385  data: 0.0017  max mem: 2356
Train: Epoch[2/5]  [300/313]  eta: 0:00:04  Lr: 0.001875  Loss: 0.4188  Acc@1: 87.5000 (84.0324)  Acc@5: 100.0000 (97.6744)  time: 0.3336  data: 0.0005  max mem: 2356
Train: Epoch[2/5]  [310/313]  eta: 0:00:01  Lr: 0.001875  Loss: 0.1477  Acc@1: 87.5000 (84.0434)  Acc@5: 100.0000 (97.6889)  time: 0.3326  data: 0.0005  max mem: 2356
Train: Epoch[2/5]  [312/313]  eta: 0:00:00  Lr: 0.001875  Loss: -0.1249  Acc@1: 87.5000 (84.0800)  Acc@5: 100.0000 (97.7000)  time: 0.3243  data: 0.0004  max mem: 2356
Train: Epoch[2/5] Total time: 0:01:45 (0.3376 s / it)
{0: {0: 22412, 1: 9958, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}, 1: {0: 1577, 1: 20, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}, 2: {0: 3518, 1: 1922, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}, 3: {0: 21486, 1: 9701, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}, 4: {0: 16124, 1: 4166, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}, 5: {0: 23402, 1: 9989, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}, 6: {0: 9472, 1: 4268, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}, 7: {0: 752, 1: 0, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}, 8: {0: 24269, 1: 9975, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}, 9: {0: 1988, 1: 1, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}}
Averaged stats: Lr: 0.001875  Loss: -0.1249  Acc@1: 87.5000 (84.0800)  Acc@5: 100.0000 (97.7000)
Train: Epoch[3/5]  [  0/313]  eta: 0:03:03  Lr: 0.001875  Loss: 0.2726  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (100.0000)  time: 0.5874  data: 0.2519  max mem: 2356
Train: Epoch[3/5]  [ 10/313]  eta: 0:01:48  Lr: 0.001875  Loss: 0.2792  Acc@1: 87.5000 (85.7955)  Acc@5: 100.0000 (99.4318)  time: 0.3569  data: 0.0235  max mem: 2356
Train: Epoch[3/5]  [ 20/313]  eta: 0:01:41  Lr: 0.001875  Loss: 0.2558  Acc@1: 87.5000 (85.7143)  Acc@5: 100.0000 (98.8095)  time: 0.3332  data: 0.0005  max mem: 2356
Train: Epoch[3/5]  [ 30/313]  eta: 0:01:36  Lr: 0.001875  Loss: 0.0604  Acc@1: 87.5000 (84.8790)  Acc@5: 100.0000 (98.1855)  time: 0.3328  data: 0.0003  max mem: 2356
Train: Epoch[3/5]  [ 40/313]  eta: 0:01:32  Lr: 0.001875  Loss: -0.0773  Acc@1: 81.2500 (85.2134)  Acc@5: 100.0000 (98.1707)  time: 0.3347  data: 0.0004  max mem: 2356
Train: Epoch[3/5]  [ 50/313]  eta: 0:01:29  Lr: 0.001875  Loss: 0.0919  Acc@1: 87.5000 (85.5392)  Acc@5: 100.0000 (97.9167)  time: 0.3345  data: 0.0004  max mem: 2356
Train: Epoch[3/5]  [ 60/313]  eta: 0:01:25  Lr: 0.001875  Loss: 0.2208  Acc@1: 87.5000 (85.6557)  Acc@5: 100.0000 (98.1557)  time: 0.3329  data: 0.0004  max mem: 2356
Train: Epoch[3/5]  [ 70/313]  eta: 0:01:22  Lr: 0.001875  Loss: 0.4708  Acc@1: 87.5000 (85.6514)  Acc@5: 100.0000 (97.9754)  time: 0.3345  data: 0.0006  max mem: 2356
Train: Epoch[3/5]  [ 80/313]  eta: 0:01:18  Lr: 0.001875  Loss: 0.1378  Acc@1: 81.2500 (85.1852)  Acc@5: 100.0000 (97.9938)  time: 0.3325  data: 0.0005  max mem: 2356
Train: Epoch[3/5]  [ 90/313]  eta: 0:01:14  Lr: 0.001875  Loss: 0.2231  Acc@1: 87.5000 (85.8516)  Acc@5: 100.0000 (98.1456)  time: 0.3294  data: 0.0003  max mem: 2356
Train: Epoch[3/5]  [100/313]  eta: 0:01:11  Lr: 0.001875  Loss: 0.2782  Acc@1: 87.5000 (86.2005)  Acc@5: 100.0000 (98.2054)  time: 0.3315  data: 0.0010  max mem: 2356
Train: Epoch[3/5]  [110/313]  eta: 0:01:08  Lr: 0.001875  Loss: 0.0181  Acc@1: 87.5000 (86.3176)  Acc@5: 100.0000 (98.3108)  time: 0.3330  data: 0.0010  max mem: 2356
Train: Epoch[3/5]  [120/313]  eta: 0:01:04  Lr: 0.001875  Loss: 0.2759  Acc@1: 87.5000 (86.4153)  Acc@5: 100.0000 (98.1921)  time: 0.3332  data: 0.0003  max mem: 2356
Train: Epoch[3/5]  [130/313]  eta: 0:01:01  Lr: 0.001875  Loss: 0.8347  Acc@1: 87.5000 (86.2595)  Acc@5: 100.0000 (98.2347)  time: 0.3329  data: 0.0003  max mem: 2356
Train: Epoch[3/5]  [140/313]  eta: 0:00:57  Lr: 0.001875  Loss: 0.2516  Acc@1: 81.2500 (86.0372)  Acc@5: 100.0000 (98.1826)  time: 0.3313  data: 0.0003  max mem: 2356
Train: Epoch[3/5]  [150/313]  eta: 0:00:54  Lr: 0.001875  Loss: -0.0966  Acc@1: 81.2500 (86.1755)  Acc@5: 100.0000 (98.3030)  time: 0.3318  data: 0.0007  max mem: 2356
Train: Epoch[3/5]  [160/313]  eta: 0:00:51  Lr: 0.001875  Loss: 0.1545  Acc@1: 87.5000 (86.1413)  Acc@5: 100.0000 (98.3307)  time: 0.3330  data: 0.0008  max mem: 2356
Train: Epoch[3/5]  [170/313]  eta: 0:00:47  Lr: 0.001875  Loss: 0.0823  Acc@1: 87.5000 (86.2208)  Acc@5: 100.0000 (98.3553)  time: 0.3339  data: 0.0005  max mem: 2356
Train: Epoch[3/5]  [180/313]  eta: 0:00:44  Lr: 0.001875  Loss: -0.1479  Acc@1: 87.5000 (86.1188)  Acc@5: 100.0000 (98.3080)  time: 0.3362  data: 0.0006  max mem: 2356
Train: Epoch[3/5]  [190/313]  eta: 0:00:41  Lr: 0.001875  Loss: 0.0125  Acc@1: 87.5000 (86.1257)  Acc@5: 100.0000 (98.2984)  time: 0.3388  data: 0.0007  max mem: 2356
Train: Epoch[3/5]  [200/313]  eta: 0:00:37  Lr: 0.001875  Loss: 0.5242  Acc@1: 87.5000 (86.0075)  Acc@5: 100.0000 (98.1965)  time: 0.3381  data: 0.0009  max mem: 2356
Train: Epoch[3/5]  [210/313]  eta: 0:00:34  Lr: 0.001875  Loss: 0.2583  Acc@1: 81.2500 (85.9301)  Acc@5: 93.7500 (98.0746)  time: 0.3362  data: 0.0013  max mem: 2356
Train: Epoch[3/5]  [220/313]  eta: 0:00:31  Lr: 0.001875  Loss: 0.2503  Acc@1: 81.2500 (85.8032)  Acc@5: 100.0000 (98.0486)  time: 0.3394  data: 0.0016  max mem: 2356
Train: Epoch[3/5]  [230/313]  eta: 0:00:27  Lr: 0.001875  Loss: 0.9927  Acc@1: 81.2500 (85.8225)  Acc@5: 100.0000 (97.9978)  time: 0.3410  data: 0.0020  max mem: 2356
Train: Epoch[3/5]  [240/313]  eta: 0:00:24  Lr: 0.001875  Loss: 0.0579  Acc@1: 87.5000 (85.7884)  Acc@5: 100.0000 (97.9772)  time: 0.3428  data: 0.0013  max mem: 2356
Train: Epoch[3/5]  [250/313]  eta: 0:00:21  Lr: 0.001875  Loss: -0.0814  Acc@1: 87.5000 (85.9064)  Acc@5: 100.0000 (98.0329)  time: 0.3424  data: 0.0012  max mem: 2356
Train: Epoch[3/5]  [260/313]  eta: 0:00:17  Lr: 0.001875  Loss: 0.2963  Acc@1: 87.5000 (85.9195)  Acc@5: 100.0000 (97.9646)  time: 0.3395  data: 0.0013  max mem: 2356
Train: Epoch[3/5]  [270/313]  eta: 0:00:14  Lr: 0.001875  Loss: 0.1843  Acc@1: 81.2500 (85.7703)  Acc@5: 100.0000 (97.9244)  time: 0.3362  data: 0.0006  max mem: 2356
Train: Epoch[3/5]  [280/313]  eta: 0:00:11  Lr: 0.001875  Loss: 0.1346  Acc@1: 81.2500 (85.6984)  Acc@5: 100.0000 (97.9315)  time: 0.3348  data: 0.0027  max mem: 2356
Train: Epoch[3/5]  [290/313]  eta: 0:00:07  Lr: 0.001875  Loss: 0.0730  Acc@1: 87.5000 (85.8033)  Acc@5: 100.0000 (97.9381)  time: 0.3393  data: 0.0040  max mem: 2356
Train: Epoch[3/5]  [300/313]  eta: 0:00:04  Lr: 0.001875  Loss: 0.2666  Acc@1: 87.5000 (85.6520)  Acc@5: 100.0000 (97.8821)  time: 0.3410  data: 0.0025  max mem: 2356
Train: Epoch[3/5]  [310/313]  eta: 0:00:01  Lr: 0.001875  Loss: 0.2122  Acc@1: 87.5000 (85.6511)  Acc@5: 100.0000 (97.8698)  time: 0.3382  data: 0.0012  max mem: 2356
Train: Epoch[3/5]  [312/313]  eta: 0:00:00  Lr: 0.001875  Loss: 0.6742  Acc@1: 87.5000 (85.6600)  Acc@5: 100.0000 (97.8600)  time: 0.3322  data: 0.0004  max mem: 2356
Train: Epoch[3/5] Total time: 0:01:45 (0.3364 s / it)
{0: {0: 22412, 1: 14946, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}, 1: {0: 1577, 1: 38, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}, 2: {0: 3518, 1: 3295, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}, 3: {0: 21486, 1: 13910, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}, 4: {0: 16124, 1: 6182, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}, 5: {0: 23402, 1: 14982, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}, 6: {0: 9472, 1: 6663, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}, 7: {0: 752, 1: 10, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}, 8: {0: 24269, 1: 14973, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}, 9: {0: 1988, 1: 1, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}}
Averaged stats: Lr: 0.001875  Loss: 0.6742  Acc@1: 87.5000 (85.6600)  Acc@5: 100.0000 (97.8600)
Train: Epoch[4/5]  [  0/313]  eta: 0:04:12  Lr: 0.001875  Loss: 0.3120  Acc@1: 81.2500 (81.2500)  Acc@5: 100.0000 (100.0000)  time: 0.8071  data: 0.4690  max mem: 2356
Train: Epoch[4/5]  [ 10/313]  eta: 0:01:55  Lr: 0.001875  Loss: 0.0445  Acc@1: 93.7500 (89.7727)  Acc@5: 100.0000 (98.8636)  time: 0.3820  data: 0.0437  max mem: 2356
Train: Epoch[4/5]  [ 20/313]  eta: 0:01:44  Lr: 0.001875  Loss: 0.3920  Acc@1: 87.5000 (86.3095)  Acc@5: 100.0000 (98.5119)  time: 0.3354  data: 0.0007  max mem: 2356
Train: Epoch[4/5]  [ 30/313]  eta: 0:01:38  Lr: 0.001875  Loss: 0.2886  Acc@1: 87.5000 (86.2903)  Acc@5: 100.0000 (98.7903)  time: 0.3313  data: 0.0004  max mem: 2356
Train: Epoch[4/5]  [ 40/313]  eta: 0:01:34  Lr: 0.001875  Loss: 0.1424  Acc@1: 87.5000 (86.4329)  Acc@5: 100.0000 (98.4756)  time: 0.3316  data: 0.0004  max mem: 2356
Train: Epoch[4/5]  [ 50/313]  eta: 0:01:30  Lr: 0.001875  Loss: 0.2736  Acc@1: 87.5000 (86.0294)  Acc@5: 100.0000 (98.4069)  time: 0.3324  data: 0.0004  max mem: 2356
Train: Epoch[4/5]  [ 60/313]  eta: 0:01:26  Lr: 0.001875  Loss: -0.0817  Acc@1: 87.5000 (85.8607)  Acc@5: 100.0000 (98.4631)  time: 0.3339  data: 0.0009  max mem: 2356
Train: Epoch[4/5]  [ 70/313]  eta: 0:01:22  Lr: 0.001875  Loss: 0.1681  Acc@1: 87.5000 (85.7394)  Acc@5: 100.0000 (98.3275)  time: 0.3331  data: 0.0010  max mem: 2356
Train: Epoch[4/5]  [ 80/313]  eta: 0:01:19  Lr: 0.001875  Loss: 0.0831  Acc@1: 81.2500 (85.5710)  Acc@5: 100.0000 (98.1481)  time: 0.3319  data: 0.0005  max mem: 2356
Train: Epoch[4/5]  [ 90/313]  eta: 0:01:15  Lr: 0.001875  Loss: -0.1016  Acc@1: 87.5000 (86.5385)  Acc@5: 100.0000 (98.2830)  time: 0.3320  data: 0.0004  max mem: 2356
Train: Epoch[4/5]  [100/313]  eta: 0:01:11  Lr: 0.001875  Loss: 0.0315  Acc@1: 93.7500 (86.7574)  Acc@5: 100.0000 (98.2673)  time: 0.3336  data: 0.0013  max mem: 2356
Train: Epoch[4/5]  [110/313]  eta: 0:01:08  Lr: 0.001875  Loss: 0.0141  Acc@1: 87.5000 (86.6554)  Acc@5: 100.0000 (98.3671)  time: 0.3342  data: 0.0013  max mem: 2356
Train: Epoch[4/5]  [120/313]  eta: 0:01:05  Lr: 0.001875  Loss: 0.4785  Acc@1: 87.5000 (86.7769)  Acc@5: 100.0000 (98.3988)  time: 0.3313  data: 0.0004  max mem: 2356
Train: Epoch[4/5]  [130/313]  eta: 0:01:01  Lr: 0.001875  Loss: 0.5003  Acc@1: 87.5000 (86.6412)  Acc@5: 100.0000 (98.4733)  time: 0.3293  data: 0.0004  max mem: 2356
Train: Epoch[4/5]  [140/313]  eta: 0:00:58  Lr: 0.001875  Loss: 0.0327  Acc@1: 81.2500 (86.6578)  Acc@5: 100.0000 (98.4486)  time: 0.3311  data: 0.0004  max mem: 2356
Train: Epoch[4/5]  [150/313]  eta: 0:00:54  Lr: 0.001875  Loss: 0.1488  Acc@1: 87.5000 (86.5894)  Acc@5: 100.0000 (98.4685)  time: 0.3320  data: 0.0005  max mem: 2356
Train: Epoch[4/5]  [160/313]  eta: 0:00:51  Lr: 0.001875  Loss: 0.0638  Acc@1: 87.5000 (86.5683)  Acc@5: 100.0000 (98.4860)  time: 0.3301  data: 0.0005  max mem: 2356
Train: Epoch[4/5]  [170/313]  eta: 0:00:47  Lr: 0.001875  Loss: -0.1854  Acc@1: 87.5000 (86.5132)  Acc@5: 100.0000 (98.5015)  time: 0.3308  data: 0.0003  max mem: 2356
Train: Epoch[4/5]  [180/313]  eta: 0:00:44  Lr: 0.001875  Loss: 0.3273  Acc@1: 81.2500 (86.3260)  Acc@5: 100.0000 (98.4807)  time: 0.3317  data: 0.0003  max mem: 2356
Train: Epoch[4/5]  [190/313]  eta: 0:00:41  Lr: 0.001875  Loss: 0.3313  Acc@1: 81.2500 (86.4202)  Acc@5: 100.0000 (98.5275)  time: 0.3318  data: 0.0010  max mem: 2356
Train: Epoch[4/5]  [200/313]  eta: 0:00:37  Lr: 0.001875  Loss: 0.6746  Acc@1: 87.5000 (86.5050)  Acc@5: 100.0000 (98.4764)  time: 0.3331  data: 0.0010  max mem: 2356
Train: Epoch[4/5]  [210/313]  eta: 0:00:34  Lr: 0.001875  Loss: 0.2477  Acc@1: 87.5000 (86.6114)  Acc@5: 100.0000 (98.4893)  time: 0.3355  data: 0.0011  max mem: 2356
Train: Epoch[4/5]  [220/313]  eta: 0:00:31  Lr: 0.001875  Loss: 0.1857  Acc@1: 87.5000 (86.6516)  Acc@5: 100.0000 (98.5577)  time: 0.3364  data: 0.0013  max mem: 2356
Train: Epoch[4/5]  [230/313]  eta: 0:00:27  Lr: 0.001875  Loss: 0.1388  Acc@1: 87.5000 (86.7154)  Acc@5: 100.0000 (98.5119)  time: 0.3348  data: 0.0009  max mem: 2356
Train: Epoch[4/5]  [240/313]  eta: 0:00:24  Lr: 0.001875  Loss: 0.0528  Acc@1: 87.5000 (86.7739)  Acc@5: 100.0000 (98.5218)  time: 0.3354  data: 0.0006  max mem: 2356
Train: Epoch[4/5]  [250/313]  eta: 0:00:21  Lr: 0.001875  Loss: -0.0354  Acc@1: 87.5000 (86.6285)  Acc@5: 100.0000 (98.5309)  time: 0.3373  data: 0.0019  max mem: 2356
Train: Epoch[4/5]  [260/313]  eta: 0:00:17  Lr: 0.001875  Loss: 0.4942  Acc@1: 87.5000 (86.6140)  Acc@5: 100.0000 (98.5632)  time: 0.3389  data: 0.0021  max mem: 2356
Train: Epoch[4/5]  [270/313]  eta: 0:00:14  Lr: 0.001875  Loss: 0.1592  Acc@1: 87.5000 (86.6006)  Acc@5: 100.0000 (98.5470)  time: 0.3410  data: 0.0006  max mem: 2356
Train: Epoch[4/5]  [280/313]  eta: 0:00:11  Lr: 0.001875  Loss: 0.0407  Acc@1: 87.5000 (86.6326)  Acc@5: 100.0000 (98.5765)  time: 0.3381  data: 0.0005  max mem: 2356
Train: Epoch[4/5]  [290/313]  eta: 0:00:07  Lr: 0.001875  Loss: 0.1028  Acc@1: 87.5000 (86.6194)  Acc@5: 100.0000 (98.5825)  time: 0.3382  data: 0.0010  max mem: 2356
Train: Epoch[4/5]  [300/313]  eta: 0:00:04  Lr: 0.001875  Loss: -0.0656  Acc@1: 87.5000 (86.6902)  Acc@5: 100.0000 (98.6296)  time: 0.3415  data: 0.0012  max mem: 2356
Train: Epoch[4/5]  [310/313]  eta: 0:00:01  Lr: 0.001875  Loss: 0.1944  Acc@1: 87.5000 (86.7765)  Acc@5: 100.0000 (98.6334)  time: 0.3429  data: 0.0005  max mem: 2356
Train: Epoch[4/5]  [312/313]  eta: 0:00:00  Lr: 0.001875  Loss: -0.0109  Acc@1: 87.5000 (86.7800)  Acc@5: 100.0000 (98.6400)  time: 0.3361  data: 0.0005  max mem: 2356
Train: Epoch[4/5] Total time: 0:01:45 (0.3365 s / it)
{0: {0: 22412, 1: 19923, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}, 1: {0: 1577, 1: 66, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}, 2: {0: 3518, 1: 5041, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}, 3: {0: 21486, 1: 17453, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}, 4: {0: 16124, 1: 8243, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}, 5: {0: 23402, 1: 19809, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}, 6: {0: 9472, 1: 9289, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}, 7: {0: 752, 1: 198, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}, 8: {0: 24269, 1: 19973, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}, 9: {0: 1988, 1: 5, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}}
Averaged stats: Lr: 0.001875  Loss: -0.0109  Acc@1: 87.5000 (86.7800)  Acc@5: 100.0000 (98.6400)
Train: Epoch[5/5]  [  0/313]  eta: 0:04:13  Lr: 0.001875  Loss: 0.0402  Acc@1: 93.7500 (93.7500)  Acc@5: 100.0000 (100.0000)  time: 0.8101  data: 0.4721  max mem: 2356
Train: Epoch[5/5]  [ 10/313]  eta: 0:01:54  Lr: 0.001875  Loss: 0.0985  Acc@1: 87.5000 (86.3636)  Acc@5: 100.0000 (99.4318)  time: 0.3764  data: 0.0433  max mem: 2356
Train: Epoch[5/5]  [ 20/313]  eta: 0:01:45  Lr: 0.001875  Loss: 0.0994  Acc@1: 87.5000 (87.7976)  Acc@5: 100.0000 (99.4048)  time: 0.3360  data: 0.0007  max mem: 2356
Train: Epoch[5/5]  [ 30/313]  eta: 0:01:39  Lr: 0.001875  Loss: 0.2458  Acc@1: 87.5000 (87.0968)  Acc@5: 100.0000 (99.3952)  time: 0.3402  data: 0.0014  max mem: 2356
Train: Epoch[5/5]  [ 40/313]  eta: 0:01:35  Lr: 0.001875  Loss: 0.1657  Acc@1: 87.5000 (86.5854)  Acc@5: 100.0000 (98.9329)  time: 0.3406  data: 0.0025  max mem: 2356
Train: Epoch[5/5]  [ 50/313]  eta: 0:01:31  Lr: 0.001875  Loss: 0.0975  Acc@1: 87.5000 (86.5196)  Acc@5: 100.0000 (98.8971)  time: 0.3395  data: 0.0026  max mem: 2356
Train: Epoch[5/5]  [ 60/313]  eta: 0:01:27  Lr: 0.001875  Loss: 0.0797  Acc@1: 81.2500 (86.2705)  Acc@5: 100.0000 (98.8730)  time: 0.3366  data: 0.0012  max mem: 2356
Train: Epoch[5/5]  [ 70/313]  eta: 0:01:23  Lr: 0.001875  Loss: 0.0192  Acc@1: 87.5000 (86.2676)  Acc@5: 100.0000 (99.0317)  time: 0.3336  data: 0.0003  max mem: 2356
Train: Epoch[5/5]  [ 80/313]  eta: 0:01:19  Lr: 0.001875  Loss: -0.0387  Acc@1: 93.7500 (86.5741)  Acc@5: 100.0000 (99.1512)  time: 0.3341  data: 0.0013  max mem: 2356
Train: Epoch[5/5]  [ 90/313]  eta: 0:01:16  Lr: 0.001875  Loss: 0.4004  Acc@1: 87.5000 (86.6071)  Acc@5: 100.0000 (98.9698)  time: 0.3347  data: 0.0014  max mem: 2356
Train: Epoch[5/5]  [100/313]  eta: 0:01:12  Lr: 0.001875  Loss: -0.1910  Acc@1: 87.5000 (86.9431)  Acc@5: 100.0000 (98.8861)  time: 0.3346  data: 0.0004  max mem: 2356
Train: Epoch[5/5]  [110/313]  eta: 0:01:09  Lr: 0.001875  Loss: 0.1104  Acc@1: 93.7500 (87.3311)  Acc@5: 100.0000 (98.8176)  time: 0.3341  data: 0.0004  max mem: 2356
Train: Epoch[5/5]  [120/313]  eta: 0:01:05  Lr: 0.001875  Loss: -0.0008  Acc@1: 87.5000 (87.3450)  Acc@5: 100.0000 (98.7603)  time: 0.3334  data: 0.0005  max mem: 2356
Train: Epoch[5/5]  [130/313]  eta: 0:01:02  Lr: 0.001875  Loss: -0.0657  Acc@1: 87.5000 (87.3092)  Acc@5: 100.0000 (98.7118)  time: 0.3334  data: 0.0004  max mem: 2356
Train: Epoch[5/5]  [140/313]  eta: 0:00:58  Lr: 0.001875  Loss: -0.0975  Acc@1: 87.5000 (87.1011)  Acc@5: 100.0000 (98.7145)  time: 0.3338  data: 0.0003  max mem: 2356
Train: Epoch[5/5]  [150/313]  eta: 0:00:55  Lr: 0.001875  Loss: -0.1903  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (98.7169)  time: 0.3335  data: 0.0004  max mem: 2356
Train: Epoch[5/5]  [160/313]  eta: 0:00:51  Lr: 0.001875  Loss: -0.1590  Acc@1: 87.5000 (87.4612)  Acc@5: 100.0000 (98.7189)  time: 0.3311  data: 0.0004  max mem: 2356
Train: Epoch[5/5]  [170/313]  eta: 0:00:48  Lr: 0.001875  Loss: 0.0937  Acc@1: 87.5000 (87.3173)  Acc@5: 100.0000 (98.7208)  time: 0.3302  data: 0.0003  max mem: 2356
Train: Epoch[5/5]  [180/313]  eta: 0:00:44  Lr: 0.001875  Loss: 0.0658  Acc@1: 87.5000 (87.2583)  Acc@5: 100.0000 (98.6533)  time: 0.3309  data: 0.0002  max mem: 2356
Train: Epoch[5/5]  [190/313]  eta: 0:00:41  Lr: 0.001875  Loss: 0.1848  Acc@1: 87.5000 (87.1073)  Acc@5: 100.0000 (98.5929)  time: 0.3315  data: 0.0007  max mem: 2356
Train: Epoch[5/5]  [200/313]  eta: 0:00:38  Lr: 0.001875  Loss: 0.1609  Acc@1: 87.5000 (87.2201)  Acc@5: 100.0000 (98.6007)  time: 0.3323  data: 0.0007  max mem: 2356
Train: Epoch[5/5]  [210/313]  eta: 0:00:34  Lr: 0.001875  Loss: 0.3906  Acc@1: 87.5000 (87.2038)  Acc@5: 100.0000 (98.5190)  time: 0.3325  data: 0.0004  max mem: 2356
Train: Epoch[5/5]  [220/313]  eta: 0:00:31  Lr: 0.001875  Loss: 0.0981  Acc@1: 87.5000 (87.4717)  Acc@5: 100.0000 (98.5577)  time: 0.3308  data: 0.0003  max mem: 2356
Train: Epoch[5/5]  [230/313]  eta: 0:00:27  Lr: 0.001875  Loss: -0.1128  Acc@1: 93.7500 (87.6353)  Acc@5: 100.0000 (98.5660)  time: 0.3303  data: 0.0003  max mem: 2356
Train: Epoch[5/5]  [240/313]  eta: 0:00:24  Lr: 0.001875  Loss: -0.0999  Acc@1: 87.5000 (87.5778)  Acc@5: 100.0000 (98.5737)  time: 0.3339  data: 0.0004  max mem: 2356
Train: Epoch[5/5]  [250/313]  eta: 0:00:21  Lr: 0.001875  Loss: -0.1545  Acc@1: 87.5000 (87.5249)  Acc@5: 100.0000 (98.5309)  time: 0.3382  data: 0.0013  max mem: 2356
Train: Epoch[5/5]  [260/313]  eta: 0:00:17  Lr: 0.001875  Loss: 0.2871  Acc@1: 87.5000 (87.5239)  Acc@5: 100.0000 (98.5632)  time: 0.3391  data: 0.0015  max mem: 2356
Train: Epoch[5/5]  [270/313]  eta: 0:00:14  Lr: 0.001875  Loss: 0.4573  Acc@1: 87.5000 (87.3847)  Acc@5: 100.0000 (98.4779)  time: 0.3392  data: 0.0027  max mem: 2356
Train: Epoch[5/5]  [280/313]  eta: 0:00:11  Lr: 0.001875  Loss: -0.0014  Acc@1: 81.2500 (87.3443)  Acc@5: 100.0000 (98.5320)  time: 0.3396  data: 0.0025  max mem: 2356
Train: Epoch[5/5]  [290/313]  eta: 0:00:07  Lr: 0.001875  Loss: 0.1005  Acc@1: 87.5000 (87.2637)  Acc@5: 100.0000 (98.5610)  time: 0.3371  data: 0.0005  max mem: 2356
Train: Epoch[5/5]  [300/313]  eta: 0:00:04  Lr: 0.001875  Loss: 0.1357  Acc@1: 87.5000 (87.2508)  Acc@5: 100.0000 (98.5465)  time: 0.3356  data: 0.0011  max mem: 2356
Train: Epoch[5/5]  [310/313]  eta: 0:00:01  Lr: 0.001875  Loss: 0.2787  Acc@1: 87.5000 (87.2789)  Acc@5: 100.0000 (98.5330)  time: 0.3364  data: 0.0011  max mem: 2356
Train: Epoch[5/5]  [312/313]  eta: 0:00:00  Lr: 0.001875  Loss: 0.6374  Acc@1: 87.5000 (87.2600)  Acc@5: 100.0000 (98.5000)  time: 0.3289  data: 0.0011  max mem: 2356
Train: Epoch[5/5] Total time: 0:01:45 (0.3364 s / it)
{0: {0: 22412, 1: 24815, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}, 1: {0: 1577, 1: 208, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}, 2: {0: 3518, 1: 6779, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}, 3: {0: 21486, 1: 20777, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}, 4: {0: 16124, 1: 10227, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}, 5: {0: 23402, 1: 24357, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}, 6: {0: 9472, 1: 12148, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}, 7: {0: 752, 1: 676, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}, 8: {0: 24269, 1: 24959, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}, 9: {0: 1988, 1: 54, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}}
Averaged stats: Lr: 0.001875  Loss: 0.6374  Acc@1: 87.5000 (87.2600)  Acc@5: 100.0000 (98.5000)
Test: [Task 1]  [ 0/63]  eta: 0:00:44  Loss: 0.4789 (0.4789)  Acc@1: 93.7500 (93.7500)  Acc@5: 100.0000 (100.0000)  time: 0.7032  data: 0.4896  max mem: 2356
Test: [Task 1]  [10/63]  eta: 0:00:13  Loss: 0.4487 (0.4661)  Acc@1: 93.7500 (91.4773)  Acc@5: 100.0000 (100.0000)  time: 0.2534  data: 0.0471  max mem: 2356
Test: [Task 1]  [20/63]  eta: 0:00:10  Loss: 0.4481 (0.5326)  Acc@1: 93.7500 (89.8810)  Acc@5: 100.0000 (100.0000)  time: 0.2104  data: 0.0027  max mem: 2356
Test: [Task 1]  [30/63]  eta: 0:00:07  Loss: 0.4157 (0.4920)  Acc@1: 93.7500 (90.3226)  Acc@5: 100.0000 (100.0000)  time: 0.2096  data: 0.0022  max mem: 2356
Test: [Task 1]  [40/63]  eta: 0:00:05  Loss: 0.4138 (0.4927)  Acc@1: 93.7500 (91.1585)  Acc@5: 100.0000 (100.0000)  time: 0.2081  data: 0.0010  max mem: 2356
Test: [Task 1]  [50/63]  eta: 0:00:02  Loss: 0.4211 (0.4743)  Acc@1: 93.7500 (91.9118)  Acc@5: 100.0000 (99.8775)  time: 0.2084  data: 0.0011  max mem: 2356
Test: [Task 1]  [60/63]  eta: 0:00:00  Loss: 0.4211 (0.4685)  Acc@1: 93.7500 (92.4180)  Acc@5: 100.0000 (99.7951)  time: 0.2085  data: 0.0011  max mem: 2356
Test: [Task 1]  [62/63]  eta: 0:00:00  Loss: 0.4211 (0.4683)  Acc@1: 93.7500 (92.6000)  Acc@5: 100.0000 (99.8000)  time: 0.2048  data: 0.0010  max mem: 2356
Test: [Task 1] Total time: 0:00:13 (0.2171 s / it)
* Acc@1 92.600 Acc@5 99.800 loss 0.468
Test: [Task 2]  [ 0/63]  eta: 0:00:41  Loss: 0.5422 (0.5422)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)  time: 0.6621  data: 0.4557  max mem: 2356
Test: [Task 2]  [10/63]  eta: 0:00:13  Loss: 0.5167 (0.5341)  Acc@1: 93.7500 (96.0227)  Acc@5: 100.0000 (99.4318)  time: 0.2501  data: 0.0428  max mem: 2356
Test: [Task 2]  [20/63]  eta: 0:00:09  Loss: 0.5212 (0.6104)  Acc@1: 93.7500 (94.9405)  Acc@5: 100.0000 (99.4048)  time: 0.2082  data: 0.0020  max mem: 2356
Test: [Task 2]  [30/63]  eta: 0:00:07  Loss: 0.6276 (0.6021)  Acc@1: 93.7500 (94.3548)  Acc@5: 100.0000 (98.9919)  time: 0.2085  data: 0.0015  max mem: 2356
Test: [Task 2]  [40/63]  eta: 0:00:05  Loss: 0.5924 (0.5850)  Acc@1: 93.7500 (94.8171)  Acc@5: 100.0000 (99.0854)  time: 0.2101  data: 0.0008  max mem: 2356
Test: [Task 2]  [50/63]  eta: 0:00:02  Loss: 0.4634 (0.5774)  Acc@1: 93.7500 (94.3627)  Acc@5: 100.0000 (99.0196)  time: 0.2098  data: 0.0014  max mem: 2356
Test: [Task 2]  [60/63]  eta: 0:00:00  Loss: 0.4723 (0.5610)  Acc@1: 93.7500 (94.4672)  Acc@5: 100.0000 (99.1803)  time: 0.2097  data: 0.0017  max mem: 2356
Test: [Task 2]  [62/63]  eta: 0:00:00  Loss: 0.4662 (0.5514)  Acc@1: 93.7500 (94.6000)  Acc@5: 100.0000 (99.2000)  time: 0.2048  data: 0.0017  max mem: 2356
Test: [Task 2] Total time: 0:00:13 (0.2179 s / it)
* Acc@1 94.600 Acc@5 99.200 loss 0.551
{0: {0: 846, 1: 219, 2: 292, 3: 658, 4: 381, 5: 682, 6: 488, 7: 271, 8: 951, 9: 212}, 1: {0: 884, 1: 130, 2: 519, 3: 472, 4: 616, 5: 812, 6: 341, 7: 186, 8: 914, 9: 126}}
[Average accuracy till task2]	Acc@1: 93.6000	Acc@5: 99.5000	Loss: 0.5099	Forgetting: 4.7000	Backward: -4.7000
Train: Epoch[1/5]  [  0/313]  eta: 0:03:49  Lr: 0.001875  Loss: 2.0611  Acc@1: 0.0000 (0.0000)  Acc@5: 62.5000 (62.5000)  time: 0.7335  data: 0.3728  max mem: 2356
Train: Epoch[1/5]  [ 10/313]  eta: 0:01:51  Lr: 0.001875  Loss: 1.7597  Acc@1: 56.2500 (44.8864)  Acc@5: 81.2500 (80.6818)  time: 0.3684  data: 0.0344  max mem: 2356
Train: Epoch[1/5]  [ 20/313]  eta: 0:01:43  Lr: 0.001875  Loss: 1.6201  Acc@1: 62.5000 (58.0357)  Acc@5: 93.7500 (85.7143)  time: 0.3326  data: 0.0005  max mem: 2356
Train: Epoch[1/5]  [ 30/313]  eta: 0:01:37  Lr: 0.001875  Loss: 1.4813  Acc@1: 75.0000 (63.5081)  Acc@5: 93.7500 (89.7177)  time: 0.3326  data: 0.0004  max mem: 2356
Train: Epoch[1/5]  [ 40/313]  eta: 0:01:33  Lr: 0.001875  Loss: 1.2956  Acc@1: 81.2500 (67.8354)  Acc@5: 100.0000 (91.1585)  time: 0.3322  data: 0.0004  max mem: 2356
Train: Epoch[1/5]  [ 50/313]  eta: 0:01:29  Lr: 0.001875  Loss: 0.7877  Acc@1: 87.5000 (70.5882)  Acc@5: 93.7500 (91.7892)  time: 0.3339  data: 0.0004  max mem: 2356
Train: Epoch[1/5]  [ 60/313]  eta: 0:01:25  Lr: 0.001875  Loss: 0.7919  Acc@1: 81.2500 (71.7213)  Acc@5: 93.7500 (92.5205)  time: 0.3340  data: 0.0004  max mem: 2356
Train: Epoch[1/5]  [ 70/313]  eta: 0:01:22  Lr: 0.001875  Loss: 0.6462  Acc@1: 75.0000 (73.0634)  Acc@5: 93.7500 (92.6937)  time: 0.3326  data: 0.0005  max mem: 2356
Train: Epoch[1/5]  [ 80/313]  eta: 0:01:18  Lr: 0.001875  Loss: 0.4815  Acc@1: 81.2500 (73.9198)  Acc@5: 100.0000 (93.3642)  time: 0.3323  data: 0.0004  max mem: 2356
Train: Epoch[1/5]  [ 90/313]  eta: 0:01:15  Lr: 0.001875  Loss: 0.9300  Acc@1: 81.2500 (74.5192)  Acc@5: 100.0000 (93.7500)  time: 0.3339  data: 0.0004  max mem: 2356
Train: Epoch[1/5]  [100/313]  eta: 0:01:11  Lr: 0.001875  Loss: 0.5176  Acc@1: 81.2500 (75.6807)  Acc@5: 100.0000 (94.1213)  time: 0.3360  data: 0.0005  max mem: 2356
Train: Epoch[1/5]  [110/313]  eta: 0:01:08  Lr: 0.001875  Loss: 0.4417  Acc@1: 87.5000 (76.4077)  Acc@5: 100.0000 (94.3694)  time: 0.3343  data: 0.0003  max mem: 2356
Train: Epoch[1/5]  [120/313]  eta: 0:01:04  Lr: 0.001875  Loss: 0.3825  Acc@1: 81.2500 (77.0661)  Acc@5: 100.0000 (94.6281)  time: 0.3312  data: 0.0003  max mem: 2356
Train: Epoch[1/5]  [130/313]  eta: 0:01:01  Lr: 0.001875  Loss: 0.3749  Acc@1: 81.2500 (77.4332)  Acc@5: 100.0000 (94.8473)  time: 0.3313  data: 0.0003  max mem: 2356
Train: Epoch[1/5]  [140/313]  eta: 0:00:58  Lr: 0.001875  Loss: 0.5107  Acc@1: 81.2500 (77.6152)  Acc@5: 100.0000 (95.0355)  time: 0.3326  data: 0.0003  max mem: 2356
Train: Epoch[1/5]  [150/313]  eta: 0:00:54  Lr: 0.001875  Loss: 0.6879  Acc@1: 81.2500 (77.8146)  Acc@5: 100.0000 (95.1987)  time: 0.3331  data: 0.0004  max mem: 2356
Train: Epoch[1/5]  [160/313]  eta: 0:00:51  Lr: 0.001875  Loss: 0.1727  Acc@1: 81.2500 (78.1444)  Acc@5: 100.0000 (95.3804)  time: 0.3339  data: 0.0010  max mem: 2356
Train: Epoch[1/5]  [170/313]  eta: 0:00:47  Lr: 0.001875  Loss: 0.7036  Acc@1: 81.2500 (78.3626)  Acc@5: 100.0000 (95.6140)  time: 0.3338  data: 0.0019  max mem: 2356
Train: Epoch[1/5]  [180/313]  eta: 0:00:44  Lr: 0.001875  Loss: 0.3769  Acc@1: 81.2500 (78.7638)  Acc@5: 100.0000 (95.6837)  time: 0.3334  data: 0.0012  max mem: 2356
Train: Epoch[1/5]  [190/313]  eta: 0:00:41  Lr: 0.001875  Loss: 0.1856  Acc@1: 87.5000 (79.0249)  Acc@5: 100.0000 (95.8115)  time: 0.3323  data: 0.0003  max mem: 2356
Train: Epoch[1/5]  [200/313]  eta: 0:00:37  Lr: 0.001875  Loss: 0.3549  Acc@1: 81.2500 (79.1978)  Acc@5: 100.0000 (95.8955)  time: 0.3350  data: 0.0006  max mem: 2356
Train: Epoch[1/5]  [210/313]  eta: 0:00:34  Lr: 0.001875  Loss: 0.1726  Acc@1: 81.2500 (79.5616)  Acc@5: 100.0000 (96.0604)  time: 0.3376  data: 0.0013  max mem: 2356
Train: Epoch[1/5]  [220/313]  eta: 0:00:31  Lr: 0.001875  Loss: 0.2646  Acc@1: 87.5000 (79.9208)  Acc@5: 100.0000 (96.1821)  time: 0.3388  data: 0.0016  max mem: 2356
Train: Epoch[1/5]  [230/313]  eta: 0:00:27  Lr: 0.001875  Loss: 0.3358  Acc@1: 87.5000 (80.0866)  Acc@5: 100.0000 (96.2121)  time: 0.3403  data: 0.0026  max mem: 2356
Train: Epoch[1/5]  [240/313]  eta: 0:00:24  Lr: 0.001875  Loss: 0.5323  Acc@1: 87.5000 (80.4979)  Acc@5: 100.0000 (96.3434)  time: 0.3378  data: 0.0030  max mem: 2356
Train: Epoch[1/5]  [250/313]  eta: 0:00:21  Lr: 0.001875  Loss: 0.7267  Acc@1: 87.5000 (80.7022)  Acc@5: 100.0000 (96.4143)  time: 0.3375  data: 0.0016  max mem: 2356
Train: Epoch[1/5]  [260/313]  eta: 0:00:17  Lr: 0.001875  Loss: 0.1598  Acc@1: 87.5000 (80.8429)  Acc@5: 100.0000 (96.5038)  time: 0.3375  data: 0.0011  max mem: 2356
Train: Epoch[1/5]  [270/313]  eta: 0:00:14  Lr: 0.001875  Loss: 0.2020  Acc@1: 87.5000 (81.0424)  Acc@5: 100.0000 (96.5175)  time: 0.3383  data: 0.0014  max mem: 2356
Train: Epoch[1/5]  [280/313]  eta: 0:00:11  Lr: 0.001875  Loss: 0.3997  Acc@1: 81.2500 (81.1165)  Acc@5: 100.0000 (96.5747)  time: 0.3391  data: 0.0016  max mem: 2356
Train: Epoch[1/5]  [290/313]  eta: 0:00:07  Lr: 0.001875  Loss: 0.0216  Acc@1: 81.2500 (81.2715)  Acc@5: 100.0000 (96.6280)  time: 0.3430  data: 0.0017  max mem: 2356
Train: Epoch[1/5]  [300/313]  eta: 0:00:04  Lr: 0.001875  Loss: 0.0212  Acc@1: 87.5000 (81.4576)  Acc@5: 100.0000 (96.6985)  time: 0.3442  data: 0.0011  max mem: 2356
Train: Epoch[1/5]  [310/313]  eta: 0:00:01  Lr: 0.001875  Loss: 0.3858  Acc@1: 87.5000 (81.5715)  Acc@5: 100.0000 (96.7243)  time: 0.3379  data: 0.0009  max mem: 2356
Train: Epoch[1/5]  [312/313]  eta: 0:00:00  Lr: 0.001875  Loss: -0.0063  Acc@1: 87.5000 (81.6400)  Acc@5: 100.0000 (96.7400)  time: 0.3293  data: 0.0009  max mem: 2356
Train: Epoch[1/5] Total time: 0:01:45 (0.3368 s / it)
{0: {0: 22412, 1: 24815, 2: 4533, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}, 1: {0: 1577, 1: 208, 2: 483, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}, 2: {0: 3518, 1: 6779, 2: 934, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}, 3: {0: 21486, 1: 20777, 2: 4026, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}, 4: {0: 16124, 1: 10227, 2: 1134, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}, 5: {0: 23402, 1: 24357, 2: 4905, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}, 6: {0: 9472, 1: 12148, 2: 3801, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}, 7: {0: 752, 1: 676, 2: 177, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}, 8: {0: 24269, 1: 24959, 2: 5000, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}, 9: {0: 1988, 1: 54, 2: 7, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}}
Averaged stats: Lr: 0.001875  Loss: -0.0063  Acc@1: 87.5000 (81.6400)  Acc@5: 100.0000 (96.7400)
Train: Epoch[2/5]  [  0/313]  eta: 0:04:01  Lr: 0.001875  Loss: 0.0046  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)  time: 0.7708  data: 0.4283  max mem: 2356
Train: Epoch[2/5]  [ 10/313]  eta: 0:01:53  Lr: 0.001875  Loss: 0.0030  Acc@1: 93.7500 (90.9091)  Acc@5: 100.0000 (97.7273)  time: 0.3761  data: 0.0400  max mem: 2356
Train: Epoch[2/5]  [ 20/313]  eta: 0:01:44  Lr: 0.001875  Loss: 0.1111  Acc@1: 87.5000 (86.3095)  Acc@5: 100.0000 (98.5119)  time: 0.3368  data: 0.0008  max mem: 2356
Train: Epoch[2/5]  [ 30/313]  eta: 0:01:39  Lr: 0.001875  Loss: 0.3800  Acc@1: 81.2500 (86.2903)  Acc@5: 100.0000 (98.5887)  time: 0.3405  data: 0.0015  max mem: 2356
Train: Epoch[2/5]  [ 40/313]  eta: 0:01:35  Lr: 0.001875  Loss: 0.2242  Acc@1: 81.2500 (85.9756)  Acc@5: 100.0000 (98.6280)  time: 0.3414  data: 0.0020  max mem: 2356
Train: Epoch[2/5]  [ 50/313]  eta: 0:01:32  Lr: 0.001875  Loss: -0.0298  Acc@1: 87.5000 (86.8873)  Acc@5: 100.0000 (98.6520)  time: 0.3451  data: 0.0016  max mem: 2356
Train: Epoch[2/5]  [ 60/313]  eta: 0:01:27  Lr: 0.001875  Loss: 0.1473  Acc@1: 87.5000 (86.6803)  Acc@5: 100.0000 (98.6680)  time: 0.3420  data: 0.0012  max mem: 2356
Train: Epoch[2/5]  [ 70/313]  eta: 0:01:23  Lr: 0.001875  Loss: 0.1479  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (98.7676)  time: 0.3328  data: 0.0005  max mem: 2356
Train: Epoch[2/5]  [ 80/313]  eta: 0:01:20  Lr: 0.001875  Loss: 0.2452  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (98.7654)  time: 0.3331  data: 0.0005  max mem: 2356
Train: Epoch[2/5]  [ 90/313]  eta: 0:01:16  Lr: 0.001875  Loss: 0.1623  Acc@1: 87.5000 (87.0879)  Acc@5: 100.0000 (98.7637)  time: 0.3359  data: 0.0009  max mem: 2356
Train: Epoch[2/5]  [100/313]  eta: 0:01:12  Lr: 0.001875  Loss: 0.2364  Acc@1: 81.2500 (86.6955)  Acc@5: 100.0000 (98.6386)  time: 0.3352  data: 0.0008  max mem: 2356
Train: Epoch[2/5]  [110/313]  eta: 0:01:09  Lr: 0.001875  Loss: 0.1031  Acc@1: 87.5000 (86.9932)  Acc@5: 100.0000 (98.5923)  time: 0.3323  data: 0.0004  max mem: 2356
Train: Epoch[2/5]  [120/313]  eta: 0:01:05  Lr: 0.001875  Loss: 0.3823  Acc@1: 93.7500 (87.1384)  Acc@5: 100.0000 (98.6570)  time: 0.3343  data: 0.0019  max mem: 2356
Train: Epoch[2/5]  [130/313]  eta: 0:01:02  Lr: 0.001875  Loss: 0.1953  Acc@1: 87.5000 (86.9275)  Acc@5: 100.0000 (98.6164)  time: 0.3344  data: 0.0019  max mem: 2356
Train: Epoch[2/5]  [140/313]  eta: 0:00:58  Lr: 0.001875  Loss: 0.4561  Acc@1: 87.5000 (87.0124)  Acc@5: 100.0000 (98.6259)  time: 0.3325  data: 0.0004  max mem: 2356
Train: Epoch[2/5]  [150/313]  eta: 0:00:55  Lr: 0.001875  Loss: 0.2952  Acc@1: 87.5000 (86.7136)  Acc@5: 100.0000 (98.5927)  time: 0.3330  data: 0.0004  max mem: 2356
Train: Epoch[2/5]  [160/313]  eta: 0:00:51  Lr: 0.001875  Loss: 0.0106  Acc@1: 87.5000 (87.0342)  Acc@5: 100.0000 (98.6025)  time: 0.3332  data: 0.0003  max mem: 2356
Train: Epoch[2/5]  [170/313]  eta: 0:00:48  Lr: 0.001875  Loss: 0.1789  Acc@1: 93.7500 (87.1345)  Acc@5: 100.0000 (98.5380)  time: 0.3327  data: 0.0010  max mem: 2356
Train: Epoch[2/5]  [180/313]  eta: 0:00:44  Lr: 0.001875  Loss: 0.2152  Acc@1: 81.2500 (86.8785)  Acc@5: 100.0000 (98.4116)  time: 0.3324  data: 0.0015  max mem: 2356
Train: Epoch[2/5]  [190/313]  eta: 0:00:41  Lr: 0.001875  Loss: 0.3109  Acc@1: 81.2500 (86.9110)  Acc@5: 100.0000 (98.4948)  time: 0.3326  data: 0.0007  max mem: 2356
Train: Epoch[2/5]  [200/313]  eta: 0:00:38  Lr: 0.001875  Loss: 0.2220  Acc@1: 87.5000 (86.8470)  Acc@5: 100.0000 (98.5075)  time: 0.3329  data: 0.0003  max mem: 2356
Train: Epoch[2/5]  [210/313]  eta: 0:00:34  Lr: 0.001875  Loss: -0.0732  Acc@1: 87.5000 (86.7595)  Acc@5: 100.0000 (98.4597)  time: 0.3336  data: 0.0005  max mem: 2356
Train: Epoch[2/5]  [220/313]  eta: 0:00:31  Lr: 0.001875  Loss: -0.1180  Acc@1: 87.5000 (86.7647)  Acc@5: 100.0000 (98.4163)  time: 0.3334  data: 0.0005  max mem: 2356
Train: Epoch[2/5]  [230/313]  eta: 0:00:27  Lr: 0.001875  Loss: 0.2375  Acc@1: 87.5000 (86.6342)  Acc@5: 100.0000 (98.3225)  time: 0.3329  data: 0.0012  max mem: 2356
Train: Epoch[2/5]  [240/313]  eta: 0:00:24  Lr: 0.001875  Loss: 0.1781  Acc@1: 87.5000 (86.7998)  Acc@5: 100.0000 (98.3662)  time: 0.3327  data: 0.0012  max mem: 2356
Train: Epoch[2/5]  [250/313]  eta: 0:00:21  Lr: 0.001875  Loss: -0.0270  Acc@1: 87.5000 (86.8526)  Acc@5: 100.0000 (98.3815)  time: 0.3329  data: 0.0004  max mem: 2356
Train: Epoch[2/5]  [260/313]  eta: 0:00:17  Lr: 0.001875  Loss: 0.3999  Acc@1: 87.5000 (86.8056)  Acc@5: 100.0000 (98.3477)  time: 0.3364  data: 0.0006  max mem: 2356
Train: Epoch[2/5]  [270/313]  eta: 0:00:14  Lr: 0.001875  Loss: 0.1077  Acc@1: 87.5000 (86.8542)  Acc@5: 100.0000 (98.3395)  time: 0.3416  data: 0.0007  max mem: 2356
Train: Epoch[2/5]  [280/313]  eta: 0:00:11  Lr: 0.001875  Loss: 0.4220  Acc@1: 87.5000 (86.8550)  Acc@5: 100.0000 (98.3541)  time: 0.3425  data: 0.0015  max mem: 2356
Train: Epoch[2/5]  [290/313]  eta: 0:00:07  Lr: 0.001875  Loss: 0.2102  Acc@1: 87.5000 (86.7912)  Acc@5: 100.0000 (98.3033)  time: 0.3379  data: 0.0019  max mem: 2356
Train: Epoch[2/5]  [300/313]  eta: 0:00:04  Lr: 0.001875  Loss: -0.0051  Acc@1: 81.2500 (86.6902)  Acc@5: 100.0000 (98.3389)  time: 0.3384  data: 0.0010  max mem: 2356
Train: Epoch[2/5]  [310/313]  eta: 0:00:01  Lr: 0.001875  Loss: 0.4697  Acc@1: 81.2500 (86.6158)  Acc@5: 100.0000 (98.3320)  time: 0.3425  data: 0.0009  max mem: 2356
Train: Epoch[2/5]  [312/313]  eta: 0:00:00  Lr: 0.001875  Loss: -0.1146  Acc@1: 81.2500 (86.6400)  Acc@5: 100.0000 (98.3400)  time: 0.3348  data: 0.0009  max mem: 2356
Train: Epoch[2/5] Total time: 0:01:45 (0.3374 s / it)
{0: {0: 22412, 1: 24815, 2: 8831, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}, 1: {0: 1577, 1: 208, 2: 1195, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}, 2: {0: 3518, 1: 6779, 2: 1983, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}, 3: {0: 21486, 1: 20777, 2: 7903, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}, 4: {0: 16124, 1: 10227, 2: 2387, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}, 5: {0: 23402, 1: 24357, 2: 9491, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}, 6: {0: 9472, 1: 12148, 2: 7426, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}, 7: {0: 752, 1: 676, 2: 774, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}, 8: {0: 24269, 1: 24959, 2: 9998, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}, 9: {0: 1988, 1: 54, 2: 12, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}}
Averaged stats: Lr: 0.001875  Loss: -0.1146  Acc@1: 81.2500 (86.6400)  Acc@5: 100.0000 (98.3400)
Train: Epoch[3/5]  [  0/313]  eta: 0:03:14  Lr: 0.001875  Loss: 0.0544  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)  time: 0.6222  data: 0.2842  max mem: 2356
Train: Epoch[3/5]  [ 10/313]  eta: 0:01:51  Lr: 0.001875  Loss: 0.1226  Acc@1: 87.5000 (86.9318)  Acc@5: 100.0000 (99.4318)  time: 0.3681  data: 0.0278  max mem: 2356
Train: Epoch[3/5]  [ 20/313]  eta: 0:01:44  Lr: 0.001875  Loss: 0.2620  Acc@1: 87.5000 (83.6310)  Acc@5: 100.0000 (98.5119)  time: 0.3435  data: 0.0017  max mem: 2356
Train: Epoch[3/5]  [ 30/313]  eta: 0:01:39  Lr: 0.001875  Loss: -0.0543  Acc@1: 87.5000 (85.4839)  Acc@5: 100.0000 (98.9919)  time: 0.3449  data: 0.0009  max mem: 2356
Train: Epoch[3/5]  [ 40/313]  eta: 0:01:35  Lr: 0.001875  Loss: 0.1153  Acc@1: 93.7500 (86.7378)  Acc@5: 100.0000 (99.0854)  time: 0.3397  data: 0.0009  max mem: 2356
Train: Epoch[3/5]  [ 50/313]  eta: 0:01:31  Lr: 0.001875  Loss: 0.0067  Acc@1: 87.5000 (87.1324)  Acc@5: 100.0000 (98.8971)  time: 0.3358  data: 0.0014  max mem: 2356
Train: Epoch[3/5]  [ 60/313]  eta: 0:01:27  Lr: 0.001875  Loss: 0.5821  Acc@1: 81.2500 (85.9631)  Acc@5: 100.0000 (98.7705)  time: 0.3446  data: 0.0021  max mem: 2356
Train: Epoch[3/5]  [ 70/313]  eta: 0:01:24  Lr: 0.001875  Loss: -0.0532  Acc@1: 87.5000 (86.8838)  Acc@5: 100.0000 (98.7676)  time: 0.3473  data: 0.0020  max mem: 2356
Train: Epoch[3/5]  [ 80/313]  eta: 0:01:20  Lr: 0.001875  Loss: 0.1561  Acc@1: 93.7500 (87.2685)  Acc@5: 100.0000 (98.7654)  time: 0.3425  data: 0.0019  max mem: 2356
Train: Epoch[3/5]  [ 90/313]  eta: 0:01:17  Lr: 0.001875  Loss: 0.3748  Acc@1: 87.5000 (86.7445)  Acc@5: 100.0000 (98.6264)  time: 0.3412  data: 0.0020  max mem: 2356
Train: Epoch[3/5]  [100/313]  eta: 0:01:13  Lr: 0.001875  Loss: 0.0838  Acc@1: 87.5000 (86.5099)  Acc@5: 93.7500 (98.3911)  time: 0.3377  data: 0.0009  max mem: 2356
Train: Epoch[3/5]  [110/313]  eta: 0:01:09  Lr: 0.001875  Loss: -0.0229  Acc@1: 87.5000 (86.8806)  Acc@5: 100.0000 (98.4234)  time: 0.3345  data: 0.0009  max mem: 2356
Train: Epoch[3/5]  [120/313]  eta: 0:01:06  Lr: 0.001875  Loss: -0.0696  Acc@1: 87.5000 (86.8802)  Acc@5: 100.0000 (98.2955)  time: 0.3339  data: 0.0009  max mem: 2356
Train: Epoch[3/5]  [130/313]  eta: 0:01:02  Lr: 0.001875  Loss: 0.6637  Acc@1: 87.5000 (86.6412)  Acc@5: 100.0000 (98.2347)  time: 0.3332  data: 0.0004  max mem: 2356
Train: Epoch[3/5]  [140/313]  eta: 0:00:59  Lr: 0.001875  Loss: 0.2756  Acc@1: 87.5000 (86.7908)  Acc@5: 100.0000 (98.3599)  time: 0.3334  data: 0.0004  max mem: 2356
Train: Epoch[3/5]  [150/313]  eta: 0:00:55  Lr: 0.001875  Loss: 0.2227  Acc@1: 87.5000 (86.7136)  Acc@5: 100.0000 (98.3858)  time: 0.3341  data: 0.0004  max mem: 2356
Train: Epoch[3/5]  [160/313]  eta: 0:00:52  Lr: 0.001875  Loss: 0.3548  Acc@1: 87.5000 (86.4519)  Acc@5: 100.0000 (98.4472)  time: 0.3336  data: 0.0004  max mem: 2356
Train: Epoch[3/5]  [170/313]  eta: 0:00:48  Lr: 0.001875  Loss: 0.2769  Acc@1: 87.5000 (86.6594)  Acc@5: 100.0000 (98.5015)  time: 0.3334  data: 0.0011  max mem: 2356
Train: Epoch[3/5]  [180/313]  eta: 0:00:45  Lr: 0.001875  Loss: 0.0893  Acc@1: 87.5000 (86.5677)  Acc@5: 100.0000 (98.5843)  time: 0.3347  data: 0.0011  max mem: 2356
Train: Epoch[3/5]  [190/313]  eta: 0:00:41  Lr: 0.001875  Loss: 0.0083  Acc@1: 87.5000 (86.6819)  Acc@5: 100.0000 (98.6257)  time: 0.3363  data: 0.0014  max mem: 2356
Train: Epoch[3/5]  [200/313]  eta: 0:00:38  Lr: 0.001875  Loss: -0.0414  Acc@1: 87.5000 (86.8470)  Acc@5: 100.0000 (98.6940)  time: 0.3343  data: 0.0014  max mem: 2356
Train: Epoch[3/5]  [210/313]  eta: 0:00:34  Lr: 0.001875  Loss: 0.9792  Acc@1: 87.5000 (86.6410)  Acc@5: 100.0000 (98.6374)  time: 0.3324  data: 0.0007  max mem: 2356
Train: Epoch[3/5]  [220/313]  eta: 0:00:31  Lr: 0.001875  Loss: -0.0174  Acc@1: 87.5000 (86.7647)  Acc@5: 100.0000 (98.6991)  time: 0.3326  data: 0.0008  max mem: 2356
Train: Epoch[3/5]  [230/313]  eta: 0:00:28  Lr: 0.001875  Loss: 0.3925  Acc@1: 87.5000 (86.4448)  Acc@5: 100.0000 (98.5931)  time: 0.3320  data: 0.0004  max mem: 2356
Train: Epoch[3/5]  [240/313]  eta: 0:00:24  Lr: 0.001875  Loss: 0.0769  Acc@1: 87.5000 (86.5145)  Acc@5: 100.0000 (98.5737)  time: 0.3320  data: 0.0004  max mem: 2356
Train: Epoch[3/5]  [250/313]  eta: 0:00:21  Lr: 0.001875  Loss: 0.3775  Acc@1: 87.5000 (86.5787)  Acc@5: 100.0000 (98.6305)  time: 0.3326  data: 0.0008  max mem: 2356
Train: Epoch[3/5]  [260/313]  eta: 0:00:17  Lr: 0.001875  Loss: -0.1939  Acc@1: 87.5000 (86.5661)  Acc@5: 100.0000 (98.6830)  time: 0.3323  data: 0.0007  max mem: 2356
Train: Epoch[3/5]  [270/313]  eta: 0:00:14  Lr: 0.001875  Loss: 0.2467  Acc@1: 87.5000 (86.4622)  Acc@5: 100.0000 (98.7085)  time: 0.3312  data: 0.0003  max mem: 2356
Train: Epoch[3/5]  [280/313]  eta: 0:00:11  Lr: 0.001875  Loss: 0.2734  Acc@1: 87.5000 (86.5214)  Acc@5: 100.0000 (98.7100)  time: 0.3316  data: 0.0003  max mem: 2356
Train: Epoch[3/5]  [290/313]  eta: 0:00:07  Lr: 0.001875  Loss: -0.0164  Acc@1: 87.5000 (86.5550)  Acc@5: 100.0000 (98.7113)  time: 0.3349  data: 0.0011  max mem: 2356
Train: Epoch[3/5]  [300/313]  eta: 0:00:04  Lr: 0.001875  Loss: -0.0535  Acc@1: 87.5000 (86.6694)  Acc@5: 100.0000 (98.7126)  time: 0.3374  data: 0.0023  max mem: 2356
Train: Epoch[3/5]  [310/313]  eta: 0:00:01  Lr: 0.001875  Loss: 0.0288  Acc@1: 93.7500 (86.7966)  Acc@5: 100.0000 (98.7138)  time: 0.3391  data: 0.0020  max mem: 2356
Train: Epoch[3/5]  [312/313]  eta: 0:00:00  Lr: 0.001875  Loss: -0.1439  Acc@1: 93.7500 (86.8200)  Acc@5: 100.0000 (98.7200)  time: 0.3302  data: 0.0020  max mem: 2356
Train: Epoch[3/5] Total time: 0:01:45 (0.3371 s / it)
{0: {0: 22412, 1: 24815, 2: 12952, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}, 1: {0: 1577, 1: 208, 2: 2094, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}, 2: {0: 3518, 1: 6779, 2: 3086, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}, 3: {0: 21486, 1: 20777, 2: 11655, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}, 4: {0: 16124, 1: 10227, 2: 3688, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}, 5: {0: 23402, 1: 24357, 2: 13840, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}, 6: {0: 9472, 1: 12148, 2: 10914, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}, 7: {0: 752, 1: 676, 2: 1749, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}, 8: {0: 24269, 1: 24959, 2: 14994, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}, 9: {0: 1988, 1: 54, 2: 28, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}}
Averaged stats: Lr: 0.001875  Loss: -0.1439  Acc@1: 93.7500 (86.8200)  Acc@5: 100.0000 (98.7200)
Train: Epoch[4/5]  [  0/313]  eta: 0:03:54  Lr: 0.001875  Loss: -0.0043  Acc@1: 93.7500 (93.7500)  Acc@5: 100.0000 (100.0000)  time: 0.7493  data: 0.4123  max mem: 2356
Train: Epoch[4/5]  [ 10/313]  eta: 0:01:53  Lr: 0.001875  Loss: 0.0615  Acc@1: 87.5000 (86.9318)  Acc@5: 100.0000 (98.2955)  time: 0.3746  data: 0.0379  max mem: 2356
Train: Epoch[4/5]  [ 20/313]  eta: 0:01:43  Lr: 0.001875  Loss: 0.1181  Acc@1: 87.5000 (89.2857)  Acc@5: 100.0000 (98.8095)  time: 0.3345  data: 0.0004  max mem: 2356
Train: Epoch[4/5]  [ 30/313]  eta: 0:01:38  Lr: 0.001875  Loss: 0.2361  Acc@1: 87.5000 (88.1048)  Acc@5: 100.0000 (98.5887)  time: 0.3326  data: 0.0011  max mem: 2356
Train: Epoch[4/5]  [ 40/313]  eta: 0:01:34  Lr: 0.001875  Loss: 0.3495  Acc@1: 81.2500 (87.8049)  Acc@5: 100.0000 (98.6280)  time: 0.3342  data: 0.0013  max mem: 2356
Train: Epoch[4/5]  [ 50/313]  eta: 0:01:30  Lr: 0.001875  Loss: 0.3708  Acc@1: 87.5000 (88.7255)  Acc@5: 100.0000 (98.7745)  time: 0.3354  data: 0.0014  max mem: 2356
Train: Epoch[4/5]  [ 60/313]  eta: 0:01:26  Lr: 0.001875  Loss: 0.2741  Acc@1: 87.5000 (88.2172)  Acc@5: 100.0000 (98.7705)  time: 0.3391  data: 0.0015  max mem: 2356
Train: Epoch[4/5]  [ 70/313]  eta: 0:01:23  Lr: 0.001875  Loss: 0.5324  Acc@1: 87.5000 (88.2923)  Acc@5: 100.0000 (98.7676)  time: 0.3442  data: 0.0013  max mem: 2356
Train: Epoch[4/5]  [ 80/313]  eta: 0:01:19  Lr: 0.001875  Loss: 0.0563  Acc@1: 87.5000 (88.5031)  Acc@5: 100.0000 (98.6883)  time: 0.3419  data: 0.0010  max mem: 2356
Train: Epoch[4/5]  [ 90/313]  eta: 0:01:16  Lr: 0.001875  Loss: 0.0942  Acc@1: 87.5000 (88.5302)  Acc@5: 100.0000 (98.8324)  time: 0.3399  data: 0.0015  max mem: 2356
Train: Epoch[4/5]  [100/313]  eta: 0:01:12  Lr: 0.001875  Loss: 0.0046  Acc@1: 87.5000 (88.4901)  Acc@5: 100.0000 (98.8243)  time: 0.3395  data: 0.0027  max mem: 2356
Train: Epoch[4/5]  [110/313]  eta: 0:01:09  Lr: 0.001875  Loss: -0.0542  Acc@1: 93.7500 (88.6261)  Acc@5: 100.0000 (98.8176)  time: 0.3400  data: 0.0027  max mem: 2356
Train: Epoch[4/5]  [120/313]  eta: 0:01:05  Lr: 0.001875  Loss: 0.0971  Acc@1: 87.5000 (88.4298)  Acc@5: 100.0000 (98.7603)  time: 0.3398  data: 0.0016  max mem: 2356
Train: Epoch[4/5]  [130/313]  eta: 0:01:02  Lr: 0.001875  Loss: 0.1383  Acc@1: 87.5000 (88.4542)  Acc@5: 100.0000 (98.8073)  time: 0.3390  data: 0.0006  max mem: 2356
Train: Epoch[4/5]  [140/313]  eta: 0:00:59  Lr: 0.001875  Loss: 0.1158  Acc@1: 93.7500 (88.4752)  Acc@5: 100.0000 (98.8918)  time: 0.3390  data: 0.0007  max mem: 2356
Train: Epoch[4/5]  [150/313]  eta: 0:00:55  Lr: 0.001875  Loss: 0.3946  Acc@1: 87.5000 (88.2450)  Acc@5: 100.0000 (98.8825)  time: 0.3379  data: 0.0008  max mem: 2356
Train: Epoch[4/5]  [160/313]  eta: 0:00:52  Lr: 0.001875  Loss: 0.4328  Acc@1: 87.5000 (88.2376)  Acc@5: 100.0000 (98.9130)  time: 0.3395  data: 0.0012  max mem: 2356
Train: Epoch[4/5]  [170/313]  eta: 0:00:48  Lr: 0.001875  Loss: 0.6823  Acc@1: 87.5000 (88.1579)  Acc@5: 100.0000 (98.9401)  time: 0.3471  data: 0.0040  max mem: 2356
Train: Epoch[4/5]  [180/313]  eta: 0:00:45  Lr: 0.001875  Loss: 0.0077  Acc@1: 87.5000 (88.2251)  Acc@5: 100.0000 (98.8605)  time: 0.3447  data: 0.0037  max mem: 2356
Train: Epoch[4/5]  [190/313]  eta: 0:00:41  Lr: 0.001875  Loss: -0.0006  Acc@1: 87.5000 (88.3181)  Acc@5: 100.0000 (98.8874)  time: 0.3335  data: 0.0006  max mem: 2356
Train: Epoch[4/5]  [200/313]  eta: 0:00:38  Lr: 0.001875  Loss: 0.3386  Acc@1: 87.5000 (88.1841)  Acc@5: 100.0000 (98.8495)  time: 0.3322  data: 0.0004  max mem: 2356
Train: Epoch[4/5]  [210/313]  eta: 0:00:35  Lr: 0.001875  Loss: 0.4023  Acc@1: 81.2500 (88.0036)  Acc@5: 100.0000 (98.8448)  time: 0.3331  data: 0.0004  max mem: 2356
Train: Epoch[4/5]  [220/313]  eta: 0:00:31  Lr: 0.001875  Loss: -0.0479  Acc@1: 87.5000 (88.0373)  Acc@5: 100.0000 (98.8688)  time: 0.3333  data: 0.0004  max mem: 2356
Train: Epoch[4/5]  [230/313]  eta: 0:00:28  Lr: 0.001875  Loss: 0.0182  Acc@1: 87.5000 (88.0141)  Acc@5: 100.0000 (98.8636)  time: 0.3339  data: 0.0004  max mem: 2356
Train: Epoch[4/5]  [240/313]  eta: 0:00:24  Lr: 0.001875  Loss: 0.0599  Acc@1: 87.5000 (87.9409)  Acc@5: 100.0000 (98.9108)  time: 0.3342  data: 0.0004  max mem: 2356
Train: Epoch[4/5]  [250/313]  eta: 0:00:21  Lr: 0.001875  Loss: 0.2682  Acc@1: 87.5000 (87.9731)  Acc@5: 100.0000 (98.9293)  time: 0.3335  data: 0.0004  max mem: 2356
Train: Epoch[4/5]  [260/313]  eta: 0:00:17  Lr: 0.001875  Loss: 0.0660  Acc@1: 87.5000 (88.0268)  Acc@5: 100.0000 (98.9224)  time: 0.3331  data: 0.0004  max mem: 2356
Train: Epoch[4/5]  [270/313]  eta: 0:00:14  Lr: 0.001875  Loss: -0.0549  Acc@1: 87.5000 (87.9613)  Acc@5: 100.0000 (98.8930)  time: 0.3336  data: 0.0009  max mem: 2356
Train: Epoch[4/5]  [280/313]  eta: 0:00:11  Lr: 0.001875  Loss: 0.2339  Acc@1: 87.5000 (87.9448)  Acc@5: 100.0000 (98.8657)  time: 0.3359  data: 0.0009  max mem: 2356
Train: Epoch[4/5]  [290/313]  eta: 0:00:07  Lr: 0.001875  Loss: -0.0488  Acc@1: 87.5000 (87.9940)  Acc@5: 100.0000 (98.8187)  time: 0.3354  data: 0.0004  max mem: 2356
Train: Epoch[4/5]  [300/313]  eta: 0:00:04  Lr: 0.001875  Loss: 0.3715  Acc@1: 87.5000 (87.8322)  Acc@5: 100.0000 (98.8372)  time: 0.3332  data: 0.0003  max mem: 2356
Train: Epoch[4/5]  [310/313]  eta: 0:00:01  Lr: 0.001875  Loss: 0.2252  Acc@1: 81.2500 (87.6608)  Acc@5: 100.0000 (98.7942)  time: 0.3331  data: 0.0003  max mem: 2356
Train: Epoch[4/5]  [312/313]  eta: 0:00:00  Lr: 0.001875  Loss: -0.0513  Acc@1: 87.5000 (87.6200)  Acc@5: 100.0000 (98.8000)  time: 0.3243  data: 0.0003  max mem: 2356
Train: Epoch[4/5] Total time: 0:01:45 (0.3379 s / it)
{0: {0: 22412, 1: 24815, 2: 16702, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}, 1: {0: 1577, 1: 208, 2: 3399, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}, 2: {0: 3518, 1: 6779, 2: 4191, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}, 3: {0: 21486, 1: 20777, 2: 15303, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}, 4: {0: 16124, 1: 10227, 2: 5049, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}, 5: {0: 23402, 1: 24357, 2: 17863, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}, 6: {0: 9472, 1: 12148, 2: 14319, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}, 7: {0: 752, 1: 676, 2: 3059, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}, 8: {0: 24269, 1: 24959, 2: 19920, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}, 9: {0: 1988, 1: 54, 2: 195, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}}
Averaged stats: Lr: 0.001875  Loss: -0.0513  Acc@1: 87.5000 (87.6200)  Acc@5: 100.0000 (98.8000)
Train: Epoch[5/5]  [  0/313]  eta: 0:03:40  Lr: 0.001875  Loss: 0.0770  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (100.0000)  time: 0.7035  data: 0.3600  max mem: 2356
Train: Epoch[5/5]  [ 10/313]  eta: 0:01:51  Lr: 0.001875  Loss: 0.1636  Acc@1: 93.7500 (92.0455)  Acc@5: 100.0000 (98.8636)  time: 0.3688  data: 0.0333  max mem: 2356
Train: Epoch[5/5]  [ 20/313]  eta: 0:01:43  Lr: 0.001875  Loss: 0.3416  Acc@1: 93.7500 (90.7738)  Acc@5: 100.0000 (99.4048)  time: 0.3350  data: 0.0010  max mem: 2356
Train: Epoch[5/5]  [ 30/313]  eta: 0:01:38  Lr: 0.001875  Loss: 0.2673  Acc@1: 87.5000 (88.5081)  Acc@5: 100.0000 (98.9919)  time: 0.3341  data: 0.0011  max mem: 2356
Train: Epoch[5/5]  [ 40/313]  eta: 0:01:33  Lr: 0.001875  Loss: 0.1305  Acc@1: 81.2500 (87.3476)  Acc@5: 100.0000 (98.6280)  time: 0.3326  data: 0.0006  max mem: 2356
Train: Epoch[5/5]  [ 50/313]  eta: 0:01:29  Lr: 0.001875  Loss: -0.0665  Acc@1: 87.5000 (88.4804)  Acc@5: 100.0000 (98.6520)  time: 0.3322  data: 0.0004  max mem: 2356
Train: Epoch[5/5]  [ 60/313]  eta: 0:01:26  Lr: 0.001875  Loss: 0.2723  Acc@1: 87.5000 (88.0123)  Acc@5: 100.0000 (98.7705)  time: 0.3354  data: 0.0008  max mem: 2356
Train: Epoch[5/5]  [ 70/313]  eta: 0:01:22  Lr: 0.001875  Loss: 0.4983  Acc@1: 87.5000 (88.2042)  Acc@5: 100.0000 (98.5915)  time: 0.3359  data: 0.0011  max mem: 2356
Train: Epoch[5/5]  [ 80/313]  eta: 0:01:19  Lr: 0.001875  Loss: 0.1058  Acc@1: 87.5000 (87.9630)  Acc@5: 100.0000 (98.3796)  time: 0.3362  data: 0.0013  max mem: 2356
Train: Epoch[5/5]  [ 90/313]  eta: 0:01:15  Lr: 0.001875  Loss: 0.1597  Acc@1: 87.5000 (87.9808)  Acc@5: 100.0000 (98.3516)  time: 0.3389  data: 0.0011  max mem: 2356
Train: Epoch[5/5]  [100/313]  eta: 0:01:12  Lr: 0.001875  Loss: 0.0702  Acc@1: 87.5000 (87.9332)  Acc@5: 100.0000 (98.3292)  time: 0.3391  data: 0.0011  max mem: 2356
Train: Epoch[5/5]  [110/313]  eta: 0:01:08  Lr: 0.001875  Loss: 0.1615  Acc@1: 87.5000 (87.9505)  Acc@5: 100.0000 (98.4234)  time: 0.3388  data: 0.0025  max mem: 2356
Train: Epoch[5/5]  [120/313]  eta: 0:01:05  Lr: 0.001875  Loss: 0.1757  Acc@1: 87.5000 (88.0165)  Acc@5: 100.0000 (98.5537)  time: 0.3357  data: 0.0019  max mem: 2356
Train: Epoch[5/5]  [130/313]  eta: 0:01:01  Lr: 0.001875  Loss: 0.2760  Acc@1: 87.5000 (88.2156)  Acc@5: 100.0000 (98.6164)  time: 0.3347  data: 0.0017  max mem: 2356
Train: Epoch[5/5]  [140/313]  eta: 0:00:58  Lr: 0.001875  Loss: 0.3774  Acc@1: 87.5000 (87.9433)  Acc@5: 100.0000 (98.6259)  time: 0.3382  data: 0.0028  max mem: 2356
Train: Epoch[5/5]  [150/313]  eta: 0:00:55  Lr: 0.001875  Loss: 0.3079  Acc@1: 81.2500 (87.9553)  Acc@5: 100.0000 (98.5513)  time: 0.3379  data: 0.0019  max mem: 2356
Train: Epoch[5/5]  [160/313]  eta: 0:00:51  Lr: 0.001875  Loss: -0.1192  Acc@1: 87.5000 (88.0047)  Acc@5: 100.0000 (98.5637)  time: 0.3367  data: 0.0010  max mem: 2356
Train: Epoch[5/5]  [170/313]  eta: 0:00:48  Lr: 0.001875  Loss: -0.0418  Acc@1: 87.5000 (88.2310)  Acc@5: 100.0000 (98.5746)  time: 0.3359  data: 0.0005  max mem: 2356
Train: Epoch[5/5]  [180/313]  eta: 0:00:44  Lr: 0.001875  Loss: -0.0329  Acc@1: 87.5000 (88.2597)  Acc@5: 100.0000 (98.6188)  time: 0.3355  data: 0.0005  max mem: 2356
Train: Epoch[5/5]  [190/313]  eta: 0:00:41  Lr: 0.001875  Loss: -0.0422  Acc@1: 87.5000 (88.2199)  Acc@5: 100.0000 (98.6257)  time: 0.3370  data: 0.0013  max mem: 2356
Train: Epoch[5/5]  [200/313]  eta: 0:00:38  Lr: 0.001875  Loss: 0.4232  Acc@1: 81.2500 (87.9975)  Acc@5: 100.0000 (98.5697)  time: 0.3364  data: 0.0013  max mem: 2356
Train: Epoch[5/5]  [210/313]  eta: 0:00:34  Lr: 0.001875  Loss: -0.0745  Acc@1: 87.5000 (87.9443)  Acc@5: 100.0000 (98.5190)  time: 0.3363  data: 0.0013  max mem: 2356
Train: Epoch[5/5]  [220/313]  eta: 0:00:31  Lr: 0.001875  Loss: 0.6280  Acc@1: 87.5000 (87.8111)  Acc@5: 100.0000 (98.5577)  time: 0.3402  data: 0.0035  max mem: 2356
Train: Epoch[5/5]  [230/313]  eta: 0:00:28  Lr: 0.001875  Loss: 0.0120  Acc@1: 87.5000 (87.8788)  Acc@5: 100.0000 (98.5931)  time: 0.3424  data: 0.0029  max mem: 2356
Train: Epoch[5/5]  [240/313]  eta: 0:00:24  Lr: 0.001875  Loss: 0.1064  Acc@1: 93.7500 (88.0965)  Acc@5: 100.0000 (98.5996)  time: 0.3391  data: 0.0010  max mem: 2356
Train: Epoch[5/5]  [250/313]  eta: 0:00:21  Lr: 0.001875  Loss: -0.0688  Acc@1: 93.7500 (88.1474)  Acc@5: 100.0000 (98.5807)  time: 0.3347  data: 0.0009  max mem: 2356
Train: Epoch[5/5]  [260/313]  eta: 0:00:17  Lr: 0.001875  Loss: -0.0250  Acc@1: 87.5000 (88.1466)  Acc@5: 100.0000 (98.5872)  time: 0.3360  data: 0.0008  max mem: 2356
Train: Epoch[5/5]  [270/313]  eta: 0:00:14  Lr: 0.001875  Loss: 0.2088  Acc@1: 87.5000 (88.1688)  Acc@5: 100.0000 (98.6393)  time: 0.3395  data: 0.0008  max mem: 2356
Train: Epoch[5/5]  [280/313]  eta: 0:00:11  Lr: 0.001875  Loss: 0.2899  Acc@1: 87.5000 (88.1005)  Acc@5: 100.0000 (98.6432)  time: 0.3401  data: 0.0006  max mem: 2356
Train: Epoch[5/5]  [290/313]  eta: 0:00:07  Lr: 0.001875  Loss: -0.0470  Acc@1: 87.5000 (88.0584)  Acc@5: 100.0000 (98.6899)  time: 0.3467  data: 0.0012  max mem: 2356
Train: Epoch[5/5]  [300/313]  eta: 0:00:04  Lr: 0.001875  Loss: -0.0683  Acc@1: 87.5000 (88.0399)  Acc@5: 100.0000 (98.6503)  time: 0.3435  data: 0.0010  max mem: 2356
Train: Epoch[5/5]  [310/313]  eta: 0:00:01  Lr: 0.001875  Loss: 0.3535  Acc@1: 87.5000 (87.9421)  Acc@5: 100.0000 (98.6535)  time: 0.3340  data: 0.0003  max mem: 2356
Train: Epoch[5/5]  [312/313]  eta: 0:00:00  Lr: 0.001875  Loss: 0.0367  Acc@1: 87.5000 (87.9400)  Acc@5: 100.0000 (98.6400)  time: 0.3258  data: 0.0003  max mem: 2356
Train: Epoch[5/5] Total time: 0:01:45 (0.3382 s / it)
{0: {0: 22412, 1: 24815, 2: 19998, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}, 1: {0: 1577, 1: 208, 2: 5200, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}, 2: {0: 3518, 1: 6779, 2: 5327, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}, 3: {0: 21486, 1: 20777, 2: 18903, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}, 4: {0: 16124, 1: 10227, 2: 6432, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}, 5: {0: 23402, 1: 24357, 2: 21714, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}, 6: {0: 9472, 1: 12148, 2: 17669, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}, 7: {0: 752, 1: 676, 2: 4577, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}, 8: {0: 24269, 1: 24959, 2: 24373, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}, 9: {0: 1988, 1: 54, 2: 807, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}}
Averaged stats: Lr: 0.001875  Loss: 0.0367  Acc@1: 87.5000 (87.9400)  Acc@5: 100.0000 (98.6400)
Test: [Task 1]  [ 0/63]  eta: 0:00:30  Loss: 0.4843 (0.4843)  Acc@1: 93.7500 (93.7500)  Acc@5: 100.0000 (100.0000)  time: 0.4838  data: 0.2725  max mem: 2356
Test: [Task 1]  [10/63]  eta: 0:00:12  Loss: 0.5621 (0.5708)  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (99.4318)  time: 0.2317  data: 0.0252  max mem: 2356
Test: [Task 1]  [20/63]  eta: 0:00:09  Loss: 0.5636 (0.5999)  Acc@1: 87.5000 (87.7976)  Acc@5: 100.0000 (99.7024)  time: 0.2063  data: 0.0004  max mem: 2356
Test: [Task 1]  [30/63]  eta: 0:00:07  Loss: 0.4825 (0.5614)  Acc@1: 87.5000 (87.7016)  Acc@5: 100.0000 (99.7984)  time: 0.2060  data: 0.0003  max mem: 2356
Test: [Task 1]  [40/63]  eta: 0:00:04  Loss: 0.4825 (0.5552)  Acc@1: 87.5000 (87.9573)  Acc@5: 100.0000 (99.8476)  time: 0.2064  data: 0.0004  max mem: 2356
Test: [Task 1]  [50/63]  eta: 0:00:02  Loss: 0.4680 (0.5345)  Acc@1: 93.7500 (88.8480)  Acc@5: 100.0000 (99.7549)  time: 0.2061  data: 0.0004  max mem: 2356
Test: [Task 1]  [60/63]  eta: 0:00:00  Loss: 0.4658 (0.5259)  Acc@1: 87.5000 (88.9344)  Acc@5: 100.0000 (99.5902)  time: 0.2061  data: 0.0003  max mem: 2356
Test: [Task 1]  [62/63]  eta: 0:00:00  Loss: 0.4584 (0.5232)  Acc@1: 93.7500 (89.1000)  Acc@5: 100.0000 (99.6000)  time: 0.2012  data: 0.0003  max mem: 2356
Test: [Task 1] Total time: 0:00:13 (0.2102 s / it)
* Acc@1 89.100 Acc@5 99.600 loss 0.523
Test: [Task 2]  [ 0/63]  eta: 0:00:30  Loss: 0.7398 (0.7398)  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (100.0000)  time: 0.4859  data: 0.2806  max mem: 2356
Test: [Task 2]  [10/63]  eta: 0:00:12  Loss: 0.5730 (0.6596)  Acc@1: 93.7500 (93.7500)  Acc@5: 100.0000 (98.8636)  time: 0.2320  data: 0.0258  max mem: 2356
Test: [Task 2]  [20/63]  eta: 0:00:09  Loss: 0.6718 (0.7441)  Acc@1: 93.7500 (90.4762)  Acc@5: 100.0000 (98.8095)  time: 0.2063  data: 0.0004  max mem: 2356
Test: [Task 2]  [30/63]  eta: 0:00:07  Loss: 0.6932 (0.7163)  Acc@1: 87.5000 (91.1290)  Acc@5: 100.0000 (98.5887)  time: 0.2068  data: 0.0004  max mem: 2356
Test: [Task 2]  [40/63]  eta: 0:00:04  Loss: 0.6796 (0.7004)  Acc@1: 93.7500 (91.4634)  Acc@5: 100.0000 (98.6280)  time: 0.2072  data: 0.0007  max mem: 2356
Test: [Task 2]  [50/63]  eta: 0:00:02  Loss: 0.5966 (0.6881)  Acc@1: 93.7500 (91.5441)  Acc@5: 100.0000 (98.5294)  time: 0.2075  data: 0.0013  max mem: 2356
Test: [Task 2]  [60/63]  eta: 0:00:00  Loss: 0.5449 (0.6689)  Acc@1: 93.7500 (92.0082)  Acc@5: 100.0000 (98.6680)  time: 0.2084  data: 0.0009  max mem: 2356
Test: [Task 2]  [62/63]  eta: 0:00:00  Loss: 0.5073 (0.6594)  Acc@1: 93.7500 (92.1000)  Acc@5: 100.0000 (98.7000)  time: 0.2037  data: 0.0009  max mem: 2356
Test: [Task 2] Total time: 0:00:13 (0.2112 s / it)
* Acc@1 92.100 Acc@5 98.700 loss 0.659
Test: [Task 3]  [ 0/63]  eta: 0:00:38  Loss: 0.2948 (0.2948)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)  time: 0.6154  data: 0.4101  max mem: 2356
Test: [Task 3]  [10/63]  eta: 0:00:12  Loss: 0.4501 (0.4948)  Acc@1: 93.7500 (90.3409)  Acc@5: 100.0000 (100.0000)  time: 0.2451  data: 0.0379  max mem: 2356
Test: [Task 3]  [20/63]  eta: 0:00:09  Loss: 0.5191 (0.4986)  Acc@1: 93.7500 (90.7738)  Acc@5: 100.0000 (99.4048)  time: 0.2087  data: 0.0015  max mem: 2356
Test: [Task 3]  [30/63]  eta: 0:00:07  Loss: 0.4838 (0.4962)  Acc@1: 93.7500 (90.9274)  Acc@5: 100.0000 (99.5968)  time: 0.2074  data: 0.0013  max mem: 2356
Test: [Task 3]  [40/63]  eta: 0:00:04  Loss: 0.4838 (0.5039)  Acc@1: 93.7500 (90.8537)  Acc@5: 100.0000 (99.5427)  time: 0.2061  data: 0.0005  max mem: 2356
Test: [Task 3]  [50/63]  eta: 0:00:02  Loss: 0.4847 (0.5161)  Acc@1: 93.7500 (90.5637)  Acc@5: 100.0000 (99.3873)  time: 0.2060  data: 0.0005  max mem: 2356
Test: [Task 3]  [60/63]  eta: 0:00:00  Loss: 0.5296 (0.5249)  Acc@1: 87.5000 (90.2664)  Acc@5: 100.0000 (99.4877)  time: 0.2047  data: 0.0003  max mem: 2356
Test: [Task 3]  [62/63]  eta: 0:00:00  Loss: 0.5379 (0.5260)  Acc@1: 87.5000 (90.2000)  Acc@5: 100.0000 (99.5000)  time: 0.1997  data: 0.0002  max mem: 2356
Test: [Task 3] Total time: 0:00:13 (0.2124 s / it)
* Acc@1 90.200 Acc@5 99.500 loss 0.526
{0: {0: 674, 1: 335, 2: 395, 3: 552, 4: 440, 5: 600, 6: 501, 7: 488, 8: 766, 9: 249}, 1: {0: 673, 1: 337, 2: 568, 3: 404, 4: 590, 5: 424, 6: 371, 7: 614, 8: 940, 9: 79}, 2: {0: 748, 1: 258, 2: 364, 3: 583, 4: 414, 5: 635, 6: 545, 7: 453, 8: 797, 9: 203}}
[Average accuracy till task3]	Acc@1: 90.4667	Acc@5: 99.2667	Loss: 0.5695	Forgetting: 5.3500	Backward: -5.3500
Train: Epoch[1/5]  [  0/313]  eta: 0:02:57  Lr: 0.001875  Loss: 2.0593  Acc@1: 18.7500 (18.7500)  Acc@5: 43.7500 (43.7500)  time: 0.5656  data: 0.2051  max mem: 2356
Train: Epoch[1/5]  [ 10/313]  eta: 0:01:46  Lr: 0.001875  Loss: 1.8175  Acc@1: 50.0000 (47.1591)  Acc@5: 81.2500 (79.5455)  time: 0.3523  data: 0.0190  max mem: 2356
Train: Epoch[1/5]  [ 20/313]  eta: 0:01:40  Lr: 0.001875  Loss: 1.4257  Acc@1: 56.2500 (59.5238)  Acc@5: 87.5000 (86.0119)  time: 0.3314  data: 0.0004  max mem: 2356
Train: Epoch[1/5]  [ 30/313]  eta: 0:01:36  Lr: 0.001875  Loss: 1.0320  Acc@1: 81.2500 (66.3306)  Acc@5: 100.0000 (89.5161)  time: 0.3322  data: 0.0004  max mem: 2356
Train: Epoch[1/5]  [ 40/313]  eta: 0:01:32  Lr: 0.001875  Loss: 0.7791  Acc@1: 81.2500 (69.5122)  Acc@5: 93.7500 (91.0061)  time: 0.3360  data: 0.0009  max mem: 2356
Train: Epoch[1/5]  [ 50/313]  eta: 0:01:29  Lr: 0.001875  Loss: 0.8049  Acc@1: 81.2500 (71.4461)  Acc@5: 100.0000 (92.5245)  time: 0.3381  data: 0.0017  max mem: 2356
Train: Epoch[1/5]  [ 60/313]  eta: 0:01:25  Lr: 0.001875  Loss: 0.6125  Acc@1: 81.2500 (72.8484)  Acc@5: 100.0000 (93.1352)  time: 0.3366  data: 0.0016  max mem: 2356
Train: Epoch[1/5]  [ 70/313]  eta: 0:01:22  Lr: 0.001875  Loss: 0.6730  Acc@1: 81.2500 (74.9120)  Acc@5: 100.0000 (93.7500)  time: 0.3376  data: 0.0009  max mem: 2356
Train: Epoch[1/5]  [ 80/313]  eta: 0:01:18  Lr: 0.001875  Loss: 0.7889  Acc@1: 87.5000 (76.2346)  Acc@5: 100.0000 (94.3673)  time: 0.3378  data: 0.0008  max mem: 2356
Train: Epoch[1/5]  [ 90/313]  eta: 0:01:15  Lr: 0.001875  Loss: 0.1315  Acc@1: 87.5000 (77.5412)  Acc@5: 100.0000 (94.8489)  time: 0.3376  data: 0.0021  max mem: 2356
Train: Epoch[1/5]  [100/313]  eta: 0:01:12  Lr: 0.001875  Loss: 0.5134  Acc@1: 87.5000 (78.3416)  Acc@5: 100.0000 (95.0495)  time: 0.3393  data: 0.0019  max mem: 2356
Train: Epoch[1/5]  [110/313]  eta: 0:01:08  Lr: 0.001875  Loss: 0.5868  Acc@1: 81.2500 (78.9977)  Acc@5: 93.7500 (95.0450)  time: 0.3417  data: 0.0016  max mem: 2356
Train: Epoch[1/5]  [120/313]  eta: 0:01:05  Lr: 0.001875  Loss: 0.6385  Acc@1: 81.2500 (79.5455)  Acc@5: 93.7500 (95.2479)  time: 0.3402  data: 0.0015  max mem: 2356
Train: Epoch[1/5]  [130/313]  eta: 0:01:01  Lr: 0.001875  Loss: 0.3409  Acc@1: 81.2500 (79.8187)  Acc@5: 100.0000 (95.4676)  time: 0.3370  data: 0.0013  max mem: 2356
Train: Epoch[1/5]  [140/313]  eta: 0:00:58  Lr: 0.001875  Loss: 0.2256  Acc@1: 87.5000 (80.4521)  Acc@5: 100.0000 (95.6560)  time: 0.3429  data: 0.0013  max mem: 2356
Train: Epoch[1/5]  [150/313]  eta: 0:00:55  Lr: 0.001875  Loss: 0.0821  Acc@1: 87.5000 (80.7947)  Acc@5: 100.0000 (95.8609)  time: 0.3446  data: 0.0007  max mem: 2356
Train: Epoch[1/5]  [160/313]  eta: 0:00:51  Lr: 0.001875  Loss: 0.5569  Acc@1: 87.5000 (81.1335)  Acc@5: 100.0000 (96.0792)  time: 0.3406  data: 0.0010  max mem: 2356
Train: Epoch[1/5]  [170/313]  eta: 0:00:48  Lr: 0.001875  Loss: 0.1436  Acc@1: 81.2500 (81.2865)  Acc@5: 100.0000 (96.1623)  time: 0.3398  data: 0.0024  max mem: 2356
Train: Epoch[1/5]  [180/313]  eta: 0:00:45  Lr: 0.001875  Loss: 0.0964  Acc@1: 87.5000 (81.6644)  Acc@5: 100.0000 (96.3052)  time: 0.3398  data: 0.0030  max mem: 2356
Train: Epoch[1/5]  [190/313]  eta: 0:00:41  Lr: 0.001875  Loss: 0.1853  Acc@1: 87.5000 (82.0026)  Acc@5: 100.0000 (96.3351)  time: 0.3466  data: 0.0019  max mem: 2356
Train: Epoch[1/5]  [200/313]  eta: 0:00:38  Lr: 0.001875  Loss: 0.3912  Acc@1: 87.5000 (82.3383)  Acc@5: 100.0000 (96.4863)  time: 0.3425  data: 0.0010  max mem: 2356
Train: Epoch[1/5]  [210/313]  eta: 0:00:34  Lr: 0.001875  Loss: 0.1434  Acc@1: 87.5000 (82.5829)  Acc@5: 100.0000 (96.5936)  time: 0.3328  data: 0.0004  max mem: 2356
Train: Epoch[1/5]  [220/313]  eta: 0:00:31  Lr: 0.001875  Loss: 0.0225  Acc@1: 87.5000 (82.8337)  Acc@5: 100.0000 (96.6912)  time: 0.3323  data: 0.0004  max mem: 2356
Train: Epoch[1/5]  [230/313]  eta: 0:00:28  Lr: 0.001875  Loss: 0.3170  Acc@1: 87.5000 (82.7922)  Acc@5: 100.0000 (96.7262)  time: 0.3325  data: 0.0003  max mem: 2356
Train: Epoch[1/5]  [240/313]  eta: 0:00:24  Lr: 0.001875  Loss: 0.1240  Acc@1: 81.2500 (82.7801)  Acc@5: 100.0000 (96.7324)  time: 0.3353  data: 0.0003  max mem: 2356
Train: Epoch[1/5]  [250/313]  eta: 0:00:21  Lr: 0.001875  Loss: 0.2382  Acc@1: 87.5000 (82.8685)  Acc@5: 100.0000 (96.8127)  time: 0.3362  data: 0.0004  max mem: 2356
Train: Epoch[1/5]  [260/313]  eta: 0:00:17  Lr: 0.001875  Loss: -0.0504  Acc@1: 87.5000 (83.1897)  Acc@5: 100.0000 (96.8870)  time: 0.3338  data: 0.0004  max mem: 2356
Train: Epoch[1/5]  [270/313]  eta: 0:00:14  Lr: 0.001875  Loss: 0.2135  Acc@1: 87.5000 (83.2334)  Acc@5: 100.0000 (96.9327)  time: 0.3328  data: 0.0004  max mem: 2356
Train: Epoch[1/5]  [280/313]  eta: 0:00:11  Lr: 0.001875  Loss: 0.3704  Acc@1: 87.5000 (83.4964)  Acc@5: 100.0000 (96.9751)  time: 0.3329  data: 0.0004  max mem: 2356
Train: Epoch[1/5]  [290/313]  eta: 0:00:07  Lr: 0.001875  Loss: 0.2243  Acc@1: 87.5000 (83.4622)  Acc@5: 100.0000 (97.0576)  time: 0.3335  data: 0.0011  max mem: 2356
Train: Epoch[1/5]  [300/313]  eta: 0:00:04  Lr: 0.001875  Loss: 0.3553  Acc@1: 81.2500 (83.4510)  Acc@5: 100.0000 (97.0723)  time: 0.3339  data: 0.0014  max mem: 2356
Train: Epoch[1/5]  [310/313]  eta: 0:00:01  Lr: 0.001875  Loss: 0.5202  Acc@1: 81.2500 (83.6013)  Acc@5: 100.0000 (97.1664)  time: 0.3332  data: 0.0010  max mem: 2356
Train: Epoch[1/5]  [312/313]  eta: 0:00:00  Lr: 0.001875  Loss: -0.0944  Acc@1: 81.2500 (83.5600)  Acc@5: 100.0000 (97.1800)  time: 0.3246  data: 0.0010  max mem: 2356
Train: Epoch[1/5] Total time: 0:01:45 (0.3374 s / it)
{0: {0: 22412, 1: 24815, 2: 19998, 3: 2930, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}, 1: {0: 1577, 1: 208, 2: 5200, 3: 2126, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}, 2: {0: 3518, 1: 6779, 2: 5327, 3: 2057, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}, 3: {0: 21486, 1: 20777, 2: 18903, 3: 2795, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}, 4: {0: 16124, 1: 10227, 2: 6432, 3: 2199, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}, 5: {0: 23402, 1: 24357, 2: 21714, 3: 2930, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}, 6: {0: 9472, 1: 12148, 2: 17669, 3: 2690, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}, 7: {0: 752, 1: 676, 2: 4577, 3: 2244, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}, 8: {0: 24269, 1: 24959, 2: 24373, 3: 4953, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}, 9: {0: 1988, 1: 54, 2: 807, 3: 76, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}}
Averaged stats: Lr: 0.001875  Loss: -0.0944  Acc@1: 81.2500 (83.5600)  Acc@5: 100.0000 (97.1800)
Train: Epoch[2/5]  [  0/313]  eta: 0:02:47  Lr: 0.001875  Loss: -0.1059  Acc@1: 93.7500 (93.7500)  Acc@5: 100.0000 (100.0000)  time: 0.5364  data: 0.2044  max mem: 2356
Train: Epoch[2/5]  [ 10/313]  eta: 0:01:45  Lr: 0.001875  Loss: 0.1265  Acc@1: 87.5000 (89.2045)  Acc@5: 100.0000 (98.8636)  time: 0.3483  data: 0.0188  max mem: 2356
Train: Epoch[2/5]  [ 20/313]  eta: 0:01:39  Lr: 0.001875  Loss: 0.3055  Acc@1: 87.5000 (88.3929)  Acc@5: 100.0000 (98.8095)  time: 0.3309  data: 0.0003  max mem: 2356
Train: Epoch[2/5]  [ 30/313]  eta: 0:01:35  Lr: 0.001875  Loss: 0.6787  Acc@1: 87.5000 (88.7097)  Acc@5: 100.0000 (98.9919)  time: 0.3321  data: 0.0004  max mem: 2356
Train: Epoch[2/5]  [ 40/313]  eta: 0:01:31  Lr: 0.001875  Loss: 0.5018  Acc@1: 87.5000 (89.3293)  Acc@5: 100.0000 (99.0854)  time: 0.3328  data: 0.0007  max mem: 2356
Train: Epoch[2/5]  [ 50/313]  eta: 0:01:28  Lr: 0.001875  Loss: 0.1528  Acc@1: 87.5000 (88.9706)  Acc@5: 100.0000 (99.0196)  time: 0.3333  data: 0.0006  max mem: 2356
Train: Epoch[2/5]  [ 60/313]  eta: 0:01:24  Lr: 0.001875  Loss: 0.1254  Acc@1: 87.5000 (88.6270)  Acc@5: 100.0000 (98.6680)  time: 0.3325  data: 0.0009  max mem: 2356
Train: Epoch[2/5]  [ 70/313]  eta: 0:01:21  Lr: 0.001875  Loss: 0.0604  Acc@1: 87.5000 (88.2923)  Acc@5: 100.0000 (98.5035)  time: 0.3324  data: 0.0010  max mem: 2356
Train: Epoch[2/5]  [ 80/313]  eta: 0:01:18  Lr: 0.001875  Loss: -0.0685  Acc@1: 93.7500 (88.5031)  Acc@5: 100.0000 (98.6111)  time: 0.3359  data: 0.0012  max mem: 2356
Train: Epoch[2/5]  [ 90/313]  eta: 0:01:14  Lr: 0.001875  Loss: 0.2313  Acc@1: 87.5000 (88.3929)  Acc@5: 100.0000 (98.2830)  time: 0.3372  data: 0.0012  max mem: 2356
Train: Epoch[2/5]  [100/313]  eta: 0:01:11  Lr: 0.001875  Loss: -0.1430  Acc@1: 87.5000 (88.4282)  Acc@5: 100.0000 (98.2673)  time: 0.3351  data: 0.0005  max mem: 2356
Train: Epoch[2/5]  [110/313]  eta: 0:01:08  Lr: 0.001875  Loss: -0.0695  Acc@1: 87.5000 (88.4009)  Acc@5: 100.0000 (98.3671)  time: 0.3388  data: 0.0005  max mem: 2356
Train: Epoch[2/5]  [120/313]  eta: 0:01:04  Lr: 0.001875  Loss: 0.2158  Acc@1: 87.5000 (88.1198)  Acc@5: 100.0000 (98.4504)  time: 0.3415  data: 0.0015  max mem: 2356
Train: Epoch[2/5]  [130/313]  eta: 0:01:01  Lr: 0.001875  Loss: 0.3185  Acc@1: 87.5000 (88.2156)  Acc@5: 100.0000 (98.4733)  time: 0.3391  data: 0.0017  max mem: 2356
Train: Epoch[2/5]  [140/313]  eta: 0:00:58  Lr: 0.001875  Loss: 0.3301  Acc@1: 87.5000 (87.8989)  Acc@5: 100.0000 (98.4929)  time: 0.3380  data: 0.0008  max mem: 2356
Train: Epoch[2/5]  [150/313]  eta: 0:00:54  Lr: 0.001875  Loss: -0.0556  Acc@1: 87.5000 (87.8725)  Acc@5: 100.0000 (98.4685)  time: 0.3380  data: 0.0006  max mem: 2356
Train: Epoch[2/5]  [160/313]  eta: 0:00:51  Lr: 0.001875  Loss: -0.1426  Acc@1: 87.5000 (87.8882)  Acc@5: 100.0000 (98.4860)  time: 0.3403  data: 0.0005  max mem: 2356
Train: Epoch[2/5]  [170/313]  eta: 0:00:48  Lr: 0.001875  Loss: 0.4309  Acc@1: 87.5000 (87.9020)  Acc@5: 100.0000 (98.5015)  time: 0.3418  data: 0.0016  max mem: 2356
Train: Epoch[2/5]  [180/313]  eta: 0:00:44  Lr: 0.001875  Loss: 0.0894  Acc@1: 93.7500 (88.1906)  Acc@5: 100.0000 (98.5843)  time: 0.3398  data: 0.0018  max mem: 2356
Train: Epoch[2/5]  [190/313]  eta: 0:00:41  Lr: 0.001875  Loss: 0.2395  Acc@1: 87.5000 (87.9254)  Acc@5: 100.0000 (98.5929)  time: 0.3395  data: 0.0009  max mem: 2356
Train: Epoch[2/5]  [200/313]  eta: 0:00:38  Lr: 0.001875  Loss: 0.2867  Acc@1: 81.2500 (87.7177)  Acc@5: 100.0000 (98.5075)  time: 0.3418  data: 0.0025  max mem: 2356
Train: Epoch[2/5]  [210/313]  eta: 0:00:34  Lr: 0.001875  Loss: 0.4027  Acc@1: 87.5000 (87.7962)  Acc@5: 100.0000 (98.5486)  time: 0.3455  data: 0.0032  max mem: 2356
Train: Epoch[2/5]  [220/313]  eta: 0:00:31  Lr: 0.001875  Loss: 0.1425  Acc@1: 87.5000 (87.7262)  Acc@5: 100.0000 (98.5294)  time: 0.3438  data: 0.0019  max mem: 2356
Train: Epoch[2/5]  [230/313]  eta: 0:00:28  Lr: 0.001875  Loss: 0.2876  Acc@1: 87.5000 (87.5812)  Acc@5: 100.0000 (98.5390)  time: 0.3405  data: 0.0021  max mem: 2356
Train: Epoch[2/5]  [240/313]  eta: 0:00:24  Lr: 0.001875  Loss: 0.1718  Acc@1: 87.5000 (87.6297)  Acc@5: 100.0000 (98.5737)  time: 0.3416  data: 0.0019  max mem: 2356
Train: Epoch[2/5]  [250/313]  eta: 0:00:21  Lr: 0.001875  Loss: -0.1606  Acc@1: 87.5000 (87.7490)  Acc@5: 100.0000 (98.6056)  time: 0.3378  data: 0.0007  max mem: 2356
Train: Epoch[2/5]  [260/313]  eta: 0:00:17  Lr: 0.001875  Loss: -0.0579  Acc@1: 87.5000 (87.7874)  Acc@5: 100.0000 (98.5632)  time: 0.3339  data: 0.0005  max mem: 2356
Train: Epoch[2/5]  [270/313]  eta: 0:00:14  Lr: 0.001875  Loss: 0.1022  Acc@1: 87.5000 (87.7998)  Acc@5: 100.0000 (98.5701)  time: 0.3357  data: 0.0005  max mem: 2356
Train: Epoch[2/5]  [280/313]  eta: 0:00:11  Lr: 0.001875  Loss: 0.0053  Acc@1: 87.5000 (87.7891)  Acc@5: 100.0000 (98.5543)  time: 0.3351  data: 0.0005  max mem: 2356
Train: Epoch[2/5]  [290/313]  eta: 0:00:07  Lr: 0.001875  Loss: -0.0568  Acc@1: 87.5000 (87.8866)  Acc@5: 100.0000 (98.5825)  time: 0.3339  data: 0.0004  max mem: 2356
Train: Epoch[2/5]  [300/313]  eta: 0:00:04  Lr: 0.001875  Loss: 0.3309  Acc@1: 87.5000 (87.7492)  Acc@5: 100.0000 (98.5050)  time: 0.3342  data: 0.0004  max mem: 2356
Train: Epoch[2/5]  [310/313]  eta: 0:00:01  Lr: 0.001875  Loss: 0.2465  Acc@1: 87.5000 (87.7010)  Acc@5: 100.0000 (98.4727)  time: 0.3334  data: 0.0004  max mem: 2356
Train: Epoch[2/5]  [312/313]  eta: 0:00:00  Lr: 0.001875  Loss: 0.4838  Acc@1: 87.5000 (87.6800)  Acc@5: 100.0000 (98.4600)  time: 0.3254  data: 0.0003  max mem: 2356
Train: Epoch[2/5] Total time: 0:01:45 (0.3376 s / it)
{0: {0: 22412, 1: 24815, 2: 19998, 3: 5534, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}, 1: {0: 1577, 1: 208, 2: 5200, 3: 4503, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}, 2: {0: 3518, 1: 6779, 2: 5327, 3: 4052, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}, 3: {0: 21486, 1: 20777, 2: 18903, 3: 5729, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}, 4: {0: 16124, 1: 10227, 2: 6432, 3: 4240, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}, 5: {0: 23402, 1: 24357, 2: 21714, 3: 5910, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}, 6: {0: 9472, 1: 12148, 2: 17669, 3: 5534, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}, 7: {0: 752, 1: 676, 2: 4577, 3: 4362, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}, 8: {0: 24269, 1: 24959, 2: 24373, 3: 9830, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}, 9: {0: 1988, 1: 54, 2: 807, 3: 306, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}}
Averaged stats: Lr: 0.001875  Loss: 0.4838  Acc@1: 87.5000 (87.6800)  Acc@5: 100.0000 (98.4600)
Train: Epoch[3/5]  [  0/313]  eta: 0:03:19  Lr: 0.001875  Loss: 0.1049  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (100.0000)  time: 0.6360  data: 0.2954  max mem: 2356
Train: Epoch[3/5]  [ 10/313]  eta: 0:01:49  Lr: 0.001875  Loss: 0.0487  Acc@1: 87.5000 (88.6364)  Acc@5: 100.0000 (98.2955)  time: 0.3606  data: 0.0273  max mem: 2356
Train: Epoch[3/5]  [ 20/313]  eta: 0:01:42  Lr: 0.001875  Loss: -0.0031  Acc@1: 87.5000 (88.3929)  Acc@5: 100.0000 (98.2143)  time: 0.3345  data: 0.0004  max mem: 2356
Train: Epoch[3/5]  [ 30/313]  eta: 0:01:37  Lr: 0.001875  Loss: -0.0936  Acc@1: 87.5000 (87.7016)  Acc@5: 100.0000 (98.1855)  time: 0.3369  data: 0.0014  max mem: 2356
Train: Epoch[3/5]  [ 40/313]  eta: 0:01:33  Lr: 0.001875  Loss: 0.3869  Acc@1: 87.5000 (86.5854)  Acc@5: 100.0000 (97.8659)  time: 0.3349  data: 0.0013  max mem: 2356
Train: Epoch[3/5]  [ 50/313]  eta: 0:01:29  Lr: 0.001875  Loss: 0.2968  Acc@1: 87.5000 (87.0098)  Acc@5: 100.0000 (97.9167)  time: 0.3315  data: 0.0003  max mem: 2356
Train: Epoch[3/5]  [ 60/313]  eta: 0:01:25  Lr: 0.001875  Loss: 0.0240  Acc@1: 87.5000 (87.1926)  Acc@5: 100.0000 (98.2582)  time: 0.3325  data: 0.0006  max mem: 2356
Train: Epoch[3/5]  [ 70/313]  eta: 0:01:22  Lr: 0.001875  Loss: 0.2173  Acc@1: 87.5000 (86.7077)  Acc@5: 100.0000 (98.1514)  time: 0.3326  data: 0.0007  max mem: 2356
Train: Epoch[3/5]  [ 80/313]  eta: 0:01:18  Lr: 0.001875  Loss: 0.2451  Acc@1: 87.5000 (87.3457)  Acc@5: 100.0000 (98.3796)  time: 0.3311  data: 0.0004  max mem: 2356
Train: Epoch[3/5]  [ 90/313]  eta: 0:01:15  Lr: 0.001875  Loss: 0.1988  Acc@1: 93.7500 (87.3626)  Acc@5: 100.0000 (98.4203)  time: 0.3316  data: 0.0007  max mem: 2356
Train: Epoch[3/5]  [100/313]  eta: 0:01:11  Lr: 0.001875  Loss: -0.0331  Acc@1: 87.5000 (87.4381)  Acc@5: 100.0000 (98.4530)  time: 0.3321  data: 0.0007  max mem: 2356
Train: Epoch[3/5]  [110/313]  eta: 0:01:08  Lr: 0.001875  Loss: 0.0528  Acc@1: 87.5000 (87.4437)  Acc@5: 100.0000 (98.4797)  time: 0.3306  data: 0.0003  max mem: 2356
Train: Epoch[3/5]  [120/313]  eta: 0:01:04  Lr: 0.001875  Loss: 0.2152  Acc@1: 87.5000 (87.4483)  Acc@5: 100.0000 (98.5537)  time: 0.3321  data: 0.0008  max mem: 2356
Train: Epoch[3/5]  [130/313]  eta: 0:01:01  Lr: 0.001875  Loss: 0.0674  Acc@1: 87.5000 (87.7863)  Acc@5: 100.0000 (98.5210)  time: 0.3363  data: 0.0009  max mem: 2356
Train: Epoch[3/5]  [140/313]  eta: 0:00:58  Lr: 0.001875  Loss: 0.3763  Acc@1: 87.5000 (87.5443)  Acc@5: 100.0000 (98.4486)  time: 0.3426  data: 0.0015  max mem: 2356
Train: Epoch[3/5]  [150/313]  eta: 0:00:54  Lr: 0.001875  Loss: 0.0054  Acc@1: 87.5000 (87.5414)  Acc@5: 100.0000 (98.4272)  time: 0.3432  data: 0.0015  max mem: 2356
Train: Epoch[3/5]  [160/313]  eta: 0:00:51  Lr: 0.001875  Loss: 0.0795  Acc@1: 87.5000 (87.5776)  Acc@5: 100.0000 (98.4860)  time: 0.3368  data: 0.0007  max mem: 2356
Train: Epoch[3/5]  [170/313]  eta: 0:00:48  Lr: 0.001875  Loss: 0.1729  Acc@1: 87.5000 (87.7558)  Acc@5: 100.0000 (98.5015)  time: 0.3378  data: 0.0007  max mem: 2356
Train: Epoch[3/5]  [180/313]  eta: 0:00:44  Lr: 0.001875  Loss: 0.1602  Acc@1: 87.5000 (87.6381)  Acc@5: 100.0000 (98.4116)  time: 0.3381  data: 0.0006  max mem: 2356
Train: Epoch[3/5]  [190/313]  eta: 0:00:41  Lr: 0.001875  Loss: 0.0936  Acc@1: 81.2500 (87.4018)  Acc@5: 100.0000 (98.3966)  time: 0.3354  data: 0.0005  max mem: 2356
Train: Epoch[3/5]  [200/313]  eta: 0:00:38  Lr: 0.001875  Loss: 0.4000  Acc@1: 81.2500 (87.4689)  Acc@5: 100.0000 (98.3831)  time: 0.3353  data: 0.0007  max mem: 2356
Train: Epoch[3/5]  [210/313]  eta: 0:00:34  Lr: 0.001875  Loss: 0.2006  Acc@1: 93.7500 (87.6185)  Acc@5: 100.0000 (98.3709)  time: 0.3408  data: 0.0012  max mem: 2356
Train: Epoch[3/5]  [220/313]  eta: 0:00:31  Lr: 0.001875  Loss: -0.0656  Acc@1: 93.7500 (87.5000)  Acc@5: 100.0000 (98.3880)  time: 0.3421  data: 0.0013  max mem: 2356
Train: Epoch[3/5]  [230/313]  eta: 0:00:27  Lr: 0.001875  Loss: -0.1127  Acc@1: 87.5000 (87.5541)  Acc@5: 100.0000 (98.3496)  time: 0.3403  data: 0.0009  max mem: 2356
Train: Epoch[3/5]  [240/313]  eta: 0:00:24  Lr: 0.001875  Loss: -0.0632  Acc@1: 87.5000 (87.6815)  Acc@5: 100.0000 (98.3662)  time: 0.3431  data: 0.0014  max mem: 2356
Train: Epoch[3/5]  [250/313]  eta: 0:00:21  Lr: 0.001875  Loss: -0.0633  Acc@1: 93.7500 (87.7490)  Acc@5: 100.0000 (98.3068)  time: 0.3415  data: 0.0014  max mem: 2356
Train: Epoch[3/5]  [260/313]  eta: 0:00:17  Lr: 0.001875  Loss: 0.2508  Acc@1: 87.5000 (87.7395)  Acc@5: 93.7500 (98.2519)  time: 0.3380  data: 0.0007  max mem: 2356
Train: Epoch[3/5]  [270/313]  eta: 0:00:14  Lr: 0.001875  Loss: 0.4371  Acc@1: 87.5000 (87.8229)  Acc@5: 100.0000 (98.2703)  time: 0.3359  data: 0.0012  max mem: 2356
Train: Epoch[3/5]  [280/313]  eta: 0:00:11  Lr: 0.001875  Loss: 0.1404  Acc@1: 87.5000 (87.8336)  Acc@5: 100.0000 (98.2651)  time: 0.3359  data: 0.0012  max mem: 2356
Train: Epoch[3/5]  [290/313]  eta: 0:00:07  Lr: 0.001875  Loss: 0.0418  Acc@1: 87.5000 (87.8436)  Acc@5: 100.0000 (98.3033)  time: 0.3347  data: 0.0006  max mem: 2356
Train: Epoch[3/5]  [300/313]  eta: 0:00:04  Lr: 0.001875  Loss: 0.0876  Acc@1: 87.5000 (87.7699)  Acc@5: 100.0000 (98.2766)  time: 0.3330  data: 0.0005  max mem: 2356
Train: Epoch[3/5]  [310/313]  eta: 0:00:01  Lr: 0.001875  Loss: -0.1158  Acc@1: 87.5000 (87.6407)  Acc@5: 100.0000 (98.3119)  time: 0.3325  data: 0.0004  max mem: 2356
Train: Epoch[3/5]  [312/313]  eta: 0:00:00  Lr: 0.001875  Loss: 0.1006  Acc@1: 87.5000 (87.6600)  Acc@5: 100.0000 (98.3200)  time: 0.3244  data: 0.0003  max mem: 2356
Train: Epoch[3/5] Total time: 0:01:45 (0.3370 s / it)
{0: {0: 22412, 1: 24815, 2: 19998, 3: 7842, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}, 1: {0: 1577, 1: 208, 2: 5200, 3: 7125, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}, 2: {0: 3518, 1: 6779, 2: 5327, 3: 5981, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}, 3: {0: 21486, 1: 20777, 2: 18903, 3: 8756, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}, 4: {0: 16124, 1: 10227, 2: 6432, 3: 6193, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}, 5: {0: 23402, 1: 24357, 2: 21714, 3: 8962, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}, 6: {0: 9472, 1: 12148, 2: 17669, 3: 8459, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}, 7: {0: 752, 1: 676, 2: 4577, 3: 6385, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}, 8: {0: 24269, 1: 24959, 2: 24373, 3: 14471, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}, 9: {0: 1988, 1: 54, 2: 807, 3: 826, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}}
Averaged stats: Lr: 0.001875  Loss: 0.1006  Acc@1: 87.5000 (87.6600)  Acc@5: 100.0000 (98.3200)
Train: Epoch[4/5]  [  0/313]  eta: 0:03:17  Lr: 0.001875  Loss: -0.0980  Acc@1: 93.7500 (93.7500)  Acc@5: 100.0000 (100.0000)  time: 0.6297  data: 0.2952  max mem: 2356
Train: Epoch[4/5]  [ 10/313]  eta: 0:01:48  Lr: 0.001875  Loss: -0.1635  Acc@1: 93.7500 (90.9091)  Acc@5: 100.0000 (98.2955)  time: 0.3588  data: 0.0273  max mem: 2356
Train: Epoch[4/5]  [ 20/313]  eta: 0:01:41  Lr: 0.001875  Loss: 0.1635  Acc@1: 87.5000 (90.4762)  Acc@5: 100.0000 (98.5119)  time: 0.3325  data: 0.0004  max mem: 2356
Train: Epoch[4/5]  [ 30/313]  eta: 0:01:36  Lr: 0.001875  Loss: 0.1458  Acc@1: 87.5000 (88.5081)  Acc@5: 100.0000 (98.7903)  time: 0.3330  data: 0.0004  max mem: 2356
Train: Epoch[4/5]  [ 40/313]  eta: 0:01:32  Lr: 0.001875  Loss: 0.1171  Acc@1: 87.5000 (89.0244)  Acc@5: 100.0000 (98.7805)  time: 0.3333  data: 0.0006  max mem: 2356
Train: Epoch[4/5]  [ 50/313]  eta: 0:01:29  Lr: 0.001875  Loss: -0.0437  Acc@1: 87.5000 (88.7255)  Acc@5: 100.0000 (98.8971)  time: 0.3334  data: 0.0006  max mem: 2356
Train: Epoch[4/5]  [ 60/313]  eta: 0:01:25  Lr: 0.001875  Loss: 0.0473  Acc@1: 87.5000 (88.3197)  Acc@5: 100.0000 (98.9754)  time: 0.3331  data: 0.0006  max mem: 2356
Train: Epoch[4/5]  [ 70/313]  eta: 0:01:22  Lr: 0.001875  Loss: 0.1444  Acc@1: 87.5000 (88.3803)  Acc@5: 100.0000 (99.0317)  time: 0.3346  data: 0.0011  max mem: 2356
Train: Epoch[4/5]  [ 80/313]  eta: 0:01:18  Lr: 0.001875  Loss: 0.1371  Acc@1: 93.7500 (89.0432)  Acc@5: 100.0000 (99.0741)  time: 0.3355  data: 0.0018  max mem: 2356
Train: Epoch[4/5]  [ 90/313]  eta: 0:01:15  Lr: 0.001875  Loss: -0.1173  Acc@1: 93.7500 (89.2857)  Acc@5: 100.0000 (98.9698)  time: 0.3330  data: 0.0012  max mem: 2356
Train: Epoch[4/5]  [100/313]  eta: 0:01:11  Lr: 0.001875  Loss: -0.0102  Acc@1: 93.7500 (89.4802)  Acc@5: 100.0000 (99.0099)  time: 0.3324  data: 0.0003  max mem: 2356
Train: Epoch[4/5]  [110/313]  eta: 0:01:08  Lr: 0.001875  Loss: 0.2985  Acc@1: 93.7500 (89.3018)  Acc@5: 100.0000 (98.9865)  time: 0.3331  data: 0.0003  max mem: 2356
Train: Epoch[4/5]  [120/313]  eta: 0:01:04  Lr: 0.001875  Loss: 0.0574  Acc@1: 87.5000 (89.3595)  Acc@5: 100.0000 (98.9669)  time: 0.3330  data: 0.0003  max mem: 2356
Train: Epoch[4/5]  [130/313]  eta: 0:01:01  Lr: 0.001875  Loss: 0.2562  Acc@1: 87.5000 (89.2653)  Acc@5: 100.0000 (98.9027)  time: 0.3326  data: 0.0005  max mem: 2356
Train: Epoch[4/5]  [140/313]  eta: 0:00:58  Lr: 0.001875  Loss: 0.4689  Acc@1: 87.5000 (89.1401)  Acc@5: 100.0000 (98.9362)  time: 0.3328  data: 0.0014  max mem: 2356
Train: Epoch[4/5]  [150/313]  eta: 0:00:54  Lr: 0.001875  Loss: 0.2064  Acc@1: 87.5000 (88.7417)  Acc@5: 100.0000 (98.8825)  time: 0.3365  data: 0.0025  max mem: 2356
Train: Epoch[4/5]  [160/313]  eta: 0:00:51  Lr: 0.001875  Loss: 0.4063  Acc@1: 87.5000 (88.8199)  Acc@5: 100.0000 (98.8354)  time: 0.3366  data: 0.0017  max mem: 2356
Train: Epoch[4/5]  [170/313]  eta: 0:00:48  Lr: 0.001875  Loss: -0.1044  Acc@1: 93.7500 (89.0351)  Acc@5: 100.0000 (98.9035)  time: 0.3387  data: 0.0014  max mem: 2356
Train: Epoch[4/5]  [180/313]  eta: 0:00:44  Lr: 0.001875  Loss: -0.0923  Acc@1: 93.7500 (89.1575)  Acc@5: 100.0000 (98.9296)  time: 0.3408  data: 0.0020  max mem: 2356
Train: Epoch[4/5]  [190/313]  eta: 0:00:41  Lr: 0.001875  Loss: 0.0932  Acc@1: 93.7500 (89.2016)  Acc@5: 100.0000 (98.9529)  time: 0.3391  data: 0.0015  max mem: 2356
Train: Epoch[4/5]  [200/313]  eta: 0:00:38  Lr: 0.001875  Loss: -0.1785  Acc@1: 87.5000 (89.2102)  Acc@5: 100.0000 (98.9739)  time: 0.3400  data: 0.0019  max mem: 2356
Train: Epoch[4/5]  [210/313]  eta: 0:00:34  Lr: 0.001875  Loss: 0.1967  Acc@1: 87.5000 (89.2476)  Acc@5: 100.0000 (98.9633)  time: 0.3398  data: 0.0019  max mem: 2356
Train: Epoch[4/5]  [220/313]  eta: 0:00:31  Lr: 0.001875  Loss: 0.4208  Acc@1: 87.5000 (89.0837)  Acc@5: 100.0000 (98.8688)  time: 0.3398  data: 0.0041  max mem: 2356
Train: Epoch[4/5]  [230/313]  eta: 0:00:27  Lr: 0.001875  Loss: 0.1873  Acc@1: 87.5000 (89.0152)  Acc@5: 100.0000 (98.8907)  time: 0.3384  data: 0.0039  max mem: 2356
Train: Epoch[4/5]  [240/313]  eta: 0:00:24  Lr: 0.001875  Loss: 0.1045  Acc@1: 93.7500 (89.0820)  Acc@5: 100.0000 (98.8849)  time: 0.3353  data: 0.0013  max mem: 2356
Train: Epoch[4/5]  [250/313]  eta: 0:00:21  Lr: 0.001875  Loss: -0.0140  Acc@1: 87.5000 (88.9193)  Acc@5: 100.0000 (98.8048)  time: 0.3357  data: 0.0014  max mem: 2356
Train: Epoch[4/5]  [260/313]  eta: 0:00:17  Lr: 0.001875  Loss: 0.0109  Acc@1: 87.5000 (88.9368)  Acc@5: 100.0000 (98.8027)  time: 0.3350  data: 0.0008  max mem: 2356
Train: Epoch[4/5]  [270/313]  eta: 0:00:14  Lr: 0.001875  Loss: 0.3316  Acc@1: 93.7500 (89.0452)  Acc@5: 100.0000 (98.8238)  time: 0.3372  data: 0.0010  max mem: 2356
Train: Epoch[4/5]  [280/313]  eta: 0:00:11  Lr: 0.001875  Loss: 0.1511  Acc@1: 87.5000 (88.7678)  Acc@5: 100.0000 (98.8212)  time: 0.3431  data: 0.0011  max mem: 2356
Train: Epoch[4/5]  [290/313]  eta: 0:00:07  Lr: 0.001875  Loss: 0.2802  Acc@1: 87.5000 (88.8316)  Acc@5: 100.0000 (98.8617)  time: 0.3406  data: 0.0005  max mem: 2356
Train: Epoch[4/5]  [300/313]  eta: 0:00:04  Lr: 0.001875  Loss: 0.3860  Acc@1: 93.7500 (88.9120)  Acc@5: 100.0000 (98.8164)  time: 0.3364  data: 0.0004  max mem: 2356
Train: Epoch[4/5]  [310/313]  eta: 0:00:01  Lr: 0.001875  Loss: -0.0605  Acc@1: 93.7500 (88.9871)  Acc@5: 100.0000 (98.8143)  time: 0.3422  data: 0.0004  max mem: 2356
Train: Epoch[4/5]  [312/313]  eta: 0:00:00  Lr: 0.001875  Loss: -0.0434  Acc@1: 87.5000 (88.9800)  Acc@5: 100.0000 (98.8200)  time: 0.3349  data: 0.0004  max mem: 2356
Train: Epoch[4/5] Total time: 0:01:45 (0.3374 s / it)
{0: {0: 22412, 1: 24815, 2: 19998, 3: 10016, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}, 1: {0: 1577, 1: 208, 2: 5200, 3: 9900, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}, 2: {0: 3518, 1: 6779, 2: 5327, 3: 7894, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}, 3: {0: 21486, 1: 20777, 2: 18903, 3: 11806, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}, 4: {0: 16124, 1: 10227, 2: 6432, 3: 8140, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}, 5: {0: 23402, 1: 24357, 2: 21714, 3: 12020, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}, 6: {0: 9472, 1: 12148, 2: 17669, 3: 11446, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}, 7: {0: 752, 1: 676, 2: 4577, 3: 8358, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}, 8: {0: 24269, 1: 24959, 2: 24373, 3: 18928, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}, 9: {0: 1988, 1: 54, 2: 807, 3: 1492, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}}
Averaged stats: Lr: 0.001875  Loss: -0.0434  Acc@1: 87.5000 (88.9800)  Acc@5: 100.0000 (98.8200)
Train: Epoch[5/5]  [  0/313]  eta: 0:04:10  Lr: 0.001875  Loss: -0.0740  Acc@1: 93.7500 (93.7500)  Acc@5: 100.0000 (100.0000)  time: 0.7998  data: 0.3340  max mem: 2356
Train: Epoch[5/5]  [ 10/313]  eta: 0:01:56  Lr: 0.001875  Loss: -0.0426  Acc@1: 93.7500 (90.3409)  Acc@5: 100.0000 (98.2955)  time: 0.3839  data: 0.0314  max mem: 2356
Train: Epoch[5/5]  [ 20/313]  eta: 0:01:45  Lr: 0.001875  Loss: 0.1681  Acc@1: 87.5000 (89.8810)  Acc@5: 100.0000 (98.2143)  time: 0.3377  data: 0.0008  max mem: 2356
Train: Epoch[5/5]  [ 30/313]  eta: 0:01:39  Lr: 0.001875  Loss: 0.1789  Acc@1: 87.5000 (89.7177)  Acc@5: 100.0000 (98.5887)  time: 0.3339  data: 0.0003  max mem: 2356
Train: Epoch[5/5]  [ 40/313]  eta: 0:01:34  Lr: 0.001875  Loss: 0.1720  Acc@1: 87.5000 (88.5671)  Acc@5: 100.0000 (98.4756)  time: 0.3337  data: 0.0004  max mem: 2356
Train: Epoch[5/5]  [ 50/313]  eta: 0:01:30  Lr: 0.001875  Loss: 0.3319  Acc@1: 87.5000 (88.7255)  Acc@5: 100.0000 (98.6520)  time: 0.3343  data: 0.0006  max mem: 2356
Train: Epoch[5/5]  [ 60/313]  eta: 0:01:27  Lr: 0.001875  Loss: -0.0780  Acc@1: 87.5000 (89.1393)  Acc@5: 100.0000 (98.7705)  time: 0.3379  data: 0.0020  max mem: 2356
Train: Epoch[5/5]  [ 70/313]  eta: 0:01:23  Lr: 0.001875  Loss: -0.0742  Acc@1: 93.7500 (89.4366)  Acc@5: 100.0000 (98.7676)  time: 0.3373  data: 0.0018  max mem: 2356
Train: Epoch[5/5]  [ 80/313]  eta: 0:01:19  Lr: 0.001875  Loss: -0.0701  Acc@1: 87.5000 (89.4290)  Acc@5: 100.0000 (98.5340)  time: 0.3354  data: 0.0004  max mem: 2356
Train: Epoch[5/5]  [ 90/313]  eta: 0:01:16  Lr: 0.001875  Loss: -0.1513  Acc@1: 93.7500 (89.9038)  Acc@5: 100.0000 (98.6264)  time: 0.3350  data: 0.0010  max mem: 2356
Train: Epoch[5/5]  [100/313]  eta: 0:01:12  Lr: 0.001875  Loss: -0.0398  Acc@1: 93.7500 (90.0371)  Acc@5: 100.0000 (98.7005)  time: 0.3336  data: 0.0010  max mem: 2356
Train: Epoch[5/5]  [110/313]  eta: 0:01:09  Lr: 0.001875  Loss: 0.1628  Acc@1: 93.7500 (89.9212)  Acc@5: 100.0000 (98.7050)  time: 0.3351  data: 0.0004  max mem: 2356
Train: Epoch[5/5]  [120/313]  eta: 0:01:05  Lr: 0.001875  Loss: 0.0816  Acc@1: 87.5000 (89.9793)  Acc@5: 100.0000 (98.6570)  time: 0.3350  data: 0.0004  max mem: 2356
Train: Epoch[5/5]  [130/313]  eta: 0:01:01  Lr: 0.001875  Loss: 0.0380  Acc@1: 87.5000 (89.8378)  Acc@5: 100.0000 (98.7118)  time: 0.3322  data: 0.0003  max mem: 2356
Train: Epoch[5/5]  [140/313]  eta: 0:00:58  Lr: 0.001875  Loss: -0.0975  Acc@1: 93.7500 (90.1152)  Acc@5: 100.0000 (98.8032)  time: 0.3321  data: 0.0003  max mem: 2356
Train: Epoch[5/5]  [150/313]  eta: 0:00:55  Lr: 0.001875  Loss: -0.0392  Acc@1: 93.7500 (90.2732)  Acc@5: 100.0000 (98.8825)  time: 0.3341  data: 0.0003  max mem: 2356
Train: Epoch[5/5]  [160/313]  eta: 0:00:51  Lr: 0.001875  Loss: 0.2272  Acc@1: 93.7500 (90.3727)  Acc@5: 100.0000 (98.8742)  time: 0.3343  data: 0.0006  max mem: 2356
Train: Epoch[5/5]  [170/313]  eta: 0:00:48  Lr: 0.001875  Loss: -0.0597  Acc@1: 93.7500 (90.4971)  Acc@5: 100.0000 (98.9035)  time: 0.3354  data: 0.0007  max mem: 2356
Train: Epoch[5/5]  [180/313]  eta: 0:00:44  Lr: 0.001875  Loss: 0.2745  Acc@1: 93.7500 (90.5732)  Acc@5: 100.0000 (98.8605)  time: 0.3344  data: 0.0006  max mem: 2356
Train: Epoch[5/5]  [190/313]  eta: 0:00:41  Lr: 0.001875  Loss: 0.5506  Acc@1: 87.5000 (90.3796)  Acc@5: 100.0000 (98.7893)  time: 0.3322  data: 0.0013  max mem: 2356
Train: Epoch[5/5]  [200/313]  eta: 0:00:38  Lr: 0.001875  Loss: 0.0053  Acc@1: 87.5000 (90.3918)  Acc@5: 100.0000 (98.8495)  time: 0.3352  data: 0.0011  max mem: 2356
Train: Epoch[5/5]  [210/313]  eta: 0:00:34  Lr: 0.001875  Loss: 0.4981  Acc@1: 87.5000 (90.4028)  Acc@5: 100.0000 (98.8744)  time: 0.3409  data: 0.0009  max mem: 2356
Train: Epoch[5/5]  [220/313]  eta: 0:00:31  Lr: 0.001875  Loss: -0.0787  Acc@1: 93.7500 (90.3846)  Acc@5: 100.0000 (98.8405)  time: 0.3427  data: 0.0022  max mem: 2356
Train: Epoch[5/5]  [230/313]  eta: 0:00:28  Lr: 0.001875  Loss: -0.0455  Acc@1: 93.7500 (90.3680)  Acc@5: 100.0000 (98.8095)  time: 0.3411  data: 0.0019  max mem: 2356
Train: Epoch[5/5]  [240/313]  eta: 0:00:24  Lr: 0.001875  Loss: 0.4122  Acc@1: 87.5000 (90.3008)  Acc@5: 100.0000 (98.8589)  time: 0.3369  data: 0.0006  max mem: 2356
Train: Epoch[5/5]  [250/313]  eta: 0:00:21  Lr: 0.001875  Loss: -0.1383  Acc@1: 93.7500 (90.3884)  Acc@5: 100.0000 (98.8546)  time: 0.3364  data: 0.0005  max mem: 2356
Train: Epoch[5/5]  [260/313]  eta: 0:00:17  Lr: 0.001875  Loss: 0.1129  Acc@1: 93.7500 (90.4215)  Acc@5: 100.0000 (98.8506)  time: 0.3392  data: 0.0006  max mem: 2356
Train: Epoch[5/5]  [270/313]  eta: 0:00:14  Lr: 0.001875  Loss: -0.1661  Acc@1: 93.7500 (90.3367)  Acc@5: 100.0000 (98.8007)  time: 0.3391  data: 0.0006  max mem: 2356
Train: Epoch[5/5]  [280/313]  eta: 0:00:11  Lr: 0.001875  Loss: 0.0634  Acc@1: 87.5000 (90.2580)  Acc@5: 100.0000 (98.7989)  time: 0.3425  data: 0.0011  max mem: 2356
Train: Epoch[5/5]  [290/313]  eta: 0:00:07  Lr: 0.001875  Loss: 0.3859  Acc@1: 87.5000 (90.2491)  Acc@5: 100.0000 (98.8187)  time: 0.3417  data: 0.0018  max mem: 2356
Train: Epoch[5/5]  [300/313]  eta: 0:00:04  Lr: 0.001875  Loss: 0.3223  Acc@1: 93.7500 (90.2616)  Acc@5: 100.0000 (98.7749)  time: 0.3438  data: 0.0014  max mem: 2356
Train: Epoch[5/5]  [310/313]  eta: 0:00:01  Lr: 0.001875  Loss: 0.2594  Acc@1: 93.7500 (90.2331)  Acc@5: 100.0000 (98.7138)  time: 0.3441  data: 0.0005  max mem: 2356
Train: Epoch[5/5]  [312/313]  eta: 0:00:00  Lr: 0.001875  Loss: -0.0359  Acc@1: 87.5000 (90.2400)  Acc@5: 100.0000 (98.7200)  time: 0.3286  data: 0.0004  max mem: 2356
Train: Epoch[5/5] Total time: 0:01:45 (0.3384 s / it)
{0: {0: 22412, 1: 24815, 2: 19998, 3: 12102, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}, 1: {0: 1577, 1: 208, 2: 5200, 3: 12775, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}, 2: {0: 3518, 1: 6779, 2: 5327, 3: 9830, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}, 3: {0: 21486, 1: 20777, 2: 18903, 3: 14840, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}, 4: {0: 16124, 1: 10227, 2: 6432, 3: 10102, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}, 5: {0: 23402, 1: 24357, 2: 21714, 3: 15057, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}, 6: {0: 9472, 1: 12148, 2: 17669, 3: 14460, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}, 7: {0: 752, 1: 676, 2: 4577, 3: 10334, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}, 8: {0: 24269, 1: 24959, 2: 24373, 3: 23260, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}, 9: {0: 1988, 1: 54, 2: 807, 3: 2240, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}}
Averaged stats: Lr: 0.001875  Loss: -0.0359  Acc@1: 87.5000 (90.2400)  Acc@5: 100.0000 (98.7200)
Test: [Task 1]  [ 0/63]  eta: 0:00:37  Loss: 0.5482 (0.5482)  Acc@1: 93.7500 (93.7500)  Acc@5: 100.0000 (100.0000)  time: 0.5989  data: 0.3926  max mem: 2356
Test: [Task 1]  [10/63]  eta: 0:00:12  Loss: 0.5226 (0.5323)  Acc@1: 87.5000 (88.6364)  Acc@5: 100.0000 (99.4318)  time: 0.2427  data: 0.0368  max mem: 2356
Test: [Task 1]  [20/63]  eta: 0:00:09  Loss: 0.5226 (0.5924)  Acc@1: 87.5000 (87.2024)  Acc@5: 100.0000 (99.1071)  time: 0.2068  data: 0.0012  max mem: 2356
Test: [Task 1]  [30/63]  eta: 0:00:07  Loss: 0.5274 (0.5667)  Acc@1: 87.5000 (88.1048)  Acc@5: 100.0000 (99.3952)  time: 0.2088  data: 0.0018  max mem: 2356
Test: [Task 1]  [40/63]  eta: 0:00:05  Loss: 0.4945 (0.5703)  Acc@1: 93.7500 (88.1098)  Acc@5: 100.0000 (99.5427)  time: 0.2103  data: 0.0020  max mem: 2356
Test: [Task 1]  [50/63]  eta: 0:00:02  Loss: 0.4767 (0.5479)  Acc@1: 93.7500 (88.9706)  Acc@5: 100.0000 (99.3873)  time: 0.2093  data: 0.0010  max mem: 2356
Test: [Task 1]  [60/63]  eta: 0:00:00  Loss: 0.4759 (0.5402)  Acc@1: 93.7500 (89.1393)  Acc@5: 100.0000 (99.2828)  time: 0.2092  data: 0.0003  max mem: 2356
Test: [Task 1]  [62/63]  eta: 0:00:00  Loss: 0.4479 (0.5394)  Acc@1: 93.7500 (89.4000)  Acc@5: 100.0000 (99.3000)  time: 0.2041  data: 0.0003  max mem: 2356
Test: [Task 1] Total time: 0:00:13 (0.2142 s / it)
* Acc@1 89.400 Acc@5 99.300 loss 0.539
Test: [Task 2]  [ 0/63]  eta: 0:00:43  Loss: 0.7693 (0.7693)  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (100.0000)  time: 0.6979  data: 0.4849  max mem: 2356
Test: [Task 2]  [10/63]  eta: 0:00:13  Loss: 0.6942 (0.7078)  Acc@1: 93.7500 (90.9091)  Acc@5: 100.0000 (98.2955)  time: 0.2580  data: 0.0445  max mem: 2356
Test: [Task 2]  [20/63]  eta: 0:00:10  Loss: 0.7125 (0.7807)  Acc@1: 87.5000 (88.0952)  Acc@5: 100.0000 (97.6190)  time: 0.2110  data: 0.0010  max mem: 2356
Test: [Task 2]  [30/63]  eta: 0:00:07  Loss: 0.7242 (0.7657)  Acc@1: 87.5000 (87.9032)  Acc@5: 100.0000 (97.3790)  time: 0.2156  data: 0.0015  max mem: 2356
Test: [Task 2]  [40/63]  eta: 0:00:05  Loss: 0.7066 (0.7429)  Acc@1: 87.5000 (88.2622)  Acc@5: 100.0000 (97.7134)  time: 0.2151  data: 0.0012  max mem: 2356
Test: [Task 2]  [50/63]  eta: 0:00:02  Loss: 0.6385 (0.7398)  Acc@1: 87.5000 (87.2549)  Acc@5: 100.0000 (98.0392)  time: 0.2062  data: 0.0006  max mem: 2356
Test: [Task 2]  [60/63]  eta: 0:00:00  Loss: 0.6073 (0.7111)  Acc@1: 87.5000 (87.9098)  Acc@5: 100.0000 (98.3607)  time: 0.2059  data: 0.0003  max mem: 2356
Test: [Task 2]  [62/63]  eta: 0:00:00  Loss: 0.5449 (0.7004)  Acc@1: 87.5000 (88.1000)  Acc@5: 100.0000 (98.4000)  time: 0.2011  data: 0.0003  max mem: 2356
Test: [Task 2] Total time: 0:00:13 (0.2178 s / it)
* Acc@1 88.100 Acc@5 98.400 loss 0.700
Test: [Task 3]  [ 0/63]  eta: 0:00:35  Loss: 0.3759 (0.3759)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)  time: 0.5620  data: 0.3543  max mem: 2356
Test: [Task 3]  [10/63]  eta: 0:00:12  Loss: 0.5428 (0.5730)  Acc@1: 87.5000 (88.6364)  Acc@5: 100.0000 (98.8636)  time: 0.2392  data: 0.0329  max mem: 2356
Test: [Task 3]  [20/63]  eta: 0:00:09  Loss: 0.5531 (0.5648)  Acc@1: 87.5000 (88.6905)  Acc@5: 100.0000 (98.5119)  time: 0.2062  data: 0.0005  max mem: 2356
Test: [Task 3]  [30/63]  eta: 0:00:07  Loss: 0.5425 (0.5702)  Acc@1: 87.5000 (88.3065)  Acc@5: 100.0000 (98.7903)  time: 0.2064  data: 0.0011  max mem: 2356
Test: [Task 3]  [40/63]  eta: 0:00:04  Loss: 0.5066 (0.5659)  Acc@1: 87.5000 (88.4146)  Acc@5: 100.0000 (99.0854)  time: 0.2070  data: 0.0015  max mem: 2356
Test: [Task 3]  [50/63]  eta: 0:00:02  Loss: 0.5066 (0.5740)  Acc@1: 87.5000 (88.1127)  Acc@5: 100.0000 (98.7745)  time: 0.2059  data: 0.0007  max mem: 2356
Test: [Task 3]  [60/63]  eta: 0:00:00  Loss: 0.6001 (0.5802)  Acc@1: 87.5000 (88.0123)  Acc@5: 100.0000 (98.7705)  time: 0.2053  data: 0.0003  max mem: 2356
Test: [Task 3]  [62/63]  eta: 0:00:00  Loss: 0.6405 (0.5843)  Acc@1: 87.5000 (88.0000)  Acc@5: 100.0000 (98.7000)  time: 0.2004  data: 0.0002  max mem: 2356
Test: [Task 3] Total time: 0:00:13 (0.2113 s / it)
* Acc@1 88.000 Acc@5 98.700 loss 0.584
Test: [Task 4]  [ 0/63]  eta: 0:00:32  Loss: 0.7560 (0.7560)  Acc@1: 87.5000 (87.5000)  Acc@5: 93.7500 (93.7500)  time: 0.5188  data: 0.3123  max mem: 2356
Test: [Task 4]  [10/63]  eta: 0:00:12  Loss: 0.5271 (0.5223)  Acc@1: 87.5000 (89.7727)  Acc@5: 100.0000 (98.8636)  time: 0.2349  data: 0.0287  max mem: 2356
Test: [Task 4]  [20/63]  eta: 0:00:09  Loss: 0.4689 (0.5322)  Acc@1: 87.5000 (87.7976)  Acc@5: 100.0000 (97.9167)  time: 0.2061  data: 0.0004  max mem: 2356
Test: [Task 4]  [30/63]  eta: 0:00:07  Loss: 0.4485 (0.5104)  Acc@1: 87.5000 (89.5161)  Acc@5: 100.0000 (98.3871)  time: 0.2059  data: 0.0004  max mem: 2356
Test: [Task 4]  [40/63]  eta: 0:00:04  Loss: 0.3201 (0.4689)  Acc@1: 93.7500 (90.5488)  Acc@5: 100.0000 (98.6280)  time: 0.2058  data: 0.0004  max mem: 2356
Test: [Task 4]  [50/63]  eta: 0:00:02  Loss: 0.3436 (0.4819)  Acc@1: 93.7500 (90.4412)  Acc@5: 100.0000 (98.6520)  time: 0.2058  data: 0.0003  max mem: 2356
Test: [Task 4]  [60/63]  eta: 0:00:00  Loss: 0.4731 (0.4982)  Acc@1: 87.5000 (89.7541)  Acc@5: 100.0000 (98.4631)  time: 0.2057  data: 0.0003  max mem: 2356
Test: [Task 4]  [62/63]  eta: 0:00:00  Loss: 0.4320 (0.4906)  Acc@1: 87.5000 (90.0000)  Acc@5: 100.0000 (98.5000)  time: 0.2010  data: 0.0003  max mem: 2356
Test: [Task 4] Total time: 0:00:13 (0.2104 s / it)
* Acc@1 90.000 Acc@5 98.500 loss 0.491
{0: {0: 370, 1: 608, 2: 331, 3: 658, 4: 337, 5: 661, 6: 653, 7: 342, 8: 712, 9: 328}, 1: {0: 543, 1: 453, 2: 542, 3: 454, 4: 546, 5: 452, 6: 450, 7: 544, 8: 918, 9: 98}, 2: {0: 343, 1: 641, 2: 311, 3: 675, 4: 323, 5: 676, 6: 668, 7: 329, 8: 763, 9: 271}, 3: {0: 582, 1: 411, 2: 570, 3: 427, 4: 573, 5: 426, 6: 426, 7: 574, 8: 750, 9: 261}}
[Average accuracy till task4]	Acc@1: 88.8750	Acc@5: 98.7250	Loss: 0.5787	Forgetting: 5.5333	Backward: -5.5333
Train: Epoch[1/5]  [  0/313]  eta: 0:03:34  Lr: 0.001875  Loss: 2.0827  Acc@1: 6.2500 (6.2500)  Acc@5: 37.5000 (37.5000)  time: 0.6841  data: 0.3251  max mem: 2356
Train: Epoch[1/5]  [ 10/313]  eta: 0:01:50  Lr: 0.001875  Loss: 1.7058  Acc@1: 50.0000 (48.2955)  Acc@5: 81.2500 (80.6818)  time: 0.3651  data: 0.0304  max mem: 2356
Train: Epoch[1/5]  [ 20/313]  eta: 0:01:42  Lr: 0.001875  Loss: 1.5893  Acc@1: 62.5000 (57.7381)  Acc@5: 93.7500 (87.5000)  time: 0.3324  data: 0.0007  max mem: 2356
Train: Epoch[1/5]  [ 30/313]  eta: 0:01:37  Lr: 0.001875  Loss: 1.2699  Acc@1: 75.0000 (64.3145)  Acc@5: 93.7500 (90.5242)  time: 0.3318  data: 0.0012  max mem: 2356
Train: Epoch[1/5]  [ 40/313]  eta: 0:01:33  Lr: 0.001875  Loss: 0.9670  Acc@1: 81.2500 (69.3598)  Acc@5: 100.0000 (92.2256)  time: 0.3324  data: 0.0011  max mem: 2356
Train: Epoch[1/5]  [ 50/313]  eta: 0:01:29  Lr: 0.001875  Loss: 0.8023  Acc@1: 81.2500 (71.4461)  Acc@5: 100.0000 (93.3824)  time: 0.3330  data: 0.0005  max mem: 2356
Train: Epoch[1/5]  [ 60/313]  eta: 0:01:25  Lr: 0.001875  Loss: 0.5695  Acc@1: 81.2500 (73.5656)  Acc@5: 100.0000 (93.9549)  time: 0.3333  data: 0.0009  max mem: 2356
Train: Epoch[1/5]  [ 70/313]  eta: 0:01:21  Lr: 0.001875  Loss: 0.7393  Acc@1: 81.2500 (74.6479)  Acc@5: 93.7500 (94.0141)  time: 0.3316  data: 0.0007  max mem: 2356
Train: Epoch[1/5]  [ 80/313]  eta: 0:01:18  Lr: 0.001875  Loss: 0.7287  Acc@1: 81.2500 (75.3086)  Acc@5: 93.7500 (94.3673)  time: 0.3318  data: 0.0003  max mem: 2356
Train: Epoch[1/5]  [ 90/313]  eta: 0:01:15  Lr: 0.001875  Loss: 0.6324  Acc@1: 81.2500 (76.3049)  Acc@5: 100.0000 (94.7802)  time: 0.3355  data: 0.0005  max mem: 2356
Train: Epoch[1/5]  [100/313]  eta: 0:01:11  Lr: 0.001875  Loss: 0.5263  Acc@1: 87.5000 (77.2277)  Acc@5: 100.0000 (95.1733)  time: 0.3363  data: 0.0007  max mem: 2356
Train: Epoch[1/5]  [110/313]  eta: 0:01:08  Lr: 0.001875  Loss: 0.2793  Acc@1: 87.5000 (78.0968)  Acc@5: 100.0000 (95.3829)  time: 0.3390  data: 0.0008  max mem: 2356
Train: Epoch[1/5]  [120/313]  eta: 0:01:05  Lr: 0.001875  Loss: 0.5815  Acc@1: 87.5000 (78.7190)  Acc@5: 100.0000 (95.7645)  time: 0.3413  data: 0.0008  max mem: 2356
Train: Epoch[1/5]  [130/313]  eta: 0:01:01  Lr: 0.001875  Loss: 0.8460  Acc@1: 81.2500 (78.9599)  Acc@5: 100.0000 (95.8015)  time: 0.3391  data: 0.0009  max mem: 2356
Train: Epoch[1/5]  [140/313]  eta: 0:00:58  Lr: 0.001875  Loss: 0.2882  Acc@1: 87.5000 (79.5656)  Acc@5: 100.0000 (95.8777)  time: 0.3360  data: 0.0008  max mem: 2356
Train: Epoch[1/5]  [150/313]  eta: 0:00:55  Lr: 0.001875  Loss: 0.5851  Acc@1: 87.5000 (80.0083)  Acc@5: 100.0000 (96.0679)  time: 0.3382  data: 0.0007  max mem: 2356
Train: Epoch[1/5]  [160/313]  eta: 0:00:51  Lr: 0.001875  Loss: 0.3918  Acc@1: 81.2500 (80.1242)  Acc@5: 100.0000 (96.3121)  time: 0.3398  data: 0.0006  max mem: 2356
Train: Epoch[1/5]  [170/313]  eta: 0:00:48  Lr: 0.001875  Loss: 0.2505  Acc@1: 87.5000 (80.5190)  Acc@5: 100.0000 (96.5278)  time: 0.3396  data: 0.0005  max mem: 2356
Train: Epoch[1/5]  [180/313]  eta: 0:00:44  Lr: 0.001875  Loss: 0.5020  Acc@1: 87.5000 (80.9392)  Acc@5: 100.0000 (96.5815)  time: 0.3415  data: 0.0009  max mem: 2356
Train: Epoch[1/5]  [190/313]  eta: 0:00:41  Lr: 0.001875  Loss: 0.4083  Acc@1: 87.5000 (81.4463)  Acc@5: 100.0000 (96.7277)  time: 0.3407  data: 0.0017  max mem: 2356
Train: Epoch[1/5]  [200/313]  eta: 0:00:38  Lr: 0.001875  Loss: 0.0021  Acc@1: 87.5000 (81.3122)  Acc@5: 100.0000 (96.7662)  time: 0.3408  data: 0.0015  max mem: 2356
Train: Epoch[1/5]  [210/313]  eta: 0:00:34  Lr: 0.001875  Loss: 0.2088  Acc@1: 81.2500 (81.5166)  Acc@5: 100.0000 (96.7713)  time: 0.3399  data: 0.0008  max mem: 2356
Train: Epoch[1/5]  [220/313]  eta: 0:00:31  Lr: 0.001875  Loss: 0.6892  Acc@1: 87.5000 (81.6459)  Acc@5: 100.0000 (96.8609)  time: 0.3411  data: 0.0009  max mem: 2356
Train: Epoch[1/5]  [230/313]  eta: 0:00:28  Lr: 0.001875  Loss: 0.3868  Acc@1: 87.5000 (81.8182)  Acc@5: 100.0000 (96.8615)  time: 0.3423  data: 0.0020  max mem: 2356
Train: Epoch[1/5]  [240/313]  eta: 0:00:24  Lr: 0.001875  Loss: 0.2324  Acc@1: 87.5000 (82.0280)  Acc@5: 100.0000 (96.9658)  time: 0.3405  data: 0.0016  max mem: 2356
Train: Epoch[1/5]  [250/313]  eta: 0:00:21  Lr: 0.001875  Loss: 0.3019  Acc@1: 87.5000 (82.3456)  Acc@5: 100.0000 (97.0120)  time: 0.3441  data: 0.0024  max mem: 2356
Train: Epoch[1/5]  [260/313]  eta: 0:00:17  Lr: 0.001875  Loss: 0.0848  Acc@1: 87.5000 (82.3994)  Acc@5: 100.0000 (97.0546)  time: 0.3422  data: 0.0026  max mem: 2356
Train: Epoch[1/5]  [270/313]  eta: 0:00:14  Lr: 0.001875  Loss: 0.2368  Acc@1: 81.2500 (82.3339)  Acc@5: 100.0000 (97.1172)  time: 0.3351  data: 0.0013  max mem: 2356
Train: Epoch[1/5]  [280/313]  eta: 0:00:11  Lr: 0.001875  Loss: 0.1188  Acc@1: 81.2500 (82.4066)  Acc@5: 100.0000 (97.1753)  time: 0.3339  data: 0.0011  max mem: 2356
Train: Epoch[1/5]  [290/313]  eta: 0:00:07  Lr: 0.001875  Loss: 0.3029  Acc@1: 87.5000 (82.7105)  Acc@5: 100.0000 (97.2723)  time: 0.3333  data: 0.0004  max mem: 2356
Train: Epoch[1/5]  [300/313]  eta: 0:00:04  Lr: 0.001875  Loss: 0.1751  Acc@1: 87.5000 (82.7865)  Acc@5: 100.0000 (97.3007)  time: 0.3336  data: 0.0004  max mem: 2356
Train: Epoch[1/5]  [310/313]  eta: 0:00:01  Lr: 0.001875  Loss: 0.4455  Acc@1: 81.2500 (82.8175)  Acc@5: 100.0000 (97.3473)  time: 0.3337  data: 0.0004  max mem: 2356
Train: Epoch[1/5]  [312/313]  eta: 0:00:00  Lr: 0.001875  Loss: 0.7879  Acc@1: 81.2500 (82.7600)  Acc@5: 100.0000 (97.3200)  time: 0.3254  data: 0.0003  max mem: 2356
Train: Epoch[1/5] Total time: 0:01:45 (0.3380 s / it)
{0: {0: 22412, 1: 24815, 2: 19998, 3: 12102, 4: 1586, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}, 1: {0: 1577, 1: 208, 2: 5200, 3: 12775, 4: 3262, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}, 2: {0: 3518, 1: 6779, 2: 5327, 3: 9830, 4: 1513, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}, 3: {0: 21486, 1: 20777, 2: 18903, 3: 14840, 4: 3437, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}, 4: {0: 16124, 1: 10227, 2: 6432, 3: 10102, 4: 1580, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}, 5: {0: 23402, 1: 24357, 2: 21714, 3: 15057, 4: 3450, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}, 6: {0: 9472, 1: 12148, 2: 17669, 3: 14460, 4: 3420, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}, 7: {0: 752, 1: 676, 2: 4577, 3: 10334, 4: 1552, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}, 8: {0: 24269, 1: 24959, 2: 24373, 3: 23260, 4: 4497, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}, 9: {0: 1988, 1: 54, 2: 807, 3: 2240, 4: 703, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}}
Averaged stats: Lr: 0.001875  Loss: 0.7879  Acc@1: 81.2500 (82.7600)  Acc@5: 100.0000 (97.3200)
Train: Epoch[2/5]  [  0/313]  eta: 0:03:24  Lr: 0.001875  Loss: 0.2021  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (100.0000)  time: 0.6543  data: 0.3196  max mem: 2356
Train: Epoch[2/5]  [ 10/313]  eta: 0:01:49  Lr: 0.001875  Loss: 0.2786  Acc@1: 87.5000 (88.0682)  Acc@5: 100.0000 (98.2955)  time: 0.3617  data: 0.0294  max mem: 2356
Train: Epoch[2/5]  [ 20/313]  eta: 0:01:42  Lr: 0.001875  Loss: 0.2983  Acc@1: 87.5000 (88.9881)  Acc@5: 100.0000 (98.5119)  time: 0.3329  data: 0.0004  max mem: 2356
Train: Epoch[2/5]  [ 30/313]  eta: 0:01:37  Lr: 0.001875  Loss: 0.1496  Acc@1: 87.5000 (87.7016)  Acc@5: 100.0000 (98.3871)  time: 0.3338  data: 0.0004  max mem: 2356
Train: Epoch[2/5]  [ 40/313]  eta: 0:01:33  Lr: 0.001875  Loss: 0.0459  Acc@1: 87.5000 (88.1098)  Acc@5: 100.0000 (98.6280)  time: 0.3346  data: 0.0009  max mem: 2356
Train: Epoch[2/5]  [ 50/313]  eta: 0:01:29  Lr: 0.001875  Loss: 0.2446  Acc@1: 87.5000 (88.3578)  Acc@5: 100.0000 (98.7745)  time: 0.3329  data: 0.0008  max mem: 2356
Train: Epoch[2/5]  [ 60/313]  eta: 0:01:25  Lr: 0.001875  Loss: 0.3176  Acc@1: 87.5000 (87.9098)  Acc@5: 100.0000 (98.7705)  time: 0.3329  data: 0.0003  max mem: 2356
Train: Epoch[2/5]  [ 70/313]  eta: 0:01:22  Lr: 0.001875  Loss: 0.1422  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (98.6796)  time: 0.3352  data: 0.0005  max mem: 2356
Train: Epoch[2/5]  [ 80/313]  eta: 0:01:18  Lr: 0.001875  Loss: 0.1549  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (98.6883)  time: 0.3337  data: 0.0006  max mem: 2356
Train: Epoch[2/5]  [ 90/313]  eta: 0:01:15  Lr: 0.001875  Loss: -0.0729  Acc@1: 81.2500 (86.5385)  Acc@5: 100.0000 (98.6264)  time: 0.3315  data: 0.0003  max mem: 2356
Train: Epoch[2/5]  [100/313]  eta: 0:01:11  Lr: 0.001875  Loss: -0.0929  Acc@1: 81.2500 (86.5718)  Acc@5: 100.0000 (98.5149)  time: 0.3315  data: 0.0009  max mem: 2356
Train: Epoch[2/5]  [110/313]  eta: 0:01:08  Lr: 0.001875  Loss: 0.0769  Acc@1: 87.5000 (86.7117)  Acc@5: 100.0000 (98.5923)  time: 0.3329  data: 0.0010  max mem: 2356
Train: Epoch[2/5]  [120/313]  eta: 0:01:04  Lr: 0.001875  Loss: 0.0558  Acc@1: 87.5000 (86.5702)  Acc@5: 100.0000 (98.5537)  time: 0.3336  data: 0.0003  max mem: 2356
Train: Epoch[2/5]  [130/313]  eta: 0:01:01  Lr: 0.001875  Loss: 0.2774  Acc@1: 81.2500 (86.4027)  Acc@5: 100.0000 (98.3779)  time: 0.3338  data: 0.0005  max mem: 2356
Train: Epoch[2/5]  [140/313]  eta: 0:00:58  Lr: 0.001875  Loss: 0.1848  Acc@1: 87.5000 (86.3918)  Acc@5: 100.0000 (98.4486)  time: 0.3376  data: 0.0006  max mem: 2356
Train: Epoch[2/5]  [150/313]  eta: 0:00:54  Lr: 0.001875  Loss: 0.1992  Acc@1: 87.5000 (86.2997)  Acc@5: 100.0000 (98.3444)  time: 0.3380  data: 0.0007  max mem: 2356
Train: Epoch[2/5]  [160/313]  eta: 0:00:51  Lr: 0.001875  Loss: 0.3439  Acc@1: 87.5000 (86.6071)  Acc@5: 100.0000 (98.4084)  time: 0.3368  data: 0.0019  max mem: 2356
Train: Epoch[2/5]  [170/313]  eta: 0:00:48  Lr: 0.001875  Loss: 0.3450  Acc@1: 93.7500 (86.6594)  Acc@5: 100.0000 (98.4284)  time: 0.3396  data: 0.0020  max mem: 2356
Train: Epoch[2/5]  [180/313]  eta: 0:00:44  Lr: 0.001875  Loss: 0.1573  Acc@1: 87.5000 (86.8094)  Acc@5: 100.0000 (98.4461)  time: 0.3395  data: 0.0022  max mem: 2356
Train: Epoch[2/5]  [190/313]  eta: 0:00:41  Lr: 0.001875  Loss: 0.0638  Acc@1: 87.5000 (86.8455)  Acc@5: 100.0000 (98.4620)  time: 0.3401  data: 0.0031  max mem: 2356
Train: Epoch[2/5]  [200/313]  eta: 0:00:38  Lr: 0.001875  Loss: 0.2493  Acc@1: 81.2500 (86.7848)  Acc@5: 100.0000 (98.4764)  time: 0.3421  data: 0.0017  max mem: 2356
Train: Epoch[2/5]  [210/313]  eta: 0:00:34  Lr: 0.001875  Loss: -0.0216  Acc@1: 87.5000 (86.7891)  Acc@5: 100.0000 (98.5486)  time: 0.3440  data: 0.0005  max mem: 2356
Train: Epoch[2/5]  [220/313]  eta: 0:00:31  Lr: 0.001875  Loss: -0.1325  Acc@1: 87.5000 (86.9627)  Acc@5: 100.0000 (98.5860)  time: 0.3421  data: 0.0006  max mem: 2356
Train: Epoch[2/5]  [230/313]  eta: 0:00:28  Lr: 0.001875  Loss: 0.5986  Acc@1: 87.5000 (86.9589)  Acc@5: 100.0000 (98.5390)  time: 0.3393  data: 0.0008  max mem: 2356
Train: Epoch[2/5]  [240/313]  eta: 0:00:24  Lr: 0.001875  Loss: 0.1545  Acc@1: 87.5000 (86.9295)  Acc@5: 100.0000 (98.5477)  time: 0.3392  data: 0.0016  max mem: 2356
Train: Epoch[2/5]  [250/313]  eta: 0:00:21  Lr: 0.001875  Loss: -0.1792  Acc@1: 87.5000 (86.8526)  Acc@5: 100.0000 (98.5309)  time: 0.3397  data: 0.0018  max mem: 2356
Train: Epoch[2/5]  [260/313]  eta: 0:00:17  Lr: 0.001875  Loss: 0.0555  Acc@1: 87.5000 (86.9732)  Acc@5: 100.0000 (98.5632)  time: 0.3421  data: 0.0028  max mem: 2356
Train: Epoch[2/5]  [270/313]  eta: 0:00:14  Lr: 0.001875  Loss: 0.1726  Acc@1: 87.5000 (86.9696)  Acc@5: 100.0000 (98.5701)  time: 0.3407  data: 0.0029  max mem: 2356
Train: Epoch[2/5]  [280/313]  eta: 0:00:11  Lr: 0.001875  Loss: -0.0326  Acc@1: 87.5000 (87.0329)  Acc@5: 100.0000 (98.6210)  time: 0.3362  data: 0.0011  max mem: 2356
Train: Epoch[2/5]  [290/313]  eta: 0:00:07  Lr: 0.001875  Loss: 0.1942  Acc@1: 87.5000 (87.0704)  Acc@5: 100.0000 (98.6040)  time: 0.3353  data: 0.0012  max mem: 2356
Train: Epoch[2/5]  [300/313]  eta: 0:00:04  Lr: 0.001875  Loss: 0.0995  Acc@1: 93.7500 (87.2508)  Acc@5: 100.0000 (98.6503)  time: 0.3375  data: 0.0011  max mem: 2356
Train: Epoch[2/5]  [310/313]  eta: 0:00:01  Lr: 0.001875  Loss: 0.0413  Acc@1: 87.5000 (87.1584)  Acc@5: 100.0000 (98.6937)  time: 0.3366  data: 0.0004  max mem: 2356
Train: Epoch[2/5]  [312/313]  eta: 0:00:00  Lr: 0.001875  Loss: 0.3209  Acc@1: 87.5000 (87.1600)  Acc@5: 100.0000 (98.7000)  time: 0.3282  data: 0.0003  max mem: 2356
Train: Epoch[2/5] Total time: 0:01:45 (0.3376 s / it)
{0: {0: 22412, 1: 24815, 2: 19998, 3: 12102, 4: 3175, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}, 1: {0: 1577, 1: 208, 2: 5200, 3: 12775, 4: 6594, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}, 2: {0: 3518, 1: 6779, 2: 5327, 3: 9830, 4: 3043, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}, 3: {0: 21486, 1: 20777, 2: 18903, 3: 14840, 4: 6881, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}, 4: {0: 16124, 1: 10227, 2: 6432, 3: 10102, 4: 3151, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}, 5: {0: 23402, 1: 24357, 2: 21714, 3: 15057, 4: 6875, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}, 6: {0: 9472, 1: 12148, 2: 17669, 3: 14460, 4: 6855, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}, 7: {0: 752, 1: 676, 2: 4577, 3: 10334, 4: 3126, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}, 8: {0: 24269, 1: 24959, 2: 24373, 3: 23260, 4: 8395, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}, 9: {0: 1988, 1: 54, 2: 807, 3: 2240, 4: 1905, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}}
Averaged stats: Lr: 0.001875  Loss: 0.3209  Acc@1: 87.5000 (87.1600)  Acc@5: 100.0000 (98.7000)
Train: Epoch[3/5]  [  0/313]  eta: 0:03:17  Lr: 0.001875  Loss: 0.2335  Acc@1: 81.2500 (81.2500)  Acc@5: 93.7500 (93.7500)  time: 0.6314  data: 0.2966  max mem: 2356
Train: Epoch[3/5]  [ 10/313]  eta: 0:01:49  Lr: 0.001875  Loss: 0.0240  Acc@1: 87.5000 (88.0682)  Acc@5: 100.0000 (98.8636)  time: 0.3603  data: 0.0279  max mem: 2356
Train: Epoch[3/5]  [ 20/313]  eta: 0:01:41  Lr: 0.001875  Loss: -0.0690  Acc@1: 87.5000 (88.9881)  Acc@5: 100.0000 (97.6190)  time: 0.3330  data: 0.0007  max mem: 2356
Train: Epoch[3/5]  [ 30/313]  eta: 0:01:36  Lr: 0.001875  Loss: 0.2413  Acc@1: 87.5000 (87.7016)  Acc@5: 100.0000 (97.9839)  time: 0.3330  data: 0.0004  max mem: 2356
Train: Epoch[3/5]  [ 40/313]  eta: 0:01:32  Lr: 0.001875  Loss: 0.1898  Acc@1: 87.5000 (87.6524)  Acc@5: 100.0000 (98.1707)  time: 0.3331  data: 0.0004  max mem: 2356
Train: Epoch[3/5]  [ 50/313]  eta: 0:01:29  Lr: 0.001875  Loss: 0.0360  Acc@1: 87.5000 (87.0098)  Acc@5: 100.0000 (98.2843)  time: 0.3329  data: 0.0004  max mem: 2356
Train: Epoch[3/5]  [ 60/313]  eta: 0:01:25  Lr: 0.001875  Loss: 0.2677  Acc@1: 87.5000 (87.3975)  Acc@5: 100.0000 (98.0533)  time: 0.3335  data: 0.0004  max mem: 2356
Train: Epoch[3/5]  [ 70/313]  eta: 0:01:22  Lr: 0.001875  Loss: 0.1651  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (98.3275)  time: 0.3344  data: 0.0007  max mem: 2356
Train: Epoch[3/5]  [ 80/313]  eta: 0:01:18  Lr: 0.001875  Loss: 0.5188  Acc@1: 87.5000 (87.6543)  Acc@5: 100.0000 (98.1481)  time: 0.3342  data: 0.0008  max mem: 2356
Train: Epoch[3/5]  [ 90/313]  eta: 0:01:15  Lr: 0.001875  Loss: -0.1038  Acc@1: 93.7500 (88.2555)  Acc@5: 100.0000 (98.2830)  time: 0.3338  data: 0.0004  max mem: 2356
Train: Epoch[3/5]  [100/313]  eta: 0:01:11  Lr: 0.001875  Loss: -0.0149  Acc@1: 93.7500 (88.4901)  Acc@5: 100.0000 (98.3911)  time: 0.3332  data: 0.0003  max mem: 2356
Train: Epoch[3/5]  [110/313]  eta: 0:01:08  Lr: 0.001875  Loss: 0.4341  Acc@1: 87.5000 (87.8378)  Acc@5: 100.0000 (98.3671)  time: 0.3335  data: 0.0011  max mem: 2356
Train: Epoch[3/5]  [120/313]  eta: 0:01:04  Lr: 0.001875  Loss: 0.0546  Acc@1: 87.5000 (87.9132)  Acc@5: 100.0000 (98.5021)  time: 0.3331  data: 0.0011  max mem: 2356
Train: Epoch[3/5]  [130/313]  eta: 0:01:01  Lr: 0.001875  Loss: 0.0301  Acc@1: 87.5000 (87.8817)  Acc@5: 100.0000 (98.5210)  time: 0.3317  data: 0.0003  max mem: 2356
Train: Epoch[3/5]  [140/313]  eta: 0:00:58  Lr: 0.001875  Loss: 0.0303  Acc@1: 87.5000 (87.8546)  Acc@5: 100.0000 (98.5816)  time: 0.3327  data: 0.0003  max mem: 2356
Train: Epoch[3/5]  [150/313]  eta: 0:00:54  Lr: 0.001875  Loss: 0.4800  Acc@1: 87.5000 (87.5414)  Acc@5: 100.0000 (98.4685)  time: 0.3333  data: 0.0003  max mem: 2356
Train: Epoch[3/5]  [160/313]  eta: 0:00:51  Lr: 0.001875  Loss: 0.2411  Acc@1: 87.5000 (87.5776)  Acc@5: 100.0000 (98.4860)  time: 0.3324  data: 0.0004  max mem: 2356
Train: Epoch[3/5]  [170/313]  eta: 0:00:47  Lr: 0.001875  Loss: 0.7239  Acc@1: 87.5000 (87.5731)  Acc@5: 100.0000 (98.4649)  time: 0.3313  data: 0.0004  max mem: 2356
Train: Epoch[3/5]  [180/313]  eta: 0:00:44  Lr: 0.001875  Loss: 0.1904  Acc@1: 87.5000 (87.5691)  Acc@5: 100.0000 (98.5497)  time: 0.3321  data: 0.0008  max mem: 2356
Train: Epoch[3/5]  [190/313]  eta: 0:00:41  Lr: 0.001875  Loss: -0.0557  Acc@1: 87.5000 (87.4673)  Acc@5: 100.0000 (98.5275)  time: 0.3357  data: 0.0009  max mem: 2356
Train: Epoch[3/5]  [200/313]  eta: 0:00:37  Lr: 0.001875  Loss: 0.1526  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (98.5075)  time: 0.3402  data: 0.0014  max mem: 2356
Train: Epoch[3/5]  [210/313]  eta: 0:00:34  Lr: 0.001875  Loss: -0.1150  Acc@1: 87.5000 (87.4704)  Acc@5: 100.0000 (98.5486)  time: 0.3417  data: 0.0014  max mem: 2356
Train: Epoch[3/5]  [220/313]  eta: 0:00:31  Lr: 0.001875  Loss: -0.0714  Acc@1: 87.5000 (87.5566)  Acc@5: 100.0000 (98.5860)  time: 0.3406  data: 0.0006  max mem: 2356
Train: Epoch[3/5]  [230/313]  eta: 0:00:27  Lr: 0.001875  Loss: 0.0105  Acc@1: 87.5000 (87.5541)  Acc@5: 100.0000 (98.6472)  time: 0.3386  data: 0.0011  max mem: 2356
Train: Epoch[3/5]  [240/313]  eta: 0:00:24  Lr: 0.001875  Loss: 0.4991  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (98.5996)  time: 0.3373  data: 0.0009  max mem: 2356
Train: Epoch[3/5]  [250/313]  eta: 0:00:21  Lr: 0.001875  Loss: 0.3131  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (98.6554)  time: 0.3421  data: 0.0012  max mem: 2356
Train: Epoch[3/5]  [260/313]  eta: 0:00:17  Lr: 0.001875  Loss: -0.0294  Acc@1: 87.5000 (87.4761)  Acc@5: 100.0000 (98.6830)  time: 0.3412  data: 0.0012  max mem: 2356
Train: Epoch[3/5]  [270/313]  eta: 0:00:14  Lr: 0.001875  Loss: 0.2769  Acc@1: 81.2500 (87.3155)  Acc@5: 100.0000 (98.7085)  time: 0.3364  data: 0.0005  max mem: 2356
Train: Epoch[3/5]  [280/313]  eta: 0:00:11  Lr: 0.001875  Loss: 0.0842  Acc@1: 81.2500 (87.2776)  Acc@5: 100.0000 (98.6655)  time: 0.3393  data: 0.0015  max mem: 2356
Train: Epoch[3/5]  [290/313]  eta: 0:00:07  Lr: 0.001875  Loss: 0.0870  Acc@1: 87.5000 (87.3067)  Acc@5: 100.0000 (98.6684)  time: 0.3386  data: 0.0019  max mem: 2356
Train: Epoch[3/5]  [300/313]  eta: 0:00:04  Lr: 0.001875  Loss: 0.0230  Acc@1: 87.5000 (87.5208)  Acc@5: 100.0000 (98.6919)  time: 0.3369  data: 0.0018  max mem: 2356
Train: Epoch[3/5]  [310/313]  eta: 0:00:01  Lr: 0.001875  Loss: 0.2396  Acc@1: 93.7500 (87.5201)  Acc@5: 100.0000 (98.6535)  time: 0.3378  data: 0.0013  max mem: 2356
Train: Epoch[3/5]  [312/313]  eta: 0:00:00  Lr: 0.001875  Loss: -0.1638  Acc@1: 87.5000 (87.4800)  Acc@5: 100.0000 (98.6400)  time: 0.3276  data: 0.0013  max mem: 2356
Train: Epoch[3/5] Total time: 0:01:45 (0.3366 s / it)
{0: {0: 22412, 1: 24815, 2: 19998, 3: 12102, 4: 4717, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}, 1: {0: 1577, 1: 208, 2: 5200, 3: 12775, 4: 10042, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}, 2: {0: 3518, 1: 6779, 2: 5327, 3: 9830, 4: 4541, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}, 3: {0: 21486, 1: 20777, 2: 18903, 3: 14840, 4: 10380, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}, 4: {0: 16124, 1: 10227, 2: 6432, 3: 10102, 4: 4674, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}, 5: {0: 23402, 1: 24357, 2: 21714, 3: 15057, 4: 10342, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}, 6: {0: 9472, 1: 12148, 2: 17669, 3: 14460, 4: 10332, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}, 7: {0: 752, 1: 676, 2: 4577, 3: 10334, 4: 4661, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}, 8: {0: 24269, 1: 24959, 2: 24373, 3: 23260, 4: 12030, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}, 9: {0: 1988, 1: 54, 2: 807, 3: 2240, 4: 3281, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}}
Averaged stats: Lr: 0.001875  Loss: -0.1638  Acc@1: 87.5000 (87.4800)  Acc@5: 100.0000 (98.6400)
Train: Epoch[4/5]  [  0/313]  eta: 0:04:29  Lr: 0.001875  Loss: 0.1458  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (100.0000)  time: 0.8609  data: 0.4952  max mem: 2356
Train: Epoch[4/5]  [ 10/313]  eta: 0:01:55  Lr: 0.001875  Loss: 0.1307  Acc@1: 87.5000 (85.7955)  Acc@5: 100.0000 (99.4318)  time: 0.3824  data: 0.0455  max mem: 2356
Train: Epoch[4/5]  [ 20/313]  eta: 0:01:46  Lr: 0.001875  Loss: 0.2145  Acc@1: 87.5000 (87.7976)  Acc@5: 100.0000 (99.1071)  time: 0.3399  data: 0.0005  max mem: 2356
Train: Epoch[4/5]  [ 30/313]  eta: 0:01:41  Lr: 0.001875  Loss: 0.1667  Acc@1: 87.5000 (87.9032)  Acc@5: 100.0000 (99.1935)  time: 0.3429  data: 0.0016  max mem: 2356
Train: Epoch[4/5]  [ 40/313]  eta: 0:01:36  Lr: 0.001875  Loss: -0.0726  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (98.9329)  time: 0.3441  data: 0.0020  max mem: 2356
Train: Epoch[4/5]  [ 50/313]  eta: 0:01:32  Lr: 0.001875  Loss: 0.1667  Acc@1: 87.5000 (87.6225)  Acc@5: 100.0000 (98.7745)  time: 0.3411  data: 0.0008  max mem: 2356
Train: Epoch[4/5]  [ 60/313]  eta: 0:01:27  Lr: 0.001875  Loss: 0.2674  Acc@1: 87.5000 (87.7049)  Acc@5: 100.0000 (98.9754)  time: 0.3334  data: 0.0004  max mem: 2356
Train: Epoch[4/5]  [ 70/313]  eta: 0:01:24  Lr: 0.001875  Loss: -0.1404  Acc@1: 93.7500 (87.8521)  Acc@5: 100.0000 (98.8556)  time: 0.3330  data: 0.0004  max mem: 2356
Train: Epoch[4/5]  [ 80/313]  eta: 0:01:20  Lr: 0.001875  Loss: 0.2882  Acc@1: 87.5000 (87.7315)  Acc@5: 100.0000 (98.8426)  time: 0.3341  data: 0.0004  max mem: 2356
Train: Epoch[4/5]  [ 90/313]  eta: 0:01:16  Lr: 0.001875  Loss: -0.0390  Acc@1: 87.5000 (87.7060)  Acc@5: 100.0000 (98.8324)  time: 0.3334  data: 0.0004  max mem: 2356
Train: Epoch[4/5]  [100/313]  eta: 0:01:12  Lr: 0.001875  Loss: 0.0298  Acc@1: 93.7500 (88.2426)  Acc@5: 100.0000 (98.8861)  time: 0.3333  data: 0.0006  max mem: 2356
Train: Epoch[4/5]  [110/313]  eta: 0:01:09  Lr: 0.001875  Loss: -0.1086  Acc@1: 87.5000 (88.4009)  Acc@5: 100.0000 (98.8739)  time: 0.3336  data: 0.0005  max mem: 2356
Train: Epoch[4/5]  [120/313]  eta: 0:01:05  Lr: 0.001875  Loss: -0.0272  Acc@1: 87.5000 (88.6364)  Acc@5: 100.0000 (98.8120)  time: 0.3333  data: 0.0004  max mem: 2356
Train: Epoch[4/5]  [130/313]  eta: 0:01:02  Lr: 0.001875  Loss: 0.2206  Acc@1: 87.5000 (88.5973)  Acc@5: 100.0000 (98.7118)  time: 0.3358  data: 0.0007  max mem: 2356
Train: Epoch[4/5]  [140/313]  eta: 0:00:58  Lr: 0.001875  Loss: 0.3424  Acc@1: 87.5000 (88.4752)  Acc@5: 100.0000 (98.7589)  time: 0.3360  data: 0.0007  max mem: 2356
Train: Epoch[4/5]  [150/313]  eta: 0:00:55  Lr: 0.001875  Loss: 0.2207  Acc@1: 87.5000 (88.5348)  Acc@5: 100.0000 (98.8411)  time: 0.3347  data: 0.0004  max mem: 2356
Train: Epoch[4/5]  [160/313]  eta: 0:00:51  Lr: 0.001875  Loss: 0.2041  Acc@1: 87.5000 (88.6646)  Acc@5: 100.0000 (98.8354)  time: 0.3345  data: 0.0007  max mem: 2356
Train: Epoch[4/5]  [170/313]  eta: 0:00:48  Lr: 0.001875  Loss: 0.1300  Acc@1: 87.5000 (88.4868)  Acc@5: 100.0000 (98.7939)  time: 0.3328  data: 0.0009  max mem: 2356
Train: Epoch[4/5]  [180/313]  eta: 0:00:45  Lr: 0.001875  Loss: 0.2301  Acc@1: 87.5000 (88.2251)  Acc@5: 100.0000 (98.7914)  time: 0.3325  data: 0.0005  max mem: 2356
Train: Epoch[4/5]  [190/313]  eta: 0:00:41  Lr: 0.001875  Loss: 0.0014  Acc@1: 87.5000 (88.1872)  Acc@5: 100.0000 (98.7565)  time: 0.3323  data: 0.0005  max mem: 2356
Train: Epoch[4/5]  [200/313]  eta: 0:00:38  Lr: 0.001875  Loss: 0.2812  Acc@1: 87.5000 (88.0908)  Acc@5: 100.0000 (98.7251)  time: 0.3325  data: 0.0006  max mem: 2356
Train: Epoch[4/5]  [210/313]  eta: 0:00:34  Lr: 0.001875  Loss: -0.0796  Acc@1: 87.5000 (88.1220)  Acc@5: 100.0000 (98.7263)  time: 0.3322  data: 0.0004  max mem: 2356
Train: Epoch[4/5]  [220/313]  eta: 0:00:31  Lr: 0.001875  Loss: 0.1488  Acc@1: 87.5000 (88.1505)  Acc@5: 100.0000 (98.6991)  time: 0.3326  data: 0.0010  max mem: 2356
Train: Epoch[4/5]  [230/313]  eta: 0:00:27  Lr: 0.001875  Loss: 0.2005  Acc@1: 87.5000 (88.1764)  Acc@5: 100.0000 (98.7554)  time: 0.3335  data: 0.0009  max mem: 2356
Train: Epoch[4/5]  [240/313]  eta: 0:00:24  Lr: 0.001875  Loss: -0.0058  Acc@1: 87.5000 (88.2002)  Acc@5: 100.0000 (98.7811)  time: 0.3332  data: 0.0004  max mem: 2356
Train: Epoch[4/5]  [250/313]  eta: 0:00:21  Lr: 0.001875  Loss: -0.1293  Acc@1: 87.5000 (88.2968)  Acc@5: 100.0000 (98.7550)  time: 0.3359  data: 0.0006  max mem: 2356
Train: Epoch[4/5]  [260/313]  eta: 0:00:17  Lr: 0.001875  Loss: -0.1630  Acc@1: 87.5000 (88.2902)  Acc@5: 100.0000 (98.8027)  time: 0.3366  data: 0.0006  max mem: 2356
Train: Epoch[4/5]  [270/313]  eta: 0:00:14  Lr: 0.001875  Loss: -0.1676  Acc@1: 93.7500 (88.4456)  Acc@5: 100.0000 (98.8007)  time: 0.3385  data: 0.0027  max mem: 2356
Train: Epoch[4/5]  [280/313]  eta: 0:00:11  Lr: 0.001875  Loss: 0.1182  Acc@1: 93.7500 (88.5676)  Acc@5: 100.0000 (98.8434)  time: 0.3400  data: 0.0035  max mem: 2356
Train: Epoch[4/5]  [290/313]  eta: 0:00:07  Lr: 0.001875  Loss: -0.1168  Acc@1: 93.7500 (88.7242)  Acc@5: 100.0000 (98.8402)  time: 0.3385  data: 0.0017  max mem: 2356
Train: Epoch[4/5]  [300/313]  eta: 0:00:04  Lr: 0.001875  Loss: 0.1641  Acc@1: 87.5000 (88.6420)  Acc@5: 100.0000 (98.8164)  time: 0.3396  data: 0.0024  max mem: 2356
Train: Epoch[4/5]  [310/313]  eta: 0:00:01  Lr: 0.001875  Loss: 0.2705  Acc@1: 87.5000 (88.5852)  Acc@5: 100.0000 (98.8545)  time: 0.3393  data: 0.0020  max mem: 2356
Train: Epoch[4/5]  [312/313]  eta: 0:00:00  Lr: 0.001875  Loss: 0.3929  Acc@1: 87.5000 (88.5600)  Acc@5: 100.0000 (98.8600)  time: 0.3311  data: 0.0020  max mem: 2356
Train: Epoch[4/5] Total time: 0:01:45 (0.3373 s / it)
{0: {0: 22412, 1: 24815, 2: 19998, 3: 12102, 4: 6242, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}, 1: {0: 1577, 1: 208, 2: 5200, 3: 12775, 4: 13516, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}, 2: {0: 3518, 1: 6779, 2: 5327, 3: 9830, 4: 6053, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}, 3: {0: 21486, 1: 20777, 2: 18903, 3: 14840, 4: 13865, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}, 4: {0: 16124, 1: 10227, 2: 6432, 3: 10102, 4: 6193, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}, 5: {0: 23402, 1: 24357, 2: 21714, 3: 15057, 4: 13819, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}, 6: {0: 9472, 1: 12148, 2: 17669, 3: 14460, 4: 13812, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}, 7: {0: 752, 1: 676, 2: 4577, 3: 10334, 4: 6183, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}, 8: {0: 24269, 1: 24959, 2: 24373, 3: 23260, 4: 15570, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}, 9: {0: 1988, 1: 54, 2: 807, 3: 2240, 4: 4747, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}}
Averaged stats: Lr: 0.001875  Loss: 0.3929  Acc@1: 87.5000 (88.5600)  Acc@5: 100.0000 (98.8600)
Train: Epoch[5/5]  [  0/313]  eta: 0:03:40  Lr: 0.001875  Loss: -0.0290  Acc@1: 93.7500 (93.7500)  Acc@5: 100.0000 (100.0000)  time: 0.7054  data: 0.3444  max mem: 2356
Train: Epoch[5/5]  [ 10/313]  eta: 0:01:51  Lr: 0.001875  Loss: -0.1655  Acc@1: 93.7500 (91.4773)  Acc@5: 100.0000 (100.0000)  time: 0.3688  data: 0.0323  max mem: 2356
Train: Epoch[5/5]  [ 20/313]  eta: 0:01:44  Lr: 0.001875  Loss: -0.0029  Acc@1: 93.7500 (91.3690)  Acc@5: 100.0000 (99.7024)  time: 0.3395  data: 0.0015  max mem: 2356
Train: Epoch[5/5]  [ 30/313]  eta: 0:01:39  Lr: 0.001875  Loss: 0.1561  Acc@1: 93.7500 (91.1290)  Acc@5: 100.0000 (98.9919)  time: 0.3401  data: 0.0016  max mem: 2356
Train: Epoch[5/5]  [ 40/313]  eta: 0:01:34  Lr: 0.001875  Loss: -0.1088  Acc@1: 93.7500 (91.1585)  Acc@5: 100.0000 (98.9329)  time: 0.3364  data: 0.0014  max mem: 2356
Train: Epoch[5/5]  [ 50/313]  eta: 0:01:30  Lr: 0.001875  Loss: 0.0662  Acc@1: 93.7500 (90.9314)  Acc@5: 100.0000 (99.0196)  time: 0.3376  data: 0.0012  max mem: 2356
Train: Epoch[5/5]  [ 60/313]  eta: 0:01:26  Lr: 0.001875  Loss: -0.0089  Acc@1: 93.7500 (90.6762)  Acc@5: 100.0000 (99.0779)  time: 0.3365  data: 0.0010  max mem: 2356
Train: Epoch[5/5]  [ 70/313]  eta: 0:01:23  Lr: 0.001875  Loss: -0.0878  Acc@1: 93.7500 (90.6690)  Acc@5: 100.0000 (99.0317)  time: 0.3367  data: 0.0017  max mem: 2356
Train: Epoch[5/5]  [ 80/313]  eta: 0:01:19  Lr: 0.001875  Loss: -0.0350  Acc@1: 93.7500 (90.5864)  Acc@5: 100.0000 (99.1512)  time: 0.3355  data: 0.0013  max mem: 2356
Train: Epoch[5/5]  [ 90/313]  eta: 0:01:16  Lr: 0.001875  Loss: -0.1421  Acc@1: 93.7500 (90.7280)  Acc@5: 100.0000 (99.1071)  time: 0.3336  data: 0.0004  max mem: 2356
Train: Epoch[5/5]  [100/313]  eta: 0:01:12  Lr: 0.001875  Loss: 0.1273  Acc@1: 93.7500 (90.5322)  Acc@5: 100.0000 (99.1337)  time: 0.3369  data: 0.0005  max mem: 2356
Train: Epoch[5/5]  [110/313]  eta: 0:01:09  Lr: 0.001875  Loss: 0.1013  Acc@1: 93.7500 (90.6532)  Acc@5: 100.0000 (99.0428)  time: 0.3377  data: 0.0015  max mem: 2356
Train: Epoch[5/5]  [120/313]  eta: 0:01:05  Lr: 0.001875  Loss: 0.0185  Acc@1: 93.7500 (90.4959)  Acc@5: 100.0000 (99.0702)  time: 0.3401  data: 0.0019  max mem: 2356
Train: Epoch[5/5]  [130/313]  eta: 0:01:02  Lr: 0.001875  Loss: 0.2110  Acc@1: 93.7500 (90.3626)  Acc@5: 100.0000 (99.0458)  time: 0.3417  data: 0.0009  max mem: 2356
Train: Epoch[5/5]  [140/313]  eta: 0:00:58  Lr: 0.001875  Loss: 0.1182  Acc@1: 87.5000 (90.2482)  Acc@5: 100.0000 (99.0691)  time: 0.3362  data: 0.0004  max mem: 2356
Train: Epoch[5/5]  [150/313]  eta: 0:00:55  Lr: 0.001875  Loss: 0.0079  Acc@1: 87.5000 (90.2732)  Acc@5: 100.0000 (99.0480)  time: 0.3325  data: 0.0004  max mem: 2356
Train: Epoch[5/5]  [160/313]  eta: 0:00:51  Lr: 0.001875  Loss: 0.0816  Acc@1: 87.5000 (90.1009)  Acc@5: 100.0000 (99.0295)  time: 0.3324  data: 0.0004  max mem: 2356
Train: Epoch[5/5]  [170/313]  eta: 0:00:48  Lr: 0.001875  Loss: 0.0746  Acc@1: 87.5000 (90.0585)  Acc@5: 100.0000 (99.0497)  time: 0.3328  data: 0.0004  max mem: 2356
Train: Epoch[5/5]  [180/313]  eta: 0:00:45  Lr: 0.001875  Loss: -0.0433  Acc@1: 87.5000 (90.0207)  Acc@5: 100.0000 (99.0331)  time: 0.3333  data: 0.0004  max mem: 2356
Train: Epoch[5/5]  [190/313]  eta: 0:00:41  Lr: 0.001875  Loss: 0.0463  Acc@1: 93.7500 (90.0851)  Acc@5: 100.0000 (99.0838)  time: 0.3327  data: 0.0004  max mem: 2356
Train: Epoch[5/5]  [200/313]  eta: 0:00:38  Lr: 0.001875  Loss: 0.1990  Acc@1: 93.7500 (90.1119)  Acc@5: 100.0000 (99.0672)  time: 0.3319  data: 0.0004  max mem: 2356
Train: Epoch[5/5]  [210/313]  eta: 0:00:34  Lr: 0.001875  Loss: 0.4383  Acc@1: 93.7500 (89.8993)  Acc@5: 100.0000 (99.0521)  time: 0.3333  data: 0.0004  max mem: 2356
Train: Epoch[5/5]  [220/313]  eta: 0:00:31  Lr: 0.001875  Loss: 0.0569  Acc@1: 87.5000 (89.9604)  Acc@5: 100.0000 (98.9819)  time: 0.3334  data: 0.0006  max mem: 2356
Train: Epoch[5/5]  [230/313]  eta: 0:00:27  Lr: 0.001875  Loss: 0.4595  Acc@1: 87.5000 (89.8268)  Acc@5: 100.0000 (98.9989)  time: 0.3329  data: 0.0006  max mem: 2356
Train: Epoch[5/5]  [240/313]  eta: 0:00:24  Lr: 0.001875  Loss: 0.5454  Acc@1: 87.5000 (89.9637)  Acc@5: 100.0000 (98.9367)  time: 0.3336  data: 0.0012  max mem: 2356
Train: Epoch[5/5]  [250/313]  eta: 0:00:21  Lr: 0.001875  Loss: 0.2025  Acc@1: 87.5000 (89.8655)  Acc@5: 100.0000 (98.9293)  time: 0.3324  data: 0.0012  max mem: 2356
Train: Epoch[5/5]  [260/313]  eta: 0:00:17  Lr: 0.001875  Loss: 0.4612  Acc@1: 87.5000 (89.6552)  Acc@5: 100.0000 (98.9464)  time: 0.3315  data: 0.0004  max mem: 2356
Train: Epoch[5/5]  [270/313]  eta: 0:00:14  Lr: 0.001875  Loss: -0.0197  Acc@1: 87.5000 (89.7371)  Acc@5: 100.0000 (98.8930)  time: 0.3326  data: 0.0003  max mem: 2356
Train: Epoch[5/5]  [280/313]  eta: 0:00:11  Lr: 0.001875  Loss: -0.1728  Acc@1: 87.5000 (89.6797)  Acc@5: 100.0000 (98.9324)  time: 0.3334  data: 0.0004  max mem: 2356
Train: Epoch[5/5]  [290/313]  eta: 0:00:07  Lr: 0.001875  Loss: -0.0175  Acc@1: 87.5000 (89.5833)  Acc@5: 100.0000 (98.9261)  time: 0.3325  data: 0.0012  max mem: 2356
Train: Epoch[5/5]  [300/313]  eta: 0:00:04  Lr: 0.001875  Loss: -0.0965  Acc@1: 87.5000 (89.5556)  Acc@5: 100.0000 (98.9410)  time: 0.3317  data: 0.0012  max mem: 2356
Train: Epoch[5/5]  [310/313]  eta: 0:00:01  Lr: 0.001875  Loss: 0.1683  Acc@1: 87.5000 (89.4895)  Acc@5: 100.0000 (98.9751)  time: 0.3318  data: 0.0003  max mem: 2356
Train: Epoch[5/5]  [312/313]  eta: 0:00:00  Lr: 0.001875  Loss: -0.1983  Acc@1: 87.5000 (89.5200)  Acc@5: 100.0000 (98.9800)  time: 0.3241  data: 0.0003  max mem: 2356
Train: Epoch[5/5] Total time: 0:01:45 (0.3358 s / it)
{0: {0: 22412, 1: 24815, 2: 19998, 3: 12102, 4: 7737, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}, 1: {0: 1577, 1: 208, 2: 5200, 3: 12775, 4: 17024, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}, 2: {0: 3518, 1: 6779, 2: 5327, 3: 9830, 4: 7541, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}, 3: {0: 21486, 1: 20777, 2: 18903, 3: 14840, 4: 17372, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}, 4: {0: 16124, 1: 10227, 2: 6432, 3: 10102, 4: 7685, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}, 5: {0: 23402, 1: 24357, 2: 21714, 3: 15057, 4: 17322, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}, 6: {0: 9472, 1: 12148, 2: 17669, 3: 14460, 4: 17318, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}, 7: {0: 752, 1: 676, 2: 4577, 3: 10334, 4: 7679, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}, 8: {0: 24269, 1: 24959, 2: 24373, 3: 23260, 4: 19009, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}, 9: {0: 1988, 1: 54, 2: 807, 3: 2240, 4: 6313, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}}
Averaged stats: Lr: 0.001875  Loss: -0.1983  Acc@1: 87.5000 (89.5200)  Acc@5: 100.0000 (98.9800)
Test: [Task 1]  [ 0/63]  eta: 0:00:33  Loss: 0.6620 (0.6620)  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (100.0000)  time: 0.5313  data: 0.3242  max mem: 2356
Test: [Task 1]  [10/63]  eta: 0:00:12  Loss: 0.6499 (0.6285)  Acc@1: 87.5000 (84.0909)  Acc@5: 100.0000 (99.4318)  time: 0.2351  data: 0.0298  max mem: 2356
Test: [Task 1]  [20/63]  eta: 0:00:09  Loss: 0.6499 (0.6742)  Acc@1: 81.2500 (83.3333)  Acc@5: 100.0000 (98.8095)  time: 0.2070  data: 0.0011  max mem: 2356
Test: [Task 1]  [30/63]  eta: 0:00:07  Loss: 0.5970 (0.6483)  Acc@1: 87.5000 (84.8790)  Acc@5: 100.0000 (98.7903)  time: 0.2085  data: 0.0013  max mem: 2356
Test: [Task 1]  [40/63]  eta: 0:00:04  Loss: 0.5970 (0.6474)  Acc@1: 87.5000 (84.2988)  Acc@5: 100.0000 (99.0854)  time: 0.2067  data: 0.0005  max mem: 2356
Test: [Task 1]  [50/63]  eta: 0:00:02  Loss: 0.5411 (0.6211)  Acc@1: 81.2500 (85.1716)  Acc@5: 100.0000 (99.2647)  time: 0.2055  data: 0.0006  max mem: 2356
Test: [Task 1]  [60/63]  eta: 0:00:00  Loss: 0.5352 (0.6033)  Acc@1: 93.7500 (86.0656)  Acc@5: 100.0000 (99.1803)  time: 0.2066  data: 0.0006  max mem: 2356
Test: [Task 1]  [62/63]  eta: 0:00:00  Loss: 0.5011 (0.6016)  Acc@1: 93.7500 (86.4000)  Acc@5: 100.0000 (99.2000)  time: 0.2015  data: 0.0005  max mem: 2356
Test: [Task 1] Total time: 0:00:13 (0.2118 s / it)
* Acc@1 86.400 Acc@5 99.200 loss 0.602
Test: [Task 2]  [ 0/63]  eta: 0:00:33  Loss: 0.8368 (0.8368)  Acc@1: 93.7500 (93.7500)  Acc@5: 100.0000 (100.0000)  time: 0.5377  data: 0.3300  max mem: 2356
Test: [Task 2]  [10/63]  eta: 0:00:12  Loss: 0.7646 (0.7904)  Acc@1: 87.5000 (86.3636)  Acc@5: 100.0000 (98.8636)  time: 0.2402  data: 0.0324  max mem: 2356
Test: [Task 2]  [20/63]  eta: 0:00:09  Loss: 0.7418 (0.8193)  Acc@1: 81.2500 (85.1190)  Acc@5: 100.0000 (97.9167)  time: 0.2101  data: 0.0033  max mem: 2356
Test: [Task 2]  [30/63]  eta: 0:00:07  Loss: 0.7604 (0.8055)  Acc@1: 81.2500 (85.2823)  Acc@5: 100.0000 (97.1774)  time: 0.2127  data: 0.0050  max mem: 2356
Test: [Task 2]  [40/63]  eta: 0:00:05  Loss: 0.6763 (0.7696)  Acc@1: 87.5000 (86.7378)  Acc@5: 100.0000 (97.4085)  time: 0.2103  data: 0.0032  max mem: 2356
Test: [Task 2]  [50/63]  eta: 0:00:02  Loss: 0.6763 (0.7630)  Acc@1: 87.5000 (85.7843)  Acc@5: 100.0000 (97.4265)  time: 0.2090  data: 0.0015  max mem: 2356
Test: [Task 2]  [60/63]  eta: 0:00:00  Loss: 0.6001 (0.7344)  Acc@1: 87.5000 (86.4754)  Acc@5: 100.0000 (97.5410)  time: 0.2104  data: 0.0019  max mem: 2356
Test: [Task 2]  [62/63]  eta: 0:00:00  Loss: 0.5536 (0.7247)  Acc@1: 87.5000 (86.5000)  Acc@5: 100.0000 (97.6000)  time: 0.2031  data: 0.0015  max mem: 2356
Test: [Task 2] Total time: 0:00:13 (0.2152 s / it)
* Acc@1 86.500 Acc@5 97.600 loss 0.725
Test: [Task 3]  [ 0/63]  eta: 0:00:33  Loss: 0.4086 (0.4086)  Acc@1: 93.7500 (93.7500)  Acc@5: 100.0000 (100.0000)  time: 0.5325  data: 0.3284  max mem: 2356
Test: [Task 3]  [10/63]  eta: 0:00:12  Loss: 0.6256 (0.6458)  Acc@1: 81.2500 (82.9545)  Acc@5: 100.0000 (96.5909)  time: 0.2349  data: 0.0302  max mem: 2356
Test: [Task 3]  [20/63]  eta: 0:00:09  Loss: 0.6789 (0.6401)  Acc@1: 81.2500 (82.1429)  Acc@5: 100.0000 (96.7262)  time: 0.2056  data: 0.0004  max mem: 2356
Test: [Task 3]  [30/63]  eta: 0:00:07  Loss: 0.6789 (0.6396)  Acc@1: 81.2500 (82.6613)  Acc@5: 100.0000 (97.5806)  time: 0.2062  data: 0.0004  max mem: 2356
Test: [Task 3]  [40/63]  eta: 0:00:04  Loss: 0.5346 (0.6389)  Acc@1: 87.5000 (83.0793)  Acc@5: 100.0000 (98.0183)  time: 0.2062  data: 0.0004  max mem: 2356
Test: [Task 3]  [50/63]  eta: 0:00:02  Loss: 0.6625 (0.6437)  Acc@1: 87.5000 (83.8235)  Acc@5: 100.0000 (97.9167)  time: 0.2077  data: 0.0013  max mem: 2356
Test: [Task 3]  [60/63]  eta: 0:00:00  Loss: 0.6656 (0.6451)  Acc@1: 81.2500 (84.0164)  Acc@5: 100.0000 (98.0533)  time: 0.2075  data: 0.0012  max mem: 2356
Test: [Task 3]  [62/63]  eta: 0:00:00  Loss: 0.6890 (0.6482)  Acc@1: 81.2500 (84.0000)  Acc@5: 100.0000 (98.1000)  time: 0.2024  data: 0.0012  max mem: 2356
Test: [Task 3] Total time: 0:00:13 (0.2139 s / it)
* Acc@1 84.000 Acc@5 98.100 loss 0.648
Test: [Task 4]  [ 0/63]  eta: 0:00:38  Loss: 0.7278 (0.7278)  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (100.0000)  time: 0.6152  data: 0.4056  max mem: 2356
Test: [Task 4]  [10/63]  eta: 0:00:12  Loss: 0.6017 (0.5577)  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (98.8636)  time: 0.2431  data: 0.0372  max mem: 2356
Test: [Task 4]  [20/63]  eta: 0:00:09  Loss: 0.5247 (0.5788)  Acc@1: 87.5000 (85.7143)  Acc@5: 100.0000 (97.3214)  time: 0.2059  data: 0.0004  max mem: 2356
Test: [Task 4]  [30/63]  eta: 0:00:07  Loss: 0.5995 (0.5682)  Acc@1: 87.5000 (87.0968)  Acc@5: 100.0000 (97.3790)  time: 0.2060  data: 0.0004  max mem: 2356
Test: [Task 4]  [40/63]  eta: 0:00:04  Loss: 0.4073 (0.5257)  Acc@1: 87.5000 (88.5671)  Acc@5: 100.0000 (97.8659)  time: 0.2058  data: 0.0003  max mem: 2356
Test: [Task 4]  [50/63]  eta: 0:00:02  Loss: 0.4861 (0.5500)  Acc@1: 87.5000 (87.7451)  Acc@5: 100.0000 (97.7941)  time: 0.2113  data: 0.0024  max mem: 2356
Test: [Task 4]  [60/63]  eta: 0:00:00  Loss: 0.6055 (0.5701)  Acc@1: 87.5000 (87.0902)  Acc@5: 100.0000 (97.6434)  time: 0.2122  data: 0.0023  max mem: 2356
Test: [Task 4]  [62/63]  eta: 0:00:00  Loss: 0.5446 (0.5658)  Acc@1: 87.5000 (87.3000)  Acc@5: 100.0000 (97.7000)  time: 0.2093  data: 0.0022  max mem: 2356
Test: [Task 4] Total time: 0:00:13 (0.2170 s / it)
* Acc@1 87.300 Acc@5 97.700 loss 0.566
Test: [Task 5]  [ 0/63]  eta: 0:00:30  Loss: 0.1687 (0.1687)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)  time: 0.4784  data: 0.2579  max mem: 2356
Test: [Task 5]  [10/63]  eta: 0:00:12  Loss: 0.3893 (0.5416)  Acc@1: 93.7500 (90.3409)  Acc@5: 100.0000 (97.1591)  time: 0.2381  data: 0.0270  max mem: 2356
Test: [Task 5]  [20/63]  eta: 0:00:09  Loss: 0.3893 (0.5098)  Acc@1: 93.7500 (91.6667)  Acc@5: 100.0000 (97.6190)  time: 0.2137  data: 0.0036  max mem: 2356
Test: [Task 5]  [30/63]  eta: 0:00:07  Loss: 0.4031 (0.4967)  Acc@1: 93.7500 (91.9355)  Acc@5: 100.0000 (98.1855)  time: 0.2123  data: 0.0019  max mem: 2356
Test: [Task 5]  [40/63]  eta: 0:00:05  Loss: 0.3885 (0.4717)  Acc@1: 93.7500 (92.5305)  Acc@5: 100.0000 (98.1707)  time: 0.2090  data: 0.0008  max mem: 2356
Test: [Task 5]  [50/63]  eta: 0:00:02  Loss: 0.3885 (0.4698)  Acc@1: 93.7500 (92.7696)  Acc@5: 100.0000 (98.4069)  time: 0.2074  data: 0.0006  max mem: 2356
Test: [Task 5]  [60/63]  eta: 0:00:00  Loss: 0.4328 (0.4807)  Acc@1: 93.7500 (92.2131)  Acc@5: 100.0000 (98.3607)  time: 0.2133  data: 0.0016  max mem: 2356
Test: [Task 5]  [62/63]  eta: 0:00:00  Loss: 0.4892 (0.4982)  Acc@1: 93.7500 (92.0000)  Acc@5: 100.0000 (98.3000)  time: 0.2083  data: 0.0016  max mem: 2356
Test: [Task 5] Total time: 0:00:13 (0.2158 s / it)
* Acc@1 92.000 Acc@5 98.300 loss 0.498
{0: {0: 316, 1: 687, 2: 313, 3: 684, 4: 316, 5: 678, 6: 685, 7: 319, 8: 573, 9: 429}, 1: {0: 540, 1: 461, 2: 540, 3: 460, 4: 539, 5: 459, 6: 460, 7: 540, 8: 670, 9: 331}, 2: {0: 299, 1: 701, 2: 298, 3: 702, 4: 299, 5: 699, 6: 701, 7: 300, 8: 506, 9: 495}, 3: {0: 588, 1: 412, 2: 587, 3: 413, 4: 587, 5: 410, 6: 413, 7: 588, 8: 434, 9: 568}, 4: {0: 502, 1: 498, 2: 503, 3: 497, 4: 502, 5: 497, 6: 497, 7: 503, 8: 577, 9: 424}}
[Average accuracy till task5]	Acc@1: 87.2400	Acc@5: 98.1800	Loss: 0.6077	Forgetting: 6.9750	Backward: -6.9750
Train: Epoch[1/5]  [  0/313]  eta: 0:03:27  Lr: 0.001875  Loss: 2.1351  Acc@1: 0.0000 (0.0000)  Acc@5: 31.2500 (31.2500)  time: 0.6620  data: 0.3136  max mem: 2356
Train: Epoch[1/5]  [ 10/313]  eta: 0:01:50  Lr: 0.001875  Loss: 1.7108  Acc@1: 50.0000 (44.8864)  Acc@5: 93.7500 (80.6818)  time: 0.3638  data: 0.0299  max mem: 2356
Train: Epoch[1/5]  [ 20/313]  eta: 0:01:42  Lr: 0.001875  Loss: 1.3942  Acc@1: 68.7500 (59.8214)  Acc@5: 93.7500 (88.0952)  time: 0.3331  data: 0.0009  max mem: 2356
Train: Epoch[1/5]  [ 30/313]  eta: 0:01:37  Lr: 0.001875  Loss: 1.0376  Acc@1: 75.0000 (65.3226)  Acc@5: 100.0000 (90.3226)  time: 0.3329  data: 0.0004  max mem: 2356
Train: Epoch[1/5]  [ 40/313]  eta: 0:01:33  Lr: 0.001875  Loss: 1.0307  Acc@1: 81.2500 (69.6646)  Acc@5: 100.0000 (92.2256)  time: 0.3346  data: 0.0004  max mem: 2356
Train: Epoch[1/5]  [ 50/313]  eta: 0:01:29  Lr: 0.001875  Loss: 0.6691  Acc@1: 81.2500 (72.7941)  Acc@5: 100.0000 (93.6275)  time: 0.3344  data: 0.0005  max mem: 2356
Train: Epoch[1/5]  [ 60/313]  eta: 0:01:25  Lr: 0.001875  Loss: 0.4740  Acc@1: 81.2500 (74.5902)  Acc@5: 100.0000 (94.4672)  time: 0.3328  data: 0.0005  max mem: 2356
Train: Epoch[1/5]  [ 70/313]  eta: 0:01:22  Lr: 0.001875  Loss: 0.3875  Acc@1: 87.5000 (76.1444)  Acc@5: 100.0000 (94.8944)  time: 0.3333  data: 0.0004  max mem: 2356
Train: Epoch[1/5]  [ 80/313]  eta: 0:01:18  Lr: 0.001875  Loss: 0.7056  Acc@1: 87.5000 (77.5463)  Acc@5: 100.0000 (95.3704)  time: 0.3341  data: 0.0008  max mem: 2356
Train: Epoch[1/5]  [ 90/313]  eta: 0:01:15  Lr: 0.001875  Loss: 0.5768  Acc@1: 87.5000 (78.5714)  Acc@5: 100.0000 (95.8791)  time: 0.3330  data: 0.0007  max mem: 2356
Train: Epoch[1/5]  [100/313]  eta: 0:01:11  Lr: 0.001875  Loss: 0.4853  Acc@1: 87.5000 (78.9604)  Acc@5: 100.0000 (96.1634)  time: 0.3327  data: 0.0004  max mem: 2356
Train: Epoch[1/5]  [110/313]  eta: 0:01:08  Lr: 0.001875  Loss: 0.3471  Acc@1: 87.5000 (79.5045)  Acc@5: 100.0000 (96.3964)  time: 0.3326  data: 0.0010  max mem: 2356
Train: Epoch[1/5]  [120/313]  eta: 0:01:04  Lr: 0.001875  Loss: 0.3455  Acc@1: 87.5000 (79.8554)  Acc@5: 100.0000 (96.5909)  time: 0.3317  data: 0.0012  max mem: 2356
Train: Epoch[1/5]  [130/313]  eta: 0:01:01  Lr: 0.001875  Loss: 0.0978  Acc@1: 87.5000 (80.5344)  Acc@5: 100.0000 (96.8034)  time: 0.3335  data: 0.0010  max mem: 2356
Train: Epoch[1/5]  [140/313]  eta: 0:00:58  Lr: 0.001875  Loss: 0.1631  Acc@1: 87.5000 (81.1613)  Acc@5: 100.0000 (96.8528)  time: 0.3338  data: 0.0008  max mem: 2356
Train: Epoch[1/5]  [150/313]  eta: 0:00:54  Lr: 0.001875  Loss: 0.0354  Acc@1: 87.5000 (81.3742)  Acc@5: 100.0000 (97.0199)  time: 0.3326  data: 0.0008  max mem: 2356
Train: Epoch[1/5]  [160/313]  eta: 0:00:51  Lr: 0.001875  Loss: 0.3508  Acc@1: 87.5000 (81.7158)  Acc@5: 100.0000 (97.1273)  time: 0.3319  data: 0.0013  max mem: 2356
Train: Epoch[1/5]  [170/313]  eta: 0:00:47  Lr: 0.001875  Loss: 0.2833  Acc@1: 87.5000 (81.7617)  Acc@5: 100.0000 (97.2953)  time: 0.3314  data: 0.0011  max mem: 2356
Train: Epoch[1/5]  [180/313]  eta: 0:00:44  Lr: 0.001875  Loss: -0.0203  Acc@1: 87.5000 (82.1823)  Acc@5: 100.0000 (97.4102)  time: 0.3323  data: 0.0009  max mem: 2356
Train: Epoch[1/5]  [190/313]  eta: 0:00:41  Lr: 0.001875  Loss: 0.1675  Acc@1: 87.5000 (82.5262)  Acc@5: 100.0000 (97.5458)  time: 0.3393  data: 0.0017  max mem: 2356
Train: Epoch[1/5]  [200/313]  eta: 0:00:37  Lr: 0.001875  Loss: 0.2389  Acc@1: 87.5000 (82.8358)  Acc@5: 100.0000 (97.6679)  time: 0.3410  data: 0.0019  max mem: 2356
Train: Epoch[1/5]  [210/313]  eta: 0:00:34  Lr: 0.001875  Loss: 0.3102  Acc@1: 81.2500 (82.7607)  Acc@5: 100.0000 (97.6600)  time: 0.3394  data: 0.0025  max mem: 2356
Train: Epoch[1/5]  [220/313]  eta: 0:00:31  Lr: 0.001875  Loss: 0.0447  Acc@1: 81.2500 (82.6640)  Acc@5: 100.0000 (97.7376)  time: 0.3428  data: 0.0029  max mem: 2356
Train: Epoch[1/5]  [230/313]  eta: 0:00:27  Lr: 0.001875  Loss: 0.0949  Acc@1: 87.5000 (82.8193)  Acc@5: 100.0000 (97.7814)  time: 0.3383  data: 0.0013  max mem: 2356
Train: Epoch[1/5]  [240/313]  eta: 0:00:24  Lr: 0.001875  Loss: 0.2566  Acc@1: 87.5000 (83.1172)  Acc@5: 100.0000 (97.7956)  time: 0.3336  data: 0.0004  max mem: 2356
Train: Epoch[1/5]  [250/313]  eta: 0:00:21  Lr: 0.001875  Loss: -0.1108  Acc@1: 87.5000 (83.2420)  Acc@5: 100.0000 (97.8088)  time: 0.3352  data: 0.0005  max mem: 2356
Train: Epoch[1/5]  [260/313]  eta: 0:00:17  Lr: 0.001875  Loss: 0.2280  Acc@1: 87.5000 (83.3573)  Acc@5: 100.0000 (97.8209)  time: 0.3359  data: 0.0007  max mem: 2356
Train: Epoch[1/5]  [270/313]  eta: 0:00:14  Lr: 0.001875  Loss: 0.1032  Acc@1: 87.5000 (83.5101)  Acc@5: 100.0000 (97.8552)  time: 0.3376  data: 0.0011  max mem: 2356
Train: Epoch[1/5]  [280/313]  eta: 0:00:11  Lr: 0.001875  Loss: 0.2639  Acc@1: 87.5000 (83.6521)  Acc@5: 100.0000 (97.8870)  time: 0.3373  data: 0.0009  max mem: 2356
Train: Epoch[1/5]  [290/313]  eta: 0:00:07  Lr: 0.001875  Loss: 0.3977  Acc@1: 87.5000 (83.7414)  Acc@5: 100.0000 (97.9381)  time: 0.3335  data: 0.0004  max mem: 2356
Train: Epoch[1/5]  [300/313]  eta: 0:00:04  Lr: 0.001875  Loss: 0.1492  Acc@1: 87.5000 (83.8040)  Acc@5: 100.0000 (97.9859)  time: 0.3418  data: 0.0009  max mem: 2356
Train: Epoch[1/5]  [310/313]  eta: 0:00:01  Lr: 0.001875  Loss: 0.2422  Acc@1: 87.5000 (83.7621)  Acc@5: 100.0000 (97.9100)  time: 0.3455  data: 0.0013  max mem: 2356
Train: Epoch[1/5]  [312/313]  eta: 0:00:00  Lr: 0.001875  Loss: 0.3269  Acc@1: 87.5000 (83.8000)  Acc@5: 100.0000 (97.9200)  time: 0.3348  data: 0.0013  max mem: 2356
Train: Epoch[1/5] Total time: 0:01:45 (0.3363 s / it)
{0: {0: 22412, 1: 24815, 2: 19998, 3: 12102, 4: 7737, 5: 1609, 6: 0, 7: 0, 8: 0, 9: 0}, 1: {0: 1577, 1: 208, 2: 5200, 3: 12775, 4: 17024, 5: 3369, 6: 0, 7: 0, 8: 0, 9: 0}, 2: {0: 3518, 1: 6779, 2: 5327, 3: 9830, 4: 7541, 5: 1600, 6: 0, 7: 0, 8: 0, 9: 0}, 3: {0: 21486, 1: 20777, 2: 18903, 3: 14840, 4: 17372, 5: 3395, 6: 0, 7: 0, 8: 0, 9: 0}, 4: {0: 16124, 1: 10227, 2: 6432, 3: 10102, 4: 7685, 5: 1606, 6: 0, 7: 0, 8: 0, 9: 0}, 5: {0: 23402, 1: 24357, 2: 21714, 3: 15057, 4: 17322, 5: 3388, 6: 0, 7: 0, 8: 0, 9: 0}, 6: {0: 9472, 1: 12148, 2: 17669, 3: 14460, 4: 17318, 5: 3393, 6: 0, 7: 0, 8: 0, 9: 0}, 7: {0: 752, 1: 676, 2: 4577, 3: 10334, 4: 7679, 5: 1585, 6: 0, 7: 0, 8: 0, 9: 0}, 8: {0: 24269, 1: 24959, 2: 24373, 3: 23260, 4: 19009, 5: 3716, 6: 0, 7: 0, 8: 0, 9: 0}, 9: {0: 1988, 1: 54, 2: 807, 3: 2240, 4: 6313, 5: 1339, 6: 0, 7: 0, 8: 0, 9: 0}}
Averaged stats: Lr: 0.001875  Loss: 0.3269  Acc@1: 87.5000 (83.8000)  Acc@5: 100.0000 (97.9200)
Train: Epoch[2/5]  [  0/313]  eta: 0:04:05  Lr: 0.001875  Loss: 0.3294  Acc@1: 81.2500 (81.2500)  Acc@5: 93.7500 (93.7500)  time: 0.7834  data: 0.4468  max mem: 2356
Train: Epoch[2/5]  [ 10/313]  eta: 0:01:53  Lr: 0.001875  Loss: -0.0264  Acc@1: 93.7500 (90.9091)  Acc@5: 100.0000 (99.4318)  time: 0.3753  data: 0.0412  max mem: 2356
Train: Epoch[2/5]  [ 20/313]  eta: 0:01:45  Lr: 0.001875  Loss: 0.0284  Acc@1: 93.7500 (90.4762)  Acc@5: 100.0000 (99.4048)  time: 0.3384  data: 0.0006  max mem: 2356
Train: Epoch[2/5]  [ 30/313]  eta: 0:01:40  Lr: 0.001875  Loss: 0.0968  Acc@1: 87.5000 (87.9032)  Acc@5: 100.0000 (99.1935)  time: 0.3435  data: 0.0015  max mem: 2356
Train: Epoch[2/5]  [ 40/313]  eta: 0:01:35  Lr: 0.001875  Loss: 0.0839  Acc@1: 87.5000 (87.1951)  Acc@5: 100.0000 (99.2378)  time: 0.3391  data: 0.0015  max mem: 2356
Train: Epoch[2/5]  [ 50/313]  eta: 0:01:31  Lr: 0.001875  Loss: 0.1065  Acc@1: 87.5000 (86.5196)  Acc@5: 100.0000 (98.7745)  time: 0.3335  data: 0.0004  max mem: 2356
Train: Epoch[2/5]  [ 60/313]  eta: 0:01:27  Lr: 0.001875  Loss: 0.4375  Acc@1: 87.5000 (86.6803)  Acc@5: 100.0000 (98.7705)  time: 0.3335  data: 0.0004  max mem: 2356
Train: Epoch[2/5]  [ 70/313]  eta: 0:01:23  Lr: 0.001875  Loss: 0.5161  Acc@1: 87.5000 (86.3556)  Acc@5: 100.0000 (98.5915)  time: 0.3345  data: 0.0004  max mem: 2356
Train: Epoch[2/5]  [ 80/313]  eta: 0:01:19  Lr: 0.001875  Loss: -0.1305  Acc@1: 87.5000 (86.9599)  Acc@5: 100.0000 (98.6883)  time: 0.3336  data: 0.0005  max mem: 2356
Train: Epoch[2/5]  [ 90/313]  eta: 0:01:15  Lr: 0.001875  Loss: 0.1324  Acc@1: 87.5000 (86.9505)  Acc@5: 100.0000 (98.8324)  time: 0.3328  data: 0.0004  max mem: 2356
Train: Epoch[2/5]  [100/313]  eta: 0:01:12  Lr: 0.001875  Loss: 0.1156  Acc@1: 87.5000 (87.0050)  Acc@5: 100.0000 (98.8861)  time: 0.3329  data: 0.0003  max mem: 2356
Train: Epoch[2/5]  [110/313]  eta: 0:01:08  Lr: 0.001875  Loss: 0.2375  Acc@1: 87.5000 (86.7680)  Acc@5: 100.0000 (98.9302)  time: 0.3330  data: 0.0011  max mem: 2356
Train: Epoch[2/5]  [120/313]  eta: 0:01:05  Lr: 0.001875  Loss: 0.1231  Acc@1: 87.5000 (86.7769)  Acc@5: 100.0000 (98.9669)  time: 0.3330  data: 0.0011  max mem: 2356
Train: Epoch[2/5]  [130/313]  eta: 0:01:01  Lr: 0.001875  Loss: 0.1362  Acc@1: 87.5000 (86.7844)  Acc@5: 100.0000 (98.9504)  time: 0.3323  data: 0.0004  max mem: 2356
Train: Epoch[2/5]  [140/313]  eta: 0:00:58  Lr: 0.001875  Loss: 0.2521  Acc@1: 87.5000 (86.7465)  Acc@5: 100.0000 (99.0248)  time: 0.3334  data: 0.0004  max mem: 2356
Train: Epoch[2/5]  [150/313]  eta: 0:00:55  Lr: 0.001875  Loss: 0.3261  Acc@1: 81.2500 (86.5894)  Acc@5: 100.0000 (99.0480)  time: 0.3322  data: 0.0004  max mem: 2356
Train: Epoch[2/5]  [160/313]  eta: 0:00:51  Lr: 0.001875  Loss: 0.5721  Acc@1: 81.2500 (86.4130)  Acc@5: 100.0000 (99.0295)  time: 0.3297  data: 0.0003  max mem: 2356
Train: Epoch[2/5]  [170/313]  eta: 0:00:48  Lr: 0.001875  Loss: 0.1502  Acc@1: 87.5000 (86.2573)  Acc@5: 100.0000 (98.9766)  time: 0.3304  data: 0.0003  max mem: 2356
Train: Epoch[2/5]  [180/313]  eta: 0:00:44  Lr: 0.001875  Loss: -0.0294  Acc@1: 87.5000 (86.4986)  Acc@5: 100.0000 (98.9641)  time: 0.3316  data: 0.0003  max mem: 2356
Train: Epoch[2/5]  [190/313]  eta: 0:00:41  Lr: 0.001875  Loss: -0.0090  Acc@1: 93.7500 (86.7474)  Acc@5: 100.0000 (98.9856)  time: 0.3322  data: 0.0003  max mem: 2356
Train: Epoch[2/5]  [200/313]  eta: 0:00:37  Lr: 0.001875  Loss: -0.0244  Acc@1: 87.5000 (86.7848)  Acc@5: 100.0000 (98.9739)  time: 0.3312  data: 0.0004  max mem: 2356
Train: Epoch[2/5]  [210/313]  eta: 0:00:34  Lr: 0.001875  Loss: 0.1360  Acc@1: 87.5000 (86.7299)  Acc@5: 100.0000 (98.9633)  time: 0.3325  data: 0.0008  max mem: 2356
Train: Epoch[2/5]  [220/313]  eta: 0:00:31  Lr: 0.001875  Loss: 0.0488  Acc@1: 87.5000 (86.7647)  Acc@5: 100.0000 (98.9819)  time: 0.3329  data: 0.0007  max mem: 2356
Train: Epoch[2/5]  [230/313]  eta: 0:00:27  Lr: 0.001875  Loss: 0.2505  Acc@1: 87.5000 (86.8236)  Acc@5: 100.0000 (98.9448)  time: 0.3330  data: 0.0009  max mem: 2356
Train: Epoch[2/5]  [240/313]  eta: 0:00:24  Lr: 0.001875  Loss: 0.1250  Acc@1: 87.5000 (86.8776)  Acc@5: 100.0000 (98.9367)  time: 0.3385  data: 0.0021  max mem: 2356
Train: Epoch[2/5]  [250/313]  eta: 0:00:21  Lr: 0.001875  Loss: 0.2243  Acc@1: 87.5000 (86.9273)  Acc@5: 100.0000 (98.9542)  time: 0.3417  data: 0.0024  max mem: 2356
Train: Epoch[2/5]  [260/313]  eta: 0:00:17  Lr: 0.001875  Loss: 0.1432  Acc@1: 87.5000 (87.0211)  Acc@5: 100.0000 (98.9943)  time: 0.3397  data: 0.0020  max mem: 2356
Train: Epoch[2/5]  [270/313]  eta: 0:00:14  Lr: 0.001875  Loss: 0.0223  Acc@1: 87.5000 (87.0387)  Acc@5: 100.0000 (99.0083)  time: 0.3370  data: 0.0013  max mem: 2356
Train: Epoch[2/5]  [280/313]  eta: 0:00:11  Lr: 0.001875  Loss: 0.1690  Acc@1: 87.5000 (87.1886)  Acc@5: 100.0000 (98.9991)  time: 0.3381  data: 0.0011  max mem: 2356
Train: Epoch[2/5]  [290/313]  eta: 0:00:07  Lr: 0.001875  Loss: 0.1191  Acc@1: 87.5000 (87.2208)  Acc@5: 100.0000 (99.0120)  time: 0.3365  data: 0.0010  max mem: 2356
Train: Epoch[2/5]  [300/313]  eta: 0:00:04  Lr: 0.001875  Loss: 0.1894  Acc@1: 87.5000 (87.3962)  Acc@5: 100.0000 (99.0449)  time: 0.3356  data: 0.0008  max mem: 2356
Train: Epoch[2/5]  [310/313]  eta: 0:00:01  Lr: 0.001875  Loss: 0.2920  Acc@1: 93.7500 (87.4196)  Acc@5: 100.0000 (99.0555)  time: 0.3425  data: 0.0012  max mem: 2356
Train: Epoch[2/5]  [312/313]  eta: 0:00:00  Lr: 0.001875  Loss: 0.2329  Acc@1: 87.5000 (87.3600)  Acc@5: 100.0000 (99.0600)  time: 0.3344  data: 0.0012  max mem: 2356
Train: Epoch[2/5] Total time: 0:01:45 (0.3365 s / it)
{0: {0: 22412, 1: 24815, 2: 19998, 3: 12102, 4: 7737, 5: 3204, 6: 0, 7: 0, 8: 0, 9: 0}, 1: {0: 1577, 1: 208, 2: 5200, 3: 12775, 4: 17024, 5: 6730, 6: 0, 7: 0, 8: 0, 9: 0}, 2: {0: 3518, 1: 6779, 2: 5327, 3: 9830, 4: 7541, 5: 3212, 6: 0, 7: 0, 8: 0, 9: 0}, 3: {0: 21486, 1: 20777, 2: 18903, 3: 14840, 4: 17372, 5: 6794, 6: 0, 7: 0, 8: 0, 9: 0}, 4: {0: 16124, 1: 10227, 2: 6432, 3: 10102, 4: 7685, 5: 3205, 6: 0, 7: 0, 8: 0, 9: 0}, 5: {0: 23402, 1: 24357, 2: 21714, 3: 15057, 4: 17322, 5: 6752, 6: 0, 7: 0, 8: 0, 9: 0}, 6: {0: 9472, 1: 12148, 2: 17669, 3: 14460, 4: 17318, 5: 6800, 6: 0, 7: 0, 8: 0, 9: 0}, 7: {0: 752, 1: 676, 2: 4577, 3: 10334, 4: 7679, 5: 3185, 6: 0, 7: 0, 8: 0, 9: 0}, 8: {0: 24269, 1: 24959, 2: 24373, 3: 23260, 4: 19009, 5: 6867, 6: 0, 7: 0, 8: 0, 9: 0}, 9: {0: 1988, 1: 54, 2: 807, 3: 2240, 4: 6313, 5: 3251, 6: 0, 7: 0, 8: 0, 9: 0}}
Averaged stats: Lr: 0.001875  Loss: 0.2329  Acc@1: 87.5000 (87.3600)  Acc@5: 100.0000 (99.0600)
Train: Epoch[3/5]  [  0/313]  eta: 0:02:58  Lr: 0.001875  Loss: -0.1027  Acc@1: 93.7500 (93.7500)  Acc@5: 100.0000 (100.0000)  time: 0.5707  data: 0.2355  max mem: 2356
Train: Epoch[3/5]  [ 10/313]  eta: 0:01:50  Lr: 0.001875  Loss: -0.0452  Acc@1: 87.5000 (86.3636)  Acc@5: 100.0000 (99.4318)  time: 0.3654  data: 0.0217  max mem: 2356
Train: Epoch[3/5]  [ 20/313]  eta: 0:01:43  Lr: 0.001875  Loss: 0.0227  Acc@1: 87.5000 (86.0119)  Acc@5: 100.0000 (99.4048)  time: 0.3408  data: 0.0011  max mem: 2356
Train: Epoch[3/5]  [ 30/313]  eta: 0:01:38  Lr: 0.001875  Loss: -0.0137  Acc@1: 81.2500 (85.0806)  Acc@5: 100.0000 (99.5968)  time: 0.3400  data: 0.0011  max mem: 2356
Train: Epoch[3/5]  [ 40/313]  eta: 0:01:34  Lr: 0.001875  Loss: 0.0316  Acc@1: 87.5000 (85.3659)  Acc@5: 100.0000 (99.6951)  time: 0.3402  data: 0.0005  max mem: 2356
Train: Epoch[3/5]  [ 50/313]  eta: 0:01:30  Lr: 0.001875  Loss: 0.3286  Acc@1: 87.5000 (86.1520)  Acc@5: 100.0000 (99.7549)  time: 0.3368  data: 0.0006  max mem: 2356
Train: Epoch[3/5]  [ 60/313]  eta: 0:01:26  Lr: 0.001875  Loss: 0.0001  Acc@1: 87.5000 (86.1680)  Acc@5: 100.0000 (99.4877)  time: 0.3387  data: 0.0009  max mem: 2356
Train: Epoch[3/5]  [ 70/313]  eta: 0:01:23  Lr: 0.001875  Loss: 0.0530  Acc@1: 87.5000 (86.6197)  Acc@5: 100.0000 (99.5599)  time: 0.3428  data: 0.0022  max mem: 2356
Train: Epoch[3/5]  [ 80/313]  eta: 0:01:19  Lr: 0.001875  Loss: -0.0756  Acc@1: 87.5000 (87.3457)  Acc@5: 100.0000 (99.5370)  time: 0.3382  data: 0.0019  max mem: 2356
Train: Epoch[3/5]  [ 90/313]  eta: 0:01:16  Lr: 0.001875  Loss: 0.1351  Acc@1: 93.7500 (87.7060)  Acc@5: 100.0000 (99.5192)  time: 0.3330  data: 0.0005  max mem: 2356
Train: Epoch[3/5]  [100/313]  eta: 0:01:12  Lr: 0.001875  Loss: 0.3519  Acc@1: 93.7500 (87.7475)  Acc@5: 100.0000 (99.5668)  time: 0.3328  data: 0.0004  max mem: 2356
Train: Epoch[3/5]  [110/313]  eta: 0:01:08  Lr: 0.001875  Loss: 0.3053  Acc@1: 87.5000 (87.6126)  Acc@5: 100.0000 (99.5495)  time: 0.3321  data: 0.0004  max mem: 2356
Train: Epoch[3/5]  [120/313]  eta: 0:01:05  Lr: 0.001875  Loss: -0.0237  Acc@1: 87.5000 (87.7583)  Acc@5: 100.0000 (99.5351)  time: 0.3344  data: 0.0005  max mem: 2356
Train: Epoch[3/5]  [130/313]  eta: 0:01:02  Lr: 0.001875  Loss: -0.0193  Acc@1: 87.5000 (87.9294)  Acc@5: 100.0000 (99.5229)  time: 0.3358  data: 0.0005  max mem: 2356
Train: Epoch[3/5]  [140/313]  eta: 0:00:58  Lr: 0.001875  Loss: 0.4151  Acc@1: 87.5000 (87.9433)  Acc@5: 100.0000 (99.5124)  time: 0.3346  data: 0.0005  max mem: 2356
Train: Epoch[3/5]  [150/313]  eta: 0:00:55  Lr: 0.001875  Loss: 0.1630  Acc@1: 87.5000 (88.2036)  Acc@5: 100.0000 (99.5447)  time: 0.3329  data: 0.0004  max mem: 2356
Train: Epoch[3/5]  [160/313]  eta: 0:00:51  Lr: 0.001875  Loss: -0.0821  Acc@1: 93.7500 (88.3152)  Acc@5: 100.0000 (99.5730)  time: 0.3328  data: 0.0004  max mem: 2356
Train: Epoch[3/5]  [170/313]  eta: 0:00:48  Lr: 0.001875  Loss: 0.0051  Acc@1: 87.5000 (88.1213)  Acc@5: 100.0000 (99.5980)  time: 0.3328  data: 0.0004  max mem: 2356
Train: Epoch[3/5]  [180/313]  eta: 0:00:44  Lr: 0.001875  Loss: 0.1645  Acc@1: 87.5000 (87.9489)  Acc@5: 100.0000 (99.5511)  time: 0.3324  data: 0.0004  max mem: 2356
Train: Epoch[3/5]  [190/313]  eta: 0:00:41  Lr: 0.001875  Loss: -0.0337  Acc@1: 87.5000 (87.9908)  Acc@5: 100.0000 (99.5419)  time: 0.3331  data: 0.0003  max mem: 2356
Train: Epoch[3/5]  [200/313]  eta: 0:00:38  Lr: 0.001875  Loss: -0.0730  Acc@1: 87.5000 (87.8731)  Acc@5: 100.0000 (99.5025)  time: 0.3317  data: 0.0003  max mem: 2356
Train: Epoch[3/5]  [210/313]  eta: 0:00:34  Lr: 0.001875  Loss: -0.0790  Acc@1: 87.5000 (87.9443)  Acc@5: 100.0000 (99.4372)  time: 0.3302  data: 0.0007  max mem: 2356
Train: Epoch[3/5]  [220/313]  eta: 0:00:31  Lr: 0.001875  Loss: 0.2118  Acc@1: 87.5000 (87.7545)  Acc@5: 100.0000 (99.3495)  time: 0.3325  data: 0.0013  max mem: 2356
Train: Epoch[3/5]  [230/313]  eta: 0:00:27  Lr: 0.001875  Loss: 0.1505  Acc@1: 87.5000 (87.7976)  Acc@5: 100.0000 (99.3506)  time: 0.3334  data: 0.0013  max mem: 2356
Train: Epoch[3/5]  [240/313]  eta: 0:00:24  Lr: 0.001875  Loss: -0.0031  Acc@1: 87.5000 (87.9149)  Acc@5: 100.0000 (99.3776)  time: 0.3324  data: 0.0007  max mem: 2356
Train: Epoch[3/5]  [250/313]  eta: 0:00:21  Lr: 0.001875  Loss: 0.0832  Acc@1: 93.7500 (88.0727)  Acc@5: 100.0000 (99.4024)  time: 0.3309  data: 0.0003  max mem: 2356
Train: Epoch[3/5]  [260/313]  eta: 0:00:17  Lr: 0.001875  Loss: 0.4058  Acc@1: 87.5000 (87.9789)  Acc@5: 100.0000 (99.4013)  time: 0.3317  data: 0.0005  max mem: 2356
Train: Epoch[3/5]  [270/313]  eta: 0:00:14  Lr: 0.001875  Loss: 0.1388  Acc@1: 87.5000 (87.9151)  Acc@5: 100.0000 (99.3312)  time: 0.3358  data: 0.0012  max mem: 2356
Train: Epoch[3/5]  [280/313]  eta: 0:00:11  Lr: 0.001875  Loss: 0.3412  Acc@1: 87.5000 (88.0560)  Acc@5: 100.0000 (99.3105)  time: 0.3393  data: 0.0016  max mem: 2356
Train: Epoch[3/5]  [290/313]  eta: 0:00:07  Lr: 0.001875  Loss: 0.3262  Acc@1: 87.5000 (87.9510)  Acc@5: 100.0000 (99.3127)  time: 0.3408  data: 0.0016  max mem: 2356
Train: Epoch[3/5]  [300/313]  eta: 0:00:04  Lr: 0.001875  Loss: -0.0027  Acc@1: 87.5000 (87.9360)  Acc@5: 100.0000 (99.2940)  time: 0.3379  data: 0.0018  max mem: 2356
Train: Epoch[3/5]  [310/313]  eta: 0:00:01  Lr: 0.001875  Loss: -0.0106  Acc@1: 87.5000 (87.9421)  Acc@5: 100.0000 (99.3167)  time: 0.3363  data: 0.0013  max mem: 2356
Train: Epoch[3/5]  [312/313]  eta: 0:00:00  Lr: 0.001875  Loss: -0.1852  Acc@1: 87.5000 (88.0000)  Acc@5: 100.0000 (99.3200)  time: 0.3284  data: 0.0013  max mem: 2356
Train: Epoch[3/5] Total time: 0:01:45 (0.3360 s / it)
{0: {0: 22412, 1: 24815, 2: 19998, 3: 12102, 4: 7737, 5: 4769, 6: 0, 7: 0, 8: 0, 9: 0}, 1: {0: 1577, 1: 208, 2: 5200, 3: 12775, 4: 17024, 5: 10121, 6: 0, 7: 0, 8: 0, 9: 0}, 2: {0: 3518, 1: 6779, 2: 5327, 3: 9830, 4: 7541, 5: 4804, 6: 0, 7: 0, 8: 0, 9: 0}, 3: {0: 21486, 1: 20777, 2: 18903, 3: 14840, 4: 17372, 5: 10225, 6: 0, 7: 0, 8: 0, 9: 0}, 4: {0: 16124, 1: 10227, 2: 6432, 3: 10102, 4: 7685, 5: 4765, 6: 0, 7: 0, 8: 0, 9: 0}, 5: {0: 23402, 1: 24357, 2: 21714, 3: 15057, 4: 17322, 5: 10134, 6: 0, 7: 0, 8: 0, 9: 0}, 6: {0: 9472, 1: 12148, 2: 17669, 3: 14460, 4: 17318, 5: 10235, 6: 0, 7: 0, 8: 0, 9: 0}, 7: {0: 752, 1: 676, 2: 4577, 3: 10334, 4: 7679, 5: 4761, 6: 0, 7: 0, 8: 0, 9: 0}, 8: {0: 24269, 1: 24959, 2: 24373, 3: 23260, 4: 19009, 5: 9574, 6: 0, 7: 0, 8: 0, 9: 0}, 9: {0: 1988, 1: 54, 2: 807, 3: 2240, 4: 6313, 5: 5612, 6: 0, 7: 0, 8: 0, 9: 0}}
Averaged stats: Lr: 0.001875  Loss: -0.1852  Acc@1: 87.5000 (88.0000)  Acc@5: 100.0000 (99.3200)
Train: Epoch[4/5]  [  0/313]  eta: 0:04:18  Lr: 0.001875  Loss: 0.1296  Acc@1: 87.5000 (87.5000)  Acc@5: 93.7500 (93.7500)  time: 0.8262  data: 0.4282  max mem: 2356
Train: Epoch[4/5]  [ 10/313]  eta: 0:01:54  Lr: 0.001875  Loss: 0.0253  Acc@1: 87.5000 (90.3409)  Acc@5: 100.0000 (98.2955)  time: 0.3788  data: 0.0395  max mem: 2356
Train: Epoch[4/5]  [ 20/313]  eta: 0:01:44  Lr: 0.001875  Loss: 0.0017  Acc@1: 87.5000 (89.2857)  Acc@5: 100.0000 (99.1071)  time: 0.3341  data: 0.0005  max mem: 2356
Train: Epoch[4/5]  [ 30/313]  eta: 0:01:39  Lr: 0.001875  Loss: -0.0585  Acc@1: 93.7500 (89.9194)  Acc@5: 100.0000 (99.1935)  time: 0.3391  data: 0.0013  max mem: 2356
Train: Epoch[4/5]  [ 40/313]  eta: 0:01:35  Lr: 0.001875  Loss: 0.0962  Acc@1: 87.5000 (90.0915)  Acc@5: 100.0000 (99.2378)  time: 0.3424  data: 0.0015  max mem: 2356
Train: Epoch[4/5]  [ 50/313]  eta: 0:01:31  Lr: 0.001875  Loss: 0.1852  Acc@1: 87.5000 (89.5833)  Acc@5: 100.0000 (98.8971)  time: 0.3400  data: 0.0006  max mem: 2356
Train: Epoch[4/5]  [ 60/313]  eta: 0:01:27  Lr: 0.001875  Loss: -0.0917  Acc@1: 87.5000 (89.4467)  Acc@5: 100.0000 (98.7705)  time: 0.3386  data: 0.0008  max mem: 2356
Train: Epoch[4/5]  [ 70/313]  eta: 0:01:23  Lr: 0.001875  Loss: 0.0582  Acc@1: 87.5000 (88.2923)  Acc@5: 100.0000 (98.8556)  time: 0.3379  data: 0.0018  max mem: 2356
Train: Epoch[4/5]  [ 80/313]  eta: 0:01:20  Lr: 0.001875  Loss: -0.0134  Acc@1: 87.5000 (88.5802)  Acc@5: 100.0000 (98.9198)  time: 0.3356  data: 0.0014  max mem: 2356
Train: Epoch[4/5]  [ 90/313]  eta: 0:01:16  Lr: 0.001875  Loss: -0.1654  Acc@1: 87.5000 (88.5302)  Acc@5: 100.0000 (98.9011)  time: 0.3372  data: 0.0004  max mem: 2356
Train: Epoch[4/5]  [100/313]  eta: 0:01:13  Lr: 0.001875  Loss: 0.1625  Acc@1: 87.5000 (88.3663)  Acc@5: 100.0000 (98.9480)  time: 0.3407  data: 0.0012  max mem: 2356
Train: Epoch[4/5]  [110/313]  eta: 0:01:09  Lr: 0.001875  Loss: -0.0022  Acc@1: 87.5000 (88.0631)  Acc@5: 100.0000 (98.9302)  time: 0.3445  data: 0.0014  max mem: 2356
Train: Epoch[4/5]  [120/313]  eta: 0:01:06  Lr: 0.001875  Loss: 0.0713  Acc@1: 87.5000 (87.7583)  Acc@5: 100.0000 (98.9153)  time: 0.3407  data: 0.0006  max mem: 2356
Train: Epoch[4/5]  [130/313]  eta: 0:01:02  Lr: 0.001875  Loss: -0.0852  Acc@1: 87.5000 (87.6431)  Acc@5: 100.0000 (98.9504)  time: 0.3324  data: 0.0004  max mem: 2356
Train: Epoch[4/5]  [140/313]  eta: 0:00:59  Lr: 0.001875  Loss: 0.0186  Acc@1: 93.7500 (87.8546)  Acc@5: 100.0000 (98.9805)  time: 0.3323  data: 0.0004  max mem: 2356
Train: Epoch[4/5]  [150/313]  eta: 0:00:55  Lr: 0.001875  Loss: -0.1348  Acc@1: 93.7500 (88.0795)  Acc@5: 100.0000 (99.0066)  time: 0.3330  data: 0.0004  max mem: 2356
Train: Epoch[4/5]  [160/313]  eta: 0:00:52  Lr: 0.001875  Loss: -0.2103  Acc@1: 93.7500 (88.3540)  Acc@5: 100.0000 (98.9907)  time: 0.3329  data: 0.0004  max mem: 2356
Train: Epoch[4/5]  [170/313]  eta: 0:00:48  Lr: 0.001875  Loss: 0.3781  Acc@1: 87.5000 (88.1213)  Acc@5: 100.0000 (99.0497)  time: 0.3351  data: 0.0004  max mem: 2356
Train: Epoch[4/5]  [180/313]  eta: 0:00:45  Lr: 0.001875  Loss: 0.1815  Acc@1: 81.2500 (88.0180)  Acc@5: 100.0000 (98.9986)  time: 0.3365  data: 0.0011  max mem: 2356
Train: Epoch[4/5]  [190/313]  eta: 0:00:41  Lr: 0.001875  Loss: -0.0539  Acc@1: 87.5000 (88.1545)  Acc@5: 100.0000 (99.0183)  time: 0.3350  data: 0.0012  max mem: 2356
Train: Epoch[4/5]  [200/313]  eta: 0:00:38  Lr: 0.001875  Loss: 0.1319  Acc@1: 87.5000 (88.1841)  Acc@5: 100.0000 (99.0361)  time: 0.3340  data: 0.0005  max mem: 2356
Train: Epoch[4/5]  [210/313]  eta: 0:00:34  Lr: 0.001875  Loss: -0.0027  Acc@1: 87.5000 (88.2701)  Acc@5: 100.0000 (99.0225)  time: 0.3339  data: 0.0004  max mem: 2356
Train: Epoch[4/5]  [220/313]  eta: 0:00:31  Lr: 0.001875  Loss: 0.1290  Acc@1: 93.7500 (88.3201)  Acc@5: 100.0000 (99.0102)  time: 0.3348  data: 0.0007  max mem: 2356
Train: Epoch[4/5]  [230/313]  eta: 0:00:28  Lr: 0.001875  Loss: 0.1853  Acc@1: 93.7500 (88.3929)  Acc@5: 100.0000 (99.0530)  time: 0.3339  data: 0.0007  max mem: 2356
Train: Epoch[4/5]  [240/313]  eta: 0:00:24  Lr: 0.001875  Loss: 0.0951  Acc@1: 87.5000 (88.2780)  Acc@5: 100.0000 (99.0664)  time: 0.3320  data: 0.0004  max mem: 2356
Train: Epoch[4/5]  [250/313]  eta: 0:00:21  Lr: 0.001875  Loss: -0.1760  Acc@1: 87.5000 (88.3715)  Acc@5: 100.0000 (99.1036)  time: 0.3310  data: 0.0003  max mem: 2356
Train: Epoch[4/5]  [260/313]  eta: 0:00:17  Lr: 0.001875  Loss: -0.0592  Acc@1: 93.7500 (88.5057)  Acc@5: 100.0000 (99.1379)  time: 0.3313  data: 0.0004  max mem: 2356
Train: Epoch[4/5]  [270/313]  eta: 0:00:14  Lr: 0.001875  Loss: 0.3048  Acc@1: 93.7500 (88.4456)  Acc@5: 100.0000 (99.1467)  time: 0.3320  data: 0.0004  max mem: 2356
Train: Epoch[4/5]  [280/313]  eta: 0:00:11  Lr: 0.001875  Loss: 0.0069  Acc@1: 87.5000 (88.3230)  Acc@5: 100.0000 (99.1548)  time: 0.3309  data: 0.0003  max mem: 2356
Train: Epoch[4/5]  [290/313]  eta: 0:00:07  Lr: 0.001875  Loss: 0.1688  Acc@1: 87.5000 (88.3162)  Acc@5: 100.0000 (99.1409)  time: 0.3312  data: 0.0014  max mem: 2356
Train: Epoch[4/5]  [300/313]  eta: 0:00:04  Lr: 0.001875  Loss: -0.0608  Acc@1: 87.5000 (88.2890)  Acc@5: 100.0000 (99.1071)  time: 0.3331  data: 0.0020  max mem: 2356
Train: Epoch[4/5]  [310/313]  eta: 0:00:01  Lr: 0.001875  Loss: 0.0018  Acc@1: 87.5000 (88.2838)  Acc@5: 100.0000 (99.0957)  time: 0.3322  data: 0.0015  max mem: 2356
Train: Epoch[4/5]  [312/313]  eta: 0:00:00  Lr: 0.001875  Loss: -0.1726  Acc@1: 87.5000 (88.3400)  Acc@5: 100.0000 (99.1000)  time: 0.3242  data: 0.0015  max mem: 2356
Train: Epoch[4/5] Total time: 0:01:45 (0.3365 s / it)
{0: {0: 22412, 1: 24815, 2: 19998, 3: 12102, 4: 7737, 5: 6324, 6: 0, 7: 0, 8: 0, 9: 0}, 1: {0: 1577, 1: 208, 2: 5200, 3: 12775, 4: 17024, 5: 13559, 6: 0, 7: 0, 8: 0, 9: 0}, 2: {0: 3518, 1: 6779, 2: 5327, 3: 9830, 4: 7541, 5: 6371, 6: 0, 7: 0, 8: 0, 9: 0}, 3: {0: 21486, 1: 20777, 2: 18903, 3: 14840, 4: 17372, 5: 13679, 6: 0, 7: 0, 8: 0, 9: 0}, 4: {0: 16124, 1: 10227, 2: 6432, 3: 10102, 4: 7685, 5: 6305, 6: 0, 7: 0, 8: 0, 9: 0}, 5: {0: 23402, 1: 24357, 2: 21714, 3: 15057, 4: 17322, 5: 13541, 6: 0, 7: 0, 8: 0, 9: 0}, 6: {0: 9472, 1: 12148, 2: 17669, 3: 14460, 4: 17318, 5: 13689, 6: 0, 7: 0, 8: 0, 9: 0}, 7: {0: 752, 1: 676, 2: 4577, 3: 10334, 4: 7679, 5: 6310, 6: 0, 7: 0, 8: 0, 9: 0}, 8: {0: 24269, 1: 24959, 2: 24373, 3: 23260, 4: 19009, 5: 12019, 6: 0, 7: 0, 8: 0, 9: 0}, 9: {0: 1988, 1: 54, 2: 807, 3: 2240, 4: 6313, 5: 8203, 6: 0, 7: 0, 8: 0, 9: 0}}
Averaged stats: Lr: 0.001875  Loss: -0.1726  Acc@1: 87.5000 (88.3400)  Acc@5: 100.0000 (99.1000)
Train: Epoch[5/5]  [  0/313]  eta: 0:02:58  Lr: 0.001875  Loss: 0.4538  Acc@1: 81.2500 (81.2500)  Acc@5: 93.7500 (93.7500)  time: 0.5691  data: 0.2308  max mem: 2356
Train: Epoch[5/5]  [ 10/313]  eta: 0:01:47  Lr: 0.001875  Loss: -0.0832  Acc@1: 93.7500 (90.3409)  Acc@5: 100.0000 (98.8636)  time: 0.3552  data: 0.0218  max mem: 2356
Train: Epoch[5/5]  [ 20/313]  eta: 0:01:41  Lr: 0.001875  Loss: 0.3053  Acc@1: 87.5000 (88.3929)  Acc@5: 100.0000 (98.5119)  time: 0.3340  data: 0.0007  max mem: 2356
Train: Epoch[5/5]  [ 30/313]  eta: 0:01:36  Lr: 0.001875  Loss: -0.0147  Acc@1: 87.5000 (89.1129)  Acc@5: 100.0000 (98.7903)  time: 0.3343  data: 0.0008  max mem: 2356
Train: Epoch[5/5]  [ 40/313]  eta: 0:01:32  Lr: 0.001875  Loss: 0.1147  Acc@1: 87.5000 (89.3293)  Acc@5: 100.0000 (98.9329)  time: 0.3333  data: 0.0007  max mem: 2356
Train: Epoch[5/5]  [ 50/313]  eta: 0:01:29  Lr: 0.001875  Loss: 0.0713  Acc@1: 87.5000 (89.0931)  Acc@5: 100.0000 (99.1422)  time: 0.3348  data: 0.0013  max mem: 2356
Train: Epoch[5/5]  [ 60/313]  eta: 0:01:25  Lr: 0.001875  Loss: -0.0384  Acc@1: 87.5000 (89.0369)  Acc@5: 100.0000 (99.0779)  time: 0.3357  data: 0.0013  max mem: 2356
Train: Epoch[5/5]  [ 70/313]  eta: 0:01:22  Lr: 0.001875  Loss: 0.1460  Acc@1: 87.5000 (88.2923)  Acc@5: 100.0000 (99.0317)  time: 0.3345  data: 0.0005  max mem: 2356
Train: Epoch[5/5]  [ 80/313]  eta: 0:01:18  Lr: 0.001875  Loss: 0.1474  Acc@1: 87.5000 (88.4259)  Acc@5: 100.0000 (99.1512)  time: 0.3349  data: 0.0008  max mem: 2356
Train: Epoch[5/5]  [ 90/313]  eta: 0:01:15  Lr: 0.001875  Loss: -0.0622  Acc@1: 93.7500 (88.9423)  Acc@5: 100.0000 (99.2445)  time: 0.3341  data: 0.0012  max mem: 2356
Train: Epoch[5/5]  [100/313]  eta: 0:01:11  Lr: 0.001875  Loss: 0.0024  Acc@1: 87.5000 (88.6139)  Acc@5: 100.0000 (99.3193)  time: 0.3349  data: 0.0011  max mem: 2356
Train: Epoch[5/5]  [110/313]  eta: 0:01:08  Lr: 0.001875  Loss: 0.6399  Acc@1: 87.5000 (88.6261)  Acc@5: 100.0000 (99.1554)  time: 0.3371  data: 0.0009  max mem: 2356
Train: Epoch[5/5]  [120/313]  eta: 0:01:04  Lr: 0.001875  Loss: -0.1494  Acc@1: 93.7500 (88.6364)  Acc@5: 100.0000 (99.1219)  time: 0.3355  data: 0.0008  max mem: 2356
Train: Epoch[5/5]  [130/313]  eta: 0:01:01  Lr: 0.001875  Loss: 0.0443  Acc@1: 87.5000 (88.6927)  Acc@5: 100.0000 (99.1889)  time: 0.3328  data: 0.0010  max mem: 2356
Train: Epoch[5/5]  [140/313]  eta: 0:00:58  Lr: 0.001875  Loss: 0.1625  Acc@1: 87.5000 (88.6968)  Acc@5: 100.0000 (99.0248)  time: 0.3332  data: 0.0013  max mem: 2356
Train: Epoch[5/5]  [150/313]  eta: 0:00:54  Lr: 0.001875  Loss: 0.0140  Acc@1: 87.5000 (88.6589)  Acc@5: 100.0000 (99.0894)  time: 0.3371  data: 0.0009  max mem: 2356
Train: Epoch[5/5]  [160/313]  eta: 0:00:51  Lr: 0.001875  Loss: -0.0036  Acc@1: 87.5000 (88.7422)  Acc@5: 100.0000 (99.1071)  time: 0.3366  data: 0.0006  max mem: 2356
Train: Epoch[5/5]  [170/313]  eta: 0:00:48  Lr: 0.001875  Loss: -0.1218  Acc@1: 87.5000 (88.4868)  Acc@5: 100.0000 (99.1228)  time: 0.3344  data: 0.0010  max mem: 2356
Train: Epoch[5/5]  [180/313]  eta: 0:00:44  Lr: 0.001875  Loss: -0.1532  Acc@1: 87.5000 (88.4669)  Acc@5: 100.0000 (99.1022)  time: 0.3354  data: 0.0008  max mem: 2356
Train: Epoch[5/5]  [190/313]  eta: 0:00:41  Lr: 0.001875  Loss: 0.5328  Acc@1: 87.5000 (88.4162)  Acc@5: 100.0000 (99.1492)  time: 0.3357  data: 0.0008  max mem: 2356
Train: Epoch[5/5]  [200/313]  eta: 0:00:37  Lr: 0.001875  Loss: -0.0951  Acc@1: 87.5000 (88.4328)  Acc@5: 100.0000 (99.1915)  time: 0.3370  data: 0.0010  max mem: 2356
Train: Epoch[5/5]  [210/313]  eta: 0:00:34  Lr: 0.001875  Loss: -0.0418  Acc@1: 93.7500 (88.6848)  Acc@5: 100.0000 (99.2299)  time: 0.3373  data: 0.0008  max mem: 2356
Train: Epoch[5/5]  [220/313]  eta: 0:00:31  Lr: 0.001875  Loss: 0.1448  Acc@1: 93.7500 (88.7726)  Acc@5: 100.0000 (99.2647)  time: 0.3352  data: 0.0006  max mem: 2356
Train: Epoch[5/5]  [230/313]  eta: 0:00:27  Lr: 0.001875  Loss: 0.1332  Acc@1: 87.5000 (88.6905)  Acc@5: 100.0000 (99.2424)  time: 0.3331  data: 0.0003  max mem: 2356
Train: Epoch[5/5]  [240/313]  eta: 0:00:24  Lr: 0.001875  Loss: -0.1610  Acc@1: 87.5000 (88.4595)  Acc@5: 100.0000 (99.1961)  time: 0.3327  data: 0.0003  max mem: 2356
Train: Epoch[5/5]  [250/313]  eta: 0:00:21  Lr: 0.001875  Loss: -0.1715  Acc@1: 81.2500 (88.4711)  Acc@5: 100.0000 (99.2032)  time: 0.3326  data: 0.0004  max mem: 2356
Train: Epoch[5/5]  [260/313]  eta: 0:00:17  Lr: 0.001875  Loss: 0.0513  Acc@1: 87.5000 (88.4579)  Acc@5: 100.0000 (99.2337)  time: 0.3332  data: 0.0004  max mem: 2356
Train: Epoch[5/5]  [270/313]  eta: 0:00:14  Lr: 0.001875  Loss: 0.2665  Acc@1: 93.7500 (88.6070)  Acc@5: 100.0000 (99.2389)  time: 0.3338  data: 0.0006  max mem: 2356
Train: Epoch[5/5]  [280/313]  eta: 0:00:11  Lr: 0.001875  Loss: 0.0528  Acc@1: 93.7500 (88.6788)  Acc@5: 100.0000 (99.2660)  time: 0.3343  data: 0.0006  max mem: 2356
Train: Epoch[5/5]  [290/313]  eta: 0:00:07  Lr: 0.001875  Loss: 0.0886  Acc@1: 87.5000 (88.6383)  Acc@5: 100.0000 (99.2698)  time: 0.3348  data: 0.0004  max mem: 2356
Train: Epoch[5/5]  [300/313]  eta: 0:00:04  Lr: 0.001875  Loss: 0.2155  Acc@1: 87.5000 (88.4967)  Acc@5: 100.0000 (99.2940)  time: 0.3346  data: 0.0004  max mem: 2356
Train: Epoch[5/5]  [310/313]  eta: 0:00:01  Lr: 0.001875  Loss: 0.3676  Acc@1: 87.5000 (88.5048)  Acc@5: 100.0000 (99.2966)  time: 0.3347  data: 0.0004  max mem: 2356
Train: Epoch[5/5]  [312/313]  eta: 0:00:00  Lr: 0.001875  Loss: 0.1561  Acc@1: 87.5000 (88.5200)  Acc@5: 100.0000 (99.3000)  time: 0.3260  data: 0.0004  max mem: 2356
Train: Epoch[5/5] Total time: 0:01:44 (0.3353 s / it)
{0: {0: 22412, 1: 24815, 2: 19998, 3: 12102, 4: 7737, 5: 7897, 6: 0, 7: 0, 8: 0, 9: 0}, 1: {0: 1577, 1: 208, 2: 5200, 3: 12775, 4: 17024, 5: 16965, 6: 0, 7: 0, 8: 0, 9: 0}, 2: {0: 3518, 1: 6779, 2: 5327, 3: 9830, 4: 7541, 5: 7967, 6: 0, 7: 0, 8: 0, 9: 0}, 3: {0: 21486, 1: 20777, 2: 18903, 3: 14840, 4: 17372, 5: 17103, 6: 0, 7: 0, 8: 0, 9: 0}, 4: {0: 16124, 1: 10227, 2: 6432, 3: 10102, 4: 7685, 5: 7874, 6: 0, 7: 0, 8: 0, 9: 0}, 5: {0: 23402, 1: 24357, 2: 21714, 3: 15057, 4: 17322, 5: 16935, 6: 0, 7: 0, 8: 0, 9: 0}, 6: {0: 9472, 1: 12148, 2: 17669, 3: 14460, 4: 17318, 5: 17115, 6: 0, 7: 0, 8: 0, 9: 0}, 7: {0: 752, 1: 676, 2: 4577, 3: 10334, 4: 7679, 5: 7891, 6: 0, 7: 0, 8: 0, 9: 0}, 8: {0: 24269, 1: 24959, 2: 24373, 3: 23260, 4: 19009, 5: 14409, 6: 0, 7: 0, 8: 0, 9: 0}, 9: {0: 1988, 1: 54, 2: 807, 3: 2240, 4: 6313, 5: 10844, 6: 0, 7: 0, 8: 0, 9: 0}}
Averaged stats: Lr: 0.001875  Loss: 0.1561  Acc@1: 87.5000 (88.5200)  Acc@5: 100.0000 (99.3000)
Test: [Task 1]  [ 0/63]  eta: 0:00:29  Loss: 0.7042 (0.7042)  Acc@1: 81.2500 (81.2500)  Acc@5: 100.0000 (100.0000)  time: 0.4755  data: 0.2657  max mem: 2356
Test: [Task 1]  [10/63]  eta: 0:00:12  Loss: 0.6811 (0.6403)  Acc@1: 81.2500 (81.8182)  Acc@5: 100.0000 (98.8636)  time: 0.2333  data: 0.0253  max mem: 2356
Test: [Task 1]  [20/63]  eta: 0:00:09  Loss: 0.6811 (0.6939)  Acc@1: 81.2500 (81.2500)  Acc@5: 100.0000 (98.2143)  time: 0.2073  data: 0.0008  max mem: 2356
Test: [Task 1]  [30/63]  eta: 0:00:07  Loss: 0.5166 (0.6474)  Acc@1: 87.5000 (83.6694)  Acc@5: 100.0000 (98.5887)  time: 0.2059  data: 0.0008  max mem: 2356
Test: [Task 1]  [40/63]  eta: 0:00:04  Loss: 0.4991 (0.6311)  Acc@1: 87.5000 (84.2988)  Acc@5: 100.0000 (98.7805)  time: 0.2050  data: 0.0007  max mem: 2356
Test: [Task 1]  [50/63]  eta: 0:00:02  Loss: 0.4991 (0.6008)  Acc@1: 87.5000 (85.5392)  Acc@5: 100.0000 (98.7745)  time: 0.2053  data: 0.0005  max mem: 2356
Test: [Task 1]  [60/63]  eta: 0:00:00  Loss: 0.4946 (0.5872)  Acc@1: 87.5000 (86.1680)  Acc@5: 100.0000 (98.7705)  time: 0.2057  data: 0.0005  max mem: 2356
Test: [Task 1]  [62/63]  eta: 0:00:00  Loss: 0.4893 (0.5854)  Acc@1: 87.5000 (86.4000)  Acc@5: 100.0000 (98.8000)  time: 0.2004  data: 0.0003  max mem: 2356
Test: [Task 1] Total time: 0:00:13 (0.2096 s / it)
* Acc@1 86.400 Acc@5 98.800 loss 0.585
Test: [Task 2]  [ 0/63]  eta: 0:00:33  Loss: 0.9188 (0.9188)  Acc@1: 68.7500 (68.7500)  Acc@5: 93.7500 (93.7500)  time: 0.5392  data: 0.3340  max mem: 2356
Test: [Task 2]  [10/63]  eta: 0:00:12  Loss: 0.7911 (0.7997)  Acc@1: 81.2500 (82.3864)  Acc@5: 100.0000 (96.5909)  time: 0.2360  data: 0.0309  max mem: 2356
Test: [Task 2]  [20/63]  eta: 0:00:09  Loss: 0.7972 (0.8544)  Acc@1: 81.2500 (80.9524)  Acc@5: 100.0000 (96.4286)  time: 0.2058  data: 0.0010  max mem: 2356
Test: [Task 2]  [30/63]  eta: 0:00:07  Loss: 0.7816 (0.8382)  Acc@1: 81.2500 (80.8468)  Acc@5: 93.7500 (95.9677)  time: 0.2054  data: 0.0008  max mem: 2356
Test: [Task 2]  [40/63]  eta: 0:00:04  Loss: 0.6126 (0.8000)  Acc@1: 81.2500 (81.5549)  Acc@5: 100.0000 (96.3415)  time: 0.2053  data: 0.0003  max mem: 2356
Test: [Task 2]  [50/63]  eta: 0:00:02  Loss: 0.6126 (0.7871)  Acc@1: 81.2500 (81.3725)  Acc@5: 100.0000 (96.5686)  time: 0.2059  data: 0.0003  max mem: 2356
Test: [Task 2]  [60/63]  eta: 0:00:00  Loss: 0.6628 (0.7641)  Acc@1: 81.2500 (82.3770)  Acc@5: 100.0000 (97.0287)  time: 0.2053  data: 0.0003  max mem: 2356
Test: [Task 2]  [62/63]  eta: 0:00:00  Loss: 0.6131 (0.7550)  Acc@1: 87.5000 (82.5000)  Acc@5: 100.0000 (97.1000)  time: 0.2028  data: 0.0003  max mem: 2356
Test: [Task 2] Total time: 0:00:13 (0.2109 s / it)
* Acc@1 82.500 Acc@5 97.100 loss 0.755
Test: [Task 3]  [ 0/63]  eta: 0:00:27  Loss: 0.4286 (0.4286)  Acc@1: 93.7500 (93.7500)  Acc@5: 100.0000 (100.0000)  time: 0.4306  data: 0.2203  max mem: 2356
Test: [Task 3]  [10/63]  eta: 0:00:12  Loss: 0.6674 (0.6620)  Acc@1: 87.5000 (85.2273)  Acc@5: 93.7500 (96.5909)  time: 0.2288  data: 0.0224  max mem: 2356
Test: [Task 3]  [20/63]  eta: 0:00:09  Loss: 0.6910 (0.6541)  Acc@1: 81.2500 (85.4167)  Acc@5: 93.7500 (97.0238)  time: 0.2073  data: 0.0014  max mem: 2356
Test: [Task 3]  [30/63]  eta: 0:00:07  Loss: 0.7478 (0.6625)  Acc@1: 81.2500 (84.0726)  Acc@5: 100.0000 (97.3790)  time: 0.2072  data: 0.0005  max mem: 2356
Test: [Task 3]  [40/63]  eta: 0:00:04  Loss: 0.7231 (0.6693)  Acc@1: 81.2500 (83.8415)  Acc@5: 100.0000 (97.5610)  time: 0.2078  data: 0.0005  max mem: 2356
Test: [Task 3]  [50/63]  eta: 0:00:02  Loss: 0.6486 (0.6688)  Acc@1: 81.2500 (84.1912)  Acc@5: 100.0000 (97.4265)  time: 0.2123  data: 0.0015  max mem: 2356
Test: [Task 3]  [60/63]  eta: 0:00:00  Loss: 0.7017 (0.6802)  Acc@1: 81.2500 (83.9139)  Acc@5: 100.0000 (97.6434)  time: 0.2159  data: 0.0014  max mem: 2356
Test: [Task 3]  [62/63]  eta: 0:00:00  Loss: 0.7208 (0.6918)  Acc@1: 81.2500 (83.5000)  Acc@5: 100.0000 (97.5000)  time: 0.2107  data: 0.0011  max mem: 2356
Test: [Task 3] Total time: 0:00:13 (0.2135 s / it)
* Acc@1 83.500 Acc@5 97.500 loss 0.692
Test: [Task 4]  [ 0/63]  eta: 0:00:29  Loss: 0.8061 (0.8061)  Acc@1: 81.2500 (81.2500)  Acc@5: 93.7500 (93.7500)  time: 0.4755  data: 0.2489  max mem: 2356
Test: [Task 4]  [10/63]  eta: 0:00:12  Loss: 0.6354 (0.6135)  Acc@1: 81.2500 (82.9545)  Acc@5: 100.0000 (97.7273)  time: 0.2310  data: 0.0234  max mem: 2356
Test: [Task 4]  [20/63]  eta: 0:00:09  Loss: 0.5428 (0.6156)  Acc@1: 81.2500 (82.7381)  Acc@5: 100.0000 (97.3214)  time: 0.2092  data: 0.0012  max mem: 2356
Test: [Task 4]  [30/63]  eta: 0:00:07  Loss: 0.4926 (0.5762)  Acc@1: 87.5000 (84.6774)  Acc@5: 100.0000 (97.7823)  time: 0.2108  data: 0.0015  max mem: 2356
Test: [Task 4]  [40/63]  eta: 0:00:04  Loss: 0.3680 (0.5245)  Acc@1: 87.5000 (86.7378)  Acc@5: 100.0000 (98.1707)  time: 0.2106  data: 0.0022  max mem: 2356
Test: [Task 4]  [50/63]  eta: 0:00:02  Loss: 0.4888 (0.5563)  Acc@1: 87.5000 (86.0294)  Acc@5: 100.0000 (97.9167)  time: 0.2107  data: 0.0020  max mem: 2356
Test: [Task 4]  [60/63]  eta: 0:00:00  Loss: 0.5642 (0.5732)  Acc@1: 81.2500 (85.7582)  Acc@5: 100.0000 (97.6434)  time: 0.2098  data: 0.0007  max mem: 2356
Test: [Task 4]  [62/63]  eta: 0:00:00  Loss: 0.5290 (0.5676)  Acc@1: 87.5000 (85.9000)  Acc@5: 100.0000 (97.7000)  time: 0.2042  data: 0.0006  max mem: 2356
Test: [Task 4] Total time: 0:00:13 (0.2138 s / it)
* Acc@1 85.900 Acc@5 97.700 loss 0.568
Test: [Task 5]  [ 0/63]  eta: 0:00:40  Loss: 0.1470 (0.1470)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)  time: 0.6494  data: 0.4443  max mem: 2356
Test: [Task 5]  [10/63]  eta: 0:00:13  Loss: 0.3628 (0.5119)  Acc@1: 93.7500 (92.0455)  Acc@5: 100.0000 (98.2955)  time: 0.2463  data: 0.0407  max mem: 2356
Test: [Task 5]  [20/63]  eta: 0:00:09  Loss: 0.3628 (0.4682)  Acc@1: 93.7500 (93.4524)  Acc@5: 100.0000 (98.5119)  time: 0.2069  data: 0.0006  max mem: 2356
Test: [Task 5]  [30/63]  eta: 0:00:07  Loss: 0.4437 (0.4781)  Acc@1: 93.7500 (92.3387)  Acc@5: 100.0000 (98.5887)  time: 0.2101  data: 0.0012  max mem: 2356
Test: [Task 5]  [40/63]  eta: 0:00:05  Loss: 0.4436 (0.4749)  Acc@1: 93.7500 (92.3780)  Acc@5: 100.0000 (98.4756)  time: 0.2111  data: 0.0025  max mem: 2356
Test: [Task 5]  [50/63]  eta: 0:00:02  Loss: 0.4516 (0.4910)  Acc@1: 93.7500 (92.5245)  Acc@5: 100.0000 (98.2843)  time: 0.2117  data: 0.0038  max mem: 2356
Test: [Task 5]  [60/63]  eta: 0:00:00  Loss: 0.4839 (0.5026)  Acc@1: 93.7500 (91.5984)  Acc@5: 100.0000 (98.3607)  time: 0.2099  data: 0.0023  max mem: 2356
Test: [Task 5]  [62/63]  eta: 0:00:00  Loss: 0.5763 (0.5215)  Acc@1: 87.5000 (91.1000)  Acc@5: 100.0000 (98.3000)  time: 0.2055  data: 0.0023  max mem: 2356
Test: [Task 5] Total time: 0:00:13 (0.2164 s / it)
* Acc@1 91.100 Acc@5 98.300 loss 0.521
Test: [Task 6]  [ 0/63]  eta: 0:00:41  Loss: 0.5002 (0.5002)  Acc@1: 75.0000 (75.0000)  Acc@5: 100.0000 (100.0000)  time: 0.6560  data: 0.4413  max mem: 2356
Test: [Task 6]  [10/63]  eta: 0:00:13  Loss: 0.5887 (0.5852)  Acc@1: 81.2500 (80.6818)  Acc@5: 100.0000 (99.4318)  time: 0.2540  data: 0.0405  max mem: 2356
Test: [Task 6]  [20/63]  eta: 0:00:10  Loss: 0.5887 (0.6303)  Acc@1: 81.2500 (80.0595)  Acc@5: 100.0000 (98.2143)  time: 0.2120  data: 0.0006  max mem: 2356
Test: [Task 6]  [30/63]  eta: 0:00:07  Loss: 0.5359 (0.6129)  Acc@1: 81.2500 (80.6452)  Acc@5: 100.0000 (98.7903)  time: 0.2109  data: 0.0010  max mem: 2356
Test: [Task 6]  [40/63]  eta: 0:00:05  Loss: 0.5687 (0.6359)  Acc@1: 81.2500 (79.4207)  Acc@5: 100.0000 (98.7805)  time: 0.2110  data: 0.0011  max mem: 2356
Test: [Task 6]  [50/63]  eta: 0:00:02  Loss: 0.6472 (0.6241)  Acc@1: 81.2500 (80.1471)  Acc@5: 100.0000 (98.8971)  time: 0.2082  data: 0.0010  max mem: 2356
Test: [Task 6]  [60/63]  eta: 0:00:00  Loss: 0.5985 (0.6385)  Acc@1: 81.2500 (80.2254)  Acc@5: 100.0000 (98.6680)  time: 0.2076  data: 0.0019  max mem: 2356
Test: [Task 6]  [62/63]  eta: 0:00:00  Loss: 0.5649 (0.6353)  Acc@1: 81.2500 (80.4000)  Acc@5: 100.0000 (98.7000)  time: 0.2026  data: 0.0019  max mem: 2356
Test: [Task 6] Total time: 0:00:13 (0.2166 s / it)
* Acc@1 80.400 Acc@5 98.700 loss 0.635
{0: {0: 224, 1: 772, 2: 228, 3: 783, 4: 217, 5: 768, 6: 780, 7: 221, 8: 372, 9: 635}, 1: {0: 530, 1: 468, 2: 532, 3: 470, 4: 530, 5: 466, 6: 469, 7: 531, 8: 534, 9: 470}, 2: {0: 261, 1: 733, 2: 267, 3: 741, 4: 259, 5: 721, 6: 740, 7: 261, 8: 198, 9: 819}, 3: {0: 429, 1: 562, 2: 436, 3: 569, 4: 431, 5: 560, 6: 570, 7: 435, 8: 408, 9: 600}, 4: {0: 490, 1: 500, 2: 500, 3: 515, 4: 485, 5: 496, 6: 510, 7: 497, 8: 453, 9: 554}, 5: {0: 453, 1: 540, 2: 460, 3: 548, 4: 451, 5: 544, 6: 548, 7: 454, 8: 664, 9: 338}}
[Average accuracy till task6]	Acc@1: 84.9667	Acc@5: 98.0167	Loss: 0.6261	Forgetting: 6.9400	Backward: -6.9400
Train: Epoch[1/5]  [  0/313]  eta: 0:03:53  Lr: 0.001875  Loss: 2.0968  Acc@1: 0.0000 (0.0000)  Acc@5: 37.5000 (37.5000)  time: 0.7459  data: 0.3334  max mem: 2356
Train: Epoch[1/5]  [ 10/313]  eta: 0:01:55  Lr: 0.001875  Loss: 1.8128  Acc@1: 56.2500 (48.2955)  Acc@5: 81.2500 (81.2500)  time: 0.3810  data: 0.0324  max mem: 2356
Train: Epoch[1/5]  [ 20/313]  eta: 0:01:46  Lr: 0.001875  Loss: 1.4049  Acc@1: 68.7500 (61.0119)  Acc@5: 93.7500 (88.0952)  time: 0.3436  data: 0.0028  max mem: 2356
Train: Epoch[1/5]  [ 30/313]  eta: 0:01:40  Lr: 0.001875  Loss: 1.1329  Acc@1: 75.0000 (66.5323)  Acc@5: 93.7500 (90.5242)  time: 0.3415  data: 0.0021  max mem: 2356
Train: Epoch[1/5]  [ 40/313]  eta: 0:01:35  Lr: 0.001875  Loss: 0.9074  Acc@1: 81.2500 (70.5793)  Acc@5: 100.0000 (92.5305)  time: 0.3373  data: 0.0011  max mem: 2356
Train: Epoch[1/5]  [ 50/313]  eta: 0:01:31  Lr: 0.001875  Loss: 0.9805  Acc@1: 81.2500 (72.6716)  Acc@5: 100.0000 (93.6275)  time: 0.3337  data: 0.0009  max mem: 2356
Train: Epoch[1/5]  [ 60/313]  eta: 0:01:27  Lr: 0.001875  Loss: 0.5718  Acc@1: 81.2500 (73.9754)  Acc@5: 100.0000 (94.3648)  time: 0.3344  data: 0.0005  max mem: 2356
Train: Epoch[1/5]  [ 70/313]  eta: 0:01:23  Lr: 0.001875  Loss: 0.7288  Acc@1: 81.2500 (75.2641)  Acc@5: 100.0000 (94.7183)  time: 0.3339  data: 0.0005  max mem: 2356
Train: Epoch[1/5]  [ 80/313]  eta: 0:01:19  Lr: 0.001875  Loss: 0.7019  Acc@1: 81.2500 (76.0031)  Acc@5: 100.0000 (94.9846)  time: 0.3331  data: 0.0004  max mem: 2356
Train: Epoch[1/5]  [ 90/313]  eta: 0:01:16  Lr: 0.001875  Loss: 0.4994  Acc@1: 81.2500 (77.0604)  Acc@5: 100.0000 (95.1923)  time: 0.3344  data: 0.0004  max mem: 2356
Train: Epoch[1/5]  [100/313]  eta: 0:01:12  Lr: 0.001875  Loss: 0.8683  Acc@1: 87.5000 (77.9703)  Acc@5: 100.0000 (95.4827)  time: 0.3357  data: 0.0012  max mem: 2356
Train: Epoch[1/5]  [110/313]  eta: 0:01:09  Lr: 0.001875  Loss: 0.2403  Acc@1: 87.5000 (78.8851)  Acc@5: 100.0000 (95.8896)  time: 0.3352  data: 0.0011  max mem: 2356
Train: Epoch[1/5]  [120/313]  eta: 0:01:05  Lr: 0.001875  Loss: 0.4815  Acc@1: 87.5000 (79.4421)  Acc@5: 100.0000 (96.0744)  time: 0.3348  data: 0.0004  max mem: 2356
Train: Epoch[1/5]  [130/313]  eta: 0:01:02  Lr: 0.001875  Loss: 0.3567  Acc@1: 87.5000 (79.8664)  Acc@5: 100.0000 (96.2786)  time: 0.3350  data: 0.0004  max mem: 2356
Train: Epoch[1/5]  [140/313]  eta: 0:00:58  Lr: 0.001875  Loss: 0.5156  Acc@1: 87.5000 (80.3635)  Acc@5: 100.0000 (96.4096)  time: 0.3330  data: 0.0004  max mem: 2356
Train: Epoch[1/5]  [150/313]  eta: 0:00:55  Lr: 0.001875  Loss: 0.0907  Acc@1: 87.5000 (80.6705)  Acc@5: 100.0000 (96.6060)  time: 0.3335  data: 0.0007  max mem: 2356
Train: Epoch[1/5]  [160/313]  eta: 0:00:51  Lr: 0.001875  Loss: 0.2469  Acc@1: 87.5000 (80.8618)  Acc@5: 100.0000 (96.7391)  time: 0.3350  data: 0.0008  max mem: 2356
Train: Epoch[1/5]  [170/313]  eta: 0:00:48  Lr: 0.001875  Loss: 0.2937  Acc@1: 87.5000 (81.3596)  Acc@5: 100.0000 (96.8933)  time: 0.3333  data: 0.0004  max mem: 2356
Train: Epoch[1/5]  [180/313]  eta: 0:00:44  Lr: 0.001875  Loss: -0.0402  Acc@1: 87.5000 (81.6989)  Acc@5: 100.0000 (96.9959)  time: 0.3316  data: 0.0003  max mem: 2356
Train: Epoch[1/5]  [190/313]  eta: 0:00:41  Lr: 0.001875  Loss: 0.0847  Acc@1: 87.5000 (82.0681)  Acc@5: 100.0000 (97.1204)  time: 0.3313  data: 0.0004  max mem: 2356
Train: Epoch[1/5]  [200/313]  eta: 0:00:38  Lr: 0.001875  Loss: 0.5624  Acc@1: 81.2500 (82.0896)  Acc@5: 100.0000 (97.2015)  time: 0.3324  data: 0.0011  max mem: 2356
Train: Epoch[1/5]  [210/313]  eta: 0:00:34  Lr: 0.001875  Loss: 0.2044  Acc@1: 81.2500 (82.1979)  Acc@5: 100.0000 (97.2156)  time: 0.3343  data: 0.0013  max mem: 2356
Train: Epoch[1/5]  [220/313]  eta: 0:00:31  Lr: 0.001875  Loss: 0.1406  Acc@1: 81.2500 (82.2398)  Acc@5: 100.0000 (97.2851)  time: 0.3362  data: 0.0008  max mem: 2356
Train: Epoch[1/5]  [230/313]  eta: 0:00:27  Lr: 0.001875  Loss: 0.2259  Acc@1: 87.5000 (82.4946)  Acc@5: 100.0000 (97.2944)  time: 0.3376  data: 0.0007  max mem: 2356
Train: Epoch[1/5]  [240/313]  eta: 0:00:24  Lr: 0.001875  Loss: 0.5350  Acc@1: 87.5000 (82.6245)  Acc@5: 100.0000 (97.1992)  time: 0.3382  data: 0.0008  max mem: 2356
Train: Epoch[1/5]  [250/313]  eta: 0:00:21  Lr: 0.001875  Loss: 0.1336  Acc@1: 87.5000 (82.7440)  Acc@5: 100.0000 (97.2859)  time: 0.3395  data: 0.0022  max mem: 2356
Train: Epoch[1/5]  [260/313]  eta: 0:00:17  Lr: 0.001875  Loss: 0.1713  Acc@1: 87.5000 (82.8305)  Acc@5: 100.0000 (97.3659)  time: 0.3392  data: 0.0029  max mem: 2356
Train: Epoch[1/5]  [270/313]  eta: 0:00:14  Lr: 0.001875  Loss: 0.8558  Acc@1: 87.5000 (82.9336)  Acc@5: 100.0000 (97.3939)  time: 0.3375  data: 0.0028  max mem: 2356
Train: Epoch[1/5]  [280/313]  eta: 0:00:11  Lr: 0.001875  Loss: 0.2775  Acc@1: 87.5000 (82.9849)  Acc@5: 100.0000 (97.4422)  time: 0.3389  data: 0.0021  max mem: 2356
Train: Epoch[1/5]  [290/313]  eta: 0:00:07  Lr: 0.001875  Loss: 0.4337  Acc@1: 81.2500 (82.9467)  Acc@5: 100.0000 (97.4227)  time: 0.3420  data: 0.0014  max mem: 2356
Train: Epoch[1/5]  [300/313]  eta: 0:00:04  Lr: 0.001875  Loss: 0.2561  Acc@1: 87.5000 (83.0565)  Acc@5: 100.0000 (97.3837)  time: 0.3430  data: 0.0022  max mem: 2356
Train: Epoch[1/5]  [310/313]  eta: 0:00:01  Lr: 0.001875  Loss: 0.2920  Acc@1: 87.5000 (83.1391)  Acc@5: 100.0000 (97.4277)  time: 0.3408  data: 0.0015  max mem: 2356
Train: Epoch[1/5]  [312/313]  eta: 0:00:00  Lr: 0.001875  Loss: 0.2508  Acc@1: 87.5000 (83.1400)  Acc@5: 100.0000 (97.4400)  time: 0.3339  data: 0.0015  max mem: 2356
Train: Epoch[1/5] Total time: 0:01:45 (0.3382 s / it)
{0: {0: 22412, 1: 24815, 2: 19998, 3: 12102, 4: 7737, 5: 7897, 6: 1248, 7: 0, 8: 0, 9: 0}, 1: {0: 1577, 1: 208, 2: 5200, 3: 12775, 4: 17024, 5: 16965, 6: 3735, 7: 0, 8: 0, 9: 0}, 2: {0: 3518, 1: 6779, 2: 5327, 3: 9830, 4: 7541, 5: 7967, 6: 1234, 7: 0, 8: 0, 9: 0}, 3: {0: 21486, 1: 20777, 2: 18903, 3: 14840, 4: 17372, 5: 17103, 6: 3784, 7: 0, 8: 0, 9: 0}, 4: {0: 16124, 1: 10227, 2: 6432, 3: 10102, 4: 7685, 5: 7874, 6: 1241, 7: 0, 8: 0, 9: 0}, 5: {0: 23402, 1: 24357, 2: 21714, 3: 15057, 4: 17322, 5: 16935, 6: 3780, 7: 0, 8: 0, 9: 0}, 6: {0: 9472, 1: 12148, 2: 17669, 3: 14460, 4: 17318, 5: 17115, 6: 3755, 7: 0, 8: 0, 9: 0}, 7: {0: 752, 1: 676, 2: 4577, 3: 10334, 4: 7679, 5: 7891, 6: 1207, 7: 0, 8: 0, 9: 0}, 8: {0: 24269, 1: 24959, 2: 24373, 3: 23260, 4: 19009, 5: 14409, 6: 1270, 7: 0, 8: 0, 9: 0}, 9: {0: 1988, 1: 54, 2: 807, 3: 2240, 4: 6313, 5: 10844, 6: 3746, 7: 0, 8: 0, 9: 0}}
Averaged stats: Lr: 0.001875  Loss: 0.2508  Acc@1: 87.5000 (83.1400)  Acc@5: 100.0000 (97.4400)
Train: Epoch[2/5]  [  0/313]  eta: 0:03:03  Lr: 0.001875  Loss: 0.0829  Acc@1: 93.7500 (93.7500)  Acc@5: 100.0000 (100.0000)  time: 0.5869  data: 0.2423  max mem: 2356
Train: Epoch[2/5]  [ 10/313]  eta: 0:01:50  Lr: 0.001875  Loss: 0.0141  Acc@1: 81.2500 (83.5227)  Acc@5: 100.0000 (98.8636)  time: 0.3642  data: 0.0226  max mem: 2356
Train: Epoch[2/5]  [ 20/313]  eta: 0:01:43  Lr: 0.001875  Loss: 0.0573  Acc@1: 81.2500 (82.4405)  Acc@5: 100.0000 (98.2143)  time: 0.3419  data: 0.0014  max mem: 2356
Train: Epoch[2/5]  [ 30/313]  eta: 0:01:38  Lr: 0.001875  Loss: -0.0658  Acc@1: 81.2500 (84.2742)  Acc@5: 100.0000 (98.1855)  time: 0.3394  data: 0.0013  max mem: 2356
Train: Epoch[2/5]  [ 40/313]  eta: 0:01:34  Lr: 0.001875  Loss: 0.0380  Acc@1: 87.5000 (84.7561)  Acc@5: 100.0000 (98.0183)  time: 0.3414  data: 0.0019  max mem: 2356
Train: Epoch[2/5]  [ 50/313]  eta: 0:01:30  Lr: 0.001875  Loss: 0.0226  Acc@1: 87.5000 (84.9265)  Acc@5: 100.0000 (98.2843)  time: 0.3424  data: 0.0018  max mem: 2356
Train: Epoch[2/5]  [ 60/313]  eta: 0:01:27  Lr: 0.001875  Loss: 0.1552  Acc@1: 87.5000 (84.9385)  Acc@5: 100.0000 (98.4631)  time: 0.3456  data: 0.0007  max mem: 2356
Train: Epoch[2/5]  [ 70/313]  eta: 0:01:23  Lr: 0.001875  Loss: 0.6709  Acc@1: 87.5000 (85.1232)  Acc@5: 100.0000 (98.5035)  time: 0.3440  data: 0.0009  max mem: 2356
Train: Epoch[2/5]  [ 80/313]  eta: 0:01:20  Lr: 0.001875  Loss: -0.0281  Acc@1: 87.5000 (85.2623)  Acc@5: 100.0000 (98.4568)  time: 0.3351  data: 0.0006  max mem: 2356
Train: Epoch[2/5]  [ 90/313]  eta: 0:01:16  Lr: 0.001875  Loss: -0.0821  Acc@1: 87.5000 (85.2335)  Acc@5: 100.0000 (98.3516)  time: 0.3339  data: 0.0005  max mem: 2356
Train: Epoch[2/5]  [100/313]  eta: 0:01:12  Lr: 0.001875  Loss: 0.1301  Acc@1: 87.5000 (85.6436)  Acc@5: 100.0000 (98.3911)  time: 0.3343  data: 0.0005  max mem: 2356
Train: Epoch[2/5]  [110/313]  eta: 0:01:09  Lr: 0.001875  Loss: 0.1052  Acc@1: 87.5000 (85.7545)  Acc@5: 100.0000 (98.5360)  time: 0.3344  data: 0.0005  max mem: 2356
Train: Epoch[2/5]  [120/313]  eta: 0:01:05  Lr: 0.001875  Loss: 0.2179  Acc@1: 87.5000 (85.9504)  Acc@5: 100.0000 (98.5537)  time: 0.3346  data: 0.0012  max mem: 2356
Train: Epoch[2/5]  [130/313]  eta: 0:01:02  Lr: 0.001875  Loss: -0.1481  Acc@1: 87.5000 (86.0687)  Acc@5: 100.0000 (98.6164)  time: 0.3354  data: 0.0021  max mem: 2356
Train: Epoch[2/5]  [140/313]  eta: 0:00:58  Lr: 0.001875  Loss: 0.3305  Acc@1: 87.5000 (86.0372)  Acc@5: 100.0000 (98.6702)  time: 0.3344  data: 0.0013  max mem: 2356
Train: Epoch[2/5]  [150/313]  eta: 0:00:55  Lr: 0.001875  Loss: 0.2198  Acc@1: 81.2500 (86.0099)  Acc@5: 100.0000 (98.7583)  time: 0.3342  data: 0.0003  max mem: 2356
Train: Epoch[2/5]  [160/313]  eta: 0:00:51  Lr: 0.001875  Loss: 0.1497  Acc@1: 87.5000 (86.2189)  Acc@5: 100.0000 (98.7966)  time: 0.3345  data: 0.0004  max mem: 2356
Train: Epoch[2/5]  [170/313]  eta: 0:00:48  Lr: 0.001875  Loss: -0.1196  Acc@1: 87.5000 (86.4766)  Acc@5: 100.0000 (98.7939)  time: 0.3355  data: 0.0015  max mem: 2356
Train: Epoch[2/5]  [180/313]  eta: 0:00:45  Lr: 0.001875  Loss: 0.0410  Acc@1: 87.5000 (86.5331)  Acc@5: 100.0000 (98.8260)  time: 0.3340  data: 0.0015  max mem: 2356
Train: Epoch[2/5]  [190/313]  eta: 0:00:41  Lr: 0.001875  Loss: -0.1209  Acc@1: 87.5000 (86.8128)  Acc@5: 100.0000 (98.8547)  time: 0.3317  data: 0.0003  max mem: 2356
Train: Epoch[2/5]  [200/313]  eta: 0:00:38  Lr: 0.001875  Loss: 0.0511  Acc@1: 87.5000 (86.8159)  Acc@5: 100.0000 (98.8184)  time: 0.3322  data: 0.0007  max mem: 2356
Train: Epoch[2/5]  [210/313]  eta: 0:00:34  Lr: 0.001875  Loss: 0.2841  Acc@1: 87.5000 (86.9076)  Acc@5: 100.0000 (98.7855)  time: 0.3343  data: 0.0007  max mem: 2356
Train: Epoch[2/5]  [220/313]  eta: 0:00:31  Lr: 0.001875  Loss: 0.2038  Acc@1: 87.5000 (86.8778)  Acc@5: 100.0000 (98.8122)  time: 0.3348  data: 0.0003  max mem: 2356
Train: Epoch[2/5]  [230/313]  eta: 0:00:28  Lr: 0.001875  Loss: 0.0755  Acc@1: 87.5000 (86.9048)  Acc@5: 100.0000 (98.7825)  time: 0.3327  data: 0.0004  max mem: 2356
Train: Epoch[2/5]  [240/313]  eta: 0:00:24  Lr: 0.001875  Loss: 1.0237  Acc@1: 87.5000 (86.8776)  Acc@5: 100.0000 (98.7552)  time: 0.3323  data: 0.0005  max mem: 2356
Train: Epoch[2/5]  [250/313]  eta: 0:00:21  Lr: 0.001875  Loss: 0.1360  Acc@1: 87.5000 (86.9273)  Acc@5: 100.0000 (98.7799)  time: 0.3324  data: 0.0004  max mem: 2356
Train: Epoch[2/5]  [260/313]  eta: 0:00:17  Lr: 0.001875  Loss: 0.0197  Acc@1: 87.5000 (87.0929)  Acc@5: 100.0000 (98.7548)  time: 0.3331  data: 0.0003  max mem: 2356
Train: Epoch[2/5]  [270/313]  eta: 0:00:14  Lr: 0.001875  Loss: 0.1197  Acc@1: 93.7500 (87.1771)  Acc@5: 100.0000 (98.8007)  time: 0.3371  data: 0.0005  max mem: 2356
Train: Epoch[2/5]  [280/313]  eta: 0:00:11  Lr: 0.001875  Loss: 0.0917  Acc@1: 87.5000 (87.1886)  Acc@5: 100.0000 (98.7989)  time: 0.3410  data: 0.0006  max mem: 2356
Train: Epoch[2/5]  [290/313]  eta: 0:00:07  Lr: 0.001875  Loss: 0.0188  Acc@1: 87.5000 (87.2208)  Acc@5: 100.0000 (98.7113)  time: 0.3417  data: 0.0006  max mem: 2356
Train: Epoch[2/5]  [300/313]  eta: 0:00:04  Lr: 0.001875  Loss: 0.0976  Acc@1: 87.5000 (87.1055)  Acc@5: 100.0000 (98.7334)  time: 0.3405  data: 0.0005  max mem: 2356
Train: Epoch[2/5]  [310/313]  eta: 0:00:01  Lr: 0.001875  Loss: 0.3081  Acc@1: 87.5000 (87.0981)  Acc@5: 100.0000 (98.7339)  time: 0.3388  data: 0.0006  max mem: 2356
Train: Epoch[2/5]  [312/313]  eta: 0:00:00  Lr: 0.001875  Loss: -0.0518  Acc@1: 87.5000 (87.1400)  Acc@5: 100.0000 (98.7400)  time: 0.3308  data: 0.0006  max mem: 2356
Train: Epoch[2/5] Total time: 0:01:45 (0.3373 s / it)
{0: {0: 22412, 1: 24815, 2: 19998, 3: 12102, 4: 7737, 5: 7897, 6: 2699, 7: 0, 8: 0, 9: 0}, 1: {0: 1577, 1: 208, 2: 5200, 3: 12775, 4: 17024, 5: 16965, 6: 7278, 7: 0, 8: 0, 9: 0}, 2: {0: 3518, 1: 6779, 2: 5327, 3: 9830, 4: 7541, 5: 7967, 6: 2677, 7: 0, 8: 0, 9: 0}, 3: {0: 21486, 1: 20777, 2: 18903, 3: 14840, 4: 17372, 5: 17103, 6: 7381, 7: 0, 8: 0, 9: 0}, 4: {0: 16124, 1: 10227, 2: 6432, 3: 10102, 4: 7685, 5: 7874, 6: 2676, 7: 0, 8: 0, 9: 0}, 5: {0: 23402, 1: 24357, 2: 21714, 3: 15057, 4: 17322, 5: 16935, 6: 7338, 7: 0, 8: 0, 9: 0}, 6: {0: 9472, 1: 12148, 2: 17669, 3: 14460, 4: 17318, 5: 17115, 6: 7313, 7: 0, 8: 0, 9: 0}, 7: {0: 752, 1: 676, 2: 4577, 3: 10334, 4: 7679, 5: 7891, 6: 2608, 7: 0, 8: 0, 9: 0}, 8: {0: 24269, 1: 24959, 2: 24373, 3: 23260, 4: 19009, 5: 14409, 6: 2708, 7: 0, 8: 0, 9: 0}, 9: {0: 1988, 1: 54, 2: 807, 3: 2240, 4: 6313, 5: 10844, 6: 7322, 7: 0, 8: 0, 9: 0}}
Averaged stats: Lr: 0.001875  Loss: -0.0518  Acc@1: 87.5000 (87.1400)  Acc@5: 100.0000 (98.7400)
Train: Epoch[3/5]  [  0/313]  eta: 0:04:07  Lr: 0.001875  Loss: 0.0110  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (100.0000)  time: 0.7895  data: 0.4510  max mem: 2356
Train: Epoch[3/5]  [ 10/313]  eta: 0:01:55  Lr: 0.001875  Loss: 0.3291  Acc@1: 87.5000 (85.7955)  Acc@5: 100.0000 (100.0000)  time: 0.3817  data: 0.0427  max mem: 2356
Train: Epoch[3/5]  [ 20/313]  eta: 0:01:46  Lr: 0.001875  Loss: 0.1770  Acc@1: 87.5000 (86.9048)  Acc@5: 100.0000 (100.0000)  time: 0.3416  data: 0.0013  max mem: 2356
Train: Epoch[3/5]  [ 30/313]  eta: 0:01:40  Lr: 0.001875  Loss: 0.1563  Acc@1: 87.5000 (87.2984)  Acc@5: 100.0000 (99.7984)  time: 0.3421  data: 0.0006  max mem: 2356
Train: Epoch[3/5]  [ 40/313]  eta: 0:01:36  Lr: 0.001875  Loss: -0.1223  Acc@1: 87.5000 (87.6524)  Acc@5: 100.0000 (98.9329)  time: 0.3430  data: 0.0017  max mem: 2356
Train: Epoch[3/5]  [ 50/313]  eta: 0:01:32  Lr: 0.001875  Loss: 0.2207  Acc@1: 87.5000 (88.3578)  Acc@5: 100.0000 (99.0196)  time: 0.3431  data: 0.0025  max mem: 2356
Train: Epoch[3/5]  [ 60/313]  eta: 0:01:28  Lr: 0.001875  Loss: 0.2966  Acc@1: 87.5000 (88.0123)  Acc@5: 100.0000 (99.1803)  time: 0.3385  data: 0.0015  max mem: 2356
Train: Epoch[3/5]  [ 70/313]  eta: 0:01:24  Lr: 0.001875  Loss: 0.1306  Acc@1: 81.2500 (87.2359)  Acc@5: 100.0000 (99.0317)  time: 0.3362  data: 0.0017  max mem: 2356
Train: Epoch[3/5]  [ 80/313]  eta: 0:01:20  Lr: 0.001875  Loss: -0.1903  Acc@1: 87.5000 (87.6543)  Acc@5: 100.0000 (98.9969)  time: 0.3395  data: 0.0022  max mem: 2356
Train: Epoch[3/5]  [ 90/313]  eta: 0:01:17  Lr: 0.001875  Loss: 0.3424  Acc@1: 93.7500 (87.6374)  Acc@5: 100.0000 (99.0385)  time: 0.3413  data: 0.0031  max mem: 2356
Train: Epoch[3/5]  [100/313]  eta: 0:01:13  Lr: 0.001875  Loss: 0.0641  Acc@1: 93.7500 (87.8094)  Acc@5: 100.0000 (99.0718)  time: 0.3431  data: 0.0025  max mem: 2356
Train: Epoch[3/5]  [110/313]  eta: 0:01:10  Lr: 0.001875  Loss: 0.5667  Acc@1: 87.5000 (87.8378)  Acc@5: 100.0000 (99.0428)  time: 0.3436  data: 0.0033  max mem: 2356
Train: Epoch[3/5]  [120/313]  eta: 0:01:06  Lr: 0.001875  Loss: -0.2185  Acc@1: 87.5000 (87.5517)  Acc@5: 100.0000 (98.9153)  time: 0.3376  data: 0.0032  max mem: 2356
Train: Epoch[3/5]  [130/313]  eta: 0:01:02  Lr: 0.001875  Loss: 0.1788  Acc@1: 81.2500 (87.1660)  Acc@5: 100.0000 (98.9504)  time: 0.3331  data: 0.0004  max mem: 2356
Train: Epoch[3/5]  [140/313]  eta: 0:00:59  Lr: 0.001875  Loss: 0.3066  Acc@1: 81.2500 (87.0567)  Acc@5: 100.0000 (99.0248)  time: 0.3327  data: 0.0004  max mem: 2356
Train: Epoch[3/5]  [150/313]  eta: 0:00:55  Lr: 0.001875  Loss: -0.0276  Acc@1: 87.5000 (86.9205)  Acc@5: 100.0000 (98.9238)  time: 0.3324  data: 0.0004  max mem: 2356
Train: Epoch[3/5]  [160/313]  eta: 0:00:52  Lr: 0.001875  Loss: -0.0330  Acc@1: 87.5000 (86.9953)  Acc@5: 100.0000 (98.9130)  time: 0.3346  data: 0.0004  max mem: 2356
Train: Epoch[3/5]  [170/313]  eta: 0:00:48  Lr: 0.001875  Loss: 0.3020  Acc@1: 87.5000 (87.0980)  Acc@5: 100.0000 (98.9766)  time: 0.3354  data: 0.0010  max mem: 2356
Train: Epoch[3/5]  [180/313]  eta: 0:00:45  Lr: 0.001875  Loss: 0.2590  Acc@1: 87.5000 (87.0856)  Acc@5: 100.0000 (98.9641)  time: 0.3342  data: 0.0010  max mem: 2356
Train: Epoch[3/5]  [190/313]  eta: 0:00:41  Lr: 0.001875  Loss: 0.2002  Acc@1: 87.5000 (87.1401)  Acc@5: 100.0000 (98.9529)  time: 0.3346  data: 0.0004  max mem: 2356
Train: Epoch[3/5]  [200/313]  eta: 0:00:38  Lr: 0.001875  Loss: 0.1846  Acc@1: 81.2500 (86.9714)  Acc@5: 100.0000 (98.9117)  time: 0.3344  data: 0.0011  max mem: 2356
Train: Epoch[3/5]  [210/313]  eta: 0:00:35  Lr: 0.001875  Loss: 0.1651  Acc@1: 87.5000 (87.1742)  Acc@5: 100.0000 (98.9040)  time: 0.3339  data: 0.0012  max mem: 2356
Train: Epoch[3/5]  [220/313]  eta: 0:00:31  Lr: 0.001875  Loss: 0.3146  Acc@1: 87.5000 (86.9910)  Acc@5: 100.0000 (98.8405)  time: 0.3332  data: 0.0010  max mem: 2356
Train: Epoch[3/5]  [230/313]  eta: 0:00:28  Lr: 0.001875  Loss: 0.2803  Acc@1: 87.5000 (87.0130)  Acc@5: 100.0000 (98.8636)  time: 0.3337  data: 0.0010  max mem: 2356
Train: Epoch[3/5]  [240/313]  eta: 0:00:24  Lr: 0.001875  Loss: 0.0243  Acc@1: 87.5000 (87.0073)  Acc@5: 100.0000 (98.8589)  time: 0.3328  data: 0.0004  max mem: 2356
Train: Epoch[3/5]  [250/313]  eta: 0:00:21  Lr: 0.001875  Loss: 0.0007  Acc@1: 87.5000 (87.0767)  Acc@5: 100.0000 (98.9044)  time: 0.3309  data: 0.0003  max mem: 2356
Train: Epoch[3/5]  [260/313]  eta: 0:00:17  Lr: 0.001875  Loss: -0.0352  Acc@1: 87.5000 (87.2126)  Acc@5: 100.0000 (98.9224)  time: 0.3322  data: 0.0003  max mem: 2356
Train: Epoch[3/5]  [270/313]  eta: 0:00:14  Lr: 0.001875  Loss: 0.3772  Acc@1: 87.5000 (87.2002)  Acc@5: 100.0000 (98.9161)  time: 0.3339  data: 0.0010  max mem: 2356
Train: Epoch[3/5]  [280/313]  eta: 0:00:11  Lr: 0.001875  Loss: -0.0700  Acc@1: 87.5000 (87.2998)  Acc@5: 100.0000 (98.9324)  time: 0.3340  data: 0.0010  max mem: 2356
Train: Epoch[3/5]  [290/313]  eta: 0:00:07  Lr: 0.001875  Loss: -0.0526  Acc@1: 93.7500 (87.3926)  Acc@5: 100.0000 (98.9046)  time: 0.3329  data: 0.0004  max mem: 2356
Train: Epoch[3/5]  [300/313]  eta: 0:00:04  Lr: 0.001875  Loss: 0.1016  Acc@1: 87.5000 (87.4169)  Acc@5: 100.0000 (98.8995)  time: 0.3334  data: 0.0004  max mem: 2356
Train: Epoch[3/5]  [310/313]  eta: 0:00:01  Lr: 0.001875  Loss: 0.3446  Acc@1: 87.5000 (87.4196)  Acc@5: 100.0000 (98.9148)  time: 0.3360  data: 0.0004  max mem: 2356
Train: Epoch[3/5]  [312/313]  eta: 0:00:00  Lr: 0.001875  Loss: -0.1176  Acc@1: 93.7500 (87.4600)  Acc@5: 100.0000 (98.9200)  time: 0.3280  data: 0.0004  max mem: 2356
Train: Epoch[3/5] Total time: 0:01:45 (0.3378 s / it)
{0: {0: 22412, 1: 24815, 2: 19998, 3: 12102, 4: 7737, 5: 7897, 6: 4169, 7: 0, 8: 0, 9: 0}, 1: {0: 1577, 1: 208, 2: 5200, 3: 12775, 4: 17024, 5: 16965, 6: 10807, 7: 0, 8: 0, 9: 0}, 2: {0: 3518, 1: 6779, 2: 5327, 3: 9830, 4: 7541, 5: 7967, 6: 4183, 7: 0, 8: 0, 9: 0}, 3: {0: 21486, 1: 20777, 2: 18903, 3: 14840, 4: 17372, 5: 17103, 6: 10939, 7: 0, 8: 0, 9: 0}, 4: {0: 16124, 1: 10227, 2: 6432, 3: 10102, 4: 7685, 5: 7874, 6: 4132, 7: 0, 8: 0, 9: 0}, 5: {0: 23402, 1: 24357, 2: 21714, 3: 15057, 4: 17322, 5: 16935, 6: 10834, 7: 0, 8: 0, 9: 0}, 6: {0: 9472, 1: 12148, 2: 17669, 3: 14460, 4: 17318, 5: 17115, 6: 10849, 7: 0, 8: 0, 9: 0}, 7: {0: 752, 1: 676, 2: 4577, 3: 10334, 4: 7679, 5: 7891, 6: 4054, 7: 0, 8: 0, 9: 0}, 8: {0: 24269, 1: 24959, 2: 24373, 3: 23260, 4: 19009, 5: 14409, 6: 4052, 7: 0, 8: 0, 9: 0}, 9: {0: 1988, 1: 54, 2: 807, 3: 2240, 4: 6313, 5: 10844, 6: 10981, 7: 0, 8: 0, 9: 0}}
Averaged stats: Lr: 0.001875  Loss: -0.1176  Acc@1: 93.7500 (87.4600)  Acc@5: 100.0000 (98.9200)
Train: Epoch[4/5]  [  0/313]  eta: 0:02:55  Lr: 0.001875  Loss: 0.0147  Acc@1: 93.7500 (93.7500)  Acc@5: 100.0000 (100.0000)  time: 0.5606  data: 0.2287  max mem: 2356
Train: Epoch[4/5]  [ 10/313]  eta: 0:01:47  Lr: 0.001875  Loss: 0.0649  Acc@1: 93.7500 (90.9091)  Acc@5: 100.0000 (98.8636)  time: 0.3553  data: 0.0212  max mem: 2356
Train: Epoch[4/5]  [ 20/313]  eta: 0:01:41  Lr: 0.001875  Loss: -0.0147  Acc@1: 93.7500 (89.2857)  Acc@5: 100.0000 (98.8095)  time: 0.3359  data: 0.0016  max mem: 2356
Train: Epoch[4/5]  [ 30/313]  eta: 0:01:37  Lr: 0.001875  Loss: -0.0719  Acc@1: 87.5000 (88.9113)  Acc@5: 100.0000 (98.7903)  time: 0.3383  data: 0.0023  max mem: 2356
Train: Epoch[4/5]  [ 40/313]  eta: 0:01:33  Lr: 0.001875  Loss: 0.3251  Acc@1: 87.5000 (87.1951)  Acc@5: 100.0000 (98.9329)  time: 0.3372  data: 0.0014  max mem: 2356
Train: Epoch[4/5]  [ 50/313]  eta: 0:01:29  Lr: 0.001875  Loss: 0.1510  Acc@1: 87.5000 (87.1324)  Acc@5: 100.0000 (98.4069)  time: 0.3369  data: 0.0014  max mem: 2356
Train: Epoch[4/5]  [ 60/313]  eta: 0:01:26  Lr: 0.001875  Loss: -0.0693  Acc@1: 93.7500 (87.3975)  Acc@5: 100.0000 (98.2582)  time: 0.3386  data: 0.0020  max mem: 2356
Train: Epoch[4/5]  [ 70/313]  eta: 0:01:22  Lr: 0.001875  Loss: -0.1375  Acc@1: 87.5000 (87.7641)  Acc@5: 100.0000 (98.3275)  time: 0.3384  data: 0.0013  max mem: 2356
Train: Epoch[4/5]  [ 80/313]  eta: 0:01:19  Lr: 0.001875  Loss: 0.0213  Acc@1: 93.7500 (88.6574)  Acc@5: 100.0000 (98.3796)  time: 0.3392  data: 0.0032  max mem: 2356
Train: Epoch[4/5]  [ 90/313]  eta: 0:01:15  Lr: 0.001875  Loss: 0.4988  Acc@1: 87.5000 (88.3242)  Acc@5: 100.0000 (98.4890)  time: 0.3402  data: 0.0035  max mem: 2356
Train: Epoch[4/5]  [100/313]  eta: 0:01:12  Lr: 0.001875  Loss: -0.1277  Acc@1: 87.5000 (88.4901)  Acc@5: 100.0000 (98.5767)  time: 0.3399  data: 0.0008  max mem: 2356
Train: Epoch[4/5]  [110/313]  eta: 0:01:09  Lr: 0.001875  Loss: 0.4059  Acc@1: 93.7500 (88.6824)  Acc@5: 100.0000 (98.5923)  time: 0.3379  data: 0.0004  max mem: 2356
Train: Epoch[4/5]  [120/313]  eta: 0:01:05  Lr: 0.001875  Loss: 0.2086  Acc@1: 87.5000 (88.5331)  Acc@5: 100.0000 (98.6054)  time: 0.3355  data: 0.0005  max mem: 2356
Train: Epoch[4/5]  [130/313]  eta: 0:01:02  Lr: 0.001875  Loss: -0.0643  Acc@1: 87.5000 (88.7405)  Acc@5: 100.0000 (98.6641)  time: 0.3381  data: 0.0005  max mem: 2356
Train: Epoch[4/5]  [140/313]  eta: 0:00:58  Lr: 0.001875  Loss: -0.1674  Acc@1: 87.5000 (88.6968)  Acc@5: 100.0000 (98.7589)  time: 0.3395  data: 0.0009  max mem: 2356
Train: Epoch[4/5]  [150/313]  eta: 0:00:55  Lr: 0.001875  Loss: 0.2630  Acc@1: 93.7500 (88.8245)  Acc@5: 100.0000 (98.8411)  time: 0.3391  data: 0.0009  max mem: 2356
Train: Epoch[4/5]  [160/313]  eta: 0:00:51  Lr: 0.001875  Loss: -0.0066  Acc@1: 87.5000 (88.6258)  Acc@5: 100.0000 (98.7966)  time: 0.3420  data: 0.0010  max mem: 2356
Train: Epoch[4/5]  [170/313]  eta: 0:00:48  Lr: 0.001875  Loss: -0.1828  Acc@1: 87.5000 (88.7061)  Acc@5: 100.0000 (98.8670)  time: 0.3394  data: 0.0015  max mem: 2356
Train: Epoch[4/5]  [180/313]  eta: 0:00:45  Lr: 0.001875  Loss: -0.0544  Acc@1: 87.5000 (88.5014)  Acc@5: 100.0000 (98.7914)  time: 0.3373  data: 0.0019  max mem: 2356
Train: Epoch[4/5]  [190/313]  eta: 0:00:41  Lr: 0.001875  Loss: -0.2041  Acc@1: 87.5000 (88.6126)  Acc@5: 100.0000 (98.8220)  time: 0.3406  data: 0.0023  max mem: 2356
Train: Epoch[4/5]  [200/313]  eta: 0:00:38  Lr: 0.001875  Loss: 0.0019  Acc@1: 93.7500 (88.7438)  Acc@5: 100.0000 (98.8495)  time: 0.3381  data: 0.0014  max mem: 2356
Train: Epoch[4/5]  [210/313]  eta: 0:00:34  Lr: 0.001875  Loss: -0.0137  Acc@1: 93.7500 (88.9514)  Acc@5: 100.0000 (98.8744)  time: 0.3333  data: 0.0005  max mem: 2356
Train: Epoch[4/5]  [220/313]  eta: 0:00:31  Lr: 0.001875  Loss: 0.0655  Acc@1: 93.7500 (88.9423)  Acc@5: 100.0000 (98.8405)  time: 0.3331  data: 0.0004  max mem: 2356
Train: Epoch[4/5]  [230/313]  eta: 0:00:28  Lr: 0.001875  Loss: 0.1153  Acc@1: 87.5000 (88.9069)  Acc@5: 100.0000 (98.8366)  time: 0.3333  data: 0.0004  max mem: 2356
Train: Epoch[4/5]  [240/313]  eta: 0:00:24  Lr: 0.001875  Loss: 0.1068  Acc@1: 87.5000 (88.9782)  Acc@5: 100.0000 (98.8589)  time: 0.3352  data: 0.0016  max mem: 2356
Train: Epoch[4/5]  [250/313]  eta: 0:00:21  Lr: 0.001875  Loss: 0.2630  Acc@1: 87.5000 (88.9691)  Acc@5: 100.0000 (98.8546)  time: 0.3349  data: 0.0016  max mem: 2356
Train: Epoch[4/5]  [260/313]  eta: 0:00:17  Lr: 0.001875  Loss: -0.0583  Acc@1: 87.5000 (88.9847)  Acc@5: 100.0000 (98.8745)  time: 0.3345  data: 0.0004  max mem: 2356
Train: Epoch[4/5]  [270/313]  eta: 0:00:14  Lr: 0.001875  Loss: -0.1190  Acc@1: 87.5000 (89.0221)  Acc@5: 100.0000 (98.8930)  time: 0.3355  data: 0.0004  max mem: 2356
Train: Epoch[4/5]  [280/313]  eta: 0:00:11  Lr: 0.001875  Loss: 0.1212  Acc@1: 87.5000 (89.0347)  Acc@5: 100.0000 (98.9101)  time: 0.3343  data: 0.0004  max mem: 2356
Train: Epoch[4/5]  [290/313]  eta: 0:00:07  Lr: 0.001875  Loss: -0.1925  Acc@1: 87.5000 (89.1323)  Acc@5: 100.0000 (98.9261)  time: 0.3339  data: 0.0004  max mem: 2356
Train: Epoch[4/5]  [300/313]  eta: 0:00:04  Lr: 0.001875  Loss: 0.3463  Acc@1: 87.5000 (89.0365)  Acc@5: 100.0000 (98.9410)  time: 0.3353  data: 0.0009  max mem: 2356
Train: Epoch[4/5]  [310/313]  eta: 0:00:01  Lr: 0.001875  Loss: 0.2727  Acc@1: 87.5000 (88.9068)  Acc@5: 100.0000 (98.9550)  time: 0.3339  data: 0.0009  max mem: 2356
Train: Epoch[4/5]  [312/313]  eta: 0:00:00  Lr: 0.001875  Loss: 0.0047  Acc@1: 87.5000 (88.9000)  Acc@5: 100.0000 (98.9600)  time: 0.3253  data: 0.0009  max mem: 2356
Train: Epoch[4/5] Total time: 0:01:45 (0.3374 s / it)
{0: {0: 22412, 1: 24815, 2: 19998, 3: 12102, 4: 7737, 5: 7897, 6: 5634, 7: 0, 8: 0, 9: 0}, 1: {0: 1577, 1: 208, 2: 5200, 3: 12775, 4: 17024, 5: 16965, 6: 14340, 7: 0, 8: 0, 9: 0}, 2: {0: 3518, 1: 6779, 2: 5327, 3: 9830, 4: 7541, 5: 7967, 6: 5680, 7: 0, 8: 0, 9: 0}, 3: {0: 21486, 1: 20777, 2: 18903, 3: 14840, 4: 17372, 5: 17103, 6: 14491, 7: 0, 8: 0, 9: 0}, 4: {0: 16124, 1: 10227, 2: 6432, 3: 10102, 4: 7685, 5: 7874, 6: 5584, 7: 0, 8: 0, 9: 0}, 5: {0: 23402, 1: 24357, 2: 21714, 3: 15057, 4: 17322, 5: 16935, 6: 14337, 7: 0, 8: 0, 9: 0}, 6: {0: 9472, 1: 12148, 2: 17669, 3: 14460, 4: 17318, 5: 17115, 6: 14395, 7: 0, 8: 0, 9: 0}, 7: {0: 752, 1: 676, 2: 4577, 3: 10334, 4: 7679, 5: 7891, 6: 5506, 7: 0, 8: 0, 9: 0}, 8: {0: 24269, 1: 24959, 2: 24373, 3: 23260, 4: 19009, 5: 14409, 6: 5345, 7: 0, 8: 0, 9: 0}, 9: {0: 1988, 1: 54, 2: 807, 3: 2240, 4: 6313, 5: 10844, 6: 14688, 7: 0, 8: 0, 9: 0}}
Averaged stats: Lr: 0.001875  Loss: 0.0047  Acc@1: 87.5000 (88.9000)  Acc@5: 100.0000 (98.9600)
Train: Epoch[5/5]  [  0/313]  eta: 0:03:05  Lr: 0.001875  Loss: -0.0868  Acc@1: 93.7500 (93.7500)  Acc@5: 100.0000 (100.0000)  time: 0.5929  data: 0.2570  max mem: 2356
Train: Epoch[5/5]  [ 10/313]  eta: 0:01:48  Lr: 0.001875  Loss: 0.0746  Acc@1: 87.5000 (89.2045)  Acc@5: 100.0000 (99.4318)  time: 0.3581  data: 0.0242  max mem: 2356
Train: Epoch[5/5]  [ 20/313]  eta: 0:01:41  Lr: 0.001875  Loss: 0.0847  Acc@1: 93.7500 (91.3690)  Acc@5: 100.0000 (99.4048)  time: 0.3337  data: 0.0007  max mem: 2356
Train: Epoch[5/5]  [ 30/313]  eta: 0:01:36  Lr: 0.001875  Loss: 0.0675  Acc@1: 87.5000 (89.7177)  Acc@5: 100.0000 (99.3952)  time: 0.3325  data: 0.0004  max mem: 2356
Train: Epoch[5/5]  [ 40/313]  eta: 0:01:32  Lr: 0.001875  Loss: -0.1039  Acc@1: 87.5000 (89.6341)  Acc@5: 100.0000 (99.5427)  time: 0.3327  data: 0.0003  max mem: 2356
Train: Epoch[5/5]  [ 50/313]  eta: 0:01:28  Lr: 0.001875  Loss: 0.5553  Acc@1: 87.5000 (88.3578)  Acc@5: 100.0000 (99.5098)  time: 0.3328  data: 0.0004  max mem: 2356
Train: Epoch[5/5]  [ 60/313]  eta: 0:01:25  Lr: 0.001875  Loss: 0.0868  Acc@1: 87.5000 (88.2172)  Acc@5: 100.0000 (99.4877)  time: 0.3324  data: 0.0004  max mem: 2356
Train: Epoch[5/5]  [ 70/313]  eta: 0:01:21  Lr: 0.001875  Loss: 0.6055  Acc@1: 93.7500 (88.6444)  Acc@5: 100.0000 (99.3838)  time: 0.3329  data: 0.0004  max mem: 2356
Train: Epoch[5/5]  [ 80/313]  eta: 0:01:18  Lr: 0.001875  Loss: 0.2234  Acc@1: 93.7500 (88.8117)  Acc@5: 100.0000 (99.3827)  time: 0.3355  data: 0.0012  max mem: 2356
Train: Epoch[5/5]  [ 90/313]  eta: 0:01:15  Lr: 0.001875  Loss: 0.1379  Acc@1: 87.5000 (89.0110)  Acc@5: 100.0000 (99.3819)  time: 0.3383  data: 0.0024  max mem: 2356
Train: Epoch[5/5]  [100/313]  eta: 0:01:11  Lr: 0.001875  Loss: -0.0054  Acc@1: 87.5000 (88.5520)  Acc@5: 100.0000 (99.3812)  time: 0.3414  data: 0.0038  max mem: 2356
Train: Epoch[5/5]  [110/313]  eta: 0:01:08  Lr: 0.001875  Loss: 0.2182  Acc@1: 87.5000 (88.4009)  Acc@5: 100.0000 (99.3243)  time: 0.3426  data: 0.0039  max mem: 2356
Train: Epoch[5/5]  [120/313]  eta: 0:01:05  Lr: 0.001875  Loss: -0.0657  Acc@1: 87.5000 (88.3781)  Acc@5: 100.0000 (99.2769)  time: 0.3418  data: 0.0026  max mem: 2356
Train: Epoch[5/5]  [130/313]  eta: 0:01:01  Lr: 0.001875  Loss: -0.0145  Acc@1: 87.5000 (88.3111)  Acc@5: 100.0000 (99.1412)  time: 0.3391  data: 0.0013  max mem: 2356
Train: Epoch[5/5]  [140/313]  eta: 0:00:58  Lr: 0.001875  Loss: 0.0785  Acc@1: 87.5000 (88.1649)  Acc@5: 100.0000 (99.2021)  time: 0.3370  data: 0.0011  max mem: 2356
Train: Epoch[5/5]  [150/313]  eta: 0:00:55  Lr: 0.001875  Loss: -0.0177  Acc@1: 87.5000 (88.3692)  Acc@5: 100.0000 (99.1308)  time: 0.3391  data: 0.0011  max mem: 2356
Train: Epoch[5/5]  [160/313]  eta: 0:00:51  Lr: 0.001875  Loss: 0.1358  Acc@1: 93.7500 (88.4317)  Acc@5: 100.0000 (99.0295)  time: 0.3478  data: 0.0036  max mem: 2356
Train: Epoch[5/5]  [170/313]  eta: 0:00:48  Lr: 0.001875  Loss: -0.2079  Acc@1: 87.5000 (88.4137)  Acc@5: 100.0000 (99.0863)  time: 0.3482  data: 0.0042  max mem: 2356
Train: Epoch[5/5]  [180/313]  eta: 0:00:45  Lr: 0.001875  Loss: 0.4420  Acc@1: 81.2500 (88.2942)  Acc@5: 100.0000 (98.9986)  time: 0.3400  data: 0.0018  max mem: 2356
Train: Epoch[5/5]  [190/313]  eta: 0:00:41  Lr: 0.001875  Loss: 0.1054  Acc@1: 87.5000 (88.3835)  Acc@5: 100.0000 (98.9856)  time: 0.3394  data: 0.0012  max mem: 2356
Train: Epoch[5/5]  [200/313]  eta: 0:00:38  Lr: 0.001875  Loss: -0.1182  Acc@1: 93.7500 (88.7127)  Acc@5: 100.0000 (99.0050)  time: 0.3400  data: 0.0015  max mem: 2356
Train: Epoch[5/5]  [210/313]  eta: 0:00:34  Lr: 0.001875  Loss: -0.0615  Acc@1: 93.7500 (88.8922)  Acc@5: 100.0000 (99.0521)  time: 0.3382  data: 0.0015  max mem: 2356
Train: Epoch[5/5]  [220/313]  eta: 0:00:31  Lr: 0.001875  Loss: 0.1994  Acc@1: 93.7500 (88.9989)  Acc@5: 100.0000 (99.0385)  time: 0.3379  data: 0.0012  max mem: 2356
Train: Epoch[5/5]  [230/313]  eta: 0:00:28  Lr: 0.001875  Loss: 0.2936  Acc@1: 87.5000 (89.1504)  Acc@5: 100.0000 (99.0260)  time: 0.3442  data: 0.0044  max mem: 2356
Train: Epoch[5/5]  [240/313]  eta: 0:00:24  Lr: 0.001875  Loss: -0.1031  Acc@1: 93.7500 (89.2894)  Acc@5: 100.0000 (99.0664)  time: 0.3432  data: 0.0038  max mem: 2356
Train: Epoch[5/5]  [250/313]  eta: 0:00:21  Lr: 0.001875  Loss: 0.0858  Acc@1: 93.7500 (89.2181)  Acc@5: 100.0000 (99.0040)  time: 0.3364  data: 0.0010  max mem: 2356
Train: Epoch[5/5]  [260/313]  eta: 0:00:18  Lr: 0.001875  Loss: -0.0167  Acc@1: 87.5000 (89.2481)  Acc@5: 100.0000 (98.9703)  time: 0.3406  data: 0.0008  max mem: 2356
Train: Epoch[5/5]  [270/313]  eta: 0:00:14  Lr: 0.001875  Loss: 0.0098  Acc@1: 87.5000 (89.2066)  Acc@5: 100.0000 (98.9622)  time: 0.3424  data: 0.0007  max mem: 2356
Train: Epoch[5/5]  [280/313]  eta: 0:00:11  Lr: 0.001875  Loss: 0.0276  Acc@1: 87.5000 (89.4128)  Acc@5: 100.0000 (98.9769)  time: 0.3379  data: 0.0006  max mem: 2356
Train: Epoch[5/5]  [290/313]  eta: 0:00:07  Lr: 0.001875  Loss: 0.1281  Acc@1: 87.5000 (89.0679)  Acc@5: 100.0000 (98.9476)  time: 0.3351  data: 0.0004  max mem: 2356
Train: Epoch[5/5]  [300/313]  eta: 0:00:04  Lr: 0.001875  Loss: 0.5409  Acc@1: 81.2500 (89.0781)  Acc@5: 100.0000 (98.9410)  time: 0.3342  data: 0.0004  max mem: 2356
Train: Epoch[5/5]  [310/313]  eta: 0:00:01  Lr: 0.001875  Loss: 0.2080  Acc@1: 87.5000 (88.9670)  Acc@5: 100.0000 (98.9550)  time: 0.3347  data: 0.0003  max mem: 2356
Train: Epoch[5/5]  [312/313]  eta: 0:00:00  Lr: 0.001875  Loss: -0.0438  Acc@1: 87.5000 (89.0000)  Acc@5: 100.0000 (98.9600)  time: 0.3259  data: 0.0003  max mem: 2356
Train: Epoch[5/5] Total time: 0:01:46 (0.3388 s / it)
{0: {0: 22412, 1: 24815, 2: 19998, 3: 12102, 4: 7737, 5: 7897, 6: 7115, 7: 0, 8: 0, 9: 0}, 1: {0: 1577, 1: 208, 2: 5200, 3: 12775, 4: 17024, 5: 16965, 6: 17861, 7: 0, 8: 0, 9: 0}, 2: {0: 3518, 1: 6779, 2: 5327, 3: 9830, 4: 7541, 5: 7967, 6: 7212, 7: 0, 8: 0, 9: 0}, 3: {0: 21486, 1: 20777, 2: 18903, 3: 14840, 4: 17372, 5: 17103, 6: 18038, 7: 0, 8: 0, 9: 0}, 4: {0: 16124, 1: 10227, 2: 6432, 3: 10102, 4: 7685, 5: 7874, 6: 7043, 7: 0, 8: 0, 9: 0}, 5: {0: 23402, 1: 24357, 2: 21714, 3: 15057, 4: 17322, 5: 16935, 6: 17805, 7: 0, 8: 0, 9: 0}, 6: {0: 9472, 1: 12148, 2: 17669, 3: 14460, 4: 17318, 5: 17115, 6: 17934, 7: 0, 8: 0, 9: 0}, 7: {0: 752, 1: 676, 2: 4577, 3: 10334, 4: 7679, 5: 7891, 6: 6959, 7: 0, 8: 0, 9: 0}, 8: {0: 24269, 1: 24959, 2: 24373, 3: 23260, 4: 19009, 5: 14409, 6: 6643, 7: 0, 8: 0, 9: 0}, 9: {0: 1988, 1: 54, 2: 807, 3: 2240, 4: 6313, 5: 10844, 6: 18390, 7: 0, 8: 0, 9: 0}}
Averaged stats: Lr: 0.001875  Loss: -0.0438  Acc@1: 87.5000 (89.0000)  Acc@5: 100.0000 (98.9600)
Test: [Task 1]  [ 0/63]  eta: 0:00:36  Loss: 0.7854 (0.7854)  Acc@1: 81.2500 (81.2500)  Acc@5: 100.0000 (100.0000)  time: 0.5737  data: 0.3635  max mem: 2356
Test: [Task 1]  [10/63]  eta: 0:00:12  Loss: 0.6549 (0.6292)  Acc@1: 81.2500 (86.3636)  Acc@5: 100.0000 (98.8636)  time: 0.2395  data: 0.0334  max mem: 2356
Test: [Task 1]  [20/63]  eta: 0:00:09  Loss: 0.6549 (0.6794)  Acc@1: 87.5000 (85.1190)  Acc@5: 100.0000 (98.2143)  time: 0.2065  data: 0.0004  max mem: 2356
Test: [Task 1]  [30/63]  eta: 0:00:07  Loss: 0.5862 (0.6566)  Acc@1: 87.5000 (85.8871)  Acc@5: 100.0000 (98.3871)  time: 0.2064  data: 0.0004  max mem: 2356
Test: [Task 1]  [40/63]  eta: 0:00:04  Loss: 0.5633 (0.6497)  Acc@1: 81.2500 (85.5183)  Acc@5: 100.0000 (98.7805)  time: 0.2059  data: 0.0004  max mem: 2356
Test: [Task 1]  [50/63]  eta: 0:00:02  Loss: 0.5391 (0.6264)  Acc@1: 87.5000 (86.0294)  Acc@5: 100.0000 (98.7745)  time: 0.2064  data: 0.0009  max mem: 2356
Test: [Task 1]  [60/63]  eta: 0:00:00  Loss: 0.5391 (0.6154)  Acc@1: 87.5000 (86.0656)  Acc@5: 100.0000 (98.5656)  time: 0.2068  data: 0.0008  max mem: 2356
Test: [Task 1]  [62/63]  eta: 0:00:00  Loss: 0.5391 (0.6170)  Acc@1: 87.5000 (86.2000)  Acc@5: 100.0000 (98.6000)  time: 0.2018  data: 0.0008  max mem: 2356
Test: [Task 1] Total time: 0:00:13 (0.2118 s / it)
* Acc@1 86.200 Acc@5 98.600 loss 0.617
Test: [Task 2]  [ 0/63]  eta: 0:00:29  Loss: 0.9358 (0.9358)  Acc@1: 81.2500 (81.2500)  Acc@5: 93.7500 (93.7500)  time: 0.4637  data: 0.2566  max mem: 2356
Test: [Task 2]  [10/63]  eta: 0:00:12  Loss: 0.8082 (0.8174)  Acc@1: 81.2500 (83.5227)  Acc@5: 100.0000 (96.0227)  time: 0.2294  data: 0.0236  max mem: 2356
Test: [Task 2]  [20/63]  eta: 0:00:09  Loss: 0.8096 (0.8634)  Acc@1: 81.2500 (81.8452)  Acc@5: 100.0000 (96.4286)  time: 0.2061  data: 0.0003  max mem: 2356
Test: [Task 2]  [30/63]  eta: 0:00:07  Loss: 0.8118 (0.8466)  Acc@1: 81.2500 (82.2581)  Acc@5: 100.0000 (95.9677)  time: 0.2068  data: 0.0003  max mem: 2356
Test: [Task 2]  [40/63]  eta: 0:00:04  Loss: 0.6823 (0.8286)  Acc@1: 87.5000 (82.6220)  Acc@5: 100.0000 (96.3415)  time: 0.2078  data: 0.0010  max mem: 2356
Test: [Task 2]  [50/63]  eta: 0:00:02  Loss: 0.6823 (0.8204)  Acc@1: 81.2500 (82.4755)  Acc@5: 100.0000 (96.6912)  time: 0.2079  data: 0.0012  max mem: 2356
Test: [Task 2]  [60/63]  eta: 0:00:00  Loss: 0.6862 (0.7896)  Acc@1: 81.2500 (83.0943)  Acc@5: 100.0000 (97.1311)  time: 0.2060  data: 0.0005  max mem: 2356
Test: [Task 2]  [62/63]  eta: 0:00:00  Loss: 0.6512 (0.7846)  Acc@1: 81.2500 (83.1000)  Acc@5: 100.0000 (97.2000)  time: 0.2005  data: 0.0005  max mem: 2356
Test: [Task 2] Total time: 0:00:13 (0.2104 s / it)
* Acc@1 83.100 Acc@5 97.200 loss 0.785
Test: [Task 3]  [ 0/63]  eta: 0:00:33  Loss: 0.6470 (0.6470)  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (100.0000)  time: 0.5248  data: 0.3170  max mem: 2356
Test: [Task 3]  [10/63]  eta: 0:00:12  Loss: 0.6470 (0.6939)  Acc@1: 81.2500 (82.9545)  Acc@5: 100.0000 (97.7273)  time: 0.2348  data: 0.0291  max mem: 2356
Test: [Task 3]  [20/63]  eta: 0:00:09  Loss: 0.6667 (0.7068)  Acc@1: 81.2500 (82.4405)  Acc@5: 100.0000 (97.3214)  time: 0.2058  data: 0.0003  max mem: 2356
Test: [Task 3]  [30/63]  eta: 0:00:07  Loss: 0.7133 (0.7112)  Acc@1: 81.2500 (81.2500)  Acc@5: 100.0000 (97.7823)  time: 0.2053  data: 0.0003  max mem: 2356
Test: [Task 3]  [40/63]  eta: 0:00:04  Loss: 0.6300 (0.7069)  Acc@1: 81.2500 (81.2500)  Acc@5: 100.0000 (97.8659)  time: 0.2061  data: 0.0003  max mem: 2356
Test: [Task 3]  [50/63]  eta: 0:00:02  Loss: 0.7119 (0.7120)  Acc@1: 87.5000 (82.5980)  Acc@5: 100.0000 (97.3039)  time: 0.2070  data: 0.0006  max mem: 2356
Test: [Task 3]  [60/63]  eta: 0:00:00  Loss: 0.7232 (0.7276)  Acc@1: 87.5000 (82.1721)  Acc@5: 93.7500 (97.1311)  time: 0.2067  data: 0.0006  max mem: 2356
Test: [Task 3]  [62/63]  eta: 0:00:00  Loss: 0.7370 (0.7271)  Acc@1: 81.2500 (81.9000)  Acc@5: 93.7500 (97.1000)  time: 0.2023  data: 0.0006  max mem: 2356
Test: [Task 3] Total time: 0:00:13 (0.2107 s / it)
* Acc@1 81.900 Acc@5 97.100 loss 0.727
Test: [Task 4]  [ 0/63]  eta: 0:00:26  Loss: 0.6841 (0.6841)  Acc@1: 75.0000 (75.0000)  Acc@5: 93.7500 (93.7500)  time: 0.4207  data: 0.2127  max mem: 2356
Test: [Task 4]  [10/63]  eta: 0:00:11  Loss: 0.6790 (0.6238)  Acc@1: 81.2500 (83.5227)  Acc@5: 100.0000 (97.7273)  time: 0.2243  data: 0.0196  max mem: 2356
Test: [Task 4]  [20/63]  eta: 0:00:09  Loss: 0.6037 (0.6470)  Acc@1: 81.2500 (82.7381)  Acc@5: 100.0000 (97.0238)  time: 0.2060  data: 0.0009  max mem: 2356
Test: [Task 4]  [30/63]  eta: 0:00:07  Loss: 0.5571 (0.6301)  Acc@1: 81.2500 (83.4677)  Acc@5: 93.7500 (96.7742)  time: 0.2067  data: 0.0011  max mem: 2356
Test: [Task 4]  [40/63]  eta: 0:00:04  Loss: 0.4359 (0.5799)  Acc@1: 87.5000 (85.5183)  Acc@5: 100.0000 (97.2561)  time: 0.2058  data: 0.0008  max mem: 2356
Test: [Task 4]  [50/63]  eta: 0:00:02  Loss: 0.4406 (0.5990)  Acc@1: 87.5000 (85.6618)  Acc@5: 100.0000 (96.8137)  time: 0.2058  data: 0.0006  max mem: 2356
Test: [Task 4]  [60/63]  eta: 0:00:00  Loss: 0.6335 (0.6150)  Acc@1: 87.5000 (85.2459)  Acc@5: 100.0000 (96.7213)  time: 0.2057  data: 0.0003  max mem: 2356
Test: [Task 4]  [62/63]  eta: 0:00:00  Loss: 0.5135 (0.6087)  Acc@1: 87.5000 (85.3000)  Acc@5: 100.0000 (96.8000)  time: 0.2020  data: 0.0003  max mem: 2356
Test: [Task 4] Total time: 0:00:13 (0.2095 s / it)
* Acc@1 85.300 Acc@5 96.800 loss 0.609
Test: [Task 5]  [ 0/63]  eta: 0:00:45  Loss: 0.1836 (0.1836)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)  time: 0.7257  data: 0.5195  max mem: 2356
Test: [Task 5]  [10/63]  eta: 0:00:13  Loss: 0.3917 (0.5504)  Acc@1: 93.7500 (88.6364)  Acc@5: 100.0000 (97.7273)  time: 0.2564  data: 0.0492  max mem: 2356
Test: [Task 5]  [20/63]  eta: 0:00:10  Loss: 0.3908 (0.4923)  Acc@1: 93.7500 (91.3690)  Acc@5: 100.0000 (97.9167)  time: 0.2090  data: 0.0013  max mem: 2356
Test: [Task 5]  [30/63]  eta: 0:00:07  Loss: 0.4276 (0.5042)  Acc@1: 93.7500 (90.9274)  Acc@5: 100.0000 (97.9839)  time: 0.2091  data: 0.0016  max mem: 2356
Test: [Task 5]  [40/63]  eta: 0:00:05  Loss: 0.4229 (0.4887)  Acc@1: 93.7500 (91.4634)  Acc@5: 100.0000 (98.0183)  time: 0.2118  data: 0.0020  max mem: 2356
Test: [Task 5]  [50/63]  eta: 0:00:02  Loss: 0.4441 (0.4957)  Acc@1: 93.7500 (91.6667)  Acc@5: 100.0000 (97.9167)  time: 0.2103  data: 0.0009  max mem: 2356
Test: [Task 5]  [60/63]  eta: 0:00:00  Loss: 0.4805 (0.5162)  Acc@1: 93.7500 (90.6762)  Acc@5: 100.0000 (97.7459)  time: 0.2104  data: 0.0005  max mem: 2356
Test: [Task 5]  [62/63]  eta: 0:00:00  Loss: 0.5580 (0.5324)  Acc@1: 87.5000 (90.2000)  Acc@5: 100.0000 (97.6000)  time: 0.2078  data: 0.0004  max mem: 2356
Test: [Task 5] Total time: 0:00:13 (0.2201 s / it)
* Acc@1 90.200 Acc@5 97.600 loss 0.532
Test: [Task 6]  [ 0/63]  eta: 0:00:45  Loss: 0.5153 (0.5153)  Acc@1: 81.2500 (81.2500)  Acc@5: 100.0000 (100.0000)  time: 0.7274  data: 0.5223  max mem: 2356
Test: [Task 6]  [10/63]  eta: 0:00:13  Loss: 0.7219 (0.7003)  Acc@1: 81.2500 (81.2500)  Acc@5: 100.0000 (96.5909)  time: 0.2533  data: 0.0478  max mem: 2356
Test: [Task 6]  [20/63]  eta: 0:00:10  Loss: 0.7375 (0.7609)  Acc@1: 81.2500 (80.0595)  Acc@5: 100.0000 (97.0238)  time: 0.2089  data: 0.0017  max mem: 2356
Test: [Task 6]  [30/63]  eta: 0:00:07  Loss: 0.6698 (0.7382)  Acc@1: 81.2500 (80.2419)  Acc@5: 100.0000 (97.5806)  time: 0.2096  data: 0.0017  max mem: 2356
Test: [Task 6]  [40/63]  eta: 0:00:05  Loss: 0.7431 (0.7775)  Acc@1: 75.0000 (78.3537)  Acc@5: 100.0000 (97.2561)  time: 0.2085  data: 0.0013  max mem: 2356
Test: [Task 6]  [50/63]  eta: 0:00:02  Loss: 0.7330 (0.7576)  Acc@1: 81.2500 (78.7990)  Acc@5: 100.0000 (97.6716)  time: 0.2080  data: 0.0013  max mem: 2356
Test: [Task 6]  [60/63]  eta: 0:00:00  Loss: 0.6900 (0.7665)  Acc@1: 81.2500 (78.7910)  Acc@5: 100.0000 (97.5410)  time: 0.2070  data: 0.0006  max mem: 2356
Test: [Task 6]  [62/63]  eta: 0:00:00  Loss: 0.6900 (0.7630)  Acc@1: 81.2500 (78.9000)  Acc@5: 100.0000 (97.6000)  time: 0.2021  data: 0.0006  max mem: 2356
Test: [Task 6] Total time: 0:00:13 (0.2163 s / it)
* Acc@1 78.900 Acc@5 97.600 loss 0.763
Test: [Task 7]  [ 0/63]  eta: 0:00:33  Loss: 0.6869 (0.6869)  Acc@1: 75.0000 (75.0000)  Acc@5: 93.7500 (93.7500)  time: 0.5252  data: 0.3119  max mem: 2356
Test: [Task 7]  [10/63]  eta: 0:00:12  Loss: 0.4832 (0.5546)  Acc@1: 87.5000 (84.6591)  Acc@5: 100.0000 (98.2955)  time: 0.2379  data: 0.0295  max mem: 2356
Test: [Task 7]  [20/63]  eta: 0:00:09  Loss: 0.4832 (0.5913)  Acc@1: 87.5000 (86.3095)  Acc@5: 100.0000 (97.6190)  time: 0.2080  data: 0.0009  max mem: 2356
Test: [Task 7]  [30/63]  eta: 0:00:07  Loss: 0.5300 (0.5888)  Acc@1: 87.5000 (86.6935)  Acc@5: 100.0000 (97.7823)  time: 0.2070  data: 0.0012  max mem: 2356
Test: [Task 7]  [40/63]  eta: 0:00:04  Loss: 0.4564 (0.5779)  Acc@1: 87.5000 (87.1951)  Acc@5: 100.0000 (97.4085)  time: 0.2090  data: 0.0025  max mem: 2356
Test: [Task 7]  [50/63]  eta: 0:00:02  Loss: 0.5820 (0.5982)  Acc@1: 87.5000 (86.6422)  Acc@5: 100.0000 (97.1814)  time: 0.2107  data: 0.0023  max mem: 2356
Test: [Task 7]  [60/63]  eta: 0:00:00  Loss: 0.5813 (0.5859)  Acc@1: 87.5000 (86.9877)  Acc@5: 100.0000 (97.2336)  time: 0.2083  data: 0.0010  max mem: 2356
Test: [Task 7]  [62/63]  eta: 0:00:00  Loss: 0.5958 (0.5885)  Acc@1: 87.5000 (86.9000)  Acc@5: 100.0000 (97.3000)  time: 0.2036  data: 0.0010  max mem: 2356
Test: [Task 7] Total time: 0:00:13 (0.2135 s / it)
* Acc@1 86.900 Acc@5 97.300 loss 0.589
{0: {0: 251, 1: 749, 2: 269, 3: 750, 4: 248, 5: 731, 6: 751, 7: 251, 8: 193, 9: 807}, 1: {0: 536, 1: 464, 2: 545, 3: 465, 4: 533, 5: 455, 6: 467, 7: 535, 8: 491, 9: 509}, 2: {0: 275, 1: 725, 2: 288, 3: 725, 4: 272, 5: 712, 6: 728, 7: 275, 8: 223, 9: 777}, 3: {0: 503, 1: 497, 2: 524, 3: 497, 4: 503, 5: 475, 6: 497, 7: 504, 8: 446, 9: 554}, 4: {0: 477, 1: 521, 2: 494, 3: 527, 4: 475, 5: 506, 6: 523, 7: 477, 8: 430, 9: 570}, 5: {0: 473, 1: 527, 2: 484, 3: 538, 4: 462, 5: 516, 6: 537, 7: 463, 8: 429, 9: 571}, 6: {0: 430, 1: 570, 2: 467, 3: 581, 4: 419, 5: 533, 6: 580, 7: 420, 8: 347, 9: 653}}
[Average accuracy till task7]	Acc@1: 84.6429	Acc@5: 97.4571	Loss: 0.6602	Forgetting: 6.4833	Backward: -6.4833
Train: Epoch[1/5]  [  0/313]  eta: 0:04:20  Lr: 0.001875  Loss: 2.0462  Acc@1: 6.2500 (6.2500)  Acc@5: 68.7500 (68.7500)  time: 0.8335  data: 0.4845  max mem: 2356
Train: Epoch[1/5]  [ 10/313]  eta: 0:01:56  Lr: 0.001875  Loss: 1.6215  Acc@1: 56.2500 (54.5455)  Acc@5: 87.5000 (84.0909)  time: 0.3840  data: 0.0445  max mem: 2356
Train: Epoch[1/5]  [ 20/313]  eta: 0:01:46  Lr: 0.001875  Loss: 1.1682  Acc@1: 68.7500 (65.4762)  Acc@5: 87.5000 (88.6905)  time: 0.3383  data: 0.0013  max mem: 2356
Train: Epoch[1/5]  [ 30/313]  eta: 0:01:41  Lr: 0.001875  Loss: 1.0829  Acc@1: 75.0000 (69.9597)  Acc@5: 100.0000 (90.9274)  time: 0.3466  data: 0.0059  max mem: 2356
Train: Epoch[1/5]  [ 40/313]  eta: 0:01:36  Lr: 0.001875  Loss: 1.0281  Acc@1: 81.2500 (71.6463)  Acc@5: 100.0000 (92.2256)  time: 0.3441  data: 0.0051  max mem: 2356
Train: Epoch[1/5]  [ 50/313]  eta: 0:01:31  Lr: 0.001875  Loss: 0.5968  Acc@1: 81.2500 (73.7745)  Acc@5: 100.0000 (93.2598)  time: 0.3329  data: 0.0004  max mem: 2356
Train: Epoch[1/5]  [ 60/313]  eta: 0:01:27  Lr: 0.001875  Loss: 0.4337  Acc@1: 81.2500 (74.3852)  Acc@5: 100.0000 (94.0574)  time: 0.3334  data: 0.0005  max mem: 2356
Train: Epoch[1/5]  [ 70/313]  eta: 0:01:23  Lr: 0.001875  Loss: 0.3391  Acc@1: 81.2500 (75.8803)  Acc@5: 100.0000 (94.6303)  time: 0.3337  data: 0.0004  max mem: 2356
Train: Epoch[1/5]  [ 80/313]  eta: 0:01:20  Lr: 0.001875  Loss: 0.5581  Acc@1: 81.2500 (77.0833)  Acc@5: 100.0000 (94.9074)  time: 0.3343  data: 0.0004  max mem: 2356
Train: Epoch[1/5]  [ 90/313]  eta: 0:01:16  Lr: 0.001875  Loss: 0.3170  Acc@1: 81.2500 (77.7473)  Acc@5: 100.0000 (95.3297)  time: 0.3340  data: 0.0009  max mem: 2356
Train: Epoch[1/5]  [100/313]  eta: 0:01:12  Lr: 0.001875  Loss: 0.4122  Acc@1: 87.5000 (78.8366)  Acc@5: 100.0000 (95.6683)  time: 0.3330  data: 0.0009  max mem: 2356
Train: Epoch[1/5]  [110/313]  eta: 0:01:09  Lr: 0.001875  Loss: 0.4967  Acc@1: 87.5000 (79.3919)  Acc@5: 100.0000 (95.8896)  time: 0.3329  data: 0.0005  max mem: 2356
Train: Epoch[1/5]  [120/313]  eta: 0:01:05  Lr: 0.001875  Loss: 0.3488  Acc@1: 87.5000 (79.9587)  Acc@5: 100.0000 (96.1777)  time: 0.3338  data: 0.0005  max mem: 2356
Train: Epoch[1/5]  [130/313]  eta: 0:01:02  Lr: 0.001875  Loss: 0.3955  Acc@1: 87.5000 (80.4866)  Acc@5: 100.0000 (96.1355)  time: 0.3340  data: 0.0004  max mem: 2356
Train: Epoch[1/5]  [140/313]  eta: 0:00:58  Lr: 0.001875  Loss: 0.7028  Acc@1: 81.2500 (80.4965)  Acc@5: 100.0000 (96.3209)  time: 0.3330  data: 0.0004  max mem: 2356
Train: Epoch[1/5]  [150/313]  eta: 0:00:55  Lr: 0.001875  Loss: 0.3203  Acc@1: 81.2500 (80.9189)  Acc@5: 100.0000 (96.3990)  time: 0.3338  data: 0.0003  max mem: 2356
Train: Epoch[1/5]  [160/313]  eta: 0:00:51  Lr: 0.001875  Loss: 0.1571  Acc@1: 87.5000 (81.4829)  Acc@5: 100.0000 (96.5839)  time: 0.3342  data: 0.0004  max mem: 2356
Train: Epoch[1/5]  [170/313]  eta: 0:00:48  Lr: 0.001875  Loss: 0.2410  Acc@1: 93.7500 (81.8348)  Acc@5: 100.0000 (96.6740)  time: 0.3322  data: 0.0004  max mem: 2356
Train: Epoch[1/5]  [180/313]  eta: 0:00:44  Lr: 0.001875  Loss: 0.1582  Acc@1: 87.5000 (82.1478)  Acc@5: 100.0000 (96.6506)  time: 0.3322  data: 0.0010  max mem: 2356
Train: Epoch[1/5]  [190/313]  eta: 0:00:41  Lr: 0.001875  Loss: 0.1032  Acc@1: 87.5000 (82.6243)  Acc@5: 100.0000 (96.7277)  time: 0.3321  data: 0.0010  max mem: 2356
Train: Epoch[1/5]  [200/313]  eta: 0:00:38  Lr: 0.001875  Loss: 0.6883  Acc@1: 87.5000 (82.8980)  Acc@5: 100.0000 (96.8595)  time: 0.3309  data: 0.0003  max mem: 2356
Train: Epoch[1/5]  [210/313]  eta: 0:00:34  Lr: 0.001875  Loss: 0.1169  Acc@1: 87.5000 (83.0273)  Acc@5: 100.0000 (96.9194)  time: 0.3310  data: 0.0004  max mem: 2356
Train: Epoch[1/5]  [220/313]  eta: 0:00:31  Lr: 0.001875  Loss: 0.2986  Acc@1: 87.5000 (83.1448)  Acc@5: 100.0000 (96.9174)  time: 0.3331  data: 0.0011  max mem: 2356
Train: Epoch[1/5]  [230/313]  eta: 0:00:27  Lr: 0.001875  Loss: 0.2827  Acc@1: 87.5000 (83.3604)  Acc@5: 100.0000 (96.9968)  time: 0.3339  data: 0.0016  max mem: 2356
Train: Epoch[1/5]  [240/313]  eta: 0:00:24  Lr: 0.001875  Loss: -0.0602  Acc@1: 93.7500 (83.7137)  Acc@5: 100.0000 (97.0954)  time: 0.3370  data: 0.0025  max mem: 2356
Train: Epoch[1/5]  [250/313]  eta: 0:00:21  Lr: 0.001875  Loss: 0.1125  Acc@1: 87.5000 (83.7649)  Acc@5: 100.0000 (97.1614)  time: 0.3426  data: 0.0021  max mem: 2356
Train: Epoch[1/5]  [260/313]  eta: 0:00:17  Lr: 0.001875  Loss: -0.0388  Acc@1: 81.2500 (83.7404)  Acc@5: 100.0000 (97.1743)  time: 0.3424  data: 0.0006  max mem: 2356
Train: Epoch[1/5]  [270/313]  eta: 0:00:14  Lr: 0.001875  Loss: 0.3827  Acc@1: 81.2500 (83.7638)  Acc@5: 100.0000 (97.2094)  time: 0.3407  data: 0.0036  max mem: 2356
Train: Epoch[1/5]  [280/313]  eta: 0:00:11  Lr: 0.001875  Loss: 0.0285  Acc@1: 81.2500 (83.8523)  Acc@5: 100.0000 (97.2420)  time: 0.3407  data: 0.0048  max mem: 2356
Train: Epoch[1/5]  [290/313]  eta: 0:00:07  Lr: 0.001875  Loss: 0.1693  Acc@1: 87.5000 (84.0851)  Acc@5: 100.0000 (97.2938)  time: 0.3408  data: 0.0029  max mem: 2356
Train: Epoch[1/5]  [300/313]  eta: 0:00:04  Lr: 0.001875  Loss: -0.0652  Acc@1: 93.7500 (84.3439)  Acc@5: 100.0000 (97.3422)  time: 0.3421  data: 0.0017  max mem: 2356
Train: Epoch[1/5]  [310/313]  eta: 0:00:01  Lr: 0.001875  Loss: 0.4374  Acc@1: 87.5000 (84.3047)  Acc@5: 100.0000 (97.3473)  time: 0.3421  data: 0.0007  max mem: 2356
Train: Epoch[1/5]  [312/313]  eta: 0:00:00  Lr: 0.001875  Loss: 0.4199  Acc@1: 87.5000 (84.3400)  Acc@5: 100.0000 (97.3600)  time: 0.3340  data: 0.0007  max mem: 2356
Train: Epoch[1/5] Total time: 0:01:45 (0.3379 s / it)
{0: {0: 22412, 1: 24815, 2: 19998, 3: 12102, 4: 7737, 5: 7897, 6: 7115, 7: 1297, 8: 0, 9: 0}, 1: {0: 1577, 1: 208, 2: 5200, 3: 12775, 4: 17024, 5: 16965, 6: 17861, 7: 3702, 8: 0, 9: 0}, 2: {0: 3518, 1: 6779, 2: 5327, 3: 9830, 4: 7541, 5: 7967, 6: 7212, 7: 1302, 8: 0, 9: 0}, 3: {0: 21486, 1: 20777, 2: 18903, 3: 14840, 4: 17372, 5: 17103, 6: 18038, 7: 3734, 8: 0, 9: 0}, 4: {0: 16124, 1: 10227, 2: 6432, 3: 10102, 4: 7685, 5: 7874, 6: 7043, 7: 1280, 8: 0, 9: 0}, 5: {0: 23402, 1: 24357, 2: 21714, 3: 15057, 4: 17322, 5: 16935, 6: 17805, 7: 3708, 8: 0, 9: 0}, 6: {0: 9472, 1: 12148, 2: 17669, 3: 14460, 4: 17318, 5: 17115, 6: 17934, 7: 3718, 8: 0, 9: 0}, 7: {0: 752, 1: 676, 2: 4577, 3: 10334, 4: 7679, 5: 7891, 6: 6959, 7: 1263, 8: 0, 9: 0}, 8: {0: 24269, 1: 24959, 2: 24373, 3: 23260, 4: 19009, 5: 14409, 6: 6643, 7: 1035, 8: 0, 9: 0}, 9: {0: 1988, 1: 54, 2: 807, 3: 2240, 4: 6313, 5: 10844, 6: 18390, 7: 3961, 8: 0, 9: 0}}
Averaged stats: Lr: 0.001875  Loss: 0.4199  Acc@1: 87.5000 (84.3400)  Acc@5: 100.0000 (97.3600)
Train: Epoch[2/5]  [  0/313]  eta: 0:03:56  Lr: 0.001875  Loss: 0.4498  Acc@1: 81.2500 (81.2500)  Acc@5: 93.7500 (93.7500)  time: 0.7542  data: 0.4006  max mem: 2356
Train: Epoch[2/5]  [ 10/313]  eta: 0:01:53  Lr: 0.001875  Loss: 0.1596  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (96.5909)  time: 0.3758  data: 0.0373  max mem: 2356
Train: Epoch[2/5]  [ 20/313]  eta: 0:01:44  Lr: 0.001875  Loss: 0.4647  Acc@1: 87.5000 (87.7976)  Acc@5: 100.0000 (97.3214)  time: 0.3366  data: 0.0007  max mem: 2356
Train: Epoch[2/5]  [ 30/313]  eta: 0:01:38  Lr: 0.001875  Loss: 0.2739  Acc@1: 87.5000 (87.9032)  Acc@5: 100.0000 (97.5806)  time: 0.3343  data: 0.0005  max mem: 2356
Train: Epoch[2/5]  [ 40/313]  eta: 0:01:34  Lr: 0.001875  Loss: 0.2120  Acc@1: 87.5000 (87.8049)  Acc@5: 100.0000 (98.0183)  time: 0.3370  data: 0.0004  max mem: 2356
Train: Epoch[2/5]  [ 50/313]  eta: 0:01:30  Lr: 0.001875  Loss: 0.0826  Acc@1: 87.5000 (88.2353)  Acc@5: 100.0000 (97.9167)  time: 0.3390  data: 0.0010  max mem: 2356
Train: Epoch[2/5]  [ 60/313]  eta: 0:01:27  Lr: 0.001875  Loss: 0.0516  Acc@1: 87.5000 (88.8320)  Acc@5: 100.0000 (98.0533)  time: 0.3389  data: 0.0015  max mem: 2356
Train: Epoch[2/5]  [ 70/313]  eta: 0:01:23  Lr: 0.001875  Loss: -0.0250  Acc@1: 93.7500 (89.0845)  Acc@5: 100.0000 (98.1514)  time: 0.3385  data: 0.0014  max mem: 2356
Train: Epoch[2/5]  [ 80/313]  eta: 0:01:20  Lr: 0.001875  Loss: -0.0669  Acc@1: 87.5000 (89.1204)  Acc@5: 100.0000 (98.3796)  time: 0.3420  data: 0.0014  max mem: 2356
Train: Epoch[2/5]  [ 90/313]  eta: 0:01:16  Lr: 0.001875  Loss: -0.0329  Acc@1: 81.2500 (88.5989)  Acc@5: 100.0000 (98.3516)  time: 0.3401  data: 0.0009  max mem: 2356
Train: Epoch[2/5]  [100/313]  eta: 0:01:12  Lr: 0.001875  Loss: 0.5092  Acc@1: 87.5000 (88.4282)  Acc@5: 100.0000 (98.3911)  time: 0.3328  data: 0.0004  max mem: 2356
Train: Epoch[2/5]  [110/313]  eta: 0:01:09  Lr: 0.001875  Loss: 0.0392  Acc@1: 93.7500 (88.5135)  Acc@5: 100.0000 (98.4797)  time: 0.3334  data: 0.0004  max mem: 2356
Train: Epoch[2/5]  [120/313]  eta: 0:01:05  Lr: 0.001875  Loss: 0.0596  Acc@1: 93.7500 (89.0496)  Acc@5: 100.0000 (98.6054)  time: 0.3333  data: 0.0003  max mem: 2356
Train: Epoch[2/5]  [130/313]  eta: 0:01:02  Lr: 0.001875  Loss: 0.3596  Acc@1: 93.7500 (88.8836)  Acc@5: 100.0000 (98.6164)  time: 0.3325  data: 0.0004  max mem: 2356
Train: Epoch[2/5]  [140/313]  eta: 0:00:58  Lr: 0.001875  Loss: 0.0492  Acc@1: 87.5000 (88.8741)  Acc@5: 100.0000 (98.5816)  time: 0.3325  data: 0.0004  max mem: 2356
Train: Epoch[2/5]  [150/313]  eta: 0:00:55  Lr: 0.001875  Loss: 0.3537  Acc@1: 87.5000 (88.5348)  Acc@5: 100.0000 (98.5513)  time: 0.3336  data: 0.0004  max mem: 2356
Train: Epoch[2/5]  [160/313]  eta: 0:00:51  Lr: 0.001875  Loss: -0.1506  Acc@1: 81.2500 (88.3929)  Acc@5: 100.0000 (98.5637)  time: 0.3337  data: 0.0004  max mem: 2356
Train: Epoch[2/5]  [170/313]  eta: 0:00:48  Lr: 0.001875  Loss: 0.0138  Acc@1: 87.5000 (88.4503)  Acc@5: 100.0000 (98.5015)  time: 0.3341  data: 0.0010  max mem: 2356
Train: Epoch[2/5]  [180/313]  eta: 0:00:44  Lr: 0.001875  Loss: 0.0301  Acc@1: 87.5000 (88.3633)  Acc@5: 100.0000 (98.5152)  time: 0.3350  data: 0.0011  max mem: 2356
Train: Epoch[2/5]  [190/313]  eta: 0:00:41  Lr: 0.001875  Loss: 0.0569  Acc@1: 93.7500 (88.5471)  Acc@5: 100.0000 (98.5275)  time: 0.3350  data: 0.0005  max mem: 2356
Train: Epoch[2/5]  [200/313]  eta: 0:00:38  Lr: 0.001875  Loss: -0.0552  Acc@1: 93.7500 (88.5261)  Acc@5: 100.0000 (98.5386)  time: 0.3331  data: 0.0005  max mem: 2356
Train: Epoch[2/5]  [210/313]  eta: 0:00:34  Lr: 0.001875  Loss: 0.3569  Acc@1: 87.5000 (88.3294)  Acc@5: 100.0000 (98.4893)  time: 0.3310  data: 0.0006  max mem: 2356
Train: Epoch[2/5]  [220/313]  eta: 0:00:31  Lr: 0.001875  Loss: 0.5684  Acc@1: 87.5000 (88.4050)  Acc@5: 100.0000 (98.4729)  time: 0.3320  data: 0.0016  max mem: 2356
Train: Epoch[2/5]  [230/313]  eta: 0:00:27  Lr: 0.001875  Loss: 0.0573  Acc@1: 87.5000 (88.2305)  Acc@5: 100.0000 (98.4307)  time: 0.3330  data: 0.0016  max mem: 2356
Train: Epoch[2/5]  [240/313]  eta: 0:00:24  Lr: 0.001875  Loss: 0.1946  Acc@1: 87.5000 (88.2261)  Acc@5: 100.0000 (98.4959)  time: 0.3326  data: 0.0008  max mem: 2356
Train: Epoch[2/5]  [250/313]  eta: 0:00:21  Lr: 0.001875  Loss: 0.2753  Acc@1: 81.2500 (87.9233)  Acc@5: 100.0000 (98.5309)  time: 0.3325  data: 0.0012  max mem: 2356
Train: Epoch[2/5]  [260/313]  eta: 0:00:17  Lr: 0.001875  Loss: 0.0046  Acc@1: 87.5000 (87.9550)  Acc@5: 100.0000 (98.5632)  time: 0.3346  data: 0.0016  max mem: 2356
Train: Epoch[2/5]  [270/313]  eta: 0:00:14  Lr: 0.001875  Loss: -0.0449  Acc@1: 93.7500 (88.1458)  Acc@5: 100.0000 (98.5932)  time: 0.3352  data: 0.0010  max mem: 2356
Train: Epoch[2/5]  [280/313]  eta: 0:00:11  Lr: 0.001875  Loss: 0.0131  Acc@1: 87.5000 (88.0116)  Acc@5: 100.0000 (98.5988)  time: 0.3324  data: 0.0003  max mem: 2356
Train: Epoch[2/5]  [290/313]  eta: 0:00:07  Lr: 0.001875  Loss: 0.1144  Acc@1: 87.5000 (87.9510)  Acc@5: 100.0000 (98.5395)  time: 0.3310  data: 0.0003  max mem: 2356
Train: Epoch[2/5]  [300/313]  eta: 0:00:04  Lr: 0.001875  Loss: 0.1853  Acc@1: 87.5000 (88.1229)  Acc@5: 100.0000 (98.5673)  time: 0.3340  data: 0.0004  max mem: 2356
Train: Epoch[2/5]  [310/313]  eta: 0:00:01  Lr: 0.001875  Loss: -0.1044  Acc@1: 93.7500 (88.1431)  Acc@5: 100.0000 (98.5531)  time: 0.3356  data: 0.0005  max mem: 2356
Train: Epoch[2/5]  [312/313]  eta: 0:00:00  Lr: 0.001875  Loss: 0.2397  Acc@1: 93.7500 (88.1000)  Acc@5: 100.0000 (98.5600)  time: 0.3295  data: 0.0005  max mem: 2356
Train: Epoch[2/5] Total time: 0:01:45 (0.3360 s / it)
{0: {0: 22412, 1: 24815, 2: 19998, 3: 12102, 4: 7737, 5: 7897, 6: 7115, 7: 2660, 8: 0, 9: 0}, 1: {0: 1577, 1: 208, 2: 5200, 3: 12775, 4: 17024, 5: 16965, 6: 17861, 7: 7317, 8: 0, 9: 0}, 2: {0: 3518, 1: 6779, 2: 5327, 3: 9830, 4: 7541, 5: 7967, 6: 7212, 7: 2647, 8: 0, 9: 0}, 3: {0: 21486, 1: 20777, 2: 18903, 3: 14840, 4: 17372, 5: 17103, 6: 18038, 7: 7419, 8: 0, 9: 0}, 4: {0: 16124, 1: 10227, 2: 6432, 3: 10102, 4: 7685, 5: 7874, 6: 7043, 7: 2652, 8: 0, 9: 0}, 5: {0: 23402, 1: 24357, 2: 21714, 3: 15057, 4: 17322, 5: 16935, 6: 17805, 7: 7386, 8: 0, 9: 0}, 6: {0: 9472, 1: 12148, 2: 17669, 3: 14460, 4: 17318, 5: 17115, 6: 17934, 7: 7337, 8: 0, 9: 0}, 7: {0: 752, 1: 676, 2: 4577, 3: 10334, 4: 7679, 5: 7891, 6: 6959, 7: 2584, 8: 0, 9: 0}, 8: {0: 24269, 1: 24959, 2: 24373, 3: 23260, 4: 19009, 5: 14409, 6: 6643, 7: 2183, 8: 0, 9: 0}, 9: {0: 1988, 1: 54, 2: 807, 3: 2240, 4: 6313, 5: 10844, 6: 18390, 7: 7815, 8: 0, 9: 0}}
Averaged stats: Lr: 0.001875  Loss: 0.2397  Acc@1: 93.7500 (88.1000)  Acc@5: 100.0000 (98.5600)
Train: Epoch[3/5]  [  0/313]  eta: 0:03:40  Lr: 0.001875  Loss: 0.2334  Acc@1: 75.0000 (75.0000)  Acc@5: 100.0000 (100.0000)  time: 0.7045  data: 0.3642  max mem: 2356
Train: Epoch[3/5]  [ 10/313]  eta: 0:01:52  Lr: 0.001875  Loss: 0.2763  Acc@1: 93.7500 (88.0682)  Acc@5: 100.0000 (98.8636)  time: 0.3726  data: 0.0344  max mem: 2356
Train: Epoch[3/5]  [ 20/313]  eta: 0:01:44  Lr: 0.001875  Loss: 0.2362  Acc@1: 81.2500 (84.8214)  Acc@5: 100.0000 (98.2143)  time: 0.3376  data: 0.0009  max mem: 2356
Train: Epoch[3/5]  [ 30/313]  eta: 0:01:38  Lr: 0.001875  Loss: 0.1884  Acc@1: 87.5000 (86.4919)  Acc@5: 100.0000 (98.3871)  time: 0.3364  data: 0.0008  max mem: 2356
Train: Epoch[3/5]  [ 40/313]  eta: 0:01:34  Lr: 0.001875  Loss: 0.2194  Acc@1: 87.5000 (87.0427)  Acc@5: 100.0000 (98.3232)  time: 0.3393  data: 0.0020  max mem: 2356
Train: Epoch[3/5]  [ 50/313]  eta: 0:01:31  Lr: 0.001875  Loss: 0.0396  Acc@1: 87.5000 (87.8676)  Acc@5: 100.0000 (98.5294)  time: 0.3443  data: 0.0017  max mem: 2356
Train: Epoch[3/5]  [ 60/313]  eta: 0:01:27  Lr: 0.001875  Loss: 0.1006  Acc@1: 87.5000 (88.0123)  Acc@5: 100.0000 (98.3607)  time: 0.3444  data: 0.0014  max mem: 2356
Train: Epoch[3/5]  [ 70/313]  eta: 0:01:23  Lr: 0.001875  Loss: -0.0986  Acc@1: 87.5000 (88.0282)  Acc@5: 100.0000 (98.2394)  time: 0.3385  data: 0.0015  max mem: 2356
Train: Epoch[3/5]  [ 80/313]  eta: 0:01:20  Lr: 0.001875  Loss: 0.5066  Acc@1: 87.5000 (88.1173)  Acc@5: 100.0000 (98.2253)  time: 0.3381  data: 0.0011  max mem: 2356
Train: Epoch[3/5]  [ 90/313]  eta: 0:01:16  Lr: 0.001875  Loss: 0.1338  Acc@1: 87.5000 (87.9121)  Acc@5: 100.0000 (98.2830)  time: 0.3392  data: 0.0012  max mem: 2356
Train: Epoch[3/5]  [100/313]  eta: 0:01:13  Lr: 0.001875  Loss: 0.0342  Acc@1: 87.5000 (87.8713)  Acc@5: 100.0000 (98.3292)  time: 0.3380  data: 0.0008  max mem: 2356
Train: Epoch[3/5]  [110/313]  eta: 0:01:09  Lr: 0.001875  Loss: 0.3468  Acc@1: 87.5000 (87.8378)  Acc@5: 100.0000 (98.4234)  time: 0.3392  data: 0.0012  max mem: 2356
Train: Epoch[3/5]  [120/313]  eta: 0:01:06  Lr: 0.001875  Loss: 0.4943  Acc@1: 87.5000 (87.5517)  Acc@5: 100.0000 (98.3988)  time: 0.3436  data: 0.0016  max mem: 2356
Train: Epoch[3/5]  [130/313]  eta: 0:01:02  Lr: 0.001875  Loss: 0.1962  Acc@1: 87.5000 (87.5954)  Acc@5: 100.0000 (98.4256)  time: 0.3428  data: 0.0018  max mem: 2356
Train: Epoch[3/5]  [140/313]  eta: 0:00:59  Lr: 0.001875  Loss: -0.1463  Acc@1: 87.5000 (87.5887)  Acc@5: 100.0000 (98.3156)  time: 0.3402  data: 0.0020  max mem: 2356
Train: Epoch[3/5]  [150/313]  eta: 0:00:55  Lr: 0.001875  Loss: -0.0801  Acc@1: 87.5000 (87.6656)  Acc@5: 100.0000 (98.3030)  time: 0.3445  data: 0.0018  max mem: 2356
Train: Epoch[3/5]  [160/313]  eta: 0:00:52  Lr: 0.001875  Loss: 0.5590  Acc@1: 87.5000 (87.5388)  Acc@5: 100.0000 (98.3307)  time: 0.3443  data: 0.0012  max mem: 2356
Train: Epoch[3/5]  [170/313]  eta: 0:00:48  Lr: 0.001875  Loss: -0.0202  Acc@1: 87.5000 (87.5731)  Acc@5: 100.0000 (98.4284)  time: 0.3372  data: 0.0005  max mem: 2356
Train: Epoch[3/5]  [180/313]  eta: 0:00:45  Lr: 0.001875  Loss: 0.1195  Acc@1: 87.5000 (87.7072)  Acc@5: 100.0000 (98.4116)  time: 0.3331  data: 0.0004  max mem: 2356
Train: Epoch[3/5]  [190/313]  eta: 0:00:41  Lr: 0.001875  Loss: 0.0986  Acc@1: 87.5000 (87.3691)  Acc@5: 100.0000 (98.3966)  time: 0.3335  data: 0.0004  max mem: 2356
Train: Epoch[3/5]  [200/313]  eta: 0:00:38  Lr: 0.001875  Loss: -0.1206  Acc@1: 87.5000 (87.6555)  Acc@5: 100.0000 (98.3831)  time: 0.3330  data: 0.0003  max mem: 2356
Train: Epoch[3/5]  [210/313]  eta: 0:00:35  Lr: 0.001875  Loss: -0.0836  Acc@1: 87.5000 (87.5592)  Acc@5: 100.0000 (98.3709)  time: 0.3337  data: 0.0003  max mem: 2356
Train: Epoch[3/5]  [220/313]  eta: 0:00:31  Lr: 0.001875  Loss: 0.0399  Acc@1: 87.5000 (87.7545)  Acc@5: 100.0000 (98.3880)  time: 0.3353  data: 0.0004  max mem: 2356
Train: Epoch[3/5]  [230/313]  eta: 0:00:28  Lr: 0.001875  Loss: -0.0783  Acc@1: 87.5000 (87.8517)  Acc@5: 100.0000 (98.4037)  time: 0.3351  data: 0.0004  max mem: 2356
Train: Epoch[3/5]  [240/313]  eta: 0:00:24  Lr: 0.001875  Loss: 0.1403  Acc@1: 87.5000 (87.8631)  Acc@5: 100.0000 (98.4180)  time: 0.3338  data: 0.0004  max mem: 2356
Train: Epoch[3/5]  [250/313]  eta: 0:00:21  Lr: 0.001875  Loss: -0.0815  Acc@1: 87.5000 (87.9233)  Acc@5: 100.0000 (98.4064)  time: 0.3333  data: 0.0004  max mem: 2356
Train: Epoch[3/5]  [260/313]  eta: 0:00:17  Lr: 0.001875  Loss: -0.0699  Acc@1: 87.5000 (87.9071)  Acc@5: 100.0000 (98.3956)  time: 0.3337  data: 0.0004  max mem: 2356
Train: Epoch[3/5]  [270/313]  eta: 0:00:14  Lr: 0.001875  Loss: 0.0754  Acc@1: 87.5000 (87.9843)  Acc@5: 100.0000 (98.4087)  time: 0.3334  data: 0.0005  max mem: 2356
Train: Epoch[3/5]  [280/313]  eta: 0:00:11  Lr: 0.001875  Loss: 0.3007  Acc@1: 87.5000 (88.0338)  Acc@5: 100.0000 (98.4431)  time: 0.3322  data: 0.0004  max mem: 2356
Train: Epoch[3/5]  [290/313]  eta: 0:00:07  Lr: 0.001875  Loss: 0.1431  Acc@1: 87.5000 (87.9296)  Acc@5: 100.0000 (98.4966)  time: 0.3319  data: 0.0007  max mem: 2356
Train: Epoch[3/5]  [300/313]  eta: 0:00:04  Lr: 0.001875  Loss: -0.0948  Acc@1: 87.5000 (88.0399)  Acc@5: 100.0000 (98.5050)  time: 0.3332  data: 0.0014  max mem: 2356
Train: Epoch[3/5]  [310/313]  eta: 0:00:01  Lr: 0.001875  Loss: 0.2574  Acc@1: 87.5000 (88.0225)  Acc@5: 100.0000 (98.5129)  time: 0.3329  data: 0.0010  max mem: 2356
Train: Epoch[3/5]  [312/313]  eta: 0:00:00  Lr: 0.001875  Loss: 0.4417  Acc@1: 87.5000 (88.0200)  Acc@5: 100.0000 (98.5200)  time: 0.3247  data: 0.0009  max mem: 2356
Train: Epoch[3/5] Total time: 0:01:45 (0.3381 s / it)
{0: {0: 22412, 1: 24815, 2: 19998, 3: 12102, 4: 7737, 5: 7897, 6: 7115, 7: 4147, 8: 0, 9: 0}, 1: {0: 1577, 1: 208, 2: 5200, 3: 12775, 4: 17024, 5: 16965, 6: 17861, 7: 10796, 8: 0, 9: 0}, 2: {0: 3518, 1: 6779, 2: 5327, 3: 9830, 4: 7541, 5: 7967, 6: 7212, 7: 4096, 8: 0, 9: 0}, 3: {0: 21486, 1: 20777, 2: 18903, 3: 14840, 4: 17372, 5: 17103, 6: 18038, 7: 11002, 8: 0, 9: 0}, 4: {0: 16124, 1: 10227, 2: 6432, 3: 10102, 4: 7685, 5: 7874, 6: 7043, 7: 4161, 8: 0, 9: 0}, 5: {0: 23402, 1: 24357, 2: 21714, 3: 15057, 4: 17322, 5: 16935, 6: 17805, 7: 10996, 8: 0, 9: 0}, 6: {0: 9472, 1: 12148, 2: 17669, 3: 14460, 4: 17318, 5: 17115, 6: 17934, 7: 10827, 8: 0, 9: 0}, 7: {0: 752, 1: 676, 2: 4577, 3: 10334, 4: 7679, 5: 7891, 6: 6959, 7: 3978, 8: 0, 9: 0}, 8: {0: 24269, 1: 24959, 2: 24373, 3: 23260, 4: 19009, 5: 14409, 6: 6643, 7: 3474, 8: 0, 9: 0}, 9: {0: 1988, 1: 54, 2: 807, 3: 2240, 4: 6313, 5: 10844, 6: 18390, 7: 11523, 8: 0, 9: 0}}
Averaged stats: Lr: 0.001875  Loss: 0.4417  Acc@1: 87.5000 (88.0200)  Acc@5: 100.0000 (98.5200)
Train: Epoch[4/5]  [  0/313]  eta: 0:03:26  Lr: 0.001875  Loss: 0.1694  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (100.0000)  time: 0.6590  data: 0.3253  max mem: 2356
Train: Epoch[4/5]  [ 10/313]  eta: 0:01:49  Lr: 0.001875  Loss: 0.3279  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (99.4318)  time: 0.3627  data: 0.0300  max mem: 2356
Train: Epoch[4/5]  [ 20/313]  eta: 0:01:41  Lr: 0.001875  Loss: 0.1813  Acc@1: 87.5000 (86.3095)  Acc@5: 100.0000 (99.7024)  time: 0.3322  data: 0.0004  max mem: 2356
Train: Epoch[4/5]  [ 30/313]  eta: 0:01:37  Lr: 0.001875  Loss: -0.1452  Acc@1: 81.2500 (85.8871)  Acc@5: 100.0000 (99.3952)  time: 0.3335  data: 0.0015  max mem: 2356
Train: Epoch[4/5]  [ 40/313]  eta: 0:01:33  Lr: 0.001875  Loss: 0.0670  Acc@1: 87.5000 (86.2805)  Acc@5: 100.0000 (98.7805)  time: 0.3357  data: 0.0016  max mem: 2356
Train: Epoch[4/5]  [ 50/313]  eta: 0:01:29  Lr: 0.001875  Loss: -0.1781  Acc@1: 87.5000 (87.0098)  Acc@5: 100.0000 (98.8971)  time: 0.3357  data: 0.0005  max mem: 2356
Train: Epoch[4/5]  [ 60/313]  eta: 0:01:26  Lr: 0.001875  Loss: 0.3597  Acc@1: 87.5000 (86.8852)  Acc@5: 100.0000 (98.6680)  time: 0.3386  data: 0.0022  max mem: 2356
Train: Epoch[4/5]  [ 70/313]  eta: 0:01:22  Lr: 0.001875  Loss: -0.1980  Acc@1: 87.5000 (87.8521)  Acc@5: 100.0000 (98.6796)  time: 0.3419  data: 0.0026  max mem: 2356
Train: Epoch[4/5]  [ 80/313]  eta: 0:01:19  Lr: 0.001875  Loss: 0.0012  Acc@1: 93.7500 (88.4259)  Acc@5: 100.0000 (98.8426)  time: 0.3411  data: 0.0012  max mem: 2356
Train: Epoch[4/5]  [ 90/313]  eta: 0:01:16  Lr: 0.001875  Loss: 0.1968  Acc@1: 93.7500 (88.5989)  Acc@5: 100.0000 (98.9011)  time: 0.3405  data: 0.0012  max mem: 2356
Train: Epoch[4/5]  [100/313]  eta: 0:01:12  Lr: 0.001875  Loss: 0.3796  Acc@1: 93.7500 (88.7376)  Acc@5: 100.0000 (98.9480)  time: 0.3415  data: 0.0008  max mem: 2356
Train: Epoch[4/5]  [110/313]  eta: 0:01:09  Lr: 0.001875  Loss: -0.0353  Acc@1: 93.7500 (88.7387)  Acc@5: 100.0000 (98.9302)  time: 0.3407  data: 0.0005  max mem: 2356
Train: Epoch[4/5]  [120/313]  eta: 0:01:05  Lr: 0.001875  Loss: 0.1173  Acc@1: 87.5000 (88.5847)  Acc@5: 100.0000 (98.8120)  time: 0.3375  data: 0.0007  max mem: 2356
Train: Epoch[4/5]  [130/313]  eta: 0:01:02  Lr: 0.001875  Loss: -0.0733  Acc@1: 87.5000 (88.5973)  Acc@5: 100.0000 (98.8073)  time: 0.3344  data: 0.0006  max mem: 2356
Train: Epoch[4/5]  [140/313]  eta: 0:00:58  Lr: 0.001875  Loss: 0.3833  Acc@1: 87.5000 (88.4752)  Acc@5: 100.0000 (98.6702)  time: 0.3348  data: 0.0004  max mem: 2356
Train: Epoch[4/5]  [150/313]  eta: 0:00:55  Lr: 0.001875  Loss: 0.5039  Acc@1: 87.5000 (88.2450)  Acc@5: 100.0000 (98.5927)  time: 0.3366  data: 0.0010  max mem: 2356
Train: Epoch[4/5]  [160/313]  eta: 0:00:51  Lr: 0.001875  Loss: 0.2754  Acc@1: 87.5000 (88.5870)  Acc@5: 100.0000 (98.6413)  time: 0.3376  data: 0.0012  max mem: 2356
Train: Epoch[4/5]  [170/313]  eta: 0:00:48  Lr: 0.001875  Loss: 0.2044  Acc@1: 93.7500 (88.5965)  Acc@5: 100.0000 (98.6111)  time: 0.3396  data: 0.0018  max mem: 2356
Train: Epoch[4/5]  [180/313]  eta: 0:00:45  Lr: 0.001875  Loss: 0.3093  Acc@1: 87.5000 (88.5014)  Acc@5: 100.0000 (98.5152)  time: 0.3381  data: 0.0017  max mem: 2356
Train: Epoch[4/5]  [190/313]  eta: 0:00:41  Lr: 0.001875  Loss: -0.1053  Acc@1: 87.5000 (88.5144)  Acc@5: 100.0000 (98.4948)  time: 0.3345  data: 0.0011  max mem: 2356
Train: Epoch[4/5]  [200/313]  eta: 0:00:38  Lr: 0.001875  Loss: 0.0020  Acc@1: 87.5000 (88.6194)  Acc@5: 100.0000 (98.5697)  time: 0.3374  data: 0.0014  max mem: 2356
Train: Epoch[4/5]  [210/313]  eta: 0:00:34  Lr: 0.001875  Loss: -0.1082  Acc@1: 87.5000 (88.6848)  Acc@5: 100.0000 (98.4893)  time: 0.3429  data: 0.0009  max mem: 2356
Train: Epoch[4/5]  [220/313]  eta: 0:00:31  Lr: 0.001875  Loss: -0.0103  Acc@1: 87.5000 (88.7161)  Acc@5: 100.0000 (98.5577)  time: 0.3397  data: 0.0005  max mem: 2356
Train: Epoch[4/5]  [230/313]  eta: 0:00:28  Lr: 0.001875  Loss: -0.1228  Acc@1: 93.7500 (88.7716)  Acc@5: 100.0000 (98.5660)  time: 0.3343  data: 0.0004  max mem: 2356
Train: Epoch[4/5]  [240/313]  eta: 0:00:24  Lr: 0.001875  Loss: -0.0632  Acc@1: 93.7500 (88.8745)  Acc@5: 100.0000 (98.6255)  time: 0.3337  data: 0.0004  max mem: 2356
Train: Epoch[4/5]  [250/313]  eta: 0:00:21  Lr: 0.001875  Loss: 0.1452  Acc@1: 93.7500 (89.0438)  Acc@5: 100.0000 (98.6554)  time: 0.3336  data: 0.0004  max mem: 2356
Train: Epoch[4/5]  [260/313]  eta: 0:00:17  Lr: 0.001875  Loss: 0.3765  Acc@1: 87.5000 (89.0326)  Acc@5: 100.0000 (98.6351)  time: 0.3336  data: 0.0004  max mem: 2356
Train: Epoch[4/5]  [270/313]  eta: 0:00:14  Lr: 0.001875  Loss: 0.0163  Acc@1: 87.5000 (88.9530)  Acc@5: 100.0000 (98.6624)  time: 0.3341  data: 0.0011  max mem: 2356
Train: Epoch[4/5]  [280/313]  eta: 0:00:11  Lr: 0.001875  Loss: -0.1058  Acc@1: 93.7500 (89.0125)  Acc@5: 100.0000 (98.6432)  time: 0.3357  data: 0.0011  max mem: 2356
Train: Epoch[4/5]  [290/313]  eta: 0:00:07  Lr: 0.001875  Loss: 0.0291  Acc@1: 87.5000 (89.0034)  Acc@5: 100.0000 (98.6684)  time: 0.3353  data: 0.0005  max mem: 2356
Train: Epoch[4/5]  [300/313]  eta: 0:00:04  Lr: 0.001875  Loss: 0.2020  Acc@1: 87.5000 (88.9950)  Acc@5: 100.0000 (98.6503)  time: 0.3348  data: 0.0005  max mem: 2356
Train: Epoch[4/5]  [310/313]  eta: 0:00:01  Lr: 0.001875  Loss: 0.1442  Acc@1: 87.5000 (89.0474)  Acc@5: 100.0000 (98.6736)  time: 0.3344  data: 0.0004  max mem: 2356
Train: Epoch[4/5]  [312/313]  eta: 0:00:00  Lr: 0.001875  Loss: -0.0769  Acc@1: 87.5000 (89.1000)  Acc@5: 100.0000 (98.6800)  time: 0.3263  data: 0.0004  max mem: 2356
Train: Epoch[4/5] Total time: 0:01:45 (0.3375 s / it)
{0: {0: 22412, 1: 24815, 2: 19998, 3: 12102, 4: 7737, 5: 7897, 6: 7115, 7: 5647, 8: 0, 9: 0}, 1: {0: 1577, 1: 208, 2: 5200, 3: 12775, 4: 17024, 5: 16965, 6: 17861, 7: 14265, 8: 0, 9: 0}, 2: {0: 3518, 1: 6779, 2: 5327, 3: 9830, 4: 7541, 5: 7967, 6: 7212, 7: 5609, 8: 0, 9: 0}, 3: {0: 21486, 1: 20777, 2: 18903, 3: 14840, 4: 17372, 5: 17103, 6: 18038, 7: 14515, 8: 0, 9: 0}, 4: {0: 16124, 1: 10227, 2: 6432, 3: 10102, 4: 7685, 5: 7874, 6: 7043, 7: 5658, 8: 0, 9: 0}, 5: {0: 23402, 1: 24357, 2: 21714, 3: 15057, 4: 17322, 5: 16935, 6: 17805, 7: 14502, 8: 0, 9: 0}, 6: {0: 9472, 1: 12148, 2: 17669, 3: 14460, 4: 17318, 5: 17115, 6: 17934, 7: 14320, 8: 0, 9: 0}, 7: {0: 752, 1: 676, 2: 4577, 3: 10334, 4: 7679, 5: 7891, 6: 6959, 7: 5488, 8: 0, 9: 0}, 8: {0: 24269, 1: 24959, 2: 24373, 3: 23260, 4: 19009, 5: 14409, 6: 6643, 7: 4836, 8: 0, 9: 0}, 9: {0: 1988, 1: 54, 2: 807, 3: 2240, 4: 6313, 5: 10844, 6: 18390, 7: 15160, 8: 0, 9: 0}}
Averaged stats: Lr: 0.001875  Loss: -0.0769  Acc@1: 87.5000 (89.1000)  Acc@5: 100.0000 (98.6800)
Train: Epoch[5/5]  [  0/313]  eta: 0:03:33  Lr: 0.001875  Loss: 0.0346  Acc@1: 93.7500 (93.7500)  Acc@5: 93.7500 (93.7500)  time: 0.6809  data: 0.3458  max mem: 2356
Train: Epoch[5/5]  [ 10/313]  eta: 0:01:52  Lr: 0.001875  Loss: 0.2814  Acc@1: 81.2500 (83.5227)  Acc@5: 100.0000 (98.2955)  time: 0.3708  data: 0.0321  max mem: 2356
Train: Epoch[5/5]  [ 20/313]  eta: 0:01:43  Lr: 0.001875  Loss: 0.2500  Acc@1: 87.5000 (88.0952)  Acc@5: 100.0000 (98.8095)  time: 0.3352  data: 0.0005  max mem: 2356
Train: Epoch[5/5]  [ 30/313]  eta: 0:01:37  Lr: 0.001875  Loss: 0.3860  Acc@1: 93.7500 (88.5081)  Acc@5: 100.0000 (98.9919)  time: 0.3315  data: 0.0003  max mem: 2356
Train: Epoch[5/5]  [ 40/313]  eta: 0:01:33  Lr: 0.001875  Loss: -0.0198  Acc@1: 87.5000 (88.5671)  Acc@5: 100.0000 (98.7805)  time: 0.3329  data: 0.0010  max mem: 2356
Train: Epoch[5/5]  [ 50/313]  eta: 0:01:29  Lr: 0.001875  Loss: 0.1594  Acc@1: 87.5000 (88.8480)  Acc@5: 100.0000 (98.8971)  time: 0.3335  data: 0.0010  max mem: 2356
Train: Epoch[5/5]  [ 60/313]  eta: 0:01:25  Lr: 0.001875  Loss: 0.4001  Acc@1: 87.5000 (88.9344)  Acc@5: 100.0000 (98.7705)  time: 0.3332  data: 0.0009  max mem: 2356
Train: Epoch[5/5]  [ 70/313]  eta: 0:01:22  Lr: 0.001875  Loss: 0.0296  Acc@1: 87.5000 (88.9965)  Acc@5: 100.0000 (98.9437)  time: 0.3316  data: 0.0009  max mem: 2356
Train: Epoch[5/5]  [ 80/313]  eta: 0:01:18  Lr: 0.001875  Loss: 0.1264  Acc@1: 87.5000 (89.1204)  Acc@5: 100.0000 (98.9969)  time: 0.3306  data: 0.0003  max mem: 2356
Train: Epoch[5/5]  [ 90/313]  eta: 0:01:15  Lr: 0.001875  Loss: 0.2495  Acc@1: 87.5000 (89.1484)  Acc@5: 100.0000 (98.9011)  time: 0.3311  data: 0.0004  max mem: 2356
Train: Epoch[5/5]  [100/313]  eta: 0:01:11  Lr: 0.001875  Loss: -0.1035  Acc@1: 93.7500 (89.4802)  Acc@5: 100.0000 (98.7624)  time: 0.3321  data: 0.0004  max mem: 2356
Train: Epoch[5/5]  [110/313]  eta: 0:01:08  Lr: 0.001875  Loss: -0.1348  Acc@1: 93.7500 (89.6959)  Acc@5: 100.0000 (98.8739)  time: 0.3356  data: 0.0004  max mem: 2356
Train: Epoch[5/5]  [120/313]  eta: 0:01:04  Lr: 0.001875  Loss: -0.0511  Acc@1: 93.7500 (89.6694)  Acc@5: 100.0000 (98.9669)  time: 0.3368  data: 0.0007  max mem: 2356
Train: Epoch[5/5]  [130/313]  eta: 0:01:01  Lr: 0.001875  Loss: 0.1323  Acc@1: 87.5000 (89.8378)  Acc@5: 100.0000 (98.9504)  time: 0.3365  data: 0.0012  max mem: 2356
Train: Epoch[5/5]  [140/313]  eta: 0:00:58  Lr: 0.001875  Loss: 0.1002  Acc@1: 93.7500 (89.8936)  Acc@5: 100.0000 (98.9805)  time: 0.3374  data: 0.0016  max mem: 2356
Train: Epoch[5/5]  [150/313]  eta: 0:00:54  Lr: 0.001875  Loss: 0.1423  Acc@1: 87.5000 (89.8179)  Acc@5: 100.0000 (99.0066)  time: 0.3390  data: 0.0012  max mem: 2356
Train: Epoch[5/5]  [160/313]  eta: 0:00:51  Lr: 0.001875  Loss: -0.1019  Acc@1: 87.5000 (89.8680)  Acc@5: 100.0000 (99.0295)  time: 0.3403  data: 0.0015  max mem: 2356
Train: Epoch[5/5]  [170/313]  eta: 0:00:48  Lr: 0.001875  Loss: 0.1082  Acc@1: 87.5000 (89.7295)  Acc@5: 100.0000 (99.0497)  time: 0.3404  data: 0.0027  max mem: 2356
Train: Epoch[5/5]  [180/313]  eta: 0:00:44  Lr: 0.001875  Loss: -0.1184  Acc@1: 87.5000 (89.7790)  Acc@5: 100.0000 (99.0677)  time: 0.3427  data: 0.0019  max mem: 2356
Train: Epoch[5/5]  [190/313]  eta: 0:00:41  Lr: 0.001875  Loss: 0.1044  Acc@1: 87.5000 (89.7251)  Acc@5: 100.0000 (98.9856)  time: 0.3426  data: 0.0007  max mem: 2356
Train: Epoch[5/5]  [200/313]  eta: 0:00:38  Lr: 0.001875  Loss: -0.0324  Acc@1: 87.5000 (89.8321)  Acc@5: 100.0000 (98.9428)  time: 0.3407  data: 0.0011  max mem: 2356
Train: Epoch[5/5]  [210/313]  eta: 0:00:34  Lr: 0.001875  Loss: -0.0107  Acc@1: 93.7500 (89.9882)  Acc@5: 100.0000 (98.9336)  time: 0.3384  data: 0.0020  max mem: 2356
Train: Epoch[5/5]  [220/313]  eta: 0:00:31  Lr: 0.001875  Loss: 0.2814  Acc@1: 93.7500 (89.9887)  Acc@5: 100.0000 (98.8688)  time: 0.3399  data: 0.0038  max mem: 2356
Train: Epoch[5/5]  [230/313]  eta: 0:00:28  Lr: 0.001875  Loss: -0.0171  Acc@1: 87.5000 (89.9351)  Acc@5: 100.0000 (98.9177)  time: 0.3414  data: 0.0035  max mem: 2356
Train: Epoch[5/5]  [240/313]  eta: 0:00:24  Lr: 0.001875  Loss: 0.0779  Acc@1: 87.5000 (89.9118)  Acc@5: 100.0000 (98.8589)  time: 0.3414  data: 0.0016  max mem: 2356
Train: Epoch[5/5]  [250/313]  eta: 0:00:21  Lr: 0.001875  Loss: 0.2136  Acc@1: 87.5000 (89.8904)  Acc@5: 100.0000 (98.8546)  time: 0.3431  data: 0.0023  max mem: 2356
Train: Epoch[5/5]  [260/313]  eta: 0:00:17  Lr: 0.001875  Loss: 0.2126  Acc@1: 93.7500 (89.9665)  Acc@5: 100.0000 (98.8985)  time: 0.3401  data: 0.0024  max mem: 2356
Train: Epoch[5/5]  [270/313]  eta: 0:00:14  Lr: 0.001875  Loss: 0.1496  Acc@1: 93.7500 (90.0138)  Acc@5: 100.0000 (98.9161)  time: 0.3352  data: 0.0010  max mem: 2356
Train: Epoch[5/5]  [280/313]  eta: 0:00:11  Lr: 0.001875  Loss: -0.0787  Acc@1: 93.7500 (89.8354)  Acc@5: 100.0000 (98.9101)  time: 0.3350  data: 0.0004  max mem: 2356
Train: Epoch[5/5]  [290/313]  eta: 0:00:07  Lr: 0.001875  Loss: 0.0285  Acc@1: 87.5000 (89.8196)  Acc@5: 100.0000 (98.9261)  time: 0.3347  data: 0.0004  max mem: 2356
Train: Epoch[5/5]  [300/313]  eta: 0:00:04  Lr: 0.001875  Loss: 0.2407  Acc@1: 87.5000 (89.7633)  Acc@5: 100.0000 (98.9410)  time: 0.3330  data: 0.0004  max mem: 2356
Train: Epoch[5/5]  [310/313]  eta: 0:00:01  Lr: 0.001875  Loss: 0.2364  Acc@1: 87.5000 (89.5900)  Acc@5: 100.0000 (98.9349)  time: 0.3332  data: 0.0004  max mem: 2356
Train: Epoch[5/5]  [312/313]  eta: 0:00:00  Lr: 0.001875  Loss: -0.2010  Acc@1: 87.5000 (89.6200)  Acc@5: 100.0000 (98.9400)  time: 0.3248  data: 0.0004  max mem: 2356
Train: Epoch[5/5] Total time: 0:01:45 (0.3377 s / it)
{0: {0: 22412, 1: 24815, 2: 19998, 3: 12102, 4: 7737, 5: 7897, 6: 7115, 7: 7163, 8: 0, 9: 0}, 1: {0: 1577, 1: 208, 2: 5200, 3: 12775, 4: 17024, 5: 16965, 6: 17861, 7: 17752, 8: 0, 9: 0}, 2: {0: 3518, 1: 6779, 2: 5327, 3: 9830, 4: 7541, 5: 7967, 6: 7212, 7: 7116, 8: 0, 9: 0}, 3: {0: 21486, 1: 20777, 2: 18903, 3: 14840, 4: 17372, 5: 17103, 6: 18038, 7: 18004, 8: 0, 9: 0}, 4: {0: 16124, 1: 10227, 2: 6432, 3: 10102, 4: 7685, 5: 7874, 6: 7043, 7: 7174, 8: 0, 9: 0}, 5: {0: 23402, 1: 24357, 2: 21714, 3: 15057, 4: 17322, 5: 16935, 6: 17805, 7: 17989, 8: 0, 9: 0}, 6: {0: 9472, 1: 12148, 2: 17669, 3: 14460, 4: 17318, 5: 17115, 6: 17934, 7: 17802, 8: 0, 9: 0}, 7: {0: 752, 1: 676, 2: 4577, 3: 10334, 4: 7679, 5: 7891, 6: 6959, 7: 7005, 8: 0, 9: 0}, 8: {0: 24269, 1: 24959, 2: 24373, 3: 23260, 4: 19009, 5: 14409, 6: 6643, 7: 6241, 8: 0, 9: 0}, 9: {0: 1988, 1: 54, 2: 807, 3: 2240, 4: 6313, 5: 10844, 6: 18390, 7: 18754, 8: 0, 9: 0}}
Averaged stats: Lr: 0.001875  Loss: -0.2010  Acc@1: 87.5000 (89.6200)  Acc@5: 100.0000 (98.9400)
Test: [Task 1]  [ 0/63]  eta: 0:00:35  Loss: 0.8194 (0.8194)  Acc@1: 81.2500 (81.2500)  Acc@5: 100.0000 (100.0000)  time: 0.5651  data: 0.3572  max mem: 2356
Test: [Task 1]  [10/63]  eta: 0:00:12  Loss: 0.7043 (0.6292)  Acc@1: 81.2500 (84.0909)  Acc@5: 100.0000 (99.4318)  time: 0.2384  data: 0.0327  max mem: 2356
Test: [Task 1]  [20/63]  eta: 0:00:09  Loss: 0.7043 (0.6956)  Acc@1: 81.2500 (82.4405)  Acc@5: 100.0000 (98.8095)  time: 0.2060  data: 0.0003  max mem: 2356
Test: [Task 1]  [30/63]  eta: 0:00:07  Loss: 0.5897 (0.6659)  Acc@1: 81.2500 (83.4677)  Acc@5: 100.0000 (98.9919)  time: 0.2067  data: 0.0004  max mem: 2356
Test: [Task 1]  [40/63]  eta: 0:00:04  Loss: 0.5563 (0.6524)  Acc@1: 81.2500 (83.6890)  Acc@5: 100.0000 (99.0854)  time: 0.2070  data: 0.0004  max mem: 2356
Test: [Task 1]  [50/63]  eta: 0:00:02  Loss: 0.5400 (0.6291)  Acc@1: 87.5000 (84.5588)  Acc@5: 100.0000 (99.1422)  time: 0.2062  data: 0.0004  max mem: 2356
Test: [Task 1]  [60/63]  eta: 0:00:00  Loss: 0.5186 (0.6215)  Acc@1: 87.5000 (84.7336)  Acc@5: 100.0000 (98.9754)  time: 0.2056  data: 0.0003  max mem: 2356
Test: [Task 1]  [62/63]  eta: 0:00:00  Loss: 0.5186 (0.6223)  Acc@1: 87.5000 (84.9000)  Acc@5: 100.0000 (99.0000)  time: 0.2009  data: 0.0003  max mem: 2356
Test: [Task 1] Total time: 0:00:13 (0.2115 s / it)
* Acc@1 84.900 Acc@5 99.000 loss 0.622
Test: [Task 2]  [ 0/63]  eta: 0:00:37  Loss: 0.9637 (0.9637)  Acc@1: 75.0000 (75.0000)  Acc@5: 93.7500 (93.7500)  time: 0.5992  data: 0.3933  max mem: 2356
Test: [Task 2]  [10/63]  eta: 0:00:12  Loss: 0.7914 (0.8150)  Acc@1: 81.2500 (81.8182)  Acc@5: 100.0000 (96.5909)  time: 0.2434  data: 0.0361  max mem: 2356
Test: [Task 2]  [20/63]  eta: 0:00:09  Loss: 0.7914 (0.8739)  Acc@1: 81.2500 (78.8690)  Acc@5: 100.0000 (96.1310)  time: 0.2067  data: 0.0004  max mem: 2356
Test: [Task 2]  [30/63]  eta: 0:00:07  Loss: 0.7980 (0.8534)  Acc@1: 81.2500 (80.6452)  Acc@5: 100.0000 (95.7661)  time: 0.2064  data: 0.0008  max mem: 2356
Test: [Task 2]  [40/63]  eta: 0:00:04  Loss: 0.7119 (0.8248)  Acc@1: 81.2500 (81.4024)  Acc@5: 100.0000 (96.1890)  time: 0.2065  data: 0.0008  max mem: 2356
Test: [Task 2]  [50/63]  eta: 0:00:02  Loss: 0.7295 (0.8145)  Acc@1: 81.2500 (81.0049)  Acc@5: 100.0000 (96.4461)  time: 0.2060  data: 0.0007  max mem: 2356
Test: [Task 2]  [60/63]  eta: 0:00:00  Loss: 0.6853 (0.7929)  Acc@1: 81.2500 (81.5574)  Acc@5: 100.0000 (96.7213)  time: 0.2057  data: 0.0007  max mem: 2356
Test: [Task 2]  [62/63]  eta: 0:00:00  Loss: 0.6388 (0.7853)  Acc@1: 81.2500 (81.6000)  Acc@5: 100.0000 (96.8000)  time: 0.2007  data: 0.0007  max mem: 2356
Test: [Task 2] Total time: 0:00:13 (0.2120 s / it)
* Acc@1 81.600 Acc@5 96.800 loss 0.785
Test: [Task 3]  [ 0/63]  eta: 0:00:27  Loss: 0.5782 (0.5782)  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (100.0000)  time: 0.4326  data: 0.2262  max mem: 2356
Test: [Task 3]  [10/63]  eta: 0:00:12  Loss: 0.6159 (0.7431)  Acc@1: 81.2500 (80.6818)  Acc@5: 93.7500 (96.0227)  time: 0.2276  data: 0.0218  max mem: 2356
Test: [Task 3]  [20/63]  eta: 0:00:09  Loss: 0.7579 (0.7325)  Acc@1: 75.0000 (78.8690)  Acc@5: 100.0000 (97.0238)  time: 0.2072  data: 0.0017  max mem: 2356
Test: [Task 3]  [30/63]  eta: 0:00:07  Loss: 0.7185 (0.7398)  Acc@1: 75.0000 (78.8306)  Acc@5: 100.0000 (97.3790)  time: 0.2065  data: 0.0012  max mem: 2356
Test: [Task 3]  [40/63]  eta: 0:00:04  Loss: 0.7185 (0.7290)  Acc@1: 81.2500 (79.2683)  Acc@5: 100.0000 (97.5610)  time: 0.2076  data: 0.0008  max mem: 2356
Test: [Task 3]  [50/63]  eta: 0:00:02  Loss: 0.7522 (0.7338)  Acc@1: 81.2500 (80.2696)  Acc@5: 100.0000 (96.9363)  time: 0.2071  data: 0.0008  max mem: 2356
Test: [Task 3]  [60/63]  eta: 0:00:00  Loss: 0.8080 (0.7481)  Acc@1: 81.2500 (80.1230)  Acc@5: 93.7500 (97.0287)  time: 0.2054  data: 0.0003  max mem: 2356
Test: [Task 3]  [62/63]  eta: 0:00:00  Loss: 0.8615 (0.7540)  Acc@1: 81.2500 (79.7000)  Acc@5: 93.7500 (97.0000)  time: 0.2005  data: 0.0002  max mem: 2356
Test: [Task 3] Total time: 0:00:13 (0.2098 s / it)
* Acc@1 79.700 Acc@5 97.000 loss 0.754
Test: [Task 4]  [ 0/63]  eta: 0:00:33  Loss: 0.7128 (0.7128)  Acc@1: 81.2500 (81.2500)  Acc@5: 93.7500 (93.7500)  time: 0.5298  data: 0.3167  max mem: 2356
Test: [Task 4]  [10/63]  eta: 0:00:12  Loss: 0.6986 (0.6865)  Acc@1: 81.2500 (83.5227)  Acc@5: 93.7500 (95.4545)  time: 0.2344  data: 0.0291  max mem: 2356
Test: [Task 4]  [20/63]  eta: 0:00:09  Loss: 0.6177 (0.6897)  Acc@1: 81.2500 (82.7381)  Acc@5: 93.7500 (95.5357)  time: 0.2053  data: 0.0005  max mem: 2356
Test: [Task 4]  [30/63]  eta: 0:00:07  Loss: 0.5785 (0.6655)  Acc@1: 87.5000 (84.2742)  Acc@5: 100.0000 (95.9677)  time: 0.2067  data: 0.0005  max mem: 2356
Test: [Task 4]  [40/63]  eta: 0:00:04  Loss: 0.4202 (0.6042)  Acc@1: 93.7500 (86.2805)  Acc@5: 100.0000 (96.7988)  time: 0.2087  data: 0.0004  max mem: 2356
Test: [Task 4]  [50/63]  eta: 0:00:02  Loss: 0.4222 (0.6278)  Acc@1: 93.7500 (85.7843)  Acc@5: 100.0000 (96.4461)  time: 0.2130  data: 0.0019  max mem: 2356
Test: [Task 4]  [60/63]  eta: 0:00:00  Loss: 0.6114 (0.6372)  Acc@1: 87.5000 (85.3484)  Acc@5: 93.7500 (96.3115)  time: 0.2112  data: 0.0018  max mem: 2356
Test: [Task 4]  [62/63]  eta: 0:00:00  Loss: 0.5452 (0.6317)  Acc@1: 87.5000 (85.5000)  Acc@5: 93.7500 (96.3000)  time: 0.2040  data: 0.0013  max mem: 2356
Test: [Task 4] Total time: 0:00:13 (0.2129 s / it)
* Acc@1 85.500 Acc@5 96.300 loss 0.632
Test: [Task 5]  [ 0/63]  eta: 0:00:36  Loss: 0.2281 (0.2281)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)  time: 0.5838  data: 0.3612  max mem: 2356
Test: [Task 5]  [10/63]  eta: 0:00:12  Loss: 0.4079 (0.5490)  Acc@1: 93.7500 (89.7727)  Acc@5: 100.0000 (98.8636)  time: 0.2432  data: 0.0332  max mem: 2356
Test: [Task 5]  [20/63]  eta: 0:00:09  Loss: 0.4547 (0.4979)  Acc@1: 93.7500 (91.9643)  Acc@5: 100.0000 (98.2143)  time: 0.2083  data: 0.0004  max mem: 2356
Test: [Task 5]  [30/63]  eta: 0:00:07  Loss: 0.4856 (0.5101)  Acc@1: 93.7500 (91.5323)  Acc@5: 100.0000 (97.9839)  time: 0.2118  data: 0.0024  max mem: 2356
Test: [Task 5]  [40/63]  eta: 0:00:05  Loss: 0.4500 (0.4958)  Acc@1: 93.7500 (92.0732)  Acc@5: 100.0000 (98.0183)  time: 0.2123  data: 0.0026  max mem: 2356
Test: [Task 5]  [50/63]  eta: 0:00:02  Loss: 0.4451 (0.5043)  Acc@1: 93.7500 (91.5441)  Acc@5: 100.0000 (97.9167)  time: 0.2094  data: 0.0010  max mem: 2356
Test: [Task 5]  [60/63]  eta: 0:00:00  Loss: 0.5091 (0.5136)  Acc@1: 87.5000 (90.6762)  Acc@5: 100.0000 (97.8484)  time: 0.2086  data: 0.0008  max mem: 2356
Test: [Task 5]  [62/63]  eta: 0:00:00  Loss: 0.5158 (0.5300)  Acc@1: 87.5000 (90.4000)  Acc@5: 100.0000 (97.7000)  time: 0.2023  data: 0.0005  max mem: 2356
Test: [Task 5] Total time: 0:00:13 (0.2155 s / it)
* Acc@1 90.400 Acc@5 97.700 loss 0.530
Test: [Task 6]  [ 0/63]  eta: 0:00:49  Loss: 0.4466 (0.4466)  Acc@1: 81.2500 (81.2500)  Acc@5: 100.0000 (100.0000)  time: 0.7894  data: 0.5830  max mem: 2356
Test: [Task 6]  [10/63]  eta: 0:00:13  Loss: 0.6829 (0.6859)  Acc@1: 81.2500 (79.5455)  Acc@5: 100.0000 (97.1591)  time: 0.2612  data: 0.0533  max mem: 2356
Test: [Task 6]  [20/63]  eta: 0:00:10  Loss: 0.7160 (0.7393)  Acc@1: 81.2500 (78.5714)  Acc@5: 100.0000 (97.3214)  time: 0.2089  data: 0.0008  max mem: 2356
Test: [Task 6]  [30/63]  eta: 0:00:07  Loss: 0.6415 (0.7277)  Acc@1: 81.2500 (79.2339)  Acc@5: 100.0000 (97.7823)  time: 0.2098  data: 0.0015  max mem: 2356
Test: [Task 6]  [40/63]  eta: 0:00:05  Loss: 0.7045 (0.7690)  Acc@1: 75.0000 (77.2866)  Acc@5: 100.0000 (97.4085)  time: 0.2112  data: 0.0020  max mem: 2356
Test: [Task 6]  [50/63]  eta: 0:00:02  Loss: 0.7708 (0.7492)  Acc@1: 75.0000 (78.0637)  Acc@5: 100.0000 (97.5490)  time: 0.2126  data: 0.0019  max mem: 2356
Test: [Task 6]  [60/63]  eta: 0:00:00  Loss: 0.7662 (0.7584)  Acc@1: 81.2500 (78.4836)  Acc@5: 100.0000 (97.1311)  time: 0.2102  data: 0.0008  max mem: 2356
Test: [Task 6]  [62/63]  eta: 0:00:00  Loss: 0.7442 (0.7536)  Acc@1: 81.2500 (78.7000)  Acc@5: 100.0000 (97.2000)  time: 0.2053  data: 0.0008  max mem: 2356
Test: [Task 6] Total time: 0:00:13 (0.2195 s / it)
* Acc@1 78.700 Acc@5 97.200 loss 0.754
Test: [Task 7]  [ 0/63]  eta: 0:00:32  Loss: 0.7984 (0.7984)  Acc@1: 68.7500 (68.7500)  Acc@5: 100.0000 (100.0000)  time: 0.5194  data: 0.3106  max mem: 2356
Test: [Task 7]  [10/63]  eta: 0:00:12  Loss: 0.5594 (0.6519)  Acc@1: 81.2500 (81.2500)  Acc@5: 100.0000 (98.2955)  time: 0.2420  data: 0.0326  max mem: 2356
Test: [Task 7]  [20/63]  eta: 0:00:09  Loss: 0.5594 (0.6856)  Acc@1: 81.2500 (81.8452)  Acc@5: 100.0000 (96.7262)  time: 0.2097  data: 0.0026  max mem: 2356
Test: [Task 7]  [30/63]  eta: 0:00:07  Loss: 0.5782 (0.6759)  Acc@1: 81.2500 (82.8629)  Acc@5: 93.7500 (96.3710)  time: 0.2090  data: 0.0010  max mem: 2356
Test: [Task 7]  [40/63]  eta: 0:00:05  Loss: 0.5782 (0.6671)  Acc@1: 87.5000 (83.2317)  Acc@5: 100.0000 (96.7988)  time: 0.2117  data: 0.0027  max mem: 2356
Test: [Task 7]  [50/63]  eta: 0:00:02  Loss: 0.6480 (0.6905)  Acc@1: 81.2500 (82.8431)  Acc@5: 100.0000 (96.3235)  time: 0.2104  data: 0.0025  max mem: 2356
Test: [Task 7]  [60/63]  eta: 0:00:00  Loss: 0.6480 (0.6793)  Acc@1: 81.2500 (83.2992)  Acc@5: 93.7500 (96.4139)  time: 0.2088  data: 0.0013  max mem: 2356
Test: [Task 7]  [62/63]  eta: 0:00:00  Loss: 0.6480 (0.6767)  Acc@1: 81.2500 (83.2000)  Acc@5: 100.0000 (96.5000)  time: 0.2038  data: 0.0013  max mem: 2356
Test: [Task 7] Total time: 0:00:13 (0.2143 s / it)
* Acc@1 83.200 Acc@5 96.500 loss 0.677
Test: [Task 8]  [ 0/63]  eta: 0:00:30  Loss: 0.6084 (0.6084)  Acc@1: 93.7500 (93.7500)  Acc@5: 100.0000 (100.0000)  time: 0.4808  data: 0.2756  max mem: 2356
Test: [Task 8]  [10/63]  eta: 0:00:12  Loss: 0.5036 (0.5815)  Acc@1: 93.7500 (85.7955)  Acc@5: 100.0000 (97.7273)  time: 0.2380  data: 0.0290  max mem: 2356
Test: [Task 8]  [20/63]  eta: 0:00:09  Loss: 0.5248 (0.6122)  Acc@1: 87.5000 (85.4167)  Acc@5: 100.0000 (97.3214)  time: 0.2117  data: 0.0029  max mem: 2356
Test: [Task 8]  [30/63]  eta: 0:00:07  Loss: 0.5417 (0.5955)  Acc@1: 87.5000 (85.6855)  Acc@5: 100.0000 (97.9839)  time: 0.2086  data: 0.0011  max mem: 2356
Test: [Task 8]  [40/63]  eta: 0:00:04  Loss: 0.5421 (0.5970)  Acc@1: 87.5000 (85.5183)  Acc@5: 100.0000 (97.5610)  time: 0.2097  data: 0.0020  max mem: 2356
Test: [Task 8]  [50/63]  eta: 0:00:02  Loss: 0.6132 (0.5898)  Acc@1: 81.2500 (85.4167)  Acc@5: 100.0000 (97.6716)  time: 0.2125  data: 0.0038  max mem: 2356
Test: [Task 8]  [60/63]  eta: 0:00:00  Loss: 0.6543 (0.6079)  Acc@1: 81.2500 (84.3238)  Acc@5: 93.7500 (97.3361)  time: 0.2102  data: 0.0023  max mem: 2356
Test: [Task 8]  [62/63]  eta: 0:00:00  Loss: 0.6132 (0.5989)  Acc@1: 81.2500 (84.6000)  Acc@5: 100.0000 (97.4000)  time: 0.2054  data: 0.0023  max mem: 2356
Test: [Task 8] Total time: 0:00:13 (0.2143 s / it)
* Acc@1 84.600 Acc@5 97.400 loss 0.599
{0: {0: 194, 1: 796, 2: 203, 3: 805, 4: 195, 5: 798, 6: 804, 7: 205, 8: 114, 9: 886}, 1: {0: 441, 1: 555, 2: 444, 3: 559, 4: 441, 5: 552, 6: 558, 7: 450, 8: 355, 9: 645}, 2: {0: 225, 1: 761, 2: 238, 3: 774, 4: 225, 5: 762, 6: 775, 7: 240, 8: 162, 9: 838}, 3: {0: 478, 1: 506, 2: 488, 3: 522, 4: 478, 5: 510, 6: 522, 7: 496, 8: 325, 9: 675}, 4: {0: 377, 1: 615, 2: 378, 3: 623, 4: 378, 5: 617, 6: 621, 7: 391, 8: 284, 9: 716}, 5: {0: 400, 1: 594, 2: 407, 3: 598, 4: 399, 5: 592, 6: 601, 7: 409, 8: 315, 9: 685}, 6: {0: 436, 1: 555, 2: 444, 3: 564, 4: 436, 5: 554, 6: 564, 7: 447, 8: 338, 9: 662}, 7: {0: 442, 1: 549, 2: 447, 3: 560, 4: 441, 5: 553, 6: 560, 7: 449, 8: 364, 9: 635}}
[Average accuracy till task8]	Acc@1: 83.5750	Acc@5: 97.2375	Loss: 0.6691	Forgetting: 6.7714	Backward: -6.7714
Train: Epoch[1/5]  [  0/313]  eta: 0:03:17  Lr: 0.001875  Loss: 2.0544  Acc@1: 31.2500 (31.2500)  Acc@5: 68.7500 (68.7500)  time: 0.6314  data: 0.2692  max mem: 2356
Train: Epoch[1/5]  [ 10/313]  eta: 0:01:49  Lr: 0.001875  Loss: 1.7270  Acc@1: 50.0000 (53.4091)  Acc@5: 81.2500 (82.9545)  time: 0.3605  data: 0.0250  max mem: 2356
Train: Epoch[1/5]  [ 20/313]  eta: 0:01:41  Lr: 0.001875  Loss: 1.4164  Acc@1: 68.7500 (62.5000)  Acc@5: 93.7500 (88.6905)  time: 0.3332  data: 0.0005  max mem: 2356
Train: Epoch[1/5]  [ 30/313]  eta: 0:01:37  Lr: 0.001875  Loss: 1.1113  Acc@1: 81.2500 (69.3548)  Acc@5: 100.0000 (91.7339)  time: 0.3344  data: 0.0005  max mem: 2356
Train: Epoch[1/5]  [ 40/313]  eta: 0:01:33  Lr: 0.001875  Loss: 0.9434  Acc@1: 87.5000 (73.9329)  Acc@5: 100.0000 (93.1402)  time: 0.3348  data: 0.0005  max mem: 2356
Train: Epoch[1/5]  [ 50/313]  eta: 0:01:29  Lr: 0.001875  Loss: 0.8827  Acc@1: 87.5000 (76.8382)  Acc@5: 100.0000 (94.2402)  time: 0.3342  data: 0.0005  max mem: 2356
Train: Epoch[1/5]  [ 60/313]  eta: 0:01:25  Lr: 0.001875  Loss: 0.6163  Acc@1: 93.7500 (79.5082)  Acc@5: 100.0000 (95.0820)  time: 0.3343  data: 0.0012  max mem: 2356
Train: Epoch[1/5]  [ 70/313]  eta: 0:01:22  Lr: 0.001875  Loss: 0.9840  Acc@1: 93.7500 (80.5458)  Acc@5: 100.0000 (95.6866)  time: 0.3336  data: 0.0012  max mem: 2356
Train: Epoch[1/5]  [ 80/313]  eta: 0:01:18  Lr: 0.001875  Loss: 0.2764  Acc@1: 93.7500 (81.2500)  Acc@5: 100.0000 (96.1420)  time: 0.3344  data: 0.0007  max mem: 2356
Train: Epoch[1/5]  [ 90/313]  eta: 0:01:15  Lr: 0.001875  Loss: 0.2503  Acc@1: 93.7500 (82.3489)  Acc@5: 100.0000 (96.4973)  time: 0.3350  data: 0.0006  max mem: 2356
Train: Epoch[1/5]  [100/313]  eta: 0:01:11  Lr: 0.001875  Loss: 0.1402  Acc@1: 93.7500 (83.1683)  Acc@5: 100.0000 (96.7203)  time: 0.3338  data: 0.0003  max mem: 2356
Train: Epoch[1/5]  [110/313]  eta: 0:01:08  Lr: 0.001875  Loss: 0.4228  Acc@1: 87.5000 (83.4459)  Acc@5: 100.0000 (96.9032)  time: 0.3326  data: 0.0008  max mem: 2356
Train: Epoch[1/5]  [120/313]  eta: 0:01:04  Lr: 0.001875  Loss: 0.4811  Acc@1: 87.5000 (83.8326)  Acc@5: 100.0000 (97.0041)  time: 0.3315  data: 0.0008  max mem: 2356
Train: Epoch[1/5]  [130/313]  eta: 0:01:01  Lr: 0.001875  Loss: 0.3489  Acc@1: 87.5000 (84.1126)  Acc@5: 100.0000 (96.9943)  time: 0.3322  data: 0.0004  max mem: 2356
Train: Epoch[1/5]  [140/313]  eta: 0:00:58  Lr: 0.001875  Loss: 0.1381  Acc@1: 87.5000 (84.4415)  Acc@5: 100.0000 (97.1631)  time: 0.3331  data: 0.0004  max mem: 2356
Train: Epoch[1/5]  [150/313]  eta: 0:00:54  Lr: 0.001875  Loss: 0.1595  Acc@1: 87.5000 (84.8510)  Acc@5: 100.0000 (97.1854)  time: 0.3321  data: 0.0003  max mem: 2356
Train: Epoch[1/5]  [160/313]  eta: 0:00:51  Lr: 0.001875  Loss: 0.4339  Acc@1: 87.5000 (85.2096)  Acc@5: 100.0000 (97.2438)  time: 0.3324  data: 0.0005  max mem: 2356
Train: Epoch[1/5]  [170/313]  eta: 0:00:47  Lr: 0.001875  Loss: 0.0569  Acc@1: 87.5000 (85.4532)  Acc@5: 100.0000 (97.3684)  time: 0.3330  data: 0.0005  max mem: 2356
Train: Epoch[1/5]  [180/313]  eta: 0:00:44  Lr: 0.001875  Loss: 0.0493  Acc@1: 87.5000 (85.6699)  Acc@5: 100.0000 (97.4793)  time: 0.3351  data: 0.0005  max mem: 2356
Train: Epoch[1/5]  [190/313]  eta: 0:00:41  Lr: 0.001875  Loss: 0.0947  Acc@1: 87.5000 (85.7657)  Acc@5: 100.0000 (97.4804)  time: 0.3379  data: 0.0006  max mem: 2356
Train: Epoch[1/5]  [200/313]  eta: 0:00:37  Lr: 0.001875  Loss: 0.2320  Acc@1: 93.7500 (86.0386)  Acc@5: 100.0000 (97.6057)  time: 0.3392  data: 0.0019  max mem: 2356
Train: Epoch[1/5]  [210/313]  eta: 0:00:34  Lr: 0.001875  Loss: 0.5108  Acc@1: 87.5000 (85.9597)  Acc@5: 100.0000 (97.6600)  time: 0.3388  data: 0.0020  max mem: 2356
Train: Epoch[1/5]  [220/313]  eta: 0:00:31  Lr: 0.001875  Loss: 0.0801  Acc@1: 87.5000 (86.1991)  Acc@5: 100.0000 (97.7093)  time: 0.3414  data: 0.0012  max mem: 2356
Train: Epoch[1/5]  [230/313]  eta: 0:00:27  Lr: 0.001875  Loss: -0.1119  Acc@1: 93.7500 (86.4719)  Acc@5: 100.0000 (97.8084)  time: 0.3437  data: 0.0012  max mem: 2356
Train: Epoch[1/5]  [240/313]  eta: 0:00:24  Lr: 0.001875  Loss: 0.1080  Acc@1: 93.7500 (86.6442)  Acc@5: 100.0000 (97.7956)  time: 0.3379  data: 0.0006  max mem: 2356
Train: Epoch[1/5]  [250/313]  eta: 0:00:21  Lr: 0.001875  Loss: 0.2388  Acc@1: 93.7500 (86.7530)  Acc@5: 100.0000 (97.8337)  time: 0.3399  data: 0.0006  max mem: 2356
Train: Epoch[1/5]  [260/313]  eta: 0:00:17  Lr: 0.001875  Loss: 0.3422  Acc@1: 93.7500 (86.9013)  Acc@5: 100.0000 (97.8927)  time: 0.3455  data: 0.0009  max mem: 2356
Train: Epoch[1/5]  [270/313]  eta: 0:00:14  Lr: 0.001875  Loss: 0.3506  Acc@1: 93.7500 (87.1541)  Acc@5: 100.0000 (97.9474)  time: 0.3426  data: 0.0016  max mem: 2356
Train: Epoch[1/5]  [280/313]  eta: 0:00:11  Lr: 0.001875  Loss: 0.5413  Acc@1: 93.7500 (87.1219)  Acc@5: 100.0000 (97.9760)  time: 0.3435  data: 0.0023  max mem: 2356
Train: Epoch[1/5]  [290/313]  eta: 0:00:07  Lr: 0.001875  Loss: 0.0456  Acc@1: 87.5000 (87.1778)  Acc@5: 100.0000 (97.9596)  time: 0.3444  data: 0.0028  max mem: 2356
Train: Epoch[1/5]  [300/313]  eta: 0:00:04  Lr: 0.001875  Loss: -0.0141  Acc@1: 93.7500 (87.2716)  Acc@5: 100.0000 (98.0274)  time: 0.3409  data: 0.0020  max mem: 2356
Train: Epoch[1/5]  [310/313]  eta: 0:00:01  Lr: 0.001875  Loss: 0.4378  Acc@1: 93.7500 (87.3995)  Acc@5: 100.0000 (98.0506)  time: 0.3371  data: 0.0006  max mem: 2356
Train: Epoch[1/5]  [312/313]  eta: 0:00:00  Lr: 0.001875  Loss: -0.1116  Acc@1: 93.7500 (87.4200)  Acc@5: 100.0000 (98.0600)  time: 0.3320  data: 0.0006  max mem: 2356
Train: Epoch[1/5] Total time: 0:01:45 (0.3376 s / it)
{0: {0: 22412, 1: 24815, 2: 19998, 3: 12102, 4: 7737, 5: 7897, 6: 7115, 7: 7163, 8: 1054, 9: 0}, 1: {0: 1577, 1: 208, 2: 5200, 3: 12775, 4: 17024, 5: 16965, 6: 17861, 7: 17752, 8: 3938, 9: 0}, 2: {0: 3518, 1: 6779, 2: 5327, 3: 9830, 4: 7541, 5: 7967, 6: 7212, 7: 7116, 8: 1036, 9: 0}, 3: {0: 21486, 1: 20777, 2: 18903, 3: 14840, 4: 17372, 5: 17103, 6: 18038, 7: 18004, 8: 3975, 9: 0}, 4: {0: 16124, 1: 10227, 2: 6432, 3: 10102, 4: 7685, 5: 7874, 6: 7043, 7: 7174, 8: 1044, 9: 0}, 5: {0: 23402, 1: 24357, 2: 21714, 3: 15057, 4: 17322, 5: 16935, 6: 17805, 7: 17989, 8: 3983, 9: 0}, 6: {0: 9472, 1: 12148, 2: 17669, 3: 14460, 4: 17318, 5: 17115, 6: 17934, 7: 17802, 8: 3952, 9: 0}, 7: {0: 752, 1: 676, 2: 4577, 3: 10334, 4: 7679, 5: 7891, 6: 6959, 7: 7005, 8: 1018, 9: 0}, 8: {0: 24269, 1: 24959, 2: 24373, 3: 23260, 4: 19009, 5: 14409, 6: 6643, 7: 6241, 8: 890, 9: 0}, 9: {0: 1988, 1: 54, 2: 807, 3: 2240, 4: 6313, 5: 10844, 6: 18390, 7: 18754, 8: 4110, 9: 0}}
Averaged stats: Lr: 0.001875  Loss: -0.1116  Acc@1: 93.7500 (87.4200)  Acc@5: 100.0000 (98.0600)
Train: Epoch[2/5]  [  0/313]  eta: 0:03:28  Lr: 0.001875  Loss: 0.2552  Acc@1: 81.2500 (81.2500)  Acc@5: 93.7500 (93.7500)  time: 0.6661  data: 0.3008  max mem: 2356
Train: Epoch[2/5]  [ 10/313]  eta: 0:01:52  Lr: 0.001875  Loss: 0.1152  Acc@1: 87.5000 (88.0682)  Acc@5: 100.0000 (97.1591)  time: 0.3720  data: 0.0278  max mem: 2356
Train: Epoch[2/5]  [ 20/313]  eta: 0:01:44  Lr: 0.001875  Loss: 0.0269  Acc@1: 87.5000 (88.0952)  Acc@5: 100.0000 (97.3214)  time: 0.3401  data: 0.0008  max mem: 2356
Train: Epoch[2/5]  [ 30/313]  eta: 0:01:39  Lr: 0.001875  Loss: 0.0363  Acc@1: 93.7500 (89.7177)  Acc@5: 100.0000 (97.7823)  time: 0.3407  data: 0.0011  max mem: 2356
Train: Epoch[2/5]  [ 40/313]  eta: 0:01:34  Lr: 0.001875  Loss: 0.0062  Acc@1: 93.7500 (89.6341)  Acc@5: 100.0000 (98.0183)  time: 0.3392  data: 0.0007  max mem: 2356
Train: Epoch[2/5]  [ 50/313]  eta: 0:01:30  Lr: 0.001875  Loss: 0.4656  Acc@1: 87.5000 (88.2353)  Acc@5: 100.0000 (97.6716)  time: 0.3337  data: 0.0004  max mem: 2356
Train: Epoch[2/5]  [ 60/313]  eta: 0:01:26  Lr: 0.001875  Loss: 0.2444  Acc@1: 87.5000 (89.0369)  Acc@5: 100.0000 (98.0533)  time: 0.3344  data: 0.0017  max mem: 2356
Train: Epoch[2/5]  [ 70/313]  eta: 0:01:23  Lr: 0.001875  Loss: 0.0332  Acc@1: 93.7500 (88.9965)  Acc@5: 100.0000 (98.2394)  time: 0.3354  data: 0.0026  max mem: 2356
Train: Epoch[2/5]  [ 80/313]  eta: 0:01:19  Lr: 0.001875  Loss: 0.2513  Acc@1: 93.7500 (89.2747)  Acc@5: 100.0000 (98.3025)  time: 0.3359  data: 0.0012  max mem: 2356
Train: Epoch[2/5]  [ 90/313]  eta: 0:01:15  Lr: 0.001875  Loss: 0.1120  Acc@1: 87.5000 (89.3544)  Acc@5: 100.0000 (98.4203)  time: 0.3355  data: 0.0004  max mem: 2356
Train: Epoch[2/5]  [100/313]  eta: 0:01:12  Lr: 0.001875  Loss: 0.0908  Acc@1: 87.5000 (89.2327)  Acc@5: 100.0000 (98.5149)  time: 0.3339  data: 0.0004  max mem: 2356
Train: Epoch[2/5]  [110/313]  eta: 0:01:08  Lr: 0.001875  Loss: 0.5692  Acc@1: 87.5000 (88.9640)  Acc@5: 100.0000 (98.3671)  time: 0.3338  data: 0.0007  max mem: 2356
Train: Epoch[2/5]  [120/313]  eta: 0:01:05  Lr: 0.001875  Loss: -0.0116  Acc@1: 87.5000 (88.9463)  Acc@5: 100.0000 (98.3471)  time: 0.3337  data: 0.0012  max mem: 2356
Train: Epoch[2/5]  [130/313]  eta: 0:01:01  Lr: 0.001875  Loss: 0.3830  Acc@1: 87.5000 (88.7882)  Acc@5: 100.0000 (98.3779)  time: 0.3343  data: 0.0010  max mem: 2356
Train: Epoch[2/5]  [140/313]  eta: 0:00:58  Lr: 0.001875  Loss: -0.0186  Acc@1: 87.5000 (88.6525)  Acc@5: 100.0000 (98.3599)  time: 0.3342  data: 0.0006  max mem: 2356
Train: Epoch[2/5]  [150/313]  eta: 0:00:55  Lr: 0.001875  Loss: 0.0049  Acc@1: 87.5000 (88.7417)  Acc@5: 100.0000 (98.3444)  time: 0.3321  data: 0.0005  max mem: 2356
Train: Epoch[2/5]  [160/313]  eta: 0:00:51  Lr: 0.001875  Loss: 0.4824  Acc@1: 93.7500 (88.7811)  Acc@5: 100.0000 (98.4472)  time: 0.3308  data: 0.0003  max mem: 2356
Train: Epoch[2/5]  [170/313]  eta: 0:00:48  Lr: 0.001875  Loss: 0.0772  Acc@1: 87.5000 (88.8158)  Acc@5: 100.0000 (98.4649)  time: 0.3311  data: 0.0003  max mem: 2356
Train: Epoch[2/5]  [180/313]  eta: 0:00:44  Lr: 0.001875  Loss: 0.2318  Acc@1: 93.7500 (88.9503)  Acc@5: 100.0000 (98.4807)  time: 0.3312  data: 0.0003  max mem: 2356
Train: Epoch[2/5]  [190/313]  eta: 0:00:41  Lr: 0.001875  Loss: 0.0814  Acc@1: 87.5000 (88.7762)  Acc@5: 100.0000 (98.4948)  time: 0.3314  data: 0.0003  max mem: 2356
Train: Epoch[2/5]  [200/313]  eta: 0:00:37  Lr: 0.001875  Loss: -0.0740  Acc@1: 87.5000 (88.9303)  Acc@5: 100.0000 (98.5075)  time: 0.3316  data: 0.0003  max mem: 2356
Train: Epoch[2/5]  [210/313]  eta: 0:00:34  Lr: 0.001875  Loss: 0.3980  Acc@1: 93.7500 (89.0403)  Acc@5: 100.0000 (98.5486)  time: 0.3328  data: 0.0007  max mem: 2356
Train: Epoch[2/5]  [220/313]  eta: 0:00:31  Lr: 0.001875  Loss: -0.1708  Acc@1: 93.7500 (89.3100)  Acc@5: 100.0000 (98.6143)  time: 0.3344  data: 0.0008  max mem: 2356
Train: Epoch[2/5]  [230/313]  eta: 0:00:27  Lr: 0.001875  Loss: 0.0978  Acc@1: 93.7500 (89.3398)  Acc@5: 100.0000 (98.6472)  time: 0.3358  data: 0.0006  max mem: 2356
Train: Epoch[2/5]  [240/313]  eta: 0:00:24  Lr: 0.001875  Loss: -0.0380  Acc@1: 87.5000 (89.2635)  Acc@5: 100.0000 (98.6255)  time: 0.3394  data: 0.0011  max mem: 2356
Train: Epoch[2/5]  [250/313]  eta: 0:00:21  Lr: 0.001875  Loss: 0.1962  Acc@1: 87.5000 (89.3177)  Acc@5: 100.0000 (98.6305)  time: 0.3435  data: 0.0010  max mem: 2356
Train: Epoch[2/5]  [260/313]  eta: 0:00:17  Lr: 0.001875  Loss: 0.1566  Acc@1: 93.7500 (89.4636)  Acc@5: 100.0000 (98.6590)  time: 0.3419  data: 0.0005  max mem: 2356
Train: Epoch[2/5]  [270/313]  eta: 0:00:14  Lr: 0.001875  Loss: 0.1536  Acc@1: 93.7500 (89.5065)  Acc@5: 100.0000 (98.6162)  time: 0.3386  data: 0.0013  max mem: 2356
Train: Epoch[2/5]  [280/313]  eta: 0:00:11  Lr: 0.001875  Loss: 0.0537  Acc@1: 87.5000 (89.5685)  Acc@5: 100.0000 (98.6210)  time: 0.3400  data: 0.0016  max mem: 2356
Train: Epoch[2/5]  [290/313]  eta: 0:00:07  Lr: 0.001875  Loss: -0.1185  Acc@1: 87.5000 (89.5189)  Acc@5: 100.0000 (98.6469)  time: 0.3429  data: 0.0009  max mem: 2356
Train: Epoch[2/5]  [300/313]  eta: 0:00:04  Lr: 0.001875  Loss: 0.0288  Acc@1: 93.7500 (89.5556)  Acc@5: 100.0000 (98.5880)  time: 0.3447  data: 0.0005  max mem: 2356
Train: Epoch[2/5]  [310/313]  eta: 0:00:01  Lr: 0.001875  Loss: 0.4150  Acc@1: 87.5000 (89.4494)  Acc@5: 100.0000 (98.6133)  time: 0.3402  data: 0.0004  max mem: 2356
Train: Epoch[2/5]  [312/313]  eta: 0:00:00  Lr: 0.001875  Loss: -0.0273  Acc@1: 87.5000 (89.4600)  Acc@5: 100.0000 (98.6200)  time: 0.3324  data: 0.0004  max mem: 2356
Train: Epoch[2/5] Total time: 0:01:45 (0.3375 s / it)
{0: {0: 22412, 1: 24815, 2: 19998, 3: 12102, 4: 7737, 5: 7897, 6: 7115, 7: 7163, 8: 2310, 9: 0}, 1: {0: 1577, 1: 208, 2: 5200, 3: 12775, 4: 17024, 5: 16965, 6: 17861, 7: 17752, 8: 7689, 9: 0}, 2: {0: 3518, 1: 6779, 2: 5327, 3: 9830, 4: 7541, 5: 7967, 6: 7212, 7: 7116, 8: 2312, 9: 0}, 3: {0: 21486, 1: 20777, 2: 18903, 3: 14840, 4: 17372, 5: 17103, 6: 18038, 7: 18004, 8: 7704, 9: 0}, 4: {0: 16124, 1: 10227, 2: 6432, 3: 10102, 4: 7685, 5: 7874, 6: 7043, 7: 7174, 8: 2310, 9: 0}, 5: {0: 23402, 1: 24357, 2: 21714, 3: 15057, 4: 17322, 5: 16935, 6: 17805, 7: 17989, 8: 7709, 9: 0}, 6: {0: 9472, 1: 12148, 2: 17669, 3: 14460, 4: 17318, 5: 17115, 6: 17934, 7: 17802, 8: 7682, 9: 0}, 7: {0: 752, 1: 676, 2: 4577, 3: 10334, 4: 7679, 5: 7891, 6: 6959, 7: 7005, 8: 2279, 9: 0}, 8: {0: 24269, 1: 24959, 2: 24373, 3: 23260, 4: 19009, 5: 14409, 6: 6643, 7: 6241, 8: 1811, 9: 0}, 9: {0: 1988, 1: 54, 2: 807, 3: 2240, 4: 6313, 5: 10844, 6: 18390, 7: 18754, 8: 8194, 9: 0}}
Averaged stats: Lr: 0.001875  Loss: -0.0273  Acc@1: 87.5000 (89.4600)  Acc@5: 100.0000 (98.6200)
Train: Epoch[3/5]  [  0/313]  eta: 0:05:20  Lr: 0.001875  Loss: 0.2238  Acc@1: 81.2500 (81.2500)  Acc@5: 100.0000 (100.0000)  time: 1.0242  data: 0.6895  max mem: 2356
Train: Epoch[3/5]  [ 10/313]  eta: 0:02:03  Lr: 0.001875  Loss: 0.0803  Acc@1: 87.5000 (86.3636)  Acc@5: 100.0000 (99.4318)  time: 0.4067  data: 0.0647  max mem: 2356
Train: Epoch[3/5]  [ 20/313]  eta: 0:01:50  Lr: 0.001875  Loss: -0.0711  Acc@1: 87.5000 (87.7976)  Acc@5: 100.0000 (99.4048)  time: 0.3445  data: 0.0015  max mem: 2356
Train: Epoch[3/5]  [ 30/313]  eta: 0:01:43  Lr: 0.001875  Loss: 0.1790  Acc@1: 87.5000 (88.7097)  Acc@5: 100.0000 (99.1935)  time: 0.3409  data: 0.0007  max mem: 2356
Train: Epoch[3/5]  [ 40/313]  eta: 0:01:37  Lr: 0.001875  Loss: 0.0919  Acc@1: 87.5000 (89.1768)  Acc@5: 100.0000 (99.0854)  time: 0.3382  data: 0.0014  max mem: 2356
Train: Epoch[3/5]  [ 50/313]  eta: 0:01:33  Lr: 0.001875  Loss: -0.2014  Acc@1: 93.7500 (89.7059)  Acc@5: 100.0000 (98.8971)  time: 0.3394  data: 0.0017  max mem: 2356
Train: Epoch[3/5]  [ 60/313]  eta: 0:01:29  Lr: 0.001875  Loss: 0.1663  Acc@1: 93.7500 (89.5492)  Acc@5: 100.0000 (98.8730)  time: 0.3404  data: 0.0016  max mem: 2356
Train: Epoch[3/5]  [ 70/313]  eta: 0:01:25  Lr: 0.001875  Loss: 0.0602  Acc@1: 87.5000 (89.1725)  Acc@5: 100.0000 (98.6796)  time: 0.3407  data: 0.0012  max mem: 2356
Train: Epoch[3/5]  [ 80/313]  eta: 0:01:21  Lr: 0.001875  Loss: -0.1712  Acc@1: 93.7500 (89.5062)  Acc@5: 100.0000 (98.7654)  time: 0.3424  data: 0.0018  max mem: 2356
Train: Epoch[3/5]  [ 90/313]  eta: 0:01:17  Lr: 0.001875  Loss: 0.0328  Acc@1: 87.5000 (89.1484)  Acc@5: 100.0000 (98.6951)  time: 0.3431  data: 0.0021  max mem: 2356
Train: Epoch[3/5]  [100/313]  eta: 0:01:14  Lr: 0.001875  Loss: 0.1278  Acc@1: 93.7500 (89.4802)  Acc@5: 100.0000 (98.7624)  time: 0.3410  data: 0.0008  max mem: 2356
Train: Epoch[3/5]  [110/313]  eta: 0:01:10  Lr: 0.001875  Loss: 0.1548  Acc@1: 93.7500 (89.6959)  Acc@5: 100.0000 (98.8176)  time: 0.3438  data: 0.0008  max mem: 2356
Train: Epoch[3/5]  [120/313]  eta: 0:01:06  Lr: 0.001875  Loss: -0.1332  Acc@1: 93.7500 (89.8244)  Acc@5: 100.0000 (98.9153)  time: 0.3408  data: 0.0007  max mem: 2356
Train: Epoch[3/5]  [130/313]  eta: 0:01:03  Lr: 0.001875  Loss: -0.1283  Acc@1: 93.7500 (90.0763)  Acc@5: 100.0000 (98.9981)  time: 0.3336  data: 0.0004  max mem: 2356
Train: Epoch[3/5]  [140/313]  eta: 0:00:59  Lr: 0.001875  Loss: -0.1884  Acc@1: 93.7500 (90.2482)  Acc@5: 100.0000 (99.0691)  time: 0.3322  data: 0.0004  max mem: 2356
Train: Epoch[3/5]  [150/313]  eta: 0:00:56  Lr: 0.001875  Loss: 0.2162  Acc@1: 93.7500 (90.3146)  Acc@5: 100.0000 (99.1308)  time: 0.3323  data: 0.0010  max mem: 2356
Train: Epoch[3/5]  [160/313]  eta: 0:00:52  Lr: 0.001875  Loss: -0.1174  Acc@1: 93.7500 (90.3339)  Acc@5: 100.0000 (99.1848)  time: 0.3330  data: 0.0010  max mem: 2356
Train: Epoch[3/5]  [170/313]  eta: 0:00:49  Lr: 0.001875  Loss: 0.0980  Acc@1: 93.7500 (90.2047)  Acc@5: 100.0000 (99.0863)  time: 0.3338  data: 0.0004  max mem: 2356
Train: Epoch[3/5]  [180/313]  eta: 0:00:45  Lr: 0.001875  Loss: 0.2053  Acc@1: 87.5000 (90.1243)  Acc@5: 100.0000 (99.1022)  time: 0.3340  data: 0.0005  max mem: 2356
Train: Epoch[3/5]  [190/313]  eta: 0:00:42  Lr: 0.001875  Loss: 0.1675  Acc@1: 87.5000 (90.2487)  Acc@5: 100.0000 (99.0510)  time: 0.3332  data: 0.0006  max mem: 2356
Train: Epoch[3/5]  [200/313]  eta: 0:00:38  Lr: 0.001875  Loss: 0.3956  Acc@1: 87.5000 (90.3296)  Acc@5: 100.0000 (98.9739)  time: 0.3360  data: 0.0012  max mem: 2356
Train: Epoch[3/5]  [210/313]  eta: 0:00:35  Lr: 0.001875  Loss: 0.1599  Acc@1: 93.7500 (90.3436)  Acc@5: 100.0000 (98.9633)  time: 0.3356  data: 0.0012  max mem: 2356
Train: Epoch[3/5]  [220/313]  eta: 0:00:31  Lr: 0.001875  Loss: -0.0847  Acc@1: 87.5000 (90.2998)  Acc@5: 100.0000 (98.9819)  time: 0.3332  data: 0.0012  max mem: 2356
Train: Epoch[3/5]  [230/313]  eta: 0:00:28  Lr: 0.001875  Loss: -0.1234  Acc@1: 87.5000 (90.2327)  Acc@5: 100.0000 (98.9448)  time: 0.3323  data: 0.0013  max mem: 2356
Train: Epoch[3/5]  [240/313]  eta: 0:00:24  Lr: 0.001875  Loss: 0.6599  Acc@1: 93.7500 (90.2230)  Acc@5: 100.0000 (98.9627)  time: 0.3321  data: 0.0006  max mem: 2356
Train: Epoch[3/5]  [250/313]  eta: 0:00:21  Lr: 0.001875  Loss: 0.3526  Acc@1: 93.7500 (90.1892)  Acc@5: 100.0000 (98.9791)  time: 0.3332  data: 0.0005  max mem: 2356
Train: Epoch[3/5]  [260/313]  eta: 0:00:18  Lr: 0.001875  Loss: -0.2141  Acc@1: 87.5000 (90.2059)  Acc@5: 100.0000 (98.9464)  time: 0.3331  data: 0.0014  max mem: 2356
Train: Epoch[3/5]  [270/313]  eta: 0:00:14  Lr: 0.001875  Loss: 0.0279  Acc@1: 93.7500 (90.2675)  Acc@5: 100.0000 (98.8699)  time: 0.3320  data: 0.0013  max mem: 2356
Train: Epoch[3/5]  [280/313]  eta: 0:00:11  Lr: 0.001875  Loss: 0.1958  Acc@1: 93.7500 (90.3470)  Acc@5: 100.0000 (98.8657)  time: 0.3315  data: 0.0005  max mem: 2356
Train: Epoch[3/5]  [290/313]  eta: 0:00:07  Lr: 0.001875  Loss: -0.1064  Acc@1: 93.7500 (90.3995)  Acc@5: 100.0000 (98.9046)  time: 0.3319  data: 0.0005  max mem: 2356
Train: Epoch[3/5]  [300/313]  eta: 0:00:04  Lr: 0.001875  Loss: 0.4380  Acc@1: 93.7500 (90.3654)  Acc@5: 100.0000 (98.8787)  time: 0.3315  data: 0.0003  max mem: 2356
Train: Epoch[3/5]  [310/313]  eta: 0:00:01  Lr: 0.001875  Loss: 0.3697  Acc@1: 87.5000 (90.3738)  Acc@5: 100.0000 (98.8947)  time: 0.3319  data: 0.0003  max mem: 2356
Train: Epoch[3/5]  [312/313]  eta: 0:00:00  Lr: 0.001875  Loss: 0.2231  Acc@1: 93.7500 (90.4000)  Acc@5: 100.0000 (98.9000)  time: 0.3266  data: 0.0003  max mem: 2356
Train: Epoch[3/5] Total time: 0:01:45 (0.3383 s / it)
{0: {0: 22412, 1: 24815, 2: 19998, 3: 12102, 4: 7737, 5: 7897, 6: 7115, 7: 7163, 8: 3654, 9: 0}, 1: {0: 1577, 1: 208, 2: 5200, 3: 12775, 4: 17024, 5: 16965, 6: 17861, 7: 17752, 8: 11343, 9: 0}, 2: {0: 3518, 1: 6779, 2: 5327, 3: 9830, 4: 7541, 5: 7967, 6: 7212, 7: 7116, 8: 3675, 9: 0}, 3: {0: 21486, 1: 20777, 2: 18903, 3: 14840, 4: 17372, 5: 17103, 6: 18038, 7: 18004, 8: 11339, 9: 0}, 4: {0: 16124, 1: 10227, 2: 6432, 3: 10102, 4: 7685, 5: 7874, 6: 7043, 7: 7174, 8: 3671, 9: 0}, 5: {0: 23402, 1: 24357, 2: 21714, 3: 15057, 4: 17322, 5: 16935, 6: 17805, 7: 17989, 8: 11346, 9: 0}, 6: {0: 9472, 1: 12148, 2: 17669, 3: 14460, 4: 17318, 5: 17115, 6: 17934, 7: 17802, 8: 11321, 9: 0}, 7: {0: 752, 1: 676, 2: 4577, 3: 10334, 4: 7679, 5: 7891, 6: 6959, 7: 7005, 8: 3642, 9: 0}, 8: {0: 24269, 1: 24959, 2: 24373, 3: 23260, 4: 19009, 5: 14409, 6: 6643, 7: 6241, 8: 2751, 9: 0}, 9: {0: 1988, 1: 54, 2: 807, 3: 2240, 4: 6313, 5: 10844, 6: 18390, 7: 18754, 8: 12258, 9: 0}}
Averaged stats: Lr: 0.001875  Loss: 0.2231  Acc@1: 93.7500 (90.4000)  Acc@5: 100.0000 (98.9000)
Train: Epoch[4/5]  [  0/313]  eta: 0:03:08  Lr: 0.001875  Loss: -0.0246  Acc@1: 93.7500 (93.7500)  Acc@5: 100.0000 (100.0000)  time: 0.6034  data: 0.2490  max mem: 2356
Train: Epoch[4/5]  [ 10/313]  eta: 0:01:48  Lr: 0.001875  Loss: -0.1978  Acc@1: 93.7500 (93.1818)  Acc@5: 100.0000 (98.8636)  time: 0.3589  data: 0.0236  max mem: 2356
Train: Epoch[4/5]  [ 20/313]  eta: 0:01:41  Lr: 0.001875  Loss: 0.0327  Acc@1: 93.7500 (91.9643)  Acc@5: 100.0000 (98.8095)  time: 0.3345  data: 0.0008  max mem: 2356
Train: Epoch[4/5]  [ 30/313]  eta: 0:01:37  Lr: 0.001875  Loss: 0.3111  Acc@1: 93.7500 (91.9355)  Acc@5: 100.0000 (98.7903)  time: 0.3361  data: 0.0006  max mem: 2356
Train: Epoch[4/5]  [ 40/313]  eta: 0:01:33  Lr: 0.001875  Loss: 0.5199  Acc@1: 93.7500 (91.4634)  Acc@5: 100.0000 (98.3232)  time: 0.3375  data: 0.0014  max mem: 2356
Train: Epoch[4/5]  [ 50/313]  eta: 0:01:29  Lr: 0.001875  Loss: -0.2177  Acc@1: 93.7500 (91.5441)  Acc@5: 100.0000 (98.5294)  time: 0.3360  data: 0.0017  max mem: 2356
Train: Epoch[4/5]  [ 60/313]  eta: 0:01:26  Lr: 0.001875  Loss: 0.1810  Acc@1: 93.7500 (91.0861)  Acc@5: 100.0000 (98.7705)  time: 0.3352  data: 0.0011  max mem: 2356
Train: Epoch[4/5]  [ 70/313]  eta: 0:01:22  Lr: 0.001875  Loss: 0.0344  Acc@1: 93.7500 (90.9331)  Acc@5: 100.0000 (98.9437)  time: 0.3370  data: 0.0007  max mem: 2356
Train: Epoch[4/5]  [ 80/313]  eta: 0:01:19  Lr: 0.001875  Loss: -0.0669  Acc@1: 93.7500 (91.0494)  Acc@5: 100.0000 (98.9969)  time: 0.3388  data: 0.0006  max mem: 2356
Train: Epoch[4/5]  [ 90/313]  eta: 0:01:15  Lr: 0.001875  Loss: 0.5330  Acc@1: 87.5000 (90.5907)  Acc@5: 100.0000 (99.0385)  time: 0.3406  data: 0.0010  max mem: 2356
Train: Epoch[4/5]  [100/313]  eta: 0:01:12  Lr: 0.001875  Loss: 0.0971  Acc@1: 87.5000 (90.4084)  Acc@5: 100.0000 (98.9480)  time: 0.3408  data: 0.0010  max mem: 2356
Train: Epoch[4/5]  [110/313]  eta: 0:01:08  Lr: 0.001875  Loss: -0.0075  Acc@1: 93.7500 (90.6532)  Acc@5: 100.0000 (99.0428)  time: 0.3385  data: 0.0008  max mem: 2356
Train: Epoch[4/5]  [120/313]  eta: 0:01:05  Lr: 0.001875  Loss: 0.3070  Acc@1: 93.7500 (90.7025)  Acc@5: 100.0000 (99.1219)  time: 0.3368  data: 0.0007  max mem: 2356
Train: Epoch[4/5]  [130/313]  eta: 0:01:02  Lr: 0.001875  Loss: 0.2674  Acc@1: 87.5000 (90.5534)  Acc@5: 100.0000 (99.1412)  time: 0.3367  data: 0.0004  max mem: 2356
Train: Epoch[4/5]  [140/313]  eta: 0:00:58  Lr: 0.001875  Loss: 0.4626  Acc@1: 87.5000 (90.4699)  Acc@5: 100.0000 (99.1135)  time: 0.3383  data: 0.0008  max mem: 2356
Train: Epoch[4/5]  [150/313]  eta: 0:00:55  Lr: 0.001875  Loss: -0.0484  Acc@1: 93.7500 (90.6043)  Acc@5: 100.0000 (99.1722)  time: 0.3441  data: 0.0018  max mem: 2356
Train: Epoch[4/5]  [160/313]  eta: 0:00:52  Lr: 0.001875  Loss: -0.0281  Acc@1: 93.7500 (90.7609)  Acc@5: 100.0000 (99.1848)  time: 0.3461  data: 0.0015  max mem: 2356
Train: Epoch[4/5]  [170/313]  eta: 0:00:48  Lr: 0.001875  Loss: 0.0593  Acc@1: 87.5000 (90.6798)  Acc@5: 100.0000 (99.1959)  time: 0.3412  data: 0.0007  max mem: 2356
Train: Epoch[4/5]  [180/313]  eta: 0:00:45  Lr: 0.001875  Loss: 0.5817  Acc@1: 87.5000 (90.5041)  Acc@5: 100.0000 (99.1367)  time: 0.3426  data: 0.0009  max mem: 2356
Train: Epoch[4/5]  [190/313]  eta: 0:00:41  Lr: 0.001875  Loss: 0.1926  Acc@1: 87.5000 (90.4450)  Acc@5: 100.0000 (99.1492)  time: 0.3405  data: 0.0008  max mem: 2356
Train: Epoch[4/5]  [200/313]  eta: 0:00:38  Lr: 0.001875  Loss: 0.0321  Acc@1: 87.5000 (90.4229)  Acc@5: 100.0000 (99.1294)  time: 0.3331  data: 0.0006  max mem: 2356
Train: Epoch[4/5]  [210/313]  eta: 0:00:34  Lr: 0.001875  Loss: 0.0662  Acc@1: 87.5000 (90.3140)  Acc@5: 100.0000 (99.1114)  time: 0.3320  data: 0.0005  max mem: 2356
Train: Epoch[4/5]  [220/313]  eta: 0:00:31  Lr: 0.001875  Loss: -0.0294  Acc@1: 87.5000 (90.3281)  Acc@5: 100.0000 (99.1516)  time: 0.3330  data: 0.0004  max mem: 2356
Train: Epoch[4/5]  [230/313]  eta: 0:00:28  Lr: 0.001875  Loss: -0.1135  Acc@1: 93.7500 (90.4762)  Acc@5: 100.0000 (99.1071)  time: 0.3337  data: 0.0005  max mem: 2356
Train: Epoch[4/5]  [240/313]  eta: 0:00:24  Lr: 0.001875  Loss: -0.0660  Acc@1: 93.7500 (90.5342)  Acc@5: 100.0000 (99.1442)  time: 0.3329  data: 0.0005  max mem: 2356
Train: Epoch[4/5]  [250/313]  eta: 0:00:21  Lr: 0.001875  Loss: 0.3356  Acc@1: 87.5000 (90.4382)  Acc@5: 100.0000 (99.1534)  time: 0.3321  data: 0.0004  max mem: 2356
Train: Epoch[4/5]  [260/313]  eta: 0:00:17  Lr: 0.001875  Loss: -0.0344  Acc@1: 87.5000 (90.5172)  Acc@5: 100.0000 (99.1379)  time: 0.3332  data: 0.0009  max mem: 2356
Train: Epoch[4/5]  [270/313]  eta: 0:00:14  Lr: 0.001875  Loss: -0.1630  Acc@1: 93.7500 (90.5904)  Acc@5: 100.0000 (99.1467)  time: 0.3335  data: 0.0009  max mem: 2356
Train: Epoch[4/5]  [280/313]  eta: 0:00:11  Lr: 0.001875  Loss: 0.0612  Acc@1: 93.7500 (90.4804)  Acc@5: 100.0000 (99.1770)  time: 0.3327  data: 0.0004  max mem: 2356
Train: Epoch[4/5]  [290/313]  eta: 0:00:07  Lr: 0.001875  Loss: -0.1917  Acc@1: 87.5000 (90.4639)  Acc@5: 100.0000 (99.1838)  time: 0.3347  data: 0.0011  max mem: 2356
Train: Epoch[4/5]  [300/313]  eta: 0:00:04  Lr: 0.001875  Loss: -0.0175  Acc@1: 87.5000 (90.2824)  Acc@5: 100.0000 (99.1487)  time: 0.3343  data: 0.0011  max mem: 2356
Train: Epoch[4/5]  [310/313]  eta: 0:00:01  Lr: 0.001875  Loss: 0.2147  Acc@1: 87.5000 (90.2733)  Acc@5: 100.0000 (99.1359)  time: 0.3325  data: 0.0003  max mem: 2356
Train: Epoch[4/5]  [312/313]  eta: 0:00:00  Lr: 0.001875  Loss: 0.1836  Acc@1: 87.5000 (90.2400)  Acc@5: 100.0000 (99.1200)  time: 0.3244  data: 0.0003  max mem: 2356
Train: Epoch[4/5] Total time: 0:01:45 (0.3372 s / it)
{0: {0: 22412, 1: 24815, 2: 19998, 3: 12102, 4: 7737, 5: 7897, 6: 7115, 7: 7163, 8: 4968, 9: 0}, 1: {0: 1577, 1: 208, 2: 5200, 3: 12775, 4: 17024, 5: 16965, 6: 17861, 7: 17752, 8: 15029, 9: 0}, 2: {0: 3518, 1: 6779, 2: 5327, 3: 9830, 4: 7541, 5: 7967, 6: 7212, 7: 7116, 8: 4999, 9: 0}, 3: {0: 21486, 1: 20777, 2: 18903, 3: 14840, 4: 17372, 5: 17103, 6: 18038, 7: 18004, 8: 15014, 9: 0}, 4: {0: 16124, 1: 10227, 2: 6432, 3: 10102, 4: 7685, 5: 7874, 6: 7043, 7: 7174, 8: 4994, 9: 0}, 5: {0: 23402, 1: 24357, 2: 21714, 3: 15057, 4: 17322, 5: 16935, 6: 17805, 7: 17989, 8: 15019, 9: 0}, 6: {0: 9472, 1: 12148, 2: 17669, 3: 14460, 4: 17318, 5: 17115, 6: 17934, 7: 17802, 8: 14999, 9: 0}, 7: {0: 752, 1: 676, 2: 4577, 3: 10334, 4: 7679, 5: 7891, 6: 6959, 7: 7005, 8: 4966, 9: 0}, 8: {0: 24269, 1: 24959, 2: 24373, 3: 23260, 4: 19009, 5: 14409, 6: 6643, 7: 6241, 8: 3646, 9: 0}, 9: {0: 1988, 1: 54, 2: 807, 3: 2240, 4: 6313, 5: 10844, 6: 18390, 7: 18754, 8: 16366, 9: 0}}
Averaged stats: Lr: 0.001875  Loss: 0.1836  Acc@1: 87.5000 (90.2400)  Acc@5: 100.0000 (99.1200)
Train: Epoch[5/5]  [  0/313]  eta: 0:03:17  Lr: 0.001875  Loss: 0.3512  Acc@1: 87.5000 (87.5000)  Acc@5: 93.7500 (93.7500)  time: 0.6300  data: 0.2979  max mem: 2356
Train: Epoch[5/5]  [ 10/313]  eta: 0:01:49  Lr: 0.001875  Loss: 0.0331  Acc@1: 87.5000 (90.9091)  Acc@5: 100.0000 (98.2955)  time: 0.3602  data: 0.0274  max mem: 2356
Train: Epoch[5/5]  [ 20/313]  eta: 0:01:41  Lr: 0.001875  Loss: -0.0874  Acc@1: 93.7500 (89.8810)  Acc@5: 100.0000 (98.5119)  time: 0.3323  data: 0.0012  max mem: 2356
Train: Epoch[5/5]  [ 30/313]  eta: 0:01:36  Lr: 0.001875  Loss: 0.1763  Acc@1: 93.7500 (90.5242)  Acc@5: 100.0000 (98.9919)  time: 0.3312  data: 0.0013  max mem: 2356
Train: Epoch[5/5]  [ 40/313]  eta: 0:01:32  Lr: 0.001875  Loss: 0.2311  Acc@1: 93.7500 (91.7683)  Acc@5: 100.0000 (99.0854)  time: 0.3315  data: 0.0004  max mem: 2356
Train: Epoch[5/5]  [ 50/313]  eta: 0:01:28  Lr: 0.001875  Loss: -0.0025  Acc@1: 93.7500 (92.0343)  Acc@5: 100.0000 (99.2647)  time: 0.3319  data: 0.0003  max mem: 2356
Train: Epoch[5/5]  [ 60/313]  eta: 0:01:25  Lr: 0.001875  Loss: -0.0072  Acc@1: 93.7500 (92.5205)  Acc@5: 100.0000 (99.3852)  time: 0.3317  data: 0.0003  max mem: 2356
Train: Epoch[5/5]  [ 70/313]  eta: 0:01:21  Lr: 0.001875  Loss: -0.0380  Acc@1: 93.7500 (92.2535)  Acc@5: 100.0000 (99.3838)  time: 0.3328  data: 0.0005  max mem: 2356
Train: Epoch[5/5]  [ 80/313]  eta: 0:01:18  Lr: 0.001875  Loss: 0.0574  Acc@1: 93.7500 (92.2068)  Acc@5: 100.0000 (99.3827)  time: 0.3355  data: 0.0010  max mem: 2356
Train: Epoch[5/5]  [ 90/313]  eta: 0:01:15  Lr: 0.001875  Loss: 0.1839  Acc@1: 93.7500 (92.0330)  Acc@5: 100.0000 (99.3819)  time: 0.3414  data: 0.0012  max mem: 2356
Train: Epoch[5/5]  [100/313]  eta: 0:01:11  Lr: 0.001875  Loss: -0.1643  Acc@1: 93.7500 (92.2030)  Acc@5: 100.0000 (99.4431)  time: 0.3425  data: 0.0008  max mem: 2356
Train: Epoch[5/5]  [110/313]  eta: 0:01:08  Lr: 0.001875  Loss: -0.0404  Acc@1: 93.7500 (92.2297)  Acc@5: 100.0000 (99.4369)  time: 0.3387  data: 0.0017  max mem: 2356
Train: Epoch[5/5]  [120/313]  eta: 0:01:05  Lr: 0.001875  Loss: -0.0327  Acc@1: 93.7500 (92.2004)  Acc@5: 100.0000 (99.3802)  time: 0.3382  data: 0.0017  max mem: 2356
Train: Epoch[5/5]  [130/313]  eta: 0:01:01  Lr: 0.001875  Loss: 0.0618  Acc@1: 87.5000 (91.8893)  Acc@5: 100.0000 (99.4275)  time: 0.3379  data: 0.0005  max mem: 2356
Train: Epoch[5/5]  [140/313]  eta: 0:00:58  Lr: 0.001875  Loss: 0.3583  Acc@1: 87.5000 (91.7553)  Acc@5: 100.0000 (99.4238)  time: 0.3361  data: 0.0005  max mem: 2356
Train: Epoch[5/5]  [150/313]  eta: 0:00:55  Lr: 0.001875  Loss: 0.1895  Acc@1: 93.7500 (91.7632)  Acc@5: 100.0000 (99.3791)  time: 0.3381  data: 0.0018  max mem: 2356
Train: Epoch[5/5]  [160/313]  eta: 0:00:51  Lr: 0.001875  Loss: -0.1279  Acc@1: 87.5000 (91.5761)  Acc@5: 100.0000 (99.3789)  time: 0.3412  data: 0.0023  max mem: 2356
Train: Epoch[5/5]  [170/313]  eta: 0:00:48  Lr: 0.001875  Loss: -0.1676  Acc@1: 87.5000 (91.5205)  Acc@5: 100.0000 (99.4152)  time: 0.3391  data: 0.0016  max mem: 2356
Train: Epoch[5/5]  [180/313]  eta: 0:00:44  Lr: 0.001875  Loss: -0.1556  Acc@1: 93.7500 (91.6782)  Acc@5: 100.0000 (99.4475)  time: 0.3407  data: 0.0023  max mem: 2356
Train: Epoch[5/5]  [190/313]  eta: 0:00:41  Lr: 0.001875  Loss: 0.0779  Acc@1: 87.5000 (91.5576)  Acc@5: 100.0000 (99.3455)  time: 0.3429  data: 0.0023  max mem: 2356
Train: Epoch[5/5]  [200/313]  eta: 0:00:38  Lr: 0.001875  Loss: -0.0603  Acc@1: 87.5000 (91.5112)  Acc@5: 100.0000 (99.2848)  time: 0.3414  data: 0.0013  max mem: 2356
Train: Epoch[5/5]  [210/313]  eta: 0:00:34  Lr: 0.001875  Loss: 0.0838  Acc@1: 87.5000 (91.2915)  Acc@5: 100.0000 (99.2595)  time: 0.3395  data: 0.0015  max mem: 2356
Train: Epoch[5/5]  [220/313]  eta: 0:00:31  Lr: 0.001875  Loss: -0.0554  Acc@1: 87.5000 (91.2896)  Acc@5: 100.0000 (99.2647)  time: 0.3361  data: 0.0014  max mem: 2356
Train: Epoch[5/5]  [230/313]  eta: 0:00:28  Lr: 0.001875  Loss: 0.0426  Acc@1: 93.7500 (91.3420)  Acc@5: 100.0000 (99.2695)  time: 0.3352  data: 0.0008  max mem: 2356
Train: Epoch[5/5]  [240/313]  eta: 0:00:24  Lr: 0.001875  Loss: -0.0877  Acc@1: 93.7500 (91.3382)  Acc@5: 100.0000 (99.2479)  time: 0.3361  data: 0.0007  max mem: 2356
Train: Epoch[5/5]  [250/313]  eta: 0:00:21  Lr: 0.001875  Loss: 0.1121  Acc@1: 93.7500 (91.3596)  Acc@5: 100.0000 (99.2281)  time: 0.3439  data: 0.0017  max mem: 2356
Train: Epoch[5/5]  [260/313]  eta: 0:00:17  Lr: 0.001875  Loss: -0.0005  Acc@1: 93.7500 (91.3793)  Acc@5: 100.0000 (99.2577)  time: 0.3464  data: 0.0026  max mem: 2356
Train: Epoch[5/5]  [270/313]  eta: 0:00:14  Lr: 0.001875  Loss: -0.1846  Acc@1: 93.7500 (91.5360)  Acc@5: 100.0000 (99.2851)  time: 0.3366  data: 0.0014  max mem: 2356
Train: Epoch[5/5]  [280/313]  eta: 0:00:11  Lr: 0.001875  Loss: -0.1516  Acc@1: 93.7500 (91.5925)  Acc@5: 100.0000 (99.2883)  time: 0.3331  data: 0.0006  max mem: 2356
Train: Epoch[5/5]  [290/313]  eta: 0:00:07  Lr: 0.001875  Loss: 0.0247  Acc@1: 93.7500 (91.5378)  Acc@5: 100.0000 (99.3127)  time: 0.3339  data: 0.0006  max mem: 2356
Train: Epoch[5/5]  [300/313]  eta: 0:00:04  Lr: 0.001875  Loss: -0.0839  Acc@1: 93.7500 (91.6113)  Acc@5: 100.0000 (99.2940)  time: 0.3334  data: 0.0006  max mem: 2356
Train: Epoch[5/5]  [310/313]  eta: 0:00:01  Lr: 0.001875  Loss: -0.1156  Acc@1: 93.7500 (91.5193)  Acc@5: 100.0000 (99.2765)  time: 0.3338  data: 0.0006  max mem: 2356
Train: Epoch[5/5]  [312/313]  eta: 0:00:00  Lr: 0.001875  Loss: 0.1179  Acc@1: 93.7500 (91.5200)  Acc@5: 100.0000 (99.2800)  time: 0.3261  data: 0.0006  max mem: 2356
Train: Epoch[5/5] Total time: 0:01:45 (0.3378 s / it)
{0: {0: 22412, 1: 24815, 2: 19998, 3: 12102, 4: 7737, 5: 7897, 6: 7115, 7: 7163, 8: 6299, 9: 0}, 1: {0: 1577, 1: 208, 2: 5200, 3: 12775, 4: 17024, 5: 16965, 6: 17861, 7: 17752, 8: 18698, 9: 0}, 2: {0: 3518, 1: 6779, 2: 5327, 3: 9830, 4: 7541, 5: 7967, 6: 7212, 7: 7116, 8: 6338, 9: 0}, 3: {0: 21486, 1: 20777, 2: 18903, 3: 14840, 4: 17372, 5: 17103, 6: 18038, 7: 18004, 8: 18675, 9: 0}, 4: {0: 16124, 1: 10227, 2: 6432, 3: 10102, 4: 7685, 5: 7874, 6: 7043, 7: 7174, 8: 6329, 9: 0}, 5: {0: 23402, 1: 24357, 2: 21714, 3: 15057, 4: 17322, 5: 16935, 6: 17805, 7: 17989, 8: 18676, 9: 0}, 6: {0: 9472, 1: 12148, 2: 17669, 3: 14460, 4: 17318, 5: 17115, 6: 17934, 7: 17802, 8: 18664, 9: 0}, 7: {0: 752, 1: 676, 2: 4577, 3: 10334, 4: 7679, 5: 7891, 6: 6959, 7: 7005, 8: 6309, 9: 0}, 8: {0: 24269, 1: 24959, 2: 24373, 3: 23260, 4: 19009, 5: 14409, 6: 6643, 7: 6241, 8: 4545, 9: 0}, 9: {0: 1988, 1: 54, 2: 807, 3: 2240, 4: 6313, 5: 10844, 6: 18390, 7: 18754, 8: 20467, 9: 0}}
Averaged stats: Lr: 0.001875  Loss: 0.1179  Acc@1: 93.7500 (91.5200)  Acc@5: 100.0000 (99.2800)
Test: [Task 1]  [ 0/63]  eta: 0:00:35  Loss: 0.9413 (0.9413)  Acc@1: 75.0000 (75.0000)  Acc@5: 100.0000 (100.0000)  time: 0.5558  data: 0.3494  max mem: 2356
Test: [Task 1]  [10/63]  eta: 0:00:12  Loss: 0.7997 (0.6988)  Acc@1: 87.5000 (82.3864)  Acc@5: 100.0000 (99.4318)  time: 0.2386  data: 0.0326  max mem: 2356
Test: [Task 1]  [20/63]  eta: 0:00:09  Loss: 0.7596 (0.7429)  Acc@1: 81.2500 (81.5476)  Acc@5: 100.0000 (97.9167)  time: 0.2060  data: 0.0006  max mem: 2356
Test: [Task 1]  [30/63]  eta: 0:00:07  Loss: 0.5186 (0.6886)  Acc@1: 87.5000 (83.4677)  Acc@5: 100.0000 (98.3871)  time: 0.2062  data: 0.0008  max mem: 2356
Test: [Task 1]  [40/63]  eta: 0:00:04  Loss: 0.5186 (0.6862)  Acc@1: 87.5000 (83.2317)  Acc@5: 100.0000 (98.4756)  time: 0.2074  data: 0.0012  max mem: 2356
Test: [Task 1]  [50/63]  eta: 0:00:02  Loss: 0.5366 (0.6580)  Acc@1: 87.5000 (84.1912)  Acc@5: 100.0000 (98.6520)  time: 0.2065  data: 0.0010  max mem: 2356
Test: [Task 1]  [60/63]  eta: 0:00:00  Loss: 0.5318 (0.6467)  Acc@1: 87.5000 (84.3238)  Acc@5: 100.0000 (98.5656)  time: 0.2060  data: 0.0005  max mem: 2356
Test: [Task 1]  [62/63]  eta: 0:00:00  Loss: 0.5317 (0.6428)  Acc@1: 87.5000 (84.5000)  Acc@5: 100.0000 (98.6000)  time: 0.2011  data: 0.0005  max mem: 2356
Test: [Task 1] Total time: 0:00:13 (0.2115 s / it)
* Acc@1 84.500 Acc@5 98.600 loss 0.643
Test: [Task 2]  [ 0/63]  eta: 0:00:33  Loss: 1.2175 (1.2175)  Acc@1: 81.2500 (81.2500)  Acc@5: 87.5000 (87.5000)  time: 0.5243  data: 0.3159  max mem: 2356
Test: [Task 2]  [10/63]  eta: 0:00:12  Loss: 0.8065 (0.8507)  Acc@1: 81.2500 (80.1136)  Acc@5: 100.0000 (96.5909)  time: 0.2374  data: 0.0294  max mem: 2356
Test: [Task 2]  [20/63]  eta: 0:00:09  Loss: 0.8065 (0.9091)  Acc@1: 75.0000 (77.0833)  Acc@5: 93.7500 (95.8333)  time: 0.2080  data: 0.0011  max mem: 2356
Test: [Task 2]  [30/63]  eta: 0:00:07  Loss: 0.8660 (0.8889)  Acc@1: 75.0000 (78.4274)  Acc@5: 93.7500 (95.5645)  time: 0.2062  data: 0.0009  max mem: 2356
Test: [Task 2]  [40/63]  eta: 0:00:04  Loss: 0.7273 (0.8680)  Acc@1: 81.2500 (79.2683)  Acc@5: 93.7500 (95.7317)  time: 0.2072  data: 0.0011  max mem: 2356
Test: [Task 2]  [50/63]  eta: 0:00:02  Loss: 0.7506 (0.8608)  Acc@1: 75.0000 (78.3088)  Acc@5: 93.7500 (95.9559)  time: 0.2072  data: 0.0011  max mem: 2356
Test: [Task 2]  [60/63]  eta: 0:00:00  Loss: 0.7573 (0.8422)  Acc@1: 81.2500 (79.0984)  Acc@5: 100.0000 (96.2090)  time: 0.2051  data: 0.0002  max mem: 2356
Test: [Task 2]  [62/63]  eta: 0:00:00  Loss: 0.7070 (0.8324)  Acc@1: 81.2500 (79.3000)  Acc@5: 100.0000 (96.3000)  time: 0.2004  data: 0.0002  max mem: 2356
Test: [Task 2] Total time: 0:00:13 (0.2113 s / it)
* Acc@1 79.300 Acc@5 96.300 loss 0.832
Test: [Task 3]  [ 0/63]  eta: 0:00:31  Loss: 0.6282 (0.6282)  Acc@1: 81.2500 (81.2500)  Acc@5: 100.0000 (100.0000)  time: 0.5067  data: 0.2785  max mem: 2356
Test: [Task 3]  [10/63]  eta: 0:00:12  Loss: 0.6998 (0.7244)  Acc@1: 81.2500 (82.3864)  Acc@5: 93.7500 (95.4545)  time: 0.2330  data: 0.0261  max mem: 2356
Test: [Task 3]  [20/63]  eta: 0:00:09  Loss: 0.7183 (0.7211)  Acc@1: 81.2500 (81.5476)  Acc@5: 93.7500 (96.4286)  time: 0.2058  data: 0.0006  max mem: 2356
Test: [Task 3]  [30/63]  eta: 0:00:07  Loss: 0.7790 (0.7378)  Acc@1: 75.0000 (80.0403)  Acc@5: 100.0000 (96.5726)  time: 0.2056  data: 0.0003  max mem: 2356
Test: [Task 3]  [40/63]  eta: 0:00:04  Loss: 0.7418 (0.7370)  Acc@1: 75.0000 (79.8780)  Acc@5: 100.0000 (96.6463)  time: 0.2058  data: 0.0010  max mem: 2356
Test: [Task 3]  [50/63]  eta: 0:00:02  Loss: 0.7418 (0.7476)  Acc@1: 81.2500 (80.5147)  Acc@5: 93.7500 (96.0784)  time: 0.2070  data: 0.0010  max mem: 2356
Test: [Task 3]  [60/63]  eta: 0:00:00  Loss: 0.7958 (0.7649)  Acc@1: 81.2500 (80.2254)  Acc@5: 93.7500 (95.5943)  time: 0.2063  data: 0.0002  max mem: 2356
Test: [Task 3]  [62/63]  eta: 0:00:00  Loss: 0.8154 (0.7667)  Acc@1: 81.2500 (80.0000)  Acc@5: 93.7500 (95.6000)  time: 0.2013  data: 0.0002  max mem: 2356
Test: [Task 3] Total time: 0:00:13 (0.2102 s / it)
* Acc@1 80.000 Acc@5 95.600 loss 0.767
Test: [Task 4]  [ 0/63]  eta: 0:00:32  Loss: 0.8150 (0.8150)  Acc@1: 81.2500 (81.2500)  Acc@5: 93.7500 (93.7500)  time: 0.5179  data: 0.3135  max mem: 2356
Test: [Task 4]  [10/63]  eta: 0:00:12  Loss: 0.7763 (0.6891)  Acc@1: 87.5000 (86.9318)  Acc@5: 93.7500 (96.5909)  time: 0.2346  data: 0.0294  max mem: 2356
Test: [Task 4]  [20/63]  eta: 0:00:09  Loss: 0.7066 (0.6952)  Acc@1: 87.5000 (84.2262)  Acc@5: 93.7500 (95.5357)  time: 0.2053  data: 0.0006  max mem: 2356
Test: [Task 4]  [30/63]  eta: 0:00:07  Loss: 0.6258 (0.6744)  Acc@1: 81.2500 (84.8790)  Acc@5: 93.7500 (95.9677)  time: 0.2055  data: 0.0008  max mem: 2356
Test: [Task 4]  [40/63]  eta: 0:00:04  Loss: 0.4177 (0.6104)  Acc@1: 87.5000 (86.7378)  Acc@5: 100.0000 (96.7988)  time: 0.2089  data: 0.0024  max mem: 2356
Test: [Task 4]  [50/63]  eta: 0:00:02  Loss: 0.4603 (0.6339)  Acc@1: 87.5000 (86.1520)  Acc@5: 100.0000 (96.3235)  time: 0.2113  data: 0.0028  max mem: 2356
Test: [Task 4]  [60/63]  eta: 0:00:00  Loss: 0.5299 (0.6427)  Acc@1: 81.2500 (85.9631)  Acc@5: 93.7500 (96.3115)  time: 0.2093  data: 0.0016  max mem: 2356
Test: [Task 4]  [62/63]  eta: 0:00:00  Loss: 0.6152 (0.6425)  Acc@1: 81.2500 (85.9000)  Acc@5: 93.7500 (96.3000)  time: 0.2037  data: 0.0016  max mem: 2356
Test: [Task 4] Total time: 0:00:13 (0.2125 s / it)
* Acc@1 85.900 Acc@5 96.300 loss 0.642
Test: [Task 5]  [ 0/63]  eta: 0:00:43  Loss: 0.2310 (0.2310)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)  time: 0.6844  data: 0.4767  max mem: 2356
Test: [Task 5]  [10/63]  eta: 0:00:13  Loss: 0.4479 (0.5743)  Acc@1: 87.5000 (88.0682)  Acc@5: 100.0000 (97.1591)  time: 0.2489  data: 0.0437  max mem: 2356
Test: [Task 5]  [20/63]  eta: 0:00:09  Loss: 0.4479 (0.5419)  Acc@1: 87.5000 (89.2857)  Acc@5: 100.0000 (97.9167)  time: 0.2068  data: 0.0005  max mem: 2356
Test: [Task 5]  [30/63]  eta: 0:00:07  Loss: 0.5061 (0.5547)  Acc@1: 87.5000 (88.7097)  Acc@5: 100.0000 (97.5806)  time: 0.2076  data: 0.0010  max mem: 2356
Test: [Task 5]  [40/63]  eta: 0:00:05  Loss: 0.4974 (0.5447)  Acc@1: 87.5000 (89.6341)  Acc@5: 100.0000 (97.5610)  time: 0.2097  data: 0.0013  max mem: 2356
Test: [Task 5]  [50/63]  eta: 0:00:02  Loss: 0.5445 (0.5642)  Acc@1: 87.5000 (89.2157)  Acc@5: 100.0000 (97.5490)  time: 0.2093  data: 0.0008  max mem: 2356
Test: [Task 5]  [60/63]  eta: 0:00:00  Loss: 0.5590 (0.5723)  Acc@1: 87.5000 (88.6270)  Acc@5: 100.0000 (97.6434)  time: 0.2076  data: 0.0010  max mem: 2356
Test: [Task 5]  [62/63]  eta: 0:00:00  Loss: 0.5704 (0.5869)  Acc@1: 87.5000 (88.5000)  Acc@5: 100.0000 (97.4000)  time: 0.2026  data: 0.0010  max mem: 2356
Test: [Task 5] Total time: 0:00:13 (0.2150 s / it)
* Acc@1 88.500 Acc@5 97.400 loss 0.587
Test: [Task 6]  [ 0/63]  eta: 0:00:28  Loss: 0.5243 (0.5243)  Acc@1: 75.0000 (75.0000)  Acc@5: 100.0000 (100.0000)  time: 0.4469  data: 0.2320  max mem: 2356
Test: [Task 6]  [10/63]  eta: 0:00:12  Loss: 0.7508 (0.6644)  Acc@1: 81.2500 (78.9773)  Acc@5: 100.0000 (97.1591)  time: 0.2317  data: 0.0220  max mem: 2356
Test: [Task 6]  [20/63]  eta: 0:00:09  Loss: 0.7508 (0.7348)  Acc@1: 75.0000 (77.0833)  Acc@5: 100.0000 (96.7262)  time: 0.2088  data: 0.0011  max mem: 2356
Test: [Task 6]  [30/63]  eta: 0:00:07  Loss: 0.6690 (0.7208)  Acc@1: 81.2500 (77.8226)  Acc@5: 100.0000 (97.5806)  time: 0.2089  data: 0.0023  max mem: 2356
Test: [Task 6]  [40/63]  eta: 0:00:04  Loss: 0.6951 (0.7451)  Acc@1: 81.2500 (76.9817)  Acc@5: 100.0000 (97.8659)  time: 0.2118  data: 0.0045  max mem: 2356
Test: [Task 6]  [50/63]  eta: 0:00:02  Loss: 0.6631 (0.7254)  Acc@1: 81.2500 (77.8186)  Acc@5: 100.0000 (98.1618)  time: 0.2124  data: 0.0043  max mem: 2356
Test: [Task 6]  [60/63]  eta: 0:00:00  Loss: 0.7471 (0.7456)  Acc@1: 81.2500 (78.0738)  Acc@5: 100.0000 (97.5410)  time: 0.2104  data: 0.0022  max mem: 2356
Test: [Task 6]  [62/63]  eta: 0:00:00  Loss: 0.6933 (0.7398)  Acc@1: 81.2500 (78.3000)  Acc@5: 100.0000 (97.6000)  time: 0.2047  data: 0.0014  max mem: 2356
Test: [Task 6] Total time: 0:00:13 (0.2139 s / it)
* Acc@1 78.300 Acc@5 97.600 loss 0.740
Test: [Task 7]  [ 0/63]  eta: 0:00:46  Loss: 1.0023 (1.0023)  Acc@1: 62.5000 (62.5000)  Acc@5: 93.7500 (93.7500)  time: 0.7418  data: 0.5369  max mem: 2356
Test: [Task 7]  [10/63]  eta: 0:00:13  Loss: 0.6655 (0.7128)  Acc@1: 87.5000 (81.8182)  Acc@5: 93.7500 (95.4545)  time: 0.2563  data: 0.0491  max mem: 2356
Test: [Task 7]  [20/63]  eta: 0:00:10  Loss: 0.6495 (0.7309)  Acc@1: 87.5000 (83.0357)  Acc@5: 93.7500 (94.3452)  time: 0.2106  data: 0.0027  max mem: 2356
Test: [Task 7]  [30/63]  eta: 0:00:07  Loss: 0.6128 (0.6964)  Acc@1: 81.2500 (83.0645)  Acc@5: 93.7500 (95.1613)  time: 0.2135  data: 0.0035  max mem: 2356
Test: [Task 7]  [40/63]  eta: 0:00:05  Loss: 0.6104 (0.6882)  Acc@1: 87.5000 (83.6890)  Acc@5: 93.7500 (95.5793)  time: 0.2097  data: 0.0012  max mem: 2356
Test: [Task 7]  [50/63]  eta: 0:00:02  Loss: 0.7276 (0.7112)  Acc@1: 81.2500 (83.3333)  Acc@5: 93.7500 (95.2206)  time: 0.2072  data: 0.0005  max mem: 2356
Test: [Task 7]  [60/63]  eta: 0:00:00  Loss: 0.7276 (0.7054)  Acc@1: 81.2500 (83.8115)  Acc@5: 93.7500 (95.1844)  time: 0.2077  data: 0.0004  max mem: 2356
Test: [Task 7]  [62/63]  eta: 0:00:00  Loss: 0.7672 (0.7150)  Acc@1: 81.2500 (83.7000)  Acc@5: 93.7500 (95.1000)  time: 0.2024  data: 0.0004  max mem: 2356
Test: [Task 7] Total time: 0:00:13 (0.2176 s / it)
* Acc@1 83.700 Acc@5 95.100 loss 0.715
Test: [Task 8]  [ 0/63]  eta: 0:00:28  Loss: 0.5538 (0.5538)  Acc@1: 93.7500 (93.7500)  Acc@5: 100.0000 (100.0000)  time: 0.4565  data: 0.2511  max mem: 2356
Test: [Task 8]  [10/63]  eta: 0:00:12  Loss: 0.6234 (0.6927)  Acc@1: 87.5000 (82.9545)  Acc@5: 100.0000 (96.0227)  time: 0.2335  data: 0.0251  max mem: 2356
Test: [Task 8]  [20/63]  eta: 0:00:09  Loss: 0.6242 (0.7079)  Acc@1: 81.2500 (82.4405)  Acc@5: 93.7500 (96.1310)  time: 0.2103  data: 0.0016  max mem: 2356
Test: [Task 8]  [30/63]  eta: 0:00:07  Loss: 0.5746 (0.6653)  Acc@1: 87.5000 (84.0726)  Acc@5: 100.0000 (96.9758)  time: 0.2089  data: 0.0006  max mem: 2356
Test: [Task 8]  [40/63]  eta: 0:00:05  Loss: 0.5746 (0.6704)  Acc@1: 87.5000 (84.2988)  Acc@5: 100.0000 (96.4939)  time: 0.2131  data: 0.0022  max mem: 2356
Test: [Task 8]  [50/63]  eta: 0:00:02  Loss: 0.6690 (0.6576)  Acc@1: 87.5000 (84.1912)  Acc@5: 100.0000 (96.6912)  time: 0.2122  data: 0.0028  max mem: 2356
Test: [Task 8]  [60/63]  eta: 0:00:00  Loss: 0.6957 (0.6856)  Acc@1: 81.2500 (83.2992)  Acc@5: 93.7500 (96.0041)  time: 0.2058  data: 0.0009  max mem: 2356
Test: [Task 8]  [62/63]  eta: 0:00:00  Loss: 0.6754 (0.6733)  Acc@1: 81.2500 (83.6000)  Acc@5: 100.0000 (96.1000)  time: 0.2009  data: 0.0009  max mem: 2356
Test: [Task 8] Total time: 0:00:13 (0.2132 s / it)
* Acc@1 83.600 Acc@5 96.100 loss 0.673
Test: [Task 9]  [ 0/63]  eta: 0:00:34  Loss: 0.1128 (0.1128)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)  time: 0.5450  data: 0.3340  max mem: 2356
Test: [Task 9]  [10/63]  eta: 0:00:12  Loss: 0.4163 (0.4507)  Acc@1: 93.7500 (90.9091)  Acc@5: 100.0000 (98.2955)  time: 0.2364  data: 0.0308  max mem: 2356
Test: [Task 9]  [20/63]  eta: 0:00:09  Loss: 0.3843 (0.4557)  Acc@1: 87.5000 (89.2857)  Acc@5: 100.0000 (98.5119)  time: 0.2061  data: 0.0012  max mem: 2356
Test: [Task 9]  [30/63]  eta: 0:00:07  Loss: 0.3364 (0.4219)  Acc@1: 93.7500 (90.3226)  Acc@5: 100.0000 (98.7903)  time: 0.2059  data: 0.0011  max mem: 2356
Test: [Task 9]  [40/63]  eta: 0:00:04  Loss: 0.3537 (0.4301)  Acc@1: 93.7500 (89.7866)  Acc@5: 100.0000 (98.9329)  time: 0.2053  data: 0.0003  max mem: 2356
Test: [Task 9]  [50/63]  eta: 0:00:02  Loss: 0.4480 (0.4360)  Acc@1: 87.5000 (89.7059)  Acc@5: 100.0000 (98.8971)  time: 0.2053  data: 0.0004  max mem: 2356
Test: [Task 9]  [60/63]  eta: 0:00:00  Loss: 0.3839 (0.4201)  Acc@1: 93.7500 (90.0615)  Acc@5: 100.0000 (98.9754)  time: 0.2055  data: 0.0003  max mem: 2356
Test: [Task 9]  [62/63]  eta: 0:00:00  Loss: 0.3120 (0.4135)  Acc@1: 93.7500 (90.2000)  Acc@5: 100.0000 (99.0000)  time: 0.2006  data: 0.0003  max mem: 2356
Test: [Task 9] Total time: 0:00:13 (0.2110 s / it)
* Acc@1 90.200 Acc@5 99.000 loss 0.413
{0: {0: 373, 1: 626, 2: 377, 3: 623, 4: 375, 5: 618, 6: 624, 7: 379, 8: 156, 9: 849}, 1: {0: 596, 1: 404, 2: 597, 3: 403, 4: 596, 5: 403, 6: 404, 7: 597, 8: 463, 9: 537}, 2: {0: 322, 1: 678, 2: 326, 3: 673, 4: 324, 5: 673, 6: 676, 7: 328, 8: 151, 9: 849}, 3: {0: 602, 1: 398, 2: 606, 3: 394, 4: 604, 5: 393, 6: 396, 7: 606, 8: 323, 9: 678}, 4: {0: 625, 1: 374, 2: 628, 3: 372, 4: 627, 5: 370, 6: 374, 7: 629, 8: 396, 9: 605}, 5: {0: 583, 1: 417, 2: 583, 3: 417, 4: 583, 5: 416, 6: 417, 7: 584, 8: 384, 9: 616}, 6: {0: 549, 1: 452, 2: 550, 3: 450, 4: 550, 5: 449, 6: 450, 7: 550, 8: 300, 9: 700}, 7: {0: 505, 1: 494, 2: 511, 3: 490, 4: 508, 5: 484, 6: 492, 7: 516, 8: 212, 9: 788}, 8: {0: 454, 1: 546, 2: 455, 3: 545, 4: 454, 5: 544, 6: 546, 7: 456, 8: 311, 9: 689}}
[Average accuracy till task9]	Acc@1: 83.7778	Acc@5: 96.8889	Loss: 0.6681	Forgetting: 6.5250	Backward: -6.5250
Train: Epoch[1/5]  [  0/313]  eta: 0:03:33  Lr: 0.001875  Loss: 2.0653  Acc@1: 6.2500 (6.2500)  Acc@5: 75.0000 (75.0000)  time: 0.6811  data: 0.3271  max mem: 2356
Train: Epoch[1/5]  [ 10/313]  eta: 0:01:50  Lr: 0.001875  Loss: 1.6911  Acc@1: 68.7500 (58.5227)  Acc@5: 93.7500 (88.6364)  time: 0.3643  data: 0.0301  max mem: 2356
Train: Epoch[1/5]  [ 20/313]  eta: 0:01:42  Lr: 0.001875  Loss: 1.4223  Acc@1: 81.2500 (72.6190)  Acc@5: 93.7500 (92.8571)  time: 0.3339  data: 0.0009  max mem: 2356
Train: Epoch[1/5]  [ 30/313]  eta: 0:01:37  Lr: 0.001875  Loss: 0.9067  Acc@1: 87.5000 (78.6290)  Acc@5: 100.0000 (95.1613)  time: 0.3357  data: 0.0015  max mem: 2356
Train: Epoch[1/5]  [ 40/313]  eta: 0:01:34  Lr: 0.001875  Loss: 0.8706  Acc@1: 87.5000 (80.0305)  Acc@5: 100.0000 (95.2744)  time: 0.3387  data: 0.0014  max mem: 2356
Train: Epoch[1/5]  [ 50/313]  eta: 0:01:30  Lr: 0.001875  Loss: 0.6281  Acc@1: 87.5000 (82.2304)  Acc@5: 100.0000 (95.8333)  time: 0.3365  data: 0.0014  max mem: 2356
Train: Epoch[1/5]  [ 60/313]  eta: 0:01:26  Lr: 0.001875  Loss: 0.7466  Acc@1: 93.7500 (84.3238)  Acc@5: 100.0000 (96.4139)  time: 0.3326  data: 0.0013  max mem: 2356
Train: Epoch[1/5]  [ 70/313]  eta: 0:01:22  Lr: 0.001875  Loss: 0.4090  Acc@1: 93.7500 (85.1232)  Acc@5: 100.0000 (96.8310)  time: 0.3328  data: 0.0006  max mem: 2356
Train: Epoch[1/5]  [ 80/313]  eta: 0:01:18  Lr: 0.001875  Loss: 0.6102  Acc@1: 87.5000 (85.9568)  Acc@5: 100.0000 (97.0679)  time: 0.3321  data: 0.0004  max mem: 2356
Train: Epoch[1/5]  [ 90/313]  eta: 0:01:15  Lr: 0.001875  Loss: 0.8334  Acc@1: 93.7500 (86.5385)  Acc@5: 100.0000 (97.3214)  time: 0.3317  data: 0.0003  max mem: 2356
Train: Epoch[1/5]  [100/313]  eta: 0:01:11  Lr: 0.001875  Loss: 0.1298  Acc@1: 93.7500 (86.8812)  Acc@5: 100.0000 (97.3391)  time: 0.3316  data: 0.0009  max mem: 2356
Train: Epoch[1/5]  [110/313]  eta: 0:01:08  Lr: 0.001875  Loss: 0.3476  Acc@1: 93.7500 (87.5000)  Acc@5: 100.0000 (97.5225)  time: 0.3318  data: 0.0010  max mem: 2356
Train: Epoch[1/5]  [120/313]  eta: 0:01:04  Lr: 0.001875  Loss: 0.2538  Acc@1: 93.7500 (88.0165)  Acc@5: 100.0000 (97.6240)  time: 0.3329  data: 0.0005  max mem: 2356
Train: Epoch[1/5]  [130/313]  eta: 0:01:01  Lr: 0.001875  Loss: 0.3378  Acc@1: 93.7500 (88.3588)  Acc@5: 100.0000 (97.7576)  time: 0.3357  data: 0.0020  max mem: 2356
Train: Epoch[1/5]  [140/313]  eta: 0:00:58  Lr: 0.001875  Loss: 0.0005  Acc@1: 93.7500 (88.4752)  Acc@5: 100.0000 (97.9167)  time: 0.3354  data: 0.0020  max mem: 2356
Train: Epoch[1/5]  [150/313]  eta: 0:00:54  Lr: 0.001875  Loss: 0.2867  Acc@1: 93.7500 (88.7831)  Acc@5: 100.0000 (97.9305)  time: 0.3343  data: 0.0004  max mem: 2356
Train: Epoch[1/5]  [160/313]  eta: 0:00:51  Lr: 0.001875  Loss: 0.0307  Acc@1: 93.7500 (88.9752)  Acc@5: 100.0000 (98.0202)  time: 0.3359  data: 0.0011  max mem: 2356
Train: Epoch[1/5]  [170/313]  eta: 0:00:48  Lr: 0.001875  Loss: -0.0378  Acc@1: 93.7500 (89.1082)  Acc@5: 100.0000 (98.0994)  time: 0.3380  data: 0.0017  max mem: 2356
Train: Epoch[1/5]  [180/313]  eta: 0:00:44  Lr: 0.001875  Loss: 0.0395  Acc@1: 93.7500 (89.4337)  Acc@5: 100.0000 (98.1354)  time: 0.3385  data: 0.0016  max mem: 2356
Train: Epoch[1/5]  [190/313]  eta: 0:00:41  Lr: 0.001875  Loss: 0.1365  Acc@1: 93.7500 (89.4306)  Acc@5: 100.0000 (98.1348)  time: 0.3413  data: 0.0029  max mem: 2356
Train: Epoch[1/5]  [200/313]  eta: 0:00:38  Lr: 0.001875  Loss: 0.2165  Acc@1: 87.5000 (89.4279)  Acc@5: 100.0000 (98.1032)  time: 0.3434  data: 0.0024  max mem: 2356
Train: Epoch[1/5]  [210/313]  eta: 0:00:34  Lr: 0.001875  Loss: 0.0421  Acc@1: 93.7500 (89.5438)  Acc@5: 100.0000 (98.1931)  time: 0.3406  data: 0.0009  max mem: 2356
Train: Epoch[1/5]  [220/313]  eta: 0:00:31  Lr: 0.001875  Loss: 0.1166  Acc@1: 87.5000 (89.4796)  Acc@5: 100.0000 (98.1900)  time: 0.3439  data: 0.0013  max mem: 2356
Train: Epoch[1/5]  [230/313]  eta: 0:00:28  Lr: 0.001875  Loss: -0.0683  Acc@1: 93.7500 (89.7457)  Acc@5: 100.0000 (98.1872)  time: 0.3426  data: 0.0012  max mem: 2356
Train: Epoch[1/5]  [240/313]  eta: 0:00:24  Lr: 0.001875  Loss: -0.0332  Acc@1: 93.7500 (89.9118)  Acc@5: 100.0000 (98.2365)  time: 0.3409  data: 0.0023  max mem: 2356
Train: Epoch[1/5]  [250/313]  eta: 0:00:21  Lr: 0.001875  Loss: 0.1694  Acc@1: 93.7500 (89.9900)  Acc@5: 100.0000 (98.2819)  time: 0.3416  data: 0.0021  max mem: 2356
Train: Epoch[1/5]  [260/313]  eta: 0:00:17  Lr: 0.001875  Loss: 0.3163  Acc@1: 93.7500 (90.1341)  Acc@5: 100.0000 (98.3238)  time: 0.3386  data: 0.0005  max mem: 2356
Train: Epoch[1/5]  [270/313]  eta: 0:00:14  Lr: 0.001875  Loss: 0.1751  Acc@1: 93.7500 (90.1522)  Acc@5: 100.0000 (98.3856)  time: 0.3376  data: 0.0007  max mem: 2356
Train: Epoch[1/5]  [280/313]  eta: 0:00:11  Lr: 0.001875  Loss: -0.0447  Acc@1: 93.7500 (90.2580)  Acc@5: 100.0000 (98.4208)  time: 0.3429  data: 0.0008  max mem: 2356
Train: Epoch[1/5]  [290/313]  eta: 0:00:07  Lr: 0.001875  Loss: -0.0487  Acc@1: 93.7500 (90.2921)  Acc@5: 100.0000 (98.4536)  time: 0.3481  data: 0.0013  max mem: 2356
Train: Epoch[1/5]  [300/313]  eta: 0:00:04  Lr: 0.001875  Loss: -0.0541  Acc@1: 93.7500 (90.3862)  Acc@5: 100.0000 (98.5050)  time: 0.3399  data: 0.0012  max mem: 2356
Train: Epoch[1/5]  [310/313]  eta: 0:00:01  Lr: 0.001875  Loss: -0.0108  Acc@1: 93.7500 (90.4341)  Acc@5: 100.0000 (98.5330)  time: 0.3326  data: 0.0004  max mem: 2356
Train: Epoch[1/5]  [312/313]  eta: 0:00:00  Lr: 0.001875  Loss: 0.3212  Acc@1: 93.7500 (90.3600)  Acc@5: 100.0000 (98.5400)  time: 0.3238  data: 0.0003  max mem: 2356
Train: Epoch[1/5] Total time: 0:01:45 (0.3381 s / it)
{0: {0: 22412, 1: 24815, 2: 19998, 3: 12102, 4: 7737, 5: 7897, 6: 7115, 7: 7163, 8: 6299, 9: 1178}, 1: {0: 1577, 1: 208, 2: 5200, 3: 12775, 4: 17024, 5: 16965, 6: 17861, 7: 17752, 8: 18698, 9: 3778}, 2: {0: 3518, 1: 6779, 2: 5327, 3: 9830, 4: 7541, 5: 7967, 6: 7212, 7: 7116, 8: 6338, 9: 1145}, 3: {0: 21486, 1: 20777, 2: 18903, 3: 14840, 4: 17372, 5: 17103, 6: 18038, 7: 18004, 8: 18675, 9: 3855}, 4: {0: 16124, 1: 10227, 2: 6432, 3: 10102, 4: 7685, 5: 7874, 6: 7043, 7: 7174, 8: 6329, 9: 1222}, 5: {0: 23402, 1: 24357, 2: 21714, 3: 15057, 4: 17322, 5: 16935, 6: 17805, 7: 17989, 8: 18676, 9: 3897}, 6: {0: 9472, 1: 12148, 2: 17669, 3: 14460, 4: 17318, 5: 17115, 6: 17934, 7: 17802, 8: 18664, 9: 3819}, 7: {0: 752, 1: 676, 2: 4577, 3: 10334, 4: 7679, 5: 7891, 6: 6959, 7: 7005, 8: 6309, 9: 1102}, 8: {0: 24269, 1: 24959, 2: 24373, 3: 23260, 4: 19009, 5: 14409, 6: 6643, 7: 6241, 8: 4545, 9: 630}, 9: {0: 1988, 1: 54, 2: 807, 3: 2240, 4: 6313, 5: 10844, 6: 18390, 7: 18754, 8: 20467, 9: 4374}}
Averaged stats: Lr: 0.001875  Loss: 0.3212  Acc@1: 93.7500 (90.3600)  Acc@5: 100.0000 (98.5400)
Train: Epoch[2/5]  [  0/313]  eta: 0:03:16  Lr: 0.001875  Loss: 0.0103  Acc@1: 93.7500 (93.7500)  Acc@5: 100.0000 (100.0000)  time: 0.6276  data: 0.2823  max mem: 2356
Train: Epoch[2/5]  [ 10/313]  eta: 0:01:49  Lr: 0.001875  Loss: -0.0600  Acc@1: 93.7500 (90.9091)  Acc@5: 100.0000 (98.8636)  time: 0.3603  data: 0.0269  max mem: 2356
Train: Epoch[2/5]  [ 20/313]  eta: 0:01:41  Lr: 0.001875  Loss: 0.3320  Acc@1: 87.5000 (90.4762)  Acc@5: 100.0000 (98.5119)  time: 0.3341  data: 0.0009  max mem: 2356
Train: Epoch[2/5]  [ 30/313]  eta: 0:01:37  Lr: 0.001875  Loss: -0.0686  Acc@1: 87.5000 (90.1210)  Acc@5: 93.7500 (97.5806)  time: 0.3341  data: 0.0005  max mem: 2356
Train: Epoch[2/5]  [ 40/313]  eta: 0:01:33  Lr: 0.001875  Loss: -0.0009  Acc@1: 93.7500 (90.2439)  Acc@5: 100.0000 (97.8659)  time: 0.3331  data: 0.0004  max mem: 2356
Train: Epoch[2/5]  [ 50/313]  eta: 0:01:29  Lr: 0.001875  Loss: -0.0380  Acc@1: 93.7500 (90.6863)  Acc@5: 100.0000 (98.2843)  time: 0.3328  data: 0.0004  max mem: 2356
Train: Epoch[2/5]  [ 60/313]  eta: 0:01:25  Lr: 0.001875  Loss: 0.1228  Acc@1: 93.7500 (91.0861)  Acc@5: 100.0000 (98.4631)  time: 0.3332  data: 0.0004  max mem: 2356
Train: Epoch[2/5]  [ 70/313]  eta: 0:01:22  Lr: 0.001875  Loss: 0.1893  Acc@1: 93.7500 (91.2852)  Acc@5: 100.0000 (98.6796)  time: 0.3332  data: 0.0004  max mem: 2356
Train: Epoch[2/5]  [ 80/313]  eta: 0:01:18  Lr: 0.001875  Loss: 0.1449  Acc@1: 93.7500 (91.5895)  Acc@5: 100.0000 (98.7654)  time: 0.3336  data: 0.0004  max mem: 2356
Train: Epoch[2/5]  [ 90/313]  eta: 0:01:15  Lr: 0.001875  Loss: 0.2407  Acc@1: 93.7500 (91.4835)  Acc@5: 100.0000 (98.8324)  time: 0.3323  data: 0.0004  max mem: 2356
Train: Epoch[2/5]  [100/313]  eta: 0:01:11  Lr: 0.001875  Loss: -0.1504  Acc@1: 93.7500 (91.3985)  Acc@5: 100.0000 (98.7624)  time: 0.3306  data: 0.0007  max mem: 2356
Train: Epoch[2/5]  [110/313]  eta: 0:01:08  Lr: 0.001875  Loss: -0.1725  Acc@1: 93.7500 (91.7230)  Acc@5: 100.0000 (98.8176)  time: 0.3308  data: 0.0014  max mem: 2356
Train: Epoch[2/5]  [120/313]  eta: 0:01:04  Lr: 0.001875  Loss: -0.1145  Acc@1: 93.7500 (92.0455)  Acc@5: 100.0000 (98.8636)  time: 0.3305  data: 0.0009  max mem: 2356
Train: Epoch[2/5]  [130/313]  eta: 0:01:01  Lr: 0.001875  Loss: -0.1437  Acc@1: 93.7500 (91.8416)  Acc@5: 100.0000 (98.7595)  time: 0.3301  data: 0.0007  max mem: 2356
Train: Epoch[2/5]  [140/313]  eta: 0:00:57  Lr: 0.001875  Loss: 0.3282  Acc@1: 87.5000 (91.6223)  Acc@5: 100.0000 (98.7145)  time: 0.3305  data: 0.0007  max mem: 2356
Train: Epoch[2/5]  [150/313]  eta: 0:00:54  Lr: 0.001875  Loss: 0.2357  Acc@1: 87.5000 (91.5563)  Acc@5: 100.0000 (98.7169)  time: 0.3301  data: 0.0003  max mem: 2356
Train: Epoch[2/5]  [160/313]  eta: 0:00:51  Lr: 0.001875  Loss: 0.2032  Acc@1: 93.7500 (91.5373)  Acc@5: 100.0000 (98.7189)  time: 0.3305  data: 0.0003  max mem: 2356
Train: Epoch[2/5]  [170/313]  eta: 0:00:47  Lr: 0.001875  Loss: 0.1289  Acc@1: 87.5000 (91.4108)  Acc@5: 100.0000 (98.7208)  time: 0.3315  data: 0.0003  max mem: 2356
Train: Epoch[2/5]  [180/313]  eta: 0:00:44  Lr: 0.001875  Loss: 0.1199  Acc@1: 87.5000 (91.3674)  Acc@5: 100.0000 (98.7569)  time: 0.3354  data: 0.0012  max mem: 2356
Train: Epoch[2/5]  [190/313]  eta: 0:00:41  Lr: 0.001875  Loss: -0.0037  Acc@1: 87.5000 (91.2304)  Acc@5: 100.0000 (98.7893)  time: 0.3379  data: 0.0014  max mem: 2356
Train: Epoch[2/5]  [200/313]  eta: 0:00:37  Lr: 0.001875  Loss: 0.0570  Acc@1: 93.7500 (91.2313)  Acc@5: 100.0000 (98.7251)  time: 0.3374  data: 0.0021  max mem: 2356
Train: Epoch[2/5]  [210/313]  eta: 0:00:34  Lr: 0.001875  Loss: 0.1385  Acc@1: 93.7500 (91.1730)  Acc@5: 100.0000 (98.6967)  time: 0.3380  data: 0.0018  max mem: 2356
Train: Epoch[2/5]  [220/313]  eta: 0:00:31  Lr: 0.001875  Loss: 0.1511  Acc@1: 93.7500 (91.2048)  Acc@5: 100.0000 (98.6991)  time: 0.3358  data: 0.0008  max mem: 2356
Train: Epoch[2/5]  [230/313]  eta: 0:00:27  Lr: 0.001875  Loss: 0.0372  Acc@1: 93.7500 (91.2067)  Acc@5: 100.0000 (98.7013)  time: 0.3393  data: 0.0009  max mem: 2356
Train: Epoch[2/5]  [240/313]  eta: 0:00:24  Lr: 0.001875  Loss: 0.0797  Acc@1: 93.7500 (91.3382)  Acc@5: 100.0000 (98.7552)  time: 0.3434  data: 0.0005  max mem: 2356
Train: Epoch[2/5]  [250/313]  eta: 0:00:21  Lr: 0.001875  Loss: 0.2226  Acc@1: 93.7500 (91.3845)  Acc@5: 100.0000 (98.8048)  time: 0.3390  data: 0.0005  max mem: 2356
Train: Epoch[2/5]  [260/313]  eta: 0:00:17  Lr: 0.001875  Loss: -0.0498  Acc@1: 93.7500 (91.4272)  Acc@5: 100.0000 (98.8266)  time: 0.3444  data: 0.0017  max mem: 2356
Train: Epoch[2/5]  [270/313]  eta: 0:00:14  Lr: 0.001875  Loss: 0.1047  Acc@1: 93.7500 (91.4899)  Acc@5: 100.0000 (98.8238)  time: 0.3455  data: 0.0017  max mem: 2356
Train: Epoch[2/5]  [280/313]  eta: 0:00:11  Lr: 0.001875  Loss: 0.0690  Acc@1: 93.7500 (91.5480)  Acc@5: 100.0000 (98.8434)  time: 0.3408  data: 0.0005  max mem: 2356
Train: Epoch[2/5]  [290/313]  eta: 0:00:07  Lr: 0.001875  Loss: 0.3899  Acc@1: 93.7500 (91.5808)  Acc@5: 100.0000 (98.8832)  time: 0.3449  data: 0.0007  max mem: 2356
Train: Epoch[2/5]  [300/313]  eta: 0:00:04  Lr: 0.001875  Loss: 0.0470  Acc@1: 93.7500 (91.6113)  Acc@5: 100.0000 (98.8995)  time: 0.3423  data: 0.0014  max mem: 2356
Train: Epoch[2/5]  [310/313]  eta: 0:00:01  Lr: 0.001875  Loss: -0.1746  Acc@1: 93.7500 (91.6198)  Acc@5: 100.0000 (98.8746)  time: 0.3370  data: 0.0023  max mem: 2356
Train: Epoch[2/5]  [312/313]  eta: 0:00:00  Lr: 0.001875  Loss: -0.0471  Acc@1: 93.7500 (91.6400)  Acc@5: 100.0000 (98.8800)  time: 0.3286  data: 0.0023  max mem: 2356
Train: Epoch[2/5] Total time: 0:01:45 (0.3364 s / it)
{0: {0: 22412, 1: 24815, 2: 19998, 3: 12102, 4: 7737, 5: 7897, 6: 7115, 7: 7163, 8: 6299, 9: 2516}, 1: {0: 1577, 1: 208, 2: 5200, 3: 12775, 4: 17024, 5: 16965, 6: 17861, 7: 17752, 8: 18698, 9: 7377}, 2: {0: 3518, 1: 6779, 2: 5327, 3: 9830, 4: 7541, 5: 7967, 6: 7212, 7: 7116, 8: 6338, 9: 2369}, 3: {0: 21486, 1: 20777, 2: 18903, 3: 14840, 4: 17372, 5: 17103, 6: 18038, 7: 18004, 8: 18675, 9: 7630}, 4: {0: 16124, 1: 10227, 2: 6432, 3: 10102, 4: 7685, 5: 7874, 6: 7043, 7: 7174, 8: 6329, 9: 2622}, 5: {0: 23402, 1: 24357, 2: 21714, 3: 15057, 4: 17322, 5: 16935, 6: 17805, 7: 17989, 8: 18676, 9: 7740}, 6: {0: 9472, 1: 12148, 2: 17669, 3: 14460, 4: 17318, 5: 17115, 6: 17934, 7: 17802, 8: 18664, 9: 7478}, 7: {0: 752, 1: 676, 2: 4577, 3: 10334, 4: 7679, 5: 7891, 6: 6959, 7: 7005, 8: 6309, 9: 2257}, 8: {0: 24269, 1: 24959, 2: 24373, 3: 23260, 4: 19009, 5: 14409, 6: 6643, 7: 6241, 8: 4545, 9: 1313}, 9: {0: 1988, 1: 54, 2: 807, 3: 2240, 4: 6313, 5: 10844, 6: 18390, 7: 18754, 8: 20467, 9: 8698}}
Averaged stats: Lr: 0.001875  Loss: -0.0471  Acc@1: 93.7500 (91.6400)  Acc@5: 100.0000 (98.8800)
Train: Epoch[3/5]  [  0/313]  eta: 0:03:12  Lr: 0.001875  Loss: -0.0049  Acc@1: 93.7500 (93.7500)  Acc@5: 100.0000 (100.0000)  time: 0.6157  data: 0.2783  max mem: 2356
Train: Epoch[3/5]  [ 10/313]  eta: 0:01:52  Lr: 0.001875  Loss: 0.1387  Acc@1: 87.5000 (88.0682)  Acc@5: 100.0000 (98.2955)  time: 0.3703  data: 0.0280  max mem: 2356
Train: Epoch[3/5]  [ 20/313]  eta: 0:01:44  Lr: 0.001875  Loss: -0.0687  Acc@1: 87.5000 (90.7738)  Acc@5: 100.0000 (99.1071)  time: 0.3421  data: 0.0024  max mem: 2356
Train: Epoch[3/5]  [ 30/313]  eta: 0:01:38  Lr: 0.001875  Loss: -0.0936  Acc@1: 93.7500 (90.7258)  Acc@5: 100.0000 (99.3952)  time: 0.3359  data: 0.0011  max mem: 2356
Train: Epoch[3/5]  [ 40/313]  eta: 0:01:34  Lr: 0.001875  Loss: 0.3662  Acc@1: 93.7500 (91.4634)  Acc@5: 100.0000 (99.3902)  time: 0.3332  data: 0.0005  max mem: 2356
Train: Epoch[3/5]  [ 50/313]  eta: 0:01:30  Lr: 0.001875  Loss: 0.2146  Acc@1: 93.7500 (91.5441)  Acc@5: 100.0000 (99.5098)  time: 0.3331  data: 0.0007  max mem: 2356
Train: Epoch[3/5]  [ 60/313]  eta: 0:01:26  Lr: 0.001875  Loss: -0.0535  Acc@1: 93.7500 (91.2910)  Acc@5: 100.0000 (99.3852)  time: 0.3324  data: 0.0006  max mem: 2356
Train: Epoch[3/5]  [ 70/313]  eta: 0:01:22  Lr: 0.001875  Loss: -0.1948  Acc@1: 93.7500 (91.5493)  Acc@5: 100.0000 (99.4718)  time: 0.3328  data: 0.0005  max mem: 2356
Train: Epoch[3/5]  [ 80/313]  eta: 0:01:18  Lr: 0.001875  Loss: -0.0928  Acc@1: 93.7500 (91.6667)  Acc@5: 100.0000 (99.4599)  time: 0.3334  data: 0.0004  max mem: 2356
Train: Epoch[3/5]  [ 90/313]  eta: 0:01:15  Lr: 0.001875  Loss: -0.2097  Acc@1: 93.7500 (91.8269)  Acc@5: 100.0000 (99.4505)  time: 0.3324  data: 0.0004  max mem: 2356
Train: Epoch[3/5]  [100/313]  eta: 0:01:11  Lr: 0.001875  Loss: -0.0892  Acc@1: 93.7500 (92.2030)  Acc@5: 100.0000 (99.5050)  time: 0.3325  data: 0.0004  max mem: 2356
Train: Epoch[3/5]  [110/313]  eta: 0:01:08  Lr: 0.001875  Loss: 0.1313  Acc@1: 93.7500 (92.3423)  Acc@5: 100.0000 (99.4932)  time: 0.3333  data: 0.0003  max mem: 2356
Train: Epoch[3/5]  [120/313]  eta: 0:01:05  Lr: 0.001875  Loss: -0.0608  Acc@1: 93.7500 (92.6136)  Acc@5: 100.0000 (99.5351)  time: 0.3343  data: 0.0004  max mem: 2356
Train: Epoch[3/5]  [130/313]  eta: 0:01:01  Lr: 0.001875  Loss: 0.0256  Acc@1: 93.7500 (92.4618)  Acc@5: 100.0000 (99.4275)  time: 0.3351  data: 0.0007  max mem: 2356
Train: Epoch[3/5]  [140/313]  eta: 0:00:58  Lr: 0.001875  Loss: 0.1882  Acc@1: 93.7500 (92.4202)  Acc@5: 100.0000 (99.3351)  time: 0.3342  data: 0.0006  max mem: 2356
Train: Epoch[3/5]  [150/313]  eta: 0:00:54  Lr: 0.001875  Loss: 0.2873  Acc@1: 93.7500 (92.3427)  Acc@5: 100.0000 (99.3791)  time: 0.3322  data: 0.0003  max mem: 2356
Train: Epoch[3/5]  [160/313]  eta: 0:00:51  Lr: 0.001875  Loss: 0.1197  Acc@1: 93.7500 (92.3137)  Acc@5: 100.0000 (99.4177)  time: 0.3318  data: 0.0007  max mem: 2356
Train: Epoch[3/5]  [170/313]  eta: 0:00:48  Lr: 0.001875  Loss: 0.2009  Acc@1: 87.5000 (92.1784)  Acc@5: 100.0000 (99.4152)  time: 0.3321  data: 0.0007  max mem: 2356
Train: Epoch[3/5]  [180/313]  eta: 0:00:44  Lr: 0.001875  Loss: -0.0575  Acc@1: 87.5000 (92.1271)  Acc@5: 100.0000 (99.4475)  time: 0.3339  data: 0.0013  max mem: 2356
Train: Epoch[3/5]  [190/313]  eta: 0:00:41  Lr: 0.001875  Loss: 0.1968  Acc@1: 93.7500 (92.0812)  Acc@5: 100.0000 (99.4437)  time: 0.3350  data: 0.0013  max mem: 2356
Train: Epoch[3/5]  [200/313]  eta: 0:00:37  Lr: 0.001875  Loss: -0.1702  Acc@1: 93.7500 (92.1020)  Acc@5: 100.0000 (99.4092)  time: 0.3326  data: 0.0004  max mem: 2356
Train: Epoch[3/5]  [210/313]  eta: 0:00:34  Lr: 0.001875  Loss: 0.1999  Acc@1: 93.7500 (92.1801)  Acc@5: 100.0000 (99.3780)  time: 0.3324  data: 0.0014  max mem: 2356
Train: Epoch[3/5]  [220/313]  eta: 0:00:31  Lr: 0.001875  Loss: -0.1294  Acc@1: 93.7500 (92.3077)  Acc@5: 100.0000 (99.4061)  time: 0.3363  data: 0.0019  max mem: 2356
Train: Epoch[3/5]  [230/313]  eta: 0:00:27  Lr: 0.001875  Loss: 0.0698  Acc@1: 93.7500 (92.2890)  Acc@5: 100.0000 (99.3506)  time: 0.3385  data: 0.0010  max mem: 2356
Train: Epoch[3/5]  [240/313]  eta: 0:00:24  Lr: 0.001875  Loss: -0.0935  Acc@1: 93.7500 (92.3237)  Acc@5: 100.0000 (99.3257)  time: 0.3364  data: 0.0007  max mem: 2356
Train: Epoch[3/5]  [250/313]  eta: 0:00:21  Lr: 0.001875  Loss: -0.1822  Acc@1: 93.7500 (92.2809)  Acc@5: 100.0000 (99.3028)  time: 0.3366  data: 0.0007  max mem: 2356
Train: Epoch[3/5]  [260/313]  eta: 0:00:17  Lr: 0.001875  Loss: -0.0112  Acc@1: 93.7500 (92.3372)  Acc@5: 100.0000 (99.3056)  time: 0.3382  data: 0.0015  max mem: 2356
Train: Epoch[3/5]  [270/313]  eta: 0:00:14  Lr: 0.001875  Loss: -0.1666  Acc@1: 93.7500 (92.4124)  Acc@5: 100.0000 (99.3081)  time: 0.3356  data: 0.0022  max mem: 2356
Train: Epoch[3/5]  [280/313]  eta: 0:00:11  Lr: 0.001875  Loss: -0.0971  Acc@1: 93.7500 (92.4377)  Acc@5: 100.0000 (99.3105)  time: 0.3383  data: 0.0028  max mem: 2356
Train: Epoch[3/5]  [290/313]  eta: 0:00:07  Lr: 0.001875  Loss: -0.1467  Acc@1: 93.7500 (92.4184)  Acc@5: 100.0000 (99.3342)  time: 0.3446  data: 0.0028  max mem: 2356
Train: Epoch[3/5]  [300/313]  eta: 0:00:04  Lr: 0.001875  Loss: 0.1520  Acc@1: 93.7500 (92.4003)  Acc@5: 100.0000 (99.2940)  time: 0.3414  data: 0.0011  max mem: 2356
Train: Epoch[3/5]  [310/313]  eta: 0:00:01  Lr: 0.001875  Loss: 0.3389  Acc@1: 93.7500 (92.4437)  Acc@5: 100.0000 (99.2966)  time: 0.3377  data: 0.0013  max mem: 2356
Train: Epoch[3/5]  [312/313]  eta: 0:00:00  Lr: 0.001875  Loss: -0.0169  Acc@1: 93.7500 (92.4600)  Acc@5: 100.0000 (99.3000)  time: 0.3292  data: 0.0013  max mem: 2356
Train: Epoch[3/5] Total time: 0:01:45 (0.3362 s / it)
{0: {0: 22412, 1: 24815, 2: 19998, 3: 12102, 4: 7737, 5: 7897, 6: 7115, 7: 7163, 8: 6299, 9: 3902}, 1: {0: 1577, 1: 208, 2: 5200, 3: 12775, 4: 17024, 5: 16965, 6: 17861, 7: 17752, 8: 18698, 9: 10901}, 2: {0: 3518, 1: 6779, 2: 5327, 3: 9830, 4: 7541, 5: 7967, 6: 7212, 7: 7116, 8: 6338, 9: 3670}, 3: {0: 21486, 1: 20777, 2: 18903, 3: 14840, 4: 17372, 5: 17103, 6: 18038, 7: 18004, 8: 18675, 9: 11329}, 4: {0: 16124, 1: 10227, 2: 6432, 3: 10102, 4: 7685, 5: 7874, 6: 7043, 7: 7174, 8: 6329, 9: 4095}, 5: {0: 23402, 1: 24357, 2: 21714, 3: 15057, 4: 17322, 5: 16935, 6: 17805, 7: 17989, 8: 18676, 9: 11534}, 6: {0: 9472, 1: 12148, 2: 17669, 3: 14460, 4: 17318, 5: 17115, 6: 17934, 7: 17802, 8: 18664, 9: 11091}, 7: {0: 752, 1: 676, 2: 4577, 3: 10334, 4: 7679, 5: 7891, 6: 6959, 7: 7005, 8: 6309, 9: 3466}, 8: {0: 24269, 1: 24959, 2: 24373, 3: 23260, 4: 19009, 5: 14409, 6: 6643, 7: 6241, 8: 4545, 9: 1972}, 9: {0: 1988, 1: 54, 2: 807, 3: 2240, 4: 6313, 5: 10844, 6: 18390, 7: 18754, 8: 20467, 9: 13040}}
Averaged stats: Lr: 0.001875  Loss: -0.0169  Acc@1: 93.7500 (92.4600)  Acc@5: 100.0000 (99.3000)
Train: Epoch[4/5]  [  0/313]  eta: 0:03:16  Lr: 0.001875  Loss: 0.0905  Acc@1: 93.7500 (93.7500)  Acc@5: 100.0000 (100.0000)  time: 0.6267  data: 0.2899  max mem: 2356
Train: Epoch[4/5]  [ 10/313]  eta: 0:01:51  Lr: 0.001875  Loss: -0.0472  Acc@1: 93.7500 (93.1818)  Acc@5: 100.0000 (100.0000)  time: 0.3695  data: 0.0268  max mem: 2356
Train: Epoch[4/5]  [ 20/313]  eta: 0:01:44  Lr: 0.001875  Loss: -0.1381  Acc@1: 93.7500 (93.4524)  Acc@5: 100.0000 (100.0000)  time: 0.3422  data: 0.0023  max mem: 2356
Train: Epoch[4/5]  [ 30/313]  eta: 0:01:38  Lr: 0.001875  Loss: 0.0704  Acc@1: 93.7500 (93.5484)  Acc@5: 100.0000 (99.7984)  time: 0.3381  data: 0.0024  max mem: 2356
Train: Epoch[4/5]  [ 40/313]  eta: 0:01:34  Lr: 0.001875  Loss: 0.1996  Acc@1: 93.7500 (92.9878)  Acc@5: 100.0000 (99.6951)  time: 0.3380  data: 0.0010  max mem: 2356
Train: Epoch[4/5]  [ 50/313]  eta: 0:01:31  Lr: 0.001875  Loss: 0.2981  Acc@1: 93.7500 (92.5245)  Acc@5: 100.0000 (99.6324)  time: 0.3420  data: 0.0026  max mem: 2356
Train: Epoch[4/5]  [ 60/313]  eta: 0:01:27  Lr: 0.001875  Loss: 0.0304  Acc@1: 93.7500 (92.4180)  Acc@5: 100.0000 (99.5902)  time: 0.3444  data: 0.0024  max mem: 2356
Train: Epoch[4/5]  [ 70/313]  eta: 0:01:23  Lr: 0.001875  Loss: 0.6737  Acc@1: 93.7500 (91.9014)  Acc@5: 100.0000 (99.4718)  time: 0.3387  data: 0.0006  max mem: 2356
Train: Epoch[4/5]  [ 80/313]  eta: 0:01:19  Lr: 0.001875  Loss: 0.0164  Acc@1: 93.7500 (91.8981)  Acc@5: 100.0000 (99.5370)  time: 0.3326  data: 0.0005  max mem: 2356
Train: Epoch[4/5]  [ 90/313]  eta: 0:01:16  Lr: 0.001875  Loss: -0.0114  Acc@1: 93.7500 (92.1016)  Acc@5: 100.0000 (99.5192)  time: 0.3331  data: 0.0004  max mem: 2356
Train: Epoch[4/5]  [100/313]  eta: 0:01:12  Lr: 0.001875  Loss: -0.1805  Acc@1: 93.7500 (92.3886)  Acc@5: 100.0000 (99.5668)  time: 0.3326  data: 0.0003  max mem: 2356
Train: Epoch[4/5]  [110/313]  eta: 0:01:09  Lr: 0.001875  Loss: 0.2047  Acc@1: 93.7500 (92.2860)  Acc@5: 100.0000 (99.4932)  time: 0.3329  data: 0.0003  max mem: 2356
Train: Epoch[4/5]  [120/313]  eta: 0:01:05  Lr: 0.001875  Loss: 0.5938  Acc@1: 87.5000 (92.2004)  Acc@5: 100.0000 (99.4318)  time: 0.3329  data: 0.0004  max mem: 2356
Train: Epoch[4/5]  [130/313]  eta: 0:01:02  Lr: 0.001875  Loss: -0.0558  Acc@1: 93.7500 (92.4141)  Acc@5: 100.0000 (99.4752)  time: 0.3327  data: 0.0006  max mem: 2356
Train: Epoch[4/5]  [140/313]  eta: 0:00:58  Lr: 0.001875  Loss: -0.1158  Acc@1: 93.7500 (92.4645)  Acc@5: 100.0000 (99.5124)  time: 0.3332  data: 0.0006  max mem: 2356
Train: Epoch[4/5]  [150/313]  eta: 0:00:55  Lr: 0.001875  Loss: 0.2149  Acc@1: 93.7500 (92.4255)  Acc@5: 100.0000 (99.5033)  time: 0.3328  data: 0.0003  max mem: 2356
Train: Epoch[4/5]  [160/313]  eta: 0:00:51  Lr: 0.001875  Loss: 0.3037  Acc@1: 93.7500 (92.3525)  Acc@5: 100.0000 (99.5342)  time: 0.3338  data: 0.0007  max mem: 2356
Train: Epoch[4/5]  [170/313]  eta: 0:00:48  Lr: 0.001875  Loss: -0.1141  Acc@1: 87.5000 (92.1418)  Acc@5: 100.0000 (99.5614)  time: 0.3343  data: 0.0012  max mem: 2356
Train: Epoch[4/5]  [180/313]  eta: 0:00:44  Lr: 0.001875  Loss: -0.0404  Acc@1: 93.7500 (92.1961)  Acc@5: 100.0000 (99.5166)  time: 0.3337  data: 0.0008  max mem: 2356
Train: Epoch[4/5]  [190/313]  eta: 0:00:41  Lr: 0.001875  Loss: -0.0821  Acc@1: 93.7500 (92.4084)  Acc@5: 100.0000 (99.5092)  time: 0.3339  data: 0.0009  max mem: 2356
Train: Epoch[4/5]  [200/313]  eta: 0:00:38  Lr: 0.001875  Loss: 0.1291  Acc@1: 93.7500 (92.3507)  Acc@5: 100.0000 (99.5025)  time: 0.3341  data: 0.0015  max mem: 2356
Train: Epoch[4/5]  [210/313]  eta: 0:00:34  Lr: 0.001875  Loss: -0.1531  Acc@1: 93.7500 (92.3578)  Acc@5: 100.0000 (99.4668)  time: 0.3327  data: 0.0009  max mem: 2356
Train: Epoch[4/5]  [220/313]  eta: 0:00:31  Lr: 0.001875  Loss: -0.1875  Acc@1: 93.7500 (92.4774)  Acc@5: 100.0000 (99.4910)  time: 0.3320  data: 0.0014  max mem: 2356
Train: Epoch[4/5]  [230/313]  eta: 0:00:27  Lr: 0.001875  Loss: 0.0102  Acc@1: 93.7500 (92.5054)  Acc@5: 100.0000 (99.4589)  time: 0.3317  data: 0.0014  max mem: 2356
Train: Epoch[4/5]  [240/313]  eta: 0:00:24  Lr: 0.001875  Loss: 0.3109  Acc@1: 93.7500 (92.6089)  Acc@5: 100.0000 (99.4554)  time: 0.3311  data: 0.0006  max mem: 2356
Train: Epoch[4/5]  [250/313]  eta: 0:00:21  Lr: 0.001875  Loss: 0.1787  Acc@1: 93.7500 (92.6295)  Acc@5: 100.0000 (99.4771)  time: 0.3327  data: 0.0011  max mem: 2356
Train: Epoch[4/5]  [260/313]  eta: 0:00:17  Lr: 0.001875  Loss: -0.1407  Acc@1: 93.7500 (92.5287)  Acc@5: 100.0000 (99.4253)  time: 0.3332  data: 0.0009  max mem: 2356
Train: Epoch[4/5]  [270/313]  eta: 0:00:14  Lr: 0.001875  Loss: -0.0173  Acc@1: 93.7500 (92.4815)  Acc@5: 100.0000 (99.3773)  time: 0.3357  data: 0.0015  max mem: 2356
Train: Epoch[4/5]  [280/313]  eta: 0:00:11  Lr: 0.001875  Loss: -0.2211  Acc@1: 93.7500 (92.6157)  Acc@5: 100.0000 (99.3995)  time: 0.3392  data: 0.0016  max mem: 2356
Train: Epoch[4/5]  [290/313]  eta: 0:00:07  Lr: 0.001875  Loss: -0.1894  Acc@1: 100.0000 (92.7191)  Acc@5: 100.0000 (99.3986)  time: 0.3413  data: 0.0020  max mem: 2356
Train: Epoch[4/5]  [300/313]  eta: 0:00:04  Lr: 0.001875  Loss: -0.0539  Acc@1: 93.7500 (92.7118)  Acc@5: 100.0000 (99.3771)  time: 0.3413  data: 0.0019  max mem: 2356
Train: Epoch[4/5]  [310/313]  eta: 0:00:01  Lr: 0.001875  Loss: 0.2483  Acc@1: 93.7500 (92.8256)  Acc@5: 100.0000 (99.3971)  time: 0.3393  data: 0.0007  max mem: 2356
Train: Epoch[4/5]  [312/313]  eta: 0:00:00  Lr: 0.001875  Loss: -0.2384  Acc@1: 93.7500 (92.8200)  Acc@5: 100.0000 (99.4000)  time: 0.3330  data: 0.0007  max mem: 2356
Train: Epoch[4/5] Total time: 0:01:45 (0.3367 s / it)
{0: {0: 22412, 1: 24815, 2: 19998, 3: 12102, 4: 7737, 5: 7897, 6: 7115, 7: 7163, 8: 6299, 9: 5433}, 1: {0: 1577, 1: 208, 2: 5200, 3: 12775, 4: 17024, 5: 16965, 6: 17861, 7: 17752, 8: 18698, 9: 14265}, 2: {0: 3518, 1: 6779, 2: 5327, 3: 9830, 4: 7541, 5: 7967, 6: 7212, 7: 7116, 8: 6338, 9: 5097}, 3: {0: 21486, 1: 20777, 2: 18903, 3: 14840, 4: 17372, 5: 17103, 6: 18038, 7: 18004, 8: 18675, 9: 14904}, 4: {0: 16124, 1: 10227, 2: 6432, 3: 10102, 4: 7685, 5: 7874, 6: 7043, 7: 7174, 8: 6329, 9: 5725}, 5: {0: 23402, 1: 24357, 2: 21714, 3: 15057, 4: 17322, 5: 16935, 6: 17805, 7: 17989, 8: 18676, 9: 15186}, 6: {0: 9472, 1: 12148, 2: 17669, 3: 14460, 4: 17318, 5: 17115, 6: 17934, 7: 17802, 8: 18664, 9: 14557}, 7: {0: 752, 1: 676, 2: 4577, 3: 10334, 4: 7679, 5: 7891, 6: 6959, 7: 7005, 8: 6309, 9: 4819}, 8: {0: 24269, 1: 24959, 2: 24373, 3: 23260, 4: 19009, 5: 14409, 6: 6643, 7: 6241, 8: 4545, 9: 2652}, 9: {0: 1988, 1: 54, 2: 807, 3: 2240, 4: 6313, 5: 10844, 6: 18390, 7: 18754, 8: 20467, 9: 17362}}
Averaged stats: Lr: 0.001875  Loss: -0.2384  Acc@1: 93.7500 (92.8200)  Acc@5: 100.0000 (99.4000)
Train: Epoch[5/5]  [  0/313]  eta: 0:03:19  Lr: 0.001875  Loss: 0.1077  Acc@1: 81.2500 (81.2500)  Acc@5: 100.0000 (100.0000)  time: 0.6387  data: 0.2879  max mem: 2356
Train: Epoch[5/5]  [ 10/313]  eta: 0:01:52  Lr: 0.001875  Loss: 0.2988  Acc@1: 93.7500 (92.0455)  Acc@5: 100.0000 (100.0000)  time: 0.3710  data: 0.0267  max mem: 2356
Train: Epoch[5/5]  [ 20/313]  eta: 0:01:44  Lr: 0.001875  Loss: 0.1888  Acc@1: 93.7500 (92.2619)  Acc@5: 100.0000 (100.0000)  time: 0.3443  data: 0.0011  max mem: 2356
Train: Epoch[5/5]  [ 30/313]  eta: 0:01:39  Lr: 0.001875  Loss: 0.0139  Acc@1: 93.7500 (91.5323)  Acc@5: 100.0000 (99.3952)  time: 0.3404  data: 0.0011  max mem: 2356
Train: Epoch[5/5]  [ 40/313]  eta: 0:01:35  Lr: 0.001875  Loss: 0.5277  Acc@1: 93.7500 (91.6159)  Acc@5: 100.0000 (99.0854)  time: 0.3396  data: 0.0029  max mem: 2356
Train: Epoch[5/5]  [ 50/313]  eta: 0:01:31  Lr: 0.001875  Loss: -0.1645  Acc@1: 100.0000 (92.6471)  Acc@5: 100.0000 (99.1422)  time: 0.3419  data: 0.0035  max mem: 2356
Train: Epoch[5/5]  [ 60/313]  eta: 0:01:27  Lr: 0.001875  Loss: -0.1553  Acc@1: 93.7500 (92.8279)  Acc@5: 100.0000 (99.2828)  time: 0.3400  data: 0.0010  max mem: 2356
Train: Epoch[5/5]  [ 70/313]  eta: 0:01:23  Lr: 0.001875  Loss: -0.1583  Acc@1: 93.7500 (93.1338)  Acc@5: 100.0000 (99.2958)  time: 0.3395  data: 0.0004  max mem: 2356
Train: Epoch[5/5]  [ 80/313]  eta: 0:01:20  Lr: 0.001875  Loss: 0.0625  Acc@1: 93.7500 (92.9784)  Acc@5: 100.0000 (99.3056)  time: 0.3389  data: 0.0006  max mem: 2356
Train: Epoch[5/5]  [ 90/313]  eta: 0:01:16  Lr: 0.001875  Loss: -0.1423  Acc@1: 93.7500 (93.2005)  Acc@5: 100.0000 (99.3819)  time: 0.3432  data: 0.0014  max mem: 2356
Train: Epoch[5/5]  [100/313]  eta: 0:01:13  Lr: 0.001875  Loss: 0.1781  Acc@1: 93.7500 (93.0693)  Acc@5: 100.0000 (99.3193)  time: 0.3442  data: 0.0036  max mem: 2356
Train: Epoch[5/5]  [110/313]  eta: 0:01:09  Lr: 0.001875  Loss: -0.0633  Acc@1: 93.7500 (93.0180)  Acc@5: 100.0000 (99.3806)  time: 0.3362  data: 0.0028  max mem: 2356
Train: Epoch[5/5]  [120/313]  eta: 0:01:06  Lr: 0.001875  Loss: -0.1587  Acc@1: 93.7500 (93.1818)  Acc@5: 100.0000 (99.3802)  time: 0.3327  data: 0.0004  max mem: 2356
Train: Epoch[5/5]  [130/313]  eta: 0:01:02  Lr: 0.001875  Loss: 0.1218  Acc@1: 93.7500 (93.2729)  Acc@5: 100.0000 (99.3798)  time: 0.3329  data: 0.0004  max mem: 2356
Train: Epoch[5/5]  [140/313]  eta: 0:00:59  Lr: 0.001875  Loss: 0.1428  Acc@1: 87.5000 (92.9965)  Acc@5: 100.0000 (99.4238)  time: 0.3334  data: 0.0004  max mem: 2356
Train: Epoch[5/5]  [150/313]  eta: 0:00:55  Lr: 0.001875  Loss: 0.0743  Acc@1: 87.5000 (92.7566)  Acc@5: 100.0000 (99.2550)  time: 0.3332  data: 0.0004  max mem: 2356
Train: Epoch[5/5]  [160/313]  eta: 0:00:52  Lr: 0.001875  Loss: -0.1133  Acc@1: 93.7500 (92.8571)  Acc@5: 100.0000 (99.2624)  time: 0.3326  data: 0.0004  max mem: 2356
Train: Epoch[5/5]  [170/313]  eta: 0:00:48  Lr: 0.001875  Loss: -0.0662  Acc@1: 93.7500 (92.9459)  Acc@5: 100.0000 (99.2690)  time: 0.3331  data: 0.0004  max mem: 2356
Train: Epoch[5/5]  [180/313]  eta: 0:00:45  Lr: 0.001875  Loss: -0.0609  Acc@1: 93.7500 (92.7141)  Acc@5: 100.0000 (99.2058)  time: 0.3329  data: 0.0004  max mem: 2356
Train: Epoch[5/5]  [190/313]  eta: 0:00:41  Lr: 0.001875  Loss: -0.0788  Acc@1: 93.7500 (92.7683)  Acc@5: 100.0000 (99.1819)  time: 0.3325  data: 0.0004  max mem: 2356
Train: Epoch[5/5]  [200/313]  eta: 0:00:38  Lr: 0.001875  Loss: -0.0226  Acc@1: 93.7500 (92.7550)  Acc@5: 100.0000 (99.2226)  time: 0.3330  data: 0.0004  max mem: 2356
Train: Epoch[5/5]  [210/313]  eta: 0:00:34  Lr: 0.001875  Loss: 0.0250  Acc@1: 93.7500 (92.6244)  Acc@5: 100.0000 (99.2299)  time: 0.3327  data: 0.0004  max mem: 2356
Train: Epoch[5/5]  [220/313]  eta: 0:00:31  Lr: 0.001875  Loss: -0.1810  Acc@1: 93.7500 (92.7036)  Acc@5: 100.0000 (99.2364)  time: 0.3312  data: 0.0003  max mem: 2356
Train: Epoch[5/5]  [230/313]  eta: 0:00:28  Lr: 0.001875  Loss: 0.2918  Acc@1: 93.7500 (92.7219)  Acc@5: 100.0000 (99.2424)  time: 0.3305  data: 0.0004  max mem: 2356
Train: Epoch[5/5]  [240/313]  eta: 0:00:24  Lr: 0.001875  Loss: 0.2203  Acc@1: 93.7500 (92.8423)  Acc@5: 100.0000 (99.2479)  time: 0.3304  data: 0.0004  max mem: 2356
Train: Epoch[5/5]  [250/313]  eta: 0:00:21  Lr: 0.001875  Loss: -0.1378  Acc@1: 93.7500 (92.8785)  Acc@5: 100.0000 (99.2032)  time: 0.3301  data: 0.0003  max mem: 2356
Train: Epoch[5/5]  [260/313]  eta: 0:00:17  Lr: 0.001875  Loss: 0.3841  Acc@1: 93.7500 (92.8400)  Acc@5: 100.0000 (99.2098)  time: 0.3307  data: 0.0003  max mem: 2356
Train: Epoch[5/5]  [270/313]  eta: 0:00:14  Lr: 0.001875  Loss: -0.0679  Acc@1: 93.7500 (92.8736)  Acc@5: 100.0000 (99.2159)  time: 0.3308  data: 0.0003  max mem: 2356
Train: Epoch[5/5]  [280/313]  eta: 0:00:11  Lr: 0.001875  Loss: -0.1913  Acc@1: 93.7500 (92.9493)  Acc@5: 100.0000 (99.2215)  time: 0.3315  data: 0.0003  max mem: 2356
Train: Epoch[5/5]  [290/313]  eta: 0:00:07  Lr: 0.001875  Loss: -0.1921  Acc@1: 93.7500 (92.8265)  Acc@5: 100.0000 (99.2268)  time: 0.3354  data: 0.0004  max mem: 2356
Train: Epoch[5/5]  [300/313]  eta: 0:00:04  Lr: 0.001875  Loss: 0.1082  Acc@1: 93.7500 (92.8571)  Acc@5: 100.0000 (99.2525)  time: 0.3391  data: 0.0013  max mem: 2356
Train: Epoch[5/5]  [310/313]  eta: 0:00:01  Lr: 0.001875  Loss: -0.0114  Acc@1: 93.7500 (92.9461)  Acc@5: 100.0000 (99.2564)  time: 0.3450  data: 0.0023  max mem: 2356
Train: Epoch[5/5]  [312/313]  eta: 0:00:00  Lr: 0.001875  Loss: -0.0555  Acc@1: 93.7500 (92.9400)  Acc@5: 100.0000 (99.2600)  time: 0.3370  data: 0.0023  max mem: 2356
Train: Epoch[5/5] Total time: 0:01:45 (0.3369 s / it)
{0: {0: 22412, 1: 24815, 2: 19998, 3: 12102, 4: 7737, 5: 7897, 6: 7115, 7: 7163, 8: 6299, 9: 7168}, 1: {0: 1577, 1: 208, 2: 5200, 3: 12775, 4: 17024, 5: 16965, 6: 17861, 7: 17752, 8: 18698, 9: 17485}, 2: {0: 3518, 1: 6779, 2: 5327, 3: 9830, 4: 7541, 5: 7967, 6: 7212, 7: 7116, 8: 6338, 9: 6646}, 3: {0: 21486, 1: 20777, 2: 18903, 3: 14840, 4: 17372, 5: 17103, 6: 18038, 7: 18004, 8: 18675, 9: 18354}, 4: {0: 16124, 1: 10227, 2: 6432, 3: 10102, 4: 7685, 5: 7874, 6: 7043, 7: 7174, 8: 6329, 9: 7496}, 5: {0: 23402, 1: 24357, 2: 21714, 3: 15057, 4: 17322, 5: 16935, 6: 17805, 7: 17989, 8: 18676, 9: 18716}, 6: {0: 9472, 1: 12148, 2: 17669, 3: 14460, 4: 17318, 5: 17115, 6: 17934, 7: 17802, 8: 18664, 9: 17820}, 7: {0: 752, 1: 676, 2: 4577, 3: 10334, 4: 7679, 5: 7891, 6: 6959, 7: 7005, 8: 6309, 9: 6296}, 8: {0: 24269, 1: 24959, 2: 24373, 3: 23260, 4: 19009, 5: 14409, 6: 6643, 7: 6241, 8: 4545, 9: 3377}, 9: {0: 1988, 1: 54, 2: 807, 3: 2240, 4: 6313, 5: 10844, 6: 18390, 7: 18754, 8: 20467, 9: 21642}}
Averaged stats: Lr: 0.001875  Loss: -0.0555  Acc@1: 93.7500 (92.9400)  Acc@5: 100.0000 (99.2600)
Test: [Task 1]  [ 0/63]  eta: 0:00:27  Loss: 1.0138 (1.0138)  Acc@1: 75.0000 (75.0000)  Acc@5: 93.7500 (93.7500)  time: 0.4384  data: 0.2336  max mem: 2356
Test: [Task 1]  [10/63]  eta: 0:00:12  Loss: 0.7496 (0.7203)  Acc@1: 87.5000 (81.8182)  Acc@5: 100.0000 (97.1591)  time: 0.2298  data: 0.0220  max mem: 2356
Test: [Task 1]  [20/63]  eta: 0:00:09  Loss: 0.7496 (0.7562)  Acc@1: 81.2500 (80.9524)  Acc@5: 93.7500 (96.4286)  time: 0.2133  data: 0.0015  max mem: 2356
Test: [Task 1]  [30/63]  eta: 0:00:07  Loss: 0.6580 (0.7242)  Acc@1: 81.2500 (82.8629)  Acc@5: 100.0000 (97.1774)  time: 0.2120  data: 0.0013  max mem: 2356
Test: [Task 1]  [40/63]  eta: 0:00:04  Loss: 0.5830 (0.7082)  Acc@1: 87.5000 (83.2317)  Acc@5: 100.0000 (97.5610)  time: 0.2080  data: 0.0015  max mem: 2356
Test: [Task 1]  [50/63]  eta: 0:00:02  Loss: 0.5868 (0.6860)  Acc@1: 81.2500 (83.9461)  Acc@5: 100.0000 (97.7941)  time: 0.2108  data: 0.0020  max mem: 2356
Test: [Task 1]  [60/63]  eta: 0:00:00  Loss: 0.5848 (0.6694)  Acc@1: 87.5000 (84.1189)  Acc@5: 100.0000 (97.8484)  time: 0.2096  data: 0.0015  max mem: 2356
Test: [Task 1]  [62/63]  eta: 0:00:00  Loss: 0.5724 (0.6675)  Acc@1: 87.5000 (84.3000)  Acc@5: 100.0000 (97.9000)  time: 0.2045  data: 0.0015  max mem: 2356
Test: [Task 1] Total time: 0:00:13 (0.2148 s / it)
* Acc@1 84.300 Acc@5 97.900 loss 0.667
Test: [Task 2]  [ 0/63]  eta: 0:00:34  Loss: 1.0058 (1.0058)  Acc@1: 75.0000 (75.0000)  Acc@5: 93.7500 (93.7500)  time: 0.5409  data: 0.3358  max mem: 2356
Test: [Task 2]  [10/63]  eta: 0:00:12  Loss: 0.7873 (0.8619)  Acc@1: 81.2500 (78.9773)  Acc@5: 93.7500 (95.4545)  time: 0.2412  data: 0.0317  max mem: 2356
Test: [Task 2]  [20/63]  eta: 0:00:09  Loss: 0.8466 (0.9125)  Acc@1: 81.2500 (76.4881)  Acc@5: 93.7500 (94.9405)  time: 0.2084  data: 0.0009  max mem: 2356
Test: [Task 2]  [30/63]  eta: 0:00:07  Loss: 0.8663 (0.9069)  Acc@1: 81.2500 (77.4194)  Acc@5: 93.7500 (94.9597)  time: 0.2088  data: 0.0019  max mem: 2356
Test: [Task 2]  [40/63]  eta: 0:00:04  Loss: 0.7419 (0.8769)  Acc@1: 81.2500 (77.7439)  Acc@5: 100.0000 (95.7317)  time: 0.2096  data: 0.0017  max mem: 2356
Test: [Task 2]  [50/63]  eta: 0:00:02  Loss: 0.7419 (0.8749)  Acc@1: 75.0000 (76.8382)  Acc@5: 100.0000 (95.9559)  time: 0.2084  data: 0.0004  max mem: 2356
Test: [Task 2]  [60/63]  eta: 0:00:00  Loss: 0.7682 (0.8533)  Acc@1: 81.2500 (77.8689)  Acc@5: 100.0000 (96.2090)  time: 0.2081  data: 0.0006  max mem: 2356
Test: [Task 2]  [62/63]  eta: 0:00:00  Loss: 0.7361 (0.8464)  Acc@1: 81.2500 (78.0000)  Acc@5: 100.0000 (96.3000)  time: 0.2027  data: 0.0006  max mem: 2356
Test: [Task 2] Total time: 0:00:13 (0.2135 s / it)
* Acc@1 78.000 Acc@5 96.300 loss 0.846
Test: [Task 3]  [ 0/63]  eta: 0:00:41  Loss: 0.4874 (0.4874)  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (100.0000)  time: 0.6526  data: 0.4463  max mem: 2356
Test: [Task 3]  [10/63]  eta: 0:00:13  Loss: 0.6431 (0.6939)  Acc@1: 81.2500 (84.0909)  Acc@5: 93.7500 (93.7500)  time: 0.2496  data: 0.0413  max mem: 2356
Test: [Task 3]  [20/63]  eta: 0:00:09  Loss: 0.6725 (0.7119)  Acc@1: 81.2500 (81.5476)  Acc@5: 93.7500 (94.6429)  time: 0.2079  data: 0.0006  max mem: 2356
Test: [Task 3]  [30/63]  eta: 0:00:07  Loss: 0.7194 (0.6967)  Acc@1: 75.0000 (81.4516)  Acc@5: 100.0000 (95.7661)  time: 0.2117  data: 0.0013  max mem: 2356
Test: [Task 3]  [40/63]  eta: 0:00:05  Loss: 0.7194 (0.7161)  Acc@1: 81.2500 (80.6402)  Acc@5: 100.0000 (96.0366)  time: 0.2112  data: 0.0012  max mem: 2356
Test: [Task 3]  [50/63]  eta: 0:00:02  Loss: 0.8340 (0.7310)  Acc@1: 81.2500 (81.2500)  Acc@5: 93.7500 (95.5882)  time: 0.2073  data: 0.0005  max mem: 2356
Test: [Task 3]  [60/63]  eta: 0:00:00  Loss: 0.8032 (0.7417)  Acc@1: 81.2500 (80.9426)  Acc@5: 93.7500 (95.7992)  time: 0.2084  data: 0.0007  max mem: 2356
Test: [Task 3]  [62/63]  eta: 0:00:00  Loss: 0.8032 (0.7409)  Acc@1: 81.2500 (80.7000)  Acc@5: 93.7500 (95.8000)  time: 0.2035  data: 0.0007  max mem: 2356
Test: [Task 3] Total time: 0:00:13 (0.2165 s / it)
* Acc@1 80.700 Acc@5 95.800 loss 0.741
Test: [Task 4]  [ 0/63]  eta: 0:00:37  Loss: 0.9026 (0.9026)  Acc@1: 75.0000 (75.0000)  Acc@5: 93.7500 (93.7500)  time: 0.5903  data: 0.3833  max mem: 2356
Test: [Task 4]  [10/63]  eta: 0:00:13  Loss: 0.7766 (0.7122)  Acc@1: 81.2500 (83.5227)  Acc@5: 93.7500 (96.0227)  time: 0.2496  data: 0.0359  max mem: 2356
Test: [Task 4]  [20/63]  eta: 0:00:09  Loss: 0.6513 (0.7105)  Acc@1: 81.2500 (80.9524)  Acc@5: 93.7500 (95.5357)  time: 0.2117  data: 0.0012  max mem: 2356
Test: [Task 4]  [30/63]  eta: 0:00:07  Loss: 0.6252 (0.6896)  Acc@1: 81.2500 (81.8548)  Acc@5: 100.0000 (96.1694)  time: 0.2117  data: 0.0023  max mem: 2356
Test: [Task 4]  [40/63]  eta: 0:00:05  Loss: 0.3995 (0.6261)  Acc@1: 87.5000 (83.2317)  Acc@5: 100.0000 (96.9512)  time: 0.2117  data: 0.0028  max mem: 2356
Test: [Task 4]  [50/63]  eta: 0:00:02  Loss: 0.4764 (0.6535)  Acc@1: 81.2500 (82.1078)  Acc@5: 100.0000 (96.8137)  time: 0.2067  data: 0.0012  max mem: 2356
Test: [Task 4]  [60/63]  eta: 0:00:00  Loss: 0.6321 (0.6609)  Acc@1: 81.2500 (82.5820)  Acc@5: 100.0000 (96.5164)  time: 0.2053  data: 0.0003  max mem: 2356
Test: [Task 4]  [62/63]  eta: 0:00:00  Loss: 0.5897 (0.6588)  Acc@1: 81.2500 (82.6000)  Acc@5: 100.0000 (96.6000)  time: 0.2004  data: 0.0003  max mem: 2356
Test: [Task 4] Total time: 0:00:13 (0.2156 s / it)
* Acc@1 82.600 Acc@5 96.600 loss 0.659
Test: [Task 5]  [ 0/63]  eta: 0:00:32  Loss: 0.2234 (0.2234)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)  time: 0.5218  data: 0.3125  max mem: 2356
Test: [Task 5]  [10/63]  eta: 0:00:12  Loss: 0.5073 (0.5930)  Acc@1: 81.2500 (85.7955)  Acc@5: 100.0000 (97.1591)  time: 0.2345  data: 0.0293  max mem: 2356
Test: [Task 5]  [20/63]  eta: 0:00:09  Loss: 0.5073 (0.5492)  Acc@1: 87.5000 (88.3929)  Acc@5: 100.0000 (97.9167)  time: 0.2053  data: 0.0007  max mem: 2356
Test: [Task 5]  [30/63]  eta: 0:00:07  Loss: 0.5527 (0.5712)  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (97.9839)  time: 0.2051  data: 0.0004  max mem: 2356
Test: [Task 5]  [40/63]  eta: 0:00:04  Loss: 0.5470 (0.5556)  Acc@1: 87.5000 (88.7195)  Acc@5: 100.0000 (97.8659)  time: 0.2054  data: 0.0004  max mem: 2356
Test: [Task 5]  [50/63]  eta: 0:00:02  Loss: 0.5434 (0.5638)  Acc@1: 87.5000 (88.1127)  Acc@5: 100.0000 (98.0392)  time: 0.2064  data: 0.0006  max mem: 2356
Test: [Task 5]  [60/63]  eta: 0:00:00  Loss: 0.5434 (0.5730)  Acc@1: 87.5000 (88.0123)  Acc@5: 100.0000 (97.8484)  time: 0.2062  data: 0.0005  max mem: 2356
Test: [Task 5]  [62/63]  eta: 0:00:00  Loss: 0.5914 (0.5893)  Acc@1: 87.5000 (87.8000)  Acc@5: 100.0000 (97.5000)  time: 0.2006  data: 0.0005  max mem: 2356
Test: [Task 5] Total time: 0:00:13 (0.2102 s / it)
* Acc@1 87.800 Acc@5 97.500 loss 0.589
Test: [Task 6]  [ 0/63]  eta: 0:00:36  Loss: 0.5336 (0.5336)  Acc@1: 81.2500 (81.2500)  Acc@5: 100.0000 (100.0000)  time: 0.5792  data: 0.3718  max mem: 2356
Test: [Task 6]  [10/63]  eta: 0:00:12  Loss: 0.7428 (0.7049)  Acc@1: 81.2500 (78.9773)  Acc@5: 100.0000 (96.5909)  time: 0.2398  data: 0.0341  max mem: 2356
Test: [Task 6]  [20/63]  eta: 0:00:09  Loss: 0.7428 (0.7648)  Acc@1: 81.2500 (77.6786)  Acc@5: 100.0000 (96.7262)  time: 0.2076  data: 0.0013  max mem: 2356
Test: [Task 6]  [30/63]  eta: 0:00:07  Loss: 0.7171 (0.7575)  Acc@1: 81.2500 (78.4274)  Acc@5: 100.0000 (97.3790)  time: 0.2073  data: 0.0013  max mem: 2356
Test: [Task 6]  [40/63]  eta: 0:00:04  Loss: 0.7854 (0.7957)  Acc@1: 75.0000 (76.5244)  Acc@5: 100.0000 (97.5610)  time: 0.2063  data: 0.0004  max mem: 2356
Test: [Task 6]  [50/63]  eta: 0:00:02  Loss: 0.7639 (0.7730)  Acc@1: 75.0000 (76.9608)  Acc@5: 100.0000 (97.7941)  time: 0.2066  data: 0.0004  max mem: 2356
Test: [Task 6]  [60/63]  eta: 0:00:00  Loss: 0.7295 (0.7876)  Acc@1: 81.2500 (77.1516)  Acc@5: 100.0000 (97.4385)  time: 0.2056  data: 0.0005  max mem: 2356
Test: [Task 6]  [62/63]  eta: 0:00:00  Loss: 0.6964 (0.7814)  Acc@1: 81.2500 (77.4000)  Acc@5: 100.0000 (97.5000)  time: 0.2008  data: 0.0004  max mem: 2356
Test: [Task 6] Total time: 0:00:13 (0.2121 s / it)
* Acc@1 77.400 Acc@5 97.500 loss 0.781
Test: [Task 7]  [ 0/63]  eta: 0:00:48  Loss: 1.0351 (1.0351)  Acc@1: 68.7500 (68.7500)  Acc@5: 100.0000 (100.0000)  time: 0.7716  data: 0.5588  max mem: 2356
Test: [Task 7]  [10/63]  eta: 0:00:13  Loss: 0.5552 (0.6835)  Acc@1: 81.2500 (81.8182)  Acc@5: 100.0000 (98.2955)  time: 0.2582  data: 0.0513  max mem: 2356
Test: [Task 7]  [20/63]  eta: 0:00:09  Loss: 0.5835 (0.7450)  Acc@1: 81.2500 (80.9524)  Acc@5: 100.0000 (96.1310)  time: 0.2056  data: 0.0004  max mem: 2356
Test: [Task 7]  [30/63]  eta: 0:00:07  Loss: 0.6055 (0.7086)  Acc@1: 87.5000 (82.0565)  Acc@5: 100.0000 (96.5726)  time: 0.2050  data: 0.0009  max mem: 2356
Test: [Task 7]  [40/63]  eta: 0:00:05  Loss: 0.5792 (0.6947)  Acc@1: 87.5000 (83.0793)  Acc@5: 100.0000 (96.1890)  time: 0.2054  data: 0.0013  max mem: 2356
Test: [Task 7]  [50/63]  eta: 0:00:02  Loss: 0.6838 (0.7127)  Acc@1: 81.2500 (82.3529)  Acc@5: 93.7500 (95.9559)  time: 0.2056  data: 0.0013  max mem: 2356
Test: [Task 7]  [60/63]  eta: 0:00:00  Loss: 0.7396 (0.7027)  Acc@1: 81.2500 (82.5820)  Acc@5: 93.7500 (96.0041)  time: 0.2053  data: 0.0011  max mem: 2356
Test: [Task 7]  [62/63]  eta: 0:00:00  Loss: 0.7853 (0.7061)  Acc@1: 81.2500 (82.4000)  Acc@5: 100.0000 (96.1000)  time: 0.2004  data: 0.0011  max mem: 2356
Test: [Task 7] Total time: 0:00:13 (0.2138 s / it)
* Acc@1 82.400 Acc@5 96.100 loss 0.706
Test: [Task 8]  [ 0/63]  eta: 0:00:29  Loss: 0.5869 (0.5869)  Acc@1: 93.7500 (93.7500)  Acc@5: 100.0000 (100.0000)  time: 0.4606  data: 0.2457  max mem: 2356
Test: [Task 8]  [10/63]  eta: 0:00:12  Loss: 0.6863 (0.7342)  Acc@1: 81.2500 (78.9773)  Acc@5: 100.0000 (96.0227)  time: 0.2325  data: 0.0247  max mem: 2356
Test: [Task 8]  [20/63]  eta: 0:00:09  Loss: 0.6870 (0.7503)  Acc@1: 81.2500 (81.2500)  Acc@5: 93.7500 (95.8333)  time: 0.2080  data: 0.0016  max mem: 2356
Test: [Task 8]  [30/63]  eta: 0:00:07  Loss: 0.6687 (0.7241)  Acc@1: 87.5000 (82.0565)  Acc@5: 100.0000 (96.5726)  time: 0.2052  data: 0.0004  max mem: 2356
Test: [Task 8]  [40/63]  eta: 0:00:04  Loss: 0.6668 (0.7165)  Acc@1: 87.5000 (82.1646)  Acc@5: 100.0000 (96.4939)  time: 0.2052  data: 0.0006  max mem: 2356
Test: [Task 8]  [50/63]  eta: 0:00:02  Loss: 0.6632 (0.7047)  Acc@1: 75.0000 (81.7402)  Acc@5: 93.7500 (96.5686)  time: 0.2052  data: 0.0005  max mem: 2356
Test: [Task 8]  [60/63]  eta: 0:00:00  Loss: 0.7524 (0.7299)  Acc@1: 81.2500 (81.3525)  Acc@5: 93.7500 (95.6967)  time: 0.2041  data: 0.0002  max mem: 2356
Test: [Task 8]  [62/63]  eta: 0:00:00  Loss: 0.6632 (0.7186)  Acc@1: 81.2500 (81.6000)  Acc@5: 93.7500 (95.8000)  time: 0.1995  data: 0.0002  max mem: 2356
Test: [Task 8] Total time: 0:00:13 (0.2106 s / it)
* Acc@1 81.600 Acc@5 95.800 loss 0.719
Test: [Task 9]  [ 0/63]  eta: 0:00:34  Loss: 0.1656 (0.1656)  Acc@1: 93.7500 (93.7500)  Acc@5: 100.0000 (100.0000)  time: 0.5451  data: 0.3296  max mem: 2356
Test: [Task 9]  [10/63]  eta: 0:00:12  Loss: 0.4702 (0.5137)  Acc@1: 87.5000 (86.3636)  Acc@5: 100.0000 (98.2955)  time: 0.2386  data: 0.0319  max mem: 2356
Test: [Task 9]  [20/63]  eta: 0:00:09  Loss: 0.4737 (0.5356)  Acc@1: 87.5000 (85.7143)  Acc@5: 100.0000 (98.2143)  time: 0.2103  data: 0.0025  max mem: 2356
Test: [Task 9]  [30/63]  eta: 0:00:07  Loss: 0.4304 (0.5067)  Acc@1: 87.5000 (86.0887)  Acc@5: 100.0000 (98.3871)  time: 0.2109  data: 0.0023  max mem: 2356
Test: [Task 9]  [40/63]  eta: 0:00:05  Loss: 0.4105 (0.5122)  Acc@1: 87.5000 (85.3659)  Acc@5: 100.0000 (98.4756)  time: 0.2095  data: 0.0014  max mem: 2356
Test: [Task 9]  [50/63]  eta: 0:00:02  Loss: 0.4422 (0.5178)  Acc@1: 87.5000 (85.5392)  Acc@5: 100.0000 (98.5294)  time: 0.2122  data: 0.0030  max mem: 2356
Test: [Task 9]  [60/63]  eta: 0:00:00  Loss: 0.4359 (0.4993)  Acc@1: 87.5000 (86.2705)  Acc@5: 100.0000 (98.3607)  time: 0.2106  data: 0.0025  max mem: 2356
Test: [Task 9]  [62/63]  eta: 0:00:00  Loss: 0.3852 (0.4902)  Acc@1: 87.5000 (86.5000)  Acc@5: 100.0000 (98.4000)  time: 0.2043  data: 0.0025  max mem: 2356
Test: [Task 9] Total time: 0:00:13 (0.2151 s / it)
* Acc@1 86.500 Acc@5 98.400 loss 0.490
Test: [Task 10]  [ 0/63]  eta: 0:00:45  Loss: 0.4988 (0.4988)  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (100.0000)  time: 0.7275  data: 0.5190  max mem: 2356
Test: [Task 10]  [10/63]  eta: 0:00:13  Loss: 0.4654 (0.4886)  Acc@1: 93.7500 (91.4773)  Acc@5: 100.0000 (98.2955)  time: 0.2558  data: 0.0486  max mem: 2356
Test: [Task 10]  [20/63]  eta: 0:00:09  Loss: 0.5045 (0.5329)  Acc@1: 87.5000 (88.0952)  Acc@5: 100.0000 (99.1071)  time: 0.2073  data: 0.0017  max mem: 2356
Test: [Task 10]  [30/63]  eta: 0:00:07  Loss: 0.5980 (0.5464)  Acc@1: 81.2500 (86.6935)  Acc@5: 100.0000 (98.9919)  time: 0.2095  data: 0.0024  max mem: 2356
Test: [Task 10]  [40/63]  eta: 0:00:05  Loss: 0.5412 (0.5357)  Acc@1: 87.5000 (87.1951)  Acc@5: 100.0000 (99.0854)  time: 0.2106  data: 0.0020  max mem: 2356
Test: [Task 10]  [50/63]  eta: 0:00:02  Loss: 0.4872 (0.5351)  Acc@1: 87.5000 (87.0098)  Acc@5: 100.0000 (99.1422)  time: 0.2077  data: 0.0014  max mem: 2356
Test: [Task 10]  [60/63]  eta: 0:00:00  Loss: 0.5294 (0.5370)  Acc@1: 87.5000 (86.7828)  Acc@5: 100.0000 (98.8730)  time: 0.2083  data: 0.0018  max mem: 2356
Test: [Task 10]  [62/63]  eta: 0:00:00  Loss: 0.5093 (0.5323)  Acc@1: 87.5000 (87.0000)  Acc@5: 100.0000 (98.9000)  time: 0.2035  data: 0.0018  max mem: 2356
Test: [Task 10] Total time: 0:00:13 (0.2167 s / it)
* Acc@1 87.000 Acc@5 98.900 loss 0.532
{0: {0: 370, 1: 624, 2: 347, 3: 652, 4: 372, 5: 679, 6: 632, 7: 321, 8: 225, 9: 778}, 1: {0: 543, 1: 457, 2: 545, 3: 458, 4: 539, 5: 459, 6: 456, 7: 543, 8: 530, 9: 470}, 2: {0: 343, 1: 651, 2: 331, 3: 669, 4: 349, 5: 679, 6: 657, 7: 321, 8: 216, 9: 784}, 3: {0: 598, 1: 406, 2: 610, 3: 390, 4: 593, 5: 396, 6: 402, 7: 605, 8: 420, 9: 580}, 4: {0: 573, 1: 423, 2: 581, 3: 419, 4: 575, 5: 427, 6: 427, 7: 574, 8: 447, 9: 554}, 5: {0: 544, 1: 451, 2: 550, 3: 452, 4: 545, 5: 454, 6: 457, 7: 546, 8: 470, 9: 531}, 6: {0: 567, 1: 429, 2: 568, 3: 431, 4: 570, 5: 445, 6: 433, 7: 557, 8: 365, 9: 635}, 7: {0: 551, 1: 443, 2: 543, 3: 456, 4: 556, 5: 463, 6: 447, 7: 541, 8: 284, 9: 716}, 8: {0: 465, 1: 536, 2: 471, 3: 529, 4: 462, 5: 529, 6: 535, 7: 471, 8: 405, 9: 597}, 9: {0: 532, 1: 465, 2: 506, 3: 493, 4: 535, 5: 531, 6: 468, 7: 470, 8: 236, 9: 764}}
[Average accuracy till task10]	Acc@1: 82.8300	Acc@5: 97.0800	Loss: 0.6731	Forgetting: 7.2111	Backward: -7.2111
Total training time: 1:40:56
