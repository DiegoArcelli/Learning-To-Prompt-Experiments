/storagenfs/d.arcelli/Prompting-Based-CL-Methods-Experiments/.env/lib/python3.9/site-packages/torchvision/transforms/transforms.py:329: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.
  warnings.warn(
/storagenfs/d.arcelli/l2p-pytorch/continual_datasets/dataset_utils.py:335: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:199.)
  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)
Namespace(subparser_name='five_datasets_l2p', batch_size=16, epochs=5, model='vit_base_patch16_224', input_size=224, pretrained=True, drop=0.0, drop_path=0.0, opt='adam', opt_eps=1e-08, opt_betas=(0.9, 0.999), clip_grad=1.0, momentum=0.9, weight_decay=0.0, reinit_optimizer=True, sched='constant', lr=0.03, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, unscale_lr=True, color_jitter=None, aa=None, smoothing=0.1, train_interpolation='bicubic', reprob=0.0, remode='pixel', recount=1, data_path='./local_datasets/', dataset='5-datasets', shuffle=False, output_dir='./output_task_init_only', device='cuda', seed=42, eval=False, num_workers=4, pin_mem=True, world_size=1, dist_url='env://', num_tasks=5, train_mask=True, task_inc=False, prompt_pool=True, size=20, length=10, top_k=4, initializer='uniform', prompt_key=True, prompt_key_init='uniform', use_prompt_mask=False, shared_prompt_pool=False, shared_prompt_key=False, batchwise_prompt=True, embedding_key='cls', predefined_key='', pull_constraint=True, pull_constraint_coeff=0.5, global_pool='token', head_type='prompt', freeze=['blocks', 'patch_embed', 'cls_token', 'norm', 'pos_embed'], print_freq=10, freeze_head=False, train_type='l2p', eval_task_id=False, frequency_penalization=False, class_incremental=False, init_class_prompts=False, task_incremental=False, init_tasks_prompts=True, prompts_per_task=4, prompts_per_class=1, freeze_keys=False)
Not using distributed mode
['SVHN', 'MNIST', 'CIFAR10', 'NotMNIST', 'FashionMNIST']
Using downloaded and verified file: ./local_datasets/train_32x32.mat
Using downloaded and verified file: ./local_datasets/train_32x32.mat
Using downloaded and verified file: ./local_datasets/test_32x32.mat
Using downloaded and verified file: ./local_datasets/test_32x32.mat
[1 9 2 3 2 5 9 3 3 1]
tensor([5, 0, 4, 1, 9, 2, 1, 3, 1, 4])
Files already downloaded and verified
Files already downloaded and verified
[6, 9, 9, 4, 1, 1, 2, 7, 8, 3]
File F/Q3Jvc3NvdmVyIEJvbGRPYmxpcXVlLnR0Zg==.png is broken
File A/RGVtb2NyYXRpY2FCb2xkT2xkc3R5bGUgQm9sZC50dGY=.png is broken
[5, 5, 5, 5, 5, 5, 5, 5, 5, 5]
tensor([9, 0, 0, 3, 0, 2, 7, 2, 5, 5])
Creating original model: vit_base_patch16_224
Creating model: vit_base_patch16_224
number of params: 207410
Start training for 5 epochs
Train: Epoch[1/5]  [   0/4579]  eta: 2:15:14  Lr: 0.001875  Loss: 0.9925  Acc@1: 12.5000 (12.5000)  Acc@5: 68.7500 (68.7500)  time: 1.7721  data: 0.4444  max mem: 2497
Train: Epoch[1/5]  [  10/4579]  eta: 0:35:54  Lr: 0.001875  Loss: 1.0045  Acc@1: 18.7500 (15.9091)  Acc@5: 50.0000 (57.3864)  time: 0.4715  data: 0.0406  max mem: 2500
Train: Epoch[1/5]  [  20/4579]  eta: 0:31:14  Lr: 0.001875  Loss: 1.3641  Acc@1: 12.5000 (14.8810)  Acc@5: 56.2500 (60.4167)  time: 0.3430  data: 0.0002  max mem: 2500
Train: Epoch[1/5]  [  30/4579]  eta: 0:29:41  Lr: 0.001875  Loss: 0.6091  Acc@1: 18.7500 (17.9435)  Acc@5: 62.5000 (61.0887)  time: 0.3476  data: 0.0011  max mem: 2500
Train: Epoch[1/5]  [  40/4579]  eta: 0:28:48  Lr: 0.001875  Loss: 0.7373  Acc@1: 25.0000 (19.2073)  Acc@5: 68.7500 (63.4146)  time: 0.3489  data: 0.0019  max mem: 2500
Train: Epoch[1/5]  [  50/4579]  eta: 0:28:12  Lr: 0.001875  Loss: 0.6680  Acc@1: 25.0000 (20.5882)  Acc@5: 68.7500 (63.6029)  time: 0.3459  data: 0.0012  max mem: 2500
Train: Epoch[1/5]  [  60/4579]  eta: 0:27:57  Lr: 0.001875  Loss: 0.9832  Acc@1: 25.0000 (21.9262)  Acc@5: 68.7500 (64.7541)  time: 0.3520  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [  70/4579]  eta: 0:27:42  Lr: 0.001875  Loss: 0.8714  Acc@1: 25.0000 (22.5352)  Acc@5: 75.0000 (65.8451)  time: 0.3562  data: 0.0022  max mem: 2500
Train: Epoch[1/5]  [  80/4579]  eta: 0:27:28  Lr: 0.001875  Loss: 0.6316  Acc@1: 31.2500 (24.1512)  Acc@5: 75.0000 (67.2068)  time: 0.3516  data: 0.0021  max mem: 2500
Train: Epoch[1/5]  [  90/4579]  eta: 0:27:15  Lr: 0.001875  Loss: 0.7356  Acc@1: 31.2500 (24.7253)  Acc@5: 75.0000 (68.1319)  time: 0.3484  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [ 100/4579]  eta: 0:27:06  Lr: 0.001875  Loss: 0.7814  Acc@1: 31.2500 (25.4332)  Acc@5: 75.0000 (68.5025)  time: 0.3500  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [ 110/4579]  eta: 0:26:56  Lr: 0.001875  Loss: 0.5710  Acc@1: 31.2500 (26.3514)  Acc@5: 75.0000 (69.1441)  time: 0.3497  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [ 120/4579]  eta: 0:26:46  Lr: 0.001875  Loss: 0.6651  Acc@1: 31.2500 (26.5496)  Acc@5: 75.0000 (69.5764)  time: 0.3461  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 130/4579]  eta: 0:26:39  Lr: 0.001875  Loss: 0.5410  Acc@1: 31.2500 (26.7176)  Acc@5: 75.0000 (69.9427)  time: 0.3476  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 140/4579]  eta: 0:26:31  Lr: 0.001875  Loss: 0.8369  Acc@1: 31.2500 (26.9947)  Acc@5: 75.0000 (70.4344)  time: 0.3477  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [ 150/4579]  eta: 0:26:24  Lr: 0.001875  Loss: 0.3324  Acc@1: 31.2500 (27.2351)  Acc@5: 75.0000 (71.1507)  time: 0.3463  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 160/4579]  eta: 0:26:18  Lr: 0.001875  Loss: 0.6214  Acc@1: 37.5000 (27.7562)  Acc@5: 81.2500 (71.6615)  time: 0.3474  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 170/4579]  eta: 0:26:11  Lr: 0.001875  Loss: 0.8627  Acc@1: 37.5000 (28.1067)  Acc@5: 81.2500 (72.1857)  time: 0.3467  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [ 180/4579]  eta: 0:26:05  Lr: 0.001875  Loss: 0.6204  Acc@1: 37.5000 (28.5912)  Acc@5: 81.2500 (72.6519)  time: 0.3445  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [ 190/4579]  eta: 0:25:58  Lr: 0.001875  Loss: 0.5705  Acc@1: 37.5000 (29.2539)  Acc@5: 81.2500 (73.3312)  time: 0.3444  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [ 200/4579]  eta: 0:25:53  Lr: 0.001875  Loss: 0.7916  Acc@1: 37.5000 (29.5709)  Acc@5: 81.2500 (73.3520)  time: 0.3446  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [ 210/4579]  eta: 0:25:48  Lr: 0.001875  Loss: 0.6601  Acc@1: 37.5000 (29.7986)  Acc@5: 75.0000 (73.4301)  time: 0.3471  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 220/4579]  eta: 0:25:45  Lr: 0.001875  Loss: 0.5687  Acc@1: 37.5000 (30.0057)  Acc@5: 81.2500 (73.7557)  time: 0.3546  data: 0.0009  max mem: 2500
Train: Epoch[1/5]  [ 230/4579]  eta: 0:25:42  Lr: 0.001875  Loss: 0.4809  Acc@1: 31.2500 (30.1948)  Acc@5: 81.2500 (74.1342)  time: 0.3586  data: 0.0016  max mem: 2500
Train: Epoch[1/5]  [ 240/4579]  eta: 0:25:42  Lr: 0.001875  Loss: 0.9214  Acc@1: 31.2500 (30.2127)  Acc@5: 75.0000 (74.0923)  time: 0.3636  data: 0.0039  max mem: 2500
Train: Epoch[1/5]  [ 250/4579]  eta: 0:25:39  Lr: 0.001875  Loss: 0.6364  Acc@1: 37.5000 (30.4034)  Acc@5: 75.0000 (74.3526)  time: 0.3650  data: 0.0040  max mem: 2500
Train: Epoch[1/5]  [ 260/4579]  eta: 0:25:35  Lr: 0.001875  Loss: 0.7305  Acc@1: 37.5000 (30.4837)  Acc@5: 81.2500 (74.6887)  time: 0.3563  data: 0.0021  max mem: 2500
Train: Epoch[1/5]  [ 270/4579]  eta: 0:25:30  Lr: 0.001875  Loss: 0.4642  Acc@1: 31.2500 (30.5581)  Acc@5: 81.2500 (74.7232)  time: 0.3512  data: 0.0014  max mem: 2500
Train: Epoch[1/5]  [ 280/4579]  eta: 0:25:26  Lr: 0.001875  Loss: 0.5570  Acc@1: 37.5000 (30.9386)  Acc@5: 75.0000 (74.7553)  time: 0.3497  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [ 290/4579]  eta: 0:25:23  Lr: 0.001875  Loss: 0.5910  Acc@1: 37.5000 (31.2930)  Acc@5: 81.2500 (75.0215)  time: 0.3531  data: 0.0015  max mem: 2500
Train: Epoch[1/5]  [ 300/4579]  eta: 0:25:18  Lr: 0.001875  Loss: 0.5028  Acc@1: 31.2500 (31.3953)  Acc@5: 87.5000 (75.3530)  time: 0.3521  data: 0.0014  max mem: 2500
Train: Epoch[1/5]  [ 310/4579]  eta: 0:25:14  Lr: 0.001875  Loss: 0.6322  Acc@1: 37.5000 (31.7323)  Acc@5: 87.5000 (75.6029)  time: 0.3485  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [ 320/4579]  eta: 0:25:09  Lr: 0.001875  Loss: 0.3970  Acc@1: 37.5000 (31.8925)  Acc@5: 87.5000 (75.9540)  time: 0.3486  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [ 330/4579]  eta: 0:25:05  Lr: 0.001875  Loss: 0.1911  Acc@1: 37.5000 (32.1375)  Acc@5: 81.2500 (76.1140)  time: 0.3477  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [ 340/4579]  eta: 0:25:00  Lr: 0.001875  Loss: 0.4648  Acc@1: 37.5000 (32.3680)  Acc@5: 87.5000 (76.4479)  time: 0.3474  data: 0.0014  max mem: 2500
Train: Epoch[1/5]  [ 350/4579]  eta: 0:24:56  Lr: 0.001875  Loss: 0.0002  Acc@1: 37.5000 (32.4964)  Acc@5: 87.5000 (76.6204)  time: 0.3452  data: 0.0010  max mem: 2500
Train: Epoch[1/5]  [ 360/4579]  eta: 0:24:51  Lr: 0.001875  Loss: 0.8327  Acc@1: 37.5000 (32.6697)  Acc@5: 81.2500 (76.8179)  time: 0.3445  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [ 370/4579]  eta: 0:24:47  Lr: 0.001875  Loss: 0.6638  Acc@1: 37.5000 (32.8673)  Acc@5: 81.2500 (76.9542)  time: 0.3474  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [ 380/4579]  eta: 0:24:43  Lr: 0.001875  Loss: 0.7233  Acc@1: 37.5000 (33.0709)  Acc@5: 81.2500 (77.0669)  time: 0.3468  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [ 390/4579]  eta: 0:24:38  Lr: 0.001875  Loss: 0.0340  Acc@1: 37.5000 (33.3600)  Acc@5: 81.2500 (77.1899)  time: 0.3447  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [ 400/4579]  eta: 0:24:35  Lr: 0.001875  Loss: 0.0611  Acc@1: 43.7500 (33.6814)  Acc@5: 81.2500 (77.3379)  time: 0.3516  data: 0.0011  max mem: 2500
Train: Epoch[1/5]  [ 410/4579]  eta: 0:24:32  Lr: 0.001875  Loss: 0.2443  Acc@1: 43.7500 (33.8200)  Acc@5: 87.5000 (77.5547)  time: 0.3577  data: 0.0016  max mem: 2500
Train: Epoch[1/5]  [ 420/4579]  eta: 0:24:28  Lr: 0.001875  Loss: 0.4984  Acc@1: 37.5000 (33.9816)  Acc@5: 81.2500 (77.5980)  time: 0.3550  data: 0.0010  max mem: 2500
Train: Epoch[1/5]  [ 430/4579]  eta: 0:24:26  Lr: 0.001875  Loss: 0.4503  Acc@1: 43.7500 (34.2662)  Acc@5: 81.2500 (77.8132)  time: 0.3571  data: 0.0019  max mem: 2500
Train: Epoch[1/5]  [ 440/4579]  eta: 0:24:22  Lr: 0.001875  Loss: -0.1543  Acc@1: 43.7500 (34.5947)  Acc@5: 87.5000 (78.0754)  time: 0.3581  data: 0.0029  max mem: 2500
Train: Epoch[1/5]  [ 450/4579]  eta: 0:24:19  Lr: 0.001875  Loss: 0.1850  Acc@1: 43.7500 (34.9224)  Acc@5: 87.5000 (78.3398)  time: 0.3554  data: 0.0017  max mem: 2500
Train: Epoch[1/5]  [ 460/4579]  eta: 0:24:16  Lr: 0.001875  Loss: 0.2882  Acc@1: 50.0000 (35.1546)  Acc@5: 87.5000 (78.5385)  time: 0.3561  data: 0.0021  max mem: 2500
Train: Epoch[1/5]  [ 470/4579]  eta: 0:24:12  Lr: 0.001875  Loss: 0.4569  Acc@1: 43.7500 (35.2972)  Acc@5: 87.5000 (78.7155)  time: 0.3538  data: 0.0019  max mem: 2500
Train: Epoch[1/5]  [ 480/4579]  eta: 0:24:08  Lr: 0.001875  Loss: 0.4520  Acc@1: 43.7500 (35.4340)  Acc@5: 81.2500 (78.7942)  time: 0.3488  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [ 490/4579]  eta: 0:24:04  Lr: 0.001875  Loss: 0.5755  Acc@1: 43.7500 (35.6670)  Acc@5: 81.2500 (78.8315)  time: 0.3472  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 500/4579]  eta: 0:24:00  Lr: 0.001875  Loss: 0.4851  Acc@1: 43.7500 (35.7909)  Acc@5: 81.2500 (78.8922)  time: 0.3500  data: 0.0018  max mem: 2500
Train: Epoch[1/5]  [ 510/4579]  eta: 0:23:56  Lr: 0.001875  Loss: 0.4303  Acc@1: 50.0000 (36.1179)  Acc@5: 81.2500 (79.0117)  time: 0.3496  data: 0.0019  max mem: 2500
Train: Epoch[1/5]  [ 520/4579]  eta: 0:23:52  Lr: 0.001875  Loss: -0.2223  Acc@1: 50.0000 (36.3844)  Acc@5: 87.5000 (79.1867)  time: 0.3469  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 530/4579]  eta: 0:23:48  Lr: 0.001875  Loss: 0.2062  Acc@1: 43.7500 (36.4878)  Acc@5: 87.5000 (79.2491)  time: 0.3459  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [ 540/4579]  eta: 0:23:44  Lr: 0.001875  Loss: 0.3627  Acc@1: 43.7500 (36.6913)  Acc@5: 87.5000 (79.3785)  time: 0.3462  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [ 550/4579]  eta: 0:23:40  Lr: 0.001875  Loss: 0.5663  Acc@1: 43.7500 (36.8194)  Acc@5: 87.5000 (79.4011)  time: 0.3469  data: 0.0011  max mem: 2500
Train: Epoch[1/5]  [ 560/4579]  eta: 0:23:36  Lr: 0.001875  Loss: 0.4710  Acc@1: 37.5000 (36.9095)  Acc@5: 87.5000 (79.5566)  time: 0.3461  data: 0.0011  max mem: 2500
Train: Epoch[1/5]  [ 570/4579]  eta: 0:23:32  Lr: 0.001875  Loss: 0.3378  Acc@1: 50.0000 (37.1497)  Acc@5: 87.5000 (79.7067)  time: 0.3454  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [ 580/4579]  eta: 0:23:29  Lr: 0.001875  Loss: 0.3870  Acc@1: 50.0000 (37.2096)  Acc@5: 87.5000 (79.8731)  time: 0.3502  data: 0.0009  max mem: 2500
Train: Epoch[1/5]  [ 590/4579]  eta: 0:23:25  Lr: 0.001875  Loss: 0.4253  Acc@1: 37.5000 (37.3731)  Acc@5: 87.5000 (79.9704)  time: 0.3538  data: 0.0010  max mem: 2500
Train: Epoch[1/5]  [ 600/4579]  eta: 0:23:22  Lr: 0.001875  Loss: 0.1141  Acc@1: 50.0000 (37.6456)  Acc@5: 87.5000 (80.0853)  time: 0.3512  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [ 610/4579]  eta: 0:23:18  Lr: 0.001875  Loss: 0.0790  Acc@1: 50.0000 (37.7455)  Acc@5: 81.2500 (80.0941)  time: 0.3533  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [ 620/4579]  eta: 0:23:15  Lr: 0.001875  Loss: 0.5994  Acc@1: 43.7500 (37.8623)  Acc@5: 81.2500 (80.2134)  time: 0.3567  data: 0.0017  max mem: 2500
Train: Epoch[1/5]  [ 630/4579]  eta: 0:23:12  Lr: 0.001875  Loss: 0.5126  Acc@1: 37.5000 (37.9259)  Acc@5: 87.5000 (80.2100)  time: 0.3559  data: 0.0029  max mem: 2500
Train: Epoch[1/5]  [ 640/4579]  eta: 0:23:08  Lr: 0.001875  Loss: -0.2035  Acc@1: 37.5000 (38.0460)  Acc@5: 87.5000 (80.3725)  time: 0.3535  data: 0.0021  max mem: 2500
Train: Epoch[1/5]  [ 650/4579]  eta: 0:23:05  Lr: 0.001875  Loss: 0.4043  Acc@1: 43.7500 (38.1432)  Acc@5: 87.5000 (80.4531)  time: 0.3525  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [ 660/4579]  eta: 0:23:01  Lr: 0.001875  Loss: 0.6964  Acc@1: 43.7500 (38.2281)  Acc@5: 87.5000 (80.4841)  time: 0.3508  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [ 670/4579]  eta: 0:22:57  Lr: 0.001875  Loss: 0.5646  Acc@1: 43.7500 (38.2638)  Acc@5: 81.2500 (80.5607)  time: 0.3481  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 680/4579]  eta: 0:22:54  Lr: 0.001875  Loss: 0.4381  Acc@1: 50.0000 (38.4453)  Acc@5: 87.5000 (80.6810)  time: 0.3508  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [ 690/4579]  eta: 0:22:50  Lr: 0.001875  Loss: 0.2618  Acc@1: 50.0000 (38.5854)  Acc@5: 87.5000 (80.7706)  time: 0.3511  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [ 700/4579]  eta: 0:22:46  Lr: 0.001875  Loss: 0.3563  Acc@1: 50.0000 (38.6769)  Acc@5: 87.5000 (80.8755)  time: 0.3480  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 710/4579]  eta: 0:22:42  Lr: 0.001875  Loss: 0.2785  Acc@1: 43.7500 (38.6691)  Acc@5: 87.5000 (80.9072)  time: 0.3476  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [ 720/4579]  eta: 0:22:39  Lr: 0.001875  Loss: 0.4199  Acc@1: 43.7500 (38.8089)  Acc@5: 81.2500 (80.9639)  time: 0.3478  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 730/4579]  eta: 0:22:35  Lr: 0.001875  Loss: 0.2392  Acc@1: 50.0000 (38.9022)  Acc@5: 87.5000 (81.0363)  time: 0.3472  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 740/4579]  eta: 0:22:31  Lr: 0.001875  Loss: 0.2599  Acc@1: 50.0000 (39.1026)  Acc@5: 87.5000 (81.1066)  time: 0.3462  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [ 750/4579]  eta: 0:22:27  Lr: 0.001875  Loss: 0.4830  Acc@1: 50.0000 (39.1977)  Acc@5: 87.5000 (81.1751)  time: 0.3462  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [ 760/4579]  eta: 0:22:24  Lr: 0.001875  Loss: 0.0404  Acc@1: 50.0000 (39.3479)  Acc@5: 87.5000 (81.2911)  time: 0.3494  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [ 770/4579]  eta: 0:22:20  Lr: 0.001875  Loss: 0.4092  Acc@1: 43.7500 (39.4131)  Acc@5: 87.5000 (81.3473)  time: 0.3551  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [ 780/4579]  eta: 0:22:17  Lr: 0.001875  Loss: 0.7021  Acc@1: 43.7500 (39.5567)  Acc@5: 81.2500 (81.3540)  time: 0.3556  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [ 790/4579]  eta: 0:22:13  Lr: 0.001875  Loss: 0.0137  Acc@1: 50.0000 (39.6255)  Acc@5: 87.5000 (81.4238)  time: 0.3539  data: 0.0016  max mem: 2500
Train: Epoch[1/5]  [ 800/4579]  eta: 0:22:10  Lr: 0.001875  Loss: 0.5268  Acc@1: 50.0000 (39.7862)  Acc@5: 87.5000 (81.5153)  time: 0.3567  data: 0.0019  max mem: 2500
Train: Epoch[1/5]  [ 810/4579]  eta: 0:22:07  Lr: 0.001875  Loss: 0.1450  Acc@1: 50.0000 (39.8505)  Acc@5: 87.5000 (81.6199)  time: 0.3603  data: 0.0016  max mem: 2500
Train: Epoch[1/5]  [ 820/4579]  eta: 0:22:04  Lr: 0.001875  Loss: -0.0149  Acc@1: 50.0000 (40.0350)  Acc@5: 87.5000 (81.6839)  time: 0.3589  data: 0.0018  max mem: 2500
Train: Epoch[1/5]  [ 830/4579]  eta: 0:22:00  Lr: 0.001875  Loss: -0.1374  Acc@1: 56.2500 (40.1324)  Acc@5: 87.5000 (81.7840)  time: 0.3547  data: 0.0016  max mem: 2500
Train: Epoch[1/5]  [ 840/4579]  eta: 0:21:57  Lr: 0.001875  Loss: 0.7000  Acc@1: 56.2500 (40.2497)  Acc@5: 87.5000 (81.8445)  time: 0.3537  data: 0.0011  max mem: 2500
Train: Epoch[1/5]  [ 850/4579]  eta: 0:21:54  Lr: 0.001875  Loss: 0.3133  Acc@1: 50.0000 (40.3202)  Acc@5: 87.5000 (81.8816)  time: 0.3551  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [ 860/4579]  eta: 0:21:50  Lr: 0.001875  Loss: 0.2633  Acc@1: 50.0000 (40.4399)  Acc@5: 81.2500 (81.9178)  time: 0.3524  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [ 870/4579]  eta: 0:21:46  Lr: 0.001875  Loss: 0.0394  Acc@1: 50.0000 (40.4779)  Acc@5: 87.5000 (81.9891)  time: 0.3497  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [ 880/4579]  eta: 0:21:43  Lr: 0.001875  Loss: 0.6150  Acc@1: 43.7500 (40.5647)  Acc@5: 87.5000 (82.0375)  time: 0.3490  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [ 890/4579]  eta: 0:21:39  Lr: 0.001875  Loss: 0.4190  Acc@1: 50.0000 (40.6425)  Acc@5: 87.5000 (82.1268)  time: 0.3477  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 900/4579]  eta: 0:21:35  Lr: 0.001875  Loss: 0.2894  Acc@1: 50.0000 (40.7950)  Acc@5: 87.5000 (82.1379)  time: 0.3510  data: 0.0011  max mem: 2500
Train: Epoch[1/5]  [ 910/4579]  eta: 0:21:32  Lr: 0.001875  Loss: 0.2563  Acc@1: 50.0000 (40.8548)  Acc@5: 81.2500 (82.1830)  time: 0.3512  data: 0.0011  max mem: 2500
Train: Epoch[1/5]  [ 920/4579]  eta: 0:21:28  Lr: 0.001875  Loss: 0.6181  Acc@1: 43.7500 (40.8455)  Acc@5: 81.2500 (82.2068)  time: 0.3468  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [ 930/4579]  eta: 0:21:24  Lr: 0.001875  Loss: 0.5288  Acc@1: 37.5000 (40.8633)  Acc@5: 81.2500 (82.2771)  time: 0.3451  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [ 940/4579]  eta: 0:21:20  Lr: 0.001875  Loss: -0.1432  Acc@1: 43.7500 (40.9338)  Acc@5: 87.5000 (82.3459)  time: 0.3459  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [ 950/4579]  eta: 0:21:17  Lr: 0.001875  Loss: -0.0216  Acc@1: 43.7500 (40.9109)  Acc@5: 87.5000 (82.3672)  time: 0.3469  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [ 960/4579]  eta: 0:21:13  Lr: 0.001875  Loss: 0.0275  Acc@1: 43.7500 (40.9990)  Acc@5: 87.5000 (82.4272)  time: 0.3489  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 970/4579]  eta: 0:21:10  Lr: 0.001875  Loss: 0.0603  Acc@1: 50.0000 (41.0852)  Acc@5: 87.5000 (82.4601)  time: 0.3519  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [ 980/4579]  eta: 0:21:06  Lr: 0.001875  Loss: 0.2209  Acc@1: 50.0000 (41.1634)  Acc@5: 87.5000 (82.5115)  time: 0.3522  data: 0.0014  max mem: 2500
Train: Epoch[1/5]  [ 990/4579]  eta: 0:21:03  Lr: 0.001875  Loss: 0.6785  Acc@1: 50.0000 (41.2462)  Acc@5: 87.5000 (82.5492)  time: 0.3526  data: 0.0025  max mem: 2500
Train: Epoch[1/5]  [1000/4579]  eta: 0:20:59  Lr: 0.001875  Loss: -0.1481  Acc@1: 50.0000 (41.3711)  Acc@5: 87.5000 (82.5924)  time: 0.3542  data: 0.0019  max mem: 2500
Train: Epoch[1/5]  [1010/4579]  eta: 0:20:56  Lr: 0.001875  Loss: 0.0491  Acc@1: 50.0000 (41.4318)  Acc@5: 87.5000 (82.6286)  time: 0.3568  data: 0.0010  max mem: 2500
Train: Epoch[1/5]  [1020/4579]  eta: 0:20:52  Lr: 0.001875  Loss: 0.3868  Acc@1: 50.0000 (41.5891)  Acc@5: 87.5000 (82.6824)  time: 0.3542  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [1030/4579]  eta: 0:20:49  Lr: 0.001875  Loss: 0.7531  Acc@1: 56.2500 (41.6768)  Acc@5: 87.5000 (82.6988)  time: 0.3513  data: 0.0015  max mem: 2500
Train: Epoch[1/5]  [1040/4579]  eta: 0:20:46  Lr: 0.001875  Loss: 0.8132  Acc@1: 56.2500 (41.7927)  Acc@5: 87.5000 (82.7750)  time: 0.3562  data: 0.0024  max mem: 2500
Train: Epoch[1/5]  [1050/4579]  eta: 0:20:42  Lr: 0.001875  Loss: 0.1296  Acc@1: 50.0000 (41.8471)  Acc@5: 93.7500 (82.8378)  time: 0.3529  data: 0.0013  max mem: 2500
Train: Epoch[1/5]  [1060/4579]  eta: 0:20:38  Lr: 0.001875  Loss: -0.2311  Acc@1: 50.0000 (41.9180)  Acc@5: 93.7500 (82.8876)  time: 0.3460  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1070/4579]  eta: 0:20:35  Lr: 0.001875  Loss: -0.0665  Acc@1: 50.0000 (42.0110)  Acc@5: 93.7500 (82.9540)  time: 0.3477  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1080/4579]  eta: 0:20:31  Lr: 0.001875  Loss: 0.0162  Acc@1: 56.2500 (42.1311)  Acc@5: 93.7500 (83.0076)  time: 0.3484  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1090/4579]  eta: 0:20:27  Lr: 0.001875  Loss: 0.0903  Acc@1: 50.0000 (42.1975)  Acc@5: 87.5000 (83.0259)  time: 0.3482  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1100/4579]  eta: 0:20:24  Lr: 0.001875  Loss: 0.4031  Acc@1: 50.0000 (42.2854)  Acc@5: 87.5000 (83.0665)  time: 0.3474  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1110/4579]  eta: 0:20:20  Lr: 0.001875  Loss: -0.0260  Acc@1: 50.0000 (42.3886)  Acc@5: 87.5000 (83.0896)  time: 0.3456  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [1120/4579]  eta: 0:20:16  Lr: 0.001875  Loss: 0.0242  Acc@1: 56.2500 (42.4900)  Acc@5: 87.5000 (83.1456)  time: 0.3466  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1130/4579]  eta: 0:20:13  Lr: 0.001875  Loss: 0.0265  Acc@1: 50.0000 (42.5287)  Acc@5: 87.5000 (83.2118)  time: 0.3474  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1140/4579]  eta: 0:20:09  Lr: 0.001875  Loss: -0.0617  Acc@1: 43.7500 (42.5613)  Acc@5: 87.5000 (83.2439)  time: 0.3462  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [1150/4579]  eta: 0:20:05  Lr: 0.001875  Loss: 0.2246  Acc@1: 50.0000 (42.6423)  Acc@5: 87.5000 (83.2591)  time: 0.3461  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [1160/4579]  eta: 0:20:02  Lr: 0.001875  Loss: -0.3698  Acc@1: 56.2500 (42.7756)  Acc@5: 87.5000 (83.3226)  time: 0.3498  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [1170/4579]  eta: 0:19:58  Lr: 0.001875  Loss: -0.0041  Acc@1: 56.2500 (42.8213)  Acc@5: 87.5000 (83.3422)  time: 0.3515  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [1180/4579]  eta: 0:19:55  Lr: 0.001875  Loss: 0.5824  Acc@1: 50.0000 (42.8927)  Acc@5: 87.5000 (83.3774)  time: 0.3526  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [1190/4579]  eta: 0:19:51  Lr: 0.001875  Loss: -0.1065  Acc@1: 43.7500 (42.9209)  Acc@5: 87.5000 (83.4016)  time: 0.3536  data: 0.0011  max mem: 2500
Train: Epoch[1/5]  [1200/4579]  eta: 0:19:48  Lr: 0.001875  Loss: 0.6917  Acc@1: 50.0000 (43.0058)  Acc@5: 87.5000 (83.4305)  time: 0.3523  data: 0.0011  max mem: 2500
Train: Epoch[1/5]  [1210/4579]  eta: 0:19:44  Lr: 0.001875  Loss: 0.0701  Acc@1: 56.2500 (43.1307)  Acc@5: 87.5000 (83.5002)  time: 0.3536  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [1220/4579]  eta: 0:19:41  Lr: 0.001875  Loss: 0.1748  Acc@1: 56.2500 (43.2637)  Acc@5: 93.7500 (83.5534)  time: 0.3540  data: 0.0017  max mem: 2500
Train: Epoch[1/5]  [1230/4579]  eta: 0:19:37  Lr: 0.001875  Loss: -0.0665  Acc@1: 56.2500 (43.3489)  Acc@5: 93.7500 (83.6210)  time: 0.3519  data: 0.0023  max mem: 2500
Train: Epoch[1/5]  [1240/4579]  eta: 0:19:34  Lr: 0.001875  Loss: 0.2865  Acc@1: 56.2500 (43.4529)  Acc@5: 93.7500 (83.6573)  time: 0.3493  data: 0.0011  max mem: 2500
Train: Epoch[1/5]  [1250/4579]  eta: 0:19:30  Lr: 0.001875  Loss: 0.2990  Acc@1: 50.0000 (43.5002)  Acc@5: 87.5000 (83.6880)  time: 0.3472  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [1260/4579]  eta: 0:19:27  Lr: 0.001875  Loss: 0.1016  Acc@1: 50.0000 (43.5319)  Acc@5: 87.5000 (83.6985)  time: 0.3508  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1270/4579]  eta: 0:19:23  Lr: 0.001875  Loss: 0.1658  Acc@1: 50.0000 (43.6369)  Acc@5: 87.5000 (83.7480)  time: 0.3512  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [1280/4579]  eta: 0:19:19  Lr: 0.001875  Loss: 0.1353  Acc@1: 56.2500 (43.7207)  Acc@5: 87.5000 (83.7822)  time: 0.3476  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [1290/4579]  eta: 0:19:16  Lr: 0.001875  Loss: -0.1397  Acc@1: 56.2500 (43.8033)  Acc@5: 87.5000 (83.8207)  time: 0.3464  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [1300/4579]  eta: 0:19:12  Lr: 0.001875  Loss: -0.3097  Acc@1: 50.0000 (43.8269)  Acc@5: 93.7500 (83.8682)  time: 0.3466  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [1310/4579]  eta: 0:19:08  Lr: 0.001875  Loss: -0.0790  Acc@1: 50.0000 (43.9359)  Acc@5: 87.5000 (83.8863)  time: 0.3477  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [1320/4579]  eta: 0:19:05  Lr: 0.001875  Loss: -0.1074  Acc@1: 50.0000 (43.9960)  Acc@5: 87.5000 (83.9232)  time: 0.3467  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [1330/4579]  eta: 0:19:01  Lr: 0.001875  Loss: -0.4964  Acc@1: 50.0000 (44.1022)  Acc@5: 93.7500 (83.9735)  time: 0.3459  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [1340/4579]  eta: 0:18:58  Lr: 0.001875  Loss: 0.1738  Acc@1: 50.0000 (44.1508)  Acc@5: 93.7500 (84.0371)  time: 0.3551  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1350/4579]  eta: 0:18:54  Lr: 0.001875  Loss: 0.1830  Acc@1: 50.0000 (44.1849)  Acc@5: 93.7500 (84.0489)  time: 0.3582  data: 0.0012  max mem: 2500
Train: Epoch[1/5]  [1360/4579]  eta: 0:18:51  Lr: 0.001875  Loss: 0.4545  Acc@1: 50.0000 (44.2506)  Acc@5: 87.5000 (84.0834)  time: 0.3519  data: 0.0012  max mem: 2500
Train: Epoch[1/5]  [1370/4579]  eta: 0:18:47  Lr: 0.001875  Loss: -0.1253  Acc@1: 50.0000 (44.3107)  Acc@5: 87.5000 (84.1129)  time: 0.3528  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [1380/4579]  eta: 0:18:44  Lr: 0.001875  Loss: -0.1872  Acc@1: 56.2500 (44.3927)  Acc@5: 87.5000 (84.1465)  time: 0.3570  data: 0.0015  max mem: 2500
Train: Epoch[1/5]  [1390/4579]  eta: 0:18:41  Lr: 0.001875  Loss: 0.1688  Acc@1: 50.0000 (44.4105)  Acc@5: 93.7500 (84.2110)  time: 0.3585  data: 0.0036  max mem: 2500
Train: Epoch[1/5]  [1400/4579]  eta: 0:18:37  Lr: 0.001875  Loss: 0.1080  Acc@1: 50.0000 (44.4593)  Acc@5: 93.7500 (84.2523)  time: 0.3531  data: 0.0027  max mem: 2500
Train: Epoch[1/5]  [1410/4579]  eta: 0:18:34  Lr: 0.001875  Loss: -0.1319  Acc@1: 50.0000 (44.4809)  Acc@5: 87.5000 (84.2576)  time: 0.3525  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [1420/4579]  eta: 0:18:30  Lr: 0.001875  Loss: 0.2126  Acc@1: 50.0000 (44.5417)  Acc@5: 87.5000 (84.3024)  time: 0.3522  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [1430/4579]  eta: 0:18:27  Lr: 0.001875  Loss: 0.2546  Acc@1: 50.0000 (44.5798)  Acc@5: 87.5000 (84.3204)  time: 0.3481  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1440/4579]  eta: 0:18:23  Lr: 0.001875  Loss: -0.1063  Acc@1: 50.0000 (44.6695)  Acc@5: 87.5000 (84.3468)  time: 0.3490  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [1450/4579]  eta: 0:18:19  Lr: 0.001875  Loss: -0.1531  Acc@1: 56.2500 (44.7665)  Acc@5: 87.5000 (84.3556)  time: 0.3488  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [1460/4579]  eta: 0:18:16  Lr: 0.001875  Loss: -0.0291  Acc@1: 50.0000 (44.7810)  Acc@5: 81.2500 (84.3557)  time: 0.3478  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1470/4579]  eta: 0:18:12  Lr: 0.001875  Loss: -0.3100  Acc@1: 50.0000 (44.8674)  Acc@5: 87.5000 (84.4154)  time: 0.3466  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [1480/4579]  eta: 0:18:09  Lr: 0.001875  Loss: 0.0319  Acc@1: 56.2500 (44.9485)  Acc@5: 87.5000 (84.4151)  time: 0.3461  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [1490/4579]  eta: 0:18:05  Lr: 0.001875  Loss: -0.1676  Acc@1: 56.2500 (44.9908)  Acc@5: 87.5000 (84.4442)  time: 0.3467  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1500/4579]  eta: 0:18:01  Lr: 0.001875  Loss: 0.1702  Acc@1: 56.2500 (45.0408)  Acc@5: 87.5000 (84.4520)  time: 0.3453  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1510/4579]  eta: 0:17:58  Lr: 0.001875  Loss: -0.1260  Acc@1: 56.2500 (45.1191)  Acc@5: 87.5000 (84.5012)  time: 0.3457  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [1520/4579]  eta: 0:17:54  Lr: 0.001875  Loss: 0.0105  Acc@1: 56.2500 (45.1923)  Acc@5: 93.7500 (84.5455)  time: 0.3497  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [1530/4579]  eta: 0:17:51  Lr: 0.001875  Loss: 0.1331  Acc@1: 50.0000 (45.2155)  Acc@5: 93.7500 (84.5648)  time: 0.3512  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [1540/4579]  eta: 0:17:47  Lr: 0.001875  Loss: -0.2359  Acc@1: 50.0000 (45.2304)  Acc@5: 87.5000 (84.6001)  time: 0.3523  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [1550/4579]  eta: 0:17:44  Lr: 0.001875  Loss: -0.1730  Acc@1: 56.2500 (45.3216)  Acc@5: 87.5000 (84.6389)  time: 0.3540  data: 0.0010  max mem: 2500
Train: Epoch[1/5]  [1560/4579]  eta: 0:17:40  Lr: 0.001875  Loss: 0.1657  Acc@1: 56.2500 (45.4196)  Acc@5: 93.7500 (84.6853)  time: 0.3566  data: 0.0016  max mem: 2500
Train: Epoch[1/5]  [1570/4579]  eta: 0:17:37  Lr: 0.001875  Loss: 0.4604  Acc@1: 56.2500 (45.4328)  Acc@5: 93.7500 (84.7231)  time: 0.3569  data: 0.0014  max mem: 2500
Train: Epoch[1/5]  [1580/4579]  eta: 0:17:33  Lr: 0.001875  Loss: -0.2615  Acc@1: 50.0000 (45.4973)  Acc@5: 87.5000 (84.7367)  time: 0.3521  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [1590/4579]  eta: 0:17:30  Lr: 0.001875  Loss: -0.0859  Acc@1: 50.0000 (45.4981)  Acc@5: 87.5000 (84.7541)  time: 0.3492  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [1600/4579]  eta: 0:17:26  Lr: 0.001875  Loss: 0.0647  Acc@1: 50.0000 (45.5809)  Acc@5: 87.5000 (84.7751)  time: 0.3480  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1610/4579]  eta: 0:17:23  Lr: 0.001875  Loss: 0.4208  Acc@1: 56.2500 (45.6510)  Acc@5: 87.5000 (84.7843)  time: 0.3479  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1620/4579]  eta: 0:17:19  Lr: 0.001875  Loss: 0.3456  Acc@1: 56.2500 (45.6971)  Acc@5: 87.5000 (84.8088)  time: 0.3499  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1630/4579]  eta: 0:17:16  Lr: 0.001875  Loss: 0.0321  Acc@1: 56.2500 (45.7733)  Acc@5: 87.5000 (84.8483)  time: 0.3496  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1640/4579]  eta: 0:17:12  Lr: 0.001875  Loss: 0.0187  Acc@1: 56.2500 (45.8371)  Acc@5: 93.7500 (84.9025)  time: 0.3473  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [1650/4579]  eta: 0:17:08  Lr: 0.001875  Loss: -0.3350  Acc@1: 50.0000 (45.8889)  Acc@5: 93.7500 (84.9334)  time: 0.3463  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [1660/4579]  eta: 0:17:05  Lr: 0.001875  Loss: 0.2608  Acc@1: 50.0000 (45.9211)  Acc@5: 87.5000 (84.9714)  time: 0.3458  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [1670/4579]  eta: 0:17:01  Lr: 0.001875  Loss: -0.3361  Acc@1: 56.2500 (46.0016)  Acc@5: 87.5000 (84.9828)  time: 0.3458  data: 0.0002  max mem: 2500
Train: Epoch[1/5]  [1680/4579]  eta: 0:16:58  Lr: 0.001875  Loss: 0.1560  Acc@1: 50.0000 (46.0068)  Acc@5: 87.5000 (84.9755)  time: 0.3448  data: 0.0002  max mem: 2500
Train: Epoch[1/5]  [1690/4579]  eta: 0:16:54  Lr: 0.001875  Loss: -0.1753  Acc@1: 50.0000 (46.0674)  Acc@5: 87.5000 (84.9830)  time: 0.3488  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [1700/4579]  eta: 0:16:51  Lr: 0.001875  Loss: 0.0761  Acc@1: 56.2500 (46.1567)  Acc@5: 87.5000 (85.0088)  time: 0.3514  data: 0.0009  max mem: 2500
Train: Epoch[1/5]  [1710/4579]  eta: 0:16:47  Lr: 0.001875  Loss: 0.8073  Acc@1: 43.7500 (46.1499)  Acc@5: 87.5000 (85.0197)  time: 0.3497  data: 0.0012  max mem: 2500
Train: Epoch[1/5]  [1720/4579]  eta: 0:16:44  Lr: 0.001875  Loss: -0.4110  Acc@1: 43.7500 (46.2231)  Acc@5: 87.5000 (85.0414)  time: 0.3523  data: 0.0015  max mem: 2500
Train: Epoch[1/5]  [1730/4579]  eta: 0:16:40  Lr: 0.001875  Loss: 0.0121  Acc@1: 56.2500 (46.2594)  Acc@5: 87.5000 (85.0737)  time: 0.3534  data: 0.0010  max mem: 2500
Train: Epoch[1/5]  [1740/4579]  eta: 0:16:37  Lr: 0.001875  Loss: 0.2556  Acc@1: 56.2500 (46.2952)  Acc@5: 87.5000 (85.1055)  time: 0.3569  data: 0.0038  max mem: 2500
Train: Epoch[1/5]  [1750/4579]  eta: 0:16:33  Lr: 0.001875  Loss: 0.6602  Acc@1: 56.2500 (46.3985)  Acc@5: 93.7500 (85.1478)  time: 0.3577  data: 0.0045  max mem: 2500
Train: Epoch[1/5]  [1760/4579]  eta: 0:16:30  Lr: 0.001875  Loss: 0.1191  Acc@1: 56.2500 (46.4757)  Acc@5: 93.7500 (85.1718)  time: 0.3523  data: 0.0014  max mem: 2500
Train: Epoch[1/5]  [1770/4579]  eta: 0:16:26  Lr: 0.001875  Loss: -0.0923  Acc@1: 62.5000 (46.5697)  Acc@5: 93.7500 (85.2096)  time: 0.3509  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [1780/4579]  eta: 0:16:23  Lr: 0.001875  Loss: -0.0772  Acc@1: 62.5000 (46.6311)  Acc@5: 93.7500 (85.2330)  time: 0.3491  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1790/4579]  eta: 0:16:19  Lr: 0.001875  Loss: 0.3386  Acc@1: 56.2500 (46.6883)  Acc@5: 87.5000 (85.2282)  time: 0.3486  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1800/4579]  eta: 0:16:16  Lr: 0.001875  Loss: 0.2320  Acc@1: 56.2500 (46.7310)  Acc@5: 87.5000 (85.2651)  time: 0.3497  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1810/4579]  eta: 0:16:12  Lr: 0.001875  Loss: 0.4416  Acc@1: 56.2500 (46.7663)  Acc@5: 93.7500 (85.2947)  time: 0.3482  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [1820/4579]  eta: 0:16:08  Lr: 0.001875  Loss: -0.2336  Acc@1: 50.0000 (46.7875)  Acc@5: 87.5000 (85.3240)  time: 0.3479  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [1830/4579]  eta: 0:16:05  Lr: 0.001875  Loss: -0.0596  Acc@1: 56.2500 (46.8460)  Acc@5: 87.5000 (85.3427)  time: 0.3501  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [1840/4579]  eta: 0:16:01  Lr: 0.001875  Loss: 0.2080  Acc@1: 56.2500 (46.9073)  Acc@5: 93.7500 (85.3850)  time: 0.3488  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [1850/4579]  eta: 0:15:58  Lr: 0.001875  Loss: 0.3012  Acc@1: 56.2500 (46.9476)  Acc@5: 93.7500 (85.4032)  time: 0.3456  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [1860/4579]  eta: 0:15:54  Lr: 0.001875  Loss: 0.1169  Acc@1: 56.2500 (46.9774)  Acc@5: 87.5000 (85.4144)  time: 0.3459  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1870/4579]  eta: 0:15:51  Lr: 0.001875  Loss: -0.3601  Acc@1: 56.2500 (47.0804)  Acc@5: 87.5000 (85.4389)  time: 0.3531  data: 0.0020  max mem: 2500
Train: Epoch[1/5]  [1880/4579]  eta: 0:15:47  Lr: 0.001875  Loss: -0.3289  Acc@1: 62.5000 (47.1192)  Acc@5: 93.7500 (85.4499)  time: 0.3567  data: 0.0020  max mem: 2500
Train: Epoch[1/5]  [1890/4579]  eta: 0:15:44  Lr: 0.001875  Loss: -0.3068  Acc@1: 56.2500 (47.1906)  Acc@5: 87.5000 (85.4673)  time: 0.3506  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [1900/4579]  eta: 0:15:40  Lr: 0.001875  Loss: 0.2099  Acc@1: 56.2500 (47.2383)  Acc@5: 87.5000 (85.4748)  time: 0.3498  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [1910/4579]  eta: 0:15:37  Lr: 0.001875  Loss: 0.4689  Acc@1: 50.0000 (47.2789)  Acc@5: 87.5000 (85.4755)  time: 0.3539  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [1920/4579]  eta: 0:15:33  Lr: 0.001875  Loss: -0.0375  Acc@1: 56.2500 (47.3126)  Acc@5: 87.5000 (85.4828)  time: 0.3546  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [1930/4579]  eta: 0:15:30  Lr: 0.001875  Loss: -0.1687  Acc@1: 56.2500 (47.3556)  Acc@5: 87.5000 (85.5062)  time: 0.3512  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [1940/4579]  eta: 0:15:26  Lr: 0.001875  Loss: 0.1407  Acc@1: 56.2500 (47.4143)  Acc@5: 93.7500 (85.5294)  time: 0.3516  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1950/4579]  eta: 0:15:23  Lr: 0.001875  Loss: 0.2899  Acc@1: 56.2500 (47.4660)  Acc@5: 87.5000 (85.5459)  time: 0.3532  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [1960/4579]  eta: 0:15:19  Lr: 0.001875  Loss: -0.1740  Acc@1: 56.2500 (47.5108)  Acc@5: 87.5000 (85.5622)  time: 0.3519  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1970/4579]  eta: 0:15:16  Lr: 0.001875  Loss: 0.2109  Acc@1: 50.0000 (47.5425)  Acc@5: 87.5000 (85.5720)  time: 0.3514  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [1980/4579]  eta: 0:15:12  Lr: 0.001875  Loss: 0.3259  Acc@1: 56.2500 (47.6148)  Acc@5: 87.5000 (85.5912)  time: 0.3494  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [1990/4579]  eta: 0:15:09  Lr: 0.001875  Loss: -0.1356  Acc@1: 56.2500 (47.6394)  Acc@5: 93.7500 (85.6102)  time: 0.3477  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2000/4579]  eta: 0:15:05  Lr: 0.001875  Loss: -0.0317  Acc@1: 56.2500 (47.7011)  Acc@5: 93.7500 (85.6416)  time: 0.3507  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2010/4579]  eta: 0:15:02  Lr: 0.001875  Loss: -0.0566  Acc@1: 56.2500 (47.7250)  Acc@5: 93.7500 (85.6508)  time: 0.3520  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [2020/4579]  eta: 0:14:58  Lr: 0.001875  Loss: 0.7245  Acc@1: 50.0000 (47.7363)  Acc@5: 87.5000 (85.6599)  time: 0.3469  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [2030/4579]  eta: 0:14:54  Lr: 0.001875  Loss: 0.0820  Acc@1: 50.0000 (47.7936)  Acc@5: 87.5000 (85.6875)  time: 0.3446  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [2040/4579]  eta: 0:14:51  Lr: 0.001875  Loss: 0.4098  Acc@1: 56.2500 (47.8289)  Acc@5: 87.5000 (85.6749)  time: 0.3463  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2050/4579]  eta: 0:14:47  Lr: 0.001875  Loss: 0.0564  Acc@1: 56.2500 (47.8882)  Acc@5: 87.5000 (85.7082)  time: 0.3483  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2060/4579]  eta: 0:14:44  Lr: 0.001875  Loss: 0.2203  Acc@1: 56.2500 (47.9470)  Acc@5: 93.7500 (85.7351)  time: 0.3512  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2070/4579]  eta: 0:14:40  Lr: 0.001875  Loss: -0.3996  Acc@1: 56.2500 (47.9780)  Acc@5: 87.5000 (85.7527)  time: 0.3519  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2080/4579]  eta: 0:14:37  Lr: 0.001875  Loss: 0.2624  Acc@1: 50.0000 (48.0028)  Acc@5: 93.7500 (85.7821)  time: 0.3507  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2090/4579]  eta: 0:14:33  Lr: 0.001875  Loss: 0.3623  Acc@1: 50.0000 (48.0213)  Acc@5: 93.7500 (85.7813)  time: 0.3522  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [2100/4579]  eta: 0:14:30  Lr: 0.001875  Loss: 0.4616  Acc@1: 50.0000 (48.0664)  Acc@5: 87.5000 (85.7836)  time: 0.3524  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [2110/4579]  eta: 0:14:26  Lr: 0.001875  Loss: 0.4218  Acc@1: 56.2500 (48.1229)  Acc@5: 87.5000 (85.7946)  time: 0.3503  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2120/4579]  eta: 0:14:23  Lr: 0.001875  Loss: 0.0477  Acc@1: 56.2500 (48.1377)  Acc@5: 87.5000 (85.8174)  time: 0.3526  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2130/4579]  eta: 0:14:19  Lr: 0.001875  Loss: 0.0211  Acc@1: 50.0000 (48.1728)  Acc@5: 87.5000 (85.8282)  time: 0.3534  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2140/4579]  eta: 0:14:16  Lr: 0.001875  Loss: 0.3595  Acc@1: 56.2500 (48.1901)  Acc@5: 87.5000 (85.8507)  time: 0.3498  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [2150/4579]  eta: 0:14:12  Lr: 0.001875  Loss: -0.1165  Acc@1: 56.2500 (48.2624)  Acc@5: 93.7500 (85.8787)  time: 0.3480  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [2160/4579]  eta: 0:14:09  Lr: 0.001875  Loss: 0.1412  Acc@1: 62.5000 (48.3168)  Acc@5: 93.7500 (85.9151)  time: 0.3478  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2170/4579]  eta: 0:14:05  Lr: 0.001875  Loss: -0.0527  Acc@1: 56.2500 (48.3533)  Acc@5: 93.7500 (85.9224)  time: 0.3480  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2180/4579]  eta: 0:14:02  Lr: 0.001875  Loss: 0.0155  Acc@1: 56.2500 (48.4010)  Acc@5: 87.5000 (85.9325)  time: 0.3506  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2190/4579]  eta: 0:13:58  Lr: 0.001875  Loss: -0.2857  Acc@1: 56.2500 (48.4453)  Acc@5: 87.5000 (85.9396)  time: 0.3514  data: 0.0010  max mem: 2500
Train: Epoch[1/5]  [2200/4579]  eta: 0:13:55  Lr: 0.001875  Loss: -0.2896  Acc@1: 56.2500 (48.5007)  Acc@5: 87.5000 (85.9666)  time: 0.3466  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [2210/4579]  eta: 0:13:51  Lr: 0.001875  Loss: 0.2963  Acc@1: 56.2500 (48.5188)  Acc@5: 87.5000 (85.9566)  time: 0.3449  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2220/4579]  eta: 0:13:47  Lr: 0.001875  Loss: 0.1381  Acc@1: 56.2500 (48.5564)  Acc@5: 81.2500 (85.9551)  time: 0.3470  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2230/4579]  eta: 0:13:44  Lr: 0.001875  Loss: -0.3104  Acc@1: 56.2500 (48.5825)  Acc@5: 87.5000 (85.9816)  time: 0.3503  data: 0.0010  max mem: 2500
Train: Epoch[1/5]  [2240/4579]  eta: 0:13:40  Lr: 0.001875  Loss: 0.1064  Acc@1: 56.2500 (48.6195)  Acc@5: 87.5000 (85.9884)  time: 0.3521  data: 0.0010  max mem: 2500
Train: Epoch[1/5]  [2250/4579]  eta: 0:13:37  Lr: 0.001875  Loss: -0.3096  Acc@1: 56.2500 (48.6562)  Acc@5: 87.5000 (86.0145)  time: 0.3506  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2260/4579]  eta: 0:13:34  Lr: 0.001875  Loss: 0.1436  Acc@1: 56.2500 (48.6732)  Acc@5: 87.5000 (86.0294)  time: 0.3547  data: 0.0015  max mem: 2500
Train: Epoch[1/5]  [2270/4579]  eta: 0:13:30  Lr: 0.001875  Loss: -0.0646  Acc@1: 56.2500 (48.7038)  Acc@5: 87.5000 (86.0304)  time: 0.3594  data: 0.0018  max mem: 2500
Train: Epoch[1/5]  [2280/4579]  eta: 0:13:27  Lr: 0.001875  Loss: 0.4568  Acc@1: 56.2500 (48.7204)  Acc@5: 87.5000 (86.0313)  time: 0.3562  data: 0.0009  max mem: 2500
Train: Epoch[1/5]  [2290/4579]  eta: 0:13:23  Lr: 0.001875  Loss: 0.2531  Acc@1: 50.0000 (48.7342)  Acc@5: 87.5000 (86.0432)  time: 0.3517  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [2300/4579]  eta: 0:13:20  Lr: 0.001875  Loss: -0.0940  Acc@1: 56.2500 (48.7641)  Acc@5: 87.5000 (86.0550)  time: 0.3523  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2310/4579]  eta: 0:13:16  Lr: 0.001875  Loss: -0.5548  Acc@1: 56.2500 (48.7884)  Acc@5: 87.5000 (86.0829)  time: 0.3591  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [2320/4579]  eta: 0:13:13  Lr: 0.001875  Loss: 0.2355  Acc@1: 56.2500 (48.8017)  Acc@5: 87.5000 (86.0809)  time: 0.3556  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [2330/4579]  eta: 0:13:09  Lr: 0.001875  Loss: 0.2979  Acc@1: 50.0000 (48.8122)  Acc@5: 87.5000 (86.0870)  time: 0.3479  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2340/4579]  eta: 0:13:06  Lr: 0.001875  Loss: 0.0202  Acc@1: 56.2500 (48.8653)  Acc@5: 93.7500 (86.1170)  time: 0.3510  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2350/4579]  eta: 0:13:02  Lr: 0.001875  Loss: 0.0190  Acc@1: 56.2500 (48.8967)  Acc@5: 93.7500 (86.1442)  time: 0.3523  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [2360/4579]  eta: 0:12:59  Lr: 0.001875  Loss: -0.1168  Acc@1: 56.2500 (48.9385)  Acc@5: 93.7500 (86.1764)  time: 0.3515  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2370/4579]  eta: 0:12:55  Lr: 0.001875  Loss: 0.1824  Acc@1: 62.5000 (48.9746)  Acc@5: 93.7500 (86.1794)  time: 0.3486  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [2380/4579]  eta: 0:12:52  Lr: 0.001875  Loss: -0.6342  Acc@1: 62.5000 (49.0340)  Acc@5: 87.5000 (86.2007)  time: 0.3454  data: 0.0002  max mem: 2500
Train: Epoch[1/5]  [2390/4579]  eta: 0:12:48  Lr: 0.001875  Loss: 0.0207  Acc@1: 62.5000 (49.0590)  Acc@5: 87.5000 (86.2061)  time: 0.3470  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2400/4579]  eta: 0:12:44  Lr: 0.001875  Loss: -0.4997  Acc@1: 62.5000 (49.1254)  Acc@5: 93.7500 (86.2531)  time: 0.3468  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2410/4579]  eta: 0:12:41  Lr: 0.001875  Loss: 0.0919  Acc@1: 56.2500 (49.1497)  Acc@5: 93.7500 (86.2609)  time: 0.3477  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [2420/4579]  eta: 0:12:37  Lr: 0.001875  Loss: -0.3707  Acc@1: 56.2500 (49.1920)  Acc@5: 87.5000 (86.2763)  time: 0.3499  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2430/4579]  eta: 0:12:34  Lr: 0.001875  Loss: 0.7216  Acc@1: 56.2500 (49.2056)  Acc@5: 87.5000 (86.2916)  time: 0.3528  data: 0.0011  max mem: 2500
Train: Epoch[1/5]  [2440/4579]  eta: 0:12:30  Lr: 0.001875  Loss: 0.1511  Acc@1: 56.2500 (49.2319)  Acc@5: 87.5000 (86.2992)  time: 0.3547  data: 0.0014  max mem: 2500
Train: Epoch[1/5]  [2450/4579]  eta: 0:12:27  Lr: 0.001875  Loss: -0.2359  Acc@1: 62.5000 (49.2962)  Acc@5: 93.7500 (86.3219)  time: 0.3533  data: 0.0009  max mem: 2500
Train: Epoch[1/5]  [2460/4579]  eta: 0:12:23  Lr: 0.001875  Loss: 0.1078  Acc@1: 56.2500 (49.3041)  Acc@5: 93.7500 (86.3292)  time: 0.3507  data: 0.0009  max mem: 2500
Train: Epoch[1/5]  [2470/4579]  eta: 0:12:20  Lr: 0.001875  Loss: -0.3359  Acc@1: 56.2500 (49.3373)  Acc@5: 87.5000 (86.3264)  time: 0.3502  data: 0.0009  max mem: 2500
Train: Epoch[1/5]  [2480/4579]  eta: 0:12:16  Lr: 0.001875  Loss: -0.1901  Acc@1: 56.2500 (49.3727)  Acc@5: 87.5000 (86.3387)  time: 0.3529  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [2490/4579]  eta: 0:12:13  Lr: 0.001875  Loss: -0.2505  Acc@1: 56.2500 (49.4154)  Acc@5: 93.7500 (86.3709)  time: 0.3541  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [2500/4579]  eta: 0:12:09  Lr: 0.001875  Loss: 0.0324  Acc@1: 56.2500 (49.4502)  Acc@5: 93.7500 (86.3854)  time: 0.3513  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2510/4579]  eta: 0:12:06  Lr: 0.001875  Loss: -0.0309  Acc@1: 56.2500 (49.4947)  Acc@5: 87.5000 (86.4023)  time: 0.3481  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2520/4579]  eta: 0:12:02  Lr: 0.001875  Loss: -0.1721  Acc@1: 62.5000 (49.5414)  Acc@5: 93.7500 (86.4191)  time: 0.3481  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2530/4579]  eta: 0:11:59  Lr: 0.001875  Loss: -0.3453  Acc@1: 62.5000 (49.6024)  Acc@5: 93.7500 (86.4456)  time: 0.3491  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [2540/4579]  eta: 0:11:55  Lr: 0.001875  Loss: 0.2216  Acc@1: 56.2500 (49.6286)  Acc@5: 93.7500 (86.4645)  time: 0.3497  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [2550/4579]  eta: 0:11:52  Lr: 0.001875  Loss: -0.3520  Acc@1: 56.2500 (49.6741)  Acc@5: 93.7500 (86.4808)  time: 0.3481  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2560/4579]  eta: 0:11:48  Lr: 0.001875  Loss: 0.6096  Acc@1: 56.2500 (49.7120)  Acc@5: 93.7500 (86.4848)  time: 0.3460  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [2570/4579]  eta: 0:11:45  Lr: 0.001875  Loss: -0.2084  Acc@1: 56.2500 (49.7277)  Acc@5: 87.5000 (86.4912)  time: 0.3473  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [2580/4579]  eta: 0:11:41  Lr: 0.001875  Loss: -0.1451  Acc@1: 56.2500 (49.7554)  Acc@5: 87.5000 (86.4951)  time: 0.3463  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [2590/4579]  eta: 0:11:38  Lr: 0.001875  Loss: 0.2773  Acc@1: 62.5000 (49.7781)  Acc@5: 87.5000 (86.4748)  time: 0.3446  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [2600/4579]  eta: 0:11:34  Lr: 0.001875  Loss: -0.2742  Acc@1: 56.2500 (49.7958)  Acc@5: 87.5000 (86.4980)  time: 0.3529  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [2610/4579]  eta: 0:11:31  Lr: 0.001875  Loss: 0.0001  Acc@1: 56.2500 (49.8133)  Acc@5: 93.7500 (86.5066)  time: 0.3584  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [2620/4579]  eta: 0:11:27  Lr: 0.001875  Loss: -0.1774  Acc@1: 56.2500 (49.8450)  Acc@5: 87.5000 (86.5199)  time: 0.3543  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [2630/4579]  eta: 0:11:24  Lr: 0.001875  Loss: 0.0959  Acc@1: 56.2500 (49.8622)  Acc@5: 87.5000 (86.5189)  time: 0.3536  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [2640/4579]  eta: 0:11:20  Lr: 0.001875  Loss: 0.3845  Acc@1: 56.2500 (49.8911)  Acc@5: 87.5000 (86.5368)  time: 0.3538  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [2650/4579]  eta: 0:11:17  Lr: 0.001875  Loss: -0.3123  Acc@1: 50.0000 (49.9010)  Acc@5: 87.5000 (86.5499)  time: 0.3539  data: 0.0010  max mem: 2500
Train: Epoch[1/5]  [2660/4579]  eta: 0:11:13  Lr: 0.001875  Loss: -0.5687  Acc@1: 56.2500 (49.9389)  Acc@5: 87.5000 (86.5675)  time: 0.3549  data: 0.0011  max mem: 2500
Train: Epoch[1/5]  [2670/4579]  eta: 0:11:10  Lr: 0.001875  Loss: -0.3304  Acc@1: 62.5000 (49.9579)  Acc@5: 87.5000 (86.5734)  time: 0.3623  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [2680/4579]  eta: 0:11:06  Lr: 0.001875  Loss: -0.3277  Acc@1: 50.0000 (49.9907)  Acc@5: 87.5000 (86.5885)  time: 0.3605  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [2690/4579]  eta: 0:11:03  Lr: 0.001875  Loss: 0.8591  Acc@1: 50.0000 (49.9907)  Acc@5: 87.5000 (86.5919)  time: 0.3492  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [2700/4579]  eta: 0:10:59  Lr: 0.001875  Loss: -0.1809  Acc@1: 56.2500 (50.0069)  Acc@5: 87.5000 (86.5906)  time: 0.3482  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2710/4579]  eta: 0:10:56  Lr: 0.001875  Loss: 0.1498  Acc@1: 56.2500 (50.0323)  Acc@5: 81.2500 (86.5778)  time: 0.3487  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2720/4579]  eta: 0:10:52  Lr: 0.001875  Loss: -0.0080  Acc@1: 62.5000 (50.0781)  Acc@5: 87.5000 (86.5835)  time: 0.3494  data: 0.0011  max mem: 2500
Train: Epoch[1/5]  [2730/4579]  eta: 0:10:49  Lr: 0.001875  Loss: 0.1920  Acc@1: 62.5000 (50.0847)  Acc@5: 87.5000 (86.5915)  time: 0.3483  data: 0.0010  max mem: 2500
Train: Epoch[1/5]  [2740/4579]  eta: 0:10:45  Lr: 0.001875  Loss: 0.2639  Acc@1: 50.0000 (50.0935)  Acc@5: 87.5000 (86.5948)  time: 0.3478  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [2750/4579]  eta: 0:10:42  Lr: 0.001875  Loss: -0.0350  Acc@1: 56.2500 (50.1181)  Acc@5: 87.5000 (86.6003)  time: 0.3480  data: 0.0009  max mem: 2500
Train: Epoch[1/5]  [2760/4579]  eta: 0:10:38  Lr: 0.001875  Loss: 0.0177  Acc@1: 56.2500 (50.1381)  Acc@5: 87.5000 (86.6104)  time: 0.3463  data: 0.0009  max mem: 2500
Train: Epoch[1/5]  [2770/4579]  eta: 0:10:34  Lr: 0.001875  Loss: 0.3445  Acc@1: 56.2500 (50.1444)  Acc@5: 87.5000 (86.5955)  time: 0.3456  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [2780/4579]  eta: 0:10:31  Lr: 0.001875  Loss: -0.1312  Acc@1: 56.2500 (50.1888)  Acc@5: 87.5000 (86.6100)  time: 0.3520  data: 0.0018  max mem: 2500
Train: Epoch[1/5]  [2790/4579]  eta: 0:10:28  Lr: 0.001875  Loss: 0.0445  Acc@1: 56.2500 (50.1903)  Acc@5: 87.5000 (86.6043)  time: 0.3559  data: 0.0021  max mem: 2500
Train: Epoch[1/5]  [2800/4579]  eta: 0:10:24  Lr: 0.001875  Loss: -0.0738  Acc@1: 50.0000 (50.2053)  Acc@5: 87.5000 (86.6097)  time: 0.3509  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [2810/4579]  eta: 0:10:20  Lr: 0.001875  Loss: -0.1797  Acc@1: 56.2500 (50.2424)  Acc@5: 87.5000 (86.6262)  time: 0.3502  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [2820/4579]  eta: 0:10:17  Lr: 0.001875  Loss: -0.0894  Acc@1: 62.5000 (50.2880)  Acc@5: 93.7500 (86.6404)  time: 0.3539  data: 0.0011  max mem: 2500
Train: Epoch[1/5]  [2830/4579]  eta: 0:10:14  Lr: 0.001875  Loss: -0.1201  Acc@1: 62.5000 (50.3069)  Acc@5: 87.5000 (86.6456)  time: 0.3570  data: 0.0010  max mem: 2500
Train: Epoch[1/5]  [2840/4579]  eta: 0:10:10  Lr: 0.001875  Loss: -0.1097  Acc@1: 62.5000 (50.3608)  Acc@5: 93.7500 (86.6596)  time: 0.3535  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2850/4579]  eta: 0:10:07  Lr: 0.001875  Loss: -0.2135  Acc@1: 68.7500 (50.4078)  Acc@5: 93.7500 (86.6801)  time: 0.3498  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2860/4579]  eta: 0:10:03  Lr: 0.001875  Loss: -0.3220  Acc@1: 62.5000 (50.4413)  Acc@5: 93.7500 (86.6961)  time: 0.3489  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2870/4579]  eta: 0:09:59  Lr: 0.001875  Loss: 0.2127  Acc@1: 56.2500 (50.4724)  Acc@5: 93.7500 (86.7098)  time: 0.3489  data: 0.0011  max mem: 2500
Train: Epoch[1/5]  [2880/4579]  eta: 0:09:56  Lr: 0.001875  Loss: -0.5306  Acc@1: 50.0000 (50.4925)  Acc@5: 87.5000 (86.7038)  time: 0.3499  data: 0.0011  max mem: 2500
Train: Epoch[1/5]  [2890/4579]  eta: 0:09:52  Lr: 0.001875  Loss: -0.6475  Acc@1: 56.2500 (50.5340)  Acc@5: 87.5000 (86.7282)  time: 0.3481  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2900/4579]  eta: 0:09:49  Lr: 0.001875  Loss: -0.1157  Acc@1: 62.5000 (50.5752)  Acc@5: 87.5000 (86.7287)  time: 0.3474  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2910/4579]  eta: 0:09:45  Lr: 0.001875  Loss: -0.1686  Acc@1: 62.5000 (50.6033)  Acc@5: 87.5000 (86.7378)  time: 0.3487  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [2920/4579]  eta: 0:09:42  Lr: 0.001875  Loss: -0.1903  Acc@1: 56.2500 (50.6141)  Acc@5: 93.7500 (86.7490)  time: 0.3485  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [2930/4579]  eta: 0:09:38  Lr: 0.001875  Loss: 0.2384  Acc@1: 56.2500 (50.6291)  Acc@5: 87.5000 (86.7515)  time: 0.3457  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [2940/4579]  eta: 0:09:35  Lr: 0.001875  Loss: -0.1626  Acc@1: 56.2500 (50.6482)  Acc@5: 87.5000 (86.7668)  time: 0.3447  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [2950/4579]  eta: 0:09:31  Lr: 0.001875  Loss: -0.1511  Acc@1: 56.2500 (50.6799)  Acc@5: 87.5000 (86.7630)  time: 0.3487  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2960/4579]  eta: 0:09:28  Lr: 0.001875  Loss: -0.0003  Acc@1: 56.2500 (50.7156)  Acc@5: 87.5000 (86.7760)  time: 0.3522  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [2970/4579]  eta: 0:09:24  Lr: 0.001875  Loss: -0.2195  Acc@1: 62.5000 (50.7573)  Acc@5: 93.7500 (86.7826)  time: 0.3516  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [2980/4579]  eta: 0:09:21  Lr: 0.001875  Loss: 0.4697  Acc@1: 62.5000 (50.7736)  Acc@5: 87.5000 (86.7892)  time: 0.3509  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [2990/4579]  eta: 0:09:17  Lr: 0.001875  Loss: -0.4224  Acc@1: 62.5000 (50.8149)  Acc@5: 87.5000 (86.8063)  time: 0.3527  data: 0.0012  max mem: 2500
Train: Epoch[1/5]  [3000/4579]  eta: 0:09:14  Lr: 0.001875  Loss: 0.0533  Acc@1: 56.2500 (50.8185)  Acc@5: 87.5000 (86.8044)  time: 0.3565  data: 0.0013  max mem: 2500
Train: Epoch[1/5]  [3010/4579]  eta: 0:09:10  Lr: 0.001875  Loss: -0.0973  Acc@1: 56.2500 (50.8593)  Acc@5: 87.5000 (86.8150)  time: 0.3563  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [3020/4579]  eta: 0:09:07  Lr: 0.001875  Loss: -0.2979  Acc@1: 68.7500 (50.8896)  Acc@5: 93.7500 (86.8256)  time: 0.3555  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [3030/4579]  eta: 0:09:03  Lr: 0.001875  Loss: 0.1004  Acc@1: 62.5000 (50.9197)  Acc@5: 87.5000 (86.8298)  time: 0.3531  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [3040/4579]  eta: 0:09:00  Lr: 0.001875  Loss: -0.2836  Acc@1: 56.2500 (50.9413)  Acc@5: 87.5000 (86.8362)  time: 0.3493  data: 0.0010  max mem: 2500
Train: Epoch[1/5]  [3050/4579]  eta: 0:08:56  Lr: 0.001875  Loss: -0.3509  Acc@1: 56.2500 (50.9608)  Acc@5: 93.7500 (86.8506)  time: 0.3504  data: 0.0009  max mem: 2500
Train: Epoch[1/5]  [3060/4579]  eta: 0:08:53  Lr: 0.001875  Loss: 0.2910  Acc@1: 62.5000 (50.9984)  Acc@5: 93.7500 (86.8732)  time: 0.3492  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3070/4579]  eta: 0:08:49  Lr: 0.001875  Loss: 0.2845  Acc@1: 56.2500 (51.0155)  Acc@5: 93.7500 (86.8772)  time: 0.3480  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3080/4579]  eta: 0:08:46  Lr: 0.001875  Loss: 0.0026  Acc@1: 50.0000 (51.0204)  Acc@5: 87.5000 (86.8752)  time: 0.3468  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3090/4579]  eta: 0:08:42  Lr: 0.001875  Loss: -0.4692  Acc@1: 62.5000 (51.0535)  Acc@5: 87.5000 (86.8813)  time: 0.3470  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3100/4579]  eta: 0:08:39  Lr: 0.001875  Loss: -0.4341  Acc@1: 62.5000 (51.0823)  Acc@5: 87.5000 (86.8913)  time: 0.3472  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [3110/4579]  eta: 0:08:35  Lr: 0.001875  Loss: 0.4200  Acc@1: 62.5000 (51.1070)  Acc@5: 87.5000 (86.8893)  time: 0.3453  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [3120/4579]  eta: 0:08:32  Lr: 0.001875  Loss: -0.4458  Acc@1: 62.5000 (51.1375)  Acc@5: 87.5000 (86.9153)  time: 0.3472  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [3130/4579]  eta: 0:08:28  Lr: 0.001875  Loss: -0.0268  Acc@1: 56.2500 (51.1498)  Acc@5: 93.7500 (86.9251)  time: 0.3557  data: 0.0013  max mem: 2500
Train: Epoch[1/5]  [3140/4579]  eta: 0:08:25  Lr: 0.001875  Loss: -0.1872  Acc@1: 50.0000 (51.1481)  Acc@5: 93.7500 (86.9269)  time: 0.3578  data: 0.0014  max mem: 2500
Train: Epoch[1/5]  [3150/4579]  eta: 0:08:21  Lr: 0.001875  Loss: 0.2983  Acc@1: 50.0000 (51.1504)  Acc@5: 87.5000 (86.9268)  time: 0.3534  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [3160/4579]  eta: 0:08:18  Lr: 0.001875  Loss: 0.0426  Acc@1: 56.2500 (51.1804)  Acc@5: 93.7500 (86.9424)  time: 0.3524  data: 0.0009  max mem: 2500
Train: Epoch[1/5]  [3170/4579]  eta: 0:08:14  Lr: 0.001875  Loss: 0.2451  Acc@1: 56.2500 (51.1846)  Acc@5: 87.5000 (86.9383)  time: 0.3544  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [3180/4579]  eta: 0:08:11  Lr: 0.001875  Loss: -0.2832  Acc@1: 56.2500 (51.2064)  Acc@5: 87.5000 (86.9459)  time: 0.3547  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [3190/4579]  eta: 0:08:07  Lr: 0.001875  Loss: 0.3101  Acc@1: 56.2500 (51.2281)  Acc@5: 87.5000 (86.9516)  time: 0.3495  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [3200/4579]  eta: 0:08:04  Lr: 0.001875  Loss: -0.4633  Acc@1: 56.2500 (51.2340)  Acc@5: 87.5000 (86.9494)  time: 0.3479  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [3210/4579]  eta: 0:08:00  Lr: 0.001875  Loss: 0.0472  Acc@1: 56.2500 (51.2632)  Acc@5: 87.5000 (86.9628)  time: 0.3516  data: 0.0013  max mem: 2500
Train: Epoch[1/5]  [3220/4579]  eta: 0:07:57  Lr: 0.001875  Loss: -0.2817  Acc@1: 68.7500 (51.3059)  Acc@5: 87.5000 (86.9703)  time: 0.3557  data: 0.0012  max mem: 2500
Train: Epoch[1/5]  [3230/4579]  eta: 0:07:53  Lr: 0.001875  Loss: -0.0765  Acc@1: 62.5000 (51.3386)  Acc@5: 93.7500 (86.9893)  time: 0.3531  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [3240/4579]  eta: 0:07:49  Lr: 0.001875  Loss: -0.2144  Acc@1: 62.5000 (51.3807)  Acc@5: 93.7500 (87.0140)  time: 0.3482  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3250/4579]  eta: 0:07:46  Lr: 0.001875  Loss: 0.1355  Acc@1: 62.5000 (51.4246)  Acc@5: 93.7500 (87.0348)  time: 0.3480  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3260/4579]  eta: 0:07:42  Lr: 0.001875  Loss: -0.1104  Acc@1: 62.5000 (51.4547)  Acc@5: 93.7500 (87.0458)  time: 0.3490  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [3270/4579]  eta: 0:07:39  Lr: 0.001875  Loss: -0.1464  Acc@1: 62.5000 (51.4751)  Acc@5: 93.7500 (87.0586)  time: 0.3504  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [3280/4579]  eta: 0:07:35  Lr: 0.001875  Loss: 0.2388  Acc@1: 56.2500 (51.4896)  Acc@5: 93.7500 (87.0638)  time: 0.3475  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [3290/4579]  eta: 0:07:32  Lr: 0.001875  Loss: -0.4294  Acc@1: 56.2500 (51.5098)  Acc@5: 87.5000 (87.0632)  time: 0.3451  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [3300/4579]  eta: 0:07:28  Lr: 0.001875  Loss: 0.3414  Acc@1: 56.2500 (51.5336)  Acc@5: 87.5000 (87.0797)  time: 0.3477  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [3310/4579]  eta: 0:07:25  Lr: 0.001875  Loss: -0.2039  Acc@1: 62.5000 (51.5611)  Acc@5: 93.7500 (87.0923)  time: 0.3480  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [3320/4579]  eta: 0:07:21  Lr: 0.001875  Loss: -0.1754  Acc@1: 62.5000 (51.5903)  Acc@5: 87.5000 (87.0935)  time: 0.3484  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [3330/4579]  eta: 0:07:18  Lr: 0.001875  Loss: -0.7661  Acc@1: 62.5000 (51.6380)  Acc@5: 93.7500 (87.1154)  time: 0.3503  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [3340/4579]  eta: 0:07:14  Lr: 0.001875  Loss: -0.2184  Acc@1: 62.5000 (51.6350)  Acc@5: 93.7500 (87.1259)  time: 0.3540  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [3350/4579]  eta: 0:07:11  Lr: 0.001875  Loss: -0.3319  Acc@1: 56.2500 (51.6693)  Acc@5: 87.5000 (87.1288)  time: 0.3553  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [3360/4579]  eta: 0:07:07  Lr: 0.001875  Loss: -0.5202  Acc@1: 56.2500 (51.6941)  Acc@5: 87.5000 (87.1374)  time: 0.3528  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [3370/4579]  eta: 0:07:04  Lr: 0.001875  Loss: -0.0083  Acc@1: 56.2500 (51.7168)  Acc@5: 87.5000 (87.1403)  time: 0.3518  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [3380/4579]  eta: 0:07:00  Lr: 0.001875  Loss: -0.1318  Acc@1: 56.2500 (51.7450)  Acc@5: 87.5000 (87.1432)  time: 0.3509  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [3390/4579]  eta: 0:06:57  Lr: 0.001875  Loss: -0.7090  Acc@1: 56.2500 (51.7639)  Acc@5: 87.5000 (87.1406)  time: 0.3536  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [3400/4579]  eta: 0:06:53  Lr: 0.001875  Loss: 0.3976  Acc@1: 56.2500 (51.7715)  Acc@5: 87.5000 (87.1564)  time: 0.3549  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [3410/4579]  eta: 0:06:50  Lr: 0.001875  Loss: -0.1129  Acc@1: 56.2500 (51.7938)  Acc@5: 87.5000 (87.1629)  time: 0.3497  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [3420/4579]  eta: 0:06:46  Lr: 0.001875  Loss: -0.2477  Acc@1: 56.2500 (51.8178)  Acc@5: 87.5000 (87.1693)  time: 0.3473  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3430/4579]  eta: 0:06:43  Lr: 0.001875  Loss: -0.6061  Acc@1: 62.5000 (51.8471)  Acc@5: 93.7500 (87.1867)  time: 0.3483  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [3440/4579]  eta: 0:06:39  Lr: 0.001875  Loss: -0.2326  Acc@1: 56.2500 (51.8545)  Acc@5: 93.7500 (87.1803)  time: 0.3486  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3450/4579]  eta: 0:06:36  Lr: 0.001875  Loss: 0.1814  Acc@1: 56.2500 (51.8708)  Acc@5: 87.5000 (87.1903)  time: 0.3485  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3460/4579]  eta: 0:06:32  Lr: 0.001875  Loss: -0.3189  Acc@1: 56.2500 (51.8745)  Acc@5: 93.7500 (87.2020)  time: 0.3476  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3470/4579]  eta: 0:06:29  Lr: 0.001875  Loss: 0.3125  Acc@1: 56.2500 (51.8979)  Acc@5: 93.7500 (87.2191)  time: 0.3462  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [3480/4579]  eta: 0:06:25  Lr: 0.001875  Loss: 0.1748  Acc@1: 50.0000 (51.8942)  Acc@5: 87.5000 (87.2109)  time: 0.3466  data: 0.0009  max mem: 2500
Train: Epoch[1/5]  [3490/4579]  eta: 0:06:22  Lr: 0.001875  Loss: -0.3279  Acc@1: 56.2500 (51.9103)  Acc@5: 87.5000 (87.2171)  time: 0.3460  data: 0.0010  max mem: 2500
Train: Epoch[1/5]  [3500/4579]  eta: 0:06:18  Lr: 0.001875  Loss: 0.0254  Acc@1: 56.2500 (51.9280)  Acc@5: 87.5000 (87.2197)  time: 0.3445  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3510/4579]  eta: 0:06:15  Lr: 0.001875  Loss: 0.0148  Acc@1: 56.2500 (51.9350)  Acc@5: 87.5000 (87.2294)  time: 0.3481  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3520/4579]  eta: 0:06:11  Lr: 0.001875  Loss: -0.0414  Acc@1: 56.2500 (51.9614)  Acc@5: 87.5000 (87.2391)  time: 0.3527  data: 0.0012  max mem: 2500
Train: Epoch[1/5]  [3530/4579]  eta: 0:06:08  Lr: 0.001875  Loss: -0.0095  Acc@1: 56.2500 (51.9824)  Acc@5: 93.7500 (87.2540)  time: 0.3530  data: 0.0013  max mem: 2500
Train: Epoch[1/5]  [3540/4579]  eta: 0:06:04  Lr: 0.001875  Loss: -0.3823  Acc@1: 56.2500 (51.9998)  Acc@5: 93.7500 (87.2670)  time: 0.3565  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [3550/4579]  eta: 0:06:01  Lr: 0.001875  Loss: 0.2901  Acc@1: 62.5000 (52.0241)  Acc@5: 93.7500 (87.2747)  time: 0.3561  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [3560/4579]  eta: 0:05:57  Lr: 0.001875  Loss: -0.0253  Acc@1: 56.2500 (52.0412)  Acc@5: 93.7500 (87.2841)  time: 0.3560  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [3570/4579]  eta: 0:05:54  Lr: 0.001875  Loss: 0.5706  Acc@1: 56.2500 (52.0565)  Acc@5: 93.7500 (87.2760)  time: 0.3581  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [3580/4579]  eta: 0:05:50  Lr: 0.001875  Loss: -0.2497  Acc@1: 56.2500 (52.0769)  Acc@5: 87.5000 (87.2818)  time: 0.3532  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [3590/4579]  eta: 0:05:47  Lr: 0.001875  Loss: -0.4508  Acc@1: 62.5000 (52.0938)  Acc@5: 93.7500 (87.2894)  time: 0.3527  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [3600/4579]  eta: 0:05:43  Lr: 0.001875  Loss: -0.0552  Acc@1: 56.2500 (52.1192)  Acc@5: 93.7500 (87.2969)  time: 0.3513  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3610/4579]  eta: 0:05:40  Lr: 0.001875  Loss: -0.1850  Acc@1: 56.2500 (52.1410)  Acc@5: 93.7500 (87.3148)  time: 0.3490  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [3620/4579]  eta: 0:05:36  Lr: 0.001875  Loss: 0.5137  Acc@1: 56.2500 (52.1437)  Acc@5: 93.7500 (87.3170)  time: 0.3493  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [3630/4579]  eta: 0:05:33  Lr: 0.001875  Loss: -0.0377  Acc@1: 56.2500 (52.1654)  Acc@5: 93.7500 (87.3365)  time: 0.3482  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3640/4579]  eta: 0:05:29  Lr: 0.001875  Loss: -0.1916  Acc@1: 62.5000 (52.1938)  Acc@5: 93.7500 (87.3421)  time: 0.3475  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3650/4579]  eta: 0:05:26  Lr: 0.001875  Loss: -0.2794  Acc@1: 62.5000 (52.2151)  Acc@5: 93.7500 (87.3562)  time: 0.3482  data: 0.0010  max mem: 2500
Train: Epoch[1/5]  [3660/4579]  eta: 0:05:22  Lr: 0.001875  Loss: -0.2621  Acc@1: 62.5000 (52.2484)  Acc@5: 93.7500 (87.3754)  time: 0.3471  data: 0.0009  max mem: 2500
Train: Epoch[1/5]  [3670/4579]  eta: 0:05:18  Lr: 0.001875  Loss: 0.9121  Acc@1: 62.5000 (52.2695)  Acc@5: 93.7500 (87.3842)  time: 0.3447  data: 0.0002  max mem: 2500
Train: Epoch[1/5]  [3680/4579]  eta: 0:05:15  Lr: 0.001875  Loss: -0.2496  Acc@1: 62.5000 (52.2973)  Acc@5: 93.7500 (87.4032)  time: 0.3452  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [3690/4579]  eta: 0:05:11  Lr: 0.001875  Loss: -0.3625  Acc@1: 62.5000 (52.3131)  Acc@5: 93.7500 (87.4103)  time: 0.3491  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [3700/4579]  eta: 0:05:08  Lr: 0.001875  Loss: 0.1695  Acc@1: 56.2500 (52.3321)  Acc@5: 87.5000 (87.4189)  time: 0.3518  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [3710/4579]  eta: 0:05:04  Lr: 0.001875  Loss: 0.0890  Acc@1: 56.2500 (52.3528)  Acc@5: 87.5000 (87.4259)  time: 0.3502  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [3720/4579]  eta: 0:05:01  Lr: 0.001875  Loss: -0.2571  Acc@1: 56.2500 (52.3532)  Acc@5: 87.5000 (87.4278)  time: 0.3503  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3730/4579]  eta: 0:04:57  Lr: 0.001875  Loss: 0.1297  Acc@1: 56.2500 (52.3703)  Acc@5: 93.7500 (87.4330)  time: 0.3536  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [3740/4579]  eta: 0:04:54  Lr: 0.001875  Loss: -0.0888  Acc@1: 62.5000 (52.3974)  Acc@5: 93.7500 (87.4482)  time: 0.3592  data: 0.0009  max mem: 2500
Train: Epoch[1/5]  [3750/4579]  eta: 0:04:50  Lr: 0.001875  Loss: 0.3352  Acc@1: 56.2500 (52.3994)  Acc@5: 87.5000 (87.4517)  time: 0.3565  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [3760/4579]  eta: 0:04:47  Lr: 0.001875  Loss: -0.0459  Acc@1: 56.2500 (52.4196)  Acc@5: 87.5000 (87.4634)  time: 0.3513  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [3770/4579]  eta: 0:04:43  Lr: 0.001875  Loss: -0.2641  Acc@1: 62.5000 (52.4330)  Acc@5: 93.7500 (87.4718)  time: 0.3525  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [3780/4579]  eta: 0:04:40  Lr: 0.001875  Loss: -0.0258  Acc@1: 62.5000 (52.4597)  Acc@5: 93.7500 (87.4884)  time: 0.3524  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3790/4579]  eta: 0:04:36  Lr: 0.001875  Loss: -0.0906  Acc@1: 62.5000 (52.4812)  Acc@5: 93.7500 (87.5033)  time: 0.3514  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3800/4579]  eta: 0:04:33  Lr: 0.001875  Loss: -0.2282  Acc@1: 56.2500 (52.5026)  Acc@5: 93.7500 (87.5082)  time: 0.3511  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3810/4579]  eta: 0:04:29  Lr: 0.001875  Loss: 0.3454  Acc@1: 56.2500 (52.5141)  Acc@5: 87.5000 (87.5131)  time: 0.3507  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [3820/4579]  eta: 0:04:26  Lr: 0.001875  Loss: -0.3598  Acc@1: 56.2500 (52.5157)  Acc@5: 93.7500 (87.5245)  time: 0.3511  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [3830/4579]  eta: 0:04:22  Lr: 0.001875  Loss: 0.0911  Acc@1: 56.2500 (52.5271)  Acc@5: 93.7500 (87.5359)  time: 0.3508  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [3840/4579]  eta: 0:04:19  Lr: 0.001875  Loss: -0.4311  Acc@1: 62.5000 (52.5530)  Acc@5: 87.5000 (87.5423)  time: 0.3465  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3850/4579]  eta: 0:04:15  Lr: 0.001875  Loss: 0.7160  Acc@1: 62.5000 (52.5659)  Acc@5: 87.5000 (87.5487)  time: 0.3444  data: 0.0002  max mem: 2500
Train: Epoch[1/5]  [3860/4579]  eta: 0:04:12  Lr: 0.001875  Loss: -0.4243  Acc@1: 56.2500 (52.5868)  Acc@5: 87.5000 (87.5502)  time: 0.3456  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [3870/4579]  eta: 0:04:08  Lr: 0.001875  Loss: -0.1055  Acc@1: 56.2500 (52.6011)  Acc@5: 87.5000 (87.5549)  time: 0.3467  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [3880/4579]  eta: 0:04:05  Lr: 0.001875  Loss: -0.1968  Acc@1: 56.2500 (52.6137)  Acc@5: 87.5000 (87.5612)  time: 0.3502  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3890/4579]  eta: 0:04:01  Lr: 0.001875  Loss: -0.1718  Acc@1: 50.0000 (52.6070)  Acc@5: 87.5000 (87.5626)  time: 0.3525  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [3900/4579]  eta: 0:03:58  Lr: 0.001875  Loss: -0.3238  Acc@1: 56.2500 (52.6291)  Acc@5: 93.7500 (87.5753)  time: 0.3512  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [3910/4579]  eta: 0:03:54  Lr: 0.001875  Loss: -0.1089  Acc@1: 62.5000 (52.6528)  Acc@5: 93.7500 (87.5815)  time: 0.3531  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [3920/4579]  eta: 0:03:51  Lr: 0.001875  Loss: -0.1116  Acc@1: 56.2500 (52.6540)  Acc@5: 87.5000 (87.5845)  time: 0.3550  data: 0.0011  max mem: 2500
Train: Epoch[1/5]  [3930/4579]  eta: 0:03:47  Lr: 0.001875  Loss: 0.1284  Acc@1: 56.2500 (52.6695)  Acc@5: 87.5000 (87.5843)  time: 0.3545  data: 0.0012  max mem: 2500
Train: Epoch[1/5]  [3940/4579]  eta: 0:03:44  Lr: 0.001875  Loss: -0.0516  Acc@1: 56.2500 (52.6881)  Acc@5: 93.7500 (87.6015)  time: 0.3530  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [3950/4579]  eta: 0:03:40  Lr: 0.001875  Loss: -0.7213  Acc@1: 56.2500 (52.6876)  Acc@5: 93.7500 (87.5965)  time: 0.3542  data: 0.0009  max mem: 2500
Train: Epoch[1/5]  [3960/4579]  eta: 0:03:37  Lr: 0.001875  Loss: -0.3100  Acc@1: 56.2500 (52.7203)  Acc@5: 87.5000 (87.6152)  time: 0.3537  data: 0.0009  max mem: 2500
Train: Epoch[1/5]  [3970/4579]  eta: 0:03:33  Lr: 0.001875  Loss: 0.0626  Acc@1: 62.5000 (52.7418)  Acc@5: 93.7500 (87.6212)  time: 0.3514  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [3980/4579]  eta: 0:03:30  Lr: 0.001875  Loss: 0.3960  Acc@1: 62.5000 (52.7694)  Acc@5: 93.7500 (87.6334)  time: 0.3492  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3990/4579]  eta: 0:03:26  Lr: 0.001875  Loss: 0.2330  Acc@1: 56.2500 (52.7766)  Acc@5: 93.7500 (87.6362)  time: 0.3483  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [4000/4579]  eta: 0:03:23  Lr: 0.001875  Loss: -0.1019  Acc@1: 56.2500 (52.7899)  Acc@5: 93.7500 (87.6484)  time: 0.3496  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [4010/4579]  eta: 0:03:19  Lr: 0.001875  Loss: 0.2428  Acc@1: 56.2500 (52.8141)  Acc@5: 87.5000 (87.6465)  time: 0.3486  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [4020/4579]  eta: 0:03:16  Lr: 0.001875  Loss: -0.3931  Acc@1: 62.5000 (52.8413)  Acc@5: 87.5000 (87.6632)  time: 0.3479  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [4030/4579]  eta: 0:03:12  Lr: 0.001875  Loss: -0.2937  Acc@1: 62.5000 (52.8575)  Acc@5: 93.7500 (87.6675)  time: 0.3469  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [4040/4579]  eta: 0:03:09  Lr: 0.001875  Loss: 0.5107  Acc@1: 62.5000 (52.8799)  Acc@5: 87.5000 (87.6670)  time: 0.3466  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [4050/4579]  eta: 0:03:05  Lr: 0.001875  Loss: 0.1969  Acc@1: 62.5000 (52.8928)  Acc@5: 87.5000 (87.6759)  time: 0.3475  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [4060/4579]  eta: 0:03:02  Lr: 0.001875  Loss: 0.3414  Acc@1: 56.2500 (52.9011)  Acc@5: 93.7500 (87.6801)  time: 0.3473  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [4070/4579]  eta: 0:02:58  Lr: 0.001875  Loss: -0.4151  Acc@1: 62.5000 (52.9231)  Acc@5: 87.5000 (87.6827)  time: 0.3470  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [4080/4579]  eta: 0:02:55  Lr: 0.001875  Loss: 0.3989  Acc@1: 62.5000 (52.9374)  Acc@5: 87.5000 (87.6822)  time: 0.3545  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [4090/4579]  eta: 0:02:51  Lr: 0.001875  Loss: -0.0781  Acc@1: 62.5000 (52.9531)  Acc@5: 87.5000 (87.6864)  time: 0.3560  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [4100/4579]  eta: 0:02:48  Lr: 0.001875  Loss: -0.2604  Acc@1: 62.5000 (52.9749)  Acc@5: 93.7500 (87.6966)  time: 0.3503  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [4110/4579]  eta: 0:02:44  Lr: 0.001875  Loss: -0.0104  Acc@1: 62.5000 (53.0057)  Acc@5: 87.5000 (87.6976)  time: 0.3536  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [4120/4579]  eta: 0:02:41  Lr: 0.001875  Loss: -0.2399  Acc@1: 62.5000 (53.0150)  Acc@5: 87.5000 (87.7063)  time: 0.3548  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [4130/4579]  eta: 0:02:37  Lr: 0.001875  Loss: -0.4538  Acc@1: 56.2500 (53.0410)  Acc@5: 93.7500 (87.7133)  time: 0.3561  data: 0.0009  max mem: 2500
Train: Epoch[1/5]  [4140/4579]  eta: 0:02:34  Lr: 0.001875  Loss: -0.4152  Acc@1: 62.5000 (53.0624)  Acc@5: 93.7500 (87.7249)  time: 0.3578  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [4150/4579]  eta: 0:02:30  Lr: 0.001875  Loss: 0.2361  Acc@1: 62.5000 (53.0851)  Acc@5: 93.7500 (87.7319)  time: 0.3535  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [4160/4579]  eta: 0:02:27  Lr: 0.001875  Loss: -0.3220  Acc@1: 62.5000 (53.1032)  Acc@5: 93.7500 (87.7358)  time: 0.3507  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [4170/4579]  eta: 0:02:23  Lr: 0.001875  Loss: 0.1456  Acc@1: 56.2500 (53.1063)  Acc@5: 87.5000 (87.7323)  time: 0.3545  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [4180/4579]  eta: 0:02:20  Lr: 0.001875  Loss: 0.1181  Acc@1: 56.2500 (53.1198)  Acc@5: 87.5000 (87.7392)  time: 0.3575  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [4190/4579]  eta: 0:02:16  Lr: 0.001875  Loss: 0.2143  Acc@1: 56.2500 (53.1332)  Acc@5: 87.5000 (87.7446)  time: 0.3517  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [4200/4579]  eta: 0:02:13  Lr: 0.001875  Loss: 0.0011  Acc@1: 56.2500 (53.1302)  Acc@5: 87.5000 (87.7455)  time: 0.3478  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [4210/4579]  eta: 0:02:09  Lr: 0.001875  Loss: 1.2293  Acc@1: 56.2500 (53.1450)  Acc@5: 87.5000 (87.7464)  time: 0.3482  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [4220/4579]  eta: 0:02:05  Lr: 0.001875  Loss: -0.1477  Acc@1: 62.5000 (53.1687)  Acc@5: 93.7500 (87.7562)  time: 0.3503  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [4230/4579]  eta: 0:02:02  Lr: 0.001875  Loss: -0.1776  Acc@1: 62.5000 (53.1774)  Acc@5: 93.7500 (87.7615)  time: 0.3500  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [4240/4579]  eta: 0:01:58  Lr: 0.001875  Loss: 0.1059  Acc@1: 62.5000 (53.2009)  Acc@5: 87.5000 (87.7638)  time: 0.3464  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [4250/4579]  eta: 0:01:55  Lr: 0.001875  Loss: 0.1653  Acc@1: 62.5000 (53.2125)  Acc@5: 87.5000 (87.7676)  time: 0.3458  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [4260/4579]  eta: 0:01:51  Lr: 0.001875  Loss: -0.4982  Acc@1: 62.5000 (53.2387)  Acc@5: 87.5000 (87.7699)  time: 0.3469  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [4270/4579]  eta: 0:01:48  Lr: 0.001875  Loss: -0.5379  Acc@1: 62.5000 (53.2648)  Acc@5: 93.7500 (87.7795)  time: 0.3469  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [4280/4579]  eta: 0:01:44  Lr: 0.001875  Loss: -0.3371  Acc@1: 68.7500 (53.2907)  Acc@5: 93.7500 (87.7964)  time: 0.3455  data: 0.0002  max mem: 2500
Train: Epoch[1/5]  [4290/4579]  eta: 0:01:41  Lr: 0.001875  Loss: -0.0334  Acc@1: 62.5000 (53.3020)  Acc@5: 93.7500 (87.8088)  time: 0.3476  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [4300/4579]  eta: 0:01:37  Lr: 0.001875  Loss: -0.6947  Acc@1: 62.5000 (53.3277)  Acc@5: 93.7500 (87.8197)  time: 0.3602  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [4310/4579]  eta: 0:01:34  Lr: 0.001875  Loss: -0.4609  Acc@1: 56.2500 (53.3417)  Acc@5: 87.5000 (87.8248)  time: 0.3600  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [4320/4579]  eta: 0:01:30  Lr: 0.001875  Loss: 0.3275  Acc@1: 56.2500 (53.3658)  Acc@5: 87.5000 (87.8283)  time: 0.3510  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [4330/4579]  eta: 0:01:27  Lr: 0.001875  Loss: 0.0474  Acc@1: 62.5000 (53.3956)  Acc@5: 93.7500 (87.8391)  time: 0.3515  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [4340/4579]  eta: 0:01:23  Lr: 0.001875  Loss: -0.5615  Acc@1: 62.5000 (53.4065)  Acc@5: 87.5000 (87.8398)  time: 0.3501  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [4350/4579]  eta: 0:01:20  Lr: 0.001875  Loss: 0.1189  Acc@1: 62.5000 (53.4317)  Acc@5: 93.7500 (87.8491)  time: 0.3525  data: 0.0011  max mem: 2500
Train: Epoch[1/5]  [4360/4579]  eta: 0:01:16  Lr: 0.001875  Loss: 0.1654  Acc@1: 62.5000 (53.4568)  Acc@5: 93.7500 (87.8569)  time: 0.3545  data: 0.0011  max mem: 2500
Train: Epoch[1/5]  [4370/4579]  eta: 0:01:13  Lr: 0.001875  Loss: -0.1633  Acc@1: 62.5000 (53.4689)  Acc@5: 87.5000 (87.8603)  time: 0.3516  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [4380/4579]  eta: 0:01:09  Lr: 0.001875  Loss: -0.3592  Acc@1: 56.2500 (53.4667)  Acc@5: 87.5000 (87.8567)  time: 0.3500  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [4390/4579]  eta: 0:01:06  Lr: 0.001875  Loss: -0.6811  Acc@1: 56.2500 (53.4844)  Acc@5: 87.5000 (87.8687)  time: 0.3493  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [4400/4579]  eta: 0:01:02  Lr: 0.001875  Loss: 0.0501  Acc@1: 62.5000 (53.5091)  Acc@5: 87.5000 (87.8721)  time: 0.3487  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [4410/4579]  eta: 0:00:59  Lr: 0.001875  Loss: 0.0250  Acc@1: 62.5000 (53.5295)  Acc@5: 87.5000 (87.8840)  time: 0.3487  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [4420/4579]  eta: 0:00:55  Lr: 0.001875  Loss: 0.0061  Acc@1: 68.7500 (53.5625)  Acc@5: 93.7500 (87.8902)  time: 0.3485  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [4430/4579]  eta: 0:00:52  Lr: 0.001875  Loss: 0.1567  Acc@1: 62.5000 (53.5644)  Acc@5: 93.7500 (87.9006)  time: 0.3491  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [4440/4579]  eta: 0:00:48  Lr: 0.001875  Loss: -0.2070  Acc@1: 56.2500 (53.5915)  Acc@5: 93.7500 (87.9025)  time: 0.3484  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [4450/4579]  eta: 0:00:45  Lr: 0.001875  Loss: 0.1258  Acc@1: 68.7500 (53.6200)  Acc@5: 93.7500 (87.9128)  time: 0.3474  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [4460/4579]  eta: 0:00:41  Lr: 0.001875  Loss: -0.2230  Acc@1: 62.5000 (53.6301)  Acc@5: 87.5000 (87.9049)  time: 0.3460  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [4470/4579]  eta: 0:00:38  Lr: 0.001875  Loss: -0.5536  Acc@1: 56.2500 (53.6317)  Acc@5: 93.7500 (87.9166)  time: 0.3459  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [4480/4579]  eta: 0:00:34  Lr: 0.001875  Loss: -0.4310  Acc@1: 56.2500 (53.6543)  Acc@5: 93.7500 (87.9282)  time: 0.3472  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [4490/4579]  eta: 0:00:31  Lr: 0.001875  Loss: -0.2717  Acc@1: 62.5000 (53.6698)  Acc@5: 93.7500 (87.9286)  time: 0.3513  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [4500/4579]  eta: 0:00:27  Lr: 0.001875  Loss: 0.0438  Acc@1: 56.2500 (53.6825)  Acc@5: 93.7500 (87.9332)  time: 0.3534  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [4510/4579]  eta: 0:00:24  Lr: 0.001875  Loss: -0.0938  Acc@1: 56.2500 (53.6937)  Acc@5: 93.7500 (87.9406)  time: 0.3508  data: 0.0011  max mem: 2500
Train: Epoch[1/5]  [4520/4579]  eta: 0:00:20  Lr: 0.001875  Loss: -0.1404  Acc@1: 62.5000 (53.7174)  Acc@5: 93.7500 (87.9493)  time: 0.3545  data: 0.0012  max mem: 2500
Train: Epoch[1/5]  [4530/4579]  eta: 0:00:17  Lr: 0.001875  Loss: 0.3367  Acc@1: 56.2500 (53.7174)  Acc@5: 93.7500 (87.9552)  time: 0.3561  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [4540/4579]  eta: 0:00:13  Lr: 0.001875  Loss: 0.1411  Acc@1: 56.2500 (53.7327)  Acc@5: 87.5000 (87.9569)  time: 0.3523  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [4550/4579]  eta: 0:00:10  Lr: 0.001875  Loss: -0.3921  Acc@1: 62.5000 (53.7629)  Acc@5: 87.5000 (87.9587)  time: 0.3492  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [4560/4579]  eta: 0:00:06  Lr: 0.001875  Loss: -0.2573  Acc@1: 62.5000 (53.7670)  Acc@5: 87.5000 (87.9577)  time: 0.3496  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [4570/4579]  eta: 0:00:03  Lr: 0.001875  Loss: 0.1779  Acc@1: 56.2500 (53.7916)  Acc@5: 93.7500 (87.9717)  time: 0.3538  data: 0.0014  max mem: 2500
Train: Epoch[1/5]  [4578/4579]  eta: 0:00:00  Lr: 0.001875  Loss: 1.1330  Acc@1: 56.2500 (53.7887)  Acc@5: 87.5000 (87.9698)  time: 0.3532  data: 0.0017  max mem: 2500
Train: Epoch[1/5] Total time: 0:26:47 (0.3511 s / it)
{0: {0: 73257, 1: 0, 2: 0, 3: 0, 4: 0}, 1: {0: 73257, 1: 0, 2: 0, 3: 0, 4: 0}, 2: {0: 73257, 1: 0, 2: 0, 3: 0, 4: 0}, 3: {0: 73257, 1: 0, 2: 0, 3: 0, 4: 0}, 4: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 5: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 6: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 7: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 8: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 9: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 10: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 11: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 12: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 13: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 14: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 15: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 16: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 17: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 18: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 19: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}}
Averaged stats: Lr: 0.001875  Loss: 1.1330  Acc@1: 56.2500 (53.7887)  Acc@5: 87.5000 (87.9698)
Train: Epoch[2/5]  [   0/4579]  eta: 1:27:07  Lr: 0.001875  Loss: -0.3868  Acc@1: 62.5000 (62.5000)  Acc@5: 100.0000 (100.0000)  time: 1.1416  data: 0.7934  max mem: 2500
Train: Epoch[2/5]  [  10/4579]  eta: 0:32:06  Lr: 0.001875  Loss: -0.3149  Acc@1: 62.5000 (63.0682)  Acc@5: 93.7500 (91.4773)  time: 0.4217  data: 0.0736  max mem: 2500
Train: Epoch[2/5]  [  20/4579]  eta: 0:29:19  Lr: 0.001875  Loss: -0.5466  Acc@1: 68.7500 (65.4762)  Acc@5: 93.7500 (91.9643)  time: 0.3482  data: 0.0010  max mem: 2500
Train: Epoch[2/5]  [  30/4579]  eta: 0:28:26  Lr: 0.001875  Loss: 0.2750  Acc@1: 62.5000 (63.3065)  Acc@5: 93.7500 (91.7339)  time: 0.3495  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [  40/4579]  eta: 0:27:54  Lr: 0.001875  Loss: 0.3206  Acc@1: 56.2500 (62.0427)  Acc@5: 87.5000 (90.7012)  time: 0.3510  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [  50/4579]  eta: 0:27:33  Lr: 0.001875  Loss: -0.1957  Acc@1: 56.2500 (62.1324)  Acc@5: 87.5000 (90.1961)  time: 0.3494  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [  60/4579]  eta: 0:27:14  Lr: 0.001875  Loss: -0.2589  Acc@1: 62.5000 (62.0902)  Acc@5: 87.5000 (90.4713)  time: 0.3471  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [  70/4579]  eta: 0:27:01  Lr: 0.001875  Loss: -0.2427  Acc@1: 62.5000 (61.6197)  Acc@5: 93.7500 (90.0528)  time: 0.3456  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [  80/4579]  eta: 0:26:50  Lr: 0.001875  Loss: 0.7646  Acc@1: 56.2500 (61.1111)  Acc@5: 87.5000 (89.8920)  time: 0.3466  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [  90/4579]  eta: 0:26:41  Lr: 0.001875  Loss: 0.0367  Acc@1: 62.5000 (61.4011)  Acc@5: 87.5000 (90.1786)  time: 0.3468  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 100/4579]  eta: 0:26:32  Lr: 0.001875  Loss: -0.3504  Acc@1: 62.5000 (61.6955)  Acc@5: 93.7500 (90.4084)  time: 0.3454  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [ 110/4579]  eta: 0:26:26  Lr: 0.001875  Loss: -0.0737  Acc@1: 62.5000 (61.5991)  Acc@5: 93.7500 (90.2590)  time: 0.3473  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 120/4579]  eta: 0:26:23  Lr: 0.001875  Loss: 0.4587  Acc@1: 56.2500 (61.1570)  Acc@5: 87.5000 (90.0826)  time: 0.3527  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [ 130/4579]  eta: 0:26:18  Lr: 0.001875  Loss: -0.1507  Acc@1: 56.2500 (61.1164)  Acc@5: 93.7500 (89.9809)  time: 0.3531  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [ 140/4579]  eta: 0:26:14  Lr: 0.001875  Loss: -0.3378  Acc@1: 56.2500 (60.7270)  Acc@5: 93.7500 (89.8493)  time: 0.3529  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [ 150/4579]  eta: 0:26:09  Lr: 0.001875  Loss: -0.3132  Acc@1: 56.2500 (60.7202)  Acc@5: 93.7500 (90.1490)  time: 0.3520  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [ 160/4579]  eta: 0:26:05  Lr: 0.001875  Loss: 0.0917  Acc@1: 56.2500 (60.3649)  Acc@5: 93.7500 (90.4115)  time: 0.3511  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [ 170/4579]  eta: 0:26:02  Lr: 0.001875  Loss: -0.0631  Acc@1: 50.0000 (59.9415)  Acc@5: 93.7500 (90.3874)  time: 0.3550  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [ 180/4579]  eta: 0:25:58  Lr: 0.001875  Loss: 0.4049  Acc@1: 56.2500 (60.0138)  Acc@5: 93.7500 (90.4351)  time: 0.3553  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [ 190/4579]  eta: 0:25:55  Lr: 0.001875  Loss: -0.1188  Acc@1: 62.5000 (60.1113)  Acc@5: 87.5000 (90.3796)  time: 0.3531  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [ 200/4579]  eta: 0:25:50  Lr: 0.001875  Loss: -0.2890  Acc@1: 62.5000 (60.1057)  Acc@5: 87.5000 (90.4229)  time: 0.3513  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [ 210/4579]  eta: 0:25:46  Lr: 0.001875  Loss: -0.0787  Acc@1: 62.5000 (60.4858)  Acc@5: 87.5000 (90.3732)  time: 0.3495  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [ 220/4579]  eta: 0:25:42  Lr: 0.001875  Loss: 0.0593  Acc@1: 62.5000 (60.5204)  Acc@5: 87.5000 (90.4695)  time: 0.3510  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [ 230/4579]  eta: 0:25:37  Lr: 0.001875  Loss: -0.3037  Acc@1: 62.5000 (60.6602)  Acc@5: 93.7500 (90.6385)  time: 0.3502  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 240/4579]  eta: 0:25:33  Lr: 0.001875  Loss: -0.4715  Acc@1: 62.5000 (61.0737)  Acc@5: 93.7500 (90.7158)  time: 0.3479  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 250/4579]  eta: 0:25:28  Lr: 0.001875  Loss: 0.2079  Acc@1: 62.5000 (61.1554)  Acc@5: 93.7500 (90.7620)  time: 0.3481  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [ 260/4579]  eta: 0:25:24  Lr: 0.001875  Loss: -0.3129  Acc@1: 62.5000 (61.4224)  Acc@5: 93.7500 (90.8046)  time: 0.3496  data: 0.0009  max mem: 2500
Train: Epoch[2/5]  [ 270/4579]  eta: 0:25:19  Lr: 0.001875  Loss: -0.2338  Acc@1: 62.5000 (61.3699)  Acc@5: 87.5000 (90.7980)  time: 0.3479  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [ 280/4579]  eta: 0:25:15  Lr: 0.001875  Loss: -0.0598  Acc@1: 62.5000 (61.6326)  Acc@5: 93.7500 (90.7696)  time: 0.3444  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [ 290/4579]  eta: 0:25:10  Lr: 0.001875  Loss: -0.1110  Acc@1: 62.5000 (61.5765)  Acc@5: 93.7500 (90.7002)  time: 0.3455  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [ 300/4579]  eta: 0:25:08  Lr: 0.001875  Loss: -0.3397  Acc@1: 62.5000 (61.6694)  Acc@5: 93.7500 (90.7392)  time: 0.3533  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [ 310/4579]  eta: 0:25:04  Lr: 0.001875  Loss: -0.1127  Acc@1: 68.7500 (61.8770)  Acc@5: 93.7500 (90.7556)  time: 0.3548  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 320/4579]  eta: 0:25:00  Lr: 0.001875  Loss: -0.0177  Acc@1: 62.5000 (61.6238)  Acc@5: 93.7500 (90.8489)  time: 0.3495  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 330/4579]  eta: 0:24:57  Lr: 0.001875  Loss: -0.2116  Acc@1: 56.2500 (61.6314)  Acc@5: 93.7500 (90.7289)  time: 0.3526  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [ 340/4579]  eta: 0:24:54  Lr: 0.001875  Loss: -0.0104  Acc@1: 56.2500 (61.4553)  Acc@5: 87.5000 (90.6525)  time: 0.3571  data: 0.0012  max mem: 2500
Train: Epoch[2/5]  [ 350/4579]  eta: 0:24:51  Lr: 0.001875  Loss: -0.1167  Acc@1: 56.2500 (61.3960)  Acc@5: 93.7500 (90.7764)  time: 0.3583  data: 0.0009  max mem: 2500
Train: Epoch[2/5]  [ 360/4579]  eta: 0:24:47  Lr: 0.001875  Loss: 0.2822  Acc@1: 56.2500 (61.3573)  Acc@5: 93.7500 (90.7895)  time: 0.3541  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [ 370/4579]  eta: 0:24:44  Lr: 0.001875  Loss: 0.1662  Acc@1: 56.2500 (61.3713)  Acc@5: 93.7500 (90.7682)  time: 0.3504  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [ 380/4579]  eta: 0:24:40  Lr: 0.001875  Loss: 0.2192  Acc@1: 56.2500 (61.2861)  Acc@5: 93.7500 (90.7972)  time: 0.3498  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 390/4579]  eta: 0:24:37  Lr: 0.001875  Loss: 0.1993  Acc@1: 56.2500 (61.2052)  Acc@5: 87.5000 (90.7129)  time: 0.3549  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 400/4579]  eta: 0:24:34  Lr: 0.001875  Loss: -0.7686  Acc@1: 62.5000 (61.2219)  Acc@5: 93.7500 (90.8042)  time: 0.3565  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [ 410/4579]  eta: 0:24:29  Lr: 0.001875  Loss: -0.3659  Acc@1: 62.5000 (61.3595)  Acc@5: 93.7500 (90.8151)  time: 0.3497  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [ 420/4579]  eta: 0:24:25  Lr: 0.001875  Loss: -0.2225  Acc@1: 62.5000 (61.3717)  Acc@5: 87.5000 (90.7067)  time: 0.3478  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 430/4579]  eta: 0:24:22  Lr: 0.001875  Loss: -0.0370  Acc@1: 62.5000 (61.2964)  Acc@5: 87.5000 (90.7338)  time: 0.3495  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 440/4579]  eta: 0:24:18  Lr: 0.001875  Loss: -0.2437  Acc@1: 62.5000 (61.4229)  Acc@5: 93.7500 (90.7880)  time: 0.3498  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 450/4579]  eta: 0:24:14  Lr: 0.001875  Loss: -0.1318  Acc@1: 62.5000 (61.3636)  Acc@5: 87.5000 (90.6458)  time: 0.3466  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 460/4579]  eta: 0:24:09  Lr: 0.001875  Loss: -0.3505  Acc@1: 62.5000 (61.4018)  Acc@5: 87.5000 (90.6725)  time: 0.3445  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 470/4579]  eta: 0:24:06  Lr: 0.001875  Loss: 0.5834  Acc@1: 62.5000 (61.4119)  Acc@5: 93.7500 (90.6184)  time: 0.3473  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [ 480/4579]  eta: 0:24:02  Lr: 0.001875  Loss: -0.7339  Acc@1: 62.5000 (61.4475)  Acc@5: 87.5000 (90.6705)  time: 0.3494  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [ 490/4579]  eta: 0:23:58  Lr: 0.001875  Loss: -0.1489  Acc@1: 62.5000 (61.4817)  Acc@5: 93.7500 (90.7332)  time: 0.3495  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [ 500/4579]  eta: 0:23:55  Lr: 0.001875  Loss: -0.2699  Acc@1: 56.2500 (61.3897)  Acc@5: 93.7500 (90.7186)  time: 0.3510  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [ 510/4579]  eta: 0:23:52  Lr: 0.001875  Loss: 0.0315  Acc@1: 56.2500 (61.3136)  Acc@5: 87.5000 (90.7045)  time: 0.3557  data: 0.0010  max mem: 2500
Train: Epoch[2/5]  [ 520/4579]  eta: 0:23:49  Lr: 0.001875  Loss: 0.3083  Acc@1: 56.2500 (61.3364)  Acc@5: 87.5000 (90.6430)  time: 0.3574  data: 0.0014  max mem: 2500
Train: Epoch[2/5]  [ 530/4579]  eta: 0:23:45  Lr: 0.001875  Loss: 0.3278  Acc@1: 62.5000 (61.2759)  Acc@5: 81.2500 (90.5250)  time: 0.3545  data: 0.0011  max mem: 2500
Train: Epoch[2/5]  [ 540/4579]  eta: 0:23:42  Lr: 0.001875  Loss: -0.2701  Acc@1: 62.5000 (61.2754)  Acc@5: 87.5000 (90.5037)  time: 0.3527  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [ 550/4579]  eta: 0:23:38  Lr: 0.001875  Loss: -0.5292  Acc@1: 62.5000 (61.3544)  Acc@5: 93.7500 (90.5399)  time: 0.3517  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [ 560/4579]  eta: 0:23:35  Lr: 0.001875  Loss: 0.2221  Acc@1: 56.2500 (61.1854)  Acc@5: 93.7500 (90.5414)  time: 0.3520  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [ 570/4579]  eta: 0:23:31  Lr: 0.001875  Loss: -0.0813  Acc@1: 56.2500 (61.2303)  Acc@5: 93.7500 (90.5429)  time: 0.3505  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [ 580/4579]  eta: 0:23:27  Lr: 0.001875  Loss: 0.0905  Acc@1: 62.5000 (61.1876)  Acc@5: 93.7500 (90.5336)  time: 0.3481  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 590/4579]  eta: 0:23:23  Lr: 0.001875  Loss: -0.0523  Acc@1: 56.2500 (61.1146)  Acc@5: 93.7500 (90.5457)  time: 0.3485  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [ 600/4579]  eta: 0:23:20  Lr: 0.001875  Loss: 0.4327  Acc@1: 62.5000 (61.1585)  Acc@5: 93.7500 (90.5574)  time: 0.3492  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 610/4579]  eta: 0:23:16  Lr: 0.001875  Loss: -0.8229  Acc@1: 62.5000 (61.3032)  Acc@5: 93.7500 (90.5790)  time: 0.3506  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [ 620/4579]  eta: 0:23:12  Lr: 0.001875  Loss: 0.1403  Acc@1: 62.5000 (61.4030)  Acc@5: 93.7500 (90.6502)  time: 0.3482  data: 0.0002  max mem: 2500
Train: Epoch[2/5]  [ 630/4579]  eta: 0:23:08  Lr: 0.001875  Loss: -0.3993  Acc@1: 62.5000 (61.3708)  Acc@5: 93.7500 (90.6894)  time: 0.3448  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [ 640/4579]  eta: 0:23:05  Lr: 0.001875  Loss: -0.4985  Acc@1: 62.5000 (61.3787)  Acc@5: 93.7500 (90.6884)  time: 0.3487  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [ 650/4579]  eta: 0:23:01  Lr: 0.001875  Loss: -0.0043  Acc@1: 56.2500 (61.3863)  Acc@5: 93.7500 (90.7162)  time: 0.3495  data: 0.0010  max mem: 2500
Train: Epoch[2/5]  [ 660/4579]  eta: 0:22:57  Lr: 0.001875  Loss: 0.4858  Acc@1: 56.2500 (61.2897)  Acc@5: 87.5000 (90.6581)  time: 0.3492  data: 0.0010  max mem: 2500
Train: Epoch[2/5]  [ 670/4579]  eta: 0:22:54  Lr: 0.001875  Loss: -0.0354  Acc@1: 62.5000 (61.4009)  Acc@5: 87.5000 (90.6669)  time: 0.3522  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [ 680/4579]  eta: 0:22:50  Lr: 0.001875  Loss: -0.4829  Acc@1: 62.5000 (61.4813)  Acc@5: 93.7500 (90.7122)  time: 0.3524  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [ 690/4579]  eta: 0:22:48  Lr: 0.001875  Loss: -0.8489  Acc@1: 68.7500 (61.6136)  Acc@5: 93.7500 (90.7742)  time: 0.3572  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [ 700/4579]  eta: 0:22:44  Lr: 0.001875  Loss: -0.4587  Acc@1: 68.7500 (61.7065)  Acc@5: 93.7500 (90.7810)  time: 0.3574  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [ 710/4579]  eta: 0:22:40  Lr: 0.001875  Loss: 0.3318  Acc@1: 68.7500 (61.7704)  Acc@5: 93.7500 (90.8052)  time: 0.3511  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [ 720/4579]  eta: 0:22:37  Lr: 0.001875  Loss: -0.1763  Acc@1: 62.5000 (61.7112)  Acc@5: 93.7500 (90.8200)  time: 0.3500  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [ 730/4579]  eta: 0:22:34  Lr: 0.001875  Loss: 0.0136  Acc@1: 56.2500 (61.6621)  Acc@5: 87.5000 (90.7917)  time: 0.3553  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [ 740/4579]  eta: 0:22:30  Lr: 0.001875  Loss: -0.7019  Acc@1: 56.2500 (61.6059)  Acc@5: 87.5000 (90.7979)  time: 0.3575  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [ 750/4579]  eta: 0:22:27  Lr: 0.001875  Loss: 0.1860  Acc@1: 56.2500 (61.5596)  Acc@5: 87.5000 (90.7623)  time: 0.3521  data: 0.0016  max mem: 2500
Train: Epoch[2/5]  [ 760/4579]  eta: 0:22:23  Lr: 0.001875  Loss: -0.7018  Acc@1: 62.5000 (61.5391)  Acc@5: 87.5000 (90.7523)  time: 0.3486  data: 0.0016  max mem: 2500
Train: Epoch[2/5]  [ 770/4579]  eta: 0:22:19  Lr: 0.001875  Loss: 0.6220  Acc@1: 62.5000 (61.5191)  Acc@5: 87.5000 (90.7182)  time: 0.3480  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 780/4579]  eta: 0:22:16  Lr: 0.001875  Loss: -0.0726  Acc@1: 56.2500 (61.4757)  Acc@5: 87.5000 (90.7170)  time: 0.3492  data: 0.0009  max mem: 2500
Train: Epoch[2/5]  [ 790/4579]  eta: 0:22:12  Lr: 0.001875  Loss: -0.2021  Acc@1: 62.5000 (61.4807)  Acc@5: 87.5000 (90.6843)  time: 0.3497  data: 0.0009  max mem: 2500
Train: Epoch[2/5]  [ 800/4579]  eta: 0:22:08  Lr: 0.001875  Loss: -0.5246  Acc@1: 62.5000 (61.4622)  Acc@5: 93.7500 (90.7459)  time: 0.3479  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 810/4579]  eta: 0:22:05  Lr: 0.001875  Loss: 0.0098  Acc@1: 56.2500 (61.3748)  Acc@5: 93.7500 (90.7059)  time: 0.3465  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [ 820/4579]  eta: 0:22:01  Lr: 0.001875  Loss: -0.4751  Acc@1: 68.7500 (61.4571)  Acc@5: 93.7500 (90.7582)  time: 0.3474  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 830/4579]  eta: 0:21:57  Lr: 0.001875  Loss: -0.0289  Acc@1: 62.5000 (61.4471)  Acc@5: 93.7500 (90.7040)  time: 0.3468  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [ 840/4579]  eta: 0:21:53  Lr: 0.001875  Loss: 0.3614  Acc@1: 62.5000 (61.4596)  Acc@5: 87.5000 (90.6807)  time: 0.3453  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [ 850/4579]  eta: 0:21:50  Lr: 0.001875  Loss: 0.3491  Acc@1: 56.2500 (61.4645)  Acc@5: 93.7500 (90.6580)  time: 0.3483  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [ 860/4579]  eta: 0:21:47  Lr: 0.001875  Loss: -0.0522  Acc@1: 62.5000 (61.4692)  Acc@5: 87.5000 (90.6286)  time: 0.3544  data: 0.0016  max mem: 2500
Train: Epoch[2/5]  [ 870/4579]  eta: 0:21:43  Lr: 0.001875  Loss: -0.0554  Acc@1: 62.5000 (61.4811)  Acc@5: 87.5000 (90.5712)  time: 0.3528  data: 0.0012  max mem: 2500
Train: Epoch[2/5]  [ 880/4579]  eta: 0:21:40  Lr: 0.001875  Loss: 0.0057  Acc@1: 62.5000 (61.5068)  Acc@5: 87.5000 (90.5931)  time: 0.3526  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [ 890/4579]  eta: 0:21:36  Lr: 0.001875  Loss: 0.0431  Acc@1: 56.2500 (61.4268)  Acc@5: 93.7500 (90.5864)  time: 0.3536  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [ 900/4579]  eta: 0:21:33  Lr: 0.001875  Loss: -0.2213  Acc@1: 56.2500 (61.4248)  Acc@5: 93.7500 (90.5799)  time: 0.3518  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [ 910/4579]  eta: 0:21:29  Lr: 0.001875  Loss: -0.1854  Acc@1: 56.2500 (61.4366)  Acc@5: 87.5000 (90.5530)  time: 0.3560  data: 0.0015  max mem: 2500
Train: Epoch[2/5]  [ 920/4579]  eta: 0:21:26  Lr: 0.001875  Loss: -0.1295  Acc@1: 62.5000 (61.4685)  Acc@5: 93.7500 (90.6148)  time: 0.3542  data: 0.0015  max mem: 2500
Train: Epoch[2/5]  [ 930/4579]  eta: 0:21:22  Lr: 0.001875  Loss: 0.0112  Acc@1: 56.2500 (61.4527)  Acc@5: 93.7500 (90.6149)  time: 0.3506  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [ 940/4579]  eta: 0:21:19  Lr: 0.001875  Loss: 0.3825  Acc@1: 56.2500 (61.4772)  Acc@5: 87.5000 (90.6018)  time: 0.3496  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 950/4579]  eta: 0:21:15  Lr: 0.001875  Loss: -0.4177  Acc@1: 62.5000 (61.5602)  Acc@5: 87.5000 (90.6151)  time: 0.3489  data: 0.0011  max mem: 2500
Train: Epoch[2/5]  [ 960/4579]  eta: 0:21:11  Lr: 0.001875  Loss: 0.0409  Acc@1: 62.5000 (61.5895)  Acc@5: 93.7500 (90.6478)  time: 0.3494  data: 0.0016  max mem: 2500
Train: Epoch[2/5]  [ 970/4579]  eta: 0:21:08  Lr: 0.001875  Loss: -0.6119  Acc@1: 62.5000 (61.5731)  Acc@5: 93.7500 (90.6411)  time: 0.3481  data: 0.0009  max mem: 2500
Train: Epoch[2/5]  [ 980/4579]  eta: 0:21:04  Lr: 0.001875  Loss: -0.0712  Acc@1: 62.5000 (61.6144)  Acc@5: 93.7500 (90.6664)  time: 0.3477  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 990/4579]  eta: 0:21:00  Lr: 0.001875  Loss: 0.6775  Acc@1: 62.5000 (61.5729)  Acc@5: 93.7500 (90.6471)  time: 0.3477  data: 0.0011  max mem: 2500
Train: Epoch[2/5]  [1000/4579]  eta: 0:20:57  Lr: 0.001875  Loss: 0.4926  Acc@1: 56.2500 (61.5447)  Acc@5: 87.5000 (90.6219)  time: 0.3474  data: 0.0011  max mem: 2500
Train: Epoch[2/5]  [1010/4579]  eta: 0:20:53  Lr: 0.001875  Loss: -0.3569  Acc@1: 68.7500 (61.5851)  Acc@5: 93.7500 (90.6466)  time: 0.3458  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [1020/4579]  eta: 0:20:49  Lr: 0.001875  Loss: -0.1743  Acc@1: 62.5000 (61.5818)  Acc@5: 93.7500 (90.6587)  time: 0.3445  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [1030/4579]  eta: 0:20:46  Lr: 0.001875  Loss: -0.4285  Acc@1: 62.5000 (61.5968)  Acc@5: 87.5000 (90.6523)  time: 0.3510  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [1040/4579]  eta: 0:20:43  Lr: 0.001875  Loss: -0.2137  Acc@1: 62.5000 (61.6535)  Acc@5: 93.7500 (90.6700)  time: 0.3554  data: 0.0010  max mem: 2500
Train: Epoch[2/5]  [1050/4579]  eta: 0:20:39  Lr: 0.001875  Loss: 0.2819  Acc@1: 62.5000 (61.6437)  Acc@5: 93.7500 (90.6755)  time: 0.3520  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [1060/4579]  eta: 0:20:36  Lr: 0.001875  Loss: -0.3859  Acc@1: 56.2500 (61.6223)  Acc@5: 93.7500 (90.6810)  time: 0.3511  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1070/4579]  eta: 0:20:32  Lr: 0.001875  Loss: 0.2458  Acc@1: 56.2500 (61.5955)  Acc@5: 93.7500 (90.6979)  time: 0.3534  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [1080/4579]  eta: 0:20:29  Lr: 0.001875  Loss: 0.0772  Acc@1: 56.2500 (61.5634)  Acc@5: 93.7500 (90.6915)  time: 0.3586  data: 0.0016  max mem: 2500
Train: Epoch[2/5]  [1090/4579]  eta: 0:20:26  Lr: 0.001875  Loss: -0.0986  Acc@1: 56.2500 (61.5834)  Acc@5: 93.7500 (90.6852)  time: 0.3579  data: 0.0014  max mem: 2500
Train: Epoch[2/5]  [1100/4579]  eta: 0:20:22  Lr: 0.001875  Loss: -0.0740  Acc@1: 62.5000 (61.6655)  Acc@5: 87.5000 (90.6676)  time: 0.3527  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [1110/4579]  eta: 0:20:18  Lr: 0.001875  Loss: -0.4724  Acc@1: 75.0000 (61.7631)  Acc@5: 93.7500 (90.6841)  time: 0.3497  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1120/4579]  eta: 0:20:15  Lr: 0.001875  Loss: -0.2753  Acc@1: 68.7500 (61.7362)  Acc@5: 93.7500 (90.6668)  time: 0.3519  data: 0.0009  max mem: 2500
Train: Epoch[2/5]  [1130/4579]  eta: 0:20:12  Lr: 0.001875  Loss: 0.2862  Acc@1: 56.2500 (61.7319)  Acc@5: 87.5000 (90.6333)  time: 0.3567  data: 0.0009  max mem: 2500
Train: Epoch[2/5]  [1140/4579]  eta: 0:20:08  Lr: 0.001875  Loss: -0.2876  Acc@1: 62.5000 (61.7441)  Acc@5: 87.5000 (90.6496)  time: 0.3518  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1150/4579]  eta: 0:20:04  Lr: 0.001875  Loss: -0.0001  Acc@1: 62.5000 (61.7507)  Acc@5: 93.7500 (90.6223)  time: 0.3474  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [1160/4579]  eta: 0:20:01  Lr: 0.001875  Loss: 0.1008  Acc@1: 62.5000 (61.7410)  Acc@5: 93.7500 (90.6385)  time: 0.3481  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1170/4579]  eta: 0:19:57  Lr: 0.001875  Loss: 0.0820  Acc@1: 56.2500 (61.7314)  Acc@5: 87.5000 (90.6437)  time: 0.3495  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [1180/4579]  eta: 0:19:54  Lr: 0.001875  Loss: 0.0365  Acc@1: 56.2500 (61.7115)  Acc@5: 87.5000 (90.6488)  time: 0.3501  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [1190/4579]  eta: 0:19:50  Lr: 0.001875  Loss: -0.0619  Acc@1: 68.7500 (61.8021)  Acc@5: 93.7500 (90.6486)  time: 0.3474  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1200/4579]  eta: 0:19:46  Lr: 0.001875  Loss: 0.4974  Acc@1: 62.5000 (61.7662)  Acc@5: 87.5000 (90.6172)  time: 0.3463  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1210/4579]  eta: 0:19:43  Lr: 0.001875  Loss: -0.1218  Acc@1: 62.5000 (61.7413)  Acc@5: 87.5000 (90.6327)  time: 0.3474  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1220/4579]  eta: 0:19:39  Lr: 0.001875  Loss: 0.1439  Acc@1: 56.2500 (61.6708)  Acc@5: 93.7500 (90.6634)  time: 0.3462  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [1230/4579]  eta: 0:19:36  Lr: 0.001875  Loss: -0.6037  Acc@1: 56.2500 (61.6724)  Acc@5: 93.7500 (90.6732)  time: 0.3465  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [1240/4579]  eta: 0:19:32  Lr: 0.001875  Loss: -0.2174  Acc@1: 68.7500 (61.7194)  Acc@5: 93.7500 (90.6880)  time: 0.3494  data: 0.0009  max mem: 2500
Train: Epoch[2/5]  [1250/4579]  eta: 0:19:29  Lr: 0.001875  Loss: -0.2332  Acc@1: 68.7500 (61.7256)  Acc@5: 93.7500 (90.7074)  time: 0.3534  data: 0.0018  max mem: 2500
Train: Epoch[2/5]  [1260/4579]  eta: 0:19:25  Lr: 0.001875  Loss: 0.4161  Acc@1: 62.5000 (61.6971)  Acc@5: 93.7500 (90.6870)  time: 0.3545  data: 0.0021  max mem: 2500
Train: Epoch[2/5]  [1270/4579]  eta: 0:19:22  Lr: 0.001875  Loss: 0.1944  Acc@1: 56.2500 (61.6739)  Acc@5: 87.5000 (90.6815)  time: 0.3512  data: 0.0013  max mem: 2500
Train: Epoch[2/5]  [1280/4579]  eta: 0:19:18  Lr: 0.001875  Loss: -0.2378  Acc@1: 56.2500 (61.6315)  Acc@5: 93.7500 (90.6811)  time: 0.3502  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [1290/4579]  eta: 0:19:15  Lr: 0.001875  Loss: -0.3815  Acc@1: 62.5000 (61.7157)  Acc@5: 93.7500 (90.7000)  time: 0.3541  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [1300/4579]  eta: 0:19:11  Lr: 0.001875  Loss: -0.5210  Acc@1: 68.7500 (61.7794)  Acc@5: 100.0000 (90.7475)  time: 0.3555  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [1310/4579]  eta: 0:19:08  Lr: 0.001875  Loss: 0.0252  Acc@1: 62.5000 (61.7611)  Acc@5: 93.7500 (90.7561)  time: 0.3530  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [1320/4579]  eta: 0:19:04  Lr: 0.001875  Loss: 0.1914  Acc@1: 62.5000 (61.8092)  Acc@5: 93.7500 (90.7504)  time: 0.3503  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1330/4579]  eta: 0:19:01  Lr: 0.001875  Loss: 0.2299  Acc@1: 62.5000 (61.7722)  Acc@5: 93.7500 (90.7447)  time: 0.3477  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1340/4579]  eta: 0:18:57  Lr: 0.001875  Loss: 0.2731  Acc@1: 62.5000 (61.8056)  Acc@5: 93.7500 (90.7392)  time: 0.3507  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [1350/4579]  eta: 0:18:54  Lr: 0.001875  Loss: 0.0933  Acc@1: 62.5000 (61.8014)  Acc@5: 93.7500 (90.7430)  time: 0.3509  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [1360/4579]  eta: 0:18:50  Lr: 0.001875  Loss: -0.6595  Acc@1: 56.2500 (61.8158)  Acc@5: 93.7500 (90.7513)  time: 0.3482  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1370/4579]  eta: 0:18:46  Lr: 0.001875  Loss: 0.1331  Acc@1: 56.2500 (61.8071)  Acc@5: 87.5000 (90.7276)  time: 0.3472  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [1380/4579]  eta: 0:18:43  Lr: 0.001875  Loss: 0.0267  Acc@1: 62.5000 (61.7985)  Acc@5: 87.5000 (90.7404)  time: 0.3456  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [1390/4579]  eta: 0:18:39  Lr: 0.001875  Loss: 0.4138  Acc@1: 62.5000 (61.8215)  Acc@5: 93.7500 (90.7620)  time: 0.3462  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [1400/4579]  eta: 0:18:35  Lr: 0.001875  Loss: -0.2584  Acc@1: 62.5000 (61.8130)  Acc@5: 93.7500 (90.7566)  time: 0.3456  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [1410/4579]  eta: 0:18:32  Lr: 0.001875  Loss: 0.3952  Acc@1: 62.5000 (61.8134)  Acc@5: 87.5000 (90.7424)  time: 0.3446  data: 0.0002  max mem: 2500
Train: Epoch[2/5]  [1420/4579]  eta: 0:18:28  Lr: 0.001875  Loss: 0.1265  Acc@1: 62.5000 (61.8183)  Acc@5: 93.7500 (90.7723)  time: 0.3469  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [1430/4579]  eta: 0:18:25  Lr: 0.001875  Loss: 0.3713  Acc@1: 56.2500 (61.7925)  Acc@5: 93.7500 (90.7800)  time: 0.3482  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1440/4579]  eta: 0:18:21  Lr: 0.001875  Loss: 0.0288  Acc@1: 56.2500 (61.7974)  Acc@5: 93.7500 (90.7746)  time: 0.3471  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1450/4579]  eta: 0:18:17  Lr: 0.001875  Loss: -0.2739  Acc@1: 56.2500 (61.7333)  Acc@5: 87.5000 (90.7650)  time: 0.3466  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1460/4579]  eta: 0:18:14  Lr: 0.001875  Loss: -0.1245  Acc@1: 56.2500 (61.7385)  Acc@5: 87.5000 (90.7598)  time: 0.3499  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [1470/4579]  eta: 0:18:10  Lr: 0.001875  Loss: 0.0939  Acc@1: 62.5000 (61.7395)  Acc@5: 87.5000 (90.7418)  time: 0.3517  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [1480/4579]  eta: 0:18:07  Lr: 0.001875  Loss: -0.4635  Acc@1: 56.2500 (61.7362)  Acc@5: 87.5000 (90.7284)  time: 0.3481  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1490/4579]  eta: 0:18:03  Lr: 0.001875  Loss: -0.1050  Acc@1: 56.2500 (61.7203)  Acc@5: 87.5000 (90.7277)  time: 0.3456  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [1500/4579]  eta: 0:18:00  Lr: 0.001875  Loss: -0.1913  Acc@1: 62.5000 (61.7422)  Acc@5: 87.5000 (90.7312)  time: 0.3509  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1510/4579]  eta: 0:17:56  Lr: 0.001875  Loss: -0.6136  Acc@1: 62.5000 (61.7555)  Acc@5: 87.5000 (90.7429)  time: 0.3525  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [1520/4579]  eta: 0:17:53  Lr: 0.001875  Loss: 0.1200  Acc@1: 62.5000 (61.7562)  Acc@5: 93.7500 (90.7216)  time: 0.3481  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [1530/4579]  eta: 0:17:49  Lr: 0.001875  Loss: -0.2831  Acc@1: 62.5000 (61.7856)  Acc@5: 93.7500 (90.7332)  time: 0.3467  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1540/4579]  eta: 0:17:46  Lr: 0.001875  Loss: -0.3967  Acc@1: 68.7500 (61.8024)  Acc@5: 93.7500 (90.7284)  time: 0.3486  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [1550/4579]  eta: 0:17:42  Lr: 0.001875  Loss: -0.1732  Acc@1: 68.7500 (61.8472)  Acc@5: 93.7500 (90.7439)  time: 0.3497  data: 0.0010  max mem: 2500
Train: Epoch[2/5]  [1560/4579]  eta: 0:17:38  Lr: 0.001875  Loss: -0.0742  Acc@1: 68.7500 (61.8274)  Acc@5: 93.7500 (90.7511)  time: 0.3468  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1570/4579]  eta: 0:17:35  Lr: 0.001875  Loss: -0.2638  Acc@1: 62.5000 (61.8197)  Acc@5: 93.7500 (90.7424)  time: 0.3452  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [1580/4579]  eta: 0:17:31  Lr: 0.001875  Loss: 0.3258  Acc@1: 56.2500 (61.8003)  Acc@5: 93.7500 (90.7495)  time: 0.3504  data: 0.0012  max mem: 2500
Train: Epoch[2/5]  [1590/4579]  eta: 0:17:28  Lr: 0.001875  Loss: -0.4888  Acc@1: 62.5000 (61.8283)  Acc@5: 93.7500 (90.7566)  time: 0.3523  data: 0.0016  max mem: 2500
Train: Epoch[2/5]  [1600/4579]  eta: 0:17:24  Lr: 0.001875  Loss: -0.5974  Acc@1: 62.5000 (61.8285)  Acc@5: 93.7500 (90.7714)  time: 0.3475  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [1610/4579]  eta: 0:17:21  Lr: 0.001875  Loss: -0.3734  Acc@1: 62.5000 (61.8405)  Acc@5: 93.7500 (90.7627)  time: 0.3465  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [1620/4579]  eta: 0:17:17  Lr: 0.001875  Loss: -0.0599  Acc@1: 62.5000 (61.8253)  Acc@5: 93.7500 (90.7734)  time: 0.3487  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [1630/4579]  eta: 0:17:14  Lr: 0.001875  Loss: -0.2330  Acc@1: 62.5000 (61.8294)  Acc@5: 93.7500 (90.7802)  time: 0.3491  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [1640/4579]  eta: 0:17:10  Lr: 0.001875  Loss: -0.0250  Acc@1: 62.5000 (61.8525)  Acc@5: 93.7500 (90.7907)  time: 0.3478  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1650/4579]  eta: 0:17:06  Lr: 0.001875  Loss: -0.2781  Acc@1: 62.5000 (61.8640)  Acc@5: 93.7500 (90.7897)  time: 0.3465  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [1660/4579]  eta: 0:17:03  Lr: 0.001875  Loss: -0.1405  Acc@1: 68.7500 (61.9205)  Acc@5: 93.7500 (90.8000)  time: 0.3455  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [1670/4579]  eta: 0:16:59  Lr: 0.001875  Loss: -0.2594  Acc@1: 68.7500 (61.9577)  Acc@5: 93.7500 (90.7989)  time: 0.3458  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [1680/4579]  eta: 0:16:56  Lr: 0.001875  Loss: 0.0156  Acc@1: 68.7500 (61.9349)  Acc@5: 87.5000 (90.7942)  time: 0.3453  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [1690/4579]  eta: 0:16:52  Lr: 0.001875  Loss: -0.4489  Acc@1: 62.5000 (61.9493)  Acc@5: 87.5000 (90.7784)  time: 0.3457  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [1700/4579]  eta: 0:16:49  Lr: 0.001875  Loss: -0.5378  Acc@1: 56.2500 (61.9268)  Acc@5: 87.5000 (90.7591)  time: 0.3503  data: 0.0013  max mem: 2500
Train: Epoch[2/5]  [1710/4579]  eta: 0:16:45  Lr: 0.001875  Loss: -0.2490  Acc@1: 56.2500 (61.9448)  Acc@5: 87.5000 (90.7583)  time: 0.3530  data: 0.0014  max mem: 2500
Train: Epoch[2/5]  [1720/4579]  eta: 0:16:42  Lr: 0.001875  Loss: -0.0547  Acc@1: 56.2500 (61.9189)  Acc@5: 93.7500 (90.7576)  time: 0.3501  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1730/4579]  eta: 0:16:38  Lr: 0.001875  Loss: -0.1868  Acc@1: 62.5000 (61.9404)  Acc@5: 93.7500 (90.7676)  time: 0.3482  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1740/4579]  eta: 0:16:35  Lr: 0.001875  Loss: -0.6911  Acc@1: 62.5000 (61.9615)  Acc@5: 93.7500 (90.7704)  time: 0.3505  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1750/4579]  eta: 0:16:31  Lr: 0.001875  Loss: -0.5899  Acc@1: 62.5000 (61.9931)  Acc@5: 93.7500 (90.7660)  time: 0.3569  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [1760/4579]  eta: 0:16:28  Lr: 0.001875  Loss: -0.0151  Acc@1: 62.5000 (62.0102)  Acc@5: 93.7500 (90.7723)  time: 0.3552  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [1770/4579]  eta: 0:16:24  Lr: 0.001875  Loss: 0.4531  Acc@1: 62.5000 (62.0095)  Acc@5: 87.5000 (90.7291)  time: 0.3499  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [1780/4579]  eta: 0:16:21  Lr: 0.001875  Loss: -0.7242  Acc@1: 62.5000 (62.0157)  Acc@5: 87.5000 (90.7355)  time: 0.3499  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [1790/4579]  eta: 0:16:17  Lr: 0.001875  Loss: -0.2839  Acc@1: 62.5000 (62.0289)  Acc@5: 93.7500 (90.7384)  time: 0.3501  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [1800/4579]  eta: 0:16:14  Lr: 0.001875  Loss: -0.3380  Acc@1: 56.2500 (61.9968)  Acc@5: 93.7500 (90.7482)  time: 0.3519  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1810/4579]  eta: 0:16:10  Lr: 0.001875  Loss: -0.1991  Acc@1: 56.2500 (61.9927)  Acc@5: 93.7500 (90.7165)  time: 0.3512  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1820/4579]  eta: 0:16:07  Lr: 0.001875  Loss: -0.1596  Acc@1: 62.5000 (62.0367)  Acc@5: 93.7500 (90.7228)  time: 0.3492  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1830/4579]  eta: 0:16:03  Lr: 0.001875  Loss: -0.2704  Acc@1: 68.7500 (62.0289)  Acc@5: 93.7500 (90.7155)  time: 0.3491  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1840/4579]  eta: 0:16:00  Lr: 0.001875  Loss: -0.2204  Acc@1: 62.5000 (62.0417)  Acc@5: 93.7500 (90.7251)  time: 0.3506  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1850/4579]  eta: 0:15:56  Lr: 0.001875  Loss: 0.0454  Acc@1: 62.5000 (61.9969)  Acc@5: 93.7500 (90.7212)  time: 0.3493  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1860/4579]  eta: 0:15:53  Lr: 0.001875  Loss: -0.0716  Acc@1: 56.2500 (61.9794)  Acc@5: 93.7500 (90.7241)  time: 0.3463  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1870/4579]  eta: 0:15:49  Lr: 0.001875  Loss: -0.0514  Acc@1: 62.5000 (61.9755)  Acc@5: 93.7500 (90.7436)  time: 0.3469  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [1880/4579]  eta: 0:15:46  Lr: 0.001875  Loss: -0.1385  Acc@1: 62.5000 (62.0116)  Acc@5: 93.7500 (90.7596)  time: 0.3499  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [1890/4579]  eta: 0:15:42  Lr: 0.001875  Loss: -0.1847  Acc@1: 68.7500 (62.0009)  Acc@5: 93.7500 (90.7622)  time: 0.3520  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [1900/4579]  eta: 0:15:39  Lr: 0.001875  Loss: 0.3926  Acc@1: 56.2500 (61.9937)  Acc@5: 93.7500 (90.7680)  time: 0.3523  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1910/4579]  eta: 0:15:35  Lr: 0.001875  Loss: 0.1576  Acc@1: 56.2500 (61.9865)  Acc@5: 93.7500 (90.7575)  time: 0.3504  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1920/4579]  eta: 0:15:32  Lr: 0.001875  Loss: -0.1591  Acc@1: 62.5000 (61.9925)  Acc@5: 87.5000 (90.7600)  time: 0.3537  data: 0.0013  max mem: 2500
Train: Epoch[2/5]  [1930/4579]  eta: 0:15:28  Lr: 0.001875  Loss: -0.5152  Acc@1: 62.5000 (61.9854)  Acc@5: 93.7500 (90.7626)  time: 0.3558  data: 0.0013  max mem: 2500
Train: Epoch[2/5]  [1940/4579]  eta: 0:15:25  Lr: 0.001875  Loss: 0.0365  Acc@1: 62.5000 (61.9784)  Acc@5: 93.7500 (90.7522)  time: 0.3504  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1950/4579]  eta: 0:15:21  Lr: 0.001875  Loss: -0.7460  Acc@1: 56.2500 (61.9746)  Acc@5: 93.7500 (90.7708)  time: 0.3497  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1960/4579]  eta: 0:15:18  Lr: 0.001875  Loss: -0.4692  Acc@1: 62.5000 (61.9837)  Acc@5: 93.7500 (90.7796)  time: 0.3518  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1970/4579]  eta: 0:15:14  Lr: 0.001875  Loss: -0.0653  Acc@1: 62.5000 (61.9895)  Acc@5: 93.7500 (90.7693)  time: 0.3543  data: 0.0017  max mem: 2500
Train: Epoch[2/5]  [1980/4579]  eta: 0:15:11  Lr: 0.001875  Loss: 0.1523  Acc@1: 62.5000 (61.9763)  Acc@5: 87.5000 (90.7528)  time: 0.3536  data: 0.0017  max mem: 2500
Train: Epoch[2/5]  [1990/4579]  eta: 0:15:07  Lr: 0.001875  Loss: -0.3541  Acc@1: 62.5000 (62.0072)  Acc@5: 87.5000 (90.7616)  time: 0.3491  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [2000/4579]  eta: 0:15:04  Lr: 0.001875  Loss: -0.2479  Acc@1: 62.5000 (62.0159)  Acc@5: 93.7500 (90.7515)  time: 0.3482  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [2010/4579]  eta: 0:15:00  Lr: 0.001875  Loss: -0.1350  Acc@1: 62.5000 (62.0338)  Acc@5: 87.5000 (90.7509)  time: 0.3500  data: 0.0009  max mem: 2500
Train: Epoch[2/5]  [2020/4579]  eta: 0:14:57  Lr: 0.001875  Loss: -0.2130  Acc@1: 62.5000 (62.0516)  Acc@5: 93.7500 (90.7595)  time: 0.3502  data: 0.0014  max mem: 2500
Train: Epoch[2/5]  [2030/4579]  eta: 0:14:53  Lr: 0.001875  Loss: 0.6073  Acc@1: 62.5000 (62.0476)  Acc@5: 87.5000 (90.7435)  time: 0.3482  data: 0.0013  max mem: 2500
Train: Epoch[2/5]  [2040/4579]  eta: 0:14:49  Lr: 0.001875  Loss: 0.0399  Acc@1: 56.2500 (62.0131)  Acc@5: 87.5000 (90.7184)  time: 0.3460  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [2050/4579]  eta: 0:14:46  Lr: 0.001875  Loss: -0.5752  Acc@1: 50.0000 (61.9972)  Acc@5: 87.5000 (90.7088)  time: 0.3466  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [2060/4579]  eta: 0:14:42  Lr: 0.001875  Loss: 0.2085  Acc@1: 62.5000 (62.0148)  Acc@5: 93.7500 (90.7084)  time: 0.3474  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [2070/4579]  eta: 0:14:39  Lr: 0.001875  Loss: -0.4687  Acc@1: 62.5000 (62.0171)  Acc@5: 87.5000 (90.6929)  time: 0.3461  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [2080/4579]  eta: 0:14:35  Lr: 0.001875  Loss: 0.0844  Acc@1: 62.5000 (62.0195)  Acc@5: 87.5000 (90.7076)  time: 0.3471  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [2090/4579]  eta: 0:14:32  Lr: 0.001875  Loss: -0.4976  Acc@1: 62.5000 (62.0307)  Acc@5: 93.7500 (90.7132)  time: 0.3542  data: 0.0010  max mem: 2500
Train: Epoch[2/5]  [2100/4579]  eta: 0:14:28  Lr: 0.001875  Loss: -0.5904  Acc@1: 62.5000 (62.0389)  Acc@5: 93.7500 (90.7128)  time: 0.3549  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [2110/4579]  eta: 0:14:25  Lr: 0.001875  Loss: -0.5756  Acc@1: 62.5000 (62.0618)  Acc@5: 93.7500 (90.7331)  time: 0.3508  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [2120/4579]  eta: 0:14:21  Lr: 0.001875  Loss: -0.6982  Acc@1: 68.7500 (62.0992)  Acc@5: 93.7500 (90.7620)  time: 0.3508  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [2130/4579]  eta: 0:14:18  Lr: 0.001875  Loss: 0.3213  Acc@1: 62.5000 (62.0835)  Acc@5: 93.7500 (90.7584)  time: 0.3541  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [2140/4579]  eta: 0:14:15  Lr: 0.001875  Loss: -0.0535  Acc@1: 56.2500 (62.0621)  Acc@5: 87.5000 (90.7432)  time: 0.3554  data: 0.0012  max mem: 2500
Train: Epoch[2/5]  [2150/4579]  eta: 0:14:11  Lr: 0.001875  Loss: -0.8136  Acc@1: 56.2500 (62.0671)  Acc@5: 87.5000 (90.7340)  time: 0.3510  data: 0.0010  max mem: 2500
Train: Epoch[2/5]  [2160/4579]  eta: 0:14:07  Lr: 0.001875  Loss: 0.1452  Acc@1: 62.5000 (62.0720)  Acc@5: 87.5000 (90.7335)  time: 0.3503  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [2170/4579]  eta: 0:14:04  Lr: 0.001875  Loss: 0.3504  Acc@1: 56.2500 (62.0451)  Acc@5: 93.7500 (90.7358)  time: 0.3532  data: 0.0011  max mem: 2500
Train: Epoch[2/5]  [2180/4579]  eta: 0:14:01  Lr: 0.001875  Loss: -0.4579  Acc@1: 56.2500 (62.0300)  Acc@5: 93.7500 (90.7267)  time: 0.3527  data: 0.0010  max mem: 2500
Train: Epoch[2/5]  [2190/4579]  eta: 0:13:57  Lr: 0.001875  Loss: -0.3856  Acc@1: 62.5000 (62.0550)  Acc@5: 93.7500 (90.7405)  time: 0.3507  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [2200/4579]  eta: 0:13:53  Lr: 0.001875  Loss: -0.2566  Acc@1: 68.7500 (62.0655)  Acc@5: 93.7500 (90.7372)  time: 0.3494  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2210/4579]  eta: 0:13:50  Lr: 0.001875  Loss: -0.1803  Acc@1: 68.7500 (62.0845)  Acc@5: 93.7500 (90.7451)  time: 0.3486  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2220/4579]  eta: 0:13:46  Lr: 0.001875  Loss: 0.2056  Acc@1: 62.5000 (62.0695)  Acc@5: 87.5000 (90.7165)  time: 0.3492  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2230/4579]  eta: 0:13:43  Lr: 0.001875  Loss: -0.4165  Acc@1: 56.2500 (62.0686)  Acc@5: 87.5000 (90.7160)  time: 0.3489  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [2240/4579]  eta: 0:13:39  Lr: 0.001875  Loss: 0.2132  Acc@1: 62.5000 (62.0566)  Acc@5: 93.7500 (90.7212)  time: 0.3465  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2250/4579]  eta: 0:13:36  Lr: 0.001875  Loss: -0.4085  Acc@1: 62.5000 (62.0363)  Acc@5: 87.5000 (90.7125)  time: 0.3450  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2260/4579]  eta: 0:13:32  Lr: 0.001875  Loss: -0.2155  Acc@1: 62.5000 (62.0356)  Acc@5: 87.5000 (90.7065)  time: 0.3477  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2270/4579]  eta: 0:13:29  Lr: 0.001875  Loss: -0.3783  Acc@1: 62.5000 (62.0239)  Acc@5: 93.7500 (90.7117)  time: 0.3498  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [2280/4579]  eta: 0:13:25  Lr: 0.001875  Loss: -0.4539  Acc@1: 56.2500 (62.0205)  Acc@5: 93.7500 (90.7168)  time: 0.3510  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [2290/4579]  eta: 0:13:22  Lr: 0.001875  Loss: -0.5444  Acc@1: 62.5000 (62.0362)  Acc@5: 93.7500 (90.7246)  time: 0.3516  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [2300/4579]  eta: 0:13:18  Lr: 0.001875  Loss: -0.7008  Acc@1: 62.5000 (62.0382)  Acc@5: 87.5000 (90.7160)  time: 0.3508  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [2310/4579]  eta: 0:13:15  Lr: 0.001875  Loss: -0.4785  Acc@1: 62.5000 (62.0511)  Acc@5: 93.7500 (90.7291)  time: 0.3540  data: 0.0012  max mem: 2500
Train: Epoch[2/5]  [2320/4579]  eta: 0:13:11  Lr: 0.001875  Loss: -0.1080  Acc@1: 62.5000 (62.0611)  Acc@5: 93.7500 (90.7260)  time: 0.3569  data: 0.0020  max mem: 2500
Train: Epoch[2/5]  [2330/4579]  eta: 0:13:08  Lr: 0.001875  Loss: -0.2011  Acc@1: 62.5000 (62.0549)  Acc@5: 87.5000 (90.7068)  time: 0.3519  data: 0.0014  max mem: 2500
Train: Epoch[2/5]  [2340/4579]  eta: 0:13:04  Lr: 0.001875  Loss: 0.3407  Acc@1: 62.5000 (62.0622)  Acc@5: 87.5000 (90.7091)  time: 0.3505  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [2350/4579]  eta: 0:13:01  Lr: 0.001875  Loss: -0.2567  Acc@1: 62.5000 (62.0693)  Acc@5: 93.7500 (90.7194)  time: 0.3542  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [2360/4579]  eta: 0:12:57  Lr: 0.001875  Loss: -0.8114  Acc@1: 62.5000 (62.0897)  Acc@5: 100.0000 (90.7507)  time: 0.3538  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [2370/4579]  eta: 0:12:54  Lr: 0.001875  Loss: 0.0628  Acc@1: 62.5000 (62.0993)  Acc@5: 93.7500 (90.7608)  time: 0.3516  data: 0.0010  max mem: 2500
Train: Epoch[2/5]  [2380/4579]  eta: 0:12:50  Lr: 0.001875  Loss: -0.3044  Acc@1: 62.5000 (62.0826)  Acc@5: 93.7500 (90.7576)  time: 0.3502  data: 0.0009  max mem: 2500
Train: Epoch[2/5]  [2390/4579]  eta: 0:12:47  Lr: 0.001875  Loss: -0.5046  Acc@1: 56.2500 (62.0635)  Acc@5: 87.5000 (90.7439)  time: 0.3493  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2400/4579]  eta: 0:12:43  Lr: 0.001875  Loss: -0.2028  Acc@1: 62.5000 (62.0809)  Acc@5: 87.5000 (90.7512)  time: 0.3512  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2410/4579]  eta: 0:12:40  Lr: 0.001875  Loss: 0.0932  Acc@1: 62.5000 (62.0697)  Acc@5: 93.7500 (90.7559)  time: 0.3510  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2420/4579]  eta: 0:12:36  Lr: 0.001875  Loss: -0.4530  Acc@1: 62.5000 (62.0869)  Acc@5: 93.7500 (90.7760)  time: 0.3460  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [2430/4579]  eta: 0:12:33  Lr: 0.001875  Loss: -0.4173  Acc@1: 62.5000 (62.0732)  Acc@5: 93.7500 (90.7805)  time: 0.3447  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [2440/4579]  eta: 0:12:29  Lr: 0.001875  Loss: 0.3435  Acc@1: 62.5000 (62.0852)  Acc@5: 93.7500 (90.7799)  time: 0.3483  data: 0.0012  max mem: 2500
Train: Epoch[2/5]  [2450/4579]  eta: 0:12:26  Lr: 0.001875  Loss: 0.1604  Acc@1: 62.5000 (62.0869)  Acc@5: 87.5000 (90.7767)  time: 0.3483  data: 0.0011  max mem: 2500
Train: Epoch[2/5]  [2460/4579]  eta: 0:12:22  Lr: 0.001875  Loss: -0.6224  Acc@1: 62.5000 (62.1165)  Acc@5: 93.7500 (90.7863)  time: 0.3469  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [2470/4579]  eta: 0:12:19  Lr: 0.001875  Loss: -0.0132  Acc@1: 68.7500 (62.1282)  Acc@5: 93.7500 (90.7856)  time: 0.3504  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [2480/4579]  eta: 0:12:15  Lr: 0.001875  Loss: 0.0076  Acc@1: 62.5000 (62.1297)  Acc@5: 93.7500 (90.7900)  time: 0.3540  data: 0.0016  max mem: 2500
Train: Epoch[2/5]  [2490/4579]  eta: 0:12:12  Lr: 0.001875  Loss: -0.3709  Acc@1: 68.7500 (62.1563)  Acc@5: 93.7500 (90.7994)  time: 0.3579  data: 0.0016  max mem: 2500
Train: Epoch[2/5]  [2500/4579]  eta: 0:12:08  Lr: 0.001875  Loss: -0.1692  Acc@1: 68.7500 (62.1751)  Acc@5: 93.7500 (90.8037)  time: 0.3574  data: 0.0009  max mem: 2500
Train: Epoch[2/5]  [2510/4579]  eta: 0:12:05  Lr: 0.001875  Loss: 0.1690  Acc@1: 62.5000 (62.1764)  Acc@5: 93.7500 (90.7980)  time: 0.3532  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [2520/4579]  eta: 0:12:01  Lr: 0.001875  Loss: 0.1117  Acc@1: 62.5000 (62.1628)  Acc@5: 93.7500 (90.8047)  time: 0.3503  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [2530/4579]  eta: 0:11:58  Lr: 0.001875  Loss: -0.3607  Acc@1: 62.5000 (62.1568)  Acc@5: 93.7500 (90.8016)  time: 0.3534  data: 0.0016  max mem: 2500
Train: Epoch[2/5]  [2540/4579]  eta: 0:11:54  Lr: 0.001875  Loss: -0.1675  Acc@1: 62.5000 (62.1483)  Acc@5: 87.5000 (90.8009)  time: 0.3554  data: 0.0016  max mem: 2500
Train: Epoch[2/5]  [2550/4579]  eta: 0:11:51  Lr: 0.001875  Loss: 0.6230  Acc@1: 56.2500 (62.1423)  Acc@5: 87.5000 (90.7904)  time: 0.3504  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [2560/4579]  eta: 0:11:47  Lr: 0.001875  Loss: -0.0954  Acc@1: 56.2500 (62.1144)  Acc@5: 93.7500 (90.7922)  time: 0.3476  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2570/4579]  eta: 0:11:44  Lr: 0.001875  Loss: 0.0893  Acc@1: 56.2500 (62.0940)  Acc@5: 93.7500 (90.7988)  time: 0.3475  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2580/4579]  eta: 0:11:40  Lr: 0.001875  Loss: 0.0867  Acc@1: 62.5000 (62.1053)  Acc@5: 93.7500 (90.8102)  time: 0.3492  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2590/4579]  eta: 0:11:37  Lr: 0.001875  Loss: -0.1234  Acc@1: 68.7500 (62.1261)  Acc@5: 93.7500 (90.8264)  time: 0.3500  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2600/4579]  eta: 0:11:33  Lr: 0.001875  Loss: -0.2845  Acc@1: 62.5000 (62.1227)  Acc@5: 93.7500 (90.8256)  time: 0.3470  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [2610/4579]  eta: 0:11:30  Lr: 0.001875  Loss: -0.1102  Acc@1: 68.7500 (62.1457)  Acc@5: 93.7500 (90.8201)  time: 0.3457  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [2620/4579]  eta: 0:11:26  Lr: 0.001875  Loss: 0.1504  Acc@1: 62.5000 (62.1447)  Acc@5: 87.5000 (90.8170)  time: 0.3467  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [2630/4579]  eta: 0:11:23  Lr: 0.001875  Loss: 0.0947  Acc@1: 56.2500 (62.1223)  Acc@5: 93.7500 (90.8257)  time: 0.3456  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [2640/4579]  eta: 0:11:19  Lr: 0.001875  Loss: -0.3086  Acc@1: 56.2500 (62.1143)  Acc@5: 93.7500 (90.8321)  time: 0.3454  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [2650/4579]  eta: 0:11:16  Lr: 0.001875  Loss: -0.6753  Acc@1: 62.5000 (62.1346)  Acc@5: 93.7500 (90.8478)  time: 0.3493  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [2660/4579]  eta: 0:11:12  Lr: 0.001875  Loss: 0.0183  Acc@1: 68.7500 (62.1312)  Acc@5: 93.7500 (90.8493)  time: 0.3552  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [2670/4579]  eta: 0:11:09  Lr: 0.001875  Loss: -0.0817  Acc@1: 62.5000 (62.1350)  Acc@5: 93.7500 (90.8438)  time: 0.3549  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [2680/4579]  eta: 0:11:05  Lr: 0.001875  Loss: 0.0676  Acc@1: 62.5000 (62.1317)  Acc@5: 87.5000 (90.8336)  time: 0.3543  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [2690/4579]  eta: 0:11:02  Lr: 0.001875  Loss: 0.1061  Acc@1: 56.2500 (62.1145)  Acc@5: 87.5000 (90.8352)  time: 0.3542  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [2700/4579]  eta: 0:10:58  Lr: 0.001875  Loss: -0.4341  Acc@1: 62.5000 (62.1275)  Acc@5: 87.5000 (90.8344)  time: 0.3515  data: 0.0011  max mem: 2500
Train: Epoch[2/5]  [2710/4579]  eta: 0:10:55  Lr: 0.001875  Loss: -0.0822  Acc@1: 62.5000 (62.1265)  Acc@5: 87.5000 (90.8359)  time: 0.3552  data: 0.0015  max mem: 2500
Train: Epoch[2/5]  [2720/4579]  eta: 0:10:51  Lr: 0.001875  Loss: -0.2396  Acc@1: 62.5000 (62.1394)  Acc@5: 87.5000 (90.8260)  time: 0.3548  data: 0.0010  max mem: 2500
Train: Epoch[2/5]  [2730/4579]  eta: 0:10:48  Lr: 0.001875  Loss: 0.1056  Acc@1: 62.5000 (62.1384)  Acc@5: 93.7500 (90.8413)  time: 0.3519  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [2740/4579]  eta: 0:10:44  Lr: 0.001875  Loss: -0.0715  Acc@1: 62.5000 (62.1169)  Acc@5: 93.7500 (90.8245)  time: 0.3571  data: 0.0012  max mem: 2500
Train: Epoch[2/5]  [2750/4579]  eta: 0:10:41  Lr: 0.001875  Loss: 0.7338  Acc@1: 50.0000 (62.0911)  Acc@5: 87.5000 (90.8170)  time: 0.3566  data: 0.0011  max mem: 2500
Train: Epoch[2/5]  [2760/4579]  eta: 0:10:37  Lr: 0.001875  Loss: -0.8740  Acc@1: 62.5000 (62.1152)  Acc@5: 87.5000 (90.8231)  time: 0.3521  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [2770/4579]  eta: 0:10:34  Lr: 0.001875  Loss: 0.0244  Acc@1: 62.5000 (62.1008)  Acc@5: 93.7500 (90.8201)  time: 0.3500  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2780/4579]  eta: 0:10:30  Lr: 0.001875  Loss: 0.2058  Acc@1: 62.5000 (62.1000)  Acc@5: 87.5000 (90.8149)  time: 0.3478  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2790/4579]  eta: 0:10:27  Lr: 0.001875  Loss: -0.0228  Acc@1: 62.5000 (62.0745)  Acc@5: 87.5000 (90.8165)  time: 0.3491  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2800/4579]  eta: 0:10:23  Lr: 0.001875  Loss: -0.2264  Acc@1: 62.5000 (62.0850)  Acc@5: 93.7500 (90.8180)  time: 0.3504  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2810/4579]  eta: 0:10:20  Lr: 0.001875  Loss: -0.5408  Acc@1: 68.7500 (62.1020)  Acc@5: 93.7500 (90.8351)  time: 0.3478  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [2820/4579]  eta: 0:10:16  Lr: 0.001875  Loss: -0.4339  Acc@1: 68.7500 (62.1167)  Acc@5: 93.7500 (90.8299)  time: 0.3460  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [2830/4579]  eta: 0:10:13  Lr: 0.001875  Loss: -0.3922  Acc@1: 68.7500 (62.1401)  Acc@5: 93.7500 (90.8336)  time: 0.3468  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [2840/4579]  eta: 0:10:09  Lr: 0.001875  Loss: -0.3468  Acc@1: 62.5000 (62.1194)  Acc@5: 93.7500 (90.8285)  time: 0.3466  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [2850/4579]  eta: 0:10:06  Lr: 0.001875  Loss: -0.5822  Acc@1: 56.2500 (62.1383)  Acc@5: 87.5000 (90.8234)  time: 0.3483  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2860/4579]  eta: 0:10:02  Lr: 0.001875  Loss: 0.2199  Acc@1: 62.5000 (62.1548)  Acc@5: 93.7500 (90.8227)  time: 0.3502  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [2870/4579]  eta: 0:09:59  Lr: 0.001875  Loss: 0.2884  Acc@1: 62.5000 (62.1756)  Acc@5: 93.7500 (90.8351)  time: 0.3526  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [2880/4579]  eta: 0:09:55  Lr: 0.001875  Loss: 0.0572  Acc@1: 68.7500 (62.1963)  Acc@5: 93.7500 (90.8452)  time: 0.3528  data: 0.0010  max mem: 2500
Train: Epoch[2/5]  [2890/4579]  eta: 0:09:52  Lr: 0.001875  Loss: -0.3973  Acc@1: 62.5000 (62.1909)  Acc@5: 93.7500 (90.8466)  time: 0.3499  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [2900/4579]  eta: 0:09:48  Lr: 0.001875  Loss: -0.2097  Acc@1: 62.5000 (62.1876)  Acc@5: 93.7500 (90.8394)  time: 0.3507  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [2910/4579]  eta: 0:09:45  Lr: 0.001875  Loss: -0.4172  Acc@1: 56.2500 (62.1737)  Acc@5: 93.7500 (90.8429)  time: 0.3519  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [2920/4579]  eta: 0:09:41  Lr: 0.001875  Loss: -0.0953  Acc@1: 56.2500 (62.1705)  Acc@5: 93.7500 (90.8443)  time: 0.3529  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [2930/4579]  eta: 0:09:38  Lr: 0.001875  Loss: -0.0730  Acc@1: 62.5000 (62.1737)  Acc@5: 87.5000 (90.8393)  time: 0.3535  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [2940/4579]  eta: 0:09:34  Lr: 0.001875  Loss: 0.0941  Acc@1: 62.5000 (62.1642)  Acc@5: 93.7500 (90.8428)  time: 0.3506  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [2950/4579]  eta: 0:09:31  Lr: 0.001875  Loss: 0.0807  Acc@1: 56.2500 (62.1463)  Acc@5: 87.5000 (90.8294)  time: 0.3484  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [2960/4579]  eta: 0:09:27  Lr: 0.001875  Loss: -0.6243  Acc@1: 62.5000 (62.1581)  Acc@5: 87.5000 (90.8266)  time: 0.3505  data: 0.0009  max mem: 2500
Train: Epoch[2/5]  [2970/4579]  eta: 0:09:24  Lr: 0.001875  Loss: -0.8476  Acc@1: 62.5000 (62.1760)  Acc@5: 87.5000 (90.8238)  time: 0.3514  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [2980/4579]  eta: 0:09:20  Lr: 0.001875  Loss: -0.2498  Acc@1: 62.5000 (62.1729)  Acc@5: 93.7500 (90.8378)  time: 0.3489  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2990/4579]  eta: 0:09:17  Lr: 0.001875  Loss: -0.3620  Acc@1: 62.5000 (62.1761)  Acc@5: 93.7500 (90.8371)  time: 0.3488  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3000/4579]  eta: 0:09:13  Lr: 0.001875  Loss: -0.4625  Acc@1: 68.7500 (62.1855)  Acc@5: 93.7500 (90.8406)  time: 0.3490  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3010/4579]  eta: 0:09:10  Lr: 0.001875  Loss: -0.2892  Acc@1: 62.5000 (62.1803)  Acc@5: 93.7500 (90.8398)  time: 0.3518  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3020/4579]  eta: 0:09:06  Lr: 0.001875  Loss: -0.4987  Acc@1: 62.5000 (62.1814)  Acc@5: 93.7500 (90.8433)  time: 0.3549  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3030/4579]  eta: 0:09:03  Lr: 0.001875  Loss: -0.1938  Acc@1: 62.5000 (62.1948)  Acc@5: 93.7500 (90.8467)  time: 0.3494  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [3040/4579]  eta: 0:08:59  Lr: 0.001875  Loss: -0.4895  Acc@1: 68.7500 (62.2082)  Acc@5: 93.7500 (90.8500)  time: 0.3452  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [3050/4579]  eta: 0:08:56  Lr: 0.001875  Loss: 0.0268  Acc@1: 68.7500 (62.2009)  Acc@5: 93.7500 (90.8514)  time: 0.3483  data: 0.0017  max mem: 2500
Train: Epoch[2/5]  [3060/4579]  eta: 0:08:52  Lr: 0.001875  Loss: -0.4359  Acc@1: 62.5000 (62.2162)  Acc@5: 93.7500 (90.8486)  time: 0.3484  data: 0.0017  max mem: 2500
Train: Epoch[2/5]  [3070/4579]  eta: 0:08:48  Lr: 0.001875  Loss: -1.0143  Acc@1: 62.5000 (62.2273)  Acc@5: 87.5000 (90.8458)  time: 0.3460  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [3080/4579]  eta: 0:08:45  Lr: 0.001875  Loss: -0.3966  Acc@1: 62.5000 (62.2302)  Acc@5: 93.7500 (90.8512)  time: 0.3473  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3090/4579]  eta: 0:08:41  Lr: 0.001875  Loss: -0.2786  Acc@1: 62.5000 (62.2311)  Acc@5: 93.7500 (90.8545)  time: 0.3510  data: 0.0009  max mem: 2500
Train: Epoch[2/5]  [3100/4579]  eta: 0:08:38  Lr: 0.001875  Loss: -0.4456  Acc@1: 62.5000 (62.2340)  Acc@5: 93.7500 (90.8538)  time: 0.3529  data: 0.0010  max mem: 2500
Train: Epoch[2/5]  [3110/4579]  eta: 0:08:34  Lr: 0.001875  Loss: -0.0241  Acc@1: 56.2500 (62.2228)  Acc@5: 93.7500 (90.8570)  time: 0.3503  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [3120/4579]  eta: 0:08:31  Lr: 0.001875  Loss: 0.0106  Acc@1: 56.2500 (62.2156)  Acc@5: 93.7500 (90.8563)  time: 0.3489  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [3130/4579]  eta: 0:08:27  Lr: 0.001875  Loss: -0.5015  Acc@1: 62.5000 (62.2165)  Acc@5: 93.7500 (90.8536)  time: 0.3493  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [3140/4579]  eta: 0:08:24  Lr: 0.001875  Loss: -0.3721  Acc@1: 62.5000 (62.2194)  Acc@5: 93.7500 (90.8628)  time: 0.3522  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3150/4579]  eta: 0:08:20  Lr: 0.001875  Loss: 0.2837  Acc@1: 62.5000 (62.2124)  Acc@5: 93.7500 (90.8541)  time: 0.3520  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [3160/4579]  eta: 0:08:17  Lr: 0.001875  Loss: -0.7425  Acc@1: 62.5000 (62.2192)  Acc@5: 93.7500 (90.8652)  time: 0.3490  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [3170/4579]  eta: 0:08:13  Lr: 0.001875  Loss: -0.3091  Acc@1: 62.5000 (62.2339)  Acc@5: 93.7500 (90.8566)  time: 0.3489  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [3180/4579]  eta: 0:08:10  Lr: 0.001875  Loss: 0.4641  Acc@1: 62.5000 (62.2348)  Acc@5: 87.5000 (90.8618)  time: 0.3506  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3190/4579]  eta: 0:08:06  Lr: 0.001875  Loss: -0.4223  Acc@1: 62.5000 (62.2375)  Acc@5: 93.7500 (90.8669)  time: 0.3507  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3200/4579]  eta: 0:08:03  Lr: 0.001875  Loss: -0.3917  Acc@1: 68.7500 (62.2637)  Acc@5: 93.7500 (90.8720)  time: 0.3501  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3210/4579]  eta: 0:07:59  Lr: 0.001875  Loss: -0.7169  Acc@1: 68.7500 (62.2684)  Acc@5: 93.7500 (90.8810)  time: 0.3498  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3220/4579]  eta: 0:07:56  Lr: 0.001875  Loss: -0.2156  Acc@1: 68.7500 (62.2807)  Acc@5: 93.7500 (90.8879)  time: 0.3481  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3230/4579]  eta: 0:07:52  Lr: 0.001875  Loss: -0.0148  Acc@1: 62.5000 (62.2601)  Acc@5: 93.7500 (90.8910)  time: 0.3494  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3240/4579]  eta: 0:07:49  Lr: 0.001875  Loss: 0.2694  Acc@1: 62.5000 (62.2705)  Acc@5: 93.7500 (90.8882)  time: 0.3482  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [3250/4579]  eta: 0:07:45  Lr: 0.001875  Loss: -0.0722  Acc@1: 62.5000 (62.2655)  Acc@5: 87.5000 (90.8817)  time: 0.3456  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [3260/4579]  eta: 0:07:42  Lr: 0.001875  Loss: -0.4208  Acc@1: 62.5000 (62.2681)  Acc@5: 87.5000 (90.8732)  time: 0.3469  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [3270/4579]  eta: 0:07:38  Lr: 0.001875  Loss: -0.0673  Acc@1: 62.5000 (62.2554)  Acc@5: 87.5000 (90.8705)  time: 0.3474  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3280/4579]  eta: 0:07:35  Lr: 0.001875  Loss: -0.1087  Acc@1: 62.5000 (62.2581)  Acc@5: 87.5000 (90.8679)  time: 0.3473  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3290/4579]  eta: 0:07:31  Lr: 0.001875  Loss: 0.0594  Acc@1: 62.5000 (62.2664)  Acc@5: 87.5000 (90.8709)  time: 0.3489  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [3300/4579]  eta: 0:07:28  Lr: 0.001875  Loss: -0.2636  Acc@1: 62.5000 (62.2804)  Acc@5: 93.7500 (90.8778)  time: 0.3506  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [3310/4579]  eta: 0:07:24  Lr: 0.001875  Loss: 0.5755  Acc@1: 68.7500 (62.2810)  Acc@5: 93.7500 (90.8808)  time: 0.3518  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [3320/4579]  eta: 0:07:21  Lr: 0.001875  Loss: -0.6706  Acc@1: 68.7500 (62.3024)  Acc@5: 93.7500 (90.8838)  time: 0.3521  data: 0.0013  max mem: 2500
Train: Epoch[2/5]  [3330/4579]  eta: 0:07:17  Lr: 0.001875  Loss: -0.4202  Acc@1: 62.5000 (62.3011)  Acc@5: 87.5000 (90.8830)  time: 0.3521  data: 0.0012  max mem: 2500
Train: Epoch[2/5]  [3340/4579]  eta: 0:07:14  Lr: 0.001875  Loss: -0.3377  Acc@1: 62.5000 (62.3148)  Acc@5: 87.5000 (90.8822)  time: 0.3509  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [3350/4579]  eta: 0:07:10  Lr: 0.001875  Loss: 0.2816  Acc@1: 62.5000 (62.3135)  Acc@5: 87.5000 (90.8833)  time: 0.3501  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [3360/4579]  eta: 0:07:07  Lr: 0.001875  Loss: 0.1857  Acc@1: 62.5000 (62.3066)  Acc@5: 87.5000 (90.8677)  time: 0.3608  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [3370/4579]  eta: 0:07:03  Lr: 0.001875  Loss: 0.1512  Acc@1: 62.5000 (62.3183)  Acc@5: 93.7500 (90.8781)  time: 0.3603  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [3380/4579]  eta: 0:07:00  Lr: 0.001875  Loss: -0.4098  Acc@1: 68.7500 (62.3133)  Acc@5: 93.7500 (90.8607)  time: 0.3485  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [3390/4579]  eta: 0:06:56  Lr: 0.001875  Loss: 0.1279  Acc@1: 56.2500 (62.3065)  Acc@5: 87.5000 (90.8526)  time: 0.3475  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3400/4579]  eta: 0:06:53  Lr: 0.001875  Loss: 0.2436  Acc@1: 62.5000 (62.3015)  Acc@5: 87.5000 (90.8520)  time: 0.3480  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3410/4579]  eta: 0:06:49  Lr: 0.001875  Loss: -0.4369  Acc@1: 62.5000 (62.2893)  Acc@5: 87.5000 (90.8458)  time: 0.3497  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [3420/4579]  eta: 0:06:46  Lr: 0.001875  Loss: -0.2969  Acc@1: 62.5000 (62.2808)  Acc@5: 93.7500 (90.8543)  time: 0.3489  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [3430/4579]  eta: 0:06:42  Lr: 0.001875  Loss: -0.2161  Acc@1: 62.5000 (62.2832)  Acc@5: 93.7500 (90.8573)  time: 0.3460  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [3440/4579]  eta: 0:06:39  Lr: 0.001875  Loss: -0.1169  Acc@1: 68.7500 (62.2820)  Acc@5: 87.5000 (90.8548)  time: 0.3468  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [3450/4579]  eta: 0:06:35  Lr: 0.001875  Loss: -0.3034  Acc@1: 62.5000 (62.2953)  Acc@5: 93.7500 (90.8595)  time: 0.3478  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3460/4579]  eta: 0:06:32  Lr: 0.001875  Loss: -0.2048  Acc@1: 62.5000 (62.2869)  Acc@5: 93.7500 (90.8607)  time: 0.3459  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3470/4579]  eta: 0:06:28  Lr: 0.001875  Loss: 0.4555  Acc@1: 56.2500 (62.2677)  Acc@5: 87.5000 (90.8420)  time: 0.3466  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3480/4579]  eta: 0:06:25  Lr: 0.001875  Loss: 0.0136  Acc@1: 56.2500 (62.2432)  Acc@5: 87.5000 (90.8288)  time: 0.3513  data: 0.0017  max mem: 2500
Train: Epoch[2/5]  [3490/4579]  eta: 0:06:21  Lr: 0.001875  Loss: -0.4278  Acc@1: 56.2500 (62.2476)  Acc@5: 87.5000 (90.8300)  time: 0.3507  data: 0.0020  max mem: 2500
Train: Epoch[2/5]  [3500/4579]  eta: 0:06:18  Lr: 0.001875  Loss: 0.0928  Acc@1: 56.2500 (62.2197)  Acc@5: 93.7500 (90.8205)  time: 0.3489  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [3510/4579]  eta: 0:06:14  Lr: 0.001875  Loss: 0.1618  Acc@1: 56.2500 (62.2187)  Acc@5: 87.5000 (90.8235)  time: 0.3510  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [3520/4579]  eta: 0:06:11  Lr: 0.001875  Loss: 0.2640  Acc@1: 56.2500 (62.2195)  Acc@5: 87.5000 (90.8229)  time: 0.3525  data: 0.0009  max mem: 2500
Train: Epoch[2/5]  [3530/4579]  eta: 0:06:07  Lr: 0.001875  Loss: -0.4736  Acc@1: 56.2500 (62.2239)  Acc@5: 93.7500 (90.8241)  time: 0.3526  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [3540/4579]  eta: 0:06:04  Lr: 0.001875  Loss: 0.0747  Acc@1: 62.5000 (62.2458)  Acc@5: 93.7500 (90.8412)  time: 0.3513  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [3550/4579]  eta: 0:06:00  Lr: 0.001875  Loss: -0.2450  Acc@1: 62.5000 (62.2395)  Acc@5: 93.7500 (90.8371)  time: 0.3500  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [3560/4579]  eta: 0:05:57  Lr: 0.001875  Loss: -0.1707  Acc@1: 62.5000 (62.2613)  Acc@5: 93.7500 (90.8453)  time: 0.3496  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [3570/4579]  eta: 0:05:53  Lr: 0.001875  Loss: -0.2631  Acc@1: 68.7500 (62.2655)  Acc@5: 93.7500 (90.8394)  time: 0.3499  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [3580/4579]  eta: 0:05:50  Lr: 0.001875  Loss: -0.1650  Acc@1: 62.5000 (62.2661)  Acc@5: 87.5000 (90.8371)  time: 0.3493  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3590/4579]  eta: 0:05:46  Lr: 0.001875  Loss: -0.0117  Acc@1: 56.2500 (62.2598)  Acc@5: 87.5000 (90.8347)  time: 0.3482  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3600/4579]  eta: 0:05:43  Lr: 0.001875  Loss: 0.3217  Acc@1: 56.2500 (62.2397)  Acc@5: 87.5000 (90.8289)  time: 0.3476  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [3610/4579]  eta: 0:05:39  Lr: 0.001875  Loss: -0.3702  Acc@1: 62.5000 (62.2542)  Acc@5: 93.7500 (90.8318)  time: 0.3476  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3620/4579]  eta: 0:05:36  Lr: 0.001875  Loss: -0.1554  Acc@1: 68.7500 (62.2549)  Acc@5: 93.7500 (90.8295)  time: 0.3499  data: 0.0024  max mem: 2500
Train: Epoch[2/5]  [3630/4579]  eta: 0:05:32  Lr: 0.001875  Loss: -0.2355  Acc@1: 62.5000 (62.2539)  Acc@5: 93.7500 (90.8341)  time: 0.3489  data: 0.0023  max mem: 2500
Train: Epoch[2/5]  [3640/4579]  eta: 0:05:29  Lr: 0.001875  Loss: -0.4233  Acc@1: 62.5000 (62.2683)  Acc@5: 93.7500 (90.8370)  time: 0.3457  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [3650/4579]  eta: 0:05:25  Lr: 0.001875  Loss: -0.3050  Acc@1: 62.5000 (62.2775)  Acc@5: 93.7500 (90.8467)  time: 0.3456  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [3660/4579]  eta: 0:05:22  Lr: 0.001875  Loss: 0.9069  Acc@1: 56.2500 (62.2627)  Acc@5: 93.7500 (90.8324)  time: 0.3468  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [3670/4579]  eta: 0:05:18  Lr: 0.001875  Loss: -0.3836  Acc@1: 56.2500 (62.2616)  Acc@5: 87.5000 (90.8302)  time: 0.3489  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [3680/4579]  eta: 0:05:15  Lr: 0.001875  Loss: -0.0349  Acc@1: 62.5000 (62.2555)  Acc@5: 93.7500 (90.8381)  time: 0.3535  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [3690/4579]  eta: 0:05:11  Lr: 0.001875  Loss: -0.2242  Acc@1: 62.5000 (62.2646)  Acc@5: 93.7500 (90.8409)  time: 0.3527  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [3700/4579]  eta: 0:05:08  Lr: 0.001875  Loss: -0.5038  Acc@1: 62.5000 (62.2686)  Acc@5: 93.7500 (90.8403)  time: 0.3515  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [3710/4579]  eta: 0:05:04  Lr: 0.001875  Loss: -0.2751  Acc@1: 62.5000 (62.2726)  Acc@5: 93.7500 (90.8397)  time: 0.3541  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [3720/4579]  eta: 0:05:01  Lr: 0.001875  Loss: -0.0735  Acc@1: 68.7500 (62.2732)  Acc@5: 93.7500 (90.8408)  time: 0.3530  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [3730/4579]  eta: 0:04:57  Lr: 0.001875  Loss: -0.2374  Acc@1: 68.7500 (62.2755)  Acc@5: 93.7500 (90.8470)  time: 0.3515  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [3740/4579]  eta: 0:04:54  Lr: 0.001875  Loss: -0.3863  Acc@1: 62.5000 (62.2778)  Acc@5: 93.7500 (90.8397)  time: 0.3514  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [3750/4579]  eta: 0:04:50  Lr: 0.001875  Loss: -0.1730  Acc@1: 62.5000 (62.2934)  Acc@5: 93.7500 (90.8508)  time: 0.3578  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [3760/4579]  eta: 0:04:47  Lr: 0.001875  Loss: 0.0708  Acc@1: 68.7500 (62.3056)  Acc@5: 93.7500 (90.8518)  time: 0.3555  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3770/4579]  eta: 0:04:43  Lr: 0.001875  Loss: -0.4460  Acc@1: 62.5000 (62.3044)  Acc@5: 93.7500 (90.8595)  time: 0.3474  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3780/4579]  eta: 0:04:40  Lr: 0.001875  Loss: -0.3827  Acc@1: 62.5000 (62.2983)  Acc@5: 93.7500 (90.8655)  time: 0.3484  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3790/4579]  eta: 0:04:36  Lr: 0.001875  Loss: -0.2232  Acc@1: 62.5000 (62.3104)  Acc@5: 93.7500 (90.8715)  time: 0.3489  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [3800/4579]  eta: 0:04:32  Lr: 0.001875  Loss: -0.0046  Acc@1: 56.2500 (62.2961)  Acc@5: 93.7500 (90.8823)  time: 0.3495  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [3810/4579]  eta: 0:04:29  Lr: 0.001875  Loss: -0.6588  Acc@1: 56.2500 (62.2884)  Acc@5: 87.5000 (90.8718)  time: 0.3474  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [3820/4579]  eta: 0:04:25  Lr: 0.001875  Loss: -0.0638  Acc@1: 62.5000 (62.2972)  Acc@5: 87.5000 (90.8794)  time: 0.3451  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [3830/4579]  eta: 0:04:22  Lr: 0.001875  Loss: -0.0091  Acc@1: 62.5000 (62.2977)  Acc@5: 93.7500 (90.8803)  time: 0.3461  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3840/4579]  eta: 0:04:18  Lr: 0.001875  Loss: -0.0208  Acc@1: 62.5000 (62.2950)  Acc@5: 93.7500 (90.8797)  time: 0.3466  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [3850/4579]  eta: 0:04:15  Lr: 0.001875  Loss: -0.0161  Acc@1: 62.5000 (62.3036)  Acc@5: 93.7500 (90.8757)  time: 0.3485  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3860/4579]  eta: 0:04:11  Lr: 0.001875  Loss: 0.2901  Acc@1: 68.7500 (62.3219)  Acc@5: 87.5000 (90.8751)  time: 0.3520  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [3870/4579]  eta: 0:04:08  Lr: 0.001875  Loss: -0.0615  Acc@1: 68.7500 (62.3385)  Acc@5: 93.7500 (90.8841)  time: 0.3514  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [3880/4579]  eta: 0:04:04  Lr: 0.001875  Loss: 0.0383  Acc@1: 75.0000 (62.3647)  Acc@5: 93.7500 (90.8947)  time: 0.3502  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [3890/4579]  eta: 0:04:01  Lr: 0.001875  Loss: -0.2834  Acc@1: 62.5000 (62.3635)  Acc@5: 93.7500 (90.8876)  time: 0.3502  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [3900/4579]  eta: 0:03:57  Lr: 0.001875  Loss: -0.2912  Acc@1: 62.5000 (62.3510)  Acc@5: 87.5000 (90.8886)  time: 0.3501  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [3910/4579]  eta: 0:03:54  Lr: 0.001875  Loss: -0.0266  Acc@1: 62.5000 (62.3578)  Acc@5: 93.7500 (90.8847)  time: 0.3540  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [3920/4579]  eta: 0:03:50  Lr: 0.001875  Loss: -0.1288  Acc@1: 62.5000 (62.3549)  Acc@5: 87.5000 (90.8856)  time: 0.3555  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [3930/4579]  eta: 0:03:47  Lr: 0.001875  Loss: -0.2813  Acc@1: 62.5000 (62.3458)  Acc@5: 93.7500 (90.8897)  time: 0.3537  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [3940/4579]  eta: 0:03:43  Lr: 0.001875  Loss: -0.6864  Acc@1: 62.5000 (62.3620)  Acc@5: 93.7500 (90.8922)  time: 0.3564  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [3950/4579]  eta: 0:03:40  Lr: 0.001875  Loss: -0.2178  Acc@1: 68.7500 (62.3671)  Acc@5: 93.7500 (90.8947)  time: 0.3544  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [3960/4579]  eta: 0:03:36  Lr: 0.001875  Loss: -0.1033  Acc@1: 62.5000 (62.3706)  Acc@5: 87.5000 (90.8925)  time: 0.3493  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [3970/4579]  eta: 0:03:33  Lr: 0.001875  Loss: -0.5326  Acc@1: 62.5000 (62.3772)  Acc@5: 93.7500 (90.8996)  time: 0.3499  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [3980/4579]  eta: 0:03:29  Lr: 0.001875  Loss: -0.4422  Acc@1: 62.5000 (62.3728)  Acc@5: 93.7500 (90.8974)  time: 0.3493  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [3990/4579]  eta: 0:03:26  Lr: 0.001875  Loss: -0.2266  Acc@1: 56.2500 (62.3669)  Acc@5: 87.5000 (90.8951)  time: 0.3487  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [4000/4579]  eta: 0:03:22  Lr: 0.001875  Loss: -0.7901  Acc@1: 56.2500 (62.3688)  Acc@5: 93.7500 (90.9023)  time: 0.3477  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [4010/4579]  eta: 0:03:19  Lr: 0.001875  Loss: 0.1559  Acc@1: 62.5000 (62.3722)  Acc@5: 93.7500 (90.9016)  time: 0.3479  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [4020/4579]  eta: 0:03:15  Lr: 0.001875  Loss: 0.3352  Acc@1: 62.5000 (62.3679)  Acc@5: 93.7500 (90.9102)  time: 0.3476  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [4030/4579]  eta: 0:03:12  Lr: 0.001875  Loss: -0.1530  Acc@1: 62.5000 (62.3775)  Acc@5: 93.7500 (90.9126)  time: 0.3450  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [4040/4579]  eta: 0:03:08  Lr: 0.001875  Loss: -0.3454  Acc@1: 68.7500 (62.3886)  Acc@5: 87.5000 (90.9119)  time: 0.3460  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [4050/4579]  eta: 0:03:05  Lr: 0.001875  Loss: -0.4860  Acc@1: 68.7500 (62.3920)  Acc@5: 87.5000 (90.9127)  time: 0.3562  data: 0.0011  max mem: 2500
Train: Epoch[2/5]  [4060/4579]  eta: 0:03:01  Lr: 0.001875  Loss: 0.0117  Acc@1: 62.5000 (62.3938)  Acc@5: 93.7500 (90.9197)  time: 0.3563  data: 0.0013  max mem: 2500
Train: Epoch[2/5]  [4070/4579]  eta: 0:02:58  Lr: 0.001875  Loss: -0.0116  Acc@1: 56.2500 (62.3910)  Acc@5: 93.7500 (90.9221)  time: 0.3485  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [4080/4579]  eta: 0:02:54  Lr: 0.001875  Loss: -0.3615  Acc@1: 62.5000 (62.3913)  Acc@5: 93.7500 (90.9244)  time: 0.3535  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [4090/4579]  eta: 0:02:51  Lr: 0.001875  Loss: -0.0224  Acc@1: 62.5000 (62.3976)  Acc@5: 93.7500 (90.9267)  time: 0.3626  data: 0.0010  max mem: 2500
Train: Epoch[2/5]  [4100/4579]  eta: 0:02:47  Lr: 0.001875  Loss: 0.1347  Acc@1: 62.5000 (62.4025)  Acc@5: 93.7500 (90.9260)  time: 0.3598  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [4110/4579]  eta: 0:02:44  Lr: 0.001875  Loss: -0.0861  Acc@1: 62.5000 (62.4103)  Acc@5: 93.7500 (90.9268)  time: 0.3499  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [4120/4579]  eta: 0:02:40  Lr: 0.001875  Loss: -0.7706  Acc@1: 68.7500 (62.4196)  Acc@5: 93.7500 (90.9336)  time: 0.3516  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [4130/4579]  eta: 0:02:37  Lr: 0.001875  Loss: 0.1260  Acc@1: 62.5000 (62.4107)  Acc@5: 93.7500 (90.9344)  time: 0.3544  data: 0.0015  max mem: 2500
Train: Epoch[2/5]  [4140/4579]  eta: 0:02:33  Lr: 0.001875  Loss: -0.1443  Acc@1: 62.5000 (62.4260)  Acc@5: 93.7500 (90.9382)  time: 0.3539  data: 0.0035  max mem: 2500
Train: Epoch[2/5]  [4150/4579]  eta: 0:02:30  Lr: 0.001875  Loss: -0.4018  Acc@1: 62.5000 (62.4202)  Acc@5: 93.7500 (90.9344)  time: 0.3515  data: 0.0024  max mem: 2500
Train: Epoch[2/5]  [4160/4579]  eta: 0:02:26  Lr: 0.001875  Loss: -0.5573  Acc@1: 62.5000 (62.4264)  Acc@5: 87.5000 (90.9352)  time: 0.3500  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [4170/4579]  eta: 0:02:23  Lr: 0.001875  Loss: -0.3054  Acc@1: 62.5000 (62.4296)  Acc@5: 93.7500 (90.9374)  time: 0.3501  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [4180/4579]  eta: 0:02:19  Lr: 0.001875  Loss: -0.2394  Acc@1: 62.5000 (62.4477)  Acc@5: 93.7500 (90.9427)  time: 0.3489  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [4190/4579]  eta: 0:02:16  Lr: 0.001875  Loss: -0.2250  Acc@1: 62.5000 (62.4582)  Acc@5: 93.7500 (90.9464)  time: 0.3486  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [4200/4579]  eta: 0:02:12  Lr: 0.001875  Loss: 0.0524  Acc@1: 62.5000 (62.4479)  Acc@5: 93.7500 (90.9441)  time: 0.3465  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [4210/4579]  eta: 0:02:09  Lr: 0.001875  Loss: -0.1193  Acc@1: 56.2500 (62.4362)  Acc@5: 93.7500 (90.9389)  time: 0.3456  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [4220/4579]  eta: 0:02:05  Lr: 0.001875  Loss: -0.2083  Acc@1: 56.2500 (62.4423)  Acc@5: 93.7500 (90.9456)  time: 0.3495  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [4230/4579]  eta: 0:02:02  Lr: 0.001875  Loss: -0.2671  Acc@1: 68.7500 (62.4660)  Acc@5: 93.7500 (90.9492)  time: 0.3503  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [4240/4579]  eta: 0:01:58  Lr: 0.001875  Loss: -0.0992  Acc@1: 68.7500 (62.4691)  Acc@5: 93.7500 (90.9455)  time: 0.3481  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [4250/4579]  eta: 0:01:55  Lr: 0.001875  Loss: 0.2111  Acc@1: 62.5000 (62.4588)  Acc@5: 87.5000 (90.9433)  time: 0.3488  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [4260/4579]  eta: 0:01:51  Lr: 0.001875  Loss: -0.2593  Acc@1: 56.2500 (62.4575)  Acc@5: 87.5000 (90.9440)  time: 0.3532  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [4270/4579]  eta: 0:01:48  Lr: 0.001875  Loss: 0.1810  Acc@1: 56.2500 (62.4502)  Acc@5: 93.7500 (90.9462)  time: 0.3555  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [4280/4579]  eta: 0:01:44  Lr: 0.001875  Loss: -0.4125  Acc@1: 56.2500 (62.4474)  Acc@5: 93.7500 (90.9396)  time: 0.3513  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [4290/4579]  eta: 0:01:41  Lr: 0.001875  Loss: -0.5659  Acc@1: 62.5000 (62.4461)  Acc@5: 93.7500 (90.9418)  time: 0.3504  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [4300/4579]  eta: 0:01:37  Lr: 0.001875  Loss: -0.2886  Acc@1: 62.5000 (62.4375)  Acc@5: 93.7500 (90.9367)  time: 0.3505  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [4310/4579]  eta: 0:01:34  Lr: 0.001875  Loss: -0.7118  Acc@1: 56.2500 (62.4304)  Acc@5: 87.5000 (90.9316)  time: 0.3547  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [4320/4579]  eta: 0:01:30  Lr: 0.001875  Loss: -0.4497  Acc@1: 62.5000 (62.4450)  Acc@5: 87.5000 (90.9280)  time: 0.3558  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [4330/4579]  eta: 0:01:27  Lr: 0.001875  Loss: -0.2080  Acc@1: 62.5000 (62.4408)  Acc@5: 87.5000 (90.9230)  time: 0.3502  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [4340/4579]  eta: 0:01:23  Lr: 0.001875  Loss: -0.7004  Acc@1: 62.5000 (62.4554)  Acc@5: 93.7500 (90.9266)  time: 0.3490  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [4350/4579]  eta: 0:01:20  Lr: 0.001875  Loss: -0.2128  Acc@1: 62.5000 (62.4655)  Acc@5: 93.7500 (90.9274)  time: 0.3489  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [4360/4579]  eta: 0:01:16  Lr: 0.001875  Loss: 0.0445  Acc@1: 62.5000 (62.4584)  Acc@5: 87.5000 (90.9224)  time: 0.3513  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [4370/4579]  eta: 0:01:13  Lr: 0.001875  Loss: 0.0947  Acc@1: 68.7500 (62.4743)  Acc@5: 87.5000 (90.9274)  time: 0.3491  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [4380/4579]  eta: 0:01:09  Lr: 0.001875  Loss: -0.3807  Acc@1: 68.7500 (62.4643)  Acc@5: 93.7500 (90.9339)  time: 0.3454  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [4390/4579]  eta: 0:01:06  Lr: 0.001875  Loss: 0.1453  Acc@1: 62.5000 (62.4616)  Acc@5: 93.7500 (90.9303)  time: 0.3467  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [4400/4579]  eta: 0:01:02  Lr: 0.001875  Loss: -0.5402  Acc@1: 62.5000 (62.4673)  Acc@5: 93.7500 (90.9296)  time: 0.3478  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [4410/4579]  eta: 0:00:59  Lr: 0.001875  Loss: -0.2248  Acc@1: 68.7500 (62.4688)  Acc@5: 93.7500 (90.9289)  time: 0.3476  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [4420/4579]  eta: 0:00:55  Lr: 0.001875  Loss: -0.6075  Acc@1: 62.5000 (62.4675)  Acc@5: 93.7500 (90.9424)  time: 0.3506  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [4430/4579]  eta: 0:00:52  Lr: 0.001875  Loss: -0.0429  Acc@1: 62.5000 (62.4732)  Acc@5: 93.7500 (90.9417)  time: 0.3538  data: 0.0014  max mem: 2500
Train: Epoch[2/5]  [4440/4579]  eta: 0:00:48  Lr: 0.001875  Loss: -0.7867  Acc@1: 68.7500 (62.4859)  Acc@5: 87.5000 (90.9409)  time: 0.3549  data: 0.0026  max mem: 2500
Train: Epoch[2/5]  [4450/4579]  eta: 0:00:45  Lr: 0.001875  Loss: -0.3134  Acc@1: 68.7500 (62.4902)  Acc@5: 87.5000 (90.9360)  time: 0.3558  data: 0.0021  max mem: 2500
Train: Epoch[2/5]  [4460/4579]  eta: 0:00:41  Lr: 0.001875  Loss: -0.1079  Acc@1: 68.7500 (62.5098)  Acc@5: 93.7500 (90.9451)  time: 0.3544  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [4470/4579]  eta: 0:00:38  Lr: 0.001875  Loss: -0.5210  Acc@1: 68.7500 (62.5294)  Acc@5: 93.7500 (90.9514)  time: 0.3515  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [4480/4579]  eta: 0:00:34  Lr: 0.001875  Loss: -0.1922  Acc@1: 68.7500 (62.5460)  Acc@5: 93.7500 (90.9493)  time: 0.3530  data: 0.0018  max mem: 2500
Train: Epoch[2/5]  [4490/4579]  eta: 0:00:31  Lr: 0.001875  Loss: -0.3699  Acc@1: 68.7500 (62.5543)  Acc@5: 87.5000 (90.9416)  time: 0.3557  data: 0.0032  max mem: 2500
Train: Epoch[2/5]  [4500/4579]  eta: 0:00:27  Lr: 0.001875  Loss: -0.2900  Acc@1: 62.5000 (62.5528)  Acc@5: 87.5000 (90.9270)  time: 0.3514  data: 0.0019  max mem: 2500
Train: Epoch[2/5]  [4510/4579]  eta: 0:00:24  Lr: 0.001875  Loss: 0.0217  Acc@1: 62.5000 (62.5568)  Acc@5: 87.5000 (90.9305)  time: 0.3476  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [4520/4579]  eta: 0:00:20  Lr: 0.001875  Loss: -0.0546  Acc@1: 62.5000 (62.5581)  Acc@5: 93.7500 (90.9340)  time: 0.3479  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [4530/4579]  eta: 0:00:17  Lr: 0.001875  Loss: -0.2835  Acc@1: 62.5000 (62.5635)  Acc@5: 87.5000 (90.9250)  time: 0.3489  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [4540/4579]  eta: 0:00:13  Lr: 0.001875  Loss: -0.1045  Acc@1: 62.5000 (62.5633)  Acc@5: 87.5000 (90.9285)  time: 0.3510  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [4550/4579]  eta: 0:00:10  Lr: 0.001875  Loss: -0.4317  Acc@1: 62.5000 (62.5645)  Acc@5: 87.5000 (90.9264)  time: 0.3488  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [4560/4579]  eta: 0:00:06  Lr: 0.001875  Loss: 0.3808  Acc@1: 56.2500 (62.5630)  Acc@5: 87.5000 (90.9244)  time: 0.3453  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [4570/4579]  eta: 0:00:03  Lr: 0.001875  Loss: -0.1555  Acc@1: 62.5000 (62.5670)  Acc@5: 87.5000 (90.9224)  time: 0.3483  data: 0.0010  max mem: 2500
Train: Epoch[2/5]  [4578/4579]  eta: 0:00:00  Lr: 0.001875  Loss: -0.2828  Acc@1: 62.5000 (62.5701)  Acc@5: 93.7500 (90.9265)  time: 0.3416  data: 0.0010  max mem: 2500
Train: Epoch[2/5] Total time: 0:26:45 (0.3506 s / it)
{0: {0: 146514, 1: 0, 2: 0, 3: 0, 4: 0}, 1: {0: 146514, 1: 0, 2: 0, 3: 0, 4: 0}, 2: {0: 146514, 1: 0, 2: 0, 3: 0, 4: 0}, 3: {0: 146514, 1: 0, 2: 0, 3: 0, 4: 0}, 4: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 5: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 6: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 7: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 8: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 9: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 10: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 11: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 12: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 13: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 14: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 15: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 16: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 17: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 18: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 19: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}}
Averaged stats: Lr: 0.001875  Loss: -0.2828  Acc@1: 62.5000 (62.5701)  Acc@5: 93.7500 (90.9265)
Train: Epoch[3/5]  [   0/4579]  eta: 0:57:11  Lr: 0.001875  Loss: 0.1665  Acc@1: 56.2500 (56.2500)  Acc@5: 81.2500 (81.2500)  time: 0.7494  data: 0.4034  max mem: 2500
Train: Epoch[3/5]  [  10/4579]  eta: 0:29:10  Lr: 0.001875  Loss: -0.4356  Acc@1: 75.0000 (71.0227)  Acc@5: 100.0000 (96.0227)  time: 0.3832  data: 0.0369  max mem: 2500
Train: Epoch[3/5]  [  20/4579]  eta: 0:27:53  Lr: 0.001875  Loss: -0.0685  Acc@1: 68.7500 (67.2619)  Acc@5: 87.5000 (91.3690)  time: 0.3479  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [  30/4579]  eta: 0:27:41  Lr: 0.001875  Loss: 0.1692  Acc@1: 68.7500 (66.9355)  Acc@5: 87.5000 (91.5323)  time: 0.3552  data: 0.0027  max mem: 2500
Train: Epoch[3/5]  [  40/4579]  eta: 0:27:24  Lr: 0.001875  Loss: -0.7835  Acc@1: 68.7500 (67.2256)  Acc@5: 93.7500 (91.3110)  time: 0.3572  data: 0.0028  max mem: 2500
Train: Epoch[3/5]  [  50/4579]  eta: 0:27:10  Lr: 0.001875  Loss: -0.0290  Acc@1: 62.5000 (65.4412)  Acc@5: 87.5000 (90.5637)  time: 0.3519  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [  60/4579]  eta: 0:27:00  Lr: 0.001875  Loss: -0.1440  Acc@1: 68.7500 (66.0861)  Acc@5: 87.5000 (90.8811)  time: 0.3514  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [  70/4579]  eta: 0:26:51  Lr: 0.001875  Loss: -0.1329  Acc@1: 68.7500 (65.0528)  Acc@5: 87.5000 (90.4049)  time: 0.3509  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [  80/4579]  eta: 0:26:46  Lr: 0.001875  Loss: -0.6670  Acc@1: 62.5000 (65.2006)  Acc@5: 87.5000 (90.6636)  time: 0.3524  data: 0.0014  max mem: 2500
Train: Epoch[3/5]  [  90/4579]  eta: 0:26:41  Lr: 0.001875  Loss: -0.3475  Acc@1: 62.5000 (64.9038)  Acc@5: 87.5000 (90.4533)  time: 0.3543  data: 0.0021  max mem: 2500
Train: Epoch[3/5]  [ 100/4579]  eta: 0:26:36  Lr: 0.001875  Loss: -0.6469  Acc@1: 62.5000 (64.7896)  Acc@5: 93.7500 (90.8416)  time: 0.3539  data: 0.0014  max mem: 2500
Train: Epoch[3/5]  [ 110/4579]  eta: 0:26:30  Lr: 0.001875  Loss: -0.2741  Acc@1: 68.7500 (64.9775)  Acc@5: 93.7500 (90.9347)  time: 0.3517  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [ 120/4579]  eta: 0:26:25  Lr: 0.001875  Loss: -0.2138  Acc@1: 68.7500 (65.2376)  Acc@5: 93.7500 (91.2190)  time: 0.3506  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [ 130/4579]  eta: 0:26:20  Lr: 0.001875  Loss: -0.4662  Acc@1: 68.7500 (65.3626)  Acc@5: 93.7500 (91.2691)  time: 0.3516  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [ 140/4579]  eta: 0:26:14  Lr: 0.001875  Loss: -0.1952  Acc@1: 62.5000 (65.2926)  Acc@5: 93.7500 (91.4450)  time: 0.3496  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [ 150/4579]  eta: 0:26:09  Lr: 0.001875  Loss: -0.6669  Acc@1: 62.5000 (65.5629)  Acc@5: 93.7500 (91.5149)  time: 0.3497  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 160/4579]  eta: 0:26:04  Lr: 0.001875  Loss: -0.0969  Acc@1: 68.7500 (65.7609)  Acc@5: 87.5000 (91.5373)  time: 0.3486  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 170/4579]  eta: 0:25:58  Lr: 0.001875  Loss: -0.3648  Acc@1: 62.5000 (65.7895)  Acc@5: 93.7500 (91.5570)  time: 0.3459  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 180/4579]  eta: 0:25:52  Lr: 0.001875  Loss: -0.4843  Acc@1: 62.5000 (65.9876)  Acc@5: 93.7500 (91.6436)  time: 0.3452  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [ 190/4579]  eta: 0:25:47  Lr: 0.001875  Loss: -0.3768  Acc@1: 62.5000 (65.7395)  Acc@5: 93.7500 (91.4921)  time: 0.3450  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 200/4579]  eta: 0:25:42  Lr: 0.001875  Loss: -0.5079  Acc@1: 56.2500 (65.4540)  Acc@5: 93.7500 (91.6978)  time: 0.3467  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [ 210/4579]  eta: 0:25:39  Lr: 0.001875  Loss: -0.3126  Acc@1: 62.5000 (65.6102)  Acc@5: 93.7500 (91.7950)  time: 0.3497  data: 0.0009  max mem: 2500
Train: Epoch[3/5]  [ 220/4579]  eta: 0:25:35  Lr: 0.001875  Loss: 0.3183  Acc@1: 62.5000 (65.3281)  Acc@5: 93.7500 (91.8269)  time: 0.3510  data: 0.0009  max mem: 2500
Train: Epoch[3/5]  [ 230/4579]  eta: 0:25:32  Lr: 0.001875  Loss: -0.6515  Acc@1: 62.5000 (65.3139)  Acc@5: 93.7500 (91.8290)  time: 0.3533  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [ 240/4579]  eta: 0:25:29  Lr: 0.001875  Loss: -0.4096  Acc@1: 68.7500 (65.4824)  Acc@5: 93.7500 (91.8050)  time: 0.3567  data: 0.0009  max mem: 2500
Train: Epoch[3/5]  [ 250/4579]  eta: 0:25:27  Lr: 0.001875  Loss: -0.2539  Acc@1: 68.7500 (65.4133)  Acc@5: 93.7500 (91.8825)  time: 0.3571  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [ 260/4579]  eta: 0:25:23  Lr: 0.001875  Loss: -0.7877  Acc@1: 62.5000 (65.4215)  Acc@5: 93.7500 (91.9301)  time: 0.3535  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [ 270/4579]  eta: 0:25:19  Lr: 0.001875  Loss: 0.0354  Acc@1: 62.5000 (65.3828)  Acc@5: 93.7500 (92.0203)  time: 0.3500  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [ 280/4579]  eta: 0:25:15  Lr: 0.001875  Loss: -0.3226  Acc@1: 62.5000 (65.3692)  Acc@5: 93.7500 (91.9484)  time: 0.3520  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [ 290/4579]  eta: 0:25:12  Lr: 0.001875  Loss: -0.3106  Acc@1: 62.5000 (65.4424)  Acc@5: 93.7500 (92.0318)  time: 0.3545  data: 0.0015  max mem: 2500
Train: Epoch[3/5]  [ 300/4579]  eta: 0:25:09  Lr: 0.001875  Loss: -0.3268  Acc@1: 62.5000 (65.1993)  Acc@5: 93.7500 (91.9228)  time: 0.3562  data: 0.0015  max mem: 2500
Train: Epoch[3/5]  [ 310/4579]  eta: 0:25:05  Lr: 0.001875  Loss: 0.3804  Acc@1: 62.5000 (65.0322)  Acc@5: 93.7500 (91.8408)  time: 0.3526  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 320/4579]  eta: 0:25:01  Lr: 0.001875  Loss: 0.0423  Acc@1: 62.5000 (65.0312)  Acc@5: 93.7500 (91.8419)  time: 0.3477  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 330/4579]  eta: 0:24:58  Lr: 0.001875  Loss: -0.1259  Acc@1: 62.5000 (64.8603)  Acc@5: 93.7500 (91.7485)  time: 0.3514  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 340/4579]  eta: 0:24:54  Lr: 0.001875  Loss: 0.2455  Acc@1: 62.5000 (64.7911)  Acc@5: 93.7500 (91.6789)  time: 0.3525  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [ 350/4579]  eta: 0:24:50  Lr: 0.001875  Loss: -0.2219  Acc@1: 62.5000 (64.6902)  Acc@5: 93.7500 (91.6845)  time: 0.3492  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [ 360/4579]  eta: 0:24:45  Lr: 0.001875  Loss: -0.1262  Acc@1: 62.5000 (64.5602)  Acc@5: 93.7500 (91.7071)  time: 0.3465  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [ 370/4579]  eta: 0:24:41  Lr: 0.001875  Loss: -0.1739  Acc@1: 62.5000 (64.4373)  Acc@5: 93.7500 (91.6442)  time: 0.3453  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [ 380/4579]  eta: 0:24:37  Lr: 0.001875  Loss: -0.3391  Acc@1: 62.5000 (64.5833)  Acc@5: 93.7500 (91.6667)  time: 0.3474  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [ 390/4579]  eta: 0:24:33  Lr: 0.001875  Loss: -0.4654  Acc@1: 68.7500 (64.6100)  Acc@5: 93.7500 (91.7040)  time: 0.3471  data: 0.0009  max mem: 2500
Train: Epoch[3/5]  [ 400/4579]  eta: 0:24:29  Lr: 0.001875  Loss: 0.1441  Acc@1: 68.7500 (64.6197)  Acc@5: 93.7500 (91.7394)  time: 0.3464  data: 0.0010  max mem: 2500
Train: Epoch[3/5]  [ 410/4579]  eta: 0:24:26  Lr: 0.001875  Loss: -0.5478  Acc@1: 68.7500 (64.6898)  Acc@5: 93.7500 (91.8187)  time: 0.3520  data: 0.0013  max mem: 2500
Train: Epoch[3/5]  [ 420/4579]  eta: 0:24:23  Lr: 0.001875  Loss: -0.1960  Acc@1: 68.7500 (64.7120)  Acc@5: 93.7500 (91.8498)  time: 0.3562  data: 0.0022  max mem: 2500
Train: Epoch[3/5]  [ 430/4579]  eta: 0:24:19  Lr: 0.001875  Loss: -0.3478  Acc@1: 62.5000 (64.6607)  Acc@5: 93.7500 (91.8794)  time: 0.3527  data: 0.0014  max mem: 2500
Train: Epoch[3/5]  [ 440/4579]  eta: 0:24:15  Lr: 0.001875  Loss: -0.2206  Acc@1: 62.5000 (64.6117)  Acc@5: 93.7500 (91.8367)  time: 0.3485  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [ 450/4579]  eta: 0:24:12  Lr: 0.001875  Loss: -0.3354  Acc@1: 62.5000 (64.6341)  Acc@5: 87.5000 (91.8514)  time: 0.3495  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [ 460/4579]  eta: 0:24:08  Lr: 0.001875  Loss: 0.1763  Acc@1: 62.5000 (64.5743)  Acc@5: 87.5000 (91.8384)  time: 0.3523  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [ 470/4579]  eta: 0:24:05  Lr: 0.001875  Loss: 0.1018  Acc@1: 62.5000 (64.5303)  Acc@5: 93.7500 (91.9055)  time: 0.3544  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [ 480/4579]  eta: 0:24:02  Lr: 0.001875  Loss: -0.2368  Acc@1: 62.5000 (64.5920)  Acc@5: 93.7500 (91.8529)  time: 0.3544  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [ 490/4579]  eta: 0:23:58  Lr: 0.001875  Loss: 0.3556  Acc@1: 62.5000 (64.5748)  Acc@5: 87.5000 (91.8534)  time: 0.3504  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [ 500/4579]  eta: 0:23:54  Lr: 0.001875  Loss: -0.1480  Acc@1: 62.5000 (64.5709)  Acc@5: 93.7500 (91.8787)  time: 0.3483  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [ 510/4579]  eta: 0:23:51  Lr: 0.001875  Loss: 0.1269  Acc@1: 62.5000 (64.5548)  Acc@5: 93.7500 (91.9154)  time: 0.3494  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 520/4579]  eta: 0:23:47  Lr: 0.001875  Loss: -0.0213  Acc@1: 68.7500 (64.5873)  Acc@5: 93.7500 (91.9266)  time: 0.3492  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [ 530/4579]  eta: 0:23:43  Lr: 0.001875  Loss: -0.2755  Acc@1: 68.7500 (64.6304)  Acc@5: 93.7500 (91.9962)  time: 0.3482  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 540/4579]  eta: 0:23:39  Lr: 0.001875  Loss: -0.2702  Acc@1: 68.7500 (64.7759)  Acc@5: 93.7500 (92.0402)  time: 0.3466  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [ 550/4579]  eta: 0:23:35  Lr: 0.001875  Loss: -0.1717  Acc@1: 68.7500 (64.7686)  Acc@5: 87.5000 (91.9691)  time: 0.3462  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [ 560/4579]  eta: 0:23:31  Lr: 0.001875  Loss: -0.5465  Acc@1: 62.5000 (64.7170)  Acc@5: 87.5000 (91.9340)  time: 0.3478  data: 0.0015  max mem: 2500
Train: Epoch[3/5]  [ 570/4579]  eta: 0:23:27  Lr: 0.001875  Loss: -0.6318  Acc@1: 62.5000 (64.7548)  Acc@5: 87.5000 (91.9549)  time: 0.3469  data: 0.0014  max mem: 2500
Train: Epoch[3/5]  [ 580/4579]  eta: 0:23:24  Lr: 0.001875  Loss: -0.1805  Acc@1: 62.5000 (64.6515)  Acc@5: 87.5000 (91.8675)  time: 0.3469  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 590/4579]  eta: 0:23:21  Lr: 0.001875  Loss: -0.4233  Acc@1: 62.5000 (64.6362)  Acc@5: 87.5000 (91.8359)  time: 0.3533  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [ 600/4579]  eta: 0:23:17  Lr: 0.001875  Loss: 0.3418  Acc@1: 68.7500 (64.6423)  Acc@5: 93.7500 (91.8261)  time: 0.3567  data: 0.0009  max mem: 2500
Train: Epoch[3/5]  [ 610/4579]  eta: 0:23:14  Lr: 0.001875  Loss: -0.2751  Acc@1: 68.7500 (64.6174)  Acc@5: 93.7500 (91.7860)  time: 0.3525  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [ 620/4579]  eta: 0:23:11  Lr: 0.001875  Loss: 0.0550  Acc@1: 62.5000 (64.5431)  Acc@5: 87.5000 (91.7472)  time: 0.3522  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [ 630/4579]  eta: 0:23:07  Lr: 0.001875  Loss: -0.1021  Acc@1: 68.7500 (64.6395)  Acc@5: 93.7500 (91.7789)  time: 0.3551  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [ 640/4579]  eta: 0:23:04  Lr: 0.001875  Loss: -0.4836  Acc@1: 68.7500 (64.6646)  Acc@5: 93.7500 (91.7122)  time: 0.3587  data: 0.0019  max mem: 2500
Train: Epoch[3/5]  [ 650/4579]  eta: 0:23:01  Lr: 0.001875  Loss: -0.2785  Acc@1: 68.7500 (64.7849)  Acc@5: 93.7500 (91.6955)  time: 0.3571  data: 0.0019  max mem: 2500
Train: Epoch[3/5]  [ 660/4579]  eta: 0:22:58  Lr: 0.001875  Loss: -0.3792  Acc@1: 68.7500 (64.8166)  Acc@5: 93.7500 (91.7266)  time: 0.3525  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [ 670/4579]  eta: 0:22:54  Lr: 0.001875  Loss: -0.2398  Acc@1: 68.7500 (64.7820)  Acc@5: 93.7500 (91.7288)  time: 0.3513  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [ 680/4579]  eta: 0:22:51  Lr: 0.001875  Loss: -0.3832  Acc@1: 68.7500 (64.8678)  Acc@5: 93.7500 (91.7493)  time: 0.3521  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [ 690/4579]  eta: 0:22:47  Lr: 0.001875  Loss: -0.5221  Acc@1: 68.7500 (64.8788)  Acc@5: 93.7500 (91.7601)  time: 0.3526  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [ 700/4579]  eta: 0:22:43  Lr: 0.001875  Loss: -0.3926  Acc@1: 62.5000 (64.8449)  Acc@5: 93.7500 (91.7529)  time: 0.3491  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [ 710/4579]  eta: 0:22:40  Lr: 0.001875  Loss: -0.0550  Acc@1: 62.5000 (64.8734)  Acc@5: 93.7500 (91.7546)  time: 0.3475  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 720/4579]  eta: 0:22:36  Lr: 0.001875  Loss: -0.2559  Acc@1: 68.7500 (64.9532)  Acc@5: 93.7500 (91.7736)  time: 0.3479  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 730/4579]  eta: 0:22:32  Lr: 0.001875  Loss: -0.0052  Acc@1: 62.5000 (64.8769)  Acc@5: 93.7500 (91.7750)  time: 0.3480  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 740/4579]  eta: 0:22:28  Lr: 0.001875  Loss: -0.3854  Acc@1: 62.5000 (64.9460)  Acc@5: 93.7500 (91.8185)  time: 0.3468  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [ 750/4579]  eta: 0:22:24  Lr: 0.001875  Loss: -0.3717  Acc@1: 62.5000 (64.9051)  Acc@5: 93.7500 (91.8442)  time: 0.3455  data: 0.0002  max mem: 2500
Train: Epoch[3/5]  [ 760/4579]  eta: 0:22:21  Lr: 0.001875  Loss: -0.3146  Acc@1: 56.2500 (64.7750)  Acc@5: 87.5000 (91.8035)  time: 0.3459  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 770/4579]  eta: 0:22:18  Lr: 0.001875  Loss: -0.2770  Acc@1: 62.5000 (64.7860)  Acc@5: 93.7500 (91.8126)  time: 0.3520  data: 0.0013  max mem: 2500
Train: Epoch[3/5]  [ 780/4579]  eta: 0:22:14  Lr: 0.001875  Loss: -0.4128  Acc@1: 62.5000 (64.7567)  Acc@5: 93.7500 (91.8454)  time: 0.3536  data: 0.0013  max mem: 2500
Train: Epoch[3/5]  [ 790/4579]  eta: 0:22:10  Lr: 0.001875  Loss: -0.3876  Acc@1: 62.5000 (64.7756)  Acc@5: 93.7500 (91.8616)  time: 0.3493  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 800/4579]  eta: 0:22:07  Lr: 0.001875  Loss: -0.3052  Acc@1: 68.7500 (64.7784)  Acc@5: 93.7500 (91.8461)  time: 0.3501  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [ 810/4579]  eta: 0:22:03  Lr: 0.001875  Loss: -0.4477  Acc@1: 62.5000 (64.7349)  Acc@5: 93.7500 (91.8465)  time: 0.3529  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 820/4579]  eta: 0:22:00  Lr: 0.001875  Loss: -0.2994  Acc@1: 56.2500 (64.6924)  Acc@5: 93.7500 (91.9153)  time: 0.3536  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [ 830/4579]  eta: 0:21:56  Lr: 0.001875  Loss: 0.1320  Acc@1: 62.5000 (64.7262)  Acc@5: 100.0000 (91.9675)  time: 0.3506  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [ 840/4579]  eta: 0:21:53  Lr: 0.001875  Loss: 0.1115  Acc@1: 68.7500 (64.6998)  Acc@5: 93.7500 (91.9515)  time: 0.3499  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [ 850/4579]  eta: 0:21:49  Lr: 0.001875  Loss: -0.3144  Acc@1: 68.7500 (64.7253)  Acc@5: 93.7500 (91.9580)  time: 0.3503  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [ 860/4579]  eta: 0:21:46  Lr: 0.001875  Loss: -0.0466  Acc@1: 68.7500 (64.7503)  Acc@5: 93.7500 (91.9715)  time: 0.3499  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [ 870/4579]  eta: 0:21:42  Lr: 0.001875  Loss: -0.0192  Acc@1: 62.5000 (64.6886)  Acc@5: 93.7500 (91.9059)  time: 0.3504  data: 0.0009  max mem: 2500
Train: Epoch[3/5]  [ 880/4579]  eta: 0:21:38  Lr: 0.001875  Loss: -0.3033  Acc@1: 62.5000 (64.6779)  Acc@5: 87.5000 (91.8913)  time: 0.3493  data: 0.0009  max mem: 2500
Train: Epoch[3/5]  [ 890/4579]  eta: 0:21:35  Lr: 0.001875  Loss: 0.0692  Acc@1: 68.7500 (64.7727)  Acc@5: 93.7500 (91.9192)  time: 0.3482  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 900/4579]  eta: 0:21:31  Lr: 0.001875  Loss: -0.2048  Acc@1: 68.7500 (64.8169)  Acc@5: 93.7500 (91.9395)  time: 0.3484  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [ 910/4579]  eta: 0:21:28  Lr: 0.001875  Loss: -0.6588  Acc@1: 62.5000 (64.7914)  Acc@5: 93.7500 (91.9182)  time: 0.3486  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [ 920/4579]  eta: 0:21:24  Lr: 0.001875  Loss: -0.5083  Acc@1: 56.2500 (64.7055)  Acc@5: 87.5000 (91.9042)  time: 0.3464  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [ 930/4579]  eta: 0:21:20  Lr: 0.001875  Loss: -0.5838  Acc@1: 62.5000 (64.6885)  Acc@5: 93.7500 (91.8972)  time: 0.3445  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [ 940/4579]  eta: 0:21:17  Lr: 0.001875  Loss: 0.1265  Acc@1: 62.5000 (64.6719)  Acc@5: 87.5000 (91.8637)  time: 0.3487  data: 0.0025  max mem: 2500
Train: Epoch[3/5]  [ 950/4579]  eta: 0:21:13  Lr: 0.001875  Loss: -0.0626  Acc@1: 62.5000 (64.6688)  Acc@5: 87.5000 (91.8375)  time: 0.3518  data: 0.0026  max mem: 2500
Train: Epoch[3/5]  [ 960/4579]  eta: 0:21:10  Lr: 0.001875  Loss: -0.0595  Acc@1: 62.5000 (64.6592)  Acc@5: 93.7500 (91.8574)  time: 0.3514  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [ 970/4579]  eta: 0:21:06  Lr: 0.001875  Loss: -0.0976  Acc@1: 62.5000 (64.6692)  Acc@5: 93.7500 (91.8962)  time: 0.3496  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [ 980/4579]  eta: 0:21:03  Lr: 0.001875  Loss: -0.1864  Acc@1: 62.5000 (64.6725)  Acc@5: 93.7500 (91.8960)  time: 0.3498  data: 0.0012  max mem: 2500
Train: Epoch[3/5]  [ 990/4579]  eta: 0:21:00  Lr: 0.001875  Loss: -0.7124  Acc@1: 62.5000 (64.6254)  Acc@5: 87.5000 (91.8958)  time: 0.3583  data: 0.0025  max mem: 2500
Train: Epoch[3/5]  [1000/4579]  eta: 0:20:56  Lr: 0.001875  Loss: -0.3271  Acc@1: 56.2500 (64.5917)  Acc@5: 87.5000 (91.8581)  time: 0.3576  data: 0.0018  max mem: 2500
Train: Epoch[3/5]  [1010/4579]  eta: 0:20:52  Lr: 0.001875  Loss: -0.4971  Acc@1: 62.5000 (64.5833)  Acc@5: 87.5000 (91.8274)  time: 0.3502  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [1020/4579]  eta: 0:20:49  Lr: 0.001875  Loss: -0.1213  Acc@1: 62.5000 (64.5507)  Acc@5: 93.7500 (91.8462)  time: 0.3507  data: 0.0014  max mem: 2500
Train: Epoch[3/5]  [1030/4579]  eta: 0:20:46  Lr: 0.001875  Loss: -0.5119  Acc@1: 62.5000 (64.5429)  Acc@5: 93.7500 (91.8647)  time: 0.3539  data: 0.0022  max mem: 2500
Train: Epoch[3/5]  [1040/4579]  eta: 0:20:42  Lr: 0.001875  Loss: -0.1529  Acc@1: 68.7500 (64.5353)  Acc@5: 93.7500 (91.8768)  time: 0.3574  data: 0.0014  max mem: 2500
Train: Epoch[3/5]  [1050/4579]  eta: 0:20:39  Lr: 0.001875  Loss: -0.1802  Acc@1: 62.5000 (64.5457)  Acc@5: 93.7500 (91.8649)  time: 0.3539  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [1060/4579]  eta: 0:20:35  Lr: 0.001875  Loss: -0.3783  Acc@1: 68.7500 (64.5735)  Acc@5: 93.7500 (91.8827)  time: 0.3480  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [1070/4579]  eta: 0:20:32  Lr: 0.001875  Loss: 0.4416  Acc@1: 68.7500 (64.6067)  Acc@5: 93.7500 (91.9059)  time: 0.3498  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1080/4579]  eta: 0:20:28  Lr: 0.001875  Loss: -0.2073  Acc@1: 62.5000 (64.5756)  Acc@5: 93.7500 (91.8999)  time: 0.3511  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1090/4579]  eta: 0:20:25  Lr: 0.001875  Loss: -0.8190  Acc@1: 62.5000 (64.6024)  Acc@5: 93.7500 (91.8939)  time: 0.3500  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1100/4579]  eta: 0:20:21  Lr: 0.001875  Loss: -0.2109  Acc@1: 68.7500 (64.6287)  Acc@5: 93.7500 (91.9335)  time: 0.3479  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1110/4579]  eta: 0:20:17  Lr: 0.001875  Loss: 0.0059  Acc@1: 62.5000 (64.6096)  Acc@5: 93.7500 (91.9217)  time: 0.3448  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [1120/4579]  eta: 0:20:14  Lr: 0.001875  Loss: -0.2266  Acc@1: 62.5000 (64.6409)  Acc@5: 87.5000 (91.9101)  time: 0.3459  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [1130/4579]  eta: 0:20:10  Lr: 0.001875  Loss: -0.4116  Acc@1: 62.5000 (64.6165)  Acc@5: 93.7500 (91.9209)  time: 0.3480  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [1140/4579]  eta: 0:20:06  Lr: 0.001875  Loss: -0.5118  Acc@1: 62.5000 (64.6637)  Acc@5: 93.7500 (91.9369)  time: 0.3486  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [1150/4579]  eta: 0:20:03  Lr: 0.001875  Loss: -0.4634  Acc@1: 68.7500 (64.6883)  Acc@5: 93.7500 (91.9418)  time: 0.3512  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [1160/4579]  eta: 0:20:00  Lr: 0.001875  Loss: -0.2154  Acc@1: 62.5000 (64.6425)  Acc@5: 93.7500 (91.9520)  time: 0.3574  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [1170/4579]  eta: 0:19:56  Lr: 0.001875  Loss: -0.4358  Acc@1: 56.2500 (64.6296)  Acc@5: 93.7500 (91.9460)  time: 0.3553  data: 0.0010  max mem: 2500
Train: Epoch[3/5]  [1180/4579]  eta: 0:19:53  Lr: 0.001875  Loss: -0.4450  Acc@1: 68.7500 (64.6856)  Acc@5: 93.7500 (91.9613)  time: 0.3510  data: 0.0009  max mem: 2500
Train: Epoch[3/5]  [1190/4579]  eta: 0:19:49  Lr: 0.001875  Loss: -0.1786  Acc@1: 68.7500 (64.6830)  Acc@5: 93.7500 (91.9658)  time: 0.3521  data: 0.0010  max mem: 2500
Train: Epoch[3/5]  [1200/4579]  eta: 0:19:46  Lr: 0.001875  Loss: -0.5118  Acc@1: 62.5000 (64.6753)  Acc@5: 93.7500 (91.9494)  time: 0.3557  data: 0.0029  max mem: 2500
Train: Epoch[3/5]  [1210/4579]  eta: 0:19:42  Lr: 0.001875  Loss: -0.7422  Acc@1: 68.7500 (64.6625)  Acc@5: 87.5000 (91.9385)  time: 0.3547  data: 0.0024  max mem: 2500
Train: Epoch[3/5]  [1220/4579]  eta: 0:19:39  Lr: 0.001875  Loss: 0.2542  Acc@1: 68.7500 (64.6499)  Acc@5: 93.7500 (91.9328)  time: 0.3498  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [1230/4579]  eta: 0:19:35  Lr: 0.001875  Loss: -0.3086  Acc@1: 68.7500 (64.6680)  Acc@5: 87.5000 (91.9222)  time: 0.3522  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [1240/4579]  eta: 0:19:32  Lr: 0.001875  Loss: -0.1943  Acc@1: 68.7500 (64.6807)  Acc@5: 93.7500 (91.9218)  time: 0.3510  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [1250/4579]  eta: 0:19:28  Lr: 0.001875  Loss: -0.4394  Acc@1: 68.7500 (64.6882)  Acc@5: 93.7500 (91.9015)  time: 0.3477  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1260/4579]  eta: 0:19:25  Lr: 0.001875  Loss: -0.0997  Acc@1: 68.7500 (64.6907)  Acc@5: 93.7500 (91.8963)  time: 0.3526  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [1270/4579]  eta: 0:19:21  Lr: 0.001875  Loss: 0.2873  Acc@1: 62.5000 (64.6784)  Acc@5: 93.7500 (91.8863)  time: 0.3526  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [1280/4579]  eta: 0:19:18  Lr: 0.001875  Loss: -0.2330  Acc@1: 62.5000 (64.7004)  Acc@5: 93.7500 (91.8911)  time: 0.3481  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1290/4579]  eta: 0:19:14  Lr: 0.001875  Loss: -0.0849  Acc@1: 68.7500 (64.7318)  Acc@5: 93.7500 (91.8765)  time: 0.3489  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1300/4579]  eta: 0:19:11  Lr: 0.001875  Loss: 0.0836  Acc@1: 68.7500 (64.7243)  Acc@5: 87.5000 (91.8524)  time: 0.3509  data: 0.0017  max mem: 2500
Train: Epoch[3/5]  [1310/4579]  eta: 0:19:07  Lr: 0.001875  Loss: 0.5094  Acc@1: 62.5000 (64.6930)  Acc@5: 87.5000 (91.8431)  time: 0.3487  data: 0.0016  max mem: 2500
Train: Epoch[3/5]  [1320/4579]  eta: 0:19:03  Lr: 0.001875  Loss: -0.2710  Acc@1: 56.2500 (64.6291)  Acc@5: 87.5000 (91.8055)  time: 0.3457  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [1330/4579]  eta: 0:19:00  Lr: 0.001875  Loss: -0.3537  Acc@1: 56.2500 (64.6131)  Acc@5: 87.5000 (91.8060)  time: 0.3522  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [1340/4579]  eta: 0:18:57  Lr: 0.001875  Loss: -0.2166  Acc@1: 68.7500 (64.5973)  Acc@5: 87.5000 (91.7972)  time: 0.3552  data: 0.0010  max mem: 2500
Train: Epoch[3/5]  [1350/4579]  eta: 0:18:53  Lr: 0.001875  Loss: -0.1450  Acc@1: 62.5000 (64.6095)  Acc@5: 93.7500 (91.8348)  time: 0.3526  data: 0.0011  max mem: 2500
Train: Epoch[3/5]  [1360/4579]  eta: 0:18:50  Lr: 0.001875  Loss: -0.1700  Acc@1: 62.5000 (64.5940)  Acc@5: 93.7500 (91.8121)  time: 0.3526  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [1370/4579]  eta: 0:18:46  Lr: 0.001875  Loss: -0.3506  Acc@1: 62.5000 (64.5925)  Acc@5: 87.5000 (91.7943)  time: 0.3524  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [1380/4579]  eta: 0:18:43  Lr: 0.001875  Loss: 0.0041  Acc@1: 62.5000 (64.6090)  Acc@5: 93.7500 (91.8130)  time: 0.3561  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [1390/4579]  eta: 0:18:39  Lr: 0.001875  Loss: -0.2649  Acc@1: 68.7500 (64.6073)  Acc@5: 93.7500 (91.8224)  time: 0.3555  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [1400/4579]  eta: 0:18:36  Lr: 0.001875  Loss: -0.1800  Acc@1: 68.7500 (64.5789)  Acc@5: 93.7500 (91.7782)  time: 0.3504  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [1410/4579]  eta: 0:18:32  Lr: 0.001875  Loss: -0.0448  Acc@1: 62.5000 (64.5730)  Acc@5: 87.5000 (91.7612)  time: 0.3516  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [1420/4579]  eta: 0:18:29  Lr: 0.001875  Loss: 0.0165  Acc@1: 62.5000 (64.5584)  Acc@5: 87.5000 (91.7532)  time: 0.3518  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [1430/4579]  eta: 0:18:25  Lr: 0.001875  Loss: -0.5202  Acc@1: 62.5000 (64.5877)  Acc@5: 93.7500 (91.7671)  time: 0.3508  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [1440/4579]  eta: 0:18:22  Lr: 0.001875  Loss: 0.1745  Acc@1: 62.5000 (64.5906)  Acc@5: 93.7500 (91.7809)  time: 0.3497  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1450/4579]  eta: 0:18:18  Lr: 0.001875  Loss: -0.1114  Acc@1: 62.5000 (64.5848)  Acc@5: 93.7500 (91.7815)  time: 0.3477  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1460/4579]  eta: 0:18:15  Lr: 0.001875  Loss: -0.5807  Acc@1: 62.5000 (64.5619)  Acc@5: 93.7500 (91.7736)  time: 0.3483  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1470/4579]  eta: 0:18:11  Lr: 0.001875  Loss: -0.5509  Acc@1: 62.5000 (64.5607)  Acc@5: 93.7500 (91.7701)  time: 0.3508  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [1480/4579]  eta: 0:18:07  Lr: 0.001875  Loss: 0.0837  Acc@1: 68.7500 (64.5510)  Acc@5: 93.7500 (91.7876)  time: 0.3499  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [1490/4579]  eta: 0:18:04  Lr: 0.001875  Loss: -0.2152  Acc@1: 68.7500 (64.5540)  Acc@5: 93.7500 (91.7840)  time: 0.3461  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1500/4579]  eta: 0:18:00  Lr: 0.001875  Loss: -0.4064  Acc@1: 62.5000 (64.5486)  Acc@5: 93.7500 (91.7930)  time: 0.3463  data: 0.0011  max mem: 2500
Train: Epoch[3/5]  [1510/4579]  eta: 0:17:57  Lr: 0.001875  Loss: -0.3625  Acc@1: 62.5000 (64.5309)  Acc@5: 93.7500 (91.7935)  time: 0.3524  data: 0.0021  max mem: 2500
Train: Epoch[3/5]  [1520/4579]  eta: 0:17:53  Lr: 0.001875  Loss: -0.8247  Acc@1: 68.7500 (64.5710)  Acc@5: 93.7500 (91.7940)  time: 0.3560  data: 0.0013  max mem: 2500
Train: Epoch[3/5]  [1530/4579]  eta: 0:17:50  Lr: 0.001875  Loss: -0.1231  Acc@1: 68.7500 (64.5901)  Acc@5: 93.7500 (91.7864)  time: 0.3535  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [1540/4579]  eta: 0:17:46  Lr: 0.001875  Loss: -0.2001  Acc@1: 62.5000 (64.5644)  Acc@5: 87.5000 (91.7667)  time: 0.3513  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [1550/4579]  eta: 0:17:43  Lr: 0.001875  Loss: -0.3843  Acc@1: 62.5000 (64.5632)  Acc@5: 93.7500 (91.7634)  time: 0.3554  data: 0.0012  max mem: 2500
Train: Epoch[3/5]  [1560/4579]  eta: 0:17:40  Lr: 0.001875  Loss: -0.6462  Acc@1: 62.5000 (64.5820)  Acc@5: 93.7500 (91.7721)  time: 0.3627  data: 0.0016  max mem: 2500
Train: Epoch[3/5]  [1570/4579]  eta: 0:17:36  Lr: 0.001875  Loss: 0.0135  Acc@1: 68.7500 (64.5926)  Acc@5: 87.5000 (91.7529)  time: 0.3576  data: 0.0009  max mem: 2500
Train: Epoch[3/5]  [1580/4579]  eta: 0:17:33  Lr: 0.001875  Loss: 0.1096  Acc@1: 68.7500 (64.5715)  Acc@5: 87.5000 (91.7260)  time: 0.3514  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [1590/4579]  eta: 0:17:30  Lr: 0.001875  Loss: -0.3509  Acc@1: 62.5000 (64.5702)  Acc@5: 87.5000 (91.7190)  time: 0.3571  data: 0.0013  max mem: 2500
Train: Epoch[3/5]  [1600/4579]  eta: 0:17:26  Lr: 0.001875  Loss: -0.3111  Acc@1: 62.5000 (64.5612)  Acc@5: 87.5000 (91.7044)  time: 0.3566  data: 0.0015  max mem: 2500
Train: Epoch[3/5]  [1610/4579]  eta: 0:17:23  Lr: 0.001875  Loss: -0.2210  Acc@1: 62.5000 (64.5290)  Acc@5: 87.5000 (91.6783)  time: 0.3509  data: 0.0014  max mem: 2500
Train: Epoch[3/5]  [1620/4579]  eta: 0:17:19  Lr: 0.001875  Loss: -0.2753  Acc@1: 62.5000 (64.5242)  Acc@5: 87.5000 (91.6757)  time: 0.3499  data: 0.0009  max mem: 2500
Train: Epoch[3/5]  [1630/4579]  eta: 0:17:15  Lr: 0.001875  Loss: 0.1210  Acc@1: 62.5000 (64.4965)  Acc@5: 93.7500 (91.6692)  time: 0.3486  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1640/4579]  eta: 0:17:12  Lr: 0.001875  Loss: -0.2509  Acc@1: 62.5000 (64.5224)  Acc@5: 87.5000 (91.6438)  time: 0.3486  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1650/4579]  eta: 0:17:08  Lr: 0.001875  Loss: -0.0841  Acc@1: 68.7500 (64.5026)  Acc@5: 93.7500 (91.6641)  time: 0.3490  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [1660/4579]  eta: 0:17:05  Lr: 0.001875  Loss: -0.2029  Acc@1: 62.5000 (64.5131)  Acc@5: 93.7500 (91.6466)  time: 0.3477  data: 0.0013  max mem: 2500
Train: Epoch[3/5]  [1670/4579]  eta: 0:17:01  Lr: 0.001875  Loss: -0.0491  Acc@1: 68.7500 (64.5085)  Acc@5: 87.5000 (91.6330)  time: 0.3460  data: 0.0012  max mem: 2500
Train: Epoch[3/5]  [1680/4579]  eta: 0:16:58  Lr: 0.001875  Loss: -0.7352  Acc@1: 68.7500 (64.5338)  Acc@5: 87.5000 (91.6270)  time: 0.3474  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [1690/4579]  eta: 0:16:54  Lr: 0.001875  Loss: -0.5014  Acc@1: 68.7500 (64.5402)  Acc@5: 93.7500 (91.6322)  time: 0.3484  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [1700/4579]  eta: 0:16:50  Lr: 0.001875  Loss: -1.0155  Acc@1: 56.2500 (64.5356)  Acc@5: 93.7500 (91.6373)  time: 0.3498  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [1710/4579]  eta: 0:16:47  Lr: 0.001875  Loss: -0.8078  Acc@1: 56.2500 (64.5456)  Acc@5: 93.7500 (91.6314)  time: 0.3502  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [1720/4579]  eta: 0:16:43  Lr: 0.001875  Loss: 0.1096  Acc@1: 62.5000 (64.5482)  Acc@5: 93.7500 (91.6182)  time: 0.3512  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [1730/4579]  eta: 0:16:40  Lr: 0.001875  Loss: 0.1003  Acc@1: 62.5000 (64.5328)  Acc@5: 93.7500 (91.6269)  time: 0.3533  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [1740/4579]  eta: 0:16:36  Lr: 0.001875  Loss: -0.2664  Acc@1: 62.5000 (64.5247)  Acc@5: 93.7500 (91.6104)  time: 0.3515  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [1750/4579]  eta: 0:16:33  Lr: 0.001875  Loss: -0.2796  Acc@1: 62.5000 (64.5060)  Acc@5: 87.5000 (91.6119)  time: 0.3527  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [1760/4579]  eta: 0:16:29  Lr: 0.001875  Loss: -0.3224  Acc@1: 62.5000 (64.5194)  Acc@5: 93.7500 (91.6134)  time: 0.3513  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [1770/4579]  eta: 0:16:26  Lr: 0.001875  Loss: -0.1249  Acc@1: 62.5000 (64.5010)  Acc@5: 93.7500 (91.6220)  time: 0.3519  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [1780/4579]  eta: 0:16:22  Lr: 0.001875  Loss: 0.2608  Acc@1: 62.5000 (64.5038)  Acc@5: 93.7500 (91.6129)  time: 0.3534  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [1790/4579]  eta: 0:16:19  Lr: 0.001875  Loss: 0.0744  Acc@1: 62.5000 (64.5101)  Acc@5: 93.7500 (91.6143)  time: 0.3509  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [1800/4579]  eta: 0:16:15  Lr: 0.001875  Loss: -0.4163  Acc@1: 68.7500 (64.5162)  Acc@5: 93.7500 (91.6123)  time: 0.3495  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1810/4579]  eta: 0:16:12  Lr: 0.001875  Loss: -0.1884  Acc@1: 62.5000 (64.5327)  Acc@5: 93.7500 (91.6345)  time: 0.3483  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1820/4579]  eta: 0:16:08  Lr: 0.001875  Loss: 0.5564  Acc@1: 62.5000 (64.4941)  Acc@5: 93.7500 (91.6323)  time: 0.3515  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [1830/4579]  eta: 0:16:05  Lr: 0.001875  Loss: -0.5225  Acc@1: 62.5000 (64.5105)  Acc@5: 93.7500 (91.6337)  time: 0.3518  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [1840/4579]  eta: 0:16:01  Lr: 0.001875  Loss: 0.2220  Acc@1: 62.5000 (64.4792)  Acc@5: 87.5000 (91.6078)  time: 0.3487  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [1850/4579]  eta: 0:15:58  Lr: 0.001875  Loss: 0.1549  Acc@1: 62.5000 (64.4922)  Acc@5: 87.5000 (91.6126)  time: 0.3476  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [1860/4579]  eta: 0:15:54  Lr: 0.001875  Loss: -0.3227  Acc@1: 68.7500 (64.5083)  Acc@5: 93.7500 (91.6040)  time: 0.3476  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1870/4579]  eta: 0:15:51  Lr: 0.001875  Loss: -0.3575  Acc@1: 68.7500 (64.4976)  Acc@5: 93.7500 (91.5987)  time: 0.3483  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1880/4579]  eta: 0:15:47  Lr: 0.001875  Loss: 0.4769  Acc@1: 62.5000 (64.4870)  Acc@5: 93.7500 (91.6002)  time: 0.3472  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [1890/4579]  eta: 0:15:43  Lr: 0.001875  Loss: -0.3895  Acc@1: 62.5000 (64.4831)  Acc@5: 93.7500 (91.6083)  time: 0.3458  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [1900/4579]  eta: 0:15:40  Lr: 0.001875  Loss: -0.0363  Acc@1: 62.5000 (64.4661)  Acc@5: 93.7500 (91.6097)  time: 0.3506  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [1910/4579]  eta: 0:15:36  Lr: 0.001875  Loss: -0.1380  Acc@1: 62.5000 (64.4819)  Acc@5: 93.7500 (91.6143)  time: 0.3535  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [1920/4579]  eta: 0:15:33  Lr: 0.001875  Loss: -0.0665  Acc@1: 68.7500 (64.4879)  Acc@5: 93.7500 (91.6189)  time: 0.3514  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [1930/4579]  eta: 0:15:29  Lr: 0.001875  Loss: 0.1932  Acc@1: 62.5000 (64.5003)  Acc@5: 93.7500 (91.6073)  time: 0.3506  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1940/4579]  eta: 0:15:26  Lr: 0.001875  Loss: -0.4367  Acc@1: 68.7500 (64.4964)  Acc@5: 87.5000 (91.5990)  time: 0.3493  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1950/4579]  eta: 0:15:22  Lr: 0.001875  Loss: -0.4521  Acc@1: 62.5000 (64.4669)  Acc@5: 93.7500 (91.6005)  time: 0.3520  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1960/4579]  eta: 0:15:19  Lr: 0.001875  Loss: 0.1771  Acc@1: 62.5000 (64.4505)  Acc@5: 93.7500 (91.5891)  time: 0.3534  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [1970/4579]  eta: 0:15:15  Lr: 0.001875  Loss: 0.0066  Acc@1: 62.5000 (64.4470)  Acc@5: 93.7500 (91.6001)  time: 0.3492  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [1980/4579]  eta: 0:15:12  Lr: 0.001875  Loss: -0.5659  Acc@1: 68.7500 (64.4529)  Acc@5: 93.7500 (91.6109)  time: 0.3472  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1990/4579]  eta: 0:15:08  Lr: 0.001875  Loss: 0.0287  Acc@1: 62.5000 (64.4274)  Acc@5: 93.7500 (91.6060)  time: 0.3491  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [2000/4579]  eta: 0:15:05  Lr: 0.001875  Loss: 1.2330  Acc@1: 62.5000 (64.4240)  Acc@5: 93.7500 (91.5855)  time: 0.3511  data: 0.0011  max mem: 2500
Train: Epoch[3/5]  [2010/4579]  eta: 0:15:01  Lr: 0.001875  Loss: -0.2974  Acc@1: 62.5000 (64.4207)  Acc@5: 93.7500 (91.5838)  time: 0.3489  data: 0.0009  max mem: 2500
Train: Epoch[3/5]  [2020/4579]  eta: 0:14:58  Lr: 0.001875  Loss: -0.2605  Acc@1: 62.5000 (64.4081)  Acc@5: 93.7500 (91.5883)  time: 0.3462  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2030/4579]  eta: 0:14:54  Lr: 0.001875  Loss: -0.1335  Acc@1: 62.5000 (64.4048)  Acc@5: 93.7500 (91.5990)  time: 0.3472  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2040/4579]  eta: 0:14:51  Lr: 0.001875  Loss: -0.3711  Acc@1: 62.5000 (64.4078)  Acc@5: 93.7500 (91.6034)  time: 0.3488  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2050/4579]  eta: 0:14:47  Lr: 0.001875  Loss: -0.7426  Acc@1: 62.5000 (64.4107)  Acc@5: 93.7500 (91.6047)  time: 0.3485  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2060/4579]  eta: 0:14:43  Lr: 0.001875  Loss: -0.3350  Acc@1: 62.5000 (64.4256)  Acc@5: 93.7500 (91.6000)  time: 0.3481  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2070/4579]  eta: 0:14:40  Lr: 0.001875  Loss: -0.2517  Acc@1: 68.7500 (64.4616)  Acc@5: 93.7500 (91.6043)  time: 0.3490  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2080/4579]  eta: 0:14:36  Lr: 0.001875  Loss: 0.1689  Acc@1: 68.7500 (64.4432)  Acc@5: 93.7500 (91.5936)  time: 0.3488  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2090/4579]  eta: 0:14:33  Lr: 0.001875  Loss: 0.1832  Acc@1: 62.5000 (64.4578)  Acc@5: 93.7500 (91.5979)  time: 0.3469  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [2100/4579]  eta: 0:14:29  Lr: 0.001875  Loss: -0.5476  Acc@1: 62.5000 (64.4663)  Acc@5: 93.7500 (91.5963)  time: 0.3455  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [2110/4579]  eta: 0:14:26  Lr: 0.001875  Loss: -0.2386  Acc@1: 62.5000 (64.4659)  Acc@5: 93.7500 (91.6035)  time: 0.3456  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [2120/4579]  eta: 0:14:22  Lr: 0.001875  Loss: -0.3915  Acc@1: 68.7500 (64.4773)  Acc@5: 93.7500 (91.5989)  time: 0.3473  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [2130/4579]  eta: 0:14:19  Lr: 0.001875  Loss: -0.2484  Acc@1: 62.5000 (64.4474)  Acc@5: 87.5000 (91.5767)  time: 0.3471  data: 0.0009  max mem: 2500
Train: Epoch[3/5]  [2140/4579]  eta: 0:14:15  Lr: 0.001875  Loss: -0.8048  Acc@1: 62.5000 (64.4588)  Acc@5: 87.5000 (91.5723)  time: 0.3473  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2150/4579]  eta: 0:14:12  Lr: 0.001875  Loss: 0.0512  Acc@1: 62.5000 (64.4555)  Acc@5: 93.7500 (91.5737)  time: 0.3490  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [2160/4579]  eta: 0:14:08  Lr: 0.001875  Loss: -0.2608  Acc@1: 62.5000 (64.4435)  Acc@5: 93.7500 (91.5838)  time: 0.3509  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [2170/4579]  eta: 0:14:05  Lr: 0.001875  Loss: -0.4512  Acc@1: 62.5000 (64.4720)  Acc@5: 93.7500 (91.6081)  time: 0.3508  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2180/4579]  eta: 0:14:01  Lr: 0.001875  Loss: -0.1228  Acc@1: 62.5000 (64.4572)  Acc@5: 93.7500 (91.5922)  time: 0.3493  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [2190/4579]  eta: 0:13:57  Lr: 0.001875  Loss: -0.4055  Acc@1: 62.5000 (64.4540)  Acc@5: 87.5000 (91.5935)  time: 0.3489  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [2200/4579]  eta: 0:13:54  Lr: 0.001875  Loss: -0.0730  Acc@1: 62.5000 (64.4508)  Acc@5: 87.5000 (91.5834)  time: 0.3482  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [2210/4579]  eta: 0:13:50  Lr: 0.001875  Loss: -0.5139  Acc@1: 68.7500 (64.4618)  Acc@5: 87.5000 (91.5819)  time: 0.3494  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [2220/4579]  eta: 0:13:47  Lr: 0.001875  Loss: -0.2116  Acc@1: 68.7500 (64.4895)  Acc@5: 93.7500 (91.5944)  time: 0.3484  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [2230/4579]  eta: 0:13:43  Lr: 0.001875  Loss: -0.5603  Acc@1: 62.5000 (64.4834)  Acc@5: 93.7500 (91.6013)  time: 0.3472  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [2240/4579]  eta: 0:13:40  Lr: 0.001875  Loss: 0.3407  Acc@1: 62.5000 (64.4774)  Acc@5: 93.7500 (91.6081)  time: 0.3516  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [2250/4579]  eta: 0:13:36  Lr: 0.001875  Loss: -0.0688  Acc@1: 62.5000 (64.4825)  Acc@5: 93.7500 (91.6093)  time: 0.3538  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [2260/4579]  eta: 0:13:33  Lr: 0.001875  Loss: -0.5979  Acc@1: 62.5000 (64.4654)  Acc@5: 93.7500 (91.6105)  time: 0.3520  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [2270/4579]  eta: 0:13:29  Lr: 0.001875  Loss: 0.1179  Acc@1: 56.2500 (64.4292)  Acc@5: 93.7500 (91.6089)  time: 0.3490  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2280/4579]  eta: 0:13:26  Lr: 0.001875  Loss: -0.0021  Acc@1: 56.2500 (64.4125)  Acc@5: 87.5000 (91.5936)  time: 0.3472  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2290/4579]  eta: 0:13:22  Lr: 0.001875  Loss: 0.1433  Acc@1: 62.5000 (64.4015)  Acc@5: 87.5000 (91.5894)  time: 0.3482  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2300/4579]  eta: 0:13:19  Lr: 0.001875  Loss: -0.5795  Acc@1: 62.5000 (64.4013)  Acc@5: 93.7500 (91.5879)  time: 0.3488  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [2310/4579]  eta: 0:13:15  Lr: 0.001875  Loss: -0.8492  Acc@1: 62.5000 (64.3931)  Acc@5: 93.7500 (91.5864)  time: 0.3488  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [2320/4579]  eta: 0:13:12  Lr: 0.001875  Loss: -0.1676  Acc@1: 62.5000 (64.3823)  Acc@5: 93.7500 (91.5931)  time: 0.3472  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2330/4579]  eta: 0:13:08  Lr: 0.001875  Loss: -0.1912  Acc@1: 62.5000 (64.3822)  Acc@5: 93.7500 (91.5943)  time: 0.3467  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [2340/4579]  eta: 0:13:05  Lr: 0.001875  Loss: -0.3649  Acc@1: 62.5000 (64.3929)  Acc@5: 87.5000 (91.5768)  time: 0.3485  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2350/4579]  eta: 0:13:01  Lr: 0.001875  Loss: 0.4037  Acc@1: 68.7500 (64.4088)  Acc@5: 93.7500 (91.5887)  time: 0.3470  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2360/4579]  eta: 0:12:58  Lr: 0.001875  Loss: 0.4425  Acc@1: 68.7500 (64.4139)  Acc@5: 93.7500 (91.5793)  time: 0.3461  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [2370/4579]  eta: 0:12:54  Lr: 0.001875  Loss: -0.2361  Acc@1: 68.7500 (64.4401)  Acc@5: 87.5000 (91.5779)  time: 0.3497  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2380/4579]  eta: 0:12:51  Lr: 0.001875  Loss: 0.2293  Acc@1: 62.5000 (64.4136)  Acc@5: 87.5000 (91.5687)  time: 0.3515  data: 0.0013  max mem: 2500
Train: Epoch[3/5]  [2390/4579]  eta: 0:12:47  Lr: 0.001875  Loss: -0.4263  Acc@1: 56.2500 (64.3977)  Acc@5: 87.5000 (91.5673)  time: 0.3498  data: 0.0012  max mem: 2500
Train: Epoch[3/5]  [2400/4579]  eta: 0:12:43  Lr: 0.001875  Loss: -0.2037  Acc@1: 62.5000 (64.4002)  Acc@5: 93.7500 (91.5712)  time: 0.3497  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [2410/4579]  eta: 0:12:40  Lr: 0.001875  Loss: -0.1518  Acc@1: 62.5000 (64.3768)  Acc@5: 93.7500 (91.5777)  time: 0.3505  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [2420/4579]  eta: 0:12:36  Lr: 0.001875  Loss: -0.0628  Acc@1: 62.5000 (64.3794)  Acc@5: 93.7500 (91.5711)  time: 0.3510  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [2430/4579]  eta: 0:12:33  Lr: 0.001875  Loss: -0.1954  Acc@1: 62.5000 (64.3871)  Acc@5: 93.7500 (91.5698)  time: 0.3532  data: 0.0011  max mem: 2500
Train: Epoch[3/5]  [2440/4579]  eta: 0:12:29  Lr: 0.001875  Loss: -0.0198  Acc@1: 62.5000 (64.3870)  Acc@5: 87.5000 (91.5634)  time: 0.3513  data: 0.0010  max mem: 2500
Train: Epoch[3/5]  [2450/4579]  eta: 0:12:26  Lr: 0.001875  Loss: -0.1404  Acc@1: 62.5000 (64.3997)  Acc@5: 87.5000 (91.5672)  time: 0.3505  data: 0.0009  max mem: 2500
Train: Epoch[3/5]  [2460/4579]  eta: 0:12:22  Lr: 0.001875  Loss: -0.3977  Acc@1: 62.5000 (64.3920)  Acc@5: 93.7500 (91.5659)  time: 0.3504  data: 0.0009  max mem: 2500
Train: Epoch[3/5]  [2470/4579]  eta: 0:12:19  Lr: 0.001875  Loss: -0.1334  Acc@1: 62.5000 (64.3869)  Acc@5: 93.7500 (91.5571)  time: 0.3494  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [2480/4579]  eta: 0:12:15  Lr: 0.001875  Loss: 0.0783  Acc@1: 68.7500 (64.4020)  Acc@5: 93.7500 (91.5533)  time: 0.3518  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [2490/4579]  eta: 0:12:12  Lr: 0.001875  Loss: -0.2094  Acc@1: 68.7500 (64.3993)  Acc@5: 93.7500 (91.5446)  time: 0.3503  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2500/4579]  eta: 0:12:08  Lr: 0.001875  Loss: 0.1346  Acc@1: 68.7500 (64.4092)  Acc@5: 93.7500 (91.5384)  time: 0.3477  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2510/4579]  eta: 0:12:05  Lr: 0.001875  Loss: 0.1800  Acc@1: 68.7500 (64.4166)  Acc@5: 93.7500 (91.5447)  time: 0.3493  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2520/4579]  eta: 0:12:01  Lr: 0.001875  Loss: 0.0889  Acc@1: 68.7500 (64.4288)  Acc@5: 93.7500 (91.5559)  time: 0.3497  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [2530/4579]  eta: 0:11:58  Lr: 0.001875  Loss: -0.0680  Acc@1: 75.0000 (64.4385)  Acc@5: 93.7500 (91.5547)  time: 0.3468  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [2540/4579]  eta: 0:11:54  Lr: 0.001875  Loss: 0.4546  Acc@1: 68.7500 (64.4407)  Acc@5: 93.7500 (91.5535)  time: 0.3448  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [2550/4579]  eta: 0:11:51  Lr: 0.001875  Loss: -0.1083  Acc@1: 62.5000 (64.4233)  Acc@5: 93.7500 (91.5450)  time: 0.3459  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [2560/4579]  eta: 0:11:47  Lr: 0.001875  Loss: -0.3705  Acc@1: 62.5000 (64.4231)  Acc@5: 87.5000 (91.5341)  time: 0.3490  data: 0.0011  max mem: 2500
Train: Epoch[3/5]  [2570/4579]  eta: 0:11:44  Lr: 0.001875  Loss: -0.2424  Acc@1: 62.5000 (64.4302)  Acc@5: 93.7500 (91.5354)  time: 0.3506  data: 0.0012  max mem: 2500
Train: Epoch[3/5]  [2580/4579]  eta: 0:11:40  Lr: 0.001875  Loss: -0.2587  Acc@1: 62.5000 (64.4106)  Acc@5: 87.5000 (91.5173)  time: 0.3515  data: 0.0011  max mem: 2500
Train: Epoch[3/5]  [2590/4579]  eta: 0:11:37  Lr: 0.001875  Loss: -0.0727  Acc@1: 62.5000 (64.4032)  Acc@5: 87.5000 (91.5235)  time: 0.3558  data: 0.0024  max mem: 2500
Train: Epoch[3/5]  [2600/4579]  eta: 0:11:33  Lr: 0.001875  Loss: -0.8339  Acc@1: 62.5000 (64.4223)  Acc@5: 93.7500 (91.5321)  time: 0.3591  data: 0.0027  max mem: 2500
Train: Epoch[3/5]  [2610/4579]  eta: 0:11:30  Lr: 0.001875  Loss: 0.4115  Acc@1: 62.5000 (64.4174)  Acc@5: 93.7500 (91.5310)  time: 0.3546  data: 0.0015  max mem: 2500
Train: Epoch[3/5]  [2620/4579]  eta: 0:11:26  Lr: 0.001875  Loss: -0.5626  Acc@1: 68.7500 (64.4339)  Acc@5: 93.7500 (91.5300)  time: 0.3507  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [2630/4579]  eta: 0:11:23  Lr: 0.001875  Loss: -0.4735  Acc@1: 68.7500 (64.4503)  Acc@5: 93.7500 (91.5313)  time: 0.3517  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [2640/4579]  eta: 0:11:19  Lr: 0.001875  Loss: -0.4166  Acc@1: 62.5000 (64.4358)  Acc@5: 87.5000 (91.5136)  time: 0.3522  data: 0.0014  max mem: 2500
Train: Epoch[3/5]  [2650/4579]  eta: 0:11:16  Lr: 0.001875  Loss: 0.5457  Acc@1: 62.5000 (64.4474)  Acc@5: 87.5000 (91.5103)  time: 0.3502  data: 0.0014  max mem: 2500
Train: Epoch[3/5]  [2660/4579]  eta: 0:11:12  Lr: 0.001875  Loss: -0.4727  Acc@1: 62.5000 (64.4354)  Acc@5: 93.7500 (91.5116)  time: 0.3474  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2670/4579]  eta: 0:11:09  Lr: 0.001875  Loss: -0.6338  Acc@1: 62.5000 (64.4632)  Acc@5: 93.7500 (91.5294)  time: 0.3473  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2680/4579]  eta: 0:11:05  Lr: 0.001875  Loss: -0.1336  Acc@1: 68.7500 (64.4675)  Acc@5: 93.7500 (91.5260)  time: 0.3489  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [2690/4579]  eta: 0:11:02  Lr: 0.001875  Loss: -0.7391  Acc@1: 68.7500 (64.4719)  Acc@5: 93.7500 (91.5412)  time: 0.3538  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [2700/4579]  eta: 0:10:58  Lr: 0.001875  Loss: -0.2113  Acc@1: 68.7500 (64.4761)  Acc@5: 93.7500 (91.5471)  time: 0.3511  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2710/4579]  eta: 0:10:55  Lr: 0.001875  Loss: -0.5214  Acc@1: 68.7500 (64.4688)  Acc@5: 93.7500 (91.5460)  time: 0.3449  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [2720/4579]  eta: 0:10:51  Lr: 0.001875  Loss: -0.2011  Acc@1: 56.2500 (64.4616)  Acc@5: 93.7500 (91.5495)  time: 0.3459  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [2730/4579]  eta: 0:10:48  Lr: 0.001875  Loss: -0.0658  Acc@1: 56.2500 (64.4384)  Acc@5: 93.7500 (91.5553)  time: 0.3466  data: 0.0012  max mem: 2500
Train: Epoch[3/5]  [2740/4579]  eta: 0:10:44  Lr: 0.001875  Loss: -0.5510  Acc@1: 62.5000 (64.4336)  Acc@5: 87.5000 (91.5496)  time: 0.3472  data: 0.0009  max mem: 2500
Train: Epoch[3/5]  [2750/4579]  eta: 0:10:41  Lr: 0.001875  Loss: -0.0340  Acc@1: 62.5000 (64.4311)  Acc@5: 87.5000 (91.5417)  time: 0.3520  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [2760/4579]  eta: 0:10:37  Lr: 0.001875  Loss: 0.4603  Acc@1: 62.5000 (64.4151)  Acc@5: 87.5000 (91.5316)  time: 0.3580  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [2770/4579]  eta: 0:10:34  Lr: 0.001875  Loss: 0.0270  Acc@1: 62.5000 (64.4127)  Acc@5: 87.5000 (91.5283)  time: 0.3562  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [2780/4579]  eta: 0:10:30  Lr: 0.001875  Loss: -0.0089  Acc@1: 62.5000 (64.4058)  Acc@5: 93.7500 (91.5296)  time: 0.3527  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [2790/4579]  eta: 0:10:27  Lr: 0.001875  Loss: -0.0626  Acc@1: 62.5000 (64.3878)  Acc@5: 93.7500 (91.5219)  time: 0.3518  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [2800/4579]  eta: 0:10:23  Lr: 0.001875  Loss: -0.2377  Acc@1: 62.5000 (64.4078)  Acc@5: 93.7500 (91.5253)  time: 0.3495  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [2810/4579]  eta: 0:10:20  Lr: 0.001875  Loss: -0.4131  Acc@1: 68.7500 (64.4121)  Acc@5: 93.7500 (91.5355)  time: 0.3531  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [2820/4579]  eta: 0:10:16  Lr: 0.001875  Loss: -0.0277  Acc@1: 62.5000 (64.3965)  Acc@5: 93.7500 (91.5278)  time: 0.3555  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [2830/4579]  eta: 0:10:13  Lr: 0.001875  Loss: 0.2066  Acc@1: 62.5000 (64.3964)  Acc@5: 93.7500 (91.5246)  time: 0.3512  data: 0.0009  max mem: 2500
Train: Epoch[3/5]  [2840/4579]  eta: 0:10:09  Lr: 0.001875  Loss: -0.7485  Acc@1: 62.5000 (64.4073)  Acc@5: 93.7500 (91.5259)  time: 0.3481  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [2850/4579]  eta: 0:10:06  Lr: 0.001875  Loss: -0.5122  Acc@1: 68.7500 (64.4204)  Acc@5: 93.7500 (91.5205)  time: 0.3473  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2860/4579]  eta: 0:10:02  Lr: 0.001875  Loss: -0.3153  Acc@1: 68.7500 (64.4224)  Acc@5: 93.7500 (91.5261)  time: 0.3495  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [2870/4579]  eta: 0:09:59  Lr: 0.001875  Loss: -0.1258  Acc@1: 62.5000 (64.4244)  Acc@5: 93.7500 (91.5317)  time: 0.3504  data: 0.0010  max mem: 2500
Train: Epoch[3/5]  [2880/4579]  eta: 0:09:55  Lr: 0.001875  Loss: -0.4518  Acc@1: 62.5000 (64.4221)  Acc@5: 87.5000 (91.5199)  time: 0.3488  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [2890/4579]  eta: 0:09:52  Lr: 0.001875  Loss: -0.4061  Acc@1: 62.5000 (64.4198)  Acc@5: 87.5000 (91.5125)  time: 0.3472  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [2900/4579]  eta: 0:09:48  Lr: 0.001875  Loss: -0.1402  Acc@1: 62.5000 (64.4261)  Acc@5: 93.7500 (91.5115)  time: 0.3471  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [2910/4579]  eta: 0:09:45  Lr: 0.001875  Loss: -0.1900  Acc@1: 62.5000 (64.4044)  Acc@5: 93.7500 (91.5085)  time: 0.3477  data: 0.0011  max mem: 2500
Train: Epoch[3/5]  [2920/4579]  eta: 0:09:41  Lr: 0.001875  Loss: 0.0476  Acc@1: 56.2500 (64.3915)  Acc@5: 87.5000 (91.5012)  time: 0.3464  data: 0.0011  max mem: 2500
Train: Epoch[3/5]  [2930/4579]  eta: 0:09:38  Lr: 0.001875  Loss: -0.3873  Acc@1: 56.2500 (64.3786)  Acc@5: 93.7500 (91.5067)  time: 0.3457  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [2940/4579]  eta: 0:09:34  Lr: 0.001875  Loss: -0.0883  Acc@1: 62.5000 (64.3892)  Acc@5: 93.7500 (91.5037)  time: 0.3512  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2950/4579]  eta: 0:09:31  Lr: 0.001875  Loss: -0.2846  Acc@1: 68.7500 (64.4146)  Acc@5: 93.7500 (91.5156)  time: 0.3549  data: 0.0013  max mem: 2500
Train: Epoch[3/5]  [2960/4579]  eta: 0:09:27  Lr: 0.001875  Loss: -0.0774  Acc@1: 68.7500 (64.4250)  Acc@5: 93.7500 (91.5210)  time: 0.3532  data: 0.0015  max mem: 2500
Train: Epoch[3/5]  [2970/4579]  eta: 0:09:24  Lr: 0.001875  Loss: -0.0138  Acc@1: 62.5000 (64.4249)  Acc@5: 93.7500 (91.5138)  time: 0.3520  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [2980/4579]  eta: 0:09:20  Lr: 0.001875  Loss: 0.2550  Acc@1: 62.5000 (64.4289)  Acc@5: 93.7500 (91.5108)  time: 0.3528  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [2990/4579]  eta: 0:09:17  Lr: 0.001875  Loss: 0.0419  Acc@1: 62.5000 (64.4287)  Acc@5: 93.7500 (91.5120)  time: 0.3586  data: 0.0013  max mem: 2500
Train: Epoch[3/5]  [3000/4579]  eta: 0:09:13  Lr: 0.001875  Loss: 0.6485  Acc@1: 62.5000 (64.4410)  Acc@5: 93.7500 (91.5132)  time: 0.3571  data: 0.0014  max mem: 2500
Train: Epoch[3/5]  [3010/4579]  eta: 0:09:10  Lr: 0.001875  Loss: 0.3763  Acc@1: 68.7500 (64.4429)  Acc@5: 93.7500 (91.5082)  time: 0.3521  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [3020/4579]  eta: 0:09:06  Lr: 0.001875  Loss: -0.9948  Acc@1: 68.7500 (64.4716)  Acc@5: 93.7500 (91.5218)  time: 0.3512  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [3030/4579]  eta: 0:09:03  Lr: 0.001875  Loss: 0.0572  Acc@1: 68.7500 (64.4734)  Acc@5: 93.7500 (91.5106)  time: 0.3530  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [3040/4579]  eta: 0:08:59  Lr: 0.001875  Loss: -0.4152  Acc@1: 62.5000 (64.4648)  Acc@5: 87.5000 (91.5159)  time: 0.3528  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [3050/4579]  eta: 0:08:56  Lr: 0.001875  Loss: -0.1030  Acc@1: 62.5000 (64.4481)  Acc@5: 93.7500 (91.5192)  time: 0.3493  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [3060/4579]  eta: 0:08:52  Lr: 0.001875  Loss: -0.4786  Acc@1: 62.5000 (64.4397)  Acc@5: 93.7500 (91.5183)  time: 0.3483  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3070/4579]  eta: 0:08:49  Lr: 0.001875  Loss: 0.5484  Acc@1: 62.5000 (64.4517)  Acc@5: 93.7500 (91.5113)  time: 0.3482  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3080/4579]  eta: 0:08:45  Lr: 0.001875  Loss: -0.3058  Acc@1: 68.7500 (64.4819)  Acc@5: 93.7500 (91.5186)  time: 0.3504  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3090/4579]  eta: 0:08:42  Lr: 0.001875  Loss: -0.8647  Acc@1: 68.7500 (64.4876)  Acc@5: 93.7500 (91.5157)  time: 0.3483  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3100/4579]  eta: 0:08:38  Lr: 0.001875  Loss: -0.2537  Acc@1: 62.5000 (64.4772)  Acc@5: 93.7500 (91.5249)  time: 0.3455  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3110/4579]  eta: 0:08:35  Lr: 0.001875  Loss: -0.7029  Acc@1: 68.7500 (64.4969)  Acc@5: 93.7500 (91.5401)  time: 0.3478  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3120/4579]  eta: 0:08:31  Lr: 0.001875  Loss: -0.7292  Acc@1: 68.7500 (64.4986)  Acc@5: 93.7500 (91.5372)  time: 0.3509  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [3130/4579]  eta: 0:08:28  Lr: 0.001875  Loss: 0.1828  Acc@1: 62.5000 (64.5002)  Acc@5: 93.7500 (91.5422)  time: 0.3511  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3140/4579]  eta: 0:08:24  Lr: 0.001875  Loss: -0.5625  Acc@1: 62.5000 (64.5157)  Acc@5: 93.7500 (91.5393)  time: 0.3491  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [3150/4579]  eta: 0:08:21  Lr: 0.001875  Loss: -0.3822  Acc@1: 62.5000 (64.5192)  Acc@5: 93.7500 (91.5404)  time: 0.3523  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [3160/4579]  eta: 0:08:17  Lr: 0.001875  Loss: -0.1473  Acc@1: 68.7500 (64.5247)  Acc@5: 93.7500 (91.5434)  time: 0.3562  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [3170/4579]  eta: 0:08:14  Lr: 0.001875  Loss: -0.6261  Acc@1: 62.5000 (64.5163)  Acc@5: 93.7500 (91.5307)  time: 0.3575  data: 0.0011  max mem: 2500
Train: Epoch[3/5]  [3180/4579]  eta: 0:08:10  Lr: 0.001875  Loss: -0.3978  Acc@1: 68.7500 (64.5336)  Acc@5: 87.5000 (91.5278)  time: 0.3579  data: 0.0013  max mem: 2500
Train: Epoch[3/5]  [3190/4579]  eta: 0:08:07  Lr: 0.001875  Loss: -0.8176  Acc@1: 75.0000 (64.5585)  Acc@5: 93.7500 (91.5270)  time: 0.3541  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [3200/4579]  eta: 0:08:03  Lr: 0.001875  Loss: -0.7172  Acc@1: 68.7500 (64.5482)  Acc@5: 93.7500 (91.5358)  time: 0.3508  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [3210/4579]  eta: 0:08:00  Lr: 0.001875  Loss: -0.1430  Acc@1: 62.5000 (64.5476)  Acc@5: 93.7500 (91.5389)  time: 0.3555  data: 0.0016  max mem: 2500
Train: Epoch[3/5]  [3220/4579]  eta: 0:07:56  Lr: 0.001875  Loss: -0.6100  Acc@1: 62.5000 (64.5432)  Acc@5: 93.7500 (91.5496)  time: 0.3556  data: 0.0013  max mem: 2500
Train: Epoch[3/5]  [3230/4579]  eta: 0:07:53  Lr: 0.001875  Loss: -0.3021  Acc@1: 68.7500 (64.5543)  Acc@5: 93.7500 (91.5545)  time: 0.3498  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3240/4579]  eta: 0:07:49  Lr: 0.001875  Loss: -0.1004  Acc@1: 68.7500 (64.5615)  Acc@5: 93.7500 (91.5612)  time: 0.3518  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [3250/4579]  eta: 0:07:46  Lr: 0.001875  Loss: -0.2441  Acc@1: 68.7500 (64.5686)  Acc@5: 93.7500 (91.5718)  time: 0.3539  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [3260/4579]  eta: 0:07:42  Lr: 0.001875  Loss: -0.5476  Acc@1: 68.7500 (64.5795)  Acc@5: 93.7500 (91.5670)  time: 0.3516  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [3270/4579]  eta: 0:07:39  Lr: 0.001875  Loss: -0.0585  Acc@1: 62.5000 (64.5751)  Acc@5: 93.7500 (91.5718)  time: 0.3487  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3280/4579]  eta: 0:07:35  Lr: 0.001875  Loss: -0.1794  Acc@1: 62.5000 (64.5744)  Acc@5: 93.7500 (91.5708)  time: 0.3467  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [3290/4579]  eta: 0:07:32  Lr: 0.001875  Loss: -0.1172  Acc@1: 68.7500 (64.5928)  Acc@5: 93.7500 (91.5679)  time: 0.3468  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [3300/4579]  eta: 0:07:28  Lr: 0.001875  Loss: -0.4172  Acc@1: 68.7500 (64.6073)  Acc@5: 93.7500 (91.5783)  time: 0.3468  data: 0.0009  max mem: 2500
Train: Epoch[3/5]  [3310/4579]  eta: 0:07:24  Lr: 0.001875  Loss: -0.5248  Acc@1: 62.5000 (64.5802)  Acc@5: 93.7500 (91.5698)  time: 0.3456  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3320/4579]  eta: 0:07:21  Lr: 0.001875  Loss: -0.3689  Acc@1: 62.5000 (64.5777)  Acc@5: 93.7500 (91.5745)  time: 0.3487  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3330/4579]  eta: 0:07:17  Lr: 0.001875  Loss: 0.1247  Acc@1: 62.5000 (64.5752)  Acc@5: 93.7500 (91.5660)  time: 0.3539  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [3340/4579]  eta: 0:07:14  Lr: 0.001875  Loss: -0.2656  Acc@1: 68.7500 (64.5914)  Acc@5: 93.7500 (91.5650)  time: 0.3548  data: 0.0020  max mem: 2500
Train: Epoch[3/5]  [3350/4579]  eta: 0:07:11  Lr: 0.001875  Loss: 0.0707  Acc@1: 68.7500 (64.5796)  Acc@5: 93.7500 (91.5715)  time: 0.3560  data: 0.0018  max mem: 2500
Train: Epoch[3/5]  [3360/4579]  eta: 0:07:07  Lr: 0.001875  Loss: 0.1259  Acc@1: 62.5000 (64.5790)  Acc@5: 87.5000 (91.5594)  time: 0.3540  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [3370/4579]  eta: 0:07:03  Lr: 0.001875  Loss: -0.2341  Acc@1: 68.7500 (64.6006)  Acc@5: 87.5000 (91.5641)  time: 0.3508  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [3380/4579]  eta: 0:07:00  Lr: 0.001875  Loss: 0.1532  Acc@1: 68.7500 (64.5870)  Acc@5: 93.7500 (91.5613)  time: 0.3539  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [3390/4579]  eta: 0:06:57  Lr: 0.001875  Loss: -0.2791  Acc@1: 62.5000 (64.5993)  Acc@5: 93.7500 (91.5567)  time: 0.3540  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [3400/4579]  eta: 0:06:53  Lr: 0.001875  Loss: -0.1500  Acc@1: 68.7500 (64.5895)  Acc@5: 93.7500 (91.5576)  time: 0.3505  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [3410/4579]  eta: 0:06:49  Lr: 0.001875  Loss: -0.1477  Acc@1: 62.5000 (64.5943)  Acc@5: 93.7500 (91.5476)  time: 0.3485  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [3420/4579]  eta: 0:06:46  Lr: 0.001875  Loss: -0.1964  Acc@1: 68.7500 (64.6028)  Acc@5: 93.7500 (91.5540)  time: 0.3482  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [3430/4579]  eta: 0:06:42  Lr: 0.001875  Loss: -0.4797  Acc@1: 68.7500 (64.6094)  Acc@5: 93.7500 (91.5531)  time: 0.3515  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [3440/4579]  eta: 0:06:39  Lr: 0.001875  Loss: 0.3646  Acc@1: 68.7500 (64.6124)  Acc@5: 93.7500 (91.5559)  time: 0.3521  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [3450/4579]  eta: 0:06:35  Lr: 0.001875  Loss: -0.2725  Acc@1: 62.5000 (64.6171)  Acc@5: 93.7500 (91.5622)  time: 0.3483  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3460/4579]  eta: 0:06:32  Lr: 0.001875  Loss: -0.2727  Acc@1: 68.7500 (64.6273)  Acc@5: 93.7500 (91.5685)  time: 0.3479  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3470/4579]  eta: 0:06:28  Lr: 0.001875  Loss: 0.0074  Acc@1: 68.7500 (64.6103)  Acc@5: 93.7500 (91.5640)  time: 0.3487  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3480/4579]  eta: 0:06:25  Lr: 0.001875  Loss: -0.3879  Acc@1: 56.2500 (64.6204)  Acc@5: 93.7500 (91.5721)  time: 0.3464  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [3490/4579]  eta: 0:06:21  Lr: 0.001875  Loss: -0.7893  Acc@1: 62.5000 (64.6251)  Acc@5: 93.7500 (91.5766)  time: 0.3446  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [3500/4579]  eta: 0:06:18  Lr: 0.001875  Loss: 0.0961  Acc@1: 62.5000 (64.6048)  Acc@5: 87.5000 (91.5560)  time: 0.3520  data: 0.0011  max mem: 2500
Train: Epoch[3/5]  [3510/4579]  eta: 0:06:14  Lr: 0.001875  Loss: -0.2215  Acc@1: 62.5000 (64.6255)  Acc@5: 93.7500 (91.5676)  time: 0.3551  data: 0.0011  max mem: 2500
Train: Epoch[3/5]  [3520/4579]  eta: 0:06:11  Lr: 0.001875  Loss: -0.2767  Acc@1: 68.7500 (64.6425)  Acc@5: 93.7500 (91.5720)  time: 0.3511  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3530/4579]  eta: 0:06:07  Lr: 0.001875  Loss: -0.4255  Acc@1: 68.7500 (64.6329)  Acc@5: 93.7500 (91.5693)  time: 0.3502  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [3540/4579]  eta: 0:06:04  Lr: 0.001875  Loss: -0.2498  Acc@1: 68.7500 (64.6428)  Acc@5: 93.7500 (91.5772)  time: 0.3540  data: 0.0020  max mem: 2500
Train: Epoch[3/5]  [3550/4579]  eta: 0:06:00  Lr: 0.001875  Loss: 0.1909  Acc@1: 68.7500 (64.6420)  Acc@5: 93.7500 (91.5781)  time: 0.3584  data: 0.0020  max mem: 2500
Train: Epoch[3/5]  [3560/4579]  eta: 0:05:57  Lr: 0.001875  Loss: -0.2261  Acc@1: 68.7500 (64.6465)  Acc@5: 87.5000 (91.5807)  time: 0.3535  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [3570/4579]  eta: 0:05:53  Lr: 0.001875  Loss: -0.0740  Acc@1: 62.5000 (64.6388)  Acc@5: 87.5000 (91.5762)  time: 0.3512  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [3580/4579]  eta: 0:05:50  Lr: 0.001875  Loss: -0.0968  Acc@1: 62.5000 (64.6433)  Acc@5: 93.7500 (91.5788)  time: 0.3530  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [3590/4579]  eta: 0:05:46  Lr: 0.001875  Loss: -0.0518  Acc@1: 68.7500 (64.6547)  Acc@5: 93.7500 (91.5883)  time: 0.3504  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [3600/4579]  eta: 0:05:43  Lr: 0.001875  Loss: -0.0856  Acc@1: 62.5000 (64.6504)  Acc@5: 93.7500 (91.5822)  time: 0.3489  data: 0.0012  max mem: 2500
Train: Epoch[3/5]  [3610/4579]  eta: 0:05:39  Lr: 0.001875  Loss: 0.1249  Acc@1: 62.5000 (64.6566)  Acc@5: 93.7500 (91.5882)  time: 0.3511  data: 0.0012  max mem: 2500
Train: Epoch[3/5]  [3620/4579]  eta: 0:05:36  Lr: 0.001875  Loss: 0.2581  Acc@1: 62.5000 (64.6506)  Acc@5: 93.7500 (91.5959)  time: 0.3506  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [3630/4579]  eta: 0:05:32  Lr: 0.001875  Loss: -0.5980  Acc@1: 62.5000 (64.6533)  Acc@5: 93.7500 (91.5949)  time: 0.3478  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [3640/4579]  eta: 0:05:29  Lr: 0.001875  Loss: 0.8232  Acc@1: 68.7500 (64.6715)  Acc@5: 87.5000 (91.5940)  time: 0.3478  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [3650/4579]  eta: 0:05:25  Lr: 0.001875  Loss: -0.4798  Acc@1: 62.5000 (64.6552)  Acc@5: 93.7500 (91.5948)  time: 0.3498  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [3660/4579]  eta: 0:05:22  Lr: 0.001875  Loss: -0.6792  Acc@1: 62.5000 (64.6579)  Acc@5: 93.7500 (91.5904)  time: 0.3482  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [3670/4579]  eta: 0:05:18  Lr: 0.001875  Loss: 0.4202  Acc@1: 62.5000 (64.6350)  Acc@5: 87.5000 (91.5827)  time: 0.3459  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [3680/4579]  eta: 0:05:15  Lr: 0.001875  Loss: 0.0046  Acc@1: 62.5000 (64.6377)  Acc@5: 93.7500 (91.5886)  time: 0.3487  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [3690/4579]  eta: 0:05:11  Lr: 0.001875  Loss: -0.3453  Acc@1: 68.7500 (64.6488)  Acc@5: 93.7500 (91.5978)  time: 0.3506  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3700/4579]  eta: 0:05:08  Lr: 0.001875  Loss: -0.0403  Acc@1: 62.5000 (64.6514)  Acc@5: 93.7500 (91.5969)  time: 0.3502  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [3710/4579]  eta: 0:05:04  Lr: 0.001875  Loss: -0.5820  Acc@1: 62.5000 (64.6355)  Acc@5: 93.7500 (91.5926)  time: 0.3503  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [3720/4579]  eta: 0:05:01  Lr: 0.001875  Loss: -0.3285  Acc@1: 62.5000 (64.6399)  Acc@5: 87.5000 (91.5849)  time: 0.3531  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [3730/4579]  eta: 0:04:57  Lr: 0.001875  Loss: -0.6287  Acc@1: 62.5000 (64.6375)  Acc@5: 87.5000 (91.5907)  time: 0.3563  data: 0.0013  max mem: 2500
Train: Epoch[3/5]  [3740/4579]  eta: 0:04:54  Lr: 0.001875  Loss: 0.4179  Acc@1: 56.2500 (64.6067)  Acc@5: 87.5000 (91.5765)  time: 0.3539  data: 0.0013  max mem: 2500
Train: Epoch[3/5]  [3750/4579]  eta: 0:04:50  Lr: 0.001875  Loss: -0.7901  Acc@1: 62.5000 (64.6161)  Acc@5: 87.5000 (91.5722)  time: 0.3500  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [3760/4579]  eta: 0:04:47  Lr: 0.001875  Loss: -0.5424  Acc@1: 62.5000 (64.6188)  Acc@5: 87.5000 (91.5714)  time: 0.3494  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [3770/4579]  eta: 0:04:43  Lr: 0.001875  Loss: -0.2688  Acc@1: 68.7500 (64.6297)  Acc@5: 93.7500 (91.5821)  time: 0.3519  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [3780/4579]  eta: 0:04:40  Lr: 0.001875  Loss: -0.1467  Acc@1: 62.5000 (64.6142)  Acc@5: 93.7500 (91.5780)  time: 0.3551  data: 0.0013  max mem: 2500
Train: Epoch[3/5]  [3790/4579]  eta: 0:04:36  Lr: 0.001875  Loss: -0.1031  Acc@1: 62.5000 (64.6169)  Acc@5: 93.7500 (91.5771)  time: 0.3516  data: 0.0013  max mem: 2500
Train: Epoch[3/5]  [3800/4579]  eta: 0:04:33  Lr: 0.001875  Loss: -0.5773  Acc@1: 68.7500 (64.6179)  Acc@5: 93.7500 (91.5845)  time: 0.3475  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3810/4579]  eta: 0:04:29  Lr: 0.001875  Loss: -0.3283  Acc@1: 62.5000 (64.6238)  Acc@5: 93.7500 (91.5819)  time: 0.3476  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3820/4579]  eta: 0:04:26  Lr: 0.001875  Loss: 0.3717  Acc@1: 62.5000 (64.6166)  Acc@5: 93.7500 (91.5827)  time: 0.3508  data: 0.0018  max mem: 2500
Train: Epoch[3/5]  [3830/4579]  eta: 0:04:22  Lr: 0.001875  Loss: -0.4965  Acc@1: 62.5000 (64.6241)  Acc@5: 93.7500 (91.5998)  time: 0.3512  data: 0.0018  max mem: 2500
Train: Epoch[3/5]  [3840/4579]  eta: 0:04:19  Lr: 0.001875  Loss: -0.2093  Acc@1: 62.5000 (64.6105)  Acc@5: 100.0000 (91.5940)  time: 0.3470  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [3850/4579]  eta: 0:04:15  Lr: 0.001875  Loss: -0.1992  Acc@1: 62.5000 (64.6098)  Acc@5: 93.7500 (91.5947)  time: 0.3456  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3860/4579]  eta: 0:04:12  Lr: 0.001875  Loss: 0.4722  Acc@1: 62.5000 (64.6109)  Acc@5: 93.7500 (91.5938)  time: 0.3476  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [3870/4579]  eta: 0:04:08  Lr: 0.001875  Loss: -0.0842  Acc@1: 68.7500 (64.6070)  Acc@5: 93.7500 (91.5881)  time: 0.3482  data: 0.0012  max mem: 2500
Train: Epoch[3/5]  [3880/4579]  eta: 0:04:05  Lr: 0.001875  Loss: -0.2595  Acc@1: 62.5000 (64.6080)  Acc@5: 93.7500 (91.5921)  time: 0.3490  data: 0.0012  max mem: 2500
Train: Epoch[3/5]  [3890/4579]  eta: 0:04:01  Lr: 0.001875  Loss: -0.8325  Acc@1: 68.7500 (64.6187)  Acc@5: 93.7500 (91.5960)  time: 0.3495  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [3900/4579]  eta: 0:03:58  Lr: 0.001875  Loss: -0.6341  Acc@1: 68.7500 (64.6405)  Acc@5: 93.7500 (91.6047)  time: 0.3492  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [3910/4579]  eta: 0:03:54  Lr: 0.001875  Loss: 0.4082  Acc@1: 68.7500 (64.6478)  Acc@5: 93.7500 (91.6070)  time: 0.3545  data: 0.0019  max mem: 2500
Train: Epoch[3/5]  [3920/4579]  eta: 0:03:51  Lr: 0.001875  Loss: -0.5094  Acc@1: 68.7500 (64.6407)  Acc@5: 93.7500 (91.6045)  time: 0.3534  data: 0.0020  max mem: 2500
Train: Epoch[3/5]  [3930/4579]  eta: 0:03:47  Lr: 0.001875  Loss: 0.1793  Acc@1: 68.7500 (64.6464)  Acc@5: 87.5000 (91.6036)  time: 0.3493  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [3940/4579]  eta: 0:03:44  Lr: 0.001875  Loss: -0.3982  Acc@1: 62.5000 (64.6330)  Acc@5: 87.5000 (91.6043)  time: 0.3501  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [3950/4579]  eta: 0:03:40  Lr: 0.001875  Loss: -0.5730  Acc@1: 68.7500 (64.6561)  Acc@5: 93.7500 (91.6050)  time: 0.3527  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [3960/4579]  eta: 0:03:37  Lr: 0.001875  Loss: 0.3729  Acc@1: 68.7500 (64.6443)  Acc@5: 87.5000 (91.5962)  time: 0.3541  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [3970/4579]  eta: 0:03:33  Lr: 0.001875  Loss: 0.0355  Acc@1: 62.5000 (64.6452)  Acc@5: 93.7500 (91.6016)  time: 0.3508  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [3980/4579]  eta: 0:03:30  Lr: 0.001875  Loss: -0.0655  Acc@1: 62.5000 (64.6493)  Acc@5: 93.7500 (91.6007)  time: 0.3482  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3990/4579]  eta: 0:03:26  Lr: 0.001875  Loss: -0.2117  Acc@1: 62.5000 (64.6408)  Acc@5: 93.7500 (91.5952)  time: 0.3481  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [4000/4579]  eta: 0:03:23  Lr: 0.001875  Loss: 0.3170  Acc@1: 68.7500 (64.6526)  Acc@5: 87.5000 (91.5865)  time: 0.3512  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [4010/4579]  eta: 0:03:19  Lr: 0.001875  Loss: -0.0648  Acc@1: 62.5000 (64.6441)  Acc@5: 87.5000 (91.5888)  time: 0.3509  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [4020/4579]  eta: 0:03:16  Lr: 0.001875  Loss: -0.1434  Acc@1: 62.5000 (64.6590)  Acc@5: 87.5000 (91.5848)  time: 0.3479  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [4030/4579]  eta: 0:03:12  Lr: 0.001875  Loss: 0.1114  Acc@1: 62.5000 (64.6459)  Acc@5: 93.7500 (91.5902)  time: 0.3478  data: 0.0010  max mem: 2500
Train: Epoch[3/5]  [4040/4579]  eta: 0:03:08  Lr: 0.001875  Loss: -0.3990  Acc@1: 62.5000 (64.6545)  Acc@5: 93.7500 (91.5909)  time: 0.3485  data: 0.0010  max mem: 2500
Train: Epoch[3/5]  [4050/4579]  eta: 0:03:05  Lr: 0.001875  Loss: -0.1005  Acc@1: 62.5000 (64.6569)  Acc@5: 93.7500 (91.5962)  time: 0.3475  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [4060/4579]  eta: 0:03:01  Lr: 0.001875  Loss: -0.1975  Acc@1: 62.5000 (64.6531)  Acc@5: 93.7500 (91.5923)  time: 0.3456  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [4070/4579]  eta: 0:02:58  Lr: 0.001875  Loss: 0.1695  Acc@1: 56.2500 (64.6325)  Acc@5: 87.5000 (91.5853)  time: 0.3483  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [4080/4579]  eta: 0:02:54  Lr: 0.001875  Loss: -0.0883  Acc@1: 62.5000 (64.6364)  Acc@5: 87.5000 (91.5829)  time: 0.3542  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [4090/4579]  eta: 0:02:51  Lr: 0.001875  Loss: -0.0926  Acc@1: 68.7500 (64.6480)  Acc@5: 93.7500 (91.5821)  time: 0.3547  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [4100/4579]  eta: 0:02:47  Lr: 0.001875  Loss: -0.2868  Acc@1: 68.7500 (64.6397)  Acc@5: 93.7500 (91.5859)  time: 0.3521  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [4110/4579]  eta: 0:02:44  Lr: 0.001875  Loss: 0.0338  Acc@1: 68.7500 (64.6421)  Acc@5: 93.7500 (91.5851)  time: 0.3510  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [4120/4579]  eta: 0:02:40  Lr: 0.001875  Loss: -0.4155  Acc@1: 68.7500 (64.6460)  Acc@5: 93.7500 (91.5843)  time: 0.3507  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [4130/4579]  eta: 0:02:37  Lr: 0.001875  Loss: -0.4975  Acc@1: 62.5000 (64.6393)  Acc@5: 93.7500 (91.5865)  time: 0.3542  data: 0.0014  max mem: 2500
Train: Epoch[3/5]  [4140/4579]  eta: 0:02:33  Lr: 0.001875  Loss: -0.0501  Acc@1: 62.5000 (64.6357)  Acc@5: 93.7500 (91.5902)  time: 0.3541  data: 0.0015  max mem: 2500
Train: Epoch[3/5]  [4150/4579]  eta: 0:02:30  Lr: 0.001875  Loss: -0.6622  Acc@1: 62.5000 (64.6486)  Acc@5: 93.7500 (91.5909)  time: 0.3555  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [4160/4579]  eta: 0:02:26  Lr: 0.001875  Loss: -0.0995  Acc@1: 68.7500 (64.6509)  Acc@5: 93.7500 (91.5991)  time: 0.3541  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [4170/4579]  eta: 0:02:23  Lr: 0.001875  Loss: -0.2209  Acc@1: 68.7500 (64.6593)  Acc@5: 93.7500 (91.5952)  time: 0.3489  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [4180/4579]  eta: 0:02:19  Lr: 0.001875  Loss: -0.2309  Acc@1: 62.5000 (64.6556)  Acc@5: 87.5000 (91.5944)  time: 0.3510  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [4190/4579]  eta: 0:02:16  Lr: 0.001875  Loss: -0.4267  Acc@1: 62.5000 (64.6579)  Acc@5: 87.5000 (91.5891)  time: 0.3500  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [4200/4579]  eta: 0:02:12  Lr: 0.001875  Loss: -0.2811  Acc@1: 62.5000 (64.6528)  Acc@5: 93.7500 (91.5868)  time: 0.3479  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [4210/4579]  eta: 0:02:09  Lr: 0.001875  Loss: 0.0966  Acc@1: 56.2500 (64.6358)  Acc@5: 93.7500 (91.5860)  time: 0.3473  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [4220/4579]  eta: 0:02:05  Lr: 0.001875  Loss: 0.2332  Acc@1: 62.5000 (64.6500)  Acc@5: 93.7500 (91.5882)  time: 0.3467  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [4230/4579]  eta: 0:02:02  Lr: 0.001875  Loss: -0.4483  Acc@1: 68.7500 (64.6567)  Acc@5: 93.7500 (91.5963)  time: 0.3467  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [4240/4579]  eta: 0:01:58  Lr: 0.001875  Loss: 0.3058  Acc@1: 68.7500 (64.6605)  Acc@5: 93.7500 (91.5984)  time: 0.3457  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [4250/4579]  eta: 0:01:55  Lr: 0.001875  Loss: -0.1531  Acc@1: 62.5000 (64.6480)  Acc@5: 93.7500 (91.5976)  time: 0.3480  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [4260/4579]  eta: 0:01:51  Lr: 0.001875  Loss: -0.6171  Acc@1: 62.5000 (64.6591)  Acc@5: 93.7500 (91.5953)  time: 0.3517  data: 0.0011  max mem: 2500
Train: Epoch[3/5]  [4270/4579]  eta: 0:01:48  Lr: 0.001875  Loss: 0.0372  Acc@1: 62.5000 (64.6555)  Acc@5: 93.7500 (91.5945)  time: 0.3503  data: 0.0009  max mem: 2500
Train: Epoch[3/5]  [4280/4579]  eta: 0:01:44  Lr: 0.001875  Loss: 0.0806  Acc@1: 68.7500 (64.6578)  Acc@5: 93.7500 (91.5893)  time: 0.3484  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [4290/4579]  eta: 0:01:41  Lr: 0.001875  Loss: -0.7076  Acc@1: 68.7500 (64.6659)  Acc@5: 87.5000 (91.5870)  time: 0.3514  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [4300/4579]  eta: 0:01:37  Lr: 0.001875  Loss: -0.2978  Acc@1: 68.7500 (64.6812)  Acc@5: 93.7500 (91.5964)  time: 0.3554  data: 0.0009  max mem: 2500
Train: Epoch[3/5]  [4310/4579]  eta: 0:01:34  Lr: 0.001875  Loss: 0.1904  Acc@1: 68.7500 (64.6761)  Acc@5: 93.7500 (91.6014)  time: 0.3551  data: 0.0009  max mem: 2500
Train: Epoch[3/5]  [4320/4579]  eta: 0:01:30  Lr: 0.001875  Loss: -0.3362  Acc@1: 62.5000 (64.6841)  Acc@5: 93.7500 (91.5977)  time: 0.3522  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [4330/4579]  eta: 0:01:27  Lr: 0.001875  Loss: -0.2260  Acc@1: 68.7500 (64.6776)  Acc@5: 87.5000 (91.5984)  time: 0.3490  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [4340/4579]  eta: 0:01:23  Lr: 0.001875  Loss: 0.0705  Acc@1: 68.7500 (64.6812)  Acc@5: 93.7500 (91.5990)  time: 0.3484  data: 0.0010  max mem: 2500
Train: Epoch[3/5]  [4350/4579]  eta: 0:01:20  Lr: 0.001875  Loss: -0.2106  Acc@1: 62.5000 (64.6604)  Acc@5: 93.7500 (91.5996)  time: 0.3555  data: 0.0024  max mem: 2500
Train: Epoch[3/5]  [4360/4579]  eta: 0:01:16  Lr: 0.001875  Loss: -0.5620  Acc@1: 56.2500 (64.6655)  Acc@5: 93.7500 (91.6017)  time: 0.3561  data: 0.0020  max mem: 2500
Train: Epoch[3/5]  [4370/4579]  eta: 0:01:13  Lr: 0.001875  Loss: -0.4881  Acc@1: 62.5000 (64.6362)  Acc@5: 93.7500 (91.5952)  time: 0.3506  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [4380/4579]  eta: 0:01:09  Lr: 0.001875  Loss: -0.1989  Acc@1: 62.5000 (64.6413)  Acc@5: 93.7500 (91.5958)  time: 0.3498  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [4390/4579]  eta: 0:01:06  Lr: 0.001875  Loss: 0.0641  Acc@1: 62.5000 (64.6450)  Acc@5: 93.7500 (91.5979)  time: 0.3497  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [4400/4579]  eta: 0:01:02  Lr: 0.001875  Loss: -0.2050  Acc@1: 68.7500 (64.6515)  Acc@5: 93.7500 (91.5942)  time: 0.3516  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [4410/4579]  eta: 0:00:59  Lr: 0.001875  Loss: -0.6387  Acc@1: 56.2500 (64.6438)  Acc@5: 93.7500 (91.5963)  time: 0.3489  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [4420/4579]  eta: 0:00:55  Lr: 0.001875  Loss: -0.6457  Acc@1: 56.2500 (64.6347)  Acc@5: 93.7500 (91.5955)  time: 0.3454  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [4430/4579]  eta: 0:00:52  Lr: 0.001875  Loss: -0.4475  Acc@1: 62.5000 (64.6299)  Acc@5: 87.5000 (91.5877)  time: 0.3521  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [4440/4579]  eta: 0:00:48  Lr: 0.001875  Loss: -0.2658  Acc@1: 68.7500 (64.6349)  Acc@5: 87.5000 (91.5883)  time: 0.3518  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [4450/4579]  eta: 0:00:45  Lr: 0.001875  Loss: 0.3307  Acc@1: 68.7500 (64.6329)  Acc@5: 93.7500 (91.5876)  time: 0.3473  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [4460/4579]  eta: 0:00:41  Lr: 0.001875  Loss: -0.4055  Acc@1: 62.5000 (64.6310)  Acc@5: 93.7500 (91.5854)  time: 0.3517  data: 0.0009  max mem: 2500
Train: Epoch[3/5]  [4470/4579]  eta: 0:00:38  Lr: 0.001875  Loss: -0.5211  Acc@1: 68.7500 (64.6500)  Acc@5: 93.7500 (91.5916)  time: 0.3571  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [4480/4579]  eta: 0:00:34  Lr: 0.001875  Loss: -0.7027  Acc@1: 75.0000 (64.6591)  Acc@5: 93.7500 (91.5923)  time: 0.3561  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [4490/4579]  eta: 0:00:31  Lr: 0.001875  Loss: -0.2871  Acc@1: 62.5000 (64.6501)  Acc@5: 93.7500 (91.5887)  time: 0.3517  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [4500/4579]  eta: 0:00:27  Lr: 0.001875  Loss: -0.4953  Acc@1: 62.5000 (64.6454)  Acc@5: 93.7500 (91.5921)  time: 0.3506  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [4510/4579]  eta: 0:00:24  Lr: 0.001875  Loss: 0.2922  Acc@1: 62.5000 (64.6461)  Acc@5: 93.7500 (91.5872)  time: 0.3493  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [4520/4579]  eta: 0:00:20  Lr: 0.001875  Loss: -0.7901  Acc@1: 68.7500 (64.6552)  Acc@5: 93.7500 (91.5920)  time: 0.3541  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [4530/4579]  eta: 0:00:17  Lr: 0.001875  Loss: -0.3469  Acc@1: 68.7500 (64.6698)  Acc@5: 93.7500 (91.5968)  time: 0.3547  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [4540/4579]  eta: 0:00:13  Lr: 0.001875  Loss: -0.5929  Acc@1: 68.7500 (64.6815)  Acc@5: 93.7500 (91.6001)  time: 0.3496  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [4550/4579]  eta: 0:00:10  Lr: 0.001875  Loss: -0.0799  Acc@1: 62.5000 (64.6712)  Acc@5: 93.7500 (91.5980)  time: 0.3496  data: 0.0011  max mem: 2500
Train: Epoch[3/5]  [4560/4579]  eta: 0:00:06  Lr: 0.001875  Loss: 0.1625  Acc@1: 62.5000 (64.6719)  Acc@5: 87.5000 (91.5959)  time: 0.3493  data: 0.0011  max mem: 2500
Train: Epoch[3/5]  [4570/4579]  eta: 0:00:03  Lr: 0.001875  Loss: -0.5760  Acc@1: 62.5000 (64.6658)  Acc@5: 87.5000 (91.5951)  time: 0.3512  data: 0.0013  max mem: 2500
Train: Epoch[3/5]  [4578/4579]  eta: 0:00:00  Lr: 0.001875  Loss: -0.8735  Acc@1: 62.5000 (64.6723)  Acc@5: 93.7500 (91.5967)  time: 0.3434  data: 0.0013  max mem: 2500
Train: Epoch[3/5] Total time: 0:26:46 (0.3508 s / it)
{0: {0: 219771, 1: 0, 2: 0, 3: 0, 4: 0}, 1: {0: 219771, 1: 0, 2: 0, 3: 0, 4: 0}, 2: {0: 219771, 1: 0, 2: 0, 3: 0, 4: 0}, 3: {0: 219771, 1: 0, 2: 0, 3: 0, 4: 0}, 4: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 5: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 6: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 7: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 8: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 9: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 10: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 11: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 12: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 13: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 14: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 15: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 16: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 17: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 18: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 19: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}}
Averaged stats: Lr: 0.001875  Loss: -0.8735  Acc@1: 62.5000 (64.6723)  Acc@5: 93.7500 (91.5967)
Train: Epoch[4/5]  [   0/4579]  eta: 0:59:32  Lr: 0.001875  Loss: -0.3448  Acc@1: 75.0000 (75.0000)  Acc@5: 93.7500 (93.7500)  time: 0.7802  data: 0.4271  max mem: 2500
Train: Epoch[4/5]  [  10/4579]  eta: 0:29:29  Lr: 0.001875  Loss: 0.1585  Acc@1: 68.7500 (64.7727)  Acc@5: 93.7500 (93.7500)  time: 0.3872  data: 0.0392  max mem: 2500
Train: Epoch[4/5]  [  20/4579]  eta: 0:27:56  Lr: 0.001875  Loss: -0.5888  Acc@1: 68.7500 (64.5833)  Acc@5: 93.7500 (93.4524)  time: 0.3471  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [  30/4579]  eta: 0:27:23  Lr: 0.001875  Loss: -0.0453  Acc@1: 68.7500 (66.1290)  Acc@5: 87.5000 (92.3387)  time: 0.3470  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [  40/4579]  eta: 0:27:03  Lr: 0.001875  Loss: 0.3701  Acc@1: 62.5000 (64.6341)  Acc@5: 87.5000 (91.6159)  time: 0.3472  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [  50/4579]  eta: 0:26:49  Lr: 0.001875  Loss: -0.5586  Acc@1: 68.7500 (66.1765)  Acc@5: 93.7500 (92.2794)  time: 0.3463  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [  60/4579]  eta: 0:26:39  Lr: 0.001875  Loss: -0.0678  Acc@1: 68.7500 (66.7008)  Acc@5: 93.7500 (92.0082)  time: 0.3460  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [  70/4579]  eta: 0:26:32  Lr: 0.001875  Loss: -0.5113  Acc@1: 62.5000 (66.1972)  Acc@5: 87.5000 (91.5493)  time: 0.3476  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [  80/4579]  eta: 0:26:27  Lr: 0.001875  Loss: 0.2950  Acc@1: 62.5000 (65.8179)  Acc@5: 87.5000 (91.6667)  time: 0.3500  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [  90/4579]  eta: 0:26:21  Lr: 0.001875  Loss: -0.0849  Acc@1: 62.5000 (65.8654)  Acc@5: 93.7500 (91.7582)  time: 0.3492  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [ 100/4579]  eta: 0:26:17  Lr: 0.001875  Loss: -0.0497  Acc@1: 68.7500 (66.2129)  Acc@5: 93.7500 (91.7698)  time: 0.3492  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [ 110/4579]  eta: 0:26:13  Lr: 0.001875  Loss: -0.0987  Acc@1: 68.7500 (66.7230)  Acc@5: 93.7500 (91.8356)  time: 0.3506  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [ 120/4579]  eta: 0:26:12  Lr: 0.001875  Loss: -0.2235  Acc@1: 68.7500 (66.2707)  Acc@5: 93.7500 (91.7872)  time: 0.3544  data: 0.0011  max mem: 2500
Train: Epoch[4/5]  [ 130/4579]  eta: 0:26:08  Lr: 0.001875  Loss: -0.7015  Acc@1: 68.7500 (66.4599)  Acc@5: 93.7500 (92.1279)  time: 0.3551  data: 0.0011  max mem: 2500
Train: Epoch[4/5]  [ 140/4579]  eta: 0:26:03  Lr: 0.001875  Loss: -0.2792  Acc@1: 68.7500 (66.6223)  Acc@5: 93.7500 (92.1099)  time: 0.3510  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [ 150/4579]  eta: 0:26:01  Lr: 0.001875  Loss: -0.2490  Acc@1: 68.7500 (66.8046)  Acc@5: 93.7500 (92.1772)  time: 0.3526  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [ 160/4579]  eta: 0:25:56  Lr: 0.001875  Loss: -0.0805  Acc@1: 68.7500 (66.9643)  Acc@5: 93.7500 (91.8866)  time: 0.3524  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [ 170/4579]  eta: 0:25:53  Lr: 0.001875  Loss: -0.0371  Acc@1: 62.5000 (66.7763)  Acc@5: 87.5000 (91.6667)  time: 0.3516  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [ 180/4579]  eta: 0:25:48  Lr: 0.001875  Loss: -0.3064  Acc@1: 62.5000 (66.7127)  Acc@5: 87.5000 (91.6436)  time: 0.3501  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [ 190/4579]  eta: 0:25:45  Lr: 0.001875  Loss: 0.2250  Acc@1: 62.5000 (66.8521)  Acc@5: 93.7500 (91.6558)  time: 0.3497  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 200/4579]  eta: 0:25:41  Lr: 0.001875  Loss: 0.1088  Acc@1: 68.7500 (66.7600)  Acc@5: 93.7500 (91.6978)  time: 0.3511  data: 0.0014  max mem: 2500
Train: Epoch[4/5]  [ 210/4579]  eta: 0:25:37  Lr: 0.001875  Loss: -0.3331  Acc@1: 62.5000 (66.8543)  Acc@5: 93.7500 (91.8246)  time: 0.3503  data: 0.0021  max mem: 2500
Train: Epoch[4/5]  [ 220/4579]  eta: 0:25:33  Lr: 0.001875  Loss: 0.7372  Acc@1: 68.7500 (66.6855)  Acc@5: 93.7500 (91.8835)  time: 0.3498  data: 0.0012  max mem: 2500
Train: Epoch[4/5]  [ 230/4579]  eta: 0:25:28  Lr: 0.001875  Loss: -0.2174  Acc@1: 62.5000 (66.4773)  Acc@5: 93.7500 (91.9913)  time: 0.3470  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [ 240/4579]  eta: 0:25:24  Lr: 0.001875  Loss: -0.2029  Acc@1: 62.5000 (66.5456)  Acc@5: 93.7500 (92.0643)  time: 0.3465  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [ 250/4579]  eta: 0:25:20  Lr: 0.001875  Loss: 0.7351  Acc@1: 68.7500 (66.4592)  Acc@5: 93.7500 (92.0070)  time: 0.3469  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [ 260/4579]  eta: 0:25:15  Lr: 0.001875  Loss: -0.5100  Acc@1: 68.7500 (66.4272)  Acc@5: 93.7500 (92.1216)  time: 0.3457  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [ 270/4579]  eta: 0:25:11  Lr: 0.001875  Loss: 0.7959  Acc@1: 62.5000 (66.1900)  Acc@5: 93.7500 (91.9742)  time: 0.3477  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 280/4579]  eta: 0:25:08  Lr: 0.001875  Loss: -0.6150  Acc@1: 68.7500 (66.3256)  Acc@5: 93.7500 (92.1041)  time: 0.3519  data: 0.0013  max mem: 2500
Train: Epoch[4/5]  [ 290/4579]  eta: 0:25:05  Lr: 0.001875  Loss: 0.3219  Acc@1: 68.7500 (66.3015)  Acc@5: 93.7500 (92.0103)  time: 0.3536  data: 0.0015  max mem: 2500
Train: Epoch[4/5]  [ 300/4579]  eta: 0:25:02  Lr: 0.001875  Loss: -0.0167  Acc@1: 62.5000 (66.1130)  Acc@5: 87.5000 (92.0266)  time: 0.3540  data: 0.0012  max mem: 2500
Train: Epoch[4/5]  [ 310/4579]  eta: 0:24:59  Lr: 0.001875  Loss: -0.2867  Acc@1: 62.5000 (66.0571)  Acc@5: 93.7500 (91.9815)  time: 0.3543  data: 0.0014  max mem: 2500
Train: Epoch[4/5]  [ 320/4579]  eta: 0:24:56  Lr: 0.001875  Loss: 0.1132  Acc@1: 62.5000 (66.0241)  Acc@5: 87.5000 (91.9003)  time: 0.3541  data: 0.0009  max mem: 2500
Train: Epoch[4/5]  [ 330/4579]  eta: 0:24:52  Lr: 0.001875  Loss: -0.0268  Acc@1: 62.5000 (65.8421)  Acc@5: 87.5000 (91.6730)  time: 0.3515  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [ 340/4579]  eta: 0:24:49  Lr: 0.001875  Loss: -0.1277  Acc@1: 68.7500 (65.9274)  Acc@5: 93.7500 (91.6972)  time: 0.3530  data: 0.0010  max mem: 2500
Train: Epoch[4/5]  [ 350/4579]  eta: 0:24:46  Lr: 0.001875  Loss: -0.5266  Acc@1: 68.7500 (66.0078)  Acc@5: 93.7500 (91.7201)  time: 0.3550  data: 0.0009  max mem: 2500
Train: Epoch[4/5]  [ 360/4579]  eta: 0:24:42  Lr: 0.001875  Loss: -0.1334  Acc@1: 68.7500 (66.0319)  Acc@5: 87.5000 (91.6551)  time: 0.3515  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [ 370/4579]  eta: 0:24:38  Lr: 0.001875  Loss: -0.3066  Acc@1: 68.7500 (66.0546)  Acc@5: 87.5000 (91.5263)  time: 0.3489  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 380/4579]  eta: 0:24:35  Lr: 0.001875  Loss: -0.2298  Acc@1: 62.5000 (66.0597)  Acc@5: 87.5000 (91.5354)  time: 0.3515  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 390/4579]  eta: 0:24:32  Lr: 0.001875  Loss: -0.3035  Acc@1: 62.5000 (65.9047)  Acc@5: 87.5000 (91.4642)  time: 0.3521  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 400/4579]  eta: 0:24:28  Lr: 0.001875  Loss: -0.1024  Acc@1: 56.2500 (65.7887)  Acc@5: 87.5000 (91.4121)  time: 0.3490  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [ 410/4579]  eta: 0:24:24  Lr: 0.001875  Loss: -0.3093  Acc@1: 68.7500 (65.9519)  Acc@5: 93.7500 (91.4842)  time: 0.3485  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 420/4579]  eta: 0:24:20  Lr: 0.001875  Loss: -0.5753  Acc@1: 68.7500 (65.9887)  Acc@5: 93.7500 (91.5380)  time: 0.3462  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [ 430/4579]  eta: 0:24:16  Lr: 0.001875  Loss: -0.2436  Acc@1: 68.7500 (66.0673)  Acc@5: 93.7500 (91.5168)  time: 0.3469  data: 0.0009  max mem: 2500
Train: Epoch[4/5]  [ 440/4579]  eta: 0:24:12  Lr: 0.001875  Loss: -0.7215  Acc@1: 68.7500 (66.1565)  Acc@5: 93.7500 (91.6241)  time: 0.3475  data: 0.0010  max mem: 2500
Train: Epoch[4/5]  [ 450/4579]  eta: 0:24:08  Lr: 0.001875  Loss: 0.0492  Acc@1: 62.5000 (66.0338)  Acc@5: 93.7500 (91.6020)  time: 0.3466  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [ 460/4579]  eta: 0:24:05  Lr: 0.001875  Loss: -0.4239  Acc@1: 62.5000 (66.0249)  Acc@5: 93.7500 (91.6486)  time: 0.3482  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 470/4579]  eta: 0:24:02  Lr: 0.001875  Loss: 0.2893  Acc@1: 62.5000 (65.8174)  Acc@5: 93.7500 (91.5870)  time: 0.3533  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [ 480/4579]  eta: 0:23:58  Lr: 0.001875  Loss: 0.1459  Acc@1: 62.5000 (65.7484)  Acc@5: 87.5000 (91.5800)  time: 0.3545  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [ 490/4579]  eta: 0:23:54  Lr: 0.001875  Loss: 0.1610  Acc@1: 62.5000 (65.5804)  Acc@5: 93.7500 (91.5860)  time: 0.3492  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 500/4579]  eta: 0:23:51  Lr: 0.001875  Loss: -0.2974  Acc@1: 56.2500 (65.4691)  Acc@5: 93.7500 (91.6043)  time: 0.3481  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [ 510/4579]  eta: 0:23:47  Lr: 0.001875  Loss: -0.2823  Acc@1: 62.5000 (65.3376)  Acc@5: 93.7500 (91.5851)  time: 0.3519  data: 0.0014  max mem: 2500
Train: Epoch[4/5]  [ 520/4579]  eta: 0:23:44  Lr: 0.001875  Loss: 0.0760  Acc@1: 62.5000 (65.3911)  Acc@5: 93.7500 (91.6387)  time: 0.3534  data: 0.0014  max mem: 2500
Train: Epoch[4/5]  [ 530/4579]  eta: 0:23:41  Lr: 0.001875  Loss: -0.6002  Acc@1: 62.5000 (65.3837)  Acc@5: 93.7500 (91.6667)  time: 0.3534  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [ 540/4579]  eta: 0:23:37  Lr: 0.001875  Loss: -0.6147  Acc@1: 62.5000 (65.4113)  Acc@5: 93.7500 (91.6474)  time: 0.3520  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [ 550/4579]  eta: 0:23:33  Lr: 0.001875  Loss: -0.7524  Acc@1: 62.5000 (65.3017)  Acc@5: 93.7500 (91.6629)  time: 0.3486  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [ 560/4579]  eta: 0:23:30  Lr: 0.001875  Loss: -0.4034  Acc@1: 62.5000 (65.3186)  Acc@5: 87.5000 (91.6555)  time: 0.3522  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [ 570/4579]  eta: 0:23:27  Lr: 0.001875  Loss: 0.0418  Acc@1: 62.5000 (65.2583)  Acc@5: 87.5000 (91.6375)  time: 0.3521  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 580/4579]  eta: 0:23:23  Lr: 0.001875  Loss: -0.2794  Acc@1: 62.5000 (65.2754)  Acc@5: 93.7500 (91.6631)  time: 0.3480  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 590/4579]  eta: 0:23:19  Lr: 0.001875  Loss: -0.3835  Acc@1: 62.5000 (65.1861)  Acc@5: 93.7500 (91.6878)  time: 0.3479  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [ 600/4579]  eta: 0:23:15  Lr: 0.001875  Loss: -0.6284  Acc@1: 62.5000 (65.1934)  Acc@5: 93.7500 (91.7533)  time: 0.3478  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [ 610/4579]  eta: 0:23:12  Lr: 0.001875  Loss: 0.0341  Acc@1: 62.5000 (65.2312)  Acc@5: 93.7500 (91.7860)  time: 0.3485  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 620/4579]  eta: 0:23:08  Lr: 0.001875  Loss: -0.0364  Acc@1: 62.5000 (65.2174)  Acc@5: 93.7500 (91.6969)  time: 0.3471  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [ 630/4579]  eta: 0:23:04  Lr: 0.001875  Loss: -0.5654  Acc@1: 62.5000 (65.2536)  Acc@5: 93.7500 (91.7195)  time: 0.3455  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [ 640/4579]  eta: 0:23:00  Lr: 0.001875  Loss: -0.2118  Acc@1: 68.7500 (65.2399)  Acc@5: 93.7500 (91.7317)  time: 0.3457  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [ 650/4579]  eta: 0:22:57  Lr: 0.001875  Loss: -0.3327  Acc@1: 62.5000 (65.2362)  Acc@5: 93.7500 (91.7147)  time: 0.3465  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 660/4579]  eta: 0:22:53  Lr: 0.001875  Loss: -0.2688  Acc@1: 68.7500 (65.2893)  Acc@5: 93.7500 (91.7549)  time: 0.3468  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 670/4579]  eta: 0:22:49  Lr: 0.001875  Loss: 0.0988  Acc@1: 68.7500 (65.3130)  Acc@5: 93.7500 (91.7567)  time: 0.3493  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 680/4579]  eta: 0:22:46  Lr: 0.001875  Loss: 0.2750  Acc@1: 62.5000 (65.2717)  Acc@5: 93.7500 (91.7584)  time: 0.3519  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [ 690/4579]  eta: 0:22:42  Lr: 0.001875  Loss: -0.4926  Acc@1: 68.7500 (65.2949)  Acc@5: 93.7500 (91.7601)  time: 0.3507  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [ 700/4579]  eta: 0:22:40  Lr: 0.001875  Loss: -0.1897  Acc@1: 62.5000 (65.2461)  Acc@5: 93.7500 (91.7707)  time: 0.3548  data: 0.0023  max mem: 2500
Train: Epoch[4/5]  [ 710/4579]  eta: 0:22:36  Lr: 0.001875  Loss: 0.0261  Acc@1: 62.5000 (65.2602)  Acc@5: 93.7500 (91.8161)  time: 0.3560  data: 0.0024  max mem: 2500
Train: Epoch[4/5]  [ 720/4579]  eta: 0:22:33  Lr: 0.001875  Loss: -0.8731  Acc@1: 62.5000 (65.2739)  Acc@5: 93.7500 (91.7996)  time: 0.3519  data: 0.0014  max mem: 2500
Train: Epoch[4/5]  [ 730/4579]  eta: 0:22:29  Lr: 0.001875  Loss: 0.4060  Acc@1: 62.5000 (65.3300)  Acc@5: 93.7500 (91.8092)  time: 0.3510  data: 0.0014  max mem: 2500
Train: Epoch[4/5]  [ 740/4579]  eta: 0:22:26  Lr: 0.001875  Loss: -0.6318  Acc@1: 62.5000 (65.3424)  Acc@5: 93.7500 (91.8607)  time: 0.3524  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [ 750/4579]  eta: 0:22:22  Lr: 0.001875  Loss: 0.3014  Acc@1: 62.5000 (65.3129)  Acc@5: 93.7500 (91.8692)  time: 0.3525  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [ 760/4579]  eta: 0:22:19  Lr: 0.001875  Loss: 0.0907  Acc@1: 62.5000 (65.3170)  Acc@5: 93.7500 (91.9021)  time: 0.3496  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [ 770/4579]  eta: 0:22:15  Lr: 0.001875  Loss: -0.4522  Acc@1: 62.5000 (65.2643)  Acc@5: 93.7500 (91.8855)  time: 0.3502  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 780/4579]  eta: 0:22:12  Lr: 0.001875  Loss: 0.3802  Acc@1: 62.5000 (65.1969)  Acc@5: 87.5000 (91.8854)  time: 0.3496  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [ 790/4579]  eta: 0:22:08  Lr: 0.001875  Loss: -0.1882  Acc@1: 62.5000 (65.2418)  Acc@5: 87.5000 (91.8537)  time: 0.3480  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 800/4579]  eta: 0:22:05  Lr: 0.001875  Loss: -0.5612  Acc@1: 62.5000 (65.2466)  Acc@5: 87.5000 (91.8227)  time: 0.3504  data: 0.0011  max mem: 2500
Train: Epoch[4/5]  [ 810/4579]  eta: 0:22:01  Lr: 0.001875  Loss: -0.5753  Acc@1: 62.5000 (65.2589)  Acc@5: 87.5000 (91.8002)  time: 0.3493  data: 0.0011  max mem: 2500
Train: Epoch[4/5]  [ 820/4579]  eta: 0:21:57  Lr: 0.001875  Loss: -0.4569  Acc@1: 68.7500 (65.3243)  Acc@5: 93.7500 (91.8088)  time: 0.3460  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 830/4579]  eta: 0:21:54  Lr: 0.001875  Loss: -0.1689  Acc@1: 68.7500 (65.2828)  Acc@5: 93.7500 (91.8171)  time: 0.3475  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [ 840/4579]  eta: 0:21:50  Lr: 0.001875  Loss: -0.9577  Acc@1: 62.5000 (65.3389)  Acc@5: 93.7500 (91.8624)  time: 0.3491  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 850/4579]  eta: 0:21:46  Lr: 0.001875  Loss: -0.3630  Acc@1: 62.5000 (65.2688)  Acc@5: 93.7500 (91.8405)  time: 0.3472  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 860/4579]  eta: 0:21:43  Lr: 0.001875  Loss: -0.1891  Acc@1: 62.5000 (65.3455)  Acc@5: 93.7500 (91.8554)  time: 0.3475  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [ 870/4579]  eta: 0:21:39  Lr: 0.001875  Loss: -0.0761  Acc@1: 68.7500 (65.4061)  Acc@5: 93.7500 (91.8987)  time: 0.3523  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [ 880/4579]  eta: 0:21:36  Lr: 0.001875  Loss: -0.4328  Acc@1: 62.5000 (65.3802)  Acc@5: 93.7500 (91.8771)  time: 0.3538  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [ 890/4579]  eta: 0:21:33  Lr: 0.001875  Loss: 0.3582  Acc@1: 62.5000 (65.3690)  Acc@5: 93.7500 (91.8911)  time: 0.3551  data: 0.0009  max mem: 2500
Train: Epoch[4/5]  [ 900/4579]  eta: 0:21:29  Lr: 0.001875  Loss: 0.1052  Acc@1: 68.7500 (65.4412)  Acc@5: 93.7500 (91.9256)  time: 0.3559  data: 0.0011  max mem: 2500
Train: Epoch[4/5]  [ 910/4579]  eta: 0:21:26  Lr: 0.001875  Loss: -0.7317  Acc@1: 75.0000 (65.5118)  Acc@5: 93.7500 (91.9319)  time: 0.3517  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [ 920/4579]  eta: 0:21:23  Lr: 0.001875  Loss: -0.1876  Acc@1: 68.7500 (65.5266)  Acc@5: 93.7500 (91.9042)  time: 0.3535  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [ 930/4579]  eta: 0:21:19  Lr: 0.001875  Loss: -0.4551  Acc@1: 62.5000 (65.4605)  Acc@5: 93.7500 (91.8837)  time: 0.3564  data: 0.0015  max mem: 2500
Train: Epoch[4/5]  [ 940/4579]  eta: 0:21:16  Lr: 0.001875  Loss: -0.4646  Acc@1: 62.5000 (65.5021)  Acc@5: 93.7500 (91.8836)  time: 0.3541  data: 0.0015  max mem: 2500
Train: Epoch[4/5]  [ 950/4579]  eta: 0:21:12  Lr: 0.001875  Loss: -0.0395  Acc@1: 62.5000 (65.4640)  Acc@5: 93.7500 (91.8967)  time: 0.3514  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [ 960/4579]  eta: 0:21:09  Lr: 0.001875  Loss: -0.2093  Acc@1: 62.5000 (65.4982)  Acc@5: 93.7500 (91.8900)  time: 0.3491  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 970/4579]  eta: 0:21:05  Lr: 0.001875  Loss: -0.3079  Acc@1: 68.7500 (65.4737)  Acc@5: 93.7500 (91.8512)  time: 0.3524  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [ 980/4579]  eta: 0:21:02  Lr: 0.001875  Loss: -0.4400  Acc@1: 62.5000 (65.4498)  Acc@5: 93.7500 (91.8259)  time: 0.3523  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [ 990/4579]  eta: 0:20:58  Lr: 0.001875  Loss: -0.6122  Acc@1: 62.5000 (65.5083)  Acc@5: 87.5000 (91.8012)  time: 0.3479  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1000/4579]  eta: 0:20:55  Lr: 0.001875  Loss: 0.1428  Acc@1: 62.5000 (65.4658)  Acc@5: 87.5000 (91.7770)  time: 0.3477  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [1010/4579]  eta: 0:20:51  Lr: 0.001875  Loss: -0.0379  Acc@1: 62.5000 (65.4364)  Acc@5: 87.5000 (91.7532)  time: 0.3481  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1020/4579]  eta: 0:20:47  Lr: 0.001875  Loss: -0.1922  Acc@1: 68.7500 (65.4628)  Acc@5: 93.7500 (91.7789)  time: 0.3481  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1030/4579]  eta: 0:20:44  Lr: 0.001875  Loss: -0.3031  Acc@1: 68.7500 (65.5432)  Acc@5: 93.7500 (91.7980)  time: 0.3466  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [1040/4579]  eta: 0:20:40  Lr: 0.001875  Loss: -0.1430  Acc@1: 68.7500 (65.5199)  Acc@5: 87.5000 (91.7807)  time: 0.3456  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [1050/4579]  eta: 0:20:37  Lr: 0.001875  Loss: 0.1876  Acc@1: 62.5000 (65.4734)  Acc@5: 87.5000 (91.7519)  time: 0.3490  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1060/4579]  eta: 0:20:33  Lr: 0.001875  Loss: -0.3916  Acc@1: 62.5000 (65.4630)  Acc@5: 93.7500 (91.7766)  time: 0.3536  data: 0.0014  max mem: 2500
Train: Epoch[4/5]  [1070/4579]  eta: 0:20:30  Lr: 0.001875  Loss: -0.3579  Acc@1: 68.7500 (65.4704)  Acc@5: 93.7500 (91.8126)  time: 0.3528  data: 0.0016  max mem: 2500
Train: Epoch[4/5]  [1080/4579]  eta: 0:20:26  Lr: 0.001875  Loss: -0.3151  Acc@1: 62.5000 (65.4544)  Acc@5: 93.7500 (91.8131)  time: 0.3505  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [1090/4579]  eta: 0:20:23  Lr: 0.001875  Loss: -0.4502  Acc@1: 62.5000 (65.4102)  Acc@5: 87.5000 (91.7736)  time: 0.3504  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [1100/4579]  eta: 0:20:20  Lr: 0.001875  Loss: -0.5436  Acc@1: 68.7500 (65.4064)  Acc@5: 87.5000 (91.7916)  time: 0.3566  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [1110/4579]  eta: 0:20:16  Lr: 0.001875  Loss: -0.4329  Acc@1: 68.7500 (65.4309)  Acc@5: 93.7500 (91.7698)  time: 0.3581  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [1120/4579]  eta: 0:20:13  Lr: 0.001875  Loss: -0.0678  Acc@1: 62.5000 (65.4326)  Acc@5: 93.7500 (91.7875)  time: 0.3528  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [1130/4579]  eta: 0:20:09  Lr: 0.001875  Loss: -0.1300  Acc@1: 62.5000 (65.4344)  Acc@5: 93.7500 (91.7882)  time: 0.3520  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [1140/4579]  eta: 0:20:06  Lr: 0.001875  Loss: -0.2242  Acc@1: 62.5000 (65.4196)  Acc@5: 93.7500 (91.7616)  time: 0.3498  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [1150/4579]  eta: 0:20:02  Lr: 0.001875  Loss: -0.2974  Acc@1: 62.5000 (65.3997)  Acc@5: 93.7500 (91.7463)  time: 0.3493  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1160/4579]  eta: 0:19:59  Lr: 0.001875  Loss: 0.2767  Acc@1: 62.5000 (65.3639)  Acc@5: 87.5000 (91.7259)  time: 0.3524  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1170/4579]  eta: 0:19:55  Lr: 0.001875  Loss: -0.4349  Acc@1: 62.5000 (65.3128)  Acc@5: 87.5000 (91.7058)  time: 0.3508  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1180/4579]  eta: 0:19:52  Lr: 0.001875  Loss: -0.0662  Acc@1: 56.2500 (65.3154)  Acc@5: 93.7500 (91.7019)  time: 0.3479  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [1190/4579]  eta: 0:19:48  Lr: 0.001875  Loss: -0.1033  Acc@1: 62.5000 (65.3547)  Acc@5: 93.7500 (91.7244)  time: 0.3486  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [1200/4579]  eta: 0:19:44  Lr: 0.001875  Loss: -0.3570  Acc@1: 68.7500 (65.3986)  Acc@5: 93.7500 (91.7465)  time: 0.3486  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1210/4579]  eta: 0:19:41  Lr: 0.001875  Loss: -0.2947  Acc@1: 68.7500 (65.3902)  Acc@5: 93.7500 (91.7630)  time: 0.3475  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [1220/4579]  eta: 0:19:37  Lr: 0.001875  Loss: -0.3865  Acc@1: 62.5000 (65.3563)  Acc@5: 93.7500 (91.7639)  time: 0.3463  data: 0.0002  max mem: 2500
Train: Epoch[4/5]  [1230/4579]  eta: 0:19:34  Lr: 0.001875  Loss: -0.9421  Acc@1: 68.7500 (65.3940)  Acc@5: 93.7500 (91.7953)  time: 0.3468  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [1240/4579]  eta: 0:19:30  Lr: 0.001875  Loss: -0.0760  Acc@1: 68.7500 (65.3807)  Acc@5: 93.7500 (91.8211)  time: 0.3475  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1250/4579]  eta: 0:19:26  Lr: 0.001875  Loss: -0.0034  Acc@1: 62.5000 (65.3927)  Acc@5: 93.7500 (91.8615)  time: 0.3494  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [1260/4579]  eta: 0:19:23  Lr: 0.001875  Loss: -0.0130  Acc@1: 62.5000 (65.4144)  Acc@5: 93.7500 (91.8715)  time: 0.3514  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [1270/4579]  eta: 0:19:20  Lr: 0.001875  Loss: -0.1312  Acc@1: 68.7500 (65.4406)  Acc@5: 93.7500 (91.8814)  time: 0.3511  data: 0.0014  max mem: 2500
Train: Epoch[4/5]  [1280/4579]  eta: 0:19:16  Lr: 0.001875  Loss: 0.5160  Acc@1: 62.5000 (65.4323)  Acc@5: 93.7500 (91.8716)  time: 0.3518  data: 0.0014  max mem: 2500
Train: Epoch[4/5]  [1290/4579]  eta: 0:19:13  Lr: 0.001875  Loss: -0.0045  Acc@1: 62.5000 (65.4435)  Acc@5: 87.5000 (91.8377)  time: 0.3534  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [1300/4579]  eta: 0:19:09  Lr: 0.001875  Loss: -0.2522  Acc@1: 68.7500 (65.4929)  Acc@5: 87.5000 (91.8380)  time: 0.3547  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [1310/4579]  eta: 0:19:06  Lr: 0.001875  Loss: -0.5817  Acc@1: 68.7500 (65.5273)  Acc@5: 93.7500 (91.8335)  time: 0.3524  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [1320/4579]  eta: 0:19:02  Lr: 0.001875  Loss: -0.5747  Acc@1: 68.7500 (65.5469)  Acc@5: 93.7500 (91.8433)  time: 0.3510  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [1330/4579]  eta: 0:18:59  Lr: 0.001875  Loss: 0.0051  Acc@1: 68.7500 (65.5569)  Acc@5: 93.7500 (91.8529)  time: 0.3534  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [1340/4579]  eta: 0:18:55  Lr: 0.001875  Loss: 0.2155  Acc@1: 62.5000 (65.5248)  Acc@5: 93.7500 (91.8391)  time: 0.3513  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [1350/4579]  eta: 0:18:52  Lr: 0.001875  Loss: -0.1214  Acc@1: 68.7500 (65.5579)  Acc@5: 87.5000 (91.8255)  time: 0.3479  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1360/4579]  eta: 0:18:48  Lr: 0.001875  Loss: -0.1716  Acc@1: 62.5000 (65.5584)  Acc@5: 87.5000 (91.8259)  time: 0.3498  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1370/4579]  eta: 0:18:45  Lr: 0.001875  Loss: -0.0954  Acc@1: 62.5000 (65.5543)  Acc@5: 87.5000 (91.7989)  time: 0.3501  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1380/4579]  eta: 0:18:41  Lr: 0.001875  Loss: -0.6341  Acc@1: 68.7500 (65.5684)  Acc@5: 87.5000 (91.8085)  time: 0.3484  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1390/4579]  eta: 0:18:38  Lr: 0.001875  Loss: -0.4426  Acc@1: 62.5000 (65.5464)  Acc@5: 93.7500 (91.7955)  time: 0.3483  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [1400/4579]  eta: 0:18:34  Lr: 0.001875  Loss: 0.3589  Acc@1: 62.5000 (65.5202)  Acc@5: 87.5000 (91.7960)  time: 0.3466  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [1410/4579]  eta: 0:18:30  Lr: 0.001875  Loss: -0.0522  Acc@1: 62.5000 (65.4988)  Acc@5: 93.7500 (91.8099)  time: 0.3458  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [1420/4579]  eta: 0:18:27  Lr: 0.001875  Loss: -0.3295  Acc@1: 56.2500 (65.4689)  Acc@5: 93.7500 (91.7884)  time: 0.3468  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [1430/4579]  eta: 0:18:23  Lr: 0.001875  Loss: -0.6339  Acc@1: 68.7500 (65.5136)  Acc@5: 93.7500 (91.7890)  time: 0.3487  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [1440/4579]  eta: 0:18:20  Lr: 0.001875  Loss: -0.4178  Acc@1: 68.7500 (65.5274)  Acc@5: 93.7500 (91.8026)  time: 0.3495  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [1450/4579]  eta: 0:18:16  Lr: 0.001875  Loss: 0.1073  Acc@1: 62.5000 (65.5195)  Acc@5: 87.5000 (91.7729)  time: 0.3511  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [1460/4579]  eta: 0:18:13  Lr: 0.001875  Loss: -0.3665  Acc@1: 68.7500 (65.5416)  Acc@5: 87.5000 (91.7779)  time: 0.3537  data: 0.0014  max mem: 2500
Train: Epoch[4/5]  [1470/4579]  eta: 0:18:09  Lr: 0.001875  Loss: -0.0068  Acc@1: 68.7500 (65.5379)  Acc@5: 93.7500 (91.7658)  time: 0.3568  data: 0.0031  max mem: 2500
Train: Epoch[4/5]  [1480/4579]  eta: 0:18:06  Lr: 0.001875  Loss: -0.4814  Acc@1: 68.7500 (65.4878)  Acc@5: 93.7500 (91.7623)  time: 0.3562  data: 0.0023  max mem: 2500
Train: Epoch[4/5]  [1490/4579]  eta: 0:18:03  Lr: 0.001875  Loss: -0.7809  Acc@1: 62.5000 (65.4888)  Acc@5: 93.7500 (91.7547)  time: 0.3518  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [1500/4579]  eta: 0:17:59  Lr: 0.001875  Loss: -0.3369  Acc@1: 68.7500 (65.4897)  Acc@5: 93.7500 (91.7513)  time: 0.3513  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [1510/4579]  eta: 0:17:56  Lr: 0.001875  Loss: -0.1408  Acc@1: 68.7500 (65.5071)  Acc@5: 93.7500 (91.7480)  time: 0.3553  data: 0.0010  max mem: 2500
Train: Epoch[4/5]  [1520/4579]  eta: 0:17:52  Lr: 0.001875  Loss: 0.0156  Acc@1: 62.5000 (65.4956)  Acc@5: 87.5000 (91.7447)  time: 0.3563  data: 0.0022  max mem: 2500
Train: Epoch[4/5]  [1530/4579]  eta: 0:17:49  Lr: 0.001875  Loss: -0.3450  Acc@1: 62.5000 (65.4801)  Acc@5: 87.5000 (91.7252)  time: 0.3519  data: 0.0016  max mem: 2500
Train: Epoch[4/5]  [1540/4579]  eta: 0:17:45  Lr: 0.001875  Loss: -0.6306  Acc@1: 62.5000 (65.5013)  Acc@5: 93.7500 (91.7545)  time: 0.3487  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1550/4579]  eta: 0:17:42  Lr: 0.001875  Loss: 0.2863  Acc@1: 62.5000 (65.4699)  Acc@5: 93.7500 (91.7513)  time: 0.3483  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1560/4579]  eta: 0:17:38  Lr: 0.001875  Loss: 0.6198  Acc@1: 62.5000 (65.4388)  Acc@5: 87.5000 (91.7321)  time: 0.3487  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1570/4579]  eta: 0:17:35  Lr: 0.001875  Loss: -0.2525  Acc@1: 56.2500 (65.4201)  Acc@5: 87.5000 (91.7290)  time: 0.3477  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1580/4579]  eta: 0:17:31  Lr: 0.001875  Loss: -0.9349  Acc@1: 68.7500 (65.4688)  Acc@5: 93.7500 (91.7418)  time: 0.3474  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [1590/4579]  eta: 0:17:27  Lr: 0.001875  Loss: 0.0375  Acc@1: 68.7500 (65.4698)  Acc@5: 87.5000 (91.7151)  time: 0.3467  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [1600/4579]  eta: 0:17:24  Lr: 0.001875  Loss: -0.3035  Acc@1: 62.5000 (65.4747)  Acc@5: 87.5000 (91.7083)  time: 0.3463  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [1610/4579]  eta: 0:17:20  Lr: 0.001875  Loss: -0.0709  Acc@1: 62.5000 (65.4989)  Acc@5: 93.7500 (91.7249)  time: 0.3462  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [1620/4579]  eta: 0:17:17  Lr: 0.001875  Loss: -0.6216  Acc@1: 68.7500 (65.4920)  Acc@5: 93.7500 (91.7104)  time: 0.3463  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [1630/4579]  eta: 0:17:13  Lr: 0.001875  Loss: 0.2840  Acc@1: 68.7500 (65.4966)  Acc@5: 87.5000 (91.7190)  time: 0.3504  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1640/4579]  eta: 0:17:10  Lr: 0.001875  Loss: -0.6016  Acc@1: 62.5000 (65.4479)  Acc@5: 93.7500 (91.6971)  time: 0.3531  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [1650/4579]  eta: 0:17:06  Lr: 0.001875  Loss: -0.4312  Acc@1: 62.5000 (65.4338)  Acc@5: 87.5000 (91.6906)  time: 0.3492  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [1660/4579]  eta: 0:17:03  Lr: 0.001875  Loss: -0.0873  Acc@1: 68.7500 (65.4350)  Acc@5: 93.7500 (91.6842)  time: 0.3472  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [1670/4579]  eta: 0:16:59  Lr: 0.001875  Loss: 0.3100  Acc@1: 68.7500 (65.4623)  Acc@5: 93.7500 (91.6891)  time: 0.3513  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [1680/4579]  eta: 0:16:56  Lr: 0.001875  Loss: 0.2229  Acc@1: 56.2500 (65.4298)  Acc@5: 93.7500 (91.6865)  time: 0.3574  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [1690/4579]  eta: 0:16:52  Lr: 0.001875  Loss: -0.8557  Acc@1: 56.2500 (65.4162)  Acc@5: 93.7500 (91.6765)  time: 0.3559  data: 0.0011  max mem: 2500
Train: Epoch[4/5]  [1700/4579]  eta: 0:16:49  Lr: 0.001875  Loss: -0.4710  Acc@1: 62.5000 (65.4505)  Acc@5: 93.7500 (91.6961)  time: 0.3491  data: 0.0010  max mem: 2500
Train: Epoch[4/5]  [1710/4579]  eta: 0:16:45  Lr: 0.001875  Loss: -0.3982  Acc@1: 75.0000 (65.4990)  Acc@5: 93.7500 (91.7190)  time: 0.3486  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [1720/4579]  eta: 0:16:42  Lr: 0.001875  Loss: 0.1461  Acc@1: 68.7500 (65.5142)  Acc@5: 93.7500 (91.7345)  time: 0.3528  data: 0.0009  max mem: 2500
Train: Epoch[4/5]  [1730/4579]  eta: 0:16:38  Lr: 0.001875  Loss: -0.3684  Acc@1: 68.7500 (65.5546)  Acc@5: 93.7500 (91.7461)  time: 0.3517  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [1740/4579]  eta: 0:16:35  Lr: 0.001875  Loss: -0.1581  Acc@1: 75.0000 (65.5765)  Acc@5: 93.7500 (91.7504)  time: 0.3488  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1750/4579]  eta: 0:16:31  Lr: 0.001875  Loss: -0.6036  Acc@1: 56.2500 (65.5447)  Acc@5: 87.5000 (91.7476)  time: 0.3490  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1760/4579]  eta: 0:16:28  Lr: 0.001875  Loss: -0.1855  Acc@1: 62.5000 (65.5487)  Acc@5: 93.7500 (91.7412)  time: 0.3487  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [1770/4579]  eta: 0:16:24  Lr: 0.001875  Loss: -0.0221  Acc@1: 62.5000 (65.5562)  Acc@5: 93.7500 (91.7455)  time: 0.3507  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [1780/4579]  eta: 0:16:21  Lr: 0.001875  Loss: 0.0050  Acc@1: 68.7500 (65.5706)  Acc@5: 93.7500 (91.7462)  time: 0.3497  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [1790/4579]  eta: 0:16:17  Lr: 0.001875  Loss: 0.1452  Acc@1: 62.5000 (65.5500)  Acc@5: 93.7500 (91.7539)  time: 0.3461  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1800/4579]  eta: 0:16:13  Lr: 0.001875  Loss: 0.0013  Acc@1: 62.5000 (65.5400)  Acc@5: 93.7500 (91.7372)  time: 0.3455  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [1810/4579]  eta: 0:16:10  Lr: 0.001875  Loss: 0.0193  Acc@1: 62.5000 (65.5266)  Acc@5: 87.5000 (91.7207)  time: 0.3466  data: 0.0012  max mem: 2500
Train: Epoch[4/5]  [1820/4579]  eta: 0:16:06  Lr: 0.001875  Loss: 0.6293  Acc@1: 62.5000 (65.4997)  Acc@5: 93.7500 (91.7181)  time: 0.3499  data: 0.0011  max mem: 2500
Train: Epoch[4/5]  [1830/4579]  eta: 0:16:03  Lr: 0.001875  Loss: -0.0248  Acc@1: 62.5000 (65.4970)  Acc@5: 87.5000 (91.7019)  time: 0.3513  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [1840/4579]  eta: 0:15:59  Lr: 0.001875  Loss: -0.0336  Acc@1: 68.7500 (65.4943)  Acc@5: 93.7500 (91.7199)  time: 0.3492  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [1850/4579]  eta: 0:15:56  Lr: 0.001875  Loss: -0.1041  Acc@1: 68.7500 (65.5153)  Acc@5: 93.7500 (91.7410)  time: 0.3500  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1860/4579]  eta: 0:15:52  Lr: 0.001875  Loss: -0.0332  Acc@1: 68.7500 (65.5293)  Acc@5: 93.7500 (91.7417)  time: 0.3527  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [1870/4579]  eta: 0:15:49  Lr: 0.001875  Loss: -0.1220  Acc@1: 62.5000 (65.5131)  Acc@5: 93.7500 (91.7491)  time: 0.3531  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [1880/4579]  eta: 0:15:45  Lr: 0.001875  Loss: -0.7979  Acc@1: 62.5000 (65.5203)  Acc@5: 93.7500 (91.7663)  time: 0.3505  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [1890/4579]  eta: 0:15:42  Lr: 0.001875  Loss: -0.1585  Acc@1: 56.2500 (65.4878)  Acc@5: 93.7500 (91.7603)  time: 0.3495  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [1900/4579]  eta: 0:15:38  Lr: 0.001875  Loss: -0.1175  Acc@1: 56.2500 (65.4721)  Acc@5: 93.7500 (91.7576)  time: 0.3511  data: 0.0009  max mem: 2500
Train: Epoch[4/5]  [1910/4579]  eta: 0:15:35  Lr: 0.001875  Loss: -0.5055  Acc@1: 62.5000 (65.4664)  Acc@5: 93.7500 (91.7517)  time: 0.3519  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [1920/4579]  eta: 0:15:31  Lr: 0.001875  Loss: -0.5336  Acc@1: 62.5000 (65.4737)  Acc@5: 93.7500 (91.7588)  time: 0.3500  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [1930/4579]  eta: 0:15:28  Lr: 0.001875  Loss: -0.5945  Acc@1: 68.7500 (65.4777)  Acc@5: 93.7500 (91.7595)  time: 0.3492  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [1940/4579]  eta: 0:15:24  Lr: 0.001875  Loss: 0.0049  Acc@1: 62.5000 (65.4785)  Acc@5: 93.7500 (91.7697)  time: 0.3493  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [1950/4579]  eta: 0:15:21  Lr: 0.001875  Loss: 0.0576  Acc@1: 62.5000 (65.4824)  Acc@5: 93.7500 (91.7767)  time: 0.3486  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1960/4579]  eta: 0:15:17  Lr: 0.001875  Loss: -0.1428  Acc@1: 68.7500 (65.4864)  Acc@5: 93.7500 (91.7803)  time: 0.3480  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1970/4579]  eta: 0:15:14  Lr: 0.001875  Loss: 0.2419  Acc@1: 68.7500 (65.4744)  Acc@5: 93.7500 (91.7808)  time: 0.3467  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1980/4579]  eta: 0:15:10  Lr: 0.001875  Loss: -0.3174  Acc@1: 62.5000 (65.4594)  Acc@5: 93.7500 (91.7908)  time: 0.3473  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1990/4579]  eta: 0:15:07  Lr: 0.001875  Loss: -0.4970  Acc@1: 62.5000 (65.4696)  Acc@5: 93.7500 (91.7849)  time: 0.3477  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [2000/4579]  eta: 0:15:03  Lr: 0.001875  Loss: 0.1770  Acc@1: 68.7500 (65.4766)  Acc@5: 93.7500 (91.7947)  time: 0.3468  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2010/4579]  eta: 0:15:00  Lr: 0.001875  Loss: -0.3262  Acc@1: 68.7500 (65.4587)  Acc@5: 93.7500 (91.7889)  time: 0.3487  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2020/4579]  eta: 0:14:56  Lr: 0.001875  Loss: -0.6939  Acc@1: 62.5000 (65.4472)  Acc@5: 93.7500 (91.7955)  time: 0.3507  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2030/4579]  eta: 0:14:53  Lr: 0.001875  Loss: -0.6956  Acc@1: 62.5000 (65.4419)  Acc@5: 93.7500 (91.7898)  time: 0.3502  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2040/4579]  eta: 0:14:49  Lr: 0.001875  Loss: -0.6439  Acc@1: 68.7500 (65.4642)  Acc@5: 93.7500 (91.7994)  time: 0.3493  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [2050/4579]  eta: 0:14:46  Lr: 0.001875  Loss: -0.0117  Acc@1: 68.7500 (65.4559)  Acc@5: 93.7500 (91.7936)  time: 0.3483  data: 0.0009  max mem: 2500
Train: Epoch[4/5]  [2060/4579]  eta: 0:14:42  Lr: 0.001875  Loss: -0.5448  Acc@1: 68.7500 (65.4597)  Acc@5: 93.7500 (91.7940)  time: 0.3511  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [2070/4579]  eta: 0:14:39  Lr: 0.001875  Loss: -0.0091  Acc@1: 62.5000 (65.4575)  Acc@5: 93.7500 (91.8005)  time: 0.3533  data: 0.0012  max mem: 2500
Train: Epoch[4/5]  [2080/4579]  eta: 0:14:35  Lr: 0.001875  Loss: 0.1254  Acc@1: 68.7500 (65.4493)  Acc@5: 93.7500 (91.8098)  time: 0.3540  data: 0.0010  max mem: 2500
Train: Epoch[4/5]  [2090/4579]  eta: 0:14:32  Lr: 0.001875  Loss: -0.2743  Acc@1: 62.5000 (65.4143)  Acc@5: 93.7500 (91.8131)  time: 0.3531  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2100/4579]  eta: 0:14:28  Lr: 0.001875  Loss: 0.6886  Acc@1: 62.5000 (65.4034)  Acc@5: 93.7500 (91.8283)  time: 0.3525  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2110/4579]  eta: 0:14:25  Lr: 0.001875  Loss: -0.4322  Acc@1: 62.5000 (65.3807)  Acc@5: 93.7500 (91.8078)  time: 0.3508  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2120/4579]  eta: 0:14:21  Lr: 0.001875  Loss: -0.4775  Acc@1: 68.7500 (65.4231)  Acc@5: 93.7500 (91.8169)  time: 0.3485  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2130/4579]  eta: 0:14:18  Lr: 0.001875  Loss: -0.0478  Acc@1: 75.0000 (65.4358)  Acc@5: 93.7500 (91.8084)  time: 0.3503  data: 0.0012  max mem: 2500
Train: Epoch[4/5]  [2140/4579]  eta: 0:14:14  Lr: 0.001875  Loss: -0.7000  Acc@1: 68.7500 (65.4426)  Acc@5: 87.5000 (91.8146)  time: 0.3512  data: 0.0020  max mem: 2500
Train: Epoch[4/5]  [2150/4579]  eta: 0:14:11  Lr: 0.001875  Loss: -0.0919  Acc@1: 68.7500 (65.4492)  Acc@5: 87.5000 (91.7974)  time: 0.3502  data: 0.0012  max mem: 2500
Train: Epoch[4/5]  [2160/4579]  eta: 0:14:07  Lr: 0.001875  Loss: -0.0765  Acc@1: 68.7500 (65.4616)  Acc@5: 87.5000 (91.8093)  time: 0.3496  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2170/4579]  eta: 0:14:04  Lr: 0.001875  Loss: -0.0608  Acc@1: 62.5000 (65.4508)  Acc@5: 87.5000 (91.7981)  time: 0.3481  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [2180/4579]  eta: 0:14:00  Lr: 0.001875  Loss: 0.0757  Acc@1: 62.5000 (65.4459)  Acc@5: 87.5000 (91.7985)  time: 0.3471  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [2190/4579]  eta: 0:13:57  Lr: 0.001875  Loss: -0.0435  Acc@1: 62.5000 (65.4382)  Acc@5: 93.7500 (91.8074)  time: 0.3479  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [2200/4579]  eta: 0:13:53  Lr: 0.001875  Loss: -0.6773  Acc@1: 62.5000 (65.4447)  Acc@5: 93.7500 (91.7992)  time: 0.3481  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [2210/4579]  eta: 0:13:49  Lr: 0.001875  Loss: -0.1247  Acc@1: 68.7500 (65.4681)  Acc@5: 93.7500 (91.8024)  time: 0.3486  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2220/4579]  eta: 0:13:46  Lr: 0.001875  Loss: -0.6846  Acc@1: 68.7500 (65.4941)  Acc@5: 93.7500 (91.7999)  time: 0.3504  data: 0.0013  max mem: 2500
Train: Epoch[4/5]  [2230/4579]  eta: 0:13:42  Lr: 0.001875  Loss: -0.5253  Acc@1: 68.7500 (65.4975)  Acc@5: 93.7500 (91.8030)  time: 0.3512  data: 0.0013  max mem: 2500
Train: Epoch[4/5]  [2240/4579]  eta: 0:13:39  Lr: 0.001875  Loss: -0.4580  Acc@1: 68.7500 (65.4953)  Acc@5: 93.7500 (91.7894)  time: 0.3537  data: 0.0011  max mem: 2500
Train: Epoch[4/5]  [2250/4579]  eta: 0:13:36  Lr: 0.001875  Loss: -0.4992  Acc@1: 62.5000 (65.4681)  Acc@5: 93.7500 (91.7814)  time: 0.3560  data: 0.0012  max mem: 2500
Train: Epoch[4/5]  [2260/4579]  eta: 0:13:32  Lr: 0.001875  Loss: -0.0723  Acc@1: 62.5000 (65.4716)  Acc@5: 93.7500 (91.7846)  time: 0.3565  data: 0.0010  max mem: 2500
Train: Epoch[4/5]  [2270/4579]  eta: 0:13:29  Lr: 0.001875  Loss: -0.3581  Acc@1: 68.7500 (65.4695)  Acc@5: 93.7500 (91.7878)  time: 0.3547  data: 0.0009  max mem: 2500
Train: Epoch[4/5]  [2280/4579]  eta: 0:13:25  Lr: 0.001875  Loss: -0.1953  Acc@1: 68.7500 (65.4839)  Acc@5: 93.7500 (91.8046)  time: 0.3511  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [2290/4579]  eta: 0:13:22  Lr: 0.001875  Loss: -0.2986  Acc@1: 68.7500 (65.4927)  Acc@5: 93.7500 (91.8213)  time: 0.3524  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [2300/4579]  eta: 0:13:18  Lr: 0.001875  Loss: -0.2635  Acc@1: 68.7500 (65.4905)  Acc@5: 93.7500 (91.8296)  time: 0.3527  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [2310/4579]  eta: 0:13:15  Lr: 0.001875  Loss: -0.3695  Acc@1: 62.5000 (65.4803)  Acc@5: 93.7500 (91.8217)  time: 0.3495  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [2320/4579]  eta: 0:13:11  Lr: 0.001875  Loss: -0.5095  Acc@1: 68.7500 (65.5079)  Acc@5: 93.7500 (91.8273)  time: 0.3489  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2330/4579]  eta: 0:13:08  Lr: 0.001875  Loss: -0.7160  Acc@1: 68.7500 (65.4950)  Acc@5: 93.7500 (91.8195)  time: 0.3488  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2340/4579]  eta: 0:13:04  Lr: 0.001875  Loss: -0.5775  Acc@1: 62.5000 (65.5009)  Acc@5: 93.7500 (91.8197)  time: 0.3490  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2350/4579]  eta: 0:13:01  Lr: 0.001875  Loss: 0.2791  Acc@1: 68.7500 (65.5094)  Acc@5: 93.7500 (91.8279)  time: 0.3484  data: 0.0009  max mem: 2500
Train: Epoch[4/5]  [2360/4579]  eta: 0:12:57  Lr: 0.001875  Loss: 0.2765  Acc@1: 68.7500 (65.5098)  Acc@5: 93.7500 (91.8361)  time: 0.3468  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [2370/4579]  eta: 0:12:54  Lr: 0.001875  Loss: -0.4883  Acc@1: 62.5000 (65.4998)  Acc@5: 93.7500 (91.8283)  time: 0.3470  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [2380/4579]  eta: 0:12:50  Lr: 0.001875  Loss: -0.4973  Acc@1: 62.5000 (65.5187)  Acc@5: 93.7500 (91.8259)  time: 0.3472  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [2390/4579]  eta: 0:12:46  Lr: 0.001875  Loss: -0.1165  Acc@1: 62.5000 (65.5348)  Acc@5: 93.7500 (91.8340)  time: 0.3474  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [2400/4579]  eta: 0:12:43  Lr: 0.001875  Loss: -0.5075  Acc@1: 75.0000 (65.5560)  Acc@5: 93.7500 (91.8367)  time: 0.3496  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2410/4579]  eta: 0:12:40  Lr: 0.001875  Loss: 0.3749  Acc@1: 68.7500 (65.5563)  Acc@5: 87.5000 (91.8187)  time: 0.3549  data: 0.0015  max mem: 2500
Train: Epoch[4/5]  [2420/4579]  eta: 0:12:36  Lr: 0.001875  Loss: -0.2556  Acc@1: 68.7500 (65.5901)  Acc@5: 87.5000 (91.8216)  time: 0.3570  data: 0.0018  max mem: 2500
Train: Epoch[4/5]  [2430/4579]  eta: 0:12:33  Lr: 0.001875  Loss: -0.5988  Acc@1: 75.0000 (65.6006)  Acc@5: 93.7500 (91.8166)  time: 0.3533  data: 0.0009  max mem: 2500
Train: Epoch[4/5]  [2440/4579]  eta: 0:12:29  Lr: 0.001875  Loss: -0.1427  Acc@1: 62.5000 (65.5648)  Acc@5: 87.5000 (91.8143)  time: 0.3524  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [2450/4579]  eta: 0:12:26  Lr: 0.001875  Loss: -0.3831  Acc@1: 62.5000 (65.5753)  Acc@5: 93.7500 (91.8222)  time: 0.3529  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [2460/4579]  eta: 0:12:22  Lr: 0.001875  Loss: -0.1767  Acc@1: 68.7500 (65.5806)  Acc@5: 93.7500 (91.8224)  time: 0.3525  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [2470/4579]  eta: 0:12:19  Lr: 0.001875  Loss: -0.7737  Acc@1: 68.7500 (65.5782)  Acc@5: 93.7500 (91.8277)  time: 0.3522  data: 0.0015  max mem: 2500
Train: Epoch[4/5]  [2480/4579]  eta: 0:12:15  Lr: 0.001875  Loss: -0.8212  Acc@1: 62.5000 (65.5734)  Acc@5: 93.7500 (91.8354)  time: 0.3515  data: 0.0017  max mem: 2500
Train: Epoch[4/5]  [2490/4579]  eta: 0:12:12  Lr: 0.001875  Loss: -0.5886  Acc@1: 68.7500 (65.6137)  Acc@5: 93.7500 (91.8406)  time: 0.3511  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [2500/4579]  eta: 0:12:08  Lr: 0.001875  Loss: -0.3788  Acc@1: 68.7500 (65.6113)  Acc@5: 93.7500 (91.8408)  time: 0.3498  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2510/4579]  eta: 0:12:05  Lr: 0.001875  Loss: -0.2826  Acc@1: 62.5000 (65.6063)  Acc@5: 93.7500 (91.8285)  time: 0.3490  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2520/4579]  eta: 0:12:01  Lr: 0.001875  Loss: 0.0315  Acc@1: 62.5000 (65.6014)  Acc@5: 87.5000 (91.8162)  time: 0.3484  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2530/4579]  eta: 0:11:58  Lr: 0.001875  Loss: 0.3386  Acc@1: 62.5000 (65.5917)  Acc@5: 93.7500 (91.8189)  time: 0.3479  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2540/4579]  eta: 0:11:54  Lr: 0.001875  Loss: -0.0713  Acc@1: 62.5000 (65.5918)  Acc@5: 93.7500 (91.8241)  time: 0.3476  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2550/4579]  eta: 0:11:50  Lr: 0.001875  Loss: -0.2678  Acc@1: 62.5000 (65.6042)  Acc@5: 93.7500 (91.8341)  time: 0.3460  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [2560/4579]  eta: 0:11:47  Lr: 0.001875  Loss: -0.5857  Acc@1: 68.7500 (65.5921)  Acc@5: 93.7500 (91.8416)  time: 0.3460  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [2570/4579]  eta: 0:11:43  Lr: 0.001875  Loss: -0.2380  Acc@1: 68.7500 (65.5970)  Acc@5: 93.7500 (91.8490)  time: 0.3466  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [2580/4579]  eta: 0:11:40  Lr: 0.001875  Loss: -0.6935  Acc@1: 68.7500 (65.6020)  Acc@5: 93.7500 (91.8442)  time: 0.3460  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [2590/4579]  eta: 0:11:36  Lr: 0.001875  Loss: -0.1560  Acc@1: 68.7500 (65.6093)  Acc@5: 93.7500 (91.8468)  time: 0.3481  data: 0.0009  max mem: 2500
Train: Epoch[4/5]  [2600/4579]  eta: 0:11:33  Lr: 0.001875  Loss: -0.2950  Acc@1: 62.5000 (65.5950)  Acc@5: 93.7500 (91.8445)  time: 0.3493  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2610/4579]  eta: 0:11:29  Lr: 0.001875  Loss: -0.4470  Acc@1: 62.5000 (65.5759)  Acc@5: 93.7500 (91.8446)  time: 0.3485  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2620/4579]  eta: 0:11:26  Lr: 0.001875  Loss: 0.5065  Acc@1: 68.7500 (65.5570)  Acc@5: 93.7500 (91.8399)  time: 0.3494  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2630/4579]  eta: 0:11:22  Lr: 0.001875  Loss: 0.0375  Acc@1: 62.5000 (65.5644)  Acc@5: 93.7500 (91.8425)  time: 0.3488  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2640/4579]  eta: 0:11:19  Lr: 0.001875  Loss: -0.5651  Acc@1: 62.5000 (65.5599)  Acc@5: 93.7500 (91.8473)  time: 0.3494  data: 0.0011  max mem: 2500
Train: Epoch[4/5]  [2650/4579]  eta: 0:11:15  Lr: 0.001875  Loss: -0.4284  Acc@1: 68.7500 (65.5955)  Acc@5: 93.7500 (91.8474)  time: 0.3489  data: 0.0012  max mem: 2500
Train: Epoch[4/5]  [2660/4579]  eta: 0:11:12  Lr: 0.001875  Loss: -0.4909  Acc@1: 68.7500 (65.6074)  Acc@5: 93.7500 (91.8452)  time: 0.3479  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [2670/4579]  eta: 0:11:08  Lr: 0.001875  Loss: 0.1336  Acc@1: 68.7500 (65.6004)  Acc@5: 93.7500 (91.8593)  time: 0.3497  data: 0.0015  max mem: 2500
Train: Epoch[4/5]  [2680/4579]  eta: 0:11:05  Lr: 0.001875  Loss: -0.6060  Acc@1: 62.5000 (65.5912)  Acc@5: 93.7500 (91.8640)  time: 0.3493  data: 0.0020  max mem: 2500
Train: Epoch[4/5]  [2690/4579]  eta: 0:11:01  Lr: 0.001875  Loss: -0.4754  Acc@1: 62.5000 (65.5867)  Acc@5: 93.7500 (91.8664)  time: 0.3470  data: 0.0010  max mem: 2500
Train: Epoch[4/5]  [2700/4579]  eta: 0:10:58  Lr: 0.001875  Loss: -0.4794  Acc@1: 62.5000 (65.5845)  Acc@5: 93.7500 (91.8688)  time: 0.3498  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2710/4579]  eta: 0:10:54  Lr: 0.001875  Loss: -0.1443  Acc@1: 62.5000 (65.5823)  Acc@5: 93.7500 (91.8596)  time: 0.3505  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [2720/4579]  eta: 0:10:51  Lr: 0.001875  Loss: 0.0913  Acc@1: 62.5000 (65.5687)  Acc@5: 93.7500 (91.8481)  time: 0.3471  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [2730/4579]  eta: 0:10:47  Lr: 0.001875  Loss: -0.5230  Acc@1: 56.2500 (65.5415)  Acc@5: 87.5000 (91.8436)  time: 0.3472  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2740/4579]  eta: 0:10:44  Lr: 0.001875  Loss: -0.1749  Acc@1: 68.7500 (65.5555)  Acc@5: 87.5000 (91.8392)  time: 0.3487  data: 0.0010  max mem: 2500
Train: Epoch[4/5]  [2750/4579]  eta: 0:10:40  Lr: 0.001875  Loss: -0.1344  Acc@1: 68.7500 (65.5534)  Acc@5: 93.7500 (91.8371)  time: 0.3483  data: 0.0010  max mem: 2500
Train: Epoch[4/5]  [2760/4579]  eta: 0:10:37  Lr: 0.001875  Loss: -0.0433  Acc@1: 68.7500 (65.5582)  Acc@5: 93.7500 (91.8463)  time: 0.3471  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2770/4579]  eta: 0:10:33  Lr: 0.001875  Loss: -0.4818  Acc@1: 68.7500 (65.5697)  Acc@5: 93.7500 (91.8509)  time: 0.3475  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [2780/4579]  eta: 0:10:30  Lr: 0.001875  Loss: -0.4961  Acc@1: 68.7500 (65.5902)  Acc@5: 93.7500 (91.8599)  time: 0.3498  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2790/4579]  eta: 0:10:26  Lr: 0.001875  Loss: -0.5701  Acc@1: 68.7500 (65.5881)  Acc@5: 93.7500 (91.8555)  time: 0.3496  data: 0.0010  max mem: 2500
Train: Epoch[4/5]  [2800/4579]  eta: 0:10:23  Lr: 0.001875  Loss: -0.3140  Acc@1: 68.7500 (65.5949)  Acc@5: 93.7500 (91.8511)  time: 0.3467  data: 0.0009  max mem: 2500
Train: Epoch[4/5]  [2810/4579]  eta: 0:10:19  Lr: 0.001875  Loss: -0.1988  Acc@1: 68.7500 (65.5950)  Acc@5: 93.7500 (91.8557)  time: 0.3458  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [2820/4579]  eta: 0:10:16  Lr: 0.001875  Loss: -0.1056  Acc@1: 68.7500 (65.6084)  Acc@5: 93.7500 (91.8757)  time: 0.3495  data: 0.0013  max mem: 2500
Train: Epoch[4/5]  [2830/4579]  eta: 0:10:12  Lr: 0.001875  Loss: -0.3520  Acc@1: 68.7500 (65.6084)  Acc@5: 93.7500 (91.8580)  time: 0.3506  data: 0.0013  max mem: 2500
Train: Epoch[4/5]  [2840/4579]  eta: 0:10:08  Lr: 0.001875  Loss: -0.6614  Acc@1: 68.7500 (65.6239)  Acc@5: 87.5000 (91.8581)  time: 0.3478  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2850/4579]  eta: 0:10:05  Lr: 0.001875  Loss: -0.5832  Acc@1: 68.7500 (65.6371)  Acc@5: 93.7500 (91.8691)  time: 0.3496  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2860/4579]  eta: 0:10:02  Lr: 0.001875  Loss: 0.0869  Acc@1: 62.5000 (65.6174)  Acc@5: 93.7500 (91.8713)  time: 0.3522  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2870/4579]  eta: 0:09:58  Lr: 0.001875  Loss: 0.2847  Acc@1: 62.5000 (65.6043)  Acc@5: 93.7500 (91.8669)  time: 0.3536  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2880/4579]  eta: 0:09:55  Lr: 0.001875  Loss: -0.3536  Acc@1: 62.5000 (65.6131)  Acc@5: 93.7500 (91.8735)  time: 0.3548  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [2890/4579]  eta: 0:09:51  Lr: 0.001875  Loss: -0.9745  Acc@1: 75.0000 (65.6391)  Acc@5: 93.7500 (91.8843)  time: 0.3536  data: 0.0013  max mem: 2500
Train: Epoch[4/5]  [2900/4579]  eta: 0:09:48  Lr: 0.001875  Loss: 0.0243  Acc@1: 75.0000 (65.6541)  Acc@5: 93.7500 (91.8886)  time: 0.3512  data: 0.0011  max mem: 2500
Train: Epoch[4/5]  [2910/4579]  eta: 0:09:44  Lr: 0.001875  Loss: 0.4322  Acc@1: 68.7500 (65.6690)  Acc@5: 93.7500 (91.8950)  time: 0.3520  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [2920/4579]  eta: 0:09:41  Lr: 0.001875  Loss: -0.6288  Acc@1: 68.7500 (65.6838)  Acc@5: 93.7500 (91.8906)  time: 0.3517  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [2930/4579]  eta: 0:09:37  Lr: 0.001875  Loss: 0.0577  Acc@1: 62.5000 (65.6666)  Acc@5: 87.5000 (91.8906)  time: 0.3487  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2940/4579]  eta: 0:09:34  Lr: 0.001875  Loss: -0.1231  Acc@1: 62.5000 (65.6707)  Acc@5: 87.5000 (91.8863)  time: 0.3490  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2950/4579]  eta: 0:09:30  Lr: 0.001875  Loss: -0.5296  Acc@1: 68.7500 (65.6769)  Acc@5: 93.7500 (91.8968)  time: 0.3507  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [2960/4579]  eta: 0:09:27  Lr: 0.001875  Loss: -0.8626  Acc@1: 68.7500 (65.6852)  Acc@5: 93.7500 (91.8946)  time: 0.3515  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [2970/4579]  eta: 0:09:23  Lr: 0.001875  Loss: -0.3949  Acc@1: 62.5000 (65.6807)  Acc@5: 93.7500 (91.8925)  time: 0.3498  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2980/4579]  eta: 0:09:20  Lr: 0.001875  Loss: -0.5383  Acc@1: 62.5000 (65.6785)  Acc@5: 93.7500 (91.8882)  time: 0.3469  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2990/4579]  eta: 0:09:16  Lr: 0.001875  Loss: -0.7408  Acc@1: 62.5000 (65.6699)  Acc@5: 87.5000 (91.8882)  time: 0.3465  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3000/4579]  eta: 0:09:12  Lr: 0.001875  Loss: -0.3243  Acc@1: 68.7500 (65.6739)  Acc@5: 93.7500 (91.8902)  time: 0.3473  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [3010/4579]  eta: 0:09:09  Lr: 0.001875  Loss: 0.2905  Acc@1: 68.7500 (65.6821)  Acc@5: 93.7500 (91.8922)  time: 0.3467  data: 0.0009  max mem: 2500
Train: Epoch[4/5]  [3020/4579]  eta: 0:09:05  Lr: 0.001875  Loss: -0.4509  Acc@1: 68.7500 (65.6964)  Acc@5: 93.7500 (91.9025)  time: 0.3480  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [3030/4579]  eta: 0:09:02  Lr: 0.001875  Loss: -0.0456  Acc@1: 62.5000 (65.6961)  Acc@5: 93.7500 (91.8983)  time: 0.3512  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [3040/4579]  eta: 0:08:58  Lr: 0.001875  Loss: 0.2376  Acc@1: 62.5000 (65.6980)  Acc@5: 87.5000 (91.8941)  time: 0.3514  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [3050/4579]  eta: 0:08:55  Lr: 0.001875  Loss: -0.8900  Acc@1: 62.5000 (65.6957)  Acc@5: 93.7500 (91.8920)  time: 0.3512  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [3060/4579]  eta: 0:08:51  Lr: 0.001875  Loss: -0.7669  Acc@1: 68.7500 (65.7057)  Acc@5: 93.7500 (91.8940)  time: 0.3532  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [3070/4579]  eta: 0:08:48  Lr: 0.001875  Loss: -0.1305  Acc@1: 68.7500 (65.6993)  Acc@5: 93.7500 (91.8960)  time: 0.3530  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [3080/4579]  eta: 0:08:44  Lr: 0.001875  Loss: -0.1780  Acc@1: 62.5000 (65.6909)  Acc@5: 93.7500 (91.9040)  time: 0.3506  data: 0.0012  max mem: 2500
Train: Epoch[4/5]  [3090/4579]  eta: 0:08:41  Lr: 0.001875  Loss: 0.2446  Acc@1: 62.5000 (65.7089)  Acc@5: 93.7500 (91.8999)  time: 0.3510  data: 0.0013  max mem: 2500
Train: Epoch[4/5]  [3100/4579]  eta: 0:08:38  Lr: 0.001875  Loss: -0.3139  Acc@1: 68.7500 (65.7046)  Acc@5: 93.7500 (91.9099)  time: 0.3525  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [3110/4579]  eta: 0:08:34  Lr: 0.001875  Loss: -0.8829  Acc@1: 68.7500 (65.7084)  Acc@5: 93.7500 (91.9077)  time: 0.3511  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [3120/4579]  eta: 0:08:31  Lr: 0.001875  Loss: -0.4697  Acc@1: 68.7500 (65.7101)  Acc@5: 93.7500 (91.9076)  time: 0.3498  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [3130/4579]  eta: 0:08:27  Lr: 0.001875  Loss: -0.6941  Acc@1: 68.7500 (65.7338)  Acc@5: 93.7500 (91.9175)  time: 0.3500  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3140/4579]  eta: 0:08:23  Lr: 0.001875  Loss: -0.5438  Acc@1: 68.7500 (65.7334)  Acc@5: 93.7500 (91.9094)  time: 0.3490  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3150/4579]  eta: 0:08:20  Lr: 0.001875  Loss: -0.3616  Acc@1: 68.7500 (65.7272)  Acc@5: 93.7500 (91.9093)  time: 0.3499  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3160/4579]  eta: 0:08:16  Lr: 0.001875  Loss: 0.0548  Acc@1: 62.5000 (65.7150)  Acc@5: 93.7500 (91.9092)  time: 0.3487  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3170/4579]  eta: 0:08:13  Lr: 0.001875  Loss: -0.0935  Acc@1: 56.2500 (65.7029)  Acc@5: 93.7500 (91.9032)  time: 0.3457  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [3180/4579]  eta: 0:08:09  Lr: 0.001875  Loss: -0.7012  Acc@1: 62.5000 (65.6928)  Acc@5: 87.5000 (91.8933)  time: 0.3467  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [3190/4579]  eta: 0:08:06  Lr: 0.001875  Loss: -0.6976  Acc@1: 68.7500 (65.7180)  Acc@5: 93.7500 (91.9030)  time: 0.3474  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [3200/4579]  eta: 0:08:02  Lr: 0.001875  Loss: -0.7552  Acc@1: 68.7500 (65.7138)  Acc@5: 93.7500 (91.9088)  time: 0.3465  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [3210/4579]  eta: 0:07:59  Lr: 0.001875  Loss: -0.4880  Acc@1: 56.2500 (65.7077)  Acc@5: 93.7500 (91.9028)  time: 0.3573  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [3220/4579]  eta: 0:07:55  Lr: 0.001875  Loss: 0.0231  Acc@1: 62.5000 (65.7152)  Acc@5: 93.7500 (91.8969)  time: 0.3619  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [3230/4579]  eta: 0:07:52  Lr: 0.001875  Loss: -0.4526  Acc@1: 62.5000 (65.7053)  Acc@5: 93.7500 (91.8911)  time: 0.3537  data: 0.0013  max mem: 2500
Train: Epoch[4/5]  [3240/4579]  eta: 0:07:49  Lr: 0.001875  Loss: 0.4864  Acc@1: 62.5000 (65.6780)  Acc@5: 87.5000 (91.8582)  time: 0.3532  data: 0.0013  max mem: 2500
Train: Epoch[4/5]  [3250/4579]  eta: 0:07:45  Lr: 0.001875  Loss: -0.0137  Acc@1: 68.7500 (65.6817)  Acc@5: 87.5000 (91.8679)  time: 0.3556  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [3260/4579]  eta: 0:07:42  Lr: 0.001875  Loss: -0.0155  Acc@1: 68.7500 (65.6624)  Acc@5: 87.5000 (91.8602)  time: 0.3540  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [3270/4579]  eta: 0:07:38  Lr: 0.001875  Loss: -0.0358  Acc@1: 56.2500 (65.6470)  Acc@5: 87.5000 (91.8584)  time: 0.3570  data: 0.0010  max mem: 2500
Train: Epoch[4/5]  [3280/4579]  eta: 0:07:35  Lr: 0.001875  Loss: -0.2813  Acc@1: 62.5000 (65.6488)  Acc@5: 93.7500 (91.8641)  time: 0.3564  data: 0.0010  max mem: 2500
Train: Epoch[4/5]  [3290/4579]  eta: 0:07:31  Lr: 0.001875  Loss: 0.0451  Acc@1: 62.5000 (65.6430)  Acc@5: 93.7500 (91.8585)  time: 0.3500  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3300/4579]  eta: 0:07:28  Lr: 0.001875  Loss: -0.3227  Acc@1: 68.7500 (65.6468)  Acc@5: 93.7500 (91.8623)  time: 0.3486  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3310/4579]  eta: 0:07:24  Lr: 0.001875  Loss: -0.1329  Acc@1: 68.7500 (65.6524)  Acc@5: 93.7500 (91.8605)  time: 0.3485  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3320/4579]  eta: 0:07:21  Lr: 0.001875  Loss: -0.4851  Acc@1: 68.7500 (65.6561)  Acc@5: 93.7500 (91.8605)  time: 0.3500  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [3330/4579]  eta: 0:07:17  Lr: 0.001875  Loss: 0.0111  Acc@1: 62.5000 (65.6560)  Acc@5: 87.5000 (91.8512)  time: 0.3494  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [3340/4579]  eta: 0:07:14  Lr: 0.001875  Loss: -0.2237  Acc@1: 62.5000 (65.6671)  Acc@5: 93.7500 (91.8625)  time: 0.3485  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3350/4579]  eta: 0:07:10  Lr: 0.001875  Loss: -0.3522  Acc@1: 62.5000 (65.6632)  Acc@5: 93.7500 (91.8681)  time: 0.3472  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3360/4579]  eta: 0:07:07  Lr: 0.001875  Loss: 0.0271  Acc@1: 62.5000 (65.6743)  Acc@5: 93.7500 (91.8663)  time: 0.3479  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [3370/4579]  eta: 0:07:03  Lr: 0.001875  Loss: 0.3973  Acc@1: 62.5000 (65.6723)  Acc@5: 93.7500 (91.8700)  time: 0.3535  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [3380/4579]  eta: 0:07:00  Lr: 0.001875  Loss: -0.6105  Acc@1: 68.7500 (65.6703)  Acc@5: 93.7500 (91.8774)  time: 0.3558  data: 0.0011  max mem: 2500
Train: Epoch[4/5]  [3390/4579]  eta: 0:06:56  Lr: 0.001875  Loss: 0.2710  Acc@1: 68.7500 (65.6923)  Acc@5: 93.7500 (91.8848)  time: 0.3521  data: 0.0012  max mem: 2500
Train: Epoch[4/5]  [3400/4579]  eta: 0:06:53  Lr: 0.001875  Loss: -0.0013  Acc@1: 68.7500 (65.6829)  Acc@5: 93.7500 (91.8829)  time: 0.3532  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [3410/4579]  eta: 0:06:49  Lr: 0.001875  Loss: -0.4110  Acc@1: 62.5000 (65.6772)  Acc@5: 93.7500 (91.8920)  time: 0.3700  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [3420/4579]  eta: 0:06:47  Lr: 0.001875  Loss: -0.3504  Acc@1: 68.7500 (65.6880)  Acc@5: 93.7500 (91.8975)  time: 0.5727  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [3430/4579]  eta: 0:06:44  Lr: 0.001875  Loss: -0.1864  Acc@1: 68.7500 (65.6824)  Acc@5: 93.7500 (91.8938)  time: 0.6725  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [3440/4579]  eta: 0:06:41  Lr: 0.001875  Loss: -0.3118  Acc@1: 62.5000 (65.6840)  Acc@5: 93.7500 (91.8973)  time: 0.4659  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [3450/4579]  eta: 0:06:37  Lr: 0.001875  Loss: 0.2123  Acc@1: 62.5000 (65.6748)  Acc@5: 93.7500 (91.8991)  time: 0.3516  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [3460/4579]  eta: 0:06:34  Lr: 0.001875  Loss: -0.4976  Acc@1: 62.5000 (65.6747)  Acc@5: 93.7500 (91.8990)  time: 0.3576  data: 0.0012  max mem: 2500
Train: Epoch[4/5]  [3470/4579]  eta: 0:06:30  Lr: 0.001875  Loss: 0.2880  Acc@1: 56.2500 (65.6619)  Acc@5: 93.7500 (91.9007)  time: 0.3540  data: 0.0010  max mem: 2500
Train: Epoch[4/5]  [3480/4579]  eta: 0:06:27  Lr: 0.001875  Loss: -0.5499  Acc@1: 62.5000 (65.6762)  Acc@5: 93.7500 (91.9007)  time: 0.3478  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3490/4579]  eta: 0:06:23  Lr: 0.001875  Loss: 0.2980  Acc@1: 68.7500 (65.6868)  Acc@5: 93.7500 (91.8988)  time: 0.3482  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3500/4579]  eta: 0:06:20  Lr: 0.001875  Loss: -0.2524  Acc@1: 68.7500 (65.7098)  Acc@5: 93.7500 (91.9005)  time: 0.3476  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [3510/4579]  eta: 0:06:16  Lr: 0.001875  Loss: -0.1138  Acc@1: 68.7500 (65.7202)  Acc@5: 93.7500 (91.9076)  time: 0.3477  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [3520/4579]  eta: 0:06:13  Lr: 0.001875  Loss: -0.5801  Acc@1: 68.7500 (65.7271)  Acc@5: 93.7500 (91.9146)  time: 0.3579  data: 0.0013  max mem: 2500
Train: Epoch[4/5]  [3530/4579]  eta: 0:06:09  Lr: 0.001875  Loss: -0.6571  Acc@1: 68.7500 (65.7321)  Acc@5: 93.7500 (91.9233)  time: 0.3582  data: 0.0011  max mem: 2500
Train: Epoch[4/5]  [3540/4579]  eta: 0:06:06  Lr: 0.001875  Loss: 0.0472  Acc@1: 68.7500 (65.7212)  Acc@5: 93.7500 (91.9161)  time: 0.3472  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [3550/4579]  eta: 0:06:02  Lr: 0.001875  Loss: -0.5254  Acc@1: 68.7500 (65.7368)  Acc@5: 93.7500 (91.9336)  time: 0.3884  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [3560/4579]  eta: 0:06:00  Lr: 0.001875  Loss: -0.3867  Acc@1: 68.7500 (65.7329)  Acc@5: 93.7500 (91.9229)  time: 0.5911  data: 0.0012  max mem: 2500
Train: Epoch[4/5]  [3570/4579]  eta: 0:05:57  Lr: 0.001875  Loss: -0.4065  Acc@1: 62.5000 (65.7256)  Acc@5: 93.7500 (91.9210)  time: 0.7260  data: 0.0014  max mem: 2500
Train: Epoch[4/5]  [3580/4579]  eta: 0:05:55  Lr: 0.001875  Loss: -0.6801  Acc@1: 68.7500 (65.7341)  Acc@5: 93.7500 (91.9314)  time: 0.7287  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [3590/4579]  eta: 0:05:52  Lr: 0.001875  Loss: -0.4875  Acc@1: 68.7500 (65.7442)  Acc@5: 93.7500 (91.9399)  time: 0.7507  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [3600/4579]  eta: 0:05:50  Lr: 0.001875  Loss: -0.1504  Acc@1: 62.5000 (65.7300)  Acc@5: 93.7500 (91.9380)  time: 0.7445  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [3610/4579]  eta: 0:05:47  Lr: 0.001875  Loss: -0.3675  Acc@1: 62.5000 (65.7263)  Acc@5: 93.7500 (91.9396)  time: 0.6336  data: 0.0010  max mem: 2500
Train: Epoch[4/5]  [3620/4579]  eta: 0:05:43  Lr: 0.001875  Loss: -0.8583  Acc@1: 62.5000 (65.7277)  Acc@5: 93.7500 (91.9428)  time: 0.4353  data: 0.0009  max mem: 2500
Train: Epoch[4/5]  [3630/4579]  eta: 0:05:40  Lr: 0.001875  Loss: -0.7290  Acc@1: 68.7500 (65.7360)  Acc@5: 93.7500 (91.9495)  time: 0.3476  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3640/4579]  eta: 0:05:36  Lr: 0.001875  Loss: -0.0212  Acc@1: 68.7500 (65.7512)  Acc@5: 93.7500 (91.9579)  time: 0.3484  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3650/4579]  eta: 0:05:32  Lr: 0.001875  Loss: 0.0125  Acc@1: 68.7500 (65.7491)  Acc@5: 93.7500 (91.9577)  time: 0.3488  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [3660/4579]  eta: 0:05:29  Lr: 0.001875  Loss: -0.2338  Acc@1: 62.5000 (65.7539)  Acc@5: 93.7500 (91.9643)  time: 0.3476  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [3670/4579]  eta: 0:05:25  Lr: 0.001875  Loss: -0.0967  Acc@1: 68.7500 (65.7586)  Acc@5: 93.7500 (91.9657)  time: 0.3459  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [3680/4579]  eta: 0:05:21  Lr: 0.001875  Loss: -0.6779  Acc@1: 68.7500 (65.7753)  Acc@5: 93.7500 (91.9655)  time: 0.3463  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [3690/4579]  eta: 0:05:18  Lr: 0.001875  Loss: -0.1649  Acc@1: 68.7500 (65.7816)  Acc@5: 93.7500 (91.9720)  time: 0.3476  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3700/4579]  eta: 0:05:14  Lr: 0.001875  Loss: -0.3468  Acc@1: 68.7500 (65.7812)  Acc@5: 93.7500 (91.9701)  time: 0.3580  data: 0.0009  max mem: 2500
Train: Epoch[4/5]  [3710/4579]  eta: 0:05:11  Lr: 0.001875  Loss: 0.4255  Acc@1: 62.5000 (65.7724)  Acc@5: 93.7500 (91.9715)  time: 0.3572  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [3720/4579]  eta: 0:05:07  Lr: 0.001875  Loss: -0.0863  Acc@1: 68.7500 (65.7804)  Acc@5: 93.7500 (91.9662)  time: 0.3483  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [3730/4579]  eta: 0:05:04  Lr: 0.001875  Loss: -0.0562  Acc@1: 62.5000 (65.7548)  Acc@5: 87.5000 (91.9593)  time: 0.3600  data: 0.0014  max mem: 2500
Train: Epoch[4/5]  [3740/4579]  eta: 0:05:01  Lr: 0.001875  Loss: -0.8386  Acc@1: 62.5000 (65.7561)  Acc@5: 87.5000 (91.9540)  time: 0.5075  data: 0.0012  max mem: 2500
Train: Epoch[4/5]  [3750/4579]  eta: 0:04:58  Lr: 0.001875  Loss: -0.1818  Acc@1: 62.5000 (65.7391)  Acc@5: 93.7500 (91.9605)  time: 0.7007  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [3760/4579]  eta: 0:04:55  Lr: 0.001875  Loss: -0.0574  Acc@1: 62.5000 (65.7289)  Acc@5: 93.7500 (91.9470)  time: 0.7554  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [3770/4579]  eta: 0:04:52  Lr: 0.001875  Loss: -0.3015  Acc@1: 68.7500 (65.7369)  Acc@5: 87.5000 (91.9501)  time: 0.7538  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [3780/4579]  eta: 0:04:50  Lr: 0.001875  Loss: -0.4058  Acc@1: 68.7500 (65.7399)  Acc@5: 93.7500 (91.9532)  time: 0.7568  data: 0.0012  max mem: 2500
Train: Epoch[4/5]  [3790/4579]  eta: 0:04:47  Lr: 0.001875  Loss: -0.2943  Acc@1: 68.7500 (65.7445)  Acc@5: 93.7500 (91.9579)  time: 0.7571  data: 0.0012  max mem: 2500
Train: Epoch[4/5]  [3800/4579]  eta: 0:04:44  Lr: 0.001875  Loss: 0.4637  Acc@1: 68.7500 (65.7623)  Acc@5: 93.7500 (91.9561)  time: 0.7509  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3810/4579]  eta: 0:04:41  Lr: 0.001875  Loss: -0.6240  Acc@1: 68.7500 (65.7783)  Acc@5: 93.7500 (91.9641)  time: 0.7507  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3820/4579]  eta: 0:04:38  Lr: 0.001875  Loss: -0.3822  Acc@1: 68.7500 (65.7861)  Acc@5: 93.7500 (91.9605)  time: 0.7500  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [3830/4579]  eta: 0:04:35  Lr: 0.001875  Loss: -0.3810  Acc@1: 62.5000 (65.7808)  Acc@5: 93.7500 (91.9603)  time: 0.7511  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [3840/4579]  eta: 0:04:32  Lr: 0.001875  Loss: -0.3749  Acc@1: 62.5000 (65.7771)  Acc@5: 93.7500 (91.9536)  time: 0.7538  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [3850/4579]  eta: 0:04:29  Lr: 0.001875  Loss: -0.6482  Acc@1: 68.7500 (65.7914)  Acc@5: 93.7500 (91.9615)  time: 0.7500  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [3860/4579]  eta: 0:04:26  Lr: 0.001875  Loss: -0.2541  Acc@1: 68.7500 (65.7893)  Acc@5: 93.7500 (91.9564)  time: 0.7450  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [3870/4579]  eta: 0:04:23  Lr: 0.001875  Loss: -0.0094  Acc@1: 68.7500 (65.8002)  Acc@5: 87.5000 (91.9465)  time: 0.7448  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3880/4579]  eta: 0:04:20  Lr: 0.001875  Loss: 0.5337  Acc@1: 68.7500 (65.7997)  Acc@5: 93.7500 (91.9447)  time: 0.7468  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3890/4579]  eta: 0:04:17  Lr: 0.001875  Loss: -0.2212  Acc@1: 68.7500 (65.8153)  Acc@5: 93.7500 (91.9462)  time: 0.7436  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3900/4579]  eta: 0:04:14  Lr: 0.001875  Loss: -0.0252  Acc@1: 68.7500 (65.8165)  Acc@5: 93.7500 (91.9524)  time: 0.7418  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [3910/4579]  eta: 0:04:11  Lr: 0.001875  Loss: -0.1788  Acc@1: 68.7500 (65.8288)  Acc@5: 93.7500 (91.9554)  time: 0.7424  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3920/4579]  eta: 0:04:08  Lr: 0.001875  Loss: -0.6103  Acc@1: 68.7500 (65.8346)  Acc@5: 93.7500 (91.9584)  time: 0.7437  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [3930/4579]  eta: 0:04:05  Lr: 0.001875  Loss: -0.4973  Acc@1: 62.5000 (65.8277)  Acc@5: 93.7500 (91.9597)  time: 0.7470  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [3940/4579]  eta: 0:04:01  Lr: 0.001875  Loss: -0.6623  Acc@1: 62.5000 (65.8335)  Acc@5: 93.7500 (91.9611)  time: 0.7461  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [3950/4579]  eta: 0:03:58  Lr: 0.001875  Loss: 0.2582  Acc@1: 62.5000 (65.8314)  Acc@5: 93.7500 (91.9530)  time: 0.7425  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [3960/4579]  eta: 0:03:55  Lr: 0.001875  Loss: -0.5319  Acc@1: 62.5000 (65.8325)  Acc@5: 93.7500 (91.9670)  time: 0.7422  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [3970/4579]  eta: 0:03:52  Lr: 0.001875  Loss: -0.0917  Acc@1: 62.5000 (65.8351)  Acc@5: 93.7500 (91.9715)  time: 0.7473  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [3980/4579]  eta: 0:03:49  Lr: 0.001875  Loss: 0.0771  Acc@1: 62.5000 (65.8346)  Acc@5: 93.7500 (91.9681)  time: 0.7535  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [3990/4579]  eta: 0:03:45  Lr: 0.001875  Loss: -0.5717  Acc@1: 62.5000 (65.8294)  Acc@5: 93.7500 (91.9616)  time: 0.7560  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [4000/4579]  eta: 0:03:42  Lr: 0.001875  Loss: -0.1463  Acc@1: 62.5000 (65.8179)  Acc@5: 93.7500 (91.9645)  time: 0.7523  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [4010/4579]  eta: 0:03:39  Lr: 0.001875  Loss: -0.3310  Acc@1: 62.5000 (65.8096)  Acc@5: 93.7500 (91.9627)  time: 0.7444  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [4020/4579]  eta: 0:03:35  Lr: 0.001875  Loss: -0.3890  Acc@1: 62.5000 (65.8045)  Acc@5: 93.7500 (91.9765)  time: 0.7434  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [4030/4579]  eta: 0:03:32  Lr: 0.001875  Loss: -0.4895  Acc@1: 68.7500 (65.8196)  Acc@5: 93.7500 (91.9824)  time: 0.7408  data: 0.0021  max mem: 2500
Train: Epoch[4/5]  [4040/4579]  eta: 0:03:28  Lr: 0.001875  Loss: 0.0397  Acc@1: 62.5000 (65.8129)  Acc@5: 93.7500 (91.9760)  time: 0.6968  data: 0.0023  max mem: 2500
Train: Epoch[4/5]  [4050/4579]  eta: 0:03:25  Lr: 0.001875  Loss: -0.1388  Acc@1: 62.5000 (65.8186)  Acc@5: 87.5000 (91.9757)  time: 0.6964  data: 0.0010  max mem: 2500
Train: Epoch[4/5]  [4060/4579]  eta: 0:03:22  Lr: 0.001875  Loss: -0.0494  Acc@1: 68.7500 (65.8228)  Acc@5: 93.7500 (91.9740)  time: 0.7351  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [4070/4579]  eta: 0:03:18  Lr: 0.001875  Loss: 0.3728  Acc@1: 62.5000 (65.8177)  Acc@5: 93.7500 (91.9676)  time: 0.7320  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [4080/4579]  eta: 0:03:14  Lr: 0.001875  Loss: 0.3238  Acc@1: 62.5000 (65.8249)  Acc@5: 93.7500 (91.9704)  time: 0.6577  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [4090/4579]  eta: 0:03:10  Lr: 0.001875  Loss: -0.1398  Acc@1: 68.7500 (65.8366)  Acc@5: 93.7500 (91.9748)  time: 0.4668  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [4100/4579]  eta: 0:03:07  Lr: 0.001875  Loss: -0.5195  Acc@1: 62.5000 (65.8406)  Acc@5: 93.7500 (91.9760)  time: 0.5325  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [4110/4579]  eta: 0:03:03  Lr: 0.001875  Loss: -0.1757  Acc@1: 62.5000 (65.8356)  Acc@5: 87.5000 (91.9667)  time: 0.7251  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [4120/4579]  eta: 0:03:00  Lr: 0.001875  Loss: -0.8059  Acc@1: 68.7500 (65.8320)  Acc@5: 93.7500 (91.9740)  time: 0.7354  data: 0.0009  max mem: 2500
Train: Epoch[4/5]  [4130/4579]  eta: 0:02:56  Lr: 0.001875  Loss: 0.1328  Acc@1: 68.7500 (65.8361)  Acc@5: 93.7500 (91.9708)  time: 0.7348  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [4140/4579]  eta: 0:02:53  Lr: 0.001875  Loss: -0.2540  Acc@1: 68.7500 (65.8416)  Acc@5: 93.7500 (91.9720)  time: 0.7343  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [4150/4579]  eta: 0:02:49  Lr: 0.001875  Loss: -0.2184  Acc@1: 68.7500 (65.8441)  Acc@5: 93.7500 (91.9703)  time: 0.7332  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [4160/4579]  eta: 0:02:46  Lr: 0.001875  Loss: -0.2487  Acc@1: 68.7500 (65.8405)  Acc@5: 93.7500 (91.9701)  time: 0.7328  data: 0.0010  max mem: 2500
Train: Epoch[4/5]  [4170/4579]  eta: 0:02:42  Lr: 0.001875  Loss: -0.3703  Acc@1: 68.7500 (65.8385)  Acc@5: 93.7500 (91.9728)  time: 0.7330  data: 0.0010  max mem: 2500
Train: Epoch[4/5]  [4180/4579]  eta: 0:02:38  Lr: 0.001875  Loss: -0.4821  Acc@1: 68.7500 (65.8440)  Acc@5: 93.7500 (91.9801)  time: 0.7341  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [4190/4579]  eta: 0:02:35  Lr: 0.001875  Loss: -0.6619  Acc@1: 68.7500 (65.8420)  Acc@5: 93.7500 (91.9754)  time: 0.7346  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [4200/4579]  eta: 0:02:31  Lr: 0.001875  Loss: -0.3162  Acc@1: 68.7500 (65.8444)  Acc@5: 93.7500 (91.9796)  time: 0.7275  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [4210/4579]  eta: 0:02:27  Lr: 0.001875  Loss: -0.4494  Acc@1: 68.7500 (65.8395)  Acc@5: 93.7500 (91.9734)  time: 0.7306  data: 0.0010  max mem: 2500
Train: Epoch[4/5]  [4220/4579]  eta: 0:02:23  Lr: 0.001875  Loss: 0.1046  Acc@1: 62.5000 (65.8375)  Acc@5: 93.7500 (91.9687)  time: 0.7351  data: 0.0015  max mem: 2500
Train: Epoch[4/5]  [4230/4579]  eta: 0:02:20  Lr: 0.001875  Loss: -0.3254  Acc@1: 62.5000 (65.8429)  Acc@5: 93.7500 (91.9744)  time: 0.7309  data: 0.0014  max mem: 2500
Train: Epoch[4/5]  [4240/4579]  eta: 0:02:16  Lr: 0.001875  Loss: 0.0749  Acc@1: 62.5000 (65.8350)  Acc@5: 93.7500 (91.9712)  time: 0.7285  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [4250/4579]  eta: 0:02:12  Lr: 0.001875  Loss: -0.2134  Acc@1: 62.5000 (65.8330)  Acc@5: 93.7500 (91.9725)  time: 0.7296  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [4260/4579]  eta: 0:02:08  Lr: 0.001875  Loss: -0.3261  Acc@1: 62.5000 (65.8326)  Acc@5: 93.7500 (91.9708)  time: 0.7314  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [4270/4579]  eta: 0:02:05  Lr: 0.001875  Loss: -0.2624  Acc@1: 68.7500 (65.8350)  Acc@5: 87.5000 (91.9632)  time: 0.7301  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [4280/4579]  eta: 0:02:01  Lr: 0.001875  Loss: -0.2581  Acc@1: 62.5000 (65.8257)  Acc@5: 87.5000 (91.9601)  time: 0.7297  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [4290/4579]  eta: 0:01:57  Lr: 0.001875  Loss: 0.0936  Acc@1: 56.2500 (65.8165)  Acc@5: 87.5000 (91.9526)  time: 0.7299  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [4300/4579]  eta: 0:01:53  Lr: 0.001875  Loss: 0.1303  Acc@1: 62.5000 (65.8190)  Acc@5: 87.5000 (91.9510)  time: 0.7335  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [4310/4579]  eta: 0:01:49  Lr: 0.001875  Loss: -0.1462  Acc@1: 68.7500 (65.8113)  Acc@5: 93.7500 (91.9479)  time: 0.7321  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [4320/4579]  eta: 0:01:45  Lr: 0.001875  Loss: -0.5485  Acc@1: 62.5000 (65.8195)  Acc@5: 87.5000 (91.9434)  time: 0.7274  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [4330/4579]  eta: 0:01:41  Lr: 0.001875  Loss: 0.2695  Acc@1: 68.7500 (65.8191)  Acc@5: 93.7500 (91.9433)  time: 0.7264  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [4340/4579]  eta: 0:01:38  Lr: 0.001875  Loss: -0.1027  Acc@1: 68.7500 (65.8158)  Acc@5: 93.7500 (91.9445)  time: 0.7290  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [4350/4579]  eta: 0:01:34  Lr: 0.001875  Loss: 0.0806  Acc@1: 68.7500 (65.8268)  Acc@5: 93.7500 (91.9544)  time: 0.7293  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [4360/4579]  eta: 0:01:30  Lr: 0.001875  Loss: -0.0506  Acc@1: 68.7500 (65.8278)  Acc@5: 93.7500 (91.9528)  time: 0.7280  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [4370/4579]  eta: 0:01:26  Lr: 0.001875  Loss: -0.4099  Acc@1: 68.7500 (65.8187)  Acc@5: 93.7500 (91.9512)  time: 0.7259  data: 0.0016  max mem: 2500
Train: Epoch[4/5]  [4380/4579]  eta: 0:01:22  Lr: 0.001875  Loss: -0.4996  Acc@1: 62.5000 (65.8254)  Acc@5: 93.7500 (91.9567)  time: 0.7259  data: 0.0014  max mem: 2500
Train: Epoch[4/5]  [4390/4579]  eta: 0:01:18  Lr: 0.001875  Loss: -0.5176  Acc@1: 68.7500 (65.8293)  Acc@5: 93.7500 (91.9551)  time: 0.7326  data: 0.0013  max mem: 2500
Train: Epoch[4/5]  [4400/4579]  eta: 0:01:14  Lr: 0.001875  Loss: -0.7775  Acc@1: 62.5000 (65.8302)  Acc@5: 93.7500 (91.9535)  time: 0.7297  data: 0.0014  max mem: 2500
Train: Epoch[4/5]  [4410/4579]  eta: 0:01:10  Lr: 0.001875  Loss: -0.1027  Acc@1: 56.2500 (65.8170)  Acc@5: 87.5000 (91.9491)  time: 0.7311  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [4420/4579]  eta: 0:01:06  Lr: 0.001875  Loss: -0.4533  Acc@1: 56.2500 (65.8137)  Acc@5: 93.7500 (91.9518)  time: 0.7299  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [4430/4579]  eta: 0:01:02  Lr: 0.001875  Loss: 0.0035  Acc@1: 62.5000 (65.8161)  Acc@5: 93.7500 (91.9586)  time: 0.7247  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [4440/4579]  eta: 0:00:57  Lr: 0.001875  Loss: 0.0183  Acc@1: 62.5000 (65.8157)  Acc@5: 93.7500 (91.9599)  time: 0.7268  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [4450/4579]  eta: 0:00:53  Lr: 0.001875  Loss: 0.1784  Acc@1: 62.5000 (65.8096)  Acc@5: 87.5000 (91.9512)  time: 0.7237  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [4460/4579]  eta: 0:00:49  Lr: 0.001875  Loss: -0.1914  Acc@1: 68.7500 (65.8232)  Acc@5: 93.7500 (91.9581)  time: 0.6950  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [4470/4579]  eta: 0:00:45  Lr: 0.001875  Loss: -0.3449  Acc@1: 68.7500 (65.8242)  Acc@5: 93.7500 (91.9635)  time: 0.6857  data: 0.0033  max mem: 2500
Train: Epoch[4/5]  [4480/4579]  eta: 0:00:41  Lr: 0.001875  Loss: -0.6064  Acc@1: 68.7500 (65.8363)  Acc@5: 93.7500 (91.9703)  time: 0.7053  data: 0.0034  max mem: 2500
Train: Epoch[4/5]  [4490/4579]  eta: 0:00:37  Lr: 0.001875  Loss: -0.2051  Acc@1: 68.7500 (65.8400)  Acc@5: 93.7500 (91.9701)  time: 0.7068  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [4500/4579]  eta: 0:00:33  Lr: 0.001875  Loss: -0.2900  Acc@1: 68.7500 (65.8493)  Acc@5: 87.5000 (91.9671)  time: 0.7051  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [4510/4579]  eta: 0:00:29  Lr: 0.001875  Loss: -0.3697  Acc@1: 68.7500 (65.8529)  Acc@5: 87.5000 (91.9696)  time: 0.6830  data: 0.0017  max mem: 2500
Train: Epoch[4/5]  [4520/4579]  eta: 0:00:24  Lr: 0.001875  Loss: -0.2674  Acc@1: 62.5000 (65.8538)  Acc@5: 93.7500 (91.9680)  time: 0.6829  data: 0.0017  max mem: 2500
Train: Epoch[4/5]  [4530/4579]  eta: 0:00:20  Lr: 0.001875  Loss: -0.0617  Acc@1: 62.5000 (65.8560)  Acc@5: 93.7500 (91.9623)  time: 0.7092  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [4540/4579]  eta: 0:00:16  Lr: 0.001875  Loss: -0.4697  Acc@1: 68.7500 (65.8610)  Acc@5: 87.5000 (91.9607)  time: 0.7106  data: 0.0011  max mem: 2500
Train: Epoch[4/5]  [4550/4579]  eta: 0:00:12  Lr: 0.001875  Loss: 0.0715  Acc@1: 68.7500 (65.8646)  Acc@5: 93.7500 (91.9564)  time: 0.7114  data: 0.0010  max mem: 2500
Train: Epoch[4/5]  [4560/4579]  eta: 0:00:08  Lr: 0.001875  Loss: -0.1064  Acc@1: 68.7500 (65.8710)  Acc@5: 93.7500 (91.9549)  time: 0.6876  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [4570/4579]  eta: 0:00:03  Lr: 0.001875  Loss: 0.4891  Acc@1: 62.5000 (65.8595)  Acc@5: 93.7500 (91.9561)  time: 0.5234  data: 0.0016  max mem: 2500
Train: Epoch[4/5]  [4578/4579]  eta: 0:00:00  Lr: 0.001875  Loss: 0.0594  Acc@1: 62.5000 (65.8572)  Acc@5: 87.5000 (91.9462)  time: 0.5178  data: 0.0016  max mem: 2500
Train: Epoch[4/5] Total time: 0:32:27 (0.4252 s / it)
{0: {0: 293028, 1: 0, 2: 0, 3: 0, 4: 0}, 1: {0: 293028, 1: 0, 2: 0, 3: 0, 4: 0}, 2: {0: 293028, 1: 0, 2: 0, 3: 0, 4: 0}, 3: {0: 293028, 1: 0, 2: 0, 3: 0, 4: 0}, 4: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 5: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 6: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 7: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 8: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 9: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 10: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 11: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 12: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 13: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 14: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 15: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 16: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 17: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 18: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 19: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}}
Averaged stats: Lr: 0.001875  Loss: 0.0594  Acc@1: 62.5000 (65.8572)  Acc@5: 87.5000 (91.9462)
Train: Epoch[5/5]  [   0/4579]  eta: 1:43:43  Lr: 0.001875  Loss: -0.2585  Acc@1: 56.2500 (56.2500)  Acc@5: 93.7500 (93.7500)  time: 1.3591  data: 0.6356  max mem: 2500
Train: Epoch[5/5]  [  10/4579]  eta: 0:59:12  Lr: 0.001875  Loss: -0.5431  Acc@1: 62.5000 (63.0682)  Acc@5: 93.7500 (89.2045)  time: 0.7776  data: 0.0583  max mem: 2500
Train: Epoch[5/5]  [  20/4579]  eta: 0:52:42  Lr: 0.001875  Loss: -0.0040  Acc@1: 62.5000 (62.5000)  Acc@5: 93.7500 (91.3690)  time: 0.6604  data: 0.0012  max mem: 2500
Train: Epoch[5/5]  [  30/4579]  eta: 0:44:12  Lr: 0.001875  Loss: -0.4237  Acc@1: 62.5000 (63.9113)  Acc@5: 93.7500 (91.7339)  time: 0.4760  data: 0.0019  max mem: 2500
Train: Epoch[5/5]  [  40/4579]  eta: 0:39:48  Lr: 0.001875  Loss: -0.3882  Acc@1: 68.7500 (66.1585)  Acc@5: 93.7500 (92.5305)  time: 0.3503  data: 0.0012  max mem: 2500
Train: Epoch[5/5]  [  50/4579]  eta: 0:37:04  Lr: 0.001875  Loss: -0.6952  Acc@1: 75.0000 (66.7892)  Acc@5: 93.7500 (92.8922)  time: 0.3486  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [  60/4579]  eta: 0:35:14  Lr: 0.001875  Loss: 0.1320  Acc@1: 68.7500 (66.0861)  Acc@5: 93.7500 (92.4180)  time: 0.3486  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [  70/4579]  eta: 0:33:56  Lr: 0.001875  Loss: 0.0221  Acc@1: 62.5000 (65.6690)  Acc@5: 93.7500 (92.5176)  time: 0.3509  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [  80/4579]  eta: 0:32:54  Lr: 0.001875  Loss: -0.5536  Acc@1: 62.5000 (65.8179)  Acc@5: 93.7500 (92.5926)  time: 0.3503  data: 0.0010  max mem: 2500
Train: Epoch[5/5]  [  90/4579]  eta: 0:32:04  Lr: 0.001875  Loss: -0.1600  Acc@1: 62.5000 (65.5220)  Acc@5: 93.7500 (92.5824)  time: 0.3478  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [ 100/4579]  eta: 0:31:25  Lr: 0.001875  Loss: 0.0687  Acc@1: 68.7500 (65.7797)  Acc@5: 93.7500 (92.3267)  time: 0.3484  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 110/4579]  eta: 0:30:53  Lr: 0.001875  Loss: -0.7019  Acc@1: 68.7500 (66.2725)  Acc@5: 93.7500 (92.3986)  time: 0.3503  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 120/4579]  eta: 0:30:24  Lr: 0.001875  Loss: -0.4016  Acc@1: 68.7500 (66.1157)  Acc@5: 93.7500 (92.3037)  time: 0.3493  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 130/4579]  eta: 0:30:01  Lr: 0.001875  Loss: -0.3119  Acc@1: 62.5000 (65.6489)  Acc@5: 93.7500 (92.1279)  time: 0.3510  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [ 140/4579]  eta: 0:29:40  Lr: 0.001875  Loss: -0.0479  Acc@1: 62.5000 (65.7801)  Acc@5: 93.7500 (92.1543)  time: 0.3523  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [ 150/4579]  eta: 0:29:22  Lr: 0.001875  Loss: 0.3412  Acc@1: 62.5000 (65.6457)  Acc@5: 93.7500 (92.1772)  time: 0.3517  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [ 160/4579]  eta: 0:29:06  Lr: 0.001875  Loss: -0.3627  Acc@1: 68.7500 (65.7220)  Acc@5: 93.7500 (92.1584)  time: 0.3537  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [ 170/4579]  eta: 0:28:51  Lr: 0.001875  Loss: -0.5443  Acc@1: 68.7500 (65.9357)  Acc@5: 93.7500 (92.2149)  time: 0.3545  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [ 180/4579]  eta: 0:28:37  Lr: 0.001875  Loss: -0.0142  Acc@1: 68.7500 (65.8149)  Acc@5: 87.5000 (91.8508)  time: 0.3515  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [ 190/4579]  eta: 0:28:24  Lr: 0.001875  Loss: 0.5020  Acc@1: 62.5000 (65.9031)  Acc@5: 93.7500 (91.9830)  time: 0.3497  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [ 200/4579]  eta: 0:28:14  Lr: 0.001875  Loss: -0.0783  Acc@1: 62.5000 (65.7338)  Acc@5: 93.7500 (91.8843)  time: 0.3552  data: 0.0015  max mem: 2500
Train: Epoch[5/5]  [ 210/4579]  eta: 0:28:02  Lr: 0.001875  Loss: 0.1735  Acc@1: 62.5000 (65.5213)  Acc@5: 93.7500 (91.9727)  time: 0.3554  data: 0.0013  max mem: 2500
Train: Epoch[5/5]  [ 220/4579]  eta: 0:27:52  Lr: 0.001875  Loss: -0.3431  Acc@1: 62.5000 (65.3563)  Acc@5: 93.7500 (91.9400)  time: 0.3524  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [ 230/4579]  eta: 0:27:42  Lr: 0.001875  Loss: -0.0212  Acc@1: 62.5000 (65.3950)  Acc@5: 93.7500 (92.0184)  time: 0.3507  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [ 240/4579]  eta: 0:27:32  Lr: 0.001875  Loss: -0.4898  Acc@1: 68.7500 (65.5602)  Acc@5: 93.7500 (92.0124)  time: 0.3479  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 250/4579]  eta: 0:27:22  Lr: 0.001875  Loss: -0.2915  Acc@1: 68.7500 (65.5876)  Acc@5: 93.7500 (92.1066)  time: 0.3487  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [ 260/4579]  eta: 0:27:13  Lr: 0.001875  Loss: -0.4634  Acc@1: 68.7500 (65.6609)  Acc@5: 93.7500 (92.0498)  time: 0.3489  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [ 270/4579]  eta: 0:27:05  Lr: 0.001875  Loss: -0.6057  Acc@1: 68.7500 (65.8210)  Acc@5: 87.5000 (92.0895)  time: 0.3479  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [ 280/4579]  eta: 0:26:57  Lr: 0.001875  Loss: -0.2981  Acc@1: 68.7500 (65.8585)  Acc@5: 87.5000 (91.9929)  time: 0.3490  data: 0.0013  max mem: 2500
Train: Epoch[5/5]  [ 290/4579]  eta: 0:26:49  Lr: 0.001875  Loss: -0.4203  Acc@1: 68.7500 (65.8505)  Acc@5: 87.5000 (92.0318)  time: 0.3483  data: 0.0010  max mem: 2500
Train: Epoch[5/5]  [ 300/4579]  eta: 0:26:41  Lr: 0.001875  Loss: -0.3745  Acc@1: 68.7500 (66.0714)  Acc@5: 93.7500 (92.1096)  time: 0.3483  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [ 310/4579]  eta: 0:26:34  Lr: 0.001875  Loss: -0.4902  Acc@1: 68.7500 (66.1576)  Acc@5: 93.7500 (92.0619)  time: 0.3496  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [ 320/4579]  eta: 0:26:27  Lr: 0.001875  Loss: 0.0352  Acc@1: 68.7500 (66.1215)  Acc@5: 93.7500 (91.9198)  time: 0.3499  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [ 330/4579]  eta: 0:26:21  Lr: 0.001875  Loss: 0.2635  Acc@1: 68.7500 (66.1820)  Acc@5: 93.7500 (91.9373)  time: 0.3494  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [ 340/4579]  eta: 0:26:15  Lr: 0.001875  Loss: -0.7040  Acc@1: 68.7500 (66.1107)  Acc@5: 93.7500 (91.9172)  time: 0.3538  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [ 350/4579]  eta: 0:26:10  Lr: 0.001875  Loss: -0.1276  Acc@1: 62.5000 (66.0434)  Acc@5: 93.7500 (91.7913)  time: 0.3584  data: 0.0010  max mem: 2500
Train: Epoch[5/5]  [ 360/4579]  eta: 0:26:03  Lr: 0.001875  Loss: -0.3205  Acc@1: 62.5000 (66.0838)  Acc@5: 87.5000 (91.6724)  time: 0.3529  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [ 370/4579]  eta: 0:25:57  Lr: 0.001875  Loss: -0.3440  Acc@1: 62.5000 (65.8524)  Acc@5: 87.5000 (91.6274)  time: 0.3483  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [ 380/4579]  eta: 0:25:52  Lr: 0.001875  Loss: -0.0467  Acc@1: 62.5000 (65.8793)  Acc@5: 93.7500 (91.6667)  time: 0.3519  data: 0.0015  max mem: 2500
Train: Epoch[5/5]  [ 390/4579]  eta: 0:25:47  Lr: 0.001875  Loss: -0.0364  Acc@1: 62.5000 (65.7129)  Acc@5: 93.7500 (91.6081)  time: 0.3559  data: 0.0014  max mem: 2500
Train: Epoch[5/5]  [ 400/4579]  eta: 0:25:41  Lr: 0.001875  Loss: -0.8824  Acc@1: 62.5000 (65.7731)  Acc@5: 93.7500 (91.6459)  time: 0.3515  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 410/4579]  eta: 0:25:35  Lr: 0.001875  Loss: -0.1634  Acc@1: 68.7500 (65.8607)  Acc@5: 93.7500 (91.6515)  time: 0.3475  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 420/4579]  eta: 0:25:29  Lr: 0.001875  Loss: -0.5304  Acc@1: 68.7500 (65.8106)  Acc@5: 93.7500 (91.6419)  time: 0.3475  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 430/4579]  eta: 0:25:24  Lr: 0.001875  Loss: -0.7288  Acc@1: 68.7500 (66.0093)  Acc@5: 93.7500 (91.6763)  time: 0.3484  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [ 440/4579]  eta: 0:25:18  Lr: 0.001875  Loss: -0.0292  Acc@1: 68.7500 (66.0006)  Acc@5: 93.7500 (91.7234)  time: 0.3499  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [ 450/4579]  eta: 0:25:13  Lr: 0.001875  Loss: -0.5454  Acc@1: 68.7500 (66.1724)  Acc@5: 93.7500 (91.8099)  time: 0.3480  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 460/4579]  eta: 0:25:07  Lr: 0.001875  Loss: -0.4444  Acc@1: 68.7500 (66.1605)  Acc@5: 93.7500 (91.8113)  time: 0.3455  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [ 470/4579]  eta: 0:25:02  Lr: 0.001875  Loss: -0.4480  Acc@1: 62.5000 (66.0961)  Acc@5: 93.7500 (91.7861)  time: 0.3485  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 480/4579]  eta: 0:24:57  Lr: 0.001875  Loss: 0.1833  Acc@1: 56.2500 (66.0083)  Acc@5: 93.7500 (91.8269)  time: 0.3484  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [ 490/4579]  eta: 0:24:52  Lr: 0.001875  Loss: -0.0798  Acc@1: 62.5000 (66.0642)  Acc@5: 93.7500 (91.8534)  time: 0.3467  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 500/4579]  eta: 0:24:47  Lr: 0.001875  Loss: -0.3783  Acc@1: 62.5000 (66.0180)  Acc@5: 93.7500 (91.8663)  time: 0.3497  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [ 510/4579]  eta: 0:24:42  Lr: 0.001875  Loss: -0.0618  Acc@1: 62.5000 (65.8757)  Acc@5: 93.7500 (91.8297)  time: 0.3510  data: 0.0011  max mem: 2500
Train: Epoch[5/5]  [ 520/4579]  eta: 0:24:38  Lr: 0.001875  Loss: -0.5026  Acc@1: 56.2500 (65.8229)  Acc@5: 87.5000 (91.7586)  time: 0.3516  data: 0.0011  max mem: 2500
Train: Epoch[5/5]  [ 530/4579]  eta: 0:24:33  Lr: 0.001875  Loss: 0.1250  Acc@1: 56.2500 (65.7839)  Acc@5: 87.5000 (91.7491)  time: 0.3509  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [ 540/4579]  eta: 0:24:28  Lr: 0.001875  Loss: -0.3049  Acc@1: 56.2500 (65.6539)  Acc@5: 93.7500 (91.7283)  time: 0.3508  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [ 550/4579]  eta: 0:24:24  Lr: 0.001875  Loss: -0.4789  Acc@1: 62.5000 (65.5966)  Acc@5: 93.7500 (91.7650)  time: 0.3507  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [ 560/4579]  eta: 0:24:20  Lr: 0.001875  Loss: -0.4136  Acc@1: 68.7500 (65.6640)  Acc@5: 93.7500 (91.8115)  time: 0.3550  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [ 570/4579]  eta: 0:24:15  Lr: 0.001875  Loss: -0.2148  Acc@1: 68.7500 (65.6195)  Acc@5: 93.7500 (91.8454)  time: 0.3547  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [ 580/4579]  eta: 0:24:11  Lr: 0.001875  Loss: -0.5677  Acc@1: 62.5000 (65.5551)  Acc@5: 93.7500 (91.8460)  time: 0.3494  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [ 590/4579]  eta: 0:24:06  Lr: 0.001875  Loss: -0.2722  Acc@1: 56.2500 (65.4188)  Acc@5: 93.7500 (91.8359)  time: 0.3496  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 600/4579]  eta: 0:24:02  Lr: 0.001875  Loss: -0.4483  Acc@1: 62.5000 (65.4430)  Acc@5: 87.5000 (91.7429)  time: 0.3515  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [ 610/4579]  eta: 0:23:57  Lr: 0.001875  Loss: -0.3748  Acc@1: 62.5000 (65.4562)  Acc@5: 87.5000 (91.6837)  time: 0.3505  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [ 620/4579]  eta: 0:23:53  Lr: 0.001875  Loss: -0.6885  Acc@1: 62.5000 (65.4690)  Acc@5: 87.5000 (91.6667)  time: 0.3467  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 630/4579]  eta: 0:23:48  Lr: 0.001875  Loss: -0.2353  Acc@1: 68.7500 (65.5012)  Acc@5: 93.7500 (91.6799)  time: 0.3470  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [ 640/4579]  eta: 0:23:44  Lr: 0.001875  Loss: 0.0607  Acc@1: 68.7500 (65.5714)  Acc@5: 93.7500 (91.7414)  time: 0.3466  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 650/4579]  eta: 0:23:39  Lr: 0.001875  Loss: -0.3165  Acc@1: 68.7500 (65.6970)  Acc@5: 100.0000 (91.8011)  time: 0.3468  data: 0.0012  max mem: 2500
Train: Epoch[5/5]  [ 660/4579]  eta: 0:23:35  Lr: 0.001875  Loss: -0.4340  Acc@1: 68.7500 (65.7148)  Acc@5: 93.7500 (91.8211)  time: 0.3463  data: 0.0011  max mem: 2500
Train: Epoch[5/5]  [ 670/4579]  eta: 0:23:30  Lr: 0.001875  Loss: -0.1956  Acc@1: 68.7500 (65.7973)  Acc@5: 93.7500 (91.8778)  time: 0.3448  data: 0.0002  max mem: 2500
Train: Epoch[5/5]  [ 680/4579]  eta: 0:23:26  Lr: 0.001875  Loss: -0.5249  Acc@1: 62.5000 (65.7122)  Acc@5: 93.7500 (91.8410)  time: 0.3505  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [ 690/4579]  eta: 0:23:22  Lr: 0.001875  Loss: -0.2332  Acc@1: 56.2500 (65.6476)  Acc@5: 87.5000 (91.7782)  time: 0.3546  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 700/4579]  eta: 0:23:18  Lr: 0.001875  Loss: -0.1129  Acc@1: 62.5000 (65.6651)  Acc@5: 87.5000 (91.8063)  time: 0.3518  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [ 710/4579]  eta: 0:23:14  Lr: 0.001875  Loss: -0.4535  Acc@1: 62.5000 (65.6118)  Acc@5: 93.7500 (91.8337)  time: 0.3496  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [ 720/4579]  eta: 0:23:10  Lr: 0.001875  Loss: -0.0935  Acc@1: 62.5000 (65.5947)  Acc@5: 93.7500 (91.8429)  time: 0.3498  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [ 730/4579]  eta: 0:23:06  Lr: 0.001875  Loss: -0.0566  Acc@1: 62.5000 (65.6036)  Acc@5: 93.7500 (91.8263)  time: 0.3536  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [ 740/4579]  eta: 0:23:02  Lr: 0.001875  Loss: -0.5479  Acc@1: 75.0000 (65.7136)  Acc@5: 93.7500 (91.8438)  time: 0.3533  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [ 750/4579]  eta: 0:22:57  Lr: 0.001875  Loss: -0.2274  Acc@1: 68.7500 (65.7623)  Acc@5: 93.7500 (91.8609)  time: 0.3490  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [ 760/4579]  eta: 0:22:53  Lr: 0.001875  Loss: -0.0166  Acc@1: 68.7500 (65.8098)  Acc@5: 93.7500 (91.8857)  time: 0.3494  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [ 770/4579]  eta: 0:22:49  Lr: 0.001875  Loss: -0.5123  Acc@1: 68.7500 (65.8155)  Acc@5: 93.7500 (91.9018)  time: 0.3528  data: 0.0021  max mem: 2500
Train: Epoch[5/5]  [ 780/4579]  eta: 0:22:45  Lr: 0.001875  Loss: 0.1779  Acc@1: 68.7500 (65.9011)  Acc@5: 93.7500 (91.9334)  time: 0.3529  data: 0.0021  max mem: 2500
Train: Epoch[5/5]  [ 790/4579]  eta: 0:22:41  Lr: 0.001875  Loss: -0.2273  Acc@1: 62.5000 (65.7949)  Acc@5: 93.7500 (91.8932)  time: 0.3506  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [ 800/4579]  eta: 0:22:37  Lr: 0.001875  Loss: 0.1119  Acc@1: 62.5000 (65.8162)  Acc@5: 93.7500 (91.9164)  time: 0.3491  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 810/4579]  eta: 0:22:33  Lr: 0.001875  Loss: -0.0567  Acc@1: 62.5000 (65.7753)  Acc@5: 93.7500 (91.8850)  time: 0.3487  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 820/4579]  eta: 0:22:29  Lr: 0.001875  Loss: -1.0166  Acc@1: 62.5000 (65.7963)  Acc@5: 93.7500 (91.8621)  time: 0.3508  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [ 830/4579]  eta: 0:22:25  Lr: 0.001875  Loss: -0.5183  Acc@1: 62.5000 (65.7867)  Acc@5: 93.7500 (91.8923)  time: 0.3490  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 840/4579]  eta: 0:22:21  Lr: 0.001875  Loss: -0.8291  Acc@1: 68.7500 (65.7922)  Acc@5: 93.7500 (91.8772)  time: 0.3450  data: 0.0002  max mem: 2500
Train: Epoch[5/5]  [ 850/4579]  eta: 0:22:17  Lr: 0.001875  Loss: -0.6623  Acc@1: 68.7500 (65.7756)  Acc@5: 93.7500 (91.8845)  time: 0.3447  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [ 860/4579]  eta: 0:22:13  Lr: 0.001875  Loss: -0.2966  Acc@1: 62.5000 (65.7448)  Acc@5: 93.7500 (91.9135)  time: 0.3468  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [ 870/4579]  eta: 0:22:09  Lr: 0.001875  Loss: -0.3783  Acc@1: 56.2500 (65.6932)  Acc@5: 93.7500 (91.9202)  time: 0.3471  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [ 880/4579]  eta: 0:22:05  Lr: 0.001875  Loss: 0.6095  Acc@1: 62.5000 (65.6215)  Acc@5: 93.7500 (91.8913)  time: 0.3489  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [ 890/4579]  eta: 0:22:01  Lr: 0.001875  Loss: -0.7709  Acc@1: 62.5000 (65.6776)  Acc@5: 87.5000 (91.8631)  time: 0.3520  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [ 900/4579]  eta: 0:21:57  Lr: 0.001875  Loss: 0.3304  Acc@1: 68.7500 (65.6285)  Acc@5: 87.5000 (91.8216)  time: 0.3542  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [ 910/4579]  eta: 0:21:54  Lr: 0.001875  Loss: -0.4119  Acc@1: 68.7500 (65.6970)  Acc@5: 93.7500 (91.8633)  time: 0.3567  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [ 920/4579]  eta: 0:21:50  Lr: 0.001875  Loss: -0.2980  Acc@1: 68.7500 (65.6691)  Acc@5: 93.7500 (91.8499)  time: 0.3533  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [ 930/4579]  eta: 0:21:46  Lr: 0.001875  Loss: -0.4576  Acc@1: 68.7500 (65.7425)  Acc@5: 93.7500 (91.8703)  time: 0.3496  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [ 940/4579]  eta: 0:21:42  Lr: 0.001875  Loss: 0.0339  Acc@1: 68.7500 (65.7213)  Acc@5: 93.7500 (91.8704)  time: 0.3501  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [ 950/4579]  eta: 0:21:38  Lr: 0.001875  Loss: 0.3124  Acc@1: 62.5000 (65.7006)  Acc@5: 87.5000 (91.8375)  time: 0.3539  data: 0.0020  max mem: 2500
Train: Epoch[5/5]  [ 960/4579]  eta: 0:21:34  Lr: 0.001875  Loss: -0.8463  Acc@1: 68.7500 (65.7713)  Acc@5: 87.5000 (91.8444)  time: 0.3545  data: 0.0025  max mem: 2500
Train: Epoch[5/5]  [ 970/4579]  eta: 0:21:30  Lr: 0.001875  Loss: -0.6143  Acc@1: 68.7500 (65.7248)  Acc@5: 93.7500 (91.8447)  time: 0.3496  data: 0.0010  max mem: 2500
Train: Epoch[5/5]  [ 980/4579]  eta: 0:21:27  Lr: 0.001875  Loss: -0.6507  Acc@1: 62.5000 (65.7492)  Acc@5: 93.7500 (91.8451)  time: 0.3471  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 990/4579]  eta: 0:21:23  Lr: 0.001875  Loss: -0.0053  Acc@1: 68.7500 (65.7480)  Acc@5: 93.7500 (91.8327)  time: 0.3484  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1000/4579]  eta: 0:21:19  Lr: 0.001875  Loss: -0.2206  Acc@1: 68.7500 (65.7280)  Acc@5: 87.5000 (91.7957)  time: 0.3493  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1010/4579]  eta: 0:21:15  Lr: 0.001875  Loss: -0.1518  Acc@1: 68.7500 (65.8012)  Acc@5: 93.7500 (91.7965)  time: 0.3486  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1020/4579]  eta: 0:21:11  Lr: 0.001875  Loss: -0.4520  Acc@1: 68.7500 (65.8239)  Acc@5: 93.7500 (91.8095)  time: 0.3460  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [1030/4579]  eta: 0:21:07  Lr: 0.001875  Loss: -0.0050  Acc@1: 68.7500 (65.8160)  Acc@5: 93.7500 (91.7980)  time: 0.3446  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [1040/4579]  eta: 0:21:03  Lr: 0.001875  Loss: 0.2152  Acc@1: 56.2500 (65.7481)  Acc@5: 87.5000 (91.7687)  time: 0.3461  data: 0.0011  max mem: 2500
Train: Epoch[5/5]  [1050/4579]  eta: 0:20:59  Lr: 0.001875  Loss: -0.7084  Acc@1: 62.5000 (65.7291)  Acc@5: 87.5000 (91.7460)  time: 0.3458  data: 0.0011  max mem: 2500
Train: Epoch[5/5]  [1060/4579]  eta: 0:20:55  Lr: 0.001875  Loss: 0.0296  Acc@1: 68.7500 (65.7988)  Acc@5: 93.7500 (91.7531)  time: 0.3457  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [1070/4579]  eta: 0:20:51  Lr: 0.001875  Loss: -0.4752  Acc@1: 75.0000 (65.8789)  Acc@5: 93.7500 (91.7600)  time: 0.3499  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [1080/4579]  eta: 0:20:48  Lr: 0.001875  Loss: -0.2360  Acc@1: 68.7500 (65.9170)  Acc@5: 93.7500 (91.7727)  time: 0.3532  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [1090/4579]  eta: 0:20:44  Lr: 0.001875  Loss: -0.3366  Acc@1: 68.7500 (65.9258)  Acc@5: 87.5000 (91.7507)  time: 0.3511  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [1100/4579]  eta: 0:20:40  Lr: 0.001875  Loss: -0.4289  Acc@1: 62.5000 (65.9230)  Acc@5: 87.5000 (91.7291)  time: 0.3517  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [1110/4579]  eta: 0:20:37  Lr: 0.001875  Loss: -0.2123  Acc@1: 75.0000 (66.0385)  Acc@5: 93.7500 (91.7529)  time: 0.3539  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [1120/4579]  eta: 0:20:33  Lr: 0.001875  Loss: -0.6040  Acc@1: 75.0000 (66.0794)  Acc@5: 93.7500 (91.7540)  time: 0.3552  data: 0.0019  max mem: 2500
Train: Epoch[5/5]  [1130/4579]  eta: 0:20:29  Lr: 0.001875  Loss: -0.0225  Acc@1: 62.5000 (66.0477)  Acc@5: 93.7500 (91.7385)  time: 0.3568  data: 0.0018  max mem: 2500
Train: Epoch[5/5]  [1140/4579]  eta: 0:20:26  Lr: 0.001875  Loss: -0.5503  Acc@1: 68.7500 (66.1043)  Acc@5: 93.7500 (91.7616)  time: 0.3529  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [1150/4579]  eta: 0:20:22  Lr: 0.001875  Loss: -0.4913  Acc@1: 68.7500 (66.0838)  Acc@5: 93.7500 (91.7952)  time: 0.3487  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [1160/4579]  eta: 0:20:18  Lr: 0.001875  Loss: -0.1991  Acc@1: 62.5000 (66.0314)  Acc@5: 93.7500 (91.7582)  time: 0.3478  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [1170/4579]  eta: 0:20:14  Lr: 0.001875  Loss: -0.4562  Acc@1: 62.5000 (66.0066)  Acc@5: 87.5000 (91.7538)  time: 0.3491  data: 0.0017  max mem: 2500
Train: Epoch[5/5]  [1180/4579]  eta: 0:20:11  Lr: 0.001875  Loss: -0.4393  Acc@1: 62.5000 (66.0457)  Acc@5: 93.7500 (91.7707)  time: 0.3515  data: 0.0011  max mem: 2500
Train: Epoch[5/5]  [1190/4579]  eta: 0:20:07  Lr: 0.001875  Loss: -0.0586  Acc@1: 62.5000 (66.0107)  Acc@5: 93.7500 (91.7926)  time: 0.3498  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [1200/4579]  eta: 0:20:03  Lr: 0.001875  Loss: -0.3162  Acc@1: 68.7500 (66.0595)  Acc@5: 93.7500 (91.7985)  time: 0.3477  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1210/4579]  eta: 0:19:59  Lr: 0.001875  Loss: 0.3070  Acc@1: 68.7500 (66.0611)  Acc@5: 93.7500 (91.8095)  time: 0.3471  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [1220/4579]  eta: 0:19:55  Lr: 0.001875  Loss: -0.2583  Acc@1: 62.5000 (66.0524)  Acc@5: 93.7500 (91.7793)  time: 0.3475  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [1230/4579]  eta: 0:19:52  Lr: 0.001875  Loss: -0.1497  Acc@1: 68.7500 (66.0845)  Acc@5: 87.5000 (91.7953)  time: 0.3468  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [1240/4579]  eta: 0:19:48  Lr: 0.001875  Loss: -0.6078  Acc@1: 68.7500 (66.1110)  Acc@5: 93.7500 (91.8261)  time: 0.3448  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [1250/4579]  eta: 0:19:44  Lr: 0.001875  Loss: -0.5943  Acc@1: 68.7500 (66.0671)  Acc@5: 93.7500 (91.8016)  time: 0.3469  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [1260/4579]  eta: 0:19:40  Lr: 0.001875  Loss: -0.6632  Acc@1: 68.7500 (66.1082)  Acc@5: 93.7500 (91.8121)  time: 0.3499  data: 0.0010  max mem: 2500
Train: Epoch[5/5]  [1270/4579]  eta: 0:19:37  Lr: 0.001875  Loss: -0.3891  Acc@1: 68.7500 (66.1241)  Acc@5: 93.7500 (91.8322)  time: 0.3509  data: 0.0011  max mem: 2500
Train: Epoch[5/5]  [1280/4579]  eta: 0:19:33  Lr: 0.001875  Loss: -0.3897  Acc@1: 62.5000 (66.0909)  Acc@5: 93.7500 (91.8277)  time: 0.3509  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [1290/4579]  eta: 0:19:29  Lr: 0.001875  Loss: -0.1670  Acc@1: 68.7500 (66.1212)  Acc@5: 93.7500 (91.8522)  time: 0.3521  data: 0.0013  max mem: 2500
Train: Epoch[5/5]  [1300/4579]  eta: 0:19:26  Lr: 0.001875  Loss: 0.4292  Acc@1: 68.7500 (66.1510)  Acc@5: 93.7500 (91.8572)  time: 0.3544  data: 0.0010  max mem: 2500
Train: Epoch[5/5]  [1310/4579]  eta: 0:19:22  Lr: 0.001875  Loss: -0.5756  Acc@1: 68.7500 (66.1899)  Acc@5: 93.7500 (91.8574)  time: 0.3531  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [1320/4579]  eta: 0:19:18  Lr: 0.001875  Loss: -0.5096  Acc@1: 68.7500 (66.1715)  Acc@5: 93.7500 (91.8575)  time: 0.3518  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [1330/4579]  eta: 0:19:15  Lr: 0.001875  Loss: -0.1228  Acc@1: 68.7500 (66.1721)  Acc@5: 93.7500 (91.8670)  time: 0.3509  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [1340/4579]  eta: 0:19:11  Lr: 0.001875  Loss: -0.2630  Acc@1: 68.7500 (66.1633)  Acc@5: 93.7500 (91.8531)  time: 0.3500  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [1350/4579]  eta: 0:19:07  Lr: 0.001875  Loss: -0.1553  Acc@1: 62.5000 (66.1501)  Acc@5: 87.5000 (91.8394)  time: 0.3500  data: 0.0011  max mem: 2500
Train: Epoch[5/5]  [1360/4579]  eta: 0:19:04  Lr: 0.001875  Loss: -0.9641  Acc@1: 68.7500 (66.1784)  Acc@5: 93.7500 (91.8718)  time: 0.3482  data: 0.0010  max mem: 2500
Train: Epoch[5/5]  [1370/4579]  eta: 0:19:00  Lr: 0.001875  Loss: -0.1568  Acc@1: 68.7500 (66.1515)  Acc@5: 93.7500 (91.8536)  time: 0.3473  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1380/4579]  eta: 0:18:56  Lr: 0.001875  Loss: -0.3425  Acc@1: 68.7500 (66.2020)  Acc@5: 93.7500 (91.8764)  time: 0.3472  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1390/4579]  eta: 0:18:52  Lr: 0.001875  Loss: -0.5007  Acc@1: 68.7500 (66.1889)  Acc@5: 93.7500 (91.8853)  time: 0.3486  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1400/4579]  eta: 0:18:49  Lr: 0.001875  Loss: -0.3008  Acc@1: 68.7500 (66.2206)  Acc@5: 93.7500 (91.8942)  time: 0.3471  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [1410/4579]  eta: 0:18:45  Lr: 0.001875  Loss: -0.2665  Acc@1: 68.7500 (66.2341)  Acc@5: 93.7500 (91.9029)  time: 0.3450  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [1420/4579]  eta: 0:18:41  Lr: 0.001875  Loss: -0.1028  Acc@1: 68.7500 (66.2254)  Acc@5: 93.7500 (91.8851)  time: 0.3477  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [1430/4579]  eta: 0:18:37  Lr: 0.001875  Loss: -0.3473  Acc@1: 62.5000 (66.2168)  Acc@5: 93.7500 (91.8894)  time: 0.3491  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [1440/4579]  eta: 0:18:34  Lr: 0.001875  Loss: -0.3962  Acc@1: 68.7500 (66.2734)  Acc@5: 93.7500 (91.9110)  time: 0.3483  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [1450/4579]  eta: 0:18:30  Lr: 0.001875  Loss: -0.6299  Acc@1: 75.0000 (66.2991)  Acc@5: 93.7500 (91.9064)  time: 0.3478  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [1460/4579]  eta: 0:18:26  Lr: 0.001875  Loss: -0.0206  Acc@1: 68.7500 (66.2817)  Acc@5: 93.7500 (91.9105)  time: 0.3484  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [1470/4579]  eta: 0:18:23  Lr: 0.001875  Loss: -0.3791  Acc@1: 62.5000 (66.2559)  Acc@5: 87.5000 (91.8848)  time: 0.3515  data: 0.0014  max mem: 2500
Train: Epoch[5/5]  [1480/4579]  eta: 0:18:19  Lr: 0.001875  Loss: -0.6412  Acc@1: 68.7500 (66.3108)  Acc@5: 93.7500 (91.8931)  time: 0.3549  data: 0.0022  max mem: 2500
Train: Epoch[5/5]  [1490/4579]  eta: 0:18:16  Lr: 0.001875  Loss: -0.3735  Acc@1: 68.7500 (66.3187)  Acc@5: 93.7500 (91.9056)  time: 0.3549  data: 0.0014  max mem: 2500
Train: Epoch[5/5]  [1500/4579]  eta: 0:18:12  Lr: 0.001875  Loss: -0.4974  Acc@1: 68.7500 (66.3433)  Acc@5: 93.7500 (91.9137)  time: 0.3520  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [1510/4579]  eta: 0:18:08  Lr: 0.001875  Loss: -0.4984  Acc@1: 68.7500 (66.3220)  Acc@5: 93.7500 (91.9135)  time: 0.3501  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [1520/4579]  eta: 0:18:05  Lr: 0.001875  Loss: 0.1436  Acc@1: 62.5000 (66.3297)  Acc@5: 93.7500 (91.9132)  time: 0.3521  data: 0.0021  max mem: 2500
Train: Epoch[5/5]  [1530/4579]  eta: 0:18:01  Lr: 0.001875  Loss: -0.2182  Acc@1: 62.5000 (66.3088)  Acc@5: 93.7500 (91.9211)  time: 0.3538  data: 0.0022  max mem: 2500
Train: Epoch[5/5]  [1540/4579]  eta: 0:17:58  Lr: 0.001875  Loss: -0.5642  Acc@1: 68.7500 (66.3449)  Acc@5: 93.7500 (91.9249)  time: 0.3503  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [1550/4579]  eta: 0:17:54  Lr: 0.001875  Loss: -0.3497  Acc@1: 68.7500 (66.3604)  Acc@5: 93.7500 (91.9487)  time: 0.3475  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1560/4579]  eta: 0:17:50  Lr: 0.001875  Loss: -0.0688  Acc@1: 56.2500 (66.3077)  Acc@5: 93.7500 (91.9283)  time: 0.3506  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [1570/4579]  eta: 0:17:47  Lr: 0.001875  Loss: -0.0009  Acc@1: 56.2500 (66.2794)  Acc@5: 87.5000 (91.9200)  time: 0.3554  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [1580/4579]  eta: 0:17:43  Lr: 0.001875  Loss: -0.1794  Acc@1: 62.5000 (66.2674)  Acc@5: 93.7500 (91.9236)  time: 0.3531  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [1590/4579]  eta: 0:17:39  Lr: 0.001875  Loss: 0.2314  Acc@1: 62.5000 (66.2084)  Acc@5: 93.7500 (91.9312)  time: 0.3472  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1600/4579]  eta: 0:17:36  Lr: 0.001875  Loss: 0.3043  Acc@1: 56.2500 (66.1852)  Acc@5: 93.7500 (91.9035)  time: 0.3456  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [1610/4579]  eta: 0:17:32  Lr: 0.001875  Loss: -0.4035  Acc@1: 68.7500 (66.1972)  Acc@5: 93.7500 (91.9188)  time: 0.3476  data: 0.0010  max mem: 2500
Train: Epoch[5/5]  [1620/4579]  eta: 0:17:28  Lr: 0.001875  Loss: -0.3315  Acc@1: 68.7500 (66.2130)  Acc@5: 93.7500 (91.9224)  time: 0.3467  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [1630/4579]  eta: 0:17:25  Lr: 0.001875  Loss: 0.1990  Acc@1: 62.5000 (66.1711)  Acc@5: 93.7500 (91.9106)  time: 0.3451  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1640/4579]  eta: 0:17:21  Lr: 0.001875  Loss: -0.5469  Acc@1: 62.5000 (66.1868)  Acc@5: 93.7500 (91.9218)  time: 0.3491  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [1650/4579]  eta: 0:17:18  Lr: 0.001875  Loss: -0.7854  Acc@1: 75.0000 (66.2250)  Acc@5: 100.0000 (91.9518)  time: 0.3526  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [1660/4579]  eta: 0:17:14  Lr: 0.001875  Loss: -0.0566  Acc@1: 68.7500 (66.2176)  Acc@5: 93.7500 (91.9401)  time: 0.3505  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [1670/4579]  eta: 0:17:10  Lr: 0.001875  Loss: -0.2394  Acc@1: 62.5000 (66.2216)  Acc@5: 93.7500 (91.9397)  time: 0.3500  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [1680/4579]  eta: 0:17:07  Lr: 0.001875  Loss: -0.6597  Acc@1: 62.5000 (66.1994)  Acc@5: 93.7500 (91.9653)  time: 0.3537  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [1690/4579]  eta: 0:17:03  Lr: 0.001875  Loss: 0.0234  Acc@1: 62.5000 (66.1960)  Acc@5: 93.7500 (91.9759)  time: 0.3546  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [1700/4579]  eta: 0:17:00  Lr: 0.001875  Loss: -0.4908  Acc@1: 68.7500 (66.2147)  Acc@5: 93.7500 (91.9790)  time: 0.3520  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [1710/4579]  eta: 0:16:56  Lr: 0.001875  Loss: -0.4253  Acc@1: 68.7500 (66.2332)  Acc@5: 93.7500 (91.9747)  time: 0.3485  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [1720/4579]  eta: 0:16:52  Lr: 0.001875  Loss: -0.0804  Acc@1: 68.7500 (66.2188)  Acc@5: 93.7500 (91.9778)  time: 0.3489  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [1730/4579]  eta: 0:16:49  Lr: 0.001875  Loss: 0.2690  Acc@1: 62.5000 (66.1720)  Acc@5: 87.5000 (91.9519)  time: 0.3505  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [1740/4579]  eta: 0:16:45  Lr: 0.001875  Loss: -0.0674  Acc@1: 62.5000 (66.1760)  Acc@5: 87.5000 (91.9407)  time: 0.3503  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1750/4579]  eta: 0:16:42  Lr: 0.001875  Loss: -0.5892  Acc@1: 68.7500 (66.1586)  Acc@5: 93.7500 (91.9439)  time: 0.3515  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1760/4579]  eta: 0:16:38  Lr: 0.001875  Loss: -0.1471  Acc@1: 68.7500 (66.1520)  Acc@5: 93.7500 (91.9364)  time: 0.3500  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [1770/4579]  eta: 0:16:34  Lr: 0.001875  Loss: -0.4186  Acc@1: 68.7500 (66.1491)  Acc@5: 93.7500 (91.9361)  time: 0.3477  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [1780/4579]  eta: 0:16:31  Lr: 0.001875  Loss: -0.3105  Acc@1: 68.7500 (66.1672)  Acc@5: 93.7500 (91.9568)  time: 0.3481  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1790/4579]  eta: 0:16:27  Lr: 0.001875  Loss: -0.2216  Acc@1: 68.7500 (66.1572)  Acc@5: 93.7500 (91.9563)  time: 0.3466  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [1800/4579]  eta: 0:16:23  Lr: 0.001875  Loss: -0.0670  Acc@1: 68.7500 (66.1716)  Acc@5: 93.7500 (91.9801)  time: 0.3452  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [1810/4579]  eta: 0:16:20  Lr: 0.001875  Loss: -0.2681  Acc@1: 62.5000 (66.1444)  Acc@5: 93.7500 (91.9727)  time: 0.3456  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [1820/4579]  eta: 0:16:16  Lr: 0.001875  Loss: -0.2202  Acc@1: 62.5000 (66.1690)  Acc@5: 93.7500 (91.9687)  time: 0.3464  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1830/4579]  eta: 0:16:12  Lr: 0.001875  Loss: -0.0098  Acc@1: 68.7500 (66.1899)  Acc@5: 93.7500 (91.9648)  time: 0.3474  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1840/4579]  eta: 0:16:09  Lr: 0.001875  Loss: -0.2257  Acc@1: 68.7500 (66.2242)  Acc@5: 93.7500 (91.9643)  time: 0.3503  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [1850/4579]  eta: 0:16:05  Lr: 0.001875  Loss: -0.3308  Acc@1: 68.7500 (66.2041)  Acc@5: 93.7500 (91.9537)  time: 0.3511  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1860/4579]  eta: 0:16:02  Lr: 0.001875  Loss: -0.5715  Acc@1: 68.7500 (66.2379)  Acc@5: 93.7500 (91.9566)  time: 0.3502  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [1870/4579]  eta: 0:15:58  Lr: 0.001875  Loss: -0.2395  Acc@1: 75.0000 (66.2680)  Acc@5: 93.7500 (91.9729)  time: 0.3519  data: 0.0017  max mem: 2500
Train: Epoch[5/5]  [1880/4579]  eta: 0:15:54  Lr: 0.001875  Loss: -0.7572  Acc@1: 68.7500 (66.2713)  Acc@5: 100.0000 (91.9823)  time: 0.3529  data: 0.0017  max mem: 2500
Train: Epoch[5/5]  [1890/4579]  eta: 0:15:51  Lr: 0.001875  Loss: -0.2168  Acc@1: 68.7500 (66.2712)  Acc@5: 93.7500 (91.9818)  time: 0.3502  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [1900/4579]  eta: 0:15:47  Lr: 0.001875  Loss: -0.5204  Acc@1: 68.7500 (66.2973)  Acc@5: 93.7500 (91.9976)  time: 0.3493  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [1910/4579]  eta: 0:15:44  Lr: 0.001875  Loss: -0.5986  Acc@1: 68.7500 (66.3036)  Acc@5: 93.7500 (91.9872)  time: 0.3527  data: 0.0015  max mem: 2500
Train: Epoch[5/5]  [1920/4579]  eta: 0:15:40  Lr: 0.001875  Loss: 0.3608  Acc@1: 68.7500 (66.3164)  Acc@5: 87.5000 (91.9768)  time: 0.3521  data: 0.0012  max mem: 2500
Train: Epoch[5/5]  [1930/4579]  eta: 0:15:37  Lr: 0.001875  Loss: -0.5561  Acc@1: 68.7500 (66.3160)  Acc@5: 93.7500 (91.9893)  time: 0.3490  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [1940/4579]  eta: 0:15:33  Lr: 0.001875  Loss: -0.1870  Acc@1: 68.7500 (66.3157)  Acc@5: 93.7500 (91.9983)  time: 0.3477  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1950/4579]  eta: 0:15:29  Lr: 0.001875  Loss: -0.3526  Acc@1: 62.5000 (66.3121)  Acc@5: 93.7500 (92.0009)  time: 0.3478  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1960/4579]  eta: 0:15:26  Lr: 0.001875  Loss: -0.1238  Acc@1: 62.5000 (66.3373)  Acc@5: 93.7500 (92.0098)  time: 0.3480  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1970/4579]  eta: 0:15:22  Lr: 0.001875  Loss: -0.5535  Acc@1: 68.7500 (66.3369)  Acc@5: 93.7500 (92.0186)  time: 0.3490  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [1980/4579]  eta: 0:15:18  Lr: 0.001875  Loss: -0.4440  Acc@1: 68.7500 (66.3459)  Acc@5: 93.7500 (92.0148)  time: 0.3475  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [1990/4579]  eta: 0:15:15  Lr: 0.001875  Loss: -0.6252  Acc@1: 68.7500 (66.3705)  Acc@5: 93.7500 (92.0203)  time: 0.3452  data: 0.0002  max mem: 2500
Train: Epoch[5/5]  [2000/4579]  eta: 0:15:11  Lr: 0.001875  Loss: -0.1864  Acc@1: 62.5000 (66.3543)  Acc@5: 93.7500 (92.0102)  time: 0.3461  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [2010/4579]  eta: 0:15:08  Lr: 0.001875  Loss: 0.1298  Acc@1: 62.5000 (66.3911)  Acc@5: 93.7500 (92.0220)  time: 0.3470  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2020/4579]  eta: 0:15:04  Lr: 0.001875  Loss: -0.6535  Acc@1: 75.0000 (66.4059)  Acc@5: 93.7500 (92.0429)  time: 0.3459  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [2030/4579]  eta: 0:15:00  Lr: 0.001875  Loss: -0.1375  Acc@1: 68.7500 (66.4051)  Acc@5: 93.7500 (92.0575)  time: 0.3477  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2040/4579]  eta: 0:14:57  Lr: 0.001875  Loss: 0.0060  Acc@1: 68.7500 (66.4350)  Acc@5: 93.7500 (92.0750)  time: 0.3528  data: 0.0012  max mem: 2500
Train: Epoch[5/5]  [2050/4579]  eta: 0:14:53  Lr: 0.001875  Loss: -0.5394  Acc@1: 62.5000 (66.4219)  Acc@5: 93.7500 (92.0801)  time: 0.3527  data: 0.0016  max mem: 2500
Train: Epoch[5/5]  [2060/4579]  eta: 0:14:50  Lr: 0.001875  Loss: -0.5158  Acc@1: 75.0000 (66.4574)  Acc@5: 93.7500 (92.0943)  time: 0.3500  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [2070/4579]  eta: 0:14:46  Lr: 0.001875  Loss: -0.5798  Acc@1: 75.0000 (66.4685)  Acc@5: 93.7500 (92.0841)  time: 0.3477  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2080/4579]  eta: 0:14:42  Lr: 0.001875  Loss: -0.2531  Acc@1: 62.5000 (66.4704)  Acc@5: 93.7500 (92.0861)  time: 0.3480  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [2090/4579]  eta: 0:14:39  Lr: 0.001875  Loss: -0.7295  Acc@1: 62.5000 (66.4843)  Acc@5: 93.7500 (92.0762)  time: 0.3500  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [2100/4579]  eta: 0:14:35  Lr: 0.001875  Loss: -0.3467  Acc@1: 68.7500 (66.5100)  Acc@5: 93.7500 (92.0871)  time: 0.3484  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2110/4579]  eta: 0:14:32  Lr: 0.001875  Loss: 0.8394  Acc@1: 62.5000 (66.4910)  Acc@5: 93.7500 (92.0772)  time: 0.3465  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [2120/4579]  eta: 0:14:28  Lr: 0.001875  Loss: -0.6123  Acc@1: 62.5000 (66.5017)  Acc@5: 87.5000 (92.0763)  time: 0.3474  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [2130/4579]  eta: 0:14:25  Lr: 0.001875  Loss: 0.2071  Acc@1: 62.5000 (66.4829)  Acc@5: 93.7500 (92.0753)  time: 0.3517  data: 0.0015  max mem: 2500
Train: Epoch[5/5]  [2140/4579]  eta: 0:14:21  Lr: 0.001875  Loss: -0.4951  Acc@1: 62.5000 (66.4672)  Acc@5: 93.7500 (92.0481)  time: 0.3512  data: 0.0018  max mem: 2500
Train: Epoch[5/5]  [2150/4579]  eta: 0:14:17  Lr: 0.001875  Loss: 0.0613  Acc@1: 62.5000 (66.4575)  Acc@5: 87.5000 (92.0502)  time: 0.3473  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [2160/4579]  eta: 0:14:14  Lr: 0.001875  Loss: -0.5713  Acc@1: 62.5000 (66.4536)  Acc@5: 93.7500 (92.0581)  time: 0.3466  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2170/4579]  eta: 0:14:10  Lr: 0.001875  Loss: -0.0077  Acc@1: 68.7500 (66.4757)  Acc@5: 93.7500 (92.0601)  time: 0.3476  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2180/4579]  eta: 0:14:07  Lr: 0.001875  Loss: -0.0347  Acc@1: 68.7500 (66.4460)  Acc@5: 93.7500 (92.0535)  time: 0.3489  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2190/4579]  eta: 0:14:03  Lr: 0.001875  Loss: 0.0220  Acc@1: 62.5000 (66.4480)  Acc@5: 93.7500 (92.0727)  time: 0.3492  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2200/4579]  eta: 0:13:59  Lr: 0.001875  Loss: -0.0260  Acc@1: 62.5000 (66.4499)  Acc@5: 93.7500 (92.0775)  time: 0.3485  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2210/4579]  eta: 0:13:56  Lr: 0.001875  Loss: -0.2020  Acc@1: 62.5000 (66.4151)  Acc@5: 93.7500 (92.0709)  time: 0.3479  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2220/4579]  eta: 0:13:52  Lr: 0.001875  Loss: -0.2385  Acc@1: 62.5000 (66.4115)  Acc@5: 87.5000 (92.0672)  time: 0.3490  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [2230/4579]  eta: 0:13:49  Lr: 0.001875  Loss: -0.5966  Acc@1: 68.7500 (66.4220)  Acc@5: 87.5000 (92.0579)  time: 0.3479  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [2240/4579]  eta: 0:13:45  Lr: 0.001875  Loss: -0.5034  Acc@1: 68.7500 (66.4268)  Acc@5: 87.5000 (92.0599)  time: 0.3458  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [2250/4579]  eta: 0:13:42  Lr: 0.001875  Loss: 0.7386  Acc@1: 62.5000 (66.3955)  Acc@5: 87.5000 (92.0424)  time: 0.3465  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [2260/4579]  eta: 0:13:38  Lr: 0.001875  Loss: -0.4968  Acc@1: 68.7500 (66.4225)  Acc@5: 87.5000 (92.0389)  time: 0.3475  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2270/4579]  eta: 0:13:34  Lr: 0.001875  Loss: -0.1349  Acc@1: 68.7500 (66.4162)  Acc@5: 93.7500 (92.0410)  time: 0.3480  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [2280/4579]  eta: 0:13:31  Lr: 0.001875  Loss: -0.1859  Acc@1: 62.5000 (66.4100)  Acc@5: 93.7500 (92.0512)  time: 0.3490  data: 0.0011  max mem: 2500
Train: Epoch[5/5]  [2290/4579]  eta: 0:13:27  Lr: 0.001875  Loss: 0.1179  Acc@1: 62.5000 (66.3957)  Acc@5: 93.7500 (92.0504)  time: 0.3504  data: 0.0011  max mem: 2500
Train: Epoch[5/5]  [2300/4579]  eta: 0:13:24  Lr: 0.001875  Loss: 0.0326  Acc@1: 62.5000 (66.3896)  Acc@5: 93.7500 (92.0524)  time: 0.3523  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [2310/4579]  eta: 0:13:20  Lr: 0.001875  Loss: -0.6810  Acc@1: 68.7500 (66.4079)  Acc@5: 93.7500 (92.0516)  time: 0.3521  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [2320/4579]  eta: 0:13:17  Lr: 0.001875  Loss: -0.8521  Acc@1: 75.0000 (66.4288)  Acc@5: 93.7500 (92.0562)  time: 0.3496  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [2330/4579]  eta: 0:13:13  Lr: 0.001875  Loss: -0.3741  Acc@1: 68.7500 (66.4334)  Acc@5: 93.7500 (92.0608)  time: 0.3484  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [2340/4579]  eta: 0:13:10  Lr: 0.001875  Loss: 0.0004  Acc@1: 68.7500 (66.4566)  Acc@5: 93.7500 (92.0707)  time: 0.3614  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [2350/4579]  eta: 0:13:06  Lr: 0.001875  Loss: -0.6103  Acc@1: 68.7500 (66.4691)  Acc@5: 93.7500 (92.0699)  time: 0.3626  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [2360/4579]  eta: 0:13:03  Lr: 0.001875  Loss: -0.5680  Acc@1: 68.7500 (66.4840)  Acc@5: 93.7500 (92.0743)  time: 0.3506  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [2370/4579]  eta: 0:13:00  Lr: 0.001875  Loss: -0.4223  Acc@1: 68.7500 (66.5041)  Acc@5: 93.7500 (92.0735)  time: 0.4189  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2380/4579]  eta: 0:13:00  Lr: 0.001875  Loss: -0.6754  Acc@1: 68.7500 (66.4978)  Acc@5: 93.7500 (92.0727)  time: 0.6208  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2390/4579]  eta: 0:13:01  Lr: 0.001875  Loss: -0.4282  Acc@1: 68.7500 (66.4941)  Acc@5: 93.7500 (92.0692)  time: 0.7525  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2400/4579]  eta: 0:13:01  Lr: 0.001875  Loss: -0.5425  Acc@1: 68.7500 (66.5009)  Acc@5: 93.7500 (92.0684)  time: 0.7514  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2410/4579]  eta: 0:13:01  Lr: 0.001875  Loss: -0.6449  Acc@1: 68.7500 (66.5025)  Acc@5: 93.7500 (92.0702)  time: 0.7511  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [2420/4579]  eta: 0:13:00  Lr: 0.001875  Loss: -0.7975  Acc@1: 62.5000 (66.4989)  Acc@5: 93.7500 (92.0720)  time: 0.7501  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [2430/4579]  eta: 0:12:57  Lr: 0.001875  Loss: -0.3430  Acc@1: 62.5000 (66.4824)  Acc@5: 93.7500 (92.0814)  time: 0.5684  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2440/4579]  eta: 0:12:53  Lr: 0.001875  Loss: -0.6992  Acc@1: 68.7500 (66.5122)  Acc@5: 93.7500 (92.0960)  time: 0.3686  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [2450/4579]  eta: 0:12:50  Lr: 0.001875  Loss: -0.3736  Acc@1: 68.7500 (66.4882)  Acc@5: 93.7500 (92.0874)  time: 0.3502  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [2460/4579]  eta: 0:12:46  Lr: 0.001875  Loss: -0.5297  Acc@1: 62.5000 (66.5126)  Acc@5: 93.7500 (92.0916)  time: 0.3528  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [2470/4579]  eta: 0:12:42  Lr: 0.001875  Loss: -0.1809  Acc@1: 68.7500 (66.5191)  Acc@5: 93.7500 (92.0908)  time: 0.3551  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [2480/4579]  eta: 0:12:39  Lr: 0.001875  Loss: -0.9057  Acc@1: 68.7500 (66.5281)  Acc@5: 93.7500 (92.0924)  time: 0.3542  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [2490/4579]  eta: 0:12:35  Lr: 0.001875  Loss: -0.2731  Acc@1: 68.7500 (66.5345)  Acc@5: 93.7500 (92.0991)  time: 0.3522  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [2500/4579]  eta: 0:12:31  Lr: 0.001875  Loss: -0.4608  Acc@1: 68.7500 (66.5284)  Acc@5: 93.7500 (92.1007)  time: 0.3510  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2510/4579]  eta: 0:12:27  Lr: 0.001875  Loss: 0.2878  Acc@1: 68.7500 (66.5298)  Acc@5: 93.7500 (92.1122)  time: 0.3533  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [2520/4579]  eta: 0:12:24  Lr: 0.001875  Loss: -0.2775  Acc@1: 68.7500 (66.5435)  Acc@5: 93.7500 (92.1237)  time: 0.3513  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [2530/4579]  eta: 0:12:20  Lr: 0.001875  Loss: -0.2375  Acc@1: 62.5000 (66.5276)  Acc@5: 93.7500 (92.1227)  time: 0.3489  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2540/4579]  eta: 0:12:16  Lr: 0.001875  Loss: -0.1034  Acc@1: 68.7500 (66.5314)  Acc@5: 93.7500 (92.1168)  time: 0.3505  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [2550/4579]  eta: 0:12:13  Lr: 0.001875  Loss: -0.2675  Acc@1: 68.7500 (66.5303)  Acc@5: 93.7500 (92.1281)  time: 0.3561  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [2560/4579]  eta: 0:12:09  Lr: 0.001875  Loss: -0.3112  Acc@1: 62.5000 (66.5267)  Acc@5: 93.7500 (92.1369)  time: 0.3583  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2570/4579]  eta: 0:12:05  Lr: 0.001875  Loss: -0.5365  Acc@1: 62.5000 (66.5281)  Acc@5: 93.7500 (92.1285)  time: 0.3505  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [2580/4579]  eta: 0:12:02  Lr: 0.001875  Loss: -0.5979  Acc@1: 68.7500 (66.5440)  Acc@5: 93.7500 (92.1373)  time: 0.3509  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2590/4579]  eta: 0:12:01  Lr: 0.001875  Loss: -0.5957  Acc@1: 62.5000 (66.5187)  Acc@5: 93.7500 (92.1121)  time: 0.5407  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2600/4579]  eta: 0:12:00  Lr: 0.001875  Loss: -0.1997  Acc@1: 62.5000 (66.5105)  Acc@5: 87.5000 (92.1088)  time: 0.7408  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2610/4579]  eta: 0:12:00  Lr: 0.001875  Loss: -0.1490  Acc@1: 62.5000 (66.5095)  Acc@5: 93.7500 (92.1151)  time: 0.7544  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [2620/4579]  eta: 0:11:59  Lr: 0.001875  Loss: -0.5994  Acc@1: 62.5000 (66.4918)  Acc@5: 93.7500 (92.1094)  time: 0.7524  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [2630/4579]  eta: 0:11:58  Lr: 0.001875  Loss: -0.7035  Acc@1: 68.7500 (66.5075)  Acc@5: 93.7500 (92.1251)  time: 0.7531  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [2640/4579]  eta: 0:11:57  Lr: 0.001875  Loss: -0.1874  Acc@1: 75.0000 (66.5349)  Acc@5: 93.7500 (92.1337)  time: 0.7517  data: 0.0014  max mem: 2500
Train: Epoch[5/5]  [2650/4579]  eta: 0:11:56  Lr: 0.001875  Loss: -0.2165  Acc@1: 68.7500 (66.5480)  Acc@5: 93.7500 (92.1233)  time: 0.7523  data: 0.0013  max mem: 2500
Train: Epoch[5/5]  [2660/4579]  eta: 0:11:55  Lr: 0.001875  Loss: -0.3184  Acc@1: 68.7500 (66.5375)  Acc@5: 87.5000 (92.1176)  time: 0.7533  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2670/4579]  eta: 0:11:54  Lr: 0.001875  Loss: -0.9180  Acc@1: 68.7500 (66.5668)  Acc@5: 93.7500 (92.1331)  time: 0.7491  data: 0.0010  max mem: 2500
Train: Epoch[5/5]  [2680/4579]  eta: 0:11:53  Lr: 0.001875  Loss: -0.3655  Acc@1: 68.7500 (66.5377)  Acc@5: 93.7500 (92.1438)  time: 0.7485  data: 0.0013  max mem: 2500
Train: Epoch[5/5]  [2690/4579]  eta: 0:11:52  Lr: 0.001875  Loss: 0.1964  Acc@1: 62.5000 (66.5459)  Acc@5: 93.7500 (92.1405)  time: 0.7492  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [2700/4579]  eta: 0:11:51  Lr: 0.001875  Loss: -0.4734  Acc@1: 68.7500 (66.5471)  Acc@5: 93.7500 (92.1349)  time: 0.7475  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [2710/4579]  eta: 0:11:49  Lr: 0.001875  Loss: -0.1539  Acc@1: 68.7500 (66.5529)  Acc@5: 93.7500 (92.1454)  time: 0.7472  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2720/4579]  eta: 0:11:48  Lr: 0.001875  Loss: -0.2225  Acc@1: 68.7500 (66.5748)  Acc@5: 93.7500 (92.1582)  time: 0.7480  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2730/4579]  eta: 0:11:47  Lr: 0.001875  Loss: -0.2424  Acc@1: 68.7500 (66.5667)  Acc@5: 93.7500 (92.1549)  time: 0.7447  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [2740/4579]  eta: 0:11:45  Lr: 0.001875  Loss: -0.6559  Acc@1: 68.7500 (66.5861)  Acc@5: 93.7500 (92.1653)  time: 0.7439  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [2750/4579]  eta: 0:11:44  Lr: 0.001875  Loss: -0.1705  Acc@1: 68.7500 (66.6121)  Acc@5: 93.7500 (92.1483)  time: 0.7460  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2760/4579]  eta: 0:11:42  Lr: 0.001875  Loss: -0.5242  Acc@1: 68.7500 (66.5972)  Acc@5: 93.7500 (92.1405)  time: 0.7420  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2770/4579]  eta: 0:11:41  Lr: 0.001875  Loss: -0.6971  Acc@1: 62.5000 (66.5960)  Acc@5: 93.7500 (92.1486)  time: 0.7360  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2780/4579]  eta: 0:11:39  Lr: 0.001875  Loss: -0.2855  Acc@1: 68.7500 (66.5925)  Acc@5: 93.7500 (92.1409)  time: 0.7380  data: 0.0011  max mem: 2500
Train: Epoch[5/5]  [2790/4579]  eta: 0:11:38  Lr: 0.001875  Loss: 0.0174  Acc@1: 68.7500 (66.5890)  Acc@5: 93.7500 (92.1466)  time: 0.7435  data: 0.0012  max mem: 2500
Train: Epoch[5/5]  [2800/4579]  eta: 0:11:36  Lr: 0.001875  Loss: -0.2602  Acc@1: 68.7500 (66.5878)  Acc@5: 93.7500 (92.1390)  time: 0.7416  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [2810/4579]  eta: 0:11:34  Lr: 0.001875  Loss: 0.3136  Acc@1: 62.5000 (66.5688)  Acc@5: 87.5000 (92.1314)  time: 0.7406  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [2820/4579]  eta: 0:11:32  Lr: 0.001875  Loss: -0.0405  Acc@1: 62.5000 (66.5876)  Acc@5: 93.7500 (92.1482)  time: 0.7403  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [2830/4579]  eta: 0:11:31  Lr: 0.001875  Loss: -0.1704  Acc@1: 68.7500 (66.5953)  Acc@5: 93.7500 (92.1472)  time: 0.7423  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [2840/4579]  eta: 0:11:29  Lr: 0.001875  Loss: -0.4737  Acc@1: 62.5000 (66.5831)  Acc@5: 87.5000 (92.1419)  time: 0.7480  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2850/4579]  eta: 0:11:25  Lr: 0.001875  Loss: -0.7671  Acc@1: 62.5000 (66.5841)  Acc@5: 93.7500 (92.1475)  time: 0.5480  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2860/4579]  eta: 0:11:20  Lr: 0.001875  Loss: -0.5013  Acc@1: 62.5000 (66.5829)  Acc@5: 93.7500 (92.1444)  time: 0.3462  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2870/4579]  eta: 0:11:16  Lr: 0.001875  Loss: -0.0127  Acc@1: 62.5000 (66.5752)  Acc@5: 93.7500 (92.1456)  time: 0.3460  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [2880/4579]  eta: 0:11:12  Lr: 0.001875  Loss: -0.0223  Acc@1: 62.5000 (66.5763)  Acc@5: 93.7500 (92.1381)  time: 0.3468  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [2890/4579]  eta: 0:11:08  Lr: 0.001875  Loss: -0.4004  Acc@1: 62.5000 (66.5773)  Acc@5: 93.7500 (92.1416)  time: 0.3477  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [2900/4579]  eta: 0:11:04  Lr: 0.001875  Loss: -0.7182  Acc@1: 75.0000 (66.6085)  Acc@5: 93.7500 (92.1514)  time: 0.3617  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [2910/4579]  eta: 0:10:59  Lr: 0.001875  Loss: -0.6925  Acc@1: 68.7500 (66.6073)  Acc@5: 93.7500 (92.1526)  time: 0.3626  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [2920/4579]  eta: 0:10:55  Lr: 0.001875  Loss: -0.5443  Acc@1: 62.5000 (66.5932)  Acc@5: 93.7500 (92.1559)  time: 0.3502  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [2930/4579]  eta: 0:10:51  Lr: 0.001875  Loss: -0.6383  Acc@1: 62.5000 (66.5707)  Acc@5: 93.7500 (92.1571)  time: 0.3590  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [2940/4579]  eta: 0:10:49  Lr: 0.001875  Loss: -0.1318  Acc@1: 62.5000 (66.5632)  Acc@5: 93.7500 (92.1625)  time: 0.5236  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [2950/4579]  eta: 0:10:47  Lr: 0.001875  Loss: -0.0927  Acc@1: 62.5000 (66.5643)  Acc@5: 93.7500 (92.1721)  time: 0.7164  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [2960/4579]  eta: 0:10:45  Lr: 0.001875  Loss: 0.3954  Acc@1: 62.5000 (66.5442)  Acc@5: 93.7500 (92.1627)  time: 0.7527  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [2970/4579]  eta: 0:10:43  Lr: 0.001875  Loss: -0.3415  Acc@1: 62.5000 (66.5496)  Acc@5: 93.7500 (92.1659)  time: 0.7513  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2980/4579]  eta: 0:10:41  Lr: 0.001875  Loss: 0.0936  Acc@1: 68.7500 (66.5569)  Acc@5: 93.7500 (92.1671)  time: 0.7530  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2990/4579]  eta: 0:10:38  Lr: 0.001875  Loss: 0.0522  Acc@1: 62.5000 (66.5413)  Acc@5: 93.7500 (92.1577)  time: 0.7525  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3000/4579]  eta: 0:10:36  Lr: 0.001875  Loss: -0.1841  Acc@1: 62.5000 (66.5341)  Acc@5: 87.5000 (92.1422)  time: 0.7489  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3010/4579]  eta: 0:10:34  Lr: 0.001875  Loss: -0.4757  Acc@1: 68.7500 (66.5373)  Acc@5: 93.7500 (92.1434)  time: 0.7495  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [3020/4579]  eta: 0:10:32  Lr: 0.001875  Loss: -0.2889  Acc@1: 68.7500 (66.5467)  Acc@5: 93.7500 (92.1466)  time: 0.7530  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [3030/4579]  eta: 0:10:29  Lr: 0.001875  Loss: -0.1211  Acc@1: 62.5000 (66.5416)  Acc@5: 93.7500 (92.1519)  time: 0.7529  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [3040/4579]  eta: 0:10:27  Lr: 0.001875  Loss: 0.1637  Acc@1: 62.5000 (66.5303)  Acc@5: 93.7500 (92.1469)  time: 0.7527  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [3050/4579]  eta: 0:10:25  Lr: 0.001875  Loss: -0.0418  Acc@1: 62.5000 (66.5130)  Acc@5: 87.5000 (92.1440)  time: 0.7494  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [3060/4579]  eta: 0:10:22  Lr: 0.001875  Loss: -0.4082  Acc@1: 62.5000 (66.5142)  Acc@5: 93.7500 (92.1594)  time: 0.7437  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3070/4579]  eta: 0:10:20  Lr: 0.001875  Loss: -0.6093  Acc@1: 62.5000 (66.5072)  Acc@5: 93.7500 (92.1544)  time: 0.7421  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3080/4579]  eta: 0:10:17  Lr: 0.001875  Loss: 0.4594  Acc@1: 62.5000 (66.5064)  Acc@5: 93.7500 (92.1474)  time: 0.7391  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [3090/4579]  eta: 0:10:15  Lr: 0.001875  Loss: -0.5639  Acc@1: 62.5000 (66.5116)  Acc@5: 93.7500 (92.1466)  time: 0.7396  data: 0.0014  max mem: 2500
Train: Epoch[5/5]  [3100/4579]  eta: 0:10:12  Lr: 0.001875  Loss: -0.1302  Acc@1: 68.7500 (66.5088)  Acc@5: 93.7500 (92.1416)  time: 0.7439  data: 0.0013  max mem: 2500
Train: Epoch[5/5]  [3110/4579]  eta: 0:10:10  Lr: 0.001875  Loss: 0.1837  Acc@1: 62.5000 (66.4979)  Acc@5: 93.7500 (92.1408)  time: 0.7471  data: 0.0019  max mem: 2500
Train: Epoch[5/5]  [3120/4579]  eta: 0:10:07  Lr: 0.001875  Loss: 0.0420  Acc@1: 62.5000 (66.4851)  Acc@5: 93.7500 (92.1419)  time: 0.7436  data: 0.0019  max mem: 2500
Train: Epoch[5/5]  [3130/4579]  eta: 0:10:04  Lr: 0.001875  Loss: 0.0944  Acc@1: 62.5000 (66.4784)  Acc@5: 93.7500 (92.1411)  time: 0.7401  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [3140/4579]  eta: 0:10:02  Lr: 0.001875  Loss: -0.3542  Acc@1: 68.7500 (66.4896)  Acc@5: 93.7500 (92.1422)  time: 0.7392  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [3150/4579]  eta: 0:09:59  Lr: 0.001875  Loss: -0.0974  Acc@1: 68.7500 (66.4848)  Acc@5: 87.5000 (92.1354)  time: 0.7379  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [3160/4579]  eta: 0:09:56  Lr: 0.001875  Loss: -0.6235  Acc@1: 68.7500 (66.4801)  Acc@5: 87.5000 (92.1247)  time: 0.7408  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3170/4579]  eta: 0:09:53  Lr: 0.001875  Loss: -0.2036  Acc@1: 62.5000 (66.4696)  Acc@5: 93.7500 (92.1318)  time: 0.7443  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3180/4579]  eta: 0:09:51  Lr: 0.001875  Loss: -0.2827  Acc@1: 62.5000 (66.4767)  Acc@5: 93.7500 (92.1389)  time: 0.7480  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [3190/4579]  eta: 0:09:48  Lr: 0.001875  Loss: -0.3310  Acc@1: 62.5000 (66.4584)  Acc@5: 93.7500 (92.1420)  time: 0.7455  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [3200/4579]  eta: 0:09:45  Lr: 0.001875  Loss: -0.0386  Acc@1: 68.7500 (66.4636)  Acc@5: 93.7500 (92.1450)  time: 0.7431  data: 0.0014  max mem: 2500
Train: Epoch[5/5]  [3210/4579]  eta: 0:09:42  Lr: 0.001875  Loss: -0.6713  Acc@1: 68.7500 (66.4785)  Acc@5: 93.7500 (92.1500)  time: 0.7446  data: 0.0015  max mem: 2500
Train: Epoch[5/5]  [3220/4579]  eta: 0:09:39  Lr: 0.001875  Loss: -0.6892  Acc@1: 68.7500 (66.4875)  Acc@5: 93.7500 (92.1531)  time: 0.7432  data: 0.0014  max mem: 2500
Train: Epoch[5/5]  [3230/4579]  eta: 0:09:36  Lr: 0.001875  Loss: 0.2773  Acc@1: 62.5000 (66.4616)  Acc@5: 87.5000 (92.1464)  time: 0.7389  data: 0.0013  max mem: 2500
Train: Epoch[5/5]  [3240/4579]  eta: 0:09:33  Lr: 0.001875  Loss: -0.1733  Acc@1: 68.7500 (66.4783)  Acc@5: 87.5000 (92.1475)  time: 0.7077  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3250/4579]  eta: 0:09:30  Lr: 0.001875  Loss: -0.3532  Acc@1: 68.7500 (66.4719)  Acc@5: 93.7500 (92.1486)  time: 0.7130  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [3260/4579]  eta: 0:09:27  Lr: 0.001875  Loss: -0.3228  Acc@1: 62.5000 (66.4597)  Acc@5: 93.7500 (92.1420)  time: 0.7463  data: 0.0014  max mem: 2500
Train: Epoch[5/5]  [3270/4579]  eta: 0:09:24  Lr: 0.001875  Loss: -0.4228  Acc@1: 68.7500 (66.4839)  Acc@5: 93.7500 (92.1469)  time: 0.7459  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [3280/4579]  eta: 0:09:21  Lr: 0.001875  Loss: -0.5377  Acc@1: 68.7500 (66.4927)  Acc@5: 93.7500 (92.1423)  time: 0.7471  data: 0.0011  max mem: 2500
Train: Epoch[5/5]  [3290/4579]  eta: 0:09:18  Lr: 0.001875  Loss: -0.3737  Acc@1: 68.7500 (66.5014)  Acc@5: 93.7500 (92.1471)  time: 0.7487  data: 0.0011  max mem: 2500
Train: Epoch[5/5]  [3300/4579]  eta: 0:09:15  Lr: 0.001875  Loss: -0.6360  Acc@1: 75.0000 (66.5272)  Acc@5: 93.7500 (92.1501)  time: 0.7455  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [3310/4579]  eta: 0:09:11  Lr: 0.001875  Loss: -0.2105  Acc@1: 75.0000 (66.5320)  Acc@5: 93.7500 (92.1549)  time: 0.7424  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [3320/4579]  eta: 0:09:08  Lr: 0.001875  Loss: -0.5015  Acc@1: 62.5000 (66.5293)  Acc@5: 93.7500 (92.1616)  time: 0.7426  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3330/4579]  eta: 0:09:05  Lr: 0.001875  Loss: -0.1316  Acc@1: 62.5000 (66.5322)  Acc@5: 93.7500 (92.1608)  time: 0.7373  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3340/4579]  eta: 0:09:02  Lr: 0.001875  Loss: -0.4518  Acc@1: 68.7500 (66.5239)  Acc@5: 93.7500 (92.1655)  time: 0.7328  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3350/4579]  eta: 0:08:59  Lr: 0.001875  Loss: -0.7907  Acc@1: 68.7500 (66.5566)  Acc@5: 93.7500 (92.1721)  time: 0.7409  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3360/4579]  eta: 0:08:55  Lr: 0.001875  Loss: -0.3526  Acc@1: 75.0000 (66.5539)  Acc@5: 93.7500 (92.1768)  time: 0.7457  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [3370/4579]  eta: 0:08:52  Lr: 0.001875  Loss: -0.2927  Acc@1: 62.5000 (66.5270)  Acc@5: 93.7500 (92.1741)  time: 0.7446  data: 0.0016  max mem: 2500
Train: Epoch[5/5]  [3380/4579]  eta: 0:08:49  Lr: 0.001875  Loss: -0.2040  Acc@1: 68.7500 (66.5299)  Acc@5: 93.7500 (92.1695)  time: 0.7487  data: 0.0015  max mem: 2500
Train: Epoch[5/5]  [3390/4579]  eta: 0:08:45  Lr: 0.001875  Loss: -0.5379  Acc@1: 68.7500 (66.5309)  Acc@5: 93.7500 (92.1668)  time: 0.7483  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3400/4579]  eta: 0:08:42  Lr: 0.001875  Loss: -0.3137  Acc@1: 68.7500 (66.5448)  Acc@5: 93.7500 (92.1696)  time: 0.7423  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3410/4579]  eta: 0:08:38  Lr: 0.001875  Loss: 0.0044  Acc@1: 68.7500 (66.5604)  Acc@5: 93.7500 (92.1779)  time: 0.7385  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3420/4579]  eta: 0:08:35  Lr: 0.001875  Loss: 0.3752  Acc@1: 68.7500 (66.5485)  Acc@5: 93.7500 (92.1733)  time: 0.7419  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3430/4579]  eta: 0:08:32  Lr: 0.001875  Loss: 0.0801  Acc@1: 62.5000 (66.5422)  Acc@5: 93.7500 (92.1779)  time: 0.7439  data: 0.0017  max mem: 2500
Train: Epoch[5/5]  [3440/4579]  eta: 0:08:28  Lr: 0.001875  Loss: -0.4713  Acc@1: 62.5000 (66.5323)  Acc@5: 93.7500 (92.1734)  time: 0.7416  data: 0.0018  max mem: 2500
Train: Epoch[5/5]  [3450/4579]  eta: 0:08:25  Lr: 0.001875  Loss: -0.1100  Acc@1: 68.7500 (66.5405)  Acc@5: 93.7500 (92.1780)  time: 0.7380  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [3460/4579]  eta: 0:08:21  Lr: 0.001875  Loss: -0.5770  Acc@1: 68.7500 (66.5270)  Acc@5: 93.7500 (92.1825)  time: 0.7353  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [3470/4579]  eta: 0:08:18  Lr: 0.001875  Loss: 0.3809  Acc@1: 62.5000 (66.5226)  Acc@5: 93.7500 (92.1852)  time: 0.7446  data: 0.0014  max mem: 2500
Train: Epoch[5/5]  [3480/4579]  eta: 0:08:14  Lr: 0.001875  Loss: -0.1782  Acc@1: 68.7500 (66.5308)  Acc@5: 93.7500 (92.1915)  time: 0.7460  data: 0.0013  max mem: 2500
Train: Epoch[5/5]  [3490/4579]  eta: 0:08:10  Lr: 0.001875  Loss: -0.2524  Acc@1: 68.7500 (66.5497)  Acc@5: 93.7500 (92.1960)  time: 0.7412  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3500/4579]  eta: 0:08:07  Lr: 0.001875  Loss: 0.3085  Acc@1: 68.7500 (66.5506)  Acc@5: 93.7500 (92.1969)  time: 0.7419  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3510/4579]  eta: 0:08:03  Lr: 0.001875  Loss: 0.5767  Acc@1: 62.5000 (66.5498)  Acc@5: 87.5000 (92.1853)  time: 0.7393  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [3520/4579]  eta: 0:07:59  Lr: 0.001875  Loss: 0.0949  Acc@1: 62.5000 (66.5578)  Acc@5: 87.5000 (92.1720)  time: 0.7359  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3530/4579]  eta: 0:07:56  Lr: 0.001875  Loss: -0.3580  Acc@1: 62.5000 (66.5622)  Acc@5: 93.7500 (92.1694)  time: 0.7362  data: 0.0010  max mem: 2500
Train: Epoch[5/5]  [3540/4579]  eta: 0:07:52  Lr: 0.001875  Loss: -0.6628  Acc@1: 62.5000 (66.5525)  Acc@5: 93.7500 (92.1562)  time: 0.7342  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [3550/4579]  eta: 0:07:48  Lr: 0.001875  Loss: 0.0638  Acc@1: 62.5000 (66.5323)  Acc@5: 87.5000 (92.1536)  time: 0.7413  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [3560/4579]  eta: 0:07:44  Lr: 0.001875  Loss: -0.0020  Acc@1: 62.5000 (66.5227)  Acc@5: 87.5000 (92.1406)  time: 0.7210  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [3570/4579]  eta: 0:07:41  Lr: 0.001875  Loss: -0.2799  Acc@1: 62.5000 (66.5360)  Acc@5: 93.7500 (92.1416)  time: 0.6931  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [3580/4579]  eta: 0:07:37  Lr: 0.001875  Loss: -0.4960  Acc@1: 62.5000 (66.5317)  Acc@5: 93.7500 (92.1478)  time: 0.7121  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [3590/4579]  eta: 0:07:33  Lr: 0.001875  Loss: -0.2966  Acc@1: 62.5000 (66.5292)  Acc@5: 93.7500 (92.1418)  time: 0.6802  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [3600/4579]  eta: 0:07:28  Lr: 0.001875  Loss: -0.1901  Acc@1: 68.7500 (66.5284)  Acc@5: 93.7500 (92.1428)  time: 0.4892  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3610/4579]  eta: 0:07:23  Lr: 0.001875  Loss: -0.2769  Acc@1: 68.7500 (66.5276)  Acc@5: 93.7500 (92.1455)  time: 0.3470  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3620/4579]  eta: 0:07:18  Lr: 0.001875  Loss: -0.4869  Acc@1: 68.7500 (66.5286)  Acc@5: 93.7500 (92.1551)  time: 0.3470  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3630/4579]  eta: 0:07:13  Lr: 0.001875  Loss: -0.1136  Acc@1: 68.7500 (66.5399)  Acc@5: 93.7500 (92.1561)  time: 0.3454  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [3640/4579]  eta: 0:07:08  Lr: 0.001875  Loss: -0.7817  Acc@1: 62.5000 (66.5339)  Acc@5: 93.7500 (92.1622)  time: 0.3480  data: 0.0011  max mem: 2500
Train: Epoch[5/5]  [3650/4579]  eta: 0:07:04  Lr: 0.001875  Loss: 0.0657  Acc@1: 62.5000 (66.5246)  Acc@5: 93.7500 (92.1545)  time: 0.3536  data: 0.0032  max mem: 2500
Train: Epoch[5/5]  [3660/4579]  eta: 0:06:59  Lr: 0.001875  Loss: -0.1884  Acc@1: 62.5000 (66.5238)  Acc@5: 93.7500 (92.1572)  time: 0.3527  data: 0.0025  max mem: 2500
Train: Epoch[5/5]  [3670/4579]  eta: 0:06:54  Lr: 0.001875  Loss: -0.3950  Acc@1: 62.5000 (66.5197)  Acc@5: 93.7500 (92.1547)  time: 0.3492  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [3680/4579]  eta: 0:06:49  Lr: 0.001875  Loss: -0.4065  Acc@1: 62.5000 (66.5240)  Acc@5: 93.7500 (92.1574)  time: 0.3491  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [3690/4579]  eta: 0:06:44  Lr: 0.001875  Loss: -0.2888  Acc@1: 68.7500 (66.5301)  Acc@5: 93.7500 (92.1600)  time: 0.3497  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [3700/4579]  eta: 0:06:39  Lr: 0.001875  Loss: -0.0365  Acc@1: 75.0000 (66.5530)  Acc@5: 93.7500 (92.1609)  time: 0.3564  data: 0.0013  max mem: 2500
Train: Epoch[5/5]  [3710/4579]  eta: 0:06:35  Lr: 0.001875  Loss: -0.4429  Acc@1: 68.7500 (66.5521)  Acc@5: 93.7500 (92.1601)  time: 0.3569  data: 0.0013  max mem: 2500
Train: Epoch[5/5]  [3720/4579]  eta: 0:06:30  Lr: 0.001875  Loss: -0.0411  Acc@1: 68.7500 (66.5547)  Acc@5: 93.7500 (92.1644)  time: 0.3500  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [3730/4579]  eta: 0:06:25  Lr: 0.001875  Loss: -0.2508  Acc@1: 62.5000 (66.5572)  Acc@5: 93.7500 (92.1653)  time: 0.3491  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [3740/4579]  eta: 0:06:20  Lr: 0.001875  Loss: 0.1887  Acc@1: 68.7500 (66.5614)  Acc@5: 93.7500 (92.1712)  time: 0.3491  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3750/4579]  eta: 0:06:16  Lr: 0.001875  Loss: -0.1737  Acc@1: 68.7500 (66.5689)  Acc@5: 93.7500 (92.1721)  time: 0.3492  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [3760/4579]  eta: 0:06:11  Lr: 0.001875  Loss: 0.1671  Acc@1: 68.7500 (66.5614)  Acc@5: 93.7500 (92.1647)  time: 0.3478  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [3770/4579]  eta: 0:06:06  Lr: 0.001875  Loss: -0.5723  Acc@1: 68.7500 (66.5705)  Acc@5: 93.7500 (92.1689)  time: 0.3462  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [3780/4579]  eta: 0:06:01  Lr: 0.001875  Loss: -0.3468  Acc@1: 68.7500 (66.5631)  Acc@5: 93.7500 (92.1714)  time: 0.3493  data: 0.0012  max mem: 2500
Train: Epoch[5/5]  [3790/4579]  eta: 0:05:57  Lr: 0.001875  Loss: -0.4149  Acc@1: 62.5000 (66.5507)  Acc@5: 93.7500 (92.1723)  time: 0.3503  data: 0.0012  max mem: 2500
Train: Epoch[5/5]  [3800/4579]  eta: 0:05:52  Lr: 0.001875  Loss: -0.7830  Acc@1: 62.5000 (66.5598)  Acc@5: 93.7500 (92.1731)  time: 0.3467  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [3810/4579]  eta: 0:05:47  Lr: 0.001875  Loss: -0.1369  Acc@1: 68.7500 (66.5557)  Acc@5: 93.7500 (92.1756)  time: 0.3447  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [3820/4579]  eta: 0:05:42  Lr: 0.001875  Loss: -0.2587  Acc@1: 68.7500 (66.5582)  Acc@5: 93.7500 (92.1683)  time: 0.3473  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [3830/4579]  eta: 0:05:38  Lr: 0.001875  Loss: -0.1092  Acc@1: 68.7500 (66.5623)  Acc@5: 87.5000 (92.1659)  time: 0.3512  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3840/4579]  eta: 0:05:33  Lr: 0.001875  Loss: -0.2125  Acc@1: 68.7500 (66.5647)  Acc@5: 93.7500 (92.1700)  time: 0.3514  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [3850/4579]  eta: 0:05:28  Lr: 0.001875  Loss: -0.3527  Acc@1: 68.7500 (66.5590)  Acc@5: 93.7500 (92.1709)  time: 0.3484  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [3860/4579]  eta: 0:05:23  Lr: 0.001875  Loss: -0.3351  Acc@1: 68.7500 (66.5793)  Acc@5: 93.7500 (92.1701)  time: 0.3471  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3870/4579]  eta: 0:05:19  Lr: 0.001875  Loss: -0.4921  Acc@1: 75.0000 (66.5945)  Acc@5: 93.7500 (92.1742)  time: 0.3489  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [3880/4579]  eta: 0:05:14  Lr: 0.001875  Loss: -0.5489  Acc@1: 68.7500 (66.5921)  Acc@5: 93.7500 (92.1815)  time: 0.3485  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [3890/4579]  eta: 0:05:09  Lr: 0.001875  Loss: -0.5566  Acc@1: 68.7500 (66.6040)  Acc@5: 93.7500 (92.1887)  time: 0.3471  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3900/4579]  eta: 0:05:05  Lr: 0.001875  Loss: -0.4487  Acc@1: 75.0000 (66.6159)  Acc@5: 93.7500 (92.1911)  time: 0.3499  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [3910/4579]  eta: 0:05:00  Lr: 0.001875  Loss: -0.1173  Acc@1: 68.7500 (66.6022)  Acc@5: 93.7500 (92.1903)  time: 0.3545  data: 0.0011  max mem: 2500
Train: Epoch[5/5]  [3920/4579]  eta: 0:04:55  Lr: 0.001875  Loss: -0.2649  Acc@1: 62.5000 (66.6077)  Acc@5: 93.7500 (92.1927)  time: 0.3520  data: 0.0011  max mem: 2500
Train: Epoch[5/5]  [3930/4579]  eta: 0:04:51  Lr: 0.001875  Loss: 0.0340  Acc@1: 68.7500 (66.6274)  Acc@5: 93.7500 (92.1951)  time: 0.3487  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [3940/4579]  eta: 0:04:46  Lr: 0.001875  Loss: -0.1031  Acc@1: 68.7500 (66.6217)  Acc@5: 93.7500 (92.1895)  time: 0.3483  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [3950/4579]  eta: 0:04:41  Lr: 0.001875  Loss: -0.7894  Acc@1: 68.7500 (66.6366)  Acc@5: 87.5000 (92.1824)  time: 0.3474  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3960/4579]  eta: 0:04:37  Lr: 0.001875  Loss: -0.3310  Acc@1: 68.7500 (66.6262)  Acc@5: 87.5000 (92.1753)  time: 0.3491  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3970/4579]  eta: 0:04:32  Lr: 0.001875  Loss: -0.6867  Acc@1: 68.7500 (66.6331)  Acc@5: 93.7500 (92.1808)  time: 0.3481  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3980/4579]  eta: 0:04:28  Lr: 0.001875  Loss: 0.1478  Acc@1: 75.0000 (66.6400)  Acc@5: 93.7500 (92.1769)  time: 0.3474  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3990/4579]  eta: 0:04:23  Lr: 0.001875  Loss: 0.2006  Acc@1: 62.5000 (66.6218)  Acc@5: 93.7500 (92.1730)  time: 0.3466  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [4000/4579]  eta: 0:04:18  Lr: 0.001875  Loss: -0.4766  Acc@1: 62.5000 (66.6193)  Acc@5: 87.5000 (92.1676)  time: 0.3471  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [4010/4579]  eta: 0:04:14  Lr: 0.001875  Loss: -0.3356  Acc@1: 68.7500 (66.6355)  Acc@5: 87.5000 (92.1684)  time: 0.3471  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [4020/4579]  eta: 0:04:09  Lr: 0.001875  Loss: -0.1694  Acc@1: 75.0000 (66.6485)  Acc@5: 93.7500 (92.1630)  time: 0.3448  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [4030/4579]  eta: 0:04:05  Lr: 0.001875  Loss: 0.1308  Acc@1: 62.5000 (66.6398)  Acc@5: 93.7500 (92.1623)  time: 0.3471  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [4040/4579]  eta: 0:04:00  Lr: 0.001875  Loss: -0.4127  Acc@1: 62.5000 (66.6311)  Acc@5: 87.5000 (92.1600)  time: 0.3538  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [4050/4579]  eta: 0:03:55  Lr: 0.001875  Loss: -0.7957  Acc@1: 68.7500 (66.6456)  Acc@5: 93.7500 (92.1624)  time: 0.3544  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [4060/4579]  eta: 0:03:51  Lr: 0.001875  Loss: -0.0336  Acc@1: 68.7500 (66.6446)  Acc@5: 93.7500 (92.1586)  time: 0.3497  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [4070/4579]  eta: 0:03:46  Lr: 0.001875  Loss: -0.5701  Acc@1: 68.7500 (66.6498)  Acc@5: 93.7500 (92.1626)  time: 0.3498  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [4080/4579]  eta: 0:03:42  Lr: 0.001875  Loss: -0.5643  Acc@1: 75.0000 (66.6672)  Acc@5: 100.0000 (92.1741)  time: 0.3581  data: 0.0018  max mem: 2500
Train: Epoch[5/5]  [4090/4579]  eta: 0:03:37  Lr: 0.001875  Loss: -0.2183  Acc@1: 68.7500 (66.6662)  Acc@5: 93.7500 (92.1627)  time: 0.3617  data: 0.0026  max mem: 2500
Train: Epoch[5/5]  [4100/4579]  eta: 0:03:33  Lr: 0.001875  Loss: 0.1107  Acc@1: 62.5000 (66.6712)  Acc@5: 87.5000 (92.1559)  time: 0.3522  data: 0.0013  max mem: 2500
Train: Epoch[5/5]  [4110/4579]  eta: 0:03:28  Lr: 0.001875  Loss: -0.1062  Acc@1: 62.5000 (66.6778)  Acc@5: 87.5000 (92.1582)  time: 0.3484  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [4120/4579]  eta: 0:03:23  Lr: 0.001875  Loss: -0.5163  Acc@1: 68.7500 (66.6828)  Acc@5: 87.5000 (92.1560)  time: 0.3510  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [4130/4579]  eta: 0:03:19  Lr: 0.001875  Loss: -0.2919  Acc@1: 68.7500 (66.6818)  Acc@5: 93.7500 (92.1599)  time: 0.3583  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [4140/4579]  eta: 0:03:14  Lr: 0.001875  Loss: -0.6186  Acc@1: 68.7500 (66.6974)  Acc@5: 93.7500 (92.1652)  time: 0.3560  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [4150/4579]  eta: 0:03:10  Lr: 0.001875  Loss: 0.0744  Acc@1: 68.7500 (66.7023)  Acc@5: 93.7500 (92.1660)  time: 0.3469  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [4160/4579]  eta: 0:03:05  Lr: 0.001875  Loss: -0.3042  Acc@1: 62.5000 (66.7027)  Acc@5: 93.7500 (92.1668)  time: 0.3474  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [4170/4579]  eta: 0:03:01  Lr: 0.001875  Loss: 0.0821  Acc@1: 62.5000 (66.6911)  Acc@5: 93.7500 (92.1646)  time: 0.3486  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [4180/4579]  eta: 0:02:56  Lr: 0.001875  Loss: 0.6871  Acc@1: 62.5000 (66.6692)  Acc@5: 87.5000 (92.1535)  time: 0.3488  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [4190/4579]  eta: 0:02:52  Lr: 0.001875  Loss: 0.1890  Acc@1: 62.5000 (66.6726)  Acc@5: 87.5000 (92.1469)  time: 0.3477  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [4200/4579]  eta: 0:02:47  Lr: 0.001875  Loss: -0.5766  Acc@1: 68.7500 (66.6761)  Acc@5: 93.7500 (92.1507)  time: 0.3540  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [4210/4579]  eta: 0:02:43  Lr: 0.001875  Loss: -0.4342  Acc@1: 68.7500 (66.6736)  Acc@5: 93.7500 (92.1530)  time: 0.3576  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [4220/4579]  eta: 0:02:38  Lr: 0.001875  Loss: -0.0736  Acc@1: 62.5000 (66.6711)  Acc@5: 93.7500 (92.1479)  time: 0.3506  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [4230/4579]  eta: 0:02:34  Lr: 0.001875  Loss: -0.1326  Acc@1: 68.7500 (66.6908)  Acc@5: 93.7500 (92.1546)  time: 0.3512  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [4240/4579]  eta: 0:02:30  Lr: 0.001875  Loss: -0.2142  Acc@1: 68.7500 (66.6868)  Acc@5: 93.7500 (92.1613)  time: 0.5323  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [4250/4579]  eta: 0:02:25  Lr: 0.001875  Loss: -0.3472  Acc@1: 68.7500 (66.6887)  Acc@5: 93.7500 (92.1695)  time: 0.7299  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [4260/4579]  eta: 0:02:21  Lr: 0.001875  Loss: -0.8203  Acc@1: 68.7500 (66.7053)  Acc@5: 93.7500 (92.1761)  time: 0.6962  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [4270/4579]  eta: 0:02:17  Lr: 0.001875  Loss: -0.6501  Acc@1: 68.7500 (66.7057)  Acc@5: 93.7500 (92.1769)  time: 0.4942  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [4280/4579]  eta: 0:02:12  Lr: 0.001875  Loss: 0.6120  Acc@1: 62.5000 (66.7061)  Acc@5: 93.7500 (92.1689)  time: 0.3501  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [4290/4579]  eta: 0:02:08  Lr: 0.001875  Loss: -0.2996  Acc@1: 68.7500 (66.7108)  Acc@5: 93.7500 (92.1711)  time: 0.3544  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [4300/4579]  eta: 0:02:03  Lr: 0.001875  Loss: -0.6429  Acc@1: 62.5000 (66.7011)  Acc@5: 93.7500 (92.1704)  time: 0.3507  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [4310/4579]  eta: 0:01:59  Lr: 0.001875  Loss: -0.1862  Acc@1: 62.5000 (66.6855)  Acc@5: 87.5000 (92.1610)  time: 0.3476  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [4320/4579]  eta: 0:01:54  Lr: 0.001875  Loss: -0.1506  Acc@1: 62.5000 (66.6773)  Acc@5: 87.5000 (92.1604)  time: 0.3493  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [4330/4579]  eta: 0:01:50  Lr: 0.001875  Loss: -0.6296  Acc@1: 68.7500 (66.6922)  Acc@5: 87.5000 (92.1583)  time: 0.3515  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [4340/4579]  eta: 0:01:45  Lr: 0.001875  Loss: -0.1674  Acc@1: 68.7500 (66.6883)  Acc@5: 87.5000 (92.1562)  time: 0.3503  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [4350/4579]  eta: 0:01:41  Lr: 0.001875  Loss: -0.8636  Acc@1: 68.7500 (66.7059)  Acc@5: 93.7500 (92.1555)  time: 0.3472  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [4360/4579]  eta: 0:01:36  Lr: 0.001875  Loss: -0.6788  Acc@1: 68.7500 (66.7106)  Acc@5: 93.7500 (92.1520)  time: 0.3464  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [4370/4579]  eta: 0:01:32  Lr: 0.001875  Loss: -0.5064  Acc@1: 68.7500 (66.7167)  Acc@5: 93.7500 (92.1585)  time: 0.3478  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [4380/4579]  eta: 0:01:27  Lr: 0.001875  Loss: -0.3819  Acc@1: 75.0000 (66.7299)  Acc@5: 100.0000 (92.1636)  time: 0.3484  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [4390/4579]  eta: 0:01:23  Lr: 0.001875  Loss: -0.2014  Acc@1: 62.5000 (66.7246)  Acc@5: 93.7500 (92.1686)  time: 0.3552  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [4400/4579]  eta: 0:01:18  Lr: 0.001875  Loss: -0.0079  Acc@1: 62.5000 (66.7107)  Acc@5: 93.7500 (92.1609)  time: 0.3568  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [4410/4579]  eta: 0:01:14  Lr: 0.001875  Loss: -0.2505  Acc@1: 56.2500 (66.6969)  Acc@5: 87.5000 (92.1560)  time: 0.3526  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [4420/4579]  eta: 0:01:10  Lr: 0.001875  Loss: 0.1104  Acc@1: 68.7500 (66.7058)  Acc@5: 93.7500 (92.1596)  time: 0.3588  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [4430/4579]  eta: 0:01:05  Lr: 0.001875  Loss: 0.0262  Acc@1: 68.7500 (66.7146)  Acc@5: 93.7500 (92.1618)  time: 0.5320  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [4440/4579]  eta: 0:01:01  Lr: 0.001875  Loss: 0.3493  Acc@1: 68.7500 (66.7094)  Acc@5: 93.7500 (92.1639)  time: 0.5260  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [4450/4579]  eta: 0:00:56  Lr: 0.001875  Loss: -0.0847  Acc@1: 68.7500 (66.7196)  Acc@5: 93.7500 (92.1577)  time: 0.3534  data: 0.0021  max mem: 2500
Train: Epoch[5/5]  [4460/4579]  eta: 0:00:52  Lr: 0.001875  Loss: -0.5141  Acc@1: 68.7500 (66.7297)  Acc@5: 93.7500 (92.1598)  time: 0.3528  data: 0.0020  max mem: 2500
Train: Epoch[5/5]  [4470/4579]  eta: 0:00:47  Lr: 0.001875  Loss: -0.2683  Acc@1: 68.7500 (66.7370)  Acc@5: 93.7500 (92.1550)  time: 0.3510  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [4480/4579]  eta: 0:00:43  Lr: 0.001875  Loss: -0.3823  Acc@1: 68.7500 (66.7527)  Acc@5: 93.7500 (92.1544)  time: 0.3533  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [4490/4579]  eta: 0:00:39  Lr: 0.001875  Loss: -0.3955  Acc@1: 68.7500 (66.7516)  Acc@5: 93.7500 (92.1524)  time: 0.3548  data: 0.0016  max mem: 2500
Train: Epoch[5/5]  [4500/4579]  eta: 0:00:34  Lr: 0.001875  Loss: -0.5024  Acc@1: 68.7500 (66.7504)  Acc@5: 93.7500 (92.1517)  time: 0.3537  data: 0.0014  max mem: 2500
Train: Epoch[5/5]  [4510/4579]  eta: 0:00:30  Lr: 0.001875  Loss: -0.6237  Acc@1: 68.7500 (66.7466)  Acc@5: 93.7500 (92.1594)  time: 0.3493  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [4520/4579]  eta: 0:00:25  Lr: 0.001875  Loss: -0.0884  Acc@1: 68.7500 (66.7551)  Acc@5: 93.7500 (92.1616)  time: 0.3473  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [4530/4579]  eta: 0:00:21  Lr: 0.001875  Loss: -0.7662  Acc@1: 62.5000 (66.7485)  Acc@5: 93.7500 (92.1540)  time: 0.3490  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [4540/4579]  eta: 0:00:17  Lr: 0.001875  Loss: -0.3707  Acc@1: 62.5000 (66.7392)  Acc@5: 87.5000 (92.1493)  time: 0.3502  data: 0.0010  max mem: 2500
Train: Epoch[5/5]  [4550/4579]  eta: 0:00:12  Lr: 0.001875  Loss: 1.0459  Acc@1: 62.5000 (66.7326)  Acc@5: 87.5000 (92.1446)  time: 0.3485  data: 0.0010  max mem: 2500
Train: Epoch[5/5]  [4560/4579]  eta: 0:00:08  Lr: 0.001875  Loss: -0.6605  Acc@1: 62.5000 (66.7329)  Acc@5: 93.7500 (92.1440)  time: 0.3560  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [4570/4579]  eta: 0:00:03  Lr: 0.001875  Loss: -0.2430  Acc@1: 68.7500 (66.7373)  Acc@5: 93.7500 (92.1420)  time: 0.3579  data: 0.0013  max mem: 2500
Train: Epoch[5/5]  [4578/4579]  eta: 0:00:00  Lr: 0.001875  Loss: -0.2660  Acc@1: 68.7500 (66.7376)  Acc@5: 93.7500 (92.1441)  time: 0.3450  data: 0.0013  max mem: 2500
Train: Epoch[5/5] Total time: 0:33:26 (0.4382 s / it)
{0: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 1: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 2: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 3: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 4: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 5: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 6: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 7: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 8: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 9: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 10: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 11: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 12: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 13: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 14: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 15: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 16: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 17: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 18: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 19: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}}
Averaged stats: Lr: 0.001875  Loss: -0.2660  Acc@1: 68.7500 (66.7376)  Acc@5: 93.7500 (92.1441)
Test: [Task 1]  [   0/1627]  eta: 0:15:07  Loss: 1.0983 (1.0983)  Acc@1: 75.0000 (75.0000)  Acc@5: 93.7500 (93.7500)  time: 0.5581  data: 0.3457  max mem: 2500
Test: [Task 1]  [  10/1627]  eta: 0:06:58  Loss: 1.0426 (0.9326)  Acc@1: 81.2500 (82.9545)  Acc@5: 100.0000 (98.2955)  time: 0.2586  data: 0.0336  max mem: 2500
Test: [Task 1]  [  20/1627]  eta: 0:08:50  Loss: 0.8975 (0.9044)  Acc@1: 81.2500 (83.6310)  Acc@5: 100.0000 (97.9167)  time: 0.3187  data: 0.0013  max mem: 2500
Test: [Task 1]  [  30/1627]  eta: 0:09:57  Loss: 0.9190 (0.9138)  Acc@1: 81.2500 (83.0645)  Acc@5: 100.0000 (97.9839)  time: 0.4379  data: 0.0003  max mem: 2500
Test: [Task 1]  [  40/1627]  eta: 0:10:29  Loss: 0.9708 (0.9198)  Acc@1: 81.2500 (82.4695)  Acc@5: 100.0000 (97.5610)  time: 0.4664  data: 0.0015  max mem: 2500
Test: [Task 1]  [  50/1627]  eta: 0:10:47  Loss: 0.8527 (0.8963)  Acc@1: 87.5000 (83.7010)  Acc@5: 100.0000 (97.6716)  time: 0.4663  data: 0.0015  max mem: 2500
Test: [Task 1]  [  60/1627]  eta: 0:10:58  Loss: 0.8852 (0.9061)  Acc@1: 87.5000 (83.8115)  Acc@5: 100.0000 (97.6434)  time: 0.4681  data: 0.0004  max mem: 2500
Test: [Task 1]  [  70/1627]  eta: 0:11:05  Loss: 0.8595 (0.9031)  Acc@1: 81.2500 (84.0669)  Acc@5: 100.0000 (97.6232)  time: 0.4701  data: 0.0008  max mem: 2500
Test: [Task 1]  [  80/1627]  eta: 0:11:08  Loss: 0.6767 (0.8825)  Acc@1: 87.5000 (84.5679)  Acc@5: 100.0000 (97.9167)  time: 0.4685  data: 0.0020  max mem: 2500
Test: [Task 1]  [  90/1627]  eta: 0:10:55  Loss: 0.8458 (0.8964)  Acc@1: 87.5000 (84.2033)  Acc@5: 100.0000 (97.9396)  time: 0.4252  data: 0.0017  max mem: 2500
Test: [Task 1]  [ 100/1627]  eta: 0:10:19  Loss: 0.9477 (0.9208)  Acc@1: 81.2500 (83.7871)  Acc@5: 100.0000 (97.6485)  time: 0.2998  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 110/1627]  eta: 0:09:49  Loss: 0.9235 (0.9150)  Acc@1: 81.2500 (83.8401)  Acc@5: 100.0000 (97.7477)  time: 0.2164  data: 0.0007  max mem: 2500
Test: [Task 1]  [ 120/1627]  eta: 0:09:24  Loss: 0.8152 (0.9122)  Acc@1: 87.5000 (84.1426)  Acc@5: 100.0000 (97.6240)  time: 0.2162  data: 0.0007  max mem: 2500
Test: [Task 1]  [ 130/1627]  eta: 0:09:02  Loss: 0.9370 (0.9192)  Acc@1: 87.5000 (84.1603)  Acc@5: 100.0000 (97.5668)  time: 0.2162  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 140/1627]  eta: 0:08:43  Loss: 0.8007 (0.9157)  Acc@1: 81.2500 (84.1755)  Acc@5: 100.0000 (97.5177)  time: 0.2169  data: 0.0010  max mem: 2500
Test: [Task 1]  [ 150/1627]  eta: 0:08:26  Loss: 0.7415 (0.9016)  Acc@1: 81.2500 (84.3957)  Acc@5: 100.0000 (97.5579)  time: 0.2159  data: 0.0010  max mem: 2500
Test: [Task 1]  [ 160/1627]  eta: 0:08:11  Loss: 0.7730 (0.8968)  Acc@1: 87.5000 (84.4720)  Acc@5: 100.0000 (97.5543)  time: 0.2157  data: 0.0008  max mem: 2500
Test: [Task 1]  [ 170/1627]  eta: 0:07:58  Loss: 0.8510 (0.8914)  Acc@1: 87.5000 (84.5395)  Acc@5: 100.0000 (97.5512)  time: 0.2154  data: 0.0008  max mem: 2500
Test: [Task 1]  [ 180/1627]  eta: 0:07:45  Loss: 0.9137 (0.8977)  Acc@1: 81.2500 (84.3577)  Acc@5: 100.0000 (97.5138)  time: 0.2151  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 190/1627]  eta: 0:07:34  Loss: 0.9142 (0.8959)  Acc@1: 81.2500 (84.3914)  Acc@5: 100.0000 (97.4804)  time: 0.2155  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 200/1627]  eta: 0:07:24  Loss: 0.9201 (0.8988)  Acc@1: 81.2500 (84.2973)  Acc@5: 100.0000 (97.5435)  time: 0.2153  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 210/1627]  eta: 0:07:14  Loss: 0.8146 (0.8977)  Acc@1: 81.2500 (84.4194)  Acc@5: 100.0000 (97.5711)  time: 0.2156  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 220/1627]  eta: 0:07:05  Loss: 0.8127 (0.9041)  Acc@1: 87.5000 (84.1346)  Acc@5: 100.0000 (97.5962)  time: 0.2164  data: 0.0005  max mem: 2500
Test: [Task 1]  [ 230/1627]  eta: 0:06:57  Loss: 0.8635 (0.9013)  Acc@1: 87.5000 (84.2262)  Acc@5: 100.0000 (97.6190)  time: 0.2150  data: 0.0005  max mem: 2500
Test: [Task 1]  [ 240/1627]  eta: 0:06:49  Loss: 0.8140 (0.8975)  Acc@1: 87.5000 (84.3880)  Acc@5: 100.0000 (97.6400)  time: 0.2137  data: 0.0002  max mem: 2500
Test: [Task 1]  [ 250/1627]  eta: 0:06:42  Loss: 0.8140 (0.9015)  Acc@1: 87.5000 (84.4622)  Acc@5: 100.0000 (97.5349)  time: 0.2137  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 260/1627]  eta: 0:06:35  Loss: 0.8497 (0.9008)  Acc@1: 87.5000 (84.5785)  Acc@5: 100.0000 (97.5335)  time: 0.2147  data: 0.0005  max mem: 2500
Test: [Task 1]  [ 270/1627]  eta: 0:06:28  Loss: 0.7225 (0.8947)  Acc@1: 87.5000 (84.6633)  Acc@5: 100.0000 (97.6015)  time: 0.2155  data: 0.0006  max mem: 2500
Test: [Task 1]  [ 280/1627]  eta: 0:06:22  Loss: 0.7225 (0.8963)  Acc@1: 87.5000 (84.5863)  Acc@5: 100.0000 (97.5311)  time: 0.2150  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 290/1627]  eta: 0:06:16  Loss: 0.9203 (0.8950)  Acc@1: 87.5000 (84.7509)  Acc@5: 93.7500 (97.5086)  time: 0.2155  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 300/1627]  eta: 0:06:10  Loss: 0.7468 (0.8931)  Acc@1: 87.5000 (84.8422)  Acc@5: 100.0000 (97.5083)  time: 0.2161  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 310/1627]  eta: 0:06:05  Loss: 0.7427 (0.8934)  Acc@1: 87.5000 (84.8071)  Acc@5: 100.0000 (97.5080)  time: 0.2163  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 320/1627]  eta: 0:06:00  Loss: 0.8808 (0.8930)  Acc@1: 87.5000 (84.9688)  Acc@5: 100.0000 (97.5078)  time: 0.2175  data: 0.0005  max mem: 2500
Test: [Task 1]  [ 330/1627]  eta: 0:05:55  Loss: 0.7450 (0.8928)  Acc@1: 87.5000 (85.0264)  Acc@5: 100.0000 (97.5264)  time: 0.2178  data: 0.0005  max mem: 2500
Test: [Task 1]  [ 340/1627]  eta: 0:05:50  Loss: 0.7204 (0.8927)  Acc@1: 87.5000 (85.0990)  Acc@5: 100.0000 (97.5440)  time: 0.2180  data: 0.0005  max mem: 2500
Test: [Task 1]  [ 350/1627]  eta: 0:05:45  Loss: 0.8585 (0.8939)  Acc@1: 81.2500 (85.0605)  Acc@5: 100.0000 (97.4715)  time: 0.2191  data: 0.0012  max mem: 2500
Test: [Task 1]  [ 360/1627]  eta: 0:05:41  Loss: 0.8456 (0.8919)  Acc@1: 81.2500 (85.0242)  Acc@5: 100.0000 (97.5069)  time: 0.2209  data: 0.0014  max mem: 2500
Test: [Task 1]  [ 370/1627]  eta: 0:05:36  Loss: 0.8091 (0.8909)  Acc@1: 87.5000 (85.0910)  Acc@5: 100.0000 (97.5404)  time: 0.2198  data: 0.0009  max mem: 2500
Test: [Task 1]  [ 380/1627]  eta: 0:05:32  Loss: 0.7643 (0.8888)  Acc@1: 87.5000 (85.0886)  Acc@5: 100.0000 (97.5722)  time: 0.2173  data: 0.0006  max mem: 2500
Test: [Task 1]  [ 390/1627]  eta: 0:05:28  Loss: 0.7967 (0.8906)  Acc@1: 87.5000 (85.0064)  Acc@5: 100.0000 (97.5863)  time: 0.2176  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 400/1627]  eta: 0:05:24  Loss: 0.8131 (0.8912)  Acc@1: 81.2500 (85.0374)  Acc@5: 100.0000 (97.5842)  time: 0.2175  data: 0.0005  max mem: 2500
Test: [Task 1]  [ 410/1627]  eta: 0:05:20  Loss: 0.7601 (0.8913)  Acc@1: 87.5000 (85.0517)  Acc@5: 100.0000 (97.5517)  time: 0.2172  data: 0.0005  max mem: 2500
Test: [Task 1]  [ 420/1627]  eta: 0:05:16  Loss: 0.7198 (0.8901)  Acc@1: 87.5000 (85.0950)  Acc@5: 100.0000 (97.5653)  time: 0.2166  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 430/1627]  eta: 0:05:12  Loss: 0.7145 (0.8886)  Acc@1: 87.5000 (85.0783)  Acc@5: 100.0000 (97.5928)  time: 0.2163  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 440/1627]  eta: 0:05:08  Loss: 0.8378 (0.8872)  Acc@1: 87.5000 (85.0482)  Acc@5: 100.0000 (97.6332)  time: 0.2182  data: 0.0013  max mem: 2500
Test: [Task 1]  [ 450/1627]  eta: 0:05:04  Loss: 0.8754 (0.8894)  Acc@1: 81.2500 (85.0055)  Acc@5: 100.0000 (97.6025)  time: 0.2174  data: 0.0013  max mem: 2500
Test: [Task 1]  [ 460/1627]  eta: 0:05:01  Loss: 0.8754 (0.8883)  Acc@1: 81.2500 (84.9512)  Acc@5: 100.0000 (97.6274)  time: 0.2157  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 470/1627]  eta: 0:04:57  Loss: 0.6584 (0.8849)  Acc@1: 87.5000 (85.0318)  Acc@5: 100.0000 (97.6247)  time: 0.2159  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 480/1627]  eta: 0:04:53  Loss: 0.8925 (0.8893)  Acc@1: 81.2500 (84.8753)  Acc@5: 100.0000 (97.6351)  time: 0.2158  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 490/1627]  eta: 0:04:50  Loss: 0.9177 (0.8896)  Acc@1: 81.2500 (84.8523)  Acc@5: 100.0000 (97.6578)  time: 0.2163  data: 0.0006  max mem: 2500
Test: [Task 1]  [ 500/1627]  eta: 0:04:46  Loss: 0.8650 (0.8914)  Acc@1: 81.2500 (84.8179)  Acc@5: 100.0000 (97.6173)  time: 0.2160  data: 0.0006  max mem: 2500
Test: [Task 1]  [ 510/1627]  eta: 0:04:43  Loss: 1.0153 (0.8968)  Acc@1: 81.2500 (84.7480)  Acc@5: 93.7500 (97.5783)  time: 0.2172  data: 0.0012  max mem: 2500
Test: [Task 1]  [ 520/1627]  eta: 0:04:40  Loss: 1.0082 (0.9043)  Acc@1: 81.2500 (84.7049)  Acc@5: 100.0000 (97.5288)  time: 0.2172  data: 0.0012  max mem: 2500
Test: [Task 1]  [ 530/1627]  eta: 0:04:36  Loss: 0.8130 (0.9007)  Acc@1: 87.5000 (84.8164)  Acc@5: 100.0000 (97.5636)  time: 0.2153  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 540/1627]  eta: 0:04:33  Loss: 0.8045 (0.9008)  Acc@1: 87.5000 (84.8660)  Acc@5: 100.0000 (97.5508)  time: 0.2149  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 550/1627]  eta: 0:04:30  Loss: 0.9729 (0.9026)  Acc@1: 87.5000 (84.8457)  Acc@5: 100.0000 (97.5613)  time: 0.2143  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 560/1627]  eta: 0:04:27  Loss: 1.0645 (0.9052)  Acc@1: 81.2500 (84.7371)  Acc@5: 100.0000 (97.5713)  time: 0.2157  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 570/1627]  eta: 0:04:24  Loss: 0.8963 (0.9025)  Acc@1: 81.2500 (84.7526)  Acc@5: 100.0000 (97.5372)  time: 0.2177  data: 0.0013  max mem: 2500
Test: [Task 1]  [ 580/1627]  eta: 0:04:21  Loss: 0.8620 (0.9032)  Acc@1: 87.5000 (84.7569)  Acc@5: 100.0000 (97.5688)  time: 0.2205  data: 0.0023  max mem: 2500
Test: [Task 1]  [ 590/1627]  eta: 0:04:18  Loss: 0.8620 (0.9020)  Acc@1: 87.5000 (84.8245)  Acc@5: 100.0000 (97.5783)  time: 0.2203  data: 0.0015  max mem: 2500
Test: [Task 1]  [ 600/1627]  eta: 0:04:15  Loss: 0.7932 (0.9033)  Acc@1: 87.5000 (84.7754)  Acc@5: 100.0000 (97.5978)  time: 0.2172  data: 0.0005  max mem: 2500
Test: [Task 1]  [ 610/1627]  eta: 0:04:12  Loss: 0.8796 (0.9019)  Acc@1: 87.5000 (84.8404)  Acc@5: 100.0000 (97.5962)  time: 0.2174  data: 0.0005  max mem: 2500
Test: [Task 1]  [ 620/1627]  eta: 0:04:09  Loss: 0.8512 (0.9036)  Acc@1: 87.5000 (84.8128)  Acc@5: 100.0000 (97.5745)  time: 0.2193  data: 0.0006  max mem: 2500
Test: [Task 1]  [ 630/1627]  eta: 0:04:06  Loss: 0.8240 (0.9028)  Acc@1: 87.5000 (84.8455)  Acc@5: 100.0000 (97.5832)  time: 0.2194  data: 0.0008  max mem: 2500
Test: [Task 1]  [ 640/1627]  eta: 0:04:03  Loss: 0.7320 (0.9030)  Acc@1: 87.5000 (84.8089)  Acc@5: 100.0000 (97.5624)  time: 0.2196  data: 0.0009  max mem: 2500
Test: [Task 1]  [ 650/1627]  eta: 0:04:00  Loss: 0.7988 (0.9023)  Acc@1: 81.2500 (84.7926)  Acc@5: 100.0000 (97.5806)  time: 0.2208  data: 0.0007  max mem: 2500
Test: [Task 1]  [ 660/1627]  eta: 0:03:57  Loss: 0.7804 (0.9011)  Acc@1: 81.2500 (84.7674)  Acc@5: 100.0000 (97.5889)  time: 0.2210  data: 0.0014  max mem: 2500
Test: [Task 1]  [ 670/1627]  eta: 0:03:54  Loss: 0.8877 (0.9007)  Acc@1: 87.5000 (84.7615)  Acc@5: 100.0000 (97.5969)  time: 0.2193  data: 0.0013  max mem: 2500
Test: [Task 1]  [ 680/1627]  eta: 0:03:51  Loss: 0.9071 (0.8999)  Acc@1: 87.5000 (84.7926)  Acc@5: 100.0000 (97.5954)  time: 0.2175  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 690/1627]  eta: 0:03:49  Loss: 0.8230 (0.8980)  Acc@1: 87.5000 (84.8318)  Acc@5: 100.0000 (97.6212)  time: 0.2177  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 700/1627]  eta: 0:03:46  Loss: 0.8516 (0.8983)  Acc@1: 87.5000 (84.8698)  Acc@5: 100.0000 (97.6016)  time: 0.2208  data: 0.0005  max mem: 2500
Test: [Task 1]  [ 710/1627]  eta: 0:03:43  Loss: 0.7653 (0.8956)  Acc@1: 87.5000 (84.9684)  Acc@5: 100.0000 (97.5914)  time: 0.2198  data: 0.0005  max mem: 2500
Test: [Task 1]  [ 720/1627]  eta: 0:03:40  Loss: 0.7600 (0.8938)  Acc@1: 87.5000 (84.9775)  Acc@5: 100.0000 (97.6075)  time: 0.2160  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 730/1627]  eta: 0:03:38  Loss: 0.8530 (0.8951)  Acc@1: 81.2500 (84.9008)  Acc@5: 100.0000 (97.5975)  time: 0.2169  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 740/1627]  eta: 0:03:35  Loss: 0.8911 (0.8963)  Acc@1: 81.2500 (84.8937)  Acc@5: 100.0000 (97.5709)  time: 0.2173  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 750/1627]  eta: 0:03:32  Loss: 0.8400 (0.8957)  Acc@1: 87.5000 (84.9284)  Acc@5: 100.0000 (97.5782)  time: 0.2165  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 760/1627]  eta: 0:03:29  Loss: 0.9769 (0.8988)  Acc@1: 87.5000 (84.8883)  Acc@5: 100.0000 (97.5526)  time: 0.2154  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 770/1627]  eta: 0:03:27  Loss: 0.7215 (0.8956)  Acc@1: 87.5000 (84.9627)  Acc@5: 100.0000 (97.5681)  time: 0.2154  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 780/1627]  eta: 0:03:24  Loss: 0.6772 (0.8944)  Acc@1: 87.5000 (84.9632)  Acc@5: 100.0000 (97.5752)  time: 0.2216  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 790/1627]  eta: 0:03:21  Loss: 0.7431 (0.8960)  Acc@1: 87.5000 (84.9479)  Acc@5: 100.0000 (97.5585)  time: 0.2260  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 800/1627]  eta: 0:03:19  Loss: 0.8040 (0.8952)  Acc@1: 87.5000 (84.9641)  Acc@5: 100.0000 (97.5890)  time: 0.2198  data: 0.0007  max mem: 2500
Test: [Task 1]  [ 810/1627]  eta: 0:03:16  Loss: 0.8040 (0.8946)  Acc@1: 87.5000 (84.9800)  Acc@5: 100.0000 (97.5956)  time: 0.2149  data: 0.0008  max mem: 2500
Test: [Task 1]  [ 820/1627]  eta: 0:03:13  Loss: 0.7840 (0.8936)  Acc@1: 87.5000 (85.0183)  Acc@5: 100.0000 (97.5944)  time: 0.2144  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 830/1627]  eta: 0:03:11  Loss: 0.6919 (0.8928)  Acc@1: 87.5000 (85.0331)  Acc@5: 100.0000 (97.6008)  time: 0.2145  data: 0.0002  max mem: 2500
Test: [Task 1]  [ 840/1627]  eta: 0:03:09  Loss: 0.6339 (0.8911)  Acc@1: 93.7500 (85.0847)  Acc@5: 100.0000 (97.6219)  time: 0.2413  data: 0.0013  max mem: 2500
Test: [Task 1]  [ 850/1627]  eta: 0:03:08  Loss: 0.8213 (0.8916)  Acc@1: 87.5000 (85.0837)  Acc@5: 100.0000 (97.6425)  time: 0.3666  data: 0.0014  max mem: 2500
Test: [Task 1]  [ 860/1627]  eta: 0:03:08  Loss: 0.7281 (0.8904)  Acc@1: 87.5000 (85.1336)  Acc@5: 100.0000 (97.6699)  time: 0.4672  data: 0.0005  max mem: 2500
Test: [Task 1]  [ 870/1627]  eta: 0:03:07  Loss: 0.7056 (0.8889)  Acc@1: 87.5000 (85.1679)  Acc@5: 100.0000 (97.6751)  time: 0.4661  data: 0.0012  max mem: 2500
Test: [Task 1]  [ 880/1627]  eta: 0:03:07  Loss: 0.8909 (0.8902)  Acc@1: 87.5000 (85.1518)  Acc@5: 100.0000 (97.6802)  time: 0.4651  data: 0.0012  max mem: 2500
Test: [Task 1]  [ 890/1627]  eta: 0:03:06  Loss: 0.9163 (0.8923)  Acc@1: 87.5000 (85.1361)  Acc@5: 100.0000 (97.6641)  time: 0.4653  data: 0.0006  max mem: 2500
Test: [Task 1]  [ 900/1627]  eta: 0:03:05  Loss: 0.9039 (0.8921)  Acc@1: 81.2500 (85.1276)  Acc@5: 100.0000 (97.6554)  time: 0.4633  data: 0.0010  max mem: 2500
Test: [Task 1]  [ 910/1627]  eta: 0:03:04  Loss: 0.9180 (0.8932)  Acc@1: 87.5000 (85.1125)  Acc@5: 93.7500 (97.6331)  time: 0.4638  data: 0.0010  max mem: 2500
Test: [Task 1]  [ 920/1627]  eta: 0:03:03  Loss: 0.8635 (0.8927)  Acc@1: 87.5000 (85.1452)  Acc@5: 100.0000 (97.6384)  time: 0.4650  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 930/1627]  eta: 0:03:02  Loss: 0.8584 (0.8927)  Acc@1: 87.5000 (85.1437)  Acc@5: 100.0000 (97.6437)  time: 0.4666  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 940/1627]  eta: 0:03:01  Loss: 0.8266 (0.8914)  Acc@1: 87.5000 (85.1886)  Acc@5: 100.0000 (97.6621)  time: 0.4667  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 950/1627]  eta: 0:03:00  Loss: 0.8481 (0.8919)  Acc@1: 87.5000 (85.1472)  Acc@5: 100.0000 (97.6735)  time: 0.4653  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 960/1627]  eta: 0:02:59  Loss: 0.9068 (0.8915)  Acc@1: 81.2500 (85.1262)  Acc@5: 100.0000 (97.6652)  time: 0.4648  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 970/1627]  eta: 0:02:57  Loss: 0.7443 (0.8903)  Acc@1: 87.5000 (85.1313)  Acc@5: 100.0000 (97.6764)  time: 0.4654  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 980/1627]  eta: 0:02:56  Loss: 0.8271 (0.8908)  Acc@1: 87.5000 (85.1109)  Acc@5: 100.0000 (97.6618)  time: 0.4655  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 990/1627]  eta: 0:02:54  Loss: 1.0587 (0.8937)  Acc@1: 87.5000 (85.0782)  Acc@5: 93.7500 (97.6350)  time: 0.4671  data: 0.0008  max mem: 2500
Test: [Task 1]  [1000/1627]  eta: 0:02:52  Loss: 1.0451 (0.8943)  Acc@1: 87.5000 (85.0712)  Acc@5: 100.0000 (97.6336)  time: 0.3851  data: 0.0009  max mem: 2500
Test: [Task 1]  [1010/1627]  eta: 0:02:49  Loss: 0.9210 (0.8942)  Acc@1: 87.5000 (85.0828)  Acc@5: 100.0000 (97.6323)  time: 0.2578  data: 0.0004  max mem: 2500
Test: [Task 1]  [1020/1627]  eta: 0:02:46  Loss: 0.8582 (0.8938)  Acc@1: 87.5000 (85.0759)  Acc@5: 100.0000 (97.6494)  time: 0.2148  data: 0.0004  max mem: 2500
Test: [Task 1]  [1030/1627]  eta: 0:02:42  Loss: 0.6940 (0.8920)  Acc@1: 87.5000 (85.1115)  Acc@5: 100.0000 (97.6661)  time: 0.2150  data: 0.0005  max mem: 2500
Test: [Task 1]  [1040/1627]  eta: 0:02:39  Loss: 0.6572 (0.8909)  Acc@1: 87.5000 (85.1345)  Acc@5: 100.0000 (97.6825)  time: 0.2171  data: 0.0007  max mem: 2500
Test: [Task 1]  [1050/1627]  eta: 0:02:36  Loss: 0.6692 (0.8894)  Acc@1: 87.5000 (85.1689)  Acc@5: 100.0000 (97.6808)  time: 0.2184  data: 0.0006  max mem: 2500
Test: [Task 1]  [1060/1627]  eta: 0:02:33  Loss: 0.8700 (0.8901)  Acc@1: 87.5000 (85.1673)  Acc@5: 100.0000 (97.6614)  time: 0.2205  data: 0.0005  max mem: 2500
Test: [Task 1]  [1070/1627]  eta: 0:02:30  Loss: 0.8895 (0.8908)  Acc@1: 81.2500 (85.1541)  Acc@5: 100.0000 (97.6482)  time: 0.2223  data: 0.0008  max mem: 2500
Test: [Task 1]  [1080/1627]  eta: 0:02:28  Loss: 0.8995 (0.8910)  Acc@1: 81.2500 (85.1642)  Acc@5: 100.0000 (97.6353)  time: 0.2218  data: 0.0024  max mem: 2500
Test: [Task 1]  [1090/1627]  eta: 0:02:25  Loss: 0.8813 (0.8913)  Acc@1: 81.2500 (85.1455)  Acc@5: 100.0000 (97.6455)  time: 0.2203  data: 0.0021  max mem: 2500
Test: [Task 1]  [1100/1627]  eta: 0:02:22  Loss: 0.8048 (0.8897)  Acc@1: 87.5000 (85.1726)  Acc@5: 100.0000 (97.6555)  time: 0.2181  data: 0.0006  max mem: 2500
Test: [Task 1]  [1110/1627]  eta: 0:02:19  Loss: 0.8692 (0.8902)  Acc@1: 87.5000 (85.1654)  Acc@5: 100.0000 (97.6485)  time: 0.2170  data: 0.0005  max mem: 2500
Test: [Task 1]  [1120/1627]  eta: 0:02:16  Loss: 0.8731 (0.8909)  Acc@1: 81.2500 (85.1528)  Acc@5: 100.0000 (97.6416)  time: 0.2189  data: 0.0005  max mem: 2500
Test: [Task 1]  [1130/1627]  eta: 0:02:13  Loss: 0.8190 (0.8911)  Acc@1: 81.2500 (85.1625)  Acc@5: 100.0000 (97.6459)  time: 0.2189  data: 0.0005  max mem: 2500
Test: [Task 1]  [1140/1627]  eta: 0:02:10  Loss: 0.9416 (0.8924)  Acc@1: 87.5000 (85.1556)  Acc@5: 100.0000 (97.6391)  time: 0.2158  data: 0.0004  max mem: 2500
Test: [Task 1]  [1150/1627]  eta: 0:02:07  Loss: 1.0409 (0.8933)  Acc@1: 81.2500 (85.1108)  Acc@5: 100.0000 (97.6434)  time: 0.2176  data: 0.0018  max mem: 2500
Test: [Task 1]  [1160/1627]  eta: 0:02:04  Loss: 0.9533 (0.8924)  Acc@1: 87.5000 (85.1260)  Acc@5: 100.0000 (97.6529)  time: 0.2185  data: 0.0019  max mem: 2500
Test: [Task 1]  [1170/1627]  eta: 0:02:01  Loss: 0.8828 (0.8916)  Acc@1: 87.5000 (85.1623)  Acc@5: 100.0000 (97.6569)  time: 0.2159  data: 0.0004  max mem: 2500
Test: [Task 1]  [1180/1627]  eta: 0:01:58  Loss: 0.8828 (0.8919)  Acc@1: 87.5000 (85.1768)  Acc@5: 100.0000 (97.6662)  time: 0.2154  data: 0.0006  max mem: 2500
Test: [Task 1]  [1190/1627]  eta: 0:01:56  Loss: 0.9209 (0.8921)  Acc@1: 87.5000 (85.1858)  Acc@5: 100.0000 (97.6805)  time: 0.2152  data: 0.0006  max mem: 2500
Test: [Task 1]  [1200/1627]  eta: 0:01:53  Loss: 0.9085 (0.8921)  Acc@1: 87.5000 (85.1946)  Acc@5: 100.0000 (97.6738)  time: 0.2167  data: 0.0004  max mem: 2500
Test: [Task 1]  [1210/1627]  eta: 0:01:50  Loss: 0.7547 (0.8927)  Acc@1: 87.5000 (85.1672)  Acc@5: 100.0000 (97.6724)  time: 0.2255  data: 0.0004  max mem: 2500
Test: [Task 1]  [1220/1627]  eta: 0:01:47  Loss: 0.7547 (0.8922)  Acc@1: 87.5000 (85.1761)  Acc@5: 100.0000 (97.6812)  time: 0.2240  data: 0.0007  max mem: 2500
Test: [Task 1]  [1230/1627]  eta: 0:01:44  Loss: 0.9245 (0.8925)  Acc@1: 81.2500 (85.1493)  Acc@5: 100.0000 (97.6899)  time: 0.2148  data: 0.0006  max mem: 2500
Test: [Task 1]  [1240/1627]  eta: 0:01:42  Loss: 0.8651 (0.8916)  Acc@1: 87.5000 (85.1783)  Acc@5: 100.0000 (97.6984)  time: 0.2136  data: 0.0003  max mem: 2500
Test: [Task 1]  [1250/1627]  eta: 0:01:39  Loss: 0.8651 (0.8920)  Acc@1: 87.5000 (85.1769)  Acc@5: 100.0000 (97.7018)  time: 0.2183  data: 0.0003  max mem: 2500
Test: [Task 1]  [1260/1627]  eta: 0:01:37  Loss: 0.8606 (0.8921)  Acc@1: 81.2500 (85.1655)  Acc@5: 100.0000 (97.7002)  time: 0.3205  data: 0.0003  max mem: 2500
Test: [Task 1]  [1270/1627]  eta: 0:01:35  Loss: 0.7969 (0.8926)  Acc@1: 81.2500 (85.1397)  Acc@5: 100.0000 (97.6839)  time: 0.4433  data: 0.0003  max mem: 2500
Test: [Task 1]  [1280/1627]  eta: 0:01:32  Loss: 0.7411 (0.8908)  Acc@1: 87.5000 (85.1630)  Acc@5: 100.0000 (97.6971)  time: 0.4658  data: 0.0010  max mem: 2500
Test: [Task 1]  [1290/1627]  eta: 0:01:30  Loss: 0.7706 (0.8913)  Acc@1: 81.2500 (85.1520)  Acc@5: 100.0000 (97.7004)  time: 0.4647  data: 0.0011  max mem: 2500
Test: [Task 1]  [1300/1627]  eta: 0:01:28  Loss: 0.8999 (0.8906)  Acc@1: 87.5000 (85.1749)  Acc@5: 100.0000 (97.7037)  time: 0.4686  data: 0.0005  max mem: 2500
Test: [Task 1]  [1310/1627]  eta: 0:01:26  Loss: 0.6208 (0.8891)  Acc@1: 87.5000 (85.2117)  Acc@5: 100.0000 (97.6974)  time: 0.4695  data: 0.0015  max mem: 2500
Test: [Task 1]  [1320/1627]  eta: 0:01:24  Loss: 0.5903 (0.8876)  Acc@1: 93.7500 (85.2526)  Acc@5: 100.0000 (97.7006)  time: 0.4692  data: 0.0023  max mem: 2500
Test: [Task 1]  [1330/1627]  eta: 0:01:21  Loss: 0.6813 (0.8877)  Acc@1: 87.5000 (85.2508)  Acc@5: 100.0000 (97.6944)  time: 0.4703  data: 0.0012  max mem: 2500
Test: [Task 1]  [1340/1627]  eta: 0:01:19  Loss: 0.8447 (0.8881)  Acc@1: 87.5000 (85.2302)  Acc@5: 100.0000 (97.6930)  time: 0.4701  data: 0.0003  max mem: 2500
Test: [Task 1]  [1350/1627]  eta: 0:01:16  Loss: 0.7325 (0.8873)  Acc@1: 87.5000 (85.2563)  Acc@5: 100.0000 (97.6962)  time: 0.4428  data: 0.0005  max mem: 2500
Test: [Task 1]  [1360/1627]  eta: 0:01:14  Loss: 0.7600 (0.8870)  Acc@1: 87.5000 (85.2774)  Acc@5: 100.0000 (97.7039)  time: 0.3157  data: 0.0005  max mem: 2500
Test: [Task 1]  [1370/1627]  eta: 0:01:11  Loss: 0.7600 (0.8861)  Acc@1: 87.5000 (85.2981)  Acc@5: 100.0000 (97.7161)  time: 0.2154  data: 0.0003  max mem: 2500
Test: [Task 1]  [1380/1627]  eta: 0:01:08  Loss: 0.7420 (0.8861)  Acc@1: 87.5000 (85.3050)  Acc@5: 100.0000 (97.7145)  time: 0.2153  data: 0.0003  max mem: 2500
Test: [Task 1]  [1390/1627]  eta: 0:01:05  Loss: 0.8956 (0.8854)  Acc@1: 87.5000 (85.3163)  Acc@5: 100.0000 (97.7175)  time: 0.2152  data: 0.0003  max mem: 2500
Test: [Task 1]  [1400/1627]  eta: 0:01:02  Loss: 0.8521 (0.8859)  Acc@1: 81.2500 (85.2784)  Acc@5: 100.0000 (97.7115)  time: 0.2149  data: 0.0003  max mem: 2500
Test: [Task 1]  [1410/1627]  eta: 0:00:59  Loss: 0.7113 (0.8855)  Acc@1: 87.5000 (85.2985)  Acc@5: 100.0000 (97.7144)  time: 0.2148  data: 0.0003  max mem: 2500
Test: [Task 1]  [1420/1627]  eta: 0:00:56  Loss: 0.7992 (0.8853)  Acc@1: 87.5000 (85.3008)  Acc@5: 100.0000 (97.7173)  time: 0.2154  data: 0.0005  max mem: 2500
Test: [Task 1]  [1430/1627]  eta: 0:00:54  Loss: 1.0235 (0.8873)  Acc@1: 81.2500 (85.2725)  Acc@5: 100.0000 (97.6765)  time: 0.2151  data: 0.0005  max mem: 2500
Test: [Task 1]  [1440/1627]  eta: 0:00:51  Loss: 0.9669 (0.8870)  Acc@1: 81.2500 (85.2576)  Acc@5: 100.0000 (97.6839)  time: 0.2142  data: 0.0002  max mem: 2500
Test: [Task 1]  [1450/1627]  eta: 0:00:48  Loss: 0.8892 (0.8883)  Acc@1: 81.2500 (85.2343)  Acc@5: 100.0000 (97.6740)  time: 0.2144  data: 0.0003  max mem: 2500
Test: [Task 1]  [1460/1627]  eta: 0:00:45  Loss: 1.0590 (0.8885)  Acc@1: 87.5000 (85.2242)  Acc@5: 100.0000 (97.6557)  time: 0.2151  data: 0.0003  max mem: 2500
Test: [Task 1]  [1470/1627]  eta: 0:00:42  Loss: 0.8934 (0.8891)  Acc@1: 81.2500 (85.2014)  Acc@5: 100.0000 (97.6462)  time: 0.2170  data: 0.0008  max mem: 2500
Test: [Task 1]  [1480/1627]  eta: 0:00:40  Loss: 0.8952 (0.8891)  Acc@1: 87.5000 (85.2296)  Acc@5: 100.0000 (97.6452)  time: 0.2194  data: 0.0013  max mem: 2500
Test: [Task 1]  [1490/1627]  eta: 0:00:37  Loss: 0.9083 (0.8894)  Acc@1: 87.5000 (85.2364)  Acc@5: 100.0000 (97.6442)  time: 0.2194  data: 0.0014  max mem: 2500
Test: [Task 1]  [1500/1627]  eta: 0:00:34  Loss: 0.9163 (0.8896)  Acc@1: 87.5000 (85.2307)  Acc@5: 100.0000 (97.6391)  time: 0.2168  data: 0.0010  max mem: 2500
Test: [Task 1]  [1510/1627]  eta: 0:00:31  Loss: 0.7988 (0.8896)  Acc@1: 87.5000 (85.2457)  Acc@5: 100.0000 (97.6340)  time: 0.2155  data: 0.0004  max mem: 2500
Test: [Task 1]  [1520/1627]  eta: 0:00:28  Loss: 0.7308 (0.8885)  Acc@1: 87.5000 (85.2728)  Acc@5: 100.0000 (97.6414)  time: 0.2178  data: 0.0006  max mem: 2500
Test: [Task 1]  [1530/1627]  eta: 0:00:26  Loss: 0.7308 (0.8882)  Acc@1: 87.5000 (85.2670)  Acc@5: 100.0000 (97.6445)  time: 0.2187  data: 0.0007  max mem: 2500
Test: [Task 1]  [1540/1627]  eta: 0:00:23  Loss: 0.6447 (0.8873)  Acc@1: 87.5000 (85.2774)  Acc@5: 100.0000 (97.6476)  time: 0.2179  data: 0.0005  max mem: 2500
Test: [Task 1]  [1550/1627]  eta: 0:00:20  Loss: 0.6447 (0.8866)  Acc@1: 87.5000 (85.3119)  Acc@5: 100.0000 (97.6467)  time: 0.2180  data: 0.0006  max mem: 2500
Test: [Task 1]  [1560/1627]  eta: 0:00:18  Loss: 0.6302 (0.8856)  Acc@1: 87.5000 (85.3459)  Acc@5: 100.0000 (97.6457)  time: 0.2193  data: 0.0015  max mem: 2500
Test: [Task 1]  [1570/1627]  eta: 0:00:15  Loss: 0.7174 (0.8856)  Acc@1: 87.5000 (85.3676)  Acc@5: 100.0000 (97.6369)  time: 0.2178  data: 0.0013  max mem: 2500
Test: [Task 1]  [1580/1627]  eta: 0:00:12  Loss: 0.7940 (0.8857)  Acc@1: 87.5000 (85.3732)  Acc@5: 100.0000 (97.6399)  time: 0.2158  data: 0.0004  max mem: 2500
Test: [Task 1]  [1590/1627]  eta: 0:00:09  Loss: 0.8183 (0.8858)  Acc@1: 81.2500 (85.3708)  Acc@5: 100.0000 (97.6430)  time: 0.2175  data: 0.0006  max mem: 2500
Test: [Task 1]  [1600/1627]  eta: 0:00:07  Loss: 0.8718 (0.8866)  Acc@1: 81.2500 (85.3490)  Acc@5: 100.0000 (97.6382)  time: 0.2176  data: 0.0006  max mem: 2500
Test: [Task 1]  [1610/1627]  eta: 0:00:04  Loss: 0.8298 (0.8863)  Acc@1: 81.2500 (85.3430)  Acc@5: 100.0000 (97.6451)  time: 0.2162  data: 0.0005  max mem: 2500
Test: [Task 1]  [1620/1627]  eta: 0:00:01  Loss: 0.6904 (0.8854)  Acc@1: 87.5000 (85.3563)  Acc@5: 100.0000 (97.6403)  time: 0.2165  data: 0.0004  max mem: 2500
Test: [Task 1]  [1626/1627]  eta: 0:00:00  Loss: 0.6696 (0.8848)  Acc@1: 87.5000 (85.3680)  Acc@5: 100.0000 (97.6375)  time: 0.2169  data: 0.0003  max mem: 2500
Test: [Task 1] Total time: 0:07:15 (0.2677 s / it)
* Acc@1 85.368 Acc@5 97.638 loss 0.885
{0: {0: 26032, 1: 26032, 2: 26032, 3: 26032, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0, 10: 0, 11: 0, 12: 0, 13: 0, 14: 0, 15: 0, 16: 0, 17: 0, 18: 0, 19: 0}}
[Average accuracy till task1]	Acc@1: 85.3680	Acc@5: 97.6375	Loss: 0.8848
Train: Epoch[1/5]  [   0/3750]  eta: 0:48:32  Lr: 0.001875  Loss: 0.7721  Acc@1: 18.7500 (18.7500)  Acc@5: 56.2500 (56.2500)  time: 0.7768  data: 0.4106  max mem: 2500
Train: Epoch[1/5]  [  10/3750]  eta: 0:24:04  Lr: 0.001875  Loss: 0.5831  Acc@1: 18.7500 (21.5909)  Acc@5: 62.5000 (62.5000)  time: 0.3863  data: 0.0378  max mem: 2500
Train: Epoch[1/5]  [  20/3750]  eta: 0:22:53  Lr: 0.001875  Loss: 0.5937  Acc@1: 25.0000 (23.2143)  Acc@5: 62.5000 (64.8810)  time: 0.3477  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [  30/3750]  eta: 0:22:23  Lr: 0.001875  Loss: 0.4441  Acc@1: 31.2500 (29.0323)  Acc@5: 75.0000 (70.1613)  time: 0.3472  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [  40/3750]  eta: 0:22:09  Lr: 0.001875  Loss: 0.4248  Acc@1: 43.7500 (33.5366)  Acc@5: 81.2500 (74.0854)  time: 0.3480  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [  50/3750]  eta: 0:21:55  Lr: 0.001875  Loss: 0.1960  Acc@1: 50.0000 (36.2745)  Acc@5: 87.5000 (76.5931)  time: 0.3470  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [  60/3750]  eta: 0:21:45  Lr: 0.001875  Loss: 0.0707  Acc@1: 50.0000 (39.1393)  Acc@5: 87.5000 (78.8934)  time: 0.3446  data: 0.0002  max mem: 2500
Train: Epoch[1/5]  [  70/3750]  eta: 0:21:40  Lr: 0.001875  Loss: 0.4561  Acc@1: 50.0000 (41.0211)  Acc@5: 87.5000 (80.1937)  time: 0.3478  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [  80/3750]  eta: 0:21:38  Lr: 0.001875  Loss: -0.4089  Acc@1: 56.2500 (43.0556)  Acc@5: 93.7500 (81.9444)  time: 0.3536  data: 0.0021  max mem: 2500
Train: Epoch[1/5]  [  90/3750]  eta: 0:21:33  Lr: 0.001875  Loss: -0.0726  Acc@1: 56.2500 (44.8489)  Acc@5: 93.7500 (82.9670)  time: 0.3532  data: 0.0021  max mem: 2500
Train: Epoch[1/5]  [ 100/3750]  eta: 0:21:28  Lr: 0.001875  Loss: -0.2869  Acc@1: 62.5000 (46.5965)  Acc@5: 93.7500 (84.0965)  time: 0.3500  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [ 110/3750]  eta: 0:21:24  Lr: 0.001875  Loss: -0.0619  Acc@1: 62.5000 (48.4797)  Acc@5: 93.7500 (84.7410)  time: 0.3507  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [ 120/3750]  eta: 0:21:21  Lr: 0.001875  Loss: -0.2844  Acc@1: 68.7500 (49.6901)  Acc@5: 93.7500 (85.4339)  time: 0.3536  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [ 130/3750]  eta: 0:21:19  Lr: 0.001875  Loss: -0.1938  Acc@1: 56.2500 (50.4294)  Acc@5: 93.7500 (86.0210)  time: 0.3568  data: 0.0012  max mem: 2500
Train: Epoch[1/5]  [ 140/3750]  eta: 0:21:14  Lr: 0.001875  Loss: -0.3642  Acc@1: 62.5000 (51.7287)  Acc@5: 100.0000 (86.6578)  time: 0.3534  data: 0.0012  max mem: 2500
Train: Epoch[1/5]  [ 150/3750]  eta: 0:21:10  Lr: 0.001875  Loss: -0.0994  Acc@1: 75.0000 (52.4421)  Acc@5: 93.7500 (86.9619)  time: 0.3492  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [ 160/3750]  eta: 0:21:05  Lr: 0.001875  Loss: -0.4542  Acc@1: 62.5000 (53.3385)  Acc@5: 93.7500 (87.5388)  time: 0.3487  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 170/3750]  eta: 0:21:01  Lr: 0.001875  Loss: -0.1968  Acc@1: 62.5000 (53.8012)  Acc@5: 93.7500 (87.9020)  time: 0.3483  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 180/3750]  eta: 0:20:57  Lr: 0.001875  Loss: -0.4114  Acc@1: 62.5000 (54.5580)  Acc@5: 93.7500 (88.3633)  time: 0.3503  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 190/3750]  eta: 0:20:53  Lr: 0.001875  Loss: -0.1042  Acc@1: 62.5000 (54.7448)  Acc@5: 100.0000 (88.6126)  time: 0.3493  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 200/3750]  eta: 0:20:48  Lr: 0.001875  Loss: -0.4713  Acc@1: 62.5000 (55.3794)  Acc@5: 93.7500 (88.9303)  time: 0.3471  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [ 210/3750]  eta: 0:20:45  Lr: 0.001875  Loss: -0.4200  Acc@1: 68.7500 (56.0723)  Acc@5: 93.7500 (89.2773)  time: 0.3488  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 220/3750]  eta: 0:20:41  Lr: 0.001875  Loss: -0.1961  Acc@1: 68.7500 (56.4197)  Acc@5: 93.7500 (89.5079)  time: 0.3491  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 230/3750]  eta: 0:20:36  Lr: 0.001875  Loss: -0.3029  Acc@1: 62.5000 (56.7641)  Acc@5: 93.7500 (89.6374)  time: 0.3477  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [ 240/3750]  eta: 0:20:32  Lr: 0.001875  Loss: -0.1763  Acc@1: 62.5000 (57.1836)  Acc@5: 93.7500 (89.8340)  time: 0.3475  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [ 250/3750]  eta: 0:20:28  Lr: 0.001875  Loss: -0.5085  Acc@1: 62.5000 (57.6444)  Acc@5: 93.7500 (89.9651)  time: 0.3480  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 260/3750]  eta: 0:20:24  Lr: 0.001875  Loss: -0.5164  Acc@1: 68.7500 (58.1897)  Acc@5: 93.7500 (90.1341)  time: 0.3469  data: 0.0009  max mem: 2500
Train: Epoch[1/5]  [ 270/3750]  eta: 0:20:21  Lr: 0.001875  Loss: -0.6364  Acc@1: 68.7500 (58.6024)  Acc@5: 93.7500 (90.3137)  time: 0.3480  data: 0.0011  max mem: 2500
Train: Epoch[1/5]  [ 280/3750]  eta: 0:20:17  Lr: 0.001875  Loss: -0.2217  Acc@1: 68.7500 (58.8301)  Acc@5: 93.7500 (90.4137)  time: 0.3483  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [ 290/3750]  eta: 0:20:13  Lr: 0.001875  Loss: -0.4230  Acc@1: 68.7500 (59.1495)  Acc@5: 93.7500 (90.4854)  time: 0.3478  data: 0.0012  max mem: 2500
Train: Epoch[1/5]  [ 300/3750]  eta: 0:20:09  Lr: 0.001875  Loss: -0.4940  Acc@1: 68.7500 (59.5723)  Acc@5: 93.7500 (90.5316)  time: 0.3495  data: 0.0012  max mem: 2500
Train: Epoch[1/5]  [ 310/3750]  eta: 0:20:05  Lr: 0.001875  Loss: -0.8760  Acc@1: 68.7500 (59.9277)  Acc@5: 93.7500 (90.6752)  time: 0.3477  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 320/3750]  eta: 0:20:01  Lr: 0.001875  Loss: -0.4244  Acc@1: 68.7500 (60.2025)  Acc@5: 93.7500 (90.8879)  time: 0.3456  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [ 330/3750]  eta: 0:19:58  Lr: 0.001875  Loss: -0.4615  Acc@1: 68.7500 (60.3852)  Acc@5: 93.7500 (90.9554)  time: 0.3504  data: 0.0012  max mem: 2500
Train: Epoch[1/5]  [ 340/3750]  eta: 0:19:54  Lr: 0.001875  Loss: -0.6847  Acc@1: 75.0000 (60.7955)  Acc@5: 93.7500 (91.0374)  time: 0.3516  data: 0.0015  max mem: 2500
Train: Epoch[1/5]  [ 350/3750]  eta: 0:19:50  Lr: 0.001875  Loss: -0.3227  Acc@1: 68.7500 (60.9330)  Acc@5: 93.7500 (91.1147)  time: 0.3467  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [ 360/3750]  eta: 0:19:46  Lr: 0.001875  Loss: 0.1106  Acc@1: 68.7500 (61.1150)  Acc@5: 93.7500 (91.1011)  time: 0.3457  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [ 370/3750]  eta: 0:19:43  Lr: 0.001875  Loss: -0.1543  Acc@1: 68.7500 (61.5061)  Acc@5: 93.7500 (91.2062)  time: 0.3479  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 380/3750]  eta: 0:19:39  Lr: 0.001875  Loss: -0.9103  Acc@1: 75.0000 (61.8930)  Acc@5: 93.7500 (91.2566)  time: 0.3483  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 390/3750]  eta: 0:19:35  Lr: 0.001875  Loss: -1.1105  Acc@1: 75.0000 (62.1164)  Acc@5: 93.7500 (91.2564)  time: 0.3459  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [ 400/3750]  eta: 0:19:32  Lr: 0.001875  Loss: -0.3105  Acc@1: 68.7500 (62.3909)  Acc@5: 93.7500 (91.3186)  time: 0.3474  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [ 410/3750]  eta: 0:19:28  Lr: 0.001875  Loss: -0.2785  Acc@1: 68.7500 (62.4544)  Acc@5: 93.7500 (91.4386)  time: 0.3491  data: 0.0009  max mem: 2500
Train: Epoch[1/5]  [ 420/3750]  eta: 0:19:24  Lr: 0.001875  Loss: -0.5519  Acc@1: 68.7500 (62.6930)  Acc@5: 93.7500 (91.5083)  time: 0.3481  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [ 430/3750]  eta: 0:19:21  Lr: 0.001875  Loss: -0.5580  Acc@1: 68.7500 (62.8045)  Acc@5: 93.7500 (91.5313)  time: 0.3470  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [ 440/3750]  eta: 0:19:17  Lr: 0.001875  Loss: -0.6067  Acc@1: 68.7500 (63.0102)  Acc@5: 93.7500 (91.5675)  time: 0.3469  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 450/3750]  eta: 0:19:13  Lr: 0.001875  Loss: -0.8921  Acc@1: 68.7500 (63.2345)  Acc@5: 93.7500 (91.6713)  time: 0.3475  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 460/3750]  eta: 0:19:10  Lr: 0.001875  Loss: -0.4760  Acc@1: 68.7500 (63.4355)  Acc@5: 93.7500 (91.7842)  time: 0.3476  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [ 470/3750]  eta: 0:19:06  Lr: 0.001875  Loss: -0.2561  Acc@1: 75.0000 (63.6412)  Acc@5: 93.7500 (91.7861)  time: 0.3457  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [ 480/3750]  eta: 0:19:02  Lr: 0.001875  Loss: -0.1452  Acc@1: 75.0000 (63.9293)  Acc@5: 93.7500 (91.8919)  time: 0.3443  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [ 490/3750]  eta: 0:18:58  Lr: 0.001875  Loss: -0.2175  Acc@1: 75.0000 (64.0530)  Acc@5: 93.7500 (91.9425)  time: 0.3456  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [ 500/3750]  eta: 0:18:55  Lr: 0.001875  Loss: -0.8779  Acc@1: 62.5000 (64.0594)  Acc@5: 93.7500 (91.9661)  time: 0.3460  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [ 510/3750]  eta: 0:18:51  Lr: 0.001875  Loss: -0.5557  Acc@1: 68.7500 (64.1634)  Acc@5: 93.7500 (92.0010)  time: 0.3467  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [ 520/3750]  eta: 0:18:48  Lr: 0.001875  Loss: -0.7182  Acc@1: 68.7500 (64.3954)  Acc@5: 93.7500 (92.0465)  time: 0.3494  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [ 530/3750]  eta: 0:18:45  Lr: 0.001875  Loss: -0.6456  Acc@1: 75.0000 (64.6304)  Acc@5: 93.7500 (92.1139)  time: 0.3546  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [ 540/3750]  eta: 0:18:41  Lr: 0.001875  Loss: -0.3277  Acc@1: 75.0000 (64.7874)  Acc@5: 93.7500 (92.1673)  time: 0.3547  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [ 550/3750]  eta: 0:18:38  Lr: 0.001875  Loss: -0.7403  Acc@1: 68.7500 (64.8026)  Acc@5: 93.7500 (92.1960)  time: 0.3512  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [ 560/3750]  eta: 0:18:34  Lr: 0.001875  Loss: -0.7419  Acc@1: 68.7500 (64.8507)  Acc@5: 93.7500 (92.2348)  time: 0.3509  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [ 570/3750]  eta: 0:18:31  Lr: 0.001875  Loss: -0.7707  Acc@1: 68.7500 (64.9847)  Acc@5: 93.7500 (92.2504)  time: 0.3513  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [ 580/3750]  eta: 0:18:28  Lr: 0.001875  Loss: -0.0941  Acc@1: 68.7500 (65.0387)  Acc@5: 93.7500 (92.2978)  time: 0.3532  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [ 590/3750]  eta: 0:18:24  Lr: 0.001875  Loss: -0.6257  Acc@1: 68.7500 (65.1967)  Acc@5: 93.7500 (92.3223)  time: 0.3531  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [ 600/3750]  eta: 0:18:21  Lr: 0.001875  Loss: -0.7451  Acc@1: 75.0000 (65.2662)  Acc@5: 93.7500 (92.3357)  time: 0.3513  data: 0.0013  max mem: 2500
Train: Epoch[1/5]  [ 610/3750]  eta: 0:18:17  Lr: 0.001875  Loss: -0.7985  Acc@1: 68.7500 (65.3335)  Acc@5: 93.7500 (92.3486)  time: 0.3492  data: 0.0011  max mem: 2500
Train: Epoch[1/5]  [ 620/3750]  eta: 0:18:14  Lr: 0.001875  Loss: -0.6609  Acc@1: 68.7500 (65.3784)  Acc@5: 93.7500 (92.3611)  time: 0.3475  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 630/3750]  eta: 0:18:10  Lr: 0.001875  Loss: -0.4893  Acc@1: 68.7500 (65.4616)  Acc@5: 93.7500 (92.3435)  time: 0.3486  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 640/3750]  eta: 0:18:07  Lr: 0.001875  Loss: -0.3451  Acc@1: 62.5000 (65.4056)  Acc@5: 93.7500 (92.3362)  time: 0.3487  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 650/3750]  eta: 0:18:03  Lr: 0.001875  Loss: -0.5059  Acc@1: 75.0000 (65.5242)  Acc@5: 93.7500 (92.3483)  time: 0.3472  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 660/3750]  eta: 0:18:00  Lr: 0.001875  Loss: -0.5583  Acc@1: 75.0000 (65.6770)  Acc@5: 93.7500 (92.3695)  time: 0.3483  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 670/3750]  eta: 0:17:56  Lr: 0.001875  Loss: -0.8225  Acc@1: 75.0000 (65.7787)  Acc@5: 100.0000 (92.4367)  time: 0.3490  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 680/3750]  eta: 0:17:52  Lr: 0.001875  Loss: -0.5401  Acc@1: 68.7500 (65.8682)  Acc@5: 93.7500 (92.4559)  time: 0.3463  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [ 690/3750]  eta: 0:17:49  Lr: 0.001875  Loss: -0.4023  Acc@1: 68.7500 (65.8828)  Acc@5: 93.7500 (92.4385)  time: 0.3460  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [ 700/3750]  eta: 0:17:45  Lr: 0.001875  Loss: -0.8346  Acc@1: 68.7500 (65.9326)  Acc@5: 93.7500 (92.4572)  time: 0.3508  data: 0.0013  max mem: 2500
Train: Epoch[1/5]  [ 710/3750]  eta: 0:17:42  Lr: 0.001875  Loss: -0.7190  Acc@1: 75.0000 (66.0777)  Acc@5: 93.7500 (92.4930)  time: 0.3526  data: 0.0016  max mem: 2500
Train: Epoch[1/5]  [ 720/3750]  eta: 0:17:38  Lr: 0.001875  Loss: -0.6792  Acc@1: 75.0000 (66.1061)  Acc@5: 93.7500 (92.5104)  time: 0.3492  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [ 730/3750]  eta: 0:17:35  Lr: 0.001875  Loss: -1.1504  Acc@1: 68.7500 (66.2107)  Acc@5: 93.7500 (92.5359)  time: 0.3485  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [ 740/3750]  eta: 0:17:32  Lr: 0.001875  Loss: -0.6497  Acc@1: 75.0000 (66.3293)  Acc@5: 93.7500 (92.5860)  time: 0.3514  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [ 750/3750]  eta: 0:17:28  Lr: 0.001875  Loss: -0.7553  Acc@1: 75.0000 (66.4198)  Acc@5: 93.7500 (92.5849)  time: 0.3533  data: 0.0014  max mem: 2500
Train: Epoch[1/5]  [ 760/3750]  eta: 0:17:25  Lr: 0.001875  Loss: -1.1434  Acc@1: 75.0000 (66.5079)  Acc@5: 87.5000 (92.5756)  time: 0.3521  data: 0.0014  max mem: 2500
Train: Epoch[1/5]  [ 770/3750]  eta: 0:17:22  Lr: 0.001875  Loss: -0.6440  Acc@1: 75.0000 (66.6342)  Acc@5: 93.7500 (92.6151)  time: 0.3536  data: 0.0010  max mem: 2500
Train: Epoch[1/5]  [ 780/3750]  eta: 0:17:18  Lr: 0.001875  Loss: -0.2121  Acc@1: 75.0000 (66.7173)  Acc@5: 93.7500 (92.6376)  time: 0.3528  data: 0.0011  max mem: 2500
Train: Epoch[1/5]  [ 790/3750]  eta: 0:17:14  Lr: 0.001875  Loss: -1.0128  Acc@1: 68.7500 (66.7747)  Acc@5: 93.7500 (92.6438)  time: 0.3479  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 800/3750]  eta: 0:17:11  Lr: 0.001875  Loss: -1.1764  Acc@1: 68.7500 (66.9242)  Acc@5: 93.7500 (92.6810)  time: 0.3470  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 810/3750]  eta: 0:17:07  Lr: 0.001875  Loss: -0.3809  Acc@1: 75.0000 (67.0006)  Acc@5: 93.7500 (92.6865)  time: 0.3474  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 820/3750]  eta: 0:17:04  Lr: 0.001875  Loss: -1.0803  Acc@1: 75.0000 (67.1057)  Acc@5: 93.7500 (92.7299)  time: 0.3479  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 830/3750]  eta: 0:17:00  Lr: 0.001875  Loss: -0.8499  Acc@1: 75.0000 (67.1631)  Acc@5: 93.7500 (92.7271)  time: 0.3497  data: 0.0020  max mem: 2500
Train: Epoch[1/5]  [ 840/3750]  eta: 0:16:57  Lr: 0.001875  Loss: -0.6834  Acc@1: 68.7500 (67.2191)  Acc@5: 93.7500 (92.7542)  time: 0.3501  data: 0.0027  max mem: 2500
Train: Epoch[1/5]  [ 850/3750]  eta: 0:16:53  Lr: 0.001875  Loss: -0.6873  Acc@1: 68.7500 (67.3032)  Acc@5: 93.7500 (92.7952)  time: 0.3477  data: 0.0011  max mem: 2500
Train: Epoch[1/5]  [ 860/3750]  eta: 0:16:50  Lr: 0.001875  Loss: -0.6635  Acc@1: 68.7500 (67.3635)  Acc@5: 93.7500 (92.8208)  time: 0.3467  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [ 870/3750]  eta: 0:16:46  Lr: 0.001875  Loss: -0.4887  Acc@1: 75.0000 (67.4153)  Acc@5: 93.7500 (92.8315)  time: 0.3468  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [ 880/3750]  eta: 0:16:42  Lr: 0.001875  Loss: -0.9995  Acc@1: 75.0000 (67.4872)  Acc@5: 93.7500 (92.8703)  time: 0.3472  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [ 890/3750]  eta: 0:16:39  Lr: 0.001875  Loss: -0.9167  Acc@1: 75.0000 (67.6347)  Acc@5: 100.0000 (92.9082)  time: 0.3508  data: 0.0010  max mem: 2500
Train: Epoch[1/5]  [ 900/3750]  eta: 0:16:36  Lr: 0.001875  Loss: -0.5720  Acc@1: 75.0000 (67.7234)  Acc@5: 93.7500 (92.9176)  time: 0.3532  data: 0.0012  max mem: 2500
Train: Epoch[1/5]  [ 910/3750]  eta: 0:16:32  Lr: 0.001875  Loss: -1.0700  Acc@1: 75.0000 (67.7895)  Acc@5: 93.7500 (92.9336)  time: 0.3530  data: 0.0019  max mem: 2500
Train: Epoch[1/5]  [ 920/3750]  eta: 0:16:29  Lr: 0.001875  Loss: -0.4916  Acc@1: 75.0000 (67.8678)  Acc@5: 93.7500 (92.9696)  time: 0.3533  data: 0.0014  max mem: 2500
Train: Epoch[1/5]  [ 930/3750]  eta: 0:16:25  Lr: 0.001875  Loss: -0.8179  Acc@1: 75.0000 (67.9511)  Acc@5: 93.7500 (92.9847)  time: 0.3511  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [ 940/3750]  eta: 0:16:22  Lr: 0.001875  Loss: -0.9088  Acc@1: 75.0000 (68.0260)  Acc@5: 93.7500 (92.9928)  time: 0.3504  data: 0.0013  max mem: 2500
Train: Epoch[1/5]  [ 950/3750]  eta: 0:16:19  Lr: 0.001875  Loss: -0.3069  Acc@1: 75.0000 (68.1519)  Acc@5: 93.7500 (93.0205)  time: 0.3509  data: 0.0013  max mem: 2500
Train: Epoch[1/5]  [ 960/3750]  eta: 0:16:15  Lr: 0.001875  Loss: -0.5747  Acc@1: 81.2500 (68.3078)  Acc@5: 100.0000 (93.0541)  time: 0.3507  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [ 970/3750]  eta: 0:16:12  Lr: 0.001875  Loss: -0.6905  Acc@1: 75.0000 (68.3509)  Acc@5: 93.7500 (93.0677)  time: 0.3554  data: 0.0009  max mem: 2500
Train: Epoch[1/5]  [ 980/3750]  eta: 0:16:08  Lr: 0.001875  Loss: -0.6484  Acc@1: 75.0000 (68.4123)  Acc@5: 93.7500 (93.0874)  time: 0.3531  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [ 990/3750]  eta: 0:16:05  Lr: 0.001875  Loss: -0.8284  Acc@1: 75.0000 (68.4536)  Acc@5: 93.7500 (93.1193)  time: 0.3477  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1000/3750]  eta: 0:16:01  Lr: 0.001875  Loss: -0.5652  Acc@1: 75.0000 (68.4940)  Acc@5: 93.7500 (93.1006)  time: 0.3480  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1010/3750]  eta: 0:15:58  Lr: 0.001875  Loss: -0.8187  Acc@1: 68.7500 (68.5089)  Acc@5: 93.7500 (93.0700)  time: 0.3478  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [1020/3750]  eta: 0:15:54  Lr: 0.001875  Loss: -0.7905  Acc@1: 75.0000 (68.5786)  Acc@5: 93.7500 (93.1011)  time: 0.3473  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1030/3750]  eta: 0:15:50  Lr: 0.001875  Loss: -0.8415  Acc@1: 75.0000 (68.6348)  Acc@5: 93.7500 (93.1195)  time: 0.3464  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1040/3750]  eta: 0:15:47  Lr: 0.001875  Loss: -0.5824  Acc@1: 75.0000 (68.7080)  Acc@5: 93.7500 (93.1256)  time: 0.3455  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [1050/3750]  eta: 0:15:43  Lr: 0.001875  Loss: -0.8572  Acc@1: 75.0000 (68.7559)  Acc@5: 93.7500 (93.1494)  time: 0.3447  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [1060/3750]  eta: 0:15:40  Lr: 0.001875  Loss: -0.7362  Acc@1: 68.7500 (68.7795)  Acc@5: 93.7500 (93.1786)  time: 0.3448  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [1070/3750]  eta: 0:15:36  Lr: 0.001875  Loss: -0.9973  Acc@1: 68.7500 (68.8259)  Acc@5: 93.7500 (93.2073)  time: 0.3463  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1080/3750]  eta: 0:15:33  Lr: 0.001875  Loss: -1.1752  Acc@1: 75.0000 (68.8541)  Acc@5: 100.0000 (93.2181)  time: 0.3501  data: 0.0012  max mem: 2500
Train: Epoch[1/5]  [1090/3750]  eta: 0:15:29  Lr: 0.001875  Loss: -1.2662  Acc@1: 75.0000 (68.9276)  Acc@5: 100.0000 (93.2573)  time: 0.3541  data: 0.0012  max mem: 2500
Train: Epoch[1/5]  [1100/3750]  eta: 0:15:26  Lr: 0.001875  Loss: -0.6125  Acc@1: 68.7500 (68.9544)  Acc@5: 93.7500 (93.2845)  time: 0.3530  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1110/3750]  eta: 0:15:22  Lr: 0.001875  Loss: -0.7677  Acc@1: 75.0000 (69.0369)  Acc@5: 100.0000 (93.3281)  time: 0.3530  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [1120/3750]  eta: 0:15:19  Lr: 0.001875  Loss: -0.4643  Acc@1: 75.0000 (69.1403)  Acc@5: 93.7500 (93.3318)  time: 0.3557  data: 0.0015  max mem: 2500
Train: Epoch[1/5]  [1130/3750]  eta: 0:15:16  Lr: 0.001875  Loss: -0.8343  Acc@1: 75.0000 (69.1976)  Acc@5: 100.0000 (93.3742)  time: 0.3544  data: 0.0016  max mem: 2500
Train: Epoch[1/5]  [1140/3750]  eta: 0:15:12  Lr: 0.001875  Loss: -0.6373  Acc@1: 75.0000 (69.2211)  Acc@5: 100.0000 (93.3830)  time: 0.3530  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [1150/3750]  eta: 0:15:09  Lr: 0.001875  Loss: -0.6576  Acc@1: 68.7500 (69.2333)  Acc@5: 93.7500 (93.4242)  time: 0.3522  data: 0.0010  max mem: 2500
Train: Epoch[1/5]  [1160/3750]  eta: 0:15:05  Lr: 0.001875  Loss: -0.7832  Acc@1: 75.0000 (69.2722)  Acc@5: 100.0000 (93.4378)  time: 0.3498  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [1170/3750]  eta: 0:15:02  Lr: 0.001875  Loss: -0.6320  Acc@1: 75.0000 (69.3211)  Acc@5: 93.7500 (93.4458)  time: 0.3475  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1180/3750]  eta: 0:14:58  Lr: 0.001875  Loss: -0.7506  Acc@1: 75.0000 (69.3851)  Acc@5: 93.7500 (93.4642)  time: 0.3487  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1190/3750]  eta: 0:14:55  Lr: 0.001875  Loss: -0.1918  Acc@1: 75.0000 (69.4217)  Acc@5: 93.7500 (93.4771)  time: 0.3499  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1200/3750]  eta: 0:14:51  Lr: 0.001875  Loss: -0.5828  Acc@1: 75.0000 (69.4942)  Acc@5: 100.0000 (93.5054)  time: 0.3488  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1210/3750]  eta: 0:14:48  Lr: 0.001875  Loss: -0.7761  Acc@1: 75.0000 (69.5293)  Acc@5: 93.7500 (93.4919)  time: 0.3471  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1220/3750]  eta: 0:14:44  Lr: 0.001875  Loss: -0.9674  Acc@1: 75.0000 (69.5997)  Acc@5: 93.7500 (93.5043)  time: 0.3462  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [1230/3750]  eta: 0:14:40  Lr: 0.001875  Loss: -0.7743  Acc@1: 75.0000 (69.6182)  Acc@5: 93.7500 (93.4911)  time: 0.3453  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1240/3750]  eta: 0:14:37  Lr: 0.001875  Loss: -0.8325  Acc@1: 75.0000 (69.6817)  Acc@5: 93.7500 (93.5183)  time: 0.3441  data: 0.0002  max mem: 2500
Train: Epoch[1/5]  [1250/3750]  eta: 0:14:33  Lr: 0.001875  Loss: -0.1158  Acc@1: 75.0000 (69.6942)  Acc@5: 93.7500 (93.5252)  time: 0.3448  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [1260/3750]  eta: 0:14:30  Lr: 0.001875  Loss: -0.6650  Acc@1: 75.0000 (69.7363)  Acc@5: 93.7500 (93.5369)  time: 0.3510  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [1270/3750]  eta: 0:14:26  Lr: 0.001875  Loss: -0.7311  Acc@1: 75.0000 (69.7630)  Acc@5: 93.7500 (93.5631)  time: 0.3538  data: 0.0009  max mem: 2500
Train: Epoch[1/5]  [1280/3750]  eta: 0:14:23  Lr: 0.001875  Loss: -1.0713  Acc@1: 68.7500 (69.8087)  Acc@5: 100.0000 (93.5792)  time: 0.3514  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1290/3750]  eta: 0:14:20  Lr: 0.001875  Loss: -0.5124  Acc@1: 75.0000 (69.8490)  Acc@5: 93.7500 (93.5999)  time: 0.3503  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [1300/3750]  eta: 0:14:16  Lr: 0.001875  Loss: -0.4970  Acc@1: 75.0000 (69.9030)  Acc@5: 93.7500 (93.6203)  time: 0.3514  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1310/3750]  eta: 0:14:13  Lr: 0.001875  Loss: -0.7694  Acc@1: 75.0000 (69.9609)  Acc@5: 93.7500 (93.6308)  time: 0.3545  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [1320/3750]  eta: 0:14:09  Lr: 0.001875  Loss: -0.7651  Acc@1: 75.0000 (69.9849)  Acc@5: 93.7500 (93.6317)  time: 0.3551  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [1330/3750]  eta: 0:14:06  Lr: 0.001875  Loss: -0.1335  Acc@1: 75.0000 (70.0319)  Acc@5: 93.7500 (93.6514)  time: 0.3576  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [1340/3750]  eta: 0:14:03  Lr: 0.001875  Loss: -0.9897  Acc@1: 75.0000 (70.0410)  Acc@5: 100.0000 (93.6708)  time: 0.3556  data: 0.0013  max mem: 2500
Train: Epoch[1/5]  [1350/3750]  eta: 0:13:59  Lr: 0.001875  Loss: -0.3925  Acc@1: 68.7500 (70.0638)  Acc@5: 93.7500 (93.6714)  time: 0.3498  data: 0.0011  max mem: 2500
Train: Epoch[1/5]  [1360/3750]  eta: 0:13:55  Lr: 0.001875  Loss: -0.6082  Acc@1: 75.0000 (70.1323)  Acc@5: 100.0000 (93.6995)  time: 0.3492  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1370/3750]  eta: 0:13:52  Lr: 0.001875  Loss: -0.8226  Acc@1: 75.0000 (70.1769)  Acc@5: 93.7500 (93.7090)  time: 0.3488  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [1380/3750]  eta: 0:13:48  Lr: 0.001875  Loss: -0.8318  Acc@1: 75.0000 (70.2028)  Acc@5: 93.7500 (93.7319)  time: 0.3475  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1390/3750]  eta: 0:13:45  Lr: 0.001875  Loss: -0.7264  Acc@1: 75.0000 (70.2238)  Acc@5: 93.7500 (93.7410)  time: 0.3468  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1400/3750]  eta: 0:13:41  Lr: 0.001875  Loss: -1.2075  Acc@1: 75.0000 (70.2579)  Acc@5: 93.7500 (93.7455)  time: 0.3473  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [1410/3750]  eta: 0:13:38  Lr: 0.001875  Loss: -0.8314  Acc@1: 75.0000 (70.2959)  Acc@5: 93.7500 (93.7500)  time: 0.3466  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1420/3750]  eta: 0:13:34  Lr: 0.001875  Loss: -0.2179  Acc@1: 75.0000 (70.2982)  Acc@5: 93.7500 (93.7588)  time: 0.3453  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1430/3750]  eta: 0:13:31  Lr: 0.001875  Loss: -0.9071  Acc@1: 75.0000 (70.3485)  Acc@5: 93.7500 (93.7675)  time: 0.3467  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [1440/3750]  eta: 0:13:27  Lr: 0.001875  Loss: -0.6230  Acc@1: 75.0000 (70.3244)  Acc@5: 93.7500 (93.7890)  time: 0.3483  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1450/3750]  eta: 0:13:24  Lr: 0.001875  Loss: -0.9964  Acc@1: 68.7500 (70.3782)  Acc@5: 100.0000 (93.8103)  time: 0.3494  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1460/3750]  eta: 0:13:20  Lr: 0.001875  Loss: -0.9433  Acc@1: 81.2500 (70.4398)  Acc@5: 93.7500 (93.8184)  time: 0.3516  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1470/3750]  eta: 0:13:17  Lr: 0.001875  Loss: -0.9210  Acc@1: 81.2500 (70.4835)  Acc@5: 93.7500 (93.8392)  time: 0.3520  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1480/3750]  eta: 0:13:13  Lr: 0.001875  Loss: -0.7316  Acc@1: 81.2500 (70.5478)  Acc@5: 100.0000 (93.8555)  time: 0.3517  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [1490/3750]  eta: 0:13:10  Lr: 0.001875  Loss: -0.4725  Acc@1: 81.2500 (70.5986)  Acc@5: 100.0000 (93.8883)  time: 0.3524  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [1500/3750]  eta: 0:13:06  Lr: 0.001875  Loss: -0.4857  Acc@1: 81.2500 (70.6446)  Acc@5: 100.0000 (93.8999)  time: 0.3543  data: 0.0020  max mem: 2500
Train: Epoch[1/5]  [1510/3750]  eta: 0:13:03  Lr: 0.001875  Loss: -0.8020  Acc@1: 81.2500 (70.7148)  Acc@5: 93.7500 (93.9072)  time: 0.3529  data: 0.0021  max mem: 2500
Train: Epoch[1/5]  [1520/3750]  eta: 0:13:00  Lr: 0.001875  Loss: -0.5210  Acc@1: 75.0000 (70.7429)  Acc@5: 93.7500 (93.9144)  time: 0.3556  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [1530/3750]  eta: 0:12:56  Lr: 0.001875  Loss: -0.4936  Acc@1: 75.0000 (70.7871)  Acc@5: 93.7500 (93.9215)  time: 0.3551  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1540/3750]  eta: 0:12:53  Lr: 0.001875  Loss: -1.1389  Acc@1: 75.0000 (70.8306)  Acc@5: 100.0000 (93.9487)  time: 0.3488  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [1550/3750]  eta: 0:12:49  Lr: 0.001875  Loss: -0.6526  Acc@1: 75.0000 (70.8656)  Acc@5: 100.0000 (93.9555)  time: 0.3484  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [1560/3750]  eta: 0:12:46  Lr: 0.001875  Loss: -1.0721  Acc@1: 75.0000 (70.9281)  Acc@5: 93.7500 (93.9622)  time: 0.3475  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1570/3750]  eta: 0:12:42  Lr: 0.001875  Loss: -1.2920  Acc@1: 75.0000 (70.9659)  Acc@5: 93.7500 (93.9688)  time: 0.3468  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [1580/3750]  eta: 0:12:38  Lr: 0.001875  Loss: -0.6318  Acc@1: 75.0000 (70.9638)  Acc@5: 93.7500 (93.9398)  time: 0.3460  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [1590/3750]  eta: 0:12:35  Lr: 0.001875  Loss: -0.9432  Acc@1: 75.0000 (71.0009)  Acc@5: 93.7500 (93.9582)  time: 0.3453  data: 0.0009  max mem: 2500
Train: Epoch[1/5]  [1600/3750]  eta: 0:12:31  Lr: 0.001875  Loss: -0.5448  Acc@1: 75.0000 (71.0181)  Acc@5: 93.7500 (93.9764)  time: 0.3452  data: 0.0009  max mem: 2500
Train: Epoch[1/5]  [1610/3750]  eta: 0:12:28  Lr: 0.001875  Loss: -0.5785  Acc@1: 75.0000 (71.0312)  Acc@5: 93.7500 (93.9867)  time: 0.3467  data: 0.0010  max mem: 2500
Train: Epoch[1/5]  [1620/3750]  eta: 0:12:24  Lr: 0.001875  Loss: -0.3197  Acc@1: 68.7500 (71.0248)  Acc@5: 93.7500 (93.9775)  time: 0.3503  data: 0.0012  max mem: 2500
Train: Epoch[1/5]  [1630/3750]  eta: 0:12:21  Lr: 0.001875  Loss: -0.2553  Acc@1: 68.7500 (71.0569)  Acc@5: 93.7500 (93.9914)  time: 0.3501  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1640/3750]  eta: 0:12:17  Lr: 0.001875  Loss: -0.6663  Acc@1: 75.0000 (71.0923)  Acc@5: 93.7500 (94.0014)  time: 0.3480  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1650/3750]  eta: 0:12:14  Lr: 0.001875  Loss: -0.9912  Acc@1: 75.0000 (71.1425)  Acc@5: 100.0000 (94.0150)  time: 0.3498  data: 0.0014  max mem: 2500
Train: Epoch[1/5]  [1660/3750]  eta: 0:12:10  Lr: 0.001875  Loss: -0.9270  Acc@1: 75.0000 (71.1883)  Acc@5: 100.0000 (94.0247)  time: 0.3545  data: 0.0018  max mem: 2500
Train: Epoch[1/5]  [1670/3750]  eta: 0:12:07  Lr: 0.001875  Loss: -0.8863  Acc@1: 75.0000 (71.2186)  Acc@5: 93.7500 (94.0305)  time: 0.3576  data: 0.0021  max mem: 2500
Train: Epoch[1/5]  [1680/3750]  eta: 0:12:04  Lr: 0.001875  Loss: -0.8989  Acc@1: 75.0000 (71.2336)  Acc@5: 93.7500 (94.0289)  time: 0.3529  data: 0.0017  max mem: 2500
Train: Epoch[1/5]  [1690/3750]  eta: 0:12:00  Lr: 0.001875  Loss: -1.1148  Acc@1: 75.0000 (71.2559)  Acc@5: 93.7500 (94.0457)  time: 0.3489  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1700/3750]  eta: 0:11:57  Lr: 0.001875  Loss: -0.6946  Acc@1: 81.2500 (71.3183)  Acc@5: 93.7500 (94.0550)  time: 0.3490  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1710/3750]  eta: 0:11:53  Lr: 0.001875  Loss: -1.0558  Acc@1: 81.2500 (71.3800)  Acc@5: 100.0000 (94.0605)  time: 0.3529  data: 0.0042  max mem: 2500
Train: Epoch[1/5]  [1720/3750]  eta: 0:11:50  Lr: 0.001875  Loss: -0.7407  Acc@1: 81.2500 (71.4265)  Acc@5: 100.0000 (94.0732)  time: 0.3530  data: 0.0042  max mem: 2500
Train: Epoch[1/5]  [1730/3750]  eta: 0:11:46  Lr: 0.001875  Loss: -0.4633  Acc@1: 81.2500 (71.4760)  Acc@5: 100.0000 (94.0966)  time: 0.3482  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1740/3750]  eta: 0:11:43  Lr: 0.001875  Loss: -1.0469  Acc@1: 75.0000 (71.5178)  Acc@5: 100.0000 (94.1018)  time: 0.3491  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1750/3750]  eta: 0:11:39  Lr: 0.001875  Loss: -0.7497  Acc@1: 75.0000 (71.5627)  Acc@5: 93.7500 (94.1069)  time: 0.3507  data: 0.0011  max mem: 2500
Train: Epoch[1/5]  [1760/3750]  eta: 0:11:36  Lr: 0.001875  Loss: -0.9813  Acc@1: 75.0000 (71.5680)  Acc@5: 100.0000 (94.1298)  time: 0.3500  data: 0.0011  max mem: 2500
Train: Epoch[1/5]  [1770/3750]  eta: 0:11:32  Lr: 0.001875  Loss: -0.9619  Acc@1: 75.0000 (71.6121)  Acc@5: 100.0000 (94.1382)  time: 0.3473  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1780/3750]  eta: 0:11:28  Lr: 0.001875  Loss: -1.0905  Acc@1: 81.2500 (71.6416)  Acc@5: 100.0000 (94.1536)  time: 0.3456  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [1790/3750]  eta: 0:11:25  Lr: 0.001875  Loss: -0.6395  Acc@1: 81.2500 (71.6883)  Acc@5: 100.0000 (94.1757)  time: 0.3458  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [1800/3750]  eta: 0:11:21  Lr: 0.001875  Loss: -0.9206  Acc@1: 81.2500 (71.7414)  Acc@5: 100.0000 (94.1838)  time: 0.3467  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [1810/3750]  eta: 0:11:18  Lr: 0.001875  Loss: -1.0588  Acc@1: 75.0000 (71.7697)  Acc@5: 93.7500 (94.1779)  time: 0.3467  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [1820/3750]  eta: 0:11:14  Lr: 0.001875  Loss: -0.7833  Acc@1: 75.0000 (71.7875)  Acc@5: 93.7500 (94.1859)  time: 0.3472  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1830/3750]  eta: 0:11:11  Lr: 0.001875  Loss: -1.2364  Acc@1: 75.0000 (71.8221)  Acc@5: 93.7500 (94.1903)  time: 0.3521  data: 0.0013  max mem: 2500
Train: Epoch[1/5]  [1840/3750]  eta: 0:11:07  Lr: 0.001875  Loss: -0.9705  Acc@1: 81.2500 (71.8801)  Acc@5: 100.0000 (94.2117)  time: 0.3529  data: 0.0013  max mem: 2500
Train: Epoch[1/5]  [1850/3750]  eta: 0:11:04  Lr: 0.001875  Loss: -1.0290  Acc@1: 81.2500 (71.8902)  Acc@5: 100.0000 (94.2227)  time: 0.3507  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1860/3750]  eta: 0:11:00  Lr: 0.001875  Loss: -0.3950  Acc@1: 68.7500 (71.8733)  Acc@5: 93.7500 (94.2067)  time: 0.3501  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1870/3750]  eta: 0:10:57  Lr: 0.001875  Loss: -0.9776  Acc@1: 68.7500 (71.9101)  Acc@5: 93.7500 (94.2277)  time: 0.3490  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1880/3750]  eta: 0:10:54  Lr: 0.001875  Loss: -1.0057  Acc@1: 81.2500 (71.9331)  Acc@5: 100.0000 (94.2318)  time: 0.3521  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [1890/3750]  eta: 0:10:50  Lr: 0.001875  Loss: -0.5404  Acc@1: 75.0000 (71.9593)  Acc@5: 93.7500 (94.2325)  time: 0.3515  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [1900/3750]  eta: 0:10:47  Lr: 0.001875  Loss: -1.1513  Acc@1: 81.2500 (72.0180)  Acc@5: 100.0000 (94.2563)  time: 0.3553  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1910/3750]  eta: 0:10:43  Lr: 0.001875  Loss: -0.8994  Acc@1: 81.2500 (72.0271)  Acc@5: 100.0000 (94.2504)  time: 0.3557  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1920/3750]  eta: 0:10:40  Lr: 0.001875  Loss: 0.0164  Acc@1: 75.0000 (72.0491)  Acc@5: 93.7500 (94.2543)  time: 0.3480  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [1930/3750]  eta: 0:10:36  Lr: 0.001875  Loss: -0.7153  Acc@1: 75.0000 (72.0741)  Acc@5: 93.7500 (94.2646)  time: 0.3489  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1940/3750]  eta: 0:10:33  Lr: 0.001875  Loss: -1.0709  Acc@1: 75.0000 (72.0859)  Acc@5: 93.7500 (94.2588)  time: 0.3495  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1950/3750]  eta: 0:10:29  Lr: 0.001875  Loss: -1.1926  Acc@1: 75.0000 (72.1073)  Acc@5: 93.7500 (94.2690)  time: 0.3480  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1960/3750]  eta: 0:10:26  Lr: 0.001875  Loss: -0.6744  Acc@1: 75.0000 (72.1252)  Acc@5: 93.7500 (94.2663)  time: 0.3478  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1970/3750]  eta: 0:10:22  Lr: 0.001875  Loss: -0.6932  Acc@1: 75.0000 (72.1620)  Acc@5: 93.7500 (94.2827)  time: 0.3470  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [1980/3750]  eta: 0:10:19  Lr: 0.001875  Loss: -0.6085  Acc@1: 81.2500 (72.1858)  Acc@5: 93.7500 (94.2706)  time: 0.3462  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [1990/3750]  eta: 0:10:15  Lr: 0.001875  Loss: -0.6995  Acc@1: 75.0000 (72.1873)  Acc@5: 93.7500 (94.2837)  time: 0.3460  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [2000/3750]  eta: 0:10:11  Lr: 0.001875  Loss: -0.6378  Acc@1: 75.0000 (72.2233)  Acc@5: 100.0000 (94.2935)  time: 0.3464  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2010/3750]  eta: 0:10:08  Lr: 0.001875  Loss: -0.7177  Acc@1: 81.2500 (72.2682)  Acc@5: 100.0000 (94.2939)  time: 0.3474  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2020/3750]  eta: 0:10:05  Lr: 0.001875  Loss: -1.2012  Acc@1: 81.2500 (72.3157)  Acc@5: 93.7500 (94.3036)  time: 0.3517  data: 0.0017  max mem: 2500
Train: Epoch[1/5]  [2030/3750]  eta: 0:10:01  Lr: 0.001875  Loss: -0.5864  Acc@1: 75.0000 (72.3227)  Acc@5: 93.7500 (94.3039)  time: 0.3540  data: 0.0017  max mem: 2500
Train: Epoch[1/5]  [2040/3750]  eta: 0:09:58  Lr: 0.001875  Loss: -0.4592  Acc@1: 75.0000 (72.3573)  Acc@5: 93.7500 (94.3196)  time: 0.3535  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [2050/3750]  eta: 0:09:54  Lr: 0.001875  Loss: -1.2004  Acc@1: 81.2500 (72.3915)  Acc@5: 100.0000 (94.3412)  time: 0.3516  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [2060/3750]  eta: 0:09:51  Lr: 0.001875  Loss: -0.7650  Acc@1: 75.0000 (72.3557)  Acc@5: 100.0000 (94.3444)  time: 0.3503  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [2070/3750]  eta: 0:09:47  Lr: 0.001875  Loss: -0.6972  Acc@1: 68.7500 (72.3745)  Acc@5: 93.7500 (94.3536)  time: 0.3509  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [2080/3750]  eta: 0:09:44  Lr: 0.001875  Loss: -0.7994  Acc@1: 75.0000 (72.3931)  Acc@5: 100.0000 (94.3777)  time: 0.3532  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2090/3750]  eta: 0:09:40  Lr: 0.001875  Loss: -0.7107  Acc@1: 75.0000 (72.3906)  Acc@5: 100.0000 (94.3687)  time: 0.3545  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2100/3750]  eta: 0:09:37  Lr: 0.001875  Loss: -0.9106  Acc@1: 75.0000 (72.4000)  Acc@5: 93.7500 (94.3747)  time: 0.3502  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2110/3750]  eta: 0:09:33  Lr: 0.001875  Loss: -0.9124  Acc@1: 75.0000 (72.4360)  Acc@5: 93.7500 (94.3717)  time: 0.3478  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2120/3750]  eta: 0:09:30  Lr: 0.001875  Loss: -0.2711  Acc@1: 75.0000 (72.4452)  Acc@5: 93.7500 (94.3777)  time: 0.3504  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2130/3750]  eta: 0:09:26  Lr: 0.001875  Loss: -0.7996  Acc@1: 81.2500 (72.4836)  Acc@5: 93.7500 (94.3806)  time: 0.3510  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2140/3750]  eta: 0:09:23  Lr: 0.001875  Loss: -0.9061  Acc@1: 81.2500 (72.5070)  Acc@5: 93.7500 (94.3805)  time: 0.3489  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2150/3750]  eta: 0:09:19  Lr: 0.001875  Loss: -1.0467  Acc@1: 75.0000 (72.5186)  Acc@5: 93.7500 (94.3863)  time: 0.3482  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2160/3750]  eta: 0:09:16  Lr: 0.001875  Loss: -0.9176  Acc@1: 75.0000 (72.5330)  Acc@5: 100.0000 (94.4065)  time: 0.3467  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2170/3750]  eta: 0:09:12  Lr: 0.001875  Loss: -1.1448  Acc@1: 75.0000 (72.5587)  Acc@5: 100.0000 (94.4179)  time: 0.3461  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [2180/3750]  eta: 0:09:09  Lr: 0.001875  Loss: -0.5987  Acc@1: 75.0000 (72.5613)  Acc@5: 93.7500 (94.4292)  time: 0.3462  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [2190/3750]  eta: 0:09:05  Lr: 0.001875  Loss: -1.2608  Acc@1: 75.0000 (72.5953)  Acc@5: 100.0000 (94.4489)  time: 0.3468  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [2200/3750]  eta: 0:09:02  Lr: 0.001875  Loss: -1.0262  Acc@1: 81.2500 (72.6374)  Acc@5: 100.0000 (94.4656)  time: 0.3475  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [2210/3750]  eta: 0:08:58  Lr: 0.001875  Loss: -0.7825  Acc@1: 81.2500 (72.6764)  Acc@5: 100.0000 (94.4737)  time: 0.3501  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2220/3750]  eta: 0:08:55  Lr: 0.001875  Loss: -0.7699  Acc@1: 81.2500 (72.6981)  Acc@5: 100.0000 (94.4873)  time: 0.3544  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [2230/3750]  eta: 0:08:51  Lr: 0.001875  Loss: -0.8563  Acc@1: 81.2500 (72.7308)  Acc@5: 100.0000 (94.4980)  time: 0.3546  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2240/3750]  eta: 0:08:48  Lr: 0.001875  Loss: -0.7353  Acc@1: 81.2500 (72.7577)  Acc@5: 100.0000 (94.5114)  time: 0.3522  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2250/3750]  eta: 0:08:44  Lr: 0.001875  Loss: -0.9870  Acc@1: 81.2500 (72.8065)  Acc@5: 100.0000 (94.5219)  time: 0.3567  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [2260/3750]  eta: 0:08:41  Lr: 0.001875  Loss: -0.6137  Acc@1: 81.2500 (72.8162)  Acc@5: 93.7500 (94.5240)  time: 0.3559  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [2270/3750]  eta: 0:08:37  Lr: 0.001875  Loss: -0.6522  Acc@1: 81.2500 (72.8451)  Acc@5: 93.7500 (94.5316)  time: 0.3512  data: 0.0018  max mem: 2500
Train: Epoch[1/5]  [2280/3750]  eta: 0:08:34  Lr: 0.001875  Loss: -0.6215  Acc@1: 81.2500 (72.8600)  Acc@5: 93.7500 (94.5309)  time: 0.3522  data: 0.0018  max mem: 2500
Train: Epoch[1/5]  [2290/3750]  eta: 0:08:30  Lr: 0.001875  Loss: -0.8586  Acc@1: 81.2500 (72.8994)  Acc@5: 93.7500 (94.5439)  time: 0.3494  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2300/3750]  eta: 0:08:27  Lr: 0.001875  Loss: -0.8886  Acc@1: 81.2500 (72.9302)  Acc@5: 93.7500 (94.5513)  time: 0.3474  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2310/3750]  eta: 0:08:23  Lr: 0.001875  Loss: -1.1201  Acc@1: 81.2500 (72.9635)  Acc@5: 93.7500 (94.5586)  time: 0.3475  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2320/3750]  eta: 0:08:20  Lr: 0.001875  Loss: -1.0856  Acc@1: 81.2500 (72.9831)  Acc@5: 93.7500 (94.5659)  time: 0.3476  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2330/3750]  eta: 0:08:16  Lr: 0.001875  Loss: -0.7589  Acc@1: 81.2500 (73.0427)  Acc@5: 100.0000 (94.5812)  time: 0.3488  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2340/3750]  eta: 0:08:13  Lr: 0.001875  Loss: -0.8124  Acc@1: 81.2500 (73.0671)  Acc@5: 100.0000 (94.5883)  time: 0.3488  data: 0.0010  max mem: 2500
Train: Epoch[1/5]  [2350/3750]  eta: 0:08:09  Lr: 0.001875  Loss: -0.9036  Acc@1: 75.0000 (73.0992)  Acc@5: 93.7500 (94.5927)  time: 0.3490  data: 0.0010  max mem: 2500
Train: Epoch[1/5]  [2360/3750]  eta: 0:08:06  Lr: 0.001875  Loss: -1.0417  Acc@1: 81.2500 (73.1390)  Acc@5: 93.7500 (94.5997)  time: 0.3492  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2370/3750]  eta: 0:08:02  Lr: 0.001875  Loss: -1.1550  Acc@1: 81.2500 (73.1574)  Acc@5: 93.7500 (94.6067)  time: 0.3471  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [2380/3750]  eta: 0:07:59  Lr: 0.001875  Loss: -0.6614  Acc@1: 75.0000 (73.1757)  Acc@5: 93.7500 (94.6084)  time: 0.3458  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [2390/3750]  eta: 0:07:55  Lr: 0.001875  Loss: -1.0023  Acc@1: 81.2500 (73.2016)  Acc@5: 93.7500 (94.6152)  time: 0.3478  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2400/3750]  eta: 0:07:52  Lr: 0.001875  Loss: -1.0090  Acc@1: 81.2500 (73.2221)  Acc@5: 93.7500 (94.6246)  time: 0.3497  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [2410/3750]  eta: 0:07:48  Lr: 0.001875  Loss: -0.6896  Acc@1: 81.2500 (73.2476)  Acc@5: 100.0000 (94.6392)  time: 0.3488  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2420/3750]  eta: 0:07:45  Lr: 0.001875  Loss: 0.3719  Acc@1: 75.0000 (73.2290)  Acc@5: 100.0000 (94.6355)  time: 0.3532  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [2430/3750]  eta: 0:07:41  Lr: 0.001875  Loss: -1.1833  Acc@1: 75.0000 (73.2492)  Acc@5: 100.0000 (94.6447)  time: 0.3581  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [2440/3750]  eta: 0:07:38  Lr: 0.001875  Loss: 0.1821  Acc@1: 75.0000 (73.2487)  Acc@5: 100.0000 (94.6513)  time: 0.3554  data: 0.0016  max mem: 2500
Train: Epoch[1/5]  [2450/3750]  eta: 0:07:34  Lr: 0.001875  Loss: -0.8802  Acc@1: 75.0000 (73.2813)  Acc@5: 100.0000 (94.6654)  time: 0.3530  data: 0.0017  max mem: 2500
Train: Epoch[1/5]  [2460/3750]  eta: 0:07:31  Lr: 0.001875  Loss: 0.0265  Acc@1: 75.0000 (73.2781)  Acc@5: 100.0000 (94.6643)  time: 0.3505  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [2470/3750]  eta: 0:07:27  Lr: 0.001875  Loss: -0.7551  Acc@1: 75.0000 (73.3028)  Acc@5: 100.0000 (94.6732)  time: 0.3493  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [2480/3750]  eta: 0:07:24  Lr: 0.001875  Loss: -0.9273  Acc@1: 87.5000 (73.3575)  Acc@5: 100.0000 (94.6796)  time: 0.3491  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [2490/3750]  eta: 0:07:20  Lr: 0.001875  Loss: -0.5678  Acc@1: 87.5000 (73.3792)  Acc@5: 100.0000 (94.6859)  time: 0.3477  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2500/3750]  eta: 0:07:17  Lr: 0.001875  Loss: -0.4818  Acc@1: 81.2500 (73.3981)  Acc@5: 100.0000 (94.6946)  time: 0.3477  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2510/3750]  eta: 0:07:13  Lr: 0.001875  Loss: -1.1485  Acc@1: 75.0000 (73.4195)  Acc@5: 100.0000 (94.7033)  time: 0.3482  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2520/3750]  eta: 0:07:10  Lr: 0.001875  Loss: -0.7935  Acc@1: 81.2500 (73.4480)  Acc@5: 93.7500 (94.7070)  time: 0.3491  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2530/3750]  eta: 0:07:06  Lr: 0.001875  Loss: -0.7833  Acc@1: 81.2500 (73.4517)  Acc@5: 93.7500 (94.7056)  time: 0.3479  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [2540/3750]  eta: 0:07:03  Lr: 0.001875  Loss: -1.1114  Acc@1: 75.0000 (73.4701)  Acc@5: 93.7500 (94.7142)  time: 0.3459  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [2550/3750]  eta: 0:06:59  Lr: 0.001875  Loss: -0.8901  Acc@1: 75.0000 (73.4859)  Acc@5: 93.7500 (94.7153)  time: 0.3454  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [2560/3750]  eta: 0:06:56  Lr: 0.001875  Loss: -0.6724  Acc@1: 75.0000 (73.5089)  Acc@5: 100.0000 (94.7237)  time: 0.3452  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2570/3750]  eta: 0:06:52  Lr: 0.001875  Loss: -0.7624  Acc@1: 75.0000 (73.5195)  Acc@5: 93.7500 (94.7200)  time: 0.3478  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [2580/3750]  eta: 0:06:49  Lr: 0.001875  Loss: -0.8955  Acc@1: 75.0000 (73.5325)  Acc@5: 93.7500 (94.7186)  time: 0.3502  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [2590/3750]  eta: 0:06:45  Lr: 0.001875  Loss: -1.0201  Acc@1: 81.2500 (73.5503)  Acc@5: 93.7500 (94.7221)  time: 0.3485  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [2600/3750]  eta: 0:06:42  Lr: 0.001875  Loss: -0.9436  Acc@1: 81.2500 (73.5823)  Acc@5: 100.0000 (94.7280)  time: 0.3477  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2610/3750]  eta: 0:06:38  Lr: 0.001875  Loss: -0.5397  Acc@1: 81.2500 (73.5877)  Acc@5: 100.0000 (94.7362)  time: 0.3505  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [2620/3750]  eta: 0:06:35  Lr: 0.001875  Loss: -0.8917  Acc@1: 75.0000 (73.5788)  Acc@5: 100.0000 (94.7420)  time: 0.3513  data: 0.0014  max mem: 2500
Train: Epoch[1/5]  [2630/3750]  eta: 0:06:31  Lr: 0.001875  Loss: -0.2820  Acc@1: 75.0000 (73.5842)  Acc@5: 100.0000 (94.7406)  time: 0.3498  data: 0.0014  max mem: 2500
Train: Epoch[1/5]  [2640/3750]  eta: 0:06:28  Lr: 0.001875  Loss: -0.6071  Acc@1: 75.0000 (73.5919)  Acc@5: 93.7500 (94.7321)  time: 0.3513  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [2650/3750]  eta: 0:06:24  Lr: 0.001875  Loss: -1.1872  Acc@1: 75.0000 (73.6232)  Acc@5: 93.7500 (94.7425)  time: 0.3517  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [2660/3750]  eta: 0:06:21  Lr: 0.001875  Loss: -1.3109  Acc@1: 81.2500 (73.6471)  Acc@5: 100.0000 (94.7529)  time: 0.3494  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2670/3750]  eta: 0:06:17  Lr: 0.001875  Loss: -0.8488  Acc@1: 81.2500 (73.6686)  Acc@5: 100.0000 (94.7538)  time: 0.3480  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2680/3750]  eta: 0:06:14  Lr: 0.001875  Loss: -0.5940  Acc@1: 75.0000 (73.6759)  Acc@5: 100.0000 (94.7571)  time: 0.3485  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2690/3750]  eta: 0:06:10  Lr: 0.001875  Loss: -1.2669  Acc@1: 75.0000 (73.6924)  Acc@5: 93.7500 (94.7580)  time: 0.3482  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2700/3750]  eta: 0:06:07  Lr: 0.001875  Loss: -1.0113  Acc@1: 75.0000 (73.7088)  Acc@5: 93.7500 (94.7658)  time: 0.3479  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2710/3750]  eta: 0:06:03  Lr: 0.001875  Loss: -0.6427  Acc@1: 75.0000 (73.7113)  Acc@5: 93.7500 (94.7690)  time: 0.3470  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [2720/3750]  eta: 0:06:00  Lr: 0.001875  Loss: -0.8682  Acc@1: 75.0000 (73.7068)  Acc@5: 93.7500 (94.7653)  time: 0.3452  data: 0.0002  max mem: 2500
Train: Epoch[1/5]  [2730/3750]  eta: 0:05:56  Lr: 0.001875  Loss: -0.4384  Acc@1: 75.0000 (73.7161)  Acc@5: 93.7500 (94.7776)  time: 0.3454  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [2740/3750]  eta: 0:05:53  Lr: 0.001875  Loss: -0.8780  Acc@1: 81.2500 (73.7368)  Acc@5: 100.0000 (94.7784)  time: 0.3462  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [2750/3750]  eta: 0:05:49  Lr: 0.001875  Loss: -0.9219  Acc@1: 81.2500 (73.7482)  Acc@5: 100.0000 (94.7905)  time: 0.3463  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [2760/3750]  eta: 0:05:46  Lr: 0.001875  Loss: -1.1747  Acc@1: 81.2500 (73.7799)  Acc@5: 100.0000 (94.8026)  time: 0.3508  data: 0.0030  max mem: 2500
Train: Epoch[1/5]  [2770/3750]  eta: 0:05:42  Lr: 0.001875  Loss: -0.7841  Acc@1: 81.2500 (73.7911)  Acc@5: 100.0000 (94.8101)  time: 0.3524  data: 0.0030  max mem: 2500
Train: Epoch[1/5]  [2780/3750]  eta: 0:05:39  Lr: 0.001875  Loss: -0.6755  Acc@1: 75.0000 (73.7954)  Acc@5: 100.0000 (94.8175)  time: 0.3505  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2790/3750]  eta: 0:05:35  Lr: 0.001875  Loss: -0.8606  Acc@1: 75.0000 (73.8131)  Acc@5: 93.7500 (94.8159)  time: 0.3509  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [2800/3750]  eta: 0:05:32  Lr: 0.001875  Loss: -0.9888  Acc@1: 81.2500 (73.8375)  Acc@5: 93.7500 (94.8077)  time: 0.3525  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2810/3750]  eta: 0:05:28  Lr: 0.001875  Loss: -1.0479  Acc@1: 81.2500 (73.8483)  Acc@5: 93.7500 (94.8106)  time: 0.3526  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2820/3750]  eta: 0:05:25  Lr: 0.001875  Loss: -0.8223  Acc@1: 75.0000 (73.8546)  Acc@5: 93.7500 (94.8157)  time: 0.3513  data: 0.0012  max mem: 2500
Train: Epoch[1/5]  [2830/3750]  eta: 0:05:21  Lr: 0.001875  Loss: -1.0186  Acc@1: 75.0000 (73.8564)  Acc@5: 93.7500 (94.8163)  time: 0.3532  data: 0.0026  max mem: 2500
Train: Epoch[1/5]  [2840/3750]  eta: 0:05:18  Lr: 0.001875  Loss: -1.2636  Acc@1: 75.0000 (73.8626)  Acc@5: 93.7500 (94.8148)  time: 0.3512  data: 0.0020  max mem: 2500
Train: Epoch[1/5]  [2850/3750]  eta: 0:05:14  Lr: 0.001875  Loss: -0.6669  Acc@1: 75.0000 (73.8907)  Acc@5: 93.7500 (94.8088)  time: 0.3480  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2860/3750]  eta: 0:05:11  Lr: 0.001875  Loss: -0.9543  Acc@1: 81.2500 (73.9274)  Acc@5: 93.7500 (94.8161)  time: 0.3477  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2870/3750]  eta: 0:05:07  Lr: 0.001875  Loss: -0.8613  Acc@1: 81.2500 (73.9355)  Acc@5: 93.7500 (94.8189)  time: 0.3483  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2880/3750]  eta: 0:05:04  Lr: 0.001875  Loss: -1.0548  Acc@1: 81.2500 (73.9522)  Acc@5: 93.7500 (94.8238)  time: 0.3485  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [2890/3750]  eta: 0:05:00  Lr: 0.001875  Loss: -0.6926  Acc@1: 75.0000 (73.9601)  Acc@5: 100.0000 (94.8245)  time: 0.3480  data: 0.0010  max mem: 2500
Train: Epoch[1/5]  [2900/3750]  eta: 0:04:57  Lr: 0.001875  Loss: -0.8076  Acc@1: 81.2500 (73.9853)  Acc@5: 100.0000 (94.8272)  time: 0.3473  data: 0.0014  max mem: 2500
Train: Epoch[1/5]  [2910/3750]  eta: 0:04:53  Lr: 0.001875  Loss: -1.1185  Acc@1: 81.2500 (74.0081)  Acc@5: 100.0000 (94.8428)  time: 0.3466  data: 0.0011  max mem: 2500
Train: Epoch[1/5]  [2920/3750]  eta: 0:04:50  Lr: 0.001875  Loss: -0.8153  Acc@1: 81.2500 (74.0393)  Acc@5: 100.0000 (94.8498)  time: 0.3471  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2930/3750]  eta: 0:04:46  Lr: 0.001875  Loss: -0.3742  Acc@1: 81.2500 (74.0511)  Acc@5: 93.7500 (94.8418)  time: 0.3469  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2940/3750]  eta: 0:04:43  Lr: 0.001875  Loss: -0.9336  Acc@1: 75.0000 (74.0437)  Acc@5: 93.7500 (94.8508)  time: 0.3475  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [2950/3750]  eta: 0:04:39  Lr: 0.001875  Loss: -1.0551  Acc@1: 81.2500 (74.0596)  Acc@5: 100.0000 (94.8513)  time: 0.3501  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2960/3750]  eta: 0:04:36  Lr: 0.001875  Loss: -0.6663  Acc@1: 75.0000 (74.0649)  Acc@5: 100.0000 (94.8582)  time: 0.3521  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2970/3750]  eta: 0:04:32  Lr: 0.001875  Loss: -0.9699  Acc@1: 75.0000 (74.0765)  Acc@5: 100.0000 (94.8649)  time: 0.3514  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2980/3750]  eta: 0:04:29  Lr: 0.001875  Loss: -0.4579  Acc@1: 81.2500 (74.0775)  Acc@5: 100.0000 (94.8717)  time: 0.3516  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [2990/3750]  eta: 0:04:25  Lr: 0.001875  Loss: -0.8931  Acc@1: 81.2500 (74.1077)  Acc@5: 100.0000 (94.8784)  time: 0.3520  data: 0.0013  max mem: 2500
Train: Epoch[1/5]  [3000/3750]  eta: 0:04:22  Lr: 0.001875  Loss: -1.1635  Acc@1: 81.2500 (74.1086)  Acc@5: 93.7500 (94.8788)  time: 0.3539  data: 0.0013  max mem: 2500
Train: Epoch[1/5]  [3010/3750]  eta: 0:04:18  Lr: 0.001875  Loss: -0.7539  Acc@1: 68.7500 (74.1054)  Acc@5: 93.7500 (94.8792)  time: 0.3544  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [3020/3750]  eta: 0:04:15  Lr: 0.001875  Loss: -0.7085  Acc@1: 75.0000 (74.1187)  Acc@5: 93.7500 (94.8858)  time: 0.3496  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [3030/3750]  eta: 0:04:11  Lr: 0.001875  Loss: -0.9027  Acc@1: 75.0000 (74.1257)  Acc@5: 93.7500 (94.8841)  time: 0.3502  data: 0.0015  max mem: 2500
Train: Epoch[1/5]  [3040/3750]  eta: 0:04:08  Lr: 0.001875  Loss: -1.1358  Acc@1: 75.0000 (74.1450)  Acc@5: 93.7500 (94.8948)  time: 0.3504  data: 0.0013  max mem: 2500
Train: Epoch[1/5]  [3050/3750]  eta: 0:04:04  Lr: 0.001875  Loss: -0.8950  Acc@1: 75.0000 (74.1458)  Acc@5: 93.7500 (94.8931)  time: 0.3477  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3060/3750]  eta: 0:04:01  Lr: 0.001875  Loss: -0.8916  Acc@1: 75.0000 (74.1751)  Acc@5: 93.7500 (94.8995)  time: 0.3479  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [3070/3750]  eta: 0:03:57  Lr: 0.001875  Loss: -0.4138  Acc@1: 81.2500 (74.1920)  Acc@5: 100.0000 (94.9100)  time: 0.3479  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [3080/3750]  eta: 0:03:54  Lr: 0.001875  Loss: -0.0471  Acc@1: 81.2500 (74.2149)  Acc@5: 100.0000 (94.9144)  time: 0.3474  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3090/3750]  eta: 0:03:50  Lr: 0.001875  Loss: -0.6661  Acc@1: 75.0000 (74.2195)  Acc@5: 100.0000 (94.9187)  time: 0.3486  data: 0.0009  max mem: 2500
Train: Epoch[1/5]  [3100/3750]  eta: 0:03:47  Lr: 0.001875  Loss: -0.8548  Acc@1: 81.2500 (74.2442)  Acc@5: 100.0000 (94.9250)  time: 0.3488  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [3110/3750]  eta: 0:03:43  Lr: 0.001875  Loss: -1.2466  Acc@1: 75.0000 (74.2486)  Acc@5: 100.0000 (94.9373)  time: 0.3465  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [3120/3750]  eta: 0:03:40  Lr: 0.001875  Loss: -0.7617  Acc@1: 75.0000 (74.2611)  Acc@5: 100.0000 (94.9495)  time: 0.3468  data: 0.0010  max mem: 2500
Train: Epoch[1/5]  [3130/3750]  eta: 0:03:36  Lr: 0.001875  Loss: -0.3845  Acc@1: 75.0000 (74.2614)  Acc@5: 100.0000 (94.9497)  time: 0.3481  data: 0.0009  max mem: 2500
Train: Epoch[1/5]  [3140/3750]  eta: 0:03:33  Lr: 0.001875  Loss: -0.8802  Acc@1: 75.0000 (74.2757)  Acc@5: 93.7500 (94.9518)  time: 0.3474  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [3150/3750]  eta: 0:03:29  Lr: 0.001875  Loss: -0.7036  Acc@1: 75.0000 (74.2661)  Acc@5: 93.7500 (94.9540)  time: 0.3503  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3160/3750]  eta: 0:03:26  Lr: 0.001875  Loss: -0.8926  Acc@1: 75.0000 (74.2645)  Acc@5: 93.7500 (94.9482)  time: 0.3524  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [3170/3750]  eta: 0:03:22  Lr: 0.001875  Loss: -1.2350  Acc@1: 81.2500 (74.2944)  Acc@5: 93.7500 (94.9582)  time: 0.3510  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [3180/3750]  eta: 0:03:19  Lr: 0.001875  Loss: -0.9296  Acc@1: 81.2500 (74.3064)  Acc@5: 100.0000 (94.9642)  time: 0.3513  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [3190/3750]  eta: 0:03:15  Lr: 0.001875  Loss: -0.5205  Acc@1: 75.0000 (74.3125)  Acc@5: 93.7500 (94.9644)  time: 0.3545  data: 0.0012  max mem: 2500
Train: Epoch[1/5]  [3200/3750]  eta: 0:03:12  Lr: 0.001875  Loss: -1.2838  Acc@1: 81.2500 (74.3322)  Acc@5: 100.0000 (94.9742)  time: 0.3542  data: 0.0018  max mem: 2500
Train: Epoch[1/5]  [3210/3750]  eta: 0:03:08  Lr: 0.001875  Loss: -0.7233  Acc@1: 81.2500 (74.3674)  Acc@5: 100.0000 (94.9782)  time: 0.3504  data: 0.0012  max mem: 2500
Train: Epoch[1/5]  [3220/3750]  eta: 0:03:05  Lr: 0.001875  Loss: -0.8635  Acc@1: 81.2500 (74.3674)  Acc@5: 93.7500 (94.9802)  time: 0.3517  data: 0.0016  max mem: 2500
Train: Epoch[1/5]  [3230/3750]  eta: 0:03:01  Lr: 0.001875  Loss: -0.6322  Acc@1: 75.0000 (74.3771)  Acc@5: 93.7500 (94.9803)  time: 0.3574  data: 0.0015  max mem: 2500
Train: Epoch[1/5]  [3240/3750]  eta: 0:02:58  Lr: 0.001875  Loss: -0.3785  Acc@1: 75.0000 (74.3983)  Acc@5: 93.7500 (94.9842)  time: 0.3540  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [3250/3750]  eta: 0:02:54  Lr: 0.001875  Loss: -0.8750  Acc@1: 81.2500 (74.4213)  Acc@5: 100.0000 (94.9900)  time: 0.3490  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3260/3750]  eta: 0:02:51  Lr: 0.001875  Loss: -1.0499  Acc@1: 81.2500 (74.4346)  Acc@5: 100.0000 (94.9996)  time: 0.3486  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [3270/3750]  eta: 0:02:47  Lr: 0.001875  Loss: -0.9506  Acc@1: 75.0000 (74.4497)  Acc@5: 100.0000 (95.0034)  time: 0.3476  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [3280/3750]  eta: 0:02:44  Lr: 0.001875  Loss: -0.8139  Acc@1: 81.2500 (74.4647)  Acc@5: 100.0000 (95.0130)  time: 0.3500  data: 0.0013  max mem: 2500
Train: Epoch[1/5]  [3290/3750]  eta: 0:02:40  Lr: 0.001875  Loss: -1.0343  Acc@1: 75.0000 (74.4796)  Acc@5: 100.0000 (95.0167)  time: 0.3484  data: 0.0011  max mem: 2500
Train: Epoch[1/5]  [3300/3750]  eta: 0:02:37  Lr: 0.001875  Loss: -0.8229  Acc@1: 81.2500 (74.5077)  Acc@5: 93.7500 (95.0167)  time: 0.3454  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [3310/3750]  eta: 0:02:33  Lr: 0.001875  Loss: -0.6748  Acc@1: 81.2500 (74.5111)  Acc@5: 93.7500 (95.0204)  time: 0.3475  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [3320/3750]  eta: 0:02:30  Lr: 0.001875  Loss: -0.5416  Acc@1: 75.0000 (74.5107)  Acc@5: 93.7500 (95.0184)  time: 0.3489  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [3330/3750]  eta: 0:02:26  Lr: 0.001875  Loss: -1.1334  Acc@1: 81.2500 (74.5290)  Acc@5: 93.7500 (95.0221)  time: 0.3497  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [3340/3750]  eta: 0:02:23  Lr: 0.001875  Loss: -0.9825  Acc@1: 81.2500 (74.5379)  Acc@5: 100.0000 (95.0258)  time: 0.3509  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [3350/3750]  eta: 0:02:19  Lr: 0.001875  Loss: -1.0669  Acc@1: 75.0000 (74.5486)  Acc@5: 100.0000 (95.0239)  time: 0.3533  data: 0.0018  max mem: 2500
Train: Epoch[1/5]  [3360/3750]  eta: 0:02:16  Lr: 0.001875  Loss: -0.7930  Acc@1: 81.2500 (74.5686)  Acc@5: 93.7500 (95.0294)  time: 0.3556  data: 0.0018  max mem: 2500
Train: Epoch[1/5]  [3370/3750]  eta: 0:02:12  Lr: 0.001875  Loss: -1.3340  Acc@1: 81.2500 (74.5884)  Acc@5: 100.0000 (95.0349)  time: 0.3566  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [3380/3750]  eta: 0:02:09  Lr: 0.001875  Loss: -0.7658  Acc@1: 81.2500 (74.6081)  Acc@5: 100.0000 (95.0421)  time: 0.3559  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [3390/3750]  eta: 0:02:05  Lr: 0.001875  Loss: -1.1720  Acc@1: 81.2500 (74.6166)  Acc@5: 100.0000 (95.0476)  time: 0.3514  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [3400/3750]  eta: 0:02:02  Lr: 0.001875  Loss: -0.4507  Acc@1: 75.0000 (74.6288)  Acc@5: 93.7500 (95.0511)  time: 0.3496  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [3410/3750]  eta: 0:01:58  Lr: 0.001875  Loss: -1.0189  Acc@1: 75.0000 (74.6427)  Acc@5: 100.0000 (95.0528)  time: 0.3549  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [3420/3750]  eta: 0:01:55  Lr: 0.001875  Loss: -0.8164  Acc@1: 81.2500 (74.6620)  Acc@5: 100.0000 (95.0636)  time: 0.3543  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [3430/3750]  eta: 0:01:51  Lr: 0.001875  Loss: -0.5113  Acc@1: 81.2500 (74.6703)  Acc@5: 100.0000 (95.0707)  time: 0.3483  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [3440/3750]  eta: 0:01:48  Lr: 0.001875  Loss: -0.8105  Acc@1: 75.0000 (74.6840)  Acc@5: 100.0000 (95.0741)  time: 0.3506  data: 0.0018  max mem: 2500
Train: Epoch[1/5]  [3450/3750]  eta: 0:01:44  Lr: 0.001875  Loss: -0.6421  Acc@1: 81.2500 (74.7066)  Acc@5: 93.7500 (95.0739)  time: 0.3516  data: 0.0019  max mem: 2500
Train: Epoch[1/5]  [3460/3750]  eta: 0:01:41  Lr: 0.001875  Loss: -1.0405  Acc@1: 75.0000 (74.7020)  Acc@5: 93.7500 (95.0755)  time: 0.3497  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [3470/3750]  eta: 0:01:37  Lr: 0.001875  Loss: -1.1508  Acc@1: 75.0000 (74.7191)  Acc@5: 100.0000 (95.0825)  time: 0.3484  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [3480/3750]  eta: 0:01:34  Lr: 0.001875  Loss: -0.7980  Acc@1: 75.0000 (74.7253)  Acc@5: 100.0000 (95.0822)  time: 0.3463  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [3490/3750]  eta: 0:01:30  Lr: 0.001875  Loss: -1.2650  Acc@1: 81.2500 (74.7350)  Acc@5: 93.7500 (95.0820)  time: 0.3461  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [3500/3750]  eta: 0:01:27  Lr: 0.001875  Loss: -1.0275  Acc@1: 81.2500 (74.7483)  Acc@5: 100.0000 (95.0943)  time: 0.3469  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [3510/3750]  eta: 0:01:23  Lr: 0.001875  Loss: -1.2478  Acc@1: 81.2500 (74.7632)  Acc@5: 100.0000 (95.1011)  time: 0.3466  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [3520/3750]  eta: 0:01:20  Lr: 0.001875  Loss: -0.9441  Acc@1: 81.2500 (74.7817)  Acc@5: 100.0000 (95.1079)  time: 0.3467  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [3530/3750]  eta: 0:01:16  Lr: 0.001875  Loss: -0.2626  Acc@1: 81.2500 (74.7770)  Acc@5: 100.0000 (95.1058)  time: 0.3473  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [3540/3750]  eta: 0:01:13  Lr: 0.001875  Loss: -0.7231  Acc@1: 68.7500 (74.7917)  Acc@5: 100.0000 (95.1126)  time: 0.3480  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [3550/3750]  eta: 0:01:09  Lr: 0.001875  Loss: -0.6737  Acc@1: 75.0000 (74.7853)  Acc@5: 100.0000 (95.1176)  time: 0.3493  data: 0.0012  max mem: 2500
Train: Epoch[1/5]  [3560/3750]  eta: 0:01:06  Lr: 0.001875  Loss: -1.2841  Acc@1: 75.0000 (74.7876)  Acc@5: 100.0000 (95.1260)  time: 0.3549  data: 0.0012  max mem: 2500
Train: Epoch[1/5]  [3570/3750]  eta: 0:01:02  Lr: 0.001875  Loss: -1.2188  Acc@1: 81.2500 (74.8267)  Acc@5: 100.0000 (95.1362)  time: 0.3573  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [3580/3750]  eta: 0:00:59  Lr: 0.001875  Loss: -0.5534  Acc@1: 87.5000 (74.8412)  Acc@5: 100.0000 (95.1393)  time: 0.3531  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [3590/3750]  eta: 0:00:55  Lr: 0.001875  Loss: -1.0370  Acc@1: 81.2500 (74.8677)  Acc@5: 100.0000 (95.1424)  time: 0.3524  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [3600/3750]  eta: 0:00:52  Lr: 0.001875  Loss: -0.2912  Acc@1: 81.2500 (74.8854)  Acc@5: 100.0000 (95.1454)  time: 0.3508  data: 0.0012  max mem: 2500
Train: Epoch[1/5]  [3610/3750]  eta: 0:00:48  Lr: 0.001875  Loss: -1.2511  Acc@1: 81.2500 (74.9065)  Acc@5: 100.0000 (95.1537)  time: 0.3521  data: 0.0024  max mem: 2500
Train: Epoch[1/5]  [3620/3750]  eta: 0:00:45  Lr: 0.001875  Loss: -0.5948  Acc@1: 81.2500 (74.9102)  Acc@5: 100.0000 (95.1515)  time: 0.3526  data: 0.0018  max mem: 2500
Train: Epoch[1/5]  [3630/3750]  eta: 0:00:41  Lr: 0.001875  Loss: -0.7156  Acc@1: 81.2500 (74.9191)  Acc@5: 93.7500 (95.1511)  time: 0.3491  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3640/3750]  eta: 0:00:38  Lr: 0.001875  Loss: -0.8070  Acc@1: 75.0000 (74.9210)  Acc@5: 93.7500 (95.1473)  time: 0.3488  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [3650/3750]  eta: 0:00:34  Lr: 0.001875  Loss: -1.2138  Acc@1: 75.0000 (74.9349)  Acc@5: 93.7500 (95.1452)  time: 0.3490  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [3660/3750]  eta: 0:00:31  Lr: 0.001875  Loss: -0.9131  Acc@1: 75.0000 (74.9317)  Acc@5: 93.7500 (95.1431)  time: 0.3498  data: 0.0012  max mem: 2500
Train: Epoch[1/5]  [3670/3750]  eta: 0:00:27  Lr: 0.001875  Loss: 0.1000  Acc@1: 68.7500 (74.9234)  Acc@5: 93.7500 (95.1410)  time: 0.3490  data: 0.0011  max mem: 2500
Train: Epoch[1/5]  [3680/3750]  eta: 0:00:24  Lr: 0.001875  Loss: -0.3230  Acc@1: 81.2500 (74.9270)  Acc@5: 93.7500 (95.1406)  time: 0.3483  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3690/3750]  eta: 0:00:20  Lr: 0.001875  Loss: -0.7970  Acc@1: 81.2500 (74.9357)  Acc@5: 93.7500 (95.1436)  time: 0.3501  data: 0.0034  max mem: 2500
Train: Epoch[1/5]  [3700/3750]  eta: 0:00:17  Lr: 0.001875  Loss: -0.8730  Acc@1: 81.2500 (74.9561)  Acc@5: 100.0000 (95.1500)  time: 0.3492  data: 0.0034  max mem: 2500
Train: Epoch[1/5]  [3710/3750]  eta: 0:00:13  Lr: 0.001875  Loss: -0.6481  Acc@1: 81.2500 (74.9680)  Acc@5: 100.0000 (95.1613)  time: 0.3467  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3720/3750]  eta: 0:00:10  Lr: 0.001875  Loss: -1.1241  Acc@1: 75.0000 (74.9681)  Acc@5: 100.0000 (95.1492)  time: 0.3489  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [3730/3750]  eta: 0:00:06  Lr: 0.001875  Loss: -1.1016  Acc@1: 75.0000 (74.9816)  Acc@5: 93.7500 (95.1555)  time: 0.3507  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [3740/3750]  eta: 0:00:03  Lr: 0.001875  Loss: -0.6625  Acc@1: 75.0000 (74.9933)  Acc@5: 93.7500 (95.1517)  time: 0.3523  data: 0.0016  max mem: 2500
Train: Epoch[1/5]  [3749/3750]  eta: 0:00:00  Lr: 0.001875  Loss: -0.3826  Acc@1: 81.2500 (75.0067)  Acc@5: 93.7500 (95.1550)  time: 0.3529  data: 0.0018  max mem: 2500
Train: Epoch[1/5] Total time: 0:21:52 (0.3500 s / it)
{0: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 1: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 2: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 3: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 4: {0: 0, 1: 60000, 2: 0, 3: 0, 4: 0}, 5: {0: 0, 1: 60000, 2: 0, 3: 0, 4: 0}, 6: {0: 0, 1: 60000, 2: 0, 3: 0, 4: 0}, 7: {0: 0, 1: 60000, 2: 0, 3: 0, 4: 0}, 8: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 9: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 10: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 11: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 12: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 13: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 14: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 15: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 16: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 17: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 18: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 19: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}}
Averaged stats: Lr: 0.001875  Loss: -0.3826  Acc@1: 81.2500 (75.0067)  Acc@5: 93.7500 (95.1550)
Train: Epoch[2/5]  [   0/3750]  eta: 0:56:45  Lr: 0.001875  Loss: -1.1475  Acc@1: 93.7500 (93.7500)  Acc@5: 93.7500 (93.7500)  time: 0.9081  data: 0.5559  max mem: 2500
Train: Epoch[2/5]  [  10/3750]  eta: 0:25:08  Lr: 0.001875  Loss: -0.8605  Acc@1: 81.2500 (80.1136)  Acc@5: 100.0000 (97.1591)  time: 0.4032  data: 0.0523  max mem: 2500
Train: Epoch[2/5]  [  20/3750]  eta: 0:23:26  Lr: 0.001875  Loss: -0.9635  Acc@1: 81.2500 (81.8452)  Acc@5: 100.0000 (97.6190)  time: 0.3505  data: 0.0015  max mem: 2500
Train: Epoch[2/5]  [  30/3750]  eta: 0:22:52  Lr: 0.001875  Loss: -0.9115  Acc@1: 81.2500 (81.4516)  Acc@5: 100.0000 (96.9758)  time: 0.3503  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [  40/3750]  eta: 0:22:32  Lr: 0.001875  Loss: -1.0743  Acc@1: 81.2500 (81.8598)  Acc@5: 93.7500 (96.9512)  time: 0.3513  data: 0.0019  max mem: 2500
Train: Epoch[2/5]  [  50/3750]  eta: 0:22:16  Lr: 0.001875  Loss: -0.3769  Acc@1: 81.2500 (80.7598)  Acc@5: 93.7500 (96.5686)  time: 0.3492  data: 0.0019  max mem: 2500
Train: Epoch[2/5]  [  60/3750]  eta: 0:22:05  Lr: 0.001875  Loss: -0.6655  Acc@1: 75.0000 (79.7131)  Acc@5: 93.7500 (96.1066)  time: 0.3483  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [  70/3750]  eta: 0:21:55  Lr: 0.001875  Loss: -0.9727  Acc@1: 75.0000 (80.1937)  Acc@5: 93.7500 (95.8627)  time: 0.3480  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [  80/3750]  eta: 0:21:49  Lr: 0.001875  Loss: -0.9257  Acc@1: 87.5000 (80.7099)  Acc@5: 93.7500 (96.0648)  time: 0.3493  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [  90/3750]  eta: 0:21:41  Lr: 0.001875  Loss: -0.8436  Acc@1: 81.2500 (80.4258)  Acc@5: 100.0000 (96.0852)  time: 0.3491  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 100/3750]  eta: 0:21:35  Lr: 0.001875  Loss: -0.7425  Acc@1: 81.2500 (80.5693)  Acc@5: 100.0000 (96.2871)  time: 0.3479  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 110/3750]  eta: 0:21:29  Lr: 0.001875  Loss: -0.4615  Acc@1: 81.2500 (80.1239)  Acc@5: 100.0000 (96.1149)  time: 0.3482  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 120/3750]  eta: 0:21:24  Lr: 0.001875  Loss: -0.8750  Acc@1: 75.0000 (79.9587)  Acc@5: 93.7500 (95.9194)  time: 0.3474  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 130/3750]  eta: 0:21:18  Lr: 0.001875  Loss: -1.1021  Acc@1: 75.0000 (79.5802)  Acc@5: 93.7500 (95.9924)  time: 0.3471  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [ 140/3750]  eta: 0:21:13  Lr: 0.001875  Loss: -0.7035  Acc@1: 75.0000 (79.1667)  Acc@5: 93.7500 (95.8777)  time: 0.3478  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [ 150/3750]  eta: 0:21:08  Lr: 0.001875  Loss: -0.6970  Acc@1: 81.2500 (79.3874)  Acc@5: 93.7500 (95.8609)  time: 0.3466  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [ 160/3750]  eta: 0:21:04  Lr: 0.001875  Loss: -1.0568  Acc@1: 81.2500 (79.5419)  Acc@5: 93.7500 (95.9239)  time: 0.3472  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 170/3750]  eta: 0:21:00  Lr: 0.001875  Loss: -0.8025  Acc@1: 81.2500 (79.6418)  Acc@5: 93.7500 (95.9430)  time: 0.3500  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 180/3750]  eta: 0:20:57  Lr: 0.001875  Loss: -1.1957  Acc@1: 81.2500 (79.6271)  Acc@5: 93.7500 (95.8218)  time: 0.3523  data: 0.0009  max mem: 2500
Train: Epoch[2/5]  [ 190/3750]  eta: 0:20:53  Lr: 0.001875  Loss: -1.1239  Acc@1: 81.2500 (79.7775)  Acc@5: 100.0000 (95.9097)  time: 0.3527  data: 0.0010  max mem: 2500
Train: Epoch[2/5]  [ 200/3750]  eta: 0:20:49  Lr: 0.001875  Loss: -1.1511  Acc@1: 81.2500 (79.7886)  Acc@5: 100.0000 (96.0199)  time: 0.3513  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [ 210/3750]  eta: 0:20:46  Lr: 0.001875  Loss: -1.1376  Acc@1: 81.2500 (79.7393)  Acc@5: 100.0000 (96.0012)  time: 0.3511  data: 0.0015  max mem: 2500
Train: Epoch[2/5]  [ 220/3750]  eta: 0:20:42  Lr: 0.001875  Loss: -1.1235  Acc@1: 75.0000 (79.6380)  Acc@5: 100.0000 (96.0973)  time: 0.3503  data: 0.0014  max mem: 2500
Train: Epoch[2/5]  [ 230/3750]  eta: 0:20:38  Lr: 0.001875  Loss: -0.8688  Acc@1: 75.0000 (79.5996)  Acc@5: 100.0000 (96.1310)  time: 0.3493  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 240/3750]  eta: 0:20:35  Lr: 0.001875  Loss: -1.0353  Acc@1: 75.0000 (79.6421)  Acc@5: 100.0000 (96.1359)  time: 0.3532  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [ 250/3750]  eta: 0:20:32  Lr: 0.001875  Loss: -0.7615  Acc@1: 81.2500 (79.6813)  Acc@5: 100.0000 (96.1902)  time: 0.3576  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [ 260/3750]  eta: 0:20:28  Lr: 0.001875  Loss: -0.9092  Acc@1: 81.2500 (79.5977)  Acc@5: 100.0000 (96.1446)  time: 0.3527  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [ 270/3750]  eta: 0:20:24  Lr: 0.001875  Loss: -1.2272  Acc@1: 81.2500 (79.6356)  Acc@5: 93.7500 (96.1485)  time: 0.3477  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 280/3750]  eta: 0:20:20  Lr: 0.001875  Loss: -0.9736  Acc@1: 81.2500 (79.6263)  Acc@5: 100.0000 (96.2189)  time: 0.3477  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 290/3750]  eta: 0:20:17  Lr: 0.001875  Loss: -0.6799  Acc@1: 81.2500 (79.5962)  Acc@5: 100.0000 (96.1985)  time: 0.3497  data: 0.0009  max mem: 2500
Train: Epoch[2/5]  [ 300/3750]  eta: 0:20:13  Lr: 0.001875  Loss: -1.2559  Acc@1: 81.2500 (79.6719)  Acc@5: 93.7500 (96.1586)  time: 0.3503  data: 0.0010  max mem: 2500
Train: Epoch[2/5]  [ 310/3750]  eta: 0:20:09  Lr: 0.001875  Loss: -1.1238  Acc@1: 81.2500 (79.7026)  Acc@5: 93.7500 (96.2018)  time: 0.3470  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 320/3750]  eta: 0:20:05  Lr: 0.001875  Loss: -0.5770  Acc@1: 81.2500 (79.5755)  Acc@5: 100.0000 (96.1643)  time: 0.3466  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [ 330/3750]  eta: 0:20:01  Lr: 0.001875  Loss: -0.8645  Acc@1: 81.2500 (79.5317)  Acc@5: 93.7500 (96.0536)  time: 0.3481  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [ 340/3750]  eta: 0:19:57  Lr: 0.001875  Loss: -0.7154  Acc@1: 81.2500 (79.5455)  Acc@5: 93.7500 (96.0044)  time: 0.3459  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [ 350/3750]  eta: 0:19:53  Lr: 0.001875  Loss: -0.8804  Acc@1: 75.0000 (79.3625)  Acc@5: 100.0000 (96.0648)  time: 0.3448  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 360/3750]  eta: 0:19:49  Lr: 0.001875  Loss: -0.5441  Acc@1: 75.0000 (79.2936)  Acc@5: 93.7500 (95.9488)  time: 0.3481  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [ 370/3750]  eta: 0:19:46  Lr: 0.001875  Loss: -1.3576  Acc@1: 81.2500 (79.2621)  Acc@5: 93.7500 (96.0243)  time: 0.3540  data: 0.0014  max mem: 2500
Train: Epoch[2/5]  [ 380/3750]  eta: 0:19:42  Lr: 0.001875  Loss: -1.0853  Acc@1: 81.2500 (79.3799)  Acc@5: 100.0000 (96.0302)  time: 0.3528  data: 0.0013  max mem: 2500
Train: Epoch[2/5]  [ 390/3750]  eta: 0:19:38  Lr: 0.001875  Loss: -1.2003  Acc@1: 87.5000 (79.5396)  Acc@5: 100.0000 (96.0997)  time: 0.3473  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 400/3750]  eta: 0:19:35  Lr: 0.001875  Loss: -1.1489  Acc@1: 81.2500 (79.6135)  Acc@5: 100.0000 (96.1035)  time: 0.3481  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [ 410/3750]  eta: 0:19:31  Lr: 0.001875  Loss: -0.4406  Acc@1: 81.2500 (79.7141)  Acc@5: 100.0000 (96.1223)  time: 0.3509  data: 0.0014  max mem: 2500
Train: Epoch[2/5]  [ 420/3750]  eta: 0:19:28  Lr: 0.001875  Loss: -1.0101  Acc@1: 81.2500 (79.6615)  Acc@5: 100.0000 (96.1253)  time: 0.3530  data: 0.0015  max mem: 2500
Train: Epoch[2/5]  [ 430/3750]  eta: 0:19:25  Lr: 0.001875  Loss: -0.5054  Acc@1: 81.2500 (79.6549)  Acc@5: 100.0000 (96.1282)  time: 0.3525  data: 0.0012  max mem: 2500
Train: Epoch[2/5]  [ 440/3750]  eta: 0:19:22  Lr: 0.001875  Loss: -1.2384  Acc@1: 81.2500 (79.7619)  Acc@5: 100.0000 (96.1168)  time: 0.3543  data: 0.0017  max mem: 2500
Train: Epoch[2/5]  [ 450/3750]  eta: 0:19:18  Lr: 0.001875  Loss: -0.7503  Acc@1: 81.2500 (79.7395)  Acc@5: 93.7500 (96.0920)  time: 0.3527  data: 0.0011  max mem: 2500
Train: Epoch[2/5]  [ 460/3750]  eta: 0:19:15  Lr: 0.001875  Loss: -1.3297  Acc@1: 81.2500 (79.8943)  Acc@5: 100.0000 (96.1226)  time: 0.3511  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 470/3750]  eta: 0:19:11  Lr: 0.001875  Loss: -1.0307  Acc@1: 81.2500 (79.8567)  Acc@5: 100.0000 (96.1385)  time: 0.3507  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 480/3750]  eta: 0:19:07  Lr: 0.001875  Loss: -0.8623  Acc@1: 81.2500 (79.9246)  Acc@5: 100.0000 (96.1538)  time: 0.3479  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 490/3750]  eta: 0:19:03  Lr: 0.001875  Loss: -0.5310  Acc@1: 81.2500 (79.8116)  Acc@5: 93.7500 (96.1049)  time: 0.3479  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 500/3750]  eta: 0:19:00  Lr: 0.001875  Loss: -1.4069  Acc@1: 75.0000 (79.8653)  Acc@5: 93.7500 (96.0953)  time: 0.3467  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [ 510/3750]  eta: 0:18:56  Lr: 0.001875  Loss: -0.4940  Acc@1: 75.0000 (79.7211)  Acc@5: 93.7500 (96.0861)  time: 0.3484  data: 0.0017  max mem: 2500
Train: Epoch[2/5]  [ 520/3750]  eta: 0:18:52  Lr: 0.001875  Loss: -0.8368  Acc@1: 75.0000 (79.7265)  Acc@5: 100.0000 (96.1132)  time: 0.3482  data: 0.0017  max mem: 2500
Train: Epoch[2/5]  [ 530/3750]  eta: 0:18:49  Lr: 0.001875  Loss: -0.3314  Acc@1: 81.2500 (79.6610)  Acc@5: 100.0000 (96.1158)  time: 0.3463  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 540/3750]  eta: 0:18:45  Lr: 0.001875  Loss: -1.3238  Acc@1: 75.0000 (79.6673)  Acc@5: 100.0000 (96.1414)  time: 0.3504  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [ 550/3750]  eta: 0:18:42  Lr: 0.001875  Loss: -0.6568  Acc@1: 81.2500 (79.7074)  Acc@5: 100.0000 (96.1661)  time: 0.3574  data: 0.0014  max mem: 2500
Train: Epoch[2/5]  [ 560/3750]  eta: 0:18:40  Lr: 0.001875  Loss: -0.3588  Acc@1: 81.2500 (79.7906)  Acc@5: 100.0000 (96.1453)  time: 0.3653  data: 0.0013  max mem: 2500
Train: Epoch[2/5]  [ 570/3750]  eta: 0:18:36  Lr: 0.001875  Loss: -1.2107  Acc@1: 81.2500 (79.8161)  Acc@5: 100.0000 (96.1581)  time: 0.3588  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 580/3750]  eta: 0:18:33  Lr: 0.001875  Loss: -0.9295  Acc@1: 75.0000 (79.7655)  Acc@5: 100.0000 (96.1596)  time: 0.3503  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [ 590/3750]  eta: 0:18:30  Lr: 0.001875  Loss: -1.0920  Acc@1: 75.0000 (79.7166)  Acc@5: 93.7500 (96.1189)  time: 0.3573  data: 0.0013  max mem: 2500
Train: Epoch[2/5]  [ 600/3750]  eta: 0:18:44  Lr: 0.001875  Loss: -0.8658  Acc@1: 81.2500 (79.7733)  Acc@5: 93.7500 (96.1106)  time: 0.5296  data: 0.0016  max mem: 2500
Train: Epoch[2/5]  [ 610/3750]  eta: 0:19:01  Lr: 0.001875  Loss: -1.2772  Acc@1: 81.2500 (79.7054)  Acc@5: 100.0000 (96.1027)  time: 0.7232  data: 0.0009  max mem: 2500
Train: Epoch[2/5]  [ 620/3750]  eta: 0:19:17  Lr: 0.001875  Loss: -1.0444  Acc@1: 75.0000 (79.6800)  Acc@5: 100.0000 (96.1252)  time: 0.7500  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [ 630/3750]  eta: 0:19:32  Lr: 0.001875  Loss: -0.9484  Acc@1: 75.0000 (79.6157)  Acc@5: 100.0000 (96.1272)  time: 0.7513  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 640/3750]  eta: 0:19:47  Lr: 0.001875  Loss: -1.1388  Acc@1: 75.0000 (79.6314)  Acc@5: 93.7500 (96.1388)  time: 0.7524  data: 0.0011  max mem: 2500
Train: Epoch[2/5]  [ 650/3750]  eta: 0:20:00  Lr: 0.001875  Loss: -0.9933  Acc@1: 81.2500 (79.6659)  Acc@5: 100.0000 (96.1502)  time: 0.7477  data: 0.0011  max mem: 2500
Train: Epoch[2/5]  [ 660/3750]  eta: 0:20:13  Lr: 0.001875  Loss: -0.9205  Acc@1: 81.2500 (79.7750)  Acc@5: 100.0000 (96.1517)  time: 0.7429  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 670/3750]  eta: 0:20:25  Lr: 0.001875  Loss: -1.2159  Acc@1: 81.2500 (79.7969)  Acc@5: 100.0000 (96.1718)  time: 0.7454  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 680/3750]  eta: 0:20:37  Lr: 0.001875  Loss: -0.6077  Acc@1: 75.0000 (79.7265)  Acc@5: 93.7500 (96.1362)  time: 0.7539  data: 0.0018  max mem: 2500
Train: Epoch[2/5]  [ 690/3750]  eta: 0:20:49  Lr: 0.001875  Loss: -0.3483  Acc@1: 75.0000 (79.7214)  Acc@5: 93.7500 (96.1107)  time: 0.7536  data: 0.0018  max mem: 2500
Train: Epoch[2/5]  [ 700/3750]  eta: 0:21:00  Lr: 0.001875  Loss: -1.3423  Acc@1: 81.2500 (79.8502)  Acc@5: 100.0000 (96.1305)  time: 0.7528  data: 0.0015  max mem: 2500
Train: Epoch[2/5]  [ 710/3750]  eta: 0:21:04  Lr: 0.001875  Loss: -0.9686  Acc@1: 87.5000 (79.9139)  Acc@5: 100.0000 (96.1586)  time: 0.6849  data: 0.0014  max mem: 2500
Train: Epoch[2/5]  [ 720/3750]  eta: 0:20:57  Lr: 0.001875  Loss: -0.7451  Acc@1: 81.2500 (79.8977)  Acc@5: 100.0000 (96.1425)  time: 0.4795  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 730/3750]  eta: 0:20:50  Lr: 0.001875  Loss: -0.7813  Acc@1: 81.2500 (79.8906)  Acc@5: 93.7500 (96.1354)  time: 0.3500  data: 0.0011  max mem: 2500
Train: Epoch[2/5]  [ 740/3750]  eta: 0:20:44  Lr: 0.001875  Loss: -1.0179  Acc@1: 81.2500 (79.8667)  Acc@5: 93.7500 (96.0948)  time: 0.3508  data: 0.0011  max mem: 2500
Train: Epoch[2/5]  [ 750/3750]  eta: 0:20:37  Lr: 0.001875  Loss: -0.7622  Acc@1: 75.0000 (79.8186)  Acc@5: 93.7500 (96.0802)  time: 0.3490  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 760/3750]  eta: 0:20:31  Lr: 0.001875  Loss: -0.7607  Acc@1: 75.0000 (79.8210)  Acc@5: 100.0000 (96.0907)  time: 0.3559  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [ 770/3750]  eta: 0:20:24  Lr: 0.001875  Loss: -1.0106  Acc@1: 81.2500 (79.8314)  Acc@5: 100.0000 (96.1008)  time: 0.3555  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [ 780/3750]  eta: 0:20:18  Lr: 0.001875  Loss: -1.0679  Acc@1: 81.2500 (79.8576)  Acc@5: 93.7500 (96.0787)  time: 0.3488  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [ 790/3750]  eta: 0:20:11  Lr: 0.001875  Loss: -0.9572  Acc@1: 81.2500 (79.8752)  Acc@5: 93.7500 (96.0888)  time: 0.3497  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [ 800/3750]  eta: 0:20:15  Lr: 0.001875  Loss: -0.9804  Acc@1: 81.2500 (79.9001)  Acc@5: 100.0000 (96.1220)  time: 0.4847  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [ 810/3750]  eta: 0:20:23  Lr: 0.001875  Loss: -0.6127  Acc@1: 75.0000 (79.8474)  Acc@5: 100.0000 (96.0928)  time: 0.6882  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [ 820/3750]  eta: 0:20:31  Lr: 0.001875  Loss: -0.8746  Acc@1: 75.0000 (79.8112)  Acc@5: 93.7500 (96.0947)  time: 0.7503  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [ 830/3750]  eta: 0:20:38  Lr: 0.001875  Loss: -0.8045  Acc@1: 81.2500 (79.7834)  Acc@5: 93.7500 (96.0740)  time: 0.7435  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [ 840/3750]  eta: 0:20:39  Lr: 0.001875  Loss: -0.9652  Acc@1: 81.2500 (79.7711)  Acc@5: 93.7500 (96.0984)  time: 0.6606  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [ 850/3750]  eta: 0:20:32  Lr: 0.001875  Loss: -1.0842  Acc@1: 81.2500 (79.7885)  Acc@5: 100.0000 (96.1149)  time: 0.4622  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [ 860/3750]  eta: 0:20:25  Lr: 0.001875  Loss: 0.0563  Acc@1: 75.0000 (79.7256)  Acc@5: 100.0000 (96.0947)  time: 0.3470  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 870/3750]  eta: 0:20:19  Lr: 0.001875  Loss: -1.0095  Acc@1: 75.0000 (79.7646)  Acc@5: 100.0000 (96.1108)  time: 0.3499  data: 0.0011  max mem: 2500
Train: Epoch[2/5]  [ 880/3750]  eta: 0:20:12  Lr: 0.001875  Loss: -0.9682  Acc@1: 87.5000 (79.8241)  Acc@5: 100.0000 (96.1266)  time: 0.3517  data: 0.0011  max mem: 2500
Train: Epoch[2/5]  [ 890/3750]  eta: 0:20:06  Lr: 0.001875  Loss: -1.1598  Acc@1: 81.2500 (79.8190)  Acc@5: 100.0000 (96.1209)  time: 0.3499  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 900/3750]  eta: 0:19:59  Lr: 0.001875  Loss: -0.5014  Acc@1: 75.0000 (79.7100)  Acc@5: 100.0000 (96.1154)  time: 0.3472  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 910/3750]  eta: 0:19:52  Lr: 0.001875  Loss: -0.8419  Acc@1: 75.0000 (79.6721)  Acc@5: 100.0000 (96.1238)  time: 0.3469  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [ 920/3750]  eta: 0:19:46  Lr: 0.001875  Loss: -1.1144  Acc@1: 75.0000 (79.6213)  Acc@5: 100.0000 (96.1251)  time: 0.3469  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [ 930/3750]  eta: 0:19:40  Lr: 0.001875  Loss: -1.1210  Acc@1: 75.0000 (79.6053)  Acc@5: 93.7500 (96.0996)  time: 0.3453  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [ 940/3750]  eta: 0:19:33  Lr: 0.001875  Loss: -0.8225  Acc@1: 75.0000 (79.5895)  Acc@5: 93.7500 (96.1079)  time: 0.3461  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [ 950/3750]  eta: 0:19:27  Lr: 0.001875  Loss: -1.0720  Acc@1: 81.2500 (79.6136)  Acc@5: 93.7500 (96.0896)  time: 0.3492  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [ 960/3750]  eta: 0:19:21  Lr: 0.001875  Loss: -1.3364  Acc@1: 81.2500 (79.6436)  Acc@5: 100.0000 (96.1108)  time: 0.3503  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [ 970/3750]  eta: 0:19:15  Lr: 0.001875  Loss: -1.2592  Acc@1: 87.5000 (79.6923)  Acc@5: 100.0000 (96.1123)  time: 0.3500  data: 0.0013  max mem: 2500
Train: Epoch[2/5]  [ 980/3750]  eta: 0:19:09  Lr: 0.001875  Loss: -0.9123  Acc@1: 81.2500 (79.7209)  Acc@5: 93.7500 (96.1137)  time: 0.3506  data: 0.0014  max mem: 2500
Train: Epoch[2/5]  [ 990/3750]  eta: 0:19:03  Lr: 0.001875  Loss: -0.3079  Acc@1: 81.2500 (79.6733)  Acc@5: 93.7500 (96.1024)  time: 0.3527  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [1000/3750]  eta: 0:18:57  Lr: 0.001875  Loss: -1.3845  Acc@1: 81.2500 (79.7078)  Acc@5: 93.7500 (96.1101)  time: 0.3535  data: 0.0010  max mem: 2500
Train: Epoch[2/5]  [1010/3750]  eta: 0:18:51  Lr: 0.001875  Loss: -0.7304  Acc@1: 81.2500 (79.6983)  Acc@5: 93.7500 (96.0992)  time: 0.3515  data: 0.0010  max mem: 2500
Train: Epoch[2/5]  [1020/3750]  eta: 0:18:46  Lr: 0.001875  Loss: -0.8646  Acc@1: 75.0000 (79.6339)  Acc@5: 93.7500 (96.1006)  time: 0.3497  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [1030/3750]  eta: 0:18:40  Lr: 0.001875  Loss: -1.0985  Acc@1: 75.0000 (79.6314)  Acc@5: 100.0000 (96.1203)  time: 0.3482  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [1040/3750]  eta: 0:18:34  Lr: 0.001875  Loss: -0.5928  Acc@1: 81.2500 (79.6410)  Acc@5: 100.0000 (96.0795)  time: 0.3497  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1050/3750]  eta: 0:18:28  Lr: 0.001875  Loss: -0.9745  Acc@1: 81.2500 (79.6682)  Acc@5: 93.7500 (96.0930)  time: 0.3503  data: 0.0013  max mem: 2500
Train: Epoch[2/5]  [1060/3750]  eta: 0:18:23  Lr: 0.001875  Loss: -1.0388  Acc@1: 81.2500 (79.6890)  Acc@5: 100.0000 (96.0945)  time: 0.3502  data: 0.0012  max mem: 2500
Train: Epoch[2/5]  [1070/3750]  eta: 0:18:17  Lr: 0.001875  Loss: -0.7324  Acc@1: 81.2500 (79.6277)  Acc@5: 93.7500 (96.0784)  time: 0.3493  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1080/3750]  eta: 0:18:11  Lr: 0.001875  Loss: -0.9419  Acc@1: 75.0000 (79.6138)  Acc@5: 93.7500 (96.0685)  time: 0.3485  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1090/3750]  eta: 0:18:06  Lr: 0.001875  Loss: -0.5208  Acc@1: 75.0000 (79.5658)  Acc@5: 93.7500 (96.0587)  time: 0.3490  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1100/3750]  eta: 0:18:00  Lr: 0.001875  Loss: -0.7501  Acc@1: 75.0000 (79.5470)  Acc@5: 93.7500 (96.0434)  time: 0.3469  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1110/3750]  eta: 0:17:55  Lr: 0.001875  Loss: -0.7118  Acc@1: 75.0000 (79.5230)  Acc@5: 93.7500 (96.0452)  time: 0.3453  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [1120/3750]  eta: 0:17:49  Lr: 0.001875  Loss: -0.9040  Acc@1: 75.0000 (79.5384)  Acc@5: 100.0000 (96.0471)  time: 0.3454  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [1130/3750]  eta: 0:17:44  Lr: 0.001875  Loss: -0.9495  Acc@1: 81.2500 (79.5645)  Acc@5: 100.0000 (96.0654)  time: 0.3459  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [1140/3750]  eta: 0:17:38  Lr: 0.001875  Loss: -1.0644  Acc@1: 81.2500 (79.5738)  Acc@5: 100.0000 (96.0616)  time: 0.3472  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1150/3750]  eta: 0:17:33  Lr: 0.001875  Loss: -1.2325  Acc@1: 81.2500 (79.6373)  Acc@5: 100.0000 (96.0795)  time: 0.3492  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1160/3750]  eta: 0:17:28  Lr: 0.001875  Loss: -1.3014  Acc@1: 87.5000 (79.6673)  Acc@5: 100.0000 (96.0917)  time: 0.3501  data: 0.0013  max mem: 2500
Train: Epoch[2/5]  [1170/3750]  eta: 0:17:23  Lr: 0.001875  Loss: -0.7604  Acc@1: 81.2500 (79.6808)  Acc@5: 100.0000 (96.0824)  time: 0.3508  data: 0.0024  max mem: 2500
Train: Epoch[2/5]  [1180/3750]  eta: 0:17:17  Lr: 0.001875  Loss: -0.7235  Acc@1: 81.2500 (79.6729)  Acc@5: 93.7500 (96.0785)  time: 0.3506  data: 0.0015  max mem: 2500
Train: Epoch[2/5]  [1190/3750]  eta: 0:17:12  Lr: 0.001875  Loss: -0.9291  Acc@1: 81.2500 (79.6862)  Acc@5: 100.0000 (96.0800)  time: 0.3483  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1200/3750]  eta: 0:17:07  Lr: 0.001875  Loss: -1.1305  Acc@1: 81.2500 (79.7148)  Acc@5: 100.0000 (96.0918)  time: 0.3487  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1210/3750]  eta: 0:17:02  Lr: 0.001875  Loss: -1.0190  Acc@1: 81.2500 (79.6965)  Acc@5: 93.7500 (96.0879)  time: 0.3513  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [1220/3750]  eta: 0:16:57  Lr: 0.001875  Loss: -1.2700  Acc@1: 81.2500 (79.7451)  Acc@5: 100.0000 (96.1046)  time: 0.3523  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [1230/3750]  eta: 0:16:52  Lr: 0.001875  Loss: -1.2984  Acc@1: 81.2500 (79.7776)  Acc@5: 100.0000 (96.1210)  time: 0.3512  data: 0.0009  max mem: 2500
Train: Epoch[2/5]  [1240/3750]  eta: 0:16:47  Lr: 0.001875  Loss: -0.7879  Acc@1: 81.2500 (79.7945)  Acc@5: 100.0000 (96.1170)  time: 0.3481  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [1250/3750]  eta: 0:16:41  Lr: 0.001875  Loss: -1.4434  Acc@1: 81.2500 (79.7962)  Acc@5: 100.0000 (96.1281)  time: 0.3467  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1260/3750]  eta: 0:16:36  Lr: 0.001875  Loss: -1.0889  Acc@1: 81.2500 (79.7780)  Acc@5: 100.0000 (96.1439)  time: 0.3470  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1270/3750]  eta: 0:16:31  Lr: 0.001875  Loss: -0.2913  Acc@1: 81.2500 (79.7404)  Acc@5: 100.0000 (96.1497)  time: 0.3494  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1280/3750]  eta: 0:16:26  Lr: 0.001875  Loss: -1.0751  Acc@1: 75.0000 (79.7570)  Acc@5: 100.0000 (96.1553)  time: 0.3487  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [1290/3750]  eta: 0:16:21  Lr: 0.001875  Loss: -1.2021  Acc@1: 81.2500 (79.7783)  Acc@5: 100.0000 (96.1706)  time: 0.3454  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [1300/3750]  eta: 0:16:16  Lr: 0.001875  Loss: -0.8677  Acc@1: 81.2500 (79.7608)  Acc@5: 93.7500 (96.1568)  time: 0.3456  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [1310/3750]  eta: 0:16:11  Lr: 0.001875  Loss: -0.7260  Acc@1: 75.0000 (79.7101)  Acc@5: 93.7500 (96.1527)  time: 0.3462  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [1320/3750]  eta: 0:16:06  Lr: 0.001875  Loss: -0.8797  Acc@1: 75.0000 (79.6934)  Acc@5: 100.0000 (96.1629)  time: 0.3458  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [1330/3750]  eta: 0:16:02  Lr: 0.001875  Loss: -0.8210  Acc@1: 75.0000 (79.6816)  Acc@5: 100.0000 (96.1636)  time: 0.3470  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1340/3750]  eta: 0:15:57  Lr: 0.001875  Loss: -0.9375  Acc@1: 81.2500 (79.7166)  Acc@5: 100.0000 (96.1829)  time: 0.3489  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [1350/3750]  eta: 0:15:52  Lr: 0.001875  Loss: -0.8966  Acc@1: 81.2500 (79.7372)  Acc@5: 100.0000 (96.1788)  time: 0.3523  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [1360/3750]  eta: 0:15:47  Lr: 0.001875  Loss: -0.7848  Acc@1: 81.2500 (79.7162)  Acc@5: 93.7500 (96.1655)  time: 0.3550  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [1370/3750]  eta: 0:15:43  Lr: 0.001875  Loss: -1.1933  Acc@1: 75.0000 (79.7183)  Acc@5: 93.7500 (96.1524)  time: 0.3529  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [1380/3750]  eta: 0:15:38  Lr: 0.001875  Loss: -0.4449  Acc@1: 75.0000 (79.6841)  Acc@5: 93.7500 (96.1441)  time: 0.3517  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [1390/3750]  eta: 0:15:33  Lr: 0.001875  Loss: -0.9165  Acc@1: 75.0000 (79.6729)  Acc@5: 93.7500 (96.1538)  time: 0.3526  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [1400/3750]  eta: 0:15:29  Lr: 0.001875  Loss: -0.3971  Acc@1: 75.0000 (79.6708)  Acc@5: 100.0000 (96.1679)  time: 0.3558  data: 0.0011  max mem: 2500
Train: Epoch[2/5]  [1410/3750]  eta: 0:15:24  Lr: 0.001875  Loss: -1.3988  Acc@1: 81.2500 (79.7307)  Acc@5: 100.0000 (96.1906)  time: 0.3582  data: 0.0011  max mem: 2500
Train: Epoch[2/5]  [1420/3750]  eta: 0:15:19  Lr: 0.001875  Loss: -1.3723  Acc@1: 81.2500 (79.7414)  Acc@5: 100.0000 (96.1999)  time: 0.3534  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1430/3750]  eta: 0:15:15  Lr: 0.001875  Loss: -0.6879  Acc@1: 81.2500 (79.7607)  Acc@5: 100.0000 (96.2046)  time: 0.3480  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1440/3750]  eta: 0:15:10  Lr: 0.001875  Loss: -1.0027  Acc@1: 81.2500 (79.7883)  Acc@5: 100.0000 (96.2092)  time: 0.3481  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1450/3750]  eta: 0:15:05  Lr: 0.001875  Loss: -0.8756  Acc@1: 81.2500 (79.7941)  Acc@5: 100.0000 (96.2138)  time: 0.3487  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [1460/3750]  eta: 0:15:01  Lr: 0.001875  Loss: -0.8755  Acc@1: 75.0000 (79.7741)  Acc@5: 100.0000 (96.2141)  time: 0.3482  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [1470/3750]  eta: 0:14:56  Lr: 0.001875  Loss: -0.8412  Acc@1: 81.2500 (79.7799)  Acc@5: 93.7500 (96.2143)  time: 0.3476  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1480/3750]  eta: 0:14:51  Lr: 0.001875  Loss: -0.6347  Acc@1: 81.2500 (79.7730)  Acc@5: 93.7500 (96.2061)  time: 0.3470  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [1490/3750]  eta: 0:14:47  Lr: 0.001875  Loss: -1.0811  Acc@1: 81.2500 (79.7871)  Acc@5: 93.7500 (96.2064)  time: 0.3472  data: 0.0014  max mem: 2500
Train: Epoch[2/5]  [1500/3750]  eta: 0:14:42  Lr: 0.001875  Loss: -1.1894  Acc@1: 81.2500 (79.8301)  Acc@5: 93.7500 (96.1984)  time: 0.3467  data: 0.0010  max mem: 2500
Train: Epoch[2/5]  [1510/3750]  eta: 0:14:37  Lr: 0.001875  Loss: -0.7253  Acc@1: 81.2500 (79.8188)  Acc@5: 100.0000 (96.2028)  time: 0.3454  data: 0.0002  max mem: 2500
Train: Epoch[2/5]  [1520/3750]  eta: 0:14:33  Lr: 0.001875  Loss: -0.5444  Acc@1: 81.2500 (79.7954)  Acc@5: 93.7500 (96.1867)  time: 0.3459  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [1530/3750]  eta: 0:14:28  Lr: 0.001875  Loss: -1.3445  Acc@1: 81.2500 (79.7845)  Acc@5: 93.7500 (96.1831)  time: 0.3478  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [1540/3750]  eta: 0:14:24  Lr: 0.001875  Loss: -1.1296  Acc@1: 81.2500 (79.8021)  Acc@5: 93.7500 (96.1713)  time: 0.3493  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1550/3750]  eta: 0:14:19  Lr: 0.001875  Loss: -0.9635  Acc@1: 81.2500 (79.7872)  Acc@5: 100.0000 (96.1799)  time: 0.3493  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [1560/3750]  eta: 0:14:15  Lr: 0.001875  Loss: -0.8608  Acc@1: 81.2500 (79.8046)  Acc@5: 100.0000 (96.1883)  time: 0.3496  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [1570/3750]  eta: 0:14:10  Lr: 0.001875  Loss: -0.7374  Acc@1: 81.2500 (79.8218)  Acc@5: 100.0000 (96.1808)  time: 0.3522  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [1580/3750]  eta: 0:14:06  Lr: 0.001875  Loss: -1.0036  Acc@1: 81.2500 (79.8269)  Acc@5: 100.0000 (96.1931)  time: 0.3539  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [1590/3750]  eta: 0:14:01  Lr: 0.001875  Loss: -0.4376  Acc@1: 81.2500 (79.8201)  Acc@5: 100.0000 (96.1895)  time: 0.3510  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1600/3750]  eta: 0:13:57  Lr: 0.001875  Loss: -0.8611  Acc@1: 81.2500 (79.8056)  Acc@5: 93.7500 (96.1782)  time: 0.3497  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1610/3750]  eta: 0:13:53  Lr: 0.001875  Loss: -1.3592  Acc@1: 81.2500 (79.8262)  Acc@5: 93.7500 (96.1864)  time: 0.3512  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1620/3750]  eta: 0:13:48  Lr: 0.001875  Loss: -0.9091  Acc@1: 81.2500 (79.8273)  Acc@5: 100.0000 (96.1906)  time: 0.3500  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1630/3750]  eta: 0:13:44  Lr: 0.001875  Loss: -0.4675  Acc@1: 75.0000 (79.7785)  Acc@5: 93.7500 (96.1757)  time: 0.3481  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1640/3750]  eta: 0:13:39  Lr: 0.001875  Loss: -1.2674  Acc@1: 81.2500 (79.8027)  Acc@5: 93.7500 (96.1685)  time: 0.3491  data: 0.0009  max mem: 2500
Train: Epoch[2/5]  [1650/3750]  eta: 0:13:35  Lr: 0.001875  Loss: -0.8916  Acc@1: 81.2500 (79.7963)  Acc@5: 93.7500 (96.1576)  time: 0.3489  data: 0.0009  max mem: 2500
Train: Epoch[2/5]  [1660/3750]  eta: 0:13:31  Lr: 0.001875  Loss: -0.3855  Acc@1: 81.2500 (79.7938)  Acc@5: 93.7500 (96.1695)  time: 0.3470  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1670/3750]  eta: 0:13:26  Lr: 0.001875  Loss: -1.0689  Acc@1: 81.2500 (79.8063)  Acc@5: 100.0000 (96.1662)  time: 0.3471  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [1680/3750]  eta: 0:13:22  Lr: 0.001875  Loss: -1.1352  Acc@1: 75.0000 (79.7963)  Acc@5: 100.0000 (96.1779)  time: 0.3485  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1690/3750]  eta: 0:13:18  Lr: 0.001875  Loss: -1.0690  Acc@1: 75.0000 (79.7901)  Acc@5: 100.0000 (96.1746)  time: 0.3488  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1700/3750]  eta: 0:13:13  Lr: 0.001875  Loss: -0.8511  Acc@1: 81.2500 (79.8023)  Acc@5: 93.7500 (96.1714)  time: 0.3462  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [1710/3750]  eta: 0:13:09  Lr: 0.001875  Loss: -1.0248  Acc@1: 81.2500 (79.8035)  Acc@5: 93.7500 (96.1609)  time: 0.3448  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [1720/3750]  eta: 0:13:04  Lr: 0.001875  Loss: -0.5797  Acc@1: 75.0000 (79.7828)  Acc@5: 93.7500 (96.1614)  time: 0.3457  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1730/3750]  eta: 0:13:00  Lr: 0.001875  Loss: -1.0420  Acc@1: 81.2500 (79.7985)  Acc@5: 93.7500 (96.1583)  time: 0.3461  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1740/3750]  eta: 0:12:56  Lr: 0.001875  Loss: -0.9047  Acc@1: 81.2500 (79.7817)  Acc@5: 93.7500 (96.1337)  time: 0.3452  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [1750/3750]  eta: 0:12:51  Lr: 0.001875  Loss: -1.2503  Acc@1: 75.0000 (79.7723)  Acc@5: 93.7500 (96.1379)  time: 0.3464  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [1760/3750]  eta: 0:12:47  Lr: 0.001875  Loss: -0.4253  Acc@1: 81.2500 (79.7594)  Acc@5: 100.0000 (96.1386)  time: 0.3503  data: 0.0012  max mem: 2500
Train: Epoch[2/5]  [1770/3750]  eta: 0:12:43  Lr: 0.001875  Loss: -1.1155  Acc@1: 81.2500 (79.7572)  Acc@5: 100.0000 (96.1357)  time: 0.3516  data: 0.0013  max mem: 2500
Train: Epoch[2/5]  [1780/3750]  eta: 0:12:39  Lr: 0.001875  Loss: -0.6223  Acc@1: 81.2500 (79.7586)  Acc@5: 93.7500 (96.1258)  time: 0.3510  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1790/3750]  eta: 0:12:34  Lr: 0.001875  Loss: -1.0763  Acc@1: 81.2500 (79.7808)  Acc@5: 100.0000 (96.1439)  time: 0.3507  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1800/3750]  eta: 0:12:30  Lr: 0.001875  Loss: -0.7293  Acc@1: 81.2500 (79.7890)  Acc@5: 100.0000 (96.1514)  time: 0.3498  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1810/3750]  eta: 0:12:26  Lr: 0.001875  Loss: -1.2741  Acc@1: 81.2500 (79.8074)  Acc@5: 100.0000 (96.1623)  time: 0.3510  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1820/3750]  eta: 0:12:22  Lr: 0.001875  Loss: -0.6753  Acc@1: 81.2500 (79.8291)  Acc@5: 100.0000 (96.1731)  time: 0.3526  data: 0.0015  max mem: 2500
Train: Epoch[2/5]  [1830/3750]  eta: 0:12:18  Lr: 0.001875  Loss: -1.1498  Acc@1: 81.2500 (79.8300)  Acc@5: 100.0000 (96.1599)  time: 0.3524  data: 0.0018  max mem: 2500
Train: Epoch[2/5]  [1840/3750]  eta: 0:12:13  Lr: 0.001875  Loss: -1.0538  Acc@1: 81.2500 (79.8513)  Acc@5: 93.7500 (96.1638)  time: 0.3493  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [1850/3750]  eta: 0:12:09  Lr: 0.001875  Loss: -1.1705  Acc@1: 81.2500 (79.8386)  Acc@5: 93.7500 (96.1541)  time: 0.3476  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1860/3750]  eta: 0:12:05  Lr: 0.001875  Loss: -0.4413  Acc@1: 75.0000 (79.8092)  Acc@5: 93.7500 (96.1412)  time: 0.3485  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1870/3750]  eta: 0:12:01  Lr: 0.001875  Loss: -1.0800  Acc@1: 75.0000 (79.7835)  Acc@5: 93.7500 (96.1284)  time: 0.3482  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [1880/3750]  eta: 0:11:57  Lr: 0.001875  Loss: -1.0224  Acc@1: 75.0000 (79.7814)  Acc@5: 93.7500 (96.1257)  time: 0.3500  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [1890/3750]  eta: 0:11:52  Lr: 0.001875  Loss: -0.7708  Acc@1: 75.0000 (79.7693)  Acc@5: 100.0000 (96.1264)  time: 0.3501  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1900/3750]  eta: 0:11:48  Lr: 0.001875  Loss: -0.3877  Acc@1: 81.2500 (79.7804)  Acc@5: 100.0000 (96.1270)  time: 0.3481  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1910/3750]  eta: 0:11:44  Lr: 0.001875  Loss: -0.5737  Acc@1: 81.2500 (79.7684)  Acc@5: 93.7500 (96.1244)  time: 0.3484  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1920/3750]  eta: 0:11:40  Lr: 0.001875  Loss: -0.6557  Acc@1: 75.0000 (79.7762)  Acc@5: 93.7500 (96.1283)  time: 0.3479  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1930/3750]  eta: 0:11:36  Lr: 0.001875  Loss: -0.6092  Acc@1: 81.2500 (79.7806)  Acc@5: 93.7500 (96.1289)  time: 0.3459  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [1940/3750]  eta: 0:11:32  Lr: 0.001875  Loss: -0.9218  Acc@1: 81.2500 (79.7978)  Acc@5: 93.7500 (96.1296)  time: 0.3451  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [1950/3750]  eta: 0:11:27  Lr: 0.001875  Loss: -0.6819  Acc@1: 81.2500 (79.8084)  Acc@5: 100.0000 (96.1366)  time: 0.3474  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [1960/3750]  eta: 0:11:23  Lr: 0.001875  Loss: -0.7299  Acc@1: 81.2500 (79.8030)  Acc@5: 100.0000 (96.1372)  time: 0.3470  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [1970/3750]  eta: 0:11:19  Lr: 0.001875  Loss: -0.8401  Acc@1: 81.2500 (79.7882)  Acc@5: 93.7500 (96.1314)  time: 0.3462  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [1980/3750]  eta: 0:11:15  Lr: 0.001875  Loss: -0.6368  Acc@1: 87.5000 (79.8303)  Acc@5: 93.7500 (96.1352)  time: 0.3500  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1990/3750]  eta: 0:11:11  Lr: 0.001875  Loss: -0.7049  Acc@1: 87.5000 (79.8405)  Acc@5: 100.0000 (96.1389)  time: 0.3563  data: 0.0009  max mem: 2500
Train: Epoch[2/5]  [2000/3750]  eta: 0:11:07  Lr: 0.001875  Loss: -0.7793  Acc@1: 81.2500 (79.8413)  Acc@5: 100.0000 (96.1582)  time: 0.3563  data: 0.0018  max mem: 2500
Train: Epoch[2/5]  [2010/3750]  eta: 0:11:03  Lr: 0.001875  Loss: -0.7705  Acc@1: 81.2500 (79.8390)  Acc@5: 100.0000 (96.1617)  time: 0.3518  data: 0.0018  max mem: 2500
Train: Epoch[2/5]  [2020/3750]  eta: 0:10:59  Lr: 0.001875  Loss: -0.8458  Acc@1: 81.2500 (79.8491)  Acc@5: 100.0000 (96.1591)  time: 0.3507  data: 0.0009  max mem: 2500
Train: Epoch[2/5]  [2030/3750]  eta: 0:10:55  Lr: 0.001875  Loss: -0.9720  Acc@1: 81.2500 (79.8714)  Acc@5: 93.7500 (96.1534)  time: 0.3521  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [2040/3750]  eta: 0:10:51  Lr: 0.001875  Loss: -1.0045  Acc@1: 81.2500 (79.8628)  Acc@5: 93.7500 (96.1569)  time: 0.3570  data: 0.0012  max mem: 2500
Train: Epoch[2/5]  [2050/3750]  eta: 0:10:47  Lr: 0.001875  Loss: -0.4177  Acc@1: 75.0000 (79.8422)  Acc@5: 93.7500 (96.1482)  time: 0.3589  data: 0.0011  max mem: 2500
Train: Epoch[2/5]  [2060/3750]  eta: 0:10:43  Lr: 0.001875  Loss: -1.0718  Acc@1: 81.2500 (79.8429)  Acc@5: 93.7500 (96.1457)  time: 0.3525  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [2070/3750]  eta: 0:10:39  Lr: 0.001875  Loss: -0.5798  Acc@1: 81.2500 (79.8225)  Acc@5: 93.7500 (96.1462)  time: 0.3473  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2080/3750]  eta: 0:10:35  Lr: 0.001875  Loss: -1.3289  Acc@1: 81.2500 (79.8354)  Acc@5: 100.0000 (96.1437)  time: 0.3496  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [2090/3750]  eta: 0:10:31  Lr: 0.001875  Loss: -0.9576  Acc@1: 81.2500 (79.8242)  Acc@5: 93.7500 (96.1412)  time: 0.3493  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2100/3750]  eta: 0:10:26  Lr: 0.001875  Loss: -0.9118  Acc@1: 75.0000 (79.8132)  Acc@5: 93.7500 (96.1447)  time: 0.3465  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [2110/3750]  eta: 0:10:22  Lr: 0.001875  Loss: -0.8532  Acc@1: 81.2500 (79.8318)  Acc@5: 93.7500 (96.1422)  time: 0.3460  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [2120/3750]  eta: 0:10:18  Lr: 0.001875  Loss: -1.1181  Acc@1: 87.5000 (79.8503)  Acc@5: 100.0000 (96.1457)  time: 0.3468  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [2130/3750]  eta: 0:10:14  Lr: 0.001875  Loss: -0.5893  Acc@1: 87.5000 (79.8598)  Acc@5: 100.0000 (96.1432)  time: 0.3467  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [2140/3750]  eta: 0:10:10  Lr: 0.001875  Loss: -0.8350  Acc@1: 81.2500 (79.8634)  Acc@5: 93.7500 (96.1408)  time: 0.3450  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [2150/3750]  eta: 0:10:06  Lr: 0.001875  Loss: -0.8182  Acc@1: 81.2500 (79.8756)  Acc@5: 93.7500 (96.1355)  time: 0.3462  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [2160/3750]  eta: 0:10:02  Lr: 0.001875  Loss: -0.9420  Acc@1: 81.2500 (79.8820)  Acc@5: 93.7500 (96.1418)  time: 0.3480  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [2170/3750]  eta: 0:09:58  Lr: 0.001875  Loss: -0.8602  Acc@1: 81.2500 (79.8969)  Acc@5: 100.0000 (96.1481)  time: 0.3490  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [2180/3750]  eta: 0:09:54  Lr: 0.001875  Loss: -0.5115  Acc@1: 81.2500 (79.8745)  Acc@5: 100.0000 (96.1400)  time: 0.3499  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2190/3750]  eta: 0:09:50  Lr: 0.001875  Loss: -0.7165  Acc@1: 75.0000 (79.8665)  Acc@5: 93.7500 (96.1376)  time: 0.3501  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2200/3750]  eta: 0:09:46  Lr: 0.001875  Loss: -1.1731  Acc@1: 81.2500 (79.8586)  Acc@5: 93.7500 (96.1410)  time: 0.3509  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [2210/3750]  eta: 0:09:42  Lr: 0.001875  Loss: -0.8893  Acc@1: 81.2500 (79.8479)  Acc@5: 93.7500 (96.1415)  time: 0.3536  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [2220/3750]  eta: 0:09:38  Lr: 0.001875  Loss: -0.4438  Acc@1: 81.2500 (79.8486)  Acc@5: 93.7500 (96.1419)  time: 0.3534  data: 0.0012  max mem: 2500
Train: Epoch[2/5]  [2230/3750]  eta: 0:09:34  Lr: 0.001875  Loss: -0.9922  Acc@1: 81.2500 (79.8661)  Acc@5: 100.0000 (96.1480)  time: 0.3508  data: 0.0011  max mem: 2500
Train: Epoch[2/5]  [2240/3750]  eta: 0:09:30  Lr: 0.001875  Loss: -1.0499  Acc@1: 81.2500 (79.8778)  Acc@5: 100.0000 (96.1568)  time: 0.3494  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2250/3750]  eta: 0:09:26  Lr: 0.001875  Loss: -0.6370  Acc@1: 81.2500 (79.8701)  Acc@5: 100.0000 (96.1489)  time: 0.3486  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [2260/3750]  eta: 0:09:22  Lr: 0.001875  Loss: -0.5753  Acc@1: 75.0000 (79.8679)  Acc@5: 100.0000 (96.1604)  time: 0.3486  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [2270/3750]  eta: 0:09:18  Lr: 0.001875  Loss: -0.5062  Acc@1: 81.2500 (79.8657)  Acc@5: 100.0000 (96.1581)  time: 0.3482  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2280/3750]  eta: 0:09:14  Lr: 0.001875  Loss: -0.5784  Acc@1: 81.2500 (79.8553)  Acc@5: 93.7500 (96.1585)  time: 0.3481  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2290/3750]  eta: 0:09:11  Lr: 0.001875  Loss: -1.1172  Acc@1: 81.2500 (79.8560)  Acc@5: 100.0000 (96.1589)  time: 0.3494  data: 0.0010  max mem: 2500
Train: Epoch[2/5]  [2300/3750]  eta: 0:09:07  Lr: 0.001875  Loss: -1.0861  Acc@1: 81.2500 (79.8674)  Acc@5: 100.0000 (96.1701)  time: 0.3485  data: 0.0010  max mem: 2500
Train: Epoch[2/5]  [2310/3750]  eta: 0:09:03  Lr: 0.001875  Loss: -0.5839  Acc@1: 81.2500 (79.8626)  Acc@5: 100.0000 (96.1786)  time: 0.3470  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2320/3750]  eta: 0:08:59  Lr: 0.001875  Loss: -0.7494  Acc@1: 75.0000 (79.8390)  Acc@5: 93.7500 (96.1708)  time: 0.3480  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [2330/3750]  eta: 0:08:55  Lr: 0.001875  Loss: -0.7869  Acc@1: 75.0000 (79.8182)  Acc@5: 93.7500 (96.1658)  time: 0.3485  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2340/3750]  eta: 0:08:51  Lr: 0.001875  Loss: -1.0118  Acc@1: 75.0000 (79.8136)  Acc@5: 93.7500 (96.1662)  time: 0.3488  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2350/3750]  eta: 0:08:47  Lr: 0.001875  Loss: -0.9204  Acc@1: 81.2500 (79.7932)  Acc@5: 93.7500 (96.1665)  time: 0.3516  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [2360/3750]  eta: 0:08:43  Lr: 0.001875  Loss: -0.8633  Acc@1: 81.2500 (79.7888)  Acc@5: 100.0000 (96.1695)  time: 0.3534  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [2370/3750]  eta: 0:08:39  Lr: 0.001875  Loss: -1.1722  Acc@1: 81.2500 (79.7844)  Acc@5: 100.0000 (96.1725)  time: 0.3520  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [2380/3750]  eta: 0:08:35  Lr: 0.001875  Loss: -1.1019  Acc@1: 81.2500 (79.8010)  Acc@5: 100.0000 (96.1781)  time: 0.3517  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [2390/3750]  eta: 0:08:31  Lr: 0.001875  Loss: -0.2697  Acc@1: 81.2500 (79.7966)  Acc@5: 100.0000 (96.1862)  time: 0.3517  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [2400/3750]  eta: 0:08:27  Lr: 0.001875  Loss: -0.7949  Acc@1: 75.0000 (79.7949)  Acc@5: 100.0000 (96.1917)  time: 0.3557  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [2410/3750]  eta: 0:08:23  Lr: 0.001875  Loss: -0.5755  Acc@1: 81.2500 (79.7983)  Acc@5: 100.0000 (96.1997)  time: 0.3548  data: 0.0010  max mem: 2500
Train: Epoch[2/5]  [2420/3750]  eta: 0:08:20  Lr: 0.001875  Loss: -0.6339  Acc@1: 81.2500 (79.8017)  Acc@5: 100.0000 (96.2025)  time: 0.3512  data: 0.0010  max mem: 2500
Train: Epoch[2/5]  [2430/3750]  eta: 0:08:16  Lr: 0.001875  Loss: -0.4774  Acc@1: 81.2500 (79.7974)  Acc@5: 100.0000 (96.2053)  time: 0.3508  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [2440/3750]  eta: 0:08:12  Lr: 0.001875  Loss: -0.8078  Acc@1: 81.2500 (79.8162)  Acc@5: 100.0000 (96.2157)  time: 0.3512  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [2450/3750]  eta: 0:08:08  Lr: 0.001875  Loss: -0.6462  Acc@1: 81.2500 (79.8118)  Acc@5: 100.0000 (96.2209)  time: 0.3526  data: 0.0011  max mem: 2500
Train: Epoch[2/5]  [2460/3750]  eta: 0:08:04  Lr: 0.001875  Loss: -0.9065  Acc@1: 81.2500 (79.8329)  Acc@5: 100.0000 (96.2210)  time: 0.3512  data: 0.0011  max mem: 2500
Train: Epoch[2/5]  [2470/3750]  eta: 0:08:00  Lr: 0.001875  Loss: -0.9174  Acc@1: 81.2500 (79.8310)  Acc@5: 93.7500 (96.2212)  time: 0.3493  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2480/3750]  eta: 0:07:56  Lr: 0.001875  Loss: -1.1258  Acc@1: 75.0000 (79.8267)  Acc@5: 100.0000 (96.2213)  time: 0.3475  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [2490/3750]  eta: 0:07:52  Lr: 0.001875  Loss: -1.0363  Acc@1: 81.2500 (79.8449)  Acc@5: 100.0000 (96.2239)  time: 0.3463  data: 0.0002  max mem: 2500
Train: Epoch[2/5]  [2500/3750]  eta: 0:07:48  Lr: 0.001875  Loss: -0.8884  Acc@1: 81.2500 (79.8556)  Acc@5: 100.0000 (96.2315)  time: 0.3457  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [2510/3750]  eta: 0:07:45  Lr: 0.001875  Loss: -0.6981  Acc@1: 81.2500 (79.8462)  Acc@5: 100.0000 (96.2366)  time: 0.3456  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [2520/3750]  eta: 0:07:41  Lr: 0.001875  Loss: -1.2794  Acc@1: 75.0000 (79.8220)  Acc@5: 100.0000 (96.2267)  time: 0.3462  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [2530/3750]  eta: 0:07:37  Lr: 0.001875  Loss: -0.9927  Acc@1: 81.2500 (79.8449)  Acc@5: 93.7500 (96.2268)  time: 0.3507  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2540/3750]  eta: 0:07:33  Lr: 0.001875  Loss: -0.9291  Acc@1: 81.2500 (79.8455)  Acc@5: 93.7500 (96.2244)  time: 0.3536  data: 0.0010  max mem: 2500
Train: Epoch[2/5]  [2550/3750]  eta: 0:07:29  Lr: 0.001875  Loss: -1.1448  Acc@1: 81.2500 (79.8486)  Acc@5: 100.0000 (96.2343)  time: 0.3518  data: 0.0009  max mem: 2500
Train: Epoch[2/5]  [2560/3750]  eta: 0:07:25  Lr: 0.001875  Loss: -0.9868  Acc@1: 81.2500 (79.8638)  Acc@5: 100.0000 (96.2466)  time: 0.3499  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [2570/3750]  eta: 0:07:21  Lr: 0.001875  Loss: -0.7921  Acc@1: 81.2500 (79.8619)  Acc@5: 100.0000 (96.2515)  time: 0.3539  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [2580/3750]  eta: 0:07:18  Lr: 0.001875  Loss: -1.0763  Acc@1: 81.2500 (79.8625)  Acc@5: 100.0000 (96.2490)  time: 0.3627  data: 0.0012  max mem: 2500
Train: Epoch[2/5]  [2590/3750]  eta: 0:07:14  Lr: 0.001875  Loss: -1.0109  Acc@1: 81.2500 (79.8678)  Acc@5: 93.7500 (96.2466)  time: 0.3587  data: 0.0012  max mem: 2500
Train: Epoch[2/5]  [2600/3750]  eta: 0:07:10  Lr: 0.001875  Loss: -1.2723  Acc@1: 81.2500 (79.8683)  Acc@5: 93.7500 (96.2394)  time: 0.3500  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [2610/3750]  eta: 0:07:06  Lr: 0.001875  Loss: -1.0811  Acc@1: 81.2500 (79.8688)  Acc@5: 93.7500 (96.2419)  time: 0.3621  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [2620/3750]  eta: 0:07:02  Lr: 0.001875  Loss: -0.5911  Acc@1: 81.2500 (79.8717)  Acc@5: 93.7500 (96.2395)  time: 0.3622  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [2630/3750]  eta: 0:06:58  Lr: 0.001875  Loss: -0.7411  Acc@1: 81.2500 (79.8817)  Acc@5: 93.7500 (96.2395)  time: 0.3499  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [2640/3750]  eta: 0:06:55  Lr: 0.001875  Loss: -0.7064  Acc@1: 81.2500 (79.8774)  Acc@5: 100.0000 (96.2420)  time: 0.3505  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [2650/3750]  eta: 0:06:51  Lr: 0.001875  Loss: -1.0492  Acc@1: 81.2500 (79.8708)  Acc@5: 93.7500 (96.2420)  time: 0.3498  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2660/3750]  eta: 0:06:47  Lr: 0.001875  Loss: -0.6304  Acc@1: 75.0000 (79.8642)  Acc@5: 100.0000 (96.2444)  time: 0.3481  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2670/3750]  eta: 0:06:43  Lr: 0.001875  Loss: -0.8583  Acc@1: 75.0000 (79.8460)  Acc@5: 100.0000 (96.2444)  time: 0.3478  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2680/3750]  eta: 0:06:39  Lr: 0.001875  Loss: -0.9664  Acc@1: 75.0000 (79.8443)  Acc@5: 100.0000 (96.2444)  time: 0.3511  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2690/3750]  eta: 0:06:35  Lr: 0.001875  Loss: -1.1345  Acc@1: 81.2500 (79.8472)  Acc@5: 100.0000 (96.2444)  time: 0.3525  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [2700/3750]  eta: 0:06:32  Lr: 0.001875  Loss: -0.6980  Acc@1: 81.2500 (79.8362)  Acc@5: 100.0000 (96.2444)  time: 0.3482  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [2710/3750]  eta: 0:06:28  Lr: 0.001875  Loss: -1.1357  Acc@1: 75.0000 (79.8276)  Acc@5: 100.0000 (96.2445)  time: 0.3449  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [2720/3750]  eta: 0:06:24  Lr: 0.001875  Loss: -1.2562  Acc@1: 81.2500 (79.8236)  Acc@5: 100.0000 (96.2468)  time: 0.3461  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2730/3750]  eta: 0:06:20  Lr: 0.001875  Loss: -0.5376  Acc@1: 81.2500 (79.8425)  Acc@5: 100.0000 (96.2422)  time: 0.3477  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2740/3750]  eta: 0:06:16  Lr: 0.001875  Loss: -0.7091  Acc@1: 81.2500 (79.8477)  Acc@5: 93.7500 (96.2400)  time: 0.3470  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2750/3750]  eta: 0:06:12  Lr: 0.001875  Loss: -1.1039  Acc@1: 81.2500 (79.8573)  Acc@5: 93.7500 (96.2423)  time: 0.3463  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2760/3750]  eta: 0:06:09  Lr: 0.001875  Loss: -0.7842  Acc@1: 81.2500 (79.8465)  Acc@5: 93.7500 (96.2423)  time: 0.3501  data: 0.0013  max mem: 2500
Train: Epoch[2/5]  [2770/3750]  eta: 0:06:05  Lr: 0.001875  Loss: -0.5944  Acc@1: 81.2500 (79.8471)  Acc@5: 93.7500 (96.2378)  time: 0.3526  data: 0.0013  max mem: 2500
Train: Epoch[2/5]  [2780/3750]  eta: 0:06:01  Lr: 0.001875  Loss: -0.9557  Acc@1: 81.2500 (79.8229)  Acc@5: 93.7500 (96.2334)  time: 0.3503  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [2790/3750]  eta: 0:05:57  Lr: 0.001875  Loss: -1.0794  Acc@1: 81.2500 (79.8347)  Acc@5: 93.7500 (96.2334)  time: 0.3508  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [2800/3750]  eta: 0:05:53  Lr: 0.001875  Loss: -0.5208  Acc@1: 81.2500 (79.8331)  Acc@5: 93.7500 (96.2290)  time: 0.3516  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [2810/3750]  eta: 0:05:50  Lr: 0.001875  Loss: -0.8728  Acc@1: 81.2500 (79.8337)  Acc@5: 100.0000 (96.2335)  time: 0.3519  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [2820/3750]  eta: 0:05:46  Lr: 0.001875  Loss: -0.8016  Acc@1: 75.0000 (79.8232)  Acc@5: 93.7500 (96.2292)  time: 0.3527  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [2830/3750]  eta: 0:05:42  Lr: 0.001875  Loss: -0.8268  Acc@1: 75.0000 (79.8150)  Acc@5: 93.7500 (96.2292)  time: 0.3510  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [2840/3750]  eta: 0:05:38  Lr: 0.001875  Loss: -1.0743  Acc@1: 81.2500 (79.8288)  Acc@5: 100.0000 (96.2359)  time: 0.3488  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2850/3750]  eta: 0:05:34  Lr: 0.001875  Loss: -0.6833  Acc@1: 81.2500 (79.8360)  Acc@5: 100.0000 (96.2360)  time: 0.3483  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2860/3750]  eta: 0:05:31  Lr: 0.001875  Loss: -1.2787  Acc@1: 81.2500 (79.8519)  Acc@5: 93.7500 (96.2382)  time: 0.3492  data: 0.0009  max mem: 2500
Train: Epoch[2/5]  [2870/3750]  eta: 0:05:27  Lr: 0.001875  Loss: -1.2731  Acc@1: 87.5000 (79.8916)  Acc@5: 100.0000 (96.2448)  time: 0.3489  data: 0.0011  max mem: 2500
Train: Epoch[2/5]  [2880/3750]  eta: 0:05:23  Lr: 0.001875  Loss: -1.1925  Acc@1: 87.5000 (79.8811)  Acc@5: 100.0000 (96.2513)  time: 0.3476  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [2890/3750]  eta: 0:05:19  Lr: 0.001875  Loss: -0.7721  Acc@1: 75.0000 (79.8859)  Acc@5: 100.0000 (96.2491)  time: 0.3460  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2900/3750]  eta: 0:05:15  Lr: 0.001875  Loss: -1.2884  Acc@1: 81.2500 (79.8906)  Acc@5: 100.0000 (96.2534)  time: 0.3467  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [2910/3750]  eta: 0:05:12  Lr: 0.001875  Loss: -0.6867  Acc@1: 81.2500 (79.8845)  Acc@5: 93.7500 (96.2384)  time: 0.3476  data: 0.0009  max mem: 2500
Train: Epoch[2/5]  [2920/3750]  eta: 0:05:08  Lr: 0.001875  Loss: -0.8277  Acc@1: 81.2500 (79.8892)  Acc@5: 93.7500 (96.2363)  time: 0.3468  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2930/3750]  eta: 0:05:04  Lr: 0.001875  Loss: -0.3379  Acc@1: 81.2500 (79.8704)  Acc@5: 93.7500 (96.2300)  time: 0.3499  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [2940/3750]  eta: 0:05:00  Lr: 0.001875  Loss: -0.8184  Acc@1: 75.0000 (79.8644)  Acc@5: 93.7500 (96.2343)  time: 0.3571  data: 0.0013  max mem: 2500
Train: Epoch[2/5]  [2950/3750]  eta: 0:04:57  Lr: 0.001875  Loss: -1.0298  Acc@1: 81.2500 (79.8670)  Acc@5: 100.0000 (96.2364)  time: 0.3557  data: 0.0012  max mem: 2500
Train: Epoch[2/5]  [2960/3750]  eta: 0:04:53  Lr: 0.001875  Loss: -0.8329  Acc@1: 81.2500 (79.8611)  Acc@5: 100.0000 (96.2386)  time: 0.3514  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [2970/3750]  eta: 0:04:49  Lr: 0.001875  Loss: -1.0142  Acc@1: 81.2500 (79.8574)  Acc@5: 93.7500 (96.2365)  time: 0.3525  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [2980/3750]  eta: 0:04:45  Lr: 0.001875  Loss: -0.8364  Acc@1: 81.2500 (79.8558)  Acc@5: 100.0000 (96.2450)  time: 0.3531  data: 0.0013  max mem: 2500
Train: Epoch[2/5]  [2990/3750]  eta: 0:04:42  Lr: 0.001875  Loss: -1.1956  Acc@1: 81.2500 (79.8667)  Acc@5: 100.0000 (96.2408)  time: 0.3558  data: 0.0021  max mem: 2500
Train: Epoch[2/5]  [3000/3750]  eta: 0:04:38  Lr: 0.001875  Loss: -1.1402  Acc@1: 87.5000 (79.8775)  Acc@5: 93.7500 (96.2429)  time: 0.3585  data: 0.0013  max mem: 2500
Train: Epoch[2/5]  [3010/3750]  eta: 0:04:34  Lr: 0.001875  Loss: -1.2725  Acc@1: 87.5000 (79.8925)  Acc@5: 100.0000 (96.2471)  time: 0.3531  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3020/3750]  eta: 0:04:30  Lr: 0.001875  Loss: -0.9235  Acc@1: 87.5000 (79.8990)  Acc@5: 100.0000 (96.2471)  time: 0.3468  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [3030/3750]  eta: 0:04:27  Lr: 0.001875  Loss: -0.8711  Acc@1: 81.2500 (79.9159)  Acc@5: 93.7500 (96.2451)  time: 0.3479  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3040/3750]  eta: 0:04:23  Lr: 0.001875  Loss: -0.9278  Acc@1: 81.2500 (79.9038)  Acc@5: 100.0000 (96.2492)  time: 0.3507  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3050/3750]  eta: 0:04:19  Lr: 0.001875  Loss: -0.4871  Acc@1: 81.2500 (79.9205)  Acc@5: 100.0000 (96.2492)  time: 0.3495  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3060/3750]  eta: 0:04:15  Lr: 0.001875  Loss: -1.1138  Acc@1: 81.2500 (79.9208)  Acc@5: 100.0000 (96.2553)  time: 0.3471  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3070/3750]  eta: 0:04:12  Lr: 0.001875  Loss: -1.2525  Acc@1: 81.2500 (79.9434)  Acc@5: 100.0000 (96.2553)  time: 0.3478  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [3080/3750]  eta: 0:04:08  Lr: 0.001875  Loss: -1.3553  Acc@1: 87.5000 (79.9497)  Acc@5: 93.7500 (96.2573)  time: 0.3481  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [3090/3750]  eta: 0:04:04  Lr: 0.001875  Loss: -0.9043  Acc@1: 81.2500 (79.9701)  Acc@5: 100.0000 (96.2613)  time: 0.3481  data: 0.0011  max mem: 2500
Train: Epoch[2/5]  [3100/3750]  eta: 0:04:00  Lr: 0.001875  Loss: -1.0794  Acc@1: 87.5000 (79.9843)  Acc@5: 100.0000 (96.2653)  time: 0.3466  data: 0.0012  max mem: 2500
Train: Epoch[2/5]  [3110/3750]  eta: 0:03:57  Lr: 0.001875  Loss: -0.9126  Acc@1: 87.5000 (80.0145)  Acc@5: 100.0000 (96.2733)  time: 0.3453  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [3120/3750]  eta: 0:03:53  Lr: 0.001875  Loss: -0.5896  Acc@1: 81.2500 (80.0064)  Acc@5: 100.0000 (96.2752)  time: 0.3473  data: 0.0009  max mem: 2500
Train: Epoch[2/5]  [3130/3750]  eta: 0:03:49  Lr: 0.001875  Loss: -1.1810  Acc@1: 81.2500 (80.0044)  Acc@5: 93.7500 (96.2712)  time: 0.3528  data: 0.0009  max mem: 2500
Train: Epoch[2/5]  [3140/3750]  eta: 0:03:45  Lr: 0.001875  Loss: -1.0591  Acc@1: 81.2500 (80.0064)  Acc@5: 93.7500 (96.2731)  time: 0.3530  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [3150/3750]  eta: 0:03:42  Lr: 0.001875  Loss: -0.9552  Acc@1: 81.2500 (79.9885)  Acc@5: 93.7500 (96.2730)  time: 0.3487  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [3160/3750]  eta: 0:03:38  Lr: 0.001875  Loss: -0.9713  Acc@1: 75.0000 (79.9945)  Acc@5: 100.0000 (96.2789)  time: 0.3577  data: 0.0014  max mem: 2500
Train: Epoch[2/5]  [3170/3750]  eta: 0:03:34  Lr: 0.001875  Loss: -1.0902  Acc@1: 81.2500 (80.0024)  Acc@5: 100.0000 (96.2827)  time: 0.3596  data: 0.0014  max mem: 2500
Train: Epoch[2/5]  [3180/3750]  eta: 0:03:30  Lr: 0.001875  Loss: -0.9500  Acc@1: 81.2500 (79.9984)  Acc@5: 100.0000 (96.2826)  time: 0.3507  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3190/3750]  eta: 0:03:27  Lr: 0.001875  Loss: -0.9568  Acc@1: 81.2500 (80.0180)  Acc@5: 100.0000 (96.2845)  time: 0.3486  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [3200/3750]  eta: 0:03:23  Lr: 0.001875  Loss: -1.1022  Acc@1: 87.5000 (80.0258)  Acc@5: 100.0000 (96.2844)  time: 0.3499  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [3210/3750]  eta: 0:03:19  Lr: 0.001875  Loss: -0.7783  Acc@1: 87.5000 (80.0335)  Acc@5: 100.0000 (96.2882)  time: 0.3539  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [3220/3750]  eta: 0:03:15  Lr: 0.001875  Loss: -0.9009  Acc@1: 87.5000 (80.0411)  Acc@5: 100.0000 (96.2939)  time: 0.3531  data: 0.0009  max mem: 2500
Train: Epoch[2/5]  [3230/3750]  eta: 0:03:12  Lr: 0.001875  Loss: -0.8613  Acc@1: 75.0000 (80.0313)  Acc@5: 100.0000 (96.2918)  time: 0.3485  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [3240/3750]  eta: 0:03:08  Lr: 0.001875  Loss: -0.5243  Acc@1: 75.0000 (80.0235)  Acc@5: 93.7500 (96.2897)  time: 0.3469  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3250/3750]  eta: 0:03:04  Lr: 0.001875  Loss: -0.8879  Acc@1: 75.0000 (80.0100)  Acc@5: 93.7500 (96.2858)  time: 0.3483  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3260/3750]  eta: 0:03:01  Lr: 0.001875  Loss: -0.5797  Acc@1: 81.2500 (80.0042)  Acc@5: 93.7500 (96.2856)  time: 0.3486  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3270/3750]  eta: 0:02:57  Lr: 0.001875  Loss: -1.2292  Acc@1: 75.0000 (79.9870)  Acc@5: 93.7500 (96.2817)  time: 0.3484  data: 0.0010  max mem: 2500
Train: Epoch[2/5]  [3280/3750]  eta: 0:02:53  Lr: 0.001875  Loss: -1.1802  Acc@1: 75.0000 (79.9813)  Acc@5: 93.7500 (96.2797)  time: 0.3473  data: 0.0010  max mem: 2500
Train: Epoch[2/5]  [3290/3750]  eta: 0:02:49  Lr: 0.001875  Loss: -0.8653  Acc@1: 75.0000 (79.9700)  Acc@5: 93.7500 (96.2796)  time: 0.3462  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [3300/3750]  eta: 0:02:46  Lr: 0.001875  Loss: -0.9958  Acc@1: 81.2500 (79.9814)  Acc@5: 100.0000 (96.2814)  time: 0.3472  data: 0.0016  max mem: 2500
Train: Epoch[2/5]  [3310/3750]  eta: 0:02:42  Lr: 0.001875  Loss: -1.4393  Acc@1: 81.2500 (79.9853)  Acc@5: 100.0000 (96.2794)  time: 0.3462  data: 0.0016  max mem: 2500
Train: Epoch[2/5]  [3320/3750]  eta: 0:02:38  Lr: 0.001875  Loss: -0.6997  Acc@1: 75.0000 (79.9665)  Acc@5: 93.7500 (96.2737)  time: 0.3448  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [3330/3750]  eta: 0:02:34  Lr: 0.001875  Loss: -0.9095  Acc@1: 75.0000 (79.9647)  Acc@5: 100.0000 (96.2811)  time: 0.3508  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [3340/3750]  eta: 0:02:31  Lr: 0.001875  Loss: -0.7238  Acc@1: 81.2500 (79.9704)  Acc@5: 100.0000 (96.2754)  time: 0.3519  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [3350/3750]  eta: 0:02:27  Lr: 0.001875  Loss: -0.7126  Acc@1: 81.2500 (79.9743)  Acc@5: 100.0000 (96.2791)  time: 0.3479  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [3360/3750]  eta: 0:02:23  Lr: 0.001875  Loss: -1.1057  Acc@1: 81.2500 (79.9892)  Acc@5: 100.0000 (96.2846)  time: 0.3485  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [3370/3750]  eta: 0:02:20  Lr: 0.001875  Loss: -1.1165  Acc@1: 81.2500 (79.9800)  Acc@5: 100.0000 (96.2808)  time: 0.3501  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [3380/3750]  eta: 0:02:16  Lr: 0.001875  Loss: -0.7445  Acc@1: 81.2500 (79.9893)  Acc@5: 93.7500 (96.2770)  time: 0.3529  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [3390/3750]  eta: 0:02:12  Lr: 0.001875  Loss: -0.6299  Acc@1: 81.2500 (79.9727)  Acc@5: 93.7500 (96.2769)  time: 0.3519  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [3400/3750]  eta: 0:02:09  Lr: 0.001875  Loss: -0.8594  Acc@1: 75.0000 (79.9673)  Acc@5: 93.7500 (96.2732)  time: 0.3521  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [3410/3750]  eta: 0:02:05  Lr: 0.001875  Loss: -0.4284  Acc@1: 81.2500 (79.9710)  Acc@5: 93.7500 (96.2731)  time: 0.3514  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [3420/3750]  eta: 0:02:01  Lr: 0.001875  Loss: -0.7168  Acc@1: 81.2500 (79.9748)  Acc@5: 100.0000 (96.2748)  time: 0.3517  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [3430/3750]  eta: 0:01:57  Lr: 0.001875  Loss: -1.0393  Acc@1: 81.2500 (79.9767)  Acc@5: 100.0000 (96.2766)  time: 0.3521  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [3440/3750]  eta: 0:01:54  Lr: 0.001875  Loss: -1.2019  Acc@1: 87.5000 (79.9985)  Acc@5: 100.0000 (96.2783)  time: 0.3494  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3450/3750]  eta: 0:01:50  Lr: 0.001875  Loss: -1.0416  Acc@1: 81.2500 (79.9986)  Acc@5: 100.0000 (96.2837)  time: 0.3491  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3460/3750]  eta: 0:01:46  Lr: 0.001875  Loss: -1.1847  Acc@1: 81.2500 (80.0130)  Acc@5: 100.0000 (96.2872)  time: 0.3479  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3470/3750]  eta: 0:01:43  Lr: 0.001875  Loss: -0.8642  Acc@1: 81.2500 (80.0076)  Acc@5: 100.0000 (96.2853)  time: 0.3476  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3480/3750]  eta: 0:01:39  Lr: 0.001875  Loss: -1.0240  Acc@1: 81.2500 (80.0093)  Acc@5: 93.7500 (96.2816)  time: 0.3472  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3490/3750]  eta: 0:01:35  Lr: 0.001875  Loss: -1.3223  Acc@1: 81.2500 (80.0344)  Acc@5: 100.0000 (96.2869)  time: 0.3458  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [3500/3750]  eta: 0:01:32  Lr: 0.001875  Loss: -1.0677  Acc@1: 87.5000 (80.0343)  Acc@5: 100.0000 (96.2850)  time: 0.3449  data: 0.0002  max mem: 2500
Train: Epoch[2/5]  [3510/3750]  eta: 0:01:28  Lr: 0.001875  Loss: -0.5815  Acc@1: 81.2500 (80.0484)  Acc@5: 93.7500 (96.2885)  time: 0.3464  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [3520/3750]  eta: 0:01:24  Lr: 0.001875  Loss: -0.4679  Acc@1: 81.2500 (80.0270)  Acc@5: 100.0000 (96.2883)  time: 0.3513  data: 0.0014  max mem: 2500
Train: Epoch[2/5]  [3530/3750]  eta: 0:01:20  Lr: 0.001875  Loss: -1.2389  Acc@1: 75.0000 (80.0287)  Acc@5: 93.7500 (96.2865)  time: 0.3542  data: 0.0015  max mem: 2500
Train: Epoch[2/5]  [3540/3750]  eta: 0:01:17  Lr: 0.001875  Loss: -1.1723  Acc@1: 81.2500 (80.0339)  Acc@5: 93.7500 (96.2899)  time: 0.3532  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [3550/3750]  eta: 0:01:13  Lr: 0.001875  Loss: -1.2673  Acc@1: 81.2500 (80.0391)  Acc@5: 100.0000 (96.2898)  time: 0.3522  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [3560/3750]  eta: 0:01:09  Lr: 0.001875  Loss: -1.2578  Acc@1: 81.2500 (80.0407)  Acc@5: 93.7500 (96.2897)  time: 0.3504  data: 0.0015  max mem: 2500
Train: Epoch[2/5]  [3570/3750]  eta: 0:01:06  Lr: 0.001875  Loss: -0.8170  Acc@1: 81.2500 (80.0389)  Acc@5: 100.0000 (96.2931)  time: 0.3526  data: 0.0013  max mem: 2500
Train: Epoch[2/5]  [3580/3750]  eta: 0:01:02  Lr: 0.001875  Loss: -1.0976  Acc@1: 81.2500 (80.0527)  Acc@5: 93.7500 (96.2894)  time: 0.3530  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [3590/3750]  eta: 0:00:58  Lr: 0.001875  Loss: -0.6425  Acc@1: 81.2500 (80.0473)  Acc@5: 93.7500 (96.2893)  time: 0.3520  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [3600/3750]  eta: 0:00:55  Lr: 0.001875  Loss: -0.9413  Acc@1: 75.0000 (80.0420)  Acc@5: 100.0000 (96.2944)  time: 0.3528  data: 0.0012  max mem: 2500
Train: Epoch[2/5]  [3610/3750]  eta: 0:00:51  Lr: 0.001875  Loss: -0.6977  Acc@1: 81.2500 (80.0505)  Acc@5: 100.0000 (96.3030)  time: 0.3534  data: 0.0012  max mem: 2500
Train: Epoch[2/5]  [3620/3750]  eta: 0:00:47  Lr: 0.001875  Loss: -0.8670  Acc@1: 81.2500 (80.0504)  Acc@5: 100.0000 (96.3011)  time: 0.3520  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [3630/3750]  eta: 0:00:44  Lr: 0.001875  Loss: -0.6857  Acc@1: 75.0000 (80.0451)  Acc@5: 100.0000 (96.3010)  time: 0.3483  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [3640/3750]  eta: 0:00:40  Lr: 0.001875  Loss: -0.7614  Acc@1: 75.0000 (80.0381)  Acc@5: 93.7500 (96.3008)  time: 0.3475  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3650/3750]  eta: 0:00:36  Lr: 0.001875  Loss: -1.1311  Acc@1: 81.2500 (80.0380)  Acc@5: 93.7500 (96.3024)  time: 0.3476  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3660/3750]  eta: 0:00:33  Lr: 0.001875  Loss: -1.1548  Acc@1: 81.2500 (80.0242)  Acc@5: 93.7500 (96.3005)  time: 0.3486  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3670/3750]  eta: 0:00:29  Lr: 0.001875  Loss: -0.7547  Acc@1: 81.2500 (80.0310)  Acc@5: 100.0000 (96.3021)  time: 0.3474  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3680/3750]  eta: 0:00:25  Lr: 0.001875  Loss: -0.7657  Acc@1: 81.2500 (80.0428)  Acc@5: 100.0000 (96.3037)  time: 0.3455  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [3690/3750]  eta: 0:00:22  Lr: 0.001875  Loss: -1.3450  Acc@1: 81.2500 (80.0545)  Acc@5: 100.0000 (96.3069)  time: 0.3564  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [3700/3750]  eta: 0:00:18  Lr: 0.001875  Loss: -0.8666  Acc@1: 81.2500 (80.0476)  Acc@5: 100.0000 (96.3051)  time: 0.3578  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [3710/3750]  eta: 0:00:14  Lr: 0.001875  Loss: -0.8165  Acc@1: 75.0000 (80.0357)  Acc@5: 93.7500 (96.2999)  time: 0.3485  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [3720/3750]  eta: 0:00:11  Lr: 0.001875  Loss: -0.7249  Acc@1: 75.0000 (80.0390)  Acc@5: 93.7500 (96.3031)  time: 0.3639  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [3730/3750]  eta: 0:00:07  Lr: 0.001875  Loss: -1.0081  Acc@1: 81.2500 (80.0539)  Acc@5: 100.0000 (96.3096)  time: 0.3652  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [3740/3750]  eta: 0:00:03  Lr: 0.001875  Loss: -0.7948  Acc@1: 81.2500 (80.0521)  Acc@5: 100.0000 (96.3095)  time: 0.3489  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [3749/3750]  eta: 0:00:00  Lr: 0.001875  Loss: -1.1187  Acc@1: 81.2500 (80.0617)  Acc@5: 93.7500 (96.3067)  time: 0.3494  data: 0.0010  max mem: 2500
Train: Epoch[2/5] Total time: 0:22:56 (0.3672 s / it)
{0: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 1: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 2: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 3: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 4: {0: 0, 1: 120000, 2: 0, 3: 0, 4: 0}, 5: {0: 0, 1: 120000, 2: 0, 3: 0, 4: 0}, 6: {0: 0, 1: 120000, 2: 0, 3: 0, 4: 0}, 7: {0: 0, 1: 120000, 2: 0, 3: 0, 4: 0}, 8: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 9: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 10: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 11: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 12: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 13: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 14: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 15: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 16: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 17: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 18: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 19: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}}
Averaged stats: Lr: 0.001875  Loss: -1.1187  Acc@1: 81.2500 (80.0617)  Acc@5: 93.7500 (96.3067)
Train: Epoch[3/5]  [   0/3750]  eta: 1:09:28  Lr: 0.001875  Loss: -0.7452  Acc@1: 75.0000 (75.0000)  Acc@5: 100.0000 (100.0000)  time: 1.1116  data: 0.7119  max mem: 2500
Train: Epoch[3/5]  [  10/3750]  eta: 0:26:30  Lr: 0.001875  Loss: -1.3552  Acc@1: 81.2500 (80.1136)  Acc@5: 93.7500 (95.4545)  time: 0.4252  data: 0.0654  max mem: 2500
Train: Epoch[3/5]  [  20/3750]  eta: 0:24:09  Lr: 0.001875  Loss: -0.7196  Acc@1: 75.0000 (79.4643)  Acc@5: 93.7500 (95.8333)  time: 0.3526  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [  30/3750]  eta: 0:23:15  Lr: 0.001875  Loss: -1.0447  Acc@1: 81.2500 (79.4355)  Acc@5: 100.0000 (95.9677)  time: 0.3476  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [  40/3750]  eta: 0:22:47  Lr: 0.001875  Loss: -1.1964  Acc@1: 81.2500 (79.1159)  Acc@5: 93.7500 (96.0366)  time: 0.3475  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [  50/3750]  eta: 0:22:34  Lr: 0.001875  Loss: -0.7335  Acc@1: 81.2500 (79.9020)  Acc@5: 93.7500 (96.0784)  time: 0.3522  data: 0.0017  max mem: 2500
Train: Epoch[3/5]  [  60/3750]  eta: 0:22:22  Lr: 0.001875  Loss: -0.9397  Acc@1: 81.2500 (80.0205)  Acc@5: 93.7500 (96.0041)  time: 0.3544  data: 0.0023  max mem: 2500
Train: Epoch[3/5]  [  70/3750]  eta: 0:22:10  Lr: 0.001875  Loss: -1.3322  Acc@1: 81.2500 (80.9859)  Acc@5: 93.7500 (96.1268)  time: 0.3497  data: 0.0010  max mem: 2500
Train: Epoch[3/5]  [  80/3750]  eta: 0:22:01  Lr: 0.001875  Loss: -0.9258  Acc@1: 81.2500 (81.0957)  Acc@5: 100.0000 (96.2963)  time: 0.3484  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [  90/3750]  eta: 0:21:54  Lr: 0.001875  Loss: -0.8809  Acc@1: 81.2500 (81.3874)  Acc@5: 100.0000 (96.4973)  time: 0.3507  data: 0.0017  max mem: 2500
Train: Epoch[3/5]  [ 100/3750]  eta: 0:21:47  Lr: 0.001875  Loss: -0.8259  Acc@1: 81.2500 (81.8688)  Acc@5: 100.0000 (96.6584)  time: 0.3503  data: 0.0016  max mem: 2500
Train: Epoch[3/5]  [ 110/3750]  eta: 0:21:39  Lr: 0.001875  Loss: -1.0845  Acc@1: 87.5000 (81.9820)  Acc@5: 100.0000 (96.9032)  time: 0.3476  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 120/3750]  eta: 0:21:32  Lr: 0.001875  Loss: -1.3440  Acc@1: 81.2500 (82.0248)  Acc@5: 100.0000 (96.9008)  time: 0.3455  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [ 130/3750]  eta: 0:21:27  Lr: 0.001875  Loss: -0.8912  Acc@1: 87.5000 (82.2996)  Acc@5: 100.0000 (96.8989)  time: 0.3472  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 140/3750]  eta: 0:21:21  Lr: 0.001875  Loss: -1.1496  Acc@1: 81.2500 (82.1365)  Acc@5: 100.0000 (96.9858)  time: 0.3488  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 150/3750]  eta: 0:21:15  Lr: 0.001875  Loss: -0.9501  Acc@1: 81.2500 (82.2434)  Acc@5: 100.0000 (96.8957)  time: 0.3466  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [ 160/3750]  eta: 0:21:10  Lr: 0.001875  Loss: -1.1176  Acc@1: 81.2500 (82.2593)  Acc@5: 93.7500 (96.8556)  time: 0.3468  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 170/3750]  eta: 0:21:07  Lr: 0.001875  Loss: -0.3641  Acc@1: 81.2500 (82.1637)  Acc@5: 93.7500 (96.7105)  time: 0.3515  data: 0.0009  max mem: 2500
Train: Epoch[3/5]  [ 180/3750]  eta: 0:21:04  Lr: 0.001875  Loss: -0.9822  Acc@1: 81.2500 (82.3204)  Acc@5: 93.7500 (96.7196)  time: 0.3558  data: 0.0019  max mem: 2500
Train: Epoch[3/5]  [ 190/3750]  eta: 0:21:03  Lr: 0.001875  Loss: -0.8060  Acc@1: 81.2500 (82.2644)  Acc@5: 93.7500 (96.5969)  time: 0.3612  data: 0.0015  max mem: 2500
Train: Epoch[3/5]  [ 200/3750]  eta: 0:20:58  Lr: 0.001875  Loss: -0.7386  Acc@1: 75.0000 (82.1206)  Acc@5: 93.7500 (96.5796)  time: 0.3583  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [ 210/3750]  eta: 0:20:54  Lr: 0.001875  Loss: -0.6747  Acc@1: 75.0000 (81.9313)  Acc@5: 93.7500 (96.5047)  time: 0.3502  data: 0.0009  max mem: 2500
Train: Epoch[3/5]  [ 220/3750]  eta: 0:20:53  Lr: 0.001875  Loss: -1.2030  Acc@1: 81.2500 (81.9005)  Acc@5: 93.7500 (96.4084)  time: 0.3594  data: 0.0009  max mem: 2500
Train: Epoch[3/5]  [ 230/3750]  eta: 0:21:45  Lr: 0.001875  Loss: -0.9883  Acc@1: 81.2500 (81.7370)  Acc@5: 93.7500 (96.2933)  time: 0.5449  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [ 240/3750]  eta: 0:22:36  Lr: 0.001875  Loss: -1.2073  Acc@1: 81.2500 (81.6909)  Acc@5: 93.7500 (96.2656)  time: 0.7337  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [ 250/3750]  eta: 0:23:23  Lr: 0.001875  Loss: -1.0222  Acc@1: 81.2500 (81.6982)  Acc@5: 100.0000 (96.3147)  time: 0.7487  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [ 260/3750]  eta: 0:24:05  Lr: 0.001875  Loss: -1.0663  Acc@1: 81.2500 (81.7050)  Acc@5: 100.0000 (96.3841)  time: 0.7479  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [ 270/3750]  eta: 0:24:43  Lr: 0.001875  Loss: -0.4652  Acc@1: 81.2500 (81.6882)  Acc@5: 100.0000 (96.3792)  time: 0.7451  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 280/3750]  eta: 0:25:18  Lr: 0.001875  Loss: -1.0249  Acc@1: 81.2500 (81.5836)  Acc@5: 100.0000 (96.3968)  time: 0.7447  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 290/3750]  eta: 0:25:51  Lr: 0.001875  Loss: -0.7751  Acc@1: 81.2500 (81.5507)  Acc@5: 100.0000 (96.4347)  time: 0.7463  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 300/3750]  eta: 0:26:21  Lr: 0.001875  Loss: -0.9768  Acc@1: 81.2500 (81.6030)  Acc@5: 100.0000 (96.4909)  time: 0.7488  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [ 310/3750]  eta: 0:26:49  Lr: 0.001875  Loss: -1.0706  Acc@1: 81.2500 (81.6318)  Acc@5: 100.0000 (96.4831)  time: 0.7511  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [ 320/3750]  eta: 0:27:14  Lr: 0.001875  Loss: -1.4030  Acc@1: 81.2500 (81.6589)  Acc@5: 93.7500 (96.4369)  time: 0.7484  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [ 330/3750]  eta: 0:27:37  Lr: 0.001875  Loss: -0.7445  Acc@1: 75.0000 (81.4388)  Acc@5: 93.7500 (96.3746)  time: 0.7465  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 340/3750]  eta: 0:27:58  Lr: 0.001875  Loss: -1.2189  Acc@1: 75.0000 (81.4883)  Acc@5: 93.7500 (96.3893)  time: 0.7455  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [ 350/3750]  eta: 0:28:17  Lr: 0.001875  Loss: -1.0547  Acc@1: 81.2500 (81.4103)  Acc@5: 100.0000 (96.4387)  time: 0.7414  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 360/3750]  eta: 0:28:35  Lr: 0.001875  Loss: -0.8280  Acc@1: 81.2500 (81.4578)  Acc@5: 100.0000 (96.4681)  time: 0.7406  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [ 370/3750]  eta: 0:28:51  Lr: 0.001875  Loss: -1.0209  Acc@1: 81.2500 (81.4690)  Acc@5: 100.0000 (96.5128)  time: 0.7421  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [ 380/3750]  eta: 0:29:06  Lr: 0.001875  Loss: -0.5950  Acc@1: 81.2500 (81.3484)  Acc@5: 100.0000 (96.5387)  time: 0.7397  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [ 390/3750]  eta: 0:29:20  Lr: 0.001875  Loss: -0.7981  Acc@1: 81.2500 (81.2340)  Acc@5: 93.7500 (96.4674)  time: 0.7393  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [ 400/3750]  eta: 0:29:33  Lr: 0.001875  Loss: -0.9108  Acc@1: 75.0000 (81.0941)  Acc@5: 93.7500 (96.4152)  time: 0.7401  data: 0.0012  max mem: 2500
Train: Epoch[3/5]  [ 410/3750]  eta: 0:29:45  Lr: 0.001875  Loss: -0.7664  Acc@1: 75.0000 (81.0675)  Acc@5: 93.7500 (96.3656)  time: 0.7397  data: 0.0011  max mem: 2500
Train: Epoch[3/5]  [ 420/3750]  eta: 0:29:55  Lr: 0.001875  Loss: -0.5802  Acc@1: 81.2500 (81.0125)  Acc@5: 93.7500 (96.3183)  time: 0.7398  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [ 430/3750]  eta: 0:30:06  Lr: 0.001875  Loss: -0.6752  Acc@1: 81.2500 (81.0035)  Acc@5: 93.7500 (96.3602)  time: 0.7441  data: 0.0020  max mem: 2500
Train: Epoch[3/5]  [ 440/3750]  eta: 0:30:16  Lr: 0.001875  Loss: -1.0465  Acc@1: 81.2500 (81.1083)  Acc@5: 100.0000 (96.3861)  time: 0.7475  data: 0.0016  max mem: 2500
Train: Epoch[3/5]  [ 450/3750]  eta: 0:30:25  Lr: 0.001875  Loss: -1.0026  Acc@1: 81.2500 (81.1253)  Acc@5: 100.0000 (96.4385)  time: 0.7446  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [ 460/3750]  eta: 0:30:32  Lr: 0.001875  Loss: -1.0706  Acc@1: 81.2500 (81.1822)  Acc@5: 100.0000 (96.4208)  time: 0.7409  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [ 470/3750]  eta: 0:30:39  Lr: 0.001875  Loss: -1.2482  Acc@1: 81.2500 (81.1173)  Acc@5: 93.7500 (96.4172)  time: 0.7367  data: 0.0012  max mem: 2500
Train: Epoch[3/5]  [ 480/3750]  eta: 0:30:46  Lr: 0.001875  Loss: -0.8012  Acc@1: 81.2500 (81.2110)  Acc@5: 100.0000 (96.4267)  time: 0.7380  data: 0.0015  max mem: 2500
Train: Epoch[3/5]  [ 490/3750]  eta: 0:30:51  Lr: 0.001875  Loss: -1.2227  Acc@1: 87.5000 (81.3391)  Acc@5: 100.0000 (96.4231)  time: 0.7333  data: 0.0013  max mem: 2500
Train: Epoch[3/5]  [ 500/3750]  eta: 0:30:57  Lr: 0.001875  Loss: -0.8054  Acc@1: 87.5000 (81.2874)  Acc@5: 93.7500 (96.4321)  time: 0.7360  data: 0.0010  max mem: 2500
Train: Epoch[3/5]  [ 510/3750]  eta: 0:31:01  Lr: 0.001875  Loss: -0.8568  Acc@1: 75.0000 (81.1644)  Acc@5: 93.7500 (96.4286)  time: 0.7406  data: 0.0009  max mem: 2500
Train: Epoch[3/5]  [ 520/3750]  eta: 0:31:05  Lr: 0.001875  Loss: -1.0418  Acc@1: 81.2500 (81.0701)  Acc@5: 93.7500 (96.3892)  time: 0.7340  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [ 530/3750]  eta: 0:31:05  Lr: 0.001875  Loss: -0.8072  Acc@1: 81.2500 (81.1676)  Acc@5: 100.0000 (96.4336)  time: 0.6966  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 540/3750]  eta: 0:31:08  Lr: 0.001875  Loss: -1.2569  Acc@1: 81.2500 (81.1114)  Acc@5: 100.0000 (96.3956)  time: 0.6961  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [ 550/3750]  eta: 0:31:11  Lr: 0.001875  Loss: -0.8735  Acc@1: 81.2500 (81.1139)  Acc@5: 93.7500 (96.3589)  time: 0.7339  data: 0.0013  max mem: 2500
Train: Epoch[3/5]  [ 560/3750]  eta: 0:31:14  Lr: 0.001875  Loss: -1.0772  Acc@1: 81.2500 (81.0940)  Acc@5: 93.7500 (96.3347)  time: 0.7359  data: 0.0013  max mem: 2500
Train: Epoch[3/5]  [ 570/3750]  eta: 0:31:16  Lr: 0.001875  Loss: -0.4343  Acc@1: 81.2500 (81.1077)  Acc@5: 93.7500 (96.3332)  time: 0.7340  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 580/3750]  eta: 0:31:01  Lr: 0.001875  Loss: -1.1508  Acc@1: 81.2500 (81.1209)  Acc@5: 93.7500 (96.2887)  time: 0.5753  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [ 590/3750]  eta: 0:30:54  Lr: 0.001875  Loss: -1.1519  Acc@1: 81.2500 (81.1231)  Acc@5: 100.0000 (96.3198)  time: 0.4928  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [ 600/3750]  eta: 0:30:55  Lr: 0.001875  Loss: -0.4271  Acc@1: 81.2500 (81.0940)  Acc@5: 100.0000 (96.3394)  time: 0.6474  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [ 610/3750]  eta: 0:30:57  Lr: 0.001875  Loss: -0.9170  Acc@1: 81.2500 (81.0556)  Acc@5: 100.0000 (96.3687)  time: 0.7318  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [ 620/3750]  eta: 0:30:58  Lr: 0.001875  Loss: -1.2648  Acc@1: 81.2500 (81.0588)  Acc@5: 100.0000 (96.3768)  time: 0.7321  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 630/3750]  eta: 0:30:44  Lr: 0.001875  Loss: -0.8917  Acc@1: 87.5000 (81.0816)  Acc@5: 100.0000 (96.3847)  time: 0.5798  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [ 640/3750]  eta: 0:30:26  Lr: 0.001875  Loss: -0.7157  Acc@1: 81.2500 (81.0940)  Acc@5: 93.7500 (96.3534)  time: 0.3902  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 650/3750]  eta: 0:30:09  Lr: 0.001875  Loss: -1.1565  Acc@1: 81.2500 (81.0676)  Acc@5: 100.0000 (96.3614)  time: 0.3467  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [ 660/3750]  eta: 0:29:52  Lr: 0.001875  Loss: -0.8410  Acc@1: 81.2500 (81.0703)  Acc@5: 100.0000 (96.3880)  time: 0.3450  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [ 670/3750]  eta: 0:29:36  Lr: 0.001875  Loss: -0.8065  Acc@1: 81.2500 (81.0265)  Acc@5: 100.0000 (96.3767)  time: 0.3485  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 680/3750]  eta: 0:29:20  Lr: 0.001875  Loss: -1.1253  Acc@1: 75.0000 (80.9563)  Acc@5: 93.7500 (96.3840)  time: 0.3579  data: 0.0010  max mem: 2500
Train: Epoch[3/5]  [ 690/3750]  eta: 0:29:05  Lr: 0.001875  Loss: -1.1201  Acc@1: 75.0000 (80.9606)  Acc@5: 93.7500 (96.3730)  time: 0.3558  data: 0.0011  max mem: 2500
Train: Epoch[3/5]  [ 700/3750]  eta: 0:28:49  Lr: 0.001875  Loss: -1.4373  Acc@1: 81.2500 (81.0093)  Acc@5: 93.7500 (96.3802)  time: 0.3495  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [ 710/3750]  eta: 0:28:39  Lr: 0.001875  Loss: -0.9208  Acc@1: 81.2500 (80.9863)  Acc@5: 100.0000 (96.3871)  time: 0.4090  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [ 720/3750]  eta: 0:28:42  Lr: 0.001875  Loss: -0.5878  Acc@1: 81.2500 (81.0073)  Acc@5: 93.7500 (96.3766)  time: 0.6106  data: 0.0009  max mem: 2500
Train: Epoch[3/5]  [ 730/3750]  eta: 0:28:44  Lr: 0.001875  Loss: -1.0902  Acc@1: 87.5000 (80.9679)  Acc@5: 93.7500 (96.3663)  time: 0.7550  data: 0.0010  max mem: 2500
Train: Epoch[3/5]  [ 740/3750]  eta: 0:28:45  Lr: 0.001875  Loss: -0.7722  Acc@1: 81.2500 (80.9295)  Acc@5: 93.7500 (96.3225)  time: 0.7512  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [ 750/3750]  eta: 0:28:46  Lr: 0.001875  Loss: -1.2410  Acc@1: 81.2500 (81.0003)  Acc@5: 100.0000 (96.3632)  time: 0.7478  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [ 760/3750]  eta: 0:28:47  Lr: 0.001875  Loss: -1.2576  Acc@1: 87.5000 (81.0200)  Acc@5: 100.0000 (96.3535)  time: 0.7481  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 770/3750]  eta: 0:28:48  Lr: 0.001875  Loss: -1.1462  Acc@1: 81.2500 (81.0473)  Acc@5: 100.0000 (96.3846)  time: 0.7477  data: 0.0010  max mem: 2500
Train: Epoch[3/5]  [ 780/3750]  eta: 0:28:49  Lr: 0.001875  Loss: -1.2501  Acc@1: 87.5000 (81.1220)  Acc@5: 100.0000 (96.4069)  time: 0.7484  data: 0.0010  max mem: 2500
Train: Epoch[3/5]  [ 790/3750]  eta: 0:28:49  Lr: 0.001875  Loss: -0.6887  Acc@1: 87.5000 (81.1315)  Acc@5: 100.0000 (96.3970)  time: 0.7498  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 800/3750]  eta: 0:28:50  Lr: 0.001875  Loss: -1.0179  Acc@1: 81.2500 (81.0939)  Acc@5: 93.7500 (96.3873)  time: 0.7508  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [ 810/3750]  eta: 0:28:50  Lr: 0.001875  Loss: -0.3845  Acc@1: 81.2500 (81.1036)  Acc@5: 93.7500 (96.3779)  time: 0.7494  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [ 820/3750]  eta: 0:28:49  Lr: 0.001875  Loss: -1.0549  Acc@1: 81.2500 (81.1054)  Acc@5: 93.7500 (96.3688)  time: 0.7439  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [ 830/3750]  eta: 0:28:48  Lr: 0.001875  Loss: -0.7579  Acc@1: 81.2500 (81.0695)  Acc@5: 93.7500 (96.3748)  time: 0.7401  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [ 840/3750]  eta: 0:28:48  Lr: 0.001875  Loss: -0.4073  Acc@1: 81.2500 (81.0493)  Acc@5: 93.7500 (96.3659)  time: 0.7410  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [ 850/3750]  eta: 0:28:47  Lr: 0.001875  Loss: -0.6479  Acc@1: 81.2500 (81.0664)  Acc@5: 100.0000 (96.3793)  time: 0.7416  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [ 860/3750]  eta: 0:28:46  Lr: 0.001875  Loss: -0.9143  Acc@1: 81.2500 (81.0467)  Acc@5: 100.0000 (96.3850)  time: 0.7410  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 870/3750]  eta: 0:28:45  Lr: 0.001875  Loss: -0.9253  Acc@1: 81.2500 (81.0563)  Acc@5: 100.0000 (96.4050)  time: 0.7417  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 880/3750]  eta: 0:28:43  Lr: 0.001875  Loss: -0.8271  Acc@1: 81.2500 (81.0088)  Acc@5: 100.0000 (96.3820)  time: 0.7445  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [ 890/3750]  eta: 0:28:42  Lr: 0.001875  Loss: -0.9251  Acc@1: 75.0000 (80.9834)  Acc@5: 93.7500 (96.3594)  time: 0.7470  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [ 900/3750]  eta: 0:28:41  Lr: 0.001875  Loss: -0.2998  Acc@1: 81.2500 (81.0003)  Acc@5: 100.0000 (96.3860)  time: 0.7491  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [ 910/3750]  eta: 0:28:39  Lr: 0.001875  Loss: -1.0570  Acc@1: 81.2500 (80.9962)  Acc@5: 100.0000 (96.3707)  time: 0.7449  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [ 920/3750]  eta: 0:28:37  Lr: 0.001875  Loss: -1.1370  Acc@1: 81.2500 (80.9853)  Acc@5: 93.7500 (96.3762)  time: 0.7371  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [ 930/3750]  eta: 0:28:35  Lr: 0.001875  Loss: -1.3379  Acc@1: 81.2500 (80.9278)  Acc@5: 100.0000 (96.3749)  time: 0.7399  data: 0.0012  max mem: 2500
Train: Epoch[3/5]  [ 940/3750]  eta: 0:28:33  Lr: 0.001875  Loss: -1.0434  Acc@1: 75.0000 (80.9312)  Acc@5: 93.7500 (96.3735)  time: 0.7429  data: 0.0011  max mem: 2500
Train: Epoch[3/5]  [ 950/3750]  eta: 0:28:31  Lr: 0.001875  Loss: -0.8301  Acc@1: 81.2500 (80.9477)  Acc@5: 93.7500 (96.3657)  time: 0.7421  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 960/3750]  eta: 0:28:28  Lr: 0.001875  Loss: -0.7239  Acc@1: 81.2500 (80.9703)  Acc@5: 93.7500 (96.3580)  time: 0.7382  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [ 970/3750]  eta: 0:28:26  Lr: 0.001875  Loss: -1.2593  Acc@1: 81.2500 (80.9861)  Acc@5: 100.0000 (96.3633)  time: 0.7365  data: 0.0013  max mem: 2500
Train: Epoch[3/5]  [ 980/3750]  eta: 0:28:23  Lr: 0.001875  Loss: -1.1488  Acc@1: 81.2500 (80.9569)  Acc@5: 100.0000 (96.3685)  time: 0.7367  data: 0.0015  max mem: 2500
Train: Epoch[3/5]  [ 990/3750]  eta: 0:28:20  Lr: 0.001875  Loss: -0.8502  Acc@1: 81.2500 (81.0040)  Acc@5: 93.7500 (96.3610)  time: 0.7326  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [1000/3750]  eta: 0:28:17  Lr: 0.001875  Loss: -1.0528  Acc@1: 81.2500 (81.0002)  Acc@5: 93.7500 (96.3474)  time: 0.7351  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [1010/3750]  eta: 0:28:14  Lr: 0.001875  Loss: -0.8483  Acc@1: 81.2500 (80.9965)  Acc@5: 93.7500 (96.3217)  time: 0.7356  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [1020/3750]  eta: 0:28:09  Lr: 0.001875  Loss: -0.4822  Acc@1: 81.2500 (81.0235)  Acc@5: 100.0000 (96.3333)  time: 0.6991  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [1030/3750]  eta: 0:28:06  Lr: 0.001875  Loss: -1.0527  Acc@1: 81.2500 (81.0378)  Acc@5: 100.0000 (96.3324)  time: 0.7012  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1040/3750]  eta: 0:28:03  Lr: 0.001875  Loss: -0.8232  Acc@1: 81.2500 (81.0159)  Acc@5: 93.7500 (96.3196)  time: 0.7358  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1050/3750]  eta: 0:27:59  Lr: 0.001875  Loss: -0.7885  Acc@1: 81.2500 (80.9883)  Acc@5: 93.7500 (96.3190)  time: 0.7306  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [1060/3750]  eta: 0:27:56  Lr: 0.001875  Loss: -1.1845  Acc@1: 81.2500 (80.9672)  Acc@5: 100.0000 (96.3360)  time: 0.7311  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1070/3750]  eta: 0:27:53  Lr: 0.001875  Loss: -1.1009  Acc@1: 81.2500 (80.9641)  Acc@5: 93.7500 (96.3177)  time: 0.7356  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [1080/3750]  eta: 0:27:49  Lr: 0.001875  Loss: -1.0193  Acc@1: 81.2500 (80.9494)  Acc@5: 93.7500 (96.3286)  time: 0.7358  data: 0.0009  max mem: 2500
Train: Epoch[3/5]  [1090/3750]  eta: 0:27:46  Lr: 0.001875  Loss: -1.0968  Acc@1: 81.2500 (80.9578)  Acc@5: 100.0000 (96.3165)  time: 0.7457  data: 0.0022  max mem: 2500
Train: Epoch[3/5]  [1100/3750]  eta: 0:27:43  Lr: 0.001875  Loss: -1.0246  Acc@1: 81.2500 (80.9718)  Acc@5: 100.0000 (96.3272)  time: 0.7506  data: 0.0021  max mem: 2500
Train: Epoch[3/5]  [1110/3750]  eta: 0:27:39  Lr: 0.001875  Loss: -0.9752  Acc@1: 81.2500 (80.9743)  Acc@5: 100.0000 (96.3490)  time: 0.7402  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [1120/3750]  eta: 0:27:35  Lr: 0.001875  Loss: -0.6618  Acc@1: 81.2500 (80.9712)  Acc@5: 100.0000 (96.3481)  time: 0.7342  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [1130/3750]  eta: 0:27:31  Lr: 0.001875  Loss: -0.4958  Acc@1: 81.2500 (80.9516)  Acc@5: 100.0000 (96.3528)  time: 0.7318  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1140/3750]  eta: 0:27:27  Lr: 0.001875  Loss: -1.0026  Acc@1: 81.2500 (80.9268)  Acc@5: 100.0000 (96.3738)  time: 0.7310  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [1150/3750]  eta: 0:27:23  Lr: 0.001875  Loss: -1.1728  Acc@1: 75.0000 (80.8916)  Acc@5: 100.0000 (96.3781)  time: 0.7315  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [1160/3750]  eta: 0:27:19  Lr: 0.001875  Loss: -1.1886  Acc@1: 81.2500 (80.8947)  Acc@5: 100.0000 (96.3717)  time: 0.7339  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [1170/3750]  eta: 0:27:15  Lr: 0.001875  Loss: -0.6044  Acc@1: 81.2500 (80.8817)  Acc@5: 93.7500 (96.3599)  time: 0.7365  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [1180/3750]  eta: 0:27:11  Lr: 0.001875  Loss: -1.1523  Acc@1: 81.2500 (80.8954)  Acc@5: 93.7500 (96.3696)  time: 0.7360  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [1190/3750]  eta: 0:27:07  Lr: 0.001875  Loss: -1.2872  Acc@1: 81.2500 (80.9037)  Acc@5: 100.0000 (96.3738)  time: 0.7341  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [1200/3750]  eta: 0:27:02  Lr: 0.001875  Loss: -1.3250  Acc@1: 87.5000 (80.9534)  Acc@5: 100.0000 (96.3728)  time: 0.7342  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [1210/3750]  eta: 0:26:58  Lr: 0.001875  Loss: -0.9012  Acc@1: 87.5000 (80.9300)  Acc@5: 100.0000 (96.3924)  time: 0.7345  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [1220/3750]  eta: 0:26:54  Lr: 0.001875  Loss: -1.3069  Acc@1: 81.2500 (80.9480)  Acc@5: 100.0000 (96.4066)  time: 0.7328  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [1230/3750]  eta: 0:26:49  Lr: 0.001875  Loss: -1.1485  Acc@1: 81.2500 (80.9403)  Acc@5: 100.0000 (96.4003)  time: 0.7321  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [1240/3750]  eta: 0:26:45  Lr: 0.001875  Loss: -1.2632  Acc@1: 81.2500 (80.9176)  Acc@5: 93.7500 (96.3940)  time: 0.7315  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [1250/3750]  eta: 0:26:40  Lr: 0.001875  Loss: -0.9749  Acc@1: 75.0000 (80.8903)  Acc@5: 93.7500 (96.3729)  time: 0.7331  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [1260/3750]  eta: 0:26:36  Lr: 0.001875  Loss: -1.1298  Acc@1: 81.2500 (80.9031)  Acc@5: 93.7500 (96.3868)  time: 0.7400  data: 0.0011  max mem: 2500
Train: Epoch[3/5]  [1270/3750]  eta: 0:26:31  Lr: 0.001875  Loss: -1.1337  Acc@1: 81.2500 (80.8959)  Acc@5: 100.0000 (96.3808)  time: 0.7404  data: 0.0012  max mem: 2500
Train: Epoch[3/5]  [1280/3750]  eta: 0:26:27  Lr: 0.001875  Loss: -1.1460  Acc@1: 81.2500 (80.8792)  Acc@5: 100.0000 (96.3944)  time: 0.7373  data: 0.0026  max mem: 2500
Train: Epoch[3/5]  [1290/3750]  eta: 0:26:22  Lr: 0.001875  Loss: -0.8036  Acc@1: 81.2500 (80.8918)  Acc@5: 93.7500 (96.3788)  time: 0.7354  data: 0.0023  max mem: 2500
Train: Epoch[3/5]  [1300/3750]  eta: 0:26:17  Lr: 0.001875  Loss: -1.1689  Acc@1: 81.2500 (80.8705)  Acc@5: 93.7500 (96.3874)  time: 0.7335  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [1310/3750]  eta: 0:26:13  Lr: 0.001875  Loss: -0.8950  Acc@1: 87.5000 (80.9068)  Acc@5: 100.0000 (96.4006)  time: 0.7336  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [1320/3750]  eta: 0:26:08  Lr: 0.001875  Loss: -0.5839  Acc@1: 87.5000 (80.9093)  Acc@5: 100.0000 (96.3900)  time: 0.7290  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [1330/3750]  eta: 0:26:03  Lr: 0.001875  Loss: -0.6328  Acc@1: 81.2500 (80.9213)  Acc@5: 93.7500 (96.3890)  time: 0.7283  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [1340/3750]  eta: 0:25:58  Lr: 0.001875  Loss: -1.1684  Acc@1: 87.5000 (80.9377)  Acc@5: 100.0000 (96.3880)  time: 0.7324  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [1350/3750]  eta: 0:25:53  Lr: 0.001875  Loss: -0.6036  Acc@1: 87.5000 (80.9678)  Acc@5: 93.7500 (96.3823)  time: 0.7318  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [1360/3750]  eta: 0:25:47  Lr: 0.001875  Loss: -0.5873  Acc@1: 87.5000 (80.9699)  Acc@5: 93.7500 (96.3813)  time: 0.7029  data: 0.0012  max mem: 2500
Train: Epoch[3/5]  [1370/3750]  eta: 0:25:42  Lr: 0.001875  Loss: -0.7028  Acc@1: 81.2500 (80.9902)  Acc@5: 100.0000 (96.3849)  time: 0.7030  data: 0.0022  max mem: 2500
Train: Epoch[3/5]  [1380/3750]  eta: 0:25:37  Lr: 0.001875  Loss: -0.7310  Acc@1: 81.2500 (80.9966)  Acc@5: 93.7500 (96.3704)  time: 0.7309  data: 0.0014  max mem: 2500
Train: Epoch[3/5]  [1390/3750]  eta: 0:25:32  Lr: 0.001875  Loss: -1.2319  Acc@1: 81.2500 (80.9849)  Acc@5: 93.7500 (96.3740)  time: 0.7270  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1400/3750]  eta: 0:25:23  Lr: 0.001875  Loss: -0.9910  Acc@1: 75.0000 (80.9466)  Acc@5: 100.0000 (96.3642)  time: 0.6121  data: 0.0012  max mem: 2500
Train: Epoch[3/5]  [1410/3750]  eta: 0:25:12  Lr: 0.001875  Loss: -1.0757  Acc@1: 81.2500 (80.9488)  Acc@5: 93.7500 (96.3590)  time: 0.4662  data: 0.0014  max mem: 2500
Train: Epoch[3/5]  [1420/3750]  eta: 0:25:05  Lr: 0.001875  Loss: -1.0172  Acc@1: 87.5000 (80.9685)  Acc@5: 93.7500 (96.3670)  time: 0.5075  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [1430/3750]  eta: 0:24:54  Lr: 0.001875  Loss: -0.7992  Acc@1: 87.5000 (81.0010)  Acc@5: 100.0000 (96.3705)  time: 0.4657  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [1440/3750]  eta: 0:24:43  Lr: 0.001875  Loss: -1.0993  Acc@1: 81.2500 (81.0071)  Acc@5: 100.0000 (96.3784)  time: 0.3511  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [1450/3750]  eta: 0:24:32  Lr: 0.001875  Loss: -0.7814  Acc@1: 81.2500 (81.0045)  Acc@5: 100.0000 (96.3861)  time: 0.3546  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [1460/3750]  eta: 0:24:21  Lr: 0.001875  Loss: -1.0439  Acc@1: 81.2500 (81.0275)  Acc@5: 100.0000 (96.3895)  time: 0.3504  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [1470/3750]  eta: 0:24:10  Lr: 0.001875  Loss: -0.2347  Acc@1: 81.2500 (81.0121)  Acc@5: 93.7500 (96.3885)  time: 0.3496  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [1480/3750]  eta: 0:23:59  Lr: 0.001875  Loss: -1.1162  Acc@1: 81.2500 (81.0306)  Acc@5: 100.0000 (96.4002)  time: 0.3524  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [1490/3750]  eta: 0:23:49  Lr: 0.001875  Loss: -1.0158  Acc@1: 81.2500 (81.0111)  Acc@5: 100.0000 (96.4076)  time: 0.3534  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [1500/3750]  eta: 0:23:38  Lr: 0.001875  Loss: -0.9914  Acc@1: 81.2500 (81.0251)  Acc@5: 100.0000 (96.4024)  time: 0.3510  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [1510/3750]  eta: 0:23:27  Lr: 0.001875  Loss: -1.3635  Acc@1: 81.2500 (81.0390)  Acc@5: 100.0000 (96.3931)  time: 0.3474  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [1520/3750]  eta: 0:23:17  Lr: 0.001875  Loss: -0.6611  Acc@1: 81.2500 (81.0487)  Acc@5: 100.0000 (96.4004)  time: 0.3473  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [1530/3750]  eta: 0:23:07  Lr: 0.001875  Loss: -0.7246  Acc@1: 81.2500 (81.0663)  Acc@5: 93.7500 (96.3872)  time: 0.3488  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [1540/3750]  eta: 0:22:57  Lr: 0.001875  Loss: -0.7171  Acc@1: 87.5000 (81.0918)  Acc@5: 93.7500 (96.3944)  time: 0.3498  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1550/3750]  eta: 0:22:46  Lr: 0.001875  Loss: -1.3019  Acc@1: 87.5000 (81.1049)  Acc@5: 100.0000 (96.3773)  time: 0.3498  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1560/3750]  eta: 0:22:36  Lr: 0.001875  Loss: -0.9430  Acc@1: 81.2500 (81.0858)  Acc@5: 93.7500 (96.3645)  time: 0.3495  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [1570/3750]  eta: 0:22:26  Lr: 0.001875  Loss: -0.7211  Acc@1: 81.2500 (81.0988)  Acc@5: 93.7500 (96.3678)  time: 0.3493  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1580/3750]  eta: 0:22:17  Lr: 0.001875  Loss: -1.0349  Acc@1: 87.5000 (81.1275)  Acc@5: 100.0000 (96.3789)  time: 0.3504  data: 0.0011  max mem: 2500
Train: Epoch[3/5]  [1590/3750]  eta: 0:22:07  Lr: 0.001875  Loss: -0.5333  Acc@1: 81.2500 (81.1047)  Acc@5: 100.0000 (96.3820)  time: 0.3474  data: 0.0010  max mem: 2500
Train: Epoch[3/5]  [1600/3750]  eta: 0:21:57  Lr: 0.001875  Loss: -0.7926  Acc@1: 81.2500 (81.1134)  Acc@5: 100.0000 (96.3812)  time: 0.3450  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [1610/3750]  eta: 0:21:47  Lr: 0.001875  Loss: -1.2077  Acc@1: 81.2500 (81.1103)  Acc@5: 93.7500 (96.3687)  time: 0.3464  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [1620/3750]  eta: 0:21:38  Lr: 0.001875  Loss: -0.8439  Acc@1: 81.2500 (81.1228)  Acc@5: 93.7500 (96.3718)  time: 0.3458  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [1630/3750]  eta: 0:21:28  Lr: 0.001875  Loss: -0.6133  Acc@1: 81.2500 (81.0891)  Acc@5: 93.7500 (96.3519)  time: 0.3457  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [1640/3750]  eta: 0:21:19  Lr: 0.001875  Loss: -1.0855  Acc@1: 81.2500 (81.0786)  Acc@5: 93.7500 (96.3551)  time: 0.3468  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [1650/3750]  eta: 0:21:10  Lr: 0.001875  Loss: -1.0331  Acc@1: 81.2500 (81.0834)  Acc@5: 100.0000 (96.3621)  time: 0.3501  data: 0.0011  max mem: 2500
Train: Epoch[3/5]  [1660/3750]  eta: 0:21:00  Lr: 0.001875  Loss: -0.8947  Acc@1: 81.2500 (81.0957)  Acc@5: 100.0000 (96.3614)  time: 0.3508  data: 0.0012  max mem: 2500
Train: Epoch[3/5]  [1670/3750]  eta: 0:20:51  Lr: 0.001875  Loss: -0.7719  Acc@1: 81.2500 (81.0854)  Acc@5: 100.0000 (96.3757)  time: 0.3469  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1680/3750]  eta: 0:20:42  Lr: 0.001875  Loss: -1.1431  Acc@1: 81.2500 (81.1162)  Acc@5: 100.0000 (96.3861)  time: 0.3457  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [1690/3750]  eta: 0:20:33  Lr: 0.001875  Loss: -0.9800  Acc@1: 87.5000 (81.1206)  Acc@5: 100.0000 (96.3927)  time: 0.3462  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1700/3750]  eta: 0:20:24  Lr: 0.001875  Loss: -0.8198  Acc@1: 81.2500 (81.1141)  Acc@5: 100.0000 (96.3735)  time: 0.3523  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [1710/3750]  eta: 0:20:15  Lr: 0.001875  Loss: -0.7349  Acc@1: 81.2500 (81.1514)  Acc@5: 100.0000 (96.3837)  time: 0.3523  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [1720/3750]  eta: 0:20:06  Lr: 0.001875  Loss: -1.3851  Acc@1: 81.2500 (81.1665)  Acc@5: 100.0000 (96.3938)  time: 0.3464  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [1730/3750]  eta: 0:19:57  Lr: 0.001875  Loss: -0.9853  Acc@1: 81.2500 (81.1670)  Acc@5: 100.0000 (96.3966)  time: 0.3475  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1740/3750]  eta: 0:19:48  Lr: 0.001875  Loss: -0.6017  Acc@1: 81.2500 (81.1531)  Acc@5: 100.0000 (96.4029)  time: 0.3500  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [1750/3750]  eta: 0:19:40  Lr: 0.001875  Loss: -0.8180  Acc@1: 75.0000 (81.1393)  Acc@5: 100.0000 (96.4092)  time: 0.3484  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1760/3750]  eta: 0:19:31  Lr: 0.001875  Loss: -0.8069  Acc@1: 81.2500 (81.1648)  Acc@5: 100.0000 (96.4118)  time: 0.3458  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [1770/3750]  eta: 0:19:23  Lr: 0.001875  Loss: -1.0217  Acc@1: 87.5000 (81.1794)  Acc@5: 100.0000 (96.4180)  time: 0.3470  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1780/3750]  eta: 0:19:14  Lr: 0.001875  Loss: -0.4165  Acc@1: 81.2500 (81.1623)  Acc@5: 100.0000 (96.4030)  time: 0.3486  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1790/3750]  eta: 0:19:06  Lr: 0.001875  Loss: -0.4835  Acc@1: 87.5000 (81.2046)  Acc@5: 93.7500 (96.3987)  time: 0.3478  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1800/3750]  eta: 0:18:57  Lr: 0.001875  Loss: -0.5849  Acc@1: 87.5000 (81.2084)  Acc@5: 100.0000 (96.4013)  time: 0.3472  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1810/3750]  eta: 0:18:49  Lr: 0.001875  Loss: -0.7659  Acc@1: 81.2500 (81.2086)  Acc@5: 100.0000 (96.4039)  time: 0.3471  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1820/3750]  eta: 0:18:40  Lr: 0.001875  Loss: -0.6542  Acc@1: 81.2500 (81.2157)  Acc@5: 100.0000 (96.4202)  time: 0.3474  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1830/3750]  eta: 0:18:32  Lr: 0.001875  Loss: -1.1523  Acc@1: 81.2500 (81.2295)  Acc@5: 100.0000 (96.4364)  time: 0.3481  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1840/3750]  eta: 0:18:24  Lr: 0.001875  Loss: -1.1194  Acc@1: 81.2500 (81.2330)  Acc@5: 100.0000 (96.4320)  time: 0.3471  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [1850/3750]  eta: 0:18:16  Lr: 0.001875  Loss: -1.3273  Acc@1: 87.5000 (81.2669)  Acc@5: 100.0000 (96.4479)  time: 0.3516  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1860/3750]  eta: 0:18:08  Lr: 0.001875  Loss: -0.8867  Acc@1: 81.2500 (81.2500)  Acc@5: 100.0000 (96.4468)  time: 0.3602  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [1870/3750]  eta: 0:18:00  Lr: 0.001875  Loss: -0.8371  Acc@1: 81.2500 (81.2533)  Acc@5: 100.0000 (96.4524)  time: 0.3585  data: 0.0009  max mem: 2500
Train: Epoch[3/5]  [1880/3750]  eta: 0:17:52  Lr: 0.001875  Loss: -1.0046  Acc@1: 81.2500 (81.2467)  Acc@5: 93.7500 (96.4480)  time: 0.3538  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [1890/3750]  eta: 0:17:44  Lr: 0.001875  Loss: -0.6509  Acc@1: 81.2500 (81.2566)  Acc@5: 93.7500 (96.4470)  time: 0.3536  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [1900/3750]  eta: 0:17:36  Lr: 0.001875  Loss: -0.4489  Acc@1: 81.2500 (81.2336)  Acc@5: 93.7500 (96.4427)  time: 0.3581  data: 0.0012  max mem: 2500
Train: Epoch[3/5]  [1910/3750]  eta: 0:17:29  Lr: 0.001875  Loss: -0.9506  Acc@1: 81.2500 (81.2304)  Acc@5: 93.7500 (96.4384)  time: 0.3638  data: 0.0022  max mem: 2500
Train: Epoch[3/5]  [1920/3750]  eta: 0:17:21  Lr: 0.001875  Loss: -1.1192  Acc@1: 75.0000 (81.2045)  Acc@5: 93.7500 (96.4341)  time: 0.3585  data: 0.0023  max mem: 2500
Train: Epoch[3/5]  [1930/3750]  eta: 0:17:13  Lr: 0.001875  Loss: -0.9407  Acc@1: 75.0000 (81.2112)  Acc@5: 93.7500 (96.4300)  time: 0.3538  data: 0.0016  max mem: 2500
Train: Epoch[3/5]  [1940/3750]  eta: 0:17:06  Lr: 0.001875  Loss: -1.3380  Acc@1: 81.2500 (81.2242)  Acc@5: 100.0000 (96.4290)  time: 0.3541  data: 0.0011  max mem: 2500
Train: Epoch[3/5]  [1950/3750]  eta: 0:16:58  Lr: 0.001875  Loss: -1.0874  Acc@1: 87.5000 (81.2468)  Acc@5: 93.7500 (96.4249)  time: 0.3557  data: 0.0016  max mem: 2500
Train: Epoch[3/5]  [1960/3750]  eta: 0:16:50  Lr: 0.001875  Loss: -1.2680  Acc@1: 81.2500 (81.2341)  Acc@5: 100.0000 (96.4304)  time: 0.3528  data: 0.0014  max mem: 2500
Train: Epoch[3/5]  [1970/3750]  eta: 0:16:43  Lr: 0.001875  Loss: -0.6317  Acc@1: 75.0000 (81.2246)  Acc@5: 100.0000 (96.4295)  time: 0.3469  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1980/3750]  eta: 0:16:35  Lr: 0.001875  Loss: -0.4849  Acc@1: 75.0000 (81.2153)  Acc@5: 100.0000 (96.4254)  time: 0.3465  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1990/3750]  eta: 0:16:28  Lr: 0.001875  Loss: -1.0448  Acc@1: 75.0000 (81.2217)  Acc@5: 93.7500 (96.4214)  time: 0.3478  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [2000/3750]  eta: 0:16:20  Lr: 0.001875  Loss: -1.0773  Acc@1: 81.2500 (81.2219)  Acc@5: 100.0000 (96.4268)  time: 0.3487  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [2010/3750]  eta: 0:16:13  Lr: 0.001875  Loss: -1.2013  Acc@1: 81.2500 (81.2034)  Acc@5: 100.0000 (96.4321)  time: 0.3468  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [2020/3750]  eta: 0:16:05  Lr: 0.001875  Loss: -0.9613  Acc@1: 75.0000 (81.1912)  Acc@5: 93.7500 (96.4250)  time: 0.3461  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [2030/3750]  eta: 0:15:58  Lr: 0.001875  Loss: -0.8429  Acc@1: 81.2500 (81.2038)  Acc@5: 100.0000 (96.4365)  time: 0.3474  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2040/3750]  eta: 0:15:51  Lr: 0.001875  Loss: -1.0105  Acc@1: 81.2500 (81.2041)  Acc@5: 100.0000 (96.4356)  time: 0.3464  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2050/3750]  eta: 0:15:43  Lr: 0.001875  Loss: -0.5603  Acc@1: 87.5000 (81.2134)  Acc@5: 100.0000 (96.4438)  time: 0.3477  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [2060/3750]  eta: 0:15:36  Lr: 0.001875  Loss: -0.7621  Acc@1: 87.5000 (81.2106)  Acc@5: 100.0000 (96.4459)  time: 0.3526  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [2070/3750]  eta: 0:15:29  Lr: 0.001875  Loss: -0.9662  Acc@1: 81.2500 (81.2077)  Acc@5: 100.0000 (96.4450)  time: 0.3557  data: 0.0009  max mem: 2500
Train: Epoch[3/5]  [2080/3750]  eta: 0:15:22  Lr: 0.001875  Loss: -1.0622  Acc@1: 81.2500 (81.2019)  Acc@5: 93.7500 (96.4440)  time: 0.3570  data: 0.0010  max mem: 2500
Train: Epoch[3/5]  [2090/3750]  eta: 0:15:15  Lr: 0.001875  Loss: -0.8651  Acc@1: 87.5000 (81.2171)  Acc@5: 100.0000 (96.4461)  time: 0.3599  data: 0.0016  max mem: 2500
Train: Epoch[3/5]  [2100/3750]  eta: 0:15:08  Lr: 0.001875  Loss: -0.6116  Acc@1: 81.2500 (81.1905)  Acc@5: 100.0000 (96.4451)  time: 0.3605  data: 0.0020  max mem: 2500
Train: Epoch[3/5]  [2110/3750]  eta: 0:15:01  Lr: 0.001875  Loss: -0.6764  Acc@1: 75.0000 (81.1789)  Acc@5: 93.7500 (96.4383)  time: 0.3584  data: 0.0015  max mem: 2500
Train: Epoch[3/5]  [2120/3750]  eta: 0:14:54  Lr: 0.001875  Loss: -1.3072  Acc@1: 81.2500 (81.1881)  Acc@5: 100.0000 (96.4463)  time: 0.3573  data: 0.0010  max mem: 2500
Train: Epoch[3/5]  [2130/3750]  eta: 0:14:47  Lr: 0.001875  Loss: -0.5243  Acc@1: 81.2500 (81.1737)  Acc@5: 100.0000 (96.4512)  time: 0.3554  data: 0.0012  max mem: 2500
Train: Epoch[3/5]  [2140/3750]  eta: 0:14:40  Lr: 0.001875  Loss: -0.8633  Acc@1: 81.2500 (81.1653)  Acc@5: 93.7500 (96.4444)  time: 0.3544  data: 0.0012  max mem: 2500
Train: Epoch[3/5]  [2150/3750]  eta: 0:14:33  Lr: 0.001875  Loss: -0.7882  Acc@1: 81.2500 (81.1861)  Acc@5: 100.0000 (96.4522)  time: 0.3520  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [2160/3750]  eta: 0:14:26  Lr: 0.001875  Loss: -0.7474  Acc@1: 87.5000 (81.1922)  Acc@5: 100.0000 (96.4571)  time: 0.3487  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2170/3750]  eta: 0:14:19  Lr: 0.001875  Loss: -0.9877  Acc@1: 87.5000 (81.2097)  Acc@5: 100.0000 (96.4590)  time: 0.3486  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [2180/3750]  eta: 0:14:12  Lr: 0.001875  Loss: -1.0451  Acc@1: 87.5000 (81.2242)  Acc@5: 100.0000 (96.4580)  time: 0.3479  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [2190/3750]  eta: 0:14:05  Lr: 0.001875  Loss: -1.0192  Acc@1: 81.2500 (81.2357)  Acc@5: 100.0000 (96.4599)  time: 0.3480  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2200/3750]  eta: 0:13:59  Lr: 0.001875  Loss: -1.3397  Acc@1: 81.2500 (81.2273)  Acc@5: 100.0000 (96.4562)  time: 0.3481  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2210/3750]  eta: 0:13:52  Lr: 0.001875  Loss: -0.6981  Acc@1: 81.2500 (81.2246)  Acc@5: 93.7500 (96.4467)  time: 0.3468  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [2220/3750]  eta: 0:13:45  Lr: 0.001875  Loss: -0.7693  Acc@1: 81.2500 (81.2162)  Acc@5: 93.7500 (96.4487)  time: 0.3456  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2230/3750]  eta: 0:13:38  Lr: 0.001875  Loss: -1.3935  Acc@1: 81.2500 (81.2164)  Acc@5: 100.0000 (96.4534)  time: 0.3451  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [2240/3750]  eta: 0:13:32  Lr: 0.001875  Loss: -0.4720  Acc@1: 75.0000 (81.1775)  Acc@5: 93.7500 (96.4413)  time: 0.3459  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [2250/3750]  eta: 0:13:25  Lr: 0.001875  Loss: -0.7871  Acc@1: 75.0000 (81.1667)  Acc@5: 93.7500 (96.4405)  time: 0.3509  data: 0.0013  max mem: 2500
Train: Epoch[3/5]  [2260/3750]  eta: 0:13:19  Lr: 0.001875  Loss: -1.3471  Acc@1: 81.2500 (81.1781)  Acc@5: 100.0000 (96.4507)  time: 0.3560  data: 0.0016  max mem: 2500
Train: Epoch[3/5]  [2270/3750]  eta: 0:13:12  Lr: 0.001875  Loss: -0.7287  Acc@1: 81.2500 (81.1839)  Acc@5: 100.0000 (96.4498)  time: 0.3553  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [2280/3750]  eta: 0:13:06  Lr: 0.001875  Loss: -0.8287  Acc@1: 81.2500 (81.1596)  Acc@5: 93.7500 (96.4434)  time: 0.3578  data: 0.0016  max mem: 2500
Train: Epoch[3/5]  [2290/3750]  eta: 0:12:59  Lr: 0.001875  Loss: -1.0181  Acc@1: 81.2500 (81.1600)  Acc@5: 100.0000 (96.4453)  time: 0.3598  data: 0.0021  max mem: 2500
Train: Epoch[3/5]  [2300/3750]  eta: 0:12:53  Lr: 0.001875  Loss: -0.6501  Acc@1: 81.2500 (81.1576)  Acc@5: 100.0000 (96.4445)  time: 0.3561  data: 0.0010  max mem: 2500
Train: Epoch[3/5]  [2310/3750]  eta: 0:12:46  Lr: 0.001875  Loss: -0.9956  Acc@1: 87.5000 (81.1662)  Acc@5: 93.7500 (96.4436)  time: 0.3546  data: 0.0024  max mem: 2500
Train: Epoch[3/5]  [2320/3750]  eta: 0:12:40  Lr: 0.001875  Loss: -0.8894  Acc@1: 81.2500 (81.1638)  Acc@5: 93.7500 (96.4401)  time: 0.3535  data: 0.0023  max mem: 2500
Train: Epoch[3/5]  [2330/3750]  eta: 0:12:33  Lr: 0.001875  Loss: -1.1721  Acc@1: 81.2500 (81.1481)  Acc@5: 93.7500 (96.4366)  time: 0.3502  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [2340/3750]  eta: 0:12:27  Lr: 0.001875  Loss: -0.9918  Acc@1: 81.2500 (81.1539)  Acc@5: 100.0000 (96.4385)  time: 0.3514  data: 0.0011  max mem: 2500
Train: Epoch[3/5]  [2350/3750]  eta: 0:12:21  Lr: 0.001875  Loss: -1.2768  Acc@1: 81.2500 (81.1543)  Acc@5: 100.0000 (96.4430)  time: 0.3510  data: 0.0010  max mem: 2500
Train: Epoch[3/5]  [2360/3750]  eta: 0:12:14  Lr: 0.001875  Loss: -1.0863  Acc@1: 87.5000 (81.1812)  Acc@5: 100.0000 (96.4395)  time: 0.3478  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2370/3750]  eta: 0:12:08  Lr: 0.001875  Loss: -1.1045  Acc@1: 87.5000 (81.1946)  Acc@5: 93.7500 (96.4361)  time: 0.3482  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [2380/3750]  eta: 0:12:02  Lr: 0.001875  Loss: -0.5928  Acc@1: 81.2500 (81.1870)  Acc@5: 100.0000 (96.4432)  time: 0.3475  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2390/3750]  eta: 0:11:55  Lr: 0.001875  Loss: -1.1639  Acc@1: 81.2500 (81.2056)  Acc@5: 100.0000 (96.4502)  time: 0.3458  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [2400/3750]  eta: 0:11:49  Lr: 0.001875  Loss: -0.8017  Acc@1: 81.2500 (81.2031)  Acc@5: 100.0000 (96.4520)  time: 0.3449  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [2410/3750]  eta: 0:11:43  Lr: 0.001875  Loss: -1.1126  Acc@1: 81.2500 (81.1826)  Acc@5: 100.0000 (96.4486)  time: 0.3450  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [2420/3750]  eta: 0:11:36  Lr: 0.001875  Loss: -1.2298  Acc@1: 81.2500 (81.1932)  Acc@5: 93.7500 (96.4503)  time: 0.3483  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2430/3750]  eta: 0:11:30  Lr: 0.001875  Loss: -0.9562  Acc@1: 81.2500 (81.1677)  Acc@5: 100.0000 (96.4469)  time: 0.3539  data: 0.0014  max mem: 2500
Train: Epoch[3/5]  [2440/3750]  eta: 0:11:24  Lr: 0.001875  Loss: -0.9803  Acc@1: 75.0000 (81.1425)  Acc@5: 93.7500 (96.4384)  time: 0.3567  data: 0.0018  max mem: 2500
Train: Epoch[3/5]  [2450/3750]  eta: 0:11:18  Lr: 0.001875  Loss: -1.1299  Acc@1: 75.0000 (81.1353)  Acc@5: 93.7500 (96.4300)  time: 0.3567  data: 0.0016  max mem: 2500
Train: Epoch[3/5]  [2460/3750]  eta: 0:11:12  Lr: 0.001875  Loss: -0.3538  Acc@1: 81.2500 (81.1281)  Acc@5: 93.7500 (96.4217)  time: 0.3602  data: 0.0021  max mem: 2500
Train: Epoch[3/5]  [2470/3750]  eta: 0:11:06  Lr: 0.001875  Loss: -0.6486  Acc@1: 75.0000 (81.1109)  Acc@5: 93.7500 (96.4235)  time: 0.3635  data: 0.0016  max mem: 2500
Train: Epoch[3/5]  [2480/3750]  eta: 0:11:00  Lr: 0.001875  Loss: -0.8932  Acc@1: 75.0000 (81.1014)  Acc@5: 100.0000 (96.4203)  time: 0.3581  data: 0.0012  max mem: 2500
Train: Epoch[3/5]  [2490/3750]  eta: 0:10:54  Lr: 0.001875  Loss: -0.8876  Acc@1: 81.2500 (81.0995)  Acc@5: 93.7500 (96.4146)  time: 0.3552  data: 0.0014  max mem: 2500
Train: Epoch[3/5]  [2500/3750]  eta: 0:10:48  Lr: 0.001875  Loss: -0.9947  Acc@1: 75.0000 (81.0826)  Acc@5: 100.0000 (96.4164)  time: 0.3561  data: 0.0009  max mem: 2500
Train: Epoch[3/5]  [2510/3750]  eta: 0:10:42  Lr: 0.001875  Loss: -1.2462  Acc@1: 81.2500 (81.1031)  Acc@5: 100.0000 (96.4183)  time: 0.3587  data: 0.0021  max mem: 2500
Train: Epoch[3/5]  [2520/3750]  eta: 0:10:36  Lr: 0.001875  Loss: -0.6920  Acc@1: 87.5000 (81.1161)  Acc@5: 100.0000 (96.4226)  time: 0.3543  data: 0.0019  max mem: 2500
Train: Epoch[3/5]  [2530/3750]  eta: 0:10:30  Lr: 0.001875  Loss: -1.0018  Acc@1: 87.5000 (81.1315)  Acc@5: 93.7500 (96.4219)  time: 0.3463  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2540/3750]  eta: 0:10:24  Lr: 0.001875  Loss: -0.8513  Acc@1: 81.2500 (81.1270)  Acc@5: 93.7500 (96.4064)  time: 0.3479  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2550/3750]  eta: 0:10:18  Lr: 0.001875  Loss: -0.9172  Acc@1: 81.2500 (81.1103)  Acc@5: 100.0000 (96.4181)  time: 0.3493  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2560/3750]  eta: 0:10:12  Lr: 0.001875  Loss: -1.0564  Acc@1: 81.2500 (81.1036)  Acc@5: 100.0000 (96.4174)  time: 0.3492  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2570/3750]  eta: 0:10:06  Lr: 0.001875  Loss: -0.8813  Acc@1: 81.2500 (81.1090)  Acc@5: 93.7500 (96.4168)  time: 0.3470  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2580/3750]  eta: 0:10:00  Lr: 0.001875  Loss: -0.9723  Acc@1: 81.2500 (81.1071)  Acc@5: 100.0000 (96.4234)  time: 0.3449  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [2590/3750]  eta: 0:09:54  Lr: 0.001875  Loss: -0.7451  Acc@1: 81.2500 (81.1053)  Acc@5: 100.0000 (96.4299)  time: 0.3456  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [2600/3750]  eta: 0:09:49  Lr: 0.001875  Loss: -1.3083  Acc@1: 81.2500 (81.0986)  Acc@5: 100.0000 (96.4293)  time: 0.3454  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [2610/3750]  eta: 0:09:43  Lr: 0.001875  Loss: -1.1437  Acc@1: 81.2500 (81.1112)  Acc@5: 100.0000 (96.4358)  time: 0.3470  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [2620/3750]  eta: 0:09:37  Lr: 0.001875  Loss: -1.0603  Acc@1: 81.2500 (81.1284)  Acc@5: 100.0000 (96.4374)  time: 0.3519  data: 0.0012  max mem: 2500
Train: Epoch[3/5]  [2630/3750]  eta: 0:09:31  Lr: 0.001875  Loss: -1.1852  Acc@1: 81.2500 (81.1193)  Acc@5: 100.0000 (96.4391)  time: 0.3551  data: 0.0028  max mem: 2500
Train: Epoch[3/5]  [2640/3750]  eta: 0:09:25  Lr: 0.001875  Loss: -0.5020  Acc@1: 81.2500 (81.1222)  Acc@5: 100.0000 (96.4360)  time: 0.3550  data: 0.0028  max mem: 2500
Train: Epoch[3/5]  [2650/3750]  eta: 0:09:20  Lr: 0.001875  Loss: -1.0999  Acc@1: 81.2500 (81.1274)  Acc@5: 100.0000 (96.4400)  time: 0.3558  data: 0.0015  max mem: 2500
Train: Epoch[3/5]  [2660/3750]  eta: 0:09:14  Lr: 0.001875  Loss: -1.2387  Acc@1: 81.2500 (81.1302)  Acc@5: 100.0000 (96.4464)  time: 0.3583  data: 0.0011  max mem: 2500
Train: Epoch[3/5]  [2670/3750]  eta: 0:09:08  Lr: 0.001875  Loss: -0.9686  Acc@1: 81.2500 (81.1260)  Acc@5: 100.0000 (96.4456)  time: 0.3566  data: 0.0009  max mem: 2500
Train: Epoch[3/5]  [2680/3750]  eta: 0:09:03  Lr: 0.001875  Loss: -1.2691  Acc@1: 81.2500 (81.1381)  Acc@5: 93.7500 (96.4449)  time: 0.3538  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [2690/3750]  eta: 0:08:57  Lr: 0.001875  Loss: -1.0630  Acc@1: 87.5000 (81.1501)  Acc@5: 100.0000 (96.4465)  time: 0.3546  data: 0.0009  max mem: 2500
Train: Epoch[3/5]  [2700/3750]  eta: 0:08:51  Lr: 0.001875  Loss: -1.0736  Acc@1: 87.5000 (81.1505)  Acc@5: 100.0000 (96.4365)  time: 0.3595  data: 0.0010  max mem: 2500
Train: Epoch[3/5]  [2710/3750]  eta: 0:08:46  Lr: 0.001875  Loss: -0.5662  Acc@1: 81.2500 (81.1601)  Acc@5: 93.7500 (96.4381)  time: 0.3564  data: 0.0009  max mem: 2500
Train: Epoch[3/5]  [2720/3750]  eta: 0:08:40  Lr: 0.001875  Loss: -0.9436  Acc@1: 81.2500 (81.1558)  Acc@5: 100.0000 (96.4420)  time: 0.3482  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [2730/3750]  eta: 0:08:34  Lr: 0.001875  Loss: -1.1013  Acc@1: 81.2500 (81.1768)  Acc@5: 100.0000 (96.4459)  time: 0.3488  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2740/3750]  eta: 0:08:29  Lr: 0.001875  Loss: -1.0482  Acc@1: 81.2500 (81.1770)  Acc@5: 100.0000 (96.4429)  time: 0.3490  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2750/3750]  eta: 0:08:23  Lr: 0.001875  Loss: -0.9447  Acc@1: 81.2500 (81.1841)  Acc@5: 93.7500 (96.4399)  time: 0.3483  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2760/3750]  eta: 0:08:17  Lr: 0.001875  Loss: -0.6874  Acc@1: 87.5000 (81.2002)  Acc@5: 100.0000 (96.4483)  time: 0.3470  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2770/3750]  eta: 0:08:12  Lr: 0.001875  Loss: -0.7164  Acc@1: 87.5000 (81.2139)  Acc@5: 100.0000 (96.4476)  time: 0.3453  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [2780/3750]  eta: 0:08:06  Lr: 0.001875  Loss: -0.9518  Acc@1: 81.2500 (81.2208)  Acc@5: 100.0000 (96.4559)  time: 0.3451  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [2790/3750]  eta: 0:08:01  Lr: 0.001875  Loss: -0.8142  Acc@1: 81.2500 (81.2276)  Acc@5: 100.0000 (96.4462)  time: 0.3451  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [2800/3750]  eta: 0:07:55  Lr: 0.001875  Loss: -1.1482  Acc@1: 81.2500 (81.2143)  Acc@5: 93.7500 (96.4388)  time: 0.3475  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [2810/3750]  eta: 0:07:50  Lr: 0.001875  Loss: -0.7643  Acc@1: 81.2500 (81.2033)  Acc@5: 93.7500 (96.4270)  time: 0.3534  data: 0.0015  max mem: 2500
Train: Epoch[3/5]  [2820/3750]  eta: 0:07:44  Lr: 0.001875  Loss: -1.2364  Acc@1: 81.2500 (81.2013)  Acc@5: 93.7500 (96.4219)  time: 0.3555  data: 0.0016  max mem: 2500
Train: Epoch[3/5]  [2830/3750]  eta: 0:07:39  Lr: 0.001875  Loss: -0.5352  Acc@1: 81.2500 (81.1860)  Acc@5: 93.7500 (96.4169)  time: 0.3548  data: 0.0026  max mem: 2500
Train: Epoch[3/5]  [2840/3750]  eta: 0:07:33  Lr: 0.001875  Loss: -0.8853  Acc@1: 81.2500 (81.1818)  Acc@5: 93.7500 (96.4097)  time: 0.3584  data: 0.0032  max mem: 2500
Train: Epoch[3/5]  [2850/3750]  eta: 0:07:28  Lr: 0.001875  Loss: -1.3080  Acc@1: 81.2500 (81.2018)  Acc@5: 100.0000 (96.4201)  time: 0.3662  data: 0.0019  max mem: 2500
Train: Epoch[3/5]  [2860/3750]  eta: 0:07:22  Lr: 0.001875  Loss: -0.8320  Acc@1: 81.2500 (81.2063)  Acc@5: 100.0000 (96.4195)  time: 0.3629  data: 0.0019  max mem: 2500
Train: Epoch[3/5]  [2870/3750]  eta: 0:07:17  Lr: 0.001875  Loss: -1.0806  Acc@1: 81.2500 (81.2261)  Acc@5: 100.0000 (96.4298)  time: 0.3546  data: 0.0015  max mem: 2500
Train: Epoch[3/5]  [2880/3750]  eta: 0:07:12  Lr: 0.001875  Loss: -0.6627  Acc@1: 81.2500 (81.2240)  Acc@5: 100.0000 (96.4249)  time: 0.3541  data: 0.0009  max mem: 2500
Train: Epoch[3/5]  [2890/3750]  eta: 0:07:06  Lr: 0.001875  Loss: -1.0094  Acc@1: 81.2500 (81.2327)  Acc@5: 100.0000 (96.4242)  time: 0.3550  data: 0.0016  max mem: 2500
Train: Epoch[3/5]  [2900/3750]  eta: 0:07:01  Lr: 0.001875  Loss: -0.7726  Acc@1: 87.5000 (81.2478)  Acc@5: 100.0000 (96.4301)  time: 0.3530  data: 0.0012  max mem: 2500
Train: Epoch[3/5]  [2910/3750]  eta: 0:06:55  Lr: 0.001875  Loss: -0.8015  Acc@1: 81.2500 (81.2521)  Acc@5: 100.0000 (96.4359)  time: 0.3480  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2920/3750]  eta: 0:06:50  Lr: 0.001875  Loss: -1.0568  Acc@1: 81.2500 (81.2500)  Acc@5: 100.0000 (96.4310)  time: 0.3489  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [2930/3750]  eta: 0:06:45  Lr: 0.001875  Loss: -0.4386  Acc@1: 87.5000 (81.2564)  Acc@5: 100.0000 (96.4347)  time: 0.3497  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [2940/3750]  eta: 0:06:39  Lr: 0.001875  Loss: -0.4902  Acc@1: 87.5000 (81.2585)  Acc@5: 100.0000 (96.4404)  time: 0.3558  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [2950/3750]  eta: 0:06:34  Lr: 0.001875  Loss: -1.0928  Acc@1: 81.2500 (81.2754)  Acc@5: 100.0000 (96.4461)  time: 0.3581  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2960/3750]  eta: 0:06:29  Lr: 0.001875  Loss: -0.9687  Acc@1: 81.2500 (81.2648)  Acc@5: 100.0000 (96.4455)  time: 0.3488  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [2970/3750]  eta: 0:06:24  Lr: 0.001875  Loss: -0.8527  Acc@1: 75.0000 (81.2521)  Acc@5: 100.0000 (96.4469)  time: 0.3457  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [2980/3750]  eta: 0:06:18  Lr: 0.001875  Loss: -1.0152  Acc@1: 81.2500 (81.2416)  Acc@5: 100.0000 (96.4462)  time: 0.3900  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2990/3750]  eta: 0:06:14  Lr: 0.001875  Loss: -1.1671  Acc@1: 81.2500 (81.2396)  Acc@5: 100.0000 (96.4414)  time: 0.5895  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [3000/3750]  eta: 0:06:10  Lr: 0.001875  Loss: -1.2055  Acc@1: 81.2500 (81.2375)  Acc@5: 93.7500 (96.4449)  time: 0.7442  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [3010/3750]  eta: 0:06:06  Lr: 0.001875  Loss: -1.0123  Acc@1: 81.2500 (81.2375)  Acc@5: 93.7500 (96.4381)  time: 0.7460  data: 0.0010  max mem: 2500
Train: Epoch[3/5]  [3020/3750]  eta: 0:06:01  Lr: 0.001875  Loss: -1.0398  Acc@1: 81.2500 (81.2314)  Acc@5: 93.7500 (96.4354)  time: 0.7491  data: 0.0010  max mem: 2500
Train: Epoch[3/5]  [3030/3750]  eta: 0:05:57  Lr: 0.001875  Loss: -1.0298  Acc@1: 81.2500 (81.2356)  Acc@5: 93.7500 (96.4327)  time: 0.7497  data: 0.0015  max mem: 2500
Train: Epoch[3/5]  [3040/3750]  eta: 0:05:52  Lr: 0.001875  Loss: -1.1106  Acc@1: 81.2500 (81.2377)  Acc@5: 93.7500 (96.4321)  time: 0.7484  data: 0.0015  max mem: 2500
Train: Epoch[3/5]  [3050/3750]  eta: 0:05:48  Lr: 0.001875  Loss: -0.8434  Acc@1: 81.2500 (81.2316)  Acc@5: 93.7500 (96.4274)  time: 0.7460  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [3060/3750]  eta: 0:05:44  Lr: 0.001875  Loss: -0.7622  Acc@1: 81.2500 (81.2357)  Acc@5: 100.0000 (96.4309)  time: 0.7447  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [3070/3750]  eta: 0:05:39  Lr: 0.001875  Loss: -0.9833  Acc@1: 81.2500 (81.2439)  Acc@5: 100.0000 (96.4324)  time: 0.7432  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3080/3750]  eta: 0:05:35  Lr: 0.001875  Loss: -0.3339  Acc@1: 81.2500 (81.2338)  Acc@5: 93.7500 (96.4297)  time: 0.7434  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3090/3750]  eta: 0:05:30  Lr: 0.001875  Loss: -1.2735  Acc@1: 81.2500 (81.2298)  Acc@5: 93.7500 (96.4251)  time: 0.7449  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [3100/3750]  eta: 0:05:26  Lr: 0.001875  Loss: -1.0735  Acc@1: 81.2500 (81.2379)  Acc@5: 100.0000 (96.4306)  time: 0.7460  data: 0.0011  max mem: 2500
Train: Epoch[3/5]  [3110/3750]  eta: 0:05:21  Lr: 0.001875  Loss: -0.9592  Acc@1: 81.2500 (81.2359)  Acc@5: 93.7500 (96.4200)  time: 0.7492  data: 0.0012  max mem: 2500
Train: Epoch[3/5]  [3120/3750]  eta: 0:05:17  Lr: 0.001875  Loss: -0.5820  Acc@1: 75.0000 (81.2260)  Acc@5: 93.7500 (96.4154)  time: 0.7495  data: 0.0010  max mem: 2500
Train: Epoch[3/5]  [3130/3750]  eta: 0:05:12  Lr: 0.001875  Loss: -0.7405  Acc@1: 75.0000 (81.2181)  Acc@5: 100.0000 (96.4149)  time: 0.7499  data: 0.0017  max mem: 2500
Train: Epoch[3/5]  [3140/3750]  eta: 0:05:08  Lr: 0.001875  Loss: -1.1190  Acc@1: 81.2500 (81.2122)  Acc@5: 93.7500 (96.4024)  time: 0.7494  data: 0.0013  max mem: 2500
Train: Epoch[3/5]  [3150/3750]  eta: 0:05:03  Lr: 0.001875  Loss: -0.6034  Acc@1: 81.2500 (81.2123)  Acc@5: 100.0000 (96.4079)  time: 0.7465  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3160/3750]  eta: 0:04:58  Lr: 0.001875  Loss: -0.8430  Acc@1: 75.0000 (81.2025)  Acc@5: 100.0000 (96.4074)  time: 0.7468  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3170/3750]  eta: 0:04:54  Lr: 0.001875  Loss: -1.2910  Acc@1: 81.2500 (81.2185)  Acc@5: 100.0000 (96.4148)  time: 0.7489  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [3180/3750]  eta: 0:04:49  Lr: 0.001875  Loss: -1.4724  Acc@1: 87.5000 (81.2166)  Acc@5: 100.0000 (96.4143)  time: 0.7487  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [3190/3750]  eta: 0:04:44  Lr: 0.001875  Loss: -0.5128  Acc@1: 81.2500 (81.2245)  Acc@5: 100.0000 (96.4137)  time: 0.7412  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [3200/3750]  eta: 0:04:40  Lr: 0.001875  Loss: -1.0338  Acc@1: 81.2500 (81.2149)  Acc@5: 93.7500 (96.4132)  time: 0.7429  data: 0.0016  max mem: 2500
Train: Epoch[3/5]  [3210/3750]  eta: 0:04:35  Lr: 0.001875  Loss: -0.7013  Acc@1: 75.0000 (81.1916)  Acc@5: 93.7500 (96.4147)  time: 0.7423  data: 0.0028  max mem: 2500
Train: Epoch[3/5]  [3220/3750]  eta: 0:04:30  Lr: 0.001875  Loss: -1.0496  Acc@1: 68.7500 (81.1704)  Acc@5: 93.7500 (96.4103)  time: 0.7397  data: 0.0021  max mem: 2500
Train: Epoch[3/5]  [3230/3750]  eta: 0:04:25  Lr: 0.001875  Loss: -1.0159  Acc@1: 81.2500 (81.1784)  Acc@5: 93.7500 (96.4098)  time: 0.6631  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [3240/3750]  eta: 0:04:20  Lr: 0.001875  Loss: -0.6076  Acc@1: 81.2500 (81.1651)  Acc@5: 93.7500 (96.4093)  time: 0.4662  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3250/3750]  eta: 0:04:15  Lr: 0.001875  Loss: -0.9531  Acc@1: 75.0000 (81.1693)  Acc@5: 93.7500 (96.4088)  time: 0.3493  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3260/3750]  eta: 0:04:09  Lr: 0.001875  Loss: -0.8415  Acc@1: 81.2500 (81.1561)  Acc@5: 93.7500 (96.4064)  time: 0.3491  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3270/3750]  eta: 0:04:04  Lr: 0.001875  Loss: -1.1840  Acc@1: 81.2500 (81.1506)  Acc@5: 100.0000 (96.4078)  time: 0.3482  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3280/3750]  eta: 0:03:59  Lr: 0.001875  Loss: -0.8978  Acc@1: 75.0000 (81.1338)  Acc@5: 93.7500 (96.3959)  time: 0.3471  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3290/3750]  eta: 0:03:53  Lr: 0.001875  Loss: -0.9118  Acc@1: 75.0000 (81.1247)  Acc@5: 93.7500 (96.3955)  time: 0.3470  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3300/3750]  eta: 0:03:48  Lr: 0.001875  Loss: -1.1106  Acc@1: 81.2500 (81.1345)  Acc@5: 93.7500 (96.3969)  time: 0.3462  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3310/3750]  eta: 0:03:43  Lr: 0.001875  Loss: -1.0390  Acc@1: 81.2500 (81.1349)  Acc@5: 100.0000 (96.3927)  time: 0.3461  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3320/3750]  eta: 0:03:37  Lr: 0.001875  Loss: -1.0378  Acc@1: 81.2500 (81.1371)  Acc@5: 93.7500 (96.3885)  time: 0.3481  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [3330/3750]  eta: 0:03:32  Lr: 0.001875  Loss: -1.0402  Acc@1: 81.2500 (81.1299)  Acc@5: 100.0000 (96.3900)  time: 0.3526  data: 0.0022  max mem: 2500
Train: Epoch[3/5]  [3340/3750]  eta: 0:03:27  Lr: 0.001875  Loss: -1.0066  Acc@1: 81.2500 (81.1265)  Acc@5: 100.0000 (96.3914)  time: 0.3545  data: 0.0031  max mem: 2500
Train: Epoch[3/5]  [3350/3750]  eta: 0:03:22  Lr: 0.001875  Loss: -0.6971  Acc@1: 81.2500 (81.1045)  Acc@5: 93.7500 (96.3891)  time: 0.3573  data: 0.0016  max mem: 2500
Train: Epoch[3/5]  [3360/3750]  eta: 0:03:16  Lr: 0.001875  Loss: -0.8520  Acc@1: 81.2500 (81.1235)  Acc@5: 100.0000 (96.3943)  time: 0.3593  data: 0.0009  max mem: 2500
Train: Epoch[3/5]  [3370/3750]  eta: 0:03:11  Lr: 0.001875  Loss: -1.1718  Acc@1: 81.2500 (81.1128)  Acc@5: 93.7500 (96.3846)  time: 0.3543  data: 0.0009  max mem: 2500
Train: Epoch[3/5]  [3380/3750]  eta: 0:03:06  Lr: 0.001875  Loss: -1.0897  Acc@1: 81.2500 (81.1114)  Acc@5: 93.7500 (96.3824)  time: 0.3529  data: 0.0019  max mem: 2500
Train: Epoch[3/5]  [3390/3750]  eta: 0:03:01  Lr: 0.001875  Loss: -1.3001  Acc@1: 81.2500 (81.1118)  Acc@5: 100.0000 (96.3838)  time: 0.3563  data: 0.0024  max mem: 2500
Train: Epoch[3/5]  [3400/3750]  eta: 0:02:56  Lr: 0.001875  Loss: -0.9557  Acc@1: 81.2500 (81.1030)  Acc@5: 100.0000 (96.3834)  time: 0.3529  data: 0.0012  max mem: 2500
Train: Epoch[3/5]  [3410/3750]  eta: 0:02:50  Lr: 0.001875  Loss: -0.8664  Acc@1: 81.2500 (81.0943)  Acc@5: 100.0000 (96.3812)  time: 0.3486  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3420/3750]  eta: 0:02:45  Lr: 0.001875  Loss: -0.4316  Acc@1: 81.2500 (81.0874)  Acc@5: 100.0000 (96.3826)  time: 0.3503  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3430/3750]  eta: 0:02:40  Lr: 0.001875  Loss: -0.3327  Acc@1: 87.5000 (81.0915)  Acc@5: 100.0000 (96.3823)  time: 0.3497  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3440/3750]  eta: 0:02:35  Lr: 0.001875  Loss: -1.0893  Acc@1: 81.2500 (81.0902)  Acc@5: 100.0000 (96.3837)  time: 0.3477  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [3450/3750]  eta: 0:02:30  Lr: 0.001875  Loss: -1.0289  Acc@1: 81.2500 (81.0761)  Acc@5: 100.0000 (96.3869)  time: 0.3482  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3460/3750]  eta: 0:02:25  Lr: 0.001875  Loss: -0.8839  Acc@1: 81.2500 (81.0784)  Acc@5: 100.0000 (96.3919)  time: 0.3475  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3470/3750]  eta: 0:02:20  Lr: 0.001875  Loss: -0.7405  Acc@1: 81.2500 (81.0807)  Acc@5: 100.0000 (96.3915)  time: 0.3464  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3480/3750]  eta: 0:02:14  Lr: 0.001875  Loss: -0.9352  Acc@1: 87.5000 (81.0938)  Acc@5: 100.0000 (96.3911)  time: 0.3460  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3490/3750]  eta: 0:02:09  Lr: 0.001875  Loss: -1.0748  Acc@1: 81.2500 (81.0889)  Acc@5: 100.0000 (96.3925)  time: 0.3460  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3500/3750]  eta: 0:02:04  Lr: 0.001875  Loss: -0.9302  Acc@1: 81.2500 (81.0893)  Acc@5: 100.0000 (96.3957)  time: 0.3479  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [3510/3750]  eta: 0:01:59  Lr: 0.001875  Loss: -1.0651  Acc@1: 81.2500 (81.0933)  Acc@5: 93.7500 (96.3935)  time: 0.3513  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [3520/3750]  eta: 0:01:54  Lr: 0.001875  Loss: -0.8382  Acc@1: 81.2500 (81.0991)  Acc@5: 93.7500 (96.3931)  time: 0.3515  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [3530/3750]  eta: 0:01:49  Lr: 0.001875  Loss: -0.2640  Acc@1: 81.2500 (81.0925)  Acc@5: 93.7500 (96.3874)  time: 0.3530  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [3540/3750]  eta: 0:01:44  Lr: 0.001875  Loss: -1.2544  Acc@1: 81.2500 (81.0964)  Acc@5: 100.0000 (96.3852)  time: 0.3573  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [3550/3750]  eta: 0:01:39  Lr: 0.001875  Loss: -0.6310  Acc@1: 81.2500 (81.0951)  Acc@5: 100.0000 (96.3831)  time: 0.3588  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [3560/3750]  eta: 0:01:34  Lr: 0.001875  Loss: -1.1316  Acc@1: 75.0000 (81.0833)  Acc@5: 100.0000 (96.3862)  time: 0.3559  data: 0.0009  max mem: 2500
Train: Epoch[3/5]  [3570/3750]  eta: 0:01:29  Lr: 0.001875  Loss: -1.1130  Acc@1: 81.2500 (81.0942)  Acc@5: 100.0000 (96.3946)  time: 0.3551  data: 0.0009  max mem: 2500
Train: Epoch[3/5]  [3580/3750]  eta: 0:01:24  Lr: 0.001875  Loss: -1.0078  Acc@1: 81.2500 (81.0877)  Acc@5: 100.0000 (96.3924)  time: 0.3578  data: 0.0018  max mem: 2500
Train: Epoch[3/5]  [3590/3750]  eta: 0:01:19  Lr: 0.001875  Loss: -0.1959  Acc@1: 81.2500 (81.0777)  Acc@5: 100.0000 (96.3938)  time: 0.3535  data: 0.0016  max mem: 2500
Train: Epoch[3/5]  [3600/3750]  eta: 0:01:14  Lr: 0.001875  Loss: -1.0321  Acc@1: 81.2500 (81.0869)  Acc@5: 100.0000 (96.3986)  time: 0.3483  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3610/3750]  eta: 0:01:09  Lr: 0.001875  Loss: -0.8621  Acc@1: 81.2500 (81.0908)  Acc@5: 93.7500 (96.3964)  time: 0.3482  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [3620/3750]  eta: 0:01:04  Lr: 0.001875  Loss: -1.1052  Acc@1: 81.2500 (81.0912)  Acc@5: 93.7500 (96.3977)  time: 0.3478  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [3630/3750]  eta: 0:00:59  Lr: 0.001875  Loss: -1.0242  Acc@1: 81.2500 (81.0848)  Acc@5: 100.0000 (96.3973)  time: 0.3481  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3640/3750]  eta: 0:00:54  Lr: 0.001875  Loss: -1.1675  Acc@1: 81.2500 (81.1058)  Acc@5: 100.0000 (96.4038)  time: 0.3535  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3650/3750]  eta: 0:00:49  Lr: 0.001875  Loss: -0.6380  Acc@1: 87.5000 (81.1096)  Acc@5: 100.0000 (96.4051)  time: 0.3548  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [3660/3750]  eta: 0:00:44  Lr: 0.001875  Loss: -1.1670  Acc@1: 81.2500 (81.1032)  Acc@5: 100.0000 (96.4081)  time: 0.3486  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [3670/3750]  eta: 0:00:39  Lr: 0.001875  Loss: -0.9623  Acc@1: 81.2500 (81.1036)  Acc@5: 100.0000 (96.4094)  time: 0.3471  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [3680/3750]  eta: 0:00:34  Lr: 0.001875  Loss: -1.2403  Acc@1: 81.2500 (81.1108)  Acc@5: 100.0000 (96.4123)  time: 0.5047  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3690/3750]  eta: 0:00:29  Lr: 0.001875  Loss: -0.9637  Acc@1: 87.5000 (81.1145)  Acc@5: 100.0000 (96.4119)  time: 0.7109  data: 0.0032  max mem: 2500
Train: Epoch[3/5]  [3700/3750]  eta: 0:00:24  Lr: 0.001875  Loss: -1.3059  Acc@1: 87.5000 (81.1301)  Acc@5: 100.0000 (96.4148)  time: 0.7642  data: 0.0056  max mem: 2500
Train: Epoch[3/5]  [3710/3750]  eta: 0:00:19  Lr: 0.001875  Loss: -1.0559  Acc@1: 87.5000 (81.1439)  Acc@5: 100.0000 (96.4144)  time: 0.7536  data: 0.0030  max mem: 2500
Train: Epoch[3/5]  [3720/3750]  eta: 0:00:14  Lr: 0.001875  Loss: -0.9690  Acc@1: 87.5000 (81.1543)  Acc@5: 100.0000 (96.4207)  time: 0.7453  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [3730/3750]  eta: 0:00:09  Lr: 0.001875  Loss: -0.9852  Acc@1: 87.5000 (81.1662)  Acc@5: 100.0000 (96.4219)  time: 0.7482  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [3740/3750]  eta: 0:00:04  Lr: 0.001875  Loss: -0.7147  Acc@1: 87.5000 (81.1765)  Acc@5: 100.0000 (96.4264)  time: 0.7461  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [3749/3750]  eta: 0:00:00  Lr: 0.001875  Loss: -0.6258  Acc@1: 81.2500 (81.1750)  Acc@5: 93.7500 (96.4250)  time: 0.7465  data: 0.0008  max mem: 2500
Train: Epoch[3/5] Total time: 0:31:05 (0.4975 s / it)
{0: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 1: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 2: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 3: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 4: {0: 0, 1: 180000, 2: 0, 3: 0, 4: 0}, 5: {0: 0, 1: 180000, 2: 0, 3: 0, 4: 0}, 6: {0: 0, 1: 180000, 2: 0, 3: 0, 4: 0}, 7: {0: 0, 1: 180000, 2: 0, 3: 0, 4: 0}, 8: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 9: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 10: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 11: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 12: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 13: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 14: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 15: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 16: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 17: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 18: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 19: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}}
Averaged stats: Lr: 0.001875  Loss: -0.6258  Acc@1: 81.2500 (81.1750)  Acc@5: 93.7500 (96.4250)
Train: Epoch[4/5]  [   0/3750]  eta: 1:05:36  Lr: 0.001875  Loss: -0.6123  Acc@1: 68.7500 (68.7500)  Acc@5: 93.7500 (93.7500)  time: 1.0496  data: 0.3006  max mem: 2500
Train: Epoch[4/5]  [  10/3750]  eta: 0:48:14  Lr: 0.001875  Loss: -1.0996  Acc@1: 75.0000 (76.7045)  Acc@5: 100.0000 (95.4545)  time: 0.7739  data: 0.0277  max mem: 2500
Train: Epoch[4/5]  [  20/3750]  eta: 0:47:18  Lr: 0.001875  Loss: -0.7105  Acc@1: 81.2500 (78.2738)  Acc@5: 100.0000 (95.5357)  time: 0.7465  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [  30/3750]  eta: 0:47:01  Lr: 0.001875  Loss: -0.8143  Acc@1: 81.2500 (80.6452)  Acc@5: 100.0000 (96.1694)  time: 0.7502  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [  40/3750]  eta: 0:46:49  Lr: 0.001875  Loss: -0.7564  Acc@1: 81.2500 (80.7927)  Acc@5: 100.0000 (96.6463)  time: 0.7536  data: 0.0010  max mem: 2500
Train: Epoch[4/5]  [  50/3750]  eta: 0:46:39  Lr: 0.001875  Loss: -1.1390  Acc@1: 81.2500 (79.7794)  Acc@5: 100.0000 (96.5686)  time: 0.7539  data: 0.0016  max mem: 2500
Train: Epoch[4/5]  [  60/3750]  eta: 0:46:25  Lr: 0.001875  Loss: -0.9688  Acc@1: 81.2500 (79.6107)  Acc@5: 100.0000 (96.8238)  time: 0.7496  data: 0.0015  max mem: 2500
Train: Epoch[4/5]  [  70/3750]  eta: 0:46:13  Lr: 0.001875  Loss: -1.3014  Acc@1: 75.0000 (80.1056)  Acc@5: 100.0000 (96.7430)  time: 0.7456  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [  80/3750]  eta: 0:46:00  Lr: 0.001875  Loss: -1.1631  Acc@1: 81.2500 (80.7870)  Acc@5: 100.0000 (96.8364)  time: 0.7440  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [  90/3750]  eta: 0:45:48  Lr: 0.001875  Loss: -1.2207  Acc@1: 87.5000 (80.9753)  Acc@5: 100.0000 (96.7033)  time: 0.7418  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 100/3750]  eta: 0:45:39  Lr: 0.001875  Loss: -1.3129  Acc@1: 81.2500 (81.3119)  Acc@5: 100.0000 (96.7203)  time: 0.7441  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [ 110/3750]  eta: 0:45:29  Lr: 0.001875  Loss: -1.3360  Acc@1: 81.2500 (81.3063)  Acc@5: 100.0000 (96.8468)  time: 0.7439  data: 0.0017  max mem: 2500
Train: Epoch[4/5]  [ 120/3750]  eta: 0:45:18  Lr: 0.001875  Loss: -0.3108  Acc@1: 81.2500 (81.3533)  Acc@5: 100.0000 (96.6942)  time: 0.7414  data: 0.0015  max mem: 2500
Train: Epoch[4/5]  [ 130/3750]  eta: 0:45:11  Lr: 0.001875  Loss: -1.1659  Acc@1: 81.2500 (81.4885)  Acc@5: 93.7500 (96.6603)  time: 0.7448  data: 0.0017  max mem: 2500
Train: Epoch[4/5]  [ 140/3750]  eta: 0:45:02  Lr: 0.001875  Loss: -1.4018  Acc@1: 81.2500 (81.6046)  Acc@5: 93.7500 (96.6755)  time: 0.7468  data: 0.0027  max mem: 2500
Train: Epoch[4/5]  [ 150/3750]  eta: 0:44:54  Lr: 0.001875  Loss: -1.1381  Acc@1: 81.2500 (81.6639)  Acc@5: 100.0000 (96.7715)  time: 0.7445  data: 0.0017  max mem: 2500
Train: Epoch[4/5]  [ 160/3750]  eta: 0:44:46  Lr: 0.001875  Loss: -1.0834  Acc@1: 81.2500 (81.6382)  Acc@5: 100.0000 (96.7391)  time: 0.7452  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [ 170/3750]  eta: 0:44:37  Lr: 0.001875  Loss: -1.0861  Acc@1: 81.2500 (81.5789)  Acc@5: 100.0000 (96.7471)  time: 0.7434  data: 0.0013  max mem: 2500
Train: Epoch[4/5]  [ 180/3750]  eta: 0:43:38  Lr: 0.001875  Loss: -1.2903  Acc@1: 81.2500 (81.5262)  Acc@5: 100.0000 (96.7196)  time: 0.6145  data: 0.0012  max mem: 2500
Train: Epoch[4/5]  [ 190/3750]  eta: 0:42:18  Lr: 0.001875  Loss: -0.8345  Acc@1: 81.2500 (81.6427)  Acc@5: 100.0000 (96.7605)  time: 0.4171  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [ 200/3750]  eta: 0:41:06  Lr: 0.001875  Loss: -1.0355  Acc@1: 87.5000 (81.9341)  Acc@5: 100.0000 (96.7973)  time: 0.3454  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [ 210/3750]  eta: 0:40:01  Lr: 0.001875  Loss: -0.6452  Acc@1: 87.5000 (82.0201)  Acc@5: 100.0000 (96.8009)  time: 0.3472  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 220/3750]  eta: 0:39:03  Lr: 0.001875  Loss: -0.6936  Acc@1: 87.5000 (82.0701)  Acc@5: 100.0000 (96.7760)  time: 0.3519  data: 0.0015  max mem: 2500
Train: Epoch[4/5]  [ 230/3750]  eta: 0:38:10  Lr: 0.001875  Loss: -1.1949  Acc@1: 87.5000 (82.0346)  Acc@5: 100.0000 (96.7803)  time: 0.3565  data: 0.0019  max mem: 2500
Train: Epoch[4/5]  [ 240/3750]  eta: 0:37:21  Lr: 0.001875  Loss: -1.2715  Acc@1: 81.2500 (82.0539)  Acc@5: 100.0000 (96.8102)  time: 0.3581  data: 0.0025  max mem: 2500
Train: Epoch[4/5]  [ 250/3750]  eta: 0:36:35  Lr: 0.001875  Loss: -0.9367  Acc@1: 81.2500 (82.1215)  Acc@5: 100.0000 (96.8127)  time: 0.3596  data: 0.0025  max mem: 2500
Train: Epoch[4/5]  [ 260/3750]  eta: 0:35:53  Lr: 0.001875  Loss: -0.7891  Acc@1: 81.2500 (82.0402)  Acc@5: 100.0000 (96.7912)  time: 0.3605  data: 0.0019  max mem: 2500
Train: Epoch[4/5]  [ 270/3750]  eta: 0:35:13  Lr: 0.001875  Loss: -0.5618  Acc@1: 81.2500 (81.8496)  Acc@5: 93.7500 (96.7251)  time: 0.3569  data: 0.0018  max mem: 2500
Train: Epoch[4/5]  [ 280/3750]  eta: 0:34:37  Lr: 0.001875  Loss: -0.9544  Acc@1: 75.0000 (81.8728)  Acc@5: 93.7500 (96.7082)  time: 0.3585  data: 0.0017  max mem: 2500
Train: Epoch[4/5]  [ 290/3750]  eta: 0:34:03  Lr: 0.001875  Loss: -1.2853  Acc@1: 75.0000 (81.7010)  Acc@5: 93.7500 (96.5421)  time: 0.3642  data: 0.0022  max mem: 2500
Train: Epoch[4/5]  [ 300/3750]  eta: 0:33:32  Lr: 0.001875  Loss: -1.0011  Acc@1: 81.2500 (81.8106)  Acc@5: 93.7500 (96.5947)  time: 0.3664  data: 0.0015  max mem: 2500
Train: Epoch[4/5]  [ 310/3750]  eta: 0:33:01  Lr: 0.001875  Loss: -0.7477  Acc@1: 81.2500 (81.7524)  Acc@5: 100.0000 (96.5635)  time: 0.3616  data: 0.0010  max mem: 2500
Train: Epoch[4/5]  [ 320/3750]  eta: 0:32:31  Lr: 0.001875  Loss: -1.1666  Acc@1: 81.2500 (81.8146)  Acc@5: 100.0000 (96.5537)  time: 0.3517  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [ 330/3750]  eta: 0:32:03  Lr: 0.001875  Loss: -1.0335  Acc@1: 81.2500 (81.9109)  Acc@5: 100.0000 (96.6201)  time: 0.3498  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 340/3750]  eta: 0:32:03  Lr: 0.001875  Loss: -1.0985  Acc@1: 81.2500 (81.9465)  Acc@5: 100.0000 (96.5909)  time: 0.4848  data: 0.0009  max mem: 2500
Train: Epoch[4/5]  [ 350/3750]  eta: 0:32:15  Lr: 0.001875  Loss: -0.4683  Acc@1: 81.2500 (81.8198)  Acc@5: 93.7500 (96.5812)  time: 0.6838  data: 0.0009  max mem: 2500
Train: Epoch[4/5]  [ 360/3750]  eta: 0:32:26  Lr: 0.001875  Loss: -1.3976  Acc@1: 81.2500 (81.8733)  Acc@5: 93.7500 (96.5893)  time: 0.7467  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [ 370/3750]  eta: 0:32:36  Lr: 0.001875  Loss: -0.9375  Acc@1: 81.2500 (81.9744)  Acc@5: 93.7500 (96.5802)  time: 0.7452  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 380/3750]  eta: 0:32:45  Lr: 0.001875  Loss: -1.0587  Acc@1: 87.5000 (82.0538)  Acc@5: 100.0000 (96.6043)  time: 0.7486  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [ 390/3750]  eta: 0:32:55  Lr: 0.001875  Loss: -0.8141  Acc@1: 81.2500 (81.9054)  Acc@5: 100.0000 (96.6113)  time: 0.7578  data: 0.0013  max mem: 2500
Train: Epoch[4/5]  [ 400/3750]  eta: 0:33:03  Lr: 0.001875  Loss: -0.8883  Acc@1: 81.2500 (82.0137)  Acc@5: 93.7500 (96.5867)  time: 0.7588  data: 0.0029  max mem: 2500
Train: Epoch[4/5]  [ 410/3750]  eta: 0:33:10  Lr: 0.001875  Loss: -0.6529  Acc@1: 81.2500 (82.0408)  Acc@5: 100.0000 (96.6241)  time: 0.7520  data: 0.0023  max mem: 2500
Train: Epoch[4/5]  [ 420/3750]  eta: 0:33:16  Lr: 0.001875  Loss: -0.9143  Acc@1: 81.2500 (82.0962)  Acc@5: 100.0000 (96.6300)  time: 0.7499  data: 0.0010  max mem: 2500
Train: Epoch[4/5]  [ 430/3750]  eta: 0:33:21  Lr: 0.001875  Loss: -0.8423  Acc@1: 81.2500 (82.1781)  Acc@5: 93.7500 (96.5777)  time: 0.7466  data: 0.0010  max mem: 2500
Train: Epoch[4/5]  [ 440/3750]  eta: 0:33:25  Lr: 0.001875  Loss: -1.2211  Acc@1: 87.5000 (82.2421)  Acc@5: 93.7500 (96.5845)  time: 0.7428  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 450/3750]  eta: 0:33:29  Lr: 0.001875  Loss: -1.0342  Acc@1: 81.2500 (82.0953)  Acc@5: 93.7500 (96.5216)  time: 0.7396  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [ 460/3750]  eta: 0:33:32  Lr: 0.001875  Loss: -0.6352  Acc@1: 75.0000 (81.9685)  Acc@5: 93.7500 (96.5157)  time: 0.7400  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [ 470/3750]  eta: 0:33:36  Lr: 0.001875  Loss: -1.0788  Acc@1: 75.0000 (81.9666)  Acc@5: 93.7500 (96.5101)  time: 0.7479  data: 0.0035  max mem: 2500
Train: Epoch[4/5]  [ 480/3750]  eta: 0:33:39  Lr: 0.001875  Loss: -1.1502  Acc@1: 87.5000 (81.9777)  Acc@5: 93.7500 (96.5177)  time: 0.7493  data: 0.0033  max mem: 2500
Train: Epoch[4/5]  [ 490/3750]  eta: 0:33:41  Lr: 0.001875  Loss: -1.0755  Acc@1: 87.5000 (82.0265)  Acc@5: 93.7500 (96.5122)  time: 0.7420  data: 0.0015  max mem: 2500
Train: Epoch[4/5]  [ 500/3750]  eta: 0:33:43  Lr: 0.001875  Loss: -0.8526  Acc@1: 81.2500 (81.9486)  Acc@5: 93.7500 (96.4820)  time: 0.7420  data: 0.0023  max mem: 2500
Train: Epoch[4/5]  [ 510/3750]  eta: 0:33:44  Lr: 0.001875  Loss: -0.7711  Acc@1: 87.5000 (82.0695)  Acc@5: 100.0000 (96.5142)  time: 0.7439  data: 0.0015  max mem: 2500
Train: Epoch[4/5]  [ 520/3750]  eta: 0:33:45  Lr: 0.001875  Loss: -1.2233  Acc@1: 87.5000 (81.9338)  Acc@5: 100.0000 (96.4851)  time: 0.7447  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [ 530/3750]  eta: 0:33:46  Lr: 0.001875  Loss: -1.0985  Acc@1: 81.2500 (81.8621)  Acc@5: 100.0000 (96.5160)  time: 0.7415  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 540/3750]  eta: 0:33:46  Lr: 0.001875  Loss: -1.1158  Acc@1: 81.2500 (81.8045)  Acc@5: 93.7500 (96.4533)  time: 0.7359  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 550/3750]  eta: 0:33:45  Lr: 0.001875  Loss: -0.8512  Acc@1: 81.2500 (81.8512)  Acc@5: 93.7500 (96.4610)  time: 0.7332  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 560/3750]  eta: 0:33:45  Lr: 0.001875  Loss: -0.4256  Acc@1: 87.5000 (81.8516)  Acc@5: 100.0000 (96.4795)  time: 0.7399  data: 0.0010  max mem: 2500
Train: Epoch[4/5]  [ 570/3750]  eta: 0:33:46  Lr: 0.001875  Loss: -0.4426  Acc@1: 81.2500 (81.8192)  Acc@5: 100.0000 (96.4864)  time: 0.7517  data: 0.0015  max mem: 2500
Train: Epoch[4/5]  [ 580/3750]  eta: 0:33:46  Lr: 0.001875  Loss: -1.0972  Acc@1: 81.2500 (81.8201)  Acc@5: 100.0000 (96.5039)  time: 0.7552  data: 0.0013  max mem: 2500
Train: Epoch[4/5]  [ 590/3750]  eta: 0:33:46  Lr: 0.001875  Loss: -0.8972  Acc@1: 81.2500 (81.8316)  Acc@5: 100.0000 (96.4996)  time: 0.7553  data: 0.0013  max mem: 2500
Train: Epoch[4/5]  [ 600/3750]  eta: 0:33:44  Lr: 0.001875  Loss: -0.9881  Acc@1: 87.5000 (81.8740)  Acc@5: 100.0000 (96.5370)  time: 0.7463  data: 0.0009  max mem: 2500
Train: Epoch[4/5]  [ 610/3750]  eta: 0:33:42  Lr: 0.001875  Loss: -1.1222  Acc@1: 75.0000 (81.7819)  Acc@5: 100.0000 (96.5426)  time: 0.7337  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 620/3750]  eta: 0:33:40  Lr: 0.001875  Loss: -0.7569  Acc@1: 75.0000 (81.7532)  Acc@5: 100.0000 (96.5378)  time: 0.7306  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 630/3750]  eta: 0:33:38  Lr: 0.001875  Loss: -0.9678  Acc@1: 81.2500 (81.8146)  Acc@5: 100.0000 (96.5630)  time: 0.7304  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 640/3750]  eta: 0:33:33  Lr: 0.001875  Loss: -1.2537  Acc@1: 87.5000 (81.8838)  Acc@5: 100.0000 (96.6069)  time: 0.7024  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [ 650/3750]  eta: 0:33:28  Lr: 0.001875  Loss: -0.5033  Acc@1: 87.5000 (81.9028)  Acc@5: 100.0000 (96.6110)  time: 0.6795  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [ 660/3750]  eta: 0:33:26  Lr: 0.001875  Loss: -1.4187  Acc@1: 81.2500 (81.9213)  Acc@5: 100.0000 (96.6244)  time: 0.7117  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [ 670/3750]  eta: 0:33:24  Lr: 0.001875  Loss: -0.7857  Acc@1: 81.2500 (81.8648)  Acc@5: 100.0000 (96.6095)  time: 0.7389  data: 0.0015  max mem: 2500
Train: Epoch[4/5]  [ 680/3750]  eta: 0:33:22  Lr: 0.001875  Loss: -1.0681  Acc@1: 81.2500 (81.8374)  Acc@5: 93.7500 (96.5492)  time: 0.7521  data: 0.0021  max mem: 2500
Train: Epoch[4/5]  [ 690/3750]  eta: 0:33:20  Lr: 0.001875  Loss: -0.7151  Acc@1: 81.2500 (81.8379)  Acc@5: 93.7500 (96.5720)  time: 0.7549  data: 0.0022  max mem: 2500
Train: Epoch[4/5]  [ 700/3750]  eta: 0:33:17  Lr: 0.001875  Loss: -1.0505  Acc@1: 81.2500 (81.8117)  Acc@5: 100.0000 (96.5496)  time: 0.7401  data: 0.0014  max mem: 2500
Train: Epoch[4/5]  [ 710/3750]  eta: 0:33:13  Lr: 0.001875  Loss: -1.0729  Acc@1: 81.2500 (81.8126)  Acc@5: 93.7500 (96.5454)  time: 0.7329  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [ 720/3750]  eta: 0:33:10  Lr: 0.001875  Loss: -1.0164  Acc@1: 81.2500 (81.7874)  Acc@5: 100.0000 (96.5413)  time: 0.7309  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 730/3750]  eta: 0:33:07  Lr: 0.001875  Loss: -0.9539  Acc@1: 81.2500 (81.7801)  Acc@5: 100.0000 (96.5458)  time: 0.7319  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [ 740/3750]  eta: 0:33:04  Lr: 0.001875  Loss: -1.3102  Acc@1: 81.2500 (81.8151)  Acc@5: 100.0000 (96.5503)  time: 0.7405  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [ 750/3750]  eta: 0:33:00  Lr: 0.001875  Loss: -0.7649  Acc@1: 81.2500 (81.7826)  Acc@5: 100.0000 (96.5463)  time: 0.7453  data: 0.0009  max mem: 2500
Train: Epoch[4/5]  [ 760/3750]  eta: 0:32:58  Lr: 0.001875  Loss: -1.3246  Acc@1: 81.2500 (81.7510)  Acc@5: 100.0000 (96.5670)  time: 0.7493  data: 0.0010  max mem: 2500
Train: Epoch[4/5]  [ 770/3750]  eta: 0:32:54  Lr: 0.001875  Loss: -0.7994  Acc@1: 81.2500 (81.7202)  Acc@5: 100.0000 (96.5710)  time: 0.7474  data: 0.0012  max mem: 2500
Train: Epoch[4/5]  [ 780/3750]  eta: 0:32:51  Lr: 0.001875  Loss: -1.1061  Acc@1: 81.2500 (81.7222)  Acc@5: 100.0000 (96.5669)  time: 0.7423  data: 0.0009  max mem: 2500
Train: Epoch[4/5]  [ 790/3750]  eta: 0:32:46  Lr: 0.001875  Loss: -0.8901  Acc@1: 81.2500 (81.7557)  Acc@5: 100.0000 (96.5708)  time: 0.7385  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 800/3750]  eta: 0:32:42  Lr: 0.001875  Loss: -1.2345  Acc@1: 81.2500 (81.7650)  Acc@5: 100.0000 (96.5590)  time: 0.7343  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 810/3750]  eta: 0:32:38  Lr: 0.001875  Loss: -0.9553  Acc@1: 81.2500 (81.7586)  Acc@5: 100.0000 (96.5937)  time: 0.7354  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [ 820/3750]  eta: 0:32:34  Lr: 0.001875  Loss: -1.1241  Acc@1: 81.2500 (81.7753)  Acc@5: 100.0000 (96.5895)  time: 0.7358  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [ 830/3750]  eta: 0:32:30  Lr: 0.001875  Loss: -1.2477  Acc@1: 81.2500 (81.7464)  Acc@5: 100.0000 (96.6155)  time: 0.7379  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [ 840/3750]  eta: 0:32:26  Lr: 0.001875  Loss: -1.0093  Acc@1: 81.2500 (81.7108)  Acc@5: 100.0000 (96.6409)  time: 0.7472  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [ 850/3750]  eta: 0:32:23  Lr: 0.001875  Loss: -0.9994  Acc@1: 81.2500 (81.6833)  Acc@5: 100.0000 (96.6363)  time: 0.7547  data: 0.0011  max mem: 2500
Train: Epoch[4/5]  [ 860/3750]  eta: 0:32:18  Lr: 0.001875  Loss: -1.0531  Acc@1: 81.2500 (81.7146)  Acc@5: 93.7500 (96.5955)  time: 0.7465  data: 0.0012  max mem: 2500
Train: Epoch[4/5]  [ 870/3750]  eta: 0:32:14  Lr: 0.001875  Loss: -1.1270  Acc@1: 87.5000 (81.7810)  Acc@5: 93.7500 (96.5987)  time: 0.7419  data: 0.0012  max mem: 2500
Train: Epoch[4/5]  [ 880/3750]  eta: 0:32:09  Lr: 0.001875  Loss: -1.0325  Acc@1: 81.2500 (81.7608)  Acc@5: 100.0000 (96.5877)  time: 0.7392  data: 0.0010  max mem: 2500
Train: Epoch[4/5]  [ 890/3750]  eta: 0:32:05  Lr: 0.001875  Loss: -0.5779  Acc@1: 81.2500 (81.7901)  Acc@5: 93.7500 (96.5839)  time: 0.7351  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 900/3750]  eta: 0:32:00  Lr: 0.001875  Loss: -0.8377  Acc@1: 81.2500 (81.8257)  Acc@5: 100.0000 (96.6079)  time: 0.7357  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 910/3750]  eta: 0:31:55  Lr: 0.001875  Loss: -0.9052  Acc@1: 81.2500 (81.7920)  Acc@5: 100.0000 (96.6246)  time: 0.7369  data: 0.0011  max mem: 2500
Train: Epoch[4/5]  [ 920/3750]  eta: 0:31:50  Lr: 0.001875  Loss: -1.2227  Acc@1: 75.0000 (81.7522)  Acc@5: 100.0000 (96.6137)  time: 0.7377  data: 0.0013  max mem: 2500
Train: Epoch[4/5]  [ 930/3750]  eta: 0:31:45  Lr: 0.001875  Loss: -0.8808  Acc@1: 75.0000 (81.7669)  Acc@5: 93.7500 (96.5695)  time: 0.7386  data: 0.0013  max mem: 2500
Train: Epoch[4/5]  [ 940/3750]  eta: 0:31:41  Lr: 0.001875  Loss: -0.5634  Acc@1: 81.2500 (81.7548)  Acc@5: 93.7500 (96.5794)  time: 0.7438  data: 0.0027  max mem: 2500
Train: Epoch[4/5]  [ 950/3750]  eta: 0:31:36  Lr: 0.001875  Loss: -1.1794  Acc@1: 81.2500 (81.7560)  Acc@5: 100.0000 (96.5891)  time: 0.7467  data: 0.0025  max mem: 2500
Train: Epoch[4/5]  [ 960/3750]  eta: 0:31:32  Lr: 0.001875  Loss: -0.7944  Acc@1: 81.2500 (81.7898)  Acc@5: 100.0000 (96.6051)  time: 0.7512  data: 0.0019  max mem: 2500
Train: Epoch[4/5]  [ 970/3750]  eta: 0:31:26  Lr: 0.001875  Loss: -1.1547  Acc@1: 87.5000 (81.8486)  Acc@5: 100.0000 (96.6143)  time: 0.7386  data: 0.0014  max mem: 2500
Train: Epoch[4/5]  [ 980/3750]  eta: 0:31:17  Lr: 0.001875  Loss: -1.0896  Acc@1: 81.2500 (81.8361)  Acc@5: 100.0000 (96.6361)  time: 0.6560  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [ 990/3750]  eta: 0:31:01  Lr: 0.001875  Loss: -0.9202  Acc@1: 75.0000 (81.7987)  Acc@5: 100.0000 (96.6448)  time: 0.4704  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [1000/3750]  eta: 0:30:45  Lr: 0.001875  Loss: -0.7914  Acc@1: 75.0000 (81.7932)  Acc@5: 100.0000 (96.6596)  time: 0.3468  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1010/3750]  eta: 0:30:30  Lr: 0.001875  Loss: -1.0820  Acc@1: 81.2500 (81.7878)  Acc@5: 100.0000 (96.6741)  time: 0.3466  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1020/3750]  eta: 0:30:14  Lr: 0.001875  Loss: -1.1586  Acc@1: 81.2500 (81.8009)  Acc@5: 100.0000 (96.6822)  time: 0.3462  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [1030/3750]  eta: 0:29:59  Lr: 0.001875  Loss: -0.6846  Acc@1: 87.5000 (81.7895)  Acc@5: 100.0000 (96.6901)  time: 0.3446  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [1040/3750]  eta: 0:29:45  Lr: 0.001875  Loss: -1.3135  Acc@1: 81.2500 (81.7723)  Acc@5: 100.0000 (96.7099)  time: 0.3495  data: 0.0013  max mem: 2500
Train: Epoch[4/5]  [1050/3750]  eta: 0:29:30  Lr: 0.001875  Loss: -1.2726  Acc@1: 87.5000 (81.8268)  Acc@5: 100.0000 (96.7055)  time: 0.3564  data: 0.0022  max mem: 2500
Train: Epoch[4/5]  [1060/3750]  eta: 0:29:16  Lr: 0.001875  Loss: -0.6295  Acc@1: 87.5000 (81.8567)  Acc@5: 100.0000 (96.7130)  time: 0.3573  data: 0.0029  max mem: 2500
Train: Epoch[4/5]  [1070/3750]  eta: 0:29:02  Lr: 0.001875  Loss: -0.8357  Acc@1: 87.5000 (81.9094)  Acc@5: 100.0000 (96.7262)  time: 0.3573  data: 0.0023  max mem: 2500
Train: Epoch[4/5]  [1080/3750]  eta: 0:28:49  Lr: 0.001875  Loss: -1.0712  Acc@1: 81.2500 (81.8860)  Acc@5: 100.0000 (96.7218)  time: 0.3593  data: 0.0009  max mem: 2500
Train: Epoch[4/5]  [1090/3750]  eta: 0:28:35  Lr: 0.001875  Loss: -1.0071  Acc@1: 81.2500 (81.8744)  Acc@5: 93.7500 (96.6831)  time: 0.3611  data: 0.0040  max mem: 2500
Train: Epoch[4/5]  [1100/3750]  eta: 0:28:22  Lr: 0.001875  Loss: -0.6765  Acc@1: 81.2500 (81.8347)  Acc@5: 93.7500 (96.6792)  time: 0.3587  data: 0.0046  max mem: 2500
Train: Epoch[4/5]  [1110/3750]  eta: 0:28:08  Lr: 0.001875  Loss: -1.2494  Acc@1: 75.0000 (81.8238)  Acc@5: 93.7500 (96.6640)  time: 0.3551  data: 0.0014  max mem: 2500
Train: Epoch[4/5]  [1120/3750]  eta: 0:27:55  Lr: 0.001875  Loss: -0.6760  Acc@1: 75.0000 (81.7852)  Acc@5: 93.7500 (96.6659)  time: 0.3561  data: 0.0014  max mem: 2500
Train: Epoch[4/5]  [1130/3750]  eta: 0:27:43  Lr: 0.001875  Loss: -1.2334  Acc@1: 81.2500 (81.8247)  Acc@5: 100.0000 (96.6788)  time: 0.3566  data: 0.0015  max mem: 2500
Train: Epoch[4/5]  [1140/3750]  eta: 0:27:30  Lr: 0.001875  Loss: -1.0156  Acc@1: 87.5000 (81.8252)  Acc@5: 100.0000 (96.6805)  time: 0.3517  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [1150/3750]  eta: 0:27:17  Lr: 0.001875  Loss: -1.0307  Acc@1: 81.2500 (81.8202)  Acc@5: 100.0000 (96.6877)  time: 0.3488  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1160/3750]  eta: 0:27:04  Lr: 0.001875  Loss: -1.2127  Acc@1: 81.2500 (81.8637)  Acc@5: 100.0000 (96.7054)  time: 0.3487  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [1170/3750]  eta: 0:26:52  Lr: 0.001875  Loss: -1.1026  Acc@1: 87.5000 (81.8851)  Acc@5: 100.0000 (96.7015)  time: 0.3479  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1180/3750]  eta: 0:26:40  Lr: 0.001875  Loss: -1.0449  Acc@1: 81.2500 (81.8692)  Acc@5: 100.0000 (96.7030)  time: 0.3480  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1190/3750]  eta: 0:26:27  Lr: 0.001875  Loss: -0.8262  Acc@1: 75.0000 (81.8377)  Acc@5: 100.0000 (96.7097)  time: 0.3462  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [1200/3750]  eta: 0:26:15  Lr: 0.001875  Loss: -1.4365  Acc@1: 81.2500 (81.8276)  Acc@5: 100.0000 (96.7319)  time: 0.3456  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1210/3750]  eta: 0:26:03  Lr: 0.001875  Loss: -0.9182  Acc@1: 81.2500 (81.8538)  Acc@5: 100.0000 (96.7434)  time: 0.3454  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1220/3750]  eta: 0:25:52  Lr: 0.001875  Loss: -0.8686  Acc@1: 81.2500 (81.8438)  Acc@5: 100.0000 (96.7394)  time: 0.3446  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [1230/3750]  eta: 0:25:40  Lr: 0.001875  Loss: -0.6777  Acc@1: 75.0000 (81.7882)  Acc@5: 93.7500 (96.7201)  time: 0.3490  data: 0.0016  max mem: 2500
Train: Epoch[4/5]  [1240/3750]  eta: 0:25:29  Lr: 0.001875  Loss: -0.6679  Acc@1: 81.2500 (81.7939)  Acc@5: 100.0000 (96.7315)  time: 0.3534  data: 0.0022  max mem: 2500
Train: Epoch[4/5]  [1250/3750]  eta: 0:25:18  Lr: 0.001875  Loss: -0.6915  Acc@1: 81.2500 (81.7846)  Acc@5: 100.0000 (96.7326)  time: 0.3552  data: 0.0015  max mem: 2500
Train: Epoch[4/5]  [1260/3750]  eta: 0:25:07  Lr: 0.001875  Loss: -1.3937  Acc@1: 87.5000 (81.8349)  Acc@5: 100.0000 (96.7585)  time: 0.3593  data: 0.0012  max mem: 2500
Train: Epoch[4/5]  [1270/3750]  eta: 0:24:56  Lr: 0.001875  Loss: -1.3756  Acc@1: 81.2500 (81.8155)  Acc@5: 100.0000 (96.7644)  time: 0.3598  data: 0.0010  max mem: 2500
Train: Epoch[4/5]  [1280/3750]  eta: 0:24:45  Lr: 0.001875  Loss: -0.6931  Acc@1: 81.2500 (81.8257)  Acc@5: 100.0000 (96.7701)  time: 0.3575  data: 0.0017  max mem: 2500
Train: Epoch[4/5]  [1290/3750]  eta: 0:24:35  Lr: 0.001875  Loss: -1.1942  Acc@1: 81.2500 (81.8406)  Acc@5: 93.7500 (96.7515)  time: 0.3575  data: 0.0015  max mem: 2500
Train: Epoch[4/5]  [1300/3750]  eta: 0:24:24  Lr: 0.001875  Loss: -0.8210  Acc@1: 81.2500 (81.8553)  Acc@5: 93.7500 (96.7573)  time: 0.3576  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [1310/3750]  eta: 0:24:14  Lr: 0.001875  Loss: -0.7704  Acc@1: 81.2500 (81.8459)  Acc@5: 100.0000 (96.7677)  time: 0.3583  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [1320/3750]  eta: 0:24:03  Lr: 0.001875  Loss: -0.7148  Acc@1: 87.5000 (81.8556)  Acc@5: 100.0000 (96.7638)  time: 0.3539  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [1330/3750]  eta: 0:23:53  Lr: 0.001875  Loss: -0.8481  Acc@1: 87.5000 (81.8557)  Acc@5: 100.0000 (96.7647)  time: 0.3477  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [1340/3750]  eta: 0:23:42  Lr: 0.001875  Loss: -1.1732  Acc@1: 81.2500 (81.8839)  Acc@5: 100.0000 (96.7795)  time: 0.3486  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1350/3750]  eta: 0:23:32  Lr: 0.001875  Loss: -0.4750  Acc@1: 87.5000 (81.8977)  Acc@5: 100.0000 (96.7848)  time: 0.3492  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1360/3750]  eta: 0:23:22  Lr: 0.001875  Loss: -0.9341  Acc@1: 87.5000 (81.9251)  Acc@5: 100.0000 (96.7900)  time: 0.3485  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1370/3750]  eta: 0:23:12  Lr: 0.001875  Loss: -0.9298  Acc@1: 81.2500 (81.9201)  Acc@5: 100.0000 (96.7724)  time: 0.3465  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1380/3750]  eta: 0:23:02  Lr: 0.001875  Loss: -1.0161  Acc@1: 81.2500 (81.9153)  Acc@5: 93.7500 (96.7596)  time: 0.3464  data: 0.0012  max mem: 2500
Train: Epoch[4/5]  [1390/3750]  eta: 0:22:52  Lr: 0.001875  Loss: -1.1178  Acc@1: 81.2500 (81.9060)  Acc@5: 93.7500 (96.7559)  time: 0.3467  data: 0.0012  max mem: 2500
Train: Epoch[4/5]  [1400/3750]  eta: 0:22:42  Lr: 0.001875  Loss: -1.0380  Acc@1: 81.2500 (81.8746)  Acc@5: 100.0000 (96.7479)  time: 0.3456  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [1410/3750]  eta: 0:22:33  Lr: 0.001875  Loss: -0.7255  Acc@1: 81.2500 (81.8878)  Acc@5: 93.7500 (96.7310)  time: 0.3483  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1420/3750]  eta: 0:22:23  Lr: 0.001875  Loss: -0.9355  Acc@1: 81.2500 (81.8702)  Acc@5: 93.7500 (96.7277)  time: 0.3553  data: 0.0018  max mem: 2500
Train: Epoch[4/5]  [1430/3750]  eta: 0:22:14  Lr: 0.001875  Loss: -1.1452  Acc@1: 81.2500 (81.8484)  Acc@5: 100.0000 (96.7287)  time: 0.3588  data: 0.0019  max mem: 2500
Train: Epoch[4/5]  [1440/3750]  eta: 0:22:05  Lr: 0.001875  Loss: -1.1386  Acc@1: 81.2500 (81.8312)  Acc@5: 100.0000 (96.7340)  time: 0.3568  data: 0.0009  max mem: 2500
Train: Epoch[4/5]  [1450/3750]  eta: 0:21:56  Lr: 0.001875  Loss: -0.5192  Acc@1: 81.2500 (81.8444)  Acc@5: 100.0000 (96.7307)  time: 0.3627  data: 0.0009  max mem: 2500
Train: Epoch[4/5]  [1460/3750]  eta: 0:21:47  Lr: 0.001875  Loss: -0.9282  Acc@1: 81.2500 (81.8446)  Acc@5: 100.0000 (96.7402)  time: 0.3660  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [1470/3750]  eta: 0:21:38  Lr: 0.001875  Loss: -1.1398  Acc@1: 81.2500 (81.8448)  Acc@5: 100.0000 (96.7412)  time: 0.3607  data: 0.0010  max mem: 2500
Train: Epoch[4/5]  [1480/3750]  eta: 0:21:31  Lr: 0.001875  Loss: -1.0339  Acc@1: 81.2500 (81.8282)  Acc@5: 100.0000 (96.7252)  time: 0.4137  data: 0.0009  max mem: 2500
Train: Epoch[4/5]  [1490/3750]  eta: 0:21:28  Lr: 0.001875  Loss: -1.1908  Acc@1: 81.2500 (81.8327)  Acc@5: 100.0000 (96.7304)  time: 0.6081  data: 0.0017  max mem: 2500
Train: Epoch[4/5]  [1500/3750]  eta: 0:21:24  Lr: 0.001875  Loss: -1.2385  Acc@1: 81.2500 (81.8413)  Acc@5: 100.0000 (96.7397)  time: 0.7432  data: 0.0016  max mem: 2500
Train: Epoch[4/5]  [1510/3750]  eta: 0:21:21  Lr: 0.001875  Loss: -0.8181  Acc@1: 81.2500 (81.8374)  Acc@5: 100.0000 (96.7488)  time: 0.7364  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [1520/3750]  eta: 0:21:18  Lr: 0.001875  Loss: -1.0139  Acc@1: 81.2500 (81.8376)  Acc@5: 100.0000 (96.7497)  time: 0.7357  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1530/3750]  eta: 0:21:14  Lr: 0.001875  Loss: -1.2169  Acc@1: 87.5000 (81.8787)  Acc@5: 100.0000 (96.7505)  time: 0.7359  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [1540/3750]  eta: 0:21:11  Lr: 0.001875  Loss: -1.0931  Acc@1: 87.5000 (81.8908)  Acc@5: 100.0000 (96.7513)  time: 0.7337  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1550/3750]  eta: 0:21:08  Lr: 0.001875  Loss: -0.6183  Acc@1: 81.2500 (81.8867)  Acc@5: 100.0000 (96.7602)  time: 0.7346  data: 0.0013  max mem: 2500
Train: Epoch[4/5]  [1560/3750]  eta: 0:21:04  Lr: 0.001875  Loss: -1.3304  Acc@1: 81.2500 (81.8666)  Acc@5: 100.0000 (96.7489)  time: 0.7309  data: 0.0027  max mem: 2500
Train: Epoch[4/5]  [1570/3750]  eta: 0:21:00  Lr: 0.001875  Loss: -0.7583  Acc@1: 81.2500 (81.8388)  Acc@5: 100.0000 (96.7656)  time: 0.7359  data: 0.0022  max mem: 2500
Train: Epoch[4/5]  [1580/3750]  eta: 0:20:57  Lr: 0.001875  Loss: -0.9324  Acc@1: 87.5000 (81.8469)  Acc@5: 100.0000 (96.7781)  time: 0.7370  data: 0.0013  max mem: 2500
Train: Epoch[4/5]  [1590/3750]  eta: 0:20:53  Lr: 0.001875  Loss: -0.7283  Acc@1: 87.5000 (81.8707)  Acc@5: 100.0000 (96.7866)  time: 0.7280  data: 0.0016  max mem: 2500
Train: Epoch[4/5]  [1600/3750]  eta: 0:20:46  Lr: 0.001875  Loss: -1.0264  Acc@1: 87.5000 (81.8980)  Acc@5: 100.0000 (96.7833)  time: 0.6158  data: 0.0012  max mem: 2500
Train: Epoch[4/5]  [1610/3750]  eta: 0:20:37  Lr: 0.001875  Loss: -1.0063  Acc@1: 81.2500 (81.8824)  Acc@5: 100.0000 (96.7877)  time: 0.4261  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1620/3750]  eta: 0:20:28  Lr: 0.001875  Loss: -0.9007  Acc@1: 81.2500 (81.8900)  Acc@5: 100.0000 (96.7960)  time: 0.3495  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [1630/3750]  eta: 0:20:20  Lr: 0.001875  Loss: -1.1627  Acc@1: 81.2500 (81.8976)  Acc@5: 100.0000 (96.7926)  time: 0.3484  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [1640/3750]  eta: 0:20:11  Lr: 0.001875  Loss: -0.4684  Acc@1: 81.2500 (81.8899)  Acc@5: 100.0000 (96.7855)  time: 0.3476  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1650/3750]  eta: 0:20:02  Lr: 0.001875  Loss: -1.2270  Acc@1: 81.2500 (81.8973)  Acc@5: 100.0000 (96.8012)  time: 0.3484  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1660/3750]  eta: 0:19:54  Lr: 0.001875  Loss: -0.9349  Acc@1: 81.2500 (81.8972)  Acc@5: 100.0000 (96.8054)  time: 0.3507  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1670/3750]  eta: 0:19:45  Lr: 0.001875  Loss: -0.6654  Acc@1: 81.2500 (81.8784)  Acc@5: 93.7500 (96.7834)  time: 0.3496  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [1680/3750]  eta: 0:19:37  Lr: 0.001875  Loss: -1.1269  Acc@1: 81.2500 (81.8969)  Acc@5: 93.7500 (96.7765)  time: 0.3465  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [1690/3750]  eta: 0:19:29  Lr: 0.001875  Loss: -0.7127  Acc@1: 81.2500 (81.8746)  Acc@5: 100.0000 (96.7881)  time: 0.3459  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1700/3750]  eta: 0:19:20  Lr: 0.001875  Loss: -1.2638  Acc@1: 81.2500 (81.8893)  Acc@5: 100.0000 (96.7997)  time: 0.3480  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1710/3750]  eta: 0:19:12  Lr: 0.001875  Loss: -0.7891  Acc@1: 81.2500 (81.8783)  Acc@5: 100.0000 (96.8001)  time: 0.3534  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [1720/3750]  eta: 0:19:04  Lr: 0.001875  Loss: -0.8174  Acc@1: 81.2500 (81.8528)  Acc@5: 100.0000 (96.8151)  time: 0.3560  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [1730/3750]  eta: 0:18:56  Lr: 0.001875  Loss: -0.9216  Acc@1: 81.2500 (81.8421)  Acc@5: 100.0000 (96.8226)  time: 0.3548  data: 0.0010  max mem: 2500
Train: Epoch[4/5]  [1740/3750]  eta: 0:18:48  Lr: 0.001875  Loss: -0.7574  Acc@1: 75.0000 (81.8136)  Acc@5: 100.0000 (96.8014)  time: 0.3547  data: 0.0017  max mem: 2500
Train: Epoch[4/5]  [1750/3750]  eta: 0:18:40  Lr: 0.001875  Loss: -0.8467  Acc@1: 81.2500 (81.8104)  Acc@5: 93.7500 (96.8018)  time: 0.3577  data: 0.0018  max mem: 2500
Train: Epoch[4/5]  [1760/3750]  eta: 0:18:32  Lr: 0.001875  Loss: -1.0295  Acc@1: 81.2500 (81.8250)  Acc@5: 100.0000 (96.7951)  time: 0.3580  data: 0.0012  max mem: 2500
Train: Epoch[4/5]  [1770/3750]  eta: 0:18:24  Lr: 0.001875  Loss: -1.3186  Acc@1: 87.5000 (81.8429)  Acc@5: 100.0000 (96.8062)  time: 0.3578  data: 0.0009  max mem: 2500
Train: Epoch[4/5]  [1780/3750]  eta: 0:18:16  Lr: 0.001875  Loss: -0.9555  Acc@1: 81.2500 (81.8396)  Acc@5: 100.0000 (96.7996)  time: 0.3559  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [1790/3750]  eta: 0:18:09  Lr: 0.001875  Loss: -1.1296  Acc@1: 81.2500 (81.8223)  Acc@5: 93.7500 (96.8000)  time: 0.3522  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [1800/3750]  eta: 0:18:01  Lr: 0.001875  Loss: -0.7997  Acc@1: 75.0000 (81.7879)  Acc@5: 93.7500 (96.7900)  time: 0.3530  data: 0.0010  max mem: 2500
Train: Epoch[4/5]  [1810/3750]  eta: 0:17:53  Lr: 0.001875  Loss: -0.4531  Acc@1: 81.2500 (81.8056)  Acc@5: 93.7500 (96.7870)  time: 0.3554  data: 0.0011  max mem: 2500
Train: Epoch[4/5]  [1820/3750]  eta: 0:17:46  Lr: 0.001875  Loss: -0.6179  Acc@1: 87.5000 (81.8094)  Acc@5: 100.0000 (96.7909)  time: 0.3586  data: 0.0020  max mem: 2500
Train: Epoch[4/5]  [1830/3750]  eta: 0:17:38  Lr: 0.001875  Loss: -0.8441  Acc@1: 87.5000 (81.8269)  Acc@5: 100.0000 (96.7914)  time: 0.3568  data: 0.0018  max mem: 2500
Train: Epoch[4/5]  [1840/3750]  eta: 0:17:30  Lr: 0.001875  Loss: -0.9838  Acc@1: 81.2500 (81.8169)  Acc@5: 93.7500 (96.7681)  time: 0.3508  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [1850/3750]  eta: 0:17:23  Lr: 0.001875  Loss: -0.5673  Acc@1: 81.2500 (81.8038)  Acc@5: 93.7500 (96.7686)  time: 0.3482  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1860/3750]  eta: 0:17:15  Lr: 0.001875  Loss: -1.1644  Acc@1: 81.2500 (81.8109)  Acc@5: 100.0000 (96.7726)  time: 0.3479  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1870/3750]  eta: 0:17:08  Lr: 0.001875  Loss: -1.1641  Acc@1: 87.5000 (81.8312)  Acc@5: 100.0000 (96.7698)  time: 0.3477  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1880/3750]  eta: 0:17:00  Lr: 0.001875  Loss: -0.8280  Acc@1: 81.2500 (81.8049)  Acc@5: 100.0000 (96.7803)  time: 0.3500  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [1890/3750]  eta: 0:16:53  Lr: 0.001875  Loss: -1.1043  Acc@1: 81.2500 (81.8119)  Acc@5: 100.0000 (96.7808)  time: 0.3492  data: 0.0009  max mem: 2500
Train: Epoch[4/5]  [1900/3750]  eta: 0:16:46  Lr: 0.001875  Loss: -1.0465  Acc@1: 81.2500 (81.8286)  Acc@5: 93.7500 (96.7747)  time: 0.3459  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [1910/3750]  eta: 0:16:38  Lr: 0.001875  Loss: -0.9453  Acc@1: 81.2500 (81.7995)  Acc@5: 93.7500 (96.7785)  time: 0.3462  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1920/3750]  eta: 0:16:31  Lr: 0.001875  Loss: -0.9952  Acc@1: 81.2500 (81.7966)  Acc@5: 100.0000 (96.7790)  time: 0.3468  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1930/3750]  eta: 0:16:24  Lr: 0.001875  Loss: -0.5358  Acc@1: 81.2500 (81.8002)  Acc@5: 100.0000 (96.7860)  time: 0.3465  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1940/3750]  eta: 0:16:16  Lr: 0.001875  Loss: -0.9725  Acc@1: 81.2500 (81.7716)  Acc@5: 100.0000 (96.7929)  time: 0.3488  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [1950/3750]  eta: 0:16:09  Lr: 0.001875  Loss: -0.9257  Acc@1: 81.2500 (81.7722)  Acc@5: 100.0000 (96.8029)  time: 0.3550  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [1960/3750]  eta: 0:16:02  Lr: 0.001875  Loss: -0.8386  Acc@1: 81.2500 (81.7854)  Acc@5: 100.0000 (96.8033)  time: 0.3554  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [1970/3750]  eta: 0:15:55  Lr: 0.001875  Loss: -0.7569  Acc@1: 81.2500 (81.7859)  Acc@5: 100.0000 (96.8068)  time: 0.3568  data: 0.0017  max mem: 2500
Train: Epoch[4/5]  [1980/3750]  eta: 0:15:48  Lr: 0.001875  Loss: -1.1685  Acc@1: 81.2500 (81.8084)  Acc@5: 100.0000 (96.8135)  time: 0.3617  data: 0.0028  max mem: 2500
Train: Epoch[4/5]  [1990/3750]  eta: 0:15:41  Lr: 0.001875  Loss: -0.6582  Acc@1: 87.5000 (81.8307)  Acc@5: 100.0000 (96.8138)  time: 0.3577  data: 0.0019  max mem: 2500
Train: Epoch[4/5]  [2000/3750]  eta: 0:15:35  Lr: 0.001875  Loss: -1.0672  Acc@1: 81.2500 (81.8060)  Acc@5: 93.7500 (96.8110)  time: 0.3570  data: 0.0031  max mem: 2500
Train: Epoch[4/5]  [2010/3750]  eta: 0:15:28  Lr: 0.001875  Loss: -0.7578  Acc@1: 81.2500 (81.8125)  Acc@5: 100.0000 (96.8206)  time: 0.3578  data: 0.0036  max mem: 2500
Train: Epoch[4/5]  [2020/3750]  eta: 0:15:21  Lr: 0.001875  Loss: -0.9954  Acc@1: 81.2500 (81.8067)  Acc@5: 100.0000 (96.8302)  time: 0.3547  data: 0.0015  max mem: 2500
Train: Epoch[4/5]  [2030/3750]  eta: 0:15:14  Lr: 0.001875  Loss: -0.9800  Acc@1: 87.5000 (81.8378)  Acc@5: 100.0000 (96.8304)  time: 0.3504  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [2040/3750]  eta: 0:15:07  Lr: 0.001875  Loss: -0.8936  Acc@1: 81.2500 (81.8134)  Acc@5: 100.0000 (96.8306)  time: 0.3470  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2050/3750]  eta: 0:15:00  Lr: 0.001875  Loss: -0.8190  Acc@1: 81.2500 (81.8137)  Acc@5: 100.0000 (96.8278)  time: 0.3504  data: 0.0010  max mem: 2500
Train: Epoch[4/5]  [2060/3750]  eta: 0:14:53  Lr: 0.001875  Loss: -1.1974  Acc@1: 81.2500 (81.8019)  Acc@5: 93.7500 (96.8250)  time: 0.3509  data: 0.0011  max mem: 2500
Train: Epoch[4/5]  [2070/3750]  eta: 0:14:47  Lr: 0.001875  Loss: -1.2072  Acc@1: 81.2500 (81.7993)  Acc@5: 93.7500 (96.8192)  time: 0.3484  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2080/3750]  eta: 0:14:40  Lr: 0.001875  Loss: -1.1237  Acc@1: 81.2500 (81.7906)  Acc@5: 100.0000 (96.8194)  time: 0.3473  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2090/3750]  eta: 0:14:33  Lr: 0.001875  Loss: -0.6783  Acc@1: 81.2500 (81.7910)  Acc@5: 100.0000 (96.8287)  time: 0.3479  data: 0.0014  max mem: 2500
Train: Epoch[4/5]  [2100/3750]  eta: 0:14:27  Lr: 0.001875  Loss: -0.3537  Acc@1: 81.2500 (81.8003)  Acc@5: 100.0000 (96.8289)  time: 0.3486  data: 0.0014  max mem: 2500
Train: Epoch[4/5]  [2110/3750]  eta: 0:14:20  Lr: 0.001875  Loss: -1.1198  Acc@1: 87.5000 (81.8244)  Acc@5: 100.0000 (96.8410)  time: 0.3469  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2120/3750]  eta: 0:14:13  Lr: 0.001875  Loss: -1.2047  Acc@1: 87.5000 (81.8128)  Acc@5: 100.0000 (96.8500)  time: 0.3463  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2130/3750]  eta: 0:14:07  Lr: 0.001875  Loss: -0.9129  Acc@1: 81.2500 (81.7955)  Acc@5: 100.0000 (96.8471)  time: 0.3515  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2140/3750]  eta: 0:14:00  Lr: 0.001875  Loss: -1.2654  Acc@1: 81.2500 (81.8017)  Acc@5: 100.0000 (96.8473)  time: 0.3557  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [2150/3750]  eta: 0:13:54  Lr: 0.001875  Loss: -1.1183  Acc@1: 81.2500 (81.7904)  Acc@5: 100.0000 (96.8532)  time: 0.3561  data: 0.0025  max mem: 2500
Train: Epoch[4/5]  [2160/3750]  eta: 0:13:47  Lr: 0.001875  Loss: -0.9194  Acc@1: 81.2500 (81.7735)  Acc@5: 100.0000 (96.8591)  time: 0.3570  data: 0.0036  max mem: 2500
Train: Epoch[4/5]  [2170/3750]  eta: 0:13:41  Lr: 0.001875  Loss: -0.8961  Acc@1: 81.2500 (81.7740)  Acc@5: 100.0000 (96.8649)  time: 0.3606  data: 0.0039  max mem: 2500
Train: Epoch[4/5]  [2180/3750]  eta: 0:13:35  Lr: 0.001875  Loss: -0.5364  Acc@1: 81.2500 (81.7830)  Acc@5: 100.0000 (96.8736)  time: 0.3655  data: 0.0040  max mem: 2500
Train: Epoch[4/5]  [2190/3750]  eta: 0:13:28  Lr: 0.001875  Loss: -1.1661  Acc@1: 87.5000 (81.7920)  Acc@5: 100.0000 (96.8793)  time: 0.3629  data: 0.0027  max mem: 2500
Train: Epoch[4/5]  [2200/3750]  eta: 0:13:22  Lr: 0.001875  Loss: -1.0419  Acc@1: 81.2500 (81.7697)  Acc@5: 100.0000 (96.8736)  time: 0.3609  data: 0.0023  max mem: 2500
Train: Epoch[4/5]  [2210/3750]  eta: 0:13:16  Lr: 0.001875  Loss: -0.7357  Acc@1: 81.2500 (81.7814)  Acc@5: 100.0000 (96.8736)  time: 0.3622  data: 0.0020  max mem: 2500
Train: Epoch[4/5]  [2220/3750]  eta: 0:13:10  Lr: 0.001875  Loss: -0.5793  Acc@1: 87.5000 (81.7903)  Acc@5: 100.0000 (96.8736)  time: 0.3563  data: 0.0011  max mem: 2500
Train: Epoch[4/5]  [2230/3750]  eta: 0:13:03  Lr: 0.001875  Loss: -1.2475  Acc@1: 81.2500 (81.7991)  Acc@5: 100.0000 (96.8736)  time: 0.3499  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [2240/3750]  eta: 0:12:57  Lr: 0.001875  Loss: -1.3969  Acc@1: 81.2500 (81.7883)  Acc@5: 100.0000 (96.8708)  time: 0.3491  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [2250/3750]  eta: 0:12:51  Lr: 0.001875  Loss: -1.2917  Acc@1: 81.2500 (81.7970)  Acc@5: 100.0000 (96.8764)  time: 0.3482  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2260/3750]  eta: 0:12:45  Lr: 0.001875  Loss: -1.1688  Acc@1: 81.2500 (81.8029)  Acc@5: 100.0000 (96.8709)  time: 0.3477  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2270/3750]  eta: 0:12:38  Lr: 0.001875  Loss: -0.6331  Acc@1: 81.2500 (81.7812)  Acc@5: 93.7500 (96.8626)  time: 0.3476  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [2280/3750]  eta: 0:12:32  Lr: 0.001875  Loss: -0.9203  Acc@1: 81.2500 (81.7953)  Acc@5: 93.7500 (96.8654)  time: 0.3462  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [2290/3750]  eta: 0:12:26  Lr: 0.001875  Loss: -0.8295  Acc@1: 81.2500 (81.7765)  Acc@5: 100.0000 (96.8600)  time: 0.3451  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [2300/3750]  eta: 0:12:20  Lr: 0.001875  Loss: -0.9781  Acc@1: 75.0000 (81.7715)  Acc@5: 100.0000 (96.8546)  time: 0.3447  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [2310/3750]  eta: 0:12:14  Lr: 0.001875  Loss: -1.0098  Acc@1: 81.2500 (81.7530)  Acc@5: 100.0000 (96.8547)  time: 0.3459  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [2320/3750]  eta: 0:12:08  Lr: 0.001875  Loss: -1.2115  Acc@1: 81.2500 (81.7751)  Acc@5: 100.0000 (96.8467)  time: 0.3506  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [2330/3750]  eta: 0:12:02  Lr: 0.001875  Loss: -0.6944  Acc@1: 87.5000 (81.7621)  Acc@5: 93.7500 (96.8468)  time: 0.3540  data: 0.0011  max mem: 2500
Train: Epoch[4/5]  [2340/3750]  eta: 0:11:56  Lr: 0.001875  Loss: -1.0935  Acc@1: 81.2500 (81.7653)  Acc@5: 100.0000 (96.8443)  time: 0.3556  data: 0.0014  max mem: 2500
Train: Epoch[4/5]  [2350/3750]  eta: 0:11:50  Lr: 0.001875  Loss: -0.8160  Acc@1: 81.2500 (81.7498)  Acc@5: 100.0000 (96.8471)  time: 0.3584  data: 0.0013  max mem: 2500
Train: Epoch[4/5]  [2360/3750]  eta: 0:11:44  Lr: 0.001875  Loss: -0.6276  Acc@1: 81.2500 (81.7503)  Acc@5: 100.0000 (96.8499)  time: 0.3614  data: 0.0016  max mem: 2500
Train: Epoch[4/5]  [2370/3750]  eta: 0:11:38  Lr: 0.001875  Loss: -1.3003  Acc@1: 81.2500 (81.7588)  Acc@5: 100.0000 (96.8579)  time: 0.3649  data: 0.0016  max mem: 2500
Train: Epoch[4/5]  [2380/3750]  eta: 0:11:32  Lr: 0.001875  Loss: -1.1482  Acc@1: 81.2500 (81.7697)  Acc@5: 100.0000 (96.8553)  time: 0.3604  data: 0.0011  max mem: 2500
Train: Epoch[4/5]  [2390/3750]  eta: 0:11:26  Lr: 0.001875  Loss: -0.6502  Acc@1: 81.2500 (81.7754)  Acc@5: 100.0000 (96.8528)  time: 0.3558  data: 0.0016  max mem: 2500
Train: Epoch[4/5]  [2400/3750]  eta: 0:11:20  Lr: 0.001875  Loss: -1.1180  Acc@1: 81.2500 (81.7732)  Acc@5: 100.0000 (96.8555)  time: 0.3559  data: 0.0015  max mem: 2500
Train: Epoch[4/5]  [2410/3750]  eta: 0:11:14  Lr: 0.001875  Loss: -1.0844  Acc@1: 75.0000 (81.7529)  Acc@5: 93.7500 (96.8400)  time: 0.3580  data: 0.0014  max mem: 2500
Train: Epoch[4/5]  [2420/3750]  eta: 0:11:08  Lr: 0.001875  Loss: -1.2005  Acc@1: 75.0000 (81.7560)  Acc@5: 93.7500 (96.8427)  time: 0.3540  data: 0.0010  max mem: 2500
Train: Epoch[4/5]  [2430/3750]  eta: 0:11:02  Lr: 0.001875  Loss: -0.7316  Acc@1: 81.2500 (81.7590)  Acc@5: 100.0000 (96.8377)  time: 0.3485  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2440/3750]  eta: 0:10:57  Lr: 0.001875  Loss: -1.1583  Acc@1: 81.2500 (81.7800)  Acc@5: 100.0000 (96.8404)  time: 0.3491  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2450/3750]  eta: 0:10:51  Lr: 0.001875  Loss: -1.1245  Acc@1: 87.5000 (81.7855)  Acc@5: 100.0000 (96.8380)  time: 0.3483  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2460/3750]  eta: 0:10:45  Lr: 0.001875  Loss: -1.0173  Acc@1: 87.5000 (81.8113)  Acc@5: 100.0000 (96.8407)  time: 0.3485  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2470/3750]  eta: 0:10:39  Lr: 0.001875  Loss: -1.1825  Acc@1: 87.5000 (81.8343)  Acc@5: 100.0000 (96.8459)  time: 0.3466  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [2480/3750]  eta: 0:10:33  Lr: 0.001875  Loss: -1.3801  Acc@1: 87.5000 (81.8445)  Acc@5: 100.0000 (96.8485)  time: 0.3454  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [2490/3750]  eta: 0:10:28  Lr: 0.001875  Loss: -0.9658  Acc@1: 87.5000 (81.8446)  Acc@5: 93.7500 (96.8436)  time: 0.3463  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2500/3750]  eta: 0:10:22  Lr: 0.001875  Loss: -0.9270  Acc@1: 81.2500 (81.8348)  Acc@5: 100.0000 (96.8488)  time: 0.3457  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2510/3750]  eta: 0:10:16  Lr: 0.001875  Loss: -1.3908  Acc@1: 81.2500 (81.8474)  Acc@5: 100.0000 (96.8439)  time: 0.3484  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [2520/3750]  eta: 0:10:11  Lr: 0.001875  Loss: -0.9049  Acc@1: 81.2500 (81.8301)  Acc@5: 100.0000 (96.8440)  time: 0.3558  data: 0.0015  max mem: 2500
Train: Epoch[4/5]  [2530/3750]  eta: 0:10:05  Lr: 0.001875  Loss: -1.0763  Acc@1: 81.2500 (81.8377)  Acc@5: 100.0000 (96.8466)  time: 0.3582  data: 0.0014  max mem: 2500
Train: Epoch[4/5]  [2540/3750]  eta: 0:09:59  Lr: 0.001875  Loss: -1.2230  Acc@1: 81.2500 (81.8280)  Acc@5: 100.0000 (96.8418)  time: 0.3571  data: 0.0011  max mem: 2500
Train: Epoch[4/5]  [2550/3750]  eta: 0:09:54  Lr: 0.001875  Loss: -0.6001  Acc@1: 81.2500 (81.8307)  Acc@5: 93.7500 (96.8346)  time: 0.3628  data: 0.0047  max mem: 2500
Train: Epoch[4/5]  [2560/3750]  eta: 0:09:48  Lr: 0.001875  Loss: -0.7871  Acc@1: 81.2500 (81.8162)  Acc@5: 100.0000 (96.8396)  time: 0.3680  data: 0.0068  max mem: 2500
Train: Epoch[4/5]  [2570/3750]  eta: 0:09:43  Lr: 0.001875  Loss: -1.1079  Acc@1: 81.2500 (81.8140)  Acc@5: 100.0000 (96.8373)  time: 0.3615  data: 0.0032  max mem: 2500
Train: Epoch[4/5]  [2580/3750]  eta: 0:09:37  Lr: 0.001875  Loss: -0.8399  Acc@1: 81.2500 (81.8191)  Acc@5: 100.0000 (96.8423)  time: 0.3576  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [2590/3750]  eta: 0:09:31  Lr: 0.001875  Loss: -1.0701  Acc@1: 81.2500 (81.8072)  Acc@5: 100.0000 (96.8400)  time: 0.3595  data: 0.0009  max mem: 2500
Train: Epoch[4/5]  [2600/3750]  eta: 0:09:26  Lr: 0.001875  Loss: -0.7478  Acc@1: 81.2500 (81.8147)  Acc@5: 100.0000 (96.8498)  time: 0.3581  data: 0.0011  max mem: 2500
Train: Epoch[4/5]  [2610/3750]  eta: 0:09:20  Lr: 0.001875  Loss: -0.8846  Acc@1: 81.2500 (81.8029)  Acc@5: 100.0000 (96.8499)  time: 0.3528  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [2620/3750]  eta: 0:09:15  Lr: 0.001875  Loss: -1.0250  Acc@1: 75.0000 (81.7508)  Acc@5: 93.7500 (96.8404)  time: 0.3507  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2630/3750]  eta: 0:09:09  Lr: 0.001875  Loss: -1.4109  Acc@1: 75.0000 (81.7536)  Acc@5: 93.7500 (96.8311)  time: 0.3503  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2640/3750]  eta: 0:09:04  Lr: 0.001875  Loss: -0.7762  Acc@1: 81.2500 (81.7588)  Acc@5: 93.7500 (96.8265)  time: 0.3476  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2650/3750]  eta: 0:08:58  Lr: 0.001875  Loss: -0.7671  Acc@1: 81.2500 (81.7687)  Acc@5: 93.7500 (96.8267)  time: 0.3482  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2660/3750]  eta: 0:08:53  Lr: 0.001875  Loss: -1.1874  Acc@1: 87.5000 (81.7855)  Acc@5: 100.0000 (96.8339)  time: 0.3480  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2670/3750]  eta: 0:08:47  Lr: 0.001875  Loss: -0.9491  Acc@1: 87.5000 (81.7929)  Acc@5: 100.0000 (96.8411)  time: 0.3460  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2680/3750]  eta: 0:08:42  Lr: 0.001875  Loss: -0.7709  Acc@1: 87.5000 (81.8025)  Acc@5: 100.0000 (96.8459)  time: 0.3454  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [2690/3750]  eta: 0:08:36  Lr: 0.001875  Loss: -0.8711  Acc@1: 81.2500 (81.8144)  Acc@5: 100.0000 (96.8460)  time: 0.3482  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2700/3750]  eta: 0:08:31  Lr: 0.001875  Loss: -1.1716  Acc@1: 87.5000 (81.8377)  Acc@5: 100.0000 (96.8507)  time: 0.3515  data: 0.0012  max mem: 2500
Train: Epoch[4/5]  [2710/3750]  eta: 0:08:26  Lr: 0.001875  Loss: -0.5631  Acc@1: 87.5000 (81.8517)  Acc@5: 100.0000 (96.8554)  time: 0.3499  data: 0.0011  max mem: 2500
Train: Epoch[4/5]  [2720/3750]  eta: 0:08:20  Lr: 0.001875  Loss: -0.6007  Acc@1: 81.2500 (81.8380)  Acc@5: 100.0000 (96.8486)  time: 0.3481  data: 0.0012  max mem: 2500
Train: Epoch[4/5]  [2730/3750]  eta: 0:08:15  Lr: 0.001875  Loss: -1.1439  Acc@1: 75.0000 (81.8153)  Acc@5: 93.7500 (96.8441)  time: 0.3517  data: 0.0023  max mem: 2500
Train: Epoch[4/5]  [2740/3750]  eta: 0:08:10  Lr: 0.001875  Loss: -0.9956  Acc@1: 81.2500 (81.8200)  Acc@5: 93.7500 (96.8488)  time: 0.3539  data: 0.0025  max mem: 2500
Train: Epoch[4/5]  [2750/3750]  eta: 0:08:04  Lr: 0.001875  Loss: -1.1890  Acc@1: 81.2500 (81.7998)  Acc@5: 100.0000 (96.8489)  time: 0.3513  data: 0.0015  max mem: 2500
Train: Epoch[4/5]  [2760/3750]  eta: 0:07:59  Lr: 0.001875  Loss: -0.9903  Acc@1: 75.0000 (81.8001)  Acc@5: 100.0000 (96.8490)  time: 0.3510  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [2770/3750]  eta: 0:07:54  Lr: 0.001875  Loss: -1.0621  Acc@1: 81.2500 (81.7958)  Acc@5: 100.0000 (96.8513)  time: 0.3510  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [2780/3750]  eta: 0:07:48  Lr: 0.001875  Loss: -1.2353  Acc@1: 81.2500 (81.8118)  Acc@5: 100.0000 (96.8514)  time: 0.3520  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [2790/3750]  eta: 0:07:43  Lr: 0.001875  Loss: -1.3421  Acc@1: 87.5000 (81.8143)  Acc@5: 93.7500 (96.8515)  time: 0.3574  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [2800/3750]  eta: 0:07:38  Lr: 0.001875  Loss: -1.2791  Acc@1: 87.5000 (81.8368)  Acc@5: 100.0000 (96.8605)  time: 0.3550  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [2810/3750]  eta: 0:07:33  Lr: 0.001875  Loss: -0.4219  Acc@1: 87.5000 (81.8303)  Acc@5: 100.0000 (96.8605)  time: 0.3490  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [2820/3750]  eta: 0:07:27  Lr: 0.001875  Loss: -0.5030  Acc@1: 81.2500 (81.8172)  Acc@5: 100.0000 (96.8606)  time: 0.3503  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2830/3750]  eta: 0:07:22  Lr: 0.001875  Loss: -0.7080  Acc@1: 81.2500 (81.8196)  Acc@5: 100.0000 (96.8562)  time: 0.3508  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [2840/3750]  eta: 0:07:17  Lr: 0.001875  Loss: -1.1782  Acc@1: 87.5000 (81.8308)  Acc@5: 93.7500 (96.8519)  time: 0.3481  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2850/3750]  eta: 0:07:12  Lr: 0.001875  Loss: -0.8210  Acc@1: 81.2500 (81.8375)  Acc@5: 100.0000 (96.8476)  time: 0.3468  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [2860/3750]  eta: 0:07:06  Lr: 0.001875  Loss: -0.8296  Acc@1: 81.2500 (81.8486)  Acc@5: 93.7500 (96.8368)  time: 0.3467  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2870/3750]  eta: 0:07:01  Lr: 0.001875  Loss: -1.0475  Acc@1: 81.2500 (81.8400)  Acc@5: 100.0000 (96.8369)  time: 0.3472  data: 0.0014  max mem: 2500
Train: Epoch[4/5]  [2880/3750]  eta: 0:06:56  Lr: 0.001875  Loss: -0.5186  Acc@1: 81.2500 (81.8422)  Acc@5: 100.0000 (96.8327)  time: 0.3474  data: 0.0013  max mem: 2500
Train: Epoch[4/5]  [2890/3750]  eta: 0:06:51  Lr: 0.001875  Loss: -0.9667  Acc@1: 81.2500 (81.8467)  Acc@5: 100.0000 (96.8372)  time: 0.3474  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [2900/3750]  eta: 0:06:46  Lr: 0.001875  Loss: -0.7751  Acc@1: 81.2500 (81.8231)  Acc@5: 93.7500 (96.8265)  time: 0.3494  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2910/3750]  eta: 0:06:40  Lr: 0.001875  Loss: -1.4196  Acc@1: 75.0000 (81.8168)  Acc@5: 93.7500 (96.8310)  time: 0.3529  data: 0.0010  max mem: 2500
Train: Epoch[4/5]  [2920/3750]  eta: 0:06:35  Lr: 0.001875  Loss: -0.8887  Acc@1: 75.0000 (81.7956)  Acc@5: 100.0000 (96.8269)  time: 0.3529  data: 0.0018  max mem: 2500
Train: Epoch[4/5]  [2930/3750]  eta: 0:06:30  Lr: 0.001875  Loss: -1.4443  Acc@1: 75.0000 (81.7980)  Acc@5: 100.0000 (96.8313)  time: 0.3504  data: 0.0013  max mem: 2500
Train: Epoch[4/5]  [2940/3750]  eta: 0:06:25  Lr: 0.001875  Loss: -1.2873  Acc@1: 81.2500 (81.8025)  Acc@5: 100.0000 (96.8357)  time: 0.3522  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [2950/3750]  eta: 0:06:20  Lr: 0.001875  Loss: -1.1372  Acc@1: 81.2500 (81.8049)  Acc@5: 100.0000 (96.8422)  time: 0.3526  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [2960/3750]  eta: 0:06:15  Lr: 0.001875  Loss: -0.9059  Acc@1: 81.2500 (81.7967)  Acc@5: 100.0000 (96.8423)  time: 0.3514  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2970/3750]  eta: 0:06:10  Lr: 0.001875  Loss: -1.0186  Acc@1: 81.2500 (81.7843)  Acc@5: 93.7500 (96.8382)  time: 0.3517  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2980/3750]  eta: 0:06:05  Lr: 0.001875  Loss: -1.1124  Acc@1: 75.0000 (81.7783)  Acc@5: 100.0000 (96.8446)  time: 0.3520  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2990/3750]  eta: 0:06:00  Lr: 0.001875  Loss: -0.9392  Acc@1: 75.0000 (81.7787)  Acc@5: 100.0000 (96.8447)  time: 0.3501  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3000/3750]  eta: 0:05:55  Lr: 0.001875  Loss: -0.3999  Acc@1: 75.0000 (81.7665)  Acc@5: 100.0000 (96.8490)  time: 0.3478  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [3010/3750]  eta: 0:05:50  Lr: 0.001875  Loss: -0.5742  Acc@1: 75.0000 (81.7627)  Acc@5: 100.0000 (96.8511)  time: 0.3506  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [3020/3750]  eta: 0:05:45  Lr: 0.001875  Loss: -0.8675  Acc@1: 81.2500 (81.7693)  Acc@5: 93.7500 (96.8429)  time: 0.3501  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [3030/3750]  eta: 0:05:40  Lr: 0.001875  Loss: -0.9018  Acc@1: 81.2500 (81.7696)  Acc@5: 100.0000 (96.8492)  time: 0.3476  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3040/3750]  eta: 0:05:35  Lr: 0.001875  Loss: -0.7988  Acc@1: 81.2500 (81.7782)  Acc@5: 100.0000 (96.8493)  time: 0.3466  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [3050/3750]  eta: 0:05:30  Lr: 0.001875  Loss: -0.4944  Acc@1: 81.2500 (81.7724)  Acc@5: 100.0000 (96.8514)  time: 0.3483  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3060/3750]  eta: 0:05:25  Lr: 0.001875  Loss: -0.7968  Acc@1: 87.5000 (81.7911)  Acc@5: 100.0000 (96.8556)  time: 0.3491  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3070/3750]  eta: 0:05:20  Lr: 0.001875  Loss: -0.9020  Acc@1: 87.5000 (81.7995)  Acc@5: 100.0000 (96.8557)  time: 0.3459  data: 0.0002  max mem: 2500
Train: Epoch[4/5]  [3080/3750]  eta: 0:05:15  Lr: 0.001875  Loss: -0.8374  Acc@1: 87.5000 (81.8139)  Acc@5: 100.0000 (96.8618)  time: 0.3468  data: 0.0013  max mem: 2500
Train: Epoch[4/5]  [3090/3750]  eta: 0:05:10  Lr: 0.001875  Loss: -0.8673  Acc@1: 87.5000 (81.8162)  Acc@5: 100.0000 (96.8598)  time: 0.3523  data: 0.0031  max mem: 2500
Train: Epoch[4/5]  [3100/3750]  eta: 0:05:05  Lr: 0.001875  Loss: -1.2586  Acc@1: 87.5000 (81.8305)  Acc@5: 100.0000 (96.8659)  time: 0.3531  data: 0.0035  max mem: 2500
Train: Epoch[4/5]  [3110/3750]  eta: 0:05:00  Lr: 0.001875  Loss: -0.3489  Acc@1: 87.5000 (81.8406)  Acc@5: 100.0000 (96.8700)  time: 0.3519  data: 0.0019  max mem: 2500
Train: Epoch[4/5]  [3120/3750]  eta: 0:04:55  Lr: 0.001875  Loss: -1.0929  Acc@1: 87.5000 (81.8327)  Acc@5: 100.0000 (96.8640)  time: 0.3521  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [3130/3750]  eta: 0:04:50  Lr: 0.001875  Loss: -0.7787  Acc@1: 81.2500 (81.8309)  Acc@5: 100.0000 (96.8680)  time: 0.3529  data: 0.0011  max mem: 2500
Train: Epoch[4/5]  [3140/3750]  eta: 0:04:45  Lr: 0.001875  Loss: -0.9128  Acc@1: 81.2500 (81.8191)  Acc@5: 100.0000 (96.8581)  time: 0.3526  data: 0.0016  max mem: 2500
Train: Epoch[4/5]  [3150/3750]  eta: 0:04:40  Lr: 0.001875  Loss: -0.6077  Acc@1: 81.2500 (81.8292)  Acc@5: 100.0000 (96.8581)  time: 0.3499  data: 0.0011  max mem: 2500
Train: Epoch[4/5]  [3160/3750]  eta: 0:04:35  Lr: 0.001875  Loss: -1.1734  Acc@1: 81.2500 (81.8273)  Acc@5: 100.0000 (96.8621)  time: 0.3495  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [3170/3750]  eta: 0:04:30  Lr: 0.001875  Loss: -0.4327  Acc@1: 81.2500 (81.8196)  Acc@5: 100.0000 (96.8661)  time: 0.3510  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [3180/3750]  eta: 0:04:25  Lr: 0.001875  Loss: -1.0242  Acc@1: 81.2500 (81.8335)  Acc@5: 100.0000 (96.8681)  time: 0.3502  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [3190/3750]  eta: 0:04:21  Lr: 0.001875  Loss: -1.1089  Acc@1: 87.5000 (81.8474)  Acc@5: 100.0000 (96.8701)  time: 0.3482  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [3200/3750]  eta: 0:04:16  Lr: 0.001875  Loss: -0.8723  Acc@1: 81.2500 (81.8592)  Acc@5: 100.0000 (96.8662)  time: 0.3487  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3210/3750]  eta: 0:04:11  Lr: 0.001875  Loss: -1.0634  Acc@1: 87.5000 (81.8709)  Acc@5: 100.0000 (96.8682)  time: 0.3482  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3220/3750]  eta: 0:04:06  Lr: 0.001875  Loss: -0.9075  Acc@1: 81.2500 (81.8709)  Acc@5: 100.0000 (96.8624)  time: 0.3477  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3230/3750]  eta: 0:04:01  Lr: 0.001875  Loss: -0.9080  Acc@1: 81.2500 (81.8787)  Acc@5: 100.0000 (96.8702)  time: 0.3475  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3240/3750]  eta: 0:03:56  Lr: 0.001875  Loss: -1.0492  Acc@1: 81.2500 (81.8690)  Acc@5: 100.0000 (96.8683)  time: 0.3461  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [3250/3750]  eta: 0:03:52  Lr: 0.001875  Loss: -0.9818  Acc@1: 81.2500 (81.8671)  Acc@5: 100.0000 (96.8740)  time: 0.3463  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3260/3750]  eta: 0:03:47  Lr: 0.001875  Loss: -0.9652  Acc@1: 81.2500 (81.8710)  Acc@5: 100.0000 (96.8740)  time: 0.3492  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [3270/3750]  eta: 0:03:42  Lr: 0.001875  Loss: -0.3613  Acc@1: 81.2500 (81.8633)  Acc@5: 93.7500 (96.8721)  time: 0.3530  data: 0.0022  max mem: 2500
Train: Epoch[4/5]  [3280/3750]  eta: 0:03:37  Lr: 0.001875  Loss: -1.2146  Acc@1: 81.2500 (81.8672)  Acc@5: 100.0000 (96.8760)  time: 0.3564  data: 0.0022  max mem: 2500
Train: Epoch[4/5]  [3290/3750]  eta: 0:03:32  Lr: 0.001875  Loss: -0.8422  Acc@1: 81.2500 (81.8577)  Acc@5: 100.0000 (96.8703)  time: 0.3541  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [3300/3750]  eta: 0:03:28  Lr: 0.001875  Loss: -1.3918  Acc@1: 81.2500 (81.8578)  Acc@5: 93.7500 (96.8665)  time: 0.3498  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [3310/3750]  eta: 0:03:23  Lr: 0.001875  Loss: -0.9993  Acc@1: 81.2500 (81.8616)  Acc@5: 100.0000 (96.8665)  time: 0.3541  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [3320/3750]  eta: 0:03:18  Lr: 0.001875  Loss: -1.0785  Acc@1: 81.2500 (81.8729)  Acc@5: 100.0000 (96.8722)  time: 0.3575  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [3330/3750]  eta: 0:03:13  Lr: 0.001875  Loss: -1.2165  Acc@1: 81.2500 (81.8711)  Acc@5: 100.0000 (96.8666)  time: 0.3530  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [3340/3750]  eta: 0:03:09  Lr: 0.001875  Loss: -0.6823  Acc@1: 81.2500 (81.8561)  Acc@5: 93.7500 (96.8666)  time: 0.3498  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [3350/3750]  eta: 0:03:04  Lr: 0.001875  Loss: -1.3270  Acc@1: 81.2500 (81.8748)  Acc@5: 100.0000 (96.8685)  time: 0.3516  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [3360/3750]  eta: 0:02:59  Lr: 0.001875  Loss: -1.2851  Acc@1: 87.5000 (81.8804)  Acc@5: 93.7500 (96.8648)  time: 0.3555  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [3370/3750]  eta: 0:02:54  Lr: 0.001875  Loss: -1.1964  Acc@1: 81.2500 (81.8915)  Acc@5: 100.0000 (96.8704)  time: 0.3533  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [3380/3750]  eta: 0:02:50  Lr: 0.001875  Loss: -0.9094  Acc@1: 81.2500 (81.8970)  Acc@5: 100.0000 (96.8648)  time: 0.3477  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3390/3750]  eta: 0:02:45  Lr: 0.001875  Loss: -1.2125  Acc@1: 87.5000 (81.9025)  Acc@5: 100.0000 (96.8649)  time: 0.3471  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [3400/3750]  eta: 0:02:40  Lr: 0.001875  Loss: -0.8847  Acc@1: 87.5000 (81.9189)  Acc@5: 100.0000 (96.8631)  time: 0.3483  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [3410/3750]  eta: 0:02:35  Lr: 0.001875  Loss: -0.5237  Acc@1: 87.5000 (81.9115)  Acc@5: 93.7500 (96.8613)  time: 0.3486  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [3420/3750]  eta: 0:02:31  Lr: 0.001875  Loss: -1.0299  Acc@1: 75.0000 (81.8967)  Acc@5: 93.7500 (96.8522)  time: 0.3467  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3430/3750]  eta: 0:02:26  Lr: 0.001875  Loss: -0.7620  Acc@1: 81.2500 (81.8894)  Acc@5: 93.7500 (96.8504)  time: 0.3451  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3440/3750]  eta: 0:02:21  Lr: 0.001875  Loss: -1.2990  Acc@1: 81.2500 (81.9057)  Acc@5: 93.7500 (96.8505)  time: 0.3487  data: 0.0011  max mem: 2500
Train: Epoch[4/5]  [3450/3750]  eta: 0:02:17  Lr: 0.001875  Loss: -0.5788  Acc@1: 87.5000 (81.9129)  Acc@5: 100.0000 (96.8560)  time: 0.3507  data: 0.0024  max mem: 2500
Train: Epoch[4/5]  [3460/3750]  eta: 0:02:12  Lr: 0.001875  Loss: -1.0950  Acc@1: 87.5000 (81.9127)  Acc@5: 100.0000 (96.8560)  time: 0.3502  data: 0.0018  max mem: 2500
Train: Epoch[4/5]  [3470/3750]  eta: 0:02:07  Lr: 0.001875  Loss: -0.9059  Acc@1: 81.2500 (81.9144)  Acc@5: 100.0000 (96.8597)  time: 0.3495  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [3480/3750]  eta: 0:02:03  Lr: 0.001875  Loss: -1.1422  Acc@1: 81.2500 (81.9071)  Acc@5: 100.0000 (96.8561)  time: 0.3502  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [3490/3750]  eta: 0:01:58  Lr: 0.001875  Loss: -0.7769  Acc@1: 81.2500 (81.9124)  Acc@5: 100.0000 (96.8634)  time: 0.3540  data: 0.0021  max mem: 2500
Train: Epoch[4/5]  [3500/3750]  eta: 0:01:53  Lr: 0.001875  Loss: -1.2221  Acc@1: 81.2500 (81.9105)  Acc@5: 100.0000 (96.8705)  time: 0.3544  data: 0.0021  max mem: 2500
Train: Epoch[4/5]  [3510/3750]  eta: 0:01:49  Lr: 0.001875  Loss: -0.9038  Acc@1: 81.2500 (81.9104)  Acc@5: 100.0000 (96.8616)  time: 0.3516  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [3520/3750]  eta: 0:01:44  Lr: 0.001875  Loss: -1.0658  Acc@1: 81.2500 (81.9050)  Acc@5: 100.0000 (96.8652)  time: 0.3534  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [3530/3750]  eta: 0:01:40  Lr: 0.001875  Loss: -0.6777  Acc@1: 87.5000 (81.9191)  Acc@5: 100.0000 (96.8670)  time: 0.3596  data: 0.0016  max mem: 2500
Train: Epoch[4/5]  [3540/3750]  eta: 0:01:35  Lr: 0.001875  Loss: -1.2068  Acc@1: 81.2500 (81.9048)  Acc@5: 100.0000 (96.8653)  time: 0.3565  data: 0.0016  max mem: 2500
Train: Epoch[4/5]  [3550/3750]  eta: 0:01:30  Lr: 0.001875  Loss: -0.5809  Acc@1: 81.2500 (81.9047)  Acc@5: 100.0000 (96.8671)  time: 0.3488  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3560/3750]  eta: 0:01:26  Lr: 0.001875  Loss: -0.6007  Acc@1: 87.5000 (81.9047)  Acc@5: 100.0000 (96.8706)  time: 0.3472  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [3570/3750]  eta: 0:01:21  Lr: 0.001875  Loss: -1.2902  Acc@1: 87.5000 (81.9046)  Acc@5: 100.0000 (96.8636)  time: 0.3501  data: 0.0025  max mem: 2500
Train: Epoch[4/5]  [3580/3750]  eta: 0:01:17  Lr: 0.001875  Loss: -1.0907  Acc@1: 81.2500 (81.8958)  Acc@5: 93.7500 (96.8584)  time: 0.3509  data: 0.0027  max mem: 2500
Train: Epoch[4/5]  [3590/3750]  eta: 0:01:12  Lr: 0.001875  Loss: -0.8115  Acc@1: 81.2500 (81.8870)  Acc@5: 93.7500 (96.8602)  time: 0.3493  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [3600/3750]  eta: 0:01:07  Lr: 0.001875  Loss: -0.7668  Acc@1: 75.0000 (81.8887)  Acc@5: 93.7500 (96.8568)  time: 0.3483  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3610/3750]  eta: 0:01:03  Lr: 0.001875  Loss: -1.3496  Acc@1: 81.2500 (81.8904)  Acc@5: 100.0000 (96.8603)  time: 0.3476  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3620/3750]  eta: 0:00:58  Lr: 0.001875  Loss: -1.1766  Acc@1: 81.2500 (81.8990)  Acc@5: 100.0000 (96.8672)  time: 0.3479  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3630/3750]  eta: 0:00:54  Lr: 0.001875  Loss: -0.8155  Acc@1: 87.5000 (81.8972)  Acc@5: 100.0000 (96.8673)  time: 0.3463  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [3640/3750]  eta: 0:00:49  Lr: 0.001875  Loss: -0.9391  Acc@1: 75.0000 (81.8937)  Acc@5: 93.7500 (96.8604)  time: 0.3455  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [3650/3750]  eta: 0:00:45  Lr: 0.001875  Loss: -0.5036  Acc@1: 75.0000 (81.8851)  Acc@5: 93.7500 (96.8587)  time: 0.3470  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [3660/3750]  eta: 0:00:40  Lr: 0.001875  Loss: -1.1051  Acc@1: 81.2500 (81.8782)  Acc@5: 100.0000 (96.8554)  time: 0.3491  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [3670/3750]  eta: 0:00:36  Lr: 0.001875  Loss: -1.2322  Acc@1: 81.2500 (81.8663)  Acc@5: 100.0000 (96.8503)  time: 0.3494  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [3680/3750]  eta: 0:00:31  Lr: 0.001875  Loss: -0.5670  Acc@1: 81.2500 (81.8629)  Acc@5: 100.0000 (96.8436)  time: 0.3489  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [3690/3750]  eta: 0:00:27  Lr: 0.001875  Loss: -0.6343  Acc@1: 75.0000 (81.8444)  Acc@5: 93.7500 (96.8352)  time: 0.3512  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [3700/3750]  eta: 0:00:22  Lr: 0.001875  Loss: -0.6020  Acc@1: 81.2500 (81.8478)  Acc@5: 100.0000 (96.8370)  time: 0.3544  data: 0.0009  max mem: 2500
Train: Epoch[4/5]  [3710/3750]  eta: 0:00:17  Lr: 0.001875  Loss: -0.0319  Acc@1: 81.2500 (81.8496)  Acc@5: 100.0000 (96.8337)  time: 0.3525  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [3720/3750]  eta: 0:00:13  Lr: 0.001875  Loss: -1.2936  Acc@1: 81.2500 (81.8530)  Acc@5: 100.0000 (96.8322)  time: 0.3484  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3730/3750]  eta: 0:00:08  Lr: 0.001875  Loss: -0.9654  Acc@1: 87.5000 (81.8715)  Acc@5: 100.0000 (96.8356)  time: 0.3513  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3740/3750]  eta: 0:00:04  Lr: 0.001875  Loss: -1.1562  Acc@1: 87.5000 (81.8748)  Acc@5: 100.0000 (96.8391)  time: 0.3563  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [3749/3750]  eta: 0:00:00  Lr: 0.001875  Loss: -1.0165  Acc@1: 81.2500 (81.8700)  Acc@5: 100.0000 (96.8350)  time: 0.3551  data: 0.0008  max mem: 2500
Train: Epoch[4/5] Total time: 0:28:04 (0.4492 s / it)
{0: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 1: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 2: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 3: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 4: {0: 0, 1: 240000, 2: 0, 3: 0, 4: 0}, 5: {0: 0, 1: 240000, 2: 0, 3: 0, 4: 0}, 6: {0: 0, 1: 240000, 2: 0, 3: 0, 4: 0}, 7: {0: 0, 1: 240000, 2: 0, 3: 0, 4: 0}, 8: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 9: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 10: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 11: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 12: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 13: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 14: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 15: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 16: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 17: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 18: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 19: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}}
Averaged stats: Lr: 0.001875  Loss: -1.0165  Acc@1: 81.2500 (81.8700)  Acc@5: 100.0000 (96.8350)
Train: Epoch[5/5]  [   0/3750]  eta: 0:50:25  Lr: 0.001875  Loss: -0.9684  Acc@1: 81.2500 (81.2500)  Acc@5: 100.0000 (100.0000)  time: 0.8067  data: 0.4616  max mem: 2500
Train: Epoch[5/5]  [  10/3750]  eta: 0:24:25  Lr: 0.001875  Loss: -0.8403  Acc@1: 75.0000 (76.7045)  Acc@5: 100.0000 (96.0227)  time: 0.3919  data: 0.0423  max mem: 2500
Train: Epoch[5/5]  [  20/3750]  eta: 0:23:01  Lr: 0.001875  Loss: -1.3119  Acc@1: 81.2500 (80.9524)  Acc@5: 93.7500 (96.4286)  time: 0.3484  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [  30/3750]  eta: 0:22:30  Lr: 0.001875  Loss: -1.0893  Acc@1: 87.5000 (81.8548)  Acc@5: 93.7500 (95.7661)  time: 0.3471  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [  40/3750]  eta: 0:22:13  Lr: 0.001875  Loss: -0.9544  Acc@1: 87.5000 (82.3171)  Acc@5: 93.7500 (96.1890)  time: 0.3483  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [  50/3750]  eta: 0:22:01  Lr: 0.001875  Loss: -0.7353  Acc@1: 81.2500 (81.2500)  Acc@5: 100.0000 (96.0784)  time: 0.3483  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [  60/3750]  eta: 0:21:51  Lr: 0.001875  Loss: -1.1155  Acc@1: 81.2500 (80.8402)  Acc@5: 100.0000 (96.2090)  time: 0.3467  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [  70/3750]  eta: 0:21:42  Lr: 0.001875  Loss: -1.0717  Acc@1: 81.2500 (81.4261)  Acc@5: 100.0000 (96.3908)  time: 0.3455  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [  80/3750]  eta: 0:21:36  Lr: 0.001875  Loss: -1.4520  Acc@1: 81.2500 (81.6358)  Acc@5: 100.0000 (96.5278)  time: 0.3471  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [  90/3750]  eta: 0:21:30  Lr: 0.001875  Loss: -0.6736  Acc@1: 81.2500 (81.6621)  Acc@5: 100.0000 (96.4973)  time: 0.3484  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [ 100/3750]  eta: 0:21:25  Lr: 0.001875  Loss: -1.2622  Acc@1: 81.2500 (82.2401)  Acc@5: 100.0000 (96.5347)  time: 0.3479  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 110/3750]  eta: 0:21:21  Lr: 0.001875  Loss: -0.7389  Acc@1: 81.2500 (82.0383)  Acc@5: 93.7500 (96.5090)  time: 0.3494  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 120/3750]  eta: 0:21:18  Lr: 0.001875  Loss: -1.1931  Acc@1: 81.2500 (81.9215)  Acc@5: 100.0000 (96.6942)  time: 0.3523  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [ 130/3750]  eta: 0:21:15  Lr: 0.001875  Loss: -0.9335  Acc@1: 81.2500 (82.0134)  Acc@5: 100.0000 (96.7080)  time: 0.3533  data: 0.0011  max mem: 2500
Train: Epoch[5/5]  [ 140/3750]  eta: 0:21:11  Lr: 0.001875  Loss: -1.4849  Acc@1: 87.5000 (82.4025)  Acc@5: 100.0000 (96.7642)  time: 0.3521  data: 0.0010  max mem: 2500
Train: Epoch[5/5]  [ 150/3750]  eta: 0:21:06  Lr: 0.001875  Loss: -1.1705  Acc@1: 81.2500 (82.3262)  Acc@5: 100.0000 (96.8129)  time: 0.3494  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [ 160/3750]  eta: 0:21:03  Lr: 0.001875  Loss: -1.5253  Acc@1: 81.2500 (82.4146)  Acc@5: 100.0000 (96.8944)  time: 0.3500  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [ 170/3750]  eta: 0:21:00  Lr: 0.001875  Loss: -0.9603  Acc@1: 81.2500 (82.3465)  Acc@5: 100.0000 (97.0029)  time: 0.3540  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [ 180/3750]  eta: 0:20:57  Lr: 0.001875  Loss: -1.0499  Acc@1: 81.2500 (82.2169)  Acc@5: 100.0000 (97.0649)  time: 0.3541  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [ 190/3750]  eta: 0:20:52  Lr: 0.001875  Loss: -1.0877  Acc@1: 81.2500 (82.2644)  Acc@5: 100.0000 (97.1204)  time: 0.3502  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [ 200/3750]  eta: 0:20:48  Lr: 0.001875  Loss: -0.8254  Acc@1: 81.2500 (82.1517)  Acc@5: 100.0000 (97.1393)  time: 0.3486  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 210/3750]  eta: 0:20:44  Lr: 0.001875  Loss: -0.9679  Acc@1: 81.2500 (82.1090)  Acc@5: 100.0000 (97.1564)  time: 0.3492  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 220/3750]  eta: 0:20:40  Lr: 0.001875  Loss: -0.8909  Acc@1: 81.2500 (81.9287)  Acc@5: 93.7500 (96.9174)  time: 0.3488  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 230/3750]  eta: 0:20:36  Lr: 0.001875  Loss: -1.1706  Acc@1: 81.2500 (81.8994)  Acc@5: 93.7500 (96.9156)  time: 0.3472  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [ 240/3750]  eta: 0:20:32  Lr: 0.001875  Loss: -0.8631  Acc@1: 75.0000 (81.8205)  Acc@5: 100.0000 (96.9139)  time: 0.3455  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [ 250/3750]  eta: 0:20:28  Lr: 0.001875  Loss: -0.7716  Acc@1: 75.0000 (81.8476)  Acc@5: 100.0000 (96.9622)  time: 0.3459  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 260/3750]  eta: 0:20:23  Lr: 0.001875  Loss: -1.2477  Acc@1: 81.2500 (81.8966)  Acc@5: 100.0000 (97.0067)  time: 0.3460  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 270/3750]  eta: 0:20:19  Lr: 0.001875  Loss: -0.8899  Acc@1: 81.2500 (81.9649)  Acc@5: 100.0000 (96.9557)  time: 0.3457  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [ 280/3750]  eta: 0:20:16  Lr: 0.001875  Loss: -0.6998  Acc@1: 81.2500 (82.0285)  Acc@5: 100.0000 (96.9528)  time: 0.3484  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 290/3750]  eta: 0:20:12  Lr: 0.001875  Loss: -0.9767  Acc@1: 81.2500 (82.0232)  Acc@5: 100.0000 (96.9502)  time: 0.3502  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 300/3750]  eta: 0:20:09  Lr: 0.001875  Loss: -0.6300  Acc@1: 81.2500 (82.0183)  Acc@5: 93.7500 (96.8646)  time: 0.3524  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [ 310/3750]  eta: 0:20:06  Lr: 0.001875  Loss: -1.2744  Acc@1: 81.2500 (81.9735)  Acc@5: 93.7500 (96.8449)  time: 0.3542  data: 0.0013  max mem: 2500
Train: Epoch[5/5]  [ 320/3750]  eta: 0:20:03  Lr: 0.001875  Loss: -1.1117  Acc@1: 81.2500 (81.9509)  Acc@5: 100.0000 (96.8458)  time: 0.3527  data: 0.0012  max mem: 2500
Train: Epoch[5/5]  [ 330/3750]  eta: 0:19:59  Lr: 0.001875  Loss: -0.7546  Acc@1: 81.2500 (82.0053)  Acc@5: 100.0000 (96.8467)  time: 0.3530  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [ 340/3750]  eta: 0:19:56  Lr: 0.001875  Loss: -1.1622  Acc@1: 81.2500 (81.9648)  Acc@5: 100.0000 (96.8658)  time: 0.3521  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [ 350/3750]  eta: 0:19:53  Lr: 0.001875  Loss: -0.9268  Acc@1: 81.2500 (81.9444)  Acc@5: 100.0000 (96.8305)  time: 0.3556  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [ 360/3750]  eta: 0:19:50  Lr: 0.001875  Loss: -0.9919  Acc@1: 81.2500 (81.9079)  Acc@5: 93.7500 (96.7798)  time: 0.3574  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [ 370/3750]  eta: 0:19:46  Lr: 0.001875  Loss: -0.4084  Acc@1: 81.2500 (81.8565)  Acc@5: 100.0000 (96.7992)  time: 0.3501  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 380/3750]  eta: 0:19:42  Lr: 0.001875  Loss: -0.5319  Acc@1: 81.2500 (81.8570)  Acc@5: 100.0000 (96.7848)  time: 0.3465  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 390/3750]  eta: 0:19:39  Lr: 0.001875  Loss: -0.4127  Acc@1: 81.2500 (81.7615)  Acc@5: 100.0000 (96.8031)  time: 0.3502  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [ 400/3750]  eta: 0:19:35  Lr: 0.001875  Loss: -1.2334  Acc@1: 81.2500 (81.8734)  Acc@5: 100.0000 (96.8049)  time: 0.3514  data: 0.0013  max mem: 2500
Train: Epoch[5/5]  [ 410/3750]  eta: 0:19:31  Lr: 0.001875  Loss: -1.2336  Acc@1: 87.5000 (81.9647)  Acc@5: 100.0000 (96.8066)  time: 0.3485  data: 0.0011  max mem: 2500
Train: Epoch[5/5]  [ 420/3750]  eta: 0:19:27  Lr: 0.001875  Loss: -0.9081  Acc@1: 87.5000 (82.0665)  Acc@5: 100.0000 (96.8527)  time: 0.3463  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [ 430/3750]  eta: 0:19:24  Lr: 0.001875  Loss: -0.8290  Acc@1: 81.2500 (82.0621)  Acc@5: 100.0000 (96.8823)  time: 0.3453  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [ 440/3750]  eta: 0:19:20  Lr: 0.001875  Loss: -1.1127  Acc@1: 81.2500 (81.9870)  Acc@5: 100.0000 (96.8254)  time: 0.3467  data: 0.0010  max mem: 2500
Train: Epoch[5/5]  [ 450/3750]  eta: 0:19:16  Lr: 0.001875  Loss: -1.0006  Acc@1: 81.2500 (82.0261)  Acc@5: 93.7500 (96.7988)  time: 0.3459  data: 0.0010  max mem: 2500
Train: Epoch[5/5]  [ 460/3750]  eta: 0:19:12  Lr: 0.001875  Loss: -1.0791  Acc@1: 87.5000 (82.1041)  Acc@5: 93.7500 (96.8140)  time: 0.3463  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 470/3750]  eta: 0:19:09  Lr: 0.001875  Loss: -0.8286  Acc@1: 81.2500 (82.1391)  Acc@5: 93.7500 (96.7887)  time: 0.3519  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [ 480/3750]  eta: 0:19:06  Lr: 0.001875  Loss: -1.0978  Acc@1: 81.2500 (82.2245)  Acc@5: 100.0000 (96.8295)  time: 0.3562  data: 0.0012  max mem: 2500
Train: Epoch[5/5]  [ 490/3750]  eta: 0:19:03  Lr: 0.001875  Loss: -0.5767  Acc@1: 87.5000 (82.3320)  Acc@5: 100.0000 (96.8686)  time: 0.3544  data: 0.0011  max mem: 2500
Train: Epoch[5/5]  [ 500/3750]  eta: 0:18:59  Lr: 0.001875  Loss: -0.7251  Acc@1: 81.2500 (82.2106)  Acc@5: 100.0000 (96.8812)  time: 0.3496  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [ 510/3750]  eta: 0:18:56  Lr: 0.001875  Loss: -0.9981  Acc@1: 81.2500 (82.2652)  Acc@5: 100.0000 (96.9056)  time: 0.3501  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [ 520/3750]  eta: 0:18:52  Lr: 0.001875  Loss: -1.5453  Acc@1: 87.5000 (82.3776)  Acc@5: 100.0000 (96.8810)  time: 0.3543  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 530/3750]  eta: 0:18:49  Lr: 0.001875  Loss: -0.6870  Acc@1: 81.2500 (82.4153)  Acc@5: 100.0000 (96.9044)  time: 0.3559  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [ 540/3750]  eta: 0:18:46  Lr: 0.001875  Loss: -1.3198  Acc@1: 81.2500 (82.4053)  Acc@5: 100.0000 (96.8923)  time: 0.3543  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [ 550/3750]  eta: 0:18:42  Lr: 0.001875  Loss: -0.8448  Acc@1: 75.0000 (82.3503)  Acc@5: 93.7500 (96.8126)  time: 0.3499  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [ 560/3750]  eta: 0:18:38  Lr: 0.001875  Loss: -1.3593  Acc@1: 81.2500 (82.2861)  Acc@5: 93.7500 (96.8249)  time: 0.3482  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [ 570/3750]  eta: 0:18:35  Lr: 0.001875  Loss: -0.6863  Acc@1: 81.2500 (82.1804)  Acc@5: 100.0000 (96.8148)  time: 0.3505  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [ 580/3750]  eta: 0:18:31  Lr: 0.001875  Loss: -0.9206  Acc@1: 75.0000 (82.1429)  Acc@5: 100.0000 (96.8158)  time: 0.3497  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 590/3750]  eta: 0:18:28  Lr: 0.001875  Loss: -0.7140  Acc@1: 81.2500 (82.1912)  Acc@5: 93.7500 (96.7851)  time: 0.3482  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 600/3750]  eta: 0:18:24  Lr: 0.001875  Loss: -1.0147  Acc@1: 81.2500 (82.1443)  Acc@5: 100.0000 (96.8074)  time: 0.3468  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 610/3750]  eta: 0:18:20  Lr: 0.001875  Loss: -0.7327  Acc@1: 81.2500 (82.1604)  Acc@5: 100.0000 (96.8187)  time: 0.3456  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [ 620/3750]  eta: 0:18:16  Lr: 0.001875  Loss: -1.1130  Acc@1: 81.2500 (82.1659)  Acc@5: 100.0000 (96.8297)  time: 0.3466  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 630/3750]  eta: 0:18:13  Lr: 0.001875  Loss: -0.9233  Acc@1: 81.2500 (82.1613)  Acc@5: 93.7500 (96.7908)  time: 0.3463  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [ 640/3750]  eta: 0:18:09  Lr: 0.001875  Loss: -1.2231  Acc@1: 81.2500 (82.2153)  Acc@5: 93.7500 (96.7921)  time: 0.3474  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [ 650/3750]  eta: 0:18:06  Lr: 0.001875  Loss: -0.7699  Acc@1: 81.2500 (82.2101)  Acc@5: 93.7500 (96.7742)  time: 0.3504  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 660/3750]  eta: 0:18:02  Lr: 0.001875  Loss: -1.0269  Acc@1: 81.2500 (82.2523)  Acc@5: 100.0000 (96.7757)  time: 0.3500  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 670/3750]  eta: 0:17:59  Lr: 0.001875  Loss: -1.3300  Acc@1: 81.2500 (82.2653)  Acc@5: 100.0000 (96.7586)  time: 0.3499  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [ 680/3750]  eta: 0:17:55  Lr: 0.001875  Loss: -1.0578  Acc@1: 81.2500 (82.2595)  Acc@5: 93.7500 (96.7419)  time: 0.3515  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [ 690/3750]  eta: 0:17:52  Lr: 0.001875  Loss: -1.0798  Acc@1: 81.2500 (82.2268)  Acc@5: 100.0000 (96.7619)  time: 0.3544  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [ 700/3750]  eta: 0:17:49  Lr: 0.001875  Loss: -1.1123  Acc@1: 81.2500 (82.1416)  Acc@5: 93.7500 (96.7190)  time: 0.3558  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [ 710/3750]  eta: 0:17:45  Lr: 0.001875  Loss: -0.6693  Acc@1: 75.0000 (82.1290)  Acc@5: 93.7500 (96.7124)  time: 0.3508  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [ 720/3750]  eta: 0:17:42  Lr: 0.001875  Loss: -1.2515  Acc@1: 87.5000 (82.1949)  Acc@5: 100.0000 (96.7406)  time: 0.3509  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [ 730/3750]  eta: 0:17:38  Lr: 0.001875  Loss: -1.2679  Acc@1: 87.5000 (82.2161)  Acc@5: 100.0000 (96.7339)  time: 0.3529  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [ 740/3750]  eta: 0:17:35  Lr: 0.001875  Loss: -0.8301  Acc@1: 81.2500 (82.2200)  Acc@5: 100.0000 (96.7527)  time: 0.3507  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 750/3750]  eta: 0:17:31  Lr: 0.001875  Loss: -0.8265  Acc@1: 81.2500 (82.1904)  Acc@5: 100.0000 (96.7793)  time: 0.3491  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 760/3750]  eta: 0:17:28  Lr: 0.001875  Loss: -0.8577  Acc@1: 81.2500 (82.2355)  Acc@5: 100.0000 (96.7970)  time: 0.3490  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 770/3750]  eta: 0:17:24  Lr: 0.001875  Loss: -1.2713  Acc@1: 81.2500 (82.2633)  Acc@5: 100.0000 (96.7899)  time: 0.3491  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 780/3750]  eta: 0:17:20  Lr: 0.001875  Loss: -0.7958  Acc@1: 81.2500 (82.2583)  Acc@5: 93.7500 (96.7910)  time: 0.3480  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [ 790/3750]  eta: 0:17:17  Lr: 0.001875  Loss: -0.7449  Acc@1: 81.2500 (82.2851)  Acc@5: 100.0000 (96.8078)  time: 0.3470  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [ 800/3750]  eta: 0:17:13  Lr: 0.001875  Loss: -1.2470  Acc@1: 81.2500 (82.2409)  Acc@5: 100.0000 (96.8087)  time: 0.3471  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [ 810/3750]  eta: 0:17:09  Lr: 0.001875  Loss: -0.6100  Acc@1: 81.2500 (82.2056)  Acc@5: 93.7500 (96.8018)  time: 0.3467  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [ 820/3750]  eta: 0:17:06  Lr: 0.001875  Loss: -0.8113  Acc@1: 81.2500 (82.2244)  Acc@5: 93.7500 (96.7951)  time: 0.3462  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [ 830/3750]  eta: 0:17:02  Lr: 0.001875  Loss: -0.8693  Acc@1: 81.2500 (82.2353)  Acc@5: 100.0000 (96.8111)  time: 0.3472  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [ 840/3750]  eta: 0:16:59  Lr: 0.001875  Loss: -1.1989  Acc@1: 81.2500 (82.2384)  Acc@5: 100.0000 (96.8118)  time: 0.3482  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 850/3750]  eta: 0:16:55  Lr: 0.001875  Loss: -1.4069  Acc@1: 81.2500 (82.2488)  Acc@5: 100.0000 (96.8052)  time: 0.3493  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [ 860/3750]  eta: 0:16:52  Lr: 0.001875  Loss: -0.8968  Acc@1: 81.2500 (82.2808)  Acc@5: 100.0000 (96.8060)  time: 0.3499  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [ 870/3750]  eta: 0:16:48  Lr: 0.001875  Loss: -1.2736  Acc@1: 81.2500 (82.3263)  Acc@5: 100.0000 (96.8068)  time: 0.3496  data: 0.0010  max mem: 2500
Train: Epoch[5/5]  [ 880/3750]  eta: 0:16:45  Lr: 0.001875  Loss: -0.8184  Acc@1: 81.2500 (82.3141)  Acc@5: 93.7500 (96.7792)  time: 0.3545  data: 0.0010  max mem: 2500
Train: Epoch[5/5]  [ 890/3750]  eta: 0:16:42  Lr: 0.001875  Loss: -0.8257  Acc@1: 81.2500 (82.3162)  Acc@5: 93.7500 (96.7452)  time: 0.3582  data: 0.0014  max mem: 2500
Train: Epoch[5/5]  [ 900/3750]  eta: 0:16:38  Lr: 0.001875  Loss: -1.1092  Acc@1: 81.2500 (82.3044)  Acc@5: 93.7500 (96.7120)  time: 0.3512  data: 0.0013  max mem: 2500
Train: Epoch[5/5]  [ 910/3750]  eta: 0:16:34  Lr: 0.001875  Loss: -0.4735  Acc@1: 81.2500 (82.3065)  Acc@5: 93.7500 (96.6795)  time: 0.3469  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [ 920/3750]  eta: 0:16:31  Lr: 0.001875  Loss: -1.2492  Acc@1: 81.2500 (82.2815)  Acc@5: 100.0000 (96.6952)  time: 0.3482  data: 0.0014  max mem: 2500
Train: Epoch[5/5]  [ 930/3750]  eta: 0:16:27  Lr: 0.001875  Loss: -1.1509  Acc@1: 81.2500 (82.2771)  Acc@5: 100.0000 (96.6904)  time: 0.3482  data: 0.0012  max mem: 2500
Train: Epoch[5/5]  [ 940/3750]  eta: 0:16:24  Lr: 0.001875  Loss: -1.0098  Acc@1: 81.2500 (82.2994)  Acc@5: 100.0000 (96.7256)  time: 0.3485  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 950/3750]  eta: 0:16:20  Lr: 0.001875  Loss: -1.1088  Acc@1: 87.5000 (82.3344)  Acc@5: 100.0000 (96.7468)  time: 0.3482  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 960/3750]  eta: 0:16:17  Lr: 0.001875  Loss: -0.9710  Acc@1: 81.2500 (82.3231)  Acc@5: 100.0000 (96.7287)  time: 0.3483  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [ 970/3750]  eta: 0:16:13  Lr: 0.001875  Loss: -0.7187  Acc@1: 81.2500 (82.2734)  Acc@5: 93.7500 (96.7173)  time: 0.3486  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [ 980/3750]  eta: 0:16:09  Lr: 0.001875  Loss: -1.3025  Acc@1: 81.2500 (82.2821)  Acc@5: 93.7500 (96.7189)  time: 0.3477  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [ 990/3750]  eta: 0:16:06  Lr: 0.001875  Loss: -0.7410  Acc@1: 81.2500 (82.2717)  Acc@5: 100.0000 (96.7079)  time: 0.3459  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1000/3750]  eta: 0:16:02  Lr: 0.001875  Loss: -1.1138  Acc@1: 81.2500 (82.2927)  Acc@5: 100.0000 (96.7033)  time: 0.3452  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [1010/3750]  eta: 0:15:59  Lr: 0.001875  Loss: -0.7716  Acc@1: 81.2500 (82.2886)  Acc@5: 100.0000 (96.7050)  time: 0.3492  data: 0.0016  max mem: 2500
Train: Epoch[5/5]  [1020/3750]  eta: 0:15:55  Lr: 0.001875  Loss: -1.1037  Acc@1: 87.5000 (82.3335)  Acc@5: 100.0000 (96.7128)  time: 0.3517  data: 0.0016  max mem: 2500
Train: Epoch[5/5]  [1030/3750]  eta: 0:15:52  Lr: 0.001875  Loss: -0.8400  Acc@1: 81.2500 (82.2987)  Acc@5: 100.0000 (96.7144)  time: 0.3504  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1040/3750]  eta: 0:15:48  Lr: 0.001875  Loss: -0.6501  Acc@1: 75.0000 (82.2286)  Acc@5: 100.0000 (96.7279)  time: 0.3490  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [1050/3750]  eta: 0:15:45  Lr: 0.001875  Loss: -1.0671  Acc@1: 75.0000 (82.2015)  Acc@5: 100.0000 (96.7353)  time: 0.3489  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [1060/3750]  eta: 0:15:41  Lr: 0.001875  Loss: -0.9900  Acc@1: 81.2500 (82.2161)  Acc@5: 100.0000 (96.7542)  time: 0.3515  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [1070/3750]  eta: 0:15:38  Lr: 0.001875  Loss: -0.6144  Acc@1: 87.5000 (82.2479)  Acc@5: 100.0000 (96.7495)  time: 0.3509  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [1080/3750]  eta: 0:15:34  Lr: 0.001875  Loss: -1.3792  Acc@1: 87.5000 (82.2502)  Acc@5: 100.0000 (96.7565)  time: 0.3495  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [1090/3750]  eta: 0:15:31  Lr: 0.001875  Loss: -0.8981  Acc@1: 81.2500 (82.2124)  Acc@5: 100.0000 (96.7518)  time: 0.3506  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [1100/3750]  eta: 0:15:27  Lr: 0.001875  Loss: -0.9295  Acc@1: 81.2500 (82.2094)  Acc@5: 100.0000 (96.7643)  time: 0.3518  data: 0.0010  max mem: 2500
Train: Epoch[5/5]  [1110/3750]  eta: 0:15:24  Lr: 0.001875  Loss: -1.0253  Acc@1: 81.2500 (82.1838)  Acc@5: 100.0000 (96.7653)  time: 0.3509  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [1120/3750]  eta: 0:15:20  Lr: 0.001875  Loss: -0.2963  Acc@1: 81.2500 (82.1867)  Acc@5: 100.0000 (96.7719)  time: 0.3484  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1130/3750]  eta: 0:15:17  Lr: 0.001875  Loss: -1.1166  Acc@1: 81.2500 (82.1784)  Acc@5: 100.0000 (96.7672)  time: 0.3479  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1140/3750]  eta: 0:15:13  Lr: 0.001875  Loss: -0.1579  Acc@1: 81.2500 (82.1812)  Acc@5: 100.0000 (96.7791)  time: 0.3483  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1150/3750]  eta: 0:15:10  Lr: 0.001875  Loss: -1.2217  Acc@1: 81.2500 (82.2166)  Acc@5: 100.0000 (96.8071)  time: 0.3491  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1160/3750]  eta: 0:15:06  Lr: 0.001875  Loss: -1.3034  Acc@1: 81.2500 (82.2136)  Acc@5: 100.0000 (96.8185)  time: 0.3486  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1170/3750]  eta: 0:15:02  Lr: 0.001875  Loss: -1.1195  Acc@1: 81.2500 (82.2214)  Acc@5: 100.0000 (96.8243)  time: 0.3469  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [1180/3750]  eta: 0:14:59  Lr: 0.001875  Loss: -1.2788  Acc@1: 87.5000 (82.2608)  Acc@5: 100.0000 (96.8353)  time: 0.3464  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1190/3750]  eta: 0:14:55  Lr: 0.001875  Loss: -0.8459  Acc@1: 81.2500 (82.2261)  Acc@5: 100.0000 (96.8356)  time: 0.3481  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [1200/3750]  eta: 0:14:52  Lr: 0.001875  Loss: -1.2134  Acc@1: 81.2500 (82.2388)  Acc@5: 100.0000 (96.8464)  time: 0.3487  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [1210/3750]  eta: 0:14:48  Lr: 0.001875  Loss: -0.8771  Acc@1: 81.2500 (82.2100)  Acc@5: 100.0000 (96.8260)  time: 0.3502  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [1220/3750]  eta: 0:14:45  Lr: 0.001875  Loss: -1.2423  Acc@1: 75.0000 (82.1970)  Acc@5: 100.0000 (96.8315)  time: 0.3506  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1230/3750]  eta: 0:14:41  Lr: 0.001875  Loss: -1.1341  Acc@1: 81.2500 (82.2350)  Acc@5: 100.0000 (96.8369)  time: 0.3514  data: 0.0020  max mem: 2500
Train: Epoch[5/5]  [1240/3750]  eta: 0:14:38  Lr: 0.001875  Loss: -1.0511  Acc@1: 81.2500 (82.1968)  Acc@5: 100.0000 (96.8423)  time: 0.3516  data: 0.0020  max mem: 2500
Train: Epoch[5/5]  [1250/3750]  eta: 0:14:34  Lr: 0.001875  Loss: -1.2387  Acc@1: 81.2500 (82.2242)  Acc@5: 100.0000 (96.8475)  time: 0.3496  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [1260/3750]  eta: 0:14:31  Lr: 0.001875  Loss: -1.3481  Acc@1: 87.5000 (82.2215)  Acc@5: 100.0000 (96.8577)  time: 0.3495  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [1270/3750]  eta: 0:14:27  Lr: 0.001875  Loss: -0.7261  Acc@1: 81.2500 (82.2286)  Acc@5: 100.0000 (96.8725)  time: 0.3502  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [1280/3750]  eta: 0:14:24  Lr: 0.001875  Loss: -0.8878  Acc@1: 81.2500 (82.2502)  Acc@5: 100.0000 (96.8921)  time: 0.3519  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [1290/3750]  eta: 0:14:21  Lr: 0.001875  Loss: -1.1271  Acc@1: 87.5000 (82.2376)  Acc@5: 100.0000 (96.8823)  time: 0.3519  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [1300/3750]  eta: 0:14:17  Lr: 0.001875  Loss: -0.4682  Acc@1: 81.2500 (82.2252)  Acc@5: 100.0000 (96.8822)  time: 0.3500  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [1310/3750]  eta: 0:14:13  Lr: 0.001875  Loss: -0.9057  Acc@1: 81.2500 (82.2130)  Acc@5: 100.0000 (96.8822)  time: 0.3482  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1320/3750]  eta: 0:14:10  Lr: 0.001875  Loss: -0.9732  Acc@1: 81.2500 (82.2199)  Acc@5: 100.0000 (96.8916)  time: 0.3482  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1330/3750]  eta: 0:14:06  Lr: 0.001875  Loss: -1.2717  Acc@1: 81.2500 (82.2220)  Acc@5: 100.0000 (96.8961)  time: 0.3496  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1340/3750]  eta: 0:14:03  Lr: 0.001875  Loss: -1.1266  Acc@1: 81.2500 (82.2474)  Acc@5: 100.0000 (96.9006)  time: 0.3483  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [1350/3750]  eta: 0:13:59  Lr: 0.001875  Loss: -1.2530  Acc@1: 81.2500 (82.2446)  Acc@5: 100.0000 (96.9051)  time: 0.3461  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [1360/3750]  eta: 0:13:56  Lr: 0.001875  Loss: -0.4497  Acc@1: 81.2500 (82.2235)  Acc@5: 100.0000 (96.9094)  time: 0.3475  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [1370/3750]  eta: 0:13:52  Lr: 0.001875  Loss: -1.0615  Acc@1: 81.2500 (82.2392)  Acc@5: 100.0000 (96.9137)  time: 0.3492  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [1380/3750]  eta: 0:13:49  Lr: 0.001875  Loss: -1.1393  Acc@1: 81.2500 (82.2230)  Acc@5: 100.0000 (96.9180)  time: 0.3479  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [1390/3750]  eta: 0:13:45  Lr: 0.001875  Loss: -1.1253  Acc@1: 81.2500 (82.2385)  Acc@5: 100.0000 (96.9312)  time: 0.3495  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1400/3750]  eta: 0:13:42  Lr: 0.001875  Loss: -0.4786  Acc@1: 75.0000 (82.1913)  Acc@5: 100.0000 (96.9263)  time: 0.3521  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [1410/3750]  eta: 0:13:38  Lr: 0.001875  Loss: -1.0505  Acc@1: 81.2500 (82.1846)  Acc@5: 93.7500 (96.9171)  time: 0.3508  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [1420/3750]  eta: 0:13:35  Lr: 0.001875  Loss: -0.8788  Acc@1: 81.2500 (82.1956)  Acc@5: 100.0000 (96.9300)  time: 0.3497  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [1430/3750]  eta: 0:13:31  Lr: 0.001875  Loss: -1.2923  Acc@1: 87.5000 (82.2065)  Acc@5: 100.0000 (96.9340)  time: 0.3501  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [1440/3750]  eta: 0:13:28  Lr: 0.001875  Loss: -1.2602  Acc@1: 81.2500 (82.2172)  Acc@5: 100.0000 (96.9379)  time: 0.3501  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [1450/3750]  eta: 0:13:24  Lr: 0.001875  Loss: -1.2277  Acc@1: 81.2500 (82.2407)  Acc@5: 100.0000 (96.9504)  time: 0.3495  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [1460/3750]  eta: 0:13:21  Lr: 0.001875  Loss: -0.8292  Acc@1: 81.2500 (82.2296)  Acc@5: 100.0000 (96.9541)  time: 0.3505  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [1470/3750]  eta: 0:13:17  Lr: 0.001875  Loss: -1.4946  Acc@1: 81.2500 (82.2485)  Acc@5: 100.0000 (96.9621)  time: 0.3535  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [1480/3750]  eta: 0:13:14  Lr: 0.001875  Loss: -0.8076  Acc@1: 81.2500 (82.2459)  Acc@5: 100.0000 (96.9700)  time: 0.3540  data: 0.0021  max mem: 2500
Train: Epoch[5/5]  [1490/3750]  eta: 0:13:10  Lr: 0.001875  Loss: -1.0140  Acc@1: 75.0000 (82.2183)  Acc@5: 100.0000 (96.9651)  time: 0.3501  data: 0.0020  max mem: 2500
Train: Epoch[5/5]  [1500/3750]  eta: 0:13:07  Lr: 0.001875  Loss: -1.0413  Acc@1: 81.2500 (82.2119)  Acc@5: 100.0000 (96.9687)  time: 0.3495  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1510/3750]  eta: 0:13:03  Lr: 0.001875  Loss: -0.7267  Acc@1: 81.2500 (82.1683)  Acc@5: 100.0000 (96.9515)  time: 0.3492  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [1520/3750]  eta: 0:13:00  Lr: 0.001875  Loss: -0.8590  Acc@1: 81.2500 (82.1540)  Acc@5: 100.0000 (96.9428)  time: 0.3478  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1530/3750]  eta: 0:12:56  Lr: 0.001875  Loss: -0.6371  Acc@1: 81.2500 (82.1359)  Acc@5: 100.0000 (96.9424)  time: 0.3473  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1540/3750]  eta: 0:12:53  Lr: 0.001875  Loss: -0.9614  Acc@1: 81.2500 (82.1504)  Acc@5: 100.0000 (96.9500)  time: 0.3464  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [1550/3750]  eta: 0:12:49  Lr: 0.001875  Loss: -0.6372  Acc@1: 81.2500 (82.1809)  Acc@5: 100.0000 (96.9375)  time: 0.3465  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [1560/3750]  eta: 0:12:46  Lr: 0.001875  Loss: -1.1112  Acc@1: 87.5000 (82.1989)  Acc@5: 93.7500 (96.9371)  time: 0.3464  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1570/3750]  eta: 0:12:42  Lr: 0.001875  Loss: -0.6723  Acc@1: 81.2500 (82.2207)  Acc@5: 93.7500 (96.9367)  time: 0.3461  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [1580/3750]  eta: 0:12:39  Lr: 0.001875  Loss: -1.1022  Acc@1: 81.2500 (82.2225)  Acc@5: 100.0000 (96.9363)  time: 0.3468  data: 0.0010  max mem: 2500
Train: Epoch[5/5]  [1590/3750]  eta: 0:12:35  Lr: 0.001875  Loss: -1.3881  Acc@1: 81.2500 (82.2164)  Acc@5: 100.0000 (96.9280)  time: 0.3484  data: 0.0011  max mem: 2500
Train: Epoch[5/5]  [1600/3750]  eta: 0:12:32  Lr: 0.001875  Loss: -0.9333  Acc@1: 81.2500 (82.1947)  Acc@5: 93.7500 (96.9121)  time: 0.3494  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [1610/3750]  eta: 0:12:28  Lr: 0.001875  Loss: -0.8551  Acc@1: 81.2500 (82.1733)  Acc@5: 93.7500 (96.9080)  time: 0.3517  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [1620/3750]  eta: 0:12:25  Lr: 0.001875  Loss: -0.9138  Acc@1: 81.2500 (82.1869)  Acc@5: 100.0000 (96.9232)  time: 0.3535  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [1630/3750]  eta: 0:12:21  Lr: 0.001875  Loss: -0.7325  Acc@1: 81.2500 (82.1735)  Acc@5: 100.0000 (96.9421)  time: 0.3515  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [1640/3750]  eta: 0:12:18  Lr: 0.001875  Loss: -1.0000  Acc@1: 81.2500 (82.1717)  Acc@5: 100.0000 (96.9493)  time: 0.3498  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1650/3750]  eta: 0:12:14  Lr: 0.001875  Loss: -1.2652  Acc@1: 81.2500 (82.1623)  Acc@5: 100.0000 (96.9526)  time: 0.3511  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [1660/3750]  eta: 0:12:11  Lr: 0.001875  Loss: -1.0515  Acc@1: 81.2500 (82.1343)  Acc@5: 100.0000 (96.9484)  time: 0.3548  data: 0.0013  max mem: 2500
Train: Epoch[5/5]  [1670/3750]  eta: 0:12:07  Lr: 0.001875  Loss: -1.0933  Acc@1: 81.2500 (82.1327)  Acc@5: 93.7500 (96.9442)  time: 0.3536  data: 0.0012  max mem: 2500
Train: Epoch[5/5]  [1680/3750]  eta: 0:12:04  Lr: 0.001875  Loss: -0.4540  Acc@1: 81.2500 (82.1609)  Acc@5: 100.0000 (96.9512)  time: 0.3485  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [1690/3750]  eta: 0:12:00  Lr: 0.001875  Loss: -0.4565  Acc@1: 81.2500 (82.1666)  Acc@5: 100.0000 (96.9471)  time: 0.3472  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1700/3750]  eta: 0:11:57  Lr: 0.001875  Loss: -0.7363  Acc@1: 81.2500 (82.1355)  Acc@5: 100.0000 (96.9430)  time: 0.3489  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1710/3750]  eta: 0:11:53  Lr: 0.001875  Loss: -1.1224  Acc@1: 81.2500 (82.1705)  Acc@5: 100.0000 (96.9389)  time: 0.3509  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1720/3750]  eta: 0:11:50  Lr: 0.001875  Loss: -1.1539  Acc@1: 87.5000 (82.1797)  Acc@5: 100.0000 (96.9422)  time: 0.3491  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1730/3750]  eta: 0:11:46  Lr: 0.001875  Loss: -0.6801  Acc@1: 81.2500 (82.1671)  Acc@5: 100.0000 (96.9310)  time: 0.3468  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [1740/3750]  eta: 0:11:43  Lr: 0.001875  Loss: -0.7673  Acc@1: 75.0000 (82.1511)  Acc@5: 93.7500 (96.9306)  time: 0.3472  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [1750/3750]  eta: 0:11:39  Lr: 0.001875  Loss: -1.1919  Acc@1: 81.2500 (82.1531)  Acc@5: 100.0000 (96.9375)  time: 0.3477  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [1760/3750]  eta: 0:11:36  Lr: 0.001875  Loss: -0.9683  Acc@1: 75.0000 (82.1302)  Acc@5: 93.7500 (96.9158)  time: 0.3462  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1770/3750]  eta: 0:11:32  Lr: 0.001875  Loss: -0.8534  Acc@1: 75.0000 (82.1252)  Acc@5: 93.7500 (96.9050)  time: 0.3447  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [1780/3750]  eta: 0:11:29  Lr: 0.001875  Loss: -0.9836  Acc@1: 81.2500 (82.1238)  Acc@5: 100.0000 (96.9048)  time: 0.3485  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1790/3750]  eta: 0:11:25  Lr: 0.001875  Loss: -0.8399  Acc@1: 81.2500 (82.1329)  Acc@5: 100.0000 (96.9082)  time: 0.3532  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [1800/3750]  eta: 0:11:22  Lr: 0.001875  Loss: -0.7976  Acc@1: 81.2500 (82.1315)  Acc@5: 100.0000 (96.9080)  time: 0.3520  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [1810/3750]  eta: 0:11:18  Lr: 0.001875  Loss: -0.3049  Acc@1: 87.5000 (82.1507)  Acc@5: 100.0000 (96.9112)  time: 0.3494  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [1820/3750]  eta: 0:11:15  Lr: 0.001875  Loss: -0.9010  Acc@1: 81.2500 (82.1561)  Acc@5: 100.0000 (96.9145)  time: 0.3508  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [1830/3750]  eta: 0:11:11  Lr: 0.001875  Loss: -1.0173  Acc@1: 81.2500 (82.1750)  Acc@5: 100.0000 (96.9211)  time: 0.3566  data: 0.0011  max mem: 2500
Train: Epoch[5/5]  [1840/3750]  eta: 0:11:08  Lr: 0.001875  Loss: -1.2482  Acc@1: 81.2500 (82.1666)  Acc@5: 100.0000 (96.9140)  time: 0.3569  data: 0.0013  max mem: 2500
Train: Epoch[5/5]  [1850/3750]  eta: 0:11:04  Lr: 0.001875  Loss: -0.6034  Acc@1: 81.2500 (82.1414)  Acc@5: 100.0000 (96.9138)  time: 0.3512  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [1860/3750]  eta: 0:11:01  Lr: 0.001875  Loss: -0.8986  Acc@1: 81.2500 (82.1333)  Acc@5: 100.0000 (96.9069)  time: 0.3492  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [1870/3750]  eta: 0:10:57  Lr: 0.001875  Loss: -1.0732  Acc@1: 75.0000 (82.1018)  Acc@5: 100.0000 (96.9001)  time: 0.3483  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [1880/3750]  eta: 0:10:54  Lr: 0.001875  Loss: -0.8377  Acc@1: 81.2500 (82.1006)  Acc@5: 100.0000 (96.9032)  time: 0.3482  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1890/3750]  eta: 0:10:50  Lr: 0.001875  Loss: -1.0219  Acc@1: 81.2500 (82.1159)  Acc@5: 93.7500 (96.8998)  time: 0.3500  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [1900/3750]  eta: 0:10:47  Lr: 0.001875  Loss: -0.5112  Acc@1: 87.5000 (82.1114)  Acc@5: 100.0000 (96.9062)  time: 0.3491  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [1910/3750]  eta: 0:10:43  Lr: 0.001875  Loss: -0.7999  Acc@1: 87.5000 (82.1200)  Acc@5: 100.0000 (96.9028)  time: 0.3474  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1920/3750]  eta: 0:10:40  Lr: 0.001875  Loss: -1.1136  Acc@1: 81.2500 (82.1284)  Acc@5: 100.0000 (96.9092)  time: 0.3512  data: 0.0011  max mem: 2500
Train: Epoch[5/5]  [1930/3750]  eta: 0:10:36  Lr: 0.001875  Loss: -1.0950  Acc@1: 81.2500 (82.1239)  Acc@5: 100.0000 (96.9155)  time: 0.3522  data: 0.0011  max mem: 2500
Train: Epoch[5/5]  [1940/3750]  eta: 0:10:33  Lr: 0.001875  Loss: -1.0676  Acc@1: 81.2500 (82.1419)  Acc@5: 100.0000 (96.9217)  time: 0.3471  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [1950/3750]  eta: 0:10:29  Lr: 0.001875  Loss: -1.1660  Acc@1: 87.5000 (82.1470)  Acc@5: 100.0000 (96.9311)  time: 0.3456  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [1960/3750]  eta: 0:10:26  Lr: 0.001875  Loss: -1.1440  Acc@1: 87.5000 (82.1679)  Acc@5: 100.0000 (96.9276)  time: 0.3480  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1970/3750]  eta: 0:10:22  Lr: 0.001875  Loss: -0.9822  Acc@1: 87.5000 (82.1823)  Acc@5: 93.7500 (96.9178)  time: 0.3521  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [1980/3750]  eta: 0:10:19  Lr: 0.001875  Loss: -1.2619  Acc@1: 81.2500 (82.1870)  Acc@5: 100.0000 (96.9239)  time: 0.3527  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [1990/3750]  eta: 0:10:15  Lr: 0.001875  Loss: -0.8708  Acc@1: 81.2500 (82.1792)  Acc@5: 100.0000 (96.9205)  time: 0.3492  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [2000/3750]  eta: 0:10:12  Lr: 0.001875  Loss: -1.2218  Acc@1: 81.2500 (82.1933)  Acc@5: 93.7500 (96.9172)  time: 0.3511  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [2010/3750]  eta: 0:10:08  Lr: 0.001875  Loss: -0.8996  Acc@1: 81.2500 (82.1762)  Acc@5: 100.0000 (96.9201)  time: 0.3536  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [2020/3750]  eta: 0:10:05  Lr: 0.001875  Loss: -0.7991  Acc@1: 81.2500 (82.2025)  Acc@5: 100.0000 (96.9322)  time: 0.3518  data: 0.0010  max mem: 2500
Train: Epoch[5/5]  [2030/3750]  eta: 0:10:01  Lr: 0.001875  Loss: -1.1555  Acc@1: 87.5000 (82.2132)  Acc@5: 100.0000 (96.9319)  time: 0.3498  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [2040/3750]  eta: 0:09:58  Lr: 0.001875  Loss: -1.1253  Acc@1: 87.5000 (82.2360)  Acc@5: 100.0000 (96.9408)  time: 0.3485  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [2050/3750]  eta: 0:09:54  Lr: 0.001875  Loss: -0.9373  Acc@1: 81.2500 (82.2282)  Acc@5: 100.0000 (96.9253)  time: 0.3539  data: 0.0012  max mem: 2500
Train: Epoch[5/5]  [2060/3750]  eta: 0:09:51  Lr: 0.001875  Loss: -0.9282  Acc@1: 81.2500 (82.2325)  Acc@5: 93.7500 (96.9220)  time: 0.3540  data: 0.0011  max mem: 2500
Train: Epoch[5/5]  [2070/3750]  eta: 0:09:47  Lr: 0.001875  Loss: -0.9422  Acc@1: 87.5000 (82.2338)  Acc@5: 93.7500 (96.9157)  time: 0.3492  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2080/3750]  eta: 0:09:44  Lr: 0.001875  Loss: -0.4684  Acc@1: 81.2500 (82.2141)  Acc@5: 100.0000 (96.9185)  time: 0.3491  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2090/3750]  eta: 0:09:40  Lr: 0.001875  Loss: -1.3055  Acc@1: 75.0000 (82.1885)  Acc@5: 100.0000 (96.9124)  time: 0.3488  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2100/3750]  eta: 0:09:37  Lr: 0.001875  Loss: -0.9249  Acc@1: 75.0000 (82.1871)  Acc@5: 93.7500 (96.9152)  time: 0.3501  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [2110/3750]  eta: 0:09:33  Lr: 0.001875  Loss: -0.5883  Acc@1: 81.2500 (82.1797)  Acc@5: 93.7500 (96.9061)  time: 0.3507  data: 0.0013  max mem: 2500
Train: Epoch[5/5]  [2120/3750]  eta: 0:09:30  Lr: 0.001875  Loss: -1.2967  Acc@1: 81.2500 (82.1694)  Acc@5: 93.7500 (96.9059)  time: 0.3481  data: 0.0010  max mem: 2500
Train: Epoch[5/5]  [2130/3750]  eta: 0:09:26  Lr: 0.001875  Loss: -0.7926  Acc@1: 81.2500 (82.1797)  Acc@5: 100.0000 (96.9146)  time: 0.3484  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [2140/3750]  eta: 0:09:23  Lr: 0.001875  Loss: -0.9558  Acc@1: 81.2500 (82.1637)  Acc@5: 100.0000 (96.9086)  time: 0.3496  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [2150/3750]  eta: 0:09:19  Lr: 0.001875  Loss: -0.6344  Acc@1: 81.2500 (82.1624)  Acc@5: 93.7500 (96.9055)  time: 0.3485  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [2160/3750]  eta: 0:09:16  Lr: 0.001875  Loss: -0.8124  Acc@1: 81.2500 (82.1581)  Acc@5: 100.0000 (96.9112)  time: 0.3489  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2170/3750]  eta: 0:09:12  Lr: 0.001875  Loss: -1.0225  Acc@1: 81.2500 (82.1770)  Acc@5: 100.0000 (96.9167)  time: 0.3498  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2180/3750]  eta: 0:09:09  Lr: 0.001875  Loss: -0.8539  Acc@1: 81.2500 (82.1555)  Acc@5: 93.7500 (96.9051)  time: 0.3513  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [2190/3750]  eta: 0:09:05  Lr: 0.001875  Loss: -1.1089  Acc@1: 81.2500 (82.1429)  Acc@5: 93.7500 (96.9050)  time: 0.3539  data: 0.0010  max mem: 2500
Train: Epoch[5/5]  [2200/3750]  eta: 0:09:02  Lr: 0.001875  Loss: -0.7848  Acc@1: 81.2500 (82.1558)  Acc@5: 100.0000 (96.9133)  time: 0.3525  data: 0.0011  max mem: 2500
Train: Epoch[5/5]  [2210/3750]  eta: 0:08:58  Lr: 0.001875  Loss: -0.9750  Acc@1: 81.2500 (82.1602)  Acc@5: 100.0000 (96.9160)  time: 0.3490  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [2220/3750]  eta: 0:08:55  Lr: 0.001875  Loss: -0.9921  Acc@1: 81.2500 (82.1618)  Acc@5: 100.0000 (96.9214)  time: 0.3496  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [2230/3750]  eta: 0:08:51  Lr: 0.001875  Loss: -1.2232  Acc@1: 87.5000 (82.1829)  Acc@5: 100.0000 (96.9268)  time: 0.3499  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [2240/3750]  eta: 0:08:48  Lr: 0.001875  Loss: -1.2782  Acc@1: 87.5000 (82.2010)  Acc@5: 100.0000 (96.9322)  time: 0.3500  data: 0.0015  max mem: 2500
Train: Epoch[5/5]  [2250/3750]  eta: 0:08:44  Lr: 0.001875  Loss: -1.2799  Acc@1: 87.5000 (82.2107)  Acc@5: 100.0000 (96.9291)  time: 0.3507  data: 0.0016  max mem: 2500
Train: Epoch[5/5]  [2260/3750]  eta: 0:08:41  Lr: 0.001875  Loss: -0.3128  Acc@1: 87.5000 (82.2147)  Acc@5: 100.0000 (96.9317)  time: 0.3490  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [2270/3750]  eta: 0:08:37  Lr: 0.001875  Loss: -1.2254  Acc@1: 87.5000 (82.2242)  Acc@5: 100.0000 (96.9424)  time: 0.3479  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [2280/3750]  eta: 0:08:34  Lr: 0.001875  Loss: -0.6286  Acc@1: 81.2500 (82.2090)  Acc@5: 100.0000 (96.9339)  time: 0.3501  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2290/3750]  eta: 0:08:30  Lr: 0.001875  Loss: -0.7210  Acc@1: 81.2500 (82.1939)  Acc@5: 93.7500 (96.9364)  time: 0.3498  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [2300/3750]  eta: 0:08:27  Lr: 0.001875  Loss: -1.0841  Acc@1: 81.2500 (82.1898)  Acc@5: 100.0000 (96.9443)  time: 0.3475  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2310/3750]  eta: 0:08:23  Lr: 0.001875  Loss: -1.1890  Acc@1: 81.2500 (82.1857)  Acc@5: 100.0000 (96.9467)  time: 0.3474  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [2320/3750]  eta: 0:08:20  Lr: 0.001875  Loss: -1.0211  Acc@1: 81.2500 (82.2086)  Acc@5: 100.0000 (96.9491)  time: 0.3466  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [2330/3750]  eta: 0:08:16  Lr: 0.001875  Loss: -1.1826  Acc@1: 81.2500 (82.2072)  Acc@5: 100.0000 (96.9514)  time: 0.3468  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [2340/3750]  eta: 0:08:13  Lr: 0.001875  Loss: -1.1416  Acc@1: 81.2500 (82.2138)  Acc@5: 100.0000 (96.9564)  time: 0.3466  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2350/3750]  eta: 0:08:09  Lr: 0.001875  Loss: -0.6424  Acc@1: 81.2500 (82.1911)  Acc@5: 100.0000 (96.9534)  time: 0.3472  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2360/3750]  eta: 0:08:06  Lr: 0.001875  Loss: -0.6778  Acc@1: 81.2500 (82.2030)  Acc@5: 100.0000 (96.9531)  time: 0.3495  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [2370/3750]  eta: 0:08:02  Lr: 0.001875  Loss: -0.5360  Acc@1: 87.5000 (82.2042)  Acc@5: 100.0000 (96.9554)  time: 0.3558  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [2380/3750]  eta: 0:07:59  Lr: 0.001875  Loss: -1.3933  Acc@1: 81.2500 (82.2002)  Acc@5: 100.0000 (96.9577)  time: 0.3546  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [2390/3750]  eta: 0:07:55  Lr: 0.001875  Loss: -1.3344  Acc@1: 81.2500 (82.1910)  Acc@5: 93.7500 (96.9443)  time: 0.3528  data: 0.0022  max mem: 2500
Train: Epoch[5/5]  [2400/3750]  eta: 0:07:52  Lr: 0.001875  Loss: -0.4821  Acc@1: 81.2500 (82.1741)  Acc@5: 100.0000 (96.9492)  time: 0.3548  data: 0.0027  max mem: 2500
Train: Epoch[5/5]  [2410/3750]  eta: 0:07:48  Lr: 0.001875  Loss: -1.2509  Acc@1: 81.2500 (82.1651)  Acc@5: 100.0000 (96.9515)  time: 0.3513  data: 0.0020  max mem: 2500
Train: Epoch[5/5]  [2420/3750]  eta: 0:07:45  Lr: 0.001875  Loss: -1.2184  Acc@1: 81.2500 (82.1613)  Acc@5: 100.0000 (96.9563)  time: 0.3511  data: 0.0014  max mem: 2500
Train: Epoch[5/5]  [2430/3750]  eta: 0:07:41  Lr: 0.001875  Loss: -0.7297  Acc@1: 81.2500 (82.1678)  Acc@5: 100.0000 (96.9586)  time: 0.3576  data: 0.0010  max mem: 2500
Train: Epoch[5/5]  [2440/3750]  eta: 0:07:38  Lr: 0.001875  Loss: -0.3902  Acc@1: 81.2500 (82.1615)  Acc@5: 93.7500 (96.9531)  time: 0.3572  data: 0.0013  max mem: 2500
Train: Epoch[5/5]  [2450/3750]  eta: 0:07:34  Lr: 0.001875  Loss: -1.0405  Acc@1: 81.2500 (82.1501)  Acc@5: 93.7500 (96.9349)  time: 0.3490  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [2460/3750]  eta: 0:07:31  Lr: 0.001875  Loss: -1.4870  Acc@1: 75.0000 (82.1465)  Acc@5: 93.7500 (96.9423)  time: 0.3502  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2470/3750]  eta: 0:07:27  Lr: 0.001875  Loss: -1.3085  Acc@1: 81.2500 (82.1606)  Acc@5: 100.0000 (96.9446)  time: 0.3519  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2480/3750]  eta: 0:07:24  Lr: 0.001875  Loss: -0.8158  Acc@1: 81.2500 (82.1670)  Acc@5: 100.0000 (96.9493)  time: 0.3511  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2490/3750]  eta: 0:07:20  Lr: 0.001875  Loss: -0.6087  Acc@1: 81.2500 (82.1457)  Acc@5: 100.0000 (96.9415)  time: 0.3483  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [2500/3750]  eta: 0:07:17  Lr: 0.001875  Loss: -0.9356  Acc@1: 81.2500 (82.1421)  Acc@5: 93.7500 (96.9362)  time: 0.3454  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [2510/3750]  eta: 0:07:13  Lr: 0.001875  Loss: -1.2676  Acc@1: 87.5000 (82.1585)  Acc@5: 93.7500 (96.9385)  time: 0.3458  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [2520/3750]  eta: 0:07:10  Lr: 0.001875  Loss: -0.9796  Acc@1: 81.2500 (82.1499)  Acc@5: 100.0000 (96.9283)  time: 0.3467  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [2530/3750]  eta: 0:07:06  Lr: 0.001875  Loss: -1.3027  Acc@1: 81.2500 (82.1563)  Acc@5: 100.0000 (96.9330)  time: 0.3469  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [2540/3750]  eta: 0:07:03  Lr: 0.001875  Loss: -1.1612  Acc@1: 81.2500 (82.1453)  Acc@5: 100.0000 (96.9353)  time: 0.3477  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2550/3750]  eta: 0:06:59  Lr: 0.001875  Loss: -1.2902  Acc@1: 87.5000 (82.1712)  Acc@5: 100.0000 (96.9375)  time: 0.3494  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [2560/3750]  eta: 0:06:56  Lr: 0.001875  Loss: -1.2014  Acc@1: 87.5000 (82.1676)  Acc@5: 100.0000 (96.9421)  time: 0.3485  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [2570/3750]  eta: 0:06:52  Lr: 0.001875  Loss: -0.8788  Acc@1: 87.5000 (82.1567)  Acc@5: 100.0000 (96.9443)  time: 0.3521  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [2580/3750]  eta: 0:06:49  Lr: 0.001875  Loss: -1.1650  Acc@1: 81.2500 (82.1678)  Acc@5: 100.0000 (96.9464)  time: 0.3547  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [2590/3750]  eta: 0:06:45  Lr: 0.001875  Loss: -0.6680  Acc@1: 81.2500 (82.1642)  Acc@5: 100.0000 (96.9462)  time: 0.3517  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [2600/3750]  eta: 0:06:42  Lr: 0.001875  Loss: -0.7857  Acc@1: 75.0000 (82.1295)  Acc@5: 93.7500 (96.9339)  time: 0.3525  data: 0.0020  max mem: 2500
Train: Epoch[5/5]  [2610/3750]  eta: 0:06:38  Lr: 0.001875  Loss: -1.1474  Acc@1: 75.0000 (82.1381)  Acc@5: 100.0000 (96.9360)  time: 0.3507  data: 0.0020  max mem: 2500
Train: Epoch[5/5]  [2620/3750]  eta: 0:06:35  Lr: 0.001875  Loss: -1.2194  Acc@1: 87.5000 (82.1514)  Acc@5: 100.0000 (96.9453)  time: 0.3527  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [2630/3750]  eta: 0:06:32  Lr: 0.001875  Loss: -0.8052  Acc@1: 87.5000 (82.1670)  Acc@5: 100.0000 (96.9451)  time: 0.3566  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [2640/3750]  eta: 0:06:28  Lr: 0.001875  Loss: -0.8136  Acc@1: 81.2500 (82.1587)  Acc@5: 100.0000 (96.9472)  time: 0.3523  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [2650/3750]  eta: 0:06:25  Lr: 0.001875  Loss: -1.0476  Acc@1: 81.2500 (82.1365)  Acc@5: 100.0000 (96.9422)  time: 0.3585  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2660/3750]  eta: 0:06:21  Lr: 0.001875  Loss: -1.0257  Acc@1: 81.2500 (82.1449)  Acc@5: 100.0000 (96.9443)  time: 0.3574  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2670/3750]  eta: 0:06:18  Lr: 0.001875  Loss: -1.1264  Acc@1: 81.2500 (82.1368)  Acc@5: 93.7500 (96.9347)  time: 0.3474  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2680/3750]  eta: 0:06:15  Lr: 0.001875  Loss: -0.9397  Acc@1: 87.5000 (82.1475)  Acc@5: 93.7500 (96.9298)  time: 0.4059  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2690/3750]  eta: 0:06:13  Lr: 0.001875  Loss: -0.3803  Acc@1: 87.5000 (82.1465)  Acc@5: 100.0000 (96.9249)  time: 0.6071  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2700/3750]  eta: 0:06:11  Lr: 0.001875  Loss: -0.8812  Acc@1: 87.5000 (82.1548)  Acc@5: 100.0000 (96.9248)  time: 0.7504  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [2710/3750]  eta: 0:06:09  Lr: 0.001875  Loss: -0.9919  Acc@1: 81.2500 (82.1445)  Acc@5: 93.7500 (96.9177)  time: 0.7489  data: 0.0015  max mem: 2500
Train: Epoch[5/5]  [2720/3750]  eta: 0:06:07  Lr: 0.001875  Loss: -1.3778  Acc@1: 81.2500 (82.1366)  Acc@5: 100.0000 (96.9175)  time: 0.7470  data: 0.0016  max mem: 2500
Train: Epoch[5/5]  [2730/3750]  eta: 0:06:04  Lr: 0.001875  Loss: -1.1535  Acc@1: 81.2500 (82.1494)  Acc@5: 100.0000 (96.9242)  time: 0.7530  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [2740/3750]  eta: 0:06:02  Lr: 0.001875  Loss: -0.6174  Acc@1: 81.2500 (82.1393)  Acc@5: 100.0000 (96.9240)  time: 0.7544  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [2750/3750]  eta: 0:06:00  Lr: 0.001875  Loss: -1.2223  Acc@1: 81.2500 (82.1633)  Acc@5: 100.0000 (96.9307)  time: 0.7550  data: 0.0010  max mem: 2500
Train: Epoch[5/5]  [2760/3750]  eta: 0:05:58  Lr: 0.001875  Loss: -1.1163  Acc@1: 87.5000 (82.1691)  Acc@5: 100.0000 (96.9350)  time: 0.7566  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [2770/3750]  eta: 0:05:56  Lr: 0.001875  Loss: -1.2860  Acc@1: 81.2500 (82.1680)  Acc@5: 100.0000 (96.9348)  time: 0.7501  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2780/3750]  eta: 0:05:53  Lr: 0.001875  Loss: -0.6903  Acc@1: 81.2500 (82.1647)  Acc@5: 100.0000 (96.9278)  time: 0.7459  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2790/3750]  eta: 0:05:51  Lr: 0.001875  Loss: -1.0815  Acc@1: 81.2500 (82.1592)  Acc@5: 93.7500 (96.9209)  time: 0.7439  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2800/3750]  eta: 0:05:49  Lr: 0.001875  Loss: -0.7776  Acc@1: 75.0000 (82.1559)  Acc@5: 100.0000 (96.9252)  time: 0.7442  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2810/3750]  eta: 0:05:46  Lr: 0.001875  Loss: -0.9816  Acc@1: 87.5000 (82.1638)  Acc@5: 100.0000 (96.9273)  time: 0.7471  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [2820/3750]  eta: 0:05:44  Lr: 0.001875  Loss: -1.2817  Acc@1: 87.5000 (82.1584)  Acc@5: 100.0000 (96.9248)  time: 0.7522  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [2830/3750]  eta: 0:05:41  Lr: 0.001875  Loss: -1.1984  Acc@1: 81.2500 (82.1618)  Acc@5: 100.0000 (96.9203)  time: 0.7476  data: 0.0011  max mem: 2500
Train: Epoch[5/5]  [2840/3750]  eta: 0:05:39  Lr: 0.001875  Loss: -1.0467  Acc@1: 81.2500 (82.1652)  Acc@5: 100.0000 (96.9245)  time: 0.7426  data: 0.0012  max mem: 2500
Train: Epoch[5/5]  [2850/3750]  eta: 0:05:36  Lr: 0.001875  Loss: -0.7501  Acc@1: 81.2500 (82.1685)  Acc@5: 100.0000 (96.9353)  time: 0.7447  data: 0.0011  max mem: 2500
Train: Epoch[5/5]  [2860/3750]  eta: 0:05:34  Lr: 0.001875  Loss: -1.0730  Acc@1: 81.2500 (82.1762)  Acc@5: 100.0000 (96.9373)  time: 0.7426  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [2870/3750]  eta: 0:05:31  Lr: 0.001875  Loss: -1.0262  Acc@1: 87.5000 (82.1796)  Acc@5: 100.0000 (96.9349)  time: 0.7425  data: 0.0016  max mem: 2500
Train: Epoch[5/5]  [2880/3750]  eta: 0:05:28  Lr: 0.001875  Loss: -0.5422  Acc@1: 81.2500 (82.1720)  Acc@5: 100.0000 (96.9303)  time: 0.7411  data: 0.0016  max mem: 2500
Train: Epoch[5/5]  [2890/3750]  eta: 0:05:26  Lr: 0.001875  Loss: -1.2399  Acc@1: 81.2500 (82.1666)  Acc@5: 100.0000 (96.9301)  time: 0.7391  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [2900/3750]  eta: 0:05:23  Lr: 0.001875  Loss: -0.8675  Acc@1: 81.2500 (82.1807)  Acc@5: 100.0000 (96.9256)  time: 0.7381  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2910/3750]  eta: 0:05:20  Lr: 0.001875  Loss: -1.0671  Acc@1: 81.2500 (82.1840)  Acc@5: 93.7500 (96.9169)  time: 0.7360  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2920/3750]  eta: 0:05:17  Lr: 0.001875  Loss: -0.9060  Acc@1: 81.2500 (82.1786)  Acc@5: 93.7500 (96.9167)  time: 0.7344  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2930/3750]  eta: 0:05:15  Lr: 0.001875  Loss: -1.2022  Acc@1: 81.2500 (82.1712)  Acc@5: 100.0000 (96.9123)  time: 0.7377  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [2940/3750]  eta: 0:05:12  Lr: 0.001875  Loss: -1.3021  Acc@1: 81.2500 (82.1617)  Acc@5: 100.0000 (96.9207)  time: 0.7420  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [2950/3750]  eta: 0:05:09  Lr: 0.001875  Loss: -1.1759  Acc@1: 87.5000 (82.1755)  Acc@5: 100.0000 (96.9227)  time: 0.7397  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2960/3750]  eta: 0:05:06  Lr: 0.001875  Loss: -0.9598  Acc@1: 81.2500 (82.1745)  Acc@5: 93.7500 (96.9183)  time: 0.7377  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [2970/3750]  eta: 0:05:03  Lr: 0.001875  Loss: -1.3508  Acc@1: 81.2500 (82.1735)  Acc@5: 93.7500 (96.9139)  time: 0.7061  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [2980/3750]  eta: 0:05:00  Lr: 0.001875  Loss: -0.6161  Acc@1: 81.2500 (82.1704)  Acc@5: 100.0000 (96.9096)  time: 0.7046  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2990/3750]  eta: 0:04:57  Lr: 0.001875  Loss: -0.7502  Acc@1: 81.2500 (82.1673)  Acc@5: 100.0000 (96.9032)  time: 0.7315  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [3000/3750]  eta: 0:04:53  Lr: 0.001875  Loss: -1.0591  Acc@1: 87.5000 (82.1851)  Acc@5: 100.0000 (96.9073)  time: 0.6978  data: 0.0011  max mem: 2500
Train: Epoch[5/5]  [3010/3750]  eta: 0:04:49  Lr: 0.001875  Loss: -1.2361  Acc@1: 87.5000 (82.1903)  Acc@5: 100.0000 (96.9051)  time: 0.5061  data: 0.0010  max mem: 2500
Train: Epoch[5/5]  [3020/3750]  eta: 0:04:45  Lr: 0.001875  Loss: -0.9344  Acc@1: 87.5000 (82.1975)  Acc@5: 100.0000 (96.9091)  time: 0.3475  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [3030/3750]  eta: 0:04:41  Lr: 0.001875  Loss: -1.3124  Acc@1: 87.5000 (82.2130)  Acc@5: 100.0000 (96.9111)  time: 0.3508  data: 0.0010  max mem: 2500
Train: Epoch[5/5]  [3040/3750]  eta: 0:04:37  Lr: 0.001875  Loss: -1.1499  Acc@1: 87.5000 (82.2262)  Acc@5: 100.0000 (96.9130)  time: 0.3545  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [3050/3750]  eta: 0:04:33  Lr: 0.001875  Loss: -1.3734  Acc@1: 81.2500 (82.2189)  Acc@5: 100.0000 (96.9129)  time: 0.3549  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [3060/3750]  eta: 0:04:29  Lr: 0.001875  Loss: -0.6797  Acc@1: 81.2500 (82.2035)  Acc@5: 100.0000 (96.9148)  time: 0.3538  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [3070/3750]  eta: 0:04:25  Lr: 0.001875  Loss: -1.0312  Acc@1: 75.0000 (82.1862)  Acc@5: 100.0000 (96.9045)  time: 0.3643  data: 0.0017  max mem: 2500
Train: Epoch[5/5]  [3080/3750]  eta: 0:04:21  Lr: 0.001875  Loss: -1.0977  Acc@1: 75.0000 (82.1831)  Acc@5: 93.7500 (96.9024)  time: 0.3615  data: 0.0016  max mem: 2500
Train: Epoch[5/5]  [3090/3750]  eta: 0:04:17  Lr: 0.001875  Loss: -1.0650  Acc@1: 81.2500 (82.1862)  Acc@5: 100.0000 (96.9023)  time: 0.3508  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [3100/3750]  eta: 0:04:13  Lr: 0.001875  Loss: -1.1197  Acc@1: 87.5000 (82.1973)  Acc@5: 100.0000 (96.9103)  time: 0.3561  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [3110/3750]  eta: 0:04:10  Lr: 0.001875  Loss: -0.7735  Acc@1: 87.5000 (82.2083)  Acc@5: 100.0000 (96.9142)  time: 0.3801  data: 0.0013  max mem: 2500
Train: Epoch[5/5]  [3120/3750]  eta: 0:04:06  Lr: 0.001875  Loss: -0.6337  Acc@1: 81.2500 (82.2092)  Acc@5: 100.0000 (96.9120)  time: 0.3742  data: 0.0012  max mem: 2500
Train: Epoch[5/5]  [3130/3750]  eta: 0:04:02  Lr: 0.001875  Loss: -1.0059  Acc@1: 81.2500 (82.2122)  Acc@5: 93.7500 (96.9039)  time: 0.3489  data: 0.0010  max mem: 2500
Train: Epoch[5/5]  [3140/3750]  eta: 0:03:58  Lr: 0.001875  Loss: -0.9356  Acc@1: 81.2500 (82.2011)  Acc@5: 93.7500 (96.9078)  time: 0.3510  data: 0.0014  max mem: 2500
Train: Epoch[5/5]  [3150/3750]  eta: 0:03:54  Lr: 0.001875  Loss: -1.1128  Acc@1: 81.2500 (82.2041)  Acc@5: 100.0000 (96.9057)  time: 0.3498  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [3160/3750]  eta: 0:03:50  Lr: 0.001875  Loss: -0.7457  Acc@1: 81.2500 (82.1951)  Acc@5: 93.7500 (96.8977)  time: 0.3470  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [3170/3750]  eta: 0:03:46  Lr: 0.001875  Loss: -0.6029  Acc@1: 87.5000 (82.2079)  Acc@5: 100.0000 (96.9036)  time: 0.3468  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [3180/3750]  eta: 0:03:42  Lr: 0.001875  Loss: -0.8661  Acc@1: 87.5000 (82.2108)  Acc@5: 100.0000 (96.9035)  time: 0.3492  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [3190/3750]  eta: 0:03:38  Lr: 0.001875  Loss: -0.2966  Acc@1: 81.2500 (82.2136)  Acc@5: 93.7500 (96.9034)  time: 0.3487  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [3200/3750]  eta: 0:03:34  Lr: 0.001875  Loss: -0.8515  Acc@1: 87.5000 (82.2184)  Acc@5: 100.0000 (96.9072)  time: 0.3448  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [3210/3750]  eta: 0:03:30  Lr: 0.001875  Loss: -1.3694  Acc@1: 87.5000 (82.2329)  Acc@5: 100.0000 (96.9110)  time: 0.3452  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [3220/3750]  eta: 0:03:26  Lr: 0.001875  Loss: -0.9196  Acc@1: 87.5000 (82.2318)  Acc@5: 100.0000 (96.9051)  time: 0.3513  data: 0.0012  max mem: 2500
Train: Epoch[5/5]  [3230/3750]  eta: 0:03:22  Lr: 0.001875  Loss: -1.3882  Acc@1: 81.2500 (82.2443)  Acc@5: 100.0000 (96.9089)  time: 0.3554  data: 0.0016  max mem: 2500
Train: Epoch[5/5]  [3240/3750]  eta: 0:03:18  Lr: 0.001875  Loss: -1.1800  Acc@1: 87.5000 (82.2451)  Acc@5: 100.0000 (96.9068)  time: 0.3531  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [3250/3750]  eta: 0:03:14  Lr: 0.001875  Loss: -1.3239  Acc@1: 81.2500 (82.2516)  Acc@5: 100.0000 (96.9086)  time: 0.3518  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [3260/3750]  eta: 0:03:10  Lr: 0.001875  Loss: -1.2837  Acc@1: 81.2500 (82.2543)  Acc@5: 100.0000 (96.9085)  time: 0.3517  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [3270/3750]  eta: 0:03:06  Lr: 0.001875  Loss: -0.6824  Acc@1: 81.2500 (82.2474)  Acc@5: 100.0000 (96.9084)  time: 0.3546  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [3280/3750]  eta: 0:03:02  Lr: 0.001875  Loss: -1.0913  Acc@1: 81.2500 (82.2520)  Acc@5: 100.0000 (96.9102)  time: 0.3518  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [3290/3750]  eta: 0:02:58  Lr: 0.001875  Loss: -1.2241  Acc@1: 81.2500 (82.2527)  Acc@5: 100.0000 (96.9139)  time: 0.3476  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [3300/3750]  eta: 0:02:54  Lr: 0.001875  Loss: -0.9238  Acc@1: 81.2500 (82.2573)  Acc@5: 100.0000 (96.9214)  time: 0.3488  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [3310/3750]  eta: 0:02:50  Lr: 0.001875  Loss: -1.2686  Acc@1: 81.2500 (82.2505)  Acc@5: 100.0000 (96.9269)  time: 0.3509  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3320/3750]  eta: 0:02:46  Lr: 0.001875  Loss: -0.9577  Acc@1: 81.2500 (82.2474)  Acc@5: 100.0000 (96.9230)  time: 0.3511  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3330/3750]  eta: 0:02:42  Lr: 0.001875  Loss: -0.6376  Acc@1: 81.2500 (82.2369)  Acc@5: 100.0000 (96.9210)  time: 0.3479  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3340/3750]  eta: 0:02:39  Lr: 0.001875  Loss: -1.4381  Acc@1: 81.2500 (82.2415)  Acc@5: 100.0000 (96.9208)  time: 0.3470  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3350/3750]  eta: 0:02:35  Lr: 0.001875  Loss: -1.1487  Acc@1: 81.2500 (82.2441)  Acc@5: 100.0000 (96.9226)  time: 0.3488  data: 0.0015  max mem: 2500
Train: Epoch[5/5]  [3360/3750]  eta: 0:02:31  Lr: 0.001875  Loss: -1.1337  Acc@1: 81.2500 (82.2411)  Acc@5: 100.0000 (96.9206)  time: 0.3503  data: 0.0016  max mem: 2500
Train: Epoch[5/5]  [3370/3750]  eta: 0:02:27  Lr: 0.001875  Loss: -0.8884  Acc@1: 81.2500 (82.2493)  Acc@5: 93.7500 (96.9186)  time: 0.3485  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3380/3750]  eta: 0:02:23  Lr: 0.001875  Loss: -0.8792  Acc@1: 87.5000 (82.2482)  Acc@5: 100.0000 (96.9166)  time: 0.3459  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [3390/3750]  eta: 0:02:19  Lr: 0.001875  Loss: -0.9834  Acc@1: 81.2500 (82.2453)  Acc@5: 100.0000 (96.9202)  time: 0.3459  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [3400/3750]  eta: 0:02:15  Lr: 0.001875  Loss: -0.9489  Acc@1: 87.5000 (82.2718)  Acc@5: 100.0000 (96.9274)  time: 0.3468  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [3410/3750]  eta: 0:02:11  Lr: 0.001875  Loss: -0.9255  Acc@1: 87.5000 (82.2614)  Acc@5: 100.0000 (96.9309)  time: 0.3460  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [3420/3750]  eta: 0:02:07  Lr: 0.001875  Loss: -1.3692  Acc@1: 81.2500 (82.2749)  Acc@5: 100.0000 (96.9252)  time: 0.3473  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [3430/3750]  eta: 0:02:03  Lr: 0.001875  Loss: -0.3933  Acc@1: 81.2500 (82.2628)  Acc@5: 93.7500 (96.9233)  time: 0.3541  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [3440/3750]  eta: 0:01:59  Lr: 0.001875  Loss: -1.1529  Acc@1: 81.2500 (82.2617)  Acc@5: 93.7500 (96.9177)  time: 0.3562  data: 0.0010  max mem: 2500
Train: Epoch[5/5]  [3450/3750]  eta: 0:01:56  Lr: 0.001875  Loss: -0.7747  Acc@1: 81.2500 (82.2551)  Acc@5: 100.0000 (96.9139)  time: 0.3517  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [3460/3750]  eta: 0:01:52  Lr: 0.001875  Loss: -0.9703  Acc@1: 81.2500 (82.2559)  Acc@5: 100.0000 (96.9120)  time: 0.3500  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [3470/3750]  eta: 0:01:48  Lr: 0.001875  Loss: -1.0723  Acc@1: 81.2500 (82.2656)  Acc@5: 100.0000 (96.9155)  time: 0.3502  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [3480/3750]  eta: 0:01:44  Lr: 0.001875  Loss: -0.2520  Acc@1: 81.2500 (82.2555)  Acc@5: 100.0000 (96.9082)  time: 0.3540  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [3490/3750]  eta: 0:01:40  Lr: 0.001875  Loss: -0.9960  Acc@1: 81.2500 (82.2579)  Acc@5: 100.0000 (96.9117)  time: 0.3556  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [3500/3750]  eta: 0:01:36  Lr: 0.001875  Loss: -0.9105  Acc@1: 81.2500 (82.2729)  Acc@5: 100.0000 (96.9134)  time: 0.3518  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [3510/3750]  eta: 0:01:32  Lr: 0.001875  Loss: -1.3604  Acc@1: 81.2500 (82.2736)  Acc@5: 100.0000 (96.9133)  time: 0.3506  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [3520/3750]  eta: 0:01:28  Lr: 0.001875  Loss: -0.9778  Acc@1: 81.2500 (82.2831)  Acc@5: 100.0000 (96.9132)  time: 0.3497  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [3530/3750]  eta: 0:01:24  Lr: 0.001875  Loss: -1.0945  Acc@1: 81.2500 (82.2855)  Acc@5: 100.0000 (96.9148)  time: 0.3518  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [3540/3750]  eta: 0:01:21  Lr: 0.001875  Loss: -1.0530  Acc@1: 81.2500 (82.2773)  Acc@5: 100.0000 (96.9182)  time: 0.3529  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [3550/3750]  eta: 0:01:17  Lr: 0.001875  Loss: -0.8462  Acc@1: 81.2500 (82.2726)  Acc@5: 93.7500 (96.9146)  time: 0.3498  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3560/3750]  eta: 0:01:13  Lr: 0.001875  Loss: -0.7754  Acc@1: 81.2500 (82.2890)  Acc@5: 93.7500 (96.9162)  time: 0.3486  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3570/3750]  eta: 0:01:09  Lr: 0.001875  Loss: -1.2720  Acc@1: 87.5000 (82.2949)  Acc@5: 100.0000 (96.9161)  time: 0.3490  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [3580/3750]  eta: 0:01:05  Lr: 0.001875  Loss: -1.0069  Acc@1: 81.2500 (82.2937)  Acc@5: 93.7500 (96.9125)  time: 0.3472  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [3590/3750]  eta: 0:01:01  Lr: 0.001875  Loss: -1.3171  Acc@1: 81.2500 (82.2960)  Acc@5: 100.0000 (96.9176)  time: 0.3450  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [3600/3750]  eta: 0:00:57  Lr: 0.001875  Loss: -1.4057  Acc@1: 87.5000 (82.3157)  Acc@5: 100.0000 (96.9245)  time: 0.3457  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [3610/3750]  eta: 0:00:53  Lr: 0.001875  Loss: -1.3182  Acc@1: 87.5000 (82.3214)  Acc@5: 100.0000 (96.9243)  time: 0.3478  data: 0.0011  max mem: 2500
Train: Epoch[5/5]  [3620/3750]  eta: 0:00:50  Lr: 0.001875  Loss: -0.9888  Acc@1: 87.5000 (82.3426)  Acc@5: 100.0000 (96.9311)  time: 0.3500  data: 0.0010  max mem: 2500
Train: Epoch[5/5]  [3630/3750]  eta: 0:00:46  Lr: 0.001875  Loss: -1.1125  Acc@1: 87.5000 (82.3568)  Acc@5: 100.0000 (96.9327)  time: 0.3490  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3640/3750]  eta: 0:00:42  Lr: 0.001875  Loss: -1.0526  Acc@1: 81.2500 (82.3400)  Acc@5: 100.0000 (96.9291)  time: 0.3495  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3650/3750]  eta: 0:00:38  Lr: 0.001875  Loss: -1.3070  Acc@1: 75.0000 (82.3370)  Acc@5: 100.0000 (96.9323)  time: 0.3511  data: 0.0011  max mem: 2500
Train: Epoch[5/5]  [3660/3750]  eta: 0:00:34  Lr: 0.001875  Loss: -0.8975  Acc@1: 81.2500 (82.3392)  Acc@5: 100.0000 (96.9339)  time: 0.3559  data: 0.0012  max mem: 2500
Train: Epoch[5/5]  [3670/3750]  eta: 0:00:30  Lr: 0.001875  Loss: -0.8962  Acc@1: 87.5000 (82.3430)  Acc@5: 100.0000 (96.9354)  time: 0.3553  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [3680/3750]  eta: 0:00:26  Lr: 0.001875  Loss: -1.2391  Acc@1: 87.5000 (82.3536)  Acc@5: 100.0000 (96.9336)  time: 0.3496  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [3690/3750]  eta: 0:00:23  Lr: 0.001875  Loss: -0.6390  Acc@1: 81.2500 (82.3439)  Acc@5: 100.0000 (96.9368)  time: 0.3489  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [3700/3750]  eta: 0:00:19  Lr: 0.001875  Loss: -0.6325  Acc@1: 81.2500 (82.3477)  Acc@5: 100.0000 (96.9316)  time: 0.3499  data: 0.0020  max mem: 2500
Train: Epoch[5/5]  [3710/3750]  eta: 0:00:15  Lr: 0.001875  Loss: -0.9930  Acc@1: 81.2500 (82.3380)  Acc@5: 93.7500 (96.9297)  time: 0.3499  data: 0.0018  max mem: 2500
Train: Epoch[5/5]  [3720/3750]  eta: 0:00:11  Lr: 0.001875  Loss: -1.3400  Acc@1: 81.2500 (82.3435)  Acc@5: 100.0000 (96.9296)  time: 0.3488  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3730/3750]  eta: 0:00:07  Lr: 0.001875  Loss: -1.2869  Acc@1: 81.2500 (82.3238)  Acc@5: 100.0000 (96.9328)  time: 0.3481  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3740/3750]  eta: 0:00:03  Lr: 0.001875  Loss: -0.4878  Acc@1: 81.2500 (82.3109)  Acc@5: 100.0000 (96.9293)  time: 0.3477  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3749/3750]  eta: 0:00:00  Lr: 0.001875  Loss: -1.3035  Acc@1: 81.2500 (82.3183)  Acc@5: 100.0000 (96.9300)  time: 0.3495  data: 0.0010  max mem: 2500
Train: Epoch[5/5] Total time: 0:23:59 (0.3840 s / it)
{0: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 1: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 2: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 3: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 4: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 5: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 6: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 7: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 8: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 9: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 10: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 11: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 12: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 13: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 14: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 15: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 16: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 17: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 18: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 19: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}}
Averaged stats: Lr: 0.001875  Loss: -1.3035  Acc@1: 81.2500 (82.3183)  Acc@5: 100.0000 (96.9300)
Test: [Task 1]  [   0/1627]  eta: 0:19:14  Loss: 1.4170 (1.4170)  Acc@1: 56.2500 (56.2500)  Acc@5: 93.7500 (93.7500)  time: 0.7099  data: 0.4959  max mem: 2500
Test: [Task 1]  [  10/1627]  eta: 0:06:58  Loss: 1.2600 (1.1975)  Acc@1: 68.7500 (65.9091)  Acc@5: 93.7500 (94.8864)  time: 0.2591  data: 0.0453  max mem: 2500
Test: [Task 1]  [  20/1627]  eta: 0:06:21  Loss: 1.1197 (1.1390)  Acc@1: 68.7500 (67.8571)  Acc@5: 93.7500 (94.6429)  time: 0.2137  data: 0.0002  max mem: 2500
Test: [Task 1]  [  30/1627]  eta: 0:06:06  Loss: 1.1322 (1.1338)  Acc@1: 68.7500 (67.9435)  Acc@5: 93.7500 (94.5565)  time: 0.2133  data: 0.0002  max mem: 2500
Test: [Task 1]  [  40/1627]  eta: 0:05:58  Loss: 1.2062 (1.1468)  Acc@1: 68.7500 (67.2256)  Acc@5: 93.7500 (94.5122)  time: 0.2136  data: 0.0003  max mem: 2500
Test: [Task 1]  [  50/1627]  eta: 0:05:53  Loss: 0.9468 (1.1217)  Acc@1: 68.7500 (68.7500)  Acc@5: 100.0000 (95.0980)  time: 0.2151  data: 0.0011  max mem: 2500
Test: [Task 1]  [  60/1627]  eta: 0:05:48  Loss: 1.0124 (1.1341)  Acc@1: 68.7500 (68.5451)  Acc@5: 100.0000 (94.9795)  time: 0.2155  data: 0.0011  max mem: 2500
Test: [Task 1]  [  70/1627]  eta: 0:05:44  Loss: 1.1163 (1.1336)  Acc@1: 68.7500 (68.8380)  Acc@5: 93.7500 (95.2465)  time: 0.2153  data: 0.0009  max mem: 2500
Test: [Task 1]  [  80/1627]  eta: 0:05:41  Loss: 0.8791 (1.1135)  Acc@1: 75.0000 (69.5216)  Acc@5: 100.0000 (95.6019)  time: 0.2168  data: 0.0010  max mem: 2500
Test: [Task 1]  [  90/1627]  eta: 0:05:38  Loss: 1.0578 (1.1270)  Acc@1: 75.0000 (69.0247)  Acc@5: 93.7500 (95.3297)  time: 0.2172  data: 0.0005  max mem: 2500
Test: [Task 1]  [ 100/1627]  eta: 0:05:36  Loss: 1.1886 (1.1492)  Acc@1: 68.7500 (68.9975)  Acc@5: 93.7500 (94.6782)  time: 0.2163  data: 0.0005  max mem: 2500
Test: [Task 1]  [ 110/1627]  eta: 0:05:33  Loss: 1.1063 (1.1435)  Acc@1: 75.0000 (69.2005)  Acc@5: 93.7500 (94.9324)  time: 0.2160  data: 0.0005  max mem: 2500
Test: [Task 1]  [ 120/1627]  eta: 0:05:31  Loss: 1.0700 (1.1396)  Acc@1: 75.0000 (69.5248)  Acc@5: 100.0000 (94.9380)  time: 0.2183  data: 0.0005  max mem: 2500
Test: [Task 1]  [ 130/1627]  eta: 0:05:29  Loss: 1.1294 (1.1464)  Acc@1: 75.0000 (69.2271)  Acc@5: 93.7500 (94.9905)  time: 0.2217  data: 0.0005  max mem: 2500
Test: [Task 1]  [ 140/1627]  eta: 0:05:26  Loss: 1.0705 (1.1443)  Acc@1: 68.7500 (69.3262)  Acc@5: 93.7500 (94.9468)  time: 0.2199  data: 0.0005  max mem: 2500
Test: [Task 1]  [ 150/1627]  eta: 0:05:24  Loss: 0.9116 (1.1263)  Acc@1: 75.0000 (69.9089)  Acc@5: 93.7500 (95.1159)  time: 0.2157  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 160/1627]  eta: 0:05:21  Loss: 0.9388 (1.1213)  Acc@1: 75.0000 (70.2252)  Acc@5: 100.0000 (95.2640)  time: 0.2149  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 170/1627]  eta: 0:05:19  Loss: 1.0949 (1.1151)  Acc@1: 75.0000 (70.3582)  Acc@5: 100.0000 (95.3216)  time: 0.2167  data: 0.0007  max mem: 2500
Test: [Task 1]  [ 180/1627]  eta: 0:05:16  Loss: 1.0949 (1.1214)  Acc@1: 68.7500 (70.0622)  Acc@5: 93.7500 (95.3384)  time: 0.2172  data: 0.0007  max mem: 2500
Test: [Task 1]  [ 190/1627]  eta: 0:05:14  Loss: 1.1276 (1.1196)  Acc@1: 68.7500 (70.0262)  Acc@5: 93.7500 (95.2880)  time: 0.2165  data: 0.0005  max mem: 2500
Test: [Task 1]  [ 200/1627]  eta: 0:05:12  Loss: 1.1299 (1.1193)  Acc@1: 68.7500 (70.2736)  Acc@5: 93.7500 (95.3047)  time: 0.2163  data: 0.0006  max mem: 2500
Test: [Task 1]  [ 210/1627]  eta: 0:05:09  Loss: 0.9712 (1.1159)  Acc@1: 75.0000 (70.6161)  Acc@5: 93.7500 (95.3199)  time: 0.2157  data: 0.0005  max mem: 2500
Test: [Task 1]  [ 220/1627]  eta: 0:05:07  Loss: 0.9757 (1.1230)  Acc@1: 75.0000 (70.3620)  Acc@5: 93.7500 (95.2771)  time: 0.2155  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 230/1627]  eta: 0:05:04  Loss: 1.0801 (1.1201)  Acc@1: 68.7500 (70.4545)  Acc@5: 93.7500 (95.2110)  time: 0.2151  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 240/1627]  eta: 0:05:02  Loss: 1.0478 (1.1159)  Acc@1: 75.0000 (70.6172)  Acc@5: 93.7500 (95.2801)  time: 0.2149  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 250/1627]  eta: 0:05:00  Loss: 0.9990 (1.1191)  Acc@1: 75.0000 (70.7171)  Acc@5: 93.7500 (95.1693)  time: 0.2151  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 260/1627]  eta: 0:04:57  Loss: 1.0822 (1.1189)  Acc@1: 75.0000 (70.8333)  Acc@5: 93.7500 (95.1389)  time: 0.2157  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 270/1627]  eta: 0:04:55  Loss: 0.9877 (1.1115)  Acc@1: 75.0000 (71.1024)  Acc@5: 100.0000 (95.2491)  time: 0.2158  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 280/1627]  eta: 0:04:53  Loss: 0.9029 (1.1119)  Acc@1: 75.0000 (71.1966)  Acc@5: 93.7500 (95.1735)  time: 0.2155  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 290/1627]  eta: 0:04:51  Loss: 1.0903 (1.1109)  Acc@1: 68.7500 (71.2414)  Acc@5: 93.7500 (95.2105)  time: 0.2162  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 300/1627]  eta: 0:04:48  Loss: 0.9836 (1.1107)  Acc@1: 68.7500 (71.2417)  Acc@5: 93.7500 (95.2035)  time: 0.2151  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 310/1627]  eta: 0:04:46  Loss: 0.9836 (1.1106)  Acc@1: 75.0000 (71.3023)  Acc@5: 93.7500 (95.2371)  time: 0.2139  data: 0.0002  max mem: 2500
Test: [Task 1]  [ 320/1627]  eta: 0:04:44  Loss: 1.1522 (1.1107)  Acc@1: 75.0000 (71.2617)  Acc@5: 100.0000 (95.2687)  time: 0.2144  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 330/1627]  eta: 0:04:41  Loss: 0.9929 (1.1099)  Acc@1: 68.7500 (71.2991)  Acc@5: 100.0000 (95.2983)  time: 0.2142  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 340/1627]  eta: 0:04:39  Loss: 0.9467 (1.1100)  Acc@1: 75.0000 (71.4076)  Acc@5: 100.0000 (95.2713)  time: 0.2142  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 350/1627]  eta: 0:04:37  Loss: 1.1343 (1.1113)  Acc@1: 75.0000 (71.3675)  Acc@5: 93.7500 (95.1923)  time: 0.2147  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 360/1627]  eta: 0:04:35  Loss: 1.0197 (1.1094)  Acc@1: 75.0000 (71.5028)  Acc@5: 93.7500 (95.2389)  time: 0.2161  data: 0.0007  max mem: 2500
Test: [Task 1]  [ 370/1627]  eta: 0:04:32  Loss: 1.0077 (1.1073)  Acc@1: 75.0000 (71.5633)  Acc@5: 100.0000 (95.2830)  time: 0.2180  data: 0.0010  max mem: 2500
Test: [Task 1]  [ 380/1627]  eta: 0:04:30  Loss: 0.9425 (1.1057)  Acc@1: 75.0000 (71.6043)  Acc@5: 93.7500 (95.2920)  time: 0.2191  data: 0.0007  max mem: 2500
Test: [Task 1]  [ 390/1627]  eta: 0:04:28  Loss: 0.9592 (1.1069)  Acc@1: 75.0000 (71.5313)  Acc@5: 93.7500 (95.2366)  time: 0.2195  data: 0.0011  max mem: 2500
Test: [Task 1]  [ 400/1627]  eta: 0:04:26  Loss: 0.9935 (1.1073)  Acc@1: 68.7500 (71.4464)  Acc@5: 100.0000 (95.2618)  time: 0.2185  data: 0.0011  max mem: 2500
Test: [Task 1]  [ 410/1627]  eta: 0:04:24  Loss: 0.9033 (1.1071)  Acc@1: 75.0000 (71.5785)  Acc@5: 93.7500 (95.2251)  time: 0.2188  data: 0.0005  max mem: 2500
Test: [Task 1]  [ 420/1627]  eta: 0:04:22  Loss: 0.9033 (1.1055)  Acc@1: 75.0000 (71.5855)  Acc@5: 93.7500 (95.2643)  time: 0.2206  data: 0.0008  max mem: 2500
Test: [Task 1]  [ 430/1627]  eta: 0:04:20  Loss: 0.9529 (1.1038)  Acc@1: 75.0000 (71.6212)  Acc@5: 100.0000 (95.3306)  time: 0.2195  data: 0.0009  max mem: 2500
Test: [Task 1]  [ 440/1627]  eta: 0:04:18  Loss: 1.0482 (1.1018)  Acc@1: 75.0000 (71.6553)  Acc@5: 100.0000 (95.3798)  time: 0.2190  data: 0.0008  max mem: 2500
Test: [Task 1]  [ 450/1627]  eta: 0:04:16  Loss: 1.1007 (1.1045)  Acc@1: 68.7500 (71.5909)  Acc@5: 100.0000 (95.3298)  time: 0.2204  data: 0.0008  max mem: 2500
Test: [Task 1]  [ 460/1627]  eta: 0:04:13  Loss: 1.1007 (1.1039)  Acc@1: 62.5000 (71.5428)  Acc@5: 100.0000 (95.3769)  time: 0.2190  data: 0.0006  max mem: 2500
Test: [Task 1]  [ 470/1627]  eta: 0:04:11  Loss: 1.0018 (1.1008)  Acc@1: 68.7500 (71.5897)  Acc@5: 100.0000 (95.3954)  time: 0.2176  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 480/1627]  eta: 0:04:09  Loss: 1.1419 (1.1055)  Acc@1: 68.7500 (71.4787)  Acc@5: 93.7500 (95.4002)  time: 0.2192  data: 0.0007  max mem: 2500
Test: [Task 1]  [ 490/1627]  eta: 0:04:07  Loss: 1.1746 (1.1066)  Acc@1: 62.5000 (71.3977)  Acc@5: 93.7500 (95.4048)  time: 0.2192  data: 0.0008  max mem: 2500
Test: [Task 1]  [ 500/1627]  eta: 0:04:05  Loss: 1.0209 (1.1075)  Acc@1: 75.0000 (71.4072)  Acc@5: 93.7500 (95.3593)  time: 0.2165  data: 0.0005  max mem: 2500
Test: [Task 1]  [ 510/1627]  eta: 0:04:03  Loss: 1.1564 (1.1129)  Acc@1: 68.7500 (71.2940)  Acc@5: 93.7500 (95.3400)  time: 0.2161  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 520/1627]  eta: 0:04:00  Loss: 1.2285 (1.1205)  Acc@1: 62.5000 (71.1012)  Acc@5: 93.7500 (95.3335)  time: 0.2198  data: 0.0008  max mem: 2500
Test: [Task 1]  [ 530/1627]  eta: 0:03:58  Loss: 1.0628 (1.1165)  Acc@1: 62.5000 (71.1982)  Acc@5: 100.0000 (95.3978)  time: 0.2222  data: 0.0020  max mem: 2500
Test: [Task 1]  [ 540/1627]  eta: 0:03:57  Loss: 0.9735 (1.1167)  Acc@1: 75.0000 (71.1761)  Acc@5: 100.0000 (95.3905)  time: 0.2283  data: 0.0016  max mem: 2500
Test: [Task 1]  [ 550/1627]  eta: 0:03:54  Loss: 1.1700 (1.1183)  Acc@1: 75.0000 (71.2114)  Acc@5: 93.7500 (95.3607)  time: 0.2284  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 560/1627]  eta: 0:03:52  Loss: 1.2660 (1.1212)  Acc@1: 68.7500 (71.1007)  Acc@5: 93.7500 (95.3654)  time: 0.2189  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 570/1627]  eta: 0:03:50  Loss: 1.1295 (1.1186)  Acc@1: 68.7500 (71.1799)  Acc@5: 93.7500 (95.3700)  time: 0.2180  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 580/1627]  eta: 0:03:48  Loss: 1.0099 (1.1191)  Acc@1: 75.0000 (71.1274)  Acc@5: 93.7500 (95.3959)  time: 0.2181  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 590/1627]  eta: 0:03:46  Loss: 1.1404 (1.1186)  Acc@1: 68.7500 (71.1612)  Acc@5: 100.0000 (95.4420)  time: 0.2163  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 600/1627]  eta: 0:03:44  Loss: 1.1081 (1.1195)  Acc@1: 68.7500 (71.1418)  Acc@5: 100.0000 (95.4763)  time: 0.2286  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 610/1627]  eta: 0:03:42  Loss: 1.0026 (1.1176)  Acc@1: 68.7500 (71.1845)  Acc@5: 100.0000 (95.4992)  time: 0.2287  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 620/1627]  eta: 0:03:39  Loss: 1.0469 (1.1186)  Acc@1: 75.0000 (71.2057)  Acc@5: 93.7500 (95.4408)  time: 0.2161  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 630/1627]  eta: 0:03:37  Loss: 1.0343 (1.1182)  Acc@1: 75.0000 (71.2361)  Acc@5: 93.7500 (95.4140)  time: 0.2154  data: 0.0002  max mem: 2500
Test: [Task 1]  [ 640/1627]  eta: 0:03:35  Loss: 0.9442 (1.1185)  Acc@1: 75.0000 (71.2363)  Acc@5: 93.7500 (95.3783)  time: 0.2157  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 650/1627]  eta: 0:03:33  Loss: 0.9934 (1.1180)  Acc@1: 68.7500 (71.2270)  Acc@5: 100.0000 (95.4013)  time: 0.2155  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 660/1627]  eta: 0:03:31  Loss: 0.9916 (1.1164)  Acc@1: 68.7500 (71.2840)  Acc@5: 93.7500 (95.4047)  time: 0.2152  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 670/1627]  eta: 0:03:28  Loss: 1.0108 (1.1159)  Acc@1: 68.7500 (71.2928)  Acc@5: 93.7500 (95.4173)  time: 0.2151  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 680/1627]  eta: 0:03:26  Loss: 1.0108 (1.1155)  Acc@1: 75.0000 (71.3198)  Acc@5: 93.7500 (95.4020)  time: 0.2153  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 690/1627]  eta: 0:03:24  Loss: 1.0448 (1.1134)  Acc@1: 75.0000 (71.3821)  Acc@5: 93.7500 (95.4323)  time: 0.2150  data: 0.0002  max mem: 2500
Test: [Task 1]  [ 700/1627]  eta: 0:03:22  Loss: 1.0646 (1.1130)  Acc@1: 75.0000 (71.4515)  Acc@5: 93.7500 (95.4262)  time: 0.2154  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 710/1627]  eta: 0:03:19  Loss: 0.9708 (1.1104)  Acc@1: 75.0000 (71.5541)  Acc@5: 93.7500 (95.4378)  time: 0.2167  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 720/1627]  eta: 0:03:17  Loss: 0.9708 (1.1084)  Acc@1: 75.0000 (71.5673)  Acc@5: 100.0000 (95.4577)  time: 0.2172  data: 0.0009  max mem: 2500
Test: [Task 1]  [ 730/1627]  eta: 0:03:15  Loss: 1.0073 (1.1099)  Acc@1: 68.7500 (71.4860)  Acc@5: 100.0000 (95.4685)  time: 0.2180  data: 0.0015  max mem: 2500
Test: [Task 1]  [ 740/1627]  eta: 0:03:13  Loss: 1.0895 (1.1110)  Acc@1: 68.7500 (71.5250)  Acc@5: 93.7500 (95.4538)  time: 0.2179  data: 0.0010  max mem: 2500
Test: [Task 1]  [ 750/1627]  eta: 0:03:11  Loss: 1.0198 (1.1099)  Acc@1: 75.0000 (71.6212)  Acc@5: 93.7500 (95.4477)  time: 0.2189  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 760/1627]  eta: 0:03:09  Loss: 1.1825 (1.1129)  Acc@1: 75.0000 (71.5506)  Acc@5: 93.7500 (95.4254)  time: 0.2193  data: 0.0014  max mem: 2500
Test: [Task 1]  [ 770/1627]  eta: 0:03:06  Loss: 0.8751 (1.1094)  Acc@1: 75.0000 (71.6440)  Acc@5: 93.7500 (95.4523)  time: 0.2174  data: 0.0014  max mem: 2500
Test: [Task 1]  [ 780/1627]  eta: 0:03:04  Loss: 0.8595 (1.1080)  Acc@1: 75.0000 (71.6309)  Acc@5: 100.0000 (95.4786)  time: 0.2181  data: 0.0006  max mem: 2500
Test: [Task 1]  [ 790/1627]  eta: 0:03:02  Loss: 0.9200 (1.1095)  Acc@1: 68.7500 (71.6261)  Acc@5: 100.0000 (95.4646)  time: 0.2177  data: 0.0005  max mem: 2500
Test: [Task 1]  [ 800/1627]  eta: 0:03:00  Loss: 1.0185 (1.1085)  Acc@1: 75.0000 (71.6214)  Acc@5: 100.0000 (95.4900)  time: 0.2165  data: 0.0006  max mem: 2500
Test: [Task 1]  [ 810/1627]  eta: 0:02:58  Loss: 0.9698 (1.1074)  Acc@1: 75.0000 (71.7016)  Acc@5: 100.0000 (95.4994)  time: 0.2185  data: 0.0010  max mem: 2500
Test: [Task 1]  [ 820/1627]  eta: 0:02:55  Loss: 0.9511 (1.1067)  Acc@1: 75.0000 (71.6809)  Acc@5: 100.0000 (95.4933)  time: 0.2191  data: 0.0015  max mem: 2500
Test: [Task 1]  [ 830/1627]  eta: 0:02:53  Loss: 0.9179 (1.1060)  Acc@1: 75.0000 (71.6907)  Acc@5: 100.0000 (95.5024)  time: 0.2179  data: 0.0014  max mem: 2500
Test: [Task 1]  [ 840/1627]  eta: 0:02:51  Loss: 0.9250 (1.1040)  Acc@1: 75.0000 (71.7598)  Acc@5: 100.0000 (95.5336)  time: 0.2177  data: 0.0010  max mem: 2500
Test: [Task 1]  [ 850/1627]  eta: 0:02:49  Loss: 1.0056 (1.1043)  Acc@1: 68.7500 (71.7244)  Acc@5: 100.0000 (95.5494)  time: 0.2171  data: 0.0009  max mem: 2500
Test: [Task 1]  [ 860/1627]  eta: 0:02:47  Loss: 0.9769 (1.1031)  Acc@1: 68.7500 (71.7334)  Acc@5: 100.0000 (95.5865)  time: 0.2164  data: 0.0005  max mem: 2500
Test: [Task 1]  [ 870/1627]  eta: 0:02:45  Loss: 0.9067 (1.1017)  Acc@1: 75.0000 (71.7853)  Acc@5: 100.0000 (95.5870)  time: 0.2204  data: 0.0005  max mem: 2500
Test: [Task 1]  [ 880/1627]  eta: 0:02:43  Loss: 1.0563 (1.1038)  Acc@1: 75.0000 (71.7083)  Acc@5: 100.0000 (95.6016)  time: 0.2276  data: 0.0005  max mem: 2500
Test: [Task 1]  [ 890/1627]  eta: 0:02:40  Loss: 1.2402 (1.1058)  Acc@1: 62.5000 (71.6330)  Acc@5: 100.0000 (95.6089)  time: 0.2228  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 900/1627]  eta: 0:02:38  Loss: 1.0852 (1.1060)  Acc@1: 68.7500 (71.6357)  Acc@5: 100.0000 (95.6160)  time: 0.2171  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 910/1627]  eta: 0:02:36  Loss: 1.0872 (1.1069)  Acc@1: 75.0000 (71.6452)  Acc@5: 93.7500 (95.5955)  time: 0.2177  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 920/1627]  eta: 0:02:34  Loss: 1.0872 (1.1066)  Acc@1: 68.7500 (71.6409)  Acc@5: 93.7500 (95.5890)  time: 0.2156  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 930/1627]  eta: 0:02:32  Loss: 1.0996 (1.1076)  Acc@1: 68.7500 (71.5964)  Acc@5: 93.7500 (95.5827)  time: 0.2161  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 940/1627]  eta: 0:02:30  Loss: 1.0918 (1.1060)  Acc@1: 68.7500 (71.6658)  Acc@5: 93.7500 (95.5964)  time: 0.2509  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 950/1627]  eta: 0:02:29  Loss: 1.0965 (1.1067)  Acc@1: 68.7500 (71.6351)  Acc@5: 100.0000 (95.6033)  time: 0.3753  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 960/1627]  eta: 0:02:29  Loss: 1.1358 (1.1061)  Acc@1: 68.7500 (71.6311)  Acc@5: 93.7500 (95.5905)  time: 0.4661  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 970/1627]  eta: 0:02:28  Loss: 0.9833 (1.1049)  Acc@1: 75.0000 (71.6722)  Acc@5: 93.7500 (95.5973)  time: 0.4666  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 980/1627]  eta: 0:02:28  Loss: 1.0581 (1.1052)  Acc@1: 75.0000 (71.6871)  Acc@5: 93.7500 (95.5912)  time: 0.4670  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 990/1627]  eta: 0:02:27  Loss: 1.1529 (1.1082)  Acc@1: 68.7500 (71.6574)  Acc@5: 93.7500 (95.5537)  time: 0.4651  data: 0.0013  max mem: 2500
Test: [Task 1]  [1000/1627]  eta: 0:02:26  Loss: 1.2420 (1.1089)  Acc@1: 68.7500 (71.6533)  Acc@5: 93.7500 (95.5357)  time: 0.4664  data: 0.0017  max mem: 2500
Test: [Task 1]  [1010/1627]  eta: 0:02:25  Loss: 1.1172 (1.1086)  Acc@1: 68.7500 (71.6494)  Acc@5: 100.0000 (95.5428)  time: 0.4698  data: 0.0007  max mem: 2500
Test: [Task 1]  [1020/1627]  eta: 0:02:24  Loss: 1.0607 (1.1084)  Acc@1: 68.7500 (71.6271)  Acc@5: 100.0000 (95.5558)  time: 0.4698  data: 0.0007  max mem: 2500
Test: [Task 1]  [1030/1627]  eta: 0:02:23  Loss: 0.9392 (1.1065)  Acc@1: 75.0000 (71.6840)  Acc@5: 100.0000 (95.5807)  time: 0.4674  data: 0.0008  max mem: 2500
Test: [Task 1]  [1040/1627]  eta: 0:02:22  Loss: 0.8763 (1.1053)  Acc@1: 75.0000 (71.7099)  Acc@5: 100.0000 (95.5992)  time: 0.4642  data: 0.0005  max mem: 2500
Test: [Task 1]  [1050/1627]  eta: 0:02:21  Loss: 0.8981 (1.1037)  Acc@1: 75.0000 (71.7650)  Acc@5: 100.0000 (95.5994)  time: 0.4663  data: 0.0004  max mem: 2500
Test: [Task 1]  [1060/1627]  eta: 0:02:19  Loss: 1.0365 (1.1042)  Acc@1: 75.0000 (71.7601)  Acc@5: 93.7500 (95.5702)  time: 0.4651  data: 0.0012  max mem: 2500
Test: [Task 1]  [1070/1627]  eta: 0:02:18  Loss: 1.1133 (1.1050)  Acc@1: 75.0000 (71.7495)  Acc@5: 93.7500 (95.5532)  time: 0.4633  data: 0.0011  max mem: 2500
Test: [Task 1]  [1080/1627]  eta: 0:02:17  Loss: 1.1490 (1.1055)  Acc@1: 68.7500 (71.7565)  Acc@5: 93.7500 (95.5423)  time: 0.4650  data: 0.0003  max mem: 2500
Test: [Task 1]  [1090/1627]  eta: 0:02:15  Loss: 1.1311 (1.1056)  Acc@1: 68.7500 (71.7690)  Acc@5: 93.7500 (95.5431)  time: 0.4643  data: 0.0004  max mem: 2500
Test: [Task 1]  [1100/1627]  eta: 0:02:14  Loss: 1.0232 (1.1036)  Acc@1: 75.0000 (71.7984)  Acc@5: 100.0000 (95.5609)  time: 0.4640  data: 0.0004  max mem: 2500
Test: [Task 1]  [1110/1627]  eta: 0:02:12  Loss: 1.0232 (1.1041)  Acc@1: 75.0000 (71.8047)  Acc@5: 100.0000 (95.5614)  time: 0.4622  data: 0.0003  max mem: 2500
Test: [Task 1]  [1120/1627]  eta: 0:02:11  Loss: 1.1078 (1.1052)  Acc@1: 62.5000 (71.7273)  Acc@5: 100.0000 (95.5620)  time: 0.4604  data: 0.0003  max mem: 2500
Test: [Task 1]  [1130/1627]  eta: 0:02:09  Loss: 1.0915 (1.1058)  Acc@1: 62.5000 (71.7175)  Acc@5: 93.7500 (95.5570)  time: 0.4611  data: 0.0003  max mem: 2500
Test: [Task 1]  [1140/1627]  eta: 0:02:07  Loss: 1.2481 (1.1071)  Acc@1: 68.7500 (71.6970)  Acc@5: 93.7500 (95.5521)  time: 0.4619  data: 0.0003  max mem: 2500
Test: [Task 1]  [1150/1627]  eta: 0:02:05  Loss: 1.2752 (1.1081)  Acc@1: 68.7500 (71.6659)  Acc@5: 93.7500 (95.5528)  time: 0.4609  data: 0.0004  max mem: 2500
Test: [Task 1]  [1160/1627]  eta: 0:02:03  Loss: 1.1261 (1.1070)  Acc@1: 75.0000 (71.7270)  Acc@5: 93.7500 (95.5642)  time: 0.4610  data: 0.0005  max mem: 2500
Test: [Task 1]  [1170/1627]  eta: 0:02:02  Loss: 1.0767 (1.1062)  Acc@1: 75.0000 (71.7602)  Acc@5: 100.0000 (95.5700)  time: 0.4630  data: 0.0004  max mem: 2500
Test: [Task 1]  [1180/1627]  eta: 0:02:00  Loss: 1.0767 (1.1066)  Acc@1: 75.0000 (71.7824)  Acc@5: 93.7500 (95.5705)  time: 0.4657  data: 0.0004  max mem: 2500
Test: [Task 1]  [1190/1627]  eta: 0:01:58  Loss: 1.1903 (1.1071)  Acc@1: 68.7500 (71.7412)  Acc@5: 100.0000 (95.5919)  time: 0.4640  data: 0.0004  max mem: 2500
Test: [Task 1]  [1200/1627]  eta: 0:01:56  Loss: 1.1300 (1.1071)  Acc@1: 68.7500 (71.7319)  Acc@5: 100.0000 (95.5818)  time: 0.4619  data: 0.0004  max mem: 2500
Test: [Task 1]  [1210/1627]  eta: 0:01:54  Loss: 0.9376 (1.1077)  Acc@1: 68.7500 (71.6918)  Acc@5: 100.0000 (95.5667)  time: 0.4638  data: 0.0004  max mem: 2500
Test: [Task 1]  [1220/1627]  eta: 0:01:52  Loss: 0.9376 (1.1069)  Acc@1: 68.7500 (71.7035)  Acc@5: 93.7500 (95.5723)  time: 0.4656  data: 0.0006  max mem: 2500
Test: [Task 1]  [1230/1627]  eta: 0:01:49  Loss: 1.1154 (1.1071)  Acc@1: 68.7500 (71.6998)  Acc@5: 93.7500 (95.5626)  time: 0.4624  data: 0.0005  max mem: 2500
Test: [Task 1]  [1240/1627]  eta: 0:01:47  Loss: 1.1220 (1.1063)  Acc@1: 75.0000 (71.7063)  Acc@5: 93.7500 (95.5681)  time: 0.4606  data: 0.0004  max mem: 2500
Test: [Task 1]  [1250/1627]  eta: 0:01:45  Loss: 1.1274 (1.1069)  Acc@1: 68.7500 (71.6727)  Acc@5: 93.7500 (95.5635)  time: 0.4625  data: 0.0004  max mem: 2500
Test: [Task 1]  [1260/1627]  eta: 0:01:43  Loss: 1.0595 (1.1067)  Acc@1: 68.7500 (71.6941)  Acc@5: 93.7500 (95.5541)  time: 0.4588  data: 0.0004  max mem: 2500
Test: [Task 1]  [1270/1627]  eta: 0:01:40  Loss: 1.0194 (1.1074)  Acc@1: 68.7500 (71.6709)  Acc@5: 93.7500 (95.5350)  time: 0.4588  data: 0.0003  max mem: 2500
Test: [Task 1]  [1280/1627]  eta: 0:01:38  Loss: 0.9461 (1.1057)  Acc@1: 75.0000 (71.7018)  Acc@5: 93.7500 (95.5552)  time: 0.4629  data: 0.0010  max mem: 2500
Test: [Task 1]  [1290/1627]  eta: 0:01:36  Loss: 1.0562 (1.1059)  Acc@1: 68.7500 (71.6789)  Acc@5: 100.0000 (95.5703)  time: 0.4620  data: 0.0010  max mem: 2500
Test: [Task 1]  [1300/1627]  eta: 0:01:33  Loss: 1.0639 (1.1052)  Acc@1: 75.0000 (71.7237)  Acc@5: 93.7500 (95.5755)  time: 0.4620  data: 0.0003  max mem: 2500
Test: [Task 1]  [1310/1627]  eta: 0:01:31  Loss: 0.8701 (1.1038)  Acc@1: 75.0000 (71.7582)  Acc@5: 93.7500 (95.5807)  time: 0.4632  data: 0.0009  max mem: 2500
Test: [Task 1]  [1320/1627]  eta: 0:01:28  Loss: 0.8116 (1.1023)  Acc@1: 75.0000 (71.7969)  Acc@5: 100.0000 (95.5905)  time: 0.4629  data: 0.0010  max mem: 2500
Test: [Task 1]  [1330/1627]  eta: 0:01:26  Loss: 0.9247 (1.1022)  Acc@1: 75.0000 (71.8398)  Acc@5: 100.0000 (95.5907)  time: 0.4642  data: 0.0005  max mem: 2500
Test: [Task 1]  [1340/1627]  eta: 0:01:23  Loss: 1.0679 (1.1027)  Acc@1: 75.0000 (71.8121)  Acc@5: 93.7500 (95.5910)  time: 0.4638  data: 0.0004  max mem: 2500
Test: [Task 1]  [1350/1627]  eta: 0:01:21  Loss: 0.9046 (1.1019)  Acc@1: 68.7500 (71.8172)  Acc@5: 100.0000 (95.6051)  time: 0.4639  data: 0.0017  max mem: 2500
Test: [Task 1]  [1360/1627]  eta: 0:01:18  Loss: 0.9283 (1.1014)  Acc@1: 75.0000 (71.8360)  Acc@5: 100.0000 (95.6190)  time: 0.4586  data: 0.0018  max mem: 2500
Test: [Task 1]  [1370/1627]  eta: 0:01:15  Loss: 0.9571 (1.1008)  Acc@1: 75.0000 (71.8590)  Acc@5: 100.0000 (95.6327)  time: 0.4586  data: 0.0004  max mem: 2500
Test: [Task 1]  [1380/1627]  eta: 0:01:13  Loss: 1.0814 (1.1012)  Acc@1: 75.0000 (71.8456)  Acc@5: 100.0000 (95.6236)  time: 0.4628  data: 0.0004  max mem: 2500
Test: [Task 1]  [1390/1627]  eta: 0:01:10  Loss: 1.1155 (1.1004)  Acc@1: 68.7500 (71.8638)  Acc@5: 93.7500 (95.6237)  time: 0.4582  data: 0.0004  max mem: 2500
Test: [Task 1]  [1400/1627]  eta: 0:01:07  Loss: 1.1155 (1.1006)  Acc@1: 75.0000 (71.8594)  Acc@5: 93.7500 (95.6103)  time: 0.4569  data: 0.0004  max mem: 2500
Test: [Task 1]  [1410/1627]  eta: 0:01:05  Loss: 0.9197 (1.1000)  Acc@1: 75.0000 (71.8949)  Acc@5: 93.7500 (95.6192)  time: 0.4293  data: 0.0003  max mem: 2500
Test: [Task 1]  [1420/1627]  eta: 0:01:02  Loss: 1.0183 (1.1000)  Acc@1: 68.7500 (71.8772)  Acc@5: 100.0000 (95.6369)  time: 0.4271  data: 0.0003  max mem: 2500
Test: [Task 1]  [1430/1627]  eta: 0:00:59  Loss: 1.2577 (1.1017)  Acc@1: 68.7500 (71.8379)  Acc@5: 93.7500 (95.6019)  time: 0.4574  data: 0.0003  max mem: 2500
Test: [Task 1]  [1440/1627]  eta: 0:00:56  Loss: 1.1187 (1.1012)  Acc@1: 68.7500 (71.8338)  Acc@5: 93.7500 (95.6237)  time: 0.4618  data: 0.0004  max mem: 2500
Test: [Task 1]  [1450/1627]  eta: 0:00:53  Loss: 1.1473 (1.1027)  Acc@1: 68.7500 (71.7910)  Acc@5: 100.0000 (95.6108)  time: 0.4628  data: 0.0004  max mem: 2500
Test: [Task 1]  [1460/1627]  eta: 0:00:50  Loss: 1.2482 (1.1030)  Acc@1: 68.7500 (71.7830)  Acc@5: 93.7500 (95.5980)  time: 0.4601  data: 0.0005  max mem: 2500
Test: [Task 1]  [1470/1627]  eta: 0:00:48  Loss: 1.1226 (1.1036)  Acc@1: 68.7500 (71.7497)  Acc@5: 93.7500 (95.5897)  time: 0.4585  data: 0.0004  max mem: 2500
Test: [Task 1]  [1480/1627]  eta: 0:00:45  Loss: 1.1252 (1.1039)  Acc@1: 68.7500 (71.7252)  Acc@5: 100.0000 (95.5900)  time: 0.4613  data: 0.0010  max mem: 2500
Test: [Task 1]  [1490/1627]  eta: 0:00:42  Loss: 1.1252 (1.1042)  Acc@1: 68.7500 (71.7262)  Acc@5: 100.0000 (95.5944)  time: 0.4646  data: 0.0010  max mem: 2500
Test: [Task 1]  [1500/1627]  eta: 0:00:39  Loss: 1.0974 (1.1042)  Acc@1: 75.0000 (71.7313)  Acc@5: 93.7500 (95.5863)  time: 0.4662  data: 0.0004  max mem: 2500
Test: [Task 1]  [1510/1627]  eta: 0:00:36  Loss: 0.9764 (1.1044)  Acc@1: 75.0000 (71.7282)  Acc@5: 93.7500 (95.5824)  time: 0.4680  data: 0.0007  max mem: 2500
Test: [Task 1]  [1520/1627]  eta: 0:00:33  Loss: 0.9764 (1.1033)  Acc@1: 68.7500 (71.7579)  Acc@5: 93.7500 (95.5950)  time: 0.4637  data: 0.0008  max mem: 2500
Test: [Task 1]  [1530/1627]  eta: 0:00:30  Loss: 1.0168 (1.1031)  Acc@1: 68.7500 (71.7505)  Acc@5: 100.0000 (95.6074)  time: 0.4587  data: 0.0009  max mem: 2500
Test: [Task 1]  [1540/1627]  eta: 0:00:27  Loss: 0.9002 (1.1023)  Acc@1: 68.7500 (71.7472)  Acc@5: 100.0000 (95.6157)  time: 0.4586  data: 0.0007  max mem: 2500
Test: [Task 1]  [1550/1627]  eta: 0:00:24  Loss: 0.9002 (1.1020)  Acc@1: 75.0000 (71.7642)  Acc@5: 100.0000 (95.6198)  time: 0.4607  data: 0.0011  max mem: 2500
Test: [Task 1]  [1560/1627]  eta: 0:00:21  Loss: 0.8562 (1.1008)  Acc@1: 81.2500 (71.8290)  Acc@5: 93.7500 (95.6238)  time: 0.4626  data: 0.0009  max mem: 2500
Test: [Task 1]  [1570/1627]  eta: 0:00:18  Loss: 0.9395 (1.1007)  Acc@1: 81.2500 (71.8571)  Acc@5: 93.7500 (95.6158)  time: 0.4615  data: 0.0002  max mem: 2500
Test: [Task 1]  [1580/1627]  eta: 0:00:14  Loss: 0.9930 (1.1005)  Acc@1: 75.0000 (71.8691)  Acc@5: 100.0000 (95.6199)  time: 0.4639  data: 0.0018  max mem: 2500
Test: [Task 1]  [1590/1627]  eta: 0:00:11  Loss: 1.0462 (1.1007)  Acc@1: 68.7500 (71.8613)  Acc@5: 100.0000 (95.6277)  time: 0.4629  data: 0.0019  max mem: 2500
Test: [Task 1]  [1600/1627]  eta: 0:00:08  Loss: 1.1126 (1.1016)  Acc@1: 68.7500 (71.8340)  Acc@5: 93.7500 (95.6082)  time: 0.4578  data: 0.0009  max mem: 2500
Test: [Task 1]  [1610/1627]  eta: 0:00:05  Loss: 1.1126 (1.1011)  Acc@1: 68.7500 (71.8498)  Acc@5: 93.7500 (95.6122)  time: 0.4037  data: 0.0010  max mem: 2500
Test: [Task 1]  [1620/1627]  eta: 0:00:02  Loss: 0.9227 (1.1001)  Acc@1: 75.0000 (71.9001)  Acc@5: 100.0000 (95.6123)  time: 0.2849  data: 0.0009  max mem: 2500
Test: [Task 1]  [1626/1627]  eta: 0:00:00  Loss: 0.8529 (1.0993)  Acc@1: 75.0000 (71.9307)  Acc@5: 93.7500 (95.6093)  time: 0.2185  data: 0.0008  max mem: 2500
Test: [Task 1] Total time: 0:08:38 (0.3184 s / it)
* Acc@1 71.931 Acc@5 95.609 loss 1.099
Test: [Task 2]  [  0/625]  eta: 0:08:49  Loss: 0.1494 (0.1494)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)  time: 0.8470  data: 0.6315  max mem: 2500
Test: [Task 2]  [ 10/625]  eta: 0:02:49  Loss: 0.2098 (0.2435)  Acc@1: 93.7500 (95.4545)  Acc@5: 100.0000 (98.8636)  time: 0.2754  data: 0.0589  max mem: 2500
Test: [Task 2]  [ 20/625]  eta: 0:02:29  Loss: 0.1671 (0.2364)  Acc@1: 93.7500 (95.5357)  Acc@5: 100.0000 (99.4048)  time: 0.2171  data: 0.0010  max mem: 2500
Test: [Task 2]  [ 30/625]  eta: 0:02:20  Loss: 0.1925 (0.2578)  Acc@1: 93.7500 (93.9516)  Acc@5: 100.0000 (99.5968)  time: 0.2158  data: 0.0004  max mem: 2500
Test: [Task 2]  [ 40/625]  eta: 0:02:15  Loss: 0.2642 (0.2613)  Acc@1: 93.7500 (94.3598)  Acc@5: 100.0000 (99.6951)  time: 0.2157  data: 0.0004  max mem: 2500
Test: [Task 2]  [ 50/625]  eta: 0:02:11  Loss: 0.2713 (0.2732)  Acc@1: 93.7500 (93.9951)  Acc@5: 100.0000 (99.6324)  time: 0.2166  data: 0.0008  max mem: 2500
Test: [Task 2]  [ 60/625]  eta: 0:02:08  Loss: 0.2486 (0.2764)  Acc@1: 93.7500 (93.5451)  Acc@5: 100.0000 (99.5902)  time: 0.2212  data: 0.0027  max mem: 2500
Test: [Task 2]  [ 70/625]  eta: 0:02:06  Loss: 0.2180 (0.2723)  Acc@1: 93.7500 (93.5739)  Acc@5: 100.0000 (99.5599)  time: 0.2228  data: 0.0036  max mem: 2500
Test: [Task 2]  [ 80/625]  eta: 0:02:03  Loss: 0.2521 (0.2805)  Acc@1: 93.7500 (93.3642)  Acc@5: 100.0000 (99.3827)  time: 0.2185  data: 0.0023  max mem: 2500
Test: [Task 2]  [ 90/625]  eta: 0:02:00  Loss: 0.2780 (0.2757)  Acc@1: 93.7500 (93.4753)  Acc@5: 100.0000 (99.4505)  time: 0.2158  data: 0.0009  max mem: 2500
Test: [Task 2]  [100/625]  eta: 0:01:57  Loss: 0.2516 (0.2758)  Acc@1: 93.7500 (93.4406)  Acc@5: 100.0000 (99.4431)  time: 0.2152  data: 0.0003  max mem: 2500
Test: [Task 2]  [110/625]  eta: 0:01:54  Loss: 0.1919 (0.2745)  Acc@1: 93.7500 (93.5248)  Acc@5: 100.0000 (99.4932)  time: 0.2151  data: 0.0003  max mem: 2500
Test: [Task 2]  [120/625]  eta: 0:01:52  Loss: 0.2001 (0.2764)  Acc@1: 93.7500 (93.4401)  Acc@5: 100.0000 (99.4318)  time: 0.2154  data: 0.0003  max mem: 2500
Test: [Task 2]  [130/625]  eta: 0:01:49  Loss: 0.2303 (0.2762)  Acc@1: 93.7500 (93.4637)  Acc@5: 100.0000 (99.4752)  time: 0.2158  data: 0.0004  max mem: 2500
Test: [Task 2]  [140/625]  eta: 0:01:47  Loss: 0.2254 (0.2800)  Acc@1: 93.7500 (93.2181)  Acc@5: 100.0000 (99.4681)  time: 0.2176  data: 0.0010  max mem: 2500
Test: [Task 2]  [150/625]  eta: 0:01:45  Loss: 0.2320 (0.2856)  Acc@1: 87.5000 (92.8394)  Acc@5: 100.0000 (99.5033)  time: 0.2173  data: 0.0009  max mem: 2500
Test: [Task 2]  [160/625]  eta: 0:01:42  Loss: 0.2460 (0.2901)  Acc@1: 93.7500 (92.8183)  Acc@5: 100.0000 (99.4177)  time: 0.2155  data: 0.0003  max mem: 2500
Test: [Task 2]  [170/625]  eta: 0:01:40  Loss: 0.2460 (0.2906)  Acc@1: 93.7500 (92.7266)  Acc@5: 100.0000 (99.4152)  time: 0.2149  data: 0.0003  max mem: 2500
Test: [Task 2]  [180/625]  eta: 0:01:37  Loss: 0.2028 (0.2900)  Acc@1: 93.7500 (92.6796)  Acc@5: 100.0000 (99.4475)  time: 0.2143  data: 0.0003  max mem: 2500
Test: [Task 2]  [190/625]  eta: 0:01:35  Loss: 0.2359 (0.2914)  Acc@1: 93.7500 (92.7029)  Acc@5: 100.0000 (99.4437)  time: 0.2145  data: 0.0002  max mem: 2500
Test: [Task 2]  [200/625]  eta: 0:01:33  Loss: 0.2672 (0.2902)  Acc@1: 93.7500 (92.6928)  Acc@5: 100.0000 (99.4714)  time: 0.2161  data: 0.0012  max mem: 2500
Test: [Task 2]  [210/625]  eta: 0:01:31  Loss: 0.2335 (0.2906)  Acc@1: 93.7500 (92.6244)  Acc@5: 100.0000 (99.4668)  time: 0.2158  data: 0.0013  max mem: 2500
Test: [Task 2]  [220/625]  eta: 0:01:28  Loss: 0.1926 (0.2877)  Acc@1: 93.7500 (92.7602)  Acc@5: 100.0000 (99.4910)  time: 0.2140  data: 0.0003  max mem: 2500
Test: [Task 2]  [230/625]  eta: 0:01:26  Loss: 0.1900 (0.2869)  Acc@1: 100.0000 (92.8301)  Acc@5: 100.0000 (99.5130)  time: 0.2141  data: 0.0002  max mem: 2500
Test: [Task 2]  [240/625]  eta: 0:01:24  Loss: 0.2744 (0.2877)  Acc@1: 93.7500 (92.7905)  Acc@5: 100.0000 (99.5332)  time: 0.2142  data: 0.0002  max mem: 2500
Test: [Task 2]  [250/625]  eta: 0:01:22  Loss: 0.3127 (0.2908)  Acc@1: 87.5000 (92.6295)  Acc@5: 100.0000 (99.5269)  time: 0.2143  data: 0.0003  max mem: 2500
Test: [Task 2]  [260/625]  eta: 0:01:19  Loss: 0.3157 (0.2928)  Acc@1: 87.5000 (92.5048)  Acc@5: 100.0000 (99.5211)  time: 0.2195  data: 0.0011  max mem: 2500
Test: [Task 2]  [270/625]  eta: 0:01:17  Loss: 0.3157 (0.2926)  Acc@1: 87.5000 (92.5507)  Acc@5: 100.0000 (99.5157)  time: 0.2213  data: 0.0012  max mem: 2500
Test: [Task 2]  [280/625]  eta: 0:01:15  Loss: 0.2648 (0.2941)  Acc@1: 93.7500 (92.4822)  Acc@5: 100.0000 (99.4662)  time: 0.2166  data: 0.0004  max mem: 2500
Test: [Task 2]  [290/625]  eta: 0:01:13  Loss: 0.2648 (0.2934)  Acc@1: 93.7500 (92.4828)  Acc@5: 100.0000 (99.4631)  time: 0.2154  data: 0.0004  max mem: 2500
Test: [Task 2]  [300/625]  eta: 0:01:11  Loss: 0.2742 (0.2943)  Acc@1: 93.7500 (92.4003)  Acc@5: 100.0000 (99.4809)  time: 0.2162  data: 0.0005  max mem: 2500
Test: [Task 2]  [310/625]  eta: 0:01:08  Loss: 0.2981 (0.2963)  Acc@1: 93.7500 (92.3432)  Acc@5: 100.0000 (99.4775)  time: 0.2170  data: 0.0005  max mem: 2500
Test: [Task 2]  [320/625]  eta: 0:01:06  Loss: 0.1407 (0.2900)  Acc@1: 100.0000 (92.5623)  Acc@5: 100.0000 (99.4938)  time: 0.2177  data: 0.0005  max mem: 2500
Test: [Task 2]  [330/625]  eta: 0:01:04  Loss: 0.1069 (0.2859)  Acc@1: 100.0000 (92.7115)  Acc@5: 100.0000 (99.5091)  time: 0.2198  data: 0.0012  max mem: 2500
Test: [Task 2]  [340/625]  eta: 0:01:02  Loss: 0.0895 (0.2794)  Acc@1: 100.0000 (92.9069)  Acc@5: 100.0000 (99.5235)  time: 0.2224  data: 0.0013  max mem: 2500
Test: [Task 2]  [350/625]  eta: 0:01:00  Loss: 0.0596 (0.2762)  Acc@1: 100.0000 (92.9665)  Acc@5: 100.0000 (99.5370)  time: 0.2215  data: 0.0006  max mem: 2500
Test: [Task 2]  [360/625]  eta: 0:00:57  Loss: 0.2105 (0.2771)  Acc@1: 93.7500 (92.9882)  Acc@5: 100.0000 (99.5325)  time: 0.2175  data: 0.0004  max mem: 2500
Test: [Task 2]  [370/625]  eta: 0:00:55  Loss: 0.1432 (0.2738)  Acc@1: 93.7500 (93.1267)  Acc@5: 100.0000 (99.5451)  time: 0.2157  data: 0.0004  max mem: 2500
Test: [Task 2]  [380/625]  eta: 0:00:53  Loss: 0.2843 (0.2777)  Acc@1: 93.7500 (93.0446)  Acc@5: 100.0000 (99.4915)  time: 0.2162  data: 0.0004  max mem: 2500
Test: [Task 2]  [390/625]  eta: 0:00:51  Loss: 0.2847 (0.2772)  Acc@1: 93.7500 (93.0307)  Acc@5: 100.0000 (99.4725)  time: 0.2170  data: 0.0004  max mem: 2500
Test: [Task 2]  [400/625]  eta: 0:00:49  Loss: 0.0952 (0.2737)  Acc@1: 93.7500 (93.1421)  Acc@5: 100.0000 (99.4857)  time: 0.2198  data: 0.0004  max mem: 2500
Test: [Task 2]  [410/625]  eta: 0:00:46  Loss: 0.0724 (0.2715)  Acc@1: 100.0000 (93.1873)  Acc@5: 100.0000 (99.4678)  time: 0.2197  data: 0.0004  max mem: 2500
Test: [Task 2]  [420/625]  eta: 0:00:44  Loss: 0.0975 (0.2708)  Acc@1: 93.7500 (93.2156)  Acc@5: 100.0000 (99.4804)  time: 0.2164  data: 0.0003  max mem: 2500
Test: [Task 2]  [430/625]  eta: 0:00:42  Loss: 0.1281 (0.2678)  Acc@1: 93.7500 (93.3005)  Acc@5: 100.0000 (99.4925)  time: 0.2156  data: 0.0003  max mem: 2500
Test: [Task 2]  [440/625]  eta: 0:00:40  Loss: 0.0777 (0.2633)  Acc@1: 100.0000 (93.4524)  Acc@5: 100.0000 (99.5040)  time: 0.2172  data: 0.0003  max mem: 2500
Test: [Task 2]  [450/625]  eta: 0:00:38  Loss: 0.0720 (0.2600)  Acc@1: 100.0000 (93.4867)  Acc@5: 100.0000 (99.5150)  time: 0.2168  data: 0.0004  max mem: 2500
Test: [Task 2]  [460/625]  eta: 0:00:36  Loss: 0.1009 (0.2565)  Acc@1: 100.0000 (93.6009)  Acc@5: 100.0000 (99.5255)  time: 0.2153  data: 0.0004  max mem: 2500
Test: [Task 2]  [470/625]  eta: 0:00:33  Loss: 0.1237 (0.2539)  Acc@1: 100.0000 (93.7235)  Acc@5: 100.0000 (99.5356)  time: 0.2153  data: 0.0003  max mem: 2500
Test: [Task 2]  [480/625]  eta: 0:00:31  Loss: 0.1400 (0.2529)  Acc@1: 100.0000 (93.7760)  Acc@5: 100.0000 (99.5452)  time: 0.2151  data: 0.0003  max mem: 2500
Test: [Task 2]  [490/625]  eta: 0:00:29  Loss: 0.1310 (0.2505)  Acc@1: 100.0000 (93.8518)  Acc@5: 100.0000 (99.5545)  time: 0.2158  data: 0.0009  max mem: 2500
Test: [Task 2]  [500/625]  eta: 0:00:27  Loss: 0.1050 (0.2485)  Acc@1: 100.0000 (93.8997)  Acc@5: 100.0000 (99.5634)  time: 0.2155  data: 0.0011  max mem: 2500
Test: [Task 2]  [510/625]  eta: 0:00:25  Loss: 0.1605 (0.2498)  Acc@1: 93.7500 (93.7989)  Acc@5: 100.0000 (99.5597)  time: 0.2146  data: 0.0005  max mem: 2500
Test: [Task 2]  [520/625]  eta: 0:00:22  Loss: 0.1901 (0.2493)  Acc@1: 93.7500 (93.8220)  Acc@5: 100.0000 (99.5681)  time: 0.2149  data: 0.0003  max mem: 2500
Test: [Task 2]  [530/625]  eta: 0:00:20  Loss: 0.1560 (0.2472)  Acc@1: 100.0000 (93.8912)  Acc@5: 100.0000 (99.5763)  time: 0.2154  data: 0.0003  max mem: 2500
Test: [Task 2]  [540/625]  eta: 0:00:18  Loss: 0.1099 (0.2453)  Acc@1: 100.0000 (93.9695)  Acc@5: 100.0000 (99.5841)  time: 0.2149  data: 0.0003  max mem: 2500
Test: [Task 2]  [550/625]  eta: 0:00:16  Loss: 0.0732 (0.2422)  Acc@1: 100.0000 (94.0563)  Acc@5: 100.0000 (99.5917)  time: 0.2145  data: 0.0005  max mem: 2500
Test: [Task 2]  [560/625]  eta: 0:00:14  Loss: 0.0505 (0.2387)  Acc@1: 100.0000 (94.1622)  Acc@5: 100.0000 (99.5989)  time: 0.2148  data: 0.0005  max mem: 2500
Test: [Task 2]  [570/625]  eta: 0:00:11  Loss: 0.0517 (0.2372)  Acc@1: 100.0000 (94.2207)  Acc@5: 100.0000 (99.6060)  time: 0.2163  data: 0.0004  max mem: 2500
Test: [Task 2]  [580/625]  eta: 0:00:09  Loss: 0.0721 (0.2345)  Acc@1: 100.0000 (94.2986)  Acc@5: 100.0000 (99.6127)  time: 0.2183  data: 0.0006  max mem: 2500
Test: [Task 2]  [590/625]  eta: 0:00:07  Loss: 0.1015 (0.2336)  Acc@1: 100.0000 (94.2999)  Acc@5: 100.0000 (99.6193)  time: 0.2189  data: 0.0005  max mem: 2500
Test: [Task 2]  [600/625]  eta: 0:00:05  Loss: 0.1716 (0.2334)  Acc@1: 93.7500 (94.2908)  Acc@5: 100.0000 (99.6256)  time: 0.2212  data: 0.0013  max mem: 2500
Test: [Task 2]  [610/625]  eta: 0:00:03  Loss: 0.2615 (0.2361)  Acc@1: 93.7500 (94.2615)  Acc@5: 100.0000 (99.5908)  time: 0.2226  data: 0.0034  max mem: 2500
Test: [Task 2]  [620/625]  eta: 0:00:01  Loss: 0.2705 (0.2361)  Acc@1: 93.7500 (94.2633)  Acc@5: 100.0000 (99.5974)  time: 0.2207  data: 0.0032  max mem: 2500
Test: [Task 2]  [624/625]  eta: 0:00:00  Loss: 0.2622 (0.2358)  Acc@1: 93.7500 (94.2700)  Acc@5: 100.0000 (99.6000)  time: 0.2195  data: 0.0025  max mem: 2500
Test: [Task 2] Total time: 0:02:16 (0.2182 s / it)
* Acc@1 94.270 Acc@5 99.600 loss 0.236
{0: {0: 26032, 1: 26032, 2: 26032, 3: 26032, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0, 10: 0, 11: 0, 12: 0, 13: 0, 14: 0, 15: 0, 16: 0, 17: 0, 18: 0, 19: 0}, 1: {0: 0, 1: 0, 2: 0, 3: 0, 4: 10000, 5: 10000, 6: 10000, 7: 10000, 8: 0, 9: 0, 10: 0, 11: 0, 12: 0, 13: 0, 14: 0, 15: 0, 16: 0, 17: 0, 18: 0, 19: 0}}
[Average accuracy till task2]	Acc@1: 83.1004	Acc@5: 97.6046	Loss: 0.6676	Forgetting: 13.4373	Backward: -13.4373
Train: Epoch[1/5]  [   0/3125]  eta: 1:02:20  Lr: 0.001875  Loss: 1.6147  Acc@1: 12.5000 (12.5000)  Acc@5: 43.7500 (43.7500)  time: 1.1968  data: 0.8286  max mem: 2500
Train: Epoch[1/5]  [  10/3125]  eta: 0:22:57  Lr: 0.001875  Loss: 1.3348  Acc@1: 25.0000 (26.7045)  Acc@5: 62.5000 (63.0682)  time: 0.4422  data: 0.0762  max mem: 2502
Train: Epoch[1/5]  [  20/3125]  eta: 0:20:43  Lr: 0.001875  Loss: 1.1621  Acc@1: 37.5000 (40.1786)  Acc@5: 75.0000 (74.7024)  time: 0.3605  data: 0.0008  max mem: 2502
Train: Epoch[1/5]  [  30/3125]  eta: 0:19:56  Lr: 0.001875  Loss: 0.8796  Acc@1: 50.0000 (44.3548)  Acc@5: 87.5000 (78.8306)  time: 0.3561  data: 0.0007  max mem: 2502
Train: Epoch[1/5]  [  40/3125]  eta: 0:19:24  Lr: 0.001875  Loss: 0.5022  Acc@1: 56.2500 (48.7805)  Acc@5: 93.7500 (82.0122)  time: 0.3534  data: 0.0011  max mem: 2502
Train: Epoch[1/5]  [  50/3125]  eta: 0:19:32  Lr: 0.001875  Loss: 0.3574  Acc@1: 68.7500 (53.4314)  Acc@5: 93.7500 (84.8039)  time: 0.3728  data: 0.0011  max mem: 2502
Train: Epoch[1/5]  [  60/3125]  eta: 0:22:34  Lr: 0.001875  Loss: 0.7003  Acc@1: 68.7500 (54.8156)  Acc@5: 100.0000 (85.9631)  time: 0.5737  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [  70/3125]  eta: 0:24:40  Lr: 0.001875  Loss: 0.4714  Acc@1: 68.7500 (57.1303)  Acc@5: 93.7500 (87.3239)  time: 0.7482  data: 0.0006  max mem: 2502
Train: Epoch[1/5]  [  80/3125]  eta: 0:26:13  Lr: 0.001875  Loss: 0.0875  Acc@1: 68.7500 (58.2562)  Acc@5: 93.7500 (88.5031)  time: 0.7456  data: 0.0006  max mem: 2502
Train: Epoch[1/5]  [  90/3125]  eta: 0:27:23  Lr: 0.001875  Loss: 0.0227  Acc@1: 68.7500 (59.0659)  Acc@5: 93.7500 (89.0110)  time: 0.7441  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [ 100/3125]  eta: 0:27:38  Lr: 0.001875  Loss: 0.0278  Acc@1: 68.7500 (60.8911)  Acc@5: 93.7500 (89.5421)  time: 0.6754  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [ 110/3125]  eta: 0:26:39  Lr: 0.001875  Loss: 0.2977  Acc@1: 75.0000 (61.8243)  Acc@5: 93.7500 (90.0901)  time: 0.4798  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [ 120/3125]  eta: 0:25:49  Lr: 0.001875  Loss: 0.0122  Acc@1: 68.7500 (62.5000)  Acc@5: 93.7500 (90.5475)  time: 0.3503  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [ 130/3125]  eta: 0:25:05  Lr: 0.001875  Loss: 0.0074  Acc@1: 68.7500 (62.8340)  Acc@5: 93.7500 (90.6966)  time: 0.3493  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [ 140/3125]  eta: 0:24:29  Lr: 0.001875  Loss: -0.0111  Acc@1: 68.7500 (63.5195)  Acc@5: 93.7500 (91.0904)  time: 0.3523  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [ 150/3125]  eta: 0:23:57  Lr: 0.001875  Loss: -0.5184  Acc@1: 75.0000 (64.2798)  Acc@5: 100.0000 (91.4735)  time: 0.3542  data: 0.0012  max mem: 2502
Train: Epoch[1/5]  [ 160/3125]  eta: 0:23:28  Lr: 0.001875  Loss: -0.2213  Acc@1: 68.7500 (64.7516)  Acc@5: 93.7500 (91.6149)  time: 0.3535  data: 0.0023  max mem: 2502
Train: Epoch[1/5]  [ 170/3125]  eta: 0:23:02  Lr: 0.001875  Loss: -0.2161  Acc@1: 75.0000 (65.4971)  Acc@5: 93.7500 (91.9591)  time: 0.3536  data: 0.0017  max mem: 2502
Train: Epoch[1/5]  [ 180/3125]  eta: 0:22:38  Lr: 0.001875  Loss: 0.1194  Acc@1: 81.2500 (66.2638)  Acc@5: 100.0000 (92.2307)  time: 0.3503  data: 0.0006  max mem: 2502
Train: Epoch[1/5]  [ 190/3125]  eta: 0:22:16  Lr: 0.001875  Loss: -0.1165  Acc@1: 75.0000 (66.3285)  Acc@5: 100.0000 (92.3429)  time: 0.3489  data: 0.0007  max mem: 2502
Train: Epoch[1/5]  [ 200/3125]  eta: 0:21:57  Lr: 0.001875  Loss: -0.0289  Acc@1: 75.0000 (66.9465)  Acc@5: 100.0000 (92.6928)  time: 0.3513  data: 0.0007  max mem: 2502
Train: Epoch[1/5]  [ 210/3125]  eta: 0:21:39  Lr: 0.001875  Loss: -0.3473  Acc@1: 75.0000 (67.3282)  Acc@5: 100.0000 (92.9206)  time: 0.3517  data: 0.0013  max mem: 2502
Train: Epoch[1/5]  [ 220/3125]  eta: 0:21:21  Lr: 0.001875  Loss: -0.0670  Acc@1: 75.0000 (67.6753)  Acc@5: 100.0000 (93.1561)  time: 0.3495  data: 0.0011  max mem: 2502
Train: Epoch[1/5]  [ 230/3125]  eta: 0:21:05  Lr: 0.001875  Loss: -0.3856  Acc@1: 75.0000 (68.0465)  Acc@5: 100.0000 (93.2900)  time: 0.3488  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [ 240/3125]  eta: 0:20:50  Lr: 0.001875  Loss: -0.2106  Acc@1: 75.0000 (68.5425)  Acc@5: 100.0000 (93.4647)  time: 0.3494  data: 0.0008  max mem: 2502
Train: Epoch[1/5]  [ 250/3125]  eta: 0:20:37  Lr: 0.001875  Loss: -0.0117  Acc@1: 81.2500 (68.8496)  Acc@5: 100.0000 (93.5757)  time: 0.3494  data: 0.0007  max mem: 2502
Train: Epoch[1/5]  [ 260/3125]  eta: 0:20:23  Lr: 0.001875  Loss: -0.3397  Acc@1: 81.2500 (69.1571)  Acc@5: 100.0000 (93.7261)  time: 0.3475  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [ 270/3125]  eta: 0:20:10  Lr: 0.001875  Loss: -0.1941  Acc@1: 75.0000 (69.3727)  Acc@5: 93.7500 (93.7961)  time: 0.3449  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [ 280/3125]  eta: 0:19:58  Lr: 0.001875  Loss: -0.0091  Acc@1: 75.0000 (69.4395)  Acc@5: 93.7500 (93.8612)  time: 0.3462  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [ 290/3125]  eta: 0:19:47  Lr: 0.001875  Loss: -0.3458  Acc@1: 75.0000 (69.5876)  Acc@5: 100.0000 (94.0292)  time: 0.3486  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [ 300/3125]  eta: 0:19:36  Lr: 0.001875  Loss: -0.2717  Acc@1: 75.0000 (69.8297)  Acc@5: 100.0000 (94.0822)  time: 0.3476  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [ 310/3125]  eta: 0:19:26  Lr: 0.001875  Loss: 0.0718  Acc@1: 75.0000 (69.9960)  Acc@5: 93.7500 (94.1519)  time: 0.3482  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [ 320/3125]  eta: 0:19:16  Lr: 0.001875  Loss: -0.0905  Acc@1: 75.0000 (70.1713)  Acc@5: 100.0000 (94.2173)  time: 0.3524  data: 0.0018  max mem: 2502
Train: Epoch[1/5]  [ 330/3125]  eta: 0:19:08  Lr: 0.001875  Loss: 0.3591  Acc@1: 81.2500 (70.5249)  Acc@5: 100.0000 (94.3353)  time: 0.3561  data: 0.0018  max mem: 2502
Train: Epoch[1/5]  [ 340/3125]  eta: 0:18:59  Lr: 0.001875  Loss: -0.6336  Acc@1: 81.2500 (70.6195)  Acc@5: 100.0000 (94.3915)  time: 0.3544  data: 0.0013  max mem: 2502
Train: Epoch[1/5]  [ 350/3125]  eta: 0:18:50  Lr: 0.001875  Loss: -0.3040  Acc@1: 81.2500 (70.8511)  Acc@5: 100.0000 (94.4623)  time: 0.3503  data: 0.0012  max mem: 2502
Train: Epoch[1/5]  [ 360/3125]  eta: 0:18:41  Lr: 0.001875  Loss: -0.0234  Acc@1: 81.2500 (71.1046)  Acc@5: 100.0000 (94.4945)  time: 0.3504  data: 0.0007  max mem: 2502
Train: Epoch[1/5]  [ 370/3125]  eta: 0:18:33  Lr: 0.001875  Loss: 0.1623  Acc@1: 81.2500 (71.3443)  Acc@5: 93.7500 (94.4912)  time: 0.3510  data: 0.0008  max mem: 2502
Train: Epoch[1/5]  [ 380/3125]  eta: 0:18:26  Lr: 0.001875  Loss: -0.4727  Acc@1: 87.5000 (71.6864)  Acc@5: 93.7500 (94.5538)  time: 0.3540  data: 0.0011  max mem: 2502
Train: Epoch[1/5]  [ 390/3125]  eta: 0:18:18  Lr: 0.001875  Loss: 0.0343  Acc@1: 81.2500 (71.8350)  Acc@5: 93.7500 (94.5492)  time: 0.3543  data: 0.0011  max mem: 2502
Train: Epoch[1/5]  [ 400/3125]  eta: 0:18:11  Lr: 0.001875  Loss: -0.2675  Acc@1: 81.2500 (72.0854)  Acc@5: 100.0000 (94.5916)  time: 0.3505  data: 0.0006  max mem: 2502
Train: Epoch[1/5]  [ 410/3125]  eta: 0:18:03  Lr: 0.001875  Loss: -0.1571  Acc@1: 81.2500 (72.3084)  Acc@5: 100.0000 (94.6624)  time: 0.3482  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [ 420/3125]  eta: 0:17:56  Lr: 0.001875  Loss: -0.0062  Acc@1: 81.2500 (72.4020)  Acc@5: 100.0000 (94.7150)  time: 0.3507  data: 0.0011  max mem: 2502
Train: Epoch[1/5]  [ 430/3125]  eta: 0:17:49  Lr: 0.001875  Loss: -0.3563  Acc@1: 81.2500 (72.5928)  Acc@5: 100.0000 (94.7796)  time: 0.3520  data: 0.0023  max mem: 2502
Train: Epoch[1/5]  [ 440/3125]  eta: 0:17:42  Lr: 0.001875  Loss: 0.1187  Acc@1: 75.0000 (72.5907)  Acc@5: 100.0000 (94.7988)  time: 0.3485  data: 0.0016  max mem: 2502
Train: Epoch[1/5]  [ 450/3125]  eta: 0:17:35  Lr: 0.001875  Loss: -0.3333  Acc@1: 75.0000 (72.7966)  Acc@5: 100.0000 (94.8586)  time: 0.3475  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [ 460/3125]  eta: 0:17:29  Lr: 0.001875  Loss: -0.4270  Acc@1: 81.2500 (72.8715)  Acc@5: 100.0000 (94.9295)  time: 0.3490  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [ 470/3125]  eta: 0:17:23  Lr: 0.001875  Loss: -0.1890  Acc@1: 75.0000 (72.9565)  Acc@5: 100.0000 (95.0106)  time: 0.3513  data: 0.0023  max mem: 2502
Train: Epoch[1/5]  [ 480/3125]  eta: 0:17:16  Lr: 0.001875  Loss: -0.1960  Acc@1: 81.2500 (73.1029)  Acc@5: 100.0000 (95.0754)  time: 0.3485  data: 0.0023  max mem: 2502
Train: Epoch[1/5]  [ 490/3125]  eta: 0:17:10  Lr: 0.001875  Loss: -0.5532  Acc@1: 81.2500 (73.2561)  Acc@5: 100.0000 (95.1375)  time: 0.3454  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [ 500/3125]  eta: 0:17:04  Lr: 0.001875  Loss: -0.3263  Acc@1: 81.2500 (73.4032)  Acc@5: 100.0000 (95.2345)  time: 0.3508  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [ 510/3125]  eta: 0:16:58  Lr: 0.001875  Loss: -0.7163  Acc@1: 81.2500 (73.5078)  Acc@5: 100.0000 (95.2911)  time: 0.3561  data: 0.0011  max mem: 2502
Train: Epoch[1/5]  [ 520/3125]  eta: 0:16:52  Lr: 0.001875  Loss: -0.5473  Acc@1: 81.2500 (73.6444)  Acc@5: 100.0000 (95.3215)  time: 0.3524  data: 0.0012  max mem: 2502
Train: Epoch[1/5]  [ 530/3125]  eta: 0:16:47  Lr: 0.001875  Loss: -0.0417  Acc@1: 81.2500 (73.6700)  Acc@5: 100.0000 (95.3508)  time: 0.3501  data: 0.0007  max mem: 2502
Train: Epoch[1/5]  [ 540/3125]  eta: 0:16:41  Lr: 0.001875  Loss: -0.0302  Acc@1: 75.0000 (73.7061)  Acc@5: 100.0000 (95.3905)  time: 0.3528  data: 0.0007  max mem: 2502
Train: Epoch[1/5]  [ 550/3125]  eta: 0:16:36  Lr: 0.001875  Loss: -0.2451  Acc@1: 75.0000 (73.7636)  Acc@5: 93.7500 (95.4061)  time: 0.3550  data: 0.0006  max mem: 2502
Train: Epoch[1/5]  [ 560/3125]  eta: 0:16:30  Lr: 0.001875  Loss: -0.5727  Acc@1: 75.0000 (73.8748)  Acc@5: 100.0000 (95.4434)  time: 0.3538  data: 0.0006  max mem: 2502
Train: Epoch[1/5]  [ 570/3125]  eta: 0:16:25  Lr: 0.001875  Loss: -0.5370  Acc@1: 81.2500 (73.9492)  Acc@5: 100.0000 (95.4685)  time: 0.3532  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [ 580/3125]  eta: 0:16:20  Lr: 0.001875  Loss: -0.4234  Acc@1: 81.2500 (74.0534)  Acc@5: 100.0000 (95.5142)  time: 0.3559  data: 0.0008  max mem: 2502
Train: Epoch[1/5]  [ 590/3125]  eta: 0:16:14  Lr: 0.001875  Loss: -0.3987  Acc@1: 75.0000 (74.1011)  Acc@5: 100.0000 (95.5161)  time: 0.3518  data: 0.0008  max mem: 2502
Train: Epoch[1/5]  [ 600/3125]  eta: 0:16:09  Lr: 0.001875  Loss: -0.1376  Acc@1: 75.0000 (74.1785)  Acc@5: 93.7500 (95.5387)  time: 0.3494  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [ 610/3125]  eta: 0:16:04  Lr: 0.001875  Loss: -0.4571  Acc@1: 81.2500 (74.3351)  Acc@5: 100.0000 (95.5912)  time: 0.3498  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [ 620/3125]  eta: 0:15:59  Lr: 0.001875  Loss: -0.3901  Acc@1: 81.2500 (74.3156)  Acc@5: 100.0000 (95.6019)  time: 0.3493  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [ 630/3125]  eta: 0:15:54  Lr: 0.001875  Loss: -0.3261  Acc@1: 75.0000 (74.3562)  Acc@5: 100.0000 (95.6616)  time: 0.3502  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [ 640/3125]  eta: 0:15:49  Lr: 0.001875  Loss: 0.1014  Acc@1: 75.0000 (74.4052)  Acc@5: 100.0000 (95.7001)  time: 0.3512  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [ 650/3125]  eta: 0:15:43  Lr: 0.001875  Loss: -0.4528  Acc@1: 81.2500 (74.4912)  Acc@5: 100.0000 (95.6989)  time: 0.3495  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [ 660/3125]  eta: 0:15:38  Lr: 0.001875  Loss: -0.0698  Acc@1: 75.0000 (74.4989)  Acc@5: 93.7500 (95.7073)  time: 0.3455  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [ 670/3125]  eta: 0:15:33  Lr: 0.001875  Loss: -0.3465  Acc@1: 81.2500 (74.6461)  Acc@5: 100.0000 (95.7619)  time: 0.3452  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [ 680/3125]  eta: 0:15:29  Lr: 0.001875  Loss: -0.4025  Acc@1: 81.2500 (74.7338)  Acc@5: 100.0000 (95.7691)  time: 0.3547  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [ 690/3125]  eta: 0:15:24  Lr: 0.001875  Loss: -0.2239  Acc@1: 81.2500 (74.7829)  Acc@5: 93.7500 (95.7760)  time: 0.3570  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [ 700/3125]  eta: 0:15:19  Lr: 0.001875  Loss: -0.1994  Acc@1: 81.2500 (74.8484)  Acc@5: 93.7500 (95.7828)  time: 0.3498  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [ 710/3125]  eta: 0:15:14  Lr: 0.001875  Loss: -0.2601  Acc@1: 81.2500 (74.9121)  Acc@5: 93.7500 (95.7982)  time: 0.3514  data: 0.0006  max mem: 2502
Train: Epoch[1/5]  [ 720/3125]  eta: 0:15:10  Lr: 0.001875  Loss: -0.4545  Acc@1: 81.2500 (75.0173)  Acc@5: 100.0000 (95.8218)  time: 0.3531  data: 0.0007  max mem: 2502
Train: Epoch[1/5]  [ 730/3125]  eta: 0:15:05  Lr: 0.001875  Loss: -0.3717  Acc@1: 81.2500 (75.1624)  Acc@5: 100.0000 (95.8618)  time: 0.3558  data: 0.0013  max mem: 2502
Train: Epoch[1/5]  [ 740/3125]  eta: 0:15:01  Lr: 0.001875  Loss: -0.5676  Acc@1: 81.2500 (75.2024)  Acc@5: 100.0000 (95.8839)  time: 0.3555  data: 0.0019  max mem: 2502
Train: Epoch[1/5]  [ 750/3125]  eta: 0:14:56  Lr: 0.001875  Loss: -0.2197  Acc@1: 81.2500 (75.2746)  Acc@5: 100.0000 (95.8971)  time: 0.3512  data: 0.0012  max mem: 2502
Train: Epoch[1/5]  [ 760/3125]  eta: 0:14:51  Lr: 0.001875  Loss: -0.1389  Acc@1: 81.2500 (75.3367)  Acc@5: 100.0000 (95.8689)  time: 0.3492  data: 0.0006  max mem: 2502
Train: Epoch[1/5]  [ 770/3125]  eta: 0:14:47  Lr: 0.001875  Loss: -0.1652  Acc@1: 81.2500 (75.4053)  Acc@5: 100.0000 (95.9063)  time: 0.3479  data: 0.0006  max mem: 2502
Train: Epoch[1/5]  [ 780/3125]  eta: 0:14:42  Lr: 0.001875  Loss: -0.4735  Acc@1: 81.2500 (75.4722)  Acc@5: 100.0000 (95.9427)  time: 0.3480  data: 0.0006  max mem: 2502
Train: Epoch[1/5]  [ 790/3125]  eta: 0:14:38  Lr: 0.001875  Loss: -0.0844  Acc@1: 81.2500 (75.5373)  Acc@5: 100.0000 (95.9861)  time: 0.3497  data: 0.0006  max mem: 2502
Train: Epoch[1/5]  [ 800/3125]  eta: 0:14:33  Lr: 0.001875  Loss: -0.5449  Acc@1: 81.2500 (75.6242)  Acc@5: 100.0000 (96.0128)  time: 0.3495  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [ 810/3125]  eta: 0:14:28  Lr: 0.001875  Loss: -0.1538  Acc@1: 81.2500 (75.6551)  Acc@5: 100.0000 (96.0157)  time: 0.3478  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [ 820/3125]  eta: 0:14:24  Lr: 0.001875  Loss: -0.2494  Acc@1: 75.0000 (75.7080)  Acc@5: 100.0000 (96.0490)  time: 0.3500  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [ 830/3125]  eta: 0:14:19  Lr: 0.001875  Loss: -0.5035  Acc@1: 81.2500 (75.7596)  Acc@5: 100.0000 (96.0740)  time: 0.3491  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [ 840/3125]  eta: 0:14:15  Lr: 0.001875  Loss: -0.6489  Acc@1: 81.2500 (75.8323)  Acc@5: 100.0000 (96.0910)  time: 0.3461  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [ 850/3125]  eta: 0:14:10  Lr: 0.001875  Loss: -0.5995  Acc@1: 81.2500 (75.8373)  Acc@5: 100.0000 (96.0928)  time: 0.3468  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [ 860/3125]  eta: 0:14:06  Lr: 0.001875  Loss: -0.4771  Acc@1: 75.0000 (75.8420)  Acc@5: 100.0000 (96.1092)  time: 0.3513  data: 0.0011  max mem: 2502
Train: Epoch[1/5]  [ 870/3125]  eta: 0:14:02  Lr: 0.001875  Loss: -0.3840  Acc@1: 81.2500 (75.9041)  Acc@5: 100.0000 (96.0964)  time: 0.3516  data: 0.0013  max mem: 2502
Train: Epoch[1/5]  [ 880/3125]  eta: 0:13:57  Lr: 0.001875  Loss: -0.4197  Acc@1: 81.2500 (75.9152)  Acc@5: 100.0000 (96.1053)  time: 0.3488  data: 0.0009  max mem: 2502
Train: Epoch[1/5]  [ 890/3125]  eta: 0:13:53  Lr: 0.001875  Loss: -0.0013  Acc@1: 81.2500 (75.9049)  Acc@5: 100.0000 (96.0999)  time: 0.3497  data: 0.0009  max mem: 2502
Train: Epoch[1/5]  [ 900/3125]  eta: 0:13:49  Lr: 0.001875  Loss: -0.2339  Acc@1: 81.2500 (75.9295)  Acc@5: 93.7500 (96.1085)  time: 0.3561  data: 0.0012  max mem: 2502
Train: Epoch[1/5]  [ 910/3125]  eta: 0:13:45  Lr: 0.001875  Loss: -0.6106  Acc@1: 81.2500 (75.9536)  Acc@5: 100.0000 (96.1238)  time: 0.3569  data: 0.0012  max mem: 2502
Train: Epoch[1/5]  [ 920/3125]  eta: 0:13:41  Lr: 0.001875  Loss: -0.3707  Acc@1: 81.2500 (76.0315)  Acc@5: 100.0000 (96.1387)  time: 0.3500  data: 0.0007  max mem: 2502
Train: Epoch[1/5]  [ 930/3125]  eta: 0:13:36  Lr: 0.001875  Loss: -0.2408  Acc@1: 87.5000 (76.1211)  Acc@5: 100.0000 (96.1533)  time: 0.3487  data: 0.0006  max mem: 2502
Train: Epoch[1/5]  [ 940/3125]  eta: 0:13:32  Lr: 0.001875  Loss: -0.5340  Acc@1: 87.5000 (76.2022)  Acc@5: 100.0000 (96.1876)  time: 0.3496  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [ 950/3125]  eta: 0:13:28  Lr: 0.001875  Loss: -0.4366  Acc@1: 81.2500 (76.2487)  Acc@5: 100.0000 (96.1948)  time: 0.3545  data: 0.0008  max mem: 2502
Train: Epoch[1/5]  [ 960/3125]  eta: 0:13:24  Lr: 0.001875  Loss: -0.5274  Acc@1: 81.2500 (76.3072)  Acc@5: 100.0000 (96.2149)  time: 0.3584  data: 0.0016  max mem: 2502
Train: Epoch[1/5]  [ 970/3125]  eta: 0:13:20  Lr: 0.001875  Loss: -0.5629  Acc@1: 81.2500 (76.4354)  Acc@5: 100.0000 (96.2346)  time: 0.3541  data: 0.0014  max mem: 2502
Train: Epoch[1/5]  [ 980/3125]  eta: 0:13:16  Lr: 0.001875  Loss: -0.4004  Acc@1: 87.5000 (76.4653)  Acc@5: 100.0000 (96.2538)  time: 0.3489  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [ 990/3125]  eta: 0:13:11  Lr: 0.001875  Loss: -0.4089  Acc@1: 75.0000 (76.5010)  Acc@5: 100.0000 (96.2538)  time: 0.3489  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [1000/3125]  eta: 0:13:07  Lr: 0.001875  Loss: -0.4204  Acc@1: 81.2500 (76.5672)  Acc@5: 100.0000 (96.2413)  time: 0.3490  data: 0.0006  max mem: 2502
Train: Epoch[1/5]  [1010/3125]  eta: 0:13:03  Lr: 0.001875  Loss: -0.5260  Acc@1: 81.2500 (76.5888)  Acc@5: 100.0000 (96.2661)  time: 0.3475  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [1020/3125]  eta: 0:12:59  Lr: 0.001875  Loss: -0.6960  Acc@1: 81.2500 (76.6589)  Acc@5: 100.0000 (96.2659)  time: 0.3456  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [1030/3125]  eta: 0:12:55  Lr: 0.001875  Loss: -0.2891  Acc@1: 87.5000 (76.7459)  Acc@5: 100.0000 (96.2839)  time: 0.3503  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [1040/3125]  eta: 0:12:51  Lr: 0.001875  Loss: -0.5594  Acc@1: 87.5000 (76.7831)  Acc@5: 100.0000 (96.3016)  time: 0.3510  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [1050/3125]  eta: 0:12:46  Lr: 0.001875  Loss: -0.5365  Acc@1: 81.2500 (76.8375)  Acc@5: 100.0000 (96.3190)  time: 0.3451  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [1060/3125]  eta: 0:12:42  Lr: 0.001875  Loss: 0.1587  Acc@1: 87.5000 (76.9086)  Acc@5: 100.0000 (96.3360)  time: 0.3458  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [1070/3125]  eta: 0:12:38  Lr: 0.001875  Loss: -0.3801  Acc@1: 81.2500 (76.9433)  Acc@5: 100.0000 (96.3469)  time: 0.3552  data: 0.0024  max mem: 2502
Train: Epoch[1/5]  [1080/3125]  eta: 0:12:34  Lr: 0.001875  Loss: -0.2520  Acc@1: 81.2500 (76.9889)  Acc@5: 100.0000 (96.3749)  time: 0.3568  data: 0.0024  max mem: 2502
Train: Epoch[1/5]  [1090/3125]  eta: 0:12:30  Lr: 0.001875  Loss: -0.4085  Acc@1: 81.2500 (77.0394)  Acc@5: 100.0000 (96.3852)  time: 0.3489  data: 0.0006  max mem: 2502
Train: Epoch[1/5]  [1100/3125]  eta: 0:12:26  Lr: 0.001875  Loss: -0.2661  Acc@1: 81.2500 (77.0550)  Acc@5: 100.0000 (96.4067)  time: 0.3512  data: 0.0006  max mem: 2502
Train: Epoch[1/5]  [1110/3125]  eta: 0:12:22  Lr: 0.001875  Loss: -0.0063  Acc@1: 81.2500 (77.0927)  Acc@5: 100.0000 (96.4053)  time: 0.3535  data: 0.0011  max mem: 2502
Train: Epoch[1/5]  [1120/3125]  eta: 0:12:18  Lr: 0.001875  Loss: -0.2943  Acc@1: 81.2500 (77.1354)  Acc@5: 100.0000 (96.4206)  time: 0.3538  data: 0.0014  max mem: 2502
Train: Epoch[1/5]  [1130/3125]  eta: 0:12:15  Lr: 0.001875  Loss: -0.4930  Acc@1: 81.2500 (77.1773)  Acc@5: 100.0000 (96.4080)  time: 0.3547  data: 0.0008  max mem: 2502
Train: Epoch[1/5]  [1140/3125]  eta: 0:12:11  Lr: 0.001875  Loss: -0.4013  Acc@1: 81.2500 (77.1856)  Acc@5: 100.0000 (96.4176)  time: 0.3520  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [1150/3125]  eta: 0:12:07  Lr: 0.001875  Loss: -0.1495  Acc@1: 81.2500 (77.2209)  Acc@5: 100.0000 (96.4325)  time: 0.3515  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [1160/3125]  eta: 0:12:03  Lr: 0.001875  Loss: -0.2180  Acc@1: 81.2500 (77.2664)  Acc@5: 100.0000 (96.4255)  time: 0.3504  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [1170/3125]  eta: 0:11:59  Lr: 0.001875  Loss: -0.4574  Acc@1: 81.2500 (77.3004)  Acc@5: 100.0000 (96.4453)  time: 0.3491  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [1180/3125]  eta: 0:11:55  Lr: 0.001875  Loss: -0.6818  Acc@1: 87.5000 (77.3285)  Acc@5: 100.0000 (96.4543)  time: 0.3488  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [1190/3125]  eta: 0:11:51  Lr: 0.001875  Loss: -0.6843  Acc@1: 87.5000 (77.4087)  Acc@5: 100.0000 (96.4683)  time: 0.3476  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [1200/3125]  eta: 0:11:47  Lr: 0.001875  Loss: -0.6632  Acc@1: 87.5000 (77.4511)  Acc@5: 100.0000 (96.4769)  time: 0.3471  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [1210/3125]  eta: 0:11:43  Lr: 0.001875  Loss: -0.4106  Acc@1: 81.2500 (77.5031)  Acc@5: 100.0000 (96.4905)  time: 0.3470  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [1220/3125]  eta: 0:11:39  Lr: 0.001875  Loss: -0.8519  Acc@1: 81.2500 (77.5594)  Acc@5: 100.0000 (96.4988)  time: 0.3484  data: 0.0014  max mem: 2502
Train: Epoch[1/5]  [1230/3125]  eta: 0:11:35  Lr: 0.001875  Loss: -0.4697  Acc@1: 87.5000 (77.6198)  Acc@5: 100.0000 (96.5221)  time: 0.3470  data: 0.0013  max mem: 2502
Train: Epoch[1/5]  [1240/3125]  eta: 0:11:31  Lr: 0.001875  Loss: -0.1149  Acc@1: 81.2500 (77.6440)  Acc@5: 100.0000 (96.5351)  time: 0.3456  data: 0.0006  max mem: 2502
Train: Epoch[1/5]  [1250/3125]  eta: 0:11:27  Lr: 0.001875  Loss: -0.5392  Acc@1: 81.2500 (77.6629)  Acc@5: 100.0000 (96.5478)  time: 0.3473  data: 0.0008  max mem: 2502
Train: Epoch[1/5]  [1260/3125]  eta: 0:11:23  Lr: 0.001875  Loss: -0.5753  Acc@1: 81.2500 (77.7359)  Acc@5: 100.0000 (96.5454)  time: 0.3496  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [1270/3125]  eta: 0:11:19  Lr: 0.001875  Loss: -0.6366  Acc@1: 87.5000 (77.7685)  Acc@5: 100.0000 (96.5627)  time: 0.3509  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [1280/3125]  eta: 0:11:15  Lr: 0.001875  Loss: -0.4252  Acc@1: 81.2500 (77.8103)  Acc@5: 100.0000 (96.5603)  time: 0.3492  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [1290/3125]  eta: 0:11:11  Lr: 0.001875  Loss: -0.3229  Acc@1: 81.2500 (77.8273)  Acc@5: 100.0000 (96.5627)  time: 0.3523  data: 0.0006  max mem: 2502
Train: Epoch[1/5]  [1300/3125]  eta: 0:11:07  Lr: 0.001875  Loss: -0.3421  Acc@1: 81.2500 (77.8488)  Acc@5: 100.0000 (96.5699)  time: 0.3583  data: 0.0007  max mem: 2502
Train: Epoch[1/5]  [1310/3125]  eta: 0:11:04  Lr: 0.001875  Loss: -0.1347  Acc@1: 87.5000 (77.9033)  Acc@5: 100.0000 (96.5866)  time: 0.3553  data: 0.0006  max mem: 2502
Train: Epoch[1/5]  [1320/3125]  eta: 0:11:00  Lr: 0.001875  Loss: -0.6293  Acc@1: 87.5000 (77.9428)  Acc@5: 100.0000 (96.5935)  time: 0.3499  data: 0.0007  max mem: 2502
Train: Epoch[1/5]  [1330/3125]  eta: 0:10:56  Lr: 0.001875  Loss: -0.7982  Acc@1: 87.5000 (78.0287)  Acc@5: 100.0000 (96.6144)  time: 0.3531  data: 0.0007  max mem: 2502
Train: Epoch[1/5]  [1340/3125]  eta: 0:10:52  Lr: 0.001875  Loss: -0.7873  Acc@1: 87.5000 (78.0574)  Acc@5: 100.0000 (96.6163)  time: 0.3571  data: 0.0010  max mem: 2502
Train: Epoch[1/5]  [1350/3125]  eta: 0:10:48  Lr: 0.001875  Loss: -0.3024  Acc@1: 81.2500 (78.0857)  Acc@5: 100.0000 (96.6136)  time: 0.3524  data: 0.0013  max mem: 2502
Train: Epoch[1/5]  [1360/3125]  eta: 0:10:44  Lr: 0.001875  Loss: -0.5318  Acc@1: 81.2500 (78.0860)  Acc@5: 93.7500 (96.6155)  time: 0.3471  data: 0.0007  max mem: 2502
Train: Epoch[1/5]  [1370/3125]  eta: 0:10:40  Lr: 0.001875  Loss: -0.5406  Acc@1: 81.2500 (78.1455)  Acc@5: 100.0000 (96.6265)  time: 0.3476  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [1380/3125]  eta: 0:10:37  Lr: 0.001875  Loss: -0.5976  Acc@1: 81.2500 (78.1770)  Acc@5: 100.0000 (96.6510)  time: 0.3493  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [1390/3125]  eta: 0:10:33  Lr: 0.001875  Loss: -0.1515  Acc@1: 81.2500 (78.1722)  Acc@5: 100.0000 (96.6706)  time: 0.3492  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [1400/3125]  eta: 0:10:29  Lr: 0.001875  Loss: -0.1652  Acc@1: 81.2500 (78.2075)  Acc@5: 100.0000 (96.6809)  time: 0.3466  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [1410/3125]  eta: 0:10:25  Lr: 0.001875  Loss: -0.3628  Acc@1: 81.2500 (78.2335)  Acc@5: 100.0000 (96.6867)  time: 0.3449  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [1420/3125]  eta: 0:10:21  Lr: 0.001875  Loss: -0.7529  Acc@1: 81.2500 (78.2679)  Acc@5: 100.0000 (96.6881)  time: 0.3470  data: 0.0011  max mem: 2502
Train: Epoch[1/5]  [1430/3125]  eta: 0:10:17  Lr: 0.001875  Loss: -0.0060  Acc@1: 81.2500 (78.2669)  Acc@5: 93.7500 (96.6719)  time: 0.3473  data: 0.0011  max mem: 2502
Train: Epoch[1/5]  [1440/3125]  eta: 0:10:13  Lr: 0.001875  Loss: 0.0557  Acc@1: 81.2500 (78.2660)  Acc@5: 93.7500 (96.6733)  time: 0.3473  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [1450/3125]  eta: 0:10:10  Lr: 0.001875  Loss: -0.3462  Acc@1: 81.2500 (78.3038)  Acc@5: 100.0000 (96.6833)  time: 0.3488  data: 0.0006  max mem: 2502
Train: Epoch[1/5]  [1460/3125]  eta: 0:10:06  Lr: 0.001875  Loss: -0.5177  Acc@1: 87.5000 (78.3196)  Acc@5: 100.0000 (96.6932)  time: 0.3534  data: 0.0008  max mem: 2502
Train: Epoch[1/5]  [1470/3125]  eta: 0:10:02  Lr: 0.001875  Loss: -0.2054  Acc@1: 81.2500 (78.3438)  Acc@5: 100.0000 (96.7157)  time: 0.3561  data: 0.0008  max mem: 2502
Train: Epoch[1/5]  [1480/3125]  eta: 0:09:58  Lr: 0.001875  Loss: -0.7177  Acc@1: 75.0000 (78.3170)  Acc@5: 100.0000 (96.7083)  time: 0.3532  data: 0.0013  max mem: 2502
Train: Epoch[1/5]  [1490/3125]  eta: 0:09:55  Lr: 0.001875  Loss: -0.2510  Acc@1: 75.0000 (78.3325)  Acc@5: 93.7500 (96.7010)  time: 0.3513  data: 0.0013  max mem: 2502
Train: Epoch[1/5]  [1500/3125]  eta: 0:09:51  Lr: 0.001875  Loss: -0.6340  Acc@1: 81.2500 (78.3269)  Acc@5: 93.7500 (96.7022)  time: 0.3508  data: 0.0009  max mem: 2502
Train: Epoch[1/5]  [1510/3125]  eta: 0:09:47  Lr: 0.001875  Loss: -0.4516  Acc@1: 81.2500 (78.3546)  Acc@5: 100.0000 (96.7033)  time: 0.3579  data: 0.0010  max mem: 2502
Train: Epoch[1/5]  [1520/3125]  eta: 0:09:43  Lr: 0.001875  Loss: -0.3578  Acc@1: 81.2500 (78.3736)  Acc@5: 100.0000 (96.7045)  time: 0.3590  data: 0.0010  max mem: 2502
Train: Epoch[1/5]  [1530/3125]  eta: 0:09:40  Lr: 0.001875  Loss: -0.3016  Acc@1: 81.2500 (78.3842)  Acc@5: 100.0000 (96.7137)  time: 0.3547  data: 0.0008  max mem: 2502
Train: Epoch[1/5]  [1540/3125]  eta: 0:09:36  Lr: 0.001875  Loss: -0.0863  Acc@1: 81.2500 (78.4109)  Acc@5: 100.0000 (96.7148)  time: 0.3521  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [1550/3125]  eta: 0:09:32  Lr: 0.001875  Loss: -0.4572  Acc@1: 81.2500 (78.4413)  Acc@5: 100.0000 (96.7319)  time: 0.3479  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [1560/3125]  eta: 0:09:28  Lr: 0.001875  Loss: -0.4977  Acc@1: 81.2500 (78.4673)  Acc@5: 100.0000 (96.7369)  time: 0.3491  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [1570/3125]  eta: 0:09:25  Lr: 0.001875  Loss: -0.0919  Acc@1: 81.2500 (78.4731)  Acc@5: 100.0000 (96.7417)  time: 0.3502  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [1580/3125]  eta: 0:09:21  Lr: 0.001875  Loss: -0.5751  Acc@1: 81.2500 (78.4828)  Acc@5: 100.0000 (96.7426)  time: 0.3490  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [1590/3125]  eta: 0:09:17  Lr: 0.001875  Loss: -0.0189  Acc@1: 81.2500 (78.5002)  Acc@5: 100.0000 (96.7473)  time: 0.3475  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [1600/3125]  eta: 0:09:13  Lr: 0.001875  Loss: -0.5232  Acc@1: 81.2500 (78.5251)  Acc@5: 100.0000 (96.7520)  time: 0.3463  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [1610/3125]  eta: 0:09:09  Lr: 0.001875  Loss: -0.4964  Acc@1: 81.2500 (78.5265)  Acc@5: 100.0000 (96.7644)  time: 0.3472  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [1620/3125]  eta: 0:09:06  Lr: 0.001875  Loss: -0.4220  Acc@1: 81.2500 (78.5510)  Acc@5: 100.0000 (96.7728)  time: 0.3465  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [1630/3125]  eta: 0:09:02  Lr: 0.001875  Loss: -0.4900  Acc@1: 87.5000 (78.5753)  Acc@5: 100.0000 (96.7735)  time: 0.3447  data: 0.0002  max mem: 2502
Train: Epoch[1/5]  [1640/3125]  eta: 0:08:58  Lr: 0.001875  Loss: -0.4267  Acc@1: 87.5000 (78.6106)  Acc@5: 100.0000 (96.7741)  time: 0.3502  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [1650/3125]  eta: 0:08:54  Lr: 0.001875  Loss: -0.9166  Acc@1: 81.2500 (78.6379)  Acc@5: 100.0000 (96.7860)  time: 0.3521  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [1660/3125]  eta: 0:08:51  Lr: 0.001875  Loss: -0.3263  Acc@1: 81.2500 (78.6650)  Acc@5: 100.0000 (96.7941)  time: 0.3489  data: 0.0006  max mem: 2502
Train: Epoch[1/5]  [1670/3125]  eta: 0:08:47  Lr: 0.001875  Loss: -0.7358  Acc@1: 81.2500 (78.6842)  Acc@5: 100.0000 (96.7983)  time: 0.3497  data: 0.0006  max mem: 2502
Train: Epoch[1/5]  [1680/3125]  eta: 0:08:43  Lr: 0.001875  Loss: -0.5195  Acc@1: 81.2500 (78.7069)  Acc@5: 100.0000 (96.8099)  time: 0.3495  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [1690/3125]  eta: 0:08:40  Lr: 0.001875  Loss: -0.2885  Acc@1: 81.2500 (78.7293)  Acc@5: 100.0000 (96.8177)  time: 0.3537  data: 0.0015  max mem: 2502
Train: Epoch[1/5]  [1700/3125]  eta: 0:08:36  Lr: 0.001875  Loss: -0.4841  Acc@1: 81.2500 (78.7441)  Acc@5: 100.0000 (96.8254)  time: 0.3539  data: 0.0015  max mem: 2502
Train: Epoch[1/5]  [1710/3125]  eta: 0:08:32  Lr: 0.001875  Loss: -0.2559  Acc@1: 81.2500 (78.7807)  Acc@5: 100.0000 (96.8220)  time: 0.3490  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [1720/3125]  eta: 0:08:28  Lr: 0.001875  Loss: -0.4990  Acc@1: 81.2500 (78.8096)  Acc@5: 100.0000 (96.8260)  time: 0.3482  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [1730/3125]  eta: 0:08:25  Lr: 0.001875  Loss: -0.4913  Acc@1: 81.2500 (78.8562)  Acc@5: 100.0000 (96.8299)  time: 0.3508  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [1740/3125]  eta: 0:08:21  Lr: 0.001875  Loss: -0.4815  Acc@1: 87.5000 (78.8807)  Acc@5: 100.0000 (96.8301)  time: 0.3584  data: 0.0014  max mem: 2502
Train: Epoch[1/5]  [1750/3125]  eta: 0:08:17  Lr: 0.001875  Loss: -0.5235  Acc@1: 87.5000 (78.9228)  Acc@5: 100.0000 (96.8304)  time: 0.3550  data: 0.0013  max mem: 2502
Train: Epoch[1/5]  [1760/3125]  eta: 0:08:14  Lr: 0.001875  Loss: 0.0507  Acc@1: 87.5000 (78.9431)  Acc@5: 100.0000 (96.8306)  time: 0.3478  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [1770/3125]  eta: 0:08:10  Lr: 0.001875  Loss: -0.6922  Acc@1: 81.2500 (78.9667)  Acc@5: 93.7500 (96.8203)  time: 0.3486  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [1780/3125]  eta: 0:08:06  Lr: 0.001875  Loss: -0.7248  Acc@1: 81.2500 (78.9795)  Acc@5: 100.0000 (96.8276)  time: 0.3500  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [1790/3125]  eta: 0:08:02  Lr: 0.001875  Loss: -0.5188  Acc@1: 81.2500 (79.0061)  Acc@5: 100.0000 (96.8453)  time: 0.3495  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [1800/3125]  eta: 0:07:59  Lr: 0.001875  Loss: 0.0472  Acc@1: 81.2500 (79.0186)  Acc@5: 100.0000 (96.8490)  time: 0.3468  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [1810/3125]  eta: 0:07:55  Lr: 0.001875  Loss: -0.2951  Acc@1: 87.5000 (79.0551)  Acc@5: 100.0000 (96.8629)  time: 0.3463  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [1820/3125]  eta: 0:07:51  Lr: 0.001875  Loss: -0.3261  Acc@1: 81.2500 (79.0500)  Acc@5: 100.0000 (96.8630)  time: 0.3485  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [1830/3125]  eta: 0:07:48  Lr: 0.001875  Loss: -0.4631  Acc@1: 81.2500 (79.0722)  Acc@5: 100.0000 (96.8596)  time: 0.3480  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [1840/3125]  eta: 0:07:44  Lr: 0.001875  Loss: -0.4520  Acc@1: 81.2500 (79.0875)  Acc@5: 100.0000 (96.8665)  time: 0.3461  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [1850/3125]  eta: 0:07:40  Lr: 0.001875  Loss: -0.4989  Acc@1: 81.2500 (79.1093)  Acc@5: 100.0000 (96.8733)  time: 0.3486  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [1860/3125]  eta: 0:07:36  Lr: 0.001875  Loss: -0.5038  Acc@1: 81.2500 (79.1376)  Acc@5: 100.0000 (96.8834)  time: 0.3526  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [1870/3125]  eta: 0:07:33  Lr: 0.001875  Loss: -0.3556  Acc@1: 87.5000 (79.1589)  Acc@5: 100.0000 (96.8834)  time: 0.3527  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [1880/3125]  eta: 0:07:29  Lr: 0.001875  Loss: -0.2712  Acc@1: 87.5000 (79.1733)  Acc@5: 100.0000 (96.8933)  time: 0.3515  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [1890/3125]  eta: 0:07:25  Lr: 0.001875  Loss: -0.1837  Acc@1: 87.5000 (79.1975)  Acc@5: 100.0000 (96.8932)  time: 0.3512  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [1900/3125]  eta: 0:07:22  Lr: 0.001875  Loss: -0.3570  Acc@1: 81.2500 (79.2083)  Acc@5: 100.0000 (96.8898)  time: 0.3543  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [1910/3125]  eta: 0:07:18  Lr: 0.001875  Loss: -0.3702  Acc@1: 81.2500 (79.2157)  Acc@5: 100.0000 (96.8995)  time: 0.3561  data: 0.0007  max mem: 2502
Train: Epoch[1/5]  [1920/3125]  eta: 0:07:14  Lr: 0.001875  Loss: 0.0006  Acc@1: 81.2500 (79.2231)  Acc@5: 100.0000 (96.8961)  time: 0.3519  data: 0.0006  max mem: 2502
Train: Epoch[1/5]  [1930/3125]  eta: 0:07:11  Lr: 0.001875  Loss: -0.6519  Acc@1: 81.2500 (79.2336)  Acc@5: 93.7500 (96.8896)  time: 0.3494  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [1940/3125]  eta: 0:07:07  Lr: 0.001875  Loss: -0.2538  Acc@1: 81.2500 (79.2407)  Acc@5: 93.7500 (96.8830)  time: 0.3497  data: 0.0006  max mem: 2502
Train: Epoch[1/5]  [1950/3125]  eta: 0:07:03  Lr: 0.001875  Loss: -0.4777  Acc@1: 81.2500 (79.2382)  Acc@5: 100.0000 (96.8862)  time: 0.3544  data: 0.0015  max mem: 2502
Train: Epoch[1/5]  [1960/3125]  eta: 0:07:00  Lr: 0.001875  Loss: 0.1950  Acc@1: 81.2500 (79.2453)  Acc@5: 100.0000 (96.8957)  time: 0.3571  data: 0.0014  max mem: 2502
Train: Epoch[1/5]  [1970/3125]  eta: 0:06:56  Lr: 0.001875  Loss: -0.4714  Acc@1: 81.2500 (79.2459)  Acc@5: 100.0000 (96.9051)  time: 0.3514  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [1980/3125]  eta: 0:06:52  Lr: 0.001875  Loss: -0.6100  Acc@1: 81.2500 (79.2750)  Acc@5: 100.0000 (96.9081)  time: 0.3478  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [1990/3125]  eta: 0:06:49  Lr: 0.001875  Loss: -0.6540  Acc@1: 81.2500 (79.2724)  Acc@5: 100.0000 (96.9048)  time: 0.3558  data: 0.0009  max mem: 2502
Train: Epoch[1/5]  [2000/3125]  eta: 0:06:45  Lr: 0.001875  Loss: -0.3911  Acc@1: 81.2500 (79.3103)  Acc@5: 100.0000 (96.9109)  time: 0.3557  data: 0.0008  max mem: 2502
Train: Epoch[1/5]  [2010/3125]  eta: 0:06:42  Lr: 0.001875  Loss: -0.7372  Acc@1: 81.2500 (79.3045)  Acc@5: 100.0000 (96.9045)  time: 0.3483  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [2020/3125]  eta: 0:06:38  Lr: 0.001875  Loss: -0.2202  Acc@1: 75.0000 (79.2924)  Acc@5: 100.0000 (96.9075)  time: 0.3462  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [2030/3125]  eta: 0:06:34  Lr: 0.001875  Loss: -0.5589  Acc@1: 81.2500 (79.3021)  Acc@5: 100.0000 (96.9135)  time: 0.3451  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [2040/3125]  eta: 0:06:30  Lr: 0.001875  Loss: -0.5413  Acc@1: 81.2500 (79.3116)  Acc@5: 100.0000 (96.9255)  time: 0.3462  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [2050/3125]  eta: 0:06:27  Lr: 0.001875  Loss: 0.0285  Acc@1: 81.2500 (79.3393)  Acc@5: 100.0000 (96.9314)  time: 0.3460  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [2060/3125]  eta: 0:06:23  Lr: 0.001875  Loss: -0.4833  Acc@1: 87.5000 (79.3607)  Acc@5: 100.0000 (96.9372)  time: 0.3451  data: 0.0002  max mem: 2502
Train: Epoch[1/5]  [2070/3125]  eta: 0:06:19  Lr: 0.001875  Loss: -0.8352  Acc@1: 87.5000 (79.3759)  Acc@5: 100.0000 (96.9429)  time: 0.3470  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [2080/3125]  eta: 0:06:16  Lr: 0.001875  Loss: -0.4467  Acc@1: 87.5000 (79.4089)  Acc@5: 100.0000 (96.9486)  time: 0.3488  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [2090/3125]  eta: 0:06:12  Lr: 0.001875  Loss: -0.0232  Acc@1: 81.2500 (79.4088)  Acc@5: 100.0000 (96.9452)  time: 0.3485  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [2100/3125]  eta: 0:06:08  Lr: 0.001875  Loss: -0.7217  Acc@1: 81.2500 (79.4265)  Acc@5: 100.0000 (96.9509)  time: 0.3486  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [2110/3125]  eta: 0:06:05  Lr: 0.001875  Loss: -0.5700  Acc@1: 87.5000 (79.4351)  Acc@5: 100.0000 (96.9475)  time: 0.3486  data: 0.0007  max mem: 2502
Train: Epoch[1/5]  [2120/3125]  eta: 0:06:01  Lr: 0.001875  Loss: -0.5084  Acc@1: 87.5000 (79.4496)  Acc@5: 100.0000 (96.9560)  time: 0.3508  data: 0.0007  max mem: 2502
Train: Epoch[1/5]  [2130/3125]  eta: 0:05:58  Lr: 0.001875  Loss: -0.6189  Acc@1: 87.5000 (79.4815)  Acc@5: 100.0000 (96.9645)  time: 0.3498  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [2140/3125]  eta: 0:05:54  Lr: 0.001875  Loss: -0.6850  Acc@1: 87.5000 (79.5277)  Acc@5: 100.0000 (96.9728)  time: 0.3462  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [2150/3125]  eta: 0:05:50  Lr: 0.001875  Loss: -0.6851  Acc@1: 87.5000 (79.5328)  Acc@5: 100.0000 (96.9781)  time: 0.3466  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [2160/3125]  eta: 0:05:47  Lr: 0.001875  Loss: -0.0979  Acc@1: 81.2500 (79.5234)  Acc@5: 100.0000 (96.9719)  time: 0.3547  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [2170/3125]  eta: 0:05:43  Lr: 0.001875  Loss: -0.6113  Acc@1: 81.2500 (79.5457)  Acc@5: 100.0000 (96.9743)  time: 0.3570  data: 0.0014  max mem: 2502
Train: Epoch[1/5]  [2180/3125]  eta: 0:05:39  Lr: 0.001875  Loss: -0.3382  Acc@1: 81.2500 (79.5621)  Acc@5: 100.0000 (96.9739)  time: 0.3510  data: 0.0018  max mem: 2502
Train: Epoch[1/5]  [2190/3125]  eta: 0:05:36  Lr: 0.001875  Loss: -0.4578  Acc@1: 87.5000 (79.6041)  Acc@5: 100.0000 (96.9763)  time: 0.3490  data: 0.0012  max mem: 2502
Train: Epoch[1/5]  [2200/3125]  eta: 0:05:32  Lr: 0.001875  Loss: -0.6287  Acc@1: 87.5000 (79.6371)  Acc@5: 100.0000 (96.9815)  time: 0.3499  data: 0.0008  max mem: 2502
Train: Epoch[1/5]  [2210/3125]  eta: 0:05:28  Lr: 0.001875  Loss: -0.7077  Acc@1: 87.5000 (79.6557)  Acc@5: 100.0000 (96.9867)  time: 0.3498  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [2220/3125]  eta: 0:05:25  Lr: 0.001875  Loss: -0.2776  Acc@1: 81.2500 (79.6629)  Acc@5: 100.0000 (96.9890)  time: 0.3484  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [2230/3125]  eta: 0:05:21  Lr: 0.001875  Loss: -0.1671  Acc@1: 81.2500 (79.6700)  Acc@5: 100.0000 (96.9857)  time: 0.3478  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [2240/3125]  eta: 0:05:18  Lr: 0.001875  Loss: -0.4352  Acc@1: 81.2500 (79.6715)  Acc@5: 100.0000 (96.9963)  time: 0.3476  data: 0.0006  max mem: 2502
Train: Epoch[1/5]  [2250/3125]  eta: 0:05:14  Lr: 0.001875  Loss: -0.2662  Acc@1: 81.2500 (79.6951)  Acc@5: 100.0000 (97.0069)  time: 0.3488  data: 0.0006  max mem: 2502
Train: Epoch[1/5]  [2260/3125]  eta: 0:05:10  Lr: 0.001875  Loss: -0.4476  Acc@1: 87.5000 (79.7131)  Acc@5: 100.0000 (97.0091)  time: 0.3476  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [2270/3125]  eta: 0:05:07  Lr: 0.001875  Loss: -0.7438  Acc@1: 81.2500 (79.7171)  Acc@5: 100.0000 (97.0195)  time: 0.3457  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [2280/3125]  eta: 0:05:03  Lr: 0.001875  Loss: -0.7000  Acc@1: 81.2500 (79.7183)  Acc@5: 100.0000 (97.0189)  time: 0.3458  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [2290/3125]  eta: 0:04:59  Lr: 0.001875  Loss: -0.5510  Acc@1: 81.2500 (79.7468)  Acc@5: 100.0000 (97.0210)  time: 0.3471  data: 0.0006  max mem: 2502
Train: Epoch[1/5]  [2300/3125]  eta: 0:04:56  Lr: 0.001875  Loss: -0.7245  Acc@1: 87.5000 (79.7832)  Acc@5: 100.0000 (97.0285)  time: 0.3465  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [2310/3125]  eta: 0:04:52  Lr: 0.001875  Loss: 0.0158  Acc@1: 81.2500 (79.7815)  Acc@5: 100.0000 (97.0224)  time: 0.3460  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [2320/3125]  eta: 0:04:48  Lr: 0.001875  Loss: -0.6913  Acc@1: 81.2500 (79.7905)  Acc@5: 93.7500 (97.0191)  time: 0.3470  data: 0.0006  max mem: 2502
Train: Epoch[1/5]  [2330/3125]  eta: 0:04:45  Lr: 0.001875  Loss: -0.2940  Acc@1: 87.5000 (79.8155)  Acc@5: 93.7500 (97.0184)  time: 0.3543  data: 0.0016  max mem: 2502
Train: Epoch[1/5]  [2340/3125]  eta: 0:04:41  Lr: 0.001875  Loss: -0.7358  Acc@1: 87.5000 (79.8457)  Acc@5: 100.0000 (97.0232)  time: 0.3562  data: 0.0018  max mem: 2502
Train: Epoch[1/5]  [2350/3125]  eta: 0:04:38  Lr: 0.001875  Loss: -0.5542  Acc@1: 87.5000 (79.8703)  Acc@5: 100.0000 (97.0305)  time: 0.3513  data: 0.0009  max mem: 2502
Train: Epoch[1/5]  [2360/3125]  eta: 0:04:34  Lr: 0.001875  Loss: 0.2199  Acc@1: 87.5000 (79.8841)  Acc@5: 100.0000 (97.0352)  time: 0.3530  data: 0.0006  max mem: 2502
Train: Epoch[1/5]  [2370/3125]  eta: 0:04:30  Lr: 0.001875  Loss: -0.5263  Acc@1: 87.5000 (79.8977)  Acc@5: 100.0000 (97.0398)  time: 0.3505  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [2380/3125]  eta: 0:04:27  Lr: 0.001875  Loss: -0.2406  Acc@1: 87.5000 (79.9218)  Acc@5: 100.0000 (97.0391)  time: 0.3554  data: 0.0015  max mem: 2502
Train: Epoch[1/5]  [2390/3125]  eta: 0:04:23  Lr: 0.001875  Loss: -0.5730  Acc@1: 87.5000 (79.9299)  Acc@5: 93.7500 (97.0358)  time: 0.3557  data: 0.0016  max mem: 2502
Train: Epoch[1/5]  [2400/3125]  eta: 0:04:20  Lr: 0.001875  Loss: -0.8082  Acc@1: 87.5000 (79.9459)  Acc@5: 100.0000 (97.0455)  time: 0.3515  data: 0.0008  max mem: 2502
Train: Epoch[1/5]  [2410/3125]  eta: 0:04:16  Lr: 0.001875  Loss: -0.5146  Acc@1: 87.5000 (79.9746)  Acc@5: 100.0000 (97.0526)  time: 0.3525  data: 0.0007  max mem: 2502
Train: Epoch[1/5]  [2420/3125]  eta: 0:04:12  Lr: 0.001875  Loss: -0.4306  Acc@1: 87.5000 (79.9902)  Acc@5: 100.0000 (97.0570)  time: 0.3493  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [2430/3125]  eta: 0:04:09  Lr: 0.001875  Loss: -0.2168  Acc@1: 81.2500 (79.9851)  Acc@5: 100.0000 (97.0640)  time: 0.3536  data: 0.0018  max mem: 2502
Train: Epoch[1/5]  [2440/3125]  eta: 0:04:05  Lr: 0.001875  Loss: -0.4746  Acc@1: 81.2500 (80.0082)  Acc@5: 100.0000 (97.0709)  time: 0.3529  data: 0.0018  max mem: 2502
Train: Epoch[1/5]  [2450/3125]  eta: 0:04:02  Lr: 0.001875  Loss: -0.5449  Acc@1: 81.2500 (80.0107)  Acc@5: 100.0000 (97.0675)  time: 0.3488  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [2460/3125]  eta: 0:03:58  Lr: 0.001875  Loss: -0.2380  Acc@1: 81.2500 (80.0056)  Acc@5: 100.0000 (97.0667)  time: 0.3494  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [2470/3125]  eta: 0:03:54  Lr: 0.001875  Loss: -0.5330  Acc@1: 81.2500 (80.0258)  Acc@5: 100.0000 (97.0710)  time: 0.3491  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [2480/3125]  eta: 0:03:51  Lr: 0.001875  Loss: -0.6033  Acc@1: 87.5000 (80.0584)  Acc@5: 100.0000 (97.0753)  time: 0.3473  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [2490/3125]  eta: 0:03:47  Lr: 0.001875  Loss: -0.5372  Acc@1: 87.5000 (80.0532)  Acc@5: 100.0000 (97.0745)  time: 0.3453  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [2500/3125]  eta: 0:03:43  Lr: 0.001875  Loss: -0.0252  Acc@1: 87.5000 (80.0830)  Acc@5: 100.0000 (97.0762)  time: 0.3465  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [2510/3125]  eta: 0:03:40  Lr: 0.001875  Loss: -0.7539  Acc@1: 87.5000 (80.1274)  Acc@5: 100.0000 (97.0853)  time: 0.3481  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [2520/3125]  eta: 0:03:36  Lr: 0.001875  Loss: -0.8661  Acc@1: 87.5000 (80.1245)  Acc@5: 100.0000 (97.0845)  time: 0.3504  data: 0.0007  max mem: 2502
Train: Epoch[1/5]  [2530/3125]  eta: 0:03:33  Lr: 0.001875  Loss: -0.3185  Acc@1: 81.2500 (80.1314)  Acc@5: 100.0000 (97.0960)  time: 0.3507  data: 0.0008  max mem: 2502
Train: Epoch[1/5]  [2540/3125]  eta: 0:03:29  Lr: 0.001875  Loss: -0.3048  Acc@1: 81.2500 (80.1432)  Acc@5: 100.0000 (97.1025)  time: 0.3483  data: 0.0006  max mem: 2502
Train: Epoch[1/5]  [2550/3125]  eta: 0:03:25  Lr: 0.001875  Loss: -0.7100  Acc@1: 87.5000 (80.1695)  Acc@5: 100.0000 (97.1041)  time: 0.3503  data: 0.0006  max mem: 2502
Train: Epoch[1/5]  [2560/3125]  eta: 0:03:22  Lr: 0.001875  Loss: -0.5619  Acc@1: 87.5000 (80.1982)  Acc@5: 100.0000 (97.1081)  time: 0.3525  data: 0.0016  max mem: 2502
Train: Epoch[1/5]  [2570/3125]  eta: 0:03:18  Lr: 0.001875  Loss: -0.6230  Acc@1: 87.5000 (80.2193)  Acc@5: 100.0000 (97.1169)  time: 0.3516  data: 0.0015  max mem: 2502
Train: Epoch[1/5]  [2580/3125]  eta: 0:03:15  Lr: 0.001875  Loss: -0.8152  Acc@1: 87.5000 (80.2330)  Acc@5: 100.0000 (97.1159)  time: 0.3509  data: 0.0006  max mem: 2502
Train: Epoch[1/5]  [2590/3125]  eta: 0:03:11  Lr: 0.001875  Loss: -0.4035  Acc@1: 87.5000 (80.2586)  Acc@5: 100.0000 (97.1223)  time: 0.3495  data: 0.0007  max mem: 2502
Train: Epoch[1/5]  [2600/3125]  eta: 0:03:07  Lr: 0.001875  Loss: -0.5537  Acc@1: 87.5000 (80.2864)  Acc@5: 100.0000 (97.1261)  time: 0.3511  data: 0.0009  max mem: 2502
Train: Epoch[1/5]  [2610/3125]  eta: 0:03:04  Lr: 0.001875  Loss: -0.1181  Acc@1: 87.5000 (80.3093)  Acc@5: 100.0000 (97.1251)  time: 0.3511  data: 0.0009  max mem: 2502
Train: Epoch[1/5]  [2620/3125]  eta: 0:03:00  Lr: 0.001875  Loss: -0.6537  Acc@1: 87.5000 (80.3224)  Acc@5: 100.0000 (97.1266)  time: 0.3485  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [2630/3125]  eta: 0:02:57  Lr: 0.001875  Loss: -0.5247  Acc@1: 81.2500 (80.3354)  Acc@5: 100.0000 (97.1280)  time: 0.3480  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [2640/3125]  eta: 0:02:53  Lr: 0.001875  Loss: -0.6376  Acc@1: 81.2500 (80.3460)  Acc@5: 100.0000 (97.1199)  time: 0.3498  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [2650/3125]  eta: 0:02:49  Lr: 0.001875  Loss: -0.6889  Acc@1: 81.2500 (80.3541)  Acc@5: 93.7500 (97.1119)  time: 0.3506  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [2660/3125]  eta: 0:02:46  Lr: 0.001875  Loss: -0.9567  Acc@1: 81.2500 (80.3739)  Acc@5: 93.7500 (97.1110)  time: 0.3486  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [2670/3125]  eta: 0:02:42  Lr: 0.001875  Loss: -0.4553  Acc@1: 81.2500 (80.3866)  Acc@5: 100.0000 (97.1219)  time: 0.3470  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [2680/3125]  eta: 0:02:39  Lr: 0.001875  Loss: -0.4083  Acc@1: 81.2500 (80.3898)  Acc@5: 100.0000 (97.1303)  time: 0.3467  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [2690/3125]  eta: 0:02:35  Lr: 0.001875  Loss: -0.3627  Acc@1: 81.2500 (80.4069)  Acc@5: 100.0000 (97.1293)  time: 0.3469  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [2700/3125]  eta: 0:02:32  Lr: 0.001875  Loss: -0.8147  Acc@1: 87.5000 (80.4239)  Acc@5: 100.0000 (97.1376)  time: 0.3453  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [2710/3125]  eta: 0:02:28  Lr: 0.001875  Loss: -0.7243  Acc@1: 87.5000 (80.4247)  Acc@5: 100.0000 (97.1390)  time: 0.3458  data: 0.0002  max mem: 2502
Train: Epoch[1/5]  [2720/3125]  eta: 0:02:24  Lr: 0.001875  Loss: -0.6278  Acc@1: 81.2500 (80.4208)  Acc@5: 100.0000 (97.1449)  time: 0.3568  data: 0.0049  max mem: 2502
Train: Epoch[1/5]  [2730/3125]  eta: 0:02:21  Lr: 0.001875  Loss: -0.5313  Acc@1: 81.2500 (80.4376)  Acc@5: 100.0000 (97.1439)  time: 0.3634  data: 0.0051  max mem: 2502
Train: Epoch[1/5]  [2740/3125]  eta: 0:02:17  Lr: 0.001875  Loss: -0.5551  Acc@1: 87.5000 (80.4611)  Acc@5: 100.0000 (97.1498)  time: 0.3540  data: 0.0006  max mem: 2502
Train: Epoch[1/5]  [2750/3125]  eta: 0:02:14  Lr: 0.001875  Loss: -0.6567  Acc@1: 87.5000 (80.4753)  Acc@5: 100.0000 (97.1510)  time: 0.3511  data: 0.0006  max mem: 2502
Train: Epoch[1/5]  [2760/3125]  eta: 0:02:10  Lr: 0.001875  Loss: -0.7402  Acc@1: 81.2500 (80.4939)  Acc@5: 100.0000 (97.1546)  time: 0.3550  data: 0.0007  max mem: 2502
Train: Epoch[1/5]  [2770/3125]  eta: 0:02:06  Lr: 0.001875  Loss: -0.2600  Acc@1: 81.2500 (80.5079)  Acc@5: 100.0000 (97.1558)  time: 0.3577  data: 0.0014  max mem: 2502
Train: Epoch[1/5]  [2780/3125]  eta: 0:02:03  Lr: 0.001875  Loss: -0.5354  Acc@1: 81.2500 (80.5218)  Acc@5: 100.0000 (97.1615)  time: 0.3544  data: 0.0013  max mem: 2502
Train: Epoch[1/5]  [2790/3125]  eta: 0:01:59  Lr: 0.001875  Loss: -0.3226  Acc@1: 87.5000 (80.5446)  Acc@5: 100.0000 (97.1583)  time: 0.3484  data: 0.0006  max mem: 2502
Train: Epoch[1/5]  [2800/3125]  eta: 0:01:56  Lr: 0.001875  Loss: -0.1805  Acc@1: 81.2500 (80.5337)  Acc@5: 100.0000 (97.1595)  time: 0.3513  data: 0.0006  max mem: 2502
Train: Epoch[1/5]  [2810/3125]  eta: 0:01:52  Lr: 0.001875  Loss: -0.7086  Acc@1: 81.2500 (80.5385)  Acc@5: 100.0000 (97.1629)  time: 0.3508  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [2820/3125]  eta: 0:01:49  Lr: 0.001875  Loss: -0.7220  Acc@1: 81.2500 (80.5477)  Acc@5: 100.0000 (97.1641)  time: 0.3484  data: 0.0009  max mem: 2502
Train: Epoch[1/5]  [2830/3125]  eta: 0:01:45  Lr: 0.001875  Loss: -0.4013  Acc@1: 87.5000 (80.5656)  Acc@5: 100.0000 (97.1675)  time: 0.3487  data: 0.0009  max mem: 2502
Train: Epoch[1/5]  [2840/3125]  eta: 0:01:41  Lr: 0.001875  Loss: 0.4340  Acc@1: 81.2500 (80.5614)  Acc@5: 100.0000 (97.1621)  time: 0.3473  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [2850/3125]  eta: 0:01:38  Lr: 0.001875  Loss: -0.0791  Acc@1: 81.2500 (80.5726)  Acc@5: 100.0000 (97.1677)  time: 0.3477  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [2860/3125]  eta: 0:01:34  Lr: 0.001875  Loss: -0.5305  Acc@1: 81.2500 (80.5903)  Acc@5: 100.0000 (97.1732)  time: 0.3499  data: 0.0010  max mem: 2502
Train: Epoch[1/5]  [2870/3125]  eta: 0:01:31  Lr: 0.001875  Loss: -0.8355  Acc@1: 87.5000 (80.6165)  Acc@5: 100.0000 (97.1765)  time: 0.3490  data: 0.0009  max mem: 2502
Train: Epoch[1/5]  [2880/3125]  eta: 0:01:27  Lr: 0.001875  Loss: -0.4139  Acc@1: 87.5000 (80.6404)  Acc@5: 100.0000 (97.1820)  time: 0.3461  data: 0.0007  max mem: 2502
Train: Epoch[1/5]  [2890/3125]  eta: 0:01:23  Lr: 0.001875  Loss: -0.5761  Acc@1: 87.5000 (80.6576)  Acc@5: 100.0000 (97.1874)  time: 0.3460  data: 0.0007  max mem: 2502
Train: Epoch[1/5]  [2900/3125]  eta: 0:01:20  Lr: 0.001875  Loss: -0.7338  Acc@1: 87.5000 (80.6640)  Acc@5: 100.0000 (97.1863)  time: 0.3497  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [2910/3125]  eta: 0:01:16  Lr: 0.001875  Loss: -0.1074  Acc@1: 81.2500 (80.6724)  Acc@5: 93.7500 (97.1831)  time: 0.3508  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [2920/3125]  eta: 0:01:13  Lr: 0.001875  Loss: -0.4582  Acc@1: 87.5000 (80.6915)  Acc@5: 100.0000 (97.1778)  time: 0.3498  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [2930/3125]  eta: 0:01:09  Lr: 0.001875  Loss: -0.7630  Acc@1: 87.5000 (80.6977)  Acc@5: 100.0000 (97.1789)  time: 0.3500  data: 0.0006  max mem: 2502
Train: Epoch[1/5]  [2940/3125]  eta: 0:01:06  Lr: 0.001875  Loss: -0.2540  Acc@1: 81.2500 (80.7102)  Acc@5: 100.0000 (97.1821)  time: 0.3514  data: 0.0006  max mem: 2502
Train: Epoch[1/5]  [2950/3125]  eta: 0:01:02  Lr: 0.001875  Loss: -0.5238  Acc@1: 87.5000 (80.7205)  Acc@5: 100.0000 (97.1874)  time: 0.3550  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [2960/3125]  eta: 0:00:58  Lr: 0.001875  Loss: -0.3738  Acc@1: 81.2500 (80.7202)  Acc@5: 100.0000 (97.1948)  time: 0.3546  data: 0.0010  max mem: 2502
Train: Epoch[1/5]  [2970/3125]  eta: 0:00:55  Lr: 0.001875  Loss: -0.5790  Acc@1: 87.5000 (80.7535)  Acc@5: 100.0000 (97.1979)  time: 0.3519  data: 0.0010  max mem: 2502
Train: Epoch[1/5]  [2980/3125]  eta: 0:00:51  Lr: 0.001875  Loss: -0.5380  Acc@1: 87.5000 (80.7678)  Acc@5: 100.0000 (97.2031)  time: 0.3497  data: 0.0006  max mem: 2502
Train: Epoch[1/5]  [2990/3125]  eta: 0:00:48  Lr: 0.001875  Loss: -0.4537  Acc@1: 81.2500 (80.7777)  Acc@5: 100.0000 (97.2125)  time: 0.3513  data: 0.0008  max mem: 2502
Train: Epoch[1/5]  [3000/3125]  eta: 0:00:44  Lr: 0.001875  Loss: -0.4003  Acc@1: 87.5000 (80.7939)  Acc@5: 100.0000 (97.2176)  time: 0.3535  data: 0.0008  max mem: 2502
Train: Epoch[1/5]  [3010/3125]  eta: 0:00:41  Lr: 0.001875  Loss: -0.3408  Acc@1: 81.2500 (80.7954)  Acc@5: 100.0000 (97.2206)  time: 0.3499  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [3020/3125]  eta: 0:00:37  Lr: 0.001875  Loss: -0.3184  Acc@1: 81.2500 (80.8031)  Acc@5: 100.0000 (97.2257)  time: 0.3468  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [3030/3125]  eta: 0:00:33  Lr: 0.001875  Loss: -0.7847  Acc@1: 87.5000 (80.8252)  Acc@5: 100.0000 (97.2307)  time: 0.3472  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [3040/3125]  eta: 0:00:30  Lr: 0.001875  Loss: -0.4350  Acc@1: 87.5000 (80.8266)  Acc@5: 100.0000 (97.2295)  time: 0.3486  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [3050/3125]  eta: 0:00:26  Lr: 0.001875  Loss: -0.6666  Acc@1: 87.5000 (80.8505)  Acc@5: 100.0000 (97.2325)  time: 0.3496  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [3060/3125]  eta: 0:00:23  Lr: 0.001875  Loss: -0.0524  Acc@1: 87.5000 (80.8478)  Acc@5: 100.0000 (97.2333)  time: 0.3474  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [3070/3125]  eta: 0:00:19  Lr: 0.001875  Loss: -0.7141  Acc@1: 87.5000 (80.8755)  Acc@5: 100.0000 (97.2383)  time: 0.3456  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [3080/3125]  eta: 0:00:16  Lr: 0.001875  Loss: -0.6257  Acc@1: 87.5000 (80.8869)  Acc@5: 100.0000 (97.2412)  time: 0.3474  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [3090/3125]  eta: 0:00:12  Lr: 0.001875  Loss: -0.7378  Acc@1: 81.2500 (80.8901)  Acc@5: 100.0000 (97.2440)  time: 0.3470  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [3100/3125]  eta: 0:00:08  Lr: 0.001875  Loss: -0.2576  Acc@1: 87.5000 (80.9033)  Acc@5: 100.0000 (97.2509)  time: 0.3460  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [3110/3125]  eta: 0:00:05  Lr: 0.001875  Loss: -0.5293  Acc@1: 81.2500 (80.8924)  Acc@5: 100.0000 (97.2537)  time: 0.3498  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [3120/3125]  eta: 0:00:01  Lr: 0.001875  Loss: -0.4375  Acc@1: 81.2500 (80.8935)  Acc@5: 100.0000 (97.2625)  time: 0.3525  data: 0.0013  max mem: 2502
Train: Epoch[1/5]  [3124/3125]  eta: 0:00:00  Lr: 0.001875  Loss: -0.1888  Acc@1: 81.2500 (80.8820)  Acc@5: 100.0000 (97.2640)  time: 0.3524  data: 0.0012  max mem: 2502
Train: Epoch[1/5] Total time: 0:18:35 (0.3569 s / it)
{0: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 1: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 2: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 3: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 4: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 5: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 6: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 7: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 8: {0: 0, 1: 0, 2: 50000, 3: 0, 4: 0}, 9: {0: 0, 1: 0, 2: 50000, 3: 0, 4: 0}, 10: {0: 0, 1: 0, 2: 50000, 3: 0, 4: 0}, 11: {0: 0, 1: 0, 2: 50000, 3: 0, 4: 0}, 12: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 13: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 14: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 15: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 16: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 17: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 18: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 19: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}}
Averaged stats: Lr: 0.001875  Loss: -0.1888  Acc@1: 81.2500 (80.8820)  Acc@5: 100.0000 (97.2640)
Train: Epoch[2/5]  [   0/3125]  eta: 0:37:49  Lr: 0.001875  Loss: -0.5799  Acc@1: 81.2500 (81.2500)  Acc@5: 93.7500 (93.7500)  time: 0.7263  data: 0.3792  max mem: 2502
Train: Epoch[2/5]  [  10/3125]  eta: 0:19:56  Lr: 0.001875  Loss: -0.3018  Acc@1: 81.2500 (83.5227)  Acc@5: 100.0000 (98.2955)  time: 0.3841  data: 0.0349  max mem: 2502
Train: Epoch[2/5]  [  20/3125]  eta: 0:19:06  Lr: 0.001875  Loss: -0.3176  Acc@1: 81.2500 (82.4405)  Acc@5: 100.0000 (98.5119)  time: 0.3515  data: 0.0007  max mem: 2502
Train: Epoch[2/5]  [  30/3125]  eta: 0:18:41  Lr: 0.001875  Loss: -0.7045  Acc@1: 81.2500 (83.0645)  Acc@5: 100.0000 (98.3871)  time: 0.3503  data: 0.0007  max mem: 2502
Train: Epoch[2/5]  [  40/3125]  eta: 0:18:32  Lr: 0.001875  Loss: -0.7622  Acc@1: 81.2500 (83.5366)  Acc@5: 100.0000 (98.3232)  time: 0.3516  data: 0.0009  max mem: 2502
Train: Epoch[2/5]  [  50/3125]  eta: 0:18:28  Lr: 0.001875  Loss: -0.2495  Acc@1: 87.5000 (83.0882)  Acc@5: 100.0000 (98.5294)  time: 0.3578  data: 0.0010  max mem: 2502
Train: Epoch[2/5]  [  60/3125]  eta: 0:18:18  Lr: 0.001875  Loss: -0.7519  Acc@1: 87.5000 (83.8115)  Acc@5: 100.0000 (98.7705)  time: 0.3539  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [  70/3125]  eta: 0:18:10  Lr: 0.001875  Loss: -0.4915  Acc@1: 87.5000 (83.8028)  Acc@5: 100.0000 (98.5035)  time: 0.3475  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [  80/3125]  eta: 0:18:03  Lr: 0.001875  Loss: -0.3682  Acc@1: 81.2500 (82.6389)  Acc@5: 93.7500 (98.0710)  time: 0.3483  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [  90/3125]  eta: 0:17:58  Lr: 0.001875  Loss: -0.6791  Acc@1: 75.0000 (82.8297)  Acc@5: 93.7500 (98.0082)  time: 0.3506  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [ 100/3125]  eta: 0:17:53  Lr: 0.001875  Loss: -0.3041  Acc@1: 87.5000 (82.6733)  Acc@5: 100.0000 (97.8960)  time: 0.3505  data: 0.0007  max mem: 2502
Train: Epoch[2/5]  [ 110/3125]  eta: 0:17:47  Lr: 0.001875  Loss: -0.4038  Acc@1: 87.5000 (82.8266)  Acc@5: 100.0000 (98.0293)  time: 0.3483  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [ 120/3125]  eta: 0:17:41  Lr: 0.001875  Loss: -0.5987  Acc@1: 87.5000 (82.9545)  Acc@5: 100.0000 (97.9855)  time: 0.3458  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [ 130/3125]  eta: 0:17:37  Lr: 0.001875  Loss: -0.6941  Acc@1: 87.5000 (82.9676)  Acc@5: 100.0000 (98.0439)  time: 0.3464  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [ 140/3125]  eta: 0:17:32  Lr: 0.001875  Loss: -0.4059  Acc@1: 81.2500 (83.2004)  Acc@5: 100.0000 (98.1383)  time: 0.3467  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [ 150/3125]  eta: 0:17:27  Lr: 0.001875  Loss: -0.4211  Acc@1: 87.5000 (83.2781)  Acc@5: 100.0000 (98.1374)  time: 0.3462  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [ 160/3125]  eta: 0:17:24  Lr: 0.001875  Loss: -0.0873  Acc@1: 87.5000 (83.3851)  Acc@5: 100.0000 (98.1366)  time: 0.3515  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [ 170/3125]  eta: 0:17:22  Lr: 0.001875  Loss: -0.5978  Acc@1: 87.5000 (83.5892)  Acc@5: 100.0000 (98.0629)  time: 0.3572  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [ 180/3125]  eta: 0:17:17  Lr: 0.001875  Loss: -0.6822  Acc@1: 87.5000 (83.6671)  Acc@5: 100.0000 (98.1008)  time: 0.3534  data: 0.0007  max mem: 2502
Train: Epoch[2/5]  [ 190/3125]  eta: 0:17:14  Lr: 0.001875  Loss: -0.8320  Acc@1: 81.2500 (83.7042)  Acc@5: 100.0000 (98.1348)  time: 0.3500  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [ 200/3125]  eta: 0:17:11  Lr: 0.001875  Loss: -0.3977  Acc@1: 81.2500 (83.6443)  Acc@5: 100.0000 (98.1032)  time: 0.3530  data: 0.0009  max mem: 2502
Train: Epoch[2/5]  [ 210/3125]  eta: 0:17:07  Lr: 0.001875  Loss: -0.4521  Acc@1: 87.5000 (83.7974)  Acc@5: 100.0000 (98.1931)  time: 0.3515  data: 0.0009  max mem: 2502
Train: Epoch[2/5]  [ 220/3125]  eta: 0:17:04  Lr: 0.001875  Loss: -0.2253  Acc@1: 87.5000 (83.7952)  Acc@5: 100.0000 (98.1900)  time: 0.3531  data: 0.0010  max mem: 2502
Train: Epoch[2/5]  [ 230/3125]  eta: 0:17:00  Lr: 0.001875  Loss: -0.7670  Acc@1: 81.2500 (83.7933)  Acc@5: 100.0000 (98.1602)  time: 0.3531  data: 0.0011  max mem: 2502
Train: Epoch[2/5]  [ 240/3125]  eta: 0:16:56  Lr: 0.001875  Loss: 0.0448  Acc@1: 81.2500 (83.6878)  Acc@5: 100.0000 (98.1328)  time: 0.3514  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [ 250/3125]  eta: 0:16:52  Lr: 0.001875  Loss: -0.0736  Acc@1: 81.2500 (83.5159)  Acc@5: 100.0000 (98.1574)  time: 0.3504  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [ 260/3125]  eta: 0:16:49  Lr: 0.001875  Loss: -0.4742  Acc@1: 81.2500 (83.5489)  Acc@5: 100.0000 (98.2040)  time: 0.3505  data: 0.0007  max mem: 2502
Train: Epoch[2/5]  [ 270/3125]  eta: 0:16:45  Lr: 0.001875  Loss: -0.4483  Acc@1: 81.2500 (83.5332)  Acc@5: 100.0000 (98.2242)  time: 0.3538  data: 0.0008  max mem: 2502
Train: Epoch[2/5]  [ 280/3125]  eta: 0:16:41  Lr: 0.001875  Loss: -0.6476  Acc@1: 81.2500 (83.6299)  Acc@5: 100.0000 (98.1762)  time: 0.3505  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [ 290/3125]  eta: 0:16:37  Lr: 0.001875  Loss: -0.7121  Acc@1: 87.5000 (83.7199)  Acc@5: 100.0000 (98.1100)  time: 0.3471  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [ 300/3125]  eta: 0:16:34  Lr: 0.001875  Loss: 0.0706  Acc@1: 87.5000 (83.5963)  Acc@5: 100.0000 (98.0689)  time: 0.3477  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [ 310/3125]  eta: 0:16:30  Lr: 0.001875  Loss: -0.5720  Acc@1: 81.2500 (83.6616)  Acc@5: 100.0000 (98.1109)  time: 0.3479  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [ 320/3125]  eta: 0:16:25  Lr: 0.001875  Loss: -0.6704  Acc@1: 87.5000 (83.8201)  Acc@5: 100.0000 (98.1503)  time: 0.3460  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [ 330/3125]  eta: 0:16:21  Lr: 0.001875  Loss: -0.4288  Acc@1: 87.5000 (83.8557)  Acc@5: 100.0000 (98.1495)  time: 0.3451  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [ 340/3125]  eta: 0:16:19  Lr: 0.001875  Loss: -0.8654  Acc@1: 87.5000 (83.9993)  Acc@5: 100.0000 (98.1488)  time: 0.3532  data: 0.0008  max mem: 2502
Train: Epoch[2/5]  [ 350/3125]  eta: 0:16:15  Lr: 0.001875  Loss: -0.3605  Acc@1: 87.5000 (84.0456)  Acc@5: 100.0000 (98.1481)  time: 0.3547  data: 0.0015  max mem: 2502
Train: Epoch[2/5]  [ 360/3125]  eta: 0:16:11  Lr: 0.001875  Loss: -0.5708  Acc@1: 87.5000 (84.1240)  Acc@5: 100.0000 (98.1475)  time: 0.3501  data: 0.0011  max mem: 2502
Train: Epoch[2/5]  [ 370/3125]  eta: 0:16:08  Lr: 0.001875  Loss: -0.2463  Acc@1: 87.5000 (84.2655)  Acc@5: 100.0000 (98.1806)  time: 0.3495  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [ 380/3125]  eta: 0:16:04  Lr: 0.001875  Loss: -0.2353  Acc@1: 87.5000 (84.3176)  Acc@5: 100.0000 (98.1955)  time: 0.3495  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [ 390/3125]  eta: 0:16:01  Lr: 0.001875  Loss: -0.4234  Acc@1: 87.5000 (84.4150)  Acc@5: 100.0000 (98.1937)  time: 0.3549  data: 0.0008  max mem: 2502
Train: Epoch[2/5]  [ 400/3125]  eta: 0:15:57  Lr: 0.001875  Loss: -0.3598  Acc@1: 87.5000 (84.4140)  Acc@5: 100.0000 (98.2076)  time: 0.3537  data: 0.0009  max mem: 2502
Train: Epoch[2/5]  [ 410/3125]  eta: 0:15:54  Lr: 0.001875  Loss: -0.2321  Acc@1: 87.5000 (84.5347)  Acc@5: 100.0000 (98.2056)  time: 0.3499  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [ 420/3125]  eta: 0:15:50  Lr: 0.001875  Loss: -0.2729  Acc@1: 87.5000 (84.4863)  Acc@5: 100.0000 (98.2185)  time: 0.3518  data: 0.0007  max mem: 2502
Train: Epoch[2/5]  [ 430/3125]  eta: 0:15:47  Lr: 0.001875  Loss: -0.1052  Acc@1: 75.0000 (84.3532)  Acc@5: 100.0000 (98.2309)  time: 0.3507  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [ 440/3125]  eta: 0:15:43  Lr: 0.001875  Loss: -0.4002  Acc@1: 81.2500 (84.3396)  Acc@5: 100.0000 (98.2285)  time: 0.3491  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [ 450/3125]  eta: 0:15:39  Lr: 0.001875  Loss: -0.4784  Acc@1: 81.2500 (84.3819)  Acc@5: 100.0000 (98.2262)  time: 0.3497  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [ 460/3125]  eta: 0:15:36  Lr: 0.001875  Loss: -0.5478  Acc@1: 87.5000 (84.3953)  Acc@5: 100.0000 (98.2240)  time: 0.3483  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [ 470/3125]  eta: 0:15:32  Lr: 0.001875  Loss: -0.7799  Acc@1: 87.5000 (84.4214)  Acc@5: 100.0000 (98.2351)  time: 0.3480  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [ 480/3125]  eta: 0:15:28  Lr: 0.001875  Loss: -0.7028  Acc@1: 87.5000 (84.4075)  Acc@5: 100.0000 (98.2458)  time: 0.3495  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [ 490/3125]  eta: 0:15:25  Lr: 0.001875  Loss: -0.7375  Acc@1: 81.2500 (84.4323)  Acc@5: 100.0000 (98.2688)  time: 0.3485  data: 0.0007  max mem: 2502
Train: Epoch[2/5]  [ 500/3125]  eta: 0:15:21  Lr: 0.001875  Loss: -0.5945  Acc@1: 81.2500 (84.4311)  Acc@5: 100.0000 (98.2660)  time: 0.3458  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [ 510/3125]  eta: 0:15:17  Lr: 0.001875  Loss: -0.5664  Acc@1: 87.5000 (84.3689)  Acc@5: 100.0000 (98.2877)  time: 0.3460  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [ 520/3125]  eta: 0:15:14  Lr: 0.001875  Loss: -0.6964  Acc@1: 87.5000 (84.5130)  Acc@5: 100.0000 (98.3205)  time: 0.3511  data: 0.0015  max mem: 2502
Train: Epoch[2/5]  [ 530/3125]  eta: 0:15:10  Lr: 0.001875  Loss: -0.6715  Acc@1: 87.5000 (84.5221)  Acc@5: 100.0000 (98.3404)  time: 0.3532  data: 0.0016  max mem: 2502
Train: Epoch[2/5]  [ 540/3125]  eta: 0:15:07  Lr: 0.001875  Loss: -0.7384  Acc@1: 87.5000 (84.6118)  Acc@5: 100.0000 (98.3480)  time: 0.3514  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [ 550/3125]  eta: 0:15:03  Lr: 0.001875  Loss: -0.5479  Acc@1: 87.5000 (84.5735)  Acc@5: 100.0000 (98.3212)  time: 0.3490  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [ 560/3125]  eta: 0:15:00  Lr: 0.001875  Loss: -0.0814  Acc@1: 81.2500 (84.5588)  Acc@5: 100.0000 (98.3177)  time: 0.3529  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [ 570/3125]  eta: 0:14:57  Lr: 0.001875  Loss: -0.2904  Acc@1: 87.5000 (84.6432)  Acc@5: 100.0000 (98.3253)  time: 0.3586  data: 0.0015  max mem: 2502
Train: Epoch[2/5]  [ 580/3125]  eta: 0:14:53  Lr: 0.001875  Loss: -0.7097  Acc@1: 87.5000 (84.6063)  Acc@5: 100.0000 (98.3111)  time: 0.3538  data: 0.0015  max mem: 2502
Train: Epoch[2/5]  [ 590/3125]  eta: 0:14:50  Lr: 0.001875  Loss: 0.0180  Acc@1: 81.2500 (84.6447)  Acc@5: 100.0000 (98.3080)  time: 0.3497  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [ 600/3125]  eta: 0:14:46  Lr: 0.001875  Loss: -0.6691  Acc@1: 81.2500 (84.6090)  Acc@5: 100.0000 (98.3049)  time: 0.3489  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [ 610/3125]  eta: 0:14:43  Lr: 0.001875  Loss: -0.4118  Acc@1: 81.2500 (84.5847)  Acc@5: 100.0000 (98.3020)  time: 0.3542  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [ 620/3125]  eta: 0:14:39  Lr: 0.001875  Loss: -0.2943  Acc@1: 81.2500 (84.5914)  Acc@5: 100.0000 (98.3192)  time: 0.3552  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [ 630/3125]  eta: 0:14:36  Lr: 0.001875  Loss: -0.8206  Acc@1: 87.5000 (84.6573)  Acc@5: 100.0000 (98.3063)  time: 0.3484  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [ 640/3125]  eta: 0:14:32  Lr: 0.001875  Loss: -0.5642  Acc@1: 87.5000 (84.6334)  Acc@5: 100.0000 (98.2937)  time: 0.3488  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [ 650/3125]  eta: 0:14:29  Lr: 0.001875  Loss: -0.3488  Acc@1: 87.5000 (84.7254)  Acc@5: 100.0000 (98.3199)  time: 0.3496  data: 0.0007  max mem: 2502
Train: Epoch[2/5]  [ 660/3125]  eta: 0:14:25  Lr: 0.001875  Loss: -0.4264  Acc@1: 87.5000 (84.7674)  Acc@5: 100.0000 (98.3264)  time: 0.3494  data: 0.0018  max mem: 2502
Train: Epoch[2/5]  [ 670/3125]  eta: 0:14:21  Lr: 0.001875  Loss: -0.8128  Acc@1: 87.5000 (84.8547)  Acc@5: 100.0000 (98.3327)  time: 0.3492  data: 0.0014  max mem: 2502
Train: Epoch[2/5]  [ 680/3125]  eta: 0:14:18  Lr: 0.001875  Loss: -0.1949  Acc@1: 87.5000 (84.8293)  Acc@5: 100.0000 (98.3297)  time: 0.3462  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [ 690/3125]  eta: 0:14:14  Lr: 0.001875  Loss: -0.1450  Acc@1: 81.2500 (84.8589)  Acc@5: 100.0000 (98.3086)  time: 0.3476  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [ 700/3125]  eta: 0:14:10  Lr: 0.001875  Loss: -0.3523  Acc@1: 81.2500 (84.8163)  Acc@5: 100.0000 (98.2882)  time: 0.3490  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [ 710/3125]  eta: 0:14:07  Lr: 0.001875  Loss: -0.2623  Acc@1: 81.2500 (84.7925)  Acc@5: 100.0000 (98.2683)  time: 0.3462  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [ 720/3125]  eta: 0:14:03  Lr: 0.001875  Loss: -0.1243  Acc@1: 87.5000 (84.7607)  Acc@5: 93.7500 (98.2403)  time: 0.3466  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [ 730/3125]  eta: 0:14:00  Lr: 0.001875  Loss: -0.3987  Acc@1: 81.2500 (84.6956)  Acc@5: 93.7500 (98.2302)  time: 0.3532  data: 0.0013  max mem: 2502
Train: Epoch[2/5]  [ 740/3125]  eta: 0:13:57  Lr: 0.001875  Loss: -0.8450  Acc@1: 81.2500 (84.6829)  Acc@5: 100.0000 (98.2203)  time: 0.3577  data: 0.0020  max mem: 2502
Train: Epoch[2/5]  [ 750/3125]  eta: 0:13:53  Lr: 0.001875  Loss: -0.7425  Acc@1: 81.2500 (84.6704)  Acc@5: 100.0000 (98.2190)  time: 0.3529  data: 0.0012  max mem: 2502
Train: Epoch[2/5]  [ 760/3125]  eta: 0:13:49  Lr: 0.001875  Loss: -0.5703  Acc@1: 87.5000 (84.7158)  Acc@5: 100.0000 (98.2260)  time: 0.3494  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [ 770/3125]  eta: 0:13:46  Lr: 0.001875  Loss: -0.5790  Acc@1: 87.5000 (84.7114)  Acc@5: 100.0000 (98.2247)  time: 0.3489  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [ 780/3125]  eta: 0:13:43  Lr: 0.001875  Loss: -0.2477  Acc@1: 87.5000 (84.7071)  Acc@5: 100.0000 (98.2234)  time: 0.3539  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [ 790/3125]  eta: 0:13:39  Lr: 0.001875  Loss: -0.1505  Acc@1: 87.5000 (84.6634)  Acc@5: 100.0000 (98.2064)  time: 0.3571  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [ 800/3125]  eta: 0:13:36  Lr: 0.001875  Loss: -0.4366  Acc@1: 87.5000 (84.6598)  Acc@5: 100.0000 (98.2132)  time: 0.3526  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [ 810/3125]  eta: 0:13:32  Lr: 0.001875  Loss: -0.1047  Acc@1: 87.5000 (84.6332)  Acc@5: 100.0000 (98.2121)  time: 0.3491  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [ 820/3125]  eta: 0:13:28  Lr: 0.001875  Loss: -0.2082  Acc@1: 81.2500 (84.5843)  Acc@5: 100.0000 (98.1958)  time: 0.3475  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [ 830/3125]  eta: 0:13:25  Lr: 0.001875  Loss: -0.3539  Acc@1: 81.2500 (84.6044)  Acc@5: 100.0000 (98.2025)  time: 0.3484  data: 0.0010  max mem: 2502
Train: Epoch[2/5]  [ 840/3125]  eta: 0:13:21  Lr: 0.001875  Loss: -0.5430  Acc@1: 87.5000 (84.6017)  Acc@5: 100.0000 (98.2015)  time: 0.3480  data: 0.0010  max mem: 2502
Train: Epoch[2/5]  [ 850/3125]  eta: 0:13:18  Lr: 0.001875  Loss: -0.7306  Acc@1: 87.5000 (84.6063)  Acc@5: 100.0000 (98.1713)  time: 0.3477  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [ 860/3125]  eta: 0:13:14  Lr: 0.001875  Loss: -0.0659  Acc@1: 87.5000 (84.6182)  Acc@5: 93.7500 (98.1490)  time: 0.3471  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [ 870/3125]  eta: 0:13:10  Lr: 0.001875  Loss: -0.8041  Acc@1: 87.5000 (84.6369)  Acc@5: 100.0000 (98.1702)  time: 0.3470  data: 0.0009  max mem: 2502
Train: Epoch[2/5]  [ 880/3125]  eta: 0:13:07  Lr: 0.001875  Loss: -0.4986  Acc@1: 87.5000 (84.6127)  Acc@5: 100.0000 (98.1768)  time: 0.3468  data: 0.0010  max mem: 2502
Train: Epoch[2/5]  [ 890/3125]  eta: 0:13:03  Lr: 0.001875  Loss: -0.3056  Acc@1: 87.5000 (84.6871)  Acc@5: 100.0000 (98.1902)  time: 0.3454  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [ 900/3125]  eta: 0:13:00  Lr: 0.001875  Loss: -0.0744  Acc@1: 87.5000 (84.6698)  Acc@5: 100.0000 (98.1826)  time: 0.3462  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [ 910/3125]  eta: 0:12:56  Lr: 0.001875  Loss: -0.5449  Acc@1: 87.5000 (84.7009)  Acc@5: 100.0000 (98.1957)  time: 0.3499  data: 0.0012  max mem: 2502
Train: Epoch[2/5]  [ 920/3125]  eta: 0:12:53  Lr: 0.001875  Loss: -0.8452  Acc@1: 87.5000 (84.7245)  Acc@5: 100.0000 (98.2153)  time: 0.3497  data: 0.0012  max mem: 2502
Train: Epoch[2/5]  [ 930/3125]  eta: 0:12:49  Lr: 0.001875  Loss: -0.6803  Acc@1: 87.5000 (84.7274)  Acc@5: 100.0000 (98.2143)  time: 0.3500  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [ 940/3125]  eta: 0:12:46  Lr: 0.001875  Loss: -0.4984  Acc@1: 87.5000 (84.7104)  Acc@5: 100.0000 (98.2001)  time: 0.3516  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [ 950/3125]  eta: 0:12:42  Lr: 0.001875  Loss: -0.5946  Acc@1: 87.5000 (84.7200)  Acc@5: 100.0000 (98.1993)  time: 0.3533  data: 0.0010  max mem: 2502
Train: Epoch[2/5]  [ 960/3125]  eta: 0:12:39  Lr: 0.001875  Loss: -0.3282  Acc@1: 87.5000 (84.7360)  Acc@5: 100.0000 (98.1920)  time: 0.3542  data: 0.0010  max mem: 2502
Train: Epoch[2/5]  [ 970/3125]  eta: 0:12:35  Lr: 0.001875  Loss: -0.7048  Acc@1: 87.5000 (84.7644)  Acc@5: 100.0000 (98.1977)  time: 0.3539  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [ 980/3125]  eta: 0:12:32  Lr: 0.001875  Loss: -0.4328  Acc@1: 87.5000 (84.7541)  Acc@5: 100.0000 (98.2097)  time: 0.3537  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [ 990/3125]  eta: 0:12:28  Lr: 0.001875  Loss: -0.7053  Acc@1: 87.5000 (84.7818)  Acc@5: 100.0000 (98.2026)  time: 0.3535  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [1000/3125]  eta: 0:12:25  Lr: 0.001875  Loss: -0.6561  Acc@1: 87.5000 (84.8152)  Acc@5: 100.0000 (98.2143)  time: 0.3552  data: 0.0015  max mem: 2502
Train: Epoch[2/5]  [1010/3125]  eta: 0:12:21  Lr: 0.001875  Loss: -0.0929  Acc@1: 87.5000 (84.7985)  Acc@5: 100.0000 (98.2196)  time: 0.3514  data: 0.0015  max mem: 2502
Train: Epoch[2/5]  [1020/3125]  eta: 0:12:18  Lr: 0.001875  Loss: -0.4478  Acc@1: 87.5000 (84.8188)  Acc@5: 100.0000 (98.2003)  time: 0.3474  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [1030/3125]  eta: 0:12:14  Lr: 0.001875  Loss: -0.5956  Acc@1: 81.2500 (84.7903)  Acc@5: 100.0000 (98.2117)  time: 0.3475  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [1040/3125]  eta: 0:12:11  Lr: 0.001875  Loss: -0.6207  Acc@1: 81.2500 (84.7983)  Acc@5: 100.0000 (98.2169)  time: 0.3493  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [1050/3125]  eta: 0:12:07  Lr: 0.001875  Loss: -0.5613  Acc@1: 87.5000 (84.8240)  Acc@5: 100.0000 (98.2219)  time: 0.3492  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [1060/3125]  eta: 0:12:04  Lr: 0.001875  Loss: -0.2954  Acc@1: 87.5000 (84.8139)  Acc@5: 100.0000 (98.2269)  time: 0.3470  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [1070/3125]  eta: 0:12:00  Lr: 0.001875  Loss: -0.3580  Acc@1: 87.5000 (84.8156)  Acc@5: 100.0000 (98.2318)  time: 0.3455  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [1080/3125]  eta: 0:11:56  Lr: 0.001875  Loss: -0.7594  Acc@1: 87.5000 (84.7884)  Acc@5: 100.0000 (98.2192)  time: 0.3463  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [1090/3125]  eta: 0:11:53  Lr: 0.001875  Loss: -0.3666  Acc@1: 87.5000 (84.8018)  Acc@5: 100.0000 (98.2241)  time: 0.3464  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [1100/3125]  eta: 0:11:49  Lr: 0.001875  Loss: -0.0997  Acc@1: 87.5000 (84.7866)  Acc@5: 100.0000 (98.2289)  time: 0.3467  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [1110/3125]  eta: 0:11:46  Lr: 0.001875  Loss: -0.6219  Acc@1: 81.2500 (84.7660)  Acc@5: 100.0000 (98.2392)  time: 0.3501  data: 0.0021  max mem: 2502
Train: Epoch[2/5]  [1120/3125]  eta: 0:11:42  Lr: 0.001875  Loss: -0.1369  Acc@1: 87.5000 (84.7625)  Acc@5: 100.0000 (98.2215)  time: 0.3531  data: 0.0023  max mem: 2502
Train: Epoch[2/5]  [1130/3125]  eta: 0:11:39  Lr: 0.001875  Loss: -0.3980  Acc@1: 81.2500 (84.7425)  Acc@5: 100.0000 (98.2206)  time: 0.3525  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [1140/3125]  eta: 0:11:35  Lr: 0.001875  Loss: -0.5281  Acc@1: 81.2500 (84.7283)  Acc@5: 100.0000 (98.2252)  time: 0.3504  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [1150/3125]  eta: 0:11:32  Lr: 0.001875  Loss: -0.7863  Acc@1: 81.2500 (84.7144)  Acc@5: 100.0000 (98.1972)  time: 0.3500  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [1160/3125]  eta: 0:11:28  Lr: 0.001875  Loss: -0.3089  Acc@1: 81.2500 (84.7384)  Acc@5: 100.0000 (98.1966)  time: 0.3520  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [1170/3125]  eta: 0:11:25  Lr: 0.001875  Loss: -0.0722  Acc@1: 81.2500 (84.7246)  Acc@5: 100.0000 (98.1906)  time: 0.3507  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [1180/3125]  eta: 0:11:21  Lr: 0.001875  Loss: 0.2250  Acc@1: 81.2500 (84.7005)  Acc@5: 100.0000 (98.1901)  time: 0.3474  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [1190/3125]  eta: 0:11:18  Lr: 0.001875  Loss: -0.6280  Acc@1: 87.5000 (84.7345)  Acc@5: 100.0000 (98.1948)  time: 0.3471  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [1200/3125]  eta: 0:11:14  Lr: 0.001875  Loss: -0.8428  Acc@1: 87.5000 (84.7575)  Acc@5: 100.0000 (98.1942)  time: 0.3494  data: 0.0012  max mem: 2502
Train: Epoch[2/5]  [1210/3125]  eta: 0:11:11  Lr: 0.001875  Loss: -0.1531  Acc@1: 81.2500 (84.7440)  Acc@5: 100.0000 (98.1833)  time: 0.3496  data: 0.0014  max mem: 2502
Train: Epoch[2/5]  [1220/3125]  eta: 0:11:07  Lr: 0.001875  Loss: -0.6919  Acc@1: 81.2500 (84.7512)  Acc@5: 100.0000 (98.1828)  time: 0.3475  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [1230/3125]  eta: 0:11:04  Lr: 0.001875  Loss: -0.4735  Acc@1: 87.5000 (84.7431)  Acc@5: 100.0000 (98.1824)  time: 0.3481  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [1240/3125]  eta: 0:11:00  Lr: 0.001875  Loss: -0.7690  Acc@1: 87.5000 (84.7452)  Acc@5: 100.0000 (98.1819)  time: 0.3483  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [1250/3125]  eta: 0:10:57  Lr: 0.001875  Loss: -0.7851  Acc@1: 87.5000 (84.7922)  Acc@5: 100.0000 (98.1865)  time: 0.3491  data: 0.0007  max mem: 2502
Train: Epoch[2/5]  [1260/3125]  eta: 0:10:53  Lr: 0.001875  Loss: -0.4935  Acc@1: 87.5000 (84.7938)  Acc@5: 100.0000 (98.2008)  time: 0.3487  data: 0.0007  max mem: 2502
Train: Epoch[2/5]  [1270/3125]  eta: 0:10:49  Lr: 0.001875  Loss: -0.8848  Acc@1: 81.2500 (84.7856)  Acc@5: 100.0000 (98.2052)  time: 0.3459  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [1280/3125]  eta: 0:10:46  Lr: 0.001875  Loss: -0.5741  Acc@1: 87.5000 (84.8019)  Acc@5: 100.0000 (98.2045)  time: 0.3449  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [1290/3125]  eta: 0:10:42  Lr: 0.001875  Loss: -0.6275  Acc@1: 87.5000 (84.7986)  Acc@5: 100.0000 (98.2039)  time: 0.3481  data: 0.0009  max mem: 2502
Train: Epoch[2/5]  [1300/3125]  eta: 0:10:39  Lr: 0.001875  Loss: -0.8437  Acc@1: 87.5000 (84.8386)  Acc@5: 100.0000 (98.2177)  time: 0.3490  data: 0.0008  max mem: 2502
Train: Epoch[2/5]  [1310/3125]  eta: 0:10:35  Lr: 0.001875  Loss: -0.4728  Acc@1: 87.5000 (84.8160)  Acc@5: 100.0000 (98.2218)  time: 0.3468  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [1320/3125]  eta: 0:10:32  Lr: 0.001875  Loss: -0.7425  Acc@1: 87.5000 (84.8363)  Acc@5: 100.0000 (98.2305)  time: 0.3472  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [1330/3125]  eta: 0:10:28  Lr: 0.001875  Loss: -0.2237  Acc@1: 87.5000 (84.8281)  Acc@5: 100.0000 (98.2203)  time: 0.3532  data: 0.0021  max mem: 2502
Train: Epoch[2/5]  [1340/3125]  eta: 0:10:25  Lr: 0.001875  Loss: -0.7245  Acc@1: 81.2500 (84.8294)  Acc@5: 100.0000 (98.2150)  time: 0.3549  data: 0.0022  max mem: 2502
Train: Epoch[2/5]  [1350/3125]  eta: 0:10:21  Lr: 0.001875  Loss: -0.5037  Acc@1: 81.2500 (84.8261)  Acc@5: 100.0000 (98.2189)  time: 0.3539  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [1360/3125]  eta: 0:10:18  Lr: 0.001875  Loss: -0.0639  Acc@1: 81.2500 (84.8227)  Acc@5: 100.0000 (98.2228)  time: 0.3530  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [1370/3125]  eta: 0:10:14  Lr: 0.001875  Loss: -0.1482  Acc@1: 87.5000 (84.8149)  Acc@5: 100.0000 (98.2312)  time: 0.3507  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [1380/3125]  eta: 0:10:11  Lr: 0.001875  Loss: -0.6202  Acc@1: 81.2500 (84.8163)  Acc@5: 100.0000 (98.2395)  time: 0.3526  data: 0.0009  max mem: 2502
Train: Epoch[2/5]  [1390/3125]  eta: 0:10:08  Lr: 0.001875  Loss: -0.6334  Acc@1: 81.2500 (84.8266)  Acc@5: 100.0000 (98.2252)  time: 0.3567  data: 0.0009  max mem: 2502
Train: Epoch[2/5]  [1400/3125]  eta: 0:10:04  Lr: 0.001875  Loss: -0.1527  Acc@1: 81.2500 (84.7966)  Acc@5: 100.0000 (98.2156)  time: 0.3536  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [1410/3125]  eta: 0:10:00  Lr: 0.001875  Loss: -0.6624  Acc@1: 87.5000 (84.8024)  Acc@5: 100.0000 (98.2016)  time: 0.3475  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [1420/3125]  eta: 0:09:57  Lr: 0.001875  Loss: -0.5611  Acc@1: 81.2500 (84.7686)  Acc@5: 100.0000 (98.1967)  time: 0.3491  data: 0.0009  max mem: 2502
Train: Epoch[2/5]  [1430/3125]  eta: 0:09:53  Lr: 0.001875  Loss: -0.1646  Acc@1: 81.2500 (84.7528)  Acc@5: 100.0000 (98.2049)  time: 0.3513  data: 0.0015  max mem: 2502
Train: Epoch[2/5]  [1440/3125]  eta: 0:09:50  Lr: 0.001875  Loss: -0.4861  Acc@1: 81.2500 (84.7285)  Acc@5: 100.0000 (98.2087)  time: 0.3503  data: 0.0012  max mem: 2502
Train: Epoch[2/5]  [1450/3125]  eta: 0:09:46  Lr: 0.001875  Loss: -0.7925  Acc@1: 87.5000 (84.7217)  Acc@5: 100.0000 (98.1995)  time: 0.3464  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [1460/3125]  eta: 0:09:43  Lr: 0.001875  Loss: -0.5778  Acc@1: 87.5000 (84.7579)  Acc@5: 100.0000 (98.2033)  time: 0.3449  data: 0.0002  max mem: 2502
Train: Epoch[2/5]  [1470/3125]  eta: 0:09:39  Lr: 0.001875  Loss: -0.6924  Acc@1: 93.7500 (84.8020)  Acc@5: 100.0000 (98.2113)  time: 0.3456  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [1480/3125]  eta: 0:09:36  Lr: 0.001875  Loss: -0.5166  Acc@1: 87.5000 (84.8076)  Acc@5: 100.0000 (98.2191)  time: 0.3454  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [1490/3125]  eta: 0:09:32  Lr: 0.001875  Loss: -0.5332  Acc@1: 81.2500 (84.8047)  Acc@5: 100.0000 (98.2143)  time: 0.3459  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [1500/3125]  eta: 0:09:29  Lr: 0.001875  Loss: -0.1314  Acc@1: 87.5000 (84.8309)  Acc@5: 100.0000 (98.2137)  time: 0.3513  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [1510/3125]  eta: 0:09:25  Lr: 0.001875  Loss: -0.8287  Acc@1: 87.5000 (84.8527)  Acc@5: 100.0000 (98.2214)  time: 0.3543  data: 0.0013  max mem: 2502
Train: Epoch[2/5]  [1520/3125]  eta: 0:09:22  Lr: 0.001875  Loss: -0.6060  Acc@1: 87.5000 (84.8578)  Acc@5: 100.0000 (98.2249)  time: 0.3506  data: 0.0011  max mem: 2502
Train: Epoch[2/5]  [1530/3125]  eta: 0:09:18  Lr: 0.001875  Loss: -0.4755  Acc@1: 81.2500 (84.8424)  Acc@5: 100.0000 (98.2242)  time: 0.3508  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [1540/3125]  eta: 0:09:15  Lr: 0.001875  Loss: -0.2406  Acc@1: 81.2500 (84.8475)  Acc@5: 100.0000 (98.2236)  time: 0.3523  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [1550/3125]  eta: 0:09:11  Lr: 0.001875  Loss: -0.3792  Acc@1: 81.2500 (84.8203)  Acc@5: 100.0000 (98.2229)  time: 0.3533  data: 0.0010  max mem: 2502
Train: Epoch[2/5]  [1560/3125]  eta: 0:09:08  Lr: 0.001875  Loss: -0.4646  Acc@1: 81.2500 (84.8134)  Acc@5: 100.0000 (98.2263)  time: 0.3542  data: 0.0010  max mem: 2502
Train: Epoch[2/5]  [1570/3125]  eta: 0:09:04  Lr: 0.001875  Loss: -0.6971  Acc@1: 81.2500 (84.7947)  Acc@5: 100.0000 (98.2257)  time: 0.3509  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [1580/3125]  eta: 0:09:01  Lr: 0.001875  Loss: -0.8464  Acc@1: 87.5000 (84.8276)  Acc@5: 100.0000 (98.2211)  time: 0.3506  data: 0.0008  max mem: 2502
Train: Epoch[2/5]  [1590/3125]  eta: 0:08:57  Lr: 0.001875  Loss: -0.3322  Acc@1: 87.5000 (84.7894)  Acc@5: 100.0000 (98.2322)  time: 0.3510  data: 0.0018  max mem: 2502
Train: Epoch[2/5]  [1600/3125]  eta: 0:08:54  Lr: 0.001875  Loss: -0.7451  Acc@1: 81.2500 (84.8064)  Acc@5: 100.0000 (98.2355)  time: 0.3504  data: 0.0015  max mem: 2502
Train: Epoch[2/5]  [1610/3125]  eta: 0:08:50  Lr: 0.001875  Loss: -0.7358  Acc@1: 87.5000 (84.8037)  Acc@5: 100.0000 (98.2348)  time: 0.3496  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [1620/3125]  eta: 0:08:47  Lr: 0.001875  Loss: -0.5944  Acc@1: 81.2500 (84.7856)  Acc@5: 100.0000 (98.2187)  time: 0.3483  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [1630/3125]  eta: 0:08:43  Lr: 0.001875  Loss: -0.6826  Acc@1: 81.2500 (84.8061)  Acc@5: 100.0000 (98.2296)  time: 0.3489  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [1640/3125]  eta: 0:08:40  Lr: 0.001875  Loss: -0.5892  Acc@1: 87.5000 (84.8035)  Acc@5: 100.0000 (98.2252)  time: 0.3480  data: 0.0009  max mem: 2502
Train: Epoch[2/5]  [1650/3125]  eta: 0:08:36  Lr: 0.001875  Loss: -0.4988  Acc@1: 87.5000 (84.8084)  Acc@5: 100.0000 (98.2321)  time: 0.3476  data: 0.0008  max mem: 2502
Train: Epoch[2/5]  [1660/3125]  eta: 0:08:33  Lr: 0.001875  Loss: -0.2170  Acc@1: 87.5000 (84.8359)  Acc@5: 100.0000 (98.2277)  time: 0.3466  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [1670/3125]  eta: 0:08:29  Lr: 0.001875  Loss: -0.3321  Acc@1: 87.5000 (84.8332)  Acc@5: 100.0000 (98.2196)  time: 0.3458  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [1680/3125]  eta: 0:08:26  Lr: 0.001875  Loss: -0.4170  Acc@1: 87.5000 (84.8453)  Acc@5: 100.0000 (98.2191)  time: 0.3515  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [1690/3125]  eta: 0:08:22  Lr: 0.001875  Loss: -0.3648  Acc@1: 87.5000 (84.8573)  Acc@5: 100.0000 (98.2148)  time: 0.3527  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [1700/3125]  eta: 0:08:19  Lr: 0.001875  Loss: -0.7067  Acc@1: 87.5000 (84.8655)  Acc@5: 100.0000 (98.2180)  time: 0.3483  data: 0.0007  max mem: 2502
Train: Epoch[2/5]  [1710/3125]  eta: 0:08:15  Lr: 0.001875  Loss: -0.6398  Acc@1: 87.5000 (84.8736)  Acc@5: 100.0000 (98.2284)  time: 0.3512  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [1720/3125]  eta: 0:08:12  Lr: 0.001875  Loss: -0.6542  Acc@1: 87.5000 (84.8816)  Acc@5: 100.0000 (98.2350)  time: 0.3544  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [1730/3125]  eta: 0:08:08  Lr: 0.001875  Loss: -0.8154  Acc@1: 87.5000 (84.9148)  Acc@5: 100.0000 (98.2308)  time: 0.3534  data: 0.0010  max mem: 2502
Train: Epoch[2/5]  [1740/3125]  eta: 0:08:05  Lr: 0.001875  Loss: -0.5935  Acc@1: 93.7500 (84.9332)  Acc@5: 100.0000 (98.2374)  time: 0.3531  data: 0.0009  max mem: 2502
Train: Epoch[2/5]  [1750/3125]  eta: 0:08:01  Lr: 0.001875  Loss: -0.2805  Acc@1: 87.5000 (84.9229)  Acc@5: 100.0000 (98.2403)  time: 0.3514  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [1760/3125]  eta: 0:07:58  Lr: 0.001875  Loss: -0.5968  Acc@1: 81.2500 (84.9162)  Acc@5: 100.0000 (98.2432)  time: 0.3511  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [1770/3125]  eta: 0:07:54  Lr: 0.001875  Loss: -0.4595  Acc@1: 87.5000 (84.9449)  Acc@5: 100.0000 (98.2425)  time: 0.3516  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [1780/3125]  eta: 0:07:51  Lr: 0.001875  Loss: -0.8233  Acc@1: 93.7500 (84.9698)  Acc@5: 100.0000 (98.2454)  time: 0.3495  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [1790/3125]  eta: 0:07:47  Lr: 0.001875  Loss: -0.7287  Acc@1: 87.5000 (84.9700)  Acc@5: 100.0000 (98.2447)  time: 0.3488  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [1800/3125]  eta: 0:07:44  Lr: 0.001875  Loss: -0.6413  Acc@1: 87.5000 (84.9840)  Acc@5: 100.0000 (98.2440)  time: 0.3483  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [1810/3125]  eta: 0:07:40  Lr: 0.001875  Loss: -0.6968  Acc@1: 87.5000 (84.9807)  Acc@5: 100.0000 (98.2503)  time: 0.3486  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [1820/3125]  eta: 0:07:37  Lr: 0.001875  Loss: -0.4377  Acc@1: 87.5000 (84.9739)  Acc@5: 100.0000 (98.2427)  time: 0.3488  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [1830/3125]  eta: 0:07:33  Lr: 0.001875  Loss: -0.4875  Acc@1: 87.5000 (84.9980)  Acc@5: 100.0000 (98.2489)  time: 0.3467  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [1840/3125]  eta: 0:07:30  Lr: 0.001875  Loss: -0.6341  Acc@1: 87.5000 (85.0048)  Acc@5: 100.0000 (98.2516)  time: 0.3479  data: 0.0016  max mem: 2502
Train: Epoch[2/5]  [1850/3125]  eta: 0:07:26  Lr: 0.001875  Loss: -0.7496  Acc@1: 87.5000 (85.0047)  Acc@5: 100.0000 (98.2611)  time: 0.3522  data: 0.0017  max mem: 2502
Train: Epoch[2/5]  [1860/3125]  eta: 0:07:23  Lr: 0.001875  Loss: -0.5939  Acc@1: 81.2500 (84.9913)  Acc@5: 100.0000 (98.2570)  time: 0.3519  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [1870/3125]  eta: 0:07:19  Lr: 0.001875  Loss: -0.8483  Acc@1: 81.2500 (84.9913)  Acc@5: 100.0000 (98.2596)  time: 0.3519  data: 0.0011  max mem: 2502
Train: Epoch[2/5]  [1880/3125]  eta: 0:07:16  Lr: 0.001875  Loss: -0.3934  Acc@1: 81.2500 (84.9747)  Acc@5: 100.0000 (98.2589)  time: 0.3533  data: 0.0011  max mem: 2502
Train: Epoch[2/5]  [1890/3125]  eta: 0:07:12  Lr: 0.001875  Loss: -0.7213  Acc@1: 87.5000 (84.9947)  Acc@5: 100.0000 (98.2549)  time: 0.3564  data: 0.0007  max mem: 2502
Train: Epoch[2/5]  [1900/3125]  eta: 0:07:09  Lr: 0.001875  Loss: -0.1595  Acc@1: 87.5000 (84.9882)  Acc@5: 100.0000 (98.2542)  time: 0.3556  data: 0.0010  max mem: 2502
Train: Epoch[2/5]  [1910/3125]  eta: 0:07:05  Lr: 0.001875  Loss: -0.5139  Acc@1: 87.5000 (85.0111)  Acc@5: 100.0000 (98.2601)  time: 0.3524  data: 0.0009  max mem: 2502
Train: Epoch[2/5]  [1920/3125]  eta: 0:07:02  Lr: 0.001875  Loss: -0.8045  Acc@1: 87.5000 (85.0143)  Acc@5: 100.0000 (98.2561)  time: 0.3549  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [1930/3125]  eta: 0:06:58  Lr: 0.001875  Loss: -0.1248  Acc@1: 87.5000 (85.0175)  Acc@5: 100.0000 (98.2587)  time: 0.3551  data: 0.0015  max mem: 2502
Train: Epoch[2/5]  [1940/3125]  eta: 0:06:55  Lr: 0.001875  Loss: -0.5285  Acc@1: 87.5000 (85.0206)  Acc@5: 100.0000 (98.2644)  time: 0.3557  data: 0.0016  max mem: 2502
Train: Epoch[2/5]  [1950/3125]  eta: 0:06:51  Lr: 0.001875  Loss: -0.2295  Acc@1: 87.5000 (85.0333)  Acc@5: 100.0000 (98.2477)  time: 0.3533  data: 0.0012  max mem: 2502
Train: Epoch[2/5]  [1960/3125]  eta: 0:06:48  Lr: 0.001875  Loss: -0.4954  Acc@1: 87.5000 (85.0427)  Acc@5: 100.0000 (98.2503)  time: 0.3490  data: 0.0012  max mem: 2502
Train: Epoch[2/5]  [1970/3125]  eta: 0:06:44  Lr: 0.001875  Loss: -0.4006  Acc@1: 87.5000 (85.0457)  Acc@5: 100.0000 (98.2528)  time: 0.3483  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [1980/3125]  eta: 0:06:41  Lr: 0.001875  Loss: -0.5699  Acc@1: 87.5000 (85.0297)  Acc@5: 100.0000 (98.2521)  time: 0.3481  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [1990/3125]  eta: 0:06:37  Lr: 0.001875  Loss: -0.4336  Acc@1: 87.5000 (85.0264)  Acc@5: 100.0000 (98.2484)  time: 0.3488  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [2000/3125]  eta: 0:06:34  Lr: 0.001875  Loss: -0.6339  Acc@1: 87.5000 (85.0294)  Acc@5: 100.0000 (98.2478)  time: 0.3472  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [2010/3125]  eta: 0:06:30  Lr: 0.001875  Loss: -0.6748  Acc@1: 87.5000 (85.0323)  Acc@5: 100.0000 (98.2440)  time: 0.3455  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [2020/3125]  eta: 0:06:27  Lr: 0.001875  Loss: -0.5217  Acc@1: 81.2500 (85.0229)  Acc@5: 100.0000 (98.2465)  time: 0.3464  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [2030/3125]  eta: 0:06:23  Lr: 0.001875  Loss: -0.6559  Acc@1: 81.2500 (85.0135)  Acc@5: 100.0000 (98.2459)  time: 0.3473  data: 0.0007  max mem: 2502
Train: Epoch[2/5]  [2040/3125]  eta: 0:06:20  Lr: 0.001875  Loss: -0.0812  Acc@1: 81.2500 (85.0043)  Acc@5: 100.0000 (98.2484)  time: 0.3519  data: 0.0009  max mem: 2502
Train: Epoch[2/5]  [2050/3125]  eta: 0:06:16  Lr: 0.001875  Loss: -0.8143  Acc@1: 81.2500 (85.0043)  Acc@5: 100.0000 (98.2539)  time: 0.3527  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [2060/3125]  eta: 0:06:13  Lr: 0.001875  Loss: -0.7311  Acc@1: 87.5000 (85.0194)  Acc@5: 100.0000 (98.2533)  time: 0.3503  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [2070/3125]  eta: 0:06:09  Lr: 0.001875  Loss: -0.2422  Acc@1: 81.2500 (85.0012)  Acc@5: 100.0000 (98.2527)  time: 0.3524  data: 0.0015  max mem: 2502
Train: Epoch[2/5]  [2080/3125]  eta: 0:06:06  Lr: 0.001875  Loss: -0.6813  Acc@1: 87.5000 (85.0012)  Acc@5: 100.0000 (98.2520)  time: 0.3533  data: 0.0016  max mem: 2502
Train: Epoch[2/5]  [2090/3125]  eta: 0:06:02  Lr: 0.001875  Loss: -0.5503  Acc@1: 87.5000 (84.9922)  Acc@5: 100.0000 (98.2455)  time: 0.3549  data: 0.0011  max mem: 2502
Train: Epoch[2/5]  [2100/3125]  eta: 0:05:59  Lr: 0.001875  Loss: -0.4343  Acc@1: 81.2500 (85.0071)  Acc@5: 100.0000 (98.2479)  time: 0.3531  data: 0.0011  max mem: 2502
Train: Epoch[2/5]  [2110/3125]  eta: 0:05:55  Lr: 0.001875  Loss: -0.3381  Acc@1: 87.5000 (85.0189)  Acc@5: 100.0000 (98.2532)  time: 0.3487  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [2120/3125]  eta: 0:05:52  Lr: 0.001875  Loss: -0.4253  Acc@1: 87.5000 (85.0365)  Acc@5: 100.0000 (98.2496)  time: 0.3538  data: 0.0013  max mem: 2502
Train: Epoch[2/5]  [2130/3125]  eta: 0:05:48  Lr: 0.001875  Loss: -0.6054  Acc@1: 87.5000 (85.0393)  Acc@5: 100.0000 (98.2491)  time: 0.3563  data: 0.0013  max mem: 2502
Train: Epoch[2/5]  [2140/3125]  eta: 0:05:45  Lr: 0.001875  Loss: -0.8089  Acc@1: 87.5000 (85.0333)  Acc@5: 100.0000 (98.2456)  time: 0.3528  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [2150/3125]  eta: 0:05:41  Lr: 0.001875  Loss: -0.7400  Acc@1: 87.5000 (85.0506)  Acc@5: 100.0000 (98.2508)  time: 0.3500  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [2160/3125]  eta: 0:05:38  Lr: 0.001875  Loss: -0.3414  Acc@1: 87.5000 (85.0445)  Acc@5: 100.0000 (98.2531)  time: 0.3489  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [2170/3125]  eta: 0:05:34  Lr: 0.001875  Loss: -0.6320  Acc@1: 87.5000 (85.0357)  Acc@5: 100.0000 (98.2554)  time: 0.3499  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [2180/3125]  eta: 0:05:31  Lr: 0.001875  Loss: -0.5058  Acc@1: 81.2500 (85.0241)  Acc@5: 100.0000 (98.2462)  time: 0.3504  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [2190/3125]  eta: 0:05:27  Lr: 0.001875  Loss: -0.9075  Acc@1: 87.5000 (85.0525)  Acc@5: 100.0000 (98.2514)  time: 0.3495  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [2200/3125]  eta: 0:05:24  Lr: 0.001875  Loss: -0.6165  Acc@1: 87.5000 (85.0466)  Acc@5: 100.0000 (98.2451)  time: 0.3467  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [2210/3125]  eta: 0:05:20  Lr: 0.001875  Loss: -0.7935  Acc@1: 87.5000 (85.0577)  Acc@5: 100.0000 (98.2446)  time: 0.3481  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [2220/3125]  eta: 0:05:17  Lr: 0.001875  Loss: -0.4583  Acc@1: 87.5000 (85.0687)  Acc@5: 100.0000 (98.2468)  time: 0.3492  data: 0.0008  max mem: 2502
Train: Epoch[2/5]  [2230/3125]  eta: 0:05:13  Lr: 0.001875  Loss: -0.3321  Acc@1: 87.5000 (85.0768)  Acc@5: 100.0000 (98.2519)  time: 0.3469  data: 0.0007  max mem: 2502
Train: Epoch[2/5]  [2240/3125]  eta: 0:05:10  Lr: 0.001875  Loss: -0.4878  Acc@1: 87.5000 (85.0820)  Acc@5: 100.0000 (98.2569)  time: 0.3472  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [2250/3125]  eta: 0:05:06  Lr: 0.001875  Loss: -0.6634  Acc@1: 87.5000 (85.0900)  Acc@5: 100.0000 (98.2563)  time: 0.3518  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [2260/3125]  eta: 0:05:03  Lr: 0.001875  Loss: -0.3699  Acc@1: 87.5000 (85.1144)  Acc@5: 100.0000 (98.2613)  time: 0.3537  data: 0.0007  max mem: 2502
Train: Epoch[2/5]  [2270/3125]  eta: 0:04:59  Lr: 0.001875  Loss: -0.4955  Acc@1: 87.5000 (85.1194)  Acc@5: 100.0000 (98.2552)  time: 0.3498  data: 0.0007  max mem: 2502
Train: Epoch[2/5]  [2280/3125]  eta: 0:04:56  Lr: 0.001875  Loss: -0.5110  Acc@1: 81.2500 (85.1217)  Acc@5: 100.0000 (98.2546)  time: 0.3506  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [2290/3125]  eta: 0:04:52  Lr: 0.001875  Loss: -0.6335  Acc@1: 87.5000 (85.1266)  Acc@5: 100.0000 (98.2595)  time: 0.3530  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [2300/3125]  eta: 0:04:49  Lr: 0.001875  Loss: -0.5186  Acc@1: 87.5000 (85.1125)  Acc@5: 100.0000 (98.2562)  time: 0.3509  data: 0.0010  max mem: 2502
Train: Epoch[2/5]  [2310/3125]  eta: 0:04:45  Lr: 0.001875  Loss: -0.2792  Acc@1: 87.5000 (85.1147)  Acc@5: 100.0000 (98.2556)  time: 0.3505  data: 0.0009  max mem: 2502
Train: Epoch[2/5]  [2320/3125]  eta: 0:04:42  Lr: 0.001875  Loss: -0.6668  Acc@1: 81.2500 (85.0792)  Acc@5: 100.0000 (98.2551)  time: 0.3526  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [2330/3125]  eta: 0:04:38  Lr: 0.001875  Loss: -0.8022  Acc@1: 81.2500 (85.0896)  Acc@5: 100.0000 (98.2625)  time: 0.3513  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [2340/3125]  eta: 0:04:35  Lr: 0.001875  Loss: -0.8002  Acc@1: 87.5000 (85.1079)  Acc@5: 100.0000 (98.2700)  time: 0.3525  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [2350/3125]  eta: 0:04:31  Lr: 0.001875  Loss: -0.6229  Acc@1: 87.5000 (85.1154)  Acc@5: 100.0000 (98.2694)  time: 0.3531  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [2360/3125]  eta: 0:04:28  Lr: 0.001875  Loss: -0.7706  Acc@1: 87.5000 (85.1069)  Acc@5: 100.0000 (98.2555)  time: 0.3486  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [2370/3125]  eta: 0:04:24  Lr: 0.001875  Loss: -0.4223  Acc@1: 81.2500 (85.1039)  Acc@5: 100.0000 (98.2576)  time: 0.3475  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [2380/3125]  eta: 0:04:21  Lr: 0.001875  Loss: -0.7174  Acc@1: 93.7500 (85.1244)  Acc@5: 100.0000 (98.2570)  time: 0.3473  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [2390/3125]  eta: 0:04:17  Lr: 0.001875  Loss: -0.6646  Acc@1: 87.5000 (85.1317)  Acc@5: 100.0000 (98.2539)  time: 0.3480  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [2400/3125]  eta: 0:04:14  Lr: 0.001875  Loss: -0.8023  Acc@1: 87.5000 (85.1286)  Acc@5: 100.0000 (98.2585)  time: 0.3475  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [2410/3125]  eta: 0:04:10  Lr: 0.001875  Loss: -0.6650  Acc@1: 87.5000 (85.1281)  Acc@5: 100.0000 (98.2632)  time: 0.3458  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [2420/3125]  eta: 0:04:07  Lr: 0.001875  Loss: -0.6569  Acc@1: 87.5000 (85.1379)  Acc@5: 100.0000 (98.2678)  time: 0.3457  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [2430/3125]  eta: 0:04:03  Lr: 0.001875  Loss: -0.1685  Acc@1: 87.5000 (85.1244)  Acc@5: 100.0000 (98.2697)  time: 0.3483  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [2440/3125]  eta: 0:03:59  Lr: 0.001875  Loss: -0.2742  Acc@1: 75.0000 (85.0855)  Acc@5: 100.0000 (98.2717)  time: 0.3490  data: 0.0009  max mem: 2502
Train: Epoch[2/5]  [2450/3125]  eta: 0:03:56  Lr: 0.001875  Loss: -0.6658  Acc@1: 81.2500 (85.0954)  Acc@5: 100.0000 (98.2762)  time: 0.3461  data: 0.0008  max mem: 2502
Train: Epoch[2/5]  [2460/3125]  eta: 0:03:52  Lr: 0.001875  Loss: -0.6174  Acc@1: 87.5000 (85.0721)  Acc@5: 100.0000 (98.2705)  time: 0.3465  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [2470/3125]  eta: 0:03:49  Lr: 0.001875  Loss: -0.1583  Acc@1: 87.5000 (85.0744)  Acc@5: 100.0000 (98.2750)  time: 0.3518  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [2480/3125]  eta: 0:03:45  Lr: 0.001875  Loss: -0.1677  Acc@1: 87.5000 (85.0766)  Acc@5: 100.0000 (98.2719)  time: 0.3548  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [2490/3125]  eta: 0:03:42  Lr: 0.001875  Loss: -0.4148  Acc@1: 87.5000 (85.0838)  Acc@5: 100.0000 (98.2663)  time: 0.3526  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [2500/3125]  eta: 0:03:38  Lr: 0.001875  Loss: -0.3326  Acc@1: 87.5000 (85.0885)  Acc@5: 100.0000 (98.2657)  time: 0.3518  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [2510/3125]  eta: 0:03:35  Lr: 0.001875  Loss: -0.5795  Acc@1: 81.2500 (85.0806)  Acc@5: 100.0000 (98.2626)  time: 0.3537  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [2520/3125]  eta: 0:03:32  Lr: 0.001875  Loss: -0.7327  Acc@1: 81.2500 (85.0754)  Acc@5: 100.0000 (98.2695)  time: 0.3594  data: 0.0007  max mem: 2502
Train: Epoch[2/5]  [2530/3125]  eta: 0:03:28  Lr: 0.001875  Loss: -0.2140  Acc@1: 87.5000 (85.0899)  Acc@5: 100.0000 (98.2690)  time: 0.3571  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [2540/3125]  eta: 0:03:25  Lr: 0.001875  Loss: -0.6226  Acc@1: 87.5000 (85.0846)  Acc@5: 100.0000 (98.2659)  time: 0.3493  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [2550/3125]  eta: 0:03:21  Lr: 0.001875  Loss: -0.3170  Acc@1: 87.5000 (85.0941)  Acc@5: 100.0000 (98.2629)  time: 0.3480  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [2560/3125]  eta: 0:03:17  Lr: 0.001875  Loss: -0.8705  Acc@1: 87.5000 (85.1108)  Acc@5: 100.0000 (98.2673)  time: 0.3481  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [2570/3125]  eta: 0:03:14  Lr: 0.001875  Loss: -0.6216  Acc@1: 87.5000 (85.1201)  Acc@5: 100.0000 (98.2643)  time: 0.3487  data: 0.0007  max mem: 2502
Train: Epoch[2/5]  [2580/3125]  eta: 0:03:10  Lr: 0.001875  Loss: -0.6281  Acc@1: 87.5000 (85.1438)  Acc@5: 100.0000 (98.2662)  time: 0.3483  data: 0.0007  max mem: 2502
Train: Epoch[2/5]  [2590/3125]  eta: 0:03:07  Lr: 0.001875  Loss: -0.3053  Acc@1: 87.5000 (85.1481)  Acc@5: 100.0000 (98.2680)  time: 0.3474  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [2600/3125]  eta: 0:03:03  Lr: 0.001875  Loss: -0.7419  Acc@1: 87.5000 (85.1692)  Acc@5: 100.0000 (98.2651)  time: 0.3475  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [2610/3125]  eta: 0:03:00  Lr: 0.001875  Loss: -0.5832  Acc@1: 87.5000 (85.1805)  Acc@5: 100.0000 (98.2693)  time: 0.3491  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [2620/3125]  eta: 0:02:56  Lr: 0.001875  Loss: -0.7563  Acc@1: 87.5000 (85.1703)  Acc@5: 100.0000 (98.2616)  time: 0.3490  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [2630/3125]  eta: 0:02:53  Lr: 0.001875  Loss: -0.4989  Acc@1: 81.2500 (85.1649)  Acc@5: 100.0000 (98.2635)  time: 0.3463  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [2640/3125]  eta: 0:02:49  Lr: 0.001875  Loss: -0.9147  Acc@1: 87.5000 (85.1713)  Acc@5: 100.0000 (98.2559)  time: 0.3454  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [2650/3125]  eta: 0:02:46  Lr: 0.001875  Loss: -0.3808  Acc@1: 81.2500 (85.1636)  Acc@5: 100.0000 (98.2483)  time: 0.3473  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [2660/3125]  eta: 0:02:42  Lr: 0.001875  Loss: -0.7711  Acc@1: 87.5000 (85.1818)  Acc@5: 100.0000 (98.2431)  time: 0.3497  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [2670/3125]  eta: 0:02:39  Lr: 0.001875  Loss: -0.3908  Acc@1: 87.5000 (85.1811)  Acc@5: 100.0000 (98.2427)  time: 0.3513  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [2680/3125]  eta: 0:02:35  Lr: 0.001875  Loss: -0.6816  Acc@1: 87.5000 (85.1944)  Acc@5: 100.0000 (98.2376)  time: 0.3517  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [2690/3125]  eta: 0:02:32  Lr: 0.001875  Loss: -0.3095  Acc@1: 87.5000 (85.1798)  Acc@5: 100.0000 (98.2372)  time: 0.3535  data: 0.0007  max mem: 2502
Train: Epoch[2/5]  [2700/3125]  eta: 0:02:28  Lr: 0.001875  Loss: -0.3651  Acc@1: 81.2500 (85.1745)  Acc@5: 100.0000 (98.2437)  time: 0.3528  data: 0.0010  max mem: 2502
Train: Epoch[2/5]  [2710/3125]  eta: 0:02:25  Lr: 0.001875  Loss: -0.3456  Acc@1: 81.2500 (85.1738)  Acc@5: 100.0000 (98.2364)  time: 0.3503  data: 0.0008  max mem: 2502
Train: Epoch[2/5]  [2720/3125]  eta: 0:02:21  Lr: 0.001875  Loss: -0.7054  Acc@1: 87.5000 (85.1824)  Acc@5: 100.0000 (98.2359)  time: 0.3505  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [2730/3125]  eta: 0:02:18  Lr: 0.001875  Loss: -0.7795  Acc@1: 87.5000 (85.1886)  Acc@5: 100.0000 (98.2332)  time: 0.3500  data: 0.0007  max mem: 2502
Train: Epoch[2/5]  [2740/3125]  eta: 0:02:14  Lr: 0.001875  Loss: -0.4683  Acc@1: 81.2500 (85.1765)  Acc@5: 100.0000 (98.2374)  time: 0.3573  data: 0.0008  max mem: 2502
Train: Epoch[2/5]  [2750/3125]  eta: 0:02:11  Lr: 0.001875  Loss: -0.0095  Acc@1: 81.2500 (85.1781)  Acc@5: 100.0000 (98.2370)  time: 0.3578  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [2760/3125]  eta: 0:02:07  Lr: 0.001875  Loss: -0.5133  Acc@1: 81.2500 (85.1707)  Acc@5: 100.0000 (98.2343)  time: 0.3488  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [2770/3125]  eta: 0:02:04  Lr: 0.001875  Loss: -0.8619  Acc@1: 87.5000 (85.1813)  Acc@5: 100.0000 (98.2385)  time: 0.3487  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [2780/3125]  eta: 0:02:00  Lr: 0.001875  Loss: -0.4985  Acc@1: 87.5000 (85.2032)  Acc@5: 100.0000 (98.2425)  time: 0.3490  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [2790/3125]  eta: 0:01:57  Lr: 0.001875  Loss: -0.4238  Acc@1: 87.5000 (85.1935)  Acc@5: 100.0000 (98.2376)  time: 0.3496  data: 0.0011  max mem: 2502
Train: Epoch[2/5]  [2800/3125]  eta: 0:01:53  Lr: 0.001875  Loss: -0.3734  Acc@1: 87.5000 (85.1928)  Acc@5: 100.0000 (98.2372)  time: 0.3492  data: 0.0014  max mem: 2502
Train: Epoch[2/5]  [2810/3125]  eta: 0:01:50  Lr: 0.001875  Loss: -0.6915  Acc@1: 87.5000 (85.2010)  Acc@5: 100.0000 (98.2413)  time: 0.3463  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [2820/3125]  eta: 0:01:46  Lr: 0.001875  Loss: -0.8549  Acc@1: 87.5000 (85.2136)  Acc@5: 100.0000 (98.2453)  time: 0.3475  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [2830/3125]  eta: 0:01:43  Lr: 0.001875  Loss: -0.8565  Acc@1: 87.5000 (85.2084)  Acc@5: 100.0000 (98.2471)  time: 0.3489  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [2840/3125]  eta: 0:01:39  Lr: 0.001875  Loss: -0.8636  Acc@1: 87.5000 (85.2253)  Acc@5: 100.0000 (98.2511)  time: 0.3484  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [2850/3125]  eta: 0:01:36  Lr: 0.001875  Loss: -0.1932  Acc@1: 87.5000 (85.2157)  Acc@5: 100.0000 (98.2528)  time: 0.3499  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [2860/3125]  eta: 0:01:32  Lr: 0.001875  Loss: -0.2654  Acc@1: 81.2500 (85.2171)  Acc@5: 100.0000 (98.2545)  time: 0.3502  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [2870/3125]  eta: 0:01:29  Lr: 0.001875  Loss: -0.4391  Acc@1: 87.5000 (85.2120)  Acc@5: 100.0000 (98.2497)  time: 0.3520  data: 0.0008  max mem: 2502
Train: Epoch[2/5]  [2880/3125]  eta: 0:01:25  Lr: 0.001875  Loss: -0.1853  Acc@1: 87.5000 (85.2135)  Acc@5: 100.0000 (98.2558)  time: 0.3533  data: 0.0007  max mem: 2502
Train: Epoch[2/5]  [2890/3125]  eta: 0:01:22  Lr: 0.001875  Loss: -0.4433  Acc@1: 81.2500 (85.2171)  Acc@5: 100.0000 (98.2575)  time: 0.3516  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [2900/3125]  eta: 0:01:18  Lr: 0.001875  Loss: -0.4221  Acc@1: 81.2500 (85.2120)  Acc@5: 100.0000 (98.2571)  time: 0.3516  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [2910/3125]  eta: 0:01:15  Lr: 0.001875  Loss: -0.8898  Acc@1: 87.5000 (85.2241)  Acc@5: 100.0000 (98.2588)  time: 0.3501  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [2920/3125]  eta: 0:01:11  Lr: 0.001875  Loss: -0.6823  Acc@1: 87.5000 (85.2319)  Acc@5: 100.0000 (98.2626)  time: 0.3513  data: 0.0019  max mem: 2502
Train: Epoch[2/5]  [2930/3125]  eta: 0:01:08  Lr: 0.001875  Loss: -0.2026  Acc@1: 87.5000 (85.2290)  Acc@5: 100.0000 (98.2621)  time: 0.3540  data: 0.0026  max mem: 2502
Train: Epoch[2/5]  [2940/3125]  eta: 0:01:04  Lr: 0.001875  Loss: 0.0305  Acc@1: 81.2500 (85.2304)  Acc@5: 100.0000 (98.2616)  time: 0.3537  data: 0.0014  max mem: 2502
Train: Epoch[2/5]  [2950/3125]  eta: 0:01:01  Lr: 0.001875  Loss: -0.4576  Acc@1: 87.5000 (85.2423)  Acc@5: 100.0000 (98.2612)  time: 0.3500  data: 0.0007  max mem: 2502
Train: Epoch[2/5]  [2960/3125]  eta: 0:00:57  Lr: 0.001875  Loss: -0.4232  Acc@1: 87.5000 (85.2541)  Acc@5: 100.0000 (98.2628)  time: 0.3488  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [2970/3125]  eta: 0:00:54  Lr: 0.001875  Loss: -0.5320  Acc@1: 87.5000 (85.2596)  Acc@5: 100.0000 (98.2561)  time: 0.3499  data: 0.0007  max mem: 2502
Train: Epoch[2/5]  [2980/3125]  eta: 0:00:50  Lr: 0.001875  Loss: -0.2896  Acc@1: 87.5000 (85.2629)  Acc@5: 100.0000 (98.2577)  time: 0.3484  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [2990/3125]  eta: 0:00:47  Lr: 0.001875  Loss: -0.6592  Acc@1: 87.5000 (85.2641)  Acc@5: 100.0000 (98.2573)  time: 0.3476  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [3000/3125]  eta: 0:00:43  Lr: 0.001875  Loss: -0.5134  Acc@1: 87.5000 (85.2716)  Acc@5: 100.0000 (98.2610)  time: 0.3462  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [3010/3125]  eta: 0:00:40  Lr: 0.001875  Loss: -0.3985  Acc@1: 81.2500 (85.2582)  Acc@5: 100.0000 (98.2522)  time: 0.3476  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [3020/3125]  eta: 0:00:36  Lr: 0.001875  Loss: -0.3594  Acc@1: 81.2500 (85.2656)  Acc@5: 93.7500 (98.2477)  time: 0.3471  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [3030/3125]  eta: 0:00:33  Lr: 0.001875  Loss: -0.7728  Acc@1: 81.2500 (85.2668)  Acc@5: 100.0000 (98.2473)  time: 0.3445  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [3040/3125]  eta: 0:00:29  Lr: 0.001875  Loss: -0.0294  Acc@1: 87.5000 (85.2680)  Acc@5: 100.0000 (98.2510)  time: 0.3498  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [3050/3125]  eta: 0:00:26  Lr: 0.001875  Loss: -0.6836  Acc@1: 87.5000 (85.2651)  Acc@5: 100.0000 (98.2485)  time: 0.3524  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [3060/3125]  eta: 0:00:22  Lr: 0.001875  Loss: -0.7356  Acc@1: 87.5000 (85.2744)  Acc@5: 100.0000 (98.2502)  time: 0.3502  data: 0.0008  max mem: 2502
Train: Epoch[2/5]  [3070/3125]  eta: 0:00:19  Lr: 0.001875  Loss: -0.2306  Acc@1: 87.5000 (85.2654)  Acc@5: 100.0000 (98.2518)  time: 0.3523  data: 0.0008  max mem: 2502
Train: Epoch[2/5]  [3080/3125]  eta: 0:00:15  Lr: 0.001875  Loss: -0.5433  Acc@1: 87.5000 (85.2686)  Acc@5: 100.0000 (98.2494)  time: 0.3520  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [3090/3125]  eta: 0:00:12  Lr: 0.001875  Loss: -0.2474  Acc@1: 87.5000 (85.2616)  Acc@5: 100.0000 (98.2449)  time: 0.3503  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [3100/3125]  eta: 0:00:08  Lr: 0.001875  Loss: -0.5246  Acc@1: 81.2500 (85.2507)  Acc@5: 100.0000 (98.2465)  time: 0.3501  data: 0.0007  max mem: 2502
Train: Epoch[2/5]  [3110/3125]  eta: 0:00:05  Lr: 0.001875  Loss: -0.6101  Acc@1: 81.2500 (85.2519)  Acc@5: 100.0000 (98.2502)  time: 0.3513  data: 0.0015  max mem: 2502
Train: Epoch[2/5]  [3120/3125]  eta: 0:00:01  Lr: 0.001875  Loss: -0.4718  Acc@1: 81.2500 (85.2491)  Acc@5: 100.0000 (98.2558)  time: 0.3523  data: 0.0020  max mem: 2502
Train: Epoch[2/5]  [3124/3125]  eta: 0:00:00  Lr: 0.001875  Loss: -0.4928  Acc@1: 81.2500 (85.2380)  Acc@5: 100.0000 (98.2500)  time: 0.3505  data: 0.0010  max mem: 2502
Train: Epoch[2/5] Total time: 0:18:15 (0.3505 s / it)
{0: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 1: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 2: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 3: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 4: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 5: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 6: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 7: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 8: {0: 0, 1: 0, 2: 100000, 3: 0, 4: 0}, 9: {0: 0, 1: 0, 2: 100000, 3: 0, 4: 0}, 10: {0: 0, 1: 0, 2: 100000, 3: 0, 4: 0}, 11: {0: 0, 1: 0, 2: 100000, 3: 0, 4: 0}, 12: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 13: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 14: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 15: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 16: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 17: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 18: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 19: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}}
Averaged stats: Lr: 0.001875  Loss: -0.4928  Acc@1: 81.2500 (85.2380)  Acc@5: 100.0000 (98.2500)
Train: Epoch[3/5]  [   0/3125]  eta: 0:38:03  Lr: 0.001875  Loss: -0.6626  Acc@1: 93.7500 (93.7500)  Acc@5: 100.0000 (100.0000)  time: 0.7308  data: 0.3817  max mem: 2502
Train: Epoch[3/5]  [  10/3125]  eta: 0:19:57  Lr: 0.001875  Loss: -0.5814  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (98.8636)  time: 0.3844  data: 0.0350  max mem: 2502
Train: Epoch[3/5]  [  20/3125]  eta: 0:19:07  Lr: 0.001875  Loss: -0.7677  Acc@1: 87.5000 (85.4167)  Acc@5: 100.0000 (98.8095)  time: 0.3516  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [  30/3125]  eta: 0:18:42  Lr: 0.001875  Loss: -0.5696  Acc@1: 87.5000 (86.0887)  Acc@5: 100.0000 (98.5887)  time: 0.3508  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [  40/3125]  eta: 0:18:28  Lr: 0.001875  Loss: -0.5902  Acc@1: 81.2500 (85.5183)  Acc@5: 100.0000 (98.6280)  time: 0.3482  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [  50/3125]  eta: 0:18:17  Lr: 0.001875  Loss: -0.1979  Acc@1: 81.2500 (85.7843)  Acc@5: 100.0000 (98.5294)  time: 0.3475  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [  60/3125]  eta: 0:18:11  Lr: 0.001875  Loss: -0.6327  Acc@1: 87.5000 (86.2705)  Acc@5: 100.0000 (98.6680)  time: 0.3494  data: 0.0015  max mem: 2502
Train: Epoch[3/5]  [  70/3125]  eta: 0:18:03  Lr: 0.001875  Loss: -0.6366  Acc@1: 87.5000 (86.0035)  Acc@5: 100.0000 (98.5915)  time: 0.3489  data: 0.0015  max mem: 2502
Train: Epoch[3/5]  [  80/3125]  eta: 0:17:56  Lr: 0.001875  Loss: -0.1196  Acc@1: 81.2500 (85.9568)  Acc@5: 100.0000 (98.3796)  time: 0.3454  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [  90/3125]  eta: 0:17:50  Lr: 0.001875  Loss: -0.5103  Acc@1: 81.2500 (85.4396)  Acc@5: 100.0000 (98.5577)  time: 0.3464  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [ 100/3125]  eta: 0:17:47  Lr: 0.001875  Loss: -0.5757  Acc@1: 87.5000 (85.8911)  Acc@5: 100.0000 (98.6386)  time: 0.3508  data: 0.0006  max mem: 2502
Train: Epoch[3/5]  [ 110/3125]  eta: 0:17:43  Lr: 0.001875  Loss: -0.4495  Acc@1: 87.5000 (85.9797)  Acc@5: 100.0000 (98.5923)  time: 0.3522  data: 0.0007  max mem: 2502
Train: Epoch[3/5]  [ 120/3125]  eta: 0:17:38  Lr: 0.001875  Loss: -0.6085  Acc@1: 87.5000 (86.0021)  Acc@5: 100.0000 (98.4504)  time: 0.3499  data: 0.0006  max mem: 2502
Train: Epoch[3/5]  [ 130/3125]  eta: 0:17:34  Lr: 0.001875  Loss: -0.8643  Acc@1: 87.5000 (86.0687)  Acc@5: 100.0000 (98.4733)  time: 0.3487  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [ 140/3125]  eta: 0:17:31  Lr: 0.001875  Loss: -0.8358  Acc@1: 87.5000 (86.2145)  Acc@5: 100.0000 (98.5816)  time: 0.3505  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [ 150/3125]  eta: 0:17:28  Lr: 0.001875  Loss: -0.4247  Acc@1: 87.5000 (85.9272)  Acc@5: 100.0000 (98.6341)  time: 0.3540  data: 0.0006  max mem: 2502
Train: Epoch[3/5]  [ 160/3125]  eta: 0:17:24  Lr: 0.001875  Loss: -0.6468  Acc@1: 81.2500 (86.1413)  Acc@5: 100.0000 (98.6025)  time: 0.3536  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [ 170/3125]  eta: 0:17:21  Lr: 0.001875  Loss: -0.8724  Acc@1: 87.5000 (86.0746)  Acc@5: 100.0000 (98.6111)  time: 0.3534  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [ 180/3125]  eta: 0:17:17  Lr: 0.001875  Loss: -0.6022  Acc@1: 87.5000 (86.1188)  Acc@5: 100.0000 (98.6188)  time: 0.3517  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [ 190/3125]  eta: 0:17:13  Lr: 0.001875  Loss: -0.8366  Acc@1: 87.5000 (86.3547)  Acc@5: 100.0000 (98.5929)  time: 0.3481  data: 0.0007  max mem: 2502
Train: Epoch[3/5]  [ 200/3125]  eta: 0:17:08  Lr: 0.001875  Loss: -0.5496  Acc@1: 87.5000 (86.5050)  Acc@5: 100.0000 (98.6007)  time: 0.3478  data: 0.0007  max mem: 2502
Train: Epoch[3/5]  [ 210/3125]  eta: 0:17:05  Lr: 0.001875  Loss: -0.6464  Acc@1: 87.5000 (86.5818)  Acc@5: 100.0000 (98.5782)  time: 0.3497  data: 0.0012  max mem: 2502
Train: Epoch[3/5]  [ 220/3125]  eta: 0:17:01  Lr: 0.001875  Loss: -0.3453  Acc@1: 87.5000 (86.4536)  Acc@5: 100.0000 (98.6143)  time: 0.3497  data: 0.0013  max mem: 2502
Train: Epoch[3/5]  [ 230/3125]  eta: 0:16:57  Lr: 0.001875  Loss: -0.4392  Acc@1: 81.2500 (86.3907)  Acc@5: 100.0000 (98.6201)  time: 0.3478  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [ 240/3125]  eta: 0:16:53  Lr: 0.001875  Loss: -0.8256  Acc@1: 87.5000 (86.4367)  Acc@5: 100.0000 (98.5737)  time: 0.3460  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [ 250/3125]  eta: 0:16:49  Lr: 0.001875  Loss: -0.3737  Acc@1: 87.5000 (86.4293)  Acc@5: 100.0000 (98.5558)  time: 0.3460  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [ 260/3125]  eta: 0:16:45  Lr: 0.001875  Loss: -0.2485  Acc@1: 87.5000 (86.3985)  Acc@5: 100.0000 (98.5393)  time: 0.3469  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [ 270/3125]  eta: 0:16:41  Lr: 0.001875  Loss: -0.4243  Acc@1: 87.5000 (86.3238)  Acc@5: 100.0000 (98.5470)  time: 0.3472  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [ 280/3125]  eta: 0:16:37  Lr: 0.001875  Loss: -0.3184  Acc@1: 87.5000 (86.2544)  Acc@5: 100.0000 (98.5543)  time: 0.3479  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [ 290/3125]  eta: 0:16:34  Lr: 0.001875  Loss: -0.5161  Acc@1: 81.2500 (86.1684)  Acc@5: 100.0000 (98.5610)  time: 0.3514  data: 0.0012  max mem: 2502
Train: Epoch[3/5]  [ 300/3125]  eta: 0:16:31  Lr: 0.001875  Loss: -0.4369  Acc@1: 81.2500 (86.0257)  Acc@5: 100.0000 (98.5257)  time: 0.3536  data: 0.0016  max mem: 2502
Train: Epoch[3/5]  [ 310/3125]  eta: 0:16:27  Lr: 0.001875  Loss: -0.2823  Acc@1: 81.2500 (86.0129)  Acc@5: 100.0000 (98.5531)  time: 0.3519  data: 0.0009  max mem: 2502
Train: Epoch[3/5]  [ 320/3125]  eta: 0:16:24  Lr: 0.001875  Loss: -0.5384  Acc@1: 87.5000 (85.9618)  Acc@5: 100.0000 (98.5397)  time: 0.3539  data: 0.0007  max mem: 2502
Train: Epoch[3/5]  [ 330/3125]  eta: 0:16:21  Lr: 0.001875  Loss: -0.6221  Acc@1: 87.5000 (86.0272)  Acc@5: 100.0000 (98.5838)  time: 0.3542  data: 0.0008  max mem: 2502
Train: Epoch[3/5]  [ 340/3125]  eta: 0:16:17  Lr: 0.001875  Loss: -0.4836  Acc@1: 87.5000 (85.9421)  Acc@5: 100.0000 (98.5704)  time: 0.3536  data: 0.0008  max mem: 2502
Train: Epoch[3/5]  [ 350/3125]  eta: 0:16:14  Lr: 0.001875  Loss: -0.3159  Acc@1: 81.2500 (85.8618)  Acc@5: 100.0000 (98.5399)  time: 0.3526  data: 0.0009  max mem: 2502
Train: Epoch[3/5]  [ 360/3125]  eta: 0:16:11  Lr: 0.001875  Loss: -0.4452  Acc@1: 81.2500 (85.7687)  Acc@5: 100.0000 (98.5111)  time: 0.3538  data: 0.0013  max mem: 2502
Train: Epoch[3/5]  [ 370/3125]  eta: 0:16:07  Lr: 0.001875  Loss: -0.1591  Acc@1: 87.5000 (85.8827)  Acc@5: 100.0000 (98.5007)  time: 0.3533  data: 0.0012  max mem: 2502
Train: Epoch[3/5]  [ 380/3125]  eta: 0:16:04  Lr: 0.001875  Loss: -0.7971  Acc@1: 87.5000 (85.9744)  Acc@5: 100.0000 (98.5072)  time: 0.3516  data: 0.0006  max mem: 2502
Train: Epoch[3/5]  [ 390/3125]  eta: 0:16:00  Lr: 0.001875  Loss: -0.4578  Acc@1: 87.5000 (85.8855)  Acc@5: 100.0000 (98.5294)  time: 0.3515  data: 0.0006  max mem: 2502
Train: Epoch[3/5]  [ 400/3125]  eta: 0:15:56  Lr: 0.001875  Loss: -0.4150  Acc@1: 81.2500 (85.7855)  Acc@5: 100.0000 (98.4570)  time: 0.3480  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [ 410/3125]  eta: 0:15:53  Lr: 0.001875  Loss: -0.6573  Acc@1: 81.2500 (85.7512)  Acc@5: 100.0000 (98.4641)  time: 0.3478  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [ 420/3125]  eta: 0:15:49  Lr: 0.001875  Loss: -0.4075  Acc@1: 87.5000 (85.8224)  Acc@5: 100.0000 (98.5006)  time: 0.3483  data: 0.0006  max mem: 2502
Train: Epoch[3/5]  [ 430/3125]  eta: 0:15:45  Lr: 0.001875  Loss: -0.5083  Acc@1: 87.5000 (85.8034)  Acc@5: 100.0000 (98.4629)  time: 0.3485  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [ 440/3125]  eta: 0:15:42  Lr: 0.001875  Loss: -0.5273  Acc@1: 87.5000 (85.7851)  Acc@5: 100.0000 (98.4836)  time: 0.3492  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [ 450/3125]  eta: 0:15:38  Lr: 0.001875  Loss: -0.4855  Acc@1: 87.5000 (85.7816)  Acc@5: 100.0000 (98.4895)  time: 0.3481  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [ 460/3125]  eta: 0:15:34  Lr: 0.001875  Loss: -0.8047  Acc@1: 87.5000 (85.8867)  Acc@5: 100.0000 (98.4951)  time: 0.3467  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [ 470/3125]  eta: 0:15:31  Lr: 0.001875  Loss: -0.5361  Acc@1: 87.5000 (85.9342)  Acc@5: 100.0000 (98.5138)  time: 0.3465  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [ 480/3125]  eta: 0:15:27  Lr: 0.001875  Loss: -0.2575  Acc@1: 87.5000 (85.9797)  Acc@5: 100.0000 (98.5057)  time: 0.3476  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [ 490/3125]  eta: 0:15:24  Lr: 0.001875  Loss: -0.5966  Acc@1: 87.5000 (86.0107)  Acc@5: 100.0000 (98.5362)  time: 0.3508  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [ 500/3125]  eta: 0:15:20  Lr: 0.001875  Loss: -0.6138  Acc@1: 87.5000 (86.0529)  Acc@5: 100.0000 (98.5279)  time: 0.3511  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [ 510/3125]  eta: 0:15:17  Lr: 0.001875  Loss: -0.6172  Acc@1: 93.7500 (86.1057)  Acc@5: 100.0000 (98.5445)  time: 0.3543  data: 0.0026  max mem: 2502
Train: Epoch[3/5]  [ 520/3125]  eta: 0:15:13  Lr: 0.001875  Loss: -0.6237  Acc@1: 87.5000 (86.1444)  Acc@5: 100.0000 (98.5485)  time: 0.3550  data: 0.0032  max mem: 2502
Train: Epoch[3/5]  [ 530/3125]  eta: 0:15:10  Lr: 0.001875  Loss: -0.0743  Acc@1: 87.5000 (86.1111)  Acc@5: 100.0000 (98.5287)  time: 0.3569  data: 0.0014  max mem: 2502
Train: Epoch[3/5]  [ 540/3125]  eta: 0:15:07  Lr: 0.001875  Loss: -0.6361  Acc@1: 87.5000 (86.0444)  Acc@5: 100.0000 (98.5097)  time: 0.3567  data: 0.0014  max mem: 2502
Train: Epoch[3/5]  [ 550/3125]  eta: 0:15:03  Lr: 0.001875  Loss: -0.5812  Acc@1: 81.2500 (85.9914)  Acc@5: 100.0000 (98.5141)  time: 0.3503  data: 0.0011  max mem: 2502
Train: Epoch[3/5]  [ 560/3125]  eta: 0:15:00  Lr: 0.001875  Loss: -0.3409  Acc@1: 81.2500 (85.9626)  Acc@5: 100.0000 (98.4960)  time: 0.3532  data: 0.0011  max mem: 2502
Train: Epoch[3/5]  [ 570/3125]  eta: 0:14:57  Lr: 0.001875  Loss: -0.3469  Acc@1: 87.5000 (86.0442)  Acc@5: 100.0000 (98.5114)  time: 0.3544  data: 0.0019  max mem: 2502
Train: Epoch[3/5]  [ 580/3125]  eta: 0:14:53  Lr: 0.001875  Loss: -0.7929  Acc@1: 87.5000 (86.1015)  Acc@5: 100.0000 (98.5370)  time: 0.3505  data: 0.0016  max mem: 2502
Train: Epoch[3/5]  [ 590/3125]  eta: 0:14:49  Lr: 0.001875  Loss: -0.7662  Acc@1: 87.5000 (86.1252)  Acc@5: 100.0000 (98.5300)  time: 0.3479  data: 0.0007  max mem: 2502
Train: Epoch[3/5]  [ 600/3125]  eta: 0:14:46  Lr: 0.001875  Loss: -0.4985  Acc@1: 87.5000 (86.1273)  Acc@5: 100.0000 (98.5129)  time: 0.3491  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [ 610/3125]  eta: 0:14:42  Lr: 0.001875  Loss: -0.8865  Acc@1: 87.5000 (86.1293)  Acc@5: 100.0000 (98.5270)  time: 0.3491  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [ 620/3125]  eta: 0:14:39  Lr: 0.001875  Loss: -0.8162  Acc@1: 87.5000 (86.1614)  Acc@5: 100.0000 (98.5205)  time: 0.3479  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [ 630/3125]  eta: 0:14:35  Lr: 0.001875  Loss: -0.2815  Acc@1: 87.5000 (86.1331)  Acc@5: 100.0000 (98.4845)  time: 0.3477  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [ 640/3125]  eta: 0:14:31  Lr: 0.001875  Loss: 0.0724  Acc@1: 81.2500 (86.0667)  Acc@5: 93.7500 (98.4594)  time: 0.3461  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [ 650/3125]  eta: 0:14:27  Lr: 0.001875  Loss: -0.7699  Acc@1: 87.5000 (86.0695)  Acc@5: 100.0000 (98.4831)  time: 0.3454  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [ 660/3125]  eta: 0:14:24  Lr: 0.001875  Loss: -0.2968  Acc@1: 87.5000 (86.0817)  Acc@5: 100.0000 (98.4777)  time: 0.3461  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [ 670/3125]  eta: 0:14:20  Lr: 0.001875  Loss: -0.8160  Acc@1: 87.5000 (86.0842)  Acc@5: 100.0000 (98.4724)  time: 0.3458  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [ 680/3125]  eta: 0:14:16  Lr: 0.001875  Loss: -0.3521  Acc@1: 87.5000 (86.0775)  Acc@5: 100.0000 (98.4673)  time: 0.3461  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [ 690/3125]  eta: 0:14:13  Lr: 0.001875  Loss: -0.5501  Acc@1: 87.5000 (86.0709)  Acc@5: 100.0000 (98.4624)  time: 0.3479  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [ 700/3125]  eta: 0:14:09  Lr: 0.001875  Loss: -0.6647  Acc@1: 87.5000 (86.0646)  Acc@5: 100.0000 (98.4754)  time: 0.3492  data: 0.0012  max mem: 2502
Train: Epoch[3/5]  [ 710/3125]  eta: 0:14:06  Lr: 0.001875  Loss: -0.3541  Acc@1: 87.5000 (86.0935)  Acc@5: 100.0000 (98.4880)  time: 0.3490  data: 0.0014  max mem: 2502
Train: Epoch[3/5]  [ 720/3125]  eta: 0:14:02  Lr: 0.001875  Loss: -0.3189  Acc@1: 87.5000 (86.1044)  Acc@5: 100.0000 (98.5003)  time: 0.3516  data: 0.0016  max mem: 2502
Train: Epoch[3/5]  [ 730/3125]  eta: 0:13:59  Lr: 0.001875  Loss: -0.7620  Acc@1: 87.5000 (86.1662)  Acc@5: 100.0000 (98.4952)  time: 0.3536  data: 0.0015  max mem: 2502
Train: Epoch[3/5]  [ 740/3125]  eta: 0:13:56  Lr: 0.001875  Loss: -0.4870  Acc@1: 87.5000 (86.1926)  Acc@5: 100.0000 (98.5071)  time: 0.3527  data: 0.0013  max mem: 2502
Train: Epoch[3/5]  [ 750/3125]  eta: 0:13:52  Lr: 0.001875  Loss: -0.7110  Acc@1: 87.5000 (86.2350)  Acc@5: 100.0000 (98.5186)  time: 0.3516  data: 0.0012  max mem: 2502
Train: Epoch[3/5]  [ 760/3125]  eta: 0:13:49  Lr: 0.001875  Loss: -0.6073  Acc@1: 87.5000 (86.2024)  Acc@5: 100.0000 (98.5053)  time: 0.3501  data: 0.0006  max mem: 2502
Train: Epoch[3/5]  [ 770/3125]  eta: 0:13:45  Lr: 0.001875  Loss: -0.6496  Acc@1: 81.2500 (86.1949)  Acc@5: 100.0000 (98.5003)  time: 0.3501  data: 0.0007  max mem: 2502
Train: Epoch[3/5]  [ 780/3125]  eta: 0:13:41  Lr: 0.001875  Loss: -0.4380  Acc@1: 87.5000 (86.2196)  Acc@5: 100.0000 (98.5035)  time: 0.3493  data: 0.0006  max mem: 2502
Train: Epoch[3/5]  [ 790/3125]  eta: 0:13:38  Lr: 0.001875  Loss: -0.5961  Acc@1: 87.5000 (86.2674)  Acc@5: 100.0000 (98.5145)  time: 0.3487  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [ 800/3125]  eta: 0:13:34  Lr: 0.001875  Loss: -0.8188  Acc@1: 87.5000 (86.2906)  Acc@5: 100.0000 (98.4863)  time: 0.3500  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [ 810/3125]  eta: 0:13:31  Lr: 0.001875  Loss: -0.8302  Acc@1: 87.5000 (86.3132)  Acc@5: 100.0000 (98.4972)  time: 0.3489  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [ 820/3125]  eta: 0:13:27  Lr: 0.001875  Loss: -0.6652  Acc@1: 87.5000 (86.3048)  Acc@5: 100.0000 (98.5079)  time: 0.3483  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [ 830/3125]  eta: 0:13:24  Lr: 0.001875  Loss: -0.1511  Acc@1: 87.5000 (86.3568)  Acc@5: 100.0000 (98.5033)  time: 0.3483  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [ 840/3125]  eta: 0:13:20  Lr: 0.001875  Loss: -0.4212  Acc@1: 93.7500 (86.3927)  Acc@5: 100.0000 (98.4988)  time: 0.3468  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [ 850/3125]  eta: 0:13:16  Lr: 0.001875  Loss: -0.4405  Acc@1: 93.7500 (86.4057)  Acc@5: 100.0000 (98.5165)  time: 0.3464  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [ 860/3125]  eta: 0:13:13  Lr: 0.001875  Loss: -0.4605  Acc@1: 87.5000 (86.3966)  Acc@5: 100.0000 (98.5264)  time: 0.3462  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [ 870/3125]  eta: 0:13:09  Lr: 0.001875  Loss: -0.6511  Acc@1: 87.5000 (86.4093)  Acc@5: 100.0000 (98.5290)  time: 0.3508  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [ 880/3125]  eta: 0:13:06  Lr: 0.001875  Loss: -0.7096  Acc@1: 87.5000 (86.4217)  Acc@5: 100.0000 (98.5244)  time: 0.3523  data: 0.0011  max mem: 2502
Train: Epoch[3/5]  [ 890/3125]  eta: 0:13:02  Lr: 0.001875  Loss: -0.4719  Acc@1: 87.5000 (86.4198)  Acc@5: 100.0000 (98.5199)  time: 0.3488  data: 0.0011  max mem: 2502
Train: Epoch[3/5]  [ 900/3125]  eta: 0:12:59  Lr: 0.001875  Loss: -0.4772  Acc@1: 87.5000 (86.4595)  Acc@5: 100.0000 (98.5294)  time: 0.3511  data: 0.0007  max mem: 2502
Train: Epoch[3/5]  [ 910/3125]  eta: 0:12:56  Lr: 0.001875  Loss: -0.4962  Acc@1: 87.5000 (86.4572)  Acc@5: 100.0000 (98.5250)  time: 0.3535  data: 0.0007  max mem: 2502
Train: Epoch[3/5]  [ 920/3125]  eta: 0:12:52  Lr: 0.001875  Loss: 0.0051  Acc@1: 87.5000 (86.4414)  Acc@5: 100.0000 (98.5206)  time: 0.3539  data: 0.0009  max mem: 2502
Train: Epoch[3/5]  [ 930/3125]  eta: 0:12:49  Lr: 0.001875  Loss: -0.8369  Acc@1: 87.5000 (86.4460)  Acc@5: 100.0000 (98.5164)  time: 0.3530  data: 0.0012  max mem: 2502
Train: Epoch[3/5]  [ 940/3125]  eta: 0:12:45  Lr: 0.001875  Loss: -0.2945  Acc@1: 81.2500 (86.4107)  Acc@5: 100.0000 (98.5122)  time: 0.3505  data: 0.0009  max mem: 2502
Train: Epoch[3/5]  [ 950/3125]  eta: 0:12:42  Lr: 0.001875  Loss: -0.5097  Acc@1: 81.2500 (86.3893)  Acc@5: 100.0000 (98.5081)  time: 0.3495  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [ 960/3125]  eta: 0:12:38  Lr: 0.001875  Loss: -0.2228  Acc@1: 81.2500 (86.3749)  Acc@5: 100.0000 (98.5107)  time: 0.3489  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [ 970/3125]  eta: 0:12:35  Lr: 0.001875  Loss: -0.6540  Acc@1: 87.5000 (86.4315)  Acc@5: 100.0000 (98.5260)  time: 0.3506  data: 0.0024  max mem: 2502
Train: Epoch[3/5]  [ 980/3125]  eta: 0:12:31  Lr: 0.001875  Loss: -0.2354  Acc@1: 87.5000 (86.3914)  Acc@5: 100.0000 (98.5219)  time: 0.3502  data: 0.0024  max mem: 2502
Train: Epoch[3/5]  [ 990/3125]  eta: 0:12:28  Lr: 0.001875  Loss: -0.9315  Acc@1: 87.5000 (86.3837)  Acc@5: 100.0000 (98.5242)  time: 0.3487  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [1000/3125]  eta: 0:12:24  Lr: 0.001875  Loss: -0.5358  Acc@1: 87.5000 (86.4136)  Acc@5: 100.0000 (98.5140)  time: 0.3498  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [1010/3125]  eta: 0:12:20  Lr: 0.001875  Loss: -0.0191  Acc@1: 87.5000 (86.3996)  Acc@5: 100.0000 (98.5101)  time: 0.3498  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [1020/3125]  eta: 0:12:17  Lr: 0.001875  Loss: -0.3917  Acc@1: 87.5000 (86.3369)  Acc@5: 100.0000 (98.4880)  time: 0.3482  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [1030/3125]  eta: 0:12:13  Lr: 0.001875  Loss: -0.2137  Acc@1: 81.2500 (86.3421)  Acc@5: 93.7500 (98.4784)  time: 0.3458  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [1040/3125]  eta: 0:12:10  Lr: 0.001875  Loss: -0.5706  Acc@1: 87.5000 (86.3413)  Acc@5: 100.0000 (98.4930)  time: 0.3458  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [1050/3125]  eta: 0:12:06  Lr: 0.001875  Loss: -0.6578  Acc@1: 87.5000 (86.3523)  Acc@5: 100.0000 (98.4955)  time: 0.3464  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [1060/3125]  eta: 0:12:03  Lr: 0.001875  Loss: -0.4620  Acc@1: 87.5000 (86.3690)  Acc@5: 100.0000 (98.4979)  time: 0.3469  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [1070/3125]  eta: 0:11:59  Lr: 0.001875  Loss: -0.5468  Acc@1: 87.5000 (86.3854)  Acc@5: 100.0000 (98.5002)  time: 0.3491  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [1080/3125]  eta: 0:11:56  Lr: 0.001875  Loss: -0.3741  Acc@1: 87.5000 (86.4130)  Acc@5: 100.0000 (98.4910)  time: 0.3557  data: 0.0009  max mem: 2502
Train: Epoch[3/5]  [1090/3125]  eta: 0:11:52  Lr: 0.001875  Loss: -0.5671  Acc@1: 87.5000 (86.4173)  Acc@5: 100.0000 (98.4934)  time: 0.3547  data: 0.0009  max mem: 2502
Train: Epoch[3/5]  [1100/3125]  eta: 0:11:49  Lr: 0.001875  Loss: -0.7244  Acc@1: 87.5000 (86.4271)  Acc@5: 100.0000 (98.4900)  time: 0.3522  data: 0.0006  max mem: 2502
Train: Epoch[3/5]  [1110/3125]  eta: 0:11:45  Lr: 0.001875  Loss: -0.8553  Acc@1: 87.5000 (86.4030)  Acc@5: 100.0000 (98.4867)  time: 0.3569  data: 0.0011  max mem: 2502
Train: Epoch[3/5]  [1120/3125]  eta: 0:11:42  Lr: 0.001875  Loss: -0.3022  Acc@1: 87.5000 (86.4128)  Acc@5: 100.0000 (98.5002)  time: 0.3533  data: 0.0010  max mem: 2502
Train: Epoch[3/5]  [1130/3125]  eta: 0:11:38  Lr: 0.001875  Loss: -0.4904  Acc@1: 87.5000 (86.4279)  Acc@5: 100.0000 (98.5024)  time: 0.3503  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [1140/3125]  eta: 0:11:35  Lr: 0.001875  Loss: -0.0288  Acc@1: 87.5000 (86.4099)  Acc@5: 100.0000 (98.4991)  time: 0.3525  data: 0.0006  max mem: 2502
Train: Epoch[3/5]  [1150/3125]  eta: 0:11:32  Lr: 0.001875  Loss: -0.6813  Acc@1: 87.5000 (86.3760)  Acc@5: 100.0000 (98.4959)  time: 0.3538  data: 0.0008  max mem: 2502
Train: Epoch[3/5]  [1160/3125]  eta: 0:11:28  Lr: 0.001875  Loss: -0.3235  Acc@1: 81.2500 (86.3372)  Acc@5: 100.0000 (98.4981)  time: 0.3513  data: 0.0008  max mem: 2502
Train: Epoch[3/5]  [1170/3125]  eta: 0:11:25  Lr: 0.001875  Loss: -0.5376  Acc@1: 81.2500 (86.3205)  Acc@5: 100.0000 (98.5002)  time: 0.3487  data: 0.0006  max mem: 2502
Train: Epoch[3/5]  [1180/3125]  eta: 0:11:21  Lr: 0.001875  Loss: -0.6968  Acc@1: 87.5000 (86.3304)  Acc@5: 100.0000 (98.5023)  time: 0.3484  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [1190/3125]  eta: 0:11:17  Lr: 0.001875  Loss: -0.5634  Acc@1: 87.5000 (86.3350)  Acc@5: 100.0000 (98.5044)  time: 0.3489  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [1200/3125]  eta: 0:11:14  Lr: 0.001875  Loss: -0.7067  Acc@1: 87.5000 (86.3135)  Acc@5: 100.0000 (98.5065)  time: 0.3505  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [1210/3125]  eta: 0:11:10  Lr: 0.001875  Loss: -0.7502  Acc@1: 87.5000 (86.2768)  Acc@5: 100.0000 (98.5033)  time: 0.3497  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [1220/3125]  eta: 0:11:07  Lr: 0.001875  Loss: -0.2534  Acc@1: 87.5000 (86.2766)  Acc@5: 100.0000 (98.5104)  time: 0.3473  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [1230/3125]  eta: 0:11:03  Lr: 0.001875  Loss: -0.6994  Acc@1: 87.5000 (86.3221)  Acc@5: 100.0000 (98.5225)  time: 0.3460  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [1240/3125]  eta: 0:11:00  Lr: 0.001875  Loss: -0.6762  Acc@1: 87.5000 (86.2863)  Acc@5: 100.0000 (98.5294)  time: 0.3464  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [1250/3125]  eta: 0:10:56  Lr: 0.001875  Loss: -0.7145  Acc@1: 81.2500 (86.3010)  Acc@5: 100.0000 (98.5362)  time: 0.3498  data: 0.0007  max mem: 2502
Train: Epoch[3/5]  [1260/3125]  eta: 0:10:53  Lr: 0.001875  Loss: -0.5096  Acc@1: 87.5000 (86.3154)  Acc@5: 100.0000 (98.5379)  time: 0.3517  data: 0.0011  max mem: 2502
Train: Epoch[3/5]  [1270/3125]  eta: 0:10:49  Lr: 0.001875  Loss: -0.4496  Acc@1: 87.5000 (86.3395)  Acc@5: 100.0000 (98.5297)  time: 0.3507  data: 0.0008  max mem: 2502
Train: Epoch[3/5]  [1280/3125]  eta: 0:10:46  Lr: 0.001875  Loss: -0.2066  Acc@1: 87.5000 (86.3193)  Acc@5: 100.0000 (98.5168)  time: 0.3555  data: 0.0008  max mem: 2502
Train: Epoch[3/5]  [1290/3125]  eta: 0:10:42  Lr: 0.001875  Loss: -0.6696  Acc@1: 87.5000 (86.3478)  Acc@5: 100.0000 (98.5283)  time: 0.3569  data: 0.0016  max mem: 2502
Train: Epoch[3/5]  [1300/3125]  eta: 0:10:39  Lr: 0.001875  Loss: -0.4835  Acc@1: 87.5000 (86.3374)  Acc@5: 100.0000 (98.5204)  time: 0.3519  data: 0.0013  max mem: 2502
Train: Epoch[3/5]  [1310/3125]  eta: 0:10:35  Lr: 0.001875  Loss: -0.5617  Acc@1: 87.5000 (86.3272)  Acc@5: 100.0000 (98.5269)  time: 0.3505  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [1320/3125]  eta: 0:10:32  Lr: 0.001875  Loss: -0.1352  Acc@1: 87.5000 (86.3266)  Acc@5: 100.0000 (98.5333)  time: 0.3521  data: 0.0020  max mem: 2502
Train: Epoch[3/5]  [1330/3125]  eta: 0:10:29  Lr: 0.001875  Loss: -0.7088  Acc@1: 87.5000 (86.2744)  Acc@5: 100.0000 (98.5396)  time: 0.3541  data: 0.0020  max mem: 2502
Train: Epoch[3/5]  [1340/3125]  eta: 0:10:25  Lr: 0.001875  Loss: -0.4276  Acc@1: 87.5000 (86.2836)  Acc@5: 100.0000 (98.5412)  time: 0.3520  data: 0.0010  max mem: 2502
Train: Epoch[3/5]  [1350/3125]  eta: 0:10:21  Lr: 0.001875  Loss: -0.1717  Acc@1: 87.5000 (86.2694)  Acc@5: 100.0000 (98.5381)  time: 0.3477  data: 0.0009  max mem: 2502
Train: Epoch[3/5]  [1360/3125]  eta: 0:10:18  Lr: 0.001875  Loss: -0.7481  Acc@1: 87.5000 (86.2785)  Acc@5: 100.0000 (98.5397)  time: 0.3482  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [1370/3125]  eta: 0:10:15  Lr: 0.001875  Loss: -0.1460  Acc@1: 87.5000 (86.2509)  Acc@5: 100.0000 (98.5275)  time: 0.3525  data: 0.0009  max mem: 2502
Train: Epoch[3/5]  [1380/3125]  eta: 0:10:11  Lr: 0.001875  Loss: 0.0599  Acc@1: 87.5000 (86.2509)  Acc@5: 100.0000 (98.5337)  time: 0.3512  data: 0.0009  max mem: 2502
Train: Epoch[3/5]  [1390/3125]  eta: 0:10:07  Lr: 0.001875  Loss: -0.2024  Acc@1: 87.5000 (86.2689)  Acc@5: 100.0000 (98.5352)  time: 0.3481  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [1400/3125]  eta: 0:10:04  Lr: 0.001875  Loss: -0.0783  Acc@1: 81.2500 (86.2464)  Acc@5: 100.0000 (98.5278)  time: 0.3476  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [1410/3125]  eta: 0:10:00  Lr: 0.001875  Loss: -0.6172  Acc@1: 81.2500 (86.2376)  Acc@5: 100.0000 (98.5338)  time: 0.3480  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [1420/3125]  eta: 0:09:57  Lr: 0.001875  Loss: -0.4240  Acc@1: 87.5000 (86.2509)  Acc@5: 100.0000 (98.5354)  time: 0.3480  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [1430/3125]  eta: 0:09:53  Lr: 0.001875  Loss: -0.2953  Acc@1: 87.5000 (86.1985)  Acc@5: 100.0000 (98.5412)  time: 0.3461  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [1440/3125]  eta: 0:09:50  Lr: 0.001875  Loss: -0.6560  Acc@1: 81.2500 (86.1641)  Acc@5: 100.0000 (98.5427)  time: 0.3476  data: 0.0006  max mem: 2502
Train: Epoch[3/5]  [1450/3125]  eta: 0:09:46  Lr: 0.001875  Loss: -0.2991  Acc@1: 81.2500 (86.1733)  Acc@5: 100.0000 (98.5527)  time: 0.3515  data: 0.0008  max mem: 2502
Train: Epoch[3/5]  [1460/3125]  eta: 0:09:43  Lr: 0.001875  Loss: -0.4015  Acc@1: 87.5000 (86.1653)  Acc@5: 100.0000 (98.5498)  time: 0.3515  data: 0.0006  max mem: 2502
Train: Epoch[3/5]  [1470/3125]  eta: 0:09:39  Lr: 0.001875  Loss: -0.6071  Acc@1: 87.5000 (86.1829)  Acc@5: 100.0000 (98.5512)  time: 0.3502  data: 0.0007  max mem: 2502
Train: Epoch[3/5]  [1480/3125]  eta: 0:09:36  Lr: 0.001875  Loss: -0.3247  Acc@1: 87.5000 (86.1791)  Acc@5: 100.0000 (98.5567)  time: 0.3497  data: 0.0007  max mem: 2502
Train: Epoch[3/5]  [1490/3125]  eta: 0:09:32  Lr: 0.001875  Loss: -0.6237  Acc@1: 87.5000 (86.1544)  Acc@5: 100.0000 (98.5622)  time: 0.3533  data: 0.0013  max mem: 2502
Train: Epoch[3/5]  [1500/3125]  eta: 0:09:29  Lr: 0.001875  Loss: -0.2989  Acc@1: 81.2500 (86.1384)  Acc@5: 100.0000 (98.5551)  time: 0.3574  data: 0.0020  max mem: 2502
Train: Epoch[3/5]  [1510/3125]  eta: 0:09:25  Lr: 0.001875  Loss: -0.3596  Acc@1: 81.2500 (86.1226)  Acc@5: 100.0000 (98.5564)  time: 0.3530  data: 0.0014  max mem: 2502
Train: Epoch[3/5]  [1520/3125]  eta: 0:09:22  Lr: 0.001875  Loss: -0.8269  Acc@1: 87.5000 (86.1440)  Acc@5: 100.0000 (98.5577)  time: 0.3501  data: 0.0006  max mem: 2502
Train: Epoch[3/5]  [1530/3125]  eta: 0:09:18  Lr: 0.001875  Loss: -0.3690  Acc@1: 87.5000 (86.1447)  Acc@5: 100.0000 (98.5630)  time: 0.3515  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [1540/3125]  eta: 0:09:15  Lr: 0.001875  Loss: -0.4999  Acc@1: 87.5000 (86.1535)  Acc@5: 100.0000 (98.5724)  time: 0.3528  data: 0.0020  max mem: 2502
Train: Epoch[3/5]  [1550/3125]  eta: 0:09:11  Lr: 0.001875  Loss: -0.7669  Acc@1: 87.5000 (86.1702)  Acc@5: 100.0000 (98.5816)  time: 0.3512  data: 0.0021  max mem: 2502
Train: Epoch[3/5]  [1560/3125]  eta: 0:09:08  Lr: 0.001875  Loss: -0.0395  Acc@1: 87.5000 (86.1387)  Acc@5: 100.0000 (98.5826)  time: 0.3485  data: 0.0006  max mem: 2502
Train: Epoch[3/5]  [1570/3125]  eta: 0:09:04  Lr: 0.001875  Loss: -0.6597  Acc@1: 81.2500 (86.1314)  Acc@5: 100.0000 (98.5797)  time: 0.3475  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [1580/3125]  eta: 0:09:01  Lr: 0.001875  Loss: -0.8014  Acc@1: 81.2500 (86.1243)  Acc@5: 100.0000 (98.5769)  time: 0.3494  data: 0.0007  max mem: 2502
Train: Epoch[3/5]  [1590/3125]  eta: 0:08:57  Lr: 0.001875  Loss: -0.3984  Acc@1: 87.5000 (86.1172)  Acc@5: 100.0000 (98.5858)  time: 0.3534  data: 0.0007  max mem: 2502
Train: Epoch[3/5]  [1600/3125]  eta: 0:08:54  Lr: 0.001875  Loss: -0.3679  Acc@1: 87.5000 (86.1454)  Acc@5: 100.0000 (98.5868)  time: 0.3501  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [1610/3125]  eta: 0:08:50  Lr: 0.001875  Loss: -0.5899  Acc@1: 93.7500 (86.1615)  Acc@5: 100.0000 (98.5801)  time: 0.3452  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [1620/3125]  eta: 0:08:47  Lr: 0.001875  Loss: -0.7917  Acc@1: 87.5000 (86.1891)  Acc@5: 100.0000 (98.5850)  time: 0.3478  data: 0.0013  max mem: 2502
Train: Epoch[3/5]  [1630/3125]  eta: 0:08:43  Lr: 0.001875  Loss: -0.1388  Acc@1: 87.5000 (86.1856)  Acc@5: 100.0000 (98.5745)  time: 0.3493  data: 0.0013  max mem: 2502
Train: Epoch[3/5]  [1640/3125]  eta: 0:08:40  Lr: 0.001875  Loss: -0.5761  Acc@1: 81.2500 (86.1632)  Acc@5: 100.0000 (98.5794)  time: 0.3483  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [1650/3125]  eta: 0:08:36  Lr: 0.001875  Loss: -0.1207  Acc@1: 81.2500 (86.1334)  Acc@5: 100.0000 (98.5577)  time: 0.3502  data: 0.0006  max mem: 2502
Train: Epoch[3/5]  [1660/3125]  eta: 0:08:33  Lr: 0.001875  Loss: -0.4071  Acc@1: 81.2500 (86.1341)  Acc@5: 100.0000 (98.5589)  time: 0.3533  data: 0.0006  max mem: 2502
Train: Epoch[3/5]  [1670/3125]  eta: 0:08:29  Lr: 0.001875  Loss: 0.4181  Acc@1: 87.5000 (86.1161)  Acc@5: 100.0000 (98.5413)  time: 0.3530  data: 0.0010  max mem: 2502
Train: Epoch[3/5]  [1680/3125]  eta: 0:08:26  Lr: 0.001875  Loss: -0.6792  Acc@1: 87.5000 (86.1243)  Acc@5: 100.0000 (98.5388)  time: 0.3504  data: 0.0010  max mem: 2502
Train: Epoch[3/5]  [1690/3125]  eta: 0:08:22  Lr: 0.001875  Loss: -0.5755  Acc@1: 87.5000 (86.1325)  Acc@5: 100.0000 (98.5364)  time: 0.3537  data: 0.0006  max mem: 2502
Train: Epoch[3/5]  [1700/3125]  eta: 0:08:19  Lr: 0.001875  Loss: -0.3868  Acc@1: 87.5000 (86.1442)  Acc@5: 100.0000 (98.5340)  time: 0.3527  data: 0.0006  max mem: 2502
Train: Epoch[3/5]  [1710/3125]  eta: 0:08:15  Lr: 0.001875  Loss: -0.3466  Acc@1: 87.5000 (86.1338)  Acc@5: 100.0000 (98.5316)  time: 0.3509  data: 0.0010  max mem: 2502
Train: Epoch[3/5]  [1720/3125]  eta: 0:08:12  Lr: 0.001875  Loss: -0.6578  Acc@1: 87.5000 (86.1563)  Acc@5: 100.0000 (98.5328)  time: 0.3558  data: 0.0011  max mem: 2502
Train: Epoch[3/5]  [1730/3125]  eta: 0:08:08  Lr: 0.001875  Loss: -0.5051  Acc@1: 87.5000 (86.1713)  Acc@5: 100.0000 (98.5341)  time: 0.3541  data: 0.0006  max mem: 2502
Train: Epoch[3/5]  [1740/3125]  eta: 0:08:05  Lr: 0.001875  Loss: -0.0551  Acc@1: 87.5000 (86.1538)  Acc@5: 100.0000 (98.5353)  time: 0.3492  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [1750/3125]  eta: 0:08:01  Lr: 0.001875  Loss: 0.0617  Acc@1: 87.5000 (86.1543)  Acc@5: 100.0000 (98.5330)  time: 0.3474  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [1760/3125]  eta: 0:07:58  Lr: 0.001875  Loss: -0.7483  Acc@1: 87.5000 (86.1442)  Acc@5: 100.0000 (98.5271)  time: 0.3516  data: 0.0011  max mem: 2502
Train: Epoch[3/5]  [1770/3125]  eta: 0:07:54  Lr: 0.001875  Loss: -0.5304  Acc@1: 81.2500 (86.1378)  Acc@5: 100.0000 (98.5284)  time: 0.3532  data: 0.0011  max mem: 2502
Train: Epoch[3/5]  [1780/3125]  eta: 0:07:51  Lr: 0.001875  Loss: -0.2976  Acc@1: 81.2500 (86.1419)  Acc@5: 100.0000 (98.5261)  time: 0.3501  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [1790/3125]  eta: 0:07:47  Lr: 0.001875  Loss: -0.4934  Acc@1: 87.5000 (86.1460)  Acc@5: 100.0000 (98.5308)  time: 0.3472  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [1800/3125]  eta: 0:07:44  Lr: 0.001875  Loss: -0.7447  Acc@1: 87.5000 (86.1605)  Acc@5: 100.0000 (98.5286)  time: 0.3465  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [1810/3125]  eta: 0:07:40  Lr: 0.001875  Loss: -0.1589  Acc@1: 87.5000 (86.1575)  Acc@5: 100.0000 (98.5229)  time: 0.3471  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [1820/3125]  eta: 0:07:37  Lr: 0.001875  Loss: -0.4430  Acc@1: 81.2500 (86.1477)  Acc@5: 100.0000 (98.5139)  time: 0.3456  data: 0.0002  max mem: 2502
Train: Epoch[3/5]  [1830/3125]  eta: 0:07:33  Lr: 0.001875  Loss: -0.4601  Acc@1: 81.2500 (86.1449)  Acc@5: 100.0000 (98.5220)  time: 0.3476  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [1840/3125]  eta: 0:07:30  Lr: 0.001875  Loss: -0.8296  Acc@1: 81.2500 (86.1488)  Acc@5: 100.0000 (98.5232)  time: 0.3537  data: 0.0007  max mem: 2502
Train: Epoch[3/5]  [1850/3125]  eta: 0:07:26  Lr: 0.001875  Loss: -0.5254  Acc@1: 81.2500 (86.1359)  Acc@5: 100.0000 (98.5244)  time: 0.3563  data: 0.0013  max mem: 2502
Train: Epoch[3/5]  [1860/3125]  eta: 0:07:23  Lr: 0.001875  Loss: -0.3567  Acc@1: 87.5000 (86.1365)  Acc@5: 100.0000 (98.5257)  time: 0.3519  data: 0.0009  max mem: 2502
Train: Epoch[3/5]  [1870/3125]  eta: 0:07:19  Lr: 0.001875  Loss: -0.6490  Acc@1: 87.5000 (86.1304)  Acc@5: 100.0000 (98.5235)  time: 0.3513  data: 0.0008  max mem: 2502
Train: Epoch[3/5]  [1880/3125]  eta: 0:07:16  Lr: 0.001875  Loss: -0.8437  Acc@1: 87.5000 (86.1477)  Acc@5: 100.0000 (98.5280)  time: 0.3533  data: 0.0008  max mem: 2502
Train: Epoch[3/5]  [1890/3125]  eta: 0:07:12  Lr: 0.001875  Loss: -0.1430  Acc@1: 87.5000 (86.1317)  Acc@5: 100.0000 (98.5193)  time: 0.3587  data: 0.0007  max mem: 2502
Train: Epoch[3/5]  [1900/3125]  eta: 0:07:09  Lr: 0.001875  Loss: -0.6117  Acc@1: 87.5000 (86.1323)  Acc@5: 100.0000 (98.5205)  time: 0.3580  data: 0.0007  max mem: 2502
Train: Epoch[3/5]  [1910/3125]  eta: 0:07:05  Lr: 0.001875  Loss: -0.6567  Acc@1: 87.5000 (86.1329)  Acc@5: 100.0000 (98.5184)  time: 0.3507  data: 0.0006  max mem: 2502
Train: Epoch[3/5]  [1920/3125]  eta: 0:07:02  Lr: 0.001875  Loss: -0.7519  Acc@1: 87.5000 (86.1465)  Acc@5: 100.0000 (98.5197)  time: 0.3490  data: 0.0007  max mem: 2502
Train: Epoch[3/5]  [1930/3125]  eta: 0:06:58  Lr: 0.001875  Loss: -0.4123  Acc@1: 87.5000 (86.1471)  Acc@5: 100.0000 (98.5144)  time: 0.3497  data: 0.0013  max mem: 2502
Train: Epoch[3/5]  [1940/3125]  eta: 0:06:55  Lr: 0.001875  Loss: -0.6257  Acc@1: 81.2500 (86.1186)  Acc@5: 100.0000 (98.5188)  time: 0.3500  data: 0.0012  max mem: 2502
Train: Epoch[3/5]  [1950/3125]  eta: 0:06:51  Lr: 0.001875  Loss: -0.5977  Acc@1: 87.5000 (86.1321)  Acc@5: 100.0000 (98.5200)  time: 0.3499  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [1960/3125]  eta: 0:06:48  Lr: 0.001875  Loss: -0.4015  Acc@1: 87.5000 (86.1168)  Acc@5: 100.0000 (98.5116)  time: 0.3493  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [1970/3125]  eta: 0:06:44  Lr: 0.001875  Loss: -0.6835  Acc@1: 87.5000 (86.1238)  Acc@5: 100.0000 (98.5160)  time: 0.3476  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [1980/3125]  eta: 0:06:41  Lr: 0.001875  Loss: -0.5876  Acc@1: 87.5000 (86.1213)  Acc@5: 100.0000 (98.5235)  time: 0.3512  data: 0.0012  max mem: 2502
Train: Epoch[3/5]  [1990/3125]  eta: 0:06:37  Lr: 0.001875  Loss: -0.5292  Acc@1: 87.5000 (86.1094)  Acc@5: 100.0000 (98.5246)  time: 0.3498  data: 0.0011  max mem: 2502
Train: Epoch[3/5]  [2000/3125]  eta: 0:06:34  Lr: 0.001875  Loss: -0.6896  Acc@1: 87.5000 (86.1038)  Acc@5: 100.0000 (98.5289)  time: 0.3449  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [2010/3125]  eta: 0:06:30  Lr: 0.001875  Loss: -0.6560  Acc@1: 81.2500 (86.0952)  Acc@5: 100.0000 (98.5237)  time: 0.3460  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [2020/3125]  eta: 0:06:27  Lr: 0.001875  Loss: -0.7184  Acc@1: 87.5000 (86.1176)  Acc@5: 100.0000 (98.5218)  time: 0.3485  data: 0.0011  max mem: 2502
Train: Epoch[3/5]  [2030/3125]  eta: 0:06:23  Lr: 0.001875  Loss: -0.4289  Acc@1: 93.7500 (86.1244)  Acc@5: 100.0000 (98.5198)  time: 0.3481  data: 0.0011  max mem: 2502
Train: Epoch[3/5]  [2040/3125]  eta: 0:06:20  Lr: 0.001875  Loss: -0.3354  Acc@1: 87.5000 (86.1251)  Acc@5: 100.0000 (98.5209)  time: 0.3468  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [2050/3125]  eta: 0:06:16  Lr: 0.001875  Loss: -0.6630  Acc@1: 87.5000 (86.1257)  Acc@5: 100.0000 (98.5282)  time: 0.3500  data: 0.0009  max mem: 2502
Train: Epoch[3/5]  [2060/3125]  eta: 0:06:13  Lr: 0.001875  Loss: -0.7379  Acc@1: 81.2500 (86.1202)  Acc@5: 100.0000 (98.5262)  time: 0.3551  data: 0.0024  max mem: 2502
Train: Epoch[3/5]  [2070/3125]  eta: 0:06:09  Lr: 0.001875  Loss: -0.3170  Acc@1: 81.2500 (86.1088)  Acc@5: 100.0000 (98.5243)  time: 0.3532  data: 0.0020  max mem: 2502
Train: Epoch[3/5]  [2080/3125]  eta: 0:06:06  Lr: 0.001875  Loss: -0.4920  Acc@1: 81.2500 (86.0974)  Acc@5: 100.0000 (98.5223)  time: 0.3505  data: 0.0006  max mem: 2502
Train: Epoch[3/5]  [2090/3125]  eta: 0:06:02  Lr: 0.001875  Loss: -0.6304  Acc@1: 87.5000 (86.1251)  Acc@5: 100.0000 (98.5264)  time: 0.3525  data: 0.0006  max mem: 2502
Train: Epoch[3/5]  [2100/3125]  eta: 0:05:59  Lr: 0.001875  Loss: -0.6562  Acc@1: 87.5000 (86.1197)  Acc@5: 100.0000 (98.5275)  time: 0.3550  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [2110/3125]  eta: 0:05:55  Lr: 0.001875  Loss: -0.3547  Acc@1: 87.5000 (86.1144)  Acc@5: 100.0000 (98.5315)  time: 0.3575  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [2120/3125]  eta: 0:05:52  Lr: 0.001875  Loss: -0.3056  Acc@1: 87.5000 (86.0974)  Acc@5: 100.0000 (98.5355)  time: 0.3552  data: 0.0008  max mem: 2502
Train: Epoch[3/5]  [2130/3125]  eta: 0:05:48  Lr: 0.001875  Loss: -0.4964  Acc@1: 87.5000 (86.0893)  Acc@5: 100.0000 (98.5394)  time: 0.3554  data: 0.0009  max mem: 2502
Train: Epoch[3/5]  [2140/3125]  eta: 0:05:45  Lr: 0.001875  Loss: -0.3095  Acc@1: 87.5000 (86.1017)  Acc@5: 100.0000 (98.5462)  time: 0.3531  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [2150/3125]  eta: 0:05:41  Lr: 0.001875  Loss: -0.7037  Acc@1: 87.5000 (86.0821)  Acc@5: 100.0000 (98.5443)  time: 0.3499  data: 0.0006  max mem: 2502
Train: Epoch[3/5]  [2160/3125]  eta: 0:05:38  Lr: 0.001875  Loss: -0.6400  Acc@1: 87.5000 (86.1060)  Acc@5: 100.0000 (98.5423)  time: 0.3539  data: 0.0006  max mem: 2502
Train: Epoch[3/5]  [2170/3125]  eta: 0:05:34  Lr: 0.001875  Loss: -0.6412  Acc@1: 87.5000 (86.1210)  Acc@5: 100.0000 (98.5433)  time: 0.3517  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [2180/3125]  eta: 0:05:31  Lr: 0.001875  Loss: -0.6378  Acc@1: 87.5000 (86.1417)  Acc@5: 100.0000 (98.5442)  time: 0.3489  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [2190/3125]  eta: 0:05:27  Lr: 0.001875  Loss: -0.4539  Acc@1: 87.5000 (86.1479)  Acc@5: 100.0000 (98.5452)  time: 0.3478  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [2200/3125]  eta: 0:05:24  Lr: 0.001875  Loss: -0.5480  Acc@1: 87.5000 (86.1540)  Acc@5: 100.0000 (98.5461)  time: 0.3470  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [2210/3125]  eta: 0:05:20  Lr: 0.001875  Loss: -0.1263  Acc@1: 87.5000 (86.1488)  Acc@5: 100.0000 (98.5470)  time: 0.3468  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [2220/3125]  eta: 0:05:17  Lr: 0.001875  Loss: -0.6995  Acc@1: 81.2500 (86.1296)  Acc@5: 100.0000 (98.5423)  time: 0.3453  data: 0.0002  max mem: 2502
Train: Epoch[3/5]  [2230/3125]  eta: 0:05:13  Lr: 0.001875  Loss: -0.3995  Acc@1: 81.2500 (86.1273)  Acc@5: 100.0000 (98.5405)  time: 0.3490  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [2240/3125]  eta: 0:05:10  Lr: 0.001875  Loss: -0.6176  Acc@1: 87.5000 (86.1446)  Acc@5: 100.0000 (98.5414)  time: 0.3549  data: 0.0007  max mem: 2502
Train: Epoch[3/5]  [2250/3125]  eta: 0:05:06  Lr: 0.001875  Loss: -0.7075  Acc@1: 87.5000 (86.1367)  Acc@5: 100.0000 (98.5395)  time: 0.3538  data: 0.0006  max mem: 2502
Train: Epoch[3/5]  [2260/3125]  eta: 0:05:03  Lr: 0.001875  Loss: -0.3733  Acc@1: 87.5000 (86.1400)  Acc@5: 100.0000 (98.5349)  time: 0.3499  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [2270/3125]  eta: 0:04:59  Lr: 0.001875  Loss: -0.0986  Acc@1: 81.2500 (86.1267)  Acc@5: 100.0000 (98.5359)  time: 0.3516  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [2280/3125]  eta: 0:04:56  Lr: 0.001875  Loss: -0.6666  Acc@1: 81.2500 (86.1272)  Acc@5: 100.0000 (98.5423)  time: 0.3583  data: 0.0006  max mem: 2502
Train: Epoch[3/5]  [2290/3125]  eta: 0:04:52  Lr: 0.001875  Loss: -0.7332  Acc@1: 87.5000 (86.1442)  Acc@5: 100.0000 (98.5459)  time: 0.3590  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [2300/3125]  eta: 0:04:49  Lr: 0.001875  Loss: -0.5280  Acc@1: 87.5000 (86.1500)  Acc@5: 100.0000 (98.5387)  time: 0.3514  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [2310/3125]  eta: 0:04:45  Lr: 0.001875  Loss: -0.6460  Acc@1: 87.5000 (86.1478)  Acc@5: 100.0000 (98.5423)  time: 0.3492  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [2320/3125]  eta: 0:04:42  Lr: 0.001875  Loss: -0.7522  Acc@1: 87.5000 (86.1347)  Acc@5: 100.0000 (98.5405)  time: 0.3489  data: 0.0006  max mem: 2502
Train: Epoch[3/5]  [2330/3125]  eta: 0:04:38  Lr: 0.001875  Loss: -0.5188  Acc@1: 81.2500 (86.1218)  Acc@5: 100.0000 (98.5387)  time: 0.3488  data: 0.0009  max mem: 2502
Train: Epoch[3/5]  [2340/3125]  eta: 0:04:35  Lr: 0.001875  Loss: -0.6290  Acc@1: 81.2500 (86.1144)  Acc@5: 100.0000 (98.5396)  time: 0.3513  data: 0.0010  max mem: 2502
Train: Epoch[3/5]  [2350/3125]  eta: 0:04:31  Lr: 0.001875  Loss: -0.4810  Acc@1: 87.5000 (86.1043)  Acc@5: 100.0000 (98.5432)  time: 0.3496  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [2360/3125]  eta: 0:04:28  Lr: 0.001875  Loss: -0.5065  Acc@1: 87.5000 (86.1155)  Acc@5: 100.0000 (98.5440)  time: 0.3470  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [2370/3125]  eta: 0:04:24  Lr: 0.001875  Loss: -0.3405  Acc@1: 87.5000 (86.1135)  Acc@5: 100.0000 (98.5449)  time: 0.3502  data: 0.0011  max mem: 2502
Train: Epoch[3/5]  [2380/3125]  eta: 0:04:21  Lr: 0.001875  Loss: -0.7443  Acc@1: 87.5000 (86.1272)  Acc@5: 100.0000 (98.5510)  time: 0.3509  data: 0.0011  max mem: 2502
Train: Epoch[3/5]  [2390/3125]  eta: 0:04:17  Lr: 0.001875  Loss: -0.5121  Acc@1: 87.5000 (86.1224)  Acc@5: 100.0000 (98.5492)  time: 0.3469  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [2400/3125]  eta: 0:04:14  Lr: 0.001875  Loss: -0.3174  Acc@1: 81.2500 (86.0995)  Acc@5: 100.0000 (98.5475)  time: 0.3456  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [2410/3125]  eta: 0:04:10  Lr: 0.001875  Loss: -0.3058  Acc@1: 81.2500 (86.0768)  Acc@5: 100.0000 (98.5380)  time: 0.3476  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [2420/3125]  eta: 0:04:07  Lr: 0.001875  Loss: -0.3273  Acc@1: 81.2500 (86.0879)  Acc@5: 100.0000 (98.5414)  time: 0.3478  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [2430/3125]  eta: 0:04:03  Lr: 0.001875  Loss: -0.5396  Acc@1: 87.5000 (86.0988)  Acc@5: 100.0000 (98.5397)  time: 0.3491  data: 0.0009  max mem: 2502
Train: Epoch[3/5]  [2440/3125]  eta: 0:04:00  Lr: 0.001875  Loss: -0.5292  Acc@1: 87.5000 (86.1046)  Acc@5: 100.0000 (98.5431)  time: 0.3508  data: 0.0011  max mem: 2502
Train: Epoch[3/5]  [2450/3125]  eta: 0:03:56  Lr: 0.001875  Loss: -0.8773  Acc@1: 87.5000 (86.0899)  Acc@5: 100.0000 (98.5414)  time: 0.3503  data: 0.0010  max mem: 2502
Train: Epoch[3/5]  [2460/3125]  eta: 0:03:53  Lr: 0.001875  Loss: -0.3145  Acc@1: 87.5000 (86.0981)  Acc@5: 100.0000 (98.5448)  time: 0.3525  data: 0.0009  max mem: 2502
Train: Epoch[3/5]  [2470/3125]  eta: 0:03:49  Lr: 0.001875  Loss: -0.5592  Acc@1: 87.5000 (86.0912)  Acc@5: 100.0000 (98.5456)  time: 0.3574  data: 0.0008  max mem: 2502
Train: Epoch[3/5]  [2480/3125]  eta: 0:03:46  Lr: 0.001875  Loss: -0.7622  Acc@1: 87.5000 (86.0994)  Acc@5: 100.0000 (98.5465)  time: 0.3558  data: 0.0007  max mem: 2502
Train: Epoch[3/5]  [2490/3125]  eta: 0:03:42  Lr: 0.001875  Loss: -0.6494  Acc@1: 87.5000 (86.0924)  Acc@5: 100.0000 (98.5473)  time: 0.3512  data: 0.0006  max mem: 2502
Train: Epoch[3/5]  [2500/3125]  eta: 0:03:39  Lr: 0.001875  Loss: -0.6965  Acc@1: 87.5000 (86.0981)  Acc@5: 100.0000 (98.5481)  time: 0.3539  data: 0.0007  max mem: 2502
Train: Epoch[3/5]  [2510/3125]  eta: 0:03:35  Lr: 0.001875  Loss: -0.7671  Acc@1: 87.5000 (86.1111)  Acc@5: 100.0000 (98.5489)  time: 0.3586  data: 0.0009  max mem: 2502
Train: Epoch[3/5]  [2520/3125]  eta: 0:03:32  Lr: 0.001875  Loss: -0.6610  Acc@1: 87.5000 (86.1365)  Acc@5: 100.0000 (98.5522)  time: 0.3545  data: 0.0007  max mem: 2502
Train: Epoch[3/5]  [2530/3125]  eta: 0:03:28  Lr: 0.001875  Loss: -0.5113  Acc@1: 87.5000 (86.1369)  Acc@5: 100.0000 (98.5579)  time: 0.3483  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [2540/3125]  eta: 0:03:25  Lr: 0.001875  Loss: -0.5210  Acc@1: 87.5000 (86.1373)  Acc@5: 100.0000 (98.5636)  time: 0.3511  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [2550/3125]  eta: 0:03:21  Lr: 0.001875  Loss: -0.5532  Acc@1: 87.5000 (86.1182)  Acc@5: 100.0000 (98.5594)  time: 0.3512  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [2560/3125]  eta: 0:03:18  Lr: 0.001875  Loss: -0.3097  Acc@1: 87.5000 (86.1211)  Acc@5: 100.0000 (98.5626)  time: 0.3485  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [2570/3125]  eta: 0:03:14  Lr: 0.001875  Loss: -0.6922  Acc@1: 87.5000 (86.1022)  Acc@5: 100.0000 (98.5511)  time: 0.3480  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [2580/3125]  eta: 0:03:11  Lr: 0.001875  Loss: -0.7523  Acc@1: 87.5000 (86.1076)  Acc@5: 100.0000 (98.5543)  time: 0.3476  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [2590/3125]  eta: 0:03:07  Lr: 0.001875  Loss: -0.5970  Acc@1: 87.5000 (86.1130)  Acc@5: 100.0000 (98.5575)  time: 0.3466  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [2600/3125]  eta: 0:03:04  Lr: 0.001875  Loss: -0.2081  Acc@1: 81.2500 (86.0943)  Acc@5: 100.0000 (98.5510)  time: 0.3458  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [2610/3125]  eta: 0:03:00  Lr: 0.001875  Loss: -0.8579  Acc@1: 81.2500 (86.0973)  Acc@5: 100.0000 (98.5566)  time: 0.3465  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [2620/3125]  eta: 0:02:57  Lr: 0.001875  Loss: -0.7025  Acc@1: 87.5000 (86.0979)  Acc@5: 100.0000 (98.5549)  time: 0.3512  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [2630/3125]  eta: 0:02:53  Lr: 0.001875  Loss: -0.3700  Acc@1: 87.5000 (86.1174)  Acc@5: 100.0000 (98.5557)  time: 0.3538  data: 0.0008  max mem: 2502
Train: Epoch[3/5]  [2640/3125]  eta: 0:02:50  Lr: 0.001875  Loss: -0.5553  Acc@1: 87.5000 (86.1156)  Acc@5: 100.0000 (98.5541)  time: 0.3511  data: 0.0008  max mem: 2502
Train: Epoch[3/5]  [2650/3125]  eta: 0:02:46  Lr: 0.001875  Loss: -0.4960  Acc@1: 87.5000 (86.1043)  Acc@5: 100.0000 (98.5524)  time: 0.3526  data: 0.0007  max mem: 2502
Train: Epoch[3/5]  [2660/3125]  eta: 0:02:43  Lr: 0.001875  Loss: -0.4990  Acc@1: 87.5000 (86.1260)  Acc@5: 100.0000 (98.5508)  time: 0.3540  data: 0.0009  max mem: 2502
Train: Epoch[3/5]  [2670/3125]  eta: 0:02:39  Lr: 0.001875  Loss: -0.7213  Acc@1: 93.7500 (86.1358)  Acc@5: 100.0000 (98.5539)  time: 0.3531  data: 0.0008  max mem: 2502
Train: Epoch[3/5]  [2680/3125]  eta: 0:02:36  Lr: 0.001875  Loss: -0.0124  Acc@1: 87.5000 (86.1316)  Acc@5: 100.0000 (98.5500)  time: 0.3534  data: 0.0007  max mem: 2502
Train: Epoch[3/5]  [2690/3125]  eta: 0:02:32  Lr: 0.001875  Loss: -0.5865  Acc@1: 87.5000 (86.1297)  Acc@5: 100.0000 (98.5507)  time: 0.3518  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [2700/3125]  eta: 0:02:29  Lr: 0.001875  Loss: -0.6127  Acc@1: 87.5000 (86.1301)  Acc@5: 100.0000 (98.5468)  time: 0.3503  data: 0.0007  max mem: 2502
Train: Epoch[3/5]  [2710/3125]  eta: 0:02:25  Lr: 0.001875  Loss: -0.6342  Acc@1: 87.5000 (86.1421)  Acc@5: 100.0000 (98.5499)  time: 0.3488  data: 0.0007  max mem: 2502
Train: Epoch[3/5]  [2720/3125]  eta: 0:02:21  Lr: 0.001875  Loss: -0.8048  Acc@1: 87.5000 (86.1356)  Acc@5: 100.0000 (98.5506)  time: 0.3485  data: 0.0008  max mem: 2502
Train: Epoch[3/5]  [2730/3125]  eta: 0:02:18  Lr: 0.001875  Loss: -0.6953  Acc@1: 87.5000 (86.1429)  Acc@5: 100.0000 (98.5514)  time: 0.3492  data: 0.0009  max mem: 2502
Train: Epoch[3/5]  [2740/3125]  eta: 0:02:14  Lr: 0.001875  Loss: -0.7205  Acc@1: 87.5000 (86.1570)  Acc@5: 100.0000 (98.5498)  time: 0.3490  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [2750/3125]  eta: 0:02:11  Lr: 0.001875  Loss: -0.9157  Acc@1: 87.5000 (86.1732)  Acc@5: 100.0000 (98.5505)  time: 0.3489  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [2760/3125]  eta: 0:02:07  Lr: 0.001875  Loss: -0.8285  Acc@1: 87.5000 (86.1803)  Acc@5: 100.0000 (98.5558)  time: 0.3476  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [2770/3125]  eta: 0:02:04  Lr: 0.001875  Loss: -0.5028  Acc@1: 93.7500 (86.1963)  Acc@5: 100.0000 (98.5542)  time: 0.3472  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [2780/3125]  eta: 0:02:00  Lr: 0.001875  Loss: -0.5856  Acc@1: 87.5000 (86.1943)  Acc@5: 100.0000 (98.5572)  time: 0.3473  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [2790/3125]  eta: 0:01:57  Lr: 0.001875  Loss: -0.7309  Acc@1: 87.5000 (86.2146)  Acc@5: 100.0000 (98.5601)  time: 0.3464  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [2800/3125]  eta: 0:01:53  Lr: 0.001875  Loss: -0.6614  Acc@1: 87.5000 (86.2281)  Acc@5: 100.0000 (98.5630)  time: 0.3481  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [2810/3125]  eta: 0:01:50  Lr: 0.001875  Loss: -0.5790  Acc@1: 87.5000 (86.2082)  Acc@5: 100.0000 (98.5570)  time: 0.3501  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [2820/3125]  eta: 0:01:46  Lr: 0.001875  Loss: -0.7646  Acc@1: 81.2500 (86.2106)  Acc@5: 100.0000 (98.5555)  time: 0.3510  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [2830/3125]  eta: 0:01:43  Lr: 0.001875  Loss: -0.5260  Acc@1: 81.2500 (86.1952)  Acc@5: 100.0000 (98.5562)  time: 0.3510  data: 0.0006  max mem: 2502
Train: Epoch[3/5]  [2840/3125]  eta: 0:01:39  Lr: 0.001875  Loss: -0.3055  Acc@1: 87.5000 (86.1976)  Acc@5: 100.0000 (98.5546)  time: 0.3519  data: 0.0006  max mem: 2502
Train: Epoch[3/5]  [2850/3125]  eta: 0:01:36  Lr: 0.001875  Loss: -0.6238  Acc@1: 87.5000 (86.2044)  Acc@5: 100.0000 (98.5531)  time: 0.3615  data: 0.0020  max mem: 2502
Train: Epoch[3/5]  [2860/3125]  eta: 0:01:32  Lr: 0.001875  Loss: -0.1806  Acc@1: 87.5000 (86.1915)  Acc@5: 100.0000 (98.5495)  time: 0.3624  data: 0.0021  max mem: 2502
Train: Epoch[3/5]  [2870/3125]  eta: 0:01:29  Lr: 0.001875  Loss: -0.7641  Acc@1: 81.2500 (86.1960)  Acc@5: 100.0000 (98.5502)  time: 0.3531  data: 0.0006  max mem: 2502
Train: Epoch[3/5]  [2880/3125]  eta: 0:01:25  Lr: 0.001875  Loss: -0.1535  Acc@1: 81.2500 (86.1788)  Acc@5: 100.0000 (98.5465)  time: 0.3502  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [2890/3125]  eta: 0:01:22  Lr: 0.001875  Loss: -0.8587  Acc@1: 87.5000 (86.1856)  Acc@5: 100.0000 (98.5472)  time: 0.3509  data: 0.0006  max mem: 2502
Train: Epoch[3/5]  [2900/3125]  eta: 0:01:18  Lr: 0.001875  Loss: -0.5831  Acc@1: 87.5000 (86.1966)  Acc@5: 100.0000 (98.5479)  time: 0.3639  data: 0.0024  max mem: 2502
Train: Epoch[3/5]  [2910/3125]  eta: 0:01:15  Lr: 0.001875  Loss: -0.7312  Acc@1: 87.5000 (86.1925)  Acc@5: 100.0000 (98.5465)  time: 0.3631  data: 0.0023  max mem: 2502
Train: Epoch[3/5]  [2920/3125]  eta: 0:01:11  Lr: 0.001875  Loss: -0.2011  Acc@1: 81.2500 (86.1798)  Acc@5: 100.0000 (98.5450)  time: 0.3494  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [2930/3125]  eta: 0:01:08  Lr: 0.001875  Loss: -0.7376  Acc@1: 87.5000 (86.1865)  Acc@5: 100.0000 (98.5479)  time: 0.3478  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [2940/3125]  eta: 0:01:04  Lr: 0.001875  Loss: -0.4489  Acc@1: 87.5000 (86.1824)  Acc@5: 100.0000 (98.5443)  time: 0.3491  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [2950/3125]  eta: 0:01:01  Lr: 0.001875  Loss: -0.4383  Acc@1: 81.2500 (86.1699)  Acc@5: 100.0000 (98.5407)  time: 0.3503  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [2960/3125]  eta: 0:00:57  Lr: 0.001875  Loss: -0.5355  Acc@1: 87.5000 (86.1723)  Acc@5: 100.0000 (98.5393)  time: 0.3486  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [2970/3125]  eta: 0:00:54  Lr: 0.001875  Loss: -0.6748  Acc@1: 87.5000 (86.1747)  Acc@5: 100.0000 (98.5401)  time: 0.3462  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [2980/3125]  eta: 0:00:50  Lr: 0.001875  Loss: -0.3994  Acc@1: 87.5000 (86.1854)  Acc@5: 100.0000 (98.5429)  time: 0.3457  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [2990/3125]  eta: 0:00:47  Lr: 0.001875  Loss: -0.3514  Acc@1: 87.5000 (86.1856)  Acc@5: 100.0000 (98.5435)  time: 0.3477  data: 0.0011  max mem: 2502
Train: Epoch[3/5]  [3000/3125]  eta: 0:00:43  Lr: 0.001875  Loss: -0.5634  Acc@1: 81.2500 (86.1629)  Acc@5: 100.0000 (98.5463)  time: 0.3477  data: 0.0011  max mem: 2502
Train: Epoch[3/5]  [3010/3125]  eta: 0:00:40  Lr: 0.001875  Loss: -0.2992  Acc@1: 81.2500 (86.1529)  Acc@5: 100.0000 (98.5511)  time: 0.3461  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [3020/3125]  eta: 0:00:36  Lr: 0.001875  Loss: -0.6875  Acc@1: 87.5000 (86.1552)  Acc@5: 100.0000 (98.5518)  time: 0.3481  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [3030/3125]  eta: 0:00:33  Lr: 0.001875  Loss: -0.4573  Acc@1: 87.5000 (86.1576)  Acc@5: 100.0000 (98.5504)  time: 0.3577  data: 0.0006  max mem: 2502
Train: Epoch[3/5]  [3040/3125]  eta: 0:00:29  Lr: 0.001875  Loss: -0.5544  Acc@1: 81.2500 (86.1497)  Acc@5: 100.0000 (98.5490)  time: 0.3589  data: 0.0007  max mem: 2502
Train: Epoch[3/5]  [3050/3125]  eta: 0:00:26  Lr: 0.001875  Loss: -0.4450  Acc@1: 81.2500 (86.1418)  Acc@5: 100.0000 (98.5517)  time: 0.3517  data: 0.0006  max mem: 2502
Train: Epoch[3/5]  [3060/3125]  eta: 0:00:22  Lr: 0.001875  Loss: -0.4282  Acc@1: 87.5000 (86.1626)  Acc@5: 100.0000 (98.5483)  time: 0.3515  data: 0.0006  max mem: 2502
Train: Epoch[3/5]  [3070/3125]  eta: 0:00:19  Lr: 0.001875  Loss: -0.6659  Acc@1: 93.7500 (86.1731)  Acc@5: 100.0000 (98.5510)  time: 0.3518  data: 0.0007  max mem: 2502
Train: Epoch[3/5]  [3080/3125]  eta: 0:00:15  Lr: 0.001875  Loss: -0.6635  Acc@1: 87.5000 (86.1693)  Acc@5: 100.0000 (98.5516)  time: 0.3581  data: 0.0017  max mem: 2502
Train: Epoch[3/5]  [3090/3125]  eta: 0:00:12  Lr: 0.001875  Loss: -0.7090  Acc@1: 87.5000 (86.1776)  Acc@5: 100.0000 (98.5522)  time: 0.3583  data: 0.0016  max mem: 2502
Train: Epoch[3/5]  [3100/3125]  eta: 0:00:08  Lr: 0.001875  Loss: -0.6395  Acc@1: 93.7500 (86.1940)  Acc@5: 100.0000 (98.5569)  time: 0.3503  data: 0.0006  max mem: 2502
Train: Epoch[3/5]  [3110/3125]  eta: 0:00:05  Lr: 0.001875  Loss: -0.6767  Acc@1: 93.7500 (86.2042)  Acc@5: 100.0000 (98.5595)  time: 0.3510  data: 0.0006  max mem: 2502
Train: Epoch[3/5]  [3120/3125]  eta: 0:00:01  Lr: 0.001875  Loss: -0.4940  Acc@1: 87.5000 (86.2083)  Acc@5: 100.0000 (98.5642)  time: 0.3523  data: 0.0009  max mem: 2502
Train: Epoch[3/5]  [3124/3125]  eta: 0:00:00  Lr: 0.001875  Loss: -0.5532  Acc@1: 87.5000 (86.2080)  Acc@5: 100.0000 (98.5620)  time: 0.3515  data: 0.0008  max mem: 2502
Train: Epoch[3/5] Total time: 0:18:16 (0.3509 s / it)
{0: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 1: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 2: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 3: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 4: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 5: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 6: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 7: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 8: {0: 0, 1: 0, 2: 150000, 3: 0, 4: 0}, 9: {0: 0, 1: 0, 2: 150000, 3: 0, 4: 0}, 10: {0: 0, 1: 0, 2: 150000, 3: 0, 4: 0}, 11: {0: 0, 1: 0, 2: 150000, 3: 0, 4: 0}, 12: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 13: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 14: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 15: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 16: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 17: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 18: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 19: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}}
Averaged stats: Lr: 0.001875  Loss: -0.5532  Acc@1: 87.5000 (86.2080)  Acc@5: 100.0000 (98.5620)
Train: Epoch[4/5]  [   0/3125]  eta: 0:45:10  Lr: 0.001875  Loss: -0.3450  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (100.0000)  time: 0.8675  data: 0.5175  max mem: 2502
Train: Epoch[4/5]  [  10/3125]  eta: 0:20:32  Lr: 0.001875  Loss: -0.9195  Acc@1: 87.5000 (86.3636)  Acc@5: 100.0000 (98.8636)  time: 0.3956  data: 0.0474  max mem: 2502
Train: Epoch[4/5]  [  20/3125]  eta: 0:19:17  Lr: 0.001875  Loss: -0.3552  Acc@1: 87.5000 (86.6071)  Acc@5: 100.0000 (99.1071)  time: 0.3480  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [  30/3125]  eta: 0:18:49  Lr: 0.001875  Loss: -0.3293  Acc@1: 81.2500 (86.2903)  Acc@5: 100.0000 (98.9919)  time: 0.3478  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [  40/3125]  eta: 0:18:33  Lr: 0.001875  Loss: -0.3631  Acc@1: 87.5000 (86.5854)  Acc@5: 100.0000 (98.7805)  time: 0.3488  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [  50/3125]  eta: 0:18:21  Lr: 0.001875  Loss: -0.6051  Acc@1: 87.5000 (86.3971)  Acc@5: 100.0000 (98.7745)  time: 0.3484  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [  60/3125]  eta: 0:18:11  Lr: 0.001875  Loss: -0.6370  Acc@1: 87.5000 (86.2705)  Acc@5: 100.0000 (98.7705)  time: 0.3462  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [  70/3125]  eta: 0:18:03  Lr: 0.001875  Loss: -0.5627  Acc@1: 87.5000 (86.6197)  Acc@5: 100.0000 (98.5915)  time: 0.3454  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [  80/3125]  eta: 0:17:59  Lr: 0.001875  Loss: -0.7777  Acc@1: 87.5000 (86.5741)  Acc@5: 100.0000 (98.6883)  time: 0.3488  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [  90/3125]  eta: 0:17:52  Lr: 0.001875  Loss: -0.6381  Acc@1: 87.5000 (86.2637)  Acc@5: 100.0000 (98.4890)  time: 0.3487  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [ 100/3125]  eta: 0:17:48  Lr: 0.001875  Loss: -0.5231  Acc@1: 87.5000 (86.4480)  Acc@5: 100.0000 (98.5149)  time: 0.3483  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [ 110/3125]  eta: 0:17:43  Lr: 0.001875  Loss: -0.4390  Acc@1: 87.5000 (86.4302)  Acc@5: 100.0000 (98.5923)  time: 0.3507  data: 0.0007  max mem: 2502
Train: Epoch[4/5]  [ 120/3125]  eta: 0:17:41  Lr: 0.001875  Loss: -0.1037  Acc@1: 87.5000 (86.3636)  Acc@5: 100.0000 (98.6570)  time: 0.3537  data: 0.0008  max mem: 2502
Train: Epoch[4/5]  [ 130/3125]  eta: 0:17:38  Lr: 0.001875  Loss: -0.7658  Acc@1: 87.5000 (86.3550)  Acc@5: 100.0000 (98.7118)  time: 0.3555  data: 0.0012  max mem: 2502
Train: Epoch[4/5]  [ 140/3125]  eta: 0:17:33  Lr: 0.001875  Loss: -0.7195  Acc@1: 87.5000 (86.5691)  Acc@5: 100.0000 (98.6259)  time: 0.3514  data: 0.0010  max mem: 2502
Train: Epoch[4/5]  [ 150/3125]  eta: 0:17:30  Lr: 0.001875  Loss: -0.3756  Acc@1: 87.5000 (86.5480)  Acc@5: 100.0000 (98.6341)  time: 0.3513  data: 0.0007  max mem: 2502
Train: Epoch[4/5]  [ 160/3125]  eta: 0:17:25  Lr: 0.001875  Loss: -0.7485  Acc@1: 81.2500 (86.2966)  Acc@5: 100.0000 (98.5637)  time: 0.3505  data: 0.0006  max mem: 2502
Train: Epoch[4/5]  [ 170/3125]  eta: 0:17:22  Lr: 0.001875  Loss: -0.8113  Acc@1: 81.2500 (86.3670)  Acc@5: 100.0000 (98.6111)  time: 0.3513  data: 0.0010  max mem: 2502
Train: Epoch[4/5]  [ 180/3125]  eta: 0:17:18  Lr: 0.001875  Loss: -0.5525  Acc@1: 87.5000 (86.3950)  Acc@5: 100.0000 (98.6188)  time: 0.3537  data: 0.0010  max mem: 2502
Train: Epoch[4/5]  [ 190/3125]  eta: 0:17:14  Lr: 0.001875  Loss: -0.7557  Acc@1: 87.5000 (86.8128)  Acc@5: 100.0000 (98.6584)  time: 0.3501  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [ 200/3125]  eta: 0:17:10  Lr: 0.001875  Loss: -0.3847  Acc@1: 93.7500 (86.8159)  Acc@5: 100.0000 (98.7251)  time: 0.3478  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [ 210/3125]  eta: 0:17:07  Lr: 0.001875  Loss: -0.7898  Acc@1: 87.5000 (86.9964)  Acc@5: 100.0000 (98.7559)  time: 0.3508  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [ 220/3125]  eta: 0:17:03  Lr: 0.001875  Loss: -0.6670  Acc@1: 87.5000 (86.9061)  Acc@5: 100.0000 (98.7839)  time: 0.3515  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [ 230/3125]  eta: 0:16:59  Lr: 0.001875  Loss: -0.5449  Acc@1: 81.2500 (86.7695)  Acc@5: 100.0000 (98.8095)  time: 0.3487  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [ 240/3125]  eta: 0:16:55  Lr: 0.001875  Loss: 0.1599  Acc@1: 81.2500 (86.5664)  Acc@5: 100.0000 (98.7811)  time: 0.3474  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [ 250/3125]  eta: 0:16:51  Lr: 0.001875  Loss: -0.6936  Acc@1: 87.5000 (86.6285)  Acc@5: 100.0000 (98.7301)  time: 0.3481  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [ 260/3125]  eta: 0:16:47  Lr: 0.001875  Loss: -0.7426  Acc@1: 87.5000 (86.3745)  Acc@5: 100.0000 (98.7308)  time: 0.3511  data: 0.0016  max mem: 2502
Train: Epoch[4/5]  [ 270/3125]  eta: 0:16:43  Lr: 0.001875  Loss: -0.4091  Acc@1: 81.2500 (86.2777)  Acc@5: 100.0000 (98.6854)  time: 0.3490  data: 0.0016  max mem: 2502
Train: Epoch[4/5]  [ 280/3125]  eta: 0:16:39  Lr: 0.001875  Loss: -0.3445  Acc@1: 81.2500 (86.2989)  Acc@5: 100.0000 (98.7100)  time: 0.3457  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [ 290/3125]  eta: 0:16:36  Lr: 0.001875  Loss: -0.6666  Acc@1: 87.5000 (86.2758)  Acc@5: 100.0000 (98.6899)  time: 0.3498  data: 0.0007  max mem: 2502
Train: Epoch[4/5]  [ 300/3125]  eta: 0:16:32  Lr: 0.001875  Loss: -0.7677  Acc@1: 87.5000 (86.2957)  Acc@5: 100.0000 (98.6919)  time: 0.3536  data: 0.0016  max mem: 2502
Train: Epoch[4/5]  [ 310/3125]  eta: 0:16:29  Lr: 0.001875  Loss: -0.3379  Acc@1: 87.5000 (86.3143)  Acc@5: 100.0000 (98.6736)  time: 0.3518  data: 0.0013  max mem: 2502
Train: Epoch[4/5]  [ 320/3125]  eta: 0:16:26  Lr: 0.001875  Loss: -0.8747  Acc@1: 87.5000 (86.3512)  Acc@5: 100.0000 (98.6565)  time: 0.3520  data: 0.0007  max mem: 2502
Train: Epoch[4/5]  [ 330/3125]  eta: 0:16:22  Lr: 0.001875  Loss: -0.1332  Acc@1: 87.5000 (86.4048)  Acc@5: 100.0000 (98.6405)  time: 0.3531  data: 0.0008  max mem: 2502
Train: Epoch[4/5]  [ 340/3125]  eta: 0:16:19  Lr: 0.001875  Loss: -0.7381  Acc@1: 87.5000 (86.4186)  Acc@5: 100.0000 (98.6620)  time: 0.3559  data: 0.0011  max mem: 2502
Train: Epoch[4/5]  [ 350/3125]  eta: 0:16:16  Lr: 0.001875  Loss: -0.3482  Acc@1: 87.5000 (86.2892)  Acc@5: 100.0000 (98.6467)  time: 0.3571  data: 0.0014  max mem: 2502
Train: Epoch[4/5]  [ 360/3125]  eta: 0:16:12  Lr: 0.001875  Loss: -0.7286  Acc@1: 87.5000 (86.3573)  Acc@5: 100.0000 (98.6669)  time: 0.3530  data: 0.0010  max mem: 2502
Train: Epoch[4/5]  [ 370/3125]  eta: 0:16:09  Lr: 0.001875  Loss: -0.6140  Acc@1: 87.5000 (86.3208)  Acc@5: 100.0000 (98.6691)  time: 0.3510  data: 0.0006  max mem: 2502
Train: Epoch[4/5]  [ 380/3125]  eta: 0:16:05  Lr: 0.001875  Loss: -0.4367  Acc@1: 87.5000 (86.4009)  Acc@5: 100.0000 (98.6549)  time: 0.3499  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [ 390/3125]  eta: 0:16:01  Lr: 0.001875  Loss: -0.7591  Acc@1: 87.5000 (86.4930)  Acc@5: 100.0000 (98.6733)  time: 0.3501  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [ 400/3125]  eta: 0:15:58  Lr: 0.001875  Loss: -0.5029  Acc@1: 87.5000 (86.4869)  Acc@5: 100.0000 (98.6752)  time: 0.3499  data: 0.0012  max mem: 2502
Train: Epoch[4/5]  [ 410/3125]  eta: 0:15:54  Lr: 0.001875  Loss: -0.8157  Acc@1: 81.2500 (86.4355)  Acc@5: 100.0000 (98.6466)  time: 0.3481  data: 0.0011  max mem: 2502
Train: Epoch[4/5]  [ 420/3125]  eta: 0:15:50  Lr: 0.001875  Loss: -0.4975  Acc@1: 81.2500 (86.3866)  Acc@5: 100.0000 (98.6342)  time: 0.3474  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [ 430/3125]  eta: 0:15:47  Lr: 0.001875  Loss: -0.5666  Acc@1: 87.5000 (86.3689)  Acc@5: 100.0000 (98.6224)  time: 0.3493  data: 0.0009  max mem: 2502
Train: Epoch[4/5]  [ 440/3125]  eta: 0:15:43  Lr: 0.001875  Loss: -0.3408  Acc@1: 87.5000 (86.2812)  Acc@5: 100.0000 (98.6395)  time: 0.3498  data: 0.0009  max mem: 2502
Train: Epoch[4/5]  [ 450/3125]  eta: 0:15:39  Lr: 0.001875  Loss: -0.8326  Acc@1: 81.2500 (86.2666)  Acc@5: 100.0000 (98.6280)  time: 0.3466  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [ 460/3125]  eta: 0:15:35  Lr: 0.001875  Loss: -0.5801  Acc@1: 81.2500 (86.2392)  Acc@5: 100.0000 (98.6036)  time: 0.3451  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [ 470/3125]  eta: 0:15:32  Lr: 0.001875  Loss: -0.0769  Acc@1: 81.2500 (86.2128)  Acc@5: 100.0000 (98.6200)  time: 0.3466  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [ 480/3125]  eta: 0:15:28  Lr: 0.001875  Loss: -0.4480  Acc@1: 87.5000 (86.2396)  Acc@5: 100.0000 (98.6357)  time: 0.3474  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [ 490/3125]  eta: 0:15:24  Lr: 0.001875  Loss: -0.6210  Acc@1: 87.5000 (86.2780)  Acc@5: 100.0000 (98.6634)  time: 0.3488  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [ 500/3125]  eta: 0:15:21  Lr: 0.001875  Loss: -0.1750  Acc@1: 87.5000 (86.3149)  Acc@5: 100.0000 (98.6776)  time: 0.3494  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [ 510/3125]  eta: 0:15:17  Lr: 0.001875  Loss: -0.6883  Acc@1: 87.5000 (86.3014)  Acc@5: 100.0000 (98.6913)  time: 0.3490  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [ 520/3125]  eta: 0:15:14  Lr: 0.001875  Loss: -0.6897  Acc@1: 87.5000 (86.3364)  Acc@5: 100.0000 (98.7164)  time: 0.3559  data: 0.0006  max mem: 2502
Train: Epoch[4/5]  [ 530/3125]  eta: 0:15:11  Lr: 0.001875  Loss: -0.5510  Acc@1: 87.5000 (86.2406)  Acc@5: 100.0000 (98.7053)  time: 0.3592  data: 0.0006  max mem: 2502
Train: Epoch[4/5]  [ 540/3125]  eta: 0:15:07  Lr: 0.001875  Loss: -0.6426  Acc@1: 81.2500 (86.2061)  Acc@5: 100.0000 (98.6599)  time: 0.3539  data: 0.0006  max mem: 2502
Train: Epoch[4/5]  [ 550/3125]  eta: 0:15:04  Lr: 0.001875  Loss: -0.6163  Acc@1: 87.5000 (86.2863)  Acc@5: 100.0000 (98.6842)  time: 0.3504  data: 0.0006  max mem: 2502
Train: Epoch[4/5]  [ 560/3125]  eta: 0:15:00  Lr: 0.001875  Loss: -0.2020  Acc@1: 87.5000 (86.2411)  Acc@5: 100.0000 (98.6742)  time: 0.3510  data: 0.0006  max mem: 2502
Train: Epoch[4/5]  [ 570/3125]  eta: 0:14:57  Lr: 0.001875  Loss: -0.6547  Acc@1: 87.5000 (86.3288)  Acc@5: 100.0000 (98.6865)  time: 0.3550  data: 0.0009  max mem: 2502
Train: Epoch[4/5]  [ 580/3125]  eta: 0:14:53  Lr: 0.001875  Loss: -0.5847  Acc@1: 87.5000 (86.3275)  Acc@5: 100.0000 (98.6984)  time: 0.3530  data: 0.0009  max mem: 2502
Train: Epoch[4/5]  [ 590/3125]  eta: 0:14:50  Lr: 0.001875  Loss: -0.6965  Acc@1: 87.5000 (86.3050)  Acc@5: 100.0000 (98.6992)  time: 0.3475  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [ 600/3125]  eta: 0:14:46  Lr: 0.001875  Loss: -0.7735  Acc@1: 87.5000 (86.2937)  Acc@5: 100.0000 (98.6689)  time: 0.3480  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [ 610/3125]  eta: 0:14:42  Lr: 0.001875  Loss: -0.4075  Acc@1: 81.2500 (86.2214)  Acc@5: 100.0000 (98.6395)  time: 0.3489  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [ 620/3125]  eta: 0:14:39  Lr: 0.001875  Loss: -0.7723  Acc@1: 87.5000 (86.2923)  Acc@5: 100.0000 (98.6413)  time: 0.3488  data: 0.0007  max mem: 2502
Train: Epoch[4/5]  [ 630/3125]  eta: 0:14:35  Lr: 0.001875  Loss: -0.2674  Acc@1: 87.5000 (86.2520)  Acc@5: 100.0000 (98.6133)  time: 0.3469  data: 0.0006  max mem: 2502
Train: Epoch[4/5]  [ 640/3125]  eta: 0:14:31  Lr: 0.001875  Loss: -0.5350  Acc@1: 87.5000 (86.2520)  Acc@5: 100.0000 (98.5959)  time: 0.3455  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [ 650/3125]  eta: 0:14:28  Lr: 0.001875  Loss: -0.4198  Acc@1: 87.5000 (86.2999)  Acc@5: 100.0000 (98.5887)  time: 0.3473  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [ 660/3125]  eta: 0:14:24  Lr: 0.001875  Loss: -0.7201  Acc@1: 87.5000 (86.2992)  Acc@5: 100.0000 (98.5817)  time: 0.3496  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [ 670/3125]  eta: 0:14:21  Lr: 0.001875  Loss: -0.7167  Acc@1: 87.5000 (86.3171)  Acc@5: 100.0000 (98.6028)  time: 0.3499  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [ 680/3125]  eta: 0:14:17  Lr: 0.001875  Loss: -0.5759  Acc@1: 87.5000 (86.2518)  Acc@5: 100.0000 (98.5958)  time: 0.3504  data: 0.0006  max mem: 2502
Train: Epoch[4/5]  [ 690/3125]  eta: 0:14:14  Lr: 0.001875  Loss: -0.5344  Acc@1: 81.2500 (86.1885)  Acc@5: 100.0000 (98.5800)  time: 0.3540  data: 0.0010  max mem: 2502
Train: Epoch[4/5]  [ 700/3125]  eta: 0:14:11  Lr: 0.001875  Loss: -0.7422  Acc@1: 87.5000 (86.2250)  Acc@5: 100.0000 (98.5824)  time: 0.3552  data: 0.0011  max mem: 2502
Train: Epoch[4/5]  [ 710/3125]  eta: 0:14:07  Lr: 0.001875  Loss: -0.6767  Acc@1: 87.5000 (86.2078)  Acc@5: 100.0000 (98.5759)  time: 0.3522  data: 0.0007  max mem: 2502
Train: Epoch[4/5]  [ 720/3125]  eta: 0:14:03  Lr: 0.001875  Loss: -0.6448  Acc@1: 87.5000 (86.2257)  Acc@5: 100.0000 (98.5697)  time: 0.3500  data: 0.0006  max mem: 2502
Train: Epoch[4/5]  [ 730/3125]  eta: 0:14:00  Lr: 0.001875  Loss: -0.5419  Acc@1: 87.5000 (86.2603)  Acc@5: 100.0000 (98.5807)  time: 0.3495  data: 0.0006  max mem: 2502
Train: Epoch[4/5]  [ 740/3125]  eta: 0:13:56  Lr: 0.001875  Loss: -0.6572  Acc@1: 87.5000 (86.2348)  Acc@5: 100.0000 (98.5577)  time: 0.3502  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [ 750/3125]  eta: 0:13:53  Lr: 0.001875  Loss: -0.2068  Acc@1: 87.5000 (86.2850)  Acc@5: 100.0000 (98.5603)  time: 0.3523  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [ 760/3125]  eta: 0:13:50  Lr: 0.001875  Loss: -0.6867  Acc@1: 87.5000 (86.2516)  Acc@5: 100.0000 (98.5545)  time: 0.3534  data: 0.0006  max mem: 2502
Train: Epoch[4/5]  [ 770/3125]  eta: 0:13:46  Lr: 0.001875  Loss: 0.2370  Acc@1: 81.2500 (86.2435)  Acc@5: 100.0000 (98.5490)  time: 0.3508  data: 0.0006  max mem: 2502
Train: Epoch[4/5]  [ 780/3125]  eta: 0:13:42  Lr: 0.001875  Loss: -0.5920  Acc@1: 93.7500 (86.3156)  Acc@5: 100.0000 (98.5675)  time: 0.3480  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [ 790/3125]  eta: 0:13:39  Lr: 0.001875  Loss: -0.7232  Acc@1: 93.7500 (86.3859)  Acc@5: 100.0000 (98.5698)  time: 0.3499  data: 0.0007  max mem: 2502
Train: Epoch[4/5]  [ 800/3125]  eta: 0:13:35  Lr: 0.001875  Loss: -0.2160  Acc@1: 87.5000 (86.3686)  Acc@5: 100.0000 (98.5721)  time: 0.3494  data: 0.0007  max mem: 2502
Train: Epoch[4/5]  [ 810/3125]  eta: 0:13:32  Lr: 0.001875  Loss: -0.7041  Acc@1: 87.5000 (86.4057)  Acc@5: 100.0000 (98.5666)  time: 0.3486  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [ 820/3125]  eta: 0:13:28  Lr: 0.001875  Loss: -0.5820  Acc@1: 81.2500 (86.3276)  Acc@5: 100.0000 (98.5764)  time: 0.3489  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [ 830/3125]  eta: 0:13:24  Lr: 0.001875  Loss: -0.7909  Acc@1: 87.5000 (86.4019)  Acc@5: 100.0000 (98.5860)  time: 0.3471  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [ 840/3125]  eta: 0:13:21  Lr: 0.001875  Loss: -0.3811  Acc@1: 87.5000 (86.3407)  Acc@5: 100.0000 (98.5880)  time: 0.3462  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [ 850/3125]  eta: 0:13:17  Lr: 0.001875  Loss: -0.5631  Acc@1: 81.2500 (86.3323)  Acc@5: 100.0000 (98.5899)  time: 0.3466  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [ 860/3125]  eta: 0:13:14  Lr: 0.001875  Loss: -0.7057  Acc@1: 87.5000 (86.3240)  Acc@5: 100.0000 (98.5845)  time: 0.3509  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [ 870/3125]  eta: 0:13:10  Lr: 0.001875  Loss: -0.5743  Acc@1: 87.5000 (86.3447)  Acc@5: 100.0000 (98.5792)  time: 0.3535  data: 0.0013  max mem: 2502
Train: Epoch[4/5]  [ 880/3125]  eta: 0:13:07  Lr: 0.001875  Loss: -0.5791  Acc@1: 87.5000 (86.3791)  Acc@5: 100.0000 (98.5953)  time: 0.3522  data: 0.0014  max mem: 2502
Train: Epoch[4/5]  [ 890/3125]  eta: 0:13:03  Lr: 0.001875  Loss: -0.6928  Acc@1: 87.5000 (86.4198)  Acc@5: 100.0000 (98.5971)  time: 0.3513  data: 0.0006  max mem: 2502
Train: Epoch[4/5]  [ 900/3125]  eta: 0:13:00  Lr: 0.001875  Loss: -0.4799  Acc@1: 87.5000 (86.4526)  Acc@5: 100.0000 (98.6057)  time: 0.3517  data: 0.0006  max mem: 2502
Train: Epoch[4/5]  [ 910/3125]  eta: 0:12:57  Lr: 0.001875  Loss: -0.3375  Acc@1: 87.5000 (86.4572)  Acc@5: 100.0000 (98.6073)  time: 0.3533  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [ 920/3125]  eta: 0:12:53  Lr: 0.001875  Loss: -0.6746  Acc@1: 87.5000 (86.4957)  Acc@5: 100.0000 (98.6088)  time: 0.3537  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [ 930/3125]  eta: 0:12:50  Lr: 0.001875  Loss: -0.3267  Acc@1: 87.5000 (86.5199)  Acc@5: 100.0000 (98.5768)  time: 0.3522  data: 0.0006  max mem: 2502
Train: Epoch[4/5]  [ 940/3125]  eta: 0:12:46  Lr: 0.001875  Loss: -0.2742  Acc@1: 87.5000 (86.4639)  Acc@5: 100.0000 (98.5786)  time: 0.3514  data: 0.0007  max mem: 2502
Train: Epoch[4/5]  [ 950/3125]  eta: 0:12:43  Lr: 0.001875  Loss: -0.1424  Acc@1: 81.2500 (86.4748)  Acc@5: 100.0000 (98.5673)  time: 0.3539  data: 0.0007  max mem: 2502
Train: Epoch[4/5]  [ 960/3125]  eta: 0:12:39  Lr: 0.001875  Loss: 0.0558  Acc@1: 87.5000 (86.4594)  Acc@5: 100.0000 (98.5627)  time: 0.3578  data: 0.0013  max mem: 2502
Train: Epoch[4/5]  [ 970/3125]  eta: 0:12:36  Lr: 0.001875  Loss: -0.6702  Acc@1: 81.2500 (86.4444)  Acc@5: 100.0000 (98.5646)  time: 0.3540  data: 0.0010  max mem: 2502
Train: Epoch[4/5]  [ 980/3125]  eta: 0:12:32  Lr: 0.001875  Loss: -0.7856  Acc@1: 87.5000 (86.4997)  Acc@5: 100.0000 (98.5793)  time: 0.3483  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [ 990/3125]  eta: 0:12:29  Lr: 0.001875  Loss: -0.5378  Acc@1: 93.7500 (86.5351)  Acc@5: 100.0000 (98.5747)  time: 0.3482  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [1000/3125]  eta: 0:12:25  Lr: 0.001875  Loss: -0.8586  Acc@1: 93.7500 (86.5822)  Acc@5: 100.0000 (98.5702)  time: 0.3486  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [1010/3125]  eta: 0:12:22  Lr: 0.001875  Loss: -0.3048  Acc@1: 87.5000 (86.6098)  Acc@5: 100.0000 (98.5781)  time: 0.3489  data: 0.0007  max mem: 2502
Train: Epoch[4/5]  [1020/3125]  eta: 0:12:18  Lr: 0.001875  Loss: -0.7086  Acc@1: 87.5000 (86.6063)  Acc@5: 100.0000 (98.5676)  time: 0.3469  data: 0.0007  max mem: 2502
Train: Epoch[4/5]  [1030/3125]  eta: 0:12:14  Lr: 0.001875  Loss: -0.4096  Acc@1: 87.5000 (86.6331)  Acc@5: 100.0000 (98.5694)  time: 0.3458  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [1040/3125]  eta: 0:12:11  Lr: 0.001875  Loss: -0.3430  Acc@1: 87.5000 (86.6294)  Acc@5: 100.0000 (98.5771)  time: 0.3492  data: 0.0011  max mem: 2502
Train: Epoch[4/5]  [1050/3125]  eta: 0:12:07  Lr: 0.001875  Loss: -0.3657  Acc@1: 87.5000 (86.6199)  Acc@5: 100.0000 (98.5668)  time: 0.3488  data: 0.0011  max mem: 2502
Train: Epoch[4/5]  [1060/3125]  eta: 0:12:04  Lr: 0.001875  Loss: -0.3125  Acc@1: 81.2500 (86.6046)  Acc@5: 100.0000 (98.5686)  time: 0.3467  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [1070/3125]  eta: 0:12:00  Lr: 0.001875  Loss: -0.5018  Acc@1: 87.5000 (86.6246)  Acc@5: 100.0000 (98.5703)  time: 0.3483  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [1080/3125]  eta: 0:11:57  Lr: 0.001875  Loss: -0.4020  Acc@1: 87.5000 (86.6559)  Acc@5: 100.0000 (98.5661)  time: 0.3507  data: 0.0007  max mem: 2502
Train: Epoch[4/5]  [1090/3125]  eta: 0:11:53  Lr: 0.001875  Loss: -0.3758  Acc@1: 87.5000 (86.6636)  Acc@5: 100.0000 (98.5678)  time: 0.3508  data: 0.0009  max mem: 2502
Train: Epoch[4/5]  [1100/3125]  eta: 0:11:50  Lr: 0.001875  Loss: -0.2263  Acc@1: 87.5000 (86.6371)  Acc@5: 100.0000 (98.5638)  time: 0.3484  data: 0.0006  max mem: 2502
Train: Epoch[4/5]  [1110/3125]  eta: 0:11:46  Lr: 0.001875  Loss: -0.4749  Acc@1: 81.2500 (86.5718)  Acc@5: 100.0000 (98.5542)  time: 0.3477  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [1120/3125]  eta: 0:11:43  Lr: 0.001875  Loss: -0.7129  Acc@1: 81.2500 (86.5578)  Acc@5: 100.0000 (98.5671)  time: 0.3530  data: 0.0014  max mem: 2502
Train: Epoch[4/5]  [1130/3125]  eta: 0:11:39  Lr: 0.001875  Loss: -0.0885  Acc@1: 81.2500 (86.5440)  Acc@5: 100.0000 (98.5632)  time: 0.3574  data: 0.0016  max mem: 2502
Train: Epoch[4/5]  [1140/3125]  eta: 0:11:36  Lr: 0.001875  Loss: -0.6692  Acc@1: 87.5000 (86.5798)  Acc@5: 100.0000 (98.5703)  time: 0.3529  data: 0.0007  max mem: 2502
Train: Epoch[4/5]  [1150/3125]  eta: 0:11:32  Lr: 0.001875  Loss: -0.6210  Acc@1: 87.5000 (86.5552)  Acc@5: 100.0000 (98.5719)  time: 0.3508  data: 0.0007  max mem: 2502
Train: Epoch[4/5]  [1160/3125]  eta: 0:11:29  Lr: 0.001875  Loss: -0.0737  Acc@1: 87.5000 (86.5525)  Acc@5: 100.0000 (98.5734)  time: 0.3512  data: 0.0007  max mem: 2502
Train: Epoch[4/5]  [1170/3125]  eta: 0:11:25  Lr: 0.001875  Loss: -0.8316  Acc@1: 87.5000 (86.5980)  Acc@5: 100.0000 (98.5803)  time: 0.3513  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [1180/3125]  eta: 0:11:22  Lr: 0.001875  Loss: -0.3097  Acc@1: 87.5000 (86.5898)  Acc@5: 100.0000 (98.5923)  time: 0.3506  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [1190/3125]  eta: 0:11:18  Lr: 0.001875  Loss: -0.3161  Acc@1: 87.5000 (86.5554)  Acc@5: 100.0000 (98.5831)  time: 0.3496  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [1200/3125]  eta: 0:11:15  Lr: 0.001875  Loss: -0.5760  Acc@1: 87.5000 (86.5633)  Acc@5: 100.0000 (98.5897)  time: 0.3489  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [1210/3125]  eta: 0:11:11  Lr: 0.001875  Loss: -0.6922  Acc@1: 87.5000 (86.5710)  Acc@5: 100.0000 (98.5962)  time: 0.3492  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [1220/3125]  eta: 0:11:08  Lr: 0.001875  Loss: -0.8282  Acc@1: 87.5000 (86.5530)  Acc@5: 100.0000 (98.5975)  time: 0.3489  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [1230/3125]  eta: 0:11:04  Lr: 0.001875  Loss: -0.6738  Acc@1: 87.5000 (86.5404)  Acc@5: 100.0000 (98.5936)  time: 0.3459  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [1240/3125]  eta: 0:11:00  Lr: 0.001875  Loss: -0.4932  Acc@1: 87.5000 (86.5633)  Acc@5: 100.0000 (98.5999)  time: 0.3447  data: 0.0002  max mem: 2502
Train: Epoch[4/5]  [1250/3125]  eta: 0:10:57  Lr: 0.001875  Loss: -0.9015  Acc@1: 87.5000 (86.5857)  Acc@5: 100.0000 (98.6011)  time: 0.3505  data: 0.0012  max mem: 2502
Train: Epoch[4/5]  [1260/3125]  eta: 0:10:53  Lr: 0.001875  Loss: -0.8616  Acc@1: 87.5000 (86.5979)  Acc@5: 100.0000 (98.6073)  time: 0.3515  data: 0.0012  max mem: 2502
Train: Epoch[4/5]  [1270/3125]  eta: 0:10:50  Lr: 0.001875  Loss: -0.4822  Acc@1: 87.5000 (86.6198)  Acc@5: 100.0000 (98.6182)  time: 0.3479  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [1280/3125]  eta: 0:10:46  Lr: 0.001875  Loss: -0.7483  Acc@1: 87.5000 (86.6267)  Acc@5: 100.0000 (98.6241)  time: 0.3508  data: 0.0010  max mem: 2502
Train: Epoch[4/5]  [1290/3125]  eta: 0:10:43  Lr: 0.001875  Loss: -0.6805  Acc@1: 87.5000 (86.6189)  Acc@5: 100.0000 (98.6251)  time: 0.3534  data: 0.0011  max mem: 2502
Train: Epoch[4/5]  [1300/3125]  eta: 0:10:40  Lr: 0.001875  Loss: -0.0955  Acc@1: 87.5000 (86.6161)  Acc@5: 100.0000 (98.6213)  time: 0.3569  data: 0.0006  max mem: 2502
Train: Epoch[4/5]  [1310/3125]  eta: 0:10:36  Lr: 0.001875  Loss: -0.5190  Acc@1: 81.2500 (86.5990)  Acc@5: 100.0000 (98.6222)  time: 0.3560  data: 0.0008  max mem: 2502
Train: Epoch[4/5]  [1320/3125]  eta: 0:10:32  Lr: 0.001875  Loss: -0.4599  Acc@1: 81.2500 (86.5774)  Acc@5: 100.0000 (98.6232)  time: 0.3499  data: 0.0009  max mem: 2502
Train: Epoch[4/5]  [1330/3125]  eta: 0:10:29  Lr: 0.001875  Loss: -0.4430  Acc@1: 87.5000 (86.5843)  Acc@5: 100.0000 (98.6195)  time: 0.3498  data: 0.0007  max mem: 2502
Train: Epoch[4/5]  [1340/3125]  eta: 0:10:26  Lr: 0.001875  Loss: -0.5848  Acc@1: 87.5000 (86.5679)  Acc@5: 100.0000 (98.6018)  time: 0.3519  data: 0.0008  max mem: 2502
Train: Epoch[4/5]  [1350/3125]  eta: 0:10:22  Lr: 0.001875  Loss: -0.6164  Acc@1: 87.5000 (86.5609)  Acc@5: 100.0000 (98.6029)  time: 0.3496  data: 0.0008  max mem: 2502
Train: Epoch[4/5]  [1360/3125]  eta: 0:10:18  Lr: 0.001875  Loss: -0.1465  Acc@1: 81.2500 (86.5494)  Acc@5: 100.0000 (98.6086)  time: 0.3494  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [1370/3125]  eta: 0:10:15  Lr: 0.001875  Loss: -0.4914  Acc@1: 87.5000 (86.5563)  Acc@5: 100.0000 (98.6142)  time: 0.3493  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [1380/3125]  eta: 0:10:11  Lr: 0.001875  Loss: -0.8633  Acc@1: 87.5000 (86.5768)  Acc@5: 100.0000 (98.6106)  time: 0.3484  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [1390/3125]  eta: 0:10:08  Lr: 0.001875  Loss: -0.4545  Acc@1: 87.5000 (86.5654)  Acc@5: 100.0000 (98.6116)  time: 0.3491  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [1400/3125]  eta: 0:10:04  Lr: 0.001875  Loss: -0.3337  Acc@1: 87.5000 (86.5899)  Acc@5: 100.0000 (98.6037)  time: 0.3484  data: 0.0007  max mem: 2502
Train: Epoch[4/5]  [1410/3125]  eta: 0:10:01  Lr: 0.001875  Loss: -0.4264  Acc@1: 87.5000 (86.5920)  Acc@5: 100.0000 (98.6047)  time: 0.3460  data: 0.0006  max mem: 2502
Train: Epoch[4/5]  [1420/3125]  eta: 0:09:57  Lr: 0.001875  Loss: -0.4001  Acc@1: 81.2500 (86.5808)  Acc@5: 100.0000 (98.6145)  time: 0.3457  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [1430/3125]  eta: 0:09:54  Lr: 0.001875  Loss: -0.5819  Acc@1: 87.5000 (86.5959)  Acc@5: 100.0000 (98.6155)  time: 0.3491  data: 0.0011  max mem: 2502
Train: Epoch[4/5]  [1440/3125]  eta: 0:09:50  Lr: 0.001875  Loss: -0.6214  Acc@1: 87.5000 (86.5805)  Acc@5: 100.0000 (98.6121)  time: 0.3494  data: 0.0011  max mem: 2502
Train: Epoch[4/5]  [1450/3125]  eta: 0:09:47  Lr: 0.001875  Loss: -0.8755  Acc@1: 87.5000 (86.5653)  Acc@5: 100.0000 (98.6044)  time: 0.3497  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [1460/3125]  eta: 0:09:43  Lr: 0.001875  Loss: -0.3828  Acc@1: 87.5000 (86.5589)  Acc@5: 100.0000 (98.5969)  time: 0.3506  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [1470/3125]  eta: 0:09:40  Lr: 0.001875  Loss: -0.2809  Acc@1: 81.2500 (86.5313)  Acc@5: 100.0000 (98.5851)  time: 0.3508  data: 0.0011  max mem: 2502
Train: Epoch[4/5]  [1480/3125]  eta: 0:09:36  Lr: 0.001875  Loss: -0.3310  Acc@1: 81.2500 (86.5209)  Acc@5: 100.0000 (98.5736)  time: 0.3527  data: 0.0015  max mem: 2502
Train: Epoch[4/5]  [1490/3125]  eta: 0:09:33  Lr: 0.001875  Loss: -0.3819  Acc@1: 87.5000 (86.5233)  Acc@5: 100.0000 (98.5748)  time: 0.3511  data: 0.0009  max mem: 2502
Train: Epoch[4/5]  [1500/3125]  eta: 0:09:29  Lr: 0.001875  Loss: -0.5882  Acc@1: 87.5000 (86.5298)  Acc@5: 100.0000 (98.5759)  time: 0.3484  data: 0.0006  max mem: 2502
Train: Epoch[4/5]  [1510/3125]  eta: 0:09:26  Lr: 0.001875  Loss: -0.4487  Acc@1: 87.5000 (86.5197)  Acc@5: 100.0000 (98.5854)  time: 0.3487  data: 0.0006  max mem: 2502
Train: Epoch[4/5]  [1520/3125]  eta: 0:09:22  Lr: 0.001875  Loss: -0.6591  Acc@1: 81.2500 (86.5056)  Acc@5: 100.0000 (98.5823)  time: 0.3525  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [1530/3125]  eta: 0:09:19  Lr: 0.001875  Loss: -0.4970  Acc@1: 87.5000 (86.5162)  Acc@5: 100.0000 (98.5794)  time: 0.3546  data: 0.0012  max mem: 2502
Train: Epoch[4/5]  [1540/3125]  eta: 0:09:15  Lr: 0.001875  Loss: -0.6474  Acc@1: 87.5000 (86.5266)  Acc@5: 100.0000 (98.5724)  time: 0.3552  data: 0.0012  max mem: 2502
Train: Epoch[4/5]  [1550/3125]  eta: 0:09:12  Lr: 0.001875  Loss: -0.7245  Acc@1: 93.7500 (86.5571)  Acc@5: 100.0000 (98.5735)  time: 0.3519  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [1560/3125]  eta: 0:09:08  Lr: 0.001875  Loss: -0.7364  Acc@1: 87.5000 (86.5591)  Acc@5: 100.0000 (98.5746)  time: 0.3483  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [1570/3125]  eta: 0:09:05  Lr: 0.001875  Loss: -0.3035  Acc@1: 87.5000 (86.5372)  Acc@5: 100.0000 (98.5718)  time: 0.3502  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [1580/3125]  eta: 0:09:01  Lr: 0.001875  Loss: -0.5854  Acc@1: 87.5000 (86.5394)  Acc@5: 100.0000 (98.5808)  time: 0.3497  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [1590/3125]  eta: 0:08:58  Lr: 0.001875  Loss: -0.2207  Acc@1: 87.5000 (86.5533)  Acc@5: 100.0000 (98.5819)  time: 0.3479  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [1600/3125]  eta: 0:08:54  Lr: 0.001875  Loss: -0.5601  Acc@1: 87.5000 (86.5592)  Acc@5: 100.0000 (98.5829)  time: 0.3464  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [1610/3125]  eta: 0:08:51  Lr: 0.001875  Loss: -0.6332  Acc@1: 87.5000 (86.5728)  Acc@5: 100.0000 (98.5840)  time: 0.3468  data: 0.0009  max mem: 2502
Train: Epoch[4/5]  [1620/3125]  eta: 0:08:47  Lr: 0.001875  Loss: -0.4761  Acc@1: 87.5000 (86.5592)  Acc@5: 100.0000 (98.5773)  time: 0.3477  data: 0.0009  max mem: 2502
Train: Epoch[4/5]  [1630/3125]  eta: 0:08:43  Lr: 0.001875  Loss: -0.4833  Acc@1: 81.2500 (86.5113)  Acc@5: 100.0000 (98.5745)  time: 0.3465  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [1640/3125]  eta: 0:08:40  Lr: 0.001875  Loss: -0.2134  Acc@1: 81.2500 (86.5021)  Acc@5: 100.0000 (98.5756)  time: 0.3487  data: 0.0007  max mem: 2502
Train: Epoch[4/5]  [1650/3125]  eta: 0:08:36  Lr: 0.001875  Loss: -0.9365  Acc@1: 87.5000 (86.5082)  Acc@5: 100.0000 (98.5842)  time: 0.3526  data: 0.0008  max mem: 2502
Train: Epoch[4/5]  [1660/3125]  eta: 0:08:33  Lr: 0.001875  Loss: -0.6762  Acc@1: 87.5000 (86.5292)  Acc@5: 100.0000 (98.5814)  time: 0.3507  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [1670/3125]  eta: 0:08:29  Lr: 0.001875  Loss: -0.7031  Acc@1: 87.5000 (86.5051)  Acc@5: 100.0000 (98.5750)  time: 0.3482  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [1680/3125]  eta: 0:08:26  Lr: 0.001875  Loss: -0.5174  Acc@1: 87.5000 (86.4999)  Acc@5: 100.0000 (98.5686)  time: 0.3493  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [1690/3125]  eta: 0:08:22  Lr: 0.001875  Loss: -0.2462  Acc@1: 87.5000 (86.5132)  Acc@5: 100.0000 (98.5622)  time: 0.3523  data: 0.0011  max mem: 2502
Train: Epoch[4/5]  [1700/3125]  eta: 0:08:19  Lr: 0.001875  Loss: 0.1410  Acc@1: 87.5000 (86.5116)  Acc@5: 100.0000 (98.5597)  time: 0.3541  data: 0.0022  max mem: 2502
Train: Epoch[4/5]  [1710/3125]  eta: 0:08:15  Lr: 0.001875  Loss: -0.4860  Acc@1: 87.5000 (86.5210)  Acc@5: 100.0000 (98.5644)  time: 0.3527  data: 0.0016  max mem: 2502
Train: Epoch[4/5]  [1720/3125]  eta: 0:08:12  Lr: 0.001875  Loss: -0.4967  Acc@1: 87.5000 (86.5195)  Acc@5: 100.0000 (98.5655)  time: 0.3507  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [1730/3125]  eta: 0:08:08  Lr: 0.001875  Loss: -0.4119  Acc@1: 87.5000 (86.5071)  Acc@5: 100.0000 (98.5702)  time: 0.3494  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [1740/3125]  eta: 0:08:05  Lr: 0.001875  Loss: -0.3394  Acc@1: 81.2500 (86.4912)  Acc@5: 100.0000 (98.5605)  time: 0.3495  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [1750/3125]  eta: 0:08:01  Lr: 0.001875  Loss: -0.6837  Acc@1: 87.5000 (86.5291)  Acc@5: 100.0000 (98.5651)  time: 0.3510  data: 0.0006  max mem: 2502
Train: Epoch[4/5]  [1760/3125]  eta: 0:07:58  Lr: 0.001875  Loss: 0.0600  Acc@1: 93.7500 (86.5204)  Acc@5: 100.0000 (98.5555)  time: 0.3504  data: 0.0006  max mem: 2502
Train: Epoch[4/5]  [1770/3125]  eta: 0:07:54  Lr: 0.001875  Loss: -0.7194  Acc@1: 81.2500 (86.5154)  Acc@5: 100.0000 (98.5495)  time: 0.3483  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [1780/3125]  eta: 0:07:51  Lr: 0.001875  Loss: -0.5337  Acc@1: 87.5000 (86.5139)  Acc@5: 100.0000 (98.5542)  time: 0.3472  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [1790/3125]  eta: 0:07:47  Lr: 0.001875  Loss: -0.4854  Acc@1: 87.5000 (86.4950)  Acc@5: 100.0000 (98.5518)  time: 0.3474  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [1800/3125]  eta: 0:07:44  Lr: 0.001875  Loss: -0.6776  Acc@1: 87.5000 (86.5075)  Acc@5: 100.0000 (98.5529)  time: 0.3493  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [1810/3125]  eta: 0:07:40  Lr: 0.001875  Loss: -0.3622  Acc@1: 87.5000 (86.5130)  Acc@5: 100.0000 (98.5471)  time: 0.3515  data: 0.0011  max mem: 2502
Train: Epoch[4/5]  [1820/3125]  eta: 0:07:37  Lr: 0.001875  Loss: -0.4357  Acc@1: 87.5000 (86.5184)  Acc@5: 100.0000 (98.5551)  time: 0.3524  data: 0.0010  max mem: 2502
Train: Epoch[4/5]  [1830/3125]  eta: 0:07:33  Lr: 0.001875  Loss: -0.6059  Acc@1: 87.5000 (86.5272)  Acc@5: 100.0000 (98.5561)  time: 0.3520  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [1840/3125]  eta: 0:07:30  Lr: 0.001875  Loss: -0.3137  Acc@1: 87.5000 (86.5087)  Acc@5: 100.0000 (98.5538)  time: 0.3517  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [1850/3125]  eta: 0:07:26  Lr: 0.001875  Loss: -0.5645  Acc@1: 81.2500 (86.4972)  Acc@5: 100.0000 (98.5481)  time: 0.3499  data: 0.0006  max mem: 2502
Train: Epoch[4/5]  [1860/3125]  eta: 0:07:23  Lr: 0.001875  Loss: -0.7855  Acc@1: 87.5000 (86.5026)  Acc@5: 100.0000 (98.5525)  time: 0.3507  data: 0.0006  max mem: 2502
Train: Epoch[4/5]  [1870/3125]  eta: 0:07:19  Lr: 0.001875  Loss: -0.6177  Acc@1: 87.5000 (86.4979)  Acc@5: 100.0000 (98.5502)  time: 0.3552  data: 0.0022  max mem: 2502
Train: Epoch[4/5]  [1880/3125]  eta: 0:07:16  Lr: 0.001875  Loss: -0.5813  Acc@1: 87.5000 (86.4932)  Acc@5: 100.0000 (98.5480)  time: 0.3578  data: 0.0034  max mem: 2502
Train: Epoch[4/5]  [1890/3125]  eta: 0:07:12  Lr: 0.001875  Loss: -0.6252  Acc@1: 87.5000 (86.4919)  Acc@5: 100.0000 (98.5524)  time: 0.3526  data: 0.0017  max mem: 2502
Train: Epoch[4/5]  [1900/3125]  eta: 0:07:09  Lr: 0.001875  Loss: -0.8708  Acc@1: 87.5000 (86.5038)  Acc@5: 100.0000 (98.5567)  time: 0.3510  data: 0.0014  max mem: 2502
Train: Epoch[4/5]  [1910/3125]  eta: 0:07:05  Lr: 0.001875  Loss: -0.8765  Acc@1: 87.5000 (86.5123)  Acc@5: 100.0000 (98.5512)  time: 0.3515  data: 0.0015  max mem: 2502
Train: Epoch[4/5]  [1920/3125]  eta: 0:07:02  Lr: 0.001875  Loss: -0.6154  Acc@1: 87.5000 (86.5174)  Acc@5: 100.0000 (98.5392)  time: 0.3489  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [1930/3125]  eta: 0:06:58  Lr: 0.001875  Loss: -0.7320  Acc@1: 87.5000 (86.4999)  Acc@5: 100.0000 (98.5403)  time: 0.3493  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [1940/3125]  eta: 0:06:55  Lr: 0.001875  Loss: -0.5529  Acc@1: 81.2500 (86.4857)  Acc@5: 100.0000 (98.5349)  time: 0.3496  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [1950/3125]  eta: 0:06:51  Lr: 0.001875  Loss: -0.5346  Acc@1: 81.2500 (86.4717)  Acc@5: 100.0000 (98.5328)  time: 0.3488  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [1960/3125]  eta: 0:06:48  Lr: 0.001875  Loss: -0.6183  Acc@1: 87.5000 (86.4865)  Acc@5: 100.0000 (98.5403)  time: 0.3484  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [1970/3125]  eta: 0:06:44  Lr: 0.001875  Loss: -0.3050  Acc@1: 81.2500 (86.4504)  Acc@5: 100.0000 (98.5413)  time: 0.3484  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [1980/3125]  eta: 0:06:41  Lr: 0.001875  Loss: -0.4231  Acc@1: 81.2500 (86.4620)  Acc@5: 100.0000 (98.5487)  time: 0.3465  data: 0.0002  max mem: 2502
Train: Epoch[4/5]  [1990/3125]  eta: 0:06:37  Lr: 0.001875  Loss: -0.4326  Acc@1: 87.5000 (86.4547)  Acc@5: 100.0000 (98.5466)  time: 0.3460  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [2000/3125]  eta: 0:06:34  Lr: 0.001875  Loss: -0.6920  Acc@1: 87.5000 (86.4599)  Acc@5: 100.0000 (98.5476)  time: 0.3495  data: 0.0006  max mem: 2502
Train: Epoch[4/5]  [2010/3125]  eta: 0:06:30  Lr: 0.001875  Loss: -0.7392  Acc@1: 87.5000 (86.4837)  Acc@5: 100.0000 (98.5517)  time: 0.3513  data: 0.0006  max mem: 2502
Train: Epoch[4/5]  [2020/3125]  eta: 0:06:27  Lr: 0.001875  Loss: -0.6414  Acc@1: 87.5000 (86.4702)  Acc@5: 100.0000 (98.5496)  time: 0.3540  data: 0.0006  max mem: 2502
Train: Epoch[4/5]  [2030/3125]  eta: 0:06:23  Lr: 0.001875  Loss: -0.3462  Acc@1: 87.5000 (86.4876)  Acc@5: 100.0000 (98.5475)  time: 0.3545  data: 0.0007  max mem: 2502
Train: Epoch[4/5]  [2040/3125]  eta: 0:06:20  Lr: 0.001875  Loss: -0.6264  Acc@1: 87.5000 (86.4987)  Acc@5: 100.0000 (98.5424)  time: 0.3529  data: 0.0006  max mem: 2502
Train: Epoch[4/5]  [2050/3125]  eta: 0:06:16  Lr: 0.001875  Loss: -0.5288  Acc@1: 87.5000 (86.4974)  Acc@5: 100.0000 (98.5464)  time: 0.3550  data: 0.0007  max mem: 2502
Train: Epoch[4/5]  [2060/3125]  eta: 0:06:13  Lr: 0.001875  Loss: -0.7215  Acc@1: 87.5000 (86.5235)  Acc@5: 100.0000 (98.5383)  time: 0.3550  data: 0.0008  max mem: 2502
Train: Epoch[4/5]  [2070/3125]  eta: 0:06:09  Lr: 0.001875  Loss: -0.7956  Acc@1: 87.5000 (86.5192)  Acc@5: 100.0000 (98.5303)  time: 0.3528  data: 0.0012  max mem: 2502
Train: Epoch[4/5]  [2080/3125]  eta: 0:06:06  Lr: 0.001875  Loss: -0.4602  Acc@1: 87.5000 (86.5179)  Acc@5: 100.0000 (98.5284)  time: 0.3496  data: 0.0011  max mem: 2502
Train: Epoch[4/5]  [2090/3125]  eta: 0:06:02  Lr: 0.001875  Loss: 0.0492  Acc@1: 87.5000 (86.5286)  Acc@5: 100.0000 (98.5234)  time: 0.3508  data: 0.0011  max mem: 2502
Train: Epoch[4/5]  [2100/3125]  eta: 0:05:59  Lr: 0.001875  Loss: -0.5952  Acc@1: 87.5000 (86.5272)  Acc@5: 100.0000 (98.5245)  time: 0.3515  data: 0.0011  max mem: 2502
Train: Epoch[4/5]  [2110/3125]  eta: 0:05:55  Lr: 0.001875  Loss: -0.3348  Acc@1: 87.5000 (86.5171)  Acc@5: 100.0000 (98.5256)  time: 0.3497  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [2120/3125]  eta: 0:05:52  Lr: 0.001875  Loss: -0.5881  Acc@1: 81.2500 (86.5040)  Acc@5: 100.0000 (98.5266)  time: 0.3494  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [2130/3125]  eta: 0:05:48  Lr: 0.001875  Loss: -0.5959  Acc@1: 81.2500 (86.4969)  Acc@5: 100.0000 (98.5218)  time: 0.3497  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [2140/3125]  eta: 0:05:45  Lr: 0.001875  Loss: -0.6586  Acc@1: 87.5000 (86.5133)  Acc@5: 100.0000 (98.5170)  time: 0.3503  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [2150/3125]  eta: 0:05:41  Lr: 0.001875  Loss: -0.2695  Acc@1: 87.5000 (86.5121)  Acc@5: 100.0000 (98.5210)  time: 0.3480  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [2160/3125]  eta: 0:05:38  Lr: 0.001875  Loss: -0.5654  Acc@1: 87.5000 (86.5196)  Acc@5: 100.0000 (98.5221)  time: 0.3467  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [2170/3125]  eta: 0:05:34  Lr: 0.001875  Loss: -0.6081  Acc@1: 87.5000 (86.5241)  Acc@5: 100.0000 (98.5260)  time: 0.3462  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [2180/3125]  eta: 0:05:31  Lr: 0.001875  Loss: -0.4210  Acc@1: 87.5000 (86.5343)  Acc@5: 100.0000 (98.5271)  time: 0.3457  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [2190/3125]  eta: 0:05:27  Lr: 0.001875  Loss: -0.7214  Acc@1: 87.5000 (86.5415)  Acc@5: 100.0000 (98.5309)  time: 0.3500  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [2200/3125]  eta: 0:05:24  Lr: 0.001875  Loss: -0.3721  Acc@1: 87.5000 (86.5601)  Acc@5: 100.0000 (98.5291)  time: 0.3523  data: 0.0009  max mem: 2502
Train: Epoch[4/5]  [2210/3125]  eta: 0:05:20  Lr: 0.001875  Loss: -0.9042  Acc@1: 87.5000 (86.5756)  Acc@5: 100.0000 (98.5301)  time: 0.3505  data: 0.0010  max mem: 2502
Train: Epoch[4/5]  [2220/3125]  eta: 0:05:17  Lr: 0.001875  Loss: -0.5677  Acc@1: 87.5000 (86.5601)  Acc@5: 100.0000 (98.5283)  time: 0.3494  data: 0.0006  max mem: 2502
Train: Epoch[4/5]  [2230/3125]  eta: 0:05:13  Lr: 0.001875  Loss: -0.6656  Acc@1: 87.5000 (86.5699)  Acc@5: 100.0000 (98.5292)  time: 0.3504  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [2240/3125]  eta: 0:05:10  Lr: 0.001875  Loss: -0.6389  Acc@1: 87.5000 (86.5713)  Acc@5: 100.0000 (98.5330)  time: 0.3536  data: 0.0007  max mem: 2502
Train: Epoch[4/5]  [2250/3125]  eta: 0:05:06  Lr: 0.001875  Loss: -0.8060  Acc@1: 87.5000 (86.5754)  Acc@5: 100.0000 (98.5312)  time: 0.3519  data: 0.0008  max mem: 2502
Train: Epoch[4/5]  [2260/3125]  eta: 0:05:03  Lr: 0.001875  Loss: -0.2379  Acc@1: 87.5000 (86.5408)  Acc@5: 100.0000 (98.5239)  time: 0.3493  data: 0.0006  max mem: 2502
Train: Epoch[4/5]  [2270/3125]  eta: 0:04:59  Lr: 0.001875  Loss: -0.6934  Acc@1: 87.5000 (86.5478)  Acc@5: 100.0000 (98.5276)  time: 0.3489  data: 0.0006  max mem: 2502
Train: Epoch[4/5]  [2280/3125]  eta: 0:04:56  Lr: 0.001875  Loss: -0.3411  Acc@1: 87.5000 (86.5574)  Acc@5: 100.0000 (98.5286)  time: 0.3527  data: 0.0011  max mem: 2502
Train: Epoch[4/5]  [2290/3125]  eta: 0:04:52  Lr: 0.001875  Loss: -0.7392  Acc@1: 87.5000 (86.5670)  Acc@5: 100.0000 (98.5268)  time: 0.3547  data: 0.0011  max mem: 2502
Train: Epoch[4/5]  [2300/3125]  eta: 0:04:49  Lr: 0.001875  Loss: -0.6693  Acc@1: 87.5000 (86.5738)  Acc@5: 100.0000 (98.5278)  time: 0.3499  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [2310/3125]  eta: 0:04:45  Lr: 0.001875  Loss: -0.6904  Acc@1: 87.5000 (86.5751)  Acc@5: 100.0000 (98.5261)  time: 0.3485  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [2320/3125]  eta: 0:04:42  Lr: 0.001875  Loss: -0.0148  Acc@1: 87.5000 (86.5791)  Acc@5: 100.0000 (98.5217)  time: 0.3492  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [2330/3125]  eta: 0:04:38  Lr: 0.001875  Loss: -0.7766  Acc@1: 81.2500 (86.5803)  Acc@5: 100.0000 (98.5173)  time: 0.3513  data: 0.0008  max mem: 2502
Train: Epoch[4/5]  [2340/3125]  eta: 0:04:35  Lr: 0.001875  Loss: -0.0804  Acc@1: 81.2500 (86.5656)  Acc@5: 100.0000 (98.5049)  time: 0.3509  data: 0.0008  max mem: 2502
Train: Epoch[4/5]  [2350/3125]  eta: 0:04:31  Lr: 0.001875  Loss: -0.4742  Acc@1: 87.5000 (86.5749)  Acc@5: 100.0000 (98.5086)  time: 0.3468  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [2360/3125]  eta: 0:04:28  Lr: 0.001875  Loss: -0.6164  Acc@1: 87.5000 (86.5894)  Acc@5: 100.0000 (98.5123)  time: 0.3472  data: 0.0011  max mem: 2502
Train: Epoch[4/5]  [2370/3125]  eta: 0:04:24  Lr: 0.001875  Loss: -0.4274  Acc@1: 87.5000 (86.5879)  Acc@5: 100.0000 (98.5106)  time: 0.3498  data: 0.0011  max mem: 2502
Train: Epoch[4/5]  [2380/3125]  eta: 0:04:21  Lr: 0.001875  Loss: -0.7566  Acc@1: 87.5000 (86.5786)  Acc@5: 100.0000 (98.5143)  time: 0.3502  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [2390/3125]  eta: 0:04:17  Lr: 0.001875  Loss: -0.4176  Acc@1: 87.5000 (86.5799)  Acc@5: 100.0000 (98.5153)  time: 0.3517  data: 0.0006  max mem: 2502
Train: Epoch[4/5]  [2400/3125]  eta: 0:04:14  Lr: 0.001875  Loss: -0.6832  Acc@1: 87.5000 (86.5863)  Acc@5: 100.0000 (98.5110)  time: 0.3505  data: 0.0006  max mem: 2502
Train: Epoch[4/5]  [2410/3125]  eta: 0:04:10  Lr: 0.001875  Loss: -0.3540  Acc@1: 87.5000 (86.5927)  Acc@5: 100.0000 (98.5120)  time: 0.3508  data: 0.0012  max mem: 2502
Train: Epoch[4/5]  [2420/3125]  eta: 0:04:07  Lr: 0.001875  Loss: -0.3984  Acc@1: 87.5000 (86.5887)  Acc@5: 100.0000 (98.5130)  time: 0.3562  data: 0.0021  max mem: 2502
Train: Epoch[4/5]  [2430/3125]  eta: 0:04:03  Lr: 0.001875  Loss: -0.3151  Acc@1: 87.5000 (86.6002)  Acc@5: 100.0000 (98.5166)  time: 0.3553  data: 0.0020  max mem: 2502
Train: Epoch[4/5]  [2440/3125]  eta: 0:04:00  Lr: 0.001875  Loss: -0.6188  Acc@1: 93.7500 (86.6141)  Acc@5: 100.0000 (98.5175)  time: 0.3497  data: 0.0013  max mem: 2502
Train: Epoch[4/5]  [2450/3125]  eta: 0:03:56  Lr: 0.001875  Loss: -0.6601  Acc@1: 87.5000 (86.6305)  Acc@5: 100.0000 (98.5185)  time: 0.3478  data: 0.0007  max mem: 2502
Train: Epoch[4/5]  [2460/3125]  eta: 0:03:53  Lr: 0.001875  Loss: -0.3089  Acc@1: 87.5000 (86.6162)  Acc@5: 100.0000 (98.5194)  time: 0.3546  data: 0.0008  max mem: 2502
Train: Epoch[4/5]  [2470/3125]  eta: 0:03:49  Lr: 0.001875  Loss: -0.7124  Acc@1: 87.5000 (86.6122)  Acc@5: 100.0000 (98.5203)  time: 0.3550  data: 0.0007  max mem: 2502
Train: Epoch[4/5]  [2480/3125]  eta: 0:03:46  Lr: 0.001875  Loss: -0.6469  Acc@1: 87.5000 (86.6158)  Acc@5: 100.0000 (98.5162)  time: 0.3486  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [2490/3125]  eta: 0:03:42  Lr: 0.001875  Loss: -0.4403  Acc@1: 87.5000 (86.6269)  Acc@5: 100.0000 (98.5197)  time: 0.3478  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [2500/3125]  eta: 0:03:39  Lr: 0.001875  Loss: -0.2694  Acc@1: 87.5000 (86.6278)  Acc@5: 100.0000 (98.5256)  time: 0.3513  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [2510/3125]  eta: 0:03:35  Lr: 0.001875  Loss: -0.7990  Acc@1: 87.5000 (86.6438)  Acc@5: 100.0000 (98.5265)  time: 0.3520  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [2520/3125]  eta: 0:03:32  Lr: 0.001875  Loss: -0.4974  Acc@1: 87.5000 (86.6472)  Acc@5: 100.0000 (98.5274)  time: 0.3486  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [2530/3125]  eta: 0:03:28  Lr: 0.001875  Loss: -0.6991  Acc@1: 87.5000 (86.6579)  Acc@5: 100.0000 (98.5332)  time: 0.3477  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [2540/3125]  eta: 0:03:25  Lr: 0.001875  Loss: -0.8900  Acc@1: 87.5000 (86.6686)  Acc@5: 100.0000 (98.5291)  time: 0.3466  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [2550/3125]  eta: 0:03:21  Lr: 0.001875  Loss: -0.1646  Acc@1: 87.5000 (86.6768)  Acc@5: 100.0000 (98.5300)  time: 0.3478  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [2560/3125]  eta: 0:03:18  Lr: 0.001875  Loss: -0.5619  Acc@1: 87.5000 (86.6678)  Acc@5: 100.0000 (98.5333)  time: 0.3482  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [2570/3125]  eta: 0:03:14  Lr: 0.001875  Loss: -0.7032  Acc@1: 87.5000 (86.6783)  Acc@5: 100.0000 (98.5317)  time: 0.3460  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [2580/3125]  eta: 0:03:11  Lr: 0.001875  Loss: -0.3914  Acc@1: 87.5000 (86.6597)  Acc@5: 100.0000 (98.5301)  time: 0.3510  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [2590/3125]  eta: 0:03:07  Lr: 0.001875  Loss: -0.5590  Acc@1: 87.5000 (86.6630)  Acc@5: 100.0000 (98.5310)  time: 0.3556  data: 0.0013  max mem: 2502
Train: Epoch[4/5]  [2600/3125]  eta: 0:03:04  Lr: 0.001875  Loss: -0.2853  Acc@1: 87.5000 (86.6566)  Acc@5: 100.0000 (98.5366)  time: 0.3537  data: 0.0013  max mem: 2502
Train: Epoch[4/5]  [2610/3125]  eta: 0:03:00  Lr: 0.001875  Loss: -0.6672  Acc@1: 87.5000 (86.6622)  Acc@5: 100.0000 (98.5327)  time: 0.3524  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [2620/3125]  eta: 0:02:56  Lr: 0.001875  Loss: -0.3622  Acc@1: 87.5000 (86.6702)  Acc@5: 100.0000 (98.5359)  time: 0.3498  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [2630/3125]  eta: 0:02:53  Lr: 0.001875  Loss: -0.4516  Acc@1: 87.5000 (86.6638)  Acc@5: 100.0000 (98.5343)  time: 0.3524  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [2640/3125]  eta: 0:02:50  Lr: 0.001875  Loss: -0.8140  Acc@1: 87.5000 (86.6835)  Acc@5: 100.0000 (98.5304)  time: 0.3559  data: 0.0022  max mem: 2502
Train: Epoch[4/5]  [2650/3125]  eta: 0:02:46  Lr: 0.001875  Loss: -0.7713  Acc@1: 87.5000 (86.6748)  Acc@5: 100.0000 (98.5289)  time: 0.3536  data: 0.0022  max mem: 2502
Train: Epoch[4/5]  [2660/3125]  eta: 0:02:43  Lr: 0.001875  Loss: -0.6859  Acc@1: 87.5000 (86.6850)  Acc@5: 100.0000 (98.5344)  time: 0.3521  data: 0.0007  max mem: 2502
Train: Epoch[4/5]  [2670/3125]  eta: 0:02:39  Lr: 0.001875  Loss: -0.6703  Acc@1: 87.5000 (86.6623)  Acc@5: 100.0000 (98.5352)  time: 0.3500  data: 0.0006  max mem: 2502
Train: Epoch[4/5]  [2680/3125]  eta: 0:02:35  Lr: 0.001875  Loss: 0.1432  Acc@1: 87.5000 (86.6584)  Acc@5: 100.0000 (98.5360)  time: 0.3487  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [2690/3125]  eta: 0:02:32  Lr: 0.001875  Loss: -0.2627  Acc@1: 87.5000 (86.6685)  Acc@5: 100.0000 (98.5368)  time: 0.3498  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [2700/3125]  eta: 0:02:28  Lr: 0.001875  Loss: -0.7534  Acc@1: 87.5000 (86.6577)  Acc@5: 100.0000 (98.5330)  time: 0.3489  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [2710/3125]  eta: 0:02:25  Lr: 0.001875  Loss: -0.6068  Acc@1: 87.5000 (86.6608)  Acc@5: 100.0000 (98.5338)  time: 0.3478  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [2720/3125]  eta: 0:02:21  Lr: 0.001875  Loss: -0.2823  Acc@1: 87.5000 (86.6570)  Acc@5: 100.0000 (98.5300)  time: 0.3483  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [2730/3125]  eta: 0:02:18  Lr: 0.001875  Loss: -0.6777  Acc@1: 87.5000 (86.6807)  Acc@5: 100.0000 (98.5353)  time: 0.3477  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [2740/3125]  eta: 0:02:14  Lr: 0.001875  Loss: -0.4912  Acc@1: 93.7500 (86.6905)  Acc@5: 100.0000 (98.5384)  time: 0.3461  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [2750/3125]  eta: 0:02:11  Lr: 0.001875  Loss: -0.5876  Acc@1: 87.5000 (86.6889)  Acc@5: 100.0000 (98.5392)  time: 0.3451  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [2760/3125]  eta: 0:02:07  Lr: 0.001875  Loss: -0.1832  Acc@1: 87.5000 (86.6715)  Acc@5: 100.0000 (98.5354)  time: 0.3485  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [2770/3125]  eta: 0:02:04  Lr: 0.001875  Loss: -0.5152  Acc@1: 81.2500 (86.6700)  Acc@5: 100.0000 (98.5317)  time: 0.3504  data: 0.0008  max mem: 2502
Train: Epoch[4/5]  [2780/3125]  eta: 0:02:00  Lr: 0.001875  Loss: -0.5659  Acc@1: 87.5000 (86.6662)  Acc@5: 100.0000 (98.5257)  time: 0.3499  data: 0.0008  max mem: 2502
Train: Epoch[4/5]  [2790/3125]  eta: 0:01:57  Lr: 0.001875  Loss: -0.4303  Acc@1: 87.5000 (86.6602)  Acc@5: 100.0000 (98.5220)  time: 0.3504  data: 0.0006  max mem: 2502
Train: Epoch[4/5]  [2800/3125]  eta: 0:01:53  Lr: 0.001875  Loss: -0.4773  Acc@1: 87.5000 (86.6588)  Acc@5: 100.0000 (98.5228)  time: 0.3492  data: 0.0006  max mem: 2502
Train: Epoch[4/5]  [2810/3125]  eta: 0:01:50  Lr: 0.001875  Loss: -0.6233  Acc@1: 87.5000 (86.6707)  Acc@5: 100.0000 (98.5237)  time: 0.3516  data: 0.0006  max mem: 2502
Train: Epoch[4/5]  [2820/3125]  eta: 0:01:46  Lr: 0.001875  Loss: -0.2930  Acc@1: 87.5000 (86.6714)  Acc@5: 100.0000 (98.5222)  time: 0.3550  data: 0.0007  max mem: 2502
Train: Epoch[4/5]  [2830/3125]  eta: 0:01:43  Lr: 0.001875  Loss: -0.6399  Acc@1: 87.5000 (86.6787)  Acc@5: 100.0000 (98.5253)  time: 0.3520  data: 0.0006  max mem: 2502
Train: Epoch[4/5]  [2840/3125]  eta: 0:01:39  Lr: 0.001875  Loss: -0.3381  Acc@1: 87.5000 (86.6882)  Acc@5: 100.0000 (98.5282)  time: 0.3488  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [2850/3125]  eta: 0:01:36  Lr: 0.001875  Loss: -0.5252  Acc@1: 87.5000 (86.6889)  Acc@5: 100.0000 (98.5312)  time: 0.3512  data: 0.0009  max mem: 2502
Train: Epoch[4/5]  [2860/3125]  eta: 0:01:32  Lr: 0.001875  Loss: -0.7834  Acc@1: 87.5000 (86.6917)  Acc@5: 100.0000 (98.5364)  time: 0.3512  data: 0.0009  max mem: 2502
Train: Epoch[4/5]  [2870/3125]  eta: 0:01:29  Lr: 0.001875  Loss: -0.7538  Acc@1: 87.5000 (86.7011)  Acc@5: 100.0000 (98.5371)  time: 0.3487  data: 0.0006  max mem: 2502
Train: Epoch[4/5]  [2880/3125]  eta: 0:01:25  Lr: 0.001875  Loss: -0.2352  Acc@1: 93.7500 (86.7060)  Acc@5: 100.0000 (98.5335)  time: 0.3477  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [2890/3125]  eta: 0:01:22  Lr: 0.001875  Loss: -0.4918  Acc@1: 87.5000 (86.7174)  Acc@5: 100.0000 (98.5364)  time: 0.3474  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [2900/3125]  eta: 0:01:18  Lr: 0.001875  Loss: 0.1138  Acc@1: 87.5000 (86.7266)  Acc@5: 100.0000 (98.5350)  time: 0.3477  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [2910/3125]  eta: 0:01:15  Lr: 0.001875  Loss: -0.7814  Acc@1: 87.5000 (86.7249)  Acc@5: 100.0000 (98.5357)  time: 0.3483  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [2920/3125]  eta: 0:01:11  Lr: 0.001875  Loss: -0.8252  Acc@1: 87.5000 (86.7319)  Acc@5: 100.0000 (98.5343)  time: 0.3488  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [2930/3125]  eta: 0:01:08  Lr: 0.001875  Loss: -0.5039  Acc@1: 87.5000 (86.7281)  Acc@5: 100.0000 (98.5329)  time: 0.3473  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [2940/3125]  eta: 0:01:04  Lr: 0.001875  Loss: -0.5093  Acc@1: 87.5000 (86.7307)  Acc@5: 100.0000 (98.5358)  time: 0.3460  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [2950/3125]  eta: 0:01:01  Lr: 0.001875  Loss: -0.1819  Acc@1: 87.5000 (86.7142)  Acc@5: 100.0000 (98.5302)  time: 0.3491  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [2960/3125]  eta: 0:00:57  Lr: 0.001875  Loss: -0.7155  Acc@1: 87.5000 (86.7232)  Acc@5: 100.0000 (98.5330)  time: 0.3511  data: 0.0007  max mem: 2502
Train: Epoch[4/5]  [2970/3125]  eta: 0:00:54  Lr: 0.001875  Loss: -0.5487  Acc@1: 87.5000 (86.7364)  Acc@5: 100.0000 (98.5358)  time: 0.3501  data: 0.0007  max mem: 2502
Train: Epoch[4/5]  [2980/3125]  eta: 0:00:50  Lr: 0.001875  Loss: -0.1060  Acc@1: 81.2500 (86.7159)  Acc@5: 100.0000 (98.5366)  time: 0.3516  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [2990/3125]  eta: 0:00:47  Lr: 0.001875  Loss: -0.6463  Acc@1: 87.5000 (86.7143)  Acc@5: 100.0000 (98.5373)  time: 0.3522  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [3000/3125]  eta: 0:00:43  Lr: 0.001875  Loss: -0.6914  Acc@1: 87.5000 (86.7211)  Acc@5: 100.0000 (98.5380)  time: 0.3541  data: 0.0013  max mem: 2502
Train: Epoch[4/5]  [3010/3125]  eta: 0:00:40  Lr: 0.001875  Loss: -0.3263  Acc@1: 87.5000 (86.7237)  Acc@5: 100.0000 (98.5408)  time: 0.3535  data: 0.0017  max mem: 2502
Train: Epoch[4/5]  [3020/3125]  eta: 0:00:36  Lr: 0.001875  Loss: -0.8645  Acc@1: 87.5000 (86.7242)  Acc@5: 100.0000 (98.5435)  time: 0.3505  data: 0.0009  max mem: 2502
Train: Epoch[4/5]  [3030/3125]  eta: 0:00:33  Lr: 0.001875  Loss: -0.6683  Acc@1: 87.5000 (86.7267)  Acc@5: 100.0000 (98.5421)  time: 0.3516  data: 0.0006  max mem: 2502
Train: Epoch[4/5]  [3040/3125]  eta: 0:00:29  Lr: 0.001875  Loss: -0.5547  Acc@1: 87.5000 (86.7211)  Acc@5: 100.0000 (98.5387)  time: 0.3554  data: 0.0006  max mem: 2502
Train: Epoch[4/5]  [3050/3125]  eta: 0:00:26  Lr: 0.001875  Loss: -0.5397  Acc@1: 87.5000 (86.7277)  Acc@5: 100.0000 (98.5394)  time: 0.3537  data: 0.0006  max mem: 2502
Train: Epoch[4/5]  [3060/3125]  eta: 0:00:22  Lr: 0.001875  Loss: -0.2968  Acc@1: 87.5000 (86.7221)  Acc@5: 100.0000 (98.5442)  time: 0.3483  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [3070/3125]  eta: 0:00:19  Lr: 0.001875  Loss: -0.4297  Acc@1: 87.5000 (86.7246)  Acc@5: 100.0000 (98.5449)  time: 0.3486  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [3080/3125]  eta: 0:00:15  Lr: 0.001875  Loss: -0.7429  Acc@1: 87.5000 (86.7332)  Acc@5: 100.0000 (98.5455)  time: 0.3495  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [3090/3125]  eta: 0:00:12  Lr: 0.001875  Loss: -0.4824  Acc@1: 93.7500 (86.7478)  Acc@5: 100.0000 (98.5442)  time: 0.3509  data: 0.0007  max mem: 2502
Train: Epoch[4/5]  [3100/3125]  eta: 0:00:08  Lr: 0.001875  Loss: -0.6265  Acc@1: 87.5000 (86.7361)  Acc@5: 100.0000 (98.5448)  time: 0.3500  data: 0.0007  max mem: 2502
Train: Epoch[4/5]  [3110/3125]  eta: 0:00:05  Lr: 0.001875  Loss: -0.4066  Acc@1: 87.5000 (86.7466)  Acc@5: 100.0000 (98.5475)  time: 0.3472  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [3120/3125]  eta: 0:00:01  Lr: 0.001875  Loss: -0.6026  Acc@1: 87.5000 (86.7530)  Acc@5: 100.0000 (98.5441)  time: 0.3471  data: 0.0006  max mem: 2502
Train: Epoch[4/5]  [3124/3125]  eta: 0:00:00  Lr: 0.001875  Loss: -0.7052  Acc@1: 87.5000 (86.7540)  Acc@5: 100.0000 (98.5460)  time: 0.3475  data: 0.0006  max mem: 2502
Train: Epoch[4/5] Total time: 0:18:15 (0.3506 s / it)
{0: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 1: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 2: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 3: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 4: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 5: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 6: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 7: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 8: {0: 0, 1: 0, 2: 200000, 3: 0, 4: 0}, 9: {0: 0, 1: 0, 2: 200000, 3: 0, 4: 0}, 10: {0: 0, 1: 0, 2: 200000, 3: 0, 4: 0}, 11: {0: 0, 1: 0, 2: 200000, 3: 0, 4: 0}, 12: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 13: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 14: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 15: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 16: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 17: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 18: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 19: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}}
Averaged stats: Lr: 0.001875  Loss: -0.7052  Acc@1: 87.5000 (86.7540)  Acc@5: 100.0000 (98.5460)
Train: Epoch[5/5]  [   0/3125]  eta: 0:38:58  Lr: 0.001875  Loss: -0.3251  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (100.0000)  time: 0.7483  data: 0.3975  max mem: 2502
Train: Epoch[5/5]  [  10/3125]  eta: 0:19:54  Lr: 0.001875  Loss: -0.0379  Acc@1: 87.5000 (83.5227)  Acc@5: 100.0000 (97.1591)  time: 0.3835  data: 0.0364  max mem: 2502
Train: Epoch[5/5]  [  20/3125]  eta: 0:18:55  Lr: 0.001875  Loss: -0.3998  Acc@1: 87.5000 (86.9048)  Acc@5: 100.0000 (97.6190)  time: 0.3467  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [  30/3125]  eta: 0:18:35  Lr: 0.001875  Loss: -0.7273  Acc@1: 87.5000 (88.3065)  Acc@5: 100.0000 (98.3871)  time: 0.3476  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [  40/3125]  eta: 0:18:27  Lr: 0.001875  Loss: -0.6939  Acc@1: 87.5000 (88.1098)  Acc@5: 100.0000 (98.4756)  time: 0.3516  data: 0.0012  max mem: 2502
Train: Epoch[5/5]  [  50/3125]  eta: 0:18:18  Lr: 0.001875  Loss: -0.4457  Acc@1: 93.7500 (88.2353)  Acc@5: 100.0000 (98.5294)  time: 0.3528  data: 0.0013  max mem: 2502
Train: Epoch[5/5]  [  60/3125]  eta: 0:18:14  Lr: 0.001875  Loss: -0.9106  Acc@1: 87.5000 (88.2172)  Acc@5: 100.0000 (98.5656)  time: 0.3537  data: 0.0006  max mem: 2502
Train: Epoch[5/5]  [  70/3125]  eta: 0:18:08  Lr: 0.001875  Loss: -0.3312  Acc@1: 87.5000 (88.6444)  Acc@5: 100.0000 (98.7676)  time: 0.3537  data: 0.0006  max mem: 2502
Train: Epoch[5/5]  [  80/3125]  eta: 0:18:04  Lr: 0.001875  Loss: -0.7846  Acc@1: 87.5000 (88.1173)  Acc@5: 100.0000 (98.5340)  time: 0.3532  data: 0.0007  max mem: 2502
Train: Epoch[5/5]  [  90/3125]  eta: 0:18:00  Lr: 0.001875  Loss: -0.6621  Acc@1: 87.5000 (88.1868)  Acc@5: 100.0000 (98.6951)  time: 0.3549  data: 0.0007  max mem: 2502
Train: Epoch[5/5]  [ 100/3125]  eta: 0:17:56  Lr: 0.001875  Loss: -0.7159  Acc@1: 87.5000 (88.6757)  Acc@5: 100.0000 (98.8243)  time: 0.3548  data: 0.0006  max mem: 2502
Train: Epoch[5/5]  [ 110/3125]  eta: 0:17:51  Lr: 0.001875  Loss: -0.7996  Acc@1: 93.7500 (88.9640)  Acc@5: 100.0000 (98.8176)  time: 0.3527  data: 0.0006  max mem: 2502
Train: Epoch[5/5]  [ 120/3125]  eta: 0:17:46  Lr: 0.001875  Loss: -0.6350  Acc@1: 87.5000 (88.7913)  Acc@5: 100.0000 (98.8636)  time: 0.3489  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [ 130/3125]  eta: 0:17:41  Lr: 0.001875  Loss: -0.8216  Acc@1: 87.5000 (88.8836)  Acc@5: 100.0000 (98.9027)  time: 0.3483  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [ 140/3125]  eta: 0:17:36  Lr: 0.001875  Loss: 0.0619  Acc@1: 87.5000 (88.6525)  Acc@5: 100.0000 (98.8475)  time: 0.3494  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [ 150/3125]  eta: 0:17:32  Lr: 0.001875  Loss: -0.4722  Acc@1: 87.5000 (88.4934)  Acc@5: 100.0000 (98.7997)  time: 0.3492  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [ 160/3125]  eta: 0:17:27  Lr: 0.001875  Loss: -0.8019  Acc@1: 87.5000 (88.3929)  Acc@5: 100.0000 (98.7578)  time: 0.3492  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [ 170/3125]  eta: 0:17:23  Lr: 0.001875  Loss: -0.5745  Acc@1: 87.5000 (88.4503)  Acc@5: 100.0000 (98.7939)  time: 0.3482  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [ 180/3125]  eta: 0:17:19  Lr: 0.001875  Loss: -0.6654  Acc@1: 87.5000 (88.1215)  Acc@5: 100.0000 (98.7224)  time: 0.3485  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [ 190/3125]  eta: 0:17:15  Lr: 0.001875  Loss: -0.5811  Acc@1: 87.5000 (88.1872)  Acc@5: 100.0000 (98.7238)  time: 0.3495  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [ 200/3125]  eta: 0:17:10  Lr: 0.001875  Loss: -0.5800  Acc@1: 87.5000 (88.1530)  Acc@5: 100.0000 (98.6940)  time: 0.3484  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [ 210/3125]  eta: 0:17:06  Lr: 0.001875  Loss: -0.5890  Acc@1: 87.5000 (87.9739)  Acc@5: 100.0000 (98.6671)  time: 0.3484  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [ 220/3125]  eta: 0:17:05  Lr: 0.001875  Loss: -0.8146  Acc@1: 87.5000 (87.9525)  Acc@5: 100.0000 (98.6991)  time: 0.3588  data: 0.0007  max mem: 2502
Train: Epoch[5/5]  [ 230/3125]  eta: 0:17:01  Lr: 0.001875  Loss: -0.5191  Acc@1: 87.5000 (87.6353)  Acc@5: 100.0000 (98.7013)  time: 0.3598  data: 0.0007  max mem: 2502
Train: Epoch[5/5]  [ 240/3125]  eta: 0:16:57  Lr: 0.001875  Loss: -0.5030  Acc@1: 87.5000 (87.6815)  Acc@5: 100.0000 (98.7293)  time: 0.3510  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [ 250/3125]  eta: 0:16:54  Lr: 0.001875  Loss: -0.6390  Acc@1: 87.5000 (87.7490)  Acc@5: 100.0000 (98.7550)  time: 0.3515  data: 0.0006  max mem: 2502
Train: Epoch[5/5]  [ 260/3125]  eta: 0:16:51  Lr: 0.001875  Loss: -0.5698  Acc@1: 87.5000 (87.7634)  Acc@5: 100.0000 (98.7787)  time: 0.3549  data: 0.0007  max mem: 2502
Train: Epoch[5/5]  [ 270/3125]  eta: 0:16:48  Lr: 0.001875  Loss: 0.1038  Acc@1: 87.5000 (87.8921)  Acc@5: 100.0000 (98.7315)  time: 0.3580  data: 0.0025  max mem: 2502
Train: Epoch[5/5]  [ 280/3125]  eta: 0:16:44  Lr: 0.001875  Loss: -0.4312  Acc@1: 93.7500 (87.8559)  Acc@5: 100.0000 (98.6877)  time: 0.3539  data: 0.0026  max mem: 2502
Train: Epoch[5/5]  [ 290/3125]  eta: 0:16:40  Lr: 0.001875  Loss: -0.3595  Acc@1: 93.7500 (87.8436)  Acc@5: 100.0000 (98.6899)  time: 0.3490  data: 0.0008  max mem: 2502
Train: Epoch[5/5]  [ 300/3125]  eta: 0:16:36  Lr: 0.001875  Loss: -0.6432  Acc@1: 87.5000 (87.8115)  Acc@5: 100.0000 (98.6296)  time: 0.3488  data: 0.0007  max mem: 2502
Train: Epoch[5/5]  [ 310/3125]  eta: 0:16:32  Lr: 0.001875  Loss: -0.2768  Acc@1: 87.5000 (87.8014)  Acc@5: 100.0000 (98.6334)  time: 0.3501  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [ 320/3125]  eta: 0:16:28  Lr: 0.001875  Loss: -0.8343  Acc@1: 87.5000 (87.7531)  Acc@5: 100.0000 (98.5981)  time: 0.3497  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [ 330/3125]  eta: 0:16:25  Lr: 0.001875  Loss: -0.0504  Acc@1: 87.5000 (87.5944)  Acc@5: 100.0000 (98.5838)  time: 0.3501  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [ 340/3125]  eta: 0:16:21  Lr: 0.001875  Loss: -0.8763  Acc@1: 87.5000 (87.6833)  Acc@5: 100.0000 (98.5704)  time: 0.3503  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [ 350/3125]  eta: 0:16:17  Lr: 0.001875  Loss: -0.7019  Acc@1: 87.5000 (87.5890)  Acc@5: 100.0000 (98.5399)  time: 0.3492  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [ 360/3125]  eta: 0:16:13  Lr: 0.001875  Loss: -0.3616  Acc@1: 87.5000 (87.4481)  Acc@5: 100.0000 (98.5111)  time: 0.3490  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [ 370/3125]  eta: 0:16:09  Lr: 0.001875  Loss: -0.6092  Acc@1: 87.5000 (87.3315)  Acc@5: 100.0000 (98.5175)  time: 0.3470  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [ 380/3125]  eta: 0:16:06  Lr: 0.001875  Loss: -0.3179  Acc@1: 87.5000 (87.2867)  Acc@5: 100.0000 (98.5236)  time: 0.3462  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [ 390/3125]  eta: 0:16:02  Lr: 0.001875  Loss: -0.7421  Acc@1: 87.5000 (87.3402)  Acc@5: 100.0000 (98.5294)  time: 0.3513  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [ 400/3125]  eta: 0:15:58  Lr: 0.001875  Loss: -0.3481  Acc@1: 87.5000 (87.4221)  Acc@5: 100.0000 (98.5505)  time: 0.3512  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [ 410/3125]  eta: 0:15:55  Lr: 0.001875  Loss: -0.8134  Acc@1: 87.5000 (87.4392)  Acc@5: 100.0000 (98.5858)  time: 0.3472  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [ 420/3125]  eta: 0:15:51  Lr: 0.001875  Loss: -0.3450  Acc@1: 87.5000 (87.4555)  Acc@5: 100.0000 (98.5748)  time: 0.3499  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [ 430/3125]  eta: 0:15:48  Lr: 0.001875  Loss: -0.4356  Acc@1: 87.5000 (87.4565)  Acc@5: 100.0000 (98.5499)  time: 0.3532  data: 0.0006  max mem: 2502
Train: Epoch[5/5]  [ 440/3125]  eta: 0:15:44  Lr: 0.001875  Loss: -0.6711  Acc@1: 87.5000 (87.4575)  Acc@5: 100.0000 (98.5544)  time: 0.3549  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [ 450/3125]  eta: 0:15:41  Lr: 0.001875  Loss: -0.4993  Acc@1: 87.5000 (87.4307)  Acc@5: 100.0000 (98.5310)  time: 0.3538  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [ 460/3125]  eta: 0:15:37  Lr: 0.001875  Loss: -0.8308  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (98.5629)  time: 0.3525  data: 0.0006  max mem: 2502
Train: Epoch[5/5]  [ 470/3125]  eta: 0:15:34  Lr: 0.001875  Loss: -0.5781  Acc@1: 87.5000 (87.5265)  Acc@5: 100.0000 (98.5801)  time: 0.3502  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [ 480/3125]  eta: 0:15:31  Lr: 0.001875  Loss: -0.7938  Acc@1: 81.2500 (87.4350)  Acc@5: 100.0000 (98.5577)  time: 0.3534  data: 0.0024  max mem: 2502
Train: Epoch[5/5]  [ 490/3125]  eta: 0:15:27  Lr: 0.001875  Loss: -0.2467  Acc@1: 87.5000 (87.4618)  Acc@5: 100.0000 (98.5234)  time: 0.3544  data: 0.0028  max mem: 2502
Train: Epoch[5/5]  [ 500/3125]  eta: 0:15:23  Lr: 0.001875  Loss: -0.4715  Acc@1: 87.5000 (87.4626)  Acc@5: 100.0000 (98.5155)  time: 0.3502  data: 0.0008  max mem: 2502
Train: Epoch[5/5]  [ 510/3125]  eta: 0:15:20  Lr: 0.001875  Loss: -0.5054  Acc@1: 81.2500 (87.3777)  Acc@5: 100.0000 (98.5323)  time: 0.3489  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [ 520/3125]  eta: 0:15:16  Lr: 0.001875  Loss: -0.7823  Acc@1: 81.2500 (87.3440)  Acc@5: 100.0000 (98.5125)  time: 0.3486  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [ 530/3125]  eta: 0:15:13  Lr: 0.001875  Loss: -0.5098  Acc@1: 87.5000 (87.3234)  Acc@5: 100.0000 (98.5287)  time: 0.3511  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [ 540/3125]  eta: 0:15:09  Lr: 0.001875  Loss: -0.7528  Acc@1: 87.5000 (87.4307)  Acc@5: 100.0000 (98.5328)  time: 0.3504  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [ 550/3125]  eta: 0:15:05  Lr: 0.001875  Loss: -0.3092  Acc@1: 87.5000 (87.3866)  Acc@5: 100.0000 (98.5368)  time: 0.3469  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [ 560/3125]  eta: 0:15:01  Lr: 0.001875  Loss: -0.4517  Acc@1: 81.2500 (87.3329)  Acc@5: 100.0000 (98.5517)  time: 0.3459  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [ 570/3125]  eta: 0:14:58  Lr: 0.001875  Loss: -0.4541  Acc@1: 87.5000 (87.3468)  Acc@5: 100.0000 (98.5552)  time: 0.3468  data: 0.0008  max mem: 2502
Train: Epoch[5/5]  [ 580/3125]  eta: 0:14:54  Lr: 0.001875  Loss: -0.5028  Acc@1: 87.5000 (87.4032)  Acc@5: 100.0000 (98.5370)  time: 0.3458  data: 0.0007  max mem: 2502
Train: Epoch[5/5]  [ 590/3125]  eta: 0:14:50  Lr: 0.001875  Loss: -0.2668  Acc@1: 87.5000 (87.3096)  Acc@5: 100.0000 (98.5195)  time: 0.3461  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [ 600/3125]  eta: 0:14:47  Lr: 0.001875  Loss: -0.6074  Acc@1: 87.5000 (87.3856)  Acc@5: 100.0000 (98.5441)  time: 0.3520  data: 0.0009  max mem: 2502
Train: Epoch[5/5]  [ 610/3125]  eta: 0:14:43  Lr: 0.001875  Loss: -0.8757  Acc@1: 87.5000 (87.3773)  Acc@5: 100.0000 (98.5577)  time: 0.3564  data: 0.0014  max mem: 2502
Train: Epoch[5/5]  [ 620/3125]  eta: 0:14:40  Lr: 0.001875  Loss: -0.3768  Acc@1: 81.2500 (87.3088)  Acc@5: 100.0000 (98.5608)  time: 0.3531  data: 0.0010  max mem: 2502
Train: Epoch[5/5]  [ 630/3125]  eta: 0:14:36  Lr: 0.001875  Loss: -0.3968  Acc@1: 87.5000 (87.2821)  Acc@5: 100.0000 (98.5539)  time: 0.3502  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [ 640/3125]  eta: 0:14:33  Lr: 0.001875  Loss: -0.5194  Acc@1: 87.5000 (87.2757)  Acc@5: 100.0000 (98.5667)  time: 0.3514  data: 0.0006  max mem: 2502
Train: Epoch[5/5]  [ 650/3125]  eta: 0:14:30  Lr: 0.001875  Loss: -0.4162  Acc@1: 87.5000 (87.2600)  Acc@5: 100.0000 (98.5599)  time: 0.3550  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [ 660/3125]  eta: 0:14:26  Lr: 0.001875  Loss: -0.6372  Acc@1: 87.5000 (87.2825)  Acc@5: 100.0000 (98.5628)  time: 0.3544  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [ 670/3125]  eta: 0:14:23  Lr: 0.001875  Loss: -0.4930  Acc@1: 87.5000 (87.2485)  Acc@5: 100.0000 (98.5656)  time: 0.3515  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [ 680/3125]  eta: 0:14:19  Lr: 0.001875  Loss: -0.4090  Acc@1: 87.5000 (87.2430)  Acc@5: 100.0000 (98.5683)  time: 0.3541  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [ 690/3125]  eta: 0:14:15  Lr: 0.001875  Loss: -0.7509  Acc@1: 87.5000 (87.2648)  Acc@5: 100.0000 (98.5800)  time: 0.3515  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [ 700/3125]  eta: 0:14:12  Lr: 0.001875  Loss: -0.7022  Acc@1: 87.5000 (87.2593)  Acc@5: 100.0000 (98.5735)  time: 0.3526  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [ 710/3125]  eta: 0:14:09  Lr: 0.001875  Loss: -0.8173  Acc@1: 87.5000 (87.2187)  Acc@5: 100.0000 (98.5672)  time: 0.3531  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [ 720/3125]  eta: 0:14:05  Lr: 0.001875  Loss: -0.2966  Acc@1: 81.2500 (87.1793)  Acc@5: 100.0000 (98.5784)  time: 0.3483  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [ 730/3125]  eta: 0:14:01  Lr: 0.001875  Loss: -0.4744  Acc@1: 87.5000 (87.1751)  Acc@5: 100.0000 (98.5722)  time: 0.3476  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [ 740/3125]  eta: 0:13:58  Lr: 0.001875  Loss: -0.5215  Acc@1: 87.5000 (87.1542)  Acc@5: 100.0000 (98.5577)  time: 0.3475  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [ 750/3125]  eta: 0:13:54  Lr: 0.001875  Loss: -0.6145  Acc@1: 87.5000 (87.1255)  Acc@5: 100.0000 (98.5603)  time: 0.3474  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [ 760/3125]  eta: 0:13:50  Lr: 0.001875  Loss: -0.6587  Acc@1: 87.5000 (87.1386)  Acc@5: 100.0000 (98.5545)  time: 0.3461  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [ 770/3125]  eta: 0:13:47  Lr: 0.001875  Loss: -0.7678  Acc@1: 87.5000 (87.1028)  Acc@5: 100.0000 (98.5571)  time: 0.3476  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [ 780/3125]  eta: 0:13:43  Lr: 0.001875  Loss: -0.4694  Acc@1: 87.5000 (87.1799)  Acc@5: 100.0000 (98.5675)  time: 0.3521  data: 0.0011  max mem: 2502
Train: Epoch[5/5]  [ 790/3125]  eta: 0:13:40  Lr: 0.001875  Loss: -0.3753  Acc@1: 93.7500 (87.2314)  Acc@5: 100.0000 (98.5777)  time: 0.3537  data: 0.0012  max mem: 2502
Train: Epoch[5/5]  [ 800/3125]  eta: 0:13:36  Lr: 0.001875  Loss: -0.5076  Acc@1: 87.5000 (87.2347)  Acc@5: 100.0000 (98.5799)  time: 0.3511  data: 0.0007  max mem: 2502
Train: Epoch[5/5]  [ 810/3125]  eta: 0:13:33  Lr: 0.001875  Loss: -0.5343  Acc@1: 87.5000 (87.2303)  Acc@5: 100.0000 (98.5974)  time: 0.3513  data: 0.0006  max mem: 2502
Train: Epoch[5/5]  [ 820/3125]  eta: 0:13:29  Lr: 0.001875  Loss: -0.5608  Acc@1: 87.5000 (87.2336)  Acc@5: 100.0000 (98.5764)  time: 0.3542  data: 0.0010  max mem: 2502
Train: Epoch[5/5]  [ 830/3125]  eta: 0:13:26  Lr: 0.001875  Loss: -0.7064  Acc@1: 87.5000 (87.2368)  Acc@5: 93.7500 (98.5560)  time: 0.3578  data: 0.0010  max mem: 2502
Train: Epoch[5/5]  [ 840/3125]  eta: 0:13:23  Lr: 0.001875  Loss: -0.5141  Acc@1: 87.5000 (87.2548)  Acc@5: 100.0000 (98.5583)  time: 0.3552  data: 0.0006  max mem: 2502
Train: Epoch[5/5]  [ 850/3125]  eta: 0:13:19  Lr: 0.001875  Loss: -0.4420  Acc@1: 93.7500 (87.3017)  Acc@5: 100.0000 (98.5679)  time: 0.3500  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [ 860/3125]  eta: 0:13:15  Lr: 0.001875  Loss: -0.5516  Acc@1: 93.7500 (87.3258)  Acc@5: 100.0000 (98.5772)  time: 0.3496  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [ 870/3125]  eta: 0:13:12  Lr: 0.001875  Loss: -0.5959  Acc@1: 87.5000 (87.3421)  Acc@5: 100.0000 (98.5792)  time: 0.3489  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [ 880/3125]  eta: 0:13:08  Lr: 0.001875  Loss: -0.7874  Acc@1: 87.5000 (87.2659)  Acc@5: 100.0000 (98.5457)  time: 0.3495  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [ 890/3125]  eta: 0:13:05  Lr: 0.001875  Loss: -0.4914  Acc@1: 87.5000 (87.2755)  Acc@5: 100.0000 (98.5480)  time: 0.3489  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [ 900/3125]  eta: 0:13:01  Lr: 0.001875  Loss: -0.6209  Acc@1: 87.5000 (87.2433)  Acc@5: 100.0000 (98.5433)  time: 0.3483  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [ 910/3125]  eta: 0:12:58  Lr: 0.001875  Loss: -0.7138  Acc@1: 87.5000 (87.2393)  Acc@5: 100.0000 (98.5318)  time: 0.3486  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [ 920/3125]  eta: 0:12:54  Lr: 0.001875  Loss: -0.7314  Acc@1: 87.5000 (87.2218)  Acc@5: 100.0000 (98.5342)  time: 0.3497  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [ 930/3125]  eta: 0:12:50  Lr: 0.001875  Loss: -0.7660  Acc@1: 87.5000 (87.2449)  Acc@5: 100.0000 (98.5432)  time: 0.3488  data: 0.0009  max mem: 2502
Train: Epoch[5/5]  [ 940/3125]  eta: 0:12:47  Lr: 0.001875  Loss: -0.6448  Acc@1: 87.5000 (87.2609)  Acc@5: 100.0000 (98.5388)  time: 0.3456  data: 0.0009  max mem: 2502
Train: Epoch[5/5]  [ 950/3125]  eta: 0:12:43  Lr: 0.001875  Loss: -0.8532  Acc@1: 87.5000 (87.2437)  Acc@5: 100.0000 (98.5344)  time: 0.3496  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [ 960/3125]  eta: 0:12:40  Lr: 0.001875  Loss: -0.5019  Acc@1: 87.5000 (87.2789)  Acc@5: 100.0000 (98.5497)  time: 0.3542  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [ 970/3125]  eta: 0:12:36  Lr: 0.001875  Loss: -0.6135  Acc@1: 87.5000 (87.3005)  Acc@5: 100.0000 (98.5582)  time: 0.3536  data: 0.0019  max mem: 2502
Train: Epoch[5/5]  [ 980/3125]  eta: 0:12:33  Lr: 0.001875  Loss: -0.4769  Acc@1: 87.5000 (87.3025)  Acc@5: 100.0000 (98.5538)  time: 0.3502  data: 0.0020  max mem: 2502
Train: Epoch[5/5]  [ 990/3125]  eta: 0:12:29  Lr: 0.001875  Loss: -0.3514  Acc@1: 87.5000 (87.3171)  Acc@5: 100.0000 (98.5558)  time: 0.3481  data: 0.0006  max mem: 2502
Train: Epoch[5/5]  [1000/3125]  eta: 0:12:26  Lr: 0.001875  Loss: -0.7137  Acc@1: 87.5000 (87.3439)  Acc@5: 100.0000 (98.5639)  time: 0.3550  data: 0.0019  max mem: 2502
Train: Epoch[5/5]  [1010/3125]  eta: 0:12:22  Lr: 0.001875  Loss: -0.7981  Acc@1: 87.5000 (87.3269)  Acc@5: 100.0000 (98.5472)  time: 0.3557  data: 0.0024  max mem: 2502
Train: Epoch[5/5]  [1020/3125]  eta: 0:12:19  Lr: 0.001875  Loss: -0.5032  Acc@1: 87.5000 (87.3102)  Acc@5: 100.0000 (98.5370)  time: 0.3500  data: 0.0009  max mem: 2502
Train: Epoch[5/5]  [1030/3125]  eta: 0:12:15  Lr: 0.001875  Loss: -0.8189  Acc@1: 87.5000 (87.3303)  Acc@5: 100.0000 (98.5269)  time: 0.3513  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [1040/3125]  eta: 0:12:12  Lr: 0.001875  Loss: -0.4987  Acc@1: 87.5000 (87.2959)  Acc@5: 100.0000 (98.5110)  time: 0.3522  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [1050/3125]  eta: 0:12:08  Lr: 0.001875  Loss: -0.4355  Acc@1: 87.5000 (87.3335)  Acc@5: 100.0000 (98.5133)  time: 0.3536  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [1060/3125]  eta: 0:12:05  Lr: 0.001875  Loss: -0.4899  Acc@1: 87.5000 (87.3115)  Acc@5: 100.0000 (98.5156)  time: 0.3520  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [1070/3125]  eta: 0:12:01  Lr: 0.001875  Loss: -0.5212  Acc@1: 81.2500 (87.2899)  Acc@5: 100.0000 (98.5294)  time: 0.3478  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [1080/3125]  eta: 0:11:58  Lr: 0.001875  Loss: -0.5989  Acc@1: 87.5000 (87.2745)  Acc@5: 100.0000 (98.5372)  time: 0.3486  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [1090/3125]  eta: 0:11:54  Lr: 0.001875  Loss: -0.3829  Acc@1: 87.5000 (87.2766)  Acc@5: 100.0000 (98.5506)  time: 0.3506  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [1100/3125]  eta: 0:11:51  Lr: 0.001875  Loss: -0.7271  Acc@1: 87.5000 (87.3013)  Acc@5: 100.0000 (98.5581)  time: 0.3513  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [1110/3125]  eta: 0:11:47  Lr: 0.001875  Loss: -0.4992  Acc@1: 87.5000 (87.2975)  Acc@5: 100.0000 (98.5374)  time: 0.3483  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [1120/3125]  eta: 0:11:44  Lr: 0.001875  Loss: -0.5907  Acc@1: 87.5000 (87.3160)  Acc@5: 100.0000 (98.5448)  time: 0.3454  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [1130/3125]  eta: 0:11:40  Lr: 0.001875  Loss: -0.8500  Acc@1: 87.5000 (87.3121)  Acc@5: 100.0000 (98.5411)  time: 0.3496  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [1140/3125]  eta: 0:11:36  Lr: 0.001875  Loss: -0.3258  Acc@1: 87.5000 (87.2864)  Acc@5: 100.0000 (98.5265)  time: 0.3500  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [1150/3125]  eta: 0:11:33  Lr: 0.001875  Loss: -0.6069  Acc@1: 87.5000 (87.2774)  Acc@5: 100.0000 (98.5285)  time: 0.3475  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [1160/3125]  eta: 0:11:29  Lr: 0.001875  Loss: -0.8294  Acc@1: 87.5000 (87.2901)  Acc@5: 100.0000 (98.5357)  time: 0.3478  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [1170/3125]  eta: 0:11:26  Lr: 0.001875  Loss: -0.5225  Acc@1: 87.5000 (87.3345)  Acc@5: 100.0000 (98.5429)  time: 0.3533  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [1180/3125]  eta: 0:11:22  Lr: 0.001875  Loss: -0.5564  Acc@1: 87.5000 (87.3148)  Acc@5: 100.0000 (98.5235)  time: 0.3566  data: 0.0007  max mem: 2502
Train: Epoch[5/5]  [1190/3125]  eta: 0:11:19  Lr: 0.001875  Loss: -0.2909  Acc@1: 87.5000 (87.3111)  Acc@5: 100.0000 (98.5202)  time: 0.3517  data: 0.0007  max mem: 2502
Train: Epoch[5/5]  [1200/3125]  eta: 0:11:15  Lr: 0.001875  Loss: -0.5403  Acc@1: 87.5000 (87.3179)  Acc@5: 100.0000 (98.5169)  time: 0.3502  data: 0.0006  max mem: 2502
Train: Epoch[5/5]  [1210/3125]  eta: 0:11:12  Lr: 0.001875  Loss: -0.5310  Acc@1: 87.5000 (87.3245)  Acc@5: 100.0000 (98.5239)  time: 0.3501  data: 0.0007  max mem: 2502
Train: Epoch[5/5]  [1220/3125]  eta: 0:11:08  Lr: 0.001875  Loss: -0.5184  Acc@1: 81.2500 (87.3055)  Acc@5: 100.0000 (98.5258)  time: 0.3505  data: 0.0007  max mem: 2502
Train: Epoch[5/5]  [1230/3125]  eta: 0:11:05  Lr: 0.001875  Loss: -0.8677  Acc@1: 81.2500 (87.3071)  Acc@5: 100.0000 (98.5276)  time: 0.3540  data: 0.0011  max mem: 2502
Train: Epoch[5/5]  [1240/3125]  eta: 0:11:02  Lr: 0.001875  Loss: -0.4285  Acc@1: 81.2500 (87.2683)  Acc@5: 100.0000 (98.5143)  time: 0.3575  data: 0.0011  max mem: 2502
Train: Epoch[5/5]  [1250/3125]  eta: 0:10:58  Lr: 0.001875  Loss: -0.4382  Acc@1: 81.2500 (87.1803)  Acc@5: 100.0000 (98.5062)  time: 0.3525  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [1260/3125]  eta: 0:10:54  Lr: 0.001875  Loss: -0.5537  Acc@1: 87.5000 (87.2125)  Acc@5: 100.0000 (98.5180)  time: 0.3492  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [1270/3125]  eta: 0:10:51  Lr: 0.001875  Loss: -0.3732  Acc@1: 87.5000 (87.1951)  Acc@5: 100.0000 (98.5100)  time: 0.3511  data: 0.0011  max mem: 2502
Train: Epoch[5/5]  [1280/3125]  eta: 0:10:47  Lr: 0.001875  Loss: -0.3608  Acc@1: 87.5000 (87.2024)  Acc@5: 100.0000 (98.5119)  time: 0.3494  data: 0.0011  max mem: 2502
Train: Epoch[5/5]  [1290/3125]  eta: 0:10:44  Lr: 0.001875  Loss: -0.6672  Acc@1: 93.7500 (87.2192)  Acc@5: 100.0000 (98.5186)  time: 0.3474  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [1300/3125]  eta: 0:10:40  Lr: 0.001875  Loss: -0.4645  Acc@1: 87.5000 (87.2118)  Acc@5: 100.0000 (98.5252)  time: 0.3460  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [1310/3125]  eta: 0:10:37  Lr: 0.001875  Loss: -0.5154  Acc@1: 87.5000 (87.1997)  Acc@5: 100.0000 (98.5317)  time: 0.3491  data: 0.0029  max mem: 2502
Train: Epoch[5/5]  [1320/3125]  eta: 0:10:33  Lr: 0.001875  Loss: -0.5620  Acc@1: 87.5000 (87.1972)  Acc@5: 100.0000 (98.5286)  time: 0.3495  data: 0.0030  max mem: 2502
Train: Epoch[5/5]  [1330/3125]  eta: 0:10:30  Lr: 0.001875  Loss: -0.3040  Acc@1: 87.5000 (87.2042)  Acc@5: 100.0000 (98.5349)  time: 0.3459  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [1340/3125]  eta: 0:10:26  Lr: 0.001875  Loss: -0.7760  Acc@1: 93.7500 (87.2110)  Acc@5: 100.0000 (98.5412)  time: 0.3471  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [1350/3125]  eta: 0:10:23  Lr: 0.001875  Loss: -0.5572  Acc@1: 93.7500 (87.1900)  Acc@5: 100.0000 (98.5381)  time: 0.3545  data: 0.0008  max mem: 2502
Train: Epoch[5/5]  [1360/3125]  eta: 0:10:19  Lr: 0.001875  Loss: -0.5299  Acc@1: 87.5000 (87.1923)  Acc@5: 100.0000 (98.5351)  time: 0.3552  data: 0.0007  max mem: 2502
Train: Epoch[5/5]  [1370/3125]  eta: 0:10:16  Lr: 0.001875  Loss: -0.5199  Acc@1: 87.5000 (87.1946)  Acc@5: 100.0000 (98.5412)  time: 0.3509  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [1380/3125]  eta: 0:10:12  Lr: 0.001875  Loss: -0.5567  Acc@1: 87.5000 (87.2058)  Acc@5: 100.0000 (98.5472)  time: 0.3511  data: 0.0006  max mem: 2502
Train: Epoch[5/5]  [1390/3125]  eta: 0:10:09  Lr: 0.001875  Loss: -0.6458  Acc@1: 87.5000 (87.2169)  Acc@5: 100.0000 (98.5577)  time: 0.3522  data: 0.0006  max mem: 2502
Train: Epoch[5/5]  [1400/3125]  eta: 0:10:05  Lr: 0.001875  Loss: -0.5132  Acc@1: 87.5000 (87.2100)  Acc@5: 100.0000 (98.5635)  time: 0.3548  data: 0.0013  max mem: 2502
Train: Epoch[5/5]  [1410/3125]  eta: 0:10:02  Lr: 0.001875  Loss: -0.6683  Acc@1: 87.5000 (87.2121)  Acc@5: 100.0000 (98.5737)  time: 0.3524  data: 0.0012  max mem: 2502
Train: Epoch[5/5]  [1420/3125]  eta: 0:09:58  Lr: 0.001875  Loss: -0.7667  Acc@1: 87.5000 (87.2053)  Acc@5: 100.0000 (98.5705)  time: 0.3509  data: 0.0007  max mem: 2502
Train: Epoch[5/5]  [1430/3125]  eta: 0:09:55  Lr: 0.001875  Loss: -0.3888  Acc@1: 87.5000 (87.2074)  Acc@5: 100.0000 (98.5631)  time: 0.3505  data: 0.0006  max mem: 2502
Train: Epoch[5/5]  [1440/3125]  eta: 0:09:51  Lr: 0.001875  Loss: -0.7763  Acc@1: 87.5000 (87.2181)  Acc@5: 100.0000 (98.5600)  time: 0.3497  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [1450/3125]  eta: 0:09:48  Lr: 0.001875  Loss: -0.7373  Acc@1: 87.5000 (87.2243)  Acc@5: 100.0000 (98.5613)  time: 0.3513  data: 0.0009  max mem: 2502
Train: Epoch[5/5]  [1460/3125]  eta: 0:09:44  Lr: 0.001875  Loss: -0.8805  Acc@1: 87.5000 (87.2091)  Acc@5: 100.0000 (98.5669)  time: 0.3493  data: 0.0008  max mem: 2502
Train: Epoch[5/5]  [1470/3125]  eta: 0:09:40  Lr: 0.001875  Loss: -0.5640  Acc@1: 87.5000 (87.2026)  Acc@5: 100.0000 (98.5639)  time: 0.3475  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [1480/3125]  eta: 0:09:37  Lr: 0.001875  Loss: -0.6435  Acc@1: 87.5000 (87.1751)  Acc@5: 100.0000 (98.5652)  time: 0.3472  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [1490/3125]  eta: 0:09:33  Lr: 0.001875  Loss: -0.6001  Acc@1: 87.5000 (87.1647)  Acc@5: 100.0000 (98.5706)  time: 0.3482  data: 0.0015  max mem: 2502
Train: Epoch[5/5]  [1500/3125]  eta: 0:09:30  Lr: 0.001875  Loss: -0.6514  Acc@1: 87.5000 (87.1794)  Acc@5: 100.0000 (98.5718)  time: 0.3473  data: 0.0014  max mem: 2502
Train: Epoch[5/5]  [1510/3125]  eta: 0:09:26  Lr: 0.001875  Loss: -0.4793  Acc@1: 87.5000 (87.1525)  Acc@5: 100.0000 (98.5730)  time: 0.3456  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [1520/3125]  eta: 0:09:23  Lr: 0.001875  Loss: -0.4631  Acc@1: 87.5000 (87.1548)  Acc@5: 100.0000 (98.5700)  time: 0.3486  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [1530/3125]  eta: 0:09:19  Lr: 0.001875  Loss: -0.7161  Acc@1: 81.2500 (87.1448)  Acc@5: 100.0000 (98.5794)  time: 0.3537  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [1540/3125]  eta: 0:09:16  Lr: 0.001875  Loss: -0.6825  Acc@1: 87.5000 (87.1512)  Acc@5: 100.0000 (98.5886)  time: 0.3528  data: 0.0006  max mem: 2502
Train: Epoch[5/5]  [1550/3125]  eta: 0:09:12  Lr: 0.001875  Loss: -0.4370  Acc@1: 87.5000 (87.1655)  Acc@5: 100.0000 (98.5856)  time: 0.3485  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [1560/3125]  eta: 0:09:09  Lr: 0.001875  Loss: -0.5827  Acc@1: 87.5000 (87.1357)  Acc@5: 100.0000 (98.5866)  time: 0.3569  data: 0.0006  max mem: 2502
Train: Epoch[5/5]  [1570/3125]  eta: 0:09:05  Lr: 0.001875  Loss: -0.4724  Acc@1: 81.2500 (87.1141)  Acc@5: 100.0000 (98.5837)  time: 0.3589  data: 0.0007  max mem: 2502
Train: Epoch[5/5]  [1580/3125]  eta: 0:09:02  Lr: 0.001875  Loss: -0.3582  Acc@1: 87.5000 (87.1363)  Acc@5: 100.0000 (98.5808)  time: 0.3508  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [1590/3125]  eta: 0:08:58  Lr: 0.001875  Loss: -0.2962  Acc@1: 87.5000 (87.1425)  Acc@5: 100.0000 (98.5858)  time: 0.3510  data: 0.0008  max mem: 2502
Train: Epoch[5/5]  [1600/3125]  eta: 0:08:55  Lr: 0.001875  Loss: -0.7628  Acc@1: 87.5000 (87.1369)  Acc@5: 100.0000 (98.5907)  time: 0.3515  data: 0.0010  max mem: 2502
Train: Epoch[5/5]  [1610/3125]  eta: 0:08:51  Lr: 0.001875  Loss: -0.7763  Acc@1: 87.5000 (87.1547)  Acc@5: 100.0000 (98.5995)  time: 0.3513  data: 0.0008  max mem: 2502
Train: Epoch[5/5]  [1620/3125]  eta: 0:08:48  Lr: 0.001875  Loss: -0.6197  Acc@1: 87.5000 (87.1491)  Acc@5: 100.0000 (98.6043)  time: 0.3504  data: 0.0007  max mem: 2502
Train: Epoch[5/5]  [1630/3125]  eta: 0:08:44  Lr: 0.001875  Loss: -0.7661  Acc@1: 87.5000 (87.1781)  Acc@5: 100.0000 (98.6128)  time: 0.3487  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [1640/3125]  eta: 0:08:41  Lr: 0.001875  Loss: -0.2352  Acc@1: 93.7500 (87.1991)  Acc@5: 100.0000 (98.6137)  time: 0.3514  data: 0.0013  max mem: 2502
Train: Epoch[5/5]  [1650/3125]  eta: 0:08:37  Lr: 0.001875  Loss: -0.8747  Acc@1: 87.5000 (87.1972)  Acc@5: 100.0000 (98.6183)  time: 0.3515  data: 0.0013  max mem: 2502
Train: Epoch[5/5]  [1660/3125]  eta: 0:08:34  Lr: 0.001875  Loss: -0.6641  Acc@1: 87.5000 (87.1915)  Acc@5: 100.0000 (98.6115)  time: 0.3483  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [1670/3125]  eta: 0:08:30  Lr: 0.001875  Loss: -0.6946  Acc@1: 87.5000 (87.1933)  Acc@5: 100.0000 (98.6086)  time: 0.3482  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [1680/3125]  eta: 0:08:27  Lr: 0.001875  Loss: -0.3208  Acc@1: 87.5000 (87.1802)  Acc@5: 100.0000 (98.6020)  time: 0.3483  data: 0.0010  max mem: 2502
Train: Epoch[5/5]  [1690/3125]  eta: 0:08:23  Lr: 0.001875  Loss: -0.4000  Acc@1: 87.5000 (87.1858)  Acc@5: 100.0000 (98.5992)  time: 0.3497  data: 0.0009  max mem: 2502
Train: Epoch[5/5]  [1700/3125]  eta: 0:08:20  Lr: 0.001875  Loss: -0.3792  Acc@1: 87.5000 (87.1767)  Acc@5: 100.0000 (98.6074)  time: 0.3487  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [1710/3125]  eta: 0:08:16  Lr: 0.001875  Loss: -0.4794  Acc@1: 87.5000 (87.1968)  Acc@5: 100.0000 (98.6119)  time: 0.3470  data: 0.0014  max mem: 2502
Train: Epoch[5/5]  [1720/3125]  eta: 0:08:13  Lr: 0.001875  Loss: 0.1801  Acc@1: 87.5000 (87.2131)  Acc@5: 100.0000 (98.6055)  time: 0.3504  data: 0.0017  max mem: 2502
Train: Epoch[5/5]  [1730/3125]  eta: 0:08:09  Lr: 0.001875  Loss: -0.7267  Acc@1: 87.5000 (87.1859)  Acc@5: 100.0000 (98.6027)  time: 0.3522  data: 0.0016  max mem: 2502
Train: Epoch[5/5]  [1740/3125]  eta: 0:08:06  Lr: 0.001875  Loss: -0.5584  Acc@1: 87.5000 (87.2020)  Acc@5: 100.0000 (98.6107)  time: 0.3514  data: 0.0015  max mem: 2502
Train: Epoch[5/5]  [1750/3125]  eta: 0:08:02  Lr: 0.001875  Loss: -0.7488  Acc@1: 87.5000 (87.1859)  Acc@5: 100.0000 (98.6008)  time: 0.3522  data: 0.0008  max mem: 2502
Train: Epoch[5/5]  [1760/3125]  eta: 0:07:59  Lr: 0.001875  Loss: -0.6325  Acc@1: 87.5000 (87.1877)  Acc@5: 100.0000 (98.6087)  time: 0.3567  data: 0.0007  max mem: 2502
Train: Epoch[5/5]  [1770/3125]  eta: 0:07:55  Lr: 0.001875  Loss: -0.8755  Acc@1: 87.5000 (87.1647)  Acc@5: 100.0000 (98.5990)  time: 0.3552  data: 0.0014  max mem: 2502
Train: Epoch[5/5]  [1780/3125]  eta: 0:07:52  Lr: 0.001875  Loss: -0.7424  Acc@1: 87.5000 (87.1877)  Acc@5: 100.0000 (98.6033)  time: 0.3520  data: 0.0013  max mem: 2502
Train: Epoch[5/5]  [1790/3125]  eta: 0:07:48  Lr: 0.001875  Loss: -0.1621  Acc@1: 87.5000 (87.1824)  Acc@5: 100.0000 (98.6076)  time: 0.3528  data: 0.0006  max mem: 2502
Train: Epoch[5/5]  [1800/3125]  eta: 0:07:45  Lr: 0.001875  Loss: -0.4755  Acc@1: 87.5000 (87.1738)  Acc@5: 100.0000 (98.6084)  time: 0.3559  data: 0.0006  max mem: 2502
Train: Epoch[5/5]  [1810/3125]  eta: 0:07:41  Lr: 0.001875  Loss: -0.7701  Acc@1: 87.5000 (87.1790)  Acc@5: 100.0000 (98.6126)  time: 0.3558  data: 0.0009  max mem: 2502
Train: Epoch[5/5]  [1820/3125]  eta: 0:07:38  Lr: 0.001875  Loss: -0.5324  Acc@1: 87.5000 (87.1911)  Acc@5: 100.0000 (98.6168)  time: 0.3507  data: 0.0009  max mem: 2502
Train: Epoch[5/5]  [1830/3125]  eta: 0:07:34  Lr: 0.001875  Loss: -0.2647  Acc@1: 87.5000 (87.1894)  Acc@5: 100.0000 (98.6141)  time: 0.3497  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [1840/3125]  eta: 0:07:31  Lr: 0.001875  Loss: -0.6468  Acc@1: 93.7500 (87.2114)  Acc@5: 100.0000 (98.6149)  time: 0.3485  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [1850/3125]  eta: 0:07:27  Lr: 0.001875  Loss: -0.6224  Acc@1: 87.5000 (87.2062)  Acc@5: 100.0000 (98.6190)  time: 0.3484  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [1860/3125]  eta: 0:07:24  Lr: 0.001875  Loss: -0.6260  Acc@1: 87.5000 (87.1910)  Acc@5: 100.0000 (98.6231)  time: 0.3487  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [1870/3125]  eta: 0:07:20  Lr: 0.001875  Loss: -0.3297  Acc@1: 87.5000 (87.1893)  Acc@5: 100.0000 (98.6237)  time: 0.3496  data: 0.0007  max mem: 2502
Train: Epoch[5/5]  [1880/3125]  eta: 0:07:16  Lr: 0.001875  Loss: -0.7015  Acc@1: 87.5000 (87.2076)  Acc@5: 100.0000 (98.6211)  time: 0.3484  data: 0.0007  max mem: 2502
Train: Epoch[5/5]  [1890/3125]  eta: 0:07:13  Lr: 0.001875  Loss: -0.6791  Acc@1: 87.5000 (87.1959)  Acc@5: 100.0000 (98.6118)  time: 0.3474  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [1900/3125]  eta: 0:07:09  Lr: 0.001875  Loss: -0.8352  Acc@1: 87.5000 (87.2173)  Acc@5: 100.0000 (98.6159)  time: 0.3508  data: 0.0007  max mem: 2502
Train: Epoch[5/5]  [1910/3125]  eta: 0:07:06  Lr: 0.001875  Loss: -0.6841  Acc@1: 87.5000 (87.2057)  Acc@5: 100.0000 (98.6100)  time: 0.3522  data: 0.0009  max mem: 2502
Train: Epoch[5/5]  [1920/3125]  eta: 0:07:02  Lr: 0.001875  Loss: -0.5380  Acc@1: 87.5000 (87.2104)  Acc@5: 100.0000 (98.6042)  time: 0.3513  data: 0.0007  max mem: 2502
Train: Epoch[5/5]  [1930/3125]  eta: 0:06:59  Lr: 0.001875  Loss: -0.3635  Acc@1: 87.5000 (87.1990)  Acc@5: 100.0000 (98.6018)  time: 0.3513  data: 0.0006  max mem: 2502
Train: Epoch[5/5]  [1940/3125]  eta: 0:06:55  Lr: 0.001875  Loss: -0.5884  Acc@1: 87.5000 (87.2263)  Acc@5: 100.0000 (98.6057)  time: 0.3568  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [1950/3125]  eta: 0:06:52  Lr: 0.001875  Loss: -0.3947  Acc@1: 93.7500 (87.2117)  Acc@5: 100.0000 (98.5969)  time: 0.3576  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [1960/3125]  eta: 0:06:48  Lr: 0.001875  Loss: -0.8421  Acc@1: 81.2500 (87.2036)  Acc@5: 100.0000 (98.5913)  time: 0.3524  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [1970/3125]  eta: 0:06:45  Lr: 0.001875  Loss: -0.3496  Acc@1: 81.2500 (87.1956)  Acc@5: 100.0000 (98.5984)  time: 0.3516  data: 0.0006  max mem: 2502
Train: Epoch[5/5]  [1980/3125]  eta: 0:06:41  Lr: 0.001875  Loss: -0.6475  Acc@1: 87.5000 (87.1813)  Acc@5: 100.0000 (98.6055)  time: 0.3499  data: 0.0007  max mem: 2502
Train: Epoch[5/5]  [1990/3125]  eta: 0:06:38  Lr: 0.001875  Loss: -0.8656  Acc@1: 87.5000 (87.1767)  Acc@5: 100.0000 (98.6094)  time: 0.3537  data: 0.0010  max mem: 2502
Train: Epoch[5/5]  [2000/3125]  eta: 0:06:34  Lr: 0.001875  Loss: -0.4733  Acc@1: 87.5000 (87.1783)  Acc@5: 100.0000 (98.6101)  time: 0.3538  data: 0.0008  max mem: 2502
Train: Epoch[5/5]  [2010/3125]  eta: 0:06:31  Lr: 0.001875  Loss: -0.4933  Acc@1: 87.5000 (87.1985)  Acc@5: 100.0000 (98.6108)  time: 0.3487  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [2020/3125]  eta: 0:06:27  Lr: 0.001875  Loss: -0.8087  Acc@1: 87.5000 (87.1753)  Acc@5: 100.0000 (98.6176)  time: 0.3485  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [2030/3125]  eta: 0:06:24  Lr: 0.001875  Loss: 0.4672  Acc@1: 87.5000 (87.1830)  Acc@5: 100.0000 (98.6091)  time: 0.3481  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [2040/3125]  eta: 0:06:20  Lr: 0.001875  Loss: -0.8129  Acc@1: 87.5000 (87.1601)  Acc@5: 100.0000 (98.6098)  time: 0.3502  data: 0.0012  max mem: 2502
Train: Epoch[5/5]  [2050/3125]  eta: 0:06:17  Lr: 0.001875  Loss: 0.0828  Acc@1: 87.5000 (87.1618)  Acc@5: 100.0000 (98.6074)  time: 0.3495  data: 0.0012  max mem: 2502
Train: Epoch[5/5]  [2060/3125]  eta: 0:06:13  Lr: 0.001875  Loss: -0.4123  Acc@1: 87.5000 (87.1695)  Acc@5: 100.0000 (98.6050)  time: 0.3465  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [2070/3125]  eta: 0:06:10  Lr: 0.001875  Loss: -0.5580  Acc@1: 87.5000 (87.1650)  Acc@5: 100.0000 (98.6088)  time: 0.3503  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [2080/3125]  eta: 0:06:06  Lr: 0.001875  Loss: -0.5053  Acc@1: 87.5000 (87.1666)  Acc@5: 100.0000 (98.6124)  time: 0.3511  data: 0.0008  max mem: 2502
Train: Epoch[5/5]  [2090/3125]  eta: 0:06:03  Lr: 0.001875  Loss: -0.7905  Acc@1: 87.5000 (87.1772)  Acc@5: 100.0000 (98.6131)  time: 0.3484  data: 0.0008  max mem: 2502
Train: Epoch[5/5]  [2100/3125]  eta: 0:05:59  Lr: 0.001875  Loss: -0.8039  Acc@1: 93.7500 (87.1757)  Acc@5: 100.0000 (98.6167)  time: 0.3518  data: 0.0006  max mem: 2502
Train: Epoch[5/5]  [2110/3125]  eta: 0:05:56  Lr: 0.001875  Loss: -0.4342  Acc@1: 87.5000 (87.1773)  Acc@5: 100.0000 (98.6233)  time: 0.3541  data: 0.0006  max mem: 2502
Train: Epoch[5/5]  [2120/3125]  eta: 0:05:52  Lr: 0.001875  Loss: -0.7049  Acc@1: 87.5000 (87.1759)  Acc@5: 100.0000 (98.6298)  time: 0.3553  data: 0.0015  max mem: 2502
Train: Epoch[5/5]  [2130/3125]  eta: 0:05:49  Lr: 0.001875  Loss: -0.3032  Acc@1: 87.5000 (87.1627)  Acc@5: 100.0000 (98.6215)  time: 0.3520  data: 0.0015  max mem: 2502
Train: Epoch[5/5]  [2140/3125]  eta: 0:05:45  Lr: 0.001875  Loss: -0.3594  Acc@1: 87.5000 (87.1760)  Acc@5: 100.0000 (98.6221)  time: 0.3480  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [2150/3125]  eta: 0:05:42  Lr: 0.001875  Loss: -0.5863  Acc@1: 87.5000 (87.1804)  Acc@5: 100.0000 (98.6198)  time: 0.3497  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [2160/3125]  eta: 0:05:38  Lr: 0.001875  Loss: -0.5304  Acc@1: 87.5000 (87.1587)  Acc@5: 100.0000 (98.6233)  time: 0.3541  data: 0.0017  max mem: 2502
Train: Epoch[5/5]  [2170/3125]  eta: 0:05:35  Lr: 0.001875  Loss: -0.7841  Acc@1: 81.2500 (87.1488)  Acc@5: 100.0000 (98.6239)  time: 0.3551  data: 0.0018  max mem: 2502
Train: Epoch[5/5]  [2180/3125]  eta: 0:05:31  Lr: 0.001875  Loss: -0.3886  Acc@1: 81.2500 (87.1389)  Acc@5: 100.0000 (98.6245)  time: 0.3506  data: 0.0006  max mem: 2502
Train: Epoch[5/5]  [2190/3125]  eta: 0:05:28  Lr: 0.001875  Loss: -0.4189  Acc@1: 87.5000 (87.1377)  Acc@5: 100.0000 (98.6251)  time: 0.3477  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [2200/3125]  eta: 0:05:24  Lr: 0.001875  Loss: -0.8826  Acc@1: 87.5000 (87.1394)  Acc@5: 100.0000 (98.6228)  time: 0.3474  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [2210/3125]  eta: 0:05:21  Lr: 0.001875  Loss: -0.6721  Acc@1: 87.5000 (87.1438)  Acc@5: 100.0000 (98.6205)  time: 0.3487  data: 0.0006  max mem: 2502
Train: Epoch[5/5]  [2220/3125]  eta: 0:05:17  Lr: 0.001875  Loss: -0.6567  Acc@1: 87.5000 (87.1454)  Acc@5: 100.0000 (98.6155)  time: 0.3494  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [2230/3125]  eta: 0:05:14  Lr: 0.001875  Loss: -0.9159  Acc@1: 87.5000 (87.1498)  Acc@5: 100.0000 (98.6161)  time: 0.3489  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [2240/3125]  eta: 0:05:10  Lr: 0.001875  Loss: -0.8707  Acc@1: 87.5000 (87.1542)  Acc@5: 100.0000 (98.6167)  time: 0.3468  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [2250/3125]  eta: 0:05:07  Lr: 0.001875  Loss: -0.9013  Acc@1: 87.5000 (87.1807)  Acc@5: 100.0000 (98.6173)  time: 0.3464  data: 0.0013  max mem: 2502
Train: Epoch[5/5]  [2260/3125]  eta: 0:05:03  Lr: 0.001875  Loss: -0.7185  Acc@1: 93.7500 (87.1987)  Acc@5: 100.0000 (98.6234)  time: 0.3466  data: 0.0013  max mem: 2502
Train: Epoch[5/5]  [2270/3125]  eta: 0:05:00  Lr: 0.001875  Loss: -0.3954  Acc@1: 87.5000 (87.1973)  Acc@5: 100.0000 (98.6295)  time: 0.3455  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [2280/3125]  eta: 0:04:56  Lr: 0.001875  Loss: 0.1665  Acc@1: 81.2500 (87.1739)  Acc@5: 100.0000 (98.6218)  time: 0.3461  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [2290/3125]  eta: 0:04:53  Lr: 0.001875  Loss: -0.4422  Acc@1: 87.5000 (87.1863)  Acc@5: 100.0000 (98.6278)  time: 0.3514  data: 0.0015  max mem: 2502
Train: Epoch[5/5]  [2300/3125]  eta: 0:04:49  Lr: 0.001875  Loss: -0.5772  Acc@1: 87.5000 (87.1822)  Acc@5: 100.0000 (98.6283)  time: 0.3542  data: 0.0018  max mem: 2502
Train: Epoch[5/5]  [2310/3125]  eta: 0:04:45  Lr: 0.001875  Loss: -0.6659  Acc@1: 87.5000 (87.2052)  Acc@5: 100.0000 (98.6315)  time: 0.3522  data: 0.0007  max mem: 2502
Train: Epoch[5/5]  [2320/3125]  eta: 0:04:42  Lr: 0.001875  Loss: -0.7543  Acc@1: 87.5000 (87.1984)  Acc@5: 100.0000 (98.6321)  time: 0.3522  data: 0.0007  max mem: 2502
Train: Epoch[5/5]  [2330/3125]  eta: 0:04:38  Lr: 0.001875  Loss: -0.7951  Acc@1: 81.2500 (87.1702)  Acc@5: 100.0000 (98.6245)  time: 0.3520  data: 0.0008  max mem: 2502
Train: Epoch[5/5]  [2340/3125]  eta: 0:04:35  Lr: 0.001875  Loss: -0.6456  Acc@1: 81.2500 (87.1876)  Acc@5: 100.0000 (98.6224)  time: 0.3529  data: 0.0006  max mem: 2502
Train: Epoch[5/5]  [2350/3125]  eta: 0:04:31  Lr: 0.001875  Loss: -0.7719  Acc@1: 87.5000 (87.1836)  Acc@5: 100.0000 (98.6256)  time: 0.3517  data: 0.0009  max mem: 2502
Train: Epoch[5/5]  [2360/3125]  eta: 0:04:28  Lr: 0.001875  Loss: -0.6022  Acc@1: 87.5000 (87.1876)  Acc@5: 100.0000 (98.6261)  time: 0.3497  data: 0.0008  max mem: 2502
Train: Epoch[5/5]  [2370/3125]  eta: 0:04:24  Lr: 0.001875  Loss: -0.2315  Acc@1: 87.5000 (87.1863)  Acc@5: 100.0000 (98.6266)  time: 0.3532  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [2380/3125]  eta: 0:04:21  Lr: 0.001875  Loss: -0.8229  Acc@1: 87.5000 (87.1981)  Acc@5: 100.0000 (98.6272)  time: 0.3524  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [2390/3125]  eta: 0:04:17  Lr: 0.001875  Loss: -0.5392  Acc@1: 87.5000 (87.1994)  Acc@5: 100.0000 (98.6251)  time: 0.3529  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [2400/3125]  eta: 0:04:14  Lr: 0.001875  Loss: -0.5105  Acc@1: 87.5000 (87.2006)  Acc@5: 100.0000 (98.6230)  time: 0.3533  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [2410/3125]  eta: 0:04:10  Lr: 0.001875  Loss: -0.5498  Acc@1: 87.5000 (87.1993)  Acc@5: 100.0000 (98.6157)  time: 0.3488  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [2420/3125]  eta: 0:04:07  Lr: 0.001875  Loss: -0.6258  Acc@1: 87.5000 (87.1980)  Acc@5: 100.0000 (98.6137)  time: 0.3478  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [2430/3125]  eta: 0:04:03  Lr: 0.001875  Loss: -0.6456  Acc@1: 87.5000 (87.1966)  Acc@5: 100.0000 (98.6143)  time: 0.3494  data: 0.0007  max mem: 2502
Train: Epoch[5/5]  [2440/3125]  eta: 0:04:00  Lr: 0.001875  Loss: -0.5553  Acc@1: 87.5000 (87.2056)  Acc@5: 100.0000 (98.6148)  time: 0.3504  data: 0.0006  max mem: 2502
Train: Epoch[5/5]  [2450/3125]  eta: 0:03:56  Lr: 0.001875  Loss: -0.7090  Acc@1: 87.5000 (87.2093)  Acc@5: 100.0000 (98.6179)  time: 0.3482  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [2460/3125]  eta: 0:03:53  Lr: 0.001875  Loss: -0.7485  Acc@1: 87.5000 (87.2029)  Acc@5: 100.0000 (98.6210)  time: 0.3471  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [2470/3125]  eta: 0:03:49  Lr: 0.001875  Loss: -0.2824  Acc@1: 87.5000 (87.1939)  Acc@5: 100.0000 (98.6266)  time: 0.3536  data: 0.0009  max mem: 2502
Train: Epoch[5/5]  [2480/3125]  eta: 0:03:46  Lr: 0.001875  Loss: -0.3623  Acc@1: 87.5000 (87.1851)  Acc@5: 100.0000 (98.6220)  time: 0.3568  data: 0.0011  max mem: 2502
Train: Epoch[5/5]  [2490/3125]  eta: 0:03:42  Lr: 0.001875  Loss: -0.5405  Acc@1: 81.2500 (87.1788)  Acc@5: 100.0000 (98.6251)  time: 0.3522  data: 0.0006  max mem: 2502
Train: Epoch[5/5]  [2500/3125]  eta: 0:03:39  Lr: 0.001875  Loss: -0.9086  Acc@1: 87.5000 (87.1901)  Acc@5: 100.0000 (98.6280)  time: 0.3505  data: 0.0007  max mem: 2502
Train: Epoch[5/5]  [2510/3125]  eta: 0:03:35  Lr: 0.001875  Loss: -0.5729  Acc@1: 87.5000 (87.1889)  Acc@5: 100.0000 (98.6285)  time: 0.3491  data: 0.0007  max mem: 2502
Train: Epoch[5/5]  [2520/3125]  eta: 0:03:32  Lr: 0.001875  Loss: -0.8416  Acc@1: 87.5000 (87.2025)  Acc@5: 100.0000 (98.6241)  time: 0.3531  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [2530/3125]  eta: 0:03:28  Lr: 0.001875  Loss: -0.5044  Acc@1: 93.7500 (87.2234)  Acc@5: 100.0000 (98.6295)  time: 0.3539  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [2540/3125]  eta: 0:03:25  Lr: 0.001875  Loss: -0.6634  Acc@1: 93.7500 (87.2270)  Acc@5: 100.0000 (98.6349)  time: 0.3502  data: 0.0006  max mem: 2502
Train: Epoch[5/5]  [2550/3125]  eta: 0:03:21  Lr: 0.001875  Loss: -0.7656  Acc@1: 87.5000 (87.2378)  Acc@5: 100.0000 (98.6353)  time: 0.3512  data: 0.0007  max mem: 2502
Train: Epoch[5/5]  [2560/3125]  eta: 0:03:18  Lr: 0.001875  Loss: -0.6861  Acc@1: 87.5000 (87.2291)  Acc@5: 100.0000 (98.6309)  time: 0.3514  data: 0.0007  max mem: 2502
Train: Epoch[5/5]  [2570/3125]  eta: 0:03:14  Lr: 0.001875  Loss: -0.4348  Acc@1: 87.5000 (87.2350)  Acc@5: 100.0000 (98.6314)  time: 0.3527  data: 0.0018  max mem: 2502
Train: Epoch[5/5]  [2580/3125]  eta: 0:03:11  Lr: 0.001875  Loss: -0.5558  Acc@1: 87.5000 (87.2506)  Acc@5: 100.0000 (98.6343)  time: 0.3520  data: 0.0017  max mem: 2502
Train: Epoch[5/5]  [2590/3125]  eta: 0:03:07  Lr: 0.001875  Loss: -0.8619  Acc@1: 87.5000 (87.2467)  Acc@5: 100.0000 (98.6347)  time: 0.3486  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [2600/3125]  eta: 0:03:04  Lr: 0.001875  Loss: -0.5227  Acc@1: 81.2500 (87.2429)  Acc@5: 100.0000 (98.6399)  time: 0.3494  data: 0.0011  max mem: 2502
Train: Epoch[5/5]  [2610/3125]  eta: 0:03:00  Lr: 0.001875  Loss: -0.4849  Acc@1: 87.5000 (87.2463)  Acc@5: 100.0000 (98.6428)  time: 0.3505  data: 0.0010  max mem: 2502
Train: Epoch[5/5]  [2620/3125]  eta: 0:02:57  Lr: 0.001875  Loss: -0.5650  Acc@1: 87.5000 (87.2544)  Acc@5: 100.0000 (98.6456)  time: 0.3483  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [2630/3125]  eta: 0:02:53  Lr: 0.001875  Loss: -0.2646  Acc@1: 87.5000 (87.2411)  Acc@5: 100.0000 (98.6412)  time: 0.3462  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [2640/3125]  eta: 0:02:50  Lr: 0.001875  Loss: -0.5513  Acc@1: 87.5000 (87.2349)  Acc@5: 100.0000 (98.6416)  time: 0.3455  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [2650/3125]  eta: 0:02:46  Lr: 0.001875  Loss: -0.5337  Acc@1: 87.5000 (87.2171)  Acc@5: 100.0000 (98.6397)  time: 0.3508  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [2660/3125]  eta: 0:02:43  Lr: 0.001875  Loss: -0.6589  Acc@1: 87.5000 (87.2205)  Acc@5: 100.0000 (98.6424)  time: 0.3525  data: 0.0006  max mem: 2502
Train: Epoch[5/5]  [2670/3125]  eta: 0:02:39  Lr: 0.001875  Loss: -0.7600  Acc@1: 87.5000 (87.2098)  Acc@5: 100.0000 (98.6335)  time: 0.3488  data: 0.0007  max mem: 2502
Train: Epoch[5/5]  [2680/3125]  eta: 0:02:36  Lr: 0.001875  Loss: -0.5233  Acc@1: 81.2500 (87.2039)  Acc@5: 100.0000 (98.6316)  time: 0.3489  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [2690/3125]  eta: 0:02:32  Lr: 0.001875  Loss: -0.6382  Acc@1: 87.5000 (87.2027)  Acc@5: 100.0000 (98.6343)  time: 0.3529  data: 0.0027  max mem: 2502
Train: Epoch[5/5]  [2700/3125]  eta: 0:02:29  Lr: 0.001875  Loss: -0.5419  Acc@1: 87.5000 (87.2177)  Acc@5: 100.0000 (98.6301)  time: 0.3536  data: 0.0028  max mem: 2502
Train: Epoch[5/5]  [2710/3125]  eta: 0:02:25  Lr: 0.001875  Loss: -0.4743  Acc@1: 93.7500 (87.2233)  Acc@5: 100.0000 (98.6329)  time: 0.3497  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [2720/3125]  eta: 0:02:22  Lr: 0.001875  Loss: -0.6657  Acc@1: 87.5000 (87.2290)  Acc@5: 100.0000 (98.6356)  time: 0.3499  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [2730/3125]  eta: 0:02:18  Lr: 0.001875  Loss: -0.7813  Acc@1: 87.5000 (87.2368)  Acc@5: 100.0000 (98.6360)  time: 0.3531  data: 0.0024  max mem: 2502
Train: Epoch[5/5]  [2740/3125]  eta: 0:02:15  Lr: 0.001875  Loss: -0.5173  Acc@1: 87.5000 (87.2309)  Acc@5: 100.0000 (98.6410)  time: 0.3554  data: 0.0028  max mem: 2502
Train: Epoch[5/5]  [2750/3125]  eta: 0:02:11  Lr: 0.001875  Loss: -0.3129  Acc@1: 87.5000 (87.2319)  Acc@5: 100.0000 (98.6414)  time: 0.3531  data: 0.0010  max mem: 2502
Train: Epoch[5/5]  [2760/3125]  eta: 0:02:08  Lr: 0.001875  Loss: -0.5636  Acc@1: 87.5000 (87.2306)  Acc@5: 100.0000 (98.6441)  time: 0.3493  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [2770/3125]  eta: 0:02:04  Lr: 0.001875  Loss: -0.6474  Acc@1: 87.5000 (87.2451)  Acc@5: 100.0000 (98.6467)  time: 0.3474  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [2780/3125]  eta: 0:02:01  Lr: 0.001875  Loss: -0.5096  Acc@1: 93.7500 (87.2550)  Acc@5: 100.0000 (98.6381)  time: 0.3489  data: 0.0006  max mem: 2502
Train: Epoch[5/5]  [2790/3125]  eta: 0:01:57  Lr: 0.001875  Loss: -0.6481  Acc@1: 87.5000 (87.2671)  Acc@5: 100.0000 (98.6340)  time: 0.3498  data: 0.0006  max mem: 2502
Train: Epoch[5/5]  [2800/3125]  eta: 0:01:54  Lr: 0.001875  Loss: -0.8997  Acc@1: 93.7500 (87.2858)  Acc@5: 100.0000 (98.6366)  time: 0.3481  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [2810/3125]  eta: 0:01:50  Lr: 0.001875  Loss: -0.7023  Acc@1: 93.7500 (87.2910)  Acc@5: 100.0000 (98.6348)  time: 0.3466  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [2820/3125]  eta: 0:01:47  Lr: 0.001875  Loss: -0.6853  Acc@1: 93.7500 (87.3072)  Acc@5: 100.0000 (98.6352)  time: 0.3461  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [2830/3125]  eta: 0:01:43  Lr: 0.001875  Loss: -0.6559  Acc@1: 93.7500 (87.3146)  Acc@5: 100.0000 (98.6268)  time: 0.3472  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [2840/3125]  eta: 0:01:39  Lr: 0.001875  Loss: -0.7305  Acc@1: 87.5000 (87.3152)  Acc@5: 100.0000 (98.6272)  time: 0.3465  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [2850/3125]  eta: 0:01:36  Lr: 0.001875  Loss: -0.8174  Acc@1: 87.5000 (87.3093)  Acc@5: 100.0000 (98.6321)  time: 0.3468  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [2860/3125]  eta: 0:01:32  Lr: 0.001875  Loss: -0.5100  Acc@1: 87.5000 (87.3056)  Acc@5: 100.0000 (98.6281)  time: 0.3495  data: 0.0014  max mem: 2502
Train: Epoch[5/5]  [2870/3125]  eta: 0:01:29  Lr: 0.001875  Loss: -0.6304  Acc@1: 87.5000 (87.3128)  Acc@5: 100.0000 (98.6242)  time: 0.3502  data: 0.0015  max mem: 2502
Train: Epoch[5/5]  [2880/3125]  eta: 0:01:25  Lr: 0.001875  Loss: -0.6490  Acc@1: 87.5000 (87.3113)  Acc@5: 100.0000 (98.6203)  time: 0.3491  data: 0.0007  max mem: 2502
Train: Epoch[5/5]  [2890/3125]  eta: 0:01:22  Lr: 0.001875  Loss: -0.3438  Acc@1: 87.5000 (87.3098)  Acc@5: 100.0000 (98.6142)  time: 0.3488  data: 0.0006  max mem: 2502
Train: Epoch[5/5]  [2900/3125]  eta: 0:01:18  Lr: 0.001875  Loss: -0.5801  Acc@1: 87.5000 (87.3212)  Acc@5: 100.0000 (98.6190)  time: 0.3481  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [2910/3125]  eta: 0:01:15  Lr: 0.001875  Loss: -0.7389  Acc@1: 87.5000 (87.3239)  Acc@5: 100.0000 (98.6173)  time: 0.3522  data: 0.0009  max mem: 2502
Train: Epoch[5/5]  [2920/3125]  eta: 0:01:11  Lr: 0.001875  Loss: -0.8895  Acc@1: 87.5000 (87.3181)  Acc@5: 100.0000 (98.6156)  time: 0.3550  data: 0.0012  max mem: 2502
Train: Epoch[5/5]  [2930/3125]  eta: 0:01:08  Lr: 0.001875  Loss: -0.7968  Acc@1: 87.5000 (87.3124)  Acc@5: 100.0000 (98.6161)  time: 0.3520  data: 0.0009  max mem: 2502
Train: Epoch[5/5]  [2940/3125]  eta: 0:01:04  Lr: 0.001875  Loss: -0.1637  Acc@1: 87.5000 (87.3066)  Acc@5: 100.0000 (98.6187)  time: 0.3524  data: 0.0008  max mem: 2502
Train: Epoch[5/5]  [2950/3125]  eta: 0:01:01  Lr: 0.001875  Loss: -0.2682  Acc@1: 87.5000 (87.3052)  Acc@5: 100.0000 (98.6128)  time: 0.3515  data: 0.0010  max mem: 2502
Train: Epoch[5/5]  [2960/3125]  eta: 0:00:57  Lr: 0.001875  Loss: -0.5844  Acc@1: 87.5000 (87.3037)  Acc@5: 93.7500 (98.6048)  time: 0.3529  data: 0.0011  max mem: 2502
Train: Epoch[5/5]  [2970/3125]  eta: 0:00:54  Lr: 0.001875  Loss: -0.3683  Acc@1: 87.5000 (87.3107)  Acc@5: 100.0000 (98.6053)  time: 0.3521  data: 0.0008  max mem: 2502
Train: Epoch[5/5]  [2980/3125]  eta: 0:00:50  Lr: 0.001875  Loss: -0.6516  Acc@1: 87.5000 (87.3134)  Acc@5: 100.0000 (98.6078)  time: 0.3476  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [2990/3125]  eta: 0:00:47  Lr: 0.001875  Loss: -0.4726  Acc@1: 87.5000 (87.3036)  Acc@5: 100.0000 (98.6083)  time: 0.3480  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [3000/3125]  eta: 0:00:43  Lr: 0.001875  Loss: -0.5487  Acc@1: 87.5000 (87.2980)  Acc@5: 100.0000 (98.6067)  time: 0.3512  data: 0.0011  max mem: 2502
Train: Epoch[5/5]  [3010/3125]  eta: 0:00:40  Lr: 0.001875  Loss: -0.3828  Acc@1: 87.5000 (87.3111)  Acc@5: 100.0000 (98.6093)  time: 0.3509  data: 0.0011  max mem: 2502
Train: Epoch[5/5]  [3020/3125]  eta: 0:00:36  Lr: 0.001875  Loss: -0.7689  Acc@1: 93.7500 (87.3221)  Acc@5: 100.0000 (98.6097)  time: 0.3470  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [3030/3125]  eta: 0:00:33  Lr: 0.001875  Loss: -0.6929  Acc@1: 87.5000 (87.3082)  Acc@5: 100.0000 (98.6102)  time: 0.3463  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [3040/3125]  eta: 0:00:29  Lr: 0.001875  Loss: -0.6738  Acc@1: 81.2500 (87.3068)  Acc@5: 100.0000 (98.6086)  time: 0.3486  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [3050/3125]  eta: 0:00:26  Lr: 0.001875  Loss: -0.5325  Acc@1: 87.5000 (87.3095)  Acc@5: 100.0000 (98.6070)  time: 0.3491  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [3060/3125]  eta: 0:00:22  Lr: 0.001875  Loss: -0.8240  Acc@1: 87.5000 (87.3142)  Acc@5: 100.0000 (98.6054)  time: 0.3462  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [3070/3125]  eta: 0:00:19  Lr: 0.001875  Loss: -0.5857  Acc@1: 87.5000 (87.3067)  Acc@5: 100.0000 (98.6100)  time: 0.3485  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [3080/3125]  eta: 0:00:15  Lr: 0.001875  Loss: -0.8255  Acc@1: 87.5000 (87.3012)  Acc@5: 100.0000 (98.6064)  time: 0.3541  data: 0.0006  max mem: 2502
Train: Epoch[5/5]  [3090/3125]  eta: 0:00:12  Lr: 0.001875  Loss: -0.6567  Acc@1: 87.5000 (87.2938)  Acc@5: 100.0000 (98.6089)  time: 0.3533  data: 0.0006  max mem: 2502
Train: Epoch[5/5]  [3100/3125]  eta: 0:00:08  Lr: 0.001875  Loss: -0.4480  Acc@1: 87.5000 (87.2864)  Acc@5: 100.0000 (98.6113)  time: 0.3521  data: 0.0006  max mem: 2502
Train: Epoch[5/5]  [3110/3125]  eta: 0:00:05  Lr: 0.001875  Loss: -0.5721  Acc@1: 87.5000 (87.2891)  Acc@5: 100.0000 (98.6118)  time: 0.3520  data: 0.0007  max mem: 2502
Train: Epoch[5/5]  [3120/3125]  eta: 0:00:01  Lr: 0.001875  Loss: -0.7024  Acc@1: 87.5000 (87.2937)  Acc@5: 100.0000 (98.6122)  time: 0.3527  data: 0.0012  max mem: 2502
Train: Epoch[5/5]  [3124/3125]  eta: 0:00:00  Lr: 0.001875  Loss: -0.4985  Acc@1: 87.5000 (87.2960)  Acc@5: 100.0000 (98.6120)  time: 0.3557  data: 0.0011  max mem: 2502
Train: Epoch[5/5] Total time: 0:18:16 (0.3510 s / it)
{0: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 1: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 2: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 3: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 4: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 5: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 6: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 7: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 8: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 9: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 10: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 11: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 12: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 13: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 14: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 15: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 16: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 17: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 18: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 19: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}}
Averaged stats: Lr: 0.001875  Loss: -0.4985  Acc@1: 87.5000 (87.2960)  Acc@5: 100.0000 (98.6120)
Test: [Task 1]  [   0/1627]  eta: 0:25:29  Loss: 1.4299 (1.4299)  Acc@1: 56.2500 (56.2500)  Acc@5: 93.7500 (93.7500)  time: 0.9398  data: 0.7180  max mem: 2502
Test: [Task 1]  [  10/1627]  eta: 0:07:43  Loss: 1.2789 (1.2181)  Acc@1: 68.7500 (65.9091)  Acc@5: 87.5000 (92.0455)  time: 0.2866  data: 0.0656  max mem: 2502
Test: [Task 1]  [  20/1627]  eta: 0:06:46  Loss: 1.1368 (1.1678)  Acc@1: 68.7500 (66.6667)  Acc@5: 93.7500 (92.5595)  time: 0.2189  data: 0.0004  max mem: 2502
Test: [Task 1]  [  30/1627]  eta: 0:06:25  Loss: 1.1543 (1.1680)  Acc@1: 62.5000 (66.5323)  Acc@5: 93.7500 (92.7419)  time: 0.2164  data: 0.0004  max mem: 2502
Test: [Task 1]  [  40/1627]  eta: 0:06:12  Loss: 1.2307 (1.1791)  Acc@1: 62.5000 (66.0061)  Acc@5: 93.7500 (92.9878)  time: 0.2159  data: 0.0003  max mem: 2502
Test: [Task 1]  [  50/1627]  eta: 0:06:05  Loss: 0.9665 (1.1519)  Acc@1: 68.7500 (67.6471)  Acc@5: 93.7500 (93.6275)  time: 0.2169  data: 0.0005  max mem: 2502
Test: [Task 1]  [  60/1627]  eta: 0:05:59  Loss: 1.0320 (1.1638)  Acc@1: 68.7500 (67.5205)  Acc@5: 93.7500 (93.6475)  time: 0.2177  data: 0.0005  max mem: 2502
Test: [Task 1]  [  70/1627]  eta: 0:05:54  Loss: 1.1861 (1.1647)  Acc@1: 62.5000 (67.6937)  Acc@5: 93.7500 (94.0141)  time: 0.2172  data: 0.0003  max mem: 2502
Test: [Task 1]  [  80/1627]  eta: 0:05:50  Loss: 0.9027 (1.1454)  Acc@1: 75.0000 (68.3642)  Acc@5: 100.0000 (94.3673)  time: 0.2172  data: 0.0004  max mem: 2502
Test: [Task 1]  [  90/1627]  eta: 0:05:46  Loss: 1.0790 (1.1577)  Acc@1: 75.0000 (67.9945)  Acc@5: 93.7500 (94.1621)  time: 0.2168  data: 0.0008  max mem: 2502
Test: [Task 1]  [ 100/1627]  eta: 0:05:42  Loss: 1.2140 (1.1800)  Acc@1: 68.7500 (68.0074)  Acc@5: 93.7500 (93.4406)  time: 0.2167  data: 0.0007  max mem: 2502
Test: [Task 1]  [ 110/1627]  eta: 0:05:39  Loss: 1.1277 (1.1741)  Acc@1: 75.0000 (68.2432)  Acc@5: 93.7500 (93.7500)  time: 0.2163  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 120/1627]  eta: 0:05:36  Loss: 1.1238 (1.1709)  Acc@1: 75.0000 (68.5950)  Acc@5: 93.7500 (93.5950)  time: 0.2162  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 130/1627]  eta: 0:05:33  Loss: 1.1685 (1.1778)  Acc@1: 75.0000 (68.2729)  Acc@5: 93.7500 (93.5592)  time: 0.2161  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 140/1627]  eta: 0:05:30  Loss: 1.0848 (1.1749)  Acc@1: 68.7500 (68.4397)  Acc@5: 93.7500 (93.4397)  time: 0.2160  data: 0.0006  max mem: 2502
Test: [Task 1]  [ 150/1627]  eta: 0:05:27  Loss: 0.9407 (1.1566)  Acc@1: 75.0000 (69.0397)  Acc@5: 93.7500 (93.5844)  time: 0.2166  data: 0.0009  max mem: 2502
Test: [Task 1]  [ 160/1627]  eta: 0:05:24  Loss: 0.9516 (1.1511)  Acc@1: 75.0000 (69.3323)  Acc@5: 93.7500 (93.6724)  time: 0.2163  data: 0.0007  max mem: 2502
Test: [Task 1]  [ 170/1627]  eta: 0:05:21  Loss: 1.1125 (1.1451)  Acc@1: 75.0000 (69.4079)  Acc@5: 93.7500 (93.7135)  time: 0.2152  data: 0.0004  max mem: 2502
Test: [Task 1]  [ 180/1627]  eta: 0:05:19  Loss: 1.1125 (1.1511)  Acc@1: 68.7500 (69.1298)  Acc@5: 93.7500 (93.6809)  time: 0.2151  data: 0.0002  max mem: 2502
Test: [Task 1]  [ 190/1627]  eta: 0:05:16  Loss: 1.1459 (1.1491)  Acc@1: 68.7500 (69.0445)  Acc@5: 93.7500 (93.6518)  time: 0.2152  data: 0.0002  max mem: 2502
Test: [Task 1]  [ 200/1627]  eta: 0:05:14  Loss: 1.1519 (1.1491)  Acc@1: 68.7500 (69.2164)  Acc@5: 93.7500 (93.6256)  time: 0.2148  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 210/1627]  eta: 0:05:11  Loss: 0.9931 (1.1459)  Acc@1: 75.0000 (69.4905)  Acc@5: 93.7500 (93.6611)  time: 0.2149  data: 0.0004  max mem: 2502
Test: [Task 1]  [ 220/1627]  eta: 0:05:09  Loss: 1.0035 (1.1533)  Acc@1: 75.0000 (69.2025)  Acc@5: 93.7500 (93.5803)  time: 0.2171  data: 0.0009  max mem: 2502
Test: [Task 1]  [ 230/1627]  eta: 0:05:06  Loss: 1.1067 (1.1505)  Acc@1: 68.7500 (69.2911)  Acc@5: 93.7500 (93.5606)  time: 0.2188  data: 0.0009  max mem: 2502
Test: [Task 1]  [ 240/1627]  eta: 0:05:04  Loss: 1.0856 (1.1461)  Acc@1: 68.7500 (69.3724)  Acc@5: 93.7500 (93.5685)  time: 0.2176  data: 0.0005  max mem: 2502
Test: [Task 1]  [ 250/1627]  eta: 0:05:02  Loss: 1.0561 (1.1490)  Acc@1: 75.0000 (69.4721)  Acc@5: 93.7500 (93.5259)  time: 0.2165  data: 0.0006  max mem: 2502
Test: [Task 1]  [ 260/1627]  eta: 0:04:59  Loss: 1.0899 (1.1489)  Acc@1: 68.7500 (69.5163)  Acc@5: 93.7500 (93.5345)  time: 0.2160  data: 0.0005  max mem: 2502
Test: [Task 1]  [ 270/1627]  eta: 0:04:57  Loss: 1.0211 (1.1413)  Acc@1: 75.0000 (69.7648)  Acc@5: 100.0000 (93.6808)  time: 0.2158  data: 0.0004  max mem: 2502
Test: [Task 1]  [ 280/1627]  eta: 0:04:55  Loss: 0.9254 (1.1419)  Acc@1: 75.0000 (69.8621)  Acc@5: 93.7500 (93.6165)  time: 0.2165  data: 0.0004  max mem: 2502
Test: [Task 1]  [ 290/1627]  eta: 0:04:53  Loss: 1.1269 (1.1406)  Acc@1: 68.7500 (69.9098)  Acc@5: 93.7500 (93.7070)  time: 0.2185  data: 0.0004  max mem: 2502
Test: [Task 1]  [ 300/1627]  eta: 0:04:50  Loss: 1.0056 (1.1402)  Acc@1: 68.7500 (69.9336)  Acc@5: 93.7500 (93.7085)  time: 0.2193  data: 0.0005  max mem: 2502
Test: [Task 1]  [ 310/1627]  eta: 0:04:48  Loss: 1.0367 (1.1400)  Acc@1: 75.0000 (70.0161)  Acc@5: 93.7500 (93.7701)  time: 0.2180  data: 0.0005  max mem: 2502
Test: [Task 1]  [ 320/1627]  eta: 0:04:46  Loss: 1.1681 (1.1404)  Acc@1: 75.0000 (69.9377)  Acc@5: 93.7500 (93.8279)  time: 0.2170  data: 0.0004  max mem: 2502
Test: [Task 1]  [ 330/1627]  eta: 0:04:43  Loss: 1.0341 (1.1395)  Acc@1: 68.7500 (69.9773)  Acc@5: 100.0000 (93.8633)  time: 0.2158  data: 0.0004  max mem: 2502
Test: [Task 1]  [ 340/1627]  eta: 0:04:41  Loss: 0.9600 (1.1395)  Acc@1: 75.0000 (70.0696)  Acc@5: 93.7500 (93.8233)  time: 0.2165  data: 0.0006  max mem: 2502
Test: [Task 1]  [ 350/1627]  eta: 0:04:39  Loss: 1.2181 (1.1409)  Acc@1: 68.7500 (70.0321)  Acc@5: 93.7500 (93.7856)  time: 0.2180  data: 0.0007  max mem: 2502
Test: [Task 1]  [ 360/1627]  eta: 0:04:37  Loss: 1.0475 (1.1389)  Acc@1: 75.0000 (70.1697)  Acc@5: 93.7500 (93.7673)  time: 0.2176  data: 0.0006  max mem: 2502
Test: [Task 1]  [ 370/1627]  eta: 0:04:34  Loss: 1.0371 (1.1370)  Acc@1: 75.0000 (70.2325)  Acc@5: 93.7500 (93.8174)  time: 0.2168  data: 0.0006  max mem: 2502
Test: [Task 1]  [ 380/1627]  eta: 0:04:32  Loss: 0.9667 (1.1354)  Acc@1: 68.7500 (70.3084)  Acc@5: 93.7500 (93.8320)  time: 0.2176  data: 0.0004  max mem: 2502
Test: [Task 1]  [ 390/1627]  eta: 0:04:30  Loss: 0.9847 (1.1367)  Acc@1: 75.0000 (70.2685)  Acc@5: 93.7500 (93.7180)  time: 0.2176  data: 0.0004  max mem: 2502
Test: [Task 1]  [ 400/1627]  eta: 0:04:28  Loss: 1.0126 (1.1371)  Acc@1: 68.7500 (70.1995)  Acc@5: 93.7500 (93.7500)  time: 0.2159  data: 0.0004  max mem: 2502
Test: [Task 1]  [ 410/1627]  eta: 0:04:25  Loss: 0.9310 (1.1366)  Acc@1: 75.0000 (70.3619)  Acc@5: 93.7500 (93.6740)  time: 0.2154  data: 0.0004  max mem: 2502
Test: [Task 1]  [ 420/1627]  eta: 0:04:23  Loss: 0.9310 (1.1349)  Acc@1: 75.0000 (70.3682)  Acc@5: 93.7500 (93.7352)  time: 0.2153  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 430/1627]  eta: 0:04:21  Loss: 1.0090 (1.1334)  Acc@1: 75.0000 (70.4031)  Acc@5: 100.0000 (93.8080)  time: 0.2158  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 440/1627]  eta: 0:04:19  Loss: 1.0763 (1.1314)  Acc@1: 68.7500 (70.4082)  Acc@5: 100.0000 (93.8634)  time: 0.2162  data: 0.0007  max mem: 2502
Test: [Task 1]  [ 450/1627]  eta: 0:04:16  Loss: 1.1309 (1.1341)  Acc@1: 68.7500 (70.3298)  Acc@5: 93.7500 (93.8054)  time: 0.2159  data: 0.0008  max mem: 2502
Test: [Task 1]  [ 460/1627]  eta: 0:04:14  Loss: 1.1359 (1.1333)  Acc@1: 62.5000 (70.2956)  Acc@5: 93.7500 (93.8178)  time: 0.2158  data: 0.0008  max mem: 2502
Test: [Task 1]  [ 470/1627]  eta: 0:04:12  Loss: 1.0078 (1.1301)  Acc@1: 68.7500 (70.3689)  Acc@5: 93.7500 (93.8031)  time: 0.2157  data: 0.0008  max mem: 2502
Test: [Task 1]  [ 480/1627]  eta: 0:04:10  Loss: 1.1527 (1.1347)  Acc@1: 68.7500 (70.2573)  Acc@5: 93.7500 (93.7890)  time: 0.2152  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 490/1627]  eta: 0:04:07  Loss: 1.1812 (1.1359)  Acc@1: 62.5000 (70.1884)  Acc@5: 93.7500 (93.7882)  time: 0.2146  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 500/1627]  eta: 0:04:05  Loss: 1.0705 (1.1370)  Acc@1: 75.0000 (70.1971)  Acc@5: 93.7500 (93.7750)  time: 0.2153  data: 0.0005  max mem: 2502
Test: [Task 1]  [ 510/1627]  eta: 0:04:03  Loss: 1.1676 (1.1425)  Acc@1: 68.7500 (70.0954)  Acc@5: 93.7500 (93.7133)  time: 0.2170  data: 0.0013  max mem: 2502
Test: [Task 1]  [ 520/1627]  eta: 0:04:01  Loss: 1.2353 (1.1501)  Acc@1: 62.5000 (69.9016)  Acc@5: 93.7500 (93.6900)  time: 0.2161  data: 0.0011  max mem: 2502
Test: [Task 1]  [ 530/1627]  eta: 0:03:59  Loss: 1.0920 (1.1462)  Acc@1: 62.5000 (69.9623)  Acc@5: 93.7500 (93.7500)  time: 0.2159  data: 0.0005  max mem: 2502
Test: [Task 1]  [ 540/1627]  eta: 0:03:56  Loss: 0.9836 (1.1464)  Acc@1: 68.7500 (69.9284)  Acc@5: 93.7500 (93.7384)  time: 0.2163  data: 0.0006  max mem: 2502
Test: [Task 1]  [ 550/1627]  eta: 0:03:54  Loss: 1.1967 (1.1483)  Acc@1: 68.7500 (69.9410)  Acc@5: 93.7500 (93.7160)  time: 0.2156  data: 0.0005  max mem: 2502
Test: [Task 1]  [ 560/1627]  eta: 0:03:52  Loss: 1.3028 (1.1512)  Acc@1: 68.7500 (69.8529)  Acc@5: 93.7500 (93.6832)  time: 0.2177  data: 0.0004  max mem: 2502
Test: [Task 1]  [ 570/1627]  eta: 0:03:50  Loss: 1.1686 (1.1486)  Acc@1: 68.7500 (69.9321)  Acc@5: 93.7500 (93.6953)  time: 0.2176  data: 0.0004  max mem: 2502
Test: [Task 1]  [ 580/1627]  eta: 0:03:48  Loss: 1.0379 (1.1493)  Acc@1: 68.7500 (69.8580)  Acc@5: 93.7500 (93.7392)  time: 0.2159  data: 0.0004  max mem: 2502
Test: [Task 1]  [ 590/1627]  eta: 0:03:45  Loss: 1.1731 (1.1489)  Acc@1: 68.7500 (69.8816)  Acc@5: 100.0000 (93.8029)  time: 0.2180  data: 0.0015  max mem: 2502
Test: [Task 1]  [ 600/1627]  eta: 0:03:43  Loss: 1.1351 (1.1498)  Acc@1: 68.7500 (69.8211)  Acc@5: 100.0000 (93.8228)  time: 0.2197  data: 0.0016  max mem: 2502
Test: [Task 1]  [ 610/1627]  eta: 0:03:41  Loss: 1.0497 (1.1478)  Acc@1: 68.7500 (69.8547)  Acc@5: 100.0000 (93.8625)  time: 0.2180  data: 0.0006  max mem: 2502
Test: [Task 1]  [ 620/1627]  eta: 0:03:39  Loss: 1.0502 (1.1487)  Acc@1: 75.0000 (69.8671)  Acc@5: 93.7500 (93.7903)  time: 0.2161  data: 0.0006  max mem: 2502
Test: [Task 1]  [ 630/1627]  eta: 0:03:37  Loss: 1.0492 (1.1482)  Acc@1: 75.0000 (69.9188)  Acc@5: 93.7500 (93.7797)  time: 0.2163  data: 0.0005  max mem: 2502
Test: [Task 1]  [ 640/1627]  eta: 0:03:34  Loss: 0.9600 (1.1484)  Acc@1: 75.0000 (69.9395)  Acc@5: 93.7500 (93.7500)  time: 0.2171  data: 0.0006  max mem: 2502
Test: [Task 1]  [ 650/1627]  eta: 0:03:32  Loss: 1.0104 (1.1481)  Acc@1: 68.7500 (69.9309)  Acc@5: 93.7500 (93.7404)  time: 0.2206  data: 0.0009  max mem: 2502
Test: [Task 1]  [ 660/1627]  eta: 0:03:30  Loss: 1.0420 (1.1465)  Acc@1: 68.7500 (69.9887)  Acc@5: 93.7500 (93.7122)  time: 0.2207  data: 0.0008  max mem: 2502
Test: [Task 1]  [ 670/1627]  eta: 0:03:28  Loss: 1.0661 (1.1460)  Acc@1: 68.7500 (69.9981)  Acc@5: 93.7500 (93.7034)  time: 0.2185  data: 0.0010  max mem: 2502
Test: [Task 1]  [ 680/1627]  eta: 0:03:26  Loss: 1.0661 (1.1458)  Acc@1: 68.7500 (70.0165)  Acc@5: 93.7500 (93.6674)  time: 0.2181  data: 0.0009  max mem: 2502
Test: [Task 1]  [ 690/1627]  eta: 0:03:24  Loss: 1.0799 (1.1437)  Acc@1: 75.0000 (70.0796)  Acc@5: 93.7500 (93.7229)  time: 0.2163  data: 0.0004  max mem: 2502
Test: [Task 1]  [ 700/1627]  eta: 0:03:21  Loss: 1.0879 (1.1434)  Acc@1: 75.0000 (70.1587)  Acc@5: 93.7500 (93.7233)  time: 0.2157  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 710/1627]  eta: 0:03:19  Loss: 0.9873 (1.1411)  Acc@1: 75.0000 (70.2444)  Acc@5: 93.7500 (93.7588)  time: 0.2155  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 720/1627]  eta: 0:03:17  Loss: 0.9873 (1.1391)  Acc@1: 75.0000 (70.2670)  Acc@5: 100.0000 (93.7933)  time: 0.2166  data: 0.0011  max mem: 2502
Test: [Task 1]  [ 730/1627]  eta: 0:03:15  Loss: 1.0303 (1.1404)  Acc@1: 68.7500 (70.1864)  Acc@5: 93.7500 (93.8098)  time: 0.2170  data: 0.0011  max mem: 2502
Test: [Task 1]  [ 740/1627]  eta: 0:03:13  Loss: 1.1125 (1.1414)  Acc@1: 68.7500 (70.2429)  Acc@5: 93.7500 (93.8006)  time: 0.2160  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 750/1627]  eta: 0:03:10  Loss: 1.0223 (1.1402)  Acc@1: 75.0000 (70.3395)  Acc@5: 93.7500 (93.8083)  time: 0.2165  data: 0.0004  max mem: 2502
Test: [Task 1]  [ 760/1627]  eta: 0:03:08  Loss: 1.1932 (1.1433)  Acc@1: 75.0000 (70.2530)  Acc@5: 93.7500 (93.7829)  time: 0.2165  data: 0.0004  max mem: 2502
Test: [Task 1]  [ 770/1627]  eta: 0:03:06  Loss: 0.9465 (1.1397)  Acc@1: 75.0000 (70.3551)  Acc@5: 93.7500 (93.8311)  time: 0.2151  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 780/1627]  eta: 0:03:04  Loss: 0.8957 (1.1382)  Acc@1: 75.0000 (70.3585)  Acc@5: 100.0000 (93.8460)  time: 0.2147  data: 0.0002  max mem: 2502
Test: [Task 1]  [ 790/1627]  eta: 0:03:02  Loss: 0.9564 (1.1397)  Acc@1: 68.7500 (70.3461)  Acc@5: 93.7500 (93.8290)  time: 0.2149  data: 0.0002  max mem: 2502
Test: [Task 1]  [ 800/1627]  eta: 0:02:59  Loss: 1.0816 (1.1387)  Acc@1: 68.7500 (70.3262)  Acc@5: 93.7500 (93.8514)  time: 0.2148  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 810/1627]  eta: 0:02:57  Loss: 1.0299 (1.1377)  Acc@1: 75.0000 (70.4069)  Acc@5: 93.7500 (93.8502)  time: 0.2151  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 820/1627]  eta: 0:02:55  Loss: 1.0247 (1.1368)  Acc@1: 75.0000 (70.3867)  Acc@5: 93.7500 (93.8642)  time: 0.2154  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 830/1627]  eta: 0:02:53  Loss: 0.9370 (1.1362)  Acc@1: 75.0000 (70.4046)  Acc@5: 100.0000 (93.8929)  time: 0.2149  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 840/1627]  eta: 0:02:51  Loss: 0.9440 (1.1342)  Acc@1: 75.0000 (70.4741)  Acc@5: 100.0000 (93.9209)  time: 0.2158  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 850/1627]  eta: 0:02:48  Loss: 1.0438 (1.1346)  Acc@1: 68.7500 (70.4245)  Acc@5: 100.0000 (93.9189)  time: 0.2171  data: 0.0004  max mem: 2502
Test: [Task 1]  [ 860/1627]  eta: 0:02:46  Loss: 1.0048 (1.1333)  Acc@1: 68.7500 (70.4413)  Acc@5: 100.0000 (93.9533)  time: 0.2177  data: 0.0004  max mem: 2502
Test: [Task 1]  [ 870/1627]  eta: 0:02:44  Loss: 0.9204 (1.1317)  Acc@1: 75.0000 (70.5080)  Acc@5: 100.0000 (93.9724)  time: 0.2193  data: 0.0004  max mem: 2502
Test: [Task 1]  [ 880/1627]  eta: 0:02:42  Loss: 1.0780 (1.1339)  Acc@1: 75.0000 (70.4384)  Acc@5: 100.0000 (93.9983)  time: 0.2193  data: 0.0008  max mem: 2502
Test: [Task 1]  [ 890/1627]  eta: 0:02:40  Loss: 1.2558 (1.1358)  Acc@1: 62.5000 (70.3774)  Acc@5: 93.7500 (93.9885)  time: 0.2178  data: 0.0008  max mem: 2502
Test: [Task 1]  [ 900/1627]  eta: 0:02:38  Loss: 1.1215 (1.1360)  Acc@1: 68.7500 (70.3871)  Acc@5: 93.7500 (93.9928)  time: 0.2178  data: 0.0005  max mem: 2502
Test: [Task 1]  [ 910/1627]  eta: 0:02:35  Loss: 1.1192 (1.1368)  Acc@1: 68.7500 (70.4034)  Acc@5: 93.7500 (93.9627)  time: 0.2174  data: 0.0004  max mem: 2502
Test: [Task 1]  [ 920/1627]  eta: 0:02:33  Loss: 1.1192 (1.1365)  Acc@1: 68.7500 (70.4126)  Acc@5: 93.7500 (93.9604)  time: 0.2180  data: 0.0005  max mem: 2502
Test: [Task 1]  [ 930/1627]  eta: 0:02:31  Loss: 1.1562 (1.1374)  Acc@1: 68.7500 (70.3679)  Acc@5: 93.7500 (93.9313)  time: 0.2202  data: 0.0006  max mem: 2502
Test: [Task 1]  [ 940/1627]  eta: 0:02:29  Loss: 1.1086 (1.1358)  Acc@1: 68.7500 (70.4370)  Acc@5: 93.7500 (93.9625)  time: 0.2201  data: 0.0012  max mem: 2502
Test: [Task 1]  [ 950/1627]  eta: 0:02:27  Loss: 1.1096 (1.1365)  Acc@1: 68.7500 (70.4127)  Acc@5: 100.0000 (93.9800)  time: 0.2187  data: 0.0011  max mem: 2502
Test: [Task 1]  [ 960/1627]  eta: 0:02:25  Loss: 1.1729 (1.1361)  Acc@1: 68.7500 (70.4084)  Acc@5: 93.7500 (93.9776)  time: 0.2186  data: 0.0004  max mem: 2502
Test: [Task 1]  [ 970/1627]  eta: 0:02:22  Loss: 0.9955 (1.1348)  Acc@1: 75.0000 (70.4493)  Acc@5: 93.7500 (93.9817)  time: 0.2195  data: 0.0004  max mem: 2502
Test: [Task 1]  [ 980/1627]  eta: 0:02:20  Loss: 1.0699 (1.1352)  Acc@1: 68.7500 (70.4447)  Acc@5: 93.7500 (93.9666)  time: 0.2193  data: 0.0004  max mem: 2502
Test: [Task 1]  [ 990/1627]  eta: 0:02:18  Loss: 1.1768 (1.1382)  Acc@1: 68.7500 (70.4150)  Acc@5: 87.5000 (93.9140)  time: 0.2211  data: 0.0011  max mem: 2502
Test: [Task 1]  [1000/1627]  eta: 0:02:16  Loss: 1.2572 (1.1389)  Acc@1: 68.7500 (70.3984)  Acc@5: 87.5000 (93.8686)  time: 0.2206  data: 0.0011  max mem: 2502
Test: [Task 1]  [1010/1627]  eta: 0:02:14  Loss: 1.1454 (1.1386)  Acc@1: 68.7500 (70.4006)  Acc@5: 93.7500 (93.8798)  time: 0.2171  data: 0.0003  max mem: 2502
Test: [Task 1]  [1020/1627]  eta: 0:02:12  Loss: 1.0897 (1.1383)  Acc@1: 68.7500 (70.3844)  Acc@5: 93.7500 (93.8786)  time: 0.2163  data: 0.0003  max mem: 2502
Test: [Task 1]  [1030/1627]  eta: 0:02:09  Loss: 0.9643 (1.1363)  Acc@1: 75.0000 (70.4474)  Acc@5: 93.7500 (93.9016)  time: 0.2173  data: 0.0004  max mem: 2502
Test: [Task 1]  [1040/1627]  eta: 0:02:07  Loss: 0.9066 (1.1351)  Acc@1: 75.0000 (70.4851)  Acc@5: 100.0000 (93.9181)  time: 0.2168  data: 0.0004  max mem: 2502
Test: [Task 1]  [1050/1627]  eta: 0:02:05  Loss: 0.9312 (1.1334)  Acc@1: 75.0000 (70.5340)  Acc@5: 93.7500 (93.9284)  time: 0.2161  data: 0.0004  max mem: 2502
Test: [Task 1]  [1060/1627]  eta: 0:02:03  Loss: 1.0934 (1.1340)  Acc@1: 75.0000 (70.5408)  Acc@5: 93.7500 (93.9149)  time: 0.2171  data: 0.0004  max mem: 2502
Test: [Task 1]  [1070/1627]  eta: 0:02:01  Loss: 1.1284 (1.1348)  Acc@1: 75.0000 (70.5357)  Acc@5: 93.7500 (93.8959)  time: 0.2176  data: 0.0004  max mem: 2502
Test: [Task 1]  [1080/1627]  eta: 0:01:59  Loss: 1.2034 (1.1352)  Acc@1: 68.7500 (70.5423)  Acc@5: 93.7500 (93.8772)  time: 0.2166  data: 0.0004  max mem: 2502
Test: [Task 1]  [1090/1627]  eta: 0:01:56  Loss: 1.1395 (1.1352)  Acc@1: 68.7500 (70.5431)  Acc@5: 93.7500 (93.8818)  time: 0.2159  data: 0.0003  max mem: 2502
Test: [Task 1]  [1100/1627]  eta: 0:01:54  Loss: 1.0303 (1.1332)  Acc@1: 68.7500 (70.5779)  Acc@5: 100.0000 (93.8976)  time: 0.2155  data: 0.0006  max mem: 2502
Test: [Task 1]  [1110/1627]  eta: 0:01:52  Loss: 1.0715 (1.1339)  Acc@1: 68.7500 (70.5671)  Acc@5: 100.0000 (93.9019)  time: 0.2149  data: 0.0006  max mem: 2502
Test: [Task 1]  [1120/1627]  eta: 0:01:50  Loss: 1.1667 (1.1351)  Acc@1: 62.5000 (70.4951)  Acc@5: 93.7500 (93.9061)  time: 0.2150  data: 0.0003  max mem: 2502
Test: [Task 1]  [1130/1627]  eta: 0:01:48  Loss: 1.0954 (1.1357)  Acc@1: 62.5000 (70.4741)  Acc@5: 93.7500 (93.9103)  time: 0.2159  data: 0.0009  max mem: 2502
Test: [Task 1]  [1140/1627]  eta: 0:01:45  Loss: 1.2878 (1.1370)  Acc@1: 68.7500 (70.4481)  Acc@5: 93.7500 (93.8979)  time: 0.2162  data: 0.0009  max mem: 2502
Test: [Task 1]  [1150/1627]  eta: 0:01:43  Loss: 1.2878 (1.1379)  Acc@1: 68.7500 (70.4225)  Acc@5: 93.7500 (93.8858)  time: 0.2168  data: 0.0005  max mem: 2502
Test: [Task 1]  [1160/1627]  eta: 0:01:41  Loss: 1.1481 (1.1369)  Acc@1: 68.7500 (70.4834)  Acc@5: 93.7500 (93.9007)  time: 0.2175  data: 0.0006  max mem: 2502
Test: [Task 1]  [1170/1627]  eta: 0:01:39  Loss: 1.1272 (1.1360)  Acc@1: 75.0000 (70.5220)  Acc@5: 100.0000 (93.9101)  time: 0.2176  data: 0.0005  max mem: 2502
Test: [Task 1]  [1180/1627]  eta: 0:01:37  Loss: 1.1022 (1.1365)  Acc@1: 75.0000 (70.5229)  Acc@5: 93.7500 (93.9193)  time: 0.2214  data: 0.0011  max mem: 2502
Test: [Task 1]  [1190/1627]  eta: 0:01:35  Loss: 1.2088 (1.1370)  Acc@1: 68.7500 (70.4870)  Acc@5: 93.7500 (93.9337)  time: 0.2215  data: 0.0011  max mem: 2502
Test: [Task 1]  [1200/1627]  eta: 0:01:32  Loss: 1.1510 (1.1369)  Acc@1: 68.7500 (70.4829)  Acc@5: 93.7500 (93.9269)  time: 0.2185  data: 0.0005  max mem: 2502
Test: [Task 1]  [1210/1627]  eta: 0:01:30  Loss: 0.9559 (1.1375)  Acc@1: 68.7500 (70.4480)  Acc@5: 93.7500 (93.9152)  time: 0.2200  data: 0.0008  max mem: 2502
Test: [Task 1]  [1220/1627]  eta: 0:01:28  Loss: 0.9559 (1.1367)  Acc@1: 68.7500 (70.4648)  Acc@5: 93.7500 (93.9343)  time: 0.2242  data: 0.0029  max mem: 2502
Test: [Task 1]  [1230/1627]  eta: 0:01:26  Loss: 1.1340 (1.1369)  Acc@1: 68.7500 (70.4610)  Acc@5: 93.7500 (93.9277)  time: 0.2233  data: 0.0033  max mem: 2502
Test: [Task 1]  [1240/1627]  eta: 0:01:24  Loss: 1.1459 (1.1362)  Acc@1: 68.7500 (70.4623)  Acc@5: 93.7500 (93.9414)  time: 0.2169  data: 0.0014  max mem: 2502
Test: [Task 1]  [1250/1627]  eta: 0:01:22  Loss: 1.1494 (1.1368)  Acc@1: 68.7500 (70.4287)  Acc@5: 93.7500 (93.9448)  time: 0.2153  data: 0.0006  max mem: 2502
Test: [Task 1]  [1260/1627]  eta: 0:01:19  Loss: 1.0759 (1.1366)  Acc@1: 68.7500 (70.4401)  Acc@5: 93.7500 (93.9383)  time: 0.2163  data: 0.0006  max mem: 2502
Test: [Task 1]  [1270/1627]  eta: 0:01:17  Loss: 1.0331 (1.1373)  Acc@1: 68.7500 (70.4072)  Acc@5: 93.7500 (93.9123)  time: 0.2163  data: 0.0006  max mem: 2502
Test: [Task 1]  [1280/1627]  eta: 0:01:15  Loss: 0.9742 (1.1355)  Acc@1: 68.7500 (70.4479)  Acc@5: 93.7500 (93.9208)  time: 0.2155  data: 0.0004  max mem: 2502
Test: [Task 1]  [1290/1627]  eta: 0:01:13  Loss: 1.0639 (1.1358)  Acc@1: 68.7500 (70.4299)  Acc@5: 93.7500 (93.9146)  time: 0.2169  data: 0.0009  max mem: 2502
Test: [Task 1]  [1300/1627]  eta: 0:01:11  Loss: 1.0864 (1.1350)  Acc@1: 75.0000 (70.4794)  Acc@5: 93.7500 (93.9277)  time: 0.2219  data: 0.0017  max mem: 2502
Test: [Task 1]  [1310/1627]  eta: 0:01:09  Loss: 0.8944 (1.1336)  Acc@1: 75.0000 (70.5235)  Acc@5: 93.7500 (93.9312)  time: 0.2212  data: 0.0011  max mem: 2502
Test: [Task 1]  [1320/1627]  eta: 0:01:06  Loss: 0.8440 (1.1320)  Acc@1: 75.0000 (70.5715)  Acc@5: 100.0000 (93.9487)  time: 0.2161  data: 0.0003  max mem: 2502
Test: [Task 1]  [1330/1627]  eta: 0:01:04  Loss: 0.9452 (1.1319)  Acc@1: 75.0000 (70.6142)  Acc@5: 93.7500 (93.9331)  time: 0.2157  data: 0.0003  max mem: 2502
Test: [Task 1]  [1340/1627]  eta: 0:01:02  Loss: 1.0866 (1.1323)  Acc@1: 68.7500 (70.5910)  Acc@5: 93.7500 (93.9318)  time: 0.2157  data: 0.0003  max mem: 2502
Test: [Task 1]  [1350/1627]  eta: 0:01:00  Loss: 0.9534 (1.1316)  Acc@1: 68.7500 (70.5912)  Acc@5: 93.7500 (93.9443)  time: 0.2156  data: 0.0003  max mem: 2502
Test: [Task 1]  [1360/1627]  eta: 0:00:58  Loss: 0.9699 (1.1312)  Acc@1: 68.7500 (70.6007)  Acc@5: 100.0000 (93.9612)  time: 0.2162  data: 0.0004  max mem: 2502
Test: [Task 1]  [1370/1627]  eta: 0:00:55  Loss: 1.0081 (1.1305)  Acc@1: 68.7500 (70.6236)  Acc@5: 93.7500 (93.9688)  time: 0.2158  data: 0.0004  max mem: 2502
Test: [Task 1]  [1380/1627]  eta: 0:00:53  Loss: 1.0962 (1.1309)  Acc@1: 62.5000 (70.6146)  Acc@5: 93.7500 (93.9582)  time: 0.2157  data: 0.0003  max mem: 2502
Test: [Task 1]  [1390/1627]  eta: 0:00:51  Loss: 1.1506 (1.1301)  Acc@1: 68.7500 (70.6281)  Acc@5: 93.7500 (93.9702)  time: 0.2157  data: 0.0003  max mem: 2502
Test: [Task 1]  [1400/1627]  eta: 0:00:49  Loss: 1.1435 (1.1303)  Acc@1: 75.0000 (70.6281)  Acc@5: 93.7500 (93.9597)  time: 0.2151  data: 0.0003  max mem: 2502
Test: [Task 1]  [1410/1627]  eta: 0:00:47  Loss: 0.9360 (1.1298)  Acc@1: 75.0000 (70.6591)  Acc@5: 93.7500 (93.9670)  time: 0.2155  data: 0.0010  max mem: 2502
Test: [Task 1]  [1420/1627]  eta: 0:00:45  Loss: 1.0510 (1.1297)  Acc@1: 68.7500 (70.6325)  Acc@5: 100.0000 (93.9875)  time: 0.2156  data: 0.0012  max mem: 2502
Test: [Task 1]  [1430/1627]  eta: 0:00:42  Loss: 1.2685 (1.1314)  Acc@1: 62.5000 (70.5975)  Acc@5: 93.7500 (93.9553)  time: 0.2152  data: 0.0005  max mem: 2502
Test: [Task 1]  [1440/1627]  eta: 0:00:40  Loss: 1.1416 (1.1308)  Acc@1: 68.7500 (70.5933)  Acc@5: 93.7500 (93.9712)  time: 0.2150  data: 0.0003  max mem: 2502
Test: [Task 1]  [1450/1627]  eta: 0:00:38  Loss: 1.1716 (1.1324)  Acc@1: 68.7500 (70.5462)  Acc@5: 93.7500 (93.9481)  time: 0.2144  data: 0.0002  max mem: 2502
Test: [Task 1]  [1460/1627]  eta: 0:00:36  Loss: 1.2770 (1.1327)  Acc@1: 68.7500 (70.5424)  Acc@5: 93.7500 (93.9425)  time: 0.2142  data: 0.0002  max mem: 2502
Test: [Task 1]  [1470/1627]  eta: 0:00:34  Loss: 1.1373 (1.1334)  Acc@1: 68.7500 (70.5090)  Acc@5: 93.7500 (93.9200)  time: 0.2162  data: 0.0013  max mem: 2502
Test: [Task 1]  [1480/1627]  eta: 0:00:31  Loss: 1.1392 (1.1336)  Acc@1: 68.7500 (70.4845)  Acc@5: 93.7500 (93.9230)  time: 0.2183  data: 0.0015  max mem: 2502
Test: [Task 1]  [1490/1627]  eta: 0:00:29  Loss: 1.1392 (1.1338)  Acc@1: 68.7500 (70.4896)  Acc@5: 93.7500 (93.9344)  time: 0.2176  data: 0.0004  max mem: 2502
Test: [Task 1]  [1500/1627]  eta: 0:00:27  Loss: 1.1275 (1.1338)  Acc@1: 75.0000 (70.5030)  Acc@5: 93.7500 (93.9290)  time: 0.2171  data: 0.0005  max mem: 2502
Test: [Task 1]  [1510/1627]  eta: 0:00:25  Loss: 1.0144 (1.1341)  Acc@1: 68.7500 (70.4914)  Acc@5: 93.7500 (93.9237)  time: 0.2170  data: 0.0006  max mem: 2502
Test: [Task 1]  [1520/1627]  eta: 0:00:23  Loss: 1.0144 (1.1330)  Acc@1: 68.7500 (70.5210)  Acc@5: 93.7500 (93.9472)  time: 0.2170  data: 0.0006  max mem: 2502
Test: [Task 1]  [1530/1627]  eta: 0:00:21  Loss: 1.0406 (1.1328)  Acc@1: 68.7500 (70.5136)  Acc@5: 100.0000 (93.9500)  time: 0.2170  data: 0.0004  max mem: 2502
Test: [Task 1]  [1540/1627]  eta: 0:00:18  Loss: 0.9218 (1.1320)  Acc@1: 68.7500 (70.5062)  Acc@5: 100.0000 (93.9609)  time: 0.2180  data: 0.0008  max mem: 2502
Test: [Task 1]  [1550/1627]  eta: 0:00:16  Loss: 0.9218 (1.1317)  Acc@1: 68.7500 (70.5230)  Acc@5: 100.0000 (93.9716)  time: 0.2193  data: 0.0010  max mem: 2502
Test: [Task 1]  [1560/1627]  eta: 0:00:14  Loss: 0.9012 (1.1304)  Acc@1: 81.2500 (70.5958)  Acc@5: 93.7500 (93.9822)  time: 0.2201  data: 0.0023  max mem: 2502
Test: [Task 1]  [1570/1627]  eta: 0:00:12  Loss: 1.0251 (1.1304)  Acc@1: 81.2500 (70.6158)  Acc@5: 93.7500 (93.9847)  time: 0.2203  data: 0.0023  max mem: 2502
Test: [Task 1]  [1580/1627]  eta: 0:00:10  Loss: 1.0354 (1.1301)  Acc@1: 68.7500 (70.6238)  Acc@5: 93.7500 (93.9872)  time: 0.2182  data: 0.0005  max mem: 2502
Test: [Task 1]  [1590/1627]  eta: 0:00:08  Loss: 1.0747 (1.1304)  Acc@1: 68.7500 (70.6160)  Acc@5: 100.0000 (94.0014)  time: 0.2174  data: 0.0003  max mem: 2502
Test: [Task 1]  [1600/1627]  eta: 0:00:05  Loss: 1.1562 (1.1313)  Acc@1: 68.7500 (70.5926)  Acc@5: 93.7500 (93.9764)  time: 0.2207  data: 0.0004  max mem: 2502
Test: [Task 1]  [1610/1627]  eta: 0:00:03  Loss: 1.1482 (1.1308)  Acc@1: 68.7500 (70.6006)  Acc@5: 93.7500 (93.9867)  time: 0.2198  data: 0.0004  max mem: 2502
Test: [Task 1]  [1620/1627]  eta: 0:00:01  Loss: 0.9840 (1.1298)  Acc@1: 75.0000 (70.6508)  Acc@5: 93.7500 (93.9929)  time: 0.2171  data: 0.0003  max mem: 2502
Test: [Task 1]  [1626/1627]  eta: 0:00:00  Loss: 0.8767 (1.1290)  Acc@1: 75.0000 (70.6861)  Acc@5: 93.7500 (93.9882)  time: 0.2175  data: 0.0003  max mem: 2502
Test: [Task 1] Total time: 0:05:54 (0.2177 s / it)
* Acc@1 70.686 Acc@5 93.988 loss 1.129
Test: [Task 2]  [  0/625]  eta: 0:06:09  Loss: 0.1532 (0.1532)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)  time: 0.5917  data: 0.3717  max mem: 2502
Test: [Task 2]  [ 10/625]  eta: 0:02:34  Loss: 0.2521 (0.2719)  Acc@1: 93.7500 (94.3182)  Acc@5: 100.0000 (98.8636)  time: 0.2515  data: 0.0342  max mem: 2502
Test: [Task 2]  [ 20/625]  eta: 0:02:22  Loss: 0.1881 (0.2624)  Acc@1: 93.7500 (94.0476)  Acc@5: 100.0000 (99.4048)  time: 0.2172  data: 0.0004  max mem: 2502
Test: [Task 2]  [ 30/625]  eta: 0:02:16  Loss: 0.2065 (0.2820)  Acc@1: 93.7500 (92.9435)  Acc@5: 100.0000 (99.1935)  time: 0.2164  data: 0.0003  max mem: 2502
Test: [Task 2]  [ 40/625]  eta: 0:02:12  Loss: 0.2987 (0.2858)  Acc@1: 93.7500 (93.5976)  Acc@5: 100.0000 (99.2378)  time: 0.2159  data: 0.0003  max mem: 2502
Test: [Task 2]  [ 50/625]  eta: 0:02:08  Loss: 0.3233 (0.3022)  Acc@1: 93.7500 (93.1373)  Acc@5: 100.0000 (99.2647)  time: 0.2161  data: 0.0003  max mem: 2502
Test: [Task 2]  [ 60/625]  eta: 0:02:05  Loss: 0.3185 (0.3044)  Acc@1: 93.7500 (92.6230)  Acc@5: 100.0000 (99.1803)  time: 0.2157  data: 0.0003  max mem: 2502
Test: [Task 2]  [ 70/625]  eta: 0:02:03  Loss: 0.2287 (0.2992)  Acc@1: 93.7500 (92.7817)  Acc@5: 100.0000 (99.2077)  time: 0.2186  data: 0.0032  max mem: 2502
Test: [Task 2]  [ 80/625]  eta: 0:02:00  Loss: 0.2636 (0.3072)  Acc@1: 93.7500 (92.6698)  Acc@5: 100.0000 (99.0741)  time: 0.2192  data: 0.0034  max mem: 2502
Test: [Task 2]  [ 90/625]  eta: 0:01:58  Loss: 0.3044 (0.3018)  Acc@1: 93.7500 (92.8571)  Acc@5: 100.0000 (99.1758)  time: 0.2160  data: 0.0006  max mem: 2502
Test: [Task 2]  [100/625]  eta: 0:01:55  Loss: 0.2905 (0.3027)  Acc@1: 93.7500 (92.7599)  Acc@5: 100.0000 (99.1955)  time: 0.2150  data: 0.0004  max mem: 2502
Test: [Task 2]  [110/625]  eta: 0:01:53  Loss: 0.2271 (0.3010)  Acc@1: 93.7500 (92.8491)  Acc@5: 100.0000 (99.2680)  time: 0.2142  data: 0.0002  max mem: 2502
Test: [Task 2]  [120/625]  eta: 0:01:50  Loss: 0.2271 (0.3029)  Acc@1: 93.7500 (92.6653)  Acc@5: 100.0000 (99.2252)  time: 0.2146  data: 0.0003  max mem: 2502
Test: [Task 2]  [130/625]  eta: 0:01:48  Loss: 0.2411 (0.3040)  Acc@1: 93.7500 (92.6527)  Acc@5: 100.0000 (99.2844)  time: 0.2175  data: 0.0004  max mem: 2502
Test: [Task 2]  [140/625]  eta: 0:01:46  Loss: 0.2411 (0.3077)  Acc@1: 93.7500 (92.4645)  Acc@5: 100.0000 (99.2465)  time: 0.2191  data: 0.0004  max mem: 2502
Test: [Task 2]  [150/625]  eta: 0:01:44  Loss: 0.2750 (0.3133)  Acc@1: 87.5000 (92.0944)  Acc@5: 100.0000 (99.2550)  time: 0.2189  data: 0.0005  max mem: 2502
Test: [Task 2]  [160/625]  eta: 0:01:41  Loss: 0.3063 (0.3172)  Acc@1: 93.7500 (92.1196)  Acc@5: 100.0000 (99.1848)  time: 0.2189  data: 0.0005  max mem: 2502
Test: [Task 2]  [170/625]  eta: 0:01:39  Loss: 0.3136 (0.3184)  Acc@1: 93.7500 (91.9956)  Acc@5: 100.0000 (99.1959)  time: 0.2189  data: 0.0007  max mem: 2502
Test: [Task 2]  [180/625]  eta: 0:01:37  Loss: 0.3095 (0.3184)  Acc@1: 87.5000 (91.8854)  Acc@5: 100.0000 (99.2058)  time: 0.2178  data: 0.0007  max mem: 2502
Test: [Task 2]  [190/625]  eta: 0:01:35  Loss: 0.2964 (0.3196)  Acc@1: 93.7500 (91.9503)  Acc@5: 100.0000 (99.2147)  time: 0.2165  data: 0.0004  max mem: 2502
Test: [Task 2]  [200/625]  eta: 0:01:33  Loss: 0.2950 (0.3186)  Acc@1: 93.7500 (91.9154)  Acc@5: 100.0000 (99.2537)  time: 0.2184  data: 0.0010  max mem: 2502
Test: [Task 2]  [210/625]  eta: 0:01:30  Loss: 0.2891 (0.3197)  Acc@1: 93.7500 (91.8543)  Acc@5: 100.0000 (99.2299)  time: 0.2206  data: 0.0011  max mem: 2502
Test: [Task 2]  [220/625]  eta: 0:01:28  Loss: 0.2152 (0.3164)  Acc@1: 93.7500 (92.0249)  Acc@5: 100.0000 (99.2364)  time: 0.2202  data: 0.0011  max mem: 2502
Test: [Task 2]  [230/625]  eta: 0:01:26  Loss: 0.2127 (0.3158)  Acc@1: 93.7500 (92.0725)  Acc@5: 100.0000 (99.2695)  time: 0.2188  data: 0.0015  max mem: 2502
Test: [Task 2]  [240/625]  eta: 0:01:24  Loss: 0.3409 (0.3175)  Acc@1: 93.7500 (91.9865)  Acc@5: 100.0000 (99.2739)  time: 0.2184  data: 0.0009  max mem: 2502
Test: [Task 2]  [250/625]  eta: 0:01:22  Loss: 0.3642 (0.3205)  Acc@1: 87.5000 (91.8327)  Acc@5: 100.0000 (99.2032)  time: 0.2183  data: 0.0006  max mem: 2502
Test: [Task 2]  [260/625]  eta: 0:01:19  Loss: 0.3508 (0.3220)  Acc@1: 87.5000 (91.7385)  Acc@5: 100.0000 (99.2098)  time: 0.2181  data: 0.0007  max mem: 2502
Test: [Task 2]  [270/625]  eta: 0:01:17  Loss: 0.3299 (0.3217)  Acc@1: 87.5000 (91.8127)  Acc@5: 100.0000 (99.1928)  time: 0.2175  data: 0.0007  max mem: 2502
Test: [Task 2]  [280/625]  eta: 0:01:15  Loss: 0.2817 (0.3231)  Acc@1: 93.7500 (91.7482)  Acc@5: 100.0000 (99.1548)  time: 0.2165  data: 0.0006  max mem: 2502
Test: [Task 2]  [290/625]  eta: 0:01:13  Loss: 0.2803 (0.3221)  Acc@1: 93.7500 (91.7741)  Acc@5: 100.0000 (99.1624)  time: 0.2165  data: 0.0004  max mem: 2502
Test: [Task 2]  [300/625]  eta: 0:01:11  Loss: 0.2890 (0.3227)  Acc@1: 93.7500 (91.7151)  Acc@5: 100.0000 (99.1902)  time: 0.2163  data: 0.0005  max mem: 2502
Test: [Task 2]  [310/625]  eta: 0:01:08  Loss: 0.3158 (0.3244)  Acc@1: 93.7500 (91.6801)  Acc@5: 100.0000 (99.1760)  time: 0.2169  data: 0.0004  max mem: 2502
Test: [Task 2]  [320/625]  eta: 0:01:06  Loss: 0.1837 (0.3178)  Acc@1: 100.0000 (91.9003)  Acc@5: 100.0000 (99.2017)  time: 0.2168  data: 0.0004  max mem: 2502
Test: [Task 2]  [330/625]  eta: 0:01:04  Loss: 0.1172 (0.3133)  Acc@1: 100.0000 (92.0506)  Acc@5: 100.0000 (99.2258)  time: 0.2159  data: 0.0004  max mem: 2502
Test: [Task 2]  [340/625]  eta: 0:01:02  Loss: 0.0926 (0.3062)  Acc@1: 100.0000 (92.2654)  Acc@5: 100.0000 (99.2485)  time: 0.2165  data: 0.0005  max mem: 2502
Test: [Task 2]  [350/625]  eta: 0:01:00  Loss: 0.0700 (0.3027)  Acc@1: 100.0000 (92.3077)  Acc@5: 100.0000 (99.2699)  time: 0.2167  data: 0.0006  max mem: 2502
Test: [Task 2]  [360/625]  eta: 0:00:57  Loss: 0.2218 (0.3042)  Acc@1: 93.7500 (92.3130)  Acc@5: 100.0000 (99.2729)  time: 0.2158  data: 0.0003  max mem: 2502
Test: [Task 2]  [370/625]  eta: 0:00:55  Loss: 0.1814 (0.3006)  Acc@1: 93.7500 (92.4697)  Acc@5: 100.0000 (99.2925)  time: 0.2149  data: 0.0005  max mem: 2502
Test: [Task 2]  [380/625]  eta: 0:00:53  Loss: 0.2902 (0.3041)  Acc@1: 93.7500 (92.3885)  Acc@5: 100.0000 (99.2454)  time: 0.2148  data: 0.0005  max mem: 2502
Test: [Task 2]  [390/625]  eta: 0:00:51  Loss: 0.2925 (0.3035)  Acc@1: 93.7500 (92.3753)  Acc@5: 100.0000 (99.2168)  time: 0.2143  data: 0.0002  max mem: 2502
Test: [Task 2]  [400/625]  eta: 0:00:49  Loss: 0.1047 (0.2994)  Acc@1: 93.7500 (92.5031)  Acc@5: 100.0000 (99.2363)  time: 0.2143  data: 0.0002  max mem: 2502
Test: [Task 2]  [410/625]  eta: 0:00:46  Loss: 0.0876 (0.2974)  Acc@1: 100.0000 (92.5487)  Acc@5: 100.0000 (99.2245)  time: 0.2154  data: 0.0005  max mem: 2502
Test: [Task 2]  [420/625]  eta: 0:00:44  Loss: 0.1382 (0.2971)  Acc@1: 93.7500 (92.5327)  Acc@5: 100.0000 (99.2429)  time: 0.2158  data: 0.0005  max mem: 2502
Test: [Task 2]  [430/625]  eta: 0:00:42  Loss: 0.1627 (0.2941)  Acc@1: 93.7500 (92.6189)  Acc@5: 100.0000 (99.2604)  time: 0.2153  data: 0.0003  max mem: 2502
Test: [Task 2]  [440/625]  eta: 0:00:40  Loss: 0.0855 (0.2892)  Acc@1: 100.0000 (92.7863)  Acc@5: 100.0000 (99.2772)  time: 0.2160  data: 0.0004  max mem: 2502
Test: [Task 2]  [450/625]  eta: 0:00:38  Loss: 0.0897 (0.2863)  Acc@1: 100.0000 (92.7799)  Acc@5: 100.0000 (99.2932)  time: 0.2161  data: 0.0004  max mem: 2502
Test: [Task 2]  [460/625]  eta: 0:00:35  Loss: 0.1243 (0.2827)  Acc@1: 93.7500 (92.8959)  Acc@5: 100.0000 (99.3086)  time: 0.2166  data: 0.0004  max mem: 2502
Test: [Task 2]  [470/625]  eta: 0:00:33  Loss: 0.1468 (0.2803)  Acc@1: 100.0000 (93.0069)  Acc@5: 100.0000 (99.3232)  time: 0.2166  data: 0.0004  max mem: 2502
Test: [Task 2]  [480/625]  eta: 0:00:31  Loss: 0.1809 (0.2793)  Acc@1: 100.0000 (93.0613)  Acc@5: 100.0000 (99.3373)  time: 0.2164  data: 0.0007  max mem: 2502
Test: [Task 2]  [490/625]  eta: 0:00:29  Loss: 0.1586 (0.2767)  Acc@1: 100.0000 (93.1517)  Acc@5: 100.0000 (99.3508)  time: 0.2172  data: 0.0007  max mem: 2502
Test: [Task 2]  [500/625]  eta: 0:00:27  Loss: 0.1488 (0.2750)  Acc@1: 100.0000 (93.1761)  Acc@5: 100.0000 (99.3638)  time: 0.2178  data: 0.0004  max mem: 2502
Test: [Task 2]  [510/625]  eta: 0:00:25  Loss: 0.1875 (0.2763)  Acc@1: 93.7500 (93.0773)  Acc@5: 100.0000 (99.3640)  time: 0.2169  data: 0.0004  max mem: 2502
Test: [Task 2]  [520/625]  eta: 0:00:22  Loss: 0.2219 (0.2763)  Acc@1: 93.7500 (93.0662)  Acc@5: 100.0000 (99.3762)  time: 0.2157  data: 0.0004  max mem: 2502
Test: [Task 2]  [530/625]  eta: 0:00:20  Loss: 0.1593 (0.2740)  Acc@1: 93.7500 (93.1379)  Acc@5: 100.0000 (99.3879)  time: 0.2162  data: 0.0004  max mem: 2502
Test: [Task 2]  [540/625]  eta: 0:00:18  Loss: 0.1142 (0.2719)  Acc@1: 100.0000 (93.2301)  Acc@5: 100.0000 (99.3993)  time: 0.2172  data: 0.0005  max mem: 2502
Test: [Task 2]  [550/625]  eta: 0:00:16  Loss: 0.0867 (0.2685)  Acc@1: 100.0000 (93.3303)  Acc@5: 100.0000 (99.4102)  time: 0.2172  data: 0.0004  max mem: 2502
Test: [Task 2]  [560/625]  eta: 0:00:14  Loss: 0.0675 (0.2654)  Acc@1: 100.0000 (93.4046)  Acc@5: 100.0000 (99.4207)  time: 0.2195  data: 0.0019  max mem: 2502
Test: [Task 2]  [570/625]  eta: 0:00:11  Loss: 0.0799 (0.2643)  Acc@1: 100.0000 (93.4326)  Acc@5: 100.0000 (99.4308)  time: 0.2221  data: 0.0024  max mem: 2502
Test: [Task 2]  [580/625]  eta: 0:00:09  Loss: 0.1129 (0.2616)  Acc@1: 100.0000 (93.5026)  Acc@5: 100.0000 (99.4406)  time: 0.2187  data: 0.0009  max mem: 2502
Test: [Task 2]  [590/625]  eta: 0:00:07  Loss: 0.1287 (0.2604)  Acc@1: 93.7500 (93.5173)  Acc@5: 100.0000 (99.4501)  time: 0.2159  data: 0.0003  max mem: 2502
Test: [Task 2]  [600/625]  eta: 0:00:05  Loss: 0.2009 (0.2605)  Acc@1: 93.7500 (93.5108)  Acc@5: 100.0000 (99.4592)  time: 0.2162  data: 0.0003  max mem: 2502
Test: [Task 2]  [610/625]  eta: 0:00:03  Loss: 0.2900 (0.2648)  Acc@1: 93.7500 (93.3920)  Acc@5: 100.0000 (99.4067)  time: 0.2168  data: 0.0003  max mem: 2502
Test: [Task 2]  [620/625]  eta: 0:00:01  Loss: 0.3210 (0.2649)  Acc@1: 87.5000 (93.3776)  Acc@5: 100.0000 (99.4163)  time: 0.2165  data: 0.0003  max mem: 2502
Test: [Task 2]  [624/625]  eta: 0:00:00  Loss: 0.2923 (0.2645)  Acc@1: 93.7500 (93.3900)  Acc@5: 100.0000 (99.4200)  time: 0.2163  data: 0.0003  max mem: 2502
Test: [Task 2] Total time: 0:02:16 (0.2179 s / it)
* Acc@1 93.390 Acc@5 99.420 loss 0.265
Test: [Task 3]  [  0/625]  eta: 0:06:31  Loss: 0.2369 (0.2369)  Acc@1: 93.7500 (93.7500)  Acc@5: 93.7500 (93.7500)  time: 0.6265  data: 0.4116  max mem: 2502
Test: [Task 3]  [ 10/625]  eta: 0:02:36  Loss: 0.2369 (0.2142)  Acc@1: 100.0000 (96.5909)  Acc@5: 100.0000 (99.4318)  time: 0.2539  data: 0.0380  max mem: 2502
Test: [Task 3]  [ 20/625]  eta: 0:02:23  Loss: 0.2310 (0.2286)  Acc@1: 100.0000 (95.5357)  Acc@5: 100.0000 (99.1071)  time: 0.2169  data: 0.0005  max mem: 2502
Test: [Task 3]  [ 30/625]  eta: 0:02:16  Loss: 0.2186 (0.2250)  Acc@1: 93.7500 (95.9677)  Acc@5: 100.0000 (99.1935)  time: 0.2161  data: 0.0003  max mem: 2502
Test: [Task 3]  [ 40/625]  eta: 0:02:12  Loss: 0.1434 (0.2032)  Acc@1: 100.0000 (96.4939)  Acc@5: 100.0000 (99.3902)  time: 0.2154  data: 0.0005  max mem: 2502
Test: [Task 3]  [ 50/625]  eta: 0:02:08  Loss: 0.1434 (0.2002)  Acc@1: 100.0000 (96.5686)  Acc@5: 100.0000 (99.3873)  time: 0.2153  data: 0.0005  max mem: 2502
Test: [Task 3]  [ 60/625]  eta: 0:02:05  Loss: 0.1769 (0.1973)  Acc@1: 100.0000 (96.8238)  Acc@5: 100.0000 (99.4877)  time: 0.2146  data: 0.0003  max mem: 2502
Test: [Task 3]  [ 70/625]  eta: 0:02:02  Loss: 0.1158 (0.1850)  Acc@1: 100.0000 (97.0951)  Acc@5: 100.0000 (99.4718)  time: 0.2146  data: 0.0003  max mem: 2502
Test: [Task 3]  [ 80/625]  eta: 0:02:00  Loss: 0.1085 (0.1890)  Acc@1: 100.0000 (97.0679)  Acc@5: 100.0000 (99.5370)  time: 0.2151  data: 0.0006  max mem: 2502
Test: [Task 3]  [ 90/625]  eta: 0:01:57  Loss: 0.1387 (0.1900)  Acc@1: 100.0000 (97.0467)  Acc@5: 100.0000 (99.4505)  time: 0.2154  data: 0.0006  max mem: 2502
Test: [Task 3]  [100/625]  eta: 0:01:55  Loss: 0.1400 (0.1878)  Acc@1: 100.0000 (97.1535)  Acc@5: 100.0000 (99.5050)  time: 0.2156  data: 0.0010  max mem: 2502
Test: [Task 3]  [110/625]  eta: 0:01:52  Loss: 0.1318 (0.1833)  Acc@1: 100.0000 (97.3536)  Acc@5: 100.0000 (99.5495)  time: 0.2167  data: 0.0018  max mem: 2502
Test: [Task 3]  [120/625]  eta: 0:01:50  Loss: 0.1248 (0.1834)  Acc@1: 100.0000 (97.3140)  Acc@5: 100.0000 (99.5868)  time: 0.2170  data: 0.0011  max mem: 2502
Test: [Task 3]  [130/625]  eta: 0:01:48  Loss: 0.1584 (0.1826)  Acc@1: 100.0000 (97.3760)  Acc@5: 100.0000 (99.5706)  time: 0.2188  data: 0.0011  max mem: 2502
Test: [Task 3]  [140/625]  eta: 0:01:46  Loss: 0.1628 (0.1881)  Acc@1: 100.0000 (97.2074)  Acc@5: 100.0000 (99.5124)  time: 0.2220  data: 0.0014  max mem: 2502
Test: [Task 3]  [150/625]  eta: 0:01:44  Loss: 0.1897 (0.1917)  Acc@1: 100.0000 (97.2682)  Acc@5: 100.0000 (99.4619)  time: 0.2193  data: 0.0006  max mem: 2502
Test: [Task 3]  [160/625]  eta: 0:01:42  Loss: 0.1471 (0.1920)  Acc@1: 100.0000 (97.2438)  Acc@5: 100.0000 (99.4177)  time: 0.2182  data: 0.0006  max mem: 2502
Test: [Task 3]  [170/625]  eta: 0:01:39  Loss: 0.1239 (0.1916)  Acc@1: 100.0000 (97.2222)  Acc@5: 100.0000 (99.4518)  time: 0.2181  data: 0.0006  max mem: 2502
Test: [Task 3]  [180/625]  eta: 0:01:37  Loss: 0.2117 (0.1957)  Acc@1: 93.7500 (97.0649)  Acc@5: 100.0000 (99.4130)  time: 0.2167  data: 0.0004  max mem: 2502
Test: [Task 3]  [190/625]  eta: 0:01:35  Loss: 0.2008 (0.1943)  Acc@1: 93.7500 (97.0550)  Acc@5: 100.0000 (99.4110)  time: 0.2191  data: 0.0007  max mem: 2502
Test: [Task 3]  [200/625]  eta: 0:01:33  Loss: 0.2008 (0.1987)  Acc@1: 93.7500 (96.8905)  Acc@5: 100.0000 (99.4092)  time: 0.2200  data: 0.0009  max mem: 2502
Test: [Task 3]  [210/625]  eta: 0:01:30  Loss: 0.1756 (0.1995)  Acc@1: 100.0000 (96.8898)  Acc@5: 100.0000 (99.4076)  time: 0.2187  data: 0.0007  max mem: 2502
Test: [Task 3]  [220/625]  eta: 0:01:28  Loss: 0.1454 (0.2019)  Acc@1: 100.0000 (96.8043)  Acc@5: 100.0000 (99.4061)  time: 0.2166  data: 0.0006  max mem: 2502
Test: [Task 3]  [230/625]  eta: 0:01:26  Loss: 0.1786 (0.2017)  Acc@1: 93.7500 (96.8344)  Acc@5: 100.0000 (99.4048)  time: 0.2154  data: 0.0003  max mem: 2502
Test: [Task 3]  [240/625]  eta: 0:01:24  Loss: 0.1539 (0.2042)  Acc@1: 93.7500 (96.7324)  Acc@5: 100.0000 (99.3776)  time: 0.2154  data: 0.0004  max mem: 2502
Test: [Task 3]  [250/625]  eta: 0:01:21  Loss: 0.1535 (0.2024)  Acc@1: 93.7500 (96.7131)  Acc@5: 100.0000 (99.4024)  time: 0.2158  data: 0.0004  max mem: 2502
Test: [Task 3]  [260/625]  eta: 0:01:19  Loss: 0.1368 (0.2008)  Acc@1: 100.0000 (96.7433)  Acc@5: 100.0000 (99.4013)  time: 0.2190  data: 0.0004  max mem: 2502
Test: [Task 3]  [270/625]  eta: 0:01:17  Loss: 0.1317 (0.2014)  Acc@1: 100.0000 (96.7020)  Acc@5: 100.0000 (99.4004)  time: 0.2191  data: 0.0004  max mem: 2502
Test: [Task 3]  [280/625]  eta: 0:01:15  Loss: 0.1239 (0.2008)  Acc@1: 93.7500 (96.7082)  Acc@5: 100.0000 (99.3995)  time: 0.2162  data: 0.0004  max mem: 2502
Test: [Task 3]  [290/625]  eta: 0:01:13  Loss: 0.1532 (0.2013)  Acc@1: 93.7500 (96.6280)  Acc@5: 100.0000 (99.4201)  time: 0.2173  data: 0.0010  max mem: 2502
Test: [Task 3]  [300/625]  eta: 0:01:11  Loss: 0.1532 (0.2014)  Acc@1: 93.7500 (96.5947)  Acc@5: 100.0000 (99.4394)  time: 0.2186  data: 0.0011  max mem: 2502
Test: [Task 3]  [310/625]  eta: 0:01:08  Loss: 0.1295 (0.2036)  Acc@1: 100.0000 (96.5434)  Acc@5: 100.0000 (99.3569)  time: 0.2172  data: 0.0003  max mem: 2502
Test: [Task 3]  [320/625]  eta: 0:01:06  Loss: 0.1479 (0.2029)  Acc@1: 93.7500 (96.5537)  Acc@5: 100.0000 (99.3380)  time: 0.2154  data: 0.0003  max mem: 2502
Test: [Task 3]  [330/625]  eta: 0:01:04  Loss: 0.1628 (0.2038)  Acc@1: 93.7500 (96.5068)  Acc@5: 100.0000 (99.3391)  time: 0.2157  data: 0.0003  max mem: 2502
Test: [Task 3]  [340/625]  eta: 0:01:02  Loss: 0.1584 (0.2020)  Acc@1: 100.0000 (96.5909)  Acc@5: 100.0000 (99.3585)  time: 0.2159  data: 0.0004  max mem: 2502
Test: [Task 3]  [350/625]  eta: 0:00:59  Loss: 0.1610 (0.2023)  Acc@1: 100.0000 (96.5812)  Acc@5: 100.0000 (99.3412)  time: 0.2155  data: 0.0004  max mem: 2502
Test: [Task 3]  [360/625]  eta: 0:00:57  Loss: 0.1819 (0.2035)  Acc@1: 93.7500 (96.5374)  Acc@5: 100.0000 (99.3421)  time: 0.2149  data: 0.0003  max mem: 2502
Test: [Task 3]  [370/625]  eta: 0:00:55  Loss: 0.2085 (0.2043)  Acc@1: 93.7500 (96.4791)  Acc@5: 100.0000 (99.3430)  time: 0.2144  data: 0.0002  max mem: 2502
Test: [Task 3]  [380/625]  eta: 0:00:53  Loss: 0.1624 (0.2031)  Acc@1: 93.7500 (96.5223)  Acc@5: 100.0000 (99.3602)  time: 0.2142  data: 0.0002  max mem: 2502
Test: [Task 3]  [390/625]  eta: 0:00:51  Loss: 0.1286 (0.2045)  Acc@1: 100.0000 (96.4354)  Acc@5: 100.0000 (99.3766)  time: 0.2146  data: 0.0002  max mem: 2502
Test: [Task 3]  [400/625]  eta: 0:00:48  Loss: 0.1563 (0.2039)  Acc@1: 93.7500 (96.4152)  Acc@5: 100.0000 (99.3766)  time: 0.2149  data: 0.0003  max mem: 2502
Test: [Task 3]  [410/625]  eta: 0:00:46  Loss: 0.1563 (0.2046)  Acc@1: 100.0000 (96.4112)  Acc@5: 100.0000 (99.3765)  time: 0.2157  data: 0.0003  max mem: 2502
Test: [Task 3]  [420/625]  eta: 0:00:44  Loss: 0.1351 (0.2046)  Acc@1: 100.0000 (96.4222)  Acc@5: 100.0000 (99.3765)  time: 0.2158  data: 0.0003  max mem: 2502
Test: [Task 3]  [430/625]  eta: 0:00:42  Loss: 0.1351 (0.2044)  Acc@1: 100.0000 (96.4182)  Acc@5: 100.0000 (99.3765)  time: 0.2165  data: 0.0004  max mem: 2502
Test: [Task 3]  [440/625]  eta: 0:00:40  Loss: 0.1691 (0.2060)  Acc@1: 93.7500 (96.3719)  Acc@5: 100.0000 (99.3339)  time: 0.2171  data: 0.0004  max mem: 2502
Test: [Task 3]  [450/625]  eta: 0:00:38  Loss: 0.1675 (0.2061)  Acc@1: 100.0000 (96.4108)  Acc@5: 100.0000 (99.3348)  time: 0.2161  data: 0.0004  max mem: 2502
Test: [Task 3]  [460/625]  eta: 0:00:35  Loss: 0.1169 (0.2055)  Acc@1: 100.0000 (96.4344)  Acc@5: 100.0000 (99.3357)  time: 0.2159  data: 0.0004  max mem: 2502
Test: [Task 3]  [470/625]  eta: 0:00:33  Loss: 0.1314 (0.2052)  Acc@1: 100.0000 (96.4305)  Acc@5: 100.0000 (99.3365)  time: 0.2168  data: 0.0004  max mem: 2502
Test: [Task 3]  [480/625]  eta: 0:00:31  Loss: 0.1979 (0.2065)  Acc@1: 100.0000 (96.4397)  Acc@5: 100.0000 (99.3243)  time: 0.2187  data: 0.0004  max mem: 2502
Test: [Task 3]  [490/625]  eta: 0:00:29  Loss: 0.1990 (0.2065)  Acc@1: 100.0000 (96.4358)  Acc@5: 100.0000 (99.3126)  time: 0.2198  data: 0.0010  max mem: 2502
Test: [Task 3]  [500/625]  eta: 0:00:27  Loss: 0.1670 (0.2057)  Acc@1: 100.0000 (96.4321)  Acc@5: 100.0000 (99.3263)  time: 0.2182  data: 0.0011  max mem: 2502
Test: [Task 3]  [510/625]  eta: 0:00:25  Loss: 0.1009 (0.2053)  Acc@1: 100.0000 (96.4286)  Acc@5: 100.0000 (99.3395)  time: 0.2172  data: 0.0005  max mem: 2502
Test: [Task 3]  [520/625]  eta: 0:00:22  Loss: 0.1612 (0.2049)  Acc@1: 100.0000 (96.4251)  Acc@5: 100.0000 (99.3522)  time: 0.2180  data: 0.0011  max mem: 2502
Test: [Task 3]  [530/625]  eta: 0:00:20  Loss: 0.1612 (0.2065)  Acc@1: 93.7500 (96.3865)  Acc@5: 100.0000 (99.3644)  time: 0.2169  data: 0.0010  max mem: 2502
Test: [Task 3]  [540/625]  eta: 0:00:18  Loss: 0.2386 (0.2076)  Acc@1: 93.7500 (96.3840)  Acc@5: 100.0000 (99.3415)  time: 0.2166  data: 0.0011  max mem: 2502
Test: [Task 3]  [550/625]  eta: 0:00:16  Loss: 0.1996 (0.2087)  Acc@1: 93.7500 (96.3702)  Acc@5: 100.0000 (99.3194)  time: 0.2204  data: 0.0015  max mem: 2502
Test: [Task 3]  [560/625]  eta: 0:00:14  Loss: 0.1834 (0.2087)  Acc@1: 93.7500 (96.3681)  Acc@5: 100.0000 (99.3204)  time: 0.2208  data: 0.0012  max mem: 2502
Test: [Task 3]  [570/625]  eta: 0:00:11  Loss: 0.1883 (0.2081)  Acc@1: 100.0000 (96.3879)  Acc@5: 100.0000 (99.3214)  time: 0.2187  data: 0.0008  max mem: 2502
Test: [Task 3]  [580/625]  eta: 0:00:09  Loss: 0.1883 (0.2095)  Acc@1: 93.7500 (96.3210)  Acc@5: 100.0000 (99.3223)  time: 0.2169  data: 0.0004  max mem: 2502
Test: [Task 3]  [590/625]  eta: 0:00:07  Loss: 0.1764 (0.2089)  Acc@1: 93.7500 (96.3515)  Acc@5: 100.0000 (99.3338)  time: 0.2152  data: 0.0003  max mem: 2502
Test: [Task 3]  [600/625]  eta: 0:00:05  Loss: 0.1764 (0.2087)  Acc@1: 100.0000 (96.3290)  Acc@5: 100.0000 (99.3240)  time: 0.2159  data: 0.0004  max mem: 2502
Test: [Task 3]  [610/625]  eta: 0:00:03  Loss: 0.1781 (0.2081)  Acc@1: 93.7500 (96.3277)  Acc@5: 100.0000 (99.3351)  time: 0.2167  data: 0.0004  max mem: 2502
Test: [Task 3]  [620/625]  eta: 0:00:01  Loss: 0.1854 (0.2089)  Acc@1: 93.7500 (96.3164)  Acc@5: 100.0000 (99.3357)  time: 0.2170  data: 0.0004  max mem: 2502
Test: [Task 3]  [624/625]  eta: 0:00:00  Loss: 0.1789 (0.2083)  Acc@1: 93.7500 (96.3400)  Acc@5: 100.0000 (99.3400)  time: 0.2164  data: 0.0003  max mem: 2502
Test: [Task 3] Total time: 0:02:16 (0.2179 s / it)
* Acc@1 96.340 Acc@5 99.340 loss 0.208
{0: {0: 26032, 1: 26032, 2: 26032, 3: 26032, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0, 10: 0, 11: 0, 12: 0, 13: 0, 14: 0, 15: 0, 16: 0, 17: 0, 18: 0, 19: 0}, 1: {0: 0, 1: 0, 2: 0, 3: 0, 4: 10000, 5: 10000, 6: 10000, 7: 10000, 8: 0, 9: 0, 10: 0, 11: 0, 12: 0, 13: 0, 14: 0, 15: 0, 16: 0, 17: 0, 18: 0, 19: 0}, 2: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 10000, 9: 10000, 10: 10000, 11: 10000, 12: 0, 13: 0, 14: 0, 15: 0, 16: 0, 17: 0, 18: 0, 19: 0}}
[Average accuracy till task3]	Acc@1: 86.8054	Acc@5: 97.5827	Loss: 0.5340	Forgetting: 7.7810	Backward: -7.7810
Train: Epoch[1/5]  [   0/1142]  eta: 0:17:27  Lr: 0.001875  Loss: 1.1352  Acc@1: 31.2500 (31.2500)  Acc@5: 62.5000 (62.5000)  time: 0.9169  data: 0.5541  max mem: 2502
Train: Epoch[1/5]  [  10/1142]  eta: 0:07:29  Lr: 0.001875  Loss: 0.9183  Acc@1: 31.2500 (26.1364)  Acc@5: 75.0000 (71.0227)  time: 0.3969  data: 0.0506  max mem: 2502
Train: Epoch[1/5]  [  20/1142]  eta: 0:06:57  Lr: 0.001875  Loss: 0.5325  Acc@1: 31.2500 (32.1429)  Acc@5: 75.0000 (75.2976)  time: 0.3452  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [  30/1142]  eta: 0:06:45  Lr: 0.001875  Loss: 0.3842  Acc@1: 37.5000 (36.4919)  Acc@5: 81.2500 (78.4274)  time: 0.3470  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [  40/1142]  eta: 0:06:37  Lr: 0.001875  Loss: 0.5600  Acc@1: 50.0000 (38.8720)  Acc@5: 87.5000 (81.2500)  time: 0.3485  data: 0.0009  max mem: 2502
Train: Epoch[1/5]  [  50/1142]  eta: 0:06:30  Lr: 0.001875  Loss: 0.2367  Acc@1: 50.0000 (42.4020)  Acc@5: 93.7500 (84.1912)  time: 0.3471  data: 0.0009  max mem: 2502
Train: Epoch[1/5]  [  60/1142]  eta: 0:06:25  Lr: 0.001875  Loss: 0.3961  Acc@1: 50.0000 (43.3402)  Acc@5: 93.7500 (84.6311)  time: 0.3463  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [  70/1142]  eta: 0:06:20  Lr: 0.001875  Loss: 0.4897  Acc@1: 50.0000 (43.9261)  Acc@5: 87.5000 (85.0352)  time: 0.3482  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [  80/1142]  eta: 0:06:16  Lr: 0.001875  Loss: -0.0600  Acc@1: 50.0000 (45.2160)  Acc@5: 87.5000 (85.3395)  time: 0.3498  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [  90/1142]  eta: 0:06:11  Lr: 0.001875  Loss: -0.2149  Acc@1: 50.0000 (45.6731)  Acc@5: 87.5000 (85.7143)  time: 0.3482  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [ 100/1142]  eta: 0:06:07  Lr: 0.001875  Loss: -0.1502  Acc@1: 50.0000 (47.6485)  Acc@5: 87.5000 (86.2005)  time: 0.3468  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [ 110/1142]  eta: 0:06:03  Lr: 0.001875  Loss: -0.1889  Acc@1: 56.2500 (48.3108)  Acc@5: 87.5000 (86.2050)  time: 0.3486  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [ 120/1142]  eta: 0:06:00  Lr: 0.001875  Loss: 0.3586  Acc@1: 56.2500 (49.3285)  Acc@5: 93.7500 (86.9835)  time: 0.3526  data: 0.0008  max mem: 2502
Train: Epoch[1/5]  [ 130/1142]  eta: 0:05:56  Lr: 0.001875  Loss: -0.6548  Acc@1: 56.2500 (49.9523)  Acc@5: 93.7500 (87.2615)  time: 0.3504  data: 0.0008  max mem: 2502
Train: Epoch[1/5]  [ 140/1142]  eta: 0:05:52  Lr: 0.001875  Loss: -0.2312  Acc@1: 56.2500 (50.3103)  Acc@5: 87.5000 (87.3670)  time: 0.3462  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [ 150/1142]  eta: 0:05:49  Lr: 0.001875  Loss: -0.0907  Acc@1: 62.5000 (51.1175)  Acc@5: 93.7500 (87.7483)  time: 0.3501  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [ 160/1142]  eta: 0:05:45  Lr: 0.001875  Loss: -0.1593  Acc@1: 62.5000 (51.3975)  Acc@5: 93.7500 (87.9270)  time: 0.3513  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [ 170/1142]  eta: 0:05:41  Lr: 0.001875  Loss: -0.3304  Acc@1: 56.2500 (51.8640)  Acc@5: 93.7500 (88.2310)  time: 0.3473  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [ 180/1142]  eta: 0:05:37  Lr: 0.001875  Loss: 0.0920  Acc@1: 56.2500 (51.9682)  Acc@5: 93.7500 (88.2942)  time: 0.3459  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [ 190/1142]  eta: 0:05:34  Lr: 0.001875  Loss: 0.2993  Acc@1: 50.0000 (51.9961)  Acc@5: 87.5000 (88.2526)  time: 0.3478  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [ 200/1142]  eta: 0:05:30  Lr: 0.001875  Loss: -0.1110  Acc@1: 56.2500 (52.7052)  Acc@5: 87.5000 (88.4639)  time: 0.3500  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [ 210/1142]  eta: 0:05:27  Lr: 0.001875  Loss: -0.0861  Acc@1: 62.5000 (52.9917)  Acc@5: 93.7500 (88.6552)  time: 0.3494  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [ 220/1142]  eta: 0:05:23  Lr: 0.001875  Loss: -0.1222  Acc@1: 56.2500 (53.3371)  Acc@5: 93.7500 (88.7726)  time: 0.3483  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [ 230/1142]  eta: 0:05:19  Lr: 0.001875  Loss: 0.0120  Acc@1: 56.2500 (53.5714)  Acc@5: 93.7500 (88.9069)  time: 0.3468  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [ 240/1142]  eta: 0:05:16  Lr: 0.001875  Loss: -0.0406  Acc@1: 56.2500 (53.9678)  Acc@5: 93.7500 (88.9782)  time: 0.3472  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [ 250/1142]  eta: 0:05:12  Lr: 0.001875  Loss: -0.1533  Acc@1: 56.2500 (54.1584)  Acc@5: 93.7500 (89.0936)  time: 0.3472  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [ 260/1142]  eta: 0:05:08  Lr: 0.001875  Loss: 0.1212  Acc@1: 56.2500 (54.2146)  Acc@5: 93.7500 (89.2002)  time: 0.3454  data: 0.0002  max mem: 2502
Train: Epoch[1/5]  [ 270/1142]  eta: 0:05:05  Lr: 0.001875  Loss: -0.5398  Acc@1: 56.2500 (54.4280)  Acc@5: 93.7500 (89.3911)  time: 0.3471  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [ 280/1142]  eta: 0:05:01  Lr: 0.001875  Loss: -0.2519  Acc@1: 56.2500 (54.6931)  Acc@5: 93.7500 (89.5018)  time: 0.3492  data: 0.0011  max mem: 2502
Train: Epoch[1/5]  [ 290/1142]  eta: 0:04:58  Lr: 0.001875  Loss: -0.1408  Acc@1: 56.2500 (54.7466)  Acc@5: 93.7500 (89.6263)  time: 0.3481  data: 0.0010  max mem: 2502
Train: Epoch[1/5]  [ 300/1142]  eta: 0:04:54  Lr: 0.001875  Loss: -0.2987  Acc@1: 56.2500 (54.8796)  Acc@5: 93.7500 (89.6595)  time: 0.3467  data: 0.0007  max mem: 2502
Train: Epoch[1/5]  [ 310/1142]  eta: 0:04:51  Lr: 0.001875  Loss: -0.3819  Acc@1: 62.5000 (55.1849)  Acc@5: 93.7500 (89.7508)  time: 0.3509  data: 0.0019  max mem: 2502
Train: Epoch[1/5]  [ 320/1142]  eta: 0:04:47  Lr: 0.001875  Loss: -0.3548  Acc@1: 62.5000 (55.3349)  Acc@5: 93.7500 (89.7780)  time: 0.3558  data: 0.0030  max mem: 2502
Train: Epoch[1/5]  [ 330/1142]  eta: 0:04:44  Lr: 0.001875  Loss: -0.0942  Acc@1: 62.5000 (55.4381)  Acc@5: 87.5000 (89.7659)  time: 0.3531  data: 0.0018  max mem: 2502
Train: Epoch[1/5]  [ 340/1142]  eta: 0:04:40  Lr: 0.001875  Loss: 0.1742  Acc@1: 62.5000 (55.6268)  Acc@5: 87.5000 (89.6994)  time: 0.3489  data: 0.0007  max mem: 2502
Train: Epoch[1/5]  [ 350/1142]  eta: 0:04:37  Lr: 0.001875  Loss: -0.3927  Acc@1: 62.5000 (55.7158)  Acc@5: 93.7500 (89.7792)  time: 0.3487  data: 0.0006  max mem: 2502
Train: Epoch[1/5]  [ 360/1142]  eta: 0:04:33  Lr: 0.001875  Loss: -0.3111  Acc@1: 62.5000 (55.9730)  Acc@5: 93.7500 (89.9065)  time: 0.3515  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [ 370/1142]  eta: 0:04:30  Lr: 0.001875  Loss: -0.3581  Acc@1: 62.5000 (56.1658)  Acc@5: 93.7500 (90.0438)  time: 0.3537  data: 0.0007  max mem: 2502
Train: Epoch[1/5]  [ 380/1142]  eta: 0:04:26  Lr: 0.001875  Loss: 0.0297  Acc@1: 62.5000 (56.2664)  Acc@5: 93.7500 (90.0262)  time: 0.3505  data: 0.0006  max mem: 2502
Train: Epoch[1/5]  [ 390/1142]  eta: 0:04:23  Lr: 0.001875  Loss: -0.3274  Acc@1: 56.2500 (56.3619)  Acc@5: 93.7500 (90.1854)  time: 0.3476  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [ 400/1142]  eta: 0:04:19  Lr: 0.001875  Loss: -0.1643  Acc@1: 56.2500 (56.4682)  Acc@5: 93.7500 (90.2120)  time: 0.3508  data: 0.0010  max mem: 2502
Train: Epoch[1/5]  [ 410/1142]  eta: 0:04:16  Lr: 0.001875  Loss: -0.1469  Acc@1: 62.5000 (56.8279)  Acc@5: 93.7500 (90.2524)  time: 0.3516  data: 0.0012  max mem: 2502
Train: Epoch[1/5]  [ 420/1142]  eta: 0:04:12  Lr: 0.001875  Loss: -0.5078  Acc@1: 62.5000 (56.7844)  Acc@5: 93.7500 (90.2464)  time: 0.3485  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [ 430/1142]  eta: 0:04:09  Lr: 0.001875  Loss: -0.2568  Acc@1: 56.2500 (56.9171)  Acc@5: 93.7500 (90.3422)  time: 0.3469  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [ 440/1142]  eta: 0:04:05  Lr: 0.001875  Loss: -0.4944  Acc@1: 62.5000 (56.9728)  Acc@5: 93.7500 (90.4195)  time: 0.3467  data: 0.0007  max mem: 2502
Train: Epoch[1/5]  [ 450/1142]  eta: 0:04:02  Lr: 0.001875  Loss: -0.4544  Acc@1: 62.5000 (57.2201)  Acc@5: 93.7500 (90.4795)  time: 0.3479  data: 0.0012  max mem: 2502
Train: Epoch[1/5]  [ 460/1142]  eta: 0:03:58  Lr: 0.001875  Loss: -0.2116  Acc@1: 62.5000 (57.2533)  Acc@5: 93.7500 (90.5233)  time: 0.3464  data: 0.0010  max mem: 2502
Train: Epoch[1/5]  [ 470/1142]  eta: 0:03:55  Lr: 0.001875  Loss: -0.6506  Acc@1: 62.5000 (57.4575)  Acc@5: 93.7500 (90.5918)  time: 0.3465  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [ 480/1142]  eta: 0:03:51  Lr: 0.001875  Loss: 0.5016  Acc@1: 62.5000 (57.4324)  Acc@5: 93.7500 (90.6055)  time: 0.3532  data: 0.0012  max mem: 2502
Train: Epoch[1/5]  [ 490/1142]  eta: 0:03:48  Lr: 0.001875  Loss: -0.0784  Acc@1: 56.2500 (57.4847)  Acc@5: 93.7500 (90.6314)  time: 0.3584  data: 0.0019  max mem: 2502
Train: Epoch[1/5]  [ 500/1142]  eta: 0:03:44  Lr: 0.001875  Loss: -0.0636  Acc@1: 62.5000 (57.6722)  Acc@5: 93.7500 (90.6811)  time: 0.3534  data: 0.0011  max mem: 2502
Train: Epoch[1/5]  [ 510/1142]  eta: 0:03:41  Lr: 0.001875  Loss: -0.7631  Acc@1: 62.5000 (57.7666)  Acc@5: 93.7500 (90.7412)  time: 0.3500  data: 0.0006  max mem: 2502
Train: Epoch[1/5]  [ 520/1142]  eta: 0:03:37  Lr: 0.001875  Loss: -0.1767  Acc@1: 62.5000 (57.7975)  Acc@5: 93.7500 (90.7390)  time: 0.3525  data: 0.0009  max mem: 2502
Train: Epoch[1/5]  [ 530/1142]  eta: 0:03:34  Lr: 0.001875  Loss: -0.0341  Acc@1: 62.5000 (57.9449)  Acc@5: 93.7500 (90.8074)  time: 0.3548  data: 0.0008  max mem: 2502
Train: Epoch[1/5]  [ 540/1142]  eta: 0:03:30  Lr: 0.001875  Loss: -0.1387  Acc@1: 68.7500 (58.0291)  Acc@5: 93.7500 (90.8503)  time: 0.3546  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [ 550/1142]  eta: 0:03:27  Lr: 0.001875  Loss: -0.3764  Acc@1: 62.5000 (58.0649)  Acc@5: 93.7500 (90.8916)  time: 0.3532  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [ 560/1142]  eta: 0:03:23  Lr: 0.001875  Loss: -0.5485  Acc@1: 62.5000 (58.1551)  Acc@5: 93.7500 (90.8868)  time: 0.3502  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [ 570/1142]  eta: 0:03:20  Lr: 0.001875  Loss: -0.3155  Acc@1: 62.5000 (58.2531)  Acc@5: 87.5000 (90.8932)  time: 0.3474  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [ 580/1142]  eta: 0:03:16  Lr: 0.001875  Loss: -0.0636  Acc@1: 68.7500 (58.4015)  Acc@5: 93.7500 (90.9316)  time: 0.3494  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [ 590/1142]  eta: 0:03:13  Lr: 0.001875  Loss: 0.1609  Acc@1: 62.5000 (58.4391)  Acc@5: 93.7500 (90.9898)  time: 0.3515  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [ 600/1142]  eta: 0:03:09  Lr: 0.001875  Loss: -0.7413  Acc@1: 62.5000 (58.5691)  Acc@5: 93.7500 (91.0046)  time: 0.3498  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [ 610/1142]  eta: 0:03:06  Lr: 0.001875  Loss: -0.1979  Acc@1: 68.7500 (58.7357)  Acc@5: 93.7500 (91.0495)  time: 0.3464  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [ 620/1142]  eta: 0:03:02  Lr: 0.001875  Loss: -0.4706  Acc@1: 68.7500 (58.8164)  Acc@5: 93.7500 (91.0427)  time: 0.3473  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [ 630/1142]  eta: 0:02:59  Lr: 0.001875  Loss: -0.5317  Acc@1: 62.5000 (58.8550)  Acc@5: 93.7500 (91.1054)  time: 0.3493  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [ 640/1142]  eta: 0:02:55  Lr: 0.001875  Loss: -0.1901  Acc@1: 62.5000 (58.9704)  Acc@5: 93.7500 (91.1564)  time: 0.3475  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [ 650/1142]  eta: 0:02:52  Lr: 0.001875  Loss: -0.1915  Acc@1: 68.7500 (59.0246)  Acc@5: 93.7500 (91.1578)  time: 0.3461  data: 0.0007  max mem: 2502
Train: Epoch[1/5]  [ 660/1142]  eta: 0:02:48  Lr: 0.001875  Loss: -0.8869  Acc@1: 56.2500 (59.0299)  Acc@5: 93.7500 (91.1498)  time: 0.3514  data: 0.0008  max mem: 2502
Train: Epoch[1/5]  [ 670/1142]  eta: 0:02:45  Lr: 0.001875  Loss: -0.2490  Acc@1: 62.5000 (59.1747)  Acc@5: 93.7500 (91.1699)  time: 0.3535  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [ 680/1142]  eta: 0:02:41  Lr: 0.001875  Loss: -0.3592  Acc@1: 68.7500 (59.2786)  Acc@5: 93.7500 (91.2170)  time: 0.3508  data: 0.0006  max mem: 2502
Train: Epoch[1/5]  [ 690/1142]  eta: 0:02:38  Lr: 0.001875  Loss: -0.4669  Acc@1: 68.7500 (59.3072)  Acc@5: 93.7500 (91.2627)  time: 0.3507  data: 0.0013  max mem: 2502
Train: Epoch[1/5]  [ 700/1142]  eta: 0:02:34  Lr: 0.001875  Loss: -0.5163  Acc@1: 62.5000 (59.4240)  Acc@5: 93.7500 (91.2981)  time: 0.3510  data: 0.0013  max mem: 2502
Train: Epoch[1/5]  [ 710/1142]  eta: 0:02:31  Lr: 0.001875  Loss: -0.4891  Acc@1: 68.7500 (59.5288)  Acc@5: 93.7500 (91.3238)  time: 0.3538  data: 0.0008  max mem: 2502
Train: Epoch[1/5]  [ 720/1142]  eta: 0:02:27  Lr: 0.001875  Loss: -0.4670  Acc@1: 68.7500 (59.6047)  Acc@5: 93.7500 (91.3488)  time: 0.3522  data: 0.0007  max mem: 2502
Train: Epoch[1/5]  [ 730/1142]  eta: 0:02:24  Lr: 0.001875  Loss: -0.0929  Acc@1: 62.5000 (59.6785)  Acc@5: 93.7500 (91.3817)  time: 0.3482  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [ 740/1142]  eta: 0:02:20  Lr: 0.001875  Loss: -0.3255  Acc@1: 62.5000 (59.7166)  Acc@5: 93.7500 (91.3883)  time: 0.3506  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [ 750/1142]  eta: 0:02:17  Lr: 0.001875  Loss: -0.2133  Acc@1: 62.5000 (59.7370)  Acc@5: 93.7500 (91.4364)  time: 0.3557  data: 0.0007  max mem: 2502
Train: Epoch[1/5]  [ 760/1142]  eta: 0:02:13  Lr: 0.001875  Loss: -0.3745  Acc@1: 62.5000 (59.8555)  Acc@5: 93.7500 (91.4750)  time: 0.3544  data: 0.0006  max mem: 2502
Train: Epoch[1/5]  [ 770/1142]  eta: 0:02:10  Lr: 0.001875  Loss: -0.5532  Acc@1: 68.7500 (59.8979)  Acc@5: 93.7500 (91.5126)  time: 0.3486  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [ 780/1142]  eta: 0:02:06  Lr: 0.001875  Loss: -0.3703  Acc@1: 68.7500 (59.9632)  Acc@5: 93.7500 (91.4933)  time: 0.3492  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [ 790/1142]  eta: 0:02:03  Lr: 0.001875  Loss: -0.4519  Acc@1: 68.7500 (60.0980)  Acc@5: 87.5000 (91.5218)  time: 0.3517  data: 0.0008  max mem: 2502
Train: Epoch[1/5]  [ 800/1142]  eta: 0:01:59  Lr: 0.001875  Loss: -0.7265  Acc@1: 68.7500 (60.1904)  Acc@5: 93.7500 (91.5340)  time: 0.3517  data: 0.0008  max mem: 2502
Train: Epoch[1/5]  [ 810/1142]  eta: 0:01:56  Lr: 0.001875  Loss: -0.5376  Acc@1: 68.7500 (60.1957)  Acc@5: 93.7500 (91.5768)  time: 0.3479  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [ 820/1142]  eta: 0:01:52  Lr: 0.001875  Loss: -0.4346  Acc@1: 68.7500 (60.2847)  Acc@5: 93.7500 (91.6261)  time: 0.3446  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [ 830/1142]  eta: 0:01:49  Lr: 0.001875  Loss: -0.4778  Acc@1: 62.5000 (60.2963)  Acc@5: 93.7500 (91.6441)  time: 0.3463  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [ 840/1142]  eta: 0:01:45  Lr: 0.001875  Loss: -0.8078  Acc@1: 62.5000 (60.3597)  Acc@5: 93.7500 (91.6617)  time: 0.3468  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [ 850/1142]  eta: 0:01:42  Lr: 0.001875  Loss: -0.6669  Acc@1: 62.5000 (60.4509)  Acc@5: 93.7500 (91.6569)  time: 0.3472  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [ 860/1142]  eta: 0:01:38  Lr: 0.001875  Loss: -0.1505  Acc@1: 62.5000 (60.4965)  Acc@5: 93.7500 (91.6812)  time: 0.3489  data: 0.0007  max mem: 2502
Train: Epoch[1/5]  [ 870/1142]  eta: 0:01:35  Lr: 0.001875  Loss: -0.3912  Acc@1: 62.5000 (60.5410)  Acc@5: 93.7500 (91.7265)  time: 0.3523  data: 0.0029  max mem: 2502
Train: Epoch[1/5]  [ 880/1142]  eta: 0:01:31  Lr: 0.001875  Loss: -0.3830  Acc@1: 62.5000 (60.5917)  Acc@5: 93.7500 (91.7565)  time: 0.3548  data: 0.0028  max mem: 2502
Train: Epoch[1/5]  [ 890/1142]  eta: 0:01:28  Lr: 0.001875  Loss: -0.4420  Acc@1: 62.5000 (60.6271)  Acc@5: 93.7500 (91.7929)  time: 0.3530  data: 0.0009  max mem: 2502
Train: Epoch[1/5]  [ 900/1142]  eta: 0:01:24  Lr: 0.001875  Loss: -0.1381  Acc@1: 68.7500 (60.7103)  Acc@5: 93.7500 (91.8216)  time: 0.3508  data: 0.0009  max mem: 2502
Train: Epoch[1/5]  [ 910/1142]  eta: 0:01:21  Lr: 0.001875  Loss: 0.0212  Acc@1: 62.5000 (60.6682)  Acc@5: 93.7500 (91.8359)  time: 0.3504  data: 0.0007  max mem: 2502
Train: Epoch[1/5]  [ 920/1142]  eta: 0:01:17  Lr: 0.001875  Loss: -0.7973  Acc@1: 56.2500 (60.6406)  Acc@5: 93.7500 (91.8702)  time: 0.3532  data: 0.0007  max mem: 2502
Train: Epoch[1/5]  [ 930/1142]  eta: 0:01:14  Lr: 0.001875  Loss: -0.4529  Acc@1: 56.2500 (60.6404)  Acc@5: 93.7500 (91.8434)  time: 0.3543  data: 0.0015  max mem: 2502
Train: Epoch[1/5]  [ 940/1142]  eta: 0:01:10  Lr: 0.001875  Loss: -0.3994  Acc@1: 62.5000 (60.6868)  Acc@5: 93.7500 (91.8704)  time: 0.3505  data: 0.0013  max mem: 2502
Train: Epoch[1/5]  [ 950/1142]  eta: 0:01:07  Lr: 0.001875  Loss: -0.3220  Acc@1: 62.5000 (60.6993)  Acc@5: 93.7500 (91.8835)  time: 0.3486  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [ 960/1142]  eta: 0:01:03  Lr: 0.001875  Loss: 0.0797  Acc@1: 62.5000 (60.7375)  Acc@5: 93.7500 (91.9225)  time: 0.3490  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [ 970/1142]  eta: 0:01:00  Lr: 0.001875  Loss: -0.0779  Acc@1: 68.7500 (60.8522)  Acc@5: 100.0000 (91.9670)  time: 0.3495  data: 0.0006  max mem: 2502
Train: Epoch[1/5]  [ 980/1142]  eta: 0:00:56  Lr: 0.001875  Loss: -0.4429  Acc@1: 68.7500 (60.9072)  Acc@5: 93.7500 (91.9852)  time: 0.3497  data: 0.0007  max mem: 2502
Train: Epoch[1/5]  [ 990/1142]  eta: 0:00:53  Lr: 0.001875  Loss: -0.5313  Acc@1: 68.7500 (60.9107)  Acc@5: 93.7500 (92.0283)  time: 0.3487  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [1000/1142]  eta: 0:00:49  Lr: 0.001875  Loss: -0.1684  Acc@1: 62.5000 (60.9515)  Acc@5: 100.0000 (92.0330)  time: 0.3472  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [1010/1142]  eta: 0:00:46  Lr: 0.001875  Loss: -0.7240  Acc@1: 62.5000 (60.9669)  Acc@5: 93.7500 (92.0376)  time: 0.3467  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [1020/1142]  eta: 0:00:42  Lr: 0.001875  Loss: -0.6460  Acc@1: 56.2500 (60.9452)  Acc@5: 93.7500 (92.0666)  time: 0.3468  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [1030/1142]  eta: 0:00:39  Lr: 0.001875  Loss: -0.7142  Acc@1: 62.5000 (60.9784)  Acc@5: 93.7500 (92.0466)  time: 0.3471  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [1040/1142]  eta: 0:00:35  Lr: 0.001875  Loss: -0.1103  Acc@1: 62.5000 (61.0110)  Acc@5: 93.7500 (92.0569)  time: 0.3481  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [1050/1142]  eta: 0:00:32  Lr: 0.001875  Loss: -0.3918  Acc@1: 62.5000 (61.0906)  Acc@5: 93.7500 (92.0849)  time: 0.3521  data: 0.0014  max mem: 2502
Train: Epoch[1/5]  [1060/1142]  eta: 0:00:28  Lr: 0.001875  Loss: -0.6456  Acc@1: 62.5000 (61.0980)  Acc@5: 93.7500 (92.0653)  time: 0.3521  data: 0.0013  max mem: 2502
Train: Epoch[1/5]  [1070/1142]  eta: 0:00:25  Lr: 0.001875  Loss: -0.8722  Acc@1: 62.5000 (61.1578)  Acc@5: 93.7500 (92.0985)  time: 0.3503  data: 0.0006  max mem: 2502
Train: Epoch[1/5]  [1080/1142]  eta: 0:00:21  Lr: 0.001875  Loss: -0.3779  Acc@1: 62.5000 (61.1760)  Acc@5: 100.0000 (92.1253)  time: 0.3503  data: 0.0006  max mem: 2502
Train: Epoch[1/5]  [1090/1142]  eta: 0:00:18  Lr: 0.001875  Loss: -0.2982  Acc@1: 56.2500 (61.1423)  Acc@5: 93.7500 (92.1345)  time: 0.3490  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [1100/1142]  eta: 0:00:14  Lr: 0.001875  Loss: -0.7593  Acc@1: 56.2500 (61.1830)  Acc@5: 93.7500 (92.1662)  time: 0.3530  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [1110/1142]  eta: 0:00:11  Lr: 0.001875  Loss: -0.8252  Acc@1: 68.7500 (61.2455)  Acc@5: 93.7500 (92.1692)  time: 0.3549  data: 0.0006  max mem: 2502
Train: Epoch[1/5]  [1120/1142]  eta: 0:00:07  Lr: 0.001875  Loss: -0.5610  Acc@1: 68.7500 (61.3013)  Acc@5: 87.5000 (92.1666)  time: 0.3520  data: 0.0008  max mem: 2502
Train: Epoch[1/5]  [1130/1142]  eta: 0:00:04  Lr: 0.001875  Loss: -0.5933  Acc@1: 68.7500 (61.3672)  Acc@5: 93.7500 (92.1806)  time: 0.3492  data: 0.0007  max mem: 2502
Train: Epoch[1/5]  [1140/1142]  eta: 0:00:00  Lr: 0.001875  Loss: -0.8051  Acc@1: 62.5000 (61.4045)  Acc@5: 93.7500 (92.2108)  time: 0.3484  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [1141/1142]  eta: 0:00:00  Lr: 0.001875  Loss: 0.3534  Acc@1: 62.5000 (61.3961)  Acc@5: 93.7500 (92.2037)  time: 0.3408  data: 0.0004  max mem: 2502
Train: Epoch[1/5] Total time: 0:06:40 (0.3503 s / it)
{0: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 1: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 2: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 3: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 4: {0: 0, 1: 300000, 2: 0, 3: 18265, 4: 0}, 5: {0: 0, 1: 300000, 2: 0, 3: 18265, 4: 0}, 6: {0: 0, 1: 300000, 2: 0, 3: 18265, 4: 0}, 7: {0: 0, 1: 300000, 2: 0, 3: 18265, 4: 0}, 8: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 9: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 10: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 11: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 12: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 13: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 14: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 15: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 16: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 17: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 18: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 19: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}}
Averaged stats: Lr: 0.001875  Loss: 0.3534  Acc@1: 62.5000 (61.3961)  Acc@5: 93.7500 (92.2037)
Train: Epoch[2/5]  [   0/1142]  eta: 0:17:45  Lr: 0.001875  Loss: -1.0806  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (100.0000)  time: 0.9328  data: 0.5705  max mem: 2502
Train: Epoch[2/5]  [  10/1142]  eta: 0:07:33  Lr: 0.001875  Loss: -0.6338  Acc@1: 75.0000 (73.8636)  Acc@5: 100.0000 (94.3182)  time: 0.4009  data: 0.0522  max mem: 2502
Train: Epoch[2/5]  [  20/1142]  eta: 0:07:01  Lr: 0.001875  Loss: 0.1754  Acc@1: 68.7500 (68.7500)  Acc@5: 93.7500 (92.5595)  time: 0.3479  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [  30/1142]  eta: 0:06:47  Lr: 0.001875  Loss: -0.2647  Acc@1: 68.7500 (68.9516)  Acc@5: 93.7500 (92.5403)  time: 0.3480  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [  40/1142]  eta: 0:06:40  Lr: 0.001875  Loss: 0.2256  Acc@1: 68.7500 (68.5976)  Acc@5: 93.7500 (92.2256)  time: 0.3495  data: 0.0013  max mem: 2502
Train: Epoch[2/5]  [  50/1142]  eta: 0:06:33  Lr: 0.001875  Loss: -0.3012  Acc@1: 68.7500 (68.8725)  Acc@5: 93.7500 (92.5245)  time: 0.3501  data: 0.0014  max mem: 2502
Train: Epoch[2/5]  [  60/1142]  eta: 0:06:26  Lr: 0.001875  Loss: -0.7442  Acc@1: 62.5000 (68.2377)  Acc@5: 93.7500 (92.7254)  time: 0.3467  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [  70/1142]  eta: 0:06:21  Lr: 0.001875  Loss: -0.6681  Acc@1: 62.5000 (68.3979)  Acc@5: 93.7500 (93.0458)  time: 0.3448  data: 0.0002  max mem: 2502
Train: Epoch[2/5]  [  80/1142]  eta: 0:06:17  Lr: 0.001875  Loss: -0.3309  Acc@1: 68.7500 (67.6698)  Acc@5: 93.7500 (93.2870)  time: 0.3495  data: 0.0019  max mem: 2502
Train: Epoch[2/5]  [  90/1142]  eta: 0:06:13  Lr: 0.001875  Loss: -0.0722  Acc@1: 62.5000 (67.3764)  Acc@5: 93.7500 (93.4066)  time: 0.3539  data: 0.0027  max mem: 2502
Train: Epoch[2/5]  [ 100/1142]  eta: 0:06:09  Lr: 0.001875  Loss: -0.3590  Acc@1: 62.5000 (67.0173)  Acc@5: 93.7500 (93.3787)  time: 0.3513  data: 0.0011  max mem: 2502
Train: Epoch[2/5]  [ 110/1142]  eta: 0:06:05  Lr: 0.001875  Loss: -0.5484  Acc@1: 62.5000 (66.6667)  Acc@5: 93.7500 (93.4685)  time: 0.3477  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [ 120/1142]  eta: 0:06:01  Lr: 0.001875  Loss: 0.0741  Acc@1: 62.5000 (66.5289)  Acc@5: 93.7500 (93.2851)  time: 0.3494  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [ 130/1142]  eta: 0:05:58  Lr: 0.001875  Loss: -0.5293  Acc@1: 68.7500 (66.6031)  Acc@5: 93.7500 (93.4160)  time: 0.3565  data: 0.0021  max mem: 2502
Train: Epoch[2/5]  [ 140/1142]  eta: 0:05:54  Lr: 0.001875  Loss: -0.3874  Acc@1: 62.5000 (66.5780)  Acc@5: 93.7500 (93.3954)  time: 0.3557  data: 0.0021  max mem: 2502
Train: Epoch[2/5]  [ 150/1142]  eta: 0:05:50  Lr: 0.001875  Loss: 0.6053  Acc@1: 68.7500 (66.6391)  Acc@5: 93.7500 (93.4189)  time: 0.3492  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [ 160/1142]  eta: 0:05:47  Lr: 0.001875  Loss: -0.8302  Acc@1: 68.7500 (67.0031)  Acc@5: 93.7500 (93.6335)  time: 0.3486  data: 0.0010  max mem: 2502
Train: Epoch[2/5]  [ 170/1142]  eta: 0:05:43  Lr: 0.001875  Loss: 0.0462  Acc@1: 68.7500 (66.8860)  Acc@5: 100.0000 (93.5673)  time: 0.3502  data: 0.0011  max mem: 2502
Train: Epoch[2/5]  [ 180/1142]  eta: 0:05:39  Lr: 0.001875  Loss: -0.4698  Acc@1: 62.5000 (66.6091)  Acc@5: 93.7500 (93.5773)  time: 0.3518  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [ 190/1142]  eta: 0:05:36  Lr: 0.001875  Loss: -0.6003  Acc@1: 68.7500 (66.7866)  Acc@5: 93.7500 (93.6191)  time: 0.3522  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [ 200/1142]  eta: 0:05:32  Lr: 0.001875  Loss: -0.7809  Acc@1: 75.0000 (67.0709)  Acc@5: 93.7500 (93.7189)  time: 0.3494  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [ 210/1142]  eta: 0:05:28  Lr: 0.001875  Loss: 0.3482  Acc@1: 68.7500 (66.7358)  Acc@5: 93.7500 (93.6611)  time: 0.3474  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [ 220/1142]  eta: 0:05:25  Lr: 0.001875  Loss: -0.1885  Acc@1: 62.5000 (66.6572)  Acc@5: 93.7500 (93.5803)  time: 0.3487  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [ 230/1142]  eta: 0:05:21  Lr: 0.001875  Loss: -0.6489  Acc@1: 62.5000 (66.7208)  Acc@5: 93.7500 (93.7229)  time: 0.3474  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [ 240/1142]  eta: 0:05:17  Lr: 0.001875  Loss: -0.6684  Acc@1: 68.7500 (66.7012)  Acc@5: 93.7500 (93.7759)  time: 0.3452  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [ 250/1142]  eta: 0:05:13  Lr: 0.001875  Loss: -0.6338  Acc@1: 62.5000 (66.6335)  Acc@5: 93.7500 (93.8247)  time: 0.3463  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [ 260/1142]  eta: 0:05:10  Lr: 0.001875  Loss: -0.3189  Acc@1: 62.5000 (66.6667)  Acc@5: 93.7500 (93.8937)  time: 0.3508  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [ 270/1142]  eta: 0:05:06  Lr: 0.001875  Loss: -0.2176  Acc@1: 68.7500 (66.6282)  Acc@5: 93.7500 (93.9345)  time: 0.3507  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [ 280/1142]  eta: 0:05:03  Lr: 0.001875  Loss: -0.0954  Acc@1: 68.7500 (66.6148)  Acc@5: 93.7500 (93.9502)  time: 0.3489  data: 0.0009  max mem: 2502
Train: Epoch[2/5]  [ 290/1142]  eta: 0:04:59  Lr: 0.001875  Loss: -0.9684  Acc@1: 68.7500 (66.6237)  Acc@5: 93.7500 (93.9863)  time: 0.3493  data: 0.0009  max mem: 2502
Train: Epoch[2/5]  [ 300/1142]  eta: 0:04:55  Lr: 0.001875  Loss: -0.7497  Acc@1: 62.5000 (66.5490)  Acc@5: 93.7500 (94.0615)  time: 0.3505  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [ 310/1142]  eta: 0:04:52  Lr: 0.001875  Loss: -0.4764  Acc@1: 68.7500 (66.4389)  Acc@5: 100.0000 (94.0715)  time: 0.3528  data: 0.0007  max mem: 2502
Train: Epoch[2/5]  [ 320/1142]  eta: 0:04:49  Lr: 0.001875  Loss: -0.4988  Acc@1: 68.7500 (66.3551)  Acc@5: 93.7500 (94.0226)  time: 0.3530  data: 0.0008  max mem: 2502
Train: Epoch[2/5]  [ 330/1142]  eta: 0:04:45  Lr: 0.001875  Loss: -0.3142  Acc@1: 68.7500 (66.3708)  Acc@5: 93.7500 (94.0144)  time: 0.3510  data: 0.0007  max mem: 2502
Train: Epoch[2/5]  [ 340/1142]  eta: 0:04:41  Lr: 0.001875  Loss: -0.2172  Acc@1: 68.7500 (66.2390)  Acc@5: 93.7500 (93.9333)  time: 0.3487  data: 0.0007  max mem: 2502
Train: Epoch[2/5]  [ 350/1142]  eta: 0:04:38  Lr: 0.001875  Loss: -0.1357  Acc@1: 62.5000 (66.1147)  Acc@5: 93.7500 (93.9103)  time: 0.3545  data: 0.0007  max mem: 2502
Train: Epoch[2/5]  [ 360/1142]  eta: 0:04:35  Lr: 0.001875  Loss: -0.2573  Acc@1: 62.5000 (66.0492)  Acc@5: 93.7500 (93.9404)  time: 0.3583  data: 0.0009  max mem: 2502
Train: Epoch[2/5]  [ 370/1142]  eta: 0:04:31  Lr: 0.001875  Loss: -0.3421  Acc@1: 62.5000 (66.0714)  Acc@5: 93.7500 (93.8848)  time: 0.3518  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [ 380/1142]  eta: 0:04:27  Lr: 0.001875  Loss: -0.7491  Acc@1: 68.7500 (66.0597)  Acc@5: 93.7500 (93.8156)  time: 0.3479  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [ 390/1142]  eta: 0:04:24  Lr: 0.001875  Loss: -0.0069  Acc@1: 68.7500 (66.0965)  Acc@5: 93.7500 (93.8779)  time: 0.3527  data: 0.0012  max mem: 2502
Train: Epoch[2/5]  [ 400/1142]  eta: 0:04:20  Lr: 0.001875  Loss: -0.5431  Acc@1: 62.5000 (66.1160)  Acc@5: 93.7500 (93.8435)  time: 0.3527  data: 0.0012  max mem: 2502
Train: Epoch[2/5]  [ 410/1142]  eta: 0:04:17  Lr: 0.001875  Loss: 0.0324  Acc@1: 62.5000 (65.9672)  Acc@5: 93.7500 (93.8108)  time: 0.3488  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [ 420/1142]  eta: 0:04:13  Lr: 0.001875  Loss: -0.3128  Acc@1: 62.5000 (65.9145)  Acc@5: 93.7500 (93.8242)  time: 0.3475  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [ 430/1142]  eta: 0:04:10  Lr: 0.001875  Loss: -0.3991  Acc@1: 62.5000 (65.9948)  Acc@5: 93.7500 (93.8515)  time: 0.3464  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [ 440/1142]  eta: 0:04:06  Lr: 0.001875  Loss: -0.6281  Acc@1: 68.7500 (66.0431)  Acc@5: 93.7500 (93.8492)  time: 0.3467  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [ 450/1142]  eta: 0:04:02  Lr: 0.001875  Loss: -0.5750  Acc@1: 68.7500 (66.0338)  Acc@5: 93.7500 (93.8609)  time: 0.3458  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [ 460/1142]  eta: 0:03:59  Lr: 0.001875  Loss: -0.5707  Acc@1: 62.5000 (65.9843)  Acc@5: 93.7500 (93.8178)  time: 0.3452  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [ 470/1142]  eta: 0:03:55  Lr: 0.001875  Loss: -1.0095  Acc@1: 62.5000 (65.8970)  Acc@5: 93.7500 (93.8163)  time: 0.3484  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [ 480/1142]  eta: 0:03:52  Lr: 0.001875  Loss: -0.4519  Acc@1: 68.7500 (65.9693)  Acc@5: 93.7500 (93.8540)  time: 0.3535  data: 0.0007  max mem: 2502
Train: Epoch[2/5]  [ 490/1142]  eta: 0:03:48  Lr: 0.001875  Loss: -0.7889  Acc@1: 75.0000 (66.1533)  Acc@5: 93.7500 (93.8646)  time: 0.3525  data: 0.0008  max mem: 2502
Train: Epoch[2/5]  [ 500/1142]  eta: 0:03:45  Lr: 0.001875  Loss: -0.8012  Acc@1: 75.0000 (66.1926)  Acc@5: 93.7500 (93.8249)  time: 0.3489  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [ 510/1142]  eta: 0:03:41  Lr: 0.001875  Loss: -0.5770  Acc@1: 62.5000 (66.1204)  Acc@5: 93.7500 (93.7745)  time: 0.3489  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [ 520/1142]  eta: 0:03:38  Lr: 0.001875  Loss: -0.5204  Acc@1: 62.5000 (66.1708)  Acc@5: 93.7500 (93.7740)  time: 0.3546  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [ 530/1142]  eta: 0:03:34  Lr: 0.001875  Loss: -0.0809  Acc@1: 62.5000 (66.1135)  Acc@5: 93.7500 (93.8324)  time: 0.3556  data: 0.0013  max mem: 2502
Train: Epoch[2/5]  [ 540/1142]  eta: 0:03:31  Lr: 0.001875  Loss: -0.1532  Acc@1: 62.5000 (66.0698)  Acc@5: 93.7500 (93.8078)  time: 0.3493  data: 0.0012  max mem: 2502
Train: Epoch[2/5]  [ 550/1142]  eta: 0:03:27  Lr: 0.001875  Loss: -0.7874  Acc@1: 62.5000 (66.0730)  Acc@5: 93.7500 (93.7840)  time: 0.3482  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [ 560/1142]  eta: 0:03:24  Lr: 0.001875  Loss: -0.3027  Acc@1: 62.5000 (66.0651)  Acc@5: 93.7500 (93.7389)  time: 0.3500  data: 0.0009  max mem: 2502
Train: Epoch[2/5]  [ 570/1142]  eta: 0:03:20  Lr: 0.001875  Loss: -0.2861  Acc@1: 68.7500 (66.0902)  Acc@5: 93.7500 (93.7500)  time: 0.3529  data: 0.0008  max mem: 2502
Train: Epoch[2/5]  [ 580/1142]  eta: 0:03:17  Lr: 0.001875  Loss: -0.4111  Acc@1: 62.5000 (66.0176)  Acc@5: 93.7500 (93.7608)  time: 0.3513  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [ 590/1142]  eta: 0:03:13  Lr: 0.001875  Loss: -0.6433  Acc@1: 68.7500 (66.0639)  Acc@5: 93.7500 (93.8029)  time: 0.3492  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [ 600/1142]  eta: 0:03:10  Lr: 0.001875  Loss: -0.4388  Acc@1: 68.7500 (66.0462)  Acc@5: 93.7500 (93.7604)  time: 0.3495  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [ 610/1142]  eta: 0:03:06  Lr: 0.001875  Loss: -0.4469  Acc@1: 62.5000 (66.0086)  Acc@5: 87.5000 (93.6784)  time: 0.3495  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [ 620/1142]  eta: 0:03:03  Lr: 0.001875  Loss: -0.5927  Acc@1: 62.5000 (65.9118)  Acc@5: 87.5000 (93.6896)  time: 0.3502  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [ 630/1142]  eta: 0:02:59  Lr: 0.001875  Loss: -0.7222  Acc@1: 68.7500 (66.0063)  Acc@5: 93.7500 (93.7005)  time: 0.3482  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [ 640/1142]  eta: 0:02:56  Lr: 0.001875  Loss: -0.7412  Acc@1: 68.7500 (66.0881)  Acc@5: 93.7500 (93.7110)  time: 0.3467  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [ 650/1142]  eta: 0:02:52  Lr: 0.001875  Loss: -0.1586  Acc@1: 68.7500 (66.0330)  Acc@5: 93.7500 (93.6828)  time: 0.3483  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [ 660/1142]  eta: 0:02:49  Lr: 0.001875  Loss: -0.3266  Acc@1: 62.5000 (65.9985)  Acc@5: 93.7500 (93.6365)  time: 0.3484  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [ 670/1142]  eta: 0:02:45  Lr: 0.001875  Loss: -0.1048  Acc@1: 62.5000 (65.9836)  Acc@5: 93.7500 (93.6103)  time: 0.3464  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [ 680/1142]  eta: 0:02:42  Lr: 0.001875  Loss: -0.4386  Acc@1: 62.5000 (65.9600)  Acc@5: 93.7500 (93.6582)  time: 0.3496  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [ 690/1142]  eta: 0:02:38  Lr: 0.001875  Loss: -0.4475  Acc@1: 62.5000 (65.9280)  Acc@5: 93.7500 (93.6415)  time: 0.3526  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [ 700/1142]  eta: 0:02:35  Lr: 0.001875  Loss: -0.6337  Acc@1: 68.7500 (65.9504)  Acc@5: 93.7500 (93.6608)  time: 0.3520  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [ 710/1142]  eta: 0:02:31  Lr: 0.001875  Loss: -0.3051  Acc@1: 68.7500 (65.9371)  Acc@5: 93.7500 (93.6621)  time: 0.3523  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [ 720/1142]  eta: 0:02:28  Lr: 0.001875  Loss: -0.4158  Acc@1: 62.5000 (65.9501)  Acc@5: 93.7500 (93.6546)  time: 0.3531  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [ 730/1142]  eta: 0:02:24  Lr: 0.001875  Loss: -0.6065  Acc@1: 68.7500 (65.9884)  Acc@5: 93.7500 (93.6645)  time: 0.3531  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [ 740/1142]  eta: 0:02:21  Lr: 0.001875  Loss: -0.1293  Acc@1: 68.7500 (66.0172)  Acc@5: 93.7500 (93.6910)  time: 0.3524  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [ 750/1142]  eta: 0:02:17  Lr: 0.001875  Loss: -0.5727  Acc@1: 68.7500 (65.9787)  Acc@5: 93.7500 (93.6917)  time: 0.3555  data: 0.0007  max mem: 2502
Train: Epoch[2/5]  [ 760/1142]  eta: 0:02:14  Lr: 0.001875  Loss: -0.5156  Acc@1: 62.5000 (65.9658)  Acc@5: 93.7500 (93.7007)  time: 0.3538  data: 0.0007  max mem: 2502
Train: Epoch[2/5]  [ 770/1142]  eta: 0:02:10  Lr: 0.001875  Loss: -0.2897  Acc@1: 68.7500 (66.0344)  Acc@5: 93.7500 (93.7095)  time: 0.3479  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [ 780/1142]  eta: 0:02:07  Lr: 0.001875  Loss: -0.3003  Acc@1: 68.7500 (66.0451)  Acc@5: 93.7500 (93.6940)  time: 0.3507  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [ 790/1142]  eta: 0:02:03  Lr: 0.001875  Loss: 0.0232  Acc@1: 62.5000 (65.9529)  Acc@5: 93.7500 (93.6315)  time: 0.3525  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [ 800/1142]  eta: 0:02:00  Lr: 0.001875  Loss: -0.7523  Acc@1: 62.5000 (65.9566)  Acc@5: 93.7500 (93.6174)  time: 0.3495  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [ 810/1142]  eta: 0:01:56  Lr: 0.001875  Loss: -0.2972  Acc@1: 62.5000 (65.9448)  Acc@5: 93.7500 (93.6113)  time: 0.3484  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [ 820/1142]  eta: 0:01:52  Lr: 0.001875  Loss: 0.1493  Acc@1: 62.5000 (65.9714)  Acc@5: 93.7500 (93.6358)  time: 0.3492  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [ 830/1142]  eta: 0:01:49  Lr: 0.001875  Loss: -0.1815  Acc@1: 68.7500 (65.9823)  Acc@5: 93.7500 (93.6372)  time: 0.3500  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [ 840/1142]  eta: 0:01:45  Lr: 0.001875  Loss: -0.2913  Acc@1: 62.5000 (65.8963)  Acc@5: 93.7500 (93.6237)  time: 0.3485  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [ 850/1142]  eta: 0:01:42  Lr: 0.001875  Loss: -0.6191  Acc@1: 62.5000 (65.9885)  Acc@5: 93.7500 (93.6545)  time: 0.3462  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [ 860/1142]  eta: 0:01:38  Lr: 0.001875  Loss: -0.4942  Acc@1: 62.5000 (65.9625)  Acc@5: 93.7500 (93.6266)  time: 0.3493  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [ 870/1142]  eta: 0:01:35  Lr: 0.001875  Loss: -0.5296  Acc@1: 62.5000 (65.9228)  Acc@5: 93.7500 (93.6495)  time: 0.3537  data: 0.0013  max mem: 2502
Train: Epoch[2/5]  [ 880/1142]  eta: 0:01:31  Lr: 0.001875  Loss: -0.5891  Acc@1: 62.5000 (65.9052)  Acc@5: 93.7500 (93.6365)  time: 0.3535  data: 0.0019  max mem: 2502
Train: Epoch[2/5]  [ 890/1142]  eta: 0:01:28  Lr: 0.001875  Loss: -0.1771  Acc@1: 62.5000 (65.8389)  Acc@5: 93.7500 (93.6308)  time: 0.3512  data: 0.0011  max mem: 2502
Train: Epoch[2/5]  [ 900/1142]  eta: 0:01:24  Lr: 0.001875  Loss: -0.2968  Acc@1: 62.5000 (65.8435)  Acc@5: 93.7500 (93.6182)  time: 0.3506  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [ 910/1142]  eta: 0:01:21  Lr: 0.001875  Loss: -0.4885  Acc@1: 62.5000 (65.8960)  Acc@5: 93.7500 (93.6059)  time: 0.3520  data: 0.0009  max mem: 2502
Train: Epoch[2/5]  [ 920/1142]  eta: 0:01:17  Lr: 0.001875  Loss: -0.3922  Acc@1: 68.7500 (65.9134)  Acc@5: 93.7500 (93.6279)  time: 0.3519  data: 0.0017  max mem: 2502
Train: Epoch[2/5]  [ 930/1142]  eta: 0:01:14  Lr: 0.001875  Loss: -0.6472  Acc@1: 68.7500 (65.9573)  Acc@5: 93.7500 (93.6157)  time: 0.3503  data: 0.0013  max mem: 2502
Train: Epoch[2/5]  [ 940/1142]  eta: 0:01:10  Lr: 0.001875  Loss: -0.3531  Acc@1: 68.7500 (65.9671)  Acc@5: 93.7500 (93.6371)  time: 0.3497  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [ 950/1142]  eta: 0:01:07  Lr: 0.001875  Loss: -0.3419  Acc@1: 68.7500 (65.9700)  Acc@5: 93.7500 (93.6711)  time: 0.3515  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [ 960/1142]  eta: 0:01:03  Lr: 0.001875  Loss: -0.5340  Acc@1: 62.5000 (65.9274)  Acc@5: 93.7500 (93.6394)  time: 0.3517  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [ 970/1142]  eta: 0:01:00  Lr: 0.001875  Loss: -0.4662  Acc@1: 62.5000 (65.9436)  Acc@5: 93.7500 (93.6406)  time: 0.3492  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [ 980/1142]  eta: 0:00:56  Lr: 0.001875  Loss: -0.3096  Acc@1: 68.7500 (66.0104)  Acc@5: 100.0000 (93.6608)  time: 0.3480  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [ 990/1142]  eta: 0:00:53  Lr: 0.001875  Loss: 0.0818  Acc@1: 68.7500 (65.9435)  Acc@5: 93.7500 (93.6743)  time: 0.3480  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [1000/1142]  eta: 0:00:49  Lr: 0.001875  Loss: -0.3757  Acc@1: 62.5000 (65.9403)  Acc@5: 93.7500 (93.7000)  time: 0.3480  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [1010/1142]  eta: 0:00:46  Lr: 0.001875  Loss: -0.0868  Acc@1: 56.2500 (65.8939)  Acc@5: 93.7500 (93.7005)  time: 0.3478  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [1020/1142]  eta: 0:00:42  Lr: 0.001875  Loss: -0.6685  Acc@1: 68.7500 (65.9525)  Acc@5: 93.7500 (93.7010)  time: 0.3468  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [1030/1142]  eta: 0:00:39  Lr: 0.001875  Loss: -0.5052  Acc@1: 68.7500 (65.9796)  Acc@5: 93.7500 (93.7197)  time: 0.3456  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [1040/1142]  eta: 0:00:35  Lr: 0.001875  Loss: 0.2935  Acc@1: 68.7500 (66.0002)  Acc@5: 100.0000 (93.7500)  time: 0.3471  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [1050/1142]  eta: 0:00:32  Lr: 0.001875  Loss: -0.3265  Acc@1: 75.0000 (66.0978)  Acc@5: 100.0000 (93.7738)  time: 0.3481  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [1060/1142]  eta: 0:00:28  Lr: 0.001875  Loss: -0.0871  Acc@1: 68.7500 (66.1110)  Acc@5: 93.7500 (93.7853)  time: 0.3475  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [1070/1142]  eta: 0:00:25  Lr: 0.001875  Loss: -0.1752  Acc@1: 62.5000 (66.0714)  Acc@5: 93.7500 (93.7733)  time: 0.3490  data: 0.0009  max mem: 2502
Train: Epoch[2/5]  [1080/1142]  eta: 0:00:21  Lr: 0.001875  Loss: -0.9813  Acc@1: 62.5000 (66.0500)  Acc@5: 93.7500 (93.7731)  time: 0.3515  data: 0.0009  max mem: 2502
Train: Epoch[2/5]  [1090/1142]  eta: 0:00:18  Lr: 0.001875  Loss: -0.3262  Acc@1: 68.7500 (66.0919)  Acc@5: 93.7500 (93.7672)  time: 0.3535  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [1100/1142]  eta: 0:00:14  Lr: 0.001875  Loss: -0.7262  Acc@1: 68.7500 (66.1217)  Acc@5: 93.7500 (93.7784)  time: 0.3532  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [1110/1142]  eta: 0:00:11  Lr: 0.001875  Loss: -0.1647  Acc@1: 68.7500 (66.1116)  Acc@5: 93.7500 (93.7613)  time: 0.3513  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [1120/1142]  eta: 0:00:07  Lr: 0.001875  Loss: -0.6853  Acc@1: 68.7500 (66.1240)  Acc@5: 93.7500 (93.7612)  time: 0.3489  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [1130/1142]  eta: 0:00:04  Lr: 0.001875  Loss: -0.8491  Acc@1: 68.7500 (66.1362)  Acc@5: 93.7500 (93.7721)  time: 0.3516  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [1140/1142]  eta: 0:00:00  Lr: 0.001875  Loss: -0.9415  Acc@1: 68.7500 (66.1865)  Acc@5: 93.7500 (93.7555)  time: 0.3575  data: 0.0031  max mem: 2502
Train: Epoch[2/5]  [1141/1142]  eta: 0:00:00  Lr: 0.001875  Loss: -1.0117  Acc@1: 68.7500 (66.1976)  Acc@5: 93.7500 (93.7586)  time: 0.3501  data: 0.0031  max mem: 2502
Train: Epoch[2/5] Total time: 0:06:40 (0.3508 s / it)
{0: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 1: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 2: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 3: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 4: {0: 0, 1: 300000, 2: 0, 3: 36530, 4: 0}, 5: {0: 0, 1: 300000, 2: 0, 3: 36530, 4: 0}, 6: {0: 0, 1: 300000, 2: 0, 3: 36530, 4: 0}, 7: {0: 0, 1: 300000, 2: 0, 3: 36530, 4: 0}, 8: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 9: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 10: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 11: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 12: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 13: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 14: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 15: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 16: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 17: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 18: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 19: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}}
Averaged stats: Lr: 0.001875  Loss: -1.0117  Acc@1: 68.7500 (66.1976)  Acc@5: 93.7500 (93.7586)
Train: Epoch[3/5]  [   0/1142]  eta: 0:12:54  Lr: 0.001875  Loss: -0.4762  Acc@1: 75.0000 (75.0000)  Acc@5: 87.5000 (87.5000)  time: 0.6780  data: 0.3279  max mem: 2502
Train: Epoch[3/5]  [  10/1142]  eta: 0:07:07  Lr: 0.001875  Loss: -0.7007  Acc@1: 68.7500 (70.4545)  Acc@5: 100.0000 (96.0227)  time: 0.3778  data: 0.0302  max mem: 2502
Train: Epoch[3/5]  [  20/1142]  eta: 0:06:47  Lr: 0.001875  Loss: -0.9062  Acc@1: 68.7500 (70.8333)  Acc@5: 100.0000 (96.1310)  time: 0.3479  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [  30/1142]  eta: 0:06:38  Lr: 0.001875  Loss: -0.5978  Acc@1: 68.7500 (69.1532)  Acc@5: 93.7500 (95.3629)  time: 0.3482  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [  40/1142]  eta: 0:06:32  Lr: 0.001875  Loss: -0.3789  Acc@1: 68.7500 (69.3598)  Acc@5: 93.7500 (95.1220)  time: 0.3487  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [  50/1142]  eta: 0:06:27  Lr: 0.001875  Loss: -0.8051  Acc@1: 68.7500 (69.7304)  Acc@5: 93.7500 (95.2206)  time: 0.3484  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [  60/1142]  eta: 0:06:22  Lr: 0.001875  Loss: -0.4959  Acc@1: 62.5000 (68.5451)  Acc@5: 93.7500 (94.4672)  time: 0.3472  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [  70/1142]  eta: 0:06:17  Lr: 0.001875  Loss: -0.1641  Acc@1: 68.7500 (68.2218)  Acc@5: 87.5000 (93.7500)  time: 0.3469  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [  80/1142]  eta: 0:06:13  Lr: 0.001875  Loss: -0.4211  Acc@1: 68.7500 (68.6728)  Acc@5: 93.7500 (93.6728)  time: 0.3479  data: 0.0007  max mem: 2502
Train: Epoch[3/5]  [  90/1142]  eta: 0:06:09  Lr: 0.001875  Loss: -0.5873  Acc@1: 68.7500 (68.2005)  Acc@5: 93.7500 (93.5440)  time: 0.3473  data: 0.0007  max mem: 2502
Train: Epoch[3/5]  [ 100/1142]  eta: 0:06:05  Lr: 0.001875  Loss: 0.0359  Acc@1: 68.7500 (68.1312)  Acc@5: 93.7500 (93.4406)  time: 0.3466  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [ 110/1142]  eta: 0:06:02  Lr: 0.001875  Loss: 0.2194  Acc@1: 68.7500 (68.2432)  Acc@5: 93.7500 (93.2995)  time: 0.3510  data: 0.0008  max mem: 2502
Train: Epoch[3/5]  [ 120/1142]  eta: 0:05:59  Lr: 0.001875  Loss: -0.6876  Acc@1: 68.7500 (68.5950)  Acc@5: 93.7500 (93.4917)  time: 0.3567  data: 0.0012  max mem: 2502
Train: Epoch[3/5]  [ 130/1142]  eta: 0:05:56  Lr: 0.001875  Loss: -0.5223  Acc@1: 68.7500 (68.7500)  Acc@5: 93.7500 (93.5592)  time: 0.3570  data: 0.0012  max mem: 2502
Train: Epoch[3/5]  [ 140/1142]  eta: 0:05:52  Lr: 0.001875  Loss: -0.2693  Acc@1: 68.7500 (68.7943)  Acc@5: 93.7500 (93.7057)  time: 0.3542  data: 0.0008  max mem: 2502
Train: Epoch[3/5]  [ 150/1142]  eta: 0:05:49  Lr: 0.001875  Loss: -0.6084  Acc@1: 62.5000 (68.1705)  Acc@5: 93.7500 (93.8742)  time: 0.3514  data: 0.0007  max mem: 2502
Train: Epoch[3/5]  [ 160/1142]  eta: 0:05:45  Lr: 0.001875  Loss: -0.8567  Acc@1: 62.5000 (68.1289)  Acc@5: 93.7500 (93.8276)  time: 0.3527  data: 0.0013  max mem: 2502
Train: Epoch[3/5]  [ 170/1142]  eta: 0:05:42  Lr: 0.001875  Loss: -0.3225  Acc@1: 68.7500 (68.3845)  Acc@5: 93.7500 (93.9327)  time: 0.3523  data: 0.0012  max mem: 2502
Train: Epoch[3/5]  [ 180/1142]  eta: 0:05:38  Lr: 0.001875  Loss: -0.5311  Acc@1: 68.7500 (68.2320)  Acc@5: 93.7500 (93.7845)  time: 0.3481  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [ 190/1142]  eta: 0:05:34  Lr: 0.001875  Loss: 0.0374  Acc@1: 62.5000 (67.8992)  Acc@5: 87.5000 (93.7500)  time: 0.3483  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [ 200/1142]  eta: 0:05:31  Lr: 0.001875  Loss: -0.6334  Acc@1: 62.5000 (67.7550)  Acc@5: 93.7500 (93.8744)  time: 0.3500  data: 0.0008  max mem: 2502
Train: Epoch[3/5]  [ 210/1142]  eta: 0:05:27  Lr: 0.001875  Loss: -0.3577  Acc@1: 68.7500 (67.8910)  Acc@5: 93.7500 (93.8092)  time: 0.3522  data: 0.0008  max mem: 2502
Train: Epoch[3/5]  [ 220/1142]  eta: 0:05:24  Lr: 0.001875  Loss: -0.8155  Acc@1: 68.7500 (67.7602)  Acc@5: 93.7500 (93.7217)  time: 0.3506  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [ 230/1142]  eta: 0:05:20  Lr: 0.001875  Loss: -0.5423  Acc@1: 68.7500 (67.8030)  Acc@5: 93.7500 (93.7229)  time: 0.3476  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [ 240/1142]  eta: 0:05:16  Lr: 0.001875  Loss: 0.4433  Acc@1: 68.7500 (67.9201)  Acc@5: 93.7500 (93.7241)  time: 0.3483  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [ 250/1142]  eta: 0:05:13  Lr: 0.001875  Loss: -0.6730  Acc@1: 62.5000 (67.6295)  Acc@5: 93.7500 (93.7500)  time: 0.3489  data: 0.0012  max mem: 2502
Train: Epoch[3/5]  [ 260/1142]  eta: 0:05:09  Lr: 0.001875  Loss: -0.5459  Acc@1: 62.5000 (67.6964)  Acc@5: 93.7500 (93.6542)  time: 0.3470  data: 0.0012  max mem: 2502
Train: Epoch[3/5]  [ 270/1142]  eta: 0:05:05  Lr: 0.001875  Loss: -0.3435  Acc@1: 68.7500 (67.6199)  Acc@5: 93.7500 (93.7039)  time: 0.3453  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [ 280/1142]  eta: 0:05:02  Lr: 0.001875  Loss: -0.2620  Acc@1: 68.7500 (67.5934)  Acc@5: 93.7500 (93.6165)  time: 0.3470  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [ 290/1142]  eta: 0:04:58  Lr: 0.001875  Loss: -0.4670  Acc@1: 68.7500 (67.6117)  Acc@5: 93.7500 (93.5782)  time: 0.3493  data: 0.0013  max mem: 2502
Train: Epoch[3/5]  [ 300/1142]  eta: 0:04:55  Lr: 0.001875  Loss: -0.3438  Acc@1: 62.5000 (67.4626)  Acc@5: 93.7500 (93.6047)  time: 0.3508  data: 0.0014  max mem: 2502
Train: Epoch[3/5]  [ 310/1142]  eta: 0:04:51  Lr: 0.001875  Loss: 0.6745  Acc@1: 62.5000 (67.3432)  Acc@5: 93.7500 (93.6093)  time: 0.3498  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [ 320/1142]  eta: 0:04:48  Lr: 0.001875  Loss: -0.9064  Acc@1: 68.7500 (67.3871)  Acc@5: 93.7500 (93.6916)  time: 0.3509  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [ 330/1142]  eta: 0:04:44  Lr: 0.001875  Loss: -0.7855  Acc@1: 75.0000 (67.5604)  Acc@5: 93.7500 (93.7122)  time: 0.3522  data: 0.0007  max mem: 2502
Train: Epoch[3/5]  [ 340/1142]  eta: 0:04:41  Lr: 0.001875  Loss: -0.3695  Acc@1: 75.0000 (67.6503)  Acc@5: 93.7500 (93.7867)  time: 0.3511  data: 0.0007  max mem: 2502
Train: Epoch[3/5]  [ 350/1142]  eta: 0:04:37  Lr: 0.001875  Loss: 0.3458  Acc@1: 75.0000 (67.6460)  Acc@5: 93.7500 (93.7678)  time: 0.3506  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [ 360/1142]  eta: 0:04:34  Lr: 0.001875  Loss: -0.5224  Acc@1: 68.7500 (67.7458)  Acc@5: 93.7500 (93.7673)  time: 0.3481  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [ 370/1142]  eta: 0:04:30  Lr: 0.001875  Loss: -0.6940  Acc@1: 75.0000 (67.9414)  Acc@5: 93.7500 (93.8848)  time: 0.3502  data: 0.0018  max mem: 2502
Train: Epoch[3/5]  [ 380/1142]  eta: 0:04:27  Lr: 0.001875  Loss: -0.2974  Acc@1: 75.0000 (68.0774)  Acc@5: 93.7500 (93.8976)  time: 0.3544  data: 0.0019  max mem: 2502
Train: Epoch[3/5]  [ 390/1142]  eta: 0:04:23  Lr: 0.001875  Loss: -0.4183  Acc@1: 68.7500 (68.1746)  Acc@5: 93.7500 (93.9418)  time: 0.3560  data: 0.0012  max mem: 2502
Train: Epoch[3/5]  [ 400/1142]  eta: 0:04:20  Lr: 0.001875  Loss: 0.0799  Acc@1: 62.5000 (67.9395)  Acc@5: 93.7500 (93.9526)  time: 0.3524  data: 0.0012  max mem: 2502
Train: Epoch[3/5]  [ 410/1142]  eta: 0:04:16  Lr: 0.001875  Loss: -0.2136  Acc@1: 56.2500 (67.7616)  Acc@5: 93.7500 (93.9021)  time: 0.3489  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [ 420/1142]  eta: 0:04:13  Lr: 0.001875  Loss: -0.4955  Acc@1: 68.7500 (67.9335)  Acc@5: 93.7500 (93.9133)  time: 0.3498  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [ 430/1142]  eta: 0:04:09  Lr: 0.001875  Loss: -0.0943  Acc@1: 68.7500 (67.8364)  Acc@5: 93.7500 (93.8950)  time: 0.3502  data: 0.0011  max mem: 2502
Train: Epoch[3/5]  [ 440/1142]  eta: 0:04:06  Lr: 0.001875  Loss: 0.0005  Acc@1: 62.5000 (67.8713)  Acc@5: 93.7500 (93.9342)  time: 0.3494  data: 0.0011  max mem: 2502
Train: Epoch[3/5]  [ 450/1142]  eta: 0:04:02  Lr: 0.001875  Loss: -0.5165  Acc@1: 68.7500 (67.9739)  Acc@5: 100.0000 (93.9302)  time: 0.3471  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [ 460/1142]  eta: 0:03:59  Lr: 0.001875  Loss: -0.4459  Acc@1: 75.0000 (68.0450)  Acc@5: 93.7500 (93.9940)  time: 0.3513  data: 0.0007  max mem: 2502
Train: Epoch[3/5]  [ 470/1142]  eta: 0:03:55  Lr: 0.001875  Loss: -0.9497  Acc@1: 68.7500 (68.1396)  Acc@5: 93.7500 (94.0154)  time: 0.3508  data: 0.0007  max mem: 2502
Train: Epoch[3/5]  [ 480/1142]  eta: 0:03:52  Lr: 0.001875  Loss: -0.7789  Acc@1: 68.7500 (68.2173)  Acc@5: 93.7500 (94.0619)  time: 0.3458  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [ 490/1142]  eta: 0:03:48  Lr: 0.001875  Loss: 0.0520  Acc@1: 68.7500 (68.1008)  Acc@5: 93.7500 (94.0428)  time: 0.3499  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [ 500/1142]  eta: 0:03:45  Lr: 0.001875  Loss: -0.0457  Acc@1: 62.5000 (68.0264)  Acc@5: 87.5000 (93.9621)  time: 0.3538  data: 0.0008  max mem: 2502
Train: Epoch[3/5]  [ 510/1142]  eta: 0:03:41  Lr: 0.001875  Loss: -0.7314  Acc@1: 62.5000 (68.0039)  Acc@5: 87.5000 (93.8845)  time: 0.3515  data: 0.0007  max mem: 2502
Train: Epoch[3/5]  [ 520/1142]  eta: 0:03:38  Lr: 0.001875  Loss: -0.4276  Acc@1: 62.5000 (68.0182)  Acc@5: 93.7500 (93.8820)  time: 0.3503  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [ 530/1142]  eta: 0:03:34  Lr: 0.001875  Loss: -0.2318  Acc@1: 68.7500 (68.1026)  Acc@5: 93.7500 (93.9148)  time: 0.3504  data: 0.0006  max mem: 2502
Train: Epoch[3/5]  [ 540/1142]  eta: 0:03:31  Lr: 0.001875  Loss: 0.1786  Acc@1: 68.7500 (68.1030)  Acc@5: 93.7500 (93.9464)  time: 0.3546  data: 0.0008  max mem: 2502
Train: Epoch[3/5]  [ 550/1142]  eta: 0:03:27  Lr: 0.001875  Loss: -0.7236  Acc@1: 68.7500 (68.1261)  Acc@5: 93.7500 (93.9655)  time: 0.3540  data: 0.0009  max mem: 2502
Train: Epoch[3/5]  [ 560/1142]  eta: 0:03:24  Lr: 0.001875  Loss: -0.3366  Acc@1: 68.7500 (68.1150)  Acc@5: 93.7500 (93.9617)  time: 0.3483  data: 0.0007  max mem: 2502
Train: Epoch[3/5]  [ 570/1142]  eta: 0:03:20  Lr: 0.001875  Loss: -0.1084  Acc@1: 68.7500 (68.1151)  Acc@5: 93.7500 (93.9251)  time: 0.3499  data: 0.0006  max mem: 2502
Train: Epoch[3/5]  [ 580/1142]  eta: 0:03:17  Lr: 0.001875  Loss: -0.5605  Acc@1: 62.5000 (67.9109)  Acc@5: 93.7500 (93.9544)  time: 0.3498  data: 0.0008  max mem: 2502
Train: Epoch[3/5]  [ 590/1142]  eta: 0:03:13  Lr: 0.001875  Loss: -0.8052  Acc@1: 56.2500 (67.9463)  Acc@5: 93.7500 (93.9298)  time: 0.3492  data: 0.0016  max mem: 2502
Train: Epoch[3/5]  [ 600/1142]  eta: 0:03:10  Lr: 0.001875  Loss: -0.4581  Acc@1: 68.7500 (67.9077)  Acc@5: 93.7500 (93.9268)  time: 0.3485  data: 0.0014  max mem: 2502
Train: Epoch[3/5]  [ 610/1142]  eta: 0:03:06  Lr: 0.001875  Loss: -0.9689  Acc@1: 68.7500 (67.9930)  Acc@5: 93.7500 (93.9444)  time: 0.3478  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [ 620/1142]  eta: 0:03:02  Lr: 0.001875  Loss: -0.1647  Acc@1: 68.7500 (67.9247)  Acc@5: 93.7500 (93.9412)  time: 0.3486  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [ 630/1142]  eta: 0:02:59  Lr: 0.001875  Loss: -0.0037  Acc@1: 68.7500 (67.9972)  Acc@5: 93.7500 (93.9283)  time: 0.3505  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [ 640/1142]  eta: 0:02:55  Lr: 0.001875  Loss: 0.3074  Acc@1: 68.7500 (67.9797)  Acc@5: 93.7500 (93.8670)  time: 0.3487  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [ 650/1142]  eta: 0:02:52  Lr: 0.001875  Loss: -0.5765  Acc@1: 56.2500 (67.8667)  Acc@5: 87.5000 (93.8364)  time: 0.3452  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [ 660/1142]  eta: 0:02:48  Lr: 0.001875  Loss: -0.4243  Acc@1: 62.5000 (67.8612)  Acc@5: 93.7500 (93.8256)  time: 0.3457  data: 0.0008  max mem: 2502
Train: Epoch[3/5]  [ 670/1142]  eta: 0:02:45  Lr: 0.001875  Loss: -0.0595  Acc@1: 68.7500 (67.8372)  Acc@5: 93.7500 (93.8059)  time: 0.3479  data: 0.0009  max mem: 2502
Train: Epoch[3/5]  [ 680/1142]  eta: 0:02:41  Lr: 0.001875  Loss: -0.7351  Acc@1: 62.5000 (67.7955)  Acc@5: 93.7500 (93.7959)  time: 0.3511  data: 0.0006  max mem: 2502
Train: Epoch[3/5]  [ 690/1142]  eta: 0:02:38  Lr: 0.001875  Loss: -0.4783  Acc@1: 68.7500 (67.8726)  Acc@5: 93.7500 (93.8043)  time: 0.3523  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [ 700/1142]  eta: 0:02:34  Lr: 0.001875  Loss: -0.5858  Acc@1: 68.7500 (67.7960)  Acc@5: 93.7500 (93.8302)  time: 0.3514  data: 0.0007  max mem: 2502
Train: Epoch[3/5]  [ 710/1142]  eta: 0:02:31  Lr: 0.001875  Loss: -0.9335  Acc@1: 62.5000 (67.7831)  Acc@5: 93.7500 (93.8379)  time: 0.3513  data: 0.0008  max mem: 2502
Train: Epoch[3/5]  [ 720/1142]  eta: 0:02:27  Lr: 0.001875  Loss: -0.2389  Acc@1: 68.7500 (67.8138)  Acc@5: 93.7500 (93.8454)  time: 0.3558  data: 0.0023  max mem: 2502
Train: Epoch[3/5]  [ 730/1142]  eta: 0:02:24  Lr: 0.001875  Loss: -0.7329  Acc@1: 68.7500 (67.7753)  Acc@5: 93.7500 (93.8098)  time: 0.3554  data: 0.0021  max mem: 2502
Train: Epoch[3/5]  [ 740/1142]  eta: 0:02:20  Lr: 0.001875  Loss: -0.3729  Acc@1: 68.7500 (67.8053)  Acc@5: 93.7500 (93.8006)  time: 0.3512  data: 0.0006  max mem: 2502
Train: Epoch[3/5]  [ 750/1142]  eta: 0:02:17  Lr: 0.001875  Loss: -0.1978  Acc@1: 68.7500 (67.7597)  Acc@5: 93.7500 (93.7833)  time: 0.3532  data: 0.0006  max mem: 2502
Train: Epoch[3/5]  [ 760/1142]  eta: 0:02:14  Lr: 0.001875  Loss: 0.4720  Acc@1: 62.5000 (67.6823)  Acc@5: 93.7500 (93.7664)  time: 0.3589  data: 0.0006  max mem: 2502
Train: Epoch[3/5]  [ 770/1142]  eta: 0:02:10  Lr: 0.001875  Loss: -0.8654  Acc@1: 68.7500 (67.6881)  Acc@5: 93.7500 (93.7095)  time: 0.3562  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [ 780/1142]  eta: 0:02:06  Lr: 0.001875  Loss: -0.4397  Acc@1: 62.5000 (67.6617)  Acc@5: 93.7500 (93.6780)  time: 0.3492  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [ 790/1142]  eta: 0:02:03  Lr: 0.001875  Loss: -0.0893  Acc@1: 62.5000 (67.6122)  Acc@5: 93.7500 (93.6710)  time: 0.3483  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [ 800/1142]  eta: 0:01:59  Lr: 0.001875  Loss: -1.0301  Acc@1: 68.7500 (67.7200)  Acc@5: 93.7500 (93.7188)  time: 0.3488  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [ 810/1142]  eta: 0:01:56  Lr: 0.001875  Loss: -0.4073  Acc@1: 68.7500 (67.7173)  Acc@5: 93.7500 (93.7269)  time: 0.3505  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [ 820/1142]  eta: 0:01:52  Lr: 0.001875  Loss: -0.8661  Acc@1: 68.7500 (67.7527)  Acc@5: 93.7500 (93.7272)  time: 0.3484  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [ 830/1142]  eta: 0:01:49  Lr: 0.001875  Loss: -0.4373  Acc@1: 68.7500 (67.7196)  Acc@5: 93.7500 (93.7199)  time: 0.3457  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [ 840/1142]  eta: 0:01:45  Lr: 0.001875  Loss: -0.8265  Acc@1: 62.5000 (67.6947)  Acc@5: 93.7500 (93.7277)  time: 0.3468  data: 0.0007  max mem: 2502
Train: Epoch[3/5]  [ 850/1142]  eta: 0:01:42  Lr: 0.001875  Loss: -0.4292  Acc@1: 68.7500 (67.6998)  Acc@5: 93.7500 (93.7353)  time: 0.3482  data: 0.0008  max mem: 2502
Train: Epoch[3/5]  [ 860/1142]  eta: 0:01:38  Lr: 0.001875  Loss: -0.4437  Acc@1: 62.5000 (67.6902)  Acc@5: 93.7500 (93.6919)  time: 0.3486  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [ 870/1142]  eta: 0:01:35  Lr: 0.001875  Loss: -0.4824  Acc@1: 68.7500 (67.7382)  Acc@5: 93.7500 (93.6998)  time: 0.3505  data: 0.0012  max mem: 2502
Train: Epoch[3/5]  [ 880/1142]  eta: 0:01:31  Lr: 0.001875  Loss: -0.2129  Acc@1: 68.7500 (67.7639)  Acc@5: 93.7500 (93.7003)  time: 0.3531  data: 0.0015  max mem: 2502
Train: Epoch[3/5]  [ 890/1142]  eta: 0:01:28  Lr: 0.001875  Loss: -0.8259  Acc@1: 68.7500 (67.7048)  Acc@5: 93.7500 (93.7149)  time: 0.3527  data: 0.0015  max mem: 2502
Train: Epoch[3/5]  [ 900/1142]  eta: 0:01:24  Lr: 0.001875  Loss: -0.6438  Acc@1: 62.5000 (67.6748)  Acc@5: 93.7500 (93.7153)  time: 0.3529  data: 0.0014  max mem: 2502
Train: Epoch[3/5]  [ 910/1142]  eta: 0:01:21  Lr: 0.001875  Loss: -0.3683  Acc@1: 68.7500 (67.7209)  Acc@5: 93.7500 (93.7294)  time: 0.3531  data: 0.0007  max mem: 2502
Train: Epoch[3/5]  [ 920/1142]  eta: 0:01:17  Lr: 0.001875  Loss: -0.2546  Acc@1: 75.0000 (67.7117)  Acc@5: 93.7500 (93.7229)  time: 0.3519  data: 0.0007  max mem: 2502
Train: Epoch[3/5]  [ 930/1142]  eta: 0:01:14  Lr: 0.001875  Loss: -0.2777  Acc@1: 68.7500 (67.7430)  Acc@5: 93.7500 (93.7097)  time: 0.3544  data: 0.0006  max mem: 2502
Train: Epoch[3/5]  [ 940/1142]  eta: 0:01:10  Lr: 0.001875  Loss: -0.7084  Acc@1: 68.7500 (67.7537)  Acc@5: 93.7500 (93.7367)  time: 0.3539  data: 0.0008  max mem: 2502
Train: Epoch[3/5]  [ 950/1142]  eta: 0:01:07  Lr: 0.001875  Loss: -0.3795  Acc@1: 68.7500 (67.7511)  Acc@5: 100.0000 (93.7631)  time: 0.3537  data: 0.0012  max mem: 2502
Train: Epoch[3/5]  [ 960/1142]  eta: 0:01:03  Lr: 0.001875  Loss: -0.5292  Acc@1: 68.7500 (67.7614)  Acc@5: 93.7500 (93.7695)  time: 0.3526  data: 0.0009  max mem: 2502
Train: Epoch[3/5]  [ 970/1142]  eta: 0:01:00  Lr: 0.001875  Loss: -0.3355  Acc@1: 68.7500 (67.7845)  Acc@5: 93.7500 (93.7822)  time: 0.3485  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [ 980/1142]  eta: 0:00:56  Lr: 0.001875  Loss: -0.3229  Acc@1: 75.0000 (67.8326)  Acc@5: 93.7500 (93.7946)  time: 0.3488  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [ 990/1142]  eta: 0:00:53  Lr: 0.001875  Loss: -0.8081  Acc@1: 68.7500 (67.8292)  Acc@5: 93.7500 (93.8005)  time: 0.3486  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [1000/1142]  eta: 0:00:49  Lr: 0.001875  Loss: -0.6414  Acc@1: 68.7500 (67.8072)  Acc@5: 93.7500 (93.8062)  time: 0.3489  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [1010/1142]  eta: 0:00:46  Lr: 0.001875  Loss: 0.0238  Acc@1: 68.7500 (67.8783)  Acc@5: 93.7500 (93.7933)  time: 0.3481  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [1020/1142]  eta: 0:00:42  Lr: 0.001875  Loss: -0.5810  Acc@1: 68.7500 (67.8624)  Acc@5: 93.7500 (93.7990)  time: 0.3475  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [1030/1142]  eta: 0:00:39  Lr: 0.001875  Loss: -0.3475  Acc@1: 68.7500 (67.8528)  Acc@5: 93.7500 (93.7864)  time: 0.3474  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [1040/1142]  eta: 0:00:35  Lr: 0.001875  Loss: -0.8604  Acc@1: 68.7500 (67.8915)  Acc@5: 93.7500 (93.8160)  time: 0.3460  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [1050/1142]  eta: 0:00:32  Lr: 0.001875  Loss: -0.2157  Acc@1: 68.7500 (67.9175)  Acc@5: 100.0000 (93.8214)  time: 0.3458  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [1060/1142]  eta: 0:00:28  Lr: 0.001875  Loss: -0.9029  Acc@1: 68.7500 (67.9607)  Acc@5: 100.0000 (93.8384)  time: 0.3508  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [1070/1142]  eta: 0:00:25  Lr: 0.001875  Loss: 0.0627  Acc@1: 68.7500 (67.9563)  Acc@5: 100.0000 (93.8317)  time: 0.3552  data: 0.0006  max mem: 2502
Train: Epoch[3/5]  [1080/1142]  eta: 0:00:21  Lr: 0.001875  Loss: -0.2502  Acc@1: 68.7500 (67.9810)  Acc@5: 93.7500 (93.8367)  time: 0.3521  data: 0.0006  max mem: 2502
Train: Epoch[3/5]  [1090/1142]  eta: 0:00:18  Lr: 0.001875  Loss: -0.8608  Acc@1: 68.7500 (68.0282)  Acc@5: 93.7500 (93.8531)  time: 0.3512  data: 0.0006  max mem: 2502
Train: Epoch[3/5]  [1100/1142]  eta: 0:00:14  Lr: 0.001875  Loss: -0.4500  Acc@1: 75.0000 (68.0574)  Acc@5: 93.7500 (93.8635)  time: 0.3518  data: 0.0006  max mem: 2502
Train: Epoch[3/5]  [1110/1142]  eta: 0:00:11  Lr: 0.001875  Loss: -0.1184  Acc@1: 68.7500 (68.1143)  Acc@5: 93.7500 (93.8625)  time: 0.3544  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [1120/1142]  eta: 0:00:07  Lr: 0.001875  Loss: -0.6832  Acc@1: 68.7500 (68.1311)  Acc@5: 93.7500 (93.8671)  time: 0.3565  data: 0.0012  max mem: 2502
Train: Epoch[3/5]  [1130/1142]  eta: 0:00:04  Lr: 0.001875  Loss: -0.2111  Acc@1: 68.7500 (68.1256)  Acc@5: 93.7500 (93.8550)  time: 0.3522  data: 0.0011  max mem: 2502
Train: Epoch[3/5]  [1140/1142]  eta: 0:00:00  Lr: 0.001875  Loss: -0.5771  Acc@1: 62.5000 (68.1310)  Acc@5: 100.0000 (93.8979)  time: 0.3485  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [1141/1142]  eta: 0:00:00  Lr: 0.001875  Loss: -1.3129  Acc@1: 68.7500 (68.1413)  Acc@5: 100.0000 (93.9009)  time: 0.3412  data: 0.0004  max mem: 2502
Train: Epoch[3/5] Total time: 0:06:40 (0.3508 s / it)
{0: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 1: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 2: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 3: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 4: {0: 0, 1: 300000, 2: 0, 3: 54795, 4: 0}, 5: {0: 0, 1: 300000, 2: 0, 3: 54795, 4: 0}, 6: {0: 0, 1: 300000, 2: 0, 3: 54795, 4: 0}, 7: {0: 0, 1: 300000, 2: 0, 3: 54795, 4: 0}, 8: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 9: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 10: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 11: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 12: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 13: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 14: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 15: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 16: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 17: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 18: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 19: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}}
Averaged stats: Lr: 0.001875  Loss: -1.3129  Acc@1: 68.7500 (68.1413)  Acc@5: 100.0000 (93.9009)
Train: Epoch[4/5]  [   0/1142]  eta: 0:13:26  Lr: 0.001875  Loss: -0.7345  Acc@1: 75.0000 (75.0000)  Acc@5: 93.7500 (93.7500)  time: 0.7058  data: 0.3576  max mem: 2502
Train: Epoch[4/5]  [  10/1142]  eta: 0:07:16  Lr: 0.001875  Loss: -0.2906  Acc@1: 68.7500 (71.0227)  Acc@5: 93.7500 (92.0455)  time: 0.3857  data: 0.0347  max mem: 2502
Train: Epoch[4/5]  [  20/1142]  eta: 0:06:54  Lr: 0.001875  Loss: -0.5988  Acc@1: 68.7500 (71.4286)  Acc@5: 93.7500 (93.4524)  time: 0.3522  data: 0.0015  max mem: 2502
Train: Epoch[4/5]  [  30/1142]  eta: 0:06:42  Lr: 0.001875  Loss: -0.9396  Acc@1: 68.7500 (69.5565)  Acc@5: 93.7500 (93.3468)  time: 0.3493  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [  40/1142]  eta: 0:06:35  Lr: 0.001875  Loss: -0.2851  Acc@1: 68.7500 (69.8171)  Acc@5: 93.7500 (93.5976)  time: 0.3477  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [  50/1142]  eta: 0:06:29  Lr: 0.001875  Loss: -0.6269  Acc@1: 68.7500 (69.6078)  Acc@5: 93.7500 (93.9951)  time: 0.3476  data: 0.0008  max mem: 2502
Train: Epoch[4/5]  [  60/1142]  eta: 0:06:24  Lr: 0.001875  Loss: -0.9025  Acc@1: 62.5000 (68.7500)  Acc@5: 93.7500 (93.6475)  time: 0.3492  data: 0.0010  max mem: 2502
Train: Epoch[4/5]  [  70/1142]  eta: 0:06:19  Lr: 0.001875  Loss: -0.1966  Acc@1: 62.5000 (69.1901)  Acc@5: 93.7500 (93.9261)  time: 0.3481  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [  80/1142]  eta: 0:06:14  Lr: 0.001875  Loss: -0.3932  Acc@1: 68.7500 (69.2901)  Acc@5: 93.7500 (94.2130)  time: 0.3455  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [  90/1142]  eta: 0:06:11  Lr: 0.001875  Loss: -0.5637  Acc@1: 75.0000 (69.5055)  Acc@5: 93.7500 (94.3681)  time: 0.3513  data: 0.0016  max mem: 2502
Train: Epoch[4/5]  [ 100/1142]  eta: 0:06:08  Lr: 0.001875  Loss: -0.4053  Acc@1: 68.7500 (68.9356)  Acc@5: 93.7500 (94.4307)  time: 0.3581  data: 0.0026  max mem: 2502
Train: Epoch[4/5]  [ 110/1142]  eta: 0:06:04  Lr: 0.001875  Loss: -0.8044  Acc@1: 68.7500 (69.2568)  Acc@5: 93.7500 (94.5383)  time: 0.3538  data: 0.0013  max mem: 2502
Train: Epoch[4/5]  [ 120/1142]  eta: 0:06:00  Lr: 0.001875  Loss: -0.8478  Acc@1: 75.0000 (69.8347)  Acc@5: 100.0000 (94.7831)  time: 0.3483  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [ 130/1142]  eta: 0:05:57  Lr: 0.001875  Loss: -0.1376  Acc@1: 68.7500 (68.8931)  Acc@5: 93.7500 (94.4656)  time: 0.3510  data: 0.0006  max mem: 2502
Train: Epoch[4/5]  [ 140/1142]  eta: 0:05:54  Lr: 0.001875  Loss: -0.8443  Acc@1: 68.7500 (69.3262)  Acc@5: 93.7500 (94.4592)  time: 0.3558  data: 0.0018  max mem: 2502
Train: Epoch[4/5]  [ 150/1142]  eta: 0:05:50  Lr: 0.001875  Loss: -0.4677  Acc@1: 75.0000 (69.3295)  Acc@5: 93.7500 (94.3295)  time: 0.3532  data: 0.0015  max mem: 2502
Train: Epoch[4/5]  [ 160/1142]  eta: 0:05:46  Lr: 0.001875  Loss: -1.2675  Acc@1: 68.7500 (69.4876)  Acc@5: 93.7500 (94.3711)  time: 0.3483  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [ 170/1142]  eta: 0:05:42  Lr: 0.001875  Loss: -0.5324  Acc@1: 68.7500 (69.5541)  Acc@5: 93.7500 (94.4079)  time: 0.3491  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [ 180/1142]  eta: 0:05:39  Lr: 0.001875  Loss: -0.4434  Acc@1: 75.0000 (69.7859)  Acc@5: 93.7500 (94.3715)  time: 0.3537  data: 0.0006  max mem: 2502
Train: Epoch[4/5]  [ 190/1142]  eta: 0:05:35  Lr: 0.001875  Loss: -0.4257  Acc@1: 68.7500 (69.3717)  Acc@5: 93.7500 (94.2736)  time: 0.3540  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [ 200/1142]  eta: 0:05:32  Lr: 0.001875  Loss: -0.4573  Acc@1: 62.5000 (69.3719)  Acc@5: 93.7500 (94.3097)  time: 0.3492  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [ 210/1142]  eta: 0:05:28  Lr: 0.001875  Loss: -0.6789  Acc@1: 68.7500 (69.1943)  Acc@5: 93.7500 (94.3424)  time: 0.3479  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [ 220/1142]  eta: 0:05:24  Lr: 0.001875  Loss: -0.9742  Acc@1: 68.7500 (69.3156)  Acc@5: 93.7500 (94.2590)  time: 0.3481  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [ 230/1142]  eta: 0:05:21  Lr: 0.001875  Loss: 0.1535  Acc@1: 68.7500 (69.3182)  Acc@5: 93.7500 (94.1558)  time: 0.3499  data: 0.0009  max mem: 2502
Train: Epoch[4/5]  [ 240/1142]  eta: 0:05:17  Lr: 0.001875  Loss: -1.0970  Acc@1: 68.7500 (69.4502)  Acc@5: 93.7500 (94.1131)  time: 0.3509  data: 0.0009  max mem: 2502
Train: Epoch[4/5]  [ 250/1142]  eta: 0:05:13  Lr: 0.001875  Loss: -0.0984  Acc@1: 68.7500 (69.4472)  Acc@5: 93.7500 (94.1235)  time: 0.3481  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [ 260/1142]  eta: 0:05:10  Lr: 0.001875  Loss: -0.5777  Acc@1: 68.7500 (69.4444)  Acc@5: 93.7500 (94.1810)  time: 0.3462  data: 0.0006  max mem: 2502
Train: Epoch[4/5]  [ 270/1142]  eta: 0:05:06  Lr: 0.001875  Loss: -0.6959  Acc@1: 68.7500 (69.4419)  Acc@5: 93.7500 (94.0959)  time: 0.3471  data: 0.0007  max mem: 2502
Train: Epoch[4/5]  [ 280/1142]  eta: 0:05:03  Lr: 0.001875  Loss: -0.6990  Acc@1: 68.7500 (69.4395)  Acc@5: 93.7500 (94.1059)  time: 0.3522  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [ 290/1142]  eta: 0:04:59  Lr: 0.001875  Loss: -0.5639  Acc@1: 68.7500 (69.3943)  Acc@5: 93.7500 (94.1796)  time: 0.3536  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [ 300/1142]  eta: 0:04:56  Lr: 0.001875  Loss: -0.0217  Acc@1: 68.7500 (69.3314)  Acc@5: 93.7500 (94.1030)  time: 0.3504  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [ 310/1142]  eta: 0:04:52  Lr: 0.001875  Loss: -0.4450  Acc@1: 62.5000 (69.1117)  Acc@5: 93.7500 (94.1117)  time: 0.3510  data: 0.0006  max mem: 2502
Train: Epoch[4/5]  [ 320/1142]  eta: 0:04:49  Lr: 0.001875  Loss: -0.2494  Acc@1: 68.7500 (69.1005)  Acc@5: 93.7500 (94.1394)  time: 0.3552  data: 0.0007  max mem: 2502
Train: Epoch[4/5]  [ 330/1142]  eta: 0:04:45  Lr: 0.001875  Loss: -0.4209  Acc@1: 68.7500 (69.1088)  Acc@5: 93.7500 (94.0899)  time: 0.3544  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [ 340/1142]  eta: 0:04:42  Lr: 0.001875  Loss: -1.0300  Acc@1: 68.7500 (69.2632)  Acc@5: 93.7500 (94.0982)  time: 0.3500  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [ 350/1142]  eta: 0:04:38  Lr: 0.001875  Loss: -0.2323  Acc@1: 75.0000 (69.5513)  Acc@5: 93.7500 (94.1239)  time: 0.3496  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [ 360/1142]  eta: 0:04:35  Lr: 0.001875  Loss: -0.1560  Acc@1: 75.0000 (69.4945)  Acc@5: 93.7500 (94.1482)  time: 0.3523  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [ 370/1142]  eta: 0:04:31  Lr: 0.001875  Loss: -0.6238  Acc@1: 68.7500 (69.3228)  Acc@5: 93.7500 (94.1375)  time: 0.3513  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [ 380/1142]  eta: 0:04:27  Lr: 0.001875  Loss: -0.5077  Acc@1: 68.7500 (69.2913)  Acc@5: 93.7500 (94.1273)  time: 0.3498  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [ 390/1142]  eta: 0:04:24  Lr: 0.001875  Loss: 0.2822  Acc@1: 68.7500 (69.2615)  Acc@5: 93.7500 (94.0537)  time: 0.3497  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [ 400/1142]  eta: 0:04:20  Lr: 0.001875  Loss: -0.1880  Acc@1: 68.7500 (69.1552)  Acc@5: 93.7500 (94.0150)  time: 0.3478  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [ 410/1142]  eta: 0:04:17  Lr: 0.001875  Loss: -0.4144  Acc@1: 68.7500 (69.1454)  Acc@5: 93.7500 (94.0237)  time: 0.3482  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [ 420/1142]  eta: 0:04:13  Lr: 0.001875  Loss: -0.9767  Acc@1: 68.7500 (68.9578)  Acc@5: 93.7500 (94.0024)  time: 0.3474  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [ 430/1142]  eta: 0:04:09  Lr: 0.001875  Loss: -0.4589  Acc@1: 62.5000 (68.9675)  Acc@5: 93.7500 (93.9385)  time: 0.3457  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [ 440/1142]  eta: 0:04:06  Lr: 0.001875  Loss: -0.5288  Acc@1: 68.7500 (69.0476)  Acc@5: 93.7500 (93.9626)  time: 0.3464  data: 0.0011  max mem: 2502
Train: Epoch[4/5]  [ 450/1142]  eta: 0:04:02  Lr: 0.001875  Loss: -0.6252  Acc@1: 68.7500 (68.9163)  Acc@5: 93.7500 (93.9579)  time: 0.3484  data: 0.0011  max mem: 2502
Train: Epoch[4/5]  [ 460/1142]  eta: 0:03:59  Lr: 0.001875  Loss: -0.4041  Acc@1: 68.7500 (68.8856)  Acc@5: 93.7500 (93.9127)  time: 0.3514  data: 0.0012  max mem: 2502
Train: Epoch[4/5]  [ 470/1142]  eta: 0:03:55  Lr: 0.001875  Loss: -0.1889  Acc@1: 68.7500 (68.8429)  Acc@5: 93.7500 (93.8562)  time: 0.3514  data: 0.0011  max mem: 2502
Train: Epoch[4/5]  [ 480/1142]  eta: 0:03:52  Lr: 0.001875  Loss: -0.3177  Acc@1: 62.5000 (68.7760)  Acc@5: 93.7500 (93.9189)  time: 0.3502  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [ 490/1142]  eta: 0:03:48  Lr: 0.001875  Loss: -0.6682  Acc@1: 62.5000 (68.6736)  Acc@5: 93.7500 (93.9027)  time: 0.3522  data: 0.0009  max mem: 2502
Train: Epoch[4/5]  [ 500/1142]  eta: 0:03:45  Lr: 0.001875  Loss: -0.8460  Acc@1: 62.5000 (68.6502)  Acc@5: 93.7500 (93.9371)  time: 0.3518  data: 0.0008  max mem: 2502
Train: Epoch[4/5]  [ 510/1142]  eta: 0:03:41  Lr: 0.001875  Loss: -0.6738  Acc@1: 68.7500 (68.6644)  Acc@5: 93.7500 (93.9457)  time: 0.3514  data: 0.0011  max mem: 2502
Train: Epoch[4/5]  [ 520/1142]  eta: 0:03:38  Lr: 0.001875  Loss: 0.5842  Acc@1: 68.7500 (68.6660)  Acc@5: 93.7500 (93.9179)  time: 0.3524  data: 0.0011  max mem: 2502
Train: Epoch[4/5]  [ 530/1142]  eta: 0:03:34  Lr: 0.001875  Loss: -0.7673  Acc@1: 62.5000 (68.5734)  Acc@5: 93.7500 (93.9736)  time: 0.3524  data: 0.0007  max mem: 2502
Train: Epoch[4/5]  [ 540/1142]  eta: 0:03:31  Lr: 0.001875  Loss: -0.3518  Acc@1: 62.5000 (68.6807)  Acc@5: 93.7500 (93.9926)  time: 0.3512  data: 0.0006  max mem: 2502
Train: Epoch[4/5]  [ 550/1142]  eta: 0:03:27  Lr: 0.001875  Loss: -0.1767  Acc@1: 68.7500 (68.6593)  Acc@5: 93.7500 (93.9769)  time: 0.3493  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [ 560/1142]  eta: 0:03:24  Lr: 0.001875  Loss: -0.5321  Acc@1: 68.7500 (68.6052)  Acc@5: 93.7500 (93.9283)  time: 0.3485  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [ 570/1142]  eta: 0:03:20  Lr: 0.001875  Loss: -0.2528  Acc@1: 68.7500 (68.6624)  Acc@5: 93.7500 (93.9470)  time: 0.3500  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [ 580/1142]  eta: 0:03:17  Lr: 0.001875  Loss: 0.2752  Acc@1: 68.7500 (68.5779)  Acc@5: 93.7500 (93.9329)  time: 0.3500  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [ 590/1142]  eta: 0:03:13  Lr: 0.001875  Loss: -0.4054  Acc@1: 68.7500 (68.5808)  Acc@5: 93.7500 (93.9404)  time: 0.3501  data: 0.0006  max mem: 2502
Train: Epoch[4/5]  [ 600/1142]  eta: 0:03:10  Lr: 0.001875  Loss: 0.0819  Acc@1: 68.7500 (68.5628)  Acc@5: 93.7500 (93.9268)  time: 0.3494  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [ 610/1142]  eta: 0:03:06  Lr: 0.001875  Loss: -0.0310  Acc@1: 62.5000 (68.4738)  Acc@5: 93.7500 (93.9137)  time: 0.3459  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [ 620/1142]  eta: 0:03:03  Lr: 0.001875  Loss: -0.4296  Acc@1: 62.5000 (68.4682)  Acc@5: 93.7500 (93.9815)  time: 0.3461  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [ 630/1142]  eta: 0:02:59  Lr: 0.001875  Loss: -0.1728  Acc@1: 68.7500 (68.4429)  Acc@5: 93.7500 (93.9382)  time: 0.3475  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [ 640/1142]  eta: 0:02:56  Lr: 0.001875  Loss: -0.5061  Acc@1: 68.7500 (68.4575)  Acc@5: 93.7500 (93.9450)  time: 0.3480  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [ 650/1142]  eta: 0:02:52  Lr: 0.001875  Loss: -0.4384  Acc@1: 68.7500 (68.5484)  Acc@5: 93.7500 (93.9900)  time: 0.3493  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [ 660/1142]  eta: 0:02:49  Lr: 0.001875  Loss: -0.3840  Acc@1: 62.5000 (68.4002)  Acc@5: 93.7500 (93.9675)  time: 0.3543  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [ 670/1142]  eta: 0:02:45  Lr: 0.001875  Loss: -0.4492  Acc@1: 62.5000 (68.3588)  Acc@5: 93.7500 (93.9922)  time: 0.3557  data: 0.0006  max mem: 2502
Train: Epoch[4/5]  [ 680/1142]  eta: 0:02:42  Lr: 0.001875  Loss: -0.4960  Acc@1: 68.7500 (68.4012)  Acc@5: 100.0000 (94.0345)  time: 0.3519  data: 0.0006  max mem: 2502
Train: Epoch[4/5]  [ 690/1142]  eta: 0:02:38  Lr: 0.001875  Loss: -0.4247  Acc@1: 75.0000 (68.4063)  Acc@5: 100.0000 (94.0394)  time: 0.3517  data: 0.0006  max mem: 2502
Train: Epoch[4/5]  [ 700/1142]  eta: 0:02:35  Lr: 0.001875  Loss: -0.6203  Acc@1: 75.0000 (68.5360)  Acc@5: 93.7500 (94.0799)  time: 0.3515  data: 0.0006  max mem: 2502
Train: Epoch[4/5]  [ 710/1142]  eta: 0:02:31  Lr: 0.001875  Loss: -0.6293  Acc@1: 75.0000 (68.5566)  Acc@5: 93.7500 (94.0577)  time: 0.3511  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [ 720/1142]  eta: 0:02:28  Lr: 0.001875  Loss: -0.1615  Acc@1: 68.7500 (68.5593)  Acc@5: 93.7500 (94.0621)  time: 0.3526  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [ 730/1142]  eta: 0:02:24  Lr: 0.001875  Loss: -0.6066  Acc@1: 68.7500 (68.5448)  Acc@5: 93.7500 (94.0492)  time: 0.3506  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [ 740/1142]  eta: 0:02:21  Lr: 0.001875  Loss: -0.9487  Acc@1: 68.7500 (68.5813)  Acc@5: 93.7500 (94.0789)  time: 0.3484  data: 0.0008  max mem: 2502
Train: Epoch[4/5]  [ 750/1142]  eta: 0:02:17  Lr: 0.001875  Loss: -0.0711  Acc@1: 68.7500 (68.5919)  Acc@5: 93.7500 (94.0829)  time: 0.3490  data: 0.0008  max mem: 2502
Train: Epoch[4/5]  [ 760/1142]  eta: 0:02:14  Lr: 0.001875  Loss: -0.1648  Acc@1: 68.7500 (68.5200)  Acc@5: 93.7500 (94.0046)  time: 0.3498  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [ 770/1142]  eta: 0:02:10  Lr: 0.001875  Loss: -0.5826  Acc@1: 68.7500 (68.4663)  Acc@5: 93.7500 (94.0094)  time: 0.3501  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [ 780/1142]  eta: 0:02:06  Lr: 0.001875  Loss: -0.6833  Acc@1: 68.7500 (68.3979)  Acc@5: 100.0000 (94.0221)  time: 0.3485  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [ 790/1142]  eta: 0:02:03  Lr: 0.001875  Loss: -0.1488  Acc@1: 62.5000 (68.3707)  Acc@5: 100.0000 (94.0028)  time: 0.3474  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [ 800/1142]  eta: 0:01:59  Lr: 0.001875  Loss: -0.2233  Acc@1: 62.5000 (68.3365)  Acc@5: 100.0000 (93.9997)  time: 0.3471  data: 0.0007  max mem: 2502
Train: Epoch[4/5]  [ 810/1142]  eta: 0:01:56  Lr: 0.001875  Loss: -0.7924  Acc@1: 62.5000 (68.2799)  Acc@5: 93.7500 (94.0043)  time: 0.3459  data: 0.0007  max mem: 2502
Train: Epoch[4/5]  [ 820/1142]  eta: 0:01:52  Lr: 0.001875  Loss: -0.2273  Acc@1: 62.5000 (68.2323)  Acc@5: 93.7500 (93.9860)  time: 0.3487  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [ 830/1142]  eta: 0:01:49  Lr: 0.001875  Loss: -0.5045  Acc@1: 68.7500 (68.2762)  Acc@5: 93.7500 (94.0057)  time: 0.3529  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [ 840/1142]  eta: 0:01:45  Lr: 0.001875  Loss: -0.7368  Acc@1: 68.7500 (68.2818)  Acc@5: 93.7500 (94.0250)  time: 0.3518  data: 0.0006  max mem: 2502
Train: Epoch[4/5]  [ 850/1142]  eta: 0:01:42  Lr: 0.001875  Loss: -0.6755  Acc@1: 68.7500 (68.3093)  Acc@5: 93.7500 (94.0144)  time: 0.3496  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [ 860/1142]  eta: 0:01:38  Lr: 0.001875  Loss: -0.6344  Acc@1: 68.7500 (68.2927)  Acc@5: 93.7500 (94.0476)  time: 0.3493  data: 0.0006  max mem: 2502
Train: Epoch[4/5]  [ 870/1142]  eta: 0:01:35  Lr: 0.001875  Loss: -0.7421  Acc@1: 68.7500 (68.3338)  Acc@5: 100.0000 (94.0729)  time: 0.3562  data: 0.0008  max mem: 2502
Train: Epoch[4/5]  [ 880/1142]  eta: 0:01:31  Lr: 0.001875  Loss: -0.1277  Acc@1: 68.7500 (68.2747)  Acc@5: 93.7500 (94.0763)  time: 0.3562  data: 0.0007  max mem: 2502
Train: Epoch[4/5]  [ 890/1142]  eta: 0:01:28  Lr: 0.001875  Loss: -0.7609  Acc@1: 68.7500 (68.3432)  Acc@5: 93.7500 (94.0937)  time: 0.3491  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [ 900/1142]  eta: 0:01:24  Lr: 0.001875  Loss: -0.0319  Acc@1: 68.7500 (68.3199)  Acc@5: 93.7500 (94.0968)  time: 0.3491  data: 0.0006  max mem: 2502
Train: Epoch[4/5]  [ 910/1142]  eta: 0:01:21  Lr: 0.001875  Loss: -0.2771  Acc@1: 62.5000 (68.2766)  Acc@5: 93.7500 (94.0793)  time: 0.3530  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [ 920/1142]  eta: 0:01:17  Lr: 0.001875  Loss: -0.7973  Acc@1: 62.5000 (68.1935)  Acc@5: 93.7500 (94.0622)  time: 0.3528  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [ 930/1142]  eta: 0:01:14  Lr: 0.001875  Loss: -0.6351  Acc@1: 62.5000 (68.1861)  Acc@5: 93.7500 (94.0857)  time: 0.3482  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [ 940/1142]  eta: 0:01:10  Lr: 0.001875  Loss: -0.1331  Acc@1: 62.5000 (68.1722)  Acc@5: 93.7500 (94.0821)  time: 0.3474  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [ 950/1142]  eta: 0:01:07  Lr: 0.001875  Loss: -0.4683  Acc@1: 68.7500 (68.1519)  Acc@5: 93.7500 (94.0720)  time: 0.3482  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [ 960/1142]  eta: 0:01:03  Lr: 0.001875  Loss: -0.7799  Acc@1: 62.5000 (68.1257)  Acc@5: 93.7500 (94.0752)  time: 0.3504  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [ 970/1142]  eta: 0:01:00  Lr: 0.001875  Loss: -0.6020  Acc@1: 68.7500 (68.1707)  Acc@5: 93.7500 (94.1040)  time: 0.3493  data: 0.0012  max mem: 2502
Train: Epoch[4/5]  [ 980/1142]  eta: 0:00:56  Lr: 0.001875  Loss: -0.4435  Acc@1: 75.0000 (68.2212)  Acc@5: 93.7500 (94.1004)  time: 0.3459  data: 0.0009  max mem: 2502
Train: Epoch[4/5]  [ 990/1142]  eta: 0:00:53  Lr: 0.001875  Loss: -0.4927  Acc@1: 75.0000 (68.2581)  Acc@5: 93.7500 (94.1158)  time: 0.3474  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [1000/1142]  eta: 0:00:49  Lr: 0.001875  Loss: -0.6629  Acc@1: 68.7500 (68.3004)  Acc@5: 100.0000 (94.1246)  time: 0.3481  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [1010/1142]  eta: 0:00:46  Lr: 0.001875  Loss: -0.8329  Acc@1: 68.7500 (68.2864)  Acc@5: 100.0000 (94.1271)  time: 0.3464  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [1020/1142]  eta: 0:00:42  Lr: 0.001875  Loss: -0.1162  Acc@1: 68.7500 (68.2664)  Acc@5: 93.7500 (94.1050)  time: 0.3469  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [1030/1142]  eta: 0:00:39  Lr: 0.001875  Loss: -0.6261  Acc@1: 68.7500 (68.2772)  Acc@5: 93.7500 (94.1198)  time: 0.3496  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [1040/1142]  eta: 0:00:35  Lr: 0.001875  Loss: -0.6935  Acc@1: 68.7500 (68.2817)  Acc@5: 93.7500 (94.1342)  time: 0.3549  data: 0.0012  max mem: 2502
Train: Epoch[4/5]  [1050/1142]  eta: 0:00:32  Lr: 0.001875  Loss: -0.1880  Acc@1: 68.7500 (68.2862)  Acc@5: 100.0000 (94.1425)  time: 0.3550  data: 0.0012  max mem: 2502
Train: Epoch[4/5]  [1060/1142]  eta: 0:00:28  Lr: 0.001875  Loss: -0.5016  Acc@1: 68.7500 (68.2729)  Acc@5: 93.7500 (94.1034)  time: 0.3503  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [1070/1142]  eta: 0:00:25  Lr: 0.001875  Loss: -0.1396  Acc@1: 68.7500 (68.2773)  Acc@5: 93.7500 (94.1060)  time: 0.3506  data: 0.0007  max mem: 2502
Train: Epoch[4/5]  [1080/1142]  eta: 0:00:21  Lr: 0.001875  Loss: -0.9495  Acc@1: 68.7500 (68.3453)  Acc@5: 93.7500 (94.1027)  time: 0.3562  data: 0.0007  max mem: 2502
Train: Epoch[4/5]  [1090/1142]  eta: 0:00:18  Lr: 0.001875  Loss: -0.9513  Acc@1: 68.7500 (68.3719)  Acc@5: 93.7500 (94.0937)  time: 0.3576  data: 0.0017  max mem: 2502
Train: Epoch[4/5]  [1100/1142]  eta: 0:00:14  Lr: 0.001875  Loss: -0.4792  Acc@1: 68.7500 (68.3583)  Acc@5: 93.7500 (94.1076)  time: 0.3539  data: 0.0017  max mem: 2502
Train: Epoch[4/5]  [1110/1142]  eta: 0:00:11  Lr: 0.001875  Loss: 0.1888  Acc@1: 68.7500 (68.3168)  Acc@5: 93.7500 (94.0819)  time: 0.3507  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [1120/1142]  eta: 0:00:07  Lr: 0.001875  Loss: 0.0777  Acc@1: 68.7500 (68.3040)  Acc@5: 93.7500 (94.1012)  time: 0.3484  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [1130/1142]  eta: 0:00:04  Lr: 0.001875  Loss: -0.9750  Acc@1: 75.0000 (68.3521)  Acc@5: 93.7500 (94.0871)  time: 0.3506  data: 0.0009  max mem: 2502
Train: Epoch[4/5]  [1140/1142]  eta: 0:00:00  Lr: 0.001875  Loss: -0.5408  Acc@1: 68.7500 (68.3392)  Acc@5: 93.7500 (94.0896)  time: 0.3514  data: 0.0010  max mem: 2502
Train: Epoch[4/5]  [1141/1142]  eta: 0:00:00  Lr: 0.001875  Loss: -0.4488  Acc@1: 68.7500 (68.3329)  Acc@5: 93.7500 (94.0925)  time: 0.3438  data: 0.0009  max mem: 2502
Train: Epoch[4/5] Total time: 0:06:40 (0.3508 s / it)
{0: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 1: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 2: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 3: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 4: {0: 0, 1: 300000, 2: 0, 3: 73060, 4: 0}, 5: {0: 0, 1: 300000, 2: 0, 3: 73060, 4: 0}, 6: {0: 0, 1: 300000, 2: 0, 3: 73060, 4: 0}, 7: {0: 0, 1: 300000, 2: 0, 3: 73060, 4: 0}, 8: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 9: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 10: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 11: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 12: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 13: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 14: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 15: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 16: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 17: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 18: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 19: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}}
Averaged stats: Lr: 0.001875  Loss: -0.4488  Acc@1: 68.7500 (68.3329)  Acc@5: 93.7500 (94.0925)
Train: Epoch[5/5]  [   0/1142]  eta: 0:13:56  Lr: 0.001875  Loss: -0.5332  Acc@1: 62.5000 (62.5000)  Acc@5: 100.0000 (100.0000)  time: 0.7321  data: 0.3825  max mem: 2502
Train: Epoch[5/5]  [  10/1142]  eta: 0:07:15  Lr: 0.001875  Loss: -0.6330  Acc@1: 68.7500 (71.0227)  Acc@5: 93.7500 (94.3182)  time: 0.3845  data: 0.0351  max mem: 2502
Train: Epoch[5/5]  [  20/1142]  eta: 0:06:51  Lr: 0.001875  Loss: -0.3825  Acc@1: 68.7500 (70.5357)  Acc@5: 93.7500 (92.8571)  time: 0.3486  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [  30/1142]  eta: 0:06:42  Lr: 0.001875  Loss: 0.3471  Acc@1: 68.7500 (68.1452)  Acc@5: 93.7500 (92.9435)  time: 0.3496  data: 0.0013  max mem: 2502
Train: Epoch[5/5]  [  40/1142]  eta: 0:06:34  Lr: 0.001875  Loss: -0.4126  Acc@1: 62.5000 (67.3780)  Acc@5: 93.7500 (93.1402)  time: 0.3482  data: 0.0013  max mem: 2502
Train: Epoch[5/5]  [  50/1142]  eta: 0:06:27  Lr: 0.001875  Loss: -0.6981  Acc@1: 68.7500 (68.3824)  Acc@5: 93.7500 (94.1176)  time: 0.3448  data: 0.0002  max mem: 2502
Train: Epoch[5/5]  [  60/1142]  eta: 0:06:22  Lr: 0.001875  Loss: -0.9477  Acc@1: 75.0000 (69.0574)  Acc@5: 100.0000 (94.2623)  time: 0.3460  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [  70/1142]  eta: 0:06:19  Lr: 0.001875  Loss: -1.1922  Acc@1: 75.0000 (70.0704)  Acc@5: 100.0000 (94.8063)  time: 0.3518  data: 0.0022  max mem: 2502
Train: Epoch[5/5]  [  80/1142]  eta: 0:06:15  Lr: 0.001875  Loss: -0.6144  Acc@1: 75.0000 (69.5988)  Acc@5: 100.0000 (94.9846)  time: 0.3529  data: 0.0023  max mem: 2502
Train: Epoch[5/5]  [  90/1142]  eta: 0:06:11  Lr: 0.001875  Loss: -0.9495  Acc@1: 75.0000 (70.1236)  Acc@5: 93.7500 (95.1236)  time: 0.3481  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [ 100/1142]  eta: 0:06:07  Lr: 0.001875  Loss: -0.4251  Acc@1: 68.7500 (69.6163)  Acc@5: 93.7500 (94.9876)  time: 0.3481  data: 0.0006  max mem: 2502
Train: Epoch[5/5]  [ 110/1142]  eta: 0:06:04  Lr: 0.001875  Loss: -0.6867  Acc@1: 62.5000 (69.3694)  Acc@5: 93.7500 (95.1014)  time: 0.3520  data: 0.0008  max mem: 2502
Train: Epoch[5/5]  [ 120/1142]  eta: 0:06:00  Lr: 0.001875  Loss: -0.1570  Acc@1: 68.7500 (68.9050)  Acc@5: 93.7500 (94.8864)  time: 0.3548  data: 0.0012  max mem: 2502
Train: Epoch[5/5]  [ 130/1142]  eta: 0:05:56  Lr: 0.001875  Loss: -0.3296  Acc@1: 68.7500 (68.7977)  Acc@5: 93.7500 (94.9427)  time: 0.3515  data: 0.0009  max mem: 2502
Train: Epoch[5/5]  [ 140/1142]  eta: 0:05:53  Lr: 0.001875  Loss: -0.3500  Acc@1: 62.5000 (68.7500)  Acc@5: 93.7500 (94.9911)  time: 0.3487  data: 0.0006  max mem: 2502
Train: Epoch[5/5]  [ 150/1142]  eta: 0:05:49  Lr: 0.001875  Loss: -0.6207  Acc@1: 62.5000 (68.7086)  Acc@5: 93.7500 (94.9089)  time: 0.3502  data: 0.0007  max mem: 2502
Train: Epoch[5/5]  [ 160/1142]  eta: 0:05:45  Lr: 0.001875  Loss: -0.1621  Acc@1: 62.5000 (68.2065)  Acc@5: 93.7500 (94.9534)  time: 0.3519  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [ 170/1142]  eta: 0:05:42  Lr: 0.001875  Loss: -0.7875  Acc@1: 62.5000 (68.2749)  Acc@5: 93.7500 (94.9196)  time: 0.3504  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [ 180/1142]  eta: 0:05:38  Lr: 0.001875  Loss: -0.7597  Acc@1: 68.7500 (68.3011)  Acc@5: 93.7500 (94.8895)  time: 0.3485  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [ 190/1142]  eta: 0:05:34  Lr: 0.001875  Loss: -1.0719  Acc@1: 62.5000 (68.2592)  Acc@5: 93.7500 (94.9607)  time: 0.3489  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [ 200/1142]  eta: 0:05:31  Lr: 0.001875  Loss: -0.0924  Acc@1: 68.7500 (68.2525)  Acc@5: 93.7500 (94.7761)  time: 0.3496  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [ 210/1142]  eta: 0:05:27  Lr: 0.001875  Loss: -0.9261  Acc@1: 68.7500 (68.6315)  Acc@5: 93.7500 (94.9052)  time: 0.3502  data: 0.0009  max mem: 2502
Train: Epoch[5/5]  [ 220/1142]  eta: 0:05:23  Lr: 0.001875  Loss: -0.4514  Acc@1: 68.7500 (68.4955)  Acc@5: 100.0000 (94.9378)  time: 0.3476  data: 0.0008  max mem: 2502
Train: Epoch[5/5]  [ 230/1142]  eta: 0:05:20  Lr: 0.001875  Loss: -0.3074  Acc@1: 68.7500 (68.5335)  Acc@5: 93.7500 (94.8593)  time: 0.3451  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [ 240/1142]  eta: 0:05:16  Lr: 0.001875  Loss: -0.6265  Acc@1: 68.7500 (68.5166)  Acc@5: 93.7500 (94.8392)  time: 0.3467  data: 0.0012  max mem: 2502
Train: Epoch[5/5]  [ 250/1142]  eta: 0:05:12  Lr: 0.001875  Loss: -0.4390  Acc@1: 68.7500 (68.5010)  Acc@5: 93.7500 (94.6713)  time: 0.3490  data: 0.0012  max mem: 2502
Train: Epoch[5/5]  [ 260/1142]  eta: 0:05:09  Lr: 0.001875  Loss: -0.1959  Acc@1: 62.5000 (68.3669)  Acc@5: 93.7500 (94.6839)  time: 0.3498  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [ 270/1142]  eta: 0:05:05  Lr: 0.001875  Loss: -0.6706  Acc@1: 62.5000 (68.4732)  Acc@5: 93.7500 (94.7648)  time: 0.3499  data: 0.0006  max mem: 2502
Train: Epoch[5/5]  [ 280/1142]  eta: 0:05:02  Lr: 0.001875  Loss: -0.5293  Acc@1: 75.0000 (68.7055)  Acc@5: 100.0000 (94.9066)  time: 0.3517  data: 0.0008  max mem: 2502
Train: Epoch[5/5]  [ 290/1142]  eta: 0:04:59  Lr: 0.001875  Loss: -0.5844  Acc@1: 75.0000 (68.7930)  Acc@5: 100.0000 (94.8883)  time: 0.3564  data: 0.0009  max mem: 2502
Train: Epoch[5/5]  [ 300/1142]  eta: 0:04:55  Lr: 0.001875  Loss: -0.6609  Acc@1: 75.0000 (68.8746)  Acc@5: 93.7500 (94.8713)  time: 0.3556  data: 0.0008  max mem: 2502
Train: Epoch[5/5]  [ 310/1142]  eta: 0:04:52  Lr: 0.001875  Loss: -0.7884  Acc@1: 75.0000 (68.8907)  Acc@5: 93.7500 (94.8151)  time: 0.3547  data: 0.0007  max mem: 2502
Train: Epoch[5/5]  [ 320/1142]  eta: 0:04:48  Lr: 0.001875  Loss: -0.4093  Acc@1: 68.7500 (68.9058)  Acc@5: 93.7500 (94.8598)  time: 0.3542  data: 0.0006  max mem: 2502
Train: Epoch[5/5]  [ 330/1142]  eta: 0:04:45  Lr: 0.001875  Loss: -0.4761  Acc@1: 75.0000 (68.9011)  Acc@5: 93.7500 (94.8263)  time: 0.3535  data: 0.0013  max mem: 2502
Train: Epoch[5/5]  [ 340/1142]  eta: 0:04:41  Lr: 0.001875  Loss: -0.4825  Acc@1: 68.7500 (68.9333)  Acc@5: 93.7500 (94.8314)  time: 0.3523  data: 0.0013  max mem: 2502
Train: Epoch[5/5]  [ 350/1142]  eta: 0:04:38  Lr: 0.001875  Loss: -0.3382  Acc@1: 68.7500 (68.9993)  Acc@5: 93.7500 (94.8006)  time: 0.3479  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [ 360/1142]  eta: 0:04:34  Lr: 0.001875  Loss: -0.3477  Acc@1: 68.7500 (69.1309)  Acc@5: 93.7500 (94.8061)  time: 0.3477  data: 0.0006  max mem: 2502
Train: Epoch[5/5]  [ 370/1142]  eta: 0:04:31  Lr: 0.001875  Loss: -0.6257  Acc@1: 68.7500 (69.1375)  Acc@5: 93.7500 (94.7608)  time: 0.3479  data: 0.0007  max mem: 2502
Train: Epoch[5/5]  [ 380/1142]  eta: 0:04:27  Lr: 0.001875  Loss: -0.7068  Acc@1: 68.7500 (69.0453)  Acc@5: 93.7500 (94.7014)  time: 0.3486  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [ 390/1142]  eta: 0:04:23  Lr: 0.001875  Loss: -0.8378  Acc@1: 62.5000 (69.1336)  Acc@5: 93.7500 (94.7410)  time: 0.3482  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [ 400/1142]  eta: 0:04:20  Lr: 0.001875  Loss: -0.5135  Acc@1: 68.7500 (69.1241)  Acc@5: 93.7500 (94.7319)  time: 0.3475  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [ 410/1142]  eta: 0:04:16  Lr: 0.001875  Loss: -0.4131  Acc@1: 68.7500 (69.0389)  Acc@5: 93.7500 (94.7536)  time: 0.3482  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [ 420/1142]  eta: 0:04:13  Lr: 0.001875  Loss: -0.6339  Acc@1: 68.7500 (69.0469)  Acc@5: 93.7500 (94.7892)  time: 0.3480  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [ 430/1142]  eta: 0:04:09  Lr: 0.001875  Loss: -0.5479  Acc@1: 75.0000 (69.1850)  Acc@5: 100.0000 (94.8231)  time: 0.3469  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [ 440/1142]  eta: 0:04:06  Lr: 0.001875  Loss: -0.4186  Acc@1: 68.7500 (69.1468)  Acc@5: 93.7500 (94.7704)  time: 0.3456  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [ 450/1142]  eta: 0:04:02  Lr: 0.001875  Loss: -0.4321  Acc@1: 68.7500 (69.1242)  Acc@5: 93.7500 (94.7894)  time: 0.3454  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [ 460/1142]  eta: 0:03:58  Lr: 0.001875  Loss: -0.8551  Acc@1: 68.7500 (69.0211)  Acc@5: 93.7500 (94.8075)  time: 0.3466  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [ 470/1142]  eta: 0:03:55  Lr: 0.001875  Loss: -0.2561  Acc@1: 62.5000 (68.9490)  Acc@5: 93.7500 (94.7585)  time: 0.3481  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [ 480/1142]  eta: 0:03:51  Lr: 0.001875  Loss: -0.0375  Acc@1: 68.7500 (68.9969)  Acc@5: 93.7500 (94.7115)  time: 0.3501  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [ 490/1142]  eta: 0:03:48  Lr: 0.001875  Loss: -0.7767  Acc@1: 68.7500 (69.0046)  Acc@5: 93.7500 (94.7047)  time: 0.3502  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [ 500/1142]  eta: 0:03:44  Lr: 0.001875  Loss: -0.5100  Acc@1: 62.5000 (68.8623)  Acc@5: 93.7500 (94.6732)  time: 0.3523  data: 0.0006  max mem: 2502
Train: Epoch[5/5]  [ 510/1142]  eta: 0:03:41  Lr: 0.001875  Loss: -0.6476  Acc@1: 68.7500 (68.9090)  Acc@5: 93.7500 (94.6551)  time: 0.3547  data: 0.0007  max mem: 2502
Train: Epoch[5/5]  [ 520/1142]  eta: 0:03:38  Lr: 0.001875  Loss: -1.0508  Acc@1: 68.7500 (68.9539)  Acc@5: 93.7500 (94.6497)  time: 0.3523  data: 0.0006  max mem: 2502
Train: Epoch[5/5]  [ 530/1142]  eta: 0:03:34  Lr: 0.001875  Loss: -0.4222  Acc@1: 75.0000 (69.0678)  Acc@5: 93.7500 (94.6563)  time: 0.3502  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [ 540/1142]  eta: 0:03:30  Lr: 0.001875  Loss: -0.8184  Acc@1: 75.0000 (69.1428)  Acc@5: 93.7500 (94.6627)  time: 0.3494  data: 0.0007  max mem: 2502
Train: Epoch[5/5]  [ 550/1142]  eta: 0:03:27  Lr: 0.001875  Loss: -0.7078  Acc@1: 75.0000 (69.0903)  Acc@5: 93.7500 (94.6461)  time: 0.3516  data: 0.0007  max mem: 2502
Train: Epoch[5/5]  [ 560/1142]  eta: 0:03:24  Lr: 0.001875  Loss: -0.5594  Acc@1: 68.7500 (69.0731)  Acc@5: 93.7500 (94.6747)  time: 0.3568  data: 0.0012  max mem: 2502
Train: Epoch[5/5]  [ 570/1142]  eta: 0:03:20  Lr: 0.001875  Loss: -0.6931  Acc@1: 68.7500 (69.0674)  Acc@5: 100.0000 (94.7023)  time: 0.3533  data: 0.0011  max mem: 2502
Train: Epoch[5/5]  [ 580/1142]  eta: 0:03:17  Lr: 0.001875  Loss: -0.3481  Acc@1: 68.7500 (69.0404)  Acc@5: 93.7500 (94.6644)  time: 0.3475  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [ 590/1142]  eta: 0:03:13  Lr: 0.001875  Loss: -0.2017  Acc@1: 68.7500 (68.9932)  Acc@5: 93.7500 (94.6277)  time: 0.3537  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [ 600/1142]  eta: 0:03:10  Lr: 0.001875  Loss: -0.3279  Acc@1: 68.7500 (68.9580)  Acc@5: 93.7500 (94.6131)  time: 0.3544  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [ 610/1142]  eta: 0:03:06  Lr: 0.001875  Loss: 0.1528  Acc@1: 62.5000 (68.8421)  Acc@5: 93.7500 (94.5786)  time: 0.3488  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [ 620/1142]  eta: 0:03:03  Lr: 0.001875  Loss: -0.5212  Acc@1: 68.7500 (68.8607)  Acc@5: 93.7500 (94.5552)  time: 0.3474  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [ 630/1142]  eta: 0:02:59  Lr: 0.001875  Loss: 0.2024  Acc@1: 75.0000 (68.9778)  Acc@5: 93.7500 (94.5721)  time: 0.3476  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [ 640/1142]  eta: 0:02:55  Lr: 0.001875  Loss: -0.8916  Acc@1: 75.0000 (69.0523)  Acc@5: 93.7500 (94.5593)  time: 0.3502  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [ 650/1142]  eta: 0:02:52  Lr: 0.001875  Loss: -0.9775  Acc@1: 68.7500 (69.0572)  Acc@5: 93.7500 (94.5757)  time: 0.3487  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [ 660/1142]  eta: 0:02:48  Lr: 0.001875  Loss: -0.6432  Acc@1: 75.0000 (69.1282)  Acc@5: 93.7500 (94.5443)  time: 0.3458  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [ 670/1142]  eta: 0:02:45  Lr: 0.001875  Loss: -0.1808  Acc@1: 75.0000 (69.1226)  Acc@5: 93.7500 (94.5697)  time: 0.3487  data: 0.0006  max mem: 2502
Train: Epoch[5/5]  [ 680/1142]  eta: 0:02:41  Lr: 0.001875  Loss: -0.7780  Acc@1: 75.0000 (69.1630)  Acc@5: 93.7500 (94.5393)  time: 0.3536  data: 0.0012  max mem: 2502
Train: Epoch[5/5]  [ 690/1142]  eta: 0:02:38  Lr: 0.001875  Loss: -0.8026  Acc@1: 75.0000 (69.2203)  Acc@5: 93.7500 (94.5459)  time: 0.3521  data: 0.0011  max mem: 2502
Train: Epoch[5/5]  [ 700/1142]  eta: 0:02:34  Lr: 0.001875  Loss: -0.5794  Acc@1: 75.0000 (69.2493)  Acc@5: 100.0000 (94.5881)  time: 0.3500  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [ 710/1142]  eta: 0:02:31  Lr: 0.001875  Loss: -0.5226  Acc@1: 68.7500 (69.2686)  Acc@5: 93.7500 (94.5763)  time: 0.3503  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [ 720/1142]  eta: 0:02:27  Lr: 0.001875  Loss: -0.7039  Acc@1: 68.7500 (69.2961)  Acc@5: 93.7500 (94.5822)  time: 0.3533  data: 0.0010  max mem: 2502
Train: Epoch[5/5]  [ 730/1142]  eta: 0:02:24  Lr: 0.001875  Loss: -0.0575  Acc@1: 68.7500 (69.2459)  Acc@5: 93.7500 (94.5793)  time: 0.3565  data: 0.0014  max mem: 2502
Train: Epoch[5/5]  [ 740/1142]  eta: 0:02:20  Lr: 0.001875  Loss: -0.4870  Acc@1: 62.5000 (69.1802)  Acc@5: 93.7500 (94.5344)  time: 0.3538  data: 0.0009  max mem: 2502
Train: Epoch[5/5]  [ 750/1142]  eta: 0:02:17  Lr: 0.001875  Loss: 0.0663  Acc@1: 68.7500 (69.2743)  Acc@5: 93.7500 (94.5240)  time: 0.3526  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [ 760/1142]  eta: 0:02:13  Lr: 0.001875  Loss: -0.5730  Acc@1: 75.0000 (69.3003)  Acc@5: 93.7500 (94.5220)  time: 0.3510  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [ 770/1142]  eta: 0:02:10  Lr: 0.001875  Loss: -0.6952  Acc@1: 75.0000 (69.3742)  Acc@5: 100.0000 (94.5444)  time: 0.3501  data: 0.0015  max mem: 2502
Train: Epoch[5/5]  [ 780/1142]  eta: 0:02:06  Lr: 0.001875  Loss: -0.5786  Acc@1: 68.7500 (69.4062)  Acc@5: 100.0000 (94.5743)  time: 0.3519  data: 0.0015  max mem: 2502
Train: Epoch[5/5]  [ 790/1142]  eta: 0:02:03  Lr: 0.001875  Loss: -0.4863  Acc@1: 75.0000 (69.4453)  Acc@5: 100.0000 (94.5954)  time: 0.3502  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [ 800/1142]  eta: 0:01:59  Lr: 0.001875  Loss: -0.6329  Acc@1: 75.0000 (69.4444)  Acc@5: 93.7500 (94.5849)  time: 0.3494  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [ 810/1142]  eta: 0:01:56  Lr: 0.001875  Loss: -0.4327  Acc@1: 68.7500 (69.5129)  Acc@5: 93.7500 (94.6054)  time: 0.3496  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [ 820/1142]  eta: 0:01:52  Lr: 0.001875  Loss: -0.2825  Acc@1: 68.7500 (69.4732)  Acc@5: 93.7500 (94.5874)  time: 0.3503  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [ 830/1142]  eta: 0:01:49  Lr: 0.001875  Loss: -0.2149  Acc@1: 68.7500 (69.4720)  Acc@5: 93.7500 (94.5773)  time: 0.3489  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [ 840/1142]  eta: 0:01:45  Lr: 0.001875  Loss: -0.6311  Acc@1: 68.7500 (69.4709)  Acc@5: 93.7500 (94.5675)  time: 0.3461  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [ 850/1142]  eta: 0:01:42  Lr: 0.001875  Loss: -0.5688  Acc@1: 68.7500 (69.5505)  Acc@5: 93.7500 (94.5946)  time: 0.3472  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [ 860/1142]  eta: 0:01:38  Lr: 0.001875  Loss: -0.6390  Acc@1: 68.7500 (69.5195)  Acc@5: 100.0000 (94.6138)  time: 0.3511  data: 0.0006  max mem: 2502
Train: Epoch[5/5]  [ 870/1142]  eta: 0:01:35  Lr: 0.001875  Loss: -0.5537  Acc@1: 68.7500 (69.4891)  Acc@5: 100.0000 (94.6398)  time: 0.3553  data: 0.0006  max mem: 2502
Train: Epoch[5/5]  [ 880/1142]  eta: 0:01:31  Lr: 0.001875  Loss: -0.8324  Acc@1: 75.0000 (69.5304)  Acc@5: 93.7500 (94.6439)  time: 0.3534  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [ 890/1142]  eta: 0:01:28  Lr: 0.001875  Loss: -0.3648  Acc@1: 75.0000 (69.6058)  Acc@5: 93.7500 (94.6479)  time: 0.3520  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [ 900/1142]  eta: 0:01:24  Lr: 0.001875  Loss: 0.0702  Acc@1: 75.0000 (69.6171)  Acc@5: 93.7500 (94.6379)  time: 0.3561  data: 0.0007  max mem: 2502
Train: Epoch[5/5]  [ 910/1142]  eta: 0:01:21  Lr: 0.001875  Loss: -0.2357  Acc@1: 75.0000 (69.6419)  Acc@5: 93.7500 (94.5939)  time: 0.3577  data: 0.0009  max mem: 2502
Train: Epoch[5/5]  [ 920/1142]  eta: 0:01:17  Lr: 0.001875  Loss: -0.5539  Acc@1: 75.0000 (69.6593)  Acc@5: 93.7500 (94.5915)  time: 0.3539  data: 0.0007  max mem: 2502
Train: Epoch[5/5]  [ 930/1142]  eta: 0:01:14  Lr: 0.001875  Loss: -0.9139  Acc@1: 75.0000 (69.6563)  Acc@5: 93.7500 (94.5959)  time: 0.3505  data: 0.0008  max mem: 2502
Train: Epoch[5/5]  [ 940/1142]  eta: 0:01:10  Lr: 0.001875  Loss: -0.5319  Acc@1: 75.0000 (69.6865)  Acc@5: 93.7500 (94.6068)  time: 0.3506  data: 0.0007  max mem: 2502
Train: Epoch[5/5]  [ 950/1142]  eta: 0:01:07  Lr: 0.001875  Loss: -0.8759  Acc@1: 75.0000 (69.7161)  Acc@5: 100.0000 (94.6175)  time: 0.3490  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [ 960/1142]  eta: 0:01:03  Lr: 0.001875  Loss: -0.0682  Acc@1: 68.7500 (69.7060)  Acc@5: 93.7500 (94.6020)  time: 0.3489  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [ 970/1142]  eta: 0:01:00  Lr: 0.001875  Loss: -0.2603  Acc@1: 68.7500 (69.6833)  Acc@5: 93.7500 (94.6189)  time: 0.3492  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [ 980/1142]  eta: 0:00:56  Lr: 0.001875  Loss: -0.6199  Acc@1: 75.0000 (69.6993)  Acc@5: 93.7500 (94.6165)  time: 0.3477  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [ 990/1142]  eta: 0:00:53  Lr: 0.001875  Loss: 0.0606  Acc@1: 62.5000 (69.6266)  Acc@5: 93.7500 (94.5888)  time: 0.3478  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [1000/1142]  eta: 0:00:49  Lr: 0.001875  Loss: -0.3208  Acc@1: 62.5000 (69.6054)  Acc@5: 93.7500 (94.5617)  time: 0.3478  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [1010/1142]  eta: 0:00:46  Lr: 0.001875  Loss: -0.2909  Acc@1: 68.7500 (69.5908)  Acc@5: 93.7500 (94.5413)  time: 0.3476  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [1020/1142]  eta: 0:00:42  Lr: 0.001875  Loss: -0.6955  Acc@1: 62.5000 (69.5642)  Acc@5: 93.7500 (94.5519)  time: 0.3466  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [1030/1142]  eta: 0:00:39  Lr: 0.001875  Loss: -0.4763  Acc@1: 68.7500 (69.5805)  Acc@5: 93.7500 (94.5381)  time: 0.3459  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [1040/1142]  eta: 0:00:35  Lr: 0.001875  Loss: 0.0699  Acc@1: 68.7500 (69.5545)  Acc@5: 93.7500 (94.5005)  time: 0.3480  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [1050/1142]  eta: 0:00:32  Lr: 0.001875  Loss: -0.7316  Acc@1: 68.7500 (69.5588)  Acc@5: 93.7500 (94.4814)  time: 0.3492  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [1060/1142]  eta: 0:00:28  Lr: 0.001875  Loss: -0.5922  Acc@1: 75.0000 (69.5393)  Acc@5: 93.7500 (94.4804)  time: 0.3506  data: 0.0006  max mem: 2502
Train: Epoch[5/5]  [1070/1142]  eta: 0:00:25  Lr: 0.001875  Loss: -0.2642  Acc@1: 68.7500 (69.5437)  Acc@5: 93.7500 (94.4853)  time: 0.3511  data: 0.0006  max mem: 2502
Train: Epoch[5/5]  [1080/1142]  eta: 0:00:21  Lr: 0.001875  Loss: -0.2460  Acc@1: 62.5000 (69.5363)  Acc@5: 93.7500 (94.5016)  time: 0.3498  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [1090/1142]  eta: 0:00:18  Lr: 0.001875  Loss: -0.5464  Acc@1: 62.5000 (69.4947)  Acc@5: 93.7500 (94.5062)  time: 0.3494  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [1100/1142]  eta: 0:00:14  Lr: 0.001875  Loss: -0.7953  Acc@1: 68.7500 (69.5163)  Acc@5: 100.0000 (94.5561)  time: 0.3510  data: 0.0006  max mem: 2502
Train: Epoch[5/5]  [1110/1142]  eta: 0:00:11  Lr: 0.001875  Loss: -0.7595  Acc@1: 68.7500 (69.5545)  Acc@5: 100.0000 (94.5826)  time: 0.3532  data: 0.0008  max mem: 2502
Train: Epoch[5/5]  [1120/1142]  eta: 0:00:07  Lr: 0.001875  Loss: -0.4386  Acc@1: 68.7500 (69.5584)  Acc@5: 93.7500 (94.5863)  time: 0.3541  data: 0.0007  max mem: 2502
Train: Epoch[5/5]  [1130/1142]  eta: 0:00:04  Lr: 0.001875  Loss: -0.5239  Acc@1: 68.7500 (69.5513)  Acc@5: 93.7500 (94.5955)  time: 0.3569  data: 0.0012  max mem: 2502
Train: Epoch[5/5]  [1140/1142]  eta: 0:00:00  Lr: 0.001875  Loss: -0.2015  Acc@1: 68.7500 (69.5333)  Acc@5: 100.0000 (94.6209)  time: 0.3538  data: 0.0012  max mem: 2502
Train: Epoch[5/5]  [1141/1142]  eta: 0:00:00  Lr: 0.001875  Loss: -1.0132  Acc@1: 68.7500 (69.5428)  Acc@5: 100.0000 (94.6236)  time: 0.3458  data: 0.0012  max mem: 2502
Train: Epoch[5/5] Total time: 0:06:40 (0.3507 s / it)
{0: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 1: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 2: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 3: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 4: {0: 0, 1: 300000, 2: 0, 3: 91325, 4: 0}, 5: {0: 0, 1: 300000, 2: 0, 3: 91325, 4: 0}, 6: {0: 0, 1: 300000, 2: 0, 3: 91325, 4: 0}, 7: {0: 0, 1: 300000, 2: 0, 3: 91325, 4: 0}, 8: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 9: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 10: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 11: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 12: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 13: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 14: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 15: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 16: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 17: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 18: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 19: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}}
Averaged stats: Lr: 0.001875  Loss: -1.0132  Acc@1: 68.7500 (69.5428)  Acc@5: 100.0000 (94.6236)
Test: [Task 1]  [   0/1627]  eta: 0:16:24  Loss: 1.4608 (1.4608)  Acc@1: 56.2500 (56.2500)  Acc@5: 93.7500 (93.7500)  time: 0.6054  data: 0.3917  max mem: 2502
Test: [Task 1]  [  10/1627]  eta: 0:06:47  Loss: 1.3379 (1.2588)  Acc@1: 62.5000 (63.6364)  Acc@5: 87.5000 (89.2045)  time: 0.2519  data: 0.0359  max mem: 2502
Test: [Task 1]  [  20/1627]  eta: 0:06:16  Loss: 1.1871 (1.2054)  Acc@1: 62.5000 (65.4762)  Acc@5: 87.5000 (89.2857)  time: 0.2157  data: 0.0003  max mem: 2502
Test: [Task 1]  [  30/1627]  eta: 0:06:04  Loss: 1.1976 (1.2070)  Acc@1: 62.5000 (65.5242)  Acc@5: 93.7500 (90.1210)  time: 0.2150  data: 0.0003  max mem: 2502
Test: [Task 1]  [  40/1627]  eta: 0:05:57  Loss: 1.2577 (1.2177)  Acc@1: 62.5000 (65.2439)  Acc@5: 93.7500 (90.7012)  time: 0.2152  data: 0.0003  max mem: 2502
Test: [Task 1]  [  50/1627]  eta: 0:05:52  Loss: 1.0173 (1.1905)  Acc@1: 68.7500 (66.9118)  Acc@5: 93.7500 (91.5441)  time: 0.2165  data: 0.0006  max mem: 2502
Test: [Task 1]  [  60/1627]  eta: 0:05:48  Loss: 1.0834 (1.2029)  Acc@1: 68.7500 (66.7008)  Acc@5: 93.7500 (91.5984)  time: 0.2164  data: 0.0006  max mem: 2502
Test: [Task 1]  [  70/1627]  eta: 0:05:44  Loss: 1.2199 (1.2053)  Acc@1: 62.5000 (66.8134)  Acc@5: 93.7500 (91.7254)  time: 0.2149  data: 0.0003  max mem: 2502
Test: [Task 1]  [  80/1627]  eta: 0:05:40  Loss: 0.9399 (1.1860)  Acc@1: 75.0000 (67.5154)  Acc@5: 93.7500 (92.0525)  time: 0.2142  data: 0.0003  max mem: 2502
Test: [Task 1]  [  90/1627]  eta: 0:05:37  Loss: 1.1303 (1.1985)  Acc@1: 68.7500 (67.1016)  Acc@5: 93.7500 (91.8269)  time: 0.2139  data: 0.0002  max mem: 2502
Test: [Task 1]  [ 100/1627]  eta: 0:05:34  Loss: 1.2516 (1.2215)  Acc@1: 68.7500 (66.8317)  Acc@5: 87.5000 (91.1510)  time: 0.2143  data: 0.0002  max mem: 2502
Test: [Task 1]  [ 110/1627]  eta: 0:05:32  Loss: 1.1631 (1.2163)  Acc@1: 68.7500 (66.9482)  Acc@5: 87.5000 (91.3288)  time: 0.2160  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 120/1627]  eta: 0:05:29  Loss: 1.1631 (1.2131)  Acc@1: 75.0000 (67.2521)  Acc@5: 93.7500 (91.3223)  time: 0.2170  data: 0.0005  max mem: 2502
Test: [Task 1]  [ 130/1627]  eta: 0:05:26  Loss: 1.2142 (1.2203)  Acc@1: 68.7500 (67.0324)  Acc@5: 93.7500 (91.3168)  time: 0.2155  data: 0.0005  max mem: 2502
Test: [Task 1]  [ 140/1627]  eta: 0:05:24  Loss: 1.1193 (1.2174)  Acc@1: 68.7500 (67.2429)  Acc@5: 93.7500 (91.3121)  time: 0.2164  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 150/1627]  eta: 0:05:22  Loss: 0.9823 (1.1986)  Acc@1: 75.0000 (67.8808)  Acc@5: 93.7500 (91.5563)  time: 0.2173  data: 0.0005  max mem: 2502
Test: [Task 1]  [ 160/1627]  eta: 0:05:20  Loss: 0.9823 (1.1926)  Acc@1: 75.0000 (68.1289)  Acc@5: 93.7500 (91.6925)  time: 0.2171  data: 0.0006  max mem: 2502
Test: [Task 1]  [ 170/1627]  eta: 0:05:17  Loss: 1.1413 (1.1862)  Acc@1: 68.7500 (68.2018)  Acc@5: 93.7500 (91.6667)  time: 0.2170  data: 0.0005  max mem: 2502
Test: [Task 1]  [ 180/1627]  eta: 0:05:15  Loss: 1.1413 (1.1928)  Acc@1: 62.5000 (67.8867)  Acc@5: 93.7500 (91.5746)  time: 0.2182  data: 0.0010  max mem: 2502
Test: [Task 1]  [ 190/1627]  eta: 0:05:13  Loss: 1.1898 (1.1910)  Acc@1: 68.7500 (67.8665)  Acc@5: 93.7500 (91.5249)  time: 0.2207  data: 0.0020  max mem: 2502
Test: [Task 1]  [ 200/1627]  eta: 0:05:11  Loss: 1.1851 (1.1915)  Acc@1: 68.7500 (68.0348)  Acc@5: 93.7500 (91.5112)  time: 0.2206  data: 0.0016  max mem: 2502
Test: [Task 1]  [ 210/1627]  eta: 0:05:09  Loss: 1.0382 (1.1884)  Acc@1: 75.0000 (68.1872)  Acc@5: 93.7500 (91.6173)  time: 0.2178  data: 0.0007  max mem: 2502
Test: [Task 1]  [ 220/1627]  eta: 0:05:06  Loss: 1.0382 (1.1962)  Acc@1: 68.7500 (67.8733)  Acc@5: 93.7500 (91.5441)  time: 0.2155  data: 0.0004  max mem: 2502
Test: [Task 1]  [ 230/1627]  eta: 0:05:04  Loss: 1.1548 (1.1929)  Acc@1: 68.7500 (67.9924)  Acc@5: 93.7500 (91.5314)  time: 0.2154  data: 0.0005  max mem: 2502
Test: [Task 1]  [ 240/1627]  eta: 0:05:02  Loss: 1.1202 (1.1885)  Acc@1: 68.7500 (68.0757)  Acc@5: 93.7500 (91.6234)  time: 0.2158  data: 0.0005  max mem: 2502
Test: [Task 1]  [ 250/1627]  eta: 0:05:00  Loss: 1.0960 (1.1910)  Acc@1: 75.0000 (68.2271)  Acc@5: 93.7500 (91.6086)  time: 0.2178  data: 0.0004  max mem: 2502
Test: [Task 1]  [ 260/1627]  eta: 0:04:58  Loss: 1.1177 (1.1908)  Acc@1: 68.7500 (68.3190)  Acc@5: 93.7500 (91.6667)  time: 0.2195  data: 0.0005  max mem: 2502
Test: [Task 1]  [ 270/1627]  eta: 0:04:55  Loss: 1.0499 (1.1829)  Acc@1: 75.0000 (68.6116)  Acc@5: 93.7500 (91.7435)  time: 0.2189  data: 0.0014  max mem: 2502
Test: [Task 1]  [ 280/1627]  eta: 0:04:53  Loss: 0.9582 (1.1832)  Acc@1: 75.0000 (68.7278)  Acc@5: 93.7500 (91.7037)  time: 0.2194  data: 0.0013  max mem: 2502
Test: [Task 1]  [ 290/1627]  eta: 0:04:51  Loss: 1.1517 (1.1818)  Acc@1: 68.7500 (68.7715)  Acc@5: 93.7500 (91.8385)  time: 0.2173  data: 0.0004  max mem: 2502
Test: [Task 1]  [ 300/1627]  eta: 0:04:49  Loss: 1.0812 (1.1809)  Acc@1: 68.7500 (68.8123)  Acc@5: 93.7500 (91.8812)  time: 0.2152  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 310/1627]  eta: 0:04:46  Loss: 1.0885 (1.1811)  Acc@1: 68.7500 (68.8304)  Acc@5: 93.7500 (91.9212)  time: 0.2155  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 320/1627]  eta: 0:04:44  Loss: 1.2145 (1.1813)  Acc@1: 68.7500 (68.7500)  Acc@5: 93.7500 (91.9977)  time: 0.2156  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 330/1627]  eta: 0:04:42  Loss: 1.0591 (1.1803)  Acc@1: 68.7500 (68.8066)  Acc@5: 93.7500 (91.9751)  time: 0.2162  data: 0.0004  max mem: 2502
Test: [Task 1]  [ 340/1627]  eta: 0:04:40  Loss: 0.9991 (1.1803)  Acc@1: 75.0000 (68.8966)  Acc@5: 93.7500 (91.9905)  time: 0.2165  data: 0.0009  max mem: 2502
Test: [Task 1]  [ 350/1627]  eta: 0:04:38  Loss: 1.2580 (1.1817)  Acc@1: 68.7500 (68.8568)  Acc@5: 87.5000 (91.9516)  time: 0.2165  data: 0.0009  max mem: 2502
Test: [Task 1]  [ 360/1627]  eta: 0:04:35  Loss: 1.0864 (1.1797)  Acc@1: 75.0000 (69.0270)  Acc@5: 87.5000 (91.9148)  time: 0.2158  data: 0.0004  max mem: 2502
Test: [Task 1]  [ 370/1627]  eta: 0:04:33  Loss: 1.0732 (1.1778)  Acc@1: 75.0000 (69.0364)  Acc@5: 93.7500 (91.9980)  time: 0.2145  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 380/1627]  eta: 0:04:31  Loss: 1.0011 (1.1764)  Acc@1: 68.7500 (69.1109)  Acc@5: 93.7500 (92.0112)  time: 0.2137  data: 0.0002  max mem: 2502
Test: [Task 1]  [ 390/1627]  eta: 0:04:28  Loss: 1.0491 (1.1777)  Acc@1: 75.0000 (69.0857)  Acc@5: 93.7500 (91.9277)  time: 0.2141  data: 0.0002  max mem: 2502
Test: [Task 1]  [ 400/1627]  eta: 0:04:26  Loss: 1.0684 (1.1781)  Acc@1: 68.7500 (69.0150)  Acc@5: 87.5000 (91.8953)  time: 0.2152  data: 0.0007  max mem: 2502
Test: [Task 1]  [ 410/1627]  eta: 0:04:24  Loss: 0.9764 (1.1775)  Acc@1: 68.7500 (69.1454)  Acc@5: 87.5000 (91.8339)  time: 0.2155  data: 0.0008  max mem: 2502
Test: [Task 1]  [ 420/1627]  eta: 0:04:22  Loss: 0.9764 (1.1758)  Acc@1: 75.0000 (69.1211)  Acc@5: 93.7500 (91.9240)  time: 0.2145  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 430/1627]  eta: 0:04:19  Loss: 1.0463 (1.1743)  Acc@1: 75.0000 (69.1560)  Acc@5: 93.7500 (91.9954)  time: 0.2146  data: 0.0002  max mem: 2502
Test: [Task 1]  [ 440/1627]  eta: 0:04:17  Loss: 1.1104 (1.1722)  Acc@1: 68.7500 (69.1610)  Acc@5: 93.7500 (92.0635)  time: 0.2156  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 450/1627]  eta: 0:04:15  Loss: 1.1755 (1.1751)  Acc@1: 68.7500 (69.0687)  Acc@5: 93.7500 (92.0177)  time: 0.2157  data: 0.0004  max mem: 2502
Test: [Task 1]  [ 460/1627]  eta: 0:04:13  Loss: 1.1933 (1.1745)  Acc@1: 62.5000 (69.0347)  Acc@5: 93.7500 (92.0146)  time: 0.2207  data: 0.0015  max mem: 2502
Test: [Task 1]  [ 470/1627]  eta: 0:04:11  Loss: 1.0571 (1.1712)  Acc@1: 68.7500 (69.1348)  Acc@5: 93.7500 (92.0249)  time: 0.2231  data: 0.0019  max mem: 2502
Test: [Task 1]  [ 480/1627]  eta: 0:04:09  Loss: 1.1907 (1.1762)  Acc@1: 68.7500 (68.9969)  Acc@5: 87.5000 (91.9439)  time: 0.2183  data: 0.0013  max mem: 2502
Test: [Task 1]  [ 490/1627]  eta: 0:04:07  Loss: 1.2707 (1.1775)  Acc@1: 62.5000 (68.9282)  Acc@5: 87.5000 (91.9425)  time: 0.2163  data: 0.0009  max mem: 2502
Test: [Task 1]  [ 500/1627]  eta: 0:04:04  Loss: 1.1147 (1.1787)  Acc@1: 68.7500 (68.9247)  Acc@5: 93.7500 (91.9661)  time: 0.2170  data: 0.0005  max mem: 2502
Test: [Task 1]  [ 510/1627]  eta: 0:04:02  Loss: 1.2122 (1.1844)  Acc@1: 68.7500 (68.8112)  Acc@5: 93.7500 (91.9031)  time: 0.2166  data: 0.0005  max mem: 2502
Test: [Task 1]  [ 520/1627]  eta: 0:04:00  Loss: 1.2734 (1.1920)  Acc@1: 62.5000 (68.6300)  Acc@5: 93.7500 (91.8786)  time: 0.2164  data: 0.0005  max mem: 2502
Test: [Task 1]  [ 530/1627]  eta: 0:03:58  Loss: 1.1477 (1.1880)  Acc@1: 62.5000 (68.6911)  Acc@5: 93.7500 (91.9374)  time: 0.2167  data: 0.0004  max mem: 2502
Test: [Task 1]  [ 540/1627]  eta: 0:03:56  Loss: 1.0485 (1.1882)  Acc@1: 68.7500 (68.6576)  Acc@5: 93.7500 (91.9016)  time: 0.2188  data: 0.0017  max mem: 2502
Test: [Task 1]  [ 550/1627]  eta: 0:03:54  Loss: 1.2459 (1.1903)  Acc@1: 68.7500 (68.6706)  Acc@5: 87.5000 (91.8671)  time: 0.2210  data: 0.0022  max mem: 2502
Test: [Task 1]  [ 560/1627]  eta: 0:03:51  Loss: 1.3580 (1.1932)  Acc@1: 68.7500 (68.5829)  Acc@5: 87.5000 (91.7892)  time: 0.2184  data: 0.0008  max mem: 2502
Test: [Task 1]  [ 570/1627]  eta: 0:03:49  Loss: 1.1908 (1.1905)  Acc@1: 68.7500 (68.6734)  Acc@5: 87.5000 (91.8126)  time: 0.2184  data: 0.0013  max mem: 2502
Test: [Task 1]  [ 580/1627]  eta: 0:03:47  Loss: 1.0988 (1.1914)  Acc@1: 68.7500 (68.5994)  Acc@5: 93.7500 (91.8029)  time: 0.2186  data: 0.0014  max mem: 2502
Test: [Task 1]  [ 590/1627]  eta: 0:03:45  Loss: 1.2063 (1.1910)  Acc@1: 68.7500 (68.6019)  Acc@5: 93.7500 (91.8676)  time: 0.2158  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 600/1627]  eta: 0:03:43  Loss: 1.1888 (1.1919)  Acc@1: 62.5000 (68.5316)  Acc@5: 93.7500 (91.8781)  time: 0.2153  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 610/1627]  eta: 0:03:41  Loss: 1.0785 (1.1900)  Acc@1: 68.7500 (68.5659)  Acc@5: 93.7500 (91.9190)  time: 0.2161  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 620/1627]  eta: 0:03:38  Loss: 1.1014 (1.1910)  Acc@1: 68.7500 (68.5789)  Acc@5: 93.7500 (91.8378)  time: 0.2175  data: 0.0004  max mem: 2502
Test: [Task 1]  [ 630/1627]  eta: 0:03:36  Loss: 1.1009 (1.1905)  Acc@1: 75.0000 (68.6410)  Acc@5: 87.5000 (91.8284)  time: 0.2175  data: 0.0004  max mem: 2502
Test: [Task 1]  [ 640/1627]  eta: 0:03:34  Loss: 1.0022 (1.1906)  Acc@1: 75.0000 (68.6817)  Acc@5: 93.7500 (91.7609)  time: 0.2162  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 650/1627]  eta: 0:03:32  Loss: 1.0400 (1.1902)  Acc@1: 68.7500 (68.6828)  Acc@5: 93.7500 (91.7723)  time: 0.2162  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 660/1627]  eta: 0:03:30  Loss: 1.0673 (1.1885)  Acc@1: 68.7500 (68.7500)  Acc@5: 93.7500 (91.7644)  time: 0.2166  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 670/1627]  eta: 0:03:27  Loss: 1.1114 (1.1878)  Acc@1: 68.7500 (68.7686)  Acc@5: 93.7500 (91.7567)  time: 0.2166  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 680/1627]  eta: 0:03:25  Loss: 1.1114 (1.1875)  Acc@1: 68.7500 (68.8051)  Acc@5: 87.5000 (91.7309)  time: 0.2156  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 690/1627]  eta: 0:03:23  Loss: 1.1433 (1.1853)  Acc@1: 75.0000 (68.8766)  Acc@5: 93.7500 (91.8144)  time: 0.2157  data: 0.0005  max mem: 2502
Test: [Task 1]  [ 700/1627]  eta: 0:03:21  Loss: 1.1433 (1.1851)  Acc@1: 75.0000 (68.9551)  Acc@5: 93.7500 (91.8242)  time: 0.2164  data: 0.0009  max mem: 2502
Test: [Task 1]  [ 710/1627]  eta: 0:03:19  Loss: 1.0390 (1.1828)  Acc@1: 75.0000 (69.0577)  Acc@5: 93.7500 (91.8601)  time: 0.2154  data: 0.0007  max mem: 2502
Test: [Task 1]  [ 720/1627]  eta: 0:03:16  Loss: 1.0346 (1.1807)  Acc@1: 75.0000 (69.0881)  Acc@5: 93.7500 (91.9123)  time: 0.2145  data: 0.0002  max mem: 2502
Test: [Task 1]  [ 730/1627]  eta: 0:03:14  Loss: 1.0753 (1.1820)  Acc@1: 68.7500 (69.0236)  Acc@5: 93.7500 (91.9374)  time: 0.2146  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 740/1627]  eta: 0:03:12  Loss: 1.1574 (1.1830)  Acc@1: 68.7500 (69.0705)  Acc@5: 93.7500 (91.9366)  time: 0.2152  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 750/1627]  eta: 0:03:10  Loss: 1.0631 (1.1818)  Acc@1: 75.0000 (69.1661)  Acc@5: 93.7500 (91.9524)  time: 0.2188  data: 0.0019  max mem: 2502
Test: [Task 1]  [ 760/1627]  eta: 0:03:08  Loss: 1.2424 (1.1850)  Acc@1: 68.7500 (69.0539)  Acc@5: 93.7500 (91.9185)  time: 0.2213  data: 0.0035  max mem: 2502
Test: [Task 1]  [ 770/1627]  eta: 0:03:06  Loss: 0.9816 (1.1813)  Acc@1: 68.7500 (69.1634)  Acc@5: 93.7500 (91.9909)  time: 0.2187  data: 0.0020  max mem: 2502
Test: [Task 1]  [ 780/1627]  eta: 0:03:03  Loss: 0.9214 (1.1797)  Acc@1: 75.0000 (69.1821)  Acc@5: 100.0000 (92.0134)  time: 0.2169  data: 0.0005  max mem: 2502
Test: [Task 1]  [ 790/1627]  eta: 0:03:01  Loss: 0.9845 (1.1814)  Acc@1: 68.7500 (69.1688)  Acc@5: 93.7500 (91.9959)  time: 0.2175  data: 0.0006  max mem: 2502
Test: [Task 1]  [ 800/1627]  eta: 0:02:59  Loss: 1.1500 (1.1805)  Acc@1: 68.7500 (69.1479)  Acc@5: 93.7500 (92.0256)  time: 0.2176  data: 0.0006  max mem: 2502
Test: [Task 1]  [ 810/1627]  eta: 0:02:57  Loss: 1.0517 (1.1796)  Acc@1: 75.0000 (69.2201)  Acc@5: 93.7500 (92.0237)  time: 0.2167  data: 0.0004  max mem: 2502
Test: [Task 1]  [ 820/1627]  eta: 0:02:55  Loss: 1.0479 (1.1786)  Acc@1: 75.0000 (69.2144)  Acc@5: 93.7500 (92.0371)  time: 0.2176  data: 0.0007  max mem: 2502
Test: [Task 1]  [ 830/1627]  eta: 0:02:53  Loss: 0.9687 (1.1780)  Acc@1: 68.7500 (69.2088)  Acc@5: 93.7500 (92.0803)  time: 0.2225  data: 0.0016  max mem: 2502
Test: [Task 1]  [ 840/1627]  eta: 0:02:51  Loss: 0.9687 (1.1760)  Acc@1: 75.0000 (69.2628)  Acc@5: 100.0000 (92.1076)  time: 0.2211  data: 0.0013  max mem: 2502
Test: [Task 1]  [ 850/1627]  eta: 0:02:48  Loss: 1.0887 (1.1767)  Acc@1: 68.7500 (69.2200)  Acc@5: 93.7500 (92.1049)  time: 0.2163  data: 0.0004  max mem: 2502
Test: [Task 1]  [ 860/1627]  eta: 0:02:46  Loss: 1.0359 (1.1753)  Acc@1: 68.7500 (69.2436)  Acc@5: 93.7500 (92.1312)  time: 0.2158  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 870/1627]  eta: 0:02:44  Loss: 0.9542 (1.1736)  Acc@1: 75.0000 (69.3097)  Acc@5: 93.7500 (92.1714)  time: 0.2159  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 880/1627]  eta: 0:02:42  Loss: 1.1520 (1.1757)  Acc@1: 68.7500 (69.2466)  Acc@5: 93.7500 (92.1822)  time: 0.2163  data: 0.0004  max mem: 2502
Test: [Task 1]  [ 890/1627]  eta: 0:02:40  Loss: 1.3450 (1.1776)  Acc@1: 62.5000 (69.1919)  Acc@5: 93.7500 (92.1647)  time: 0.2177  data: 0.0007  max mem: 2502
Test: [Task 1]  [ 900/1627]  eta: 0:02:38  Loss: 1.1565 (1.1777)  Acc@1: 68.7500 (69.2078)  Acc@5: 93.7500 (92.1754)  time: 0.2235  data: 0.0023  max mem: 2502
Test: [Task 1]  [ 910/1627]  eta: 0:02:35  Loss: 1.1883 (1.1785)  Acc@1: 68.7500 (69.2234)  Acc@5: 93.7500 (92.1446)  time: 0.2236  data: 0.0028  max mem: 2502
Test: [Task 1]  [ 920/1627]  eta: 0:02:33  Loss: 1.1838 (1.1782)  Acc@1: 68.7500 (69.2386)  Acc@5: 93.7500 (92.1485)  time: 0.2181  data: 0.0012  max mem: 2502
Test: [Task 1]  [ 930/1627]  eta: 0:02:31  Loss: 1.1708 (1.1791)  Acc@1: 68.7500 (69.1998)  Acc@5: 93.7500 (92.1254)  time: 0.2164  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 940/1627]  eta: 0:02:29  Loss: 1.1523 (1.1776)  Acc@1: 68.7500 (69.2614)  Acc@5: 93.7500 (92.1692)  time: 0.2159  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 950/1627]  eta: 0:02:27  Loss: 1.1670 (1.1783)  Acc@1: 68.7500 (69.2429)  Acc@5: 93.7500 (92.1793)  time: 0.2159  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 960/1627]  eta: 0:02:24  Loss: 1.1963 (1.1778)  Acc@1: 68.7500 (69.2378)  Acc@5: 93.7500 (92.1891)  time: 0.2163  data: 0.0004  max mem: 2502
Test: [Task 1]  [ 970/1627]  eta: 0:02:22  Loss: 1.0506 (1.1764)  Acc@1: 75.0000 (69.2842)  Acc@5: 93.7500 (92.1988)  time: 0.2174  data: 0.0005  max mem: 2502
Test: [Task 1]  [ 980/1627]  eta: 0:02:20  Loss: 1.0939 (1.1768)  Acc@1: 68.7500 (69.2788)  Acc@5: 93.7500 (92.1700)  time: 0.2177  data: 0.0005  max mem: 2502
Test: [Task 1]  [ 990/1627]  eta: 0:02:18  Loss: 1.2615 (1.1799)  Acc@1: 68.7500 (69.2545)  Acc@5: 87.5000 (92.1229)  time: 0.2162  data: 0.0003  max mem: 2502
Test: [Task 1]  [1000/1627]  eta: 0:02:16  Loss: 1.3066 (1.1807)  Acc@1: 68.7500 (69.2308)  Acc@5: 87.5000 (92.0892)  time: 0.2147  data: 0.0002  max mem: 2502
Test: [Task 1]  [1010/1627]  eta: 0:02:14  Loss: 1.1747 (1.1805)  Acc@1: 68.7500 (69.2136)  Acc@5: 93.7500 (92.1056)  time: 0.2144  data: 0.0002  max mem: 2502
Test: [Task 1]  [1020/1627]  eta: 0:02:11  Loss: 1.1363 (1.1802)  Acc@1: 68.7500 (69.2030)  Acc@5: 93.7500 (92.1095)  time: 0.2145  data: 0.0003  max mem: 2502
Test: [Task 1]  [1030/1627]  eta: 0:02:09  Loss: 0.9805 (1.1781)  Acc@1: 75.0000 (69.2653)  Acc@5: 93.7500 (92.1435)  time: 0.2152  data: 0.0003  max mem: 2502
Test: [Task 1]  [1040/1627]  eta: 0:02:07  Loss: 0.9561 (1.1769)  Acc@1: 75.0000 (69.3024)  Acc@5: 93.7500 (92.1710)  time: 0.2164  data: 0.0005  max mem: 2502
Test: [Task 1]  [1050/1627]  eta: 0:02:05  Loss: 0.9642 (1.1752)  Acc@1: 75.0000 (69.3447)  Acc@5: 93.7500 (92.1860)  time: 0.2157  data: 0.0005  max mem: 2502
Test: [Task 1]  [1060/1627]  eta: 0:02:03  Loss: 1.1340 (1.1758)  Acc@1: 68.7500 (69.3450)  Acc@5: 93.7500 (92.1772)  time: 0.2151  data: 0.0003  max mem: 2502
Test: [Task 1]  [1070/1627]  eta: 0:02:00  Loss: 1.1639 (1.1766)  Acc@1: 75.0000 (69.3511)  Acc@5: 93.7500 (92.1569)  time: 0.2160  data: 0.0004  max mem: 2502
Test: [Task 1]  [1080/1627]  eta: 0:01:58  Loss: 1.2266 (1.1770)  Acc@1: 68.7500 (69.3513)  Acc@5: 93.7500 (92.1485)  time: 0.2161  data: 0.0004  max mem: 2502
Test: [Task 1]  [1090/1627]  eta: 0:01:56  Loss: 1.1837 (1.1771)  Acc@1: 68.7500 (69.3515)  Acc@5: 93.7500 (92.1689)  time: 0.2159  data: 0.0003  max mem: 2502
Test: [Task 1]  [1100/1627]  eta: 0:01:54  Loss: 1.0689 (1.1750)  Acc@1: 68.7500 (69.3915)  Acc@5: 93.7500 (92.1889)  time: 0.2207  data: 0.0034  max mem: 2502
Test: [Task 1]  [1110/1627]  eta: 0:01:52  Loss: 1.1097 (1.1757)  Acc@1: 68.7500 (69.3857)  Acc@5: 93.7500 (92.1861)  time: 0.2245  data: 0.0046  max mem: 2502
Test: [Task 1]  [1120/1627]  eta: 0:01:50  Loss: 1.2379 (1.1769)  Acc@1: 62.5000 (69.2964)  Acc@5: 93.7500 (92.2056)  time: 0.2206  data: 0.0017  max mem: 2502
Test: [Task 1]  [1130/1627]  eta: 0:01:47  Loss: 1.1283 (1.1775)  Acc@1: 62.5000 (69.2695)  Acc@5: 93.7500 (92.2137)  time: 0.2171  data: 0.0005  max mem: 2502
Test: [Task 1]  [1140/1627]  eta: 0:01:45  Loss: 1.3318 (1.1788)  Acc@1: 62.5000 (69.2375)  Acc@5: 87.5000 (92.1779)  time: 0.2163  data: 0.0004  max mem: 2502
Test: [Task 1]  [1150/1627]  eta: 0:01:43  Loss: 1.3318 (1.1797)  Acc@1: 68.7500 (69.2116)  Acc@5: 87.5000 (92.1590)  time: 0.2165  data: 0.0004  max mem: 2502
Test: [Task 1]  [1160/1627]  eta: 0:01:41  Loss: 1.2034 (1.1786)  Acc@1: 68.7500 (69.2722)  Acc@5: 93.7500 (92.1673)  time: 0.2162  data: 0.0003  max mem: 2502
Test: [Task 1]  [1170/1627]  eta: 0:01:39  Loss: 1.1793 (1.1777)  Acc@1: 75.0000 (69.3211)  Acc@5: 93.7500 (92.1808)  time: 0.2171  data: 0.0004  max mem: 2502
Test: [Task 1]  [1180/1627]  eta: 0:01:37  Loss: 1.1221 (1.1783)  Acc@1: 68.7500 (69.3110)  Acc@5: 93.7500 (92.1941)  time: 0.2209  data: 0.0020  max mem: 2502
Test: [Task 1]  [1190/1627]  eta: 0:01:34  Loss: 1.2544 (1.1787)  Acc@1: 68.7500 (69.2800)  Acc@5: 93.7500 (92.2072)  time: 0.2225  data: 0.0019  max mem: 2502
Test: [Task 1]  [1200/1627]  eta: 0:01:32  Loss: 1.1912 (1.1787)  Acc@1: 68.7500 (69.2808)  Acc@5: 93.7500 (92.2044)  time: 0.2196  data: 0.0005  max mem: 2502
Test: [Task 1]  [1210/1627]  eta: 0:01:30  Loss: 0.9998 (1.1792)  Acc@1: 68.7500 (69.2506)  Acc@5: 93.7500 (92.1759)  time: 0.2172  data: 0.0004  max mem: 2502
Test: [Task 1]  [1220/1627]  eta: 0:01:28  Loss: 0.9998 (1.1784)  Acc@1: 68.7500 (69.2670)  Acc@5: 93.7500 (92.1990)  time: 0.2165  data: 0.0004  max mem: 2502
Test: [Task 1]  [1230/1627]  eta: 0:01:26  Loss: 1.1819 (1.1786)  Acc@1: 68.7500 (69.2679)  Acc@5: 93.7500 (92.1862)  time: 0.2157  data: 0.0004  max mem: 2502
Test: [Task 1]  [1240/1627]  eta: 0:01:24  Loss: 1.1741 (1.1779)  Acc@1: 68.7500 (69.2687)  Acc@5: 93.7500 (92.2089)  time: 0.2153  data: 0.0003  max mem: 2502
Test: [Task 1]  [1250/1627]  eta: 0:01:21  Loss: 1.1962 (1.1785)  Acc@1: 68.7500 (69.2396)  Acc@5: 93.7500 (92.2012)  time: 0.2184  data: 0.0007  max mem: 2502
Test: [Task 1]  [1260/1627]  eta: 0:01:19  Loss: 1.1430 (1.1784)  Acc@1: 68.7500 (69.2357)  Acc@5: 93.7500 (92.1987)  time: 0.2194  data: 0.0008  max mem: 2502
Test: [Task 1]  [1270/1627]  eta: 0:01:17  Loss: 1.0709 (1.1791)  Acc@1: 68.7500 (69.2122)  Acc@5: 93.7500 (92.1715)  time: 0.2166  data: 0.0003  max mem: 2502
Test: [Task 1]  [1280/1627]  eta: 0:01:15  Loss: 1.0162 (1.1773)  Acc@1: 68.7500 (69.2477)  Acc@5: 93.7500 (92.1936)  time: 0.2161  data: 0.0003  max mem: 2502
Test: [Task 1]  [1290/1627]  eta: 0:01:13  Loss: 1.0831 (1.1775)  Acc@1: 68.7500 (69.2341)  Acc@5: 93.7500 (92.1863)  time: 0.2153  data: 0.0003  max mem: 2502
Test: [Task 1]  [1300/1627]  eta: 0:01:11  Loss: 1.1209 (1.1768)  Acc@1: 68.7500 (69.2784)  Acc@5: 93.7500 (92.2127)  time: 0.2146  data: 0.0003  max mem: 2502
Test: [Task 1]  [1310/1627]  eta: 0:01:08  Loss: 0.9457 (1.1754)  Acc@1: 75.0000 (69.3316)  Acc@5: 93.7500 (92.2244)  time: 0.2158  data: 0.0010  max mem: 2502
Test: [Task 1]  [1320/1627]  eta: 0:01:06  Loss: 0.8786 (1.1737)  Acc@1: 75.0000 (69.3840)  Acc@5: 100.0000 (92.2549)  time: 0.2162  data: 0.0013  max mem: 2502
Test: [Task 1]  [1330/1627]  eta: 0:01:04  Loss: 0.9784 (1.1735)  Acc@1: 75.0000 (69.4262)  Acc@5: 93.7500 (92.2521)  time: 0.2164  data: 0.0008  max mem: 2502
Test: [Task 1]  [1340/1627]  eta: 0:01:02  Loss: 1.1120 (1.1740)  Acc@1: 68.7500 (69.3978)  Acc@5: 93.7500 (92.2539)  time: 0.2157  data: 0.0005  max mem: 2502
Test: [Task 1]  [1350/1627]  eta: 0:01:00  Loss: 0.9937 (1.1732)  Acc@1: 68.7500 (69.3977)  Acc@5: 93.7500 (92.2789)  time: 0.2144  data: 0.0002  max mem: 2502
Test: [Task 1]  [1360/1627]  eta: 0:00:57  Loss: 1.0128 (1.1728)  Acc@1: 68.7500 (69.4021)  Acc@5: 93.7500 (92.2805)  time: 0.2148  data: 0.0003  max mem: 2502
Test: [Task 1]  [1370/1627]  eta: 0:00:55  Loss: 1.0550 (1.1722)  Acc@1: 68.7500 (69.4292)  Acc@5: 93.7500 (92.2867)  time: 0.2163  data: 0.0008  max mem: 2502
Test: [Task 1]  [1380/1627]  eta: 0:00:53  Loss: 1.1235 (1.1726)  Acc@1: 62.5000 (69.4108)  Acc@5: 93.7500 (92.2791)  time: 0.2232  data: 0.0008  max mem: 2502
Test: [Task 1]  [1390/1627]  eta: 0:00:51  Loss: 1.2265 (1.1719)  Acc@1: 68.7500 (69.4240)  Acc@5: 93.7500 (92.2942)  time: 0.2241  data: 0.0012  max mem: 2502
Test: [Task 1]  [1400/1627]  eta: 0:00:49  Loss: 1.1773 (1.1721)  Acc@1: 75.0000 (69.4236)  Acc@5: 93.7500 (92.2868)  time: 0.2196  data: 0.0012  max mem: 2502
Test: [Task 1]  [1410/1627]  eta: 0:00:47  Loss: 0.9766 (1.1716)  Acc@1: 75.0000 (69.4499)  Acc@5: 93.7500 (92.2883)  time: 0.2179  data: 0.0004  max mem: 2502
Test: [Task 1]  [1420/1627]  eta: 0:00:44  Loss: 1.1117 (1.1715)  Acc@1: 68.7500 (69.4229)  Acc@5: 93.7500 (92.3074)  time: 0.2180  data: 0.0004  max mem: 2502
Test: [Task 1]  [1430/1627]  eta: 0:00:42  Loss: 1.3086 (1.1732)  Acc@1: 62.5000 (69.3877)  Acc@5: 93.7500 (92.2781)  time: 0.2190  data: 0.0006  max mem: 2502
Test: [Task 1]  [1440/1627]  eta: 0:00:40  Loss: 1.1911 (1.1726)  Acc@1: 68.7500 (69.3876)  Acc@5: 93.7500 (92.2883)  time: 0.2182  data: 0.0007  max mem: 2502
Test: [Task 1]  [1450/1627]  eta: 0:00:38  Loss: 1.2113 (1.1743)  Acc@1: 68.7500 (69.3401)  Acc@5: 93.7500 (92.2510)  time: 0.2171  data: 0.0005  max mem: 2502
Test: [Task 1]  [1460/1627]  eta: 0:00:36  Loss: 1.3239 (1.1746)  Acc@1: 68.7500 (69.3190)  Acc@5: 93.7500 (92.2527)  time: 0.2198  data: 0.0007  max mem: 2502
Test: [Task 1]  [1470/1627]  eta: 0:00:34  Loss: 1.1879 (1.1753)  Acc@1: 68.7500 (69.2938)  Acc@5: 93.7500 (92.2332)  time: 0.2236  data: 0.0019  max mem: 2502
Test: [Task 1]  [1480/1627]  eta: 0:00:31  Loss: 1.1879 (1.1755)  Acc@1: 68.7500 (69.2775)  Acc@5: 93.7500 (92.2434)  time: 0.2220  data: 0.0019  max mem: 2502
Test: [Task 1]  [1490/1627]  eta: 0:00:29  Loss: 1.1793 (1.1756)  Acc@1: 68.7500 (69.2866)  Acc@5: 93.7500 (92.2619)  time: 0.2226  data: 0.0007  max mem: 2502
Test: [Task 1]  [1500/1627]  eta: 0:00:27  Loss: 1.1379 (1.1756)  Acc@1: 68.7500 (69.3038)  Acc@5: 93.7500 (92.2510)  time: 0.2203  data: 0.0005  max mem: 2502
Test: [Task 1]  [1510/1627]  eta: 0:00:25  Loss: 1.0799 (1.1759)  Acc@1: 68.7500 (69.2795)  Acc@5: 93.7500 (92.2485)  time: 0.2162  data: 0.0004  max mem: 2502
Test: [Task 1]  [1520/1627]  eta: 0:00:23  Loss: 1.0799 (1.1748)  Acc@1: 68.7500 (69.3047)  Acc@5: 93.7500 (92.2625)  time: 0.2159  data: 0.0003  max mem: 2502
Test: [Task 1]  [1530/1627]  eta: 0:00:21  Loss: 1.0799 (1.1746)  Acc@1: 68.7500 (69.3011)  Acc@5: 100.0000 (92.2600)  time: 0.2164  data: 0.0003  max mem: 2502
Test: [Task 1]  [1540/1627]  eta: 0:00:18  Loss: 0.9596 (1.1739)  Acc@1: 68.7500 (69.2894)  Acc@5: 93.7500 (92.2818)  time: 0.2183  data: 0.0006  max mem: 2502
Test: [Task 1]  [1550/1627]  eta: 0:00:16  Loss: 0.9918 (1.1736)  Acc@1: 68.7500 (69.2980)  Acc@5: 93.7500 (92.2872)  time: 0.2176  data: 0.0008  max mem: 2502
Test: [Task 1]  [1560/1627]  eta: 0:00:14  Loss: 0.9565 (1.1723)  Acc@1: 75.0000 (69.3666)  Acc@5: 93.7500 (92.3046)  time: 0.2160  data: 0.0005  max mem: 2502
Test: [Task 1]  [1570/1627]  eta: 0:00:12  Loss: 1.0543 (1.1723)  Acc@1: 75.0000 (69.3746)  Acc@5: 93.7500 (92.3138)  time: 0.2157  data: 0.0003  max mem: 2502
Test: [Task 1]  [1580/1627]  eta: 0:00:10  Loss: 1.1386 (1.1722)  Acc@1: 68.7500 (69.3746)  Acc@5: 93.7500 (92.3189)  time: 0.2156  data: 0.0003  max mem: 2502
Test: [Task 1]  [1590/1627]  eta: 0:00:08  Loss: 1.1471 (1.1725)  Acc@1: 68.7500 (69.3707)  Acc@5: 100.0000 (92.3358)  time: 0.2150  data: 0.0003  max mem: 2502
Test: [Task 1]  [1600/1627]  eta: 0:00:05  Loss: 1.2088 (1.1734)  Acc@1: 68.7500 (69.3395)  Acc@5: 93.7500 (92.3056)  time: 0.2157  data: 0.0009  max mem: 2502
Test: [Task 1]  [1610/1627]  eta: 0:00:03  Loss: 1.1847 (1.1729)  Acc@1: 68.7500 (69.3475)  Acc@5: 93.7500 (92.3107)  time: 0.2180  data: 0.0010  max mem: 2502
Test: [Task 1]  [1620/1627]  eta: 0:00:01  Loss: 1.0039 (1.1719)  Acc@1: 75.0000 (69.3977)  Acc@5: 93.7500 (92.3234)  time: 0.2167  data: 0.0006  max mem: 2502
Test: [Task 1]  [1626/1627]  eta: 0:00:00  Loss: 0.9079 (1.1711)  Acc@1: 75.0000 (69.4338)  Acc@5: 93.7500 (92.3248)  time: 0.2147  data: 0.0004  max mem: 2502
Test: [Task 1] Total time: 0:05:53 (0.2176 s / it)
* Acc@1 69.434 Acc@5 92.325 loss 1.171
Test: [Task 2]  [  0/625]  eta: 0:05:38  Loss: 1.9500 (1.9500)  Acc@1: 43.7500 (43.7500)  Acc@5: 75.0000 (75.0000)  time: 0.5415  data: 0.3281  max mem: 2502
Test: [Task 2]  [ 10/625]  eta: 0:02:30  Loss: 2.1555 (2.2370)  Acc@1: 37.5000 (38.0682)  Acc@5: 75.0000 (71.5909)  time: 0.2449  data: 0.0301  max mem: 2502
Test: [Task 2]  [ 20/625]  eta: 0:02:19  Loss: 2.1951 (2.2224)  Acc@1: 37.5000 (39.8810)  Acc@5: 68.7500 (70.8333)  time: 0.2150  data: 0.0003  max mem: 2502
Test: [Task 2]  [ 30/625]  eta: 0:02:15  Loss: 2.1951 (2.2061)  Acc@1: 37.5000 (39.9194)  Acc@5: 75.0000 (71.5726)  time: 0.2195  data: 0.0009  max mem: 2502
Test: [Task 2]  [ 40/625]  eta: 0:02:13  Loss: 2.2176 (2.2253)  Acc@1: 31.2500 (39.1768)  Acc@5: 75.0000 (71.0366)  time: 0.2249  data: 0.0022  max mem: 2502
Test: [Task 2]  [ 50/625]  eta: 0:02:09  Loss: 2.3806 (2.2663)  Acc@1: 37.5000 (38.8480)  Acc@5: 68.7500 (70.5882)  time: 0.2221  data: 0.0027  max mem: 2502
Test: [Task 2]  [ 60/625]  eta: 0:02:06  Loss: 2.4394 (2.2872)  Acc@1: 37.5000 (37.5000)  Acc@5: 68.7500 (70.5943)  time: 0.2170  data: 0.0014  max mem: 2502
Test: [Task 2]  [ 70/625]  eta: 0:02:03  Loss: 2.3031 (2.2850)  Acc@1: 31.2500 (36.9718)  Acc@5: 68.7500 (70.7746)  time: 0.2160  data: 0.0004  max mem: 2502
Test: [Task 2]  [ 80/625]  eta: 0:02:01  Loss: 2.2371 (2.2800)  Acc@1: 37.5000 (37.6543)  Acc@5: 68.7500 (70.7562)  time: 0.2158  data: 0.0004  max mem: 2502
Test: [Task 2]  [ 90/625]  eta: 0:01:58  Loss: 2.3006 (2.2789)  Acc@1: 43.7500 (37.9121)  Acc@5: 68.7500 (70.6044)  time: 0.2156  data: 0.0004  max mem: 2502
Test: [Task 2]  [100/625]  eta: 0:01:56  Loss: 2.2969 (2.2806)  Acc@1: 37.5000 (37.3762)  Acc@5: 75.0000 (70.6064)  time: 0.2168  data: 0.0006  max mem: 2502
Test: [Task 2]  [110/625]  eta: 0:01:54  Loss: 2.2840 (2.2731)  Acc@1: 37.5000 (37.6689)  Acc@5: 75.0000 (70.9459)  time: 0.2217  data: 0.0018  max mem: 2502
Test: [Task 2]  [120/625]  eta: 0:01:51  Loss: 2.1449 (2.2638)  Acc@1: 37.5000 (38.0682)  Acc@5: 75.0000 (71.0227)  time: 0.2216  data: 0.0015  max mem: 2502
Test: [Task 2]  [130/625]  eta: 0:01:49  Loss: 2.2641 (2.2721)  Acc@1: 37.5000 (37.7863)  Acc@5: 75.0000 (70.8492)  time: 0.2170  data: 0.0005  max mem: 2502
Test: [Task 2]  [140/625]  eta: 0:01:47  Loss: 2.3131 (2.2761)  Acc@1: 31.2500 (37.6330)  Acc@5: 68.7500 (70.6117)  time: 0.2176  data: 0.0006  max mem: 2502
Test: [Task 2]  [150/625]  eta: 0:01:44  Loss: 2.2235 (2.2698)  Acc@1: 31.2500 (37.4586)  Acc@5: 75.0000 (71.0679)  time: 0.2169  data: 0.0005  max mem: 2502
Test: [Task 2]  [160/625]  eta: 0:01:42  Loss: 2.2193 (2.2756)  Acc@1: 31.2500 (37.3447)  Acc@5: 75.0000 (70.8075)  time: 0.2158  data: 0.0004  max mem: 2502
Test: [Task 2]  [170/625]  eta: 0:01:40  Loss: 2.2444 (2.2707)  Acc@1: 37.5000 (37.4635)  Acc@5: 68.7500 (70.9430)  time: 0.2158  data: 0.0004  max mem: 2502
Test: [Task 2]  [180/625]  eta: 0:01:37  Loss: 2.2487 (2.2753)  Acc@1: 31.2500 (37.2583)  Acc@5: 68.7500 (70.8909)  time: 0.2160  data: 0.0007  max mem: 2502
Test: [Task 2]  [190/625]  eta: 0:01:35  Loss: 2.3344 (2.2796)  Acc@1: 31.2500 (37.3364)  Acc@5: 68.7500 (70.4843)  time: 0.2168  data: 0.0009  max mem: 2502
Test: [Task 2]  [200/625]  eta: 0:01:33  Loss: 2.2777 (2.2821)  Acc@1: 37.5000 (37.1580)  Acc@5: 68.7500 (70.3980)  time: 0.2168  data: 0.0008  max mem: 2502
Test: [Task 2]  [210/625]  eta: 0:01:30  Loss: 2.2201 (2.2791)  Acc@1: 37.5000 (37.2630)  Acc@5: 68.7500 (70.5273)  time: 0.2164  data: 0.0005  max mem: 2502
Test: [Task 2]  [220/625]  eta: 0:01:28  Loss: 2.1503 (2.2729)  Acc@1: 37.5000 (37.4717)  Acc@5: 68.7500 (70.6165)  time: 0.2159  data: 0.0003  max mem: 2502
Test: [Task 2]  [230/625]  eta: 0:01:26  Loss: 2.1228 (2.2693)  Acc@1: 37.5000 (37.8247)  Acc@5: 68.7500 (70.6169)  time: 0.2157  data: 0.0003  max mem: 2502
Test: [Task 2]  [240/625]  eta: 0:01:24  Loss: 2.3263 (2.2702)  Acc@1: 37.5000 (37.8112)  Acc@5: 75.0000 (70.7469)  time: 0.2157  data: 0.0003  max mem: 2502
Test: [Task 2]  [250/625]  eta: 0:01:22  Loss: 2.3181 (2.2676)  Acc@1: 37.5000 (37.9482)  Acc@5: 75.0000 (70.8416)  time: 0.2164  data: 0.0010  max mem: 2502
Test: [Task 2]  [260/625]  eta: 0:01:19  Loss: 2.1187 (2.2620)  Acc@1: 37.5000 (38.1466)  Acc@5: 75.0000 (71.0489)  time: 0.2172  data: 0.0014  max mem: 2502
Test: [Task 2]  [270/625]  eta: 0:01:17  Loss: 2.1505 (2.2641)  Acc@1: 37.5000 (38.2380)  Acc@5: 68.7500 (70.7334)  time: 0.2157  data: 0.0007  max mem: 2502
Test: [Task 2]  [280/625]  eta: 0:01:15  Loss: 2.2289 (2.2672)  Acc@1: 37.5000 (38.1895)  Acc@5: 68.7500 (70.7295)  time: 0.2143  data: 0.0003  max mem: 2502
Test: [Task 2]  [290/625]  eta: 0:01:13  Loss: 2.3306 (2.2670)  Acc@1: 37.5000 (38.1658)  Acc@5: 68.7500 (70.7689)  time: 0.2145  data: 0.0004  max mem: 2502
Test: [Task 2]  [300/625]  eta: 0:01:10  Loss: 2.3183 (2.2674)  Acc@1: 37.5000 (38.1229)  Acc@5: 68.7500 (70.7849)  time: 0.2145  data: 0.0004  max mem: 2502
Test: [Task 2]  [310/625]  eta: 0:01:08  Loss: 2.1543 (2.2665)  Acc@1: 31.2500 (38.0627)  Acc@5: 75.0000 (70.9204)  time: 0.2155  data: 0.0002  max mem: 2502
Test: [Task 2]  [320/625]  eta: 0:01:06  Loss: 1.9438 (2.2524)  Acc@1: 43.7500 (38.3178)  Acc@5: 81.2500 (71.3980)  time: 0.2172  data: 0.0007  max mem: 2502
Test: [Task 2]  [330/625]  eta: 0:01:04  Loss: 1.8764 (2.2449)  Acc@1: 43.7500 (38.5385)  Acc@5: 81.2500 (71.5068)  time: 0.2173  data: 0.0009  max mem: 2502
Test: [Task 2]  [340/625]  eta: 0:01:02  Loss: 1.8000 (2.2295)  Acc@1: 56.2500 (39.0946)  Acc@5: 75.0000 (71.8475)  time: 0.2165  data: 0.0005  max mem: 2502
Test: [Task 2]  [350/625]  eta: 0:00:59  Loss: 1.7122 (2.2136)  Acc@1: 50.0000 (39.3697)  Acc@5: 81.2500 (72.2222)  time: 0.2160  data: 0.0003  max mem: 2502
Test: [Task 2]  [360/625]  eta: 0:00:57  Loss: 2.0229 (2.2164)  Acc@1: 37.5000 (39.2659)  Acc@5: 75.0000 (72.0395)  time: 0.2159  data: 0.0003  max mem: 2502
Test: [Task 2]  [370/625]  eta: 0:00:55  Loss: 2.0229 (2.2083)  Acc@1: 37.5000 (39.4542)  Acc@5: 75.0000 (72.2372)  time: 0.2161  data: 0.0004  max mem: 2502
Test: [Task 2]  [380/625]  eta: 0:00:53  Loss: 1.9641 (2.2073)  Acc@1: 43.7500 (39.6161)  Acc@5: 75.0000 (72.2113)  time: 0.2161  data: 0.0004  max mem: 2502
Test: [Task 2]  [390/625]  eta: 0:00:51  Loss: 2.0880 (2.2056)  Acc@1: 43.7500 (39.6419)  Acc@5: 75.0000 (72.2986)  time: 0.2188  data: 0.0007  max mem: 2502
Test: [Task 2]  [400/625]  eta: 0:00:49  Loss: 1.8501 (2.1952)  Acc@1: 43.7500 (39.9314)  Acc@5: 81.2500 (72.5218)  time: 0.2219  data: 0.0019  max mem: 2502
Test: [Task 2]  [410/625]  eta: 0:00:46  Loss: 1.8533 (2.1902)  Acc@1: 43.7500 (40.1308)  Acc@5: 81.2500 (72.6734)  time: 0.2207  data: 0.0016  max mem: 2502
Test: [Task 2]  [420/625]  eta: 0:00:44  Loss: 1.9892 (2.1889)  Acc@1: 43.7500 (40.0980)  Acc@5: 75.0000 (72.6989)  time: 0.2176  data: 0.0005  max mem: 2502
Test: [Task 2]  [430/625]  eta: 0:00:42  Loss: 1.9892 (2.1841)  Acc@1: 43.7500 (40.1682)  Acc@5: 75.0000 (72.8103)  time: 0.2171  data: 0.0007  max mem: 2502
Test: [Task 2]  [440/625]  eta: 0:00:40  Loss: 1.8828 (2.1756)  Acc@1: 43.7500 (40.4053)  Acc@5: 75.0000 (72.9592)  time: 0.2177  data: 0.0008  max mem: 2502
Test: [Task 2]  [450/625]  eta: 0:00:38  Loss: 1.8645 (2.1712)  Acc@1: 43.7500 (40.5349)  Acc@5: 81.2500 (73.0876)  time: 0.2170  data: 0.0005  max mem: 2502
Test: [Task 2]  [460/625]  eta: 0:00:35  Loss: 2.0200 (2.1685)  Acc@1: 43.7500 (40.6318)  Acc@5: 75.0000 (73.0884)  time: 0.2174  data: 0.0005  max mem: 2502
Test: [Task 2]  [470/625]  eta: 0:00:33  Loss: 2.1132 (2.1741)  Acc@1: 37.5000 (40.5255)  Acc@5: 68.7500 (72.9432)  time: 0.2199  data: 0.0004  max mem: 2502
Test: [Task 2]  [480/625]  eta: 0:00:31  Loss: 2.2012 (2.1748)  Acc@1: 37.5000 (40.4756)  Acc@5: 75.0000 (72.9210)  time: 0.2199  data: 0.0003  max mem: 2502
Test: [Task 2]  [490/625]  eta: 0:00:29  Loss: 2.0088 (2.1695)  Acc@1: 37.5000 (40.5677)  Acc@5: 75.0000 (73.0270)  time: 0.2171  data: 0.0003  max mem: 2502
Test: [Task 2]  [500/625]  eta: 0:00:27  Loss: 2.2047 (2.1712)  Acc@1: 37.5000 (40.4691)  Acc@5: 75.0000 (73.0165)  time: 0.2161  data: 0.0003  max mem: 2502
Test: [Task 2]  [510/625]  eta: 0:00:25  Loss: 2.2821 (2.1722)  Acc@1: 31.2500 (40.4721)  Acc@5: 68.7500 (72.9330)  time: 0.2160  data: 0.0003  max mem: 2502
Test: [Task 2]  [520/625]  eta: 0:00:22  Loss: 2.3373 (2.1795)  Acc@1: 31.2500 (40.2831)  Acc@5: 62.5000 (72.7207)  time: 0.2159  data: 0.0003  max mem: 2502
Test: [Task 2]  [530/625]  eta: 0:00:20  Loss: 2.3327 (2.1817)  Acc@1: 31.2500 (40.1836)  Acc@5: 68.7500 (72.7048)  time: 0.2162  data: 0.0003  max mem: 2502
Test: [Task 2]  [540/625]  eta: 0:00:18  Loss: 2.2408 (2.1802)  Acc@1: 37.5000 (40.2380)  Acc@5: 68.7500 (72.6548)  time: 0.2169  data: 0.0007  max mem: 2502
Test: [Task 2]  [550/625]  eta: 0:00:16  Loss: 1.8318 (2.1722)  Acc@1: 50.0000 (40.4492)  Acc@5: 75.0000 (72.8448)  time: 0.2172  data: 0.0010  max mem: 2502
Test: [Task 2]  [560/625]  eta: 0:00:14  Loss: 1.8318 (2.1685)  Acc@1: 50.0000 (40.5303)  Acc@5: 81.2500 (72.9947)  time: 0.2165  data: 0.0007  max mem: 2502
Test: [Task 2]  [570/625]  eta: 0:00:11  Loss: 1.9809 (2.1686)  Acc@1: 43.7500 (40.4772)  Acc@5: 81.2500 (73.0079)  time: 0.2157  data: 0.0003  max mem: 2502
Test: [Task 2]  [580/625]  eta: 0:00:09  Loss: 2.0944 (2.1649)  Acc@1: 43.7500 (40.5766)  Acc@5: 75.0000 (73.0960)  time: 0.2152  data: 0.0002  max mem: 2502
Test: [Task 2]  [590/625]  eta: 0:00:07  Loss: 1.9347 (2.1594)  Acc@1: 43.7500 (40.7255)  Acc@5: 81.2500 (73.1916)  time: 0.2150  data: 0.0002  max mem: 2502
Test: [Task 2]  [600/625]  eta: 0:00:05  Loss: 2.0062 (2.1627)  Acc@1: 37.5000 (40.5990)  Acc@5: 75.0000 (73.1281)  time: 0.2156  data: 0.0009  max mem: 2502
Test: [Task 2]  [610/625]  eta: 0:00:03  Loss: 2.4837 (2.1715)  Acc@1: 31.2500 (40.3642)  Acc@5: 62.5000 (72.8723)  time: 0.2157  data: 0.0009  max mem: 2502
Test: [Task 2]  [620/625]  eta: 0:00:01  Loss: 2.5178 (2.1715)  Acc@1: 31.2500 (40.3784)  Acc@5: 62.5000 (72.8462)  time: 0.2150  data: 0.0002  max mem: 2502
Test: [Task 2]  [624/625]  eta: 0:00:00  Loss: 2.3411 (2.1712)  Acc@1: 37.5000 (40.4100)  Acc@5: 68.7500 (72.8600)  time: 0.2147  data: 0.0002  max mem: 2502
Test: [Task 2] Total time: 0:02:16 (0.2177 s / it)
* Acc@1 40.410 Acc@5 72.860 loss 2.171
Test: [Task 3]  [  0/625]  eta: 0:05:52  Loss: 0.2418 (0.2418)  Acc@1: 93.7500 (93.7500)  Acc@5: 93.7500 (93.7500)  time: 0.5633  data: 0.3456  max mem: 2502
Test: [Task 3]  [ 10/625]  eta: 0:02:31  Loss: 0.2418 (0.2195)  Acc@1: 100.0000 (96.5909)  Acc@5: 100.0000 (99.4318)  time: 0.2466  data: 0.0317  max mem: 2502
Test: [Task 3]  [ 20/625]  eta: 0:02:20  Loss: 0.2344 (0.2334)  Acc@1: 100.0000 (95.5357)  Acc@5: 100.0000 (99.1071)  time: 0.2152  data: 0.0003  max mem: 2502
Test: [Task 3]  [ 30/625]  eta: 0:02:15  Loss: 0.2236 (0.2297)  Acc@1: 93.7500 (95.9677)  Acc@5: 100.0000 (99.1935)  time: 0.2167  data: 0.0005  max mem: 2502
Test: [Task 3]  [ 40/625]  eta: 0:02:11  Loss: 0.1474 (0.2078)  Acc@1: 100.0000 (96.4939)  Acc@5: 100.0000 (99.3902)  time: 0.2177  data: 0.0011  max mem: 2502
Test: [Task 3]  [ 50/625]  eta: 0:02:09  Loss: 0.1474 (0.2048)  Acc@1: 100.0000 (96.5686)  Acc@5: 100.0000 (99.3873)  time: 0.2203  data: 0.0021  max mem: 2502
Test: [Task 3]  [ 60/625]  eta: 0:02:06  Loss: 0.1827 (0.2021)  Acc@1: 100.0000 (96.8238)  Acc@5: 100.0000 (99.4877)  time: 0.2203  data: 0.0022  max mem: 2502
Test: [Task 3]  [ 70/625]  eta: 0:02:03  Loss: 0.1201 (0.1895)  Acc@1: 100.0000 (97.0951)  Acc@5: 100.0000 (99.4718)  time: 0.2161  data: 0.0010  max mem: 2502
Test: [Task 3]  [ 80/625]  eta: 0:02:00  Loss: 0.1115 (0.1935)  Acc@1: 100.0000 (97.0679)  Acc@5: 100.0000 (99.4599)  time: 0.2154  data: 0.0004  max mem: 2502
Test: [Task 3]  [ 90/625]  eta: 0:01:58  Loss: 0.1409 (0.1944)  Acc@1: 100.0000 (97.0467)  Acc@5: 100.0000 (99.3819)  time: 0.2178  data: 0.0006  max mem: 2502
Test: [Task 3]  [100/625]  eta: 0:01:55  Loss: 0.1449 (0.1923)  Acc@1: 100.0000 (97.1535)  Acc@5: 100.0000 (99.4431)  time: 0.2177  data: 0.0006  max mem: 2502
Test: [Task 3]  [110/625]  eta: 0:01:53  Loss: 0.1352 (0.1878)  Acc@1: 100.0000 (97.2973)  Acc@5: 100.0000 (99.4932)  time: 0.2198  data: 0.0012  max mem: 2502
Test: [Task 3]  [120/625]  eta: 0:01:51  Loss: 0.1277 (0.1880)  Acc@1: 100.0000 (97.2624)  Acc@5: 100.0000 (99.5351)  time: 0.2235  data: 0.0024  max mem: 2502
Test: [Task 3]  [130/625]  eta: 0:01:49  Loss: 0.1619 (0.1872)  Acc@1: 100.0000 (97.3282)  Acc@5: 100.0000 (99.5229)  time: 0.2202  data: 0.0018  max mem: 2502
Test: [Task 3]  [140/625]  eta: 0:01:46  Loss: 0.1687 (0.1927)  Acc@1: 100.0000 (97.1631)  Acc@5: 100.0000 (99.4681)  time: 0.2162  data: 0.0005  max mem: 2502
Test: [Task 3]  [150/625]  eta: 0:01:44  Loss: 0.1957 (0.1963)  Acc@1: 100.0000 (97.2268)  Acc@5: 100.0000 (99.4205)  time: 0.2160  data: 0.0003  max mem: 2502
Test: [Task 3]  [160/625]  eta: 0:01:42  Loss: 0.1496 (0.1965)  Acc@1: 100.0000 (97.2050)  Acc@5: 100.0000 (99.3789)  time: 0.2173  data: 0.0005  max mem: 2502
Test: [Task 3]  [170/625]  eta: 0:01:40  Loss: 0.1285 (0.1961)  Acc@1: 100.0000 (97.1857)  Acc@5: 100.0000 (99.4152)  time: 0.2179  data: 0.0005  max mem: 2502
Test: [Task 3]  [180/625]  eta: 0:01:37  Loss: 0.2176 (0.2002)  Acc@1: 93.7500 (97.0304)  Acc@5: 100.0000 (99.3785)  time: 0.2168  data: 0.0004  max mem: 2502
Test: [Task 3]  [190/625]  eta: 0:01:35  Loss: 0.2064 (0.1989)  Acc@1: 93.7500 (97.0223)  Acc@5: 100.0000 (99.3783)  time: 0.2173  data: 0.0009  max mem: 2502
Test: [Task 3]  [200/625]  eta: 0:01:33  Loss: 0.2064 (0.2033)  Acc@1: 93.7500 (96.7973)  Acc@5: 100.0000 (99.3781)  time: 0.2173  data: 0.0010  max mem: 2502
Test: [Task 3]  [210/625]  eta: 0:01:31  Loss: 0.1774 (0.2042)  Acc@1: 93.7500 (96.8009)  Acc@5: 100.0000 (99.3780)  time: 0.2160  data: 0.0004  max mem: 2502
Test: [Task 3]  [220/625]  eta: 0:01:28  Loss: 0.1486 (0.2065)  Acc@1: 100.0000 (96.7195)  Acc@5: 100.0000 (99.3778)  time: 0.2159  data: 0.0003  max mem: 2502
Test: [Task 3]  [230/625]  eta: 0:01:26  Loss: 0.1879 (0.2063)  Acc@1: 93.7500 (96.7532)  Acc@5: 100.0000 (99.3777)  time: 0.2161  data: 0.0003  max mem: 2502
Test: [Task 3]  [240/625]  eta: 0:01:24  Loss: 0.1603 (0.2089)  Acc@1: 93.7500 (96.6546)  Acc@5: 100.0000 (99.3517)  time: 0.2161  data: 0.0003  max mem: 2502
Test: [Task 3]  [250/625]  eta: 0:01:22  Loss: 0.1558 (0.2070)  Acc@1: 93.7500 (96.6384)  Acc@5: 100.0000 (99.3775)  time: 0.2160  data: 0.0003  max mem: 2502
Test: [Task 3]  [260/625]  eta: 0:01:19  Loss: 0.1413 (0.2055)  Acc@1: 100.0000 (96.6715)  Acc@5: 100.0000 (99.3774)  time: 0.2172  data: 0.0007  max mem: 2502
Test: [Task 3]  [270/625]  eta: 0:01:17  Loss: 0.1357 (0.2060)  Acc@1: 100.0000 (96.6328)  Acc@5: 100.0000 (99.3542)  time: 0.2178  data: 0.0007  max mem: 2502
Test: [Task 3]  [280/625]  eta: 0:01:15  Loss: 0.1278 (0.2055)  Acc@1: 93.7500 (96.6415)  Acc@5: 100.0000 (99.3550)  time: 0.2170  data: 0.0009  max mem: 2502
Test: [Task 3]  [290/625]  eta: 0:01:13  Loss: 0.1600 (0.2060)  Acc@1: 93.7500 (96.5636)  Acc@5: 100.0000 (99.3557)  time: 0.2158  data: 0.0008  max mem: 2502
Test: [Task 3]  [300/625]  eta: 0:01:10  Loss: 0.1600 (0.2062)  Acc@1: 93.7500 (96.5324)  Acc@5: 100.0000 (99.3771)  time: 0.2148  data: 0.0003  max mem: 2502
Test: [Task 3]  [310/625]  eta: 0:01:08  Loss: 0.1336 (0.2083)  Acc@1: 100.0000 (96.4831)  Acc@5: 100.0000 (99.2966)  time: 0.2146  data: 0.0003  max mem: 2502
Test: [Task 3]  [320/625]  eta: 0:01:06  Loss: 0.1526 (0.2076)  Acc@1: 93.7500 (96.4953)  Acc@5: 100.0000 (99.2796)  time: 0.2168  data: 0.0003  max mem: 2502
Test: [Task 3]  [330/625]  eta: 0:01:04  Loss: 0.1664 (0.2084)  Acc@1: 93.7500 (96.4502)  Acc@5: 100.0000 (99.2825)  time: 0.2192  data: 0.0010  max mem: 2502
Test: [Task 3]  [340/625]  eta: 0:01:02  Loss: 0.1632 (0.2066)  Acc@1: 100.0000 (96.5359)  Acc@5: 100.0000 (99.3035)  time: 0.2174  data: 0.0011  max mem: 2502
Test: [Task 3]  [350/625]  eta: 0:01:00  Loss: 0.1671 (0.2070)  Acc@1: 100.0000 (96.5278)  Acc@5: 100.0000 (99.2877)  time: 0.2168  data: 0.0004  max mem: 2502
Test: [Task 3]  [360/625]  eta: 0:00:57  Loss: 0.1871 (0.2081)  Acc@1: 93.7500 (96.4855)  Acc@5: 100.0000 (99.2902)  time: 0.2173  data: 0.0005  max mem: 2502
Test: [Task 3]  [370/625]  eta: 0:00:55  Loss: 0.2114 (0.2089)  Acc@1: 93.7500 (96.4286)  Acc@5: 100.0000 (99.2925)  time: 0.2164  data: 0.0004  max mem: 2502
Test: [Task 3]  [380/625]  eta: 0:00:53  Loss: 0.1711 (0.2077)  Acc@1: 93.7500 (96.4731)  Acc@5: 100.0000 (99.3110)  time: 0.2161  data: 0.0004  max mem: 2502
Test: [Task 3]  [390/625]  eta: 0:00:51  Loss: 0.1338 (0.2092)  Acc@1: 100.0000 (96.3875)  Acc@5: 100.0000 (99.3286)  time: 0.2182  data: 0.0007  max mem: 2502
Test: [Task 3]  [400/625]  eta: 0:00:49  Loss: 0.1585 (0.2086)  Acc@1: 93.7500 (96.3685)  Acc@5: 100.0000 (99.3298)  time: 0.2197  data: 0.0013  max mem: 2502
Test: [Task 3]  [410/625]  eta: 0:00:46  Loss: 0.1585 (0.2093)  Acc@1: 100.0000 (96.3656)  Acc@5: 100.0000 (99.3309)  time: 0.2189  data: 0.0010  max mem: 2502
Test: [Task 3]  [420/625]  eta: 0:00:44  Loss: 0.1391 (0.2092)  Acc@1: 100.0000 (96.3777)  Acc@5: 100.0000 (99.3319)  time: 0.2173  data: 0.0004  max mem: 2502
Test: [Task 3]  [430/625]  eta: 0:00:42  Loss: 0.1391 (0.2090)  Acc@1: 100.0000 (96.3747)  Acc@5: 100.0000 (99.3329)  time: 0.2169  data: 0.0004  max mem: 2502
Test: [Task 3]  [440/625]  eta: 0:00:40  Loss: 0.1762 (0.2107)  Acc@1: 93.7500 (96.3294)  Acc@5: 100.0000 (99.2914)  time: 0.2185  data: 0.0005  max mem: 2502
Test: [Task 3]  [450/625]  eta: 0:00:38  Loss: 0.1762 (0.2107)  Acc@1: 100.0000 (96.3692)  Acc@5: 100.0000 (99.2932)  time: 0.2180  data: 0.0005  max mem: 2502
Test: [Task 3]  [460/625]  eta: 0:00:35  Loss: 0.1207 (0.2101)  Acc@1: 100.0000 (96.3937)  Acc@5: 100.0000 (99.2950)  time: 0.2168  data: 0.0005  max mem: 2502
Test: [Task 3]  [470/625]  eta: 0:00:33  Loss: 0.1358 (0.2098)  Acc@1: 100.0000 (96.3907)  Acc@5: 100.0000 (99.2967)  time: 0.2166  data: 0.0008  max mem: 2502
Test: [Task 3]  [480/625]  eta: 0:00:31  Loss: 0.2028 (0.2111)  Acc@1: 100.0000 (96.4007)  Acc@5: 100.0000 (99.2853)  time: 0.2166  data: 0.0007  max mem: 2502
Test: [Task 3]  [490/625]  eta: 0:00:29  Loss: 0.2035 (0.2111)  Acc@1: 100.0000 (96.3977)  Acc@5: 100.0000 (99.2744)  time: 0.2161  data: 0.0003  max mem: 2502
Test: [Task 3]  [500/625]  eta: 0:00:27  Loss: 0.1763 (0.2103)  Acc@1: 100.0000 (96.3947)  Acc@5: 100.0000 (99.2764)  time: 0.2158  data: 0.0003  max mem: 2502
Test: [Task 3]  [510/625]  eta: 0:00:25  Loss: 0.1071 (0.2099)  Acc@1: 100.0000 (96.3919)  Acc@5: 100.0000 (99.2906)  time: 0.2175  data: 0.0005  max mem: 2502
Test: [Task 3]  [520/625]  eta: 0:00:22  Loss: 0.1661 (0.2095)  Acc@1: 100.0000 (96.3892)  Acc@5: 100.0000 (99.3042)  time: 0.2169  data: 0.0004  max mem: 2502
Test: [Task 3]  [530/625]  eta: 0:00:20  Loss: 0.1661 (0.2112)  Acc@1: 93.7500 (96.3512)  Acc@5: 100.0000 (99.3173)  time: 0.2152  data: 0.0003  max mem: 2502
Test: [Task 3]  [540/625]  eta: 0:00:18  Loss: 0.2451 (0.2123)  Acc@1: 93.7500 (96.3494)  Acc@5: 100.0000 (99.2953)  time: 0.2170  data: 0.0003  max mem: 2502
Test: [Task 3]  [550/625]  eta: 0:00:16  Loss: 0.2048 (0.2134)  Acc@1: 93.7500 (96.3362)  Acc@5: 100.0000 (99.2627)  time: 0.2173  data: 0.0003  max mem: 2502
Test: [Task 3]  [560/625]  eta: 0:00:14  Loss: 0.1888 (0.2134)  Acc@1: 93.7500 (96.3347)  Acc@5: 100.0000 (99.2647)  time: 0.2155  data: 0.0003  max mem: 2502
Test: [Task 3]  [570/625]  eta: 0:00:11  Loss: 0.1921 (0.2128)  Acc@1: 100.0000 (96.3551)  Acc@5: 100.0000 (99.2666)  time: 0.2148  data: 0.0003  max mem: 2502
Test: [Task 3]  [580/625]  eta: 0:00:09  Loss: 0.1937 (0.2142)  Acc@1: 93.7500 (96.2887)  Acc@5: 100.0000 (99.2685)  time: 0.2146  data: 0.0003  max mem: 2502
Test: [Task 3]  [590/625]  eta: 0:00:07  Loss: 0.1825 (0.2136)  Acc@1: 93.7500 (96.3198)  Acc@5: 100.0000 (99.2809)  time: 0.2144  data: 0.0003  max mem: 2502
Test: [Task 3]  [600/625]  eta: 0:00:05  Loss: 0.1818 (0.2134)  Acc@1: 100.0000 (96.2978)  Acc@5: 100.0000 (99.2720)  time: 0.2157  data: 0.0003  max mem: 2502
Test: [Task 3]  [610/625]  eta: 0:00:03  Loss: 0.1818 (0.2128)  Acc@1: 93.7500 (96.2971)  Acc@5: 100.0000 (99.2840)  time: 0.2173  data: 0.0003  max mem: 2502
Test: [Task 3]  [620/625]  eta: 0:00:01  Loss: 0.1879 (0.2136)  Acc@1: 93.7500 (96.2862)  Acc@5: 100.0000 (99.2854)  time: 0.2169  data: 0.0003  max mem: 2502
Test: [Task 3]  [624/625]  eta: 0:00:00  Loss: 0.1822 (0.2130)  Acc@1: 93.7500 (96.3100)  Acc@5: 100.0000 (99.2900)  time: 0.2168  data: 0.0003  max mem: 2502
Test: [Task 3] Total time: 0:02:16 (0.2178 s / it)
* Acc@1 96.310 Acc@5 99.290 loss 0.213
Test: [Task 4]  [ 0/29]  eta: 0:00:16  Loss: 2.9139 (2.9139)  Acc@1: 12.5000 (12.5000)  Acc@5: 75.0000 (75.0000)  time: 0.5779  data: 0.3621  max mem: 2502
Test: [Task 4]  [10/29]  eta: 0:00:04  Loss: 2.5549 (2.4083)  Acc@1: 18.7500 (26.1364)  Acc@5: 75.0000 (76.7045)  time: 0.2500  data: 0.0334  max mem: 2502
Test: [Task 4]  [20/29]  eta: 0:00:02  Loss: 2.9482 (2.7723)  Acc@1: 12.5000 (22.0238)  Acc@5: 62.5000 (62.5000)  time: 0.2167  data: 0.0005  max mem: 2502
Test: [Task 4]  [28/29]  eta: 0:00:00  Loss: 3.2326 (2.7148)  Acc@1: 6.2500 (25.2723)  Acc@5: 50.0000 (60.1307)  time: 0.2188  data: 0.0004  max mem: 2502
Test: [Task 4] Total time: 0:00:06 (0.2353 s / it)
* Acc@1 25.272 Acc@5 60.131 loss 2.715
{0: {0: 26032, 1: 26032, 2: 26032, 3: 26032, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0, 10: 0, 11: 0, 12: 0, 13: 0, 14: 0, 15: 0, 16: 0, 17: 0, 18: 0, 19: 0}, 1: {0: 0, 1: 0, 2: 0, 3: 0, 4: 32, 5: 32, 6: 32, 7: 32, 8: 0, 9: 0, 10: 0, 11: 0, 12: 9968, 13: 9968, 14: 9968, 15: 9968, 16: 0, 17: 0, 18: 0, 19: 0}, 2: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 10000, 9: 10000, 10: 10000, 11: 10000, 12: 0, 13: 0, 14: 0, 15: 0, 16: 0, 17: 0, 18: 0, 19: 0}, 3: {0: 0, 1: 0, 2: 0, 3: 0, 4: 80, 5: 80, 6: 80, 7: 80, 8: 0, 9: 0, 10: 0, 11: 0, 12: 379, 13: 379, 14: 379, 15: 379, 16: 0, 17: 0, 18: 0, 19: 0}}
[Average accuracy till task4]	Acc@1: 57.8565	Acc@5: 81.1514	Loss: 1.5675	Forgetting: 23.2747	Backward: -23.2747
Train: Epoch[1/5]  [   0/3750]  eta: 1:16:18  Lr: 0.001875  Loss: 1.2050  Acc@1: 6.2500 (6.2500)  Acc@5: 31.2500 (31.2500)  time: 1.2208  data: 0.7586  max mem: 2502
Train: Epoch[1/5]  [  10/3750]  eta: 0:27:12  Lr: 0.001875  Loss: 0.9854  Acc@1: 25.0000 (21.0227)  Acc@5: 68.7500 (63.6364)  time: 0.4364  data: 0.0712  max mem: 2503
Train: Epoch[1/5]  [  20/3750]  eta: 0:24:45  Lr: 0.001875  Loss: 0.9144  Acc@1: 25.0000 (25.5952)  Acc@5: 81.2500 (74.1071)  time: 0.3572  data: 0.0016  max mem: 2503
Train: Epoch[1/5]  [  30/3750]  eta: 0:23:44  Lr: 0.001875  Loss: 0.7945  Acc@1: 37.5000 (30.8468)  Acc@5: 87.5000 (80.0403)  time: 0.3533  data: 0.0006  max mem: 2503
Train: Epoch[1/5]  [  40/3750]  eta: 0:23:10  Lr: 0.001875  Loss: 0.4552  Acc@1: 43.7500 (35.5183)  Acc@5: 93.7500 (83.3841)  time: 0.3500  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [  50/3750]  eta: 0:22:55  Lr: 0.001875  Loss: 0.0942  Acc@1: 56.2500 (40.8088)  Acc@5: 93.7500 (85.0490)  time: 0.3547  data: 0.0011  max mem: 2503
Train: Epoch[1/5]  [  60/3750]  eta: 0:22:42  Lr: 0.001875  Loss: 0.0636  Acc@1: 68.7500 (45.3893)  Acc@5: 93.7500 (86.8852)  time: 0.3582  data: 0.0011  max mem: 2503
Train: Epoch[1/5]  [  70/3750]  eta: 0:22:27  Lr: 0.001875  Loss: 0.2791  Acc@1: 68.7500 (48.1514)  Acc@5: 93.7500 (87.9401)  time: 0.3519  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [  80/3750]  eta: 0:22:18  Lr: 0.001875  Loss: -0.1338  Acc@1: 62.5000 (50.3858)  Acc@5: 93.7500 (88.8117)  time: 0.3504  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [  90/3750]  eta: 0:22:08  Lr: 0.001875  Loss: 0.0469  Acc@1: 62.5000 (51.4423)  Acc@5: 93.7500 (89.5604)  time: 0.3516  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [ 100/3750]  eta: 0:22:00  Lr: 0.001875  Loss: 0.1079  Acc@1: 62.5000 (53.1559)  Acc@5: 93.7500 (90.0990)  time: 0.3499  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [ 110/3750]  eta: 0:21:51  Lr: 0.001875  Loss: -0.2806  Acc@1: 68.7500 (54.3919)  Acc@5: 93.7500 (90.7658)  time: 0.3481  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [ 120/3750]  eta: 0:21:43  Lr: 0.001875  Loss: -0.1832  Acc@1: 62.5000 (55.1136)  Acc@5: 100.0000 (91.2707)  time: 0.3457  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [ 130/3750]  eta: 0:21:37  Lr: 0.001875  Loss: -0.0943  Acc@1: 62.5000 (56.2023)  Acc@5: 100.0000 (91.7462)  time: 0.3474  data: 0.0017  max mem: 2503
Train: Epoch[1/5]  [ 140/3750]  eta: 0:21:31  Lr: 0.001875  Loss: -0.2477  Acc@1: 68.7500 (57.2695)  Acc@5: 100.0000 (92.1543)  time: 0.3497  data: 0.0030  max mem: 2503
Train: Epoch[1/5]  [ 150/3750]  eta: 0:21:25  Lr: 0.001875  Loss: -0.5044  Acc@1: 62.5000 (57.8642)  Acc@5: 100.0000 (92.4255)  time: 0.3487  data: 0.0016  max mem: 2503
Train: Epoch[1/5]  [ 160/3750]  eta: 0:21:20  Lr: 0.001875  Loss: -0.1903  Acc@1: 62.5000 (58.1522)  Acc@5: 100.0000 (92.7795)  time: 0.3483  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [ 170/3750]  eta: 0:21:15  Lr: 0.001875  Loss: -0.0624  Acc@1: 68.7500 (58.8816)  Acc@5: 100.0000 (92.9825)  time: 0.3499  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [ 180/3750]  eta: 0:21:13  Lr: 0.001875  Loss: -0.3261  Acc@1: 68.7500 (59.5994)  Acc@5: 100.0000 (93.1975)  time: 0.3568  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [ 190/3750]  eta: 0:21:08  Lr: 0.001875  Loss: -0.3249  Acc@1: 68.7500 (60.2094)  Acc@5: 93.7500 (93.2592)  time: 0.3580  data: 0.0008  max mem: 2503
Train: Epoch[1/5]  [ 200/3750]  eta: 0:21:04  Lr: 0.001875  Loss: -0.1672  Acc@1: 68.7500 (60.7898)  Acc@5: 100.0000 (93.5634)  time: 0.3524  data: 0.0009  max mem: 2503
Train: Epoch[1/5]  [ 210/3750]  eta: 0:20:59  Lr: 0.001875  Loss: -0.2800  Acc@1: 68.7500 (60.9301)  Acc@5: 100.0000 (93.6908)  time: 0.3507  data: 0.0006  max mem: 2503
Train: Epoch[1/5]  [ 220/3750]  eta: 0:20:55  Lr: 0.001875  Loss: -0.1527  Acc@1: 62.5000 (61.1425)  Acc@5: 100.0000 (93.8914)  time: 0.3515  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [ 230/3750]  eta: 0:20:52  Lr: 0.001875  Loss: -0.0661  Acc@1: 56.2500 (61.2284)  Acc@5: 100.0000 (93.9935)  time: 0.3546  data: 0.0015  max mem: 2503
Train: Epoch[1/5]  [ 240/3750]  eta: 0:20:48  Lr: 0.001875  Loss: -0.2743  Acc@1: 62.5000 (61.4886)  Acc@5: 100.0000 (94.0871)  time: 0.3559  data: 0.0015  max mem: 2503
Train: Epoch[1/5]  [ 250/3750]  eta: 0:20:44  Lr: 0.001875  Loss: -0.4829  Acc@1: 68.7500 (62.1016)  Acc@5: 93.7500 (94.1484)  time: 0.3519  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [ 260/3750]  eta: 0:20:39  Lr: 0.001875  Loss: -0.3776  Acc@1: 75.0000 (62.6676)  Acc@5: 93.7500 (94.2289)  time: 0.3478  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [ 270/3750]  eta: 0:20:35  Lr: 0.001875  Loss: -0.2153  Acc@1: 68.7500 (62.8459)  Acc@5: 93.7500 (94.2574)  time: 0.3496  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [ 280/3750]  eta: 0:20:31  Lr: 0.001875  Loss: 0.0491  Acc@1: 68.7500 (63.1673)  Acc@5: 100.0000 (94.4173)  time: 0.3510  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [ 290/3750]  eta: 0:20:26  Lr: 0.001875  Loss: -0.4779  Acc@1: 68.7500 (63.3376)  Acc@5: 100.0000 (94.5447)  time: 0.3485  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [ 300/3750]  eta: 0:20:22  Lr: 0.001875  Loss: -0.0135  Acc@1: 75.0000 (63.6628)  Acc@5: 100.0000 (94.6429)  time: 0.3463  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [ 310/3750]  eta: 0:20:18  Lr: 0.001875  Loss: 0.3354  Acc@1: 75.0000 (63.8063)  Acc@5: 100.0000 (94.6945)  time: 0.3476  data: 0.0011  max mem: 2503
Train: Epoch[1/5]  [ 320/3750]  eta: 0:20:13  Lr: 0.001875  Loss: -0.4996  Acc@1: 75.0000 (64.1160)  Acc@5: 100.0000 (94.7625)  time: 0.3480  data: 0.0009  max mem: 2503
Train: Epoch[1/5]  [ 330/3750]  eta: 0:20:09  Lr: 0.001875  Loss: 0.0228  Acc@1: 68.7500 (64.1994)  Acc@5: 100.0000 (94.8263)  time: 0.3464  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [ 340/3750]  eta: 0:20:05  Lr: 0.001875  Loss: -0.3510  Acc@1: 68.7500 (64.2229)  Acc@5: 100.0000 (94.9413)  time: 0.3492  data: 0.0011  max mem: 2503
Train: Epoch[1/5]  [ 350/3750]  eta: 0:20:02  Lr: 0.001875  Loss: -0.4759  Acc@1: 68.7500 (64.4231)  Acc@5: 100.0000 (95.0499)  time: 0.3545  data: 0.0013  max mem: 2503
Train: Epoch[1/5]  [ 360/3750]  eta: 0:19:58  Lr: 0.001875  Loss: -0.1006  Acc@1: 68.7500 (64.5256)  Acc@5: 100.0000 (95.0312)  time: 0.3546  data: 0.0013  max mem: 2503
Train: Epoch[1/5]  [ 370/3750]  eta: 0:19:55  Lr: 0.001875  Loss: -0.6207  Acc@1: 68.7500 (64.7069)  Acc@5: 93.7500 (95.0809)  time: 0.3540  data: 0.0012  max mem: 2503
Train: Epoch[1/5]  [ 380/3750]  eta: 0:19:51  Lr: 0.001875  Loss: -0.3832  Acc@1: 62.5000 (64.7638)  Acc@5: 100.0000 (95.1608)  time: 0.3523  data: 0.0006  max mem: 2503
Train: Epoch[1/5]  [ 390/3750]  eta: 0:19:47  Lr: 0.001875  Loss: -0.2001  Acc@1: 62.5000 (64.9297)  Acc@5: 100.0000 (95.2366)  time: 0.3493  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [ 400/3750]  eta: 0:19:44  Lr: 0.001875  Loss: 0.0996  Acc@1: 68.7500 (65.0094)  Acc@5: 100.0000 (95.2930)  time: 0.3525  data: 0.0006  max mem: 2503
Train: Epoch[1/5]  [ 410/3750]  eta: 0:19:40  Lr: 0.001875  Loss: -0.4042  Acc@1: 68.7500 (65.1764)  Acc@5: 100.0000 (95.4075)  time: 0.3534  data: 0.0006  max mem: 2503
Train: Epoch[1/5]  [ 420/3750]  eta: 0:19:36  Lr: 0.001875  Loss: -0.1779  Acc@1: 68.7500 (65.1128)  Acc@5: 100.0000 (95.4127)  time: 0.3500  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [ 430/3750]  eta: 0:19:32  Lr: 0.001875  Loss: -0.2887  Acc@1: 62.5000 (65.0522)  Acc@5: 100.0000 (95.4611)  time: 0.3488  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [ 440/3750]  eta: 0:19:29  Lr: 0.001875  Loss: -0.2133  Acc@1: 62.5000 (65.1786)  Acc@5: 100.0000 (95.5074)  time: 0.3492  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [ 450/3750]  eta: 0:19:25  Lr: 0.001875  Loss: -0.5672  Acc@1: 75.0000 (65.3825)  Acc@5: 100.0000 (95.5654)  time: 0.3489  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [ 460/3750]  eta: 0:19:21  Lr: 0.001875  Loss: -0.3659  Acc@1: 75.0000 (65.4691)  Acc@5: 100.0000 (95.6345)  time: 0.3472  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [ 470/3750]  eta: 0:19:17  Lr: 0.001875  Loss: -0.2047  Acc@1: 75.0000 (65.6714)  Acc@5: 100.0000 (95.6874)  time: 0.3472  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [ 480/3750]  eta: 0:19:13  Lr: 0.001875  Loss: -0.3572  Acc@1: 75.0000 (65.7225)  Acc@5: 100.0000 (95.7251)  time: 0.3494  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [ 490/3750]  eta: 0:19:09  Lr: 0.001875  Loss: -0.1095  Acc@1: 68.7500 (65.8096)  Acc@5: 100.0000 (95.7867)  time: 0.3487  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [ 500/3750]  eta: 0:19:05  Lr: 0.001875  Loss: -0.5845  Acc@1: 68.7500 (65.9431)  Acc@5: 100.0000 (95.8084)  time: 0.3456  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [ 510/3750]  eta: 0:19:01  Lr: 0.001875  Loss: -0.7372  Acc@1: 68.7500 (66.0592)  Acc@5: 100.0000 (95.8537)  time: 0.3450  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [ 520/3750]  eta: 0:18:57  Lr: 0.001875  Loss: -0.6774  Acc@1: 68.7500 (66.0988)  Acc@5: 100.0000 (95.8733)  time: 0.3458  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [ 530/3750]  eta: 0:18:53  Lr: 0.001875  Loss: -0.4521  Acc@1: 68.7500 (66.1488)  Acc@5: 100.0000 (95.9275)  time: 0.3471  data: 0.0009  max mem: 2503
Train: Epoch[1/5]  [ 540/3750]  eta: 0:18:50  Lr: 0.001875  Loss: -0.2302  Acc@1: 68.7500 (66.2084)  Acc@5: 100.0000 (95.9566)  time: 0.3473  data: 0.0008  max mem: 2503
Train: Epoch[1/5]  [ 550/3750]  eta: 0:18:46  Lr: 0.001875  Loss: -0.4440  Acc@1: 68.7500 (66.2999)  Acc@5: 100.0000 (95.9846)  time: 0.3484  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [ 560/3750]  eta: 0:18:42  Lr: 0.001875  Loss: -0.1670  Acc@1: 68.7500 (66.2545)  Acc@5: 100.0000 (95.9893)  time: 0.3515  data: 0.0006  max mem: 2503
Train: Epoch[1/5]  [ 570/3750]  eta: 0:18:39  Lr: 0.001875  Loss: -0.4231  Acc@1: 68.7500 (66.3638)  Acc@5: 100.0000 (96.0267)  time: 0.3534  data: 0.0007  max mem: 2503
Train: Epoch[1/5]  [ 580/3750]  eta: 0:18:36  Lr: 0.001875  Loss: -0.2543  Acc@1: 68.7500 (66.4694)  Acc@5: 100.0000 (96.0628)  time: 0.3529  data: 0.0007  max mem: 2503
Train: Epoch[1/5]  [ 590/3750]  eta: 0:18:32  Lr: 0.001875  Loss: -0.4980  Acc@1: 75.0000 (66.6244)  Acc@5: 100.0000 (96.1083)  time: 0.3530  data: 0.0006  max mem: 2503
Train: Epoch[1/5]  [ 600/3750]  eta: 0:18:28  Lr: 0.001875  Loss: -0.1329  Acc@1: 75.0000 (66.7741)  Acc@5: 100.0000 (96.1418)  time: 0.3513  data: 0.0006  max mem: 2503
Train: Epoch[1/5]  [ 610/3750]  eta: 0:18:25  Lr: 0.001875  Loss: 0.0194  Acc@1: 68.7500 (66.8167)  Acc@5: 100.0000 (96.1538)  time: 0.3496  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [ 620/3750]  eta: 0:18:21  Lr: 0.001875  Loss: -0.4780  Acc@1: 68.7500 (66.8579)  Acc@5: 100.0000 (96.1554)  time: 0.3530  data: 0.0008  max mem: 2503
Train: Epoch[1/5]  [ 630/3750]  eta: 0:18:18  Lr: 0.001875  Loss: -0.3957  Acc@1: 68.7500 (66.9077)  Acc@5: 100.0000 (96.1965)  time: 0.3531  data: 0.0009  max mem: 2503
Train: Epoch[1/5]  [ 640/3750]  eta: 0:18:14  Lr: 0.001875  Loss: -0.3998  Acc@1: 68.7500 (66.9657)  Acc@5: 100.0000 (96.1973)  time: 0.3492  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [ 650/3750]  eta: 0:18:10  Lr: 0.001875  Loss: -0.0663  Acc@1: 68.7500 (66.9835)  Acc@5: 93.7500 (96.1886)  time: 0.3481  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [ 660/3750]  eta: 0:18:07  Lr: 0.001875  Loss: 0.0122  Acc@1: 62.5000 (66.9913)  Acc@5: 100.0000 (96.1895)  time: 0.3507  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [ 670/3750]  eta: 0:18:03  Lr: 0.001875  Loss: -0.1840  Acc@1: 68.7500 (67.0455)  Acc@5: 100.0000 (96.2183)  time: 0.3502  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [ 680/3750]  eta: 0:18:00  Lr: 0.001875  Loss: -0.5662  Acc@1: 75.0000 (67.1347)  Acc@5: 100.0000 (96.2372)  time: 0.3491  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [ 690/3750]  eta: 0:17:56  Lr: 0.001875  Loss: -0.5428  Acc@1: 75.0000 (67.2124)  Acc@5: 100.0000 (96.2735)  time: 0.3480  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [ 700/3750]  eta: 0:17:52  Lr: 0.001875  Loss: -0.2355  Acc@1: 75.0000 (67.3324)  Acc@5: 100.0000 (96.2375)  time: 0.3489  data: 0.0013  max mem: 2503
Train: Epoch[1/5]  [ 710/3750]  eta: 0:17:49  Lr: 0.001875  Loss: -0.1196  Acc@1: 75.0000 (67.4666)  Acc@5: 93.7500 (96.2641)  time: 0.3495  data: 0.0013  max mem: 2503
Train: Epoch[1/5]  [ 720/3750]  eta: 0:17:45  Lr: 0.001875  Loss: -0.5223  Acc@1: 75.0000 (67.5277)  Acc@5: 100.0000 (96.3159)  time: 0.3460  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [ 730/3750]  eta: 0:17:41  Lr: 0.001875  Loss: -0.1421  Acc@1: 68.7500 (67.5274)  Acc@5: 100.0000 (96.3663)  time: 0.3494  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [ 740/3750]  eta: 0:17:38  Lr: 0.001875  Loss: -0.6394  Acc@1: 68.7500 (67.5776)  Acc@5: 100.0000 (96.3731)  time: 0.3540  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [ 750/3750]  eta: 0:17:34  Lr: 0.001875  Loss: 0.0948  Acc@1: 68.7500 (67.5682)  Acc@5: 93.7500 (96.3549)  time: 0.3520  data: 0.0013  max mem: 2503
Train: Epoch[1/5]  [ 760/3750]  eta: 0:17:31  Lr: 0.001875  Loss: -0.3199  Acc@1: 75.0000 (67.7316)  Acc@5: 100.0000 (96.3699)  time: 0.3508  data: 0.0015  max mem: 2503
Train: Epoch[1/5]  [ 770/3750]  eta: 0:17:27  Lr: 0.001875  Loss: -0.7509  Acc@1: 75.0000 (67.8340)  Acc@5: 100.0000 (96.4089)  time: 0.3508  data: 0.0007  max mem: 2503
Train: Epoch[1/5]  [ 780/3750]  eta: 0:17:24  Lr: 0.001875  Loss: -0.5623  Acc@1: 75.0000 (67.8697)  Acc@5: 100.0000 (96.3988)  time: 0.3521  data: 0.0012  max mem: 2503
Train: Epoch[1/5]  [ 790/3750]  eta: 0:17:20  Lr: 0.001875  Loss: 0.1006  Acc@1: 68.7500 (67.8808)  Acc@5: 100.0000 (96.4207)  time: 0.3521  data: 0.0011  max mem: 2503
Train: Epoch[1/5]  [ 800/3750]  eta: 0:17:17  Lr: 0.001875  Loss: -0.5162  Acc@1: 75.0000 (67.9775)  Acc@5: 100.0000 (96.4263)  time: 0.3505  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [ 810/3750]  eta: 0:17:13  Lr: 0.001875  Loss: -0.0438  Acc@1: 68.7500 (67.9639)  Acc@5: 100.0000 (96.4319)  time: 0.3522  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [ 820/3750]  eta: 0:17:10  Lr: 0.001875  Loss: -0.7079  Acc@1: 68.7500 (68.0420)  Acc@5: 100.0000 (96.4601)  time: 0.3506  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [ 830/3750]  eta: 0:17:06  Lr: 0.001875  Loss: -0.2706  Acc@1: 75.0000 (68.0355)  Acc@5: 100.0000 (96.4801)  time: 0.3503  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [ 840/3750]  eta: 0:17:03  Lr: 0.001875  Loss: -0.3722  Acc@1: 68.7500 (68.0514)  Acc@5: 100.0000 (96.4774)  time: 0.3506  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [ 850/3750]  eta: 0:16:59  Lr: 0.001875  Loss: -0.6555  Acc@1: 68.7500 (68.1037)  Acc@5: 100.0000 (96.4821)  time: 0.3484  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [ 860/3750]  eta: 0:16:55  Lr: 0.001875  Loss: -0.3602  Acc@1: 75.0000 (68.1257)  Acc@5: 100.0000 (96.4939)  time: 0.3480  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [ 870/3750]  eta: 0:16:52  Lr: 0.001875  Loss: -0.5014  Acc@1: 75.0000 (68.1831)  Acc@5: 100.0000 (96.5198)  time: 0.3485  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [ 880/3750]  eta: 0:16:48  Lr: 0.001875  Loss: -0.2045  Acc@1: 68.7500 (68.1399)  Acc@5: 100.0000 (96.5522)  time: 0.3494  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [ 890/3750]  eta: 0:16:44  Lr: 0.001875  Loss: -0.2959  Acc@1: 75.0000 (68.2379)  Acc@5: 100.0000 (96.5699)  time: 0.3474  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [ 900/3750]  eta: 0:16:41  Lr: 0.001875  Loss: -0.5686  Acc@1: 75.0000 (68.2575)  Acc@5: 100.0000 (96.5663)  time: 0.3460  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [ 910/3750]  eta: 0:16:37  Lr: 0.001875  Loss: -0.7419  Acc@1: 68.7500 (68.2835)  Acc@5: 93.7500 (96.5560)  time: 0.3489  data: 0.0017  max mem: 2503
Train: Epoch[1/5]  [ 920/3750]  eta: 0:16:34  Lr: 0.001875  Loss: -0.1796  Acc@1: 75.0000 (68.3496)  Acc@5: 100.0000 (96.5662)  time: 0.3513  data: 0.0043  max mem: 2503
Train: Epoch[1/5]  [ 930/3750]  eta: 0:16:30  Lr: 0.001875  Loss: -0.3452  Acc@1: 75.0000 (68.4479)  Acc@5: 100.0000 (96.5897)  time: 0.3510  data: 0.0029  max mem: 2503
Train: Epoch[1/5]  [ 940/3750]  eta: 0:16:27  Lr: 0.001875  Loss: -0.8637  Acc@1: 81.2500 (68.5242)  Acc@5: 100.0000 (96.6193)  time: 0.3511  data: 0.0008  max mem: 2503
Train: Epoch[1/5]  [ 950/3750]  eta: 0:16:23  Lr: 0.001875  Loss: -0.1172  Acc@1: 75.0000 (68.5331)  Acc@5: 100.0000 (96.6285)  time: 0.3521  data: 0.0013  max mem: 2503
Train: Epoch[1/5]  [ 960/3750]  eta: 0:16:20  Lr: 0.001875  Loss: -0.1386  Acc@1: 68.7500 (68.6264)  Acc@5: 100.0000 (96.6571)  time: 0.3530  data: 0.0018  max mem: 2503
Train: Epoch[1/5]  [ 970/3750]  eta: 0:16:16  Lr: 0.001875  Loss: -0.7073  Acc@1: 75.0000 (68.7243)  Acc@5: 100.0000 (96.6787)  time: 0.3530  data: 0.0014  max mem: 2503
Train: Epoch[1/5]  [ 980/3750]  eta: 0:16:13  Lr: 0.001875  Loss: -0.5460  Acc@1: 75.0000 (68.7755)  Acc@5: 100.0000 (96.6934)  time: 0.3530  data: 0.0007  max mem: 2503
Train: Epoch[1/5]  [ 990/3750]  eta: 0:16:09  Lr: 0.001875  Loss: -0.5757  Acc@1: 75.0000 (68.8572)  Acc@5: 100.0000 (96.7205)  time: 0.3522  data: 0.0006  max mem: 2503
Train: Epoch[1/5]  [1000/3750]  eta: 0:16:06  Lr: 0.001875  Loss: -0.6646  Acc@1: 75.0000 (68.9123)  Acc@5: 100.0000 (96.7408)  time: 0.3524  data: 0.0006  max mem: 2503
Train: Epoch[1/5]  [1010/3750]  eta: 0:16:02  Lr: 0.001875  Loss: -0.4416  Acc@1: 75.0000 (68.9726)  Acc@5: 100.0000 (96.7668)  time: 0.3528  data: 0.0016  max mem: 2503
Train: Epoch[1/5]  [1020/3750]  eta: 0:15:59  Lr: 0.001875  Loss: -0.8264  Acc@1: 75.0000 (69.0132)  Acc@5: 100.0000 (96.7801)  time: 0.3496  data: 0.0015  max mem: 2503
Train: Epoch[1/5]  [1030/3750]  eta: 0:15:55  Lr: 0.001875  Loss: -0.7504  Acc@1: 68.7500 (69.0349)  Acc@5: 100.0000 (96.8053)  time: 0.3480  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [1040/3750]  eta: 0:15:52  Lr: 0.001875  Loss: -0.4055  Acc@1: 68.7500 (69.0622)  Acc@5: 100.0000 (96.8000)  time: 0.3490  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [1050/3750]  eta: 0:15:48  Lr: 0.001875  Loss: -0.3264  Acc@1: 75.0000 (69.1365)  Acc@5: 100.0000 (96.8066)  time: 0.3494  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [1060/3750]  eta: 0:15:44  Lr: 0.001875  Loss: -0.7552  Acc@1: 75.0000 (69.1447)  Acc@5: 100.0000 (96.8308)  time: 0.3482  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [1070/3750]  eta: 0:15:41  Lr: 0.001875  Loss: -0.4779  Acc@1: 75.0000 (69.2110)  Acc@5: 100.0000 (96.8429)  time: 0.3478  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [1080/3750]  eta: 0:15:37  Lr: 0.001875  Loss: -0.5408  Acc@1: 75.0000 (69.2530)  Acc@5: 100.0000 (96.8663)  time: 0.3477  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [1090/3750]  eta: 0:15:34  Lr: 0.001875  Loss: -0.1100  Acc@1: 75.0000 (69.3229)  Acc@5: 100.0000 (96.8951)  time: 0.3485  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [1100/3750]  eta: 0:15:30  Lr: 0.001875  Loss: -0.6111  Acc@1: 68.7500 (69.3233)  Acc@5: 100.0000 (96.9005)  time: 0.3480  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [1110/3750]  eta: 0:15:26  Lr: 0.001875  Loss: -0.8121  Acc@1: 68.7500 (69.3632)  Acc@5: 100.0000 (96.9172)  time: 0.3460  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [1120/3750]  eta: 0:15:23  Lr: 0.001875  Loss: -0.4245  Acc@1: 75.0000 (69.4190)  Acc@5: 100.0000 (96.9280)  time: 0.3480  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [1130/3750]  eta: 0:15:19  Lr: 0.001875  Loss: -0.3585  Acc@1: 75.0000 (69.4242)  Acc@5: 100.0000 (96.9441)  time: 0.3498  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [1140/3750]  eta: 0:15:16  Lr: 0.001875  Loss: -0.5881  Acc@1: 75.0000 (69.4676)  Acc@5: 100.0000 (96.9599)  time: 0.3487  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [1150/3750]  eta: 0:15:12  Lr: 0.001875  Loss: -0.7710  Acc@1: 75.0000 (69.5374)  Acc@5: 100.0000 (96.9646)  time: 0.3497  data: 0.0007  max mem: 2503
Train: Epoch[1/5]  [1160/3750]  eta: 0:15:09  Lr: 0.001875  Loss: -0.7530  Acc@1: 75.0000 (69.6167)  Acc@5: 100.0000 (96.9746)  time: 0.3516  data: 0.0008  max mem: 2503
Train: Epoch[1/5]  [1170/3750]  eta: 0:15:05  Lr: 0.001875  Loss: -0.3089  Acc@1: 75.0000 (69.6947)  Acc@5: 100.0000 (96.9951)  time: 0.3520  data: 0.0007  max mem: 2503
Train: Epoch[1/5]  [1180/3750]  eta: 0:15:02  Lr: 0.001875  Loss: -0.6483  Acc@1: 75.0000 (69.6920)  Acc@5: 100.0000 (96.9941)  time: 0.3530  data: 0.0008  max mem: 2503
Train: Epoch[1/5]  [1190/3750]  eta: 0:14:58  Lr: 0.001875  Loss: -0.7753  Acc@1: 75.0000 (69.7628)  Acc@5: 100.0000 (96.9931)  time: 0.3520  data: 0.0015  max mem: 2503
Train: Epoch[1/5]  [1200/3750]  eta: 0:14:55  Lr: 0.001875  Loss: -0.7366  Acc@1: 75.0000 (69.7960)  Acc@5: 100.0000 (97.0181)  time: 0.3505  data: 0.0013  max mem: 2503
Train: Epoch[1/5]  [1210/3750]  eta: 0:14:51  Lr: 0.001875  Loss: -0.4446  Acc@1: 68.7500 (69.8080)  Acc@5: 100.0000 (97.0118)  time: 0.3498  data: 0.0007  max mem: 2503
Train: Epoch[1/5]  [1220/3750]  eta: 0:14:48  Lr: 0.001875  Loss: -0.5256  Acc@1: 68.7500 (69.7993)  Acc@5: 100.0000 (97.0260)  time: 0.3482  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [1230/3750]  eta: 0:14:44  Lr: 0.001875  Loss: -0.1186  Acc@1: 68.7500 (69.8213)  Acc@5: 100.0000 (97.0146)  time: 0.3485  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [1240/3750]  eta: 0:14:41  Lr: 0.001875  Loss: -0.9137  Acc@1: 75.0000 (69.8479)  Acc@5: 100.0000 (97.0387)  time: 0.3488  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [1250/3750]  eta: 0:14:37  Lr: 0.001875  Loss: -0.2260  Acc@1: 75.0000 (69.9041)  Acc@5: 100.0000 (97.0524)  time: 0.3478  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [1260/3750]  eta: 0:14:33  Lr: 0.001875  Loss: -0.3762  Acc@1: 75.0000 (69.9445)  Acc@5: 100.0000 (97.0559)  time: 0.3481  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [1270/3750]  eta: 0:14:30  Lr: 0.001875  Loss: -0.4801  Acc@1: 75.0000 (70.0039)  Acc@5: 100.0000 (97.0692)  time: 0.3494  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [1280/3750]  eta: 0:14:26  Lr: 0.001875  Loss: -0.6017  Acc@1: 75.0000 (70.0283)  Acc@5: 100.0000 (97.0872)  time: 0.3481  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [1290/3750]  eta: 0:14:23  Lr: 0.001875  Loss: -0.7747  Acc@1: 75.0000 (70.0910)  Acc@5: 100.0000 (97.1098)  time: 0.3460  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [1300/3750]  eta: 0:14:19  Lr: 0.001875  Loss: -0.8542  Acc@1: 75.0000 (70.1336)  Acc@5: 100.0000 (97.1320)  time: 0.3467  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [1310/3750]  eta: 0:14:16  Lr: 0.001875  Loss: -0.7398  Acc@1: 75.0000 (70.1611)  Acc@5: 100.0000 (97.1444)  time: 0.3477  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [1320/3750]  eta: 0:14:12  Lr: 0.001875  Loss: -0.3000  Acc@1: 68.7500 (70.1788)  Acc@5: 100.0000 (97.1470)  time: 0.3489  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [1330/3750]  eta: 0:14:09  Lr: 0.001875  Loss: -0.4120  Acc@1: 68.7500 (70.1822)  Acc@5: 93.7500 (97.1168)  time: 0.3510  data: 0.0007  max mem: 2503
Train: Epoch[1/5]  [1340/3750]  eta: 0:14:05  Lr: 0.001875  Loss: -0.5598  Acc@1: 68.7500 (70.2228)  Acc@5: 93.7500 (97.1243)  time: 0.3508  data: 0.0008  max mem: 2503
Train: Epoch[1/5]  [1350/3750]  eta: 0:14:02  Lr: 0.001875  Loss: -0.4262  Acc@1: 68.7500 (70.2304)  Acc@5: 100.0000 (97.1179)  time: 0.3552  data: 0.0006  max mem: 2503
Train: Epoch[1/5]  [1360/3750]  eta: 0:13:58  Lr: 0.001875  Loss: -0.5840  Acc@1: 68.7500 (70.2562)  Acc@5: 100.0000 (97.1391)  time: 0.3564  data: 0.0006  max mem: 2503
Train: Epoch[1/5]  [1370/3750]  eta: 0:13:55  Lr: 0.001875  Loss: -0.1104  Acc@1: 75.0000 (70.2681)  Acc@5: 100.0000 (97.1462)  time: 0.3512  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [1380/3750]  eta: 0:13:51  Lr: 0.001875  Loss: -0.1819  Acc@1: 68.7500 (70.2933)  Acc@5: 100.0000 (97.1579)  time: 0.3500  data: 0.0007  max mem: 2503
Train: Epoch[1/5]  [1390/3750]  eta: 0:13:48  Lr: 0.001875  Loss: -0.2294  Acc@1: 75.0000 (70.3091)  Acc@5: 100.0000 (97.1603)  time: 0.3520  data: 0.0009  max mem: 2503
Train: Epoch[1/5]  [1400/3750]  eta: 0:13:44  Lr: 0.001875  Loss: -0.2606  Acc@1: 68.7500 (70.2757)  Acc@5: 100.0000 (97.1672)  time: 0.3595  data: 0.0022  max mem: 2503
Train: Epoch[1/5]  [1410/3750]  eta: 0:13:41  Lr: 0.001875  Loss: 0.0762  Acc@1: 75.0000 (70.3313)  Acc@5: 100.0000 (97.1651)  time: 0.3615  data: 0.0019  max mem: 2503
Train: Epoch[1/5]  [1420/3750]  eta: 0:13:37  Lr: 0.001875  Loss: -0.8889  Acc@1: 75.0000 (70.3422)  Acc@5: 100.0000 (97.1763)  time: 0.3526  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [1430/3750]  eta: 0:13:34  Lr: 0.001875  Loss: -0.6502  Acc@1: 68.7500 (70.3573)  Acc@5: 100.0000 (97.1873)  time: 0.3478  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [1440/3750]  eta: 0:13:30  Lr: 0.001875  Loss: 0.4374  Acc@1: 62.5000 (70.3244)  Acc@5: 100.0000 (97.1938)  time: 0.3486  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [1450/3750]  eta: 0:13:27  Lr: 0.001875  Loss: -0.4577  Acc@1: 68.7500 (70.3437)  Acc@5: 100.0000 (97.2045)  time: 0.3492  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [1460/3750]  eta: 0:13:23  Lr: 0.001875  Loss: -0.4726  Acc@1: 75.0000 (70.3628)  Acc@5: 100.0000 (97.2023)  time: 0.3502  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [1470/3750]  eta: 0:13:20  Lr: 0.001875  Loss: -0.7901  Acc@1: 75.0000 (70.3730)  Acc@5: 100.0000 (97.2170)  time: 0.3493  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [1480/3750]  eta: 0:13:16  Lr: 0.001875  Loss: -0.1443  Acc@1: 75.0000 (70.4001)  Acc@5: 100.0000 (97.2063)  time: 0.3487  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [1490/3750]  eta: 0:13:13  Lr: 0.001875  Loss: -0.2292  Acc@1: 75.0000 (70.4225)  Acc@5: 100.0000 (97.2250)  time: 0.3508  data: 0.0006  max mem: 2503
Train: Epoch[1/5]  [1500/3750]  eta: 0:13:09  Lr: 0.001875  Loss: -0.6744  Acc@1: 75.0000 (70.4655)  Acc@5: 100.0000 (97.2435)  time: 0.3489  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [1510/3750]  eta: 0:13:06  Lr: 0.001875  Loss: -0.2814  Acc@1: 75.0000 (70.4914)  Acc@5: 100.0000 (97.2535)  time: 0.3467  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [1520/3750]  eta: 0:13:02  Lr: 0.001875  Loss: -0.6660  Acc@1: 75.0000 (70.5210)  Acc@5: 100.0000 (97.2633)  time: 0.3517  data: 0.0017  max mem: 2503
Train: Epoch[1/5]  [1530/3750]  eta: 0:12:59  Lr: 0.001875  Loss: -0.4225  Acc@1: 75.0000 (70.5707)  Acc@5: 100.0000 (97.2689)  time: 0.3529  data: 0.0018  max mem: 2503
Train: Epoch[1/5]  [1540/3750]  eta: 0:12:55  Lr: 0.001875  Loss: -0.4302  Acc@1: 81.2500 (70.6157)  Acc@5: 100.0000 (97.2623)  time: 0.3511  data: 0.0006  max mem: 2503
Train: Epoch[1/5]  [1550/3750]  eta: 0:12:52  Lr: 0.001875  Loss: -0.5743  Acc@1: 81.2500 (70.6721)  Acc@5: 100.0000 (97.2719)  time: 0.3514  data: 0.0006  max mem: 2503
Train: Epoch[1/5]  [1560/3750]  eta: 0:12:48  Lr: 0.001875  Loss: -0.4635  Acc@1: 75.0000 (70.7039)  Acc@5: 100.0000 (97.2814)  time: 0.3536  data: 0.0007  max mem: 2503
Train: Epoch[1/5]  [1570/3750]  eta: 0:12:45  Lr: 0.001875  Loss: -0.4722  Acc@1: 75.0000 (70.7392)  Acc@5: 100.0000 (97.2947)  time: 0.3535  data: 0.0007  max mem: 2503
Train: Epoch[1/5]  [1580/3750]  eta: 0:12:41  Lr: 0.001875  Loss: -0.5125  Acc@1: 81.2500 (70.7898)  Acc@5: 100.0000 (97.3039)  time: 0.3536  data: 0.0008  max mem: 2503
Train: Epoch[1/5]  [1590/3750]  eta: 0:12:38  Lr: 0.001875  Loss: -0.8215  Acc@1: 81.2500 (70.8281)  Acc@5: 100.0000 (97.3130)  time: 0.3528  data: 0.0006  max mem: 2503
Train: Epoch[1/5]  [1600/3750]  eta: 0:12:34  Lr: 0.001875  Loss: -0.7199  Acc@1: 75.0000 (70.8698)  Acc@5: 100.0000 (97.3220)  time: 0.3495  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [1610/3750]  eta: 0:12:31  Lr: 0.001875  Loss: -0.3392  Acc@1: 75.0000 (70.8915)  Acc@5: 100.0000 (97.3231)  time: 0.3488  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [1620/3750]  eta: 0:12:27  Lr: 0.001875  Loss: -0.1517  Acc@1: 75.0000 (70.9130)  Acc@5: 100.0000 (97.3203)  time: 0.3483  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [1630/3750]  eta: 0:12:23  Lr: 0.001875  Loss: -0.7186  Acc@1: 75.0000 (70.9419)  Acc@5: 100.0000 (97.3253)  time: 0.3487  data: 0.0006  max mem: 2503
Train: Epoch[1/5]  [1640/3750]  eta: 0:12:20  Lr: 0.001875  Loss: -0.1862  Acc@1: 81.2500 (70.9743)  Acc@5: 100.0000 (97.3378)  time: 0.3484  data: 0.0006  max mem: 2503
Train: Epoch[1/5]  [1650/3750]  eta: 0:12:16  Lr: 0.001875  Loss: -0.7500  Acc@1: 75.0000 (71.0176)  Acc@5: 100.0000 (97.3501)  time: 0.3481  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [1660/3750]  eta: 0:12:13  Lr: 0.001875  Loss: -0.3911  Acc@1: 75.0000 (71.0415)  Acc@5: 100.0000 (97.3548)  time: 0.3487  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [1670/3750]  eta: 0:12:09  Lr: 0.001875  Loss: -0.6812  Acc@1: 75.0000 (71.0577)  Acc@5: 100.0000 (97.3594)  time: 0.3491  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [1680/3750]  eta: 0:12:06  Lr: 0.001875  Loss: -0.5861  Acc@1: 68.7500 (71.0738)  Acc@5: 100.0000 (97.3751)  time: 0.3471  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [1690/3750]  eta: 0:12:02  Lr: 0.001875  Loss: -0.6682  Acc@1: 75.0000 (71.1044)  Acc@5: 100.0000 (97.3758)  time: 0.3469  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [1700/3750]  eta: 0:11:59  Lr: 0.001875  Loss: -0.7982  Acc@1: 81.2500 (71.1861)  Acc@5: 100.0000 (97.3839)  time: 0.3531  data: 0.0015  max mem: 2503
Train: Epoch[1/5]  [1710/3750]  eta: 0:11:55  Lr: 0.001875  Loss: -0.6840  Acc@1: 81.2500 (71.2084)  Acc@5: 100.0000 (97.3955)  time: 0.3549  data: 0.0016  max mem: 2503
Train: Epoch[1/5]  [1720/3750]  eta: 0:11:52  Lr: 0.001875  Loss: -0.1567  Acc@1: 75.0000 (71.2340)  Acc@5: 100.0000 (97.4070)  time: 0.3502  data: 0.0006  max mem: 2503
Train: Epoch[1/5]  [1730/3750]  eta: 0:11:48  Lr: 0.001875  Loss: -0.3492  Acc@1: 75.0000 (71.2594)  Acc@5: 100.0000 (97.4076)  time: 0.3487  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [1740/3750]  eta: 0:11:45  Lr: 0.001875  Loss: -0.4956  Acc@1: 75.0000 (71.2952)  Acc@5: 100.0000 (97.4153)  time: 0.3518  data: 0.0011  max mem: 2503
Train: Epoch[1/5]  [1750/3750]  eta: 0:11:41  Lr: 0.001875  Loss: -0.3888  Acc@1: 75.0000 (71.2950)  Acc@5: 100.0000 (97.4193)  time: 0.3540  data: 0.0029  max mem: 2503
Train: Epoch[1/5]  [1760/3750]  eta: 0:11:38  Lr: 0.001875  Loss: -0.1703  Acc@1: 75.0000 (71.3409)  Acc@5: 100.0000 (97.4233)  time: 0.3527  data: 0.0024  max mem: 2503
Train: Epoch[1/5]  [1770/3750]  eta: 0:11:34  Lr: 0.001875  Loss: -0.5965  Acc@1: 81.2500 (71.3650)  Acc@5: 100.0000 (97.4167)  time: 0.3494  data: 0.0006  max mem: 2503
Train: Epoch[1/5]  [1780/3750]  eta: 0:11:31  Lr: 0.001875  Loss: -0.6018  Acc@1: 75.0000 (71.3539)  Acc@5: 100.0000 (97.4172)  time: 0.3494  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [1790/3750]  eta: 0:11:27  Lr: 0.001875  Loss: -0.2944  Acc@1: 68.7500 (71.3358)  Acc@5: 100.0000 (97.4246)  time: 0.3616  data: 0.0017  max mem: 2503
Train: Epoch[1/5]  [1800/3750]  eta: 0:11:24  Lr: 0.001875  Loss: -0.3648  Acc@1: 68.7500 (71.3354)  Acc@5: 100.0000 (97.4320)  time: 0.3596  data: 0.0016  max mem: 2503
Train: Epoch[1/5]  [1810/3750]  eta: 0:11:20  Lr: 0.001875  Loss: -0.2675  Acc@1: 68.7500 (71.3349)  Acc@5: 100.0000 (97.4393)  time: 0.3473  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [1820/3750]  eta: 0:11:17  Lr: 0.001875  Loss: -0.5028  Acc@1: 75.0000 (71.3447)  Acc@5: 100.0000 (97.4499)  time: 0.3491  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [1830/3750]  eta: 0:11:13  Lr: 0.001875  Loss: -0.2990  Acc@1: 81.2500 (71.3749)  Acc@5: 100.0000 (97.4502)  time: 0.3532  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [1840/3750]  eta: 0:11:10  Lr: 0.001875  Loss: -0.7942  Acc@1: 81.2500 (71.4252)  Acc@5: 100.0000 (97.4572)  time: 0.3540  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [1850/3750]  eta: 0:11:06  Lr: 0.001875  Loss: -0.7465  Acc@1: 81.2500 (71.4411)  Acc@5: 100.0000 (97.4541)  time: 0.3492  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [1860/3750]  eta: 0:11:03  Lr: 0.001875  Loss: -0.6601  Acc@1: 81.2500 (71.4938)  Acc@5: 100.0000 (97.4644)  time: 0.3457  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [1870/3750]  eta: 0:10:59  Lr: 0.001875  Loss: -0.7455  Acc@1: 81.2500 (71.5126)  Acc@5: 100.0000 (97.4679)  time: 0.3476  data: 0.0016  max mem: 2503
Train: Epoch[1/5]  [1880/3750]  eta: 0:10:56  Lr: 0.001875  Loss: -0.3287  Acc@1: 75.0000 (71.5211)  Acc@5: 100.0000 (97.4681)  time: 0.3487  data: 0.0019  max mem: 2503
Train: Epoch[1/5]  [1890/3750]  eta: 0:10:52  Lr: 0.001875  Loss: -0.4847  Acc@1: 75.0000 (71.5428)  Acc@5: 100.0000 (97.4749)  time: 0.3481  data: 0.0009  max mem: 2503
Train: Epoch[1/5]  [1900/3750]  eta: 0:10:49  Lr: 0.001875  Loss: -0.7151  Acc@1: 75.0000 (71.5709)  Acc@5: 100.0000 (97.4849)  time: 0.3503  data: 0.0007  max mem: 2503
Train: Epoch[1/5]  [1910/3750]  eta: 0:10:45  Lr: 0.001875  Loss: -0.7910  Acc@1: 75.0000 (71.5692)  Acc@5: 100.0000 (97.4751)  time: 0.3573  data: 0.0008  max mem: 2503
Train: Epoch[1/5]  [1920/3750]  eta: 0:10:42  Lr: 0.001875  Loss: -0.4011  Acc@1: 75.0000 (71.6163)  Acc@5: 100.0000 (97.4818)  time: 0.3577  data: 0.0008  max mem: 2503
Train: Epoch[1/5]  [1930/3750]  eta: 0:10:38  Lr: 0.001875  Loss: -0.7150  Acc@1: 75.0000 (71.6533)  Acc@5: 100.0000 (97.4883)  time: 0.3507  data: 0.0006  max mem: 2503
Train: Epoch[1/5]  [1940/3750]  eta: 0:10:35  Lr: 0.001875  Loss: -0.4788  Acc@1: 75.0000 (71.6705)  Acc@5: 100.0000 (97.4916)  time: 0.3492  data: 0.0006  max mem: 2503
Train: Epoch[1/5]  [1950/3750]  eta: 0:10:31  Lr: 0.001875  Loss: -0.5139  Acc@1: 75.0000 (71.6684)  Acc@5: 100.0000 (97.4949)  time: 0.3489  data: 0.0006  max mem: 2503
Train: Epoch[1/5]  [1960/3750]  eta: 0:10:28  Lr: 0.001875  Loss: -0.8606  Acc@1: 75.0000 (71.6854)  Acc@5: 100.0000 (97.5013)  time: 0.3553  data: 0.0006  max mem: 2503
Train: Epoch[1/5]  [1970/3750]  eta: 0:10:24  Lr: 0.001875  Loss: -0.5409  Acc@1: 75.0000 (71.7085)  Acc@5: 100.0000 (97.4981)  time: 0.3564  data: 0.0012  max mem: 2503
Train: Epoch[1/5]  [1980/3750]  eta: 0:10:21  Lr: 0.001875  Loss: -0.6070  Acc@1: 75.0000 (71.7314)  Acc@5: 100.0000 (97.5013)  time: 0.3502  data: 0.0012  max mem: 2503
Train: Epoch[1/5]  [1990/3750]  eta: 0:10:17  Lr: 0.001875  Loss: -0.1810  Acc@1: 75.0000 (71.7353)  Acc@5: 100.0000 (97.5013)  time: 0.3491  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [2000/3750]  eta: 0:10:14  Lr: 0.001875  Loss: -0.7281  Acc@1: 75.0000 (71.7454)  Acc@5: 100.0000 (97.5044)  time: 0.3475  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [2010/3750]  eta: 0:10:10  Lr: 0.001875  Loss: -0.5618  Acc@1: 75.0000 (71.7864)  Acc@5: 100.0000 (97.5137)  time: 0.3514  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [2020/3750]  eta: 0:10:07  Lr: 0.001875  Loss: -0.5230  Acc@1: 75.0000 (71.8085)  Acc@5: 100.0000 (97.5229)  time: 0.3528  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [2030/3750]  eta: 0:10:03  Lr: 0.001875  Loss: -0.3697  Acc@1: 68.7500 (71.7996)  Acc@5: 100.0000 (97.5320)  time: 0.3485  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [2040/3750]  eta: 0:10:00  Lr: 0.001875  Loss: -0.4224  Acc@1: 68.7500 (71.7939)  Acc@5: 100.0000 (97.5318)  time: 0.3469  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [2050/3750]  eta: 0:09:56  Lr: 0.001875  Loss: -0.2119  Acc@1: 75.0000 (71.8095)  Acc@5: 100.0000 (97.5378)  time: 0.3471  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [2060/3750]  eta: 0:09:53  Lr: 0.001875  Loss: -0.2184  Acc@1: 75.0000 (71.7855)  Acc@5: 100.0000 (97.5255)  time: 0.3474  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [2070/3750]  eta: 0:09:49  Lr: 0.001875  Loss: -0.3596  Acc@1: 75.0000 (71.8192)  Acc@5: 100.0000 (97.5314)  time: 0.3461  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [2080/3750]  eta: 0:09:45  Lr: 0.001875  Loss: -0.4622  Acc@1: 81.2500 (71.8495)  Acc@5: 100.0000 (97.5372)  time: 0.3457  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [2090/3750]  eta: 0:09:42  Lr: 0.001875  Loss: -0.1676  Acc@1: 75.0000 (71.8855)  Acc@5: 100.0000 (97.5401)  time: 0.3487  data: 0.0012  max mem: 2503
Train: Epoch[1/5]  [2100/3750]  eta: 0:09:38  Lr: 0.001875  Loss: -0.8185  Acc@1: 81.2500 (71.9271)  Acc@5: 100.0000 (97.5399)  time: 0.3504  data: 0.0012  max mem: 2503
Train: Epoch[1/5]  [2110/3750]  eta: 0:09:35  Lr: 0.001875  Loss: -0.1967  Acc@1: 81.2500 (71.9653)  Acc@5: 100.0000 (97.5456)  time: 0.3495  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [2120/3750]  eta: 0:09:31  Lr: 0.001875  Loss: -0.4357  Acc@1: 75.0000 (71.9796)  Acc@5: 100.0000 (97.5483)  time: 0.3500  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [2130/3750]  eta: 0:09:28  Lr: 0.001875  Loss: -0.6083  Acc@1: 75.0000 (72.0055)  Acc@5: 100.0000 (97.5569)  time: 0.3611  data: 0.0008  max mem: 2503
Train: Epoch[1/5]  [2140/3750]  eta: 0:09:25  Lr: 0.001875  Loss: -0.0886  Acc@1: 75.0000 (71.9961)  Acc@5: 100.0000 (97.5596)  time: 0.3615  data: 0.0016  max mem: 2503
Train: Epoch[1/5]  [2150/3750]  eta: 0:09:21  Lr: 0.001875  Loss: -0.7061  Acc@1: 75.0000 (72.0363)  Acc@5: 100.0000 (97.5680)  time: 0.3530  data: 0.0012  max mem: 2503
Train: Epoch[1/5]  [2160/3750]  eta: 0:09:18  Lr: 0.001875  Loss: -0.6304  Acc@1: 81.2500 (72.0558)  Acc@5: 100.0000 (97.5706)  time: 0.3517  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [2170/3750]  eta: 0:09:14  Lr: 0.001875  Loss: -0.6636  Acc@1: 68.7500 (72.0520)  Acc@5: 100.0000 (97.5674)  time: 0.3520  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [2180/3750]  eta: 0:09:11  Lr: 0.001875  Loss: -0.4973  Acc@1: 68.7500 (72.0512)  Acc@5: 100.0000 (97.5785)  time: 0.3569  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [2190/3750]  eta: 0:09:07  Lr: 0.001875  Loss: -0.5276  Acc@1: 75.0000 (72.1018)  Acc@5: 100.0000 (97.5896)  time: 0.3537  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [2200/3750]  eta: 0:09:04  Lr: 0.001875  Loss: -0.9302  Acc@1: 81.2500 (72.1206)  Acc@5: 100.0000 (97.5948)  time: 0.3476  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [2210/3750]  eta: 0:09:00  Lr: 0.001875  Loss: -0.4259  Acc@1: 81.2500 (72.1506)  Acc@5: 100.0000 (97.5972)  time: 0.3483  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [2220/3750]  eta: 0:08:56  Lr: 0.001875  Loss: -0.6377  Acc@1: 75.0000 (72.1719)  Acc@5: 100.0000 (97.6081)  time: 0.3500  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [2230/3750]  eta: 0:08:53  Lr: 0.001875  Loss: -0.5021  Acc@1: 81.2500 (72.2154)  Acc@5: 100.0000 (97.6076)  time: 0.3516  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [2240/3750]  eta: 0:08:49  Lr: 0.001875  Loss: -0.5431  Acc@1: 81.2500 (72.2390)  Acc@5: 100.0000 (97.6071)  time: 0.3500  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [2250/3750]  eta: 0:08:46  Lr: 0.001875  Loss: -0.4127  Acc@1: 75.0000 (72.2373)  Acc@5: 100.0000 (97.6122)  time: 0.3468  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [2260/3750]  eta: 0:08:42  Lr: 0.001875  Loss: -0.3046  Acc@1: 75.0000 (72.2606)  Acc@5: 100.0000 (97.6144)  time: 0.3459  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [2270/3750]  eta: 0:08:39  Lr: 0.001875  Loss: -0.4359  Acc@1: 75.0000 (72.2782)  Acc@5: 100.0000 (97.6194)  time: 0.3462  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [2280/3750]  eta: 0:08:35  Lr: 0.001875  Loss: -0.4595  Acc@1: 75.0000 (72.2901)  Acc@5: 100.0000 (97.6162)  time: 0.3470  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [2290/3750]  eta: 0:08:32  Lr: 0.001875  Loss: -0.5524  Acc@1: 75.0000 (72.3019)  Acc@5: 100.0000 (97.6239)  time: 0.3514  data: 0.0014  max mem: 2503
Train: Epoch[1/5]  [2300/3750]  eta: 0:08:28  Lr: 0.001875  Loss: -0.6217  Acc@1: 75.0000 (72.3327)  Acc@5: 100.0000 (97.6287)  time: 0.3544  data: 0.0018  max mem: 2503
Train: Epoch[1/5]  [2310/3750]  eta: 0:08:25  Lr: 0.001875  Loss: -0.5121  Acc@1: 75.0000 (72.3334)  Acc@5: 100.0000 (97.6390)  time: 0.3515  data: 0.0008  max mem: 2503
Train: Epoch[1/5]  [2320/3750]  eta: 0:08:21  Lr: 0.001875  Loss: -0.4411  Acc@1: 75.0000 (72.3772)  Acc@5: 100.0000 (97.6465)  time: 0.3504  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [2330/3750]  eta: 0:08:18  Lr: 0.001875  Loss: -0.9103  Acc@1: 81.2500 (72.4045)  Acc@5: 100.0000 (97.6485)  time: 0.3510  data: 0.0007  max mem: 2503
Train: Epoch[1/5]  [2340/3750]  eta: 0:08:14  Lr: 0.001875  Loss: -0.5386  Acc@1: 81.2500 (72.4290)  Acc@5: 100.0000 (97.6452)  time: 0.3514  data: 0.0007  max mem: 2503
Train: Epoch[1/5]  [2350/3750]  eta: 0:08:11  Lr: 0.001875  Loss: -0.4292  Acc@1: 81.2500 (72.4373)  Acc@5: 100.0000 (97.6473)  time: 0.3510  data: 0.0006  max mem: 2503
Train: Epoch[1/5]  [2360/3750]  eta: 0:08:07  Lr: 0.001875  Loss: -0.3918  Acc@1: 75.0000 (72.4534)  Acc@5: 100.0000 (97.6467)  time: 0.3490  data: 0.0006  max mem: 2503
Train: Epoch[1/5]  [2370/3750]  eta: 0:08:04  Lr: 0.001875  Loss: -0.3257  Acc@1: 75.0000 (72.4642)  Acc@5: 100.0000 (97.6487)  time: 0.3488  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [2380/3750]  eta: 0:08:00  Lr: 0.001875  Loss: -0.5450  Acc@1: 75.0000 (72.4879)  Acc@5: 100.0000 (97.6480)  time: 0.3494  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [2390/3750]  eta: 0:07:57  Lr: 0.001875  Loss: -0.8017  Acc@1: 75.0000 (72.5010)  Acc@5: 100.0000 (97.6448)  time: 0.3492  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [2400/3750]  eta: 0:07:53  Lr: 0.001875  Loss: -0.4350  Acc@1: 75.0000 (72.4958)  Acc@5: 100.0000 (97.6494)  time: 0.3522  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [2410/3750]  eta: 0:07:50  Lr: 0.001875  Loss: -0.6045  Acc@1: 75.0000 (72.5166)  Acc@5: 100.0000 (97.6514)  time: 0.3519  data: 0.0012  max mem: 2503
Train: Epoch[1/5]  [2420/3750]  eta: 0:07:46  Lr: 0.001875  Loss: -0.5197  Acc@1: 81.2500 (72.5320)  Acc@5: 100.0000 (97.6559)  time: 0.3483  data: 0.0011  max mem: 2503
Train: Epoch[1/5]  [2430/3750]  eta: 0:07:43  Lr: 0.001875  Loss: -0.4490  Acc@1: 75.0000 (72.5602)  Acc@5: 100.0000 (97.6553)  time: 0.3479  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [2440/3750]  eta: 0:07:39  Lr: 0.001875  Loss: -0.5099  Acc@1: 75.0000 (72.5753)  Acc@5: 100.0000 (97.6598)  time: 0.3486  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [2450/3750]  eta: 0:07:36  Lr: 0.001875  Loss: -0.8848  Acc@1: 81.2500 (72.6081)  Acc@5: 100.0000 (97.6617)  time: 0.3480  data: 0.0010  max mem: 2503
Train: Epoch[1/5]  [2460/3750]  eta: 0:07:32  Lr: 0.001875  Loss: -0.7986  Acc@1: 81.2500 (72.6153)  Acc@5: 100.0000 (97.6610)  time: 0.3458  data: 0.0010  max mem: 2503
Train: Epoch[1/5]  [2470/3750]  eta: 0:07:29  Lr: 0.001875  Loss: -0.8440  Acc@1: 81.2500 (72.6452)  Acc@5: 100.0000 (97.6629)  time: 0.3468  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [2480/3750]  eta: 0:07:25  Lr: 0.001875  Loss: -0.6917  Acc@1: 81.2500 (72.6698)  Acc@5: 100.0000 (97.6723)  time: 0.3535  data: 0.0009  max mem: 2503
Train: Epoch[1/5]  [2490/3750]  eta: 0:07:22  Lr: 0.001875  Loss: 0.0687  Acc@1: 75.0000 (72.6591)  Acc@5: 100.0000 (97.6817)  time: 0.3543  data: 0.0009  max mem: 2503
Train: Epoch[1/5]  [2500/3750]  eta: 0:07:18  Lr: 0.001875  Loss: -0.3218  Acc@1: 68.7500 (72.6484)  Acc@5: 100.0000 (97.6809)  time: 0.3505  data: 0.0006  max mem: 2503
Train: Epoch[1/5]  [2510/3750]  eta: 0:07:15  Lr: 0.001875  Loss: -0.5746  Acc@1: 75.0000 (72.6628)  Acc@5: 100.0000 (97.6877)  time: 0.3499  data: 0.0007  max mem: 2503
Train: Epoch[1/5]  [2520/3750]  eta: 0:07:11  Lr: 0.001875  Loss: -0.7061  Acc@1: 81.2500 (72.6894)  Acc@5: 100.0000 (97.6894)  time: 0.3520  data: 0.0011  max mem: 2503
Train: Epoch[1/5]  [2530/3750]  eta: 0:07:08  Lr: 0.001875  Loss: -0.7884  Acc@1: 81.2500 (72.7134)  Acc@5: 100.0000 (97.6911)  time: 0.3581  data: 0.0018  max mem: 2503
Train: Epoch[1/5]  [2540/3750]  eta: 0:07:04  Lr: 0.001875  Loss: -0.1363  Acc@1: 81.2500 (72.7396)  Acc@5: 100.0000 (97.6978)  time: 0.3545  data: 0.0013  max mem: 2503
Train: Epoch[1/5]  [2550/3750]  eta: 0:07:01  Lr: 0.001875  Loss: -0.3260  Acc@1: 75.0000 (72.7509)  Acc@5: 100.0000 (97.6970)  time: 0.3493  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [2560/3750]  eta: 0:06:57  Lr: 0.001875  Loss: -0.6986  Acc@1: 75.0000 (72.7767)  Acc@5: 100.0000 (97.7035)  time: 0.3515  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [2570/3750]  eta: 0:06:54  Lr: 0.001875  Loss: -0.4456  Acc@1: 81.2500 (72.8024)  Acc@5: 100.0000 (97.7076)  time: 0.3531  data: 0.0006  max mem: 2503
Train: Epoch[1/5]  [2580/3750]  eta: 0:06:50  Lr: 0.001875  Loss: -0.5119  Acc@1: 75.0000 (72.7964)  Acc@5: 100.0000 (97.7092)  time: 0.3509  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [2590/3750]  eta: 0:06:47  Lr: 0.001875  Loss: -0.7660  Acc@1: 68.7500 (72.8121)  Acc@5: 100.0000 (97.7108)  time: 0.3504  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [2600/3750]  eta: 0:06:43  Lr: 0.001875  Loss: -0.5810  Acc@1: 75.0000 (72.8157)  Acc@5: 100.0000 (97.7148)  time: 0.3503  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [2610/3750]  eta: 0:06:39  Lr: 0.001875  Loss: -0.3248  Acc@1: 75.0000 (72.8313)  Acc@5: 100.0000 (97.7188)  time: 0.3486  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [2620/3750]  eta: 0:06:36  Lr: 0.001875  Loss: -0.2608  Acc@1: 75.0000 (72.8372)  Acc@5: 100.0000 (97.7251)  time: 0.3491  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [2630/3750]  eta: 0:06:32  Lr: 0.001875  Loss: -0.4702  Acc@1: 75.0000 (72.8406)  Acc@5: 100.0000 (97.7290)  time: 0.3466  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [2640/3750]  eta: 0:06:29  Lr: 0.001875  Loss: -0.5609  Acc@1: 75.0000 (72.8536)  Acc@5: 100.0000 (97.7258)  time: 0.3451  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [2650/3750]  eta: 0:06:25  Lr: 0.001875  Loss: -0.8717  Acc@1: 81.2500 (72.9017)  Acc@5: 100.0000 (97.7320)  time: 0.3469  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [2660/3750]  eta: 0:06:22  Lr: 0.001875  Loss: -0.6493  Acc@1: 75.0000 (72.8814)  Acc@5: 100.0000 (97.7382)  time: 0.3470  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [2670/3750]  eta: 0:06:18  Lr: 0.001875  Loss: -0.6685  Acc@1: 68.7500 (72.8894)  Acc@5: 100.0000 (97.7420)  time: 0.3491  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [2680/3750]  eta: 0:06:15  Lr: 0.001875  Loss: -0.4221  Acc@1: 75.0000 (72.8879)  Acc@5: 100.0000 (97.7457)  time: 0.3516  data: 0.0008  max mem: 2503
Train: Epoch[1/5]  [2690/3750]  eta: 0:06:11  Lr: 0.001875  Loss: -0.4082  Acc@1: 75.0000 (72.8934)  Acc@5: 100.0000 (97.7518)  time: 0.3519  data: 0.0006  max mem: 2503
Train: Epoch[1/5]  [2700/3750]  eta: 0:06:08  Lr: 0.001875  Loss: -0.3584  Acc@1: 75.0000 (72.9082)  Acc@5: 100.0000 (97.7531)  time: 0.3530  data: 0.0006  max mem: 2503
Train: Epoch[1/5]  [2710/3750]  eta: 0:06:04  Lr: 0.001875  Loss: -0.0113  Acc@1: 81.2500 (72.9182)  Acc@5: 100.0000 (97.7522)  time: 0.3517  data: 0.0006  max mem: 2503
Train: Epoch[1/5]  [2720/3750]  eta: 0:06:01  Lr: 0.001875  Loss: -0.6790  Acc@1: 68.7500 (72.8960)  Acc@5: 100.0000 (97.7559)  time: 0.3506  data: 0.0006  max mem: 2503
Train: Epoch[1/5]  [2730/3750]  eta: 0:05:57  Lr: 0.001875  Loss: -0.6949  Acc@1: 68.7500 (72.9106)  Acc@5: 100.0000 (97.7549)  time: 0.3493  data: 0.0006  max mem: 2503
Train: Epoch[1/5]  [2740/3750]  eta: 0:05:54  Lr: 0.001875  Loss: -0.1016  Acc@1: 75.0000 (72.9341)  Acc@5: 100.0000 (97.7609)  time: 0.3536  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [2750/3750]  eta: 0:05:50  Lr: 0.001875  Loss: -0.7952  Acc@1: 81.2500 (72.9507)  Acc@5: 100.0000 (97.7554)  time: 0.3568  data: 0.0012  max mem: 2503
Train: Epoch[1/5]  [2760/3750]  eta: 0:05:47  Lr: 0.001875  Loss: -0.5417  Acc@1: 81.2500 (72.9672)  Acc@5: 100.0000 (97.7590)  time: 0.3508  data: 0.0012  max mem: 2503
Train: Epoch[1/5]  [2770/3750]  eta: 0:05:43  Lr: 0.001875  Loss: -0.6174  Acc@1: 75.0000 (72.9700)  Acc@5: 100.0000 (97.7558)  time: 0.3483  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [2780/3750]  eta: 0:05:40  Lr: 0.001875  Loss: -0.6614  Acc@1: 75.0000 (72.9639)  Acc@5: 100.0000 (97.7593)  time: 0.3486  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [2790/3750]  eta: 0:05:36  Lr: 0.001875  Loss: -0.0174  Acc@1: 75.0000 (72.9779)  Acc@5: 100.0000 (97.7607)  time: 0.3497  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [2800/3750]  eta: 0:05:33  Lr: 0.001875  Loss: -0.8566  Acc@1: 81.2500 (73.0163)  Acc@5: 100.0000 (97.7687)  time: 0.3493  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [2810/3750]  eta: 0:05:29  Lr: 0.001875  Loss: -0.5209  Acc@1: 81.2500 (73.0412)  Acc@5: 100.0000 (97.7721)  time: 0.3463  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [2820/3750]  eta: 0:05:26  Lr: 0.001875  Loss: -0.3119  Acc@1: 75.0000 (73.0548)  Acc@5: 100.0000 (97.7800)  time: 0.3459  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [2830/3750]  eta: 0:05:22  Lr: 0.001875  Loss: -0.8104  Acc@1: 81.2500 (73.0727)  Acc@5: 100.0000 (97.7879)  time: 0.3473  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [2840/3750]  eta: 0:05:19  Lr: 0.001875  Loss: -0.8841  Acc@1: 81.2500 (73.1081)  Acc@5: 100.0000 (97.7935)  time: 0.3465  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [2850/3750]  eta: 0:05:15  Lr: 0.001875  Loss: -0.9685  Acc@1: 81.2500 (73.1257)  Acc@5: 100.0000 (97.7990)  time: 0.3462  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [2860/3750]  eta: 0:05:12  Lr: 0.001875  Loss: -0.8170  Acc@1: 75.0000 (73.1409)  Acc@5: 100.0000 (97.7980)  time: 0.3498  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [2870/3750]  eta: 0:05:08  Lr: 0.001875  Loss: -0.5186  Acc@1: 75.0000 (73.1627)  Acc@5: 100.0000 (97.7969)  time: 0.3536  data: 0.0006  max mem: 2503
Train: Epoch[1/5]  [2880/3750]  eta: 0:05:05  Lr: 0.001875  Loss: -0.6575  Acc@1: 75.0000 (73.1604)  Acc@5: 100.0000 (97.7959)  time: 0.3534  data: 0.0006  max mem: 2503
Train: Epoch[1/5]  [2890/3750]  eta: 0:05:01  Lr: 0.001875  Loss: -0.9164  Acc@1: 75.0000 (73.1689)  Acc@5: 100.0000 (97.7970)  time: 0.3511  data: 0.0006  max mem: 2503
Train: Epoch[1/5]  [2900/3750]  eta: 0:04:58  Lr: 0.001875  Loss: -0.4134  Acc@1: 68.7500 (73.1666)  Acc@5: 100.0000 (97.8003)  time: 0.3513  data: 0.0006  max mem: 2503
Train: Epoch[1/5]  [2910/3750]  eta: 0:04:54  Lr: 0.001875  Loss: -1.0479  Acc@1: 75.0000 (73.1707)  Acc@5: 100.0000 (97.7971)  time: 0.3546  data: 0.0006  max mem: 2503
Train: Epoch[1/5]  [2920/3750]  eta: 0:04:51  Lr: 0.001875  Loss: -0.3352  Acc@1: 75.0000 (73.1877)  Acc@5: 100.0000 (97.8004)  time: 0.3541  data: 0.0008  max mem: 2503
Train: Epoch[1/5]  [2930/3750]  eta: 0:04:47  Lr: 0.001875  Loss: -0.8380  Acc@1: 75.0000 (73.1939)  Acc@5: 100.0000 (97.7973)  time: 0.3511  data: 0.0008  max mem: 2503
Train: Epoch[1/5]  [2940/3750]  eta: 0:04:44  Lr: 0.001875  Loss: -0.5142  Acc@1: 75.0000 (73.2170)  Acc@5: 100.0000 (97.7984)  time: 0.3496  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [2950/3750]  eta: 0:04:40  Lr: 0.001875  Loss: -0.5475  Acc@1: 75.0000 (73.2104)  Acc@5: 100.0000 (97.7995)  time: 0.3481  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [2960/3750]  eta: 0:04:37  Lr: 0.001875  Loss: -0.7716  Acc@1: 68.7500 (73.1995)  Acc@5: 100.0000 (97.8006)  time: 0.3502  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [2970/3750]  eta: 0:04:33  Lr: 0.001875  Loss: -0.1758  Acc@1: 75.0000 (73.2161)  Acc@5: 100.0000 (97.8059)  time: 0.3496  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [2980/3750]  eta: 0:04:30  Lr: 0.001875  Loss: -0.6620  Acc@1: 81.2500 (73.2263)  Acc@5: 100.0000 (97.8111)  time: 0.3477  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [2990/3750]  eta: 0:04:26  Lr: 0.001875  Loss: -0.4835  Acc@1: 75.0000 (73.2301)  Acc@5: 100.0000 (97.8080)  time: 0.3471  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [3000/3750]  eta: 0:04:23  Lr: 0.001875  Loss: -0.5326  Acc@1: 75.0000 (73.2506)  Acc@5: 100.0000 (97.8132)  time: 0.3485  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [3010/3750]  eta: 0:04:19  Lr: 0.001875  Loss: -0.6301  Acc@1: 81.2500 (73.2668)  Acc@5: 100.0000 (97.8163)  time: 0.3485  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [3020/3750]  eta: 0:04:16  Lr: 0.001875  Loss: -0.6367  Acc@1: 75.0000 (73.2684)  Acc@5: 100.0000 (97.8174)  time: 0.3460  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [3030/3750]  eta: 0:04:12  Lr: 0.001875  Loss: -0.4026  Acc@1: 75.0000 (73.2782)  Acc@5: 100.0000 (97.8204)  time: 0.3496  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [3040/3750]  eta: 0:04:09  Lr: 0.001875  Loss: -0.4263  Acc@1: 75.0000 (73.2900)  Acc@5: 100.0000 (97.8256)  time: 0.3535  data: 0.0013  max mem: 2503
Train: Epoch[1/5]  [3050/3750]  eta: 0:04:05  Lr: 0.001875  Loss: 0.4539  Acc@1: 75.0000 (73.3120)  Acc@5: 100.0000 (97.8183)  time: 0.3519  data: 0.0013  max mem: 2503
Train: Epoch[1/5]  [3060/3750]  eta: 0:04:01  Lr: 0.001875  Loss: -0.6672  Acc@1: 75.0000 (73.3278)  Acc@5: 100.0000 (97.8255)  time: 0.3505  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [3070/3750]  eta: 0:03:58  Lr: 0.001875  Loss: -0.6781  Acc@1: 75.0000 (73.3352)  Acc@5: 100.0000 (97.8224)  time: 0.3499  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [3080/3750]  eta: 0:03:54  Lr: 0.001875  Loss: -0.6585  Acc@1: 75.0000 (73.3467)  Acc@5: 100.0000 (97.8254)  time: 0.3550  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [3090/3750]  eta: 0:03:51  Lr: 0.001875  Loss: -0.3865  Acc@1: 75.0000 (73.3541)  Acc@5: 100.0000 (97.8284)  time: 0.3571  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [3100/3750]  eta: 0:03:47  Lr: 0.001875  Loss: -0.4217  Acc@1: 75.0000 (73.3634)  Acc@5: 100.0000 (97.8334)  time: 0.3517  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [3110/3750]  eta: 0:03:44  Lr: 0.001875  Loss: -0.6434  Acc@1: 75.0000 (73.3767)  Acc@5: 100.0000 (97.8283)  time: 0.3484  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [3120/3750]  eta: 0:03:40  Lr: 0.001875  Loss: -0.6391  Acc@1: 75.0000 (73.3919)  Acc@5: 100.0000 (97.8272)  time: 0.3480  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [3130/3750]  eta: 0:03:37  Lr: 0.001875  Loss: -0.5002  Acc@1: 75.0000 (73.3951)  Acc@5: 100.0000 (97.8262)  time: 0.3504  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [3140/3750]  eta: 0:03:33  Lr: 0.001875  Loss: -0.7884  Acc@1: 75.0000 (73.3922)  Acc@5: 100.0000 (97.8291)  time: 0.3498  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [3150/3750]  eta: 0:03:30  Lr: 0.001875  Loss: -0.4121  Acc@1: 68.7500 (73.3973)  Acc@5: 100.0000 (97.8340)  time: 0.3479  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [3160/3750]  eta: 0:03:26  Lr: 0.001875  Loss: -0.7329  Acc@1: 75.0000 (73.4044)  Acc@5: 100.0000 (97.8369)  time: 0.3479  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [3170/3750]  eta: 0:03:23  Lr: 0.001875  Loss: -0.8570  Acc@1: 75.0000 (73.4291)  Acc@5: 100.0000 (97.8418)  time: 0.3489  data: 0.0006  max mem: 2503
Train: Epoch[1/5]  [3180/3750]  eta: 0:03:19  Lr: 0.001875  Loss: -0.3493  Acc@1: 81.2500 (73.4537)  Acc@5: 100.0000 (97.8466)  time: 0.3493  data: 0.0010  max mem: 2503
Train: Epoch[1/5]  [3190/3750]  eta: 0:03:16  Lr: 0.001875  Loss: -0.3107  Acc@1: 81.2500 (73.4821)  Acc@5: 100.0000 (97.8475)  time: 0.3480  data: 0.0006  max mem: 2503
Train: Epoch[1/5]  [3200/3750]  eta: 0:03:12  Lr: 0.001875  Loss: -0.4570  Acc@1: 81.2500 (73.4946)  Acc@5: 100.0000 (97.8444)  time: 0.3470  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [3210/3750]  eta: 0:03:09  Lr: 0.001875  Loss: -0.7201  Acc@1: 75.0000 (73.5090)  Acc@5: 100.0000 (97.8414)  time: 0.3512  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [3220/3750]  eta: 0:03:05  Lr: 0.001875  Loss: -0.0892  Acc@1: 75.0000 (73.5175)  Acc@5: 100.0000 (97.8442)  time: 0.3545  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [3230/3750]  eta: 0:03:02  Lr: 0.001875  Loss: -0.8956  Acc@1: 81.2500 (73.5376)  Acc@5: 100.0000 (97.8470)  time: 0.3515  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [3240/3750]  eta: 0:02:58  Lr: 0.001875  Loss: -0.4430  Acc@1: 81.2500 (73.5421)  Acc@5: 100.0000 (97.8517)  time: 0.3500  data: 0.0006  max mem: 2503
Train: Epoch[1/5]  [3250/3750]  eta: 0:02:55  Lr: 0.001875  Loss: -0.6205  Acc@1: 81.2500 (73.5697)  Acc@5: 100.0000 (97.8564)  time: 0.3528  data: 0.0006  max mem: 2503
Train: Epoch[1/5]  [3260/3750]  eta: 0:02:51  Lr: 0.001875  Loss: -0.3819  Acc@1: 81.2500 (73.5836)  Acc@5: 100.0000 (97.8573)  time: 0.3569  data: 0.0010  max mem: 2503
Train: Epoch[1/5]  [3270/3750]  eta: 0:02:48  Lr: 0.001875  Loss: -0.4267  Acc@1: 75.0000 (73.5918)  Acc@5: 100.0000 (97.8581)  time: 0.3542  data: 0.0009  max mem: 2503
Train: Epoch[1/5]  [3280/3750]  eta: 0:02:44  Lr: 0.001875  Loss: -0.6710  Acc@1: 75.0000 (73.5961)  Acc@5: 100.0000 (97.8570)  time: 0.3507  data: 0.0006  max mem: 2503
Train: Epoch[1/5]  [3290/3750]  eta: 0:02:41  Lr: 0.001875  Loss: -0.4188  Acc@1: 75.0000 (73.6022)  Acc@5: 100.0000 (97.8616)  time: 0.3516  data: 0.0006  max mem: 2503
Train: Epoch[1/5]  [3300/3750]  eta: 0:02:37  Lr: 0.001875  Loss: -0.7562  Acc@1: 75.0000 (73.6046)  Acc@5: 100.0000 (97.8662)  time: 0.3513  data: 0.0006  max mem: 2503
Train: Epoch[1/5]  [3310/3750]  eta: 0:02:34  Lr: 0.001875  Loss: -0.3827  Acc@1: 75.0000 (73.6201)  Acc@5: 100.0000 (97.8651)  time: 0.3513  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [3320/3750]  eta: 0:02:30  Lr: 0.001875  Loss: -0.1394  Acc@1: 75.0000 (73.6280)  Acc@5: 100.0000 (97.8640)  time: 0.3493  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [3330/3750]  eta: 0:02:27  Lr: 0.001875  Loss: -0.6055  Acc@1: 75.0000 (73.6265)  Acc@5: 100.0000 (97.8629)  time: 0.3470  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [3340/3750]  eta: 0:02:23  Lr: 0.001875  Loss: -0.4394  Acc@1: 75.0000 (73.6344)  Acc@5: 100.0000 (97.8655)  time: 0.3473  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [3350/3750]  eta: 0:02:20  Lr: 0.001875  Loss: -0.6254  Acc@1: 75.0000 (73.6534)  Acc@5: 100.0000 (97.8663)  time: 0.3498  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [3360/3750]  eta: 0:02:16  Lr: 0.001875  Loss: -0.7405  Acc@1: 75.0000 (73.6555)  Acc@5: 100.0000 (97.8708)  time: 0.3484  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [3370/3750]  eta: 0:02:13  Lr: 0.001875  Loss: -0.7265  Acc@1: 75.0000 (73.6836)  Acc@5: 100.0000 (97.8734)  time: 0.3452  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [3380/3750]  eta: 0:02:09  Lr: 0.001875  Loss: -0.4895  Acc@1: 81.2500 (73.6968)  Acc@5: 100.0000 (97.8797)  time: 0.3475  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [3390/3750]  eta: 0:02:06  Lr: 0.001875  Loss: -0.6417  Acc@1: 75.0000 (73.7153)  Acc@5: 100.0000 (97.8841)  time: 0.3498  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [3400/3750]  eta: 0:02:02  Lr: 0.001875  Loss: -0.6078  Acc@1: 75.0000 (73.7136)  Acc@5: 100.0000 (97.8885)  time: 0.3483  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [3410/3750]  eta: 0:01:59  Lr: 0.001875  Loss: -0.5415  Acc@1: 75.0000 (73.7247)  Acc@5: 100.0000 (97.8855)  time: 0.3484  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [3420/3750]  eta: 0:01:55  Lr: 0.001875  Loss: -0.5849  Acc@1: 81.2500 (73.7339)  Acc@5: 100.0000 (97.8862)  time: 0.3494  data: 0.0006  max mem: 2503
Train: Epoch[1/5]  [3430/3750]  eta: 0:01:52  Lr: 0.001875  Loss: -0.6156  Acc@1: 75.0000 (73.7431)  Acc@5: 100.0000 (97.8924)  time: 0.3515  data: 0.0014  max mem: 2503
Train: Epoch[1/5]  [3440/3750]  eta: 0:01:48  Lr: 0.001875  Loss: -0.5455  Acc@1: 75.0000 (73.7558)  Acc@5: 100.0000 (97.8949)  time: 0.3526  data: 0.0014  max mem: 2503
Train: Epoch[1/5]  [3450/3750]  eta: 0:01:45  Lr: 0.001875  Loss: -0.7453  Acc@1: 81.2500 (73.7667)  Acc@5: 100.0000 (97.8973)  time: 0.3515  data: 0.0006  max mem: 2503
Train: Epoch[1/5]  [3460/3750]  eta: 0:01:41  Lr: 0.001875  Loss: -0.5602  Acc@1: 75.0000 (73.7720)  Acc@5: 100.0000 (97.8980)  time: 0.3513  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [3470/3750]  eta: 0:01:38  Lr: 0.001875  Loss: -0.1927  Acc@1: 75.0000 (73.7720)  Acc@5: 100.0000 (97.9005)  time: 0.3530  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [3480/3750]  eta: 0:01:34  Lr: 0.001875  Loss: -0.7176  Acc@1: 81.2500 (73.7881)  Acc@5: 100.0000 (97.8993)  time: 0.3561  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [3490/3750]  eta: 0:01:31  Lr: 0.001875  Loss: -0.5362  Acc@1: 81.2500 (73.8023)  Acc@5: 100.0000 (97.9017)  time: 0.3518  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [3500/3750]  eta: 0:01:27  Lr: 0.001875  Loss: -0.3919  Acc@1: 75.0000 (73.8039)  Acc@5: 100.0000 (97.9042)  time: 0.3474  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [3510/3750]  eta: 0:01:24  Lr: 0.001875  Loss: -0.4178  Acc@1: 75.0000 (73.8127)  Acc@5: 100.0000 (97.9030)  time: 0.3486  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [3520/3750]  eta: 0:01:20  Lr: 0.001875  Loss: -0.6486  Acc@1: 81.2500 (73.8231)  Acc@5: 100.0000 (97.9072)  time: 0.3490  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [3530/3750]  eta: 0:01:17  Lr: 0.001875  Loss: -0.8036  Acc@1: 75.0000 (73.8353)  Acc@5: 100.0000 (97.9114)  time: 0.3483  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [3540/3750]  eta: 0:01:13  Lr: 0.001875  Loss: -0.9185  Acc@1: 75.0000 (73.8563)  Acc@5: 100.0000 (97.9155)  time: 0.3471  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [3550/3750]  eta: 0:01:10  Lr: 0.001875  Loss: -0.7626  Acc@1: 81.2500 (73.8771)  Acc@5: 100.0000 (97.9161)  time: 0.3457  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [3560/3750]  eta: 0:01:06  Lr: 0.001875  Loss: -0.6287  Acc@1: 81.2500 (73.8943)  Acc@5: 100.0000 (97.9184)  time: 0.3465  data: 0.0008  max mem: 2503
Train: Epoch[1/5]  [3570/3750]  eta: 0:01:03  Lr: 0.001875  Loss: -0.4951  Acc@1: 81.2500 (73.9061)  Acc@5: 100.0000 (97.9173)  time: 0.3485  data: 0.0008  max mem: 2503
Train: Epoch[1/5]  [3580/3750]  eta: 0:00:59  Lr: 0.001875  Loss: -0.2204  Acc@1: 81.2500 (73.9039)  Acc@5: 100.0000 (97.9231)  time: 0.3494  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [3590/3750]  eta: 0:00:56  Lr: 0.001875  Loss: -0.7708  Acc@1: 81.2500 (73.9209)  Acc@5: 100.0000 (97.9254)  time: 0.3511  data: 0.0006  max mem: 2503
Train: Epoch[1/5]  [3600/3750]  eta: 0:00:52  Lr: 0.001875  Loss: -0.9432  Acc@1: 81.2500 (73.9361)  Acc@5: 100.0000 (97.9277)  time: 0.3510  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [3610/3750]  eta: 0:00:49  Lr: 0.001875  Loss: -0.8314  Acc@1: 81.2500 (73.9563)  Acc@5: 100.0000 (97.9299)  time: 0.3509  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [3620/3750]  eta: 0:00:45  Lr: 0.001875  Loss: -0.4006  Acc@1: 81.2500 (73.9661)  Acc@5: 100.0000 (97.9322)  time: 0.3528  data: 0.0006  max mem: 2503
Train: Epoch[1/5]  [3630/3750]  eta: 0:00:42  Lr: 0.001875  Loss: -0.6513  Acc@1: 81.2500 (73.9948)  Acc@5: 100.0000 (97.9327)  time: 0.3534  data: 0.0012  max mem: 2503
Train: Epoch[1/5]  [3640/3750]  eta: 0:00:38  Lr: 0.001875  Loss: -0.1374  Acc@1: 81.2500 (73.9992)  Acc@5: 100.0000 (97.9367)  time: 0.3529  data: 0.0011  max mem: 2503
Train: Epoch[1/5]  [3650/3750]  eta: 0:00:35  Lr: 0.001875  Loss: -0.3973  Acc@1: 81.2500 (74.0242)  Acc@5: 100.0000 (97.9389)  time: 0.3563  data: 0.0007  max mem: 2503
Train: Epoch[1/5]  [3660/3750]  eta: 0:00:31  Lr: 0.001875  Loss: -0.3968  Acc@1: 81.2500 (74.0235)  Acc@5: 100.0000 (97.9428)  time: 0.3569  data: 0.0011  max mem: 2503
Train: Epoch[1/5]  [3670/3750]  eta: 0:00:28  Lr: 0.001875  Loss: -0.3220  Acc@1: 75.0000 (74.0432)  Acc@5: 100.0000 (97.9433)  time: 0.3512  data: 0.0008  max mem: 2503
Train: Epoch[1/5]  [3680/3750]  eta: 0:00:24  Lr: 0.001875  Loss: -0.6289  Acc@1: 75.0000 (74.0441)  Acc@5: 100.0000 (97.9455)  time: 0.3483  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [3690/3750]  eta: 0:00:21  Lr: 0.001875  Loss: -0.1608  Acc@1: 75.0000 (74.0467)  Acc@5: 100.0000 (97.9460)  time: 0.3474  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [3700/3750]  eta: 0:00:17  Lr: 0.001875  Loss: -0.6638  Acc@1: 75.0000 (74.0560)  Acc@5: 100.0000 (97.9482)  time: 0.3496  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [3710/3750]  eta: 0:00:14  Lr: 0.001875  Loss: -0.1384  Acc@1: 75.0000 (74.0518)  Acc@5: 100.0000 (97.9520)  time: 0.3504  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [3720/3750]  eta: 0:00:10  Lr: 0.001875  Loss: -0.6790  Acc@1: 75.0000 (74.0611)  Acc@5: 100.0000 (97.9542)  time: 0.3483  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [3730/3750]  eta: 0:00:07  Lr: 0.001875  Loss: -0.3920  Acc@1: 81.2500 (74.0703)  Acc@5: 100.0000 (97.9530)  time: 0.3467  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [3740/3750]  eta: 0:00:03  Lr: 0.001875  Loss: -0.6371  Acc@1: 81.2500 (74.0845)  Acc@5: 100.0000 (97.9568)  time: 0.3481  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [3749/3750]  eta: 0:00:00  Lr: 0.001875  Loss: 0.5825  Acc@1: 81.2500 (74.0883)  Acc@5: 100.0000 (97.9583)  time: 0.3494  data: 0.0006  max mem: 2503
Train: Epoch[1/5] Total time: 0:21:55 (0.3508 s / it)
{0: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 1: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 2: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 3: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 4: {0: 0, 1: 300000, 2: 0, 3: 91325, 4: 0}, 5: {0: 0, 1: 300000, 2: 0, 3: 91325, 4: 0}, 6: {0: 0, 1: 300000, 2: 0, 3: 91325, 4: 0}, 7: {0: 0, 1: 300000, 2: 0, 3: 91325, 4: 0}, 8: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 9: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 10: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 11: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 12: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 13: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 14: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 15: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 16: {0: 0, 1: 0, 2: 0, 3: 0, 4: 60000}, 17: {0: 0, 1: 0, 2: 0, 3: 0, 4: 60000}, 18: {0: 0, 1: 0, 2: 0, 3: 0, 4: 60000}, 19: {0: 0, 1: 0, 2: 0, 3: 0, 4: 60000}}
Averaged stats: Lr: 0.001875  Loss: 0.5825  Acc@1: 81.2500 (74.0883)  Acc@5: 100.0000 (97.9583)
Train: Epoch[2/5]  [   0/3750]  eta: 0:42:07  Lr: 0.001875  Loss: -0.6611  Acc@1: 81.2500 (81.2500)  Acc@5: 100.0000 (100.0000)  time: 0.6740  data: 0.3251  max mem: 2503
Train: Epoch[2/5]  [  10/3750]  eta: 0:23:34  Lr: 0.001875  Loss: -0.5725  Acc@1: 75.0000 (76.1364)  Acc@5: 100.0000 (98.8636)  time: 0.3782  data: 0.0299  max mem: 2503
Train: Epoch[2/5]  [  20/3750]  eta: 0:22:43  Lr: 0.001875  Loss: -0.6209  Acc@1: 75.0000 (75.5952)  Acc@5: 100.0000 (98.8095)  time: 0.3501  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [  30/3750]  eta: 0:22:37  Lr: 0.001875  Loss: -0.7159  Acc@1: 75.0000 (77.8226)  Acc@5: 100.0000 (98.7903)  time: 0.3575  data: 0.0007  max mem: 2503
Train: Epoch[2/5]  [  40/3750]  eta: 0:22:21  Lr: 0.001875  Loss: -0.7041  Acc@1: 75.0000 (77.2866)  Acc@5: 100.0000 (98.6280)  time: 0.3576  data: 0.0007  max mem: 2503
Train: Epoch[2/5]  [  50/3750]  eta: 0:22:08  Lr: 0.001875  Loss: -0.5815  Acc@1: 75.0000 (76.4706)  Acc@5: 100.0000 (98.6520)  time: 0.3503  data: 0.0006  max mem: 2503
Train: Epoch[2/5]  [  60/3750]  eta: 0:22:00  Lr: 0.001875  Loss: -0.3947  Acc@1: 75.0000 (76.3320)  Acc@5: 100.0000 (98.5656)  time: 0.3502  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [  70/3750]  eta: 0:21:54  Lr: 0.001875  Loss: -0.8714  Acc@1: 75.0000 (76.4085)  Acc@5: 100.0000 (98.5915)  time: 0.3522  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [  80/3750]  eta: 0:21:51  Lr: 0.001875  Loss: -0.8485  Acc@1: 81.2500 (77.3920)  Acc@5: 100.0000 (98.6111)  time: 0.3558  data: 0.0008  max mem: 2503
Train: Epoch[2/5]  [  90/3750]  eta: 0:21:45  Lr: 0.001875  Loss: -0.9514  Acc@1: 81.2500 (77.1978)  Acc@5: 100.0000 (98.6951)  time: 0.3550  data: 0.0009  max mem: 2503
Train: Epoch[2/5]  [ 100/3750]  eta: 0:21:38  Lr: 0.001875  Loss: -0.9092  Acc@1: 75.0000 (77.0421)  Acc@5: 100.0000 (98.7624)  time: 0.3497  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [ 110/3750]  eta: 0:21:32  Lr: 0.001875  Loss: -0.3788  Acc@1: 75.0000 (77.4212)  Acc@5: 100.0000 (98.7050)  time: 0.3484  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [ 120/3750]  eta: 0:21:28  Lr: 0.001875  Loss: -0.5256  Acc@1: 81.2500 (77.5826)  Acc@5: 100.0000 (98.6570)  time: 0.3499  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [ 130/3750]  eta: 0:21:23  Lr: 0.001875  Loss: -0.5294  Acc@1: 81.2500 (77.6718)  Acc@5: 100.0000 (98.5687)  time: 0.3509  data: 0.0012  max mem: 2503
Train: Epoch[2/5]  [ 140/3750]  eta: 0:21:18  Lr: 0.001875  Loss: -0.4059  Acc@1: 81.2500 (78.0142)  Acc@5: 100.0000 (98.6702)  time: 0.3503  data: 0.0012  max mem: 2503
Train: Epoch[2/5]  [ 150/3750]  eta: 0:21:13  Lr: 0.001875  Loss: -0.6135  Acc@1: 75.0000 (77.7732)  Acc@5: 100.0000 (98.5927)  time: 0.3478  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [ 160/3750]  eta: 0:21:08  Lr: 0.001875  Loss: -0.7103  Acc@1: 75.0000 (77.8727)  Acc@5: 100.0000 (98.5637)  time: 0.3474  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [ 170/3750]  eta: 0:21:04  Lr: 0.001875  Loss: -0.3472  Acc@1: 75.0000 (77.8874)  Acc@5: 100.0000 (98.5746)  time: 0.3492  data: 0.0017  max mem: 2503
Train: Epoch[2/5]  [ 180/3750]  eta: 0:20:59  Lr: 0.001875  Loss: -0.4563  Acc@1: 81.2500 (77.9351)  Acc@5: 100.0000 (98.5843)  time: 0.3482  data: 0.0017  max mem: 2503
Train: Epoch[2/5]  [ 190/3750]  eta: 0:20:54  Lr: 0.001875  Loss: -0.6390  Acc@1: 81.2500 (77.9777)  Acc@5: 100.0000 (98.5929)  time: 0.3469  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [ 200/3750]  eta: 0:20:51  Lr: 0.001875  Loss: -0.8431  Acc@1: 81.2500 (78.2027)  Acc@5: 100.0000 (98.6007)  time: 0.3491  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [ 210/3750]  eta: 0:20:49  Lr: 0.001875  Loss: -0.5298  Acc@1: 81.2500 (78.1398)  Acc@5: 100.0000 (98.5782)  time: 0.3561  data: 0.0019  max mem: 2503
Train: Epoch[2/5]  [ 220/3750]  eta: 0:20:45  Lr: 0.001875  Loss: -0.7575  Acc@1: 75.0000 (78.1109)  Acc@5: 100.0000 (98.5011)  time: 0.3555  data: 0.0020  max mem: 2503
Train: Epoch[2/5]  [ 230/3750]  eta: 0:20:41  Lr: 0.001875  Loss: -0.5889  Acc@1: 75.0000 (77.7868)  Acc@5: 100.0000 (98.4037)  time: 0.3508  data: 0.0006  max mem: 2503
Train: Epoch[2/5]  [ 240/3750]  eta: 0:20:37  Lr: 0.001875  Loss: -0.8451  Acc@1: 75.0000 (77.8527)  Acc@5: 100.0000 (98.3662)  time: 0.3497  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [ 250/3750]  eta: 0:20:33  Lr: 0.001875  Loss: -0.7712  Acc@1: 81.2500 (77.9133)  Acc@5: 100.0000 (98.3068)  time: 0.3503  data: 0.0014  max mem: 2503
Train: Epoch[2/5]  [ 260/3750]  eta: 0:20:30  Lr: 0.001875  Loss: -0.6346  Acc@1: 68.7500 (77.6580)  Acc@5: 100.0000 (98.3238)  time: 0.3529  data: 0.0014  max mem: 2503
Train: Epoch[2/5]  [ 270/3750]  eta: 0:20:26  Lr: 0.001875  Loss: -0.8551  Acc@1: 75.0000 (77.9982)  Acc@5: 100.0000 (98.3856)  time: 0.3519  data: 0.0006  max mem: 2503
Train: Epoch[2/5]  [ 280/3750]  eta: 0:20:22  Lr: 0.001875  Loss: -0.2013  Acc@1: 81.2500 (77.9582)  Acc@5: 100.0000 (98.3541)  time: 0.3487  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [ 290/3750]  eta: 0:20:18  Lr: 0.001875  Loss: -0.3802  Acc@1: 81.2500 (78.1143)  Acc@5: 100.0000 (98.3677)  time: 0.3474  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [ 300/3750]  eta: 0:20:14  Lr: 0.001875  Loss: -0.5017  Acc@1: 75.0000 (77.8239)  Acc@5: 100.0000 (98.3181)  time: 0.3514  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [ 310/3750]  eta: 0:20:11  Lr: 0.001875  Loss: -0.5232  Acc@1: 68.7500 (77.7130)  Acc@5: 100.0000 (98.2516)  time: 0.3516  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [ 320/3750]  eta: 0:20:07  Lr: 0.001875  Loss: -0.8776  Acc@1: 81.2500 (77.7064)  Acc@5: 100.0000 (98.2866)  time: 0.3486  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [ 330/3750]  eta: 0:20:03  Lr: 0.001875  Loss: -0.8244  Acc@1: 75.0000 (77.6435)  Acc@5: 100.0000 (98.3384)  time: 0.3473  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [ 340/3750]  eta: 0:19:59  Lr: 0.001875  Loss: -0.9003  Acc@1: 75.0000 (77.6210)  Acc@5: 100.0000 (98.3688)  time: 0.3475  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [ 350/3750]  eta: 0:19:55  Lr: 0.001875  Loss: -0.4214  Acc@1: 75.0000 (77.5107)  Acc@5: 100.0000 (98.3618)  time: 0.3483  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [ 360/3750]  eta: 0:19:51  Lr: 0.001875  Loss: -0.5810  Acc@1: 75.0000 (77.5104)  Acc@5: 100.0000 (98.4072)  time: 0.3459  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [ 370/3750]  eta: 0:19:47  Lr: 0.001875  Loss: -0.6848  Acc@1: 75.0000 (77.4764)  Acc@5: 100.0000 (98.4164)  time: 0.3461  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [ 380/3750]  eta: 0:19:44  Lr: 0.001875  Loss: -0.5000  Acc@1: 75.0000 (77.4934)  Acc@5: 100.0000 (98.4088)  time: 0.3512  data: 0.0017  max mem: 2503
Train: Epoch[2/5]  [ 390/3750]  eta: 0:19:40  Lr: 0.001875  Loss: -1.0291  Acc@1: 81.2500 (77.5735)  Acc@5: 100.0000 (98.4175)  time: 0.3530  data: 0.0018  max mem: 2503
Train: Epoch[2/5]  [ 400/3750]  eta: 0:19:36  Lr: 0.001875  Loss: -0.7384  Acc@1: 81.2500 (77.7276)  Acc@5: 100.0000 (98.4258)  time: 0.3505  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [ 410/3750]  eta: 0:19:33  Lr: 0.001875  Loss: -0.5463  Acc@1: 81.2500 (77.7981)  Acc@5: 100.0000 (98.4337)  time: 0.3507  data: 0.0007  max mem: 2503
Train: Epoch[2/5]  [ 420/3750]  eta: 0:19:29  Lr: 0.001875  Loss: -0.4264  Acc@1: 75.0000 (77.7167)  Acc@5: 100.0000 (98.4264)  time: 0.3515  data: 0.0014  max mem: 2503
Train: Epoch[2/5]  [ 430/3750]  eta: 0:19:26  Lr: 0.001875  Loss: -0.4563  Acc@1: 75.0000 (77.7697)  Acc@5: 100.0000 (98.4194)  time: 0.3527  data: 0.0018  max mem: 2503
Train: Epoch[2/5]  [ 440/3750]  eta: 0:19:23  Lr: 0.001875  Loss: -0.5179  Acc@1: 81.2500 (77.8203)  Acc@5: 100.0000 (98.4410)  time: 0.3534  data: 0.0012  max mem: 2503
Train: Epoch[2/5]  [ 450/3750]  eta: 0:19:19  Lr: 0.001875  Loss: -0.5829  Acc@1: 75.0000 (77.7023)  Acc@5: 100.0000 (98.4479)  time: 0.3519  data: 0.0006  max mem: 2503
Train: Epoch[2/5]  [ 460/3750]  eta: 0:19:16  Lr: 0.001875  Loss: -0.6307  Acc@1: 75.0000 (77.6573)  Acc@5: 100.0000 (98.4544)  time: 0.3511  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [ 470/3750]  eta: 0:19:12  Lr: 0.001875  Loss: -0.7399  Acc@1: 81.2500 (77.7468)  Acc@5: 100.0000 (98.4607)  time: 0.3491  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [ 480/3750]  eta: 0:19:08  Lr: 0.001875  Loss: -0.2193  Acc@1: 81.2500 (77.6897)  Acc@5: 100.0000 (98.4927)  time: 0.3484  data: 0.0006  max mem: 2503
Train: Epoch[2/5]  [ 490/3750]  eta: 0:19:05  Lr: 0.001875  Loss: -0.6069  Acc@1: 75.0000 (77.6477)  Acc@5: 100.0000 (98.4852)  time: 0.3495  data: 0.0008  max mem: 2503
Train: Epoch[2/5]  [ 500/3750]  eta: 0:19:01  Lr: 0.001875  Loss: -0.3417  Acc@1: 81.2500 (77.7819)  Acc@5: 100.0000 (98.4656)  time: 0.3482  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [ 510/3750]  eta: 0:18:57  Lr: 0.001875  Loss: -0.2696  Acc@1: 81.2500 (77.8253)  Acc@5: 100.0000 (98.4467)  time: 0.3484  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [ 520/3750]  eta: 0:18:53  Lr: 0.001875  Loss: -0.8707  Acc@1: 81.2500 (77.9391)  Acc@5: 100.0000 (98.4765)  time: 0.3489  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [ 530/3750]  eta: 0:18:50  Lr: 0.001875  Loss: -0.9100  Acc@1: 81.2500 (77.8719)  Acc@5: 100.0000 (98.4816)  time: 0.3477  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [ 540/3750]  eta: 0:18:46  Lr: 0.001875  Loss: -0.2967  Acc@1: 75.0000 (77.7611)  Acc@5: 100.0000 (98.4866)  time: 0.3480  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [ 550/3750]  eta: 0:18:42  Lr: 0.001875  Loss: -0.6392  Acc@1: 75.0000 (77.8244)  Acc@5: 100.0000 (98.4914)  time: 0.3488  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [ 560/3750]  eta: 0:18:39  Lr: 0.001875  Loss: -0.7627  Acc@1: 75.0000 (77.7963)  Acc@5: 100.0000 (98.5183)  time: 0.3491  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [ 570/3750]  eta: 0:18:35  Lr: 0.001875  Loss: -0.8594  Acc@1: 75.0000 (77.7912)  Acc@5: 100.0000 (98.5223)  time: 0.3481  data: 0.0006  max mem: 2503
Train: Epoch[2/5]  [ 580/3750]  eta: 0:18:31  Lr: 0.001875  Loss: -0.5254  Acc@1: 81.2500 (77.8830)  Acc@5: 100.0000 (98.5262)  time: 0.3468  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [ 590/3750]  eta: 0:18:28  Lr: 0.001875  Loss: -0.2236  Acc@1: 81.2500 (77.8659)  Acc@5: 100.0000 (98.5406)  time: 0.3472  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [ 600/3750]  eta: 0:18:24  Lr: 0.001875  Loss: -0.4744  Acc@1: 81.2500 (77.8702)  Acc@5: 100.0000 (98.5441)  time: 0.3509  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [ 610/3750]  eta: 0:18:21  Lr: 0.001875  Loss: -0.5634  Acc@1: 81.2500 (77.8539)  Acc@5: 100.0000 (98.5679)  time: 0.3534  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [ 620/3750]  eta: 0:18:17  Lr: 0.001875  Loss: -0.5628  Acc@1: 75.0000 (77.8080)  Acc@5: 100.0000 (98.5709)  time: 0.3510  data: 0.0006  max mem: 2503
Train: Epoch[2/5]  [ 630/3750]  eta: 0:18:14  Lr: 0.001875  Loss: -0.1987  Acc@1: 75.0000 (77.7833)  Acc@5: 100.0000 (98.5836)  time: 0.3516  data: 0.0006  max mem: 2503
Train: Epoch[2/5]  [ 640/3750]  eta: 0:18:11  Lr: 0.001875  Loss: -0.4869  Acc@1: 68.7500 (77.7009)  Acc@5: 100.0000 (98.5764)  time: 0.3528  data: 0.0013  max mem: 2503
Train: Epoch[2/5]  [ 650/3750]  eta: 0:18:07  Lr: 0.001875  Loss: -0.5649  Acc@1: 68.7500 (77.7266)  Acc@5: 100.0000 (98.5695)  time: 0.3555  data: 0.0019  max mem: 2503
Train: Epoch[2/5]  [ 660/3750]  eta: 0:18:04  Lr: 0.001875  Loss: -0.4372  Acc@1: 75.0000 (77.6475)  Acc@5: 100.0000 (98.5628)  time: 0.3542  data: 0.0011  max mem: 2503
Train: Epoch[2/5]  [ 670/3750]  eta: 0:18:00  Lr: 0.001875  Loss: -0.8765  Acc@1: 75.0000 (77.5801)  Acc@5: 100.0000 (98.5563)  time: 0.3499  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [ 680/3750]  eta: 0:17:57  Lr: 0.001875  Loss: -0.5706  Acc@1: 75.0000 (77.5606)  Acc@5: 100.0000 (98.5591)  time: 0.3505  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [ 690/3750]  eta: 0:17:53  Lr: 0.001875  Loss: -0.5896  Acc@1: 75.0000 (77.5416)  Acc@5: 100.0000 (98.5619)  time: 0.3494  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [ 700/3750]  eta: 0:17:50  Lr: 0.001875  Loss: -0.4324  Acc@1: 75.0000 (77.5499)  Acc@5: 100.0000 (98.5556)  time: 0.3504  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [ 710/3750]  eta: 0:17:46  Lr: 0.001875  Loss: -0.3654  Acc@1: 75.0000 (77.5580)  Acc@5: 100.0000 (98.5496)  time: 0.3501  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [ 720/3750]  eta: 0:17:42  Lr: 0.001875  Loss: -0.0179  Acc@1: 75.0000 (77.4705)  Acc@5: 100.0000 (98.5177)  time: 0.3484  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [ 730/3750]  eta: 0:17:39  Lr: 0.001875  Loss: -0.8117  Acc@1: 75.0000 (77.4709)  Acc@5: 100.0000 (98.5294)  time: 0.3478  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [ 740/3750]  eta: 0:17:35  Lr: 0.001875  Loss: -0.4543  Acc@1: 81.2500 (77.4376)  Acc@5: 100.0000 (98.5324)  time: 0.3478  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [ 750/3750]  eta: 0:17:32  Lr: 0.001875  Loss: -0.1390  Acc@1: 81.2500 (77.4800)  Acc@5: 100.0000 (98.5186)  time: 0.3480  data: 0.0006  max mem: 2503
Train: Epoch[2/5]  [ 760/3750]  eta: 0:17:28  Lr: 0.001875  Loss: -0.3340  Acc@1: 75.0000 (77.3899)  Acc@5: 100.0000 (98.5135)  time: 0.3467  data: 0.0006  max mem: 2503
Train: Epoch[2/5]  [ 770/3750]  eta: 0:17:24  Lr: 0.001875  Loss: -0.8049  Acc@1: 75.0000 (77.3752)  Acc@5: 100.0000 (98.5246)  time: 0.3465  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [ 780/3750]  eta: 0:17:21  Lr: 0.001875  Loss: -0.6996  Acc@1: 75.0000 (77.3848)  Acc@5: 100.0000 (98.5195)  time: 0.3491  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [ 790/3750]  eta: 0:17:17  Lr: 0.001875  Loss: -0.8255  Acc@1: 81.2500 (77.3941)  Acc@5: 100.0000 (98.5224)  time: 0.3512  data: 0.0006  max mem: 2503
Train: Epoch[2/5]  [ 800/3750]  eta: 0:17:14  Lr: 0.001875  Loss: -0.8267  Acc@1: 75.0000 (77.4032)  Acc@5: 100.0000 (98.5175)  time: 0.3506  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [ 810/3750]  eta: 0:17:10  Lr: 0.001875  Loss: -0.4422  Acc@1: 75.0000 (77.3967)  Acc@5: 100.0000 (98.5281)  time: 0.3500  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [ 820/3750]  eta: 0:17:07  Lr: 0.001875  Loss: -0.4351  Acc@1: 75.0000 (77.4361)  Acc@5: 100.0000 (98.5384)  time: 0.3542  data: 0.0006  max mem: 2503
Train: Epoch[2/5]  [ 830/3750]  eta: 0:17:04  Lr: 0.001875  Loss: -0.6716  Acc@1: 81.2500 (77.4744)  Acc@5: 100.0000 (98.5334)  time: 0.3551  data: 0.0008  max mem: 2503
Train: Epoch[2/5]  [ 840/3750]  eta: 0:17:00  Lr: 0.001875  Loss: -0.6396  Acc@1: 81.2500 (77.5342)  Acc@5: 100.0000 (98.5434)  time: 0.3497  data: 0.0007  max mem: 2503
Train: Epoch[2/5]  [ 850/3750]  eta: 0:16:56  Lr: 0.001875  Loss: -0.3517  Acc@1: 81.2500 (77.4971)  Acc@5: 100.0000 (98.5532)  time: 0.3497  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [ 860/3750]  eta: 0:16:53  Lr: 0.001875  Loss: -0.2217  Acc@1: 75.0000 (77.4826)  Acc@5: 100.0000 (98.5482)  time: 0.3519  data: 0.0006  max mem: 2503
Train: Epoch[2/5]  [ 870/3750]  eta: 0:16:49  Lr: 0.001875  Loss: -0.5747  Acc@1: 75.0000 (77.4684)  Acc@5: 100.0000 (98.5649)  time: 0.3507  data: 0.0010  max mem: 2503
Train: Epoch[2/5]  [ 880/3750]  eta: 0:16:46  Lr: 0.001875  Loss: -1.0258  Acc@1: 75.0000 (77.5184)  Acc@5: 100.0000 (98.5812)  time: 0.3498  data: 0.0009  max mem: 2503
Train: Epoch[2/5]  [ 890/3750]  eta: 0:16:42  Lr: 0.001875  Loss: -0.6632  Acc@1: 81.2500 (77.5463)  Acc@5: 100.0000 (98.5831)  time: 0.3509  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [ 900/3750]  eta: 0:16:39  Lr: 0.001875  Loss: -0.6904  Acc@1: 75.0000 (77.5111)  Acc@5: 100.0000 (98.5918)  time: 0.3497  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [ 910/3750]  eta: 0:16:35  Lr: 0.001875  Loss: -0.5591  Acc@1: 75.0000 (77.4904)  Acc@5: 100.0000 (98.5867)  time: 0.3478  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [ 920/3750]  eta: 0:16:32  Lr: 0.001875  Loss: -0.7763  Acc@1: 75.0000 (77.4837)  Acc@5: 100.0000 (98.5953)  time: 0.3496  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [ 930/3750]  eta: 0:16:28  Lr: 0.001875  Loss: -0.5053  Acc@1: 75.0000 (77.4839)  Acc@5: 100.0000 (98.5835)  time: 0.3482  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [ 940/3750]  eta: 0:16:24  Lr: 0.001875  Loss: -0.2380  Acc@1: 75.0000 (77.4044)  Acc@5: 100.0000 (98.5587)  time: 0.3460  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [ 950/3750]  eta: 0:16:21  Lr: 0.001875  Loss: -0.8644  Acc@1: 75.0000 (77.4317)  Acc@5: 100.0000 (98.5607)  time: 0.3466  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [ 960/3750]  eta: 0:16:17  Lr: 0.001875  Loss: -0.1871  Acc@1: 75.0000 (77.4129)  Acc@5: 100.0000 (98.5562)  time: 0.3470  data: 0.0007  max mem: 2503
Train: Epoch[2/5]  [ 970/3750]  eta: 0:16:14  Lr: 0.001875  Loss: -0.7753  Acc@1: 75.0000 (77.4009)  Acc@5: 100.0000 (98.5711)  time: 0.3477  data: 0.0007  max mem: 2503
Train: Epoch[2/5]  [ 980/3750]  eta: 0:16:10  Lr: 0.001875  Loss: -0.4874  Acc@1: 75.0000 (77.3828)  Acc@5: 100.0000 (98.5856)  time: 0.3524  data: 0.0008  max mem: 2503
Train: Epoch[2/5]  [ 990/3750]  eta: 0:16:07  Lr: 0.001875  Loss: -0.4669  Acc@1: 81.2500 (77.4218)  Acc@5: 100.0000 (98.5936)  time: 0.3526  data: 0.0008  max mem: 2503
Train: Epoch[2/5]  [1000/3750]  eta: 0:16:03  Lr: 0.001875  Loss: -0.5832  Acc@1: 81.2500 (77.4101)  Acc@5: 100.0000 (98.5889)  time: 0.3511  data: 0.0013  max mem: 2503
Train: Epoch[2/5]  [1010/3750]  eta: 0:16:00  Lr: 0.001875  Loss: -0.4732  Acc@1: 75.0000 (77.3801)  Acc@5: 100.0000 (98.5905)  time: 0.3522  data: 0.0014  max mem: 2503
Train: Epoch[2/5]  [1020/3750]  eta: 0:15:57  Lr: 0.001875  Loss: -0.7879  Acc@1: 75.0000 (77.3996)  Acc@5: 100.0000 (98.5921)  time: 0.3529  data: 0.0006  max mem: 2503
Train: Epoch[2/5]  [1030/3750]  eta: 0:15:53  Lr: 0.001875  Loss: -0.7115  Acc@1: 75.0000 (77.4127)  Acc@5: 100.0000 (98.5936)  time: 0.3520  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [1040/3750]  eta: 0:15:50  Lr: 0.001875  Loss: -0.6880  Acc@1: 75.0000 (77.4075)  Acc@5: 100.0000 (98.6011)  time: 0.3512  data: 0.0006  max mem: 2503
Train: Epoch[2/5]  [1050/3750]  eta: 0:15:46  Lr: 0.001875  Loss: -0.6125  Acc@1: 81.2500 (77.4263)  Acc@5: 100.0000 (98.5966)  time: 0.3573  data: 0.0020  max mem: 2503
Train: Epoch[2/5]  [1060/3750]  eta: 0:15:43  Lr: 0.001875  Loss: -0.7558  Acc@1: 75.0000 (77.3504)  Acc@5: 100.0000 (98.5980)  time: 0.3597  data: 0.0026  max mem: 2503
Train: Epoch[2/5]  [1070/3750]  eta: 0:15:39  Lr: 0.001875  Loss: -0.9474  Acc@1: 75.0000 (77.3868)  Acc@5: 100.0000 (98.5994)  time: 0.3528  data: 0.0010  max mem: 2503
Train: Epoch[2/5]  [1080/3750]  eta: 0:15:36  Lr: 0.001875  Loss: -0.7961  Acc@1: 81.2500 (77.4399)  Acc@5: 100.0000 (98.6124)  time: 0.3489  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [1090/3750]  eta: 0:15:32  Lr: 0.001875  Loss: -0.4809  Acc@1: 75.0000 (77.4232)  Acc@5: 100.0000 (98.6079)  time: 0.3492  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [1100/3750]  eta: 0:15:29  Lr: 0.001875  Loss: -0.5316  Acc@1: 75.0000 (77.4466)  Acc@5: 100.0000 (98.6149)  time: 0.3486  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [1110/3750]  eta: 0:15:25  Lr: 0.001875  Loss: -0.4921  Acc@1: 75.0000 (77.3684)  Acc@5: 100.0000 (98.6161)  time: 0.3499  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [1120/3750]  eta: 0:15:22  Lr: 0.001875  Loss: -0.8340  Acc@1: 75.0000 (77.3918)  Acc@5: 100.0000 (98.6229)  time: 0.3480  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [1130/3750]  eta: 0:15:18  Lr: 0.001875  Loss: -0.5388  Acc@1: 75.0000 (77.3541)  Acc@5: 100.0000 (98.6295)  time: 0.3467  data: 0.0008  max mem: 2503
Train: Epoch[2/5]  [1140/3750]  eta: 0:15:14  Lr: 0.001875  Loss: -0.4397  Acc@1: 75.0000 (77.4047)  Acc@5: 100.0000 (98.6361)  time: 0.3470  data: 0.0008  max mem: 2503
Train: Epoch[2/5]  [1150/3750]  eta: 0:15:11  Lr: 0.001875  Loss: -0.2697  Acc@1: 81.2500 (77.4218)  Acc@5: 100.0000 (98.6371)  time: 0.3460  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [1160/3750]  eta: 0:15:07  Lr: 0.001875  Loss: -0.5155  Acc@1: 75.0000 (77.4279)  Acc@5: 100.0000 (98.6380)  time: 0.3459  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [1170/3750]  eta: 0:15:04  Lr: 0.001875  Loss: -0.1860  Acc@1: 75.0000 (77.4231)  Acc@5: 100.0000 (98.6443)  time: 0.3483  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [1180/3750]  eta: 0:15:00  Lr: 0.001875  Loss: -0.9268  Acc@1: 81.2500 (77.4661)  Acc@5: 100.0000 (98.6452)  time: 0.3517  data: 0.0013  max mem: 2503
Train: Epoch[2/5]  [1190/3750]  eta: 0:14:57  Lr: 0.001875  Loss: -0.4465  Acc@1: 81.2500 (77.4927)  Acc@5: 100.0000 (98.6566)  time: 0.3534  data: 0.0014  max mem: 2503
Train: Epoch[2/5]  [1200/3750]  eta: 0:14:53  Lr: 0.001875  Loss: -0.8075  Acc@1: 75.0000 (77.4823)  Acc@5: 100.0000 (98.6574)  time: 0.3519  data: 0.0008  max mem: 2503
Train: Epoch[2/5]  [1210/3750]  eta: 0:14:50  Lr: 0.001875  Loss: -0.5880  Acc@1: 75.0000 (77.5031)  Acc@5: 100.0000 (98.6478)  time: 0.3513  data: 0.0007  max mem: 2503
Train: Epoch[2/5]  [1220/3750]  eta: 0:14:47  Lr: 0.001875  Loss: -0.1211  Acc@1: 81.2500 (77.4980)  Acc@5: 100.0000 (98.6333)  time: 0.3551  data: 0.0007  max mem: 2503
Train: Epoch[2/5]  [1230/3750]  eta: 0:14:43  Lr: 0.001875  Loss: -0.5565  Acc@1: 75.0000 (77.4980)  Acc@5: 100.0000 (98.6444)  time: 0.3529  data: 0.0013  max mem: 2503
Train: Epoch[2/5]  [1240/3750]  eta: 0:14:39  Lr: 0.001875  Loss: -0.6271  Acc@1: 81.2500 (77.5383)  Acc@5: 100.0000 (98.6503)  time: 0.3473  data: 0.0010  max mem: 2503
Train: Epoch[2/5]  [1250/3750]  eta: 0:14:36  Lr: 0.001875  Loss: -0.6433  Acc@1: 81.2500 (77.5480)  Acc@5: 100.0000 (98.6561)  time: 0.3475  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [1260/3750]  eta: 0:14:32  Lr: 0.001875  Loss: -0.7401  Acc@1: 81.2500 (77.5575)  Acc@5: 100.0000 (98.6568)  time: 0.3508  data: 0.0010  max mem: 2503
Train: Epoch[2/5]  [1270/3750]  eta: 0:14:29  Lr: 0.001875  Loss: -0.3242  Acc@1: 81.2500 (77.5669)  Acc@5: 100.0000 (98.6576)  time: 0.3525  data: 0.0012  max mem: 2503
Train: Epoch[2/5]  [1280/3750]  eta: 0:14:25  Lr: 0.001875  Loss: -0.8514  Acc@1: 81.2500 (77.5810)  Acc@5: 100.0000 (98.6583)  time: 0.3493  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [1290/3750]  eta: 0:14:22  Lr: 0.001875  Loss: -0.3606  Acc@1: 81.2500 (77.5900)  Acc@5: 100.0000 (98.6541)  time: 0.3478  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [1300/3750]  eta: 0:14:18  Lr: 0.001875  Loss: -0.7562  Acc@1: 81.2500 (77.6182)  Acc@5: 100.0000 (98.6597)  time: 0.3484  data: 0.0006  max mem: 2503
Train: Epoch[2/5]  [1310/3750]  eta: 0:14:15  Lr: 0.001875  Loss: -0.7470  Acc@1: 81.2500 (77.6411)  Acc@5: 100.0000 (98.6556)  time: 0.3507  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [1320/3750]  eta: 0:14:11  Lr: 0.001875  Loss: -0.5584  Acc@1: 81.2500 (77.6732)  Acc@5: 100.0000 (98.6563)  time: 0.3504  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [1330/3750]  eta: 0:14:08  Lr: 0.001875  Loss: -0.2116  Acc@1: 81.2500 (77.6766)  Acc@5: 100.0000 (98.6523)  time: 0.3462  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [1340/3750]  eta: 0:14:04  Lr: 0.001875  Loss: -0.1982  Acc@1: 75.0000 (77.6566)  Acc@5: 100.0000 (98.6624)  time: 0.3463  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [1350/3750]  eta: 0:14:00  Lr: 0.001875  Loss: -0.4741  Acc@1: 75.0000 (77.6647)  Acc@5: 100.0000 (98.6584)  time: 0.3479  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [1360/3750]  eta: 0:13:57  Lr: 0.001875  Loss: -0.7328  Acc@1: 81.2500 (77.6864)  Acc@5: 100.0000 (98.6591)  time: 0.3467  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [1370/3750]  eta: 0:13:53  Lr: 0.001875  Loss: -0.7048  Acc@1: 81.2500 (77.6851)  Acc@5: 100.0000 (98.6597)  time: 0.3474  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [1380/3750]  eta: 0:13:50  Lr: 0.001875  Loss: -0.5177  Acc@1: 75.0000 (77.6747)  Acc@5: 100.0000 (98.6604)  time: 0.3544  data: 0.0006  max mem: 2503
Train: Epoch[2/5]  [1390/3750]  eta: 0:13:47  Lr: 0.001875  Loss: -0.5572  Acc@1: 81.2500 (77.7004)  Acc@5: 100.0000 (98.6610)  time: 0.3575  data: 0.0023  max mem: 2503
Train: Epoch[2/5]  [1400/3750]  eta: 0:13:43  Lr: 0.001875  Loss: -0.4943  Acc@1: 81.2500 (77.7168)  Acc@5: 100.0000 (98.6617)  time: 0.3530  data: 0.0021  max mem: 2503
Train: Epoch[2/5]  [1410/3750]  eta: 0:13:40  Lr: 0.001875  Loss: -0.6584  Acc@1: 81.2500 (77.7241)  Acc@5: 100.0000 (98.6446)  time: 0.3505  data: 0.0011  max mem: 2503
Train: Epoch[2/5]  [1420/3750]  eta: 0:13:36  Lr: 0.001875  Loss: -0.8234  Acc@1: 81.2500 (77.7577)  Acc@5: 100.0000 (98.6497)  time: 0.3510  data: 0.0012  max mem: 2503
Train: Epoch[2/5]  [1430/3750]  eta: 0:13:33  Lr: 0.001875  Loss: -0.0708  Acc@1: 81.2500 (77.7778)  Acc@5: 100.0000 (98.6504)  time: 0.3558  data: 0.0008  max mem: 2503
Train: Epoch[2/5]  [1440/3750]  eta: 0:13:29  Lr: 0.001875  Loss: -0.4664  Acc@1: 75.0000 (77.7759)  Acc@5: 100.0000 (98.6511)  time: 0.3552  data: 0.0006  max mem: 2503
Train: Epoch[2/5]  [1450/3750]  eta: 0:13:26  Lr: 0.001875  Loss: -0.5270  Acc@1: 75.0000 (77.7223)  Acc@5: 100.0000 (98.6518)  time: 0.3495  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [1460/3750]  eta: 0:13:22  Lr: 0.001875  Loss: -0.7464  Acc@1: 68.7500 (77.7036)  Acc@5: 100.0000 (98.6396)  time: 0.3494  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [1470/3750]  eta: 0:13:19  Lr: 0.001875  Loss: -0.5650  Acc@1: 68.7500 (77.6640)  Acc@5: 100.0000 (98.6361)  time: 0.3507  data: 0.0012  max mem: 2503
Train: Epoch[2/5]  [1480/3750]  eta: 0:13:15  Lr: 0.001875  Loss: -0.7761  Acc@1: 75.0000 (77.6671)  Acc@5: 100.0000 (98.6369)  time: 0.3502  data: 0.0012  max mem: 2503
Train: Epoch[2/5]  [1490/3750]  eta: 0:13:12  Lr: 0.001875  Loss: -0.4490  Acc@1: 75.0000 (77.6241)  Acc@5: 100.0000 (98.6419)  time: 0.3478  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [1500/3750]  eta: 0:13:08  Lr: 0.001875  Loss: -0.5648  Acc@1: 75.0000 (77.6233)  Acc@5: 100.0000 (98.6342)  time: 0.3477  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [1510/3750]  eta: 0:13:05  Lr: 0.001875  Loss: -0.8010  Acc@1: 75.0000 (77.5935)  Acc@5: 100.0000 (98.6226)  time: 0.3483  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [1520/3750]  eta: 0:13:01  Lr: 0.001875  Loss: -0.7999  Acc@1: 75.0000 (77.6052)  Acc@5: 100.0000 (98.6193)  time: 0.3486  data: 0.0007  max mem: 2503
Train: Epoch[2/5]  [1530/3750]  eta: 0:12:57  Lr: 0.001875  Loss: -0.2768  Acc@1: 75.0000 (77.5800)  Acc@5: 100.0000 (98.6161)  time: 0.3466  data: 0.0006  max mem: 2503
Train: Epoch[2/5]  [1540/3750]  eta: 0:12:54  Lr: 0.001875  Loss: -0.6780  Acc@1: 81.2500 (77.6282)  Acc@5: 100.0000 (98.6251)  time: 0.3453  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [1550/3750]  eta: 0:12:50  Lr: 0.001875  Loss: -0.4671  Acc@1: 81.2500 (77.6193)  Acc@5: 100.0000 (98.6299)  time: 0.3471  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [1560/3750]  eta: 0:12:47  Lr: 0.001875  Loss: -0.9597  Acc@1: 81.2500 (77.6505)  Acc@5: 100.0000 (98.6387)  time: 0.3494  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [1570/3750]  eta: 0:12:43  Lr: 0.001875  Loss: -0.5272  Acc@1: 81.2500 (77.6416)  Acc@5: 100.0000 (98.6394)  time: 0.3513  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [1580/3750]  eta: 0:12:40  Lr: 0.001875  Loss: -0.8066  Acc@1: 75.0000 (77.6486)  Acc@5: 100.0000 (98.6441)  time: 0.3499  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [1590/3750]  eta: 0:12:36  Lr: 0.001875  Loss: -0.3739  Acc@1: 81.2500 (77.6831)  Acc@5: 100.0000 (98.6447)  time: 0.3521  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [1600/3750]  eta: 0:12:33  Lr: 0.001875  Loss: -0.6360  Acc@1: 81.2500 (77.6819)  Acc@5: 100.0000 (98.6454)  time: 0.3572  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [1610/3750]  eta: 0:12:30  Lr: 0.001875  Loss: -0.6870  Acc@1: 75.0000 (77.6614)  Acc@5: 100.0000 (98.6421)  time: 0.3558  data: 0.0008  max mem: 2503
Train: Epoch[2/5]  [1620/3750]  eta: 0:12:26  Lr: 0.001875  Loss: -0.3966  Acc@1: 75.0000 (77.6951)  Acc@5: 100.0000 (98.6428)  time: 0.3507  data: 0.0008  max mem: 2503
Train: Epoch[2/5]  [1630/3750]  eta: 0:12:22  Lr: 0.001875  Loss: -0.4534  Acc@1: 87.5000 (77.7169)  Acc@5: 100.0000 (98.6473)  time: 0.3487  data: 0.0008  max mem: 2503
Train: Epoch[2/5]  [1640/3750]  eta: 0:12:19  Lr: 0.001875  Loss: -0.5776  Acc@1: 81.2500 (77.7346)  Acc@5: 100.0000 (98.6441)  time: 0.3520  data: 0.0012  max mem: 2503
Train: Epoch[2/5]  [1650/3750]  eta: 0:12:16  Lr: 0.001875  Loss: -0.3889  Acc@1: 75.0000 (77.7256)  Acc@5: 100.0000 (98.6448)  time: 0.3536  data: 0.0009  max mem: 2503
Train: Epoch[2/5]  [1660/3750]  eta: 0:12:12  Lr: 0.001875  Loss: -0.4458  Acc@1: 75.0000 (77.7243)  Acc@5: 100.0000 (98.6454)  time: 0.3501  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [1670/3750]  eta: 0:12:09  Lr: 0.001875  Loss: -0.8826  Acc@1: 81.2500 (77.7603)  Acc@5: 100.0000 (98.6423)  time: 0.3497  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [1680/3750]  eta: 0:12:05  Lr: 0.001875  Loss: -0.5327  Acc@1: 81.2500 (77.7476)  Acc@5: 100.0000 (98.6466)  time: 0.3502  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [1690/3750]  eta: 0:12:01  Lr: 0.001875  Loss: -0.6341  Acc@1: 81.2500 (77.7572)  Acc@5: 100.0000 (98.6473)  time: 0.3493  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [1700/3750]  eta: 0:11:58  Lr: 0.001875  Loss: -0.7082  Acc@1: 81.2500 (77.7484)  Acc@5: 100.0000 (98.6515)  time: 0.3493  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [1710/3750]  eta: 0:11:54  Lr: 0.001875  Loss: -0.4039  Acc@1: 75.0000 (77.7433)  Acc@5: 100.0000 (98.6485)  time: 0.3467  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [1720/3750]  eta: 0:11:51  Lr: 0.001875  Loss: -0.3803  Acc@1: 75.0000 (77.7382)  Acc@5: 100.0000 (98.6527)  time: 0.3460  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [1730/3750]  eta: 0:11:47  Lr: 0.001875  Loss: -0.2705  Acc@1: 68.7500 (77.7080)  Acc@5: 100.0000 (98.6532)  time: 0.3481  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [1740/3750]  eta: 0:11:44  Lr: 0.001875  Loss: -0.4116  Acc@1: 75.0000 (77.7175)  Acc@5: 100.0000 (98.6574)  time: 0.3481  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [1750/3750]  eta: 0:11:40  Lr: 0.001875  Loss: 0.0357  Acc@1: 75.0000 (77.6913)  Acc@5: 100.0000 (98.6579)  time: 0.3484  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [1760/3750]  eta: 0:11:37  Lr: 0.001875  Loss: -0.1491  Acc@1: 75.0000 (77.6902)  Acc@5: 100.0000 (98.6584)  time: 0.3495  data: 0.0006  max mem: 2503
Train: Epoch[2/5]  [1770/3750]  eta: 0:11:33  Lr: 0.001875  Loss: -0.6179  Acc@1: 81.2500 (77.7033)  Acc@5: 100.0000 (98.6625)  time: 0.3559  data: 0.0012  max mem: 2503
Train: Epoch[2/5]  [1780/3750]  eta: 0:11:30  Lr: 0.001875  Loss: -0.5658  Acc@1: 81.2500 (77.7021)  Acc@5: 100.0000 (98.6630)  time: 0.3571  data: 0.0012  max mem: 2503
Train: Epoch[2/5]  [1790/3750]  eta: 0:11:26  Lr: 0.001875  Loss: -0.6513  Acc@1: 75.0000 (77.6975)  Acc@5: 100.0000 (98.6600)  time: 0.3510  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [1800/3750]  eta: 0:11:23  Lr: 0.001875  Loss: -0.6350  Acc@1: 81.2500 (77.6895)  Acc@5: 100.0000 (98.6605)  time: 0.3493  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [1810/3750]  eta: 0:11:19  Lr: 0.001875  Loss: -0.3641  Acc@1: 81.2500 (77.7091)  Acc@5: 100.0000 (98.6679)  time: 0.3481  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [1820/3750]  eta: 0:11:16  Lr: 0.001875  Loss: -0.5296  Acc@1: 75.0000 (77.6668)  Acc@5: 100.0000 (98.6683)  time: 0.3507  data: 0.0006  max mem: 2503
Train: Epoch[2/5]  [1830/3750]  eta: 0:11:12  Lr: 0.001875  Loss: -0.2204  Acc@1: 68.7500 (77.6318)  Acc@5: 100.0000 (98.6653)  time: 0.3535  data: 0.0010  max mem: 2503
Train: Epoch[2/5]  [1840/3750]  eta: 0:11:09  Lr: 0.001875  Loss: -0.5096  Acc@1: 75.0000 (77.6175)  Acc@5: 100.0000 (98.6658)  time: 0.3517  data: 0.0009  max mem: 2503
Train: Epoch[2/5]  [1850/3750]  eta: 0:11:05  Lr: 0.001875  Loss: -0.3768  Acc@1: 75.0000 (77.6506)  Acc@5: 100.0000 (98.6663)  time: 0.3500  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [1860/3750]  eta: 0:11:02  Lr: 0.001875  Loss: -0.7965  Acc@1: 81.2500 (77.6800)  Acc@5: 100.0000 (98.6701)  time: 0.3496  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [1870/3750]  eta: 0:10:58  Lr: 0.001875  Loss: -0.2538  Acc@1: 87.5000 (77.7058)  Acc@5: 100.0000 (98.6638)  time: 0.3536  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [1880/3750]  eta: 0:10:55  Lr: 0.001875  Loss: -0.4828  Acc@1: 75.0000 (77.7113)  Acc@5: 100.0000 (98.6709)  time: 0.3535  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [1890/3750]  eta: 0:10:51  Lr: 0.001875  Loss: -0.8504  Acc@1: 75.0000 (77.7267)  Acc@5: 100.0000 (98.6647)  time: 0.3471  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [1900/3750]  eta: 0:10:48  Lr: 0.001875  Loss: -0.7212  Acc@1: 75.0000 (77.7420)  Acc@5: 100.0000 (98.6619)  time: 0.3457  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [1910/3750]  eta: 0:10:44  Lr: 0.001875  Loss: -0.3025  Acc@1: 75.0000 (77.7342)  Acc@5: 100.0000 (98.6591)  time: 0.3488  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [1920/3750]  eta: 0:10:41  Lr: 0.001875  Loss: -0.8538  Acc@1: 81.2500 (77.7720)  Acc@5: 100.0000 (98.6661)  time: 0.3504  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [1930/3750]  eta: 0:10:37  Lr: 0.001875  Loss: -0.4686  Acc@1: 81.2500 (77.7447)  Acc@5: 100.0000 (98.6730)  time: 0.3501  data: 0.0006  max mem: 2503
Train: Epoch[2/5]  [1940/3750]  eta: 0:10:34  Lr: 0.001875  Loss: -0.8210  Acc@1: 81.2500 (77.7789)  Acc@5: 100.0000 (98.6766)  time: 0.3494  data: 0.0007  max mem: 2503
Train: Epoch[2/5]  [1950/3750]  eta: 0:10:30  Lr: 0.001875  Loss: -1.0137  Acc@1: 81.2500 (77.7966)  Acc@5: 100.0000 (98.6738)  time: 0.3605  data: 0.0010  max mem: 2503
Train: Epoch[2/5]  [1960/3750]  eta: 0:10:27  Lr: 0.001875  Loss: -0.6755  Acc@1: 81.2500 (77.8174)  Acc@5: 100.0000 (98.6710)  time: 0.3612  data: 0.0011  max mem: 2503
Train: Epoch[2/5]  [1970/3750]  eta: 0:10:23  Lr: 0.001875  Loss: -0.8887  Acc@1: 81.2500 (77.8222)  Acc@5: 100.0000 (98.6682)  time: 0.3497  data: 0.0006  max mem: 2503
Train: Epoch[2/5]  [1980/3750]  eta: 0:10:20  Lr: 0.001875  Loss: -0.3894  Acc@1: 75.0000 (77.8332)  Acc@5: 100.0000 (98.6749)  time: 0.3514  data: 0.0006  max mem: 2503
Train: Epoch[2/5]  [1990/3750]  eta: 0:10:16  Lr: 0.001875  Loss: -0.4572  Acc@1: 75.0000 (77.8158)  Acc@5: 100.0000 (98.6659)  time: 0.3518  data: 0.0008  max mem: 2503
Train: Epoch[2/5]  [2000/3750]  eta: 0:10:13  Lr: 0.001875  Loss: -0.6464  Acc@1: 75.0000 (77.8142)  Acc@5: 100.0000 (98.6663)  time: 0.3535  data: 0.0022  max mem: 2503
Train: Epoch[2/5]  [2010/3750]  eta: 0:10:09  Lr: 0.001875  Loss: -0.3818  Acc@1: 75.0000 (77.8064)  Acc@5: 100.0000 (98.6605)  time: 0.3522  data: 0.0019  max mem: 2503
Train: Epoch[2/5]  [2020/3750]  eta: 0:10:06  Lr: 0.001875  Loss: -0.7468  Acc@1: 75.0000 (77.8297)  Acc@5: 100.0000 (98.6640)  time: 0.3515  data: 0.0008  max mem: 2503
Train: Epoch[2/5]  [2030/3750]  eta: 0:10:02  Lr: 0.001875  Loss: -0.8275  Acc@1: 81.2500 (77.8311)  Acc@5: 100.0000 (98.6645)  time: 0.3506  data: 0.0008  max mem: 2503
Train: Epoch[2/5]  [2040/3750]  eta: 0:09:59  Lr: 0.001875  Loss: -0.4927  Acc@1: 81.2500 (77.8417)  Acc@5: 100.0000 (98.6618)  time: 0.3485  data: 0.0008  max mem: 2503
Train: Epoch[2/5]  [2050/3750]  eta: 0:09:55  Lr: 0.001875  Loss: -0.2647  Acc@1: 81.2500 (77.8218)  Acc@5: 100.0000 (98.6561)  time: 0.3493  data: 0.0008  max mem: 2503
Train: Epoch[2/5]  [2060/3750]  eta: 0:09:52  Lr: 0.001875  Loss: -0.6088  Acc@1: 68.7500 (77.7929)  Acc@5: 100.0000 (98.6566)  time: 0.3481  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [2070/3750]  eta: 0:09:48  Lr: 0.001875  Loss: -0.5030  Acc@1: 68.7500 (77.7764)  Acc@5: 100.0000 (98.6570)  time: 0.3475  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [2080/3750]  eta: 0:09:45  Lr: 0.001875  Loss: -0.5503  Acc@1: 75.0000 (77.7631)  Acc@5: 100.0000 (98.6575)  time: 0.3478  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [2090/3750]  eta: 0:09:41  Lr: 0.001875  Loss: -0.1973  Acc@1: 75.0000 (77.7559)  Acc@5: 100.0000 (98.6520)  time: 0.3480  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [2100/3750]  eta: 0:09:38  Lr: 0.001875  Loss: -0.7781  Acc@1: 81.2500 (77.7874)  Acc@5: 100.0000 (98.6524)  time: 0.3466  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [2110/3750]  eta: 0:09:34  Lr: 0.001875  Loss: -0.4897  Acc@1: 81.2500 (77.8008)  Acc@5: 100.0000 (98.6559)  time: 0.3459  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [2120/3750]  eta: 0:09:31  Lr: 0.001875  Loss: -0.5693  Acc@1: 81.2500 (77.8053)  Acc@5: 100.0000 (98.6592)  time: 0.3524  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [2130/3750]  eta: 0:09:27  Lr: 0.001875  Loss: -0.6912  Acc@1: 81.2500 (77.8449)  Acc@5: 100.0000 (98.6626)  time: 0.3556  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [2140/3750]  eta: 0:09:24  Lr: 0.001875  Loss: -0.1295  Acc@1: 81.2500 (77.8433)  Acc@5: 100.0000 (98.6572)  time: 0.3519  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [2150/3750]  eta: 0:09:20  Lr: 0.001875  Loss: -0.7730  Acc@1: 75.0000 (77.8417)  Acc@5: 100.0000 (98.6576)  time: 0.3520  data: 0.0006  max mem: 2503
Train: Epoch[2/5]  [2160/3750]  eta: 0:09:17  Lr: 0.001875  Loss: -0.3342  Acc@1: 75.0000 (77.8401)  Acc@5: 100.0000 (98.6609)  time: 0.3533  data: 0.0006  max mem: 2503
Train: Epoch[2/5]  [2170/3750]  eta: 0:09:13  Lr: 0.001875  Loss: -0.5205  Acc@1: 75.0000 (77.8414)  Acc@5: 100.0000 (98.6498)  time: 0.3550  data: 0.0022  max mem: 2503
Train: Epoch[2/5]  [2180/3750]  eta: 0:09:10  Lr: 0.001875  Loss: -0.3751  Acc@1: 75.0000 (77.8370)  Acc@5: 100.0000 (98.6531)  time: 0.3535  data: 0.0022  max mem: 2503
Train: Epoch[2/5]  [2190/3750]  eta: 0:09:06  Lr: 0.001875  Loss: -0.5959  Acc@1: 75.0000 (77.8355)  Acc@5: 100.0000 (98.6536)  time: 0.3493  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [2200/3750]  eta: 0:09:03  Lr: 0.001875  Loss: -0.7799  Acc@1: 75.0000 (77.8311)  Acc@5: 100.0000 (98.6540)  time: 0.3543  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [2210/3750]  eta: 0:08:59  Lr: 0.001875  Loss: -0.7365  Acc@1: 81.2500 (77.8381)  Acc@5: 100.0000 (98.6601)  time: 0.3551  data: 0.0011  max mem: 2503
Train: Epoch[2/5]  [2220/3750]  eta: 0:08:56  Lr: 0.001875  Loss: -0.6593  Acc@1: 81.2500 (77.8563)  Acc@5: 100.0000 (98.6577)  time: 0.3489  data: 0.0010  max mem: 2503
Train: Epoch[2/5]  [2230/3750]  eta: 0:08:52  Lr: 0.001875  Loss: -0.6079  Acc@1: 81.2500 (77.8519)  Acc@5: 100.0000 (98.6581)  time: 0.3497  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [2240/3750]  eta: 0:08:49  Lr: 0.001875  Loss: -0.4844  Acc@1: 75.0000 (77.8447)  Acc@5: 100.0000 (98.6557)  time: 0.3495  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [2250/3750]  eta: 0:08:45  Lr: 0.001875  Loss: -0.6258  Acc@1: 81.2500 (77.8543)  Acc@5: 100.0000 (98.6506)  time: 0.3489  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [2260/3750]  eta: 0:08:42  Lr: 0.001875  Loss: -0.9136  Acc@1: 75.0000 (77.8555)  Acc@5: 100.0000 (98.6483)  time: 0.3497  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [2270/3750]  eta: 0:08:38  Lr: 0.001875  Loss: -0.5996  Acc@1: 75.0000 (77.8402)  Acc@5: 100.0000 (98.6405)  time: 0.3477  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [2280/3750]  eta: 0:08:35  Lr: 0.001875  Loss: -0.6163  Acc@1: 75.0000 (77.8277)  Acc@5: 100.0000 (98.6409)  time: 0.3459  data: 0.0002  max mem: 2503
Train: Epoch[2/5]  [2290/3750]  eta: 0:08:31  Lr: 0.001875  Loss: -0.5534  Acc@1: 81.2500 (77.8426)  Acc@5: 100.0000 (98.6442)  time: 0.3471  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [2300/3750]  eta: 0:08:28  Lr: 0.001875  Loss: -0.2742  Acc@1: 81.2500 (77.8384)  Acc@5: 100.0000 (98.6446)  time: 0.3481  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [2310/3750]  eta: 0:08:24  Lr: 0.001875  Loss: -0.5666  Acc@1: 75.0000 (77.8451)  Acc@5: 100.0000 (98.6478)  time: 0.3476  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [2320/3750]  eta: 0:08:21  Lr: 0.001875  Loss: -0.4166  Acc@1: 81.2500 (77.8678)  Acc@5: 100.0000 (98.6509)  time: 0.3480  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [2330/3750]  eta: 0:08:17  Lr: 0.001875  Loss: -0.4906  Acc@1: 81.2500 (77.8716)  Acc@5: 100.0000 (98.6540)  time: 0.3508  data: 0.0013  max mem: 2503
Train: Epoch[2/5]  [2340/3750]  eta: 0:08:14  Lr: 0.001875  Loss: -0.6649  Acc@1: 75.0000 (77.8540)  Acc@5: 100.0000 (98.6518)  time: 0.3536  data: 0.0014  max mem: 2503
Train: Epoch[2/5]  [2350/3750]  eta: 0:08:10  Lr: 0.001875  Loss: -0.8210  Acc@1: 75.0000 (77.8499)  Acc@5: 100.0000 (98.6495)  time: 0.3525  data: 0.0006  max mem: 2503
Train: Epoch[2/5]  [2360/3750]  eta: 0:08:07  Lr: 0.001875  Loss: -0.1003  Acc@1: 81.2500 (77.8431)  Acc@5: 100.0000 (98.6552)  time: 0.3509  data: 0.0007  max mem: 2503
Train: Epoch[2/5]  [2370/3750]  eta: 0:08:03  Lr: 0.001875  Loss: -0.6514  Acc@1: 81.2500 (77.8443)  Acc@5: 100.0000 (98.6556)  time: 0.3521  data: 0.0008  max mem: 2503
Train: Epoch[2/5]  [2380/3750]  eta: 0:08:00  Lr: 0.001875  Loss: -0.6251  Acc@1: 75.0000 (77.8428)  Acc@5: 100.0000 (98.6560)  time: 0.3567  data: 0.0017  max mem: 2503
Train: Epoch[2/5]  [2390/3750]  eta: 0:07:56  Lr: 0.001875  Loss: -0.5756  Acc@1: 81.2500 (77.8623)  Acc@5: 100.0000 (98.6564)  time: 0.3560  data: 0.0016  max mem: 2503
Train: Epoch[2/5]  [2400/3750]  eta: 0:07:53  Lr: 0.001875  Loss: -0.4604  Acc@1: 81.2500 (77.8530)  Acc@5: 100.0000 (98.6620)  time: 0.3511  data: 0.0006  max mem: 2503
Train: Epoch[2/5]  [2410/3750]  eta: 0:07:49  Lr: 0.001875  Loss: -0.3614  Acc@1: 81.2500 (77.8723)  Acc@5: 100.0000 (98.6650)  time: 0.3491  data: 0.0006  max mem: 2503
Train: Epoch[2/5]  [2420/3750]  eta: 0:07:46  Lr: 0.001875  Loss: -0.6938  Acc@1: 81.2500 (77.8656)  Acc@5: 100.0000 (98.6705)  time: 0.3476  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [2430/3750]  eta: 0:07:42  Lr: 0.001875  Loss: -0.3295  Acc@1: 75.0000 (77.8589)  Acc@5: 100.0000 (98.6528)  time: 0.3506  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [2440/3750]  eta: 0:07:39  Lr: 0.001875  Loss: -0.7290  Acc@1: 75.0000 (77.8498)  Acc@5: 100.0000 (98.6481)  time: 0.3510  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [2450/3750]  eta: 0:07:35  Lr: 0.001875  Loss: -0.1783  Acc@1: 75.0000 (77.8534)  Acc@5: 100.0000 (98.6460)  time: 0.3483  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [2460/3750]  eta: 0:07:32  Lr: 0.001875  Loss: -0.4692  Acc@1: 75.0000 (77.8545)  Acc@5: 100.0000 (98.6515)  time: 0.3481  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [2470/3750]  eta: 0:07:28  Lr: 0.001875  Loss: -0.4443  Acc@1: 81.2500 (77.8607)  Acc@5: 100.0000 (98.6493)  time: 0.3486  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [2480/3750]  eta: 0:07:25  Lr: 0.001875  Loss: -0.6189  Acc@1: 81.2500 (77.8567)  Acc@5: 100.0000 (98.6523)  time: 0.3477  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [2490/3750]  eta: 0:07:21  Lr: 0.001875  Loss: -0.4148  Acc@1: 75.0000 (77.8478)  Acc@5: 100.0000 (98.6526)  time: 0.3455  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [2500/3750]  eta: 0:07:18  Lr: 0.001875  Loss: -0.6734  Acc@1: 75.0000 (77.8639)  Acc@5: 100.0000 (98.6580)  time: 0.3472  data: 0.0013  max mem: 2503
Train: Epoch[2/5]  [2510/3750]  eta: 0:07:14  Lr: 0.001875  Loss: -0.4353  Acc@1: 81.2500 (77.8599)  Acc@5: 100.0000 (98.6609)  time: 0.3509  data: 0.0022  max mem: 2503
Train: Epoch[2/5]  [2520/3750]  eta: 0:07:11  Lr: 0.001875  Loss: -0.4800  Acc@1: 75.0000 (77.8312)  Acc@5: 100.0000 (98.6513)  time: 0.3505  data: 0.0014  max mem: 2503
Train: Epoch[2/5]  [2530/3750]  eta: 0:07:07  Lr: 0.001875  Loss: -0.1945  Acc@1: 68.7500 (77.7978)  Acc@5: 100.0000 (98.6542)  time: 0.3484  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [2540/3750]  eta: 0:07:04  Lr: 0.001875  Loss: -0.8865  Acc@1: 75.0000 (77.8114)  Acc@5: 100.0000 (98.6546)  time: 0.3488  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [2550/3750]  eta: 0:07:00  Lr: 0.001875  Loss: -0.6505  Acc@1: 81.2500 (77.8445)  Acc@5: 100.0000 (98.6598)  time: 0.3557  data: 0.0025  max mem: 2503
Train: Epoch[2/5]  [2560/3750]  eta: 0:06:57  Lr: 0.001875  Loss: -0.8913  Acc@1: 81.2500 (77.8334)  Acc@5: 100.0000 (98.6529)  time: 0.3556  data: 0.0025  max mem: 2503
Train: Epoch[2/5]  [2570/3750]  eta: 0:06:53  Lr: 0.001875  Loss: -0.9640  Acc@1: 75.0000 (77.8515)  Acc@5: 100.0000 (98.6581)  time: 0.3500  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [2580/3750]  eta: 0:06:50  Lr: 0.001875  Loss: -0.6108  Acc@1: 81.2500 (77.8453)  Acc@5: 100.0000 (98.6585)  time: 0.3500  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [2590/3750]  eta: 0:06:46  Lr: 0.001875  Loss: -0.4759  Acc@1: 75.0000 (77.8488)  Acc@5: 100.0000 (98.6612)  time: 0.3528  data: 0.0015  max mem: 2503
Train: Epoch[2/5]  [2600/3750]  eta: 0:06:43  Lr: 0.001875  Loss: -0.2554  Acc@1: 68.7500 (77.8354)  Acc@5: 100.0000 (98.6640)  time: 0.3532  data: 0.0016  max mem: 2503
Train: Epoch[2/5]  [2610/3750]  eta: 0:06:39  Lr: 0.001875  Loss: -0.5937  Acc@1: 68.7500 (77.8222)  Acc@5: 100.0000 (98.6643)  time: 0.3500  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [2620/3750]  eta: 0:06:36  Lr: 0.001875  Loss: -0.4067  Acc@1: 75.0000 (77.8377)  Acc@5: 100.0000 (98.6670)  time: 0.3503  data: 0.0006  max mem: 2503
Train: Epoch[2/5]  [2630/3750]  eta: 0:06:32  Lr: 0.001875  Loss: -1.0368  Acc@1: 81.2500 (77.8601)  Acc@5: 100.0000 (98.6626)  time: 0.3510  data: 0.0006  max mem: 2503
Train: Epoch[2/5]  [2640/3750]  eta: 0:06:29  Lr: 0.001875  Loss: -0.6551  Acc@1: 81.2500 (77.8682)  Acc@5: 100.0000 (98.6676)  time: 0.3508  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [2650/3750]  eta: 0:06:25  Lr: 0.001875  Loss: -0.8249  Acc@1: 75.0000 (77.8668)  Acc@5: 100.0000 (98.6703)  time: 0.3483  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [2660/3750]  eta: 0:06:22  Lr: 0.001875  Loss: -0.3687  Acc@1: 75.0000 (77.8631)  Acc@5: 100.0000 (98.6706)  time: 0.3460  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [2670/3750]  eta: 0:06:18  Lr: 0.001875  Loss: -0.8269  Acc@1: 81.2500 (77.8594)  Acc@5: 100.0000 (98.6686)  time: 0.3459  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [2680/3750]  eta: 0:06:14  Lr: 0.001875  Loss: -0.3613  Acc@1: 81.2500 (77.8604)  Acc@5: 100.0000 (98.6689)  time: 0.3476  data: 0.0007  max mem: 2503
Train: Epoch[2/5]  [2690/3750]  eta: 0:06:11  Lr: 0.001875  Loss: -0.8431  Acc@1: 81.2500 (77.8567)  Acc@5: 100.0000 (98.6622)  time: 0.3473  data: 0.0007  max mem: 2503
Train: Epoch[2/5]  [2700/3750]  eta: 0:06:07  Lr: 0.001875  Loss: -0.1529  Acc@1: 75.0000 (77.8554)  Acc@5: 100.0000 (98.6556)  time: 0.3464  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [2710/3750]  eta: 0:06:04  Lr: 0.001875  Loss: -0.7302  Acc@1: 75.0000 (77.8610)  Acc@5: 100.0000 (98.6605)  time: 0.3479  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [2720/3750]  eta: 0:06:00  Lr: 0.001875  Loss: -0.8294  Acc@1: 81.2500 (77.8735)  Acc@5: 100.0000 (98.6632)  time: 0.3528  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [2730/3750]  eta: 0:05:57  Lr: 0.001875  Loss: -0.4323  Acc@1: 81.2500 (77.8767)  Acc@5: 100.0000 (98.6635)  time: 0.3546  data: 0.0006  max mem: 2503
Train: Epoch[2/5]  [2740/3750]  eta: 0:05:53  Lr: 0.001875  Loss: -0.9451  Acc@1: 75.0000 (77.8639)  Acc@5: 100.0000 (98.6638)  time: 0.3501  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [2750/3750]  eta: 0:05:50  Lr: 0.001875  Loss: -0.4952  Acc@1: 75.0000 (77.8626)  Acc@5: 100.0000 (98.6641)  time: 0.3496  data: 0.0006  max mem: 2503
Train: Epoch[2/5]  [2760/3750]  eta: 0:05:46  Lr: 0.001875  Loss: -0.4654  Acc@1: 81.2500 (77.8749)  Acc@5: 100.0000 (98.6644)  time: 0.3535  data: 0.0007  max mem: 2503
Train: Epoch[2/5]  [2770/3750]  eta: 0:05:43  Lr: 0.001875  Loss: -0.4892  Acc@1: 75.0000 (77.8758)  Acc@5: 100.0000 (98.6647)  time: 0.3554  data: 0.0007  max mem: 2503
Train: Epoch[2/5]  [2780/3750]  eta: 0:05:39  Lr: 0.001875  Loss: -0.4157  Acc@1: 81.2500 (77.8857)  Acc@5: 100.0000 (98.6628)  time: 0.3538  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [2790/3750]  eta: 0:05:36  Lr: 0.001875  Loss: -0.9978  Acc@1: 75.0000 (77.8955)  Acc@5: 100.0000 (98.6564)  time: 0.3501  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [2800/3750]  eta: 0:05:32  Lr: 0.001875  Loss: -0.1795  Acc@1: 75.0000 (77.9097)  Acc@5: 100.0000 (98.6590)  time: 0.3522  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [2810/3750]  eta: 0:05:29  Lr: 0.001875  Loss: -0.7364  Acc@1: 81.2500 (77.9238)  Acc@5: 100.0000 (98.6571)  time: 0.3556  data: 0.0008  max mem: 2503
Train: Epoch[2/5]  [2820/3750]  eta: 0:05:25  Lr: 0.001875  Loss: -0.4861  Acc@1: 81.2500 (77.9289)  Acc@5: 100.0000 (98.6530)  time: 0.3520  data: 0.0009  max mem: 2503
Train: Epoch[2/5]  [2830/3750]  eta: 0:05:22  Lr: 0.001875  Loss: -0.4838  Acc@1: 81.2500 (77.9384)  Acc@5: 100.0000 (98.6577)  time: 0.3490  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [2840/3750]  eta: 0:05:18  Lr: 0.001875  Loss: -0.7090  Acc@1: 87.5000 (77.9501)  Acc@5: 100.0000 (98.6602)  time: 0.3485  data: 0.0007  max mem: 2503
Train: Epoch[2/5]  [2850/3750]  eta: 0:05:15  Lr: 0.001875  Loss: -0.2141  Acc@1: 75.0000 (77.9310)  Acc@5: 100.0000 (98.6627)  time: 0.3503  data: 0.0007  max mem: 2503
Train: Epoch[2/5]  [2860/3750]  eta: 0:05:11  Lr: 0.001875  Loss: -0.8957  Acc@1: 75.0000 (77.9448)  Acc@5: 100.0000 (98.6652)  time: 0.3493  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [2870/3750]  eta: 0:05:08  Lr: 0.001875  Loss: -0.7958  Acc@1: 81.2500 (77.9650)  Acc@5: 100.0000 (98.6655)  time: 0.3472  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [2880/3750]  eta: 0:05:04  Lr: 0.001875  Loss: -0.6994  Acc@1: 81.2500 (77.9504)  Acc@5: 100.0000 (98.6680)  time: 0.3498  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [2890/3750]  eta: 0:05:01  Lr: 0.001875  Loss: -0.0968  Acc@1: 75.0000 (77.9315)  Acc@5: 100.0000 (98.6704)  time: 0.3591  data: 0.0013  max mem: 2503
Train: Epoch[2/5]  [2900/3750]  eta: 0:04:57  Lr: 0.001875  Loss: -0.8526  Acc@1: 68.7500 (77.9128)  Acc@5: 100.0000 (98.6664)  time: 0.3583  data: 0.0012  max mem: 2503
Train: Epoch[2/5]  [2910/3750]  eta: 0:04:54  Lr: 0.001875  Loss: -0.6265  Acc@1: 68.7500 (77.9071)  Acc@5: 100.0000 (98.6645)  time: 0.3512  data: 0.0006  max mem: 2503
Train: Epoch[2/5]  [2920/3750]  eta: 0:04:50  Lr: 0.001875  Loss: -0.3809  Acc@1: 75.0000 (77.9014)  Acc@5: 100.0000 (98.6670)  time: 0.3540  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [2930/3750]  eta: 0:04:47  Lr: 0.001875  Loss: -0.8519  Acc@1: 75.0000 (77.8872)  Acc@5: 100.0000 (98.6651)  time: 0.3564  data: 0.0008  max mem: 2503
Train: Epoch[2/5]  [2940/3750]  eta: 0:04:43  Lr: 0.001875  Loss: -0.8854  Acc@1: 81.2500 (77.9263)  Acc@5: 100.0000 (98.6697)  time: 0.3537  data: 0.0010  max mem: 2503
Train: Epoch[2/5]  [2950/3750]  eta: 0:04:40  Lr: 0.001875  Loss: -0.3618  Acc@1: 81.2500 (77.9312)  Acc@5: 100.0000 (98.6636)  time: 0.3501  data: 0.0007  max mem: 2503
Train: Epoch[2/5]  [2960/3750]  eta: 0:04:36  Lr: 0.001875  Loss: -0.0839  Acc@1: 75.0000 (77.9065)  Acc@5: 100.0000 (98.6618)  time: 0.3497  data: 0.0006  max mem: 2503
Train: Epoch[2/5]  [2970/3750]  eta: 0:04:33  Lr: 0.001875  Loss: -0.7034  Acc@1: 75.0000 (77.9262)  Acc@5: 100.0000 (98.6621)  time: 0.3558  data: 0.0027  max mem: 2503
Train: Epoch[2/5]  [2980/3750]  eta: 0:04:29  Lr: 0.001875  Loss: -0.4253  Acc@1: 75.0000 (77.9248)  Acc@5: 100.0000 (98.6561)  time: 0.3564  data: 0.0026  max mem: 2503
Train: Epoch[2/5]  [2990/3750]  eta: 0:04:26  Lr: 0.001875  Loss: -0.4326  Acc@1: 81.2500 (77.9234)  Acc@5: 100.0000 (98.6522)  time: 0.3532  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [3000/3750]  eta: 0:04:22  Lr: 0.001875  Loss: -0.4889  Acc@1: 81.2500 (77.9157)  Acc@5: 100.0000 (98.6567)  time: 0.3529  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [3010/3750]  eta: 0:04:19  Lr: 0.001875  Loss: -0.7507  Acc@1: 81.2500 (77.9351)  Acc@5: 100.0000 (98.6591)  time: 0.3521  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [3020/3750]  eta: 0:04:15  Lr: 0.001875  Loss: -0.6254  Acc@1: 81.2500 (77.9378)  Acc@5: 100.0000 (98.6615)  time: 0.3518  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [3030/3750]  eta: 0:04:12  Lr: 0.001875  Loss: -0.3807  Acc@1: 81.2500 (77.9425)  Acc@5: 100.0000 (98.6576)  time: 0.3482  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [3040/3750]  eta: 0:04:08  Lr: 0.001875  Loss: -0.6735  Acc@1: 75.0000 (77.9308)  Acc@5: 100.0000 (98.6559)  time: 0.3475  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [3050/3750]  eta: 0:04:05  Lr: 0.001875  Loss: -0.7988  Acc@1: 81.2500 (77.9314)  Acc@5: 100.0000 (98.6562)  time: 0.3513  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [3060/3750]  eta: 0:04:01  Lr: 0.001875  Loss: -0.8396  Acc@1: 81.2500 (77.9218)  Acc@5: 100.0000 (98.6585)  time: 0.3508  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [3070/3750]  eta: 0:03:58  Lr: 0.001875  Loss: -0.7740  Acc@1: 68.7500 (77.9062)  Acc@5: 100.0000 (98.6548)  time: 0.3496  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [3080/3750]  eta: 0:03:54  Lr: 0.001875  Loss: -0.3904  Acc@1: 75.0000 (77.9008)  Acc@5: 100.0000 (98.6591)  time: 0.3510  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [3090/3750]  eta: 0:03:51  Lr: 0.001875  Loss: -0.5822  Acc@1: 75.0000 (77.8975)  Acc@5: 100.0000 (98.6594)  time: 0.3558  data: 0.0019  max mem: 2503
Train: Epoch[2/5]  [3100/3750]  eta: 0:03:47  Lr: 0.001875  Loss: -0.8015  Acc@1: 75.0000 (77.9063)  Acc@5: 100.0000 (98.6516)  time: 0.3568  data: 0.0019  max mem: 2503
Train: Epoch[2/5]  [3110/3750]  eta: 0:03:44  Lr: 0.001875  Loss: -0.4736  Acc@1: 75.0000 (77.9090)  Acc@5: 100.0000 (98.6540)  time: 0.3517  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [3120/3750]  eta: 0:03:40  Lr: 0.001875  Loss: -0.6817  Acc@1: 81.2500 (77.9137)  Acc@5: 100.0000 (98.6583)  time: 0.3512  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [3130/3750]  eta: 0:03:37  Lr: 0.001875  Loss: -0.6332  Acc@1: 81.2500 (77.9064)  Acc@5: 100.0000 (98.6566)  time: 0.3565  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [3140/3750]  eta: 0:03:33  Lr: 0.001875  Loss: -0.6504  Acc@1: 81.2500 (77.8992)  Acc@5: 100.0000 (98.6569)  time: 0.3590  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [3150/3750]  eta: 0:03:30  Lr: 0.001875  Loss: -0.8477  Acc@1: 75.0000 (77.9038)  Acc@5: 100.0000 (98.6572)  time: 0.3535  data: 0.0006  max mem: 2503
Train: Epoch[2/5]  [3160/3750]  eta: 0:03:26  Lr: 0.001875  Loss: -0.6416  Acc@1: 81.2500 (77.9045)  Acc@5: 100.0000 (98.6594)  time: 0.3506  data: 0.0006  max mem: 2503
Train: Epoch[2/5]  [3170/3750]  eta: 0:03:23  Lr: 0.001875  Loss: -0.6402  Acc@1: 81.2500 (77.9072)  Acc@5: 100.0000 (98.6637)  time: 0.3497  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [3180/3750]  eta: 0:03:19  Lr: 0.001875  Loss: -0.9105  Acc@1: 75.0000 (77.9079)  Acc@5: 100.0000 (98.6620)  time: 0.3547  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [3190/3750]  eta: 0:03:16  Lr: 0.001875  Loss: -0.0552  Acc@1: 81.2500 (77.9144)  Acc@5: 100.0000 (98.6583)  time: 0.3550  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [3200/3750]  eta: 0:03:12  Lr: 0.001875  Loss: -0.3021  Acc@1: 81.2500 (77.9112)  Acc@5: 100.0000 (98.6606)  time: 0.3495  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [3210/3750]  eta: 0:03:09  Lr: 0.001875  Loss: -0.5731  Acc@1: 75.0000 (77.9197)  Acc@5: 100.0000 (98.6609)  time: 0.3488  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [3220/3750]  eta: 0:03:05  Lr: 0.001875  Loss: -0.6715  Acc@1: 81.2500 (77.9339)  Acc@5: 100.0000 (98.6631)  time: 0.3490  data: 0.0010  max mem: 2503
Train: Epoch[2/5]  [3230/3750]  eta: 0:03:02  Lr: 0.001875  Loss: -0.7159  Acc@1: 75.0000 (77.9287)  Acc@5: 100.0000 (98.6633)  time: 0.3487  data: 0.0010  max mem: 2503
Train: Epoch[2/5]  [3240/3750]  eta: 0:02:58  Lr: 0.001875  Loss: -0.8547  Acc@1: 75.0000 (77.9351)  Acc@5: 100.0000 (98.6655)  time: 0.3472  data: 0.0002  max mem: 2503
Train: Epoch[2/5]  [3250/3750]  eta: 0:02:55  Lr: 0.001875  Loss: -0.7810  Acc@1: 75.0000 (77.9279)  Acc@5: 100.0000 (98.6677)  time: 0.3521  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [3260/3750]  eta: 0:02:51  Lr: 0.001875  Loss: -0.2405  Acc@1: 81.2500 (77.9343)  Acc@5: 100.0000 (98.6699)  time: 0.3585  data: 0.0009  max mem: 2503
Train: Epoch[2/5]  [3270/3750]  eta: 0:02:48  Lr: 0.001875  Loss: -0.7997  Acc@1: 81.2500 (77.9444)  Acc@5: 100.0000 (98.6682)  time: 0.3570  data: 0.0009  max mem: 2503
Train: Epoch[2/5]  [3280/3750]  eta: 0:02:44  Lr: 0.001875  Loss: -0.7572  Acc@1: 75.0000 (77.9336)  Acc@5: 100.0000 (98.6685)  time: 0.3542  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [3290/3750]  eta: 0:02:41  Lr: 0.001875  Loss: -1.0263  Acc@1: 75.0000 (77.9322)  Acc@5: 100.0000 (98.6687)  time: 0.3518  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [3300/3750]  eta: 0:02:37  Lr: 0.001875  Loss: -0.9382  Acc@1: 75.0000 (77.9290)  Acc@5: 100.0000 (98.6633)  time: 0.3551  data: 0.0014  max mem: 2503
Train: Epoch[2/5]  [3310/3750]  eta: 0:02:34  Lr: 0.001875  Loss: -0.9248  Acc@1: 75.0000 (77.9296)  Acc@5: 100.0000 (98.6635)  time: 0.3592  data: 0.0014  max mem: 2503
Train: Epoch[2/5]  [3320/3750]  eta: 0:02:30  Lr: 0.001875  Loss: -0.5482  Acc@1: 81.2500 (77.9340)  Acc@5: 100.0000 (98.6676)  time: 0.3539  data: 0.0006  max mem: 2503
Train: Epoch[2/5]  [3330/3750]  eta: 0:02:27  Lr: 0.001875  Loss: -0.9257  Acc@1: 81.2500 (77.9421)  Acc@5: 100.0000 (98.6659)  time: 0.3504  data: 0.0006  max mem: 2503
Train: Epoch[2/5]  [3340/3750]  eta: 0:02:23  Lr: 0.001875  Loss: -0.3341  Acc@1: 81.2500 (77.9407)  Acc@5: 100.0000 (98.6699)  time: 0.3510  data: 0.0006  max mem: 2503
Train: Epoch[2/5]  [3350/3750]  eta: 0:02:20  Lr: 0.001875  Loss: -0.6318  Acc@1: 75.0000 (77.9338)  Acc@5: 100.0000 (98.6702)  time: 0.3513  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [3360/3750]  eta: 0:02:16  Lr: 0.001875  Loss: -0.8451  Acc@1: 75.0000 (77.9363)  Acc@5: 100.0000 (98.6686)  time: 0.3503  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [3370/3750]  eta: 0:02:13  Lr: 0.001875  Loss: -1.0367  Acc@1: 81.2500 (77.9535)  Acc@5: 100.0000 (98.6688)  time: 0.3488  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [3380/3750]  eta: 0:02:09  Lr: 0.001875  Loss: -0.8733  Acc@1: 87.5000 (77.9669)  Acc@5: 100.0000 (98.6653)  time: 0.3493  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [3390/3750]  eta: 0:02:06  Lr: 0.001875  Loss: -0.7942  Acc@1: 81.2500 (77.9674)  Acc@5: 100.0000 (98.6693)  time: 0.3530  data: 0.0007  max mem: 2503
Train: Epoch[2/5]  [3400/3750]  eta: 0:02:02  Lr: 0.001875  Loss: -0.8466  Acc@1: 75.0000 (77.9660)  Acc@5: 100.0000 (98.6713)  time: 0.3517  data: 0.0007  max mem: 2503
Train: Epoch[2/5]  [3410/3750]  eta: 0:01:59  Lr: 0.001875  Loss: -0.6219  Acc@1: 75.0000 (77.9592)  Acc@5: 100.0000 (98.6697)  time: 0.3469  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [3420/3750]  eta: 0:01:55  Lr: 0.001875  Loss: -0.7070  Acc@1: 81.2500 (77.9761)  Acc@5: 100.0000 (98.6736)  time: 0.3463  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [3430/3750]  eta: 0:01:52  Lr: 0.001875  Loss: -0.2773  Acc@1: 81.2500 (77.9948)  Acc@5: 100.0000 (98.6757)  time: 0.3501  data: 0.0012  max mem: 2503
Train: Epoch[2/5]  [3440/3750]  eta: 0:01:48  Lr: 0.001875  Loss: -0.9689  Acc@1: 81.2500 (78.0097)  Acc@5: 100.0000 (98.6741)  time: 0.3510  data: 0.0012  max mem: 2503
Train: Epoch[2/5]  [3450/3750]  eta: 0:01:45  Lr: 0.001875  Loss: -0.6170  Acc@1: 75.0000 (77.9937)  Acc@5: 100.0000 (98.6743)  time: 0.3496  data: 0.0008  max mem: 2503
Train: Epoch[2/5]  [3460/3750]  eta: 0:01:41  Lr: 0.001875  Loss: -0.5660  Acc@1: 75.0000 (77.9995)  Acc@5: 100.0000 (98.6781)  time: 0.3498  data: 0.0009  max mem: 2503
Train: Epoch[2/5]  [3470/3750]  eta: 0:01:38  Lr: 0.001875  Loss: -0.7569  Acc@1: 81.2500 (77.9963)  Acc@5: 100.0000 (98.6765)  time: 0.3526  data: 0.0009  max mem: 2503
Train: Epoch[2/5]  [3480/3750]  eta: 0:01:34  Lr: 0.001875  Loss: -0.3500  Acc@1: 81.2500 (78.0020)  Acc@5: 100.0000 (98.6749)  time: 0.3550  data: 0.0016  max mem: 2503
Train: Epoch[2/5]  [3490/3750]  eta: 0:01:31  Lr: 0.001875  Loss: -0.3630  Acc@1: 81.2500 (78.0059)  Acc@5: 100.0000 (98.6734)  time: 0.3518  data: 0.0013  max mem: 2503
Train: Epoch[2/5]  [3500/3750]  eta: 0:01:27  Lr: 0.001875  Loss: -0.8296  Acc@1: 81.2500 (78.0099)  Acc@5: 100.0000 (98.6772)  time: 0.3507  data: 0.0006  max mem: 2503
Train: Epoch[2/5]  [3510/3750]  eta: 0:01:24  Lr: 0.001875  Loss: -0.4826  Acc@1: 75.0000 (78.0173)  Acc@5: 100.0000 (98.6792)  time: 0.3542  data: 0.0006  max mem: 2503
Train: Epoch[2/5]  [3520/3750]  eta: 0:01:20  Lr: 0.001875  Loss: -0.2272  Acc@1: 75.0000 (78.0158)  Acc@5: 100.0000 (98.6811)  time: 0.3566  data: 0.0019  max mem: 2503
Train: Epoch[2/5]  [3530/3750]  eta: 0:01:17  Lr: 0.001875  Loss: -0.6898  Acc@1: 75.0000 (78.0338)  Acc@5: 100.0000 (98.6813)  time: 0.3530  data: 0.0018  max mem: 2503
Train: Epoch[2/5]  [3540/3750]  eta: 0:01:13  Lr: 0.001875  Loss: -0.5249  Acc@1: 81.2500 (78.0500)  Acc@5: 100.0000 (98.6833)  time: 0.3502  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [3550/3750]  eta: 0:01:10  Lr: 0.001875  Loss: -0.8142  Acc@1: 81.2500 (78.0484)  Acc@5: 100.0000 (98.6835)  time: 0.3514  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [3560/3750]  eta: 0:01:06  Lr: 0.001875  Loss: -0.8105  Acc@1: 81.2500 (78.0539)  Acc@5: 100.0000 (98.6801)  time: 0.3511  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [3570/3750]  eta: 0:01:03  Lr: 0.001875  Loss: -0.4770  Acc@1: 81.2500 (78.0611)  Acc@5: 100.0000 (98.6838)  time: 0.3496  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [3580/3750]  eta: 0:00:59  Lr: 0.001875  Loss: -0.3816  Acc@1: 75.0000 (78.0561)  Acc@5: 100.0000 (98.6840)  time: 0.3485  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [3590/3750]  eta: 0:00:56  Lr: 0.001875  Loss: -0.7008  Acc@1: 81.2500 (78.0684)  Acc@5: 100.0000 (98.6877)  time: 0.3473  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [3600/3750]  eta: 0:00:52  Lr: 0.001875  Loss: -0.9007  Acc@1: 81.2500 (78.0686)  Acc@5: 100.0000 (98.6896)  time: 0.3477  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [3610/3750]  eta: 0:00:49  Lr: 0.001875  Loss: -0.4951  Acc@1: 81.2500 (78.0757)  Acc@5: 100.0000 (98.6898)  time: 0.3479  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [3620/3750]  eta: 0:00:45  Lr: 0.001875  Loss: -0.7657  Acc@1: 81.2500 (78.0896)  Acc@5: 100.0000 (98.6917)  time: 0.3473  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [3630/3750]  eta: 0:00:42  Lr: 0.001875  Loss: -0.5034  Acc@1: 81.2500 (78.0777)  Acc@5: 100.0000 (98.6953)  time: 0.3522  data: 0.0009  max mem: 2503
Train: Epoch[2/5]  [3640/3750]  eta: 0:00:38  Lr: 0.001875  Loss: -0.5649  Acc@1: 75.0000 (78.0761)  Acc@5: 100.0000 (98.6885)  time: 0.3569  data: 0.0021  max mem: 2503
Train: Epoch[2/5]  [3650/3750]  eta: 0:00:35  Lr: 0.001875  Loss: -0.6662  Acc@1: 75.0000 (78.0677)  Acc@5: 100.0000 (98.6921)  time: 0.3538  data: 0.0016  max mem: 2503
Train: Epoch[2/5]  [3660/3750]  eta: 0:00:31  Lr: 0.001875  Loss: -0.5674  Acc@1: 75.0000 (78.0576)  Acc@5: 100.0000 (98.6957)  time: 0.3511  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [3670/3750]  eta: 0:00:28  Lr: 0.001875  Loss: -0.8006  Acc@1: 75.0000 (78.0526)  Acc@5: 100.0000 (98.6976)  time: 0.3520  data: 0.0006  max mem: 2503
Train: Epoch[2/5]  [3680/3750]  eta: 0:00:24  Lr: 0.001875  Loss: -0.9171  Acc@1: 75.0000 (78.0630)  Acc@5: 100.0000 (98.6960)  time: 0.3557  data: 0.0006  max mem: 2503
Train: Epoch[2/5]  [3690/3750]  eta: 0:00:21  Lr: 0.001875  Loss: -0.0072  Acc@1: 81.2500 (78.0666)  Acc@5: 100.0000 (98.6995)  time: 0.3541  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [3700/3750]  eta: 0:00:17  Lr: 0.001875  Loss: -0.4938  Acc@1: 81.2500 (78.0752)  Acc@5: 100.0000 (98.6946)  time: 0.3503  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [3710/3750]  eta: 0:00:14  Lr: 0.001875  Loss: -0.5358  Acc@1: 81.2500 (78.0837)  Acc@5: 100.0000 (98.6948)  time: 0.3494  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [3720/3750]  eta: 0:00:10  Lr: 0.001875  Loss: -0.6114  Acc@1: 81.2500 (78.0788)  Acc@5: 100.0000 (98.6949)  time: 0.3499  data: 0.0011  max mem: 2503
Train: Epoch[2/5]  [3730/3750]  eta: 0:00:07  Lr: 0.001875  Loss: -0.8649  Acc@1: 81.2500 (78.0840)  Acc@5: 100.0000 (98.6917)  time: 0.3509  data: 0.0013  max mem: 2503
Train: Epoch[2/5]  [3740/3750]  eta: 0:00:03  Lr: 0.001875  Loss: -0.6679  Acc@1: 81.2500 (78.0841)  Acc@5: 100.0000 (98.6935)  time: 0.3495  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [3749/3750]  eta: 0:00:00  Lr: 0.001875  Loss: -0.8789  Acc@1: 81.2500 (78.0883)  Acc@5: 100.0000 (98.6883)  time: 0.3491  data: 0.0008  max mem: 2503
Train: Epoch[2/5] Total time: 0:21:56 (0.3510 s / it)
{0: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 1: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 2: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 3: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 4: {0: 0, 1: 300000, 2: 0, 3: 91325, 4: 0}, 5: {0: 0, 1: 300000, 2: 0, 3: 91325, 4: 0}, 6: {0: 0, 1: 300000, 2: 0, 3: 91325, 4: 0}, 7: {0: 0, 1: 300000, 2: 0, 3: 91325, 4: 0}, 8: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 9: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 10: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 11: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 12: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 13: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 14: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 15: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 16: {0: 0, 1: 0, 2: 0, 3: 0, 4: 120000}, 17: {0: 0, 1: 0, 2: 0, 3: 0, 4: 120000}, 18: {0: 0, 1: 0, 2: 0, 3: 0, 4: 120000}, 19: {0: 0, 1: 0, 2: 0, 3: 0, 4: 120000}}
Averaged stats: Lr: 0.001875  Loss: -0.8789  Acc@1: 81.2500 (78.0883)  Acc@5: 100.0000 (98.6883)
Train: Epoch[3/5]  [   0/3750]  eta: 0:41:09  Lr: 0.001875  Loss: -1.0149  Acc@1: 93.7500 (93.7500)  Acc@5: 100.0000 (100.0000)  time: 0.6585  data: 0.3127  max mem: 2503
Train: Epoch[3/5]  [  10/3750]  eta: 0:23:33  Lr: 0.001875  Loss: -0.2052  Acc@1: 81.2500 (79.5455)  Acc@5: 100.0000 (98.8636)  time: 0.3778  data: 0.0287  max mem: 2503
Train: Epoch[3/5]  [  20/3750]  eta: 0:22:35  Lr: 0.001875  Loss: -0.5256  Acc@1: 75.0000 (78.2738)  Acc@5: 100.0000 (99.1071)  time: 0.3486  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [  30/3750]  eta: 0:22:10  Lr: 0.001875  Loss: -0.5463  Acc@1: 75.0000 (78.0242)  Acc@5: 100.0000 (98.7903)  time: 0.3466  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [  40/3750]  eta: 0:21:56  Lr: 0.001875  Loss: -0.3739  Acc@1: 75.0000 (78.0488)  Acc@5: 100.0000 (98.6280)  time: 0.3462  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [  50/3750]  eta: 0:21:56  Lr: 0.001875  Loss: -0.6987  Acc@1: 75.0000 (77.5735)  Acc@5: 100.0000 (98.7745)  time: 0.3526  data: 0.0014  max mem: 2503
Train: Epoch[3/5]  [  60/3750]  eta: 0:21:49  Lr: 0.001875  Loss: -0.8985  Acc@1: 75.0000 (77.3566)  Acc@5: 100.0000 (98.8730)  time: 0.3548  data: 0.0015  max mem: 2503
Train: Epoch[3/5]  [  70/3750]  eta: 0:21:42  Lr: 0.001875  Loss: -0.8159  Acc@1: 81.2500 (77.6408)  Acc@5: 100.0000 (98.9437)  time: 0.3499  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [  80/3750]  eta: 0:21:38  Lr: 0.001875  Loss: -0.5278  Acc@1: 75.0000 (77.5463)  Acc@5: 100.0000 (98.9198)  time: 0.3504  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [  90/3750]  eta: 0:21:37  Lr: 0.001875  Loss: -0.8630  Acc@1: 81.2500 (78.0907)  Acc@5: 100.0000 (98.8324)  time: 0.3558  data: 0.0007  max mem: 2503
Train: Epoch[3/5]  [ 100/3750]  eta: 0:21:34  Lr: 0.001875  Loss: -0.8075  Acc@1: 87.5000 (78.4653)  Acc@5: 100.0000 (98.8243)  time: 0.3586  data: 0.0019  max mem: 2503
Train: Epoch[3/5]  [ 110/3750]  eta: 0:21:29  Lr: 0.001875  Loss: -0.3072  Acc@1: 81.2500 (78.2658)  Acc@5: 100.0000 (98.7613)  time: 0.3542  data: 0.0018  max mem: 2503
Train: Epoch[3/5]  [ 120/3750]  eta: 0:21:24  Lr: 0.001875  Loss: -0.7604  Acc@1: 81.2500 (78.8740)  Acc@5: 100.0000 (98.8636)  time: 0.3498  data: 0.0008  max mem: 2503
Train: Epoch[3/5]  [ 130/3750]  eta: 0:21:20  Lr: 0.001875  Loss: -0.4429  Acc@1: 81.2500 (78.5782)  Acc@5: 100.0000 (98.8550)  time: 0.3499  data: 0.0007  max mem: 2503
Train: Epoch[3/5]  [ 140/3750]  eta: 0:21:16  Lr: 0.001875  Loss: -0.9456  Acc@1: 81.2500 (78.9894)  Acc@5: 100.0000 (98.8918)  time: 0.3521  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [ 150/3750]  eta: 0:21:12  Lr: 0.001875  Loss: -0.7437  Acc@1: 81.2500 (78.9321)  Acc@5: 100.0000 (98.9238)  time: 0.3519  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [ 160/3750]  eta: 0:21:07  Lr: 0.001875  Loss: -0.8670  Acc@1: 75.0000 (79.1537)  Acc@5: 100.0000 (98.9519)  time: 0.3497  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [ 170/3750]  eta: 0:21:03  Lr: 0.001875  Loss: -0.5804  Acc@1: 75.0000 (78.8012)  Acc@5: 100.0000 (98.9401)  time: 0.3490  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [ 180/3750]  eta: 0:21:00  Lr: 0.001875  Loss: -0.6878  Acc@1: 75.0000 (78.5912)  Acc@5: 100.0000 (98.9296)  time: 0.3510  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [ 190/3750]  eta: 0:20:56  Lr: 0.001875  Loss: -0.3777  Acc@1: 75.0000 (78.5668)  Acc@5: 100.0000 (98.9202)  time: 0.3518  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [ 200/3750]  eta: 0:20:51  Lr: 0.001875  Loss: -0.7946  Acc@1: 81.2500 (78.3893)  Acc@5: 100.0000 (98.9117)  time: 0.3478  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [ 210/3750]  eta: 0:20:46  Lr: 0.001875  Loss: -0.5476  Acc@1: 75.0000 (78.1694)  Acc@5: 100.0000 (98.8744)  time: 0.3461  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [ 220/3750]  eta: 0:20:42  Lr: 0.001875  Loss: -0.7297  Acc@1: 75.0000 (78.1109)  Acc@5: 100.0000 (98.8122)  time: 0.3482  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [ 230/3750]  eta: 0:20:38  Lr: 0.001875  Loss: -0.3847  Acc@1: 75.0000 (78.1656)  Acc@5: 100.0000 (98.8366)  time: 0.3489  data: 0.0007  max mem: 2503
Train: Epoch[3/5]  [ 240/3750]  eta: 0:20:34  Lr: 0.001875  Loss: -0.9600  Acc@1: 75.0000 (78.3195)  Acc@5: 100.0000 (98.8330)  time: 0.3485  data: 0.0007  max mem: 2503
Train: Epoch[3/5]  [ 250/3750]  eta: 0:20:31  Lr: 0.001875  Loss: -0.2219  Acc@1: 75.0000 (78.1873)  Acc@5: 100.0000 (98.8297)  time: 0.3517  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [ 260/3750]  eta: 0:20:29  Lr: 0.001875  Loss: -0.5937  Acc@1: 75.0000 (78.2328)  Acc@5: 100.0000 (98.8506)  time: 0.3595  data: 0.0006  max mem: 2503
Train: Epoch[3/5]  [ 270/3750]  eta: 0:20:26  Lr: 0.001875  Loss: -0.6150  Acc@1: 81.2500 (78.1596)  Acc@5: 100.0000 (98.8469)  time: 0.3590  data: 0.0006  max mem: 2503
Train: Epoch[3/5]  [ 280/3750]  eta: 0:20:22  Lr: 0.001875  Loss: -0.8236  Acc@1: 81.2500 (78.2696)  Acc@5: 100.0000 (98.8212)  time: 0.3530  data: 0.0006  max mem: 2503
Train: Epoch[3/5]  [ 290/3750]  eta: 0:20:19  Lr: 0.001875  Loss: -0.5753  Acc@1: 75.0000 (78.2431)  Acc@5: 100.0000 (98.8402)  time: 0.3523  data: 0.0007  max mem: 2503
Train: Epoch[3/5]  [ 300/3750]  eta: 0:20:15  Lr: 0.001875  Loss: -0.7130  Acc@1: 75.0000 (78.3015)  Acc@5: 100.0000 (98.8580)  time: 0.3519  data: 0.0007  max mem: 2503
Train: Epoch[3/5]  [ 310/3750]  eta: 0:20:11  Lr: 0.001875  Loss: -0.9471  Acc@1: 81.2500 (78.3561)  Acc@5: 100.0000 (98.8746)  time: 0.3510  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [ 320/3750]  eta: 0:20:08  Lr: 0.001875  Loss: -0.4928  Acc@1: 75.0000 (78.2710)  Acc@5: 100.0000 (98.8707)  time: 0.3538  data: 0.0006  max mem: 2503
Train: Epoch[3/5]  [ 330/3750]  eta: 0:20:04  Lr: 0.001875  Loss: -0.8062  Acc@1: 75.0000 (78.1722)  Acc@5: 100.0000 (98.9048)  time: 0.3521  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [ 340/3750]  eta: 0:20:00  Lr: 0.001875  Loss: -0.6286  Acc@1: 75.0000 (78.2075)  Acc@5: 100.0000 (98.9186)  time: 0.3475  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [ 350/3750]  eta: 0:19:57  Lr: 0.001875  Loss: -0.5965  Acc@1: 81.2500 (78.2407)  Acc@5: 100.0000 (98.9316)  time: 0.3488  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [ 360/3750]  eta: 0:19:53  Lr: 0.001875  Loss: -0.7021  Acc@1: 81.2500 (78.3241)  Acc@5: 100.0000 (98.9612)  time: 0.3504  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [ 370/3750]  eta: 0:19:49  Lr: 0.001875  Loss: -0.0347  Acc@1: 75.0000 (78.4030)  Acc@5: 100.0000 (98.9387)  time: 0.3493  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [ 380/3750]  eta: 0:19:45  Lr: 0.001875  Loss: -0.6465  Acc@1: 75.0000 (78.2316)  Acc@5: 100.0000 (98.9173)  time: 0.3479  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [ 390/3750]  eta: 0:19:41  Lr: 0.001875  Loss: -0.6407  Acc@1: 75.0000 (78.3088)  Acc@5: 100.0000 (98.9290)  time: 0.3482  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [ 400/3750]  eta: 0:19:38  Lr: 0.001875  Loss: -0.5255  Acc@1: 81.2500 (78.4289)  Acc@5: 100.0000 (98.9401)  time: 0.3487  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [ 410/3750]  eta: 0:19:34  Lr: 0.001875  Loss: -0.9970  Acc@1: 81.2500 (78.5280)  Acc@5: 100.0000 (98.9659)  time: 0.3473  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [ 420/3750]  eta: 0:19:30  Lr: 0.001875  Loss: -0.6796  Acc@1: 81.2500 (78.5481)  Acc@5: 100.0000 (98.9757)  time: 0.3462  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [ 430/3750]  eta: 0:19:26  Lr: 0.001875  Loss: -0.7655  Acc@1: 81.2500 (78.6833)  Acc@5: 100.0000 (98.9849)  time: 0.3488  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [ 440/3750]  eta: 0:19:22  Lr: 0.001875  Loss: -0.7048  Acc@1: 81.2500 (78.7132)  Acc@5: 100.0000 (98.9796)  time: 0.3492  data: 0.0006  max mem: 2503
Train: Epoch[3/5]  [ 450/3750]  eta: 0:19:19  Lr: 0.001875  Loss: -0.7660  Acc@1: 81.2500 (78.6724)  Acc@5: 100.0000 (98.9884)  time: 0.3508  data: 0.0006  max mem: 2503
Train: Epoch[3/5]  [ 460/3750]  eta: 0:19:16  Lr: 0.001875  Loss: -0.6200  Acc@1: 81.2500 (78.7012)  Acc@5: 100.0000 (98.9967)  time: 0.3540  data: 0.0006  max mem: 2503
Train: Epoch[3/5]  [ 470/3750]  eta: 0:19:12  Lr: 0.001875  Loss: -0.7498  Acc@1: 81.2500 (78.7155)  Acc@5: 100.0000 (98.9915)  time: 0.3536  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [ 480/3750]  eta: 0:19:09  Lr: 0.001875  Loss: -0.4794  Acc@1: 75.0000 (78.6512)  Acc@5: 100.0000 (98.9995)  time: 0.3536  data: 0.0012  max mem: 2503
Train: Epoch[3/5]  [ 490/3750]  eta: 0:19:06  Lr: 0.001875  Loss: -0.4294  Acc@1: 75.0000 (78.6278)  Acc@5: 100.0000 (98.9944)  time: 0.3530  data: 0.0015  max mem: 2503
Train: Epoch[3/5]  [ 500/3750]  eta: 0:19:02  Lr: 0.001875  Loss: -0.6141  Acc@1: 75.0000 (78.6552)  Acc@5: 100.0000 (99.0020)  time: 0.3521  data: 0.0008  max mem: 2503
Train: Epoch[3/5]  [ 510/3750]  eta: 0:18:58  Lr: 0.001875  Loss: -0.4687  Acc@1: 75.0000 (78.6448)  Acc@5: 100.0000 (98.9848)  time: 0.3513  data: 0.0006  max mem: 2503
Train: Epoch[3/5]  [ 520/3750]  eta: 0:18:55  Lr: 0.001875  Loss: -0.3140  Acc@1: 81.2500 (78.7308)  Acc@5: 100.0000 (98.9803)  time: 0.3536  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [ 530/3750]  eta: 0:18:52  Lr: 0.001875  Loss: -0.5849  Acc@1: 81.2500 (78.7665)  Acc@5: 100.0000 (98.9878)  time: 0.3536  data: 0.0012  max mem: 2503
Train: Epoch[3/5]  [ 540/3750]  eta: 0:18:48  Lr: 0.001875  Loss: -0.7507  Acc@1: 81.2500 (78.6622)  Acc@5: 100.0000 (98.9718)  time: 0.3503  data: 0.0012  max mem: 2503
Train: Epoch[3/5]  [ 550/3750]  eta: 0:18:44  Lr: 0.001875  Loss: -0.9020  Acc@1: 75.0000 (78.6865)  Acc@5: 100.0000 (98.9451)  time: 0.3489  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [ 560/3750]  eta: 0:18:41  Lr: 0.001875  Loss: -0.5792  Acc@1: 81.2500 (78.6430)  Acc@5: 100.0000 (98.9082)  time: 0.3479  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [ 570/3750]  eta: 0:18:37  Lr: 0.001875  Loss: -0.6681  Acc@1: 81.2500 (78.7544)  Acc@5: 100.0000 (98.8945)  time: 0.3507  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [ 580/3750]  eta: 0:18:33  Lr: 0.001875  Loss: -0.6530  Acc@1: 81.2500 (78.8188)  Acc@5: 100.0000 (98.9135)  time: 0.3501  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [ 590/3750]  eta: 0:18:30  Lr: 0.001875  Loss: -0.7910  Acc@1: 75.0000 (78.7648)  Acc@5: 100.0000 (98.9002)  time: 0.3464  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [ 600/3750]  eta: 0:18:26  Lr: 0.001875  Loss: -0.5512  Acc@1: 75.0000 (78.7542)  Acc@5: 100.0000 (98.8977)  time: 0.3464  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [ 610/3750]  eta: 0:18:22  Lr: 0.001875  Loss: -0.0522  Acc@1: 81.2500 (78.8462)  Acc@5: 100.0000 (98.8953)  time: 0.3485  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [ 620/3750]  eta: 0:18:19  Lr: 0.001875  Loss: -0.2135  Acc@1: 75.0000 (78.7138)  Acc@5: 100.0000 (98.8728)  time: 0.3481  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [ 630/3750]  eta: 0:18:15  Lr: 0.001875  Loss: -0.5584  Acc@1: 75.0000 (78.7441)  Acc@5: 100.0000 (98.8807)  time: 0.3473  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [ 640/3750]  eta: 0:18:11  Lr: 0.001875  Loss: -0.4642  Acc@1: 81.2500 (78.6954)  Acc@5: 100.0000 (98.8690)  time: 0.3501  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [ 650/3750]  eta: 0:18:08  Lr: 0.001875  Loss: -0.7960  Acc@1: 75.0000 (78.6386)  Acc@5: 100.0000 (98.8863)  time: 0.3521  data: 0.0012  max mem: 2503
Train: Epoch[3/5]  [ 660/3750]  eta: 0:18:05  Lr: 0.001875  Loss: -0.7125  Acc@1: 81.2500 (78.6970)  Acc@5: 100.0000 (98.9032)  time: 0.3540  data: 0.0012  max mem: 2503
Train: Epoch[3/5]  [ 670/3750]  eta: 0:18:01  Lr: 0.001875  Loss: -0.7815  Acc@1: 81.2500 (78.7072)  Acc@5: 100.0000 (98.9102)  time: 0.3532  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [ 680/3750]  eta: 0:17:58  Lr: 0.001875  Loss: -0.2799  Acc@1: 81.2500 (78.7445)  Acc@5: 100.0000 (98.9262)  time: 0.3502  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [ 690/3750]  eta: 0:17:54  Lr: 0.001875  Loss: -0.1992  Acc@1: 81.2500 (78.8079)  Acc@5: 100.0000 (98.9146)  time: 0.3501  data: 0.0009  max mem: 2503
Train: Epoch[3/5]  [ 700/3750]  eta: 0:17:51  Lr: 0.001875  Loss: -0.7617  Acc@1: 81.2500 (78.8160)  Acc@5: 100.0000 (98.8944)  time: 0.3551  data: 0.0010  max mem: 2503
Train: Epoch[3/5]  [ 710/3750]  eta: 0:17:47  Lr: 0.001875  Loss: -0.7076  Acc@1: 81.2500 (78.8502)  Acc@5: 100.0000 (98.9012)  time: 0.3545  data: 0.0006  max mem: 2503
Train: Epoch[3/5]  [ 720/3750]  eta: 0:17:44  Lr: 0.001875  Loss: -1.0755  Acc@1: 81.2500 (78.9182)  Acc@5: 100.0000 (98.8991)  time: 0.3500  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [ 730/3750]  eta: 0:17:40  Lr: 0.001875  Loss: -0.1600  Acc@1: 81.2500 (78.9159)  Acc@5: 100.0000 (98.8971)  time: 0.3500  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [ 740/3750]  eta: 0:17:37  Lr: 0.001875  Loss: -0.7334  Acc@1: 81.2500 (78.9811)  Acc@5: 100.0000 (98.8951)  time: 0.3540  data: 0.0008  max mem: 2503
Train: Epoch[3/5]  [ 750/3750]  eta: 0:17:33  Lr: 0.001875  Loss: -0.4718  Acc@1: 81.2500 (78.9447)  Acc@5: 100.0000 (98.8848)  time: 0.3543  data: 0.0008  max mem: 2503
Train: Epoch[3/5]  [ 760/3750]  eta: 0:17:30  Lr: 0.001875  Loss: -0.8721  Acc@1: 75.0000 (78.9011)  Acc@5: 100.0000 (98.8995)  time: 0.3493  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [ 770/3750]  eta: 0:17:26  Lr: 0.001875  Loss: -0.0150  Acc@1: 75.0000 (78.9478)  Acc@5: 100.0000 (98.8813)  time: 0.3489  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [ 780/3750]  eta: 0:17:23  Lr: 0.001875  Loss: -0.6319  Acc@1: 81.2500 (78.9773)  Acc@5: 100.0000 (98.8956)  time: 0.3482  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [ 790/3750]  eta: 0:17:19  Lr: 0.001875  Loss: -0.7629  Acc@1: 81.2500 (79.0060)  Acc@5: 100.0000 (98.9096)  time: 0.3476  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [ 800/3750]  eta: 0:17:15  Lr: 0.001875  Loss: -0.2840  Acc@1: 81.2500 (78.9716)  Acc@5: 100.0000 (98.8920)  time: 0.3463  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [ 810/3750]  eta: 0:17:11  Lr: 0.001875  Loss: -0.9496  Acc@1: 81.2500 (79.0382)  Acc@5: 100.0000 (98.8980)  time: 0.3453  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [ 820/3750]  eta: 0:17:08  Lr: 0.001875  Loss: -0.8514  Acc@1: 81.2500 (78.9814)  Acc@5: 100.0000 (98.8962)  time: 0.3471  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [ 830/3750]  eta: 0:17:04  Lr: 0.001875  Loss: -0.6238  Acc@1: 75.0000 (78.9937)  Acc@5: 100.0000 (98.9019)  time: 0.3492  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [ 840/3750]  eta: 0:17:01  Lr: 0.001875  Loss: -0.4193  Acc@1: 81.2500 (78.9834)  Acc@5: 100.0000 (98.9001)  time: 0.3507  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [ 850/3750]  eta: 0:16:57  Lr: 0.001875  Loss: -0.7108  Acc@1: 81.2500 (78.9733)  Acc@5: 100.0000 (98.9130)  time: 0.3502  data: 0.0006  max mem: 2503
Train: Epoch[3/5]  [ 860/3750]  eta: 0:16:54  Lr: 0.001875  Loss: -0.3638  Acc@1: 81.2500 (78.9707)  Acc@5: 100.0000 (98.9184)  time: 0.3487  data: 0.0006  max mem: 2503
Train: Epoch[3/5]  [ 870/3750]  eta: 0:16:50  Lr: 0.001875  Loss: -0.6056  Acc@1: 81.2500 (78.9681)  Acc@5: 100.0000 (98.9237)  time: 0.3510  data: 0.0008  max mem: 2503
Train: Epoch[3/5]  [ 880/3750]  eta: 0:16:47  Lr: 0.001875  Loss: -0.4015  Acc@1: 75.0000 (78.9586)  Acc@5: 100.0000 (98.9359)  time: 0.3524  data: 0.0009  max mem: 2503
Train: Epoch[3/5]  [ 890/3750]  eta: 0:16:43  Lr: 0.001875  Loss: -0.7275  Acc@1: 75.0000 (78.9422)  Acc@5: 100.0000 (98.9338)  time: 0.3504  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [ 900/3750]  eta: 0:16:40  Lr: 0.001875  Loss: -0.4728  Acc@1: 75.0000 (78.8915)  Acc@5: 100.0000 (98.9248)  time: 0.3504  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [ 910/3750]  eta: 0:16:36  Lr: 0.001875  Loss: -0.6620  Acc@1: 75.0000 (78.8419)  Acc@5: 100.0000 (98.9229)  time: 0.3553  data: 0.0010  max mem: 2503
Train: Epoch[3/5]  [ 920/3750]  eta: 0:16:33  Lr: 0.001875  Loss: -0.3616  Acc@1: 75.0000 (78.8613)  Acc@5: 100.0000 (98.9210)  time: 0.3568  data: 0.0013  max mem: 2503
Train: Epoch[3/5]  [ 930/3750]  eta: 0:16:29  Lr: 0.001875  Loss: -0.8010  Acc@1: 75.0000 (78.8400)  Acc@5: 100.0000 (98.9125)  time: 0.3520  data: 0.0007  max mem: 2503
Train: Epoch[3/5]  [ 940/3750]  eta: 0:16:26  Lr: 0.001875  Loss: -0.4092  Acc@1: 81.2500 (78.8855)  Acc@5: 100.0000 (98.9174)  time: 0.3486  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [ 950/3750]  eta: 0:16:22  Lr: 0.001875  Loss: -0.9091  Acc@1: 81.2500 (78.8906)  Acc@5: 100.0000 (98.9156)  time: 0.3521  data: 0.0013  max mem: 2503
Train: Epoch[3/5]  [ 960/3750]  eta: 0:16:19  Lr: 0.001875  Loss: -0.7874  Acc@1: 81.2500 (78.9282)  Acc@5: 100.0000 (98.9204)  time: 0.3532  data: 0.0014  max mem: 2503
Train: Epoch[3/5]  [ 970/3750]  eta: 0:16:15  Lr: 0.001875  Loss: -0.6304  Acc@1: 75.0000 (78.9457)  Acc@5: 100.0000 (98.9251)  time: 0.3503  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [ 980/3750]  eta: 0:16:12  Lr: 0.001875  Loss: -0.7983  Acc@1: 75.0000 (78.9309)  Acc@5: 100.0000 (98.9297)  time: 0.3495  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [ 990/3750]  eta: 0:16:08  Lr: 0.001875  Loss: -0.5227  Acc@1: 75.0000 (78.9417)  Acc@5: 100.0000 (98.9279)  time: 0.3496  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [1000/3750]  eta: 0:16:05  Lr: 0.001875  Loss: -0.7903  Acc@1: 81.2500 (78.9398)  Acc@5: 100.0000 (98.9261)  time: 0.3490  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [1010/3750]  eta: 0:16:01  Lr: 0.001875  Loss: -0.1299  Acc@1: 81.2500 (78.9627)  Acc@5: 100.0000 (98.9182)  time: 0.3466  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [1020/3750]  eta: 0:15:57  Lr: 0.001875  Loss: -0.5118  Acc@1: 81.2500 (78.9728)  Acc@5: 100.0000 (98.9226)  time: 0.3470  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [1030/3750]  eta: 0:15:54  Lr: 0.001875  Loss: -0.6712  Acc@1: 81.2500 (79.0010)  Acc@5: 100.0000 (98.9270)  time: 0.3536  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [1040/3750]  eta: 0:15:51  Lr: 0.001875  Loss: -0.8096  Acc@1: 81.2500 (79.0586)  Acc@5: 100.0000 (98.9253)  time: 0.3572  data: 0.0012  max mem: 2503
Train: Epoch[3/5]  [1050/3750]  eta: 0:15:47  Lr: 0.001875  Loss: -0.6980  Acc@1: 81.2500 (79.0557)  Acc@5: 100.0000 (98.9355)  time: 0.3526  data: 0.0013  max mem: 2503
Train: Epoch[3/5]  [1060/3750]  eta: 0:15:44  Lr: 0.001875  Loss: -0.4783  Acc@1: 81.2500 (79.0528)  Acc@5: 100.0000 (98.9220)  time: 0.3504  data: 0.0007  max mem: 2503
Train: Epoch[3/5]  [1070/3750]  eta: 0:15:40  Lr: 0.001875  Loss: -0.7352  Acc@1: 81.2500 (79.0850)  Acc@5: 100.0000 (98.9262)  time: 0.3510  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [1080/3750]  eta: 0:15:37  Lr: 0.001875  Loss: -0.4652  Acc@1: 81.2500 (79.0877)  Acc@5: 100.0000 (98.9188)  time: 0.3578  data: 0.0019  max mem: 2503
Train: Epoch[3/5]  [1090/3750]  eta: 0:15:33  Lr: 0.001875  Loss: -0.5500  Acc@1: 81.2500 (79.0101)  Acc@5: 100.0000 (98.9001)  time: 0.3564  data: 0.0020  max mem: 2503
Train: Epoch[3/5]  [1100/3750]  eta: 0:15:30  Lr: 0.001875  Loss: -0.2418  Acc@1: 75.0000 (79.0361)  Acc@5: 100.0000 (98.9044)  time: 0.3503  data: 0.0008  max mem: 2503
Train: Epoch[3/5]  [1110/3750]  eta: 0:15:26  Lr: 0.001875  Loss: -0.6719  Acc@1: 81.2500 (79.0223)  Acc@5: 100.0000 (98.9086)  time: 0.3500  data: 0.0006  max mem: 2503
Train: Epoch[3/5]  [1120/3750]  eta: 0:15:23  Lr: 0.001875  Loss: -0.5542  Acc@1: 81.2500 (79.0366)  Acc@5: 100.0000 (98.9072)  time: 0.3491  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [1130/3750]  eta: 0:15:19  Lr: 0.001875  Loss: -0.7195  Acc@1: 81.2500 (79.0506)  Acc@5: 100.0000 (98.9058)  time: 0.3495  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [1140/3750]  eta: 0:15:16  Lr: 0.001875  Loss: -0.6725  Acc@1: 81.2500 (79.0699)  Acc@5: 100.0000 (98.9154)  time: 0.3483  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [1150/3750]  eta: 0:15:12  Lr: 0.001875  Loss: -0.3758  Acc@1: 81.2500 (79.0834)  Acc@5: 100.0000 (98.9086)  time: 0.3497  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [1160/3750]  eta: 0:15:09  Lr: 0.001875  Loss: -0.7442  Acc@1: 75.0000 (79.0429)  Acc@5: 100.0000 (98.9018)  time: 0.3515  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [1170/3750]  eta: 0:15:05  Lr: 0.001875  Loss: -0.7875  Acc@1: 68.7500 (79.0243)  Acc@5: 100.0000 (98.9005)  time: 0.3493  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [1180/3750]  eta: 0:15:02  Lr: 0.001875  Loss: -0.3456  Acc@1: 75.0000 (79.0538)  Acc@5: 100.0000 (98.8887)  time: 0.3469  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [1190/3750]  eta: 0:14:58  Lr: 0.001875  Loss: -0.7136  Acc@1: 81.2500 (79.0407)  Acc@5: 100.0000 (98.8875)  time: 0.3468  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [1200/3750]  eta: 0:14:55  Lr: 0.001875  Loss: -0.6417  Acc@1: 81.2500 (79.0591)  Acc@5: 100.0000 (98.8759)  time: 0.3520  data: 0.0006  max mem: 2503
Train: Epoch[3/5]  [1210/3750]  eta: 0:14:51  Lr: 0.001875  Loss: -0.5702  Acc@1: 81.2500 (79.0669)  Acc@5: 100.0000 (98.8749)  time: 0.3542  data: 0.0009  max mem: 2503
Train: Epoch[3/5]  [1220/3750]  eta: 0:14:47  Lr: 0.001875  Loss: -0.6518  Acc@1: 81.2500 (79.0950)  Acc@5: 100.0000 (98.8841)  time: 0.3508  data: 0.0006  max mem: 2503
Train: Epoch[3/5]  [1230/3750]  eta: 0:14:44  Lr: 0.001875  Loss: -0.6376  Acc@1: 81.2500 (79.1176)  Acc@5: 100.0000 (98.8881)  time: 0.3490  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [1240/3750]  eta: 0:14:41  Lr: 0.001875  Loss: -0.5657  Acc@1: 75.0000 (79.0643)  Acc@5: 100.0000 (98.8769)  time: 0.3552  data: 0.0007  max mem: 2503
Train: Epoch[3/5]  [1250/3750]  eta: 0:14:37  Lr: 0.001875  Loss: -0.4055  Acc@1: 75.0000 (79.0568)  Acc@5: 100.0000 (98.8659)  time: 0.3584  data: 0.0010  max mem: 2503
Train: Epoch[3/5]  [1260/3750]  eta: 0:14:34  Lr: 0.001875  Loss: -0.4774  Acc@1: 75.0000 (79.0295)  Acc@5: 100.0000 (98.8699)  time: 0.3552  data: 0.0009  max mem: 2503
Train: Epoch[3/5]  [1270/3750]  eta: 0:14:30  Lr: 0.001875  Loss: -0.4924  Acc@1: 81.2500 (79.0323)  Acc@5: 100.0000 (98.8739)  time: 0.3530  data: 0.0006  max mem: 2503
Train: Epoch[3/5]  [1280/3750]  eta: 0:14:27  Lr: 0.001875  Loss: -0.4867  Acc@1: 81.2500 (79.0105)  Acc@5: 100.0000 (98.8632)  time: 0.3528  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [1290/3750]  eta: 0:14:24  Lr: 0.001875  Loss: -0.3068  Acc@1: 81.2500 (79.0085)  Acc@5: 100.0000 (98.8672)  time: 0.3588  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [1300/3750]  eta: 0:14:20  Lr: 0.001875  Loss: -0.2304  Acc@1: 75.0000 (78.9873)  Acc@5: 100.0000 (98.8615)  time: 0.3558  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [1310/3750]  eta: 0:14:17  Lr: 0.001875  Loss: -0.8341  Acc@1: 75.0000 (79.0046)  Acc@5: 100.0000 (98.8654)  time: 0.3511  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [1320/3750]  eta: 0:14:13  Lr: 0.001875  Loss: -0.2905  Acc@1: 81.2500 (79.0216)  Acc@5: 100.0000 (98.8645)  time: 0.3511  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [1330/3750]  eta: 0:14:10  Lr: 0.001875  Loss: -0.7588  Acc@1: 87.5000 (79.0806)  Acc@5: 100.0000 (98.8636)  time: 0.3525  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [1340/3750]  eta: 0:14:06  Lr: 0.001875  Loss: -0.8766  Acc@1: 87.5000 (79.0921)  Acc@5: 100.0000 (98.8581)  time: 0.3523  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [1350/3750]  eta: 0:14:02  Lr: 0.001875  Loss: -0.7849  Acc@1: 75.0000 (79.0387)  Acc@5: 100.0000 (98.8666)  time: 0.3476  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [1360/3750]  eta: 0:13:59  Lr: 0.001875  Loss: -0.8442  Acc@1: 75.0000 (79.0366)  Acc@5: 100.0000 (98.8657)  time: 0.3464  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [1370/3750]  eta: 0:13:55  Lr: 0.001875  Loss: -0.8518  Acc@1: 81.2500 (79.0755)  Acc@5: 100.0000 (98.8649)  time: 0.3489  data: 0.0007  max mem: 2503
Train: Epoch[3/5]  [1380/3750]  eta: 0:13:52  Lr: 0.001875  Loss: -0.6420  Acc@1: 81.2500 (79.0777)  Acc@5: 100.0000 (98.8505)  time: 0.3490  data: 0.0007  max mem: 2503
Train: Epoch[3/5]  [1390/3750]  eta: 0:13:48  Lr: 0.001875  Loss: -0.0814  Acc@1: 81.2500 (79.0528)  Acc@5: 100.0000 (98.8453)  time: 0.3483  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [1400/3750]  eta: 0:13:45  Lr: 0.001875  Loss: -0.6681  Acc@1: 75.0000 (79.0551)  Acc@5: 100.0000 (98.8357)  time: 0.3506  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [1410/3750]  eta: 0:13:41  Lr: 0.001875  Loss: -0.4067  Acc@1: 75.0000 (79.0574)  Acc@5: 100.0000 (98.8439)  time: 0.3524  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [1420/3750]  eta: 0:13:38  Lr: 0.001875  Loss: -0.8078  Acc@1: 75.0000 (79.0508)  Acc@5: 100.0000 (98.8432)  time: 0.3551  data: 0.0006  max mem: 2503
Train: Epoch[3/5]  [1430/3750]  eta: 0:13:34  Lr: 0.001875  Loss: -0.6415  Acc@1: 75.0000 (79.0444)  Acc@5: 100.0000 (98.8382)  time: 0.3564  data: 0.0007  max mem: 2503
Train: Epoch[3/5]  [1440/3750]  eta: 0:13:31  Lr: 0.001875  Loss: -0.8129  Acc@1: 81.2500 (79.0814)  Acc@5: 100.0000 (98.8463)  time: 0.3534  data: 0.0006  max mem: 2503
Train: Epoch[3/5]  [1450/3750]  eta: 0:13:27  Lr: 0.001875  Loss: -0.5516  Acc@1: 81.2500 (79.0619)  Acc@5: 100.0000 (98.8456)  time: 0.3534  data: 0.0014  max mem: 2503
Train: Epoch[3/5]  [1460/3750]  eta: 0:13:24  Lr: 0.001875  Loss: -0.4470  Acc@1: 75.0000 (79.0512)  Acc@5: 100.0000 (98.8492)  time: 0.3540  data: 0.0016  max mem: 2503
Train: Epoch[3/5]  [1470/3750]  eta: 0:13:20  Lr: 0.001875  Loss: -0.3140  Acc@1: 81.2500 (79.0789)  Acc@5: 100.0000 (98.8443)  time: 0.3511  data: 0.0008  max mem: 2503
Train: Epoch[3/5]  [1480/3750]  eta: 0:13:17  Lr: 0.001875  Loss: -0.1040  Acc@1: 81.2500 (79.0724)  Acc@5: 100.0000 (98.8437)  time: 0.3495  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [1490/3750]  eta: 0:13:13  Lr: 0.001875  Loss: -0.3573  Acc@1: 75.0000 (79.0661)  Acc@5: 100.0000 (98.8473)  time: 0.3493  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [1500/3750]  eta: 0:13:10  Lr: 0.001875  Loss: -0.7132  Acc@1: 81.2500 (79.0889)  Acc@5: 100.0000 (98.8508)  time: 0.3501  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [1510/3750]  eta: 0:13:06  Lr: 0.001875  Loss: -0.5675  Acc@1: 81.2500 (79.0950)  Acc@5: 100.0000 (98.8460)  time: 0.3505  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [1520/3750]  eta: 0:13:03  Lr: 0.001875  Loss: -0.5447  Acc@1: 75.0000 (79.0722)  Acc@5: 100.0000 (98.8371)  time: 0.3510  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [1530/3750]  eta: 0:12:59  Lr: 0.001875  Loss: -0.9284  Acc@1: 81.2500 (79.0701)  Acc@5: 100.0000 (98.8365)  time: 0.3493  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [1540/3750]  eta: 0:12:56  Lr: 0.001875  Loss: -0.7861  Acc@1: 81.2500 (79.0761)  Acc@5: 100.0000 (98.8360)  time: 0.3500  data: 0.0020  max mem: 2503
Train: Epoch[3/5]  [1550/3750]  eta: 0:12:52  Lr: 0.001875  Loss: -0.4288  Acc@1: 81.2500 (79.0941)  Acc@5: 100.0000 (98.8354)  time: 0.3500  data: 0.0020  max mem: 2503
Train: Epoch[3/5]  [1560/3750]  eta: 0:12:48  Lr: 0.001875  Loss: -0.7808  Acc@1: 81.2500 (79.0759)  Acc@5: 100.0000 (98.8349)  time: 0.3471  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [1570/3750]  eta: 0:12:45  Lr: 0.001875  Loss: -0.1984  Acc@1: 75.0000 (79.0460)  Acc@5: 100.0000 (98.8304)  time: 0.3501  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [1580/3750]  eta: 0:12:42  Lr: 0.001875  Loss: -0.8355  Acc@1: 75.0000 (79.0323)  Acc@5: 100.0000 (98.8338)  time: 0.3557  data: 0.0006  max mem: 2503
Train: Epoch[3/5]  [1590/3750]  eta: 0:12:38  Lr: 0.001875  Loss: -0.6254  Acc@1: 75.0000 (79.0344)  Acc@5: 100.0000 (98.8333)  time: 0.3565  data: 0.0008  max mem: 2503
Train: Epoch[3/5]  [1600/3750]  eta: 0:12:35  Lr: 0.001875  Loss: -0.7946  Acc@1: 75.0000 (79.0248)  Acc@5: 100.0000 (98.8289)  time: 0.3525  data: 0.0007  max mem: 2503
Train: Epoch[3/5]  [1610/3750]  eta: 0:12:31  Lr: 0.001875  Loss: -0.9494  Acc@1: 75.0000 (79.0386)  Acc@5: 100.0000 (98.8361)  time: 0.3524  data: 0.0007  max mem: 2503
Train: Epoch[3/5]  [1620/3750]  eta: 0:12:28  Lr: 0.001875  Loss: -0.7909  Acc@1: 81.2500 (79.0446)  Acc@5: 100.0000 (98.8356)  time: 0.3562  data: 0.0011  max mem: 2503
Train: Epoch[3/5]  [1630/3750]  eta: 0:12:24  Lr: 0.001875  Loss: -0.5913  Acc@1: 81.2500 (79.0658)  Acc@5: 100.0000 (98.8312)  time: 0.3553  data: 0.0009  max mem: 2503
Train: Epoch[3/5]  [1640/3750]  eta: 0:12:21  Lr: 0.001875  Loss: -0.7013  Acc@1: 81.2500 (79.0753)  Acc@5: 100.0000 (98.8269)  time: 0.3529  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [1650/3750]  eta: 0:12:17  Lr: 0.001875  Loss: -0.7443  Acc@1: 81.2500 (79.0809)  Acc@5: 100.0000 (98.8265)  time: 0.3519  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [1660/3750]  eta: 0:12:14  Lr: 0.001875  Loss: -0.6779  Acc@1: 81.2500 (79.0826)  Acc@5: 100.0000 (98.8260)  time: 0.3511  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [1670/3750]  eta: 0:12:10  Lr: 0.001875  Loss: -0.8679  Acc@1: 81.2500 (79.1143)  Acc@5: 100.0000 (98.8218)  time: 0.3513  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [1680/3750]  eta: 0:12:07  Lr: 0.001875  Loss: -0.7054  Acc@1: 81.2500 (79.1196)  Acc@5: 100.0000 (98.8214)  time: 0.3509  data: 0.0013  max mem: 2503
Train: Epoch[3/5]  [1690/3750]  eta: 0:12:03  Lr: 0.001875  Loss: -0.6503  Acc@1: 81.2500 (79.1174)  Acc@5: 100.0000 (98.8173)  time: 0.3497  data: 0.0012  max mem: 2503
Train: Epoch[3/5]  [1700/3750]  eta: 0:12:00  Lr: 0.001875  Loss: -0.7737  Acc@1: 81.2500 (79.1262)  Acc@5: 100.0000 (98.8242)  time: 0.3483  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [1710/3750]  eta: 0:11:56  Lr: 0.001875  Loss: -1.0366  Acc@1: 81.2500 (79.1167)  Acc@5: 100.0000 (98.8201)  time: 0.3501  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [1720/3750]  eta: 0:11:52  Lr: 0.001875  Loss: -0.5082  Acc@1: 81.2500 (79.1219)  Acc@5: 100.0000 (98.8234)  time: 0.3491  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [1730/3750]  eta: 0:11:49  Lr: 0.001875  Loss: -0.8135  Acc@1: 81.2500 (79.1197)  Acc@5: 100.0000 (98.8302)  time: 0.3458  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [1740/3750]  eta: 0:11:45  Lr: 0.001875  Loss: -0.7239  Acc@1: 81.2500 (79.1320)  Acc@5: 100.0000 (98.8297)  time: 0.3466  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [1750/3750]  eta: 0:11:42  Lr: 0.001875  Loss: -0.4590  Acc@1: 81.2500 (79.1119)  Acc@5: 100.0000 (98.8221)  time: 0.3509  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [1760/3750]  eta: 0:11:38  Lr: 0.001875  Loss: -0.3368  Acc@1: 75.0000 (79.1241)  Acc@5: 100.0000 (98.8217)  time: 0.3519  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [1770/3750]  eta: 0:11:35  Lr: 0.001875  Loss: -0.9130  Acc@1: 81.2500 (79.1431)  Acc@5: 100.0000 (98.8248)  time: 0.3500  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [1780/3750]  eta: 0:11:31  Lr: 0.001875  Loss: -0.9675  Acc@1: 81.2500 (79.1585)  Acc@5: 100.0000 (98.8244)  time: 0.3516  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [1790/3750]  eta: 0:11:28  Lr: 0.001875  Loss: -0.6227  Acc@1: 81.2500 (79.1562)  Acc@5: 100.0000 (98.8240)  time: 0.3544  data: 0.0015  max mem: 2503
Train: Epoch[3/5]  [1800/3750]  eta: 0:11:24  Lr: 0.001875  Loss: -0.6967  Acc@1: 81.2500 (79.1609)  Acc@5: 100.0000 (98.8305)  time: 0.3546  data: 0.0021  max mem: 2503
Train: Epoch[3/5]  [1810/3750]  eta: 0:11:21  Lr: 0.001875  Loss: -0.8032  Acc@1: 81.2500 (79.1759)  Acc@5: 100.0000 (98.8335)  time: 0.3508  data: 0.0011  max mem: 2503
Train: Epoch[3/5]  [1820/3750]  eta: 0:11:17  Lr: 0.001875  Loss: -0.8244  Acc@1: 75.0000 (79.1529)  Acc@5: 100.0000 (98.8365)  time: 0.3496  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [1830/3750]  eta: 0:11:14  Lr: 0.001875  Loss: -0.9692  Acc@1: 75.0000 (79.1576)  Acc@5: 100.0000 (98.8360)  time: 0.3515  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [1840/3750]  eta: 0:11:10  Lr: 0.001875  Loss: -0.4847  Acc@1: 75.0000 (79.1452)  Acc@5: 100.0000 (98.8322)  time: 0.3523  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [1850/3750]  eta: 0:11:07  Lr: 0.001875  Loss: -0.6024  Acc@1: 75.0000 (79.1397)  Acc@5: 100.0000 (98.8283)  time: 0.3507  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [1860/3750]  eta: 0:11:03  Lr: 0.001875  Loss: -0.9157  Acc@1: 75.0000 (79.1308)  Acc@5: 100.0000 (98.8212)  time: 0.3491  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [1870/3750]  eta: 0:11:00  Lr: 0.001875  Loss: -0.3251  Acc@1: 81.2500 (79.1321)  Acc@5: 100.0000 (98.8175)  time: 0.3488  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [1880/3750]  eta: 0:10:56  Lr: 0.001875  Loss: 0.1717  Acc@1: 81.2500 (79.1135)  Acc@5: 100.0000 (98.8105)  time: 0.3487  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [1890/3750]  eta: 0:10:53  Lr: 0.001875  Loss: -0.6090  Acc@1: 75.0000 (79.1116)  Acc@5: 100.0000 (98.8135)  time: 0.3480  data: 0.0011  max mem: 2503
Train: Epoch[3/5]  [1900/3750]  eta: 0:10:49  Lr: 0.001875  Loss: -0.7824  Acc@1: 81.2500 (79.1163)  Acc@5: 100.0000 (98.8098)  time: 0.3464  data: 0.0011  max mem: 2503
Train: Epoch[3/5]  [1910/3750]  eta: 0:10:46  Lr: 0.001875  Loss: -0.3304  Acc@1: 81.2500 (79.1078)  Acc@5: 100.0000 (98.8030)  time: 0.3479  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [1920/3750]  eta: 0:10:42  Lr: 0.001875  Loss: -0.2533  Acc@1: 75.0000 (79.1157)  Acc@5: 100.0000 (98.8027)  time: 0.3505  data: 0.0011  max mem: 2503
Train: Epoch[3/5]  [1930/3750]  eta: 0:10:39  Lr: 0.001875  Loss: -0.6930  Acc@1: 81.2500 (79.1073)  Acc@5: 100.0000 (98.7863)  time: 0.3497  data: 0.0012  max mem: 2503
Train: Epoch[3/5]  [1940/3750]  eta: 0:10:35  Lr: 0.001875  Loss: -0.2875  Acc@1: 81.2500 (79.1119)  Acc@5: 100.0000 (98.7893)  time: 0.3495  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [1950/3750]  eta: 0:10:31  Lr: 0.001875  Loss: -0.4785  Acc@1: 75.0000 (79.1037)  Acc@5: 100.0000 (98.7859)  time: 0.3500  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [1960/3750]  eta: 0:10:28  Lr: 0.001875  Loss: -0.6275  Acc@1: 75.0000 (79.1019)  Acc@5: 100.0000 (98.7889)  time: 0.3523  data: 0.0015  max mem: 2503
Train: Epoch[3/5]  [1970/3750]  eta: 0:10:24  Lr: 0.001875  Loss: -0.9470  Acc@1: 81.2500 (79.1096)  Acc@5: 100.0000 (98.7887)  time: 0.3538  data: 0.0015  max mem: 2503
Train: Epoch[3/5]  [1980/3750]  eta: 0:10:21  Lr: 0.001875  Loss: -0.4580  Acc@1: 81.2500 (79.1267)  Acc@5: 100.0000 (98.7853)  time: 0.3511  data: 0.0006  max mem: 2503
Train: Epoch[3/5]  [1990/3750]  eta: 0:10:17  Lr: 0.001875  Loss: -0.6347  Acc@1: 81.2500 (79.1060)  Acc@5: 100.0000 (98.7852)  time: 0.3486  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [2000/3750]  eta: 0:10:14  Lr: 0.001875  Loss: -0.5337  Acc@1: 75.0000 (79.0855)  Acc@5: 100.0000 (98.7850)  time: 0.3497  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [2010/3750]  eta: 0:10:10  Lr: 0.001875  Loss: -0.7055  Acc@1: 81.2500 (79.1024)  Acc@5: 100.0000 (98.7910)  time: 0.3546  data: 0.0018  max mem: 2503
Train: Epoch[3/5]  [2020/3750]  eta: 0:10:07  Lr: 0.001875  Loss: -0.4244  Acc@1: 81.2500 (79.0883)  Acc@5: 100.0000 (98.7846)  time: 0.3530  data: 0.0019  max mem: 2503
Train: Epoch[3/5]  [2030/3750]  eta: 0:10:03  Lr: 0.001875  Loss: -0.7782  Acc@1: 75.0000 (79.0743)  Acc@5: 100.0000 (98.7875)  time: 0.3490  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [2040/3750]  eta: 0:10:00  Lr: 0.001875  Loss: -0.8077  Acc@1: 75.0000 (79.0758)  Acc@5: 100.0000 (98.7874)  time: 0.3491  data: 0.0006  max mem: 2503
Train: Epoch[3/5]  [2050/3750]  eta: 0:09:56  Lr: 0.001875  Loss: -0.5694  Acc@1: 81.2500 (79.0956)  Acc@5: 100.0000 (98.7841)  time: 0.3508  data: 0.0007  max mem: 2503
Train: Epoch[3/5]  [2060/3750]  eta: 0:09:53  Lr: 0.001875  Loss: -0.7426  Acc@1: 81.2500 (79.1151)  Acc@5: 100.0000 (98.7840)  time: 0.3506  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [2070/3750]  eta: 0:09:49  Lr: 0.001875  Loss: -0.4895  Acc@1: 81.2500 (79.1164)  Acc@5: 100.0000 (98.7838)  time: 0.3500  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [2080/3750]  eta: 0:09:46  Lr: 0.001875  Loss: -0.9353  Acc@1: 81.2500 (79.1416)  Acc@5: 100.0000 (98.7806)  time: 0.3498  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [2090/3750]  eta: 0:09:42  Lr: 0.001875  Loss: -0.6219  Acc@1: 81.2500 (79.1457)  Acc@5: 100.0000 (98.7715)  time: 0.3496  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [2100/3750]  eta: 0:09:39  Lr: 0.001875  Loss: -0.7852  Acc@1: 81.2500 (79.1439)  Acc@5: 100.0000 (98.7655)  time: 0.3491  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [2110/3750]  eta: 0:09:35  Lr: 0.001875  Loss: -0.6271  Acc@1: 81.2500 (79.1538)  Acc@5: 100.0000 (98.7684)  time: 0.3463  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [2120/3750]  eta: 0:09:32  Lr: 0.001875  Loss: -0.5414  Acc@1: 81.2500 (79.1637)  Acc@5: 100.0000 (98.7653)  time: 0.3495  data: 0.0011  max mem: 2503
Train: Epoch[3/5]  [2130/3750]  eta: 0:09:28  Lr: 0.001875  Loss: -0.5707  Acc@1: 81.2500 (79.1911)  Acc@5: 100.0000 (98.7682)  time: 0.3534  data: 0.0013  max mem: 2503
Train: Epoch[3/5]  [2140/3750]  eta: 0:09:25  Lr: 0.001875  Loss: -0.5930  Acc@1: 81.2500 (79.1890)  Acc@5: 100.0000 (98.7739)  time: 0.3525  data: 0.0007  max mem: 2503
Train: Epoch[3/5]  [2150/3750]  eta: 0:09:21  Lr: 0.001875  Loss: -0.8378  Acc@1: 75.0000 (79.1812)  Acc@5: 100.0000 (98.7680)  time: 0.3520  data: 0.0006  max mem: 2503
Train: Epoch[3/5]  [2160/3750]  eta: 0:09:18  Lr: 0.001875  Loss: -0.8096  Acc@1: 81.2500 (79.1908)  Acc@5: 100.0000 (98.7679)  time: 0.3526  data: 0.0007  max mem: 2503
Train: Epoch[3/5]  [2170/3750]  eta: 0:09:14  Lr: 0.001875  Loss: -0.4786  Acc@1: 81.2500 (79.1772)  Acc@5: 100.0000 (98.7621)  time: 0.3617  data: 0.0022  max mem: 2503
Train: Epoch[3/5]  [2180/3750]  eta: 0:09:11  Lr: 0.001875  Loss: -0.4398  Acc@1: 81.2500 (79.1753)  Acc@5: 100.0000 (98.7649)  time: 0.3597  data: 0.0030  max mem: 2503
Train: Epoch[3/5]  [2190/3750]  eta: 0:09:07  Lr: 0.001875  Loss: -0.9249  Acc@1: 81.2500 (79.1904)  Acc@5: 100.0000 (98.7677)  time: 0.3493  data: 0.0014  max mem: 2503
Train: Epoch[3/5]  [2200/3750]  eta: 0:09:04  Lr: 0.001875  Loss: -0.9398  Acc@1: 81.2500 (79.1970)  Acc@5: 100.0000 (98.7619)  time: 0.3491  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [2210/3750]  eta: 0:09:00  Lr: 0.001875  Loss: -0.6868  Acc@1: 75.0000 (79.1949)  Acc@5: 100.0000 (98.7562)  time: 0.3551  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [2220/3750]  eta: 0:08:57  Lr: 0.001875  Loss: -0.7024  Acc@1: 81.2500 (79.2014)  Acc@5: 100.0000 (98.7590)  time: 0.3584  data: 0.0013  max mem: 2503
Train: Epoch[3/5]  [2230/3750]  eta: 0:08:53  Lr: 0.001875  Loss: -0.7460  Acc@1: 81.2500 (79.1937)  Acc@5: 100.0000 (98.7618)  time: 0.3519  data: 0.0012  max mem: 2503
Train: Epoch[3/5]  [2240/3750]  eta: 0:08:50  Lr: 0.001875  Loss: -0.4468  Acc@1: 81.2500 (79.1946)  Acc@5: 100.0000 (98.7645)  time: 0.3495  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [2250/3750]  eta: 0:08:46  Lr: 0.001875  Loss: -0.2456  Acc@1: 81.2500 (79.1843)  Acc@5: 100.0000 (98.7644)  time: 0.3501  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [2260/3750]  eta: 0:08:43  Lr: 0.001875  Loss: -0.1946  Acc@1: 75.0000 (79.1575)  Acc@5: 100.0000 (98.7644)  time: 0.3520  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [2270/3750]  eta: 0:08:39  Lr: 0.001875  Loss: -0.8232  Acc@1: 75.0000 (79.1391)  Acc@5: 100.0000 (98.7643)  time: 0.3517  data: 0.0013  max mem: 2503
Train: Epoch[3/5]  [2280/3750]  eta: 0:08:36  Lr: 0.001875  Loss: -0.3312  Acc@1: 75.0000 (79.1237)  Acc@5: 100.0000 (98.7670)  time: 0.3482  data: 0.0012  max mem: 2503
Train: Epoch[3/5]  [2290/3750]  eta: 0:08:32  Lr: 0.001875  Loss: -0.6040  Acc@1: 81.2500 (79.1330)  Acc@5: 100.0000 (98.7669)  time: 0.3514  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [2300/3750]  eta: 0:08:29  Lr: 0.001875  Loss: -0.8037  Acc@1: 81.2500 (79.1259)  Acc@5: 100.0000 (98.7641)  time: 0.3529  data: 0.0007  max mem: 2503
Train: Epoch[3/5]  [2310/3750]  eta: 0:08:25  Lr: 0.001875  Loss: -0.8589  Acc@1: 81.2500 (79.1243)  Acc@5: 100.0000 (98.7641)  time: 0.3507  data: 0.0007  max mem: 2503
Train: Epoch[3/5]  [2320/3750]  eta: 0:08:22  Lr: 0.001875  Loss: -0.6845  Acc@1: 81.2500 (79.1308)  Acc@5: 100.0000 (98.7613)  time: 0.3502  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [2330/3750]  eta: 0:08:18  Lr: 0.001875  Loss: -0.4845  Acc@1: 81.2500 (79.1479)  Acc@5: 100.0000 (98.7666)  time: 0.3530  data: 0.0012  max mem: 2503
Train: Epoch[3/5]  [2340/3750]  eta: 0:08:15  Lr: 0.001875  Loss: -0.8219  Acc@1: 81.2500 (79.1569)  Acc@5: 100.0000 (98.7719)  time: 0.3570  data: 0.0013  max mem: 2503
Train: Epoch[3/5]  [2350/3750]  eta: 0:08:11  Lr: 0.001875  Loss: -0.1026  Acc@1: 81.2500 (79.1392)  Acc@5: 100.0000 (98.7691)  time: 0.3537  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [2360/3750]  eta: 0:08:08  Lr: 0.001875  Loss: -0.3844  Acc@1: 75.0000 (79.1481)  Acc@5: 100.0000 (98.7691)  time: 0.3496  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [2370/3750]  eta: 0:08:04  Lr: 0.001875  Loss: -0.5551  Acc@1: 75.0000 (79.1333)  Acc@5: 100.0000 (98.7663)  time: 0.3507  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [2380/3750]  eta: 0:08:01  Lr: 0.001875  Loss: -0.4692  Acc@1: 75.0000 (79.1317)  Acc@5: 100.0000 (98.7636)  time: 0.3563  data: 0.0007  max mem: 2503
Train: Epoch[3/5]  [2390/3750]  eta: 0:07:57  Lr: 0.001875  Loss: -0.7648  Acc@1: 81.2500 (79.1458)  Acc@5: 100.0000 (98.7610)  time: 0.3594  data: 0.0013  max mem: 2503
Train: Epoch[3/5]  [2400/3750]  eta: 0:07:54  Lr: 0.001875  Loss: -0.7986  Acc@1: 81.2500 (79.1441)  Acc@5: 100.0000 (98.7635)  time: 0.3541  data: 0.0011  max mem: 2503
Train: Epoch[3/5]  [2410/3750]  eta: 0:07:50  Lr: 0.001875  Loss: -0.2222  Acc@1: 81.2500 (79.1269)  Acc@5: 100.0000 (98.7583)  time: 0.3513  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [2420/3750]  eta: 0:07:47  Lr: 0.001875  Loss: -0.8674  Acc@1: 81.2500 (79.1357)  Acc@5: 100.0000 (98.7608)  time: 0.3523  data: 0.0007  max mem: 2503
Train: Epoch[3/5]  [2430/3750]  eta: 0:07:43  Lr: 0.001875  Loss: -0.8401  Acc@1: 81.2500 (79.1341)  Acc@5: 100.0000 (98.7608)  time: 0.3520  data: 0.0016  max mem: 2503
Train: Epoch[3/5]  [2440/3750]  eta: 0:07:40  Lr: 0.001875  Loss: -0.7023  Acc@1: 81.2500 (79.1248)  Acc@5: 100.0000 (98.7633)  time: 0.3497  data: 0.0012  max mem: 2503
Train: Epoch[3/5]  [2450/3750]  eta: 0:07:36  Lr: 0.001875  Loss: -0.6799  Acc@1: 75.0000 (79.1157)  Acc@5: 100.0000 (98.7505)  time: 0.3467  data: 0.0002  max mem: 2503
Train: Epoch[3/5]  [2460/3750]  eta: 0:07:33  Lr: 0.001875  Loss: -0.5399  Acc@1: 81.2500 (79.1447)  Acc@5: 100.0000 (98.7556)  time: 0.3491  data: 0.0006  max mem: 2503
Train: Epoch[3/5]  [2470/3750]  eta: 0:07:29  Lr: 0.001875  Loss: -1.0225  Acc@1: 81.2500 (79.1279)  Acc@5: 100.0000 (98.7556)  time: 0.3494  data: 0.0009  max mem: 2503
Train: Epoch[3/5]  [2480/3750]  eta: 0:07:26  Lr: 0.001875  Loss: -0.4803  Acc@1: 81.2500 (79.1390)  Acc@5: 100.0000 (98.7555)  time: 0.3468  data: 0.0006  max mem: 2503
Train: Epoch[3/5]  [2490/3750]  eta: 0:07:22  Lr: 0.001875  Loss: -0.3412  Acc@1: 81.2500 (79.1349)  Acc@5: 100.0000 (98.7555)  time: 0.3506  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [2500/3750]  eta: 0:07:19  Lr: 0.001875  Loss: -0.7290  Acc@1: 75.0000 (79.1209)  Acc@5: 100.0000 (98.7580)  time: 0.3562  data: 0.0018  max mem: 2503
Train: Epoch[3/5]  [2510/3750]  eta: 0:07:15  Lr: 0.001875  Loss: -0.7433  Acc@1: 81.2500 (79.1517)  Acc@5: 100.0000 (98.7605)  time: 0.3549  data: 0.0026  max mem: 2503
Train: Epoch[3/5]  [2520/3750]  eta: 0:07:12  Lr: 0.001875  Loss: -0.5206  Acc@1: 81.2500 (79.1576)  Acc@5: 100.0000 (98.7654)  time: 0.3515  data: 0.0013  max mem: 2503
Train: Epoch[3/5]  [2530/3750]  eta: 0:07:08  Lr: 0.001875  Loss: -0.4087  Acc@1: 75.0000 (79.1510)  Acc@5: 100.0000 (98.7579)  time: 0.3509  data: 0.0006  max mem: 2503
Train: Epoch[3/5]  [2540/3750]  eta: 0:07:05  Lr: 0.001875  Loss: -0.9660  Acc@1: 75.0000 (79.1494)  Acc@5: 100.0000 (98.7505)  time: 0.3539  data: 0.0007  max mem: 2503
Train: Epoch[3/5]  [2550/3750]  eta: 0:07:01  Lr: 0.001875  Loss: -0.9350  Acc@1: 81.2500 (79.1381)  Acc@5: 100.0000 (98.7554)  time: 0.3597  data: 0.0027  max mem: 2503
Train: Epoch[3/5]  [2560/3750]  eta: 0:06:58  Lr: 0.001875  Loss: -0.3820  Acc@1: 81.2500 (79.1463)  Acc@5: 100.0000 (98.7505)  time: 0.3581  data: 0.0027  max mem: 2503
Train: Epoch[3/5]  [2570/3750]  eta: 0:06:54  Lr: 0.001875  Loss: -0.6665  Acc@1: 81.2500 (79.1618)  Acc@5: 100.0000 (98.7505)  time: 0.3510  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [2580/3750]  eta: 0:06:51  Lr: 0.001875  Loss: -0.8979  Acc@1: 81.2500 (79.1699)  Acc@5: 100.0000 (98.7529)  time: 0.3488  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [2590/3750]  eta: 0:06:47  Lr: 0.001875  Loss: -0.7121  Acc@1: 81.2500 (79.1731)  Acc@5: 100.0000 (98.7505)  time: 0.3520  data: 0.0016  max mem: 2503
Train: Epoch[3/5]  [2600/3750]  eta: 0:06:44  Lr: 0.001875  Loss: -0.0652  Acc@1: 75.0000 (79.1547)  Acc@5: 100.0000 (98.7529)  time: 0.3519  data: 0.0016  max mem: 2503
Train: Epoch[3/5]  [2610/3750]  eta: 0:06:40  Lr: 0.001875  Loss: -0.3481  Acc@1: 81.2500 (79.1723)  Acc@5: 100.0000 (98.7529)  time: 0.3494  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [2620/3750]  eta: 0:06:36  Lr: 0.001875  Loss: -0.3485  Acc@1: 81.2500 (79.1706)  Acc@5: 100.0000 (98.7481)  time: 0.3488  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [2630/3750]  eta: 0:06:33  Lr: 0.001875  Loss: -0.8525  Acc@1: 81.2500 (79.1762)  Acc@5: 100.0000 (98.7481)  time: 0.3499  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [2640/3750]  eta: 0:06:29  Lr: 0.001875  Loss: -0.3795  Acc@1: 81.2500 (79.1746)  Acc@5: 100.0000 (98.7457)  time: 0.3490  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [2650/3750]  eta: 0:06:26  Lr: 0.001875  Loss: -0.8824  Acc@1: 75.0000 (79.1541)  Acc@5: 100.0000 (98.7458)  time: 0.3469  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [2660/3750]  eta: 0:06:22  Lr: 0.001875  Loss: -0.5423  Acc@1: 75.0000 (79.1408)  Acc@5: 100.0000 (98.7481)  time: 0.3478  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [2670/3750]  eta: 0:06:19  Lr: 0.001875  Loss: -0.9135  Acc@1: 68.7500 (79.1136)  Acc@5: 100.0000 (98.7434)  time: 0.3484  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [2680/3750]  eta: 0:06:15  Lr: 0.001875  Loss: -0.8585  Acc@1: 75.0000 (79.1239)  Acc@5: 100.0000 (98.7435)  time: 0.3501  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [2690/3750]  eta: 0:06:12  Lr: 0.001875  Loss: -0.5262  Acc@1: 81.2500 (79.1225)  Acc@5: 100.0000 (98.7389)  time: 0.3509  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [2700/3750]  eta: 0:06:08  Lr: 0.001875  Loss: -0.2948  Acc@1: 75.0000 (79.1119)  Acc@5: 100.0000 (98.7366)  time: 0.3521  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [2710/3750]  eta: 0:06:05  Lr: 0.001875  Loss: -0.7922  Acc@1: 81.2500 (79.1198)  Acc@5: 100.0000 (98.7366)  time: 0.3546  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [2720/3750]  eta: 0:06:01  Lr: 0.001875  Loss: -0.4796  Acc@1: 81.2500 (79.0978)  Acc@5: 100.0000 (98.7367)  time: 0.3538  data: 0.0007  max mem: 2503
Train: Epoch[3/5]  [2730/3750]  eta: 0:05:58  Lr: 0.001875  Loss: -0.6571  Acc@1: 75.0000 (79.1034)  Acc@5: 100.0000 (98.7413)  time: 0.3533  data: 0.0006  max mem: 2503
Train: Epoch[3/5]  [2740/3750]  eta: 0:05:54  Lr: 0.001875  Loss: -0.6478  Acc@1: 81.2500 (79.1203)  Acc@5: 100.0000 (98.7436)  time: 0.3528  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [2750/3750]  eta: 0:05:51  Lr: 0.001875  Loss: -0.2866  Acc@1: 81.2500 (79.1190)  Acc@5: 100.0000 (98.7368)  time: 0.3547  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [2760/3750]  eta: 0:05:47  Lr: 0.001875  Loss: -0.7685  Acc@1: 81.2500 (79.1267)  Acc@5: 100.0000 (98.7414)  time: 0.3541  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [2770/3750]  eta: 0:05:44  Lr: 0.001875  Loss: -0.4414  Acc@1: 81.2500 (79.1343)  Acc@5: 100.0000 (98.7459)  time: 0.3507  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [2780/3750]  eta: 0:05:40  Lr: 0.001875  Loss: -0.9970  Acc@1: 81.2500 (79.1397)  Acc@5: 100.0000 (98.7415)  time: 0.3500  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [2790/3750]  eta: 0:05:37  Lr: 0.001875  Loss: -0.7915  Acc@1: 75.0000 (79.1473)  Acc@5: 100.0000 (98.7415)  time: 0.3488  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [2800/3750]  eta: 0:05:33  Lr: 0.001875  Loss: -0.7277  Acc@1: 81.2500 (79.1503)  Acc@5: 100.0000 (98.7393)  time: 0.3500  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [2810/3750]  eta: 0:05:30  Lr: 0.001875  Loss: -0.6060  Acc@1: 81.2500 (79.1467)  Acc@5: 100.0000 (98.7393)  time: 0.3495  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [2820/3750]  eta: 0:05:26  Lr: 0.001875  Loss: -0.4686  Acc@1: 81.2500 (79.1541)  Acc@5: 100.0000 (98.7371)  time: 0.3473  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [2830/3750]  eta: 0:05:23  Lr: 0.001875  Loss: -0.4557  Acc@1: 81.2500 (79.1615)  Acc@5: 100.0000 (98.7372)  time: 0.3469  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [2840/3750]  eta: 0:05:19  Lr: 0.001875  Loss: -0.9767  Acc@1: 81.2500 (79.1733)  Acc@5: 100.0000 (98.7394)  time: 0.3482  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [2850/3750]  eta: 0:05:16  Lr: 0.001875  Loss: -0.7626  Acc@1: 81.2500 (79.1696)  Acc@5: 100.0000 (98.7439)  time: 0.3502  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [2860/3750]  eta: 0:05:12  Lr: 0.001875  Loss: -0.4669  Acc@1: 81.2500 (79.1856)  Acc@5: 100.0000 (98.7461)  time: 0.3525  data: 0.0007  max mem: 2503
Train: Epoch[3/5]  [2870/3750]  eta: 0:05:09  Lr: 0.001875  Loss: -0.2993  Acc@1: 87.5000 (79.1863)  Acc@5: 100.0000 (98.7439)  time: 0.3527  data: 0.0009  max mem: 2503
Train: Epoch[3/5]  [2880/3750]  eta: 0:05:05  Lr: 0.001875  Loss: -0.4947  Acc@1: 87.5000 (79.1869)  Acc@5: 100.0000 (98.7461)  time: 0.3530  data: 0.0006  max mem: 2503
Train: Epoch[3/5]  [2890/3750]  eta: 0:05:02  Lr: 0.001875  Loss: -0.8771  Acc@1: 81.2500 (79.1854)  Acc@5: 100.0000 (98.7439)  time: 0.3574  data: 0.0017  max mem: 2503
Train: Epoch[3/5]  [2900/3750]  eta: 0:04:58  Lr: 0.001875  Loss: -0.6518  Acc@1: 81.2500 (79.1904)  Acc@5: 100.0000 (98.7418)  time: 0.3562  data: 0.0017  max mem: 2503
Train: Epoch[3/5]  [2910/3750]  eta: 0:04:55  Lr: 0.001875  Loss: -0.4159  Acc@1: 81.2500 (79.1867)  Acc@5: 100.0000 (98.7397)  time: 0.3506  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [2920/3750]  eta: 0:04:51  Lr: 0.001875  Loss: -0.9411  Acc@1: 81.2500 (79.1980)  Acc@5: 100.0000 (98.7397)  time: 0.3552  data: 0.0023  max mem: 2503
Train: Epoch[3/5]  [2930/3750]  eta: 0:04:48  Lr: 0.001875  Loss: -0.7468  Acc@1: 87.5000 (79.2072)  Acc@5: 100.0000 (98.7398)  time: 0.3591  data: 0.0036  max mem: 2503
Train: Epoch[3/5]  [2940/3750]  eta: 0:04:44  Lr: 0.001875  Loss: -0.1996  Acc@1: 75.0000 (79.1886)  Acc@5: 100.0000 (98.7440)  time: 0.3596  data: 0.0017  max mem: 2503
Train: Epoch[3/5]  [2950/3750]  eta: 0:04:41  Lr: 0.001875  Loss: -0.5500  Acc@1: 75.0000 (79.1956)  Acc@5: 100.0000 (98.7420)  time: 0.3556  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [2960/3750]  eta: 0:04:37  Lr: 0.001875  Loss: -0.5044  Acc@1: 81.2500 (79.1730)  Acc@5: 100.0000 (98.7462)  time: 0.3499  data: 0.0011  max mem: 2503
Train: Epoch[3/5]  [2970/3750]  eta: 0:04:34  Lr: 0.001875  Loss: -0.1185  Acc@1: 75.0000 (79.1590)  Acc@5: 100.0000 (98.7420)  time: 0.3507  data: 0.0011  max mem: 2503
Train: Epoch[3/5]  [2980/3750]  eta: 0:04:30  Lr: 0.001875  Loss: -0.8948  Acc@1: 87.5000 (79.1932)  Acc@5: 100.0000 (98.7462)  time: 0.3517  data: 0.0013  max mem: 2503
Train: Epoch[3/5]  [2990/3750]  eta: 0:04:27  Lr: 0.001875  Loss: -0.4250  Acc@1: 87.5000 (79.1938)  Acc@5: 100.0000 (98.7421)  time: 0.3505  data: 0.0013  max mem: 2503
Train: Epoch[3/5]  [3000/3750]  eta: 0:04:23  Lr: 0.001875  Loss: -0.8944  Acc@1: 81.2500 (79.1944)  Acc@5: 100.0000 (98.7358)  time: 0.3479  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [3010/3750]  eta: 0:04:19  Lr: 0.001875  Loss: -0.7929  Acc@1: 75.0000 (79.1909)  Acc@5: 100.0000 (98.7400)  time: 0.3475  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [3020/3750]  eta: 0:04:16  Lr: 0.001875  Loss: -0.0947  Acc@1: 81.2500 (79.1770)  Acc@5: 100.0000 (98.7401)  time: 0.3481  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [3030/3750]  eta: 0:04:12  Lr: 0.001875  Loss: -0.8867  Acc@1: 81.2500 (79.1797)  Acc@5: 100.0000 (98.7401)  time: 0.3474  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [3040/3750]  eta: 0:04:09  Lr: 0.001875  Loss: -0.6762  Acc@1: 81.2500 (79.1763)  Acc@5: 100.0000 (98.7401)  time: 0.3492  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [3050/3750]  eta: 0:04:05  Lr: 0.001875  Loss: -0.4176  Acc@1: 75.0000 (79.1687)  Acc@5: 100.0000 (98.7361)  time: 0.3538  data: 0.0007  max mem: 2503
Train: Epoch[3/5]  [3060/3750]  eta: 0:04:02  Lr: 0.001875  Loss: -0.9449  Acc@1: 75.0000 (79.1755)  Acc@5: 100.0000 (98.7382)  time: 0.3553  data: 0.0007  max mem: 2503
Train: Epoch[3/5]  [3070/3750]  eta: 0:03:58  Lr: 0.001875  Loss: -0.4786  Acc@1: 81.2500 (79.1782)  Acc@5: 100.0000 (98.7362)  time: 0.3526  data: 0.0006  max mem: 2503
Train: Epoch[3/5]  [3080/3750]  eta: 0:03:55  Lr: 0.001875  Loss: -0.7735  Acc@1: 81.2500 (79.1849)  Acc@5: 100.0000 (98.7362)  time: 0.3508  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [3090/3750]  eta: 0:03:51  Lr: 0.001875  Loss: -0.4601  Acc@1: 81.2500 (79.1916)  Acc@5: 100.0000 (98.7363)  time: 0.3525  data: 0.0006  max mem: 2503
Train: Epoch[3/5]  [3100/3750]  eta: 0:03:48  Lr: 0.001875  Loss: -0.7814  Acc@1: 81.2500 (79.1962)  Acc@5: 100.0000 (98.7363)  time: 0.3558  data: 0.0012  max mem: 2503
Train: Epoch[3/5]  [3110/3750]  eta: 0:03:44  Lr: 0.001875  Loss: -0.4918  Acc@1: 81.2500 (79.1928)  Acc@5: 100.0000 (98.7404)  time: 0.3566  data: 0.0010  max mem: 2503
Train: Epoch[3/5]  [3120/3750]  eta: 0:03:41  Lr: 0.001875  Loss: -0.6526  Acc@1: 81.2500 (79.1994)  Acc@5: 100.0000 (98.7444)  time: 0.3520  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [3130/3750]  eta: 0:03:37  Lr: 0.001875  Loss: -0.5744  Acc@1: 81.2500 (79.1979)  Acc@5: 100.0000 (98.7464)  time: 0.3490  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [3140/3750]  eta: 0:03:34  Lr: 0.001875  Loss: -0.5582  Acc@1: 75.0000 (79.1945)  Acc@5: 100.0000 (98.7365)  time: 0.3508  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [3150/3750]  eta: 0:03:30  Lr: 0.001875  Loss: -0.9240  Acc@1: 81.2500 (79.1971)  Acc@5: 100.0000 (98.7405)  time: 0.3509  data: 0.0008  max mem: 2503
Train: Epoch[3/5]  [3160/3750]  eta: 0:03:27  Lr: 0.001875  Loss: -0.8677  Acc@1: 75.0000 (79.1917)  Acc@5: 100.0000 (98.7425)  time: 0.3499  data: 0.0007  max mem: 2503
Train: Epoch[3/5]  [3170/3750]  eta: 0:03:23  Lr: 0.001875  Loss: -0.4176  Acc@1: 81.2500 (79.1943)  Acc@5: 100.0000 (98.7465)  time: 0.3497  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [3180/3750]  eta: 0:03:20  Lr: 0.001875  Loss: -0.9555  Acc@1: 81.2500 (79.1948)  Acc@5: 100.0000 (98.7445)  time: 0.3494  data: 0.0008  max mem: 2503
Train: Epoch[3/5]  [3190/3750]  eta: 0:03:16  Lr: 0.001875  Loss: -0.4238  Acc@1: 75.0000 (79.1797)  Acc@5: 100.0000 (98.7445)  time: 0.3484  data: 0.0008  max mem: 2503
Train: Epoch[3/5]  [3200/3750]  eta: 0:03:13  Lr: 0.001875  Loss: -0.3417  Acc@1: 75.0000 (79.1725)  Acc@5: 100.0000 (98.7406)  time: 0.3466  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [3210/3750]  eta: 0:03:09  Lr: 0.001875  Loss: -0.9688  Acc@1: 75.0000 (79.1770)  Acc@5: 100.0000 (98.7407)  time: 0.3467  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [3220/3750]  eta: 0:03:06  Lr: 0.001875  Loss: -0.7619  Acc@1: 81.2500 (79.1854)  Acc@5: 100.0000 (98.7387)  time: 0.3507  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [3230/3750]  eta: 0:03:02  Lr: 0.001875  Loss: -0.4186  Acc@1: 75.0000 (79.1686)  Acc@5: 100.0000 (98.7407)  time: 0.3547  data: 0.0007  max mem: 2503
Train: Epoch[3/5]  [3240/3750]  eta: 0:02:59  Lr: 0.001875  Loss: -0.7822  Acc@1: 75.0000 (79.1596)  Acc@5: 100.0000 (98.7407)  time: 0.3537  data: 0.0006  max mem: 2503
Train: Epoch[3/5]  [3250/3750]  eta: 0:02:55  Lr: 0.001875  Loss: -0.7849  Acc@1: 75.0000 (79.1699)  Acc@5: 100.0000 (98.7427)  time: 0.3509  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [3260/3750]  eta: 0:02:52  Lr: 0.001875  Loss: -0.6794  Acc@1: 81.2500 (79.1743)  Acc@5: 100.0000 (98.7446)  time: 0.3525  data: 0.0008  max mem: 2503
Train: Epoch[3/5]  [3270/3750]  eta: 0:02:48  Lr: 0.001875  Loss: -0.4675  Acc@1: 81.2500 (79.1730)  Acc@5: 100.0000 (98.7485)  time: 0.3550  data: 0.0008  max mem: 2503
Train: Epoch[3/5]  [3280/3750]  eta: 0:02:45  Lr: 0.001875  Loss: -0.7316  Acc@1: 81.2500 (79.1698)  Acc@5: 100.0000 (98.7504)  time: 0.3519  data: 0.0006  max mem: 2503
Train: Epoch[3/5]  [3290/3750]  eta: 0:02:41  Lr: 0.001875  Loss: 0.1302  Acc@1: 75.0000 (79.1458)  Acc@5: 100.0000 (98.7409)  time: 0.3497  data: 0.0006  max mem: 2503
Train: Epoch[3/5]  [3300/3750]  eta: 0:02:38  Lr: 0.001875  Loss: -0.6359  Acc@1: 75.0000 (79.1389)  Acc@5: 100.0000 (98.7409)  time: 0.3545  data: 0.0009  max mem: 2503
Train: Epoch[3/5]  [3310/3750]  eta: 0:02:34  Lr: 0.001875  Loss: -0.5208  Acc@1: 81.2500 (79.1604)  Acc@5: 100.0000 (98.7409)  time: 0.3548  data: 0.0012  max mem: 2503
Train: Epoch[3/5]  [3320/3750]  eta: 0:02:31  Lr: 0.001875  Loss: -0.4815  Acc@1: 81.2500 (79.1648)  Acc@5: 100.0000 (98.7391)  time: 0.3504  data: 0.0010  max mem: 2503
Train: Epoch[3/5]  [3330/3750]  eta: 0:02:27  Lr: 0.001875  Loss: -0.7665  Acc@1: 81.2500 (79.1617)  Acc@5: 100.0000 (98.7410)  time: 0.3490  data: 0.0006  max mem: 2503
Train: Epoch[3/5]  [3340/3750]  eta: 0:02:24  Lr: 0.001875  Loss: -0.5623  Acc@1: 81.2500 (79.1735)  Acc@5: 100.0000 (98.7448)  time: 0.3494  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [3350/3750]  eta: 0:02:20  Lr: 0.001875  Loss: -0.4903  Acc@1: 81.2500 (79.1816)  Acc@5: 100.0000 (98.7485)  time: 0.3510  data: 0.0006  max mem: 2503
Train: Epoch[3/5]  [3360/3750]  eta: 0:02:17  Lr: 0.001875  Loss: -0.5681  Acc@1: 81.2500 (79.1710)  Acc@5: 100.0000 (98.7504)  time: 0.3502  data: 0.0007  max mem: 2503
Train: Epoch[3/5]  [3370/3750]  eta: 0:02:13  Lr: 0.001875  Loss: -0.4027  Acc@1: 81.2500 (79.1623)  Acc@5: 100.0000 (98.7485)  time: 0.3476  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [3380/3750]  eta: 0:02:09  Lr: 0.001875  Loss: -0.5204  Acc@1: 81.2500 (79.1685)  Acc@5: 100.0000 (98.7504)  time: 0.3479  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [3390/3750]  eta: 0:02:06  Lr: 0.001875  Loss: -0.6982  Acc@1: 81.2500 (79.1765)  Acc@5: 100.0000 (98.7504)  time: 0.3510  data: 0.0015  max mem: 2503
Train: Epoch[3/5]  [3400/3750]  eta: 0:02:02  Lr: 0.001875  Loss: -0.6612  Acc@1: 81.2500 (79.1734)  Acc@5: 100.0000 (98.7522)  time: 0.3507  data: 0.0016  max mem: 2503
Train: Epoch[3/5]  [3410/3750]  eta: 0:01:59  Lr: 0.001875  Loss: -0.8883  Acc@1: 81.2500 (79.1868)  Acc@5: 100.0000 (98.7540)  time: 0.3502  data: 0.0006  max mem: 2503
Train: Epoch[3/5]  [3420/3750]  eta: 0:01:55  Lr: 0.001875  Loss: -0.5411  Acc@1: 81.2500 (79.1874)  Acc@5: 100.0000 (98.7577)  time: 0.3516  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [3430/3750]  eta: 0:01:52  Lr: 0.001875  Loss: -0.6768  Acc@1: 81.2500 (79.1916)  Acc@5: 100.0000 (98.7522)  time: 0.3534  data: 0.0009  max mem: 2503
Train: Epoch[3/5]  [3440/3750]  eta: 0:01:48  Lr: 0.001875  Loss: -0.8460  Acc@1: 75.0000 (79.1757)  Acc@5: 100.0000 (98.7540)  time: 0.3536  data: 0.0016  max mem: 2503
Train: Epoch[3/5]  [3450/3750]  eta: 0:01:45  Lr: 0.001875  Loss: -0.7895  Acc@1: 75.0000 (79.1890)  Acc@5: 100.0000 (98.7558)  time: 0.3501  data: 0.0011  max mem: 2503
Train: Epoch[3/5]  [3460/3750]  eta: 0:01:41  Lr: 0.001875  Loss: -0.5365  Acc@1: 81.2500 (79.1787)  Acc@5: 100.0000 (98.7504)  time: 0.3491  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [3470/3750]  eta: 0:01:38  Lr: 0.001875  Loss: -0.5907  Acc@1: 81.2500 (79.1937)  Acc@5: 100.0000 (98.7522)  time: 0.3548  data: 0.0006  max mem: 2503
Train: Epoch[3/5]  [3480/3750]  eta: 0:01:34  Lr: 0.001875  Loss: -0.5202  Acc@1: 81.2500 (79.1978)  Acc@5: 100.0000 (98.7522)  time: 0.3581  data: 0.0015  max mem: 2503
Train: Epoch[3/5]  [3490/3750]  eta: 0:01:31  Lr: 0.001875  Loss: -0.3688  Acc@1: 81.2500 (79.1947)  Acc@5: 100.0000 (98.7521)  time: 0.3521  data: 0.0013  max mem: 2503
Train: Epoch[3/5]  [3500/3750]  eta: 0:01:27  Lr: 0.001875  Loss: -1.0173  Acc@1: 75.0000 (79.1970)  Acc@5: 100.0000 (98.7557)  time: 0.3478  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [3510/3750]  eta: 0:01:24  Lr: 0.001875  Loss: -0.8733  Acc@1: 75.0000 (79.1922)  Acc@5: 100.0000 (98.7593)  time: 0.3488  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [3520/3750]  eta: 0:01:20  Lr: 0.001875  Loss: -0.8887  Acc@1: 75.0000 (79.1909)  Acc@5: 100.0000 (98.7592)  time: 0.3506  data: 0.0007  max mem: 2503
Train: Epoch[3/5]  [3530/3750]  eta: 0:01:17  Lr: 0.001875  Loss: -0.7568  Acc@1: 75.0000 (79.1702)  Acc@5: 100.0000 (98.7557)  time: 0.3504  data: 0.0007  max mem: 2503
Train: Epoch[3/5]  [3540/3750]  eta: 0:01:13  Lr: 0.001875  Loss: -0.6380  Acc@1: 75.0000 (79.1708)  Acc@5: 100.0000 (98.7539)  time: 0.3478  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [3550/3750]  eta: 0:01:10  Lr: 0.001875  Loss: -0.9222  Acc@1: 81.2500 (79.1784)  Acc@5: 100.0000 (98.7556)  time: 0.3469  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [3560/3750]  eta: 0:01:06  Lr: 0.001875  Loss: -0.9811  Acc@1: 81.2500 (79.1754)  Acc@5: 100.0000 (98.7539)  time: 0.3492  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [3570/3750]  eta: 0:01:03  Lr: 0.001875  Loss: -0.5257  Acc@1: 81.2500 (79.1918)  Acc@5: 100.0000 (98.7556)  time: 0.3489  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [3580/3750]  eta: 0:00:59  Lr: 0.001875  Loss: -1.0062  Acc@1: 81.2500 (79.2027)  Acc@5: 100.0000 (98.7573)  time: 0.3467  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [3590/3750]  eta: 0:00:56  Lr: 0.001875  Loss: -0.8326  Acc@1: 81.2500 (79.1997)  Acc@5: 100.0000 (98.7573)  time: 0.3503  data: 0.0018  max mem: 2503
Train: Epoch[3/5]  [3600/3750]  eta: 0:00:52  Lr: 0.001875  Loss: -0.4404  Acc@1: 81.2500 (79.2124)  Acc@5: 100.0000 (98.7556)  time: 0.3551  data: 0.0026  max mem: 2503
Train: Epoch[3/5]  [3610/3750]  eta: 0:00:49  Lr: 0.001875  Loss: -0.1963  Acc@1: 81.2500 (79.2059)  Acc@5: 100.0000 (98.7555)  time: 0.3547  data: 0.0013  max mem: 2503
Train: Epoch[3/5]  [3620/3750]  eta: 0:00:45  Lr: 0.001875  Loss: -0.8337  Acc@1: 81.2500 (79.2150)  Acc@5: 100.0000 (98.7555)  time: 0.3528  data: 0.0006  max mem: 2503
Train: Epoch[3/5]  [3630/3750]  eta: 0:00:42  Lr: 0.001875  Loss: -0.6620  Acc@1: 81.2500 (79.2258)  Acc@5: 100.0000 (98.7572)  time: 0.3505  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [3640/3750]  eta: 0:00:38  Lr: 0.001875  Loss: -0.5089  Acc@1: 81.2500 (79.2348)  Acc@5: 100.0000 (98.7572)  time: 0.3527  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [3650/3750]  eta: 0:00:35  Lr: 0.001875  Loss: -0.7097  Acc@1: 75.0000 (79.2317)  Acc@5: 100.0000 (98.7572)  time: 0.3564  data: 0.0012  max mem: 2503
Train: Epoch[3/5]  [3660/3750]  eta: 0:00:31  Lr: 0.001875  Loss: -0.4036  Acc@1: 75.0000 (79.2321)  Acc@5: 100.0000 (98.7589)  time: 0.3585  data: 0.0012  max mem: 2503
Train: Epoch[3/5]  [3670/3750]  eta: 0:00:28  Lr: 0.001875  Loss: -0.2615  Acc@1: 75.0000 (79.2240)  Acc@5: 100.0000 (98.7572)  time: 0.3547  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [3680/3750]  eta: 0:00:24  Lr: 0.001875  Loss: -0.7445  Acc@1: 81.2500 (79.2346)  Acc@5: 100.0000 (98.7605)  time: 0.3497  data: 0.0006  max mem: 2503
Train: Epoch[3/5]  [3690/3750]  eta: 0:00:21  Lr: 0.001875  Loss: -0.8205  Acc@1: 81.2500 (79.2282)  Acc@5: 100.0000 (98.7571)  time: 0.3523  data: 0.0006  max mem: 2503
Train: Epoch[3/5]  [3700/3750]  eta: 0:00:17  Lr: 0.001875  Loss: -0.5808  Acc@1: 81.2500 (79.2235)  Acc@5: 100.0000 (98.7571)  time: 0.3510  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [3710/3750]  eta: 0:00:14  Lr: 0.001875  Loss: -0.5830  Acc@1: 81.2500 (79.2290)  Acc@5: 100.0000 (98.7588)  time: 0.3492  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [3720/3750]  eta: 0:00:10  Lr: 0.001875  Loss: -0.9276  Acc@1: 81.2500 (79.2277)  Acc@5: 100.0000 (98.7571)  time: 0.3488  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [3730/3750]  eta: 0:00:07  Lr: 0.001875  Loss: -0.7871  Acc@1: 81.2500 (79.2314)  Acc@5: 100.0000 (98.7587)  time: 0.3495  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [3740/3750]  eta: 0:00:03  Lr: 0.001875  Loss: 0.2853  Acc@1: 75.0000 (79.2118)  Acc@5: 100.0000 (98.7570)  time: 0.3498  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [3749/3750]  eta: 0:00:00  Lr: 0.001875  Loss: -0.5286  Acc@1: 75.0000 (79.2083)  Acc@5: 100.0000 (98.7583)  time: 0.3486  data: 0.0007  max mem: 2503
Train: Epoch[3/5] Total time: 0:21:58 (0.3515 s / it)
{0: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 1: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 2: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 3: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 4: {0: 0, 1: 300000, 2: 0, 3: 91325, 4: 0}, 5: {0: 0, 1: 300000, 2: 0, 3: 91325, 4: 0}, 6: {0: 0, 1: 300000, 2: 0, 3: 91325, 4: 0}, 7: {0: 0, 1: 300000, 2: 0, 3: 91325, 4: 0}, 8: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 9: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 10: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 11: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 12: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 13: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 14: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 15: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 16: {0: 0, 1: 0, 2: 0, 3: 0, 4: 180000}, 17: {0: 0, 1: 0, 2: 0, 3: 0, 4: 180000}, 18: {0: 0, 1: 0, 2: 0, 3: 0, 4: 180000}, 19: {0: 0, 1: 0, 2: 0, 3: 0, 4: 180000}}
Averaged stats: Lr: 0.001875  Loss: -0.5286  Acc@1: 75.0000 (79.2083)  Acc@5: 100.0000 (98.7583)
Train: Epoch[4/5]  [   0/3750]  eta: 0:43:13  Lr: 0.001875  Loss: -0.4048  Acc@1: 81.2500 (81.2500)  Acc@5: 93.7500 (93.7500)  time: 0.6917  data: 0.3435  max mem: 2503
Train: Epoch[4/5]  [  10/3750]  eta: 0:23:37  Lr: 0.001875  Loss: -0.4852  Acc@1: 81.2500 (77.8409)  Acc@5: 100.0000 (97.7273)  time: 0.3790  data: 0.0315  max mem: 2503
Train: Epoch[4/5]  [  20/3750]  eta: 0:22:47  Lr: 0.001875  Loss: -0.8390  Acc@1: 81.2500 (80.3571)  Acc@5: 100.0000 (98.5119)  time: 0.3503  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [  30/3750]  eta: 0:22:25  Lr: 0.001875  Loss: -0.3164  Acc@1: 81.2500 (80.4435)  Acc@5: 100.0000 (97.9839)  time: 0.3522  data: 0.0006  max mem: 2503
Train: Epoch[4/5]  [  40/3750]  eta: 0:22:10  Lr: 0.001875  Loss: -0.9182  Acc@1: 81.2500 (80.9451)  Acc@5: 100.0000 (98.1707)  time: 0.3502  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [  50/3750]  eta: 0:21:59  Lr: 0.001875  Loss: -0.4215  Acc@1: 75.0000 (80.3922)  Acc@5: 100.0000 (98.4069)  time: 0.3485  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [  60/3750]  eta: 0:21:57  Lr: 0.001875  Loss: -0.5698  Acc@1: 75.0000 (79.0984)  Acc@5: 100.0000 (98.3607)  time: 0.3536  data: 0.0013  max mem: 2503
Train: Epoch[4/5]  [  70/3750]  eta: 0:21:53  Lr: 0.001875  Loss: -0.6202  Acc@1: 75.0000 (78.8732)  Acc@5: 100.0000 (98.2394)  time: 0.3576  data: 0.0016  max mem: 2503
Train: Epoch[4/5]  [  80/3750]  eta: 0:21:45  Lr: 0.001875  Loss: -0.5720  Acc@1: 81.2500 (78.4722)  Acc@5: 100.0000 (98.3796)  time: 0.3521  data: 0.0008  max mem: 2503
Train: Epoch[4/5]  [  90/3750]  eta: 0:21:39  Lr: 0.001875  Loss: -0.9412  Acc@1: 75.0000 (78.2280)  Acc@5: 100.0000 (98.4890)  time: 0.3484  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [ 100/3750]  eta: 0:21:33  Lr: 0.001875  Loss: -0.7657  Acc@1: 75.0000 (78.4653)  Acc@5: 100.0000 (98.6386)  time: 0.3492  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [ 110/3750]  eta: 0:21:30  Lr: 0.001875  Loss: -0.5788  Acc@1: 81.2500 (78.8851)  Acc@5: 100.0000 (98.7050)  time: 0.3522  data: 0.0010  max mem: 2503
Train: Epoch[4/5]  [ 120/3750]  eta: 0:21:24  Lr: 0.001875  Loss: 0.0387  Acc@1: 81.2500 (78.0475)  Acc@5: 100.0000 (98.7087)  time: 0.3512  data: 0.0010  max mem: 2503
Train: Epoch[4/5]  [ 130/3750]  eta: 0:21:19  Lr: 0.001875  Loss: -0.7063  Acc@1: 81.2500 (78.2920)  Acc@5: 100.0000 (98.7595)  time: 0.3485  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [ 140/3750]  eta: 0:21:14  Lr: 0.001875  Loss: -0.6658  Acc@1: 81.2500 (78.2801)  Acc@5: 100.0000 (98.8032)  time: 0.3487  data: 0.0003  max mem: 2503
Train: Epoch[4/5]  [ 150/3750]  eta: 0:21:10  Lr: 0.001875  Loss: -0.5053  Acc@1: 75.0000 (78.1043)  Acc@5: 100.0000 (98.6755)  time: 0.3490  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [ 160/3750]  eta: 0:21:06  Lr: 0.001875  Loss: -0.5378  Acc@1: 75.0000 (78.0668)  Acc@5: 100.0000 (98.6413)  time: 0.3494  data: 0.0010  max mem: 2503
Train: Epoch[4/5]  [ 170/3750]  eta: 0:21:01  Lr: 0.001875  Loss: -0.6571  Acc@1: 81.2500 (78.4357)  Acc@5: 100.0000 (98.6477)  time: 0.3475  data: 0.0010  max mem: 2503
Train: Epoch[4/5]  [ 180/3750]  eta: 0:20:56  Lr: 0.001875  Loss: -0.7197  Acc@1: 81.2500 (78.3840)  Acc@5: 100.0000 (98.5497)  time: 0.3463  data: 0.0003  max mem: 2503
Train: Epoch[4/5]  [ 190/3750]  eta: 0:20:52  Lr: 0.001875  Loss: -0.6609  Acc@1: 81.2500 (78.3704)  Acc@5: 100.0000 (98.5275)  time: 0.3489  data: 0.0009  max mem: 2503
Train: Epoch[4/5]  [ 200/3750]  eta: 0:20:48  Lr: 0.001875  Loss: -0.3279  Acc@1: 81.2500 (78.5137)  Acc@5: 100.0000 (98.6007)  time: 0.3491  data: 0.0009  max mem: 2503
Train: Epoch[4/5]  [ 210/3750]  eta: 0:20:44  Lr: 0.001875  Loss: -1.0224  Acc@1: 87.5000 (78.7618)  Acc@5: 100.0000 (98.6671)  time: 0.3485  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [ 220/3750]  eta: 0:20:41  Lr: 0.001875  Loss: 0.1923  Acc@1: 81.2500 (78.7048)  Acc@5: 100.0000 (98.6708)  time: 0.3507  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [ 230/3750]  eta: 0:20:38  Lr: 0.001875  Loss: -0.7969  Acc@1: 81.2500 (78.7608)  Acc@5: 100.0000 (98.7013)  time: 0.3526  data: 0.0008  max mem: 2503
Train: Epoch[4/5]  [ 240/3750]  eta: 0:20:34  Lr: 0.001875  Loss: -0.6842  Acc@1: 81.2500 (78.8900)  Acc@5: 100.0000 (98.7033)  time: 0.3538  data: 0.0008  max mem: 2503
Train: Epoch[4/5]  [ 250/3750]  eta: 0:20:31  Lr: 0.001875  Loss: -0.8437  Acc@1: 75.0000 (78.7849)  Acc@5: 100.0000 (98.7052)  time: 0.3531  data: 0.0006  max mem: 2503
Train: Epoch[4/5]  [ 260/3750]  eta: 0:20:28  Lr: 0.001875  Loss: -0.0302  Acc@1: 75.0000 (78.8793)  Acc@5: 100.0000 (98.6590)  time: 0.3540  data: 0.0007  max mem: 2503
Train: Epoch[4/5]  [ 270/3750]  eta: 0:20:24  Lr: 0.001875  Loss: -0.4227  Acc@1: 87.5000 (79.0821)  Acc@5: 100.0000 (98.6624)  time: 0.3524  data: 0.0006  max mem: 2503
Train: Epoch[4/5]  [ 280/3750]  eta: 0:20:21  Lr: 0.001875  Loss: -0.7741  Acc@1: 81.2500 (79.0925)  Acc@5: 100.0000 (98.6655)  time: 0.3515  data: 0.0010  max mem: 2503
Train: Epoch[4/5]  [ 290/3750]  eta: 0:20:17  Lr: 0.001875  Loss: -0.6811  Acc@1: 81.2500 (78.9734)  Acc@5: 100.0000 (98.6899)  time: 0.3519  data: 0.0011  max mem: 2503
Train: Epoch[4/5]  [ 300/3750]  eta: 0:20:13  Lr: 0.001875  Loss: 0.2832  Acc@1: 75.0000 (78.8621)  Acc@5: 100.0000 (98.6503)  time: 0.3493  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [ 310/3750]  eta: 0:20:09  Lr: 0.001875  Loss: -0.6738  Acc@1: 81.2500 (78.9188)  Acc@5: 100.0000 (98.6535)  time: 0.3487  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [ 320/3750]  eta: 0:20:06  Lr: 0.001875  Loss: -0.7113  Acc@1: 81.2500 (79.0304)  Acc@5: 100.0000 (98.6760)  time: 0.3502  data: 0.0017  max mem: 2503
Train: Epoch[4/5]  [ 330/3750]  eta: 0:20:02  Lr: 0.001875  Loss: -0.4525  Acc@1: 81.2500 (78.9841)  Acc@5: 100.0000 (98.6594)  time: 0.3522  data: 0.0020  max mem: 2503
Train: Epoch[4/5]  [ 340/3750]  eta: 0:19:58  Lr: 0.001875  Loss: -0.5330  Acc@1: 81.2500 (79.1422)  Acc@5: 100.0000 (98.6987)  time: 0.3502  data: 0.0007  max mem: 2503
Train: Epoch[4/5]  [ 350/3750]  eta: 0:19:55  Lr: 0.001875  Loss: -0.6379  Acc@1: 81.2500 (79.2023)  Acc@5: 100.0000 (98.6823)  time: 0.3488  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [ 360/3750]  eta: 0:19:51  Lr: 0.001875  Loss: -0.7799  Acc@1: 81.2500 (79.2763)  Acc@5: 100.0000 (98.6842)  time: 0.3483  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [ 370/3750]  eta: 0:19:47  Lr: 0.001875  Loss: -0.6404  Acc@1: 87.5000 (79.4980)  Acc@5: 100.0000 (98.6860)  time: 0.3491  data: 0.0006  max mem: 2503
Train: Epoch[4/5]  [ 380/3750]  eta: 0:19:43  Lr: 0.001875  Loss: -0.6006  Acc@1: 81.2500 (79.4455)  Acc@5: 100.0000 (98.6220)  time: 0.3485  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [ 390/3750]  eta: 0:19:39  Lr: 0.001875  Loss: -0.8724  Acc@1: 75.0000 (79.3958)  Acc@5: 100.0000 (98.6573)  time: 0.3460  data: 0.0003  max mem: 2503
Train: Epoch[4/5]  [ 400/3750]  eta: 0:19:36  Lr: 0.001875  Loss: -0.5004  Acc@1: 75.0000 (79.2706)  Acc@5: 100.0000 (98.6596)  time: 0.3479  data: 0.0003  max mem: 2503
Train: Epoch[4/5]  [ 410/3750]  eta: 0:19:32  Lr: 0.001875  Loss: 0.1654  Acc@1: 75.0000 (79.3644)  Acc@5: 100.0000 (98.6618)  time: 0.3515  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [ 420/3750]  eta: 0:19:29  Lr: 0.001875  Loss: -0.9047  Acc@1: 81.2500 (79.4388)  Acc@5: 100.0000 (98.6787)  time: 0.3519  data: 0.0006  max mem: 2503
Train: Epoch[4/5]  [ 430/3750]  eta: 0:19:25  Lr: 0.001875  Loss: -0.3410  Acc@1: 81.2500 (79.5534)  Acc@5: 100.0000 (98.6659)  time: 0.3507  data: 0.0007  max mem: 2503
Train: Epoch[4/5]  [ 440/3750]  eta: 0:19:22  Lr: 0.001875  Loss: -0.7200  Acc@1: 81.2500 (79.5351)  Acc@5: 100.0000 (98.6678)  time: 0.3500  data: 0.0006  max mem: 2503
Train: Epoch[4/5]  [ 450/3750]  eta: 0:19:18  Lr: 0.001875  Loss: -0.6664  Acc@1: 81.2500 (79.5039)  Acc@5: 100.0000 (98.6835)  time: 0.3521  data: 0.0006  max mem: 2503
Train: Epoch[4/5]  [ 460/3750]  eta: 0:19:15  Lr: 0.001875  Loss: -0.7123  Acc@1: 81.2500 (79.5146)  Acc@5: 100.0000 (98.7120)  time: 0.3535  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [ 470/3750]  eta: 0:19:11  Lr: 0.001875  Loss: -0.6229  Acc@1: 81.2500 (79.5382)  Acc@5: 100.0000 (98.6996)  time: 0.3506  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [ 480/3750]  eta: 0:19:08  Lr: 0.001875  Loss: -0.2001  Acc@1: 87.5000 (79.7167)  Acc@5: 100.0000 (98.7266)  time: 0.3509  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [ 490/3750]  eta: 0:19:04  Lr: 0.001875  Loss: -0.8113  Acc@1: 87.5000 (79.7225)  Acc@5: 100.0000 (98.7525)  time: 0.3512  data: 0.0006  max mem: 2503
Train: Epoch[4/5]  [ 500/3750]  eta: 0:19:01  Lr: 0.001875  Loss: -0.4726  Acc@1: 75.0000 (79.6407)  Acc@5: 100.0000 (98.7650)  time: 0.3507  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [ 510/3750]  eta: 0:18:57  Lr: 0.001875  Loss: -0.5220  Acc@1: 75.0000 (79.5254)  Acc@5: 100.0000 (98.7524)  time: 0.3533  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [ 520/3750]  eta: 0:18:54  Lr: 0.001875  Loss: -0.6914  Acc@1: 81.2500 (79.4986)  Acc@5: 100.0000 (98.7524)  time: 0.3516  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [ 530/3750]  eta: 0:18:50  Lr: 0.001875  Loss: -0.8389  Acc@1: 81.2500 (79.5080)  Acc@5: 100.0000 (98.7524)  time: 0.3486  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [ 540/3750]  eta: 0:18:47  Lr: 0.001875  Loss: -0.1993  Acc@1: 75.0000 (79.4824)  Acc@5: 100.0000 (98.7292)  time: 0.3501  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [ 550/3750]  eta: 0:18:43  Lr: 0.001875  Loss: -0.0945  Acc@1: 75.0000 (79.4578)  Acc@5: 100.0000 (98.7409)  time: 0.3500  data: 0.0003  max mem: 2503
Train: Epoch[4/5]  [ 560/3750]  eta: 0:18:39  Lr: 0.001875  Loss: -0.2287  Acc@1: 81.2500 (79.4340)  Acc@5: 100.0000 (98.7077)  time: 0.3472  data: 0.0003  max mem: 2503
Train: Epoch[4/5]  [ 570/3750]  eta: 0:18:35  Lr: 0.001875  Loss: -0.8329  Acc@1: 81.2500 (79.5096)  Acc@5: 100.0000 (98.7194)  time: 0.3457  data: 0.0003  max mem: 2503
Train: Epoch[4/5]  [ 580/3750]  eta: 0:18:32  Lr: 0.001875  Loss: -0.4947  Acc@1: 81.2500 (79.4966)  Acc@5: 100.0000 (98.7414)  time: 0.3493  data: 0.0003  max mem: 2503
Train: Epoch[4/5]  [ 590/3750]  eta: 0:18:28  Lr: 0.001875  Loss: -0.6666  Acc@1: 81.2500 (79.5368)  Acc@5: 100.0000 (98.7415)  time: 0.3508  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [ 600/3750]  eta: 0:18:25  Lr: 0.001875  Loss: -0.6841  Acc@1: 87.5000 (79.6173)  Acc@5: 100.0000 (98.7417)  time: 0.3500  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [ 610/3750]  eta: 0:18:21  Lr: 0.001875  Loss: -0.5002  Acc@1: 81.2500 (79.5929)  Acc@5: 100.0000 (98.7418)  time: 0.3499  data: 0.0006  max mem: 2503
Train: Epoch[4/5]  [ 620/3750]  eta: 0:18:18  Lr: 0.001875  Loss: -0.8602  Acc@1: 75.0000 (79.6296)  Acc@5: 100.0000 (98.7419)  time: 0.3529  data: 0.0020  max mem: 2503
Train: Epoch[4/5]  [ 630/3750]  eta: 0:18:15  Lr: 0.001875  Loss: -0.6618  Acc@1: 81.2500 (79.6454)  Acc@5: 100.0000 (98.7322)  time: 0.3561  data: 0.0021  max mem: 2503
Train: Epoch[4/5]  [ 640/3750]  eta: 0:18:11  Lr: 0.001875  Loss: -0.5048  Acc@1: 81.2500 (79.6022)  Acc@5: 100.0000 (98.7324)  time: 0.3514  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [ 650/3750]  eta: 0:18:07  Lr: 0.001875  Loss: -0.8139  Acc@1: 81.2500 (79.6083)  Acc@5: 100.0000 (98.7231)  time: 0.3483  data: 0.0006  max mem: 2503
Train: Epoch[4/5]  [ 660/3750]  eta: 0:18:04  Lr: 0.001875  Loss: -0.9890  Acc@1: 81.2500 (79.6520)  Acc@5: 100.0000 (98.7424)  time: 0.3491  data: 0.0007  max mem: 2503
Train: Epoch[4/5]  [ 670/3750]  eta: 0:18:01  Lr: 0.001875  Loss: -0.7520  Acc@1: 81.2500 (79.6759)  Acc@5: 100.0000 (98.7332)  time: 0.3536  data: 0.0009  max mem: 2503
Train: Epoch[4/5]  [ 680/3750]  eta: 0:17:57  Lr: 0.001875  Loss: -0.7398  Acc@1: 81.2500 (79.7357)  Acc@5: 100.0000 (98.7518)  time: 0.3544  data: 0.0009  max mem: 2503
Train: Epoch[4/5]  [ 690/3750]  eta: 0:17:54  Lr: 0.001875  Loss: -0.6921  Acc@1: 87.5000 (79.8571)  Acc@5: 100.0000 (98.7699)  time: 0.3498  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [ 700/3750]  eta: 0:17:50  Lr: 0.001875  Loss: -0.6868  Acc@1: 87.5000 (79.8859)  Acc@5: 100.0000 (98.7874)  time: 0.3493  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [ 710/3750]  eta: 0:17:46  Lr: 0.001875  Loss: -0.7885  Acc@1: 81.2500 (79.8787)  Acc@5: 100.0000 (98.7781)  time: 0.3497  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [ 720/3750]  eta: 0:17:43  Lr: 0.001875  Loss: -0.6909  Acc@1: 81.2500 (79.8544)  Acc@5: 100.0000 (98.7864)  time: 0.3504  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [ 730/3750]  eta: 0:17:39  Lr: 0.001875  Loss: -0.5653  Acc@1: 81.2500 (79.8478)  Acc@5: 100.0000 (98.7859)  time: 0.3488  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [ 740/3750]  eta: 0:17:35  Lr: 0.001875  Loss: -0.9658  Acc@1: 81.2500 (79.8583)  Acc@5: 100.0000 (98.7517)  time: 0.3456  data: 0.0003  max mem: 2503
Train: Epoch[4/5]  [ 750/3750]  eta: 0:17:32  Lr: 0.001875  Loss: -0.5134  Acc@1: 81.2500 (79.8269)  Acc@5: 100.0000 (98.7600)  time: 0.3458  data: 0.0003  max mem: 2503
Train: Epoch[4/5]  [ 760/3750]  eta: 0:17:28  Lr: 0.001875  Loss: -0.6477  Acc@1: 81.2500 (79.8210)  Acc@5: 100.0000 (98.7681)  time: 0.3469  data: 0.0008  max mem: 2503
Train: Epoch[4/5]  [ 770/3750]  eta: 0:17:24  Lr: 0.001875  Loss: -0.6754  Acc@1: 81.2500 (79.8881)  Acc@5: 100.0000 (98.7840)  time: 0.3461  data: 0.0008  max mem: 2503
Train: Epoch[4/5]  [ 780/3750]  eta: 0:17:21  Lr: 0.001875  Loss: -0.5777  Acc@1: 81.2500 (79.9296)  Acc@5: 100.0000 (98.7756)  time: 0.3466  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [ 790/3750]  eta: 0:17:18  Lr: 0.001875  Loss: -0.3972  Acc@1: 81.2500 (79.8752)  Acc@5: 100.0000 (98.7753)  time: 0.3534  data: 0.0007  max mem: 2503
Train: Epoch[4/5]  [ 800/3750]  eta: 0:17:14  Lr: 0.001875  Loss: -0.5882  Acc@1: 81.2500 (79.9625)  Acc@5: 100.0000 (98.7828)  time: 0.3572  data: 0.0006  max mem: 2503
Train: Epoch[4/5]  [ 810/3750]  eta: 0:17:11  Lr: 0.001875  Loss: -0.3664  Acc@1: 81.2500 (79.9091)  Acc@5: 100.0000 (98.7670)  time: 0.3555  data: 0.0006  max mem: 2503
Train: Epoch[4/5]  [ 820/3750]  eta: 0:17:07  Lr: 0.001875  Loss: -0.3310  Acc@1: 75.0000 (79.8569)  Acc@5: 100.0000 (98.7287)  time: 0.3536  data: 0.0007  max mem: 2503
Train: Epoch[4/5]  [ 830/3750]  eta: 0:17:04  Lr: 0.001875  Loss: -0.5289  Acc@1: 81.2500 (79.8285)  Acc@5: 100.0000 (98.7064)  time: 0.3504  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [ 840/3750]  eta: 0:17:00  Lr: 0.001875  Loss: -0.4574  Acc@1: 81.2500 (79.8380)  Acc@5: 100.0000 (98.7069)  time: 0.3513  data: 0.0007  max mem: 2503
Train: Epoch[4/5]  [ 850/3750]  eta: 0:16:57  Lr: 0.001875  Loss: -0.2891  Acc@1: 81.2500 (79.8546)  Acc@5: 100.0000 (98.7221)  time: 0.3521  data: 0.0013  max mem: 2503
Train: Epoch[4/5]  [ 860/3750]  eta: 0:16:53  Lr: 0.001875  Loss: -0.6964  Acc@1: 81.2500 (79.8418)  Acc@5: 100.0000 (98.7297)  time: 0.3507  data: 0.0010  max mem: 2503
Train: Epoch[4/5]  [ 870/3750]  eta: 0:16:50  Lr: 0.001875  Loss: -0.8222  Acc@1: 81.2500 (79.8794)  Acc@5: 100.0000 (98.7371)  time: 0.3495  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [ 880/3750]  eta: 0:16:46  Lr: 0.001875  Loss: -0.6833  Acc@1: 87.5000 (79.9447)  Acc@5: 100.0000 (98.7301)  time: 0.3492  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [ 890/3750]  eta: 0:16:43  Lr: 0.001875  Loss: -0.7022  Acc@1: 75.0000 (79.8822)  Acc@5: 100.0000 (98.7374)  time: 0.3496  data: 0.0008  max mem: 2503
Train: Epoch[4/5]  [ 900/3750]  eta: 0:16:39  Lr: 0.001875  Loss: -0.4278  Acc@1: 75.0000 (79.8349)  Acc@5: 100.0000 (98.7375)  time: 0.3485  data: 0.0008  max mem: 2503
Train: Epoch[4/5]  [ 910/3750]  eta: 0:16:36  Lr: 0.001875  Loss: -0.5723  Acc@1: 75.0000 (79.8093)  Acc@5: 100.0000 (98.7514)  time: 0.3483  data: 0.0003  max mem: 2503
Train: Epoch[4/5]  [ 920/3750]  eta: 0:16:32  Lr: 0.001875  Loss: -0.7663  Acc@1: 75.0000 (79.7774)  Acc@5: 100.0000 (98.7446)  time: 0.3476  data: 0.0006  max mem: 2503
Train: Epoch[4/5]  [ 930/3750]  eta: 0:16:28  Lr: 0.001875  Loss: -0.6588  Acc@1: 81.2500 (79.7865)  Acc@5: 100.0000 (98.7581)  time: 0.3469  data: 0.0008  max mem: 2503
Train: Epoch[4/5]  [ 940/3750]  eta: 0:16:25  Lr: 0.001875  Loss: -0.5831  Acc@1: 75.0000 (79.7024)  Acc@5: 100.0000 (98.7580)  time: 0.3463  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [ 950/3750]  eta: 0:16:21  Lr: 0.001875  Loss: -0.7677  Acc@1: 75.0000 (79.7187)  Acc@5: 100.0000 (98.7579)  time: 0.3460  data: 0.0002  max mem: 2503
Train: Epoch[4/5]  [ 960/3750]  eta: 0:16:17  Lr: 0.001875  Loss: -0.5716  Acc@1: 81.2500 (79.6956)  Acc@5: 100.0000 (98.7448)  time: 0.3461  data: 0.0003  max mem: 2503
Train: Epoch[4/5]  [ 970/3750]  eta: 0:16:14  Lr: 0.001875  Loss: -0.2001  Acc@1: 81.2500 (79.6923)  Acc@5: 100.0000 (98.7449)  time: 0.3465  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [ 980/3750]  eta: 0:16:10  Lr: 0.001875  Loss: -0.9230  Acc@1: 81.2500 (79.6572)  Acc@5: 100.0000 (98.7449)  time: 0.3500  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [ 990/3750]  eta: 0:16:07  Lr: 0.001875  Loss: -0.5185  Acc@1: 75.0000 (79.6481)  Acc@5: 100.0000 (98.7450)  time: 0.3511  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [1000/3750]  eta: 0:16:03  Lr: 0.001875  Loss: -0.8654  Acc@1: 81.2500 (79.6329)  Acc@5: 100.0000 (98.7575)  time: 0.3526  data: 0.0015  max mem: 2503
Train: Epoch[4/5]  [1010/3750]  eta: 0:16:00  Lr: 0.001875  Loss: -0.7420  Acc@1: 87.5000 (79.6860)  Acc@5: 100.0000 (98.7574)  time: 0.3557  data: 0.0018  max mem: 2503
Train: Epoch[4/5]  [1020/3750]  eta: 0:15:57  Lr: 0.001875  Loss: -0.4648  Acc@1: 87.5000 (79.7319)  Acc@5: 100.0000 (98.7573)  time: 0.3555  data: 0.0021  max mem: 2503
Train: Epoch[4/5]  [1030/3750]  eta: 0:15:53  Lr: 0.001875  Loss: -0.4984  Acc@1: 81.2500 (79.7587)  Acc@5: 100.0000 (98.7573)  time: 0.3531  data: 0.0018  max mem: 2503
Train: Epoch[4/5]  [1040/3750]  eta: 0:15:50  Lr: 0.001875  Loss: -0.8417  Acc@1: 87.5000 (79.8331)  Acc@5: 100.0000 (98.7572)  time: 0.3502  data: 0.0006  max mem: 2503
Train: Epoch[4/5]  [1050/3750]  eta: 0:15:46  Lr: 0.001875  Loss: -0.4830  Acc@1: 81.2500 (79.8228)  Acc@5: 100.0000 (98.7512)  time: 0.3546  data: 0.0009  max mem: 2503
Train: Epoch[4/5]  [1060/3750]  eta: 0:15:43  Lr: 0.001875  Loss: -0.7313  Acc@1: 75.0000 (79.8009)  Acc@5: 100.0000 (98.7512)  time: 0.3575  data: 0.0008  max mem: 2503
Train: Epoch[4/5]  [1070/3750]  eta: 0:15:39  Lr: 0.001875  Loss: -0.6984  Acc@1: 81.2500 (79.7852)  Acc@5: 100.0000 (98.7570)  time: 0.3518  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [1080/3750]  eta: 0:15:36  Lr: 0.001875  Loss: -0.6939  Acc@1: 81.2500 (79.8161)  Acc@5: 100.0000 (98.7512)  time: 0.3484  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [1090/3750]  eta: 0:15:32  Lr: 0.001875  Loss: -0.6691  Acc@1: 81.2500 (79.8465)  Acc@5: 100.0000 (98.7569)  time: 0.3503  data: 0.0011  max mem: 2503
Train: Epoch[4/5]  [1100/3750]  eta: 0:15:29  Lr: 0.001875  Loss: -0.7543  Acc@1: 81.2500 (79.8479)  Acc@5: 100.0000 (98.7625)  time: 0.3521  data: 0.0011  max mem: 2503
Train: Epoch[4/5]  [1110/3750]  eta: 0:15:25  Lr: 0.001875  Loss: -0.3938  Acc@1: 81.2500 (79.8436)  Acc@5: 100.0000 (98.7568)  time: 0.3496  data: 0.0008  max mem: 2503
Train: Epoch[4/5]  [1120/3750]  eta: 0:15:22  Lr: 0.001875  Loss: -0.1365  Acc@1: 81.2500 (79.8227)  Acc@5: 100.0000 (98.7511)  time: 0.3467  data: 0.0007  max mem: 2503
Train: Epoch[4/5]  [1130/3750]  eta: 0:15:18  Lr: 0.001875  Loss: -0.6704  Acc@1: 81.2500 (79.7966)  Acc@5: 100.0000 (98.7345)  time: 0.3479  data: 0.0003  max mem: 2503
Train: Epoch[4/5]  [1140/3750]  eta: 0:15:15  Lr: 0.001875  Loss: -0.6388  Acc@1: 81.2500 (79.7656)  Acc@5: 100.0000 (98.7401)  time: 0.3502  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [1150/3750]  eta: 0:15:11  Lr: 0.001875  Loss: -0.9252  Acc@1: 81.2500 (79.7187)  Acc@5: 100.0000 (98.7348)  time: 0.3496  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [1160/3750]  eta: 0:15:08  Lr: 0.001875  Loss: -0.9653  Acc@1: 75.0000 (79.6996)  Acc@5: 100.0000 (98.7242)  time: 0.3502  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [1170/3750]  eta: 0:15:04  Lr: 0.001875  Loss: -0.8416  Acc@1: 75.0000 (79.7289)  Acc@5: 100.0000 (98.7244)  time: 0.3530  data: 0.0006  max mem: 2503
Train: Epoch[4/5]  [1180/3750]  eta: 0:15:01  Lr: 0.001875  Loss: -0.4799  Acc@1: 75.0000 (79.7047)  Acc@5: 100.0000 (98.7299)  time: 0.3534  data: 0.0006  max mem: 2503
Train: Epoch[4/5]  [1190/3750]  eta: 0:14:57  Lr: 0.001875  Loss: -0.8009  Acc@1: 75.0000 (79.7177)  Acc@5: 100.0000 (98.7353)  time: 0.3529  data: 0.0006  max mem: 2503
Train: Epoch[4/5]  [1200/3750]  eta: 0:14:54  Lr: 0.001875  Loss: -0.4073  Acc@1: 75.0000 (79.6784)  Acc@5: 100.0000 (98.7354)  time: 0.3514  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [1210/3750]  eta: 0:14:50  Lr: 0.001875  Loss: -0.7100  Acc@1: 75.0000 (79.6810)  Acc@5: 100.0000 (98.7407)  time: 0.3506  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [1220/3750]  eta: 0:14:47  Lr: 0.001875  Loss: -0.6597  Acc@1: 81.2500 (79.6478)  Acc@5: 100.0000 (98.7459)  time: 0.3553  data: 0.0014  max mem: 2503
Train: Epoch[4/5]  [1230/3750]  eta: 0:14:44  Lr: 0.001875  Loss: -0.5291  Acc@1: 81.2500 (79.6507)  Acc@5: 100.0000 (98.7459)  time: 0.3612  data: 0.0014  max mem: 2503
Train: Epoch[4/5]  [1240/3750]  eta: 0:14:40  Lr: 0.001875  Loss: -0.4467  Acc@1: 81.2500 (79.6485)  Acc@5: 100.0000 (98.7409)  time: 0.3566  data: 0.0013  max mem: 2503
Train: Epoch[4/5]  [1250/3750]  eta: 0:14:37  Lr: 0.001875  Loss: -0.4866  Acc@1: 81.2500 (79.6513)  Acc@5: 100.0000 (98.7410)  time: 0.3489  data: 0.0012  max mem: 2503
Train: Epoch[4/5]  [1260/3750]  eta: 0:14:33  Lr: 0.001875  Loss: -0.8632  Acc@1: 81.2500 (79.6937)  Acc@5: 100.0000 (98.7460)  time: 0.3500  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [1270/3750]  eta: 0:14:30  Lr: 0.001875  Loss: -0.3564  Acc@1: 87.5000 (79.7010)  Acc@5: 100.0000 (98.7461)  time: 0.3522  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [1280/3750]  eta: 0:14:26  Lr: 0.001875  Loss: -0.9665  Acc@1: 81.2500 (79.6936)  Acc@5: 100.0000 (98.7363)  time: 0.3503  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [1290/3750]  eta: 0:14:22  Lr: 0.001875  Loss: -0.7171  Acc@1: 75.0000 (79.7153)  Acc@5: 100.0000 (98.7316)  time: 0.3474  data: 0.0003  max mem: 2503
Train: Epoch[4/5]  [1300/3750]  eta: 0:14:19  Lr: 0.001875  Loss: -0.3971  Acc@1: 81.2500 (79.7175)  Acc@5: 100.0000 (98.7221)  time: 0.3474  data: 0.0003  max mem: 2503
Train: Epoch[4/5]  [1310/3750]  eta: 0:14:15  Lr: 0.001875  Loss: -0.2923  Acc@1: 81.2500 (79.7054)  Acc@5: 100.0000 (98.7223)  time: 0.3488  data: 0.0018  max mem: 2503
Train: Epoch[4/5]  [1320/3750]  eta: 0:14:12  Lr: 0.001875  Loss: -0.9919  Acc@1: 81.2500 (79.7407)  Acc@5: 100.0000 (98.7226)  time: 0.3472  data: 0.0017  max mem: 2503
Train: Epoch[4/5]  [1330/3750]  eta: 0:14:08  Lr: 0.001875  Loss: -0.5680  Acc@1: 87.5000 (79.7662)  Acc@5: 100.0000 (98.7181)  time: 0.3469  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [1340/3750]  eta: 0:14:05  Lr: 0.001875  Loss: -0.8657  Acc@1: 81.2500 (79.7819)  Acc@5: 100.0000 (98.7136)  time: 0.3553  data: 0.0027  max mem: 2503
Train: Epoch[4/5]  [1350/3750]  eta: 0:14:01  Lr: 0.001875  Loss: -0.6781  Acc@1: 81.2500 (79.7002)  Acc@5: 100.0000 (98.7047)  time: 0.3558  data: 0.0027  max mem: 2503
Train: Epoch[4/5]  [1360/3750]  eta: 0:13:58  Lr: 0.001875  Loss: -0.9593  Acc@1: 75.0000 (79.6886)  Acc@5: 100.0000 (98.6958)  time: 0.3505  data: 0.0007  max mem: 2503
Train: Epoch[4/5]  [1370/3750]  eta: 0:13:54  Lr: 0.001875  Loss: -0.7416  Acc@1: 81.2500 (79.7137)  Acc@5: 100.0000 (98.7053)  time: 0.3529  data: 0.0007  max mem: 2503
Train: Epoch[4/5]  [1380/3750]  eta: 0:13:51  Lr: 0.001875  Loss: -0.5004  Acc@1: 75.0000 (79.6932)  Acc@5: 100.0000 (98.6830)  time: 0.3544  data: 0.0012  max mem: 2503
Train: Epoch[4/5]  [1390/3750]  eta: 0:13:48  Lr: 0.001875  Loss: -0.5963  Acc@1: 75.0000 (79.7043)  Acc@5: 100.0000 (98.6790)  time: 0.3540  data: 0.0013  max mem: 2503
Train: Epoch[4/5]  [1400/3750]  eta: 0:13:44  Lr: 0.001875  Loss: -0.5735  Acc@1: 81.2500 (79.6752)  Acc@5: 100.0000 (98.6795)  time: 0.3527  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [1410/3750]  eta: 0:13:41  Lr: 0.001875  Loss: -0.6670  Acc@1: 81.2500 (79.6820)  Acc@5: 100.0000 (98.6844)  time: 0.3518  data: 0.0006  max mem: 2503
Train: Epoch[4/5]  [1420/3750]  eta: 0:13:37  Lr: 0.001875  Loss: -0.5120  Acc@1: 81.2500 (79.6974)  Acc@5: 100.0000 (98.6849)  time: 0.3545  data: 0.0006  max mem: 2503
Train: Epoch[4/5]  [1430/3750]  eta: 0:13:34  Lr: 0.001875  Loss: -0.6782  Acc@1: 81.2500 (79.7213)  Acc@5: 100.0000 (98.6941)  time: 0.3538  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [1440/3750]  eta: 0:13:30  Lr: 0.001875  Loss: -0.5404  Acc@1: 81.2500 (79.7189)  Acc@5: 100.0000 (98.6945)  time: 0.3504  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [1450/3750]  eta: 0:13:27  Lr: 0.001875  Loss: -0.9176  Acc@1: 81.2500 (79.7080)  Acc@5: 100.0000 (98.6819)  time: 0.3497  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [1460/3750]  eta: 0:13:23  Lr: 0.001875  Loss: -0.4887  Acc@1: 81.2500 (79.7100)  Acc@5: 100.0000 (98.6781)  time: 0.3486  data: 0.0003  max mem: 2503
Train: Epoch[4/5]  [1470/3750]  eta: 0:13:20  Lr: 0.001875  Loss: -0.7094  Acc@1: 81.2500 (79.7034)  Acc@5: 100.0000 (98.6829)  time: 0.3485  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [1480/3750]  eta: 0:13:16  Lr: 0.001875  Loss: -0.6651  Acc@1: 81.2500 (79.7139)  Acc@5: 100.0000 (98.6875)  time: 0.3476  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [1490/3750]  eta: 0:13:12  Lr: 0.001875  Loss: -0.6914  Acc@1: 81.2500 (79.7284)  Acc@5: 100.0000 (98.6922)  time: 0.3460  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [1500/3750]  eta: 0:13:09  Lr: 0.001875  Loss: -0.7337  Acc@1: 81.2500 (79.7135)  Acc@5: 100.0000 (98.6925)  time: 0.3455  data: 0.0003  max mem: 2503
Train: Epoch[4/5]  [1510/3750]  eta: 0:13:05  Lr: 0.001875  Loss: -0.6286  Acc@1: 75.0000 (79.7030)  Acc@5: 100.0000 (98.7012)  time: 0.3473  data: 0.0006  max mem: 2503
Train: Epoch[4/5]  [1520/3750]  eta: 0:13:02  Lr: 0.001875  Loss: -0.5937  Acc@1: 81.2500 (79.7337)  Acc@5: 100.0000 (98.7015)  time: 0.3503  data: 0.0007  max mem: 2503
Train: Epoch[4/5]  [1530/3750]  eta: 0:12:58  Lr: 0.001875  Loss: -0.7715  Acc@1: 87.5000 (79.7681)  Acc@5: 100.0000 (98.7059)  time: 0.3510  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [1540/3750]  eta: 0:12:55  Lr: 0.001875  Loss: -0.4704  Acc@1: 81.2500 (79.7494)  Acc@5: 100.0000 (98.7021)  time: 0.3507  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [1550/3750]  eta: 0:12:51  Lr: 0.001875  Loss: -0.6729  Acc@1: 81.2500 (79.7510)  Acc@5: 100.0000 (98.7065)  time: 0.3534  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [1560/3750]  eta: 0:12:48  Lr: 0.001875  Loss: -0.8795  Acc@1: 75.0000 (79.7205)  Acc@5: 100.0000 (98.6947)  time: 0.3593  data: 0.0010  max mem: 2503
Train: Epoch[4/5]  [1570/3750]  eta: 0:12:44  Lr: 0.001875  Loss: -0.6698  Acc@1: 75.0000 (79.7104)  Acc@5: 100.0000 (98.6911)  time: 0.3567  data: 0.0017  max mem: 2503
Train: Epoch[4/5]  [1580/3750]  eta: 0:12:41  Lr: 0.001875  Loss: -0.3927  Acc@1: 81.2500 (79.7201)  Acc@5: 100.0000 (98.6875)  time: 0.3497  data: 0.0012  max mem: 2503
Train: Epoch[4/5]  [1590/3750]  eta: 0:12:37  Lr: 0.001875  Loss: -0.9854  Acc@1: 81.2500 (79.7297)  Acc@5: 100.0000 (98.6801)  time: 0.3481  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [1600/3750]  eta: 0:12:34  Lr: 0.001875  Loss: -0.3789  Acc@1: 81.2500 (79.7197)  Acc@5: 100.0000 (98.6766)  time: 0.3510  data: 0.0006  max mem: 2503
Train: Epoch[4/5]  [1610/3750]  eta: 0:12:30  Lr: 0.001875  Loss: -0.5687  Acc@1: 81.2500 (79.7059)  Acc@5: 100.0000 (98.6771)  time: 0.3555  data: 0.0012  max mem: 2503
Train: Epoch[4/5]  [1620/3750]  eta: 0:12:27  Lr: 0.001875  Loss: -0.5706  Acc@1: 81.2500 (79.7039)  Acc@5: 100.0000 (98.6737)  time: 0.3522  data: 0.0010  max mem: 2503
Train: Epoch[4/5]  [1630/3750]  eta: 0:12:23  Lr: 0.001875  Loss: -0.5573  Acc@1: 81.2500 (79.6980)  Acc@5: 100.0000 (98.6780)  time: 0.3489  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [1640/3750]  eta: 0:12:20  Lr: 0.001875  Loss: -0.9084  Acc@1: 81.2500 (79.6923)  Acc@5: 100.0000 (98.6822)  time: 0.3496  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [1650/3750]  eta: 0:12:16  Lr: 0.001875  Loss: -0.7184  Acc@1: 81.2500 (79.7093)  Acc@5: 100.0000 (98.6750)  time: 0.3500  data: 0.0013  max mem: 2503
Train: Epoch[4/5]  [1660/3750]  eta: 0:12:13  Lr: 0.001875  Loss: -0.5765  Acc@1: 75.0000 (79.6884)  Acc@5: 100.0000 (98.6755)  time: 0.3493  data: 0.0013  max mem: 2503
Train: Epoch[4/5]  [1670/3750]  eta: 0:12:09  Lr: 0.001875  Loss: -0.8094  Acc@1: 75.0000 (79.7015)  Acc@5: 100.0000 (98.6834)  time: 0.3464  data: 0.0003  max mem: 2503
Train: Epoch[4/5]  [1680/3750]  eta: 0:12:06  Lr: 0.001875  Loss: -0.8504  Acc@1: 81.2500 (79.7182)  Acc@5: 100.0000 (98.6838)  time: 0.3460  data: 0.0003  max mem: 2503
Train: Epoch[4/5]  [1690/3750]  eta: 0:12:02  Lr: 0.001875  Loss: -0.7600  Acc@1: 81.2500 (79.7235)  Acc@5: 100.0000 (98.6805)  time: 0.3489  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [1700/3750]  eta: 0:11:59  Lr: 0.001875  Loss: -0.8747  Acc@1: 81.2500 (79.7288)  Acc@5: 100.0000 (98.6809)  time: 0.3479  data: 0.0003  max mem: 2503
Train: Epoch[4/5]  [1710/3750]  eta: 0:11:55  Lr: 0.001875  Loss: -0.5127  Acc@1: 87.5000 (79.7450)  Acc@5: 100.0000 (98.6886)  time: 0.3469  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [1720/3750]  eta: 0:11:52  Lr: 0.001875  Loss: -0.3062  Acc@1: 81.2500 (79.7320)  Acc@5: 100.0000 (98.6963)  time: 0.3509  data: 0.0020  max mem: 2503
Train: Epoch[4/5]  [1730/3750]  eta: 0:11:48  Lr: 0.001875  Loss: -0.6631  Acc@1: 81.2500 (79.7263)  Acc@5: 100.0000 (98.6930)  time: 0.3555  data: 0.0038  max mem: 2503
Train: Epoch[4/5]  [1740/3750]  eta: 0:11:45  Lr: 0.001875  Loss: -0.8558  Acc@1: 81.2500 (79.7746)  Acc@5: 100.0000 (98.7005)  time: 0.3563  data: 0.0025  max mem: 2503
Train: Epoch[4/5]  [1750/3750]  eta: 0:11:41  Lr: 0.001875  Loss: -0.4585  Acc@1: 87.5000 (79.8115)  Acc@5: 100.0000 (98.7079)  time: 0.3534  data: 0.0007  max mem: 2503
Train: Epoch[4/5]  [1760/3750]  eta: 0:11:38  Lr: 0.001875  Loss: -0.4450  Acc@1: 81.2500 (79.8197)  Acc@5: 100.0000 (98.7081)  time: 0.3533  data: 0.0006  max mem: 2503
Train: Epoch[4/5]  [1770/3750]  eta: 0:11:34  Lr: 0.001875  Loss: -0.5725  Acc@1: 81.2500 (79.8172)  Acc@5: 100.0000 (98.7048)  time: 0.3528  data: 0.0012  max mem: 2503
Train: Epoch[4/5]  [1780/3750]  eta: 0:11:31  Lr: 0.001875  Loss: -0.8460  Acc@1: 81.2500 (79.8287)  Acc@5: 100.0000 (98.7086)  time: 0.3520  data: 0.0010  max mem: 2503
Train: Epoch[4/5]  [1790/3750]  eta: 0:11:27  Lr: 0.001875  Loss: -0.7289  Acc@1: 81.2500 (79.8332)  Acc@5: 100.0000 (98.7088)  time: 0.3523  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [1800/3750]  eta: 0:11:24  Lr: 0.001875  Loss: -0.5350  Acc@1: 75.0000 (79.8098)  Acc@5: 100.0000 (98.7160)  time: 0.3512  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [1810/3750]  eta: 0:11:20  Lr: 0.001875  Loss: -0.5715  Acc@1: 75.0000 (79.8040)  Acc@5: 100.0000 (98.7127)  time: 0.3492  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [1820/3750]  eta: 0:11:17  Lr: 0.001875  Loss: -0.7610  Acc@1: 81.2500 (79.8119)  Acc@5: 100.0000 (98.7129)  time: 0.3515  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [1830/3750]  eta: 0:11:13  Lr: 0.001875  Loss: -0.9057  Acc@1: 81.2500 (79.8232)  Acc@5: 100.0000 (98.7200)  time: 0.3515  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [1840/3750]  eta: 0:11:10  Lr: 0.001875  Loss: -0.8895  Acc@1: 81.2500 (79.8207)  Acc@5: 100.0000 (98.7269)  time: 0.3482  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [1850/3750]  eta: 0:11:06  Lr: 0.001875  Loss: -0.3789  Acc@1: 75.0000 (79.8048)  Acc@5: 100.0000 (98.7304)  time: 0.3469  data: 0.0003  max mem: 2503
Train: Epoch[4/5]  [1860/3750]  eta: 0:11:03  Lr: 0.001875  Loss: -0.4468  Acc@1: 81.2500 (79.7925)  Acc@5: 100.0000 (98.7272)  time: 0.3464  data: 0.0003  max mem: 2503
Train: Epoch[4/5]  [1870/3750]  eta: 0:10:59  Lr: 0.001875  Loss: -0.8014  Acc@1: 75.0000 (79.7835)  Acc@5: 100.0000 (98.7206)  time: 0.3465  data: 0.0003  max mem: 2503
Train: Epoch[4/5]  [1880/3750]  eta: 0:10:55  Lr: 0.001875  Loss: -0.6967  Acc@1: 75.0000 (79.7481)  Acc@5: 100.0000 (98.7241)  time: 0.3451  data: 0.0002  max mem: 2503
Train: Epoch[4/5]  [1890/3750]  eta: 0:10:52  Lr: 0.001875  Loss: -0.3020  Acc@1: 75.0000 (79.7164)  Acc@5: 100.0000 (98.7308)  time: 0.3469  data: 0.0003  max mem: 2503
Train: Epoch[4/5]  [1900/3750]  eta: 0:10:48  Lr: 0.001875  Loss: -0.6850  Acc@1: 81.2500 (79.7245)  Acc@5: 100.0000 (98.7309)  time: 0.3503  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [1910/3750]  eta: 0:10:45  Lr: 0.001875  Loss: -0.7721  Acc@1: 81.2500 (79.7227)  Acc@5: 100.0000 (98.7376)  time: 0.3519  data: 0.0006  max mem: 2503
Train: Epoch[4/5]  [1920/3750]  eta: 0:10:41  Lr: 0.001875  Loss: -0.1122  Acc@1: 75.0000 (79.7013)  Acc@5: 100.0000 (98.7344)  time: 0.3534  data: 0.0006  max mem: 2503
Train: Epoch[4/5]  [1930/3750]  eta: 0:10:38  Lr: 0.001875  Loss: -0.6699  Acc@1: 75.0000 (79.6932)  Acc@5: 100.0000 (98.7248)  time: 0.3534  data: 0.0007  max mem: 2503
Train: Epoch[4/5]  [1940/3750]  eta: 0:10:34  Lr: 0.001875  Loss: -0.6844  Acc@1: 81.2500 (79.6883)  Acc@5: 100.0000 (98.7281)  time: 0.3535  data: 0.0015  max mem: 2503
Train: Epoch[4/5]  [1950/3750]  eta: 0:10:31  Lr: 0.001875  Loss: -0.1474  Acc@1: 81.2500 (79.6963)  Acc@5: 100.0000 (98.7314)  time: 0.3546  data: 0.0013  max mem: 2503
Train: Epoch[4/5]  [1960/3750]  eta: 0:10:27  Lr: 0.001875  Loss: -0.8083  Acc@1: 81.2500 (79.7170)  Acc@5: 100.0000 (98.7347)  time: 0.3535  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [1970/3750]  eta: 0:10:24  Lr: 0.001875  Loss: -0.1324  Acc@1: 81.2500 (79.6804)  Acc@5: 100.0000 (98.7380)  time: 0.3515  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [1980/3750]  eta: 0:10:20  Lr: 0.001875  Loss: -0.7884  Acc@1: 81.2500 (79.7009)  Acc@5: 100.0000 (98.7412)  time: 0.3497  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [1990/3750]  eta: 0:10:17  Lr: 0.001875  Loss: -0.3179  Acc@1: 81.2500 (79.6961)  Acc@5: 100.0000 (98.7475)  time: 0.3489  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [2000/3750]  eta: 0:10:13  Lr: 0.001875  Loss: -0.8610  Acc@1: 81.2500 (79.7101)  Acc@5: 100.0000 (98.7506)  time: 0.3492  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [2010/3750]  eta: 0:10:10  Lr: 0.001875  Loss: -0.4830  Acc@1: 81.2500 (79.6960)  Acc@5: 100.0000 (98.7413)  time: 0.3486  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [2020/3750]  eta: 0:10:06  Lr: 0.001875  Loss: -0.5426  Acc@1: 75.0000 (79.6790)  Acc@5: 100.0000 (98.7413)  time: 0.3486  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [2030/3750]  eta: 0:10:03  Lr: 0.001875  Loss: -0.6822  Acc@1: 81.2500 (79.6837)  Acc@5: 100.0000 (98.7445)  time: 0.3481  data: 0.0003  max mem: 2503
Train: Epoch[4/5]  [2040/3750]  eta: 0:09:59  Lr: 0.001875  Loss: -0.7201  Acc@1: 81.2500 (79.7005)  Acc@5: 100.0000 (98.7445)  time: 0.3490  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [2050/3750]  eta: 0:09:56  Lr: 0.001875  Loss: -0.8500  Acc@1: 75.0000 (79.6654)  Acc@5: 100.0000 (98.7476)  time: 0.3478  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [2060/3750]  eta: 0:09:52  Lr: 0.001875  Loss: -0.2659  Acc@1: 75.0000 (79.6731)  Acc@5: 100.0000 (98.7445)  time: 0.3449  data: 0.0003  max mem: 2503
Train: Epoch[4/5]  [2070/3750]  eta: 0:09:49  Lr: 0.001875  Loss: -0.7009  Acc@1: 81.2500 (79.6686)  Acc@5: 100.0000 (98.7415)  time: 0.3533  data: 0.0021  max mem: 2503
Train: Epoch[4/5]  [2080/3750]  eta: 0:09:45  Lr: 0.001875  Loss: -0.4548  Acc@1: 81.2500 (79.6612)  Acc@5: 100.0000 (98.7416)  time: 0.3566  data: 0.0021  max mem: 2503
Train: Epoch[4/5]  [2090/3750]  eta: 0:09:42  Lr: 0.001875  Loss: -0.8005  Acc@1: 75.0000 (79.6539)  Acc@5: 100.0000 (98.7416)  time: 0.3504  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [2100/3750]  eta: 0:09:38  Lr: 0.001875  Loss: -0.6205  Acc@1: 81.2500 (79.6525)  Acc@5: 100.0000 (98.7387)  time: 0.3489  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [2110/3750]  eta: 0:09:35  Lr: 0.001875  Loss: -1.1232  Acc@1: 81.2500 (79.6542)  Acc@5: 100.0000 (98.7328)  time: 0.3512  data: 0.0006  max mem: 2503
Train: Epoch[4/5]  [2120/3750]  eta: 0:09:31  Lr: 0.001875  Loss: -0.3814  Acc@1: 81.2500 (79.6735)  Acc@5: 100.0000 (98.7359)  time: 0.3553  data: 0.0011  max mem: 2503
Train: Epoch[4/5]  [2130/3750]  eta: 0:09:28  Lr: 0.001875  Loss: -0.2756  Acc@1: 81.2500 (79.6750)  Acc@5: 100.0000 (98.7359)  time: 0.3553  data: 0.0009  max mem: 2503
Train: Epoch[4/5]  [2140/3750]  eta: 0:09:24  Lr: 0.001875  Loss: -0.4206  Acc@1: 81.2500 (79.6736)  Acc@5: 100.0000 (98.7360)  time: 0.3521  data: 0.0006  max mem: 2503
Train: Epoch[4/5]  [2150/3750]  eta: 0:09:21  Lr: 0.001875  Loss: -0.6797  Acc@1: 81.2500 (79.6722)  Acc@5: 100.0000 (98.7419)  time: 0.3514  data: 0.0006  max mem: 2503
Train: Epoch[4/5]  [2160/3750]  eta: 0:09:17  Lr: 0.001875  Loss: -0.4189  Acc@1: 75.0000 (79.6419)  Acc@5: 100.0000 (98.7448)  time: 0.3513  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [2170/3750]  eta: 0:09:14  Lr: 0.001875  Loss: -0.7599  Acc@1: 75.0000 (79.6378)  Acc@5: 100.0000 (98.7448)  time: 0.3502  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [2180/3750]  eta: 0:09:10  Lr: 0.001875  Loss: -0.7792  Acc@1: 81.2500 (79.6338)  Acc@5: 100.0000 (98.7391)  time: 0.3495  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [2190/3750]  eta: 0:09:07  Lr: 0.001875  Loss: -0.6767  Acc@1: 81.2500 (79.6354)  Acc@5: 100.0000 (98.7363)  time: 0.3486  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [2200/3750]  eta: 0:09:03  Lr: 0.001875  Loss: -0.3564  Acc@1: 81.2500 (79.6314)  Acc@5: 100.0000 (98.7335)  time: 0.3499  data: 0.0008  max mem: 2503
Train: Epoch[4/5]  [2210/3750]  eta: 0:09:00  Lr: 0.001875  Loss: -0.9262  Acc@1: 81.2500 (79.6727)  Acc@5: 100.0000 (98.7393)  time: 0.3490  data: 0.0008  max mem: 2503
Train: Epoch[4/5]  [2220/3750]  eta: 0:08:56  Lr: 0.001875  Loss: -0.0815  Acc@1: 81.2500 (79.6629)  Acc@5: 100.0000 (98.7393)  time: 0.3461  data: 0.0003  max mem: 2503
Train: Epoch[4/5]  [2230/3750]  eta: 0:08:53  Lr: 0.001875  Loss: -0.6391  Acc@1: 81.2500 (79.6672)  Acc@5: 100.0000 (98.7450)  time: 0.3458  data: 0.0003  max mem: 2503
Train: Epoch[4/5]  [2240/3750]  eta: 0:08:49  Lr: 0.001875  Loss: -0.5111  Acc@1: 81.2500 (79.6547)  Acc@5: 100.0000 (98.7450)  time: 0.3464  data: 0.0003  max mem: 2503
Train: Epoch[4/5]  [2250/3750]  eta: 0:08:46  Lr: 0.001875  Loss: -0.3202  Acc@1: 81.2500 (79.6563)  Acc@5: 100.0000 (98.7478)  time: 0.3481  data: 0.0006  max mem: 2503
Train: Epoch[4/5]  [2260/3750]  eta: 0:08:42  Lr: 0.001875  Loss: -0.5464  Acc@1: 81.2500 (79.6578)  Acc@5: 100.0000 (98.7506)  time: 0.3502  data: 0.0007  max mem: 2503
Train: Epoch[4/5]  [2270/3750]  eta: 0:08:39  Lr: 0.001875  Loss: -0.7048  Acc@1: 81.2500 (79.6620)  Acc@5: 100.0000 (98.7450)  time: 0.3506  data: 0.0006  max mem: 2503
Train: Epoch[4/5]  [2280/3750]  eta: 0:08:35  Lr: 0.001875  Loss: -0.4846  Acc@1: 81.2500 (79.6717)  Acc@5: 100.0000 (98.7505)  time: 0.3503  data: 0.0006  max mem: 2503
Train: Epoch[4/5]  [2290/3750]  eta: 0:08:31  Lr: 0.001875  Loss: -0.8617  Acc@1: 81.2500 (79.6650)  Acc@5: 100.0000 (98.7424)  time: 0.3502  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [2300/3750]  eta: 0:08:28  Lr: 0.001875  Loss: -0.7052  Acc@1: 75.0000 (79.6664)  Acc@5: 100.0000 (98.7424)  time: 0.3500  data: 0.0006  max mem: 2503
Train: Epoch[4/5]  [2310/3750]  eta: 0:08:24  Lr: 0.001875  Loss: -0.3459  Acc@1: 75.0000 (79.6652)  Acc@5: 100.0000 (98.7424)  time: 0.3507  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [2320/3750]  eta: 0:08:21  Lr: 0.001875  Loss: -0.3660  Acc@1: 81.2500 (79.6693)  Acc@5: 100.0000 (98.7452)  time: 0.3539  data: 0.0006  max mem: 2503
Train: Epoch[4/5]  [2330/3750]  eta: 0:08:17  Lr: 0.001875  Loss: -0.5736  Acc@1: 81.2500 (79.6627)  Acc@5: 100.0000 (98.7505)  time: 0.3534  data: 0.0006  max mem: 2503
Train: Epoch[4/5]  [2340/3750]  eta: 0:08:14  Lr: 0.001875  Loss: -0.9510  Acc@1: 75.0000 (79.6374)  Acc@5: 100.0000 (98.7399)  time: 0.3489  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [2350/3750]  eta: 0:08:10  Lr: 0.001875  Loss: -0.7085  Acc@1: 81.2500 (79.6549)  Acc@5: 100.0000 (98.7426)  time: 0.3494  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [2360/3750]  eta: 0:08:07  Lr: 0.001875  Loss: -0.4561  Acc@1: 81.2500 (79.6458)  Acc@5: 100.0000 (98.7452)  time: 0.3504  data: 0.0006  max mem: 2503
Train: Epoch[4/5]  [2370/3750]  eta: 0:08:03  Lr: 0.001875  Loss: -0.4872  Acc@1: 81.2500 (79.6473)  Acc@5: 100.0000 (98.7479)  time: 0.3504  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [2380/3750]  eta: 0:08:00  Lr: 0.001875  Loss: -0.5651  Acc@1: 81.2500 (79.6750)  Acc@5: 100.0000 (98.7400)  time: 0.3497  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [2390/3750]  eta: 0:07:56  Lr: 0.001875  Loss: -0.7493  Acc@1: 81.2500 (79.6633)  Acc@5: 100.0000 (98.7453)  time: 0.3480  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [2400/3750]  eta: 0:07:53  Lr: 0.001875  Loss: -0.3489  Acc@1: 75.0000 (79.6569)  Acc@5: 100.0000 (98.7453)  time: 0.3476  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [2410/3750]  eta: 0:07:49  Lr: 0.001875  Loss: -0.7251  Acc@1: 81.2500 (79.6661)  Acc@5: 100.0000 (98.7401)  time: 0.3470  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [2420/3750]  eta: 0:07:46  Lr: 0.001875  Loss: -0.9920  Acc@1: 81.2500 (79.6727)  Acc@5: 100.0000 (98.7376)  time: 0.3478  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [2430/3750]  eta: 0:07:42  Lr: 0.001875  Loss: -0.6222  Acc@1: 75.0000 (79.6637)  Acc@5: 100.0000 (98.7377)  time: 0.3485  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [2440/3750]  eta: 0:07:39  Lr: 0.001875  Loss: -0.5898  Acc@1: 81.2500 (79.6856)  Acc@5: 100.0000 (98.7428)  time: 0.3514  data: 0.0006  max mem: 2503
Train: Epoch[4/5]  [2450/3750]  eta: 0:07:35  Lr: 0.001875  Loss: 0.2955  Acc@1: 81.2500 (79.6741)  Acc@5: 100.0000 (98.7429)  time: 0.3571  data: 0.0007  max mem: 2503
Train: Epoch[4/5]  [2460/3750]  eta: 0:07:32  Lr: 0.001875  Loss: -0.1585  Acc@1: 81.2500 (79.6805)  Acc@5: 100.0000 (98.7403)  time: 0.3544  data: 0.0012  max mem: 2503
Train: Epoch[4/5]  [2470/3750]  eta: 0:07:28  Lr: 0.001875  Loss: -0.9598  Acc@1: 87.5000 (79.7147)  Acc@5: 100.0000 (98.7454)  time: 0.3526  data: 0.0012  max mem: 2503
Train: Epoch[4/5]  [2480/3750]  eta: 0:07:25  Lr: 0.001875  Loss: -0.2648  Acc@1: 81.2500 (79.6957)  Acc@5: 100.0000 (98.7480)  time: 0.3542  data: 0.0006  max mem: 2503
Train: Epoch[4/5]  [2490/3750]  eta: 0:07:21  Lr: 0.001875  Loss: -0.6797  Acc@1: 75.0000 (79.6919)  Acc@5: 100.0000 (98.7405)  time: 0.3519  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [2500/3750]  eta: 0:07:18  Lr: 0.001875  Loss: -0.5600  Acc@1: 81.2500 (79.7056)  Acc@5: 100.0000 (98.7430)  time: 0.3548  data: 0.0006  max mem: 2503
Train: Epoch[4/5]  [2510/3750]  eta: 0:07:14  Lr: 0.001875  Loss: -0.6705  Acc@1: 87.5000 (79.7217)  Acc@5: 100.0000 (98.7480)  time: 0.3548  data: 0.0006  max mem: 2503
Train: Epoch[4/5]  [2520/3750]  eta: 0:07:11  Lr: 0.001875  Loss: -0.0788  Acc@1: 81.2500 (79.7179)  Acc@5: 100.0000 (98.7480)  time: 0.3511  data: 0.0007  max mem: 2503
Train: Epoch[4/5]  [2530/3750]  eta: 0:07:07  Lr: 0.001875  Loss: -0.2256  Acc@1: 75.0000 (79.6918)  Acc@5: 100.0000 (98.7480)  time: 0.3508  data: 0.0008  max mem: 2503
Train: Epoch[4/5]  [2540/3750]  eta: 0:07:04  Lr: 0.001875  Loss: -0.7299  Acc@1: 75.0000 (79.6930)  Acc@5: 100.0000 (98.7530)  time: 0.3498  data: 0.0006  max mem: 2503
Train: Epoch[4/5]  [2550/3750]  eta: 0:07:00  Lr: 0.001875  Loss: -0.5200  Acc@1: 81.2500 (79.6869)  Acc@5: 100.0000 (98.7529)  time: 0.3498  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [2560/3750]  eta: 0:06:57  Lr: 0.001875  Loss: -0.6085  Acc@1: 75.0000 (79.6735)  Acc@5: 100.0000 (98.7554)  time: 0.3499  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [2570/3750]  eta: 0:06:53  Lr: 0.001875  Loss: -0.4089  Acc@1: 81.2500 (79.6747)  Acc@5: 100.0000 (98.7553)  time: 0.3484  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [2580/3750]  eta: 0:06:50  Lr: 0.001875  Loss: -0.5265  Acc@1: 81.2500 (79.6808)  Acc@5: 100.0000 (98.7553)  time: 0.3478  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [2590/3750]  eta: 0:06:46  Lr: 0.001875  Loss: -0.4491  Acc@1: 81.2500 (79.6965)  Acc@5: 100.0000 (98.7601)  time: 0.3473  data: 0.0003  max mem: 2503
Train: Epoch[4/5]  [2600/3750]  eta: 0:06:43  Lr: 0.001875  Loss: -0.8905  Acc@1: 81.2500 (79.6953)  Acc@5: 100.0000 (98.7601)  time: 0.3471  data: 0.0003  max mem: 2503
Train: Epoch[4/5]  [2610/3750]  eta: 0:06:39  Lr: 0.001875  Loss: -0.8578  Acc@1: 81.2500 (79.6773)  Acc@5: 100.0000 (98.7648)  time: 0.3485  data: 0.0009  max mem: 2503
Train: Epoch[4/5]  [2620/3750]  eta: 0:06:36  Lr: 0.001875  Loss: -0.7814  Acc@1: 81.2500 (79.6857)  Acc@5: 100.0000 (98.7648)  time: 0.3512  data: 0.0016  max mem: 2503
Train: Epoch[4/5]  [2630/3750]  eta: 0:06:32  Lr: 0.001875  Loss: -0.6012  Acc@1: 81.2500 (79.6964)  Acc@5: 100.0000 (98.7695)  time: 0.3550  data: 0.0012  max mem: 2503
Train: Epoch[4/5]  [2640/3750]  eta: 0:06:29  Lr: 0.001875  Loss: -0.7468  Acc@1: 81.2500 (79.6976)  Acc@5: 100.0000 (98.7718)  time: 0.3566  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [2650/3750]  eta: 0:06:25  Lr: 0.001875  Loss: -0.5867  Acc@1: 81.2500 (79.6963)  Acc@5: 100.0000 (98.7740)  time: 0.3569  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [2660/3750]  eta: 0:06:22  Lr: 0.001875  Loss: -0.8633  Acc@1: 81.2500 (79.6975)  Acc@5: 100.0000 (98.7787)  time: 0.3556  data: 0.0013  max mem: 2503
Train: Epoch[4/5]  [2670/3750]  eta: 0:06:18  Lr: 0.001875  Loss: -0.3472  Acc@1: 75.0000 (79.6869)  Acc@5: 100.0000 (98.7785)  time: 0.3551  data: 0.0016  max mem: 2503
Train: Epoch[4/5]  [2680/3750]  eta: 0:06:15  Lr: 0.001875  Loss: -0.9231  Acc@1: 81.2500 (79.7137)  Acc@5: 100.0000 (98.7761)  time: 0.3531  data: 0.0009  max mem: 2503
Train: Epoch[4/5]  [2690/3750]  eta: 0:06:11  Lr: 0.001875  Loss: -0.3027  Acc@1: 81.2500 (79.7032)  Acc@5: 100.0000 (98.7783)  time: 0.3522  data: 0.0006  max mem: 2503
Train: Epoch[4/5]  [2700/3750]  eta: 0:06:08  Lr: 0.001875  Loss: -0.6882  Acc@1: 81.2500 (79.6973)  Acc@5: 100.0000 (98.7759)  time: 0.3541  data: 0.0007  max mem: 2503
Train: Epoch[4/5]  [2710/3750]  eta: 0:06:04  Lr: 0.001875  Loss: -0.3425  Acc@1: 81.2500 (79.6915)  Acc@5: 100.0000 (98.7804)  time: 0.3516  data: 0.0007  max mem: 2503
Train: Epoch[4/5]  [2720/3750]  eta: 0:06:01  Lr: 0.001875  Loss: -0.8754  Acc@1: 81.2500 (79.7042)  Acc@5: 100.0000 (98.7849)  time: 0.3507  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [2730/3750]  eta: 0:05:57  Lr: 0.001875  Loss: -0.8749  Acc@1: 81.2500 (79.6984)  Acc@5: 100.0000 (98.7825)  time: 0.3516  data: 0.0003  max mem: 2503
Train: Epoch[4/5]  [2740/3750]  eta: 0:05:54  Lr: 0.001875  Loss: -1.0357  Acc@1: 81.2500 (79.7200)  Acc@5: 100.0000 (98.7869)  time: 0.3531  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [2750/3750]  eta: 0:05:50  Lr: 0.001875  Loss: -0.3768  Acc@1: 81.2500 (79.7187)  Acc@5: 100.0000 (98.7891)  time: 0.3539  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [2760/3750]  eta: 0:05:47  Lr: 0.001875  Loss: -0.8434  Acc@1: 75.0000 (79.6949)  Acc@5: 100.0000 (98.7889)  time: 0.3506  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [2770/3750]  eta: 0:05:43  Lr: 0.001875  Loss: -0.7849  Acc@1: 75.0000 (79.7005)  Acc@5: 100.0000 (98.7843)  time: 0.3485  data: 0.0003  max mem: 2503
Train: Epoch[4/5]  [2780/3750]  eta: 0:05:40  Lr: 0.001875  Loss: -0.7262  Acc@1: 81.2500 (79.6926)  Acc@5: 100.0000 (98.7842)  time: 0.3483  data: 0.0003  max mem: 2503
Train: Epoch[4/5]  [2790/3750]  eta: 0:05:36  Lr: 0.001875  Loss: -0.5710  Acc@1: 75.0000 (79.6937)  Acc@5: 100.0000 (98.7818)  time: 0.3496  data: 0.0003  max mem: 2503
Train: Epoch[4/5]  [2800/3750]  eta: 0:05:33  Lr: 0.001875  Loss: -0.7242  Acc@1: 75.0000 (79.6836)  Acc@5: 100.0000 (98.7817)  time: 0.3506  data: 0.0003  max mem: 2503
Train: Epoch[4/5]  [2810/3750]  eta: 0:05:29  Lr: 0.001875  Loss: -0.5044  Acc@1: 75.0000 (79.6758)  Acc@5: 100.0000 (98.7771)  time: 0.3504  data: 0.0003  max mem: 2503
Train: Epoch[4/5]  [2820/3750]  eta: 0:05:26  Lr: 0.001875  Loss: -0.4429  Acc@1: 75.0000 (79.6703)  Acc@5: 100.0000 (98.7792)  time: 0.3512  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [2830/3750]  eta: 0:05:22  Lr: 0.001875  Loss: -0.6906  Acc@1: 81.2500 (79.6693)  Acc@5: 100.0000 (98.7813)  time: 0.3552  data: 0.0006  max mem: 2503
Train: Epoch[4/5]  [2840/3750]  eta: 0:05:19  Lr: 0.001875  Loss: -0.5685  Acc@1: 81.2500 (79.6705)  Acc@5: 100.0000 (98.7812)  time: 0.3560  data: 0.0006  max mem: 2503
Train: Epoch[4/5]  [2850/3750]  eta: 0:05:15  Lr: 0.001875  Loss: -0.6555  Acc@1: 81.2500 (79.6913)  Acc@5: 100.0000 (98.7855)  time: 0.3527  data: 0.0007  max mem: 2503
Train: Epoch[4/5]  [2860/3750]  eta: 0:05:12  Lr: 0.001875  Loss: -0.4265  Acc@1: 87.5000 (79.7033)  Acc@5: 100.0000 (98.7788)  time: 0.3532  data: 0.0007  max mem: 2503
Train: Epoch[4/5]  [2870/3750]  eta: 0:05:08  Lr: 0.001875  Loss: -0.6204  Acc@1: 81.2500 (79.7196)  Acc@5: 100.0000 (98.7787)  time: 0.3552  data: 0.0015  max mem: 2503
Train: Epoch[4/5]  [2880/3750]  eta: 0:05:05  Lr: 0.001875  Loss: -0.7313  Acc@1: 81.2500 (79.7249)  Acc@5: 100.0000 (98.7808)  time: 0.3543  data: 0.0016  max mem: 2503
Train: Epoch[4/5]  [2890/3750]  eta: 0:05:01  Lr: 0.001875  Loss: -0.4306  Acc@1: 75.0000 (79.7151)  Acc@5: 100.0000 (98.7807)  time: 0.3576  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [2900/3750]  eta: 0:04:58  Lr: 0.001875  Loss: -0.5443  Acc@1: 75.0000 (79.7182)  Acc@5: 100.0000 (98.7827)  time: 0.3571  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [2910/3750]  eta: 0:04:54  Lr: 0.001875  Loss: -0.7412  Acc@1: 81.2500 (79.7342)  Acc@5: 100.0000 (98.7848)  time: 0.3510  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [2920/3750]  eta: 0:04:51  Lr: 0.001875  Loss: -0.1285  Acc@1: 81.2500 (79.7265)  Acc@5: 100.0000 (98.7804)  time: 0.3506  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [2930/3750]  eta: 0:04:47  Lr: 0.001875  Loss: -0.2912  Acc@1: 75.0000 (79.7339)  Acc@5: 100.0000 (98.7781)  time: 0.3509  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [2940/3750]  eta: 0:04:44  Lr: 0.001875  Loss: -0.6687  Acc@1: 81.2500 (79.7412)  Acc@5: 100.0000 (98.7781)  time: 0.3533  data: 0.0011  max mem: 2503
Train: Epoch[4/5]  [2950/3750]  eta: 0:04:40  Lr: 0.001875  Loss: -0.4955  Acc@1: 81.2500 (79.7272)  Acc@5: 100.0000 (98.7822)  time: 0.3512  data: 0.0009  max mem: 2503
Train: Epoch[4/5]  [2960/3750]  eta: 0:04:37  Lr: 0.001875  Loss: -0.6492  Acc@1: 81.2500 (79.7366)  Acc@5: 100.0000 (98.7842)  time: 0.3485  data: 0.0003  max mem: 2503
Train: Epoch[4/5]  [2970/3750]  eta: 0:04:33  Lr: 0.001875  Loss: -0.4360  Acc@1: 81.2500 (79.7375)  Acc@5: 100.0000 (98.7799)  time: 0.3507  data: 0.0008  max mem: 2503
Train: Epoch[4/5]  [2980/3750]  eta: 0:04:30  Lr: 0.001875  Loss: -0.8460  Acc@1: 81.2500 (79.7300)  Acc@5: 100.0000 (98.7819)  time: 0.3490  data: 0.0007  max mem: 2503
Train: Epoch[4/5]  [2990/3750]  eta: 0:04:26  Lr: 0.001875  Loss: -0.1134  Acc@1: 81.2500 (79.7246)  Acc@5: 100.0000 (98.7839)  time: 0.3508  data: 0.0003  max mem: 2503
Train: Epoch[4/5]  [3000/3750]  eta: 0:04:23  Lr: 0.001875  Loss: -0.6918  Acc@1: 75.0000 (79.7151)  Acc@5: 100.0000 (98.7796)  time: 0.3563  data: 0.0011  max mem: 2503
Train: Epoch[4/5]  [3010/3750]  eta: 0:04:19  Lr: 0.001875  Loss: -0.4758  Acc@1: 75.0000 (79.7140)  Acc@5: 100.0000 (98.7774)  time: 0.3542  data: 0.0011  max mem: 2503
Train: Epoch[4/5]  [3020/3750]  eta: 0:04:16  Lr: 0.001875  Loss: -0.9076  Acc@1: 81.2500 (79.6922)  Acc@5: 100.0000 (98.7794)  time: 0.3512  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [3030/3750]  eta: 0:04:12  Lr: 0.001875  Loss: -0.7802  Acc@1: 75.0000 (79.6787)  Acc@5: 100.0000 (98.7793)  time: 0.3553  data: 0.0012  max mem: 2503
Train: Epoch[4/5]  [3040/3750]  eta: 0:04:09  Lr: 0.001875  Loss: -0.8186  Acc@1: 81.2500 (79.6757)  Acc@5: 100.0000 (98.7833)  time: 0.3569  data: 0.0013  max mem: 2503
Train: Epoch[4/5]  [3050/3750]  eta: 0:04:05  Lr: 0.001875  Loss: -0.5208  Acc@1: 81.2500 (79.6788)  Acc@5: 100.0000 (98.7832)  time: 0.3539  data: 0.0006  max mem: 2503
Train: Epoch[4/5]  [3060/3750]  eta: 0:04:02  Lr: 0.001875  Loss: -0.9468  Acc@1: 81.2500 (79.6839)  Acc@5: 100.0000 (98.7872)  time: 0.3530  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [3070/3750]  eta: 0:03:58  Lr: 0.001875  Loss: -0.6416  Acc@1: 75.0000 (79.6727)  Acc@5: 100.0000 (98.7891)  time: 0.3535  data: 0.0009  max mem: 2503
Train: Epoch[4/5]  [3080/3750]  eta: 0:03:55  Lr: 0.001875  Loss: -0.2312  Acc@1: 75.0000 (79.6637)  Acc@5: 100.0000 (98.7869)  time: 0.3520  data: 0.0010  max mem: 2503
Train: Epoch[4/5]  [3090/3750]  eta: 0:03:51  Lr: 0.001875  Loss: -0.6041  Acc@1: 81.2500 (79.6749)  Acc@5: 100.0000 (98.7908)  time: 0.3493  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [3100/3750]  eta: 0:03:48  Lr: 0.001875  Loss: -0.8142  Acc@1: 87.5000 (79.7061)  Acc@5: 100.0000 (98.7947)  time: 0.3498  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [3110/3750]  eta: 0:03:44  Lr: 0.001875  Loss: -0.6909  Acc@1: 87.5000 (79.7191)  Acc@5: 100.0000 (98.7966)  time: 0.3508  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [3120/3750]  eta: 0:03:41  Lr: 0.001875  Loss: -0.4304  Acc@1: 81.2500 (79.7080)  Acc@5: 100.0000 (98.7965)  time: 0.3497  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [3130/3750]  eta: 0:03:37  Lr: 0.001875  Loss: -0.9575  Acc@1: 81.2500 (79.7130)  Acc@5: 100.0000 (98.7983)  time: 0.3488  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [3140/3750]  eta: 0:03:34  Lr: 0.001875  Loss: -0.8202  Acc@1: 81.2500 (79.7178)  Acc@5: 100.0000 (98.8021)  time: 0.3512  data: 0.0006  max mem: 2503
Train: Epoch[4/5]  [3150/3750]  eta: 0:03:30  Lr: 0.001875  Loss: -0.6004  Acc@1: 81.2500 (79.7029)  Acc@5: 100.0000 (98.8040)  time: 0.3496  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [3160/3750]  eta: 0:03:27  Lr: 0.001875  Loss: -0.2135  Acc@1: 81.2500 (79.7018)  Acc@5: 100.0000 (98.8058)  time: 0.3480  data: 0.0003  max mem: 2503
Train: Epoch[4/5]  [3170/3750]  eta: 0:03:23  Lr: 0.001875  Loss: -0.1769  Acc@1: 81.2500 (79.7047)  Acc@5: 100.0000 (98.8056)  time: 0.3541  data: 0.0017  max mem: 2503
Train: Epoch[4/5]  [3180/3750]  eta: 0:03:20  Lr: 0.001875  Loss: -0.7117  Acc@1: 81.2500 (79.6939)  Acc@5: 100.0000 (98.8054)  time: 0.3563  data: 0.0018  max mem: 2503
Train: Epoch[4/5]  [3190/3750]  eta: 0:03:16  Lr: 0.001875  Loss: -0.4474  Acc@1: 81.2500 (79.6988)  Acc@5: 100.0000 (98.8052)  time: 0.3523  data: 0.0008  max mem: 2503
Train: Epoch[4/5]  [3200/3750]  eta: 0:03:13  Lr: 0.001875  Loss: -0.8412  Acc@1: 81.2500 (79.7095)  Acc@5: 100.0000 (98.8051)  time: 0.3558  data: 0.0006  max mem: 2503
Train: Epoch[4/5]  [3210/3750]  eta: 0:03:09  Lr: 0.001875  Loss: -0.7129  Acc@1: 81.2500 (79.7182)  Acc@5: 100.0000 (98.8029)  time: 0.3614  data: 0.0035  max mem: 2503
Train: Epoch[4/5]  [3220/3750]  eta: 0:03:06  Lr: 0.001875  Loss: -0.5128  Acc@1: 81.2500 (79.7190)  Acc@5: 100.0000 (98.8028)  time: 0.3568  data: 0.0036  max mem: 2503
Train: Epoch[4/5]  [3230/3750]  eta: 0:03:02  Lr: 0.001875  Loss: -0.4703  Acc@1: 81.2500 (79.7180)  Acc@5: 100.0000 (98.8026)  time: 0.3521  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [3240/3750]  eta: 0:02:59  Lr: 0.001875  Loss: -0.7288  Acc@1: 75.0000 (79.7188)  Acc@5: 100.0000 (98.8025)  time: 0.3585  data: 0.0008  max mem: 2503
Train: Epoch[4/5]  [3250/3750]  eta: 0:02:55  Lr: 0.001875  Loss: -0.5669  Acc@1: 81.2500 (79.7408)  Acc@5: 100.0000 (98.8004)  time: 0.3648  data: 0.0008  max mem: 2503
Train: Epoch[4/5]  [3260/3750]  eta: 0:02:52  Lr: 0.001875  Loss: -0.8948  Acc@1: 81.2500 (79.7263)  Acc@5: 100.0000 (98.8040)  time: 0.3568  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [3270/3750]  eta: 0:02:48  Lr: 0.001875  Loss: -0.4424  Acc@1: 81.2500 (79.7310)  Acc@5: 100.0000 (98.8039)  time: 0.3492  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [3280/3750]  eta: 0:02:45  Lr: 0.001875  Loss: -0.3132  Acc@1: 81.2500 (79.7165)  Acc@5: 100.0000 (98.8056)  time: 0.3525  data: 0.0007  max mem: 2503
Train: Epoch[4/5]  [3290/3750]  eta: 0:02:41  Lr: 0.001875  Loss: -0.4857  Acc@1: 75.0000 (79.7041)  Acc@5: 100.0000 (98.8036)  time: 0.3532  data: 0.0007  max mem: 2503
Train: Epoch[4/5]  [3300/3750]  eta: 0:02:38  Lr: 0.001875  Loss: -0.7214  Acc@1: 75.0000 (79.6955)  Acc@5: 100.0000 (98.8053)  time: 0.3510  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [3310/3750]  eta: 0:02:34  Lr: 0.001875  Loss: -0.9801  Acc@1: 81.2500 (79.7210)  Acc@5: 100.0000 (98.8051)  time: 0.3504  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [3320/3750]  eta: 0:02:30  Lr: 0.001875  Loss: -0.8011  Acc@1: 81.2500 (79.7087)  Acc@5: 100.0000 (98.8050)  time: 0.3502  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [3330/3750]  eta: 0:02:27  Lr: 0.001875  Loss: -0.7408  Acc@1: 81.2500 (79.7189)  Acc@5: 100.0000 (98.8048)  time: 0.3496  data: 0.0003  max mem: 2503
Train: Epoch[4/5]  [3340/3750]  eta: 0:02:23  Lr: 0.001875  Loss: -0.7315  Acc@1: 81.2500 (79.7198)  Acc@5: 100.0000 (98.8065)  time: 0.3491  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [3350/3750]  eta: 0:02:20  Lr: 0.001875  Loss: -0.2598  Acc@1: 81.2500 (79.7020)  Acc@5: 100.0000 (98.8082)  time: 0.3498  data: 0.0015  max mem: 2503
Train: Epoch[4/5]  [3360/3750]  eta: 0:02:16  Lr: 0.001875  Loss: -0.7553  Acc@1: 81.2500 (79.7121)  Acc@5: 100.0000 (98.8117)  time: 0.3494  data: 0.0014  max mem: 2503
Train: Epoch[4/5]  [3370/3750]  eta: 0:02:13  Lr: 0.001875  Loss: -0.8214  Acc@1: 81.2500 (79.7204)  Acc@5: 100.0000 (98.8116)  time: 0.3541  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [3380/3750]  eta: 0:02:09  Lr: 0.001875  Loss: -0.7062  Acc@1: 81.2500 (79.7305)  Acc@5: 100.0000 (98.8132)  time: 0.3569  data: 0.0015  max mem: 2503
Train: Epoch[4/5]  [3390/3750]  eta: 0:02:06  Lr: 0.001875  Loss: -0.6596  Acc@1: 81.2500 (79.7257)  Acc@5: 100.0000 (98.8130)  time: 0.3552  data: 0.0016  max mem: 2503
Train: Epoch[4/5]  [3400/3750]  eta: 0:02:02  Lr: 0.001875  Loss: -0.1204  Acc@1: 75.0000 (79.7284)  Acc@5: 100.0000 (98.8165)  time: 0.3540  data: 0.0006  max mem: 2503
Train: Epoch[4/5]  [3410/3750]  eta: 0:01:59  Lr: 0.001875  Loss: -0.6836  Acc@1: 75.0000 (79.7255)  Acc@5: 100.0000 (98.8145)  time: 0.3553  data: 0.0006  max mem: 2503
Train: Epoch[4/5]  [3420/3750]  eta: 0:01:55  Lr: 0.001875  Loss: -0.1971  Acc@1: 75.0000 (79.7062)  Acc@5: 100.0000 (98.8088)  time: 0.3552  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [3430/3750]  eta: 0:01:52  Lr: 0.001875  Loss: -0.7110  Acc@1: 75.0000 (79.7180)  Acc@5: 100.0000 (98.8050)  time: 0.3527  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [3440/3750]  eta: 0:01:48  Lr: 0.001875  Loss: -0.9157  Acc@1: 81.2500 (79.7370)  Acc@5: 100.0000 (98.8030)  time: 0.3519  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [3450/3750]  eta: 0:01:45  Lr: 0.001875  Loss: -0.4576  Acc@1: 81.2500 (79.7269)  Acc@5: 100.0000 (98.8047)  time: 0.3511  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [3460/3750]  eta: 0:01:41  Lr: 0.001875  Loss: -0.5116  Acc@1: 75.0000 (79.7277)  Acc@5: 100.0000 (98.8045)  time: 0.3537  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [3470/3750]  eta: 0:01:38  Lr: 0.001875  Loss: -0.6867  Acc@1: 75.0000 (79.7123)  Acc@5: 100.0000 (98.8026)  time: 0.3531  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [3480/3750]  eta: 0:01:34  Lr: 0.001875  Loss: -0.6039  Acc@1: 81.2500 (79.7221)  Acc@5: 100.0000 (98.8060)  time: 0.3503  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [3490/3750]  eta: 0:01:31  Lr: 0.001875  Loss: -0.5524  Acc@1: 81.2500 (79.7032)  Acc@5: 100.0000 (98.8059)  time: 0.3520  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [3500/3750]  eta: 0:01:27  Lr: 0.001875  Loss: -0.9155  Acc@1: 75.0000 (79.6844)  Acc@5: 100.0000 (98.8057)  time: 0.3511  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [3510/3750]  eta: 0:01:24  Lr: 0.001875  Loss: -0.4200  Acc@1: 75.0000 (79.6888)  Acc@5: 100.0000 (98.8073)  time: 0.3487  data: 0.0003  max mem: 2503
Train: Epoch[4/5]  [3520/3750]  eta: 0:01:20  Lr: 0.001875  Loss: -0.7795  Acc@1: 81.2500 (79.6986)  Acc@5: 100.0000 (98.8089)  time: 0.3495  data: 0.0006  max mem: 2503
Train: Epoch[4/5]  [3530/3750]  eta: 0:01:17  Lr: 0.001875  Loss: -0.8601  Acc@1: 81.2500 (79.7012)  Acc@5: 100.0000 (98.8070)  time: 0.3496  data: 0.0006  max mem: 2503
Train: Epoch[4/5]  [3540/3750]  eta: 0:01:13  Lr: 0.001875  Loss: -0.4536  Acc@1: 81.2500 (79.6862)  Acc@5: 100.0000 (98.8051)  time: 0.3487  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [3550/3750]  eta: 0:01:10  Lr: 0.001875  Loss: -0.4774  Acc@1: 81.2500 (79.6888)  Acc@5: 100.0000 (98.8067)  time: 0.3525  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [3560/3750]  eta: 0:01:06  Lr: 0.001875  Loss: -0.6919  Acc@1: 81.2500 (79.6844)  Acc@5: 100.0000 (98.8065)  time: 0.3544  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [3570/3750]  eta: 0:01:03  Lr: 0.001875  Loss: -0.2128  Acc@1: 81.2500 (79.6871)  Acc@5: 100.0000 (98.8064)  time: 0.3519  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [3580/3750]  eta: 0:00:59  Lr: 0.001875  Loss: -0.8397  Acc@1: 81.2500 (79.6827)  Acc@5: 100.0000 (98.8027)  time: 0.3530  data: 0.0013  max mem: 2503
Train: Epoch[4/5]  [3590/3750]  eta: 0:00:56  Lr: 0.001875  Loss: -0.7083  Acc@1: 81.2500 (79.6940)  Acc@5: 100.0000 (98.8060)  time: 0.3559  data: 0.0024  max mem: 2503
Train: Epoch[4/5]  [3600/3750]  eta: 0:00:52  Lr: 0.001875  Loss: -0.8835  Acc@1: 81.2500 (79.6914)  Acc@5: 100.0000 (98.8094)  time: 0.3552  data: 0.0016  max mem: 2503
Train: Epoch[4/5]  [3610/3750]  eta: 0:00:49  Lr: 0.001875  Loss: -0.9165  Acc@1: 81.2500 (79.6905)  Acc@5: 100.0000 (98.8092)  time: 0.3521  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [3620/3750]  eta: 0:00:45  Lr: 0.001875  Loss: -0.8959  Acc@1: 81.2500 (79.7035)  Acc@5: 100.0000 (98.8125)  time: 0.3535  data: 0.0007  max mem: 2503
Train: Epoch[4/5]  [3630/3750]  eta: 0:00:42  Lr: 0.001875  Loss: -0.4294  Acc@1: 81.2500 (79.7026)  Acc@5: 100.0000 (98.8123)  time: 0.3557  data: 0.0020  max mem: 2503
Train: Epoch[4/5]  [3640/3750]  eta: 0:00:38  Lr: 0.001875  Loss: -0.7059  Acc@1: 81.2500 (79.7188)  Acc@5: 100.0000 (98.8104)  time: 0.3541  data: 0.0017  max mem: 2503
Train: Epoch[4/5]  [3650/3750]  eta: 0:00:35  Lr: 0.001875  Loss: -0.6191  Acc@1: 81.2500 (79.7093)  Acc@5: 100.0000 (98.8120)  time: 0.3528  data: 0.0006  max mem: 2503
Train: Epoch[4/5]  [3660/3750]  eta: 0:00:31  Lr: 0.001875  Loss: -1.0404  Acc@1: 81.2500 (79.7204)  Acc@5: 100.0000 (98.8135)  time: 0.3535  data: 0.0006  max mem: 2503
Train: Epoch[4/5]  [3670/3750]  eta: 0:00:28  Lr: 0.001875  Loss: -0.6121  Acc@1: 81.2500 (79.7211)  Acc@5: 100.0000 (98.8116)  time: 0.3541  data: 0.0013  max mem: 2503
Train: Epoch[4/5]  [3680/3750]  eta: 0:00:24  Lr: 0.001875  Loss: -0.1208  Acc@1: 75.0000 (79.7134)  Acc@5: 100.0000 (98.8149)  time: 0.3520  data: 0.0013  max mem: 2503
Train: Epoch[4/5]  [3690/3750]  eta: 0:00:21  Lr: 0.001875  Loss: -0.8467  Acc@1: 75.0000 (79.6972)  Acc@5: 100.0000 (98.8079)  time: 0.3500  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [3700/3750]  eta: 0:00:17  Lr: 0.001875  Loss: -0.8335  Acc@1: 75.0000 (79.6913)  Acc@5: 100.0000 (98.8044)  time: 0.3523  data: 0.0009  max mem: 2503
Train: Epoch[4/5]  [3710/3750]  eta: 0:00:14  Lr: 0.001875  Loss: -0.7046  Acc@1: 75.0000 (79.6938)  Acc@5: 100.0000 (98.8059)  time: 0.3506  data: 0.0007  max mem: 2503
Train: Epoch[4/5]  [3720/3750]  eta: 0:00:10  Lr: 0.001875  Loss: -0.6897  Acc@1: 81.2500 (79.7030)  Acc@5: 100.0000 (98.8074)  time: 0.3480  data: 0.0003  max mem: 2503
Train: Epoch[4/5]  [3730/3750]  eta: 0:00:07  Lr: 0.001875  Loss: -0.6193  Acc@1: 81.2500 (79.7089)  Acc@5: 100.0000 (98.8106)  time: 0.3499  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [3740/3750]  eta: 0:00:03  Lr: 0.001875  Loss: -0.6912  Acc@1: 81.2500 (79.7030)  Acc@5: 100.0000 (98.8088)  time: 0.3522  data: 0.0006  max mem: 2503
Train: Epoch[4/5]  [3749/3750]  eta: 0:00:00  Lr: 0.001875  Loss: -0.9890  Acc@1: 81.2500 (79.7050)  Acc@5: 100.0000 (98.8117)  time: 0.3531  data: 0.0010  max mem: 2503
Train: Epoch[4/5] Total time: 0:21:58 (0.3515 s / it)
{0: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 1: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 2: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 3: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 4: {0: 0, 1: 300000, 2: 0, 3: 91325, 4: 0}, 5: {0: 0, 1: 300000, 2: 0, 3: 91325, 4: 0}, 6: {0: 0, 1: 300000, 2: 0, 3: 91325, 4: 0}, 7: {0: 0, 1: 300000, 2: 0, 3: 91325, 4: 0}, 8: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 9: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 10: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 11: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 12: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 13: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 14: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 15: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 16: {0: 0, 1: 0, 2: 0, 3: 0, 4: 240000}, 17: {0: 0, 1: 0, 2: 0, 3: 0, 4: 240000}, 18: {0: 0, 1: 0, 2: 0, 3: 0, 4: 240000}, 19: {0: 0, 1: 0, 2: 0, 3: 0, 4: 240000}}
Averaged stats: Lr: 0.001875  Loss: -0.9890  Acc@1: 81.2500 (79.7050)  Acc@5: 100.0000 (98.8117)
Train: Epoch[5/5]  [   0/3750]  eta: 0:50:39  Lr: 0.001875  Loss: -0.8206  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (100.0000)  time: 0.8106  data: 0.4576  max mem: 2503
Train: Epoch[5/5]  [  10/3750]  eta: 0:25:05  Lr: 0.001875  Loss: -0.6495  Acc@1: 87.5000 (83.5227)  Acc@5: 100.0000 (100.0000)  time: 0.4025  data: 0.0428  max mem: 2503
Train: Epoch[5/5]  [  20/3750]  eta: 0:23:39  Lr: 0.001875  Loss: -0.0844  Acc@1: 75.0000 (80.3571)  Acc@5: 100.0000 (99.4048)  time: 0.3592  data: 0.0018  max mem: 2503
Train: Epoch[5/5]  [  30/3750]  eta: 0:23:04  Lr: 0.001875  Loss: -0.5033  Acc@1: 75.0000 (81.2500)  Acc@5: 100.0000 (99.5968)  time: 0.3557  data: 0.0015  max mem: 2503
Train: Epoch[5/5]  [  40/3750]  eta: 0:22:48  Lr: 0.001875  Loss: -0.5409  Acc@1: 81.2500 (80.3354)  Acc@5: 100.0000 (99.5427)  time: 0.3567  data: 0.0006  max mem: 2503
Train: Epoch[5/5]  [  50/3750]  eta: 0:22:42  Lr: 0.001875  Loss: -0.9446  Acc@1: 81.2500 (80.8824)  Acc@5: 100.0000 (99.3873)  time: 0.3616  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [  60/3750]  eta: 0:22:31  Lr: 0.001875  Loss: -0.2869  Acc@1: 81.2500 (80.3279)  Acc@5: 100.0000 (99.2828)  time: 0.3609  data: 0.0007  max mem: 2503
Train: Epoch[5/5]  [  70/3750]  eta: 0:22:19  Lr: 0.001875  Loss: -0.6241  Acc@1: 75.0000 (80.1937)  Acc@5: 100.0000 (98.9437)  time: 0.3531  data: 0.0006  max mem: 2503
Train: Epoch[5/5]  [  80/3750]  eta: 0:22:08  Lr: 0.001875  Loss: -0.5961  Acc@1: 81.2500 (80.3241)  Acc@5: 100.0000 (98.9198)  time: 0.3488  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [  90/3750]  eta: 0:22:00  Lr: 0.001875  Loss: -0.6930  Acc@1: 81.2500 (80.5632)  Acc@5: 100.0000 (99.0385)  time: 0.3503  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [ 100/3750]  eta: 0:21:53  Lr: 0.001875  Loss: -0.6498  Acc@1: 81.2500 (80.7550)  Acc@5: 100.0000 (99.0099)  time: 0.3512  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [ 110/3750]  eta: 0:21:46  Lr: 0.001875  Loss: -0.9699  Acc@1: 81.2500 (80.7432)  Acc@5: 100.0000 (98.9865)  time: 0.3504  data: 0.0011  max mem: 2503
Train: Epoch[5/5]  [ 120/3750]  eta: 0:21:40  Lr: 0.001875  Loss: -0.4638  Acc@1: 81.2500 (80.6302)  Acc@5: 100.0000 (99.0186)  time: 0.3494  data: 0.0011  max mem: 2503
Train: Epoch[5/5]  [ 130/3750]  eta: 0:21:33  Lr: 0.001875  Loss: -0.2593  Acc@1: 81.2500 (80.5821)  Acc@5: 100.0000 (99.0935)  time: 0.3482  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [ 140/3750]  eta: 0:21:27  Lr: 0.001875  Loss: -0.2860  Acc@1: 81.2500 (80.5851)  Acc@5: 100.0000 (99.0691)  time: 0.3474  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [ 150/3750]  eta: 0:21:22  Lr: 0.001875  Loss: -0.5751  Acc@1: 75.0000 (80.5464)  Acc@5: 100.0000 (99.0894)  time: 0.3483  data: 0.0006  max mem: 2503
Train: Epoch[5/5]  [ 160/3750]  eta: 0:21:16  Lr: 0.001875  Loss: -0.5765  Acc@1: 75.0000 (80.3571)  Acc@5: 100.0000 (99.0295)  time: 0.3493  data: 0.0006  max mem: 2503
Train: Epoch[5/5]  [ 170/3750]  eta: 0:21:12  Lr: 0.001875  Loss: -0.4225  Acc@1: 81.2500 (80.5921)  Acc@5: 100.0000 (98.9766)  time: 0.3494  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [ 180/3750]  eta: 0:21:08  Lr: 0.001875  Loss: -0.6404  Acc@1: 81.2500 (80.6630)  Acc@5: 100.0000 (98.9641)  time: 0.3515  data: 0.0006  max mem: 2503
Train: Epoch[5/5]  [ 190/3750]  eta: 0:21:05  Lr: 0.001875  Loss: -0.6164  Acc@1: 81.2500 (80.6610)  Acc@5: 100.0000 (98.9529)  time: 0.3550  data: 0.0006  max mem: 2503
Train: Epoch[5/5]  [ 200/3750]  eta: 0:21:01  Lr: 0.001875  Loss: -0.6939  Acc@1: 81.2500 (80.6903)  Acc@5: 100.0000 (98.9428)  time: 0.3550  data: 0.0007  max mem: 2503
Train: Epoch[5/5]  [ 210/3750]  eta: 0:20:57  Lr: 0.001875  Loss: -0.7715  Acc@1: 75.0000 (80.3318)  Acc@5: 100.0000 (98.9929)  time: 0.3529  data: 0.0006  max mem: 2503
Train: Epoch[5/5]  [ 220/3750]  eta: 0:20:53  Lr: 0.001875  Loss: -0.8948  Acc@1: 75.0000 (80.2602)  Acc@5: 100.0000 (98.9536)  time: 0.3530  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [ 230/3750]  eta: 0:20:50  Lr: 0.001875  Loss: -0.6078  Acc@1: 81.2500 (80.2219)  Acc@5: 100.0000 (98.9719)  time: 0.3556  data: 0.0010  max mem: 2503
Train: Epoch[5/5]  [ 240/3750]  eta: 0:20:46  Lr: 0.001875  Loss: -0.7477  Acc@1: 81.2500 (80.2127)  Acc@5: 100.0000 (98.9886)  time: 0.3560  data: 0.0012  max mem: 2503
Train: Epoch[5/5]  [ 250/3750]  eta: 0:20:42  Lr: 0.001875  Loss: -0.7243  Acc@1: 81.2500 (80.3536)  Acc@5: 100.0000 (99.0289)  time: 0.3516  data: 0.0006  max mem: 2503
Train: Epoch[5/5]  [ 260/3750]  eta: 0:20:37  Lr: 0.001875  Loss: -0.4488  Acc@1: 81.2500 (80.3161)  Acc@5: 100.0000 (99.0182)  time: 0.3499  data: 0.0003  max mem: 2503
Train: Epoch[5/5]  [ 270/3750]  eta: 0:20:33  Lr: 0.001875  Loss: -0.5411  Acc@1: 81.2500 (80.2122)  Acc@5: 100.0000 (99.0314)  time: 0.3511  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [ 280/3750]  eta: 0:20:29  Lr: 0.001875  Loss: -0.5429  Acc@1: 75.0000 (79.9377)  Acc@5: 100.0000 (99.0436)  time: 0.3512  data: 0.0006  max mem: 2503
Train: Epoch[5/5]  [ 290/3750]  eta: 0:20:26  Lr: 0.001875  Loss: -0.9476  Acc@1: 75.0000 (80.0258)  Acc@5: 100.0000 (99.0550)  time: 0.3515  data: 0.0006  max mem: 2503
Train: Epoch[5/5]  [ 300/3750]  eta: 0:20:21  Lr: 0.001875  Loss: -0.8134  Acc@1: 81.2500 (80.0872)  Acc@5: 100.0000 (99.0449)  time: 0.3503  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [ 310/3750]  eta: 0:20:17  Lr: 0.001875  Loss: -0.3627  Acc@1: 81.2500 (80.1648)  Acc@5: 100.0000 (99.0555)  time: 0.3485  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [ 320/3750]  eta: 0:20:13  Lr: 0.001875  Loss: -0.6049  Acc@1: 81.2500 (80.0428)  Acc@5: 100.0000 (99.0654)  time: 0.3496  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [ 330/3750]  eta: 0:20:10  Lr: 0.001875  Loss: -0.5574  Acc@1: 75.0000 (80.0038)  Acc@5: 100.0000 (98.9992)  time: 0.3520  data: 0.0010  max mem: 2503
Train: Epoch[5/5]  [ 340/3750]  eta: 0:20:06  Lr: 0.001875  Loss: -0.6040  Acc@1: 75.0000 (80.0037)  Acc@5: 100.0000 (99.0103)  time: 0.3515  data: 0.0010  max mem: 2503
Train: Epoch[5/5]  [ 350/3750]  eta: 0:20:02  Lr: 0.001875  Loss: -0.9656  Acc@1: 75.0000 (80.0570)  Acc@5: 100.0000 (99.0207)  time: 0.3511  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [ 360/3750]  eta: 0:19:59  Lr: 0.001875  Loss: -0.9991  Acc@1: 81.2500 (80.1247)  Acc@5: 100.0000 (99.0478)  time: 0.3527  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [ 370/3750]  eta: 0:19:55  Lr: 0.001875  Loss: -0.6679  Acc@1: 81.2500 (80.1550)  Acc@5: 100.0000 (99.0566)  time: 0.3554  data: 0.0007  max mem: 2503
Train: Epoch[5/5]  [ 380/3750]  eta: 0:19:52  Lr: 0.001875  Loss: -0.3050  Acc@1: 81.2500 (80.2001)  Acc@5: 100.0000 (99.0322)  time: 0.3552  data: 0.0007  max mem: 2503
Train: Epoch[5/5]  [ 390/3750]  eta: 0:19:49  Lr: 0.001875  Loss: -0.6598  Acc@1: 81.2500 (80.2749)  Acc@5: 100.0000 (99.0249)  time: 0.3554  data: 0.0006  max mem: 2503
Train: Epoch[5/5]  [ 400/3750]  eta: 0:19:45  Lr: 0.001875  Loss: -0.4258  Acc@1: 81.2500 (80.1901)  Acc@5: 100.0000 (98.9869)  time: 0.3576  data: 0.0006  max mem: 2503
Train: Epoch[5/5]  [ 410/3750]  eta: 0:19:42  Lr: 0.001875  Loss: -0.4149  Acc@1: 75.0000 (80.1551)  Acc@5: 100.0000 (98.9659)  time: 0.3557  data: 0.0006  max mem: 2503
Train: Epoch[5/5]  [ 420/3750]  eta: 0:19:38  Lr: 0.001875  Loss: -0.5777  Acc@1: 75.0000 (80.0772)  Acc@5: 100.0000 (98.9608)  time: 0.3527  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [ 430/3750]  eta: 0:19:35  Lr: 0.001875  Loss: -0.6598  Acc@1: 81.2500 (80.0319)  Acc@5: 100.0000 (98.9704)  time: 0.3574  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [ 440/3750]  eta: 0:19:32  Lr: 0.001875  Loss: -0.6412  Acc@1: 75.0000 (79.9745)  Acc@5: 100.0000 (98.8946)  time: 0.3584  data: 0.0012  max mem: 2503
Train: Epoch[5/5]  [ 450/3750]  eta: 0:19:28  Lr: 0.001875  Loss: -0.0499  Acc@1: 81.2500 (79.9751)  Acc@5: 100.0000 (98.8914)  time: 0.3532  data: 0.0010  max mem: 2503
Train: Epoch[5/5]  [ 460/3750]  eta: 0:19:24  Lr: 0.001875  Loss: -0.0701  Acc@1: 81.2500 (79.9485)  Acc@5: 100.0000 (98.8747)  time: 0.3526  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [ 470/3750]  eta: 0:19:21  Lr: 0.001875  Loss: -0.6864  Acc@1: 81.2500 (80.0292)  Acc@5: 100.0000 (98.8721)  time: 0.3521  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [ 480/3750]  eta: 0:19:17  Lr: 0.001875  Loss: -0.7701  Acc@1: 87.5000 (80.0156)  Acc@5: 100.0000 (98.8565)  time: 0.3540  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [ 490/3750]  eta: 0:19:13  Lr: 0.001875  Loss: -0.8739  Acc@1: 81.2500 (80.0280)  Acc@5: 100.0000 (98.8671)  time: 0.3523  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [ 500/3750]  eta: 0:19:10  Lr: 0.001875  Loss: -0.5247  Acc@1: 81.2500 (79.9900)  Acc@5: 100.0000 (98.8273)  time: 0.3501  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [ 510/3750]  eta: 0:19:06  Lr: 0.001875  Loss: -1.0156  Acc@1: 81.2500 (80.0024)  Acc@5: 100.0000 (98.8258)  time: 0.3505  data: 0.0007  max mem: 2503
Train: Epoch[5/5]  [ 520/3750]  eta: 0:19:02  Lr: 0.001875  Loss: -0.4705  Acc@1: 81.2500 (80.0264)  Acc@5: 100.0000 (98.8484)  time: 0.3495  data: 0.0006  max mem: 2503
Train: Epoch[5/5]  [ 530/3750]  eta: 0:18:58  Lr: 0.001875  Loss: -0.4590  Acc@1: 81.2500 (80.0259)  Acc@5: 100.0000 (98.8701)  time: 0.3510  data: 0.0008  max mem: 2503
Train: Epoch[5/5]  [ 540/3750]  eta: 0:18:55  Lr: 0.001875  Loss: -0.5313  Acc@1: 81.2500 (79.9677)  Acc@5: 100.0000 (98.8909)  time: 0.3527  data: 0.0009  max mem: 2503
Train: Epoch[5/5]  [ 550/3750]  eta: 0:18:51  Lr: 0.001875  Loss: -0.8220  Acc@1: 81.2500 (79.9909)  Acc@5: 100.0000 (98.8997)  time: 0.3524  data: 0.0006  max mem: 2503
Train: Epoch[5/5]  [ 560/3750]  eta: 0:18:48  Lr: 0.001875  Loss: -0.5742  Acc@1: 81.2500 (80.0134)  Acc@5: 100.0000 (98.8971)  time: 0.3533  data: 0.0007  max mem: 2503
Train: Epoch[5/5]  [ 570/3750]  eta: 0:18:44  Lr: 0.001875  Loss: -1.0435  Acc@1: 81.2500 (80.0350)  Acc@5: 100.0000 (98.9054)  time: 0.3567  data: 0.0006  max mem: 2503
Train: Epoch[5/5]  [ 580/3750]  eta: 0:18:41  Lr: 0.001875  Loss: -0.7699  Acc@1: 81.2500 (80.0344)  Acc@5: 100.0000 (98.9135)  time: 0.3560  data: 0.0006  max mem: 2503
Train: Epoch[5/5]  [ 590/3750]  eta: 0:18:37  Lr: 0.001875  Loss: -0.4056  Acc@1: 75.0000 (79.9915)  Acc@5: 100.0000 (98.9213)  time: 0.3525  data: 0.0006  max mem: 2503
Train: Epoch[5/5]  [ 600/3750]  eta: 0:18:34  Lr: 0.001875  Loss: -0.7731  Acc@1: 81.2500 (80.0957)  Acc@5: 100.0000 (98.9393)  time: 0.3525  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [ 610/3750]  eta: 0:18:31  Lr: 0.001875  Loss: -0.7309  Acc@1: 87.5000 (80.1657)  Acc@5: 100.0000 (98.9259)  time: 0.3599  data: 0.0009  max mem: 2503
Train: Epoch[5/5]  [ 620/3750]  eta: 0:18:27  Lr: 0.001875  Loss: -0.8495  Acc@1: 81.2500 (80.1731)  Acc@5: 100.0000 (98.9231)  time: 0.3585  data: 0.0010  max mem: 2503
Train: Epoch[5/5]  [ 630/3750]  eta: 0:18:23  Lr: 0.001875  Loss: -0.5564  Acc@1: 81.2500 (80.1803)  Acc@5: 100.0000 (98.9303)  time: 0.3501  data: 0.0007  max mem: 2503
Train: Epoch[5/5]  [ 640/3750]  eta: 0:18:20  Lr: 0.001875  Loss: -0.7902  Acc@1: 81.2500 (80.1287)  Acc@5: 100.0000 (98.9470)  time: 0.3527  data: 0.0008  max mem: 2503
Train: Epoch[5/5]  [ 650/3750]  eta: 0:18:16  Lr: 0.001875  Loss: -0.9245  Acc@1: 81.2500 (80.1651)  Acc@5: 100.0000 (98.9535)  time: 0.3529  data: 0.0006  max mem: 2503
Train: Epoch[5/5]  [ 660/3750]  eta: 0:18:12  Lr: 0.001875  Loss: -0.8965  Acc@1: 81.2500 (80.1910)  Acc@5: 100.0000 (98.9505)  time: 0.3501  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [ 670/3750]  eta: 0:18:09  Lr: 0.001875  Loss: -0.5497  Acc@1: 75.0000 (80.1136)  Acc@5: 100.0000 (98.9568)  time: 0.3487  data: 0.0003  max mem: 2503
Train: Epoch[5/5]  [ 680/3750]  eta: 0:18:05  Lr: 0.001875  Loss: -0.1893  Acc@1: 75.0000 (80.0753)  Acc@5: 100.0000 (98.9446)  time: 0.3496  data: 0.0009  max mem: 2503
Train: Epoch[5/5]  [ 690/3750]  eta: 0:18:01  Lr: 0.001875  Loss: -0.8996  Acc@1: 81.2500 (80.0380)  Acc@5: 100.0000 (98.9327)  time: 0.3512  data: 0.0009  max mem: 2503
Train: Epoch[5/5]  [ 700/3750]  eta: 0:17:58  Lr: 0.001875  Loss: -0.6165  Acc@1: 75.0000 (80.0464)  Acc@5: 100.0000 (98.9390)  time: 0.3532  data: 0.0003  max mem: 2503
Train: Epoch[5/5]  [ 710/3750]  eta: 0:17:54  Lr: 0.001875  Loss: -1.0102  Acc@1: 81.2500 (80.0633)  Acc@5: 100.0000 (98.9364)  time: 0.3542  data: 0.0009  max mem: 2503
Train: Epoch[5/5]  [ 720/3750]  eta: 0:17:51  Lr: 0.001875  Loss: -0.3958  Acc@1: 81.2500 (79.9671)  Acc@5: 100.0000 (98.9164)  time: 0.3530  data: 0.0011  max mem: 2503
Train: Epoch[5/5]  [ 730/3750]  eta: 0:17:47  Lr: 0.001875  Loss: -0.7957  Acc@1: 81.2500 (79.9675)  Acc@5: 100.0000 (98.9142)  time: 0.3521  data: 0.0007  max mem: 2503
Train: Epoch[5/5]  [ 740/3750]  eta: 0:17:44  Lr: 0.001875  Loss: -0.4129  Acc@1: 81.2500 (79.9342)  Acc@5: 100.0000 (98.9288)  time: 0.3536  data: 0.0012  max mem: 2503
Train: Epoch[5/5]  [ 750/3750]  eta: 0:17:40  Lr: 0.001875  Loss: -0.7806  Acc@1: 81.2500 (79.9850)  Acc@5: 100.0000 (98.9264)  time: 0.3547  data: 0.0012  max mem: 2503
Train: Epoch[5/5]  [ 760/3750]  eta: 0:17:37  Lr: 0.001875  Loss: -0.6295  Acc@1: 81.2500 (79.9524)  Acc@5: 100.0000 (98.9323)  time: 0.3532  data: 0.0013  max mem: 2503
Train: Epoch[5/5]  [ 770/3750]  eta: 0:17:33  Lr: 0.001875  Loss: -0.7186  Acc@1: 75.0000 (79.9287)  Acc@5: 100.0000 (98.9219)  time: 0.3559  data: 0.0013  max mem: 2503
Train: Epoch[5/5]  [ 780/3750]  eta: 0:17:30  Lr: 0.001875  Loss: -0.2613  Acc@1: 81.2500 (79.9616)  Acc@5: 100.0000 (98.9197)  time: 0.3589  data: 0.0008  max mem: 2503
Train: Epoch[5/5]  [ 790/3750]  eta: 0:17:27  Lr: 0.001875  Loss: -0.8012  Acc@1: 81.2500 (80.0332)  Acc@5: 100.0000 (98.9254)  time: 0.3601  data: 0.0010  max mem: 2503
Train: Epoch[5/5]  [ 800/3750]  eta: 0:17:23  Lr: 0.001875  Loss: -0.4391  Acc@1: 81.2500 (80.0328)  Acc@5: 100.0000 (98.9310)  time: 0.3551  data: 0.0007  max mem: 2503
Train: Epoch[5/5]  [ 810/3750]  eta: 0:17:19  Lr: 0.001875  Loss: -0.3464  Acc@1: 81.2500 (80.0786)  Acc@5: 100.0000 (98.9442)  time: 0.3508  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [ 820/3750]  eta: 0:17:16  Lr: 0.001875  Loss: -0.7143  Acc@1: 81.2500 (80.0320)  Acc@5: 100.0000 (98.9418)  time: 0.3523  data: 0.0007  max mem: 2503
Train: Epoch[5/5]  [ 830/3750]  eta: 0:17:12  Lr: 0.001875  Loss: -0.4722  Acc@1: 75.0000 (79.9940)  Acc@5: 100.0000 (98.9471)  time: 0.3520  data: 0.0007  max mem: 2503
Train: Epoch[5/5]  [ 840/3750]  eta: 0:17:09  Lr: 0.001875  Loss: -0.6111  Acc@1: 81.2500 (80.0163)  Acc@5: 100.0000 (98.9224)  time: 0.3502  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [ 850/3750]  eta: 0:17:05  Lr: 0.001875  Loss: -0.4164  Acc@1: 81.2500 (80.0308)  Acc@5: 100.0000 (98.9130)  time: 0.3509  data: 0.0013  max mem: 2503
Train: Epoch[5/5]  [ 860/3750]  eta: 0:17:01  Lr: 0.001875  Loss: -0.3833  Acc@1: 81.2500 (80.0232)  Acc@5: 100.0000 (98.9111)  time: 0.3523  data: 0.0014  max mem: 2503
Train: Epoch[5/5]  [ 870/3750]  eta: 0:16:58  Lr: 0.001875  Loss: -0.7033  Acc@1: 81.2500 (80.0588)  Acc@5: 100.0000 (98.9165)  time: 0.3494  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [ 880/3750]  eta: 0:16:54  Lr: 0.001875  Loss: -0.5127  Acc@1: 81.2500 (80.0936)  Acc@5: 100.0000 (98.9217)  time: 0.3492  data: 0.0003  max mem: 2503
Train: Epoch[5/5]  [ 890/3750]  eta: 0:16:50  Lr: 0.001875  Loss: -0.8751  Acc@1: 81.2500 (80.0786)  Acc@5: 100.0000 (98.9268)  time: 0.3518  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [ 900/3750]  eta: 0:16:47  Lr: 0.001875  Loss: -0.7850  Acc@1: 81.2500 (80.0985)  Acc@5: 100.0000 (98.9248)  time: 0.3522  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [ 910/3750]  eta: 0:16:43  Lr: 0.001875  Loss: -0.8893  Acc@1: 87.5000 (80.1660)  Acc@5: 100.0000 (98.9297)  time: 0.3525  data: 0.0007  max mem: 2503
Train: Epoch[5/5]  [ 920/3750]  eta: 0:16:40  Lr: 0.001875  Loss: -0.5837  Acc@1: 87.5000 (80.1642)  Acc@5: 100.0000 (98.9346)  time: 0.3573  data: 0.0009  max mem: 2503
Train: Epoch[5/5]  [ 930/3750]  eta: 0:16:37  Lr: 0.001875  Loss: -0.7069  Acc@1: 81.2500 (80.1826)  Acc@5: 100.0000 (98.9460)  time: 0.3582  data: 0.0009  max mem: 2503
Train: Epoch[5/5]  [ 940/3750]  eta: 0:16:33  Lr: 0.001875  Loss: -0.4294  Acc@1: 81.2500 (80.1674)  Acc@5: 100.0000 (98.9506)  time: 0.3541  data: 0.0008  max mem: 2503
Train: Epoch[5/5]  [ 950/3750]  eta: 0:16:29  Lr: 0.001875  Loss: -0.5096  Acc@1: 81.2500 (80.1459)  Acc@5: 100.0000 (98.9550)  time: 0.3540  data: 0.0007  max mem: 2503
Train: Epoch[5/5]  [ 960/3750]  eta: 0:16:26  Lr: 0.001875  Loss: -0.6693  Acc@1: 81.2500 (80.2029)  Acc@5: 100.0000 (98.9464)  time: 0.3569  data: 0.0016  max mem: 2503
Train: Epoch[5/5]  [ 970/3750]  eta: 0:16:23  Lr: 0.001875  Loss: -0.5917  Acc@1: 81.2500 (80.2073)  Acc@5: 100.0000 (98.9444)  time: 0.3572  data: 0.0013  max mem: 2503
Train: Epoch[5/5]  [ 980/3750]  eta: 0:16:19  Lr: 0.001875  Loss: -0.9852  Acc@1: 81.2500 (80.2306)  Acc@5: 100.0000 (98.9488)  time: 0.3535  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [ 990/3750]  eta: 0:16:15  Lr: 0.001875  Loss: -0.9360  Acc@1: 81.2500 (80.1842)  Acc@5: 100.0000 (98.9531)  time: 0.3520  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [1000/3750]  eta: 0:16:12  Lr: 0.001875  Loss: -0.6462  Acc@1: 81.2500 (80.2135)  Acc@5: 100.0000 (98.9635)  time: 0.3528  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [1010/3750]  eta: 0:16:08  Lr: 0.001875  Loss: -0.5625  Acc@1: 87.5000 (80.2485)  Acc@5: 100.0000 (98.9614)  time: 0.3528  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [1020/3750]  eta: 0:16:05  Lr: 0.001875  Loss: -0.8750  Acc@1: 87.5000 (80.2951)  Acc@5: 100.0000 (98.9716)  time: 0.3511  data: 0.0007  max mem: 2503
Train: Epoch[5/5]  [1030/3750]  eta: 0:16:01  Lr: 0.001875  Loss: -0.3712  Acc@1: 81.2500 (80.2558)  Acc@5: 100.0000 (98.9755)  time: 0.3520  data: 0.0006  max mem: 2503
Train: Epoch[5/5]  [1040/3750]  eta: 0:15:58  Lr: 0.001875  Loss: -0.8988  Acc@1: 81.2500 (80.2534)  Acc@5: 100.0000 (98.9673)  time: 0.3521  data: 0.0003  max mem: 2503
Train: Epoch[5/5]  [1050/3750]  eta: 0:15:54  Lr: 0.001875  Loss: -0.7844  Acc@1: 81.2500 (80.2569)  Acc@5: 100.0000 (98.9772)  time: 0.3497  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [1060/3750]  eta: 0:15:50  Lr: 0.001875  Loss: -0.5042  Acc@1: 81.2500 (80.2309)  Acc@5: 100.0000 (98.9809)  time: 0.3538  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [1070/3750]  eta: 0:15:47  Lr: 0.001875  Loss: -0.8626  Acc@1: 87.5000 (80.2930)  Acc@5: 100.0000 (98.9846)  time: 0.3546  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [1080/3750]  eta: 0:15:43  Lr: 0.001875  Loss: -0.4871  Acc@1: 81.2500 (80.2902)  Acc@5: 100.0000 (98.9824)  time: 0.3525  data: 0.0006  max mem: 2503
Train: Epoch[5/5]  [1090/3750]  eta: 0:15:40  Lr: 0.001875  Loss: -0.8006  Acc@1: 81.2500 (80.3162)  Acc@5: 100.0000 (98.9803)  time: 0.3537  data: 0.0007  max mem: 2503
Train: Epoch[5/5]  [1100/3750]  eta: 0:15:36  Lr: 0.001875  Loss: -0.6115  Acc@1: 81.2500 (80.2963)  Acc@5: 100.0000 (98.9782)  time: 0.3560  data: 0.0027  max mem: 2503
Train: Epoch[5/5]  [1110/3750]  eta: 0:15:33  Lr: 0.001875  Loss: -0.2445  Acc@1: 81.2500 (80.3330)  Acc@5: 100.0000 (98.9818)  time: 0.3558  data: 0.0027  max mem: 2503
Train: Epoch[5/5]  [1120/3750]  eta: 0:15:29  Lr: 0.001875  Loss: -0.5731  Acc@1: 87.5000 (80.3412)  Acc@5: 100.0000 (98.9797)  time: 0.3542  data: 0.0032  max mem: 2503
Train: Epoch[5/5]  [1130/3750]  eta: 0:15:26  Lr: 0.001875  Loss: -0.9502  Acc@1: 87.5000 (80.3658)  Acc@5: 100.0000 (98.9777)  time: 0.3558  data: 0.0046  max mem: 2503
Train: Epoch[5/5]  [1140/3750]  eta: 0:15:22  Lr: 0.001875  Loss: -0.4698  Acc@1: 75.0000 (80.3078)  Acc@5: 100.0000 (98.9812)  time: 0.3552  data: 0.0022  max mem: 2503
Train: Epoch[5/5]  [1150/3750]  eta: 0:15:19  Lr: 0.001875  Loss: -0.8505  Acc@1: 75.0000 (80.3215)  Acc@5: 100.0000 (98.9900)  time: 0.3523  data: 0.0008  max mem: 2503
Train: Epoch[5/5]  [1160/3750]  eta: 0:15:15  Lr: 0.001875  Loss: -0.5357  Acc@1: 81.2500 (80.3079)  Acc@5: 100.0000 (98.9879)  time: 0.3505  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [1170/3750]  eta: 0:15:12  Lr: 0.001875  Loss: -0.6888  Acc@1: 81.2500 (80.2786)  Acc@5: 100.0000 (98.9699)  time: 0.3518  data: 0.0011  max mem: 2503
Train: Epoch[5/5]  [1180/3750]  eta: 0:15:08  Lr: 0.001875  Loss: -0.9351  Acc@1: 81.2500 (80.2815)  Acc@5: 100.0000 (98.9627)  time: 0.3520  data: 0.0011  max mem: 2503
Train: Epoch[5/5]  [1190/3750]  eta: 0:15:04  Lr: 0.001875  Loss: -0.4764  Acc@1: 81.2500 (80.2582)  Acc@5: 100.0000 (98.9557)  time: 0.3493  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [1200/3750]  eta: 0:15:01  Lr: 0.001875  Loss: -0.6007  Acc@1: 81.2500 (80.2664)  Acc@5: 100.0000 (98.9488)  time: 0.3482  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [1210/3750]  eta: 0:14:57  Lr: 0.001875  Loss: -0.5930  Acc@1: 81.2500 (80.2436)  Acc@5: 100.0000 (98.9575)  time: 0.3480  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [1220/3750]  eta: 0:14:53  Lr: 0.001875  Loss: -0.2677  Acc@1: 75.0000 (80.2365)  Acc@5: 100.0000 (98.9609)  time: 0.3476  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [1230/3750]  eta: 0:14:50  Lr: 0.001875  Loss: -0.9929  Acc@1: 81.2500 (80.2803)  Acc@5: 100.0000 (98.9490)  time: 0.3477  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [1240/3750]  eta: 0:14:46  Lr: 0.001875  Loss: -1.0005  Acc@1: 81.2500 (80.2679)  Acc@5: 100.0000 (98.9525)  time: 0.3487  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [1250/3750]  eta: 0:14:43  Lr: 0.001875  Loss: -0.6319  Acc@1: 75.0000 (80.2658)  Acc@5: 100.0000 (98.9558)  time: 0.3515  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [1260/3750]  eta: 0:14:39  Lr: 0.001875  Loss: -0.8104  Acc@1: 75.0000 (80.2587)  Acc@5: 100.0000 (98.9641)  time: 0.3550  data: 0.0017  max mem: 2503
Train: Epoch[5/5]  [1270/3750]  eta: 0:14:36  Lr: 0.001875  Loss: -0.2974  Acc@1: 75.0000 (80.2272)  Acc@5: 100.0000 (98.9624)  time: 0.3549  data: 0.0018  max mem: 2503
Train: Epoch[5/5]  [1280/3750]  eta: 0:14:32  Lr: 0.001875  Loss: -0.1921  Acc@1: 75.0000 (80.2157)  Acc@5: 100.0000 (98.9657)  time: 0.3538  data: 0.0006  max mem: 2503
Train: Epoch[5/5]  [1290/3750]  eta: 0:14:29  Lr: 0.001875  Loss: -0.5892  Acc@1: 81.2500 (80.2188)  Acc@5: 100.0000 (98.9591)  time: 0.3540  data: 0.0006  max mem: 2503
Train: Epoch[5/5]  [1300/3750]  eta: 0:14:25  Lr: 0.001875  Loss: -0.8741  Acc@1: 81.2500 (80.2027)  Acc@5: 100.0000 (98.9671)  time: 0.3531  data: 0.0006  max mem: 2503
Train: Epoch[5/5]  [1310/3750]  eta: 0:14:21  Lr: 0.001875  Loss: -0.7928  Acc@1: 81.2500 (80.2203)  Acc@5: 100.0000 (98.9559)  time: 0.3522  data: 0.0006  max mem: 2503
Train: Epoch[5/5]  [1320/3750]  eta: 0:14:18  Lr: 0.001875  Loss: -0.0700  Acc@1: 81.2500 (80.2044)  Acc@5: 100.0000 (98.9591)  time: 0.3510  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [1330/3750]  eta: 0:14:14  Lr: 0.001875  Loss: -0.5216  Acc@1: 81.2500 (80.2310)  Acc@5: 100.0000 (98.9622)  time: 0.3499  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [1340/3750]  eta: 0:14:11  Lr: 0.001875  Loss: -0.6935  Acc@1: 81.2500 (80.2107)  Acc@5: 100.0000 (98.9607)  time: 0.3498  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [1350/3750]  eta: 0:14:07  Lr: 0.001875  Loss: -0.9400  Acc@1: 81.2500 (80.2554)  Acc@5: 100.0000 (98.9637)  time: 0.3513  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [1360/3750]  eta: 0:14:04  Lr: 0.001875  Loss: -0.6212  Acc@1: 87.5000 (80.2810)  Acc@5: 100.0000 (98.9713)  time: 0.3511  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [1370/3750]  eta: 0:14:00  Lr: 0.001875  Loss: -0.7423  Acc@1: 87.5000 (80.2972)  Acc@5: 100.0000 (98.9743)  time: 0.3523  data: 0.0011  max mem: 2503
Train: Epoch[5/5]  [1380/3750]  eta: 0:13:56  Lr: 0.001875  Loss: -0.7020  Acc@1: 87.5000 (80.3222)  Acc@5: 100.0000 (98.9817)  time: 0.3513  data: 0.0015  max mem: 2503
Train: Epoch[5/5]  [1390/3750]  eta: 0:13:53  Lr: 0.001875  Loss: -0.5999  Acc@1: 81.2500 (80.2930)  Acc@5: 100.0000 (98.9711)  time: 0.3488  data: 0.0008  max mem: 2503
Train: Epoch[5/5]  [1400/3750]  eta: 0:13:49  Lr: 0.001875  Loss: -0.7884  Acc@1: 75.0000 (80.2641)  Acc@5: 100.0000 (98.9739)  time: 0.3508  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [1410/3750]  eta: 0:13:46  Lr: 0.001875  Loss: -0.4173  Acc@1: 75.0000 (80.2755)  Acc@5: 100.0000 (98.9724)  time: 0.3510  data: 0.0003  max mem: 2503
Train: Epoch[5/5]  [1420/3750]  eta: 0:13:42  Lr: 0.001875  Loss: -1.0178  Acc@1: 81.2500 (80.2560)  Acc@5: 100.0000 (98.9752)  time: 0.3520  data: 0.0003  max mem: 2503
Train: Epoch[5/5]  [1430/3750]  eta: 0:13:39  Lr: 0.001875  Loss: -0.7407  Acc@1: 81.2500 (80.2673)  Acc@5: 100.0000 (98.9824)  time: 0.3599  data: 0.0006  max mem: 2503
Train: Epoch[5/5]  [1440/3750]  eta: 0:13:35  Lr: 0.001875  Loss: -0.4854  Acc@1: 81.2500 (80.2307)  Acc@5: 100.0000 (98.9851)  time: 0.3584  data: 0.0009  max mem: 2503
Train: Epoch[5/5]  [1450/3750]  eta: 0:13:32  Lr: 0.001875  Loss: -0.0454  Acc@1: 81.2500 (80.2205)  Acc@5: 100.0000 (98.9921)  time: 0.3526  data: 0.0008  max mem: 2503
Train: Epoch[5/5]  [1460/3750]  eta: 0:13:28  Lr: 0.001875  Loss: -0.3652  Acc@1: 81.2500 (80.1934)  Acc@5: 100.0000 (98.9947)  time: 0.3555  data: 0.0006  max mem: 2503
Train: Epoch[5/5]  [1470/3750]  eta: 0:13:25  Lr: 0.001875  Loss: -0.8824  Acc@1: 87.5000 (80.2388)  Acc@5: 100.0000 (98.9845)  time: 0.3580  data: 0.0007  max mem: 2503
Train: Epoch[5/5]  [1480/3750]  eta: 0:13:21  Lr: 0.001875  Loss: -0.5307  Acc@1: 81.2500 (80.2203)  Acc@5: 100.0000 (98.9872)  time: 0.3589  data: 0.0020  max mem: 2503
Train: Epoch[5/5]  [1490/3750]  eta: 0:13:18  Lr: 0.001875  Loss: -0.8401  Acc@1: 81.2500 (80.2272)  Acc@5: 100.0000 (98.9898)  time: 0.3575  data: 0.0019  max mem: 2503
Train: Epoch[5/5]  [1500/3750]  eta: 0:13:14  Lr: 0.001875  Loss: -0.7447  Acc@1: 75.0000 (80.2215)  Acc@5: 100.0000 (98.9965)  time: 0.3544  data: 0.0006  max mem: 2503
Train: Epoch[5/5]  [1510/3750]  eta: 0:13:11  Lr: 0.001875  Loss: -0.6219  Acc@1: 81.2500 (80.2201)  Acc@5: 100.0000 (98.9949)  time: 0.3546  data: 0.0008  max mem: 2503
Train: Epoch[5/5]  [1520/3750]  eta: 0:13:07  Lr: 0.001875  Loss: -0.0025  Acc@1: 81.2500 (80.1940)  Acc@5: 100.0000 (98.9892)  time: 0.3536  data: 0.0006  max mem: 2503
Train: Epoch[5/5]  [1530/3750]  eta: 0:13:04  Lr: 0.001875  Loss: -0.5063  Acc@1: 75.0000 (80.1764)  Acc@5: 100.0000 (98.9876)  time: 0.3530  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [1540/3750]  eta: 0:13:00  Lr: 0.001875  Loss: -0.1504  Acc@1: 75.0000 (80.1752)  Acc@5: 100.0000 (98.9779)  time: 0.3543  data: 0.0008  max mem: 2503
Train: Epoch[5/5]  [1550/3750]  eta: 0:12:57  Lr: 0.001875  Loss: -0.3038  Acc@1: 75.0000 (80.1499)  Acc@5: 100.0000 (98.9805)  time: 0.3525  data: 0.0007  max mem: 2503
Train: Epoch[5/5]  [1560/3750]  eta: 0:12:53  Lr: 0.001875  Loss: -0.4538  Acc@1: 81.2500 (80.1770)  Acc@5: 100.0000 (98.9830)  time: 0.3533  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [1570/3750]  eta: 0:12:50  Lr: 0.001875  Loss: -0.6435  Acc@1: 81.2500 (80.1639)  Acc@5: 100.0000 (98.9776)  time: 0.3523  data: 0.0007  max mem: 2503
Train: Epoch[5/5]  [1580/3750]  eta: 0:12:46  Lr: 0.001875  Loss: -0.7132  Acc@1: 81.2500 (80.1629)  Acc@5: 100.0000 (98.9801)  time: 0.3510  data: 0.0015  max mem: 2503
Train: Epoch[5/5]  [1590/3750]  eta: 0:12:43  Lr: 0.001875  Loss: -0.7988  Acc@1: 81.2500 (80.1697)  Acc@5: 100.0000 (98.9826)  time: 0.3504  data: 0.0012  max mem: 2503
Train: Epoch[5/5]  [1600/3750]  eta: 0:12:39  Lr: 0.001875  Loss: -0.6565  Acc@1: 81.2500 (80.1569)  Acc@5: 100.0000 (98.9772)  time: 0.3498  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [1610/3750]  eta: 0:12:35  Lr: 0.001875  Loss: -0.5963  Acc@1: 81.2500 (80.1754)  Acc@5: 100.0000 (98.9836)  time: 0.3516  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [1620/3750]  eta: 0:12:32  Lr: 0.001875  Loss: -0.7752  Acc@1: 81.2500 (80.1820)  Acc@5: 100.0000 (98.9860)  time: 0.3530  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [1630/3750]  eta: 0:12:28  Lr: 0.001875  Loss: -0.5190  Acc@1: 81.2500 (80.1502)  Acc@5: 100.0000 (98.9845)  time: 0.3526  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [1640/3750]  eta: 0:12:25  Lr: 0.001875  Loss: -0.4208  Acc@1: 81.2500 (80.1683)  Acc@5: 100.0000 (98.9755)  time: 0.3558  data: 0.0006  max mem: 2503
Train: Epoch[5/5]  [1650/3750]  eta: 0:12:21  Lr: 0.001875  Loss: -0.3686  Acc@1: 81.2500 (80.1749)  Acc@5: 100.0000 (98.9817)  time: 0.3561  data: 0.0008  max mem: 2503
Train: Epoch[5/5]  [1660/3750]  eta: 0:12:18  Lr: 0.001875  Loss: -0.6239  Acc@1: 81.2500 (80.1851)  Acc@5: 100.0000 (98.9878)  time: 0.3504  data: 0.0006  max mem: 2503
Train: Epoch[5/5]  [1670/3750]  eta: 0:12:14  Lr: 0.001875  Loss: -0.8820  Acc@1: 81.2500 (80.1840)  Acc@5: 100.0000 (98.9939)  time: 0.3513  data: 0.0011  max mem: 2503
Train: Epoch[5/5]  [1680/3750]  eta: 0:12:11  Lr: 0.001875  Loss: -0.9427  Acc@1: 81.2500 (80.2127)  Acc@5: 100.0000 (98.9924)  time: 0.3586  data: 0.0012  max mem: 2503
Train: Epoch[5/5]  [1690/3750]  eta: 0:12:07  Lr: 0.001875  Loss: -0.7457  Acc@1: 81.2500 (80.2114)  Acc@5: 100.0000 (98.9910)  time: 0.3566  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [1700/3750]  eta: 0:12:04  Lr: 0.001875  Loss: -0.3915  Acc@1: 75.0000 (80.2028)  Acc@5: 100.0000 (98.9896)  time: 0.3501  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [1710/3750]  eta: 0:12:00  Lr: 0.001875  Loss: -0.7600  Acc@1: 81.2500 (80.2016)  Acc@5: 100.0000 (98.9845)  time: 0.3528  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [1720/3750]  eta: 0:11:57  Lr: 0.001875  Loss: -1.0636  Acc@1: 81.2500 (80.1932)  Acc@5: 100.0000 (98.9831)  time: 0.3528  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [1730/3750]  eta: 0:11:53  Lr: 0.001875  Loss: -0.7085  Acc@1: 81.2500 (80.1957)  Acc@5: 100.0000 (98.9818)  time: 0.3503  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [1740/3750]  eta: 0:11:49  Lr: 0.001875  Loss: -0.8081  Acc@1: 75.0000 (80.1694)  Acc@5: 100.0000 (98.9841)  time: 0.3507  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [1750/3750]  eta: 0:11:46  Lr: 0.001875  Loss: -0.8419  Acc@1: 75.0000 (80.1685)  Acc@5: 100.0000 (98.9827)  time: 0.3498  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [1760/3750]  eta: 0:11:42  Lr: 0.001875  Loss: -0.8149  Acc@1: 75.0000 (80.1604)  Acc@5: 100.0000 (98.9814)  time: 0.3478  data: 0.0003  max mem: 2503
Train: Epoch[5/5]  [1770/3750]  eta: 0:11:39  Lr: 0.001875  Loss: -0.1159  Acc@1: 81.2500 (80.1595)  Acc@5: 100.0000 (98.9801)  time: 0.3488  data: 0.0007  max mem: 2503
Train: Epoch[5/5]  [1780/3750]  eta: 0:11:35  Lr: 0.001875  Loss: -0.4977  Acc@1: 75.0000 (80.1551)  Acc@5: 100.0000 (98.9788)  time: 0.3493  data: 0.0007  max mem: 2503
Train: Epoch[5/5]  [1790/3750]  eta: 0:11:32  Lr: 0.001875  Loss: -0.5424  Acc@1: 75.0000 (80.1717)  Acc@5: 100.0000 (98.9845)  time: 0.3493  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [1800/3750]  eta: 0:11:28  Lr: 0.001875  Loss: -0.5574  Acc@1: 75.0000 (80.1464)  Acc@5: 100.0000 (98.9797)  time: 0.3520  data: 0.0007  max mem: 2503
Train: Epoch[5/5]  [1810/3750]  eta: 0:11:25  Lr: 0.001875  Loss: -0.7734  Acc@1: 75.0000 (80.1387)  Acc@5: 100.0000 (98.9750)  time: 0.3556  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [1820/3750]  eta: 0:11:21  Lr: 0.001875  Loss: -0.9274  Acc@1: 81.2500 (80.1380)  Acc@5: 100.0000 (98.9806)  time: 0.3572  data: 0.0006  max mem: 2503
Train: Epoch[5/5]  [1830/3750]  eta: 0:11:18  Lr: 0.001875  Loss: -0.7794  Acc@1: 81.2500 (80.1577)  Acc@5: 100.0000 (98.9862)  time: 0.3551  data: 0.0007  max mem: 2503
Train: Epoch[5/5]  [1840/3750]  eta: 0:11:14  Lr: 0.001875  Loss: -0.8092  Acc@1: 87.5000 (80.1433)  Acc@5: 100.0000 (98.9713)  time: 0.3531  data: 0.0006  max mem: 2503
Train: Epoch[5/5]  [1850/3750]  eta: 0:11:11  Lr: 0.001875  Loss: -0.7340  Acc@1: 81.2500 (80.1560)  Acc@5: 100.0000 (98.9735)  time: 0.3550  data: 0.0014  max mem: 2503
Train: Epoch[5/5]  [1860/3750]  eta: 0:11:07  Lr: 0.001875  Loss: -0.5786  Acc@1: 81.2500 (80.1451)  Acc@5: 100.0000 (98.9790)  time: 0.3553  data: 0.0013  max mem: 2503
Train: Epoch[5/5]  [1870/3750]  eta: 0:11:03  Lr: 0.001875  Loss: -0.8216  Acc@1: 81.2500 (80.1710)  Acc@5: 100.0000 (98.9745)  time: 0.3527  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [1880/3750]  eta: 0:11:00  Lr: 0.001875  Loss: -0.7294  Acc@1: 81.2500 (80.1701)  Acc@5: 100.0000 (98.9799)  time: 0.3517  data: 0.0007  max mem: 2503
Train: Epoch[5/5]  [1890/3750]  eta: 0:10:56  Lr: 0.001875  Loss: -0.6791  Acc@1: 81.2500 (80.1891)  Acc@5: 100.0000 (98.9754)  time: 0.3538  data: 0.0007  max mem: 2503
Train: Epoch[5/5]  [1900/3750]  eta: 0:10:53  Lr: 0.001875  Loss: -0.4209  Acc@1: 81.2500 (80.1618)  Acc@5: 100.0000 (98.9709)  time: 0.3529  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [1910/3750]  eta: 0:10:49  Lr: 0.001875  Loss: -0.6795  Acc@1: 75.0000 (80.1380)  Acc@5: 100.0000 (98.9632)  time: 0.3501  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [1920/3750]  eta: 0:10:46  Lr: 0.001875  Loss: -0.7264  Acc@1: 75.0000 (80.1438)  Acc@5: 100.0000 (98.9589)  time: 0.3538  data: 0.0020  max mem: 2503
Train: Epoch[5/5]  [1930/3750]  eta: 0:10:42  Lr: 0.001875  Loss: -0.5090  Acc@1: 81.2500 (80.1463)  Acc@5: 100.0000 (98.9578)  time: 0.3526  data: 0.0020  max mem: 2503
Train: Epoch[5/5]  [1940/3750]  eta: 0:10:39  Lr: 0.001875  Loss: -0.9441  Acc@1: 81.2500 (80.1455)  Acc@5: 100.0000 (98.9567)  time: 0.3484  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [1950/3750]  eta: 0:10:35  Lr: 0.001875  Loss: -0.7087  Acc@1: 81.2500 (80.1384)  Acc@5: 100.0000 (98.9525)  time: 0.3490  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [1960/3750]  eta: 0:10:31  Lr: 0.001875  Loss: -0.7712  Acc@1: 81.2500 (80.1345)  Acc@5: 100.0000 (98.9514)  time: 0.3479  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [1970/3750]  eta: 0:10:28  Lr: 0.001875  Loss: -0.4763  Acc@1: 81.2500 (80.1306)  Acc@5: 100.0000 (98.9536)  time: 0.3485  data: 0.0010  max mem: 2503
Train: Epoch[5/5]  [1980/3750]  eta: 0:10:24  Lr: 0.001875  Loss: -0.8787  Acc@1: 75.0000 (80.1268)  Acc@5: 100.0000 (98.9494)  time: 0.3539  data: 0.0012  max mem: 2503
Train: Epoch[5/5]  [1990/3750]  eta: 0:10:21  Lr: 0.001875  Loss: -0.6498  Acc@1: 81.2500 (80.1293)  Acc@5: 100.0000 (98.9484)  time: 0.3527  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [2000/3750]  eta: 0:10:17  Lr: 0.001875  Loss: -0.5305  Acc@1: 87.5000 (80.1474)  Acc@5: 100.0000 (98.9412)  time: 0.3495  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [2010/3750]  eta: 0:10:14  Lr: 0.001875  Loss: -0.7781  Acc@1: 87.5000 (80.1560)  Acc@5: 100.0000 (98.9371)  time: 0.3546  data: 0.0018  max mem: 2503
Train: Epoch[5/5]  [2020/3750]  eta: 0:10:10  Lr: 0.001875  Loss: -0.7856  Acc@1: 87.5000 (80.1954)  Acc@5: 100.0000 (98.9393)  time: 0.3580  data: 0.0038  max mem: 2503
Train: Epoch[5/5]  [2030/3750]  eta: 0:10:07  Lr: 0.001875  Loss: -0.9963  Acc@1: 87.5000 (80.2222)  Acc@5: 100.0000 (98.9353)  time: 0.3537  data: 0.0025  max mem: 2503
Train: Epoch[5/5]  [2040/3750]  eta: 0:10:03  Lr: 0.001875  Loss: -0.6655  Acc@1: 81.2500 (80.2058)  Acc@5: 100.0000 (98.9313)  time: 0.3503  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [2050/3750]  eta: 0:10:00  Lr: 0.001875  Loss: -0.6866  Acc@1: 81.2500 (80.2078)  Acc@5: 100.0000 (98.9243)  time: 0.3592  data: 0.0014  max mem: 2503
Train: Epoch[5/5]  [2060/3750]  eta: 0:09:56  Lr: 0.001875  Loss: -0.8841  Acc@1: 81.2500 (80.2371)  Acc@5: 100.0000 (98.9295)  time: 0.3588  data: 0.0014  max mem: 2503
Train: Epoch[5/5]  [2070/3750]  eta: 0:09:53  Lr: 0.001875  Loss: -0.5415  Acc@1: 87.5000 (80.2420)  Acc@5: 100.0000 (98.9256)  time: 0.3506  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [2080/3750]  eta: 0:09:49  Lr: 0.001875  Loss: -0.8601  Acc@1: 81.2500 (80.2409)  Acc@5: 100.0000 (98.9218)  time: 0.3514  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [2090/3750]  eta: 0:09:46  Lr: 0.001875  Loss: -0.9859  Acc@1: 81.2500 (80.2457)  Acc@5: 100.0000 (98.9180)  time: 0.3524  data: 0.0016  max mem: 2503
Train: Epoch[5/5]  [2100/3750]  eta: 0:09:42  Lr: 0.001875  Loss: -0.5303  Acc@1: 75.0000 (80.2356)  Acc@5: 100.0000 (98.9142)  time: 0.3527  data: 0.0015  max mem: 2503
Train: Epoch[5/5]  [2110/3750]  eta: 0:09:39  Lr: 0.001875  Loss: -0.8689  Acc@1: 75.0000 (80.2315)  Acc@5: 100.0000 (98.9105)  time: 0.3512  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [2120/3750]  eta: 0:09:35  Lr: 0.001875  Loss: -0.8893  Acc@1: 81.2500 (80.2304)  Acc@5: 100.0000 (98.9156)  time: 0.3500  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [2130/3750]  eta: 0:09:31  Lr: 0.001875  Loss: -1.0111  Acc@1: 75.0000 (80.2264)  Acc@5: 100.0000 (98.9148)  time: 0.3494  data: 0.0016  max mem: 2503
Train: Epoch[5/5]  [2140/3750]  eta: 0:09:28  Lr: 0.001875  Loss: -0.9724  Acc@1: 81.2500 (80.2370)  Acc@5: 100.0000 (98.9141)  time: 0.3484  data: 0.0016  max mem: 2503
Train: Epoch[5/5]  [2150/3750]  eta: 0:09:24  Lr: 0.001875  Loss: -0.6589  Acc@1: 81.2500 (80.2476)  Acc@5: 100.0000 (98.9162)  time: 0.3517  data: 0.0006  max mem: 2503
Train: Epoch[5/5]  [2160/3750]  eta: 0:09:21  Lr: 0.001875  Loss: -0.6850  Acc@1: 81.2500 (80.2580)  Acc@5: 100.0000 (98.9212)  time: 0.3506  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [2170/3750]  eta: 0:09:17  Lr: 0.001875  Loss: -0.2895  Acc@1: 81.2500 (80.2395)  Acc@5: 100.0000 (98.9175)  time: 0.3473  data: 0.0003  max mem: 2503
Train: Epoch[5/5]  [2180/3750]  eta: 0:09:14  Lr: 0.001875  Loss: -0.5719  Acc@1: 75.0000 (80.2413)  Acc@5: 100.0000 (98.9082)  time: 0.3555  data: 0.0006  max mem: 2503
Train: Epoch[5/5]  [2190/3750]  eta: 0:09:10  Lr: 0.001875  Loss: -0.8052  Acc@1: 81.2500 (80.2373)  Acc@5: 100.0000 (98.9046)  time: 0.3569  data: 0.0006  max mem: 2503
Train: Epoch[5/5]  [2200/3750]  eta: 0:09:07  Lr: 0.001875  Loss: -1.0215  Acc@1: 75.0000 (80.2334)  Acc@5: 100.0000 (98.9011)  time: 0.3531  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [2210/3750]  eta: 0:09:03  Lr: 0.001875  Loss: -0.7444  Acc@1: 75.0000 (80.2211)  Acc@5: 100.0000 (98.9032)  time: 0.3558  data: 0.0008  max mem: 2503
Train: Epoch[5/5]  [2220/3750]  eta: 0:09:00  Lr: 0.001875  Loss: -0.8135  Acc@1: 81.2500 (80.2510)  Acc@5: 100.0000 (98.8941)  time: 0.3579  data: 0.0007  max mem: 2503
Train: Epoch[5/5]  [2230/3750]  eta: 0:08:56  Lr: 0.001875  Loss: -0.9069  Acc@1: 87.5000 (80.2667)  Acc@5: 100.0000 (98.8962)  time: 0.3558  data: 0.0012  max mem: 2503
Train: Epoch[5/5]  [2240/3750]  eta: 0:08:53  Lr: 0.001875  Loss: -0.5241  Acc@1: 81.2500 (80.2516)  Acc@5: 100.0000 (98.9012)  time: 0.3528  data: 0.0013  max mem: 2503
Train: Epoch[5/5]  [2250/3750]  eta: 0:08:49  Lr: 0.001875  Loss: -0.3182  Acc@1: 81.2500 (80.2477)  Acc@5: 100.0000 (98.8949)  time: 0.3566  data: 0.0013  max mem: 2503
Train: Epoch[5/5]  [2260/3750]  eta: 0:08:46  Lr: 0.001875  Loss: -0.7757  Acc@1: 81.2500 (80.2438)  Acc@5: 100.0000 (98.8971)  time: 0.3552  data: 0.0012  max mem: 2503
Train: Epoch[5/5]  [2270/3750]  eta: 0:08:42  Lr: 0.001875  Loss: -0.1969  Acc@1: 75.0000 (80.2400)  Acc@5: 100.0000 (98.8937)  time: 0.3525  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [2280/3750]  eta: 0:08:39  Lr: 0.001875  Loss: -1.0406  Acc@1: 87.5000 (80.2718)  Acc@5: 100.0000 (98.8985)  time: 0.3533  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [2290/3750]  eta: 0:08:35  Lr: 0.001875  Loss: -0.8233  Acc@1: 87.5000 (80.2843)  Acc@5: 100.0000 (98.8979)  time: 0.3529  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [2300/3750]  eta: 0:08:31  Lr: 0.001875  Loss: -0.7535  Acc@1: 81.2500 (80.2966)  Acc@5: 100.0000 (98.9027)  time: 0.3516  data: 0.0003  max mem: 2503
Train: Epoch[5/5]  [2310/3750]  eta: 0:08:28  Lr: 0.001875  Loss: -0.5162  Acc@1: 81.2500 (80.2872)  Acc@5: 100.0000 (98.8993)  time: 0.3486  data: 0.0003  max mem: 2503
Train: Epoch[5/5]  [2320/3750]  eta: 0:08:24  Lr: 0.001875  Loss: -0.7237  Acc@1: 81.2500 (80.2967)  Acc@5: 100.0000 (98.9013)  time: 0.3504  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [2330/3750]  eta: 0:08:21  Lr: 0.001875  Loss: -0.5545  Acc@1: 81.2500 (80.2982)  Acc@5: 100.0000 (98.9007)  time: 0.3504  data: 0.0007  max mem: 2503
Train: Epoch[5/5]  [2340/3750]  eta: 0:08:17  Lr: 0.001875  Loss: 0.0068  Acc@1: 81.2500 (80.2969)  Acc@5: 100.0000 (98.8974)  time: 0.3527  data: 0.0006  max mem: 2503
Train: Epoch[5/5]  [2350/3750]  eta: 0:08:14  Lr: 0.001875  Loss: -0.9228  Acc@1: 81.2500 (80.2983)  Acc@5: 100.0000 (98.8994)  time: 0.3560  data: 0.0007  max mem: 2503
Train: Epoch[5/5]  [2360/3750]  eta: 0:08:10  Lr: 0.001875  Loss: -0.9138  Acc@1: 87.5000 (80.3420)  Acc@5: 100.0000 (98.9014)  time: 0.3538  data: 0.0006  max mem: 2503
Train: Epoch[5/5]  [2370/3750]  eta: 0:08:07  Lr: 0.001875  Loss: -0.6362  Acc@1: 87.5000 (80.3406)  Acc@5: 100.0000 (98.9034)  time: 0.3546  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [2380/3750]  eta: 0:08:03  Lr: 0.001875  Loss: -0.4960  Acc@1: 81.2500 (80.3365)  Acc@5: 100.0000 (98.9080)  time: 0.3563  data: 0.0006  max mem: 2503
Train: Epoch[5/5]  [2390/3750]  eta: 0:08:00  Lr: 0.001875  Loss: -1.0691  Acc@1: 81.2500 (80.3691)  Acc@5: 100.0000 (98.9074)  time: 0.3572  data: 0.0008  max mem: 2503
Train: Epoch[5/5]  [2400/3750]  eta: 0:07:56  Lr: 0.001875  Loss: -0.7281  Acc@1: 81.2500 (80.3676)  Acc@5: 100.0000 (98.9041)  time: 0.3554  data: 0.0007  max mem: 2503
Train: Epoch[5/5]  [2410/3750]  eta: 0:07:53  Lr: 0.001875  Loss: -0.3883  Acc@1: 81.2500 (80.3686)  Acc@5: 100.0000 (98.9061)  time: 0.3532  data: 0.0007  max mem: 2503
Train: Epoch[5/5]  [2420/3750]  eta: 0:07:49  Lr: 0.001875  Loss: -0.6610  Acc@1: 81.2500 (80.3697)  Acc@5: 100.0000 (98.9080)  time: 0.3546  data: 0.0016  max mem: 2503
Train: Epoch[5/5]  [2430/3750]  eta: 0:07:46  Lr: 0.001875  Loss: -0.5774  Acc@1: 87.5000 (80.3862)  Acc@5: 100.0000 (98.9125)  time: 0.3553  data: 0.0022  max mem: 2503
Train: Epoch[5/5]  [2440/3750]  eta: 0:07:42  Lr: 0.001875  Loss: -0.6113  Acc@1: 87.5000 (80.3871)  Acc@5: 100.0000 (98.9118)  time: 0.3531  data: 0.0013  max mem: 2503
Train: Epoch[5/5]  [2450/3750]  eta: 0:07:39  Lr: 0.001875  Loss: -0.2964  Acc@1: 81.2500 (80.3856)  Acc@5: 100.0000 (98.9137)  time: 0.3517  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [2460/3750]  eta: 0:07:35  Lr: 0.001875  Loss: -0.7254  Acc@1: 81.2500 (80.3789)  Acc@5: 100.0000 (98.9130)  time: 0.3543  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [2470/3750]  eta: 0:07:31  Lr: 0.001875  Loss: -0.8712  Acc@1: 81.2500 (80.3976)  Acc@5: 100.0000 (98.9099)  time: 0.3537  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [2480/3750]  eta: 0:07:28  Lr: 0.001875  Loss: -0.5082  Acc@1: 81.2500 (80.3885)  Acc@5: 100.0000 (98.9067)  time: 0.3501  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [2490/3750]  eta: 0:07:24  Lr: 0.001875  Loss: -0.8120  Acc@1: 81.2500 (80.3869)  Acc@5: 100.0000 (98.9061)  time: 0.3517  data: 0.0007  max mem: 2503
Train: Epoch[5/5]  [2500/3750]  eta: 0:07:21  Lr: 0.001875  Loss: -0.5898  Acc@1: 81.2500 (80.3953)  Acc@5: 100.0000 (98.9079)  time: 0.3529  data: 0.0007  max mem: 2503
Train: Epoch[5/5]  [2510/3750]  eta: 0:07:17  Lr: 0.001875  Loss: -0.7795  Acc@1: 81.2500 (80.3913)  Acc@5: 100.0000 (98.9073)  time: 0.3514  data: 0.0003  max mem: 2503
Train: Epoch[5/5]  [2520/3750]  eta: 0:07:14  Lr: 0.001875  Loss: -0.7451  Acc@1: 81.2500 (80.3996)  Acc@5: 100.0000 (98.9092)  time: 0.3540  data: 0.0030  max mem: 2503
Train: Epoch[5/5]  [2530/3750]  eta: 0:07:10  Lr: 0.001875  Loss: -0.6183  Acc@1: 81.2500 (80.3981)  Acc@5: 100.0000 (98.9110)  time: 0.3533  data: 0.0030  max mem: 2503
Train: Epoch[5/5]  [2540/3750]  eta: 0:07:07  Lr: 0.001875  Loss: -0.7480  Acc@1: 81.2500 (80.3842)  Acc@5: 100.0000 (98.9079)  time: 0.3508  data: 0.0006  max mem: 2503
Train: Epoch[5/5]  [2550/3750]  eta: 0:07:03  Lr: 0.001875  Loss: -0.2132  Acc@1: 81.2500 (80.3704)  Acc@5: 100.0000 (98.9073)  time: 0.3541  data: 0.0019  max mem: 2503
Train: Epoch[5/5]  [2560/3750]  eta: 0:07:00  Lr: 0.001875  Loss: -0.5866  Acc@1: 81.2500 (80.3714)  Acc@5: 100.0000 (98.9067)  time: 0.3568  data: 0.0035  max mem: 2503
Train: Epoch[5/5]  [2570/3750]  eta: 0:06:56  Lr: 0.001875  Loss: -0.5003  Acc@1: 75.0000 (80.3505)  Acc@5: 100.0000 (98.9109)  time: 0.3537  data: 0.0023  max mem: 2503
Train: Epoch[5/5]  [2580/3750]  eta: 0:06:53  Lr: 0.001875  Loss: -0.7512  Acc@1: 75.0000 (80.3322)  Acc@5: 100.0000 (98.9127)  time: 0.3512  data: 0.0006  max mem: 2503
Train: Epoch[5/5]  [2590/3750]  eta: 0:06:49  Lr: 0.001875  Loss: -0.3488  Acc@1: 81.2500 (80.3334)  Acc@5: 100.0000 (98.9145)  time: 0.3552  data: 0.0010  max mem: 2503
Train: Epoch[5/5]  [2600/3750]  eta: 0:06:46  Lr: 0.001875  Loss: -0.7523  Acc@1: 81.2500 (80.3225)  Acc@5: 100.0000 (98.9139)  time: 0.3571  data: 0.0009  max mem: 2503
Train: Epoch[5/5]  [2610/3750]  eta: 0:06:42  Lr: 0.001875  Loss: -0.0019  Acc@1: 75.0000 (80.2901)  Acc@5: 100.0000 (98.9085)  time: 0.3533  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [2620/3750]  eta: 0:06:39  Lr: 0.001875  Loss: -0.7977  Acc@1: 81.2500 (80.2986)  Acc@5: 100.0000 (98.9102)  time: 0.3500  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [2630/3750]  eta: 0:06:35  Lr: 0.001875  Loss: -0.9514  Acc@1: 81.2500 (80.3093)  Acc@5: 100.0000 (98.9096)  time: 0.3510  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [2640/3750]  eta: 0:06:31  Lr: 0.001875  Loss: -0.6418  Acc@1: 75.0000 (80.2797)  Acc@5: 100.0000 (98.9043)  time: 0.3513  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [2650/3750]  eta: 0:06:28  Lr: 0.001875  Loss: -0.7162  Acc@1: 75.0000 (80.2763)  Acc@5: 100.0000 (98.9014)  time: 0.3503  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [2660/3750]  eta: 0:06:24  Lr: 0.001875  Loss: -0.8277  Acc@1: 81.2500 (80.2729)  Acc@5: 100.0000 (98.8937)  time: 0.3501  data: 0.0009  max mem: 2503
Train: Epoch[5/5]  [2670/3750]  eta: 0:06:21  Lr: 0.001875  Loss: -0.6145  Acc@1: 81.2500 (80.2719)  Acc@5: 100.0000 (98.8979)  time: 0.3491  data: 0.0008  max mem: 2503
Train: Epoch[5/5]  [2680/3750]  eta: 0:06:17  Lr: 0.001875  Loss: -0.8708  Acc@1: 81.2500 (80.2639)  Acc@5: 100.0000 (98.8997)  time: 0.3475  data: 0.0002  max mem: 2503
Train: Epoch[5/5]  [2690/3750]  eta: 0:06:14  Lr: 0.001875  Loss: -0.8719  Acc@1: 81.2500 (80.2652)  Acc@5: 100.0000 (98.9014)  time: 0.3493  data: 0.0007  max mem: 2503
Train: Epoch[5/5]  [2700/3750]  eta: 0:06:10  Lr: 0.001875  Loss: -0.9827  Acc@1: 87.5000 (80.2874)  Acc@5: 100.0000 (98.9009)  time: 0.3494  data: 0.0007  max mem: 2503
Train: Epoch[5/5]  [2710/3750]  eta: 0:06:07  Lr: 0.001875  Loss: -0.7629  Acc@1: 87.5000 (80.3002)  Acc@5: 100.0000 (98.9003)  time: 0.3485  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [2720/3750]  eta: 0:06:03  Lr: 0.001875  Loss: -0.3741  Acc@1: 87.5000 (80.3060)  Acc@5: 100.0000 (98.9044)  time: 0.3535  data: 0.0006  max mem: 2503
Train: Epoch[5/5]  [2730/3750]  eta: 0:06:00  Lr: 0.001875  Loss: -0.7649  Acc@1: 81.2500 (80.2934)  Acc@5: 100.0000 (98.9061)  time: 0.3561  data: 0.0006  max mem: 2503
Train: Epoch[5/5]  [2740/3750]  eta: 0:05:56  Lr: 0.001875  Loss: -0.6478  Acc@1: 75.0000 (80.2946)  Acc@5: 100.0000 (98.9032)  time: 0.3534  data: 0.0006  max mem: 2503
Train: Epoch[5/5]  [2750/3750]  eta: 0:05:53  Lr: 0.001875  Loss: -0.5565  Acc@1: 81.2500 (80.2913)  Acc@5: 100.0000 (98.9049)  time: 0.3518  data: 0.0006  max mem: 2503
Train: Epoch[5/5]  [2760/3750]  eta: 0:05:49  Lr: 0.001875  Loss: -0.6404  Acc@1: 81.2500 (80.2925)  Acc@5: 100.0000 (98.9089)  time: 0.3544  data: 0.0013  max mem: 2503
Train: Epoch[5/5]  [2770/3750]  eta: 0:05:45  Lr: 0.001875  Loss: -0.7876  Acc@1: 81.2500 (80.2892)  Acc@5: 100.0000 (98.9106)  time: 0.3582  data: 0.0013  max mem: 2503
Train: Epoch[5/5]  [2780/3750]  eta: 0:05:42  Lr: 0.001875  Loss: -1.0336  Acc@1: 81.2500 (80.2904)  Acc@5: 100.0000 (98.9123)  time: 0.3581  data: 0.0006  max mem: 2503
Train: Epoch[5/5]  [2790/3750]  eta: 0:05:38  Lr: 0.001875  Loss: -0.5867  Acc@1: 81.2500 (80.2871)  Acc@5: 100.0000 (98.9139)  time: 0.3530  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [2800/3750]  eta: 0:05:35  Lr: 0.001875  Loss: -0.4301  Acc@1: 81.2500 (80.2905)  Acc@5: 100.0000 (98.9133)  time: 0.3519  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [2810/3750]  eta: 0:05:31  Lr: 0.001875  Loss: -0.7640  Acc@1: 81.2500 (80.2895)  Acc@5: 100.0000 (98.9105)  time: 0.3516  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [2820/3750]  eta: 0:05:28  Lr: 0.001875  Loss: -0.9098  Acc@1: 81.2500 (80.3062)  Acc@5: 100.0000 (98.9100)  time: 0.3498  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [2830/3750]  eta: 0:05:24  Lr: 0.001875  Loss: -0.7606  Acc@1: 81.2500 (80.3073)  Acc@5: 100.0000 (98.9116)  time: 0.3512  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [2840/3750]  eta: 0:05:21  Lr: 0.001875  Loss: -0.7281  Acc@1: 75.0000 (80.2996)  Acc@5: 100.0000 (98.9132)  time: 0.3510  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [2850/3750]  eta: 0:05:17  Lr: 0.001875  Loss: -0.8934  Acc@1: 75.0000 (80.2964)  Acc@5: 100.0000 (98.9127)  time: 0.3487  data: 0.0003  max mem: 2503
Train: Epoch[5/5]  [2860/3750]  eta: 0:05:14  Lr: 0.001875  Loss: -0.6241  Acc@1: 81.2500 (80.2975)  Acc@5: 100.0000 (98.9099)  time: 0.3488  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [2870/3750]  eta: 0:05:10  Lr: 0.001875  Loss: -0.5112  Acc@1: 81.2500 (80.3096)  Acc@5: 100.0000 (98.9094)  time: 0.3502  data: 0.0003  max mem: 2503
Train: Epoch[5/5]  [2880/3750]  eta: 0:05:07  Lr: 0.001875  Loss: -1.0086  Acc@1: 81.2500 (80.3085)  Acc@5: 100.0000 (98.9066)  time: 0.3504  data: 0.0003  max mem: 2503
Train: Epoch[5/5]  [2890/3750]  eta: 0:05:03  Lr: 0.001875  Loss: -0.9603  Acc@1: 87.5000 (80.3269)  Acc@5: 100.0000 (98.9082)  time: 0.3522  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [2900/3750]  eta: 0:05:00  Lr: 0.001875  Loss: -0.4495  Acc@1: 81.2500 (80.3301)  Acc@5: 100.0000 (98.9034)  time: 0.3551  data: 0.0009  max mem: 2503
Train: Epoch[5/5]  [2910/3750]  eta: 0:04:56  Lr: 0.001875  Loss: -0.6592  Acc@1: 81.2500 (80.3418)  Acc@5: 100.0000 (98.9050)  time: 0.3547  data: 0.0009  max mem: 2503
Train: Epoch[5/5]  [2920/3750]  eta: 0:04:52  Lr: 0.001875  Loss: -1.0665  Acc@1: 81.2500 (80.3406)  Acc@5: 100.0000 (98.9066)  time: 0.3536  data: 0.0006  max mem: 2503
Train: Epoch[5/5]  [2930/3750]  eta: 0:04:49  Lr: 0.001875  Loss: -0.4654  Acc@1: 75.0000 (80.3395)  Acc@5: 100.0000 (98.9061)  time: 0.3554  data: 0.0006  max mem: 2503
Train: Epoch[5/5]  [2940/3750]  eta: 0:04:45  Lr: 0.001875  Loss: -0.5401  Acc@1: 81.2500 (80.3383)  Acc@5: 100.0000 (98.9077)  time: 0.3558  data: 0.0006  max mem: 2503
Train: Epoch[5/5]  [2950/3750]  eta: 0:04:42  Lr: 0.001875  Loss: -0.6585  Acc@1: 81.2500 (80.3478)  Acc@5: 100.0000 (98.9093)  time: 0.3544  data: 0.0006  max mem: 2503
Train: Epoch[5/5]  [2960/3750]  eta: 0:04:38  Lr: 0.001875  Loss: -0.6856  Acc@1: 81.2500 (80.3635)  Acc@5: 100.0000 (98.9087)  time: 0.3569  data: 0.0007  max mem: 2503
Train: Epoch[5/5]  [2970/3750]  eta: 0:04:35  Lr: 0.001875  Loss: -0.8526  Acc@1: 81.2500 (80.3559)  Acc@5: 100.0000 (98.9040)  time: 0.3576  data: 0.0015  max mem: 2503
Train: Epoch[5/5]  [2980/3750]  eta: 0:04:31  Lr: 0.001875  Loss: -0.8854  Acc@1: 81.2500 (80.3631)  Acc@5: 100.0000 (98.9035)  time: 0.3531  data: 0.0013  max mem: 2503
Train: Epoch[5/5]  [2990/3750]  eta: 0:04:28  Lr: 0.001875  Loss: -0.4959  Acc@1: 81.2500 (80.3703)  Acc@5: 100.0000 (98.9050)  time: 0.3508  data: 0.0003  max mem: 2503
Train: Epoch[5/5]  [3000/3750]  eta: 0:04:24  Lr: 0.001875  Loss: -0.6830  Acc@1: 87.5000 (80.3899)  Acc@5: 100.0000 (98.9087)  time: 0.3518  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [3010/3750]  eta: 0:04:21  Lr: 0.001875  Loss: -0.6350  Acc@1: 87.5000 (80.4010)  Acc@5: 100.0000 (98.9102)  time: 0.3533  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [3020/3750]  eta: 0:04:17  Lr: 0.001875  Loss: -0.5271  Acc@1: 81.2500 (80.3997)  Acc@5: 100.0000 (98.9097)  time: 0.3518  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [3030/3750]  eta: 0:04:14  Lr: 0.001875  Loss: -0.8839  Acc@1: 81.2500 (80.3984)  Acc@5: 100.0000 (98.9133)  time: 0.3521  data: 0.0011  max mem: 2503
Train: Epoch[5/5]  [3040/3750]  eta: 0:04:10  Lr: 0.001875  Loss: -0.7123  Acc@1: 81.2500 (80.4012)  Acc@5: 100.0000 (98.9128)  time: 0.3531  data: 0.0012  max mem: 2503
Train: Epoch[5/5]  [3050/3750]  eta: 0:04:07  Lr: 0.001875  Loss: -0.1246  Acc@1: 81.2500 (80.3978)  Acc@5: 100.0000 (98.9163)  time: 0.3495  data: 0.0003  max mem: 2503
Train: Epoch[5/5]  [3060/3750]  eta: 0:04:03  Lr: 0.001875  Loss: -0.8582  Acc@1: 81.2500 (80.4006)  Acc@5: 100.0000 (98.9138)  time: 0.3493  data: 0.0002  max mem: 2503
Train: Epoch[5/5]  [3070/3750]  eta: 0:04:00  Lr: 0.001875  Loss: -0.6799  Acc@1: 81.2500 (80.3932)  Acc@5: 100.0000 (98.9132)  time: 0.3557  data: 0.0010  max mem: 2503
Train: Epoch[5/5]  [3080/3750]  eta: 0:03:56  Lr: 0.001875  Loss: -0.5604  Acc@1: 75.0000 (80.4000)  Acc@5: 100.0000 (98.9167)  time: 0.3572  data: 0.0011  max mem: 2503
Train: Epoch[5/5]  [3090/3750]  eta: 0:03:52  Lr: 0.001875  Loss: -0.2126  Acc@1: 81.2500 (80.3907)  Acc@5: 100.0000 (98.9162)  time: 0.3532  data: 0.0006  max mem: 2503
Train: Epoch[5/5]  [3100/3750]  eta: 0:03:49  Lr: 0.001875  Loss: -0.5596  Acc@1: 81.2500 (80.4035)  Acc@5: 100.0000 (98.9137)  time: 0.3557  data: 0.0006  max mem: 2503
Train: Epoch[5/5]  [3110/3750]  eta: 0:03:45  Lr: 0.001875  Loss: -0.6994  Acc@1: 81.2500 (80.3942)  Acc@5: 100.0000 (98.9111)  time: 0.3569  data: 0.0007  max mem: 2503
Train: Epoch[5/5]  [3120/3750]  eta: 0:03:42  Lr: 0.001875  Loss: -0.4645  Acc@1: 75.0000 (80.3889)  Acc@5: 100.0000 (98.9146)  time: 0.3544  data: 0.0006  max mem: 2503
Train: Epoch[5/5]  [3130/3750]  eta: 0:03:38  Lr: 0.001875  Loss: -0.6179  Acc@1: 81.2500 (80.3857)  Acc@5: 100.0000 (98.9081)  time: 0.3550  data: 0.0006  max mem: 2503
Train: Epoch[5/5]  [3140/3750]  eta: 0:03:35  Lr: 0.001875  Loss: 0.0500  Acc@1: 81.2500 (80.3904)  Acc@5: 100.0000 (98.9076)  time: 0.3599  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [3150/3750]  eta: 0:03:31  Lr: 0.001875  Loss: -0.5513  Acc@1: 81.2500 (80.3832)  Acc@5: 100.0000 (98.9091)  time: 0.3570  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [3160/3750]  eta: 0:03:28  Lr: 0.001875  Loss: -0.7357  Acc@1: 81.2500 (80.3899)  Acc@5: 100.0000 (98.9066)  time: 0.3497  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [3170/3750]  eta: 0:03:24  Lr: 0.001875  Loss: -0.2977  Acc@1: 81.2500 (80.3729)  Acc@5: 100.0000 (98.9081)  time: 0.3497  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [3180/3750]  eta: 0:03:21  Lr: 0.001875  Loss: -0.4984  Acc@1: 81.2500 (80.3776)  Acc@5: 100.0000 (98.9076)  time: 0.3532  data: 0.0006  max mem: 2503
Train: Epoch[5/5]  [3190/3750]  eta: 0:03:17  Lr: 0.001875  Loss: -0.9191  Acc@1: 81.2500 (80.3804)  Acc@5: 100.0000 (98.9071)  time: 0.3536  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [3200/3750]  eta: 0:03:14  Lr: 0.001875  Loss: -0.4544  Acc@1: 81.2500 (80.3831)  Acc@5: 100.0000 (98.9085)  time: 0.3488  data: 0.0003  max mem: 2503
Train: Epoch[5/5]  [3210/3750]  eta: 0:03:10  Lr: 0.001875  Loss: -0.8422  Acc@1: 81.2500 (80.3955)  Acc@5: 100.0000 (98.9119)  time: 0.3491  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [3220/3750]  eta: 0:03:07  Lr: 0.001875  Loss: -0.5340  Acc@1: 81.2500 (80.3923)  Acc@5: 100.0000 (98.9114)  time: 0.3490  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [3230/3750]  eta: 0:03:03  Lr: 0.001875  Loss: -0.8663  Acc@1: 81.2500 (80.4085)  Acc@5: 100.0000 (98.9090)  time: 0.3467  data: 0.0003  max mem: 2503
Train: Epoch[5/5]  [3240/3750]  eta: 0:03:00  Lr: 0.001875  Loss: -0.8079  Acc@1: 87.5000 (80.4246)  Acc@5: 100.0000 (98.9085)  time: 0.3513  data: 0.0011  max mem: 2503
Train: Epoch[5/5]  [3250/3750]  eta: 0:02:56  Lr: 0.001875  Loss: -0.5258  Acc@1: 81.2500 (80.4176)  Acc@5: 100.0000 (98.9100)  time: 0.3539  data: 0.0012  max mem: 2503
Train: Epoch[5/5]  [3260/3750]  eta: 0:02:52  Lr: 0.001875  Loss: -0.4927  Acc@1: 75.0000 (80.4105)  Acc@5: 100.0000 (98.9095)  time: 0.3533  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [3270/3750]  eta: 0:02:49  Lr: 0.001875  Loss: -0.9854  Acc@1: 81.2500 (80.4169)  Acc@5: 100.0000 (98.9071)  time: 0.3577  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [3280/3750]  eta: 0:02:45  Lr: 0.001875  Loss: -0.7193  Acc@1: 87.5000 (80.4271)  Acc@5: 100.0000 (98.9085)  time: 0.3575  data: 0.0007  max mem: 2503
Train: Epoch[5/5]  [3290/3750]  eta: 0:02:42  Lr: 0.001875  Loss: -0.8094  Acc@1: 87.5000 (80.4296)  Acc@5: 100.0000 (98.9099)  time: 0.3545  data: 0.0007  max mem: 2503
Train: Epoch[5/5]  [3300/3750]  eta: 0:02:38  Lr: 0.001875  Loss: -0.5214  Acc@1: 81.2500 (80.4264)  Acc@5: 100.0000 (98.9113)  time: 0.3532  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [3310/3750]  eta: 0:02:35  Lr: 0.001875  Loss: -0.7010  Acc@1: 81.2500 (80.4138)  Acc@5: 100.0000 (98.9052)  time: 0.3526  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [3320/3750]  eta: 0:02:31  Lr: 0.001875  Loss: -0.5739  Acc@1: 81.2500 (80.4182)  Acc@5: 100.0000 (98.9009)  time: 0.3557  data: 0.0020  max mem: 2503
Train: Epoch[5/5]  [3330/3750]  eta: 0:02:28  Lr: 0.001875  Loss: -0.8093  Acc@1: 81.2500 (80.4150)  Acc@5: 100.0000 (98.9005)  time: 0.3541  data: 0.0023  max mem: 2503
Train: Epoch[5/5]  [3340/3750]  eta: 0:02:24  Lr: 0.001875  Loss: -0.8883  Acc@1: 81.2500 (80.4269)  Acc@5: 100.0000 (98.9000)  time: 0.3498  data: 0.0007  max mem: 2503
Train: Epoch[5/5]  [3350/3750]  eta: 0:02:21  Lr: 0.001875  Loss: -0.6510  Acc@1: 81.2500 (80.4219)  Acc@5: 100.0000 (98.9014)  time: 0.3515  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [3360/3750]  eta: 0:02:17  Lr: 0.001875  Loss: -0.3442  Acc@1: 81.2500 (80.4262)  Acc@5: 100.0000 (98.9029)  time: 0.3521  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [3370/3750]  eta: 0:02:14  Lr: 0.001875  Loss: -0.5895  Acc@1: 81.2500 (80.4138)  Acc@5: 100.0000 (98.9024)  time: 0.3505  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [3380/3750]  eta: 0:02:10  Lr: 0.001875  Loss: -0.0602  Acc@1: 75.0000 (80.3997)  Acc@5: 100.0000 (98.8946)  time: 0.3494  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [3390/3750]  eta: 0:02:07  Lr: 0.001875  Loss: -0.6179  Acc@1: 81.2500 (80.4040)  Acc@5: 100.0000 (98.8978)  time: 0.3504  data: 0.0016  max mem: 2503
Train: Epoch[5/5]  [3400/3750]  eta: 0:02:03  Lr: 0.001875  Loss: -0.9495  Acc@1: 81.2500 (80.4102)  Acc@5: 100.0000 (98.8992)  time: 0.3492  data: 0.0015  max mem: 2503
Train: Epoch[5/5]  [3410/3750]  eta: 0:02:00  Lr: 0.001875  Loss: -0.5772  Acc@1: 81.2500 (80.4053)  Acc@5: 100.0000 (98.8988)  time: 0.3482  data: 0.0003  max mem: 2503
Train: Epoch[5/5]  [3420/3750]  eta: 0:01:56  Lr: 0.001875  Loss: -0.5745  Acc@1: 81.2500 (80.4114)  Acc@5: 100.0000 (98.8983)  time: 0.3496  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [3430/3750]  eta: 0:01:52  Lr: 0.001875  Loss: -0.8882  Acc@1: 81.2500 (80.4175)  Acc@5: 100.0000 (98.8997)  time: 0.3496  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [3440/3750]  eta: 0:01:49  Lr: 0.001875  Loss: -0.6423  Acc@1: 81.2500 (80.4254)  Acc@5: 100.0000 (98.9029)  time: 0.3521  data: 0.0007  max mem: 2503
Train: Epoch[5/5]  [3450/3750]  eta: 0:01:45  Lr: 0.001875  Loss: -0.8264  Acc@1: 81.2500 (80.4260)  Acc@5: 100.0000 (98.9043)  time: 0.3558  data: 0.0030  max mem: 2503
Train: Epoch[5/5]  [3460/3750]  eta: 0:01:42  Lr: 0.001875  Loss: -0.5423  Acc@1: 81.2500 (80.4247)  Acc@5: 100.0000 (98.9039)  time: 0.3552  data: 0.0031  max mem: 2503
Train: Epoch[5/5]  [3470/3750]  eta: 0:01:38  Lr: 0.001875  Loss: -0.6933  Acc@1: 81.2500 (80.4145)  Acc@5: 100.0000 (98.9016)  time: 0.3532  data: 0.0008  max mem: 2503
Train: Epoch[5/5]  [3480/3750]  eta: 0:01:35  Lr: 0.001875  Loss: -0.4239  Acc@1: 75.0000 (80.4133)  Acc@5: 100.0000 (98.9030)  time: 0.3532  data: 0.0006  max mem: 2503
Train: Epoch[5/5]  [3490/3750]  eta: 0:01:31  Lr: 0.001875  Loss: -0.7028  Acc@1: 81.2500 (80.4193)  Acc@5: 100.0000 (98.9043)  time: 0.3531  data: 0.0007  max mem: 2503
Train: Epoch[5/5]  [3500/3750]  eta: 0:01:28  Lr: 0.001875  Loss: -0.7942  Acc@1: 87.5000 (80.4217)  Acc@5: 100.0000 (98.9039)  time: 0.3535  data: 0.0008  max mem: 2503
Train: Epoch[5/5]  [3510/3750]  eta: 0:01:24  Lr: 0.001875  Loss: -0.6272  Acc@1: 75.0000 (80.4116)  Acc@5: 100.0000 (98.9017)  time: 0.3527  data: 0.0009  max mem: 2503
Train: Epoch[5/5]  [3520/3750]  eta: 0:01:21  Lr: 0.001875  Loss: -0.7548  Acc@1: 81.2500 (80.4122)  Acc@5: 100.0000 (98.9048)  time: 0.3521  data: 0.0006  max mem: 2503
Train: Epoch[5/5]  [3530/3750]  eta: 0:01:17  Lr: 0.001875  Loss: -0.5002  Acc@1: 81.2500 (80.4145)  Acc@5: 100.0000 (98.9061)  time: 0.3519  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [3540/3750]  eta: 0:01:14  Lr: 0.001875  Loss: -0.9011  Acc@1: 81.2500 (80.4045)  Acc@5: 100.0000 (98.8986)  time: 0.3527  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [3550/3750]  eta: 0:01:10  Lr: 0.001875  Loss: -0.9389  Acc@1: 81.2500 (80.4034)  Acc@5: 100.0000 (98.8964)  time: 0.3531  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [3560/3750]  eta: 0:01:07  Lr: 0.001875  Loss: -0.1850  Acc@1: 81.2500 (80.3970)  Acc@5: 100.0000 (98.8943)  time: 0.3520  data: 0.0008  max mem: 2503
Train: Epoch[5/5]  [3570/3750]  eta: 0:01:03  Lr: 0.001875  Loss: -0.7746  Acc@1: 81.2500 (80.4011)  Acc@5: 100.0000 (98.8939)  time: 0.3502  data: 0.0007  max mem: 2503
Train: Epoch[5/5]  [3580/3750]  eta: 0:00:59  Lr: 0.001875  Loss: 0.1030  Acc@1: 81.2500 (80.3878)  Acc@5: 100.0000 (98.8917)  time: 0.3497  data: 0.0003  max mem: 2503
Train: Epoch[5/5]  [3590/3750]  eta: 0:00:56  Lr: 0.001875  Loss: -0.6465  Acc@1: 81.2500 (80.4041)  Acc@5: 100.0000 (98.8948)  time: 0.3522  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [3600/3750]  eta: 0:00:52  Lr: 0.001875  Loss: -0.7797  Acc@1: 87.5000 (80.4047)  Acc@5: 100.0000 (98.8961)  time: 0.3511  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [3610/3750]  eta: 0:00:49  Lr: 0.001875  Loss: -0.4615  Acc@1: 81.2500 (80.3984)  Acc@5: 100.0000 (98.8957)  time: 0.3498  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [3620/3750]  eta: 0:00:45  Lr: 0.001875  Loss: -0.4549  Acc@1: 75.0000 (80.3801)  Acc@5: 100.0000 (98.8971)  time: 0.3519  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [3630/3750]  eta: 0:00:42  Lr: 0.001875  Loss: -0.5096  Acc@1: 75.0000 (80.3773)  Acc@5: 100.0000 (98.8967)  time: 0.3526  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [3640/3750]  eta: 0:00:38  Lr: 0.001875  Loss: -0.4829  Acc@1: 81.2500 (80.3780)  Acc@5: 100.0000 (98.8997)  time: 0.3537  data: 0.0006  max mem: 2503
Train: Epoch[5/5]  [3650/3750]  eta: 0:00:35  Lr: 0.001875  Loss: -0.7407  Acc@1: 81.2500 (80.3838)  Acc@5: 100.0000 (98.9027)  time: 0.3558  data: 0.0007  max mem: 2503
Train: Epoch[5/5]  [3660/3750]  eta: 0:00:31  Lr: 0.001875  Loss: -0.7887  Acc@1: 81.2500 (80.3845)  Acc@5: 100.0000 (98.9006)  time: 0.3555  data: 0.0007  max mem: 2503
Train: Epoch[5/5]  [3670/3750]  eta: 0:00:28  Lr: 0.001875  Loss: -0.6356  Acc@1: 87.5000 (80.3970)  Acc@5: 100.0000 (98.9036)  time: 0.3558  data: 0.0007  max mem: 2503
Train: Epoch[5/5]  [3680/3750]  eta: 0:00:24  Lr: 0.001875  Loss: -0.7064  Acc@1: 75.0000 (80.3909)  Acc@5: 100.0000 (98.9015)  time: 0.3556  data: 0.0007  max mem: 2503
Train: Epoch[5/5]  [3690/3750]  eta: 0:00:21  Lr: 0.001875  Loss: -0.1328  Acc@1: 81.2500 (80.3983)  Acc@5: 100.0000 (98.9027)  time: 0.3552  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [3700/3750]  eta: 0:00:17  Lr: 0.001875  Loss: -0.4031  Acc@1: 81.2500 (80.3972)  Acc@5: 100.0000 (98.9023)  time: 0.3582  data: 0.0009  max mem: 2503
Train: Epoch[5/5]  [3710/3750]  eta: 0:00:14  Lr: 0.001875  Loss: -0.5166  Acc@1: 75.0000 (80.3877)  Acc@5: 100.0000 (98.9002)  time: 0.3571  data: 0.0008  max mem: 2503
Train: Epoch[5/5]  [3720/3750]  eta: 0:00:10  Lr: 0.001875  Loss: -0.6805  Acc@1: 81.2500 (80.3984)  Acc@5: 100.0000 (98.9015)  time: 0.3532  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [3730/3750]  eta: 0:00:07  Lr: 0.001875  Loss: -0.6221  Acc@1: 81.2500 (80.3890)  Acc@5: 100.0000 (98.8994)  time: 0.3577  data: 0.0009  max mem: 2503
Train: Epoch[5/5]  [3740/3750]  eta: 0:00:03  Lr: 0.001875  Loss: -0.5979  Acc@1: 81.2500 (80.3996)  Acc@5: 100.0000 (98.9007)  time: 0.3583  data: 0.0009  max mem: 2503
Train: Epoch[5/5]  [3749/3750]  eta: 0:00:00  Lr: 0.001875  Loss: -0.6094  Acc@1: 81.2500 (80.4017)  Acc@5: 100.0000 (98.9000)  time: 0.3538  data: 0.0008  max mem: 2503
Train: Epoch[5/5] Total time: 0:22:04 (0.3532 s / it)
{0: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 1: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 2: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 3: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 4: {0: 0, 1: 300000, 2: 0, 3: 91325, 4: 0}, 5: {0: 0, 1: 300000, 2: 0, 3: 91325, 4: 0}, 6: {0: 0, 1: 300000, 2: 0, 3: 91325, 4: 0}, 7: {0: 0, 1: 300000, 2: 0, 3: 91325, 4: 0}, 8: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 9: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 10: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 11: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 12: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 13: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 14: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 15: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 16: {0: 0, 1: 0, 2: 0, 3: 0, 4: 300000}, 17: {0: 0, 1: 0, 2: 0, 3: 0, 4: 300000}, 18: {0: 0, 1: 0, 2: 0, 3: 0, 4: 300000}, 19: {0: 0, 1: 0, 2: 0, 3: 0, 4: 300000}}
Averaged stats: Lr: 0.001875  Loss: -0.6094  Acc@1: 81.2500 (80.4017)  Acc@5: 100.0000 (98.9000)
Test: [Task 1]  [   0/1627]  eta: 0:14:23  Loss: 1.5257 (1.5257)  Acc@1: 56.2500 (56.2500)  Acc@5: 93.7500 (93.7500)  time: 0.5309  data: 0.3136  max mem: 2503
Test: [Task 1]  [  10/1627]  eta: 0:06:41  Loss: 1.4260 (1.3296)  Acc@1: 56.2500 (60.7955)  Acc@5: 87.5000 (88.0682)  time: 0.2483  data: 0.0288  max mem: 2503
Test: [Task 1]  [  20/1627]  eta: 0:06:17  Loss: 1.2172 (1.2804)  Acc@1: 56.2500 (62.5000)  Acc@5: 87.5000 (88.3929)  time: 0.2202  data: 0.0010  max mem: 2503
Test: [Task 1]  [  30/1627]  eta: 0:06:07  Loss: 1.2549 (1.2767)  Acc@1: 56.2500 (63.1048)  Acc@5: 87.5000 (88.7097)  time: 0.2197  data: 0.0015  max mem: 2503
Test: [Task 1]  [  40/1627]  eta: 0:06:00  Loss: 1.3109 (1.2882)  Acc@1: 62.5000 (62.8049)  Acc@5: 87.5000 (89.3293)  time: 0.2184  data: 0.0008  max mem: 2503
Test: [Task 1]  [  50/1627]  eta: 0:05:55  Loss: 1.0671 (1.2574)  Acc@1: 68.7500 (64.4608)  Acc@5: 93.7500 (90.3186)  time: 0.2180  data: 0.0003  max mem: 2503
Test: [Task 1]  [  60/1627]  eta: 0:05:51  Loss: 1.1346 (1.2701)  Acc@1: 68.7500 (64.1393)  Acc@5: 93.7500 (90.3689)  time: 0.2199  data: 0.0004  max mem: 2503
Test: [Task 1]  [  70/1627]  eta: 0:05:48  Loss: 1.2922 (1.2710)  Acc@1: 62.5000 (64.1725)  Acc@5: 87.5000 (90.4049)  time: 0.2204  data: 0.0008  max mem: 2503
Test: [Task 1]  [  80/1627]  eta: 0:05:45  Loss: 0.9989 (1.2530)  Acc@1: 68.7500 (64.5833)  Acc@5: 93.7500 (90.8951)  time: 0.2198  data: 0.0008  max mem: 2503
Test: [Task 1]  [  90/1627]  eta: 0:05:42  Loss: 1.1875 (1.2666)  Acc@1: 68.7500 (64.4231)  Acc@5: 87.5000 (90.5907)  time: 0.2203  data: 0.0006  max mem: 2503
Test: [Task 1]  [ 100/1627]  eta: 0:05:40  Loss: 1.3526 (1.2904)  Acc@1: 62.5000 (64.0470)  Acc@5: 87.5000 (89.7896)  time: 0.2208  data: 0.0006  max mem: 2503
Test: [Task 1]  [ 110/1627]  eta: 0:05:37  Loss: 1.2617 (1.2850)  Acc@1: 68.7500 (64.4144)  Acc@5: 87.5000 (90.0338)  time: 0.2215  data: 0.0007  max mem: 2503
Test: [Task 1]  [ 120/1627]  eta: 0:05:36  Loss: 1.2333 (1.2808)  Acc@1: 75.0000 (64.7211)  Acc@5: 93.7500 (90.0310)  time: 0.2238  data: 0.0012  max mem: 2503
Test: [Task 1]  [ 130/1627]  eta: 0:05:33  Loss: 1.2838 (1.2899)  Acc@1: 62.5000 (64.4561)  Acc@5: 93.7500 (90.0286)  time: 0.2230  data: 0.0010  max mem: 2503
Test: [Task 1]  [ 140/1627]  eta: 0:05:31  Loss: 1.2827 (1.2859)  Acc@1: 68.7500 (64.7606)  Acc@5: 93.7500 (90.1152)  time: 0.2221  data: 0.0012  max mem: 2503
Test: [Task 1]  [ 150/1627]  eta: 0:05:28  Loss: 1.0414 (1.2657)  Acc@1: 68.7500 (65.4387)  Acc@5: 93.7500 (90.3146)  time: 0.2219  data: 0.0012  max mem: 2503
Test: [Task 1]  [ 160/1627]  eta: 0:05:26  Loss: 1.0445 (1.2585)  Acc@1: 68.7500 (65.7220)  Acc@5: 93.7500 (90.4503)  time: 0.2196  data: 0.0011  max mem: 2503
Test: [Task 1]  [ 170/1627]  eta: 0:05:24  Loss: 1.2035 (1.2511)  Acc@1: 68.7500 (65.8260)  Acc@5: 87.5000 (90.4605)  time: 0.2215  data: 0.0013  max mem: 2503
Test: [Task 1]  [ 180/1627]  eta: 0:05:22  Loss: 1.2141 (1.2572)  Acc@1: 62.5000 (65.6077)  Acc@5: 87.5000 (90.3315)  time: 0.2234  data: 0.0018  max mem: 2503
Test: [Task 1]  [ 190/1627]  eta: 0:05:20  Loss: 1.2427 (1.2553)  Acc@1: 68.7500 (65.6414)  Acc@5: 87.5000 (90.3141)  time: 0.2247  data: 0.0023  max mem: 2503
Test: [Task 1]  [ 200/1627]  eta: 0:05:18  Loss: 1.2422 (1.2555)  Acc@1: 68.7500 (65.7649)  Acc@5: 93.7500 (90.2985)  time: 0.2274  data: 0.0019  max mem: 2503
Test: [Task 1]  [ 210/1627]  eta: 0:05:15  Loss: 1.1049 (1.2524)  Acc@1: 75.0000 (65.9953)  Acc@5: 93.7500 (90.3436)  time: 0.2241  data: 0.0011  max mem: 2503
Test: [Task 1]  [ 220/1627]  eta: 0:05:13  Loss: 1.1049 (1.2606)  Acc@1: 68.7500 (65.6674)  Acc@5: 87.5000 (90.2149)  time: 0.2186  data: 0.0004  max mem: 2503
Test: [Task 1]  [ 230/1627]  eta: 0:05:10  Loss: 1.1984 (1.2572)  Acc@1: 68.7500 (65.8279)  Acc@5: 87.5000 (90.2056)  time: 0.2180  data: 0.0004  max mem: 2503
Test: [Task 1]  [ 240/1627]  eta: 0:05:08  Loss: 1.1590 (1.2520)  Acc@1: 68.7500 (65.9492)  Acc@5: 93.7500 (90.3268)  time: 0.2187  data: 0.0004  max mem: 2503
Test: [Task 1]  [ 250/1627]  eta: 0:05:06  Loss: 1.1350 (1.2542)  Acc@1: 68.7500 (66.0608)  Acc@5: 93.7500 (90.2888)  time: 0.2194  data: 0.0009  max mem: 2503
Test: [Task 1]  [ 260/1627]  eta: 0:05:03  Loss: 1.1866 (1.2545)  Acc@1: 68.7500 (66.1877)  Acc@5: 87.5000 (90.3257)  time: 0.2191  data: 0.0012  max mem: 2503
Test: [Task 1]  [ 270/1627]  eta: 0:05:01  Loss: 1.1601 (1.2459)  Acc@1: 68.7500 (66.4668)  Acc@5: 93.7500 (90.4290)  time: 0.2187  data: 0.0008  max mem: 2503
Test: [Task 1]  [ 280/1627]  eta: 0:04:58  Loss: 1.0304 (1.2463)  Acc@1: 75.0000 (66.6148)  Acc@5: 93.7500 (90.4137)  time: 0.2187  data: 0.0004  max mem: 2503
Test: [Task 1]  [ 290/1627]  eta: 0:04:56  Loss: 1.2265 (1.2448)  Acc@1: 68.7500 (66.6667)  Acc@5: 93.7500 (90.5284)  time: 0.2183  data: 0.0003  max mem: 2503
Test: [Task 1]  [ 300/1627]  eta: 0:04:54  Loss: 1.1240 (1.2434)  Acc@1: 68.7500 (66.7566)  Acc@5: 93.7500 (90.5939)  time: 0.2181  data: 0.0009  max mem: 2503
Test: [Task 1]  [ 310/1627]  eta: 0:04:51  Loss: 1.1286 (1.2435)  Acc@1: 68.7500 (66.7404)  Acc@5: 93.7500 (90.6752)  time: 0.2180  data: 0.0012  max mem: 2503
Test: [Task 1]  [ 320/1627]  eta: 0:04:49  Loss: 1.2448 (1.2439)  Acc@1: 68.7500 (66.6861)  Acc@5: 93.7500 (90.6737)  time: 0.2175  data: 0.0010  max mem: 2503
Test: [Task 1]  [ 330/1627]  eta: 0:04:46  Loss: 1.1647 (1.2433)  Acc@1: 68.7500 (66.7674)  Acc@5: 93.7500 (90.6344)  time: 0.2167  data: 0.0007  max mem: 2503
Test: [Task 1]  [ 340/1627]  eta: 0:04:44  Loss: 1.0637 (1.2432)  Acc@1: 68.7500 (66.8988)  Acc@5: 93.7500 (90.6158)  time: 0.2174  data: 0.0010  max mem: 2503
Test: [Task 1]  [ 350/1627]  eta: 0:04:42  Loss: 1.3034 (1.2450)  Acc@1: 68.7500 (66.8625)  Acc@5: 87.5000 (90.5627)  time: 0.2187  data: 0.0011  max mem: 2503
Test: [Task 1]  [ 360/1627]  eta: 0:04:39  Loss: 1.1503 (1.2427)  Acc@1: 75.0000 (67.0360)  Acc@5: 87.5000 (90.5298)  time: 0.2182  data: 0.0004  max mem: 2503
Test: [Task 1]  [ 370/1627]  eta: 0:04:37  Loss: 1.1295 (1.2411)  Acc@1: 68.7500 (66.9980)  Acc@5: 93.7500 (90.5829)  time: 0.2186  data: 0.0004  max mem: 2503
Test: [Task 1]  [ 380/1627]  eta: 0:04:35  Loss: 1.0798 (1.2394)  Acc@1: 68.7500 (67.0768)  Acc@5: 93.7500 (90.6168)  time: 0.2192  data: 0.0004  max mem: 2503
Test: [Task 1]  [ 390/1627]  eta: 0:04:33  Loss: 1.0846 (1.2408)  Acc@1: 75.0000 (67.0876)  Acc@5: 93.7500 (90.5211)  time: 0.2199  data: 0.0004  max mem: 2503
Test: [Task 1]  [ 400/1627]  eta: 0:04:30  Loss: 1.1156 (1.2410)  Acc@1: 62.5000 (67.0200)  Acc@5: 87.5000 (90.5237)  time: 0.2193  data: 0.0004  max mem: 2503
Test: [Task 1]  [ 410/1627]  eta: 0:04:28  Loss: 1.0265 (1.2404)  Acc@1: 68.7500 (67.1229)  Acc@5: 87.5000 (90.4957)  time: 0.2205  data: 0.0009  max mem: 2503
Test: [Task 1]  [ 420/1627]  eta: 0:04:26  Loss: 1.0265 (1.2390)  Acc@1: 75.0000 (67.1021)  Acc@5: 93.7500 (90.5730)  time: 0.2229  data: 0.0011  max mem: 2503
Test: [Task 1]  [ 430/1627]  eta: 0:04:24  Loss: 1.1098 (1.2374)  Acc@1: 75.0000 (67.1404)  Acc@5: 93.7500 (90.6323)  time: 0.2204  data: 0.0005  max mem: 2503
Test: [Task 1]  [ 440/1627]  eta: 0:04:22  Loss: 1.1928 (1.2353)  Acc@1: 68.7500 (67.1344)  Acc@5: 93.7500 (90.6888)  time: 0.2202  data: 0.0005  max mem: 2503
Test: [Task 1]  [ 450/1627]  eta: 0:04:19  Loss: 1.2450 (1.2386)  Acc@1: 62.5000 (67.0316)  Acc@5: 93.7500 (90.6181)  time: 0.2200  data: 0.0005  max mem: 2503
Test: [Task 1]  [ 460/1627]  eta: 0:04:17  Loss: 1.2864 (1.2377)  Acc@1: 62.5000 (67.0282)  Acc@5: 93.7500 (90.6318)  time: 0.2197  data: 0.0004  max mem: 2503
Test: [Task 1]  [ 470/1627]  eta: 0:04:15  Loss: 1.1108 (1.2343)  Acc@1: 68.7500 (67.1311)  Acc@5: 93.7500 (90.6714)  time: 0.2221  data: 0.0006  max mem: 2503
Test: [Task 1]  [ 480/1627]  eta: 0:04:13  Loss: 1.2206 (1.2392)  Acc@1: 68.7500 (67.0088)  Acc@5: 87.5000 (90.5925)  time: 0.2231  data: 0.0012  max mem: 2503
Test: [Task 1]  [ 490/1627]  eta: 0:04:11  Loss: 1.3146 (1.2406)  Acc@1: 62.5000 (66.9425)  Acc@5: 87.5000 (90.5932)  time: 0.2226  data: 0.0012  max mem: 2503
Test: [Task 1]  [ 500/1627]  eta: 0:04:08  Loss: 1.1846 (1.2418)  Acc@1: 62.5000 (66.9411)  Acc@5: 93.7500 (90.6063)  time: 0.2204  data: 0.0006  max mem: 2503
Test: [Task 1]  [ 510/1627]  eta: 0:04:06  Loss: 1.3075 (1.2477)  Acc@1: 62.5000 (66.8420)  Acc@5: 93.7500 (90.5088)  time: 0.2192  data: 0.0004  max mem: 2503
Test: [Task 1]  [ 520/1627]  eta: 0:04:04  Loss: 1.3604 (1.2559)  Acc@1: 56.2500 (66.6027)  Acc@5: 93.7500 (90.4870)  time: 0.2187  data: 0.0003  max mem: 2503
Test: [Task 1]  [ 530/1627]  eta: 0:04:02  Loss: 1.2244 (1.2516)  Acc@1: 56.2500 (66.6549)  Acc@5: 93.7500 (90.5720)  time: 0.2187  data: 0.0003  max mem: 2503
Test: [Task 1]  [ 540/1627]  eta: 0:03:59  Loss: 1.1344 (1.2519)  Acc@1: 68.7500 (66.6128)  Acc@5: 93.7500 (90.5384)  time: 0.2197  data: 0.0011  max mem: 2503
Test: [Task 1]  [ 550/1627]  eta: 0:03:57  Loss: 1.3825 (1.2542)  Acc@1: 62.5000 (66.5721)  Acc@5: 87.5000 (90.5172)  time: 0.2193  data: 0.0011  max mem: 2503
Test: [Task 1]  [ 560/1627]  eta: 0:03:55  Loss: 1.4199 (1.2574)  Acc@1: 62.5000 (66.4550)  Acc@5: 87.5000 (90.4523)  time: 0.2187  data: 0.0004  max mem: 2503
Test: [Task 1]  [ 570/1627]  eta: 0:03:53  Loss: 1.2438 (1.2547)  Acc@1: 68.7500 (66.5609)  Acc@5: 87.5000 (90.4882)  time: 0.2188  data: 0.0004  max mem: 2503
Test: [Task 1]  [ 580/1627]  eta: 0:03:50  Loss: 1.1739 (1.2559)  Acc@1: 68.7500 (66.4694)  Acc@5: 93.7500 (90.4690)  time: 0.2183  data: 0.0003  max mem: 2503
Test: [Task 1]  [ 590/1627]  eta: 0:03:48  Loss: 1.2740 (1.2555)  Acc@1: 62.5000 (66.4657)  Acc@5: 93.7500 (90.5245)  time: 0.2183  data: 0.0003  max mem: 2503
Test: [Task 1]  [ 600/1627]  eta: 0:03:46  Loss: 1.2638 (1.2566)  Acc@1: 62.5000 (66.4101)  Acc@5: 93.7500 (90.5054)  time: 0.2183  data: 0.0004  max mem: 2503
Test: [Task 1]  [ 610/1627]  eta: 0:03:44  Loss: 1.1124 (1.2545)  Acc@1: 62.5000 (66.4484)  Acc@5: 93.7500 (90.5483)  time: 0.2191  data: 0.0003  max mem: 2503
Test: [Task 1]  [ 620/1627]  eta: 0:03:42  Loss: 1.1470 (1.2553)  Acc@1: 68.7500 (66.4855)  Acc@5: 87.5000 (90.4690)  time: 0.2188  data: 0.0003  max mem: 2503
Test: [Task 1]  [ 630/1627]  eta: 0:03:39  Loss: 1.1378 (1.2546)  Acc@1: 75.0000 (66.5709)  Acc@5: 87.5000 (90.4814)  time: 0.2185  data: 0.0007  max mem: 2503
Test: [Task 1]  [ 640/1627]  eta: 0:03:37  Loss: 1.0777 (1.2548)  Acc@1: 75.0000 (66.6342)  Acc@5: 87.5000 (90.3861)  time: 0.2193  data: 0.0010  max mem: 2503
Test: [Task 1]  [ 650/1627]  eta: 0:03:35  Loss: 1.1026 (1.2544)  Acc@1: 68.7500 (66.6379)  Acc@5: 87.5000 (90.3706)  time: 0.2195  data: 0.0007  max mem: 2503
Test: [Task 1]  [ 660/1627]  eta: 0:03:33  Loss: 1.1940 (1.2526)  Acc@1: 68.7500 (66.6887)  Acc@5: 87.5000 (90.3650)  time: 0.2202  data: 0.0010  max mem: 2503
Test: [Task 1]  [ 670/1627]  eta: 0:03:30  Loss: 1.1940 (1.2519)  Acc@1: 62.5000 (66.7008)  Acc@5: 93.7500 (90.3689)  time: 0.2212  data: 0.0010  max mem: 2503
Test: [Task 1]  [ 680/1627]  eta: 0:03:28  Loss: 1.1949 (1.2516)  Acc@1: 62.5000 (66.7493)  Acc@5: 87.5000 (90.3451)  time: 0.2205  data: 0.0005  max mem: 2503
Test: [Task 1]  [ 690/1627]  eta: 0:03:26  Loss: 1.2311 (1.2496)  Acc@1: 75.0000 (66.7963)  Acc@5: 93.7500 (90.4215)  time: 0.2204  data: 0.0011  max mem: 2503
Test: [Task 1]  [ 700/1627]  eta: 0:03:24  Loss: 1.1987 (1.2493)  Acc@1: 68.7500 (66.8777)  Acc@5: 93.7500 (90.4511)  time: 0.2224  data: 0.0016  max mem: 2503
Test: [Task 1]  [ 710/1627]  eta: 0:03:22  Loss: 1.1288 (1.2469)  Acc@1: 68.7500 (66.9831)  Acc@5: 93.7500 (90.4800)  time: 0.2215  data: 0.0010  max mem: 2503
Test: [Task 1]  [ 720/1627]  eta: 0:03:19  Loss: 1.1274 (1.2449)  Acc@1: 75.0000 (67.0076)  Acc@5: 93.7500 (90.5166)  time: 0.2205  data: 0.0005  max mem: 2503
Test: [Task 1]  [ 730/1627]  eta: 0:03:17  Loss: 1.1430 (1.2463)  Acc@1: 62.5000 (66.9289)  Acc@5: 93.7500 (90.5010)  time: 0.2213  data: 0.0005  max mem: 2503
Test: [Task 1]  [ 740/1627]  eta: 0:03:15  Loss: 1.2590 (1.2472)  Acc@1: 68.7500 (66.9787)  Acc@5: 87.5000 (90.5027)  time: 0.2210  data: 0.0008  max mem: 2503
Test: [Task 1]  [ 750/1627]  eta: 0:03:13  Loss: 1.0995 (1.2462)  Acc@1: 68.7500 (67.0107)  Acc@5: 93.7500 (90.5293)  time: 0.2199  data: 0.0008  max mem: 2503
Test: [Task 1]  [ 760/1627]  eta: 0:03:11  Loss: 1.2696 (1.2494)  Acc@1: 62.5000 (66.9103)  Acc@5: 87.5000 (90.4731)  time: 0.2223  data: 0.0016  max mem: 2503
Test: [Task 1]  [ 770/1627]  eta: 0:03:09  Loss: 1.0294 (1.2454)  Acc@1: 68.7500 (67.0315)  Acc@5: 93.7500 (90.5237)  time: 0.2233  data: 0.0016  max mem: 2503
Test: [Task 1]  [ 780/1627]  eta: 0:03:06  Loss: 0.9838 (1.2437)  Acc@1: 75.0000 (67.0615)  Acc@5: 93.7500 (90.5330)  time: 0.2195  data: 0.0004  max mem: 2503
Test: [Task 1]  [ 790/1627]  eta: 0:03:04  Loss: 1.0363 (1.2451)  Acc@1: 68.7500 (67.0591)  Acc@5: 93.7500 (90.5183)  time: 0.2179  data: 0.0003  max mem: 2503
Test: [Task 1]  [ 800/1627]  eta: 0:03:02  Loss: 1.1875 (1.2439)  Acc@1: 68.7500 (67.0568)  Acc@5: 87.5000 (90.5431)  time: 0.2183  data: 0.0004  max mem: 2503
Test: [Task 1]  [ 810/1627]  eta: 0:03:00  Loss: 1.0790 (1.2431)  Acc@1: 68.7500 (67.1162)  Acc@5: 93.7500 (90.5518)  time: 0.2184  data: 0.0004  max mem: 2503
Test: [Task 1]  [ 820/1627]  eta: 0:02:57  Loss: 1.0689 (1.2421)  Acc@1: 68.7500 (67.1057)  Acc@5: 93.7500 (90.5603)  time: 0.2183  data: 0.0004  max mem: 2503
Test: [Task 1]  [ 830/1627]  eta: 0:02:55  Loss: 1.0158 (1.2413)  Acc@1: 68.7500 (67.1255)  Acc@5: 93.7500 (90.5836)  time: 0.2184  data: 0.0004  max mem: 2503
Test: [Task 1]  [ 840/1627]  eta: 0:02:53  Loss: 1.0337 (1.2392)  Acc@1: 75.0000 (67.1968)  Acc@5: 93.7500 (90.6213)  time: 0.2187  data: 0.0003  max mem: 2503
Test: [Task 1]  [ 850/1627]  eta: 0:02:51  Loss: 1.1598 (1.2398)  Acc@1: 62.5000 (67.1563)  Acc@5: 93.7500 (90.6140)  time: 0.2191  data: 0.0004  max mem: 2503
Test: [Task 1]  [ 860/1627]  eta: 0:02:48  Loss: 1.1097 (1.2385)  Acc@1: 68.7500 (67.1748)  Acc@5: 93.7500 (90.6214)  time: 0.2184  data: 0.0003  max mem: 2503
Test: [Task 1]  [ 870/1627]  eta: 0:02:46  Loss: 1.0064 (1.2367)  Acc@1: 75.0000 (67.2575)  Acc@5: 93.7500 (90.6501)  time: 0.2181  data: 0.0003  max mem: 2503
Test: [Task 1]  [ 880/1627]  eta: 0:02:44  Loss: 1.2392 (1.2390)  Acc@1: 68.7500 (67.1893)  Acc@5: 93.7500 (90.6427)  time: 0.2180  data: 0.0003  max mem: 2503
Test: [Task 1]  [ 890/1627]  eta: 0:02:42  Loss: 1.4060 (1.2409)  Acc@1: 62.5000 (67.1296)  Acc@5: 87.5000 (90.6145)  time: 0.2190  data: 0.0003  max mem: 2503
Test: [Task 1]  [ 900/1627]  eta: 0:02:40  Loss: 1.2271 (1.2409)  Acc@1: 68.7500 (67.1615)  Acc@5: 87.5000 (90.6146)  time: 0.2196  data: 0.0004  max mem: 2503
Test: [Task 1]  [ 910/1627]  eta: 0:02:37  Loss: 1.2387 (1.2418)  Acc@1: 68.7500 (67.1652)  Acc@5: 87.5000 (90.5941)  time: 0.2179  data: 0.0004  max mem: 2503
Test: [Task 1]  [ 920/1627]  eta: 0:02:35  Loss: 1.2377 (1.2414)  Acc@1: 68.7500 (67.1960)  Acc@5: 93.7500 (90.5877)  time: 0.2176  data: 0.0003  max mem: 2503
Test: [Task 1]  [ 930/1627]  eta: 0:02:33  Loss: 1.2353 (1.2425)  Acc@1: 68.7500 (67.1590)  Acc@5: 93.7500 (90.5679)  time: 0.2185  data: 0.0008  max mem: 2503
Test: [Task 1]  [ 940/1627]  eta: 0:02:31  Loss: 1.2320 (1.2410)  Acc@1: 62.5000 (67.2024)  Acc@5: 93.7500 (90.6084)  time: 0.2226  data: 0.0021  max mem: 2503
Test: [Task 1]  [ 950/1627]  eta: 0:02:29  Loss: 1.2692 (1.2420)  Acc@1: 62.5000 (67.1793)  Acc@5: 93.7500 (90.6151)  time: 0.2239  data: 0.0024  max mem: 2503
Test: [Task 1]  [ 960/1627]  eta: 0:02:26  Loss: 1.2509 (1.2416)  Acc@1: 62.5000 (67.1566)  Acc@5: 93.7500 (90.6087)  time: 0.2213  data: 0.0018  max mem: 2503
Test: [Task 1]  [ 970/1627]  eta: 0:02:24  Loss: 1.1559 (1.2405)  Acc@1: 68.7500 (67.1795)  Acc@5: 93.7500 (90.6153)  time: 0.2209  data: 0.0018  max mem: 2503
Test: [Task 1]  [ 980/1627]  eta: 0:02:22  Loss: 1.1559 (1.2409)  Acc@1: 68.7500 (67.1764)  Acc@5: 93.7500 (90.5963)  time: 0.2202  data: 0.0012  max mem: 2503
Test: [Task 1]  [ 990/1627]  eta: 0:02:20  Loss: 1.3042 (1.2441)  Acc@1: 62.5000 (67.1292)  Acc@5: 87.5000 (90.5399)  time: 0.2200  data: 0.0005  max mem: 2503
Test: [Task 1]  [1000/1627]  eta: 0:02:18  Loss: 1.3486 (1.2448)  Acc@1: 62.5000 (67.1204)  Acc@5: 87.5000 (90.5220)  time: 0.2238  data: 0.0017  max mem: 2503
Test: [Task 1]  [1010/1627]  eta: 0:02:15  Loss: 1.2476 (1.2445)  Acc@1: 68.7500 (67.1180)  Acc@5: 93.7500 (90.5415)  time: 0.2260  data: 0.0024  max mem: 2503
Test: [Task 1]  [1020/1627]  eta: 0:02:13  Loss: 1.1889 (1.2441)  Acc@1: 68.7500 (67.1095)  Acc@5: 93.7500 (90.5546)  time: 0.2225  data: 0.0012  max mem: 2503
Test: [Task 1]  [1030/1627]  eta: 0:02:11  Loss: 1.0058 (1.2421)  Acc@1: 75.0000 (67.1799)  Acc@5: 93.7500 (90.6038)  time: 0.2202  data: 0.0006  max mem: 2503
Test: [Task 1]  [1040/1627]  eta: 0:02:09  Loss: 1.0016 (1.2407)  Acc@1: 75.0000 (67.2250)  Acc@5: 93.7500 (90.6460)  time: 0.2191  data: 0.0005  max mem: 2503
Test: [Task 1]  [1050/1627]  eta: 0:02:07  Loss: 1.0336 (1.2389)  Acc@1: 68.7500 (67.2812)  Acc@5: 93.7500 (90.6755)  time: 0.2190  data: 0.0004  max mem: 2503
Test: [Task 1]  [1060/1627]  eta: 0:02:04  Loss: 1.1872 (1.2395)  Acc@1: 68.7500 (67.2891)  Acc@5: 93.7500 (90.6574)  time: 0.2244  data: 0.0025  max mem: 2503
Test: [Task 1]  [1070/1627]  eta: 0:02:02  Loss: 1.1968 (1.2401)  Acc@1: 68.7500 (67.3028)  Acc@5: 87.5000 (90.6396)  time: 0.2254  data: 0.0024  max mem: 2503
Test: [Task 1]  [1080/1627]  eta: 0:02:00  Loss: 1.2701 (1.2406)  Acc@1: 68.7500 (67.2930)  Acc@5: 87.5000 (90.6395)  time: 0.2207  data: 0.0004  max mem: 2503
Test: [Task 1]  [1090/1627]  eta: 0:01:58  Loss: 1.2701 (1.2408)  Acc@1: 62.5000 (67.2663)  Acc@5: 87.5000 (90.6451)  time: 0.2189  data: 0.0003  max mem: 2503
Test: [Task 1]  [1100/1627]  eta: 0:01:56  Loss: 1.1145 (1.2386)  Acc@1: 62.5000 (67.3195)  Acc@5: 93.7500 (90.6619)  time: 0.2191  data: 0.0005  max mem: 2503
Test: [Task 1]  [1110/1627]  eta: 0:01:53  Loss: 1.2238 (1.2395)  Acc@1: 68.7500 (67.3155)  Acc@5: 93.7500 (90.6447)  time: 0.2200  data: 0.0005  max mem: 2503
Test: [Task 1]  [1120/1627]  eta: 0:01:51  Loss: 1.3101 (1.2407)  Acc@1: 62.5000 (67.2112)  Acc@5: 93.7500 (90.6668)  time: 0.2201  data: 0.0004  max mem: 2503
Test: [Task 1]  [1130/1627]  eta: 0:01:49  Loss: 1.2002 (1.2416)  Acc@1: 62.5000 (67.1695)  Acc@5: 93.7500 (90.6830)  time: 0.2201  data: 0.0003  max mem: 2503
Test: [Task 1]  [1140/1627]  eta: 0:01:47  Loss: 1.4147 (1.2429)  Acc@1: 62.5000 (67.1396)  Acc@5: 87.5000 (90.6551)  time: 0.2197  data: 0.0004  max mem: 2503
Test: [Task 1]  [1150/1627]  eta: 0:01:45  Loss: 1.4242 (1.2438)  Acc@1: 62.5000 (67.1264)  Acc@5: 87.5000 (90.6277)  time: 0.2192  data: 0.0004  max mem: 2503
Test: [Task 1]  [1160/1627]  eta: 0:01:42  Loss: 1.2740 (1.2428)  Acc@1: 68.7500 (67.1673)  Acc@5: 87.5000 (90.6277)  time: 0.2185  data: 0.0003  max mem: 2503
Test: [Task 1]  [1170/1627]  eta: 0:01:40  Loss: 1.2740 (1.2419)  Acc@1: 75.0000 (67.2129)  Acc@5: 93.7500 (90.6383)  time: 0.2185  data: 0.0004  max mem: 2503
Test: [Task 1]  [1180/1627]  eta: 0:01:38  Loss: 1.2500 (1.2424)  Acc@1: 68.7500 (67.2153)  Acc@5: 93.7500 (90.6594)  time: 0.2195  data: 0.0005  max mem: 2503
Test: [Task 1]  [1190/1627]  eta: 0:01:36  Loss: 1.2996 (1.2428)  Acc@1: 68.7500 (67.1914)  Acc@5: 93.7500 (90.6696)  time: 0.2194  data: 0.0004  max mem: 2503
Test: [Task 1]  [1200/1627]  eta: 0:01:34  Loss: 1.2856 (1.2429)  Acc@1: 68.7500 (67.1992)  Acc@5: 93.7500 (90.6744)  time: 0.2184  data: 0.0002  max mem: 2503
Test: [Task 1]  [1210/1627]  eta: 0:01:31  Loss: 1.0540 (1.2436)  Acc@1: 68.7500 (67.1707)  Acc@5: 93.7500 (90.6327)  time: 0.2178  data: 0.0002  max mem: 2503
Test: [Task 1]  [1220/1627]  eta: 0:01:29  Loss: 1.0540 (1.2429)  Acc@1: 68.7500 (67.1785)  Acc@5: 93.7500 (90.6583)  time: 0.2189  data: 0.0003  max mem: 2503
Test: [Task 1]  [1230/1627]  eta: 0:01:27  Loss: 1.2955 (1.2430)  Acc@1: 68.7500 (67.1761)  Acc@5: 93.7500 (90.6326)  time: 0.2197  data: 0.0003  max mem: 2503
Test: [Task 1]  [1240/1627]  eta: 0:01:25  Loss: 1.2105 (1.2422)  Acc@1: 68.7500 (67.1837)  Acc@5: 93.7500 (90.6628)  time: 0.2189  data: 0.0003  max mem: 2503
Test: [Task 1]  [1250/1627]  eta: 0:01:23  Loss: 1.2426 (1.2429)  Acc@1: 62.5000 (67.1513)  Acc@5: 93.7500 (90.6475)  time: 0.2199  data: 0.0004  max mem: 2503
Test: [Task 1]  [1260/1627]  eta: 0:01:20  Loss: 1.2010 (1.2428)  Acc@1: 62.5000 (67.1342)  Acc@5: 87.5000 (90.6523)  time: 0.2200  data: 0.0005  max mem: 2503
Test: [Task 1]  [1270/1627]  eta: 0:01:18  Loss: 1.1477 (1.2436)  Acc@1: 68.7500 (67.1223)  Acc@5: 87.5000 (90.6275)  time: 0.2210  data: 0.0004  max mem: 2503
Test: [Task 1]  [1280/1627]  eta: 0:01:16  Loss: 1.0767 (1.2417)  Acc@1: 68.7500 (67.1497)  Acc@5: 87.5000 (90.6518)  time: 0.2217  data: 0.0006  max mem: 2503
Test: [Task 1]  [1290/1627]  eta: 0:01:14  Loss: 1.1543 (1.2421)  Acc@1: 68.7500 (67.1234)  Acc@5: 87.5000 (90.6468)  time: 0.2213  data: 0.0013  max mem: 2503
Test: [Task 1]  [1300/1627]  eta: 0:01:12  Loss: 1.1648 (1.2414)  Acc@1: 68.7500 (67.1599)  Acc@5: 93.7500 (90.6658)  time: 0.2213  data: 0.0012  max mem: 2503
Test: [Task 1]  [1310/1627]  eta: 0:01:09  Loss: 1.0049 (1.2400)  Acc@1: 75.0000 (67.2149)  Acc@5: 93.7500 (90.6798)  time: 0.2199  data: 0.0005  max mem: 2503
Test: [Task 1]  [1320/1627]  eta: 0:01:07  Loss: 0.9514 (1.2383)  Acc@1: 75.0000 (67.2597)  Acc@5: 93.7500 (90.7125)  time: 0.2198  data: 0.0005  max mem: 2503
Test: [Task 1]  [1330/1627]  eta: 0:01:05  Loss: 1.0504 (1.2383)  Acc@1: 68.7500 (67.2802)  Acc@5: 93.7500 (90.7166)  time: 0.2190  data: 0.0004  max mem: 2503
Test: [Task 1]  [1340/1627]  eta: 0:01:03  Loss: 1.1447 (1.2387)  Acc@1: 68.7500 (67.2632)  Acc@5: 87.5000 (90.7159)  time: 0.2195  data: 0.0008  max mem: 2503
Test: [Task 1]  [1350/1627]  eta: 0:01:01  Loss: 1.0949 (1.2380)  Acc@1: 68.7500 (67.2511)  Acc@5: 93.7500 (90.7476)  time: 0.2237  data: 0.0012  max mem: 2503
Test: [Task 1]  [1360/1627]  eta: 0:00:58  Loss: 1.1011 (1.2376)  Acc@1: 62.5000 (67.2529)  Acc@5: 93.7500 (90.7559)  time: 0.2233  data: 0.0008  max mem: 2503
Test: [Task 1]  [1370/1627]  eta: 0:00:56  Loss: 1.1077 (1.2369)  Acc@1: 68.7500 (67.2912)  Acc@5: 93.7500 (90.7732)  time: 0.2191  data: 0.0004  max mem: 2503
Test: [Task 1]  [1380/1627]  eta: 0:00:54  Loss: 1.2303 (1.2373)  Acc@1: 62.5000 (67.2791)  Acc@5: 93.7500 (90.7630)  time: 0.2182  data: 0.0004  max mem: 2503
Test: [Task 1]  [1390/1627]  eta: 0:00:52  Loss: 1.2832 (1.2366)  Acc@1: 68.7500 (67.2942)  Acc@5: 93.7500 (90.7755)  time: 0.2183  data: 0.0004  max mem: 2503
Test: [Task 1]  [1400/1627]  eta: 0:00:50  Loss: 1.2170 (1.2368)  Acc@1: 75.0000 (67.3001)  Acc@5: 93.7500 (90.7700)  time: 0.2193  data: 0.0009  max mem: 2503
Test: [Task 1]  [1410/1627]  eta: 0:00:47  Loss: 1.0606 (1.2364)  Acc@1: 68.7500 (67.3148)  Acc@5: 93.7500 (90.7778)  time: 0.2194  data: 0.0011  max mem: 2503
Test: [Task 1]  [1420/1627]  eta: 0:00:45  Loss: 1.1972 (1.2362)  Acc@1: 62.5000 (67.2942)  Acc@5: 93.7500 (90.8075)  time: 0.2184  data: 0.0006  max mem: 2503
Test: [Task 1]  [1430/1627]  eta: 0:00:43  Loss: 1.3450 (1.2379)  Acc@1: 62.5000 (67.2650)  Acc@5: 93.7500 (90.7888)  time: 0.2180  data: 0.0004  max mem: 2503
Test: [Task 1]  [1440/1627]  eta: 0:00:41  Loss: 1.2130 (1.2372)  Acc@1: 68.7500 (67.2710)  Acc@5: 87.5000 (90.7876)  time: 0.2176  data: 0.0005  max mem: 2503
Test: [Task 1]  [1450/1627]  eta: 0:00:38  Loss: 1.2779 (1.2390)  Acc@1: 68.7500 (67.2209)  Acc@5: 87.5000 (90.7478)  time: 0.2171  data: 0.0004  max mem: 2503
Test: [Task 1]  [1460/1627]  eta: 0:00:36  Loss: 1.3641 (1.2393)  Acc@1: 62.5000 (67.2142)  Acc@5: 93.7500 (90.7555)  time: 0.2173  data: 0.0003  max mem: 2503
Test: [Task 1]  [1470/1627]  eta: 0:00:34  Loss: 1.2604 (1.2400)  Acc@1: 68.7500 (67.1949)  Acc@5: 93.7500 (90.7376)  time: 0.2181  data: 0.0005  max mem: 2503
Test: [Task 1]  [1480/1627]  eta: 0:00:32  Loss: 1.2604 (1.2402)  Acc@1: 68.7500 (67.1801)  Acc@5: 93.7500 (90.7368)  time: 0.2171  data: 0.0004  max mem: 2503
Test: [Task 1]  [1490/1627]  eta: 0:00:30  Loss: 1.2227 (1.2403)  Acc@1: 68.7500 (67.1906)  Acc@5: 93.7500 (90.7529)  time: 0.2155  data: 0.0002  max mem: 2503
Test: [Task 1]  [1500/1627]  eta: 0:00:27  Loss: 1.2454 (1.2402)  Acc@1: 68.7500 (67.2094)  Acc@5: 87.5000 (90.7437)  time: 0.2157  data: 0.0002  max mem: 2503
Test: [Task 1]  [1510/1627]  eta: 0:00:25  Loss: 1.1509 (1.2405)  Acc@1: 68.7500 (67.1865)  Acc@5: 87.5000 (90.7346)  time: 0.2171  data: 0.0003  max mem: 2503
Test: [Task 1]  [1520/1627]  eta: 0:00:23  Loss: 1.1085 (1.2394)  Acc@1: 62.5000 (67.2132)  Acc@5: 93.7500 (90.7503)  time: 0.2181  data: 0.0003  max mem: 2503
Test: [Task 1]  [1530/1627]  eta: 0:00:21  Loss: 1.1085 (1.2392)  Acc@1: 68.7500 (67.2191)  Acc@5: 93.7500 (90.7454)  time: 0.2204  data: 0.0005  max mem: 2503
Test: [Task 1]  [1540/1627]  eta: 0:00:19  Loss: 1.0288 (1.2383)  Acc@1: 68.7500 (67.2169)  Acc@5: 93.7500 (90.7649)  time: 0.2196  data: 0.0004  max mem: 2503
Test: [Task 1]  [1550/1627]  eta: 0:00:16  Loss: 1.0595 (1.2381)  Acc@1: 68.7500 (67.2228)  Acc@5: 93.7500 (90.7761)  time: 0.2186  data: 0.0005  max mem: 2503
Test: [Task 1]  [1560/1627]  eta: 0:00:14  Loss: 1.0022 (1.2368)  Acc@1: 75.0000 (67.3006)  Acc@5: 93.7500 (90.7912)  time: 0.2196  data: 0.0006  max mem: 2503
Test: [Task 1]  [1570/1627]  eta: 0:00:12  Loss: 1.1005 (1.2368)  Acc@1: 75.0000 (67.2860)  Acc@5: 93.7500 (90.8060)  time: 0.2185  data: 0.0009  max mem: 2503
Test: [Task 1]  [1580/1627]  eta: 0:00:10  Loss: 1.2081 (1.2367)  Acc@1: 62.5000 (67.2794)  Acc@5: 93.7500 (90.8088)  time: 0.2190  data: 0.0017  max mem: 2503
Test: [Task 1]  [1590/1627]  eta: 0:00:08  Loss: 1.2043 (1.2370)  Acc@1: 62.5000 (67.2690)  Acc@5: 93.7500 (90.8234)  time: 0.2188  data: 0.0012  max mem: 2503
Test: [Task 1]  [1600/1627]  eta: 0:00:05  Loss: 1.2541 (1.2378)  Acc@1: 62.5000 (67.2392)  Acc@5: 87.5000 (90.7909)  time: 0.2177  data: 0.0004  max mem: 2503
Test: [Task 1]  [1610/1627]  eta: 0:00:03  Loss: 1.2288 (1.2373)  Acc@1: 68.7500 (67.2525)  Acc@5: 87.5000 (90.7860)  time: 0.2185  data: 0.0006  max mem: 2503
Test: [Task 1]  [1620/1627]  eta: 0:00:01  Loss: 1.0698 (1.2363)  Acc@1: 75.0000 (67.3118)  Acc@5: 87.5000 (90.7927)  time: 0.2192  data: 0.0006  max mem: 2503
Test: [Task 1]  [1626/1627]  eta: 0:00:00  Loss: 0.9491 (1.2355)  Acc@1: 75.0000 (67.3440)  Acc@5: 87.5000 (90.7998)  time: 0.2186  data: 0.0003  max mem: 2503
Test: [Task 1] Total time: 0:05:58 (0.2202 s / it)
* Acc@1 67.344 Acc@5 90.800 loss 1.235
Test: [Task 2]  [  0/625]  eta: 0:06:43  Loss: 2.5465 (2.5465)  Acc@1: 25.0000 (25.0000)  Acc@5: 68.7500 (68.7500)  time: 0.6463  data: 0.4270  max mem: 2503
Test: [Task 2]  [ 10/625]  eta: 0:02:37  Loss: 2.7701 (2.8692)  Acc@1: 25.0000 (22.7273)  Acc@5: 68.7500 (65.9091)  time: 0.2567  data: 0.0392  max mem: 2503
Test: [Task 2]  [ 20/625]  eta: 0:02:24  Loss: 2.6611 (2.7888)  Acc@1: 25.0000 (25.5952)  Acc@5: 62.5000 (66.3690)  time: 0.2186  data: 0.0004  max mem: 2503
Test: [Task 2]  [ 30/625]  eta: 0:02:18  Loss: 2.6611 (2.7721)  Acc@1: 25.0000 (25.6048)  Acc@5: 62.5000 (65.1210)  time: 0.2184  data: 0.0003  max mem: 2503
Test: [Task 2]  [ 40/625]  eta: 0:02:14  Loss: 2.9121 (2.8042)  Acc@1: 25.0000 (25.0000)  Acc@5: 56.2500 (64.3293)  time: 0.2187  data: 0.0006  max mem: 2503
Test: [Task 2]  [ 50/625]  eta: 0:02:10  Loss: 2.9906 (2.8389)  Acc@1: 25.0000 (25.1225)  Acc@5: 56.2500 (63.7255)  time: 0.2192  data: 0.0006  max mem: 2503
Test: [Task 2]  [ 60/625]  eta: 0:02:07  Loss: 3.1074 (2.8536)  Acc@1: 25.0000 (24.6926)  Acc@5: 62.5000 (63.9344)  time: 0.2181  data: 0.0003  max mem: 2503
Test: [Task 2]  [ 70/625]  eta: 0:02:04  Loss: 2.8139 (2.8563)  Acc@1: 18.7500 (24.2958)  Acc@5: 62.5000 (64.0845)  time: 0.2178  data: 0.0004  max mem: 2503
Test: [Task 2]  [ 80/625]  eta: 0:02:01  Loss: 2.8081 (2.8498)  Acc@1: 18.7500 (24.6142)  Acc@5: 62.5000 (64.2747)  time: 0.2179  data: 0.0004  max mem: 2503
Test: [Task 2]  [ 90/625]  eta: 0:01:59  Loss: 2.8081 (2.8497)  Acc@1: 25.0000 (24.7253)  Acc@5: 62.5000 (64.3544)  time: 0.2184  data: 0.0003  max mem: 2503
Test: [Task 2]  [100/625]  eta: 0:01:57  Loss: 2.8349 (2.8508)  Acc@1: 25.0000 (24.5050)  Acc@5: 62.5000 (64.2946)  time: 0.2205  data: 0.0011  max mem: 2503
Test: [Task 2]  [110/625]  eta: 0:01:54  Loss: 2.8122 (2.8441)  Acc@1: 25.0000 (24.7748)  Acc@5: 62.5000 (64.5270)  time: 0.2205  data: 0.0011  max mem: 2503
Test: [Task 2]  [120/625]  eta: 0:01:52  Loss: 2.7612 (2.8339)  Acc@1: 25.0000 (24.8967)  Acc@5: 62.5000 (64.7727)  time: 0.2176  data: 0.0003  max mem: 2503
Test: [Task 2]  [130/625]  eta: 0:01:49  Loss: 2.8341 (2.8503)  Acc@1: 18.7500 (24.4752)  Acc@5: 62.5000 (64.5992)  time: 0.2169  data: 0.0003  max mem: 2503
Test: [Task 2]  [140/625]  eta: 0:01:47  Loss: 2.8400 (2.8537)  Acc@1: 18.7500 (24.3794)  Acc@5: 56.2500 (64.0957)  time: 0.2178  data: 0.0003  max mem: 2503
Test: [Task 2]  [150/625]  eta: 0:01:45  Loss: 2.8005 (2.8451)  Acc@1: 25.0000 (24.5033)  Acc@5: 62.5000 (64.4454)  time: 0.2181  data: 0.0003  max mem: 2503
Test: [Task 2]  [160/625]  eta: 0:01:42  Loss: 2.7517 (2.8541)  Acc@1: 25.0000 (24.2624)  Acc@5: 62.5000 (64.1693)  time: 0.2182  data: 0.0003  max mem: 2503
Test: [Task 2]  [170/625]  eta: 0:01:40  Loss: 2.8393 (2.8503)  Acc@1: 18.7500 (24.2690)  Acc@5: 62.5000 (64.3640)  time: 0.2184  data: 0.0003  max mem: 2503
Test: [Task 2]  [180/625]  eta: 0:01:38  Loss: 2.8468 (2.8545)  Acc@1: 18.7500 (24.0331)  Acc@5: 68.7500 (64.3992)  time: 0.2191  data: 0.0004  max mem: 2503
Test: [Task 2]  [190/625]  eta: 0:01:36  Loss: 2.8760 (2.8590)  Acc@1: 25.0000 (24.1819)  Acc@5: 62.5000 (64.1688)  time: 0.2204  data: 0.0004  max mem: 2503
Test: [Task 2]  [200/625]  eta: 0:01:33  Loss: 2.8760 (2.8624)  Acc@1: 25.0000 (23.9739)  Acc@5: 62.5000 (64.1791)  time: 0.2207  data: 0.0010  max mem: 2503
Test: [Task 2]  [210/625]  eta: 0:01:31  Loss: 2.8438 (2.8591)  Acc@1: 25.0000 (24.0818)  Acc@5: 62.5000 (64.3069)  time: 0.2212  data: 0.0020  max mem: 2503
Test: [Task 2]  [220/625]  eta: 0:01:29  Loss: 2.7625 (2.8515)  Acc@1: 31.2500 (24.1233)  Acc@5: 68.7500 (64.2817)  time: 0.2208  data: 0.0014  max mem: 2503
Test: [Task 2]  [230/625]  eta: 0:01:27  Loss: 2.7087 (2.8458)  Acc@1: 25.0000 (24.1883)  Acc@5: 68.7500 (64.3128)  time: 0.2203  data: 0.0004  max mem: 2503
Test: [Task 2]  [240/625]  eta: 0:01:25  Loss: 2.8103 (2.8473)  Acc@1: 25.0000 (24.1183)  Acc@5: 68.7500 (64.4191)  time: 0.2225  data: 0.0007  max mem: 2503
Test: [Task 2]  [250/625]  eta: 0:01:22  Loss: 2.8103 (2.8431)  Acc@1: 25.0000 (24.2530)  Acc@5: 68.7500 (64.4671)  time: 0.2219  data: 0.0007  max mem: 2503
Test: [Task 2]  [260/625]  eta: 0:01:20  Loss: 2.6959 (2.8364)  Acc@1: 25.0000 (24.4253)  Acc@5: 68.7500 (64.6073)  time: 0.2229  data: 0.0023  max mem: 2503
Test: [Task 2]  [270/625]  eta: 0:01:18  Loss: 2.7127 (2.8372)  Acc@1: 31.2500 (24.5849)  Acc@5: 62.5000 (64.4142)  time: 0.2245  data: 0.0023  max mem: 2503
Test: [Task 2]  [280/625]  eta: 0:01:16  Loss: 2.8761 (2.8419)  Acc@1: 18.7500 (24.4440)  Acc@5: 62.5000 (64.3683)  time: 0.2226  data: 0.0010  max mem: 2503
Test: [Task 2]  [290/625]  eta: 0:01:14  Loss: 2.8812 (2.8409)  Acc@1: 18.7500 (24.3986)  Acc@5: 62.5000 (64.4545)  time: 0.2221  data: 0.0017  max mem: 2503
Test: [Task 2]  [300/625]  eta: 0:01:11  Loss: 2.8664 (2.8424)  Acc@1: 18.7500 (24.2940)  Acc@5: 62.5000 (64.5349)  time: 0.2251  data: 0.0014  max mem: 2503
Test: [Task 2]  [310/625]  eta: 0:01:09  Loss: 2.8125 (2.8394)  Acc@1: 18.7500 (24.2765)  Acc@5: 68.7500 (64.6704)  time: 0.2238  data: 0.0007  max mem: 2503
Test: [Task 2]  [320/625]  eta: 0:01:07  Loss: 2.5768 (2.8276)  Acc@1: 25.0000 (24.3185)  Acc@5: 75.0000 (65.2064)  time: 0.2208  data: 0.0004  max mem: 2503
Test: [Task 2]  [330/625]  eta: 0:01:05  Loss: 2.5682 (2.8207)  Acc@1: 25.0000 (24.3958)  Acc@5: 75.0000 (65.3134)  time: 0.2209  data: 0.0004  max mem: 2503
Test: [Task 2]  [340/625]  eta: 0:01:03  Loss: 2.3591 (2.8026)  Acc@1: 31.2500 (24.6518)  Acc@5: 68.7500 (65.7075)  time: 0.2191  data: 0.0004  max mem: 2503
Test: [Task 2]  [350/625]  eta: 0:01:00  Loss: 2.1315 (2.7813)  Acc@1: 31.2500 (24.8575)  Acc@5: 75.0000 (66.1503)  time: 0.2208  data: 0.0014  max mem: 2503
Test: [Task 2]  [360/625]  eta: 0:00:58  Loss: 2.4821 (2.7848)  Acc@1: 25.0000 (24.8788)  Acc@5: 68.7500 (65.9972)  time: 0.2214  data: 0.0014  max mem: 2503
Test: [Task 2]  [370/625]  eta: 0:00:56  Loss: 2.7676 (2.7757)  Acc@1: 25.0000 (25.0337)  Acc@5: 68.7500 (66.2230)  time: 0.2204  data: 0.0004  max mem: 2503
Test: [Task 2]  [380/625]  eta: 0:00:54  Loss: 2.4114 (2.7674)  Acc@1: 31.2500 (25.3117)  Acc@5: 68.7500 (66.2894)  time: 0.2199  data: 0.0004  max mem: 2503
Test: [Task 2]  [390/625]  eta: 0:00:51  Loss: 2.5955 (2.7642)  Acc@1: 31.2500 (25.3197)  Acc@5: 68.7500 (66.4482)  time: 0.2187  data: 0.0003  max mem: 2503
Test: [Task 2]  [400/625]  eta: 0:00:49  Loss: 2.4988 (2.7521)  Acc@1: 25.0000 (25.4364)  Acc@5: 75.0000 (66.7706)  time: 0.2195  data: 0.0009  max mem: 2503
Test: [Task 2]  [410/625]  eta: 0:00:47  Loss: 2.4988 (2.7530)  Acc@1: 18.7500 (25.3650)  Acc@5: 75.0000 (66.9556)  time: 0.2195  data: 0.0009  max mem: 2503
Test: [Task 2]  [420/625]  eta: 0:00:45  Loss: 2.7002 (2.7559)  Acc@1: 18.7500 (25.2227)  Acc@5: 68.7500 (66.9982)  time: 0.2184  data: 0.0003  max mem: 2503
Test: [Task 2]  [430/625]  eta: 0:00:43  Loss: 2.5169 (2.7485)  Acc@1: 25.0000 (25.3625)  Acc@5: 68.7500 (67.1549)  time: 0.2184  data: 0.0003  max mem: 2503
Test: [Task 2]  [440/625]  eta: 0:00:40  Loss: 2.2463 (2.7385)  Acc@1: 31.2500 (25.4677)  Acc@5: 75.0000 (67.3611)  time: 0.2200  data: 0.0010  max mem: 2503
Test: [Task 2]  [450/625]  eta: 0:00:38  Loss: 2.6369 (2.7389)  Acc@1: 25.0000 (25.3326)  Acc@5: 81.2500 (67.5028)  time: 0.2199  data: 0.0010  max mem: 2503
Test: [Task 2]  [460/625]  eta: 0:00:36  Loss: 2.6722 (2.7333)  Acc@1: 25.0000 (25.3932)  Acc@5: 68.7500 (67.5298)  time: 0.2191  data: 0.0007  max mem: 2503
Test: [Task 2]  [470/625]  eta: 0:00:34  Loss: 2.6722 (2.7427)  Acc@1: 25.0000 (25.3317)  Acc@5: 62.5000 (67.3301)  time: 0.2199  data: 0.0006  max mem: 2503
Test: [Task 2]  [480/625]  eta: 0:00:32  Loss: 2.7945 (2.7423)  Acc@1: 25.0000 (25.2859)  Acc@5: 68.7500 (67.3337)  time: 0.2206  data: 0.0004  max mem: 2503
Test: [Task 2]  [490/625]  eta: 0:00:29  Loss: 2.4753 (2.7321)  Acc@1: 25.0000 (25.4201)  Acc@5: 68.7500 (67.4262)  time: 0.2221  data: 0.0007  max mem: 2503
Test: [Task 2]  [500/625]  eta: 0:00:27  Loss: 2.5708 (2.7296)  Acc@1: 25.0000 (25.4242)  Acc@5: 68.7500 (67.4152)  time: 0.2227  data: 0.0019  max mem: 2503
Test: [Task 2]  [510/625]  eta: 0:00:25  Loss: 2.7130 (2.7296)  Acc@1: 25.0000 (25.4525)  Acc@5: 62.5000 (67.3679)  time: 0.2202  data: 0.0017  max mem: 2503
Test: [Task 2]  [520/625]  eta: 0:00:23  Loss: 3.0218 (2.7447)  Acc@1: 12.5000 (25.1200)  Acc@5: 56.2500 (67.1905)  time: 0.2187  data: 0.0006  max mem: 2503
Test: [Task 2]  [530/625]  eta: 0:00:20  Loss: 3.0769 (2.7474)  Acc@1: 12.5000 (25.0235)  Acc@5: 62.5000 (67.1846)  time: 0.2196  data: 0.0006  max mem: 2503
Test: [Task 2]  [540/625]  eta: 0:00:18  Loss: 2.6135 (2.7426)  Acc@1: 25.0000 (25.0924)  Acc@5: 62.5000 (67.1442)  time: 0.2195  data: 0.0006  max mem: 2503
Test: [Task 2]  [550/625]  eta: 0:00:16  Loss: 2.3778 (2.7333)  Acc@1: 31.2500 (25.2269)  Acc@5: 68.7500 (67.3888)  time: 0.2203  data: 0.0006  max mem: 2503
Test: [Task 2]  [560/625]  eta: 0:00:14  Loss: 2.3907 (2.7313)  Acc@1: 25.0000 (25.1337)  Acc@5: 75.0000 (67.5022)  time: 0.2213  data: 0.0006  max mem: 2503
Test: [Task 2]  [570/625]  eta: 0:00:12  Loss: 2.5544 (2.7315)  Acc@1: 18.7500 (25.0657)  Acc@5: 75.0000 (67.4912)  time: 0.2203  data: 0.0006  max mem: 2503
Test: [Task 2]  [580/625]  eta: 0:00:09  Loss: 2.8325 (2.7275)  Acc@1: 18.7500 (25.0430)  Acc@5: 68.7500 (67.6205)  time: 0.2191  data: 0.0004  max mem: 2503
Test: [Task 2]  [590/625]  eta: 0:00:07  Loss: 2.3397 (2.7205)  Acc@1: 25.0000 (25.1798)  Acc@5: 75.0000 (67.7771)  time: 0.2190  data: 0.0004  max mem: 2503
Test: [Task 2]  [600/625]  eta: 0:00:05  Loss: 2.7606 (2.7284)  Acc@1: 18.7500 (25.0000)  Acc@5: 75.0000 (67.7413)  time: 0.2199  data: 0.0004  max mem: 2503
Test: [Task 2]  [610/625]  eta: 0:00:03  Loss: 3.4429 (2.7423)  Acc@1: 12.5000 (24.8261)  Acc@5: 56.2500 (67.4611)  time: 0.2198  data: 0.0004  max mem: 2503
Test: [Task 2]  [620/625]  eta: 0:00:01  Loss: 3.2281 (2.7435)  Acc@1: 18.7500 (24.8088)  Acc@5: 56.2500 (67.4517)  time: 0.2196  data: 0.0007  max mem: 2503
Test: [Task 2]  [624/625]  eta: 0:00:00  Loss: 2.9901 (2.7440)  Acc@1: 18.7500 (24.7600)  Acc@5: 62.5000 (67.4700)  time: 0.2196  data: 0.0007  max mem: 2503
Test: [Task 2] Total time: 0:02:18 (0.2210 s / it)
* Acc@1 24.760 Acc@5 67.470 loss 2.744
Test: [Task 3]  [  0/625]  eta: 0:06:14  Loss: 0.2528 (0.2528)  Acc@1: 93.7500 (93.7500)  Acc@5: 93.7500 (93.7500)  time: 0.5992  data: 0.3816  max mem: 2503
Test: [Task 3]  [ 10/625]  eta: 0:02:35  Loss: 0.2733 (0.2407)  Acc@1: 100.0000 (96.5909)  Acc@5: 100.0000 (99.4318)  time: 0.2533  data: 0.0351  max mem: 2503
Test: [Task 3]  [ 20/625]  eta: 0:02:24  Loss: 0.2425 (0.2533)  Acc@1: 100.0000 (95.5357)  Acc@5: 100.0000 (99.1071)  time: 0.2204  data: 0.0005  max mem: 2503
Test: [Task 3]  [ 30/625]  eta: 0:02:17  Loss: 0.2322 (0.2493)  Acc@1: 93.7500 (95.9677)  Acc@5: 100.0000 (99.1935)  time: 0.2202  data: 0.0004  max mem: 2503
Test: [Task 3]  [ 40/625]  eta: 0:02:13  Loss: 0.1570 (0.2253)  Acc@1: 100.0000 (96.3415)  Acc@5: 100.0000 (99.3902)  time: 0.2186  data: 0.0004  max mem: 2503
Test: [Task 3]  [ 50/625]  eta: 0:02:10  Loss: 0.1623 (0.2217)  Acc@1: 100.0000 (96.4461)  Acc@5: 100.0000 (99.3873)  time: 0.2189  data: 0.0004  max mem: 2503
Test: [Task 3]  [ 60/625]  eta: 0:02:07  Loss: 0.2020 (0.2199)  Acc@1: 100.0000 (96.6189)  Acc@5: 100.0000 (99.4877)  time: 0.2204  data: 0.0004  max mem: 2503
Test: [Task 3]  [ 70/625]  eta: 0:02:04  Loss: 0.1317 (0.2067)  Acc@1: 100.0000 (96.8310)  Acc@5: 100.0000 (99.4718)  time: 0.2195  data: 0.0003  max mem: 2503
Test: [Task 3]  [ 80/625]  eta: 0:02:01  Loss: 0.1239 (0.2110)  Acc@1: 100.0000 (96.7593)  Acc@5: 100.0000 (99.4599)  time: 0.2170  data: 0.0002  max mem: 2503
Test: [Task 3]  [ 90/625]  eta: 0:01:59  Loss: 0.1557 (0.2114)  Acc@1: 100.0000 (96.7033)  Acc@5: 100.0000 (99.3819)  time: 0.2174  data: 0.0003  max mem: 2503
Test: [Task 3]  [100/625]  eta: 0:01:56  Loss: 0.1658 (0.2090)  Acc@1: 100.0000 (96.8441)  Acc@5: 100.0000 (99.4431)  time: 0.2187  data: 0.0003  max mem: 2503
Test: [Task 3]  [110/625]  eta: 0:01:54  Loss: 0.1434 (0.2045)  Acc@1: 100.0000 (97.0158)  Acc@5: 100.0000 (99.4932)  time: 0.2204  data: 0.0003  max mem: 2503
Test: [Task 3]  [120/625]  eta: 0:01:52  Loss: 0.1612 (0.2045)  Acc@1: 100.0000 (97.0041)  Acc@5: 100.0000 (99.5351)  time: 0.2200  data: 0.0003  max mem: 2503
Test: [Task 3]  [130/625]  eta: 0:01:50  Loss: 0.1784 (0.2036)  Acc@1: 100.0000 (97.0897)  Acc@5: 100.0000 (99.5229)  time: 0.2203  data: 0.0010  max mem: 2503
Test: [Task 3]  [140/625]  eta: 0:01:47  Loss: 0.1921 (0.2095)  Acc@1: 93.7500 (96.8972)  Acc@5: 100.0000 (99.3794)  time: 0.2213  data: 0.0012  max mem: 2503
Test: [Task 3]  [150/625]  eta: 0:01:45  Loss: 0.2126 (0.2130)  Acc@1: 100.0000 (96.9785)  Acc@5: 100.0000 (99.3377)  time: 0.2215  data: 0.0017  max mem: 2503
Test: [Task 3]  [160/625]  eta: 0:01:43  Loss: 0.1657 (0.2130)  Acc@1: 100.0000 (96.9720)  Acc@5: 100.0000 (99.3012)  time: 0.2219  data: 0.0016  max mem: 2503
Test: [Task 3]  [170/625]  eta: 0:01:41  Loss: 0.1406 (0.2126)  Acc@1: 100.0000 (96.9298)  Acc@5: 100.0000 (99.3421)  time: 0.2205  data: 0.0005  max mem: 2503
Test: [Task 3]  [180/625]  eta: 0:01:38  Loss: 0.2333 (0.2172)  Acc@1: 93.7500 (96.7541)  Acc@5: 100.0000 (99.3094)  time: 0.2191  data: 0.0004  max mem: 2503
Test: [Task 3]  [190/625]  eta: 0:01:36  Loss: 0.2301 (0.2159)  Acc@1: 93.7500 (96.7605)  Acc@5: 100.0000 (99.3128)  time: 0.2209  data: 0.0014  max mem: 2503
Test: [Task 3]  [200/625]  eta: 0:01:34  Loss: 0.2301 (0.2207)  Acc@1: 93.7500 (96.5485)  Acc@5: 100.0000 (99.3159)  time: 0.2218  data: 0.0019  max mem: 2503
Test: [Task 3]  [210/625]  eta: 0:01:32  Loss: 0.1881 (0.2214)  Acc@1: 93.7500 (96.5640)  Acc@5: 100.0000 (99.2891)  time: 0.2218  data: 0.0008  max mem: 2503
Test: [Task 3]  [220/625]  eta: 0:01:29  Loss: 0.1589 (0.2235)  Acc@1: 100.0000 (96.4932)  Acc@5: 100.0000 (99.2647)  time: 0.2226  data: 0.0009  max mem: 2503
Test: [Task 3]  [230/625]  eta: 0:01:27  Loss: 0.2006 (0.2233)  Acc@1: 93.7500 (96.5097)  Acc@5: 100.0000 (99.2695)  time: 0.2203  data: 0.0009  max mem: 2503
Test: [Task 3]  [240/625]  eta: 0:01:25  Loss: 0.1777 (0.2257)  Acc@1: 93.7500 (96.4212)  Acc@5: 100.0000 (99.2479)  time: 0.2188  data: 0.0004  max mem: 2503
Test: [Task 3]  [250/625]  eta: 0:01:23  Loss: 0.1627 (0.2237)  Acc@1: 93.7500 (96.3894)  Acc@5: 100.0000 (99.2779)  time: 0.2228  data: 0.0009  max mem: 2503
Test: [Task 3]  [260/625]  eta: 0:01:20  Loss: 0.1558 (0.2223)  Acc@1: 93.7500 (96.3602)  Acc@5: 100.0000 (99.2816)  time: 0.2244  data: 0.0010  max mem: 2503
Test: [Task 3]  [270/625]  eta: 0:01:18  Loss: 0.1644 (0.2228)  Acc@1: 93.7500 (96.3330)  Acc@5: 100.0000 (99.2620)  time: 0.2214  data: 0.0005  max mem: 2503
Test: [Task 3]  [280/625]  eta: 0:01:16  Loss: 0.1644 (0.2221)  Acc@1: 93.7500 (96.3523)  Acc@5: 100.0000 (99.2660)  time: 0.2196  data: 0.0003  max mem: 2503
Test: [Task 3]  [290/625]  eta: 0:01:14  Loss: 0.1661 (0.2226)  Acc@1: 93.7500 (96.2844)  Acc@5: 100.0000 (99.2698)  time: 0.2184  data: 0.0003  max mem: 2503
Test: [Task 3]  [300/625]  eta: 0:01:11  Loss: 0.1675 (0.2227)  Acc@1: 93.7500 (96.2625)  Acc@5: 100.0000 (99.2940)  time: 0.2182  data: 0.0003  max mem: 2503
Test: [Task 3]  [310/625]  eta: 0:01:09  Loss: 0.1442 (0.2247)  Acc@1: 100.0000 (96.2219)  Acc@5: 100.0000 (99.2162)  time: 0.2203  data: 0.0009  max mem: 2503
Test: [Task 3]  [320/625]  eta: 0:01:07  Loss: 0.1658 (0.2239)  Acc@1: 93.7500 (96.2422)  Acc@5: 100.0000 (99.2017)  time: 0.2209  data: 0.0010  max mem: 2503
Test: [Task 3]  [330/625]  eta: 0:01:05  Loss: 0.1824 (0.2247)  Acc@1: 93.7500 (96.2047)  Acc@5: 100.0000 (99.1881)  time: 0.2194  data: 0.0004  max mem: 2503
Test: [Task 3]  [340/625]  eta: 0:01:03  Loss: 0.1824 (0.2229)  Acc@1: 100.0000 (96.2977)  Acc@5: 100.0000 (99.2119)  time: 0.2197  data: 0.0005  max mem: 2503
Test: [Task 3]  [350/625]  eta: 0:01:00  Loss: 0.1867 (0.2231)  Acc@1: 100.0000 (96.2785)  Acc@5: 100.0000 (99.1987)  time: 0.2189  data: 0.0005  max mem: 2503
Test: [Task 3]  [360/625]  eta: 0:00:58  Loss: 0.2036 (0.2241)  Acc@1: 93.7500 (96.2431)  Acc@5: 100.0000 (99.2036)  time: 0.2177  data: 0.0003  max mem: 2503
Test: [Task 3]  [370/625]  eta: 0:00:56  Loss: 0.2280 (0.2253)  Acc@1: 93.7500 (96.1759)  Acc@5: 100.0000 (99.2082)  time: 0.2186  data: 0.0005  max mem: 2503
Test: [Task 3]  [380/625]  eta: 0:00:54  Loss: 0.1854 (0.2240)  Acc@1: 93.7500 (96.2270)  Acc@5: 100.0000 (99.2290)  time: 0.2190  data: 0.0005  max mem: 2503
Test: [Task 3]  [390/625]  eta: 0:00:51  Loss: 0.1499 (0.2254)  Acc@1: 100.0000 (96.1477)  Acc@5: 100.0000 (99.2168)  time: 0.2179  data: 0.0003  max mem: 2503
Test: [Task 3]  [400/625]  eta: 0:00:49  Loss: 0.1610 (0.2248)  Acc@1: 93.7500 (96.1347)  Acc@5: 100.0000 (99.2207)  time: 0.2172  data: 0.0003  max mem: 2503
Test: [Task 3]  [410/625]  eta: 0:00:47  Loss: 0.1610 (0.2255)  Acc@1: 100.0000 (96.1375)  Acc@5: 100.0000 (99.2092)  time: 0.2201  data: 0.0003  max mem: 2503
Test: [Task 3]  [420/625]  eta: 0:00:45  Loss: 0.1629 (0.2255)  Acc@1: 100.0000 (96.1401)  Acc@5: 100.0000 (99.2132)  time: 0.2213  data: 0.0003  max mem: 2503
Test: [Task 3]  [430/625]  eta: 0:00:43  Loss: 0.1541 (0.2253)  Acc@1: 93.7500 (96.1427)  Acc@5: 100.0000 (99.2169)  time: 0.2195  data: 0.0004  max mem: 2503
Test: [Task 3]  [440/625]  eta: 0:00:40  Loss: 0.2184 (0.2270)  Acc@1: 93.7500 (96.0884)  Acc@5: 100.0000 (99.1780)  time: 0.2202  data: 0.0004  max mem: 2503
Test: [Task 3]  [450/625]  eta: 0:00:38  Loss: 0.2184 (0.2270)  Acc@1: 93.7500 (96.1197)  Acc@5: 100.0000 (99.1824)  time: 0.2206  data: 0.0003  max mem: 2503
Test: [Task 3]  [460/625]  eta: 0:00:36  Loss: 0.1380 (0.2264)  Acc@1: 100.0000 (96.1497)  Acc@5: 100.0000 (99.1866)  time: 0.2205  data: 0.0011  max mem: 2503
Test: [Task 3]  [470/625]  eta: 0:00:34  Loss: 0.1450 (0.2260)  Acc@1: 100.0000 (96.1385)  Acc@5: 100.0000 (99.1906)  time: 0.2209  data: 0.0011  max mem: 2503
Test: [Task 3]  [480/625]  eta: 0:00:32  Loss: 0.2257 (0.2275)  Acc@1: 100.0000 (96.1409)  Acc@5: 100.0000 (99.1814)  time: 0.2213  data: 0.0005  max mem: 2503
Test: [Task 3]  [490/625]  eta: 0:00:29  Loss: 0.2214 (0.2275)  Acc@1: 100.0000 (96.1431)  Acc@5: 100.0000 (99.1726)  time: 0.2205  data: 0.0006  max mem: 2503
Test: [Task 3]  [500/625]  eta: 0:00:27  Loss: 0.1885 (0.2267)  Acc@1: 100.0000 (96.1452)  Acc@5: 100.0000 (99.1766)  time: 0.2222  data: 0.0013  max mem: 2503
Test: [Task 3]  [510/625]  eta: 0:00:25  Loss: 0.1248 (0.2262)  Acc@1: 100.0000 (96.1473)  Acc@5: 100.0000 (99.1928)  time: 0.2218  data: 0.0013  max mem: 2503
Test: [Task 3]  [520/625]  eta: 0:00:23  Loss: 0.1706 (0.2258)  Acc@1: 100.0000 (96.1492)  Acc@5: 100.0000 (99.1963)  time: 0.2191  data: 0.0004  max mem: 2503
Test: [Task 3]  [530/625]  eta: 0:00:20  Loss: 0.1799 (0.2276)  Acc@1: 93.7500 (96.1040)  Acc@5: 100.0000 (99.2114)  time: 0.2214  data: 0.0012  max mem: 2503
Test: [Task 3]  [540/625]  eta: 0:00:18  Loss: 0.2589 (0.2288)  Acc@1: 93.7500 (96.0952)  Acc@5: 100.0000 (99.1913)  time: 0.2224  data: 0.0015  max mem: 2503
Test: [Task 3]  [550/625]  eta: 0:00:16  Loss: 0.2176 (0.2298)  Acc@1: 93.7500 (96.0867)  Acc@5: 100.0000 (99.1493)  time: 0.2207  data: 0.0007  max mem: 2503
Test: [Task 3]  [560/625]  eta: 0:00:14  Loss: 0.2147 (0.2299)  Acc@1: 93.7500 (96.0784)  Acc@5: 100.0000 (99.1533)  time: 0.2198  data: 0.0004  max mem: 2503
Test: [Task 3]  [570/625]  eta: 0:00:12  Loss: 0.2147 (0.2292)  Acc@1: 93.7500 (96.1033)  Acc@5: 100.0000 (99.1572)  time: 0.2199  data: 0.0004  max mem: 2503
Test: [Task 3]  [580/625]  eta: 0:00:09  Loss: 0.2120 (0.2306)  Acc@1: 93.7500 (96.0413)  Acc@5: 100.0000 (99.1609)  time: 0.2196  data: 0.0004  max mem: 2503
Test: [Task 3]  [590/625]  eta: 0:00:07  Loss: 0.1977 (0.2300)  Acc@1: 93.7500 (96.0766)  Acc@5: 100.0000 (99.1751)  time: 0.2197  data: 0.0003  max mem: 2503
Test: [Task 3]  [600/625]  eta: 0:00:05  Loss: 0.1916 (0.2297)  Acc@1: 100.0000 (96.0587)  Acc@5: 100.0000 (99.1681)  time: 0.2195  data: 0.0003  max mem: 2503
Test: [Task 3]  [610/625]  eta: 0:00:03  Loss: 0.1971 (0.2292)  Acc@1: 93.7500 (96.0618)  Acc@5: 100.0000 (99.1817)  time: 0.2189  data: 0.0003  max mem: 2503
Test: [Task 3]  [620/625]  eta: 0:00:01  Loss: 0.2209 (0.2301)  Acc@1: 93.7500 (96.0346)  Acc@5: 100.0000 (99.1747)  time: 0.2196  data: 0.0005  max mem: 2503
Test: [Task 3]  [624/625]  eta: 0:00:00  Loss: 0.1989 (0.2295)  Acc@1: 93.7500 (96.0600)  Acc@5: 100.0000 (99.1800)  time: 0.2199  data: 0.0005  max mem: 2503
Test: [Task 3] Total time: 0:02:18 (0.2210 s / it)
* Acc@1 96.060 Acc@5 99.180 loss 0.230
Test: [Task 4]  [ 0/29]  eta: 0:00:17  Loss: 2.9411 (2.9411)  Acc@1: 12.5000 (12.5000)  Acc@5: 75.0000 (75.0000)  time: 0.6090  data: 0.3893  max mem: 2503
Test: [Task 4]  [10/29]  eta: 0:00:04  Loss: 2.8542 (2.6108)  Acc@1: 12.5000 (21.0227)  Acc@5: 75.0000 (72.1591)  time: 0.2529  data: 0.0356  max mem: 2503
Test: [Task 4]  [20/29]  eta: 0:00:02  Loss: 3.0973 (2.9181)  Acc@1: 6.2500 (19.0476)  Acc@5: 56.2500 (58.3333)  time: 0.2178  data: 0.0003  max mem: 2503
Test: [Task 4]  [28/29]  eta: 0:00:00  Loss: 3.3249 (2.8602)  Acc@1: 6.2500 (23.0937)  Acc@5: 43.7500 (56.2092)  time: 0.2143  data: 0.0002  max mem: 2503
Test: [Task 4] Total time: 0:00:06 (0.2314 s / it)
* Acc@1 23.094 Acc@5 56.209 loss 2.860
Test: [Task 5]  [  0/625]  eta: 0:05:24  Loss: 0.2223 (0.2223)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)  time: 0.5199  data: 0.2996  max mem: 2503
Test: [Task 5]  [ 10/625]  eta: 0:02:31  Loss: 0.4060 (0.4533)  Acc@1: 87.5000 (89.7727)  Acc@5: 100.0000 (99.4318)  time: 0.2460  data: 0.0275  max mem: 2503
Test: [Task 5]  [ 20/625]  eta: 0:02:22  Loss: 0.4035 (0.3997)  Acc@1: 93.7500 (92.2619)  Acc@5: 100.0000 (99.7024)  time: 0.2205  data: 0.0010  max mem: 2503
Test: [Task 5]  [ 30/625]  eta: 0:02:16  Loss: 0.4771 (0.4455)  Acc@1: 87.5000 (89.9194)  Acc@5: 100.0000 (99.3952)  time: 0.2202  data: 0.0012  max mem: 2503
Test: [Task 5]  [ 40/625]  eta: 0:02:12  Loss: 0.4771 (0.4313)  Acc@1: 87.5000 (90.5488)  Acc@5: 100.0000 (99.3902)  time: 0.2179  data: 0.0004  max mem: 2503
Test: [Task 5]  [ 50/625]  eta: 0:02:10  Loss: 0.4778 (0.4525)  Acc@1: 87.5000 (89.5833)  Acc@5: 100.0000 (98.7745)  time: 0.2221  data: 0.0006  max mem: 2503
Test: [Task 5]  [ 60/625]  eta: 0:02:07  Loss: 0.4418 (0.4467)  Acc@1: 87.5000 (89.4467)  Acc@5: 100.0000 (98.6680)  time: 0.2245  data: 0.0023  max mem: 2503
Test: [Task 5]  [ 70/625]  eta: 0:02:05  Loss: 0.4113 (0.4499)  Acc@1: 87.5000 (88.8204)  Acc@5: 100.0000 (98.5915)  time: 0.2232  data: 0.0026  max mem: 2503
Test: [Task 5]  [ 80/625]  eta: 0:02:02  Loss: 0.4536 (0.4584)  Acc@1: 87.5000 (88.5031)  Acc@5: 100.0000 (98.4568)  time: 0.2226  data: 0.0013  max mem: 2503
Test: [Task 5]  [ 90/625]  eta: 0:02:00  Loss: 0.3948 (0.4497)  Acc@1: 87.5000 (88.8049)  Acc@5: 100.0000 (98.5577)  time: 0.2206  data: 0.0015  max mem: 2503
Test: [Task 5]  [100/625]  eta: 0:01:57  Loss: 0.3948 (0.4555)  Acc@1: 87.5000 (88.3045)  Acc@5: 100.0000 (98.5767)  time: 0.2198  data: 0.0012  max mem: 2503
Test: [Task 5]  [110/625]  eta: 0:01:55  Loss: 0.4313 (0.4556)  Acc@1: 81.2500 (88.1757)  Acc@5: 100.0000 (98.6486)  time: 0.2200  data: 0.0012  max mem: 2503
Test: [Task 5]  [120/625]  eta: 0:01:53  Loss: 0.3744 (0.4474)  Acc@1: 87.5000 (88.3264)  Acc@5: 100.0000 (98.6570)  time: 0.2265  data: 0.0029  max mem: 2503
Test: [Task 5]  [130/625]  eta: 0:01:50  Loss: 0.4344 (0.4525)  Acc@1: 87.5000 (88.1679)  Acc@5: 100.0000 (98.5210)  time: 0.2264  data: 0.0022  max mem: 2503
Test: [Task 5]  [140/625]  eta: 0:01:48  Loss: 0.5152 (0.4504)  Acc@1: 87.5000 (88.2092)  Acc@5: 100.0000 (98.4929)  time: 0.2199  data: 0.0005  max mem: 2503
Test: [Task 5]  [150/625]  eta: 0:01:46  Loss: 0.4157 (0.4533)  Acc@1: 87.5000 (88.0381)  Acc@5: 100.0000 (98.4685)  time: 0.2202  data: 0.0012  max mem: 2503
Test: [Task 5]  [160/625]  eta: 0:01:43  Loss: 0.4764 (0.4574)  Acc@1: 87.5000 (88.0047)  Acc@5: 100.0000 (98.3696)  time: 0.2195  data: 0.0012  max mem: 2503
Test: [Task 5]  [170/625]  eta: 0:01:41  Loss: 0.5197 (0.4632)  Acc@1: 87.5000 (87.6827)  Acc@5: 100.0000 (98.3918)  time: 0.2187  data: 0.0005  max mem: 2503
Test: [Task 5]  [180/625]  eta: 0:01:39  Loss: 0.5030 (0.4660)  Acc@1: 87.5000 (87.6727)  Acc@5: 100.0000 (98.3425)  time: 0.2201  data: 0.0006  max mem: 2503
Test: [Task 5]  [190/625]  eta: 0:01:36  Loss: 0.5046 (0.4774)  Acc@1: 87.5000 (87.4673)  Acc@5: 100.0000 (98.1348)  time: 0.2197  data: 0.0006  max mem: 2503
Test: [Task 5]  [200/625]  eta: 0:01:34  Loss: 0.4866 (0.4750)  Acc@1: 87.5000 (87.5622)  Acc@5: 100.0000 (98.0721)  time: 0.2183  data: 0.0003  max mem: 2503
Test: [Task 5]  [210/625]  eta: 0:01:32  Loss: 0.4840 (0.4808)  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (97.9858)  time: 0.2193  data: 0.0003  max mem: 2503
Test: [Task 5]  [220/625]  eta: 0:01:29  Loss: 0.5932 (0.4822)  Acc@1: 87.5000 (87.5283)  Acc@5: 100.0000 (97.9921)  time: 0.2190  data: 0.0003  max mem: 2503
Test: [Task 5]  [230/625]  eta: 0:01:27  Loss: 0.4660 (0.4816)  Acc@1: 87.5000 (87.5812)  Acc@5: 100.0000 (97.9708)  time: 0.2182  data: 0.0003  max mem: 2503
Test: [Task 5]  [240/625]  eta: 0:01:25  Loss: 0.4002 (0.4819)  Acc@1: 93.7500 (87.6297)  Acc@5: 100.0000 (98.0290)  time: 0.2183  data: 0.0004  max mem: 2503
Test: [Task 5]  [250/625]  eta: 0:01:23  Loss: 0.5198 (0.4843)  Acc@1: 87.5000 (87.5498)  Acc@5: 100.0000 (97.9831)  time: 0.2192  data: 0.0004  max mem: 2503
Test: [Task 5]  [260/625]  eta: 0:01:20  Loss: 0.5134 (0.4841)  Acc@1: 87.5000 (87.5479)  Acc@5: 100.0000 (97.9885)  time: 0.2185  data: 0.0004  max mem: 2503
Test: [Task 5]  [270/625]  eta: 0:01:18  Loss: 0.4373 (0.4825)  Acc@1: 87.5000 (87.6614)  Acc@5: 100.0000 (97.9935)  time: 0.2165  data: 0.0003  max mem: 2503
Test: [Task 5]  [280/625]  eta: 0:01:16  Loss: 0.4365 (0.4801)  Acc@1: 87.5000 (87.7447)  Acc@5: 100.0000 (98.0427)  time: 0.2168  data: 0.0003  max mem: 2503
Test: [Task 5]  [290/625]  eta: 0:01:14  Loss: 0.4095 (0.4783)  Acc@1: 87.5000 (87.8436)  Acc@5: 100.0000 (98.0670)  time: 0.2189  data: 0.0005  max mem: 2503
Test: [Task 5]  [300/625]  eta: 0:01:11  Loss: 0.4629 (0.4813)  Acc@1: 87.5000 (87.6661)  Acc@5: 100.0000 (98.0274)  time: 0.2216  data: 0.0022  max mem: 2503
Test: [Task 5]  [310/625]  eta: 0:01:09  Loss: 0.5124 (0.4819)  Acc@1: 81.2500 (87.6206)  Acc@5: 100.0000 (98.0305)  time: 0.2200  data: 0.0020  max mem: 2503
Test: [Task 5]  [320/625]  eta: 0:01:07  Loss: 0.5108 (0.4829)  Acc@1: 87.5000 (87.6168)  Acc@5: 100.0000 (98.0530)  time: 0.2172  data: 0.0005  max mem: 2503
Test: [Task 5]  [330/625]  eta: 0:01:05  Loss: 0.4436 (0.4815)  Acc@1: 87.5000 (87.7077)  Acc@5: 100.0000 (98.0929)  time: 0.2184  data: 0.0009  max mem: 2503
Test: [Task 5]  [340/625]  eta: 0:01:02  Loss: 0.3537 (0.4776)  Acc@1: 87.5000 (87.8116)  Acc@5: 100.0000 (98.0938)  time: 0.2200  data: 0.0007  max mem: 2503
Test: [Task 5]  [350/625]  eta: 0:01:00  Loss: 0.3911 (0.4833)  Acc@1: 87.5000 (87.6425)  Acc@5: 100.0000 (98.0591)  time: 0.2195  data: 0.0004  max mem: 2503
Test: [Task 5]  [360/625]  eta: 0:00:58  Loss: 0.4675 (0.4814)  Acc@1: 87.5000 (87.7078)  Acc@5: 100.0000 (98.1129)  time: 0.2191  data: 0.0006  max mem: 2503
Test: [Task 5]  [370/625]  eta: 0:00:56  Loss: 0.3809 (0.4797)  Acc@1: 87.5000 (87.7358)  Acc@5: 100.0000 (98.0964)  time: 0.2201  data: 0.0010  max mem: 2503
Test: [Task 5]  [380/625]  eta: 0:00:54  Loss: 0.4633 (0.4809)  Acc@1: 87.5000 (87.6312)  Acc@5: 100.0000 (98.0807)  time: 0.2209  data: 0.0009  max mem: 2503
Test: [Task 5]  [390/625]  eta: 0:00:51  Loss: 0.4965 (0.4818)  Acc@1: 81.2500 (87.5160)  Acc@5: 100.0000 (98.0818)  time: 0.2209  data: 0.0006  max mem: 2503
Test: [Task 5]  [400/625]  eta: 0:00:49  Loss: 0.5079 (0.4806)  Acc@1: 87.5000 (87.5623)  Acc@5: 100.0000 (98.1141)  time: 0.2251  data: 0.0025  max mem: 2503
Test: [Task 5]  [410/625]  eta: 0:00:47  Loss: 0.5092 (0.4811)  Acc@1: 87.5000 (87.5760)  Acc@5: 100.0000 (98.0687)  time: 0.2256  data: 0.0031  max mem: 2503
Test: [Task 5]  [420/625]  eta: 0:00:45  Loss: 0.5092 (0.4816)  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (98.0849)  time: 0.2231  data: 0.0011  max mem: 2503
Test: [Task 5]  [430/625]  eta: 0:00:43  Loss: 0.3981 (0.4802)  Acc@1: 87.5000 (87.5435)  Acc@5: 100.0000 (98.1148)  time: 0.2224  data: 0.0006  max mem: 2503
Test: [Task 5]  [440/625]  eta: 0:00:40  Loss: 0.3953 (0.4801)  Acc@1: 87.5000 (87.4858)  Acc@5: 100.0000 (98.1151)  time: 0.2200  data: 0.0006  max mem: 2503
Test: [Task 5]  [450/625]  eta: 0:00:38  Loss: 0.4201 (0.4791)  Acc@1: 87.5000 (87.5139)  Acc@5: 100.0000 (98.1292)  time: 0.2207  data: 0.0006  max mem: 2503
Test: [Task 5]  [460/625]  eta: 0:00:36  Loss: 0.4246 (0.4784)  Acc@1: 87.5000 (87.5407)  Acc@5: 100.0000 (98.1697)  time: 0.2236  data: 0.0013  max mem: 2503
Test: [Task 5]  [470/625]  eta: 0:00:34  Loss: 0.4013 (0.4749)  Acc@1: 87.5000 (87.6725)  Acc@5: 100.0000 (98.2086)  time: 0.2226  data: 0.0011  max mem: 2503
Test: [Task 5]  [480/625]  eta: 0:00:32  Loss: 0.4013 (0.4750)  Acc@1: 93.7500 (87.6689)  Acc@5: 100.0000 (98.2069)  time: 0.2192  data: 0.0004  max mem: 2503
Test: [Task 5]  [490/625]  eta: 0:00:29  Loss: 0.4122 (0.4744)  Acc@1: 87.5000 (87.6400)  Acc@5: 100.0000 (98.2052)  time: 0.2189  data: 0.0004  max mem: 2503
Test: [Task 5]  [500/625]  eta: 0:00:27  Loss: 0.4193 (0.4750)  Acc@1: 87.5000 (87.5998)  Acc@5: 100.0000 (98.2161)  time: 0.2191  data: 0.0003  max mem: 2503
Test: [Task 5]  [510/625]  eta: 0:00:25  Loss: 0.4913 (0.4755)  Acc@1: 87.5000 (87.5978)  Acc@5: 100.0000 (98.2143)  time: 0.2191  data: 0.0003  max mem: 2503
Test: [Task 5]  [520/625]  eta: 0:00:23  Loss: 0.4663 (0.4749)  Acc@1: 87.5000 (87.6080)  Acc@5: 100.0000 (98.2126)  time: 0.2193  data: 0.0006  max mem: 2503
Test: [Task 5]  [530/625]  eta: 0:00:20  Loss: 0.3894 (0.4732)  Acc@1: 87.5000 (87.6530)  Acc@5: 100.0000 (98.2227)  time: 0.2202  data: 0.0006  max mem: 2503
Test: [Task 5]  [540/625]  eta: 0:00:18  Loss: 0.3519 (0.4713)  Acc@1: 87.5000 (87.6964)  Acc@5: 100.0000 (98.2209)  time: 0.2204  data: 0.0004  max mem: 2503
Test: [Task 5]  [550/625]  eta: 0:00:16  Loss: 0.3610 (0.4729)  Acc@1: 87.5000 (87.6475)  Acc@5: 100.0000 (98.2078)  time: 0.2193  data: 0.0003  max mem: 2503
Test: [Task 5]  [560/625]  eta: 0:00:14  Loss: 0.4538 (0.4730)  Acc@1: 87.5000 (87.6003)  Acc@5: 100.0000 (98.2175)  time: 0.2177  data: 0.0003  max mem: 2503
Test: [Task 5]  [570/625]  eta: 0:00:12  Loss: 0.3728 (0.4715)  Acc@1: 87.5000 (87.6532)  Acc@5: 100.0000 (98.2268)  time: 0.2179  data: 0.0003  max mem: 2503
Test: [Task 5]  [580/625]  eta: 0:00:09  Loss: 0.4315 (0.4730)  Acc@1: 87.5000 (87.6076)  Acc@5: 100.0000 (98.2143)  time: 0.2197  data: 0.0013  max mem: 2503
Test: [Task 5]  [590/625]  eta: 0:00:07  Loss: 0.5597 (0.4723)  Acc@1: 81.2500 (87.6058)  Acc@5: 100.0000 (98.2234)  time: 0.2191  data: 0.0012  max mem: 2503
Test: [Task 5]  [600/625]  eta: 0:00:05  Loss: 0.4168 (0.4709)  Acc@1: 87.5000 (87.6872)  Acc@5: 100.0000 (98.2321)  time: 0.2175  data: 0.0002  max mem: 2503
Test: [Task 5]  [610/625]  eta: 0:00:03  Loss: 0.4168 (0.4704)  Acc@1: 87.5000 (87.7250)  Acc@5: 100.0000 (98.2304)  time: 0.2175  data: 0.0002  max mem: 2503
Test: [Task 5]  [620/625]  eta: 0:00:01  Loss: 0.3516 (0.4688)  Acc@1: 93.7500 (87.7919)  Acc@5: 100.0000 (98.2387)  time: 0.2189  data: 0.0003  max mem: 2503
Test: [Task 5]  [624/625]  eta: 0:00:00  Loss: 0.3532 (0.4693)  Acc@1: 93.7500 (87.7600)  Acc@5: 100.0000 (98.2400)  time: 0.2192  data: 0.0003  max mem: 2503
Test: [Task 5] Total time: 0:02:18 (0.2209 s / it)
* Acc@1 87.760 Acc@5 98.240 loss 0.469
{0: {0: 26032, 1: 26032, 2: 26032, 3: 26032, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0, 10: 0, 11: 0, 12: 0, 13: 0, 14: 0, 15: 0, 16: 0, 17: 0, 18: 0, 19: 0}, 1: {0: 0, 1: 0, 2: 0, 3: 0, 4: 32, 5: 32, 6: 32, 7: 32, 8: 0, 9: 0, 10: 0, 11: 0, 12: 9968, 13: 9968, 14: 9968, 15: 9968, 16: 0, 17: 0, 18: 0, 19: 0}, 2: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 10000, 9: 10000, 10: 10000, 11: 10000, 12: 0, 13: 0, 14: 0, 15: 0, 16: 0, 17: 0, 18: 0, 19: 0}, 3: {0: 0, 1: 0, 2: 0, 3: 0, 4: 64, 5: 64, 6: 64, 7: 64, 8: 0, 9: 0, 10: 0, 11: 0, 12: 395, 13: 395, 14: 395, 15: 395, 16: 0, 17: 0, 18: 0, 19: 0}, 4: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0, 10: 0, 11: 0, 12: 0, 13: 0, 14: 0, 15: 0, 16: 10000, 17: 10000, 18: 10000, 19: 10000}}
[Average accuracy till task5]	Acc@1: 59.8035	Acc@5: 82.3798	Loss: 1.5077	Forgetting: 22.4982	Backward: -22.4982
Total training time: 9:21:36
