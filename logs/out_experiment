/storagenfs/d.arcelli/Prompting-Based-CL-Methods-Experiments/.env/lib/python3.9/site-packages/torchvision/transforms/transforms.py:329: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.
  warnings.warn(
Namespace(subparser_name='cifar100_l2p', train_type='l2p', batch_size=16, epochs=5, model='vit_base_patch16_224', input_size=224, pretrained=True, drop=0.0, drop_path=0.0, opt='adam', opt_eps=1e-08, opt_betas=(0.9, 0.999), clip_grad=1.0, momentum=0.9, weight_decay=0.0, reinit_optimizer=True, sched='constant', lr=0.03, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, unscale_lr=True, color_jitter=None, aa=None, smoothing=0.1, train_interpolation='bicubic', reprob=0.0, remode='pixel', recount=1, data_path='./local_datasets/', dataset='Split-CIFAR100', shuffle=False, output_dir='./output_experiment', device='cuda', seed=729, eval=False, num_workers=4, pin_mem=True, world_size=1, dist_url='env://', num_tasks=10, train_mask=True, task_inc=False, prompt_pool=True, size=50, length=5, top_k=5, initializer='uniform', prompt_key=True, prompt_key_init='uniform', use_prompt_mask=True, shared_prompt_pool=True, shared_prompt_key=True, batchwise_prompt=False, embedding_key='cls', predefined_key='', pull_constraint=True, pull_constraint_coeff=0.5, global_pool='token', head_type='prompt', freeze=['blocks', 'patch_embed', 'cls_token', 'norm', 'pos_embed'], freeze_head=False, print_freq=10)
Not using distributed mode
Files already downloaded and verified
Files already downloaded and verified
Creating original model: vit_base_patch16_224
Creating model: vit_base_patch16_224
number of params: 307300
Start training for 5 epochs
Train: Epoch[1/5]  [  0/313]  eta: 0:09:31  Lr: 0.001875  Loss: 2.3310  Acc@1: 6.2500 (6.2500)  Acc@5: 56.2500 (56.2500)  time: 1.8270  data: 0.5237  max mem: 2355
Train: Epoch[1/5]  [ 10/313]  eta: 0:02:20  Lr: 0.001875  Loss: 2.1887  Acc@1: 31.2500 (32.9545)  Acc@5: 68.7500 (64.7727)  time: 0.4628  data: 0.0479  max mem: 2359
Train: Epoch[1/5]  [ 20/313]  eta: 0:01:56  Lr: 0.001875  Loss: 1.7684  Acc@1: 50.0000 (44.9405)  Acc@5: 81.2500 (77.3810)  time: 0.3270  data: 0.0004  max mem: 2359
Train: Epoch[1/5]  [ 30/313]  eta: 0:01:46  Lr: 0.001875  Loss: 1.6331  Acc@1: 62.5000 (52.2177)  Acc@5: 93.7500 (82.2581)  time: 0.3267  data: 0.0004  max mem: 2359
Train: Epoch[1/5]  [ 40/313]  eta: 0:01:39  Lr: 0.001875  Loss: 1.6409  Acc@1: 68.7500 (55.6402)  Acc@5: 93.7500 (84.7561)  time: 0.3261  data: 0.0004  max mem: 2359
Train: Epoch[1/5]  [ 50/313]  eta: 0:01:33  Lr: 0.001875  Loss: 1.1334  Acc@1: 68.7500 (59.0686)  Acc@5: 93.7500 (86.3971)  time: 0.3265  data: 0.0003  max mem: 2359
Train: Epoch[1/5]  [ 60/313]  eta: 0:01:28  Lr: 0.001875  Loss: 1.3822  Acc@1: 75.0000 (61.7828)  Acc@5: 93.7500 (88.0123)  time: 0.3262  data: 0.0003  max mem: 2359
Train: Epoch[1/5]  [ 70/313]  eta: 0:01:24  Lr: 0.001875  Loss: 1.1451  Acc@1: 68.7500 (63.2042)  Acc@5: 100.0000 (89.3486)  time: 0.3263  data: 0.0003  max mem: 2359
Train: Epoch[1/5]  [ 80/313]  eta: 0:01:20  Lr: 0.001875  Loss: 0.5946  Acc@1: 75.0000 (64.8920)  Acc@5: 100.0000 (90.1235)  time: 0.3266  data: 0.0003  max mem: 2359
Train: Epoch[1/5]  [ 90/313]  eta: 0:01:16  Lr: 0.001875  Loss: 0.6297  Acc@1: 75.0000 (66.0714)  Acc@5: 100.0000 (90.7967)  time: 0.3259  data: 0.0003  max mem: 2359
Train: Epoch[1/5]  [100/313]  eta: 0:01:12  Lr: 0.001875  Loss: 0.8463  Acc@1: 75.0000 (67.2030)  Acc@5: 93.7500 (91.3985)  time: 0.3251  data: 0.0003  max mem: 2359
Train: Epoch[1/5]  [110/313]  eta: 0:01:08  Lr: 0.001875  Loss: 0.6022  Acc@1: 81.2500 (68.2432)  Acc@5: 93.7500 (91.7793)  time: 0.3261  data: 0.0004  max mem: 2359
Train: Epoch[1/5]  [120/313]  eta: 0:01:05  Lr: 0.001875  Loss: 0.3744  Acc@1: 81.2500 (69.2665)  Acc@5: 93.7500 (92.1488)  time: 0.3273  data: 0.0004  max mem: 2359
Train: Epoch[1/5]  [130/313]  eta: 0:01:01  Lr: 0.001875  Loss: 0.5319  Acc@1: 81.2500 (69.9905)  Acc@5: 100.0000 (92.5095)  time: 0.3280  data: 0.0004  max mem: 2359
Train: Epoch[1/5]  [140/313]  eta: 0:00:58  Lr: 0.001875  Loss: 0.3298  Acc@1: 81.2500 (70.7447)  Acc@5: 100.0000 (92.8635)  time: 0.3288  data: 0.0004  max mem: 2359
Train: Epoch[1/5]  [150/313]  eta: 0:00:54  Lr: 0.001875  Loss: 0.3236  Acc@1: 81.2500 (70.9851)  Acc@5: 93.7500 (93.0050)  time: 0.3279  data: 0.0004  max mem: 2359
Train: Epoch[1/5]  [160/313]  eta: 0:00:51  Lr: 0.001875  Loss: 0.5694  Acc@1: 81.2500 (71.7003)  Acc@5: 93.7500 (93.2842)  time: 0.3278  data: 0.0004  max mem: 2359
Train: Epoch[1/5]  [170/313]  eta: 0:00:47  Lr: 0.001875  Loss: 0.3918  Acc@1: 81.2500 (72.4781)  Acc@5: 100.0000 (93.5673)  time: 0.3277  data: 0.0003  max mem: 2359
Train: Epoch[1/5]  [180/313]  eta: 0:00:44  Lr: 0.001875  Loss: 0.1578  Acc@1: 87.5000 (73.1699)  Acc@5: 100.0000 (93.8881)  time: 0.3271  data: 0.0003  max mem: 2359
Train: Epoch[1/5]  [190/313]  eta: 0:00:41  Lr: 0.001875  Loss: 0.0886  Acc@1: 87.5000 (73.6911)  Acc@5: 100.0000 (94.1099)  time: 0.3270  data: 0.0003  max mem: 2359
Train: Epoch[1/5]  [200/313]  eta: 0:00:37  Lr: 0.001875  Loss: 0.4391  Acc@1: 87.5000 (74.1294)  Acc@5: 100.0000 (94.2786)  time: 0.3272  data: 0.0003  max mem: 2359
Train: Epoch[1/5]  [210/313]  eta: 0:00:34  Lr: 0.001875  Loss: 0.2803  Acc@1: 87.5000 (74.7038)  Acc@5: 100.0000 (94.4313)  time: 0.3274  data: 0.0004  max mem: 2359
Train: Epoch[1/5]  [220/313]  eta: 0:00:31  Lr: 0.001875  Loss: 0.3896  Acc@1: 81.2500 (74.9717)  Acc@5: 100.0000 (94.5419)  time: 0.3271  data: 0.0004  max mem: 2359
Train: Epoch[1/5]  [230/313]  eta: 0:00:27  Lr: 0.001875  Loss: 0.3399  Acc@1: 81.2500 (75.4058)  Acc@5: 93.7500 (94.5617)  time: 0.3279  data: 0.0004  max mem: 2359
Train: Epoch[1/5]  [240/313]  eta: 0:00:24  Lr: 0.001875  Loss: 0.3420  Acc@1: 81.2500 (75.7261)  Acc@5: 100.0000 (94.7095)  time: 0.3282  data: 0.0004  max mem: 2359
Train: Epoch[1/5]  [250/313]  eta: 0:00:20  Lr: 0.001875  Loss: 0.1888  Acc@1: 81.2500 (76.0458)  Acc@5: 100.0000 (94.8207)  time: 0.3282  data: 0.0004  max mem: 2359
Train: Epoch[1/5]  [260/313]  eta: 0:00:17  Lr: 0.001875  Loss: -0.1180  Acc@1: 81.2500 (76.1973)  Acc@5: 100.0000 (94.8994)  time: 0.3291  data: 0.0004  max mem: 2359
Train: Epoch[1/5]  [270/313]  eta: 0:00:14  Lr: 0.001875  Loss: -0.0992  Acc@1: 81.2500 (76.4530)  Acc@5: 100.0000 (95.0646)  time: 0.3296  data: 0.0004  max mem: 2359
Train: Epoch[1/5]  [280/313]  eta: 0:00:10  Lr: 0.001875  Loss: -0.0194  Acc@1: 81.2500 (76.7126)  Acc@5: 100.0000 (95.1290)  time: 0.3286  data: 0.0003  max mem: 2359
Train: Epoch[1/5]  [290/313]  eta: 0:00:07  Lr: 0.001875  Loss: 0.1901  Acc@1: 81.2500 (76.8471)  Acc@5: 100.0000 (95.2749)  time: 0.3277  data: 0.0004  max mem: 2359
Train: Epoch[1/5]  [300/313]  eta: 0:00:04  Lr: 0.001875  Loss: -0.0066  Acc@1: 81.2500 (77.0556)  Acc@5: 100.0000 (95.2450)  time: 0.3278  data: 0.0004  max mem: 2359
Train: Epoch[1/5]  [310/313]  eta: 0:00:00  Lr: 0.001875  Loss: 0.0984  Acc@1: 81.2500 (77.2106)  Acc@5: 93.7500 (95.2773)  time: 0.3278  data: 0.0003  max mem: 2359
Train: Epoch[1/5]  [312/313]  eta: 0:00:00  Lr: 0.001875  Loss: -0.2865  Acc@1: 81.2500 (77.3000)  Acc@5: 93.7500 (95.3000)  time: 0.3236  data: 0.0003  max mem: 2359
Train: Epoch[1/5] Total time: 0:01:44 (0.3326 s / it)
Averaged stats: Lr: 0.001875  Loss: -0.2865  Acc@1: 81.2500 (77.3000)  Acc@5: 93.7500 (95.3000)
Train: Epoch[2/5]  [  0/313]  eta: 0:03:09  Lr: 0.001875  Loss: -0.2224  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (100.0000)  time: 0.6050  data: 0.2698  max mem: 2359
Train: Epoch[2/5]  [ 10/313]  eta: 0:01:47  Lr: 0.001875  Loss: -0.4306  Acc@1: 87.5000 (82.9545)  Acc@5: 100.0000 (98.8636)  time: 0.3533  data: 0.0249  max mem: 2359
Train: Epoch[2/5]  [ 20/313]  eta: 0:01:39  Lr: 0.001875  Loss: -0.3705  Acc@1: 75.0000 (81.8452)  Acc@5: 100.0000 (98.2143)  time: 0.3280  data: 0.0004  max mem: 2359
Train: Epoch[2/5]  [ 30/313]  eta: 0:01:35  Lr: 0.001875  Loss: -0.5020  Acc@1: 81.2500 (83.0645)  Acc@5: 100.0000 (97.9839)  time: 0.3282  data: 0.0004  max mem: 2359
Train: Epoch[2/5]  [ 40/313]  eta: 0:01:31  Lr: 0.001875  Loss: -0.1522  Acc@1: 81.2500 (82.7744)  Acc@5: 100.0000 (97.7134)  time: 0.3279  data: 0.0004  max mem: 2359
Train: Epoch[2/5]  [ 50/313]  eta: 0:01:27  Lr: 0.001875  Loss: -0.2902  Acc@1: 87.5000 (84.6814)  Acc@5: 100.0000 (97.9167)  time: 0.3277  data: 0.0004  max mem: 2359
Train: Epoch[2/5]  [ 60/313]  eta: 0:01:24  Lr: 0.001875  Loss: -0.4394  Acc@1: 87.5000 (84.7336)  Acc@5: 100.0000 (98.1557)  time: 0.3282  data: 0.0004  max mem: 2359
Train: Epoch[2/5]  [ 70/313]  eta: 0:01:20  Lr: 0.001875  Loss: -0.0897  Acc@1: 87.5000 (84.6831)  Acc@5: 100.0000 (98.1514)  time: 0.3283  data: 0.0004  max mem: 2359
Train: Epoch[2/5]  [ 80/313]  eta: 0:01:17  Lr: 0.001875  Loss: -0.4011  Acc@1: 87.5000 (85.0309)  Acc@5: 100.0000 (98.0710)  time: 0.3286  data: 0.0004  max mem: 2359
Train: Epoch[2/5]  [ 90/313]  eta: 0:01:13  Lr: 0.001875  Loss: -0.2903  Acc@1: 81.2500 (84.6154)  Acc@5: 100.0000 (98.1456)  time: 0.3288  data: 0.0006  max mem: 2359
Train: Epoch[2/5]  [100/313]  eta: 0:01:10  Lr: 0.001875  Loss: -0.2595  Acc@1: 87.5000 (84.9629)  Acc@5: 100.0000 (98.1436)  time: 0.3295  data: 0.0006  max mem: 2359
Train: Epoch[2/5]  [110/313]  eta: 0:01:07  Lr: 0.001875  Loss: -0.2992  Acc@1: 87.5000 (85.1914)  Acc@5: 100.0000 (98.0293)  time: 0.3297  data: 0.0004  max mem: 2359
Train: Epoch[2/5]  [120/313]  eta: 0:01:03  Lr: 0.001875  Loss: -0.3884  Acc@1: 87.5000 (85.2789)  Acc@5: 100.0000 (98.0372)  time: 0.3289  data: 0.0004  max mem: 2359
Train: Epoch[2/5]  [130/313]  eta: 0:01:00  Lr: 0.001875  Loss: -0.6167  Acc@1: 87.5000 (84.9714)  Acc@5: 100.0000 (98.0439)  time: 0.3291  data: 0.0004  max mem: 2359
Train: Epoch[2/5]  [140/313]  eta: 0:00:57  Lr: 0.001875  Loss: -0.3697  Acc@1: 81.2500 (84.9291)  Acc@5: 100.0000 (98.0053)  time: 0.3292  data: 0.0004  max mem: 2359
Train: Epoch[2/5]  [150/313]  eta: 0:00:53  Lr: 0.001875  Loss: -0.3034  Acc@1: 81.2500 (85.0993)  Acc@5: 100.0000 (98.0546)  time: 0.3283  data: 0.0004  max mem: 2359
Train: Epoch[2/5]  [160/313]  eta: 0:00:50  Lr: 0.001875  Loss: -0.5232  Acc@1: 87.5000 (85.0155)  Acc@5: 100.0000 (98.1366)  time: 0.3289  data: 0.0004  max mem: 2359
Train: Epoch[2/5]  [170/313]  eta: 0:00:47  Lr: 0.001875  Loss: -0.5753  Acc@1: 87.5000 (85.0877)  Acc@5: 100.0000 (98.1360)  time: 0.3297  data: 0.0004  max mem: 2359
Train: Epoch[2/5]  [180/313]  eta: 0:00:43  Lr: 0.001875  Loss: -0.5319  Acc@1: 87.5000 (85.2901)  Acc@5: 100.0000 (98.1354)  time: 0.3292  data: 0.0004  max mem: 2359
Train: Epoch[2/5]  [190/313]  eta: 0:00:40  Lr: 0.001875  Loss: -0.6179  Acc@1: 87.5000 (85.3730)  Acc@5: 100.0000 (98.1348)  time: 0.3289  data: 0.0004  max mem: 2359
Train: Epoch[2/5]  [200/313]  eta: 0:00:37  Lr: 0.001875  Loss: -0.0540  Acc@1: 87.5000 (85.3234)  Acc@5: 100.0000 (98.1343)  time: 0.3290  data: 0.0004  max mem: 2359
Train: Epoch[2/5]  [210/313]  eta: 0:00:33  Lr: 0.001875  Loss: -0.5249  Acc@1: 87.5000 (85.3377)  Acc@5: 100.0000 (98.1635)  time: 0.3293  data: 0.0004  max mem: 2359
Train: Epoch[2/5]  [220/313]  eta: 0:00:30  Lr: 0.001875  Loss: -0.4743  Acc@1: 87.5000 (85.6335)  Acc@5: 100.0000 (98.1618)  time: 0.3294  data: 0.0004  max mem: 2359
Train: Epoch[2/5]  [230/313]  eta: 0:00:27  Lr: 0.001875  Loss: -0.5935  Acc@1: 87.5000 (85.6061)  Acc@5: 100.0000 (98.1061)  time: 0.3293  data: 0.0004  max mem: 2359
Train: Epoch[2/5]  [240/313]  eta: 0:00:24  Lr: 0.001875  Loss: -0.3825  Acc@1: 87.5000 (85.7365)  Acc@5: 100.0000 (98.0809)  time: 0.3292  data: 0.0004  max mem: 2359
Train: Epoch[2/5]  [250/313]  eta: 0:00:20  Lr: 0.001875  Loss: -0.7199  Acc@1: 81.2500 (85.5578)  Acc@5: 100.0000 (98.0329)  time: 0.3288  data: 0.0004  max mem: 2359
Train: Epoch[2/5]  [260/313]  eta: 0:00:17  Lr: 0.001875  Loss: -0.3670  Acc@1: 81.2500 (85.4646)  Acc@5: 100.0000 (98.0125)  time: 0.3288  data: 0.0004  max mem: 2359
Train: Epoch[2/5]  [270/313]  eta: 0:00:14  Lr: 0.001875  Loss: -0.6694  Acc@1: 81.2500 (85.3552)  Acc@5: 100.0000 (98.0627)  time: 0.3291  data: 0.0004  max mem: 2359
Train: Epoch[2/5]  [280/313]  eta: 0:00:10  Lr: 0.001875  Loss: -0.6772  Acc@1: 87.5000 (85.4093)  Acc@5: 100.0000 (98.0649)  time: 0.3290  data: 0.0004  max mem: 2359
Train: Epoch[2/5]  [290/313]  eta: 0:00:07  Lr: 0.001875  Loss: -0.8161  Acc@1: 87.5000 (85.2663)  Acc@5: 100.0000 (98.0455)  time: 0.3296  data: 0.0004  max mem: 2359
Train: Epoch[2/5]  [300/313]  eta: 0:00:04  Lr: 0.001875  Loss: -0.2978  Acc@1: 81.2500 (85.2367)  Acc@5: 100.0000 (98.0274)  time: 0.3303  data: 0.0004  max mem: 2359
Train: Epoch[2/5]  [310/313]  eta: 0:00:00  Lr: 0.001875  Loss: -0.0791  Acc@1: 81.2500 (85.1286)  Acc@5: 100.0000 (98.0305)  time: 0.3299  data: 0.0004  max mem: 2359
Train: Epoch[2/5]  [312/313]  eta: 0:00:00  Lr: 0.001875  Loss: -0.8444  Acc@1: 81.2500 (85.1400)  Acc@5: 100.0000 (98.0200)  time: 0.3214  data: 0.0004  max mem: 2359
Train: Epoch[2/5] Total time: 0:01:43 (0.3297 s / it)
Averaged stats: Lr: 0.001875  Loss: -0.8444  Acc@1: 81.2500 (85.1400)  Acc@5: 100.0000 (98.0200)
Train: Epoch[3/5]  [  0/313]  eta: 0:03:13  Lr: 0.001875  Loss: -0.4149  Acc@1: 81.2500 (81.2500)  Acc@5: 93.7500 (93.7500)  time: 0.6183  data: 0.2875  max mem: 2359
Train: Epoch[3/5]  [ 10/313]  eta: 0:01:47  Lr: 0.001875  Loss: -0.5571  Acc@1: 81.2500 (85.7955)  Acc@5: 100.0000 (98.2955)  time: 0.3563  data: 0.0265  max mem: 2359
Train: Epoch[3/5]  [ 20/313]  eta: 0:01:40  Lr: 0.001875  Loss: -0.2730  Acc@1: 81.2500 (84.8214)  Acc@5: 100.0000 (98.5119)  time: 0.3299  data: 0.0010  max mem: 2359
Train: Epoch[3/5]  [ 30/313]  eta: 0:01:35  Lr: 0.001875  Loss: -0.7589  Acc@1: 87.5000 (86.2903)  Acc@5: 100.0000 (98.7903)  time: 0.3291  data: 0.0011  max mem: 2359
Train: Epoch[3/5]  [ 40/313]  eta: 0:01:31  Lr: 0.001875  Loss: -0.6281  Acc@1: 87.5000 (87.0427)  Acc@5: 100.0000 (98.9329)  time: 0.3283  data: 0.0004  max mem: 2359
Train: Epoch[3/5]  [ 50/313]  eta: 0:01:28  Lr: 0.001875  Loss: -0.8427  Acc@1: 87.5000 (87.1324)  Acc@5: 100.0000 (98.7745)  time: 0.3286  data: 0.0004  max mem: 2359
Train: Epoch[3/5]  [ 60/313]  eta: 0:01:24  Lr: 0.001875  Loss: -0.1314  Acc@1: 87.5000 (86.7828)  Acc@5: 100.0000 (98.5656)  time: 0.3292  data: 0.0004  max mem: 2359
Train: Epoch[3/5]  [ 70/313]  eta: 0:01:20  Lr: 0.001875  Loss: -0.5283  Acc@1: 87.5000 (86.7958)  Acc@5: 100.0000 (98.4155)  time: 0.3290  data: 0.0004  max mem: 2359
Train: Epoch[3/5]  [ 80/313]  eta: 0:01:17  Lr: 0.001875  Loss: -0.6827  Acc@1: 87.5000 (86.4969)  Acc@5: 100.0000 (98.3796)  time: 0.3289  data: 0.0004  max mem: 2359
Train: Epoch[3/5]  [ 90/313]  eta: 0:01:14  Lr: 0.001875  Loss: -0.5249  Acc@1: 87.5000 (86.6758)  Acc@5: 100.0000 (98.3516)  time: 0.3296  data: 0.0004  max mem: 2359
Train: Epoch[3/5]  [100/313]  eta: 0:01:10  Lr: 0.001875  Loss: -0.6760  Acc@1: 87.5000 (86.7574)  Acc@5: 100.0000 (98.2054)  time: 0.3298  data: 0.0004  max mem: 2359
Train: Epoch[3/5]  [110/313]  eta: 0:01:07  Lr: 0.001875  Loss: -0.8230  Acc@1: 87.5000 (86.7117)  Acc@5: 100.0000 (98.3108)  time: 0.3297  data: 0.0003  max mem: 2359
Train: Epoch[3/5]  [120/313]  eta: 0:01:04  Lr: 0.001875  Loss: -0.7216  Acc@1: 87.5000 (86.6219)  Acc@5: 100.0000 (98.1921)  time: 0.3296  data: 0.0003  max mem: 2359
Train: Epoch[3/5]  [130/313]  eta: 0:01:00  Lr: 0.001875  Loss: -0.5132  Acc@1: 87.5000 (86.5935)  Acc@5: 100.0000 (98.2824)  time: 0.3295  data: 0.0003  max mem: 2359
Train: Epoch[3/5]  [140/313]  eta: 0:00:57  Lr: 0.001875  Loss: -0.6118  Acc@1: 87.5000 (86.7908)  Acc@5: 100.0000 (98.3599)  time: 0.3295  data: 0.0003  max mem: 2359
Train: Epoch[3/5]  [150/313]  eta: 0:00:53  Lr: 0.001875  Loss: -0.7151  Acc@1: 93.7500 (87.2517)  Acc@5: 100.0000 (98.3444)  time: 0.3296  data: 0.0004  max mem: 2359
Train: Epoch[3/5]  [160/313]  eta: 0:00:50  Lr: 0.001875  Loss: -0.7887  Acc@1: 93.7500 (87.1506)  Acc@5: 100.0000 (98.2919)  time: 0.3302  data: 0.0004  max mem: 2359
Train: Epoch[3/5]  [170/313]  eta: 0:00:47  Lr: 0.001875  Loss: -0.5851  Acc@1: 81.2500 (86.9152)  Acc@5: 100.0000 (98.2456)  time: 0.3301  data: 0.0004  max mem: 2359
Train: Epoch[3/5]  [180/313]  eta: 0:00:44  Lr: 0.001875  Loss: -0.9659  Acc@1: 87.5000 (87.1202)  Acc@5: 100.0000 (98.2735)  time: 0.3298  data: 0.0004  max mem: 2359
Train: Epoch[3/5]  [190/313]  eta: 0:00:40  Lr: 0.001875  Loss: -0.2825  Acc@1: 87.5000 (86.6819)  Acc@5: 100.0000 (98.2984)  time: 0.3300  data: 0.0004  max mem: 2359
Train: Epoch[3/5]  [200/313]  eta: 0:00:37  Lr: 0.001875  Loss: -0.7627  Acc@1: 81.2500 (86.6604)  Acc@5: 100.0000 (98.3209)  time: 0.3299  data: 0.0004  max mem: 2359
Train: Epoch[3/5]  [210/313]  eta: 0:00:34  Lr: 0.001875  Loss: -0.7272  Acc@1: 87.5000 (86.5818)  Acc@5: 100.0000 (98.2524)  time: 0.3300  data: 0.0004  max mem: 2359
Train: Epoch[3/5]  [220/313]  eta: 0:00:30  Lr: 0.001875  Loss: -0.7959  Acc@1: 87.5000 (86.5102)  Acc@5: 100.0000 (98.2466)  time: 0.3307  data: 0.0004  max mem: 2359
Train: Epoch[3/5]  [230/313]  eta: 0:00:27  Lr: 0.001875  Loss: -0.5920  Acc@1: 87.5000 (86.6613)  Acc@5: 100.0000 (98.2413)  time: 0.3306  data: 0.0004  max mem: 2359
Train: Epoch[3/5]  [240/313]  eta: 0:00:24  Lr: 0.001875  Loss: -0.3404  Acc@1: 87.5000 (86.7220)  Acc@5: 100.0000 (98.2884)  time: 0.3295  data: 0.0004  max mem: 2359
Train: Epoch[3/5]  [250/313]  eta: 0:00:20  Lr: 0.001875  Loss: -0.7143  Acc@1: 87.5000 (86.7530)  Acc@5: 100.0000 (98.2819)  time: 0.3299  data: 0.0004  max mem: 2359
Train: Epoch[3/5]  [260/313]  eta: 0:00:17  Lr: 0.001875  Loss: -0.8255  Acc@1: 87.5000 (86.8534)  Acc@5: 100.0000 (98.2759)  time: 0.3302  data: 0.0004  max mem: 2359
Train: Epoch[3/5]  [270/313]  eta: 0:00:14  Lr: 0.001875  Loss: -0.6401  Acc@1: 81.2500 (86.7159)  Acc@5: 100.0000 (98.2703)  time: 0.3296  data: 0.0004  max mem: 2359
Train: Epoch[3/5]  [280/313]  eta: 0:00:10  Lr: 0.001875  Loss: -0.4919  Acc@1: 81.2500 (86.5436)  Acc@5: 100.0000 (98.2206)  time: 0.3296  data: 0.0004  max mem: 2359
Train: Epoch[3/5]  [290/313]  eta: 0:00:07  Lr: 0.001875  Loss: -0.9047  Acc@1: 87.5000 (86.6194)  Acc@5: 100.0000 (98.2388)  time: 0.3303  data: 0.0004  max mem: 2359
Train: Epoch[3/5]  [300/313]  eta: 0:00:04  Lr: 0.001875  Loss: -0.7181  Acc@1: 87.5000 (86.7317)  Acc@5: 100.0000 (98.2143)  time: 0.3314  data: 0.0005  max mem: 2359
Train: Epoch[3/5]  [310/313]  eta: 0:00:00  Lr: 0.001875  Loss: -0.9876  Acc@1: 87.5000 (86.8167)  Acc@5: 100.0000 (98.2516)  time: 0.3312  data: 0.0004  max mem: 2359
Train: Epoch[3/5]  [312/313]  eta: 0:00:00  Lr: 0.001875  Loss: -0.6923  Acc@1: 87.5000 (86.7800)  Acc@5: 100.0000 (98.2600)  time: 0.3228  data: 0.0004  max mem: 2359
Train: Epoch[3/5] Total time: 0:01:43 (0.3306 s / it)
Averaged stats: Lr: 0.001875  Loss: -0.6923  Acc@1: 87.5000 (86.7800)  Acc@5: 100.0000 (98.2600)
Train: Epoch[4/5]  [  0/313]  eta: 0:03:24  Lr: 0.001875  Loss: -0.9633  Acc@1: 93.7500 (93.7500)  Acc@5: 100.0000 (100.0000)  time: 0.6524  data: 0.3191  max mem: 2359
Train: Epoch[4/5]  [ 10/313]  eta: 0:01:49  Lr: 0.001875  Loss: -0.9397  Acc@1: 87.5000 (88.6364)  Acc@5: 100.0000 (99.4318)  time: 0.3608  data: 0.0294  max mem: 2359
Train: Epoch[4/5]  [ 20/313]  eta: 0:01:41  Lr: 0.001875  Loss: -0.7942  Acc@1: 87.5000 (87.2024)  Acc@5: 100.0000 (99.4048)  time: 0.3309  data: 0.0003  max mem: 2359
Train: Epoch[4/5]  [ 30/313]  eta: 0:01:36  Lr: 0.001875  Loss: -0.6386  Acc@1: 87.5000 (87.7016)  Acc@5: 100.0000 (98.7903)  time: 0.3305  data: 0.0004  max mem: 2359
Train: Epoch[4/5]  [ 40/313]  eta: 0:01:32  Lr: 0.001875  Loss: -0.7852  Acc@1: 87.5000 (87.1951)  Acc@5: 100.0000 (98.9329)  time: 0.3312  data: 0.0004  max mem: 2359
Train: Epoch[4/5]  [ 50/313]  eta: 0:01:28  Lr: 0.001875  Loss: -0.6294  Acc@1: 87.5000 (88.2353)  Acc@5: 100.0000 (99.1422)  time: 0.3315  data: 0.0005  max mem: 2359
Train: Epoch[4/5]  [ 60/313]  eta: 0:01:25  Lr: 0.001875  Loss: -0.8298  Acc@1: 93.7500 (87.7049)  Acc@5: 100.0000 (98.9754)  time: 0.3311  data: 0.0005  max mem: 2359
Train: Epoch[4/5]  [ 70/313]  eta: 0:01:21  Lr: 0.001875  Loss: -0.8818  Acc@1: 87.5000 (87.6761)  Acc@5: 100.0000 (99.0317)  time: 0.3306  data: 0.0004  max mem: 2359
Train: Epoch[4/5]  [ 80/313]  eta: 0:01:17  Lr: 0.001875  Loss: -0.9921  Acc@1: 87.5000 (87.7315)  Acc@5: 100.0000 (99.0741)  time: 0.3298  data: 0.0004  max mem: 2359
Train: Epoch[4/5]  [ 90/313]  eta: 0:01:14  Lr: 0.001875  Loss: -0.7570  Acc@1: 87.5000 (87.7747)  Acc@5: 100.0000 (99.1071)  time: 0.3300  data: 0.0004  max mem: 2359
Train: Epoch[4/5]  [100/313]  eta: 0:01:11  Lr: 0.001875  Loss: -0.6712  Acc@1: 93.7500 (88.1807)  Acc@5: 100.0000 (99.1337)  time: 0.3302  data: 0.0004  max mem: 2359
Train: Epoch[4/5]  [110/313]  eta: 0:01:07  Lr: 0.001875  Loss: -0.7676  Acc@1: 87.5000 (88.1194)  Acc@5: 100.0000 (99.0991)  time: 0.3299  data: 0.0004  max mem: 2359
Train: Epoch[4/5]  [120/313]  eta: 0:01:04  Lr: 0.001875  Loss: -1.0190  Acc@1: 87.5000 (88.1198)  Acc@5: 100.0000 (99.0702)  time: 0.3297  data: 0.0004  max mem: 2359
Train: Epoch[4/5]  [130/313]  eta: 0:01:00  Lr: 0.001875  Loss: -0.4217  Acc@1: 87.5000 (87.8340)  Acc@5: 100.0000 (98.9504)  time: 0.3296  data: 0.0003  max mem: 2359
Train: Epoch[4/5]  [140/313]  eta: 0:00:57  Lr: 0.001875  Loss: -0.6290  Acc@1: 87.5000 (87.8103)  Acc@5: 100.0000 (98.9362)  time: 0.3291  data: 0.0003  max mem: 2359
Train: Epoch[4/5]  [150/313]  eta: 0:00:54  Lr: 0.001875  Loss: -0.8799  Acc@1: 87.5000 (87.9967)  Acc@5: 100.0000 (98.9652)  time: 0.3289  data: 0.0003  max mem: 2359
Train: Epoch[4/5]  [160/313]  eta: 0:00:50  Lr: 0.001875  Loss: -0.8767  Acc@1: 87.5000 (87.9270)  Acc@5: 100.0000 (98.8742)  time: 0.3303  data: 0.0004  max mem: 2359
Train: Epoch[4/5]  [170/313]  eta: 0:00:47  Lr: 0.001875  Loss: -0.7653  Acc@1: 87.5000 (87.8655)  Acc@5: 100.0000 (98.7939)  time: 0.3312  data: 0.0005  max mem: 2359
Train: Epoch[4/5]  [180/313]  eta: 0:00:44  Lr: 0.001875  Loss: -0.9751  Acc@1: 87.5000 (87.9489)  Acc@5: 100.0000 (98.8605)  time: 0.3311  data: 0.0005  max mem: 2359
Train: Epoch[4/5]  [190/313]  eta: 0:00:40  Lr: 0.001875  Loss: -0.4853  Acc@1: 87.5000 (88.0563)  Acc@5: 100.0000 (98.8220)  time: 0.3309  data: 0.0004  max mem: 2359
Train: Epoch[4/5]  [200/313]  eta: 0:00:37  Lr: 0.001875  Loss: -0.5034  Acc@1: 87.5000 (88.0908)  Acc@5: 100.0000 (98.8495)  time: 0.3309  data: 0.0004  max mem: 2359
Train: Epoch[4/5]  [210/313]  eta: 0:00:34  Lr: 0.001875  Loss: -0.8465  Acc@1: 87.5000 (88.1220)  Acc@5: 100.0000 (98.8152)  time: 0.3312  data: 0.0005  max mem: 2359
Train: Epoch[4/5]  [220/313]  eta: 0:00:30  Lr: 0.001875  Loss: -0.6901  Acc@1: 87.5000 (88.0939)  Acc@5: 100.0000 (98.8688)  time: 0.3308  data: 0.0004  max mem: 2359
Train: Epoch[4/5]  [230/313]  eta: 0:00:27  Lr: 0.001875  Loss: -0.6910  Acc@1: 81.2500 (87.9600)  Acc@5: 100.0000 (98.8907)  time: 0.3300  data: 0.0004  max mem: 2359
Train: Epoch[4/5]  [240/313]  eta: 0:00:24  Lr: 0.001875  Loss: -1.0625  Acc@1: 87.5000 (87.8890)  Acc@5: 100.0000 (98.8589)  time: 0.3311  data: 0.0006  max mem: 2359
Train: Epoch[4/5]  [250/313]  eta: 0:00:20  Lr: 0.001875  Loss: -0.5911  Acc@1: 87.5000 (87.7490)  Acc@5: 100.0000 (98.8297)  time: 0.3316  data: 0.0006  max mem: 2359
Train: Epoch[4/5]  [260/313]  eta: 0:00:17  Lr: 0.001875  Loss: -0.5378  Acc@1: 81.2500 (87.6197)  Acc@5: 100.0000 (98.8506)  time: 0.3321  data: 0.0004  max mem: 2359
Train: Epoch[4/5]  [270/313]  eta: 0:00:14  Lr: 0.001875  Loss: -0.6745  Acc@1: 81.2500 (87.3386)  Acc@5: 100.0000 (98.8699)  time: 0.3316  data: 0.0004  max mem: 2359
Train: Epoch[4/5]  [280/313]  eta: 0:00:10  Lr: 0.001875  Loss: -0.9638  Acc@1: 87.5000 (87.4555)  Acc@5: 100.0000 (98.8879)  time: 0.3298  data: 0.0004  max mem: 2359
Train: Epoch[4/5]  [290/313]  eta: 0:00:07  Lr: 0.001875  Loss: -0.3979  Acc@1: 93.7500 (87.5000)  Acc@5: 100.0000 (98.8832)  time: 0.3308  data: 0.0004  max mem: 2359
Train: Epoch[4/5]  [300/313]  eta: 0:00:04  Lr: 0.001875  Loss: -0.1922  Acc@1: 87.5000 (87.4792)  Acc@5: 100.0000 (98.9203)  time: 0.3312  data: 0.0004  max mem: 2359
Train: Epoch[4/5]  [310/313]  eta: 0:00:00  Lr: 0.001875  Loss: -0.8901  Acc@1: 87.5000 (87.5402)  Acc@5: 100.0000 (98.9148)  time: 0.3308  data: 0.0004  max mem: 2359
Train: Epoch[4/5]  [312/313]  eta: 0:00:00  Lr: 0.001875  Loss: -0.9299  Acc@1: 87.5000 (87.5800)  Acc@5: 100.0000 (98.9200)  time: 0.3237  data: 0.0004  max mem: 2359
Train: Epoch[4/5] Total time: 0:01:43 (0.3315 s / it)
Averaged stats: Lr: 0.001875  Loss: -0.9299  Acc@1: 87.5000 (87.5800)  Acc@5: 100.0000 (98.9200)
Train: Epoch[5/5]  [  0/313]  eta: 0:03:10  Lr: 0.001875  Loss: -1.0621  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)  time: 0.6088  data: 0.2732  max mem: 2359
Train: Epoch[5/5]  [ 10/313]  eta: 0:01:48  Lr: 0.001875  Loss: -0.6797  Acc@1: 93.7500 (90.9091)  Acc@5: 100.0000 (98.2955)  time: 0.3569  data: 0.0252  max mem: 2359
Train: Epoch[5/5]  [ 20/313]  eta: 0:01:41  Lr: 0.001875  Loss: -0.8533  Acc@1: 87.5000 (89.8810)  Acc@5: 100.0000 (98.8095)  time: 0.3316  data: 0.0004  max mem: 2359
Train: Epoch[5/5]  [ 30/313]  eta: 0:01:36  Lr: 0.001875  Loss: -0.4913  Acc@1: 87.5000 (88.7097)  Acc@5: 100.0000 (98.5887)  time: 0.3311  data: 0.0006  max mem: 2359
Train: Epoch[5/5]  [ 40/313]  eta: 0:01:32  Lr: 0.001875  Loss: -1.0159  Acc@1: 87.5000 (88.7195)  Acc@5: 100.0000 (98.6280)  time: 0.3305  data: 0.0006  max mem: 2359
Train: Epoch[5/5]  [ 50/313]  eta: 0:01:28  Lr: 0.001875  Loss: -0.9656  Acc@1: 81.2500 (87.8676)  Acc@5: 100.0000 (98.5294)  time: 0.3316  data: 0.0004  max mem: 2359
Train: Epoch[5/5]  [ 60/313]  eta: 0:01:24  Lr: 0.001875  Loss: -0.7199  Acc@1: 87.5000 (87.9098)  Acc@5: 100.0000 (98.7705)  time: 0.3314  data: 0.0004  max mem: 2359
Train: Epoch[5/5]  [ 70/313]  eta: 0:01:21  Lr: 0.001875  Loss: -0.9378  Acc@1: 87.5000 (87.8521)  Acc@5: 100.0000 (98.6796)  time: 0.3300  data: 0.0004  max mem: 2359
Train: Epoch[5/5]  [ 80/313]  eta: 0:01:17  Lr: 0.001875  Loss: -0.5958  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (98.4568)  time: 0.3312  data: 0.0005  max mem: 2359
Train: Epoch[5/5]  [ 90/313]  eta: 0:01:14  Lr: 0.001875  Loss: -0.3491  Acc@1: 87.5000 (87.4313)  Acc@5: 100.0000 (98.4203)  time: 0.3312  data: 0.0005  max mem: 2359
Train: Epoch[5/5]  [100/313]  eta: 0:01:11  Lr: 0.001875  Loss: -0.4816  Acc@1: 87.5000 (87.7475)  Acc@5: 100.0000 (98.3911)  time: 0.3302  data: 0.0005  max mem: 2359
Train: Epoch[5/5]  [110/313]  eta: 0:01:07  Lr: 0.001875  Loss: -0.8696  Acc@1: 87.5000 (87.8378)  Acc@5: 100.0000 (98.4234)  time: 0.3307  data: 0.0004  max mem: 2359
Train: Epoch[5/5]  [120/313]  eta: 0:01:04  Lr: 0.001875  Loss: -0.4891  Acc@1: 87.5000 (87.1384)  Acc@5: 100.0000 (98.3988)  time: 0.3308  data: 0.0004  max mem: 2359
Train: Epoch[5/5]  [130/313]  eta: 0:01:00  Lr: 0.001875  Loss: -0.8297  Acc@1: 81.2500 (87.2137)  Acc@5: 100.0000 (98.4733)  time: 0.3295  data: 0.0004  max mem: 2359
Train: Epoch[5/5]  [140/313]  eta: 0:00:57  Lr: 0.001875  Loss: -0.7950  Acc@1: 87.5000 (87.1011)  Acc@5: 100.0000 (98.4043)  time: 0.3283  data: 0.0003  max mem: 2359
Train: Epoch[5/5]  [150/313]  eta: 0:00:54  Lr: 0.001875  Loss: -0.7542  Acc@1: 87.5000 (87.4586)  Acc@5: 100.0000 (98.5099)  time: 0.3284  data: 0.0003  max mem: 2359
Train: Epoch[5/5]  [160/313]  eta: 0:00:50  Lr: 0.001875  Loss: -0.7550  Acc@1: 87.5000 (87.2283)  Acc@5: 100.0000 (98.4860)  time: 0.3295  data: 0.0004  max mem: 2359
Train: Epoch[5/5]  [170/313]  eta: 0:00:47  Lr: 0.001875  Loss: -0.4877  Acc@1: 87.5000 (87.2442)  Acc@5: 100.0000 (98.5015)  time: 0.3298  data: 0.0004  max mem: 2359
Train: Epoch[5/5]  [180/313]  eta: 0:00:44  Lr: 0.001875  Loss: -0.5801  Acc@1: 87.5000 (87.1547)  Acc@5: 100.0000 (98.4116)  time: 0.3294  data: 0.0003  max mem: 2359
Train: Epoch[5/5]  [190/313]  eta: 0:00:40  Lr: 0.001875  Loss: -0.8806  Acc@1: 87.5000 (87.3364)  Acc@5: 100.0000 (98.3966)  time: 0.3292  data: 0.0004  max mem: 2359
Train: Epoch[5/5]  [200/313]  eta: 0:00:37  Lr: 0.001875  Loss: -0.8178  Acc@1: 93.7500 (87.4689)  Acc@5: 100.0000 (98.4453)  time: 0.3294  data: 0.0004  max mem: 2359
Train: Epoch[5/5]  [210/313]  eta: 0:00:34  Lr: 0.001875  Loss: -0.6530  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (98.4597)  time: 0.3294  data: 0.0003  max mem: 2359
Train: Epoch[5/5]  [220/313]  eta: 0:00:30  Lr: 0.001875  Loss: -0.7392  Acc@1: 87.5000 (87.4717)  Acc@5: 100.0000 (98.4729)  time: 0.3291  data: 0.0003  max mem: 2359
Train: Epoch[5/5]  [230/313]  eta: 0:00:27  Lr: 0.001875  Loss: -0.9231  Acc@1: 87.5000 (87.5541)  Acc@5: 100.0000 (98.5390)  time: 0.3287  data: 0.0004  max mem: 2359
Train: Epoch[5/5]  [240/313]  eta: 0:00:24  Lr: 0.001875  Loss: -0.8862  Acc@1: 93.7500 (87.7593)  Acc@5: 100.0000 (98.4699)  time: 0.3288  data: 0.0004  max mem: 2359
Train: Epoch[5/5]  [250/313]  eta: 0:00:20  Lr: 0.001875  Loss: -0.4594  Acc@1: 87.5000 (87.6992)  Acc@5: 100.0000 (98.4811)  time: 0.3301  data: 0.0005  max mem: 2359
Train: Epoch[5/5]  [260/313]  eta: 0:00:17  Lr: 0.001875  Loss: -0.8507  Acc@1: 87.5000 (87.9071)  Acc@5: 100.0000 (98.5153)  time: 0.3306  data: 0.0005  max mem: 2359
Train: Epoch[5/5]  [270/313]  eta: 0:00:14  Lr: 0.001875  Loss: -0.7655  Acc@1: 93.7500 (87.9151)  Acc@5: 100.0000 (98.5701)  time: 0.3291  data: 0.0003  max mem: 2359
Train: Epoch[5/5]  [280/313]  eta: 0:00:10  Lr: 0.001875  Loss: -0.8221  Acc@1: 87.5000 (87.8114)  Acc@5: 100.0000 (98.6210)  time: 0.3289  data: 0.0003  max mem: 2359
Train: Epoch[5/5]  [290/313]  eta: 0:00:07  Lr: 0.001875  Loss: -0.8394  Acc@1: 87.5000 (87.8436)  Acc@5: 100.0000 (98.6469)  time: 0.3291  data: 0.0004  max mem: 2359
Train: Epoch[5/5]  [300/313]  eta: 0:00:04  Lr: 0.001875  Loss: -0.4698  Acc@1: 87.5000 (87.8322)  Acc@5: 100.0000 (98.6711)  time: 0.3289  data: 0.0004  max mem: 2359
Train: Epoch[5/5]  [310/313]  eta: 0:00:00  Lr: 0.001875  Loss: -0.9117  Acc@1: 87.5000 (87.9421)  Acc@5: 100.0000 (98.6736)  time: 0.3292  data: 0.0003  max mem: 2359
Train: Epoch[5/5]  [312/313]  eta: 0:00:00  Lr: 0.001875  Loss: -1.0210  Acc@1: 87.5000 (87.9600)  Acc@5: 100.0000 (98.6800)  time: 0.3212  data: 0.0003  max mem: 2359
Train: Epoch[5/5] Total time: 0:01:43 (0.3308 s / it)
Averaged stats: Lr: 0.001875  Loss: -1.0210  Acc@1: 87.5000 (87.9600)  Acc@5: 100.0000 (98.6800)
Test: [Task 1]  [ 0/63]  eta: 0:00:32  Loss: 0.4285 (0.4285)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)  time: 0.5085  data: 0.3010  max mem: 2359
Test: [Task 1]  [10/63]  eta: 0:00:12  Loss: 0.4329 (0.4479)  Acc@1: 100.0000 (97.1591)  Acc@5: 100.0000 (100.0000)  time: 0.2330  data: 0.0276  max mem: 2359
Test: [Task 1]  [20/63]  eta: 0:00:09  Loss: 0.4329 (0.5034)  Acc@1: 93.7500 (95.5357)  Acc@5: 100.0000 (99.7024)  time: 0.2052  data: 0.0003  max mem: 2359
Test: [Task 1]  [30/63]  eta: 0:00:07  Loss: 0.3680 (0.4543)  Acc@1: 93.7500 (96.1694)  Acc@5: 100.0000 (99.7984)  time: 0.2051  data: 0.0003  max mem: 2359
Test: [Task 1]  [40/63]  eta: 0:00:04  Loss: 0.3572 (0.4426)  Acc@1: 100.0000 (96.3415)  Acc@5: 100.0000 (99.8476)  time: 0.2054  data: 0.0003  max mem: 2359
Test: [Task 1]  [50/63]  eta: 0:00:02  Loss: 0.3572 (0.4330)  Acc@1: 100.0000 (96.4461)  Acc@5: 100.0000 (99.7549)  time: 0.2054  data: 0.0004  max mem: 2359
Test: [Task 1]  [60/63]  eta: 0:00:00  Loss: 0.3518 (0.4278)  Acc@1: 100.0000 (96.8238)  Acc@5: 100.0000 (99.7951)  time: 0.2050  data: 0.0003  max mem: 2359
Test: [Task 1]  [62/63]  eta: 0:00:00  Loss: 0.3518 (0.4274)  Acc@1: 100.0000 (96.9000)  Acc@5: 100.0000 (99.8000)  time: 0.2002  data: 0.0003  max mem: 2359
Test: [Task 1] Total time: 0:00:13 (0.2095 s / it)
* Acc@1 96.900 Acc@5 99.800 loss 0.427
{0: {0: 998, 1: 998, 2: 1000, 3: 999, 4: 999, 5: 1, 6: 0, 7: 0, 8: 1, 9: 0, 10: 0, 11: 0, 12: 0, 13: 0, 14: 0, 15: 0, 16: 0, 17: 0, 18: 0, 19: 0, 20: 0, 21: 0, 22: 0, 23: 0, 24: 0, 25: 0, 26: 0, 27: 0, 28: 2, 29: 0, 30: 0, 31: 0, 32: 0, 33: 0, 34: 0, 35: 0, 36: 1, 37: 0, 38: 0, 39: 0, 40: 0, 41: 0, 42: 0, 43: 0, 44: 0, 45: 0, 46: 0, 47: 1, 48: 0, 49: 0}}
[Average accuracy till task1]	Acc@1: 96.9000	Acc@5: 99.8000	Loss: 0.4274
Train: Epoch[1/5]  [  0/313]  eta: 0:03:36  Lr: 0.001875  Loss: 1.1226  Acc@1: 12.5000 (12.5000)  Acc@5: 56.2500 (56.2500)  time: 0.6913  data: 0.3403  max mem: 2359
Train: Epoch[1/5]  [ 10/313]  eta: 0:01:49  Lr: 0.001875  Loss: 1.0310  Acc@1: 31.2500 (34.0909)  Acc@5: 75.0000 (71.0227)  time: 0.3614  data: 0.0313  max mem: 2360
Train: Epoch[1/5]  [ 20/313]  eta: 0:01:41  Lr: 0.001875  Loss: 0.8716  Acc@1: 50.0000 (48.2143)  Acc@5: 87.5000 (82.4405)  time: 0.3292  data: 0.0004  max mem: 2360
Train: Epoch[1/5]  [ 30/313]  eta: 0:01:36  Lr: 0.001875  Loss: 0.2932  Acc@1: 68.7500 (57.0565)  Acc@5: 93.7500 (86.6935)  time: 0.3292  data: 0.0004  max mem: 2360
Train: Epoch[1/5]  [ 40/313]  eta: 0:01:32  Lr: 0.001875  Loss: 0.0801  Acc@1: 75.0000 (62.5000)  Acc@5: 100.0000 (89.3293)  time: 0.3285  data: 0.0004  max mem: 2360
Train: Epoch[1/5]  [ 50/313]  eta: 0:01:28  Lr: 0.001875  Loss: 0.2103  Acc@1: 75.0000 (66.0539)  Acc@5: 100.0000 (90.6863)  time: 0.3291  data: 0.0004  max mem: 2360
Train: Epoch[1/5]  [ 60/313]  eta: 0:01:24  Lr: 0.001875  Loss: 0.0566  Acc@1: 81.2500 (68.5451)  Acc@5: 100.0000 (91.5984)  time: 0.3296  data: 0.0003  max mem: 2360
Train: Epoch[1/5]  [ 70/313]  eta: 0:01:21  Lr: 0.001875  Loss: 0.0432  Acc@1: 81.2500 (70.4225)  Acc@5: 100.0000 (92.6056)  time: 0.3298  data: 0.0004  max mem: 2360
Train: Epoch[1/5]  [ 80/313]  eta: 0:01:17  Lr: 0.001875  Loss: -0.2756  Acc@1: 81.2500 (72.1451)  Acc@5: 100.0000 (93.4414)  time: 0.3292  data: 0.0005  max mem: 2360
Train: Epoch[1/5]  [ 90/313]  eta: 0:01:14  Lr: 0.001875  Loss: -0.2589  Acc@1: 81.2500 (72.9396)  Acc@5: 100.0000 (93.6813)  time: 0.3286  data: 0.0004  max mem: 2360
Train: Epoch[1/5]  [100/313]  eta: 0:01:10  Lr: 0.001875  Loss: -0.2191  Acc@1: 81.2500 (74.1955)  Acc@5: 100.0000 (93.9356)  time: 0.3283  data: 0.0003  max mem: 2360
Train: Epoch[1/5]  [110/313]  eta: 0:01:07  Lr: 0.001875  Loss: -0.2069  Acc@1: 87.5000 (75.1126)  Acc@5: 100.0000 (94.3131)  time: 0.3284  data: 0.0003  max mem: 2360
Train: Epoch[1/5]  [120/313]  eta: 0:01:04  Lr: 0.001875  Loss: -0.4057  Acc@1: 81.2500 (75.3616)  Acc@5: 100.0000 (94.5764)  time: 0.3285  data: 0.0003  max mem: 2360
Train: Epoch[1/5]  [130/313]  eta: 0:01:00  Lr: 0.001875  Loss: -0.5744  Acc@1: 81.2500 (76.0496)  Acc@5: 100.0000 (94.7996)  time: 0.3289  data: 0.0004  max mem: 2360
Train: Epoch[1/5]  [140/313]  eta: 0:00:57  Lr: 0.001875  Loss: -0.2460  Acc@1: 87.5000 (76.6401)  Acc@5: 100.0000 (95.0798)  time: 0.3293  data: 0.0004  max mem: 2360
Train: Epoch[1/5]  [150/313]  eta: 0:00:54  Lr: 0.001875  Loss: -0.6237  Acc@1: 81.2500 (77.1937)  Acc@5: 100.0000 (95.1573)  time: 0.3296  data: 0.0003  max mem: 2360
Train: Epoch[1/5]  [160/313]  eta: 0:00:50  Lr: 0.001875  Loss: -0.1432  Acc@1: 81.2500 (77.2904)  Acc@5: 93.7500 (95.1475)  time: 0.3299  data: 0.0003  max mem: 2360
Train: Epoch[1/5]  [170/313]  eta: 0:00:47  Lr: 0.001875  Loss: -0.5819  Acc@1: 81.2500 (77.5219)  Acc@5: 93.7500 (95.3216)  time: 0.3295  data: 0.0003  max mem: 2360
Train: Epoch[1/5]  [180/313]  eta: 0:00:44  Lr: 0.001875  Loss: -0.4916  Acc@1: 81.2500 (77.9696)  Acc@5: 100.0000 (95.4420)  time: 0.3286  data: 0.0003  max mem: 2360
Train: Epoch[1/5]  [190/313]  eta: 0:00:40  Lr: 0.001875  Loss: -0.4636  Acc@1: 81.2500 (78.2395)  Acc@5: 100.0000 (95.5825)  time: 0.3283  data: 0.0003  max mem: 2360
Train: Epoch[1/5]  [200/313]  eta: 0:00:37  Lr: 0.001875  Loss: 0.3533  Acc@1: 81.2500 (78.2960)  Acc@5: 100.0000 (95.4291)  time: 0.3284  data: 0.0004  max mem: 2360
Train: Epoch[1/5]  [210/313]  eta: 0:00:34  Lr: 0.001875  Loss: -0.3607  Acc@1: 81.2500 (78.2583)  Acc@5: 93.7500 (95.4384)  time: 0.3287  data: 0.0003  max mem: 2360
Train: Epoch[1/5]  [220/313]  eta: 0:00:30  Lr: 0.001875  Loss: -0.2031  Acc@1: 81.2500 (78.3654)  Acc@5: 100.0000 (95.5600)  time: 0.3294  data: 0.0003  max mem: 2360
Train: Epoch[1/5]  [230/313]  eta: 0:00:27  Lr: 0.001875  Loss: -0.5575  Acc@1: 81.2500 (78.5444)  Acc@5: 100.0000 (95.5898)  time: 0.3291  data: 0.0004  max mem: 2360
Train: Epoch[1/5]  [240/313]  eta: 0:00:24  Lr: 0.001875  Loss: -0.7058  Acc@1: 81.2500 (78.8122)  Acc@5: 100.0000 (95.7728)  time: 0.3299  data: 0.0004  max mem: 2360
Train: Epoch[1/5]  [250/313]  eta: 0:00:20  Lr: 0.001875  Loss: -0.6232  Acc@1: 81.2500 (78.9841)  Acc@5: 100.0000 (95.8665)  time: 0.3300  data: 0.0003  max mem: 2360
Train: Epoch[1/5]  [260/313]  eta: 0:00:17  Lr: 0.001875  Loss: -0.3334  Acc@1: 87.5000 (79.2385)  Acc@5: 100.0000 (95.9291)  time: 0.3288  data: 0.0003  max mem: 2360
Train: Epoch[1/5]  [270/313]  eta: 0:00:14  Lr: 0.001875  Loss: -0.9362  Acc@1: 81.2500 (79.4511)  Acc@5: 100.0000 (96.0101)  time: 0.3293  data: 0.0003  max mem: 2360
Train: Epoch[1/5]  [280/313]  eta: 0:00:10  Lr: 0.001875  Loss: -0.6975  Acc@1: 87.5000 (79.7820)  Acc@5: 100.0000 (96.0632)  time: 0.3293  data: 0.0004  max mem: 2360
Train: Epoch[1/5]  [290/313]  eta: 0:00:07  Lr: 0.001875  Loss: -0.4971  Acc@1: 87.5000 (79.8540)  Acc@5: 100.0000 (96.0052)  time: 0.3290  data: 0.0006  max mem: 2360
Train: Epoch[1/5]  [300/313]  eta: 0:00:04  Lr: 0.001875  Loss: -0.1192  Acc@1: 81.2500 (79.8173)  Acc@5: 93.7500 (95.9925)  time: 0.3289  data: 0.0005  max mem: 2360
Train: Epoch[1/5]  [310/313]  eta: 0:00:00  Lr: 0.001875  Loss: -0.6415  Acc@1: 75.0000 (79.8031)  Acc@5: 100.0000 (96.0410)  time: 0.3292  data: 0.0004  max mem: 2360
Train: Epoch[1/5]  [312/313]  eta: 0:00:00  Lr: 0.001875  Loss: -0.6931  Acc@1: 81.2500 (79.8200)  Acc@5: 93.7500 (96.0400)  time: 0.3212  data: 0.0003  max mem: 2360
Train: Epoch[1/5] Total time: 0:01:43 (0.3300 s / it)
Averaged stats: Lr: 0.001875  Loss: -0.6931  Acc@1: 81.2500 (79.8200)  Acc@5: 93.7500 (96.0400)
Train: Epoch[2/5]  [  0/313]  eta: 0:03:36  Lr: 0.001875  Loss: -0.5527  Acc@1: 81.2500 (81.2500)  Acc@5: 100.0000 (100.0000)  time: 0.6906  data: 0.3599  max mem: 2360
Train: Epoch[2/5]  [ 10/313]  eta: 0:01:49  Lr: 0.001875  Loss: -0.7588  Acc@1: 87.5000 (85.2273)  Acc@5: 100.0000 (98.8636)  time: 0.3628  data: 0.0331  max mem: 2360
Train: Epoch[2/5]  [ 20/313]  eta: 0:01:41  Lr: 0.001875  Loss: -0.5565  Acc@1: 87.5000 (85.7143)  Acc@5: 100.0000 (97.0238)  time: 0.3296  data: 0.0004  max mem: 2360
Train: Epoch[2/5]  [ 30/313]  eta: 0:01:36  Lr: 0.001875  Loss: -0.4557  Acc@1: 87.5000 (85.4839)  Acc@5: 100.0000 (97.3790)  time: 0.3292  data: 0.0004  max mem: 2360
Train: Epoch[2/5]  [ 40/313]  eta: 0:01:32  Lr: 0.001875  Loss: -0.4739  Acc@1: 87.5000 (85.6707)  Acc@5: 100.0000 (97.2561)  time: 0.3309  data: 0.0004  max mem: 2360
Train: Epoch[2/5]  [ 50/313]  eta: 0:01:28  Lr: 0.001875  Loss: -0.5296  Acc@1: 87.5000 (85.1716)  Acc@5: 100.0000 (97.4265)  time: 0.3314  data: 0.0004  max mem: 2360
Train: Epoch[2/5]  [ 60/313]  eta: 0:01:24  Lr: 0.001875  Loss: -0.7620  Acc@1: 81.2500 (84.9385)  Acc@5: 100.0000 (97.3361)  time: 0.3294  data: 0.0003  max mem: 2360
Train: Epoch[2/5]  [ 70/313]  eta: 0:01:21  Lr: 0.001875  Loss: -0.6090  Acc@1: 87.5000 (85.1232)  Acc@5: 100.0000 (97.4472)  time: 0.3290  data: 0.0003  max mem: 2360
Train: Epoch[2/5]  [ 80/313]  eta: 0:01:17  Lr: 0.001875  Loss: -0.5325  Acc@1: 87.5000 (85.0309)  Acc@5: 100.0000 (97.4537)  time: 0.3295  data: 0.0003  max mem: 2360
Train: Epoch[2/5]  [ 90/313]  eta: 0:01:14  Lr: 0.001875  Loss: -0.9726  Acc@1: 87.5000 (85.3709)  Acc@5: 100.0000 (97.4588)  time: 0.3296  data: 0.0004  max mem: 2360
Train: Epoch[2/5]  [100/313]  eta: 0:01:10  Lr: 0.001875  Loss: -0.3746  Acc@1: 87.5000 (85.5817)  Acc@5: 100.0000 (97.6485)  time: 0.3293  data: 0.0004  max mem: 2360
Train: Epoch[2/5]  [110/313]  eta: 0:01:07  Lr: 0.001875  Loss: -0.6847  Acc@1: 81.2500 (85.0225)  Acc@5: 100.0000 (97.6914)  time: 0.3294  data: 0.0004  max mem: 2360
Train: Epoch[2/5]  [120/313]  eta: 0:01:04  Lr: 0.001875  Loss: -0.6435  Acc@1: 81.2500 (84.8657)  Acc@5: 100.0000 (97.7273)  time: 0.3295  data: 0.0004  max mem: 2360
Train: Epoch[2/5]  [130/313]  eta: 0:01:00  Lr: 0.001875  Loss: -0.7211  Acc@1: 87.5000 (85.0668)  Acc@5: 100.0000 (97.7576)  time: 0.3299  data: 0.0010  max mem: 2360
Train: Epoch[2/5]  [140/313]  eta: 0:00:57  Lr: 0.001875  Loss: -0.7664  Acc@1: 87.5000 (85.1507)  Acc@5: 100.0000 (97.8723)  time: 0.3304  data: 0.0010  max mem: 2360
Train: Epoch[2/5]  [150/313]  eta: 0:00:54  Lr: 0.001875  Loss: -0.6259  Acc@1: 87.5000 (85.0166)  Acc@5: 100.0000 (97.7649)  time: 0.3307  data: 0.0004  max mem: 2360
Train: Epoch[2/5]  [160/313]  eta: 0:00:50  Lr: 0.001875  Loss: -0.8056  Acc@1: 81.2500 (85.0543)  Acc@5: 100.0000 (97.8261)  time: 0.3316  data: 0.0004  max mem: 2360
Train: Epoch[2/5]  [170/313]  eta: 0:00:47  Lr: 0.001875  Loss: -0.7660  Acc@1: 87.5000 (85.1608)  Acc@5: 100.0000 (97.6974)  time: 0.3322  data: 0.0008  max mem: 2360
Train: Epoch[2/5]  [180/313]  eta: 0:00:44  Lr: 0.001875  Loss: -0.7479  Acc@1: 87.5000 (85.2210)  Acc@5: 100.0000 (97.7901)  time: 0.3324  data: 0.0008  max mem: 2360
Train: Epoch[2/5]  [190/313]  eta: 0:00:40  Lr: 0.001875  Loss: -0.6610  Acc@1: 81.2500 (85.1767)  Acc@5: 100.0000 (97.7094)  time: 0.3316  data: 0.0005  max mem: 2360
Train: Epoch[2/5]  [200/313]  eta: 0:00:37  Lr: 0.001875  Loss: -1.0161  Acc@1: 81.2500 (85.1368)  Acc@5: 93.7500 (97.6679)  time: 0.3309  data: 0.0005  max mem: 2360
Train: Epoch[2/5]  [210/313]  eta: 0:00:34  Lr: 0.001875  Loss: -0.4163  Acc@1: 81.2500 (84.8341)  Acc@5: 100.0000 (97.6007)  time: 0.3321  data: 0.0006  max mem: 2360
Train: Epoch[2/5]  [220/313]  eta: 0:00:30  Lr: 0.001875  Loss: -0.3571  Acc@1: 81.2500 (84.8416)  Acc@5: 100.0000 (97.6810)  time: 0.3335  data: 0.0006  max mem: 2360
Train: Epoch[2/5]  [230/313]  eta: 0:00:27  Lr: 0.001875  Loss: -0.4977  Acc@1: 87.5000 (84.8755)  Acc@5: 100.0000 (97.7273)  time: 0.3331  data: 0.0005  max mem: 2360
Train: Epoch[2/5]  [240/313]  eta: 0:00:24  Lr: 0.001875  Loss: -0.4828  Acc@1: 87.5000 (84.6214)  Acc@5: 100.0000 (97.7178)  time: 0.3333  data: 0.0006  max mem: 2360
Train: Epoch[2/5]  [250/313]  eta: 0:00:20  Lr: 0.001875  Loss: -0.7044  Acc@1: 81.2500 (84.4871)  Acc@5: 100.0000 (97.7092)  time: 0.3329  data: 0.0004  max mem: 2360
Train: Epoch[2/5]  [260/313]  eta: 0:00:17  Lr: 0.001875  Loss: -0.6954  Acc@1: 87.5000 (84.6264)  Acc@5: 100.0000 (97.7251)  time: 0.3309  data: 0.0005  max mem: 2360
Train: Epoch[2/5]  [270/313]  eta: 0:00:14  Lr: 0.001875  Loss: -0.7514  Acc@1: 87.5000 (84.6633)  Acc@5: 100.0000 (97.7399)  time: 0.3310  data: 0.0006  max mem: 2360
Train: Epoch[2/5]  [280/313]  eta: 0:00:10  Lr: 0.001875  Loss: -0.8528  Acc@1: 87.5000 (84.8310)  Acc@5: 100.0000 (97.7758)  time: 0.3317  data: 0.0006  max mem: 2360
Train: Epoch[2/5]  [290/313]  eta: 0:00:07  Lr: 0.001875  Loss: -0.3901  Acc@1: 87.5000 (84.6435)  Acc@5: 100.0000 (97.7448)  time: 0.3319  data: 0.0006  max mem: 2360
Train: Epoch[2/5]  [300/313]  eta: 0:00:04  Lr: 0.001875  Loss: -0.9706  Acc@1: 81.2500 (84.7176)  Acc@5: 100.0000 (97.7782)  time: 0.3318  data: 0.0005  max mem: 2360
Train: Epoch[2/5]  [310/313]  eta: 0:00:00  Lr: 0.001875  Loss: -0.8649  Acc@1: 87.5000 (84.7267)  Acc@5: 100.0000 (97.7291)  time: 0.3316  data: 0.0005  max mem: 2360
Train: Epoch[2/5]  [312/313]  eta: 0:00:00  Lr: 0.001875  Loss: 0.0320  Acc@1: 87.5000 (84.6600)  Acc@5: 100.0000 (97.7000)  time: 0.3236  data: 0.0005  max mem: 2360
Train: Epoch[2/5] Total time: 0:01:43 (0.3321 s / it)
Averaged stats: Lr: 0.001875  Loss: 0.0320  Acc@1: 87.5000 (84.6600)  Acc@5: 100.0000 (97.7000)
Train: Epoch[3/5]  [  0/313]  eta: 0:03:35  Lr: 0.001875  Loss: -0.7761  Acc@1: 93.7500 (93.7500)  Acc@5: 100.0000 (100.0000)  time: 0.6882  data: 0.3564  max mem: 2360
Train: Epoch[3/5]  [ 10/313]  eta: 0:01:50  Lr: 0.001875  Loss: -0.5028  Acc@1: 87.5000 (85.7955)  Acc@5: 100.0000 (97.7273)  time: 0.3635  data: 0.0329  max mem: 2360
Train: Epoch[3/5]  [ 20/313]  eta: 0:01:42  Lr: 0.001875  Loss: -0.6003  Acc@1: 87.5000 (85.1190)  Acc@5: 100.0000 (98.5119)  time: 0.3313  data: 0.0005  max mem: 2360
Train: Epoch[3/5]  [ 30/313]  eta: 0:01:36  Lr: 0.001875  Loss: -0.8290  Acc@1: 87.5000 (85.0806)  Acc@5: 100.0000 (97.7823)  time: 0.3307  data: 0.0006  max mem: 2360
Train: Epoch[3/5]  [ 40/313]  eta: 0:01:32  Lr: 0.001875  Loss: -0.5546  Acc@1: 87.5000 (84.4512)  Acc@5: 100.0000 (97.7134)  time: 0.3304  data: 0.0005  max mem: 2360
Train: Epoch[3/5]  [ 50/313]  eta: 0:01:28  Lr: 0.001875  Loss: -0.4684  Acc@1: 81.2500 (83.4559)  Acc@5: 100.0000 (97.5490)  time: 0.3304  data: 0.0005  max mem: 2360
Train: Epoch[3/5]  [ 60/313]  eta: 0:01:25  Lr: 0.001875  Loss: -0.6991  Acc@1: 81.2500 (84.1189)  Acc@5: 100.0000 (97.7459)  time: 0.3301  data: 0.0004  max mem: 2360
Train: Epoch[3/5]  [ 70/313]  eta: 0:01:21  Lr: 0.001875  Loss: -0.2470  Acc@1: 87.5000 (83.8908)  Acc@5: 100.0000 (97.7993)  time: 0.3319  data: 0.0012  max mem: 2360
Train: Epoch[3/5]  [ 80/313]  eta: 0:01:18  Lr: 0.001875  Loss: -0.5791  Acc@1: 87.5000 (84.3364)  Acc@5: 100.0000 (97.7623)  time: 0.3316  data: 0.0012  max mem: 2360
Train: Epoch[3/5]  [ 90/313]  eta: 0:01:14  Lr: 0.001875  Loss: -0.5876  Acc@1: 87.5000 (84.7527)  Acc@5: 100.0000 (97.8022)  time: 0.3304  data: 0.0005  max mem: 2360
Train: Epoch[3/5]  [100/313]  eta: 0:01:11  Lr: 0.001875  Loss: -0.5934  Acc@1: 87.5000 (84.7153)  Acc@5: 100.0000 (97.8960)  time: 0.3312  data: 0.0005  max mem: 2360
Train: Epoch[3/5]  [110/313]  eta: 0:01:07  Lr: 0.001875  Loss: -0.8911  Acc@1: 93.7500 (85.4730)  Acc@5: 100.0000 (97.9730)  time: 0.3308  data: 0.0004  max mem: 2360
Train: Epoch[3/5]  [120/313]  eta: 0:01:04  Lr: 0.001875  Loss: -0.5273  Acc@1: 93.7500 (85.4855)  Acc@5: 100.0000 (97.9855)  time: 0.3306  data: 0.0004  max mem: 2360
Train: Epoch[3/5]  [130/313]  eta: 0:01:01  Lr: 0.001875  Loss: -1.0329  Acc@1: 87.5000 (85.4962)  Acc@5: 100.0000 (97.9485)  time: 0.3311  data: 0.0005  max mem: 2360
Train: Epoch[3/5]  [140/313]  eta: 0:00:57  Lr: 0.001875  Loss: -0.9679  Acc@1: 87.5000 (85.9043)  Acc@5: 100.0000 (98.0940)  time: 0.3308  data: 0.0005  max mem: 2360
Train: Epoch[3/5]  [150/313]  eta: 0:00:54  Lr: 0.001875  Loss: -0.9505  Acc@1: 87.5000 (86.2583)  Acc@5: 100.0000 (98.0960)  time: 0.3302  data: 0.0005  max mem: 2360
Train: Epoch[3/5]  [160/313]  eta: 0:00:50  Lr: 0.001875  Loss: -0.9190  Acc@1: 87.5000 (86.0248)  Acc@5: 100.0000 (98.0978)  time: 0.3297  data: 0.0004  max mem: 2360
Train: Epoch[3/5]  [170/313]  eta: 0:00:47  Lr: 0.001875  Loss: -0.5234  Acc@1: 81.2500 (85.8918)  Acc@5: 100.0000 (97.9532)  time: 0.3299  data: 0.0004  max mem: 2360
Train: Epoch[3/5]  [180/313]  eta: 0:00:44  Lr: 0.001875  Loss: -0.8368  Acc@1: 81.2500 (85.8080)  Acc@5: 93.7500 (97.8591)  time: 0.3301  data: 0.0004  max mem: 2360
Train: Epoch[3/5]  [190/313]  eta: 0:00:40  Lr: 0.001875  Loss: -0.1701  Acc@1: 81.2500 (85.5694)  Acc@5: 100.0000 (97.9058)  time: 0.3303  data: 0.0004  max mem: 2360
Train: Epoch[3/5]  [200/313]  eta: 0:00:37  Lr: 0.001875  Loss: -0.8579  Acc@1: 87.5000 (85.6965)  Acc@5: 100.0000 (97.9789)  time: 0.3299  data: 0.0003  max mem: 2360
Train: Epoch[3/5]  [210/313]  eta: 0:00:34  Lr: 0.001875  Loss: -0.8669  Acc@1: 87.5000 (85.7524)  Acc@5: 100.0000 (98.0154)  time: 0.3293  data: 0.0004  max mem: 2360
Train: Epoch[3/5]  [220/313]  eta: 0:00:30  Lr: 0.001875  Loss: -1.0278  Acc@1: 87.5000 (85.9729)  Acc@5: 100.0000 (98.0769)  time: 0.3295  data: 0.0004  max mem: 2360
Train: Epoch[3/5]  [230/313]  eta: 0:00:27  Lr: 0.001875  Loss: -0.3971  Acc@1: 87.5000 (85.9307)  Acc@5: 100.0000 (98.0790)  time: 0.3286  data: 0.0003  max mem: 2360
Train: Epoch[3/5]  [240/313]  eta: 0:00:24  Lr: 0.001875  Loss: -0.3223  Acc@1: 87.5000 (85.8662)  Acc@5: 100.0000 (98.0550)  time: 0.3269  data: 0.0002  max mem: 2360
Train: Epoch[3/5]  [250/313]  eta: 0:00:20  Lr: 0.001875  Loss: -0.5861  Acc@1: 87.5000 (85.7819)  Acc@5: 100.0000 (98.1076)  time: 0.3264  data: 0.0002  max mem: 2360
Train: Epoch[3/5]  [260/313]  eta: 0:00:17  Lr: 0.001875  Loss: -0.3358  Acc@1: 81.2500 (85.6801)  Acc@5: 100.0000 (98.0364)  time: 0.3267  data: 0.0002  max mem: 2360
Train: Epoch[3/5]  [270/313]  eta: 0:00:14  Lr: 0.001875  Loss: -0.7062  Acc@1: 81.2500 (85.7242)  Acc@5: 100.0000 (98.0627)  time: 0.3265  data: 0.0002  max mem: 2360
Train: Epoch[3/5]  [280/313]  eta: 0:00:10  Lr: 0.001875  Loss: -1.0682  Acc@1: 87.5000 (85.7651)  Acc@5: 100.0000 (98.1094)  time: 0.3269  data: 0.0002  max mem: 2360
Train: Epoch[3/5]  [290/313]  eta: 0:00:07  Lr: 0.001875  Loss: -0.8510  Acc@1: 87.5000 (85.7603)  Acc@5: 100.0000 (98.1100)  time: 0.3270  data: 0.0002  max mem: 2360
Train: Epoch[3/5]  [300/313]  eta: 0:00:04  Lr: 0.001875  Loss: -0.6715  Acc@1: 87.5000 (85.6520)  Acc@5: 100.0000 (98.1312)  time: 0.3270  data: 0.0002  max mem: 2360
Train: Epoch[3/5]  [310/313]  eta: 0:00:00  Lr: 0.001875  Loss: -0.6408  Acc@1: 81.2500 (85.6511)  Acc@5: 100.0000 (98.1310)  time: 0.3269  data: 0.0002  max mem: 2360
Train: Epoch[3/5]  [312/313]  eta: 0:00:00  Lr: 0.001875  Loss: -0.4936  Acc@1: 81.2500 (85.5800)  Acc@5: 100.0000 (98.1200)  time: 0.3188  data: 0.0002  max mem: 2360
Train: Epoch[3/5] Total time: 0:01:43 (0.3304 s / it)
Averaged stats: Lr: 0.001875  Loss: -0.4936  Acc@1: 81.2500 (85.5800)  Acc@5: 100.0000 (98.1200)
Train: Epoch[4/5]  [  0/313]  eta: 0:02:50  Lr: 0.001875  Loss: -0.7857  Acc@1: 81.2500 (81.2500)  Acc@5: 100.0000 (100.0000)  time: 0.5445  data: 0.2155  max mem: 2360
Train: Epoch[4/5]  [ 10/313]  eta: 0:01:45  Lr: 0.001875  Loss: -0.6692  Acc@1: 87.5000 (86.9318)  Acc@5: 100.0000 (98.8636)  time: 0.3470  data: 0.0197  max mem: 2360
Train: Epoch[4/5]  [ 20/313]  eta: 0:01:38  Lr: 0.001875  Loss: -0.6809  Acc@1: 87.5000 (88.0952)  Acc@5: 100.0000 (98.2143)  time: 0.3271  data: 0.0002  max mem: 2360
Train: Epoch[4/5]  [ 30/313]  eta: 0:01:34  Lr: 0.001875  Loss: -0.5494  Acc@1: 87.5000 (87.0968)  Acc@5: 100.0000 (98.3871)  time: 0.3271  data: 0.0002  max mem: 2360
Train: Epoch[4/5]  [ 40/313]  eta: 0:01:30  Lr: 0.001875  Loss: -0.8665  Acc@1: 87.5000 (86.7378)  Acc@5: 100.0000 (98.1707)  time: 0.3269  data: 0.0002  max mem: 2360
Train: Epoch[4/5]  [ 50/313]  eta: 0:01:27  Lr: 0.001875  Loss: -0.5902  Acc@1: 87.5000 (87.0098)  Acc@5: 100.0000 (98.4069)  time: 0.3269  data: 0.0002  max mem: 2360
Train: Epoch[4/5]  [ 60/313]  eta: 0:01:23  Lr: 0.001875  Loss: -0.5477  Acc@1: 87.5000 (87.0902)  Acc@5: 100.0000 (98.2582)  time: 0.3270  data: 0.0002  max mem: 2360
Train: Epoch[4/5]  [ 70/313]  eta: 0:01:20  Lr: 0.001875  Loss: -0.6819  Acc@1: 87.5000 (87.0599)  Acc@5: 100.0000 (98.4155)  time: 0.3268  data: 0.0002  max mem: 2360
Train: Epoch[4/5]  [ 80/313]  eta: 0:01:16  Lr: 0.001875  Loss: -0.7684  Acc@1: 87.5000 (87.4228)  Acc@5: 100.0000 (98.6111)  time: 0.3265  data: 0.0002  max mem: 2360
Train: Epoch[4/5]  [ 90/313]  eta: 0:01:13  Lr: 0.001875  Loss: -0.5783  Acc@1: 87.5000 (87.0192)  Acc@5: 100.0000 (98.6264)  time: 0.3265  data: 0.0002  max mem: 2360
Train: Epoch[4/5]  [100/313]  eta: 0:01:10  Lr: 0.001875  Loss: -0.9614  Acc@1: 87.5000 (86.6955)  Acc@5: 100.0000 (98.5149)  time: 0.3269  data: 0.0001  max mem: 2360
Train: Epoch[4/5]  [110/313]  eta: 0:01:06  Lr: 0.001875  Loss: -0.4750  Acc@1: 87.5000 (86.7680)  Acc@5: 100.0000 (98.5360)  time: 0.3270  data: 0.0001  max mem: 2360
Train: Epoch[4/5]  [120/313]  eta: 0:01:03  Lr: 0.001875  Loss: -0.9211  Acc@1: 87.5000 (86.6219)  Acc@5: 100.0000 (98.5021)  time: 0.3272  data: 0.0001  max mem: 2360
Train: Epoch[4/5]  [130/313]  eta: 0:01:00  Lr: 0.001875  Loss: -1.1020  Acc@1: 87.5000 (86.5458)  Acc@5: 100.0000 (98.4733)  time: 0.3274  data: 0.0001  max mem: 2360
Train: Epoch[4/5]  [140/313]  eta: 0:00:56  Lr: 0.001875  Loss: -0.6890  Acc@1: 87.5000 (86.5248)  Acc@5: 100.0000 (98.4043)  time: 0.3276  data: 0.0001  max mem: 2360
Train: Epoch[4/5]  [150/313]  eta: 0:00:53  Lr: 0.001875  Loss: -0.3091  Acc@1: 87.5000 (86.3825)  Acc@5: 100.0000 (98.3858)  time: 0.3280  data: 0.0001  max mem: 2360
Train: Epoch[4/5]  [160/313]  eta: 0:00:50  Lr: 0.001875  Loss: 0.0012  Acc@1: 87.5000 (86.3742)  Acc@5: 100.0000 (98.4084)  time: 0.3277  data: 0.0001  max mem: 2360
Train: Epoch[4/5]  [170/313]  eta: 0:00:46  Lr: 0.001875  Loss: -0.9556  Acc@1: 93.7500 (86.5863)  Acc@5: 100.0000 (98.3187)  time: 0.3275  data: 0.0002  max mem: 2360
Train: Epoch[4/5]  [180/313]  eta: 0:00:43  Lr: 0.001875  Loss: -0.7605  Acc@1: 87.5000 (86.7403)  Acc@5: 100.0000 (98.2390)  time: 0.3277  data: 0.0001  max mem: 2360
Train: Epoch[4/5]  [190/313]  eta: 0:00:40  Lr: 0.001875  Loss: -0.5159  Acc@1: 87.5000 (86.5838)  Acc@5: 100.0000 (98.2657)  time: 0.3275  data: 0.0001  max mem: 2360
Train: Epoch[4/5]  [200/313]  eta: 0:00:37  Lr: 0.001875  Loss: -0.8379  Acc@1: 81.2500 (86.4428)  Acc@5: 100.0000 (98.1965)  time: 0.3283  data: 0.0001  max mem: 2360
Train: Epoch[4/5]  [210/313]  eta: 0:00:33  Lr: 0.001875  Loss: -0.5635  Acc@1: 87.5000 (86.5225)  Acc@5: 100.0000 (98.1931)  time: 0.3284  data: 0.0001  max mem: 2360
Train: Epoch[4/5]  [220/313]  eta: 0:00:30  Lr: 0.001875  Loss: -0.8423  Acc@1: 87.5000 (86.3971)  Acc@5: 100.0000 (98.2749)  time: 0.3278  data: 0.0001  max mem: 2360
Train: Epoch[4/5]  [230/313]  eta: 0:00:27  Lr: 0.001875  Loss: -0.8999  Acc@1: 87.5000 (86.4448)  Acc@5: 100.0000 (98.2684)  time: 0.3282  data: 0.0001  max mem: 2360
Train: Epoch[4/5]  [240/313]  eta: 0:00:23  Lr: 0.001875  Loss: -0.6388  Acc@1: 87.5000 (86.4108)  Acc@5: 100.0000 (98.3143)  time: 0.3280  data: 0.0001  max mem: 2360
Train: Epoch[4/5]  [250/313]  eta: 0:00:20  Lr: 0.001875  Loss: -0.6695  Acc@1: 87.5000 (86.4791)  Acc@5: 100.0000 (98.3566)  time: 0.3283  data: 0.0001  max mem: 2360
Train: Epoch[4/5]  [260/313]  eta: 0:00:17  Lr: 0.001875  Loss: -0.7830  Acc@1: 87.5000 (86.3985)  Acc@5: 100.0000 (98.3477)  time: 0.3283  data: 0.0001  max mem: 2360
Train: Epoch[4/5]  [270/313]  eta: 0:00:14  Lr: 0.001875  Loss: -0.6355  Acc@1: 81.2500 (86.2546)  Acc@5: 100.0000 (98.3625)  time: 0.3282  data: 0.0001  max mem: 2360
Train: Epoch[4/5]  [280/313]  eta: 0:00:10  Lr: 0.001875  Loss: -0.6121  Acc@1: 87.5000 (86.3212)  Acc@5: 100.0000 (98.3541)  time: 0.3286  data: 0.0001  max mem: 2360
Train: Epoch[4/5]  [290/313]  eta: 0:00:07  Lr: 0.001875  Loss: -0.8216  Acc@1: 87.5000 (86.3832)  Acc@5: 100.0000 (98.3033)  time: 0.3283  data: 0.0001  max mem: 2360
Train: Epoch[4/5]  [300/313]  eta: 0:00:04  Lr: 0.001875  Loss: -0.9297  Acc@1: 87.5000 (86.5241)  Acc@5: 100.0000 (98.2766)  time: 0.3284  data: 0.0001  max mem: 2360
Train: Epoch[4/5]  [310/313]  eta: 0:00:00  Lr: 0.001875  Loss: -0.8081  Acc@1: 87.5000 (86.6559)  Acc@5: 100.0000 (98.3119)  time: 0.3281  data: 0.0001  max mem: 2360
Train: Epoch[4/5]  [312/313]  eta: 0:00:00  Lr: 0.001875  Loss: -0.4491  Acc@1: 87.5000 (86.7000)  Acc@5: 100.0000 (98.3200)  time: 0.3200  data: 0.0001  max mem: 2360
Train: Epoch[4/5] Total time: 0:01:42 (0.3280 s / it)
Averaged stats: Lr: 0.001875  Loss: -0.4491  Acc@1: 87.5000 (86.7000)  Acc@5: 100.0000 (98.3200)
Train: Epoch[5/5]  [  0/313]  eta: 0:02:46  Lr: 0.001875  Loss: -0.5456  Acc@1: 75.0000 (75.0000)  Acc@5: 100.0000 (100.0000)  time: 0.5316  data: 0.2020  max mem: 2360
Train: Epoch[5/5]  [ 10/313]  eta: 0:01:44  Lr: 0.001875  Loss: -0.4919  Acc@1: 87.5000 (82.9545)  Acc@5: 100.0000 (99.4318)  time: 0.3459  data: 0.0185  max mem: 2360
Train: Epoch[5/5]  [ 20/313]  eta: 0:01:38  Lr: 0.001875  Loss: -0.8191  Acc@1: 87.5000 (85.1190)  Acc@5: 100.0000 (98.8095)  time: 0.3277  data: 0.0001  max mem: 2360
Train: Epoch[5/5]  [ 30/313]  eta: 0:01:34  Lr: 0.001875  Loss: -0.9587  Acc@1: 87.5000 (85.6855)  Acc@5: 100.0000 (98.3871)  time: 0.3283  data: 0.0001  max mem: 2360
Train: Epoch[5/5]  [ 40/313]  eta: 0:01:30  Lr: 0.001875  Loss: -0.8538  Acc@1: 87.5000 (84.9085)  Acc@5: 100.0000 (98.7805)  time: 0.3282  data: 0.0001  max mem: 2360
Train: Epoch[5/5]  [ 50/313]  eta: 0:01:27  Lr: 0.001875  Loss: -0.4592  Acc@1: 81.2500 (84.8039)  Acc@5: 100.0000 (98.6520)  time: 0.3286  data: 0.0001  max mem: 2360
Train: Epoch[5/5]  [ 60/313]  eta: 0:01:23  Lr: 0.001875  Loss: -0.8227  Acc@1: 87.5000 (84.8361)  Acc@5: 100.0000 (98.2582)  time: 0.3287  data: 0.0001  max mem: 2360
Train: Epoch[5/5]  [ 70/313]  eta: 0:01:20  Lr: 0.001875  Loss: -0.8659  Acc@1: 87.5000 (85.3873)  Acc@5: 100.0000 (98.1514)  time: 0.3281  data: 0.0001  max mem: 2360
Train: Epoch[5/5]  [ 80/313]  eta: 0:01:17  Lr: 0.001875  Loss: -0.7851  Acc@1: 87.5000 (84.9537)  Acc@5: 100.0000 (98.3796)  time: 0.3284  data: 0.0002  max mem: 2360
Train: Epoch[5/5]  [ 90/313]  eta: 0:01:13  Lr: 0.001875  Loss: -0.8022  Acc@1: 87.5000 (85.2335)  Acc@5: 100.0000 (98.4890)  time: 0.3281  data: 0.0001  max mem: 2360
Train: Epoch[5/5]  [100/313]  eta: 0:01:10  Lr: 0.001875  Loss: -0.6544  Acc@1: 87.5000 (85.0248)  Acc@5: 100.0000 (98.3292)  time: 0.3282  data: 0.0001  max mem: 2360
Train: Epoch[5/5]  [110/313]  eta: 0:01:07  Lr: 0.001875  Loss: -0.9387  Acc@1: 87.5000 (85.1351)  Acc@5: 100.0000 (98.4234)  time: 0.3288  data: 0.0001  max mem: 2360
Train: Epoch[5/5]  [120/313]  eta: 0:01:03  Lr: 0.001875  Loss: -0.9861  Acc@1: 87.5000 (85.3822)  Acc@5: 100.0000 (98.3471)  time: 0.3286  data: 0.0001  max mem: 2360
Train: Epoch[5/5]  [130/313]  eta: 0:01:00  Lr: 0.001875  Loss: -0.6151  Acc@1: 87.5000 (85.4008)  Acc@5: 100.0000 (98.3779)  time: 0.3285  data: 0.0001  max mem: 2360
Train: Epoch[5/5]  [140/313]  eta: 0:00:57  Lr: 0.001875  Loss: -0.6706  Acc@1: 87.5000 (85.4167)  Acc@5: 100.0000 (98.3599)  time: 0.3284  data: 0.0001  max mem: 2360
Train: Epoch[5/5]  [150/313]  eta: 0:00:53  Lr: 0.001875  Loss: -0.5965  Acc@1: 87.5000 (85.4719)  Acc@5: 100.0000 (98.3858)  time: 0.3280  data: 0.0001  max mem: 2360
Train: Epoch[5/5]  [160/313]  eta: 0:00:50  Lr: 0.001875  Loss: -0.7151  Acc@1: 87.5000 (85.7531)  Acc@5: 100.0000 (98.3696)  time: 0.3288  data: 0.0001  max mem: 2360
Train: Epoch[5/5]  [170/313]  eta: 0:00:47  Lr: 0.001875  Loss: -0.9212  Acc@1: 87.5000 (86.0015)  Acc@5: 100.0000 (98.3918)  time: 0.3289  data: 0.0001  max mem: 2360
Train: Epoch[5/5]  [180/313]  eta: 0:00:43  Lr: 0.001875  Loss: -0.9044  Acc@1: 87.5000 (86.1188)  Acc@5: 100.0000 (98.4461)  time: 0.3285  data: 0.0001  max mem: 2360
Train: Epoch[5/5]  [190/313]  eta: 0:00:40  Lr: 0.001875  Loss: -0.5950  Acc@1: 87.5000 (86.1257)  Acc@5: 100.0000 (98.2657)  time: 0.3290  data: 0.0001  max mem: 2360
Train: Epoch[5/5]  [200/313]  eta: 0:00:37  Lr: 0.001875  Loss: -0.7886  Acc@1: 87.5000 (86.1629)  Acc@5: 93.7500 (98.2587)  time: 0.3291  data: 0.0001  max mem: 2360
Train: Epoch[5/5]  [210/313]  eta: 0:00:33  Lr: 0.001875  Loss: -0.4299  Acc@1: 87.5000 (86.2263)  Acc@5: 100.0000 (98.2524)  time: 0.3290  data: 0.0001  max mem: 2360
Train: Epoch[5/5]  [220/313]  eta: 0:00:30  Lr: 0.001875  Loss: -1.1398  Acc@1: 87.5000 (86.3688)  Acc@5: 100.0000 (98.3032)  time: 0.3292  data: 0.0001  max mem: 2360
Train: Epoch[5/5]  [230/313]  eta: 0:00:27  Lr: 0.001875  Loss: -0.7898  Acc@1: 87.5000 (86.4177)  Acc@5: 100.0000 (98.2684)  time: 0.3294  data: 0.0001  max mem: 2360
Train: Epoch[5/5]  [240/313]  eta: 0:00:24  Lr: 0.001875  Loss: -0.3580  Acc@1: 87.5000 (86.5923)  Acc@5: 100.0000 (98.2106)  time: 0.3288  data: 0.0001  max mem: 2360
Train: Epoch[5/5]  [250/313]  eta: 0:00:20  Lr: 0.001875  Loss: -0.9716  Acc@1: 93.7500 (86.6534)  Acc@5: 100.0000 (98.1823)  time: 0.3291  data: 0.0001  max mem: 2360
Train: Epoch[5/5]  [260/313]  eta: 0:00:17  Lr: 0.001875  Loss: -0.2011  Acc@1: 87.5000 (86.5661)  Acc@5: 100.0000 (98.1561)  time: 0.3291  data: 0.0001  max mem: 2360
Train: Epoch[5/5]  [270/313]  eta: 0:00:14  Lr: 0.001875  Loss: -0.6372  Acc@1: 87.5000 (86.7159)  Acc@5: 100.0000 (98.2011)  time: 0.3289  data: 0.0001  max mem: 2360
Train: Epoch[5/5]  [280/313]  eta: 0:00:10  Lr: 0.001875  Loss: -0.6994  Acc@1: 87.5000 (86.6770)  Acc@5: 100.0000 (98.2206)  time: 0.3294  data: 0.0001  max mem: 2360
Train: Epoch[5/5]  [290/313]  eta: 0:00:07  Lr: 0.001875  Loss: -0.4899  Acc@1: 87.5000 (86.7698)  Acc@5: 100.0000 (98.2388)  time: 0.3289  data: 0.0001  max mem: 2360
Train: Epoch[5/5]  [300/313]  eta: 0:00:04  Lr: 0.001875  Loss: -0.9718  Acc@1: 87.5000 (86.7733)  Acc@5: 100.0000 (98.2558)  time: 0.3286  data: 0.0001  max mem: 2360
Train: Epoch[5/5]  [310/313]  eta: 0:00:00  Lr: 0.001875  Loss: -0.4986  Acc@1: 87.5000 (86.7966)  Acc@5: 100.0000 (98.2315)  time: 0.3289  data: 0.0001  max mem: 2360
Train: Epoch[5/5]  [312/313]  eta: 0:00:00  Lr: 0.001875  Loss: -0.6299  Acc@1: 87.5000 (86.7400)  Acc@5: 100.0000 (98.2400)  time: 0.3207  data: 0.0001  max mem: 2360
Train: Epoch[5/5] Total time: 0:01:42 (0.3290 s / it)
Averaged stats: Lr: 0.001875  Loss: -0.6299  Acc@1: 87.5000 (86.7400)  Acc@5: 100.0000 (98.2400)
Test: [Task 1]  [ 0/63]  eta: 0:00:24  Loss: 0.4705 (0.4705)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)  time: 0.3943  data: 0.1882  max mem: 2360
Test: [Task 1]  [10/63]  eta: 0:00:11  Loss: 0.4574 (0.4837)  Acc@1: 93.7500 (94.3182)  Acc@5: 100.0000 (100.0000)  time: 0.2241  data: 0.0172  max mem: 2360
Test: [Task 1]  [20/63]  eta: 0:00:09  Loss: 0.4574 (0.5429)  Acc@1: 93.7500 (92.5595)  Acc@5: 100.0000 (99.4048)  time: 0.2097  data: 0.0001  max mem: 2360
Test: [Task 1]  [30/63]  eta: 0:00:07  Loss: 0.4204 (0.4984)  Acc@1: 93.7500 (92.7419)  Acc@5: 100.0000 (99.5968)  time: 0.2124  data: 0.0001  max mem: 2360
Test: [Task 1]  [40/63]  eta: 0:00:04  Loss: 0.4035 (0.4866)  Acc@1: 93.7500 (93.5976)  Acc@5: 100.0000 (99.6951)  time: 0.2126  data: 0.0001  max mem: 2360
Test: [Task 1]  [50/63]  eta: 0:00:02  Loss: 0.4035 (0.4720)  Acc@1: 93.7500 (93.8725)  Acc@5: 100.0000 (99.6324)  time: 0.2128  data: 0.0001  max mem: 2360
Test: [Task 1]  [60/63]  eta: 0:00:00  Loss: 0.3762 (0.4672)  Acc@1: 93.7500 (94.1598)  Acc@5: 100.0000 (99.6926)  time: 0.2127  data: 0.0001  max mem: 2360
Test: [Task 1]  [62/63]  eta: 0:00:00  Loss: 0.3730 (0.4645)  Acc@1: 93.7500 (94.2000)  Acc@5: 100.0000 (99.7000)  time: 0.2075  data: 0.0001  max mem: 2360
Test: [Task 1] Total time: 0:00:13 (0.2143 s / it)
* Acc@1 94.200 Acc@5 99.700 loss 0.465
Test: [Task 2]  [ 0/63]  eta: 0:00:24  Loss: 0.5881 (0.5881)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)  time: 0.3845  data: 0.1773  max mem: 2360
Test: [Task 2]  [10/63]  eta: 0:00:11  Loss: 0.4930 (0.5671)  Acc@1: 93.7500 (94.8864)  Acc@5: 100.0000 (99.4318)  time: 0.2228  data: 0.0163  max mem: 2360
Test: [Task 2]  [20/63]  eta: 0:00:09  Loss: 0.5618 (0.6679)  Acc@1: 93.7500 (92.5595)  Acc@5: 100.0000 (99.4048)  time: 0.2124  data: 0.0002  max mem: 2360
Test: [Task 2]  [30/63]  eta: 0:00:07  Loss: 0.6760 (0.6683)  Acc@1: 93.7500 (92.3387)  Acc@5: 100.0000 (98.7903)  time: 0.2163  data: 0.0002  max mem: 2360
Test: [Task 2]  [40/63]  eta: 0:00:05  Loss: 0.6203 (0.6482)  Acc@1: 93.7500 (92.6829)  Acc@5: 100.0000 (98.9329)  time: 0.2144  data: 0.0001  max mem: 2360
Test: [Task 2]  [50/63]  eta: 0:00:02  Loss: 0.5647 (0.6406)  Acc@1: 93.7500 (92.2794)  Acc@5: 100.0000 (98.8971)  time: 0.2146  data: 0.0001  max mem: 2360
Test: [Task 2]  [60/63]  eta: 0:00:00  Loss: 0.5375 (0.6161)  Acc@1: 93.7500 (93.2377)  Acc@5: 100.0000 (99.0779)  time: 0.2144  data: 0.0001  max mem: 2360
Test: [Task 2]  [62/63]  eta: 0:00:00  Loss: 0.5013 (0.6098)  Acc@1: 93.7500 (93.3000)  Acc@5: 100.0000 (99.1000)  time: 0.2093  data: 0.0001  max mem: 2360
Test: [Task 2] Total time: 0:00:13 (0.2158 s / it)
* Acc@1 93.300 Acc@5 99.100 loss 0.610
{0: {0: 876, 1: 875, 2: 880, 3: 877, 4: 883, 5: 123, 6: 124, 7: 117, 8: 121, 9: 120, 10: 0, 11: 0, 12: 0, 13: 0, 14: 0, 15: 0, 16: 0, 17: 0, 18: 0, 19: 0, 20: 0, 21: 0, 22: 0, 23: 0, 24: 0, 25: 0, 26: 0, 27: 0, 28: 2, 29: 0, 30: 0, 31: 0, 32: 0, 33: 0, 34: 0, 35: 0, 36: 1, 37: 0, 38: 0, 39: 0, 40: 0, 41: 0, 42: 0, 43: 0, 44: 0, 45: 0, 46: 0, 47: 1, 48: 0, 49: 0}, 1: {0: 204, 1: 208, 2: 209, 3: 212, 4: 213, 5: 787, 6: 792, 7: 778, 8: 791, 9: 784, 10: 0, 11: 3, 12: 0, 13: 0, 14: 1, 15: 2, 16: 0, 17: 0, 18: 0, 19: 0, 20: 0, 21: 0, 22: 0, 23: 3, 24: 2, 25: 0, 26: 2, 27: 1, 28: 2, 29: 0, 30: 1, 31: 0, 32: 0, 33: 0, 34: 0, 35: 0, 36: 1, 37: 2, 38: 0, 39: 2, 40: 0, 41: 0, 42: 0, 43: 0, 44: 0, 45: 0, 46: 0, 47: 0, 48: 0, 49: 0}}
[Average accuracy till task2]	Acc@1: 93.7500	Acc@5: 99.4000	Loss: 0.5372	Forgetting: 2.7000	Backward: -2.7000
Train: Epoch[1/5]  [  0/313]  eta: 0:02:45  Lr: 0.001875  Loss: 1.3059  Acc@1: 12.5000 (12.5000)  Acc@5: 37.5000 (37.5000)  time: 0.5276  data: 0.1882  max mem: 2360
Train: Epoch[1/5]  [ 10/313]  eta: 0:01:44  Lr: 0.001875  Loss: 0.9895  Acc@1: 43.7500 (40.3409)  Acc@5: 81.2500 (79.5455)  time: 0.3454  data: 0.0172  max mem: 2362
Train: Epoch[1/5]  [ 20/313]  eta: 0:01:38  Lr: 0.001875  Loss: 0.6735  Acc@1: 50.0000 (53.8690)  Acc@5: 87.5000 (86.9048)  time: 0.3278  data: 0.0001  max mem: 2362
Train: Epoch[1/5]  [ 30/313]  eta: 0:01:34  Lr: 0.001875  Loss: 0.3973  Acc@1: 75.0000 (60.2823)  Acc@5: 93.7500 (89.3145)  time: 0.3286  data: 0.0001  max mem: 2362
Train: Epoch[1/5]  [ 40/313]  eta: 0:01:30  Lr: 0.001875  Loss: 0.2183  Acc@1: 75.0000 (64.7866)  Acc@5: 93.7500 (90.8537)  time: 0.3282  data: 0.0001  max mem: 2362
Train: Epoch[1/5]  [ 50/313]  eta: 0:01:27  Lr: 0.001875  Loss: 0.2133  Acc@1: 75.0000 (67.7696)  Acc@5: 100.0000 (92.0343)  time: 0.3282  data: 0.0001  max mem: 2362
Train: Epoch[1/5]  [ 60/313]  eta: 0:01:23  Lr: 0.001875  Loss: -0.0934  Acc@1: 81.2500 (70.0820)  Acc@5: 100.0000 (93.0328)  time: 0.3281  data: 0.0002  max mem: 2362
Train: Epoch[1/5]  [ 70/313]  eta: 0:01:20  Lr: 0.001875  Loss: -0.5241  Acc@1: 81.2500 (72.3592)  Acc@5: 100.0000 (93.7500)  time: 0.3278  data: 0.0002  max mem: 2362
Train: Epoch[1/5]  [ 80/313]  eta: 0:01:17  Lr: 0.001875  Loss: -0.5421  Acc@1: 81.2500 (73.5340)  Acc@5: 100.0000 (93.9815)  time: 0.3284  data: 0.0001  max mem: 2362
Train: Epoch[1/5]  [ 90/313]  eta: 0:01:13  Lr: 0.001875  Loss: -0.0516  Acc@1: 81.2500 (74.2445)  Acc@5: 100.0000 (94.3681)  time: 0.3280  data: 0.0001  max mem: 2362
Train: Epoch[1/5]  [100/313]  eta: 0:01:10  Lr: 0.001875  Loss: -0.4959  Acc@1: 81.2500 (75.1856)  Acc@5: 100.0000 (94.7401)  time: 0.3279  data: 0.0002  max mem: 2362
Train: Epoch[1/5]  [110/313]  eta: 0:01:06  Lr: 0.001875  Loss: -0.2577  Acc@1: 87.5000 (76.1824)  Acc@5: 100.0000 (94.9887)  time: 0.3282  data: 0.0002  max mem: 2362
Train: Epoch[1/5]  [120/313]  eta: 0:01:03  Lr: 0.001875  Loss: -0.8179  Acc@1: 81.2500 (76.7045)  Acc@5: 93.7500 (95.0413)  time: 0.3281  data: 0.0001  max mem: 2362
Train: Epoch[1/5]  [130/313]  eta: 0:01:00  Lr: 0.001875  Loss: -0.4564  Acc@1: 81.2500 (77.0038)  Acc@5: 93.7500 (95.1813)  time: 0.3287  data: 0.0001  max mem: 2362
Train: Epoch[1/5]  [140/313]  eta: 0:00:57  Lr: 0.001875  Loss: -0.6538  Acc@1: 81.2500 (77.4379)  Acc@5: 100.0000 (95.4787)  time: 0.3288  data: 0.0002  max mem: 2362
Train: Epoch[1/5]  [150/313]  eta: 0:00:53  Lr: 0.001875  Loss: -0.5610  Acc@1: 87.5000 (78.1457)  Acc@5: 100.0000 (95.6126)  time: 0.3284  data: 0.0002  max mem: 2362
Train: Epoch[1/5]  [160/313]  eta: 0:00:50  Lr: 0.001875  Loss: -0.6956  Acc@1: 93.7500 (78.9208)  Acc@5: 100.0000 (95.7298)  time: 0.3285  data: 0.0001  max mem: 2362
Train: Epoch[1/5]  [170/313]  eta: 0:00:47  Lr: 0.001875  Loss: -0.4282  Acc@1: 87.5000 (79.3494)  Acc@5: 100.0000 (95.8333)  time: 0.3282  data: 0.0001  max mem: 2362
Train: Epoch[1/5]  [180/313]  eta: 0:00:43  Lr: 0.001875  Loss: -0.2580  Acc@1: 87.5000 (79.4544)  Acc@5: 100.0000 (95.8218)  time: 0.3283  data: 0.0001  max mem: 2362
Train: Epoch[1/5]  [190/313]  eta: 0:00:40  Lr: 0.001875  Loss: -0.5156  Acc@1: 81.2500 (79.7775)  Acc@5: 100.0000 (95.9424)  time: 0.3287  data: 0.0001  max mem: 2362
Train: Epoch[1/5]  [200/313]  eta: 0:00:37  Lr: 0.001875  Loss: -0.2813  Acc@1: 81.2500 (79.8197)  Acc@5: 100.0000 (96.0199)  time: 0.3280  data: 0.0001  max mem: 2362
Train: Epoch[1/5]  [210/313]  eta: 0:00:33  Lr: 0.001875  Loss: -0.6416  Acc@1: 81.2500 (79.9763)  Acc@5: 100.0000 (96.0900)  time: 0.3284  data: 0.0001  max mem: 2362
Train: Epoch[1/5]  [220/313]  eta: 0:00:30  Lr: 0.001875  Loss: -0.4161  Acc@1: 81.2500 (80.2036)  Acc@5: 93.7500 (96.0690)  time: 0.3300  data: 0.0002  max mem: 2362
Train: Epoch[1/5]  [230/313]  eta: 0:00:27  Lr: 0.001875  Loss: -0.6129  Acc@1: 81.2500 (80.3301)  Acc@5: 100.0000 (96.1851)  time: 0.3319  data: 0.0004  max mem: 2362
Train: Epoch[1/5]  [240/313]  eta: 0:00:24  Lr: 0.001875  Loss: -0.3412  Acc@1: 81.2500 (80.4720)  Acc@5: 100.0000 (96.2915)  time: 0.3323  data: 0.0004  max mem: 2362
Train: Epoch[1/5]  [250/313]  eta: 0:00:20  Lr: 0.001875  Loss: -0.6371  Acc@1: 87.5000 (80.7520)  Acc@5: 100.0000 (96.3396)  time: 0.3312  data: 0.0004  max mem: 2362
Train: Epoch[1/5]  [260/313]  eta: 0:00:17  Lr: 0.001875  Loss: -0.8402  Acc@1: 87.5000 (80.9866)  Acc@5: 100.0000 (96.4559)  time: 0.3319  data: 0.0004  max mem: 2362
Train: Epoch[1/5]  [270/313]  eta: 0:00:14  Lr: 0.001875  Loss: -0.6689  Acc@1: 87.5000 (81.2961)  Acc@5: 100.0000 (96.5637)  time: 0.3326  data: 0.0003  max mem: 2362
Train: Epoch[1/5]  [280/313]  eta: 0:00:10  Lr: 0.001875  Loss: -0.7951  Acc@1: 87.5000 (81.5836)  Acc@5: 100.0000 (96.5970)  time: 0.3315  data: 0.0003  max mem: 2362
Train: Epoch[1/5]  [290/313]  eta: 0:00:07  Lr: 0.001875  Loss: -0.7690  Acc@1: 87.5000 (81.8084)  Acc@5: 100.0000 (96.7139)  time: 0.3309  data: 0.0003  max mem: 2362
Train: Epoch[1/5]  [300/313]  eta: 0:00:04  Lr: 0.001875  Loss: -0.6204  Acc@1: 93.7500 (81.9145)  Acc@5: 100.0000 (96.7400)  time: 0.3307  data: 0.0004  max mem: 2362
Train: Epoch[1/5]  [310/313]  eta: 0:00:00  Lr: 0.001875  Loss: -0.7136  Acc@1: 87.5000 (81.9936)  Acc@5: 100.0000 (96.7846)  time: 0.3302  data: 0.0004  max mem: 2362
Train: Epoch[1/5]  [312/313]  eta: 0:00:00  Lr: 0.001875  Loss: -0.7156  Acc@1: 87.5000 (82.0200)  Acc@5: 100.0000 (96.8000)  time: 0.3225  data: 0.0004  max mem: 2362
Train: Epoch[1/5] Total time: 0:01:43 (0.3297 s / it)
Averaged stats: Lr: 0.001875  Loss: -0.7156  Acc@1: 87.5000 (82.0200)  Acc@5: 100.0000 (96.8000)
Train: Epoch[2/5]  [  0/313]  eta: 0:03:29  Lr: 0.001875  Loss: -0.4887  Acc@1: 75.0000 (75.0000)  Acc@5: 100.0000 (100.0000)  time: 0.6684  data: 0.3368  max mem: 2362
Train: Epoch[2/5]  [ 10/313]  eta: 0:01:49  Lr: 0.001875  Loss: -0.6930  Acc@1: 81.2500 (84.0909)  Acc@5: 100.0000 (98.8636)  time: 0.3624  data: 0.0310  max mem: 2362
Train: Epoch[2/5]  [ 20/313]  eta: 0:01:41  Lr: 0.001875  Loss: -0.6977  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (99.4048)  time: 0.3318  data: 0.0005  max mem: 2362
Train: Epoch[2/5]  [ 30/313]  eta: 0:01:36  Lr: 0.001875  Loss: -0.5481  Acc@1: 87.5000 (87.0968)  Acc@5: 100.0000 (98.1855)  time: 0.3316  data: 0.0005  max mem: 2362
Train: Epoch[2/5]  [ 40/313]  eta: 0:01:32  Lr: 0.001875  Loss: -0.6737  Acc@1: 87.5000 (87.9573)  Acc@5: 100.0000 (98.3232)  time: 0.3321  data: 0.0004  max mem: 2362
Train: Epoch[2/5]  [ 50/313]  eta: 0:01:29  Lr: 0.001875  Loss: -0.9113  Acc@1: 87.5000 (87.0098)  Acc@5: 100.0000 (98.6520)  time: 0.3322  data: 0.0004  max mem: 2362
Train: Epoch[2/5]  [ 60/313]  eta: 0:01:25  Lr: 0.001875  Loss: -0.6301  Acc@1: 87.5000 (87.0902)  Acc@5: 100.0000 (98.6680)  time: 0.3329  data: 0.0004  max mem: 2362
Train: Epoch[2/5]  [ 70/313]  eta: 0:01:21  Lr: 0.001875  Loss: -0.4593  Acc@1: 87.5000 (86.8838)  Acc@5: 100.0000 (98.8556)  time: 0.3325  data: 0.0004  max mem: 2362
Train: Epoch[2/5]  [ 80/313]  eta: 0:01:18  Lr: 0.001875  Loss: -0.7209  Acc@1: 87.5000 (86.1883)  Acc@5: 100.0000 (98.7654)  time: 0.3314  data: 0.0004  max mem: 2362
Train: Epoch[2/5]  [ 90/313]  eta: 0:01:14  Lr: 0.001875  Loss: -0.4013  Acc@1: 87.5000 (86.3324)  Acc@5: 100.0000 (98.5577)  time: 0.3320  data: 0.0004  max mem: 2362
Train: Epoch[2/5]  [100/313]  eta: 0:01:11  Lr: 0.001875  Loss: -0.6288  Acc@1: 87.5000 (86.0767)  Acc@5: 100.0000 (98.6386)  time: 0.3312  data: 0.0004  max mem: 2362
Train: Epoch[2/5]  [110/313]  eta: 0:01:07  Lr: 0.001875  Loss: -0.7642  Acc@1: 87.5000 (86.0923)  Acc@5: 100.0000 (98.5923)  time: 0.3305  data: 0.0006  max mem: 2362
Train: Epoch[2/5]  [120/313]  eta: 0:01:04  Lr: 0.001875  Loss: -0.7222  Acc@1: 87.5000 (86.1570)  Acc@5: 100.0000 (98.6054)  time: 0.3306  data: 0.0006  max mem: 2362
Train: Epoch[2/5]  [130/313]  eta: 0:01:01  Lr: 0.001875  Loss: -0.5534  Acc@1: 87.5000 (85.9256)  Acc@5: 100.0000 (98.4256)  time: 0.3306  data: 0.0004  max mem: 2362
Train: Epoch[2/5]  [140/313]  eta: 0:00:57  Lr: 0.001875  Loss: -0.9321  Acc@1: 81.2500 (85.4610)  Acc@5: 100.0000 (98.3599)  time: 0.3317  data: 0.0005  max mem: 2362
Train: Epoch[2/5]  [150/313]  eta: 0:00:54  Lr: 0.001875  Loss: -0.7627  Acc@1: 81.2500 (85.5132)  Acc@5: 100.0000 (98.3030)  time: 0.3318  data: 0.0005  max mem: 2362
Train: Epoch[2/5]  [160/313]  eta: 0:00:51  Lr: 0.001875  Loss: -0.6419  Acc@1: 81.2500 (85.4814)  Acc@5: 100.0000 (98.2531)  time: 0.3310  data: 0.0004  max mem: 2362
Train: Epoch[2/5]  [170/313]  eta: 0:00:47  Lr: 0.001875  Loss: -1.0067  Acc@1: 87.5000 (85.7822)  Acc@5: 100.0000 (98.2456)  time: 0.3309  data: 0.0005  max mem: 2362
Train: Epoch[2/5]  [180/313]  eta: 0:00:44  Lr: 0.001875  Loss: -0.7737  Acc@1: 87.5000 (85.6008)  Acc@5: 100.0000 (98.2044)  time: 0.3304  data: 0.0005  max mem: 2362
Train: Epoch[2/5]  [190/313]  eta: 0:00:40  Lr: 0.001875  Loss: -0.3383  Acc@1: 87.5000 (85.6348)  Acc@5: 100.0000 (98.2330)  time: 0.3304  data: 0.0004  max mem: 2362
Train: Epoch[2/5]  [200/313]  eta: 0:00:37  Lr: 0.001875  Loss: -0.8054  Acc@1: 87.5000 (85.6965)  Acc@5: 100.0000 (98.2898)  time: 0.3304  data: 0.0005  max mem: 2362
Train: Epoch[2/5]  [210/313]  eta: 0:00:34  Lr: 0.001875  Loss: -0.7660  Acc@1: 87.5000 (85.6043)  Acc@5: 100.0000 (98.2524)  time: 0.3309  data: 0.0005  max mem: 2362
Train: Epoch[2/5]  [220/313]  eta: 0:00:30  Lr: 0.001875  Loss: -0.9359  Acc@1: 87.5000 (85.7749)  Acc@5: 100.0000 (98.3314)  time: 0.3309  data: 0.0006  max mem: 2362
Train: Epoch[2/5]  [230/313]  eta: 0:00:27  Lr: 0.001875  Loss: -0.7835  Acc@1: 93.7500 (85.9848)  Acc@5: 100.0000 (98.4037)  time: 0.3305  data: 0.0005  max mem: 2362
Train: Epoch[2/5]  [240/313]  eta: 0:00:24  Lr: 0.001875  Loss: -0.7411  Acc@1: 93.7500 (86.0996)  Acc@5: 100.0000 (98.3662)  time: 0.3307  data: 0.0004  max mem: 2362
Train: Epoch[2/5]  [250/313]  eta: 0:00:20  Lr: 0.001875  Loss: -0.1928  Acc@1: 87.5000 (85.9562)  Acc@5: 100.0000 (98.3566)  time: 0.3308  data: 0.0004  max mem: 2362
Train: Epoch[2/5]  [260/313]  eta: 0:00:17  Lr: 0.001875  Loss: -0.9603  Acc@1: 87.5000 (86.1351)  Acc@5: 100.0000 (98.3716)  time: 0.3304  data: 0.0004  max mem: 2362
Train: Epoch[2/5]  [270/313]  eta: 0:00:14  Lr: 0.001875  Loss: -0.7588  Acc@1: 87.5000 (86.1393)  Acc@5: 100.0000 (98.3164)  time: 0.3299  data: 0.0004  max mem: 2362
Train: Epoch[2/5]  [280/313]  eta: 0:00:10  Lr: 0.001875  Loss: -0.1721  Acc@1: 87.5000 (86.1210)  Acc@5: 100.0000 (98.3096)  time: 0.3301  data: 0.0004  max mem: 2362
Train: Epoch[2/5]  [290/313]  eta: 0:00:07  Lr: 0.001875  Loss: -0.9350  Acc@1: 81.2500 (85.9321)  Acc@5: 100.0000 (98.2818)  time: 0.3300  data: 0.0004  max mem: 2362
Train: Epoch[2/5]  [300/313]  eta: 0:00:04  Lr: 0.001875  Loss: -0.3924  Acc@1: 81.2500 (85.9219)  Acc@5: 100.0000 (98.2973)  time: 0.3298  data: 0.0004  max mem: 2362
Train: Epoch[2/5]  [310/313]  eta: 0:00:00  Lr: 0.001875  Loss: -0.5787  Acc@1: 87.5000 (85.9928)  Acc@5: 100.0000 (98.2516)  time: 0.3299  data: 0.0004  max mem: 2362
Train: Epoch[2/5]  [312/313]  eta: 0:00:00  Lr: 0.001875  Loss: -0.3109  Acc@1: 87.5000 (85.9400)  Acc@5: 100.0000 (98.2600)  time: 0.3218  data: 0.0004  max mem: 2362
Train: Epoch[2/5] Total time: 0:01:43 (0.3319 s / it)
Averaged stats: Lr: 0.001875  Loss: -0.3109  Acc@1: 87.5000 (85.9400)  Acc@5: 100.0000 (98.2600)
Train: Epoch[3/5]  [  0/313]  eta: 0:03:22  Lr: 0.001875  Loss: -0.8183  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (100.0000)  time: 0.6484  data: 0.3136  max mem: 2362
Train: Epoch[3/5]  [ 10/313]  eta: 0:01:48  Lr: 0.001875  Loss: -0.7259  Acc@1: 81.2500 (85.2273)  Acc@5: 100.0000 (97.7273)  time: 0.3586  data: 0.0289  max mem: 2362
Train: Epoch[3/5]  [ 20/313]  eta: 0:01:41  Lr: 0.001875  Loss: -0.8805  Acc@1: 81.2500 (86.0119)  Acc@5: 100.0000 (97.9167)  time: 0.3301  data: 0.0004  max mem: 2362
Train: Epoch[3/5]  [ 30/313]  eta: 0:01:36  Lr: 0.001875  Loss: -0.4729  Acc@1: 81.2500 (85.2823)  Acc@5: 100.0000 (97.9839)  time: 0.3304  data: 0.0004  max mem: 2362
Train: Epoch[3/5]  [ 40/313]  eta: 0:01:32  Lr: 0.001875  Loss: -0.8767  Acc@1: 81.2500 (85.5183)  Acc@5: 100.0000 (98.1707)  time: 0.3306  data: 0.0005  max mem: 2362
Train: Epoch[3/5]  [ 50/313]  eta: 0:01:28  Lr: 0.001875  Loss: -0.3437  Acc@1: 87.5000 (85.9069)  Acc@5: 100.0000 (98.2843)  time: 0.3306  data: 0.0004  max mem: 2362
Train: Epoch[3/5]  [ 60/313]  eta: 0:01:24  Lr: 0.001875  Loss: -0.8611  Acc@1: 87.5000 (86.2705)  Acc@5: 100.0000 (98.2582)  time: 0.3305  data: 0.0004  max mem: 2362
Train: Epoch[3/5]  [ 70/313]  eta: 0:01:21  Lr: 0.001875  Loss: 0.0850  Acc@1: 87.5000 (86.7077)  Acc@5: 100.0000 (98.3275)  time: 0.3311  data: 0.0004  max mem: 2362
Train: Epoch[3/5]  [ 80/313]  eta: 0:01:17  Lr: 0.001875  Loss: -0.8488  Acc@1: 93.7500 (86.9599)  Acc@5: 100.0000 (98.4568)  time: 0.3311  data: 0.0005  max mem: 2362
Train: Epoch[3/5]  [ 90/313]  eta: 0:01:14  Lr: 0.001875  Loss: -0.8955  Acc@1: 87.5000 (86.8819)  Acc@5: 100.0000 (98.4203)  time: 0.3306  data: 0.0005  max mem: 2362
Train: Epoch[3/5]  [100/313]  eta: 0:01:11  Lr: 0.001875  Loss: -0.7925  Acc@1: 87.5000 (86.7574)  Acc@5: 100.0000 (98.5767)  time: 0.3306  data: 0.0005  max mem: 2362
Train: Epoch[3/5]  [110/313]  eta: 0:01:07  Lr: 0.001875  Loss: -0.7539  Acc@1: 87.5000 (86.7117)  Acc@5: 100.0000 (98.4797)  time: 0.3305  data: 0.0005  max mem: 2362
Train: Epoch[3/5]  [120/313]  eta: 0:01:04  Lr: 0.001875  Loss: -1.0255  Acc@1: 87.5000 (86.6219)  Acc@5: 100.0000 (98.6054)  time: 0.3296  data: 0.0005  max mem: 2362
Train: Epoch[3/5]  [130/313]  eta: 0:01:00  Lr: 0.001875  Loss: -0.6928  Acc@1: 87.5000 (86.6889)  Acc@5: 100.0000 (98.6641)  time: 0.3293  data: 0.0004  max mem: 2362
Train: Epoch[3/5]  [140/313]  eta: 0:00:57  Lr: 0.001875  Loss: -0.7769  Acc@1: 87.5000 (86.7465)  Acc@5: 100.0000 (98.6259)  time: 0.3301  data: 0.0005  max mem: 2362
Train: Epoch[3/5]  [150/313]  eta: 0:00:54  Lr: 0.001875  Loss: -0.7856  Acc@1: 87.5000 (86.7550)  Acc@5: 100.0000 (98.7169)  time: 0.3316  data: 0.0010  max mem: 2362
Train: Epoch[3/5]  [160/313]  eta: 0:00:50  Lr: 0.001875  Loss: -0.9350  Acc@1: 87.5000 (87.0342)  Acc@5: 100.0000 (98.7189)  time: 0.3317  data: 0.0010  max mem: 2362
Train: Epoch[3/5]  [170/313]  eta: 0:00:47  Lr: 0.001875  Loss: -0.1935  Acc@1: 93.7500 (87.2076)  Acc@5: 100.0000 (98.7208)  time: 0.3316  data: 0.0005  max mem: 2362
Train: Epoch[3/5]  [180/313]  eta: 0:00:44  Lr: 0.001875  Loss: -0.7702  Acc@1: 87.5000 (87.1547)  Acc@5: 100.0000 (98.6533)  time: 0.3314  data: 0.0005  max mem: 2362
Train: Epoch[3/5]  [190/313]  eta: 0:00:40  Lr: 0.001875  Loss: -0.7321  Acc@1: 81.2500 (86.9110)  Acc@5: 100.0000 (98.6584)  time: 0.3308  data: 0.0006  max mem: 2362
Train: Epoch[3/5]  [200/313]  eta: 0:00:37  Lr: 0.001875  Loss: -0.7017  Acc@1: 87.5000 (86.9092)  Acc@5: 100.0000 (98.6940)  time: 0.3308  data: 0.0005  max mem: 2362
Train: Epoch[3/5]  [210/313]  eta: 0:00:34  Lr: 0.001875  Loss: -0.8047  Acc@1: 87.5000 (87.1149)  Acc@5: 100.0000 (98.7263)  time: 0.3309  data: 0.0004  max mem: 2362
Train: Epoch[3/5]  [220/313]  eta: 0:00:30  Lr: 0.001875  Loss: -0.9504  Acc@1: 87.5000 (87.2738)  Acc@5: 100.0000 (98.7557)  time: 0.3308  data: 0.0004  max mem: 2362
Train: Epoch[3/5]  [230/313]  eta: 0:00:27  Lr: 0.001875  Loss: -0.8969  Acc@1: 93.7500 (87.4729)  Acc@5: 100.0000 (98.7825)  time: 0.3302  data: 0.0004  max mem: 2362
Train: Epoch[3/5]  [240/313]  eta: 0:00:24  Lr: 0.001875  Loss: -0.9709  Acc@1: 93.7500 (87.5778)  Acc@5: 100.0000 (98.7552)  time: 0.3301  data: 0.0004  max mem: 2362
Train: Epoch[3/5]  [250/313]  eta: 0:00:20  Lr: 0.001875  Loss: -0.7461  Acc@1: 87.5000 (87.5747)  Acc@5: 100.0000 (98.7799)  time: 0.3308  data: 0.0004  max mem: 2362
Train: Epoch[3/5]  [260/313]  eta: 0:00:17  Lr: 0.001875  Loss: -0.7825  Acc@1: 87.5000 (87.4761)  Acc@5: 100.0000 (98.7548)  time: 0.3310  data: 0.0004  max mem: 2362
Train: Epoch[3/5]  [270/313]  eta: 0:00:14  Lr: 0.001875  Loss: -0.9095  Acc@1: 87.5000 (87.4769)  Acc@5: 100.0000 (98.7546)  time: 0.3299  data: 0.0004  max mem: 2362
Train: Epoch[3/5]  [280/313]  eta: 0:00:10  Lr: 0.001875  Loss: -0.9558  Acc@1: 87.5000 (87.5222)  Acc@5: 100.0000 (98.7100)  time: 0.3298  data: 0.0004  max mem: 2362
Train: Epoch[3/5]  [290/313]  eta: 0:00:07  Lr: 0.001875  Loss: -0.7740  Acc@1: 87.5000 (87.5644)  Acc@5: 100.0000 (98.7328)  time: 0.3306  data: 0.0004  max mem: 2362
Train: Epoch[3/5]  [300/313]  eta: 0:00:04  Lr: 0.001875  Loss: -0.3225  Acc@1: 87.5000 (87.4792)  Acc@5: 100.0000 (98.6919)  time: 0.3305  data: 0.0005  max mem: 2362
Train: Epoch[3/5]  [310/313]  eta: 0:00:00  Lr: 0.001875  Loss: -0.5791  Acc@1: 81.2500 (87.4196)  Acc@5: 100.0000 (98.6937)  time: 0.3310  data: 0.0004  max mem: 2362
Train: Epoch[3/5]  [312/313]  eta: 0:00:00  Lr: 0.001875  Loss: -0.9690  Acc@1: 87.5000 (87.4600)  Acc@5: 100.0000 (98.7000)  time: 0.3230  data: 0.0004  max mem: 2362
Train: Epoch[3/5] Total time: 0:01:43 (0.3317 s / it)
Averaged stats: Lr: 0.001875  Loss: -0.9690  Acc@1: 87.5000 (87.4600)  Acc@5: 100.0000 (98.7000)
Train: Epoch[4/5]  [  0/313]  eta: 0:03:25  Lr: 0.001875  Loss: -0.6565  Acc@1: 93.7500 (93.7500)  Acc@5: 100.0000 (100.0000)  time: 0.6561  data: 0.3241  max mem: 2362
Train: Epoch[4/5]  [ 10/313]  eta: 0:01:48  Lr: 0.001875  Loss: -0.1386  Acc@1: 87.5000 (88.0682)  Acc@5: 100.0000 (98.8636)  time: 0.3596  data: 0.0298  max mem: 2362
Train: Epoch[4/5]  [ 20/313]  eta: 0:01:41  Lr: 0.001875  Loss: -0.7570  Acc@1: 87.5000 (89.8810)  Acc@5: 100.0000 (99.1071)  time: 0.3301  data: 0.0005  max mem: 2362
Train: Epoch[4/5]  [ 30/313]  eta: 0:01:36  Lr: 0.001875  Loss: -0.6358  Acc@1: 87.5000 (88.5081)  Acc@5: 100.0000 (98.7903)  time: 0.3312  data: 0.0004  max mem: 2362
Train: Epoch[4/5]  [ 40/313]  eta: 0:01:32  Lr: 0.001875  Loss: -0.9268  Acc@1: 81.2500 (87.6524)  Acc@5: 100.0000 (98.3232)  time: 0.3310  data: 0.0003  max mem: 2362
Train: Epoch[4/5]  [ 50/313]  eta: 0:01:28  Lr: 0.001875  Loss: -0.7095  Acc@1: 87.5000 (88.2353)  Acc@5: 100.0000 (98.0392)  time: 0.3304  data: 0.0004  max mem: 2362
Train: Epoch[4/5]  [ 60/313]  eta: 0:01:25  Lr: 0.001875  Loss: -0.1765  Acc@1: 93.7500 (89.1393)  Acc@5: 100.0000 (98.2582)  time: 0.3313  data: 0.0012  max mem: 2362
Train: Epoch[4/5]  [ 70/313]  eta: 0:01:21  Lr: 0.001875  Loss: -0.7601  Acc@1: 87.5000 (88.5563)  Acc@5: 100.0000 (98.4155)  time: 0.3310  data: 0.0016  max mem: 2362
Train: Epoch[4/5]  [ 80/313]  eta: 0:01:18  Lr: 0.001875  Loss: -0.9271  Acc@1: 87.5000 (88.7346)  Acc@5: 100.0000 (98.5340)  time: 0.3306  data: 0.0008  max mem: 2362
Train: Epoch[4/5]  [ 90/313]  eta: 0:01:14  Lr: 0.001875  Loss: -0.4954  Acc@1: 93.7500 (88.8736)  Acc@5: 100.0000 (98.6951)  time: 0.3308  data: 0.0004  max mem: 2362
Train: Epoch[4/5]  [100/313]  eta: 0:01:11  Lr: 0.001875  Loss: -0.7522  Acc@1: 93.7500 (88.7376)  Acc@5: 100.0000 (98.6386)  time: 0.3309  data: 0.0004  max mem: 2362
Train: Epoch[4/5]  [110/313]  eta: 0:01:07  Lr: 0.001875  Loss: -0.8310  Acc@1: 87.5000 (88.5135)  Acc@5: 100.0000 (98.7050)  time: 0.3303  data: 0.0004  max mem: 2362
Train: Epoch[4/5]  [120/313]  eta: 0:01:04  Lr: 0.001875  Loss: -0.8896  Acc@1: 87.5000 (88.4814)  Acc@5: 100.0000 (98.6054)  time: 0.3299  data: 0.0004  max mem: 2362
Train: Epoch[4/5]  [130/313]  eta: 0:01:00  Lr: 0.001875  Loss: -0.9828  Acc@1: 87.5000 (88.5019)  Acc@5: 100.0000 (98.6641)  time: 0.3309  data: 0.0011  max mem: 2362
Train: Epoch[4/5]  [140/313]  eta: 0:00:57  Lr: 0.001875  Loss: -0.5292  Acc@1: 87.5000 (88.2979)  Acc@5: 100.0000 (98.7589)  time: 0.3313  data: 0.0010  max mem: 2362
Train: Epoch[4/5]  [150/313]  eta: 0:00:54  Lr: 0.001875  Loss: -0.9752  Acc@1: 87.5000 (88.3692)  Acc@5: 100.0000 (98.7997)  time: 0.3308  data: 0.0004  max mem: 2362
Train: Epoch[4/5]  [160/313]  eta: 0:00:50  Lr: 0.001875  Loss: -0.6101  Acc@1: 87.5000 (88.3540)  Acc@5: 100.0000 (98.6801)  time: 0.3306  data: 0.0004  max mem: 2362
Train: Epoch[4/5]  [170/313]  eta: 0:00:47  Lr: 0.001875  Loss: -0.6892  Acc@1: 87.5000 (88.1579)  Acc@5: 100.0000 (98.7208)  time: 0.3306  data: 0.0004  max mem: 2362
Train: Epoch[4/5]  [180/313]  eta: 0:00:44  Lr: 0.001875  Loss: -0.6440  Acc@1: 87.5000 (88.2597)  Acc@5: 100.0000 (98.7224)  time: 0.3303  data: 0.0005  max mem: 2362
Train: Epoch[4/5]  [190/313]  eta: 0:00:40  Lr: 0.001875  Loss: -0.8919  Acc@1: 87.5000 (88.1545)  Acc@5: 100.0000 (98.6584)  time: 0.3300  data: 0.0006  max mem: 2362
Train: Epoch[4/5]  [200/313]  eta: 0:00:37  Lr: 0.001875  Loss: -0.5449  Acc@1: 87.5000 (88.0908)  Acc@5: 100.0000 (98.6940)  time: 0.3302  data: 0.0005  max mem: 2362
Train: Epoch[4/5]  [210/313]  eta: 0:00:34  Lr: 0.001875  Loss: -0.7918  Acc@1: 87.5000 (88.0924)  Acc@5: 100.0000 (98.6374)  time: 0.3300  data: 0.0005  max mem: 2362
Train: Epoch[4/5]  [220/313]  eta: 0:00:30  Lr: 0.001875  Loss: -0.3644  Acc@1: 87.5000 (87.9525)  Acc@5: 100.0000 (98.6991)  time: 0.3299  data: 0.0004  max mem: 2362
Train: Epoch[4/5]  [230/313]  eta: 0:00:27  Lr: 0.001875  Loss: -0.6998  Acc@1: 87.5000 (87.9600)  Acc@5: 100.0000 (98.7554)  time: 0.3302  data: 0.0004  max mem: 2362
Train: Epoch[4/5]  [240/313]  eta: 0:00:24  Lr: 0.001875  Loss: -0.5113  Acc@1: 87.5000 (87.8371)  Acc@5: 100.0000 (98.7293)  time: 0.3303  data: 0.0004  max mem: 2362
Train: Epoch[4/5]  [250/313]  eta: 0:00:20  Lr: 0.001875  Loss: -0.5882  Acc@1: 87.5000 (87.9980)  Acc@5: 100.0000 (98.7799)  time: 0.3302  data: 0.0004  max mem: 2362
Train: Epoch[4/5]  [260/313]  eta: 0:00:17  Lr: 0.001875  Loss: -0.6312  Acc@1: 93.7500 (88.1226)  Acc@5: 100.0000 (98.7787)  time: 0.3300  data: 0.0004  max mem: 2362
Train: Epoch[4/5]  [270/313]  eta: 0:00:14  Lr: 0.001875  Loss: -0.7675  Acc@1: 87.5000 (88.1919)  Acc@5: 100.0000 (98.7777)  time: 0.3303  data: 0.0004  max mem: 2362
Train: Epoch[4/5]  [280/313]  eta: 0:00:10  Lr: 0.001875  Loss: -0.8126  Acc@1: 87.5000 (88.0116)  Acc@5: 100.0000 (98.7322)  time: 0.3304  data: 0.0004  max mem: 2362
Train: Epoch[4/5]  [290/313]  eta: 0:00:07  Lr: 0.001875  Loss: -0.7224  Acc@1: 87.5000 (87.9940)  Acc@5: 100.0000 (98.7328)  time: 0.3306  data: 0.0004  max mem: 2362
Train: Epoch[4/5]  [300/313]  eta: 0:00:04  Lr: 0.001875  Loss: -0.5139  Acc@1: 87.5000 (87.8945)  Acc@5: 100.0000 (98.6919)  time: 0.3306  data: 0.0004  max mem: 2362
Train: Epoch[4/5]  [310/313]  eta: 0:00:00  Lr: 0.001875  Loss: -0.4919  Acc@1: 87.5000 (87.9019)  Acc@5: 100.0000 (98.7138)  time: 0.3304  data: 0.0004  max mem: 2362
Train: Epoch[4/5]  [312/313]  eta: 0:00:00  Lr: 0.001875  Loss: -0.9824  Acc@1: 87.5000 (87.9400)  Acc@5: 100.0000 (98.7200)  time: 0.3222  data: 0.0004  max mem: 2362
Train: Epoch[4/5] Total time: 0:01:43 (0.3314 s / it)
Averaged stats: Lr: 0.001875  Loss: -0.9824  Acc@1: 87.5000 (87.9400)  Acc@5: 100.0000 (98.7200)
Train: Epoch[5/5]  [  0/313]  eta: 0:03:51  Lr: 0.001875  Loss: -0.8557  Acc@1: 93.7500 (93.7500)  Acc@5: 93.7500 (93.7500)  time: 0.7409  data: 0.4125  max mem: 2362
Train: Epoch[5/5]  [ 10/313]  eta: 0:01:51  Lr: 0.001875  Loss: -0.9067  Acc@1: 87.5000 (88.0682)  Acc@5: 100.0000 (98.2955)  time: 0.3676  data: 0.0379  max mem: 2362
Train: Epoch[5/5]  [ 20/313]  eta: 0:01:42  Lr: 0.001875  Loss: -0.8545  Acc@1: 87.5000 (88.9881)  Acc@5: 100.0000 (98.8095)  time: 0.3309  data: 0.0004  max mem: 2362
Train: Epoch[5/5]  [ 30/313]  eta: 0:01:37  Lr: 0.001875  Loss: -0.6654  Acc@1: 87.5000 (88.1048)  Acc@5: 100.0000 (98.9919)  time: 0.3312  data: 0.0004  max mem: 2362
Train: Epoch[5/5]  [ 40/313]  eta: 0:01:33  Lr: 0.001875  Loss: -0.6476  Acc@1: 87.5000 (87.8049)  Acc@5: 100.0000 (98.4756)  time: 0.3313  data: 0.0009  max mem: 2362
Train: Epoch[5/5]  [ 50/313]  eta: 0:01:29  Lr: 0.001875  Loss: -0.9225  Acc@1: 87.5000 (87.7451)  Acc@5: 100.0000 (98.7745)  time: 0.3317  data: 0.0010  max mem: 2362
Train: Epoch[5/5]  [ 60/313]  eta: 0:01:25  Lr: 0.001875  Loss: -0.7271  Acc@1: 87.5000 (87.2951)  Acc@5: 100.0000 (98.8730)  time: 0.3320  data: 0.0005  max mem: 2362
Train: Epoch[5/5]  [ 70/313]  eta: 0:01:21  Lr: 0.001875  Loss: -0.9341  Acc@1: 87.5000 (87.6761)  Acc@5: 100.0000 (98.8556)  time: 0.3320  data: 0.0011  max mem: 2362
Train: Epoch[5/5]  [ 80/313]  eta: 0:01:18  Lr: 0.001875  Loss: -0.8282  Acc@1: 93.7500 (88.1173)  Acc@5: 100.0000 (98.7654)  time: 0.3312  data: 0.0011  max mem: 2362
Train: Epoch[5/5]  [ 90/313]  eta: 0:01:14  Lr: 0.001875  Loss: -1.0418  Acc@1: 93.7500 (88.4615)  Acc@5: 100.0000 (98.7637)  time: 0.3307  data: 0.0005  max mem: 2362
Train: Epoch[5/5]  [100/313]  eta: 0:01:11  Lr: 0.001875  Loss: -0.8868  Acc@1: 87.5000 (88.4282)  Acc@5: 100.0000 (98.8243)  time: 0.3304  data: 0.0005  max mem: 2362
Train: Epoch[5/5]  [110/313]  eta: 0:01:07  Lr: 0.001875  Loss: -0.8383  Acc@1: 87.5000 (88.2883)  Acc@5: 100.0000 (98.7613)  time: 0.3305  data: 0.0004  max mem: 2362
Train: Epoch[5/5]  [120/313]  eta: 0:01:04  Lr: 0.001875  Loss: -0.9763  Acc@1: 87.5000 (88.4298)  Acc@5: 100.0000 (98.8120)  time: 0.3313  data: 0.0005  max mem: 2362
Train: Epoch[5/5]  [130/313]  eta: 0:01:01  Lr: 0.001875  Loss: -0.6100  Acc@1: 87.5000 (88.6450)  Acc@5: 100.0000 (98.7595)  time: 0.3317  data: 0.0005  max mem: 2362
Train: Epoch[5/5]  [140/313]  eta: 0:00:57  Lr: 0.001875  Loss: -0.9629  Acc@1: 87.5000 (88.6082)  Acc@5: 100.0000 (98.7589)  time: 0.3308  data: 0.0004  max mem: 2362
Train: Epoch[5/5]  [150/313]  eta: 0:00:54  Lr: 0.001875  Loss: -0.5374  Acc@1: 87.5000 (88.4106)  Acc@5: 100.0000 (98.7169)  time: 0.3305  data: 0.0005  max mem: 2362
Train: Epoch[5/5]  [160/313]  eta: 0:00:51  Lr: 0.001875  Loss: -0.6824  Acc@1: 87.5000 (88.5093)  Acc@5: 100.0000 (98.7966)  time: 0.3316  data: 0.0006  max mem: 2362
Train: Epoch[5/5]  [170/313]  eta: 0:00:47  Lr: 0.001875  Loss: -0.7842  Acc@1: 87.5000 (88.5234)  Acc@5: 100.0000 (98.7939)  time: 0.3317  data: 0.0006  max mem: 2362
Train: Epoch[5/5]  [180/313]  eta: 0:00:44  Lr: 0.001875  Loss: -0.9895  Acc@1: 93.7500 (88.7086)  Acc@5: 100.0000 (98.8260)  time: 0.3308  data: 0.0005  max mem: 2362
Train: Epoch[5/5]  [190/313]  eta: 0:00:40  Lr: 0.001875  Loss: -0.2711  Acc@1: 87.5000 (88.6780)  Acc@5: 100.0000 (98.8547)  time: 0.3309  data: 0.0007  max mem: 2362
Train: Epoch[5/5]  [200/313]  eta: 0:00:37  Lr: 0.001875  Loss: -0.8510  Acc@1: 87.5000 (88.5261)  Acc@5: 100.0000 (98.8495)  time: 0.3312  data: 0.0006  max mem: 2362
Train: Epoch[5/5]  [210/313]  eta: 0:00:34  Lr: 0.001875  Loss: -1.0415  Acc@1: 87.5000 (88.6256)  Acc@5: 100.0000 (98.8744)  time: 0.3311  data: 0.0004  max mem: 2362
Train: Epoch[5/5]  [220/313]  eta: 0:00:30  Lr: 0.001875  Loss: -0.5115  Acc@1: 87.5000 (88.4615)  Acc@5: 100.0000 (98.8405)  time: 0.3313  data: 0.0004  max mem: 2362
Train: Epoch[5/5]  [230/313]  eta: 0:00:27  Lr: 0.001875  Loss: -0.8471  Acc@1: 87.5000 (88.4740)  Acc@5: 100.0000 (98.8366)  time: 0.3310  data: 0.0004  max mem: 2362
Train: Epoch[5/5]  [240/313]  eta: 0:00:24  Lr: 0.001875  Loss: -0.8027  Acc@1: 87.5000 (88.5373)  Acc@5: 100.0000 (98.8330)  time: 0.3309  data: 0.0005  max mem: 2362
Train: Epoch[5/5]  [250/313]  eta: 0:00:20  Lr: 0.001875  Loss: -0.8184  Acc@1: 93.7500 (88.4462)  Acc@5: 100.0000 (98.8297)  time: 0.3306  data: 0.0005  max mem: 2362
Train: Epoch[5/5]  [260/313]  eta: 0:00:17  Lr: 0.001875  Loss: -0.8411  Acc@1: 93.7500 (88.5536)  Acc@5: 100.0000 (98.8506)  time: 0.3311  data: 0.0004  max mem: 2362
Train: Epoch[5/5]  [270/313]  eta: 0:00:14  Lr: 0.001875  Loss: -0.9560  Acc@1: 93.7500 (88.4686)  Acc@5: 100.0000 (98.8238)  time: 0.3315  data: 0.0004  max mem: 2362
Train: Epoch[5/5]  [280/313]  eta: 0:00:10  Lr: 0.001875  Loss: -0.6376  Acc@1: 87.5000 (88.2785)  Acc@5: 100.0000 (98.8434)  time: 0.3315  data: 0.0007  max mem: 2362
Train: Epoch[5/5]  [290/313]  eta: 0:00:07  Lr: 0.001875  Loss: -0.8277  Acc@1: 87.5000 (88.2947)  Acc@5: 100.0000 (98.8832)  time: 0.3312  data: 0.0008  max mem: 2362
Train: Epoch[5/5]  [300/313]  eta: 0:00:04  Lr: 0.001875  Loss: -0.5519  Acc@1: 87.5000 (88.3513)  Acc@5: 100.0000 (98.9203)  time: 0.3311  data: 0.0004  max mem: 2362
Train: Epoch[5/5]  [310/313]  eta: 0:00:00  Lr: 0.001875  Loss: -0.3695  Acc@1: 93.7500 (88.4043)  Acc@5: 100.0000 (98.9148)  time: 0.3307  data: 0.0003  max mem: 2362
Train: Epoch[5/5]  [312/313]  eta: 0:00:00  Lr: 0.001875  Loss: -0.9935  Acc@1: 93.7500 (88.4000)  Acc@5: 100.0000 (98.9200)  time: 0.3222  data: 0.0003  max mem: 2362
Train: Epoch[5/5] Total time: 0:01:44 (0.3323 s / it)
Averaged stats: Lr: 0.001875  Loss: -0.9935  Acc@1: 93.7500 (88.4000)  Acc@5: 100.0000 (98.9200)
Test: [Task 1]  [ 0/63]  eta: 0:00:36  Loss: 0.4885 (0.4885)  Acc@1: 93.7500 (93.7500)  Acc@5: 100.0000 (100.0000)  time: 0.5742  data: 0.3669  max mem: 2362
Test: [Task 1]  [10/63]  eta: 0:00:12  Loss: 0.4885 (0.5505)  Acc@1: 93.7500 (89.7727)  Acc@5: 100.0000 (100.0000)  time: 0.2397  data: 0.0337  max mem: 2362
Test: [Task 1]  [20/63]  eta: 0:00:09  Loss: 0.5152 (0.5902)  Acc@1: 87.5000 (88.0952)  Acc@5: 100.0000 (99.4048)  time: 0.2061  data: 0.0004  max mem: 2362
Test: [Task 1]  [30/63]  eta: 0:00:07  Loss: 0.4825 (0.5591)  Acc@1: 87.5000 (88.5081)  Acc@5: 100.0000 (99.5968)  time: 0.2060  data: 0.0004  max mem: 2362
Test: [Task 1]  [40/63]  eta: 0:00:04  Loss: 0.4290 (0.5439)  Acc@1: 93.7500 (89.3293)  Acc@5: 100.0000 (99.6951)  time: 0.2061  data: 0.0004  max mem: 2362
Test: [Task 1]  [50/63]  eta: 0:00:02  Loss: 0.4338 (0.5245)  Acc@1: 93.7500 (90.1961)  Acc@5: 100.0000 (99.5098)  time: 0.2062  data: 0.0004  max mem: 2362
Test: [Task 1]  [60/63]  eta: 0:00:00  Loss: 0.3993 (0.5205)  Acc@1: 93.7500 (90.1639)  Acc@5: 100.0000 (99.5902)  time: 0.2059  data: 0.0003  max mem: 2362
Test: [Task 1]  [62/63]  eta: 0:00:00  Loss: 0.3943 (0.5163)  Acc@1: 93.7500 (90.3000)  Acc@5: 100.0000 (99.6000)  time: 0.2009  data: 0.0003  max mem: 2362
Test: [Task 1] Total time: 0:00:13 (0.2117 s / it)
* Acc@1 90.300 Acc@5 99.600 loss 0.516
Test: [Task 2]  [ 0/63]  eta: 0:00:38  Loss: 0.5836 (0.5836)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)  time: 0.6145  data: 0.4079  max mem: 2362
Test: [Task 2]  [10/63]  eta: 0:00:12  Loss: 0.5729 (0.5731)  Acc@1: 100.0000 (95.4545)  Acc@5: 100.0000 (98.8636)  time: 0.2432  data: 0.0374  max mem: 2362
Test: [Task 2]  [20/63]  eta: 0:00:09  Loss: 0.5831 (0.6832)  Acc@1: 93.7500 (91.9643)  Acc@5: 100.0000 (98.5119)  time: 0.2060  data: 0.0004  max mem: 2362
Test: [Task 2]  [30/63]  eta: 0:00:07  Loss: 0.6971 (0.6857)  Acc@1: 87.5000 (91.3306)  Acc@5: 100.0000 (97.9839)  time: 0.2063  data: 0.0004  max mem: 2362
Test: [Task 2]  [40/63]  eta: 0:00:04  Loss: 0.6809 (0.6718)  Acc@1: 93.7500 (91.6159)  Acc@5: 100.0000 (98.3232)  time: 0.2065  data: 0.0004  max mem: 2362
Test: [Task 2]  [50/63]  eta: 0:00:02  Loss: 0.5635 (0.6588)  Acc@1: 93.7500 (91.0539)  Acc@5: 100.0000 (98.5294)  time: 0.2062  data: 0.0003  max mem: 2362
Test: [Task 2]  [60/63]  eta: 0:00:00  Loss: 0.5085 (0.6373)  Acc@1: 93.7500 (92.0082)  Acc@5: 100.0000 (98.7705)  time: 0.2058  data: 0.0003  max mem: 2362
Test: [Task 2]  [62/63]  eta: 0:00:00  Loss: 0.4995 (0.6307)  Acc@1: 93.7500 (92.1000)  Acc@5: 100.0000 (98.8000)  time: 0.2009  data: 0.0003  max mem: 2362
Test: [Task 2] Total time: 0:00:13 (0.2125 s / it)
* Acc@1 92.100 Acc@5 98.800 loss 0.631
Test: [Task 3]  [ 0/63]  eta: 0:00:35  Loss: 0.2461 (0.2461)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)  time: 0.5702  data: 0.3614  max mem: 2362
Test: [Task 3]  [10/63]  eta: 0:00:12  Loss: 0.5425 (0.5484)  Acc@1: 93.7500 (89.2045)  Acc@5: 100.0000 (97.7273)  time: 0.2398  data: 0.0332  max mem: 2362
Test: [Task 3]  [20/63]  eta: 0:00:09  Loss: 0.5425 (0.5436)  Acc@1: 87.5000 (88.9881)  Acc@5: 100.0000 (97.9167)  time: 0.2067  data: 0.0004  max mem: 2362
Test: [Task 3]  [30/63]  eta: 0:00:07  Loss: 0.5320 (0.5306)  Acc@1: 87.5000 (89.5161)  Acc@5: 100.0000 (98.5887)  time: 0.2063  data: 0.0004  max mem: 2362
Test: [Task 3]  [40/63]  eta: 0:00:04  Loss: 0.5079 (0.5346)  Acc@1: 93.7500 (90.2439)  Acc@5: 100.0000 (98.7805)  time: 0.2060  data: 0.0004  max mem: 2362
Test: [Task 3]  [50/63]  eta: 0:00:02  Loss: 0.4494 (0.5307)  Acc@1: 93.7500 (90.8088)  Acc@5: 100.0000 (98.7745)  time: 0.2060  data: 0.0004  max mem: 2362
Test: [Task 3]  [60/63]  eta: 0:00:00  Loss: 0.4667 (0.5400)  Acc@1: 87.5000 (90.3689)  Acc@5: 100.0000 (98.9754)  time: 0.2057  data: 0.0003  max mem: 2362
Test: [Task 3]  [62/63]  eta: 0:00:00  Loss: 0.5652 (0.5463)  Acc@1: 87.5000 (90.1000)  Acc@5: 100.0000 (98.9000)  time: 0.2008  data: 0.0003  max mem: 2362
Test: [Task 3] Total time: 0:00:13 (0.2115 s / it)
* Acc@1 90.100 Acc@5 98.900 loss 0.546
{0: {0: 772, 1: 769, 2: 777, 3: 778, 4: 785, 5: 114, 6: 115, 7: 108, 8: 112, 9: 111, 10: 112, 11: 114, 12: 108, 13: 112, 14: 109, 15: 0, 16: 0, 17: 0, 18: 0, 19: 0, 20: 0, 21: 0, 22: 0, 23: 0, 24: 0, 25: 0, 26: 0, 27: 0, 28: 2, 29: 0, 30: 0, 31: 0, 32: 0, 33: 0, 34: 0, 35: 0, 36: 1, 37: 0, 38: 0, 39: 0, 40: 0, 41: 0, 42: 0, 43: 0, 44: 0, 45: 0, 46: 0, 47: 1, 48: 0, 49: 0}, 1: {0: 162, 1: 163, 2: 168, 3: 169, 4: 170, 5: 725, 6: 730, 7: 718, 8: 728, 9: 722, 10: 106, 11: 105, 12: 107, 13: 106, 14: 106, 15: 2, 16: 0, 17: 0, 18: 0, 19: 0, 20: 0, 21: 0, 22: 0, 23: 3, 24: 1, 25: 0, 26: 2, 27: 0, 28: 1, 29: 0, 30: 1, 31: 0, 32: 0, 33: 0, 34: 0, 35: 0, 36: 1, 37: 2, 38: 0, 39: 2, 40: 0, 41: 0, 42: 0, 43: 0, 44: 0, 45: 0, 46: 0, 47: 0, 48: 0, 49: 0}, 2: {0: 102, 1: 102, 2: 106, 3: 102, 4: 104, 5: 110, 6: 110, 7: 107, 8: 110, 9: 109, 10: 789, 11: 785, 12: 781, 13: 788, 14: 786, 15: 0, 16: 0, 17: 0, 18: 0, 19: 0, 20: 1, 21: 0, 22: 1, 23: 0, 24: 0, 25: 0, 26: 0, 27: 1, 28: 2, 29: 1, 30: 0, 31: 0, 32: 0, 33: 0, 34: 0, 35: 0, 36: 0, 37: 0, 38: 0, 39: 0, 40: 0, 41: 0, 42: 0, 43: 0, 44: 0, 45: 1, 46: 0, 47: 1, 48: 0, 49: 1}}
[Average accuracy till task3]	Acc@1: 90.8333	Acc@5: 99.1000	Loss: 0.5645	Forgetting: 3.9000	Backward: -3.9000
Train: Epoch[1/5]  [  0/313]  eta: 0:03:57  Lr: 0.001875  Loss: 1.1796  Acc@1: 25.0000 (25.0000)  Acc@5: 50.0000 (50.0000)  time: 0.7577  data: 0.4127  max mem: 2362
Train: Epoch[1/5]  [ 10/313]  eta: 0:01:52  Lr: 0.001875  Loss: 0.6502  Acc@1: 50.0000 (51.7045)  Acc@5: 81.2500 (77.8409)  time: 0.3699  data: 0.0380  max mem: 2362
Train: Epoch[1/5]  [ 20/313]  eta: 0:01:42  Lr: 0.001875  Loss: 0.4428  Acc@1: 68.7500 (62.5000)  Acc@5: 93.7500 (87.2024)  time: 0.3307  data: 0.0005  max mem: 2362
Train: Epoch[1/5]  [ 30/313]  eta: 0:01:37  Lr: 0.001875  Loss: 0.0913  Acc@1: 75.0000 (69.1532)  Acc@5: 100.0000 (90.3226)  time: 0.3306  data: 0.0004  max mem: 2362
Train: Epoch[1/5]  [ 40/313]  eta: 0:01:33  Lr: 0.001875  Loss: 0.1115  Acc@1: 81.2500 (72.7134)  Acc@5: 100.0000 (91.9207)  time: 0.3315  data: 0.0004  max mem: 2362
Train: Epoch[1/5]  [ 50/313]  eta: 0:01:29  Lr: 0.001875  Loss: -0.0262  Acc@1: 87.5000 (75.1225)  Acc@5: 100.0000 (93.1373)  time: 0.3312  data: 0.0005  max mem: 2362
Train: Epoch[1/5]  [ 60/313]  eta: 0:01:25  Lr: 0.001875  Loss: -0.3822  Acc@1: 87.5000 (77.1516)  Acc@5: 100.0000 (94.0574)  time: 0.3301  data: 0.0004  max mem: 2362
Train: Epoch[1/5]  [ 70/313]  eta: 0:01:21  Lr: 0.001875  Loss: -0.3854  Acc@1: 81.2500 (78.0810)  Acc@5: 100.0000 (94.2782)  time: 0.3309  data: 0.0004  max mem: 2362
Train: Epoch[1/5]  [ 80/313]  eta: 0:01:18  Lr: 0.001875  Loss: -0.5490  Acc@1: 87.5000 (79.6296)  Acc@5: 100.0000 (94.9074)  time: 0.3308  data: 0.0004  max mem: 2362
Train: Epoch[1/5]  [ 90/313]  eta: 0:01:14  Lr: 0.001875  Loss: -0.4501  Acc@1: 87.5000 (80.1511)  Acc@5: 100.0000 (95.3984)  time: 0.3299  data: 0.0004  max mem: 2362
Train: Epoch[1/5]  [100/313]  eta: 0:01:11  Lr: 0.001875  Loss: -0.5603  Acc@1: 87.5000 (80.5074)  Acc@5: 100.0000 (95.7302)  time: 0.3310  data: 0.0006  max mem: 2362
Train: Epoch[1/5]  [110/313]  eta: 0:01:07  Lr: 0.001875  Loss: -0.6146  Acc@1: 87.5000 (81.3626)  Acc@5: 100.0000 (96.0586)  time: 0.3315  data: 0.0006  max mem: 2362
Train: Epoch[1/5]  [120/313]  eta: 0:01:04  Lr: 0.001875  Loss: -0.7117  Acc@1: 93.7500 (81.9731)  Acc@5: 100.0000 (96.1260)  time: 0.3304  data: 0.0005  max mem: 2362
Train: Epoch[1/5]  [130/313]  eta: 0:01:01  Lr: 0.001875  Loss: -0.3258  Acc@1: 87.5000 (82.4427)  Acc@5: 100.0000 (96.2309)  time: 0.3304  data: 0.0009  max mem: 2362
Train: Epoch[1/5]  [140/313]  eta: 0:00:57  Lr: 0.001875  Loss: -0.2460  Acc@1: 87.5000 (82.7571)  Acc@5: 100.0000 (96.3209)  time: 0.3306  data: 0.0009  max mem: 2362
Train: Epoch[1/5]  [150/313]  eta: 0:00:54  Lr: 0.001875  Loss: -0.4220  Acc@1: 87.5000 (82.8228)  Acc@5: 100.0000 (96.4818)  time: 0.3307  data: 0.0004  max mem: 2362
Train: Epoch[1/5]  [160/313]  eta: 0:00:51  Lr: 0.001875  Loss: -0.8950  Acc@1: 87.5000 (82.9969)  Acc@5: 100.0000 (96.6615)  time: 0.3321  data: 0.0004  max mem: 2362
Train: Epoch[1/5]  [170/313]  eta: 0:00:47  Lr: 0.001875  Loss: -0.8118  Acc@1: 87.5000 (83.2602)  Acc@5: 100.0000 (96.8202)  time: 0.3332  data: 0.0005  max mem: 2362
Train: Epoch[1/5]  [180/313]  eta: 0:00:44  Lr: 0.001875  Loss: -0.7902  Acc@1: 87.5000 (83.7017)  Acc@5: 100.0000 (96.9268)  time: 0.3322  data: 0.0005  max mem: 2362
Train: Epoch[1/5]  [190/313]  eta: 0:00:41  Lr: 0.001875  Loss: -0.7925  Acc@1: 93.7500 (84.0969)  Acc@5: 100.0000 (97.0550)  time: 0.3318  data: 0.0011  max mem: 2362
Train: Epoch[1/5]  [200/313]  eta: 0:00:37  Lr: 0.001875  Loss: -0.9539  Acc@1: 87.5000 (84.1107)  Acc@5: 100.0000 (97.1082)  time: 0.3317  data: 0.0011  max mem: 2362
Train: Epoch[1/5]  [210/313]  eta: 0:00:34  Lr: 0.001875  Loss: -0.7262  Acc@1: 81.2500 (84.3009)  Acc@5: 100.0000 (97.1860)  time: 0.3309  data: 0.0005  max mem: 2362
Train: Epoch[1/5]  [220/313]  eta: 0:00:30  Lr: 0.001875  Loss: -0.9487  Acc@1: 93.7500 (84.6719)  Acc@5: 100.0000 (97.2851)  time: 0.3314  data: 0.0004  max mem: 2362
Train: Epoch[1/5]  [230/313]  eta: 0:00:27  Lr: 0.001875  Loss: -0.5197  Acc@1: 87.5000 (84.6591)  Acc@5: 100.0000 (97.3214)  time: 0.3314  data: 0.0004  max mem: 2362
Train: Epoch[1/5]  [240/313]  eta: 0:00:24  Lr: 0.001875  Loss: -0.4514  Acc@1: 87.5000 (84.6473)  Acc@5: 100.0000 (97.2770)  time: 0.3311  data: 0.0004  max mem: 2362
Train: Epoch[1/5]  [250/313]  eta: 0:00:20  Lr: 0.001875  Loss: -0.6470  Acc@1: 87.5000 (84.7859)  Acc@5: 100.0000 (97.3108)  time: 0.3319  data: 0.0004  max mem: 2362
Train: Epoch[1/5]  [260/313]  eta: 0:00:17  Lr: 0.001875  Loss: -0.7265  Acc@1: 87.5000 (84.7701)  Acc@5: 100.0000 (97.3180)  time: 0.3312  data: 0.0004  max mem: 2362
Train: Epoch[1/5]  [270/313]  eta: 0:00:14  Lr: 0.001875  Loss: -0.7000  Acc@1: 81.2500 (84.8017)  Acc@5: 100.0000 (97.3478)  time: 0.3305  data: 0.0009  max mem: 2362
Train: Epoch[1/5]  [280/313]  eta: 0:00:10  Lr: 0.001875  Loss: -0.8239  Acc@1: 81.2500 (84.7642)  Acc@5: 100.0000 (97.3532)  time: 0.3310  data: 0.0010  max mem: 2362
Train: Epoch[1/5]  [290/313]  eta: 0:00:07  Lr: 0.001875  Loss: -0.3556  Acc@1: 87.5000 (84.9442)  Acc@5: 100.0000 (97.4227)  time: 0.3305  data: 0.0005  max mem: 2362
Train: Epoch[1/5]  [300/313]  eta: 0:00:04  Lr: 0.001875  Loss: -0.7127  Acc@1: 87.5000 (84.9045)  Acc@5: 100.0000 (97.5083)  time: 0.3315  data: 0.0005  max mem: 2362
Train: Epoch[1/5]  [310/313]  eta: 0:00:00  Lr: 0.001875  Loss: -0.6650  Acc@1: 81.2500 (84.8071)  Acc@5: 100.0000 (97.5080)  time: 0.3317  data: 0.0004  max mem: 2362
Train: Epoch[1/5]  [312/313]  eta: 0:00:00  Lr: 0.001875  Loss: -0.8129  Acc@1: 87.5000 (84.8000)  Acc@5: 100.0000 (97.5200)  time: 0.3235  data: 0.0004  max mem: 2362
Train: Epoch[1/5] Total time: 0:01:44 (0.3324 s / it)
Averaged stats: Lr: 0.001875  Loss: -0.8129  Acc@1: 87.5000 (84.8000)  Acc@5: 100.0000 (97.5200)
Train: Epoch[2/5]  [  0/313]  eta: 0:03:25  Lr: 0.001875  Loss: -0.8755  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (100.0000)  time: 0.6578  data: 0.3263  max mem: 2362
Train: Epoch[2/5]  [ 10/313]  eta: 0:01:49  Lr: 0.001875  Loss: -0.7827  Acc@1: 93.7500 (92.0455)  Acc@5: 100.0000 (98.2955)  time: 0.3600  data: 0.0301  max mem: 2362
Train: Epoch[2/5]  [ 20/313]  eta: 0:01:41  Lr: 0.001875  Loss: -0.7330  Acc@1: 87.5000 (89.2857)  Acc@5: 100.0000 (98.2143)  time: 0.3300  data: 0.0005  max mem: 2362
Train: Epoch[2/5]  [ 30/313]  eta: 0:01:36  Lr: 0.001875  Loss: -0.9128  Acc@1: 87.5000 (88.3065)  Acc@5: 100.0000 (98.1855)  time: 0.3303  data: 0.0004  max mem: 2362
Train: Epoch[2/5]  [ 40/313]  eta: 0:01:32  Lr: 0.001875  Loss: -0.8933  Acc@1: 87.5000 (88.2622)  Acc@5: 100.0000 (98.3232)  time: 0.3306  data: 0.0004  max mem: 2362
Train: Epoch[2/5]  [ 50/313]  eta: 0:01:28  Lr: 0.001875  Loss: -0.9475  Acc@1: 87.5000 (88.3578)  Acc@5: 100.0000 (98.4069)  time: 0.3306  data: 0.0004  max mem: 2362
Train: Epoch[2/5]  [ 60/313]  eta: 0:01:25  Lr: 0.001875  Loss: -0.7080  Acc@1: 87.5000 (88.2172)  Acc@5: 100.0000 (98.3607)  time: 0.3317  data: 0.0009  max mem: 2362
Train: Epoch[2/5]  [ 70/313]  eta: 0:01:21  Lr: 0.001875  Loss: -0.8427  Acc@1: 87.5000 (88.0282)  Acc@5: 100.0000 (98.4155)  time: 0.3316  data: 0.0009  max mem: 2362
Train: Epoch[2/5]  [ 80/313]  eta: 0:01:17  Lr: 0.001875  Loss: -0.7742  Acc@1: 87.5000 (88.1944)  Acc@5: 100.0000 (98.3025)  time: 0.3305  data: 0.0004  max mem: 2362
Train: Epoch[2/5]  [ 90/313]  eta: 0:01:14  Lr: 0.001875  Loss: -0.5798  Acc@1: 87.5000 (87.9808)  Acc@5: 100.0000 (98.2830)  time: 0.3312  data: 0.0009  max mem: 2362
Train: Epoch[2/5]  [100/313]  eta: 0:01:11  Lr: 0.001875  Loss: -0.6725  Acc@1: 87.5000 (87.2525)  Acc@5: 100.0000 (98.2054)  time: 0.3309  data: 0.0010  max mem: 2362
Train: Epoch[2/5]  [110/313]  eta: 0:01:07  Lr: 0.001875  Loss: -0.8840  Acc@1: 81.2500 (87.3874)  Acc@5: 100.0000 (98.2545)  time: 0.3307  data: 0.0005  max mem: 2362
Train: Epoch[2/5]  [120/313]  eta: 0:01:04  Lr: 0.001875  Loss: -0.6021  Acc@1: 87.5000 (87.3967)  Acc@5: 100.0000 (98.2438)  time: 0.3310  data: 0.0004  max mem: 2362
Train: Epoch[2/5]  [130/313]  eta: 0:01:00  Lr: 0.001875  Loss: -0.8779  Acc@1: 87.5000 (87.3092)  Acc@5: 100.0000 (98.1870)  time: 0.3308  data: 0.0004  max mem: 2362
Train: Epoch[2/5]  [140/313]  eta: 0:00:57  Lr: 0.001875  Loss: -0.7335  Acc@1: 87.5000 (87.4557)  Acc@5: 100.0000 (98.2713)  time: 0.3304  data: 0.0004  max mem: 2362
Train: Epoch[2/5]  [150/313]  eta: 0:00:54  Lr: 0.001875  Loss: -0.5816  Acc@1: 87.5000 (87.2930)  Acc@5: 100.0000 (98.2616)  time: 0.3304  data: 0.0004  max mem: 2362
Train: Epoch[2/5]  [160/313]  eta: 0:00:50  Lr: 0.001875  Loss: -0.9609  Acc@1: 87.5000 (87.2671)  Acc@5: 100.0000 (98.3307)  time: 0.3308  data: 0.0004  max mem: 2362
Train: Epoch[2/5]  [170/313]  eta: 0:00:47  Lr: 0.001875  Loss: -0.9241  Acc@1: 87.5000 (87.2442)  Acc@5: 100.0000 (98.2822)  time: 0.3307  data: 0.0005  max mem: 2362
Train: Epoch[2/5]  [180/313]  eta: 0:00:44  Lr: 0.001875  Loss: -0.7922  Acc@1: 87.5000 (87.5691)  Acc@5: 100.0000 (98.3080)  time: 0.3310  data: 0.0005  max mem: 2362
Train: Epoch[2/5]  [190/313]  eta: 0:00:40  Lr: 0.001875  Loss: -0.9823  Acc@1: 93.7500 (87.7618)  Acc@5: 100.0000 (98.2330)  time: 0.3312  data: 0.0004  max mem: 2362
Train: Epoch[2/5]  [200/313]  eta: 0:00:37  Lr: 0.001875  Loss: -0.5622  Acc@1: 87.5000 (87.7799)  Acc@5: 100.0000 (98.2587)  time: 0.3303  data: 0.0004  max mem: 2362
Train: Epoch[2/5]  [210/313]  eta: 0:00:34  Lr: 0.001875  Loss: -0.7682  Acc@1: 87.5000 (87.8258)  Acc@5: 100.0000 (98.2227)  time: 0.3301  data: 0.0004  max mem: 2362
Train: Epoch[2/5]  [220/313]  eta: 0:00:30  Lr: 0.001875  Loss: -0.8649  Acc@1: 87.5000 (87.9242)  Acc@5: 100.0000 (98.2749)  time: 0.3316  data: 0.0004  max mem: 2362
Train: Epoch[2/5]  [230/313]  eta: 0:00:27  Lr: 0.001875  Loss: -0.5100  Acc@1: 87.5000 (88.0682)  Acc@5: 100.0000 (98.2955)  time: 0.3321  data: 0.0005  max mem: 2362
Train: Epoch[2/5]  [240/313]  eta: 0:00:24  Lr: 0.001875  Loss: -0.7100  Acc@1: 87.5000 (87.9927)  Acc@5: 100.0000 (98.2624)  time: 0.3311  data: 0.0004  max mem: 2362
Train: Epoch[2/5]  [250/313]  eta: 0:00:20  Lr: 0.001875  Loss: -0.8008  Acc@1: 87.5000 (87.9980)  Acc@5: 100.0000 (98.3068)  time: 0.3310  data: 0.0005  max mem: 2362
Train: Epoch[2/5]  [260/313]  eta: 0:00:17  Lr: 0.001875  Loss: -0.6970  Acc@1: 87.5000 (88.0268)  Acc@5: 100.0000 (98.2519)  time: 0.3315  data: 0.0006  max mem: 2362
Train: Epoch[2/5]  [270/313]  eta: 0:00:14  Lr: 0.001875  Loss: -0.8338  Acc@1: 87.5000 (88.0766)  Acc@5: 100.0000 (98.2242)  time: 0.3311  data: 0.0004  max mem: 2362
Train: Epoch[2/5]  [280/313]  eta: 0:00:10  Lr: 0.001875  Loss: -0.8012  Acc@1: 87.5000 (88.1450)  Acc@5: 100.0000 (98.2429)  time: 0.3317  data: 0.0011  max mem: 2362
Train: Epoch[2/5]  [290/313]  eta: 0:00:07  Lr: 0.001875  Loss: -0.8949  Acc@1: 87.5000 (88.1873)  Acc@5: 100.0000 (98.2388)  time: 0.3323  data: 0.0012  max mem: 2362
Train: Epoch[2/5]  [300/313]  eta: 0:00:04  Lr: 0.001875  Loss: -0.9442  Acc@1: 87.5000 (88.1852)  Acc@5: 100.0000 (98.2766)  time: 0.3314  data: 0.0004  max mem: 2362
Train: Epoch[2/5]  [310/313]  eta: 0:00:00  Lr: 0.001875  Loss: -0.6568  Acc@1: 87.5000 (88.1230)  Acc@5: 100.0000 (98.2918)  time: 0.3308  data: 0.0003  max mem: 2362
Train: Epoch[2/5]  [312/313]  eta: 0:00:00  Lr: 0.001875  Loss: -0.7096  Acc@1: 87.5000 (88.1000)  Acc@5: 100.0000 (98.3000)  time: 0.3227  data: 0.0003  max mem: 2362
Train: Epoch[2/5] Total time: 0:01:43 (0.3318 s / it)
Averaged stats: Lr: 0.001875  Loss: -0.7096  Acc@1: 87.5000 (88.1000)  Acc@5: 100.0000 (98.3000)
Train: Epoch[3/5]  [  0/313]  eta: 0:03:40  Lr: 0.001875  Loss: -0.9984  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)  time: 0.7042  data: 0.3695  max mem: 2362
Train: Epoch[3/5]  [ 10/313]  eta: 0:01:50  Lr: 0.001875  Loss: -1.1070  Acc@1: 87.5000 (90.9091)  Acc@5: 100.0000 (98.2955)  time: 0.3652  data: 0.0340  max mem: 2362
Train: Epoch[3/5]  [ 20/313]  eta: 0:01:42  Lr: 0.001875  Loss: -0.9662  Acc@1: 87.5000 (90.1786)  Acc@5: 100.0000 (98.8095)  time: 0.3313  data: 0.0004  max mem: 2362
Train: Epoch[3/5]  [ 30/313]  eta: 0:01:37  Lr: 0.001875  Loss: -0.6590  Acc@1: 87.5000 (88.5081)  Acc@5: 100.0000 (98.7903)  time: 0.3314  data: 0.0004  max mem: 2362
Train: Epoch[3/5]  [ 40/313]  eta: 0:01:33  Lr: 0.001875  Loss: -0.4106  Acc@1: 87.5000 (88.7195)  Acc@5: 100.0000 (98.4756)  time: 0.3319  data: 0.0004  max mem: 2362
Train: Epoch[3/5]  [ 50/313]  eta: 0:01:29  Lr: 0.001875  Loss: -1.0230  Acc@1: 93.7500 (89.2157)  Acc@5: 100.0000 (98.6520)  time: 0.3316  data: 0.0004  max mem: 2362
Train: Epoch[3/5]  [ 60/313]  eta: 0:01:25  Lr: 0.001875  Loss: -0.5184  Acc@1: 93.7500 (89.7541)  Acc@5: 100.0000 (98.7705)  time: 0.3315  data: 0.0005  max mem: 2362
Train: Epoch[3/5]  [ 70/313]  eta: 0:01:21  Lr: 0.001875  Loss: -0.9081  Acc@1: 93.7500 (89.8768)  Acc@5: 100.0000 (98.7676)  time: 0.3316  data: 0.0005  max mem: 2362
Train: Epoch[3/5]  [ 80/313]  eta: 0:01:18  Lr: 0.001875  Loss: -0.7352  Acc@1: 87.5000 (89.8920)  Acc@5: 100.0000 (98.9198)  time: 0.3318  data: 0.0005  max mem: 2362
Train: Epoch[3/5]  [ 90/313]  eta: 0:01:14  Lr: 0.001875  Loss: -1.0145  Acc@1: 87.5000 (89.3544)  Acc@5: 100.0000 (98.8324)  time: 0.3317  data: 0.0005  max mem: 2362
Train: Epoch[3/5]  [100/313]  eta: 0:01:11  Lr: 0.001875  Loss: -0.7200  Acc@1: 87.5000 (89.2946)  Acc@5: 100.0000 (98.5767)  time: 0.3312  data: 0.0004  max mem: 2362
Train: Epoch[3/5]  [110/313]  eta: 0:01:08  Lr: 0.001875  Loss: -0.8596  Acc@1: 87.5000 (89.2455)  Acc@5: 100.0000 (98.6486)  time: 0.3322  data: 0.0005  max mem: 2362
Train: Epoch[3/5]  [120/313]  eta: 0:01:04  Lr: 0.001875  Loss: -0.7960  Acc@1: 87.5000 (89.1529)  Acc@5: 100.0000 (98.7087)  time: 0.3321  data: 0.0005  max mem: 2362
Train: Epoch[3/5]  [130/313]  eta: 0:01:01  Lr: 0.001875  Loss: -0.8585  Acc@1: 87.5000 (89.0744)  Acc@5: 100.0000 (98.7118)  time: 0.3312  data: 0.0004  max mem: 2362
Train: Epoch[3/5]  [140/313]  eta: 0:00:57  Lr: 0.001875  Loss: -0.7855  Acc@1: 93.7500 (89.4060)  Acc@5: 100.0000 (98.7589)  time: 0.3311  data: 0.0005  max mem: 2362
Train: Epoch[3/5]  [150/313]  eta: 0:00:54  Lr: 0.001875  Loss: -0.7111  Acc@1: 93.7500 (89.3212)  Acc@5: 100.0000 (98.6341)  time: 0.3314  data: 0.0005  max mem: 2362
Train: Epoch[3/5]  [160/313]  eta: 0:00:51  Lr: 0.001875  Loss: -1.0396  Acc@1: 87.5000 (89.3634)  Acc@5: 100.0000 (98.6413)  time: 0.3314  data: 0.0004  max mem: 2362
Train: Epoch[3/5]  [170/313]  eta: 0:00:47  Lr: 0.001875  Loss: -0.9660  Acc@1: 87.5000 (89.2544)  Acc@5: 100.0000 (98.5380)  time: 0.3312  data: 0.0004  max mem: 2362
Train: Epoch[3/5]  [180/313]  eta: 0:00:44  Lr: 0.001875  Loss: -1.0553  Acc@1: 87.5000 (89.1920)  Acc@5: 100.0000 (98.5152)  time: 0.3313  data: 0.0004  max mem: 2362
Train: Epoch[3/5]  [190/313]  eta: 0:00:41  Lr: 0.001875  Loss: -0.7268  Acc@1: 87.5000 (89.2016)  Acc@5: 100.0000 (98.5275)  time: 0.3317  data: 0.0004  max mem: 2362
Train: Epoch[3/5]  [200/313]  eta: 0:00:37  Lr: 0.001875  Loss: -0.9327  Acc@1: 93.7500 (89.3035)  Acc@5: 100.0000 (98.5697)  time: 0.3316  data: 0.0005  max mem: 2362
Train: Epoch[3/5]  [210/313]  eta: 0:00:34  Lr: 0.001875  Loss: -0.5844  Acc@1: 87.5000 (89.2773)  Acc@5: 100.0000 (98.5190)  time: 0.3310  data: 0.0005  max mem: 2362
Train: Epoch[3/5]  [220/313]  eta: 0:00:30  Lr: 0.001875  Loss: -1.1488  Acc@1: 87.5000 (89.3100)  Acc@5: 100.0000 (98.5011)  time: 0.3309  data: 0.0004  max mem: 2362
Train: Epoch[3/5]  [230/313]  eta: 0:00:27  Lr: 0.001875  Loss: -0.8606  Acc@1: 93.7500 (89.3669)  Acc@5: 100.0000 (98.5119)  time: 0.3311  data: 0.0004  max mem: 2362
Train: Epoch[3/5]  [240/313]  eta: 0:00:24  Lr: 0.001875  Loss: -0.8633  Acc@1: 93.7500 (89.4710)  Acc@5: 100.0000 (98.5737)  time: 0.3311  data: 0.0005  max mem: 2362
Train: Epoch[3/5]  [250/313]  eta: 0:00:20  Lr: 0.001875  Loss: -0.7888  Acc@1: 87.5000 (89.3426)  Acc@5: 100.0000 (98.4811)  time: 0.3315  data: 0.0005  max mem: 2362
Train: Epoch[3/5]  [260/313]  eta: 0:00:17  Lr: 0.001875  Loss: -0.8999  Acc@1: 87.5000 (89.4636)  Acc@5: 100.0000 (98.4914)  time: 0.3315  data: 0.0004  max mem: 2362
Train: Epoch[3/5]  [270/313]  eta: 0:00:14  Lr: 0.001875  Loss: -0.9467  Acc@1: 87.5000 (89.4603)  Acc@5: 100.0000 (98.5009)  time: 0.3310  data: 0.0005  max mem: 2362
Train: Epoch[3/5]  [280/313]  eta: 0:00:10  Lr: 0.001875  Loss: -0.9202  Acc@1: 87.5000 (89.3906)  Acc@5: 100.0000 (98.4653)  time: 0.3315  data: 0.0005  max mem: 2362
Train: Epoch[3/5]  [290/313]  eta: 0:00:07  Lr: 0.001875  Loss: -0.2174  Acc@1: 87.5000 (89.3686)  Acc@5: 100.0000 (98.5180)  time: 0.3316  data: 0.0005  max mem: 2362
Train: Epoch[3/5]  [300/313]  eta: 0:00:04  Lr: 0.001875  Loss: -0.8682  Acc@1: 87.5000 (89.2027)  Acc@5: 100.0000 (98.4842)  time: 0.3323  data: 0.0005  max mem: 2362
Train: Epoch[3/5]  [310/313]  eta: 0:00:00  Lr: 0.001875  Loss: -0.2068  Acc@1: 87.5000 (89.2082)  Acc@5: 100.0000 (98.4727)  time: 0.3321  data: 0.0004  max mem: 2362
Train: Epoch[3/5]  [312/313]  eta: 0:00:00  Lr: 0.001875  Loss: -0.9077  Acc@1: 87.5000 (89.2200)  Acc@5: 100.0000 (98.4800)  time: 0.3240  data: 0.0004  max mem: 2362
Train: Epoch[3/5] Total time: 0:01:44 (0.3325 s / it)
Averaged stats: Lr: 0.001875  Loss: -0.9077  Acc@1: 87.5000 (89.2200)  Acc@5: 100.0000 (98.4800)
Train: Epoch[4/5]  [  0/313]  eta: 0:03:41  Lr: 0.001875  Loss: -0.6492  Acc@1: 81.2500 (81.2500)  Acc@5: 100.0000 (100.0000)  time: 0.7082  data: 0.3764  max mem: 2362
Train: Epoch[4/5]  [ 10/313]  eta: 0:01:50  Lr: 0.001875  Loss: -0.8529  Acc@1: 87.5000 (90.3409)  Acc@5: 100.0000 (98.2955)  time: 0.3652  data: 0.0346  max mem: 2362
Train: Epoch[4/5]  [ 20/313]  eta: 0:01:42  Lr: 0.001875  Loss: -0.8598  Acc@1: 87.5000 (90.7738)  Acc@5: 100.0000 (98.2143)  time: 0.3307  data: 0.0005  max mem: 2362
Train: Epoch[4/5]  [ 30/313]  eta: 0:01:37  Lr: 0.001875  Loss: -0.8426  Acc@1: 87.5000 (88.9113)  Acc@5: 100.0000 (98.3871)  time: 0.3308  data: 0.0005  max mem: 2362
Train: Epoch[4/5]  [ 40/313]  eta: 0:01:32  Lr: 0.001875  Loss: -0.8478  Acc@1: 87.5000 (89.1768)  Acc@5: 100.0000 (98.1707)  time: 0.3310  data: 0.0004  max mem: 2362
Train: Epoch[4/5]  [ 50/313]  eta: 0:01:28  Lr: 0.001875  Loss: -1.1117  Acc@1: 87.5000 (89.8284)  Acc@5: 100.0000 (98.2843)  time: 0.3310  data: 0.0004  max mem: 2362
Train: Epoch[4/5]  [ 60/313]  eta: 0:01:25  Lr: 0.001875  Loss: -0.9376  Acc@1: 93.7500 (89.7541)  Acc@5: 100.0000 (98.4631)  time: 0.3317  data: 0.0004  max mem: 2362
Train: Epoch[4/5]  [ 70/313]  eta: 0:01:21  Lr: 0.001875  Loss: -0.8026  Acc@1: 87.5000 (89.4366)  Acc@5: 100.0000 (98.5035)  time: 0.3321  data: 0.0004  max mem: 2362
Train: Epoch[4/5]  [ 80/313]  eta: 0:01:18  Lr: 0.001875  Loss: -0.5658  Acc@1: 87.5000 (89.2747)  Acc@5: 100.0000 (98.5340)  time: 0.3323  data: 0.0005  max mem: 2362
Train: Epoch[4/5]  [ 90/313]  eta: 0:01:14  Lr: 0.001875  Loss: -0.9480  Acc@1: 87.5000 (89.1484)  Acc@5: 100.0000 (98.6264)  time: 0.3325  data: 0.0005  max mem: 2362
Train: Epoch[4/5]  [100/313]  eta: 0:01:11  Lr: 0.001875  Loss: -1.0809  Acc@1: 87.5000 (89.1089)  Acc@5: 100.0000 (98.5767)  time: 0.3330  data: 0.0020  max mem: 2362
Train: Epoch[4/5]  [110/313]  eta: 0:01:08  Lr: 0.001875  Loss: -0.3804  Acc@1: 87.5000 (88.7950)  Acc@5: 100.0000 (98.4797)  time: 0.3334  data: 0.0020  max mem: 2362
Train: Epoch[4/5]  [120/313]  eta: 0:01:04  Lr: 0.001875  Loss: -0.8623  Acc@1: 87.5000 (88.6880)  Acc@5: 100.0000 (98.3988)  time: 0.3316  data: 0.0005  max mem: 2362
Train: Epoch[4/5]  [130/313]  eta: 0:01:01  Lr: 0.001875  Loss: -1.1141  Acc@1: 87.5000 (88.9790)  Acc@5: 100.0000 (98.5210)  time: 0.3303  data: 0.0004  max mem: 2362
Train: Epoch[4/5]  [140/313]  eta: 0:00:57  Lr: 0.001875  Loss: -1.0961  Acc@1: 93.7500 (89.0957)  Acc@5: 100.0000 (98.4929)  time: 0.3305  data: 0.0004  max mem: 2362
Train: Epoch[4/5]  [150/313]  eta: 0:00:54  Lr: 0.001875  Loss: -0.9159  Acc@1: 87.5000 (89.2384)  Acc@5: 100.0000 (98.4685)  time: 0.3311  data: 0.0012  max mem: 2362
Train: Epoch[4/5]  [160/313]  eta: 0:00:51  Lr: 0.001875  Loss: -0.9444  Acc@1: 93.7500 (89.3634)  Acc@5: 100.0000 (98.4472)  time: 0.3312  data: 0.0011  max mem: 2362
Train: Epoch[4/5]  [170/313]  eta: 0:00:47  Lr: 0.001875  Loss: -0.9379  Acc@1: 93.7500 (89.2178)  Acc@5: 100.0000 (98.4649)  time: 0.3307  data: 0.0004  max mem: 2362
Train: Epoch[4/5]  [180/313]  eta: 0:00:44  Lr: 0.001875  Loss: -0.6125  Acc@1: 87.5000 (89.0884)  Acc@5: 100.0000 (98.3425)  time: 0.3310  data: 0.0005  max mem: 2362
Train: Epoch[4/5]  [190/313]  eta: 0:00:41  Lr: 0.001875  Loss: -0.7045  Acc@1: 87.5000 (89.2016)  Acc@5: 100.0000 (98.3639)  time: 0.3316  data: 0.0004  max mem: 2362
Train: Epoch[4/5]  [200/313]  eta: 0:00:37  Lr: 0.001875  Loss: -0.9058  Acc@1: 87.5000 (89.2102)  Acc@5: 100.0000 (98.3831)  time: 0.3311  data: 0.0004  max mem: 2362
Train: Epoch[4/5]  [210/313]  eta: 0:00:34  Lr: 0.001875  Loss: -0.6672  Acc@1: 93.7500 (89.2773)  Acc@5: 100.0000 (98.4005)  time: 0.3305  data: 0.0004  max mem: 2362
Train: Epoch[4/5]  [220/313]  eta: 0:00:30  Lr: 0.001875  Loss: -0.7993  Acc@1: 93.7500 (89.4796)  Acc@5: 100.0000 (98.4446)  time: 0.3308  data: 0.0004  max mem: 2362
Train: Epoch[4/5]  [230/313]  eta: 0:00:27  Lr: 0.001875  Loss: -1.0609  Acc@1: 93.7500 (89.5563)  Acc@5: 100.0000 (98.4307)  time: 0.3311  data: 0.0004  max mem: 2362
Train: Epoch[4/5]  [240/313]  eta: 0:00:24  Lr: 0.001875  Loss: -1.1465  Acc@1: 93.7500 (89.8081)  Acc@5: 100.0000 (98.4959)  time: 0.3305  data: 0.0004  max mem: 2362
Train: Epoch[4/5]  [250/313]  eta: 0:00:20  Lr: 0.001875  Loss: -0.7539  Acc@1: 93.7500 (89.8406)  Acc@5: 100.0000 (98.5309)  time: 0.3303  data: 0.0004  max mem: 2362
Train: Epoch[4/5]  [260/313]  eta: 0:00:17  Lr: 0.001875  Loss: -0.9653  Acc@1: 87.5000 (89.7989)  Acc@5: 100.0000 (98.5632)  time: 0.3306  data: 0.0004  max mem: 2362
Train: Epoch[4/5]  [270/313]  eta: 0:00:14  Lr: 0.001875  Loss: -0.8325  Acc@1: 93.7500 (89.8293)  Acc@5: 100.0000 (98.5932)  time: 0.3320  data: 0.0004  max mem: 2362
Train: Epoch[4/5]  [280/313]  eta: 0:00:10  Lr: 0.001875  Loss: -0.8103  Acc@1: 87.5000 (89.6130)  Acc@5: 100.0000 (98.5543)  time: 0.3322  data: 0.0004  max mem: 2362
Train: Epoch[4/5]  [290/313]  eta: 0:00:07  Lr: 0.001875  Loss: -0.4910  Acc@1: 87.5000 (89.6692)  Acc@5: 100.0000 (98.6040)  time: 0.3310  data: 0.0004  max mem: 2362
Train: Epoch[4/5]  [300/313]  eta: 0:00:04  Lr: 0.001875  Loss: -0.8586  Acc@1: 93.7500 (89.6179)  Acc@5: 100.0000 (98.6088)  time: 0.3308  data: 0.0004  max mem: 2362
Train: Epoch[4/5]  [310/313]  eta: 0:00:00  Lr: 0.001875  Loss: -0.9350  Acc@1: 87.5000 (89.6704)  Acc@5: 100.0000 (98.6133)  time: 0.3308  data: 0.0003  max mem: 2362
Train: Epoch[4/5]  [312/313]  eta: 0:00:00  Lr: 0.001875  Loss: -1.0546  Acc@1: 93.7500 (89.7200)  Acc@5: 100.0000 (98.6200)  time: 0.3225  data: 0.0003  max mem: 2362
Train: Epoch[4/5] Total time: 0:01:44 (0.3323 s / it)
Averaged stats: Lr: 0.001875  Loss: -1.0546  Acc@1: 93.7500 (89.7200)  Acc@5: 100.0000 (98.6200)
Train: Epoch[5/5]  [  0/313]  eta: 0:03:34  Lr: 0.001875  Loss: -0.9568  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (100.0000)  time: 0.6867  data: 0.3552  max mem: 2362
Train: Epoch[5/5]  [ 10/313]  eta: 0:01:49  Lr: 0.001875  Loss: -0.6046  Acc@1: 93.7500 (91.4773)  Acc@5: 100.0000 (98.8636)  time: 0.3630  data: 0.0327  max mem: 2362
Train: Epoch[5/5]  [ 20/313]  eta: 0:01:41  Lr: 0.001875  Loss: -0.6083  Acc@1: 87.5000 (88.9881)  Acc@5: 100.0000 (98.8095)  time: 0.3311  data: 0.0005  max mem: 2362
Train: Epoch[5/5]  [ 30/313]  eta: 0:01:36  Lr: 0.001875  Loss: -1.0733  Acc@1: 87.5000 (89.9194)  Acc@5: 100.0000 (98.7903)  time: 0.3311  data: 0.0004  max mem: 2362
Train: Epoch[5/5]  [ 40/313]  eta: 0:01:32  Lr: 0.001875  Loss: -0.8266  Acc@1: 93.7500 (90.5488)  Acc@5: 100.0000 (98.6280)  time: 0.3303  data: 0.0004  max mem: 2362
Train: Epoch[5/5]  [ 50/313]  eta: 0:01:28  Lr: 0.001875  Loss: -0.9138  Acc@1: 87.5000 (90.1961)  Acc@5: 100.0000 (98.4069)  time: 0.3307  data: 0.0009  max mem: 2362
Train: Epoch[5/5]  [ 60/313]  eta: 0:01:25  Lr: 0.001875  Loss: -0.7953  Acc@1: 87.5000 (89.7541)  Acc@5: 100.0000 (98.3607)  time: 0.3315  data: 0.0015  max mem: 2362
Train: Epoch[5/5]  [ 70/313]  eta: 0:01:21  Lr: 0.001875  Loss: -0.9291  Acc@1: 87.5000 (89.3486)  Acc@5: 100.0000 (98.3275)  time: 0.3315  data: 0.0011  max mem: 2362
Train: Epoch[5/5]  [ 80/313]  eta: 0:01:18  Lr: 0.001875  Loss: -0.9792  Acc@1: 87.5000 (89.5062)  Acc@5: 100.0000 (98.3796)  time: 0.3310  data: 0.0004  max mem: 2362
Train: Epoch[5/5]  [ 90/313]  eta: 0:01:14  Lr: 0.001875  Loss: -0.5922  Acc@1: 93.7500 (89.6291)  Acc@5: 100.0000 (98.4203)  time: 0.3304  data: 0.0004  max mem: 2362
Train: Epoch[5/5]  [100/313]  eta: 0:01:11  Lr: 0.001875  Loss: -0.9151  Acc@1: 87.5000 (89.4183)  Acc@5: 100.0000 (98.5149)  time: 0.3305  data: 0.0004  max mem: 2362
Train: Epoch[5/5]  [110/313]  eta: 0:01:07  Lr: 0.001875  Loss: -0.9672  Acc@1: 87.5000 (89.5270)  Acc@5: 100.0000 (98.5360)  time: 0.3305  data: 0.0004  max mem: 2362
Train: Epoch[5/5]  [120/313]  eta: 0:01:04  Lr: 0.001875  Loss: -0.9574  Acc@1: 87.5000 (89.4628)  Acc@5: 100.0000 (98.5537)  time: 0.3310  data: 0.0004  max mem: 2362
Train: Epoch[5/5]  [130/313]  eta: 0:01:01  Lr: 0.001875  Loss: -0.6722  Acc@1: 87.5000 (89.1698)  Acc@5: 100.0000 (98.4733)  time: 0.3313  data: 0.0004  max mem: 2362
Train: Epoch[5/5]  [140/313]  eta: 0:00:57  Lr: 0.001875  Loss: -0.5987  Acc@1: 87.5000 (89.0957)  Acc@5: 100.0000 (98.4929)  time: 0.3312  data: 0.0006  max mem: 2362
Train: Epoch[5/5]  [150/313]  eta: 0:00:54  Lr: 0.001875  Loss: -0.4824  Acc@1: 87.5000 (88.8659)  Acc@5: 100.0000 (98.4685)  time: 0.3313  data: 0.0006  max mem: 2362
Train: Epoch[5/5]  [160/313]  eta: 0:00:50  Lr: 0.001875  Loss: -0.6939  Acc@1: 87.5000 (88.9363)  Acc@5: 100.0000 (98.5637)  time: 0.3312  data: 0.0005  max mem: 2362
Train: Epoch[5/5]  [170/313]  eta: 0:00:47  Lr: 0.001875  Loss: -1.0914  Acc@1: 87.5000 (88.7061)  Acc@5: 100.0000 (98.5380)  time: 0.3314  data: 0.0009  max mem: 2362
Train: Epoch[5/5]  [180/313]  eta: 0:00:44  Lr: 0.001875  Loss: -1.0000  Acc@1: 87.5000 (88.7431)  Acc@5: 100.0000 (98.5497)  time: 0.3314  data: 0.0008  max mem: 2362
Train: Epoch[5/5]  [190/313]  eta: 0:00:40  Lr: 0.001875  Loss: -0.7747  Acc@1: 93.7500 (88.9071)  Acc@5: 100.0000 (98.5929)  time: 0.3314  data: 0.0004  max mem: 2362
Train: Epoch[5/5]  [200/313]  eta: 0:00:37  Lr: 0.001875  Loss: -1.0880  Acc@1: 93.7500 (88.9925)  Acc@5: 100.0000 (98.6007)  time: 0.3310  data: 0.0005  max mem: 2362
Train: Epoch[5/5]  [210/313]  eta: 0:00:34  Lr: 0.001875  Loss: -0.9392  Acc@1: 87.5000 (89.0107)  Acc@5: 100.0000 (98.6374)  time: 0.3303  data: 0.0004  max mem: 2362
Train: Epoch[5/5]  [220/313]  eta: 0:00:30  Lr: 0.001875  Loss: -0.7605  Acc@1: 87.5000 (89.1686)  Acc@5: 100.0000 (98.6425)  time: 0.3312  data: 0.0004  max mem: 2362
Train: Epoch[5/5]  [230/313]  eta: 0:00:27  Lr: 0.001875  Loss: -0.8064  Acc@1: 87.5000 (89.0422)  Acc@5: 100.0000 (98.6742)  time: 0.3319  data: 0.0005  max mem: 2362
Train: Epoch[5/5]  [240/313]  eta: 0:00:24  Lr: 0.001875  Loss: -0.8381  Acc@1: 87.5000 (89.1079)  Acc@5: 100.0000 (98.6774)  time: 0.3314  data: 0.0004  max mem: 2362
Train: Epoch[5/5]  [250/313]  eta: 0:00:20  Lr: 0.001875  Loss: -0.9712  Acc@1: 93.7500 (89.2181)  Acc@5: 100.0000 (98.7052)  time: 0.3318  data: 0.0005  max mem: 2362
Train: Epoch[5/5]  [260/313]  eta: 0:00:17  Lr: 0.001875  Loss: -0.8375  Acc@1: 93.7500 (89.3678)  Acc@5: 100.0000 (98.7308)  time: 0.3314  data: 0.0005  max mem: 2362
Train: Epoch[5/5]  [270/313]  eta: 0:00:14  Lr: 0.001875  Loss: -1.1884  Acc@1: 87.5000 (89.2989)  Acc@5: 100.0000 (98.7315)  time: 0.3311  data: 0.0007  max mem: 2362
Train: Epoch[5/5]  [280/313]  eta: 0:00:10  Lr: 0.001875  Loss: -0.9471  Acc@1: 87.5000 (89.2794)  Acc@5: 100.0000 (98.7322)  time: 0.3312  data: 0.0007  max mem: 2362
Train: Epoch[5/5]  [290/313]  eta: 0:00:07  Lr: 0.001875  Loss: -0.8425  Acc@1: 87.5000 (89.3041)  Acc@5: 100.0000 (98.7543)  time: 0.3308  data: 0.0005  max mem: 2362
Train: Epoch[5/5]  [300/313]  eta: 0:00:04  Lr: 0.001875  Loss: -1.0067  Acc@1: 93.7500 (89.4726)  Acc@5: 100.0000 (98.7542)  time: 0.3312  data: 0.0004  max mem: 2362
Train: Epoch[5/5]  [310/313]  eta: 0:00:00  Lr: 0.001875  Loss: -0.8745  Acc@1: 93.7500 (89.5297)  Acc@5: 100.0000 (98.7741)  time: 0.3313  data: 0.0004  max mem: 2362
Train: Epoch[5/5]  [312/313]  eta: 0:00:00  Lr: 0.001875  Loss: -0.7994  Acc@1: 93.7500 (89.5400)  Acc@5: 100.0000 (98.7800)  time: 0.3231  data: 0.0004  max mem: 2362
Train: Epoch[5/5] Total time: 0:01:43 (0.3321 s / it)
Averaged stats: Lr: 0.001875  Loss: -0.7994  Acc@1: 93.7500 (89.5400)  Acc@5: 100.0000 (98.7800)
Test: [Task 1]  [ 0/63]  eta: 0:00:31  Loss: 0.5703 (0.5703)  Acc@1: 81.2500 (81.2500)  Acc@5: 100.0000 (100.0000)  time: 0.4974  data: 0.2887  max mem: 2362
Test: [Task 1]  [10/63]  eta: 0:00:12  Loss: 0.5521 (0.5567)  Acc@1: 93.7500 (87.5000)  Acc@5: 100.0000 (99.4318)  time: 0.2323  data: 0.0266  max mem: 2362
Test: [Task 1]  [20/63]  eta: 0:00:09  Loss: 0.5517 (0.6084)  Acc@1: 87.5000 (85.4167)  Acc@5: 100.0000 (98.5119)  time: 0.2059  data: 0.0004  max mem: 2362
Test: [Task 1]  [30/63]  eta: 0:00:07  Loss: 0.5195 (0.5811)  Acc@1: 87.5000 (86.2903)  Acc@5: 100.0000 (98.5887)  time: 0.2059  data: 0.0004  max mem: 2362
Test: [Task 1]  [40/63]  eta: 0:00:04  Loss: 0.4477 (0.5635)  Acc@1: 93.7500 (87.6524)  Acc@5: 100.0000 (98.9329)  time: 0.2056  data: 0.0004  max mem: 2362
Test: [Task 1]  [50/63]  eta: 0:00:02  Loss: 0.4401 (0.5394)  Acc@1: 93.7500 (88.6029)  Acc@5: 100.0000 (98.8971)  time: 0.2054  data: 0.0003  max mem: 2362
Test: [Task 1]  [60/63]  eta: 0:00:00  Loss: 0.4401 (0.5338)  Acc@1: 93.7500 (88.8320)  Acc@5: 100.0000 (98.9754)  time: 0.2057  data: 0.0003  max mem: 2362
Test: [Task 1]  [62/63]  eta: 0:00:00  Loss: 0.4078 (0.5301)  Acc@1: 93.7500 (89.0000)  Acc@5: 100.0000 (99.0000)  time: 0.2009  data: 0.0003  max mem: 2362
Test: [Task 1] Total time: 0:00:13 (0.2103 s / it)
* Acc@1 89.000 Acc@5 99.000 loss 0.530
Test: [Task 2]  [ 0/63]  eta: 0:00:35  Loss: 0.7155 (0.7155)  Acc@1: 93.7500 (93.7500)  Acc@5: 100.0000 (100.0000)  time: 0.5558  data: 0.3494  max mem: 2362
Test: [Task 2]  [10/63]  eta: 0:00:12  Loss: 0.6425 (0.6588)  Acc@1: 93.7500 (90.9091)  Acc@5: 100.0000 (98.8636)  time: 0.2377  data: 0.0321  max mem: 2362
Test: [Task 2]  [20/63]  eta: 0:00:09  Loss: 0.6536 (0.7518)  Acc@1: 87.5000 (87.7976)  Acc@5: 100.0000 (98.2143)  time: 0.2060  data: 0.0004  max mem: 2362
Test: [Task 2]  [30/63]  eta: 0:00:07  Loss: 0.7038 (0.7436)  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (97.5806)  time: 0.2060  data: 0.0004  max mem: 2362
Test: [Task 2]  [40/63]  eta: 0:00:04  Loss: 0.6902 (0.7207)  Acc@1: 87.5000 (88.1098)  Acc@5: 100.0000 (97.8659)  time: 0.2059  data: 0.0004  max mem: 2362
Test: [Task 2]  [50/63]  eta: 0:00:02  Loss: 0.6161 (0.7132)  Acc@1: 87.5000 (87.2549)  Acc@5: 100.0000 (98.0392)  time: 0.2057  data: 0.0004  max mem: 2362
Test: [Task 2]  [60/63]  eta: 0:00:00  Loss: 0.6038 (0.6880)  Acc@1: 87.5000 (88.3197)  Acc@5: 100.0000 (98.2582)  time: 0.2057  data: 0.0003  max mem: 2362
Test: [Task 2]  [62/63]  eta: 0:00:00  Loss: 0.5994 (0.6807)  Acc@1: 87.5000 (88.4000)  Acc@5: 100.0000 (98.3000)  time: 0.2009  data: 0.0003  max mem: 2362
Test: [Task 2] Total time: 0:00:13 (0.2113 s / it)
* Acc@1 88.400 Acc@5 98.300 loss 0.681
Test: [Task 3]  [ 0/63]  eta: 0:00:33  Loss: 0.2497 (0.2497)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)  time: 0.5331  data: 0.3267  max mem: 2362
Test: [Task 3]  [10/63]  eta: 0:00:12  Loss: 0.5203 (0.5237)  Acc@1: 93.7500 (88.6364)  Acc@5: 100.0000 (98.8636)  time: 0.2357  data: 0.0300  max mem: 2362
Test: [Task 3]  [20/63]  eta: 0:00:09  Loss: 0.5534 (0.5261)  Acc@1: 87.5000 (88.3929)  Acc@5: 100.0000 (98.5119)  time: 0.2060  data: 0.0004  max mem: 2362
Test: [Task 3]  [30/63]  eta: 0:00:07  Loss: 0.4357 (0.5028)  Acc@1: 87.5000 (88.9113)  Acc@5: 100.0000 (98.7903)  time: 0.2058  data: 0.0004  max mem: 2362
Test: [Task 3]  [40/63]  eta: 0:00:04  Loss: 0.4231 (0.5090)  Acc@1: 93.7500 (89.7866)  Acc@5: 100.0000 (98.9329)  time: 0.2058  data: 0.0003  max mem: 2362
Test: [Task 3]  [50/63]  eta: 0:00:02  Loss: 0.4377 (0.5112)  Acc@1: 93.7500 (90.1961)  Acc@5: 100.0000 (98.6520)  time: 0.2064  data: 0.0003  max mem: 2362
Test: [Task 3]  [60/63]  eta: 0:00:00  Loss: 0.5171 (0.5157)  Acc@1: 87.5000 (90.0615)  Acc@5: 100.0000 (98.7705)  time: 0.2065  data: 0.0003  max mem: 2362
Test: [Task 3]  [62/63]  eta: 0:00:00  Loss: 0.5339 (0.5169)  Acc@1: 87.5000 (89.8000)  Acc@5: 100.0000 (98.8000)  time: 0.2015  data: 0.0003  max mem: 2362
Test: [Task 3] Total time: 0:00:13 (0.2108 s / it)
* Acc@1 89.800 Acc@5 98.800 loss 0.517
Test: [Task 4]  [ 0/63]  eta: 0:00:36  Loss: 0.8512 (0.8512)  Acc@1: 81.2500 (81.2500)  Acc@5: 93.7500 (93.7500)  time: 0.5806  data: 0.3722  max mem: 2362
Test: [Task 4]  [10/63]  eta: 0:00:12  Loss: 0.6429 (0.6619)  Acc@1: 87.5000 (86.3636)  Acc@5: 100.0000 (97.7273)  time: 0.2397  data: 0.0341  max mem: 2362
Test: [Task 4]  [20/63]  eta: 0:00:09  Loss: 0.5886 (0.6288)  Acc@1: 87.5000 (86.9048)  Acc@5: 100.0000 (97.6190)  time: 0.2057  data: 0.0004  max mem: 2362
Test: [Task 4]  [30/63]  eta: 0:00:07  Loss: 0.5062 (0.5959)  Acc@1: 87.5000 (88.1048)  Acc@5: 100.0000 (97.9839)  time: 0.2059  data: 0.0004  max mem: 2362
Test: [Task 4]  [40/63]  eta: 0:00:04  Loss: 0.3496 (0.5434)  Acc@1: 93.7500 (89.3293)  Acc@5: 100.0000 (98.3232)  time: 0.2062  data: 0.0004  max mem: 2362
Test: [Task 4]  [50/63]  eta: 0:00:02  Loss: 0.3784 (0.5472)  Acc@1: 93.7500 (89.4608)  Acc@5: 100.0000 (98.4069)  time: 0.2061  data: 0.0004  max mem: 2362
Test: [Task 4]  [60/63]  eta: 0:00:00  Loss: 0.5479 (0.5619)  Acc@1: 93.7500 (88.8320)  Acc@5: 100.0000 (98.0533)  time: 0.2061  data: 0.0004  max mem: 2362
Test: [Task 4]  [62/63]  eta: 0:00:00  Loss: 0.5152 (0.5548)  Acc@1: 93.7500 (89.1000)  Acc@5: 100.0000 (98.1000)  time: 0.2011  data: 0.0004  max mem: 2362
Test: [Task 4] Total time: 0:00:13 (0.2120 s / it)
* Acc@1 89.100 Acc@5 98.100 loss 0.555
{0: {0: 638, 1: 641, 2: 643, 3: 641, 4: 647, 5: 63, 6: 63, 7: 60, 8: 63, 9: 61, 10: 72, 11: 72, 12: 72, 13: 72, 14: 72, 15: 223, 16: 219, 17: 227, 18: 222, 19: 225, 20: 0, 21: 0, 22: 0, 23: 0, 24: 0, 25: 0, 26: 0, 27: 0, 28: 2, 29: 0, 30: 0, 31: 0, 32: 0, 33: 0, 34: 0, 35: 0, 36: 1, 37: 0, 38: 0, 39: 0, 40: 0, 41: 0, 42: 0, 43: 0, 44: 0, 45: 0, 46: 0, 47: 1, 48: 0, 49: 0}, 1: {0: 127, 1: 128, 2: 130, 3: 128, 4: 130, 5: 560, 6: 562, 7: 557, 8: 562, 9: 559, 10: 90, 11: 88, 12: 91, 13: 89, 14: 90, 15: 219, 16: 217, 17: 221, 18: 219, 19: 221, 20: 0, 21: 0, 22: 0, 23: 3, 24: 1, 25: 0, 26: 2, 27: 0, 28: 1, 29: 0, 30: 1, 31: 0, 32: 0, 33: 0, 34: 0, 35: 0, 36: 1, 37: 2, 38: 0, 39: 1, 40: 0, 41: 0, 42: 0, 43: 0, 44: 0, 45: 0, 46: 0, 47: 0, 48: 0, 49: 0}, 2: {0: 66, 1: 67, 2: 67, 3: 67, 4: 65, 5: 55, 6: 54, 7: 54, 8: 55, 9: 54, 10: 672, 11: 672, 12: 668, 13: 671, 14: 672, 15: 207, 16: 204, 17: 207, 18: 207, 19: 207, 20: 1, 21: 0, 22: 1, 23: 0, 24: 0, 25: 0, 26: 0, 27: 1, 28: 2, 29: 1, 30: 0, 31: 0, 32: 0, 33: 0, 34: 0, 35: 0, 36: 0, 37: 0, 38: 0, 39: 0, 40: 0, 41: 0, 42: 0, 43: 0, 44: 0, 45: 1, 46: 0, 47: 1, 48: 0, 49: 1}, 3: {0: 38, 1: 37, 2: 40, 3: 39, 4: 40, 5: 101, 6: 103, 7: 102, 8: 102, 9: 101, 10: 50, 11: 49, 12: 49, 13: 49, 14: 49, 15: 808, 16: 802, 17: 810, 18: 806, 19: 810, 20: 0, 21: 2, 22: 2, 23: 2, 24: 0, 25: 1, 26: 0, 27: 0, 28: 0, 29: 0, 30: 0, 31: 0, 32: 0, 33: 0, 34: 1, 35: 0, 36: 0, 37: 1, 38: 0, 39: 0, 40: 0, 41: 3, 42: 0, 43: 0, 44: 0, 45: 0, 46: 0, 47: 2, 48: 0, 49: 1}}
[Average accuracy till task4]	Acc@1: 89.0750	Acc@5: 98.5500	Loss: 0.5706	Forgetting: 4.3667	Backward: -4.3667
Train: Epoch[1/5]  [  0/313]  eta: 0:03:30  Lr: 0.001875  Loss: 1.3891  Acc@1: 12.5000 (12.5000)  Acc@5: 50.0000 (50.0000)  time: 0.6728  data: 0.3313  max mem: 2362
Train: Epoch[1/5]  [ 10/313]  eta: 0:01:49  Lr: 0.001875  Loss: 0.9552  Acc@1: 43.7500 (45.4545)  Acc@5: 81.2500 (76.7045)  time: 0.3616  data: 0.0304  max mem: 2362
Train: Epoch[1/5]  [ 20/313]  eta: 0:01:41  Lr: 0.001875  Loss: 0.5520  Acc@1: 62.5000 (57.1429)  Acc@5: 87.5000 (84.8214)  time: 0.3316  data: 0.0003  max mem: 2362
Train: Epoch[1/5]  [ 30/313]  eta: 0:01:36  Lr: 0.001875  Loss: 0.4498  Acc@1: 75.0000 (63.5081)  Acc@5: 93.7500 (88.3065)  time: 0.3318  data: 0.0005  max mem: 2362
Train: Epoch[1/5]  [ 40/313]  eta: 0:01:32  Lr: 0.001875  Loss: 0.0652  Acc@1: 75.0000 (66.9207)  Acc@5: 93.7500 (90.2439)  time: 0.3306  data: 0.0007  max mem: 2362
Train: Epoch[1/5]  [ 50/313]  eta: 0:01:28  Lr: 0.001875  Loss: 0.1327  Acc@1: 81.2500 (69.6078)  Acc@5: 100.0000 (91.6667)  time: 0.3302  data: 0.0006  max mem: 2362
Train: Epoch[1/5]  [ 60/313]  eta: 0:01:25  Lr: 0.001875  Loss: -0.2111  Acc@1: 81.2500 (71.7213)  Acc@5: 100.0000 (92.6230)  time: 0.3303  data: 0.0004  max mem: 2362
Train: Epoch[1/5]  [ 70/313]  eta: 0:01:21  Lr: 0.001875  Loss: -0.5635  Acc@1: 81.2500 (73.0634)  Acc@5: 100.0000 (93.3099)  time: 0.3310  data: 0.0006  max mem: 2362
Train: Epoch[1/5]  [ 80/313]  eta: 0:01:18  Lr: 0.001875  Loss: -0.3649  Acc@1: 87.5000 (75.2315)  Acc@5: 100.0000 (93.8272)  time: 0.3309  data: 0.0006  max mem: 2362
Train: Epoch[1/5]  [ 90/313]  eta: 0:01:14  Lr: 0.001875  Loss: -0.1094  Acc@1: 87.5000 (76.0989)  Acc@5: 100.0000 (94.3681)  time: 0.3305  data: 0.0004  max mem: 2362
Train: Epoch[1/5]  [100/313]  eta: 0:01:11  Lr: 0.001875  Loss: -0.3940  Acc@1: 87.5000 (76.9802)  Acc@5: 100.0000 (94.6163)  time: 0.3314  data: 0.0011  max mem: 2362
Train: Epoch[1/5]  [110/313]  eta: 0:01:07  Lr: 0.001875  Loss: -0.5822  Acc@1: 87.5000 (78.0968)  Acc@5: 100.0000 (95.0450)  time: 0.3320  data: 0.0015  max mem: 2362
Train: Epoch[1/5]  [120/313]  eta: 0:01:04  Lr: 0.001875  Loss: -0.4016  Acc@1: 87.5000 (78.8223)  Acc@5: 100.0000 (95.3512)  time: 0.3311  data: 0.0008  max mem: 2362
Train: Epoch[1/5]  [130/313]  eta: 0:01:01  Lr: 0.001875  Loss: -0.6972  Acc@1: 87.5000 (79.2462)  Acc@5: 100.0000 (95.5630)  time: 0.3304  data: 0.0004  max mem: 2362
Train: Epoch[1/5]  [140/313]  eta: 0:00:57  Lr: 0.001875  Loss: -0.6292  Acc@1: 81.2500 (79.4326)  Acc@5: 100.0000 (95.7447)  time: 0.3307  data: 0.0004  max mem: 2362
Train: Epoch[1/5]  [150/313]  eta: 0:00:54  Lr: 0.001875  Loss: -0.8102  Acc@1: 81.2500 (79.8013)  Acc@5: 100.0000 (95.8609)  time: 0.3309  data: 0.0004  max mem: 2362
Train: Epoch[1/5]  [160/313]  eta: 0:00:50  Lr: 0.001875  Loss: -0.7323  Acc@1: 87.5000 (80.5901)  Acc@5: 100.0000 (96.0404)  time: 0.3307  data: 0.0004  max mem: 2362
Train: Epoch[1/5]  [170/313]  eta: 0:00:47  Lr: 0.001875  Loss: -0.7289  Acc@1: 93.7500 (81.0307)  Acc@5: 100.0000 (96.0892)  time: 0.3312  data: 0.0004  max mem: 2362
Train: Epoch[1/5]  [180/313]  eta: 0:00:44  Lr: 0.001875  Loss: -0.6111  Acc@1: 87.5000 (81.3191)  Acc@5: 100.0000 (96.2707)  time: 0.3314  data: 0.0004  max mem: 2362
Train: Epoch[1/5]  [190/313]  eta: 0:00:40  Lr: 0.001875  Loss: -0.7503  Acc@1: 87.5000 (81.8390)  Acc@5: 100.0000 (96.3678)  time: 0.3308  data: 0.0004  max mem: 2362
Train: Epoch[1/5]  [200/313]  eta: 0:00:37  Lr: 0.001875  Loss: -0.7830  Acc@1: 87.5000 (81.9652)  Acc@5: 100.0000 (96.4241)  time: 0.3318  data: 0.0018  max mem: 2362
Train: Epoch[1/5]  [210/313]  eta: 0:00:34  Lr: 0.001875  Loss: -0.7735  Acc@1: 81.2500 (82.1090)  Acc@5: 100.0000 (96.5344)  time: 0.3318  data: 0.0018  max mem: 2362
Train: Epoch[1/5]  [220/313]  eta: 0:00:30  Lr: 0.001875  Loss: -0.8901  Acc@1: 87.5000 (82.3529)  Acc@5: 100.0000 (96.6629)  time: 0.3315  data: 0.0012  max mem: 2362
Train: Epoch[1/5]  [230/313]  eta: 0:00:27  Lr: 0.001875  Loss: -0.5236  Acc@1: 87.5000 (82.4675)  Acc@5: 100.0000 (96.7532)  time: 0.3312  data: 0.0013  max mem: 2362
Train: Epoch[1/5]  [240/313]  eta: 0:00:24  Lr: 0.001875  Loss: -0.8781  Acc@1: 87.5000 (82.7023)  Acc@5: 100.0000 (96.8620)  time: 0.3302  data: 0.0004  max mem: 2362
Train: Epoch[1/5]  [250/313]  eta: 0:00:20  Lr: 0.001875  Loss: -0.6706  Acc@1: 87.5000 (82.8436)  Acc@5: 100.0000 (96.9373)  time: 0.3304  data: 0.0004  max mem: 2362
Train: Epoch[1/5]  [260/313]  eta: 0:00:17  Lr: 0.001875  Loss: -0.4298  Acc@1: 87.5000 (82.9741)  Acc@5: 100.0000 (96.9588)  time: 0.3306  data: 0.0004  max mem: 2362
Train: Epoch[1/5]  [270/313]  eta: 0:00:14  Lr: 0.001875  Loss: -0.6841  Acc@1: 93.7500 (83.3026)  Acc@5: 100.0000 (97.0480)  time: 0.3308  data: 0.0005  max mem: 2362
Train: Epoch[1/5]  [280/313]  eta: 0:00:10  Lr: 0.001875  Loss: -0.7139  Acc@1: 93.7500 (83.4742)  Acc@5: 100.0000 (97.0641)  time: 0.3313  data: 0.0006  max mem: 2362
Train: Epoch[1/5]  [290/313]  eta: 0:00:07  Lr: 0.001875  Loss: -0.6250  Acc@1: 87.5000 (83.6985)  Acc@5: 100.0000 (97.1649)  time: 0.3308  data: 0.0005  max mem: 2362
Train: Epoch[1/5]  [300/313]  eta: 0:00:04  Lr: 0.001875  Loss: -0.9533  Acc@1: 87.5000 (83.8040)  Acc@5: 100.0000 (97.2591)  time: 0.3317  data: 0.0014  max mem: 2362
Train: Epoch[1/5]  [310/313]  eta: 0:00:00  Lr: 0.001875  Loss: -0.5326  Acc@1: 87.5000 (83.8826)  Acc@5: 100.0000 (97.2468)  time: 0.3323  data: 0.0013  max mem: 2362
Train: Epoch[1/5]  [312/313]  eta: 0:00:00  Lr: 0.001875  Loss: -0.9888  Acc@1: 87.5000 (83.8200)  Acc@5: 100.0000 (97.2600)  time: 0.3240  data: 0.0013  max mem: 2362
Train: Epoch[1/5] Total time: 0:01:43 (0.3321 s / it)
Averaged stats: Lr: 0.001875  Loss: -0.9888  Acc@1: 87.5000 (83.8200)  Acc@5: 100.0000 (97.2600)
Train: Epoch[2/5]  [  0/313]  eta: 0:03:47  Lr: 0.001875  Loss: -0.6255  Acc@1: 81.2500 (81.2500)  Acc@5: 93.7500 (93.7500)  time: 0.7263  data: 0.3944  max mem: 2362
Train: Epoch[2/5]  [ 10/313]  eta: 0:01:50  Lr: 0.001875  Loss: -0.5855  Acc@1: 87.5000 (88.6364)  Acc@5: 100.0000 (97.7273)  time: 0.3657  data: 0.0363  max mem: 2362
Train: Epoch[2/5]  [ 20/313]  eta: 0:01:42  Lr: 0.001875  Loss: -0.5557  Acc@1: 87.5000 (91.0714)  Acc@5: 100.0000 (98.2143)  time: 0.3306  data: 0.0008  max mem: 2362
Train: Epoch[2/5]  [ 30/313]  eta: 0:01:37  Lr: 0.001875  Loss: -0.7751  Acc@1: 93.7500 (90.5242)  Acc@5: 100.0000 (98.5887)  time: 0.3314  data: 0.0008  max mem: 2362
Train: Epoch[2/5]  [ 40/313]  eta: 0:01:33  Lr: 0.001875  Loss: -0.7006  Acc@1: 87.5000 (89.7866)  Acc@5: 100.0000 (98.7805)  time: 0.3319  data: 0.0004  max mem: 2362
Train: Epoch[2/5]  [ 50/313]  eta: 0:01:29  Lr: 0.001875  Loss: -0.5277  Acc@1: 81.2500 (88.4804)  Acc@5: 100.0000 (98.7745)  time: 0.3326  data: 0.0004  max mem: 2362
Train: Epoch[2/5]  [ 60/313]  eta: 0:01:25  Lr: 0.001875  Loss: -0.9363  Acc@1: 87.5000 (88.3197)  Acc@5: 100.0000 (98.6680)  time: 0.3315  data: 0.0004  max mem: 2362
Train: Epoch[2/5]  [ 70/313]  eta: 0:01:21  Lr: 0.001875  Loss: -0.4649  Acc@1: 87.5000 (87.7641)  Acc@5: 100.0000 (98.7676)  time: 0.3304  data: 0.0005  max mem: 2362
Train: Epoch[2/5]  [ 80/313]  eta: 0:01:18  Lr: 0.001875  Loss: -0.4223  Acc@1: 87.5000 (87.8858)  Acc@5: 100.0000 (98.7654)  time: 0.3302  data: 0.0005  max mem: 2362
Train: Epoch[2/5]  [ 90/313]  eta: 0:01:14  Lr: 0.001875  Loss: -0.7161  Acc@1: 87.5000 (87.8434)  Acc@5: 100.0000 (98.5577)  time: 0.3299  data: 0.0005  max mem: 2362
Train: Epoch[2/5]  [100/313]  eta: 0:01:11  Lr: 0.001875  Loss: -0.8898  Acc@1: 93.7500 (88.3663)  Acc@5: 100.0000 (98.5149)  time: 0.3306  data: 0.0005  max mem: 2362
Train: Epoch[2/5]  [110/313]  eta: 0:01:07  Lr: 0.001875  Loss: -0.3173  Acc@1: 87.5000 (88.3446)  Acc@5: 100.0000 (98.5360)  time: 0.3308  data: 0.0004  max mem: 2362
Train: Epoch[2/5]  [120/313]  eta: 0:01:04  Lr: 0.001875  Loss: -0.5247  Acc@1: 87.5000 (87.9649)  Acc@5: 100.0000 (98.5537)  time: 0.3306  data: 0.0005  max mem: 2362
Train: Epoch[2/5]  [130/313]  eta: 0:01:01  Lr: 0.001875  Loss: -0.6396  Acc@1: 87.5000 (88.0248)  Acc@5: 100.0000 (98.5687)  time: 0.3304  data: 0.0006  max mem: 2362
Train: Epoch[2/5]  [140/313]  eta: 0:00:57  Lr: 0.001875  Loss: -0.9108  Acc@1: 87.5000 (87.9876)  Acc@5: 100.0000 (98.5816)  time: 0.3304  data: 0.0005  max mem: 2362
Train: Epoch[2/5]  [150/313]  eta: 0:00:54  Lr: 0.001875  Loss: -0.6164  Acc@1: 87.5000 (88.0381)  Acc@5: 100.0000 (98.4272)  time: 0.3309  data: 0.0004  max mem: 2362
Train: Epoch[2/5]  [160/313]  eta: 0:00:50  Lr: 0.001875  Loss: -0.4169  Acc@1: 87.5000 (87.8494)  Acc@5: 100.0000 (98.4472)  time: 0.3304  data: 0.0004  max mem: 2362
Train: Epoch[2/5]  [170/313]  eta: 0:00:47  Lr: 0.001875  Loss: -0.8147  Acc@1: 87.5000 (87.9751)  Acc@5: 100.0000 (98.5380)  time: 0.3311  data: 0.0004  max mem: 2362
Train: Epoch[2/5]  [180/313]  eta: 0:00:44  Lr: 0.001875  Loss: -0.8407  Acc@1: 93.7500 (88.2942)  Acc@5: 100.0000 (98.6188)  time: 0.3321  data: 0.0005  max mem: 2362
Train: Epoch[2/5]  [190/313]  eta: 0:00:40  Lr: 0.001875  Loss: -0.9029  Acc@1: 93.7500 (88.1545)  Acc@5: 100.0000 (98.6257)  time: 0.3324  data: 0.0005  max mem: 2362
Train: Epoch[2/5]  [200/313]  eta: 0:00:37  Lr: 0.001875  Loss: -0.8695  Acc@1: 87.5000 (88.1530)  Acc@5: 100.0000 (98.6940)  time: 0.3322  data: 0.0007  max mem: 2362
Train: Epoch[2/5]  [210/313]  eta: 0:00:34  Lr: 0.001875  Loss: -0.7845  Acc@1: 87.5000 (88.0036)  Acc@5: 100.0000 (98.6374)  time: 0.3315  data: 0.0006  max mem: 2362
Train: Epoch[2/5]  [220/313]  eta: 0:00:30  Lr: 0.001875  Loss: -0.7898  Acc@1: 87.5000 (87.8676)  Acc@5: 100.0000 (98.5577)  time: 0.3313  data: 0.0004  max mem: 2362
Train: Epoch[2/5]  [230/313]  eta: 0:00:27  Lr: 0.001875  Loss: -0.7191  Acc@1: 87.5000 (87.9329)  Acc@5: 100.0000 (98.5931)  time: 0.3311  data: 0.0005  max mem: 2362
Train: Epoch[2/5]  [240/313]  eta: 0:00:24  Lr: 0.001875  Loss: -0.5679  Acc@1: 87.5000 (87.7075)  Acc@5: 100.0000 (98.5996)  time: 0.3306  data: 0.0004  max mem: 2362
Train: Epoch[2/5]  [250/313]  eta: 0:00:20  Lr: 0.001875  Loss: -0.5633  Acc@1: 87.5000 (87.5747)  Acc@5: 100.0000 (98.6056)  time: 0.3307  data: 0.0009  max mem: 2362
Train: Epoch[2/5]  [260/313]  eta: 0:00:17  Lr: 0.001875  Loss: -0.7917  Acc@1: 87.5000 (87.5958)  Acc@5: 100.0000 (98.6111)  time: 0.3313  data: 0.0010  max mem: 2362
Train: Epoch[2/5]  [270/313]  eta: 0:00:14  Lr: 0.001875  Loss: -0.8511  Acc@1: 87.5000 (87.6153)  Acc@5: 100.0000 (98.6162)  time: 0.3321  data: 0.0005  max mem: 2362
Train: Epoch[2/5]  [280/313]  eta: 0:00:10  Lr: 0.001875  Loss: -0.9351  Acc@1: 93.7500 (87.7224)  Acc@5: 100.0000 (98.6655)  time: 0.3318  data: 0.0005  max mem: 2362
Train: Epoch[2/5]  [290/313]  eta: 0:00:07  Lr: 0.001875  Loss: -0.8482  Acc@1: 87.5000 (87.7363)  Acc@5: 100.0000 (98.7113)  time: 0.3311  data: 0.0005  max mem: 2362
Train: Epoch[2/5]  [300/313]  eta: 0:00:04  Lr: 0.001875  Loss: -0.8265  Acc@1: 87.5000 (87.7492)  Acc@5: 100.0000 (98.6919)  time: 0.3310  data: 0.0005  max mem: 2362
Train: Epoch[2/5]  [310/313]  eta: 0:00:00  Lr: 0.001875  Loss: -0.8261  Acc@1: 87.5000 (87.7613)  Acc@5: 100.0000 (98.6736)  time: 0.3310  data: 0.0005  max mem: 2362
Train: Epoch[2/5]  [312/313]  eta: 0:00:00  Lr: 0.001875  Loss: -0.9697  Acc@1: 87.5000 (87.8000)  Acc@5: 100.0000 (98.6800)  time: 0.3234  data: 0.0005  max mem: 2362
Train: Epoch[2/5] Total time: 0:01:44 (0.3324 s / it)
Averaged stats: Lr: 0.001875  Loss: -0.9697  Acc@1: 87.5000 (87.8000)  Acc@5: 100.0000 (98.6800)
Train: Epoch[3/5]  [  0/313]  eta: 0:03:32  Lr: 0.001875  Loss: -0.9125  Acc@1: 93.7500 (93.7500)  Acc@5: 100.0000 (100.0000)  time: 0.6793  data: 0.3463  max mem: 2362
Train: Epoch[3/5]  [ 10/313]  eta: 0:01:49  Lr: 0.001875  Loss: -0.5775  Acc@1: 93.7500 (92.0455)  Acc@5: 100.0000 (99.4318)  time: 0.3627  data: 0.0321  max mem: 2362
Train: Epoch[3/5]  [ 20/313]  eta: 0:01:41  Lr: 0.001875  Loss: -0.6816  Acc@1: 93.7500 (92.8571)  Acc@5: 100.0000 (99.7024)  time: 0.3309  data: 0.0005  max mem: 2362
Train: Epoch[3/5]  [ 30/313]  eta: 0:01:36  Lr: 0.001875  Loss: -0.8783  Acc@1: 93.7500 (92.1371)  Acc@5: 100.0000 (99.5968)  time: 0.3307  data: 0.0004  max mem: 2362
Train: Epoch[3/5]  [ 40/313]  eta: 0:01:32  Lr: 0.001875  Loss: -1.1651  Acc@1: 93.7500 (91.9207)  Acc@5: 100.0000 (99.2378)  time: 0.3309  data: 0.0004  max mem: 2362
Train: Epoch[3/5]  [ 50/313]  eta: 0:01:28  Lr: 0.001875  Loss: -0.7380  Acc@1: 87.5000 (91.4216)  Acc@5: 100.0000 (99.1422)  time: 0.3310  data: 0.0004  max mem: 2362
Train: Epoch[3/5]  [ 60/313]  eta: 0:01:25  Lr: 0.001875  Loss: -1.0748  Acc@1: 87.5000 (91.2910)  Acc@5: 100.0000 (99.2828)  time: 0.3315  data: 0.0005  max mem: 2362
Train: Epoch[3/5]  [ 70/313]  eta: 0:01:21  Lr: 0.001875  Loss: -0.7799  Acc@1: 87.5000 (90.9331)  Acc@5: 100.0000 (99.3838)  time: 0.3312  data: 0.0005  max mem: 2362
Train: Epoch[3/5]  [ 80/313]  eta: 0:01:18  Lr: 0.001875  Loss: -0.8603  Acc@1: 87.5000 (90.8179)  Acc@5: 100.0000 (99.3056)  time: 0.3301  data: 0.0004  max mem: 2362
Train: Epoch[3/5]  [ 90/313]  eta: 0:01:14  Lr: 0.001875  Loss: -0.8948  Acc@1: 87.5000 (90.6593)  Acc@5: 100.0000 (99.2445)  time: 0.3301  data: 0.0006  max mem: 2362
Train: Epoch[3/5]  [100/313]  eta: 0:01:11  Lr: 0.001875  Loss: -0.5080  Acc@1: 81.2500 (89.7277)  Acc@5: 100.0000 (98.9480)  time: 0.3301  data: 0.0006  max mem: 2362
Train: Epoch[3/5]  [110/313]  eta: 0:01:07  Lr: 0.001875  Loss: -1.0489  Acc@1: 81.2500 (89.6959)  Acc@5: 100.0000 (98.9865)  time: 0.3299  data: 0.0004  max mem: 2362
Train: Epoch[3/5]  [120/313]  eta: 0:01:04  Lr: 0.001875  Loss: -0.8374  Acc@1: 93.7500 (89.7727)  Acc@5: 100.0000 (99.0186)  time: 0.3300  data: 0.0004  max mem: 2362
Train: Epoch[3/5]  [130/313]  eta: 0:01:00  Lr: 0.001875  Loss: -1.1421  Acc@1: 93.7500 (89.7901)  Acc@5: 100.0000 (99.0458)  time: 0.3297  data: 0.0004  max mem: 2362
Train: Epoch[3/5]  [140/313]  eta: 0:00:57  Lr: 0.001875  Loss: -0.4046  Acc@1: 93.7500 (89.7606)  Acc@5: 100.0000 (99.0691)  time: 0.3298  data: 0.0004  max mem: 2362
Train: Epoch[3/5]  [150/313]  eta: 0:00:54  Lr: 0.001875  Loss: -0.6203  Acc@1: 87.5000 (89.5281)  Acc@5: 100.0000 (98.9652)  time: 0.3304  data: 0.0003  max mem: 2362
Train: Epoch[3/5]  [160/313]  eta: 0:00:50  Lr: 0.001875  Loss: -1.0413  Acc@1: 87.5000 (89.5186)  Acc@5: 100.0000 (98.9907)  time: 0.3308  data: 0.0003  max mem: 2362
Train: Epoch[3/5]  [170/313]  eta: 0:00:47  Lr: 0.001875  Loss: -1.0129  Acc@1: 87.5000 (89.2909)  Acc@5: 100.0000 (98.7939)  time: 0.3305  data: 0.0003  max mem: 2362
Train: Epoch[3/5]  [180/313]  eta: 0:00:44  Lr: 0.001875  Loss: -0.8040  Acc@1: 87.5000 (89.2610)  Acc@5: 100.0000 (98.8260)  time: 0.3307  data: 0.0004  max mem: 2362
Train: Epoch[3/5]  [190/313]  eta: 0:00:40  Lr: 0.001875  Loss: -0.8079  Acc@1: 93.7500 (89.3979)  Acc@5: 100.0000 (98.8547)  time: 0.3304  data: 0.0004  max mem: 2362
Train: Epoch[3/5]  [200/313]  eta: 0:00:37  Lr: 0.001875  Loss: -0.9130  Acc@1: 93.7500 (89.5211)  Acc@5: 100.0000 (98.9117)  time: 0.3301  data: 0.0003  max mem: 2362
Train: Epoch[3/5]  [210/313]  eta: 0:00:34  Lr: 0.001875  Loss: -0.5752  Acc@1: 87.5000 (89.4550)  Acc@5: 100.0000 (98.8744)  time: 0.3304  data: 0.0004  max mem: 2362
Train: Epoch[3/5]  [220/313]  eta: 0:00:30  Lr: 0.001875  Loss: -0.7487  Acc@1: 87.5000 (89.3948)  Acc@5: 100.0000 (98.8688)  time: 0.3304  data: 0.0004  max mem: 2362
Train: Epoch[3/5]  [230/313]  eta: 0:00:27  Lr: 0.001875  Loss: -0.7753  Acc@1: 87.5000 (89.3939)  Acc@5: 100.0000 (98.8907)  time: 0.3304  data: 0.0004  max mem: 2362
Train: Epoch[3/5]  [240/313]  eta: 0:00:24  Lr: 0.001875  Loss: -0.7036  Acc@1: 87.5000 (89.2894)  Acc@5: 100.0000 (98.8849)  time: 0.3304  data: 0.0004  max mem: 2362
Train: Epoch[3/5]  [250/313]  eta: 0:00:20  Lr: 0.001875  Loss: -0.7161  Acc@1: 87.5000 (89.2181)  Acc@5: 100.0000 (98.8297)  time: 0.3305  data: 0.0005  max mem: 2362
Train: Epoch[3/5]  [260/313]  eta: 0:00:17  Lr: 0.001875  Loss: -0.8191  Acc@1: 87.5000 (89.2002)  Acc@5: 100.0000 (98.8506)  time: 0.3304  data: 0.0004  max mem: 2362
Train: Epoch[3/5]  [270/313]  eta: 0:00:14  Lr: 0.001875  Loss: -1.0246  Acc@1: 87.5000 (89.0913)  Acc@5: 100.0000 (98.8699)  time: 0.3309  data: 0.0003  max mem: 2362
Train: Epoch[3/5]  [280/313]  eta: 0:00:10  Lr: 0.001875  Loss: -0.8295  Acc@1: 87.5000 (89.0792)  Acc@5: 100.0000 (98.8657)  time: 0.3308  data: 0.0003  max mem: 2362
Train: Epoch[3/5]  [290/313]  eta: 0:00:07  Lr: 0.001875  Loss: -0.4819  Acc@1: 87.5000 (89.1108)  Acc@5: 100.0000 (98.8832)  time: 0.3303  data: 0.0003  max mem: 2362
Train: Epoch[3/5]  [300/313]  eta: 0:00:04  Lr: 0.001875  Loss: -0.9561  Acc@1: 93.7500 (89.2234)  Acc@5: 100.0000 (98.8372)  time: 0.3300  data: 0.0004  max mem: 2362
Train: Epoch[3/5]  [310/313]  eta: 0:00:00  Lr: 0.001875  Loss: -0.8057  Acc@1: 93.7500 (89.3489)  Acc@5: 100.0000 (98.8545)  time: 0.3298  data: 0.0004  max mem: 2362
Train: Epoch[3/5]  [312/313]  eta: 0:00:00  Lr: 0.001875  Loss: -0.7581  Acc@1: 93.7500 (89.3400)  Acc@5: 100.0000 (98.8600)  time: 0.3218  data: 0.0003  max mem: 2362
Train: Epoch[3/5] Total time: 0:01:43 (0.3314 s / it)
Averaged stats: Lr: 0.001875  Loss: -0.7581  Acc@1: 93.7500 (89.3400)  Acc@5: 100.0000 (98.8600)
Train: Epoch[4/5]  [  0/313]  eta: 0:03:26  Lr: 0.001875  Loss: -0.7765  Acc@1: 93.7500 (93.7500)  Acc@5: 100.0000 (100.0000)  time: 0.6604  data: 0.3288  max mem: 2362
Train: Epoch[4/5]  [ 10/313]  eta: 0:01:49  Lr: 0.001875  Loss: -0.6748  Acc@1: 87.5000 (88.6364)  Acc@5: 100.0000 (98.2955)  time: 0.3604  data: 0.0305  max mem: 2362
Train: Epoch[4/5]  [ 20/313]  eta: 0:01:41  Lr: 0.001875  Loss: -0.7416  Acc@1: 87.5000 (89.8810)  Acc@5: 100.0000 (98.5119)  time: 0.3316  data: 0.0006  max mem: 2362
Train: Epoch[4/5]  [ 30/313]  eta: 0:01:36  Lr: 0.001875  Loss: -1.1130  Acc@1: 93.7500 (91.3306)  Acc@5: 100.0000 (98.7903)  time: 0.3330  data: 0.0005  max mem: 2362
Train: Epoch[4/5]  [ 40/313]  eta: 0:01:32  Lr: 0.001875  Loss: -0.9905  Acc@1: 93.7500 (91.4634)  Acc@5: 100.0000 (99.0854)  time: 0.3329  data: 0.0004  max mem: 2362
Train: Epoch[4/5]  [ 50/313]  eta: 0:01:29  Lr: 0.001875  Loss: -0.8745  Acc@1: 93.7500 (91.1765)  Acc@5: 100.0000 (99.0196)  time: 0.3323  data: 0.0006  max mem: 2362
Train: Epoch[4/5]  [ 60/313]  eta: 0:01:25  Lr: 0.001875  Loss: -0.6779  Acc@1: 87.5000 (90.9836)  Acc@5: 100.0000 (99.0779)  time: 0.3306  data: 0.0005  max mem: 2362
Train: Epoch[4/5]  [ 70/313]  eta: 0:01:21  Lr: 0.001875  Loss: -1.0412  Acc@1: 93.7500 (90.9331)  Acc@5: 100.0000 (99.1197)  time: 0.3293  data: 0.0003  max mem: 2362
Train: Epoch[4/5]  [ 80/313]  eta: 0:01:18  Lr: 0.001875  Loss: -0.8830  Acc@1: 93.7500 (90.8179)  Acc@5: 100.0000 (99.1512)  time: 0.3293  data: 0.0003  max mem: 2362
Train: Epoch[4/5]  [ 90/313]  eta: 0:01:14  Lr: 0.001875  Loss: -0.8847  Acc@1: 87.5000 (90.5907)  Acc@5: 100.0000 (99.2445)  time: 0.3291  data: 0.0003  max mem: 2362
Train: Epoch[4/5]  [100/313]  eta: 0:01:11  Lr: 0.001875  Loss: -0.7761  Acc@1: 87.5000 (90.3465)  Acc@5: 100.0000 (99.2574)  time: 0.3294  data: 0.0003  max mem: 2362
Train: Epoch[4/5]  [110/313]  eta: 0:01:07  Lr: 0.001875  Loss: -0.9454  Acc@1: 87.5000 (90.0901)  Acc@5: 100.0000 (99.2680)  time: 0.3298  data: 0.0004  max mem: 2362
Train: Epoch[4/5]  [120/313]  eta: 0:01:04  Lr: 0.001875  Loss: -0.5573  Acc@1: 87.5000 (89.7727)  Acc@5: 100.0000 (99.0702)  time: 0.3300  data: 0.0004  max mem: 2362
Train: Epoch[4/5]  [130/313]  eta: 0:01:00  Lr: 0.001875  Loss: -0.5090  Acc@1: 87.5000 (89.7424)  Acc@5: 100.0000 (99.0458)  time: 0.3302  data: 0.0003  max mem: 2362
Train: Epoch[4/5]  [140/313]  eta: 0:00:57  Lr: 0.001875  Loss: -0.8010  Acc@1: 87.5000 (89.6277)  Acc@5: 100.0000 (99.1135)  time: 0.3305  data: 0.0004  max mem: 2362
Train: Epoch[4/5]  [150/313]  eta: 0:00:54  Lr: 0.001875  Loss: -0.8994  Acc@1: 87.5000 (89.7351)  Acc@5: 100.0000 (99.0480)  time: 0.3304  data: 0.0004  max mem: 2362
Train: Epoch[4/5]  [160/313]  eta: 0:00:50  Lr: 0.001875  Loss: -0.5002  Acc@1: 87.5000 (89.7127)  Acc@5: 100.0000 (98.9519)  time: 0.3305  data: 0.0004  max mem: 2362
Train: Epoch[4/5]  [170/313]  eta: 0:00:47  Lr: 0.001875  Loss: -0.9438  Acc@1: 93.7500 (89.9854)  Acc@5: 100.0000 (99.0132)  time: 0.3306  data: 0.0004  max mem: 2362
Train: Epoch[4/5]  [180/313]  eta: 0:00:44  Lr: 0.001875  Loss: -0.7448  Acc@1: 93.7500 (90.2970)  Acc@5: 100.0000 (99.0677)  time: 0.3304  data: 0.0003  max mem: 2362
Train: Epoch[4/5]  [190/313]  eta: 0:00:40  Lr: 0.001875  Loss: -0.7983  Acc@1: 93.7500 (90.1832)  Acc@5: 100.0000 (99.0838)  time: 0.3306  data: 0.0004  max mem: 2362
Train: Epoch[4/5]  [200/313]  eta: 0:00:37  Lr: 0.001875  Loss: -0.5723  Acc@1: 87.5000 (90.0498)  Acc@5: 100.0000 (99.0672)  time: 0.3308  data: 0.0004  max mem: 2362
Train: Epoch[4/5]  [210/313]  eta: 0:00:34  Lr: 0.001875  Loss: -1.0658  Acc@1: 87.5000 (89.9882)  Acc@5: 100.0000 (99.0225)  time: 0.3306  data: 0.0004  max mem: 2362
Train: Epoch[4/5]  [220/313]  eta: 0:00:30  Lr: 0.001875  Loss: -0.9140  Acc@1: 87.5000 (89.9038)  Acc@5: 100.0000 (99.0385)  time: 0.3303  data: 0.0004  max mem: 2362
Train: Epoch[4/5]  [230/313]  eta: 0:00:27  Lr: 0.001875  Loss: -0.7099  Acc@1: 87.5000 (89.8268)  Acc@5: 100.0000 (99.0260)  time: 0.3302  data: 0.0003  max mem: 2362
Train: Epoch[4/5]  [240/313]  eta: 0:00:24  Lr: 0.001875  Loss: -0.6921  Acc@1: 87.5000 (89.6784)  Acc@5: 100.0000 (99.0664)  time: 0.3303  data: 0.0003  max mem: 2362
Train: Epoch[4/5]  [250/313]  eta: 0:00:20  Lr: 0.001875  Loss: -0.7720  Acc@1: 87.5000 (89.5169)  Acc@5: 100.0000 (99.0040)  time: 0.3302  data: 0.0003  max mem: 2362
Train: Epoch[4/5]  [260/313]  eta: 0:00:17  Lr: 0.001875  Loss: -0.8619  Acc@1: 87.5000 (89.5833)  Acc@5: 100.0000 (98.9703)  time: 0.3302  data: 0.0003  max mem: 2362
Train: Epoch[4/5]  [270/313]  eta: 0:00:14  Lr: 0.001875  Loss: -0.9874  Acc@1: 93.7500 (89.5987)  Acc@5: 100.0000 (98.9391)  time: 0.3303  data: 0.0003  max mem: 2362
Train: Epoch[4/5]  [280/313]  eta: 0:00:10  Lr: 0.001875  Loss: -0.2924  Acc@1: 93.7500 (89.6352)  Acc@5: 100.0000 (98.9324)  time: 0.3299  data: 0.0004  max mem: 2362
Train: Epoch[4/5]  [290/313]  eta: 0:00:07  Lr: 0.001875  Loss: -0.8395  Acc@1: 87.5000 (89.5833)  Acc@5: 100.0000 (98.9046)  time: 0.3300  data: 0.0004  max mem: 2362
Train: Epoch[4/5]  [300/313]  eta: 0:00:04  Lr: 0.001875  Loss: -0.9003  Acc@1: 87.5000 (89.5556)  Acc@5: 100.0000 (98.9203)  time: 0.3305  data: 0.0004  max mem: 2362
Train: Epoch[4/5]  [310/313]  eta: 0:00:00  Lr: 0.001875  Loss: -0.9640  Acc@1: 87.5000 (89.5699)  Acc@5: 100.0000 (98.9550)  time: 0.3307  data: 0.0003  max mem: 2362
Train: Epoch[4/5]  [312/313]  eta: 0:00:00  Lr: 0.001875  Loss: -1.0288  Acc@1: 93.7500 (89.6200)  Acc@5: 100.0000 (98.9600)  time: 0.3229  data: 0.0003  max mem: 2362
Train: Epoch[4/5] Total time: 0:01:43 (0.3315 s / it)
Averaged stats: Lr: 0.001875  Loss: -1.0288  Acc@1: 93.7500 (89.6200)  Acc@5: 100.0000 (98.9600)
Train: Epoch[5/5]  [  0/313]  eta: 0:03:11  Lr: 0.001875  Loss: -0.7553  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (100.0000)  time: 0.6126  data: 0.2802  max mem: 2362
Train: Epoch[5/5]  [ 10/313]  eta: 0:01:47  Lr: 0.001875  Loss: -0.7792  Acc@1: 87.5000 (88.0682)  Acc@5: 100.0000 (98.2955)  time: 0.3555  data: 0.0258  max mem: 2362
Train: Epoch[5/5]  [ 20/313]  eta: 0:01:40  Lr: 0.001875  Loss: -0.9092  Acc@1: 87.5000 (88.0952)  Acc@5: 100.0000 (99.1071)  time: 0.3300  data: 0.0003  max mem: 2362
Train: Epoch[5/5]  [ 30/313]  eta: 0:01:35  Lr: 0.001875  Loss: -0.8570  Acc@1: 87.5000 (88.1048)  Acc@5: 100.0000 (98.9919)  time: 0.3301  data: 0.0003  max mem: 2362
Train: Epoch[5/5]  [ 40/313]  eta: 0:01:31  Lr: 0.001875  Loss: -0.8680  Acc@1: 87.5000 (88.2622)  Acc@5: 100.0000 (99.2378)  time: 0.3300  data: 0.0003  max mem: 2362
Train: Epoch[5/5]  [ 50/313]  eta: 0:01:28  Lr: 0.001875  Loss: -1.0013  Acc@1: 87.5000 (87.8676)  Acc@5: 100.0000 (98.8971)  time: 0.3300  data: 0.0004  max mem: 2362
Train: Epoch[5/5]  [ 60/313]  eta: 0:01:24  Lr: 0.001875  Loss: -0.3462  Acc@1: 87.5000 (88.0123)  Acc@5: 100.0000 (98.6680)  time: 0.3299  data: 0.0003  max mem: 2362
Train: Epoch[5/5]  [ 70/313]  eta: 0:01:21  Lr: 0.001875  Loss: -0.8770  Acc@1: 87.5000 (88.2923)  Acc@5: 100.0000 (98.6796)  time: 0.3305  data: 0.0003  max mem: 2362
Train: Epoch[5/5]  [ 80/313]  eta: 0:01:17  Lr: 0.001875  Loss: -0.7396  Acc@1: 87.5000 (88.1944)  Acc@5: 100.0000 (98.7654)  time: 0.3305  data: 0.0003  max mem: 2362
Train: Epoch[5/5]  [ 90/313]  eta: 0:01:14  Lr: 0.001875  Loss: -0.9284  Acc@1: 93.7500 (88.8736)  Acc@5: 100.0000 (98.9011)  time: 0.3298  data: 0.0004  max mem: 2362
Train: Epoch[5/5]  [100/313]  eta: 0:01:10  Lr: 0.001875  Loss: -0.7056  Acc@1: 93.7500 (88.7995)  Acc@5: 100.0000 (98.7624)  time: 0.3302  data: 0.0003  max mem: 2362
Train: Epoch[5/5]  [110/313]  eta: 0:01:07  Lr: 0.001875  Loss: -0.4169  Acc@1: 87.5000 (88.3446)  Acc@5: 100.0000 (98.7050)  time: 0.3313  data: 0.0010  max mem: 2362
Train: Epoch[5/5]  [120/313]  eta: 0:01:04  Lr: 0.001875  Loss: -0.9384  Acc@1: 87.5000 (88.3264)  Acc@5: 100.0000 (98.7603)  time: 0.3320  data: 0.0012  max mem: 2362
Train: Epoch[5/5]  [130/313]  eta: 0:01:00  Lr: 0.001875  Loss: -0.7164  Acc@1: 87.5000 (88.4542)  Acc@5: 100.0000 (98.8550)  time: 0.3323  data: 0.0007  max mem: 2362
Train: Epoch[5/5]  [140/313]  eta: 0:00:57  Lr: 0.001875  Loss: -0.7696  Acc@1: 93.7500 (88.6968)  Acc@5: 100.0000 (98.8475)  time: 0.3313  data: 0.0007  max mem: 2362
Train: Epoch[5/5]  [150/313]  eta: 0:00:54  Lr: 0.001875  Loss: -0.5381  Acc@1: 93.7500 (88.9901)  Acc@5: 100.0000 (98.8825)  time: 0.3309  data: 0.0004  max mem: 2362
Train: Epoch[5/5]  [160/313]  eta: 0:00:50  Lr: 0.001875  Loss: -0.8795  Acc@1: 93.7500 (89.0140)  Acc@5: 100.0000 (98.9519)  time: 0.3315  data: 0.0003  max mem: 2362
Train: Epoch[5/5]  [170/313]  eta: 0:00:47  Lr: 0.001875  Loss: -1.0551  Acc@1: 87.5000 (88.7792)  Acc@5: 100.0000 (98.8670)  time: 0.3313  data: 0.0004  max mem: 2362
Train: Epoch[5/5]  [180/313]  eta: 0:00:44  Lr: 0.001875  Loss: -0.7914  Acc@1: 87.5000 (88.9157)  Acc@5: 100.0000 (98.8605)  time: 0.3314  data: 0.0004  max mem: 2362
Train: Epoch[5/5]  [190/313]  eta: 0:00:40  Lr: 0.001875  Loss: -0.5928  Acc@1: 87.5000 (88.8089)  Acc@5: 100.0000 (98.8220)  time: 0.3310  data: 0.0004  max mem: 2362
Train: Epoch[5/5]  [200/313]  eta: 0:00:37  Lr: 0.001875  Loss: -0.8934  Acc@1: 87.5000 (88.8371)  Acc@5: 100.0000 (98.8184)  time: 0.3310  data: 0.0005  max mem: 2362
Train: Epoch[5/5]  [210/313]  eta: 0:00:34  Lr: 0.001875  Loss: -1.0142  Acc@1: 93.7500 (88.8922)  Acc@5: 100.0000 (98.8744)  time: 0.3308  data: 0.0005  max mem: 2362
Train: Epoch[5/5]  [220/313]  eta: 0:00:30  Lr: 0.001875  Loss: -0.9076  Acc@1: 93.7500 (88.8857)  Acc@5: 100.0000 (98.8405)  time: 0.3312  data: 0.0004  max mem: 2362
Train: Epoch[5/5]  [230/313]  eta: 0:00:27  Lr: 0.001875  Loss: -0.3476  Acc@1: 87.5000 (88.7446)  Acc@5: 100.0000 (98.8366)  time: 0.3315  data: 0.0005  max mem: 2362
Train: Epoch[5/5]  [240/313]  eta: 0:00:24  Lr: 0.001875  Loss: -0.6897  Acc@1: 87.5000 (88.8226)  Acc@5: 100.0000 (98.8071)  time: 0.3305  data: 0.0005  max mem: 2362
Train: Epoch[5/5]  [250/313]  eta: 0:00:20  Lr: 0.001875  Loss: -1.0821  Acc@1: 93.7500 (89.0189)  Acc@5: 100.0000 (98.8546)  time: 0.3310  data: 0.0004  max mem: 2362
Train: Epoch[5/5]  [260/313]  eta: 0:00:17  Lr: 0.001875  Loss: -1.0650  Acc@1: 93.7500 (89.0565)  Acc@5: 100.0000 (98.8745)  time: 0.3314  data: 0.0004  max mem: 2362
Train: Epoch[5/5]  [270/313]  eta: 0:00:14  Lr: 0.001875  Loss: -0.9286  Acc@1: 93.7500 (89.1375)  Acc@5: 100.0000 (98.8930)  time: 0.3317  data: 0.0004  max mem: 2362
Train: Epoch[5/5]  [280/313]  eta: 0:00:10  Lr: 0.001875  Loss: -0.7134  Acc@1: 93.7500 (89.1014)  Acc@5: 100.0000 (98.8657)  time: 0.3317  data: 0.0005  max mem: 2362
Train: Epoch[5/5]  [290/313]  eta: 0:00:07  Lr: 0.001875  Loss: -0.5114  Acc@1: 93.7500 (89.1753)  Acc@5: 100.0000 (98.8187)  time: 0.3314  data: 0.0005  max mem: 2362
Train: Epoch[5/5]  [300/313]  eta: 0:00:04  Lr: 0.001875  Loss: -0.8206  Acc@1: 93.7500 (89.1819)  Acc@5: 100.0000 (98.8372)  time: 0.3311  data: 0.0004  max mem: 2362
Train: Epoch[5/5]  [310/313]  eta: 0:00:00  Lr: 0.001875  Loss: -0.5296  Acc@1: 87.5000 (89.2082)  Acc@5: 100.0000 (98.8344)  time: 0.3306  data: 0.0003  max mem: 2362
Train: Epoch[5/5]  [312/313]  eta: 0:00:00  Lr: 0.001875  Loss: -0.8447  Acc@1: 87.5000 (89.1800)  Acc@5: 100.0000 (98.8400)  time: 0.3223  data: 0.0003  max mem: 2362
Train: Epoch[5/5] Total time: 0:01:43 (0.3318 s / it)
Averaged stats: Lr: 0.001875  Loss: -0.8447  Acc@1: 87.5000 (89.1800)  Acc@5: 100.0000 (98.8400)
Test: [Task 1]  [ 0/63]  eta: 0:00:33  Loss: 0.6606 (0.6606)  Acc@1: 75.0000 (75.0000)  Acc@5: 100.0000 (100.0000)  time: 0.5346  data: 0.3265  max mem: 2362
Test: [Task 1]  [10/63]  eta: 0:00:12  Loss: 0.6068 (0.6020)  Acc@1: 87.5000 (84.6591)  Acc@5: 100.0000 (99.4318)  time: 0.2354  data: 0.0300  max mem: 2362
Test: [Task 1]  [20/63]  eta: 0:00:09  Loss: 0.6068 (0.6570)  Acc@1: 81.2500 (83.6310)  Acc@5: 100.0000 (98.2143)  time: 0.2054  data: 0.0003  max mem: 2362
Test: [Task 1]  [30/63]  eta: 0:00:07  Loss: 0.5541 (0.6209)  Acc@1: 81.2500 (85.0806)  Acc@5: 100.0000 (98.1855)  time: 0.2056  data: 0.0003  max mem: 2362
Test: [Task 1]  [40/63]  eta: 0:00:04  Loss: 0.4328 (0.5966)  Acc@1: 93.7500 (86.4329)  Acc@5: 100.0000 (98.6280)  time: 0.2059  data: 0.0004  max mem: 2362
Test: [Task 1]  [50/63]  eta: 0:00:02  Loss: 0.4206 (0.5750)  Acc@1: 93.7500 (87.3775)  Acc@5: 100.0000 (98.6520)  time: 0.2056  data: 0.0004  max mem: 2362
Test: [Task 1]  [60/63]  eta: 0:00:00  Loss: 0.4443 (0.5654)  Acc@1: 93.7500 (87.7049)  Acc@5: 100.0000 (98.8730)  time: 0.2058  data: 0.0003  max mem: 2362
Test: [Task 1]  [62/63]  eta: 0:00:00  Loss: 0.4206 (0.5612)  Acc@1: 93.7500 (87.9000)  Acc@5: 100.0000 (98.9000)  time: 0.2010  data: 0.0003  max mem: 2362
Test: [Task 1] Total time: 0:00:13 (0.2119 s / it)
* Acc@1 87.900 Acc@5 98.900 loss 0.561
Test: [Task 2]  [ 0/63]  eta: 0:00:36  Loss: 0.7873 (0.7873)  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (100.0000)  time: 0.5794  data: 0.3710  max mem: 2362
Test: [Task 2]  [10/63]  eta: 0:00:12  Loss: 0.6659 (0.6922)  Acc@1: 87.5000 (86.3636)  Acc@5: 100.0000 (98.8636)  time: 0.2397  data: 0.0341  max mem: 2362
Test: [Task 2]  [20/63]  eta: 0:00:09  Loss: 0.7093 (0.7818)  Acc@1: 81.2500 (83.6310)  Acc@5: 100.0000 (98.2143)  time: 0.2059  data: 0.0004  max mem: 2362
Test: [Task 2]  [30/63]  eta: 0:00:07  Loss: 0.7506 (0.7763)  Acc@1: 81.2500 (84.0726)  Acc@5: 100.0000 (97.5806)  time: 0.2063  data: 0.0004  max mem: 2362
Test: [Task 2]  [40/63]  eta: 0:00:04  Loss: 0.7176 (0.7548)  Acc@1: 87.5000 (85.0610)  Acc@5: 100.0000 (97.7134)  time: 0.2065  data: 0.0003  max mem: 2362
Test: [Task 2]  [50/63]  eta: 0:00:02  Loss: 0.6718 (0.7449)  Acc@1: 87.5000 (84.6814)  Acc@5: 100.0000 (97.7941)  time: 0.2065  data: 0.0004  max mem: 2362
Test: [Task 2]  [60/63]  eta: 0:00:00  Loss: 0.6186 (0.7214)  Acc@1: 87.5000 (85.6557)  Acc@5: 100.0000 (98.0533)  time: 0.2061  data: 0.0003  max mem: 2362
Test: [Task 2]  [62/63]  eta: 0:00:00  Loss: 0.6023 (0.7142)  Acc@1: 87.5000 (85.7000)  Acc@5: 100.0000 (98.1000)  time: 0.2014  data: 0.0003  max mem: 2362
Test: [Task 2] Total time: 0:00:13 (0.2121 s / it)
* Acc@1 85.700 Acc@5 98.100 loss 0.714
Test: [Task 3]  [ 0/63]  eta: 0:00:37  Loss: 0.3158 (0.3158)  Acc@1: 93.7500 (93.7500)  Acc@5: 100.0000 (100.0000)  time: 0.5915  data: 0.3842  max mem: 2362
Test: [Task 3]  [10/63]  eta: 0:00:12  Loss: 0.5736 (0.5824)  Acc@1: 87.5000 (85.2273)  Acc@5: 100.0000 (98.8636)  time: 0.2408  data: 0.0353  max mem: 2362
Test: [Task 3]  [20/63]  eta: 0:00:09  Loss: 0.6126 (0.5931)  Acc@1: 87.5000 (85.1190)  Acc@5: 100.0000 (98.2143)  time: 0.2058  data: 0.0004  max mem: 2362
Test: [Task 3]  [30/63]  eta: 0:00:07  Loss: 0.5942 (0.5691)  Acc@1: 87.5000 (85.8871)  Acc@5: 100.0000 (98.5887)  time: 0.2065  data: 0.0004  max mem: 2362
Test: [Task 3]  [40/63]  eta: 0:00:04  Loss: 0.4774 (0.5789)  Acc@1: 87.5000 (86.8902)  Acc@5: 100.0000 (98.4756)  time: 0.2065  data: 0.0004  max mem: 2362
Test: [Task 3]  [50/63]  eta: 0:00:02  Loss: 0.5651 (0.5829)  Acc@1: 87.5000 (87.2549)  Acc@5: 100.0000 (98.2843)  time: 0.2063  data: 0.0004  max mem: 2362
Test: [Task 3]  [60/63]  eta: 0:00:00  Loss: 0.5794 (0.5805)  Acc@1: 87.5000 (87.2951)  Acc@5: 100.0000 (98.4631)  time: 0.2064  data: 0.0003  max mem: 2362
Test: [Task 3]  [62/63]  eta: 0:00:00  Loss: 0.5927 (0.5806)  Acc@1: 87.5000 (87.1000)  Acc@5: 100.0000 (98.5000)  time: 0.2012  data: 0.0003  max mem: 2362
Test: [Task 3] Total time: 0:00:13 (0.2121 s / it)
* Acc@1 87.100 Acc@5 98.500 loss 0.581
Test: [Task 4]  [ 0/63]  eta: 0:00:38  Loss: 0.9302 (0.9302)  Acc@1: 75.0000 (75.0000)  Acc@5: 93.7500 (93.7500)  time: 0.6171  data: 0.4107  max mem: 2362
Test: [Task 4]  [10/63]  eta: 0:00:12  Loss: 0.6693 (0.6941)  Acc@1: 87.5000 (85.7955)  Acc@5: 100.0000 (97.7273)  time: 0.2436  data: 0.0376  max mem: 2362
Test: [Task 4]  [20/63]  eta: 0:00:09  Loss: 0.6088 (0.6655)  Acc@1: 87.5000 (85.7143)  Acc@5: 100.0000 (97.6190)  time: 0.2064  data: 0.0004  max mem: 2362
Test: [Task 4]  [30/63]  eta: 0:00:07  Loss: 0.5088 (0.6192)  Acc@1: 87.5000 (87.2984)  Acc@5: 100.0000 (97.7823)  time: 0.2065  data: 0.0004  max mem: 2362
Test: [Task 4]  [40/63]  eta: 0:00:04  Loss: 0.3486 (0.5630)  Acc@1: 93.7500 (88.8720)  Acc@5: 100.0000 (98.1707)  time: 0.2069  data: 0.0004  max mem: 2362
Test: [Task 4]  [50/63]  eta: 0:00:02  Loss: 0.3894 (0.5689)  Acc@1: 93.7500 (88.4804)  Acc@5: 100.0000 (98.1618)  time: 0.2067  data: 0.0003  max mem: 2362
Test: [Task 4]  [60/63]  eta: 0:00:00  Loss: 0.5871 (0.5908)  Acc@1: 87.5000 (87.8074)  Acc@5: 100.0000 (97.6434)  time: 0.2061  data: 0.0003  max mem: 2362
Test: [Task 4]  [62/63]  eta: 0:00:00  Loss: 0.5374 (0.5869)  Acc@1: 87.5000 (88.0000)  Acc@5: 100.0000 (97.7000)  time: 0.2012  data: 0.0003  max mem: 2362
Test: [Task 4] Total time: 0:00:13 (0.2130 s / it)
* Acc@1 88.000 Acc@5 97.700 loss 0.587
Test: [Task 5]  [ 0/63]  eta: 0:00:30  Loss: 0.2853 (0.2853)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)  time: 0.4908  data: 0.2830  max mem: 2362
Test: [Task 5]  [10/63]  eta: 0:00:12  Loss: 0.4940 (0.6462)  Acc@1: 93.7500 (88.0682)  Acc@5: 100.0000 (96.0227)  time: 0.2314  data: 0.0260  max mem: 2362
Test: [Task 5]  [20/63]  eta: 0:00:09  Loss: 0.4940 (0.5947)  Acc@1: 87.5000 (88.9881)  Acc@5: 100.0000 (97.0238)  time: 0.2059  data: 0.0004  max mem: 2362
Test: [Task 5]  [30/63]  eta: 0:00:07  Loss: 0.4922 (0.5797)  Acc@1: 87.5000 (89.5161)  Acc@5: 100.0000 (97.7823)  time: 0.2059  data: 0.0004  max mem: 2362
Test: [Task 5]  [40/63]  eta: 0:00:04  Loss: 0.4922 (0.5639)  Acc@1: 93.7500 (89.7866)  Acc@5: 100.0000 (97.8659)  time: 0.2056  data: 0.0003  max mem: 2362
Test: [Task 5]  [50/63]  eta: 0:00:02  Loss: 0.5436 (0.5655)  Acc@1: 93.7500 (90.3186)  Acc@5: 100.0000 (97.7941)  time: 0.2061  data: 0.0003  max mem: 2362
Test: [Task 5]  [60/63]  eta: 0:00:00  Loss: 0.5500 (0.5898)  Acc@1: 87.5000 (89.3443)  Acc@5: 100.0000 (97.5410)  time: 0.2061  data: 0.0003  max mem: 2362
Test: [Task 5]  [62/63]  eta: 0:00:00  Loss: 0.5560 (0.6112)  Acc@1: 87.5000 (88.7000)  Acc@5: 100.0000 (97.6000)  time: 0.2009  data: 0.0003  max mem: 2362
Test: [Task 5] Total time: 0:00:13 (0.2102 s / it)
* Acc@1 88.700 Acc@5 97.600 loss 0.611
{0: {0: 626, 1: 630, 2: 634, 3: 631, 4: 637, 5: 53, 6: 55, 7: 50, 8: 54, 9: 51, 10: 65, 11: 65, 12: 65, 13: 65, 14: 65, 15: 204, 16: 198, 17: 208, 18: 201, 19: 206, 20: 46, 21: 46, 22: 48, 23: 47, 24: 46, 25: 0, 26: 0, 27: 0, 28: 2, 29: 0, 30: 0, 31: 0, 32: 0, 33: 0, 34: 0, 35: 0, 36: 1, 37: 0, 38: 0, 39: 0, 40: 0, 41: 0, 42: 0, 43: 0, 44: 0, 45: 0, 46: 0, 47: 1, 48: 0, 49: 0}, 1: {0: 119, 1: 122, 2: 124, 3: 122, 4: 124, 5: 536, 6: 538, 7: 534, 8: 539, 9: 535, 10: 85, 11: 83, 12: 86, 13: 84, 14: 85, 15: 196, 16: 195, 17: 198, 18: 196, 19: 198, 20: 58, 21: 60, 22: 59, 23: 58, 24: 58, 25: 0, 26: 2, 27: 0, 28: 1, 29: 0, 30: 1, 31: 0, 32: 0, 33: 0, 34: 0, 35: 0, 36: 1, 37: 2, 38: 0, 39: 1, 40: 0, 41: 0, 42: 0, 43: 0, 44: 0, 45: 0, 46: 0, 47: 0, 48: 0, 49: 0}, 2: {0: 56, 1: 57, 2: 57, 3: 57, 4: 55, 5: 40, 6: 39, 7: 40, 8: 40, 9: 40, 10: 644, 11: 640, 12: 639, 13: 641, 14: 644, 15: 177, 16: 175, 17: 178, 18: 177, 19: 177, 20: 84, 21: 83, 22: 85, 23: 84, 24: 84, 25: 0, 26: 0, 27: 1, 28: 2, 29: 1, 30: 0, 31: 0, 32: 0, 33: 0, 34: 0, 35: 0, 36: 0, 37: 0, 38: 0, 39: 0, 40: 0, 41: 0, 42: 0, 43: 0, 44: 0, 45: 1, 46: 0, 47: 1, 48: 0, 49: 1}, 3: {0: 34, 1: 35, 2: 35, 3: 34, 4: 36, 5: 96, 6: 98, 7: 96, 8: 97, 9: 96, 10: 42, 11: 42, 12: 41, 13: 42, 14: 41, 15: 773, 16: 764, 17: 776, 18: 770, 19: 775, 20: 54, 21: 53, 22: 54, 23: 53, 24: 54, 25: 1, 26: 0, 27: 0, 28: 0, 29: 0, 30: 0, 31: 0, 32: 0, 33: 0, 34: 1, 35: 0, 36: 0, 37: 1, 38: 0, 39: 0, 40: 0, 41: 3, 42: 0, 43: 0, 44: 0, 45: 0, 46: 0, 47: 2, 48: 0, 49: 1}, 4: {0: 69, 1: 68, 2: 72, 3: 72, 4: 72, 5: 83, 6: 85, 7: 82, 8: 84, 9: 83, 10: 130, 11: 130, 12: 129, 13: 130, 14: 129, 15: 220, 16: 218, 17: 222, 18: 220, 19: 220, 20: 495, 21: 495, 22: 495, 23: 496, 24: 494, 25: 0, 26: 0, 27: 0, 28: 0, 29: 0, 30: 2, 31: 0, 32: 1, 33: 0, 34: 0, 35: 0, 36: 0, 37: 0, 38: 0, 39: 0, 40: 2, 41: 1, 42: 0, 43: 0, 44: 0, 45: 1, 46: 0, 47: 0, 48: 0, 49: 0}}
[Average accuracy till task5]	Acc@1: 87.4800	Acc@5: 98.1600	Loss: 0.6108	Forgetting: 5.1750	Backward: -5.1750
Train: Epoch[1/5]  [  0/313]  eta: 0:03:29  Lr: 0.001875  Loss: 1.2493  Acc@1: 12.5000 (12.5000)  Acc@5: 25.0000 (25.0000)  time: 0.6707  data: 0.3209  max mem: 2362
Train: Epoch[1/5]  [ 10/313]  eta: 0:01:49  Lr: 0.001875  Loss: 0.7730  Acc@1: 56.2500 (51.1364)  Acc@5: 81.2500 (79.5455)  time: 0.3614  data: 0.0295  max mem: 2362
Train: Epoch[1/5]  [ 20/313]  eta: 0:01:41  Lr: 0.001875  Loss: 0.6841  Acc@1: 68.7500 (64.5833)  Acc@5: 93.7500 (88.3929)  time: 0.3306  data: 0.0004  max mem: 2362
Train: Epoch[1/5]  [ 30/313]  eta: 0:01:36  Lr: 0.001875  Loss: 0.2782  Acc@1: 81.2500 (70.7661)  Acc@5: 100.0000 (91.7339)  time: 0.3307  data: 0.0004  max mem: 2362
Train: Epoch[1/5]  [ 40/313]  eta: 0:01:32  Lr: 0.001875  Loss: 0.0446  Acc@1: 87.5000 (75.3049)  Acc@5: 100.0000 (93.4451)  time: 0.3317  data: 0.0008  max mem: 2362
Train: Epoch[1/5]  [ 50/313]  eta: 0:01:28  Lr: 0.001875  Loss: -0.3793  Acc@1: 87.5000 (77.4510)  Acc@5: 100.0000 (94.6078)  time: 0.3320  data: 0.0008  max mem: 2362
Train: Epoch[1/5]  [ 60/313]  eta: 0:01:25  Lr: 0.001875  Loss: -0.2465  Acc@1: 81.2500 (78.4836)  Acc@5: 100.0000 (95.0820)  time: 0.3324  data: 0.0004  max mem: 2362
Train: Epoch[1/5]  [ 70/313]  eta: 0:01:21  Lr: 0.001875  Loss: -0.5987  Acc@1: 87.5000 (80.0176)  Acc@5: 100.0000 (95.6866)  time: 0.3318  data: 0.0004  max mem: 2362
Train: Epoch[1/5]  [ 80/313]  eta: 0:01:18  Lr: 0.001875  Loss: -0.3033  Acc@1: 87.5000 (80.8642)  Acc@5: 100.0000 (96.0648)  time: 0.3304  data: 0.0004  max mem: 2362
Train: Epoch[1/5]  [ 90/313]  eta: 0:01:14  Lr: 0.001875  Loss: -0.6972  Acc@1: 87.5000 (81.7308)  Acc@5: 100.0000 (96.3599)  time: 0.3313  data: 0.0004  max mem: 2362
Train: Epoch[1/5]  [100/313]  eta: 0:01:11  Lr: 0.001875  Loss: -0.4421  Acc@1: 81.2500 (81.7450)  Acc@5: 100.0000 (96.5965)  time: 0.3319  data: 0.0004  max mem: 2362
Train: Epoch[1/5]  [110/313]  eta: 0:01:07  Lr: 0.001875  Loss: -0.5138  Acc@1: 81.2500 (82.0946)  Acc@5: 100.0000 (96.7342)  time: 0.3315  data: 0.0004  max mem: 2362
Train: Epoch[1/5]  [120/313]  eta: 0:01:04  Lr: 0.001875  Loss: -0.3390  Acc@1: 87.5000 (82.0248)  Acc@5: 100.0000 (96.8492)  time: 0.3310  data: 0.0004  max mem: 2362
Train: Epoch[1/5]  [130/313]  eta: 0:01:01  Lr: 0.001875  Loss: -0.8954  Acc@1: 87.5000 (82.6813)  Acc@5: 100.0000 (97.0897)  time: 0.3309  data: 0.0004  max mem: 2362
Train: Epoch[1/5]  [140/313]  eta: 0:00:57  Lr: 0.001875  Loss: -0.1601  Acc@1: 87.5000 (82.9787)  Acc@5: 100.0000 (97.2074)  time: 0.3309  data: 0.0004  max mem: 2362
Train: Epoch[1/5]  [150/313]  eta: 0:00:54  Lr: 0.001875  Loss: -0.6531  Acc@1: 87.5000 (83.1540)  Acc@5: 100.0000 (97.3924)  time: 0.3306  data: 0.0004  max mem: 2362
Train: Epoch[1/5]  [160/313]  eta: 0:00:50  Lr: 0.001875  Loss: -0.7522  Acc@1: 87.5000 (83.5404)  Acc@5: 100.0000 (97.5155)  time: 0.3306  data: 0.0004  max mem: 2362
Train: Epoch[1/5]  [170/313]  eta: 0:00:47  Lr: 0.001875  Loss: -0.7949  Acc@1: 87.5000 (83.7354)  Acc@5: 100.0000 (97.6608)  time: 0.3311  data: 0.0004  max mem: 2362
Train: Epoch[1/5]  [180/313]  eta: 0:00:44  Lr: 0.001875  Loss: -0.6115  Acc@1: 87.5000 (83.6326)  Acc@5: 100.0000 (97.7210)  time: 0.3315  data: 0.0004  max mem: 2362
Train: Epoch[1/5]  [190/313]  eta: 0:00:40  Lr: 0.001875  Loss: -0.7875  Acc@1: 87.5000 (83.7042)  Acc@5: 100.0000 (97.7749)  time: 0.3316  data: 0.0005  max mem: 2362
Train: Epoch[1/5]  [200/313]  eta: 0:00:37  Lr: 0.001875  Loss: -0.7594  Acc@1: 87.5000 (83.9863)  Acc@5: 100.0000 (97.7923)  time: 0.3311  data: 0.0004  max mem: 2362
Train: Epoch[1/5]  [210/313]  eta: 0:00:34  Lr: 0.001875  Loss: -0.8004  Acc@1: 93.7500 (84.3898)  Acc@5: 100.0000 (97.8969)  time: 0.3304  data: 0.0003  max mem: 2362
Train: Epoch[1/5]  [220/313]  eta: 0:00:30  Lr: 0.001875  Loss: -0.4100  Acc@1: 87.5000 (84.4457)  Acc@5: 100.0000 (97.9072)  time: 0.3304  data: 0.0004  max mem: 2362
Train: Epoch[1/5]  [230/313]  eta: 0:00:27  Lr: 0.001875  Loss: -0.7408  Acc@1: 87.5000 (84.6320)  Acc@5: 100.0000 (97.9437)  time: 0.3308  data: 0.0004  max mem: 2362
Train: Epoch[1/5]  [240/313]  eta: 0:00:24  Lr: 0.001875  Loss: -0.3846  Acc@1: 87.5000 (84.6992)  Acc@5: 100.0000 (98.0031)  time: 0.3307  data: 0.0004  max mem: 2362
Train: Epoch[1/5]  [250/313]  eta: 0:00:20  Lr: 0.001875  Loss: -1.0105  Acc@1: 87.5000 (84.9353)  Acc@5: 100.0000 (98.0329)  time: 0.3304  data: 0.0004  max mem: 2362
Train: Epoch[1/5]  [260/313]  eta: 0:00:17  Lr: 0.001875  Loss: -0.6697  Acc@1: 87.5000 (84.9856)  Acc@5: 100.0000 (98.0603)  time: 0.3304  data: 0.0004  max mem: 2362
Train: Epoch[1/5]  [270/313]  eta: 0:00:14  Lr: 0.001875  Loss: -0.6564  Acc@1: 87.5000 (85.1937)  Acc@5: 100.0000 (98.0858)  time: 0.3306  data: 0.0004  max mem: 2362
Train: Epoch[1/5]  [280/313]  eta: 0:00:10  Lr: 0.001875  Loss: -0.6166  Acc@1: 87.5000 (85.3870)  Acc@5: 100.0000 (98.0872)  time: 0.3307  data: 0.0004  max mem: 2362
Train: Epoch[1/5]  [290/313]  eta: 0:00:07  Lr: 0.001875  Loss: -0.6588  Acc@1: 87.5000 (85.4381)  Acc@5: 100.0000 (98.1529)  time: 0.3311  data: 0.0004  max mem: 2362
Train: Epoch[1/5]  [300/313]  eta: 0:00:04  Lr: 0.001875  Loss: -0.3094  Acc@1: 87.5000 (85.4444)  Acc@5: 100.0000 (98.1728)  time: 0.3309  data: 0.0004  max mem: 2362
Train: Epoch[1/5]  [310/313]  eta: 0:00:00  Lr: 0.001875  Loss: -1.1005  Acc@1: 87.5000 (85.4502)  Acc@5: 100.0000 (98.1511)  time: 0.3308  data: 0.0004  max mem: 2362
Train: Epoch[1/5]  [312/313]  eta: 0:00:00  Lr: 0.001875  Loss: -0.8476  Acc@1: 87.5000 (85.5000)  Acc@5: 100.0000 (98.1600)  time: 0.3227  data: 0.0003  max mem: 2362
Train: Epoch[1/5] Total time: 0:01:43 (0.3320 s / it)
Averaged stats: Lr: 0.001875  Loss: -0.8476  Acc@1: 87.5000 (85.5000)  Acc@5: 100.0000 (98.1600)
Train: Epoch[2/5]  [  0/313]  eta: 0:03:43  Lr: 0.001875  Loss: -0.3767  Acc@1: 68.7500 (68.7500)  Acc@5: 100.0000 (100.0000)  time: 0.7134  data: 0.3810  max mem: 2362
Train: Epoch[2/5]  [ 10/313]  eta: 0:01:51  Lr: 0.001875  Loss: -0.9439  Acc@1: 87.5000 (89.2045)  Acc@5: 100.0000 (100.0000)  time: 0.3664  data: 0.0350  max mem: 2362
Train: Epoch[2/5]  [ 20/313]  eta: 0:01:42  Lr: 0.001875  Loss: -0.8668  Acc@1: 87.5000 (86.9048)  Acc@5: 100.0000 (99.1071)  time: 0.3315  data: 0.0004  max mem: 2362
Train: Epoch[2/5]  [ 30/313]  eta: 0:01:37  Lr: 0.001875  Loss: -0.7160  Acc@1: 87.5000 (86.4919)  Acc@5: 100.0000 (98.7903)  time: 0.3312  data: 0.0004  max mem: 2362
Train: Epoch[2/5]  [ 40/313]  eta: 0:01:32  Lr: 0.001875  Loss: -0.7595  Acc@1: 87.5000 (86.5854)  Acc@5: 100.0000 (98.9329)  time: 0.3310  data: 0.0004  max mem: 2362
Train: Epoch[2/5]  [ 50/313]  eta: 0:01:29  Lr: 0.001875  Loss: -0.5903  Acc@1: 87.5000 (86.3971)  Acc@5: 100.0000 (99.1422)  time: 0.3309  data: 0.0004  max mem: 2362
Train: Epoch[2/5]  [ 60/313]  eta: 0:01:25  Lr: 0.001875  Loss: -0.8211  Acc@1: 87.5000 (86.5779)  Acc@5: 100.0000 (99.1803)  time: 0.3312  data: 0.0004  max mem: 2362
Train: Epoch[2/5]  [ 70/313]  eta: 0:01:21  Lr: 0.001875  Loss: -0.7353  Acc@1: 87.5000 (86.7958)  Acc@5: 100.0000 (99.2077)  time: 0.3311  data: 0.0005  max mem: 2362
Train: Epoch[2/5]  [ 80/313]  eta: 0:01:18  Lr: 0.001875  Loss: -0.6397  Acc@1: 87.5000 (86.8056)  Acc@5: 100.0000 (99.3056)  time: 0.3304  data: 0.0005  max mem: 2362
Train: Epoch[2/5]  [ 90/313]  eta: 0:01:14  Lr: 0.001875  Loss: -0.6134  Acc@1: 87.5000 (87.0879)  Acc@5: 100.0000 (99.3819)  time: 0.3302  data: 0.0003  max mem: 2362
Train: Epoch[2/5]  [100/313]  eta: 0:01:11  Lr: 0.001875  Loss: -0.5002  Acc@1: 87.5000 (86.6955)  Acc@5: 100.0000 (99.1955)  time: 0.3304  data: 0.0004  max mem: 2362
Train: Epoch[2/5]  [110/313]  eta: 0:01:07  Lr: 0.001875  Loss: -0.6131  Acc@1: 87.5000 (86.5991)  Acc@5: 100.0000 (99.2117)  time: 0.3307  data: 0.0004  max mem: 2362
Train: Epoch[2/5]  [120/313]  eta: 0:01:04  Lr: 0.001875  Loss: -0.6790  Acc@1: 87.5000 (86.6736)  Acc@5: 100.0000 (99.1736)  time: 0.3310  data: 0.0004  max mem: 2362
Train: Epoch[2/5]  [130/313]  eta: 0:01:01  Lr: 0.001875  Loss: -0.7855  Acc@1: 87.5000 (86.7844)  Acc@5: 100.0000 (99.1412)  time: 0.3309  data: 0.0005  max mem: 2362
Train: Epoch[2/5]  [140/313]  eta: 0:00:57  Lr: 0.001875  Loss: -0.5523  Acc@1: 87.5000 (86.5691)  Acc@5: 100.0000 (99.1135)  time: 0.3311  data: 0.0005  max mem: 2362
Train: Epoch[2/5]  [150/313]  eta: 0:00:54  Lr: 0.001875  Loss: -1.0000  Acc@1: 87.5000 (86.8377)  Acc@5: 100.0000 (99.0480)  time: 0.3313  data: 0.0004  max mem: 2362
Train: Epoch[2/5]  [160/313]  eta: 0:00:51  Lr: 0.001875  Loss: -0.4947  Acc@1: 93.7500 (86.9953)  Acc@5: 100.0000 (99.0295)  time: 0.3319  data: 0.0004  max mem: 2362
Train: Epoch[2/5]  [170/313]  eta: 0:00:47  Lr: 0.001875  Loss: -0.7353  Acc@1: 87.5000 (86.9518)  Acc@5: 100.0000 (99.0132)  time: 0.3320  data: 0.0003  max mem: 2362
Train: Epoch[2/5]  [180/313]  eta: 0:00:44  Lr: 0.001875  Loss: -0.6290  Acc@1: 87.5000 (87.1202)  Acc@5: 100.0000 (98.9986)  time: 0.3317  data: 0.0004  max mem: 2362
Train: Epoch[2/5]  [190/313]  eta: 0:00:40  Lr: 0.001875  Loss: -0.4990  Acc@1: 87.5000 (87.0746)  Acc@5: 100.0000 (98.9529)  time: 0.3312  data: 0.0004  max mem: 2362
Train: Epoch[2/5]  [200/313]  eta: 0:00:37  Lr: 0.001875  Loss: -0.7937  Acc@1: 87.5000 (87.0025)  Acc@5: 100.0000 (98.8806)  time: 0.3308  data: 0.0004  max mem: 2362
Train: Epoch[2/5]  [210/313]  eta: 0:00:34  Lr: 0.001875  Loss: -0.7906  Acc@1: 87.5000 (87.1742)  Acc@5: 100.0000 (98.9040)  time: 0.3307  data: 0.0004  max mem: 2362
Train: Epoch[2/5]  [220/313]  eta: 0:00:30  Lr: 0.001875  Loss: -0.8769  Acc@1: 87.5000 (87.3303)  Acc@5: 100.0000 (98.9253)  time: 0.3308  data: 0.0004  max mem: 2362
Train: Epoch[2/5]  [230/313]  eta: 0:00:27  Lr: 0.001875  Loss: -0.6188  Acc@1: 87.5000 (87.2024)  Acc@5: 100.0000 (98.9177)  time: 0.3315  data: 0.0011  max mem: 2362
Train: Epoch[2/5]  [240/313]  eta: 0:00:24  Lr: 0.001875  Loss: -0.6851  Acc@1: 81.2500 (87.0591)  Acc@5: 100.0000 (98.9627)  time: 0.3313  data: 0.0010  max mem: 2362
Train: Epoch[2/5]  [250/313]  eta: 0:00:20  Lr: 0.001875  Loss: -0.6302  Acc@1: 87.5000 (87.0767)  Acc@5: 100.0000 (98.9791)  time: 0.3307  data: 0.0004  max mem: 2362
Train: Epoch[2/5]  [260/313]  eta: 0:00:17  Lr: 0.001875  Loss: -0.9056  Acc@1: 87.5000 (87.1887)  Acc@5: 100.0000 (98.9943)  time: 0.3313  data: 0.0004  max mem: 2362
Train: Epoch[2/5]  [270/313]  eta: 0:00:14  Lr: 0.001875  Loss: -0.7772  Acc@1: 87.5000 (87.2463)  Acc@5: 100.0000 (99.0314)  time: 0.3324  data: 0.0004  max mem: 2362
Train: Epoch[2/5]  [280/313]  eta: 0:00:10  Lr: 0.001875  Loss: -0.6972  Acc@1: 87.5000 (87.1886)  Acc@5: 100.0000 (99.0214)  time: 0.3320  data: 0.0004  max mem: 2362
Train: Epoch[2/5]  [290/313]  eta: 0:00:07  Lr: 0.001875  Loss: -0.4026  Acc@1: 87.5000 (87.2208)  Acc@5: 100.0000 (99.0120)  time: 0.3315  data: 0.0005  max mem: 2362
Train: Epoch[2/5]  [300/313]  eta: 0:00:04  Lr: 0.001875  Loss: -0.7473  Acc@1: 87.5000 (87.1678)  Acc@5: 100.0000 (99.0449)  time: 0.3314  data: 0.0007  max mem: 2362
Train: Epoch[2/5]  [310/313]  eta: 0:00:00  Lr: 0.001875  Loss: -0.8935  Acc@1: 87.5000 (87.3392)  Acc@5: 100.0000 (99.0555)  time: 0.3310  data: 0.0006  max mem: 2362
Train: Epoch[2/5]  [312/313]  eta: 0:00:00  Lr: 0.001875  Loss: -0.8678  Acc@1: 87.5000 (87.3600)  Acc@5: 100.0000 (99.0600)  time: 0.3228  data: 0.0006  max mem: 2362
Train: Epoch[2/5] Total time: 0:01:44 (0.3323 s / it)
Averaged stats: Lr: 0.001875  Loss: -0.8678  Acc@1: 87.5000 (87.3600)  Acc@5: 100.0000 (99.0600)
Train: Epoch[3/5]  [  0/313]  eta: 0:04:00  Lr: 0.001875  Loss: -0.5764  Acc@1: 81.2500 (81.2500)  Acc@5: 93.7500 (93.7500)  time: 0.7675  data: 0.4348  max mem: 2362
Train: Epoch[3/5]  [ 10/313]  eta: 0:01:52  Lr: 0.001875  Loss: -0.8184  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (99.4318)  time: 0.3719  data: 0.0399  max mem: 2362
Train: Epoch[3/5]  [ 20/313]  eta: 0:01:43  Lr: 0.001875  Loss: -0.6991  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (99.7024)  time: 0.3321  data: 0.0005  max mem: 2362
Train: Epoch[3/5]  [ 30/313]  eta: 0:01:38  Lr: 0.001875  Loss: -0.9088  Acc@1: 87.5000 (88.5081)  Acc@5: 100.0000 (99.5968)  time: 0.3323  data: 0.0004  max mem: 2362
Train: Epoch[3/5]  [ 40/313]  eta: 0:01:33  Lr: 0.001875  Loss: -1.0767  Acc@1: 87.5000 (87.9573)  Acc@5: 100.0000 (99.2378)  time: 0.3327  data: 0.0004  max mem: 2362
Train: Epoch[3/5]  [ 50/313]  eta: 0:01:29  Lr: 0.001875  Loss: -0.9371  Acc@1: 87.5000 (87.6225)  Acc@5: 100.0000 (99.2647)  time: 0.3317  data: 0.0004  max mem: 2362
Train: Epoch[3/5]  [ 60/313]  eta: 0:01:25  Lr: 0.001875  Loss: -0.8314  Acc@1: 93.7500 (88.0123)  Acc@5: 100.0000 (99.2828)  time: 0.3319  data: 0.0004  max mem: 2362
Train: Epoch[3/5]  [ 70/313]  eta: 0:01:22  Lr: 0.001875  Loss: -0.5543  Acc@1: 87.5000 (87.7641)  Acc@5: 100.0000 (99.2077)  time: 0.3318  data: 0.0004  max mem: 2362
Train: Epoch[3/5]  [ 80/313]  eta: 0:01:18  Lr: 0.001875  Loss: -0.4719  Acc@1: 87.5000 (87.6543)  Acc@5: 100.0000 (99.1512)  time: 0.3311  data: 0.0004  max mem: 2362
Train: Epoch[3/5]  [ 90/313]  eta: 0:01:15  Lr: 0.001875  Loss: -0.7136  Acc@1: 87.5000 (87.4313)  Acc@5: 100.0000 (99.1071)  time: 0.3321  data: 0.0004  max mem: 2362
Train: Epoch[3/5]  [100/313]  eta: 0:01:11  Lr: 0.001875  Loss: -0.8312  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (99.1337)  time: 0.3324  data: 0.0004  max mem: 2362
Train: Epoch[3/5]  [110/313]  eta: 0:01:08  Lr: 0.001875  Loss: -0.7655  Acc@1: 93.7500 (87.8378)  Acc@5: 100.0000 (99.1554)  time: 0.3322  data: 0.0004  max mem: 2362
Train: Epoch[3/5]  [120/313]  eta: 0:01:04  Lr: 0.001875  Loss: -0.5749  Acc@1: 93.7500 (87.9649)  Acc@5: 100.0000 (99.2252)  time: 0.3319  data: 0.0004  max mem: 2362
Train: Epoch[3/5]  [130/313]  eta: 0:01:01  Lr: 0.001875  Loss: -0.9657  Acc@1: 87.5000 (88.0725)  Acc@5: 100.0000 (99.2366)  time: 0.3310  data: 0.0004  max mem: 2362
Train: Epoch[3/5]  [140/313]  eta: 0:00:57  Lr: 0.001875  Loss: -0.8369  Acc@1: 87.5000 (88.1206)  Acc@5: 100.0000 (99.2021)  time: 0.3307  data: 0.0004  max mem: 2362
Train: Epoch[3/5]  [150/313]  eta: 0:00:54  Lr: 0.001875  Loss: -0.8327  Acc@1: 87.5000 (88.3692)  Acc@5: 100.0000 (99.2550)  time: 0.3316  data: 0.0004  max mem: 2362
Train: Epoch[3/5]  [160/313]  eta: 0:00:51  Lr: 0.001875  Loss: -0.5692  Acc@1: 93.7500 (88.5870)  Acc@5: 100.0000 (99.2624)  time: 0.3319  data: 0.0004  max mem: 2362
Train: Epoch[3/5]  [170/313]  eta: 0:00:47  Lr: 0.001875  Loss: -0.6261  Acc@1: 93.7500 (88.5599)  Acc@5: 100.0000 (99.1959)  time: 0.3317  data: 0.0004  max mem: 2362
Train: Epoch[3/5]  [180/313]  eta: 0:00:44  Lr: 0.001875  Loss: -0.7258  Acc@1: 87.5000 (88.2942)  Acc@5: 100.0000 (99.2403)  time: 0.3317  data: 0.0004  max mem: 2362
Train: Epoch[3/5]  [190/313]  eta: 0:00:41  Lr: 0.001875  Loss: -1.0323  Acc@1: 87.5000 (88.4490)  Acc@5: 100.0000 (99.2801)  time: 0.3310  data: 0.0004  max mem: 2362
Train: Epoch[3/5]  [200/313]  eta: 0:00:37  Lr: 0.001875  Loss: -0.8097  Acc@1: 93.7500 (88.5261)  Acc@5: 100.0000 (99.2537)  time: 0.3312  data: 0.0004  max mem: 2362
Train: Epoch[3/5]  [210/313]  eta: 0:00:34  Lr: 0.001875  Loss: -0.4441  Acc@1: 87.5000 (88.4775)  Acc@5: 100.0000 (99.2595)  time: 0.3321  data: 0.0004  max mem: 2362
Train: Epoch[3/5]  [220/313]  eta: 0:00:31  Lr: 0.001875  Loss: -0.9784  Acc@1: 87.5000 (88.7161)  Acc@5: 100.0000 (99.2647)  time: 0.3318  data: 0.0005  max mem: 2362
Train: Epoch[3/5]  [230/313]  eta: 0:00:27  Lr: 0.001875  Loss: -0.7566  Acc@1: 93.7500 (88.6905)  Acc@5: 100.0000 (99.2424)  time: 0.3318  data: 0.0005  max mem: 2362
Train: Epoch[3/5]  [240/313]  eta: 0:00:24  Lr: 0.001875  Loss: -0.7589  Acc@1: 87.5000 (88.6929)  Acc@5: 100.0000 (99.2739)  time: 0.3314  data: 0.0005  max mem: 2362
Train: Epoch[3/5]  [250/313]  eta: 0:00:21  Lr: 0.001875  Loss: -0.9522  Acc@1: 87.5000 (88.6703)  Acc@5: 100.0000 (99.2779)  time: 0.3305  data: 0.0004  max mem: 2362
Train: Epoch[3/5]  [260/313]  eta: 0:00:17  Lr: 0.001875  Loss: -0.6279  Acc@1: 87.5000 (88.6494)  Acc@5: 100.0000 (99.2098)  time: 0.3311  data: 0.0004  max mem: 2362
Train: Epoch[3/5]  [270/313]  eta: 0:00:14  Lr: 0.001875  Loss: -0.7602  Acc@1: 87.5000 (88.5609)  Acc@5: 100.0000 (99.2389)  time: 0.3316  data: 0.0004  max mem: 2362
Train: Epoch[3/5]  [280/313]  eta: 0:00:10  Lr: 0.001875  Loss: -0.8651  Acc@1: 87.5000 (88.5454)  Acc@5: 100.0000 (99.2438)  time: 0.3315  data: 0.0005  max mem: 2362
Train: Epoch[3/5]  [290/313]  eta: 0:00:07  Lr: 0.001875  Loss: -0.7593  Acc@1: 87.5000 (88.5309)  Acc@5: 100.0000 (99.2698)  time: 0.3312  data: 0.0004  max mem: 2362
Train: Epoch[3/5]  [300/313]  eta: 0:00:04  Lr: 0.001875  Loss: -0.6208  Acc@1: 87.5000 (88.5590)  Acc@5: 100.0000 (99.2733)  time: 0.3313  data: 0.0004  max mem: 2362
Train: Epoch[3/5]  [310/313]  eta: 0:00:00  Lr: 0.001875  Loss: -0.1390  Acc@1: 87.5000 (88.4244)  Acc@5: 100.0000 (99.2564)  time: 0.3313  data: 0.0004  max mem: 2362
Train: Epoch[3/5]  [312/313]  eta: 0:00:00  Lr: 0.001875  Loss: -0.6677  Acc@1: 87.5000 (88.4000)  Acc@5: 100.0000 (99.2600)  time: 0.3232  data: 0.0004  max mem: 2362
Train: Epoch[3/5] Total time: 0:01:44 (0.3330 s / it)
Averaged stats: Lr: 0.001875  Loss: -0.6677  Acc@1: 87.5000 (88.4000)  Acc@5: 100.0000 (99.2600)
Train: Epoch[4/5]  [  0/313]  eta: 0:03:40  Lr: 0.001875  Loss: -0.7842  Acc@1: 81.2500 (81.2500)  Acc@5: 100.0000 (100.0000)  time: 0.7051  data: 0.3679  max mem: 2362
Train: Epoch[4/5]  [ 10/313]  eta: 0:01:50  Lr: 0.001875  Loss: -0.7042  Acc@1: 87.5000 (88.0682)  Acc@5: 100.0000 (99.4318)  time: 0.3650  data: 0.0338  max mem: 2362
Train: Epoch[4/5]  [ 20/313]  eta: 0:01:42  Lr: 0.001875  Loss: -0.4347  Acc@1: 93.7500 (89.2857)  Acc@5: 100.0000 (99.4048)  time: 0.3313  data: 0.0004  max mem: 2362
Train: Epoch[4/5]  [ 30/313]  eta: 0:01:37  Lr: 0.001875  Loss: -0.6822  Acc@1: 93.7500 (89.9194)  Acc@5: 100.0000 (99.3952)  time: 0.3312  data: 0.0004  max mem: 2362
Train: Epoch[4/5]  [ 40/313]  eta: 0:01:32  Lr: 0.001875  Loss: -0.8206  Acc@1: 87.5000 (88.4146)  Acc@5: 100.0000 (99.2378)  time: 0.3304  data: 0.0004  max mem: 2362
Train: Epoch[4/5]  [ 50/313]  eta: 0:01:28  Lr: 0.001875  Loss: -0.7785  Acc@1: 93.7500 (89.4608)  Acc@5: 100.0000 (99.1422)  time: 0.3302  data: 0.0004  max mem: 2362
Train: Epoch[4/5]  [ 60/313]  eta: 0:01:25  Lr: 0.001875  Loss: -0.9729  Acc@1: 93.7500 (89.2418)  Acc@5: 100.0000 (99.0779)  time: 0.3305  data: 0.0004  max mem: 2362
Train: Epoch[4/5]  [ 70/313]  eta: 0:01:21  Lr: 0.001875  Loss: -1.0702  Acc@1: 87.5000 (88.7324)  Acc@5: 100.0000 (99.0317)  time: 0.3309  data: 0.0004  max mem: 2362
Train: Epoch[4/5]  [ 80/313]  eta: 0:01:18  Lr: 0.001875  Loss: -0.5164  Acc@1: 87.5000 (88.8117)  Acc@5: 100.0000 (99.0741)  time: 0.3311  data: 0.0004  max mem: 2362
Train: Epoch[4/5]  [ 90/313]  eta: 0:01:14  Lr: 0.001875  Loss: -1.0792  Acc@1: 93.7500 (89.0110)  Acc@5: 100.0000 (99.1071)  time: 0.3311  data: 0.0004  max mem: 2362
Train: Epoch[4/5]  [100/313]  eta: 0:01:11  Lr: 0.001875  Loss: -0.8981  Acc@1: 87.5000 (88.6757)  Acc@5: 100.0000 (99.1337)  time: 0.3307  data: 0.0004  max mem: 2362
Train: Epoch[4/5]  [110/313]  eta: 0:01:07  Lr: 0.001875  Loss: -0.3669  Acc@1: 87.5000 (88.5135)  Acc@5: 100.0000 (99.1554)  time: 0.3307  data: 0.0005  max mem: 2362
Train: Epoch[4/5]  [120/313]  eta: 0:01:04  Lr: 0.001875  Loss: -0.3823  Acc@1: 87.5000 (88.6364)  Acc@5: 100.0000 (99.1736)  time: 0.3313  data: 0.0006  max mem: 2362
Train: Epoch[4/5]  [130/313]  eta: 0:01:01  Lr: 0.001875  Loss: -0.6843  Acc@1: 87.5000 (88.4542)  Acc@5: 100.0000 (99.1889)  time: 0.3311  data: 0.0006  max mem: 2362
Train: Epoch[4/5]  [140/313]  eta: 0:00:57  Lr: 0.001875  Loss: -0.8477  Acc@1: 87.5000 (88.5638)  Acc@5: 100.0000 (99.1578)  time: 0.3307  data: 0.0004  max mem: 2362
Train: Epoch[4/5]  [150/313]  eta: 0:00:54  Lr: 0.001875  Loss: -0.8746  Acc@1: 87.5000 (88.5762)  Acc@5: 100.0000 (99.1308)  time: 0.3308  data: 0.0006  max mem: 2362
Train: Epoch[4/5]  [160/313]  eta: 0:00:50  Lr: 0.001875  Loss: -0.9521  Acc@1: 93.7500 (88.7811)  Acc@5: 100.0000 (99.1848)  time: 0.3306  data: 0.0006  max mem: 2362
Train: Epoch[4/5]  [170/313]  eta: 0:00:47  Lr: 0.001875  Loss: -1.0422  Acc@1: 93.7500 (88.9620)  Acc@5: 100.0000 (99.2325)  time: 0.3305  data: 0.0004  max mem: 2362
Train: Epoch[4/5]  [180/313]  eta: 0:00:44  Lr: 0.001875  Loss: -0.8346  Acc@1: 93.7500 (89.0884)  Acc@5: 100.0000 (99.2403)  time: 0.3304  data: 0.0004  max mem: 2362
Train: Epoch[4/5]  [190/313]  eta: 0:00:40  Lr: 0.001875  Loss: -0.9105  Acc@1: 93.7500 (88.9725)  Acc@5: 100.0000 (99.2147)  time: 0.3304  data: 0.0004  max mem: 2362
Train: Epoch[4/5]  [200/313]  eta: 0:00:37  Lr: 0.001875  Loss: -0.9361  Acc@1: 93.7500 (89.0547)  Acc@5: 100.0000 (99.2226)  time: 0.3313  data: 0.0007  max mem: 2362
Train: Epoch[4/5]  [210/313]  eta: 0:00:34  Lr: 0.001875  Loss: -0.5498  Acc@1: 93.7500 (89.1588)  Acc@5: 100.0000 (99.1706)  time: 0.3317  data: 0.0007  max mem: 2362
Train: Epoch[4/5]  [220/313]  eta: 0:00:30  Lr: 0.001875  Loss: -0.7953  Acc@1: 93.7500 (89.2534)  Acc@5: 100.0000 (99.1516)  time: 0.3313  data: 0.0004  max mem: 2362
Train: Epoch[4/5]  [230/313]  eta: 0:00:27  Lr: 0.001875  Loss: -0.8116  Acc@1: 93.7500 (89.3128)  Acc@5: 100.0000 (99.1342)  time: 0.3310  data: 0.0004  max mem: 2362
Train: Epoch[4/5]  [240/313]  eta: 0:00:24  Lr: 0.001875  Loss: -0.8079  Acc@1: 87.5000 (89.3413)  Acc@5: 100.0000 (99.1701)  time: 0.3304  data: 0.0004  max mem: 2362
Train: Epoch[4/5]  [250/313]  eta: 0:00:20  Lr: 0.001875  Loss: -0.4807  Acc@1: 87.5000 (89.2679)  Acc@5: 100.0000 (99.2032)  time: 0.3304  data: 0.0005  max mem: 2362
Train: Epoch[4/5]  [260/313]  eta: 0:00:17  Lr: 0.001875  Loss: -0.6950  Acc@1: 87.5000 (89.2002)  Acc@5: 100.0000 (99.1619)  time: 0.3307  data: 0.0004  max mem: 2362
Train: Epoch[4/5]  [270/313]  eta: 0:00:14  Lr: 0.001875  Loss: -0.7940  Acc@1: 93.7500 (89.3681)  Acc@5: 100.0000 (99.1697)  time: 0.3303  data: 0.0009  max mem: 2362
Train: Epoch[4/5]  [280/313]  eta: 0:00:10  Lr: 0.001875  Loss: -0.8815  Acc@1: 93.7500 (89.4128)  Acc@5: 100.0000 (99.1770)  time: 0.3302  data: 0.0009  max mem: 2362
Train: Epoch[4/5]  [290/313]  eta: 0:00:07  Lr: 0.001875  Loss: -0.8903  Acc@1: 93.7500 (89.5189)  Acc@5: 100.0000 (99.2053)  time: 0.3308  data: 0.0004  max mem: 2362
Train: Epoch[4/5]  [300/313]  eta: 0:00:04  Lr: 0.001875  Loss: -0.5967  Acc@1: 93.7500 (89.4934)  Acc@5: 100.0000 (99.1902)  time: 0.3310  data: 0.0005  max mem: 2362
Train: Epoch[4/5]  [310/313]  eta: 0:00:00  Lr: 0.001875  Loss: -0.9410  Acc@1: 87.5000 (89.5297)  Acc@5: 100.0000 (99.1961)  time: 0.3310  data: 0.0004  max mem: 2362
Train: Epoch[4/5]  [312/313]  eta: 0:00:00  Lr: 0.001875  Loss: -0.9924  Acc@1: 93.7500 (89.5800)  Acc@5: 100.0000 (99.2000)  time: 0.3227  data: 0.0004  max mem: 2362
Train: Epoch[4/5] Total time: 0:01:43 (0.3320 s / it)
Averaged stats: Lr: 0.001875  Loss: -0.9924  Acc@1: 93.7500 (89.5800)  Acc@5: 100.0000 (99.2000)
Train: Epoch[5/5]  [  0/313]  eta: 0:03:52  Lr: 0.001875  Loss: -0.7778  Acc@1: 81.2500 (81.2500)  Acc@5: 100.0000 (100.0000)  time: 0.7440  data: 0.4076  max mem: 2362
Train: Epoch[5/5]  [ 10/313]  eta: 0:01:51  Lr: 0.001875  Loss: -0.8991  Acc@1: 93.7500 (89.2045)  Acc@5: 100.0000 (98.8636)  time: 0.3679  data: 0.0375  max mem: 2362
Train: Epoch[5/5]  [ 20/313]  eta: 0:01:42  Lr: 0.001875  Loss: -0.8351  Acc@1: 93.7500 (89.5833)  Acc@5: 100.0000 (99.1071)  time: 0.3307  data: 0.0004  max mem: 2362
Train: Epoch[5/5]  [ 30/313]  eta: 0:01:37  Lr: 0.001875  Loss: -0.8628  Acc@1: 87.5000 (89.3145)  Acc@5: 100.0000 (99.1935)  time: 0.3315  data: 0.0006  max mem: 2362
Train: Epoch[5/5]  [ 40/313]  eta: 0:01:33  Lr: 0.001875  Loss: -0.7659  Acc@1: 87.5000 (89.0244)  Acc@5: 100.0000 (99.3902)  time: 0.3318  data: 0.0006  max mem: 2362
Train: Epoch[5/5]  [ 50/313]  eta: 0:01:29  Lr: 0.001875  Loss: -0.7803  Acc@1: 87.5000 (88.3578)  Acc@5: 100.0000 (99.2647)  time: 0.3320  data: 0.0005  max mem: 2362
Train: Epoch[5/5]  [ 60/313]  eta: 0:01:25  Lr: 0.001875  Loss: -0.8943  Acc@1: 93.7500 (88.8320)  Acc@5: 100.0000 (99.3852)  time: 0.3314  data: 0.0005  max mem: 2362
Train: Epoch[5/5]  [ 70/313]  eta: 0:01:21  Lr: 0.001875  Loss: -0.4169  Acc@1: 93.7500 (88.7324)  Acc@5: 100.0000 (99.2077)  time: 0.3308  data: 0.0005  max mem: 2362
Train: Epoch[5/5]  [ 80/313]  eta: 0:01:18  Lr: 0.001875  Loss: -1.0044  Acc@1: 87.5000 (88.6574)  Acc@5: 100.0000 (99.2284)  time: 0.3319  data: 0.0005  max mem: 2362
Train: Epoch[5/5]  [ 90/313]  eta: 0:01:14  Lr: 0.001875  Loss: -0.8431  Acc@1: 87.5000 (88.9423)  Acc@5: 100.0000 (99.2445)  time: 0.3317  data: 0.0006  max mem: 2362
Train: Epoch[5/5]  [100/313]  eta: 0:01:11  Lr: 0.001875  Loss: -0.8359  Acc@1: 93.7500 (89.2946)  Acc@5: 100.0000 (99.3193)  time: 0.3316  data: 0.0005  max mem: 2362
Train: Epoch[5/5]  [110/313]  eta: 0:01:08  Lr: 0.001875  Loss: -0.5969  Acc@1: 87.5000 (88.7950)  Acc@5: 100.0000 (99.3243)  time: 0.3317  data: 0.0005  max mem: 2362
Train: Epoch[5/5]  [120/313]  eta: 0:01:04  Lr: 0.001875  Loss: -0.8225  Acc@1: 87.5000 (88.6880)  Acc@5: 100.0000 (99.2769)  time: 0.3313  data: 0.0005  max mem: 2362
Train: Epoch[5/5]  [130/313]  eta: 0:01:01  Lr: 0.001875  Loss: -1.1164  Acc@1: 87.5000 (88.7405)  Acc@5: 100.0000 (99.3321)  time: 0.3313  data: 0.0005  max mem: 2362
Train: Epoch[5/5]  [140/313]  eta: 0:00:57  Lr: 0.001875  Loss: -0.9384  Acc@1: 93.7500 (88.8298)  Acc@5: 100.0000 (99.3794)  time: 0.3310  data: 0.0004  max mem: 2362
Train: Epoch[5/5]  [150/313]  eta: 0:00:54  Lr: 0.001875  Loss: -1.0371  Acc@1: 87.5000 (88.9073)  Acc@5: 100.0000 (99.3791)  time: 0.3310  data: 0.0004  max mem: 2362
Train: Epoch[5/5]  [160/313]  eta: 0:00:51  Lr: 0.001875  Loss: -0.7204  Acc@1: 93.7500 (89.1304)  Acc@5: 100.0000 (99.3012)  time: 0.3315  data: 0.0004  max mem: 2362
Train: Epoch[5/5]  [170/313]  eta: 0:00:47  Lr: 0.001875  Loss: -0.8975  Acc@1: 93.7500 (89.0716)  Acc@5: 100.0000 (99.3056)  time: 0.3317  data: 0.0004  max mem: 2362
Train: Epoch[5/5]  [180/313]  eta: 0:00:44  Lr: 0.001875  Loss: -0.6819  Acc@1: 87.5000 (88.9848)  Acc@5: 100.0000 (99.3094)  time: 0.3311  data: 0.0005  max mem: 2362
Train: Epoch[5/5]  [190/313]  eta: 0:00:41  Lr: 0.001875  Loss: -1.0919  Acc@1: 93.7500 (89.1034)  Acc@5: 100.0000 (99.2801)  time: 0.3310  data: 0.0005  max mem: 2362
Train: Epoch[5/5]  [200/313]  eta: 0:00:37  Lr: 0.001875  Loss: -0.5108  Acc@1: 93.7500 (89.2413)  Acc@5: 100.0000 (99.2848)  time: 0.3317  data: 0.0005  max mem: 2362
Train: Epoch[5/5]  [210/313]  eta: 0:00:34  Lr: 0.001875  Loss: -0.8539  Acc@1: 87.5000 (89.0995)  Acc@5: 100.0000 (99.2891)  time: 0.3315  data: 0.0005  max mem: 2362
Train: Epoch[5/5]  [220/313]  eta: 0:00:30  Lr: 0.001875  Loss: -0.8306  Acc@1: 87.5000 (89.0554)  Acc@5: 100.0000 (99.3213)  time: 0.3308  data: 0.0004  max mem: 2362
Train: Epoch[5/5]  [230/313]  eta: 0:00:27  Lr: 0.001875  Loss: -0.9307  Acc@1: 87.5000 (89.0152)  Acc@5: 100.0000 (99.3506)  time: 0.3308  data: 0.0004  max mem: 2362
Train: Epoch[5/5]  [240/313]  eta: 0:00:24  Lr: 0.001875  Loss: -0.8410  Acc@1: 93.7500 (89.1079)  Acc@5: 100.0000 (99.3776)  time: 0.3310  data: 0.0004  max mem: 2362
Train: Epoch[5/5]  [250/313]  eta: 0:00:20  Lr: 0.001875  Loss: -0.8088  Acc@1: 93.7500 (89.0936)  Acc@5: 100.0000 (99.3775)  time: 0.3313  data: 0.0005  max mem: 2362
Train: Epoch[5/5]  [260/313]  eta: 0:00:17  Lr: 0.001875  Loss: -1.0359  Acc@1: 93.7500 (89.1523)  Acc@5: 100.0000 (99.3774)  time: 0.3315  data: 0.0004  max mem: 2362
Train: Epoch[5/5]  [270/313]  eta: 0:00:14  Lr: 0.001875  Loss: -0.7973  Acc@1: 93.7500 (89.0913)  Acc@5: 100.0000 (99.2851)  time: 0.3313  data: 0.0005  max mem: 2362
Train: Epoch[5/5]  [280/313]  eta: 0:00:10  Lr: 0.001875  Loss: -0.8093  Acc@1: 93.7500 (89.2126)  Acc@5: 100.0000 (99.2883)  time: 0.3316  data: 0.0006  max mem: 2362
Train: Epoch[5/5]  [290/313]  eta: 0:00:07  Lr: 0.001875  Loss: -0.6963  Acc@1: 93.7500 (89.2182)  Acc@5: 100.0000 (99.2912)  time: 0.3314  data: 0.0007  max mem: 2362
Train: Epoch[5/5]  [300/313]  eta: 0:00:04  Lr: 0.001875  Loss: -0.6796  Acc@1: 87.5000 (89.1404)  Acc@5: 100.0000 (99.2940)  time: 0.3309  data: 0.0005  max mem: 2362
Train: Epoch[5/5]  [310/313]  eta: 0:00:00  Lr: 0.001875  Loss: -0.7717  Acc@1: 87.5000 (89.2283)  Acc@5: 100.0000 (99.2966)  time: 0.3310  data: 0.0005  max mem: 2362
Train: Epoch[5/5]  [312/313]  eta: 0:00:00  Lr: 0.001875  Loss: -0.9674  Acc@1: 87.5000 (89.2200)  Acc@5: 100.0000 (99.3000)  time: 0.3231  data: 0.0005  max mem: 2362
Train: Epoch[5/5] Total time: 0:01:44 (0.3325 s / it)
Averaged stats: Lr: 0.001875  Loss: -0.9674  Acc@1: 87.5000 (89.2200)  Acc@5: 100.0000 (99.3000)
Test: [Task 1]  [ 0/63]  eta: 0:00:40  Loss: 0.6905 (0.6905)  Acc@1: 75.0000 (75.0000)  Acc@5: 100.0000 (100.0000)  time: 0.6481  data: 0.4404  max mem: 2362
Test: [Task 1]  [10/63]  eta: 0:00:13  Loss: 0.6041 (0.6006)  Acc@1: 87.5000 (85.2273)  Acc@5: 100.0000 (99.4318)  time: 0.2459  data: 0.0403  max mem: 2362
Test: [Task 1]  [20/63]  eta: 0:00:09  Loss: 0.6041 (0.6766)  Acc@1: 81.2500 (83.0357)  Acc@5: 100.0000 (98.2143)  time: 0.2058  data: 0.0004  max mem: 2362
Test: [Task 1]  [30/63]  eta: 0:00:07  Loss: 0.5557 (0.6364)  Acc@1: 81.2500 (84.4758)  Acc@5: 100.0000 (98.3871)  time: 0.2060  data: 0.0004  max mem: 2362
Test: [Task 1]  [40/63]  eta: 0:00:04  Loss: 0.4551 (0.6157)  Acc@1: 87.5000 (85.5183)  Acc@5: 100.0000 (98.6280)  time: 0.2062  data: 0.0004  max mem: 2362
Test: [Task 1]  [50/63]  eta: 0:00:02  Loss: 0.4570 (0.5994)  Acc@1: 87.5000 (86.0294)  Acc@5: 100.0000 (98.5294)  time: 0.2065  data: 0.0004  max mem: 2362
Test: [Task 1]  [60/63]  eta: 0:00:00  Loss: 0.4761 (0.5900)  Acc@1: 87.5000 (86.3730)  Acc@5: 100.0000 (98.7705)  time: 0.2065  data: 0.0003  max mem: 2362
Test: [Task 1]  [62/63]  eta: 0:00:00  Loss: 0.4570 (0.5857)  Acc@1: 87.5000 (86.6000)  Acc@5: 100.0000 (98.8000)  time: 0.2017  data: 0.0003  max mem: 2362
Test: [Task 1] Total time: 0:00:13 (0.2140 s / it)
* Acc@1 86.600 Acc@5 98.800 loss 0.586
Test: [Task 2]  [ 0/63]  eta: 0:00:39  Loss: 0.8261 (0.8261)  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (100.0000)  time: 0.6296  data: 0.4214  max mem: 2362
Test: [Task 2]  [10/63]  eta: 0:00:12  Loss: 0.6871 (0.7353)  Acc@1: 87.5000 (85.7955)  Acc@5: 100.0000 (97.7273)  time: 0.2450  data: 0.0387  max mem: 2362
Test: [Task 2]  [20/63]  eta: 0:00:09  Loss: 0.7196 (0.8152)  Acc@1: 81.2500 (83.0357)  Acc@5: 100.0000 (97.6190)  time: 0.2068  data: 0.0005  max mem: 2362
Test: [Task 2]  [30/63]  eta: 0:00:07  Loss: 0.7874 (0.8069)  Acc@1: 81.2500 (83.4677)  Acc@5: 100.0000 (97.1774)  time: 0.2069  data: 0.0005  max mem: 2362
Test: [Task 2]  [40/63]  eta: 0:00:04  Loss: 0.7512 (0.7842)  Acc@1: 87.5000 (84.1463)  Acc@5: 100.0000 (97.4085)  time: 0.2067  data: 0.0004  max mem: 2362
Test: [Task 2]  [50/63]  eta: 0:00:02  Loss: 0.6672 (0.7724)  Acc@1: 81.2500 (83.7010)  Acc@5: 100.0000 (97.5490)  time: 0.2064  data: 0.0004  max mem: 2362
Test: [Task 2]  [60/63]  eta: 0:00:00  Loss: 0.6107 (0.7444)  Acc@1: 87.5000 (84.6311)  Acc@5: 100.0000 (97.8484)  time: 0.2062  data: 0.0004  max mem: 2362
Test: [Task 2]  [62/63]  eta: 0:00:00  Loss: 0.6074 (0.7359)  Acc@1: 87.5000 (84.7000)  Acc@5: 100.0000 (97.9000)  time: 0.2013  data: 0.0004  max mem: 2362
Test: [Task 2] Total time: 0:00:13 (0.2133 s / it)
* Acc@1 84.700 Acc@5 97.900 loss 0.736
Test: [Task 3]  [ 0/63]  eta: 0:00:39  Loss: 0.3286 (0.3286)  Acc@1: 93.7500 (93.7500)  Acc@5: 100.0000 (100.0000)  time: 0.6238  data: 0.4107  max mem: 2362
Test: [Task 3]  [10/63]  eta: 0:00:12  Loss: 0.5885 (0.5860)  Acc@1: 87.5000 (84.6591)  Acc@5: 100.0000 (98.2955)  time: 0.2446  data: 0.0376  max mem: 2362
Test: [Task 3]  [20/63]  eta: 0:00:09  Loss: 0.6204 (0.6047)  Acc@1: 87.5000 (84.8214)  Acc@5: 100.0000 (97.9167)  time: 0.2067  data: 0.0004  max mem: 2362
Test: [Task 3]  [30/63]  eta: 0:00:07  Loss: 0.6134 (0.5821)  Acc@1: 87.5000 (85.6855)  Acc@5: 100.0000 (98.3871)  time: 0.2065  data: 0.0004  max mem: 2362
Test: [Task 3]  [40/63]  eta: 0:00:04  Loss: 0.4933 (0.5928)  Acc@1: 87.5000 (86.4329)  Acc@5: 100.0000 (98.1707)  time: 0.2068  data: 0.0005  max mem: 2362
Test: [Task 3]  [50/63]  eta: 0:00:02  Loss: 0.5742 (0.5964)  Acc@1: 87.5000 (86.8873)  Acc@5: 100.0000 (97.9167)  time: 0.2071  data: 0.0004  max mem: 2362
Test: [Task 3]  [60/63]  eta: 0:00:00  Loss: 0.5838 (0.5936)  Acc@1: 87.5000 (86.8852)  Acc@5: 100.0000 (98.1557)  time: 0.2066  data: 0.0004  max mem: 2362
Test: [Task 3]  [62/63]  eta: 0:00:00  Loss: 0.6019 (0.5938)  Acc@1: 87.5000 (86.7000)  Acc@5: 100.0000 (98.2000)  time: 0.2016  data: 0.0003  max mem: 2362
Test: [Task 3] Total time: 0:00:13 (0.2130 s / it)
* Acc@1 86.700 Acc@5 98.200 loss 0.594
Test: [Task 4]  [ 0/63]  eta: 0:00:40  Loss: 0.9736 (0.9736)  Acc@1: 75.0000 (75.0000)  Acc@5: 93.7500 (93.7500)  time: 0.6392  data: 0.4134  max mem: 2362
Test: [Task 4]  [10/63]  eta: 0:00:13  Loss: 0.6882 (0.7460)  Acc@1: 81.2500 (81.8182)  Acc@5: 100.0000 (97.7273)  time: 0.2456  data: 0.0380  max mem: 2362
Test: [Task 4]  [20/63]  eta: 0:00:09  Loss: 0.6715 (0.7098)  Acc@1: 81.2500 (83.3333)  Acc@5: 100.0000 (97.6190)  time: 0.2060  data: 0.0004  max mem: 2362
Test: [Task 4]  [30/63]  eta: 0:00:07  Loss: 0.5622 (0.6471)  Acc@1: 87.5000 (85.6855)  Acc@5: 100.0000 (97.9839)  time: 0.2057  data: 0.0003  max mem: 2362
Test: [Task 4]  [40/63]  eta: 0:00:04  Loss: 0.3640 (0.5900)  Acc@1: 93.7500 (87.0427)  Acc@5: 100.0000 (98.3232)  time: 0.2063  data: 0.0004  max mem: 2362
Test: [Task 4]  [50/63]  eta: 0:00:02  Loss: 0.4082 (0.5932)  Acc@1: 87.5000 (86.8873)  Acc@5: 100.0000 (98.1618)  time: 0.2067  data: 0.0004  max mem: 2362
Test: [Task 4]  [60/63]  eta: 0:00:00  Loss: 0.5989 (0.6181)  Acc@1: 87.5000 (86.0656)  Acc@5: 100.0000 (97.6434)  time: 0.2062  data: 0.0004  max mem: 2362
Test: [Task 4]  [62/63]  eta: 0:00:00  Loss: 0.5989 (0.6178)  Acc@1: 87.5000 (86.2000)  Acc@5: 100.0000 (97.7000)  time: 0.2013  data: 0.0003  max mem: 2362
Test: [Task 4] Total time: 0:00:13 (0.2131 s / it)
* Acc@1 86.200 Acc@5 97.700 loss 0.618
Test: [Task 5]  [ 0/63]  eta: 0:00:34  Loss: 0.2988 (0.2988)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)  time: 0.5448  data: 0.3363  max mem: 2362
Test: [Task 5]  [10/63]  eta: 0:00:12  Loss: 0.5042 (0.6540)  Acc@1: 93.7500 (88.0682)  Acc@5: 100.0000 (96.0227)  time: 0.2379  data: 0.0310  max mem: 2362
Test: [Task 5]  [20/63]  eta: 0:00:09  Loss: 0.5042 (0.5991)  Acc@1: 87.5000 (88.9881)  Acc@5: 100.0000 (97.0238)  time: 0.2073  data: 0.0006  max mem: 2362
Test: [Task 5]  [30/63]  eta: 0:00:07  Loss: 0.5173 (0.5822)  Acc@1: 87.5000 (89.7177)  Acc@5: 100.0000 (97.7823)  time: 0.2068  data: 0.0006  max mem: 2362
Test: [Task 5]  [40/63]  eta: 0:00:04  Loss: 0.5173 (0.5623)  Acc@1: 93.7500 (90.0915)  Acc@5: 100.0000 (97.7134)  time: 0.2064  data: 0.0005  max mem: 2362
Test: [Task 5]  [50/63]  eta: 0:00:02  Loss: 0.5507 (0.5671)  Acc@1: 93.7500 (90.4412)  Acc@5: 100.0000 (97.6716)  time: 0.2064  data: 0.0004  max mem: 2362
Test: [Task 5]  [60/63]  eta: 0:00:00  Loss: 0.5876 (0.5931)  Acc@1: 87.5000 (89.4467)  Acc@5: 100.0000 (97.4385)  time: 0.2061  data: 0.0004  max mem: 2362
Test: [Task 5]  [62/63]  eta: 0:00:00  Loss: 0.6001 (0.6145)  Acc@1: 87.5000 (88.8000)  Acc@5: 100.0000 (97.5000)  time: 0.2013  data: 0.0003  max mem: 2362
Test: [Task 5] Total time: 0:00:13 (0.2118 s / it)
* Acc@1 88.800 Acc@5 97.500 loss 0.615
Test: [Task 6]  [ 0/63]  eta: 0:00:39  Loss: 0.6423 (0.6423)  Acc@1: 75.0000 (75.0000)  Acc@5: 93.7500 (93.7500)  time: 0.6318  data: 0.4239  max mem: 2362
Test: [Task 6]  [10/63]  eta: 0:00:13  Loss: 0.6933 (0.7081)  Acc@1: 81.2500 (81.2500)  Acc@5: 93.7500 (95.4545)  time: 0.2454  data: 0.0389  max mem: 2362
Test: [Task 6]  [20/63]  eta: 0:00:09  Loss: 0.6905 (0.7489)  Acc@1: 81.2500 (81.5476)  Acc@5: 100.0000 (96.4286)  time: 0.2063  data: 0.0004  max mem: 2362
Test: [Task 6]  [30/63]  eta: 0:00:07  Loss: 0.6829 (0.7268)  Acc@1: 81.2500 (81.2500)  Acc@5: 100.0000 (96.9758)  time: 0.2060  data: 0.0004  max mem: 2362
Test: [Task 6]  [40/63]  eta: 0:00:04  Loss: 0.7774 (0.7768)  Acc@1: 75.0000 (79.1159)  Acc@5: 93.7500 (96.4939)  time: 0.2064  data: 0.0004  max mem: 2362
Test: [Task 6]  [50/63]  eta: 0:00:02  Loss: 0.7272 (0.7524)  Acc@1: 75.0000 (79.5343)  Acc@5: 100.0000 (96.9363)  time: 0.2062  data: 0.0004  max mem: 2362
Test: [Task 6]  [60/63]  eta: 0:00:00  Loss: 0.6877 (0.7637)  Acc@1: 81.2500 (79.8156)  Acc@5: 100.0000 (96.7213)  time: 0.2062  data: 0.0004  max mem: 2362
Test: [Task 6]  [62/63]  eta: 0:00:00  Loss: 0.7172 (0.7592)  Acc@1: 81.2500 (80.2000)  Acc@5: 100.0000 (96.8000)  time: 0.2017  data: 0.0003  max mem: 2362
Test: [Task 6] Total time: 0:00:13 (0.2137 s / it)
* Acc@1 80.200 Acc@5 96.800 loss 0.759
{0: {0: 606, 1: 607, 2: 613, 3: 608, 4: 616, 5: 50, 6: 52, 7: 47, 8: 51, 9: 48, 10: 64, 11: 64, 12: 64, 13: 64, 14: 64, 15: 199, 16: 193, 17: 203, 18: 196, 19: 201, 20: 46, 21: 44, 22: 48, 23: 45, 24: 46, 25: 31, 26: 31, 27: 33, 28: 32, 29: 33, 30: 0, 31: 0, 32: 0, 33: 0, 34: 0, 35: 0, 36: 0, 37: 0, 38: 0, 39: 0, 40: 0, 41: 0, 42: 0, 43: 0, 44: 0, 45: 0, 46: 0, 47: 1, 48: 0, 49: 0}, 1: {0: 95, 1: 98, 2: 98, 3: 98, 4: 100, 5: 511, 6: 512, 7: 508, 8: 513, 9: 510, 10: 82, 11: 80, 12: 83, 13: 81, 14: 82, 15: 193, 16: 192, 17: 195, 18: 193, 19: 195, 20: 50, 21: 51, 22: 51, 23: 50, 24: 50, 25: 65, 26: 66, 27: 64, 28: 66, 29: 64, 30: 1, 31: 0, 32: 0, 33: 0, 34: 0, 35: 0, 36: 0, 37: 2, 38: 0, 39: 1, 40: 0, 41: 0, 42: 0, 43: 0, 44: 0, 45: 0, 46: 0, 47: 0, 48: 0, 49: 0}, 2: {0: 52, 1: 53, 2: 53, 3: 54, 4: 51, 5: 35, 6: 34, 7: 35, 8: 35, 9: 35, 10: 644, 11: 640, 12: 643, 13: 641, 14: 644, 15: 170, 16: 168, 17: 171, 18: 170, 19: 170, 20: 67, 21: 66, 22: 68, 23: 67, 24: 67, 25: 33, 26: 32, 27: 33, 28: 33, 29: 33, 30: 0, 31: 0, 32: 0, 33: 0, 34: 0, 35: 0, 36: 0, 37: 0, 38: 0, 39: 0, 40: 0, 41: 0, 42: 0, 43: 0, 44: 0, 45: 1, 46: 0, 47: 1, 48: 0, 49: 1}, 3: {0: 29, 1: 29, 2: 31, 3: 29, 4: 31, 5: 89, 6: 91, 7: 89, 8: 90, 9: 89, 10: 38, 11: 38, 12: 37, 13: 38, 14: 37, 15: 764, 16: 755, 17: 767, 18: 762, 19: 766, 20: 38, 21: 37, 22: 38, 23: 37, 24: 38, 25: 41, 26: 40, 27: 42, 28: 41, 29: 41, 30: 0, 31: 0, 32: 0, 33: 0, 34: 1, 35: 0, 36: 0, 37: 1, 38: 0, 39: 0, 40: 0, 41: 3, 42: 0, 43: 0, 44: 0, 45: 0, 46: 0, 47: 2, 48: 0, 49: 1}, 4: {0: 63, 1: 62, 2: 66, 3: 65, 4: 66, 5: 75, 6: 77, 7: 74, 8: 76, 9: 75, 10: 129, 11: 129, 12: 128, 13: 129, 14: 128, 15: 211, 16: 209, 17: 213, 18: 211, 19: 211, 20: 444, 21: 443, 22: 444, 23: 445, 24: 443, 25: 75, 26: 76, 27: 76, 28: 75, 29: 75, 30: 2, 31: 0, 32: 1, 33: 0, 34: 0, 35: 0, 36: 0, 37: 0, 38: 0, 39: 0, 40: 2, 41: 1, 42: 0, 43: 0, 44: 0, 45: 1, 46: 0, 47: 0, 48: 0, 49: 0}, 5: {0: 37, 1: 34, 2: 40, 3: 35, 4: 37, 5: 83, 6: 82, 7: 83, 8: 82, 9: 83, 10: 19, 11: 19, 12: 18, 13: 19, 14: 19, 15: 242, 16: 242, 17: 242, 18: 242, 19: 242, 20: 22, 21: 22, 22: 22, 23: 22, 24: 22, 25: 597, 26: 598, 27: 595, 28: 598, 29: 598, 30: 0, 31: 0, 32: 0, 33: 0, 34: 0, 35: 0, 36: 0, 37: 0, 38: 0, 39: 0, 40: 0, 41: 0, 42: 0, 43: 0, 44: 0, 45: 0, 46: 0, 47: 4, 48: 0, 49: 0}}
[Average accuracy till task6]	Acc@1: 85.5333	Acc@5: 97.8167	Loss: 0.6511	Forgetting: 5.0400	Backward: -5.0200
Train: Epoch[1/5]  [  0/313]  eta: 0:03:56  Lr: 0.001875  Loss: 1.2035  Acc@1: 25.0000 (25.0000)  Acc@5: 50.0000 (50.0000)  time: 0.7543  data: 0.4002  max mem: 2362
Train: Epoch[1/5]  [ 10/313]  eta: 0:01:51  Lr: 0.001875  Loss: 0.8310  Acc@1: 43.7500 (47.1591)  Acc@5: 81.2500 (76.1364)  time: 0.3695  data: 0.0372  max mem: 2362
Train: Epoch[1/5]  [ 20/313]  eta: 0:01:42  Lr: 0.001875  Loss: 0.5669  Acc@1: 68.7500 (59.8214)  Acc@5: 87.5000 (85.7143)  time: 0.3307  data: 0.0007  max mem: 2362
Train: Epoch[1/5]  [ 30/313]  eta: 0:01:37  Lr: 0.001875  Loss: 0.1148  Acc@1: 75.0000 (65.7258)  Acc@5: 100.0000 (88.9113)  time: 0.3308  data: 0.0005  max mem: 2362
Train: Epoch[1/5]  [ 40/313]  eta: 0:01:33  Lr: 0.001875  Loss: 0.1380  Acc@1: 87.5000 (70.7317)  Acc@5: 100.0000 (90.8537)  time: 0.3314  data: 0.0005  max mem: 2362
Train: Epoch[1/5]  [ 50/313]  eta: 0:01:29  Lr: 0.001875  Loss: -0.0542  Acc@1: 87.5000 (73.1618)  Acc@5: 100.0000 (92.1569)  time: 0.3312  data: 0.0005  max mem: 2362
Train: Epoch[1/5]  [ 60/313]  eta: 0:01:25  Lr: 0.001875  Loss: -0.2357  Acc@1: 87.5000 (75.0000)  Acc@5: 100.0000 (93.1352)  time: 0.3314  data: 0.0005  max mem: 2362
Train: Epoch[1/5]  [ 70/313]  eta: 0:01:21  Lr: 0.001875  Loss: -0.2941  Acc@1: 87.5000 (76.5845)  Acc@5: 100.0000 (93.6620)  time: 0.3315  data: 0.0006  max mem: 2362
Train: Epoch[1/5]  [ 80/313]  eta: 0:01:18  Lr: 0.001875  Loss: -0.4058  Acc@1: 87.5000 (77.5463)  Acc@5: 100.0000 (94.2901)  time: 0.3312  data: 0.0005  max mem: 2362
Train: Epoch[1/5]  [ 90/313]  eta: 0:01:14  Lr: 0.001875  Loss: -0.4724  Acc@1: 81.2500 (77.8159)  Acc@5: 100.0000 (94.7115)  time: 0.3312  data: 0.0004  max mem: 2362
Train: Epoch[1/5]  [100/313]  eta: 0:01:11  Lr: 0.001875  Loss: -0.3589  Acc@1: 75.0000 (77.7228)  Acc@5: 100.0000 (94.9876)  time: 0.3317  data: 0.0005  max mem: 2362
Train: Epoch[1/5]  [110/313]  eta: 0:01:08  Lr: 0.001875  Loss: -0.6816  Acc@1: 81.2500 (78.3784)  Acc@5: 100.0000 (95.2703)  time: 0.3318  data: 0.0004  max mem: 2362
Train: Epoch[1/5]  [120/313]  eta: 0:01:04  Lr: 0.001875  Loss: -0.5305  Acc@1: 87.5000 (78.8223)  Acc@5: 100.0000 (95.5579)  time: 0.3312  data: 0.0005  max mem: 2362
Train: Epoch[1/5]  [130/313]  eta: 0:01:01  Lr: 0.001875  Loss: -0.4982  Acc@1: 81.2500 (79.1031)  Acc@5: 100.0000 (95.6107)  time: 0.3317  data: 0.0005  max mem: 2362
Train: Epoch[1/5]  [140/313]  eta: 0:00:57  Lr: 0.001875  Loss: -0.6460  Acc@1: 81.2500 (79.3440)  Acc@5: 100.0000 (95.8333)  time: 0.3320  data: 0.0004  max mem: 2362
Train: Epoch[1/5]  [150/313]  eta: 0:00:54  Lr: 0.001875  Loss: -0.5692  Acc@1: 81.2500 (79.7185)  Acc@5: 100.0000 (96.0679)  time: 0.3322  data: 0.0005  max mem: 2362
Train: Epoch[1/5]  [160/313]  eta: 0:00:51  Lr: 0.001875  Loss: -0.8252  Acc@1: 81.2500 (80.1630)  Acc@5: 100.0000 (96.1957)  time: 0.3321  data: 0.0007  max mem: 2362
Train: Epoch[1/5]  [170/313]  eta: 0:00:47  Lr: 0.001875  Loss: -0.6662  Acc@1: 81.2500 (80.2632)  Acc@5: 100.0000 (96.3816)  time: 0.3313  data: 0.0007  max mem: 2362
Train: Epoch[1/5]  [180/313]  eta: 0:00:44  Lr: 0.001875  Loss: -0.7523  Acc@1: 87.5000 (80.6285)  Acc@5: 100.0000 (96.4779)  time: 0.3312  data: 0.0007  max mem: 2362
Train: Epoch[1/5]  [190/313]  eta: 0:00:41  Lr: 0.001875  Loss: -0.9599  Acc@1: 87.5000 (81.0537)  Acc@5: 100.0000 (96.5969)  time: 0.3313  data: 0.0007  max mem: 2362
Train: Epoch[1/5]  [200/313]  eta: 0:00:37  Lr: 0.001875  Loss: -0.6320  Acc@1: 87.5000 (81.4055)  Acc@5: 100.0000 (96.6418)  time: 0.3307  data: 0.0005  max mem: 2362
Train: Epoch[1/5]  [210/313]  eta: 0:00:34  Lr: 0.001875  Loss: -0.2824  Acc@1: 81.2500 (81.4573)  Acc@5: 100.0000 (96.7417)  time: 0.3311  data: 0.0005  max mem: 2362
Train: Epoch[1/5]  [220/313]  eta: 0:00:30  Lr: 0.001875  Loss: -0.4905  Acc@1: 81.2500 (81.5328)  Acc@5: 100.0000 (96.7760)  time: 0.3316  data: 0.0005  max mem: 2362
Train: Epoch[1/5]  [230/313]  eta: 0:00:27  Lr: 0.001875  Loss: -0.7444  Acc@1: 87.5000 (81.7370)  Acc@5: 93.7500 (96.7262)  time: 0.3316  data: 0.0005  max mem: 2362
Train: Epoch[1/5]  [240/313]  eta: 0:00:24  Lr: 0.001875  Loss: -0.9612  Acc@1: 87.5000 (81.9243)  Acc@5: 100.0000 (96.7583)  time: 0.3313  data: 0.0005  max mem: 2362
Train: Epoch[1/5]  [250/313]  eta: 0:00:20  Lr: 0.001875  Loss: -0.6306  Acc@1: 87.5000 (82.2460)  Acc@5: 100.0000 (96.8875)  time: 0.3311  data: 0.0006  max mem: 2362
Train: Epoch[1/5]  [260/313]  eta: 0:00:17  Lr: 0.001875  Loss: -0.7344  Acc@1: 87.5000 (82.3994)  Acc@5: 100.0000 (97.0067)  time: 0.3309  data: 0.0006  max mem: 2362
Train: Epoch[1/5]  [270/313]  eta: 0:00:14  Lr: 0.001875  Loss: -0.7369  Acc@1: 87.5000 (82.5646)  Acc@5: 100.0000 (97.0710)  time: 0.3306  data: 0.0005  max mem: 2362
Train: Epoch[1/5]  [280/313]  eta: 0:00:10  Lr: 0.001875  Loss: -0.7045  Acc@1: 87.5000 (82.7625)  Acc@5: 100.0000 (97.1530)  time: 0.3314  data: 0.0007  max mem: 2362
Train: Epoch[1/5]  [290/313]  eta: 0:00:07  Lr: 0.001875  Loss: -0.7368  Acc@1: 87.5000 (82.8823)  Acc@5: 100.0000 (97.2294)  time: 0.3318  data: 0.0008  max mem: 2362
Train: Epoch[1/5]  [300/313]  eta: 0:00:04  Lr: 0.001875  Loss: -0.6722  Acc@1: 87.5000 (83.0565)  Acc@5: 100.0000 (97.3007)  time: 0.3316  data: 0.0004  max mem: 2362
Train: Epoch[1/5]  [310/313]  eta: 0:00:00  Lr: 0.001875  Loss: -0.4246  Acc@1: 87.5000 (83.1592)  Acc@5: 100.0000 (97.3473)  time: 0.3315  data: 0.0004  max mem: 2362
Train: Epoch[1/5]  [312/313]  eta: 0:00:00  Lr: 0.001875  Loss: -0.6076  Acc@1: 87.5000 (83.1600)  Acc@5: 100.0000 (97.3600)  time: 0.3231  data: 0.0004  max mem: 2362
Train: Epoch[1/5] Total time: 0:01:44 (0.3326 s / it)
Averaged stats: Lr: 0.001875  Loss: -0.6076  Acc@1: 87.5000 (83.1600)  Acc@5: 100.0000 (97.3600)
Train: Epoch[2/5]  [  0/313]  eta: 0:04:32  Lr: 0.001875  Loss: -0.6110  Acc@1: 81.2500 (81.2500)  Acc@5: 100.0000 (100.0000)  time: 0.8715  data: 0.5363  max mem: 2362
Train: Epoch[2/5]  [ 10/313]  eta: 0:01:55  Lr: 0.001875  Loss: -1.0497  Acc@1: 93.7500 (90.3409)  Acc@5: 100.0000 (98.8636)  time: 0.3808  data: 0.0492  max mem: 2362
Train: Epoch[2/5]  [ 20/313]  eta: 0:01:44  Lr: 0.001875  Loss: -0.7794  Acc@1: 87.5000 (89.8810)  Acc@5: 100.0000 (99.4048)  time: 0.3323  data: 0.0005  max mem: 2362
Train: Epoch[2/5]  [ 30/313]  eta: 0:01:38  Lr: 0.001875  Loss: -0.2954  Acc@1: 87.5000 (88.7097)  Acc@5: 100.0000 (99.1935)  time: 0.3328  data: 0.0005  max mem: 2362
Train: Epoch[2/5]  [ 40/313]  eta: 0:01:34  Lr: 0.001875  Loss: -0.7354  Acc@1: 87.5000 (88.5671)  Acc@5: 100.0000 (99.0854)  time: 0.3316  data: 0.0005  max mem: 2362
Train: Epoch[2/5]  [ 50/313]  eta: 0:01:30  Lr: 0.001875  Loss: -0.6847  Acc@1: 87.5000 (88.8480)  Acc@5: 100.0000 (99.1422)  time: 0.3311  data: 0.0006  max mem: 2362
Train: Epoch[2/5]  [ 60/313]  eta: 0:01:26  Lr: 0.001875  Loss: -0.7307  Acc@1: 87.5000 (88.7295)  Acc@5: 100.0000 (99.2828)  time: 0.3316  data: 0.0006  max mem: 2362
Train: Epoch[2/5]  [ 70/313]  eta: 0:01:22  Lr: 0.001875  Loss: -0.8836  Acc@1: 93.7500 (88.7324)  Acc@5: 100.0000 (99.2958)  time: 0.3312  data: 0.0005  max mem: 2362
Train: Epoch[2/5]  [ 80/313]  eta: 0:01:18  Lr: 0.001875  Loss: -0.5570  Acc@1: 87.5000 (88.8889)  Acc@5: 100.0000 (99.1512)  time: 0.3317  data: 0.0009  max mem: 2362
Train: Epoch[2/5]  [ 90/313]  eta: 0:01:15  Lr: 0.001875  Loss: -0.7160  Acc@1: 87.5000 (88.4615)  Acc@5: 100.0000 (99.1758)  time: 0.3319  data: 0.0009  max mem: 2362
Train: Epoch[2/5]  [100/313]  eta: 0:01:11  Lr: 0.001875  Loss: -1.0229  Acc@1: 87.5000 (88.2426)  Acc@5: 100.0000 (99.2574)  time: 0.3313  data: 0.0005  max mem: 2362
Train: Epoch[2/5]  [110/313]  eta: 0:01:08  Lr: 0.001875  Loss: -0.3823  Acc@1: 87.5000 (88.2883)  Acc@5: 100.0000 (99.2680)  time: 0.3312  data: 0.0005  max mem: 2362
Train: Epoch[2/5]  [120/313]  eta: 0:01:04  Lr: 0.001875  Loss: -0.5278  Acc@1: 87.5000 (88.2748)  Acc@5: 100.0000 (99.1736)  time: 0.3315  data: 0.0005  max mem: 2362
Train: Epoch[2/5]  [130/313]  eta: 0:01:01  Lr: 0.001875  Loss: -0.9001  Acc@1: 87.5000 (88.4065)  Acc@5: 100.0000 (99.1889)  time: 0.3315  data: 0.0005  max mem: 2362
Train: Epoch[2/5]  [140/313]  eta: 0:00:58  Lr: 0.001875  Loss: -0.6900  Acc@1: 87.5000 (88.1649)  Acc@5: 100.0000 (99.2021)  time: 0.3320  data: 0.0004  max mem: 2362
Train: Epoch[2/5]  [150/313]  eta: 0:00:54  Lr: 0.001875  Loss: -0.3507  Acc@1: 81.2500 (87.7483)  Acc@5: 100.0000 (99.1722)  time: 0.3326  data: 0.0004  max mem: 2362
Train: Epoch[2/5]  [160/313]  eta: 0:00:51  Lr: 0.001875  Loss: -0.6818  Acc@1: 87.5000 (87.8882)  Acc@5: 100.0000 (99.1460)  time: 0.3320  data: 0.0004  max mem: 2362
Train: Epoch[2/5]  [170/313]  eta: 0:00:47  Lr: 0.001875  Loss: -0.5980  Acc@1: 87.5000 (87.9751)  Acc@5: 100.0000 (99.1228)  time: 0.3312  data: 0.0005  max mem: 2362
Train: Epoch[2/5]  [180/313]  eta: 0:00:44  Lr: 0.001875  Loss: -0.9125  Acc@1: 87.5000 (88.2251)  Acc@5: 100.0000 (99.1022)  time: 0.3312  data: 0.0005  max mem: 2362
Train: Epoch[2/5]  [190/313]  eta: 0:00:41  Lr: 0.001875  Loss: -0.9687  Acc@1: 87.5000 (87.9908)  Acc@5: 100.0000 (99.1165)  time: 0.3320  data: 0.0005  max mem: 2362
Train: Epoch[2/5]  [200/313]  eta: 0:00:37  Lr: 0.001875  Loss: -1.1231  Acc@1: 87.5000 (88.1530)  Acc@5: 100.0000 (99.0983)  time: 0.3320  data: 0.0005  max mem: 2362
Train: Epoch[2/5]  [210/313]  eta: 0:00:34  Lr: 0.001875  Loss: -0.3555  Acc@1: 87.5000 (88.1517)  Acc@5: 100.0000 (99.0521)  time: 0.3314  data: 0.0005  max mem: 2362
Train: Epoch[2/5]  [220/313]  eta: 0:00:31  Lr: 0.001875  Loss: -1.0034  Acc@1: 87.5000 (88.2353)  Acc@5: 100.0000 (99.0667)  time: 0.3318  data: 0.0010  max mem: 2362
Train: Epoch[2/5]  [230/313]  eta: 0:00:27  Lr: 0.001875  Loss: -1.0138  Acc@1: 93.7500 (88.3658)  Acc@5: 100.0000 (99.0260)  time: 0.3319  data: 0.0010  max mem: 2362
Train: Epoch[2/5]  [240/313]  eta: 0:00:24  Lr: 0.001875  Loss: -0.8103  Acc@1: 87.5000 (88.1743)  Acc@5: 100.0000 (98.9886)  time: 0.3316  data: 0.0005  max mem: 2362
Train: Epoch[2/5]  [250/313]  eta: 0:00:21  Lr: 0.001875  Loss: -0.5888  Acc@1: 87.5000 (88.1474)  Acc@5: 100.0000 (99.0040)  time: 0.3328  data: 0.0013  max mem: 2362
Train: Epoch[2/5]  [260/313]  eta: 0:00:17  Lr: 0.001875  Loss: -1.0531  Acc@1: 87.5000 (88.1226)  Acc@5: 100.0000 (98.9943)  time: 0.3330  data: 0.0012  max mem: 2362
Train: Epoch[2/5]  [270/313]  eta: 0:00:14  Lr: 0.001875  Loss: -0.8616  Acc@1: 87.5000 (87.9843)  Acc@5: 100.0000 (98.9852)  time: 0.3315  data: 0.0004  max mem: 2362
Train: Epoch[2/5]  [280/313]  eta: 0:00:11  Lr: 0.001875  Loss: -1.0369  Acc@1: 87.5000 (88.0560)  Acc@5: 100.0000 (98.9769)  time: 0.3313  data: 0.0004  max mem: 2362
Train: Epoch[2/5]  [290/313]  eta: 0:00:07  Lr: 0.001875  Loss: -0.8981  Acc@1: 87.5000 (88.0369)  Acc@5: 100.0000 (99.0120)  time: 0.3317  data: 0.0004  max mem: 2362
Train: Epoch[2/5]  [300/313]  eta: 0:00:04  Lr: 0.001875  Loss: -0.4269  Acc@1: 87.5000 (88.1645)  Acc@5: 100.0000 (99.0033)  time: 0.3319  data: 0.0005  max mem: 2362
Train: Epoch[2/5]  [310/313]  eta: 0:00:01  Lr: 0.001875  Loss: -0.7224  Acc@1: 87.5000 (88.1833)  Acc@5: 100.0000 (99.0153)  time: 0.3322  data: 0.0005  max mem: 2362
Train: Epoch[2/5]  [312/313]  eta: 0:00:00  Lr: 0.001875  Loss: -1.0432  Acc@1: 87.5000 (88.1800)  Acc@5: 100.0000 (99.0200)  time: 0.3243  data: 0.0004  max mem: 2362
Train: Epoch[2/5] Total time: 0:01:44 (0.3337 s / it)
Averaged stats: Lr: 0.001875  Loss: -1.0432  Acc@1: 87.5000 (88.1800)  Acc@5: 100.0000 (99.0200)
Train: Epoch[3/5]  [  0/313]  eta: 0:03:29  Lr: 0.001875  Loss: -0.5623  Acc@1: 75.0000 (75.0000)  Acc@5: 93.7500 (93.7500)  time: 0.6709  data: 0.3358  max mem: 2362
Train: Epoch[3/5]  [ 10/313]  eta: 0:01:49  Lr: 0.001875  Loss: -0.9278  Acc@1: 93.7500 (90.3409)  Acc@5: 100.0000 (98.8636)  time: 0.3616  data: 0.0311  max mem: 2362
Train: Epoch[3/5]  [ 20/313]  eta: 0:01:41  Lr: 0.001875  Loss: -0.9622  Acc@1: 93.7500 (89.8810)  Acc@5: 100.0000 (99.4048)  time: 0.3308  data: 0.0006  max mem: 2362
Train: Epoch[3/5]  [ 30/313]  eta: 0:01:36  Lr: 0.001875  Loss: -0.6577  Acc@1: 93.7500 (90.3226)  Acc@5: 100.0000 (99.1935)  time: 0.3311  data: 0.0005  max mem: 2362
Train: Epoch[3/5]  [ 40/313]  eta: 0:01:32  Lr: 0.001875  Loss: -0.5583  Acc@1: 87.5000 (89.6341)  Acc@5: 100.0000 (99.0854)  time: 0.3315  data: 0.0004  max mem: 2362
Train: Epoch[3/5]  [ 50/313]  eta: 0:01:28  Lr: 0.001875  Loss: -0.8108  Acc@1: 87.5000 (89.7059)  Acc@5: 100.0000 (99.1422)  time: 0.3316  data: 0.0004  max mem: 2362
Train: Epoch[3/5]  [ 60/313]  eta: 0:01:25  Lr: 0.001875  Loss: -0.8178  Acc@1: 87.5000 (88.9344)  Acc@5: 100.0000 (99.1803)  time: 0.3319  data: 0.0007  max mem: 2362
Train: Epoch[3/5]  [ 70/313]  eta: 0:01:21  Lr: 0.001875  Loss: -0.9036  Acc@1: 87.5000 (88.7324)  Acc@5: 100.0000 (99.1197)  time: 0.3321  data: 0.0007  max mem: 2362
Train: Epoch[3/5]  [ 80/313]  eta: 0:01:18  Lr: 0.001875  Loss: -0.9091  Acc@1: 87.5000 (88.8117)  Acc@5: 100.0000 (99.2284)  time: 0.3319  data: 0.0005  max mem: 2362
Train: Epoch[3/5]  [ 90/313]  eta: 0:01:14  Lr: 0.001875  Loss: -0.5702  Acc@1: 87.5000 (89.0110)  Acc@5: 100.0000 (99.0385)  time: 0.3313  data: 0.0004  max mem: 2362
Train: Epoch[3/5]  [100/313]  eta: 0:01:11  Lr: 0.001875  Loss: -0.8947  Acc@1: 87.5000 (88.6757)  Acc@5: 100.0000 (99.0099)  time: 0.3316  data: 0.0005  max mem: 2362
Train: Epoch[3/5]  [110/313]  eta: 0:01:07  Lr: 0.001875  Loss: -0.5073  Acc@1: 87.5000 (88.7387)  Acc@5: 100.0000 (99.0991)  time: 0.3317  data: 0.0005  max mem: 2362
Train: Epoch[3/5]  [120/313]  eta: 0:01:04  Lr: 0.001875  Loss: -0.7095  Acc@1: 87.5000 (88.6364)  Acc@5: 100.0000 (99.1219)  time: 0.3311  data: 0.0004  max mem: 2362
Train: Epoch[3/5]  [130/313]  eta: 0:01:01  Lr: 0.001875  Loss: -0.2917  Acc@1: 87.5000 (88.5019)  Acc@5: 100.0000 (99.1889)  time: 0.3317  data: 0.0005  max mem: 2362
Train: Epoch[3/5]  [140/313]  eta: 0:00:57  Lr: 0.001875  Loss: -0.9951  Acc@1: 87.5000 (88.5638)  Acc@5: 100.0000 (99.2021)  time: 0.3315  data: 0.0006  max mem: 2362
Train: Epoch[3/5]  [150/313]  eta: 0:00:54  Lr: 0.001875  Loss: -0.9281  Acc@1: 87.5000 (88.4106)  Acc@5: 100.0000 (99.1722)  time: 0.3312  data: 0.0007  max mem: 2362
Train: Epoch[3/5]  [160/313]  eta: 0:00:51  Lr: 0.001875  Loss: -0.7430  Acc@1: 87.5000 (88.5481)  Acc@5: 100.0000 (99.1071)  time: 0.3314  data: 0.0006  max mem: 2362
Train: Epoch[3/5]  [170/313]  eta: 0:00:47  Lr: 0.001875  Loss: -0.8277  Acc@1: 87.5000 (88.5965)  Acc@5: 100.0000 (99.0863)  time: 0.3315  data: 0.0004  max mem: 2362
Train: Epoch[3/5]  [180/313]  eta: 0:00:44  Lr: 0.001875  Loss: -0.9170  Acc@1: 87.5000 (88.4323)  Acc@5: 100.0000 (99.1022)  time: 0.3316  data: 0.0004  max mem: 2362
Train: Epoch[3/5]  [190/313]  eta: 0:00:40  Lr: 0.001875  Loss: -1.1080  Acc@1: 87.5000 (88.5798)  Acc@5: 100.0000 (99.1492)  time: 0.3314  data: 0.0004  max mem: 2362
Train: Epoch[3/5]  [200/313]  eta: 0:00:37  Lr: 0.001875  Loss: -0.9629  Acc@1: 93.7500 (88.6816)  Acc@5: 100.0000 (99.1294)  time: 0.3309  data: 0.0004  max mem: 2362
Train: Epoch[3/5]  [210/313]  eta: 0:00:34  Lr: 0.001875  Loss: -0.6258  Acc@1: 93.7500 (88.7737)  Acc@5: 100.0000 (99.1410)  time: 0.3306  data: 0.0005  max mem: 2362
Train: Epoch[3/5]  [220/313]  eta: 0:00:30  Lr: 0.001875  Loss: -0.7587  Acc@1: 87.5000 (88.7443)  Acc@5: 100.0000 (99.1233)  time: 0.3315  data: 0.0005  max mem: 2362
Train: Epoch[3/5]  [230/313]  eta: 0:00:27  Lr: 0.001875  Loss: -0.7204  Acc@1: 87.5000 (88.6905)  Acc@5: 100.0000 (99.1071)  time: 0.3318  data: 0.0005  max mem: 2362
Train: Epoch[3/5]  [240/313]  eta: 0:00:24  Lr: 0.001875  Loss: -0.3259  Acc@1: 87.5000 (88.6411)  Acc@5: 100.0000 (99.1442)  time: 0.3311  data: 0.0005  max mem: 2362
Train: Epoch[3/5]  [250/313]  eta: 0:00:20  Lr: 0.001875  Loss: -0.8876  Acc@1: 87.5000 (88.7450)  Acc@5: 100.0000 (99.1285)  time: 0.3312  data: 0.0007  max mem: 2362
Train: Epoch[3/5]  [260/313]  eta: 0:00:17  Lr: 0.001875  Loss: -1.1001  Acc@1: 93.7500 (88.7931)  Acc@5: 100.0000 (99.1140)  time: 0.3314  data: 0.0007  max mem: 2362
Train: Epoch[3/5]  [270/313]  eta: 0:00:14  Lr: 0.001875  Loss: -0.4136  Acc@1: 87.5000 (88.7454)  Acc@5: 100.0000 (99.0775)  time: 0.3312  data: 0.0004  max mem: 2362
Train: Epoch[3/5]  [280/313]  eta: 0:00:10  Lr: 0.001875  Loss: -0.7334  Acc@1: 87.5000 (88.7456)  Acc@5: 100.0000 (99.0881)  time: 0.3304  data: 0.0004  max mem: 2362
Train: Epoch[3/5]  [290/313]  eta: 0:00:07  Lr: 0.001875  Loss: -0.9415  Acc@1: 87.5000 (88.7887)  Acc@5: 100.0000 (99.1194)  time: 0.3300  data: 0.0004  max mem: 2362
Train: Epoch[3/5]  [300/313]  eta: 0:00:04  Lr: 0.001875  Loss: -0.8190  Acc@1: 87.5000 (88.7666)  Acc@5: 100.0000 (99.0864)  time: 0.3309  data: 0.0004  max mem: 2362
Train: Epoch[3/5]  [310/313]  eta: 0:00:00  Lr: 0.001875  Loss: -0.5943  Acc@1: 87.5000 (88.6857)  Acc@5: 100.0000 (99.0957)  time: 0.3315  data: 0.0005  max mem: 2362
Train: Epoch[3/5]  [312/313]  eta: 0:00:00  Lr: 0.001875  Loss: -0.8908  Acc@1: 87.5000 (88.7400)  Acc@5: 100.0000 (99.1000)  time: 0.3234  data: 0.0004  max mem: 2362
Train: Epoch[3/5] Total time: 0:01:44 (0.3324 s / it)
Averaged stats: Lr: 0.001875  Loss: -0.8908  Acc@1: 87.5000 (88.7400)  Acc@5: 100.0000 (99.1000)
Train: Epoch[4/5]  [  0/313]  eta: 0:03:37  Lr: 0.001875  Loss: -0.5869  Acc@1: 81.2500 (81.2500)  Acc@5: 93.7500 (93.7500)  time: 0.6958  data: 0.3621  max mem: 2362
Train: Epoch[4/5]  [ 10/313]  eta: 0:01:50  Lr: 0.001875  Loss: -0.8416  Acc@1: 93.7500 (90.9091)  Acc@5: 100.0000 (98.2955)  time: 0.3642  data: 0.0333  max mem: 2362
Train: Epoch[4/5]  [ 20/313]  eta: 0:01:41  Lr: 0.001875  Loss: -0.6504  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (98.2143)  time: 0.3307  data: 0.0005  max mem: 2362
Train: Epoch[4/5]  [ 30/313]  eta: 0:01:37  Lr: 0.001875  Loss: -0.7774  Acc@1: 87.5000 (88.1048)  Acc@5: 100.0000 (98.3871)  time: 0.3311  data: 0.0005  max mem: 2362
Train: Epoch[4/5]  [ 40/313]  eta: 0:01:32  Lr: 0.001875  Loss: -0.6042  Acc@1: 87.5000 (87.6524)  Acc@5: 100.0000 (98.6280)  time: 0.3317  data: 0.0005  max mem: 2362
Train: Epoch[4/5]  [ 50/313]  eta: 0:01:28  Lr: 0.001875  Loss: -1.0002  Acc@1: 87.5000 (87.7451)  Acc@5: 100.0000 (98.7745)  time: 0.3314  data: 0.0005  max mem: 2362
Train: Epoch[4/5]  [ 60/313]  eta: 0:01:25  Lr: 0.001875  Loss: -0.8776  Acc@1: 93.7500 (88.7295)  Acc@5: 100.0000 (98.9754)  time: 0.3313  data: 0.0005  max mem: 2362
Train: Epoch[4/5]  [ 70/313]  eta: 0:01:21  Lr: 0.001875  Loss: -0.8029  Acc@1: 93.7500 (88.9085)  Acc@5: 100.0000 (98.8556)  time: 0.3311  data: 0.0005  max mem: 2362
Train: Epoch[4/5]  [ 80/313]  eta: 0:01:18  Lr: 0.001875  Loss: -1.0123  Acc@1: 93.7500 (89.2747)  Acc@5: 100.0000 (98.9198)  time: 0.3311  data: 0.0004  max mem: 2362
Train: Epoch[4/5]  [ 90/313]  eta: 0:01:14  Lr: 0.001875  Loss: -0.8879  Acc@1: 93.7500 (89.7665)  Acc@5: 100.0000 (99.0385)  time: 0.3309  data: 0.0005  max mem: 2362
Train: Epoch[4/5]  [100/313]  eta: 0:01:11  Lr: 0.001875  Loss: -0.9467  Acc@1: 93.7500 (89.6658)  Acc@5: 100.0000 (99.0099)  time: 0.3309  data: 0.0005  max mem: 2362
Train: Epoch[4/5]  [110/313]  eta: 0:01:07  Lr: 0.001875  Loss: -0.7625  Acc@1: 87.5000 (89.5833)  Acc@5: 100.0000 (99.0991)  time: 0.3315  data: 0.0004  max mem: 2362
Train: Epoch[4/5]  [120/313]  eta: 0:01:04  Lr: 0.001875  Loss: -0.5932  Acc@1: 87.5000 (89.2045)  Acc@5: 100.0000 (99.0702)  time: 0.3314  data: 0.0004  max mem: 2362
Train: Epoch[4/5]  [130/313]  eta: 0:01:01  Lr: 0.001875  Loss: -0.9493  Acc@1: 87.5000 (89.1221)  Acc@5: 100.0000 (98.9981)  time: 0.3313  data: 0.0005  max mem: 2362
Train: Epoch[4/5]  [140/313]  eta: 0:00:57  Lr: 0.001875  Loss: -0.8278  Acc@1: 87.5000 (89.0071)  Acc@5: 100.0000 (98.8918)  time: 0.3314  data: 0.0005  max mem: 2362
Train: Epoch[4/5]  [150/313]  eta: 0:00:54  Lr: 0.001875  Loss: -0.7985  Acc@1: 87.5000 (88.7831)  Acc@5: 100.0000 (98.9238)  time: 0.3315  data: 0.0004  max mem: 2362
Train: Epoch[4/5]  [160/313]  eta: 0:00:51  Lr: 0.001875  Loss: -1.0035  Acc@1: 87.5000 (88.9363)  Acc@5: 100.0000 (98.9519)  time: 0.3311  data: 0.0004  max mem: 2362
Train: Epoch[4/5]  [170/313]  eta: 0:00:47  Lr: 0.001875  Loss: -0.8282  Acc@1: 93.7500 (89.0351)  Acc@5: 100.0000 (99.0132)  time: 0.3308  data: 0.0004  max mem: 2362
Train: Epoch[4/5]  [180/313]  eta: 0:00:44  Lr: 0.001875  Loss: -0.6971  Acc@1: 87.5000 (89.0193)  Acc@5: 100.0000 (99.0677)  time: 0.3309  data: 0.0004  max mem: 2362
Train: Epoch[4/5]  [190/313]  eta: 0:00:40  Lr: 0.001875  Loss: -0.9597  Acc@1: 87.5000 (89.0380)  Acc@5: 100.0000 (99.0510)  time: 0.3312  data: 0.0005  max mem: 2362
Train: Epoch[4/5]  [200/313]  eta: 0:00:37  Lr: 0.001875  Loss: -0.6138  Acc@1: 87.5000 (89.0547)  Acc@5: 100.0000 (99.0672)  time: 0.3313  data: 0.0005  max mem: 2362
Train: Epoch[4/5]  [210/313]  eta: 0:00:34  Lr: 0.001875  Loss: -1.0568  Acc@1: 93.7500 (89.1291)  Acc@5: 100.0000 (99.0521)  time: 0.3314  data: 0.0005  max mem: 2362
Train: Epoch[4/5]  [220/313]  eta: 0:00:30  Lr: 0.001875  Loss: -0.9553  Acc@1: 93.7500 (89.2251)  Acc@5: 100.0000 (99.0950)  time: 0.3314  data: 0.0004  max mem: 2362
Train: Epoch[4/5]  [230/313]  eta: 0:00:27  Lr: 0.001875  Loss: -0.1721  Acc@1: 93.7500 (89.1234)  Acc@5: 100.0000 (99.1071)  time: 0.3316  data: 0.0004  max mem: 2362
Train: Epoch[4/5]  [240/313]  eta: 0:00:24  Lr: 0.001875  Loss: -0.8001  Acc@1: 93.7500 (89.2376)  Acc@5: 100.0000 (99.1183)  time: 0.3314  data: 0.0005  max mem: 2362
Train: Epoch[4/5]  [250/313]  eta: 0:00:20  Lr: 0.001875  Loss: -0.7363  Acc@1: 93.7500 (89.2181)  Acc@5: 100.0000 (99.1534)  time: 0.3314  data: 0.0005  max mem: 2362
Train: Epoch[4/5]  [260/313]  eta: 0:00:17  Lr: 0.001875  Loss: -0.7386  Acc@1: 93.7500 (89.2960)  Acc@5: 100.0000 (99.1858)  time: 0.3319  data: 0.0005  max mem: 2362
Train: Epoch[4/5]  [270/313]  eta: 0:00:14  Lr: 0.001875  Loss: -0.5338  Acc@1: 93.7500 (89.2989)  Acc@5: 100.0000 (99.1697)  time: 0.3315  data: 0.0005  max mem: 2362
Train: Epoch[4/5]  [280/313]  eta: 0:00:10  Lr: 0.001875  Loss: -0.8181  Acc@1: 87.5000 (89.1237)  Acc@5: 100.0000 (99.0881)  time: 0.3310  data: 0.0005  max mem: 2362
Train: Epoch[4/5]  [290/313]  eta: 0:00:07  Lr: 0.001875  Loss: -0.8431  Acc@1: 87.5000 (89.1967)  Acc@5: 100.0000 (99.1194)  time: 0.3311  data: 0.0005  max mem: 2362
Train: Epoch[4/5]  [300/313]  eta: 0:00:04  Lr: 0.001875  Loss: -0.7413  Acc@1: 87.5000 (89.0988)  Acc@5: 100.0000 (99.1487)  time: 0.3312  data: 0.0007  max mem: 2362
Train: Epoch[4/5]  [310/313]  eta: 0:00:00  Lr: 0.001875  Loss: -1.0279  Acc@1: 87.5000 (89.0072)  Acc@5: 100.0000 (99.1559)  time: 0.3309  data: 0.0007  max mem: 2362
Train: Epoch[4/5]  [312/313]  eta: 0:00:00  Lr: 0.001875  Loss: -0.7244  Acc@1: 87.5000 (89.0000)  Acc@5: 100.0000 (99.1600)  time: 0.3227  data: 0.0004  max mem: 2362
Train: Epoch[4/5] Total time: 0:01:44 (0.3323 s / it)
Averaged stats: Lr: 0.001875  Loss: -0.7244  Acc@1: 87.5000 (89.0000)  Acc@5: 100.0000 (99.1600)
Train: Epoch[5/5]  [  0/313]  eta: 0:04:02  Lr: 0.001875  Loss: -0.9155  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)  time: 0.7755  data: 0.4427  max mem: 2362
Train: Epoch[5/5]  [ 10/313]  eta: 0:01:52  Lr: 0.001875  Loss: -0.9050  Acc@1: 93.7500 (88.6364)  Acc@5: 100.0000 (98.8636)  time: 0.3722  data: 0.0411  max mem: 2362
Train: Epoch[5/5]  [ 20/313]  eta: 0:01:43  Lr: 0.001875  Loss: -0.7883  Acc@1: 93.7500 (88.9881)  Acc@5: 100.0000 (98.8095)  time: 0.3317  data: 0.0008  max mem: 2362
Train: Epoch[5/5]  [ 30/313]  eta: 0:01:37  Lr: 0.001875  Loss: -0.9406  Acc@1: 93.7500 (90.5242)  Acc@5: 100.0000 (98.5887)  time: 0.3317  data: 0.0007  max mem: 2362
Train: Epoch[5/5]  [ 40/313]  eta: 0:01:33  Lr: 0.001875  Loss: -0.8772  Acc@1: 93.7500 (89.7866)  Acc@5: 100.0000 (98.7805)  time: 0.3316  data: 0.0005  max mem: 2362
Train: Epoch[5/5]  [ 50/313]  eta: 0:01:29  Lr: 0.001875  Loss: -0.5837  Acc@1: 87.5000 (89.2157)  Acc@5: 100.0000 (98.5294)  time: 0.3313  data: 0.0005  max mem: 2362
Train: Epoch[5/5]  [ 60/313]  eta: 0:01:25  Lr: 0.001875  Loss: -0.9528  Acc@1: 87.5000 (89.2418)  Acc@5: 100.0000 (98.5656)  time: 0.3313  data: 0.0005  max mem: 2362
Train: Epoch[5/5]  [ 70/313]  eta: 0:01:22  Lr: 0.001875  Loss: -0.9869  Acc@1: 87.5000 (88.9965)  Acc@5: 100.0000 (98.5915)  time: 0.3312  data: 0.0004  max mem: 2362
Train: Epoch[5/5]  [ 80/313]  eta: 0:01:18  Lr: 0.001875  Loss: -0.9037  Acc@1: 87.5000 (89.2747)  Acc@5: 100.0000 (98.7654)  time: 0.3313  data: 0.0005  max mem: 2362
Train: Epoch[5/5]  [ 90/313]  eta: 0:01:14  Lr: 0.001875  Loss: -0.6362  Acc@1: 87.5000 (89.0797)  Acc@5: 100.0000 (98.7637)  time: 0.3309  data: 0.0004  max mem: 2362
Train: Epoch[5/5]  [100/313]  eta: 0:01:11  Lr: 0.001875  Loss: -0.9518  Acc@1: 87.5000 (88.8614)  Acc@5: 100.0000 (98.8243)  time: 0.3308  data: 0.0005  max mem: 2362
Train: Epoch[5/5]  [110/313]  eta: 0:01:08  Lr: 0.001875  Loss: -0.8309  Acc@1: 87.5000 (89.0766)  Acc@5: 100.0000 (98.7050)  time: 0.3312  data: 0.0005  max mem: 2362
Train: Epoch[5/5]  [120/313]  eta: 0:01:04  Lr: 0.001875  Loss: -0.8820  Acc@1: 87.5000 (88.6880)  Acc@5: 100.0000 (98.6570)  time: 0.3314  data: 0.0004  max mem: 2362
Train: Epoch[5/5]  [130/313]  eta: 0:01:01  Lr: 0.001875  Loss: -0.5101  Acc@1: 87.5000 (88.3588)  Acc@5: 100.0000 (98.7118)  time: 0.3308  data: 0.0004  max mem: 2362
Train: Epoch[5/5]  [140/313]  eta: 0:00:57  Lr: 0.001875  Loss: -0.8278  Acc@1: 93.7500 (88.7411)  Acc@5: 100.0000 (98.8032)  time: 0.3307  data: 0.0005  max mem: 2362
Train: Epoch[5/5]  [150/313]  eta: 0:00:54  Lr: 0.001875  Loss: -1.0068  Acc@1: 93.7500 (88.6589)  Acc@5: 100.0000 (98.7169)  time: 0.3305  data: 0.0004  max mem: 2362
Train: Epoch[5/5]  [160/313]  eta: 0:00:51  Lr: 0.001875  Loss: -0.6512  Acc@1: 87.5000 (88.6258)  Acc@5: 100.0000 (98.7189)  time: 0.3313  data: 0.0012  max mem: 2362
Train: Epoch[5/5]  [170/313]  eta: 0:00:47  Lr: 0.001875  Loss: -0.7913  Acc@1: 93.7500 (88.9985)  Acc@5: 100.0000 (98.7939)  time: 0.3316  data: 0.0013  max mem: 2362
Train: Epoch[5/5]  [180/313]  eta: 0:00:44  Lr: 0.001875  Loss: -0.8411  Acc@1: 93.7500 (88.9848)  Acc@5: 100.0000 (98.8605)  time: 0.3320  data: 0.0013  max mem: 2362
Train: Epoch[5/5]  [190/313]  eta: 0:00:41  Lr: 0.001875  Loss: -0.8552  Acc@1: 87.5000 (89.0052)  Acc@5: 100.0000 (98.8874)  time: 0.3322  data: 0.0012  max mem: 2362
Train: Epoch[5/5]  [200/313]  eta: 0:00:37  Lr: 0.001875  Loss: -0.9167  Acc@1: 87.5000 (88.8993)  Acc@5: 100.0000 (98.8806)  time: 0.3313  data: 0.0004  max mem: 2362
Train: Epoch[5/5]  [210/313]  eta: 0:00:34  Lr: 0.001875  Loss: -1.0159  Acc@1: 87.5000 (88.9810)  Acc@5: 100.0000 (98.9040)  time: 0.3311  data: 0.0004  max mem: 2362
Train: Epoch[5/5]  [220/313]  eta: 0:00:30  Lr: 0.001875  Loss: -0.6078  Acc@1: 93.7500 (88.9423)  Acc@5: 100.0000 (98.9253)  time: 0.3311  data: 0.0005  max mem: 2362
Train: Epoch[5/5]  [230/313]  eta: 0:00:27  Lr: 0.001875  Loss: -0.9457  Acc@1: 93.7500 (89.0963)  Acc@5: 100.0000 (98.9177)  time: 0.3316  data: 0.0005  max mem: 2362
Train: Epoch[5/5]  [240/313]  eta: 0:00:24  Lr: 0.001875  Loss: -1.1389  Acc@1: 93.7500 (89.0820)  Acc@5: 100.0000 (98.9627)  time: 0.3319  data: 0.0008  max mem: 2362
Train: Epoch[5/5]  [250/313]  eta: 0:00:20  Lr: 0.001875  Loss: -0.7552  Acc@1: 87.5000 (89.0438)  Acc@5: 100.0000 (98.9791)  time: 0.3315  data: 0.0007  max mem: 2362
Train: Epoch[5/5]  [260/313]  eta: 0:00:17  Lr: 0.001875  Loss: -1.0015  Acc@1: 87.5000 (89.0565)  Acc@5: 100.0000 (98.9464)  time: 0.3318  data: 0.0004  max mem: 2362
Train: Epoch[5/5]  [270/313]  eta: 0:00:14  Lr: 0.001875  Loss: -0.8618  Acc@1: 93.7500 (89.1836)  Acc@5: 100.0000 (98.9622)  time: 0.3320  data: 0.0006  max mem: 2362
Train: Epoch[5/5]  [280/313]  eta: 0:00:10  Lr: 0.001875  Loss: -0.7472  Acc@1: 93.7500 (89.1459)  Acc@5: 100.0000 (98.9546)  time: 0.3311  data: 0.0005  max mem: 2362
Train: Epoch[5/5]  [290/313]  eta: 0:00:07  Lr: 0.001875  Loss: -0.8911  Acc@1: 87.5000 (89.2397)  Acc@5: 100.0000 (98.9905)  time: 0.3314  data: 0.0005  max mem: 2362
Train: Epoch[5/5]  [300/313]  eta: 0:00:04  Lr: 0.001875  Loss: -1.0014  Acc@1: 93.7500 (89.3272)  Acc@5: 100.0000 (99.0033)  time: 0.3321  data: 0.0007  max mem: 2362
Train: Epoch[5/5]  [310/313]  eta: 0:00:00  Lr: 0.001875  Loss: -0.8307  Acc@1: 93.7500 (89.4695)  Acc@5: 100.0000 (98.9952)  time: 0.3316  data: 0.0006  max mem: 2362
Train: Epoch[5/5]  [312/313]  eta: 0:00:00  Lr: 0.001875  Loss: -0.8982  Acc@1: 93.7500 (89.5200)  Acc@5: 100.0000 (99.0000)  time: 0.3236  data: 0.0005  max mem: 2362
Train: Epoch[5/5] Total time: 0:01:44 (0.3328 s / it)
Averaged stats: Lr: 0.001875  Loss: -0.8982  Acc@1: 93.7500 (89.5200)  Acc@5: 100.0000 (99.0000)
Test: [Task 1]  [ 0/63]  eta: 0:00:37  Loss: 0.7162 (0.7162)  Acc@1: 75.0000 (75.0000)  Acc@5: 100.0000 (100.0000)  time: 0.5957  data: 0.3899  max mem: 2362
Test: [Task 1]  [10/63]  eta: 0:00:12  Loss: 0.6210 (0.6016)  Acc@1: 87.5000 (85.2273)  Acc@5: 100.0000 (99.4318)  time: 0.2414  data: 0.0358  max mem: 2362
Test: [Task 1]  [20/63]  eta: 0:00:09  Loss: 0.6210 (0.6829)  Acc@1: 81.2500 (82.7381)  Acc@5: 100.0000 (97.9167)  time: 0.2059  data: 0.0004  max mem: 2362
Test: [Task 1]  [30/63]  eta: 0:00:07  Loss: 0.5409 (0.6417)  Acc@1: 81.2500 (84.2742)  Acc@5: 100.0000 (97.9839)  time: 0.2059  data: 0.0004  max mem: 2362
Test: [Task 1]  [40/63]  eta: 0:00:04  Loss: 0.4643 (0.6215)  Acc@1: 87.5000 (85.2134)  Acc@5: 100.0000 (98.1707)  time: 0.2059  data: 0.0005  max mem: 2362
Test: [Task 1]  [50/63]  eta: 0:00:02  Loss: 0.4679 (0.6076)  Acc@1: 87.5000 (85.7843)  Acc@5: 100.0000 (98.1618)  time: 0.2062  data: 0.0005  max mem: 2362
Test: [Task 1]  [60/63]  eta: 0:00:00  Loss: 0.4814 (0.5988)  Acc@1: 87.5000 (86.1680)  Acc@5: 100.0000 (98.3607)  time: 0.2061  data: 0.0004  max mem: 2362
Test: [Task 1]  [62/63]  eta: 0:00:00  Loss: 0.4679 (0.5947)  Acc@1: 87.5000 (86.4000)  Acc@5: 100.0000 (98.4000)  time: 0.2012  data: 0.0004  max mem: 2362
Test: [Task 1] Total time: 0:00:13 (0.2125 s / it)
* Acc@1 86.400 Acc@5 98.400 loss 0.595
Test: [Task 2]  [ 0/63]  eta: 0:00:35  Loss: 0.8502 (0.8502)  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (100.0000)  time: 0.5700  data: 0.3608  max mem: 2362
Test: [Task 2]  [10/63]  eta: 0:00:12  Loss: 0.6679 (0.7500)  Acc@1: 81.2500 (84.0909)  Acc@5: 100.0000 (97.1591)  time: 0.2394  data: 0.0332  max mem: 2362
Test: [Task 2]  [20/63]  eta: 0:00:09  Loss: 0.7368 (0.8366)  Acc@1: 81.2500 (81.2500)  Acc@5: 100.0000 (96.7262)  time: 0.2066  data: 0.0005  max mem: 2362
Test: [Task 2]  [30/63]  eta: 0:00:07  Loss: 0.8088 (0.8237)  Acc@1: 81.2500 (81.8548)  Acc@5: 93.7500 (96.5726)  time: 0.2061  data: 0.0004  max mem: 2362
Test: [Task 2]  [40/63]  eta: 0:00:04  Loss: 0.7251 (0.8019)  Acc@1: 81.2500 (82.4695)  Acc@5: 100.0000 (96.9512)  time: 0.2060  data: 0.0004  max mem: 2362
Test: [Task 2]  [50/63]  eta: 0:00:02  Loss: 0.6906 (0.7912)  Acc@1: 81.2500 (82.4755)  Acc@5: 100.0000 (96.9363)  time: 0.2063  data: 0.0004  max mem: 2362
Test: [Task 2]  [60/63]  eta: 0:00:00  Loss: 0.6359 (0.7637)  Acc@1: 87.5000 (83.4016)  Acc@5: 100.0000 (97.3361)  time: 0.2061  data: 0.0004  max mem: 2362
Test: [Task 2]  [62/63]  eta: 0:00:00  Loss: 0.6214 (0.7554)  Acc@1: 87.5000 (83.4000)  Acc@5: 100.0000 (97.4000)  time: 0.2012  data: 0.0004  max mem: 2362
Test: [Task 2] Total time: 0:00:13 (0.2120 s / it)
* Acc@1 83.400 Acc@5 97.400 loss 0.755
Test: [Task 3]  [ 0/63]  eta: 0:00:35  Loss: 0.4407 (0.4407)  Acc@1: 81.2500 (81.2500)  Acc@5: 100.0000 (100.0000)  time: 0.5602  data: 0.3507  max mem: 2362
Test: [Task 3]  [10/63]  eta: 0:00:12  Loss: 0.5985 (0.6126)  Acc@1: 81.2500 (83.5227)  Acc@5: 100.0000 (98.2955)  time: 0.2382  data: 0.0323  max mem: 2362
Test: [Task 3]  [20/63]  eta: 0:00:09  Loss: 0.6467 (0.6236)  Acc@1: 81.2500 (83.6310)  Acc@5: 100.0000 (97.9167)  time: 0.2059  data: 0.0004  max mem: 2362
Test: [Task 3]  [30/63]  eta: 0:00:07  Loss: 0.6442 (0.6117)  Acc@1: 81.2500 (84.0726)  Acc@5: 100.0000 (98.3871)  time: 0.2062  data: 0.0004  max mem: 2362
Test: [Task 3]  [40/63]  eta: 0:00:04  Loss: 0.5911 (0.6146)  Acc@1: 87.5000 (85.0610)  Acc@5: 100.0000 (98.1707)  time: 0.2060  data: 0.0004  max mem: 2362
Test: [Task 3]  [50/63]  eta: 0:00:02  Loss: 0.6017 (0.6168)  Acc@1: 87.5000 (85.6618)  Acc@5: 100.0000 (97.9167)  time: 0.2060  data: 0.0004  max mem: 2362
Test: [Task 3]  [60/63]  eta: 0:00:00  Loss: 0.6369 (0.6219)  Acc@1: 87.5000 (85.4508)  Acc@5: 100.0000 (98.0533)  time: 0.2060  data: 0.0003  max mem: 2362
Test: [Task 3]  [62/63]  eta: 0:00:00  Loss: 0.6662 (0.6227)  Acc@1: 87.5000 (85.3000)  Acc@5: 100.0000 (98.1000)  time: 0.2012  data: 0.0003  max mem: 2362
Test: [Task 3] Total time: 0:00:13 (0.2128 s / it)
* Acc@1 85.300 Acc@5 98.100 loss 0.623
Test: [Task 4]  [ 0/63]  eta: 0:00:41  Loss: 0.9525 (0.9525)  Acc@1: 75.0000 (75.0000)  Acc@5: 93.7500 (93.7500)  time: 0.6642  data: 0.4551  max mem: 2362
Test: [Task 4]  [10/63]  eta: 0:00:13  Loss: 0.7155 (0.7594)  Acc@1: 81.2500 (81.8182)  Acc@5: 100.0000 (97.7273)  time: 0.2471  data: 0.0417  max mem: 2362
Test: [Task 4]  [20/63]  eta: 0:00:09  Loss: 0.6775 (0.7330)  Acc@1: 81.2500 (82.7381)  Acc@5: 100.0000 (97.6190)  time: 0.2057  data: 0.0004  max mem: 2362
Test: [Task 4]  [30/63]  eta: 0:00:07  Loss: 0.5431 (0.6696)  Acc@1: 87.5000 (85.0806)  Acc@5: 100.0000 (97.9839)  time: 0.2063  data: 0.0004  max mem: 2362
Test: [Task 4]  [40/63]  eta: 0:00:04  Loss: 0.3883 (0.6080)  Acc@1: 87.5000 (86.4329)  Acc@5: 100.0000 (98.3232)  time: 0.2062  data: 0.0004  max mem: 2362
Test: [Task 4]  [50/63]  eta: 0:00:02  Loss: 0.4142 (0.6110)  Acc@1: 87.5000 (86.3971)  Acc@5: 100.0000 (97.9167)  time: 0.2057  data: 0.0004  max mem: 2362
Test: [Task 4]  [60/63]  eta: 0:00:00  Loss: 0.6728 (0.6341)  Acc@1: 87.5000 (85.6557)  Acc@5: 93.7500 (97.3361)  time: 0.2058  data: 0.0003  max mem: 2362
Test: [Task 4]  [62/63]  eta: 0:00:00  Loss: 0.6728 (0.6339)  Acc@1: 87.5000 (85.7000)  Acc@5: 93.7500 (97.4000)  time: 0.2010  data: 0.0003  max mem: 2362
Test: [Task 4] Total time: 0:00:13 (0.2134 s / it)
* Acc@1 85.700 Acc@5 97.400 loss 0.634
Test: [Task 5]  [ 0/63]  eta: 0:00:41  Loss: 0.3015 (0.3015)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)  time: 0.6582  data: 0.4509  max mem: 2362
Test: [Task 5]  [10/63]  eta: 0:00:13  Loss: 0.5144 (0.6523)  Acc@1: 93.7500 (89.2045)  Acc@5: 100.0000 (95.4545)  time: 0.2478  data: 0.0419  max mem: 2362
Test: [Task 5]  [20/63]  eta: 0:00:09  Loss: 0.4906 (0.5952)  Acc@1: 87.5000 (89.5833)  Acc@5: 100.0000 (96.4286)  time: 0.2068  data: 0.0013  max mem: 2362
Test: [Task 5]  [30/63]  eta: 0:00:07  Loss: 0.4906 (0.5904)  Acc@1: 87.5000 (89.3145)  Acc@5: 100.0000 (97.1774)  time: 0.2066  data: 0.0010  max mem: 2362
Test: [Task 5]  [40/63]  eta: 0:00:05  Loss: 0.5368 (0.5717)  Acc@1: 87.5000 (89.6341)  Acc@5: 100.0000 (97.2561)  time: 0.2062  data: 0.0004  max mem: 2362
Test: [Task 5]  [50/63]  eta: 0:00:02  Loss: 0.5380 (0.5735)  Acc@1: 93.7500 (90.0735)  Acc@5: 100.0000 (97.3039)  time: 0.2061  data: 0.0004  max mem: 2362
Test: [Task 5]  [60/63]  eta: 0:00:00  Loss: 0.6007 (0.6014)  Acc@1: 87.5000 (89.1393)  Acc@5: 100.0000 (97.1311)  time: 0.2066  data: 0.0003  max mem: 2362
Test: [Task 5]  [62/63]  eta: 0:00:00  Loss: 0.6064 (0.6227)  Acc@1: 87.5000 (88.5000)  Acc@5: 100.0000 (97.2000)  time: 0.2015  data: 0.0003  max mem: 2362
Test: [Task 5] Total time: 0:00:13 (0.2136 s / it)
* Acc@1 88.500 Acc@5 97.200 loss 0.623
Test: [Task 6]  [ 0/63]  eta: 0:00:34  Loss: 0.5933 (0.5933)  Acc@1: 81.2500 (81.2500)  Acc@5: 93.7500 (93.7500)  time: 0.5517  data: 0.3458  max mem: 2362
Test: [Task 6]  [10/63]  eta: 0:00:12  Loss: 0.7018 (0.7200)  Acc@1: 81.2500 (81.2500)  Acc@5: 93.7500 (95.4545)  time: 0.2374  data: 0.0317  max mem: 2362
Test: [Task 6]  [20/63]  eta: 0:00:09  Loss: 0.7080 (0.7518)  Acc@1: 81.2500 (81.5476)  Acc@5: 100.0000 (96.7262)  time: 0.2060  data: 0.0004  max mem: 2362
Test: [Task 6]  [30/63]  eta: 0:00:07  Loss: 0.6318 (0.7257)  Acc@1: 81.2500 (81.2500)  Acc@5: 100.0000 (97.1774)  time: 0.2061  data: 0.0004  max mem: 2362
Test: [Task 6]  [40/63]  eta: 0:00:04  Loss: 0.7673 (0.7778)  Acc@1: 81.2500 (79.2683)  Acc@5: 100.0000 (96.3415)  time: 0.2062  data: 0.0005  max mem: 2362
Test: [Task 6]  [50/63]  eta: 0:00:02  Loss: 0.7355 (0.7518)  Acc@1: 81.2500 (79.6569)  Acc@5: 100.0000 (96.8137)  time: 0.2066  data: 0.0004  max mem: 2362
Test: [Task 6]  [60/63]  eta: 0:00:00  Loss: 0.7023 (0.7683)  Acc@1: 81.2500 (79.6107)  Acc@5: 100.0000 (96.6189)  time: 0.2062  data: 0.0003  max mem: 2362
Test: [Task 6]  [62/63]  eta: 0:00:00  Loss: 0.7272 (0.7643)  Acc@1: 81.2500 (80.0000)  Acc@5: 100.0000 (96.7000)  time: 0.2012  data: 0.0003  max mem: 2362
Test: [Task 6] Total time: 0:00:13 (0.2117 s / it)
* Acc@1 80.000 Acc@5 96.700 loss 0.764
Test: [Task 7]  [ 0/63]  eta: 0:00:39  Loss: 0.8365 (0.8365)  Acc@1: 75.0000 (75.0000)  Acc@5: 100.0000 (100.0000)  time: 0.6194  data: 0.4109  max mem: 2362
Test: [Task 7]  [10/63]  eta: 0:00:12  Loss: 0.7296 (0.6687)  Acc@1: 87.5000 (85.2273)  Acc@5: 100.0000 (98.2955)  time: 0.2439  data: 0.0377  max mem: 2362
Test: [Task 7]  [20/63]  eta: 0:00:09  Loss: 0.7296 (0.7310)  Acc@1: 87.5000 (84.5238)  Acc@5: 100.0000 (96.1310)  time: 0.2065  data: 0.0004  max mem: 2362
Test: [Task 7]  [30/63]  eta: 0:00:07  Loss: 0.7389 (0.7191)  Acc@1: 81.2500 (84.2742)  Acc@5: 93.7500 (96.3710)  time: 0.2065  data: 0.0004  max mem: 2362
Test: [Task 7]  [40/63]  eta: 0:00:04  Loss: 0.6575 (0.6897)  Acc@1: 87.5000 (85.0610)  Acc@5: 100.0000 (96.4939)  time: 0.2063  data: 0.0004  max mem: 2362
Test: [Task 7]  [50/63]  eta: 0:00:02  Loss: 0.6377 (0.7147)  Acc@1: 81.2500 (84.3137)  Acc@5: 93.7500 (95.9559)  time: 0.2060  data: 0.0004  max mem: 2362
Test: [Task 7]  [60/63]  eta: 0:00:00  Loss: 0.6336 (0.6949)  Acc@1: 87.5000 (84.7336)  Acc@5: 93.7500 (96.0041)  time: 0.2061  data: 0.0004  max mem: 2362
Test: [Task 7]  [62/63]  eta: 0:00:00  Loss: 0.6336 (0.6972)  Acc@1: 81.2500 (84.7000)  Acc@5: 93.7500 (96.0000)  time: 0.2010  data: 0.0003  max mem: 2362
Test: [Task 7] Total time: 0:00:13 (0.2125 s / it)
* Acc@1 84.700 Acc@5 96.000 loss 0.697
{0: {0: 603, 1: 603, 2: 609, 3: 606, 4: 612, 5: 47, 6: 49, 7: 44, 8: 48, 9: 45, 10: 60, 11: 60, 12: 60, 13: 60, 14: 60, 15: 179, 16: 175, 17: 182, 18: 176, 19: 181, 20: 40, 21: 38, 22: 42, 23: 39, 24: 40, 25: 25, 26: 25, 27: 27, 28: 26, 29: 27, 30: 42, 31: 43, 32: 42, 33: 42, 34: 42, 35: 0, 36: 0, 37: 0, 38: 0, 39: 0, 40: 0, 41: 0, 42: 0, 43: 0, 44: 0, 45: 0, 46: 0, 47: 1, 48: 0, 49: 0}, 1: {0: 93, 1: 95, 2: 96, 3: 96, 4: 97, 5: 504, 6: 505, 7: 501, 8: 506, 9: 503, 10: 59, 11: 58, 12: 60, 13: 58, 14: 59, 15: 185, 16: 184, 17: 187, 18: 185, 19: 187, 20: 46, 21: 47, 22: 47, 23: 46, 24: 46, 25: 61, 26: 62, 27: 61, 28: 62, 29: 61, 30: 48, 31: 48, 32: 48, 33: 48, 34: 48, 35: 0, 36: 0, 37: 2, 38: 0, 39: 1, 40: 0, 41: 0, 42: 0, 43: 0, 44: 0, 45: 0, 46: 0, 47: 0, 48: 0, 49: 0}, 2: {0: 48, 1: 48, 2: 50, 3: 50, 4: 48, 5: 30, 6: 29, 7: 30, 8: 30, 9: 30, 10: 600, 11: 597, 12: 599, 13: 597, 14: 600, 15: 130, 16: 128, 17: 131, 18: 130, 19: 130, 20: 44, 21: 43, 22: 45, 23: 44, 24: 44, 25: 23, 26: 22, 27: 23, 28: 23, 29: 23, 30: 126, 31: 125, 32: 126, 33: 125, 34: 126, 35: 0, 36: 0, 37: 0, 38: 0, 39: 0, 40: 0, 41: 0, 42: 0, 43: 0, 44: 0, 45: 1, 46: 0, 47: 1, 48: 0, 49: 1}, 3: {0: 28, 1: 28, 2: 30, 3: 28, 4: 30, 5: 86, 6: 88, 7: 86, 8: 87, 9: 86, 10: 27, 11: 27, 12: 26, 13: 27, 14: 26, 15: 733, 16: 725, 17: 736, 18: 731, 19: 735, 20: 34, 21: 33, 22: 34, 23: 33, 24: 34, 25: 39, 26: 38, 27: 40, 28: 39, 29: 39, 30: 52, 31: 52, 32: 52, 33: 52, 34: 52, 35: 0, 36: 0, 37: 1, 38: 0, 39: 0, 40: 0, 41: 3, 42: 0, 43: 0, 44: 0, 45: 0, 46: 0, 47: 2, 48: 0, 49: 1}, 4: {0: 61, 1: 62, 2: 63, 3: 63, 4: 64, 5: 73, 6: 75, 7: 72, 8: 74, 9: 73, 10: 120, 11: 120, 12: 119, 13: 120, 14: 119, 15: 201, 16: 200, 17: 203, 18: 201, 19: 201, 20: 425, 21: 425, 22: 425, 23: 426, 24: 424, 25: 74, 26: 75, 27: 75, 28: 74, 29: 74, 30: 43, 31: 44, 32: 42, 33: 43, 34: 43, 35: 0, 36: 0, 37: 0, 38: 0, 39: 0, 40: 2, 41: 1, 42: 0, 43: 0, 44: 0, 45: 1, 46: 0, 47: 0, 48: 0, 49: 0}, 5: {0: 34, 1: 31, 2: 36, 3: 31, 4: 34, 5: 83, 6: 82, 7: 83, 8: 82, 9: 83, 10: 12, 11: 12, 12: 12, 13: 12, 14: 13, 15: 231, 16: 231, 17: 231, 18: 231, 19: 231, 20: 16, 21: 16, 22: 16, 23: 16, 24: 16, 25: 592, 26: 593, 27: 590, 28: 593, 29: 593, 30: 32, 31: 32, 32: 32, 33: 32, 34: 32, 35: 0, 36: 0, 37: 0, 38: 0, 39: 0, 40: 0, 41: 0, 42: 0, 43: 0, 44: 0, 45: 0, 46: 0, 47: 4, 48: 0, 49: 0}, 6: {0: 47, 1: 48, 2: 49, 3: 47, 4: 50, 5: 40, 6: 40, 7: 40, 8: 41, 9: 40, 10: 47, 11: 46, 12: 46, 13: 46, 14: 47, 15: 239, 16: 237, 17: 238, 18: 238, 19: 237, 20: 25, 21: 25, 22: 26, 23: 25, 24: 25, 25: 46, 26: 48, 27: 45, 28: 47, 29: 46, 30: 555, 31: 551, 32: 548, 33: 555, 34: 554, 35: 0, 36: 0, 37: 0, 38: 0, 39: 2, 40: 0, 41: 2, 42: 8, 43: 0, 44: 1, 45: 3, 46: 0, 47: 0, 48: 0, 49: 0}}
[Average accuracy till task7]	Acc@1: 84.8571	Acc@5: 97.3143	Loss: 0.6701	Forgetting: 4.8500	Backward: -4.8333
Train: Epoch[1/5]  [  0/313]  eta: 0:03:34  Lr: 0.001875  Loss: 1.3510  Acc@1: 6.2500 (6.2500)  Acc@5: 43.7500 (43.7500)  time: 0.6862  data: 0.3396  max mem: 2362
Train: Epoch[1/5]  [ 10/313]  eta: 0:01:50  Lr: 0.001875  Loss: 0.9665  Acc@1: 62.5000 (52.2727)  Acc@5: 81.2500 (80.1136)  time: 0.3638  data: 0.0314  max mem: 2362
Train: Epoch[1/5]  [ 20/313]  eta: 0:01:41  Lr: 0.001875  Loss: 0.4402  Acc@1: 75.0000 (64.2857)  Acc@5: 93.7500 (87.2024)  time: 0.3311  data: 0.0006  max mem: 2362
Train: Epoch[1/5]  [ 30/313]  eta: 0:01:36  Lr: 0.001875  Loss: 0.1304  Acc@1: 75.0000 (68.7500)  Acc@5: 100.0000 (90.1210)  time: 0.3304  data: 0.0005  max mem: 2362
Train: Epoch[1/5]  [ 40/313]  eta: 0:01:32  Lr: 0.001875  Loss: 0.0065  Acc@1: 81.2500 (72.1037)  Acc@5: 100.0000 (91.9207)  time: 0.3305  data: 0.0004  max mem: 2362
Train: Epoch[1/5]  [ 50/313]  eta: 0:01:28  Lr: 0.001875  Loss: -0.2925  Acc@1: 81.2500 (75.0000)  Acc@5: 100.0000 (92.8922)  time: 0.3303  data: 0.0003  max mem: 2362
Train: Epoch[1/5]  [ 60/313]  eta: 0:01:25  Lr: 0.001875  Loss: -0.4058  Acc@1: 87.5000 (77.0492)  Acc@5: 100.0000 (93.8525)  time: 0.3304  data: 0.0003  max mem: 2362
Train: Epoch[1/5]  [ 70/313]  eta: 0:01:21  Lr: 0.001875  Loss: -0.3779  Acc@1: 87.5000 (78.4331)  Acc@5: 100.0000 (94.3662)  time: 0.3304  data: 0.0003  max mem: 2362
Train: Epoch[1/5]  [ 80/313]  eta: 0:01:18  Lr: 0.001875  Loss: -0.5252  Acc@1: 87.5000 (79.1667)  Acc@5: 100.0000 (94.8302)  time: 0.3302  data: 0.0004  max mem: 2362
Train: Epoch[1/5]  [ 90/313]  eta: 0:01:14  Lr: 0.001875  Loss: -0.3106  Acc@1: 87.5000 (80.0137)  Acc@5: 100.0000 (95.3297)  time: 0.3302  data: 0.0004  max mem: 2362
Train: Epoch[1/5]  [100/313]  eta: 0:01:11  Lr: 0.001875  Loss: -0.2239  Acc@1: 81.2500 (80.2599)  Acc@5: 100.0000 (95.6064)  time: 0.3305  data: 0.0004  max mem: 2362
Train: Epoch[1/5]  [110/313]  eta: 0:01:07  Lr: 0.001875  Loss: -0.2326  Acc@1: 81.2500 (80.7432)  Acc@5: 100.0000 (95.7207)  time: 0.3304  data: 0.0004  max mem: 2362
Train: Epoch[1/5]  [120/313]  eta: 0:01:04  Lr: 0.001875  Loss: -0.1565  Acc@1: 87.5000 (81.0950)  Acc@5: 100.0000 (95.9194)  time: 0.3303  data: 0.0003  max mem: 2362
Train: Epoch[1/5]  [130/313]  eta: 0:01:00  Lr: 0.001875  Loss: -0.7350  Acc@1: 81.2500 (81.4408)  Acc@5: 100.0000 (95.9924)  time: 0.3303  data: 0.0004  max mem: 2362
Train: Epoch[1/5]  [140/313]  eta: 0:00:57  Lr: 0.001875  Loss: -0.7019  Acc@1: 81.2500 (81.6489)  Acc@5: 100.0000 (96.1879)  time: 0.3299  data: 0.0004  max mem: 2362
Train: Epoch[1/5]  [150/313]  eta: 0:00:54  Lr: 0.001875  Loss: -0.5738  Acc@1: 87.5000 (82.1606)  Acc@5: 100.0000 (96.3162)  time: 0.3309  data: 0.0012  max mem: 2362
Train: Epoch[1/5]  [160/313]  eta: 0:00:50  Lr: 0.001875  Loss: -0.9781  Acc@1: 87.5000 (82.5311)  Acc@5: 100.0000 (96.4286)  time: 0.3313  data: 0.0011  max mem: 2362
Train: Epoch[1/5]  [170/313]  eta: 0:00:47  Lr: 0.001875  Loss: -0.5551  Acc@1: 87.5000 (82.8947)  Acc@5: 100.0000 (96.5278)  time: 0.3306  data: 0.0004  max mem: 2362
Train: Epoch[1/5]  [180/313]  eta: 0:00:44  Lr: 0.001875  Loss: -0.8418  Acc@1: 87.5000 (83.2528)  Acc@5: 100.0000 (96.6851)  time: 0.3300  data: 0.0004  max mem: 2362
Train: Epoch[1/5]  [190/313]  eta: 0:00:40  Lr: 0.001875  Loss: -0.4397  Acc@1: 87.5000 (83.3115)  Acc@5: 100.0000 (96.7932)  time: 0.3297  data: 0.0004  max mem: 2362
Train: Epoch[1/5]  [200/313]  eta: 0:00:37  Lr: 0.001875  Loss: -0.4826  Acc@1: 81.2500 (83.3955)  Acc@5: 100.0000 (96.8595)  time: 0.3298  data: 0.0004  max mem: 2362
Train: Epoch[1/5]  [210/313]  eta: 0:00:34  Lr: 0.001875  Loss: -0.6544  Acc@1: 87.5000 (83.7382)  Acc@5: 100.0000 (96.9787)  time: 0.3297  data: 0.0004  max mem: 2362
Train: Epoch[1/5]  [220/313]  eta: 0:00:30  Lr: 0.001875  Loss: -1.0051  Acc@1: 87.5000 (83.9367)  Acc@5: 100.0000 (97.0305)  time: 0.3303  data: 0.0004  max mem: 2362
Train: Epoch[1/5]  [230/313]  eta: 0:00:27  Lr: 0.001875  Loss: -0.4139  Acc@1: 87.5000 (84.1721)  Acc@5: 100.0000 (97.1320)  time: 0.3306  data: 0.0004  max mem: 2362
Train: Epoch[1/5]  [240/313]  eta: 0:00:24  Lr: 0.001875  Loss: -0.8975  Acc@1: 93.7500 (84.4398)  Acc@5: 100.0000 (97.1992)  time: 0.3304  data: 0.0004  max mem: 2362
Train: Epoch[1/5]  [250/313]  eta: 0:00:20  Lr: 0.001875  Loss: -0.6996  Acc@1: 93.7500 (84.6863)  Acc@5: 100.0000 (97.2859)  time: 0.3307  data: 0.0006  max mem: 2362
Train: Epoch[1/5]  [260/313]  eta: 0:00:17  Lr: 0.001875  Loss: -0.7858  Acc@1: 93.7500 (84.9377)  Acc@5: 100.0000 (97.3659)  time: 0.3305  data: 0.0007  max mem: 2362
Train: Epoch[1/5]  [270/313]  eta: 0:00:14  Lr: 0.001875  Loss: -0.8676  Acc@1: 93.7500 (85.2168)  Acc@5: 100.0000 (97.4170)  time: 0.3303  data: 0.0005  max mem: 2362
Train: Epoch[1/5]  [280/313]  eta: 0:00:10  Lr: 0.001875  Loss: -0.9788  Acc@1: 93.7500 (85.3425)  Acc@5: 100.0000 (97.4199)  time: 0.3305  data: 0.0004  max mem: 2362
Train: Epoch[1/5]  [290/313]  eta: 0:00:07  Lr: 0.001875  Loss: -0.8014  Acc@1: 87.5000 (85.3952)  Acc@5: 100.0000 (97.4871)  time: 0.3306  data: 0.0004  max mem: 2362
Train: Epoch[1/5]  [300/313]  eta: 0:00:04  Lr: 0.001875  Loss: -0.5072  Acc@1: 87.5000 (85.5897)  Acc@5: 100.0000 (97.5083)  time: 0.3305  data: 0.0003  max mem: 2362
Train: Epoch[1/5]  [310/313]  eta: 0:00:00  Lr: 0.001875  Loss: -0.6715  Acc@1: 87.5000 (85.6712)  Acc@5: 100.0000 (97.5080)  time: 0.3305  data: 0.0003  max mem: 2362
Train: Epoch[1/5]  [312/313]  eta: 0:00:00  Lr: 0.001875  Loss: -0.7997  Acc@1: 87.5000 (85.7200)  Acc@5: 100.0000 (97.5200)  time: 0.3225  data: 0.0003  max mem: 2362
Train: Epoch[1/5] Total time: 0:01:43 (0.3314 s / it)
Averaged stats: Lr: 0.001875  Loss: -0.7997  Acc@1: 87.5000 (85.7200)  Acc@5: 100.0000 (97.5200)
Train: Epoch[2/5]  [  0/313]  eta: 0:03:44  Lr: 0.001875  Loss: -0.8017  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (100.0000)  time: 0.7164  data: 0.3839  max mem: 2362
Train: Epoch[2/5]  [ 10/313]  eta: 0:01:50  Lr: 0.001875  Loss: -0.8303  Acc@1: 87.5000 (86.9318)  Acc@5: 100.0000 (99.4318)  time: 0.3653  data: 0.0353  max mem: 2362
Train: Epoch[2/5]  [ 20/313]  eta: 0:01:42  Lr: 0.001875  Loss: -0.5352  Acc@1: 87.5000 (89.5833)  Acc@5: 100.0000 (99.4048)  time: 0.3305  data: 0.0004  max mem: 2362
Train: Epoch[2/5]  [ 30/313]  eta: 0:01:37  Lr: 0.001875  Loss: -0.5246  Acc@1: 87.5000 (88.7097)  Acc@5: 100.0000 (99.1935)  time: 0.3307  data: 0.0004  max mem: 2362
Train: Epoch[2/5]  [ 40/313]  eta: 0:01:32  Lr: 0.001875  Loss: -0.8826  Acc@1: 87.5000 (88.7195)  Acc@5: 100.0000 (98.7805)  time: 0.3309  data: 0.0005  max mem: 2362
Train: Epoch[2/5]  [ 50/313]  eta: 0:01:28  Lr: 0.001875  Loss: -0.8902  Acc@1: 87.5000 (88.4804)  Acc@5: 100.0000 (98.7745)  time: 0.3306  data: 0.0005  max mem: 2362
Train: Epoch[2/5]  [ 60/313]  eta: 0:01:25  Lr: 0.001875  Loss: -0.7304  Acc@1: 87.5000 (88.4221)  Acc@5: 100.0000 (98.8730)  time: 0.3306  data: 0.0004  max mem: 2362
Train: Epoch[2/5]  [ 70/313]  eta: 0:01:21  Lr: 0.001875  Loss: -0.7492  Acc@1: 87.5000 (88.0282)  Acc@5: 100.0000 (98.6796)  time: 0.3313  data: 0.0006  max mem: 2362
Train: Epoch[2/5]  [ 80/313]  eta: 0:01:18  Lr: 0.001875  Loss: -0.6402  Acc@1: 81.2500 (87.5772)  Acc@5: 100.0000 (98.3796)  time: 0.3317  data: 0.0006  max mem: 2362
Train: Epoch[2/5]  [ 90/313]  eta: 0:01:14  Lr: 0.001875  Loss: -0.7869  Acc@1: 87.5000 (87.3626)  Acc@5: 100.0000 (98.2830)  time: 0.3315  data: 0.0005  max mem: 2362
Train: Epoch[2/5]  [100/313]  eta: 0:01:11  Lr: 0.001875  Loss: -0.4824  Acc@1: 87.5000 (87.1906)  Acc@5: 100.0000 (98.0817)  time: 0.3308  data: 0.0004  max mem: 2362
Train: Epoch[2/5]  [110/313]  eta: 0:01:07  Lr: 0.001875  Loss: -0.8187  Acc@1: 87.5000 (87.1622)  Acc@5: 100.0000 (98.0856)  time: 0.3307  data: 0.0004  max mem: 2362
Train: Epoch[2/5]  [120/313]  eta: 0:01:04  Lr: 0.001875  Loss: -0.7755  Acc@1: 87.5000 (87.2934)  Acc@5: 100.0000 (98.0888)  time: 0.3314  data: 0.0004  max mem: 2362
Train: Epoch[2/5]  [130/313]  eta: 0:01:01  Lr: 0.001875  Loss: -0.2364  Acc@1: 87.5000 (87.4523)  Acc@5: 100.0000 (98.0916)  time: 0.3316  data: 0.0004  max mem: 2362
Train: Epoch[2/5]  [140/313]  eta: 0:00:57  Lr: 0.001875  Loss: -0.8014  Acc@1: 87.5000 (87.7660)  Acc@5: 100.0000 (98.2270)  time: 0.3314  data: 0.0007  max mem: 2362
Train: Epoch[2/5]  [150/313]  eta: 0:00:54  Lr: 0.001875  Loss: -1.0333  Acc@1: 93.7500 (87.7070)  Acc@5: 100.0000 (98.1788)  time: 0.3307  data: 0.0008  max mem: 2362
Train: Epoch[2/5]  [160/313]  eta: 0:00:50  Lr: 0.001875  Loss: -0.5322  Acc@1: 87.5000 (87.5388)  Acc@5: 100.0000 (98.2531)  time: 0.3302  data: 0.0004  max mem: 2362
Train: Epoch[2/5]  [170/313]  eta: 0:00:47  Lr: 0.001875  Loss: -0.8121  Acc@1: 87.5000 (87.7193)  Acc@5: 100.0000 (98.3553)  time: 0.3311  data: 0.0004  max mem: 2362
Train: Epoch[2/5]  [180/313]  eta: 0:00:44  Lr: 0.001875  Loss: -0.9217  Acc@1: 87.5000 (87.7762)  Acc@5: 100.0000 (98.3080)  time: 0.3316  data: 0.0004  max mem: 2362
Train: Epoch[2/5]  [190/313]  eta: 0:00:40  Lr: 0.001875  Loss: -0.6890  Acc@1: 87.5000 (88.0236)  Acc@5: 100.0000 (98.3639)  time: 0.3318  data: 0.0004  max mem: 2362
Train: Epoch[2/5]  [200/313]  eta: 0:00:37  Lr: 0.001875  Loss: -0.4946  Acc@1: 87.5000 (87.8420)  Acc@5: 100.0000 (98.2898)  time: 0.3310  data: 0.0004  max mem: 2362
Train: Epoch[2/5]  [210/313]  eta: 0:00:34  Lr: 0.001875  Loss: -0.5865  Acc@1: 87.5000 (87.9739)  Acc@5: 100.0000 (98.3709)  time: 0.3301  data: 0.0004  max mem: 2362
Train: Epoch[2/5]  [220/313]  eta: 0:00:30  Lr: 0.001875  Loss: -0.9383  Acc@1: 93.7500 (88.1505)  Acc@5: 100.0000 (98.3597)  time: 0.3305  data: 0.0004  max mem: 2362
Train: Epoch[2/5]  [230/313]  eta: 0:00:27  Lr: 0.001875  Loss: -0.9712  Acc@1: 93.7500 (88.1223)  Acc@5: 100.0000 (98.4037)  time: 0.3310  data: 0.0004  max mem: 2362
Train: Epoch[2/5]  [240/313]  eta: 0:00:24  Lr: 0.001875  Loss: -0.8754  Acc@1: 93.7500 (88.3039)  Acc@5: 100.0000 (98.4699)  time: 0.3314  data: 0.0004  max mem: 2362
Train: Epoch[2/5]  [250/313]  eta: 0:00:20  Lr: 0.001875  Loss: -0.7411  Acc@1: 87.5000 (88.0976)  Acc@5: 100.0000 (98.4064)  time: 0.3312  data: 0.0004  max mem: 2362
Train: Epoch[2/5]  [260/313]  eta: 0:00:17  Lr: 0.001875  Loss: -0.9321  Acc@1: 87.5000 (88.2184)  Acc@5: 100.0000 (98.3716)  time: 0.3310  data: 0.0004  max mem: 2362
Train: Epoch[2/5]  [270/313]  eta: 0:00:14  Lr: 0.001875  Loss: -0.9389  Acc@1: 93.7500 (88.4225)  Acc@5: 100.0000 (98.3856)  time: 0.3311  data: 0.0004  max mem: 2362
Train: Epoch[2/5]  [280/313]  eta: 0:00:10  Lr: 0.001875  Loss: -0.6676  Acc@1: 93.7500 (88.5231)  Acc@5: 100.0000 (98.4431)  time: 0.3313  data: 0.0004  max mem: 2362
Train: Epoch[2/5]  [290/313]  eta: 0:00:07  Lr: 0.001875  Loss: -0.6828  Acc@1: 93.7500 (88.5095)  Acc@5: 100.0000 (98.4536)  time: 0.3311  data: 0.0004  max mem: 2362
Train: Epoch[2/5]  [300/313]  eta: 0:00:04  Lr: 0.001875  Loss: -0.8648  Acc@1: 87.5000 (88.3098)  Acc@5: 100.0000 (98.4427)  time: 0.3312  data: 0.0004  max mem: 2362
Train: Epoch[2/5]  [310/313]  eta: 0:00:00  Lr: 0.001875  Loss: -0.5661  Acc@1: 87.5000 (88.3842)  Acc@5: 100.0000 (98.4325)  time: 0.3312  data: 0.0003  max mem: 2362
Train: Epoch[2/5]  [312/313]  eta: 0:00:00  Lr: 0.001875  Loss: -0.7632  Acc@1: 87.5000 (88.3800)  Acc@5: 100.0000 (98.4200)  time: 0.3232  data: 0.0003  max mem: 2362
Train: Epoch[2/5] Total time: 0:01:43 (0.3321 s / it)
Averaged stats: Lr: 0.001875  Loss: -0.7632  Acc@1: 87.5000 (88.3800)  Acc@5: 100.0000 (98.4200)
Train: Epoch[3/5]  [  0/313]  eta: 0:03:48  Lr: 0.001875  Loss: -0.7525  Acc@1: 93.7500 (93.7500)  Acc@5: 100.0000 (100.0000)  time: 0.7302  data: 0.3989  max mem: 2362
Train: Epoch[3/5]  [ 10/313]  eta: 0:01:51  Lr: 0.001875  Loss: -0.9237  Acc@1: 87.5000 (88.6364)  Acc@5: 100.0000 (98.2955)  time: 0.3674  data: 0.0366  max mem: 2362
Train: Epoch[3/5]  [ 20/313]  eta: 0:01:42  Lr: 0.001875  Loss: -0.5433  Acc@1: 87.5000 (88.3929)  Acc@5: 100.0000 (97.9167)  time: 0.3309  data: 0.0004  max mem: 2362
Train: Epoch[3/5]  [ 30/313]  eta: 0:01:37  Lr: 0.001875  Loss: -0.8256  Acc@1: 87.5000 (89.1129)  Acc@5: 100.0000 (98.3871)  time: 0.3307  data: 0.0004  max mem: 2362
Train: Epoch[3/5]  [ 40/313]  eta: 0:01:32  Lr: 0.001875  Loss: -0.8572  Acc@1: 87.5000 (88.7195)  Acc@5: 100.0000 (97.8659)  time: 0.3308  data: 0.0004  max mem: 2362
Train: Epoch[3/5]  [ 50/313]  eta: 0:01:29  Lr: 0.001875  Loss: -0.9766  Acc@1: 87.5000 (88.4804)  Acc@5: 100.0000 (97.7941)  time: 0.3317  data: 0.0004  max mem: 2362
Train: Epoch[3/5]  [ 60/313]  eta: 0:01:25  Lr: 0.001875  Loss: -0.7812  Acc@1: 87.5000 (88.5246)  Acc@5: 100.0000 (97.7459)  time: 0.3317  data: 0.0004  max mem: 2362
Train: Epoch[3/5]  [ 70/313]  eta: 0:01:21  Lr: 0.001875  Loss: -1.0535  Acc@1: 87.5000 (88.5563)  Acc@5: 100.0000 (97.9754)  time: 0.3307  data: 0.0004  max mem: 2362
Train: Epoch[3/5]  [ 80/313]  eta: 0:01:18  Lr: 0.001875  Loss: -0.9760  Acc@1: 93.7500 (88.8889)  Acc@5: 100.0000 (98.1481)  time: 0.3308  data: 0.0004  max mem: 2362
Train: Epoch[3/5]  [ 90/313]  eta: 0:01:14  Lr: 0.001875  Loss: -0.5568  Acc@1: 93.7500 (88.8736)  Acc@5: 100.0000 (98.2143)  time: 0.3311  data: 0.0004  max mem: 2362
Train: Epoch[3/5]  [100/313]  eta: 0:01:11  Lr: 0.001875  Loss: -0.6876  Acc@1: 93.7500 (88.7995)  Acc@5: 100.0000 (98.0817)  time: 0.3309  data: 0.0006  max mem: 2362
Train: Epoch[3/5]  [110/313]  eta: 0:01:07  Lr: 0.001875  Loss: -0.8283  Acc@1: 93.7500 (88.7950)  Acc@5: 100.0000 (98.0293)  time: 0.3309  data: 0.0007  max mem: 2362
Train: Epoch[3/5]  [120/313]  eta: 0:01:04  Lr: 0.001875  Loss: -0.7457  Acc@1: 93.7500 (88.9463)  Acc@5: 100.0000 (97.9855)  time: 0.3319  data: 0.0013  max mem: 2362
Train: Epoch[3/5]  [130/313]  eta: 0:01:01  Lr: 0.001875  Loss: -0.9987  Acc@1: 87.5000 (88.9313)  Acc@5: 100.0000 (98.0439)  time: 0.3320  data: 0.0012  max mem: 2362
Train: Epoch[3/5]  [140/313]  eta: 0:00:57  Lr: 0.001875  Loss: -1.0642  Acc@1: 87.5000 (89.0957)  Acc@5: 100.0000 (98.1826)  time: 0.3312  data: 0.0004  max mem: 2362
Train: Epoch[3/5]  [150/313]  eta: 0:00:54  Lr: 0.001875  Loss: -0.5969  Acc@1: 87.5000 (89.0315)  Acc@5: 100.0000 (98.2616)  time: 0.3313  data: 0.0004  max mem: 2362
Train: Epoch[3/5]  [160/313]  eta: 0:00:51  Lr: 0.001875  Loss: -0.8660  Acc@1: 87.5000 (88.9752)  Acc@5: 100.0000 (98.2143)  time: 0.3310  data: 0.0004  max mem: 2362
Train: Epoch[3/5]  [170/313]  eta: 0:00:47  Lr: 0.001875  Loss: -0.4762  Acc@1: 87.5000 (89.0716)  Acc@5: 100.0000 (98.2822)  time: 0.3310  data: 0.0004  max mem: 2362
Train: Epoch[3/5]  [180/313]  eta: 0:00:44  Lr: 0.001875  Loss: -0.9803  Acc@1: 93.7500 (89.1229)  Acc@5: 100.0000 (98.3425)  time: 0.3309  data: 0.0004  max mem: 2362
Train: Epoch[3/5]  [190/313]  eta: 0:00:40  Lr: 0.001875  Loss: -0.9620  Acc@1: 93.7500 (89.1034)  Acc@5: 100.0000 (98.3639)  time: 0.3309  data: 0.0006  max mem: 2362
Train: Epoch[3/5]  [200/313]  eta: 0:00:37  Lr: 0.001875  Loss: -0.8334  Acc@1: 87.5000 (89.1791)  Acc@5: 100.0000 (98.3831)  time: 0.3315  data: 0.0005  max mem: 2362
Train: Epoch[3/5]  [210/313]  eta: 0:00:34  Lr: 0.001875  Loss: -0.9723  Acc@1: 93.7500 (89.3365)  Acc@5: 100.0000 (98.4597)  time: 0.3312  data: 0.0004  max mem: 2362
Train: Epoch[3/5]  [220/313]  eta: 0:00:30  Lr: 0.001875  Loss: -0.6344  Acc@1: 93.7500 (89.3948)  Acc@5: 100.0000 (98.5011)  time: 0.3308  data: 0.0004  max mem: 2362
Train: Epoch[3/5]  [230/313]  eta: 0:00:27  Lr: 0.001875  Loss: -0.9489  Acc@1: 93.7500 (89.3398)  Acc@5: 100.0000 (98.5390)  time: 0.3313  data: 0.0004  max mem: 2362
Train: Epoch[3/5]  [240/313]  eta: 0:00:24  Lr: 0.001875  Loss: -0.7679  Acc@1: 93.7500 (89.2376)  Acc@5: 100.0000 (98.5477)  time: 0.3318  data: 0.0004  max mem: 2362
Train: Epoch[3/5]  [250/313]  eta: 0:00:20  Lr: 0.001875  Loss: -0.8797  Acc@1: 87.5000 (89.1434)  Acc@5: 100.0000 (98.5807)  time: 0.3317  data: 0.0004  max mem: 2362
Train: Epoch[3/5]  [260/313]  eta: 0:00:17  Lr: 0.001875  Loss: -0.9557  Acc@1: 87.5000 (89.2241)  Acc@5: 100.0000 (98.6111)  time: 0.3314  data: 0.0005  max mem: 2362
Train: Epoch[3/5]  [270/313]  eta: 0:00:14  Lr: 0.001875  Loss: -0.7654  Acc@1: 87.5000 (89.0452)  Acc@5: 100.0000 (98.6162)  time: 0.3311  data: 0.0004  max mem: 2362
Train: Epoch[3/5]  [280/313]  eta: 0:00:10  Lr: 0.001875  Loss: -0.6475  Acc@1: 87.5000 (89.1459)  Acc@5: 100.0000 (98.5988)  time: 0.3308  data: 0.0004  max mem: 2362
Train: Epoch[3/5]  [290/313]  eta: 0:00:07  Lr: 0.001875  Loss: -0.9628  Acc@1: 87.5000 (89.0464)  Acc@5: 100.0000 (98.6254)  time: 0.3311  data: 0.0004  max mem: 2362
Train: Epoch[3/5]  [300/313]  eta: 0:00:04  Lr: 0.001875  Loss: -0.8976  Acc@1: 87.5000 (89.0988)  Acc@5: 100.0000 (98.6088)  time: 0.3312  data: 0.0004  max mem: 2362
Train: Epoch[3/5]  [310/313]  eta: 0:00:00  Lr: 0.001875  Loss: -0.5730  Acc@1: 87.5000 (89.0072)  Acc@5: 100.0000 (98.6133)  time: 0.3307  data: 0.0004  max mem: 2362
Train: Epoch[3/5]  [312/313]  eta: 0:00:00  Lr: 0.001875  Loss: -0.9002  Acc@1: 87.5000 (89.0200)  Acc@5: 100.0000 (98.6200)  time: 0.3223  data: 0.0004  max mem: 2362
Train: Epoch[3/5] Total time: 0:01:44 (0.3323 s / it)
Averaged stats: Lr: 0.001875  Loss: -0.9002  Acc@1: 87.5000 (89.0200)  Acc@5: 100.0000 (98.6200)
Train: Epoch[4/5]  [  0/313]  eta: 0:04:04  Lr: 0.001875  Loss: -0.6576  Acc@1: 87.5000 (87.5000)  Acc@5: 93.7500 (93.7500)  time: 0.7801  data: 0.4454  max mem: 2362
Train: Epoch[4/5]  [ 10/313]  eta: 0:01:52  Lr: 0.001875  Loss: -0.8555  Acc@1: 93.7500 (92.6136)  Acc@5: 100.0000 (99.4318)  time: 0.3714  data: 0.0409  max mem: 2362
Train: Epoch[4/5]  [ 20/313]  eta: 0:01:43  Lr: 0.001875  Loss: -0.8496  Acc@1: 87.5000 (89.8810)  Acc@5: 100.0000 (98.8095)  time: 0.3312  data: 0.0004  max mem: 2362
Train: Epoch[4/5]  [ 30/313]  eta: 0:01:37  Lr: 0.001875  Loss: -0.6234  Acc@1: 87.5000 (89.1129)  Acc@5: 100.0000 (99.1935)  time: 0.3319  data: 0.0005  max mem: 2362
Train: Epoch[4/5]  [ 40/313]  eta: 0:01:33  Lr: 0.001875  Loss: -0.8348  Acc@1: 93.7500 (89.6341)  Acc@5: 100.0000 (99.2378)  time: 0.3317  data: 0.0004  max mem: 2362
Train: Epoch[4/5]  [ 50/313]  eta: 0:01:29  Lr: 0.001875  Loss: -0.7407  Acc@1: 87.5000 (89.3382)  Acc@5: 100.0000 (99.2647)  time: 0.3317  data: 0.0004  max mem: 2362
Train: Epoch[4/5]  [ 60/313]  eta: 0:01:25  Lr: 0.001875  Loss: -1.0351  Acc@1: 87.5000 (89.4467)  Acc@5: 100.0000 (99.3852)  time: 0.3313  data: 0.0004  max mem: 2362
Train: Epoch[4/5]  [ 70/313]  eta: 0:01:22  Lr: 0.001875  Loss: -0.8404  Acc@1: 93.7500 (89.8768)  Acc@5: 100.0000 (99.3838)  time: 0.3312  data: 0.0004  max mem: 2362
Train: Epoch[4/5]  [ 80/313]  eta: 0:01:18  Lr: 0.001875  Loss: -0.8266  Acc@1: 93.7500 (89.9691)  Acc@5: 100.0000 (99.3827)  time: 0.3317  data: 0.0005  max mem: 2362
Train: Epoch[4/5]  [ 90/313]  eta: 0:01:15  Lr: 0.001875  Loss: -0.2464  Acc@1: 93.7500 (89.9038)  Acc@5: 100.0000 (99.2445)  time: 0.3315  data: 0.0005  max mem: 2362
Train: Epoch[4/5]  [100/313]  eta: 0:01:11  Lr: 0.001875  Loss: -0.9900  Acc@1: 87.5000 (89.9134)  Acc@5: 100.0000 (99.0718)  time: 0.3319  data: 0.0004  max mem: 2362
Train: Epoch[4/5]  [110/313]  eta: 0:01:08  Lr: 0.001875  Loss: -0.4683  Acc@1: 87.5000 (89.8086)  Acc@5: 100.0000 (98.9865)  time: 0.3314  data: 0.0004  max mem: 2362
Train: Epoch[4/5]  [120/313]  eta: 0:01:04  Lr: 0.001875  Loss: -0.6533  Acc@1: 87.5000 (89.6178)  Acc@5: 100.0000 (98.9669)  time: 0.3307  data: 0.0004  max mem: 2362
Train: Epoch[4/5]  [130/313]  eta: 0:01:01  Lr: 0.001875  Loss: -0.9022  Acc@1: 87.5000 (89.2176)  Acc@5: 100.0000 (98.9027)  time: 0.3315  data: 0.0004  max mem: 2362
Train: Epoch[4/5]  [140/313]  eta: 0:00:57  Lr: 0.001875  Loss: -0.8587  Acc@1: 87.5000 (89.4060)  Acc@5: 100.0000 (98.9805)  time: 0.3318  data: 0.0004  max mem: 2362
Train: Epoch[4/5]  [150/313]  eta: 0:00:54  Lr: 0.001875  Loss: -0.5710  Acc@1: 87.5000 (89.0728)  Acc@5: 100.0000 (98.9238)  time: 0.3313  data: 0.0005  max mem: 2362
Train: Epoch[4/5]  [160/313]  eta: 0:00:51  Lr: 0.001875  Loss: -0.9285  Acc@1: 87.5000 (89.2857)  Acc@5: 100.0000 (98.9907)  time: 0.3313  data: 0.0004  max mem: 2362
Train: Epoch[4/5]  [170/313]  eta: 0:00:47  Lr: 0.001875  Loss: -0.8835  Acc@1: 93.7500 (89.3275)  Acc@5: 100.0000 (99.0132)  time: 0.3312  data: 0.0004  max mem: 2362
Train: Epoch[4/5]  [180/313]  eta: 0:00:44  Lr: 0.001875  Loss: -0.8584  Acc@1: 93.7500 (89.2956)  Acc@5: 100.0000 (99.0331)  time: 0.3313  data: 0.0008  max mem: 2362
Train: Epoch[4/5]  [190/313]  eta: 0:00:41  Lr: 0.001875  Loss: -0.9700  Acc@1: 93.7500 (89.5615)  Acc@5: 100.0000 (99.0183)  time: 0.3323  data: 0.0009  max mem: 2362
Train: Epoch[4/5]  [200/313]  eta: 0:00:37  Lr: 0.001875  Loss: -0.9474  Acc@1: 93.7500 (89.6144)  Acc@5: 100.0000 (98.9428)  time: 0.3324  data: 0.0005  max mem: 2362
Train: Epoch[4/5]  [210/313]  eta: 0:00:34  Lr: 0.001875  Loss: -0.8185  Acc@1: 93.7500 (89.7512)  Acc@5: 100.0000 (98.9336)  time: 0.3315  data: 0.0004  max mem: 2362
Train: Epoch[4/5]  [220/313]  eta: 0:00:31  Lr: 0.001875  Loss: -0.9572  Acc@1: 93.7500 (89.6776)  Acc@5: 100.0000 (98.9253)  time: 0.3307  data: 0.0004  max mem: 2362
Train: Epoch[4/5]  [230/313]  eta: 0:00:27  Lr: 0.001875  Loss: -0.6165  Acc@1: 87.5000 (89.6104)  Acc@5: 100.0000 (98.9177)  time: 0.3310  data: 0.0004  max mem: 2362
Train: Epoch[4/5]  [240/313]  eta: 0:00:24  Lr: 0.001875  Loss: -0.6991  Acc@1: 87.5000 (89.5488)  Acc@5: 100.0000 (98.8849)  time: 0.3322  data: 0.0004  max mem: 2362
Train: Epoch[4/5]  [250/313]  eta: 0:00:21  Lr: 0.001875  Loss: -0.8875  Acc@1: 93.7500 (89.7410)  Acc@5: 100.0000 (98.9044)  time: 0.3327  data: 0.0004  max mem: 2362
Train: Epoch[4/5]  [260/313]  eta: 0:00:17  Lr: 0.001875  Loss: -0.6837  Acc@1: 87.5000 (89.5833)  Acc@5: 100.0000 (98.8985)  time: 0.3321  data: 0.0004  max mem: 2362
Train: Epoch[4/5]  [270/313]  eta: 0:00:14  Lr: 0.001875  Loss: -0.5802  Acc@1: 87.5000 (89.5295)  Acc@5: 100.0000 (98.8238)  time: 0.3317  data: 0.0004  max mem: 2362
Train: Epoch[4/5]  [280/313]  eta: 0:00:10  Lr: 0.001875  Loss: -0.7977  Acc@1: 87.5000 (89.5018)  Acc@5: 100.0000 (98.8434)  time: 0.3313  data: 0.0004  max mem: 2362
Train: Epoch[4/5]  [290/313]  eta: 0:00:07  Lr: 0.001875  Loss: -0.7164  Acc@1: 87.5000 (89.3686)  Acc@5: 100.0000 (98.7973)  time: 0.3309  data: 0.0004  max mem: 2362
Train: Epoch[4/5]  [300/313]  eta: 0:00:04  Lr: 0.001875  Loss: -0.9191  Acc@1: 87.5000 (89.3688)  Acc@5: 100.0000 (98.8372)  time: 0.3307  data: 0.0004  max mem: 2362
Train: Epoch[4/5]  [310/313]  eta: 0:00:00  Lr: 0.001875  Loss: -0.9638  Acc@1: 87.5000 (89.2886)  Acc@5: 100.0000 (98.7138)  time: 0.3305  data: 0.0004  max mem: 2362
Train: Epoch[4/5]  [312/313]  eta: 0:00:00  Lr: 0.001875  Loss: -0.9654  Acc@1: 87.5000 (89.3000)  Acc@5: 100.0000 (98.7200)  time: 0.3224  data: 0.0004  max mem: 2362
Train: Epoch[4/5] Total time: 0:01:44 (0.3328 s / it)
Averaged stats: Lr: 0.001875  Loss: -0.9654  Acc@1: 87.5000 (89.3000)  Acc@5: 100.0000 (98.7200)
Train: Epoch[5/5]  [  0/313]  eta: 0:03:49  Lr: 0.001875  Loss: -0.6414  Acc@1: 81.2500 (81.2500)  Acc@5: 93.7500 (93.7500)  time: 0.7343  data: 0.3983  max mem: 2362
Train: Epoch[5/5]  [ 10/313]  eta: 0:01:51  Lr: 0.001875  Loss: -0.6478  Acc@1: 87.5000 (89.7727)  Acc@5: 100.0000 (98.2955)  time: 0.3686  data: 0.0365  max mem: 2362
Train: Epoch[5/5]  [ 20/313]  eta: 0:01:42  Lr: 0.001875  Loss: -0.8244  Acc@1: 93.7500 (90.1786)  Acc@5: 100.0000 (98.8095)  time: 0.3313  data: 0.0004  max mem: 2362
Train: Epoch[5/5]  [ 30/313]  eta: 0:01:37  Lr: 0.001875  Loss: -0.7654  Acc@1: 93.7500 (90.3226)  Acc@5: 100.0000 (98.9919)  time: 0.3306  data: 0.0004  max mem: 2362
Train: Epoch[5/5]  [ 40/313]  eta: 0:01:33  Lr: 0.001875  Loss: -0.6432  Acc@1: 87.5000 (90.0915)  Acc@5: 100.0000 (99.2378)  time: 0.3310  data: 0.0005  max mem: 2362
Train: Epoch[5/5]  [ 50/313]  eta: 0:01:29  Lr: 0.001875  Loss: -0.7407  Acc@1: 87.5000 (89.2157)  Acc@5: 100.0000 (98.8971)  time: 0.3309  data: 0.0005  max mem: 2362
Train: Epoch[5/5]  [ 60/313]  eta: 0:01:25  Lr: 0.001875  Loss: -1.0317  Acc@1: 87.5000 (89.6516)  Acc@5: 100.0000 (98.9754)  time: 0.3312  data: 0.0005  max mem: 2362
Train: Epoch[5/5]  [ 70/313]  eta: 0:01:21  Lr: 0.001875  Loss: -0.5577  Acc@1: 87.5000 (89.7887)  Acc@5: 100.0000 (99.1197)  time: 0.3317  data: 0.0004  max mem: 2362
Train: Epoch[5/5]  [ 80/313]  eta: 0:01:18  Lr: 0.001875  Loss: -1.0223  Acc@1: 93.7500 (89.9691)  Acc@5: 100.0000 (99.2284)  time: 0.3314  data: 0.0007  max mem: 2362
Train: Epoch[5/5]  [ 90/313]  eta: 0:01:14  Lr: 0.001875  Loss: -0.9492  Acc@1: 93.7500 (90.1099)  Acc@5: 100.0000 (99.2445)  time: 0.3315  data: 0.0006  max mem: 2362
Train: Epoch[5/5]  [100/313]  eta: 0:01:11  Lr: 0.001875  Loss: -0.7133  Acc@1: 93.7500 (90.2228)  Acc@5: 100.0000 (99.1955)  time: 0.3314  data: 0.0004  max mem: 2362
Train: Epoch[5/5]  [110/313]  eta: 0:01:07  Lr: 0.001875  Loss: -0.9307  Acc@1: 87.5000 (90.2590)  Acc@5: 100.0000 (99.2680)  time: 0.3315  data: 0.0004  max mem: 2362
Train: Epoch[5/5]  [120/313]  eta: 0:01:04  Lr: 0.001875  Loss: -0.7463  Acc@1: 87.5000 (89.8244)  Acc@5: 100.0000 (99.1736)  time: 0.3318  data: 0.0005  max mem: 2362
Train: Epoch[5/5]  [130/313]  eta: 0:01:01  Lr: 0.001875  Loss: -0.9107  Acc@1: 87.5000 (90.1240)  Acc@5: 100.0000 (99.2366)  time: 0.3316  data: 0.0005  max mem: 2362
Train: Epoch[5/5]  [140/313]  eta: 0:00:57  Lr: 0.001875  Loss: -0.7774  Acc@1: 93.7500 (89.9823)  Acc@5: 100.0000 (99.1135)  time: 0.3312  data: 0.0004  max mem: 2362
Train: Epoch[5/5]  [150/313]  eta: 0:00:54  Lr: 0.001875  Loss: -0.8287  Acc@1: 87.5000 (89.6523)  Acc@5: 100.0000 (99.1722)  time: 0.3311  data: 0.0004  max mem: 2362
Train: Epoch[5/5]  [160/313]  eta: 0:00:51  Lr: 0.001875  Loss: -1.0181  Acc@1: 87.5000 (89.4798)  Acc@5: 100.0000 (99.1460)  time: 0.3313  data: 0.0004  max mem: 2362
Train: Epoch[5/5]  [170/313]  eta: 0:00:47  Lr: 0.001875  Loss: -0.9786  Acc@1: 93.7500 (89.6564)  Acc@5: 100.0000 (99.0863)  time: 0.3317  data: 0.0004  max mem: 2362
Train: Epoch[5/5]  [180/313]  eta: 0:00:44  Lr: 0.001875  Loss: -0.6780  Acc@1: 93.7500 (89.5373)  Acc@5: 100.0000 (99.0677)  time: 0.3316  data: 0.0004  max mem: 2362
Train: Epoch[5/5]  [190/313]  eta: 0:00:41  Lr: 0.001875  Loss: -0.8145  Acc@1: 87.5000 (89.5942)  Acc@5: 100.0000 (99.0510)  time: 0.3309  data: 0.0004  max mem: 2362
Train: Epoch[5/5]  [200/313]  eta: 0:00:37  Lr: 0.001875  Loss: -0.8621  Acc@1: 87.5000 (89.5522)  Acc@5: 100.0000 (99.0050)  time: 0.3310  data: 0.0004  max mem: 2362
Train: Epoch[5/5]  [210/313]  eta: 0:00:34  Lr: 0.001875  Loss: -0.9785  Acc@1: 93.7500 (89.6919)  Acc@5: 100.0000 (98.9929)  time: 0.3315  data: 0.0005  max mem: 2362
Train: Epoch[5/5]  [220/313]  eta: 0:00:30  Lr: 0.001875  Loss: -0.7740  Acc@1: 87.5000 (89.5645)  Acc@5: 100.0000 (99.0102)  time: 0.3314  data: 0.0005  max mem: 2362
Train: Epoch[5/5]  [230/313]  eta: 0:00:27  Lr: 0.001875  Loss: -0.6987  Acc@1: 87.5000 (89.5833)  Acc@5: 100.0000 (99.0260)  time: 0.3312  data: 0.0005  max mem: 2362
Train: Epoch[5/5]  [240/313]  eta: 0:00:24  Lr: 0.001875  Loss: -0.7051  Acc@1: 87.5000 (89.4969)  Acc@5: 100.0000 (98.9886)  time: 0.3313  data: 0.0005  max mem: 2362
Train: Epoch[5/5]  [250/313]  eta: 0:00:20  Lr: 0.001875  Loss: -1.0438  Acc@1: 87.5000 (89.4920)  Acc@5: 100.0000 (98.9791)  time: 0.3307  data: 0.0004  max mem: 2362
Train: Epoch[5/5]  [260/313]  eta: 0:00:17  Lr: 0.001875  Loss: -0.9825  Acc@1: 87.5000 (89.4636)  Acc@5: 100.0000 (98.9943)  time: 0.3306  data: 0.0004  max mem: 2362
Train: Epoch[5/5]  [270/313]  eta: 0:00:14  Lr: 0.001875  Loss: -0.5406  Acc@1: 87.5000 (89.3911)  Acc@5: 100.0000 (99.0083)  time: 0.3313  data: 0.0004  max mem: 2362
Train: Epoch[5/5]  [280/313]  eta: 0:00:10  Lr: 0.001875  Loss: -0.3700  Acc@1: 87.5000 (89.3016)  Acc@5: 100.0000 (98.9324)  time: 0.3319  data: 0.0004  max mem: 2362
Train: Epoch[5/5]  [290/313]  eta: 0:00:07  Lr: 0.001875  Loss: -0.7883  Acc@1: 87.5000 (89.3041)  Acc@5: 100.0000 (98.9476)  time: 0.3312  data: 0.0004  max mem: 2362
Train: Epoch[5/5]  [300/313]  eta: 0:00:04  Lr: 0.001875  Loss: -0.9884  Acc@1: 93.7500 (89.3688)  Acc@5: 100.0000 (98.9826)  time: 0.3307  data: 0.0005  max mem: 2362
Train: Epoch[5/5]  [310/313]  eta: 0:00:00  Lr: 0.001875  Loss: -0.7193  Acc@1: 93.7500 (89.3489)  Acc@5: 100.0000 (98.9550)  time: 0.3312  data: 0.0005  max mem: 2362
Train: Epoch[5/5]  [312/313]  eta: 0:00:00  Lr: 0.001875  Loss: -0.7039  Acc@1: 93.7500 (89.3600)  Acc@5: 100.0000 (98.9600)  time: 0.3232  data: 0.0004  max mem: 2362
Train: Epoch[5/5] Total time: 0:01:44 (0.3324 s / it)
Averaged stats: Lr: 0.001875  Loss: -0.7039  Acc@1: 93.7500 (89.3600)  Acc@5: 100.0000 (98.9600)
Test: [Task 1]  [ 0/63]  eta: 0:00:30  Loss: 0.7216 (0.7216)  Acc@1: 75.0000 (75.0000)  Acc@5: 93.7500 (93.7500)  time: 0.4770  data: 0.2709  max mem: 2362
Test: [Task 1]  [10/63]  eta: 0:00:12  Loss: 0.6353 (0.6097)  Acc@1: 87.5000 (84.0909)  Acc@5: 100.0000 (98.8636)  time: 0.2302  data: 0.0250  max mem: 2362
Test: [Task 1]  [20/63]  eta: 0:00:09  Loss: 0.6353 (0.6882)  Acc@1: 81.2500 (82.4405)  Acc@5: 100.0000 (98.2143)  time: 0.2054  data: 0.0004  max mem: 2362
Test: [Task 1]  [30/63]  eta: 0:00:07  Loss: 0.5593 (0.6478)  Acc@1: 81.2500 (84.0726)  Acc@5: 100.0000 (98.5887)  time: 0.2057  data: 0.0004  max mem: 2362
Test: [Task 1]  [40/63]  eta: 0:00:04  Loss: 0.4626 (0.6263)  Acc@1: 87.5000 (84.9085)  Acc@5: 100.0000 (98.6280)  time: 0.2058  data: 0.0004  max mem: 2362
Test: [Task 1]  [50/63]  eta: 0:00:02  Loss: 0.5101 (0.6111)  Acc@1: 87.5000 (85.4167)  Acc@5: 100.0000 (98.5294)  time: 0.2056  data: 0.0004  max mem: 2362
Test: [Task 1]  [60/63]  eta: 0:00:00  Loss: 0.5101 (0.6010)  Acc@1: 87.5000 (85.7582)  Acc@5: 100.0000 (98.4631)  time: 0.2055  data: 0.0003  max mem: 2362
Test: [Task 1]  [62/63]  eta: 0:00:00  Loss: 0.4872 (0.5977)  Acc@1: 87.5000 (86.0000)  Acc@5: 100.0000 (98.5000)  time: 0.2007  data: 0.0003  max mem: 2362
Test: [Task 1] Total time: 0:00:13 (0.2106 s / it)
* Acc@1 86.000 Acc@5 98.500 loss 0.598
Test: [Task 2]  [ 0/63]  eta: 0:00:40  Loss: 0.8772 (0.8772)  Acc@1: 81.2500 (81.2500)  Acc@5: 93.7500 (93.7500)  time: 0.6486  data: 0.4417  max mem: 2362
Test: [Task 2]  [10/63]  eta: 0:00:13  Loss: 0.7546 (0.7633)  Acc@1: 81.2500 (82.9545)  Acc@5: 93.7500 (96.0227)  time: 0.2456  data: 0.0404  max mem: 2362
Test: [Task 2]  [20/63]  eta: 0:00:09  Loss: 0.7546 (0.8456)  Acc@1: 81.2500 (80.3571)  Acc@5: 100.0000 (96.7262)  time: 0.2053  data: 0.0004  max mem: 2362
Test: [Task 2]  [30/63]  eta: 0:00:07  Loss: 0.8354 (0.8380)  Acc@1: 75.0000 (81.0484)  Acc@5: 100.0000 (96.5726)  time: 0.2053  data: 0.0004  max mem: 2362
Test: [Task 2]  [40/63]  eta: 0:00:04  Loss: 0.7484 (0.8154)  Acc@1: 81.2500 (81.8598)  Acc@5: 100.0000 (96.9512)  time: 0.2054  data: 0.0003  max mem: 2362
Test: [Task 2]  [50/63]  eta: 0:00:02  Loss: 0.7008 (0.8032)  Acc@1: 81.2500 (82.1078)  Acc@5: 100.0000 (96.9363)  time: 0.2056  data: 0.0003  max mem: 2362
Test: [Task 2]  [60/63]  eta: 0:00:00  Loss: 0.6517 (0.7752)  Acc@1: 87.5000 (82.9918)  Acc@5: 100.0000 (97.3361)  time: 0.2054  data: 0.0003  max mem: 2362
Test: [Task 2]  [62/63]  eta: 0:00:00  Loss: 0.6505 (0.7652)  Acc@1: 87.5000 (83.0000)  Acc@5: 100.0000 (97.4000)  time: 0.2006  data: 0.0003  max mem: 2362
Test: [Task 2] Total time: 0:00:13 (0.2129 s / it)
* Acc@1 83.000 Acc@5 97.400 loss 0.765
Test: [Task 3]  [ 0/63]  eta: 0:00:41  Loss: 0.4040 (0.4040)  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (100.0000)  time: 0.6641  data: 0.4596  max mem: 2362
Test: [Task 3]  [10/63]  eta: 0:00:13  Loss: 0.6360 (0.6624)  Acc@1: 81.2500 (80.6818)  Acc@5: 100.0000 (97.7273)  time: 0.2471  data: 0.0421  max mem: 2362
Test: [Task 3]  [20/63]  eta: 0:00:09  Loss: 0.6622 (0.6487)  Acc@1: 81.2500 (82.1429)  Acc@5: 100.0000 (97.3214)  time: 0.2057  data: 0.0004  max mem: 2362
Test: [Task 3]  [30/63]  eta: 0:00:07  Loss: 0.6622 (0.6347)  Acc@1: 81.2500 (83.0645)  Acc@5: 100.0000 (97.7823)  time: 0.2060  data: 0.0004  max mem: 2362
Test: [Task 3]  [40/63]  eta: 0:00:04  Loss: 0.5209 (0.6364)  Acc@1: 87.5000 (83.8415)  Acc@5: 100.0000 (97.5610)  time: 0.2059  data: 0.0004  max mem: 2362
Test: [Task 3]  [50/63]  eta: 0:00:02  Loss: 0.5898 (0.6438)  Acc@1: 87.5000 (84.0686)  Acc@5: 100.0000 (97.5490)  time: 0.2059  data: 0.0004  max mem: 2362
Test: [Task 3]  [60/63]  eta: 0:00:00  Loss: 0.6926 (0.6462)  Acc@1: 87.5000 (83.8115)  Acc@5: 100.0000 (97.7459)  time: 0.2058  data: 0.0003  max mem: 2362
Test: [Task 3]  [62/63]  eta: 0:00:00  Loss: 0.6926 (0.6494)  Acc@1: 81.2500 (83.6000)  Acc@5: 100.0000 (97.8000)  time: 0.2011  data: 0.0003  max mem: 2362
Test: [Task 3] Total time: 0:00:13 (0.2132 s / it)
* Acc@1 83.600 Acc@5 97.800 loss 0.649
Test: [Task 4]  [ 0/63]  eta: 0:00:34  Loss: 0.8549 (0.8549)  Acc@1: 81.2500 (81.2500)  Acc@5: 93.7500 (93.7500)  time: 0.5512  data: 0.3436  max mem: 2362
Test: [Task 4]  [10/63]  eta: 0:00:12  Loss: 0.7513 (0.7551)  Acc@1: 81.2500 (82.3864)  Acc@5: 100.0000 (97.7273)  time: 0.2372  data: 0.0316  max mem: 2362
Test: [Task 4]  [20/63]  eta: 0:00:09  Loss: 0.6987 (0.7283)  Acc@1: 81.2500 (82.7381)  Acc@5: 100.0000 (97.0238)  time: 0.2058  data: 0.0004  max mem: 2362
Test: [Task 4]  [30/63]  eta: 0:00:07  Loss: 0.5461 (0.6814)  Acc@1: 87.5000 (84.0726)  Acc@5: 100.0000 (97.5806)  time: 0.2061  data: 0.0004  max mem: 2362
Test: [Task 4]  [40/63]  eta: 0:00:04  Loss: 0.3810 (0.6146)  Acc@1: 87.5000 (85.9756)  Acc@5: 100.0000 (98.0183)  time: 0.2062  data: 0.0004  max mem: 2362
Test: [Task 4]  [50/63]  eta: 0:00:02  Loss: 0.3822 (0.6164)  Acc@1: 87.5000 (86.0294)  Acc@5: 100.0000 (97.5490)  time: 0.2057  data: 0.0003  max mem: 2362
Test: [Task 4]  [60/63]  eta: 0:00:00  Loss: 0.6165 (0.6360)  Acc@1: 87.5000 (85.4508)  Acc@5: 93.7500 (96.9262)  time: 0.2054  data: 0.0003  max mem: 2362
Test: [Task 4]  [62/63]  eta: 0:00:00  Loss: 0.6165 (0.6361)  Acc@1: 87.5000 (85.5000)  Acc@5: 93.7500 (97.0000)  time: 0.2003  data: 0.0003  max mem: 2362
Test: [Task 4] Total time: 0:00:13 (0.2115 s / it)
* Acc@1 85.500 Acc@5 97.000 loss 0.636
Test: [Task 5]  [ 0/63]  eta: 0:00:35  Loss: 0.2995 (0.2995)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)  time: 0.5614  data: 0.3523  max mem: 2362
Test: [Task 5]  [10/63]  eta: 0:00:12  Loss: 0.4949 (0.6327)  Acc@1: 93.7500 (90.3409)  Acc@5: 100.0000 (95.4545)  time: 0.2385  data: 0.0324  max mem: 2362
Test: [Task 5]  [20/63]  eta: 0:00:09  Loss: 0.4949 (0.5852)  Acc@1: 93.7500 (90.1786)  Acc@5: 100.0000 (96.4286)  time: 0.2061  data: 0.0004  max mem: 2362
Test: [Task 5]  [30/63]  eta: 0:00:07  Loss: 0.5146 (0.5799)  Acc@1: 87.5000 (89.5161)  Acc@5: 100.0000 (97.1774)  time: 0.2061  data: 0.0004  max mem: 2362
Test: [Task 5]  [40/63]  eta: 0:00:04  Loss: 0.5146 (0.5654)  Acc@1: 87.5000 (89.6341)  Acc@5: 100.0000 (97.1037)  time: 0.2059  data: 0.0003  max mem: 2362
Test: [Task 5]  [50/63]  eta: 0:00:02  Loss: 0.5354 (0.5699)  Acc@1: 93.7500 (90.1961)  Acc@5: 100.0000 (97.3039)  time: 0.2066  data: 0.0004  max mem: 2362
Test: [Task 5]  [60/63]  eta: 0:00:00  Loss: 0.5577 (0.5919)  Acc@1: 87.5000 (89.2418)  Acc@5: 100.0000 (97.0287)  time: 0.2068  data: 0.0003  max mem: 2362
Test: [Task 5]  [62/63]  eta: 0:00:00  Loss: 0.6036 (0.6108)  Acc@1: 87.5000 (88.7000)  Acc@5: 100.0000 (97.0000)  time: 0.2018  data: 0.0003  max mem: 2362
Test: [Task 5] Total time: 0:00:13 (0.2115 s / it)
* Acc@1 88.700 Acc@5 97.000 loss 0.611
Test: [Task 6]  [ 0/63]  eta: 0:00:34  Loss: 0.5725 (0.5725)  Acc@1: 81.2500 (81.2500)  Acc@5: 93.7500 (93.7500)  time: 0.5552  data: 0.3463  max mem: 2362
Test: [Task 6]  [10/63]  eta: 0:00:12  Loss: 0.7090 (0.7130)  Acc@1: 81.2500 (81.2500)  Acc@5: 93.7500 (95.4545)  time: 0.2376  data: 0.0318  max mem: 2362
Test: [Task 6]  [20/63]  eta: 0:00:09  Loss: 0.7173 (0.7485)  Acc@1: 81.2500 (80.9524)  Acc@5: 100.0000 (96.4286)  time: 0.2056  data: 0.0004  max mem: 2362
Test: [Task 6]  [30/63]  eta: 0:00:07  Loss: 0.6374 (0.7330)  Acc@1: 81.2500 (80.6452)  Acc@5: 100.0000 (96.9758)  time: 0.2056  data: 0.0004  max mem: 2362
Test: [Task 6]  [40/63]  eta: 0:00:04  Loss: 0.8102 (0.7829)  Acc@1: 81.2500 (78.9634)  Acc@5: 100.0000 (96.0366)  time: 0.2059  data: 0.0004  max mem: 2362
Test: [Task 6]  [50/63]  eta: 0:00:02  Loss: 0.7410 (0.7557)  Acc@1: 81.2500 (79.4118)  Acc@5: 93.7500 (96.4461)  time: 0.2058  data: 0.0004  max mem: 2362
Test: [Task 6]  [60/63]  eta: 0:00:00  Loss: 0.7018 (0.7687)  Acc@1: 81.2500 (79.4057)  Acc@5: 100.0000 (96.3115)  time: 0.2054  data: 0.0003  max mem: 2362
Test: [Task 6]  [62/63]  eta: 0:00:00  Loss: 0.7018 (0.7632)  Acc@1: 81.2500 (79.8000)  Acc@5: 100.0000 (96.4000)  time: 0.2005  data: 0.0003  max mem: 2362
Test: [Task 6] Total time: 0:00:13 (0.2111 s / it)
* Acc@1 79.800 Acc@5 96.400 loss 0.763
Test: [Task 7]  [ 0/63]  eta: 0:00:31  Loss: 0.7763 (0.7763)  Acc@1: 75.0000 (75.0000)  Acc@5: 100.0000 (100.0000)  time: 0.4939  data: 0.2880  max mem: 2362
Test: [Task 7]  [10/63]  eta: 0:00:12  Loss: 0.6898 (0.6934)  Acc@1: 81.2500 (83.5227)  Acc@5: 100.0000 (97.7273)  time: 0.2320  data: 0.0265  max mem: 2362
Test: [Task 7]  [20/63]  eta: 0:00:09  Loss: 0.6898 (0.7561)  Acc@1: 81.2500 (82.7381)  Acc@5: 93.7500 (95.8333)  time: 0.2058  data: 0.0004  max mem: 2362
Test: [Task 7]  [30/63]  eta: 0:00:07  Loss: 0.7675 (0.7417)  Acc@1: 81.2500 (83.0645)  Acc@5: 93.7500 (95.9677)  time: 0.2061  data: 0.0005  max mem: 2362
Test: [Task 7]  [40/63]  eta: 0:00:04  Loss: 0.6600 (0.7133)  Acc@1: 87.5000 (83.8415)  Acc@5: 100.0000 (96.4939)  time: 0.2062  data: 0.0004  max mem: 2362
Test: [Task 7]  [50/63]  eta: 0:00:02  Loss: 0.6424 (0.7354)  Acc@1: 87.5000 (83.5784)  Acc@5: 100.0000 (96.0784)  time: 0.2059  data: 0.0004  max mem: 2362
Test: [Task 7]  [60/63]  eta: 0:00:00  Loss: 0.6019 (0.7187)  Acc@1: 87.5000 (84.0164)  Acc@5: 93.7500 (96.1066)  time: 0.2055  data: 0.0003  max mem: 2362
Test: [Task 7]  [62/63]  eta: 0:00:00  Loss: 0.6035 (0.7186)  Acc@1: 87.5000 (84.0000)  Acc@5: 93.7500 (96.1000)  time: 0.2007  data: 0.0003  max mem: 2362
Test: [Task 7] Total time: 0:00:13 (0.2101 s / it)
* Acc@1 84.000 Acc@5 96.100 loss 0.719
Test: [Task 8]  [ 0/63]  eta: 0:00:32  Loss: 0.6396 (0.6396)  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (100.0000)  time: 0.5235  data: 0.3163  max mem: 2362
Test: [Task 8]  [10/63]  eta: 0:00:12  Loss: 0.7712 (0.7809)  Acc@1: 81.2500 (81.8182)  Acc@5: 93.7500 (96.0227)  time: 0.2348  data: 0.0291  max mem: 2362
Test: [Task 8]  [20/63]  eta: 0:00:09  Loss: 0.7381 (0.8035)  Acc@1: 81.2500 (82.1429)  Acc@5: 93.7500 (96.4286)  time: 0.2059  data: 0.0004  max mem: 2362
Test: [Task 8]  [30/63]  eta: 0:00:07  Loss: 0.7029 (0.7625)  Acc@1: 81.2500 (82.8629)  Acc@5: 100.0000 (96.7742)  time: 0.2056  data: 0.0003  max mem: 2362
Test: [Task 8]  [40/63]  eta: 0:00:04  Loss: 0.7307 (0.7515)  Acc@1: 81.2500 (82.4695)  Acc@5: 93.7500 (96.6463)  time: 0.2055  data: 0.0003  max mem: 2362
Test: [Task 8]  [50/63]  eta: 0:00:02  Loss: 0.7307 (0.7443)  Acc@1: 81.2500 (82.3529)  Acc@5: 93.7500 (96.3235)  time: 0.2053  data: 0.0003  max mem: 2362
Test: [Task 8]  [60/63]  eta: 0:00:00  Loss: 0.7365 (0.7576)  Acc@1: 81.2500 (82.1721)  Acc@5: 93.7500 (95.4918)  time: 0.2053  data: 0.0003  max mem: 2362
Test: [Task 8]  [62/63]  eta: 0:00:00  Loss: 0.7254 (0.7459)  Acc@1: 81.2500 (82.4000)  Acc@5: 93.7500 (95.6000)  time: 0.2003  data: 0.0003  max mem: 2362
Test: [Task 8] Total time: 0:00:13 (0.2109 s / it)
* Acc@1 82.400 Acc@5 95.600 loss 0.746
{0: {0: 574, 1: 579, 2: 579, 3: 579, 4: 584, 5: 47, 6: 49, 7: 44, 8: 48, 9: 45, 10: 56, 11: 56, 12: 56, 13: 56, 14: 56, 15: 163, 16: 159, 17: 166, 18: 160, 19: 165, 20: 27, 21: 27, 22: 31, 23: 27, 24: 29, 25: 22, 26: 22, 27: 23, 28: 23, 29: 23, 30: 9, 31: 9, 32: 9, 33: 9, 34: 9, 35: 96, 36: 96, 37: 95, 38: 96, 39: 96, 40: 0, 41: 0, 42: 0, 43: 0, 44: 0, 45: 0, 46: 0, 47: 1, 48: 0, 49: 0}, 1: {0: 76, 1: 79, 2: 81, 3: 81, 4: 81, 5: 489, 6: 492, 7: 487, 8: 491, 9: 488, 10: 49, 11: 49, 12: 50, 13: 49, 14: 49, 15: 174, 16: 173, 17: 176, 18: 174, 19: 176, 20: 32, 21: 33, 22: 33, 23: 32, 24: 32, 25: 55, 26: 55, 27: 54, 28: 55, 29: 54, 30: 29, 31: 29, 32: 29, 33: 29, 34: 29, 35: 91, 36: 91, 37: 92, 38: 91, 39: 91, 40: 0, 41: 0, 42: 0, 43: 0, 44: 0, 45: 0, 46: 0, 47: 0, 48: 0, 49: 0}, 2: {0: 45, 1: 45, 2: 47, 3: 47, 4: 45, 5: 29, 6: 28, 7: 29, 8: 29, 9: 29, 10: 568, 11: 565, 12: 567, 13: 565, 14: 568, 15: 102, 16: 100, 17: 103, 18: 102, 19: 102, 20: 33, 21: 32, 22: 34, 23: 33, 24: 33, 25: 21, 26: 20, 27: 21, 28: 21, 29: 21, 30: 37, 31: 36, 32: 37, 33: 36, 34: 37, 35: 166, 36: 166, 37: 166, 38: 166, 39: 166, 40: 0, 41: 0, 42: 0, 43: 0, 44: 0, 45: 1, 46: 0, 47: 1, 48: 0, 49: 1}, 3: {0: 24, 1: 24, 2: 25, 3: 24, 4: 25, 5: 85, 6: 87, 7: 85, 8: 86, 9: 85, 10: 17, 11: 17, 12: 16, 13: 17, 14: 16, 15: 648, 16: 641, 17: 652, 18: 647, 19: 651, 20: 28, 21: 27, 22: 28, 23: 27, 24: 28, 25: 36, 26: 36, 27: 37, 28: 36, 29: 36, 30: 15, 31: 15, 32: 15, 33: 15, 34: 15, 35: 146, 36: 146, 37: 145, 38: 146, 39: 145, 40: 0, 41: 3, 42: 0, 43: 0, 44: 0, 45: 0, 46: 0, 47: 2, 48: 0, 49: 1}, 4: {0: 50, 1: 50, 2: 51, 3: 51, 4: 52, 5: 72, 6: 74, 7: 71, 8: 73, 9: 72, 10: 98, 11: 98, 12: 98, 13: 98, 14: 98, 15: 183, 16: 182, 17: 185, 18: 183, 19: 183, 20: 383, 21: 382, 22: 383, 23: 383, 24: 382, 25: 70, 26: 71, 27: 71, 28: 70, 29: 70, 30: 9, 31: 9, 32: 8, 33: 9, 34: 9, 35: 133, 36: 133, 37: 133, 38: 133, 39: 133, 40: 2, 41: 1, 42: 0, 43: 0, 44: 0, 45: 1, 46: 0, 47: 0, 48: 0, 49: 0}, 5: {0: 28, 1: 25, 2: 30, 3: 25, 4: 27, 5: 83, 6: 82, 7: 83, 8: 82, 9: 83, 10: 5, 11: 5, 12: 6, 13: 5, 14: 6, 15: 187, 16: 187, 17: 187, 18: 187, 19: 187, 20: 10, 21: 10, 22: 10, 23: 10, 24: 10, 25: 574, 26: 575, 27: 572, 28: 575, 29: 575, 30: 12, 31: 12, 32: 12, 33: 12, 34: 12, 35: 101, 36: 101, 37: 101, 38: 101, 39: 101, 40: 0, 41: 0, 42: 0, 43: 0, 44: 0, 45: 0, 46: 0, 47: 4, 48: 0, 49: 0}, 6: {0: 37, 1: 40, 2: 39, 3: 39, 4: 41, 5: 38, 6: 38, 7: 38, 8: 39, 9: 38, 10: 39, 11: 38, 12: 38, 13: 38, 14: 39, 15: 220, 16: 218, 17: 219, 18: 219, 19: 219, 20: 22, 21: 22, 22: 23, 23: 22, 24: 22, 25: 40, 26: 42, 27: 40, 28: 41, 29: 40, 30: 418, 31: 415, 32: 412, 33: 420, 34: 418, 35: 183, 36: 183, 37: 183, 38: 183, 39: 183, 40: 0, 41: 2, 42: 8, 43: 0, 44: 1, 45: 3, 46: 0, 47: 0, 48: 0, 49: 0}, 7: {0: 39, 1: 39, 2: 42, 3: 42, 4: 45, 5: 49, 6: 48, 7: 49, 8: 48, 9: 49, 10: 32, 11: 30, 12: 32, 13: 30, 14: 32, 15: 100, 16: 99, 17: 100, 18: 99, 19: 100, 20: 17, 21: 17, 22: 17, 23: 17, 24: 17, 25: 49, 26: 49, 27: 49, 28: 49, 29: 49, 30: 35, 31: 36, 32: 35, 33: 36, 34: 35, 35: 678, 36: 679, 37: 676, 38: 678, 39: 677, 40: 0, 41: 0, 42: 0, 43: 1, 44: 0, 45: 0, 46: 0, 47: 0, 48: 0, 49: 0}}
[Average accuracy till task8]	Acc@1: 84.1250	Acc@5: 96.9750	Loss: 0.6859	Forgetting: 4.6429	Backward: -4.6286
Train: Epoch[1/5]  [  0/313]  eta: 0:03:41  Lr: 0.001875  Loss: 1.2416  Acc@1: 12.5000 (12.5000)  Acc@5: 31.2500 (31.2500)  time: 0.7070  data: 0.3559  max mem: 2362
Train: Epoch[1/5]  [ 10/313]  eta: 0:01:50  Lr: 0.001875  Loss: 0.7326  Acc@1: 75.0000 (57.3864)  Acc@5: 87.5000 (86.9318)  time: 0.3638  data: 0.0327  max mem: 2362
Train: Epoch[1/5]  [ 20/313]  eta: 0:01:41  Lr: 0.001875  Loss: 0.4701  Acc@1: 75.0000 (70.2381)  Acc@5: 93.7500 (91.3690)  time: 0.3297  data: 0.0004  max mem: 2362
Train: Epoch[1/5]  [ 30/313]  eta: 0:01:36  Lr: 0.001875  Loss: 0.1165  Acc@1: 81.2500 (73.3871)  Acc@5: 100.0000 (92.9435)  time: 0.3303  data: 0.0004  max mem: 2362
Train: Epoch[1/5]  [ 40/313]  eta: 0:01:32  Lr: 0.001875  Loss: -0.0265  Acc@1: 87.5000 (77.4390)  Acc@5: 100.0000 (93.9024)  time: 0.3306  data: 0.0004  max mem: 2362
Train: Epoch[1/5]  [ 50/313]  eta: 0:01:28  Lr: 0.001875  Loss: -0.1597  Acc@1: 87.5000 (79.6569)  Acc@5: 100.0000 (94.8529)  time: 0.3301  data: 0.0004  max mem: 2362
Train: Epoch[1/5]  [ 60/313]  eta: 0:01:25  Lr: 0.001875  Loss: -0.2380  Acc@1: 87.5000 (80.4303)  Acc@5: 100.0000 (95.4918)  time: 0.3302  data: 0.0004  max mem: 2362
Train: Epoch[1/5]  [ 70/313]  eta: 0:01:21  Lr: 0.001875  Loss: -0.4915  Acc@1: 93.7500 (81.8662)  Acc@5: 100.0000 (95.6866)  time: 0.3309  data: 0.0004  max mem: 2362
Train: Epoch[1/5]  [ 80/313]  eta: 0:01:18  Lr: 0.001875  Loss: -0.3407  Acc@1: 93.7500 (82.6389)  Acc@5: 100.0000 (95.9877)  time: 0.3306  data: 0.0005  max mem: 2362
Train: Epoch[1/5]  [ 90/313]  eta: 0:01:14  Lr: 0.001875  Loss: -0.5425  Acc@1: 87.5000 (82.8984)  Acc@5: 100.0000 (96.2912)  time: 0.3301  data: 0.0005  max mem: 2362
Train: Epoch[1/5]  [100/313]  eta: 0:01:11  Lr: 0.001875  Loss: -0.5625  Acc@1: 87.5000 (83.1064)  Acc@5: 100.0000 (96.4109)  time: 0.3298  data: 0.0005  max mem: 2362
Train: Epoch[1/5]  [110/313]  eta: 0:01:07  Lr: 0.001875  Loss: -0.5947  Acc@1: 87.5000 (83.7838)  Acc@5: 100.0000 (96.5653)  time: 0.3302  data: 0.0003  max mem: 2362
Train: Epoch[1/5]  [120/313]  eta: 0:01:04  Lr: 0.001875  Loss: -0.3655  Acc@1: 87.5000 (83.7810)  Acc@5: 100.0000 (96.6942)  time: 0.3313  data: 0.0003  max mem: 2362
Train: Epoch[1/5]  [130/313]  eta: 0:01:00  Lr: 0.001875  Loss: -0.7331  Acc@1: 81.2500 (83.9695)  Acc@5: 100.0000 (96.8511)  time: 0.3312  data: 0.0005  max mem: 2362
Train: Epoch[1/5]  [140/313]  eta: 0:00:57  Lr: 0.001875  Loss: -0.8717  Acc@1: 93.7500 (84.4858)  Acc@5: 100.0000 (97.0301)  time: 0.3300  data: 0.0006  max mem: 2362
Train: Epoch[1/5]  [150/313]  eta: 0:00:54  Lr: 0.001875  Loss: -0.8711  Acc@1: 93.7500 (84.8510)  Acc@5: 100.0000 (97.1440)  time: 0.3303  data: 0.0005  max mem: 2362
Train: Epoch[1/5]  [160/313]  eta: 0:00:50  Lr: 0.001875  Loss: -0.6354  Acc@1: 87.5000 (84.9767)  Acc@5: 100.0000 (97.2050)  time: 0.3304  data: 0.0004  max mem: 2362
Train: Epoch[1/5]  [170/313]  eta: 0:00:47  Lr: 0.001875  Loss: -0.7327  Acc@1: 87.5000 (85.3436)  Acc@5: 100.0000 (97.3319)  time: 0.3300  data: 0.0004  max mem: 2362
Train: Epoch[1/5]  [180/313]  eta: 0:00:44  Lr: 0.001875  Loss: -0.5914  Acc@1: 87.5000 (85.3936)  Acc@5: 100.0000 (97.3757)  time: 0.3309  data: 0.0004  max mem: 2362
Train: Epoch[1/5]  [190/313]  eta: 0:00:40  Lr: 0.001875  Loss: -0.6943  Acc@1: 87.5000 (85.7330)  Acc@5: 100.0000 (97.4804)  time: 0.3309  data: 0.0005  max mem: 2362
Train: Epoch[1/5]  [200/313]  eta: 0:00:37  Lr: 0.001875  Loss: -0.7620  Acc@1: 93.7500 (85.9453)  Acc@5: 100.0000 (97.5435)  time: 0.3311  data: 0.0005  max mem: 2362
Train: Epoch[1/5]  [210/313]  eta: 0:00:34  Lr: 0.001875  Loss: -0.7104  Acc@1: 87.5000 (86.0486)  Acc@5: 100.0000 (97.5415)  time: 0.3309  data: 0.0004  max mem: 2362
Train: Epoch[1/5]  [220/313]  eta: 0:00:30  Lr: 0.001875  Loss: -0.9279  Acc@1: 87.5000 (86.1425)  Acc@5: 100.0000 (97.5396)  time: 0.3298  data: 0.0004  max mem: 2362
Train: Epoch[1/5]  [230/313]  eta: 0:00:27  Lr: 0.001875  Loss: -0.9329  Acc@1: 93.7500 (86.4177)  Acc@5: 100.0000 (97.5920)  time: 0.3302  data: 0.0004  max mem: 2362
Train: Epoch[1/5]  [240/313]  eta: 0:00:24  Lr: 0.001875  Loss: -0.9051  Acc@1: 93.7500 (86.6183)  Acc@5: 100.0000 (97.6919)  time: 0.3309  data: 0.0004  max mem: 2362
Train: Epoch[1/5]  [250/313]  eta: 0:00:20  Lr: 0.001875  Loss: -0.9384  Acc@1: 87.5000 (86.8277)  Acc@5: 100.0000 (97.7341)  time: 0.3308  data: 0.0004  max mem: 2362
Train: Epoch[1/5]  [260/313]  eta: 0:00:17  Lr: 0.001875  Loss: -0.6925  Acc@1: 87.5000 (86.9013)  Acc@5: 100.0000 (97.7490)  time: 0.3303  data: 0.0005  max mem: 2362
Train: Epoch[1/5]  [270/313]  eta: 0:00:14  Lr: 0.001875  Loss: -0.7005  Acc@1: 87.5000 (87.0618)  Acc@5: 100.0000 (97.8321)  time: 0.3303  data: 0.0004  max mem: 2362
Train: Epoch[1/5]  [280/313]  eta: 0:00:10  Lr: 0.001875  Loss: -0.8647  Acc@1: 93.7500 (87.2553)  Acc@5: 100.0000 (97.8648)  time: 0.3304  data: 0.0004  max mem: 2362
Train: Epoch[1/5]  [290/313]  eta: 0:00:07  Lr: 0.001875  Loss: -0.5126  Acc@1: 87.5000 (87.1564)  Acc@5: 100.0000 (97.8522)  time: 0.3303  data: 0.0004  max mem: 2362
Train: Epoch[1/5]  [300/313]  eta: 0:00:04  Lr: 0.001875  Loss: -0.5304  Acc@1: 87.5000 (87.2301)  Acc@5: 100.0000 (97.8613)  time: 0.3301  data: 0.0004  max mem: 2362
Train: Epoch[1/5]  [310/313]  eta: 0:00:00  Lr: 0.001875  Loss: -0.7375  Acc@1: 87.5000 (87.4196)  Acc@5: 100.0000 (97.8899)  time: 0.3304  data: 0.0004  max mem: 2362
Train: Epoch[1/5]  [312/313]  eta: 0:00:00  Lr: 0.001875  Loss: -1.0050  Acc@1: 93.7500 (87.4600)  Acc@5: 100.0000 (97.9000)  time: 0.3223  data: 0.0003  max mem: 2362
Train: Epoch[1/5] Total time: 0:01:43 (0.3316 s / it)
Averaged stats: Lr: 0.001875  Loss: -1.0050  Acc@1: 93.7500 (87.4600)  Acc@5: 100.0000 (97.9000)
Train: Epoch[2/5]  [  0/313]  eta: 0:03:40  Lr: 0.001875  Loss: -0.9014  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (100.0000)  time: 0.7054  data: 0.3743  max mem: 2362
Train: Epoch[2/5]  [ 10/313]  eta: 0:01:50  Lr: 0.001875  Loss: -0.8547  Acc@1: 93.7500 (90.3409)  Acc@5: 100.0000 (100.0000)  time: 0.3651  data: 0.0343  max mem: 2362
Train: Epoch[2/5]  [ 20/313]  eta: 0:01:42  Lr: 0.001875  Loss: -0.8321  Acc@1: 93.7500 (91.3690)  Acc@5: 100.0000 (100.0000)  time: 0.3307  data: 0.0004  max mem: 2362
Train: Epoch[2/5]  [ 30/313]  eta: 0:01:37  Lr: 0.001875  Loss: -1.0236  Acc@1: 87.5000 (90.7258)  Acc@5: 100.0000 (99.5968)  time: 0.3305  data: 0.0004  max mem: 2362
Train: Epoch[2/5]  [ 40/313]  eta: 0:01:32  Lr: 0.001875  Loss: -0.9961  Acc@1: 87.5000 (89.9390)  Acc@5: 100.0000 (99.3902)  time: 0.3313  data: 0.0003  max mem: 2362
Train: Epoch[2/5]  [ 50/313]  eta: 0:01:28  Lr: 0.001875  Loss: -0.9187  Acc@1: 87.5000 (89.5833)  Acc@5: 100.0000 (99.2647)  time: 0.3310  data: 0.0003  max mem: 2362
Train: Epoch[2/5]  [ 60/313]  eta: 0:01:25  Lr: 0.001875  Loss: -0.9528  Acc@1: 87.5000 (89.3443)  Acc@5: 100.0000 (99.1803)  time: 0.3299  data: 0.0003  max mem: 2362
Train: Epoch[2/5]  [ 70/313]  eta: 0:01:21  Lr: 0.001875  Loss: -0.8828  Acc@1: 93.7500 (89.6127)  Acc@5: 100.0000 (99.2958)  time: 0.3305  data: 0.0009  max mem: 2362
Train: Epoch[2/5]  [ 80/313]  eta: 0:01:18  Lr: 0.001875  Loss: -0.9089  Acc@1: 87.5000 (89.5062)  Acc@5: 100.0000 (99.3056)  time: 0.3315  data: 0.0008  max mem: 2362
Train: Epoch[2/5]  [ 90/313]  eta: 0:01:14  Lr: 0.001875  Loss: -0.8526  Acc@1: 87.5000 (89.6291)  Acc@5: 100.0000 (99.2445)  time: 0.3312  data: 0.0004  max mem: 2362
Train: Epoch[2/5]  [100/313]  eta: 0:01:11  Lr: 0.001875  Loss: -1.0576  Acc@1: 93.7500 (90.0371)  Acc@5: 100.0000 (99.1337)  time: 0.3310  data: 0.0004  max mem: 2362
Train: Epoch[2/5]  [110/313]  eta: 0:01:07  Lr: 0.001875  Loss: -0.6977  Acc@1: 93.7500 (90.0901)  Acc@5: 100.0000 (99.2117)  time: 0.3309  data: 0.0004  max mem: 2362
Train: Epoch[2/5]  [120/313]  eta: 0:01:04  Lr: 0.001875  Loss: -0.7286  Acc@1: 87.5000 (89.8760)  Acc@5: 100.0000 (99.1219)  time: 0.3303  data: 0.0004  max mem: 2362
Train: Epoch[2/5]  [130/313]  eta: 0:01:01  Lr: 0.001875  Loss: -0.5088  Acc@1: 87.5000 (89.8855)  Acc@5: 100.0000 (99.0935)  time: 0.3306  data: 0.0004  max mem: 2362
Train: Epoch[2/5]  [140/313]  eta: 0:00:57  Lr: 0.001875  Loss: -0.7109  Acc@1: 87.5000 (89.7163)  Acc@5: 100.0000 (98.9805)  time: 0.3309  data: 0.0004  max mem: 2362
Train: Epoch[2/5]  [150/313]  eta: 0:00:54  Lr: 0.001875  Loss: -0.5712  Acc@1: 87.5000 (89.8593)  Acc@5: 100.0000 (98.9652)  time: 0.3300  data: 0.0004  max mem: 2362
Train: Epoch[2/5]  [160/313]  eta: 0:00:50  Lr: 0.001875  Loss: -0.7371  Acc@1: 93.7500 (89.9845)  Acc@5: 100.0000 (98.9130)  time: 0.3300  data: 0.0004  max mem: 2362
Train: Epoch[2/5]  [170/313]  eta: 0:00:47  Lr: 0.001875  Loss: -1.0143  Acc@1: 93.7500 (89.9854)  Acc@5: 100.0000 (98.9401)  time: 0.3306  data: 0.0003  max mem: 2362
Train: Epoch[2/5]  [180/313]  eta: 0:00:44  Lr: 0.001875  Loss: -0.4754  Acc@1: 87.5000 (89.7445)  Acc@5: 100.0000 (98.8605)  time: 0.3304  data: 0.0003  max mem: 2362
Train: Epoch[2/5]  [190/313]  eta: 0:00:40  Lr: 0.001875  Loss: -0.6601  Acc@1: 87.5000 (89.8233)  Acc@5: 100.0000 (98.9202)  time: 0.3306  data: 0.0004  max mem: 2362
Train: Epoch[2/5]  [200/313]  eta: 0:00:37  Lr: 0.001875  Loss: -1.0289  Acc@1: 87.5000 (89.7699)  Acc@5: 100.0000 (98.8495)  time: 0.3309  data: 0.0004  max mem: 2362
Train: Epoch[2/5]  [210/313]  eta: 0:00:34  Lr: 0.001875  Loss: -0.6195  Acc@1: 87.5000 (89.7808)  Acc@5: 100.0000 (98.8152)  time: 0.3303  data: 0.0005  max mem: 2362
Train: Epoch[2/5]  [220/313]  eta: 0:00:30  Lr: 0.001875  Loss: -0.6650  Acc@1: 93.7500 (89.8756)  Acc@5: 100.0000 (98.8405)  time: 0.3305  data: 0.0005  max mem: 2362
Train: Epoch[2/5]  [230/313]  eta: 0:00:27  Lr: 0.001875  Loss: -0.8978  Acc@1: 93.7500 (89.8268)  Acc@5: 100.0000 (98.8636)  time: 0.3308  data: 0.0004  max mem: 2362
Train: Epoch[2/5]  [240/313]  eta: 0:00:24  Lr: 0.001875  Loss: -0.9116  Acc@1: 93.7500 (89.9637)  Acc@5: 100.0000 (98.8330)  time: 0.3298  data: 0.0004  max mem: 2362
Train: Epoch[2/5]  [250/313]  eta: 0:00:20  Lr: 0.001875  Loss: -0.7646  Acc@1: 93.7500 (89.8904)  Acc@5: 100.0000 (98.8546)  time: 0.3295  data: 0.0004  max mem: 2362
Train: Epoch[2/5]  [260/313]  eta: 0:00:17  Lr: 0.001875  Loss: -0.7517  Acc@1: 87.5000 (89.8467)  Acc@5: 100.0000 (98.8506)  time: 0.3302  data: 0.0008  max mem: 2362
Train: Epoch[2/5]  [270/313]  eta: 0:00:14  Lr: 0.001875  Loss: -1.0354  Acc@1: 93.7500 (89.9677)  Acc@5: 100.0000 (98.8699)  time: 0.3304  data: 0.0008  max mem: 2362
Train: Epoch[2/5]  [280/313]  eta: 0:00:10  Lr: 0.001875  Loss: -0.7866  Acc@1: 87.5000 (89.8354)  Acc@5: 100.0000 (98.8657)  time: 0.3304  data: 0.0004  max mem: 2362
Train: Epoch[2/5]  [290/313]  eta: 0:00:07  Lr: 0.001875  Loss: -0.8949  Acc@1: 87.5000 (89.9270)  Acc@5: 100.0000 (98.8402)  time: 0.3304  data: 0.0003  max mem: 2362
Train: Epoch[2/5]  [300/313]  eta: 0:00:04  Lr: 0.001875  Loss: -1.0039  Acc@1: 93.7500 (89.9709)  Acc@5: 100.0000 (98.8580)  time: 0.3312  data: 0.0006  max mem: 2362
Train: Epoch[2/5]  [310/313]  eta: 0:00:00  Lr: 0.001875  Loss: -0.6525  Acc@1: 93.7500 (89.9518)  Acc@5: 100.0000 (98.8947)  time: 0.3306  data: 0.0006  max mem: 2362
Train: Epoch[2/5]  [312/313]  eta: 0:00:00  Lr: 0.001875  Loss: -0.7805  Acc@1: 87.5000 (89.9400)  Acc@5: 100.0000 (98.9000)  time: 0.3220  data: 0.0006  max mem: 2362
Train: Epoch[2/5] Total time: 0:01:43 (0.3317 s / it)
Averaged stats: Lr: 0.001875  Loss: -0.7805  Acc@1: 87.5000 (89.9400)  Acc@5: 100.0000 (98.9000)
Train: Epoch[3/5]  [  0/313]  eta: 0:03:47  Lr: 0.001875  Loss: -0.8594  Acc@1: 93.7500 (93.7500)  Acc@5: 100.0000 (100.0000)  time: 0.7278  data: 0.3978  max mem: 2362
Train: Epoch[3/5]  [ 10/313]  eta: 0:01:50  Lr: 0.001875  Loss: -0.4871  Acc@1: 93.7500 (90.9091)  Acc@5: 100.0000 (98.8636)  time: 0.3663  data: 0.0364  max mem: 2362
Train: Epoch[3/5]  [ 20/313]  eta: 0:01:42  Lr: 0.001875  Loss: -0.6891  Acc@1: 87.5000 (90.7738)  Acc@5: 100.0000 (98.8095)  time: 0.3298  data: 0.0003  max mem: 2362
Train: Epoch[3/5]  [ 30/313]  eta: 0:01:37  Lr: 0.001875  Loss: -0.6159  Acc@1: 87.5000 (90.7258)  Acc@5: 100.0000 (98.9919)  time: 0.3301  data: 0.0004  max mem: 2362
Train: Epoch[3/5]  [ 40/313]  eta: 0:01:32  Lr: 0.001875  Loss: -0.9409  Acc@1: 87.5000 (91.0061)  Acc@5: 100.0000 (99.0854)  time: 0.3309  data: 0.0004  max mem: 2362
Train: Epoch[3/5]  [ 50/313]  eta: 0:01:28  Lr: 0.001875  Loss: -1.0468  Acc@1: 93.7500 (91.1765)  Acc@5: 100.0000 (99.1422)  time: 0.3304  data: 0.0003  max mem: 2362
Train: Epoch[3/5]  [ 60/313]  eta: 0:01:25  Lr: 0.001875  Loss: -0.6650  Acc@1: 87.5000 (90.6762)  Acc@5: 100.0000 (99.1803)  time: 0.3299  data: 0.0003  max mem: 2362
Train: Epoch[3/5]  [ 70/313]  eta: 0:01:21  Lr: 0.001875  Loss: -1.0350  Acc@1: 87.5000 (90.3169)  Acc@5: 100.0000 (99.2958)  time: 0.3303  data: 0.0003  max mem: 2362
Train: Epoch[3/5]  [ 80/313]  eta: 0:01:18  Lr: 0.001875  Loss: -1.0344  Acc@1: 87.5000 (90.2006)  Acc@5: 100.0000 (99.2284)  time: 0.3305  data: 0.0004  max mem: 2362
Train: Epoch[3/5]  [ 90/313]  eta: 0:01:14  Lr: 0.001875  Loss: -0.7979  Acc@1: 87.5000 (90.4533)  Acc@5: 100.0000 (98.9698)  time: 0.3301  data: 0.0004  max mem: 2362
Train: Epoch[3/5]  [100/313]  eta: 0:01:11  Lr: 0.001875  Loss: -0.6019  Acc@1: 93.7500 (90.5941)  Acc@5: 100.0000 (98.9480)  time: 0.3306  data: 0.0004  max mem: 2362
Train: Epoch[3/5]  [110/313]  eta: 0:01:07  Lr: 0.001875  Loss: -0.7835  Acc@1: 93.7500 (90.5405)  Acc@5: 100.0000 (98.8739)  time: 0.3307  data: 0.0004  max mem: 2362
Train: Epoch[3/5]  [120/313]  eta: 0:01:04  Lr: 0.001875  Loss: -0.8208  Acc@1: 93.7500 (90.4442)  Acc@5: 100.0000 (98.8120)  time: 0.3301  data: 0.0004  max mem: 2362
Train: Epoch[3/5]  [130/313]  eta: 0:01:01  Lr: 0.001875  Loss: -0.7165  Acc@1: 87.5000 (90.3626)  Acc@5: 100.0000 (98.9027)  time: 0.3303  data: 0.0004  max mem: 2362
Train: Epoch[3/5]  [140/313]  eta: 0:00:57  Lr: 0.001875  Loss: -0.8622  Acc@1: 93.7500 (90.6028)  Acc@5: 100.0000 (98.9805)  time: 0.3309  data: 0.0004  max mem: 2362
Train: Epoch[3/5]  [150/313]  eta: 0:00:54  Lr: 0.001875  Loss: -1.0007  Acc@1: 93.7500 (90.6043)  Acc@5: 100.0000 (99.0480)  time: 0.3309  data: 0.0003  max mem: 2362
Train: Epoch[3/5]  [160/313]  eta: 0:00:50  Lr: 0.001875  Loss: -0.8059  Acc@1: 87.5000 (90.4891)  Acc@5: 100.0000 (99.0683)  time: 0.3307  data: 0.0003  max mem: 2362
Train: Epoch[3/5]  [170/313]  eta: 0:00:47  Lr: 0.001875  Loss: -0.7568  Acc@1: 87.5000 (90.5336)  Acc@5: 100.0000 (99.0863)  time: 0.3311  data: 0.0007  max mem: 2362
Train: Epoch[3/5]  [180/313]  eta: 0:00:44  Lr: 0.001875  Loss: -0.8766  Acc@1: 93.7500 (90.6077)  Acc@5: 100.0000 (99.1367)  time: 0.3312  data: 0.0008  max mem: 2362
Train: Epoch[3/5]  [190/313]  eta: 0:00:40  Lr: 0.001875  Loss: -0.8468  Acc@1: 93.7500 (90.6414)  Acc@5: 100.0000 (99.1165)  time: 0.3308  data: 0.0004  max mem: 2362
Train: Epoch[3/5]  [200/313]  eta: 0:00:37  Lr: 0.001875  Loss: -1.0442  Acc@1: 93.7500 (90.6716)  Acc@5: 100.0000 (99.1294)  time: 0.3303  data: 0.0004  max mem: 2362
Train: Epoch[3/5]  [210/313]  eta: 0:00:34  Lr: 0.001875  Loss: -1.0034  Acc@1: 93.7500 (90.7583)  Acc@5: 100.0000 (99.1410)  time: 0.3306  data: 0.0004  max mem: 2362
Train: Epoch[3/5]  [220/313]  eta: 0:00:30  Lr: 0.001875  Loss: -0.9617  Acc@1: 93.7500 (90.8937)  Acc@5: 100.0000 (99.1799)  time: 0.3316  data: 0.0005  max mem: 2362
Train: Epoch[3/5]  [230/313]  eta: 0:00:27  Lr: 0.001875  Loss: -0.7929  Acc@1: 93.7500 (90.8820)  Acc@5: 100.0000 (99.1883)  time: 0.3318  data: 0.0005  max mem: 2362
Train: Epoch[3/5]  [240/313]  eta: 0:00:24  Lr: 0.001875  Loss: -1.1269  Acc@1: 87.5000 (90.9232)  Acc@5: 100.0000 (99.1961)  time: 0.3316  data: 0.0004  max mem: 2362
Train: Epoch[3/5]  [250/313]  eta: 0:00:20  Lr: 0.001875  Loss: -0.8987  Acc@1: 93.7500 (90.9861)  Acc@5: 100.0000 (99.2032)  time: 0.3320  data: 0.0005  max mem: 2362
Train: Epoch[3/5]  [260/313]  eta: 0:00:17  Lr: 0.001875  Loss: -1.0090  Acc@1: 87.5000 (90.7328)  Acc@5: 100.0000 (99.1140)  time: 0.3314  data: 0.0004  max mem: 2362
Train: Epoch[3/5]  [270/313]  eta: 0:00:14  Lr: 0.001875  Loss: -1.0524  Acc@1: 87.5000 (90.7518)  Acc@5: 100.0000 (99.1006)  time: 0.3311  data: 0.0004  max mem: 2362
Train: Epoch[3/5]  [280/313]  eta: 0:00:10  Lr: 0.001875  Loss: -0.9177  Acc@1: 93.7500 (90.7696)  Acc@5: 100.0000 (99.0658)  time: 0.3311  data: 0.0004  max mem: 2362
Train: Epoch[3/5]  [290/313]  eta: 0:00:07  Lr: 0.001875  Loss: -0.9921  Acc@1: 93.7500 (90.7431)  Acc@5: 100.0000 (99.0979)  time: 0.3307  data: 0.0005  max mem: 2362
Train: Epoch[3/5]  [300/313]  eta: 0:00:04  Lr: 0.001875  Loss: -1.0230  Acc@1: 87.5000 (90.6977)  Acc@5: 100.0000 (99.0656)  time: 0.3304  data: 0.0005  max mem: 2362
Train: Epoch[3/5]  [310/313]  eta: 0:00:00  Lr: 0.001875  Loss: -0.7694  Acc@1: 87.5000 (90.6752)  Acc@5: 100.0000 (99.0354)  time: 0.3308  data: 0.0005  max mem: 2362
Train: Epoch[3/5]  [312/313]  eta: 0:00:00  Lr: 0.001875  Loss: -1.2860  Acc@1: 87.5000 (90.7200)  Acc@5: 100.0000 (99.0400)  time: 0.3227  data: 0.0005  max mem: 2362
Train: Epoch[3/5] Total time: 0:01:43 (0.3321 s / it)
Averaged stats: Lr: 0.001875  Loss: -1.2860  Acc@1: 87.5000 (90.7200)  Acc@5: 100.0000 (99.0400)
Train: Epoch[4/5]  [  0/313]  eta: 0:03:56  Lr: 0.001875  Loss: -0.6112  Acc@1: 87.5000 (87.5000)  Acc@5: 93.7500 (93.7500)  time: 0.7563  data: 0.4227  max mem: 2362
Train: Epoch[4/5]  [ 10/313]  eta: 0:01:52  Lr: 0.001875  Loss: -0.8821  Acc@1: 87.5000 (90.3409)  Acc@5: 100.0000 (99.4318)  time: 0.3701  data: 0.0388  max mem: 2362
Train: Epoch[4/5]  [ 20/313]  eta: 0:01:43  Lr: 0.001875  Loss: -0.7231  Acc@1: 93.7500 (91.0714)  Acc@5: 100.0000 (99.7024)  time: 0.3314  data: 0.0004  max mem: 2362
Train: Epoch[4/5]  [ 30/313]  eta: 0:01:37  Lr: 0.001875  Loss: -1.2297  Acc@1: 93.7500 (90.7258)  Acc@5: 100.0000 (99.7984)  time: 0.3308  data: 0.0004  max mem: 2362
Train: Epoch[4/5]  [ 40/313]  eta: 0:01:33  Lr: 0.001875  Loss: -0.7838  Acc@1: 93.7500 (91.1585)  Acc@5: 100.0000 (99.8476)  time: 0.3306  data: 0.0006  max mem: 2362
Train: Epoch[4/5]  [ 50/313]  eta: 0:01:29  Lr: 0.001875  Loss: -0.2466  Acc@1: 93.7500 (90.6863)  Acc@5: 100.0000 (99.7549)  time: 0.3311  data: 0.0006  max mem: 2362
Train: Epoch[4/5]  [ 60/313]  eta: 0:01:25  Lr: 0.001875  Loss: -0.9396  Acc@1: 87.5000 (90.6762)  Acc@5: 100.0000 (99.6926)  time: 0.3309  data: 0.0005  max mem: 2362
Train: Epoch[4/5]  [ 70/313]  eta: 0:01:21  Lr: 0.001875  Loss: -0.9411  Acc@1: 93.7500 (91.1972)  Acc@5: 100.0000 (99.6479)  time: 0.3313  data: 0.0008  max mem: 2362
Train: Epoch[4/5]  [ 80/313]  eta: 0:01:18  Lr: 0.001875  Loss: -1.0018  Acc@1: 93.7500 (91.3580)  Acc@5: 100.0000 (99.6914)  time: 0.3315  data: 0.0006  max mem: 2362
Train: Epoch[4/5]  [ 90/313]  eta: 0:01:14  Lr: 0.001875  Loss: -1.0040  Acc@1: 93.7500 (91.4148)  Acc@5: 100.0000 (99.6566)  time: 0.3309  data: 0.0003  max mem: 2362
Train: Epoch[4/5]  [100/313]  eta: 0:01:11  Lr: 0.001875  Loss: -0.8276  Acc@1: 93.7500 (91.6460)  Acc@5: 100.0000 (99.6287)  time: 0.3310  data: 0.0003  max mem: 2362
Train: Epoch[4/5]  [110/313]  eta: 0:01:07  Lr: 0.001875  Loss: -0.9357  Acc@1: 93.7500 (91.5541)  Acc@5: 100.0000 (99.5495)  time: 0.3310  data: 0.0004  max mem: 2362
Train: Epoch[4/5]  [120/313]  eta: 0:01:04  Lr: 0.001875  Loss: -0.8158  Acc@1: 93.7500 (91.2707)  Acc@5: 100.0000 (99.5351)  time: 0.3312  data: 0.0005  max mem: 2362
Train: Epoch[4/5]  [130/313]  eta: 0:01:01  Lr: 0.001875  Loss: -0.8879  Acc@1: 93.7500 (91.3645)  Acc@5: 100.0000 (99.5229)  time: 0.3310  data: 0.0005  max mem: 2362
Train: Epoch[4/5]  [140/313]  eta: 0:00:57  Lr: 0.001875  Loss: -0.7908  Acc@1: 93.7500 (91.3121)  Acc@5: 100.0000 (99.5124)  time: 0.3308  data: 0.0005  max mem: 2362
Train: Epoch[4/5]  [150/313]  eta: 0:00:54  Lr: 0.001875  Loss: -1.0481  Acc@1: 93.7500 (91.5149)  Acc@5: 100.0000 (99.5033)  time: 0.3311  data: 0.0004  max mem: 2362
Train: Epoch[4/5]  [160/313]  eta: 0:00:51  Lr: 0.001875  Loss: -0.8379  Acc@1: 93.7500 (91.4596)  Acc@5: 100.0000 (99.5342)  time: 0.3315  data: 0.0004  max mem: 2362
Train: Epoch[4/5]  [170/313]  eta: 0:00:47  Lr: 0.001875  Loss: -0.9693  Acc@1: 93.7500 (91.5936)  Acc@5: 100.0000 (99.5249)  time: 0.3318  data: 0.0005  max mem: 2362
Train: Epoch[4/5]  [180/313]  eta: 0:00:44  Lr: 0.001875  Loss: -0.6961  Acc@1: 93.7500 (91.7127)  Acc@5: 100.0000 (99.5511)  time: 0.3314  data: 0.0004  max mem: 2362
Train: Epoch[4/5]  [190/313]  eta: 0:00:40  Lr: 0.001875  Loss: -0.8215  Acc@1: 93.7500 (91.8848)  Acc@5: 100.0000 (99.4764)  time: 0.3306  data: 0.0006  max mem: 2362
Train: Epoch[4/5]  [200/313]  eta: 0:00:37  Lr: 0.001875  Loss: -0.8840  Acc@1: 93.7500 (91.6667)  Acc@5: 100.0000 (99.3781)  time: 0.3303  data: 0.0006  max mem: 2362
Train: Epoch[4/5]  [210/313]  eta: 0:00:34  Lr: 0.001875  Loss: -0.8106  Acc@1: 87.5000 (91.6173)  Acc@5: 100.0000 (99.3483)  time: 0.3306  data: 0.0004  max mem: 2362
Train: Epoch[4/5]  [220/313]  eta: 0:00:30  Lr: 0.001875  Loss: -1.0713  Acc@1: 87.5000 (91.5441)  Acc@5: 100.0000 (99.3213)  time: 0.3311  data: 0.0004  max mem: 2362
Train: Epoch[4/5]  [230/313]  eta: 0:00:27  Lr: 0.001875  Loss: -0.6747  Acc@1: 87.5000 (91.4502)  Acc@5: 100.0000 (99.2695)  time: 0.3307  data: 0.0004  max mem: 2362
Train: Epoch[4/5]  [240/313]  eta: 0:00:24  Lr: 0.001875  Loss: -0.7637  Acc@1: 93.7500 (91.4938)  Acc@5: 100.0000 (99.2479)  time: 0.3325  data: 0.0017  max mem: 2362
Train: Epoch[4/5]  [250/313]  eta: 0:00:20  Lr: 0.001875  Loss: -1.0266  Acc@1: 93.7500 (91.5339)  Acc@5: 100.0000 (99.2530)  time: 0.3328  data: 0.0017  max mem: 2362
Train: Epoch[4/5]  [260/313]  eta: 0:00:17  Lr: 0.001875  Loss: -0.9290  Acc@1: 93.7500 (91.3793)  Acc@5: 100.0000 (99.2337)  time: 0.3311  data: 0.0004  max mem: 2362
Train: Epoch[4/5]  [270/313]  eta: 0:00:14  Lr: 0.001875  Loss: -0.9844  Acc@1: 87.5000 (91.2823)  Acc@5: 100.0000 (99.2620)  time: 0.3313  data: 0.0004  max mem: 2362
Train: Epoch[4/5]  [280/313]  eta: 0:00:10  Lr: 0.001875  Loss: -1.0679  Acc@1: 93.7500 (91.2367)  Acc@5: 100.0000 (99.2438)  time: 0.3311  data: 0.0004  max mem: 2362
Train: Epoch[4/5]  [290/313]  eta: 0:00:07  Lr: 0.001875  Loss: -0.9968  Acc@1: 93.7500 (91.1512)  Acc@5: 100.0000 (99.2483)  time: 0.3308  data: 0.0005  max mem: 2362
Train: Epoch[4/5]  [300/313]  eta: 0:00:04  Lr: 0.001875  Loss: -0.9110  Acc@1: 93.7500 (91.2168)  Acc@5: 100.0000 (99.2110)  time: 0.3305  data: 0.0004  max mem: 2362
Train: Epoch[4/5]  [310/313]  eta: 0:00:00  Lr: 0.001875  Loss: -1.0495  Acc@1: 93.7500 (91.1777)  Acc@5: 100.0000 (99.2162)  time: 0.3303  data: 0.0004  max mem: 2362
Train: Epoch[4/5]  [312/313]  eta: 0:00:00  Lr: 0.001875  Loss: -0.9434  Acc@1: 93.7500 (91.2000)  Acc@5: 100.0000 (99.2200)  time: 0.3222  data: 0.0004  max mem: 2362
Train: Epoch[4/5] Total time: 0:01:44 (0.3324 s / it)
Averaged stats: Lr: 0.001875  Loss: -0.9434  Acc@1: 93.7500 (91.2000)  Acc@5: 100.0000 (99.2200)
Train: Epoch[5/5]  [  0/313]  eta: 0:04:08  Lr: 0.001875  Loss: -1.0055  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)  time: 0.7943  data: 0.4579  max mem: 2362
Train: Epoch[5/5]  [ 10/313]  eta: 0:01:53  Lr: 0.001875  Loss: -0.7356  Acc@1: 93.7500 (92.0455)  Acc@5: 100.0000 (99.4318)  time: 0.3734  data: 0.0424  max mem: 2362
Train: Epoch[5/5]  [ 20/313]  eta: 0:01:43  Lr: 0.001875  Loss: -0.8147  Acc@1: 87.5000 (90.7738)  Acc@5: 100.0000 (99.7024)  time: 0.3310  data: 0.0008  max mem: 2362
Train: Epoch[5/5]  [ 30/313]  eta: 0:01:37  Lr: 0.001875  Loss: -0.6757  Acc@1: 87.5000 (90.9274)  Acc@5: 100.0000 (99.5968)  time: 0.3308  data: 0.0005  max mem: 2362
Train: Epoch[5/5]  [ 40/313]  eta: 0:01:33  Lr: 0.001875  Loss: -0.8855  Acc@1: 93.7500 (91.0061)  Acc@5: 100.0000 (99.5427)  time: 0.3309  data: 0.0004  max mem: 2362
Train: Epoch[5/5]  [ 50/313]  eta: 0:01:29  Lr: 0.001875  Loss: -0.9040  Acc@1: 93.7500 (91.4216)  Acc@5: 100.0000 (99.6324)  time: 0.3302  data: 0.0004  max mem: 2362
Train: Epoch[5/5]  [ 60/313]  eta: 0:01:25  Lr: 0.001875  Loss: -0.7397  Acc@1: 87.5000 (91.4959)  Acc@5: 100.0000 (99.5902)  time: 0.3298  data: 0.0004  max mem: 2362
Train: Epoch[5/5]  [ 70/313]  eta: 0:01:21  Lr: 0.001875  Loss: -0.5537  Acc@1: 87.5000 (91.4613)  Acc@5: 100.0000 (99.6479)  time: 0.3306  data: 0.0004  max mem: 2362
Train: Epoch[5/5]  [ 80/313]  eta: 0:01:18  Lr: 0.001875  Loss: -0.9775  Acc@1: 93.7500 (91.5895)  Acc@5: 100.0000 (99.6914)  time: 0.3307  data: 0.0004  max mem: 2362
Train: Epoch[5/5]  [ 90/313]  eta: 0:01:14  Lr: 0.001875  Loss: -1.0639  Acc@1: 93.7500 (91.6209)  Acc@5: 100.0000 (99.6566)  time: 0.3308  data: 0.0010  max mem: 2362
Train: Epoch[5/5]  [100/313]  eta: 0:01:11  Lr: 0.001875  Loss: -1.0500  Acc@1: 93.7500 (91.7698)  Acc@5: 100.0000 (99.6287)  time: 0.3308  data: 0.0010  max mem: 2362
Train: Epoch[5/5]  [110/313]  eta: 0:01:07  Lr: 0.001875  Loss: -1.0168  Acc@1: 93.7500 (91.9482)  Acc@5: 100.0000 (99.4932)  time: 0.3307  data: 0.0004  max mem: 2362
Train: Epoch[5/5]  [120/313]  eta: 0:01:04  Lr: 0.001875  Loss: -1.0449  Acc@1: 93.7500 (91.9938)  Acc@5: 100.0000 (99.4835)  time: 0.3310  data: 0.0004  max mem: 2362
Train: Epoch[5/5]  [130/313]  eta: 0:01:01  Lr: 0.001875  Loss: -0.7394  Acc@1: 93.7500 (92.0324)  Acc@5: 100.0000 (99.4275)  time: 0.3310  data: 0.0004  max mem: 2362
Train: Epoch[5/5]  [140/313]  eta: 0:00:57  Lr: 0.001875  Loss: -0.3358  Acc@1: 93.7500 (91.9770)  Acc@5: 100.0000 (99.2908)  time: 0.3309  data: 0.0004  max mem: 2362
Train: Epoch[5/5]  [150/313]  eta: 0:00:54  Lr: 0.001875  Loss: -1.1689  Acc@1: 93.7500 (92.0944)  Acc@5: 100.0000 (99.2550)  time: 0.3307  data: 0.0004  max mem: 2362
Train: Epoch[5/5]  [160/313]  eta: 0:00:51  Lr: 0.001875  Loss: -1.1210  Acc@1: 93.7500 (91.8090)  Acc@5: 100.0000 (99.2624)  time: 0.3311  data: 0.0004  max mem: 2362
Train: Epoch[5/5]  [170/313]  eta: 0:00:47  Lr: 0.001875  Loss: -0.9798  Acc@1: 87.5000 (91.7763)  Acc@5: 100.0000 (99.2690)  time: 0.3313  data: 0.0004  max mem: 2362
Train: Epoch[5/5]  [180/313]  eta: 0:00:44  Lr: 0.001875  Loss: -1.0412  Acc@1: 93.7500 (91.7818)  Acc@5: 100.0000 (99.2749)  time: 0.3312  data: 0.0004  max mem: 2362
Train: Epoch[5/5]  [190/313]  eta: 0:00:40  Lr: 0.001875  Loss: -0.9674  Acc@1: 93.7500 (91.7866)  Acc@5: 100.0000 (99.3128)  time: 0.3309  data: 0.0004  max mem: 2362
Train: Epoch[5/5]  [200/313]  eta: 0:00:37  Lr: 0.001875  Loss: -0.5428  Acc@1: 93.7500 (91.7910)  Acc@5: 100.0000 (99.3159)  time: 0.3309  data: 0.0005  max mem: 2362
Train: Epoch[5/5]  [210/313]  eta: 0:00:34  Lr: 0.001875  Loss: -0.8250  Acc@1: 93.7500 (91.7358)  Acc@5: 100.0000 (99.2595)  time: 0.3305  data: 0.0004  max mem: 2362
Train: Epoch[5/5]  [220/313]  eta: 0:00:30  Lr: 0.001875  Loss: -0.8919  Acc@1: 87.5000 (91.6290)  Acc@5: 100.0000 (99.2647)  time: 0.3295  data: 0.0004  max mem: 2362
Train: Epoch[5/5]  [230/313]  eta: 0:00:27  Lr: 0.001875  Loss: -0.7134  Acc@1: 87.5000 (91.4773)  Acc@5: 100.0000 (99.2965)  time: 0.3303  data: 0.0005  max mem: 2362
Train: Epoch[5/5]  [240/313]  eta: 0:00:24  Lr: 0.001875  Loss: -0.9679  Acc@1: 87.5000 (91.5197)  Acc@5: 100.0000 (99.2479)  time: 0.3314  data: 0.0006  max mem: 2362
Train: Epoch[5/5]  [250/313]  eta: 0:00:20  Lr: 0.001875  Loss: -1.1508  Acc@1: 93.7500 (91.6086)  Acc@5: 100.0000 (99.2779)  time: 0.3318  data: 0.0004  max mem: 2362
Train: Epoch[5/5]  [260/313]  eta: 0:00:17  Lr: 0.001875  Loss: -1.1277  Acc@1: 93.7500 (91.5948)  Acc@5: 100.0000 (99.2816)  time: 0.3316  data: 0.0004  max mem: 2362
Train: Epoch[5/5]  [270/313]  eta: 0:00:14  Lr: 0.001875  Loss: -1.0395  Acc@1: 93.7500 (91.6282)  Acc@5: 100.0000 (99.2620)  time: 0.3309  data: 0.0004  max mem: 2362
Train: Epoch[5/5]  [280/313]  eta: 0:00:10  Lr: 0.001875  Loss: -0.7532  Acc@1: 87.5000 (91.5258)  Acc@5: 100.0000 (99.1993)  time: 0.3310  data: 0.0004  max mem: 2362
Train: Epoch[5/5]  [290/313]  eta: 0:00:07  Lr: 0.001875  Loss: -0.6624  Acc@1: 87.5000 (91.5163)  Acc@5: 100.0000 (99.2053)  time: 0.3305  data: 0.0003  max mem: 2362
Train: Epoch[5/5]  [300/313]  eta: 0:00:04  Lr: 0.001875  Loss: -0.9255  Acc@1: 93.7500 (91.5282)  Acc@5: 100.0000 (99.1902)  time: 0.3295  data: 0.0003  max mem: 2362
Train: Epoch[5/5]  [310/313]  eta: 0:00:00  Lr: 0.001875  Loss: -1.0322  Acc@1: 93.7500 (91.4992)  Acc@5: 100.0000 (99.2162)  time: 0.3296  data: 0.0004  max mem: 2362
Train: Epoch[5/5]  [312/313]  eta: 0:00:00  Lr: 0.001875  Loss: -1.0156  Acc@1: 93.7500 (91.5200)  Acc@5: 100.0000 (99.2000)  time: 0.3217  data: 0.0004  max mem: 2362
Train: Epoch[5/5] Total time: 0:01:43 (0.3322 s / it)
Averaged stats: Lr: 0.001875  Loss: -1.0156  Acc@1: 93.7500 (91.5200)  Acc@5: 100.0000 (99.2000)
Test: [Task 1]  [ 0/63]  eta: 0:00:39  Loss: 0.8578 (0.8578)  Acc@1: 75.0000 (75.0000)  Acc@5: 93.7500 (93.7500)  time: 0.6342  data: 0.4267  max mem: 2362
Test: [Task 1]  [10/63]  eta: 0:00:12  Loss: 0.6444 (0.6345)  Acc@1: 81.2500 (82.9545)  Acc@5: 100.0000 (99.4318)  time: 0.2448  data: 0.0391  max mem: 2362
Test: [Task 1]  [20/63]  eta: 0:00:09  Loss: 0.6444 (0.7120)  Acc@1: 81.2500 (81.5476)  Acc@5: 100.0000 (97.9167)  time: 0.2055  data: 0.0003  max mem: 2362
Test: [Task 1]  [30/63]  eta: 0:00:07  Loss: 0.6404 (0.6710)  Acc@1: 81.2500 (83.2661)  Acc@5: 100.0000 (98.3871)  time: 0.2055  data: 0.0003  max mem: 2362
Test: [Task 1]  [40/63]  eta: 0:00:04  Loss: 0.4940 (0.6451)  Acc@1: 87.5000 (84.2988)  Acc@5: 100.0000 (98.4756)  time: 0.2057  data: 0.0004  max mem: 2362
Test: [Task 1]  [50/63]  eta: 0:00:02  Loss: 0.5068 (0.6277)  Acc@1: 87.5000 (84.9265)  Acc@5: 100.0000 (98.4069)  time: 0.2058  data: 0.0006  max mem: 2362
Test: [Task 1]  [60/63]  eta: 0:00:00  Loss: 0.5068 (0.6154)  Acc@1: 87.5000 (85.5533)  Acc@5: 100.0000 (98.4631)  time: 0.2059  data: 0.0006  max mem: 2362
Test: [Task 1]  [62/63]  eta: 0:00:00  Loss: 0.4878 (0.6115)  Acc@1: 87.5000 (85.8000)  Acc@5: 100.0000 (98.5000)  time: 0.2011  data: 0.0005  max mem: 2362
Test: [Task 1] Total time: 0:00:13 (0.2125 s / it)
* Acc@1 85.800 Acc@5 98.500 loss 0.611
Test: [Task 2]  [ 0/63]  eta: 0:00:37  Loss: 0.8834 (0.8834)  Acc@1: 81.2500 (81.2500)  Acc@5: 93.7500 (93.7500)  time: 0.5919  data: 0.3826  max mem: 2362
Test: [Task 2]  [10/63]  eta: 0:00:12  Loss: 0.7847 (0.7766)  Acc@1: 81.2500 (82.9545)  Acc@5: 100.0000 (96.5909)  time: 0.2415  data: 0.0352  max mem: 2362
Test: [Task 2]  [20/63]  eta: 0:00:09  Loss: 0.7560 (0.8489)  Acc@1: 81.2500 (80.6548)  Acc@5: 100.0000 (96.7262)  time: 0.2062  data: 0.0004  max mem: 2362
Test: [Task 2]  [30/63]  eta: 0:00:07  Loss: 0.8169 (0.8371)  Acc@1: 75.0000 (81.2500)  Acc@5: 100.0000 (96.5726)  time: 0.2058  data: 0.0004  max mem: 2362
Test: [Task 2]  [40/63]  eta: 0:00:04  Loss: 0.7726 (0.8199)  Acc@1: 81.2500 (82.0122)  Acc@5: 93.7500 (96.6463)  time: 0.2059  data: 0.0004  max mem: 2362
Test: [Task 2]  [50/63]  eta: 0:00:02  Loss: 0.7029 (0.8101)  Acc@1: 81.2500 (82.2304)  Acc@5: 93.7500 (96.4461)  time: 0.2060  data: 0.0003  max mem: 2362
Test: [Task 2]  [60/63]  eta: 0:00:00  Loss: 0.6609 (0.7844)  Acc@1: 87.5000 (82.8893)  Acc@5: 100.0000 (96.9262)  time: 0.2054  data: 0.0003  max mem: 2362
Test: [Task 2]  [62/63]  eta: 0:00:00  Loss: 0.6609 (0.7757)  Acc@1: 87.5000 (83.0000)  Acc@5: 100.0000 (97.0000)  time: 0.2007  data: 0.0003  max mem: 2362
Test: [Task 2] Total time: 0:00:13 (0.2123 s / it)
* Acc@1 83.000 Acc@5 97.000 loss 0.776
Test: [Task 3]  [ 0/63]  eta: 0:00:37  Loss: 0.4068 (0.4068)  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (100.0000)  time: 0.5994  data: 0.3901  max mem: 2362
Test: [Task 3]  [10/63]  eta: 0:00:12  Loss: 0.6859 (0.6659)  Acc@1: 87.5000 (80.6818)  Acc@5: 100.0000 (97.1591)  time: 0.2420  data: 0.0358  max mem: 2362
Test: [Task 3]  [20/63]  eta: 0:00:09  Loss: 0.6859 (0.6509)  Acc@1: 81.2500 (81.5476)  Acc@5: 100.0000 (97.3214)  time: 0.2069  data: 0.0009  max mem: 2362
Test: [Task 3]  [30/63]  eta: 0:00:07  Loss: 0.6076 (0.6434)  Acc@1: 81.2500 (82.2581)  Acc@5: 100.0000 (97.3790)  time: 0.2066  data: 0.0009  max mem: 2362
Test: [Task 3]  [40/63]  eta: 0:00:04  Loss: 0.5248 (0.6324)  Acc@1: 87.5000 (83.3841)  Acc@5: 100.0000 (97.4085)  time: 0.2056  data: 0.0003  max mem: 2362
Test: [Task 3]  [50/63]  eta: 0:00:02  Loss: 0.6092 (0.6426)  Acc@1: 87.5000 (83.7010)  Acc@5: 100.0000 (97.0588)  time: 0.2055  data: 0.0003  max mem: 2362
Test: [Task 3]  [60/63]  eta: 0:00:00  Loss: 0.7292 (0.6450)  Acc@1: 87.5000 (83.5041)  Acc@5: 100.0000 (97.3361)  time: 0.2055  data: 0.0003  max mem: 2362
Test: [Task 3]  [62/63]  eta: 0:00:00  Loss: 0.7292 (0.6475)  Acc@1: 81.2500 (83.4000)  Acc@5: 100.0000 (97.3000)  time: 0.2006  data: 0.0003  max mem: 2362
Test: [Task 3] Total time: 0:00:13 (0.2118 s / it)
* Acc@1 83.400 Acc@5 97.300 loss 0.647
Test: [Task 4]  [ 0/63]  eta: 0:00:36  Loss: 0.8606 (0.8606)  Acc@1: 81.2500 (81.2500)  Acc@5: 93.7500 (93.7500)  time: 0.5717  data: 0.3656  max mem: 2362
Test: [Task 4]  [10/63]  eta: 0:00:12  Loss: 0.7595 (0.7840)  Acc@1: 81.2500 (81.8182)  Acc@5: 100.0000 (97.7273)  time: 0.2392  data: 0.0335  max mem: 2362
Test: [Task 4]  [20/63]  eta: 0:00:09  Loss: 0.7050 (0.7405)  Acc@1: 81.2500 (82.1429)  Acc@5: 100.0000 (97.0238)  time: 0.2061  data: 0.0003  max mem: 2362
Test: [Task 4]  [30/63]  eta: 0:00:07  Loss: 0.5510 (0.7040)  Acc@1: 87.5000 (83.2661)  Acc@5: 100.0000 (97.3790)  time: 0.2059  data: 0.0004  max mem: 2362
Test: [Task 4]  [40/63]  eta: 0:00:04  Loss: 0.3942 (0.6335)  Acc@1: 87.5000 (85.2134)  Acc@5: 100.0000 (97.7134)  time: 0.2058  data: 0.0004  max mem: 2362
Test: [Task 4]  [50/63]  eta: 0:00:02  Loss: 0.3942 (0.6374)  Acc@1: 87.5000 (85.0490)  Acc@5: 100.0000 (97.3039)  time: 0.2059  data: 0.0003  max mem: 2362
Test: [Task 4]  [60/63]  eta: 0:00:00  Loss: 0.6606 (0.6549)  Acc@1: 81.2500 (84.6311)  Acc@5: 93.7500 (96.7213)  time: 0.2056  data: 0.0003  max mem: 2362
Test: [Task 4]  [62/63]  eta: 0:00:00  Loss: 0.6639 (0.6555)  Acc@1: 87.5000 (84.7000)  Acc@5: 93.7500 (96.8000)  time: 0.2008  data: 0.0003  max mem: 2362
Test: [Task 4] Total time: 0:00:13 (0.2122 s / it)
* Acc@1 84.700 Acc@5 96.800 loss 0.656
Test: [Task 5]  [ 0/63]  eta: 0:00:36  Loss: 0.3332 (0.3332)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)  time: 0.5811  data: 0.3738  max mem: 2362
Test: [Task 5]  [10/63]  eta: 0:00:12  Loss: 0.5111 (0.6685)  Acc@1: 93.7500 (88.6364)  Acc@5: 100.0000 (95.4545)  time: 0.2401  data: 0.0343  max mem: 2362
Test: [Task 5]  [20/63]  eta: 0:00:09  Loss: 0.5111 (0.6203)  Acc@1: 87.5000 (88.0952)  Acc@5: 100.0000 (96.4286)  time: 0.2058  data: 0.0004  max mem: 2362
Test: [Task 5]  [30/63]  eta: 0:00:07  Loss: 0.5363 (0.6186)  Acc@1: 87.5000 (86.8952)  Acc@5: 100.0000 (96.9758)  time: 0.2056  data: 0.0004  max mem: 2362
Test: [Task 5]  [40/63]  eta: 0:00:04  Loss: 0.5363 (0.6108)  Acc@1: 87.5000 (86.4329)  Acc@5: 100.0000 (96.9512)  time: 0.2053  data: 0.0003  max mem: 2362
Test: [Task 5]  [50/63]  eta: 0:00:02  Loss: 0.5701 (0.6105)  Acc@1: 87.5000 (87.3775)  Acc@5: 100.0000 (97.1814)  time: 0.2054  data: 0.0003  max mem: 2362
Test: [Task 5]  [60/63]  eta: 0:00:00  Loss: 0.6528 (0.6299)  Acc@1: 87.5000 (86.8852)  Acc@5: 100.0000 (96.8238)  time: 0.2055  data: 0.0003  max mem: 2362
Test: [Task 5]  [62/63]  eta: 0:00:00  Loss: 0.6920 (0.6503)  Acc@1: 87.5000 (86.3000)  Acc@5: 100.0000 (96.6000)  time: 0.2007  data: 0.0003  max mem: 2362
Test: [Task 5] Total time: 0:00:13 (0.2115 s / it)
* Acc@1 86.300 Acc@5 96.600 loss 0.650
Test: [Task 6]  [ 0/63]  eta: 0:00:39  Loss: 0.5775 (0.5775)  Acc@1: 81.2500 (81.2500)  Acc@5: 93.7500 (93.7500)  time: 0.6316  data: 0.4242  max mem: 2362
Test: [Task 6]  [10/63]  eta: 0:00:12  Loss: 0.7264 (0.7150)  Acc@1: 81.2500 (81.2500)  Acc@5: 93.7500 (94.8864)  time: 0.2442  data: 0.0389  max mem: 2362
Test: [Task 6]  [20/63]  eta: 0:00:09  Loss: 0.7283 (0.7546)  Acc@1: 81.2500 (80.3571)  Acc@5: 100.0000 (96.1310)  time: 0.2055  data: 0.0004  max mem: 2362
Test: [Task 6]  [30/63]  eta: 0:00:07  Loss: 0.6453 (0.7408)  Acc@1: 81.2500 (80.0403)  Acc@5: 100.0000 (96.7742)  time: 0.2056  data: 0.0004  max mem: 2362
Test: [Task 6]  [40/63]  eta: 0:00:04  Loss: 0.8149 (0.7872)  Acc@1: 81.2500 (78.8110)  Acc@5: 93.7500 (95.7317)  time: 0.2056  data: 0.0003  max mem: 2362
Test: [Task 6]  [50/63]  eta: 0:00:02  Loss: 0.7544 (0.7622)  Acc@1: 81.2500 (79.0441)  Acc@5: 93.7500 (96.2010)  time: 0.2058  data: 0.0004  max mem: 2362
Test: [Task 6]  [60/63]  eta: 0:00:00  Loss: 0.7355 (0.7776)  Acc@1: 75.0000 (78.7910)  Acc@5: 100.0000 (96.2090)  time: 0.2061  data: 0.0004  max mem: 2362
Test: [Task 6]  [62/63]  eta: 0:00:00  Loss: 0.7355 (0.7717)  Acc@1: 75.0000 (79.2000)  Acc@5: 100.0000 (96.3000)  time: 0.2012  data: 0.0004  max mem: 2362
Test: [Task 6] Total time: 0:00:13 (0.2138 s / it)
* Acc@1 79.200 Acc@5 96.300 loss 0.772
Test: [Task 7]  [ 0/63]  eta: 0:00:40  Loss: 0.7112 (0.7112)  Acc@1: 81.2500 (81.2500)  Acc@5: 100.0000 (100.0000)  time: 0.6400  data: 0.4334  max mem: 2362
Test: [Task 7]  [10/63]  eta: 0:00:13  Loss: 0.6753 (0.6838)  Acc@1: 87.5000 (84.6591)  Acc@5: 100.0000 (97.7273)  time: 0.2453  data: 0.0397  max mem: 2362
Test: [Task 7]  [20/63]  eta: 0:00:09  Loss: 0.6778 (0.7569)  Acc@1: 81.2500 (83.3333)  Acc@5: 93.7500 (95.8333)  time: 0.2061  data: 0.0003  max mem: 2362
Test: [Task 7]  [30/63]  eta: 0:00:07  Loss: 0.7839 (0.7495)  Acc@1: 81.2500 (83.2661)  Acc@5: 93.7500 (95.7661)  time: 0.2061  data: 0.0004  max mem: 2362
Test: [Task 7]  [40/63]  eta: 0:00:04  Loss: 0.6659 (0.7208)  Acc@1: 87.5000 (83.9939)  Acc@5: 100.0000 (96.0366)  time: 0.2058  data: 0.0004  max mem: 2362
Test: [Task 7]  [50/63]  eta: 0:00:02  Loss: 0.6654 (0.7437)  Acc@1: 87.5000 (83.5784)  Acc@5: 93.7500 (95.5882)  time: 0.2057  data: 0.0003  max mem: 2362
Test: [Task 7]  [60/63]  eta: 0:00:00  Loss: 0.6104 (0.7233)  Acc@1: 87.5000 (84.1189)  Acc@5: 93.7500 (95.7992)  time: 0.2058  data: 0.0003  max mem: 2362
Test: [Task 7]  [62/63]  eta: 0:00:00  Loss: 0.6204 (0.7222)  Acc@1: 87.5000 (84.1000)  Acc@5: 93.7500 (95.8000)  time: 0.2008  data: 0.0003  max mem: 2362
Test: [Task 7] Total time: 0:00:13 (0.2125 s / it)
* Acc@1 84.100 Acc@5 95.800 loss 0.722
Test: [Task 8]  [ 0/63]  eta: 0:00:35  Loss: 0.6286 (0.6286)  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (100.0000)  time: 0.5610  data: 0.3541  max mem: 2362
Test: [Task 8]  [10/63]  eta: 0:00:12  Loss: 0.7739 (0.7729)  Acc@1: 81.2500 (81.8182)  Acc@5: 93.7500 (96.0227)  time: 0.2382  data: 0.0325  max mem: 2362
Test: [Task 8]  [20/63]  eta: 0:00:09  Loss: 0.7423 (0.7934)  Acc@1: 81.2500 (82.4405)  Acc@5: 93.7500 (96.1310)  time: 0.2056  data: 0.0003  max mem: 2362
Test: [Task 8]  [30/63]  eta: 0:00:07  Loss: 0.7073 (0.7594)  Acc@1: 81.2500 (82.6613)  Acc@5: 93.7500 (96.3710)  time: 0.2056  data: 0.0003  max mem: 2362
Test: [Task 8]  [40/63]  eta: 0:00:04  Loss: 0.6682 (0.7458)  Acc@1: 81.2500 (82.3171)  Acc@5: 93.7500 (96.3415)  time: 0.2058  data: 0.0004  max mem: 2362
Test: [Task 8]  [50/63]  eta: 0:00:02  Loss: 0.7128 (0.7408)  Acc@1: 81.2500 (82.1078)  Acc@5: 93.7500 (96.0784)  time: 0.2055  data: 0.0003  max mem: 2362
Test: [Task 8]  [60/63]  eta: 0:00:00  Loss: 0.7397 (0.7563)  Acc@1: 81.2500 (82.0697)  Acc@5: 93.7500 (95.3893)  time: 0.2052  data: 0.0003  max mem: 2362
Test: [Task 8]  [62/63]  eta: 0:00:00  Loss: 0.7373 (0.7447)  Acc@1: 81.2500 (82.3000)  Acc@5: 93.7500 (95.5000)  time: 0.2004  data: 0.0003  max mem: 2362
Test: [Task 8] Total time: 0:00:13 (0.2115 s / it)
* Acc@1 82.300 Acc@5 95.500 loss 0.745
Test: [Task 9]  [ 0/63]  eta: 0:00:35  Loss: 0.2894 (0.2894)  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (100.0000)  time: 0.5627  data: 0.3553  max mem: 2362
Test: [Task 9]  [10/63]  eta: 0:00:12  Loss: 0.4920 (0.6010)  Acc@1: 81.2500 (84.0909)  Acc@5: 100.0000 (96.5909)  time: 0.2380  data: 0.0326  max mem: 2362
Test: [Task 9]  [20/63]  eta: 0:00:09  Loss: 0.4920 (0.5640)  Acc@1: 81.2500 (85.1190)  Acc@5: 100.0000 (96.7262)  time: 0.2057  data: 0.0004  max mem: 2362
Test: [Task 9]  [30/63]  eta: 0:00:07  Loss: 0.4478 (0.5426)  Acc@1: 87.5000 (86.2903)  Acc@5: 100.0000 (96.9758)  time: 0.2061  data: 0.0004  max mem: 2362
Test: [Task 9]  [40/63]  eta: 0:00:04  Loss: 0.4471 (0.5554)  Acc@1: 87.5000 (85.3659)  Acc@5: 100.0000 (97.1037)  time: 0.2060  data: 0.0004  max mem: 2362
Test: [Task 9]  [50/63]  eta: 0:00:02  Loss: 0.5332 (0.5600)  Acc@1: 87.5000 (86.0294)  Acc@5: 100.0000 (97.1814)  time: 0.2067  data: 0.0004  max mem: 2362
Test: [Task 9]  [60/63]  eta: 0:00:00  Loss: 0.4928 (0.5392)  Acc@1: 87.5000 (86.6803)  Acc@5: 100.0000 (97.3361)  time: 0.2065  data: 0.0004  max mem: 2362
Test: [Task 9]  [62/63]  eta: 0:00:00  Loss: 0.4438 (0.5303)  Acc@1: 87.5000 (86.9000)  Acc@5: 100.0000 (97.3000)  time: 0.2016  data: 0.0003  max mem: 2362
Test: [Task 9] Total time: 0:00:13 (0.2126 s / it)
* Acc@1 86.900 Acc@5 97.300 loss 0.530
{0: {0: 549, 1: 552, 2: 548, 3: 547, 4: 555, 5: 35, 6: 35, 7: 31, 8: 35, 9: 32, 10: 51, 11: 51, 12: 51, 13: 51, 14: 51, 15: 156, 16: 152, 17: 159, 18: 153, 19: 158, 20: 26, 21: 26, 22: 30, 23: 26, 24: 28, 25: 20, 26: 20, 27: 21, 28: 21, 29: 21, 30: 9, 31: 9, 32: 9, 33: 9, 34: 9, 35: 96, 36: 96, 37: 95, 38: 96, 39: 96, 40: 56, 41: 53, 42: 61, 43: 55, 44: 59, 45: 0, 46: 0, 47: 1, 48: 0, 49: 0}, 1: {0: 71, 1: 75, 2: 77, 3: 78, 4: 77, 5: 433, 6: 437, 7: 431, 8: 435, 9: 432, 10: 44, 11: 44, 12: 45, 13: 44, 14: 44, 15: 168, 16: 167, 17: 169, 18: 168, 19: 169, 20: 31, 21: 32, 22: 32, 23: 31, 24: 31, 25: 51, 26: 51, 27: 50, 28: 51, 29: 50, 30: 27, 31: 27, 32: 27, 33: 27, 34: 27, 35: 90, 36: 90, 37: 91, 38: 90, 39: 90, 40: 79, 41: 79, 42: 80, 43: 79, 44: 79, 45: 0, 46: 0, 47: 0, 48: 0, 49: 0}, 2: {0: 28, 1: 26, 2: 29, 3: 28, 4: 28, 5: 10, 6: 9, 7: 10, 8: 10, 9: 10, 10: 526, 11: 525, 12: 526, 13: 525, 14: 527, 15: 95, 16: 93, 17: 96, 18: 95, 19: 95, 20: 32, 21: 31, 22: 33, 23: 32, 24: 32, 25: 21, 26: 20, 27: 21, 28: 21, 29: 21, 30: 33, 31: 32, 32: 33, 33: 32, 34: 33, 35: 165, 36: 165, 37: 165, 38: 165, 39: 165, 40: 91, 41: 90, 42: 92, 43: 90, 44: 91, 45: 1, 46: 0, 47: 1, 48: 0, 49: 1}, 3: {0: 23, 1: 23, 2: 24, 3: 23, 4: 24, 5: 64, 6: 66, 7: 64, 8: 65, 9: 64, 10: 12, 11: 12, 12: 11, 13: 12, 14: 11, 15: 637, 16: 633, 17: 641, 18: 636, 19: 640, 20: 27, 21: 26, 22: 27, 23: 26, 24: 27, 25: 36, 26: 36, 27: 37, 28: 36, 29: 36, 30: 15, 31: 15, 32: 15, 33: 15, 34: 15, 35: 145, 36: 145, 37: 144, 38: 145, 39: 144, 40: 40, 41: 40, 42: 40, 43: 40, 44: 40, 45: 0, 46: 0, 47: 2, 48: 0, 49: 1}, 4: {0: 35, 1: 36, 2: 37, 3: 36, 4: 36, 5: 50, 6: 50, 7: 49, 8: 50, 9: 50, 10: 86, 11: 86, 12: 86, 13: 86, 14: 86, 15: 179, 16: 178, 17: 181, 18: 179, 19: 179, 20: 360, 21: 359, 22: 360, 23: 360, 24: 359, 25: 70, 26: 71, 27: 71, 28: 70, 29: 70, 30: 8, 31: 8, 32: 7, 33: 8, 34: 8, 35: 129, 36: 129, 37: 129, 38: 129, 39: 129, 40: 82, 41: 82, 42: 82, 43: 82, 44: 82, 45: 1, 46: 0, 47: 0, 48: 0, 49: 0}, 5: {0: 24, 1: 22, 2: 25, 3: 22, 4: 22, 5: 56, 6: 56, 7: 56, 8: 56, 9: 56, 10: 4, 11: 4, 12: 5, 13: 4, 14: 5, 15: 185, 16: 185, 17: 185, 18: 185, 19: 185, 20: 9, 21: 9, 22: 9, 23: 9, 24: 9, 25: 573, 26: 574, 27: 570, 28: 574, 29: 573, 30: 12, 31: 12, 32: 12, 33: 12, 34: 12, 35: 101, 36: 101, 37: 101, 38: 101, 39: 101, 40: 36, 41: 36, 42: 36, 43: 36, 44: 36, 45: 0, 46: 0, 47: 4, 48: 0, 49: 0}, 6: {0: 31, 1: 33, 2: 34, 3: 34, 4: 35, 5: 31, 6: 31, 7: 31, 8: 32, 9: 31, 10: 34, 11: 33, 12: 34, 13: 33, 14: 34, 15: 218, 16: 217, 17: 220, 18: 217, 19: 217, 20: 20, 21: 20, 22: 21, 23: 20, 24: 20, 25: 40, 26: 41, 27: 40, 28: 40, 29: 40, 30: 409, 31: 409, 32: 403, 33: 410, 34: 409, 35: 181, 36: 181, 37: 181, 38: 181, 39: 181, 40: 34, 41: 33, 42: 35, 43: 34, 44: 34, 45: 3, 46: 0, 47: 0, 48: 0, 49: 0}, 7: {0: 35, 1: 34, 2: 36, 3: 37, 4: 38, 5: 38, 6: 38, 7: 38, 8: 38, 9: 38, 10: 30, 11: 28, 12: 30, 13: 28, 14: 30, 15: 97, 16: 96, 17: 97, 18: 96, 19: 97, 20: 14, 21: 14, 22: 14, 23: 14, 24: 14, 25: 48, 26: 48, 27: 48, 28: 48, 29: 48, 30: 34, 31: 35, 32: 34, 33: 35, 34: 34, 35: 676, 36: 677, 37: 674, 38: 676, 39: 674, 40: 28, 41: 29, 42: 28, 43: 29, 44: 28, 45: 0, 46: 0, 47: 0, 48: 0, 49: 0}, 8: {0: 52, 1: 49, 2: 53, 3: 52, 4: 52, 5: 93, 6: 93, 7: 93, 8: 93, 9: 93, 10: 32, 11: 32, 12: 32, 13: 32, 14: 32, 15: 139, 16: 138, 17: 139, 18: 139, 19: 139, 20: 67, 21: 66, 22: 67, 23: 67, 24: 67, 25: 58, 26: 59, 27: 61, 28: 58, 29: 60, 30: 8, 31: 8, 32: 8, 33: 8, 34: 8, 35: 38, 36: 37, 37: 39, 38: 37, 39: 39, 40: 512, 41: 510, 42: 515, 43: 512, 44: 513, 45: 1, 46: 0, 47: 0, 48: 0, 49: 0}}
[Average accuracy till task9]	Acc@1: 83.9667	Acc@5: 96.7889	Loss: 0.6788	Forgetting: 4.5875	Backward: -4.5750
Train: Epoch[1/5]  [  0/313]  eta: 0:03:39  Lr: 0.001875  Loss: 1.2814  Acc@1: 18.7500 (18.7500)  Acc@5: 37.5000 (37.5000)  time: 0.6999  data: 0.3583  max mem: 2362
Train: Epoch[1/5]  [ 10/313]  eta: 0:01:49  Lr: 0.001875  Loss: 0.8830  Acc@1: 68.7500 (55.6818)  Acc@5: 81.2500 (80.1136)  time: 0.3623  data: 0.0331  max mem: 2362
Train: Epoch[1/5]  [ 20/313]  eta: 0:01:41  Lr: 0.001875  Loss: 0.4298  Acc@1: 75.0000 (68.1548)  Acc@5: 93.7500 (87.2024)  time: 0.3286  data: 0.0005  max mem: 2362
Train: Epoch[1/5]  [ 30/313]  eta: 0:01:36  Lr: 0.001875  Loss: 0.1428  Acc@1: 87.5000 (75.4032)  Acc@5: 100.0000 (91.1290)  time: 0.3295  data: 0.0004  max mem: 2362
Train: Epoch[1/5]  [ 40/313]  eta: 0:01:32  Lr: 0.001875  Loss: -0.1529  Acc@1: 87.5000 (78.8110)  Acc@5: 100.0000 (92.9878)  time: 0.3298  data: 0.0004  max mem: 2362
Train: Epoch[1/5]  [ 50/313]  eta: 0:01:28  Lr: 0.001875  Loss: -0.2860  Acc@1: 93.7500 (81.0049)  Acc@5: 100.0000 (93.8725)  time: 0.3302  data: 0.0004  max mem: 2362
Train: Epoch[1/5]  [ 60/313]  eta: 0:01:24  Lr: 0.001875  Loss: -0.5220  Acc@1: 87.5000 (82.0697)  Acc@5: 100.0000 (94.4672)  time: 0.3304  data: 0.0004  max mem: 2362
Train: Epoch[1/5]  [ 70/313]  eta: 0:01:21  Lr: 0.001875  Loss: -0.4934  Acc@1: 87.5000 (83.2746)  Acc@5: 100.0000 (94.8944)  time: 0.3299  data: 0.0004  max mem: 2362
Train: Epoch[1/5]  [ 80/313]  eta: 0:01:17  Lr: 0.001875  Loss: -0.6285  Acc@1: 93.7500 (84.5679)  Acc@5: 100.0000 (95.4475)  time: 0.3300  data: 0.0004  max mem: 2362
Train: Epoch[1/5]  [ 90/313]  eta: 0:01:14  Lr: 0.001875  Loss: -0.4440  Acc@1: 93.7500 (85.3022)  Acc@5: 100.0000 (95.8104)  time: 0.3294  data: 0.0005  max mem: 2362
Train: Epoch[1/5]  [100/313]  eta: 0:01:10  Lr: 0.001875  Loss: -0.3798  Acc@1: 87.5000 (85.3342)  Acc@5: 100.0000 (96.2252)  time: 0.3289  data: 0.0004  max mem: 2362
Train: Epoch[1/5]  [110/313]  eta: 0:01:07  Lr: 0.001875  Loss: -0.6774  Acc@1: 87.5000 (85.9797)  Acc@5: 100.0000 (96.4527)  time: 0.3296  data: 0.0003  max mem: 2362
Train: Epoch[1/5]  [120/313]  eta: 0:01:04  Lr: 0.001875  Loss: -0.8651  Acc@1: 93.7500 (86.4153)  Acc@5: 100.0000 (96.6942)  time: 0.3302  data: 0.0003  max mem: 2362
Train: Epoch[1/5]  [130/313]  eta: 0:01:00  Lr: 0.001875  Loss: -0.6785  Acc@1: 93.7500 (86.9752)  Acc@5: 100.0000 (96.8034)  time: 0.3300  data: 0.0005  max mem: 2362
Train: Epoch[1/5]  [140/313]  eta: 0:00:57  Lr: 0.001875  Loss: -0.9101  Acc@1: 93.7500 (87.3670)  Acc@5: 100.0000 (97.0301)  time: 0.3299  data: 0.0005  max mem: 2362
Train: Epoch[1/5]  [150/313]  eta: 0:00:54  Lr: 0.001875  Loss: -0.5182  Acc@1: 93.7500 (87.2930)  Acc@5: 100.0000 (97.0199)  time: 0.3303  data: 0.0004  max mem: 2362
Train: Epoch[1/5]  [160/313]  eta: 0:00:50  Lr: 0.001875  Loss: -0.4614  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (97.0885)  time: 0.3303  data: 0.0004  max mem: 2362
Train: Epoch[1/5]  [170/313]  eta: 0:00:47  Lr: 0.001875  Loss: -0.5097  Acc@1: 87.5000 (87.5365)  Acc@5: 100.0000 (97.2222)  time: 0.3300  data: 0.0003  max mem: 2362
Train: Epoch[1/5]  [180/313]  eta: 0:00:44  Lr: 0.001875  Loss: -0.7436  Acc@1: 87.5000 (87.6036)  Acc@5: 100.0000 (97.3066)  time: 0.3299  data: 0.0006  max mem: 2362
Train: Epoch[1/5]  [190/313]  eta: 0:00:40  Lr: 0.001875  Loss: -0.5331  Acc@1: 87.5000 (87.8599)  Acc@5: 100.0000 (97.3822)  time: 0.3302  data: 0.0006  max mem: 2362
Train: Epoch[1/5]  [200/313]  eta: 0:00:37  Lr: 0.001875  Loss: -0.6952  Acc@1: 87.5000 (87.7488)  Acc@5: 100.0000 (97.3881)  time: 0.3304  data: 0.0004  max mem: 2362
Train: Epoch[1/5]  [210/313]  eta: 0:00:34  Lr: 0.001875  Loss: -0.5783  Acc@1: 87.5000 (88.0332)  Acc@5: 100.0000 (97.5118)  time: 0.3305  data: 0.0003  max mem: 2362
Train: Epoch[1/5]  [220/313]  eta: 0:00:30  Lr: 0.001875  Loss: -0.8570  Acc@1: 100.0000 (88.3767)  Acc@5: 100.0000 (97.6244)  time: 0.3302  data: 0.0004  max mem: 2362
Train: Epoch[1/5]  [230/313]  eta: 0:00:27  Lr: 0.001875  Loss: -0.8572  Acc@1: 93.7500 (88.5552)  Acc@5: 100.0000 (97.7002)  time: 0.3299  data: 0.0004  max mem: 2362
Train: Epoch[1/5]  [240/313]  eta: 0:00:24  Lr: 0.001875  Loss: -0.9854  Acc@1: 93.7500 (88.6151)  Acc@5: 100.0000 (97.7697)  time: 0.3303  data: 0.0004  max mem: 2362
Train: Epoch[1/5]  [250/313]  eta: 0:00:20  Lr: 0.001875  Loss: -0.9061  Acc@1: 93.7500 (88.6952)  Acc@5: 100.0000 (97.8337)  time: 0.3306  data: 0.0004  max mem: 2362
Train: Epoch[1/5]  [260/313]  eta: 0:00:17  Lr: 0.001875  Loss: -0.8248  Acc@1: 93.7500 (88.8649)  Acc@5: 100.0000 (97.8688)  time: 0.3305  data: 0.0004  max mem: 2362
Train: Epoch[1/5]  [270/313]  eta: 0:00:14  Lr: 0.001875  Loss: -0.8133  Acc@1: 87.5000 (88.8607)  Acc@5: 100.0000 (97.8782)  time: 0.3308  data: 0.0004  max mem: 2362
Train: Epoch[1/5]  [280/313]  eta: 0:00:10  Lr: 0.001875  Loss: -0.8290  Acc@1: 87.5000 (89.0792)  Acc@5: 100.0000 (97.9537)  time: 0.3303  data: 0.0004  max mem: 2362
Train: Epoch[1/5]  [290/313]  eta: 0:00:07  Lr: 0.001875  Loss: -0.9382  Acc@1: 93.7500 (89.1967)  Acc@5: 100.0000 (97.9811)  time: 0.3300  data: 0.0004  max mem: 2362
Train: Epoch[1/5]  [300/313]  eta: 0:00:04  Lr: 0.001875  Loss: -1.0189  Acc@1: 93.7500 (89.2857)  Acc@5: 100.0000 (98.0482)  time: 0.3305  data: 0.0004  max mem: 2362
Train: Epoch[1/5]  [310/313]  eta: 0:00:00  Lr: 0.001875  Loss: -0.3937  Acc@1: 87.5000 (89.3087)  Acc@5: 100.0000 (98.0506)  time: 0.3300  data: 0.0004  max mem: 2362
Train: Epoch[1/5]  [312/313]  eta: 0:00:00  Lr: 0.001875  Loss: -0.7967  Acc@1: 87.5000 (89.3000)  Acc@5: 100.0000 (98.0400)  time: 0.3219  data: 0.0004  max mem: 2362
Train: Epoch[1/5] Total time: 0:01:43 (0.3311 s / it)
Averaged stats: Lr: 0.001875  Loss: -0.7967  Acc@1: 87.5000 (89.3000)  Acc@5: 100.0000 (98.0400)
Train: Epoch[2/5]  [  0/313]  eta: 0:03:47  Lr: 0.001875  Loss: -0.7269  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (100.0000)  time: 0.7275  data: 0.3967  max mem: 2362
Train: Epoch[2/5]  [ 10/313]  eta: 0:01:50  Lr: 0.001875  Loss: -0.9933  Acc@1: 93.7500 (92.6136)  Acc@5: 100.0000 (97.7273)  time: 0.3654  data: 0.0365  max mem: 2362
Train: Epoch[2/5]  [ 20/313]  eta: 0:01:42  Lr: 0.001875  Loss: -0.9147  Acc@1: 93.7500 (91.0714)  Acc@5: 100.0000 (98.8095)  time: 0.3304  data: 0.0004  max mem: 2362
Train: Epoch[2/5]  [ 30/313]  eta: 0:01:37  Lr: 0.001875  Loss: -0.7960  Acc@1: 93.7500 (92.3387)  Acc@5: 100.0000 (98.9919)  time: 0.3312  data: 0.0003  max mem: 2362
Train: Epoch[2/5]  [ 40/313]  eta: 0:01:32  Lr: 0.001875  Loss: -0.8311  Acc@1: 93.7500 (91.9207)  Acc@5: 100.0000 (98.9329)  time: 0.3309  data: 0.0003  max mem: 2362
Train: Epoch[2/5]  [ 50/313]  eta: 0:01:28  Lr: 0.001875  Loss: -0.8251  Acc@1: 93.7500 (92.1569)  Acc@5: 100.0000 (98.8971)  time: 0.3305  data: 0.0006  max mem: 2362
Train: Epoch[2/5]  [ 60/313]  eta: 0:01:25  Lr: 0.001875  Loss: -0.7587  Acc@1: 93.7500 (91.7008)  Acc@5: 100.0000 (98.8730)  time: 0.3295  data: 0.0006  max mem: 2362
Train: Epoch[2/5]  [ 70/313]  eta: 0:01:21  Lr: 0.001875  Loss: -0.6959  Acc@1: 93.7500 (91.9014)  Acc@5: 100.0000 (98.8556)  time: 0.3297  data: 0.0004  max mem: 2362
Train: Epoch[2/5]  [ 80/313]  eta: 0:01:18  Lr: 0.001875  Loss: -0.7876  Acc@1: 93.7500 (91.6667)  Acc@5: 100.0000 (98.8426)  time: 0.3307  data: 0.0004  max mem: 2362
Train: Epoch[2/5]  [ 90/313]  eta: 0:01:14  Lr: 0.001875  Loss: -0.9700  Acc@1: 93.7500 (91.8956)  Acc@5: 100.0000 (98.8324)  time: 0.3304  data: 0.0004  max mem: 2362
Train: Epoch[2/5]  [100/313]  eta: 0:01:11  Lr: 0.001875  Loss: -0.5835  Acc@1: 93.7500 (91.6460)  Acc@5: 100.0000 (98.7624)  time: 0.3300  data: 0.0003  max mem: 2362
Train: Epoch[2/5]  [110/313]  eta: 0:01:07  Lr: 0.001875  Loss: -0.8774  Acc@1: 93.7500 (91.7793)  Acc@5: 100.0000 (98.8739)  time: 0.3306  data: 0.0007  max mem: 2362
Train: Epoch[2/5]  [120/313]  eta: 0:01:04  Lr: 0.001875  Loss: -1.0298  Acc@1: 93.7500 (92.1488)  Acc@5: 100.0000 (98.9153)  time: 0.3308  data: 0.0008  max mem: 2362
Train: Epoch[2/5]  [130/313]  eta: 0:01:01  Lr: 0.001875  Loss: -1.0161  Acc@1: 93.7500 (92.0802)  Acc@5: 100.0000 (98.9027)  time: 0.3302  data: 0.0004  max mem: 2362
Train: Epoch[2/5]  [140/313]  eta: 0:00:57  Lr: 0.001875  Loss: -0.9771  Acc@1: 93.7500 (92.2429)  Acc@5: 100.0000 (98.9805)  time: 0.3298  data: 0.0007  max mem: 2362
Train: Epoch[2/5]  [150/313]  eta: 0:00:54  Lr: 0.001875  Loss: -0.8240  Acc@1: 93.7500 (92.1772)  Acc@5: 100.0000 (99.0480)  time: 0.3297  data: 0.0008  max mem: 2362
Train: Epoch[2/5]  [160/313]  eta: 0:00:50  Lr: 0.001875  Loss: -1.0392  Acc@1: 93.7500 (92.3525)  Acc@5: 100.0000 (99.0683)  time: 0.3298  data: 0.0005  max mem: 2362
Train: Epoch[2/5]  [170/313]  eta: 0:00:47  Lr: 0.001875  Loss: -0.7556  Acc@1: 93.7500 (92.2515)  Acc@5: 100.0000 (99.0863)  time: 0.3300  data: 0.0005  max mem: 2362
Train: Epoch[2/5]  [180/313]  eta: 0:00:44  Lr: 0.001875  Loss: -0.8252  Acc@1: 87.5000 (92.0925)  Acc@5: 100.0000 (99.1367)  time: 0.3306  data: 0.0004  max mem: 2362
Train: Epoch[2/5]  [190/313]  eta: 0:00:40  Lr: 0.001875  Loss: -0.9597  Acc@1: 93.7500 (92.2120)  Acc@5: 100.0000 (99.1165)  time: 0.3308  data: 0.0004  max mem: 2362
Train: Epoch[2/5]  [200/313]  eta: 0:00:37  Lr: 0.001875  Loss: -0.7456  Acc@1: 93.7500 (92.2264)  Acc@5: 100.0000 (99.1294)  time: 0.3309  data: 0.0007  max mem: 2362
Train: Epoch[2/5]  [210/313]  eta: 0:00:34  Lr: 0.001875  Loss: -0.9152  Acc@1: 93.7500 (92.2393)  Acc@5: 100.0000 (99.1410)  time: 0.3302  data: 0.0008  max mem: 2362
Train: Epoch[2/5]  [220/313]  eta: 0:00:30  Lr: 0.001875  Loss: -0.9981  Acc@1: 87.5000 (92.1097)  Acc@5: 100.0000 (99.1233)  time: 0.3306  data: 0.0012  max mem: 2362
Train: Epoch[2/5]  [230/313]  eta: 0:00:27  Lr: 0.001875  Loss: -0.5002  Acc@1: 87.5000 (92.1266)  Acc@5: 100.0000 (99.1613)  time: 0.3321  data: 0.0013  max mem: 2362
Train: Epoch[2/5]  [240/313]  eta: 0:00:24  Lr: 0.001875  Loss: -0.9818  Acc@1: 93.7500 (92.1940)  Acc@5: 100.0000 (99.1701)  time: 0.3312  data: 0.0004  max mem: 2362
Train: Epoch[2/5]  [250/313]  eta: 0:00:20  Lr: 0.001875  Loss: -0.9225  Acc@1: 93.7500 (92.2809)  Acc@5: 100.0000 (99.2032)  time: 0.3292  data: 0.0003  max mem: 2362
Train: Epoch[2/5]  [260/313]  eta: 0:00:17  Lr: 0.001875  Loss: -1.0960  Acc@1: 93.7500 (92.3851)  Acc@5: 100.0000 (99.2337)  time: 0.3286  data: 0.0003  max mem: 2362
Train: Epoch[2/5]  [270/313]  eta: 0:00:14  Lr: 0.001875  Loss: -0.5569  Acc@1: 93.7500 (92.3662)  Acc@5: 100.0000 (99.2159)  time: 0.3288  data: 0.0003  max mem: 2362
Train: Epoch[2/5]  [280/313]  eta: 0:00:10  Lr: 0.001875  Loss: -0.5889  Acc@1: 93.7500 (92.3932)  Acc@5: 100.0000 (99.1770)  time: 0.3287  data: 0.0003  max mem: 2362
Train: Epoch[2/5]  [290/313]  eta: 0:00:07  Lr: 0.001875  Loss: -0.7873  Acc@1: 93.7500 (92.3754)  Acc@5: 100.0000 (99.1838)  time: 0.3287  data: 0.0003  max mem: 2362
Train: Epoch[2/5]  [300/313]  eta: 0:00:04  Lr: 0.001875  Loss: -0.7519  Acc@1: 93.7500 (92.3173)  Acc@5: 100.0000 (99.1902)  time: 0.3286  data: 0.0003  max mem: 2362
Train: Epoch[2/5]  [310/313]  eta: 0:00:00  Lr: 0.001875  Loss: -1.0165  Acc@1: 93.7500 (92.4035)  Acc@5: 100.0000 (99.1961)  time: 0.3279  data: 0.0003  max mem: 2362
Train: Epoch[2/5]  [312/313]  eta: 0:00:00  Lr: 0.001875  Loss: -0.8248  Acc@1: 93.7500 (92.4200)  Acc@5: 100.0000 (99.2000)  time: 0.3199  data: 0.0003  max mem: 2362
Train: Epoch[2/5] Total time: 0:01:43 (0.3312 s / it)
Averaged stats: Lr: 0.001875  Loss: -0.8248  Acc@1: 93.7500 (92.4200)  Acc@5: 100.0000 (99.2000)
Train: Epoch[3/5]  [  0/313]  eta: 0:03:24  Lr: 0.001875  Loss: -0.9037  Acc@1: 93.7500 (93.7500)  Acc@5: 100.0000 (100.0000)  time: 0.6523  data: 0.3208  max mem: 2362
Train: Epoch[3/5]  [ 10/313]  eta: 0:01:48  Lr: 0.001875  Loss: -0.9215  Acc@1: 93.7500 (91.4773)  Acc@5: 100.0000 (99.4318)  time: 0.3581  data: 0.0294  max mem: 2362
Train: Epoch[3/5]  [ 20/313]  eta: 0:01:40  Lr: 0.001875  Loss: -0.7459  Acc@1: 93.7500 (91.3690)  Acc@5: 100.0000 (98.8095)  time: 0.3289  data: 0.0003  max mem: 2362
Train: Epoch[3/5]  [ 30/313]  eta: 0:01:36  Lr: 0.001875  Loss: -0.9611  Acc@1: 93.7500 (92.7419)  Acc@5: 100.0000 (99.1935)  time: 0.3291  data: 0.0003  max mem: 2362
Train: Epoch[3/5]  [ 40/313]  eta: 0:01:31  Lr: 0.001875  Loss: -1.0234  Acc@1: 100.0000 (93.1402)  Acc@5: 100.0000 (99.2378)  time: 0.3288  data: 0.0003  max mem: 2362
Train: Epoch[3/5]  [ 50/313]  eta: 0:01:28  Lr: 0.001875  Loss: -0.6042  Acc@1: 93.7500 (92.1569)  Acc@5: 100.0000 (99.0196)  time: 0.3288  data: 0.0003  max mem: 2362
Train: Epoch[3/5]  [ 60/313]  eta: 0:01:24  Lr: 0.001875  Loss: -0.6483  Acc@1: 93.7500 (92.2131)  Acc@5: 100.0000 (99.0779)  time: 0.3287  data: 0.0003  max mem: 2362
Train: Epoch[3/5]  [ 70/313]  eta: 0:01:21  Lr: 0.001875  Loss: -0.4245  Acc@1: 93.7500 (92.2535)  Acc@5: 100.0000 (99.0317)  time: 0.3288  data: 0.0003  max mem: 2362
Train: Epoch[3/5]  [ 80/313]  eta: 0:01:17  Lr: 0.001875  Loss: -0.6846  Acc@1: 93.7500 (92.6698)  Acc@5: 100.0000 (99.0741)  time: 0.3290  data: 0.0003  max mem: 2362
Train: Epoch[3/5]  [ 90/313]  eta: 0:01:14  Lr: 0.001875  Loss: -0.8296  Acc@1: 93.7500 (92.3764)  Acc@5: 100.0000 (99.1071)  time: 0.3290  data: 0.0003  max mem: 2362
Train: Epoch[3/5]  [100/313]  eta: 0:01:10  Lr: 0.001875  Loss: -0.8690  Acc@1: 87.5000 (92.2030)  Acc@5: 100.0000 (99.1337)  time: 0.3295  data: 0.0004  max mem: 2362
Train: Epoch[3/5]  [110/313]  eta: 0:01:07  Lr: 0.001875  Loss: -1.0079  Acc@1: 93.7500 (92.4550)  Acc@5: 100.0000 (99.0991)  time: 0.3293  data: 0.0003  max mem: 2362
Train: Epoch[3/5]  [120/313]  eta: 0:01:04  Lr: 0.001875  Loss: -0.8559  Acc@1: 93.7500 (92.4587)  Acc@5: 100.0000 (99.0702)  time: 0.3291  data: 0.0003  max mem: 2362
Train: Epoch[3/5]  [130/313]  eta: 0:01:00  Lr: 0.001875  Loss: -0.8944  Acc@1: 93.7500 (92.3664)  Acc@5: 100.0000 (99.0458)  time: 0.3292  data: 0.0004  max mem: 2362
Train: Epoch[3/5]  [140/313]  eta: 0:00:57  Lr: 0.001875  Loss: -0.2140  Acc@1: 93.7500 (92.3316)  Acc@5: 100.0000 (99.0248)  time: 0.3290  data: 0.0003  max mem: 2362
Train: Epoch[3/5]  [150/313]  eta: 0:00:53  Lr: 0.001875  Loss: -0.8263  Acc@1: 93.7500 (92.3841)  Acc@5: 100.0000 (99.0480)  time: 0.3288  data: 0.0003  max mem: 2362
Train: Epoch[3/5]  [160/313]  eta: 0:00:50  Lr: 0.001875  Loss: -0.6917  Acc@1: 93.7500 (92.5854)  Acc@5: 100.0000 (99.0683)  time: 0.3292  data: 0.0003  max mem: 2362
Train: Epoch[3/5]  [170/313]  eta: 0:00:47  Lr: 0.001875  Loss: -1.1738  Acc@1: 93.7500 (92.5439)  Acc@5: 100.0000 (99.0863)  time: 0.3295  data: 0.0003  max mem: 2362
Train: Epoch[3/5]  [180/313]  eta: 0:00:44  Lr: 0.001875  Loss: -0.9751  Acc@1: 93.7500 (92.6796)  Acc@5: 100.0000 (99.1022)  time: 0.3293  data: 0.0003  max mem: 2362
Train: Epoch[3/5]  [190/313]  eta: 0:00:40  Lr: 0.001875  Loss: -0.7349  Acc@1: 93.7500 (92.5393)  Acc@5: 100.0000 (99.1165)  time: 0.3288  data: 0.0003  max mem: 2362
Train: Epoch[3/5]  [200/313]  eta: 0:00:37  Lr: 0.001875  Loss: -0.6987  Acc@1: 93.7500 (92.5684)  Acc@5: 100.0000 (99.0672)  time: 0.3284  data: 0.0003  max mem: 2362
Train: Epoch[3/5]  [210/313]  eta: 0:00:34  Lr: 0.001875  Loss: -1.0932  Acc@1: 93.7500 (92.7429)  Acc@5: 100.0000 (99.1114)  time: 0.3287  data: 0.0003  max mem: 2362
Train: Epoch[3/5]  [220/313]  eta: 0:00:30  Lr: 0.001875  Loss: -0.9972  Acc@1: 100.0000 (92.7602)  Acc@5: 100.0000 (99.1233)  time: 0.3286  data: 0.0003  max mem: 2362
Train: Epoch[3/5]  [230/313]  eta: 0:00:27  Lr: 0.001875  Loss: -0.9184  Acc@1: 93.7500 (92.8030)  Acc@5: 100.0000 (99.1613)  time: 0.3277  data: 0.0003  max mem: 2362
Train: Epoch[3/5]  [240/313]  eta: 0:00:24  Lr: 0.001875  Loss: -0.6177  Acc@1: 93.7500 (92.9461)  Acc@5: 100.0000 (99.1701)  time: 0.3272  data: 0.0002  max mem: 2362
Train: Epoch[3/5]  [250/313]  eta: 0:00:20  Lr: 0.001875  Loss: -0.4924  Acc@1: 93.7500 (92.8038)  Acc@5: 100.0000 (99.1534)  time: 0.3280  data: 0.0003  max mem: 2362
Train: Epoch[3/5]  [260/313]  eta: 0:00:17  Lr: 0.001875  Loss: -0.5924  Acc@1: 93.7500 (92.8400)  Acc@5: 100.0000 (99.1619)  time: 0.3291  data: 0.0003  max mem: 2362
Train: Epoch[3/5]  [270/313]  eta: 0:00:14  Lr: 0.001875  Loss: -0.8288  Acc@1: 93.7500 (92.8275)  Acc@5: 100.0000 (99.1697)  time: 0.3293  data: 0.0003  max mem: 2362
Train: Epoch[3/5]  [280/313]  eta: 0:00:10  Lr: 0.001875  Loss: -1.1057  Acc@1: 93.7500 (92.8158)  Acc@5: 100.0000 (99.1993)  time: 0.3294  data: 0.0003  max mem: 2362
Train: Epoch[3/5]  [290/313]  eta: 0:00:07  Lr: 0.001875  Loss: -0.9393  Acc@1: 93.7500 (92.8050)  Acc@5: 100.0000 (99.1838)  time: 0.3297  data: 0.0003  max mem: 2362
Train: Epoch[3/5]  [300/313]  eta: 0:00:04  Lr: 0.001875  Loss: -0.8213  Acc@1: 93.7500 (92.7326)  Acc@5: 100.0000 (99.1694)  time: 0.3293  data: 0.0003  max mem: 2362
Train: Epoch[3/5]  [310/313]  eta: 0:00:00  Lr: 0.001875  Loss: -0.8749  Acc@1: 93.7500 (92.7452)  Acc@5: 100.0000 (99.1760)  time: 0.3292  data: 0.0003  max mem: 2362
Train: Epoch[3/5]  [312/313]  eta: 0:00:00  Lr: 0.001875  Loss: -1.0049  Acc@1: 93.7500 (92.7400)  Acc@5: 100.0000 (99.1600)  time: 0.3211  data: 0.0003  max mem: 2362
Train: Epoch[3/5] Total time: 0:01:43 (0.3298 s / it)
Averaged stats: Lr: 0.001875  Loss: -1.0049  Acc@1: 93.7500 (92.7400)  Acc@5: 100.0000 (99.1600)
Train: Epoch[4/5]  [  0/313]  eta: 0:03:27  Lr: 0.001875  Loss: -1.1180  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)  time: 0.6630  data: 0.3320  max mem: 2362
Train: Epoch[4/5]  [ 10/313]  eta: 0:01:49  Lr: 0.001875  Loss: -0.6079  Acc@1: 93.7500 (91.4773)  Acc@5: 100.0000 (98.8636)  time: 0.3607  data: 0.0305  max mem: 2362
Train: Epoch[4/5]  [ 20/313]  eta: 0:01:41  Lr: 0.001875  Loss: -0.7373  Acc@1: 93.7500 (92.2619)  Acc@5: 100.0000 (99.1071)  time: 0.3298  data: 0.0003  max mem: 2362
Train: Epoch[4/5]  [ 30/313]  eta: 0:01:36  Lr: 0.001875  Loss: -0.6996  Acc@1: 93.7500 (92.1371)  Acc@5: 100.0000 (99.1935)  time: 0.3294  data: 0.0003  max mem: 2362
Train: Epoch[4/5]  [ 40/313]  eta: 0:01:32  Lr: 0.001875  Loss: -1.0025  Acc@1: 93.7500 (92.2256)  Acc@5: 100.0000 (99.2378)  time: 0.3298  data: 0.0003  max mem: 2362
Train: Epoch[4/5]  [ 50/313]  eta: 0:01:28  Lr: 0.001875  Loss: -0.9475  Acc@1: 93.7500 (93.1373)  Acc@5: 100.0000 (99.2647)  time: 0.3301  data: 0.0003  max mem: 2362
Train: Epoch[4/5]  [ 60/313]  eta: 0:01:24  Lr: 0.001875  Loss: -0.7007  Acc@1: 93.7500 (93.1352)  Acc@5: 100.0000 (99.3852)  time: 0.3304  data: 0.0003  max mem: 2362
Train: Epoch[4/5]  [ 70/313]  eta: 0:01:21  Lr: 0.001875  Loss: -0.9035  Acc@1: 93.7500 (92.9577)  Acc@5: 100.0000 (99.2958)  time: 0.3302  data: 0.0003  max mem: 2362
Train: Epoch[4/5]  [ 80/313]  eta: 0:01:17  Lr: 0.001875  Loss: -1.0047  Acc@1: 93.7500 (93.3642)  Acc@5: 100.0000 (99.3056)  time: 0.3299  data: 0.0003  max mem: 2362
Train: Epoch[4/5]  [ 90/313]  eta: 0:01:14  Lr: 0.001875  Loss: -0.4100  Acc@1: 93.7500 (93.0632)  Acc@5: 100.0000 (99.1071)  time: 0.3299  data: 0.0003  max mem: 2362
Train: Epoch[4/5]  [100/313]  eta: 0:01:11  Lr: 0.001875  Loss: -0.8912  Acc@1: 93.7500 (93.0693)  Acc@5: 100.0000 (99.1955)  time: 0.3306  data: 0.0003  max mem: 2362
Train: Epoch[4/5]  [110/313]  eta: 0:01:07  Lr: 0.001875  Loss: -0.6694  Acc@1: 93.7500 (92.8491)  Acc@5: 100.0000 (99.2117)  time: 0.3307  data: 0.0003  max mem: 2362
Train: Epoch[4/5]  [120/313]  eta: 0:01:04  Lr: 0.001875  Loss: -1.0156  Acc@1: 93.7500 (93.0785)  Acc@5: 100.0000 (99.2769)  time: 0.3298  data: 0.0004  max mem: 2362
Train: Epoch[4/5]  [130/313]  eta: 0:01:00  Lr: 0.001875  Loss: -0.5705  Acc@1: 93.7500 (92.9389)  Acc@5: 100.0000 (99.3321)  time: 0.3300  data: 0.0003  max mem: 2362
Train: Epoch[4/5]  [140/313]  eta: 0:00:57  Lr: 0.001875  Loss: -0.5630  Acc@1: 93.7500 (92.9521)  Acc@5: 100.0000 (99.2908)  time: 0.3301  data: 0.0003  max mem: 2362
Train: Epoch[4/5]  [150/313]  eta: 0:00:54  Lr: 0.001875  Loss: -0.7443  Acc@1: 93.7500 (92.9222)  Acc@5: 100.0000 (99.2964)  time: 0.3296  data: 0.0004  max mem: 2362
Train: Epoch[4/5]  [160/313]  eta: 0:00:50  Lr: 0.001875  Loss: -0.7893  Acc@1: 93.7500 (92.8960)  Acc@5: 100.0000 (99.3401)  time: 0.3300  data: 0.0003  max mem: 2362
Train: Epoch[4/5]  [170/313]  eta: 0:00:47  Lr: 0.001875  Loss: -0.8128  Acc@1: 93.7500 (92.9459)  Acc@5: 100.0000 (99.3787)  time: 0.3308  data: 0.0003  max mem: 2362
Train: Epoch[4/5]  [180/313]  eta: 0:00:44  Lr: 0.001875  Loss: -0.7579  Acc@1: 93.7500 (92.8522)  Acc@5: 100.0000 (99.3785)  time: 0.3307  data: 0.0003  max mem: 2362
Train: Epoch[4/5]  [190/313]  eta: 0:00:40  Lr: 0.001875  Loss: -0.8355  Acc@1: 93.7500 (92.8338)  Acc@5: 100.0000 (99.4110)  time: 0.3296  data: 0.0003  max mem: 2362
Train: Epoch[4/5]  [200/313]  eta: 0:00:37  Lr: 0.001875  Loss: -0.8904  Acc@1: 93.7500 (92.6928)  Acc@5: 100.0000 (99.3781)  time: 0.3292  data: 0.0003  max mem: 2362
Train: Epoch[4/5]  [210/313]  eta: 0:00:34  Lr: 0.001875  Loss: -0.9929  Acc@1: 93.7500 (92.7725)  Acc@5: 100.0000 (99.4076)  time: 0.3298  data: 0.0003  max mem: 2362
Train: Epoch[4/5]  [220/313]  eta: 0:00:30  Lr: 0.001875  Loss: -0.8894  Acc@1: 93.7500 (92.6188)  Acc@5: 100.0000 (99.3778)  time: 0.3303  data: 0.0004  max mem: 2362
Train: Epoch[4/5]  [230/313]  eta: 0:00:27  Lr: 0.001875  Loss: -0.6289  Acc@1: 93.7500 (92.6948)  Acc@5: 100.0000 (99.3506)  time: 0.3304  data: 0.0004  max mem: 2362
Train: Epoch[4/5]  [240/313]  eta: 0:00:24  Lr: 0.001875  Loss: -1.0326  Acc@1: 93.7500 (92.6867)  Acc@5: 100.0000 (99.3257)  time: 0.3303  data: 0.0004  max mem: 2362
Train: Epoch[4/5]  [250/313]  eta: 0:00:20  Lr: 0.001875  Loss: -0.8852  Acc@1: 93.7500 (92.6295)  Acc@5: 100.0000 (99.2779)  time: 0.3308  data: 0.0004  max mem: 2362
Train: Epoch[4/5]  [260/313]  eta: 0:00:17  Lr: 0.001875  Loss: -0.8769  Acc@1: 93.7500 (92.6245)  Acc@5: 100.0000 (99.2816)  time: 0.3307  data: 0.0004  max mem: 2362
Train: Epoch[4/5]  [270/313]  eta: 0:00:14  Lr: 0.001875  Loss: -0.8039  Acc@1: 93.7500 (92.5738)  Acc@5: 100.0000 (99.3081)  time: 0.3299  data: 0.0004  max mem: 2362
Train: Epoch[4/5]  [280/313]  eta: 0:00:10  Lr: 0.001875  Loss: -0.6528  Acc@1: 93.7500 (92.6157)  Acc@5: 100.0000 (99.2438)  time: 0.3301  data: 0.0004  max mem: 2362
Train: Epoch[4/5]  [290/313]  eta: 0:00:07  Lr: 0.001875  Loss: -0.8136  Acc@1: 93.7500 (92.4184)  Acc@5: 100.0000 (99.1838)  time: 0.3307  data: 0.0004  max mem: 2362
Train: Epoch[4/5]  [300/313]  eta: 0:00:04  Lr: 0.001875  Loss: -0.8521  Acc@1: 93.7500 (92.4211)  Acc@5: 100.0000 (99.1694)  time: 0.3306  data: 0.0003  max mem: 2362
Train: Epoch[4/5]  [310/313]  eta: 0:00:00  Lr: 0.001875  Loss: -1.1185  Acc@1: 93.7500 (92.4437)  Acc@5: 100.0000 (99.1760)  time: 0.3301  data: 0.0003  max mem: 2362
Train: Epoch[4/5]  [312/313]  eta: 0:00:00  Lr: 0.001875  Loss: -0.6304  Acc@1: 93.7500 (92.4600)  Acc@5: 100.0000 (99.1800)  time: 0.3219  data: 0.0003  max mem: 2362
Train: Epoch[4/5] Total time: 0:01:43 (0.3311 s / it)
Averaged stats: Lr: 0.001875  Loss: -0.6304  Acc@1: 93.7500 (92.4600)  Acc@5: 100.0000 (99.1800)
Train: Epoch[5/5]  [  0/313]  eta: 0:03:12  Lr: 0.001875  Loss: -0.8812  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)  time: 0.6160  data: 0.2842  max mem: 2362
Train: Epoch[5/5]  [ 10/313]  eta: 0:01:47  Lr: 0.001875  Loss: -0.8008  Acc@1: 93.7500 (90.3409)  Acc@5: 100.0000 (100.0000)  time: 0.3555  data: 0.0261  max mem: 2362
Train: Epoch[5/5]  [ 20/313]  eta: 0:01:40  Lr: 0.001875  Loss: -1.0570  Acc@1: 93.7500 (92.8571)  Acc@5: 100.0000 (100.0000)  time: 0.3300  data: 0.0004  max mem: 2362
Train: Epoch[5/5]  [ 30/313]  eta: 0:01:36  Lr: 0.001875  Loss: -0.9094  Acc@1: 93.7500 (93.3468)  Acc@5: 100.0000 (99.7984)  time: 0.3307  data: 0.0003  max mem: 2362
Train: Epoch[5/5]  [ 40/313]  eta: 0:01:32  Lr: 0.001875  Loss: -0.8608  Acc@1: 93.7500 (93.2927)  Acc@5: 100.0000 (99.0854)  time: 0.3306  data: 0.0003  max mem: 2362
Train: Epoch[5/5]  [ 50/313]  eta: 0:01:28  Lr: 0.001875  Loss: -0.9640  Acc@1: 87.5000 (92.7696)  Acc@5: 100.0000 (99.0196)  time: 0.3296  data: 0.0003  max mem: 2362
Train: Epoch[5/5]  [ 60/313]  eta: 0:01:24  Lr: 0.001875  Loss: -1.0151  Acc@1: 87.5000 (92.9303)  Acc@5: 100.0000 (99.0779)  time: 0.3293  data: 0.0003  max mem: 2362
Train: Epoch[5/5]  [ 70/313]  eta: 0:01:21  Lr: 0.001875  Loss: -0.9516  Acc@1: 87.5000 (92.5176)  Acc@5: 100.0000 (99.2077)  time: 0.3299  data: 0.0003  max mem: 2362
Train: Epoch[5/5]  [ 80/313]  eta: 0:01:17  Lr: 0.001875  Loss: -0.9901  Acc@1: 93.7500 (92.5154)  Acc@5: 100.0000 (99.3056)  time: 0.3300  data: 0.0003  max mem: 2362
Train: Epoch[5/5]  [ 90/313]  eta: 0:01:14  Lr: 0.001875  Loss: -0.7506  Acc@1: 93.7500 (92.4451)  Acc@5: 100.0000 (99.2445)  time: 0.3295  data: 0.0003  max mem: 2362
Train: Epoch[5/5]  [100/313]  eta: 0:01:10  Lr: 0.001875  Loss: -0.7490  Acc@1: 93.7500 (92.4505)  Acc@5: 100.0000 (99.2574)  time: 0.3291  data: 0.0003  max mem: 2362
Train: Epoch[5/5]  [110/313]  eta: 0:01:07  Lr: 0.001875  Loss: -0.7468  Acc@1: 93.7500 (92.6239)  Acc@5: 100.0000 (99.2680)  time: 0.3290  data: 0.0003  max mem: 2362
Train: Epoch[5/5]  [120/313]  eta: 0:01:04  Lr: 0.001875  Loss: -0.9119  Acc@1: 93.7500 (92.6653)  Acc@5: 100.0000 (99.2769)  time: 0.3290  data: 0.0003  max mem: 2362
Train: Epoch[5/5]  [130/313]  eta: 0:01:00  Lr: 0.001875  Loss: -0.9406  Acc@1: 93.7500 (92.7958)  Acc@5: 100.0000 (99.2844)  time: 0.3294  data: 0.0003  max mem: 2362
Train: Epoch[5/5]  [140/313]  eta: 0:00:57  Lr: 0.001875  Loss: -0.9602  Acc@1: 93.7500 (92.9521)  Acc@5: 100.0000 (99.3351)  time: 0.3292  data: 0.0003  max mem: 2362
Train: Epoch[5/5]  [150/313]  eta: 0:00:54  Lr: 0.001875  Loss: -0.9910  Acc@1: 100.0000 (93.0050)  Acc@5: 100.0000 (99.3791)  time: 0.3288  data: 0.0003  max mem: 2362
Train: Epoch[5/5]  [160/313]  eta: 0:00:50  Lr: 0.001875  Loss: -0.9972  Acc@1: 93.7500 (93.0124)  Acc@5: 100.0000 (99.3401)  time: 0.3290  data: 0.0003  max mem: 2362
Train: Epoch[5/5]  [170/313]  eta: 0:00:47  Lr: 0.001875  Loss: -0.4532  Acc@1: 93.7500 (92.8363)  Acc@5: 100.0000 (99.3787)  time: 0.3293  data: 0.0003  max mem: 2362
Train: Epoch[5/5]  [180/313]  eta: 0:00:44  Lr: 0.001875  Loss: -0.5293  Acc@1: 93.7500 (92.8177)  Acc@5: 100.0000 (99.3785)  time: 0.3295  data: 0.0003  max mem: 2362
Train: Epoch[5/5]  [190/313]  eta: 0:00:40  Lr: 0.001875  Loss: -0.9889  Acc@1: 93.7500 (92.6702)  Acc@5: 100.0000 (99.3455)  time: 0.3301  data: 0.0003  max mem: 2362
Train: Epoch[5/5]  [200/313]  eta: 0:00:37  Lr: 0.001875  Loss: -0.9129  Acc@1: 93.7500 (92.5995)  Acc@5: 100.0000 (99.3470)  time: 0.3299  data: 0.0003  max mem: 2362
Train: Epoch[5/5]  [210/313]  eta: 0:00:34  Lr: 0.001875  Loss: -0.7327  Acc@1: 93.7500 (92.5355)  Acc@5: 100.0000 (99.3187)  time: 0.3287  data: 0.0003  max mem: 2362
Train: Epoch[5/5]  [220/313]  eta: 0:00:30  Lr: 0.001875  Loss: -1.0760  Acc@1: 93.7500 (92.5057)  Acc@5: 100.0000 (99.3213)  time: 0.3285  data: 0.0003  max mem: 2362
Train: Epoch[5/5]  [230/313]  eta: 0:00:27  Lr: 0.001875  Loss: -0.8704  Acc@1: 93.7500 (92.4513)  Acc@5: 100.0000 (99.3236)  time: 0.3288  data: 0.0003  max mem: 2362
Train: Epoch[5/5]  [240/313]  eta: 0:00:24  Lr: 0.001875  Loss: -0.8785  Acc@1: 93.7500 (92.5052)  Acc@5: 100.0000 (99.3257)  time: 0.3288  data: 0.0003  max mem: 2362
Train: Epoch[5/5]  [250/313]  eta: 0:00:20  Lr: 0.001875  Loss: -0.9953  Acc@1: 93.7500 (92.4801)  Acc@5: 100.0000 (99.3028)  time: 0.3294  data: 0.0003  max mem: 2362
Train: Epoch[5/5]  [260/313]  eta: 0:00:17  Lr: 0.001875  Loss: -1.1079  Acc@1: 93.7500 (92.6964)  Acc@5: 100.0000 (99.3056)  time: 0.3300  data: 0.0003  max mem: 2362
Train: Epoch[5/5]  [270/313]  eta: 0:00:14  Lr: 0.001875  Loss: -0.8983  Acc@1: 93.7500 (92.6661)  Acc@5: 100.0000 (99.3312)  time: 0.3296  data: 0.0003  max mem: 2362
Train: Epoch[5/5]  [280/313]  eta: 0:00:10  Lr: 0.001875  Loss: -0.4653  Acc@1: 93.7500 (92.6601)  Acc@5: 100.0000 (99.3327)  time: 0.3297  data: 0.0003  max mem: 2362
Train: Epoch[5/5]  [290/313]  eta: 0:00:07  Lr: 0.001875  Loss: -0.5716  Acc@1: 93.7500 (92.5902)  Acc@5: 100.0000 (99.3127)  time: 0.3304  data: 0.0003  max mem: 2362
Train: Epoch[5/5]  [300/313]  eta: 0:00:04  Lr: 0.001875  Loss: -0.7789  Acc@1: 87.5000 (92.5249)  Acc@5: 100.0000 (99.3148)  time: 0.3299  data: 0.0003  max mem: 2362
Train: Epoch[5/5]  [310/313]  eta: 0:00:00  Lr: 0.001875  Loss: -0.6726  Acc@1: 87.5000 (92.4839)  Acc@5: 100.0000 (99.2966)  time: 0.3291  data: 0.0002  max mem: 2362
Train: Epoch[5/5]  [312/313]  eta: 0:00:00  Lr: 0.001875  Loss: -0.8008  Acc@1: 93.7500 (92.5200)  Acc@5: 100.0000 (99.3000)  time: 0.3208  data: 0.0002  max mem: 2362
Train: Epoch[5/5] Total time: 0:01:43 (0.3303 s / it)
Averaged stats: Lr: 0.001875  Loss: -0.8008  Acc@1: 93.7500 (92.5200)  Acc@5: 100.0000 (99.3000)
Test: [Task 1]  [ 0/63]  eta: 0:00:30  Loss: 0.8640 (0.8640)  Acc@1: 75.0000 (75.0000)  Acc@5: 93.7500 (93.7500)  time: 0.4877  data: 0.2814  max mem: 2362
Test: [Task 1]  [10/63]  eta: 0:00:12  Loss: 0.6690 (0.6448)  Acc@1: 81.2500 (82.3864)  Acc@5: 100.0000 (99.4318)  time: 0.2301  data: 0.0258  max mem: 2362
Test: [Task 1]  [20/63]  eta: 0:00:09  Loss: 0.6690 (0.7233)  Acc@1: 81.2500 (81.2500)  Acc@5: 100.0000 (97.9167)  time: 0.2041  data: 0.0002  max mem: 2362
Test: [Task 1]  [30/63]  eta: 0:00:07  Loss: 0.6515 (0.6839)  Acc@1: 81.2500 (83.0645)  Acc@5: 100.0000 (98.3871)  time: 0.2045  data: 0.0003  max mem: 2362
Test: [Task 1]  [40/63]  eta: 0:00:04  Loss: 0.5101 (0.6588)  Acc@1: 87.5000 (83.9939)  Acc@5: 100.0000 (98.4756)  time: 0.2053  data: 0.0003  max mem: 2362
Test: [Task 1]  [50/63]  eta: 0:00:02  Loss: 0.5554 (0.6439)  Acc@1: 87.5000 (84.4363)  Acc@5: 100.0000 (98.4069)  time: 0.2051  data: 0.0003  max mem: 2362
Test: [Task 1]  [60/63]  eta: 0:00:00  Loss: 0.5458 (0.6315)  Acc@1: 87.5000 (85.0410)  Acc@5: 100.0000 (98.3607)  time: 0.2049  data: 0.0002  max mem: 2362
Test: [Task 1]  [62/63]  eta: 0:00:00  Loss: 0.5131 (0.6274)  Acc@1: 87.5000 (85.3000)  Acc@5: 100.0000 (98.4000)  time: 0.2001  data: 0.0002  max mem: 2362
Test: [Task 1] Total time: 0:00:13 (0.2092 s / it)
* Acc@1 85.300 Acc@5 98.400 loss 0.627
Test: [Task 2]  [ 0/63]  eta: 0:00:29  Loss: 0.8959 (0.8959)  Acc@1: 81.2500 (81.2500)  Acc@5: 93.7500 (93.7500)  time: 0.4753  data: 0.2681  max mem: 2362
Test: [Task 2]  [10/63]  eta: 0:00:12  Loss: 0.8099 (0.7860)  Acc@1: 81.2500 (83.5227)  Acc@5: 100.0000 (96.5909)  time: 0.2285  data: 0.0246  max mem: 2362
Test: [Task 2]  [20/63]  eta: 0:00:09  Loss: 0.7734 (0.8618)  Acc@1: 81.2500 (80.6548)  Acc@5: 100.0000 (96.7262)  time: 0.2045  data: 0.0003  max mem: 2362
Test: [Task 2]  [30/63]  eta: 0:00:07  Loss: 0.8653 (0.8520)  Acc@1: 75.0000 (80.8468)  Acc@5: 100.0000 (96.5726)  time: 0.2049  data: 0.0003  max mem: 2362
Test: [Task 2]  [40/63]  eta: 0:00:04  Loss: 0.7952 (0.8353)  Acc@1: 81.2500 (81.7073)  Acc@5: 93.7500 (96.6463)  time: 0.2048  data: 0.0003  max mem: 2362
Test: [Task 2]  [50/63]  eta: 0:00:02  Loss: 0.7081 (0.8268)  Acc@1: 81.2500 (81.7402)  Acc@5: 93.7500 (96.3235)  time: 0.2050  data: 0.0003  max mem: 2362
Test: [Task 2]  [60/63]  eta: 0:00:00  Loss: 0.6639 (0.8015)  Acc@1: 81.2500 (82.2746)  Acc@5: 100.0000 (96.7213)  time: 0.2052  data: 0.0002  max mem: 2362
Test: [Task 2]  [62/63]  eta: 0:00:00  Loss: 0.6639 (0.7927)  Acc@1: 81.2500 (82.4000)  Acc@5: 100.0000 (96.8000)  time: 0.2004  data: 0.0002  max mem: 2362
Test: [Task 2] Total time: 0:00:13 (0.2090 s / it)
* Acc@1 82.400 Acc@5 96.800 loss 0.793
Test: [Task 3]  [ 0/63]  eta: 0:00:34  Loss: 0.4104 (0.4104)  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (100.0000)  time: 0.5503  data: 0.3437  max mem: 2362
Test: [Task 3]  [10/63]  eta: 0:00:12  Loss: 0.6986 (0.6696)  Acc@1: 81.2500 (80.1136)  Acc@5: 100.0000 (96.5909)  time: 0.2365  data: 0.0315  max mem: 2362
Test: [Task 3]  [20/63]  eta: 0:00:09  Loss: 0.6986 (0.6566)  Acc@1: 81.2500 (81.2500)  Acc@5: 100.0000 (97.0238)  time: 0.2046  data: 0.0002  max mem: 2362
Test: [Task 3]  [30/63]  eta: 0:00:07  Loss: 0.6125 (0.6498)  Acc@1: 81.2500 (81.8548)  Acc@5: 100.0000 (97.1774)  time: 0.2042  data: 0.0002  max mem: 2362
Test: [Task 3]  [40/63]  eta: 0:00:04  Loss: 0.5276 (0.6420)  Acc@1: 87.5000 (82.9268)  Acc@5: 100.0000 (97.2561)  time: 0.2048  data: 0.0002  max mem: 2362
Test: [Task 3]  [50/63]  eta: 0:00:02  Loss: 0.6163 (0.6534)  Acc@1: 87.5000 (83.2108)  Acc@5: 100.0000 (96.9363)  time: 0.2051  data: 0.0002  max mem: 2362
Test: [Task 3]  [60/63]  eta: 0:00:00  Loss: 0.7410 (0.6562)  Acc@1: 87.5000 (82.9918)  Acc@5: 100.0000 (97.2336)  time: 0.2047  data: 0.0002  max mem: 2362
Test: [Task 3]  [62/63]  eta: 0:00:00  Loss: 0.7410 (0.6586)  Acc@1: 81.2500 (82.9000)  Acc@5: 100.0000 (97.2000)  time: 0.2000  data: 0.0002  max mem: 2362
Test: [Task 3] Total time: 0:00:13 (0.2098 s / it)
* Acc@1 82.900 Acc@5 97.200 loss 0.659
Test: [Task 4]  [ 0/63]  eta: 0:00:29  Loss: 0.9056 (0.9056)  Acc@1: 81.2500 (81.2500)  Acc@5: 93.7500 (93.7500)  time: 0.4743  data: 0.2624  max mem: 2362
Test: [Task 4]  [10/63]  eta: 0:00:12  Loss: 0.8190 (0.8143)  Acc@1: 81.2500 (80.6818)  Acc@5: 100.0000 (97.1591)  time: 0.2297  data: 0.0241  max mem: 2362
Test: [Task 4]  [20/63]  eta: 0:00:09  Loss: 0.7257 (0.7779)  Acc@1: 81.2500 (81.5476)  Acc@5: 100.0000 (96.7262)  time: 0.2051  data: 0.0003  max mem: 2362
Test: [Task 4]  [30/63]  eta: 0:00:07  Loss: 0.5828 (0.7359)  Acc@1: 87.5000 (82.6613)  Acc@5: 100.0000 (96.7742)  time: 0.2052  data: 0.0003  max mem: 2362
Test: [Task 4]  [40/63]  eta: 0:00:04  Loss: 0.4602 (0.6638)  Acc@1: 87.5000 (84.4512)  Acc@5: 100.0000 (97.2561)  time: 0.2051  data: 0.0003  max mem: 2362
Test: [Task 4]  [50/63]  eta: 0:00:02  Loss: 0.4306 (0.6713)  Acc@1: 87.5000 (83.9461)  Acc@5: 100.0000 (96.8137)  time: 0.2048  data: 0.0002  max mem: 2362
Test: [Task 4]  [60/63]  eta: 0:00:00  Loss: 0.7096 (0.6886)  Acc@1: 81.2500 (83.5041)  Acc@5: 93.7500 (96.3115)  time: 0.2047  data: 0.0002  max mem: 2362
Test: [Task 4]  [62/63]  eta: 0:00:00  Loss: 0.7377 (0.6914)  Acc@1: 81.2500 (83.5000)  Acc@5: 93.7500 (96.4000)  time: 0.1998  data: 0.0002  max mem: 2362
Test: [Task 4] Total time: 0:00:13 (0.2091 s / it)
* Acc@1 83.500 Acc@5 96.400 loss 0.691
Test: [Task 5]  [ 0/63]  eta: 0:00:30  Loss: 0.3818 (0.3818)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)  time: 0.4834  data: 0.2779  max mem: 2362
Test: [Task 5]  [10/63]  eta: 0:00:12  Loss: 0.5863 (0.7171)  Acc@1: 87.5000 (86.3636)  Acc@5: 100.0000 (96.5909)  time: 0.2298  data: 0.0255  max mem: 2362
Test: [Task 5]  [20/63]  eta: 0:00:09  Loss: 0.5863 (0.6622)  Acc@1: 87.5000 (86.3095)  Acc@5: 100.0000 (96.7262)  time: 0.2049  data: 0.0002  max mem: 2362
Test: [Task 5]  [30/63]  eta: 0:00:07  Loss: 0.5905 (0.6627)  Acc@1: 81.2500 (84.6774)  Acc@5: 100.0000 (97.1774)  time: 0.2050  data: 0.0003  max mem: 2362
Test: [Task 5]  [40/63]  eta: 0:00:04  Loss: 0.5771 (0.6496)  Acc@1: 87.5000 (84.6037)  Acc@5: 100.0000 (97.1037)  time: 0.2045  data: 0.0003  max mem: 2362
Test: [Task 5]  [50/63]  eta: 0:00:02  Loss: 0.5771 (0.6484)  Acc@1: 87.5000 (85.6618)  Acc@5: 100.0000 (97.3039)  time: 0.2048  data: 0.0002  max mem: 2362
Test: [Task 5]  [60/63]  eta: 0:00:00  Loss: 0.7212 (0.6711)  Acc@1: 87.5000 (85.3484)  Acc@5: 100.0000 (96.9262)  time: 0.2047  data: 0.0002  max mem: 2362
Test: [Task 5]  [62/63]  eta: 0:00:00  Loss: 0.7388 (0.6906)  Acc@1: 81.2500 (84.8000)  Acc@5: 100.0000 (96.6000)  time: 0.2000  data: 0.0002  max mem: 2362
Test: [Task 5] Total time: 0:00:13 (0.2088 s / it)
* Acc@1 84.800 Acc@5 96.600 loss 0.691
Test: [Task 6]  [ 0/63]  eta: 0:00:30  Loss: 0.6456 (0.6456)  Acc@1: 81.2500 (81.2500)  Acc@5: 93.7500 (93.7500)  time: 0.4782  data: 0.2740  max mem: 2362
Test: [Task 6]  [10/63]  eta: 0:00:12  Loss: 0.7522 (0.7464)  Acc@1: 81.2500 (80.6818)  Acc@5: 93.7500 (94.8864)  time: 0.2290  data: 0.0252  max mem: 2362
Test: [Task 6]  [20/63]  eta: 0:00:09  Loss: 0.7557 (0.7911)  Acc@1: 81.2500 (79.4643)  Acc@5: 93.7500 (95.2381)  time: 0.2043  data: 0.0003  max mem: 2362
Test: [Task 6]  [30/63]  eta: 0:00:07  Loss: 0.7221 (0.7828)  Acc@1: 81.2500 (79.0323)  Acc@5: 100.0000 (96.1694)  time: 0.2048  data: 0.0002  max mem: 2362
Test: [Task 6]  [40/63]  eta: 0:00:04  Loss: 0.8281 (0.8320)  Acc@1: 75.0000 (77.2866)  Acc@5: 93.7500 (95.2744)  time: 0.2048  data: 0.0002  max mem: 2362
Test: [Task 6]  [50/63]  eta: 0:00:02  Loss: 0.7698 (0.8041)  Acc@1: 75.0000 (77.8186)  Acc@5: 93.7500 (95.8333)  time: 0.2045  data: 0.0002  max mem: 2362
Test: [Task 6]  [60/63]  eta: 0:00:00  Loss: 0.7516 (0.8193)  Acc@1: 75.0000 (77.7664)  Acc@5: 100.0000 (95.7992)  time: 0.2041  data: 0.0002  max mem: 2362
Test: [Task 6]  [62/63]  eta: 0:00:00  Loss: 0.7516 (0.8133)  Acc@1: 75.0000 (78.1000)  Acc@5: 100.0000 (95.9000)  time: 0.1992  data: 0.0002  max mem: 2362
Test: [Task 6] Total time: 0:00:13 (0.2101 s / it)
* Acc@1 78.100 Acc@5 95.900 loss 0.813
Test: [Task 7]  [ 0/63]  eta: 0:00:30  Loss: 0.7212 (0.7212)  Acc@1: 81.2500 (81.2500)  Acc@5: 100.0000 (100.0000)  time: 0.4860  data: 0.2801  max mem: 2362
Test: [Task 7]  [10/63]  eta: 0:00:12  Loss: 0.7004 (0.6985)  Acc@1: 87.5000 (84.6591)  Acc@5: 100.0000 (97.1591)  time: 0.2301  data: 0.0257  max mem: 2362
Test: [Task 7]  [20/63]  eta: 0:00:09  Loss: 0.7004 (0.7771)  Acc@1: 81.2500 (83.0357)  Acc@5: 93.7500 (94.9405)  time: 0.2050  data: 0.0002  max mem: 2362
Test: [Task 7]  [30/63]  eta: 0:00:07  Loss: 0.7992 (0.7690)  Acc@1: 81.2500 (82.8629)  Acc@5: 93.7500 (95.1613)  time: 0.2046  data: 0.0002  max mem: 2362
Test: [Task 7]  [40/63]  eta: 0:00:04  Loss: 0.6682 (0.7383)  Acc@1: 87.5000 (83.6890)  Acc@5: 93.7500 (95.4268)  time: 0.2038  data: 0.0002  max mem: 2362
Test: [Task 7]  [50/63]  eta: 0:00:02  Loss: 0.6676 (0.7594)  Acc@1: 81.2500 (83.2108)  Acc@5: 93.7500 (94.9755)  time: 0.2042  data: 0.0002  max mem: 2362
Test: [Task 7]  [60/63]  eta: 0:00:00  Loss: 0.6256 (0.7395)  Acc@1: 87.5000 (83.8115)  Acc@5: 93.7500 (95.1844)  time: 0.2043  data: 0.0002  max mem: 2362
Test: [Task 7]  [62/63]  eta: 0:00:00  Loss: 0.6535 (0.7389)  Acc@1: 81.2500 (83.8000)  Acc@5: 93.7500 (95.2000)  time: 0.1995  data: 0.0002  max mem: 2362
Test: [Task 7] Total time: 0:00:13 (0.2084 s / it)
* Acc@1 83.800 Acc@5 95.200 loss 0.739
Test: [Task 8]  [ 0/63]  eta: 0:00:31  Loss: 0.6434 (0.6434)  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (100.0000)  time: 0.4949  data: 0.2881  max mem: 2362
Test: [Task 8]  [10/63]  eta: 0:00:12  Loss: 0.8141 (0.8311)  Acc@1: 81.2500 (78.9773)  Acc@5: 93.7500 (96.0227)  time: 0.2304  data: 0.0264  max mem: 2362
Test: [Task 8]  [20/63]  eta: 0:00:09  Loss: 0.8141 (0.8450)  Acc@1: 81.2500 (79.7619)  Acc@5: 93.7500 (96.1310)  time: 0.2041  data: 0.0002  max mem: 2362
Test: [Task 8]  [30/63]  eta: 0:00:07  Loss: 0.7451 (0.8142)  Acc@1: 81.2500 (79.4355)  Acc@5: 93.7500 (96.3710)  time: 0.2040  data: 0.0002  max mem: 2362
Test: [Task 8]  [40/63]  eta: 0:00:04  Loss: 0.7451 (0.8002)  Acc@1: 75.0000 (79.4207)  Acc@5: 93.7500 (96.3415)  time: 0.2041  data: 0.0002  max mem: 2362
Test: [Task 8]  [50/63]  eta: 0:00:02  Loss: 0.7984 (0.7898)  Acc@1: 75.0000 (79.6569)  Acc@5: 93.7500 (96.0784)  time: 0.2042  data: 0.0002  max mem: 2362
Test: [Task 8]  [60/63]  eta: 0:00:00  Loss: 0.7851 (0.7988)  Acc@1: 81.2500 (79.9180)  Acc@5: 93.7500 (95.4918)  time: 0.2042  data: 0.0002  max mem: 2362
Test: [Task 8]  [62/63]  eta: 0:00:00  Loss: 0.7762 (0.7875)  Acc@1: 81.2500 (80.1000)  Acc@5: 93.7500 (95.6000)  time: 0.1992  data: 0.0002  max mem: 2362
Test: [Task 8] Total time: 0:00:13 (0.2086 s / it)
* Acc@1 80.100 Acc@5 95.600 loss 0.787
Test: [Task 9]  [ 0/63]  eta: 0:00:29  Loss: 0.3470 (0.3470)  Acc@1: 81.2500 (81.2500)  Acc@5: 100.0000 (100.0000)  time: 0.4735  data: 0.2677  max mem: 2362
Test: [Task 9]  [10/63]  eta: 0:00:12  Loss: 0.5666 (0.6534)  Acc@1: 81.2500 (82.3864)  Acc@5: 100.0000 (96.0227)  time: 0.2285  data: 0.0245  max mem: 2362
Test: [Task 9]  [20/63]  eta: 0:00:09  Loss: 0.5504 (0.6115)  Acc@1: 81.2500 (83.6310)  Acc@5: 100.0000 (96.1310)  time: 0.2041  data: 0.0002  max mem: 2362
Test: [Task 9]  [30/63]  eta: 0:00:07  Loss: 0.4718 (0.5902)  Acc@1: 81.2500 (84.2742)  Acc@5: 100.0000 (96.5726)  time: 0.2041  data: 0.0002  max mem: 2362
Test: [Task 9]  [40/63]  eta: 0:00:04  Loss: 0.4961 (0.6011)  Acc@1: 81.2500 (83.3841)  Acc@5: 100.0000 (96.7988)  time: 0.2041  data: 0.0002  max mem: 2362
Test: [Task 9]  [50/63]  eta: 0:00:02  Loss: 0.5660 (0.6036)  Acc@1: 81.2500 (83.8235)  Acc@5: 100.0000 (96.9363)  time: 0.2042  data: 0.0002  max mem: 2362
Test: [Task 9]  [60/63]  eta: 0:00:00  Loss: 0.5101 (0.5785)  Acc@1: 87.5000 (84.8361)  Acc@5: 100.0000 (96.9262)  time: 0.2043  data: 0.0002  max mem: 2362
Test: [Task 9]  [62/63]  eta: 0:00:00  Loss: 0.4580 (0.5687)  Acc@1: 87.5000 (85.1000)  Acc@5: 100.0000 (96.9000)  time: 0.1994  data: 0.0002  max mem: 2362
Test: [Task 9] Total time: 0:00:13 (0.2083 s / it)
* Acc@1 85.100 Acc@5 96.900 loss 0.569
Test: [Task 10]  [ 0/63]  eta: 0:00:30  Loss: 0.7492 (0.7492)  Acc@1: 68.7500 (68.7500)  Acc@5: 100.0000 (100.0000)  time: 0.4867  data: 0.2792  max mem: 2362
Test: [Task 10]  [10/63]  eta: 0:00:12  Loss: 0.7212 (0.7355)  Acc@1: 81.2500 (82.3864)  Acc@5: 100.0000 (97.7273)  time: 0.2300  data: 0.0256  max mem: 2362
Test: [Task 10]  [20/63]  eta: 0:00:09  Loss: 0.7212 (0.7438)  Acc@1: 81.2500 (81.2500)  Acc@5: 100.0000 (97.9167)  time: 0.2043  data: 0.0002  max mem: 2362
Test: [Task 10]  [30/63]  eta: 0:00:07  Loss: 0.7463 (0.7321)  Acc@1: 81.2500 (81.2500)  Acc@5: 100.0000 (98.1855)  time: 0.2041  data: 0.0002  max mem: 2362
Test: [Task 10]  [40/63]  eta: 0:00:04  Loss: 0.6095 (0.7041)  Acc@1: 81.2500 (81.7073)  Acc@5: 100.0000 (98.3232)  time: 0.2040  data: 0.0003  max mem: 2362
Test: [Task 10]  [50/63]  eta: 0:00:02  Loss: 0.5918 (0.6943)  Acc@1: 87.5000 (82.2304)  Acc@5: 100.0000 (98.2843)  time: 0.2039  data: 0.0003  max mem: 2362
Test: [Task 10]  [60/63]  eta: 0:00:00  Loss: 0.6215 (0.6886)  Acc@1: 87.5000 (82.5820)  Acc@5: 100.0000 (97.9508)  time: 0.2042  data: 0.0002  max mem: 2362
Test: [Task 10]  [62/63]  eta: 0:00:00  Loss: 0.6000 (0.6790)  Acc@1: 87.5000 (82.9000)  Acc@5: 100.0000 (98.0000)  time: 0.1993  data: 0.0002  max mem: 2362
Test: [Task 10] Total time: 0:00:13 (0.2082 s / it)
* Acc@1 82.900 Acc@5 98.000 loss 0.679
{0: {0: 538, 1: 542, 2: 538, 3: 537, 4: 545, 5: 35, 6: 35, 7: 31, 8: 35, 9: 32, 10: 51, 11: 51, 12: 51, 13: 51, 14: 51, 15: 156, 16: 153, 17: 159, 18: 153, 19: 158, 20: 26, 21: 26, 22: 30, 23: 26, 24: 28, 25: 20, 26: 20, 27: 21, 28: 21, 29: 21, 30: 9, 31: 9, 32: 9, 33: 9, 34: 9, 35: 94, 36: 94, 37: 93, 38: 94, 39: 94, 40: 56, 41: 53, 42: 61, 43: 55, 44: 59, 45: 12, 46: 13, 47: 12, 48: 12, 49: 12}, 1: {0: 70, 1: 74, 2: 76, 3: 77, 4: 76, 5: 430, 6: 434, 7: 428, 8: 432, 9: 429, 10: 44, 11: 44, 12: 45, 13: 44, 14: 44, 15: 167, 16: 166, 17: 168, 18: 167, 19: 168, 20: 31, 21: 32, 22: 32, 23: 31, 24: 31, 25: 51, 26: 51, 27: 50, 28: 51, 29: 50, 30: 27, 31: 27, 32: 27, 33: 27, 34: 27, 35: 84, 36: 84, 37: 85, 38: 84, 39: 84, 40: 79, 41: 78, 42: 80, 43: 79, 44: 79, 45: 11, 46: 12, 47: 11, 48: 11, 49: 11}, 2: {0: 28, 1: 26, 2: 29, 3: 28, 4: 28, 5: 10, 6: 9, 7: 10, 8: 10, 9: 10, 10: 526, 11: 526, 12: 527, 13: 526, 14: 527, 15: 95, 16: 93, 17: 96, 18: 95, 19: 95, 20: 32, 21: 31, 22: 33, 23: 32, 24: 32, 25: 21, 26: 20, 27: 21, 28: 21, 29: 21, 30: 33, 31: 32, 32: 33, 33: 32, 34: 33, 35: 162, 36: 162, 37: 162, 38: 162, 39: 162, 40: 91, 41: 90, 42: 92, 43: 90, 44: 91, 45: 3, 46: 3, 47: 3, 48: 3, 49: 3}, 3: {0: 19, 1: 19, 2: 19, 3: 19, 4: 20, 5: 64, 6: 66, 7: 64, 8: 65, 9: 64, 10: 10, 11: 10, 12: 10, 13: 10, 14: 10, 15: 631, 16: 629, 17: 635, 18: 629, 19: 634, 20: 25, 21: 24, 22: 25, 23: 24, 24: 25, 25: 36, 26: 36, 27: 36, 28: 36, 29: 36, 30: 13, 31: 13, 32: 13, 33: 13, 34: 13, 35: 133, 36: 134, 37: 132, 38: 133, 39: 132, 40: 40, 41: 40, 42: 40, 43: 40, 44: 40, 45: 28, 46: 28, 47: 28, 48: 29, 49: 28}, 4: {0: 34, 1: 35, 2: 36, 3: 35, 4: 35, 5: 48, 6: 49, 7: 47, 8: 48, 9: 48, 10: 85, 11: 85, 12: 85, 13: 85, 14: 85, 15: 174, 16: 174, 17: 176, 18: 175, 19: 174, 20: 357, 21: 357, 22: 356, 23: 357, 24: 355, 25: 70, 26: 71, 27: 71, 28: 70, 29: 70, 30: 8, 31: 8, 32: 7, 33: 8, 34: 8, 35: 124, 36: 124, 37: 124, 38: 124, 39: 124, 40: 82, 41: 82, 42: 82, 43: 82, 44: 82, 45: 17, 46: 17, 47: 16, 48: 17, 49: 17}, 5: {0: 24, 1: 22, 2: 25, 3: 22, 4: 22, 5: 56, 6: 56, 7: 56, 8: 56, 9: 56, 10: 4, 11: 4, 12: 5, 13: 4, 14: 5, 15: 185, 16: 185, 17: 185, 18: 185, 19: 185, 20: 9, 21: 9, 22: 9, 23: 9, 24: 9, 25: 573, 26: 573, 27: 572, 28: 573, 29: 572, 30: 12, 31: 12, 32: 12, 33: 12, 34: 12, 35: 100, 36: 100, 37: 100, 38: 100, 39: 100, 40: 35, 41: 35, 42: 35, 43: 35, 44: 35, 45: 3, 46: 3, 47: 3, 48: 3, 49: 3}, 6: {0: 29, 1: 31, 2: 33, 3: 33, 4: 33, 5: 29, 6: 29, 7: 29, 8: 29, 9: 29, 10: 34, 11: 33, 12: 34, 13: 33, 14: 34, 15: 218, 16: 217, 17: 220, 18: 217, 19: 217, 20: 20, 21: 20, 22: 21, 23: 20, 24: 20, 25: 38, 26: 39, 27: 38, 28: 38, 29: 38, 30: 406, 31: 406, 32: 403, 33: 407, 34: 406, 35: 178, 36: 178, 37: 178, 38: 178, 39: 178, 40: 33, 41: 32, 42: 34, 43: 33, 44: 33, 45: 13, 46: 12, 47: 13, 48: 13, 49: 13}, 7: {0: 34, 1: 32, 2: 34, 3: 35, 4: 37, 5: 38, 6: 38, 7: 38, 8: 38, 9: 38, 10: 30, 11: 28, 12: 30, 13: 28, 14: 30, 15: 92, 16: 91, 17: 92, 18: 91, 19: 92, 20: 13, 21: 13, 22: 13, 23: 13, 24: 13, 25: 47, 26: 47, 27: 47, 28: 47, 29: 47, 30: 34, 31: 35, 32: 34, 33: 35, 34: 34, 35: 666, 36: 667, 37: 664, 38: 666, 39: 664, 40: 27, 41: 28, 42: 27, 43: 28, 44: 27, 45: 20, 46: 20, 47: 19, 48: 20, 49: 19}, 8: {0: 52, 1: 49, 2: 53, 3: 52, 4: 52, 5: 93, 6: 93, 7: 93, 8: 93, 9: 93, 10: 32, 11: 32, 12: 32, 13: 32, 14: 32, 15: 137, 16: 136, 17: 137, 18: 137, 19: 137, 20: 66, 21: 65, 22: 66, 23: 66, 24: 66, 25: 58, 26: 59, 27: 61, 28: 58, 29: 60, 30: 8, 31: 8, 32: 8, 33: 8, 34: 8, 35: 37, 36: 36, 37: 38, 38: 36, 39: 38, 40: 510, 41: 509, 42: 513, 43: 510, 44: 511, 45: 6, 46: 6, 47: 6, 48: 6, 49: 6}, 9: {0: 38, 1: 40, 2: 45, 3: 42, 4: 42, 5: 57, 6: 57, 7: 58, 8: 57, 9: 58, 10: 18, 11: 17, 12: 20, 13: 18, 14: 18, 15: 175, 16: 175, 17: 177, 18: 175, 19: 176, 20: 30, 21: 29, 22: 30, 23: 29, 24: 30, 25: 67, 26: 68, 27: 68, 28: 67, 29: 67, 30: 21, 31: 20, 32: 21, 33: 20, 34: 21, 35: 170, 36: 172, 37: 169, 38: 172, 39: 170, 40: 104, 41: 104, 42: 106, 43: 104, 44: 106, 45: 314, 46: 315, 47: 315, 48: 314, 49: 314}}
[Average accuracy till task10]	Acc@1: 82.8900	Acc@5: 96.7000	Loss: 0.7048	Forgetting: 5.1556	Backward: -5.1444
Total training time: 1:39:30
