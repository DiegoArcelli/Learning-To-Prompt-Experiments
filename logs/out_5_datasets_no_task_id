Namespace(subparser_name='five_datasets_l2p', batch_size=16, epochs=5, model='vit_base_patch16_224', input_size=224, pretrained=True, drop=0.0, drop_path=0.0, opt='adam', opt_eps=1e-08, opt_betas=(0.9, 0.999), clip_grad=1.0, momentum=0.9, weight_decay=0.0, reinit_optimizer=True, sched='constant', lr=0.03, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, unscale_lr=True, color_jitter=None, aa=None, smoothing=0.1, train_interpolation='bicubic', reprob=0.0, remode='pixel', recount=1, data_path='./local_datasets/', dataset='5-datasets', shuffle=False, output_dir='./output_5_datasets_no_task_id', device='cuda', seed=42, eval=False, num_workers=4, pin_mem=True, world_size=1, dist_url='env://', num_tasks=5, train_mask=True,Namespace(subparser_name='five_datasets_l2p', batch_size=16, epochs=5, model='vit_base_patch16_224', input_size=224, pretrained=True, drop=0.0, drop_path=0.0, opt='adam', opt_eps=1e-08, opt_betas=(0.9, 0.999), clip_grad=1.0, momentum=0.9, weight_decay=0.0, reinit_optimizer=True, sched='constant', lr=0.03, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, unscale_lr=True, color_jitter=None, aa=None, smoothing=0.1, train_interpolation='bicubic', reprob=0.0, remode='pixel', recount=1, data_path='./local_datasets/', dataset='5-datasets', shuffle=False, output_dir='./output_5_datasets_no_task_id', device='cuda', seed=42, eval=False, num_workers=4, pin_mem=True, world_size=1, dist_url='env://', num_tasks=5, train_mask=True, task_inc=False, prompt_pool=True, size=20, length=10, top_k=4, initializer='uniform', prompt_key=True, prompt_key_init='uniform', use_prompt_mask=True, shared_prompt_pool=True, shared_prompt_key=True, batchwise_prompt=True, embedding_key='cls', predefined_key='', pull_constraint=True, pull_constraint_coeff=0.5, global_pool='token', head_type='prompt', freeze=['blocks', 'patch_embed', 'cls_token', 'norm', 'pos_embed'], print_freq=10, freeze_head=False, train_type='l2p', eval_task_id=False, frequency_penalization=False, class_incremental=False, init_class_prompts=False, task_incremental=False, init_tasks_prompts=False, prompts_per_task=4, prompts_per_class=1, freeze_keys=False)
Not using distributed mode
['SVHN', 'MNIST', 'CIFAR10', 'NotMNIST', 'FashionMNIST']
Using downloaded and verified file: ./local_datasets/train_32x32.mat
Using downloaded and verified file: ./local_datasets/train_32x32.mat
Using downloaded and verified file: ./local_datasets/test_32x32.mat
Using downloaded and verified file: ./local_datasets/test_32x32.mat
[1 9 2 3 2 5 9 3 3 1]
tensor([5, 0, 4, 1, 9, 2, 1, 3, 1, 4])
Files already downloaded and verified
Files already downloaded and verified
[6, 9, 9, 4, 1, 1, 2, 7, 8, 3]
File F/Q3Jvc3NvdmVyIEJvbGRPYmxpcXVlLnR0Zg==.png is broken
File A/RGVtb2NyYXRpY2FCb2xkT2xkc3R5bGUgQm9sZC50dGY=.png is broken
[5, 5, 5, 5, 5, 5, 5, 5, 5, 5]
tensor([9, 0, 0, 3, 0, 2, 7, 2, 5, 5])
Creating original model: vit_base_patch16_224
Creating model: vit_base_patch16_224
number of params: 207410
Start training for 5 epochs
Train: Epoch[1/5]  [   0/4579]  eta: 4:55:08  Lr: 0.001875  Loss: 2.3002  Acc@1: 12.5000 (12.5000)  Acc@5: 68.7500 (68.7500)  time: 3.8672  data: 0.6301  max mem: 2497
Train: Epoch[1/5]  [  10/4579]  eta: 1:18:58  Lr: 0.001875  Loss: 2.1737  Acc@1: 18.7500 (15.9091)  Acc@5: 50.0000 (56.8182)  time: 1.0370  data: 0.0579  max mem: 2500
Train: Epoch[1/5]  [  20/4579]  eta: 1:08:25  Lr: 0.001875  Loss: 2.4522  Acc@1: 12.5000 (15.1786)  Acc@5: 56.2500 (60.1190)  time: 0.7521  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [  30/4579]  eta: 1:04:31  Lr: 0.001875  Loss: 1.9384  Acc@1: 18.7500 (17.9435)  Acc@5: 62.5000 (60.8871)  time: 0.7489  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [  40/4579]  eta: 1:02:24  Lr: 0.001875  Loss: 1.9888  Acc@1: 25.0000 (19.3598)  Acc@5: 68.7500 (63.2622)  time: 0.7456  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [  50/4579]  eta: 1:01:07  Lr: 0.001875  Loss: 1.8787  Acc@1: 25.0000 (20.5882)  Acc@5: 68.7500 (63.2353)  time: 0.7456  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [  60/4579]  eta: 1:00:19  Lr: 0.001875  Loss: 2.1061  Acc@1: 31.2500 (22.3361)  Acc@5: 68.7500 (64.3443)  time: 0.7516  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [  70/4579]  eta: 0:59:39  Lr: 0.001875  Loss: 1.9293  Acc@1: 31.2500 (22.8873)  Acc@5: 68.7500 (65.5810)  time: 0.7536  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [  80/4579]  eta: 0:59:08  Lr: 0.001875  Loss: 1.7547  Acc@1: 31.2500 (24.4599)  Acc@5: 75.0000 (66.7438)  time: 0.7521  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [  90/4579]  eta: 0:58:41  Lr: 0.001875  Loss: 1.8100  Acc@1: 31.2500 (25.0687)  Acc@5: 75.0000 (67.7198)  time: 0.7512  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [ 100/4579]  eta: 0:58:20  Lr: 0.001875  Loss: 1.8165  Acc@1: 31.2500 (25.6188)  Acc@5: 75.0000 (68.2550)  time: 0.7517  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [ 110/4579]  eta: 0:58:01  Lr: 0.001875  Loss: 1.5818  Acc@1: 31.2500 (26.4640)  Acc@5: 75.0000 (69.0315)  time: 0.7542  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [ 120/4579]  eta: 0:57:43  Lr: 0.001875  Loss: 1.6143  Acc@1: 31.2500 (26.5496)  Acc@5: 75.0000 (69.5248)  time: 0.7531  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [ 130/4579]  eta: 0:57:28  Lr: 0.001875  Loss: 1.4807  Acc@1: 31.2500 (26.6698)  Acc@5: 75.0000 (69.7996)  time: 0.7533  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [ 140/4579]  eta: 0:57:12  Lr: 0.001875  Loss: 1.7109  Acc@1: 25.0000 (26.9947)  Acc@5: 75.0000 (70.2128)  time: 0.7512  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [ 150/4579]  eta: 0:56:55  Lr: 0.001875  Loss: 1.2238  Acc@1: 31.2500 (27.2765)  Acc@5: 75.0000 (70.9437)  time: 0.7455  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [ 160/4579]  eta: 0:56:41  Lr: 0.001875  Loss: 1.5070  Acc@1: 37.5000 (27.8339)  Acc@5: 81.2500 (71.5450)  time: 0.7461  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [ 170/4579]  eta: 0:56:28  Lr: 0.001875  Loss: 1.6403  Acc@1: 31.2500 (28.0702)  Acc@5: 81.2500 (72.0760)  time: 0.7489  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [ 180/4579]  eta: 0:56:16  Lr: 0.001875  Loss: 1.3707  Acc@1: 31.2500 (28.5566)  Acc@5: 81.2500 (72.5829)  time: 0.7503  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [ 190/4579]  eta: 0:56:05  Lr: 0.001875  Loss: 1.3092  Acc@1: 37.5000 (29.1230)  Acc@5: 81.2500 (73.2330)  time: 0.7512  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [ 200/4579]  eta: 0:55:54  Lr: 0.001875  Loss: 1.4548  Acc@1: 37.5000 (29.4154)  Acc@5: 81.2500 (73.3520)  time: 0.7510  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [ 210/4579]  eta: 0:55:43  Lr: 0.001875  Loss: 1.3306  Acc@1: 37.5000 (29.5320)  Acc@5: 75.0000 (73.4893)  time: 0.7505  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [ 220/4579]  eta: 0:55:32  Lr: 0.001875  Loss: 1.2471  Acc@1: 37.5000 (29.8925)  Acc@5: 75.0000 (73.7274)  time: 0.7504  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [ 230/4579]  eta: 0:55:22  Lr: 0.001875  Loss: 1.1505  Acc@1: 37.5000 (30.1407)  Acc@5: 81.2500 (74.0801)  time: 0.7516  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [ 240/4579]  eta: 0:55:12  Lr: 0.001875  Loss: 1.5341  Acc@1: 31.2500 (30.2386)  Acc@5: 75.0000 (74.1442)  time: 0.7506  data: 0.0010  max mem: 2500
Train: Epoch[1/5]  [ 250/4579]  eta: 0:55:02  Lr: 0.001875  Loss: 1.2865  Acc@1: 31.2500 (30.3536)  Acc@5: 75.0000 (74.4273)  time: 0.7486  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [ 260/4579]  eta: 0:54:52  Lr: 0.001875  Loss: 1.2785  Acc@1: 31.2500 (30.4598)  Acc@5: 81.2500 (74.8324)  time: 0.7492  data: 0.0013  max mem: 2500
Train: Epoch[1/5]  [ 270/4579]  eta: 0:54:43  Lr: 0.001875  Loss: 0.9788  Acc@1: 31.2500 (30.6734)  Acc@5: 81.2500 (74.9077)  time: 0.7508  data: 0.0012  max mem: 2500
Train: Epoch[1/5]  [ 280/4579]  eta: 0:54:32  Lr: 0.001875  Loss: 1.0992  Acc@1: 37.5000 (30.9164)  Acc@5: 75.0000 (74.9110)  time: 0.7484  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [ 290/4579]  eta: 0:54:23  Lr: 0.001875  Loss: 1.1380  Acc@1: 37.5000 (31.0567)  Acc@5: 81.2500 (75.1289)  time: 0.7476  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 300/4579]  eta: 0:54:14  Lr: 0.001875  Loss: 0.9960  Acc@1: 31.2500 (31.1669)  Acc@5: 87.5000 (75.5191)  time: 0.7490  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 310/4579]  eta: 0:54:05  Lr: 0.001875  Loss: 1.1434  Acc@1: 37.5000 (31.4309)  Acc@5: 87.5000 (75.8240)  time: 0.7493  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 320/4579]  eta: 0:53:56  Lr: 0.001875  Loss: 0.7932  Acc@1: 43.7500 (31.6783)  Acc@5: 87.5000 (76.1877)  time: 0.7494  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 330/4579]  eta: 0:53:46  Lr: 0.001875  Loss: 0.5344  Acc@1: 43.7500 (31.9486)  Acc@5: 87.5000 (76.3218)  time: 0.7470  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [ 340/4579]  eta: 0:53:37  Lr: 0.001875  Loss: 0.8403  Acc@1: 43.7500 (32.2031)  Acc@5: 87.5000 (76.6312)  time: 0.7480  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [ 350/4579]  eta: 0:53:28  Lr: 0.001875  Loss: 0.3815  Acc@1: 37.5000 (32.3540)  Acc@5: 81.2500 (76.7450)  time: 0.7490  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [ 360/4579]  eta: 0:53:20  Lr: 0.001875  Loss: 1.2181  Acc@1: 37.5000 (32.5485)  Acc@5: 81.2500 (76.9564)  time: 0.7478  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [ 370/4579]  eta: 0:53:11  Lr: 0.001875  Loss: 1.0355  Acc@1: 37.5000 (32.7830)  Acc@5: 81.2500 (77.1058)  time: 0.7478  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [ 380/4579]  eta: 0:53:02  Lr: 0.001875  Loss: 1.0846  Acc@1: 43.7500 (33.0052)  Acc@5: 81.2500 (77.2638)  time: 0.7475  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [ 390/4579]  eta: 0:52:53  Lr: 0.001875  Loss: 0.3367  Acc@1: 43.7500 (33.3600)  Acc@5: 81.2500 (77.3657)  time: 0.7474  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [ 400/4579]  eta: 0:52:45  Lr: 0.001875  Loss: 0.3552  Acc@1: 43.7500 (33.6814)  Acc@5: 81.2500 (77.5094)  time: 0.7472  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [ 410/4579]  eta: 0:52:36  Lr: 0.001875  Loss: 0.5417  Acc@1: 43.7500 (33.9112)  Acc@5: 87.5000 (77.7372)  time: 0.7481  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [ 420/4579]  eta: 0:52:28  Lr: 0.001875  Loss: 0.6976  Acc@1: 43.7500 (34.0410)  Acc@5: 81.2500 (77.8207)  time: 0.7498  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [ 430/4579]  eta: 0:52:19  Lr: 0.001875  Loss: 0.7478  Acc@1: 43.7500 (34.3532)  Acc@5: 81.2500 (78.0017)  time: 0.7476  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [ 440/4579]  eta: 0:52:11  Lr: 0.001875  Loss: 0.1163  Acc@1: 43.7500 (34.6230)  Acc@5: 87.5000 (78.2455)  time: 0.7453  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [ 450/4579]  eta: 0:52:02  Lr: 0.001875  Loss: 0.4098  Acc@1: 43.7500 (34.8947)  Acc@5: 87.5000 (78.5200)  time: 0.7463  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [ 460/4579]  eta: 0:51:54  Lr: 0.001875  Loss: 0.4715  Acc@1: 43.7500 (35.1274)  Acc@5: 87.5000 (78.7148)  time: 0.7478  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [ 470/4579]  eta: 0:51:46  Lr: 0.001875  Loss: 0.6959  Acc@1: 43.7500 (35.2442)  Acc@5: 87.5000 (78.9145)  time: 0.7508  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [ 480/4579]  eta: 0:51:38  Lr: 0.001875  Loss: 0.6589  Acc@1: 43.7500 (35.3690)  Acc@5: 81.2500 (78.9631)  time: 0.7527  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [ 490/4579]  eta: 0:51:30  Lr: 0.001875  Loss: 0.7442  Acc@1: 43.7500 (35.6415)  Acc@5: 81.2500 (78.9969)  time: 0.7499  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [ 500/4579]  eta: 0:51:22  Lr: 0.001875  Loss: 0.6423  Acc@1: 43.7500 (35.7285)  Acc@5: 81.2500 (79.0669)  time: 0.7475  data: 0.0014  max mem: 2500
Train: Epoch[1/5]  [ 510/4579]  eta: 0:51:14  Lr: 0.001875  Loss: 0.5626  Acc@1: 50.0000 (36.0568)  Acc@5: 87.5000 (79.2197)  time: 0.7482  data: 0.0016  max mem: 2500
Train: Epoch[1/5]  [ 520/4579]  eta: 0:51:06  Lr: 0.001875  Loss: -0.0485  Acc@1: 50.0000 (36.3604)  Acc@5: 87.5000 (79.3786)  time: 0.7487  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [ 530/4579]  eta: 0:50:57  Lr: 0.001875  Loss: 0.3296  Acc@1: 43.7500 (36.4407)  Acc@5: 87.5000 (79.4609)  time: 0.7475  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [ 540/4579]  eta: 0:50:49  Lr: 0.001875  Loss: 0.4610  Acc@1: 43.7500 (36.6335)  Acc@5: 87.5000 (79.5402)  time: 0.7474  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [ 550/4579]  eta: 0:50:41  Lr: 0.001875  Loss: 0.6630  Acc@1: 43.7500 (36.7740)  Acc@5: 87.5000 (79.6166)  time: 0.7479  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [ 560/4579]  eta: 0:50:33  Lr: 0.001875  Loss: 0.6482  Acc@1: 37.5000 (36.8761)  Acc@5: 87.5000 (79.7906)  time: 0.7501  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [ 570/4579]  eta: 0:50:25  Lr: 0.001875  Loss: 0.4741  Acc@1: 43.7500 (37.0841)  Acc@5: 87.5000 (79.9584)  time: 0.7505  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [ 580/4579]  eta: 0:50:17  Lr: 0.001875  Loss: 0.5094  Acc@1: 43.7500 (37.1880)  Acc@5: 87.5000 (80.1312)  time: 0.7484  data: 0.0009  max mem: 2500
Train: Epoch[1/5]  [ 590/4579]  eta: 0:50:10  Lr: 0.001875  Loss: 0.5121  Acc@1: 37.5000 (37.3202)  Acc@5: 87.5000 (80.2136)  time: 0.7490  data: 0.0012  max mem: 2500
Train: Epoch[1/5]  [ 600/4579]  eta: 0:50:02  Lr: 0.001875  Loss: 0.1831  Acc@1: 43.7500 (37.5520)  Acc@5: 87.5000 (80.3245)  time: 0.7523  data: 0.0010  max mem: 2500
Train: Epoch[1/5]  [ 610/4579]  eta: 0:49:54  Lr: 0.001875  Loss: 0.1729  Acc@1: 43.7500 (37.6023)  Acc@5: 81.2500 (80.3294)  time: 0.7518  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [ 620/4579]  eta: 0:49:46  Lr: 0.001875  Loss: 0.7034  Acc@1: 43.7500 (37.7415)  Acc@5: 87.5000 (80.4549)  time: 0.7452  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [ 630/4579]  eta: 0:49:38  Lr: 0.001875  Loss: 0.5681  Acc@1: 43.7500 (37.8170)  Acc@5: 87.5000 (80.4873)  time: 0.7439  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [ 640/4579]  eta: 0:49:30  Lr: 0.001875  Loss: -0.1470  Acc@1: 43.7500 (37.9485)  Acc@5: 87.5000 (80.6357)  time: 0.7470  data: 0.0014  max mem: 2500
Train: Epoch[1/5]  [ 650/4579]  eta: 0:49:22  Lr: 0.001875  Loss: 0.4513  Acc@1: 43.7500 (38.0472)  Acc@5: 87.5000 (80.6836)  time: 0.7503  data: 0.0013  max mem: 2500
Train: Epoch[1/5]  [ 660/4579]  eta: 0:49:08  Lr: 0.001875  Loss: 0.7375  Acc@1: 43.7500 (38.1241)  Acc@5: 81.2500 (80.7016)  time: 0.6946  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [ 670/4579]  eta: 0:48:37  Lr: 0.001875  Loss: 0.6165  Acc@1: 43.7500 (38.1800)  Acc@5: 87.5000 (80.7843)  time: 0.4923  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [ 680/4579]  eta: 0:48:06  Lr: 0.001875  Loss: 0.4805  Acc@1: 50.0000 (38.3076)  Acc@5: 87.5000 (80.8829)  time: 0.3493  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [ 690/4579]  eta: 0:47:37  Lr: 0.001875  Loss: 0.2961  Acc@1: 50.0000 (38.4316)  Acc@5: 87.5000 (81.0058)  time: 0.3511  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [ 700/4579]  eta: 0:47:09  Lr: 0.001875  Loss: 0.3743  Acc@1: 43.7500 (38.4897)  Acc@5: 87.5000 (81.1163)  time: 0.3512  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [ 710/4579]  eta: 0:46:41  Lr: 0.001875  Loss: 0.3099  Acc@1: 43.7500 (38.4845)  Acc@5: 87.5000 (81.1357)  time: 0.3507  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [ 720/4579]  eta: 0:46:13  Lr: 0.001875  Loss: 0.4376  Acc@1: 37.5000 (38.5489)  Acc@5: 81.2500 (81.1980)  time: 0.3498  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [ 730/4579]  eta: 0:45:47  Lr: 0.001875  Loss: 0.3469  Acc@1: 43.7500 (38.6200)  Acc@5: 87.5000 (81.2756)  time: 0.3489  data: 0.0009  max mem: 2500
Train: Epoch[1/5]  [ 740/4579]  eta: 0:45:21  Lr: 0.001875  Loss: 0.3214  Acc@1: 50.0000 (38.8495)  Acc@5: 87.5000 (81.3512)  time: 0.3490  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [ 750/4579]  eta: 0:44:55  Lr: 0.001875  Loss: 0.4831  Acc@1: 50.0000 (38.9397)  Acc@5: 87.5000 (81.4331)  time: 0.3505  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [ 760/4579]  eta: 0:44:31  Lr: 0.001875  Loss: 0.1309  Acc@1: 43.7500 (39.0933)  Acc@5: 87.5000 (81.5539)  time: 0.3565  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [ 770/4579]  eta: 0:44:07  Lr: 0.001875  Loss: 0.4576  Acc@1: 43.7500 (39.1537)  Acc@5: 87.5000 (81.6067)  time: 0.3556  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [ 780/4579]  eta: 0:43:43  Lr: 0.001875  Loss: 0.7142  Acc@1: 43.7500 (39.3246)  Acc@5: 87.5000 (81.6181)  time: 0.3506  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [ 790/4579]  eta: 0:43:20  Lr: 0.001875  Loss: 0.0540  Acc@1: 43.7500 (39.3963)  Acc@5: 87.5000 (81.6846)  time: 0.3509  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [ 800/4579]  eta: 0:42:57  Lr: 0.001875  Loss: 0.4904  Acc@1: 50.0000 (39.5209)  Acc@5: 87.5000 (81.7806)  time: 0.3513  data: 0.0009  max mem: 2500
Train: Epoch[1/5]  [ 810/4579]  eta: 0:42:35  Lr: 0.001875  Loss: 0.1764  Acc@1: 50.0000 (39.6347)  Acc@5: 87.5000 (81.8665)  time: 0.3511  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [ 820/4579]  eta: 0:42:13  Lr: 0.001875  Loss: 0.0395  Acc@1: 50.0000 (39.8295)  Acc@5: 87.5000 (81.9580)  time: 0.3491  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [ 830/4579]  eta: 0:41:52  Lr: 0.001875  Loss: -0.1545  Acc@1: 50.0000 (39.9368)  Acc@5: 87.5000 (82.0472)  time: 0.3501  data: 0.0012  max mem: 2500
Train: Epoch[1/5]  [ 840/4579]  eta: 0:41:31  Lr: 0.001875  Loss: 0.6948  Acc@1: 50.0000 (40.0342)  Acc@5: 87.5000 (82.1121)  time: 0.3515  data: 0.0013  max mem: 2500
Train: Epoch[1/5]  [ 850/4579]  eta: 0:41:10  Lr: 0.001875  Loss: 0.3276  Acc@1: 50.0000 (40.1366)  Acc@5: 87.5000 (82.1240)  time: 0.3499  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [ 860/4579]  eta: 0:40:50  Lr: 0.001875  Loss: 0.2273  Acc@1: 50.0000 (40.2729)  Acc@5: 87.5000 (82.1356)  time: 0.3494  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [ 870/4579]  eta: 0:40:31  Lr: 0.001875  Loss: 0.0398  Acc@1: 50.0000 (40.3200)  Acc@5: 87.5000 (82.2044)  time: 0.3507  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [ 880/4579]  eta: 0:40:11  Lr: 0.001875  Loss: 0.6343  Acc@1: 43.7500 (40.4157)  Acc@5: 87.5000 (82.2645)  time: 0.3528  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [ 890/4579]  eta: 0:39:52  Lr: 0.001875  Loss: 0.4052  Acc@1: 43.7500 (40.4882)  Acc@5: 87.5000 (82.3583)  time: 0.3524  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [ 900/4579]  eta: 0:39:34  Lr: 0.001875  Loss: 0.3323  Acc@1: 43.7500 (40.6077)  Acc@5: 87.5000 (82.3668)  time: 0.3490  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [ 910/4579]  eta: 0:39:16  Lr: 0.001875  Loss: 0.2346  Acc@1: 50.0000 (40.6765)  Acc@5: 87.5000 (82.4369)  time: 0.3514  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [ 920/4579]  eta: 0:38:58  Lr: 0.001875  Loss: 0.5805  Acc@1: 37.5000 (40.6555)  Acc@5: 87.5000 (82.4511)  time: 0.3543  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [ 930/4579]  eta: 0:38:40  Lr: 0.001875  Loss: 0.5653  Acc@1: 37.5000 (40.6619)  Acc@5: 87.5000 (82.5322)  time: 0.3515  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [ 940/4579]  eta: 0:38:22  Lr: 0.001875  Loss: -0.1462  Acc@1: 43.7500 (40.7678)  Acc@5: 87.5000 (82.5717)  time: 0.3488  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [ 950/4579]  eta: 0:38:05  Lr: 0.001875  Loss: 0.0100  Acc@1: 43.7500 (40.7466)  Acc@5: 87.5000 (82.5907)  time: 0.3481  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [ 960/4579]  eta: 0:37:48  Lr: 0.001875  Loss: 0.0752  Acc@1: 43.7500 (40.8299)  Acc@5: 87.5000 (82.6418)  time: 0.3486  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [ 970/4579]  eta: 0:37:32  Lr: 0.001875  Loss: 0.0947  Acc@1: 50.0000 (40.9372)  Acc@5: 87.5000 (82.6661)  time: 0.3484  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [ 980/4579]  eta: 0:37:15  Lr: 0.001875  Loss: 0.1762  Acc@1: 50.0000 (41.0487)  Acc@5: 87.5000 (82.7090)  time: 0.3486  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [ 990/4579]  eta: 0:36:59  Lr: 0.001875  Loss: 0.6494  Acc@1: 50.0000 (41.1201)  Acc@5: 87.5000 (82.7699)  time: 0.3493  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1000/4579]  eta: 0:36:43  Lr: 0.001875  Loss: -0.0548  Acc@1: 50.0000 (41.2338)  Acc@5: 87.5000 (82.8047)  time: 0.3493  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1010/4579]  eta: 0:36:28  Lr: 0.001875  Loss: 0.1364  Acc@1: 50.0000 (41.2957)  Acc@5: 87.5000 (82.8573)  time: 0.3491  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1020/4579]  eta: 0:36:13  Lr: 0.001875  Loss: 0.3448  Acc@1: 50.0000 (41.4545)  Acc@5: 87.5000 (82.8967)  time: 0.3487  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1030/4579]  eta: 0:35:57  Lr: 0.001875  Loss: 0.7815  Acc@1: 50.0000 (41.5192)  Acc@5: 87.5000 (82.9110)  time: 0.3488  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1040/4579]  eta: 0:35:43  Lr: 0.001875  Loss: 0.8376  Acc@1: 50.0000 (41.6547)  Acc@5: 87.5000 (82.9851)  time: 0.3504  data: 0.0012  max mem: 2500
Train: Epoch[1/5]  [1050/4579]  eta: 0:35:28  Lr: 0.001875  Loss: 0.1899  Acc@1: 50.0000 (41.7281)  Acc@5: 87.5000 (83.0459)  time: 0.3497  data: 0.0012  max mem: 2500
Train: Epoch[1/5]  [1060/4579]  eta: 0:35:13  Lr: 0.001875  Loss: -0.1066  Acc@1: 50.0000 (41.8179)  Acc@5: 87.5000 (83.0761)  time: 0.3482  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [1070/4579]  eta: 0:34:59  Lr: 0.001875  Loss: -0.0740  Acc@1: 50.0000 (41.8884)  Acc@5: 87.5000 (83.1116)  time: 0.3489  data: 0.0014  max mem: 2500
Train: Epoch[1/5]  [1080/4579]  eta: 0:34:45  Lr: 0.001875  Loss: 0.1261  Acc@1: 56.2500 (42.0155)  Acc@5: 87.5000 (83.1695)  time: 0.3494  data: 0.0017  max mem: 2500
Train: Epoch[1/5]  [1090/4579]  eta: 0:34:31  Lr: 0.001875  Loss: 0.1415  Acc@1: 56.2500 (42.1173)  Acc@5: 87.5000 (83.1978)  time: 0.3484  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [1100/4579]  eta: 0:34:18  Lr: 0.001875  Loss: 0.3944  Acc@1: 56.2500 (42.2173)  Acc@5: 87.5000 (83.2539)  time: 0.3486  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [1110/4579]  eta: 0:34:04  Lr: 0.001875  Loss: 0.0324  Acc@1: 56.2500 (42.3099)  Acc@5: 87.5000 (83.2696)  time: 0.3498  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [1120/4579]  eta: 0:33:51  Lr: 0.001875  Loss: 0.0682  Acc@1: 56.2500 (42.4008)  Acc@5: 87.5000 (83.3296)  time: 0.3503  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1130/4579]  eta: 0:33:38  Lr: 0.001875  Loss: 0.0667  Acc@1: 50.0000 (42.4127)  Acc@5: 87.5000 (83.3886)  time: 0.3525  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [1140/4579]  eta: 0:33:25  Lr: 0.001875  Loss: -0.0404  Acc@1: 43.7500 (42.4463)  Acc@5: 87.5000 (83.4411)  time: 0.3523  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [1150/4579]  eta: 0:33:12  Lr: 0.001875  Loss: 0.2544  Acc@1: 50.0000 (42.5011)  Acc@5: 87.5000 (83.4492)  time: 0.3524  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1160/4579]  eta: 0:33:00  Lr: 0.001875  Loss: -0.3896  Acc@1: 56.2500 (42.6464)  Acc@5: 87.5000 (83.5002)  time: 0.3552  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [1170/4579]  eta: 0:32:47  Lr: 0.001875  Loss: -0.0300  Acc@1: 56.2500 (42.6932)  Acc@5: 87.5000 (83.5184)  time: 0.3514  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1180/4579]  eta: 0:32:35  Lr: 0.001875  Loss: 0.5897  Acc@1: 50.0000 (42.7710)  Acc@5: 87.5000 (83.5468)  time: 0.3478  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1190/4579]  eta: 0:32:23  Lr: 0.001875  Loss: -0.0600  Acc@1: 43.7500 (42.7844)  Acc@5: 87.5000 (83.5695)  time: 0.3481  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [1200/4579]  eta: 0:32:11  Lr: 0.001875  Loss: 0.6618  Acc@1: 43.7500 (42.8653)  Acc@5: 87.5000 (83.5814)  time: 0.3480  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [1210/4579]  eta: 0:31:59  Lr: 0.001875  Loss: 0.0530  Acc@1: 56.2500 (42.9707)  Acc@5: 87.5000 (83.6654)  time: 0.3494  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [1220/4579]  eta: 0:31:47  Lr: 0.001875  Loss: 0.1781  Acc@1: 62.5000 (43.1153)  Acc@5: 93.7500 (83.7121)  time: 0.3510  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [1230/4579]  eta: 0:31:35  Lr: 0.001875  Loss: -0.1182  Acc@1: 62.5000 (43.2169)  Acc@5: 93.7500 (83.7683)  time: 0.3503  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [1240/4579]  eta: 0:31:24  Lr: 0.001875  Loss: 0.3082  Acc@1: 62.5000 (43.2867)  Acc@5: 93.7500 (83.8034)  time: 0.3510  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [1250/4579]  eta: 0:31:13  Lr: 0.001875  Loss: 0.2774  Acc@1: 50.0000 (43.3253)  Acc@5: 87.5000 (83.8379)  time: 0.3517  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [1260/4579]  eta: 0:31:02  Lr: 0.001875  Loss: 0.1679  Acc@1: 43.7500 (43.3386)  Acc@5: 87.5000 (83.8372)  time: 0.3524  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [1270/4579]  eta: 0:30:51  Lr: 0.001875  Loss: 0.2291  Acc@1: 50.0000 (43.4107)  Acc@5: 87.5000 (83.8808)  time: 0.3528  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [1280/4579]  eta: 0:30:40  Lr: 0.001875  Loss: 0.1256  Acc@1: 50.0000 (43.4670)  Acc@5: 87.5000 (83.9139)  time: 0.3500  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [1290/4579]  eta: 0:30:29  Lr: 0.001875  Loss: -0.1171  Acc@1: 50.0000 (43.5321)  Acc@5: 87.5000 (83.9417)  time: 0.3489  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [1300/4579]  eta: 0:30:18  Lr: 0.001875  Loss: -0.3246  Acc@1: 50.0000 (43.5674)  Acc@5: 87.5000 (83.9787)  time: 0.3523  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [1310/4579]  eta: 0:30:07  Lr: 0.001875  Loss: -0.0006  Acc@1: 56.2500 (43.6928)  Acc@5: 87.5000 (83.9912)  time: 0.3527  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [1320/4579]  eta: 0:29:57  Lr: 0.001875  Loss: -0.1289  Acc@1: 56.2500 (43.7737)  Acc@5: 87.5000 (84.0131)  time: 0.3526  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1330/4579]  eta: 0:29:47  Lr: 0.001875  Loss: -0.5075  Acc@1: 50.0000 (43.8580)  Acc@5: 87.5000 (84.0768)  time: 0.3527  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1340/4579]  eta: 0:29:36  Lr: 0.001875  Loss: 0.1556  Acc@1: 50.0000 (43.8991)  Acc@5: 93.7500 (84.1350)  time: 0.3508  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1350/4579]  eta: 0:29:26  Lr: 0.001875  Loss: 0.2432  Acc@1: 50.0000 (43.9258)  Acc@5: 87.5000 (84.1414)  time: 0.3497  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1360/4579]  eta: 0:29:16  Lr: 0.001875  Loss: 0.4213  Acc@1: 50.0000 (43.9980)  Acc@5: 87.5000 (84.1890)  time: 0.3498  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [1370/4579]  eta: 0:29:06  Lr: 0.001875  Loss: -0.1622  Acc@1: 50.0000 (44.0326)  Acc@5: 87.5000 (84.2268)  time: 0.3513  data: 0.0009  max mem: 2500
Train: Epoch[1/5]  [1380/4579]  eta: 0:28:56  Lr: 0.001875  Loss: -0.0930  Acc@1: 50.0000 (44.0985)  Acc@5: 93.7500 (84.2777)  time: 0.3485  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [1390/4579]  eta: 0:28:46  Lr: 0.001875  Loss: 0.2238  Acc@1: 50.0000 (44.1319)  Acc@5: 93.7500 (84.3323)  time: 0.3478  data: 0.0011  max mem: 2500
Train: Epoch[1/5]  [1400/4579]  eta: 0:28:36  Lr: 0.001875  Loss: 0.0483  Acc@1: 50.0000 (44.1872)  Acc@5: 87.5000 (84.3728)  time: 0.3497  data: 0.0011  max mem: 2500
Train: Epoch[1/5]  [1410/4579]  eta: 0:28:27  Lr: 0.001875  Loss: -0.0818  Acc@1: 50.0000 (44.2151)  Acc@5: 87.5000 (84.3816)  time: 0.3507  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [1420/4579]  eta: 0:28:17  Lr: 0.001875  Loss: 0.2059  Acc@1: 56.2500 (44.2998)  Acc@5: 87.5000 (84.4256)  time: 0.3500  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [1430/4579]  eta: 0:28:07  Lr: 0.001875  Loss: 0.2929  Acc@1: 50.0000 (44.3396)  Acc@5: 87.5000 (84.4471)  time: 0.3479  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1440/4579]  eta: 0:27:58  Lr: 0.001875  Loss: -0.1557  Acc@1: 50.0000 (44.4093)  Acc@5: 87.5000 (84.4769)  time: 0.3488  data: 0.0010  max mem: 2500
Train: Epoch[1/5]  [1450/4579]  eta: 0:27:49  Lr: 0.001875  Loss: -0.1508  Acc@1: 56.2500 (44.5038)  Acc@5: 87.5000 (84.5021)  time: 0.3501  data: 0.0011  max mem: 2500
Train: Epoch[1/5]  [1460/4579]  eta: 0:27:39  Lr: 0.001875  Loss: -0.0555  Acc@1: 56.2500 (44.5457)  Acc@5: 87.5000 (84.5140)  time: 0.3506  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [1470/4579]  eta: 0:27:30  Lr: 0.001875  Loss: -0.3468  Acc@1: 56.2500 (44.6465)  Acc@5: 87.5000 (84.5683)  time: 0.3522  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [1480/4579]  eta: 0:27:21  Lr: 0.001875  Loss: 0.0346  Acc@1: 56.2500 (44.7080)  Acc@5: 87.5000 (84.5881)  time: 0.3531  data: 0.0014  max mem: 2500
Train: Epoch[1/5]  [1490/4579]  eta: 0:27:12  Lr: 0.001875  Loss: -0.0012  Acc@1: 56.2500 (44.7351)  Acc@5: 87.5000 (84.6035)  time: 0.3519  data: 0.0012  max mem: 2500
Train: Epoch[1/5]  [1500/4579]  eta: 0:27:03  Lr: 0.001875  Loss: 0.1559  Acc@1: 50.0000 (44.7826)  Acc@5: 87.5000 (84.6186)  time: 0.3523  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1510/4579]  eta: 0:26:55  Lr: 0.001875  Loss: -0.1031  Acc@1: 50.0000 (44.8875)  Acc@5: 87.5000 (84.6583)  time: 0.3535  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1520/4579]  eta: 0:26:46  Lr: 0.001875  Loss: -0.0283  Acc@1: 56.2500 (44.9540)  Acc@5: 93.7500 (84.7099)  time: 0.3520  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1530/4579]  eta: 0:26:37  Lr: 0.001875  Loss: 0.1794  Acc@1: 50.0000 (44.9788)  Acc@5: 93.7500 (84.7404)  time: 0.3496  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1540/4579]  eta: 0:26:28  Lr: 0.001875  Loss: -0.2224  Acc@1: 50.0000 (45.0114)  Acc@5: 93.7500 (84.7745)  time: 0.3493  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [1550/4579]  eta: 0:26:20  Lr: 0.001875  Loss: -0.1868  Acc@1: 56.2500 (45.0919)  Acc@5: 87.5000 (84.8042)  time: 0.3492  data: 0.0009  max mem: 2500
Train: Epoch[1/5]  [1560/4579]  eta: 0:26:11  Lr: 0.001875  Loss: 0.1835  Acc@1: 56.2500 (45.1874)  Acc@5: 87.5000 (84.8455)  time: 0.3481  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [1570/4579]  eta: 0:26:03  Lr: 0.001875  Loss: 0.5348  Acc@1: 50.0000 (45.1822)  Acc@5: 87.5000 (84.8623)  time: 0.3504  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [1580/4579]  eta: 0:25:54  Lr: 0.001875  Loss: -0.2721  Acc@1: 50.0000 (45.2522)  Acc@5: 87.5000 (84.8830)  time: 0.3521  data: 0.0010  max mem: 2500
Train: Epoch[1/5]  [1590/4579]  eta: 0:25:46  Lr: 0.001875  Loss: -0.0474  Acc@1: 50.0000 (45.2624)  Acc@5: 87.5000 (84.8994)  time: 0.3492  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [1600/4579]  eta: 0:25:38  Lr: 0.001875  Loss: 0.0710  Acc@1: 50.0000 (45.3349)  Acc@5: 87.5000 (84.9196)  time: 0.3485  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1610/4579]  eta: 0:25:29  Lr: 0.001875  Loss: 0.4129  Acc@1: 56.2500 (45.4066)  Acc@5: 87.5000 (84.9317)  time: 0.3493  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [1620/4579]  eta: 0:25:21  Lr: 0.001875  Loss: 0.3495  Acc@1: 56.2500 (45.4465)  Acc@5: 87.5000 (84.9476)  time: 0.3485  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [1630/4579]  eta: 0:25:13  Lr: 0.001875  Loss: -0.0655  Acc@1: 56.2500 (45.5204)  Acc@5: 87.5000 (84.9862)  time: 0.3495  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1640/4579]  eta: 0:25:05  Lr: 0.001875  Loss: 0.0372  Acc@1: 56.2500 (45.5705)  Acc@5: 93.7500 (85.0244)  time: 0.3526  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [1650/4579]  eta: 0:24:57  Lr: 0.001875  Loss: -0.2845  Acc@1: 50.0000 (45.6163)  Acc@5: 93.7500 (85.0469)  time: 0.3535  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [1660/4579]  eta: 0:24:49  Lr: 0.001875  Loss: 0.2964  Acc@1: 50.0000 (45.6502)  Acc@5: 87.5000 (85.0880)  time: 0.3534  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [1670/4579]  eta: 0:24:41  Lr: 0.001875  Loss: -0.4106  Acc@1: 56.2500 (45.7361)  Acc@5: 87.5000 (85.1100)  time: 0.3513  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1680/4579]  eta: 0:24:33  Lr: 0.001875  Loss: 0.2866  Acc@1: 50.0000 (45.7391)  Acc@5: 87.5000 (85.1019)  time: 0.3479  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1690/4579]  eta: 0:24:26  Lr: 0.001875  Loss: -0.1672  Acc@1: 50.0000 (45.7976)  Acc@5: 87.5000 (85.1087)  time: 0.3495  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1700/4579]  eta: 0:24:18  Lr: 0.001875  Loss: 0.0936  Acc@1: 56.2500 (45.8811)  Acc@5: 87.5000 (85.1337)  time: 0.3527  data: 0.0011  max mem: 2500
Train: Epoch[1/5]  [1710/4579]  eta: 0:24:10  Lr: 0.001875  Loss: 0.7859  Acc@1: 50.0000 (45.8686)  Acc@5: 87.5000 (85.1293)  time: 0.3508  data: 0.0012  max mem: 2500
Train: Epoch[1/5]  [1720/4579]  eta: 0:24:03  Lr: 0.001875  Loss: -0.4101  Acc@1: 50.0000 (45.9399)  Acc@5: 87.5000 (85.1431)  time: 0.3489  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [1730/4579]  eta: 0:23:55  Lr: 0.001875  Loss: 0.0874  Acc@1: 56.2500 (46.0066)  Acc@5: 87.5000 (85.1567)  time: 0.3494  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [1740/4579]  eta: 0:23:47  Lr: 0.001875  Loss: 0.2290  Acc@1: 56.2500 (46.0511)  Acc@5: 87.5000 (85.1738)  time: 0.3486  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1750/4579]  eta: 0:23:40  Lr: 0.001875  Loss: 0.7007  Acc@1: 56.2500 (46.1379)  Acc@5: 87.5000 (85.2013)  time: 0.3484  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1760/4579]  eta: 0:23:32  Lr: 0.001875  Loss: 0.1092  Acc@1: 56.2500 (46.2202)  Acc@5: 93.7500 (85.2250)  time: 0.3486  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1770/4579]  eta: 0:23:25  Lr: 0.001875  Loss: -0.0648  Acc@1: 62.5000 (46.3015)  Acc@5: 93.7500 (85.2555)  time: 0.3496  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1780/4579]  eta: 0:23:18  Lr: 0.001875  Loss: -0.0899  Acc@1: 56.2500 (46.3574)  Acc@5: 93.7500 (85.2786)  time: 0.3500  data: 0.0010  max mem: 2500
Train: Epoch[1/5]  [1790/4579]  eta: 0:23:10  Lr: 0.001875  Loss: 0.2649  Acc@1: 56.2500 (46.4091)  Acc@5: 87.5000 (85.2806)  time: 0.3486  data: 0.0009  max mem: 2500
Train: Epoch[1/5]  [1800/4579]  eta: 0:23:03  Lr: 0.001875  Loss: 0.1944  Acc@1: 56.2500 (46.4534)  Acc@5: 87.5000 (85.3172)  time: 0.3476  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [1810/4579]  eta: 0:22:56  Lr: 0.001875  Loss: 0.4577  Acc@1: 56.2500 (46.4936)  Acc@5: 93.7500 (85.3292)  time: 0.3477  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [1820/4579]  eta: 0:22:49  Lr: 0.001875  Loss: -0.2835  Acc@1: 56.2500 (46.5301)  Acc@5: 87.5000 (85.3549)  time: 0.3487  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1830/4579]  eta: 0:22:41  Lr: 0.001875  Loss: -0.0820  Acc@1: 56.2500 (46.5866)  Acc@5: 87.5000 (85.3768)  time: 0.3504  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [1840/4579]  eta: 0:22:34  Lr: 0.001875  Loss: 0.1065  Acc@1: 56.2500 (46.6594)  Acc@5: 93.7500 (85.4223)  time: 0.3516  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [1850/4579]  eta: 0:22:27  Lr: 0.001875  Loss: 0.1718  Acc@1: 56.2500 (46.7079)  Acc@5: 93.7500 (85.4437)  time: 0.3512  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1860/4579]  eta: 0:22:20  Lr: 0.001875  Loss: 0.2095  Acc@1: 56.2500 (46.7558)  Acc@5: 87.5000 (85.4614)  time: 0.3514  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1870/4579]  eta: 0:22:13  Lr: 0.001875  Loss: -0.3279  Acc@1: 62.5000 (46.8499)  Acc@5: 93.7500 (85.4957)  time: 0.3552  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [1880/4579]  eta: 0:22:06  Lr: 0.001875  Loss: -0.2293  Acc@1: 56.2500 (46.8866)  Acc@5: 93.7500 (85.4964)  time: 0.3565  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [1890/4579]  eta: 0:22:00  Lr: 0.001875  Loss: -0.2446  Acc@1: 50.0000 (46.9461)  Acc@5: 87.5000 (85.5004)  time: 0.3529  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1900/4579]  eta: 0:21:53  Lr: 0.001875  Loss: 0.0876  Acc@1: 56.2500 (46.9950)  Acc@5: 87.5000 (85.4978)  time: 0.3511  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1910/4579]  eta: 0:21:46  Lr: 0.001875  Loss: 0.3319  Acc@1: 50.0000 (47.0075)  Acc@5: 87.5000 (85.5082)  time: 0.3496  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1920/4579]  eta: 0:21:39  Lr: 0.001875  Loss: 0.0123  Acc@1: 50.0000 (47.0458)  Acc@5: 87.5000 (85.5154)  time: 0.3516  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1930/4579]  eta: 0:21:32  Lr: 0.001875  Loss: -0.0437  Acc@1: 56.2500 (47.0935)  Acc@5: 87.5000 (85.5386)  time: 0.3533  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1940/4579]  eta: 0:21:25  Lr: 0.001875  Loss: 0.0648  Acc@1: 56.2500 (47.1503)  Acc@5: 87.5000 (85.5648)  time: 0.3501  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1950/4579]  eta: 0:21:19  Lr: 0.001875  Loss: 0.2872  Acc@1: 62.5000 (47.2034)  Acc@5: 87.5000 (85.5875)  time: 0.3488  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [1960/4579]  eta: 0:21:12  Lr: 0.001875  Loss: -0.0664  Acc@1: 56.2500 (47.2495)  Acc@5: 87.5000 (85.5973)  time: 0.3499  data: 0.0013  max mem: 2500
Train: Epoch[1/5]  [1970/4579]  eta: 0:21:05  Lr: 0.001875  Loss: 0.1857  Acc@1: 56.2500 (47.2888)  Acc@5: 87.5000 (85.6196)  time: 0.3522  data: 0.0016  max mem: 2500
Train: Epoch[1/5]  [1980/4579]  eta: 0:20:59  Lr: 0.001875  Loss: 0.3336  Acc@1: 56.2500 (47.3467)  Acc@5: 87.5000 (85.6291)  time: 0.3536  data: 0.0012  max mem: 2500
Train: Epoch[1/5]  [1990/4579]  eta: 0:20:52  Lr: 0.001875  Loss: -0.1622  Acc@1: 56.2500 (47.3788)  Acc@5: 87.5000 (85.6385)  time: 0.3509  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [2000/4579]  eta: 0:20:46  Lr: 0.001875  Loss: 0.0200  Acc@1: 56.2500 (47.4419)  Acc@5: 93.7500 (85.6634)  time: 0.3486  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2010/4579]  eta: 0:20:39  Lr: 0.001875  Loss: -0.1171  Acc@1: 56.2500 (47.4453)  Acc@5: 87.5000 (85.6819)  time: 0.3493  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2020/4579]  eta: 0:20:33  Lr: 0.001875  Loss: 0.6470  Acc@1: 50.0000 (47.4579)  Acc@5: 87.5000 (85.6971)  time: 0.3499  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [2030/4579]  eta: 0:20:26  Lr: 0.001875  Loss: 0.1075  Acc@1: 50.0000 (47.5074)  Acc@5: 87.5000 (85.7121)  time: 0.3491  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [2040/4579]  eta: 0:20:20  Lr: 0.001875  Loss: 0.4064  Acc@1: 56.2500 (47.5441)  Acc@5: 87.5000 (85.6963)  time: 0.3481  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [2050/4579]  eta: 0:20:13  Lr: 0.001875  Loss: -0.0205  Acc@1: 56.2500 (47.6109)  Acc@5: 87.5000 (85.7204)  time: 0.3492  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [2060/4579]  eta: 0:20:07  Lr: 0.001875  Loss: 0.2956  Acc@1: 56.2500 (47.6528)  Acc@5: 93.7500 (85.7563)  time: 0.3483  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [2070/4579]  eta: 0:20:00  Lr: 0.001875  Loss: -0.4650  Acc@1: 50.0000 (47.6823)  Acc@5: 93.7500 (85.7708)  time: 0.3480  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [2080/4579]  eta: 0:19:54  Lr: 0.001875  Loss: 0.2345  Acc@1: 56.2500 (47.7204)  Acc@5: 87.5000 (85.7941)  time: 0.3477  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2090/4579]  eta: 0:19:48  Lr: 0.001875  Loss: 0.3717  Acc@1: 56.2500 (47.7433)  Acc@5: 87.5000 (85.7903)  time: 0.3499  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2100/4579]  eta: 0:19:42  Lr: 0.001875  Loss: 0.3486  Acc@1: 56.2500 (47.7987)  Acc@5: 87.5000 (85.7925)  time: 0.3513  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [2110/4579]  eta: 0:19:35  Lr: 0.001875  Loss: 0.3825  Acc@1: 62.5000 (47.8565)  Acc@5: 87.5000 (85.8154)  time: 0.3499  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [2120/4579]  eta: 0:19:29  Lr: 0.001875  Loss: 0.0391  Acc@1: 56.2500 (47.8725)  Acc@5: 93.7500 (85.8469)  time: 0.3513  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2130/4579]  eta: 0:19:23  Lr: 0.001875  Loss: 0.0464  Acc@1: 50.0000 (47.9030)  Acc@5: 87.5000 (85.8488)  time: 0.3506  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2140/4579]  eta: 0:19:17  Lr: 0.001875  Loss: 0.4826  Acc@1: 56.2500 (47.9157)  Acc@5: 87.5000 (85.8623)  time: 0.3505  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2150/4579]  eta: 0:19:11  Lr: 0.001875  Loss: -0.0776  Acc@1: 56.2500 (47.9661)  Acc@5: 93.7500 (85.8845)  time: 0.3498  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [2160/4579]  eta: 0:19:04  Lr: 0.001875  Loss: 0.2845  Acc@1: 56.2500 (48.0275)  Acc@5: 87.5000 (85.9064)  time: 0.3482  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2170/4579]  eta: 0:18:58  Lr: 0.001875  Loss: -0.0403  Acc@1: 50.0000 (48.0424)  Acc@5: 87.5000 (85.9051)  time: 0.3480  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [2180/4579]  eta: 0:18:52  Lr: 0.001875  Loss: -0.0318  Acc@1: 50.0000 (48.0915)  Acc@5: 87.5000 (85.9182)  time: 0.3477  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [2190/4579]  eta: 0:18:46  Lr: 0.001875  Loss: -0.2658  Acc@1: 56.2500 (48.1344)  Acc@5: 87.5000 (85.9197)  time: 0.3491  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [2200/4579]  eta: 0:18:40  Lr: 0.001875  Loss: -0.3693  Acc@1: 56.2500 (48.1912)  Acc@5: 87.5000 (85.9467)  time: 0.3499  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [2210/4579]  eta: 0:18:34  Lr: 0.001875  Loss: 0.3658  Acc@1: 56.2500 (48.2107)  Acc@5: 87.5000 (85.9340)  time: 0.3499  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2220/4579]  eta: 0:18:28  Lr: 0.001875  Loss: 0.1513  Acc@1: 56.2500 (48.2440)  Acc@5: 81.2500 (85.9354)  time: 0.3534  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [2230/4579]  eta: 0:18:22  Lr: 0.001875  Loss: -0.2982  Acc@1: 56.2500 (48.2771)  Acc@5: 87.5000 (85.9564)  time: 0.3530  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [2240/4579]  eta: 0:18:16  Lr: 0.001875  Loss: 0.1413  Acc@1: 56.2500 (48.3015)  Acc@5: 87.5000 (85.9661)  time: 0.3477  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2250/4579]  eta: 0:18:10  Lr: 0.001875  Loss: -0.3829  Acc@1: 56.2500 (48.3480)  Acc@5: 87.5000 (85.9896)  time: 0.3476  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2260/4579]  eta: 0:18:04  Lr: 0.001875  Loss: 0.1703  Acc@1: 50.0000 (48.3553)  Acc@5: 87.5000 (86.0045)  time: 0.3500  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2270/4579]  eta: 0:17:59  Lr: 0.001875  Loss: 0.0277  Acc@1: 50.0000 (48.3790)  Acc@5: 87.5000 (86.0194)  time: 0.3524  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2280/4579]  eta: 0:17:53  Lr: 0.001875  Loss: 0.3845  Acc@1: 50.0000 (48.3916)  Acc@5: 87.5000 (86.0259)  time: 0.3504  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2290/4579]  eta: 0:17:47  Lr: 0.001875  Loss: 0.1980  Acc@1: 50.0000 (48.4123)  Acc@5: 87.5000 (86.0350)  time: 0.3484  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2300/4579]  eta: 0:17:41  Lr: 0.001875  Loss: -0.0211  Acc@1: 50.0000 (48.4327)  Acc@5: 87.5000 (86.0468)  time: 0.3490  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2310/4579]  eta: 0:17:35  Lr: 0.001875  Loss: -0.5455  Acc@1: 50.0000 (48.4531)  Acc@5: 93.7500 (86.0693)  time: 0.3499  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [2320/4579]  eta: 0:17:29  Lr: 0.001875  Loss: 0.4093  Acc@1: 50.0000 (48.4624)  Acc@5: 87.5000 (86.0674)  time: 0.3508  data: 0.0012  max mem: 2500
Train: Epoch[1/5]  [2330/4579]  eta: 0:17:24  Lr: 0.001875  Loss: 0.2116  Acc@1: 56.2500 (48.4905)  Acc@5: 87.5000 (86.0709)  time: 0.3493  data: 0.0016  max mem: 2500
Train: Epoch[1/5]  [2340/4579]  eta: 0:17:18  Lr: 0.001875  Loss: 0.0022  Acc@1: 56.2500 (48.5396)  Acc@5: 93.7500 (86.1037)  time: 0.3486  data: 0.0011  max mem: 2500
Train: Epoch[1/5]  [2350/4579]  eta: 0:17:12  Lr: 0.001875  Loss: -0.0584  Acc@1: 62.5000 (48.5777)  Acc@5: 93.7500 (86.1256)  time: 0.3499  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [2360/4579]  eta: 0:17:07  Lr: 0.001875  Loss: -0.0639  Acc@1: 56.2500 (48.6182)  Acc@5: 93.7500 (86.1499)  time: 0.3518  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [2370/4579]  eta: 0:17:01  Lr: 0.001875  Loss: 0.2368  Acc@1: 56.2500 (48.6583)  Acc@5: 87.5000 (86.1530)  time: 0.3502  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [2380/4579]  eta: 0:16:55  Lr: 0.001875  Loss: -0.5628  Acc@1: 62.5000 (48.7112)  Acc@5: 87.5000 (86.1692)  time: 0.3490  data: 0.0009  max mem: 2500
Train: Epoch[1/5]  [2390/4579]  eta: 0:16:50  Lr: 0.001875  Loss: 0.0173  Acc@1: 56.2500 (48.7322)  Acc@5: 87.5000 (86.1695)  time: 0.3497  data: 0.0010  max mem: 2500
Train: Epoch[1/5]  [2400/4579]  eta: 0:16:44  Lr: 0.001875  Loss: -0.4351  Acc@1: 56.2500 (48.8026)  Acc@5: 93.7500 (86.2115)  time: 0.3494  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [2410/4579]  eta: 0:16:38  Lr: 0.001875  Loss: 0.1326  Acc@1: 56.2500 (48.8257)  Acc@5: 93.7500 (86.2194)  time: 0.3485  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2420/4579]  eta: 0:16:33  Lr: 0.001875  Loss: -0.3431  Acc@1: 56.2500 (48.8589)  Acc@5: 87.5000 (86.2376)  time: 0.3484  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2430/4579]  eta: 0:16:27  Lr: 0.001875  Loss: 0.6592  Acc@1: 50.0000 (48.8508)  Acc@5: 87.5000 (86.2454)  time: 0.3497  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [2440/4579]  eta: 0:16:22  Lr: 0.001875  Loss: 0.1155  Acc@1: 50.0000 (48.8811)  Acc@5: 87.5000 (86.2505)  time: 0.3519  data: 0.0011  max mem: 2500
Train: Epoch[1/5]  [2450/4579]  eta: 0:16:16  Lr: 0.001875  Loss: -0.3443  Acc@1: 56.2500 (48.9443)  Acc@5: 93.7500 (86.2837)  time: 0.3553  data: 0.0010  max mem: 2500
Train: Epoch[1/5]  [2460/4579]  eta: 0:16:11  Lr: 0.001875  Loss: 0.1248  Acc@1: 62.5000 (48.9486)  Acc@5: 93.7500 (86.2835)  time: 0.3528  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [2470/4579]  eta: 0:16:05  Lr: 0.001875  Loss: -0.3774  Acc@1: 56.2500 (48.9731)  Acc@5: 87.5000 (86.2758)  time: 0.3508  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [2480/4579]  eta: 0:16:00  Lr: 0.001875  Loss: -0.2669  Acc@1: 56.2500 (49.0075)  Acc@5: 87.5000 (86.2782)  time: 0.3547  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [2490/4579]  eta: 0:15:54  Lr: 0.001875  Loss: -0.2677  Acc@1: 62.5000 (49.0641)  Acc@5: 93.7500 (86.3107)  time: 0.3532  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2500/4579]  eta: 0:15:49  Lr: 0.001875  Loss: 0.0337  Acc@1: 62.5000 (49.1054)  Acc@5: 93.7500 (86.3255)  time: 0.3504  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2510/4579]  eta: 0:15:43  Lr: 0.001875  Loss: 0.0037  Acc@1: 62.5000 (49.1413)  Acc@5: 93.7500 (86.3451)  time: 0.3533  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [2520/4579]  eta: 0:15:38  Lr: 0.001875  Loss: -0.2548  Acc@1: 62.5000 (49.1868)  Acc@5: 93.7500 (86.3720)  time: 0.3534  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [2530/4579]  eta: 0:15:33  Lr: 0.001875  Loss: -0.3909  Acc@1: 62.5000 (49.2493)  Acc@5: 93.7500 (86.3962)  time: 0.3526  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [2540/4579]  eta: 0:15:27  Lr: 0.001875  Loss: 0.2079  Acc@1: 56.2500 (49.2793)  Acc@5: 93.7500 (86.4177)  time: 0.3518  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [2550/4579]  eta: 0:15:22  Lr: 0.001875  Loss: -0.2552  Acc@1: 56.2500 (49.3066)  Acc@5: 93.7500 (86.4318)  time: 0.3499  data: 0.0009  max mem: 2500
Train: Epoch[1/5]  [2560/4579]  eta: 0:15:16  Lr: 0.001875  Loss: 0.7400  Acc@1: 56.2500 (49.3435)  Acc@5: 87.5000 (86.4384)  time: 0.3502  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [2570/4579]  eta: 0:15:11  Lr: 0.001875  Loss: -0.2533  Acc@1: 56.2500 (49.3607)  Acc@5: 93.7500 (86.4474)  time: 0.3509  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [2580/4579]  eta: 0:15:06  Lr: 0.001875  Loss: -0.1558  Acc@1: 56.2500 (49.3849)  Acc@5: 87.5000 (86.4563)  time: 0.3506  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [2590/4579]  eta: 0:15:00  Lr: 0.001875  Loss: 0.2424  Acc@1: 56.2500 (49.3970)  Acc@5: 81.2500 (86.4435)  time: 0.3484  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [2600/4579]  eta: 0:14:55  Lr: 0.001875  Loss: -0.3040  Acc@1: 56.2500 (49.4089)  Acc@5: 87.5000 (86.4691)  time: 0.3491  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [2610/4579]  eta: 0:14:50  Lr: 0.001875  Loss: -0.0105  Acc@1: 50.0000 (49.4255)  Acc@5: 93.7500 (86.4755)  time: 0.3518  data: 0.0009  max mem: 2500
Train: Epoch[1/5]  [2620/4579]  eta: 0:14:45  Lr: 0.001875  Loss: -0.1933  Acc@1: 56.2500 (49.4563)  Acc@5: 93.7500 (86.4937)  time: 0.3533  data: 0.0011  max mem: 2500
Train: Epoch[1/5]  [2630/4579]  eta: 0:14:39  Lr: 0.001875  Loss: -0.0267  Acc@1: 56.2500 (49.4869)  Acc@5: 93.7500 (86.5023)  time: 0.3518  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [2640/4579]  eta: 0:14:34  Lr: 0.001875  Loss: 0.4535  Acc@1: 56.2500 (49.5149)  Acc@5: 87.5000 (86.5155)  time: 0.3500  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2650/4579]  eta: 0:14:29  Lr: 0.001875  Loss: -0.1875  Acc@1: 56.2500 (49.5285)  Acc@5: 93.7500 (86.5381)  time: 0.3504  data: 0.0012  max mem: 2500
Train: Epoch[1/5]  [2660/4579]  eta: 0:14:23  Lr: 0.001875  Loss: -0.5183  Acc@1: 56.2500 (49.5678)  Acc@5: 93.7500 (86.5535)  time: 0.3493  data: 0.0014  max mem: 2500
Train: Epoch[1/5]  [2670/4579]  eta: 0:14:18  Lr: 0.001875  Loss: -0.2507  Acc@1: 56.2500 (49.5835)  Acc@5: 87.5000 (86.5640)  time: 0.3493  data: 0.0010  max mem: 2500
Train: Epoch[1/5]  [2680/4579]  eta: 0:14:13  Lr: 0.001875  Loss: -0.3414  Acc@1: 56.2500 (49.6107)  Acc@5: 87.5000 (86.5815)  time: 0.3519  data: 0.0011  max mem: 2500
Train: Epoch[1/5]  [2690/4579]  eta: 0:14:08  Lr: 0.001875  Loss: 0.8878  Acc@1: 50.0000 (49.6028)  Acc@5: 87.5000 (86.5803)  time: 0.3515  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [2700/4579]  eta: 0:14:03  Lr: 0.001875  Loss: -0.1882  Acc@1: 50.0000 (49.6298)  Acc@5: 87.5000 (86.5883)  time: 0.3528  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [2710/4579]  eta: 0:13:58  Lr: 0.001875  Loss: 0.2912  Acc@1: 56.2500 (49.6519)  Acc@5: 87.5000 (86.5778)  time: 0.3524  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [2720/4579]  eta: 0:13:52  Lr: 0.001875  Loss: 0.0031  Acc@1: 56.2500 (49.6922)  Acc@5: 87.5000 (86.5858)  time: 0.3500  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [2730/4579]  eta: 0:13:47  Lr: 0.001875  Loss: 0.2567  Acc@1: 56.2500 (49.7071)  Acc@5: 87.5000 (86.5754)  time: 0.3526  data: 0.0011  max mem: 2500
Train: Epoch[1/5]  [2740/4579]  eta: 0:13:42  Lr: 0.001875  Loss: 0.2080  Acc@1: 43.7500 (49.7173)  Acc@5: 87.5000 (86.5765)  time: 0.3541  data: 0.0012  max mem: 2500
Train: Epoch[1/5]  [2750/4579]  eta: 0:13:37  Lr: 0.001875  Loss: -0.0536  Acc@1: 50.0000 (49.7342)  Acc@5: 87.5000 (86.5799)  time: 0.3532  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [2760/4579]  eta: 0:13:32  Lr: 0.001875  Loss: -0.0690  Acc@1: 56.2500 (49.7510)  Acc@5: 93.7500 (86.6058)  time: 0.3516  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2770/4579]  eta: 0:13:27  Lr: 0.001875  Loss: 0.2941  Acc@1: 56.2500 (49.7632)  Acc@5: 87.5000 (86.5955)  time: 0.3507  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2780/4579]  eta: 0:13:22  Lr: 0.001875  Loss: 0.0183  Acc@1: 56.2500 (49.7955)  Acc@5: 87.5000 (86.6055)  time: 0.3527  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [2790/4579]  eta: 0:13:17  Lr: 0.001875  Loss: -0.0001  Acc@1: 50.0000 (49.7985)  Acc@5: 87.5000 (86.6087)  time: 0.3528  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [2800/4579]  eta: 0:13:12  Lr: 0.001875  Loss: -0.1134  Acc@1: 50.0000 (49.8215)  Acc@5: 81.2500 (86.6030)  time: 0.3503  data: 0.0013  max mem: 2500
Train: Epoch[1/5]  [2810/4579]  eta: 0:13:07  Lr: 0.001875  Loss: -0.1568  Acc@1: 56.2500 (49.8466)  Acc@5: 87.5000 (86.6218)  time: 0.3501  data: 0.0015  max mem: 2500
Train: Epoch[1/5]  [2820/4579]  eta: 0:13:02  Lr: 0.001875  Loss: -0.2128  Acc@1: 62.5000 (49.8892)  Acc@5: 93.7500 (86.6337)  time: 0.3499  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [2830/4579]  eta: 0:12:57  Lr: 0.001875  Loss: -0.1699  Acc@1: 62.5000 (49.9007)  Acc@5: 87.5000 (86.6390)  time: 0.3486  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2840/4579]  eta: 0:12:52  Lr: 0.001875  Loss: -0.1101  Acc@1: 62.5000 (49.9472)  Acc@5: 93.7500 (86.6508)  time: 0.3494  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [2850/4579]  eta: 0:12:47  Lr: 0.001875  Loss: -0.1901  Acc@1: 62.5000 (49.9978)  Acc@5: 93.7500 (86.6692)  time: 0.3510  data: 0.0010  max mem: 2500
Train: Epoch[1/5]  [2860/4579]  eta: 0:12:42  Lr: 0.001875  Loss: -0.3721  Acc@1: 56.2500 (50.0328)  Acc@5: 93.7500 (86.6808)  time: 0.3506  data: 0.0010  max mem: 2500
Train: Epoch[1/5]  [2870/4579]  eta: 0:12:37  Lr: 0.001875  Loss: 0.2983  Acc@1: 56.2500 (50.0610)  Acc@5: 93.7500 (86.6902)  time: 0.3513  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [2880/4579]  eta: 0:12:32  Lr: 0.001875  Loss: -0.5029  Acc@1: 50.0000 (50.0781)  Acc@5: 87.5000 (86.6865)  time: 0.3521  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [2890/4579]  eta: 0:12:27  Lr: 0.001875  Loss: -0.6319  Acc@1: 56.2500 (50.1232)  Acc@5: 93.7500 (86.7088)  time: 0.3513  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2900/4579]  eta: 0:12:22  Lr: 0.001875  Loss: -0.0729  Acc@1: 62.5000 (50.1724)  Acc@5: 87.5000 (86.7072)  time: 0.3524  data: 0.0009  max mem: 2500
Train: Epoch[1/5]  [2910/4579]  eta: 0:12:17  Lr: 0.001875  Loss: 0.0284  Acc@1: 56.2500 (50.1911)  Acc@5: 87.5000 (86.7099)  time: 0.3531  data: 0.0009  max mem: 2500
Train: Epoch[1/5]  [2920/4579]  eta: 0:12:12  Lr: 0.001875  Loss: -0.0546  Acc@1: 56.2500 (50.2075)  Acc@5: 87.5000 (86.7126)  time: 0.3503  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2930/4579]  eta: 0:12:07  Lr: 0.001875  Loss: 0.3548  Acc@1: 56.2500 (50.2239)  Acc@5: 87.5000 (86.7195)  time: 0.3480  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2940/4579]  eta: 0:12:02  Lr: 0.001875  Loss: -0.2461  Acc@1: 56.2500 (50.2423)  Acc@5: 87.5000 (86.7371)  time: 0.3493  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [2950/4579]  eta: 0:11:57  Lr: 0.001875  Loss: -0.1852  Acc@1: 56.2500 (50.2838)  Acc@5: 87.5000 (86.7333)  time: 0.3522  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [2960/4579]  eta: 0:11:52  Lr: 0.001875  Loss: 0.0151  Acc@1: 62.5000 (50.3187)  Acc@5: 87.5000 (86.7443)  time: 0.3514  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [2970/4579]  eta: 0:11:47  Lr: 0.001875  Loss: -0.1949  Acc@1: 62.5000 (50.3597)  Acc@5: 93.7500 (86.7553)  time: 0.3490  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [2980/4579]  eta: 0:11:42  Lr: 0.001875  Loss: 0.4024  Acc@1: 56.2500 (50.3732)  Acc@5: 93.7500 (86.7767)  time: 0.3492  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [2990/4579]  eta: 0:11:38  Lr: 0.001875  Loss: -0.3891  Acc@1: 62.5000 (50.4096)  Acc@5: 93.7500 (86.7916)  time: 0.3512  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [3000/4579]  eta: 0:11:33  Lr: 0.001875  Loss: 0.0315  Acc@1: 62.5000 (50.4269)  Acc@5: 87.5000 (86.7898)  time: 0.3517  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [3010/4579]  eta: 0:11:28  Lr: 0.001875  Loss: -0.1078  Acc@1: 56.2500 (50.4525)  Acc@5: 87.5000 (86.8026)  time: 0.3499  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [3020/4579]  eta: 0:11:23  Lr: 0.001875  Loss: -0.3982  Acc@1: 62.5000 (50.4779)  Acc@5: 87.5000 (86.8028)  time: 0.3518  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3030/4579]  eta: 0:11:18  Lr: 0.001875  Loss: -0.0163  Acc@1: 56.2500 (50.4990)  Acc@5: 87.5000 (86.8092)  time: 0.3507  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3040/4579]  eta: 0:11:13  Lr: 0.001875  Loss: -0.3107  Acc@1: 56.2500 (50.5220)  Acc@5: 87.5000 (86.8197)  time: 0.3482  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [3050/4579]  eta: 0:11:09  Lr: 0.001875  Loss: -0.2813  Acc@1: 56.2500 (50.5510)  Acc@5: 93.7500 (86.8301)  time: 0.3496  data: 0.0009  max mem: 2500
Train: Epoch[1/5]  [3060/4579]  eta: 0:11:04  Lr: 0.001875  Loss: 0.4603  Acc@1: 62.5000 (50.5901)  Acc@5: 93.7500 (86.8466)  time: 0.3526  data: 0.0012  max mem: 2500
Train: Epoch[1/5]  [3070/4579]  eta: 0:10:59  Lr: 0.001875  Loss: 0.2311  Acc@1: 56.2500 (50.6044)  Acc@5: 93.7500 (86.8589)  time: 0.3552  data: 0.0010  max mem: 2500
Train: Epoch[1/5]  [3080/4579]  eta: 0:10:54  Lr: 0.001875  Loss: 0.0715  Acc@1: 50.0000 (50.6126)  Acc@5: 87.5000 (86.8610)  time: 0.3532  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [3090/4579]  eta: 0:10:49  Lr: 0.001875  Loss: -0.5138  Acc@1: 50.0000 (50.6430)  Acc@5: 87.5000 (86.8651)  time: 0.3507  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [3100/4579]  eta: 0:10:45  Lr: 0.001875  Loss: -0.4423  Acc@1: 62.5000 (50.6712)  Acc@5: 93.7500 (86.8812)  time: 0.3493  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [3110/4579]  eta: 0:10:40  Lr: 0.001875  Loss: 0.4068  Acc@1: 56.2500 (50.6891)  Acc@5: 87.5000 (86.8772)  time: 0.3517  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [3120/4579]  eta: 0:10:35  Lr: 0.001875  Loss: -0.4681  Acc@1: 56.2500 (50.7249)  Acc@5: 87.5000 (86.9012)  time: 0.3524  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [3130/4579]  eta: 0:10:30  Lr: 0.001875  Loss: -0.0568  Acc@1: 56.2500 (50.7346)  Acc@5: 93.7500 (86.9111)  time: 0.3499  data: 0.0009  max mem: 2500
Train: Epoch[1/5]  [3140/4579]  eta: 0:10:26  Lr: 0.001875  Loss: -0.1711  Acc@1: 50.0000 (50.7183)  Acc@5: 87.5000 (86.9050)  time: 0.3507  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [3150/4579]  eta: 0:10:21  Lr: 0.001875  Loss: 0.3644  Acc@1: 43.7500 (50.7220)  Acc@5: 87.5000 (86.9109)  time: 0.3499  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [3160/4579]  eta: 0:10:16  Lr: 0.001875  Loss: 0.0396  Acc@1: 56.2500 (50.7474)  Acc@5: 93.7500 (86.9286)  time: 0.3483  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [3170/4579]  eta: 0:10:11  Lr: 0.001875  Loss: 0.2308  Acc@1: 56.2500 (50.7608)  Acc@5: 87.5000 (86.9186)  time: 0.3487  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [3180/4579]  eta: 0:10:07  Lr: 0.001875  Loss: -0.3962  Acc@1: 56.2500 (50.7781)  Acc@5: 87.5000 (86.9302)  time: 0.3495  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [3190/4579]  eta: 0:10:02  Lr: 0.001875  Loss: 0.3346  Acc@1: 56.2500 (50.7991)  Acc@5: 87.5000 (86.9379)  time: 0.3482  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [3200/4579]  eta: 0:09:57  Lr: 0.001875  Loss: -0.3669  Acc@1: 56.2500 (50.8005)  Acc@5: 87.5000 (86.9416)  time: 0.3473  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [3210/4579]  eta: 0:09:53  Lr: 0.001875  Loss: -0.0300  Acc@1: 56.2500 (50.8409)  Acc@5: 87.5000 (86.9492)  time: 0.3481  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [3220/4579]  eta: 0:09:48  Lr: 0.001875  Loss: -0.2966  Acc@1: 62.5000 (50.8887)  Acc@5: 87.5000 (86.9489)  time: 0.3494  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [3230/4579]  eta: 0:09:43  Lr: 0.001875  Loss: -0.1636  Acc@1: 62.5000 (50.9285)  Acc@5: 87.5000 (86.9661)  time: 0.3526  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [3240/4579]  eta: 0:09:39  Lr: 0.001875  Loss: -0.2171  Acc@1: 62.5000 (50.9681)  Acc@5: 93.7500 (86.9948)  time: 0.3517  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [3250/4579]  eta: 0:09:34  Lr: 0.001875  Loss: 0.1703  Acc@1: 62.5000 (51.0266)  Acc@5: 100.0000 (87.0155)  time: 0.3489  data: 0.0010  max mem: 2500
Train: Epoch[1/5]  [3260/4579]  eta: 0:09:29  Lr: 0.001875  Loss: -0.0451  Acc@1: 56.2500 (51.0541)  Acc@5: 93.7500 (87.0266)  time: 0.3485  data: 0.0010  max mem: 2500
Train: Epoch[1/5]  [3270/4579]  eta: 0:09:25  Lr: 0.001875  Loss: -0.2176  Acc@1: 56.2500 (51.0700)  Acc@5: 93.7500 (87.0414)  time: 0.3489  data: 0.0009  max mem: 2500
Train: Epoch[1/5]  [3280/4579]  eta: 0:09:20  Lr: 0.001875  Loss: 0.2102  Acc@1: 56.2500 (51.0915)  Acc@5: 93.7500 (87.0504)  time: 0.3494  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [3290/4579]  eta: 0:09:15  Lr: 0.001875  Loss: -0.4295  Acc@1: 56.2500 (51.1072)  Acc@5: 87.5000 (87.0518)  time: 0.3507  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [3300/4579]  eta: 0:09:11  Lr: 0.001875  Loss: 0.3018  Acc@1: 56.2500 (51.1322)  Acc@5: 87.5000 (87.0645)  time: 0.3532  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [3310/4579]  eta: 0:09:06  Lr: 0.001875  Loss: -0.2432  Acc@1: 56.2500 (51.1571)  Acc@5: 93.7500 (87.0828)  time: 0.3534  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [3320/4579]  eta: 0:09:01  Lr: 0.001875  Loss: -0.0844  Acc@1: 56.2500 (51.1819)  Acc@5: 93.7500 (87.0879)  time: 0.3523  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [3330/4579]  eta: 0:08:57  Lr: 0.001875  Loss: -0.6928  Acc@1: 62.5000 (51.2234)  Acc@5: 93.7500 (87.1060)  time: 0.3522  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [3340/4579]  eta: 0:08:52  Lr: 0.001875  Loss: -0.2897  Acc@1: 62.5000 (51.2403)  Acc@5: 87.5000 (87.1146)  time: 0.3507  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [3350/4579]  eta: 0:08:48  Lr: 0.001875  Loss: -0.3084  Acc@1: 56.2500 (51.2645)  Acc@5: 87.5000 (87.1121)  time: 0.3498  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [3360/4579]  eta: 0:08:43  Lr: 0.001875  Loss: -0.5016  Acc@1: 56.2500 (51.2905)  Acc@5: 87.5000 (87.1244)  time: 0.3496  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [3370/4579]  eta: 0:08:39  Lr: 0.001875  Loss: 0.0071  Acc@1: 56.2500 (51.3164)  Acc@5: 87.5000 (87.1255)  time: 0.3488  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [3380/4579]  eta: 0:08:34  Lr: 0.001875  Loss: -0.1241  Acc@1: 56.2500 (51.3310)  Acc@5: 87.5000 (87.1358)  time: 0.3490  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [3390/4579]  eta: 0:08:29  Lr: 0.001875  Loss: -0.5622  Acc@1: 56.2500 (51.3547)  Acc@5: 87.5000 (87.1369)  time: 0.3498  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [3400/4579]  eta: 0:08:25  Lr: 0.001875  Loss: 0.4090  Acc@1: 56.2500 (51.3654)  Acc@5: 87.5000 (87.1527)  time: 0.3504  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [3410/4579]  eta: 0:08:20  Lr: 0.001875  Loss: -0.2072  Acc@1: 56.2500 (51.3797)  Acc@5: 87.5000 (87.1574)  time: 0.3504  data: 0.0009  max mem: 2500
Train: Epoch[1/5]  [3420/4579]  eta: 0:08:16  Lr: 0.001875  Loss: -0.2508  Acc@1: 62.5000 (51.4141)  Acc@5: 87.5000 (87.1657)  time: 0.3510  data: 0.0012  max mem: 2500
Train: Epoch[1/5]  [3430/4579]  eta: 0:08:11  Lr: 0.001875  Loss: -0.5982  Acc@1: 62.5000 (51.4373)  Acc@5: 93.7500 (87.1849)  time: 0.3514  data: 0.0009  max mem: 2500
Train: Epoch[1/5]  [3440/4579]  eta: 0:08:07  Lr: 0.001875  Loss: -0.2395  Acc@1: 56.2500 (51.4440)  Acc@5: 93.7500 (87.1858)  time: 0.3521  data: 0.0011  max mem: 2500
Train: Epoch[1/5]  [3450/4579]  eta: 0:08:02  Lr: 0.001875  Loss: 0.1510  Acc@1: 56.2500 (51.4633)  Acc@5: 87.5000 (87.1939)  time: 0.3539  data: 0.0011  max mem: 2500
Train: Epoch[1/5]  [3460/4579]  eta: 0:07:58  Lr: 0.001875  Loss: -0.3457  Acc@1: 56.2500 (51.4609)  Acc@5: 87.5000 (87.1966)  time: 0.3538  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [3470/4579]  eta: 0:07:53  Lr: 0.001875  Loss: 0.2872  Acc@1: 56.2500 (51.4837)  Acc@5: 87.5000 (87.2101)  time: 0.3517  data: 0.0012  max mem: 2500
Train: Epoch[1/5]  [3480/4579]  eta: 0:07:49  Lr: 0.001875  Loss: 0.1334  Acc@1: 50.0000 (51.4741)  Acc@5: 87.5000 (87.2073)  time: 0.3512  data: 0.0011  max mem: 2500
Train: Epoch[1/5]  [3490/4579]  eta: 0:07:44  Lr: 0.001875  Loss: -0.3575  Acc@1: 50.0000 (51.4949)  Acc@5: 87.5000 (87.2135)  time: 0.3516  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [3500/4579]  eta: 0:07:40  Lr: 0.001875  Loss: 0.0984  Acc@1: 56.2500 (51.5085)  Acc@5: 87.5000 (87.2197)  time: 0.3521  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [3510/4579]  eta: 0:07:35  Lr: 0.001875  Loss: -0.0357  Acc@1: 50.0000 (51.5202)  Acc@5: 87.5000 (87.2259)  time: 0.3506  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3520/4579]  eta: 0:07:31  Lr: 0.001875  Loss: 0.0356  Acc@1: 56.2500 (51.5443)  Acc@5: 87.5000 (87.2373)  time: 0.3497  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [3530/4579]  eta: 0:07:26  Lr: 0.001875  Loss: 0.0163  Acc@1: 56.2500 (51.5576)  Acc@5: 87.5000 (87.2433)  time: 0.3517  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [3540/4579]  eta: 0:07:22  Lr: 0.001875  Loss: -0.3588  Acc@1: 56.2500 (51.5779)  Acc@5: 93.7500 (87.2511)  time: 0.3524  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [3550/4579]  eta: 0:07:17  Lr: 0.001875  Loss: 0.4177  Acc@1: 62.5000 (51.6034)  Acc@5: 93.7500 (87.2606)  time: 0.3514  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [3560/4579]  eta: 0:07:13  Lr: 0.001875  Loss: -0.0061  Acc@1: 56.2500 (51.6200)  Acc@5: 87.5000 (87.2666)  time: 0.3496  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [3570/4579]  eta: 0:07:08  Lr: 0.001875  Loss: 0.6736  Acc@1: 56.2500 (51.6382)  Acc@5: 87.5000 (87.2620)  time: 0.3501  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [3580/4579]  eta: 0:07:04  Lr: 0.001875  Loss: -0.4111  Acc@1: 56.2500 (51.6633)  Acc@5: 87.5000 (87.2696)  time: 0.3537  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [3590/4579]  eta: 0:06:59  Lr: 0.001875  Loss: -0.4685  Acc@1: 56.2500 (51.6726)  Acc@5: 93.7500 (87.2772)  time: 0.3560  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [3600/4579]  eta: 0:06:55  Lr: 0.001875  Loss: -0.0592  Acc@1: 56.2500 (51.6974)  Acc@5: 87.5000 (87.2865)  time: 0.3534  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [3610/4579]  eta: 0:06:50  Lr: 0.001875  Loss: -0.2270  Acc@1: 56.2500 (51.7291)  Acc@5: 87.5000 (87.3010)  time: 0.3516  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [3620/4579]  eta: 0:06:46  Lr: 0.001875  Loss: 0.3888  Acc@1: 56.2500 (51.7295)  Acc@5: 93.7500 (87.3067)  time: 0.3537  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3630/4579]  eta: 0:06:42  Lr: 0.001875  Loss: 0.0148  Acc@1: 56.2500 (51.7471)  Acc@5: 93.7500 (87.3193)  time: 0.3542  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [3640/4579]  eta: 0:06:37  Lr: 0.001875  Loss: -0.0763  Acc@1: 62.5000 (51.7698)  Acc@5: 93.7500 (87.3318)  time: 0.3518  data: 0.0011  max mem: 2500
Train: Epoch[1/5]  [3650/4579]  eta: 0:06:33  Lr: 0.001875  Loss: -0.2083  Acc@1: 62.5000 (51.7957)  Acc@5: 93.7500 (87.3442)  time: 0.3507  data: 0.0016  max mem: 2500
Train: Epoch[1/5]  [3660/4579]  eta: 0:06:28  Lr: 0.001875  Loss: -0.2381  Acc@1: 62.5000 (51.8233)  Acc@5: 93.7500 (87.3634)  time: 0.3498  data: 0.0010  max mem: 2500
Train: Epoch[1/5]  [3670/4579]  eta: 0:06:24  Lr: 0.001875  Loss: 0.8737  Acc@1: 68.7500 (51.8472)  Acc@5: 93.7500 (87.3706)  time: 0.3492  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [3680/4579]  eta: 0:06:20  Lr: 0.001875  Loss: -0.2950  Acc@1: 62.5000 (51.8762)  Acc@5: 93.7500 (87.3862)  time: 0.3486  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [3690/4579]  eta: 0:06:15  Lr: 0.001875  Loss: -0.3306  Acc@1: 62.5000 (51.8948)  Acc@5: 93.7500 (87.3984)  time: 0.3487  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [3700/4579]  eta: 0:06:11  Lr: 0.001875  Loss: 0.1696  Acc@1: 56.2500 (51.9032)  Acc@5: 87.5000 (87.4088)  time: 0.3500  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [3710/4579]  eta: 0:06:06  Lr: 0.001875  Loss: -0.0147  Acc@1: 50.0000 (51.9149)  Acc@5: 87.5000 (87.4175)  time: 0.3505  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [3720/4579]  eta: 0:06:02  Lr: 0.001875  Loss: -0.2267  Acc@1: 50.0000 (51.9148)  Acc@5: 93.7500 (87.4261)  time: 0.3507  data: 0.0013  max mem: 2500
Train: Epoch[1/5]  [3730/4579]  eta: 0:05:58  Lr: 0.001875  Loss: 0.2006  Acc@1: 56.2500 (51.9315)  Acc@5: 93.7500 (87.4347)  time: 0.3492  data: 0.0013  max mem: 2500
Train: Epoch[1/5]  [3740/4579]  eta: 0:05:53  Lr: 0.001875  Loss: -0.1470  Acc@1: 62.5000 (51.9564)  Acc@5: 93.7500 (87.4432)  time: 0.3479  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [3750/4579]  eta: 0:05:49  Lr: 0.001875  Loss: 0.2717  Acc@1: 56.2500 (51.9545)  Acc@5: 87.5000 (87.4483)  time: 0.3497  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [3760/4579]  eta: 0:05:44  Lr: 0.001875  Loss: -0.1059  Acc@1: 56.2500 (51.9725)  Acc@5: 87.5000 (87.4601)  time: 0.3509  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [3770/4579]  eta: 0:05:40  Lr: 0.001875  Loss: -0.2403  Acc@1: 62.5000 (51.9889)  Acc@5: 87.5000 (87.4586)  time: 0.3510  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [3780/4579]  eta: 0:05:36  Lr: 0.001875  Loss: -0.1161  Acc@1: 62.5000 (52.0101)  Acc@5: 93.7500 (87.4736)  time: 0.3547  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [3790/4579]  eta: 0:05:31  Lr: 0.001875  Loss: -0.0856  Acc@1: 62.5000 (52.0377)  Acc@5: 93.7500 (87.4885)  time: 0.3542  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [3800/4579]  eta: 0:05:27  Lr: 0.001875  Loss: -0.2381  Acc@1: 62.5000 (52.0603)  Acc@5: 93.7500 (87.4951)  time: 0.3522  data: 0.0013  max mem: 2500
Train: Epoch[1/5]  [3810/4579]  eta: 0:05:23  Lr: 0.001875  Loss: 0.4472  Acc@1: 56.2500 (52.0762)  Acc@5: 87.5000 (87.4934)  time: 0.3533  data: 0.0014  max mem: 2500
Train: Epoch[1/5]  [3820/4579]  eta: 0:05:18  Lr: 0.001875  Loss: -0.3520  Acc@1: 56.2500 (52.0806)  Acc@5: 87.5000 (87.5033)  time: 0.3507  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [3830/4579]  eta: 0:05:14  Lr: 0.001875  Loss: 0.0462  Acc@1: 56.2500 (52.0931)  Acc@5: 93.7500 (87.5163)  time: 0.3506  data: 0.0010  max mem: 2500
Train: Epoch[1/5]  [3840/4579]  eta: 0:05:10  Lr: 0.001875  Loss: -0.3450  Acc@1: 56.2500 (52.1218)  Acc@5: 93.7500 (87.5244)  time: 0.3514  data: 0.0010  max mem: 2500
Train: Epoch[1/5]  [3850/4579]  eta: 0:05:05  Lr: 0.001875  Loss: 0.5966  Acc@1: 62.5000 (52.1342)  Acc@5: 87.5000 (87.5308)  time: 0.3503  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [3860/4579]  eta: 0:05:01  Lr: 0.001875  Loss: -0.4606  Acc@1: 56.2500 (52.1594)  Acc@5: 87.5000 (87.5308)  time: 0.3509  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [3870/4579]  eta: 0:04:57  Lr: 0.001875  Loss: -0.1361  Acc@1: 62.5000 (52.1700)  Acc@5: 87.5000 (87.5371)  time: 0.3494  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [3880/4579]  eta: 0:04:52  Lr: 0.001875  Loss: -0.2043  Acc@1: 56.2500 (52.1885)  Acc@5: 87.5000 (87.5386)  time: 0.3484  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [3890/4579]  eta: 0:04:48  Lr: 0.001875  Loss: -0.1166  Acc@1: 56.2500 (52.1926)  Acc@5: 87.5000 (87.5369)  time: 0.3510  data: 0.0009  max mem: 2500
Train: Epoch[1/5]  [3900/4579]  eta: 0:04:44  Lr: 0.001875  Loss: -0.2806  Acc@1: 62.5000 (52.2158)  Acc@5: 93.7500 (87.5449)  time: 0.3507  data: 0.0009  max mem: 2500
Train: Epoch[1/5]  [3910/4579]  eta: 0:04:39  Lr: 0.001875  Loss: -0.1991  Acc@1: 62.5000 (52.2261)  Acc@5: 93.7500 (87.5543)  time: 0.3493  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [3920/4579]  eta: 0:04:35  Lr: 0.001875  Loss: -0.0961  Acc@1: 50.0000 (52.2284)  Acc@5: 87.5000 (87.5478)  time: 0.3502  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [3930/4579]  eta: 0:04:31  Lr: 0.001875  Loss: 0.1307  Acc@1: 56.2500 (52.2370)  Acc@5: 87.5000 (87.5445)  time: 0.3522  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [3940/4579]  eta: 0:04:27  Lr: 0.001875  Loss: -0.1067  Acc@1: 56.2500 (52.2583)  Acc@5: 93.7500 (87.5650)  time: 0.3541  data: 0.0009  max mem: 2500
Train: Epoch[1/5]  [3950/4579]  eta: 0:04:22  Lr: 0.001875  Loss: -0.7175  Acc@1: 56.2500 (52.2573)  Acc@5: 93.7500 (87.5617)  time: 0.3534  data: 0.0009  max mem: 2500
Train: Epoch[1/5]  [3960/4579]  eta: 0:04:18  Lr: 0.001875  Loss: -0.2550  Acc@1: 56.2500 (52.2911)  Acc@5: 93.7500 (87.5805)  time: 0.3516  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [3970/4579]  eta: 0:04:14  Lr: 0.001875  Loss: 0.0130  Acc@1: 62.5000 (52.3136)  Acc@5: 93.7500 (87.5897)  time: 0.3511  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [3980/4579]  eta: 0:04:09  Lr: 0.001875  Loss: 0.3225  Acc@1: 62.5000 (52.3502)  Acc@5: 93.7500 (87.6020)  time: 0.3508  data: 0.0013  max mem: 2500
Train: Epoch[1/5]  [3990/4579]  eta: 0:04:05  Lr: 0.001875  Loss: 0.0937  Acc@1: 62.5000 (52.3553)  Acc@5: 93.7500 (87.6096)  time: 0.3505  data: 0.0014  max mem: 2500
Train: Epoch[1/5]  [4000/4579]  eta: 0:04:01  Lr: 0.001875  Loss: -0.0773  Acc@1: 56.2500 (52.3744)  Acc@5: 87.5000 (87.6156)  time: 0.3505  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [4010/4579]  eta: 0:03:57  Lr: 0.001875  Loss: 0.2490  Acc@1: 56.2500 (52.3950)  Acc@5: 87.5000 (87.6169)  time: 0.3501  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [4020/4579]  eta: 0:03:52  Lr: 0.001875  Loss: -0.4745  Acc@1: 56.2500 (52.4186)  Acc@5: 87.5000 (87.6321)  time: 0.3505  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [4030/4579]  eta: 0:03:48  Lr: 0.001875  Loss: -0.2870  Acc@1: 56.2500 (52.4358)  Acc@5: 93.7500 (87.6318)  time: 0.3529  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [4040/4579]  eta: 0:03:44  Lr: 0.001875  Loss: 0.3799  Acc@1: 56.2500 (52.4592)  Acc@5: 87.5000 (87.6346)  time: 0.3523  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [4050/4579]  eta: 0:03:40  Lr: 0.001875  Loss: 0.2374  Acc@1: 56.2500 (52.4732)  Acc@5: 87.5000 (87.6373)  time: 0.3499  data: 0.0016  max mem: 2500
Train: Epoch[1/5]  [4060/4579]  eta: 0:03:35  Lr: 0.001875  Loss: 0.4957  Acc@1: 56.2500 (52.4809)  Acc@5: 87.5000 (87.6385)  time: 0.3492  data: 0.0014  max mem: 2500
Train: Epoch[1/5]  [4070/4579]  eta: 0:03:31  Lr: 0.001875  Loss: -0.2163  Acc@1: 62.5000 (52.5040)  Acc@5: 87.5000 (87.6443)  time: 0.3489  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [4080/4579]  eta: 0:03:27  Lr: 0.001875  Loss: 0.4829  Acc@1: 62.5000 (52.5070)  Acc@5: 87.5000 (87.6470)  time: 0.3489  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [4090/4579]  eta: 0:03:23  Lr: 0.001875  Loss: -0.1412  Acc@1: 56.2500 (52.5177)  Acc@5: 93.7500 (87.6528)  time: 0.3490  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [4100/4579]  eta: 0:03:18  Lr: 0.001875  Loss: -0.2130  Acc@1: 56.2500 (52.5421)  Acc@5: 93.7500 (87.6676)  time: 0.3489  data: 0.0014  max mem: 2500
Train: Epoch[1/5]  [4110/4579]  eta: 0:03:14  Lr: 0.001875  Loss: 0.0720  Acc@1: 62.5000 (52.5617)  Acc@5: 93.7500 (87.6672)  time: 0.3489  data: 0.0020  max mem: 2500
Train: Epoch[1/5]  [4120/4579]  eta: 0:03:10  Lr: 0.001875  Loss: -0.2192  Acc@1: 56.2500 (52.5692)  Acc@5: 87.5000 (87.6729)  time: 0.3492  data: 0.0014  max mem: 2500
Train: Epoch[1/5]  [4130/4579]  eta: 0:03:06  Lr: 0.001875  Loss: -0.4234  Acc@1: 56.2500 (52.5977)  Acc@5: 87.5000 (87.6800)  time: 0.3492  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [4140/4579]  eta: 0:03:02  Lr: 0.001875  Loss: -0.3695  Acc@1: 62.5000 (52.6201)  Acc@5: 87.5000 (87.6902)  time: 0.3489  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [4150/4579]  eta: 0:02:57  Lr: 0.001875  Loss: 0.3562  Acc@1: 62.5000 (52.6439)  Acc@5: 93.7500 (87.7018)  time: 0.3476  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [4160/4579]  eta: 0:02:53  Lr: 0.001875  Loss: -0.3223  Acc@1: 62.5000 (52.6631)  Acc@5: 87.5000 (87.6968)  time: 0.3468  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [4170/4579]  eta: 0:02:49  Lr: 0.001875  Loss: 0.0572  Acc@1: 56.2500 (52.6747)  Acc@5: 87.5000 (87.7008)  time: 0.3473  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [4180/4579]  eta: 0:02:45  Lr: 0.001875  Loss: 0.1025  Acc@1: 56.2500 (52.6878)  Acc@5: 87.5000 (87.7108)  time: 0.3481  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [4190/4579]  eta: 0:02:41  Lr: 0.001875  Loss: 0.1838  Acc@1: 56.2500 (52.7022)  Acc@5: 93.7500 (87.7162)  time: 0.3481  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [4200/4579]  eta: 0:02:36  Lr: 0.001875  Loss: 0.1171  Acc@1: 56.2500 (52.7002)  Acc@5: 87.5000 (87.7157)  time: 0.3482  data: 0.0009  max mem: 2500
Train: Epoch[1/5]  [4210/4579]  eta: 0:02:32  Lr: 0.001875  Loss: 1.2589  Acc@1: 56.2500 (52.7191)  Acc@5: 87.5000 (87.7137)  time: 0.3498  data: 0.0013  max mem: 2500
Train: Epoch[1/5]  [4220/4579]  eta: 0:02:28  Lr: 0.001875  Loss: -0.1994  Acc@1: 62.5000 (52.7408)  Acc@5: 87.5000 (87.7162)  time: 0.3524  data: 0.0010  max mem: 2500
Train: Epoch[1/5]  [4230/4579]  eta: 0:02:24  Lr: 0.001875  Loss: -0.1318  Acc@1: 62.5000 (52.7520)  Acc@5: 87.5000 (87.7142)  time: 0.3533  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [4240/4579]  eta: 0:02:20  Lr: 0.001875  Loss: 0.2492  Acc@1: 62.5000 (52.7706)  Acc@5: 87.5000 (87.7152)  time: 0.3515  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [4250/4579]  eta: 0:02:15  Lr: 0.001875  Loss: 0.1273  Acc@1: 62.5000 (52.7758)  Acc@5: 87.5000 (87.7176)  time: 0.3514  data: 0.0009  max mem: 2500
Train: Epoch[1/5]  [4260/4579]  eta: 0:02:11  Lr: 0.001875  Loss: -0.3628  Acc@1: 62.5000 (52.8045)  Acc@5: 87.5000 (87.7215)  time: 0.3510  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [4270/4579]  eta: 0:02:07  Lr: 0.001875  Loss: -0.7291  Acc@1: 62.5000 (52.8272)  Acc@5: 93.7500 (87.7312)  time: 0.3499  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [4280/4579]  eta: 0:02:03  Lr: 0.001875  Loss: -0.3576  Acc@1: 62.5000 (52.8542)  Acc@5: 93.7500 (87.7438)  time: 0.3491  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [4290/4579]  eta: 0:01:59  Lr: 0.001875  Loss: -0.1220  Acc@1: 62.5000 (52.8723)  Acc@5: 93.7500 (87.7622)  time: 0.3492  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [4300/4579]  eta: 0:01:55  Lr: 0.001875  Loss: -0.7133  Acc@1: 62.5000 (52.9005)  Acc@5: 93.7500 (87.7703)  time: 0.3500  data: 0.0010  max mem: 2500
Train: Epoch[1/5]  [4310/4579]  eta: 0:01:50  Lr: 0.001875  Loss: -0.3391  Acc@1: 56.2500 (52.9097)  Acc@5: 87.5000 (87.7769)  time: 0.3492  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [4320/4579]  eta: 0:01:46  Lr: 0.001875  Loss: 0.3181  Acc@1: 62.5000 (52.9420)  Acc@5: 87.5000 (87.7792)  time: 0.3514  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [4330/4579]  eta: 0:01:42  Lr: 0.001875  Loss: -0.0181  Acc@1: 62.5000 (52.9684)  Acc@5: 87.5000 (87.7901)  time: 0.3522  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [4340/4579]  eta: 0:01:38  Lr: 0.001875  Loss: -0.5763  Acc@1: 62.5000 (52.9817)  Acc@5: 93.7500 (87.7952)  time: 0.3502  data: 0.0020  max mem: 2500
Train: Epoch[1/5]  [4350/4579]  eta: 0:01:34  Lr: 0.001875  Loss: 0.1571  Acc@1: 62.5000 (53.0051)  Acc@5: 93.7500 (87.8045)  time: 0.3519  data: 0.0019  max mem: 2500
Train: Epoch[1/5]  [4360/4579]  eta: 0:01:30  Lr: 0.001875  Loss: 0.2680  Acc@1: 62.5000 (53.0297)  Acc@5: 93.7500 (87.8110)  time: 0.3531  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [4370/4579]  eta: 0:01:25  Lr: 0.001875  Loss: -0.2028  Acc@1: 62.5000 (53.0399)  Acc@5: 87.5000 (87.8174)  time: 0.3506  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [4380/4579]  eta: 0:01:21  Lr: 0.001875  Loss: -0.3255  Acc@1: 56.2500 (53.0415)  Acc@5: 87.5000 (87.8153)  time: 0.3486  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [4390/4579]  eta: 0:01:17  Lr: 0.001875  Loss: -0.6952  Acc@1: 56.2500 (53.0560)  Acc@5: 93.7500 (87.8274)  time: 0.3485  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [4400/4579]  eta: 0:01:13  Lr: 0.001875  Loss: -0.0239  Acc@1: 62.5000 (53.0760)  Acc@5: 87.5000 (87.8309)  time: 0.3486  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [4410/4579]  eta: 0:01:09  Lr: 0.001875  Loss: 0.0098  Acc@1: 62.5000 (53.0945)  Acc@5: 87.5000 (87.8429)  time: 0.3499  data: 0.0009  max mem: 2500
Train: Epoch[1/5]  [4420/4579]  eta: 0:01:05  Lr: 0.001875  Loss: -0.0211  Acc@1: 62.5000 (53.1271)  Acc@5: 93.7500 (87.8520)  time: 0.3529  data: 0.0010  max mem: 2500
Train: Epoch[1/5]  [4430/4579]  eta: 0:01:01  Lr: 0.001875  Loss: 0.2015  Acc@1: 62.5000 (53.1342)  Acc@5: 93.7500 (87.8597)  time: 0.3538  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [4440/4579]  eta: 0:00:57  Lr: 0.001875  Loss: -0.2407  Acc@1: 56.2500 (53.1651)  Acc@5: 93.7500 (87.8673)  time: 0.3522  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [4450/4579]  eta: 0:00:52  Lr: 0.001875  Loss: 0.1931  Acc@1: 68.7500 (53.1903)  Acc@5: 93.7500 (87.8805)  time: 0.3515  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [4460/4579]  eta: 0:00:48  Lr: 0.001875  Loss: -0.2718  Acc@1: 56.2500 (53.1972)  Acc@5: 87.5000 (87.8755)  time: 0.3518  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [4470/4579]  eta: 0:00:44  Lr: 0.001875  Loss: -0.5226  Acc@1: 50.0000 (53.1970)  Acc@5: 87.5000 (87.8872)  time: 0.3500  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [4480/4579]  eta: 0:00:40  Lr: 0.001875  Loss: -0.4281  Acc@1: 56.2500 (53.2247)  Acc@5: 93.7500 (87.9017)  time: 0.3488  data: 0.0012  max mem: 2500
Train: Epoch[1/5]  [4490/4579]  eta: 0:00:36  Lr: 0.001875  Loss: -0.3254  Acc@1: 68.7500 (53.2342)  Acc@5: 93.7500 (87.9064)  time: 0.3532  data: 0.0022  max mem: 2500
Train: Epoch[1/5]  [4500/4579]  eta: 0:00:32  Lr: 0.001875  Loss: -0.0274  Acc@1: 62.5000 (53.2590)  Acc@5: 93.7500 (87.9138)  time: 0.3530  data: 0.0014  max mem: 2500
Train: Epoch[1/5]  [4510/4579]  eta: 0:00:28  Lr: 0.001875  Loss: -0.0661  Acc@1: 62.5000 (53.2739)  Acc@5: 93.7500 (87.9184)  time: 0.3492  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [4520/4579]  eta: 0:00:24  Lr: 0.001875  Loss: 0.1042  Acc@1: 62.5000 (53.2971)  Acc@5: 93.7500 (87.9258)  time: 0.3485  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [4530/4579]  eta: 0:00:20  Lr: 0.001875  Loss: 0.5370  Acc@1: 56.2500 (53.2995)  Acc@5: 93.7500 (87.9345)  time: 0.3497  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [4540/4579]  eta: 0:00:15  Lr: 0.001875  Loss: 0.0875  Acc@1: 56.2500 (53.3142)  Acc@5: 87.5000 (87.9377)  time: 0.3516  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [4550/4579]  eta: 0:00:11  Lr: 0.001875  Loss: -0.3691  Acc@1: 62.5000 (53.3399)  Acc@5: 87.5000 (87.9408)  time: 0.3514  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [4560/4579]  eta: 0:00:07  Lr: 0.001875  Loss: -0.3503  Acc@1: 62.5000 (53.3532)  Acc@5: 87.5000 (87.9440)  time: 0.3526  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [4570/4579]  eta: 0:00:03  Lr: 0.001875  Loss: 0.1477  Acc@1: 62.5000 (53.3773)  Acc@5: 93.7500 (87.9553)  time: 0.3537  data: 0.0012  max mem: 2500
Train: Epoch[1/5]  [4578/4579]  eta: 0:00:00  Lr: 0.001875  Loss: 0.9238  Acc@1: 56.2500 (53.3751)  Acc@5: 87.5000 (87.9547)  time: 0.3503  data: 0.0011  max mem: 2500
Train: Epoch[1/5] Total time: 0:31:11 (0.4088 s / it)
{0: {0: 73257, 1: 0, 2: 0, 3: 0, 4: 0}, 1: {0: 73257, 1: 0, 2: 0, 3: 0, 4: 0}, 2: {0: 73257, 1: 0, 2: 0, 3: 0, 4: 0}, 3: {0: 73257, 1: 0, 2: 0, 3: 0, 4: 0}, 4: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 5: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 6: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 7: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 8: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 9: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 10: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 11: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 12: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 13: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 14: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 15: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 16: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 17: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 18: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 19: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}}
Averaged stats: Lr: 0.001875  Loss: 0.9238  Acc@1: 56.2500 (53.3751)  Acc@5: 87.5000 (87.9547)
Train: Epoch[2/5]  [   0/4579]  eta: 1:03:14  Lr: 0.001875  Loss: -0.3061  Acc@1: 56.2500 (56.2500)  Acc@5: 93.7500 (93.7500)  time: 0.8287  data: 0.4612  max mem: 2500
Train: Epoch[2/5]  [  10/4579]  eta: 0:29:59  Lr: 0.001875  Loss: -0.3515  Acc@1: 62.5000 (63.0682)  Acc@5: 93.7500 (91.4773)  time: 0.3938  data: 0.0424  max mem: 2500
Train: Epoch[2/5]  [  20/4579]  eta: 0:28:14  Lr: 0.001875  Loss: -0.4993  Acc@1: 62.5000 (65.1786)  Acc@5: 93.7500 (90.7738)  time: 0.3487  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [  30/4579]  eta: 0:27:47  Lr: 0.001875  Loss: 0.5603  Acc@1: 62.5000 (62.2984)  Acc@5: 93.7500 (90.7258)  time: 0.3517  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [  40/4579]  eta: 0:27:25  Lr: 0.001875  Loss: 0.4992  Acc@1: 56.2500 (61.2805)  Acc@5: 93.7500 (90.0915)  time: 0.3530  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [  50/4579]  eta: 0:27:16  Lr: 0.001875  Loss: -0.1855  Acc@1: 56.2500 (61.3971)  Acc@5: 87.5000 (89.9510)  time: 0.3533  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [  60/4579]  eta: 0:27:05  Lr: 0.001875  Loss: -0.2384  Acc@1: 62.5000 (61.4754)  Acc@5: 87.5000 (90.2664)  time: 0.3542  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [  70/4579]  eta: 0:26:55  Lr: 0.001875  Loss: -0.2858  Acc@1: 62.5000 (61.3556)  Acc@5: 93.7500 (89.9648)  time: 0.3504  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [  80/4579]  eta: 0:26:49  Lr: 0.001875  Loss: 0.7211  Acc@1: 62.5000 (60.8025)  Acc@5: 87.5000 (89.6605)  time: 0.3514  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [  90/4579]  eta: 0:26:43  Lr: 0.001875  Loss: 0.0148  Acc@1: 62.5000 (61.1951)  Acc@5: 87.5000 (89.8352)  time: 0.3535  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [ 100/4579]  eta: 0:26:36  Lr: 0.001875  Loss: -0.2594  Acc@1: 62.5000 (61.3243)  Acc@5: 93.7500 (89.7277)  time: 0.3512  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [ 110/4579]  eta: 0:26:31  Lr: 0.001875  Loss: -0.1405  Acc@1: 62.5000 (60.9234)  Acc@5: 87.5000 (89.7523)  time: 0.3511  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [ 120/4579]  eta: 0:26:25  Lr: 0.001875  Loss: 0.5423  Acc@1: 56.2500 (60.6405)  Acc@5: 87.5000 (89.5661)  time: 0.3516  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [ 130/4579]  eta: 0:26:20  Lr: 0.001875  Loss: -0.0631  Acc@1: 56.2500 (60.4008)  Acc@5: 87.5000 (89.4561)  time: 0.3500  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [ 140/4579]  eta: 0:26:14  Lr: 0.001875  Loss: -0.3151  Acc@1: 56.2500 (60.0621)  Acc@5: 87.5000 (89.3174)  time: 0.3495  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [ 150/4579]  eta: 0:26:10  Lr: 0.001875  Loss: -0.2380  Acc@1: 56.2500 (59.8096)  Acc@5: 93.7500 (89.5695)  time: 0.3499  data: 0.0014  max mem: 2500
Train: Epoch[2/5]  [ 160/4579]  eta: 0:26:05  Lr: 0.001875  Loss: 0.0047  Acc@1: 50.0000 (59.5885)  Acc@5: 93.7500 (89.7904)  time: 0.3500  data: 0.0013  max mem: 2500
Train: Epoch[2/5]  [ 170/4579]  eta: 0:26:00  Lr: 0.001875  Loss: -0.0246  Acc@1: 56.2500 (59.3567)  Acc@5: 93.7500 (89.7661)  time: 0.3488  data: 0.0012  max mem: 2500
Train: Epoch[2/5]  [ 180/4579]  eta: 0:25:55  Lr: 0.001875  Loss: 0.3986  Acc@1: 62.5000 (59.4959)  Acc@5: 93.7500 (89.9862)  time: 0.3481  data: 0.0011  max mem: 2500
Train: Epoch[2/5]  [ 190/4579]  eta: 0:25:50  Lr: 0.001875  Loss: -0.1752  Acc@1: 62.5000 (59.5550)  Acc@5: 87.5000 (89.7579)  time: 0.3492  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [ 200/4579]  eta: 0:25:46  Lr: 0.001875  Loss: -0.2129  Acc@1: 62.5000 (59.5771)  Acc@5: 87.5000 (89.8010)  time: 0.3512  data: 0.0011  max mem: 2500
Train: Epoch[2/5]  [ 210/4579]  eta: 0:25:42  Lr: 0.001875  Loss: -0.0073  Acc@1: 62.5000 (59.8934)  Acc@5: 87.5000 (89.7216)  time: 0.3497  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [ 220/4579]  eta: 0:25:38  Lr: 0.001875  Loss: 0.0982  Acc@1: 62.5000 (60.0113)  Acc@5: 87.5000 (89.6210)  time: 0.3495  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [ 230/4579]  eta: 0:25:34  Lr: 0.001875  Loss: -0.1851  Acc@1: 62.5000 (60.3084)  Acc@5: 93.7500 (89.8810)  time: 0.3507  data: 0.0009  max mem: 2500
Train: Epoch[2/5]  [ 240/4579]  eta: 0:25:30  Lr: 0.001875  Loss: -0.4827  Acc@1: 68.7500 (60.6587)  Acc@5: 93.7500 (89.8859)  time: 0.3493  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [ 250/4579]  eta: 0:25:25  Lr: 0.001875  Loss: 0.2104  Acc@1: 62.5000 (60.5827)  Acc@5: 93.7500 (89.8904)  time: 0.3488  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [ 260/4579]  eta: 0:25:21  Lr: 0.001875  Loss: -0.3046  Acc@1: 62.5000 (60.7280)  Acc@5: 93.7500 (90.0623)  time: 0.3485  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [ 270/4579]  eta: 0:25:17  Lr: 0.001875  Loss: -0.2691  Acc@1: 62.5000 (60.7011)  Acc@5: 93.7500 (90.1522)  time: 0.3492  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 280/4579]  eta: 0:25:14  Lr: 0.001875  Loss: -0.0285  Acc@1: 62.5000 (60.8096)  Acc@5: 93.7500 (90.1690)  time: 0.3516  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [ 290/4579]  eta: 0:25:10  Lr: 0.001875  Loss: 0.0276  Acc@1: 62.5000 (60.8892)  Acc@5: 93.7500 (90.1203)  time: 0.3528  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [ 300/4579]  eta: 0:25:07  Lr: 0.001875  Loss: -0.1985  Acc@1: 62.5000 (61.0257)  Acc@5: 93.7500 (90.1370)  time: 0.3513  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [ 310/4579]  eta: 0:25:02  Lr: 0.001875  Loss: 0.0020  Acc@1: 68.7500 (61.2138)  Acc@5: 93.7500 (90.1527)  time: 0.3491  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [ 320/4579]  eta: 0:24:59  Lr: 0.001875  Loss: -0.0978  Acc@1: 62.5000 (61.0592)  Acc@5: 93.7500 (90.2453)  time: 0.3506  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 330/4579]  eta: 0:24:55  Lr: 0.001875  Loss: -0.1844  Acc@1: 62.5000 (61.0838)  Acc@5: 93.7500 (90.1813)  time: 0.3496  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 340/4579]  eta: 0:24:51  Lr: 0.001875  Loss: -0.0022  Acc@1: 62.5000 (61.0337)  Acc@5: 87.5000 (90.1760)  time: 0.3485  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [ 350/4579]  eta: 0:24:48  Lr: 0.001875  Loss: -0.1027  Acc@1: 56.2500 (61.0399)  Acc@5: 93.7500 (90.2778)  time: 0.3520  data: 0.0014  max mem: 2500
Train: Epoch[2/5]  [ 360/4579]  eta: 0:24:44  Lr: 0.001875  Loss: 0.3039  Acc@1: 56.2500 (61.0111)  Acc@5: 93.7500 (90.3047)  time: 0.3519  data: 0.0019  max mem: 2500
Train: Epoch[2/5]  [ 370/4579]  eta: 0:24:40  Lr: 0.001875  Loss: 0.2488  Acc@1: 62.5000 (61.0849)  Acc@5: 93.7500 (90.3133)  time: 0.3503  data: 0.0011  max mem: 2500
Train: Epoch[2/5]  [ 380/4579]  eta: 0:24:37  Lr: 0.001875  Loss: 0.1427  Acc@1: 62.5000 (61.0728)  Acc@5: 93.7500 (90.3215)  time: 0.3523  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [ 390/4579]  eta: 0:24:33  Lr: 0.001875  Loss: 0.2248  Acc@1: 56.2500 (60.9974)  Acc@5: 87.5000 (90.2334)  time: 0.3523  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [ 400/4579]  eta: 0:24:29  Lr: 0.001875  Loss: -0.7456  Acc@1: 62.5000 (61.1284)  Acc@5: 87.5000 (90.3055)  time: 0.3487  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [ 410/4579]  eta: 0:24:26  Lr: 0.001875  Loss: -0.3456  Acc@1: 68.7500 (61.1922)  Acc@5: 93.7500 (90.3437)  time: 0.3494  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [ 420/4579]  eta: 0:24:23  Lr: 0.001875  Loss: -0.0791  Acc@1: 62.5000 (61.1787)  Acc@5: 87.5000 (90.2316)  time: 0.3529  data: 0.0012  max mem: 2500
Train: Epoch[2/5]  [ 430/4579]  eta: 0:24:19  Lr: 0.001875  Loss: 0.0121  Acc@1: 62.5000 (61.1369)  Acc@5: 87.5000 (90.2697)  time: 0.3524  data: 0.0012  max mem: 2500
Train: Epoch[2/5]  [ 440/4579]  eta: 0:24:15  Lr: 0.001875  Loss: -0.2805  Acc@1: 62.5000 (61.1961)  Acc@5: 93.7500 (90.2920)  time: 0.3492  data: 0.0009  max mem: 2500
Train: Epoch[2/5]  [ 450/4579]  eta: 0:24:12  Lr: 0.001875  Loss: -0.0604  Acc@1: 62.5000 (61.1142)  Acc@5: 87.5000 (90.1746)  time: 0.3497  data: 0.0009  max mem: 2500
Train: Epoch[2/5]  [ 460/4579]  eta: 0:24:08  Lr: 0.001875  Loss: -0.4317  Acc@1: 62.5000 (61.1714)  Acc@5: 93.7500 (90.2386)  time: 0.3504  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [ 470/4579]  eta: 0:24:04  Lr: 0.001875  Loss: 0.5751  Acc@1: 62.5000 (61.1730)  Acc@5: 93.7500 (90.2335)  time: 0.3509  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [ 480/4579]  eta: 0:24:01  Lr: 0.001875  Loss: -0.6892  Acc@1: 62.5000 (61.2136)  Acc@5: 93.7500 (90.2417)  time: 0.3539  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [ 490/4579]  eta: 0:23:58  Lr: 0.001875  Loss: -0.1959  Acc@1: 62.5000 (61.2907)  Acc@5: 87.5000 (90.2622)  time: 0.3525  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [ 500/4579]  eta: 0:23:54  Lr: 0.001875  Loss: -0.2958  Acc@1: 62.5000 (61.2026)  Acc@5: 87.5000 (90.2944)  time: 0.3502  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [ 510/4579]  eta: 0:23:51  Lr: 0.001875  Loss: 0.1110  Acc@1: 56.2500 (61.1424)  Acc@5: 93.7500 (90.3131)  time: 0.3533  data: 0.0014  max mem: 2500
Train: Epoch[2/5]  [ 520/4579]  eta: 0:23:47  Lr: 0.001875  Loss: 0.4270  Acc@1: 62.5000 (61.1684)  Acc@5: 87.5000 (90.2591)  time: 0.3526  data: 0.0013  max mem: 2500
Train: Epoch[2/5]  [ 530/4579]  eta: 0:23:43  Lr: 0.001875  Loss: 0.2403  Acc@1: 62.5000 (61.1347)  Acc@5: 87.5000 (90.1483)  time: 0.3500  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [ 540/4579]  eta: 0:23:40  Lr: 0.001875  Loss: -0.2316  Acc@1: 62.5000 (61.1252)  Acc@5: 87.5000 (90.1571)  time: 0.3502  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [ 550/4579]  eta: 0:23:36  Lr: 0.001875  Loss: -0.4103  Acc@1: 62.5000 (61.2069)  Acc@5: 93.7500 (90.1996)  time: 0.3489  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [ 560/4579]  eta: 0:23:32  Lr: 0.001875  Loss: 0.1995  Acc@1: 56.2500 (61.1074)  Acc@5: 93.7500 (90.1627)  time: 0.3478  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [ 570/4579]  eta: 0:23:28  Lr: 0.001875  Loss: -0.1762  Acc@1: 62.5000 (61.1756)  Acc@5: 93.7500 (90.2145)  time: 0.3480  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [ 580/4579]  eta: 0:23:25  Lr: 0.001875  Loss: 0.1420  Acc@1: 62.5000 (61.1876)  Acc@5: 93.7500 (90.2108)  time: 0.3483  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [ 590/4579]  eta: 0:23:21  Lr: 0.001875  Loss: -0.0417  Acc@1: 56.2500 (61.1041)  Acc@5: 93.7500 (90.2179)  time: 0.3486  data: 0.0010  max mem: 2500
Train: Epoch[2/5]  [ 600/4579]  eta: 0:23:17  Lr: 0.001875  Loss: 0.3333  Acc@1: 56.2500 (61.1169)  Acc@5: 93.7500 (90.2246)  time: 0.3484  data: 0.0010  max mem: 2500
Train: Epoch[2/5]  [ 610/4579]  eta: 0:23:14  Lr: 0.001875  Loss: -0.8190  Acc@1: 56.2500 (61.2111)  Acc@5: 93.7500 (90.2414)  time: 0.3484  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 620/4579]  eta: 0:23:10  Lr: 0.001875  Loss: 0.2296  Acc@1: 56.2500 (61.2319)  Acc@5: 93.7500 (90.3180)  time: 0.3501  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [ 630/4579]  eta: 0:23:07  Lr: 0.001875  Loss: -0.3103  Acc@1: 56.2500 (61.1926)  Acc@5: 93.7500 (90.3724)  time: 0.3514  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [ 640/4579]  eta: 0:23:03  Lr: 0.001875  Loss: -0.3593  Acc@1: 62.5000 (61.2422)  Acc@5: 93.7500 (90.3764)  time: 0.3510  data: 0.0009  max mem: 2500
Train: Epoch[2/5]  [ 650/4579]  eta: 0:23:00  Lr: 0.001875  Loss: -0.0815  Acc@1: 56.2500 (61.2423)  Acc@5: 87.5000 (90.3802)  time: 0.3513  data: 0.0012  max mem: 2500
Train: Epoch[2/5]  [ 660/4579]  eta: 0:22:56  Lr: 0.001875  Loss: 0.5967  Acc@1: 56.2500 (61.1668)  Acc@5: 87.5000 (90.3555)  time: 0.3509  data: 0.0013  max mem: 2500
Train: Epoch[2/5]  [ 670/4579]  eta: 0:22:52  Lr: 0.001875  Loss: 0.0355  Acc@1: 62.5000 (61.2425)  Acc@5: 87.5000 (90.3502)  time: 0.3484  data: 0.0012  max mem: 2500
Train: Epoch[2/5]  [ 680/4579]  eta: 0:22:49  Lr: 0.001875  Loss: -0.4064  Acc@1: 68.7500 (61.3620)  Acc@5: 93.7500 (90.3910)  time: 0.3476  data: 0.0010  max mem: 2500
Train: Epoch[2/5]  [ 690/4579]  eta: 0:22:45  Lr: 0.001875  Loss: -0.8459  Acc@1: 68.7500 (61.5141)  Acc@5: 93.7500 (90.4486)  time: 0.3483  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [ 700/4579]  eta: 0:22:41  Lr: 0.001875  Loss: -0.5281  Acc@1: 68.7500 (61.6084)  Acc@5: 93.7500 (90.4690)  time: 0.3485  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [ 710/4579]  eta: 0:22:38  Lr: 0.001875  Loss: 0.4385  Acc@1: 62.5000 (61.5946)  Acc@5: 93.7500 (90.4887)  time: 0.3490  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [ 720/4579]  eta: 0:22:34  Lr: 0.001875  Loss: -0.1723  Acc@1: 62.5000 (61.5378)  Acc@5: 93.7500 (90.5166)  time: 0.3505  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [ 730/4579]  eta: 0:22:31  Lr: 0.001875  Loss: -0.1877  Acc@1: 56.2500 (61.4313)  Acc@5: 87.5000 (90.5010)  time: 0.3498  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [ 740/4579]  eta: 0:22:27  Lr: 0.001875  Loss: -0.6421  Acc@1: 56.2500 (61.3782)  Acc@5: 93.7500 (90.5196)  time: 0.3480  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [ 750/4579]  eta: 0:22:23  Lr: 0.001875  Loss: 0.2421  Acc@1: 56.2500 (61.3515)  Acc@5: 93.7500 (90.5043)  time: 0.3508  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [ 760/4579]  eta: 0:22:20  Lr: 0.001875  Loss: -0.6906  Acc@1: 62.5000 (61.3420)  Acc@5: 87.5000 (90.4977)  time: 0.3513  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [ 770/4579]  eta: 0:22:16  Lr: 0.001875  Loss: 0.6107  Acc@1: 56.2500 (61.2840)  Acc@5: 87.5000 (90.4831)  time: 0.3498  data: 0.0009  max mem: 2500
Train: Epoch[2/5]  [ 780/4579]  eta: 0:22:13  Lr: 0.001875  Loss: -0.0222  Acc@1: 56.2500 (61.2836)  Acc@5: 87.5000 (90.4850)  time: 0.3498  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [ 790/4579]  eta: 0:22:09  Lr: 0.001875  Loss: -0.2456  Acc@1: 62.5000 (61.2674)  Acc@5: 87.5000 (90.4551)  time: 0.3478  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [ 800/4579]  eta: 0:22:05  Lr: 0.001875  Loss: -0.4865  Acc@1: 62.5000 (61.3140)  Acc@5: 93.7500 (90.5119)  time: 0.3476  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [ 810/4579]  eta: 0:22:02  Lr: 0.001875  Loss: 0.0416  Acc@1: 56.2500 (61.2130)  Acc@5: 93.7500 (90.4516)  time: 0.3509  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [ 820/4579]  eta: 0:21:58  Lr: 0.001875  Loss: -0.5256  Acc@1: 62.5000 (61.2591)  Acc@5: 93.7500 (90.4918)  time: 0.3509  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [ 830/4579]  eta: 0:21:55  Lr: 0.001875  Loss: 0.0061  Acc@1: 62.5000 (61.2515)  Acc@5: 87.5000 (90.4483)  time: 0.3517  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [ 840/4579]  eta: 0:21:52  Lr: 0.001875  Loss: 0.5258  Acc@1: 62.5000 (61.2292)  Acc@5: 87.5000 (90.4429)  time: 0.3540  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [ 850/4579]  eta: 0:21:48  Lr: 0.001875  Loss: 0.2835  Acc@1: 62.5000 (61.2515)  Acc@5: 87.5000 (90.4157)  time: 0.3522  data: 0.0015  max mem: 2500
Train: Epoch[2/5]  [ 860/4579]  eta: 0:21:45  Lr: 0.001875  Loss: 0.1112  Acc@1: 62.5000 (61.2732)  Acc@5: 87.5000 (90.4181)  time: 0.3511  data: 0.0014  max mem: 2500
Train: Epoch[2/5]  [ 870/4579]  eta: 0:21:41  Lr: 0.001875  Loss: -0.0074  Acc@1: 62.5000 (61.2586)  Acc@5: 87.5000 (90.3918)  time: 0.3500  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [ 880/4579]  eta: 0:21:38  Lr: 0.001875  Loss: 0.0522  Acc@1: 56.2500 (61.2514)  Acc@5: 93.7500 (90.4370)  time: 0.3496  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 890/4579]  eta: 0:21:34  Lr: 0.001875  Loss: 0.1331  Acc@1: 56.2500 (61.1813)  Acc@5: 93.7500 (90.4321)  time: 0.3518  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 900/4579]  eta: 0:21:30  Lr: 0.001875  Loss: -0.3142  Acc@1: 56.2500 (61.1612)  Acc@5: 93.7500 (90.4550)  time: 0.3508  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [ 910/4579]  eta: 0:21:27  Lr: 0.001875  Loss: -0.1214  Acc@1: 62.5000 (61.1965)  Acc@5: 87.5000 (90.4226)  time: 0.3501  data: 0.0013  max mem: 2500
Train: Epoch[2/5]  [ 920/4579]  eta: 0:21:23  Lr: 0.001875  Loss: -0.0731  Acc@1: 62.5000 (61.2039)  Acc@5: 93.7500 (90.4791)  time: 0.3501  data: 0.0013  max mem: 2500
Train: Epoch[2/5]  [ 930/4579]  eta: 0:21:20  Lr: 0.001875  Loss: -0.0925  Acc@1: 62.5000 (61.2245)  Acc@5: 93.7500 (90.5142)  time: 0.3490  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [ 940/4579]  eta: 0:21:16  Lr: 0.001875  Loss: 0.2475  Acc@1: 62.5000 (61.2779)  Acc@5: 93.7500 (90.5088)  time: 0.3489  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [ 950/4579]  eta: 0:21:13  Lr: 0.001875  Loss: -0.3571  Acc@1: 62.5000 (61.3302)  Acc@5: 93.7500 (90.5428)  time: 0.3494  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [ 960/4579]  eta: 0:21:09  Lr: 0.001875  Loss: 0.0625  Acc@1: 62.5000 (61.3163)  Acc@5: 93.7500 (90.5632)  time: 0.3501  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [ 970/4579]  eta: 0:21:06  Lr: 0.001875  Loss: -0.5647  Acc@1: 56.2500 (61.3157)  Acc@5: 93.7500 (90.5510)  time: 0.3487  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [ 980/4579]  eta: 0:21:02  Lr: 0.001875  Loss: 0.0023  Acc@1: 62.5000 (61.3341)  Acc@5: 93.7500 (90.5772)  time: 0.3473  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [ 990/4579]  eta: 0:20:58  Lr: 0.001875  Loss: 0.7093  Acc@1: 62.5000 (61.3143)  Acc@5: 93.7500 (90.5714)  time: 0.3493  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1000/4579]  eta: 0:20:55  Lr: 0.001875  Loss: 0.4128  Acc@1: 62.5000 (61.2762)  Acc@5: 87.5000 (90.5657)  time: 0.3519  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [1010/4579]  eta: 0:20:51  Lr: 0.001875  Loss: -0.3554  Acc@1: 62.5000 (61.3316)  Acc@5: 93.7500 (90.5972)  time: 0.3503  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1020/4579]  eta: 0:20:48  Lr: 0.001875  Loss: -0.0658  Acc@1: 62.5000 (61.3063)  Acc@5: 93.7500 (90.6219)  time: 0.3484  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1030/4579]  eta: 0:20:44  Lr: 0.001875  Loss: -0.3680  Acc@1: 62.5000 (61.3785)  Acc@5: 93.7500 (90.6280)  time: 0.3496  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [1040/4579]  eta: 0:20:41  Lr: 0.001875  Loss: -0.1993  Acc@1: 68.7500 (61.4313)  Acc@5: 93.7500 (90.6280)  time: 0.3492  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [1050/4579]  eta: 0:20:37  Lr: 0.001875  Loss: 0.3441  Acc@1: 62.5000 (61.4355)  Acc@5: 93.7500 (90.6458)  time: 0.3474  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1060/4579]  eta: 0:20:33  Lr: 0.001875  Loss: -0.4068  Acc@1: 56.2500 (61.4456)  Acc@5: 93.7500 (90.6574)  time: 0.3476  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1070/4579]  eta: 0:20:30  Lr: 0.001875  Loss: 0.1958  Acc@1: 56.2500 (61.4204)  Acc@5: 93.7500 (90.6513)  time: 0.3514  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [1080/4579]  eta: 0:20:27  Lr: 0.001875  Loss: 0.0299  Acc@1: 56.2500 (61.4073)  Acc@5: 93.7500 (90.6510)  time: 0.3537  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [1090/4579]  eta: 0:20:23  Lr: 0.001875  Loss: -0.1458  Acc@1: 62.5000 (61.4058)  Acc@5: 93.7500 (90.6565)  time: 0.3518  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [1100/4579]  eta: 0:20:20  Lr: 0.001875  Loss: -0.0033  Acc@1: 62.5000 (61.4782)  Acc@5: 87.5000 (90.6278)  time: 0.3517  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [1110/4579]  eta: 0:20:16  Lr: 0.001875  Loss: -0.5004  Acc@1: 68.7500 (61.5549)  Acc@5: 93.7500 (90.6728)  time: 0.3505  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [1120/4579]  eta: 0:20:13  Lr: 0.001875  Loss: -0.3379  Acc@1: 62.5000 (61.5355)  Acc@5: 93.7500 (90.6668)  time: 0.3506  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1130/4579]  eta: 0:20:09  Lr: 0.001875  Loss: 0.2672  Acc@1: 62.5000 (61.4998)  Acc@5: 87.5000 (90.6333)  time: 0.3498  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1140/4579]  eta: 0:20:06  Lr: 0.001875  Loss: -0.2964  Acc@1: 62.5000 (61.4921)  Acc@5: 87.5000 (90.6496)  time: 0.3503  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [1150/4579]  eta: 0:20:02  Lr: 0.001875  Loss: 0.0071  Acc@1: 62.5000 (61.5063)  Acc@5: 93.7500 (90.6440)  time: 0.3516  data: 0.0009  max mem: 2500
Train: Epoch[2/5]  [1160/4579]  eta: 0:19:59  Lr: 0.001875  Loss: 0.1695  Acc@1: 56.2500 (61.4933)  Acc@5: 93.7500 (90.6385)  time: 0.3505  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [1170/4579]  eta: 0:19:55  Lr: 0.001875  Loss: 0.1226  Acc@1: 56.2500 (61.4806)  Acc@5: 93.7500 (90.6650)  time: 0.3510  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [1180/4579]  eta: 0:19:51  Lr: 0.001875  Loss: 0.0974  Acc@1: 56.2500 (61.4627)  Acc@5: 93.7500 (90.6700)  time: 0.3497  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [1190/4579]  eta: 0:19:48  Lr: 0.001875  Loss: -0.1344  Acc@1: 62.5000 (61.5449)  Acc@5: 93.7500 (90.6853)  time: 0.3483  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [1200/4579]  eta: 0:19:45  Lr: 0.001875  Loss: 0.5961  Acc@1: 62.5000 (61.5164)  Acc@5: 87.5000 (90.6484)  time: 0.3514  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [1210/4579]  eta: 0:19:41  Lr: 0.001875  Loss: -0.2049  Acc@1: 62.5000 (61.4781)  Acc@5: 87.5000 (90.6740)  time: 0.3523  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1220/4579]  eta: 0:19:37  Lr: 0.001875  Loss: 0.2901  Acc@1: 56.2500 (61.4353)  Acc@5: 93.7500 (90.7146)  time: 0.3501  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1230/4579]  eta: 0:19:34  Lr: 0.001875  Loss: -0.6127  Acc@1: 56.2500 (61.4338)  Acc@5: 93.7500 (90.7189)  time: 0.3513  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [1240/4579]  eta: 0:19:30  Lr: 0.001875  Loss: -0.1263  Acc@1: 62.5000 (61.4625)  Acc@5: 93.7500 (90.7383)  time: 0.3511  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [1250/4579]  eta: 0:19:27  Lr: 0.001875  Loss: -0.2792  Acc@1: 62.5000 (61.4558)  Acc@5: 93.7500 (90.7574)  time: 0.3501  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1260/4579]  eta: 0:19:23  Lr: 0.001875  Loss: 0.4967  Acc@1: 62.5000 (61.4096)  Acc@5: 93.7500 (90.7316)  time: 0.3497  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1270/4579]  eta: 0:19:20  Lr: 0.001875  Loss: 0.2219  Acc@1: 62.5000 (61.4182)  Acc@5: 93.7500 (90.7307)  time: 0.3513  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1280/4579]  eta: 0:19:17  Lr: 0.001875  Loss: -0.2557  Acc@1: 62.5000 (61.3827)  Acc@5: 87.5000 (90.7299)  time: 0.3527  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [1290/4579]  eta: 0:19:13  Lr: 0.001875  Loss: -0.3430  Acc@1: 62.5000 (61.4398)  Acc@5: 87.5000 (90.7242)  time: 0.3505  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [1300/4579]  eta: 0:19:09  Lr: 0.001875  Loss: -0.5652  Acc@1: 68.7500 (61.4719)  Acc@5: 93.7500 (90.7571)  time: 0.3491  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [1310/4579]  eta: 0:19:06  Lr: 0.001875  Loss: 0.0656  Acc@1: 68.7500 (61.4798)  Acc@5: 93.7500 (90.7656)  time: 0.3509  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [1320/4579]  eta: 0:19:02  Lr: 0.001875  Loss: 0.1303  Acc@1: 68.7500 (61.5064)  Acc@5: 93.7500 (90.7646)  time: 0.3509  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [1330/4579]  eta: 0:18:59  Lr: 0.001875  Loss: 0.1995  Acc@1: 62.5000 (61.4904)  Acc@5: 93.7500 (90.7729)  time: 0.3507  data: 0.0017  max mem: 2500
Train: Epoch[2/5]  [1340/4579]  eta: 0:18:55  Lr: 0.001875  Loss: 0.3091  Acc@1: 62.5000 (61.5259)  Acc@5: 93.7500 (90.7858)  time: 0.3522  data: 0.0024  max mem: 2500
Train: Epoch[2/5]  [1350/4579]  eta: 0:18:52  Lr: 0.001875  Loss: 0.0389  Acc@1: 62.5000 (61.5146)  Acc@5: 93.7500 (90.8077)  time: 0.3503  data: 0.0013  max mem: 2500
Train: Epoch[2/5]  [1360/4579]  eta: 0:18:48  Lr: 0.001875  Loss: -0.5799  Acc@1: 56.2500 (61.5173)  Acc@5: 93.7500 (90.8156)  time: 0.3496  data: 0.0013  max mem: 2500
Train: Epoch[2/5]  [1370/4579]  eta: 0:18:45  Lr: 0.001875  Loss: 0.1367  Acc@1: 62.5000 (61.5108)  Acc@5: 87.5000 (90.7960)  time: 0.3510  data: 0.0016  max mem: 2500
Train: Epoch[2/5]  [1380/4579]  eta: 0:18:41  Lr: 0.001875  Loss: 0.1276  Acc@1: 62.5000 (61.5179)  Acc@5: 87.5000 (90.8038)  time: 0.3524  data: 0.0010  max mem: 2500
Train: Epoch[2/5]  [1390/4579]  eta: 0:18:38  Lr: 0.001875  Loss: 0.2941  Acc@1: 62.5000 (61.5430)  Acc@5: 93.7500 (90.8294)  time: 0.3570  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [1400/4579]  eta: 0:18:35  Lr: 0.001875  Loss: -0.1534  Acc@1: 62.5000 (61.5364)  Acc@5: 93.7500 (90.8146)  time: 0.3562  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [1410/4579]  eta: 0:18:31  Lr: 0.001875  Loss: 0.5152  Acc@1: 56.2500 (61.5167)  Acc@5: 87.5000 (90.8044)  time: 0.3501  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [1420/4579]  eta: 0:18:28  Lr: 0.001875  Loss: 0.1101  Acc@1: 62.5000 (61.5192)  Acc@5: 93.7500 (90.8031)  time: 0.3489  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1430/4579]  eta: 0:18:24  Lr: 0.001875  Loss: 0.2600  Acc@1: 62.5000 (61.5042)  Acc@5: 93.7500 (90.8063)  time: 0.3513  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1440/4579]  eta: 0:18:21  Lr: 0.001875  Loss: 0.0223  Acc@1: 62.5000 (61.5241)  Acc@5: 87.5000 (90.7920)  time: 0.3532  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1450/4579]  eta: 0:18:17  Lr: 0.001875  Loss: -0.3223  Acc@1: 56.2500 (61.4835)  Acc@5: 87.5000 (90.7865)  time: 0.3512  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1460/4579]  eta: 0:18:14  Lr: 0.001875  Loss: -0.1544  Acc@1: 56.2500 (61.4861)  Acc@5: 93.7500 (90.7854)  time: 0.3495  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [1470/4579]  eta: 0:18:10  Lr: 0.001875  Loss: 0.0543  Acc@1: 62.5000 (61.4760)  Acc@5: 93.7500 (90.7716)  time: 0.3502  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [1480/4579]  eta: 0:18:07  Lr: 0.001875  Loss: -0.3906  Acc@1: 56.2500 (61.4661)  Acc@5: 87.5000 (90.7411)  time: 0.3494  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [1490/4579]  eta: 0:18:03  Lr: 0.001875  Loss: -0.1881  Acc@1: 56.2500 (61.4814)  Acc@5: 93.7500 (90.7445)  time: 0.3491  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [1500/4579]  eta: 0:18:00  Lr: 0.001875  Loss: -0.3335  Acc@1: 62.5000 (61.4965)  Acc@5: 87.5000 (90.7478)  time: 0.3500  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [1510/4579]  eta: 0:17:56  Lr: 0.001875  Loss: -0.5336  Acc@1: 62.5000 (61.5156)  Acc@5: 87.5000 (90.7594)  time: 0.3530  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [1520/4579]  eta: 0:17:53  Lr: 0.001875  Loss: 0.0225  Acc@1: 62.5000 (61.5138)  Acc@5: 87.5000 (90.7339)  time: 0.3545  data: 0.0015  max mem: 2500
Train: Epoch[2/5]  [1530/4579]  eta: 0:17:49  Lr: 0.001875  Loss: -0.1850  Acc@1: 62.5000 (61.5202)  Acc@5: 87.5000 (90.7291)  time: 0.3518  data: 0.0014  max mem: 2500
Train: Epoch[2/5]  [1540/4579]  eta: 0:17:46  Lr: 0.001875  Loss: -0.3093  Acc@1: 62.5000 (61.5063)  Acc@5: 93.7500 (90.7487)  time: 0.3480  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1550/4579]  eta: 0:17:42  Lr: 0.001875  Loss: -0.1851  Acc@1: 62.5000 (61.5530)  Acc@5: 93.7500 (90.7681)  time: 0.3473  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [1560/4579]  eta: 0:17:38  Lr: 0.001875  Loss: -0.1313  Acc@1: 62.5000 (61.5391)  Acc@5: 93.7500 (90.7711)  time: 0.3489  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [1570/4579]  eta: 0:17:35  Lr: 0.001875  Loss: -0.1979  Acc@1: 62.5000 (61.5253)  Acc@5: 87.5000 (90.7662)  time: 0.3497  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [1580/4579]  eta: 0:17:31  Lr: 0.001875  Loss: 0.3223  Acc@1: 56.2500 (61.5117)  Acc@5: 87.5000 (90.7812)  time: 0.3500  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [1590/4579]  eta: 0:17:28  Lr: 0.001875  Loss: -0.5038  Acc@1: 56.2500 (61.5218)  Acc@5: 93.7500 (90.7880)  time: 0.3511  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1600/4579]  eta: 0:17:24  Lr: 0.001875  Loss: -0.5623  Acc@1: 62.5000 (61.5280)  Acc@5: 93.7500 (90.8065)  time: 0.3527  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [1610/4579]  eta: 0:17:21  Lr: 0.001875  Loss: -0.3918  Acc@1: 56.2500 (61.5146)  Acc@5: 93.7500 (90.8054)  time: 0.3521  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1620/4579]  eta: 0:17:17  Lr: 0.001875  Loss: -0.0847  Acc@1: 56.2500 (61.5014)  Acc@5: 93.7500 (90.8120)  time: 0.3510  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1630/4579]  eta: 0:17:14  Lr: 0.001875  Loss: -0.3491  Acc@1: 62.5000 (61.5075)  Acc@5: 93.7500 (90.8185)  time: 0.3539  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [1640/4579]  eta: 0:17:11  Lr: 0.001875  Loss: -0.0319  Acc@1: 62.5000 (61.5098)  Acc@5: 93.7500 (90.8402)  time: 0.3549  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [1650/4579]  eta: 0:17:07  Lr: 0.001875  Loss: -0.2931  Acc@1: 62.5000 (61.5120)  Acc@5: 93.7500 (90.8465)  time: 0.3507  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [1660/4579]  eta: 0:17:03  Lr: 0.001875  Loss: 0.0281  Acc@1: 62.5000 (61.5443)  Acc@5: 93.7500 (90.8639)  time: 0.3491  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [1670/4579]  eta: 0:17:00  Lr: 0.001875  Loss: -0.3301  Acc@1: 68.7500 (61.5836)  Acc@5: 93.7500 (90.8775)  time: 0.3515  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [1680/4579]  eta: 0:16:57  Lr: 0.001875  Loss: 0.0061  Acc@1: 62.5000 (61.5556)  Acc@5: 93.7500 (90.8760)  time: 0.3519  data: 0.0016  max mem: 2500
Train: Epoch[2/5]  [1690/4579]  eta: 0:16:53  Lr: 0.001875  Loss: -0.5243  Acc@1: 56.2500 (61.5612)  Acc@5: 87.5000 (90.8560)  time: 0.3518  data: 0.0017  max mem: 2500
Train: Epoch[2/5]  [1700/4579]  eta: 0:16:50  Lr: 0.001875  Loss: -0.5827  Acc@1: 62.5000 (61.5410)  Acc@5: 87.5000 (90.8473)  time: 0.3518  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [1710/4579]  eta: 0:16:46  Lr: 0.001875  Loss: -0.1847  Acc@1: 56.2500 (61.5357)  Acc@5: 87.5000 (90.8533)  time: 0.3518  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1720/4579]  eta: 0:16:43  Lr: 0.001875  Loss: -0.1194  Acc@1: 56.2500 (61.5158)  Acc@5: 87.5000 (90.8483)  time: 0.3541  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [1730/4579]  eta: 0:16:39  Lr: 0.001875  Loss: -0.1115  Acc@1: 62.5000 (61.5324)  Acc@5: 87.5000 (90.8543)  time: 0.3517  data: 0.0013  max mem: 2500
Train: Epoch[2/5]  [1740/4579]  eta: 0:16:36  Lr: 0.001875  Loss: -0.7133  Acc@1: 62.5000 (61.5630)  Acc@5: 93.7500 (90.8601)  time: 0.3492  data: 0.0013  max mem: 2500
Train: Epoch[2/5]  [1750/4579]  eta: 0:16:32  Lr: 0.001875  Loss: -0.6409  Acc@1: 62.5000 (61.5898)  Acc@5: 87.5000 (90.8409)  time: 0.3486  data: 0.0009  max mem: 2500
Train: Epoch[2/5]  [1760/4579]  eta: 0:16:28  Lr: 0.001875  Loss: 0.0543  Acc@1: 62.5000 (61.6269)  Acc@5: 93.7500 (90.8468)  time: 0.3481  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [1770/4579]  eta: 0:16:25  Lr: 0.001875  Loss: 0.2701  Acc@1: 62.5000 (61.6107)  Acc@5: 93.7500 (90.8279)  time: 0.3498  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [1780/4579]  eta: 0:16:21  Lr: 0.001875  Loss: -0.6092  Acc@1: 62.5000 (61.6122)  Acc@5: 93.7500 (90.8303)  time: 0.3523  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [1790/4579]  eta: 0:16:18  Lr: 0.001875  Loss: -0.2310  Acc@1: 62.5000 (61.6311)  Acc@5: 93.7500 (90.8326)  time: 0.3512  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [1800/4579]  eta: 0:16:14  Lr: 0.001875  Loss: -0.3250  Acc@1: 62.5000 (61.6047)  Acc@5: 93.7500 (90.8384)  time: 0.3488  data: 0.0011  max mem: 2500
Train: Epoch[2/5]  [1810/4579]  eta: 0:16:11  Lr: 0.001875  Loss: -0.1725  Acc@1: 56.2500 (61.5958)  Acc@5: 93.7500 (90.8096)  time: 0.3489  data: 0.0010  max mem: 2500
Train: Epoch[2/5]  [1820/4579]  eta: 0:16:07  Lr: 0.001875  Loss: -0.1275  Acc@1: 62.5000 (61.6385)  Acc@5: 93.7500 (90.8258)  time: 0.3477  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1830/4579]  eta: 0:16:04  Lr: 0.001875  Loss: -0.3002  Acc@1: 68.7500 (61.6364)  Acc@5: 93.7500 (90.8144)  time: 0.3477  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1840/4579]  eta: 0:16:00  Lr: 0.001875  Loss: -0.1846  Acc@1: 62.5000 (61.6547)  Acc@5: 93.7500 (90.8338)  time: 0.3516  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [1850/4579]  eta: 0:15:57  Lr: 0.001875  Loss: 0.0584  Acc@1: 62.5000 (61.6322)  Acc@5: 93.7500 (90.8327)  time: 0.3532  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [1860/4579]  eta: 0:15:53  Lr: 0.001875  Loss: 0.1613  Acc@1: 56.2500 (61.6033)  Acc@5: 93.7500 (90.8383)  time: 0.3510  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1870/4579]  eta: 0:15:50  Lr: 0.001875  Loss: -0.1639  Acc@1: 56.2500 (61.5947)  Acc@5: 87.5000 (90.8271)  time: 0.3514  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1880/4579]  eta: 0:15:46  Lr: 0.001875  Loss: -0.1376  Acc@1: 62.5000 (61.6361)  Acc@5: 87.5000 (90.8393)  time: 0.3526  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [1890/4579]  eta: 0:15:43  Lr: 0.001875  Loss: -0.2725  Acc@1: 62.5000 (61.6308)  Acc@5: 93.7500 (90.8283)  time: 0.3518  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [1900/4579]  eta: 0:15:39  Lr: 0.001875  Loss: 0.2954  Acc@1: 56.2500 (61.6320)  Acc@5: 93.7500 (90.8403)  time: 0.3512  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1910/4579]  eta: 0:15:36  Lr: 0.001875  Loss: 0.0831  Acc@1: 62.5000 (61.6366)  Acc@5: 93.7500 (90.8359)  time: 0.3509  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1920/4579]  eta: 0:15:32  Lr: 0.001875  Loss: -0.1339  Acc@1: 62.5000 (61.6378)  Acc@5: 87.5000 (90.8414)  time: 0.3508  data: 0.0014  max mem: 2500
Train: Epoch[2/5]  [1930/4579]  eta: 0:15:29  Lr: 0.001875  Loss: -0.4903  Acc@1: 56.2500 (61.6164)  Acc@5: 87.5000 (90.8370)  time: 0.3521  data: 0.0016  max mem: 2500
Train: Epoch[2/5]  [1940/4579]  eta: 0:15:25  Lr: 0.001875  Loss: 0.1045  Acc@1: 56.2500 (61.6048)  Acc@5: 87.5000 (90.8230)  time: 0.3531  data: 0.0009  max mem: 2500
Train: Epoch[2/5]  [1950/4579]  eta: 0:15:22  Lr: 0.001875  Loss: -0.7381  Acc@1: 56.2500 (61.6158)  Acc@5: 93.7500 (90.8380)  time: 0.3530  data: 0.0010  max mem: 2500
Train: Epoch[2/5]  [1960/4579]  eta: 0:15:18  Lr: 0.001875  Loss: -0.3978  Acc@1: 62.5000 (61.6235)  Acc@5: 93.7500 (90.8465)  time: 0.3498  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [1970/4579]  eta: 0:15:15  Lr: 0.001875  Loss: 0.0690  Acc@1: 62.5000 (61.6216)  Acc@5: 93.7500 (90.8422)  time: 0.3482  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [1980/4579]  eta: 0:15:11  Lr: 0.001875  Loss: 0.0349  Acc@1: 62.5000 (61.6166)  Acc@5: 87.5000 (90.8253)  time: 0.3480  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [1990/4579]  eta: 0:15:08  Lr: 0.001875  Loss: -0.3180  Acc@1: 62.5000 (61.6556)  Acc@5: 93.7500 (90.8338)  time: 0.3484  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [2000/4579]  eta: 0:15:04  Lr: 0.001875  Loss: -0.2715  Acc@1: 62.5000 (61.6535)  Acc@5: 87.5000 (90.8202)  time: 0.3497  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [2010/4579]  eta: 0:15:01  Lr: 0.001875  Loss: -0.0802  Acc@1: 62.5000 (61.6453)  Acc@5: 87.5000 (90.8255)  time: 0.3498  data: 0.0009  max mem: 2500
Train: Epoch[2/5]  [2020/4579]  eta: 0:14:57  Lr: 0.001875  Loss: -0.2490  Acc@1: 62.5000 (61.6712)  Acc@5: 93.7500 (90.8337)  time: 0.3508  data: 0.0009  max mem: 2500
Train: Epoch[2/5]  [2030/4579]  eta: 0:14:54  Lr: 0.001875  Loss: 0.6226  Acc@1: 62.5000 (61.6414)  Acc@5: 87.5000 (90.8235)  time: 0.3519  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [2040/4579]  eta: 0:14:50  Lr: 0.001875  Loss: -0.0322  Acc@1: 56.2500 (61.6150)  Acc@5: 87.5000 (90.8164)  time: 0.3509  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [2050/4579]  eta: 0:14:47  Lr: 0.001875  Loss: -0.5561  Acc@1: 56.2500 (61.5919)  Acc@5: 87.5000 (90.8063)  time: 0.3504  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [2060/4579]  eta: 0:14:43  Lr: 0.001875  Loss: 0.2723  Acc@1: 56.2500 (61.5842)  Acc@5: 87.5000 (90.8024)  time: 0.3518  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [2070/4579]  eta: 0:14:40  Lr: 0.001875  Loss: -0.3925  Acc@1: 56.2500 (61.5796)  Acc@5: 87.5000 (90.7955)  time: 0.3502  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [2080/4579]  eta: 0:14:36  Lr: 0.001875  Loss: 0.0736  Acc@1: 62.5000 (61.5900)  Acc@5: 93.7500 (90.8037)  time: 0.3485  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [2090/4579]  eta: 0:14:33  Lr: 0.001875  Loss: -0.4315  Acc@1: 68.7500 (61.6212)  Acc@5: 93.7500 (90.8058)  time: 0.3487  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [2100/4579]  eta: 0:14:29  Lr: 0.001875  Loss: -0.6105  Acc@1: 68.7500 (61.6284)  Acc@5: 87.5000 (90.8020)  time: 0.3501  data: 0.0014  max mem: 2500
Train: Epoch[2/5]  [2110/4579]  eta: 0:14:26  Lr: 0.001875  Loss: -0.5700  Acc@1: 68.7500 (61.6621)  Acc@5: 93.7500 (90.8189)  time: 0.3507  data: 0.0014  max mem: 2500
Train: Epoch[2/5]  [2120/4579]  eta: 0:14:22  Lr: 0.001875  Loss: -0.6441  Acc@1: 68.7500 (61.6955)  Acc@5: 93.7500 (90.8445)  time: 0.3504  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [2130/4579]  eta: 0:14:18  Lr: 0.001875  Loss: 0.3870  Acc@1: 62.5000 (61.6788)  Acc@5: 93.7500 (90.8435)  time: 0.3501  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [2140/4579]  eta: 0:14:15  Lr: 0.001875  Loss: -0.0732  Acc@1: 56.2500 (61.6593)  Acc@5: 87.5000 (90.8366)  time: 0.3485  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [2150/4579]  eta: 0:14:11  Lr: 0.001875  Loss: -0.7448  Acc@1: 56.2500 (61.6283)  Acc@5: 87.5000 (90.8328)  time: 0.3485  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [2160/4579]  eta: 0:14:08  Lr: 0.001875  Loss: 0.1176  Acc@1: 56.2500 (61.6410)  Acc@5: 93.7500 (90.8318)  time: 0.3515  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [2170/4579]  eta: 0:14:04  Lr: 0.001875  Loss: 0.2959  Acc@1: 56.2500 (61.6076)  Acc@5: 87.5000 (90.8251)  time: 0.3514  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [2180/4579]  eta: 0:14:01  Lr: 0.001875  Loss: -0.3787  Acc@1: 50.0000 (61.5744)  Acc@5: 87.5000 (90.8213)  time: 0.3505  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [2190/4579]  eta: 0:13:57  Lr: 0.001875  Loss: -0.2003  Acc@1: 62.5000 (61.5900)  Acc@5: 93.7500 (90.8318)  time: 0.3525  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [2200/4579]  eta: 0:13:54  Lr: 0.001875  Loss: -0.2374  Acc@1: 62.5000 (61.6282)  Acc@5: 93.7500 (90.8252)  time: 0.3520  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [2210/4579]  eta: 0:13:50  Lr: 0.001875  Loss: -0.1920  Acc@1: 68.7500 (61.6520)  Acc@5: 93.7500 (90.8215)  time: 0.3506  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [2220/4579]  eta: 0:13:47  Lr: 0.001875  Loss: 0.2290  Acc@1: 62.5000 (61.6333)  Acc@5: 87.5000 (90.8009)  time: 0.3503  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [2230/4579]  eta: 0:13:43  Lr: 0.001875  Loss: -0.4072  Acc@1: 62.5000 (61.6372)  Acc@5: 87.5000 (90.8001)  time: 0.3501  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [2240/4579]  eta: 0:13:40  Lr: 0.001875  Loss: 0.3330  Acc@1: 62.5000 (61.6159)  Acc@5: 87.5000 (90.7965)  time: 0.3498  data: 0.0009  max mem: 2500
Train: Epoch[2/5]  [2250/4579]  eta: 0:13:36  Lr: 0.001875  Loss: -0.4557  Acc@1: 56.2500 (61.5865)  Acc@5: 87.5000 (90.7847)  time: 0.3497  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [2260/4579]  eta: 0:13:33  Lr: 0.001875  Loss: -0.1988  Acc@1: 62.5000 (61.5906)  Acc@5: 87.5000 (90.7784)  time: 0.3495  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [2270/4579]  eta: 0:13:29  Lr: 0.001875  Loss: -0.4316  Acc@1: 62.5000 (61.5780)  Acc@5: 87.5000 (90.7777)  time: 0.3486  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [2280/4579]  eta: 0:13:26  Lr: 0.001875  Loss: -0.4165  Acc@1: 56.2500 (61.5684)  Acc@5: 93.7500 (90.7771)  time: 0.3494  data: 0.0009  max mem: 2500
Train: Epoch[2/5]  [2290/4579]  eta: 0:13:22  Lr: 0.001875  Loss: -0.4609  Acc@1: 62.5000 (61.5779)  Acc@5: 93.7500 (90.7873)  time: 0.3500  data: 0.0009  max mem: 2500
Train: Epoch[2/5]  [2300/4579]  eta: 0:13:19  Lr: 0.001875  Loss: -0.7281  Acc@1: 62.5000 (61.5901)  Acc@5: 93.7500 (90.7812)  time: 0.3502  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [2310/4579]  eta: 0:13:15  Lr: 0.001875  Loss: -0.5121  Acc@1: 62.5000 (61.6075)  Acc@5: 93.7500 (90.7859)  time: 0.3520  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [2320/4579]  eta: 0:13:12  Lr: 0.001875  Loss: -0.1692  Acc@1: 62.5000 (61.6221)  Acc@5: 93.7500 (90.7906)  time: 0.3512  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [2330/4579]  eta: 0:13:08  Lr: 0.001875  Loss: -0.2488  Acc@1: 62.5000 (61.6179)  Acc@5: 93.7500 (90.7819)  time: 0.3492  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [2340/4579]  eta: 0:13:05  Lr: 0.001875  Loss: 0.5595  Acc@1: 62.5000 (61.6270)  Acc@5: 93.7500 (90.7812)  time: 0.3483  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [2350/4579]  eta: 0:13:01  Lr: 0.001875  Loss: -0.2858  Acc@1: 56.2500 (61.6254)  Acc@5: 93.7500 (90.7858)  time: 0.3506  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [2360/4579]  eta: 0:12:58  Lr: 0.001875  Loss: -0.7704  Acc@1: 62.5000 (61.6344)  Acc@5: 93.7500 (90.8090)  time: 0.3521  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [2370/4579]  eta: 0:12:54  Lr: 0.001875  Loss: 0.2463  Acc@1: 62.5000 (61.6565)  Acc@5: 93.7500 (90.8187)  time: 0.3520  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [2380/4579]  eta: 0:12:51  Lr: 0.001875  Loss: -0.2723  Acc@1: 62.5000 (61.6521)  Acc@5: 93.7500 (90.8153)  time: 0.3531  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [2390/4579]  eta: 0:12:47  Lr: 0.001875  Loss: -0.4633  Acc@1: 62.5000 (61.6452)  Acc@5: 87.5000 (90.8041)  time: 0.3512  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [2400/4579]  eta: 0:12:44  Lr: 0.001875  Loss: -0.2005  Acc@1: 62.5000 (61.6670)  Acc@5: 87.5000 (90.8059)  time: 0.3492  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [2410/4579]  eta: 0:12:40  Lr: 0.001875  Loss: 0.0441  Acc@1: 62.5000 (61.6497)  Acc@5: 93.7500 (90.8129)  time: 0.3494  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [2420/4579]  eta: 0:12:37  Lr: 0.001875  Loss: -0.4613  Acc@1: 62.5000 (61.6662)  Acc@5: 93.7500 (90.8277)  time: 0.3510  data: 0.0010  max mem: 2500
Train: Epoch[2/5]  [2430/4579]  eta: 0:12:33  Lr: 0.001875  Loss: -0.3978  Acc@1: 62.5000 (61.6747)  Acc@5: 93.7500 (90.8242)  time: 0.3513  data: 0.0010  max mem: 2500
Train: Epoch[2/5]  [2440/4579]  eta: 0:12:30  Lr: 0.001875  Loss: 0.3368  Acc@1: 62.5000 (61.6730)  Acc@5: 87.5000 (90.8183)  time: 0.3502  data: 0.0009  max mem: 2500
Train: Epoch[2/5]  [2450/4579]  eta: 0:12:26  Lr: 0.001875  Loss: 0.1903  Acc@1: 62.5000 (61.6942)  Acc@5: 87.5000 (90.8048)  time: 0.3507  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [2460/4579]  eta: 0:12:23  Lr: 0.001875  Loss: -0.7096  Acc@1: 62.5000 (61.7178)  Acc@5: 93.7500 (90.8218)  time: 0.3520  data: 0.0012  max mem: 2500
Train: Epoch[2/5]  [2470/4579]  eta: 0:12:19  Lr: 0.001875  Loss: 0.0035  Acc@1: 62.5000 (61.7286)  Acc@5: 93.7500 (90.8185)  time: 0.3524  data: 0.0013  max mem: 2500
Train: Epoch[2/5]  [2480/4579]  eta: 0:12:16  Lr: 0.001875  Loss: 0.0027  Acc@1: 62.5000 (61.7241)  Acc@5: 87.5000 (90.8228)  time: 0.3510  data: 0.0009  max mem: 2500
Train: Epoch[2/5]  [2490/4579]  eta: 0:12:12  Lr: 0.001875  Loss: -0.3120  Acc@1: 62.5000 (61.7423)  Acc@5: 93.7500 (90.8245)  time: 0.3499  data: 0.0010  max mem: 2500
Train: Epoch[2/5]  [2500/4579]  eta: 0:12:09  Lr: 0.001875  Loss: -0.1884  Acc@1: 68.7500 (61.7678)  Acc@5: 93.7500 (90.8337)  time: 0.3493  data: 0.0011  max mem: 2500
Train: Epoch[2/5]  [2510/4579]  eta: 0:12:05  Lr: 0.001875  Loss: 0.1508  Acc@1: 62.5000 (61.7583)  Acc@5: 93.7500 (90.8378)  time: 0.3496  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [2520/4579]  eta: 0:12:02  Lr: 0.001875  Loss: 0.0588  Acc@1: 62.5000 (61.7562)  Acc@5: 93.7500 (90.8394)  time: 0.3505  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [2530/4579]  eta: 0:11:58  Lr: 0.001875  Loss: -0.2869  Acc@1: 62.5000 (61.7444)  Acc@5: 87.5000 (90.8386)  time: 0.3499  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [2540/4579]  eta: 0:11:55  Lr: 0.001875  Loss: -0.1709  Acc@1: 62.5000 (61.7547)  Acc@5: 87.5000 (90.8328)  time: 0.3535  data: 0.0021  max mem: 2500
Train: Epoch[2/5]  [2550/4579]  eta: 0:11:51  Lr: 0.001875  Loss: 0.7589  Acc@1: 62.5000 (61.7478)  Acc@5: 87.5000 (90.8271)  time: 0.3539  data: 0.0021  max mem: 2500
Train: Epoch[2/5]  [2560/4579]  eta: 0:11:48  Lr: 0.001875  Loss: -0.1418  Acc@1: 56.2500 (61.7215)  Acc@5: 93.7500 (90.8337)  time: 0.3506  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [2570/4579]  eta: 0:11:44  Lr: 0.001875  Loss: -0.0113  Acc@1: 56.2500 (61.7124)  Acc@5: 93.7500 (90.8426)  time: 0.3508  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [2580/4579]  eta: 0:11:41  Lr: 0.001875  Loss: 0.0381  Acc@1: 62.5000 (61.7154)  Acc@5: 93.7500 (90.8587)  time: 0.3521  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [2590/4579]  eta: 0:11:37  Lr: 0.001875  Loss: -0.1093  Acc@1: 68.7500 (61.7377)  Acc@5: 93.7500 (90.8698)  time: 0.3522  data: 0.0013  max mem: 2500
Train: Epoch[2/5]  [2600/4579]  eta: 0:11:34  Lr: 0.001875  Loss: -0.2022  Acc@1: 68.7500 (61.7407)  Acc@5: 93.7500 (90.8689)  time: 0.3509  data: 0.0012  max mem: 2500
Train: Epoch[2/5]  [2610/4579]  eta: 0:11:30  Lr: 0.001875  Loss: -0.0804  Acc@1: 68.7500 (61.7508)  Acc@5: 93.7500 (90.8680)  time: 0.3518  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [2620/4579]  eta: 0:11:27  Lr: 0.001875  Loss: 0.0992  Acc@1: 68.7500 (61.7655)  Acc@5: 93.7500 (90.8837)  time: 0.3495  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [2630/4579]  eta: 0:11:23  Lr: 0.001875  Loss: 0.1273  Acc@1: 56.2500 (61.7446)  Acc@5: 93.7500 (90.8899)  time: 0.3492  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [2640/4579]  eta: 0:11:20  Lr: 0.001875  Loss: -0.3225  Acc@1: 56.2500 (61.7522)  Acc@5: 93.7500 (90.8936)  time: 0.3500  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [2650/4579]  eta: 0:11:16  Lr: 0.001875  Loss: -0.6369  Acc@1: 62.5000 (61.7597)  Acc@5: 93.7500 (90.9020)  time: 0.3490  data: 0.0009  max mem: 2500
Train: Epoch[2/5]  [2660/4579]  eta: 0:11:13  Lr: 0.001875  Loss: 0.0723  Acc@1: 62.5000 (61.7461)  Acc@5: 93.7500 (90.9127)  time: 0.3503  data: 0.0010  max mem: 2500
Train: Epoch[2/5]  [2670/4579]  eta: 0:11:09  Lr: 0.001875  Loss: 0.0180  Acc@1: 56.2500 (61.7395)  Acc@5: 93.7500 (90.9046)  time: 0.3488  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [2680/4579]  eta: 0:11:05  Lr: 0.001875  Loss: 0.0543  Acc@1: 56.2500 (61.7424)  Acc@5: 87.5000 (90.9036)  time: 0.3470  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [2690/4579]  eta: 0:11:02  Lr: 0.001875  Loss: 0.0892  Acc@1: 56.2500 (61.7173)  Acc@5: 87.5000 (90.8933)  time: 0.3483  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [2700/4579]  eta: 0:10:58  Lr: 0.001875  Loss: -0.4032  Acc@1: 62.5000 (61.7387)  Acc@5: 87.5000 (90.8853)  time: 0.3487  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [2710/4579]  eta: 0:10:55  Lr: 0.001875  Loss: -0.1296  Acc@1: 68.7500 (61.7438)  Acc@5: 87.5000 (90.8844)  time: 0.3482  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [2720/4579]  eta: 0:10:51  Lr: 0.001875  Loss: -0.2350  Acc@1: 62.5000 (61.7650)  Acc@5: 87.5000 (90.8811)  time: 0.3480  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [2730/4579]  eta: 0:10:48  Lr: 0.001875  Loss: 0.0832  Acc@1: 62.5000 (61.7700)  Acc@5: 93.7500 (90.8916)  time: 0.3479  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [2740/4579]  eta: 0:10:44  Lr: 0.001875  Loss: 0.0431  Acc@1: 62.5000 (61.7544)  Acc@5: 93.7500 (90.8747)  time: 0.3485  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [2750/4579]  eta: 0:10:41  Lr: 0.001875  Loss: 0.7498  Acc@1: 56.2500 (61.7321)  Acc@5: 87.5000 (90.8670)  time: 0.3499  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [2760/4579]  eta: 0:10:37  Lr: 0.001875  Loss: -1.0183  Acc@1: 62.5000 (61.7598)  Acc@5: 93.7500 (90.8819)  time: 0.3510  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2770/4579]  eta: 0:10:34  Lr: 0.001875  Loss: 0.1332  Acc@1: 62.5000 (61.7444)  Acc@5: 87.5000 (90.8652)  time: 0.3516  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [2780/4579]  eta: 0:10:30  Lr: 0.001875  Loss: 0.1943  Acc@1: 62.5000 (61.7584)  Acc@5: 87.5000 (90.8643)  time: 0.3509  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [2790/4579]  eta: 0:10:27  Lr: 0.001875  Loss: -0.0552  Acc@1: 62.5000 (61.7543)  Acc@5: 87.5000 (90.8613)  time: 0.3507  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [2800/4579]  eta: 0:10:23  Lr: 0.001875  Loss: -0.1667  Acc@1: 56.2500 (61.7614)  Acc@5: 87.5000 (90.8649)  time: 0.3498  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [2810/4579]  eta: 0:10:20  Lr: 0.001875  Loss: -0.6580  Acc@1: 62.5000 (61.7863)  Acc@5: 93.7500 (90.8796)  time: 0.3483  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [2820/4579]  eta: 0:10:16  Lr: 0.001875  Loss: -0.4806  Acc@1: 68.7500 (61.8021)  Acc@5: 93.7500 (90.8765)  time: 0.3483  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [2830/4579]  eta: 0:10:13  Lr: 0.001875  Loss: -0.2577  Acc@1: 62.5000 (61.8090)  Acc@5: 93.7500 (90.8800)  time: 0.3506  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [2840/4579]  eta: 0:10:09  Lr: 0.001875  Loss: -0.3584  Acc@1: 62.5000 (61.7960)  Acc@5: 93.7500 (90.8725)  time: 0.3521  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [2850/4579]  eta: 0:10:06  Lr: 0.001875  Loss: -0.4982  Acc@1: 62.5000 (61.8116)  Acc@5: 93.7500 (90.8782)  time: 0.3497  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [2860/4579]  eta: 0:10:02  Lr: 0.001875  Loss: 0.3144  Acc@1: 68.7500 (61.8250)  Acc@5: 93.7500 (90.8729)  time: 0.3497  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [2870/4579]  eta: 0:09:59  Lr: 0.001875  Loss: 0.4777  Acc@1: 62.5000 (61.8404)  Acc@5: 93.7500 (90.8851)  time: 0.3504  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [2880/4579]  eta: 0:09:55  Lr: 0.001875  Loss: 0.0349  Acc@1: 62.5000 (61.8448)  Acc@5: 93.7500 (90.8864)  time: 0.3489  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [2890/4579]  eta: 0:09:52  Lr: 0.001875  Loss: -0.4310  Acc@1: 62.5000 (61.8385)  Acc@5: 93.7500 (90.8963)  time: 0.3481  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [2900/4579]  eta: 0:09:48  Lr: 0.001875  Loss: -0.1231  Acc@1: 62.5000 (61.8364)  Acc@5: 93.7500 (90.8975)  time: 0.3505  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [2910/4579]  eta: 0:09:45  Lr: 0.001875  Loss: -0.4050  Acc@1: 62.5000 (61.8258)  Acc@5: 93.7500 (90.9009)  time: 0.3509  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [2920/4579]  eta: 0:09:41  Lr: 0.001875  Loss: -0.1643  Acc@1: 62.5000 (61.8346)  Acc@5: 87.5000 (90.8999)  time: 0.3484  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [2930/4579]  eta: 0:09:38  Lr: 0.001875  Loss: -0.1519  Acc@1: 62.5000 (61.8347)  Acc@5: 87.5000 (90.8883)  time: 0.3478  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [2940/4579]  eta: 0:09:34  Lr: 0.001875  Loss: 0.0758  Acc@1: 62.5000 (61.8327)  Acc@5: 93.7500 (90.8917)  time: 0.3489  data: 0.0010  max mem: 2500
Train: Epoch[2/5]  [2950/4579]  eta: 0:09:31  Lr: 0.001875  Loss: 0.1924  Acc@1: 62.5000 (61.8329)  Acc@5: 93.7500 (90.8887)  time: 0.3495  data: 0.0010  max mem: 2500
Train: Epoch[2/5]  [2960/4579]  eta: 0:09:27  Lr: 0.001875  Loss: -0.6304  Acc@1: 62.5000 (61.8478)  Acc@5: 87.5000 (90.8857)  time: 0.3483  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [2970/4579]  eta: 0:09:24  Lr: 0.001875  Loss: -0.9332  Acc@1: 68.7500 (61.8689)  Acc@5: 87.5000 (90.8848)  time: 0.3474  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [2980/4579]  eta: 0:09:20  Lr: 0.001875  Loss: -0.1969  Acc@1: 62.5000 (61.8668)  Acc@5: 93.7500 (90.8965)  time: 0.3479  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [2990/4579]  eta: 0:09:17  Lr: 0.001875  Loss: -0.3359  Acc@1: 62.5000 (61.8669)  Acc@5: 93.7500 (90.8977)  time: 0.3488  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [3000/4579]  eta: 0:09:13  Lr: 0.001875  Loss: -0.5076  Acc@1: 62.5000 (61.8773)  Acc@5: 87.5000 (90.9009)  time: 0.3487  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [3010/4579]  eta: 0:09:10  Lr: 0.001875  Loss: -0.2667  Acc@1: 62.5000 (61.8794)  Acc@5: 93.7500 (90.8980)  time: 0.3493  data: 0.0013  max mem: 2500
Train: Epoch[2/5]  [3020/4579]  eta: 0:09:06  Lr: 0.001875  Loss: -0.5387  Acc@1: 62.5000 (61.8731)  Acc@5: 93.7500 (90.9012)  time: 0.3492  data: 0.0012  max mem: 2500
Train: Epoch[2/5]  [3030/4579]  eta: 0:09:02  Lr: 0.001875  Loss: -0.0595  Acc@1: 62.5000 (61.8979)  Acc@5: 93.7500 (90.8982)  time: 0.3486  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [3040/4579]  eta: 0:08:59  Lr: 0.001875  Loss: -0.5039  Acc@1: 68.7500 (61.9122)  Acc@5: 93.7500 (90.8973)  time: 0.3485  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [3050/4579]  eta: 0:08:55  Lr: 0.001875  Loss: 0.0022  Acc@1: 62.5000 (61.9080)  Acc@5: 93.7500 (90.8964)  time: 0.3489  data: 0.0014  max mem: 2500
Train: Epoch[2/5]  [3060/4579]  eta: 0:08:52  Lr: 0.001875  Loss: -0.3769  Acc@1: 62.5000 (61.9262)  Acc@5: 93.7500 (90.9098)  time: 0.3482  data: 0.0013  max mem: 2500
Train: Epoch[2/5]  [3070/4579]  eta: 0:08:48  Lr: 0.001875  Loss: -0.9956  Acc@1: 62.5000 (61.9383)  Acc@5: 93.7500 (90.9089)  time: 0.3488  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [3080/4579]  eta: 0:08:45  Lr: 0.001875  Loss: -0.2160  Acc@1: 68.7500 (61.9421)  Acc@5: 93.7500 (90.9060)  time: 0.3524  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [3090/4579]  eta: 0:08:41  Lr: 0.001875  Loss: -0.3239  Acc@1: 68.7500 (61.9480)  Acc@5: 87.5000 (90.9071)  time: 0.3521  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [3100/4579]  eta: 0:08:38  Lr: 0.001875  Loss: -0.4515  Acc@1: 62.5000 (61.9478)  Acc@5: 93.7500 (90.9082)  time: 0.3521  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [3110/4579]  eta: 0:08:34  Lr: 0.001875  Loss: 0.0607  Acc@1: 56.2500 (61.9355)  Acc@5: 87.5000 (90.8972)  time: 0.3540  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [3120/4579]  eta: 0:08:31  Lr: 0.001875  Loss: -0.2053  Acc@1: 56.2500 (61.9333)  Acc@5: 93.7500 (90.9004)  time: 0.3525  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [3130/4579]  eta: 0:08:27  Lr: 0.001875  Loss: -0.4680  Acc@1: 62.5000 (61.9371)  Acc@5: 93.7500 (90.8955)  time: 0.3510  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [3140/4579]  eta: 0:08:24  Lr: 0.001875  Loss: -0.3636  Acc@1: 68.7500 (61.9528)  Acc@5: 93.7500 (90.8986)  time: 0.3528  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [3150/4579]  eta: 0:08:20  Lr: 0.001875  Loss: 0.3207  Acc@1: 62.5000 (61.9466)  Acc@5: 93.7500 (90.8977)  time: 0.3543  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [3160/4579]  eta: 0:08:17  Lr: 0.001875  Loss: -0.7899  Acc@1: 62.5000 (61.9622)  Acc@5: 93.7500 (90.9087)  time: 0.3510  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [3170/4579]  eta: 0:08:13  Lr: 0.001875  Loss: -0.3108  Acc@1: 62.5000 (61.9659)  Acc@5: 93.7500 (90.9000)  time: 0.3485  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [3180/4579]  eta: 0:08:10  Lr: 0.001875  Loss: 0.2760  Acc@1: 62.5000 (61.9695)  Acc@5: 93.7500 (90.9109)  time: 0.3497  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [3190/4579]  eta: 0:08:06  Lr: 0.001875  Loss: -0.4542  Acc@1: 62.5000 (61.9751)  Acc@5: 93.7500 (90.9159)  time: 0.3501  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [3200/4579]  eta: 0:08:03  Lr: 0.001875  Loss: -0.2877  Acc@1: 62.5000 (61.9943)  Acc@5: 93.7500 (90.9228)  time: 0.3504  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [3210/4579]  eta: 0:07:59  Lr: 0.001875  Loss: -0.6353  Acc@1: 62.5000 (61.9998)  Acc@5: 93.7500 (90.9316)  time: 0.3508  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [3220/4579]  eta: 0:07:56  Lr: 0.001875  Loss: -0.3192  Acc@1: 68.7500 (62.0091)  Acc@5: 93.7500 (90.9403)  time: 0.3494  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [3230/4579]  eta: 0:07:52  Lr: 0.001875  Loss: -0.0131  Acc@1: 62.5000 (61.9971)  Acc@5: 93.7500 (90.9451)  time: 0.3487  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [3240/4579]  eta: 0:07:49  Lr: 0.001875  Loss: 0.3307  Acc@1: 56.2500 (62.0025)  Acc@5: 93.7500 (90.9384)  time: 0.3492  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [3250/4579]  eta: 0:07:45  Lr: 0.001875  Loss: 0.1392  Acc@1: 68.7500 (62.0040)  Acc@5: 87.5000 (90.9316)  time: 0.3496  data: 0.0012  max mem: 2500
Train: Epoch[2/5]  [3260/4579]  eta: 0:07:42  Lr: 0.001875  Loss: -0.4406  Acc@1: 62.5000 (62.0036)  Acc@5: 93.7500 (90.9269)  time: 0.3504  data: 0.0010  max mem: 2500
Train: Epoch[2/5]  [3270/4579]  eta: 0:07:38  Lr: 0.001875  Loss: -0.0983  Acc@1: 62.5000 (61.9917)  Acc@5: 93.7500 (90.9240)  time: 0.3523  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [3280/4579]  eta: 0:07:35  Lr: 0.001875  Loss: -0.1632  Acc@1: 62.5000 (61.9914)  Acc@5: 87.5000 (90.9098)  time: 0.3518  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3290/4579]  eta: 0:07:31  Lr: 0.001875  Loss: -0.1069  Acc@1: 62.5000 (61.9948)  Acc@5: 87.5000 (90.9127)  time: 0.3504  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [3300/4579]  eta: 0:07:28  Lr: 0.001875  Loss: -0.3280  Acc@1: 62.5000 (61.9964)  Acc@5: 93.7500 (90.9194)  time: 0.3540  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [3310/4579]  eta: 0:07:24  Lr: 0.001875  Loss: 0.5153  Acc@1: 62.5000 (62.0054)  Acc@5: 93.7500 (90.9166)  time: 0.3553  data: 0.0017  max mem: 2500
Train: Epoch[2/5]  [3320/4579]  eta: 0:07:21  Lr: 0.001875  Loss: -0.7341  Acc@1: 68.7500 (62.0295)  Acc@5: 93.7500 (90.9195)  time: 0.3530  data: 0.0014  max mem: 2500
Train: Epoch[2/5]  [3330/4579]  eta: 0:07:17  Lr: 0.001875  Loss: -0.3567  Acc@1: 68.7500 (62.0347)  Acc@5: 93.7500 (90.9149)  time: 0.3507  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [3340/4579]  eta: 0:07:14  Lr: 0.001875  Loss: -0.3932  Acc@1: 68.7500 (62.0454)  Acc@5: 93.7500 (90.9178)  time: 0.3489  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [3350/4579]  eta: 0:07:10  Lr: 0.001875  Loss: 0.1264  Acc@1: 62.5000 (62.0524)  Acc@5: 93.7500 (90.9244)  time: 0.3493  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [3360/4579]  eta: 0:07:07  Lr: 0.001875  Loss: 0.2118  Acc@1: 62.5000 (62.0463)  Acc@5: 93.7500 (90.9123)  time: 0.3495  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [3370/4579]  eta: 0:07:03  Lr: 0.001875  Loss: 0.1662  Acc@1: 62.5000 (62.0643)  Acc@5: 87.5000 (90.9115)  time: 0.3496  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [3380/4579]  eta: 0:07:00  Lr: 0.001875  Loss: -0.5585  Acc@1: 62.5000 (62.0545)  Acc@5: 87.5000 (90.8884)  time: 0.3498  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [3390/4579]  eta: 0:06:56  Lr: 0.001875  Loss: 0.2044  Acc@1: 56.2500 (62.0448)  Acc@5: 87.5000 (90.8803)  time: 0.3496  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [3400/4579]  eta: 0:06:53  Lr: 0.001875  Loss: 0.2638  Acc@1: 62.5000 (62.0498)  Acc@5: 87.5000 (90.8814)  time: 0.3496  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [3410/4579]  eta: 0:06:49  Lr: 0.001875  Loss: -0.4075  Acc@1: 62.5000 (62.0419)  Acc@5: 87.5000 (90.8751)  time: 0.3509  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [3420/4579]  eta: 0:06:46  Lr: 0.001875  Loss: -0.2265  Acc@1: 62.5000 (62.0360)  Acc@5: 93.7500 (90.8799)  time: 0.3525  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [3430/4579]  eta: 0:06:42  Lr: 0.001875  Loss: -0.1217  Acc@1: 56.2500 (62.0318)  Acc@5: 93.7500 (90.8809)  time: 0.3501  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [3440/4579]  eta: 0:06:39  Lr: 0.001875  Loss: -0.2537  Acc@1: 56.2500 (62.0314)  Acc@5: 93.7500 (90.8711)  time: 0.3500  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [3450/4579]  eta: 0:06:35  Lr: 0.001875  Loss: -0.2849  Acc@1: 56.2500 (62.0382)  Acc@5: 87.5000 (90.8704)  time: 0.3505  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [3460/4579]  eta: 0:06:32  Lr: 0.001875  Loss: -0.2143  Acc@1: 56.2500 (62.0269)  Acc@5: 93.7500 (90.8733)  time: 0.3494  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [3470/4579]  eta: 0:06:28  Lr: 0.001875  Loss: 0.3643  Acc@1: 56.2500 (62.0030)  Acc@5: 87.5000 (90.8582)  time: 0.3495  data: 0.0011  max mem: 2500
Train: Epoch[2/5]  [3480/4579]  eta: 0:06:25  Lr: 0.001875  Loss: -0.0131  Acc@1: 50.0000 (61.9775)  Acc@5: 87.5000 (90.8485)  time: 0.3492  data: 0.0012  max mem: 2500
Train: Epoch[2/5]  [3490/4579]  eta: 0:06:21  Lr: 0.001875  Loss: -0.4450  Acc@1: 62.5000 (61.9898)  Acc@5: 93.7500 (90.8551)  time: 0.3503  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [3500/4579]  eta: 0:06:18  Lr: 0.001875  Loss: 0.1843  Acc@1: 62.5000 (61.9627)  Acc@5: 93.7500 (90.8455)  time: 0.3516  data: 0.0009  max mem: 2500
Train: Epoch[2/5]  [3510/4579]  eta: 0:06:14  Lr: 0.001875  Loss: 0.3533  Acc@1: 56.2500 (61.9588)  Acc@5: 93.7500 (90.8466)  time: 0.3499  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [3520/4579]  eta: 0:06:11  Lr: 0.001875  Loss: 0.2088  Acc@1: 56.2500 (61.9604)  Acc@5: 93.7500 (90.8460)  time: 0.3484  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [3530/4579]  eta: 0:06:07  Lr: 0.001875  Loss: -0.4679  Acc@1: 62.5000 (61.9619)  Acc@5: 93.7500 (90.8471)  time: 0.3494  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [3540/4579]  eta: 0:06:04  Lr: 0.001875  Loss: -0.0534  Acc@1: 62.5000 (61.9793)  Acc@5: 93.7500 (90.8571)  time: 0.3497  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [3550/4579]  eta: 0:06:00  Lr: 0.001875  Loss: -0.3480  Acc@1: 62.5000 (61.9755)  Acc@5: 93.7500 (90.8582)  time: 0.3507  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [3560/4579]  eta: 0:05:57  Lr: 0.001875  Loss: 0.0486  Acc@1: 62.5000 (61.9910)  Acc@5: 93.7500 (90.8558)  time: 0.3517  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [3570/4579]  eta: 0:05:53  Lr: 0.001875  Loss: -0.2937  Acc@1: 68.7500 (62.0047)  Acc@5: 87.5000 (90.8534)  time: 0.3527  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [3580/4579]  eta: 0:05:50  Lr: 0.001875  Loss: -0.0807  Acc@1: 62.5000 (62.0131)  Acc@5: 87.5000 (90.8493)  time: 0.3542  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [3590/4579]  eta: 0:05:46  Lr: 0.001875  Loss: -0.0689  Acc@1: 62.5000 (62.0127)  Acc@5: 87.5000 (90.8452)  time: 0.3520  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [3600/4579]  eta: 0:05:43  Lr: 0.001875  Loss: 0.2159  Acc@1: 56.2500 (61.9967)  Acc@5: 87.5000 (90.8446)  time: 0.3519  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [3610/4579]  eta: 0:05:39  Lr: 0.001875  Loss: -0.3183  Acc@1: 62.5000 (62.0084)  Acc@5: 93.7500 (90.8388)  time: 0.3519  data: 0.0022  max mem: 2500
Train: Epoch[2/5]  [3620/4579]  eta: 0:05:36  Lr: 0.001875  Loss: 0.0488  Acc@1: 62.5000 (61.9977)  Acc@5: 93.7500 (90.8433)  time: 0.3488  data: 0.0018  max mem: 2500
Train: Epoch[2/5]  [3630/4579]  eta: 0:05:32  Lr: 0.001875  Loss: -0.1725  Acc@1: 56.2500 (61.9905)  Acc@5: 93.7500 (90.8427)  time: 0.3497  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [3640/4579]  eta: 0:05:29  Lr: 0.001875  Loss: -0.5025  Acc@1: 62.5000 (62.0056)  Acc@5: 93.7500 (90.8439)  time: 0.3506  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [3650/4579]  eta: 0:05:25  Lr: 0.001875  Loss: -0.3160  Acc@1: 68.7500 (62.0190)  Acc@5: 93.7500 (90.8535)  time: 0.3505  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [3660/4579]  eta: 0:05:22  Lr: 0.001875  Loss: 0.6598  Acc@1: 62.5000 (62.0066)  Acc@5: 93.7500 (90.8410)  time: 0.3521  data: 0.0019  max mem: 2500
Train: Epoch[2/5]  [3670/4579]  eta: 0:05:18  Lr: 0.001875  Loss: -0.3418  Acc@1: 56.2500 (62.0131)  Acc@5: 87.5000 (90.8353)  time: 0.3514  data: 0.0017  max mem: 2500
Train: Epoch[2/5]  [3680/4579]  eta: 0:05:15  Lr: 0.001875  Loss: -0.0998  Acc@1: 62.5000 (62.0127)  Acc@5: 87.5000 (90.8347)  time: 0.3493  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [3690/4579]  eta: 0:05:11  Lr: 0.001875  Loss: -0.2123  Acc@1: 68.7500 (62.0157)  Acc@5: 93.7500 (90.8443)  time: 0.3500  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [3700/4579]  eta: 0:05:08  Lr: 0.001875  Loss: -0.5176  Acc@1: 62.5000 (62.0187)  Acc@5: 93.7500 (90.8403)  time: 0.3515  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [3710/4579]  eta: 0:05:04  Lr: 0.001875  Loss: -0.1900  Acc@1: 62.5000 (62.0301)  Acc@5: 93.7500 (90.8431)  time: 0.3519  data: 0.0009  max mem: 2500
Train: Epoch[2/5]  [3720/4579]  eta: 0:05:01  Lr: 0.001875  Loss: -0.0202  Acc@1: 68.7500 (62.0314)  Acc@5: 93.7500 (90.8375)  time: 0.3514  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [3730/4579]  eta: 0:04:57  Lr: 0.001875  Loss: -0.1101  Acc@1: 68.7500 (62.0360)  Acc@5: 93.7500 (90.8403)  time: 0.3533  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [3740/4579]  eta: 0:04:54  Lr: 0.001875  Loss: -0.4140  Acc@1: 62.5000 (62.0322)  Acc@5: 93.7500 (90.8363)  time: 0.3530  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [3750/4579]  eta: 0:04:50  Lr: 0.001875  Loss: -0.2259  Acc@1: 68.7500 (62.0501)  Acc@5: 93.7500 (90.8458)  time: 0.3498  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [3760/4579]  eta: 0:04:47  Lr: 0.001875  Loss: 0.1810  Acc@1: 68.7500 (62.0679)  Acc@5: 93.7500 (90.8452)  time: 0.3489  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [3770/4579]  eta: 0:04:43  Lr: 0.001875  Loss: -0.3637  Acc@1: 62.5000 (62.0707)  Acc@5: 93.7500 (90.8479)  time: 0.3497  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [3780/4579]  eta: 0:04:40  Lr: 0.001875  Loss: -0.4532  Acc@1: 62.5000 (62.0636)  Acc@5: 93.7500 (90.8556)  time: 0.3503  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [3790/4579]  eta: 0:04:36  Lr: 0.001875  Loss: -0.1452  Acc@1: 62.5000 (62.0631)  Acc@5: 93.7500 (90.8599)  time: 0.3488  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [3800/4579]  eta: 0:04:33  Lr: 0.001875  Loss: -0.0452  Acc@1: 62.5000 (62.0544)  Acc@5: 93.7500 (90.8692)  time: 0.3519  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [3810/4579]  eta: 0:04:29  Lr: 0.001875  Loss: -0.6176  Acc@1: 62.5000 (62.0457)  Acc@5: 93.7500 (90.8521)  time: 0.3526  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [3820/4579]  eta: 0:04:26  Lr: 0.001875  Loss: -0.0991  Acc@1: 62.5000 (62.0584)  Acc@5: 93.7500 (90.8597)  time: 0.3501  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [3830/4579]  eta: 0:04:22  Lr: 0.001875  Loss: 0.0585  Acc@1: 68.7500 (62.0611)  Acc@5: 87.5000 (90.8510)  time: 0.3506  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [3840/4579]  eta: 0:04:19  Lr: 0.001875  Loss: -0.1299  Acc@1: 62.5000 (62.0525)  Acc@5: 87.5000 (90.8487)  time: 0.3518  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [3850/4579]  eta: 0:04:15  Lr: 0.001875  Loss: 0.1515  Acc@1: 62.5000 (62.0699)  Acc@5: 87.5000 (90.8482)  time: 0.3508  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [3860/4579]  eta: 0:04:12  Lr: 0.001875  Loss: 0.2880  Acc@1: 68.7500 (62.0840)  Acc@5: 87.5000 (90.8460)  time: 0.3488  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [3870/4579]  eta: 0:04:08  Lr: 0.001875  Loss: -0.0937  Acc@1: 68.7500 (62.1044)  Acc@5: 93.7500 (90.8535)  time: 0.3499  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [3880/4579]  eta: 0:04:05  Lr: 0.001875  Loss: -0.0160  Acc@1: 68.7500 (62.1248)  Acc@5: 93.7500 (90.8658)  time: 0.3516  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [3890/4579]  eta: 0:04:01  Lr: 0.001875  Loss: -0.2737  Acc@1: 68.7500 (62.1273)  Acc@5: 93.7500 (90.8603)  time: 0.3500  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [3900/4579]  eta: 0:03:58  Lr: 0.001875  Loss: -0.1912  Acc@1: 62.5000 (62.1123)  Acc@5: 87.5000 (90.8645)  time: 0.3481  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [3910/4579]  eta: 0:03:54  Lr: 0.001875  Loss: -0.1810  Acc@1: 62.5000 (62.1181)  Acc@5: 93.7500 (90.8671)  time: 0.3506  data: 0.0013  max mem: 2500
Train: Epoch[2/5]  [3920/4579]  eta: 0:03:51  Lr: 0.001875  Loss: -0.1132  Acc@1: 62.5000 (62.1174)  Acc@5: 93.7500 (90.8697)  time: 0.3560  data: 0.0011  max mem: 2500
Train: Epoch[2/5]  [3930/4579]  eta: 0:03:47  Lr: 0.001875  Loss: -0.3667  Acc@1: 62.5000 (62.1136)  Acc@5: 93.7500 (90.8675)  time: 0.3552  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [3940/4579]  eta: 0:03:44  Lr: 0.001875  Loss: -0.5275  Acc@1: 62.5000 (62.1241)  Acc@5: 93.7500 (90.8716)  time: 0.3512  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [3950/4579]  eta: 0:03:40  Lr: 0.001875  Loss: -0.2891  Acc@1: 68.7500 (62.1330)  Acc@5: 93.7500 (90.8726)  time: 0.3511  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [3960/4579]  eta: 0:03:37  Lr: 0.001875  Loss: -0.0538  Acc@1: 62.5000 (62.1324)  Acc@5: 93.7500 (90.8672)  time: 0.3506  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [3970/4579]  eta: 0:03:33  Lr: 0.001875  Loss: -0.5748  Acc@1: 68.7500 (62.1537)  Acc@5: 93.7500 (90.8745)  time: 0.3503  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [3980/4579]  eta: 0:03:30  Lr: 0.001875  Loss: -0.4118  Acc@1: 68.7500 (62.1483)  Acc@5: 93.7500 (90.8723)  time: 0.3497  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [3990/4579]  eta: 0:03:26  Lr: 0.001875  Loss: -0.0512  Acc@1: 56.2500 (62.1429)  Acc@5: 93.7500 (90.8732)  time: 0.3489  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [4000/4579]  eta: 0:03:22  Lr: 0.001875  Loss: -0.7499  Acc@1: 56.2500 (62.1454)  Acc@5: 93.7500 (90.8804)  time: 0.3484  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [4010/4579]  eta: 0:03:19  Lr: 0.001875  Loss: 0.0847  Acc@1: 62.5000 (62.1572)  Acc@5: 93.7500 (90.8751)  time: 0.3497  data: 0.0009  max mem: 2500
Train: Epoch[2/5]  [4020/4579]  eta: 0:03:15  Lr: 0.001875  Loss: 0.2771  Acc@1: 62.5000 (62.1518)  Acc@5: 93.7500 (90.8822)  time: 0.3490  data: 0.0009  max mem: 2500
Train: Epoch[2/5]  [4030/4579]  eta: 0:03:12  Lr: 0.001875  Loss: -0.3200  Acc@1: 62.5000 (62.1697)  Acc@5: 93.7500 (90.8847)  time: 0.3485  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [4040/4579]  eta: 0:03:08  Lr: 0.001875  Loss: -0.2383  Acc@1: 62.5000 (62.1690)  Acc@5: 93.7500 (90.8841)  time: 0.3509  data: 0.0009  max mem: 2500
Train: Epoch[2/5]  [4050/4579]  eta: 0:03:05  Lr: 0.001875  Loss: -0.4027  Acc@1: 62.5000 (62.1806)  Acc@5: 93.7500 (90.8865)  time: 0.3502  data: 0.0009  max mem: 2500
Train: Epoch[2/5]  [4060/4579]  eta: 0:03:01  Lr: 0.001875  Loss: -0.1775  Acc@1: 68.7500 (62.1907)  Acc@5: 93.7500 (90.8920)  time: 0.3482  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [4070/4579]  eta: 0:02:58  Lr: 0.001875  Loss: -0.2274  Acc@1: 62.5000 (62.1883)  Acc@5: 93.7500 (90.8975)  time: 0.3484  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [4080/4579]  eta: 0:02:54  Lr: 0.001875  Loss: -0.3424  Acc@1: 62.5000 (62.1952)  Acc@5: 93.7500 (90.8984)  time: 0.3486  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [4090/4579]  eta: 0:02:51  Lr: 0.001875  Loss: 0.0185  Acc@1: 62.5000 (62.2006)  Acc@5: 93.7500 (90.9008)  time: 0.3509  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [4100/4579]  eta: 0:02:47  Lr: 0.001875  Loss: 0.0940  Acc@1: 62.5000 (62.2043)  Acc@5: 93.7500 (90.9001)  time: 0.3529  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [4110/4579]  eta: 0:02:44  Lr: 0.001875  Loss: -0.0923  Acc@1: 62.5000 (62.2127)  Acc@5: 87.5000 (90.8979)  time: 0.3510  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [4120/4579]  eta: 0:02:40  Lr: 0.001875  Loss: -0.6642  Acc@1: 62.5000 (62.2179)  Acc@5: 93.7500 (90.9018)  time: 0.3495  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [4130/4579]  eta: 0:02:37  Lr: 0.001875  Loss: 0.2177  Acc@1: 62.5000 (62.2156)  Acc@5: 93.7500 (90.9026)  time: 0.3503  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [4140/4579]  eta: 0:02:33  Lr: 0.001875  Loss: -0.2908  Acc@1: 68.7500 (62.2374)  Acc@5: 93.7500 (90.9065)  time: 0.3512  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [4150/4579]  eta: 0:02:30  Lr: 0.001875  Loss: -0.3426  Acc@1: 62.5000 (62.2184)  Acc@5: 93.7500 (90.9073)  time: 0.3505  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [4160/4579]  eta: 0:02:26  Lr: 0.001875  Loss: -0.5395  Acc@1: 56.2500 (62.2311)  Acc@5: 93.7500 (90.9081)  time: 0.3532  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [4170/4579]  eta: 0:02:23  Lr: 0.001875  Loss: -0.1904  Acc@1: 62.5000 (62.2303)  Acc@5: 93.7500 (90.9120)  time: 0.3535  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [4180/4579]  eta: 0:02:19  Lr: 0.001875  Loss: -0.2277  Acc@1: 62.5000 (62.2444)  Acc@5: 93.7500 (90.9098)  time: 0.3517  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [4190/4579]  eta: 0:02:16  Lr: 0.001875  Loss: -0.2055  Acc@1: 62.5000 (62.2524)  Acc@5: 87.5000 (90.9121)  time: 0.3525  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [4200/4579]  eta: 0:02:12  Lr: 0.001875  Loss: -0.0336  Acc@1: 62.5000 (62.2486)  Acc@5: 93.7500 (90.9114)  time: 0.3516  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [4210/4579]  eta: 0:02:09  Lr: 0.001875  Loss: -0.1246  Acc@1: 56.2500 (62.2328)  Acc@5: 87.5000 (90.9048)  time: 0.3503  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [4220/4579]  eta: 0:02:05  Lr: 0.001875  Loss: -0.2924  Acc@1: 56.2500 (62.2438)  Acc@5: 93.7500 (90.9145)  time: 0.3502  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [4230/4579]  eta: 0:02:02  Lr: 0.001875  Loss: -0.3064  Acc@1: 68.7500 (62.2696)  Acc@5: 93.7500 (90.9153)  time: 0.3504  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [4240/4579]  eta: 0:01:58  Lr: 0.001875  Loss: -0.1363  Acc@1: 62.5000 (62.2642)  Acc@5: 93.7500 (90.9116)  time: 0.3489  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [4250/4579]  eta: 0:01:55  Lr: 0.001875  Loss: 0.0960  Acc@1: 62.5000 (62.2633)  Acc@5: 87.5000 (90.9051)  time: 0.3509  data: 0.0015  max mem: 2500
Train: Epoch[2/5]  [4260/4579]  eta: 0:01:51  Lr: 0.001875  Loss: -0.1258  Acc@1: 56.2500 (62.2565)  Acc@5: 87.5000 (90.9044)  time: 0.3530  data: 0.0014  max mem: 2500
Train: Epoch[2/5]  [4270/4579]  eta: 0:01:48  Lr: 0.001875  Loss: 0.0160  Acc@1: 56.2500 (62.2527)  Acc@5: 87.5000 (90.9082)  time: 0.3508  data: 0.0014  max mem: 2500
Train: Epoch[2/5]  [4280/4579]  eta: 0:01:44  Lr: 0.001875  Loss: -0.4506  Acc@1: 62.5000 (62.2577)  Acc@5: 87.5000 (90.9031)  time: 0.3490  data: 0.0013  max mem: 2500
Train: Epoch[2/5]  [4290/4579]  eta: 0:01:41  Lr: 0.001875  Loss: -0.4526  Acc@1: 62.5000 (62.2466)  Acc@5: 87.5000 (90.9025)  time: 0.3490  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [4300/4579]  eta: 0:01:37  Lr: 0.001875  Loss: -0.3922  Acc@1: 62.5000 (62.2472)  Acc@5: 87.5000 (90.8989)  time: 0.3506  data: 0.0012  max mem: 2500
Train: Epoch[2/5]  [4310/4579]  eta: 0:01:34  Lr: 0.001875  Loss: -0.6849  Acc@1: 56.2500 (62.2405)  Acc@5: 87.5000 (90.8997)  time: 0.3516  data: 0.0011  max mem: 2500
Train: Epoch[2/5]  [4320/4579]  eta: 0:01:30  Lr: 0.001875  Loss: -0.4468  Acc@1: 62.5000 (62.2440)  Acc@5: 87.5000 (90.8962)  time: 0.3520  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [4330/4579]  eta: 0:01:27  Lr: 0.001875  Loss: -0.1129  Acc@1: 62.5000 (62.2460)  Acc@5: 87.5000 (90.8884)  time: 0.3514  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [4340/4579]  eta: 0:01:23  Lr: 0.001875  Loss: -0.5535  Acc@1: 62.5000 (62.2581)  Acc@5: 87.5000 (90.8906)  time: 0.3498  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [4350/4579]  eta: 0:01:20  Lr: 0.001875  Loss: -0.2114  Acc@1: 62.5000 (62.2644)  Acc@5: 93.7500 (90.8943)  time: 0.3523  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [4360/4579]  eta: 0:01:16  Lr: 0.001875  Loss: 0.0305  Acc@1: 62.5000 (62.2549)  Acc@5: 87.5000 (90.8880)  time: 0.3533  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [4370/4579]  eta: 0:01:13  Lr: 0.001875  Loss: 0.1051  Acc@1: 62.5000 (62.2684)  Acc@5: 93.7500 (90.8945)  time: 0.3518  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [4380/4579]  eta: 0:01:09  Lr: 0.001875  Loss: -0.3852  Acc@1: 62.5000 (62.2632)  Acc@5: 93.7500 (90.9010)  time: 0.3514  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [4390/4579]  eta: 0:01:06  Lr: 0.001875  Loss: 0.1855  Acc@1: 62.5000 (62.2651)  Acc@5: 93.7500 (90.9018)  time: 0.3504  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [4400/4579]  eta: 0:01:02  Lr: 0.001875  Loss: -0.4087  Acc@1: 62.5000 (62.2671)  Acc@5: 93.7500 (90.9026)  time: 0.3501  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [4410/4579]  eta: 0:00:59  Lr: 0.001875  Loss: -0.1801  Acc@1: 62.5000 (62.2719)  Acc@5: 93.7500 (90.8992)  time: 0.3510  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [4420/4579]  eta: 0:00:55  Lr: 0.001875  Loss: -0.6879  Acc@1: 68.7500 (62.2795)  Acc@5: 93.7500 (90.9127)  time: 0.3508  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [4430/4579]  eta: 0:00:52  Lr: 0.001875  Loss: -0.0623  Acc@1: 68.7500 (62.2842)  Acc@5: 93.7500 (90.9120)  time: 0.3512  data: 0.0016  max mem: 2500
Train: Epoch[2/5]  [4440/4579]  eta: 0:00:48  Lr: 0.001875  Loss: -0.7125  Acc@1: 68.7500 (62.2973)  Acc@5: 93.7500 (90.9128)  time: 0.3518  data: 0.0021  max mem: 2500
Train: Epoch[2/5]  [4450/4579]  eta: 0:00:45  Lr: 0.001875  Loss: -0.3084  Acc@1: 68.7500 (62.3104)  Acc@5: 93.7500 (90.9108)  time: 0.3502  data: 0.0010  max mem: 2500
Train: Epoch[2/5]  [4460/4579]  eta: 0:00:41  Lr: 0.001875  Loss: 0.0052  Acc@1: 68.7500 (62.3305)  Acc@5: 93.7500 (90.9171)  time: 0.3490  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [4470/4579]  eta: 0:00:38  Lr: 0.001875  Loss: -0.5526  Acc@1: 68.7500 (62.3420)  Acc@5: 93.7500 (90.9262)  time: 0.3484  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [4480/4579]  eta: 0:00:34  Lr: 0.001875  Loss: -0.1112  Acc@1: 68.7500 (62.3535)  Acc@5: 93.7500 (90.9270)  time: 0.3494  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [4490/4579]  eta: 0:00:31  Lr: 0.001875  Loss: -0.2857  Acc@1: 68.7500 (62.3650)  Acc@5: 93.7500 (90.9193)  time: 0.3530  data: 0.0009  max mem: 2500
Train: Epoch[2/5]  [4500/4579]  eta: 0:00:27  Lr: 0.001875  Loss: -0.1689  Acc@1: 62.5000 (62.3584)  Acc@5: 87.5000 (90.9145)  time: 0.3536  data: 0.0009  max mem: 2500
Train: Epoch[2/5]  [4510/4579]  eta: 0:00:24  Lr: 0.001875  Loss: -0.1520  Acc@1: 62.5000 (62.3642)  Acc@5: 87.5000 (90.9180)  time: 0.3519  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [4520/4579]  eta: 0:00:20  Lr: 0.001875  Loss: -0.0544  Acc@1: 62.5000 (62.3645)  Acc@5: 93.7500 (90.9146)  time: 0.3541  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [4530/4579]  eta: 0:00:17  Lr: 0.001875  Loss: -0.2894  Acc@1: 62.5000 (62.3772)  Acc@5: 87.5000 (90.9085)  time: 0.3535  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [4540/4579]  eta: 0:00:13  Lr: 0.001875  Loss: -0.0839  Acc@1: 62.5000 (62.3816)  Acc@5: 87.5000 (90.9120)  time: 0.3487  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [4550/4579]  eta: 0:00:10  Lr: 0.001875  Loss: -0.4103  Acc@1: 68.7500 (62.3956)  Acc@5: 93.7500 (90.9113)  time: 0.3489  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [4560/4579]  eta: 0:00:06  Lr: 0.001875  Loss: 0.5108  Acc@1: 62.5000 (62.3890)  Acc@5: 87.5000 (90.9052)  time: 0.3503  data: 0.0010  max mem: 2500
Train: Epoch[2/5]  [4570/4579]  eta: 0:00:03  Lr: 0.001875  Loss: -0.1255  Acc@1: 62.5000 (62.3961)  Acc@5: 87.5000 (90.9046)  time: 0.3511  data: 0.0018  max mem: 2500
Train: Epoch[2/5]  [4578/4579]  eta: 0:00:00  Lr: 0.001875  Loss: -0.4856  Acc@1: 66.6667 (62.4077)  Acc@5: 93.7500 (90.9087)  time: 0.3449  data: 0.0015  max mem: 2500
Train: Epoch[2/5] Total time: 0:26:46 (0.3508 s / it)
{0: {0: 146514, 1: 0, 2: 0, 3: 0, 4: 0}, 1: {0: 146514, 1: 0, 2: 0, 3: 0, 4: 0}, 2: {0: 146514, 1: 0, 2: 0, 3: 0, 4: 0}, 3: {0: 146514, 1: 0, 2: 0, 3: 0, 4: 0}, 4: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 5: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 6: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 7: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 8: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 9: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 10: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 11: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 12: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 13: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 14: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 15: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 16: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 17: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 18: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 19: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}}
Averaged stats: Lr: 0.001875  Loss: -0.4856  Acc@1: 66.6667 (62.4077)  Acc@5: 93.7500 (90.9087)
Train: Epoch[3/5]  [   0/4579]  eta: 0:55:33  Lr: 0.001875  Loss: 0.2308  Acc@1: 56.2500 (56.2500)  Acc@5: 81.2500 (81.2500)  time: 0.7281  data: 0.3719  max mem: 2500
Train: Epoch[3/5]  [  10/4579]  eta: 0:29:17  Lr: 0.001875  Loss: -0.4319  Acc@1: 68.7500 (68.7500)  Acc@5: 93.7500 (94.3182)  time: 0.3846  data: 0.0342  max mem: 2500
Train: Epoch[3/5]  [  20/4579]  eta: 0:28:04  Lr: 0.001875  Loss: -0.0607  Acc@1: 68.7500 (67.2619)  Acc@5: 93.7500 (90.4762)  time: 0.3515  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [  30/4579]  eta: 0:27:37  Lr: 0.001875  Loss: 0.0970  Acc@1: 68.7500 (67.1371)  Acc@5: 87.5000 (90.5242)  time: 0.3532  data: 0.0010  max mem: 2500
Train: Epoch[3/5]  [  40/4579]  eta: 0:27:15  Lr: 0.001875  Loss: -0.8537  Acc@1: 62.5000 (66.9207)  Acc@5: 93.7500 (90.7012)  time: 0.3509  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [  50/4579]  eta: 0:27:02  Lr: 0.001875  Loss: -0.0343  Acc@1: 62.5000 (64.5833)  Acc@5: 87.5000 (90.4412)  time: 0.3487  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [  60/4579]  eta: 0:26:55  Lr: 0.001875  Loss: -0.1591  Acc@1: 62.5000 (64.9590)  Acc@5: 93.7500 (91.1885)  time: 0.3513  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [  70/4579]  eta: 0:26:46  Lr: 0.001875  Loss: -0.1029  Acc@1: 62.5000 (63.6444)  Acc@5: 87.5000 (90.7570)  time: 0.3514  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [  80/4579]  eta: 0:26:40  Lr: 0.001875  Loss: -0.6094  Acc@1: 56.2500 (63.6574)  Acc@5: 87.5000 (90.8179)  time: 0.3506  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [  90/4579]  eta: 0:26:34  Lr: 0.001875  Loss: -0.2907  Acc@1: 62.5000 (63.3242)  Acc@5: 87.5000 (90.6593)  time: 0.3509  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [ 100/4579]  eta: 0:26:28  Lr: 0.001875  Loss: -0.5096  Acc@1: 62.5000 (63.4901)  Acc@5: 93.7500 (91.0891)  time: 0.3506  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [ 110/4579]  eta: 0:26:22  Lr: 0.001875  Loss: -0.2726  Acc@1: 68.7500 (63.6824)  Acc@5: 93.7500 (91.2162)  time: 0.3501  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [ 120/4579]  eta: 0:26:19  Lr: 0.001875  Loss: -0.1379  Acc@1: 68.7500 (63.8946)  Acc@5: 93.7500 (91.4256)  time: 0.3515  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [ 130/4579]  eta: 0:26:14  Lr: 0.001875  Loss: -0.3682  Acc@1: 62.5000 (63.8359)  Acc@5: 93.7500 (91.2691)  time: 0.3515  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [ 140/4579]  eta: 0:26:08  Lr: 0.001875  Loss: -0.2089  Acc@1: 62.5000 (63.9184)  Acc@5: 93.7500 (91.4007)  time: 0.3489  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [ 150/4579]  eta: 0:26:03  Lr: 0.001875  Loss: -0.5437  Acc@1: 62.5000 (64.0315)  Acc@5: 93.7500 (91.3079)  time: 0.3476  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [ 160/4579]  eta: 0:25:58  Lr: 0.001875  Loss: -0.0358  Acc@1: 68.7500 (64.2857)  Acc@5: 87.5000 (91.3432)  time: 0.3471  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [ 170/4579]  eta: 0:25:54  Lr: 0.001875  Loss: -0.5403  Acc@1: 68.7500 (64.6199)  Acc@5: 93.7500 (91.4839)  time: 0.3486  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 180/4579]  eta: 0:25:50  Lr: 0.001875  Loss: -0.5698  Acc@1: 68.7500 (64.9171)  Acc@5: 93.7500 (91.5746)  time: 0.3505  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [ 190/4579]  eta: 0:25:45  Lr: 0.001875  Loss: -0.4973  Acc@1: 62.5000 (64.7251)  Acc@5: 93.7500 (91.4921)  time: 0.3501  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [ 200/4579]  eta: 0:25:41  Lr: 0.001875  Loss: -0.5492  Acc@1: 62.5000 (64.7077)  Acc@5: 93.7500 (91.7600)  time: 0.3480  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [ 210/4579]  eta: 0:25:37  Lr: 0.001875  Loss: -0.3887  Acc@1: 68.7500 (64.8697)  Acc@5: 93.7500 (91.8543)  time: 0.3498  data: 0.0011  max mem: 2500
Train: Epoch[3/5]  [ 220/4579]  eta: 0:25:34  Lr: 0.001875  Loss: 0.1400  Acc@1: 68.7500 (64.6210)  Acc@5: 93.7500 (91.8835)  time: 0.3528  data: 0.0009  max mem: 2500
Train: Epoch[3/5]  [ 230/4579]  eta: 0:25:29  Lr: 0.001875  Loss: -0.6912  Acc@1: 62.5000 (64.6374)  Acc@5: 93.7500 (91.8831)  time: 0.3497  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [ 240/4579]  eta: 0:25:26  Lr: 0.001875  Loss: -0.3836  Acc@1: 68.7500 (64.9118)  Acc@5: 93.7500 (91.9087)  time: 0.3485  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [ 250/4579]  eta: 0:25:22  Lr: 0.001875  Loss: -0.0893  Acc@1: 68.7500 (64.6912)  Acc@5: 93.7500 (91.9074)  time: 0.3512  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [ 260/4579]  eta: 0:25:18  Lr: 0.001875  Loss: -0.7399  Acc@1: 62.5000 (64.7031)  Acc@5: 93.7500 (91.9540)  time: 0.3499  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [ 270/4579]  eta: 0:25:14  Lr: 0.001875  Loss: 0.1032  Acc@1: 62.5000 (64.6448)  Acc@5: 93.7500 (91.9742)  time: 0.3480  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [ 280/4579]  eta: 0:25:10  Lr: 0.001875  Loss: -0.3045  Acc@1: 62.5000 (64.5463)  Acc@5: 87.5000 (91.8372)  time: 0.3479  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [ 290/4579]  eta: 0:25:07  Lr: 0.001875  Loss: -0.2980  Acc@1: 62.5000 (64.5619)  Acc@5: 93.7500 (91.9674)  time: 0.3523  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [ 300/4579]  eta: 0:25:03  Lr: 0.001875  Loss: -0.2765  Acc@1: 56.2500 (64.3688)  Acc@5: 93.7500 (91.8189)  time: 0.3527  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [ 310/4579]  eta: 0:25:00  Lr: 0.001875  Loss: 0.2548  Acc@1: 56.2500 (64.1680)  Acc@5: 87.5000 (91.8006)  time: 0.3514  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [ 320/4579]  eta: 0:24:57  Lr: 0.001875  Loss: -0.0720  Acc@1: 62.5000 (64.2329)  Acc@5: 93.7500 (91.7640)  time: 0.3548  data: 0.0016  max mem: 2500
Train: Epoch[3/5]  [ 330/4579]  eta: 0:24:53  Lr: 0.001875  Loss: -0.1902  Acc@1: 62.5000 (64.1616)  Acc@5: 93.7500 (91.6541)  time: 0.3521  data: 0.0017  max mem: 2500
Train: Epoch[3/5]  [ 340/4579]  eta: 0:24:50  Lr: 0.001875  Loss: 0.2118  Acc@1: 62.5000 (64.0762)  Acc@5: 87.5000 (91.5506)  time: 0.3491  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [ 350/4579]  eta: 0:24:46  Lr: 0.001875  Loss: -0.1211  Acc@1: 62.5000 (64.0313)  Acc@5: 93.7500 (91.5598)  time: 0.3494  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [ 360/4579]  eta: 0:24:42  Lr: 0.001875  Loss: -0.1510  Acc@1: 62.5000 (63.9889)  Acc@5: 93.7500 (91.5512)  time: 0.3512  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [ 370/4579]  eta: 0:24:39  Lr: 0.001875  Loss: -0.2206  Acc@1: 62.5000 (63.8309)  Acc@5: 93.7500 (91.5431)  time: 0.3518  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [ 380/4579]  eta: 0:24:35  Lr: 0.001875  Loss: -0.3164  Acc@1: 62.5000 (63.9436)  Acc@5: 93.7500 (91.5846)  time: 0.3510  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [ 390/4579]  eta: 0:24:32  Lr: 0.001875  Loss: -0.4503  Acc@1: 68.7500 (63.9706)  Acc@5: 93.7500 (91.5601)  time: 0.3516  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [ 400/4579]  eta: 0:24:28  Lr: 0.001875  Loss: 0.3324  Acc@1: 68.7500 (64.0430)  Acc@5: 93.7500 (91.5835)  time: 0.3500  data: 0.0012  max mem: 2500
Train: Epoch[3/5]  [ 410/4579]  eta: 0:24:25  Lr: 0.001875  Loss: -0.4365  Acc@1: 68.7500 (64.1575)  Acc@5: 93.7500 (91.6667)  time: 0.3519  data: 0.0010  max mem: 2500
Train: Epoch[3/5]  [ 420/4579]  eta: 0:24:21  Lr: 0.001875  Loss: -0.2644  Acc@1: 68.7500 (64.1479)  Acc@5: 93.7500 (91.7013)  time: 0.3512  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [ 430/4579]  eta: 0:24:17  Lr: 0.001875  Loss: -0.3010  Acc@1: 68.7500 (64.1821)  Acc@5: 93.7500 (91.7198)  time: 0.3476  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [ 440/4579]  eta: 0:24:13  Lr: 0.001875  Loss: -0.2468  Acc@1: 62.5000 (64.1582)  Acc@5: 93.7500 (91.6950)  time: 0.3479  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [ 450/4579]  eta: 0:24:10  Lr: 0.001875  Loss: -0.3729  Acc@1: 68.7500 (64.1907)  Acc@5: 93.7500 (91.6990)  time: 0.3495  data: 0.0009  max mem: 2500
Train: Epoch[3/5]  [ 460/4579]  eta: 0:24:06  Lr: 0.001875  Loss: 0.2305  Acc@1: 68.7500 (64.1133)  Acc@5: 93.7500 (91.7164)  time: 0.3494  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [ 470/4579]  eta: 0:24:02  Lr: 0.001875  Loss: 0.0903  Acc@1: 62.5000 (64.0260)  Acc@5: 93.7500 (91.7463)  time: 0.3477  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [ 480/4579]  eta: 0:23:58  Lr: 0.001875  Loss: -0.2646  Acc@1: 62.5000 (64.0463)  Acc@5: 93.7500 (91.6970)  time: 0.3485  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [ 490/4579]  eta: 0:23:55  Lr: 0.001875  Loss: 0.3612  Acc@1: 62.5000 (64.0657)  Acc@5: 93.7500 (91.7515)  time: 0.3493  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [ 500/4579]  eta: 0:23:51  Lr: 0.001875  Loss: -0.1312  Acc@1: 62.5000 (64.0968)  Acc@5: 93.7500 (91.7540)  time: 0.3516  data: 0.0009  max mem: 2500
Train: Epoch[3/5]  [ 510/4579]  eta: 0:23:48  Lr: 0.001875  Loss: 0.0923  Acc@1: 62.5000 (64.0900)  Acc@5: 93.7500 (91.7931)  time: 0.3528  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [ 520/4579]  eta: 0:23:44  Lr: 0.001875  Loss: -0.0064  Acc@1: 62.5000 (64.1075)  Acc@5: 93.7500 (91.7346)  time: 0.3502  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [ 530/4579]  eta: 0:23:41  Lr: 0.001875  Loss: -0.2562  Acc@1: 62.5000 (64.1361)  Acc@5: 87.5000 (91.7608)  time: 0.3512  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [ 540/4579]  eta: 0:23:37  Lr: 0.001875  Loss: -0.2716  Acc@1: 62.5000 (64.2098)  Acc@5: 93.7500 (91.8091)  time: 0.3506  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [ 550/4579]  eta: 0:23:34  Lr: 0.001875  Loss: -0.2785  Acc@1: 68.7500 (64.2015)  Acc@5: 87.5000 (91.7650)  time: 0.3498  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [ 560/4579]  eta: 0:23:30  Lr: 0.001875  Loss: -0.5786  Acc@1: 62.5000 (64.1266)  Acc@5: 87.5000 (91.7447)  time: 0.3521  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [ 570/4579]  eta: 0:23:27  Lr: 0.001875  Loss: -0.7060  Acc@1: 62.5000 (64.1419)  Acc@5: 93.7500 (91.7579)  time: 0.3506  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [ 580/4579]  eta: 0:23:23  Lr: 0.001875  Loss: -0.1802  Acc@1: 62.5000 (64.0383)  Acc@5: 93.7500 (91.7276)  time: 0.3498  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [ 590/4579]  eta: 0:23:19  Lr: 0.001875  Loss: -0.3807  Acc@1: 62.5000 (63.9700)  Acc@5: 93.7500 (91.7301)  time: 0.3496  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [ 600/4579]  eta: 0:23:16  Lr: 0.001875  Loss: 0.3017  Acc@1: 62.5000 (63.9559)  Acc@5: 93.7500 (91.7221)  time: 0.3482  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 610/4579]  eta: 0:23:12  Lr: 0.001875  Loss: -0.2057  Acc@1: 62.5000 (63.9014)  Acc@5: 93.7500 (91.6735)  time: 0.3481  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 620/4579]  eta: 0:23:08  Lr: 0.001875  Loss: 0.0247  Acc@1: 62.5000 (63.8990)  Acc@5: 93.7500 (91.6667)  time: 0.3484  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 630/4579]  eta: 0:23:05  Lr: 0.001875  Loss: -0.1671  Acc@1: 62.5000 (63.9461)  Acc@5: 93.7500 (91.6997)  time: 0.3479  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 640/4579]  eta: 0:23:01  Lr: 0.001875  Loss: -0.3812  Acc@1: 62.5000 (63.9626)  Acc@5: 93.7500 (91.6439)  time: 0.3480  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [ 650/4579]  eta: 0:22:57  Lr: 0.001875  Loss: -0.3221  Acc@1: 68.7500 (64.1129)  Acc@5: 87.5000 (91.5995)  time: 0.3488  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [ 660/4579]  eta: 0:22:54  Lr: 0.001875  Loss: -0.5063  Acc@1: 68.7500 (64.1547)  Acc@5: 93.7500 (91.6036)  time: 0.3495  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [ 670/4579]  eta: 0:22:50  Lr: 0.001875  Loss: -0.1685  Acc@1: 62.5000 (64.1487)  Acc@5: 93.7500 (91.5425)  time: 0.3497  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 680/4579]  eta: 0:22:47  Lr: 0.001875  Loss: -0.4532  Acc@1: 62.5000 (64.1979)  Acc@5: 87.5000 (91.5657)  time: 0.3487  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 690/4579]  eta: 0:22:43  Lr: 0.001875  Loss: -0.5580  Acc@1: 62.5000 (64.1914)  Acc@5: 93.7500 (91.5431)  time: 0.3484  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 700/4579]  eta: 0:22:40  Lr: 0.001875  Loss: -0.4363  Acc@1: 62.5000 (64.1673)  Acc@5: 93.7500 (91.5478)  time: 0.3499  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [ 710/4579]  eta: 0:22:36  Lr: 0.001875  Loss: -0.1888  Acc@1: 68.7500 (64.2053)  Acc@5: 93.7500 (91.5612)  time: 0.3515  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [ 720/4579]  eta: 0:22:33  Lr: 0.001875  Loss: -0.1672  Acc@1: 68.7500 (64.2510)  Acc@5: 93.7500 (91.5915)  time: 0.3506  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [ 730/4579]  eta: 0:22:29  Lr: 0.001875  Loss: -0.1089  Acc@1: 68.7500 (64.2100)  Acc@5: 93.7500 (91.6211)  time: 0.3511  data: 0.0009  max mem: 2500
Train: Epoch[3/5]  [ 740/4579]  eta: 0:22:26  Lr: 0.001875  Loss: -0.3793  Acc@1: 68.7500 (64.2713)  Acc@5: 93.7500 (91.6582)  time: 0.3537  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [ 750/4579]  eta: 0:22:22  Lr: 0.001875  Loss: -0.2488  Acc@1: 68.7500 (64.2477)  Acc@5: 93.7500 (91.6611)  time: 0.3519  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [ 760/4579]  eta: 0:22:19  Lr: 0.001875  Loss: -0.2030  Acc@1: 56.2500 (64.1015)  Acc@5: 87.5000 (91.5900)  time: 0.3486  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 770/4579]  eta: 0:22:15  Lr: 0.001875  Loss: -0.2215  Acc@1: 56.2500 (64.0807)  Acc@5: 87.5000 (91.5532)  time: 0.3487  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [ 780/4579]  eta: 0:22:12  Lr: 0.001875  Loss: -0.3689  Acc@1: 56.2500 (64.0205)  Acc@5: 93.7500 (91.5893)  time: 0.3499  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [ 790/4579]  eta: 0:22:08  Lr: 0.001875  Loss: -0.2640  Acc@1: 62.5000 (64.0408)  Acc@5: 93.7500 (91.5929)  time: 0.3487  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [ 800/4579]  eta: 0:22:04  Lr: 0.001875  Loss: -0.3365  Acc@1: 62.5000 (64.0762)  Acc@5: 93.7500 (91.5808)  time: 0.3485  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [ 810/4579]  eta: 0:22:01  Lr: 0.001875  Loss: -0.3925  Acc@1: 62.5000 (64.0336)  Acc@5: 87.5000 (91.5768)  time: 0.3494  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [ 820/4579]  eta: 0:21:57  Lr: 0.001875  Loss: -0.3175  Acc@1: 62.5000 (63.9769)  Acc@5: 93.7500 (91.6261)  time: 0.3498  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [ 830/4579]  eta: 0:21:54  Lr: 0.001875  Loss: 0.3063  Acc@1: 62.5000 (63.9967)  Acc@5: 93.7500 (91.6667)  time: 0.3507  data: 0.0009  max mem: 2500
Train: Epoch[3/5]  [ 840/4579]  eta: 0:21:51  Lr: 0.001875  Loss: 0.1008  Acc@1: 68.7500 (64.0012)  Acc@5: 93.7500 (91.6840)  time: 0.3536  data: 0.0009  max mem: 2500
Train: Epoch[3/5]  [ 850/4579]  eta: 0:21:47  Lr: 0.001875  Loss: -0.3494  Acc@1: 68.7500 (64.0570)  Acc@5: 93.7500 (91.6789)  time: 0.3522  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [ 860/4579]  eta: 0:21:43  Lr: 0.001875  Loss: -0.0026  Acc@1: 62.5000 (64.0607)  Acc@5: 93.7500 (91.6884)  time: 0.3487  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [ 870/4579]  eta: 0:21:40  Lr: 0.001875  Loss: -0.0261  Acc@1: 62.5000 (64.0141)  Acc@5: 93.7500 (91.6547)  time: 0.3503  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [ 880/4579]  eta: 0:21:36  Lr: 0.001875  Loss: -0.3126  Acc@1: 62.5000 (64.0182)  Acc@5: 87.5000 (91.6501)  time: 0.3505  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [ 890/4579]  eta: 0:21:33  Lr: 0.001875  Loss: 0.0466  Acc@1: 62.5000 (64.0502)  Acc@5: 93.7500 (91.6597)  time: 0.3499  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [ 900/4579]  eta: 0:21:29  Lr: 0.001875  Loss: -0.3262  Acc@1: 68.7500 (64.1024)  Acc@5: 93.7500 (91.6690)  time: 0.3506  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [ 910/4579]  eta: 0:21:26  Lr: 0.001875  Loss: -0.5881  Acc@1: 62.5000 (64.0505)  Acc@5: 87.5000 (91.6369)  time: 0.3493  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 920/4579]  eta: 0:21:22  Lr: 0.001875  Loss: -0.4526  Acc@1: 56.2500 (63.9929)  Acc@5: 87.5000 (91.6124)  time: 0.3500  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [ 930/4579]  eta: 0:21:19  Lr: 0.001875  Loss: -0.5595  Acc@1: 62.5000 (63.9970)  Acc@5: 93.7500 (91.6286)  time: 0.3525  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [ 940/4579]  eta: 0:21:15  Lr: 0.001875  Loss: 0.1110  Acc@1: 56.2500 (63.9479)  Acc@5: 93.7500 (91.5914)  time: 0.3535  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [ 950/4579]  eta: 0:21:12  Lr: 0.001875  Loss: -0.0794  Acc@1: 62.5000 (63.9393)  Acc@5: 87.5000 (91.5549)  time: 0.3522  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [ 960/4579]  eta: 0:21:08  Lr: 0.001875  Loss: 0.0710  Acc@1: 62.5000 (63.9243)  Acc@5: 87.5000 (91.5713)  time: 0.3493  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [ 970/4579]  eta: 0:21:05  Lr: 0.001875  Loss: -0.1488  Acc@1: 62.5000 (63.9611)  Acc@5: 93.7500 (91.6195)  time: 0.3505  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [ 980/4579]  eta: 0:21:01  Lr: 0.001875  Loss: -0.2352  Acc@1: 68.7500 (63.9717)  Acc@5: 93.7500 (91.6284)  time: 0.3519  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [ 990/4579]  eta: 0:20:58  Lr: 0.001875  Loss: -0.6449  Acc@1: 62.5000 (63.9442)  Acc@5: 87.5000 (91.6120)  time: 0.3497  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [1000/4579]  eta: 0:20:54  Lr: 0.001875  Loss: -0.3820  Acc@1: 56.2500 (63.9423)  Acc@5: 87.5000 (91.5772)  time: 0.3486  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1010/4579]  eta: 0:20:51  Lr: 0.001875  Loss: -0.4913  Acc@1: 56.2500 (63.9280)  Acc@5: 93.7500 (91.5801)  time: 0.3491  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [1020/4579]  eta: 0:20:47  Lr: 0.001875  Loss: -0.0759  Acc@1: 56.2500 (63.8896)  Acc@5: 93.7500 (91.6136)  time: 0.3498  data: 0.0009  max mem: 2500
Train: Epoch[3/5]  [1030/4579]  eta: 0:20:44  Lr: 0.001875  Loss: -0.4232  Acc@1: 62.5000 (63.8700)  Acc@5: 93.7500 (91.6343)  time: 0.3497  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [1040/4579]  eta: 0:20:40  Lr: 0.001875  Loss: -0.0229  Acc@1: 62.5000 (63.8689)  Acc@5: 93.7500 (91.6306)  time: 0.3492  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [1050/4579]  eta: 0:20:37  Lr: 0.001875  Loss: -0.2080  Acc@1: 62.5000 (63.8856)  Acc@5: 93.7500 (91.6330)  time: 0.3505  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [1060/4579]  eta: 0:20:33  Lr: 0.001875  Loss: -0.4537  Acc@1: 62.5000 (63.8961)  Acc@5: 93.7500 (91.6706)  time: 0.3507  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [1070/4579]  eta: 0:20:30  Lr: 0.001875  Loss: 0.6889  Acc@1: 62.5000 (63.8831)  Acc@5: 93.7500 (91.6900)  time: 0.3518  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [1080/4579]  eta: 0:20:26  Lr: 0.001875  Loss: -0.1138  Acc@1: 62.5000 (63.8818)  Acc@5: 93.7500 (91.6975)  time: 0.3520  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [1090/4579]  eta: 0:20:23  Lr: 0.001875  Loss: -0.7783  Acc@1: 62.5000 (63.8921)  Acc@5: 93.7500 (91.7220)  time: 0.3512  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1100/4579]  eta: 0:20:19  Lr: 0.001875  Loss: -0.1214  Acc@1: 62.5000 (63.8794)  Acc@5: 93.7500 (91.7461)  time: 0.3532  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1110/4579]  eta: 0:20:16  Lr: 0.001875  Loss: 0.0419  Acc@1: 62.5000 (63.8558)  Acc@5: 93.7500 (91.7360)  time: 0.3515  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [1120/4579]  eta: 0:20:12  Lr: 0.001875  Loss: -0.2937  Acc@1: 62.5000 (63.8827)  Acc@5: 87.5000 (91.6871)  time: 0.3493  data: 0.0011  max mem: 2500
Train: Epoch[3/5]  [1130/4579]  eta: 0:20:09  Lr: 0.001875  Loss: -0.3205  Acc@1: 62.5000 (63.8815)  Acc@5: 93.7500 (91.6943)  time: 0.3497  data: 0.0011  max mem: 2500
Train: Epoch[3/5]  [1140/4579]  eta: 0:20:05  Lr: 0.001875  Loss: -0.6421  Acc@1: 68.7500 (63.9297)  Acc@5: 93.7500 (91.7123)  time: 0.3491  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [1150/4579]  eta: 0:20:02  Lr: 0.001875  Loss: -0.4616  Acc@1: 68.7500 (63.9390)  Acc@5: 93.7500 (91.7029)  time: 0.3481  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [1160/4579]  eta: 0:19:58  Lr: 0.001875  Loss: -0.1448  Acc@1: 56.2500 (63.8781)  Acc@5: 93.7500 (91.7205)  time: 0.3499  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [1170/4579]  eta: 0:19:55  Lr: 0.001875  Loss: -0.5378  Acc@1: 62.5000 (63.8717)  Acc@5: 93.7500 (91.6951)  time: 0.3506  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [1180/4579]  eta: 0:19:51  Lr: 0.001875  Loss: -0.5503  Acc@1: 62.5000 (63.9448)  Acc@5: 93.7500 (91.7072)  time: 0.3492  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [1190/4579]  eta: 0:19:47  Lr: 0.001875  Loss: -0.2049  Acc@1: 68.7500 (63.9746)  Acc@5: 93.7500 (91.7191)  time: 0.3495  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [1200/4579]  eta: 0:19:44  Lr: 0.001875  Loss: -0.3288  Acc@1: 62.5000 (63.9675)  Acc@5: 93.7500 (91.7308)  time: 0.3485  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [1210/4579]  eta: 0:19:40  Lr: 0.001875  Loss: -0.7196  Acc@1: 62.5000 (63.9399)  Acc@5: 93.7500 (91.7166)  time: 0.3477  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [1220/4579]  eta: 0:19:37  Lr: 0.001875  Loss: 0.2343  Acc@1: 62.5000 (63.9537)  Acc@5: 93.7500 (91.7127)  time: 0.3481  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [1230/4579]  eta: 0:19:33  Lr: 0.001875  Loss: -0.2932  Acc@1: 68.7500 (63.9673)  Acc@5: 87.5000 (91.6988)  time: 0.3482  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [1240/4579]  eta: 0:19:30  Lr: 0.001875  Loss: -0.4423  Acc@1: 68.7500 (63.9756)  Acc@5: 87.5000 (91.7002)  time: 0.3481  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [1250/4579]  eta: 0:19:26  Lr: 0.001875  Loss: -0.4920  Acc@1: 68.7500 (63.9888)  Acc@5: 87.5000 (91.6867)  time: 0.3505  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [1260/4579]  eta: 0:19:23  Lr: 0.001875  Loss: 0.0748  Acc@1: 68.7500 (63.9919)  Acc@5: 87.5000 (91.6683)  time: 0.3508  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [1270/4579]  eta: 0:19:19  Lr: 0.001875  Loss: 0.1749  Acc@1: 62.5000 (63.9851)  Acc@5: 93.7500 (91.6650)  time: 0.3484  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [1280/4579]  eta: 0:19:15  Lr: 0.001875  Loss: -0.2370  Acc@1: 68.7500 (64.0125)  Acc@5: 93.7500 (91.6618)  time: 0.3477  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [1290/4579]  eta: 0:19:12  Lr: 0.001875  Loss: 0.0065  Acc@1: 68.7500 (64.0250)  Acc@5: 93.7500 (91.6489)  time: 0.3473  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [1300/4579]  eta: 0:19:08  Lr: 0.001875  Loss: 0.0484  Acc@1: 62.5000 (64.0133)  Acc@5: 87.5000 (91.6458)  time: 0.3489  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [1310/4579]  eta: 0:19:05  Lr: 0.001875  Loss: 0.4644  Acc@1: 56.2500 (63.9779)  Acc@5: 93.7500 (91.6428)  time: 0.3515  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [1320/4579]  eta: 0:19:01  Lr: 0.001875  Loss: -0.3031  Acc@1: 56.2500 (63.9194)  Acc@5: 87.5000 (91.6020)  time: 0.3516  data: 0.0014  max mem: 2500
Train: Epoch[3/5]  [1330/4579]  eta: 0:18:58  Lr: 0.001875  Loss: -0.2835  Acc@1: 56.2500 (63.9134)  Acc@5: 87.5000 (91.5947)  time: 0.3496  data: 0.0015  max mem: 2500
Train: Epoch[3/5]  [1340/4579]  eta: 0:18:54  Lr: 0.001875  Loss: -0.2441  Acc@1: 62.5000 (63.8889)  Acc@5: 87.5000 (91.5874)  time: 0.3484  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [1350/4579]  eta: 0:18:51  Lr: 0.001875  Loss: -0.2103  Acc@1: 62.5000 (63.9064)  Acc@5: 93.7500 (91.6219)  time: 0.3498  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [1360/4579]  eta: 0:18:47  Lr: 0.001875  Loss: -0.2895  Acc@1: 62.5000 (63.9052)  Acc@5: 93.7500 (91.6008)  time: 0.3540  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [1370/4579]  eta: 0:18:44  Lr: 0.001875  Loss: -0.2128  Acc@1: 62.5000 (63.8950)  Acc@5: 87.5000 (91.5937)  time: 0.3529  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [1380/4579]  eta: 0:18:40  Lr: 0.001875  Loss: -0.1231  Acc@1: 62.5000 (63.9030)  Acc@5: 93.7500 (91.6229)  time: 0.3508  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [1390/4579]  eta: 0:18:37  Lr: 0.001875  Loss: -0.3282  Acc@1: 62.5000 (63.8974)  Acc@5: 100.0000 (91.6517)  time: 0.3513  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [1400/4579]  eta: 0:18:33  Lr: 0.001875  Loss: -0.2461  Acc@1: 62.5000 (63.8606)  Acc@5: 93.7500 (91.6176)  time: 0.3495  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [1410/4579]  eta: 0:18:30  Lr: 0.001875  Loss: -0.0352  Acc@1: 62.5000 (63.8687)  Acc@5: 87.5000 (91.6106)  time: 0.3479  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [1420/4579]  eta: 0:18:26  Lr: 0.001875  Loss: 0.0023  Acc@1: 62.5000 (63.8459)  Acc@5: 87.5000 (91.6036)  time: 0.3494  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [1430/4579]  eta: 0:18:23  Lr: 0.001875  Loss: -0.4190  Acc@1: 62.5000 (63.8627)  Acc@5: 93.7500 (91.6186)  time: 0.3516  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [1440/4579]  eta: 0:18:19  Lr: 0.001875  Loss: 0.1705  Acc@1: 62.5000 (63.8532)  Acc@5: 93.7500 (91.6247)  time: 0.3514  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [1450/4579]  eta: 0:18:16  Lr: 0.001875  Loss: 0.0283  Acc@1: 62.5000 (63.8525)  Acc@5: 93.7500 (91.6135)  time: 0.3500  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [1460/4579]  eta: 0:18:12  Lr: 0.001875  Loss: -0.5139  Acc@1: 62.5000 (63.8475)  Acc@5: 93.7500 (91.6068)  time: 0.3479  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [1470/4579]  eta: 0:18:09  Lr: 0.001875  Loss: -0.4404  Acc@1: 62.5000 (63.8596)  Acc@5: 93.7500 (91.6044)  time: 0.3501  data: 0.0013  max mem: 2500
Train: Epoch[3/5]  [1480/4579]  eta: 0:18:05  Lr: 0.001875  Loss: -0.0048  Acc@1: 62.5000 (63.8336)  Acc@5: 93.7500 (91.6188)  time: 0.3519  data: 0.0015  max mem: 2500
Train: Epoch[3/5]  [1490/4579]  eta: 0:18:02  Lr: 0.001875  Loss: -0.2477  Acc@1: 62.5000 (63.8456)  Acc@5: 93.7500 (91.6247)  time: 0.3488  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [1500/4579]  eta: 0:17:58  Lr: 0.001875  Loss: -0.3688  Acc@1: 62.5000 (63.8200)  Acc@5: 93.7500 (91.6306)  time: 0.3484  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [1510/4579]  eta: 0:17:55  Lr: 0.001875  Loss: -0.2374  Acc@1: 62.5000 (63.8195)  Acc@5: 93.7500 (91.6281)  time: 0.3500  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [1520/4579]  eta: 0:17:51  Lr: 0.001875  Loss: -0.8036  Acc@1: 62.5000 (63.8601)  Acc@5: 93.7500 (91.6256)  time: 0.3490  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [1530/4579]  eta: 0:17:48  Lr: 0.001875  Loss: -0.1868  Acc@1: 68.7500 (63.9002)  Acc@5: 93.7500 (91.6150)  time: 0.3508  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [1540/4579]  eta: 0:17:44  Lr: 0.001875  Loss: -0.1293  Acc@1: 62.5000 (63.8587)  Acc@5: 87.5000 (91.6004)  time: 0.3505  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [1550/4579]  eta: 0:17:41  Lr: 0.001875  Loss: -0.3576  Acc@1: 56.2500 (63.8661)  Acc@5: 93.7500 (91.6103)  time: 0.3508  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [1560/4579]  eta: 0:17:37  Lr: 0.001875  Loss: -0.7317  Acc@1: 68.7500 (63.8813)  Acc@5: 93.7500 (91.6320)  time: 0.3513  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [1570/4579]  eta: 0:17:34  Lr: 0.001875  Loss: -0.0335  Acc@1: 68.7500 (63.8884)  Acc@5: 93.7500 (91.6256)  time: 0.3510  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [1580/4579]  eta: 0:17:30  Lr: 0.001875  Loss: 0.1968  Acc@1: 62.5000 (63.8757)  Acc@5: 93.7500 (91.6390)  time: 0.3511  data: 0.0009  max mem: 2500
Train: Epoch[3/5]  [1590/4579]  eta: 0:17:27  Lr: 0.001875  Loss: -0.2703  Acc@1: 62.5000 (63.8946)  Acc@5: 93.7500 (91.6287)  time: 0.3484  data: 0.0009  max mem: 2500
Train: Epoch[3/5]  [1600/4579]  eta: 0:17:23  Lr: 0.001875  Loss: -0.1539  Acc@1: 68.7500 (63.8819)  Acc@5: 87.5000 (91.6068)  time: 0.3502  data: 0.0023  max mem: 2500
Train: Epoch[3/5]  [1610/4579]  eta: 0:17:20  Lr: 0.001875  Loss: -0.2258  Acc@1: 62.5000 (63.8540)  Acc@5: 87.5000 (91.5891)  time: 0.3514  data: 0.0023  max mem: 2500
Train: Epoch[3/5]  [1620/4579]  eta: 0:17:16  Lr: 0.001875  Loss: -0.2663  Acc@1: 62.5000 (63.8533)  Acc@5: 87.5000 (91.5870)  time: 0.3515  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [1630/4579]  eta: 0:17:13  Lr: 0.001875  Loss: 0.0843  Acc@1: 62.5000 (63.8259)  Acc@5: 93.7500 (91.5887)  time: 0.3509  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [1640/4579]  eta: 0:17:09  Lr: 0.001875  Loss: -0.2386  Acc@1: 62.5000 (63.8521)  Acc@5: 93.7500 (91.5829)  time: 0.3484  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [1650/4579]  eta: 0:17:06  Lr: 0.001875  Loss: -0.0512  Acc@1: 62.5000 (63.8439)  Acc@5: 93.7500 (91.5922)  time: 0.3495  data: 0.0009  max mem: 2500
Train: Epoch[3/5]  [1660/4579]  eta: 0:17:02  Lr: 0.001875  Loss: -0.1398  Acc@1: 68.7500 (63.8772)  Acc@5: 93.7500 (91.5939)  time: 0.3514  data: 0.0014  max mem: 2500
Train: Epoch[3/5]  [1670/4579]  eta: 0:16:59  Lr: 0.001875  Loss: -0.1226  Acc@1: 68.7500 (63.8914)  Acc@5: 93.7500 (91.5806)  time: 0.3501  data: 0.0009  max mem: 2500
Train: Epoch[3/5]  [1680/4579]  eta: 0:16:55  Lr: 0.001875  Loss: -0.7115  Acc@1: 68.7500 (63.9054)  Acc@5: 93.7500 (91.5712)  time: 0.3495  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [1690/4579]  eta: 0:16:52  Lr: 0.001875  Loss: -0.3545  Acc@1: 62.5000 (63.8786)  Acc@5: 93.7500 (91.5730)  time: 0.3499  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [1700/4579]  eta: 0:16:48  Lr: 0.001875  Loss: -0.9577  Acc@1: 62.5000 (63.9036)  Acc@5: 93.7500 (91.5785)  time: 0.3497  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [1710/4579]  eta: 0:16:45  Lr: 0.001875  Loss: -0.7018  Acc@1: 68.7500 (63.9173)  Acc@5: 93.7500 (91.5656)  time: 0.3499  data: 0.0010  max mem: 2500
Train: Epoch[3/5]  [1720/4579]  eta: 0:16:41  Lr: 0.001875  Loss: 0.1280  Acc@1: 62.5000 (63.9272)  Acc@5: 93.7500 (91.5601)  time: 0.3498  data: 0.0011  max mem: 2500
Train: Epoch[3/5]  [1730/4579]  eta: 0:16:38  Lr: 0.001875  Loss: 0.0498  Acc@1: 62.5000 (63.9262)  Acc@5: 93.7500 (91.5728)  time: 0.3525  data: 0.0013  max mem: 2500
Train: Epoch[3/5]  [1740/4579]  eta: 0:16:34  Lr: 0.001875  Loss: -0.2524  Acc@1: 62.5000 (63.9503)  Acc@5: 93.7500 (91.5494)  time: 0.3534  data: 0.0010  max mem: 2500
Train: Epoch[3/5]  [1750/4579]  eta: 0:16:31  Lr: 0.001875  Loss: -0.2564  Acc@1: 62.5000 (63.9313)  Acc@5: 93.7500 (91.5405)  time: 0.3531  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [1760/4579]  eta: 0:16:27  Lr: 0.001875  Loss: -0.2636  Acc@1: 62.5000 (63.9516)  Acc@5: 93.7500 (91.5460)  time: 0.3550  data: 0.0013  max mem: 2500
Train: Epoch[3/5]  [1770/4579]  eta: 0:16:24  Lr: 0.001875  Loss: -0.0564  Acc@1: 62.5000 (63.9469)  Acc@5: 93.7500 (91.5302)  time: 0.3529  data: 0.0011  max mem: 2500
Train: Epoch[3/5]  [1780/4579]  eta: 0:16:20  Lr: 0.001875  Loss: 0.3716  Acc@1: 62.5000 (63.9493)  Acc@5: 93.7500 (91.5286)  time: 0.3529  data: 0.0012  max mem: 2500
Train: Epoch[3/5]  [1790/4579]  eta: 0:16:17  Lr: 0.001875  Loss: 0.0008  Acc@1: 62.5000 (63.9692)  Acc@5: 93.7500 (91.5341)  time: 0.3533  data: 0.0013  max mem: 2500
Train: Epoch[3/5]  [1800/4579]  eta: 0:16:13  Lr: 0.001875  Loss: -0.3588  Acc@1: 68.7500 (63.9749)  Acc@5: 93.7500 (91.5221)  time: 0.3516  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [1810/4579]  eta: 0:16:10  Lr: 0.001875  Loss: -0.1252  Acc@1: 62.5000 (63.9702)  Acc@5: 93.7500 (91.5171)  time: 0.3510  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [1820/4579]  eta: 0:16:06  Lr: 0.001875  Loss: 0.4413  Acc@1: 62.5000 (63.9244)  Acc@5: 87.5000 (91.5225)  time: 0.3496  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [1830/4579]  eta: 0:16:03  Lr: 0.001875  Loss: -0.6152  Acc@1: 62.5000 (63.9814)  Acc@5: 93.7500 (91.5176)  time: 0.3494  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [1840/4579]  eta: 0:15:59  Lr: 0.001875  Loss: 0.2691  Acc@1: 62.5000 (63.9632)  Acc@5: 87.5000 (91.4924)  time: 0.3494  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [1850/4579]  eta: 0:15:56  Lr: 0.001875  Loss: 0.0110  Acc@1: 62.5000 (63.9654)  Acc@5: 87.5000 (91.5046)  time: 0.3500  data: 0.0015  max mem: 2500
Train: Epoch[3/5]  [1860/4579]  eta: 0:15:52  Lr: 0.001875  Loss: -0.3321  Acc@1: 68.7500 (63.9979)  Acc@5: 93.7500 (91.4931)  time: 0.3522  data: 0.0017  max mem: 2500
Train: Epoch[3/5]  [1870/4579]  eta: 0:15:49  Lr: 0.001875  Loss: -0.2619  Acc@1: 62.5000 (63.9798)  Acc@5: 87.5000 (91.4785)  time: 0.3525  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [1880/4579]  eta: 0:15:45  Lr: 0.001875  Loss: 0.4052  Acc@1: 62.5000 (63.9753)  Acc@5: 93.7500 (91.4806)  time: 0.3505  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [1890/4579]  eta: 0:15:42  Lr: 0.001875  Loss: -0.2756  Acc@1: 62.5000 (63.9510)  Acc@5: 93.7500 (91.4860)  time: 0.3495  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [1900/4579]  eta: 0:15:38  Lr: 0.001875  Loss: -0.1182  Acc@1: 62.5000 (63.9499)  Acc@5: 93.7500 (91.4880)  time: 0.3496  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [1910/4579]  eta: 0:15:35  Lr: 0.001875  Loss: -0.3010  Acc@1: 62.5000 (63.9685)  Acc@5: 93.7500 (91.4835)  time: 0.3500  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [1920/4579]  eta: 0:15:31  Lr: 0.001875  Loss: -0.0699  Acc@1: 62.5000 (63.9738)  Acc@5: 93.7500 (91.4856)  time: 0.3508  data: 0.0021  max mem: 2500
Train: Epoch[3/5]  [1930/4579]  eta: 0:15:28  Lr: 0.001875  Loss: 0.1294  Acc@1: 68.7500 (63.9921)  Acc@5: 93.7500 (91.4843)  time: 0.3512  data: 0.0020  max mem: 2500
Train: Epoch[3/5]  [1940/4579]  eta: 0:15:24  Lr: 0.001875  Loss: -0.3902  Acc@1: 68.7500 (64.0037)  Acc@5: 93.7500 (91.4799)  time: 0.3509  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [1950/4579]  eta: 0:15:21  Lr: 0.001875  Loss: -0.4602  Acc@1: 68.7500 (63.9928)  Acc@5: 93.7500 (91.4755)  time: 0.3533  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [1960/4579]  eta: 0:15:17  Lr: 0.001875  Loss: 0.3820  Acc@1: 62.5000 (63.9757)  Acc@5: 93.7500 (91.4648)  time: 0.3533  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [1970/4579]  eta: 0:15:14  Lr: 0.001875  Loss: -0.0053  Acc@1: 62.5000 (63.9840)  Acc@5: 93.7500 (91.4701)  time: 0.3497  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1980/4579]  eta: 0:15:10  Lr: 0.001875  Loss: -0.4959  Acc@1: 68.7500 (63.9955)  Acc@5: 93.7500 (91.4879)  time: 0.3494  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [1990/4579]  eta: 0:15:07  Lr: 0.001875  Loss: -0.0841  Acc@1: 62.5000 (63.9785)  Acc@5: 93.7500 (91.4930)  time: 0.3511  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [2000/4579]  eta: 0:15:03  Lr: 0.001875  Loss: 1.0581  Acc@1: 62.5000 (63.9868)  Acc@5: 93.7500 (91.4886)  time: 0.3511  data: 0.0012  max mem: 2500
Train: Epoch[3/5]  [2010/4579]  eta: 0:15:00  Lr: 0.001875  Loss: -0.2046  Acc@1: 62.5000 (63.9825)  Acc@5: 93.7500 (91.4874)  time: 0.3504  data: 0.0012  max mem: 2500
Train: Epoch[3/5]  [2020/4579]  eta: 0:14:56  Lr: 0.001875  Loss: -0.3068  Acc@1: 62.5000 (63.9720)  Acc@5: 93.7500 (91.4863)  time: 0.3520  data: 0.0009  max mem: 2500
Train: Epoch[3/5]  [2030/4579]  eta: 0:14:53  Lr: 0.001875  Loss: -0.2638  Acc@1: 68.7500 (63.9894)  Acc@5: 93.7500 (91.4882)  time: 0.3507  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [2040/4579]  eta: 0:14:49  Lr: 0.001875  Loss: -0.2196  Acc@1: 68.7500 (63.9882)  Acc@5: 93.7500 (91.4870)  time: 0.3476  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [2050/4579]  eta: 0:14:46  Lr: 0.001875  Loss: -0.8013  Acc@1: 62.5000 (63.9871)  Acc@5: 93.7500 (91.4767)  time: 0.3485  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [2060/4579]  eta: 0:14:42  Lr: 0.001875  Loss: -0.4217  Acc@1: 62.5000 (63.9859)  Acc@5: 87.5000 (91.4726)  time: 0.3525  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [2070/4579]  eta: 0:14:39  Lr: 0.001875  Loss: -0.3418  Acc@1: 68.7500 (64.0180)  Acc@5: 93.7500 (91.4806)  time: 0.3522  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [2080/4579]  eta: 0:14:35  Lr: 0.001875  Loss: 0.0384  Acc@1: 68.7500 (64.0167)  Acc@5: 87.5000 (91.4644)  time: 0.3488  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [2090/4579]  eta: 0:14:32  Lr: 0.001875  Loss: 0.1184  Acc@1: 62.5000 (64.0304)  Acc@5: 87.5000 (91.4694)  time: 0.3495  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [2100/4579]  eta: 0:14:28  Lr: 0.001875  Loss: -0.5050  Acc@1: 62.5000 (64.0439)  Acc@5: 93.7500 (91.4683)  time: 0.3504  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [2110/4579]  eta: 0:14:25  Lr: 0.001875  Loss: -0.2754  Acc@1: 62.5000 (64.0514)  Acc@5: 93.7500 (91.4880)  time: 0.3499  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [2120/4579]  eta: 0:14:21  Lr: 0.001875  Loss: -0.2018  Acc@1: 62.5000 (64.0500)  Acc@5: 93.7500 (91.4722)  time: 0.3495  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [2130/4579]  eta: 0:14:18  Lr: 0.001875  Loss: -0.0755  Acc@1: 62.5000 (64.0368)  Acc@5: 87.5000 (91.4653)  time: 0.3510  data: 0.0010  max mem: 2500
Train: Epoch[3/5]  [2140/4579]  eta: 0:14:14  Lr: 0.001875  Loss: -0.7994  Acc@1: 62.5000 (64.0559)  Acc@5: 93.7500 (91.4672)  time: 0.3521  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [2150/4579]  eta: 0:14:11  Lr: 0.001875  Loss: 0.0497  Acc@1: 62.5000 (64.0487)  Acc@5: 87.5000 (91.4662)  time: 0.3505  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [2160/4579]  eta: 0:14:07  Lr: 0.001875  Loss: -0.3297  Acc@1: 62.5000 (64.0444)  Acc@5: 93.7500 (91.4739)  time: 0.3488  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [2170/4579]  eta: 0:14:04  Lr: 0.001875  Loss: -0.3715  Acc@1: 68.7500 (64.0719)  Acc@5: 93.7500 (91.4843)  time: 0.3500  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [2180/4579]  eta: 0:14:00  Lr: 0.001875  Loss: -0.1846  Acc@1: 62.5000 (64.0589)  Acc@5: 93.7500 (91.4747)  time: 0.3521  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [2190/4579]  eta: 0:13:57  Lr: 0.001875  Loss: -0.4541  Acc@1: 62.5000 (64.0689)  Acc@5: 87.5000 (91.4765)  time: 0.3552  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [2200/4579]  eta: 0:13:53  Lr: 0.001875  Loss: -0.0457  Acc@1: 62.5000 (64.0675)  Acc@5: 87.5000 (91.4669)  time: 0.3553  data: 0.0014  max mem: 2500
Train: Epoch[3/5]  [2210/4579]  eta: 0:13:50  Lr: 0.001875  Loss: -0.5491  Acc@1: 62.5000 (64.0858)  Acc@5: 93.7500 (91.4744)  time: 0.3526  data: 0.0013  max mem: 2500
Train: Epoch[3/5]  [2220/4579]  eta: 0:13:46  Lr: 0.001875  Loss: -0.1938  Acc@1: 68.7500 (64.1124)  Acc@5: 93.7500 (91.4819)  time: 0.3533  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [2230/4579]  eta: 0:13:43  Lr: 0.001875  Loss: -0.4351  Acc@1: 62.5000 (64.0996)  Acc@5: 93.7500 (91.4920)  time: 0.3531  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [2240/4579]  eta: 0:13:39  Lr: 0.001875  Loss: 0.4774  Acc@1: 62.5000 (64.1008)  Acc@5: 93.7500 (91.4965)  time: 0.3511  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [2250/4579]  eta: 0:13:36  Lr: 0.001875  Loss: -0.0142  Acc@1: 62.5000 (64.1021)  Acc@5: 93.7500 (91.4982)  time: 0.3522  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [2260/4579]  eta: 0:13:32  Lr: 0.001875  Loss: -0.5815  Acc@1: 62.5000 (64.1005)  Acc@5: 93.7500 (91.5082)  time: 0.3519  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [2270/4579]  eta: 0:13:29  Lr: 0.001875  Loss: -0.0040  Acc@1: 62.5000 (64.0742)  Acc@5: 93.7500 (91.5015)  time: 0.3500  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [2280/4579]  eta: 0:13:25  Lr: 0.001875  Loss: -0.0052  Acc@1: 62.5000 (64.0700)  Acc@5: 87.5000 (91.4950)  time: 0.3498  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [2290/4579]  eta: 0:13:22  Lr: 0.001875  Loss: 0.0073  Acc@1: 62.5000 (64.0659)  Acc@5: 93.7500 (91.4993)  time: 0.3491  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [2300/4579]  eta: 0:13:18  Lr: 0.001875  Loss: -0.6547  Acc@1: 68.7500 (64.0781)  Acc@5: 93.7500 (91.4955)  time: 0.3504  data: 0.0020  max mem: 2500
Train: Epoch[3/5]  [2310/4579]  eta: 0:13:15  Lr: 0.001875  Loss: -0.8434  Acc@1: 68.7500 (64.0821)  Acc@5: 93.7500 (91.4972)  time: 0.3509  data: 0.0022  max mem: 2500
Train: Epoch[3/5]  [2320/4579]  eta: 0:13:11  Lr: 0.001875  Loss: -0.2331  Acc@1: 62.5000 (64.0753)  Acc@5: 93.7500 (91.5096)  time: 0.3495  data: 0.0009  max mem: 2500
Train: Epoch[3/5]  [2330/4579]  eta: 0:13:08  Lr: 0.001875  Loss: -0.2732  Acc@1: 62.5000 (64.0632)  Acc@5: 87.5000 (91.5058)  time: 0.3500  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [2340/4579]  eta: 0:13:04  Lr: 0.001875  Loss: -0.4373  Acc@1: 62.5000 (64.0779)  Acc@5: 87.5000 (91.4833)  time: 0.3501  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [2350/4579]  eta: 0:13:01  Lr: 0.001875  Loss: 0.3240  Acc@1: 68.7500 (64.0977)  Acc@5: 87.5000 (91.4903)  time: 0.3520  data: 0.0009  max mem: 2500
Train: Epoch[3/5]  [2360/4579]  eta: 0:12:57  Lr: 0.001875  Loss: 0.4844  Acc@1: 68.7500 (64.1068)  Acc@5: 93.7500 (91.4787)  time: 0.3522  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [2370/4579]  eta: 0:12:54  Lr: 0.001875  Loss: -0.2995  Acc@1: 68.7500 (64.1370)  Acc@5: 93.7500 (91.4804)  time: 0.3490  data: 0.0009  max mem: 2500
Train: Epoch[3/5]  [2380/4579]  eta: 0:12:50  Lr: 0.001875  Loss: 0.0696  Acc@1: 62.5000 (64.1091)  Acc@5: 93.7500 (91.4742)  time: 0.3499  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [2390/4579]  eta: 0:12:47  Lr: 0.001875  Loss: -0.3451  Acc@1: 56.2500 (64.0893)  Acc@5: 87.5000 (91.4732)  time: 0.3508  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [2400/4579]  eta: 0:12:43  Lr: 0.001875  Loss: -0.2526  Acc@1: 62.5000 (64.0983)  Acc@5: 93.7500 (91.4671)  time: 0.3506  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [2410/4579]  eta: 0:12:40  Lr: 0.001875  Loss: -0.0962  Acc@1: 62.5000 (64.0787)  Acc@5: 93.7500 (91.4688)  time: 0.3498  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [2420/4579]  eta: 0:12:36  Lr: 0.001875  Loss: 0.0909  Acc@1: 62.5000 (64.0644)  Acc@5: 93.7500 (91.4653)  time: 0.3498  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [2430/4579]  eta: 0:12:33  Lr: 0.001875  Loss: -0.1528  Acc@1: 62.5000 (64.0760)  Acc@5: 93.7500 (91.4670)  time: 0.3531  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [2440/4579]  eta: 0:12:29  Lr: 0.001875  Loss: -0.0229  Acc@1: 62.5000 (64.0926)  Acc@5: 93.7500 (91.4712)  time: 0.3535  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [2450/4579]  eta: 0:12:26  Lr: 0.001875  Loss: 0.0144  Acc@1: 62.5000 (64.1039)  Acc@5: 93.7500 (91.4729)  time: 0.3496  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [2460/4579]  eta: 0:12:22  Lr: 0.001875  Loss: -0.4439  Acc@1: 62.5000 (64.1025)  Acc@5: 93.7500 (91.4720)  time: 0.3486  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [2470/4579]  eta: 0:12:19  Lr: 0.001875  Loss: -0.1065  Acc@1: 62.5000 (64.0935)  Acc@5: 93.7500 (91.4736)  time: 0.3492  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [2480/4579]  eta: 0:12:15  Lr: 0.001875  Loss: 0.0608  Acc@1: 62.5000 (64.0971)  Acc@5: 87.5000 (91.4601)  time: 0.3497  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [2490/4579]  eta: 0:12:12  Lr: 0.001875  Loss: -0.3004  Acc@1: 62.5000 (64.0957)  Acc@5: 87.5000 (91.4517)  time: 0.3514  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [2500/4579]  eta: 0:12:08  Lr: 0.001875  Loss: 0.2557  Acc@1: 68.7500 (64.0994)  Acc@5: 93.7500 (91.4434)  time: 0.3532  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [2510/4579]  eta: 0:12:05  Lr: 0.001875  Loss: 0.0836  Acc@1: 62.5000 (64.0805)  Acc@5: 93.7500 (91.4501)  time: 0.3534  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [2520/4579]  eta: 0:12:01  Lr: 0.001875  Loss: 0.1138  Acc@1: 62.5000 (64.0916)  Acc@5: 93.7500 (91.4667)  time: 0.3506  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [2530/4579]  eta: 0:11:58  Lr: 0.001875  Loss: -0.3077  Acc@1: 68.7500 (64.1026)  Acc@5: 93.7500 (91.4782)  time: 0.3501  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [2540/4579]  eta: 0:11:54  Lr: 0.001875  Loss: 0.6868  Acc@1: 68.7500 (64.1111)  Acc@5: 93.7500 (91.4797)  time: 0.3533  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [2550/4579]  eta: 0:11:51  Lr: 0.001875  Loss: -0.2190  Acc@1: 62.5000 (64.1023)  Acc@5: 93.7500 (91.4788)  time: 0.3540  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [2560/4579]  eta: 0:11:47  Lr: 0.001875  Loss: -0.2475  Acc@1: 62.5000 (64.1034)  Acc@5: 93.7500 (91.4682)  time: 0.3510  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [2570/4579]  eta: 0:11:44  Lr: 0.001875  Loss: -0.2492  Acc@1: 68.7500 (64.1287)  Acc@5: 93.7500 (91.4843)  time: 0.3487  data: 0.0009  max mem: 2500
Train: Epoch[3/5]  [2580/4579]  eta: 0:11:40  Lr: 0.001875  Loss: -0.2607  Acc@1: 62.5000 (64.1152)  Acc@5: 87.5000 (91.4641)  time: 0.3500  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [2590/4579]  eta: 0:11:37  Lr: 0.001875  Loss: -0.1472  Acc@1: 62.5000 (64.1186)  Acc@5: 87.5000 (91.4729)  time: 0.3512  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [2600/4579]  eta: 0:11:33  Lr: 0.001875  Loss: -0.9305  Acc@1: 68.7500 (64.1652)  Acc@5: 93.7500 (91.4768)  time: 0.3510  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2610/4579]  eta: 0:11:30  Lr: 0.001875  Loss: 0.3027  Acc@1: 68.7500 (64.1541)  Acc@5: 93.7500 (91.4760)  time: 0.3490  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2620/4579]  eta: 0:11:26  Lr: 0.001875  Loss: -0.5528  Acc@1: 62.5000 (64.1740)  Acc@5: 93.7500 (91.4703)  time: 0.3482  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [2630/4579]  eta: 0:11:23  Lr: 0.001875  Loss: -0.4270  Acc@1: 68.7500 (64.1819)  Acc@5: 93.7500 (91.4671)  time: 0.3514  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [2640/4579]  eta: 0:11:19  Lr: 0.001875  Loss: -0.4213  Acc@1: 62.5000 (64.1542)  Acc@5: 93.7500 (91.4521)  time: 0.3530  data: 0.0014  max mem: 2500
Train: Epoch[3/5]  [2650/4579]  eta: 0:11:16  Lr: 0.001875  Loss: 0.3182  Acc@1: 62.5000 (64.1715)  Acc@5: 87.5000 (91.4419)  time: 0.3510  data: 0.0015  max mem: 2500
Train: Epoch[3/5]  [2660/4579]  eta: 0:11:12  Lr: 0.001875  Loss: -0.3807  Acc@1: 68.7500 (64.1629)  Acc@5: 93.7500 (91.4365)  time: 0.3513  data: 0.0009  max mem: 2500
Train: Epoch[3/5]  [2670/4579]  eta: 0:11:09  Lr: 0.001875  Loss: -0.6535  Acc@1: 68.7500 (64.1848)  Acc@5: 93.7500 (91.4498)  time: 0.3508  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [2680/4579]  eta: 0:11:05  Lr: 0.001875  Loss: -0.0312  Acc@1: 68.7500 (64.1831)  Acc@5: 93.7500 (91.4491)  time: 0.3502  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [2690/4579]  eta: 0:11:02  Lr: 0.001875  Loss: -0.7305  Acc@1: 68.7500 (64.1862)  Acc@5: 93.7500 (91.4600)  time: 0.3513  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [2700/4579]  eta: 0:10:58  Lr: 0.001875  Loss: -0.3774  Acc@1: 68.7500 (64.2100)  Acc@5: 93.7500 (91.4592)  time: 0.3518  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [2710/4579]  eta: 0:10:55  Lr: 0.001875  Loss: -0.5451  Acc@1: 68.7500 (64.2060)  Acc@5: 93.7500 (91.4607)  time: 0.3508  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [2720/4579]  eta: 0:10:51  Lr: 0.001875  Loss: -0.1743  Acc@1: 62.5000 (64.2020)  Acc@5: 93.7500 (91.4622)  time: 0.3493  data: 0.0009  max mem: 2500
Train: Epoch[3/5]  [2730/4579]  eta: 0:10:48  Lr: 0.001875  Loss: -0.0788  Acc@1: 62.5000 (64.1981)  Acc@5: 93.7500 (91.4660)  time: 0.3505  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [2740/4579]  eta: 0:10:44  Lr: 0.001875  Loss: -0.4692  Acc@1: 62.5000 (64.1873)  Acc@5: 87.5000 (91.4584)  time: 0.3510  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [2750/4579]  eta: 0:10:41  Lr: 0.001875  Loss: 0.1534  Acc@1: 62.5000 (64.1835)  Acc@5: 87.5000 (91.4440)  time: 0.3522  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [2760/4579]  eta: 0:10:37  Lr: 0.001875  Loss: 0.5712  Acc@1: 62.5000 (64.1661)  Acc@5: 87.5000 (91.4456)  time: 0.3530  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [2770/4579]  eta: 0:10:34  Lr: 0.001875  Loss: 0.0265  Acc@1: 62.5000 (64.1736)  Acc@5: 87.5000 (91.4359)  time: 0.3538  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [2780/4579]  eta: 0:10:30  Lr: 0.001875  Loss: 0.0032  Acc@1: 62.5000 (64.1653)  Acc@5: 87.5000 (91.4374)  time: 0.3538  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [2790/4579]  eta: 0:10:27  Lr: 0.001875  Loss: 0.0383  Acc@1: 62.5000 (64.1638)  Acc@5: 87.5000 (91.4233)  time: 0.3528  data: 0.0009  max mem: 2500
Train: Epoch[3/5]  [2800/4579]  eta: 0:10:23  Lr: 0.001875  Loss: -0.1464  Acc@1: 62.5000 (64.1735)  Acc@5: 87.5000 (91.4227)  time: 0.3509  data: 0.0009  max mem: 2500
Train: Epoch[3/5]  [2810/4579]  eta: 0:10:20  Lr: 0.001875  Loss: -0.4280  Acc@1: 68.7500 (64.1876)  Acc@5: 93.7500 (91.4332)  time: 0.3499  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [2820/4579]  eta: 0:10:16  Lr: 0.001875  Loss: -0.1725  Acc@1: 68.7500 (64.1772)  Acc@5: 93.7500 (91.4259)  time: 0.3503  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [2830/4579]  eta: 0:10:13  Lr: 0.001875  Loss: 0.3821  Acc@1: 68.7500 (64.1779)  Acc@5: 87.5000 (91.4231)  time: 0.3510  data: 0.0009  max mem: 2500
Train: Epoch[3/5]  [2840/4579]  eta: 0:10:09  Lr: 0.001875  Loss: -0.7545  Acc@1: 68.7500 (64.1873)  Acc@5: 93.7500 (91.4181)  time: 0.3507  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [2850/4579]  eta: 0:10:06  Lr: 0.001875  Loss: -0.4309  Acc@1: 68.7500 (64.2033)  Acc@5: 93.7500 (91.4153)  time: 0.3494  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [2860/4579]  eta: 0:10:02  Lr: 0.001875  Loss: -0.4830  Acc@1: 68.7500 (64.2214)  Acc@5: 93.7500 (91.4278)  time: 0.3526  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [2870/4579]  eta: 0:09:59  Lr: 0.001875  Loss: -0.1436  Acc@1: 68.7500 (64.2285)  Acc@5: 93.7500 (91.4316)  time: 0.3525  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [2880/4579]  eta: 0:09:55  Lr: 0.001875  Loss: -0.5532  Acc@1: 68.7500 (64.2355)  Acc@5: 87.5000 (91.4201)  time: 0.3506  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [2890/4579]  eta: 0:09:52  Lr: 0.001875  Loss: -0.2401  Acc@1: 68.7500 (64.2468)  Acc@5: 87.5000 (91.4108)  time: 0.3503  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [2900/4579]  eta: 0:09:48  Lr: 0.001875  Loss: -0.0167  Acc@1: 68.7500 (64.2537)  Acc@5: 93.7500 (91.4146)  time: 0.3501  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [2910/4579]  eta: 0:09:45  Lr: 0.001875  Loss: -0.1838  Acc@1: 62.5000 (64.2412)  Acc@5: 93.7500 (91.4119)  time: 0.3513  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [2920/4579]  eta: 0:09:41  Lr: 0.001875  Loss: 0.0648  Acc@1: 56.2500 (64.2310)  Acc@5: 93.7500 (91.4178)  time: 0.3512  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [2930/4579]  eta: 0:09:38  Lr: 0.001875  Loss: -0.3460  Acc@1: 56.2500 (64.2208)  Acc@5: 93.7500 (91.4150)  time: 0.3506  data: 0.0011  max mem: 2500
Train: Epoch[3/5]  [2940/4579]  eta: 0:09:34  Lr: 0.001875  Loss: -0.1351  Acc@1: 68.7500 (64.2299)  Acc@5: 87.5000 (91.4124)  time: 0.3488  data: 0.0009  max mem: 2500
Train: Epoch[3/5]  [2950/4579]  eta: 0:09:31  Lr: 0.001875  Loss: -0.2936  Acc@1: 68.7500 (64.2494)  Acc@5: 93.7500 (91.4224)  time: 0.3510  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [2960/4579]  eta: 0:09:27  Lr: 0.001875  Loss: -0.0968  Acc@1: 62.5000 (64.2541)  Acc@5: 93.7500 (91.4324)  time: 0.3516  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [2970/4579]  eta: 0:09:24  Lr: 0.001875  Loss: -0.0048  Acc@1: 62.5000 (64.2545)  Acc@5: 93.7500 (91.4318)  time: 0.3501  data: 0.0010  max mem: 2500
Train: Epoch[3/5]  [2980/4579]  eta: 0:09:20  Lr: 0.001875  Loss: 0.1778  Acc@1: 62.5000 (64.2507)  Acc@5: 93.7500 (91.4374)  time: 0.3500  data: 0.0010  max mem: 2500
Train: Epoch[3/5]  [2990/4579]  eta: 0:09:17  Lr: 0.001875  Loss: -0.0300  Acc@1: 62.5000 (64.2511)  Acc@5: 93.7500 (91.4368)  time: 0.3483  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [3000/4579]  eta: 0:09:13  Lr: 0.001875  Loss: 0.6730  Acc@1: 62.5000 (64.2661)  Acc@5: 93.7500 (91.4404)  time: 0.3498  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [3010/4579]  eta: 0:09:10  Lr: 0.001875  Loss: 0.5260  Acc@1: 68.7500 (64.2789)  Acc@5: 93.7500 (91.4335)  time: 0.3549  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [3020/4579]  eta: 0:09:06  Lr: 0.001875  Loss: -0.9129  Acc@1: 68.7500 (64.3020)  Acc@5: 93.7500 (91.4474)  time: 0.3550  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [3030/4579]  eta: 0:09:03  Lr: 0.001875  Loss: 0.0662  Acc@1: 62.5000 (64.2919)  Acc@5: 93.7500 (91.4323)  time: 0.3513  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [3040/4579]  eta: 0:08:59  Lr: 0.001875  Loss: -0.3819  Acc@1: 62.5000 (64.2963)  Acc@5: 87.5000 (91.4296)  time: 0.3501  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [3050/4579]  eta: 0:08:56  Lr: 0.001875  Loss: -0.1580  Acc@1: 68.7500 (64.2843)  Acc@5: 93.7500 (91.4434)  time: 0.3516  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3060/4579]  eta: 0:08:52  Lr: 0.001875  Loss: -0.3597  Acc@1: 62.5000 (64.2723)  Acc@5: 93.7500 (91.4407)  time: 0.3509  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [3070/4579]  eta: 0:08:49  Lr: 0.001875  Loss: 0.3751  Acc@1: 62.5000 (64.2808)  Acc@5: 93.7500 (91.4340)  time: 0.3506  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [3080/4579]  eta: 0:08:45  Lr: 0.001875  Loss: -0.3404  Acc@1: 75.0000 (64.3237)  Acc@5: 93.7500 (91.4435)  time: 0.3500  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [3090/4579]  eta: 0:08:42  Lr: 0.001875  Loss: -0.9150  Acc@1: 75.0000 (64.3319)  Acc@5: 93.7500 (91.4409)  time: 0.3484  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [3100/4579]  eta: 0:08:38  Lr: 0.001875  Loss: -0.3218  Acc@1: 62.5000 (64.3159)  Acc@5: 93.7500 (91.4403)  time: 0.3491  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [3110/4579]  eta: 0:08:35  Lr: 0.001875  Loss: -0.6247  Acc@1: 62.5000 (64.3302)  Acc@5: 93.7500 (91.4577)  time: 0.3495  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [3120/4579]  eta: 0:08:31  Lr: 0.001875  Loss: -0.8009  Acc@1: 62.5000 (64.3203)  Acc@5: 93.7500 (91.4571)  time: 0.3497  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [3130/4579]  eta: 0:08:28  Lr: 0.001875  Loss: 0.1608  Acc@1: 62.5000 (64.3145)  Acc@5: 93.7500 (91.4664)  time: 0.3488  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [3140/4579]  eta: 0:08:24  Lr: 0.001875  Loss: -0.7407  Acc@1: 68.7500 (64.3247)  Acc@5: 93.7500 (91.4637)  time: 0.3484  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [3150/4579]  eta: 0:08:21  Lr: 0.001875  Loss: -0.4944  Acc@1: 68.7500 (64.3288)  Acc@5: 93.7500 (91.4650)  time: 0.3497  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [3160/4579]  eta: 0:08:17  Lr: 0.001875  Loss: -0.0885  Acc@1: 68.7500 (64.3250)  Acc@5: 93.7500 (91.4663)  time: 0.3508  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [3170/4579]  eta: 0:08:14  Lr: 0.001875  Loss: -0.6351  Acc@1: 62.5000 (64.3192)  Acc@5: 93.7500 (91.4637)  time: 0.3512  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [3180/4579]  eta: 0:08:10  Lr: 0.001875  Loss: -0.3844  Acc@1: 62.5000 (64.3273)  Acc@5: 93.7500 (91.4532)  time: 0.3513  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [3190/4579]  eta: 0:08:07  Lr: 0.001875  Loss: -0.8423  Acc@1: 68.7500 (64.3490)  Acc@5: 93.7500 (91.4564)  time: 0.3492  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [3200/4579]  eta: 0:08:03  Lr: 0.001875  Loss: -0.6579  Acc@1: 68.7500 (64.3451)  Acc@5: 93.7500 (91.4636)  time: 0.3473  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [3210/4579]  eta: 0:07:59  Lr: 0.001875  Loss: -0.2115  Acc@1: 62.5000 (64.3394)  Acc@5: 93.7500 (91.4629)  time: 0.3475  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [3220/4579]  eta: 0:07:56  Lr: 0.001875  Loss: -0.6262  Acc@1: 62.5000 (64.3492)  Acc@5: 93.7500 (91.4700)  time: 0.3490  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [3230/4579]  eta: 0:07:52  Lr: 0.001875  Loss: -0.1821  Acc@1: 75.0000 (64.3589)  Acc@5: 93.7500 (91.4713)  time: 0.3506  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [3240/4579]  eta: 0:07:49  Lr: 0.001875  Loss: -0.0663  Acc@1: 68.7500 (64.3706)  Acc@5: 93.7500 (91.4725)  time: 0.3500  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [3250/4579]  eta: 0:07:45  Lr: 0.001875  Loss: -0.2484  Acc@1: 68.7500 (64.3860)  Acc@5: 93.7500 (91.4815)  time: 0.3501  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [3260/4579]  eta: 0:07:42  Lr: 0.001875  Loss: -0.4394  Acc@1: 62.5000 (64.3859)  Acc@5: 93.7500 (91.4769)  time: 0.3495  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [3270/4579]  eta: 0:07:38  Lr: 0.001875  Loss: -0.1076  Acc@1: 62.5000 (64.3935)  Acc@5: 93.7500 (91.4801)  time: 0.3481  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [3280/4579]  eta: 0:07:35  Lr: 0.001875  Loss: -0.3386  Acc@1: 68.7500 (64.3954)  Acc@5: 93.7500 (91.4813)  time: 0.3495  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [3290/4579]  eta: 0:07:31  Lr: 0.001875  Loss: 0.0268  Acc@1: 68.7500 (64.4048)  Acc@5: 93.7500 (91.4730)  time: 0.3533  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [3300/4579]  eta: 0:07:28  Lr: 0.001875  Loss: -0.3459  Acc@1: 68.7500 (64.4237)  Acc@5: 93.7500 (91.4817)  time: 0.3530  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [3310/4579]  eta: 0:07:24  Lr: 0.001875  Loss: -0.5052  Acc@1: 68.7500 (64.4027)  Acc@5: 93.7500 (91.4773)  time: 0.3519  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [3320/4579]  eta: 0:07:21  Lr: 0.001875  Loss: -0.3068  Acc@1: 62.5000 (64.4045)  Acc@5: 93.7500 (91.4822)  time: 0.3536  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [3330/4579]  eta: 0:07:17  Lr: 0.001875  Loss: 0.0230  Acc@1: 68.7500 (64.4026)  Acc@5: 87.5000 (91.4647)  time: 0.3507  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [3340/4579]  eta: 0:07:14  Lr: 0.001875  Loss: -0.1697  Acc@1: 68.7500 (64.4119)  Acc@5: 87.5000 (91.4640)  time: 0.3502  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3350/4579]  eta: 0:07:10  Lr: 0.001875  Loss: -0.2046  Acc@1: 68.7500 (64.4080)  Acc@5: 93.7500 (91.4708)  time: 0.3510  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [3360/4579]  eta: 0:07:07  Lr: 0.001875  Loss: 0.2627  Acc@1: 68.7500 (64.3949)  Acc@5: 87.5000 (91.4609)  time: 0.3494  data: 0.0009  max mem: 2500
Train: Epoch[3/5]  [3370/4579]  eta: 0:07:03  Lr: 0.001875  Loss: -0.2555  Acc@1: 68.7500 (64.4208)  Acc@5: 87.5000 (91.4621)  time: 0.3490  data: 0.0009  max mem: 2500
Train: Epoch[3/5]  [3380/4579]  eta: 0:07:00  Lr: 0.001875  Loss: 0.1220  Acc@1: 62.5000 (64.4077)  Acc@5: 93.7500 (91.4689)  time: 0.3495  data: 0.0013  max mem: 2500
Train: Epoch[3/5]  [3390/4579]  eta: 0:06:56  Lr: 0.001875  Loss: -0.1424  Acc@1: 62.5000 (64.4132)  Acc@5: 93.7500 (91.4738)  time: 0.3506  data: 0.0019  max mem: 2500
Train: Epoch[3/5]  [3400/4579]  eta: 0:06:53  Lr: 0.001875  Loss: -0.1520  Acc@1: 68.7500 (64.4057)  Acc@5: 93.7500 (91.4786)  time: 0.3532  data: 0.0016  max mem: 2500
Train: Epoch[3/5]  [3410/4579]  eta: 0:06:49  Lr: 0.001875  Loss: -0.1717  Acc@1: 68.7500 (64.4111)  Acc@5: 93.7500 (91.4706)  time: 0.3531  data: 0.0010  max mem: 2500
Train: Epoch[3/5]  [3420/4579]  eta: 0:06:46  Lr: 0.001875  Loss: -0.1003  Acc@1: 68.7500 (64.4165)  Acc@5: 87.5000 (91.4773)  time: 0.3496  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [3430/4579]  eta: 0:06:42  Lr: 0.001875  Loss: -0.5252  Acc@1: 68.7500 (64.4236)  Acc@5: 93.7500 (91.4803)  time: 0.3492  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [3440/4579]  eta: 0:06:39  Lr: 0.001875  Loss: 0.2952  Acc@1: 68.7500 (64.4308)  Acc@5: 87.5000 (91.4760)  time: 0.3493  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [3450/4579]  eta: 0:06:35  Lr: 0.001875  Loss: -0.2661  Acc@1: 68.7500 (64.4415)  Acc@5: 93.7500 (91.4898)  time: 0.3499  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [3460/4579]  eta: 0:06:32  Lr: 0.001875  Loss: -0.2819  Acc@1: 68.7500 (64.4503)  Acc@5: 93.7500 (91.4891)  time: 0.3518  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [3470/4579]  eta: 0:06:28  Lr: 0.001875  Loss: -0.0390  Acc@1: 62.5000 (64.4339)  Acc@5: 87.5000 (91.4848)  time: 0.3516  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [3480/4579]  eta: 0:06:25  Lr: 0.001875  Loss: -0.3883  Acc@1: 62.5000 (64.4463)  Acc@5: 93.7500 (91.4877)  time: 0.3529  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [3490/4579]  eta: 0:06:21  Lr: 0.001875  Loss: -0.7376  Acc@1: 62.5000 (64.4532)  Acc@5: 93.7500 (91.4906)  time: 0.3526  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3500/4579]  eta: 0:06:18  Lr: 0.001875  Loss: 0.1737  Acc@1: 62.5000 (64.4352)  Acc@5: 87.5000 (91.4649)  time: 0.3506  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [3510/4579]  eta: 0:06:14  Lr: 0.001875  Loss: -0.2139  Acc@1: 62.5000 (64.4564)  Acc@5: 87.5000 (91.4732)  time: 0.3506  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [3520/4579]  eta: 0:06:11  Lr: 0.001875  Loss: -0.3132  Acc@1: 68.7500 (64.4703)  Acc@5: 93.7500 (91.4779)  time: 0.3522  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [3530/4579]  eta: 0:06:07  Lr: 0.001875  Loss: -0.3941  Acc@1: 62.5000 (64.4647)  Acc@5: 93.7500 (91.4702)  time: 0.3528  data: 0.0010  max mem: 2500
Train: Epoch[3/5]  [3540/4579]  eta: 0:06:04  Lr: 0.001875  Loss: -0.1812  Acc@1: 68.7500 (64.4627)  Acc@5: 93.7500 (91.4784)  time: 0.3510  data: 0.0011  max mem: 2500
Train: Epoch[3/5]  [3550/4579]  eta: 0:06:00  Lr: 0.001875  Loss: 0.1648  Acc@1: 68.7500 (64.4537)  Acc@5: 93.7500 (91.4795)  time: 0.3501  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [3560/4579]  eta: 0:05:57  Lr: 0.001875  Loss: -0.1913  Acc@1: 62.5000 (64.4605)  Acc@5: 93.7500 (91.4841)  time: 0.3493  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [3570/4579]  eta: 0:05:53  Lr: 0.001875  Loss: -0.0370  Acc@1: 62.5000 (64.4515)  Acc@5: 87.5000 (91.4730)  time: 0.3496  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [3580/4579]  eta: 0:05:50  Lr: 0.001875  Loss: -0.1633  Acc@1: 62.5000 (64.4565)  Acc@5: 87.5000 (91.4811)  time: 0.3510  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [3590/4579]  eta: 0:05:46  Lr: 0.001875  Loss: 0.0628  Acc@1: 68.7500 (64.4667)  Acc@5: 93.7500 (91.4891)  time: 0.3504  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [3600/4579]  eta: 0:05:43  Lr: 0.001875  Loss: -0.1412  Acc@1: 68.7500 (64.4804)  Acc@5: 93.7500 (91.4833)  time: 0.3497  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [3610/4579]  eta: 0:05:39  Lr: 0.001875  Loss: 0.1525  Acc@1: 68.7500 (64.4870)  Acc@5: 87.5000 (91.4826)  time: 0.3499  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [3620/4579]  eta: 0:05:36  Lr: 0.001875  Loss: 0.0734  Acc@1: 62.5000 (64.4936)  Acc@5: 87.5000 (91.4906)  time: 0.3493  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [3630/4579]  eta: 0:05:32  Lr: 0.001875  Loss: -0.6103  Acc@1: 62.5000 (64.5036)  Acc@5: 93.7500 (91.4899)  time: 0.3506  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3640/4579]  eta: 0:05:29  Lr: 0.001875  Loss: 0.8043  Acc@1: 68.7500 (64.5204)  Acc@5: 93.7500 (91.4944)  time: 0.3537  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [3650/4579]  eta: 0:05:25  Lr: 0.001875  Loss: -0.4617  Acc@1: 68.7500 (64.5097)  Acc@5: 93.7500 (91.4955)  time: 0.3527  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [3660/4579]  eta: 0:05:22  Lr: 0.001875  Loss: -0.5676  Acc@1: 62.5000 (64.5145)  Acc@5: 93.7500 (91.4931)  time: 0.3515  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [3670/4579]  eta: 0:05:18  Lr: 0.001875  Loss: 0.5012  Acc@1: 62.5000 (64.4920)  Acc@5: 87.5000 (91.4805)  time: 0.3537  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [3680/4579]  eta: 0:05:15  Lr: 0.001875  Loss: 0.0183  Acc@1: 62.5000 (64.5001)  Acc@5: 87.5000 (91.4867)  time: 0.3533  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [3690/4579]  eta: 0:05:11  Lr: 0.001875  Loss: -0.2703  Acc@1: 68.7500 (64.5100)  Acc@5: 93.7500 (91.4962)  time: 0.3505  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [3700/4579]  eta: 0:05:08  Lr: 0.001875  Loss: 0.1058  Acc@1: 62.5000 (64.5062)  Acc@5: 93.7500 (91.5006)  time: 0.3501  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [3710/4579]  eta: 0:05:04  Lr: 0.001875  Loss: -0.7843  Acc@1: 56.2500 (64.4890)  Acc@5: 93.7500 (91.5033)  time: 0.3506  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [3720/4579]  eta: 0:05:01  Lr: 0.001875  Loss: -0.3811  Acc@1: 62.5000 (64.4803)  Acc@5: 93.7500 (91.4993)  time: 0.3509  data: 0.0010  max mem: 2500
Train: Epoch[3/5]  [3730/4579]  eta: 0:04:57  Lr: 0.001875  Loss: -0.6268  Acc@1: 62.5000 (64.4834)  Acc@5: 93.7500 (91.5070)  time: 0.3512  data: 0.0011  max mem: 2500
Train: Epoch[3/5]  [3740/4579]  eta: 0:04:54  Lr: 0.001875  Loss: 0.4352  Acc@1: 62.5000 (64.4580)  Acc@5: 93.7500 (91.5013)  time: 0.3496  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [3750/4579]  eta: 0:04:50  Lr: 0.001875  Loss: -0.8582  Acc@1: 62.5000 (64.4728)  Acc@5: 93.7500 (91.5073)  time: 0.3533  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [3760/4579]  eta: 0:04:47  Lr: 0.001875  Loss: -0.5090  Acc@1: 62.5000 (64.4676)  Acc@5: 93.7500 (91.5132)  time: 0.3573  data: 0.0009  max mem: 2500
Train: Epoch[3/5]  [3770/4579]  eta: 0:04:43  Lr: 0.001875  Loss: -0.0842  Acc@1: 62.5000 (64.4773)  Acc@5: 93.7500 (91.5241)  time: 0.3546  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [3780/4579]  eta: 0:04:40  Lr: 0.001875  Loss: -0.0456  Acc@1: 62.5000 (64.4671)  Acc@5: 93.7500 (91.5201)  time: 0.3535  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [3790/4579]  eta: 0:04:36  Lr: 0.001875  Loss: -0.0804  Acc@1: 62.5000 (64.4718)  Acc@5: 87.5000 (91.5194)  time: 0.3538  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [3800/4579]  eta: 0:04:33  Lr: 0.001875  Loss: -0.5812  Acc@1: 68.7500 (64.4781)  Acc@5: 93.7500 (91.5285)  time: 0.3509  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [3810/4579]  eta: 0:04:29  Lr: 0.001875  Loss: -0.3682  Acc@1: 68.7500 (64.4860)  Acc@5: 93.7500 (91.5327)  time: 0.3507  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [3820/4579]  eta: 0:04:26  Lr: 0.001875  Loss: 0.2919  Acc@1: 68.7500 (64.4825)  Acc@5: 93.7500 (91.5287)  time: 0.3527  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3830/4579]  eta: 0:04:22  Lr: 0.001875  Loss: -0.5570  Acc@1: 68.7500 (64.4903)  Acc@5: 93.7500 (91.5459)  time: 0.3523  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [3840/4579]  eta: 0:04:19  Lr: 0.001875  Loss: -0.1093  Acc@1: 62.5000 (64.4705)  Acc@5: 93.7500 (91.5419)  time: 0.3504  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [3850/4579]  eta: 0:04:15  Lr: 0.001875  Loss: -0.2773  Acc@1: 56.2500 (64.4654)  Acc@5: 87.5000 (91.5428)  time: 0.3493  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [3860/4579]  eta: 0:04:12  Lr: 0.001875  Loss: 0.2584  Acc@1: 62.5000 (64.4716)  Acc@5: 93.7500 (91.5420)  time: 0.3502  data: 0.0010  max mem: 2500
Train: Epoch[3/5]  [3870/4579]  eta: 0:04:08  Lr: 0.001875  Loss: -0.1320  Acc@1: 68.7500 (64.4698)  Acc@5: 93.7500 (91.5364)  time: 0.3507  data: 0.0009  max mem: 2500
Train: Epoch[3/5]  [3880/4579]  eta: 0:04:05  Lr: 0.001875  Loss: -0.3327  Acc@1: 62.5000 (64.4711)  Acc@5: 93.7500 (91.5405)  time: 0.3515  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [3890/4579]  eta: 0:04:01  Lr: 0.001875  Loss: -0.8325  Acc@1: 62.5000 (64.4821)  Acc@5: 93.7500 (91.5382)  time: 0.3503  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [3900/4579]  eta: 0:03:58  Lr: 0.001875  Loss: -0.6270  Acc@1: 68.7500 (64.5027)  Acc@5: 93.7500 (91.5422)  time: 0.3493  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [3910/4579]  eta: 0:03:54  Lr: 0.001875  Loss: 0.4718  Acc@1: 68.7500 (64.5040)  Acc@5: 93.7500 (91.5479)  time: 0.3500  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [3920/4579]  eta: 0:03:51  Lr: 0.001875  Loss: -0.5438  Acc@1: 68.7500 (64.4989)  Acc@5: 93.7500 (91.5487)  time: 0.3522  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [3930/4579]  eta: 0:03:47  Lr: 0.001875  Loss: 0.1365  Acc@1: 68.7500 (64.5033)  Acc@5: 93.7500 (91.5511)  time: 0.3537  data: 0.0011  max mem: 2500
Train: Epoch[3/5]  [3940/4579]  eta: 0:03:44  Lr: 0.001875  Loss: -0.3176  Acc@1: 62.5000 (64.5014)  Acc@5: 93.7500 (91.5520)  time: 0.3501  data: 0.0009  max mem: 2500
Train: Epoch[3/5]  [3950/4579]  eta: 0:03:40  Lr: 0.001875  Loss: -0.5152  Acc@1: 68.7500 (64.5201)  Acc@5: 93.7500 (91.5544)  time: 0.3487  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [3960/4579]  eta: 0:03:37  Lr: 0.001875  Loss: 0.1881  Acc@1: 68.7500 (64.5150)  Acc@5: 93.7500 (91.5520)  time: 0.3497  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [3970/4579]  eta: 0:03:33  Lr: 0.001875  Loss: 0.0207  Acc@1: 62.5000 (64.5209)  Acc@5: 93.7500 (91.5560)  time: 0.3496  data: 0.0009  max mem: 2500
Train: Epoch[3/5]  [3980/4579]  eta: 0:03:30  Lr: 0.001875  Loss: -0.2981  Acc@1: 68.7500 (64.5221)  Acc@5: 87.5000 (91.5489)  time: 0.3492  data: 0.0010  max mem: 2500
Train: Epoch[3/5]  [3990/4579]  eta: 0:03:26  Lr: 0.001875  Loss: -0.2239  Acc@1: 68.7500 (64.5170)  Acc@5: 87.5000 (91.5403)  time: 0.3495  data: 0.0010  max mem: 2500
Train: Epoch[3/5]  [4000/4579]  eta: 0:03:23  Lr: 0.001875  Loss: 0.3909  Acc@1: 68.7500 (64.5261)  Acc@5: 87.5000 (91.5318)  time: 0.3513  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [4010/4579]  eta: 0:03:19  Lr: 0.001875  Loss: -0.0123  Acc@1: 68.7500 (64.5226)  Acc@5: 93.7500 (91.5327)  time: 0.3506  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [4020/4579]  eta: 0:03:16  Lr: 0.001875  Loss: -0.1097  Acc@1: 62.5000 (64.5424)  Acc@5: 93.7500 (91.5366)  time: 0.3508  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [4030/4579]  eta: 0:03:12  Lr: 0.001875  Loss: 0.3017  Acc@1: 62.5000 (64.5358)  Acc@5: 93.7500 (91.5390)  time: 0.3522  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [4040/4579]  eta: 0:03:09  Lr: 0.001875  Loss: -0.1679  Acc@1: 62.5000 (64.5385)  Acc@5: 93.7500 (91.5460)  time: 0.3510  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [4050/4579]  eta: 0:03:05  Lr: 0.001875  Loss: 0.0092  Acc@1: 62.5000 (64.5442)  Acc@5: 93.7500 (91.5530)  time: 0.3522  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [4060/4579]  eta: 0:03:02  Lr: 0.001875  Loss: -0.2553  Acc@1: 62.5000 (64.5377)  Acc@5: 93.7500 (91.5492)  time: 0.3543  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [4070/4579]  eta: 0:02:58  Lr: 0.001875  Loss: 0.2240  Acc@1: 56.2500 (64.5127)  Acc@5: 93.7500 (91.5531)  time: 0.3522  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [4080/4579]  eta: 0:02:55  Lr: 0.001875  Loss: -0.0818  Acc@1: 56.2500 (64.5108)  Acc@5: 93.7500 (91.5538)  time: 0.3513  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [4090/4579]  eta: 0:02:51  Lr: 0.001875  Loss: -0.1531  Acc@1: 68.7500 (64.5212)  Acc@5: 93.7500 (91.5516)  time: 0.3521  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [4100/4579]  eta: 0:02:47  Lr: 0.001875  Loss: -0.1814  Acc@1: 68.7500 (64.5254)  Acc@5: 93.7500 (91.5539)  time: 0.3497  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [4110/4579]  eta: 0:02:44  Lr: 0.001875  Loss: -0.0008  Acc@1: 68.7500 (64.5327)  Acc@5: 93.7500 (91.5532)  time: 0.3494  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [4120/4579]  eta: 0:02:40  Lr: 0.001875  Loss: -0.5428  Acc@1: 68.7500 (64.5444)  Acc@5: 93.7500 (91.5570)  time: 0.3491  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [4130/4579]  eta: 0:02:37  Lr: 0.001875  Loss: -0.4513  Acc@1: 62.5000 (64.5349)  Acc@5: 93.7500 (91.5562)  time: 0.3492  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [4140/4579]  eta: 0:02:33  Lr: 0.001875  Loss: -0.0480  Acc@1: 62.5000 (64.5436)  Acc@5: 93.7500 (91.5585)  time: 0.3508  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [4150/4579]  eta: 0:02:30  Lr: 0.001875  Loss: -0.7603  Acc@1: 68.7500 (64.5567)  Acc@5: 93.7500 (91.5623)  time: 0.3495  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [4160/4579]  eta: 0:02:26  Lr: 0.001875  Loss: -0.0832  Acc@1: 68.7500 (64.5713)  Acc@5: 93.7500 (91.5675)  time: 0.3490  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [4170/4579]  eta: 0:02:23  Lr: 0.001875  Loss: -0.1376  Acc@1: 68.7500 (64.5693)  Acc@5: 93.7500 (91.5638)  time: 0.3514  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [4180/4579]  eta: 0:02:19  Lr: 0.001875  Loss: -0.3061  Acc@1: 68.7500 (64.5779)  Acc@5: 87.5000 (91.5645)  time: 0.3517  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [4190/4579]  eta: 0:02:16  Lr: 0.001875  Loss: -0.5712  Acc@1: 68.7500 (64.5818)  Acc@5: 87.5000 (91.5608)  time: 0.3503  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [4200/4579]  eta: 0:02:12  Lr: 0.001875  Loss: -0.4113  Acc@1: 62.5000 (64.5843)  Acc@5: 87.5000 (91.5556)  time: 0.3515  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [4210/4579]  eta: 0:02:09  Lr: 0.001875  Loss: 0.1470  Acc@1: 62.5000 (64.5764)  Acc@5: 87.5000 (91.5534)  time: 0.3512  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [4220/4579]  eta: 0:02:05  Lr: 0.001875  Loss: -0.0782  Acc@1: 62.5000 (64.5907)  Acc@5: 93.7500 (91.5601)  time: 0.3518  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [4230/4579]  eta: 0:02:02  Lr: 0.001875  Loss: -0.4356  Acc@1: 68.7500 (64.5932)  Acc@5: 93.7500 (91.5638)  time: 0.3513  data: 0.0009  max mem: 2500
Train: Epoch[3/5]  [4240/4579]  eta: 0:01:58  Lr: 0.001875  Loss: 0.2003  Acc@1: 68.7500 (64.5971)  Acc@5: 93.7500 (91.5645)  time: 0.3478  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [4250/4579]  eta: 0:01:55  Lr: 0.001875  Loss: -0.1062  Acc@1: 68.7500 (64.5907)  Acc@5: 93.7500 (91.5711)  time: 0.3469  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [4260/4579]  eta: 0:01:51  Lr: 0.001875  Loss: -0.5408  Acc@1: 62.5000 (64.5990)  Acc@5: 93.7500 (91.5718)  time: 0.3488  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [4270/4579]  eta: 0:01:48  Lr: 0.001875  Loss: 0.0669  Acc@1: 62.5000 (64.5999)  Acc@5: 93.7500 (91.5696)  time: 0.3485  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [4280/4579]  eta: 0:01:44  Lr: 0.001875  Loss: -0.0342  Acc@1: 62.5000 (64.5994)  Acc@5: 93.7500 (91.5659)  time: 0.3476  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [4290/4579]  eta: 0:01:41  Lr: 0.001875  Loss: -0.6373  Acc@1: 62.5000 (64.6032)  Acc@5: 93.7500 (91.5667)  time: 0.3488  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [4300/4579]  eta: 0:01:37  Lr: 0.001875  Loss: -0.4020  Acc@1: 68.7500 (64.6114)  Acc@5: 93.7500 (91.5804)  time: 0.3498  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [4310/4579]  eta: 0:01:34  Lr: 0.001875  Loss: 0.1153  Acc@1: 62.5000 (64.6065)  Acc@5: 100.0000 (91.5884)  time: 0.3498  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [4320/4579]  eta: 0:01:30  Lr: 0.001875  Loss: -0.2827  Acc@1: 62.5000 (64.6074)  Acc@5: 93.7500 (91.5876)  time: 0.3504  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [4330/4579]  eta: 0:01:27  Lr: 0.001875  Loss: -0.1694  Acc@1: 62.5000 (64.5997)  Acc@5: 93.7500 (91.5868)  time: 0.3513  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [4340/4579]  eta: 0:01:23  Lr: 0.001875  Loss: -0.0278  Acc@1: 62.5000 (64.6064)  Acc@5: 93.7500 (91.5889)  time: 0.3500  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [4350/4579]  eta: 0:01:20  Lr: 0.001875  Loss: -0.2489  Acc@1: 62.5000 (64.5929)  Acc@5: 93.7500 (91.5838)  time: 0.3502  data: 0.0017  max mem: 2500
Train: Epoch[3/5]  [4360/4579]  eta: 0:01:16  Lr: 0.001875  Loss: -0.2876  Acc@1: 62.5000 (64.5953)  Acc@5: 93.7500 (91.5831)  time: 0.3514  data: 0.0016  max mem: 2500
Train: Epoch[3/5]  [4370/4579]  eta: 0:01:13  Lr: 0.001875  Loss: -0.4661  Acc@1: 62.5000 (64.5733)  Acc@5: 93.7500 (91.5823)  time: 0.3510  data: 0.0009  max mem: 2500
Train: Epoch[3/5]  [4380/4579]  eta: 0:01:09  Lr: 0.001875  Loss: -0.2597  Acc@1: 62.5000 (64.5743)  Acc@5: 87.5000 (91.5787)  time: 0.3494  data: 0.0010  max mem: 2500
Train: Epoch[3/5]  [4390/4579]  eta: 0:01:06  Lr: 0.001875  Loss: 0.0161  Acc@1: 62.5000 (64.5767)  Acc@5: 87.5000 (91.5751)  time: 0.3494  data: 0.0010  max mem: 2500
Train: Epoch[3/5]  [4400/4579]  eta: 0:01:02  Lr: 0.001875  Loss: -0.2029  Acc@1: 62.5000 (64.5805)  Acc@5: 93.7500 (91.5729)  time: 0.3505  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [4410/4579]  eta: 0:00:59  Lr: 0.001875  Loss: -0.6115  Acc@1: 62.5000 (64.5758)  Acc@5: 93.7500 (91.5736)  time: 0.3498  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [4420/4579]  eta: 0:00:55  Lr: 0.001875  Loss: -0.4881  Acc@1: 62.5000 (64.5668)  Acc@5: 93.7500 (91.5771)  time: 0.3499  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [4430/4579]  eta: 0:00:52  Lr: 0.001875  Loss: -0.3207  Acc@1: 62.5000 (64.5608)  Acc@5: 93.7500 (91.5665)  time: 0.3505  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [4440/4579]  eta: 0:00:48  Lr: 0.001875  Loss: -0.1658  Acc@1: 68.7500 (64.5716)  Acc@5: 93.7500 (91.5686)  time: 0.3487  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [4450/4579]  eta: 0:00:45  Lr: 0.001875  Loss: 0.3016  Acc@1: 68.7500 (64.5712)  Acc@5: 93.7500 (91.5679)  time: 0.3481  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [4460/4579]  eta: 0:00:41  Lr: 0.001875  Loss: -0.3412  Acc@1: 62.5000 (64.5735)  Acc@5: 93.7500 (91.5672)  time: 0.3487  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [4470/4579]  eta: 0:00:38  Lr: 0.001875  Loss: -0.4265  Acc@1: 68.7500 (64.5913)  Acc@5: 93.7500 (91.5763)  time: 0.3492  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [4480/4579]  eta: 0:00:34  Lr: 0.001875  Loss: -0.7660  Acc@1: 68.7500 (64.5991)  Acc@5: 93.7500 (91.5769)  time: 0.3486  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [4490/4579]  eta: 0:00:31  Lr: 0.001875  Loss: -0.2776  Acc@1: 62.5000 (64.5903)  Acc@5: 93.7500 (91.5790)  time: 0.3494  data: 0.0010  max mem: 2500
Train: Epoch[3/5]  [4500/4579]  eta: 0:00:27  Lr: 0.001875  Loss: -0.5425  Acc@1: 62.5000 (64.5870)  Acc@5: 93.7500 (91.5810)  time: 0.3496  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [4510/4579]  eta: 0:00:24  Lr: 0.001875  Loss: 0.3086  Acc@1: 62.5000 (64.5838)  Acc@5: 93.7500 (91.5775)  time: 0.3483  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [4520/4579]  eta: 0:00:20  Lr: 0.001875  Loss: -0.8359  Acc@1: 62.5000 (64.5985)  Acc@5: 93.7500 (91.5810)  time: 0.3485  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [4530/4579]  eta: 0:00:17  Lr: 0.001875  Loss: -0.3867  Acc@1: 68.7500 (64.6132)  Acc@5: 93.7500 (91.5871)  time: 0.3491  data: 0.0009  max mem: 2500
Train: Epoch[3/5]  [4540/4579]  eta: 0:00:13  Lr: 0.001875  Loss: -0.5831  Acc@1: 68.7500 (64.6320)  Acc@5: 93.7500 (91.5864)  time: 0.3488  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [4550/4579]  eta: 0:00:10  Lr: 0.001875  Loss: -0.1462  Acc@1: 68.7500 (64.6218)  Acc@5: 87.5000 (91.5815)  time: 0.3476  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [4560/4579]  eta: 0:00:06  Lr: 0.001875  Loss: 0.0543  Acc@1: 62.5000 (64.6212)  Acc@5: 87.5000 (91.5767)  time: 0.3484  data: 0.0011  max mem: 2500
Train: Epoch[3/5]  [4570/4579]  eta: 0:00:03  Lr: 0.001875  Loss: -0.5444  Acc@1: 62.5000 (64.6152)  Acc@5: 93.7500 (91.5814)  time: 0.3503  data: 0.0020  max mem: 2500
Train: Epoch[3/5]  [4578/4579]  eta: 0:00:00  Lr: 0.001875  Loss: -0.9506  Acc@1: 56.2500 (64.6123)  Acc@5: 93.7500 (91.5831)  time: 0.3424  data: 0.0016  max mem: 2500
Train: Epoch[3/5] Total time: 0:26:46 (0.3508 s / it)
{0: {0: 219771, 1: 0, 2: 0, 3: 0, 4: 0}, 1: {0: 219771, 1: 0, 2: 0, 3: 0, 4: 0}, 2: {0: 219771, 1: 0, 2: 0, 3: 0, 4: 0}, 3: {0: 219771, 1: 0, 2: 0, 3: 0, 4: 0}, 4: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 5: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 6: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 7: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 8: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 9: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 10: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 11: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 12: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 13: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 14: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 15: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 16: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 17: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 18: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 19: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}}
Averaged stats: Lr: 0.001875  Loss: -0.9506  Acc@1: 56.2500 (64.6123)  Acc@5: 93.7500 (91.5831)
Train: Epoch[4/5]  [   0/4579]  eta: 0:59:46  Lr: 0.001875  Loss: -0.3224  Acc@1: 75.0000 (75.0000)  Acc@5: 87.5000 (87.5000)  time: 0.7832  data: 0.4329  max mem: 2500
Train: Epoch[4/5]  [  10/4579]  eta: 0:29:34  Lr: 0.001875  Loss: 0.0391  Acc@1: 68.7500 (64.7727)  Acc@5: 93.7500 (92.0455)  time: 0.3885  data: 0.0397  max mem: 2500
Train: Epoch[4/5]  [  20/4579]  eta: 0:28:05  Lr: 0.001875  Loss: -0.5764  Acc@1: 68.7500 (66.0714)  Acc@5: 93.7500 (92.5595)  time: 0.3491  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [  30/4579]  eta: 0:27:32  Lr: 0.001875  Loss: 0.0205  Acc@1: 68.7500 (66.7339)  Acc@5: 87.5000 (91.7339)  time: 0.3494  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [  40/4579]  eta: 0:27:16  Lr: 0.001875  Loss: 0.2101  Acc@1: 68.7500 (65.8537)  Acc@5: 87.5000 (91.1585)  time: 0.3509  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [  50/4579]  eta: 0:27:03  Lr: 0.001875  Loss: -0.6284  Acc@1: 68.7500 (66.7892)  Acc@5: 93.7500 (91.9118)  time: 0.3511  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [  60/4579]  eta: 0:26:55  Lr: 0.001875  Loss: 0.0631  Acc@1: 68.7500 (66.5984)  Acc@5: 93.7500 (91.5984)  time: 0.3515  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [  70/4579]  eta: 0:26:46  Lr: 0.001875  Loss: -0.5483  Acc@1: 62.5000 (66.2852)  Acc@5: 87.5000 (91.3732)  time: 0.3507  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [  80/4579]  eta: 0:26:40  Lr: 0.001875  Loss: 0.4250  Acc@1: 62.5000 (66.2809)  Acc@5: 87.5000 (91.2809)  time: 0.3498  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [  90/4579]  eta: 0:26:36  Lr: 0.001875  Loss: -0.1650  Acc@1: 62.5000 (66.2088)  Acc@5: 93.7500 (91.5522)  time: 0.3537  data: 0.0012  max mem: 2500
Train: Epoch[4/5]  [ 100/4579]  eta: 0:26:32  Lr: 0.001875  Loss: -0.1205  Acc@1: 68.7500 (66.3985)  Acc@5: 93.7500 (91.4604)  time: 0.3546  data: 0.0011  max mem: 2500
Train: Epoch[4/5]  [ 110/4579]  eta: 0:26:25  Lr: 0.001875  Loss: 0.0099  Acc@1: 68.7500 (66.8919)  Acc@5: 93.7500 (91.4977)  time: 0.3500  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [ 120/4579]  eta: 0:26:20  Lr: 0.001875  Loss: -0.1874  Acc@1: 62.5000 (66.0124)  Acc@5: 93.7500 (91.4773)  time: 0.3488  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [ 130/4579]  eta: 0:26:14  Lr: 0.001875  Loss: -0.5733  Acc@1: 62.5000 (66.2691)  Acc@5: 93.7500 (91.8893)  time: 0.3501  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [ 140/4579]  eta: 0:26:11  Lr: 0.001875  Loss: -0.4717  Acc@1: 68.7500 (66.3564)  Acc@5: 93.7500 (91.9326)  time: 0.3513  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [ 150/4579]  eta: 0:26:07  Lr: 0.001875  Loss: -0.3264  Acc@1: 68.7500 (66.5977)  Acc@5: 93.7500 (91.9288)  time: 0.3528  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [ 160/4579]  eta: 0:26:01  Lr: 0.001875  Loss: -0.1785  Acc@1: 68.7500 (66.6537)  Acc@5: 87.5000 (91.8866)  time: 0.3499  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [ 170/4579]  eta: 0:25:57  Lr: 0.001875  Loss: -0.0161  Acc@1: 62.5000 (66.4108)  Acc@5: 87.5000 (91.6667)  time: 0.3488  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [ 180/4579]  eta: 0:25:53  Lr: 0.001875  Loss: -0.2729  Acc@1: 62.5000 (66.3329)  Acc@5: 93.7500 (91.7472)  time: 0.3511  data: 0.0009  max mem: 2500
Train: Epoch[4/5]  [ 190/4579]  eta: 0:25:49  Lr: 0.001875  Loss: 0.0988  Acc@1: 62.5000 (66.3285)  Acc@5: 93.7500 (91.8194)  time: 0.3523  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [ 200/4579]  eta: 0:25:45  Lr: 0.001875  Loss: 0.1708  Acc@1: 62.5000 (66.2624)  Acc@5: 93.7500 (91.8532)  time: 0.3515  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [ 210/4579]  eta: 0:25:41  Lr: 0.001875  Loss: -0.2999  Acc@1: 62.5000 (66.1434)  Acc@5: 93.7500 (92.0320)  time: 0.3498  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [ 220/4579]  eta: 0:25:37  Lr: 0.001875  Loss: 0.6230  Acc@1: 62.5000 (65.9785)  Acc@5: 93.7500 (91.9966)  time: 0.3504  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [ 230/4579]  eta: 0:25:33  Lr: 0.001875  Loss: -0.0978  Acc@1: 62.5000 (65.7738)  Acc@5: 87.5000 (92.0184)  time: 0.3513  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [ 240/4579]  eta: 0:25:30  Lr: 0.001875  Loss: -0.2182  Acc@1: 68.7500 (65.9751)  Acc@5: 93.7500 (92.0384)  time: 0.3522  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [ 250/4579]  eta: 0:25:26  Lr: 0.001875  Loss: 0.5647  Acc@1: 68.7500 (65.8367)  Acc@5: 93.7500 (91.9323)  time: 0.3510  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [ 260/4579]  eta: 0:25:23  Lr: 0.001875  Loss: -0.4326  Acc@1: 68.7500 (65.9004)  Acc@5: 93.7500 (92.0259)  time: 0.3515  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [ 270/4579]  eta: 0:25:19  Lr: 0.001875  Loss: 0.7775  Acc@1: 62.5000 (65.7980)  Acc@5: 93.7500 (91.8589)  time: 0.3540  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [ 280/4579]  eta: 0:25:15  Lr: 0.001875  Loss: -0.5561  Acc@1: 68.7500 (65.9698)  Acc@5: 93.7500 (91.9484)  time: 0.3512  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [ 290/4579]  eta: 0:25:11  Lr: 0.001875  Loss: 0.0337  Acc@1: 68.7500 (65.9794)  Acc@5: 93.7500 (91.8814)  time: 0.3496  data: 0.0009  max mem: 2500
Train: Epoch[4/5]  [ 300/4579]  eta: 0:25:07  Lr: 0.001875  Loss: 0.0120  Acc@1: 68.7500 (65.9468)  Acc@5: 93.7500 (91.9228)  time: 0.3503  data: 0.0010  max mem: 2500
Train: Epoch[4/5]  [ 310/4579]  eta: 0:25:03  Lr: 0.001875  Loss: -0.2536  Acc@1: 62.5000 (65.8561)  Acc@5: 87.5000 (91.6801)  time: 0.3499  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [ 320/4579]  eta: 0:25:00  Lr: 0.001875  Loss: -0.2435  Acc@1: 68.7500 (66.0241)  Acc@5: 87.5000 (91.7251)  time: 0.3501  data: 0.0009  max mem: 2500
Train: Epoch[4/5]  [ 330/4579]  eta: 0:24:56  Lr: 0.001875  Loss: -0.0393  Acc@1: 68.7500 (65.8233)  Acc@5: 93.7500 (91.5219)  time: 0.3501  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [ 340/4579]  eta: 0:24:52  Lr: 0.001875  Loss: -0.0562  Acc@1: 62.5000 (65.8541)  Acc@5: 87.5000 (91.4956)  time: 0.3514  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [ 350/4579]  eta: 0:24:49  Lr: 0.001875  Loss: -0.4429  Acc@1: 68.7500 (65.9900)  Acc@5: 87.5000 (91.4708)  time: 0.3524  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [ 360/4579]  eta: 0:24:45  Lr: 0.001875  Loss: -0.0343  Acc@1: 68.7500 (65.9799)  Acc@5: 87.5000 (91.3435)  time: 0.3507  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [ 370/4579]  eta: 0:24:41  Lr: 0.001875  Loss: -0.2178  Acc@1: 62.5000 (66.0209)  Acc@5: 87.5000 (91.2230)  time: 0.3491  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 380/4579]  eta: 0:24:38  Lr: 0.001875  Loss: -0.0484  Acc@1: 62.5000 (65.8957)  Acc@5: 87.5000 (91.2402)  time: 0.3507  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [ 390/4579]  eta: 0:24:34  Lr: 0.001875  Loss: -0.2722  Acc@1: 62.5000 (65.7609)  Acc@5: 87.5000 (91.1605)  time: 0.3508  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [ 400/4579]  eta: 0:24:30  Lr: 0.001875  Loss: -0.1915  Acc@1: 62.5000 (65.6484)  Acc@5: 87.5000 (91.1160)  time: 0.3494  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [ 410/4579]  eta: 0:24:27  Lr: 0.001875  Loss: -0.4237  Acc@1: 68.7500 (65.7543)  Acc@5: 93.7500 (91.1953)  time: 0.3510  data: 0.0013  max mem: 2500
Train: Epoch[4/5]  [ 420/4579]  eta: 0:24:23  Lr: 0.001875  Loss: -0.5935  Acc@1: 68.7500 (65.8848)  Acc@5: 93.7500 (91.3005)  time: 0.3499  data: 0.0012  max mem: 2500
Train: Epoch[4/5]  [ 430/4579]  eta: 0:24:19  Lr: 0.001875  Loss: -0.1827  Acc@1: 68.7500 (65.9368)  Acc@5: 93.7500 (91.3138)  time: 0.3494  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [ 440/4579]  eta: 0:24:16  Lr: 0.001875  Loss: -0.7383  Acc@1: 68.7500 (66.0431)  Acc@5: 93.7500 (91.4399)  time: 0.3524  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [ 450/4579]  eta: 0:24:12  Lr: 0.001875  Loss: 0.0069  Acc@1: 62.5000 (65.8537)  Acc@5: 93.7500 (91.4080)  time: 0.3514  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [ 460/4579]  eta: 0:24:08  Lr: 0.001875  Loss: -0.5541  Acc@1: 62.5000 (65.8623)  Acc@5: 93.7500 (91.4723)  time: 0.3497  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [ 470/4579]  eta: 0:24:05  Lr: 0.001875  Loss: 0.1218  Acc@1: 62.5000 (65.6582)  Acc@5: 93.7500 (91.4411)  time: 0.3498  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [ 480/4579]  eta: 0:24:01  Lr: 0.001875  Loss: -0.0631  Acc@1: 56.2500 (65.6055)  Acc@5: 93.7500 (91.4371)  time: 0.3514  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [ 490/4579]  eta: 0:23:57  Lr: 0.001875  Loss: 0.0214  Acc@1: 56.2500 (65.4022)  Acc@5: 93.7500 (91.4078)  time: 0.3514  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [ 500/4579]  eta: 0:23:54  Lr: 0.001875  Loss: -0.2568  Acc@1: 56.2500 (65.2445)  Acc@5: 87.5000 (91.3423)  time: 0.3494  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [ 510/4579]  eta: 0:23:50  Lr: 0.001875  Loss: -0.2325  Acc@1: 62.5000 (65.1786)  Acc@5: 87.5000 (91.3283)  time: 0.3518  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [ 520/4579]  eta: 0:23:47  Lr: 0.001875  Loss: -0.0350  Acc@1: 62.5000 (65.2111)  Acc@5: 93.7500 (91.3868)  time: 0.3521  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [ 530/4579]  eta: 0:23:43  Lr: 0.001875  Loss: -0.6902  Acc@1: 62.5000 (65.2072)  Acc@5: 93.7500 (91.4077)  time: 0.3510  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [ 540/4579]  eta: 0:23:40  Lr: 0.001875  Loss: -0.6399  Acc@1: 62.5000 (65.1802)  Acc@5: 93.7500 (91.4048)  time: 0.3510  data: 0.0013  max mem: 2500
Train: Epoch[4/5]  [ 550/4579]  eta: 0:23:36  Lr: 0.001875  Loss: -0.7258  Acc@1: 62.5000 (65.1996)  Acc@5: 93.7500 (91.4247)  time: 0.3502  data: 0.0016  max mem: 2500
Train: Epoch[4/5]  [ 560/4579]  eta: 0:23:32  Lr: 0.001875  Loss: -0.3012  Acc@1: 62.5000 (65.1961)  Acc@5: 93.7500 (91.4661)  time: 0.3489  data: 0.0009  max mem: 2500
Train: Epoch[4/5]  [ 570/4579]  eta: 0:23:29  Lr: 0.001875  Loss: -0.1297  Acc@1: 62.5000 (65.1489)  Acc@5: 93.7500 (91.4733)  time: 0.3484  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [ 580/4579]  eta: 0:23:25  Lr: 0.001875  Loss: -0.1911  Acc@1: 56.2500 (65.1248)  Acc@5: 93.7500 (91.5232)  time: 0.3477  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [ 590/4579]  eta: 0:23:21  Lr: 0.001875  Loss: -0.2908  Acc@1: 62.5000 (65.0486)  Acc@5: 93.7500 (91.4763)  time: 0.3468  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [ 600/4579]  eta: 0:23:17  Lr: 0.001875  Loss: -0.6748  Acc@1: 62.5000 (65.0478)  Acc@5: 93.7500 (91.5349)  time: 0.3493  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [ 610/4579]  eta: 0:23:14  Lr: 0.001875  Loss: 0.0978  Acc@1: 62.5000 (65.0982)  Acc@5: 93.7500 (91.5610)  time: 0.3510  data: 0.0009  max mem: 2500
Train: Epoch[4/5]  [ 620/4579]  eta: 0:23:10  Lr: 0.001875  Loss: -0.0531  Acc@1: 62.5000 (65.0362)  Acc@5: 93.7500 (91.5056)  time: 0.3513  data: 0.0010  max mem: 2500
Train: Epoch[4/5]  [ 630/4579]  eta: 0:23:07  Lr: 0.001875  Loss: -0.5343  Acc@1: 68.7500 (65.1050)  Acc@5: 93.7500 (91.5412)  time: 0.3507  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [ 640/4579]  eta: 0:23:03  Lr: 0.001875  Loss: -0.2435  Acc@1: 68.7500 (65.0644)  Acc@5: 93.7500 (91.5464)  time: 0.3494  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [ 650/4579]  eta: 0:23:00  Lr: 0.001875  Loss: -0.3572  Acc@1: 62.5000 (65.0730)  Acc@5: 87.5000 (91.5227)  time: 0.3493  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [ 660/4579]  eta: 0:22:56  Lr: 0.001875  Loss: -0.2676  Acc@1: 68.7500 (65.1664)  Acc@5: 93.7500 (91.5469)  time: 0.3483  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [ 670/4579]  eta: 0:22:52  Lr: 0.001875  Loss: 0.0330  Acc@1: 68.7500 (65.1919)  Acc@5: 93.7500 (91.5518)  time: 0.3482  data: 0.0012  max mem: 2500
Train: Epoch[4/5]  [ 680/4579]  eta: 0:22:48  Lr: 0.001875  Loss: 0.1177  Acc@1: 68.7500 (65.1707)  Acc@5: 93.7500 (91.5382)  time: 0.3487  data: 0.0012  max mem: 2500
Train: Epoch[4/5]  [ 690/4579]  eta: 0:22:45  Lr: 0.001875  Loss: -0.3960  Acc@1: 62.5000 (65.1773)  Acc@5: 93.7500 (91.5250)  time: 0.3488  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [ 700/4579]  eta: 0:22:41  Lr: 0.001875  Loss: -0.1148  Acc@1: 62.5000 (65.1569)  Acc@5: 93.7500 (91.5389)  time: 0.3490  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 710/4579]  eta: 0:22:38  Lr: 0.001875  Loss: 0.2708  Acc@1: 62.5000 (65.1371)  Acc@5: 93.7500 (91.5524)  time: 0.3515  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [ 720/4579]  eta: 0:22:34  Lr: 0.001875  Loss: -0.7630  Acc@1: 62.5000 (65.1612)  Acc@5: 87.5000 (91.5395)  time: 0.3538  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [ 730/4579]  eta: 0:22:31  Lr: 0.001875  Loss: 0.2946  Acc@1: 62.5000 (65.2103)  Acc@5: 87.5000 (91.5527)  time: 0.3530  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 740/4579]  eta: 0:22:28  Lr: 0.001875  Loss: -0.4942  Acc@1: 68.7500 (65.1738)  Acc@5: 93.7500 (91.5908)  time: 0.3517  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [ 750/4579]  eta: 0:22:24  Lr: 0.001875  Loss: 0.3834  Acc@1: 62.5000 (65.1381)  Acc@5: 93.7500 (91.5696)  time: 0.3501  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [ 760/4579]  eta: 0:22:20  Lr: 0.001875  Loss: 0.1190  Acc@1: 62.5000 (65.1445)  Acc@5: 93.7500 (91.6147)  time: 0.3486  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [ 770/4579]  eta: 0:22:17  Lr: 0.001875  Loss: -0.3942  Acc@1: 68.7500 (65.0940)  Acc@5: 93.7500 (91.6099)  time: 0.3477  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [ 780/4579]  eta: 0:22:13  Lr: 0.001875  Loss: 0.3258  Acc@1: 62.5000 (65.0048)  Acc@5: 93.7500 (91.6053)  time: 0.3486  data: 0.0012  max mem: 2500
Train: Epoch[4/5]  [ 790/4579]  eta: 0:22:09  Lr: 0.001875  Loss: -0.3029  Acc@1: 62.5000 (65.0917)  Acc@5: 93.7500 (91.5929)  time: 0.3487  data: 0.0011  max mem: 2500
Train: Epoch[4/5]  [ 800/4579]  eta: 0:22:06  Lr: 0.001875  Loss: -0.3048  Acc@1: 68.7500 (65.1061)  Acc@5: 87.5000 (91.5574)  time: 0.3491  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [ 810/4579]  eta: 0:22:02  Lr: 0.001875  Loss: -0.5550  Acc@1: 68.7500 (65.1356)  Acc@5: 87.5000 (91.5074)  time: 0.3491  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [ 820/4579]  eta: 0:21:58  Lr: 0.001875  Loss: -0.5394  Acc@1: 68.7500 (65.2025)  Acc@5: 93.7500 (91.5195)  time: 0.3474  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 830/4579]  eta: 0:21:55  Lr: 0.001875  Loss: -0.3080  Acc@1: 62.5000 (65.1850)  Acc@5: 93.7500 (91.5313)  time: 0.3482  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [ 840/4579]  eta: 0:21:51  Lr: 0.001875  Loss: -0.9913  Acc@1: 62.5000 (65.2497)  Acc@5: 93.7500 (91.5502)  time: 0.3506  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [ 850/4579]  eta: 0:21:48  Lr: 0.001875  Loss: -0.1865  Acc@1: 62.5000 (65.2174)  Acc@5: 93.7500 (91.5394)  time: 0.3520  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [ 860/4579]  eta: 0:21:44  Lr: 0.001875  Loss: -0.3106  Acc@1: 62.5000 (65.2947)  Acc@5: 93.7500 (91.5723)  time: 0.3509  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [ 870/4579]  eta: 0:21:41  Lr: 0.001875  Loss: -0.2617  Acc@1: 68.7500 (65.3703)  Acc@5: 93.7500 (91.6188)  time: 0.3505  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [ 880/4579]  eta: 0:21:37  Lr: 0.001875  Loss: -0.3883  Acc@1: 62.5000 (65.3164)  Acc@5: 93.7500 (91.5792)  time: 0.3520  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [ 890/4579]  eta: 0:21:34  Lr: 0.001875  Loss: 0.3254  Acc@1: 56.2500 (65.2918)  Acc@5: 93.7500 (91.5825)  time: 0.3502  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [ 900/4579]  eta: 0:21:30  Lr: 0.001875  Loss: 0.0348  Acc@1: 68.7500 (65.3233)  Acc@5: 93.7500 (91.5996)  time: 0.3511  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [ 910/4579]  eta: 0:21:27  Lr: 0.001875  Loss: -0.6970  Acc@1: 68.7500 (65.3883)  Acc@5: 93.7500 (91.6164)  time: 0.3524  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [ 920/4579]  eta: 0:21:23  Lr: 0.001875  Loss: -0.1868  Acc@1: 68.7500 (65.4180)  Acc@5: 93.7500 (91.6056)  time: 0.3507  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [ 930/4579]  eta: 0:21:20  Lr: 0.001875  Loss: -0.4307  Acc@1: 68.7500 (65.3800)  Acc@5: 93.7500 (91.6219)  time: 0.3517  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [ 940/4579]  eta: 0:21:16  Lr: 0.001875  Loss: -0.3622  Acc@1: 68.7500 (65.4224)  Acc@5: 93.7500 (91.6312)  time: 0.3515  data: 0.0010  max mem: 2500
Train: Epoch[4/5]  [ 950/4579]  eta: 0:21:13  Lr: 0.001875  Loss: 0.1729  Acc@1: 62.5000 (65.3588)  Acc@5: 93.7500 (91.6404)  time: 0.3501  data: 0.0016  max mem: 2500
Train: Epoch[4/5]  [ 960/4579]  eta: 0:21:09  Lr: 0.001875  Loss: -0.2686  Acc@1: 62.5000 (65.3811)  Acc@5: 93.7500 (91.6363)  time: 0.3497  data: 0.0015  max mem: 2500
Train: Epoch[4/5]  [ 970/4579]  eta: 0:21:06  Lr: 0.001875  Loss: -0.2712  Acc@1: 62.5000 (65.3772)  Acc@5: 93.7500 (91.6323)  time: 0.3496  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [ 980/4579]  eta: 0:21:02  Lr: 0.001875  Loss: -0.4637  Acc@1: 62.5000 (65.3606)  Acc@5: 93.7500 (91.6221)  time: 0.3489  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [ 990/4579]  eta: 0:20:59  Lr: 0.001875  Loss: -0.5609  Acc@1: 62.5000 (65.3948)  Acc@5: 87.5000 (91.6057)  time: 0.3498  data: 0.0012  max mem: 2500
Train: Epoch[4/5]  [1000/4579]  eta: 0:20:55  Lr: 0.001875  Loss: 0.3122  Acc@1: 62.5000 (65.3284)  Acc@5: 87.5000 (91.5772)  time: 0.3501  data: 0.0012  max mem: 2500
Train: Epoch[4/5]  [1010/4579]  eta: 0:20:52  Lr: 0.001875  Loss: 0.1247  Acc@1: 56.2500 (65.2634)  Acc@5: 87.5000 (91.5554)  time: 0.3496  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [1020/4579]  eta: 0:20:48  Lr: 0.001875  Loss: -0.3230  Acc@1: 62.5000 (65.2853)  Acc@5: 87.5000 (91.5646)  time: 0.3509  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [1030/4579]  eta: 0:20:45  Lr: 0.001875  Loss: -0.2335  Acc@1: 68.7500 (65.3310)  Acc@5: 93.7500 (91.5858)  time: 0.3499  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [1040/4579]  eta: 0:20:41  Lr: 0.001875  Loss: -0.1048  Acc@1: 62.5000 (65.2918)  Acc@5: 87.5000 (91.5466)  time: 0.3487  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [1050/4579]  eta: 0:20:37  Lr: 0.001875  Loss: 0.3270  Acc@1: 56.2500 (65.2355)  Acc@5: 87.5000 (91.5140)  time: 0.3505  data: 0.0013  max mem: 2500
Train: Epoch[4/5]  [1060/4579]  eta: 0:20:34  Lr: 0.001875  Loss: -0.3470  Acc@1: 62.5000 (65.2686)  Acc@5: 93.7500 (91.5410)  time: 0.3500  data: 0.0012  max mem: 2500
Train: Epoch[4/5]  [1070/4579]  eta: 0:20:30  Lr: 0.001875  Loss: -0.3694  Acc@1: 68.7500 (65.2486)  Acc@5: 93.7500 (91.5675)  time: 0.3491  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [1080/4579]  eta: 0:20:27  Lr: 0.001875  Loss: -0.4209  Acc@1: 62.5000 (65.2405)  Acc@5: 93.7500 (91.5703)  time: 0.3538  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [1090/4579]  eta: 0:20:24  Lr: 0.001875  Loss: -0.3765  Acc@1: 62.5000 (65.1810)  Acc@5: 87.5000 (91.5215)  time: 0.3539  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [1100/4579]  eta: 0:20:20  Lr: 0.001875  Loss: -0.6256  Acc@1: 62.5000 (65.1907)  Acc@5: 87.5000 (91.5588)  time: 0.3510  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [1110/4579]  eta: 0:20:17  Lr: 0.001875  Loss: -0.3185  Acc@1: 68.7500 (65.2115)  Acc@5: 93.7500 (91.5223)  time: 0.3509  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [1120/4579]  eta: 0:20:13  Lr: 0.001875  Loss: -0.1171  Acc@1: 68.7500 (65.2319)  Acc@5: 93.7500 (91.5589)  time: 0.3502  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [1130/4579]  eta: 0:20:10  Lr: 0.001875  Loss: -0.2189  Acc@1: 62.5000 (65.1967)  Acc@5: 93.7500 (91.5617)  time: 0.3513  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [1140/4579]  eta: 0:20:06  Lr: 0.001875  Loss: -0.2077  Acc@1: 62.5000 (65.1731)  Acc@5: 87.5000 (91.5370)  time: 0.3538  data: 0.0009  max mem: 2500
Train: Epoch[4/5]  [1150/4579]  eta: 0:20:03  Lr: 0.001875  Loss: -0.5012  Acc@1: 62.5000 (65.1770)  Acc@5: 93.7500 (91.5291)  time: 0.3518  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [1160/4579]  eta: 0:19:59  Lr: 0.001875  Loss: 0.4562  Acc@1: 56.2500 (65.1378)  Acc@5: 93.7500 (91.5159)  time: 0.3487  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1170/4579]  eta: 0:19:56  Lr: 0.001875  Loss: -0.3520  Acc@1: 56.2500 (65.0779)  Acc@5: 87.5000 (91.4923)  time: 0.3521  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [1180/4579]  eta: 0:19:52  Lr: 0.001875  Loss: 0.0838  Acc@1: 56.2500 (65.0826)  Acc@5: 87.5000 (91.4850)  time: 0.3545  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [1190/4579]  eta: 0:19:49  Lr: 0.001875  Loss: 0.0717  Acc@1: 68.7500 (65.1186)  Acc@5: 93.7500 (91.5145)  time: 0.3537  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [1200/4579]  eta: 0:19:45  Lr: 0.001875  Loss: -0.3041  Acc@1: 68.7500 (65.1592)  Acc@5: 93.7500 (91.5383)  time: 0.3511  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [1210/4579]  eta: 0:19:42  Lr: 0.001875  Loss: -0.3863  Acc@1: 68.7500 (65.1579)  Acc@5: 93.7500 (91.5514)  time: 0.3508  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [1220/4579]  eta: 0:19:38  Lr: 0.001875  Loss: -0.3641  Acc@1: 62.5000 (65.1515)  Acc@5: 93.7500 (91.5285)  time: 0.3518  data: 0.0010  max mem: 2500
Train: Epoch[4/5]  [1230/4579]  eta: 0:19:35  Lr: 0.001875  Loss: -0.8782  Acc@1: 62.5000 (65.1757)  Acc@5: 93.7500 (91.5719)  time: 0.3523  data: 0.0017  max mem: 2500
Train: Epoch[4/5]  [1240/4579]  eta: 0:19:31  Lr: 0.001875  Loss: -0.0089  Acc@1: 62.5000 (65.1591)  Acc@5: 93.7500 (91.5945)  time: 0.3515  data: 0.0016  max mem: 2500
Train: Epoch[4/5]  [1250/4579]  eta: 0:19:28  Lr: 0.001875  Loss: -0.0008  Acc@1: 62.5000 (65.1329)  Acc@5: 93.7500 (91.6267)  time: 0.3495  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [1260/4579]  eta: 0:19:24  Lr: 0.001875  Loss: 0.0556  Acc@1: 62.5000 (65.1467)  Acc@5: 93.7500 (91.6435)  time: 0.3501  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [1270/4579]  eta: 0:19:21  Lr: 0.001875  Loss: -0.1668  Acc@1: 68.7500 (65.1800)  Acc@5: 93.7500 (91.6454)  time: 0.3518  data: 0.0009  max mem: 2500
Train: Epoch[4/5]  [1280/4579]  eta: 0:19:17  Lr: 0.001875  Loss: 0.5591  Acc@1: 68.7500 (65.1883)  Acc@5: 93.7500 (91.6374)  time: 0.3520  data: 0.0010  max mem: 2500
Train: Epoch[4/5]  [1290/4579]  eta: 0:19:14  Lr: 0.001875  Loss: -0.2172  Acc@1: 62.5000 (65.1772)  Acc@5: 87.5000 (91.6150)  time: 0.3503  data: 0.0011  max mem: 2500
Train: Epoch[4/5]  [1300/4579]  eta: 0:19:10  Lr: 0.001875  Loss: -0.2724  Acc@1: 68.7500 (65.2095)  Acc@5: 87.5000 (91.6122)  time: 0.3503  data: 0.0011  max mem: 2500
Train: Epoch[4/5]  [1310/4579]  eta: 0:19:07  Lr: 0.001875  Loss: -0.4320  Acc@1: 68.7500 (65.2269)  Acc@5: 93.7500 (91.6142)  time: 0.3506  data: 0.0009  max mem: 2500
Train: Epoch[4/5]  [1320/4579]  eta: 0:19:03  Lr: 0.001875  Loss: -0.5244  Acc@1: 68.7500 (65.2583)  Acc@5: 93.7500 (91.6162)  time: 0.3502  data: 0.0009  max mem: 2500
Train: Epoch[4/5]  [1330/4579]  eta: 0:19:00  Lr: 0.001875  Loss: 0.1300  Acc@1: 68.7500 (65.2423)  Acc@5: 93.7500 (91.6228)  time: 0.3507  data: 0.0021  max mem: 2500
Train: Epoch[4/5]  [1340/4579]  eta: 0:18:56  Lr: 0.001875  Loss: 0.3793  Acc@1: 56.2500 (65.2079)  Acc@5: 93.7500 (91.6247)  time: 0.3508  data: 0.0022  max mem: 2500
Train: Epoch[4/5]  [1350/4579]  eta: 0:18:53  Lr: 0.001875  Loss: -0.1399  Acc@1: 62.5000 (65.2295)  Acc@5: 93.7500 (91.6266)  time: 0.3502  data: 0.0009  max mem: 2500
Train: Epoch[4/5]  [1360/4579]  eta: 0:18:49  Lr: 0.001875  Loss: -0.1282  Acc@1: 62.5000 (65.2048)  Acc@5: 93.7500 (91.6238)  time: 0.3515  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [1370/4579]  eta: 0:18:46  Lr: 0.001875  Loss: 0.0444  Acc@1: 62.5000 (65.2079)  Acc@5: 87.5000 (91.6028)  time: 0.3537  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [1380/4579]  eta: 0:18:42  Lr: 0.001875  Loss: -0.5704  Acc@1: 62.5000 (65.2018)  Acc@5: 93.7500 (91.6048)  time: 0.3530  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [1390/4579]  eta: 0:18:39  Lr: 0.001875  Loss: -0.4389  Acc@1: 62.5000 (65.1734)  Acc@5: 93.7500 (91.6113)  time: 0.3535  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [1400/4579]  eta: 0:18:35  Lr: 0.001875  Loss: 0.5051  Acc@1: 62.5000 (65.1588)  Acc@5: 93.7500 (91.6087)  time: 0.3534  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [1410/4579]  eta: 0:18:32  Lr: 0.001875  Loss: -0.0911  Acc@1: 62.5000 (65.1400)  Acc@5: 93.7500 (91.6283)  time: 0.3525  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [1420/4579]  eta: 0:18:28  Lr: 0.001875  Loss: -0.2538  Acc@1: 56.2500 (65.1082)  Acc@5: 93.7500 (91.6080)  time: 0.3530  data: 0.0009  max mem: 2500
Train: Epoch[4/5]  [1430/4579]  eta: 0:18:25  Lr: 0.001875  Loss: -0.6106  Acc@1: 68.7500 (65.1555)  Acc@5: 93.7500 (91.6361)  time: 0.3520  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [1440/4579]  eta: 0:18:21  Lr: 0.001875  Loss: -0.4100  Acc@1: 68.7500 (65.1978)  Acc@5: 93.7500 (91.6378)  time: 0.3545  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [1450/4579]  eta: 0:18:18  Lr: 0.001875  Loss: 0.3322  Acc@1: 68.7500 (65.1620)  Acc@5: 87.5000 (91.6049)  time: 0.3547  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1460/4579]  eta: 0:18:15  Lr: 0.001875  Loss: -0.3641  Acc@1: 68.7500 (65.1908)  Acc@5: 93.7500 (91.6282)  time: 0.3545  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [1470/4579]  eta: 0:18:11  Lr: 0.001875  Loss: 0.0202  Acc@1: 68.7500 (65.1428)  Acc@5: 93.7500 (91.6171)  time: 0.3538  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [1480/4579]  eta: 0:18:08  Lr: 0.001875  Loss: -0.4999  Acc@1: 56.2500 (65.0912)  Acc@5: 93.7500 (91.6188)  time: 0.3524  data: 0.0016  max mem: 2500
Train: Epoch[4/5]  [1490/4579]  eta: 0:18:04  Lr: 0.001875  Loss: -0.8279  Acc@1: 62.5000 (65.0864)  Acc@5: 93.7500 (91.6038)  time: 0.3514  data: 0.0015  max mem: 2500
Train: Epoch[4/5]  [1500/4579]  eta: 0:18:01  Lr: 0.001875  Loss: -0.3201  Acc@1: 68.7500 (65.0774)  Acc@5: 93.7500 (91.6056)  time: 0.3499  data: 0.0009  max mem: 2500
Train: Epoch[4/5]  [1510/4579]  eta: 0:17:57  Lr: 0.001875  Loss: 0.0178  Acc@1: 62.5000 (65.0687)  Acc@5: 93.7500 (91.5950)  time: 0.3502  data: 0.0009  max mem: 2500
Train: Epoch[4/5]  [1520/4579]  eta: 0:17:53  Lr: 0.001875  Loss: 0.0122  Acc@1: 62.5000 (65.0764)  Acc@5: 93.7500 (91.5927)  time: 0.3500  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [1530/4579]  eta: 0:17:50  Lr: 0.001875  Loss: -0.2571  Acc@1: 62.5000 (65.0351)  Acc@5: 93.7500 (91.5864)  time: 0.3504  data: 0.0015  max mem: 2500
Train: Epoch[4/5]  [1540/4579]  eta: 0:17:46  Lr: 0.001875  Loss: -0.6376  Acc@1: 62.5000 (65.0714)  Acc@5: 93.7500 (91.6126)  time: 0.3509  data: 0.0017  max mem: 2500
Train: Epoch[4/5]  [1550/4579]  eta: 0:17:43  Lr: 0.001875  Loss: 0.3027  Acc@1: 68.7500 (65.0548)  Acc@5: 93.7500 (91.6143)  time: 0.3541  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [1560/4579]  eta: 0:17:40  Lr: 0.001875  Loss: 0.4899  Acc@1: 62.5000 (65.0144)  Acc@5: 87.5000 (91.5959)  time: 0.3537  data: 0.0010  max mem: 2500
Train: Epoch[4/5]  [1570/4579]  eta: 0:17:36  Lr: 0.001875  Loss: -0.3329  Acc@1: 62.5000 (64.9984)  Acc@5: 93.7500 (91.6057)  time: 0.3494  data: 0.0013  max mem: 2500
Train: Epoch[4/5]  [1580/4579]  eta: 0:17:32  Lr: 0.001875  Loss: -0.9816  Acc@1: 68.7500 (65.0577)  Acc@5: 93.7500 (91.6350)  time: 0.3507  data: 0.0018  max mem: 2500
Train: Epoch[4/5]  [1590/4579]  eta: 0:17:29  Lr: 0.001875  Loss: 0.0155  Acc@1: 75.0000 (65.0574)  Acc@5: 93.7500 (91.6130)  time: 0.3515  data: 0.0017  max mem: 2500
Train: Epoch[4/5]  [1600/4579]  eta: 0:17:25  Lr: 0.001875  Loss: -0.2039  Acc@1: 62.5000 (65.0492)  Acc@5: 87.5000 (91.6029)  time: 0.3504  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [1610/4579]  eta: 0:17:22  Lr: 0.001875  Loss: -0.1745  Acc@1: 68.7500 (65.0760)  Acc@5: 93.7500 (91.6201)  time: 0.3498  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [1620/4579]  eta: 0:17:18  Lr: 0.001875  Loss: -0.6805  Acc@1: 68.7500 (65.0756)  Acc@5: 93.7500 (91.6063)  time: 0.3509  data: 0.0015  max mem: 2500
Train: Epoch[4/5]  [1630/4579]  eta: 0:17:15  Lr: 0.001875  Loss: 0.3205  Acc@1: 68.7500 (65.0904)  Acc@5: 93.7500 (91.6117)  time: 0.3522  data: 0.0015  max mem: 2500
Train: Epoch[4/5]  [1640/4579]  eta: 0:17:11  Lr: 0.001875  Loss: -0.5259  Acc@1: 68.7500 (65.0556)  Acc@5: 93.7500 (91.5829)  time: 0.3520  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [1650/4579]  eta: 0:17:08  Lr: 0.001875  Loss: -0.4346  Acc@1: 56.2500 (65.0250)  Acc@5: 93.7500 (91.5809)  time: 0.3519  data: 0.0009  max mem: 2500
Train: Epoch[4/5]  [1660/4579]  eta: 0:17:04  Lr: 0.001875  Loss: -0.0064  Acc@1: 62.5000 (65.0399)  Acc@5: 87.5000 (91.5713)  time: 0.3525  data: 0.0009  max mem: 2500
Train: Epoch[4/5]  [1670/4579]  eta: 0:17:01  Lr: 0.001875  Loss: 0.3958  Acc@1: 68.7500 (65.0546)  Acc@5: 87.5000 (91.5582)  time: 0.3532  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [1680/4579]  eta: 0:16:57  Lr: 0.001875  Loss: 0.2825  Acc@1: 62.5000 (65.0208)  Acc@5: 87.5000 (91.5564)  time: 0.3510  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [1690/4579]  eta: 0:16:54  Lr: 0.001875  Loss: -0.9424  Acc@1: 62.5000 (65.0207)  Acc@5: 87.5000 (91.5509)  time: 0.3520  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [1700/4579]  eta: 0:16:51  Lr: 0.001875  Loss: -0.4497  Acc@1: 68.7500 (65.0573)  Acc@5: 93.7500 (91.5638)  time: 0.3544  data: 0.0010  max mem: 2500
Train: Epoch[4/5]  [1710/4579]  eta: 0:16:47  Lr: 0.001875  Loss: -0.2665  Acc@1: 68.7500 (65.0972)  Acc@5: 93.7500 (91.5766)  time: 0.3529  data: 0.0013  max mem: 2500
Train: Epoch[4/5]  [1720/4579]  eta: 0:16:43  Lr: 0.001875  Loss: 0.0945  Acc@1: 68.7500 (65.1365)  Acc@5: 93.7500 (91.5892)  time: 0.3510  data: 0.0010  max mem: 2500
Train: Epoch[4/5]  [1730/4579]  eta: 0:16:40  Lr: 0.001875  Loss: -0.3417  Acc@1: 68.7500 (65.1791)  Acc@5: 93.7500 (91.6089)  time: 0.3526  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [1740/4579]  eta: 0:16:36  Lr: 0.001875  Loss: -0.1148  Acc@1: 68.7500 (65.1924)  Acc@5: 93.7500 (91.6068)  time: 0.3518  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [1750/4579]  eta: 0:16:33  Lr: 0.001875  Loss: -0.7350  Acc@1: 68.7500 (65.1842)  Acc@5: 87.5000 (91.6048)  time: 0.3501  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [1760/4579]  eta: 0:16:29  Lr: 0.001875  Loss: 0.0820  Acc@1: 62.5000 (65.1938)  Acc@5: 87.5000 (91.5886)  time: 0.3516  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [1770/4579]  eta: 0:16:26  Lr: 0.001875  Loss: -0.0193  Acc@1: 68.7500 (65.1892)  Acc@5: 87.5000 (91.5902)  time: 0.3513  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [1780/4579]  eta: 0:16:22  Lr: 0.001875  Loss: -0.1285  Acc@1: 68.7500 (65.2302)  Acc@5: 93.7500 (91.5883)  time: 0.3518  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [1790/4579]  eta: 0:16:19  Lr: 0.001875  Loss: 0.1324  Acc@1: 62.5000 (65.2115)  Acc@5: 93.7500 (91.5899)  time: 0.3506  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [1800/4579]  eta: 0:16:15  Lr: 0.001875  Loss: 0.0451  Acc@1: 62.5000 (65.1929)  Acc@5: 87.5000 (91.5672)  time: 0.3487  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [1810/4579]  eta: 0:16:12  Lr: 0.001875  Loss: 0.2419  Acc@1: 62.5000 (65.1815)  Acc@5: 87.5000 (91.5551)  time: 0.3489  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [1820/4579]  eta: 0:16:08  Lr: 0.001875  Loss: 0.6437  Acc@1: 62.5000 (65.1634)  Acc@5: 93.7500 (91.5431)  time: 0.3493  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [1830/4579]  eta: 0:16:05  Lr: 0.001875  Loss: 0.1442  Acc@1: 56.2500 (65.1557)  Acc@5: 87.5000 (91.5347)  time: 0.3501  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [1840/4579]  eta: 0:16:01  Lr: 0.001875  Loss: 0.0382  Acc@1: 62.5000 (65.1344)  Acc@5: 93.7500 (91.5399)  time: 0.3508  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [1850/4579]  eta: 0:15:58  Lr: 0.001875  Loss: -0.1218  Acc@1: 62.5000 (65.1371)  Acc@5: 93.7500 (91.5620)  time: 0.3491  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [1860/4579]  eta: 0:15:54  Lr: 0.001875  Loss: -0.1228  Acc@1: 68.7500 (65.1531)  Acc@5: 93.7500 (91.5738)  time: 0.3474  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [1870/4579]  eta: 0:15:51  Lr: 0.001875  Loss: -0.3836  Acc@1: 68.7500 (65.1590)  Acc@5: 93.7500 (91.5754)  time: 0.3483  data: 0.0009  max mem: 2500
Train: Epoch[4/5]  [1880/4579]  eta: 0:15:47  Lr: 0.001875  Loss: -0.7217  Acc@1: 62.5000 (65.1415)  Acc@5: 93.7500 (91.5936)  time: 0.3499  data: 0.0011  max mem: 2500
Train: Epoch[4/5]  [1890/4579]  eta: 0:15:44  Lr: 0.001875  Loss: 0.0138  Acc@1: 56.2500 (65.1210)  Acc@5: 93.7500 (91.5851)  time: 0.3505  data: 0.0011  max mem: 2500
Train: Epoch[4/5]  [1900/4579]  eta: 0:15:40  Lr: 0.001875  Loss: -0.0548  Acc@1: 62.5000 (65.1236)  Acc@5: 93.7500 (91.5867)  time: 0.3490  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [1910/4579]  eta: 0:15:37  Lr: 0.001875  Loss: -0.4254  Acc@1: 68.7500 (65.1197)  Acc@5: 93.7500 (91.5849)  time: 0.3508  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [1920/4579]  eta: 0:15:33  Lr: 0.001875  Loss: -0.3493  Acc@1: 62.5000 (65.1191)  Acc@5: 93.7500 (91.5897)  time: 0.3516  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [1930/4579]  eta: 0:15:29  Lr: 0.001875  Loss: -0.5120  Acc@1: 68.7500 (65.1152)  Acc@5: 93.7500 (91.5911)  time: 0.3489  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [1940/4579]  eta: 0:15:26  Lr: 0.001875  Loss: 0.0423  Acc@1: 62.5000 (65.0953)  Acc@5: 93.7500 (91.5894)  time: 0.3478  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [1950/4579]  eta: 0:15:22  Lr: 0.001875  Loss: 0.0879  Acc@1: 62.5000 (65.0852)  Acc@5: 93.7500 (91.5973)  time: 0.3498  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [1960/4579]  eta: 0:15:19  Lr: 0.001875  Loss: -0.1860  Acc@1: 62.5000 (65.0880)  Acc@5: 93.7500 (91.5955)  time: 0.3516  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [1970/4579]  eta: 0:15:15  Lr: 0.001875  Loss: 0.1354  Acc@1: 62.5000 (65.0685)  Acc@5: 87.5000 (91.5937)  time: 0.3504  data: 0.0021  max mem: 2500
Train: Epoch[4/5]  [1980/4579]  eta: 0:15:12  Lr: 0.001875  Loss: -0.4737  Acc@1: 56.2500 (65.0366)  Acc@5: 93.7500 (91.6046)  time: 0.3487  data: 0.0018  max mem: 2500
Train: Epoch[4/5]  [1990/4579]  eta: 0:15:08  Lr: 0.001875  Loss: -0.4698  Acc@1: 62.5000 (65.0364)  Acc@5: 93.7500 (91.5997)  time: 0.3491  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [2000/4579]  eta: 0:15:05  Lr: 0.001875  Loss: 0.1348  Acc@1: 68.7500 (65.0394)  Acc@5: 93.7500 (91.6042)  time: 0.3498  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [2010/4579]  eta: 0:15:01  Lr: 0.001875  Loss: -0.4586  Acc@1: 68.7500 (65.0205)  Acc@5: 93.7500 (91.6024)  time: 0.3493  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [2020/4579]  eta: 0:14:58  Lr: 0.001875  Loss: -0.3735  Acc@1: 62.5000 (65.0019)  Acc@5: 93.7500 (91.6007)  time: 0.3504  data: 0.0010  max mem: 2500
Train: Epoch[4/5]  [2030/4579]  eta: 0:14:54  Lr: 0.001875  Loss: -0.6349  Acc@1: 62.5000 (65.0111)  Acc@5: 93.7500 (91.5928)  time: 0.3499  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [2040/4579]  eta: 0:14:51  Lr: 0.001875  Loss: -0.6034  Acc@1: 68.7500 (65.0447)  Acc@5: 93.7500 (91.5942)  time: 0.3490  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [2050/4579]  eta: 0:14:47  Lr: 0.001875  Loss: 0.0206  Acc@1: 75.0000 (65.0689)  Acc@5: 93.7500 (91.5986)  time: 0.3506  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [2060/4579]  eta: 0:14:44  Lr: 0.001875  Loss: -0.4799  Acc@1: 68.7500 (65.0746)  Acc@5: 93.7500 (91.6030)  time: 0.3522  data: 0.0013  max mem: 2500
Train: Epoch[4/5]  [2070/4579]  eta: 0:14:40  Lr: 0.001875  Loss: -0.0469  Acc@1: 68.7500 (65.0803)  Acc@5: 93.7500 (91.6134)  time: 0.3512  data: 0.0012  max mem: 2500
Train: Epoch[4/5]  [2080/4579]  eta: 0:14:37  Lr: 0.001875  Loss: 0.0511  Acc@1: 68.7500 (65.0739)  Acc@5: 93.7500 (91.6146)  time: 0.3519  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2090/4579]  eta: 0:14:33  Lr: 0.001875  Loss: -0.3068  Acc@1: 62.5000 (65.0526)  Acc@5: 93.7500 (91.6218)  time: 0.3523  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2100/4579]  eta: 0:14:30  Lr: 0.001875  Loss: 0.6876  Acc@1: 62.5000 (65.0434)  Acc@5: 93.7500 (91.6379)  time: 0.3508  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2110/4579]  eta: 0:14:26  Lr: 0.001875  Loss: -0.4364  Acc@1: 62.5000 (65.0195)  Acc@5: 93.7500 (91.6302)  time: 0.3498  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2120/4579]  eta: 0:14:23  Lr: 0.001875  Loss: -0.3519  Acc@1: 62.5000 (65.0607)  Acc@5: 93.7500 (91.6313)  time: 0.3482  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2130/4579]  eta: 0:14:19  Lr: 0.001875  Loss: -0.1576  Acc@1: 75.0000 (65.0809)  Acc@5: 93.7500 (91.6324)  time: 0.3486  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2140/4579]  eta: 0:14:15  Lr: 0.001875  Loss: -0.6377  Acc@1: 68.7500 (65.0981)  Acc@5: 93.7500 (91.6365)  time: 0.3489  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [2150/4579]  eta: 0:14:12  Lr: 0.001875  Loss: -0.1438  Acc@1: 68.7500 (65.1209)  Acc@5: 87.5000 (91.6289)  time: 0.3501  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [2160/4579]  eta: 0:14:08  Lr: 0.001875  Loss: -0.0582  Acc@1: 68.7500 (65.1348)  Acc@5: 93.7500 (91.6474)  time: 0.3512  data: 0.0014  max mem: 2500
Train: Epoch[4/5]  [2170/4579]  eta: 0:14:05  Lr: 0.001875  Loss: 0.0099  Acc@1: 62.5000 (65.1054)  Acc@5: 93.7500 (91.6283)  time: 0.3515  data: 0.0014  max mem: 2500
Train: Epoch[4/5]  [2180/4579]  eta: 0:14:01  Lr: 0.001875  Loss: 0.0423  Acc@1: 62.5000 (65.1049)  Acc@5: 87.5000 (91.6180)  time: 0.3504  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [2190/4579]  eta: 0:13:58  Lr: 0.001875  Loss: -0.0038  Acc@1: 62.5000 (65.1158)  Acc@5: 87.5000 (91.6277)  time: 0.3485  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2200/4579]  eta: 0:13:54  Lr: 0.001875  Loss: -0.5946  Acc@1: 62.5000 (65.1068)  Acc@5: 93.7500 (91.6203)  time: 0.3488  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2210/4579]  eta: 0:13:51  Lr: 0.001875  Loss: -0.1057  Acc@1: 68.7500 (65.1430)  Acc@5: 93.7500 (91.6214)  time: 0.3511  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2220/4579]  eta: 0:13:47  Lr: 0.001875  Loss: -0.6715  Acc@1: 75.0000 (65.1874)  Acc@5: 93.7500 (91.6282)  time: 0.3545  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [2230/4579]  eta: 0:13:44  Lr: 0.001875  Loss: -0.4511  Acc@1: 68.7500 (65.1894)  Acc@5: 93.7500 (91.6293)  time: 0.3534  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [2240/4579]  eta: 0:13:40  Lr: 0.001875  Loss: -0.5598  Acc@1: 62.5000 (65.1718)  Acc@5: 93.7500 (91.6276)  time: 0.3509  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2250/4579]  eta: 0:13:37  Lr: 0.001875  Loss: -0.4478  Acc@1: 62.5000 (65.1572)  Acc@5: 93.7500 (91.6259)  time: 0.3504  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [2260/4579]  eta: 0:13:33  Lr: 0.001875  Loss: -0.0714  Acc@1: 62.5000 (65.1565)  Acc@5: 87.5000 (91.6132)  time: 0.3520  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2270/4579]  eta: 0:13:30  Lr: 0.001875  Loss: -0.3936  Acc@1: 62.5000 (65.1723)  Acc@5: 87.5000 (91.6226)  time: 0.3543  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2280/4579]  eta: 0:13:26  Lr: 0.001875  Loss: -0.2815  Acc@1: 68.7500 (65.1907)  Acc@5: 93.7500 (91.6402)  time: 0.3545  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2290/4579]  eta: 0:13:23  Lr: 0.001875  Loss: -0.3485  Acc@1: 68.7500 (65.2035)  Acc@5: 93.7500 (91.6521)  time: 0.3524  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [2300/4579]  eta: 0:13:19  Lr: 0.001875  Loss: -0.1218  Acc@1: 68.7500 (65.1972)  Acc@5: 93.7500 (91.6667)  time: 0.3513  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [2310/4579]  eta: 0:13:16  Lr: 0.001875  Loss: -0.4582  Acc@1: 62.5000 (65.1909)  Acc@5: 93.7500 (91.6595)  time: 0.3513  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2320/4579]  eta: 0:13:12  Lr: 0.001875  Loss: -0.4492  Acc@1: 68.7500 (65.2090)  Acc@5: 93.7500 (91.6604)  time: 0.3515  data: 0.0009  max mem: 2500
Train: Epoch[4/5]  [2330/4579]  eta: 0:13:09  Lr: 0.001875  Loss: -0.6445  Acc@1: 62.5000 (65.2161)  Acc@5: 93.7500 (91.6533)  time: 0.3507  data: 0.0009  max mem: 2500
Train: Epoch[4/5]  [2340/4579]  eta: 0:13:05  Lr: 0.001875  Loss: -0.5731  Acc@1: 62.5000 (65.2285)  Acc@5: 93.7500 (91.6515)  time: 0.3498  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [2350/4579]  eta: 0:13:02  Lr: 0.001875  Loss: 0.4367  Acc@1: 68.7500 (65.2409)  Acc@5: 93.7500 (91.6605)  time: 0.3518  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [2360/4579]  eta: 0:12:58  Lr: 0.001875  Loss: 0.1960  Acc@1: 62.5000 (65.2425)  Acc@5: 93.7500 (91.6720)  time: 0.3504  data: 0.0009  max mem: 2500
Train: Epoch[4/5]  [2370/4579]  eta: 0:12:55  Lr: 0.001875  Loss: -0.5540  Acc@1: 62.5000 (65.2415)  Acc@5: 93.7500 (91.6675)  time: 0.3481  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [2380/4579]  eta: 0:12:51  Lr: 0.001875  Loss: -0.5086  Acc@1: 62.5000 (65.2588)  Acc@5: 93.7500 (91.6737)  time: 0.3492  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [2390/4579]  eta: 0:12:48  Lr: 0.001875  Loss: -0.1559  Acc@1: 68.7500 (65.2630)  Acc@5: 93.7500 (91.6850)  time: 0.3495  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [2400/4579]  eta: 0:12:44  Lr: 0.001875  Loss: -0.6911  Acc@1: 75.0000 (65.2905)  Acc@5: 93.7500 (91.6884)  time: 0.3506  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2410/4579]  eta: 0:12:41  Lr: 0.001875  Loss: 0.3765  Acc@1: 62.5000 (65.2867)  Acc@5: 87.5000 (91.6684)  time: 0.3511  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2420/4579]  eta: 0:12:37  Lr: 0.001875  Loss: -0.0718  Acc@1: 68.7500 (65.3165)  Acc@5: 87.5000 (91.6744)  time: 0.3491  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2430/4579]  eta: 0:12:34  Lr: 0.001875  Loss: -0.5380  Acc@1: 68.7500 (65.3281)  Acc@5: 93.7500 (91.6778)  time: 0.3496  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2440/4579]  eta: 0:12:30  Lr: 0.001875  Loss: -0.2207  Acc@1: 62.5000 (65.2960)  Acc@5: 93.7500 (91.6735)  time: 0.3493  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2450/4579]  eta: 0:12:27  Lr: 0.001875  Loss: -0.4409  Acc@1: 62.5000 (65.2999)  Acc@5: 87.5000 (91.6743)  time: 0.3484  data: 0.0009  max mem: 2500
Train: Epoch[4/5]  [2460/4579]  eta: 0:12:23  Lr: 0.001875  Loss: -0.1442  Acc@1: 62.5000 (65.2885)  Acc@5: 87.5000 (91.6777)  time: 0.3493  data: 0.0009  max mem: 2500
Train: Epoch[4/5]  [2470/4579]  eta: 0:12:20  Lr: 0.001875  Loss: -0.7748  Acc@1: 62.5000 (65.3076)  Acc@5: 93.7500 (91.6861)  time: 0.3489  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2480/4579]  eta: 0:12:16  Lr: 0.001875  Loss: -0.8025  Acc@1: 62.5000 (65.2937)  Acc@5: 93.7500 (91.6843)  time: 0.3486  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2490/4579]  eta: 0:12:13  Lr: 0.001875  Loss: -0.5927  Acc@1: 62.5000 (65.3227)  Acc@5: 93.7500 (91.6876)  time: 0.3521  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [2500/4579]  eta: 0:12:09  Lr: 0.001875  Loss: -0.4617  Acc@1: 68.7500 (65.3264)  Acc@5: 93.7500 (91.6883)  time: 0.3526  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [2510/4579]  eta: 0:12:06  Lr: 0.001875  Loss: -0.1932  Acc@1: 62.5000 (65.3126)  Acc@5: 93.7500 (91.6791)  time: 0.3511  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2520/4579]  eta: 0:12:02  Lr: 0.001875  Loss: 0.0779  Acc@1: 62.5000 (65.3114)  Acc@5: 87.5000 (91.6675)  time: 0.3508  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2530/4579]  eta: 0:11:59  Lr: 0.001875  Loss: 0.3908  Acc@1: 62.5000 (65.2904)  Acc@5: 93.7500 (91.6757)  time: 0.3508  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [2540/4579]  eta: 0:11:55  Lr: 0.001875  Loss: -0.0768  Acc@1: 62.5000 (65.2893)  Acc@5: 93.7500 (91.6790)  time: 0.3521  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2550/4579]  eta: 0:11:52  Lr: 0.001875  Loss: -0.2827  Acc@1: 62.5000 (65.3151)  Acc@5: 93.7500 (91.6797)  time: 0.3514  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2560/4579]  eta: 0:11:48  Lr: 0.001875  Loss: -0.5978  Acc@1: 62.5000 (65.3016)  Acc@5: 93.7500 (91.6878)  time: 0.3518  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2570/4579]  eta: 0:11:45  Lr: 0.001875  Loss: -0.2591  Acc@1: 62.5000 (65.3126)  Acc@5: 93.7500 (91.6910)  time: 0.3504  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2580/4579]  eta: 0:11:41  Lr: 0.001875  Loss: -0.7648  Acc@1: 68.7500 (65.3235)  Acc@5: 93.7500 (91.6941)  time: 0.3485  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [2590/4579]  eta: 0:11:37  Lr: 0.001875  Loss: -0.2420  Acc@1: 68.7500 (65.3343)  Acc@5: 93.7500 (91.6996)  time: 0.3502  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [2600/4579]  eta: 0:11:34  Lr: 0.001875  Loss: -0.2660  Acc@1: 68.7500 (65.3330)  Acc@5: 93.7500 (91.6931)  time: 0.3492  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2610/4579]  eta: 0:11:30  Lr: 0.001875  Loss: -0.5276  Acc@1: 62.5000 (65.3150)  Acc@5: 93.7500 (91.6962)  time: 0.3476  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2620/4579]  eta: 0:11:27  Lr: 0.001875  Loss: 0.4109  Acc@1: 62.5000 (65.2924)  Acc@5: 93.7500 (91.6969)  time: 0.3481  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [2630/4579]  eta: 0:11:23  Lr: 0.001875  Loss: -0.0318  Acc@1: 68.7500 (65.3126)  Acc@5: 93.7500 (91.7047)  time: 0.3479  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [2640/4579]  eta: 0:11:20  Lr: 0.001875  Loss: -0.6872  Acc@1: 68.7500 (65.3114)  Acc@5: 93.7500 (91.7077)  time: 0.3482  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [2650/4579]  eta: 0:11:16  Lr: 0.001875  Loss: -0.3512  Acc@1: 68.7500 (65.3268)  Acc@5: 93.7500 (91.7107)  time: 0.3501  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [2660/4579]  eta: 0:11:13  Lr: 0.001875  Loss: -0.3427  Acc@1: 68.7500 (65.3302)  Acc@5: 93.7500 (91.7089)  time: 0.3543  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [2670/4579]  eta: 0:11:09  Lr: 0.001875  Loss: -0.1344  Acc@1: 68.7500 (65.3243)  Acc@5: 93.7500 (91.7283)  time: 0.3529  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [2680/4579]  eta: 0:11:06  Lr: 0.001875  Loss: -0.4685  Acc@1: 62.5000 (65.3208)  Acc@5: 93.7500 (91.7288)  time: 0.3496  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2690/4579]  eta: 0:11:02  Lr: 0.001875  Loss: -0.5706  Acc@1: 62.5000 (65.3266)  Acc@5: 93.7500 (91.7224)  time: 0.3503  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [2700/4579]  eta: 0:10:59  Lr: 0.001875  Loss: -0.3714  Acc@1: 68.7500 (65.3253)  Acc@5: 93.7500 (91.7160)  time: 0.3499  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [2710/4579]  eta: 0:10:55  Lr: 0.001875  Loss: -0.1824  Acc@1: 62.5000 (65.3311)  Acc@5: 93.7500 (91.7143)  time: 0.3490  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [2720/4579]  eta: 0:10:52  Lr: 0.001875  Loss: 0.1687  Acc@1: 62.5000 (65.3161)  Acc@5: 87.5000 (91.6942)  time: 0.3479  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2730/4579]  eta: 0:10:48  Lr: 0.001875  Loss: -0.4869  Acc@1: 62.5000 (65.2829)  Acc@5: 87.5000 (91.6857)  time: 0.3479  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2740/4579]  eta: 0:10:45  Lr: 0.001875  Loss: -0.2439  Acc@1: 62.5000 (65.2955)  Acc@5: 87.5000 (91.6841)  time: 0.3494  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2750/4579]  eta: 0:10:41  Lr: 0.001875  Loss: 0.0297  Acc@1: 68.7500 (65.2876)  Acc@5: 87.5000 (91.6803)  time: 0.3502  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [2760/4579]  eta: 0:10:38  Lr: 0.001875  Loss: 0.1294  Acc@1: 62.5000 (65.3024)  Acc@5: 93.7500 (91.6923)  time: 0.3501  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [2770/4579]  eta: 0:10:34  Lr: 0.001875  Loss: -0.3838  Acc@1: 68.7500 (65.2991)  Acc@5: 93.7500 (91.6997)  time: 0.3501  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [2780/4579]  eta: 0:10:31  Lr: 0.001875  Loss: -0.4999  Acc@1: 68.7500 (65.3295)  Acc@5: 93.7500 (91.6936)  time: 0.3493  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2790/4579]  eta: 0:10:27  Lr: 0.001875  Loss: -0.5864  Acc@1: 68.7500 (65.3216)  Acc@5: 87.5000 (91.6831)  time: 0.3494  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2800/4579]  eta: 0:10:24  Lr: 0.001875  Loss: -0.2626  Acc@1: 62.5000 (65.3160)  Acc@5: 93.7500 (91.6838)  time: 0.3505  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2810/4579]  eta: 0:10:20  Lr: 0.001875  Loss: -0.1152  Acc@1: 68.7500 (65.3215)  Acc@5: 93.7500 (91.6845)  time: 0.3514  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2820/4579]  eta: 0:10:17  Lr: 0.001875  Loss: -0.1762  Acc@1: 68.7500 (65.3204)  Acc@5: 93.7500 (91.6962)  time: 0.3504  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2830/4579]  eta: 0:10:13  Lr: 0.001875  Loss: -0.5139  Acc@1: 68.7500 (65.3259)  Acc@5: 93.7500 (91.6836)  time: 0.3488  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [2840/4579]  eta: 0:10:10  Lr: 0.001875  Loss: -0.6054  Acc@1: 68.7500 (65.3269)  Acc@5: 87.5000 (91.6843)  time: 0.3493  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [2850/4579]  eta: 0:10:06  Lr: 0.001875  Loss: -0.6292  Acc@1: 68.7500 (65.3499)  Acc@5: 93.7500 (91.6937)  time: 0.3499  data: 0.0009  max mem: 2500
Train: Epoch[4/5]  [2860/4579]  eta: 0:10:03  Lr: 0.001875  Loss: 0.0010  Acc@1: 62.5000 (65.3334)  Acc@5: 93.7500 (91.6922)  time: 0.3500  data: 0.0015  max mem: 2500
Train: Epoch[4/5]  [2870/4579]  eta: 0:09:59  Lr: 0.001875  Loss: 0.4175  Acc@1: 56.2500 (65.3061)  Acc@5: 93.7500 (91.6884)  time: 0.3496  data: 0.0013  max mem: 2500
Train: Epoch[4/5]  [2880/4579]  eta: 0:09:56  Lr: 0.001875  Loss: -0.2975  Acc@1: 62.5000 (65.3224)  Acc@5: 93.7500 (91.6978)  time: 0.3496  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [2890/4579]  eta: 0:09:52  Lr: 0.001875  Loss: -0.9393  Acc@1: 75.0000 (65.3472)  Acc@5: 93.7500 (91.7027)  time: 0.3504  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2900/4579]  eta: 0:09:48  Lr: 0.001875  Loss: -0.0371  Acc@1: 75.0000 (65.3568)  Acc@5: 93.7500 (91.7098)  time: 0.3504  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2910/4579]  eta: 0:09:45  Lr: 0.001875  Loss: 0.3297  Acc@1: 75.0000 (65.3770)  Acc@5: 93.7500 (91.7168)  time: 0.3498  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [2920/4579]  eta: 0:09:41  Lr: 0.001875  Loss: -0.5979  Acc@1: 68.7500 (65.3843)  Acc@5: 93.7500 (91.7109)  time: 0.3507  data: 0.0017  max mem: 2500
Train: Epoch[4/5]  [2930/4579]  eta: 0:09:38  Lr: 0.001875  Loss: 0.1259  Acc@1: 62.5000 (65.3659)  Acc@5: 87.5000 (91.7093)  time: 0.3517  data: 0.0016  max mem: 2500
Train: Epoch[4/5]  [2940/4579]  eta: 0:09:34  Lr: 0.001875  Loss: -0.0147  Acc@1: 62.5000 (65.3753)  Acc@5: 87.5000 (91.7056)  time: 0.3504  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [2950/4579]  eta: 0:09:31  Lr: 0.001875  Loss: -0.5358  Acc@1: 68.7500 (65.3783)  Acc@5: 87.5000 (91.7104)  time: 0.3501  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [2960/4579]  eta: 0:09:27  Lr: 0.001875  Loss: -0.8652  Acc@1: 68.7500 (65.3918)  Acc@5: 93.7500 (91.7173)  time: 0.3513  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [2970/4579]  eta: 0:09:24  Lr: 0.001875  Loss: -0.5189  Acc@1: 62.5000 (65.3968)  Acc@5: 93.7500 (91.7179)  time: 0.3508  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [2980/4579]  eta: 0:09:20  Lr: 0.001875  Loss: -0.6097  Acc@1: 62.5000 (65.3849)  Acc@5: 93.7500 (91.7184)  time: 0.3502  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [2990/4579]  eta: 0:09:17  Lr: 0.001875  Loss: -0.7546  Acc@1: 62.5000 (65.3795)  Acc@5: 93.7500 (91.7210)  time: 0.3500  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [3000/4579]  eta: 0:09:13  Lr: 0.001875  Loss: -0.6080  Acc@1: 68.7500 (65.3907)  Acc@5: 93.7500 (91.7257)  time: 0.3504  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3010/4579]  eta: 0:09:10  Lr: 0.001875  Loss: 0.3265  Acc@1: 68.7500 (65.3998)  Acc@5: 93.7500 (91.7282)  time: 0.3500  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3020/4579]  eta: 0:09:06  Lr: 0.001875  Loss: -0.4987  Acc@1: 68.7500 (65.4233)  Acc@5: 93.7500 (91.7411)  time: 0.3507  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3030/4579]  eta: 0:09:03  Lr: 0.001875  Loss: 0.0513  Acc@1: 68.7500 (65.4363)  Acc@5: 93.7500 (91.7395)  time: 0.3511  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [3040/4579]  eta: 0:08:59  Lr: 0.001875  Loss: 0.2103  Acc@1: 62.5000 (65.4349)  Acc@5: 93.7500 (91.7441)  time: 0.3503  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [3050/4579]  eta: 0:08:56  Lr: 0.001875  Loss: -0.9592  Acc@1: 68.7500 (65.4478)  Acc@5: 93.7500 (91.7425)  time: 0.3498  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [3060/4579]  eta: 0:08:52  Lr: 0.001875  Loss: -0.7591  Acc@1: 68.7500 (65.4647)  Acc@5: 93.7500 (91.7429)  time: 0.3495  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [3070/4579]  eta: 0:08:49  Lr: 0.001875  Loss: -0.0488  Acc@1: 68.7500 (65.4510)  Acc@5: 93.7500 (91.7413)  time: 0.3505  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [3080/4579]  eta: 0:08:45  Lr: 0.001875  Loss: -0.2142  Acc@1: 56.2500 (65.4414)  Acc@5: 93.7500 (91.7478)  time: 0.3503  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [3090/4579]  eta: 0:08:42  Lr: 0.001875  Loss: 0.1710  Acc@1: 62.5000 (65.4622)  Acc@5: 93.7500 (91.7401)  time: 0.3502  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [3100/4579]  eta: 0:08:38  Lr: 0.001875  Loss: -0.1466  Acc@1: 68.7500 (65.4567)  Acc@5: 93.7500 (91.7506)  time: 0.3511  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [3110/4579]  eta: 0:08:35  Lr: 0.001875  Loss: -0.7685  Acc@1: 62.5000 (65.4552)  Acc@5: 93.7500 (91.7470)  time: 0.3508  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [3120/4579]  eta: 0:08:31  Lr: 0.001875  Loss: -0.4921  Acc@1: 62.5000 (65.4678)  Acc@5: 93.7500 (91.7514)  time: 0.3487  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3130/4579]  eta: 0:08:28  Lr: 0.001875  Loss: -0.5363  Acc@1: 68.7500 (65.4863)  Acc@5: 93.7500 (91.7578)  time: 0.3496  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [3140/4579]  eta: 0:08:24  Lr: 0.001875  Loss: -0.4065  Acc@1: 62.5000 (65.4787)  Acc@5: 93.7500 (91.7502)  time: 0.3515  data: 0.0013  max mem: 2500
Train: Epoch[4/5]  [3150/4579]  eta: 0:08:21  Lr: 0.001875  Loss: -0.3174  Acc@1: 62.5000 (65.4693)  Acc@5: 93.7500 (91.7427)  time: 0.3527  data: 0.0016  max mem: 2500
Train: Epoch[4/5]  [3160/4579]  eta: 0:08:17  Lr: 0.001875  Loss: 0.0688  Acc@1: 62.5000 (65.4619)  Acc@5: 93.7500 (91.7352)  time: 0.3512  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [3170/4579]  eta: 0:08:14  Lr: 0.001875  Loss: -0.0539  Acc@1: 62.5000 (65.4545)  Acc@5: 93.7500 (91.7396)  time: 0.3488  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [3180/4579]  eta: 0:08:10  Lr: 0.001875  Loss: -0.7435  Acc@1: 62.5000 (65.4393)  Acc@5: 93.7500 (91.7459)  time: 0.3500  data: 0.0011  max mem: 2500
Train: Epoch[4/5]  [3190/4579]  eta: 0:08:07  Lr: 0.001875  Loss: -0.6941  Acc@1: 62.5000 (65.4595)  Acc@5: 93.7500 (91.7561)  time: 0.3503  data: 0.0012  max mem: 2500
Train: Epoch[4/5]  [3200/4579]  eta: 0:08:03  Lr: 0.001875  Loss: -0.6863  Acc@1: 68.7500 (65.4522)  Acc@5: 93.7500 (91.7545)  time: 0.3501  data: 0.0014  max mem: 2500
Train: Epoch[4/5]  [3210/4579]  eta: 0:08:00  Lr: 0.001875  Loss: -0.5048  Acc@1: 62.5000 (65.4488)  Acc@5: 87.5000 (91.7452)  time: 0.3519  data: 0.0015  max mem: 2500
Train: Epoch[4/5]  [3220/4579]  eta: 0:07:56  Lr: 0.001875  Loss: 0.1882  Acc@1: 68.7500 (65.4533)  Acc@5: 87.5000 (91.7417)  time: 0.3512  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [3230/4579]  eta: 0:07:53  Lr: 0.001875  Loss: -0.4411  Acc@1: 68.7500 (65.4557)  Acc@5: 93.7500 (91.7421)  time: 0.3522  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [3240/4579]  eta: 0:07:49  Lr: 0.001875  Loss: 0.3895  Acc@1: 62.5000 (65.4312)  Acc@5: 87.5000 (91.7194)  time: 0.3537  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [3250/4579]  eta: 0:07:46  Lr: 0.001875  Loss: 0.0017  Acc@1: 62.5000 (65.4337)  Acc@5: 87.5000 (91.7275)  time: 0.3520  data: 0.0012  max mem: 2500
Train: Epoch[4/5]  [3260/4579]  eta: 0:07:42  Lr: 0.001875  Loss: 0.0484  Acc@1: 62.5000 (65.4151)  Acc@5: 93.7500 (91.7165)  time: 0.3515  data: 0.0012  max mem: 2500
Train: Epoch[4/5]  [3270/4579]  eta: 0:07:39  Lr: 0.001875  Loss: 0.0010  Acc@1: 56.2500 (65.4024)  Acc@5: 87.5000 (91.7132)  time: 0.3515  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [3280/4579]  eta: 0:07:35  Lr: 0.001875  Loss: -0.2357  Acc@1: 62.5000 (65.4031)  Acc@5: 93.7500 (91.7175)  time: 0.3517  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [3290/4579]  eta: 0:07:32  Lr: 0.001875  Loss: -0.1013  Acc@1: 62.5000 (65.3981)  Acc@5: 93.7500 (91.7141)  time: 0.3546  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [3300/4579]  eta: 0:07:28  Lr: 0.001875  Loss: -0.2386  Acc@1: 68.7500 (65.4082)  Acc@5: 93.7500 (91.7222)  time: 0.3549  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [3310/4579]  eta: 0:07:25  Lr: 0.001875  Loss: -0.1019  Acc@1: 68.7500 (65.4145)  Acc@5: 93.7500 (91.7246)  time: 0.3509  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [3320/4579]  eta: 0:07:21  Lr: 0.001875  Loss: -0.3202  Acc@1: 68.7500 (65.4227)  Acc@5: 93.7500 (91.7250)  time: 0.3493  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [3330/4579]  eta: 0:07:18  Lr: 0.001875  Loss: -0.0634  Acc@1: 68.7500 (65.4252)  Acc@5: 87.5000 (91.7161)  time: 0.3504  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [3340/4579]  eta: 0:07:14  Lr: 0.001875  Loss: -0.2286  Acc@1: 68.7500 (65.4370)  Acc@5: 87.5000 (91.7222)  time: 0.3511  data: 0.0012  max mem: 2500
Train: Epoch[4/5]  [3350/4579]  eta: 0:07:11  Lr: 0.001875  Loss: -0.3107  Acc@1: 68.7500 (65.4338)  Acc@5: 87.5000 (91.7170)  time: 0.3513  data: 0.0021  max mem: 2500
Train: Epoch[4/5]  [3360/4579]  eta: 0:07:07  Lr: 0.001875  Loss: -0.0334  Acc@1: 68.7500 (65.4381)  Acc@5: 87.5000 (91.7082)  time: 0.3516  data: 0.0016  max mem: 2500
Train: Epoch[4/5]  [3370/4579]  eta: 0:07:04  Lr: 0.001875  Loss: 0.4373  Acc@1: 68.7500 (65.4368)  Acc@5: 93.7500 (91.7087)  time: 0.3509  data: 0.0012  max mem: 2500
Train: Epoch[4/5]  [3380/4579]  eta: 0:07:00  Lr: 0.001875  Loss: -0.5807  Acc@1: 68.7500 (65.4318)  Acc@5: 93.7500 (91.7092)  time: 0.3503  data: 0.0011  max mem: 2500
Train: Epoch[4/5]  [3390/4579]  eta: 0:06:57  Lr: 0.001875  Loss: 0.1983  Acc@1: 68.7500 (65.4398)  Acc@5: 93.7500 (91.7152)  time: 0.3523  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [3400/4579]  eta: 0:06:53  Lr: 0.001875  Loss: 0.0274  Acc@1: 62.5000 (65.4274)  Acc@5: 93.7500 (91.7120)  time: 0.3520  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [3410/4579]  eta: 0:06:50  Lr: 0.001875  Loss: -0.4162  Acc@1: 62.5000 (65.4225)  Acc@5: 93.7500 (91.7216)  time: 0.3491  data: 0.0009  max mem: 2500
Train: Epoch[4/5]  [3420/4579]  eta: 0:06:46  Lr: 0.001875  Loss: -0.2506  Acc@1: 68.7500 (65.4323)  Acc@5: 93.7500 (91.7276)  time: 0.3491  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [3430/4579]  eta: 0:06:43  Lr: 0.001875  Loss: -0.3033  Acc@1: 68.7500 (65.4182)  Acc@5: 93.7500 (91.7207)  time: 0.3505  data: 0.0010  max mem: 2500
Train: Epoch[4/5]  [3440/4579]  eta: 0:06:39  Lr: 0.001875  Loss: -0.3554  Acc@1: 68.7500 (65.4207)  Acc@5: 93.7500 (91.7248)  time: 0.3499  data: 0.0011  max mem: 2500
Train: Epoch[4/5]  [3450/4579]  eta: 0:06:36  Lr: 0.001875  Loss: 0.1733  Acc@1: 62.5000 (65.4176)  Acc@5: 93.7500 (91.7234)  time: 0.3488  data: 0.0009  max mem: 2500
Train: Epoch[4/5]  [3460/4579]  eta: 0:06:32  Lr: 0.001875  Loss: -0.4897  Acc@1: 62.5000 (65.4146)  Acc@5: 87.5000 (91.7220)  time: 0.3490  data: 0.0010  max mem: 2500
Train: Epoch[4/5]  [3470/4579]  eta: 0:06:29  Lr: 0.001875  Loss: 0.4052  Acc@1: 62.5000 (65.3936)  Acc@5: 93.7500 (91.7225)  time: 0.3507  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [3480/4579]  eta: 0:06:25  Lr: 0.001875  Loss: -0.4766  Acc@1: 62.5000 (65.4015)  Acc@5: 87.5000 (91.7175)  time: 0.3531  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [3490/4579]  eta: 0:06:22  Lr: 0.001875  Loss: 0.4047  Acc@1: 62.5000 (65.4146)  Acc@5: 87.5000 (91.7216)  time: 0.3515  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [3500/4579]  eta: 0:06:18  Lr: 0.001875  Loss: -0.1634  Acc@1: 68.7500 (65.4331)  Acc@5: 93.7500 (91.7291)  time: 0.3501  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [3510/4579]  eta: 0:06:15  Lr: 0.001875  Loss: 0.0245  Acc@1: 68.7500 (65.4425)  Acc@5: 93.7500 (91.7331)  time: 0.3515  data: 0.0010  max mem: 2500
Train: Epoch[4/5]  [3520/4579]  eta: 0:06:11  Lr: 0.001875  Loss: -0.6047  Acc@1: 68.7500 (65.4466)  Acc@5: 93.7500 (91.7389)  time: 0.3517  data: 0.0011  max mem: 2500
Train: Epoch[4/5]  [3530/4579]  eta: 0:06:08  Lr: 0.001875  Loss: -0.6002  Acc@1: 68.7500 (65.4560)  Acc@5: 93.7500 (91.7428)  time: 0.3530  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [3540/4579]  eta: 0:06:04  Lr: 0.001875  Loss: 0.0765  Acc@1: 62.5000 (65.4458)  Acc@5: 93.7500 (91.7308)  time: 0.3521  data: 0.0013  max mem: 2500
Train: Epoch[4/5]  [3550/4579]  eta: 0:06:00  Lr: 0.001875  Loss: -0.6299  Acc@1: 68.7500 (65.4657)  Acc@5: 93.7500 (91.7470)  time: 0.3496  data: 0.0012  max mem: 2500
Train: Epoch[4/5]  [3560/4579]  eta: 0:05:57  Lr: 0.001875  Loss: -0.3348  Acc@1: 68.7500 (65.4644)  Acc@5: 93.7500 (91.7386)  time: 0.3493  data: 0.0014  max mem: 2500
Train: Epoch[4/5]  [3570/4579]  eta: 0:05:53  Lr: 0.001875  Loss: -0.3279  Acc@1: 62.5000 (65.4631)  Acc@5: 87.5000 (91.7338)  time: 0.3498  data: 0.0017  max mem: 2500
Train: Epoch[4/5]  [3580/4579]  eta: 0:05:50  Lr: 0.001875  Loss: -0.7190  Acc@1: 68.7500 (65.4723)  Acc@5: 93.7500 (91.7446)  time: 0.3513  data: 0.0012  max mem: 2500
Train: Epoch[4/5]  [3590/4579]  eta: 0:05:46  Lr: 0.001875  Loss: -0.5050  Acc@1: 68.7500 (65.4971)  Acc@5: 93.7500 (91.7502)  time: 0.3511  data: 0.0009  max mem: 2500
Train: Epoch[4/5]  [3600/4579]  eta: 0:05:43  Lr: 0.001875  Loss: -0.1044  Acc@1: 62.5000 (65.4801)  Acc@5: 93.7500 (91.7471)  time: 0.3509  data: 0.0013  max mem: 2500
Train: Epoch[4/5]  [3610/4579]  eta: 0:05:39  Lr: 0.001875  Loss: -0.3273  Acc@1: 62.5000 (65.4822)  Acc@5: 93.7500 (91.7509)  time: 0.3511  data: 0.0015  max mem: 2500
Train: Epoch[4/5]  [3620/4579]  eta: 0:05:36  Lr: 0.001875  Loss: -0.8726  Acc@1: 68.7500 (65.4878)  Acc@5: 93.7500 (91.7581)  time: 0.3509  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [3630/4579]  eta: 0:05:32  Lr: 0.001875  Loss: -0.7850  Acc@1: 62.5000 (65.4899)  Acc@5: 93.7500 (91.7619)  time: 0.3510  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [3640/4579]  eta: 0:05:29  Lr: 0.001875  Loss: -0.1893  Acc@1: 68.7500 (65.5126)  Acc@5: 93.7500 (91.7691)  time: 0.3522  data: 0.0013  max mem: 2500
Train: Epoch[4/5]  [3650/4579]  eta: 0:05:25  Lr: 0.001875  Loss: 0.0511  Acc@1: 68.7500 (65.5026)  Acc@5: 93.7500 (91.7660)  time: 0.3514  data: 0.0013  max mem: 2500
Train: Epoch[4/5]  [3660/4579]  eta: 0:05:22  Lr: 0.001875  Loss: -0.2848  Acc@1: 62.5000 (65.5132)  Acc@5: 93.7500 (91.7697)  time: 0.3480  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [3670/4579]  eta: 0:05:18  Lr: 0.001875  Loss: -0.0111  Acc@1: 68.7500 (65.5254)  Acc@5: 93.7500 (91.7665)  time: 0.3485  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [3680/4579]  eta: 0:05:15  Lr: 0.001875  Loss: -0.6605  Acc@1: 68.7500 (65.5376)  Acc@5: 93.7500 (91.7685)  time: 0.3481  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [3690/4579]  eta: 0:05:11  Lr: 0.001875  Loss: -0.1441  Acc@1: 68.7500 (65.5412)  Acc@5: 93.7500 (91.7790)  time: 0.3478  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [3700/4579]  eta: 0:05:08  Lr: 0.001875  Loss: -0.4218  Acc@1: 68.7500 (65.5532)  Acc@5: 93.7500 (91.7809)  time: 0.3490  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [3710/4579]  eta: 0:05:04  Lr: 0.001875  Loss: 0.2327  Acc@1: 68.7500 (65.5484)  Acc@5: 93.7500 (91.7829)  time: 0.3508  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [3720/4579]  eta: 0:05:01  Lr: 0.001875  Loss: -0.1126  Acc@1: 68.7500 (65.5536)  Acc@5: 93.7500 (91.7831)  time: 0.3512  data: 0.0009  max mem: 2500
Train: Epoch[4/5]  [3730/4579]  eta: 0:04:57  Lr: 0.001875  Loss: -0.0633  Acc@1: 62.5000 (65.5371)  Acc@5: 93.7500 (91.7834)  time: 0.3502  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [3740/4579]  eta: 0:04:54  Lr: 0.001875  Loss: -0.7725  Acc@1: 62.5000 (65.5373)  Acc@5: 93.7500 (91.7920)  time: 0.3528  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [3750/4579]  eta: 0:04:50  Lr: 0.001875  Loss: -0.1387  Acc@1: 62.5000 (65.5275)  Acc@5: 93.7500 (91.7955)  time: 0.3533  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [3760/4579]  eta: 0:04:47  Lr: 0.001875  Loss: -0.1491  Acc@1: 68.7500 (65.5278)  Acc@5: 93.7500 (91.7858)  time: 0.3512  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [3770/4579]  eta: 0:04:43  Lr: 0.001875  Loss: -0.3430  Acc@1: 68.7500 (65.5446)  Acc@5: 87.5000 (91.7893)  time: 0.3502  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [3780/4579]  eta: 0:04:40  Lr: 0.001875  Loss: -0.4267  Acc@1: 68.7500 (65.5481)  Acc@5: 93.7500 (91.7978)  time: 0.3503  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [3790/4579]  eta: 0:04:36  Lr: 0.001875  Loss: -0.2884  Acc@1: 68.7500 (65.5450)  Acc@5: 93.7500 (91.8063)  time: 0.3502  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [3800/4579]  eta: 0:04:33  Lr: 0.001875  Loss: 0.4589  Acc@1: 68.7500 (65.5600)  Acc@5: 93.7500 (91.8064)  time: 0.3493  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [3810/4579]  eta: 0:04:29  Lr: 0.001875  Loss: -0.5941  Acc@1: 68.7500 (65.5750)  Acc@5: 93.7500 (91.8165)  time: 0.3500  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [3820/4579]  eta: 0:04:26  Lr: 0.001875  Loss: -0.4082  Acc@1: 75.0000 (65.5817)  Acc@5: 93.7500 (91.8133)  time: 0.3511  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [3830/4579]  eta: 0:04:22  Lr: 0.001875  Loss: -0.3538  Acc@1: 68.7500 (65.5703)  Acc@5: 87.5000 (91.8102)  time: 0.3502  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [3840/4579]  eta: 0:04:19  Lr: 0.001875  Loss: -0.4676  Acc@1: 68.7500 (65.5705)  Acc@5: 87.5000 (91.8088)  time: 0.3496  data: 0.0010  max mem: 2500
Train: Epoch[4/5]  [3850/4579]  eta: 0:04:15  Lr: 0.001875  Loss: -0.6440  Acc@1: 68.7500 (65.5917)  Acc@5: 93.7500 (91.8138)  time: 0.3505  data: 0.0013  max mem: 2500
Train: Epoch[4/5]  [3860/4579]  eta: 0:04:12  Lr: 0.001875  Loss: -0.1937  Acc@1: 68.7500 (65.5870)  Acc@5: 93.7500 (91.8043)  time: 0.3496  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [3870/4579]  eta: 0:04:08  Lr: 0.001875  Loss: -0.0650  Acc@1: 68.7500 (65.5984)  Acc@5: 87.5000 (91.8012)  time: 0.3485  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [3880/4579]  eta: 0:04:05  Lr: 0.001875  Loss: 0.4569  Acc@1: 68.7500 (65.6097)  Acc@5: 93.7500 (91.7998)  time: 0.3487  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [3890/4579]  eta: 0:04:01  Lr: 0.001875  Loss: -0.2878  Acc@1: 68.7500 (65.6194)  Acc@5: 93.7500 (91.8032)  time: 0.3514  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [3900/4579]  eta: 0:03:58  Lr: 0.001875  Loss: -0.0520  Acc@1: 68.7500 (65.6210)  Acc@5: 93.7500 (91.8082)  time: 0.3510  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [3910/4579]  eta: 0:03:54  Lr: 0.001875  Loss: -0.2934  Acc@1: 68.7500 (65.6370)  Acc@5: 93.7500 (91.8148)  time: 0.3512  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [3920/4579]  eta: 0:03:51  Lr: 0.001875  Loss: -0.6564  Acc@1: 68.7500 (65.6354)  Acc@5: 93.7500 (91.8149)  time: 0.3512  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [3930/4579]  eta: 0:03:47  Lr: 0.001875  Loss: -0.5639  Acc@1: 68.7500 (65.6353)  Acc@5: 93.7500 (91.8151)  time: 0.3489  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [3940/4579]  eta: 0:03:44  Lr: 0.001875  Loss: -0.6735  Acc@1: 62.5000 (65.6401)  Acc@5: 93.7500 (91.8168)  time: 0.3514  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [3950/4579]  eta: 0:03:40  Lr: 0.001875  Loss: 0.3803  Acc@1: 68.7500 (65.6448)  Acc@5: 93.7500 (91.8075)  time: 0.3517  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [3960/4579]  eta: 0:03:37  Lr: 0.001875  Loss: -0.4167  Acc@1: 62.5000 (65.6463)  Acc@5: 93.7500 (91.8171)  time: 0.3492  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [3970/4579]  eta: 0:03:33  Lr: 0.001875  Loss: -0.0499  Acc@1: 62.5000 (65.6494)  Acc@5: 93.7500 (91.8235)  time: 0.3493  data: 0.0014  max mem: 2500
Train: Epoch[4/5]  [3980/4579]  eta: 0:03:30  Lr: 0.001875  Loss: 0.1516  Acc@1: 68.7500 (65.6556)  Acc@5: 93.7500 (91.8268)  time: 0.3501  data: 0.0013  max mem: 2500
Train: Epoch[4/5]  [3990/4579]  eta: 0:03:26  Lr: 0.001875  Loss: -0.5240  Acc@1: 62.5000 (65.6477)  Acc@5: 93.7500 (91.8238)  time: 0.3497  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [4000/4579]  eta: 0:03:23  Lr: 0.001875  Loss: 0.0298  Acc@1: 62.5000 (65.6367)  Acc@5: 93.7500 (91.8270)  time: 0.3518  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [4010/4579]  eta: 0:03:19  Lr: 0.001875  Loss: -0.3356  Acc@1: 62.5000 (65.6336)  Acc@5: 93.7500 (91.8256)  time: 0.3550  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [4020/4579]  eta: 0:03:16  Lr: 0.001875  Loss: -0.3999  Acc@1: 62.5000 (65.6351)  Acc@5: 93.7500 (91.8351)  time: 0.3551  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [4030/4579]  eta: 0:03:12  Lr: 0.001875  Loss: -0.4976  Acc@1: 68.7500 (65.6537)  Acc@5: 93.7500 (91.8445)  time: 0.3513  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [4040/4579]  eta: 0:03:09  Lr: 0.001875  Loss: 0.2784  Acc@1: 62.5000 (65.6459)  Acc@5: 93.7500 (91.8383)  time: 0.3498  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [4050/4579]  eta: 0:03:05  Lr: 0.001875  Loss: -0.1567  Acc@1: 62.5000 (65.6458)  Acc@5: 87.5000 (91.8307)  time: 0.3509  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [4060/4579]  eta: 0:03:02  Lr: 0.001875  Loss: 0.0514  Acc@1: 68.7500 (65.6504)  Acc@5: 87.5000 (91.8231)  time: 0.3501  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [4070/4579]  eta: 0:02:58  Lr: 0.001875  Loss: 0.3913  Acc@1: 62.5000 (65.6427)  Acc@5: 93.7500 (91.8171)  time: 0.3518  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [4080/4579]  eta: 0:02:55  Lr: 0.001875  Loss: 0.2897  Acc@1: 62.5000 (65.6457)  Acc@5: 93.7500 (91.8280)  time: 0.3538  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [4090/4579]  eta: 0:02:51  Lr: 0.001875  Loss: -0.1559  Acc@1: 68.7500 (65.6517)  Acc@5: 93.7500 (91.8312)  time: 0.3524  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [4100/4579]  eta: 0:02:48  Lr: 0.001875  Loss: -0.5510  Acc@1: 62.5000 (65.6578)  Acc@5: 93.7500 (91.8328)  time: 0.3506  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [4110/4579]  eta: 0:02:44  Lr: 0.001875  Loss: -0.2541  Acc@1: 62.5000 (65.6592)  Acc@5: 87.5000 (91.8238)  time: 0.3510  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [4120/4579]  eta: 0:02:41  Lr: 0.001875  Loss: -0.8949  Acc@1: 62.5000 (65.6606)  Acc@5: 87.5000 (91.8254)  time: 0.3501  data: 0.0009  max mem: 2500
Train: Epoch[4/5]  [4130/4579]  eta: 0:02:37  Lr: 0.001875  Loss: 0.1667  Acc@1: 62.5000 (65.6621)  Acc@5: 93.7500 (91.8180)  time: 0.3483  data: 0.0009  max mem: 2500
Train: Epoch[4/5]  [4140/4579]  eta: 0:02:33  Lr: 0.001875  Loss: -0.2941  Acc@1: 62.5000 (65.6635)  Acc@5: 93.7500 (91.8241)  time: 0.3487  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [4150/4579]  eta: 0:02:30  Lr: 0.001875  Loss: -0.0888  Acc@1: 68.7500 (65.6649)  Acc@5: 93.7500 (91.8212)  time: 0.3488  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [4160/4579]  eta: 0:02:26  Lr: 0.001875  Loss: -0.3718  Acc@1: 68.7500 (65.6573)  Acc@5: 87.5000 (91.8229)  time: 0.3490  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [4170/4579]  eta: 0:02:23  Lr: 0.001875  Loss: -0.3172  Acc@1: 62.5000 (65.6572)  Acc@5: 87.5000 (91.8230)  time: 0.3504  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [4180/4579]  eta: 0:02:19  Lr: 0.001875  Loss: -0.4911  Acc@1: 68.7500 (65.6661)  Acc@5: 93.7500 (91.8291)  time: 0.3509  data: 0.0009  max mem: 2500
Train: Epoch[4/5]  [4190/4579]  eta: 0:02:16  Lr: 0.001875  Loss: -0.6074  Acc@1: 62.5000 (65.6615)  Acc@5: 93.7500 (91.8277)  time: 0.3509  data: 0.0011  max mem: 2500
Train: Epoch[4/5]  [4200/4579]  eta: 0:02:12  Lr: 0.001875  Loss: -0.2925  Acc@1: 62.5000 (65.6614)  Acc@5: 93.7500 (91.8278)  time: 0.3500  data: 0.0014  max mem: 2500
Train: Epoch[4/5]  [4210/4579]  eta: 0:02:09  Lr: 0.001875  Loss: -0.4860  Acc@1: 62.5000 (65.6480)  Acc@5: 93.7500 (91.8235)  time: 0.3489  data: 0.0009  max mem: 2500
Train: Epoch[4/5]  [4220/4579]  eta: 0:02:05  Lr: 0.001875  Loss: 0.1686  Acc@1: 62.5000 (65.6450)  Acc@5: 93.7500 (91.8192)  time: 0.3478  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [4230/4579]  eta: 0:02:02  Lr: 0.001875  Loss: -0.3895  Acc@1: 62.5000 (65.6479)  Acc@5: 93.7500 (91.8193)  time: 0.3472  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [4240/4579]  eta: 0:01:58  Lr: 0.001875  Loss: -0.0300  Acc@1: 62.5000 (65.6390)  Acc@5: 93.7500 (91.8180)  time: 0.3484  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [4250/4579]  eta: 0:01:55  Lr: 0.001875  Loss: -0.1683  Acc@1: 62.5000 (65.6404)  Acc@5: 93.7500 (91.8225)  time: 0.3495  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [4260/4579]  eta: 0:01:51  Lr: 0.001875  Loss: -0.2358  Acc@1: 62.5000 (65.6375)  Acc@5: 93.7500 (91.8241)  time: 0.3493  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [4270/4579]  eta: 0:01:48  Lr: 0.001875  Loss: -0.3423  Acc@1: 62.5000 (65.6374)  Acc@5: 93.7500 (91.8184)  time: 0.3489  data: 0.0014  max mem: 2500
Train: Epoch[4/5]  [4280/4579]  eta: 0:01:44  Lr: 0.001875  Loss: -0.3318  Acc@1: 62.5000 (65.6359)  Acc@5: 87.5000 (91.8200)  time: 0.3493  data: 0.0013  max mem: 2500
Train: Epoch[4/5]  [4290/4579]  eta: 0:01:41  Lr: 0.001875  Loss: -0.0977  Acc@1: 62.5000 (65.6316)  Acc@5: 87.5000 (91.8113)  time: 0.3513  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [4300/4579]  eta: 0:01:37  Lr: 0.001875  Loss: 0.2085  Acc@1: 62.5000 (65.6359)  Acc@5: 87.5000 (91.8100)  time: 0.3533  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [4310/4579]  eta: 0:01:34  Lr: 0.001875  Loss: -0.1472  Acc@1: 62.5000 (65.6228)  Acc@5: 87.5000 (91.8044)  time: 0.3533  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [4320/4579]  eta: 0:01:30  Lr: 0.001875  Loss: -0.5331  Acc@1: 62.5000 (65.6257)  Acc@5: 87.5000 (91.8002)  time: 0.3520  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [4330/4579]  eta: 0:01:27  Lr: 0.001875  Loss: 0.2664  Acc@1: 68.7500 (65.6243)  Acc@5: 87.5000 (91.7961)  time: 0.3510  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [4340/4579]  eta: 0:01:23  Lr: 0.001875  Loss: -0.0822  Acc@1: 62.5000 (65.6214)  Acc@5: 93.7500 (91.7948)  time: 0.3512  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [4350/4579]  eta: 0:01:20  Lr: 0.001875  Loss: 0.0918  Acc@1: 68.7500 (65.6286)  Acc@5: 93.7500 (91.8036)  time: 0.3518  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [4360/4579]  eta: 0:01:16  Lr: 0.001875  Loss: -0.0847  Acc@1: 68.7500 (65.6257)  Acc@5: 93.7500 (91.8023)  time: 0.3522  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [4370/4579]  eta: 0:01:13  Lr: 0.001875  Loss: -0.3554  Acc@1: 62.5000 (65.6229)  Acc@5: 93.7500 (91.8011)  time: 0.3505  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [4380/4579]  eta: 0:01:09  Lr: 0.001875  Loss: -0.4986  Acc@1: 68.7500 (65.6314)  Acc@5: 93.7500 (91.7984)  time: 0.3491  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [4390/4579]  eta: 0:01:06  Lr: 0.001875  Loss: -0.5536  Acc@1: 68.7500 (65.6385)  Acc@5: 93.7500 (91.8000)  time: 0.3484  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [4400/4579]  eta: 0:01:02  Lr: 0.001875  Loss: -0.7982  Acc@1: 68.7500 (65.6371)  Acc@5: 93.7500 (91.7959)  time: 0.3489  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [4410/4579]  eta: 0:00:59  Lr: 0.001875  Loss: -0.0895  Acc@1: 62.5000 (65.6300)  Acc@5: 93.7500 (91.7975)  time: 0.3498  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [4420/4579]  eta: 0:00:55  Lr: 0.001875  Loss: -0.4241  Acc@1: 62.5000 (65.6257)  Acc@5: 93.7500 (91.7977)  time: 0.3491  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [4430/4579]  eta: 0:00:52  Lr: 0.001875  Loss: 0.0840  Acc@1: 62.5000 (65.6285)  Acc@5: 93.7500 (91.7964)  time: 0.3489  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [4440/4579]  eta: 0:00:48  Lr: 0.001875  Loss: -0.0241  Acc@1: 62.5000 (65.6187)  Acc@5: 93.7500 (91.7952)  time: 0.3500  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [4450/4579]  eta: 0:00:45  Lr: 0.001875  Loss: 0.1530  Acc@1: 62.5000 (65.6173)  Acc@5: 87.5000 (91.7926)  time: 0.3509  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [4460/4579]  eta: 0:00:41  Lr: 0.001875  Loss: -0.1740  Acc@1: 68.7500 (65.6355)  Acc@5: 93.7500 (91.7970)  time: 0.3504  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [4470/4579]  eta: 0:00:38  Lr: 0.001875  Loss: -0.3644  Acc@1: 68.7500 (65.6397)  Acc@5: 93.7500 (91.7999)  time: 0.3496  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [4480/4579]  eta: 0:00:34  Lr: 0.001875  Loss: -0.6748  Acc@1: 68.7500 (65.6592)  Acc@5: 93.7500 (91.8057)  time: 0.3489  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [4490/4579]  eta: 0:00:31  Lr: 0.001875  Loss: -0.0903  Acc@1: 68.7500 (65.6661)  Acc@5: 93.7500 (91.8031)  time: 0.3480  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [4500/4579]  eta: 0:00:27  Lr: 0.001875  Loss: -0.3277  Acc@1: 68.7500 (65.6701)  Acc@5: 87.5000 (91.8018)  time: 0.3485  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [4510/4579]  eta: 0:00:24  Lr: 0.001875  Loss: -0.3225  Acc@1: 68.7500 (65.6659)  Acc@5: 93.7500 (91.8048)  time: 0.3498  data: 0.0009  max mem: 2500
Train: Epoch[4/5]  [4520/4579]  eta: 0:00:20  Lr: 0.001875  Loss: -0.0181  Acc@1: 68.7500 (65.6699)  Acc@5: 87.5000 (91.8008)  time: 0.3498  data: 0.0009  max mem: 2500
Train: Epoch[4/5]  [4530/4579]  eta: 0:00:17  Lr: 0.001875  Loss: 0.0024  Acc@1: 68.7500 (65.6740)  Acc@5: 87.5000 (91.7954)  time: 0.3491  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [4540/4579]  eta: 0:00:13  Lr: 0.001875  Loss: -0.4621  Acc@1: 68.7500 (65.6752)  Acc@5: 93.7500 (91.7956)  time: 0.3504  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [4550/4579]  eta: 0:00:10  Lr: 0.001875  Loss: -0.0048  Acc@1: 68.7500 (65.6820)  Acc@5: 93.7500 (91.7903)  time: 0.3509  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [4560/4579]  eta: 0:00:06  Lr: 0.001875  Loss: -0.1156  Acc@1: 68.7500 (65.6860)  Acc@5: 93.7500 (91.7891)  time: 0.3525  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [4570/4579]  eta: 0:00:03  Lr: 0.001875  Loss: 0.5032  Acc@1: 62.5000 (65.6776)  Acc@5: 93.7500 (91.7906)  time: 0.3546  data: 0.0017  max mem: 2500
Train: Epoch[4/5]  [4578/4579]  eta: 0:00:00  Lr: 0.001875  Loss: 0.1819  Acc@1: 62.5000 (65.6715)  Acc@5: 88.8889 (91.7810)  time: 0.3459  data: 0.0016  max mem: 2500
Train: Epoch[4/5] Total time: 0:26:46 (0.3509 s / it)
{0: {0: 293028, 1: 0, 2: 0, 3: 0, 4: 0}, 1: {0: 293028, 1: 0, 2: 0, 3: 0, 4: 0}, 2: {0: 293028, 1: 0, 2: 0, 3: 0, 4: 0}, 3: {0: 293028, 1: 0, 2: 0, 3: 0, 4: 0}, 4: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 5: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 6: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 7: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 8: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 9: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 10: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 11: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 12: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 13: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 14: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 15: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 16: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 17: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 18: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 19: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}}
Averaged stats: Lr: 0.001875  Loss: 0.1819  Acc@1: 62.5000 (65.6715)  Acc@5: 88.8889 (91.7810)
Train: Epoch[5/5]  [   0/4579]  eta: 0:44:31  Lr: 0.001875  Loss: -0.3332  Acc@1: 68.7500 (68.7500)  Acc@5: 93.7500 (93.7500)  time: 0.5833  data: 0.2304  max mem: 2500
Train: Epoch[5/5]  [  10/4579]  eta: 0:28:09  Lr: 0.001875  Loss: -0.5184  Acc@1: 62.5000 (61.3636)  Acc@5: 93.7500 (90.9091)  time: 0.3697  data: 0.0214  max mem: 2500
Train: Epoch[5/5]  [  20/4579]  eta: 0:27:19  Lr: 0.001875  Loss: 0.1218  Acc@1: 56.2500 (61.9048)  Acc@5: 93.7500 (91.3690)  time: 0.3484  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [  30/4579]  eta: 0:27:06  Lr: 0.001875  Loss: -0.4987  Acc@1: 62.5000 (63.5081)  Acc@5: 93.7500 (91.7339)  time: 0.3509  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [  40/4579]  eta: 0:26:57  Lr: 0.001875  Loss: -0.5458  Acc@1: 68.7500 (65.3963)  Acc@5: 93.7500 (91.9207)  time: 0.3528  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [  50/4579]  eta: 0:26:51  Lr: 0.001875  Loss: -0.6175  Acc@1: 68.7500 (66.4216)  Acc@5: 93.7500 (92.4020)  time: 0.3533  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [  60/4579]  eta: 0:26:43  Lr: 0.001875  Loss: 0.0479  Acc@1: 68.7500 (66.3934)  Acc@5: 93.7500 (92.1107)  time: 0.3519  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [  70/4579]  eta: 0:26:36  Lr: 0.001875  Loss: -0.0253  Acc@1: 68.7500 (66.2852)  Acc@5: 93.7500 (91.9894)  time: 0.3496  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [  80/4579]  eta: 0:26:30  Lr: 0.001875  Loss: -0.4470  Acc@1: 68.7500 (66.8981)  Acc@5: 93.7500 (92.2068)  time: 0.3496  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [  90/4579]  eta: 0:26:26  Lr: 0.001875  Loss: -0.2086  Acc@1: 68.7500 (66.3462)  Acc@5: 93.7500 (92.3764)  time: 0.3507  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [ 100/4579]  eta: 0:26:21  Lr: 0.001875  Loss: -0.0132  Acc@1: 62.5000 (66.4604)  Acc@5: 93.7500 (92.2030)  time: 0.3517  data: 0.0016  max mem: 2500
Train: Epoch[5/5]  [ 110/4579]  eta: 0:26:16  Lr: 0.001875  Loss: -0.6657  Acc@1: 75.0000 (67.0045)  Acc@5: 93.7500 (92.2860)  time: 0.3500  data: 0.0012  max mem: 2500
Train: Epoch[5/5]  [ 120/4579]  eta: 0:26:12  Lr: 0.001875  Loss: -0.4262  Acc@1: 68.7500 (66.8905)  Acc@5: 93.7500 (92.2521)  time: 0.3495  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [ 130/4579]  eta: 0:26:08  Lr: 0.001875  Loss: -0.3052  Acc@1: 62.5000 (66.5076)  Acc@5: 93.7500 (91.9847)  time: 0.3514  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [ 140/4579]  eta: 0:26:03  Lr: 0.001875  Loss: -0.1175  Acc@1: 62.5000 (66.4450)  Acc@5: 93.7500 (92.1099)  time: 0.3497  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [ 150/4579]  eta: 0:25:59  Lr: 0.001875  Loss: 0.4452  Acc@1: 56.2500 (66.0596)  Acc@5: 93.7500 (92.1772)  time: 0.3490  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [ 160/4579]  eta: 0:25:55  Lr: 0.001875  Loss: -0.4018  Acc@1: 62.5000 (66.0326)  Acc@5: 93.7500 (92.1196)  time: 0.3512  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [ 170/4579]  eta: 0:25:51  Lr: 0.001875  Loss: -0.5029  Acc@1: 62.5000 (66.2646)  Acc@5: 93.7500 (92.1053)  time: 0.3506  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [ 180/4579]  eta: 0:25:47  Lr: 0.001875  Loss: 0.1920  Acc@1: 62.5000 (66.0221)  Acc@5: 87.5000 (91.8508)  time: 0.3490  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [ 190/4579]  eta: 0:25:44  Lr: 0.001875  Loss: 0.5742  Acc@1: 62.5000 (66.0995)  Acc@5: 87.5000 (91.8848)  time: 0.3507  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [ 200/4579]  eta: 0:25:40  Lr: 0.001875  Loss: -0.1552  Acc@1: 62.5000 (65.9515)  Acc@5: 93.7500 (91.7910)  time: 0.3527  data: 0.0011  max mem: 2500
Train: Epoch[5/5]  [ 210/4579]  eta: 0:25:36  Lr: 0.001875  Loss: 0.1213  Acc@1: 62.5000 (65.7879)  Acc@5: 93.7500 (91.7358)  time: 0.3511  data: 0.0012  max mem: 2500
Train: Epoch[5/5]  [ 220/4579]  eta: 0:25:32  Lr: 0.001875  Loss: -0.3192  Acc@1: 62.5000 (65.7240)  Acc@5: 87.5000 (91.6572)  time: 0.3497  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [ 230/4579]  eta: 0:25:29  Lr: 0.001875  Loss: 0.2229  Acc@1: 62.5000 (65.7738)  Acc@5: 93.7500 (91.6667)  time: 0.3505  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [ 240/4579]  eta: 0:25:25  Lr: 0.001875  Loss: -0.4079  Acc@1: 68.7500 (65.9232)  Acc@5: 93.7500 (91.6494)  time: 0.3506  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [ 250/4579]  eta: 0:25:21  Lr: 0.001875  Loss: -0.3521  Acc@1: 68.7500 (66.1604)  Acc@5: 93.7500 (91.8078)  time: 0.3509  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [ 260/4579]  eta: 0:25:18  Lr: 0.001875  Loss: -0.3582  Acc@1: 68.7500 (66.2356)  Acc@5: 93.7500 (91.8103)  time: 0.3509  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [ 270/4579]  eta: 0:25:14  Lr: 0.001875  Loss: -0.6856  Acc@1: 68.7500 (66.3745)  Acc@5: 93.7500 (91.8589)  time: 0.3511  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [ 280/4579]  eta: 0:25:11  Lr: 0.001875  Loss: -0.3418  Acc@1: 68.7500 (66.2811)  Acc@5: 93.7500 (91.7927)  time: 0.3514  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [ 290/4579]  eta: 0:25:08  Lr: 0.001875  Loss: -0.5284  Acc@1: 62.5000 (66.2586)  Acc@5: 93.7500 (91.8600)  time: 0.3535  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [ 300/4579]  eta: 0:25:04  Lr: 0.001875  Loss: -0.2113  Acc@1: 68.7500 (66.4452)  Acc@5: 93.7500 (92.0266)  time: 0.3539  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [ 310/4579]  eta: 0:25:00  Lr: 0.001875  Loss: -0.5117  Acc@1: 68.7500 (66.5394)  Acc@5: 93.7500 (92.0016)  time: 0.3504  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [ 320/4579]  eta: 0:24:57  Lr: 0.001875  Loss: -0.0795  Acc@1: 68.7500 (66.5693)  Acc@5: 87.5000 (91.8808)  time: 0.3526  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [ 330/4579]  eta: 0:24:54  Lr: 0.001875  Loss: 0.2282  Acc@1: 68.7500 (66.5030)  Acc@5: 87.5000 (91.8618)  time: 0.3526  data: 0.0014  max mem: 2500
Train: Epoch[5/5]  [ 340/4579]  eta: 0:24:50  Lr: 0.001875  Loss: -0.7525  Acc@1: 62.5000 (66.3490)  Acc@5: 93.7500 (91.8255)  time: 0.3520  data: 0.0028  max mem: 2500
Train: Epoch[5/5]  [ 350/4579]  eta: 0:24:47  Lr: 0.001875  Loss: -0.0704  Acc@1: 62.5000 (66.2393)  Acc@5: 93.7500 (91.7913)  time: 0.3520  data: 0.0020  max mem: 2500
Train: Epoch[5/5]  [ 360/4579]  eta: 0:24:43  Lr: 0.001875  Loss: -0.2625  Acc@1: 68.7500 (66.2569)  Acc@5: 93.7500 (91.7071)  time: 0.3490  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [ 370/4579]  eta: 0:24:39  Lr: 0.001875  Loss: -0.2428  Acc@1: 62.5000 (66.0377)  Acc@5: 87.5000 (91.6779)  time: 0.3485  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [ 380/4579]  eta: 0:24:35  Lr: 0.001875  Loss: -0.0976  Acc@1: 62.5000 (66.1089)  Acc@5: 93.7500 (91.6831)  time: 0.3496  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [ 390/4579]  eta: 0:24:32  Lr: 0.001875  Loss: -0.1444  Acc@1: 62.5000 (65.8728)  Acc@5: 93.7500 (91.6560)  time: 0.3506  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [ 400/4579]  eta: 0:24:28  Lr: 0.001875  Loss: -0.9983  Acc@1: 62.5000 (65.9133)  Acc@5: 93.7500 (91.6771)  time: 0.3496  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [ 410/4579]  eta: 0:24:24  Lr: 0.001875  Loss: -0.0815  Acc@1: 68.7500 (65.9672)  Acc@5: 93.7500 (91.6058)  time: 0.3500  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [ 420/4579]  eta: 0:24:21  Lr: 0.001875  Loss: -0.5721  Acc@1: 68.7500 (65.9293)  Acc@5: 87.5000 (91.5677)  time: 0.3520  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [ 430/4579]  eta: 0:24:17  Lr: 0.001875  Loss: -0.6624  Acc@1: 68.7500 (66.0818)  Acc@5: 93.7500 (91.5748)  time: 0.3517  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [ 440/4579]  eta: 0:24:14  Lr: 0.001875  Loss: -0.0195  Acc@1: 68.7500 (66.0431)  Acc@5: 93.7500 (91.5816)  time: 0.3512  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [ 450/4579]  eta: 0:24:10  Lr: 0.001875  Loss: -0.5828  Acc@1: 68.7500 (66.2278)  Acc@5: 93.7500 (91.6574)  time: 0.3496  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [ 460/4579]  eta: 0:24:06  Lr: 0.001875  Loss: -0.4123  Acc@1: 68.7500 (66.2419)  Acc@5: 93.7500 (91.6486)  time: 0.3482  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [ 470/4579]  eta: 0:24:03  Lr: 0.001875  Loss: -0.3881  Acc@1: 62.5000 (66.2022)  Acc@5: 93.7500 (91.6269)  time: 0.3496  data: 0.0015  max mem: 2500
Train: Epoch[5/5]  [ 480/4579]  eta: 0:23:59  Lr: 0.001875  Loss: 0.2175  Acc@1: 62.5000 (66.1512)  Acc@5: 93.7500 (91.6450)  time: 0.3509  data: 0.0016  max mem: 2500
Train: Epoch[5/5]  [ 490/4579]  eta: 0:23:56  Lr: 0.001875  Loss: 0.0712  Acc@1: 62.5000 (66.1278)  Acc@5: 93.7500 (91.6242)  time: 0.3499  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [ 500/4579]  eta: 0:23:52  Lr: 0.001875  Loss: -0.2456  Acc@1: 68.7500 (66.0679)  Acc@5: 87.5000 (91.5793)  time: 0.3509  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [ 510/4579]  eta: 0:23:49  Lr: 0.001875  Loss: -0.1654  Acc@1: 56.2500 (65.8880)  Acc@5: 87.5000 (91.5362)  time: 0.3515  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [ 520/4579]  eta: 0:23:45  Lr: 0.001875  Loss: -0.3404  Acc@1: 56.2500 (65.8229)  Acc@5: 93.7500 (91.5787)  time: 0.3506  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [ 530/4579]  eta: 0:23:42  Lr: 0.001875  Loss: 0.2681  Acc@1: 56.2500 (65.7721)  Acc@5: 93.7500 (91.5607)  time: 0.3521  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [ 540/4579]  eta: 0:23:38  Lr: 0.001875  Loss: -0.3190  Acc@1: 56.2500 (65.6192)  Acc@5: 87.5000 (91.5434)  time: 0.3523  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [ 550/4579]  eta: 0:23:35  Lr: 0.001875  Loss: -0.5039  Acc@1: 62.5000 (65.5966)  Acc@5: 87.5000 (91.5608)  time: 0.3514  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [ 560/4579]  eta: 0:23:31  Lr: 0.001875  Loss: -0.3536  Acc@1: 68.7500 (65.6306)  Acc@5: 93.7500 (91.5998)  time: 0.3511  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [ 570/4579]  eta: 0:23:28  Lr: 0.001875  Loss: -0.1941  Acc@1: 62.5000 (65.5867)  Acc@5: 93.7500 (91.6265)  time: 0.3515  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [ 580/4579]  eta: 0:23:24  Lr: 0.001875  Loss: -0.5334  Acc@1: 62.5000 (65.5228)  Acc@5: 93.7500 (91.6201)  time: 0.3494  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [ 590/4579]  eta: 0:23:20  Lr: 0.001875  Loss: -0.1699  Acc@1: 56.2500 (65.3342)  Acc@5: 93.7500 (91.5926)  time: 0.3497  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [ 600/4579]  eta: 0:23:17  Lr: 0.001875  Loss: -0.3802  Acc@1: 56.2500 (65.3702)  Acc@5: 93.7500 (91.5245)  time: 0.3514  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [ 610/4579]  eta: 0:23:13  Lr: 0.001875  Loss: -0.3875  Acc@1: 68.7500 (65.3642)  Acc@5: 87.5000 (91.5098)  time: 0.3509  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [ 620/4579]  eta: 0:23:10  Lr: 0.001875  Loss: -0.7372  Acc@1: 62.5000 (65.3885)  Acc@5: 93.7500 (91.5258)  time: 0.3497  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [ 630/4579]  eta: 0:23:06  Lr: 0.001875  Loss: -0.1968  Acc@1: 68.7500 (65.3724)  Acc@5: 93.7500 (91.5313)  time: 0.3505  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [ 640/4579]  eta: 0:23:03  Lr: 0.001875  Loss: 0.1954  Acc@1: 68.7500 (65.4641)  Acc@5: 93.7500 (91.5757)  time: 0.3503  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [ 650/4579]  eta: 0:22:59  Lr: 0.001875  Loss: -0.2814  Acc@1: 75.0000 (65.5338)  Acc@5: 93.7500 (91.6091)  time: 0.3483  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [ 660/4579]  eta: 0:22:55  Lr: 0.001875  Loss: -0.3478  Acc@1: 68.7500 (65.5352)  Acc@5: 93.7500 (91.5847)  time: 0.3484  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [ 670/4579]  eta: 0:22:52  Lr: 0.001875  Loss: -0.2523  Acc@1: 68.7500 (65.6297)  Acc@5: 93.7500 (91.5984)  time: 0.3493  data: 0.0010  max mem: 2500
Train: Epoch[5/5]  [ 680/4579]  eta: 0:22:48  Lr: 0.001875  Loss: -0.5460  Acc@1: 68.7500 (65.6296)  Acc@5: 93.7500 (91.5565)  time: 0.3497  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [ 690/4579]  eta: 0:22:45  Lr: 0.001875  Loss: -0.1187  Acc@1: 62.5000 (65.5843)  Acc@5: 87.5000 (91.4797)  time: 0.3504  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [ 700/4579]  eta: 0:22:41  Lr: 0.001875  Loss: -0.0255  Acc@1: 62.5000 (65.5938)  Acc@5: 87.5000 (91.5121)  time: 0.3503  data: 0.0010  max mem: 2500
Train: Epoch[5/5]  [ 710/4579]  eta: 0:22:37  Lr: 0.001875  Loss: -0.4438  Acc@1: 62.5000 (65.5503)  Acc@5: 93.7500 (91.5172)  time: 0.3490  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [ 720/4579]  eta: 0:22:34  Lr: 0.001875  Loss: 0.0173  Acc@1: 62.5000 (65.5340)  Acc@5: 93.7500 (91.5222)  time: 0.3503  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [ 730/4579]  eta: 0:22:30  Lr: 0.001875  Loss: 0.0199  Acc@1: 62.5000 (65.5523)  Acc@5: 93.7500 (91.5185)  time: 0.3507  data: 0.0011  max mem: 2500
Train: Epoch[5/5]  [ 740/4579]  eta: 0:22:27  Lr: 0.001875  Loss: -0.5257  Acc@1: 68.7500 (65.6461)  Acc@5: 93.7500 (91.5570)  time: 0.3497  data: 0.0011  max mem: 2500
Train: Epoch[5/5]  [ 750/4579]  eta: 0:22:23  Lr: 0.001875  Loss: -0.1992  Acc@1: 68.7500 (65.6625)  Acc@5: 93.7500 (91.5779)  time: 0.3491  data: 0.0011  max mem: 2500
Train: Epoch[5/5]  [ 760/4579]  eta: 0:22:20  Lr: 0.001875  Loss: 0.0863  Acc@1: 62.5000 (65.6784)  Acc@5: 93.7500 (91.5900)  time: 0.3503  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [ 770/4579]  eta: 0:22:16  Lr: 0.001875  Loss: -0.6634  Acc@1: 62.5000 (65.6939)  Acc@5: 93.7500 (91.6099)  time: 0.3529  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [ 780/4579]  eta: 0:22:13  Lr: 0.001875  Loss: 0.2567  Acc@1: 68.7500 (65.7730)  Acc@5: 93.7500 (91.6213)  time: 0.3546  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [ 790/4579]  eta: 0:22:09  Lr: 0.001875  Loss: -0.1432  Acc@1: 68.7500 (65.7396)  Acc@5: 93.7500 (91.6008)  time: 0.3531  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [ 800/4579]  eta: 0:22:06  Lr: 0.001875  Loss: 0.2995  Acc@1: 62.5000 (65.7303)  Acc@5: 93.7500 (91.6120)  time: 0.3514  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [ 810/4579]  eta: 0:22:03  Lr: 0.001875  Loss: -0.0625  Acc@1: 62.5000 (65.6751)  Acc@5: 93.7500 (91.5845)  time: 0.3520  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [ 820/4579]  eta: 0:21:59  Lr: 0.001875  Loss: -0.9722  Acc@1: 62.5000 (65.6897)  Acc@5: 87.5000 (91.5347)  time: 0.3536  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [ 830/4579]  eta: 0:21:56  Lr: 0.001875  Loss: -0.5928  Acc@1: 68.7500 (65.7040)  Acc@5: 93.7500 (91.5539)  time: 0.3526  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [ 840/4579]  eta: 0:21:52  Lr: 0.001875  Loss: -0.8127  Acc@1: 68.7500 (65.7105)  Acc@5: 93.7500 (91.5354)  time: 0.3521  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [ 850/4579]  eta: 0:21:49  Lr: 0.001875  Loss: -0.5534  Acc@1: 68.7500 (65.7462)  Acc@5: 93.7500 (91.5687)  time: 0.3521  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [ 860/4579]  eta: 0:21:45  Lr: 0.001875  Loss: -0.4456  Acc@1: 68.7500 (65.7883)  Acc@5: 93.7500 (91.6086)  time: 0.3509  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [ 870/4579]  eta: 0:21:42  Lr: 0.001875  Loss: -0.4158  Acc@1: 62.5000 (65.7147)  Acc@5: 93.7500 (91.6260)  time: 0.3521  data: 0.0013  max mem: 2500
Train: Epoch[5/5]  [ 880/4579]  eta: 0:21:38  Lr: 0.001875  Loss: 0.6122  Acc@1: 56.2500 (65.6285)  Acc@5: 93.7500 (91.5792)  time: 0.3514  data: 0.0013  max mem: 2500
Train: Epoch[5/5]  [ 890/4579]  eta: 0:21:35  Lr: 0.001875  Loss: -0.6759  Acc@1: 62.5000 (65.6987)  Acc@5: 87.5000 (91.5544)  time: 0.3488  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [ 900/4579]  eta: 0:21:31  Lr: 0.001875  Loss: 0.3681  Acc@1: 62.5000 (65.6215)  Acc@5: 87.5000 (91.5302)  time: 0.3480  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [ 910/4579]  eta: 0:21:27  Lr: 0.001875  Loss: -0.4660  Acc@1: 68.7500 (65.6833)  Acc@5: 93.7500 (91.5889)  time: 0.3496  data: 0.0010  max mem: 2500
Train: Epoch[5/5]  [ 920/4579]  eta: 0:21:24  Lr: 0.001875  Loss: -0.1239  Acc@1: 68.7500 (65.6623)  Acc@5: 93.7500 (91.5852)  time: 0.3499  data: 0.0011  max mem: 2500
Train: Epoch[5/5]  [ 930/4579]  eta: 0:21:20  Lr: 0.001875  Loss: -0.3557  Acc@1: 68.7500 (65.7626)  Acc@5: 93.7500 (91.6152)  time: 0.3500  data: 0.0010  max mem: 2500
Train: Epoch[5/5]  [ 940/4579]  eta: 0:21:17  Lr: 0.001875  Loss: -0.0022  Acc@1: 68.7500 (65.7279)  Acc@5: 93.7500 (91.6113)  time: 0.3512  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [ 950/4579]  eta: 0:21:13  Lr: 0.001875  Loss: 0.3227  Acc@1: 62.5000 (65.6940)  Acc@5: 87.5000 (91.5878)  time: 0.3502  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [ 960/4579]  eta: 0:21:10  Lr: 0.001875  Loss: -0.8600  Acc@1: 68.7500 (65.7323)  Acc@5: 93.7500 (91.6103)  time: 0.3502  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [ 970/4579]  eta: 0:21:06  Lr: 0.001875  Loss: -0.6317  Acc@1: 62.5000 (65.7119)  Acc@5: 93.7500 (91.5551)  time: 0.3495  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [ 980/4579]  eta: 0:21:03  Lr: 0.001875  Loss: -0.4951  Acc@1: 62.5000 (65.7238)  Acc@5: 93.7500 (91.5711)  time: 0.3489  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [ 990/4579]  eta: 0:20:59  Lr: 0.001875  Loss: -0.1220  Acc@1: 62.5000 (65.6975)  Acc@5: 93.7500 (91.5616)  time: 0.3500  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [1000/4579]  eta: 0:20:55  Lr: 0.001875  Loss: -0.2540  Acc@1: 62.5000 (65.6968)  Acc@5: 93.7500 (91.5522)  time: 0.3501  data: 0.0010  max mem: 2500
Train: Epoch[5/5]  [1010/4579]  eta: 0:20:52  Lr: 0.001875  Loss: -0.1755  Acc@1: 68.7500 (65.7208)  Acc@5: 93.7500 (91.5492)  time: 0.3490  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [1020/4579]  eta: 0:20:48  Lr: 0.001875  Loss: -0.4336  Acc@1: 62.5000 (65.7138)  Acc@5: 93.7500 (91.5646)  time: 0.3488  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [1030/4579]  eta: 0:20:45  Lr: 0.001875  Loss: 0.0150  Acc@1: 62.5000 (65.7068)  Acc@5: 93.7500 (91.5616)  time: 0.3512  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [1040/4579]  eta: 0:20:41  Lr: 0.001875  Loss: 0.2309  Acc@1: 62.5000 (65.6700)  Acc@5: 87.5000 (91.5286)  time: 0.3519  data: 0.0011  max mem: 2500
Train: Epoch[5/5]  [1050/4579]  eta: 0:20:38  Lr: 0.001875  Loss: -0.7778  Acc@1: 62.5000 (65.6696)  Acc@5: 87.5000 (91.5319)  time: 0.3503  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [1060/4579]  eta: 0:20:34  Lr: 0.001875  Loss: 0.0862  Acc@1: 68.7500 (65.7104)  Acc@5: 93.7500 (91.5528)  time: 0.3520  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [1070/4579]  eta: 0:20:31  Lr: 0.001875  Loss: -0.4814  Acc@1: 68.7500 (65.7972)  Acc@5: 93.7500 (91.5850)  time: 0.3514  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [1080/4579]  eta: 0:20:27  Lr: 0.001875  Loss: -0.2385  Acc@1: 68.7500 (65.8534)  Acc@5: 93.7500 (91.5819)  time: 0.3519  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [1090/4579]  eta: 0:20:24  Lr: 0.001875  Loss: -0.5171  Acc@1: 68.7500 (65.8570)  Acc@5: 93.7500 (91.5788)  time: 0.3519  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [1100/4579]  eta: 0:20:20  Lr: 0.001875  Loss: -0.3758  Acc@1: 68.7500 (65.8776)  Acc@5: 93.7500 (91.5588)  time: 0.3516  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1110/4579]  eta: 0:20:17  Lr: 0.001875  Loss: -0.2372  Acc@1: 68.7500 (65.9653)  Acc@5: 93.7500 (91.5729)  time: 0.3522  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1120/4579]  eta: 0:20:13  Lr: 0.001875  Loss: -0.6398  Acc@1: 68.7500 (65.9846)  Acc@5: 93.7500 (91.5979)  time: 0.3499  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [1130/4579]  eta: 0:20:10  Lr: 0.001875  Loss: 0.0327  Acc@1: 62.5000 (65.9427)  Acc@5: 93.7500 (91.6169)  time: 0.3497  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [1140/4579]  eta: 0:20:06  Lr: 0.001875  Loss: -0.4657  Acc@1: 68.7500 (66.0167)  Acc@5: 93.7500 (91.6521)  time: 0.3505  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [1150/4579]  eta: 0:20:03  Lr: 0.001875  Loss: -0.5438  Acc@1: 68.7500 (66.0132)  Acc@5: 93.7500 (91.6594)  time: 0.3523  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [1160/4579]  eta: 0:19:59  Lr: 0.001875  Loss: -0.0873  Acc@1: 62.5000 (65.9292)  Acc@5: 87.5000 (91.6398)  time: 0.3518  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [1170/4579]  eta: 0:19:56  Lr: 0.001875  Loss: -0.4653  Acc@1: 62.5000 (65.9372)  Acc@5: 87.5000 (91.6364)  time: 0.3510  data: 0.0012  max mem: 2500
Train: Epoch[5/5]  [1180/4579]  eta: 0:19:52  Lr: 0.001875  Loss: -0.5570  Acc@1: 68.7500 (66.0087)  Acc@5: 93.7500 (91.6543)  time: 0.3515  data: 0.0011  max mem: 2500
Train: Epoch[5/5]  [1190/4579]  eta: 0:19:49  Lr: 0.001875  Loss: -0.0346  Acc@1: 62.5000 (65.9477)  Acc@5: 93.7500 (91.6719)  time: 0.3503  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [1200/4579]  eta: 0:19:45  Lr: 0.001875  Loss: -0.3148  Acc@1: 62.5000 (65.9763)  Acc@5: 93.7500 (91.6840)  time: 0.3499  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [1210/4579]  eta: 0:19:42  Lr: 0.001875  Loss: 0.4834  Acc@1: 68.7500 (65.9579)  Acc@5: 93.7500 (91.6908)  time: 0.3501  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [1220/4579]  eta: 0:19:38  Lr: 0.001875  Loss: -0.1429  Acc@1: 62.5000 (65.9500)  Acc@5: 87.5000 (91.6462)  time: 0.3495  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [1230/4579]  eta: 0:19:35  Lr: 0.001875  Loss: -0.2822  Acc@1: 68.7500 (65.9728)  Acc@5: 87.5000 (91.6684)  time: 0.3508  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [1240/4579]  eta: 0:19:31  Lr: 0.001875  Loss: -0.5218  Acc@1: 68.7500 (66.0002)  Acc@5: 93.7500 (91.6851)  time: 0.3525  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [1250/4579]  eta: 0:19:28  Lr: 0.001875  Loss: -0.7214  Acc@1: 68.7500 (65.9572)  Acc@5: 93.7500 (91.6617)  time: 0.3504  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [1260/4579]  eta: 0:19:24  Lr: 0.001875  Loss: -0.7190  Acc@1: 62.5000 (65.9843)  Acc@5: 93.7500 (91.6782)  time: 0.3507  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [1270/4579]  eta: 0:19:21  Lr: 0.001875  Loss: -0.4258  Acc@1: 68.7500 (65.9913)  Acc@5: 93.7500 (91.6945)  time: 0.3521  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [1280/4579]  eta: 0:19:17  Lr: 0.001875  Loss: -0.4564  Acc@1: 68.7500 (65.9543)  Acc@5: 93.7500 (91.6959)  time: 0.3519  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1290/4579]  eta: 0:19:14  Lr: 0.001875  Loss: -0.1312  Acc@1: 68.7500 (65.9857)  Acc@5: 93.7500 (91.7167)  time: 0.3506  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1300/4579]  eta: 0:19:10  Lr: 0.001875  Loss: 0.3871  Acc@1: 75.0000 (66.0261)  Acc@5: 93.7500 (91.7419)  time: 0.3486  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [1310/4579]  eta: 0:19:07  Lr: 0.001875  Loss: -0.5813  Acc@1: 75.0000 (66.0612)  Acc@5: 93.7500 (91.7429)  time: 0.3506  data: 0.0013  max mem: 2500
Train: Epoch[5/5]  [1320/4579]  eta: 0:19:03  Lr: 0.001875  Loss: -0.4653  Acc@1: 68.7500 (66.0579)  Acc@5: 93.7500 (91.7487)  time: 0.3522  data: 0.0020  max mem: 2500
Train: Epoch[5/5]  [1330/4579]  eta: 0:19:00  Lr: 0.001875  Loss: -0.1871  Acc@1: 68.7500 (66.0594)  Acc@5: 93.7500 (91.7496)  time: 0.3504  data: 0.0014  max mem: 2500
Train: Epoch[5/5]  [1340/4579]  eta: 0:18:56  Lr: 0.001875  Loss: -0.1957  Acc@1: 68.7500 (66.0561)  Acc@5: 87.5000 (91.7412)  time: 0.3490  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [1350/4579]  eta: 0:18:53  Lr: 0.001875  Loss: -0.1288  Acc@1: 62.5000 (66.0344)  Acc@5: 93.7500 (91.7376)  time: 0.3513  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [1360/4579]  eta: 0:18:49  Lr: 0.001875  Loss: -0.8898  Acc@1: 68.7500 (66.0819)  Acc@5: 93.7500 (91.7662)  time: 0.3547  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [1370/4579]  eta: 0:18:46  Lr: 0.001875  Loss: -0.3106  Acc@1: 68.7500 (66.0786)  Acc@5: 93.7500 (91.7533)  time: 0.3524  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [1380/4579]  eta: 0:18:42  Lr: 0.001875  Loss: -0.2949  Acc@1: 68.7500 (66.1477)  Acc@5: 93.7500 (91.7768)  time: 0.3485  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [1390/4579]  eta: 0:18:39  Lr: 0.001875  Loss: -0.6775  Acc@1: 68.7500 (66.1350)  Acc@5: 93.7500 (91.7730)  time: 0.3487  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [1400/4579]  eta: 0:18:35  Lr: 0.001875  Loss: -0.4466  Acc@1: 62.5000 (66.1358)  Acc@5: 93.7500 (91.7737)  time: 0.3488  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [1410/4579]  eta: 0:18:31  Lr: 0.001875  Loss: -0.1810  Acc@1: 62.5000 (66.1366)  Acc@5: 93.7500 (91.7745)  time: 0.3493  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [1420/4579]  eta: 0:18:28  Lr: 0.001875  Loss: -0.1009  Acc@1: 68.7500 (66.1330)  Acc@5: 93.7500 (91.7488)  time: 0.3507  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [1430/4579]  eta: 0:18:24  Lr: 0.001875  Loss: -0.4573  Acc@1: 62.5000 (66.1032)  Acc@5: 93.7500 (91.7540)  time: 0.3505  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [1440/4579]  eta: 0:18:21  Lr: 0.001875  Loss: -0.4541  Acc@1: 62.5000 (66.1476)  Acc@5: 93.7500 (91.7809)  time: 0.3491  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [1450/4579]  eta: 0:18:17  Lr: 0.001875  Loss: -0.5897  Acc@1: 68.7500 (66.1613)  Acc@5: 93.7500 (91.7945)  time: 0.3509  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [1460/4579]  eta: 0:18:14  Lr: 0.001875  Loss: 0.0782  Acc@1: 62.5000 (66.1405)  Acc@5: 93.7500 (91.7822)  time: 0.3525  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [1470/4579]  eta: 0:18:10  Lr: 0.001875  Loss: -0.4192  Acc@1: 62.5000 (66.1115)  Acc@5: 93.7500 (91.7701)  time: 0.3519  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [1480/4579]  eta: 0:18:07  Lr: 0.001875  Loss: -0.7057  Acc@1: 68.7500 (66.1884)  Acc@5: 93.7500 (91.7876)  time: 0.3515  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [1490/4579]  eta: 0:18:03  Lr: 0.001875  Loss: -0.4600  Acc@1: 75.0000 (66.1972)  Acc@5: 93.7500 (91.7840)  time: 0.3505  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [1500/4579]  eta: 0:18:00  Lr: 0.001875  Loss: -0.4603  Acc@1: 68.7500 (66.2017)  Acc@5: 93.7500 (91.7888)  time: 0.3494  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [1510/4579]  eta: 0:17:56  Lr: 0.001875  Loss: -0.3571  Acc@1: 62.5000 (66.1772)  Acc@5: 93.7500 (91.8018)  time: 0.3493  data: 0.0011  max mem: 2500
Train: Epoch[5/5]  [1520/4579]  eta: 0:17:53  Lr: 0.001875  Loss: 0.2776  Acc@1: 62.5000 (66.1941)  Acc@5: 93.7500 (91.7982)  time: 0.3495  data: 0.0011  max mem: 2500
Train: Epoch[5/5]  [1530/4579]  eta: 0:17:49  Lr: 0.001875  Loss: -0.2481  Acc@1: 68.7500 (66.2067)  Acc@5: 93.7500 (91.8109)  time: 0.3484  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [1540/4579]  eta: 0:17:46  Lr: 0.001875  Loss: -0.6081  Acc@1: 75.0000 (66.2516)  Acc@5: 93.7500 (91.8194)  time: 0.3476  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [1550/4579]  eta: 0:17:42  Lr: 0.001875  Loss: -0.3014  Acc@1: 75.0000 (66.2637)  Acc@5: 93.7500 (91.8319)  time: 0.3496  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [1560/4579]  eta: 0:17:39  Lr: 0.001875  Loss: 0.0124  Acc@1: 62.5000 (66.2276)  Acc@5: 93.7500 (91.8121)  time: 0.3501  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [1570/4579]  eta: 0:17:35  Lr: 0.001875  Loss: -0.0041  Acc@1: 62.5000 (66.1800)  Acc@5: 87.5000 (91.8046)  time: 0.3484  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [1580/4579]  eta: 0:17:31  Lr: 0.001875  Loss: -0.2295  Acc@1: 62.5000 (66.1725)  Acc@5: 93.7500 (91.8129)  time: 0.3486  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [1590/4579]  eta: 0:17:28  Lr: 0.001875  Loss: 0.1380  Acc@1: 62.5000 (66.1023)  Acc@5: 93.7500 (91.8094)  time: 0.3492  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [1600/4579]  eta: 0:17:24  Lr: 0.001875  Loss: 0.2106  Acc@1: 62.5000 (66.0876)  Acc@5: 87.5000 (91.7942)  time: 0.3484  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [1610/4579]  eta: 0:17:21  Lr: 0.001875  Loss: -0.4064  Acc@1: 62.5000 (66.0925)  Acc@5: 93.7500 (91.8180)  time: 0.3501  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [1620/4579]  eta: 0:17:17  Lr: 0.001875  Loss: -0.4199  Acc@1: 68.7500 (66.0973)  Acc@5: 93.7500 (91.8145)  time: 0.3514  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [1630/4579]  eta: 0:17:14  Lr: 0.001875  Loss: 0.2600  Acc@1: 62.5000 (66.0714)  Acc@5: 93.7500 (91.8072)  time: 0.3522  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [1640/4579]  eta: 0:17:10  Lr: 0.001875  Loss: -0.5878  Acc@1: 62.5000 (66.0763)  Acc@5: 93.7500 (91.8190)  time: 0.3516  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [1650/4579]  eta: 0:17:07  Lr: 0.001875  Loss: -0.7010  Acc@1: 68.7500 (66.1114)  Acc@5: 93.7500 (91.8459)  time: 0.3504  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [1660/4579]  eta: 0:17:03  Lr: 0.001875  Loss: 0.0718  Acc@1: 68.7500 (66.1010)  Acc@5: 93.7500 (91.8423)  time: 0.3533  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [1670/4579]  eta: 0:17:00  Lr: 0.001875  Loss: -0.5207  Acc@1: 68.7500 (66.1094)  Acc@5: 93.7500 (91.8350)  time: 0.3523  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [1680/4579]  eta: 0:16:57  Lr: 0.001875  Loss: -0.5605  Acc@1: 68.7500 (66.1214)  Acc@5: 93.7500 (91.8612)  time: 0.3516  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [1690/4579]  eta: 0:16:53  Lr: 0.001875  Loss: -0.1020  Acc@1: 68.7500 (66.1073)  Acc@5: 93.7500 (91.8650)  time: 0.3518  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [1700/4579]  eta: 0:16:49  Lr: 0.001875  Loss: -0.3535  Acc@1: 62.5000 (66.1008)  Acc@5: 93.7500 (91.8724)  time: 0.3490  data: 0.0012  max mem: 2500
Train: Epoch[5/5]  [1710/4579]  eta: 0:16:46  Lr: 0.001875  Loss: -0.4730  Acc@1: 68.7500 (66.1127)  Acc@5: 93.7500 (91.8724)  time: 0.3487  data: 0.0014  max mem: 2500
Train: Epoch[5/5]  [1720/4579]  eta: 0:16:42  Lr: 0.001875  Loss: -0.1908  Acc@1: 62.5000 (66.1026)  Acc@5: 93.7500 (91.8906)  time: 0.3498  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [1730/4579]  eta: 0:16:39  Lr: 0.001875  Loss: 0.2719  Acc@1: 62.5000 (66.0709)  Acc@5: 87.5000 (91.8580)  time: 0.3511  data: 0.0014  max mem: 2500
Train: Epoch[5/5]  [1740/4579]  eta: 0:16:35  Lr: 0.001875  Loss: -0.0136  Acc@1: 62.5000 (66.0863)  Acc@5: 87.5000 (91.8617)  time: 0.3501  data: 0.0014  max mem: 2500
Train: Epoch[5/5]  [1750/4579]  eta: 0:16:32  Lr: 0.001875  Loss: -0.5100  Acc@1: 68.7500 (66.1015)  Acc@5: 93.7500 (91.8618)  time: 0.3488  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [1760/4579]  eta: 0:16:28  Lr: 0.001875  Loss: -0.3478  Acc@1: 68.7500 (66.0988)  Acc@5: 93.7500 (91.8619)  time: 0.3497  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [1770/4579]  eta: 0:16:25  Lr: 0.001875  Loss: -0.3789  Acc@1: 68.7500 (66.0820)  Acc@5: 93.7500 (91.8725)  time: 0.3493  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [1780/4579]  eta: 0:16:21  Lr: 0.001875  Loss: -0.1796  Acc@1: 68.7500 (66.1040)  Acc@5: 93.7500 (91.8901)  time: 0.3494  data: 0.0015  max mem: 2500
Train: Epoch[5/5]  [1790/4579]  eta: 0:16:18  Lr: 0.001875  Loss: -0.2930  Acc@1: 68.7500 (66.0839)  Acc@5: 93.7500 (91.8935)  time: 0.3494  data: 0.0013  max mem: 2500
Train: Epoch[5/5]  [1800/4579]  eta: 0:16:14  Lr: 0.001875  Loss: 0.0030  Acc@1: 62.5000 (66.0779)  Acc@5: 93.7500 (91.9073)  time: 0.3492  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [1810/4579]  eta: 0:16:11  Lr: 0.001875  Loss: -0.2983  Acc@1: 62.5000 (66.0581)  Acc@5: 93.7500 (91.9105)  time: 0.3522  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [1820/4579]  eta: 0:16:07  Lr: 0.001875  Loss: -0.2154  Acc@1: 68.7500 (66.0832)  Acc@5: 93.7500 (91.9172)  time: 0.3520  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [1830/4579]  eta: 0:16:04  Lr: 0.001875  Loss: -0.0906  Acc@1: 68.7500 (66.0943)  Acc@5: 93.7500 (91.9067)  time: 0.3502  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [1840/4579]  eta: 0:16:00  Lr: 0.001875  Loss: -0.4344  Acc@1: 68.7500 (66.1122)  Acc@5: 93.7500 (91.8964)  time: 0.3504  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [1850/4579]  eta: 0:15:57  Lr: 0.001875  Loss: -0.2605  Acc@1: 62.5000 (66.0758)  Acc@5: 93.7500 (91.8861)  time: 0.3517  data: 0.0010  max mem: 2500
Train: Epoch[5/5]  [1860/4579]  eta: 0:15:53  Lr: 0.001875  Loss: -0.4801  Acc@1: 62.5000 (66.1103)  Acc@5: 93.7500 (91.8928)  time: 0.3518  data: 0.0016  max mem: 2500
Train: Epoch[5/5]  [1870/4579]  eta: 0:15:50  Lr: 0.001875  Loss: -0.2573  Acc@1: 68.7500 (66.1277)  Acc@5: 93.7500 (91.9161)  time: 0.3500  data: 0.0011  max mem: 2500
Train: Epoch[5/5]  [1880/4579]  eta: 0:15:46  Lr: 0.001875  Loss: -0.7779  Acc@1: 68.7500 (66.1317)  Acc@5: 93.7500 (91.9258)  time: 0.3523  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [1890/4579]  eta: 0:15:43  Lr: 0.001875  Loss: -0.1957  Acc@1: 62.5000 (66.1191)  Acc@5: 93.7500 (91.9355)  time: 0.3517  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [1900/4579]  eta: 0:15:39  Lr: 0.001875  Loss: -0.3637  Acc@1: 62.5000 (66.1330)  Acc@5: 93.7500 (91.9483)  time: 0.3487  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [1910/4579]  eta: 0:15:36  Lr: 0.001875  Loss: -0.5601  Acc@1: 68.7500 (66.1336)  Acc@5: 93.7500 (91.9414)  time: 0.3486  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [1920/4579]  eta: 0:15:32  Lr: 0.001875  Loss: 0.3495  Acc@1: 68.7500 (66.1439)  Acc@5: 87.5000 (91.9345)  time: 0.3488  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [1930/4579]  eta: 0:15:29  Lr: 0.001875  Loss: -0.5347  Acc@1: 68.7500 (66.1315)  Acc@5: 93.7500 (91.9375)  time: 0.3509  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [1940/4579]  eta: 0:15:25  Lr: 0.001875  Loss: -0.2333  Acc@1: 62.5000 (66.1225)  Acc@5: 93.7500 (91.9532)  time: 0.3512  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [1950/4579]  eta: 0:15:22  Lr: 0.001875  Loss: -0.4240  Acc@1: 62.5000 (66.1231)  Acc@5: 93.7500 (91.9625)  time: 0.3493  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [1960/4579]  eta: 0:15:18  Lr: 0.001875  Loss: -0.2399  Acc@1: 68.7500 (66.1397)  Acc@5: 93.7500 (91.9716)  time: 0.3483  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [1970/4579]  eta: 0:15:14  Lr: 0.001875  Loss: -0.6197  Acc@1: 68.7500 (66.1466)  Acc@5: 93.7500 (91.9806)  time: 0.3491  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1980/4579]  eta: 0:15:11  Lr: 0.001875  Loss: -0.3512  Acc@1: 68.7500 (66.1471)  Acc@5: 93.7500 (91.9738)  time: 0.3499  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [1990/4579]  eta: 0:15:07  Lr: 0.001875  Loss: -0.5416  Acc@1: 68.7500 (66.1571)  Acc@5: 93.7500 (91.9795)  time: 0.3493  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [2000/4579]  eta: 0:15:04  Lr: 0.001875  Loss: -0.3105  Acc@1: 62.5000 (66.1388)  Acc@5: 93.7500 (91.9821)  time: 0.3491  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [2010/4579]  eta: 0:15:00  Lr: 0.001875  Loss: -0.0514  Acc@1: 68.7500 (66.1704)  Acc@5: 93.7500 (91.9909)  time: 0.3490  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [2020/4579]  eta: 0:14:57  Lr: 0.001875  Loss: -0.6436  Acc@1: 68.7500 (66.1863)  Acc@5: 93.7500 (92.0027)  time: 0.3508  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [2030/4579]  eta: 0:14:53  Lr: 0.001875  Loss: -0.1604  Acc@1: 68.7500 (66.1774)  Acc@5: 93.7500 (92.0206)  time: 0.3538  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [2040/4579]  eta: 0:14:50  Lr: 0.001875  Loss: 0.0604  Acc@1: 68.7500 (66.2175)  Acc@5: 93.7500 (92.0321)  time: 0.3529  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [2050/4579]  eta: 0:14:46  Lr: 0.001875  Loss: -0.6165  Acc@1: 68.7500 (66.1994)  Acc@5: 93.7500 (92.0405)  time: 0.3519  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [2060/4579]  eta: 0:14:43  Lr: 0.001875  Loss: -0.4888  Acc@1: 62.5000 (66.1997)  Acc@5: 93.7500 (92.0457)  time: 0.3507  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [2070/4579]  eta: 0:14:39  Lr: 0.001875  Loss: -0.5236  Acc@1: 62.5000 (66.1939)  Acc@5: 93.7500 (92.0359)  time: 0.3513  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [2080/4579]  eta: 0:14:36  Lr: 0.001875  Loss: -0.2794  Acc@1: 62.5000 (66.1941)  Acc@5: 93.7500 (92.0531)  time: 0.3521  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [2090/4579]  eta: 0:14:32  Lr: 0.001875  Loss: -0.7130  Acc@1: 68.7500 (66.2093)  Acc@5: 93.7500 (92.0493)  time: 0.3508  data: 0.0010  max mem: 2500
Train: Epoch[5/5]  [2100/4579]  eta: 0:14:29  Lr: 0.001875  Loss: -0.3029  Acc@1: 68.7500 (66.2214)  Acc@5: 93.7500 (92.0663)  time: 0.3503  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [2110/4579]  eta: 0:14:25  Lr: 0.001875  Loss: 1.1395  Acc@1: 68.7500 (66.1949)  Acc@5: 93.7500 (92.0506)  time: 0.3482  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [2120/4579]  eta: 0:14:22  Lr: 0.001875  Loss: -0.5300  Acc@1: 68.7500 (66.2188)  Acc@5: 93.7500 (92.0556)  time: 0.3479  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [2130/4579]  eta: 0:14:18  Lr: 0.001875  Loss: 0.2365  Acc@1: 68.7500 (66.2013)  Acc@5: 93.7500 (92.0607)  time: 0.3503  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [2140/4579]  eta: 0:14:15  Lr: 0.001875  Loss: -0.5485  Acc@1: 62.5000 (66.1986)  Acc@5: 87.5000 (92.0364)  time: 0.3517  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [2150/4579]  eta: 0:14:11  Lr: 0.001875  Loss: 0.0024  Acc@1: 68.7500 (66.1930)  Acc@5: 87.5000 (92.0328)  time: 0.3517  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [2160/4579]  eta: 0:14:08  Lr: 0.001875  Loss: -0.5622  Acc@1: 62.5000 (66.1904)  Acc@5: 93.7500 (92.0407)  time: 0.3509  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [2170/4579]  eta: 0:14:04  Lr: 0.001875  Loss: -0.0689  Acc@1: 68.7500 (66.1993)  Acc@5: 93.7500 (92.0400)  time: 0.3500  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2180/4579]  eta: 0:14:01  Lr: 0.001875  Loss: -0.0822  Acc@1: 68.7500 (66.1824)  Acc@5: 87.5000 (92.0392)  time: 0.3493  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [2190/4579]  eta: 0:13:57  Lr: 0.001875  Loss: 0.1765  Acc@1: 62.5000 (66.1741)  Acc@5: 93.7500 (92.0413)  time: 0.3487  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [2200/4579]  eta: 0:13:54  Lr: 0.001875  Loss: 0.0088  Acc@1: 62.5000 (66.1716)  Acc@5: 93.7500 (92.0405)  time: 0.3497  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [2210/4579]  eta: 0:13:50  Lr: 0.001875  Loss: -0.2032  Acc@1: 62.5000 (66.1465)  Acc@5: 87.5000 (92.0341)  time: 0.3515  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [2220/4579]  eta: 0:13:47  Lr: 0.001875  Loss: -0.1794  Acc@1: 62.5000 (66.1442)  Acc@5: 87.5000 (92.0334)  time: 0.3523  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [2230/4579]  eta: 0:13:43  Lr: 0.001875  Loss: -0.4843  Acc@1: 68.7500 (66.1419)  Acc@5: 87.5000 (92.0215)  time: 0.3530  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [2240/4579]  eta: 0:13:40  Lr: 0.001875  Loss: -0.5139  Acc@1: 62.5000 (66.1423)  Acc@5: 87.5000 (92.0320)  time: 0.3555  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [2250/4579]  eta: 0:13:36  Lr: 0.001875  Loss: 0.6942  Acc@1: 62.5000 (66.1151)  Acc@5: 93.7500 (92.0174)  time: 0.3540  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [2260/4579]  eta: 0:13:33  Lr: 0.001875  Loss: -0.6883  Acc@1: 62.5000 (66.1295)  Acc@5: 93.7500 (92.0223)  time: 0.3510  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [2270/4579]  eta: 0:13:29  Lr: 0.001875  Loss: -0.1043  Acc@1: 62.5000 (66.1328)  Acc@5: 93.7500 (92.0217)  time: 0.3527  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [2280/4579]  eta: 0:13:26  Lr: 0.001875  Loss: -0.2678  Acc@1: 62.5000 (66.1141)  Acc@5: 93.7500 (92.0210)  time: 0.3509  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [2290/4579]  eta: 0:13:22  Lr: 0.001875  Loss: 0.0541  Acc@1: 62.5000 (66.0874)  Acc@5: 87.5000 (92.0095)  time: 0.3510  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [2300/4579]  eta: 0:13:19  Lr: 0.001875  Loss: 0.2577  Acc@1: 62.5000 (66.0745)  Acc@5: 87.5000 (92.0035)  time: 0.3518  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [2310/4579]  eta: 0:13:15  Lr: 0.001875  Loss: -0.6832  Acc@1: 68.7500 (66.0942)  Acc@5: 93.7500 (92.0083)  time: 0.3483  data: 0.0015  max mem: 2500
Train: Epoch[5/5]  [2320/4579]  eta: 0:13:12  Lr: 0.001875  Loss: -0.8115  Acc@1: 75.0000 (66.1137)  Acc@5: 93.7500 (92.0158)  time: 0.3484  data: 0.0018  max mem: 2500
Train: Epoch[5/5]  [2330/4579]  eta: 0:13:08  Lr: 0.001875  Loss: -0.4413  Acc@1: 68.7500 (66.1090)  Acc@5: 93.7500 (92.0125)  time: 0.3487  data: 0.0014  max mem: 2500
Train: Epoch[5/5]  [2340/4579]  eta: 0:13:05  Lr: 0.001875  Loss: 0.0626  Acc@1: 68.7500 (66.1283)  Acc@5: 93.7500 (92.0200)  time: 0.3490  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [2350/4579]  eta: 0:13:01  Lr: 0.001875  Loss: -0.6033  Acc@1: 68.7500 (66.1261)  Acc@5: 93.7500 (92.0114)  time: 0.3516  data: 0.0016  max mem: 2500
Train: Epoch[5/5]  [2360/4579]  eta: 0:12:58  Lr: 0.001875  Loss: -0.5947  Acc@1: 68.7500 (66.1505)  Acc@5: 93.7500 (92.0134)  time: 0.3523  data: 0.0016  max mem: 2500
Train: Epoch[5/5]  [2370/4579]  eta: 0:12:54  Lr: 0.001875  Loss: -0.3743  Acc@1: 68.7500 (66.1641)  Acc@5: 93.7500 (92.0050)  time: 0.3505  data: 0.0010  max mem: 2500
Train: Epoch[5/5]  [2380/4579]  eta: 0:12:51  Lr: 0.001875  Loss: -0.7679  Acc@1: 62.5000 (66.1513)  Acc@5: 93.7500 (91.9939)  time: 0.3507  data: 0.0011  max mem: 2500
Train: Epoch[5/5]  [2390/4579]  eta: 0:12:47  Lr: 0.001875  Loss: -0.4030  Acc@1: 62.5000 (66.1413)  Acc@5: 93.7500 (91.9960)  time: 0.3508  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [2400/4579]  eta: 0:12:44  Lr: 0.001875  Loss: -0.5881  Acc@1: 68.7500 (66.1521)  Acc@5: 93.7500 (91.9955)  time: 0.3504  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [2410/4579]  eta: 0:12:40  Lr: 0.001875  Loss: -0.7586  Acc@1: 68.7500 (66.1473)  Acc@5: 87.5000 (91.9976)  time: 0.3497  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [2420/4579]  eta: 0:12:37  Lr: 0.001875  Loss: -0.7624  Acc@1: 62.5000 (66.1478)  Acc@5: 93.7500 (91.9971)  time: 0.3495  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [2430/4579]  eta: 0:12:33  Lr: 0.001875  Loss: -0.3189  Acc@1: 62.5000 (66.1636)  Acc@5: 93.7500 (92.0069)  time: 0.3520  data: 0.0010  max mem: 2500
Train: Epoch[5/5]  [2440/4579]  eta: 0:12:30  Lr: 0.001875  Loss: -0.5291  Acc@1: 68.7500 (66.1921)  Acc@5: 93.7500 (92.0115)  time: 0.3532  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [2450/4579]  eta: 0:12:26  Lr: 0.001875  Loss: -0.4809  Acc@1: 68.7500 (66.1847)  Acc@5: 93.7500 (92.0084)  time: 0.3557  data: 0.0010  max mem: 2500
Train: Epoch[5/5]  [2460/4579]  eta: 0:12:23  Lr: 0.001875  Loss: -0.4796  Acc@1: 68.7500 (66.2002)  Acc@5: 93.7500 (92.0281)  time: 0.3546  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [2470/4579]  eta: 0:12:19  Lr: 0.001875  Loss: -0.3448  Acc@1: 68.7500 (66.2030)  Acc@5: 93.7500 (92.0351)  time: 0.3516  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [2480/4579]  eta: 0:12:16  Lr: 0.001875  Loss: -0.8378  Acc@1: 68.7500 (66.2082)  Acc@5: 93.7500 (92.0370)  time: 0.3531  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [2490/4579]  eta: 0:12:12  Lr: 0.001875  Loss: -0.2912  Acc@1: 68.7500 (66.2234)  Acc@5: 93.7500 (92.0464)  time: 0.3524  data: 0.0011  max mem: 2500
Train: Epoch[5/5]  [2500/4579]  eta: 0:12:09  Lr: 0.001875  Loss: -0.7647  Acc@1: 68.7500 (66.2410)  Acc@5: 93.7500 (92.0407)  time: 0.3505  data: 0.0011  max mem: 2500
Train: Epoch[5/5]  [2510/4579]  eta: 0:12:05  Lr: 0.001875  Loss: 0.3945  Acc@1: 68.7500 (66.2460)  Acc@5: 93.7500 (92.0550)  time: 0.3497  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [2520/4579]  eta: 0:12:02  Lr: 0.001875  Loss: -0.1910  Acc@1: 68.7500 (66.2683)  Acc@5: 93.7500 (92.0642)  time: 0.3490  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [2530/4579]  eta: 0:11:58  Lr: 0.001875  Loss: -0.2602  Acc@1: 68.7500 (66.2535)  Acc@5: 93.7500 (92.0609)  time: 0.3480  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [2540/4579]  eta: 0:11:55  Lr: 0.001875  Loss: -0.0952  Acc@1: 68.7500 (66.2682)  Acc@5: 93.7500 (92.0528)  time: 0.3475  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [2550/4579]  eta: 0:11:51  Lr: 0.001875  Loss: -0.3880  Acc@1: 68.7500 (66.2681)  Acc@5: 93.7500 (92.0619)  time: 0.3485  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [2560/4579]  eta: 0:11:48  Lr: 0.001875  Loss: -0.2419  Acc@1: 62.5000 (66.2607)  Acc@5: 93.7500 (92.0710)  time: 0.3508  data: 0.0010  max mem: 2500
Train: Epoch[5/5]  [2570/4579]  eta: 0:11:44  Lr: 0.001875  Loss: -0.5152  Acc@1: 68.7500 (66.2656)  Acc@5: 93.7500 (92.0653)  time: 0.3533  data: 0.0010  max mem: 2500
Train: Epoch[5/5]  [2580/4579]  eta: 0:11:41  Lr: 0.001875  Loss: -0.5963  Acc@1: 68.7500 (66.2921)  Acc@5: 93.7500 (92.0743)  time: 0.3519  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [2590/4579]  eta: 0:11:37  Lr: 0.001875  Loss: -0.5404  Acc@1: 68.7500 (66.2703)  Acc@5: 93.7500 (92.0518)  time: 0.3494  data: 0.0014  max mem: 2500
Train: Epoch[5/5]  [2600/4579]  eta: 0:11:34  Lr: 0.001875  Loss: -0.1217  Acc@1: 62.5000 (66.2606)  Acc@5: 87.5000 (92.0415)  time: 0.3499  data: 0.0018  max mem: 2500
Train: Epoch[5/5]  [2610/4579]  eta: 0:11:30  Lr: 0.001875  Loss: -0.0772  Acc@1: 62.5000 (66.2462)  Acc@5: 87.5000 (92.0505)  time: 0.3511  data: 0.0012  max mem: 2500
Train: Epoch[5/5]  [2620/4579]  eta: 0:11:27  Lr: 0.001875  Loss: -0.6302  Acc@1: 62.5000 (66.2486)  Acc@5: 93.7500 (92.0474)  time: 0.3503  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [2630/4579]  eta: 0:11:23  Lr: 0.001875  Loss: -0.6609  Acc@1: 75.0000 (66.2795)  Acc@5: 93.7500 (92.0658)  time: 0.3494  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [2640/4579]  eta: 0:11:20  Lr: 0.001875  Loss: -0.0543  Acc@1: 75.0000 (66.2935)  Acc@5: 93.7500 (92.0721)  time: 0.3523  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [2650/4579]  eta: 0:11:16  Lr: 0.001875  Loss: -0.3494  Acc@1: 68.7500 (66.3052)  Acc@5: 93.7500 (92.0737)  time: 0.3540  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [2660/4579]  eta: 0:11:13  Lr: 0.001875  Loss: -0.4112  Acc@1: 68.7500 (66.3050)  Acc@5: 93.7500 (92.0777)  time: 0.3515  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [2670/4579]  eta: 0:11:09  Lr: 0.001875  Loss: -0.8557  Acc@1: 68.7500 (66.3211)  Acc@5: 93.7500 (92.0933)  time: 0.3483  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2680/4579]  eta: 0:11:06  Lr: 0.001875  Loss: -0.3817  Acc@1: 68.7500 (66.3092)  Acc@5: 93.7500 (92.0878)  time: 0.3496  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2690/4579]  eta: 0:11:02  Lr: 0.001875  Loss: 0.2039  Acc@1: 62.5000 (66.3160)  Acc@5: 93.7500 (92.0847)  time: 0.3503  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [2700/4579]  eta: 0:10:59  Lr: 0.001875  Loss: -0.4722  Acc@1: 68.7500 (66.3227)  Acc@5: 93.7500 (92.0863)  time: 0.3504  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [2710/4579]  eta: 0:10:55  Lr: 0.001875  Loss: -0.1282  Acc@1: 68.7500 (66.3385)  Acc@5: 93.7500 (92.0924)  time: 0.3511  data: 0.0012  max mem: 2500
Train: Epoch[5/5]  [2720/4579]  eta: 0:10:52  Lr: 0.001875  Loss: -0.2275  Acc@1: 68.7500 (66.3612)  Acc@5: 93.7500 (92.1077)  time: 0.3507  data: 0.0014  max mem: 2500
Train: Epoch[5/5]  [2730/4579]  eta: 0:10:48  Lr: 0.001875  Loss: -0.2151  Acc@1: 68.7500 (66.3585)  Acc@5: 93.7500 (92.1045)  time: 0.3505  data: 0.0011  max mem: 2500
Train: Epoch[5/5]  [2740/4579]  eta: 0:10:45  Lr: 0.001875  Loss: -0.6265  Acc@1: 68.7500 (66.3718)  Acc@5: 93.7500 (92.1128)  time: 0.3500  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [2750/4579]  eta: 0:10:41  Lr: 0.001875  Loss: -0.3176  Acc@1: 68.7500 (66.3804)  Acc@5: 93.7500 (92.0983)  time: 0.3486  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [2760/4579]  eta: 0:10:37  Lr: 0.001875  Loss: -0.4580  Acc@1: 62.5000 (66.3596)  Acc@5: 93.7500 (92.0975)  time: 0.3493  data: 0.0010  max mem: 2500
Train: Epoch[5/5]  [2770/4579]  eta: 0:10:34  Lr: 0.001875  Loss: -0.7317  Acc@1: 62.5000 (66.3637)  Acc@5: 93.7500 (92.1057)  time: 0.3503  data: 0.0013  max mem: 2500
Train: Epoch[5/5]  [2780/4579]  eta: 0:10:30  Lr: 0.001875  Loss: -0.3796  Acc@1: 68.7500 (66.3655)  Acc@5: 93.7500 (92.1004)  time: 0.3490  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [2790/4579]  eta: 0:10:27  Lr: 0.001875  Loss: 0.0546  Acc@1: 68.7500 (66.3539)  Acc@5: 93.7500 (92.1086)  time: 0.3493  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [2800/4579]  eta: 0:10:23  Lr: 0.001875  Loss: -0.2399  Acc@1: 68.7500 (66.3513)  Acc@5: 93.7500 (92.1033)  time: 0.3499  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [2810/4579]  eta: 0:10:20  Lr: 0.001875  Loss: 0.5935  Acc@1: 62.5000 (66.3487)  Acc@5: 93.7500 (92.0958)  time: 0.3487  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [2820/4579]  eta: 0:10:16  Lr: 0.001875  Loss: -0.0376  Acc@1: 62.5000 (66.3572)  Acc@5: 93.7500 (92.1039)  time: 0.3503  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [2830/4579]  eta: 0:10:13  Lr: 0.001875  Loss: 0.0032  Acc@1: 62.5000 (66.3569)  Acc@5: 93.7500 (92.1031)  time: 0.3519  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [2840/4579]  eta: 0:10:09  Lr: 0.001875  Loss: -0.4534  Acc@1: 62.5000 (66.3499)  Acc@5: 93.7500 (92.1001)  time: 0.3511  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [2850/4579]  eta: 0:10:06  Lr: 0.001875  Loss: -0.6654  Acc@1: 62.5000 (66.3473)  Acc@5: 93.7500 (92.1058)  time: 0.3511  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [2860/4579]  eta: 0:10:02  Lr: 0.001875  Loss: -0.4854  Acc@1: 56.2500 (66.3317)  Acc@5: 93.7500 (92.1050)  time: 0.3509  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [2870/4579]  eta: 0:09:59  Lr: 0.001875  Loss: -0.0318  Acc@1: 62.5000 (66.3249)  Acc@5: 93.7500 (92.0999)  time: 0.3500  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [2880/4579]  eta: 0:09:55  Lr: 0.001875  Loss: -0.0386  Acc@1: 62.5000 (66.3181)  Acc@5: 93.7500 (92.0969)  time: 0.3482  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [2890/4579]  eta: 0:09:52  Lr: 0.001875  Loss: -0.3744  Acc@1: 68.7500 (66.3309)  Acc@5: 93.7500 (92.0962)  time: 0.3500  data: 0.0014  max mem: 2500
Train: Epoch[5/5]  [2900/4579]  eta: 0:09:48  Lr: 0.001875  Loss: -0.6954  Acc@1: 68.7500 (66.3564)  Acc@5: 93.7500 (92.1105)  time: 0.3519  data: 0.0027  max mem: 2500
Train: Epoch[5/5]  [2910/4579]  eta: 0:09:45  Lr: 0.001875  Loss: -0.6102  Acc@1: 68.7500 (66.3582)  Acc@5: 93.7500 (92.1183)  time: 0.3516  data: 0.0025  max mem: 2500
Train: Epoch[5/5]  [2920/4579]  eta: 0:09:41  Lr: 0.001875  Loss: -0.5942  Acc@1: 68.7500 (66.3643)  Acc@5: 93.7500 (92.1217)  time: 0.3517  data: 0.0011  max mem: 2500
Train: Epoch[5/5]  [2930/4579]  eta: 0:09:38  Lr: 0.001875  Loss: -0.6085  Acc@1: 62.5000 (66.3511)  Acc@5: 93.7500 (92.1273)  time: 0.3506  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [2940/4579]  eta: 0:09:34  Lr: 0.001875  Loss: -0.0167  Acc@1: 56.2500 (66.3380)  Acc@5: 93.7500 (92.1307)  time: 0.3498  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2950/4579]  eta: 0:09:31  Lr: 0.001875  Loss: -0.2024  Acc@1: 62.5000 (66.3271)  Acc@5: 93.7500 (92.1319)  time: 0.3495  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [2960/4579]  eta: 0:09:27  Lr: 0.001875  Loss: 0.5793  Acc@1: 62.5000 (66.2994)  Acc@5: 93.7500 (92.1247)  time: 0.3498  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [2970/4579]  eta: 0:09:24  Lr: 0.001875  Loss: -0.3496  Acc@1: 62.5000 (66.3097)  Acc@5: 93.7500 (92.1344)  time: 0.3498  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [2980/4579]  eta: 0:09:20  Lr: 0.001875  Loss: 0.0691  Acc@1: 68.7500 (66.3158)  Acc@5: 93.7500 (92.1356)  time: 0.3488  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [2990/4579]  eta: 0:09:17  Lr: 0.001875  Loss: -0.1390  Acc@1: 62.5000 (66.2968)  Acc@5: 93.7500 (92.1285)  time: 0.3482  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [3000/4579]  eta: 0:09:13  Lr: 0.001875  Loss: -0.2530  Acc@1: 62.5000 (66.2904)  Acc@5: 93.7500 (92.1235)  time: 0.3512  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [3010/4579]  eta: 0:09:10  Lr: 0.001875  Loss: -0.6505  Acc@1: 68.7500 (66.3027)  Acc@5: 93.7500 (92.1247)  time: 0.3523  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [3020/4579]  eta: 0:09:06  Lr: 0.001875  Loss: -0.3836  Acc@1: 68.7500 (66.3025)  Acc@5: 93.7500 (92.1322)  time: 0.3523  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [3030/4579]  eta: 0:09:03  Lr: 0.001875  Loss: 0.0179  Acc@1: 62.5000 (66.2900)  Acc@5: 93.7500 (92.1292)  time: 0.3534  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3040/4579]  eta: 0:08:59  Lr: 0.001875  Loss: 0.1366  Acc@1: 62.5000 (66.2817)  Acc@5: 87.5000 (92.1243)  time: 0.3500  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [3050/4579]  eta: 0:08:56  Lr: 0.001875  Loss: 0.0041  Acc@1: 62.5000 (66.2631)  Acc@5: 93.7500 (92.1255)  time: 0.3475  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [3060/4579]  eta: 0:08:52  Lr: 0.001875  Loss: -0.2604  Acc@1: 62.5000 (66.2672)  Acc@5: 93.7500 (92.1329)  time: 0.3502  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [3070/4579]  eta: 0:08:49  Lr: 0.001875  Loss: -0.5092  Acc@1: 62.5000 (66.2691)  Acc@5: 93.7500 (92.1320)  time: 0.3495  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [3080/4579]  eta: 0:08:45  Lr: 0.001875  Loss: 0.3669  Acc@1: 62.5000 (66.2752)  Acc@5: 93.7500 (92.1312)  time: 0.3477  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [3090/4579]  eta: 0:08:42  Lr: 0.001875  Loss: -0.4172  Acc@1: 62.5000 (66.2731)  Acc@5: 93.7500 (92.1284)  time: 0.3500  data: 0.0010  max mem: 2500
Train: Epoch[5/5]  [3100/4579]  eta: 0:08:38  Lr: 0.001875  Loss: -0.0955  Acc@1: 62.5000 (66.2569)  Acc@5: 93.7500 (92.1255)  time: 0.3500  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [3110/4579]  eta: 0:08:35  Lr: 0.001875  Loss: 0.1821  Acc@1: 68.7500 (66.2528)  Acc@5: 93.7500 (92.1287)  time: 0.3491  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [3120/4579]  eta: 0:08:31  Lr: 0.001875  Loss: -0.0894  Acc@1: 62.5000 (66.2408)  Acc@5: 93.7500 (92.1279)  time: 0.3485  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [3130/4579]  eta: 0:08:28  Lr: 0.001875  Loss: 0.1810  Acc@1: 62.5000 (66.2308)  Acc@5: 93.7500 (92.1211)  time: 0.3484  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [3140/4579]  eta: 0:08:24  Lr: 0.001875  Loss: -0.3542  Acc@1: 68.7500 (66.2468)  Acc@5: 87.5000 (92.1184)  time: 0.3504  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [3150/4579]  eta: 0:08:21  Lr: 0.001875  Loss: -0.2502  Acc@1: 68.7500 (66.2548)  Acc@5: 87.5000 (92.1017)  time: 0.3508  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [3160/4579]  eta: 0:08:17  Lr: 0.001875  Loss: -0.5360  Acc@1: 68.7500 (66.2488)  Acc@5: 87.5000 (92.0951)  time: 0.3491  data: 0.0014  max mem: 2500
Train: Epoch[5/5]  [3170/4579]  eta: 0:08:14  Lr: 0.001875  Loss: 0.1199  Acc@1: 62.5000 (66.2330)  Acc@5: 93.7500 (92.0944)  time: 0.3487  data: 0.0012  max mem: 2500
Train: Epoch[5/5]  [3180/4579]  eta: 0:08:10  Lr: 0.001875  Loss: -0.3412  Acc@1: 62.5000 (66.2488)  Acc@5: 93.7500 (92.1035)  time: 0.3497  data: 0.0015  max mem: 2500
Train: Epoch[5/5]  [3190/4579]  eta: 0:08:07  Lr: 0.001875  Loss: -0.0696  Acc@1: 68.7500 (66.2390)  Acc@5: 93.7500 (92.1028)  time: 0.3496  data: 0.0014  max mem: 2500
Train: Epoch[5/5]  [3200/4579]  eta: 0:08:03  Lr: 0.001875  Loss: -0.0457  Acc@1: 68.7500 (66.2527)  Acc@5: 93.7500 (92.1099)  time: 0.3495  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [3210/4579]  eta: 0:08:00  Lr: 0.001875  Loss: -0.6510  Acc@1: 68.7500 (66.2683)  Acc@5: 93.7500 (92.1189)  time: 0.3505  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [3220/4579]  eta: 0:07:56  Lr: 0.001875  Loss: -0.6636  Acc@1: 68.7500 (66.2760)  Acc@5: 93.7500 (92.1181)  time: 0.3501  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [3230/4579]  eta: 0:07:52  Lr: 0.001875  Loss: 0.2520  Acc@1: 62.5000 (66.2604)  Acc@5: 93.7500 (92.1077)  time: 0.3507  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [3240/4579]  eta: 0:07:49  Lr: 0.001875  Loss: 0.0484  Acc@1: 68.7500 (66.2701)  Acc@5: 87.5000 (92.1108)  time: 0.3494  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3250/4579]  eta: 0:07:45  Lr: 0.001875  Loss: -0.3778  Acc@1: 68.7500 (66.2623)  Acc@5: 93.7500 (92.1044)  time: 0.3487  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3260/4579]  eta: 0:07:42  Lr: 0.001875  Loss: -0.3358  Acc@1: 62.5000 (66.2546)  Acc@5: 87.5000 (92.0998)  time: 0.3488  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [3270/4579]  eta: 0:07:38  Lr: 0.001875  Loss: -0.4992  Acc@1: 68.7500 (66.2794)  Acc@5: 93.7500 (92.1049)  time: 0.3479  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3280/4579]  eta: 0:07:35  Lr: 0.001875  Loss: -0.3513  Acc@1: 68.7500 (66.2889)  Acc@5: 93.7500 (92.1061)  time: 0.3491  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [3290/4579]  eta: 0:07:31  Lr: 0.001875  Loss: -0.3735  Acc@1: 68.7500 (66.2944)  Acc@5: 93.7500 (92.1111)  time: 0.3501  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [3300/4579]  eta: 0:07:28  Lr: 0.001875  Loss: -0.7586  Acc@1: 75.0000 (66.3227)  Acc@5: 93.7500 (92.1141)  time: 0.3494  data: 0.0010  max mem: 2500
Train: Epoch[5/5]  [3310/4579]  eta: 0:07:24  Lr: 0.001875  Loss: -0.0923  Acc@1: 75.0000 (66.3244)  Acc@5: 93.7500 (92.1134)  time: 0.3495  data: 0.0014  max mem: 2500
Train: Epoch[5/5]  [3320/4579]  eta: 0:07:21  Lr: 0.001875  Loss: -0.4803  Acc@1: 62.5000 (66.3204)  Acc@5: 93.7500 (92.1221)  time: 0.3523  data: 0.0013  max mem: 2500
Train: Epoch[5/5]  [3330/4579]  eta: 0:07:17  Lr: 0.001875  Loss: -0.2277  Acc@1: 68.7500 (66.3221)  Acc@5: 93.7500 (92.1195)  time: 0.3518  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [3340/4579]  eta: 0:07:14  Lr: 0.001875  Loss: -0.4542  Acc@1: 68.7500 (66.3274)  Acc@5: 93.7500 (92.1262)  time: 0.3503  data: 0.0010  max mem: 2500
Train: Epoch[5/5]  [3350/4579]  eta: 0:07:10  Lr: 0.001875  Loss: -0.7759  Acc@1: 75.0000 (66.3533)  Acc@5: 93.7500 (92.1329)  time: 0.3507  data: 0.0013  max mem: 2500
Train: Epoch[5/5]  [3360/4579]  eta: 0:07:07  Lr: 0.001875  Loss: -0.2650  Acc@1: 68.7500 (66.3512)  Acc@5: 93.7500 (92.1359)  time: 0.3498  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [3370/4579]  eta: 0:07:03  Lr: 0.001875  Loss: -0.2414  Acc@1: 62.5000 (66.3268)  Acc@5: 93.7500 (92.1296)  time: 0.3500  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [3380/4579]  eta: 0:07:00  Lr: 0.001875  Loss: -0.3464  Acc@1: 62.5000 (66.3339)  Acc@5: 93.7500 (92.1270)  time: 0.3527  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [3390/4579]  eta: 0:06:56  Lr: 0.001875  Loss: -0.4513  Acc@1: 62.5000 (66.3300)  Acc@5: 93.7500 (92.1244)  time: 0.3509  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [3400/4579]  eta: 0:06:53  Lr: 0.001875  Loss: -0.1859  Acc@1: 62.5000 (66.3316)  Acc@5: 93.7500 (92.1273)  time: 0.3506  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [3410/4579]  eta: 0:06:49  Lr: 0.001875  Loss: 0.0437  Acc@1: 68.7500 (66.3460)  Acc@5: 93.7500 (92.1321)  time: 0.3521  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [3420/4579]  eta: 0:06:46  Lr: 0.001875  Loss: 0.4228  Acc@1: 68.7500 (66.3348)  Acc@5: 87.5000 (92.1204)  time: 0.3495  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [3430/4579]  eta: 0:06:42  Lr: 0.001875  Loss: 0.0795  Acc@1: 68.7500 (66.3418)  Acc@5: 87.5000 (92.1215)  time: 0.3491  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [3440/4579]  eta: 0:06:39  Lr: 0.001875  Loss: -0.5353  Acc@1: 68.7500 (66.3524)  Acc@5: 93.7500 (92.1135)  time: 0.3508  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3450/4579]  eta: 0:06:35  Lr: 0.001875  Loss: -0.1222  Acc@1: 68.7500 (66.3540)  Acc@5: 93.7500 (92.1200)  time: 0.3497  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3460/4579]  eta: 0:06:32  Lr: 0.001875  Loss: -0.5993  Acc@1: 68.7500 (66.3464)  Acc@5: 93.7500 (92.1247)  time: 0.3496  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [3470/4579]  eta: 0:06:28  Lr: 0.001875  Loss: 0.2774  Acc@1: 68.7500 (66.3444)  Acc@5: 93.7500 (92.1276)  time: 0.3506  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [3480/4579]  eta: 0:06:25  Lr: 0.001875  Loss: -0.2401  Acc@1: 68.7500 (66.3567)  Acc@5: 93.7500 (92.1305)  time: 0.3496  data: 0.0011  max mem: 2500
Train: Epoch[5/5]  [3490/4579]  eta: 0:06:21  Lr: 0.001875  Loss: -0.1963  Acc@1: 68.7500 (66.3689)  Acc@5: 93.7500 (92.1333)  time: 0.3496  data: 0.0011  max mem: 2500
Train: Epoch[5/5]  [3500/4579]  eta: 0:06:18  Lr: 0.001875  Loss: 0.2319  Acc@1: 68.7500 (66.3775)  Acc@5: 93.7500 (92.1326)  time: 0.3507  data: 0.0012  max mem: 2500
Train: Epoch[5/5]  [3510/4579]  eta: 0:06:14  Lr: 0.001875  Loss: 0.6043  Acc@1: 68.7500 (66.3682)  Acc@5: 87.5000 (92.1176)  time: 0.3524  data: 0.0010  max mem: 2500
Train: Epoch[5/5]  [3520/4579]  eta: 0:06:11  Lr: 0.001875  Loss: 0.1681  Acc@1: 62.5000 (66.3732)  Acc@5: 87.5000 (92.1045)  time: 0.3499  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [3530/4579]  eta: 0:06:07  Lr: 0.001875  Loss: -0.3540  Acc@1: 62.5000 (66.3711)  Acc@5: 93.7500 (92.1021)  time: 0.3493  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [3540/4579]  eta: 0:06:04  Lr: 0.001875  Loss: -0.6320  Acc@1: 62.5000 (66.3637)  Acc@5: 93.7500 (92.0909)  time: 0.3496  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [3550/4579]  eta: 0:06:00  Lr: 0.001875  Loss: 0.0129  Acc@1: 62.5000 (66.3457)  Acc@5: 87.5000 (92.0744)  time: 0.3522  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [3560/4579]  eta: 0:05:57  Lr: 0.001875  Loss: -0.0438  Acc@1: 56.2500 (66.3262)  Acc@5: 87.5000 (92.0756)  time: 0.3536  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [3570/4579]  eta: 0:05:53  Lr: 0.001875  Loss: -0.3833  Acc@1: 68.7500 (66.3505)  Acc@5: 93.7500 (92.0768)  time: 0.3511  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [3580/4579]  eta: 0:05:50  Lr: 0.001875  Loss: -0.4893  Acc@1: 75.0000 (66.3572)  Acc@5: 93.7500 (92.0832)  time: 0.3525  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3590/4579]  eta: 0:05:46  Lr: 0.001875  Loss: -0.3267  Acc@1: 62.5000 (66.3412)  Acc@5: 93.7500 (92.0809)  time: 0.3517  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3600/4579]  eta: 0:05:43  Lr: 0.001875  Loss: -0.1823  Acc@1: 68.7500 (66.3479)  Acc@5: 93.7500 (92.0855)  time: 0.3501  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3610/4579]  eta: 0:05:39  Lr: 0.001875  Loss: -0.0758  Acc@1: 75.0000 (66.3528)  Acc@5: 93.7500 (92.0901)  time: 0.3515  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3620/4579]  eta: 0:05:36  Lr: 0.001875  Loss: -0.5588  Acc@1: 68.7500 (66.3560)  Acc@5: 93.7500 (92.0913)  time: 0.3515  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3630/4579]  eta: 0:05:32  Lr: 0.001875  Loss: -0.0524  Acc@1: 62.5000 (66.3643)  Acc@5: 93.7500 (92.0890)  time: 0.3508  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [3640/4579]  eta: 0:05:29  Lr: 0.001875  Loss: -0.7724  Acc@1: 62.5000 (66.3657)  Acc@5: 93.7500 (92.0935)  time: 0.3504  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [3650/4579]  eta: 0:05:25  Lr: 0.001875  Loss: -0.0581  Acc@1: 62.5000 (66.3602)  Acc@5: 93.7500 (92.0963)  time: 0.3498  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [3660/4579]  eta: 0:05:22  Lr: 0.001875  Loss: -0.1344  Acc@1: 68.7500 (66.3668)  Acc@5: 93.7500 (92.0940)  time: 0.3502  data: 0.0014  max mem: 2500
Train: Epoch[5/5]  [3670/4579]  eta: 0:05:18  Lr: 0.001875  Loss: -0.2309  Acc@1: 68.7500 (66.3665)  Acc@5: 93.7500 (92.1054)  time: 0.3493  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [3680/4579]  eta: 0:05:15  Lr: 0.001875  Loss: -0.3978  Acc@1: 68.7500 (66.3678)  Acc@5: 93.7500 (92.1081)  time: 0.3514  data: 0.0019  max mem: 2500
Train: Epoch[5/5]  [3690/4579]  eta: 0:05:11  Lr: 0.001875  Loss: -0.0567  Acc@1: 68.7500 (66.3709)  Acc@5: 93.7500 (92.1092)  time: 0.3560  data: 0.0024  max mem: 2500
Train: Epoch[5/5]  [3700/4579]  eta: 0:05:08  Lr: 0.001875  Loss: 0.0072  Acc@1: 68.7500 (66.3773)  Acc@5: 93.7500 (92.1102)  time: 0.3534  data: 0.0013  max mem: 2500
Train: Epoch[5/5]  [3710/4579]  eta: 0:05:04  Lr: 0.001875  Loss: -0.3788  Acc@1: 62.5000 (66.3669)  Acc@5: 93.7500 (92.1079)  time: 0.3501  data: 0.0010  max mem: 2500
Train: Epoch[5/5]  [3720/4579]  eta: 0:05:01  Lr: 0.001875  Loss: -0.1369  Acc@1: 62.5000 (66.3733)  Acc@5: 93.7500 (92.1107)  time: 0.3494  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [3730/4579]  eta: 0:04:57  Lr: 0.001875  Loss: -0.1123  Acc@1: 62.5000 (66.3713)  Acc@5: 93.7500 (92.1150)  time: 0.3487  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [3740/4579]  eta: 0:04:54  Lr: 0.001875  Loss: 0.1265  Acc@1: 62.5000 (66.3810)  Acc@5: 93.7500 (92.1161)  time: 0.3495  data: 0.0010  max mem: 2500
Train: Epoch[5/5]  [3750/4579]  eta: 0:04:50  Lr: 0.001875  Loss: -0.0748  Acc@1: 68.7500 (66.3973)  Acc@5: 93.7500 (92.1188)  time: 0.3491  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [3760/4579]  eta: 0:04:47  Lr: 0.001875  Loss: 0.0822  Acc@1: 68.7500 (66.3903)  Acc@5: 93.7500 (92.1131)  time: 0.3492  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [3770/4579]  eta: 0:04:43  Lr: 0.001875  Loss: -0.5252  Acc@1: 68.7500 (66.3982)  Acc@5: 93.7500 (92.1175)  time: 0.3489  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [3780/4579]  eta: 0:04:40  Lr: 0.001875  Loss: -0.4377  Acc@1: 68.7500 (66.4027)  Acc@5: 93.7500 (92.1152)  time: 0.3480  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3790/4579]  eta: 0:04:36  Lr: 0.001875  Loss: -0.3228  Acc@1: 62.5000 (66.3924)  Acc@5: 87.5000 (92.1096)  time: 0.3479  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3800/4579]  eta: 0:04:33  Lr: 0.001875  Loss: -0.7108  Acc@1: 68.7500 (66.4102)  Acc@5: 93.7500 (92.1156)  time: 0.3480  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [3810/4579]  eta: 0:04:29  Lr: 0.001875  Loss: 0.0249  Acc@1: 68.7500 (66.4081)  Acc@5: 93.7500 (92.1149)  time: 0.3480  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [3820/4579]  eta: 0:04:26  Lr: 0.001875  Loss: -0.1282  Acc@1: 62.5000 (66.4077)  Acc@5: 87.5000 (92.1078)  time: 0.3483  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [3830/4579]  eta: 0:04:22  Lr: 0.001875  Loss: 0.0579  Acc@1: 62.5000 (66.4073)  Acc@5: 93.7500 (92.1088)  time: 0.3496  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [3840/4579]  eta: 0:04:19  Lr: 0.001875  Loss: -0.2624  Acc@1: 62.5000 (66.4150)  Acc@5: 93.7500 (92.1098)  time: 0.3494  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [3850/4579]  eta: 0:04:15  Lr: 0.001875  Loss: -0.1607  Acc@1: 62.5000 (66.4032)  Acc@5: 93.7500 (92.1173)  time: 0.3501  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [3860/4579]  eta: 0:04:12  Lr: 0.001875  Loss: -0.3405  Acc@1: 62.5000 (66.4174)  Acc@5: 93.7500 (92.1183)  time: 0.3518  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [3870/4579]  eta: 0:04:08  Lr: 0.001875  Loss: -0.4980  Acc@1: 75.0000 (66.4363)  Acc@5: 93.7500 (92.1274)  time: 0.3522  data: 0.0011  max mem: 2500
Train: Epoch[5/5]  [3880/4579]  eta: 0:04:05  Lr: 0.001875  Loss: -0.6282  Acc@1: 68.7500 (66.4375)  Acc@5: 93.7500 (92.1348)  time: 0.3518  data: 0.0013  max mem: 2500
Train: Epoch[5/5]  [3890/4579]  eta: 0:04:01  Lr: 0.001875  Loss: -0.5739  Acc@1: 68.7500 (66.4418)  Acc@5: 93.7500 (92.1421)  time: 0.3505  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [3900/4579]  eta: 0:03:58  Lr: 0.001875  Loss: -0.4905  Acc@1: 68.7500 (66.4573)  Acc@5: 93.7500 (92.1494)  time: 0.3499  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [3910/4579]  eta: 0:03:54  Lr: 0.001875  Loss: -0.1556  Acc@1: 68.7500 (66.4488)  Acc@5: 93.7500 (92.1471)  time: 0.3500  data: 0.0012  max mem: 2500
Train: Epoch[5/5]  [3920/4579]  eta: 0:03:51  Lr: 0.001875  Loss: -0.3853  Acc@1: 62.5000 (66.4563)  Acc@5: 93.7500 (92.1512)  time: 0.3499  data: 0.0011  max mem: 2500
Train: Epoch[5/5]  [3930/4579]  eta: 0:03:47  Lr: 0.001875  Loss: -0.2032  Acc@1: 68.7500 (66.4700)  Acc@5: 93.7500 (92.1537)  time: 0.3497  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [3940/4579]  eta: 0:03:44  Lr: 0.001875  Loss: -0.0753  Acc@1: 68.7500 (66.4584)  Acc@5: 87.5000 (92.1514)  time: 0.3492  data: 0.0010  max mem: 2500
Train: Epoch[5/5]  [3950/4579]  eta: 0:03:40  Lr: 0.001875  Loss: -0.6970  Acc@1: 68.7500 (66.4737)  Acc@5: 93.7500 (92.1476)  time: 0.3486  data: 0.0010  max mem: 2500
Train: Epoch[5/5]  [3960/4579]  eta: 0:03:36  Lr: 0.001875  Loss: -0.3182  Acc@1: 68.7500 (66.4668)  Acc@5: 93.7500 (92.1421)  time: 0.3489  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [3970/4579]  eta: 0:03:33  Lr: 0.001875  Loss: -0.7966  Acc@1: 62.5000 (66.4615)  Acc@5: 93.7500 (92.1415)  time: 0.3492  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3980/4579]  eta: 0:03:29  Lr: 0.001875  Loss: 0.1422  Acc@1: 68.7500 (66.4751)  Acc@5: 93.7500 (92.1392)  time: 0.3489  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [3990/4579]  eta: 0:03:26  Lr: 0.001875  Loss: 0.2304  Acc@1: 68.7500 (66.4699)  Acc@5: 93.7500 (92.1354)  time: 0.3501  data: 0.0014  max mem: 2500
Train: Epoch[5/5]  [4000/4579]  eta: 0:03:22  Lr: 0.001875  Loss: -0.4532  Acc@1: 62.5000 (66.4631)  Acc@5: 87.5000 (92.1254)  time: 0.3513  data: 0.0013  max mem: 2500
Train: Epoch[5/5]  [4010/4579]  eta: 0:03:19  Lr: 0.001875  Loss: -0.4141  Acc@1: 75.0000 (66.4844)  Acc@5: 93.7500 (92.1326)  time: 0.3504  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [4020/4579]  eta: 0:03:15  Lr: 0.001875  Loss: -0.1643  Acc@1: 75.0000 (66.4900)  Acc@5: 93.7500 (92.1335)  time: 0.3504  data: 0.0011  max mem: 2500
Train: Epoch[5/5]  [4030/4579]  eta: 0:03:12  Lr: 0.001875  Loss: 0.0888  Acc@1: 62.5000 (66.4739)  Acc@5: 87.5000 (92.1297)  time: 0.3498  data: 0.0012  max mem: 2500
Train: Epoch[5/5]  [4040/4579]  eta: 0:03:08  Lr: 0.001875  Loss: -0.4720  Acc@1: 62.5000 (66.4641)  Acc@5: 93.7500 (92.1338)  time: 0.3489  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [4050/4579]  eta: 0:03:05  Lr: 0.001875  Loss: -0.7333  Acc@1: 68.7500 (66.4805)  Acc@5: 93.7500 (92.1393)  time: 0.3502  data: 0.0010  max mem: 2500
Train: Epoch[5/5]  [4060/4579]  eta: 0:03:01  Lr: 0.001875  Loss: -0.1261  Acc@1: 68.7500 (66.4784)  Acc@5: 93.7500 (92.1325)  time: 0.3501  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [4070/4579]  eta: 0:02:58  Lr: 0.001875  Loss: -0.4420  Acc@1: 68.7500 (66.4794)  Acc@5: 93.7500 (92.1365)  time: 0.3490  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [4080/4579]  eta: 0:02:54  Lr: 0.001875  Loss: -0.4733  Acc@1: 68.7500 (66.4972)  Acc@5: 93.7500 (92.1450)  time: 0.3483  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [4090/4579]  eta: 0:02:51  Lr: 0.001875  Loss: -0.3201  Acc@1: 68.7500 (66.4920)  Acc@5: 93.7500 (92.1321)  time: 0.3483  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [4100/4579]  eta: 0:02:47  Lr: 0.001875  Loss: 0.1402  Acc@1: 62.5000 (66.4884)  Acc@5: 87.5000 (92.1269)  time: 0.3479  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [4110/4579]  eta: 0:02:44  Lr: 0.001875  Loss: 0.1156  Acc@1: 68.7500 (66.4969)  Acc@5: 93.7500 (92.1278)  time: 0.3476  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [4120/4579]  eta: 0:02:40  Lr: 0.001875  Loss: -0.3770  Acc@1: 68.7500 (66.4993)  Acc@5: 93.7500 (92.1257)  time: 0.3483  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [4130/4579]  eta: 0:02:37  Lr: 0.001875  Loss: -0.2643  Acc@1: 62.5000 (66.4972)  Acc@5: 93.7500 (92.1296)  time: 0.3476  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [4140/4579]  eta: 0:02:33  Lr: 0.001875  Loss: -0.6769  Acc@1: 68.7500 (66.5162)  Acc@5: 93.7500 (92.1290)  time: 0.3479  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [4150/4579]  eta: 0:02:30  Lr: 0.001875  Loss: -0.2572  Acc@1: 75.0000 (66.5246)  Acc@5: 93.7500 (92.1269)  time: 0.3487  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [4160/4579]  eta: 0:02:26  Lr: 0.001875  Loss: -0.2523  Acc@1: 68.7500 (66.5285)  Acc@5: 93.7500 (92.1278)  time: 0.3486  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [4170/4579]  eta: 0:02:23  Lr: 0.001875  Loss: 0.1521  Acc@1: 62.5000 (66.5158)  Acc@5: 87.5000 (92.1197)  time: 0.3488  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [4180/4579]  eta: 0:02:19  Lr: 0.001875  Loss: 0.6948  Acc@1: 56.2500 (66.4913)  Acc@5: 87.5000 (92.1057)  time: 0.3480  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [4190/4579]  eta: 0:02:16  Lr: 0.001875  Loss: 0.2625  Acc@1: 68.7500 (66.4967)  Acc@5: 87.5000 (92.0947)  time: 0.3473  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [4200/4579]  eta: 0:02:12  Lr: 0.001875  Loss: -0.7034  Acc@1: 68.7500 (66.5035)  Acc@5: 93.7500 (92.1016)  time: 0.3483  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [4210/4579]  eta: 0:02:09  Lr: 0.001875  Loss: -0.3684  Acc@1: 68.7500 (66.4985)  Acc@5: 93.7500 (92.1070)  time: 0.3489  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [4220/4579]  eta: 0:02:05  Lr: 0.001875  Loss: -0.0829  Acc@1: 68.7500 (66.4949)  Acc@5: 93.7500 (92.1005)  time: 0.3485  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [4230/4579]  eta: 0:02:02  Lr: 0.001875  Loss: -0.1795  Acc@1: 68.7500 (66.5180)  Acc@5: 93.7500 (92.1103)  time: 0.3479  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [4240/4579]  eta: 0:01:58  Lr: 0.001875  Loss: -0.2405  Acc@1: 68.7500 (66.5188)  Acc@5: 93.7500 (92.1157)  time: 0.3477  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [4250/4579]  eta: 0:01:55  Lr: 0.001875  Loss: -0.4350  Acc@1: 62.5000 (66.5138)  Acc@5: 93.7500 (92.1151)  time: 0.3484  data: 0.0011  max mem: 2500
Train: Epoch[5/5]  [4260/4579]  eta: 0:01:51  Lr: 0.001875  Loss: -0.8480  Acc@1: 68.7500 (66.5263)  Acc@5: 93.7500 (92.1204)  time: 0.3490  data: 0.0011  max mem: 2500
Train: Epoch[5/5]  [4270/4579]  eta: 0:01:48  Lr: 0.001875  Loss: -0.6067  Acc@1: 68.7500 (66.5330)  Acc@5: 93.7500 (92.1257)  time: 0.3494  data: 0.0012  max mem: 2500
Train: Epoch[5/5]  [4280/4579]  eta: 0:01:44  Lr: 0.001875  Loss: 0.5801  Acc@1: 68.7500 (66.5265)  Acc@5: 93.7500 (92.1222)  time: 0.3489  data: 0.0012  max mem: 2500
Train: Epoch[5/5]  [4290/4579]  eta: 0:01:41  Lr: 0.001875  Loss: -0.4001  Acc@1: 68.7500 (66.5317)  Acc@5: 93.7500 (92.1187)  time: 0.3487  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [4300/4579]  eta: 0:01:37  Lr: 0.001875  Loss: -0.6476  Acc@1: 68.7500 (66.5310)  Acc@5: 93.7500 (92.1152)  time: 0.3491  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [4310/4579]  eta: 0:01:34  Lr: 0.001875  Loss: 0.0705  Acc@1: 56.2500 (66.5057)  Acc@5: 93.7500 (92.1031)  time: 0.3495  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [4320/4579]  eta: 0:01:30  Lr: 0.001875  Loss: -0.1829  Acc@1: 56.2500 (66.4994)  Acc@5: 93.7500 (92.1025)  time: 0.3495  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [4330/4579]  eta: 0:01:27  Lr: 0.001875  Loss: -0.4876  Acc@1: 68.7500 (66.5118)  Acc@5: 93.7500 (92.1092)  time: 0.3481  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [4340/4579]  eta: 0:01:23  Lr: 0.001875  Loss: -0.1121  Acc@1: 68.7500 (66.5054)  Acc@5: 93.7500 (92.1044)  time: 0.3482  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [4350/4579]  eta: 0:01:20  Lr: 0.001875  Loss: -0.8349  Acc@1: 62.5000 (66.5120)  Acc@5: 87.5000 (92.1038)  time: 0.3493  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [4360/4579]  eta: 0:01:16  Lr: 0.001875  Loss: -0.6935  Acc@1: 62.5000 (66.5229)  Acc@5: 93.7500 (92.0990)  time: 0.3518  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [4370/4579]  eta: 0:01:13  Lr: 0.001875  Loss: -0.5732  Acc@1: 62.5000 (66.5251)  Acc@5: 93.7500 (92.1056)  time: 0.3517  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [4380/4579]  eta: 0:01:09  Lr: 0.001875  Loss: -0.3635  Acc@1: 75.0000 (66.5373)  Acc@5: 93.7500 (92.1108)  time: 0.3498  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [4390/4579]  eta: 0:01:06  Lr: 0.001875  Loss: -0.2463  Acc@1: 68.7500 (66.5224)  Acc@5: 93.7500 (92.1117)  time: 0.3485  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [4400/4579]  eta: 0:01:02  Lr: 0.001875  Loss: -0.0011  Acc@1: 62.5000 (66.5204)  Acc@5: 93.7500 (92.1069)  time: 0.3466  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [4410/4579]  eta: 0:00:59  Lr: 0.001875  Loss: -0.5339  Acc@1: 68.7500 (66.5127)  Acc@5: 87.5000 (92.1050)  time: 0.3471  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [4420/4579]  eta: 0:00:55  Lr: 0.001875  Loss: 0.0942  Acc@1: 68.7500 (66.5149)  Acc@5: 93.7500 (92.1115)  time: 0.3479  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [4430/4579]  eta: 0:00:52  Lr: 0.001875  Loss: -0.0507  Acc@1: 68.7500 (66.5256)  Acc@5: 93.7500 (92.1152)  time: 0.3478  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [4440/4579]  eta: 0:00:48  Lr: 0.001875  Loss: 0.2669  Acc@1: 68.7500 (66.5236)  Acc@5: 93.7500 (92.1175)  time: 0.3483  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [4450/4579]  eta: 0:00:45  Lr: 0.001875  Loss: -0.0662  Acc@1: 68.7500 (66.5328)  Acc@5: 93.7500 (92.1183)  time: 0.3483  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [4460/4579]  eta: 0:00:41  Lr: 0.001875  Loss: -0.5080  Acc@1: 68.7500 (66.5406)  Acc@5: 93.7500 (92.1234)  time: 0.3472  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [4470/4579]  eta: 0:00:38  Lr: 0.001875  Loss: -0.2586  Acc@1: 68.7500 (66.5455)  Acc@5: 87.5000 (92.1131)  time: 0.3485  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [4480/4579]  eta: 0:00:34  Lr: 0.001875  Loss: -0.4243  Acc@1: 68.7500 (66.5588)  Acc@5: 93.7500 (92.1153)  time: 0.3494  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [4490/4579]  eta: 0:00:31  Lr: 0.001875  Loss: -0.3104  Acc@1: 68.7500 (66.5512)  Acc@5: 93.7500 (92.1148)  time: 0.3482  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [4500/4579]  eta: 0:00:27  Lr: 0.001875  Loss: -0.4911  Acc@1: 68.7500 (66.5505)  Acc@5: 93.7500 (92.1184)  time: 0.3482  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [4510/4579]  eta: 0:00:24  Lr: 0.001875  Loss: -0.5129  Acc@1: 68.7500 (66.5526)  Acc@5: 93.7500 (92.1179)  time: 0.3483  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [4520/4579]  eta: 0:00:20  Lr: 0.001875  Loss: -0.0569  Acc@1: 68.7500 (66.5616)  Acc@5: 93.7500 (92.1187)  time: 0.3494  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [4530/4579]  eta: 0:00:17  Lr: 0.001875  Loss: -0.8137  Acc@1: 62.5000 (66.5582)  Acc@5: 87.5000 (92.1099)  time: 0.3493  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [4540/4579]  eta: 0:00:13  Lr: 0.001875  Loss: -0.4876  Acc@1: 62.5000 (66.5423)  Acc@5: 87.5000 (92.1025)  time: 0.3477  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [4550/4579]  eta: 0:00:10  Lr: 0.001875  Loss: 0.9217  Acc@1: 62.5000 (66.5431)  Acc@5: 93.7500 (92.1048)  time: 0.3509  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [4560/4579]  eta: 0:00:06  Lr: 0.001875  Loss: -0.6159  Acc@1: 62.5000 (66.5493)  Acc@5: 93.7500 (92.1015)  time: 0.3520  data: 0.0015  max mem: 2500
Train: Epoch[5/5]  [4570/4579]  eta: 0:00:03  Lr: 0.001875  Loss: -0.3442  Acc@1: 68.7500 (66.5486)  Acc@5: 93.7500 (92.0969)  time: 0.3491  data: 0.0015  max mem: 2500
Train: Epoch[5/5]  [4578/4579]  eta: 0:00:00  Lr: 0.001875  Loss: -0.3315  Acc@1: 68.7500 (66.5575)  Acc@5: 93.7500 (92.0990)  time: 0.3417  data: 0.0008  max mem: 2500
Train: Epoch[5/5] Total time: 0:26:44 (0.3505 s / it)
{0: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 1: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 2: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 3: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 4: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 5: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 6: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 7: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 8: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 9: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 10: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 11: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 12: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 13: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 14: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 15: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 16: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 17: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 18: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 19: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}}
Averaged stats: Lr: 0.001875  Loss: -0.3315  Acc@1: 68.7500 (66.5575)  Acc@5: 93.7500 (92.0990)
Test: [Task 1]  [   0/1627]  eta: 0:15:42  Loss: 1.1743 (1.1743)  Acc@1: 81.2500 (81.2500)  Acc@5: 93.7500 (93.7500)  time: 0.5795  data: 0.3630  max mem: 2500
Test: [Task 1]  [  10/1627]  eta: 0:06:44  Loss: 0.9123 (0.8739)  Acc@1: 87.5000 (84.6591)  Acc@5: 100.0000 (97.1591)  time: 0.2503  data: 0.0335  max mem: 2500
Test: [Task 1]  [  20/1627]  eta: 0:06:16  Loss: 0.7907 (0.8648)  Acc@1: 87.5000 (84.8214)  Acc@5: 100.0000 (97.6190)  time: 0.2167  data: 0.0005  max mem: 2500
Test: [Task 1]  [  30/1627]  eta: 0:06:05  Loss: 0.8897 (0.8723)  Acc@1: 87.5000 (85.0806)  Acc@5: 100.0000 (97.1774)  time: 0.2174  data: 0.0007  max mem: 2500
Test: [Task 1]  [  40/1627]  eta: 0:05:59  Loss: 0.9190 (0.8739)  Acc@1: 81.2500 (84.2988)  Acc@5: 100.0000 (96.9512)  time: 0.2182  data: 0.0007  max mem: 2500
Test: [Task 1]  [  50/1627]  eta: 0:05:54  Loss: 0.8423 (0.8573)  Acc@1: 81.2500 (84.5588)  Acc@5: 100.0000 (97.0588)  time: 0.2175  data: 0.0006  max mem: 2500
Test: [Task 1]  [  60/1627]  eta: 0:05:49  Loss: 0.8945 (0.8676)  Acc@1: 81.2500 (84.8361)  Acc@5: 100.0000 (96.9262)  time: 0.2165  data: 0.0007  max mem: 2500
Test: [Task 1]  [  70/1627]  eta: 0:05:46  Loss: 0.7426 (0.8614)  Acc@1: 81.2500 (85.1232)  Acc@5: 100.0000 (97.0951)  time: 0.2164  data: 0.0006  max mem: 2500
Test: [Task 1]  [  80/1627]  eta: 0:05:42  Loss: 0.6639 (0.8446)  Acc@1: 87.5000 (85.2623)  Acc@5: 100.0000 (97.4537)  time: 0.2162  data: 0.0005  max mem: 2500
Test: [Task 1]  [  90/1627]  eta: 0:05:39  Loss: 0.8329 (0.8618)  Acc@1: 87.5000 (85.0962)  Acc@5: 100.0000 (97.3214)  time: 0.2163  data: 0.0005  max mem: 2500
Test: [Task 1]  [ 100/1627]  eta: 0:05:36  Loss: 1.0639 (0.8878)  Acc@1: 81.2500 (84.5916)  Acc@5: 93.7500 (96.9059)  time: 0.2165  data: 0.0005  max mem: 2500
Test: [Task 1]  [ 110/1627]  eta: 0:05:33  Loss: 0.8915 (0.8843)  Acc@1: 81.2500 (84.6284)  Acc@5: 100.0000 (97.0721)  time: 0.2157  data: 0.0005  max mem: 2500
Test: [Task 1]  [ 120/1627]  eta: 0:05:31  Loss: 0.8162 (0.8825)  Acc@1: 87.5000 (85.0207)  Acc@5: 100.0000 (97.1074)  time: 0.2169  data: 0.0007  max mem: 2500
Test: [Task 1]  [ 130/1627]  eta: 0:05:28  Loss: 0.8547 (0.8885)  Acc@1: 87.5000 (85.0191)  Acc@5: 100.0000 (97.0897)  time: 0.2173  data: 0.0008  max mem: 2500
Test: [Task 1]  [ 140/1627]  eta: 0:05:26  Loss: 0.8547 (0.8879)  Acc@1: 87.5000 (84.9734)  Acc@5: 100.0000 (97.0301)  time: 0.2161  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 150/1627]  eta: 0:05:23  Loss: 0.6951 (0.8785)  Acc@1: 87.5000 (85.0993)  Acc@5: 100.0000 (97.0613)  time: 0.2170  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 160/1627]  eta: 0:05:21  Loss: 0.6571 (0.8715)  Acc@1: 87.5000 (85.2484)  Acc@5: 100.0000 (97.0497)  time: 0.2178  data: 0.0005  max mem: 2500
Test: [Task 1]  [ 170/1627]  eta: 0:05:19  Loss: 0.8533 (0.8680)  Acc@1: 87.5000 (85.2339)  Acc@5: 100.0000 (97.1126)  time: 0.2170  data: 0.0005  max mem: 2500
Test: [Task 1]  [ 180/1627]  eta: 0:05:16  Loss: 0.8824 (0.8730)  Acc@1: 81.2500 (85.2901)  Acc@5: 100.0000 (97.1685)  time: 0.2167  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 190/1627]  eta: 0:05:14  Loss: 0.8837 (0.8702)  Acc@1: 87.5000 (85.4058)  Acc@5: 100.0000 (97.1859)  time: 0.2184  data: 0.0005  max mem: 2500
Test: [Task 1]  [ 200/1627]  eta: 0:05:12  Loss: 0.8383 (0.8706)  Acc@1: 87.5000 (85.4789)  Acc@5: 100.0000 (97.2948)  time: 0.2179  data: 0.0005  max mem: 2500
Test: [Task 1]  [ 210/1627]  eta: 0:05:09  Loss: 0.8383 (0.8722)  Acc@1: 87.5000 (85.5746)  Acc@5: 100.0000 (97.3045)  time: 0.2164  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 220/1627]  eta: 0:05:07  Loss: 0.7284 (0.8753)  Acc@1: 87.5000 (85.4638)  Acc@5: 100.0000 (97.3133)  time: 0.2166  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 230/1627]  eta: 0:05:05  Loss: 0.7997 (0.8703)  Acc@1: 87.5000 (85.5790)  Acc@5: 100.0000 (97.3485)  time: 0.2163  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 240/1627]  eta: 0:05:02  Loss: 0.7877 (0.8662)  Acc@1: 87.5000 (85.7365)  Acc@5: 100.0000 (97.4066)  time: 0.2161  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 250/1627]  eta: 0:05:00  Loss: 0.7715 (0.8695)  Acc@1: 87.5000 (85.7072)  Acc@5: 100.0000 (97.2859)  time: 0.2157  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 260/1627]  eta: 0:04:58  Loss: 0.8360 (0.8687)  Acc@1: 81.2500 (85.6322)  Acc@5: 100.0000 (97.2941)  time: 0.2156  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 270/1627]  eta: 0:04:55  Loss: 0.7561 (0.8630)  Acc@1: 81.2500 (85.7011)  Acc@5: 100.0000 (97.3708)  time: 0.2163  data: 0.0005  max mem: 2500
Test: [Task 1]  [ 280/1627]  eta: 0:04:53  Loss: 0.7020 (0.8642)  Acc@1: 81.2500 (85.5649)  Acc@5: 100.0000 (97.3977)  time: 0.2170  data: 0.0005  max mem: 2500
Test: [Task 1]  [ 290/1627]  eta: 0:04:51  Loss: 0.8410 (0.8639)  Acc@1: 87.5000 (85.6100)  Acc@5: 100.0000 (97.4012)  time: 0.2168  data: 0.0007  max mem: 2500
Test: [Task 1]  [ 300/1627]  eta: 0:04:49  Loss: 0.7712 (0.8626)  Acc@1: 87.5000 (85.6105)  Acc@5: 100.0000 (97.3837)  time: 0.2173  data: 0.0013  max mem: 2500
Test: [Task 1]  [ 310/1627]  eta: 0:04:47  Loss: 0.7928 (0.8647)  Acc@1: 87.5000 (85.6712)  Acc@5: 100.0000 (97.3875)  time: 0.2175  data: 0.0012  max mem: 2500
Test: [Task 1]  [ 320/1627]  eta: 0:04:44  Loss: 0.8496 (0.8640)  Acc@1: 87.5000 (85.8061)  Acc@5: 100.0000 (97.4104)  time: 0.2169  data: 0.0007  max mem: 2500
Test: [Task 1]  [ 330/1627]  eta: 0:04:42  Loss: 0.7301 (0.8625)  Acc@1: 87.5000 (85.7628)  Acc@5: 100.0000 (97.4509)  time: 0.2180  data: 0.0008  max mem: 2500
Test: [Task 1]  [ 340/1627]  eta: 0:04:40  Loss: 0.6661 (0.8626)  Acc@1: 87.5000 (85.7588)  Acc@5: 100.0000 (97.4523)  time: 0.2181  data: 0.0006  max mem: 2500
Test: [Task 1]  [ 350/1627]  eta: 0:04:38  Loss: 0.8277 (0.8647)  Acc@1: 81.2500 (85.6838)  Acc@5: 100.0000 (97.4181)  time: 0.2173  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 360/1627]  eta: 0:04:36  Loss: 0.7867 (0.8624)  Acc@1: 81.2500 (85.6302)  Acc@5: 100.0000 (97.4550)  time: 0.2176  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 370/1627]  eta: 0:04:33  Loss: 0.7544 (0.8619)  Acc@1: 87.5000 (85.6469)  Acc@5: 100.0000 (97.4730)  time: 0.2179  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 380/1627]  eta: 0:04:31  Loss: 0.7644 (0.8608)  Acc@1: 87.5000 (85.6791)  Acc@5: 100.0000 (97.4738)  time: 0.2175  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 390/1627]  eta: 0:04:29  Loss: 0.7931 (0.8625)  Acc@1: 87.5000 (85.7097)  Acc@5: 100.0000 (97.4425)  time: 0.2175  data: 0.0012  max mem: 2500
Test: [Task 1]  [ 400/1627]  eta: 0:04:27  Loss: 0.7976 (0.8632)  Acc@1: 87.5000 (85.7388)  Acc@5: 100.0000 (97.4127)  time: 0.2172  data: 0.0013  max mem: 2500
Test: [Task 1]  [ 410/1627]  eta: 0:04:25  Loss: 0.7340 (0.8635)  Acc@1: 87.5000 (85.7816)  Acc@5: 100.0000 (97.3844)  time: 0.2169  data: 0.0006  max mem: 2500
Test: [Task 1]  [ 420/1627]  eta: 0:04:22  Loss: 0.6837 (0.8627)  Acc@1: 87.5000 (85.7779)  Acc@5: 100.0000 (97.4169)  time: 0.2166  data: 0.0006  max mem: 2500
Test: [Task 1]  [ 430/1627]  eta: 0:04:20  Loss: 0.6837 (0.8602)  Acc@1: 87.5000 (85.8324)  Acc@5: 100.0000 (97.4623)  time: 0.2165  data: 0.0005  max mem: 2500
Test: [Task 1]  [ 440/1627]  eta: 0:04:18  Loss: 0.8912 (0.8607)  Acc@1: 81.2500 (85.7710)  Acc@5: 100.0000 (97.4915)  time: 0.2172  data: 0.0005  max mem: 2500
Test: [Task 1]  [ 450/1627]  eta: 0:04:16  Loss: 0.9457 (0.8631)  Acc@1: 81.2500 (85.6153)  Acc@5: 100.0000 (97.4917)  time: 0.2190  data: 0.0005  max mem: 2500
Test: [Task 1]  [ 460/1627]  eta: 0:04:14  Loss: 0.9217 (0.8627)  Acc@1: 81.2500 (85.5613)  Acc@5: 100.0000 (97.5325)  time: 0.2191  data: 0.0005  max mem: 2500
Test: [Task 1]  [ 470/1627]  eta: 0:04:12  Loss: 0.7072 (0.8602)  Acc@1: 87.5000 (85.5759)  Acc@5: 100.0000 (97.5451)  time: 0.2171  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 480/1627]  eta: 0:04:09  Loss: 0.7584 (0.8641)  Acc@1: 81.2500 (85.4470)  Acc@5: 100.0000 (97.5442)  time: 0.2165  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 490/1627]  eta: 0:04:07  Loss: 0.8736 (0.8638)  Acc@1: 81.2500 (85.4379)  Acc@5: 100.0000 (97.5433)  time: 0.2164  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 500/1627]  eta: 0:04:05  Loss: 0.8247 (0.8657)  Acc@1: 81.2500 (85.3917)  Acc@5: 100.0000 (97.5299)  time: 0.2162  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 510/1627]  eta: 0:04:03  Loss: 0.9416 (0.8711)  Acc@1: 81.2500 (85.3229)  Acc@5: 93.7500 (97.4927)  time: 0.2157  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 520/1627]  eta: 0:04:00  Loss: 1.0726 (0.8779)  Acc@1: 81.2500 (85.2447)  Acc@5: 93.7500 (97.4328)  time: 0.2163  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 530/1627]  eta: 0:03:58  Loss: 0.8473 (0.8750)  Acc@1: 87.5000 (85.3225)  Acc@5: 100.0000 (97.4694)  time: 0.2164  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 540/1627]  eta: 0:03:56  Loss: 0.8324 (0.8753)  Acc@1: 87.5000 (85.3859)  Acc@5: 100.0000 (97.4469)  time: 0.2163  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 550/1627]  eta: 0:03:54  Loss: 0.9361 (0.8777)  Acc@1: 87.5000 (85.3902)  Acc@5: 100.0000 (97.4251)  time: 0.2163  data: 0.0005  max mem: 2500
Test: [Task 1]  [ 560/1627]  eta: 0:03:52  Loss: 1.0166 (0.8795)  Acc@1: 81.2500 (85.3721)  Acc@5: 100.0000 (97.4376)  time: 0.2163  data: 0.0005  max mem: 2500
Test: [Task 1]  [ 570/1627]  eta: 0:03:49  Loss: 0.8167 (0.8764)  Acc@1: 87.5000 (85.4203)  Acc@5: 100.0000 (97.4387)  time: 0.2173  data: 0.0013  max mem: 2500
Test: [Task 1]  [ 580/1627]  eta: 0:03:47  Loss: 0.7876 (0.8770)  Acc@1: 87.5000 (85.4346)  Acc@5: 100.0000 (97.4505)  time: 0.2177  data: 0.0015  max mem: 2500
Test: [Task 1]  [ 590/1627]  eta: 0:03:45  Loss: 0.8292 (0.8752)  Acc@1: 87.5000 (85.5013)  Acc@5: 100.0000 (97.4619)  time: 0.2167  data: 0.0007  max mem: 2500
Test: [Task 1]  [ 600/1627]  eta: 0:03:43  Loss: 0.7755 (0.8772)  Acc@1: 87.5000 (85.4409)  Acc@5: 100.0000 (97.4938)  time: 0.2160  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 610/1627]  eta: 0:03:41  Loss: 0.8556 (0.8757)  Acc@1: 87.5000 (85.5667)  Acc@5: 100.0000 (97.4836)  time: 0.2156  data: 0.0005  max mem: 2500
Test: [Task 1]  [ 620/1627]  eta: 0:03:39  Loss: 0.8193 (0.8778)  Acc@1: 87.5000 (85.5173)  Acc@5: 100.0000 (97.4638)  time: 0.2162  data: 0.0009  max mem: 2500
Test: [Task 1]  [ 630/1627]  eta: 0:03:36  Loss: 0.7646 (0.8774)  Acc@1: 87.5000 (85.5487)  Acc@5: 100.0000 (97.4643)  time: 0.2168  data: 0.0010  max mem: 2500
Test: [Task 1]  [ 640/1627]  eta: 0:03:34  Loss: 0.7254 (0.8771)  Acc@1: 87.5000 (85.5597)  Acc@5: 100.0000 (97.4746)  time: 0.2160  data: 0.0005  max mem: 2500
Test: [Task 1]  [ 650/1627]  eta: 0:03:32  Loss: 0.7553 (0.8761)  Acc@1: 87.5000 (85.5511)  Acc@5: 100.0000 (97.4942)  time: 0.2164  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 660/1627]  eta: 0:03:30  Loss: 0.7534 (0.8748)  Acc@1: 87.5000 (85.5616)  Acc@5: 100.0000 (97.4943)  time: 0.2168  data: 0.0005  max mem: 2500
Test: [Task 1]  [ 670/1627]  eta: 0:03:28  Loss: 0.8258 (0.8746)  Acc@1: 87.5000 (85.5440)  Acc@5: 100.0000 (97.5037)  time: 0.2163  data: 0.0005  max mem: 2500
Test: [Task 1]  [ 680/1627]  eta: 0:03:25  Loss: 0.9056 (0.8740)  Acc@1: 87.5000 (85.5452)  Acc@5: 100.0000 (97.5037)  time: 0.2159  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 690/1627]  eta: 0:03:23  Loss: 0.8229 (0.8723)  Acc@1: 87.5000 (85.5734)  Acc@5: 100.0000 (97.5398)  time: 0.2171  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 700/1627]  eta: 0:03:21  Loss: 0.8229 (0.8722)  Acc@1: 87.5000 (85.5831)  Acc@5: 100.0000 (97.5303)  time: 0.2166  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 710/1627]  eta: 0:03:19  Loss: 0.7648 (0.8696)  Acc@1: 87.5000 (85.6628)  Acc@5: 100.0000 (97.5475)  time: 0.2149  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 720/1627]  eta: 0:03:17  Loss: 0.7289 (0.8685)  Acc@1: 87.5000 (85.6363)  Acc@5: 100.0000 (97.5555)  time: 0.2151  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 730/1627]  eta: 0:03:14  Loss: 0.8350 (0.8690)  Acc@1: 81.2500 (85.6190)  Acc@5: 100.0000 (97.5547)  time: 0.2149  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 740/1627]  eta: 0:03:12  Loss: 0.8350 (0.8701)  Acc@1: 81.2500 (85.6022)  Acc@5: 100.0000 (97.5287)  time: 0.2155  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 750/1627]  eta: 0:03:10  Loss: 0.8528 (0.8693)  Acc@1: 87.5000 (85.6441)  Acc@5: 100.0000 (97.5366)  time: 0.2154  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 760/1627]  eta: 0:03:08  Loss: 0.9182 (0.8724)  Acc@1: 87.5000 (85.6275)  Acc@5: 100.0000 (97.5033)  time: 0.2159  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 770/1627]  eta: 0:03:06  Loss: 0.7593 (0.8697)  Acc@1: 93.7500 (85.7166)  Acc@5: 100.0000 (97.5195)  time: 0.2157  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 780/1627]  eta: 0:03:03  Loss: 0.6450 (0.8684)  Acc@1: 93.7500 (85.7634)  Acc@5: 100.0000 (97.5272)  time: 0.2154  data: 0.0005  max mem: 2500
Test: [Task 1]  [ 790/1627]  eta: 0:03:01  Loss: 0.7015 (0.8701)  Acc@1: 87.5000 (85.7459)  Acc@5: 100.0000 (97.5111)  time: 0.2162  data: 0.0011  max mem: 2500
Test: [Task 1]  [ 800/1627]  eta: 0:02:59  Loss: 0.7476 (0.8688)  Acc@1: 87.5000 (85.7756)  Acc@5: 100.0000 (97.5343)  time: 0.2161  data: 0.0012  max mem: 2500
Test: [Task 1]  [ 810/1627]  eta: 0:02:57  Loss: 0.7176 (0.8683)  Acc@1: 87.5000 (85.7969)  Acc@5: 100.0000 (97.5416)  time: 0.2156  data: 0.0005  max mem: 2500
Test: [Task 1]  [ 820/1627]  eta: 0:02:55  Loss: 0.7176 (0.8674)  Acc@1: 87.5000 (85.8252)  Acc@5: 100.0000 (97.5335)  time: 0.2152  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 830/1627]  eta: 0:02:53  Loss: 0.7004 (0.8666)  Acc@1: 93.7500 (85.8454)  Acc@5: 100.0000 (97.5481)  time: 0.2158  data: 0.0005  max mem: 2500
Test: [Task 1]  [ 840/1627]  eta: 0:02:50  Loss: 0.6325 (0.8643)  Acc@1: 93.7500 (85.8873)  Acc@5: 100.0000 (97.5699)  time: 0.2161  data: 0.0005  max mem: 2500
Test: [Task 1]  [ 850/1627]  eta: 0:02:48  Loss: 0.7146 (0.8654)  Acc@1: 87.5000 (85.8475)  Acc@5: 100.0000 (97.5764)  time: 0.2160  data: 0.0005  max mem: 2500
Test: [Task 1]  [ 860/1627]  eta: 0:02:46  Loss: 0.7146 (0.8645)  Acc@1: 87.5000 (85.9030)  Acc@5: 100.0000 (97.5973)  time: 0.2158  data: 0.0005  max mem: 2500
Test: [Task 1]  [ 870/1627]  eta: 0:02:44  Loss: 0.6750 (0.8631)  Acc@1: 87.5000 (85.8998)  Acc@5: 100.0000 (97.6033)  time: 0.2156  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 880/1627]  eta: 0:02:42  Loss: 0.8457 (0.8646)  Acc@1: 87.5000 (85.8612)  Acc@5: 100.0000 (97.6163)  time: 0.2155  data: 0.0005  max mem: 2500
Test: [Task 1]  [ 890/1627]  eta: 0:02:39  Loss: 0.9288 (0.8667)  Acc@1: 87.5000 (85.8726)  Acc@5: 100.0000 (97.6010)  time: 0.2155  data: 0.0005  max mem: 2500
Test: [Task 1]  [ 900/1627]  eta: 0:02:37  Loss: 0.9288 (0.8665)  Acc@1: 81.2500 (85.8837)  Acc@5: 100.0000 (97.5860)  time: 0.2166  data: 0.0015  max mem: 2500
Test: [Task 1]  [ 910/1627]  eta: 0:02:35  Loss: 0.9369 (0.8681)  Acc@1: 81.2500 (85.8397)  Acc@5: 93.7500 (97.5508)  time: 0.2169  data: 0.0021  max mem: 2500
Test: [Task 1]  [ 920/1627]  eta: 0:02:33  Loss: 0.8170 (0.8674)  Acc@1: 87.5000 (85.8713)  Acc@5: 100.0000 (97.5502)  time: 0.2165  data: 0.0010  max mem: 2500
Test: [Task 1]  [ 930/1627]  eta: 0:02:31  Loss: 0.7733 (0.8674)  Acc@1: 87.5000 (85.8821)  Acc@5: 93.7500 (97.5295)  time: 0.2164  data: 0.0005  max mem: 2500
Test: [Task 1]  [ 940/1627]  eta: 0:02:29  Loss: 0.7733 (0.8661)  Acc@1: 87.5000 (85.9192)  Acc@5: 100.0000 (97.5491)  time: 0.2159  data: 0.0005  max mem: 2500
Test: [Task 1]  [ 950/1627]  eta: 0:02:26  Loss: 0.8751 (0.8668)  Acc@1: 87.5000 (85.8964)  Acc@5: 100.0000 (97.5486)  time: 0.2158  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 960/1627]  eta: 0:02:24  Loss: 0.9016 (0.8665)  Acc@1: 81.2500 (85.8676)  Acc@5: 100.0000 (97.5676)  time: 0.2163  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 970/1627]  eta: 0:02:22  Loss: 0.7679 (0.8656)  Acc@1: 87.5000 (85.8780)  Acc@5: 100.0000 (97.5734)  time: 0.2164  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 980/1627]  eta: 0:02:20  Loss: 0.7531 (0.8658)  Acc@1: 87.5000 (85.9136)  Acc@5: 100.0000 (97.5599)  time: 0.2156  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 990/1627]  eta: 0:02:18  Loss: 1.0130 (0.8683)  Acc@1: 87.5000 (85.9107)  Acc@5: 93.7500 (97.5404)  time: 0.2149  data: 0.0004  max mem: 2500
Test: [Task 1]  [1000/1627]  eta: 0:02:15  Loss: 1.0002 (0.8687)  Acc@1: 87.5000 (85.8891)  Acc@5: 93.7500 (97.5212)  time: 0.2147  data: 0.0004  max mem: 2500
Test: [Task 1]  [1010/1627]  eta: 0:02:13  Loss: 0.8671 (0.8683)  Acc@1: 87.5000 (85.8865)  Acc@5: 100.0000 (97.5210)  time: 0.2146  data: 0.0004  max mem: 2500
Test: [Task 1]  [1020/1627]  eta: 0:02:11  Loss: 0.8281 (0.8678)  Acc@1: 87.5000 (85.8839)  Acc@5: 100.0000 (97.5331)  time: 0.2149  data: 0.0004  max mem: 2500
Test: [Task 1]  [1030/1627]  eta: 0:02:09  Loss: 0.6333 (0.8660)  Acc@1: 87.5000 (85.9239)  Acc@5: 100.0000 (97.5509)  time: 0.2159  data: 0.0003  max mem: 2500
Test: [Task 1]  [1040/1627]  eta: 0:02:07  Loss: 0.6034 (0.8645)  Acc@1: 87.5000 (85.9450)  Acc@5: 100.0000 (97.5684)  time: 0.2160  data: 0.0004  max mem: 2500
Test: [Task 1]  [1050/1627]  eta: 0:02:05  Loss: 0.7084 (0.8631)  Acc@1: 87.5000 (85.9657)  Acc@5: 100.0000 (97.5678)  time: 0.2158  data: 0.0006  max mem: 2500
Test: [Task 1]  [1060/1627]  eta: 0:02:02  Loss: 0.8162 (0.8638)  Acc@1: 87.5000 (85.9508)  Acc@5: 100.0000 (97.5554)  time: 0.2156  data: 0.0006  max mem: 2500
Test: [Task 1]  [1070/1627]  eta: 0:02:00  Loss: 0.8296 (0.8643)  Acc@1: 87.5000 (85.9711)  Acc@5: 100.0000 (97.5490)  time: 0.2150  data: 0.0004  max mem: 2500
Test: [Task 1]  [1080/1627]  eta: 0:01:58  Loss: 0.7630 (0.8648)  Acc@1: 87.5000 (85.9621)  Acc@5: 100.0000 (97.5428)  time: 0.2159  data: 0.0007  max mem: 2500
Test: [Task 1]  [1090/1627]  eta: 0:01:56  Loss: 0.8143 (0.8650)  Acc@1: 87.5000 (85.9762)  Acc@5: 100.0000 (97.5424)  time: 0.2163  data: 0.0007  max mem: 2500
Test: [Task 1]  [1100/1627]  eta: 0:01:54  Loss: 0.7702 (0.8635)  Acc@1: 87.5000 (86.0070)  Acc@5: 100.0000 (97.5477)  time: 0.2163  data: 0.0004  max mem: 2500
Test: [Task 1]  [1110/1627]  eta: 0:01:52  Loss: 0.6626 (0.8634)  Acc@1: 87.5000 (86.0149)  Acc@5: 100.0000 (97.5416)  time: 0.2177  data: 0.0013  max mem: 2500
Test: [Task 1]  [1120/1627]  eta: 0:01:49  Loss: 0.7943 (0.8644)  Acc@1: 81.2500 (85.9779)  Acc@5: 100.0000 (97.5245)  time: 0.2175  data: 0.0013  max mem: 2500
Test: [Task 1]  [1130/1627]  eta: 0:01:47  Loss: 0.7943 (0.8646)  Acc@1: 81.2500 (85.9748)  Acc@5: 100.0000 (97.5188)  time: 0.2161  data: 0.0005  max mem: 2500
Test: [Task 1]  [1140/1627]  eta: 0:01:45  Loss: 0.8784 (0.8657)  Acc@1: 87.5000 (85.9498)  Acc@5: 100.0000 (97.5186)  time: 0.2162  data: 0.0006  max mem: 2500
Test: [Task 1]  [1150/1627]  eta: 0:01:43  Loss: 0.9641 (0.8664)  Acc@1: 81.2500 (85.8981)  Acc@5: 100.0000 (97.5239)  time: 0.2161  data: 0.0007  max mem: 2500
Test: [Task 1]  [1160/1627]  eta: 0:01:41  Loss: 0.8558 (0.8654)  Acc@1: 81.2500 (85.9281)  Acc@5: 100.0000 (97.5345)  time: 0.2159  data: 0.0009  max mem: 2500
Test: [Task 1]  [1170/1627]  eta: 0:01:39  Loss: 0.7726 (0.8644)  Acc@1: 93.7500 (85.9468)  Acc@5: 100.0000 (97.5502)  time: 0.2164  data: 0.0007  max mem: 2500
Test: [Task 1]  [1180/1627]  eta: 0:01:36  Loss: 0.8325 (0.8647)  Acc@1: 87.5000 (85.9441)  Acc@5: 100.0000 (97.5603)  time: 0.2165  data: 0.0005  max mem: 2500
Test: [Task 1]  [1190/1627]  eta: 0:01:34  Loss: 0.8658 (0.8653)  Acc@1: 81.2500 (85.9257)  Acc@5: 100.0000 (97.5703)  time: 0.2160  data: 0.0006  max mem: 2500
Test: [Task 1]  [1200/1627]  eta: 0:01:32  Loss: 0.8666 (0.8652)  Acc@1: 81.2500 (85.9336)  Acc@5: 100.0000 (97.5645)  time: 0.2164  data: 0.0005  max mem: 2500
Test: [Task 1]  [1210/1627]  eta: 0:01:30  Loss: 0.7416 (0.8659)  Acc@1: 81.2500 (85.8898)  Acc@5: 100.0000 (97.5640)  time: 0.2166  data: 0.0005  max mem: 2500
Test: [Task 1]  [1220/1627]  eta: 0:01:28  Loss: 0.7162 (0.8651)  Acc@1: 81.2500 (85.8825)  Acc@5: 100.0000 (97.5737)  time: 0.2171  data: 0.0005  max mem: 2500
Test: [Task 1]  [1230/1627]  eta: 0:01:26  Loss: 0.8706 (0.8657)  Acc@1: 81.2500 (85.8245)  Acc@5: 100.0000 (97.5833)  time: 0.2167  data: 0.0005  max mem: 2500
Test: [Task 1]  [1240/1627]  eta: 0:01:23  Loss: 0.8706 (0.8655)  Acc@1: 81.2500 (85.8229)  Acc@5: 100.0000 (97.5826)  time: 0.2171  data: 0.0004  max mem: 2500
Test: [Task 1]  [1250/1627]  eta: 0:01:21  Loss: 0.9259 (0.8658)  Acc@1: 87.5000 (85.8263)  Acc@5: 100.0000 (97.5869)  time: 0.2169  data: 0.0004  max mem: 2500
Test: [Task 1]  [1260/1627]  eta: 0:01:19  Loss: 0.8579 (0.8656)  Acc@1: 87.5000 (85.8297)  Acc@5: 100.0000 (97.5813)  time: 0.2155  data: 0.0004  max mem: 2500
Test: [Task 1]  [1270/1627]  eta: 0:01:17  Loss: 0.8275 (0.8665)  Acc@1: 81.2500 (85.7887)  Acc@5: 100.0000 (97.5708)  time: 0.2157  data: 0.0003  max mem: 2500
Test: [Task 1]  [1280/1627]  eta: 0:01:15  Loss: 0.7402 (0.8650)  Acc@1: 81.2500 (85.7972)  Acc@5: 100.0000 (97.5849)  time: 0.2163  data: 0.0004  max mem: 2500
Test: [Task 1]  [1290/1627]  eta: 0:01:13  Loss: 0.7797 (0.8653)  Acc@1: 81.2500 (85.7911)  Acc@5: 100.0000 (97.5891)  time: 0.2162  data: 0.0005  max mem: 2500
Test: [Task 1]  [1300/1627]  eta: 0:01:10  Loss: 0.8682 (0.8648)  Acc@1: 87.5000 (85.8186)  Acc@5: 100.0000 (97.5932)  time: 0.2154  data: 0.0004  max mem: 2500
Test: [Task 1]  [1310/1627]  eta: 0:01:08  Loss: 0.5935 (0.8636)  Acc@1: 87.5000 (85.8553)  Acc@5: 100.0000 (97.5877)  time: 0.2157  data: 0.0004  max mem: 2500
Test: [Task 1]  [1320/1627]  eta: 0:01:06  Loss: 0.5866 (0.8621)  Acc@1: 93.7500 (85.8961)  Acc@5: 100.0000 (97.5918)  time: 0.2161  data: 0.0004  max mem: 2500
Test: [Task 1]  [1330/1627]  eta: 0:01:04  Loss: 0.6633 (0.8622)  Acc@1: 93.7500 (85.8988)  Acc@5: 100.0000 (97.5911)  time: 0.2162  data: 0.0004  max mem: 2500
Test: [Task 1]  [1340/1627]  eta: 0:01:02  Loss: 0.7982 (0.8624)  Acc@1: 87.5000 (85.8641)  Acc@5: 100.0000 (97.5997)  time: 0.2162  data: 0.0005  max mem: 2500
Test: [Task 1]  [1350/1627]  eta: 0:01:00  Loss: 0.7901 (0.8617)  Acc@1: 87.5000 (85.8855)  Acc@5: 100.0000 (97.5944)  time: 0.2161  data: 0.0006  max mem: 2500
Test: [Task 1]  [1360/1627]  eta: 0:00:57  Loss: 0.7608 (0.8612)  Acc@1: 87.5000 (85.9019)  Acc@5: 100.0000 (97.6120)  time: 0.2157  data: 0.0006  max mem: 2500
Test: [Task 1]  [1370/1627]  eta: 0:00:55  Loss: 0.7534 (0.8601)  Acc@1: 87.5000 (85.9181)  Acc@5: 100.0000 (97.6204)  time: 0.2161  data: 0.0005  max mem: 2500
Test: [Task 1]  [1380/1627]  eta: 0:00:53  Loss: 0.7575 (0.8602)  Acc@1: 87.5000 (85.9115)  Acc@5: 100.0000 (97.6150)  time: 0.2170  data: 0.0005  max mem: 2500
Test: [Task 1]  [1390/1627]  eta: 0:00:51  Loss: 0.9055 (0.8597)  Acc@1: 87.5000 (85.9094)  Acc@5: 100.0000 (97.6276)  time: 0.2180  data: 0.0005  max mem: 2500
Test: [Task 1]  [1400/1627]  eta: 0:00:49  Loss: 0.8135 (0.8602)  Acc@1: 87.5000 (85.8806)  Acc@5: 100.0000 (97.6133)  time: 0.2196  data: 0.0006  max mem: 2500
Test: [Task 1]  [1410/1627]  eta: 0:00:47  Loss: 0.6863 (0.8597)  Acc@1: 87.5000 (85.9098)  Acc@5: 100.0000 (97.6214)  time: 0.2188  data: 0.0005  max mem: 2500
Test: [Task 1]  [1420/1627]  eta: 0:00:44  Loss: 0.7178 (0.8591)  Acc@1: 87.5000 (85.9210)  Acc@5: 100.0000 (97.6337)  time: 0.2168  data: 0.0004  max mem: 2500
Test: [Task 1]  [1430/1627]  eta: 0:00:42  Loss: 0.9625 (0.8612)  Acc@1: 81.2500 (85.8927)  Acc@5: 100.0000 (97.5978)  time: 0.2177  data: 0.0005  max mem: 2500
Test: [Task 1]  [1440/1627]  eta: 0:00:40  Loss: 0.8942 (0.8608)  Acc@1: 81.2500 (85.8952)  Acc@5: 100.0000 (97.6058)  time: 0.2179  data: 0.0005  max mem: 2500
Test: [Task 1]  [1450/1627]  eta: 0:00:38  Loss: 0.8903 (0.8620)  Acc@1: 81.2500 (85.8675)  Acc@5: 100.0000 (97.6008)  time: 0.2162  data: 0.0004  max mem: 2500
Test: [Task 1]  [1460/1627]  eta: 0:00:36  Loss: 0.9363 (0.8622)  Acc@1: 87.5000 (85.8616)  Acc@5: 100.0000 (97.5873)  time: 0.2156  data: 0.0004  max mem: 2500
Test: [Task 1]  [1470/1627]  eta: 0:00:34  Loss: 0.7939 (0.8626)  Acc@1: 87.5000 (85.8472)  Acc@5: 100.0000 (97.5824)  time: 0.2159  data: 0.0004  max mem: 2500
Test: [Task 1]  [1480/1627]  eta: 0:00:31  Loss: 0.9037 (0.8628)  Acc@1: 87.5000 (85.8415)  Acc@5: 100.0000 (97.5692)  time: 0.2169  data: 0.0005  max mem: 2500
Test: [Task 1]  [1490/1627]  eta: 0:00:29  Loss: 0.9054 (0.8633)  Acc@1: 87.5000 (85.8400)  Acc@5: 100.0000 (97.5604)  time: 0.2171  data: 0.0005  max mem: 2500
Test: [Task 1]  [1500/1627]  eta: 0:00:27  Loss: 0.8738 (0.8636)  Acc@1: 87.5000 (85.8428)  Acc@5: 100.0000 (97.5475)  time: 0.2166  data: 0.0004  max mem: 2500
Test: [Task 1]  [1510/1627]  eta: 0:00:25  Loss: 0.6781 (0.8635)  Acc@1: 87.5000 (85.8661)  Acc@5: 100.0000 (97.5430)  time: 0.2171  data: 0.0004  max mem: 2500
Test: [Task 1]  [1520/1627]  eta: 0:00:23  Loss: 0.6618 (0.8623)  Acc@1: 93.7500 (85.8933)  Acc@5: 100.0000 (97.5510)  time: 0.2166  data: 0.0004  max mem: 2500
Test: [Task 1]  [1530/1627]  eta: 0:00:21  Loss: 0.6618 (0.8617)  Acc@1: 87.5000 (85.8752)  Acc@5: 100.0000 (97.5588)  time: 0.2159  data: 0.0004  max mem: 2500
Test: [Task 1]  [1540/1627]  eta: 0:00:18  Loss: 0.6113 (0.8607)  Acc@1: 93.7500 (85.8980)  Acc@5: 100.0000 (97.5665)  time: 0.2169  data: 0.0005  max mem: 2500
Test: [Task 1]  [1550/1627]  eta: 0:00:16  Loss: 0.6136 (0.8600)  Acc@1: 93.7500 (85.9083)  Acc@5: 100.0000 (97.5701)  time: 0.2167  data: 0.0005  max mem: 2500
Test: [Task 1]  [1560/1627]  eta: 0:00:14  Loss: 0.6136 (0.8592)  Acc@1: 87.5000 (85.9305)  Acc@5: 100.0000 (97.5737)  time: 0.2161  data: 0.0003  max mem: 2500
Test: [Task 1]  [1570/1627]  eta: 0:00:12  Loss: 0.7600 (0.8591)  Acc@1: 87.5000 (85.9564)  Acc@5: 100.0000 (97.5692)  time: 0.2162  data: 0.0003  max mem: 2500
Test: [Task 1]  [1580/1627]  eta: 0:00:10  Loss: 0.7700 (0.8595)  Acc@1: 87.5000 (85.9385)  Acc@5: 100.0000 (97.5727)  time: 0.2163  data: 0.0004  max mem: 2500
Test: [Task 1]  [1590/1627]  eta: 0:00:08  Loss: 0.7741 (0.8594)  Acc@1: 87.5000 (85.9326)  Acc@5: 100.0000 (97.5801)  time: 0.2166  data: 0.0004  max mem: 2500
Test: [Task 1]  [1600/1627]  eta: 0:00:05  Loss: 0.8048 (0.8602)  Acc@1: 81.2500 (85.9229)  Acc@5: 100.0000 (97.5874)  time: 0.2170  data: 0.0004  max mem: 2500
Test: [Task 1]  [1610/1627]  eta: 0:00:03  Loss: 0.7735 (0.8596)  Acc@1: 87.5000 (85.9404)  Acc@5: 100.0000 (97.5985)  time: 0.2169  data: 0.0004  max mem: 2500
Test: [Task 1]  [1620/1627]  eta: 0:00:01  Loss: 0.7045 (0.8586)  Acc@1: 93.7500 (85.9732)  Acc@5: 100.0000 (97.5979)  time: 0.2164  data: 0.0004  max mem: 2500
Test: [Task 1]  [1626/1627]  eta: 0:00:00  Loss: 0.7045 (0.8582)  Acc@1: 93.7500 (85.9865)  Acc@5: 100.0000 (97.6030)  time: 0.2163  data: 0.0004  max mem: 2500
Test: [Task 1] Total time: 0:05:52 (0.2169 s / it)
* Acc@1 85.986 Acc@5 97.603 loss 0.858
{0: {0: 26032, 1: 26032, 2: 26032, 3: 26032, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0, 10: 0, 11: 0, 12: 0, 13: 0, 14: 0, 15: 0, 16: 0, 17: 0, 18: 0, 19: 0}}
[Average accuracy till task1]	Acc@1: 85.9865	Acc@5: 97.6030	Loss: 0.8582
Train: Epoch[1/5]  [   0/3750]  eta: 0:54:26  Lr: 0.001875  Loss: 1.6985  Acc@1: 31.2500 (31.2500)  Acc@5: 43.7500 (43.7500)  time: 0.8711  data: 0.4915  max mem: 2500
Train: Epoch[1/5]  [  10/3750]  eta: 0:24:50  Lr: 0.001875  Loss: 1.3448  Acc@1: 31.2500 (27.2727)  Acc@5: 62.5000 (61.3636)  time: 0.3985  data: 0.0455  max mem: 2500
Train: Epoch[1/5]  [  20/3750]  eta: 0:23:17  Lr: 0.001875  Loss: 1.3326  Acc@1: 25.0000 (28.2738)  Acc@5: 68.7500 (68.1548)  time: 0.3499  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [  30/3750]  eta: 0:22:42  Lr: 0.001875  Loss: 1.0945  Acc@1: 37.5000 (34.6774)  Acc@5: 81.2500 (74.3952)  time: 0.3486  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [  40/3750]  eta: 0:22:22  Lr: 0.001875  Loss: 1.1210  Acc@1: 50.0000 (40.0915)  Acc@5: 93.7500 (78.6585)  time: 0.3484  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [  50/3750]  eta: 0:22:10  Lr: 0.001875  Loss: 0.6856  Acc@1: 56.2500 (43.8725)  Acc@5: 93.7500 (80.6373)  time: 0.3492  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [  60/3750]  eta: 0:22:00  Lr: 0.001875  Loss: 0.5740  Acc@1: 56.2500 (46.3115)  Acc@5: 93.7500 (82.7869)  time: 0.3495  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [  70/3750]  eta: 0:21:55  Lr: 0.001875  Loss: 1.0242  Acc@1: 56.2500 (47.9754)  Acc@5: 93.7500 (84.3310)  time: 0.3517  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [  80/3750]  eta: 0:21:49  Lr: 0.001875  Loss: -0.0459  Acc@1: 62.5000 (49.9228)  Acc@5: 93.7500 (85.7253)  time: 0.3532  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [  90/3750]  eta: 0:21:41  Lr: 0.001875  Loss: 0.5191  Acc@1: 62.5000 (51.8544)  Acc@5: 93.7500 (86.4698)  time: 0.3498  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [ 100/3750]  eta: 0:21:36  Lr: 0.001875  Loss: 0.1334  Acc@1: 68.7500 (53.6510)  Acc@5: 93.7500 (87.3762)  time: 0.3490  data: 0.0013  max mem: 2500
Train: Epoch[1/5]  [ 110/3750]  eta: 0:21:31  Lr: 0.001875  Loss: 0.3697  Acc@1: 68.7500 (55.5180)  Acc@5: 93.7500 (87.9505)  time: 0.3509  data: 0.0014  max mem: 2500
Train: Epoch[1/5]  [ 120/3750]  eta: 0:21:26  Lr: 0.001875  Loss: 0.0045  Acc@1: 68.7500 (56.9215)  Acc@5: 93.7500 (88.5331)  time: 0.3500  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [ 130/3750]  eta: 0:21:21  Lr: 0.001875  Loss: 0.1176  Acc@1: 68.7500 (57.5382)  Acc@5: 93.7500 (88.9313)  time: 0.3489  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [ 140/3750]  eta: 0:21:16  Lr: 0.001875  Loss: -0.0284  Acc@1: 62.5000 (58.2447)  Acc@5: 93.7500 (89.3174)  time: 0.3497  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [ 150/3750]  eta: 0:21:12  Lr: 0.001875  Loss: 0.1218  Acc@1: 68.7500 (59.1060)  Acc@5: 93.7500 (89.6937)  time: 0.3495  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [ 160/3750]  eta: 0:21:07  Lr: 0.001875  Loss: -0.2336  Acc@1: 68.7500 (59.8214)  Acc@5: 100.0000 (90.2174)  time: 0.3496  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [ 170/3750]  eta: 0:21:03  Lr: 0.001875  Loss: 0.1388  Acc@1: 68.7500 (60.4167)  Acc@5: 100.0000 (90.4971)  time: 0.3502  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [ 180/3750]  eta: 0:20:59  Lr: 0.001875  Loss: -0.2198  Acc@1: 75.0000 (61.0497)  Acc@5: 93.7500 (90.6768)  time: 0.3498  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [ 190/3750]  eta: 0:20:55  Lr: 0.001875  Loss: 0.0230  Acc@1: 68.7500 (61.3220)  Acc@5: 93.7500 (90.7395)  time: 0.3499  data: 0.0013  max mem: 2500
Train: Epoch[1/5]  [ 200/3750]  eta: 0:20:51  Lr: 0.001875  Loss: -0.3425  Acc@1: 68.7500 (61.9092)  Acc@5: 93.7500 (91.0137)  time: 0.3492  data: 0.0013  max mem: 2500
Train: Epoch[1/5]  [ 210/3750]  eta: 0:20:46  Lr: 0.001875  Loss: -0.4012  Acc@1: 68.7500 (62.4704)  Acc@5: 93.7500 (91.2026)  time: 0.3479  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [ 220/3750]  eta: 0:20:42  Lr: 0.001875  Loss: -0.1480  Acc@1: 68.7500 (62.8676)  Acc@5: 93.7500 (91.3744)  time: 0.3482  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [ 230/3750]  eta: 0:20:39  Lr: 0.001875  Loss: -0.0669  Acc@1: 68.7500 (63.2576)  Acc@5: 93.7500 (91.3961)  time: 0.3497  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [ 240/3750]  eta: 0:20:35  Lr: 0.001875  Loss: 0.0262  Acc@1: 68.7500 (63.5892)  Acc@5: 93.7500 (91.5716)  time: 0.3503  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [ 250/3750]  eta: 0:20:31  Lr: 0.001875  Loss: -0.3496  Acc@1: 75.0000 (64.1185)  Acc@5: 93.7500 (91.5588)  time: 0.3504  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [ 260/3750]  eta: 0:20:27  Lr: 0.001875  Loss: -0.4825  Acc@1: 75.0000 (64.7270)  Acc@5: 93.7500 (91.6906)  time: 0.3497  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 270/3750]  eta: 0:20:23  Lr: 0.001875  Loss: -0.7214  Acc@1: 81.2500 (65.2214)  Acc@5: 100.0000 (91.9050)  time: 0.3484  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 280/3750]  eta: 0:20:19  Lr: 0.001875  Loss: -0.0093  Acc@1: 75.0000 (65.4804)  Acc@5: 100.0000 (91.9929)  time: 0.3482  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [ 290/3750]  eta: 0:20:15  Lr: 0.001875  Loss: -0.4116  Acc@1: 75.0000 (65.7431)  Acc@5: 93.7500 (92.0962)  time: 0.3485  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [ 300/3750]  eta: 0:20:12  Lr: 0.001875  Loss: -0.6053  Acc@1: 75.0000 (66.0922)  Acc@5: 93.7500 (92.0889)  time: 0.3496  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [ 310/3750]  eta: 0:20:08  Lr: 0.001875  Loss: -0.7602  Acc@1: 75.0000 (66.3585)  Acc@5: 93.7500 (92.2227)  time: 0.3497  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [ 320/3750]  eta: 0:20:04  Lr: 0.001875  Loss: -0.5693  Acc@1: 75.0000 (66.6472)  Acc@5: 93.7500 (92.3676)  time: 0.3481  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 330/3750]  eta: 0:20:00  Lr: 0.001875  Loss: -0.5152  Acc@1: 75.0000 (66.7674)  Acc@5: 100.0000 (92.4849)  time: 0.3476  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [ 340/3750]  eta: 0:19:56  Lr: 0.001875  Loss: -0.6290  Acc@1: 75.0000 (67.1004)  Acc@5: 93.7500 (92.5220)  time: 0.3488  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [ 350/3750]  eta: 0:19:53  Lr: 0.001875  Loss: -0.2379  Acc@1: 68.7500 (67.1830)  Acc@5: 93.7500 (92.5214)  time: 0.3482  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [ 360/3750]  eta: 0:19:49  Lr: 0.001875  Loss: 0.0529  Acc@1: 68.7500 (67.4169)  Acc@5: 93.7500 (92.5727)  time: 0.3471  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [ 370/3750]  eta: 0:19:45  Lr: 0.001875  Loss: -0.2687  Acc@1: 68.7500 (67.5708)  Acc@5: 93.7500 (92.6213)  time: 0.3480  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [ 380/3750]  eta: 0:19:41  Lr: 0.001875  Loss: -0.9236  Acc@1: 75.0000 (67.7822)  Acc@5: 93.7500 (92.7657)  time: 0.3482  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [ 390/3750]  eta: 0:19:38  Lr: 0.001875  Loss: -1.1102  Acc@1: 75.0000 (67.9188)  Acc@5: 100.0000 (92.7909)  time: 0.3496  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [ 400/3750]  eta: 0:19:34  Lr: 0.001875  Loss: -0.2761  Acc@1: 68.7500 (68.0954)  Acc@5: 93.7500 (92.8148)  time: 0.3504  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [ 410/3750]  eta: 0:19:31  Lr: 0.001875  Loss: -0.3370  Acc@1: 75.0000 (68.2330)  Acc@5: 93.7500 (92.8680)  time: 0.3500  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [ 420/3750]  eta: 0:19:27  Lr: 0.001875  Loss: -0.6823  Acc@1: 75.0000 (68.3640)  Acc@5: 93.7500 (92.9335)  time: 0.3491  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [ 430/3750]  eta: 0:19:23  Lr: 0.001875  Loss: -0.6611  Acc@1: 68.7500 (68.3875)  Acc@5: 93.7500 (92.9089)  time: 0.3490  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [ 440/3750]  eta: 0:19:20  Lr: 0.001875  Loss: -0.8063  Acc@1: 68.7500 (68.5516)  Acc@5: 93.7500 (92.9280)  time: 0.3487  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [ 450/3750]  eta: 0:19:16  Lr: 0.001875  Loss: -0.9742  Acc@1: 75.0000 (68.6946)  Acc@5: 93.7500 (92.9324)  time: 0.3477  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [ 460/3750]  eta: 0:19:12  Lr: 0.001875  Loss: -0.7333  Acc@1: 81.2500 (68.9127)  Acc@5: 93.7500 (93.0179)  time: 0.3494  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [ 470/3750]  eta: 0:19:09  Lr: 0.001875  Loss: -0.2510  Acc@1: 75.0000 (69.0154)  Acc@5: 93.7500 (92.9936)  time: 0.3492  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [ 480/3750]  eta: 0:19:05  Lr: 0.001875  Loss: -0.2838  Acc@1: 75.0000 (69.2698)  Acc@5: 93.7500 (93.0353)  time: 0.3477  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [ 490/3750]  eta: 0:19:01  Lr: 0.001875  Loss: -0.2079  Acc@1: 81.2500 (69.3228)  Acc@5: 93.7500 (93.1008)  time: 0.3475  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [ 500/3750]  eta: 0:18:58  Lr: 0.001875  Loss: -0.9493  Acc@1: 68.7500 (69.3488)  Acc@5: 93.7500 (93.1138)  time: 0.3472  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [ 510/3750]  eta: 0:18:54  Lr: 0.001875  Loss: -0.6249  Acc@1: 75.0000 (69.5205)  Acc@5: 93.7500 (93.1874)  time: 0.3481  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [ 520/3750]  eta: 0:18:50  Lr: 0.001875  Loss: -0.7261  Acc@1: 75.0000 (69.6257)  Acc@5: 100.0000 (93.2462)  time: 0.3482  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [ 530/3750]  eta: 0:18:47  Lr: 0.001875  Loss: -0.7087  Acc@1: 75.0000 (69.7622)  Acc@5: 93.7500 (93.2556)  time: 0.3492  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [ 540/3750]  eta: 0:18:43  Lr: 0.001875  Loss: -0.2657  Acc@1: 75.0000 (69.8244)  Acc@5: 93.7500 (93.3226)  time: 0.3496  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [ 550/3750]  eta: 0:18:40  Lr: 0.001875  Loss: -0.9980  Acc@1: 75.0000 (69.8503)  Acc@5: 93.7500 (93.3190)  time: 0.3480  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [ 560/3750]  eta: 0:18:36  Lr: 0.001875  Loss: -0.5803  Acc@1: 68.7500 (69.8752)  Acc@5: 93.7500 (93.3601)  time: 0.3480  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [ 570/3750]  eta: 0:18:33  Lr: 0.001875  Loss: -0.9158  Acc@1: 68.7500 (70.0088)  Acc@5: 93.7500 (93.3888)  time: 0.3496  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [ 580/3750]  eta: 0:18:29  Lr: 0.001875  Loss: -0.2296  Acc@1: 75.0000 (70.0194)  Acc@5: 93.7500 (93.4488)  time: 0.3516  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [ 590/3750]  eta: 0:18:26  Lr: 0.001875  Loss: -0.5633  Acc@1: 75.0000 (70.1988)  Acc@5: 100.0000 (93.4750)  time: 0.3495  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [ 600/3750]  eta: 0:18:22  Lr: 0.001875  Loss: -0.9300  Acc@1: 75.0000 (70.1747)  Acc@5: 93.7500 (93.4900)  time: 0.3481  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [ 610/3750]  eta: 0:18:18  Lr: 0.001875  Loss: -0.9267  Acc@1: 68.7500 (70.2230)  Acc@5: 93.7500 (93.4840)  time: 0.3483  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [ 620/3750]  eta: 0:18:15  Lr: 0.001875  Loss: -0.6417  Acc@1: 68.7500 (70.2093)  Acc@5: 93.7500 (93.4783)  time: 0.3471  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [ 630/3750]  eta: 0:18:11  Lr: 0.001875  Loss: -0.6303  Acc@1: 75.0000 (70.2952)  Acc@5: 93.7500 (93.5222)  time: 0.3483  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [ 640/3750]  eta: 0:18:08  Lr: 0.001875  Loss: -0.5889  Acc@1: 68.7500 (70.1931)  Acc@5: 93.7500 (93.4672)  time: 0.3484  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [ 650/3750]  eta: 0:18:04  Lr: 0.001875  Loss: -0.5632  Acc@1: 68.7500 (70.2573)  Acc@5: 87.5000 (93.4716)  time: 0.3474  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [ 660/3750]  eta: 0:18:00  Lr: 0.001875  Loss: -0.5798  Acc@1: 75.0000 (70.3858)  Acc@5: 100.0000 (93.5514)  time: 0.3483  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [ 670/3750]  eta: 0:17:57  Lr: 0.001875  Loss: -0.8245  Acc@1: 75.0000 (70.4545)  Acc@5: 100.0000 (93.6010)  time: 0.3483  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [ 680/3750]  eta: 0:17:53  Lr: 0.001875  Loss: -0.6106  Acc@1: 75.0000 (70.5121)  Acc@5: 93.7500 (93.6123)  time: 0.3473  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [ 690/3750]  eta: 0:17:50  Lr: 0.001875  Loss: -0.6777  Acc@1: 75.0000 (70.5771)  Acc@5: 93.7500 (93.6234)  time: 0.3474  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [ 700/3750]  eta: 0:17:46  Lr: 0.001875  Loss: -0.8435  Acc@1: 75.0000 (70.6669)  Acc@5: 93.7500 (93.6252)  time: 0.3482  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [ 710/3750]  eta: 0:17:43  Lr: 0.001875  Loss: -0.7828  Acc@1: 81.2500 (70.8158)  Acc@5: 93.7500 (93.6709)  time: 0.3493  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [ 720/3750]  eta: 0:17:39  Lr: 0.001875  Loss: -0.6922  Acc@1: 75.0000 (70.7784)  Acc@5: 93.7500 (93.6893)  time: 0.3493  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [ 730/3750]  eta: 0:17:36  Lr: 0.001875  Loss: -1.1568  Acc@1: 68.7500 (70.7934)  Acc@5: 93.7500 (93.7158)  time: 0.3494  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [ 740/3750]  eta: 0:17:32  Lr: 0.001875  Loss: -0.6878  Acc@1: 75.0000 (70.9345)  Acc@5: 100.0000 (93.7753)  time: 0.3515  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [ 750/3750]  eta: 0:17:29  Lr: 0.001875  Loss: -0.9112  Acc@1: 81.2500 (71.0136)  Acc@5: 100.0000 (93.7999)  time: 0.3505  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [ 760/3750]  eta: 0:17:25  Lr: 0.001875  Loss: -1.1091  Acc@1: 81.2500 (71.1646)  Acc@5: 93.7500 (93.7993)  time: 0.3477  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 770/3750]  eta: 0:17:22  Lr: 0.001875  Loss: -0.8910  Acc@1: 81.2500 (71.2954)  Acc@5: 93.7500 (93.8149)  time: 0.3485  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [ 780/3750]  eta: 0:17:18  Lr: 0.001875  Loss: -0.3892  Acc@1: 81.2500 (71.3428)  Acc@5: 93.7500 (93.8140)  time: 0.3485  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [ 790/3750]  eta: 0:17:15  Lr: 0.001875  Loss: -1.0607  Acc@1: 75.0000 (71.3417)  Acc@5: 93.7500 (93.8369)  time: 0.3484  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [ 800/3750]  eta: 0:17:11  Lr: 0.001875  Loss: -1.0343  Acc@1: 68.7500 (71.4107)  Acc@5: 93.7500 (93.8436)  time: 0.3489  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [ 810/3750]  eta: 0:17:07  Lr: 0.001875  Loss: -0.5721  Acc@1: 81.2500 (71.4550)  Acc@5: 93.7500 (93.8502)  time: 0.3487  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [ 820/3750]  eta: 0:17:04  Lr: 0.001875  Loss: -1.2260  Acc@1: 81.2500 (71.6124)  Acc@5: 93.7500 (93.8946)  time: 0.3494  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [ 830/3750]  eta: 0:17:00  Lr: 0.001875  Loss: -1.1098  Acc@1: 75.0000 (71.6080)  Acc@5: 93.7500 (93.8929)  time: 0.3497  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [ 840/3750]  eta: 0:16:57  Lr: 0.001875  Loss: -0.7391  Acc@1: 75.0000 (71.6706)  Acc@5: 93.7500 (93.8912)  time: 0.3490  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [ 850/3750]  eta: 0:16:53  Lr: 0.001875  Loss: -0.7418  Acc@1: 75.0000 (71.7318)  Acc@5: 93.7500 (93.9336)  time: 0.3488  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [ 860/3750]  eta: 0:16:50  Lr: 0.001875  Loss: -0.6366  Acc@1: 68.7500 (71.7189)  Acc@5: 100.0000 (93.9533)  time: 0.3501  data: 0.0012  max mem: 2500
Train: Epoch[1/5]  [ 870/3750]  eta: 0:16:46  Lr: 0.001875  Loss: -0.6542  Acc@1: 68.7500 (71.7423)  Acc@5: 93.7500 (93.9509)  time: 0.3505  data: 0.0012  max mem: 2500
Train: Epoch[1/5]  [ 880/3750]  eta: 0:16:43  Lr: 0.001875  Loss: -1.0111  Acc@1: 81.2500 (71.8147)  Acc@5: 93.7500 (93.9699)  time: 0.3497  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [ 890/3750]  eta: 0:16:40  Lr: 0.001875  Loss: -0.7308  Acc@1: 81.2500 (71.9066)  Acc@5: 100.0000 (94.0095)  time: 0.3509  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [ 900/3750]  eta: 0:16:36  Lr: 0.001875  Loss: -0.4526  Acc@1: 81.2500 (71.9895)  Acc@5: 93.7500 (94.0136)  time: 0.3495  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 910/3750]  eta: 0:16:32  Lr: 0.001875  Loss: -1.1942  Acc@1: 81.2500 (72.0980)  Acc@5: 93.7500 (94.0313)  time: 0.3480  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [ 920/3750]  eta: 0:16:29  Lr: 0.001875  Loss: -0.4041  Acc@1: 81.2500 (72.1906)  Acc@5: 93.7500 (94.0486)  time: 0.3497  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [ 930/3750]  eta: 0:16:25  Lr: 0.001875  Loss: -0.9077  Acc@1: 81.2500 (72.2140)  Acc@5: 93.7500 (94.0521)  time: 0.3493  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 940/3750]  eta: 0:16:22  Lr: 0.001875  Loss: -0.9019  Acc@1: 75.0000 (72.2768)  Acc@5: 93.7500 (94.0622)  time: 0.3488  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [ 950/3750]  eta: 0:16:18  Lr: 0.001875  Loss: -0.5618  Acc@1: 75.0000 (72.3580)  Acc@5: 93.7500 (94.0917)  time: 0.3491  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [ 960/3750]  eta: 0:16:15  Lr: 0.001875  Loss: -0.5076  Acc@1: 81.2500 (72.4441)  Acc@5: 93.7500 (94.1207)  time: 0.3500  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [ 970/3750]  eta: 0:16:11  Lr: 0.001875  Loss: -0.6445  Acc@1: 75.0000 (72.5026)  Acc@5: 93.7500 (94.1105)  time: 0.3503  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [ 980/3750]  eta: 0:16:08  Lr: 0.001875  Loss: -0.8647  Acc@1: 75.0000 (72.5663)  Acc@5: 93.7500 (94.1450)  time: 0.3509  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [ 990/3750]  eta: 0:16:05  Lr: 0.001875  Loss: -0.9515  Acc@1: 81.2500 (72.6602)  Acc@5: 100.0000 (94.1599)  time: 0.3513  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [1000/3750]  eta: 0:16:01  Lr: 0.001875  Loss: -0.7837  Acc@1: 81.2500 (72.6586)  Acc@5: 93.7500 (94.1434)  time: 0.3495  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [1010/3750]  eta: 0:15:58  Lr: 0.001875  Loss: -0.9001  Acc@1: 75.0000 (72.6818)  Acc@5: 93.7500 (94.1271)  time: 0.3489  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1020/3750]  eta: 0:15:54  Lr: 0.001875  Loss: -0.9319  Acc@1: 75.0000 (72.7289)  Acc@5: 93.7500 (94.1601)  time: 0.3502  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1030/3750]  eta: 0:15:51  Lr: 0.001875  Loss: -0.7917  Acc@1: 75.0000 (72.7449)  Acc@5: 100.0000 (94.1743)  time: 0.3513  data: 0.0014  max mem: 2500
Train: Epoch[1/5]  [1040/3750]  eta: 0:15:47  Lr: 0.001875  Loss: -0.7562  Acc@1: 75.0000 (72.7966)  Acc@5: 100.0000 (94.2063)  time: 0.3503  data: 0.0013  max mem: 2500
Train: Epoch[1/5]  [1050/3750]  eta: 0:15:44  Lr: 0.001875  Loss: -1.0530  Acc@1: 81.2500 (72.8294)  Acc@5: 100.0000 (94.2138)  time: 0.3492  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1060/3750]  eta: 0:15:40  Lr: 0.001875  Loss: -0.7680  Acc@1: 81.2500 (72.8676)  Acc@5: 93.7500 (94.2271)  time: 0.3509  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [1070/3750]  eta: 0:15:37  Lr: 0.001875  Loss: -0.9351  Acc@1: 81.2500 (72.9283)  Acc@5: 93.7500 (94.2519)  time: 0.3516  data: 0.0013  max mem: 2500
Train: Epoch[1/5]  [1080/3750]  eta: 0:15:33  Lr: 0.001875  Loss: -1.1810  Acc@1: 81.2500 (72.9302)  Acc@5: 100.0000 (94.2646)  time: 0.3503  data: 0.0013  max mem: 2500
Train: Epoch[1/5]  [1090/3750]  eta: 0:15:30  Lr: 0.001875  Loss: -1.3178  Acc@1: 68.7500 (72.9720)  Acc@5: 100.0000 (94.2885)  time: 0.3508  data: 0.0013  max mem: 2500
Train: Epoch[1/5]  [1100/3750]  eta: 0:15:26  Lr: 0.001875  Loss: -0.7171  Acc@1: 81.2500 (73.0245)  Acc@5: 100.0000 (94.3063)  time: 0.3502  data: 0.0013  max mem: 2500
Train: Epoch[1/5]  [1110/3750]  eta: 0:15:23  Lr: 0.001875  Loss: -0.8671  Acc@1: 81.2500 (73.0648)  Acc@5: 93.7500 (94.3182)  time: 0.3489  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1120/3750]  eta: 0:15:19  Lr: 0.001875  Loss: -0.5275  Acc@1: 81.2500 (73.1490)  Acc@5: 93.7500 (94.3298)  time: 0.3496  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [1130/3750]  eta: 0:15:16  Lr: 0.001875  Loss: -0.9122  Acc@1: 87.5000 (73.2372)  Acc@5: 93.7500 (94.3523)  time: 0.3489  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1140/3750]  eta: 0:15:12  Lr: 0.001875  Loss: -0.7150  Acc@1: 81.2500 (73.2472)  Acc@5: 100.0000 (94.3690)  time: 0.3491  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1150/3750]  eta: 0:15:09  Lr: 0.001875  Loss: -0.6190  Acc@1: 81.2500 (73.2678)  Acc@5: 100.0000 (94.4016)  time: 0.3511  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [1160/3750]  eta: 0:15:05  Lr: 0.001875  Loss: -0.8487  Acc@1: 81.2500 (73.2720)  Acc@5: 100.0000 (94.4175)  time: 0.3534  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [1170/3750]  eta: 0:15:02  Lr: 0.001875  Loss: -0.6672  Acc@1: 68.7500 (73.2867)  Acc@5: 93.7500 (94.4172)  time: 0.3525  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [1180/3750]  eta: 0:14:58  Lr: 0.001875  Loss: -0.8014  Acc@1: 75.0000 (73.3277)  Acc@5: 93.7500 (94.4274)  time: 0.3503  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [1190/3750]  eta: 0:14:55  Lr: 0.001875  Loss: -0.3145  Acc@1: 75.0000 (73.3732)  Acc@5: 93.7500 (94.4479)  time: 0.3499  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [1200/3750]  eta: 0:14:52  Lr: 0.001875  Loss: -0.5305  Acc@1: 81.2500 (73.4492)  Acc@5: 100.0000 (94.4525)  time: 0.3524  data: 0.0025  max mem: 2500
Train: Epoch[1/5]  [1210/3750]  eta: 0:14:48  Lr: 0.001875  Loss: -0.9137  Acc@1: 75.0000 (73.4672)  Acc@5: 93.7500 (94.4467)  time: 0.3530  data: 0.0026  max mem: 2500
Train: Epoch[1/5]  [1220/3750]  eta: 0:14:45  Lr: 0.001875  Loss: -1.0908  Acc@1: 75.0000 (73.4848)  Acc@5: 93.7500 (94.4615)  time: 0.3517  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [1230/3750]  eta: 0:14:41  Lr: 0.001875  Loss: -0.9267  Acc@1: 75.0000 (73.4921)  Acc@5: 93.7500 (94.4506)  time: 0.3526  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1240/3750]  eta: 0:14:38  Lr: 0.001875  Loss: -0.7116  Acc@1: 75.0000 (73.5193)  Acc@5: 93.7500 (94.4551)  time: 0.3504  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1250/3750]  eta: 0:14:34  Lr: 0.001875  Loss: -0.2773  Acc@1: 75.0000 (73.5312)  Acc@5: 100.0000 (94.4794)  time: 0.3485  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [1260/3750]  eta: 0:14:31  Lr: 0.001875  Loss: -0.8242  Acc@1: 75.0000 (73.5626)  Acc@5: 100.0000 (94.4786)  time: 0.3492  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [1270/3750]  eta: 0:14:27  Lr: 0.001875  Loss: -0.8087  Acc@1: 75.0000 (73.5690)  Acc@5: 93.7500 (94.4827)  time: 0.3489  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1280/3750]  eta: 0:14:24  Lr: 0.001875  Loss: -1.0092  Acc@1: 81.2500 (73.6241)  Acc@5: 93.7500 (94.4965)  time: 0.3481  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [1290/3750]  eta: 0:14:20  Lr: 0.001875  Loss: -0.6773  Acc@1: 75.0000 (73.6348)  Acc@5: 100.0000 (94.5101)  time: 0.3478  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [1300/3750]  eta: 0:14:16  Lr: 0.001875  Loss: -0.6896  Acc@1: 75.0000 (73.6837)  Acc@5: 100.0000 (94.5331)  time: 0.3475  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [1310/3750]  eta: 0:14:13  Lr: 0.001875  Loss: -0.9356  Acc@1: 81.2500 (73.7319)  Acc@5: 100.0000 (94.5557)  time: 0.3474  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [1320/3750]  eta: 0:14:09  Lr: 0.001875  Loss: -1.1100  Acc@1: 81.2500 (73.7746)  Acc@5: 100.0000 (94.5685)  time: 0.3478  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [1330/3750]  eta: 0:14:06  Lr: 0.001875  Loss: -0.2249  Acc@1: 81.2500 (73.7979)  Acc@5: 93.7500 (94.5718)  time: 0.3491  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [1340/3750]  eta: 0:14:02  Lr: 0.001875  Loss: -1.0349  Acc@1: 81.2500 (73.7929)  Acc@5: 93.7500 (94.5843)  time: 0.3486  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [1350/3750]  eta: 0:13:59  Lr: 0.001875  Loss: -0.7098  Acc@1: 75.0000 (73.8064)  Acc@5: 100.0000 (94.5827)  time: 0.3481  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1360/3750]  eta: 0:13:55  Lr: 0.001875  Loss: -0.6196  Acc@1: 75.0000 (73.8198)  Acc@5: 100.0000 (94.6042)  time: 0.3493  data: 0.0012  max mem: 2500
Train: Epoch[1/5]  [1370/3750]  eta: 0:13:52  Lr: 0.001875  Loss: -0.7351  Acc@1: 75.0000 (73.8421)  Acc@5: 100.0000 (94.6070)  time: 0.3507  data: 0.0014  max mem: 2500
Train: Epoch[1/5]  [1380/3750]  eta: 0:13:48  Lr: 0.001875  Loss: -0.7393  Acc@1: 81.2500 (73.8867)  Acc@5: 100.0000 (94.6280)  time: 0.3511  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [1390/3750]  eta: 0:13:45  Lr: 0.001875  Loss: -0.6506  Acc@1: 75.0000 (73.8767)  Acc@5: 100.0000 (94.6352)  time: 0.3513  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [1400/3750]  eta: 0:13:41  Lr: 0.001875  Loss: -1.2442  Acc@1: 75.0000 (73.8892)  Acc@5: 93.7500 (94.6288)  time: 0.3504  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [1410/3750]  eta: 0:13:38  Lr: 0.001875  Loss: -0.9514  Acc@1: 75.0000 (73.9059)  Acc@5: 93.7500 (94.6315)  time: 0.3482  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1420/3750]  eta: 0:13:34  Lr: 0.001875  Loss: -0.4898  Acc@1: 75.0000 (73.9092)  Acc@5: 93.7500 (94.6253)  time: 0.3495  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [1430/3750]  eta: 0:13:31  Lr: 0.001875  Loss: -1.0273  Acc@1: 81.2500 (73.9430)  Acc@5: 93.7500 (94.6454)  time: 0.3496  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1440/3750]  eta: 0:13:27  Lr: 0.001875  Loss: -0.6440  Acc@1: 75.0000 (73.9070)  Acc@5: 100.0000 (94.6652)  time: 0.3482  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [1450/3750]  eta: 0:13:24  Lr: 0.001875  Loss: -0.9819  Acc@1: 75.0000 (73.9576)  Acc@5: 100.0000 (94.6890)  time: 0.3488  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [1460/3750]  eta: 0:13:20  Lr: 0.001875  Loss: -0.9152  Acc@1: 81.2500 (73.9990)  Acc@5: 100.0000 (94.7040)  time: 0.3488  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [1470/3750]  eta: 0:13:17  Lr: 0.001875  Loss: -0.9978  Acc@1: 81.2500 (74.0525)  Acc@5: 100.0000 (94.7187)  time: 0.3488  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [1480/3750]  eta: 0:13:13  Lr: 0.001875  Loss: -0.7493  Acc@1: 81.2500 (74.0969)  Acc@5: 93.7500 (94.7164)  time: 0.3486  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [1490/3750]  eta: 0:13:10  Lr: 0.001875  Loss: -0.6255  Acc@1: 81.2500 (74.1491)  Acc@5: 100.0000 (94.7435)  time: 0.3485  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [1500/3750]  eta: 0:13:06  Lr: 0.001875  Loss: -0.6750  Acc@1: 81.2500 (74.1839)  Acc@5: 100.0000 (94.7493)  time: 0.3495  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [1510/3750]  eta: 0:13:03  Lr: 0.001875  Loss: -0.9885  Acc@1: 81.2500 (74.2265)  Acc@5: 93.7500 (94.7427)  time: 0.3485  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [1520/3750]  eta: 0:12:59  Lr: 0.001875  Loss: -0.7375  Acc@1: 81.2500 (74.2809)  Acc@5: 93.7500 (94.7485)  time: 0.3477  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [1530/3750]  eta: 0:12:56  Lr: 0.001875  Loss: -0.5605  Acc@1: 81.2500 (74.3060)  Acc@5: 93.7500 (94.7542)  time: 0.3477  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [1540/3750]  eta: 0:12:52  Lr: 0.001875  Loss: -1.1364  Acc@1: 81.2500 (74.3308)  Acc@5: 93.7500 (94.7721)  time: 0.3476  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [1550/3750]  eta: 0:12:49  Lr: 0.001875  Loss: -0.7660  Acc@1: 75.0000 (74.3512)  Acc@5: 100.0000 (94.7735)  time: 0.3491  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [1560/3750]  eta: 0:12:45  Lr: 0.001875  Loss: -1.1187  Acc@1: 81.2500 (74.3914)  Acc@5: 100.0000 (94.7870)  time: 0.3485  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1570/3750]  eta: 0:12:42  Lr: 0.001875  Loss: -1.3875  Acc@1: 81.2500 (74.4430)  Acc@5: 100.0000 (94.8003)  time: 0.3494  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1580/3750]  eta: 0:12:38  Lr: 0.001875  Loss: -0.6706  Acc@1: 75.0000 (74.4268)  Acc@5: 93.7500 (94.7857)  time: 0.3497  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1590/3750]  eta: 0:12:35  Lr: 0.001875  Loss: -1.0194  Acc@1: 75.0000 (74.4500)  Acc@5: 93.7500 (94.7832)  time: 0.3470  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1600/3750]  eta: 0:12:31  Lr: 0.001875  Loss: -0.6421  Acc@1: 81.2500 (74.4496)  Acc@5: 93.7500 (94.7923)  time: 0.3473  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1610/3750]  eta: 0:12:28  Lr: 0.001875  Loss: -0.5984  Acc@1: 75.0000 (74.4452)  Acc@5: 93.7500 (94.8014)  time: 0.3481  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1620/3750]  eta: 0:12:24  Lr: 0.001875  Loss: -0.4761  Acc@1: 75.0000 (74.4255)  Acc@5: 93.7500 (94.7949)  time: 0.3493  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [1630/3750]  eta: 0:12:21  Lr: 0.001875  Loss: -0.4125  Acc@1: 75.0000 (74.4559)  Acc@5: 93.7500 (94.8038)  time: 0.3496  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1640/3750]  eta: 0:12:17  Lr: 0.001875  Loss: -0.8412  Acc@1: 75.0000 (74.4782)  Acc@5: 93.7500 (94.8088)  time: 0.3493  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1650/3750]  eta: 0:12:14  Lr: 0.001875  Loss: -0.9918  Acc@1: 81.2500 (74.5079)  Acc@5: 93.7500 (94.8100)  time: 0.3494  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [1660/3750]  eta: 0:12:10  Lr: 0.001875  Loss: -0.9534  Acc@1: 81.2500 (74.5259)  Acc@5: 93.7500 (94.8111)  time: 0.3495  data: 0.0009  max mem: 2500
Train: Epoch[1/5]  [1670/3750]  eta: 0:12:07  Lr: 0.001875  Loss: -0.9287  Acc@1: 81.2500 (74.5661)  Acc@5: 93.7500 (94.8085)  time: 0.3497  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [1680/3750]  eta: 0:12:03  Lr: 0.001875  Loss: -1.0646  Acc@1: 81.2500 (74.5836)  Acc@5: 93.7500 (94.8134)  time: 0.3486  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [1690/3750]  eta: 0:12:00  Lr: 0.001875  Loss: -1.1359  Acc@1: 81.2500 (74.6230)  Acc@5: 93.7500 (94.8219)  time: 0.3486  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [1700/3750]  eta: 0:11:56  Lr: 0.001875  Loss: -0.9666  Acc@1: 81.2500 (74.6840)  Acc@5: 93.7500 (94.8266)  time: 0.3485  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [1710/3750]  eta: 0:11:53  Lr: 0.001875  Loss: -0.9792  Acc@1: 81.2500 (74.7260)  Acc@5: 100.0000 (94.8385)  time: 0.3486  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1720/3750]  eta: 0:11:49  Lr: 0.001875  Loss: -0.7075  Acc@1: 81.2500 (74.7567)  Acc@5: 100.0000 (94.8467)  time: 0.3492  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [1730/3750]  eta: 0:11:46  Lr: 0.001875  Loss: -0.5477  Acc@1: 81.2500 (74.7798)  Acc@5: 100.0000 (94.8621)  time: 0.3497  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [1740/3750]  eta: 0:11:42  Lr: 0.001875  Loss: -1.0873  Acc@1: 81.2500 (74.8097)  Acc@5: 100.0000 (94.8700)  time: 0.3514  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [1750/3750]  eta: 0:11:39  Lr: 0.001875  Loss: -0.8981  Acc@1: 81.2500 (74.8608)  Acc@5: 100.0000 (94.8779)  time: 0.3502  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1760/3750]  eta: 0:11:35  Lr: 0.001875  Loss: -1.1513  Acc@1: 81.2500 (74.8687)  Acc@5: 100.0000 (94.8893)  time: 0.3485  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1770/3750]  eta: 0:11:32  Lr: 0.001875  Loss: -0.9696  Acc@1: 81.2500 (74.8906)  Acc@5: 100.0000 (94.8899)  time: 0.3488  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1780/3750]  eta: 0:11:28  Lr: 0.001875  Loss: -0.9354  Acc@1: 81.2500 (74.9228)  Acc@5: 100.0000 (94.9045)  time: 0.3486  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1790/3750]  eta: 0:11:25  Lr: 0.001875  Loss: -0.6108  Acc@1: 81.2500 (74.9407)  Acc@5: 100.0000 (94.9260)  time: 0.3489  data: 0.0013  max mem: 2500
Train: Epoch[1/5]  [1800/3750]  eta: 0:11:21  Lr: 0.001875  Loss: -1.0047  Acc@1: 81.2500 (74.9931)  Acc@5: 100.0000 (94.9368)  time: 0.3493  data: 0.0013  max mem: 2500
Train: Epoch[1/5]  [1810/3750]  eta: 0:11:18  Lr: 0.001875  Loss: -1.2639  Acc@1: 81.2500 (75.0000)  Acc@5: 93.7500 (94.9199)  time: 0.3492  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [1820/3750]  eta: 0:11:14  Lr: 0.001875  Loss: -0.7686  Acc@1: 81.2500 (75.0137)  Acc@5: 93.7500 (94.9272)  time: 0.3493  data: 0.0013  max mem: 2500
Train: Epoch[1/5]  [1830/3750]  eta: 0:11:11  Lr: 0.001875  Loss: -1.1150  Acc@1: 81.2500 (75.0444)  Acc@5: 100.0000 (94.9379)  time: 0.3503  data: 0.0012  max mem: 2500
Train: Epoch[1/5]  [1840/3750]  eta: 0:11:07  Lr: 0.001875  Loss: -0.9321  Acc@1: 75.0000 (75.0611)  Acc@5: 100.0000 (94.9518)  time: 0.3498  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [1850/3750]  eta: 0:11:04  Lr: 0.001875  Loss: -1.0124  Acc@1: 75.0000 (75.0675)  Acc@5: 100.0000 (94.9554)  time: 0.3491  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [1860/3750]  eta: 0:11:00  Lr: 0.001875  Loss: -0.2520  Acc@1: 68.7500 (75.0369)  Acc@5: 93.7500 (94.9523)  time: 0.3493  data: 0.0010  max mem: 2500
Train: Epoch[1/5]  [1870/3750]  eta: 0:10:57  Lr: 0.001875  Loss: -0.9219  Acc@1: 75.0000 (75.0735)  Acc@5: 93.7500 (94.9592)  time: 0.3487  data: 0.0011  max mem: 2500
Train: Epoch[1/5]  [1880/3750]  eta: 0:10:53  Lr: 0.001875  Loss: -0.9071  Acc@1: 75.0000 (75.0930)  Acc@5: 100.0000 (94.9728)  time: 0.3513  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [1890/3750]  eta: 0:10:50  Lr: 0.001875  Loss: -0.1208  Acc@1: 75.0000 (75.0826)  Acc@5: 100.0000 (94.9828)  time: 0.3518  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [1900/3750]  eta: 0:10:46  Lr: 0.001875  Loss: -1.1066  Acc@1: 81.2500 (75.1282)  Acc@5: 100.0000 (94.9993)  time: 0.3499  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [1910/3750]  eta: 0:10:43  Lr: 0.001875  Loss: -0.9897  Acc@1: 81.2500 (75.1210)  Acc@5: 100.0000 (94.9895)  time: 0.3505  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [1920/3750]  eta: 0:10:39  Lr: 0.001875  Loss: -0.3476  Acc@1: 75.0000 (75.1399)  Acc@5: 93.7500 (94.9798)  time: 0.3493  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1930/3750]  eta: 0:10:36  Lr: 0.001875  Loss: -0.7168  Acc@1: 75.0000 (75.1295)  Acc@5: 93.7500 (94.9896)  time: 0.3491  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1940/3750]  eta: 0:10:32  Lr: 0.001875  Loss: -1.1433  Acc@1: 75.0000 (75.1417)  Acc@5: 93.7500 (94.9833)  time: 0.3486  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1950/3750]  eta: 0:10:29  Lr: 0.001875  Loss: -1.2735  Acc@1: 75.0000 (75.1538)  Acc@5: 93.7500 (94.9865)  time: 0.3478  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1960/3750]  eta: 0:10:25  Lr: 0.001875  Loss: -0.6408  Acc@1: 75.0000 (75.1625)  Acc@5: 93.7500 (94.9962)  time: 0.3487  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1970/3750]  eta: 0:10:22  Lr: 0.001875  Loss: -0.8024  Acc@1: 81.2500 (75.1998)  Acc@5: 100.0000 (95.0057)  time: 0.3492  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1980/3750]  eta: 0:10:18  Lr: 0.001875  Loss: -0.5022  Acc@1: 81.2500 (75.2240)  Acc@5: 93.7500 (95.0057)  time: 0.3496  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [1990/3750]  eta: 0:10:15  Lr: 0.001875  Loss: -0.8145  Acc@1: 75.0000 (75.2135)  Acc@5: 100.0000 (95.0088)  time: 0.3501  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [2000/3750]  eta: 0:10:11  Lr: 0.001875  Loss: -0.7736  Acc@1: 75.0000 (75.2311)  Acc@5: 100.0000 (95.0119)  time: 0.3497  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [2010/3750]  eta: 0:10:08  Lr: 0.001875  Loss: -0.6709  Acc@1: 81.2500 (75.2548)  Acc@5: 93.7500 (94.9963)  time: 0.3499  data: 0.0010  max mem: 2500
Train: Epoch[1/5]  [2020/3750]  eta: 0:10:04  Lr: 0.001875  Loss: -1.2445  Acc@1: 81.2500 (75.2907)  Acc@5: 93.7500 (95.0056)  time: 0.3500  data: 0.0010  max mem: 2500
Train: Epoch[1/5]  [2030/3750]  eta: 0:10:01  Lr: 0.001875  Loss: -0.7792  Acc@1: 75.0000 (75.2770)  Acc@5: 93.7500 (95.0055)  time: 0.3488  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2040/3750]  eta: 0:09:57  Lr: 0.001875  Loss: -0.4768  Acc@1: 75.0000 (75.3093)  Acc@5: 93.7500 (95.0147)  time: 0.3486  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [2050/3750]  eta: 0:09:54  Lr: 0.001875  Loss: -1.2625  Acc@1: 81.2500 (75.3169)  Acc@5: 100.0000 (95.0329)  time: 0.3495  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2060/3750]  eta: 0:09:50  Lr: 0.001875  Loss: -0.8863  Acc@1: 75.0000 (75.3063)  Acc@5: 100.0000 (95.0297)  time: 0.3492  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2070/3750]  eta: 0:09:47  Lr: 0.001875  Loss: -0.8122  Acc@1: 75.0000 (75.3078)  Acc@5: 93.7500 (95.0296)  time: 0.3483  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2080/3750]  eta: 0:09:43  Lr: 0.001875  Loss: -0.9308  Acc@1: 81.2500 (75.3454)  Acc@5: 93.7500 (95.0414)  time: 0.3488  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2090/3750]  eta: 0:09:40  Lr: 0.001875  Loss: -0.6826  Acc@1: 81.2500 (75.3437)  Acc@5: 100.0000 (95.0442)  time: 0.3488  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2100/3750]  eta: 0:09:36  Lr: 0.001875  Loss: -0.9920  Acc@1: 75.0000 (75.3480)  Acc@5: 100.0000 (95.0500)  time: 0.3484  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [2110/3750]  eta: 0:09:33  Lr: 0.001875  Loss: -1.0084  Acc@1: 75.0000 (75.3760)  Acc@5: 93.7500 (95.0527)  time: 0.3483  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [2120/3750]  eta: 0:09:29  Lr: 0.001875  Loss: -0.4078  Acc@1: 75.0000 (75.3801)  Acc@5: 93.7500 (95.0554)  time: 0.3485  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2130/3750]  eta: 0:09:26  Lr: 0.001875  Loss: -0.8950  Acc@1: 81.2500 (75.4047)  Acc@5: 93.7500 (95.0639)  time: 0.3497  data: 0.0017  max mem: 2500
Train: Epoch[1/5]  [2140/3750]  eta: 0:09:22  Lr: 0.001875  Loss: -0.7503  Acc@1: 81.2500 (75.4291)  Acc@5: 93.7500 (95.0636)  time: 0.3496  data: 0.0024  max mem: 2500
Train: Epoch[1/5]  [2150/3750]  eta: 0:09:19  Lr: 0.001875  Loss: -1.1709  Acc@1: 81.2500 (75.4271)  Acc@5: 93.7500 (95.0750)  time: 0.3477  data: 0.0012  max mem: 2500
Train: Epoch[1/5]  [2160/3750]  eta: 0:09:15  Lr: 0.001875  Loss: -0.9461  Acc@1: 75.0000 (75.4454)  Acc@5: 100.0000 (95.0920)  time: 0.3482  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2170/3750]  eta: 0:09:12  Lr: 0.001875  Loss: -1.1556  Acc@1: 81.2500 (75.4808)  Acc@5: 100.0000 (95.1031)  time: 0.3499  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [2180/3750]  eta: 0:09:08  Lr: 0.001875  Loss: -0.7842  Acc@1: 81.2500 (75.4958)  Acc@5: 100.0000 (95.1112)  time: 0.3494  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [2190/3750]  eta: 0:09:05  Lr: 0.001875  Loss: -1.4069  Acc@1: 81.2500 (75.5306)  Acc@5: 93.7500 (95.1164)  time: 0.3491  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [2200/3750]  eta: 0:09:01  Lr: 0.001875  Loss: -1.1055  Acc@1: 81.2500 (75.5622)  Acc@5: 100.0000 (95.1329)  time: 0.3489  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [2210/3750]  eta: 0:08:58  Lr: 0.001875  Loss: -0.8525  Acc@1: 81.2500 (75.5823)  Acc@5: 100.0000 (95.1408)  time: 0.3484  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [2220/3750]  eta: 0:08:54  Lr: 0.001875  Loss: -0.9905  Acc@1: 81.2500 (75.6022)  Acc@5: 100.0000 (95.1542)  time: 0.3498  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [2230/3750]  eta: 0:08:51  Lr: 0.001875  Loss: -0.8916  Acc@1: 81.2500 (75.6219)  Acc@5: 93.7500 (95.1535)  time: 0.3509  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2240/3750]  eta: 0:08:47  Lr: 0.001875  Loss: -0.8550  Acc@1: 81.2500 (75.6526)  Acc@5: 93.7500 (95.1556)  time: 0.3498  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2250/3750]  eta: 0:08:44  Lr: 0.001875  Loss: -1.1110  Acc@1: 81.2500 (75.7025)  Acc@5: 100.0000 (95.1716)  time: 0.3507  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2260/3750]  eta: 0:08:40  Lr: 0.001875  Loss: -0.7024  Acc@1: 81.2500 (75.7187)  Acc@5: 100.0000 (95.1736)  time: 0.3508  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2270/3750]  eta: 0:08:37  Lr: 0.001875  Loss: -0.8892  Acc@1: 81.2500 (75.7623)  Acc@5: 93.7500 (95.1838)  time: 0.3494  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2280/3750]  eta: 0:08:33  Lr: 0.001875  Loss: -0.8071  Acc@1: 81.2500 (75.7754)  Acc@5: 93.7500 (95.1830)  time: 0.3494  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2290/3750]  eta: 0:08:30  Lr: 0.001875  Loss: -0.8436  Acc@1: 81.2500 (75.7966)  Acc@5: 93.7500 (95.1904)  time: 0.3480  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2300/3750]  eta: 0:08:26  Lr: 0.001875  Loss: -1.1445  Acc@1: 81.2500 (75.8203)  Acc@5: 93.7500 (95.1896)  time: 0.3477  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2310/3750]  eta: 0:08:23  Lr: 0.001875  Loss: -0.9991  Acc@1: 81.2500 (75.8465)  Acc@5: 100.0000 (95.2023)  time: 0.3501  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2320/3750]  eta: 0:08:19  Lr: 0.001875  Loss: -1.0922  Acc@1: 81.2500 (75.8590)  Acc@5: 100.0000 (95.2122)  time: 0.3510  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [2330/3750]  eta: 0:08:16  Lr: 0.001875  Loss: -1.0128  Acc@1: 87.5000 (75.9089)  Acc@5: 100.0000 (95.2274)  time: 0.3507  data: 0.0010  max mem: 2500
Train: Epoch[1/5]  [2340/3750]  eta: 0:08:12  Lr: 0.001875  Loss: -0.9776  Acc@1: 81.2500 (75.9318)  Acc@5: 100.0000 (95.2317)  time: 0.3499  data: 0.0010  max mem: 2500
Train: Epoch[1/5]  [2350/3750]  eta: 0:08:09  Lr: 0.001875  Loss: -0.8926  Acc@1: 81.2500 (75.9517)  Acc@5: 100.0000 (95.2387)  time: 0.3476  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2360/3750]  eta: 0:08:05  Lr: 0.001875  Loss: -1.0057  Acc@1: 81.2500 (75.9768)  Acc@5: 100.0000 (95.2457)  time: 0.3477  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2370/3750]  eta: 0:08:02  Lr: 0.001875  Loss: -1.2391  Acc@1: 81.2500 (75.9991)  Acc@5: 100.0000 (95.2604)  time: 0.3484  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2380/3750]  eta: 0:07:58  Lr: 0.001875  Loss: -0.6008  Acc@1: 81.2500 (76.0080)  Acc@5: 100.0000 (95.2567)  time: 0.3485  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2390/3750]  eta: 0:07:55  Lr: 0.001875  Loss: -0.8917  Acc@1: 81.2500 (76.0273)  Acc@5: 100.0000 (95.2635)  time: 0.3488  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2400/3750]  eta: 0:07:51  Lr: 0.001875  Loss: -1.1741  Acc@1: 81.2500 (76.0569)  Acc@5: 100.0000 (95.2780)  time: 0.3510  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2410/3750]  eta: 0:07:48  Lr: 0.001875  Loss: -0.9842  Acc@1: 81.2500 (76.0991)  Acc@5: 100.0000 (95.2950)  time: 0.3513  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [2420/3750]  eta: 0:07:44  Lr: 0.001875  Loss: 0.3617  Acc@1: 81.2500 (76.1075)  Acc@5: 100.0000 (95.2860)  time: 0.3487  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [2430/3750]  eta: 0:07:41  Lr: 0.001875  Loss: -1.1997  Acc@1: 81.2500 (76.1389)  Acc@5: 100.0000 (95.2977)  time: 0.3477  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2440/3750]  eta: 0:07:37  Lr: 0.001875  Loss: -0.1471  Acc@1: 81.2500 (76.1445)  Acc@5: 100.0000 (95.2939)  time: 0.3474  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [2450/3750]  eta: 0:07:34  Lr: 0.001875  Loss: -0.9727  Acc@1: 81.2500 (76.1679)  Acc@5: 100.0000 (95.3106)  time: 0.3486  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2460/3750]  eta: 0:07:30  Lr: 0.001875  Loss: 0.0444  Acc@1: 75.0000 (76.1555)  Acc@5: 100.0000 (95.3042)  time: 0.3488  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2470/3750]  eta: 0:07:27  Lr: 0.001875  Loss: -0.8469  Acc@1: 81.2500 (76.1812)  Acc@5: 100.0000 (95.3131)  time: 0.3478  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2480/3750]  eta: 0:07:23  Lr: 0.001875  Loss: -0.8330  Acc@1: 81.2500 (76.2142)  Acc@5: 100.0000 (95.3219)  time: 0.3478  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [2490/3750]  eta: 0:07:20  Lr: 0.001875  Loss: -0.4799  Acc@1: 81.2500 (76.2395)  Acc@5: 100.0000 (95.3332)  time: 0.3479  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [2500/3750]  eta: 0:07:16  Lr: 0.001875  Loss: -0.5968  Acc@1: 81.2500 (76.2570)  Acc@5: 100.0000 (95.3394)  time: 0.3490  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [2510/3750]  eta: 0:07:13  Lr: 0.001875  Loss: -1.2292  Acc@1: 81.2500 (76.2719)  Acc@5: 100.0000 (95.3554)  time: 0.3518  data: 0.0015  max mem: 2500
Train: Epoch[1/5]  [2520/3750]  eta: 0:07:09  Lr: 0.001875  Loss: -0.7859  Acc@1: 81.2500 (76.2793)  Acc@5: 100.0000 (95.3565)  time: 0.3526  data: 0.0023  max mem: 2500
Train: Epoch[1/5]  [2530/3750]  eta: 0:07:06  Lr: 0.001875  Loss: -0.8646  Acc@1: 81.2500 (76.2940)  Acc@5: 93.7500 (95.3502)  time: 0.3507  data: 0.0014  max mem: 2500
Train: Epoch[1/5]  [2540/3750]  eta: 0:07:02  Lr: 0.001875  Loss: -1.1006  Acc@1: 81.2500 (76.3061)  Acc@5: 93.7500 (95.3611)  time: 0.3493  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [2550/3750]  eta: 0:06:59  Lr: 0.001875  Loss: -0.9752  Acc@1: 75.0000 (76.3132)  Acc@5: 100.0000 (95.3548)  time: 0.3499  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [2560/3750]  eta: 0:06:55  Lr: 0.001875  Loss: -0.7877  Acc@1: 81.2500 (76.3325)  Acc@5: 100.0000 (95.3607)  time: 0.3493  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2570/3750]  eta: 0:06:52  Lr: 0.001875  Loss: -0.8179  Acc@1: 81.2500 (76.3346)  Acc@5: 93.7500 (95.3569)  time: 0.3495  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [2580/3750]  eta: 0:06:48  Lr: 0.001875  Loss: -0.8546  Acc@1: 81.2500 (76.3367)  Acc@5: 93.7500 (95.3627)  time: 0.3498  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2590/3750]  eta: 0:06:45  Lr: 0.001875  Loss: -1.0001  Acc@1: 81.2500 (76.3581)  Acc@5: 93.7500 (95.3686)  time: 0.3481  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2600/3750]  eta: 0:06:41  Lr: 0.001875  Loss: -1.0158  Acc@1: 81.2500 (76.3769)  Acc@5: 93.7500 (95.3744)  time: 0.3493  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2610/3750]  eta: 0:06:38  Lr: 0.001875  Loss: -0.6384  Acc@1: 81.2500 (76.3931)  Acc@5: 100.0000 (95.3801)  time: 0.3503  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2620/3750]  eta: 0:06:34  Lr: 0.001875  Loss: -0.7620  Acc@1: 75.0000 (76.3950)  Acc@5: 93.7500 (95.3739)  time: 0.3500  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2630/3750]  eta: 0:06:31  Lr: 0.001875  Loss: -0.4400  Acc@1: 75.0000 (76.4016)  Acc@5: 93.7500 (95.3749)  time: 0.3501  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2640/3750]  eta: 0:06:27  Lr: 0.001875  Loss: -0.7698  Acc@1: 75.0000 (76.4010)  Acc@5: 93.7500 (95.3711)  time: 0.3495  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [2650/3750]  eta: 0:06:24  Lr: 0.001875  Loss: -1.2666  Acc@1: 81.2500 (76.4216)  Acc@5: 93.7500 (95.3767)  time: 0.3485  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2660/3750]  eta: 0:06:20  Lr: 0.001875  Loss: -1.3375  Acc@1: 81.2500 (76.4280)  Acc@5: 100.0000 (95.3824)  time: 0.3490  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2670/3750]  eta: 0:06:17  Lr: 0.001875  Loss: -0.9481  Acc@1: 81.2500 (76.4391)  Acc@5: 93.7500 (95.3763)  time: 0.3506  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [2680/3750]  eta: 0:06:13  Lr: 0.001875  Loss: -0.9112  Acc@1: 81.2500 (76.4477)  Acc@5: 100.0000 (95.3842)  time: 0.3514  data: 0.0019  max mem: 2500
Train: Epoch[1/5]  [2690/3750]  eta: 0:06:10  Lr: 0.001875  Loss: -1.3944  Acc@1: 75.0000 (76.4655)  Acc@5: 100.0000 (95.3944)  time: 0.3505  data: 0.0018  max mem: 2500
Train: Epoch[1/5]  [2700/3750]  eta: 0:06:06  Lr: 0.001875  Loss: -0.9898  Acc@1: 81.2500 (76.4786)  Acc@5: 100.0000 (95.3999)  time: 0.3483  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2710/3750]  eta: 0:06:03  Lr: 0.001875  Loss: -0.7057  Acc@1: 75.0000 (76.4662)  Acc@5: 93.7500 (95.3961)  time: 0.3483  data: 0.0011  max mem: 2500
Train: Epoch[1/5]  [2720/3750]  eta: 0:05:59  Lr: 0.001875  Loss: -0.8017  Acc@1: 75.0000 (76.4586)  Acc@5: 93.7500 (95.3946)  time: 0.3489  data: 0.0011  max mem: 2500
Train: Epoch[1/5]  [2730/3750]  eta: 0:05:56  Lr: 0.001875  Loss: -0.8329  Acc@1: 75.0000 (76.4647)  Acc@5: 93.7500 (95.4000)  time: 0.3494  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2740/3750]  eta: 0:05:52  Lr: 0.001875  Loss: -0.9092  Acc@1: 75.0000 (76.4662)  Acc@5: 93.7500 (95.4009)  time: 0.3498  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [2750/3750]  eta: 0:05:49  Lr: 0.001875  Loss: -0.9265  Acc@1: 81.2500 (76.4836)  Acc@5: 100.0000 (95.4085)  time: 0.3486  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2760/3750]  eta: 0:05:45  Lr: 0.001875  Loss: -1.0934  Acc@1: 81.2500 (76.5053)  Acc@5: 100.0000 (95.4161)  time: 0.3483  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2770/3750]  eta: 0:05:42  Lr: 0.001875  Loss: -0.7481  Acc@1: 81.2500 (76.4977)  Acc@5: 100.0000 (95.4213)  time: 0.3483  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2780/3750]  eta: 0:05:38  Lr: 0.001875  Loss: -0.6977  Acc@1: 75.0000 (76.4945)  Acc@5: 100.0000 (95.4266)  time: 0.3490  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2790/3750]  eta: 0:05:35  Lr: 0.001875  Loss: -0.9047  Acc@1: 81.2500 (76.4981)  Acc@5: 100.0000 (95.4295)  time: 0.3498  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [2800/3750]  eta: 0:05:32  Lr: 0.001875  Loss: -1.0601  Acc@1: 81.2500 (76.5173)  Acc@5: 100.0000 (95.4347)  time: 0.3492  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [2810/3750]  eta: 0:05:28  Lr: 0.001875  Loss: -1.2029  Acc@1: 81.2500 (76.5319)  Acc@5: 100.0000 (95.4376)  time: 0.3481  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2820/3750]  eta: 0:05:25  Lr: 0.001875  Loss: -0.8593  Acc@1: 81.2500 (76.5464)  Acc@5: 100.0000 (95.4537)  time: 0.3477  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2830/3750]  eta: 0:05:21  Lr: 0.001875  Loss: -0.9738  Acc@1: 81.2500 (76.5432)  Acc@5: 100.0000 (95.4543)  time: 0.3490  data: 0.0012  max mem: 2500
Train: Epoch[1/5]  [2840/3750]  eta: 0:05:18  Lr: 0.001875  Loss: -1.2611  Acc@1: 75.0000 (76.5510)  Acc@5: 93.7500 (95.4505)  time: 0.3492  data: 0.0012  max mem: 2500
Train: Epoch[1/5]  [2850/3750]  eta: 0:05:14  Lr: 0.001875  Loss: -0.6614  Acc@1: 75.0000 (76.5652)  Acc@5: 100.0000 (95.4512)  time: 0.3492  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2860/3750]  eta: 0:05:11  Lr: 0.001875  Loss: -0.9163  Acc@1: 87.5000 (76.6056)  Acc@5: 100.0000 (95.4583)  time: 0.3490  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [2870/3750]  eta: 0:05:07  Lr: 0.001875  Loss: -0.9450  Acc@1: 87.5000 (76.6262)  Acc@5: 100.0000 (95.4567)  time: 0.3499  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [2880/3750]  eta: 0:05:04  Lr: 0.001875  Loss: -1.1807  Acc@1: 81.2500 (76.6466)  Acc@5: 93.7500 (95.4486)  time: 0.3517  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [2890/3750]  eta: 0:05:00  Lr: 0.001875  Loss: -0.8454  Acc@1: 75.0000 (76.6517)  Acc@5: 100.0000 (95.4514)  time: 0.3523  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [2900/3750]  eta: 0:04:57  Lr: 0.001875  Loss: -0.7935  Acc@1: 81.2500 (76.6654)  Acc@5: 100.0000 (95.4606)  time: 0.3541  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [2910/3750]  eta: 0:04:53  Lr: 0.001875  Loss: -0.9787  Acc@1: 81.2500 (76.6833)  Acc@5: 100.0000 (95.4698)  time: 0.3518  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2920/3750]  eta: 0:04:50  Lr: 0.001875  Loss: -0.8630  Acc@1: 81.2500 (76.7032)  Acc@5: 100.0000 (95.4789)  time: 0.3472  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [2930/3750]  eta: 0:04:46  Lr: 0.001875  Loss: -0.5061  Acc@1: 81.2500 (76.7208)  Acc@5: 100.0000 (95.4794)  time: 0.3472  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [2940/3750]  eta: 0:04:43  Lr: 0.001875  Loss: -0.8523  Acc@1: 81.2500 (76.7107)  Acc@5: 100.0000 (95.4820)  time: 0.3479  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2950/3750]  eta: 0:04:39  Lr: 0.001875  Loss: -1.1113  Acc@1: 75.0000 (76.7219)  Acc@5: 100.0000 (95.4867)  time: 0.3488  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2960/3750]  eta: 0:04:36  Lr: 0.001875  Loss: -0.6293  Acc@1: 81.2500 (76.7266)  Acc@5: 100.0000 (95.4893)  time: 0.3496  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [2970/3750]  eta: 0:04:32  Lr: 0.001875  Loss: -0.9156  Acc@1: 81.2500 (76.7355)  Acc@5: 100.0000 (95.4939)  time: 0.3490  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [2980/3750]  eta: 0:04:29  Lr: 0.001875  Loss: -0.5354  Acc@1: 81.2500 (76.7339)  Acc@5: 100.0000 (95.4902)  time: 0.3493  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [2990/3750]  eta: 0:04:25  Lr: 0.001875  Loss: -1.0033  Acc@1: 81.2500 (76.7511)  Acc@5: 100.0000 (95.4969)  time: 0.3501  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [3000/3750]  eta: 0:04:22  Lr: 0.001875  Loss: -1.1767  Acc@1: 81.2500 (76.7536)  Acc@5: 100.0000 (95.4973)  time: 0.3491  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [3010/3750]  eta: 0:04:18  Lr: 0.001875  Loss: -0.8295  Acc@1: 75.0000 (76.7581)  Acc@5: 93.7500 (95.4998)  time: 0.3485  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3020/3750]  eta: 0:04:15  Lr: 0.001875  Loss: -0.8465  Acc@1: 81.2500 (76.7833)  Acc@5: 100.0000 (95.5065)  time: 0.3482  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [3030/3750]  eta: 0:04:11  Lr: 0.001875  Loss: -1.1350  Acc@1: 81.2500 (76.8022)  Acc@5: 100.0000 (95.5048)  time: 0.3484  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [3040/3750]  eta: 0:04:08  Lr: 0.001875  Loss: -1.1616  Acc@1: 81.2500 (76.8209)  Acc@5: 100.0000 (95.5175)  time: 0.3487  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [3050/3750]  eta: 0:04:04  Lr: 0.001875  Loss: -0.9155  Acc@1: 81.2500 (76.8211)  Acc@5: 100.0000 (95.5199)  time: 0.3485  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [3060/3750]  eta: 0:04:01  Lr: 0.001875  Loss: -0.8333  Acc@1: 81.2500 (76.8397)  Acc@5: 100.0000 (95.5264)  time: 0.3499  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [3070/3750]  eta: 0:03:57  Lr: 0.001875  Loss: -0.2372  Acc@1: 81.2500 (76.8500)  Acc@5: 100.0000 (95.5348)  time: 0.3492  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [3080/3750]  eta: 0:03:54  Lr: 0.001875  Loss: 0.0080  Acc@1: 87.5000 (76.8703)  Acc@5: 100.0000 (95.5392)  time: 0.3476  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [3090/3750]  eta: 0:03:50  Lr: 0.001875  Loss: -0.8902  Acc@1: 87.5000 (76.8885)  Acc@5: 100.0000 (95.5455)  time: 0.3483  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [3100/3750]  eta: 0:03:47  Lr: 0.001875  Loss: -0.9870  Acc@1: 81.2500 (76.9107)  Acc@5: 100.0000 (95.5559)  time: 0.3496  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [3110/3750]  eta: 0:03:43  Lr: 0.001875  Loss: -1.2838  Acc@1: 81.2500 (76.9166)  Acc@5: 100.0000 (95.5661)  time: 0.3501  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [3120/3750]  eta: 0:03:40  Lr: 0.001875  Loss: -0.5275  Acc@1: 81.2500 (76.9285)  Acc@5: 100.0000 (95.5743)  time: 0.3493  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [3130/3750]  eta: 0:03:36  Lr: 0.001875  Loss: -0.4534  Acc@1: 81.2500 (76.9423)  Acc@5: 100.0000 (95.5705)  time: 0.3494  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [3140/3750]  eta: 0:03:33  Lr: 0.001875  Loss: -0.8473  Acc@1: 75.0000 (76.9520)  Acc@5: 100.0000 (95.5747)  time: 0.3495  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [3150/3750]  eta: 0:03:29  Lr: 0.001875  Loss: -0.8648  Acc@1: 75.0000 (76.9518)  Acc@5: 100.0000 (95.5748)  time: 0.3498  data: 0.0009  max mem: 2500
Train: Epoch[1/5]  [3160/3750]  eta: 0:03:26  Lr: 0.001875  Loss: -0.8277  Acc@1: 75.0000 (76.9456)  Acc@5: 93.7500 (95.5750)  time: 0.3495  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [3170/3750]  eta: 0:03:22  Lr: 0.001875  Loss: -1.2347  Acc@1: 81.2500 (76.9730)  Acc@5: 100.0000 (95.5830)  time: 0.3490  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3180/3750]  eta: 0:03:19  Lr: 0.001875  Loss: -0.9585  Acc@1: 81.2500 (76.9746)  Acc@5: 100.0000 (95.5851)  time: 0.3480  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3190/3750]  eta: 0:03:15  Lr: 0.001875  Loss: -0.3892  Acc@1: 75.0000 (76.9684)  Acc@5: 93.7500 (95.5813)  time: 0.3482  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [3200/3750]  eta: 0:03:12  Lr: 0.001875  Loss: -1.3855  Acc@1: 81.2500 (76.9838)  Acc@5: 100.0000 (95.5912)  time: 0.3492  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [3210/3750]  eta: 0:03:08  Lr: 0.001875  Loss: -0.7906  Acc@1: 81.2500 (77.0068)  Acc@5: 100.0000 (95.5933)  time: 0.3505  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [3220/3750]  eta: 0:03:05  Lr: 0.001875  Loss: -0.7299  Acc@1: 81.2500 (77.0025)  Acc@5: 93.7500 (95.5992)  time: 0.3502  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3230/3750]  eta: 0:03:01  Lr: 0.001875  Loss: -0.4973  Acc@1: 75.0000 (77.0040)  Acc@5: 100.0000 (95.6070)  time: 0.3478  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3240/3750]  eta: 0:02:58  Lr: 0.001875  Loss: -0.4847  Acc@1: 81.2500 (77.0210)  Acc@5: 100.0000 (95.6071)  time: 0.3479  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [3250/3750]  eta: 0:02:54  Lr: 0.001875  Loss: -1.0183  Acc@1: 81.2500 (77.0359)  Acc@5: 93.7500 (95.6110)  time: 0.3504  data: 0.0013  max mem: 2500
Train: Epoch[1/5]  [3260/3750]  eta: 0:02:51  Lr: 0.001875  Loss: -1.0274  Acc@1: 81.2500 (77.0508)  Acc@5: 100.0000 (95.6168)  time: 0.3518  data: 0.0012  max mem: 2500
Train: Epoch[1/5]  [3270/3750]  eta: 0:02:47  Lr: 0.001875  Loss: -0.8552  Acc@1: 81.2500 (77.0579)  Acc@5: 93.7500 (95.6149)  time: 0.3499  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [3280/3750]  eta: 0:02:44  Lr: 0.001875  Loss: -0.7775  Acc@1: 81.2500 (77.0687)  Acc@5: 93.7500 (95.6168)  time: 0.3485  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [3290/3750]  eta: 0:02:40  Lr: 0.001875  Loss: -1.0225  Acc@1: 81.2500 (77.0776)  Acc@5: 100.0000 (95.6206)  time: 0.3486  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [3300/3750]  eta: 0:02:37  Lr: 0.001875  Loss: -0.8242  Acc@1: 81.2500 (77.0960)  Acc@5: 100.0000 (95.6206)  time: 0.3500  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [3310/3750]  eta: 0:02:33  Lr: 0.001875  Loss: -0.5537  Acc@1: 81.2500 (77.1010)  Acc@5: 93.7500 (95.6225)  time: 0.3508  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [3320/3750]  eta: 0:02:30  Lr: 0.001875  Loss: -0.7558  Acc@1: 75.0000 (77.0965)  Acc@5: 93.7500 (95.6131)  time: 0.3498  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [3330/3750]  eta: 0:02:26  Lr: 0.001875  Loss: -1.2066  Acc@1: 81.2500 (77.1165)  Acc@5: 93.7500 (95.6188)  time: 0.3492  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [3340/3750]  eta: 0:02:23  Lr: 0.001875  Loss: -0.9696  Acc@1: 81.2500 (77.1120)  Acc@5: 93.7500 (95.6151)  time: 0.3501  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [3350/3750]  eta: 0:02:19  Lr: 0.001875  Loss: -1.0324  Acc@1: 81.2500 (77.1188)  Acc@5: 93.7500 (95.6170)  time: 0.3496  data: 0.0009  max mem: 2500
Train: Epoch[1/5]  [3360/3750]  eta: 0:02:16  Lr: 0.001875  Loss: -1.0088  Acc@1: 81.2500 (77.1422)  Acc@5: 93.7500 (95.6207)  time: 0.3499  data: 0.0012  max mem: 2500
Train: Epoch[1/5]  [3370/3750]  eta: 0:02:12  Lr: 0.001875  Loss: -1.3204  Acc@1: 81.2500 (77.1600)  Acc@5: 100.0000 (95.6263)  time: 0.3501  data: 0.0011  max mem: 2500
Train: Epoch[1/5]  [3380/3750]  eta: 0:02:09  Lr: 0.001875  Loss: -0.7177  Acc@1: 81.2500 (77.1739)  Acc@5: 100.0000 (95.6263)  time: 0.3489  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [3390/3750]  eta: 0:02:05  Lr: 0.001875  Loss: -1.1761  Acc@1: 81.2500 (77.1804)  Acc@5: 100.0000 (95.6300)  time: 0.3480  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3400/3750]  eta: 0:02:02  Lr: 0.001875  Loss: -0.5483  Acc@1: 81.2500 (77.1905)  Acc@5: 100.0000 (95.6355)  time: 0.3479  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3410/3750]  eta: 0:01:58  Lr: 0.001875  Loss: -0.9244  Acc@1: 81.2500 (77.2061)  Acc@5: 100.0000 (95.6391)  time: 0.3488  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3420/3750]  eta: 0:01:55  Lr: 0.001875  Loss: -1.1006  Acc@1: 81.2500 (77.2143)  Acc@5: 100.0000 (95.6464)  time: 0.3485  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [3430/3750]  eta: 0:01:51  Lr: 0.001875  Loss: -0.7143  Acc@1: 81.2500 (77.2133)  Acc@5: 100.0000 (95.6500)  time: 0.3485  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [3440/3750]  eta: 0:01:48  Lr: 0.001875  Loss: -0.9053  Acc@1: 75.0000 (77.2196)  Acc@5: 100.0000 (95.6499)  time: 0.3490  data: 0.0010  max mem: 2500
Train: Epoch[1/5]  [3450/3750]  eta: 0:01:44  Lr: 0.001875  Loss: -0.6638  Acc@1: 81.2500 (77.2385)  Acc@5: 100.0000 (95.6498)  time: 0.3485  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [3460/3750]  eta: 0:01:41  Lr: 0.001875  Loss: -1.1418  Acc@1: 81.2500 (77.2320)  Acc@5: 93.7500 (95.6515)  time: 0.3487  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [3470/3750]  eta: 0:01:37  Lr: 0.001875  Loss: -1.0504  Acc@1: 81.2500 (77.2454)  Acc@5: 100.0000 (95.6569)  time: 0.3497  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [3480/3750]  eta: 0:01:34  Lr: 0.001875  Loss: -0.8842  Acc@1: 75.0000 (77.2407)  Acc@5: 100.0000 (95.6532)  time: 0.3490  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [3490/3750]  eta: 0:01:30  Lr: 0.001875  Loss: -1.2723  Acc@1: 75.0000 (77.2451)  Acc@5: 93.7500 (95.6406)  time: 0.3499  data: 0.0017  max mem: 2500
Train: Epoch[1/5]  [3500/3750]  eta: 0:01:27  Lr: 0.001875  Loss: -1.0725  Acc@1: 81.2500 (77.2654)  Acc@5: 93.7500 (95.6459)  time: 0.3498  data: 0.0018  max mem: 2500
Train: Epoch[1/5]  [3510/3750]  eta: 0:01:23  Lr: 0.001875  Loss: -1.2691  Acc@1: 81.2500 (77.2803)  Acc@5: 100.0000 (95.6547)  time: 0.3485  data: 0.0014  max mem: 2500
Train: Epoch[1/5]  [3520/3750]  eta: 0:01:20  Lr: 0.001875  Loss: -1.0004  Acc@1: 87.5000 (77.3076)  Acc@5: 100.0000 (95.6582)  time: 0.3482  data: 0.0012  max mem: 2500
Train: Epoch[1/5]  [3530/3750]  eta: 0:01:16  Lr: 0.001875  Loss: -0.3350  Acc@1: 81.2500 (77.3081)  Acc@5: 100.0000 (95.6581)  time: 0.3481  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [3540/3750]  eta: 0:01:13  Lr: 0.001875  Loss: -0.9392  Acc@1: 81.2500 (77.3246)  Acc@5: 100.0000 (95.6651)  time: 0.3484  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [3550/3750]  eta: 0:01:09  Lr: 0.001875  Loss: -0.8024  Acc@1: 81.2500 (77.3286)  Acc@5: 100.0000 (95.6702)  time: 0.3481  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [3560/3750]  eta: 0:01:06  Lr: 0.001875  Loss: -1.2046  Acc@1: 81.2500 (77.3273)  Acc@5: 100.0000 (95.6806)  time: 0.3481  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [3570/3750]  eta: 0:01:02  Lr: 0.001875  Loss: -1.2146  Acc@1: 87.5000 (77.3628)  Acc@5: 100.0000 (95.6910)  time: 0.3478  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3580/3750]  eta: 0:00:59  Lr: 0.001875  Loss: -0.5874  Acc@1: 87.5000 (77.3649)  Acc@5: 100.0000 (95.6908)  time: 0.3495  data: 0.0012  max mem: 2500
Train: Epoch[1/5]  [3590/3750]  eta: 0:00:55  Lr: 0.001875  Loss: -1.1749  Acc@1: 81.2500 (77.3931)  Acc@5: 100.0000 (95.6924)  time: 0.3504  data: 0.0014  max mem: 2500
Train: Epoch[1/5]  [3600/3750]  eta: 0:00:52  Lr: 0.001875  Loss: -0.6006  Acc@1: 87.5000 (77.4073)  Acc@5: 100.0000 (95.6974)  time: 0.3480  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [3610/3750]  eta: 0:00:48  Lr: 0.001875  Loss: -1.3097  Acc@1: 81.2500 (77.4214)  Acc@5: 100.0000 (95.7024)  time: 0.3473  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [3620/3750]  eta: 0:00:45  Lr: 0.001875  Loss: -0.9014  Acc@1: 87.5000 (77.4268)  Acc@5: 100.0000 (95.7022)  time: 0.3489  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3630/3750]  eta: 0:00:41  Lr: 0.001875  Loss: -0.8426  Acc@1: 81.2500 (77.4287)  Acc@5: 100.0000 (95.7054)  time: 0.3491  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3640/3750]  eta: 0:00:38  Lr: 0.001875  Loss: -0.9220  Acc@1: 81.2500 (77.4289)  Acc@5: 93.7500 (95.7000)  time: 0.3491  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3650/3750]  eta: 0:00:34  Lr: 0.001875  Loss: -1.1930  Acc@1: 81.2500 (77.4445)  Acc@5: 93.7500 (95.7067)  time: 0.3481  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3660/3750]  eta: 0:00:31  Lr: 0.001875  Loss: -0.8365  Acc@1: 81.2500 (77.4464)  Acc@5: 100.0000 (95.7098)  time: 0.3472  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3670/3750]  eta: 0:00:27  Lr: 0.001875  Loss: -0.0004  Acc@1: 75.0000 (77.4397)  Acc@5: 100.0000 (95.7130)  time: 0.3486  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [3680/3750]  eta: 0:00:24  Lr: 0.001875  Loss: -0.4283  Acc@1: 75.0000 (77.4467)  Acc@5: 100.0000 (95.7128)  time: 0.3494  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [3690/3750]  eta: 0:00:20  Lr: 0.001875  Loss: -0.9231  Acc@1: 81.2500 (77.4536)  Acc@5: 93.7500 (95.7125)  time: 0.3503  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [3700/3750]  eta: 0:00:17  Lr: 0.001875  Loss: -0.9760  Acc@1: 87.5000 (77.4791)  Acc@5: 100.0000 (95.7191)  time: 0.3507  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [3710/3750]  eta: 0:00:13  Lr: 0.001875  Loss: -0.8796  Acc@1: 87.5000 (77.4960)  Acc@5: 100.0000 (95.7255)  time: 0.3485  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [3720/3750]  eta: 0:00:10  Lr: 0.001875  Loss: -1.1466  Acc@1: 81.2500 (77.4976)  Acc@5: 93.7500 (95.7186)  time: 0.3465  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3730/3750]  eta: 0:00:06  Lr: 0.001875  Loss: -1.2269  Acc@1: 81.2500 (77.5027)  Acc@5: 93.7500 (95.7217)  time: 0.3474  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [3740/3750]  eta: 0:00:03  Lr: 0.001875  Loss: -0.6216  Acc@1: 81.2500 (77.4993)  Acc@5: 100.0000 (95.7214)  time: 0.3482  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [3749/3750]  eta: 0:00:00  Lr: 0.001875  Loss: -0.4927  Acc@1: 81.2500 (77.5117)  Acc@5: 100.0000 (95.7250)  time: 0.3481  data: 0.0010  max mem: 2500
Train: Epoch[1/5] Total time: 0:21:51 (0.3496 s / it)
{0: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 1: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 2: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 3: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 4: {0: 0, 1: 60000, 2: 0, 3: 0, 4: 0}, 5: {0: 0, 1: 60000, 2: 0, 3: 0, 4: 0}, 6: {0: 0, 1: 60000, 2: 0, 3: 0, 4: 0}, 7: {0: 0, 1: 60000, 2: 0, 3: 0, 4: 0}, 8: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 9: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 10: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 11: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 12: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 13: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 14: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 15: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 16: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 17: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 18: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 19: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}}
Averaged stats: Lr: 0.001875  Loss: -0.4927  Acc@1: 81.2500 (77.5117)  Acc@5: 100.0000 (95.7250)
Train: Epoch[2/5]  [   0/3750]  eta: 0:48:06  Lr: 0.001875  Loss: -1.1384  Acc@1: 87.5000 (87.5000)  Acc@5: 93.7500 (93.7500)  time: 0.7698  data: 0.4218  max mem: 2500
Train: Epoch[2/5]  [  10/3750]  eta: 0:24:09  Lr: 0.001875  Loss: -0.9478  Acc@1: 81.2500 (79.5455)  Acc@5: 93.7500 (93.7500)  time: 0.3876  data: 0.0387  max mem: 2500
Train: Epoch[2/5]  [  20/3750]  eta: 0:22:58  Lr: 0.001875  Loss: -1.0259  Acc@1: 81.2500 (83.0357)  Acc@5: 93.7500 (95.2381)  time: 0.3496  data: 0.0016  max mem: 2500
Train: Epoch[2/5]  [  30/3750]  eta: 0:22:30  Lr: 0.001875  Loss: -1.0632  Acc@1: 87.5000 (82.2581)  Acc@5: 93.7500 (95.3629)  time: 0.3495  data: 0.0016  max mem: 2500
Train: Epoch[2/5]  [  40/3750]  eta: 0:22:14  Lr: 0.001875  Loss: -1.1872  Acc@1: 81.2500 (82.4695)  Acc@5: 93.7500 (95.4268)  time: 0.3495  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [  50/3750]  eta: 0:22:03  Lr: 0.001875  Loss: -0.3358  Acc@1: 81.2500 (81.8627)  Acc@5: 93.7500 (95.3431)  time: 0.3492  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [  60/3750]  eta: 0:21:55  Lr: 0.001875  Loss: -0.5814  Acc@1: 75.0000 (80.8402)  Acc@5: 93.7500 (95.2869)  time: 0.3494  data: 0.0009  max mem: 2500
Train: Epoch[2/5]  [  70/3750]  eta: 0:21:47  Lr: 0.001875  Loss: -0.8270  Acc@1: 75.0000 (80.9859)  Acc@5: 93.7500 (95.3345)  time: 0.3494  data: 0.0015  max mem: 2500
Train: Epoch[2/5]  [  80/3750]  eta: 0:21:40  Lr: 0.001875  Loss: -0.9573  Acc@1: 81.2500 (81.0185)  Acc@5: 93.7500 (95.5247)  time: 0.3477  data: 0.0011  max mem: 2500
Train: Epoch[2/5]  [  90/3750]  eta: 0:21:33  Lr: 0.001875  Loss: -1.0143  Acc@1: 81.2500 (81.2500)  Acc@5: 93.7500 (95.3984)  time: 0.3469  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [ 100/3750]  eta: 0:21:28  Lr: 0.001875  Loss: -0.5556  Acc@1: 81.2500 (81.3738)  Acc@5: 93.7500 (95.4827)  time: 0.3480  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [ 110/3750]  eta: 0:21:24  Lr: 0.001875  Loss: -0.6125  Acc@1: 81.2500 (80.7995)  Acc@5: 100.0000 (95.6081)  time: 0.3496  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [ 120/3750]  eta: 0:21:19  Lr: 0.001875  Loss: -0.9084  Acc@1: 81.2500 (80.6302)  Acc@5: 100.0000 (95.6095)  time: 0.3493  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 130/3750]  eta: 0:21:14  Lr: 0.001875  Loss: -1.0755  Acc@1: 81.2500 (80.7252)  Acc@5: 93.7500 (95.6107)  time: 0.3476  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 140/3750]  eta: 0:21:09  Lr: 0.001875  Loss: -0.5719  Acc@1: 81.2500 (80.0975)  Acc@5: 93.7500 (95.4787)  time: 0.3480  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [ 150/3750]  eta: 0:21:05  Lr: 0.001875  Loss: -0.5897  Acc@1: 75.0000 (80.3394)  Acc@5: 100.0000 (95.5712)  time: 0.3479  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [ 160/3750]  eta: 0:21:00  Lr: 0.001875  Loss: -1.0120  Acc@1: 81.2500 (80.5901)  Acc@5: 100.0000 (95.7298)  time: 0.3469  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [ 170/3750]  eta: 0:20:56  Lr: 0.001875  Loss: -0.9026  Acc@1: 81.2500 (80.8480)  Acc@5: 100.0000 (95.7602)  time: 0.3479  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [ 180/3750]  eta: 0:20:53  Lr: 0.001875  Loss: -1.2798  Acc@1: 81.2500 (81.0083)  Acc@5: 93.7500 (95.7873)  time: 0.3503  data: 0.0019  max mem: 2500
Train: Epoch[2/5]  [ 190/3750]  eta: 0:20:49  Lr: 0.001875  Loss: -1.2084  Acc@1: 81.2500 (81.0537)  Acc@5: 100.0000 (95.8442)  time: 0.3505  data: 0.0021  max mem: 2500
Train: Epoch[2/5]  [ 200/3750]  eta: 0:20:45  Lr: 0.001875  Loss: -1.2215  Acc@1: 81.2500 (81.1567)  Acc@5: 100.0000 (95.8333)  time: 0.3490  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [ 210/3750]  eta: 0:20:42  Lr: 0.001875  Loss: -1.2180  Acc@1: 81.2500 (81.2204)  Acc@5: 93.7500 (95.8235)  time: 0.3498  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [ 220/3750]  eta: 0:20:38  Lr: 0.001875  Loss: -1.1399  Acc@1: 81.2500 (81.2500)  Acc@5: 100.0000 (95.8993)  time: 0.3506  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [ 230/3750]  eta: 0:20:34  Lr: 0.001875  Loss: -1.0100  Acc@1: 81.2500 (81.2500)  Acc@5: 93.7500 (95.8333)  time: 0.3496  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [ 240/3750]  eta: 0:20:30  Lr: 0.001875  Loss: -1.1423  Acc@1: 81.2500 (81.2500)  Acc@5: 100.0000 (95.8247)  time: 0.3491  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [ 250/3750]  eta: 0:20:27  Lr: 0.001875  Loss: -0.7674  Acc@1: 81.2500 (81.3745)  Acc@5: 100.0000 (95.9412)  time: 0.3492  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [ 260/3750]  eta: 0:20:23  Lr: 0.001875  Loss: -1.0400  Acc@1: 81.2500 (81.3218)  Acc@5: 100.0000 (95.8812)  time: 0.3487  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [ 270/3750]  eta: 0:20:19  Lr: 0.001875  Loss: -1.0960  Acc@1: 81.2500 (81.2731)  Acc@5: 93.7500 (95.8487)  time: 0.3494  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 280/3750]  eta: 0:20:16  Lr: 0.001875  Loss: -1.1240  Acc@1: 81.2500 (81.2055)  Acc@5: 93.7500 (95.9297)  time: 0.3495  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [ 290/3750]  eta: 0:20:12  Lr: 0.001875  Loss: -0.7142  Acc@1: 81.2500 (81.1426)  Acc@5: 100.0000 (95.9192)  time: 0.3510  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [ 300/3750]  eta: 0:20:09  Lr: 0.001875  Loss: -1.1812  Acc@1: 75.0000 (81.1047)  Acc@5: 100.0000 (95.9925)  time: 0.3513  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [ 310/3750]  eta: 0:20:05  Lr: 0.001875  Loss: -1.1759  Acc@1: 81.2500 (81.1897)  Acc@5: 100.0000 (96.1013)  time: 0.3496  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [ 320/3750]  eta: 0:20:01  Lr: 0.001875  Loss: -0.3142  Acc@1: 75.0000 (81.0358)  Acc@5: 100.0000 (96.0864)  time: 0.3488  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [ 330/3750]  eta: 0:19:58  Lr: 0.001875  Loss: -1.0824  Acc@1: 81.2500 (81.0612)  Acc@5: 93.7500 (96.0536)  time: 0.3484  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [ 340/3750]  eta: 0:19:54  Lr: 0.001875  Loss: -0.5301  Acc@1: 81.2500 (81.0117)  Acc@5: 93.7500 (96.0044)  time: 0.3493  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [ 350/3750]  eta: 0:19:50  Lr: 0.001875  Loss: -1.0166  Acc@1: 75.0000 (80.9295)  Acc@5: 93.7500 (95.9758)  time: 0.3488  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [ 360/3750]  eta: 0:19:47  Lr: 0.001875  Loss: -0.6157  Acc@1: 75.0000 (80.8518)  Acc@5: 93.7500 (95.9488)  time: 0.3483  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [ 370/3750]  eta: 0:19:43  Lr: 0.001875  Loss: -1.3246  Acc@1: 81.2500 (80.7615)  Acc@5: 93.7500 (95.9737)  time: 0.3498  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [ 380/3750]  eta: 0:19:40  Lr: 0.001875  Loss: -0.8991  Acc@1: 81.2500 (80.7415)  Acc@5: 100.0000 (95.9974)  time: 0.3504  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [ 390/3750]  eta: 0:19:36  Lr: 0.001875  Loss: -1.4410  Acc@1: 81.2500 (80.8184)  Acc@5: 100.0000 (96.0358)  time: 0.3495  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [ 400/3750]  eta: 0:19:33  Lr: 0.001875  Loss: -1.2402  Acc@1: 81.2500 (80.7201)  Acc@5: 100.0000 (96.0879)  time: 0.3487  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 410/3750]  eta: 0:19:29  Lr: 0.001875  Loss: -0.5952  Acc@1: 81.2500 (80.7634)  Acc@5: 100.0000 (96.0918)  time: 0.3482  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 420/3750]  eta: 0:19:25  Lr: 0.001875  Loss: -0.9525  Acc@1: 81.2500 (80.7601)  Acc@5: 100.0000 (96.1253)  time: 0.3482  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 430/3750]  eta: 0:19:22  Lr: 0.001875  Loss: -0.6351  Acc@1: 81.2500 (80.7860)  Acc@5: 100.0000 (96.1282)  time: 0.3510  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [ 440/3750]  eta: 0:19:19  Lr: 0.001875  Loss: -1.1655  Acc@1: 81.2500 (80.8248)  Acc@5: 93.7500 (96.1310)  time: 0.3524  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [ 450/3750]  eta: 0:19:15  Lr: 0.001875  Loss: -0.7589  Acc@1: 81.2500 (80.8481)  Acc@5: 93.7500 (96.1059)  time: 0.3504  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [ 460/3750]  eta: 0:19:12  Lr: 0.001875  Loss: -1.1919  Acc@1: 81.2500 (80.9246)  Acc@5: 93.7500 (96.1090)  time: 0.3509  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [ 470/3750]  eta: 0:19:08  Lr: 0.001875  Loss: -1.1947  Acc@1: 81.2500 (80.8917)  Acc@5: 100.0000 (96.1253)  time: 0.3507  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [ 480/3750]  eta: 0:19:04  Lr: 0.001875  Loss: -0.9659  Acc@1: 87.5000 (81.0551)  Acc@5: 100.0000 (96.1538)  time: 0.3486  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [ 490/3750]  eta: 0:19:01  Lr: 0.001875  Loss: -0.5959  Acc@1: 87.5000 (81.0591)  Acc@5: 93.7500 (96.0794)  time: 0.3489  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 500/3750]  eta: 0:18:57  Lr: 0.001875  Loss: -1.3816  Acc@1: 81.2500 (81.1003)  Acc@5: 93.7500 (96.0454)  time: 0.3503  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 510/3750]  eta: 0:18:54  Lr: 0.001875  Loss: -0.4604  Acc@1: 81.2500 (80.9809)  Acc@5: 93.7500 (96.0494)  time: 0.3501  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [ 520/3750]  eta: 0:18:50  Lr: 0.001875  Loss: -0.8912  Acc@1: 81.2500 (80.9981)  Acc@5: 100.0000 (96.1012)  time: 0.3498  data: 0.0019  max mem: 2500
Train: Epoch[2/5]  [ 530/3750]  eta: 0:18:47  Lr: 0.001875  Loss: -0.4318  Acc@1: 81.2500 (81.0264)  Acc@5: 100.0000 (96.0923)  time: 0.3492  data: 0.0018  max mem: 2500
Train: Epoch[2/5]  [ 540/3750]  eta: 0:18:43  Lr: 0.001875  Loss: -1.3353  Acc@1: 87.5000 (81.0998)  Acc@5: 100.0000 (96.1067)  time: 0.3480  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [ 550/3750]  eta: 0:18:40  Lr: 0.001875  Loss: -0.8189  Acc@1: 87.5000 (81.1479)  Acc@5: 100.0000 (96.1320)  time: 0.3488  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [ 560/3750]  eta: 0:18:36  Lr: 0.001875  Loss: -0.4817  Acc@1: 87.5000 (81.2166)  Acc@5: 100.0000 (96.1119)  time: 0.3500  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [ 570/3750]  eta: 0:18:33  Lr: 0.001875  Loss: -1.3774  Acc@1: 81.2500 (81.2609)  Acc@5: 93.7500 (96.1143)  time: 0.3490  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [ 580/3750]  eta: 0:18:29  Lr: 0.001875  Loss: -1.0196  Acc@1: 81.2500 (81.2715)  Acc@5: 100.0000 (96.0736)  time: 0.3481  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [ 590/3750]  eta: 0:18:25  Lr: 0.001875  Loss: -1.1154  Acc@1: 81.2500 (81.2183)  Acc@5: 100.0000 (96.0871)  time: 0.3487  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [ 600/3750]  eta: 0:18:22  Lr: 0.001875  Loss: -0.9344  Acc@1: 81.2500 (81.2812)  Acc@5: 100.0000 (96.0587)  time: 0.3488  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [ 610/3750]  eta: 0:18:18  Lr: 0.001875  Loss: -1.2386  Acc@1: 81.2500 (81.1886)  Acc@5: 100.0000 (96.0925)  time: 0.3500  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [ 620/3750]  eta: 0:18:15  Lr: 0.001875  Loss: -1.1055  Acc@1: 81.2500 (81.2198)  Acc@5: 100.0000 (96.1051)  time: 0.3502  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [ 630/3750]  eta: 0:18:11  Lr: 0.001875  Loss: -0.9294  Acc@1: 81.2500 (81.1807)  Acc@5: 93.7500 (96.0975)  time: 0.3498  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [ 640/3750]  eta: 0:18:08  Lr: 0.001875  Loss: -1.1334  Acc@1: 81.2500 (81.2110)  Acc@5: 93.7500 (96.0998)  time: 0.3501  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [ 650/3750]  eta: 0:18:04  Lr: 0.001875  Loss: -1.1525  Acc@1: 87.5000 (81.2404)  Acc@5: 100.0000 (96.1214)  time: 0.3488  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [ 660/3750]  eta: 0:18:01  Lr: 0.001875  Loss: -0.8612  Acc@1: 87.5000 (81.2973)  Acc@5: 100.0000 (96.1233)  time: 0.3481  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [ 670/3750]  eta: 0:17:57  Lr: 0.001875  Loss: -1.2815  Acc@1: 87.5000 (81.3338)  Acc@5: 100.0000 (96.1718)  time: 0.3484  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [ 680/3750]  eta: 0:17:54  Lr: 0.001875  Loss: -0.6811  Acc@1: 75.0000 (81.2775)  Acc@5: 100.0000 (96.1454)  time: 0.3491  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [ 690/3750]  eta: 0:17:50  Lr: 0.001875  Loss: -0.5620  Acc@1: 75.0000 (81.2681)  Acc@5: 93.7500 (96.1378)  time: 0.3491  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [ 700/3750]  eta: 0:17:47  Lr: 0.001875  Loss: -1.3188  Acc@1: 81.2500 (81.3392)  Acc@5: 93.7500 (96.1484)  time: 0.3492  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [ 710/3750]  eta: 0:17:43  Lr: 0.001875  Loss: -0.8465  Acc@1: 87.5000 (81.4082)  Acc@5: 100.0000 (96.1762)  time: 0.3495  data: 0.0012  max mem: 2500
Train: Epoch[2/5]  [ 720/3750]  eta: 0:17:40  Lr: 0.001875  Loss: -0.8275  Acc@1: 87.5000 (81.4234)  Acc@5: 100.0000 (96.1772)  time: 0.3495  data: 0.0012  max mem: 2500
Train: Epoch[2/5]  [ 730/3750]  eta: 0:17:36  Lr: 0.001875  Loss: -1.0524  Acc@1: 87.5000 (81.4466)  Acc@5: 93.7500 (96.1525)  time: 0.3500  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [ 740/3750]  eta: 0:17:32  Lr: 0.001875  Loss: -1.0070  Acc@1: 81.2500 (81.4187)  Acc@5: 93.7500 (96.1117)  time: 0.3488  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [ 750/3750]  eta: 0:17:29  Lr: 0.001875  Loss: -0.8825  Acc@1: 81.2500 (81.3998)  Acc@5: 93.7500 (96.1302)  time: 0.3477  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [ 760/3750]  eta: 0:17:25  Lr: 0.001875  Loss: -0.8269  Acc@1: 81.2500 (81.3732)  Acc@5: 93.7500 (96.1153)  time: 0.3487  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [ 770/3750]  eta: 0:17:22  Lr: 0.001875  Loss: -0.9016  Acc@1: 81.2500 (81.3716)  Acc@5: 100.0000 (96.1008)  time: 0.3493  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 780/3750]  eta: 0:17:18  Lr: 0.001875  Loss: -1.0891  Acc@1: 81.2500 (81.4020)  Acc@5: 100.0000 (96.1188)  time: 0.3489  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [ 790/3750]  eta: 0:17:15  Lr: 0.001875  Loss: -1.0151  Acc@1: 81.2500 (81.3922)  Acc@5: 100.0000 (96.1362)  time: 0.3508  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [ 800/3750]  eta: 0:17:12  Lr: 0.001875  Loss: -1.0747  Acc@1: 81.2500 (81.4295)  Acc@5: 100.0000 (96.1532)  time: 0.3537  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [ 810/3750]  eta: 0:17:08  Lr: 0.001875  Loss: -0.7815  Acc@1: 81.2500 (81.4041)  Acc@5: 100.0000 (96.1621)  time: 0.3528  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [ 820/3750]  eta: 0:17:05  Lr: 0.001875  Loss: -0.9469  Acc@1: 81.2500 (81.3946)  Acc@5: 100.0000 (96.1632)  time: 0.3494  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [ 830/3750]  eta: 0:17:01  Lr: 0.001875  Loss: -0.8785  Acc@1: 81.2500 (81.3854)  Acc@5: 93.7500 (96.1417)  time: 0.3479  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [ 840/3750]  eta: 0:16:57  Lr: 0.001875  Loss: -1.0525  Acc@1: 81.2500 (81.3986)  Acc@5: 100.0000 (96.1578)  time: 0.3478  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [ 850/3750]  eta: 0:16:54  Lr: 0.001875  Loss: -1.1292  Acc@1: 81.2500 (81.3455)  Acc@5: 100.0000 (96.1663)  time: 0.3480  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [ 860/3750]  eta: 0:16:50  Lr: 0.001875  Loss: 0.0556  Acc@1: 81.2500 (81.3371)  Acc@5: 93.7500 (96.1527)  time: 0.3490  data: 0.0009  max mem: 2500
Train: Epoch[2/5]  [ 870/3750]  eta: 0:16:47  Lr: 0.001875  Loss: -0.9945  Acc@1: 81.2500 (81.3863)  Acc@5: 100.0000 (96.1825)  time: 0.3497  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [ 880/3750]  eta: 0:16:43  Lr: 0.001875  Loss: -1.0572  Acc@1: 81.2500 (81.3919)  Acc@5: 100.0000 (96.2188)  time: 0.3490  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [ 890/3750]  eta: 0:16:40  Lr: 0.001875  Loss: -1.2657  Acc@1: 81.2500 (81.3903)  Acc@5: 100.0000 (96.2191)  time: 0.3487  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [ 900/3750]  eta: 0:16:36  Lr: 0.001875  Loss: -0.8154  Acc@1: 75.0000 (81.2708)  Acc@5: 93.7500 (96.2125)  time: 0.3503  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [ 910/3750]  eta: 0:16:33  Lr: 0.001875  Loss: -0.7978  Acc@1: 75.0000 (81.2363)  Acc@5: 100.0000 (96.2267)  time: 0.3494  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [ 920/3750]  eta: 0:16:29  Lr: 0.001875  Loss: -1.2142  Acc@1: 81.2500 (81.2229)  Acc@5: 100.0000 (96.2337)  time: 0.3474  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 930/3750]  eta: 0:16:26  Lr: 0.001875  Loss: -1.2652  Acc@1: 75.0000 (81.2030)  Acc@5: 100.0000 (96.2607)  time: 0.3475  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [ 940/3750]  eta: 0:16:22  Lr: 0.001875  Loss: -0.8428  Acc@1: 75.0000 (81.2035)  Acc@5: 100.0000 (96.2540)  time: 0.3474  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [ 950/3750]  eta: 0:16:19  Lr: 0.001875  Loss: -1.3174  Acc@1: 81.2500 (81.2434)  Acc@5: 93.7500 (96.2474)  time: 0.3481  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [ 960/3750]  eta: 0:16:15  Lr: 0.001875  Loss: -1.3700  Acc@1: 87.5000 (81.2370)  Acc@5: 100.0000 (96.2669)  time: 0.3483  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [ 970/3750]  eta: 0:16:11  Lr: 0.001875  Loss: -1.2541  Acc@1: 81.2500 (81.2629)  Acc@5: 100.0000 (96.2925)  time: 0.3471  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 980/3750]  eta: 0:16:08  Lr: 0.001875  Loss: -0.9955  Acc@1: 81.2500 (81.2627)  Acc@5: 100.0000 (96.2984)  time: 0.3471  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 990/3750]  eta: 0:16:04  Lr: 0.001875  Loss: -0.4046  Acc@1: 81.2500 (81.2122)  Acc@5: 100.0000 (96.3042)  time: 0.3474  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1000/3750]  eta: 0:16:01  Lr: 0.001875  Loss: -1.4460  Acc@1: 75.0000 (81.1938)  Acc@5: 93.7500 (96.3037)  time: 0.3484  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [1010/3750]  eta: 0:15:57  Lr: 0.001875  Loss: -0.7574  Acc@1: 81.2500 (81.1882)  Acc@5: 100.0000 (96.3093)  time: 0.3480  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1020/3750]  eta: 0:15:54  Lr: 0.001875  Loss: -0.8884  Acc@1: 81.2500 (81.1521)  Acc@5: 100.0000 (96.3149)  time: 0.3491  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1030/3750]  eta: 0:15:50  Lr: 0.001875  Loss: -1.1182  Acc@1: 81.2500 (81.1409)  Acc@5: 100.0000 (96.3385)  time: 0.3504  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [1040/3750]  eta: 0:15:47  Lr: 0.001875  Loss: -0.5616  Acc@1: 81.2500 (81.1479)  Acc@5: 100.0000 (96.3256)  time: 0.3491  data: 0.0011  max mem: 2500
Train: Epoch[2/5]  [1050/3750]  eta: 0:15:43  Lr: 0.001875  Loss: -0.9518  Acc@1: 87.5000 (81.1905)  Acc@5: 100.0000 (96.3487)  time: 0.3497  data: 0.0009  max mem: 2500
Train: Epoch[2/5]  [1060/3750]  eta: 0:15:40  Lr: 0.001875  Loss: -1.0003  Acc@1: 81.2500 (81.1970)  Acc@5: 100.0000 (96.3419)  time: 0.3505  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1070/3750]  eta: 0:15:36  Lr: 0.001875  Loss: -0.9736  Acc@1: 81.2500 (81.1625)  Acc@5: 100.0000 (96.3469)  time: 0.3489  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [1080/3750]  eta: 0:15:33  Lr: 0.001875  Loss: -0.8866  Acc@1: 75.0000 (81.1170)  Acc@5: 100.0000 (96.3402)  time: 0.3477  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [1090/3750]  eta: 0:15:29  Lr: 0.001875  Loss: -0.4347  Acc@1: 75.0000 (81.0552)  Acc@5: 93.7500 (96.3394)  time: 0.3481  data: 0.0010  max mem: 2500
Train: Epoch[2/5]  [1100/3750]  eta: 0:15:26  Lr: 0.001875  Loss: -0.9042  Acc@1: 75.0000 (81.0456)  Acc@5: 100.0000 (96.3442)  time: 0.3488  data: 0.0011  max mem: 2500
Train: Epoch[2/5]  [1110/3750]  eta: 0:15:22  Lr: 0.001875  Loss: -0.7392  Acc@1: 81.2500 (81.0250)  Acc@5: 100.0000 (96.3490)  time: 0.3500  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [1120/3750]  eta: 0:15:19  Lr: 0.001875  Loss: -1.1613  Acc@1: 81.2500 (81.0381)  Acc@5: 100.0000 (96.3593)  time: 0.3493  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1130/3750]  eta: 0:15:15  Lr: 0.001875  Loss: -1.0026  Acc@1: 87.5000 (81.0787)  Acc@5: 100.0000 (96.3638)  time: 0.3511  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [1140/3750]  eta: 0:15:12  Lr: 0.001875  Loss: -1.1805  Acc@1: 81.2500 (81.0418)  Acc@5: 93.7500 (96.3519)  time: 0.3515  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [1150/3750]  eta: 0:15:08  Lr: 0.001875  Loss: -1.2368  Acc@1: 81.2500 (81.0980)  Acc@5: 100.0000 (96.3673)  time: 0.3485  data: 0.0013  max mem: 2500
Train: Epoch[2/5]  [1160/3750]  eta: 0:15:05  Lr: 0.001875  Loss: -1.2329  Acc@1: 87.5000 (81.1154)  Acc@5: 100.0000 (96.3717)  time: 0.3480  data: 0.0012  max mem: 2500
Train: Epoch[2/5]  [1170/3750]  eta: 0:15:01  Lr: 0.001875  Loss: -0.6562  Acc@1: 81.2500 (81.1059)  Acc@5: 100.0000 (96.3760)  time: 0.3485  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1180/3750]  eta: 0:14:58  Lr: 0.001875  Loss: -0.6363  Acc@1: 81.2500 (81.1177)  Acc@5: 93.7500 (96.3749)  time: 0.3485  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1190/3750]  eta: 0:14:54  Lr: 0.001875  Loss: -1.0363  Acc@1: 81.2500 (81.1031)  Acc@5: 100.0000 (96.3738)  time: 0.3481  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1200/3750]  eta: 0:14:51  Lr: 0.001875  Loss: -1.2659  Acc@1: 81.2500 (81.1511)  Acc@5: 100.0000 (96.3728)  time: 0.3492  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1210/3750]  eta: 0:14:47  Lr: 0.001875  Loss: -1.0796  Acc@1: 87.5000 (81.1313)  Acc@5: 93.7500 (96.3718)  time: 0.3494  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [1220/3750]  eta: 0:14:44  Lr: 0.001875  Loss: -1.2705  Acc@1: 81.2500 (81.1476)  Acc@5: 100.0000 (96.3862)  time: 0.3496  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [1230/3750]  eta: 0:14:40  Lr: 0.001875  Loss: -1.3090  Acc@1: 81.2500 (81.1434)  Acc@5: 100.0000 (96.4003)  time: 0.3505  data: 0.0009  max mem: 2500
Train: Epoch[2/5]  [1240/3750]  eta: 0:14:37  Lr: 0.001875  Loss: -0.8033  Acc@1: 81.2500 (81.1543)  Acc@5: 100.0000 (96.3890)  time: 0.3503  data: 0.0014  max mem: 2500
Train: Epoch[2/5]  [1250/3750]  eta: 0:14:33  Lr: 0.001875  Loss: -1.4233  Acc@1: 81.2500 (81.1351)  Acc@5: 100.0000 (96.3879)  time: 0.3489  data: 0.0011  max mem: 2500
Train: Epoch[2/5]  [1260/3750]  eta: 0:14:30  Lr: 0.001875  Loss: -1.1633  Acc@1: 75.0000 (81.1013)  Acc@5: 100.0000 (96.4116)  time: 0.3483  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1270/3750]  eta: 0:14:26  Lr: 0.001875  Loss: -0.5399  Acc@1: 75.0000 (81.0681)  Acc@5: 100.0000 (96.4103)  time: 0.3494  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1280/3750]  eta: 0:14:23  Lr: 0.001875  Loss: -1.1588  Acc@1: 81.2500 (81.0841)  Acc@5: 93.7500 (96.4139)  time: 0.3502  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [1290/3750]  eta: 0:14:19  Lr: 0.001875  Loss: -1.3236  Acc@1: 87.5000 (81.1193)  Acc@5: 100.0000 (96.4175)  time: 0.3499  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [1300/3750]  eta: 0:14:16  Lr: 0.001875  Loss: -0.9148  Acc@1: 81.2500 (81.1107)  Acc@5: 93.7500 (96.4066)  time: 0.3493  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [1310/3750]  eta: 0:14:12  Lr: 0.001875  Loss: -0.9705  Acc@1: 75.0000 (81.0498)  Acc@5: 93.7500 (96.4054)  time: 0.3492  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1320/3750]  eta: 0:14:09  Lr: 0.001875  Loss: -0.8831  Acc@1: 75.0000 (81.0513)  Acc@5: 100.0000 (96.3995)  time: 0.3489  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1330/3750]  eta: 0:14:05  Lr: 0.001875  Loss: -0.6662  Acc@1: 81.2500 (81.0481)  Acc@5: 100.0000 (96.4031)  time: 0.3502  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [1340/3750]  eta: 0:14:02  Lr: 0.001875  Loss: -0.8866  Acc@1: 81.2500 (81.0962)  Acc@5: 100.0000 (96.4299)  time: 0.3506  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [1350/3750]  eta: 0:13:58  Lr: 0.001875  Loss: -0.9070  Acc@1: 87.5000 (81.1297)  Acc@5: 100.0000 (96.4286)  time: 0.3488  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1360/3750]  eta: 0:13:55  Lr: 0.001875  Loss: -0.8690  Acc@1: 81.2500 (81.0985)  Acc@5: 93.7500 (96.4273)  time: 0.3494  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1370/3750]  eta: 0:13:51  Lr: 0.001875  Loss: -1.0266  Acc@1: 81.2500 (81.1087)  Acc@5: 93.7500 (96.4214)  time: 0.3509  data: 0.0013  max mem: 2500
Train: Epoch[2/5]  [1380/3750]  eta: 0:13:48  Lr: 0.001875  Loss: -0.3623  Acc@1: 75.0000 (81.0599)  Acc@5: 93.7500 (96.4111)  time: 0.3525  data: 0.0013  max mem: 2500
Train: Epoch[2/5]  [1390/3750]  eta: 0:13:44  Lr: 0.001875  Loss: -0.8961  Acc@1: 75.0000 (81.0838)  Acc@5: 100.0000 (96.4189)  time: 0.3520  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1400/3750]  eta: 0:13:41  Lr: 0.001875  Loss: -0.4760  Acc@1: 81.2500 (81.0760)  Acc@5: 100.0000 (96.4356)  time: 0.3498  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1410/3750]  eta: 0:13:37  Lr: 0.001875  Loss: -1.4413  Acc@1: 81.2500 (81.1083)  Acc@5: 100.0000 (96.4520)  time: 0.3497  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [1420/3750]  eta: 0:13:34  Lr: 0.001875  Loss: -1.3693  Acc@1: 87.5000 (81.1224)  Acc@5: 100.0000 (96.4638)  time: 0.3491  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [1430/3750]  eta: 0:13:30  Lr: 0.001875  Loss: -0.7778  Acc@1: 81.2500 (81.1364)  Acc@5: 100.0000 (96.4754)  time: 0.3495  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [1440/3750]  eta: 0:13:27  Lr: 0.001875  Loss: -0.9338  Acc@1: 81.2500 (81.1329)  Acc@5: 100.0000 (96.4912)  time: 0.3511  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [1450/3750]  eta: 0:13:24  Lr: 0.001875  Loss: -0.8958  Acc@1: 81.2500 (81.1509)  Acc@5: 100.0000 (96.4981)  time: 0.3522  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [1460/3750]  eta: 0:13:20  Lr: 0.001875  Loss: -0.9717  Acc@1: 81.2500 (81.1388)  Acc@5: 100.0000 (96.5092)  time: 0.3527  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [1470/3750]  eta: 0:13:17  Lr: 0.001875  Loss: -0.8411  Acc@1: 81.2500 (81.1565)  Acc@5: 100.0000 (96.5160)  time: 0.3502  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [1480/3750]  eta: 0:13:13  Lr: 0.001875  Loss: -0.6220  Acc@1: 81.2500 (81.1150)  Acc@5: 100.0000 (96.5184)  time: 0.3490  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1490/3750]  eta: 0:13:10  Lr: 0.001875  Loss: -1.2642  Acc@1: 81.2500 (81.1159)  Acc@5: 100.0000 (96.5250)  time: 0.3499  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1500/3750]  eta: 0:13:06  Lr: 0.001875  Loss: -1.1491  Acc@1: 81.2500 (81.1334)  Acc@5: 100.0000 (96.5232)  time: 0.3495  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1510/3750]  eta: 0:13:03  Lr: 0.001875  Loss: -0.8091  Acc@1: 81.2500 (81.1300)  Acc@5: 100.0000 (96.5296)  time: 0.3491  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [1520/3750]  eta: 0:12:59  Lr: 0.001875  Loss: -0.5140  Acc@1: 81.2500 (81.1267)  Acc@5: 93.7500 (96.5155)  time: 0.3490  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [1530/3750]  eta: 0:12:56  Lr: 0.001875  Loss: -1.3789  Acc@1: 81.2500 (81.0990)  Acc@5: 93.7500 (96.5015)  time: 0.3490  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [1540/3750]  eta: 0:12:52  Lr: 0.001875  Loss: -1.0896  Acc@1: 75.0000 (81.0837)  Acc@5: 93.7500 (96.4917)  time: 0.3497  data: 0.0014  max mem: 2500
Train: Epoch[2/5]  [1550/3750]  eta: 0:12:49  Lr: 0.001875  Loss: -0.9923  Acc@1: 81.2500 (81.0888)  Acc@5: 100.0000 (96.4982)  time: 0.3512  data: 0.0012  max mem: 2500
Train: Epoch[2/5]  [1560/3750]  eta: 0:12:45  Lr: 0.001875  Loss: -0.9215  Acc@1: 81.2500 (81.0778)  Acc@5: 100.0000 (96.4966)  time: 0.3518  data: 0.0013  max mem: 2500
Train: Epoch[2/5]  [1570/3750]  eta: 0:12:42  Lr: 0.001875  Loss: -0.7147  Acc@1: 81.2500 (81.0948)  Acc@5: 93.7500 (96.4871)  time: 0.3500  data: 0.0013  max mem: 2500
Train: Epoch[2/5]  [1580/3750]  eta: 0:12:38  Lr: 0.001875  Loss: -1.1167  Acc@1: 81.2500 (81.0879)  Acc@5: 93.7500 (96.4896)  time: 0.3488  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1590/3750]  eta: 0:12:35  Lr: 0.001875  Loss: -0.5738  Acc@1: 81.2500 (81.0889)  Acc@5: 93.7500 (96.4920)  time: 0.3489  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [1600/3750]  eta: 0:12:31  Lr: 0.001875  Loss: -0.7135  Acc@1: 81.2500 (81.0704)  Acc@5: 93.7500 (96.4788)  time: 0.3494  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [1610/3750]  eta: 0:12:28  Lr: 0.001875  Loss: -1.3708  Acc@1: 81.2500 (81.0793)  Acc@5: 93.7500 (96.4735)  time: 0.3511  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [1620/3750]  eta: 0:12:24  Lr: 0.001875  Loss: -0.9172  Acc@1: 81.2500 (81.0881)  Acc@5: 93.7500 (96.4721)  time: 0.3517  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [1630/3750]  eta: 0:12:21  Lr: 0.001875  Loss: -0.7028  Acc@1: 81.2500 (81.0661)  Acc@5: 93.7500 (96.4669)  time: 0.3521  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1640/3750]  eta: 0:12:17  Lr: 0.001875  Loss: -1.2195  Acc@1: 81.2500 (81.0710)  Acc@5: 100.0000 (96.4732)  time: 0.3506  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [1650/3750]  eta: 0:12:14  Lr: 0.001875  Loss: -0.9768  Acc@1: 81.2500 (81.0683)  Acc@5: 100.0000 (96.4643)  time: 0.3485  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [1660/3750]  eta: 0:12:10  Lr: 0.001875  Loss: -0.3943  Acc@1: 75.0000 (81.0543)  Acc@5: 93.7500 (96.4705)  time: 0.3491  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1670/3750]  eta: 0:12:07  Lr: 0.001875  Loss: -0.9997  Acc@1: 75.0000 (81.0630)  Acc@5: 100.0000 (96.4729)  time: 0.3490  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1680/3750]  eta: 0:12:03  Lr: 0.001875  Loss: -1.1877  Acc@1: 81.2500 (81.0418)  Acc@5: 100.0000 (96.4679)  time: 0.3490  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1690/3750]  eta: 0:12:00  Lr: 0.001875  Loss: -0.9400  Acc@1: 81.2500 (81.0356)  Acc@5: 100.0000 (96.4777)  time: 0.3494  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1700/3750]  eta: 0:11:56  Lr: 0.001875  Loss: -0.8902  Acc@1: 81.2500 (81.0442)  Acc@5: 100.0000 (96.4727)  time: 0.3490  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1710/3750]  eta: 0:11:53  Lr: 0.001875  Loss: -1.0171  Acc@1: 81.2500 (81.0418)  Acc@5: 93.7500 (96.4714)  time: 0.3488  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [1720/3750]  eta: 0:11:49  Lr: 0.001875  Loss: -0.5290  Acc@1: 81.2500 (81.0285)  Acc@5: 93.7500 (96.4701)  time: 0.3490  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [1730/3750]  eta: 0:11:46  Lr: 0.001875  Loss: -1.0244  Acc@1: 81.2500 (81.0406)  Acc@5: 93.7500 (96.4652)  time: 0.3482  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1740/3750]  eta: 0:11:42  Lr: 0.001875  Loss: -1.0301  Acc@1: 81.2500 (81.0238)  Acc@5: 93.7500 (96.4496)  time: 0.3478  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1750/3750]  eta: 0:11:39  Lr: 0.001875  Loss: -1.2667  Acc@1: 81.2500 (81.0323)  Acc@5: 93.7500 (96.4520)  time: 0.3491  data: 0.0012  max mem: 2500
Train: Epoch[2/5]  [1760/3750]  eta: 0:11:35  Lr: 0.001875  Loss: -0.5297  Acc@1: 81.2500 (81.0193)  Acc@5: 93.7500 (96.4367)  time: 0.3504  data: 0.0014  max mem: 2500
Train: Epoch[2/5]  [1770/3750]  eta: 0:11:32  Lr: 0.001875  Loss: -1.3401  Acc@1: 81.2500 (81.0100)  Acc@5: 93.7500 (96.4286)  time: 0.3502  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [1780/3750]  eta: 0:11:28  Lr: 0.001875  Loss: -0.6103  Acc@1: 81.2500 (81.0079)  Acc@5: 93.7500 (96.4206)  time: 0.3523  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [1790/3750]  eta: 0:11:25  Lr: 0.001875  Loss: -1.0856  Acc@1: 87.5000 (81.0267)  Acc@5: 100.0000 (96.4405)  time: 0.3541  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [1800/3750]  eta: 0:11:21  Lr: 0.001875  Loss: -0.7924  Acc@1: 81.2500 (81.0348)  Acc@5: 100.0000 (96.4499)  time: 0.3529  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1810/3750]  eta: 0:11:18  Lr: 0.001875  Loss: -1.2200  Acc@1: 81.2500 (81.0636)  Acc@5: 100.0000 (96.4591)  time: 0.3499  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1820/3750]  eta: 0:11:14  Lr: 0.001875  Loss: -0.5568  Acc@1: 81.2500 (81.0750)  Acc@5: 100.0000 (96.4683)  time: 0.3479  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1830/3750]  eta: 0:11:11  Lr: 0.001875  Loss: -1.2386  Acc@1: 81.2500 (81.0623)  Acc@5: 100.0000 (96.4637)  time: 0.3489  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1840/3750]  eta: 0:11:07  Lr: 0.001875  Loss: -1.0835  Acc@1: 81.2500 (81.0803)  Acc@5: 93.7500 (96.4625)  time: 0.3495  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [1850/3750]  eta: 0:11:04  Lr: 0.001875  Loss: -1.2112  Acc@1: 87.5000 (81.0947)  Acc@5: 100.0000 (96.4546)  time: 0.3494  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [1860/3750]  eta: 0:11:00  Lr: 0.001875  Loss: -0.4449  Acc@1: 75.0000 (81.0586)  Acc@5: 100.0000 (96.4468)  time: 0.3501  data: 0.0014  max mem: 2500
Train: Epoch[2/5]  [1870/3750]  eta: 0:10:57  Lr: 0.001875  Loss: -1.0947  Acc@1: 75.0000 (81.0329)  Acc@5: 93.7500 (96.4290)  time: 0.3502  data: 0.0012  max mem: 2500
Train: Epoch[2/5]  [1880/3750]  eta: 0:10:53  Lr: 0.001875  Loss: -1.1650  Acc@1: 81.2500 (81.0340)  Acc@5: 93.7500 (96.4281)  time: 0.3492  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1890/3750]  eta: 0:10:50  Lr: 0.001875  Loss: -0.9731  Acc@1: 81.2500 (81.0219)  Acc@5: 93.7500 (96.4272)  time: 0.3484  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1900/3750]  eta: 0:10:46  Lr: 0.001875  Loss: -0.4169  Acc@1: 75.0000 (81.0166)  Acc@5: 100.0000 (96.4262)  time: 0.3473  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1910/3750]  eta: 0:10:43  Lr: 0.001875  Loss: -0.4581  Acc@1: 75.0000 (80.9753)  Acc@5: 100.0000 (96.4286)  time: 0.3482  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1920/3750]  eta: 0:10:39  Lr: 0.001875  Loss: -0.6255  Acc@1: 75.0000 (80.9800)  Acc@5: 100.0000 (96.4341)  time: 0.3495  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1930/3750]  eta: 0:10:36  Lr: 0.001875  Loss: -0.5931  Acc@1: 81.2500 (80.9619)  Acc@5: 100.0000 (96.4300)  time: 0.3518  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1940/3750]  eta: 0:10:32  Lr: 0.001875  Loss: -1.0340  Acc@1: 81.2500 (80.9827)  Acc@5: 100.0000 (96.4355)  time: 0.3514  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1950/3750]  eta: 0:10:29  Lr: 0.001875  Loss: -0.7983  Acc@1: 81.2500 (80.9777)  Acc@5: 100.0000 (96.4377)  time: 0.3489  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1960/3750]  eta: 0:10:25  Lr: 0.001875  Loss: -0.6596  Acc@1: 81.2500 (80.9791)  Acc@5: 93.7500 (96.4272)  time: 0.3496  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1970/3750]  eta: 0:10:22  Lr: 0.001875  Loss: -1.1477  Acc@1: 81.2500 (80.9646)  Acc@5: 93.7500 (96.4263)  time: 0.3488  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1980/3750]  eta: 0:10:18  Lr: 0.001875  Loss: -0.7182  Acc@1: 81.2500 (80.9944)  Acc@5: 100.0000 (96.4412)  time: 0.3486  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1990/3750]  eta: 0:10:15  Lr: 0.001875  Loss: -0.9021  Acc@1: 81.2500 (80.9989)  Acc@5: 100.0000 (96.4371)  time: 0.3494  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [2000/3750]  eta: 0:10:11  Lr: 0.001875  Loss: -0.8072  Acc@1: 81.2500 (81.0095)  Acc@5: 100.0000 (96.4549)  time: 0.3489  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [2010/3750]  eta: 0:10:08  Lr: 0.001875  Loss: -0.9254  Acc@1: 81.2500 (81.0076)  Acc@5: 100.0000 (96.4694)  time: 0.3483  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [2020/3750]  eta: 0:10:04  Lr: 0.001875  Loss: -1.0425  Acc@1: 81.2500 (81.0150)  Acc@5: 100.0000 (96.4776)  time: 0.3473  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [2030/3750]  eta: 0:10:01  Lr: 0.001875  Loss: -1.0196  Acc@1: 81.2500 (81.0346)  Acc@5: 100.0000 (96.4796)  time: 0.3481  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [2040/3750]  eta: 0:09:57  Lr: 0.001875  Loss: -1.1711  Acc@1: 81.2500 (81.0295)  Acc@5: 100.0000 (96.4846)  time: 0.3485  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [2050/3750]  eta: 0:09:54  Lr: 0.001875  Loss: -0.2356  Acc@1: 75.0000 (81.0032)  Acc@5: 93.7500 (96.4743)  time: 0.3484  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [2060/3750]  eta: 0:09:50  Lr: 0.001875  Loss: -1.1743  Acc@1: 75.0000 (80.9983)  Acc@5: 93.7500 (96.4732)  time: 0.3484  data: 0.0009  max mem: 2500
Train: Epoch[2/5]  [2070/3750]  eta: 0:09:47  Lr: 0.001875  Loss: -0.7260  Acc@1: 81.2500 (80.9995)  Acc@5: 100.0000 (96.4751)  time: 0.3484  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [2080/3750]  eta: 0:09:43  Lr: 0.001875  Loss: -1.3847  Acc@1: 81.2500 (81.0127)  Acc@5: 100.0000 (96.4771)  time: 0.3497  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2090/3750]  eta: 0:09:40  Lr: 0.001875  Loss: -0.9627  Acc@1: 87.5000 (81.0049)  Acc@5: 100.0000 (96.4730)  time: 0.3499  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [2100/3750]  eta: 0:09:36  Lr: 0.001875  Loss: -0.8026  Acc@1: 81.2500 (80.9942)  Acc@5: 100.0000 (96.4719)  time: 0.3491  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [2110/3750]  eta: 0:09:33  Lr: 0.001875  Loss: -0.9290  Acc@1: 81.2500 (81.0161)  Acc@5: 100.0000 (96.4738)  time: 0.3480  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2120/3750]  eta: 0:09:29  Lr: 0.001875  Loss: -1.1793  Acc@1: 87.5000 (81.0319)  Acc@5: 100.0000 (96.4757)  time: 0.3480  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [2130/3750]  eta: 0:09:26  Lr: 0.001875  Loss: -0.6193  Acc@1: 81.2500 (81.0388)  Acc@5: 100.0000 (96.4805)  time: 0.3493  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [2140/3750]  eta: 0:09:22  Lr: 0.001875  Loss: -0.9784  Acc@1: 81.2500 (81.0427)  Acc@5: 93.7500 (96.4678)  time: 0.3492  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [2150/3750]  eta: 0:09:19  Lr: 0.001875  Loss: -0.6280  Acc@1: 81.2500 (81.0699)  Acc@5: 93.7500 (96.4609)  time: 0.3488  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [2160/3750]  eta: 0:09:15  Lr: 0.001875  Loss: -0.9439  Acc@1: 81.2500 (81.0620)  Acc@5: 93.7500 (96.4571)  time: 0.3488  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [2170/3750]  eta: 0:09:12  Lr: 0.001875  Loss: -0.9471  Acc@1: 81.2500 (81.0744)  Acc@5: 93.7500 (96.4619)  time: 0.3494  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [2180/3750]  eta: 0:09:08  Lr: 0.001875  Loss: -0.4781  Acc@1: 81.2500 (81.0609)  Acc@5: 100.0000 (96.4580)  time: 0.3500  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [2190/3750]  eta: 0:09:05  Lr: 0.001875  Loss: -0.9533  Acc@1: 75.0000 (81.0418)  Acc@5: 93.7500 (96.4571)  time: 0.3497  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [2200/3750]  eta: 0:09:01  Lr: 0.001875  Loss: -1.1925  Acc@1: 75.0000 (81.0285)  Acc@5: 93.7500 (96.4533)  time: 0.3501  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [2210/3750]  eta: 0:08:58  Lr: 0.001875  Loss: -0.8313  Acc@1: 75.0000 (81.0154)  Acc@5: 93.7500 (96.4467)  time: 0.3492  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [2220/3750]  eta: 0:08:54  Lr: 0.001875  Loss: -0.2896  Acc@1: 75.0000 (81.0080)  Acc@5: 93.7500 (96.4487)  time: 0.3484  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [2230/3750]  eta: 0:08:51  Lr: 0.001875  Loss: -1.1275  Acc@1: 81.2500 (81.0231)  Acc@5: 100.0000 (96.4534)  time: 0.3491  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [2240/3750]  eta: 0:08:47  Lr: 0.001875  Loss: -1.0208  Acc@1: 81.2500 (81.0213)  Acc@5: 100.0000 (96.4581)  time: 0.3499  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [2250/3750]  eta: 0:08:44  Lr: 0.001875  Loss: -0.6374  Acc@1: 81.2500 (81.0029)  Acc@5: 100.0000 (96.4488)  time: 0.3490  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [2260/3750]  eta: 0:08:40  Lr: 0.001875  Loss: -0.7484  Acc@1: 81.2500 (81.0067)  Acc@5: 100.0000 (96.4534)  time: 0.3488  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [2270/3750]  eta: 0:08:37  Lr: 0.001875  Loss: -0.8267  Acc@1: 87.5000 (81.0243)  Acc@5: 100.0000 (96.4498)  time: 0.3491  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [2280/3750]  eta: 0:08:33  Lr: 0.001875  Loss: -0.6502  Acc@1: 81.2500 (81.0308)  Acc@5: 93.7500 (96.4544)  time: 0.3479  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [2290/3750]  eta: 0:08:30  Lr: 0.001875  Loss: -0.9648  Acc@1: 81.2500 (81.0372)  Acc@5: 100.0000 (96.4590)  time: 0.3489  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [2300/3750]  eta: 0:08:26  Lr: 0.001875  Loss: -1.1350  Acc@1: 81.2500 (81.0354)  Acc@5: 100.0000 (96.4662)  time: 0.3493  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [2310/3750]  eta: 0:08:23  Lr: 0.001875  Loss: -0.3687  Acc@1: 81.2500 (81.0445)  Acc@5: 100.0000 (96.4734)  time: 0.3488  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [2320/3750]  eta: 0:08:19  Lr: 0.001875  Loss: -0.7935  Acc@1: 81.2500 (81.0319)  Acc@5: 100.0000 (96.4670)  time: 0.3483  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [2330/3750]  eta: 0:08:16  Lr: 0.001875  Loss: -0.8365  Acc@1: 81.2500 (81.0087)  Acc@5: 100.0000 (96.4634)  time: 0.3472  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [2340/3750]  eta: 0:08:12  Lr: 0.001875  Loss: -1.0859  Acc@1: 81.2500 (81.0044)  Acc@5: 100.0000 (96.4652)  time: 0.3478  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [2350/3750]  eta: 0:08:09  Lr: 0.001875  Loss: -0.7343  Acc@1: 81.2500 (80.9895)  Acc@5: 100.0000 (96.4669)  time: 0.3487  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [2360/3750]  eta: 0:08:05  Lr: 0.001875  Loss: -1.1649  Acc@1: 81.2500 (81.0091)  Acc@5: 100.0000 (96.4660)  time: 0.3492  data: 0.0012  max mem: 2500
Train: Epoch[2/5]  [2370/3750]  eta: 0:08:02  Lr: 0.001875  Loss: -1.2607  Acc@1: 81.2500 (81.0207)  Acc@5: 100.0000 (96.4730)  time: 0.3486  data: 0.0014  max mem: 2500
Train: Epoch[2/5]  [2380/3750]  eta: 0:07:58  Lr: 0.001875  Loss: -1.2575  Acc@1: 81.2500 (81.0426)  Acc@5: 100.0000 (96.4799)  time: 0.3497  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [2390/3750]  eta: 0:07:55  Lr: 0.001875  Loss: -0.4474  Acc@1: 81.2500 (81.0409)  Acc@5: 100.0000 (96.4894)  time: 0.3509  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [2400/3750]  eta: 0:07:51  Lr: 0.001875  Loss: -0.8621  Acc@1: 81.2500 (81.0496)  Acc@5: 100.0000 (96.4963)  time: 0.3501  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [2410/3750]  eta: 0:07:48  Lr: 0.001875  Loss: -0.7784  Acc@1: 81.2500 (81.0608)  Acc@5: 100.0000 (96.5056)  time: 0.3485  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [2420/3750]  eta: 0:07:44  Lr: 0.001875  Loss: -0.6823  Acc@1: 81.2500 (81.0564)  Acc@5: 100.0000 (96.5097)  time: 0.3478  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2430/3750]  eta: 0:07:41  Lr: 0.001875  Loss: -0.7356  Acc@1: 81.2500 (81.0572)  Acc@5: 100.0000 (96.5164)  time: 0.3483  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [2440/3750]  eta: 0:07:37  Lr: 0.001875  Loss: -0.8585  Acc@1: 81.2500 (81.0708)  Acc@5: 100.0000 (96.5281)  time: 0.3481  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [2450/3750]  eta: 0:07:34  Lr: 0.001875  Loss: -0.7315  Acc@1: 81.2500 (81.0715)  Acc@5: 100.0000 (96.5320)  time: 0.3486  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [2460/3750]  eta: 0:07:30  Lr: 0.001875  Loss: -0.8803  Acc@1: 81.2500 (81.0824)  Acc@5: 93.7500 (96.5283)  time: 0.3510  data: 0.0013  max mem: 2500
Train: Epoch[2/5]  [2470/3750]  eta: 0:07:27  Lr: 0.001875  Loss: -0.8698  Acc@1: 81.2500 (81.0932)  Acc@5: 93.7500 (96.5297)  time: 0.3512  data: 0.0014  max mem: 2500
Train: Epoch[2/5]  [2480/3750]  eta: 0:07:23  Lr: 0.001875  Loss: -1.1282  Acc@1: 81.2500 (81.0963)  Acc@5: 100.0000 (96.5337)  time: 0.3492  data: 0.0012  max mem: 2500
Train: Epoch[2/5]  [2490/3750]  eta: 0:07:20  Lr: 0.001875  Loss: -1.1267  Acc@1: 81.2500 (81.1120)  Acc@5: 100.0000 (96.5426)  time: 0.3489  data: 0.0012  max mem: 2500
Train: Epoch[2/5]  [2500/3750]  eta: 0:07:16  Lr: 0.001875  Loss: -0.9990  Acc@1: 81.2500 (81.1076)  Acc@5: 100.0000 (96.5539)  time: 0.3485  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [2510/3750]  eta: 0:07:13  Lr: 0.001875  Loss: -0.6350  Acc@1: 75.0000 (81.0857)  Acc@5: 100.0000 (96.5527)  time: 0.3481  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2520/3750]  eta: 0:07:09  Lr: 0.001875  Loss: -1.2980  Acc@1: 75.0000 (81.0641)  Acc@5: 100.0000 (96.5440)  time: 0.3484  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2530/3750]  eta: 0:07:06  Lr: 0.001875  Loss: -1.0981  Acc@1: 75.0000 (81.0599)  Acc@5: 93.7500 (96.5453)  time: 0.3485  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2540/3750]  eta: 0:07:02  Lr: 0.001875  Loss: -1.0013  Acc@1: 81.2500 (81.0557)  Acc@5: 100.0000 (96.5516)  time: 0.3492  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [2550/3750]  eta: 0:06:59  Lr: 0.001875  Loss: -1.2027  Acc@1: 81.2500 (81.0638)  Acc@5: 100.0000 (96.5553)  time: 0.3509  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [2560/3750]  eta: 0:06:55  Lr: 0.001875  Loss: -1.0319  Acc@1: 81.2500 (81.0743)  Acc@5: 100.0000 (96.5687)  time: 0.3496  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [2570/3750]  eta: 0:06:52  Lr: 0.001875  Loss: -0.9040  Acc@1: 81.2500 (81.0750)  Acc@5: 100.0000 (96.5723)  time: 0.3502  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [2580/3750]  eta: 0:06:48  Lr: 0.001875  Loss: -1.2110  Acc@1: 81.2500 (81.0756)  Acc@5: 100.0000 (96.5735)  time: 0.3504  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [2590/3750]  eta: 0:06:45  Lr: 0.001875  Loss: -0.9311  Acc@1: 81.2500 (81.0787)  Acc@5: 100.0000 (96.5795)  time: 0.3493  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [2600/3750]  eta: 0:06:41  Lr: 0.001875  Loss: -1.2718  Acc@1: 81.2500 (81.0794)  Acc@5: 100.0000 (96.5758)  time: 0.3513  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [2610/3750]  eta: 0:06:38  Lr: 0.001875  Loss: -1.0573  Acc@1: 81.2500 (81.0848)  Acc@5: 93.7500 (96.5698)  time: 0.3501  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2620/3750]  eta: 0:06:34  Lr: 0.001875  Loss: -0.5442  Acc@1: 81.2500 (81.0878)  Acc@5: 93.7500 (96.5638)  time: 0.3477  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [2630/3750]  eta: 0:06:31  Lr: 0.001875  Loss: -0.8128  Acc@1: 81.2500 (81.0932)  Acc@5: 93.7500 (96.5602)  time: 0.3476  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [2640/3750]  eta: 0:06:27  Lr: 0.001875  Loss: -0.6214  Acc@1: 81.2500 (81.1033)  Acc@5: 93.7500 (96.5567)  time: 0.3485  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [2650/3750]  eta: 0:06:24  Lr: 0.001875  Loss: -0.9680  Acc@1: 81.2500 (81.1038)  Acc@5: 93.7500 (96.5555)  time: 0.3500  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [2660/3750]  eta: 0:06:20  Lr: 0.001875  Loss: -0.7773  Acc@1: 81.2500 (81.0973)  Acc@5: 100.0000 (96.5591)  time: 0.3504  data: 0.0014  max mem: 2500
Train: Epoch[2/5]  [2670/3750]  eta: 0:06:17  Lr: 0.001875  Loss: -0.9010  Acc@1: 81.2500 (81.0932)  Acc@5: 100.0000 (96.5556)  time: 0.3498  data: 0.0015  max mem: 2500
Train: Epoch[2/5]  [2680/3750]  eta: 0:06:13  Lr: 0.001875  Loss: -0.8187  Acc@1: 81.2500 (81.0822)  Acc@5: 100.0000 (96.5591)  time: 0.3496  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [2690/3750]  eta: 0:06:10  Lr: 0.001875  Loss: -1.2001  Acc@1: 81.2500 (81.0828)  Acc@5: 100.0000 (96.5556)  time: 0.3499  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [2700/3750]  eta: 0:06:06  Lr: 0.001875  Loss: -0.9561  Acc@1: 81.2500 (81.0788)  Acc@5: 100.0000 (96.5591)  time: 0.3498  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [2710/3750]  eta: 0:06:03  Lr: 0.001875  Loss: -1.1963  Acc@1: 81.2500 (81.0863)  Acc@5: 100.0000 (96.5603)  time: 0.3501  data: 0.0009  max mem: 2500
Train: Epoch[2/5]  [2720/3750]  eta: 0:05:59  Lr: 0.001875  Loss: -1.1845  Acc@1: 81.2500 (81.0800)  Acc@5: 100.0000 (96.5661)  time: 0.3500  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [2730/3750]  eta: 0:05:56  Lr: 0.001875  Loss: -0.5809  Acc@1: 81.2500 (81.0875)  Acc@5: 100.0000 (96.5626)  time: 0.3481  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2740/3750]  eta: 0:05:52  Lr: 0.001875  Loss: -0.6964  Acc@1: 81.2500 (81.1041)  Acc@5: 93.7500 (96.5615)  time: 0.3482  data: 0.0010  max mem: 2500
Train: Epoch[2/5]  [2750/3750]  eta: 0:05:49  Lr: 0.001875  Loss: -1.0762  Acc@1: 87.5000 (81.1182)  Acc@5: 93.7500 (96.5626)  time: 0.3482  data: 0.0010  max mem: 2500
Train: Epoch[2/5]  [2760/3750]  eta: 0:05:45  Lr: 0.001875  Loss: -0.7351  Acc@1: 81.2500 (81.1051)  Acc@5: 93.7500 (96.5615)  time: 0.3485  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [2770/3750]  eta: 0:05:42  Lr: 0.001875  Loss: -0.7738  Acc@1: 81.2500 (81.1011)  Acc@5: 93.7500 (96.5604)  time: 0.3486  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [2780/3750]  eta: 0:05:38  Lr: 0.001875  Loss: -0.9682  Acc@1: 81.2500 (81.0814)  Acc@5: 100.0000 (96.5660)  time: 0.3473  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [2790/3750]  eta: 0:05:35  Lr: 0.001875  Loss: -1.1369  Acc@1: 81.2500 (81.0932)  Acc@5: 100.0000 (96.5649)  time: 0.3477  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [2800/3750]  eta: 0:05:31  Lr: 0.001875  Loss: -0.4553  Acc@1: 87.5000 (81.0983)  Acc@5: 93.7500 (96.5593)  time: 0.3483  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [2810/3750]  eta: 0:05:28  Lr: 0.001875  Loss: -0.9990  Acc@1: 81.2500 (81.0988)  Acc@5: 93.7500 (96.5648)  time: 0.3487  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [2820/3750]  eta: 0:05:24  Lr: 0.001875  Loss: -1.0038  Acc@1: 81.2500 (81.0838)  Acc@5: 100.0000 (96.5593)  time: 0.3491  data: 0.0009  max mem: 2500
Train: Epoch[2/5]  [2830/3750]  eta: 0:05:21  Lr: 0.001875  Loss: -0.8235  Acc@1: 81.2500 (81.0822)  Acc@5: 93.7500 (96.5516)  time: 0.3504  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [2840/3750]  eta: 0:05:18  Lr: 0.001875  Loss: -1.0624  Acc@1: 81.2500 (81.1004)  Acc@5: 100.0000 (96.5549)  time: 0.3500  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [2850/3750]  eta: 0:05:14  Lr: 0.001875  Loss: -0.7900  Acc@1: 87.5000 (81.1075)  Acc@5: 100.0000 (96.5560)  time: 0.3489  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [2860/3750]  eta: 0:05:11  Lr: 0.001875  Loss: -1.3348  Acc@1: 81.2500 (81.1036)  Acc@5: 100.0000 (96.5571)  time: 0.3496  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [2870/3750]  eta: 0:05:07  Lr: 0.001875  Loss: -1.2699  Acc@1: 81.2500 (81.1281)  Acc@5: 100.0000 (96.5648)  time: 0.3493  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [2880/3750]  eta: 0:05:04  Lr: 0.001875  Loss: -1.1591  Acc@1: 81.2500 (81.1263)  Acc@5: 100.0000 (96.5680)  time: 0.3473  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2890/3750]  eta: 0:05:00  Lr: 0.001875  Loss: -0.8394  Acc@1: 81.2500 (81.1289)  Acc@5: 100.0000 (96.5669)  time: 0.3465  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2900/3750]  eta: 0:04:57  Lr: 0.001875  Loss: -1.2636  Acc@1: 81.2500 (81.1337)  Acc@5: 100.0000 (96.5723)  time: 0.3475  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2910/3750]  eta: 0:04:53  Lr: 0.001875  Loss: -0.6792  Acc@1: 81.2500 (81.1341)  Acc@5: 100.0000 (96.5626)  time: 0.3478  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [2920/3750]  eta: 0:04:50  Lr: 0.001875  Loss: -1.0155  Acc@1: 81.2500 (81.1387)  Acc@5: 93.7500 (96.5573)  time: 0.3495  data: 0.0014  max mem: 2500
Train: Epoch[2/5]  [2930/3750]  eta: 0:04:46  Lr: 0.001875  Loss: -0.3416  Acc@1: 81.2500 (81.1285)  Acc@5: 93.7500 (96.5519)  time: 0.3499  data: 0.0013  max mem: 2500
Train: Epoch[2/5]  [2940/3750]  eta: 0:04:43  Lr: 0.001875  Loss: -0.8538  Acc@1: 75.0000 (81.1161)  Acc@5: 93.7500 (96.5509)  time: 0.3484  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [2950/3750]  eta: 0:04:39  Lr: 0.001875  Loss: -1.3039  Acc@1: 81.2500 (81.1356)  Acc@5: 100.0000 (96.5584)  time: 0.3510  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [2960/3750]  eta: 0:04:36  Lr: 0.001875  Loss: -0.9418  Acc@1: 81.2500 (81.1255)  Acc@5: 100.0000 (96.5594)  time: 0.3513  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [2970/3750]  eta: 0:04:32  Lr: 0.001875  Loss: -1.0898  Acc@1: 81.2500 (81.1343)  Acc@5: 100.0000 (96.5605)  time: 0.3477  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2980/3750]  eta: 0:04:29  Lr: 0.001875  Loss: -0.8276  Acc@1: 81.2500 (81.1200)  Acc@5: 100.0000 (96.5678)  time: 0.3478  data: 0.0012  max mem: 2500
Train: Epoch[2/5]  [2990/3750]  eta: 0:04:25  Lr: 0.001875  Loss: -1.2149  Acc@1: 81.2500 (81.1184)  Acc@5: 100.0000 (96.5689)  time: 0.3481  data: 0.0013  max mem: 2500
Train: Epoch[2/5]  [3000/3750]  eta: 0:04:22  Lr: 0.001875  Loss: -1.0462  Acc@1: 81.2500 (81.1375)  Acc@5: 100.0000 (96.5720)  time: 0.3484  data: 0.0010  max mem: 2500
Train: Epoch[2/5]  [3010/3750]  eta: 0:04:18  Lr: 0.001875  Loss: -1.3366  Acc@1: 81.2500 (81.1483)  Acc@5: 100.0000 (96.5792)  time: 0.3508  data: 0.0011  max mem: 2500
Train: Epoch[2/5]  [3020/3750]  eta: 0:04:15  Lr: 0.001875  Loss: -0.8122  Acc@1: 81.2500 (81.1507)  Acc@5: 100.0000 (96.5781)  time: 0.3503  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [3030/3750]  eta: 0:04:11  Lr: 0.001875  Loss: -1.0405  Acc@1: 81.2500 (81.1593)  Acc@5: 93.7500 (96.5750)  time: 0.3477  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [3040/3750]  eta: 0:04:08  Lr: 0.001875  Loss: -1.1032  Acc@1: 81.2500 (81.1534)  Acc@5: 100.0000 (96.5760)  time: 0.3477  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [3050/3750]  eta: 0:04:04  Lr: 0.001875  Loss: -0.6804  Acc@1: 81.2500 (81.1660)  Acc@5: 100.0000 (96.5728)  time: 0.3480  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [3060/3750]  eta: 0:04:01  Lr: 0.001875  Loss: -1.1221  Acc@1: 81.2500 (81.1663)  Acc@5: 100.0000 (96.5779)  time: 0.3480  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [3070/3750]  eta: 0:03:57  Lr: 0.001875  Loss: -1.2283  Acc@1: 87.5000 (81.1828)  Acc@5: 100.0000 (96.5789)  time: 0.3491  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3080/3750]  eta: 0:03:54  Lr: 0.001875  Loss: -1.3319  Acc@1: 87.5000 (81.1831)  Acc@5: 93.7500 (96.5778)  time: 0.3489  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [3090/3750]  eta: 0:03:50  Lr: 0.001875  Loss: -1.0457  Acc@1: 81.2500 (81.1914)  Acc@5: 93.7500 (96.5788)  time: 0.3473  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [3100/3750]  eta: 0:03:47  Lr: 0.001875  Loss: -1.2268  Acc@1: 81.2500 (81.1996)  Acc@5: 100.0000 (96.5817)  time: 0.3475  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [3110/3750]  eta: 0:03:43  Lr: 0.001875  Loss: -0.9270  Acc@1: 87.5000 (81.2279)  Acc@5: 100.0000 (96.5887)  time: 0.3496  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3120/3750]  eta: 0:03:40  Lr: 0.001875  Loss: -0.8006  Acc@1: 87.5000 (81.2200)  Acc@5: 100.0000 (96.5856)  time: 0.3496  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [3130/3750]  eta: 0:03:36  Lr: 0.001875  Loss: -1.2125  Acc@1: 75.0000 (81.2101)  Acc@5: 93.7500 (96.5866)  time: 0.3475  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [3140/3750]  eta: 0:03:33  Lr: 0.001875  Loss: -1.2447  Acc@1: 81.2500 (81.2122)  Acc@5: 100.0000 (96.5915)  time: 0.3484  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [3150/3750]  eta: 0:03:29  Lr: 0.001875  Loss: -0.7616  Acc@1: 81.2500 (81.2083)  Acc@5: 100.0000 (96.5924)  time: 0.3488  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [3160/3750]  eta: 0:03:26  Lr: 0.001875  Loss: -1.0751  Acc@1: 87.5000 (81.2203)  Acc@5: 100.0000 (96.5972)  time: 0.3479  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [3170/3750]  eta: 0:03:22  Lr: 0.001875  Loss: -1.0146  Acc@1: 81.2500 (81.2303)  Acc@5: 100.0000 (96.6040)  time: 0.3486  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [3180/3750]  eta: 0:03:19  Lr: 0.001875  Loss: -1.1432  Acc@1: 81.2500 (81.2205)  Acc@5: 100.0000 (96.6088)  time: 0.3518  data: 0.0011  max mem: 2500
Train: Epoch[2/5]  [3190/3750]  eta: 0:03:15  Lr: 0.001875  Loss: -0.9415  Acc@1: 81.2500 (81.2363)  Acc@5: 100.0000 (96.6037)  time: 0.3512  data: 0.0011  max mem: 2500
Train: Epoch[2/5]  [3200/3750]  eta: 0:03:12  Lr: 0.001875  Loss: -1.1336  Acc@1: 87.5000 (81.2520)  Acc@5: 93.7500 (96.6026)  time: 0.3484  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [3210/3750]  eta: 0:03:08  Lr: 0.001875  Loss: -0.7932  Acc@1: 81.2500 (81.2558)  Acc@5: 100.0000 (96.6074)  time: 0.3485  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [3220/3750]  eta: 0:03:05  Lr: 0.001875  Loss: -1.0006  Acc@1: 81.2500 (81.2675)  Acc@5: 100.0000 (96.6121)  time: 0.3473  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [3230/3750]  eta: 0:03:01  Lr: 0.001875  Loss: -0.9761  Acc@1: 81.2500 (81.2635)  Acc@5: 100.0000 (96.6110)  time: 0.3471  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [3240/3750]  eta: 0:02:58  Lr: 0.001875  Loss: -0.4473  Acc@1: 75.0000 (81.2481)  Acc@5: 93.7500 (96.6041)  time: 0.3484  data: 0.0013  max mem: 2500
Train: Epoch[2/5]  [3250/3750]  eta: 0:02:54  Lr: 0.001875  Loss: -0.9972  Acc@1: 81.2500 (81.2500)  Acc@5: 93.7500 (96.6010)  time: 0.3482  data: 0.0013  max mem: 2500
Train: Epoch[2/5]  [3260/3750]  eta: 0:02:51  Lr: 0.001875  Loss: -0.5233  Acc@1: 81.2500 (81.2404)  Acc@5: 93.7500 (96.5923)  time: 0.3474  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [3270/3750]  eta: 0:02:47  Lr: 0.001875  Loss: -1.1956  Acc@1: 75.0000 (81.2290)  Acc@5: 93.7500 (96.5836)  time: 0.3482  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [3280/3750]  eta: 0:02:44  Lr: 0.001875  Loss: -1.0396  Acc@1: 75.0000 (81.2157)  Acc@5: 100.0000 (96.5883)  time: 0.3483  data: 0.0009  max mem: 2500
Train: Epoch[2/5]  [3290/3750]  eta: 0:02:40  Lr: 0.001875  Loss: -0.9996  Acc@1: 75.0000 (81.2158)  Acc@5: 100.0000 (96.5854)  time: 0.3484  data: 0.0017  max mem: 2500
Train: Epoch[2/5]  [3300/3750]  eta: 0:02:37  Lr: 0.001875  Loss: -1.0827  Acc@1: 81.2500 (81.2140)  Acc@5: 100.0000 (96.5900)  time: 0.3490  data: 0.0012  max mem: 2500
Train: Epoch[2/5]  [3310/3750]  eta: 0:02:33  Lr: 0.001875  Loss: -1.4643  Acc@1: 87.5000 (81.2311)  Acc@5: 100.0000 (96.5890)  time: 0.3515  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3320/3750]  eta: 0:02:30  Lr: 0.001875  Loss: -0.9385  Acc@1: 87.5000 (81.2237)  Acc@5: 100.0000 (96.5918)  time: 0.3519  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3330/3750]  eta: 0:02:26  Lr: 0.001875  Loss: -0.7866  Acc@1: 81.2500 (81.2181)  Acc@5: 100.0000 (96.5945)  time: 0.3493  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3340/3750]  eta: 0:02:23  Lr: 0.001875  Loss: -0.6422  Acc@1: 81.2500 (81.2238)  Acc@5: 93.7500 (96.5916)  time: 0.3513  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [3350/3750]  eta: 0:02:19  Lr: 0.001875  Loss: -0.7186  Acc@1: 81.2500 (81.2351)  Acc@5: 93.7500 (96.5906)  time: 0.3522  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [3360/3750]  eta: 0:02:16  Lr: 0.001875  Loss: -1.2669  Acc@1: 81.2500 (81.2519)  Acc@5: 100.0000 (96.5970)  time: 0.3501  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [3370/3750]  eta: 0:02:12  Lr: 0.001875  Loss: -1.0246  Acc@1: 81.2500 (81.2426)  Acc@5: 100.0000 (96.5960)  time: 0.3488  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3380/3750]  eta: 0:02:09  Lr: 0.001875  Loss: -0.4138  Acc@1: 81.2500 (81.2518)  Acc@5: 100.0000 (96.5949)  time: 0.3489  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [3390/3750]  eta: 0:02:05  Lr: 0.001875  Loss: -0.5455  Acc@1: 81.2500 (81.2297)  Acc@5: 93.7500 (96.5866)  time: 0.3499  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [3400/3750]  eta: 0:02:02  Lr: 0.001875  Loss: -0.7933  Acc@1: 75.0000 (81.2096)  Acc@5: 93.7500 (96.5856)  time: 0.3496  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [3410/3750]  eta: 0:01:58  Lr: 0.001875  Loss: -0.6944  Acc@1: 75.0000 (81.2170)  Acc@5: 100.0000 (96.5864)  time: 0.3505  data: 0.0016  max mem: 2500
Train: Epoch[2/5]  [3420/3750]  eta: 0:01:55  Lr: 0.001875  Loss: -0.7442  Acc@1: 81.2500 (81.2153)  Acc@5: 93.7500 (96.5818)  time: 0.3501  data: 0.0020  max mem: 2500
Train: Epoch[2/5]  [3430/3750]  eta: 0:01:51  Lr: 0.001875  Loss: -0.9551  Acc@1: 75.0000 (81.2099)  Acc@5: 100.0000 (96.5863)  time: 0.3495  data: 0.0010  max mem: 2500
Train: Epoch[2/5]  [3440/3750]  eta: 0:01:48  Lr: 0.001875  Loss: -1.2387  Acc@1: 87.5000 (81.2264)  Acc@5: 100.0000 (96.5853)  time: 0.3501  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [3450/3750]  eta: 0:01:44  Lr: 0.001875  Loss: -0.9313  Acc@1: 87.5000 (81.2283)  Acc@5: 100.0000 (96.5879)  time: 0.3487  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [3460/3750]  eta: 0:01:41  Lr: 0.001875  Loss: -1.2267  Acc@1: 81.2500 (81.2410)  Acc@5: 100.0000 (96.5942)  time: 0.3481  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [3470/3750]  eta: 0:01:37  Lr: 0.001875  Loss: -0.7573  Acc@1: 81.2500 (81.2356)  Acc@5: 100.0000 (96.5914)  time: 0.3484  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [3480/3750]  eta: 0:01:34  Lr: 0.001875  Loss: -1.0347  Acc@1: 81.2500 (81.2320)  Acc@5: 93.7500 (96.5850)  time: 0.3497  data: 0.0013  max mem: 2500
Train: Epoch[2/5]  [3490/3750]  eta: 0:01:30  Lr: 0.001875  Loss: -1.3117  Acc@1: 87.5000 (81.2518)  Acc@5: 100.0000 (96.5912)  time: 0.3501  data: 0.0013  max mem: 2500
Train: Epoch[2/5]  [3500/3750]  eta: 0:01:27  Lr: 0.001875  Loss: -1.1363  Acc@1: 87.5000 (81.2571)  Acc@5: 100.0000 (96.5903)  time: 0.3497  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [3510/3750]  eta: 0:01:23  Lr: 0.001875  Loss: -0.8218  Acc@1: 87.5000 (81.2660)  Acc@5: 93.7500 (96.5893)  time: 0.3508  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [3520/3750]  eta: 0:01:20  Lr: 0.001875  Loss: -0.6899  Acc@1: 81.2500 (81.2482)  Acc@5: 93.7500 (96.5901)  time: 0.3506  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [3530/3750]  eta: 0:01:16  Lr: 0.001875  Loss: -1.3174  Acc@1: 81.2500 (81.2482)  Acc@5: 93.7500 (96.5874)  time: 0.3503  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [3540/3750]  eta: 0:01:13  Lr: 0.001875  Loss: -1.2944  Acc@1: 87.5000 (81.2641)  Acc@5: 100.0000 (96.5917)  time: 0.3496  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [3550/3750]  eta: 0:01:09  Lr: 0.001875  Loss: -1.3394  Acc@1: 87.5000 (81.2711)  Acc@5: 100.0000 (96.5890)  time: 0.3487  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3560/3750]  eta: 0:01:06  Lr: 0.001875  Loss: -1.1589  Acc@1: 81.2500 (81.2693)  Acc@5: 100.0000 (96.5951)  time: 0.3501  data: 0.0009  max mem: 2500
Train: Epoch[2/5]  [3570/3750]  eta: 0:01:02  Lr: 0.001875  Loss: -0.8141  Acc@1: 81.2500 (81.2640)  Acc@5: 100.0000 (96.5993)  time: 0.3502  data: 0.0012  max mem: 2500
Train: Epoch[2/5]  [3580/3750]  eta: 0:00:59  Lr: 0.001875  Loss: -1.0170  Acc@1: 81.2500 (81.2779)  Acc@5: 100.0000 (96.5931)  time: 0.3502  data: 0.0010  max mem: 2500
Train: Epoch[2/5]  [3590/3750]  eta: 0:00:55  Lr: 0.001875  Loss: -0.7552  Acc@1: 81.2500 (81.2691)  Acc@5: 100.0000 (96.5974)  time: 0.3495  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [3600/3750]  eta: 0:00:52  Lr: 0.001875  Loss: -1.0697  Acc@1: 81.2500 (81.2621)  Acc@5: 100.0000 (96.5999)  time: 0.3488  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [3610/3750]  eta: 0:00:48  Lr: 0.001875  Loss: -0.7415  Acc@1: 81.2500 (81.2725)  Acc@5: 100.0000 (96.6059)  time: 0.3507  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [3620/3750]  eta: 0:00:45  Lr: 0.001875  Loss: -0.9290  Acc@1: 81.2500 (81.2638)  Acc@5: 100.0000 (96.5997)  time: 0.3519  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [3630/3750]  eta: 0:00:41  Lr: 0.001875  Loss: -0.8948  Acc@1: 81.2500 (81.2552)  Acc@5: 93.7500 (96.5987)  time: 0.3503  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [3640/3750]  eta: 0:00:38  Lr: 0.001875  Loss: -0.8878  Acc@1: 81.2500 (81.2551)  Acc@5: 93.7500 (96.5978)  time: 0.3490  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [3650/3750]  eta: 0:00:34  Lr: 0.001875  Loss: -1.1703  Acc@1: 81.2500 (81.2500)  Acc@5: 100.0000 (96.6037)  time: 0.3487  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [3660/3750]  eta: 0:00:31  Lr: 0.001875  Loss: -1.2375  Acc@1: 81.2500 (81.2380)  Acc@5: 100.0000 (96.6010)  time: 0.3482  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [3670/3750]  eta: 0:00:27  Lr: 0.001875  Loss: -0.5598  Acc@1: 81.2500 (81.2483)  Acc@5: 93.7500 (96.6000)  time: 0.3491  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [3680/3750]  eta: 0:00:24  Lr: 0.001875  Loss: -0.8476  Acc@1: 87.5000 (81.2602)  Acc@5: 100.0000 (96.6025)  time: 0.3510  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [3690/3750]  eta: 0:00:20  Lr: 0.001875  Loss: -1.3701  Acc@1: 87.5000 (81.2737)  Acc@5: 100.0000 (96.6066)  time: 0.3510  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [3700/3750]  eta: 0:00:17  Lr: 0.001875  Loss: -0.9971  Acc@1: 81.2500 (81.2787)  Acc@5: 100.0000 (96.6090)  time: 0.3494  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [3710/3750]  eta: 0:00:13  Lr: 0.001875  Loss: -0.7984  Acc@1: 81.2500 (81.2635)  Acc@5: 93.7500 (96.6030)  time: 0.3491  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [3720/3750]  eta: 0:00:10  Lr: 0.001875  Loss: -0.9290  Acc@1: 81.2500 (81.2685)  Acc@5: 100.0000 (96.6121)  time: 0.3503  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [3730/3750]  eta: 0:00:06  Lr: 0.001875  Loss: -0.9894  Acc@1: 87.5000 (81.2835)  Acc@5: 100.0000 (96.6145)  time: 0.3506  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [3740/3750]  eta: 0:00:03  Lr: 0.001875  Loss: -0.8021  Acc@1: 87.5000 (81.2951)  Acc@5: 100.0000 (96.6135)  time: 0.3509  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [3749/3750]  eta: 0:00:00  Lr: 0.001875  Loss: -1.2688  Acc@1: 87.5000 (81.2983)  Acc@5: 100.0000 (96.6150)  time: 0.3510  data: 0.0012  max mem: 2500
Train: Epoch[2/5] Total time: 0:21:51 (0.3496 s / it)
{0: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 1: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 2: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 3: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 4: {0: 0, 1: 120000, 2: 0, 3: 0, 4: 0}, 5: {0: 0, 1: 120000, 2: 0, 3: 0, 4: 0}, 6: {0: 0, 1: 120000, 2: 0, 3: 0, 4: 0}, 7: {0: 0, 1: 120000, 2: 0, 3: 0, 4: 0}, 8: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 9: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 10: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 11: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 12: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 13: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 14: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 15: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 16: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 17: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 18: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 19: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}}
Averaged stats: Lr: 0.001875  Loss: -1.2688  Acc@1: 87.5000 (81.2983)  Acc@5: 100.0000 (96.6150)
Train: Epoch[3/5]  [   0/3750]  eta: 0:44:48  Lr: 0.001875  Loss: -0.8486  Acc@1: 81.2500 (81.2500)  Acc@5: 100.0000 (100.0000)  time: 0.7169  data: 0.3687  max mem: 2500
Train: Epoch[3/5]  [  10/3750]  eta: 0:23:48  Lr: 0.001875  Loss: -1.4378  Acc@1: 81.2500 (84.0909)  Acc@5: 93.7500 (96.0227)  time: 0.3819  data: 0.0339  max mem: 2500
Train: Epoch[3/5]  [  20/3750]  eta: 0:22:47  Lr: 0.001875  Loss: -0.7491  Acc@1: 81.2500 (83.9286)  Acc@5: 93.7500 (96.1310)  time: 0.3490  data: 0.0014  max mem: 2500
Train: Epoch[3/5]  [  30/3750]  eta: 0:22:27  Lr: 0.001875  Loss: -1.0805  Acc@1: 81.2500 (82.2581)  Acc@5: 93.7500 (95.9677)  time: 0.3514  data: 0.0015  max mem: 2500
Train: Epoch[3/5]  [  40/3750]  eta: 0:22:14  Lr: 0.001875  Loss: -1.1534  Acc@1: 81.2500 (81.2500)  Acc@5: 93.7500 (96.0366)  time: 0.3524  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [  50/3750]  eta: 0:22:01  Lr: 0.001875  Loss: -0.9449  Acc@1: 81.2500 (82.1078)  Acc@5: 93.7500 (96.2010)  time: 0.3492  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [  60/3750]  eta: 0:21:51  Lr: 0.001875  Loss: -1.0239  Acc@1: 87.5000 (82.6844)  Acc@5: 100.0000 (96.4139)  time: 0.3470  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [  70/3750]  eta: 0:21:45  Lr: 0.001875  Loss: -1.3321  Acc@1: 87.5000 (83.4507)  Acc@5: 100.0000 (96.5669)  time: 0.3485  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [  80/3750]  eta: 0:21:39  Lr: 0.001875  Loss: -1.0304  Acc@1: 81.2500 (83.1790)  Acc@5: 100.0000 (96.6821)  time: 0.3498  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [  90/3750]  eta: 0:21:35  Lr: 0.001875  Loss: -0.9016  Acc@1: 81.2500 (83.1044)  Acc@5: 100.0000 (96.8407)  time: 0.3511  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 100/3750]  eta: 0:21:30  Lr: 0.001875  Loss: -0.7729  Acc@1: 87.5000 (83.4158)  Acc@5: 100.0000 (96.9059)  time: 0.3517  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [ 110/3750]  eta: 0:21:25  Lr: 0.001875  Loss: -1.0978  Acc@1: 87.5000 (83.6712)  Acc@5: 100.0000 (97.0158)  time: 0.3494  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [ 120/3750]  eta: 0:21:21  Lr: 0.001875  Loss: -1.3708  Acc@1: 87.5000 (83.6260)  Acc@5: 100.0000 (97.1074)  time: 0.3501  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [ 130/3750]  eta: 0:21:16  Lr: 0.001875  Loss: -0.8542  Acc@1: 81.2500 (83.9218)  Acc@5: 100.0000 (97.1374)  time: 0.3505  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [ 140/3750]  eta: 0:21:12  Lr: 0.001875  Loss: -1.3446  Acc@1: 87.5000 (83.8209)  Acc@5: 100.0000 (97.2518)  time: 0.3496  data: 0.0011  max mem: 2500
Train: Epoch[3/5]  [ 150/3750]  eta: 0:21:08  Lr: 0.001875  Loss: -0.9933  Acc@1: 87.5000 (83.9818)  Acc@5: 100.0000 (97.1854)  time: 0.3495  data: 0.0013  max mem: 2500
Train: Epoch[3/5]  [ 160/3750]  eta: 0:21:04  Lr: 0.001875  Loss: -1.1587  Acc@1: 81.2500 (84.0062)  Acc@5: 93.7500 (97.0885)  time: 0.3510  data: 0.0010  max mem: 2500
Train: Epoch[3/5]  [ 170/3750]  eta: 0:21:00  Lr: 0.001875  Loss: -0.4779  Acc@1: 81.2500 (83.7354)  Acc@5: 93.7500 (97.0029)  time: 0.3514  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [ 180/3750]  eta: 0:20:56  Lr: 0.001875  Loss: -1.0314  Acc@1: 81.2500 (83.9088)  Acc@5: 100.0000 (96.9959)  time: 0.3488  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [ 190/3750]  eta: 0:20:52  Lr: 0.001875  Loss: -0.7988  Acc@1: 81.2500 (83.7696)  Acc@5: 100.0000 (96.9568)  time: 0.3486  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [ 200/3750]  eta: 0:20:48  Lr: 0.001875  Loss: -0.8900  Acc@1: 81.2500 (83.5510)  Acc@5: 100.0000 (96.9216)  time: 0.3485  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [ 210/3750]  eta: 0:20:44  Lr: 0.001875  Loss: -0.5249  Acc@1: 81.2500 (83.3531)  Acc@5: 93.7500 (96.8602)  time: 0.3479  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [ 220/3750]  eta: 0:20:39  Lr: 0.001875  Loss: -1.1471  Acc@1: 81.2500 (83.3145)  Acc@5: 93.7500 (96.7195)  time: 0.3472  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [ 230/3750]  eta: 0:20:35  Lr: 0.001875  Loss: -0.9764  Acc@1: 81.2500 (83.1439)  Acc@5: 93.7500 (96.6180)  time: 0.3473  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [ 240/3750]  eta: 0:20:32  Lr: 0.001875  Loss: -1.1732  Acc@1: 81.2500 (83.0394)  Acc@5: 93.7500 (96.6286)  time: 0.3489  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [ 250/3750]  eta: 0:20:28  Lr: 0.001875  Loss: -1.0380  Acc@1: 87.5000 (83.0428)  Acc@5: 93.7500 (96.5886)  time: 0.3498  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [ 260/3750]  eta: 0:20:24  Lr: 0.001875  Loss: -1.1250  Acc@1: 81.2500 (83.0220)  Acc@5: 100.0000 (96.6236)  time: 0.3489  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [ 270/3750]  eta: 0:20:20  Lr: 0.001875  Loss: -0.6073  Acc@1: 81.2500 (83.0028)  Acc@5: 100.0000 (96.6098)  time: 0.3488  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [ 280/3750]  eta: 0:20:16  Lr: 0.001875  Loss: -1.1040  Acc@1: 81.2500 (82.9181)  Acc@5: 100.0000 (96.6415)  time: 0.3484  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [ 290/3750]  eta: 0:20:13  Lr: 0.001875  Loss: -0.9211  Acc@1: 81.2500 (82.9253)  Acc@5: 100.0000 (96.6924)  time: 0.3479  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [ 300/3750]  eta: 0:20:09  Lr: 0.001875  Loss: -1.0154  Acc@1: 81.2500 (82.9942)  Acc@5: 100.0000 (96.7193)  time: 0.3486  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [ 310/3750]  eta: 0:20:05  Lr: 0.001875  Loss: -1.0520  Acc@1: 81.2500 (82.8979)  Acc@5: 100.0000 (96.6640)  time: 0.3485  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [ 320/3750]  eta: 0:20:01  Lr: 0.001875  Loss: -1.4302  Acc@1: 81.2500 (82.8660)  Acc@5: 93.7500 (96.6316)  time: 0.3486  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [ 330/3750]  eta: 0:19:58  Lr: 0.001875  Loss: -0.4371  Acc@1: 81.2500 (82.7417)  Acc@5: 93.7500 (96.5823)  time: 0.3482  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [ 340/3750]  eta: 0:19:54  Lr: 0.001875  Loss: -1.3099  Acc@1: 81.2500 (82.8812)  Acc@5: 93.7500 (96.5909)  time: 0.3472  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [ 350/3750]  eta: 0:19:50  Lr: 0.001875  Loss: -1.1058  Acc@1: 81.2500 (82.7991)  Acc@5: 100.0000 (96.6168)  time: 0.3482  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [ 360/3750]  eta: 0:19:47  Lr: 0.001875  Loss: -0.9534  Acc@1: 81.2500 (82.8774)  Acc@5: 100.0000 (96.6586)  time: 0.3493  data: 0.0011  max mem: 2500
Train: Epoch[3/5]  [ 370/3750]  eta: 0:19:43  Lr: 0.001875  Loss: -1.1661  Acc@1: 81.2500 (82.7999)  Acc@5: 100.0000 (96.6644)  time: 0.3487  data: 0.0011  max mem: 2500
Train: Epoch[3/5]  [ 380/3750]  eta: 0:19:39  Lr: 0.001875  Loss: -0.7209  Acc@1: 75.0000 (82.6444)  Acc@5: 100.0000 (96.6864)  time: 0.3473  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [ 390/3750]  eta: 0:19:35  Lr: 0.001875  Loss: -0.9553  Acc@1: 75.0000 (82.5448)  Acc@5: 93.7500 (96.6113)  time: 0.3470  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [ 400/3750]  eta: 0:19:32  Lr: 0.001875  Loss: -0.9165  Acc@1: 75.0000 (82.4034)  Acc@5: 93.7500 (96.5867)  time: 0.3497  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [ 410/3750]  eta: 0:19:29  Lr: 0.001875  Loss: -0.8580  Acc@1: 81.2500 (82.3601)  Acc@5: 100.0000 (96.6393)  time: 0.3511  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [ 420/3750]  eta: 0:19:25  Lr: 0.001875  Loss: -0.7532  Acc@1: 81.2500 (82.2298)  Acc@5: 93.7500 (96.5855)  time: 0.3500  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [ 430/3750]  eta: 0:19:21  Lr: 0.001875  Loss: -0.7381  Acc@1: 81.2500 (82.2071)  Acc@5: 93.7500 (96.6067)  time: 0.3485  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [ 440/3750]  eta: 0:19:18  Lr: 0.001875  Loss: -1.1086  Acc@1: 81.2500 (82.3413)  Acc@5: 100.0000 (96.6553)  time: 0.3483  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [ 450/3750]  eta: 0:19:14  Lr: 0.001875  Loss: -1.0536  Acc@1: 87.5000 (82.3725)  Acc@5: 100.0000 (96.7018)  time: 0.3496  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [ 460/3750]  eta: 0:19:11  Lr: 0.001875  Loss: -1.0358  Acc@1: 87.5000 (82.4295)  Acc@5: 100.0000 (96.6920)  time: 0.3502  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [ 470/3750]  eta: 0:19:07  Lr: 0.001875  Loss: -1.3586  Acc@1: 81.2500 (82.3646)  Acc@5: 93.7500 (96.6959)  time: 0.3494  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [ 480/3750]  eta: 0:19:04  Lr: 0.001875  Loss: -0.9491  Acc@1: 81.2500 (82.4454)  Acc@5: 93.7500 (96.6736)  time: 0.3500  data: 0.0011  max mem: 2500
Train: Epoch[3/5]  [ 490/3750]  eta: 0:19:00  Lr: 0.001875  Loss: -1.1753  Acc@1: 87.5000 (82.5484)  Acc@5: 93.7500 (96.6650)  time: 0.3503  data: 0.0016  max mem: 2500
Train: Epoch[3/5]  [ 500/3750]  eta: 0:18:57  Lr: 0.001875  Loss: -0.9154  Acc@1: 81.2500 (82.5100)  Acc@5: 93.7500 (96.6816)  time: 0.3485  data: 0.0009  max mem: 2500
Train: Epoch[3/5]  [ 510/3750]  eta: 0:18:53  Lr: 0.001875  Loss: -0.9724  Acc@1: 81.2500 (82.4242)  Acc@5: 100.0000 (96.7099)  time: 0.3492  data: 0.0013  max mem: 2500
Train: Epoch[3/5]  [ 520/3750]  eta: 0:18:50  Lr: 0.001875  Loss: -1.0821  Acc@1: 81.2500 (82.3177)  Acc@5: 93.7500 (96.6291)  time: 0.3494  data: 0.0015  max mem: 2500
Train: Epoch[3/5]  [ 530/3750]  eta: 0:18:46  Lr: 0.001875  Loss: -0.6995  Acc@1: 81.2500 (82.3093)  Acc@5: 93.7500 (96.6573)  time: 0.3485  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [ 540/3750]  eta: 0:18:43  Lr: 0.001875  Loss: -1.2860  Acc@1: 81.2500 (82.2320)  Acc@5: 100.0000 (96.5804)  time: 0.3500  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [ 550/3750]  eta: 0:18:39  Lr: 0.001875  Loss: -1.0250  Acc@1: 81.2500 (82.2028)  Acc@5: 93.7500 (96.5177)  time: 0.3500  data: 0.0012  max mem: 2500
Train: Epoch[3/5]  [ 560/3750]  eta: 0:18:35  Lr: 0.001875  Loss: -1.0546  Acc@1: 81.2500 (82.1524)  Acc@5: 93.7500 (96.5129)  time: 0.3487  data: 0.0011  max mem: 2500
Train: Epoch[3/5]  [ 570/3750]  eta: 0:18:32  Lr: 0.001875  Loss: -0.7403  Acc@1: 81.2500 (82.1694)  Acc@5: 100.0000 (96.5412)  time: 0.3505  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [ 580/3750]  eta: 0:18:29  Lr: 0.001875  Loss: -1.1392  Acc@1: 81.2500 (82.0998)  Acc@5: 100.0000 (96.5146)  time: 0.3518  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [ 590/3750]  eta: 0:18:25  Lr: 0.001875  Loss: -1.1171  Acc@1: 81.2500 (82.1383)  Acc@5: 100.0000 (96.5419)  time: 0.3513  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 600/3750]  eta: 0:18:22  Lr: 0.001875  Loss: -0.3640  Acc@1: 81.2500 (82.1131)  Acc@5: 100.0000 (96.5474)  time: 0.3486  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 610/3750]  eta: 0:18:18  Lr: 0.001875  Loss: -0.9210  Acc@1: 81.2500 (82.1706)  Acc@5: 100.0000 (96.5835)  time: 0.3475  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 620/3750]  eta: 0:18:15  Lr: 0.001875  Loss: -1.2700  Acc@1: 87.5000 (82.2061)  Acc@5: 100.0000 (96.5982)  time: 0.3494  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [ 630/3750]  eta: 0:18:11  Lr: 0.001875  Loss: -0.8764  Acc@1: 81.2500 (82.2207)  Acc@5: 100.0000 (96.6026)  time: 0.3490  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [ 640/3750]  eta: 0:18:07  Lr: 0.001875  Loss: -0.5776  Acc@1: 81.2500 (82.2250)  Acc@5: 100.0000 (96.5874)  time: 0.3491  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [ 650/3750]  eta: 0:18:04  Lr: 0.001875  Loss: -1.1205  Acc@1: 81.2500 (82.2293)  Acc@5: 100.0000 (96.5822)  time: 0.3502  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [ 660/3750]  eta: 0:18:00  Lr: 0.001875  Loss: -0.8059  Acc@1: 81.2500 (82.2428)  Acc@5: 100.0000 (96.5961)  time: 0.3493  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [ 670/3750]  eta: 0:17:57  Lr: 0.001875  Loss: -0.8359  Acc@1: 81.2500 (82.2187)  Acc@5: 100.0000 (96.6002)  time: 0.3499  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [ 680/3750]  eta: 0:17:53  Lr: 0.001875  Loss: -1.1376  Acc@1: 81.2500 (82.1402)  Acc@5: 100.0000 (96.6134)  time: 0.3504  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [ 690/3750]  eta: 0:17:50  Lr: 0.001875  Loss: -0.9922  Acc@1: 81.2500 (82.1093)  Acc@5: 100.0000 (96.5901)  time: 0.3492  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [ 700/3750]  eta: 0:17:46  Lr: 0.001875  Loss: -1.4601  Acc@1: 81.2500 (82.1327)  Acc@5: 93.7500 (96.5674)  time: 0.3492  data: 0.0014  max mem: 2500
Train: Epoch[3/5]  [ 710/3750]  eta: 0:17:43  Lr: 0.001875  Loss: -0.9913  Acc@1: 81.2500 (82.1203)  Acc@5: 100.0000 (96.5717)  time: 0.3507  data: 0.0012  max mem: 2500
Train: Epoch[3/5]  [ 720/3750]  eta: 0:17:39  Lr: 0.001875  Loss: -0.6954  Acc@1: 81.2500 (82.1515)  Acc@5: 100.0000 (96.5759)  time: 0.3506  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [ 730/3750]  eta: 0:17:36  Lr: 0.001875  Loss: -1.1492  Acc@1: 81.2500 (82.1306)  Acc@5: 100.0000 (96.5715)  time: 0.3509  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [ 740/3750]  eta: 0:17:33  Lr: 0.001875  Loss: -0.7854  Acc@1: 81.2500 (82.1188)  Acc@5: 93.7500 (96.5587)  time: 0.3514  data: 0.0012  max mem: 2500
Train: Epoch[3/5]  [ 750/3750]  eta: 0:17:29  Lr: 0.001875  Loss: -1.3280  Acc@1: 87.5000 (82.1987)  Acc@5: 100.0000 (96.5962)  time: 0.3502  data: 0.0014  max mem: 2500
Train: Epoch[3/5]  [ 760/3750]  eta: 0:17:26  Lr: 0.001875  Loss: -1.3279  Acc@1: 87.5000 (82.2191)  Acc@5: 100.0000 (96.6163)  time: 0.3496  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [ 770/3750]  eta: 0:17:22  Lr: 0.001875  Loss: -1.1348  Acc@1: 81.2500 (82.2552)  Acc@5: 100.0000 (96.6278)  time: 0.3493  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [ 780/3750]  eta: 0:17:19  Lr: 0.001875  Loss: -1.2100  Acc@1: 87.5000 (82.3063)  Acc@5: 100.0000 (96.6389)  time: 0.3489  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 790/3750]  eta: 0:17:15  Lr: 0.001875  Loss: -0.7288  Acc@1: 81.2500 (82.2772)  Acc@5: 100.0000 (96.6261)  time: 0.3492  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [ 800/3750]  eta: 0:17:12  Lr: 0.001875  Loss: -1.1275  Acc@1: 75.0000 (82.2175)  Acc@5: 93.7500 (96.6292)  time: 0.3498  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [ 810/3750]  eta: 0:17:08  Lr: 0.001875  Loss: -0.5462  Acc@1: 75.0000 (82.2287)  Acc@5: 100.0000 (96.6400)  time: 0.3493  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [ 820/3750]  eta: 0:17:04  Lr: 0.001875  Loss: -1.1965  Acc@1: 87.5000 (82.2320)  Acc@5: 100.0000 (96.6200)  time: 0.3490  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [ 830/3750]  eta: 0:17:01  Lr: 0.001875  Loss: -0.8751  Acc@1: 81.2500 (82.2127)  Acc@5: 100.0000 (96.6456)  time: 0.3511  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [ 840/3750]  eta: 0:16:58  Lr: 0.001875  Loss: -0.4244  Acc@1: 75.0000 (82.1269)  Acc@5: 100.0000 (96.6483)  time: 0.3510  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [ 850/3750]  eta: 0:16:54  Lr: 0.001875  Loss: -0.8999  Acc@1: 75.0000 (82.1460)  Acc@5: 93.7500 (96.6290)  time: 0.3493  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [ 860/3750]  eta: 0:16:51  Lr: 0.001875  Loss: -0.9061  Acc@1: 81.2500 (82.1283)  Acc@5: 100.0000 (96.6536)  time: 0.3494  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [ 870/3750]  eta: 0:16:47  Lr: 0.001875  Loss: -0.8970  Acc@1: 81.2500 (82.1254)  Acc@5: 100.0000 (96.6777)  time: 0.3500  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [ 880/3750]  eta: 0:16:44  Lr: 0.001875  Loss: -1.0010  Acc@1: 81.2500 (82.1013)  Acc@5: 100.0000 (96.6728)  time: 0.3517  data: 0.0014  max mem: 2500
Train: Epoch[3/5]  [ 890/3750]  eta: 0:16:40  Lr: 0.001875  Loss: -0.9012  Acc@1: 75.0000 (82.0777)  Acc@5: 100.0000 (96.6821)  time: 0.3521  data: 0.0013  max mem: 2500
Train: Epoch[3/5]  [ 900/3750]  eta: 0:16:37  Lr: 0.001875  Loss: -0.3845  Acc@1: 75.0000 (82.0477)  Acc@5: 100.0000 (96.6981)  time: 0.3527  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [ 910/3750]  eta: 0:16:33  Lr: 0.001875  Loss: -1.1820  Acc@1: 81.2500 (82.0595)  Acc@5: 100.0000 (96.7138)  time: 0.3519  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 920/3750]  eta: 0:16:30  Lr: 0.001875  Loss: -1.0260  Acc@1: 81.2500 (82.0711)  Acc@5: 100.0000 (96.7087)  time: 0.3483  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 930/3750]  eta: 0:16:26  Lr: 0.001875  Loss: -1.3341  Acc@1: 81.2500 (82.0690)  Acc@5: 100.0000 (96.7240)  time: 0.3477  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 940/3750]  eta: 0:16:23  Lr: 0.001875  Loss: -0.9186  Acc@1: 81.2500 (82.0470)  Acc@5: 100.0000 (96.7256)  time: 0.3493  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [ 950/3750]  eta: 0:16:19  Lr: 0.001875  Loss: -0.9240  Acc@1: 81.2500 (82.0715)  Acc@5: 100.0000 (96.7206)  time: 0.3497  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [ 960/3750]  eta: 0:16:16  Lr: 0.001875  Loss: -0.9165  Acc@1: 87.5000 (82.1085)  Acc@5: 93.7500 (96.7027)  time: 0.3492  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [ 970/3750]  eta: 0:16:12  Lr: 0.001875  Loss: -1.3290  Acc@1: 87.5000 (82.1318)  Acc@5: 93.7500 (96.7109)  time: 0.3499  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [ 980/3750]  eta: 0:16:09  Lr: 0.001875  Loss: -1.1847  Acc@1: 81.2500 (82.1037)  Acc@5: 100.0000 (96.7062)  time: 0.3502  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 990/3750]  eta: 0:16:05  Lr: 0.001875  Loss: -0.9412  Acc@1: 87.5000 (82.1519)  Acc@5: 100.0000 (96.7079)  time: 0.3497  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1000/3750]  eta: 0:16:02  Lr: 0.001875  Loss: -1.0650  Acc@1: 81.2500 (82.1241)  Acc@5: 93.7500 (96.6971)  time: 0.3494  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [1010/3750]  eta: 0:15:58  Lr: 0.001875  Loss: -0.8217  Acc@1: 81.2500 (82.1340)  Acc@5: 93.7500 (96.6864)  time: 0.3482  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [1020/3750]  eta: 0:15:55  Lr: 0.001875  Loss: -0.5905  Acc@1: 81.2500 (82.1560)  Acc@5: 100.0000 (96.6883)  time: 0.3479  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [1030/3750]  eta: 0:15:51  Lr: 0.001875  Loss: -1.0296  Acc@1: 81.2500 (82.1654)  Acc@5: 100.0000 (96.6840)  time: 0.3484  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1040/3750]  eta: 0:15:48  Lr: 0.001875  Loss: -0.8060  Acc@1: 81.2500 (82.1506)  Acc@5: 93.7500 (96.6559)  time: 0.3503  data: 0.0011  max mem: 2500
Train: Epoch[3/5]  [1050/3750]  eta: 0:15:44  Lr: 0.001875  Loss: -0.9768  Acc@1: 81.2500 (82.0885)  Acc@5: 93.7500 (96.6520)  time: 0.3504  data: 0.0013  max mem: 2500
Train: Epoch[3/5]  [1060/3750]  eta: 0:15:40  Lr: 0.001875  Loss: -1.0756  Acc@1: 81.2500 (82.0983)  Acc@5: 100.0000 (96.6718)  time: 0.3478  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [1070/3750]  eta: 0:15:37  Lr: 0.001875  Loss: -1.0864  Acc@1: 81.2500 (82.1195)  Acc@5: 100.0000 (96.6795)  time: 0.3482  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [1080/3750]  eta: 0:15:33  Lr: 0.001875  Loss: -1.0224  Acc@1: 81.2500 (82.1288)  Acc@5: 100.0000 (96.6929)  time: 0.3493  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [1090/3750]  eta: 0:15:30  Lr: 0.001875  Loss: -1.1151  Acc@1: 87.5000 (82.1379)  Acc@5: 100.0000 (96.7003)  time: 0.3494  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [1100/3750]  eta: 0:15:26  Lr: 0.001875  Loss: -1.1570  Acc@1: 87.5000 (82.1583)  Acc@5: 100.0000 (96.7019)  time: 0.3490  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [1110/3750]  eta: 0:15:23  Lr: 0.001875  Loss: -0.9533  Acc@1: 87.5000 (82.1895)  Acc@5: 100.0000 (96.7203)  time: 0.3501  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [1120/3750]  eta: 0:15:19  Lr: 0.001875  Loss: -0.6696  Acc@1: 81.2500 (82.1811)  Acc@5: 100.0000 (96.7161)  time: 0.3505  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [1130/3750]  eta: 0:15:16  Lr: 0.001875  Loss: -0.6600  Acc@1: 81.2500 (82.1563)  Acc@5: 100.0000 (96.7230)  time: 0.3491  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [1140/3750]  eta: 0:15:12  Lr: 0.001875  Loss: -1.0707  Acc@1: 81.2500 (82.1648)  Acc@5: 100.0000 (96.7298)  time: 0.3479  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [1150/3750]  eta: 0:15:09  Lr: 0.001875  Loss: -1.1796  Acc@1: 81.2500 (82.1514)  Acc@5: 100.0000 (96.7202)  time: 0.3484  data: 0.0010  max mem: 2500
Train: Epoch[3/5]  [1160/3750]  eta: 0:15:05  Lr: 0.001875  Loss: -1.1740  Acc@1: 81.2500 (82.1490)  Acc@5: 93.7500 (96.7108)  time: 0.3485  data: 0.0010  max mem: 2500
Train: Epoch[3/5]  [1170/3750]  eta: 0:15:02  Lr: 0.001875  Loss: -0.9240  Acc@1: 81.2500 (82.1520)  Acc@5: 93.7500 (96.7069)  time: 0.3475  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [1180/3750]  eta: 0:14:58  Lr: 0.001875  Loss: -1.1455  Acc@1: 81.2500 (82.1761)  Acc@5: 100.0000 (96.7136)  time: 0.3477  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [1190/3750]  eta: 0:14:55  Lr: 0.001875  Loss: -1.3300  Acc@1: 81.2500 (82.1736)  Acc@5: 93.7500 (96.7045)  time: 0.3484  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1200/3750]  eta: 0:14:51  Lr: 0.001875  Loss: -1.2992  Acc@1: 87.5000 (82.2388)  Acc@5: 93.7500 (96.7111)  time: 0.3487  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [1210/3750]  eta: 0:14:48  Lr: 0.001875  Loss: -0.8749  Acc@1: 87.5000 (82.2048)  Acc@5: 100.0000 (96.7331)  time: 0.3486  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [1220/3750]  eta: 0:14:44  Lr: 0.001875  Loss: -1.3862  Acc@1: 81.2500 (82.2277)  Acc@5: 100.0000 (96.7445)  time: 0.3472  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [1230/3750]  eta: 0:14:41  Lr: 0.001875  Loss: -1.0480  Acc@1: 81.2500 (82.1842)  Acc@5: 100.0000 (96.7354)  time: 0.3471  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1240/3750]  eta: 0:14:37  Lr: 0.001875  Loss: -1.2052  Acc@1: 81.2500 (82.1817)  Acc@5: 93.7500 (96.7264)  time: 0.3492  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [1250/3750]  eta: 0:14:34  Lr: 0.001875  Loss: -0.9797  Acc@1: 81.2500 (82.1643)  Acc@5: 93.7500 (96.7226)  time: 0.3512  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [1260/3750]  eta: 0:14:30  Lr: 0.001875  Loss: -1.2236  Acc@1: 81.2500 (82.1768)  Acc@5: 100.0000 (96.7189)  time: 0.3504  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [1270/3750]  eta: 0:14:27  Lr: 0.001875  Loss: -1.2263  Acc@1: 81.2500 (82.1548)  Acc@5: 93.7500 (96.7103)  time: 0.3481  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [1280/3750]  eta: 0:14:23  Lr: 0.001875  Loss: -1.1435  Acc@1: 81.2500 (82.1380)  Acc@5: 93.7500 (96.7018)  time: 0.3481  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [1290/3750]  eta: 0:14:20  Lr: 0.001875  Loss: -1.0247  Acc@1: 81.2500 (82.1456)  Acc@5: 93.7500 (96.7080)  time: 0.3482  data: 0.0010  max mem: 2500
Train: Epoch[3/5]  [1300/3750]  eta: 0:14:16  Lr: 0.001875  Loss: -1.2355  Acc@1: 81.2500 (82.1291)  Acc@5: 100.0000 (96.7141)  time: 0.3483  data: 0.0019  max mem: 2500
Train: Epoch[3/5]  [1310/3750]  eta: 0:14:13  Lr: 0.001875  Loss: -0.9722  Acc@1: 81.2500 (82.1653)  Acc@5: 100.0000 (96.7248)  time: 0.3489  data: 0.0013  max mem: 2500
Train: Epoch[3/5]  [1320/3750]  eta: 0:14:09  Lr: 0.001875  Loss: -0.5621  Acc@1: 81.2500 (82.1537)  Acc@5: 100.0000 (96.7118)  time: 0.3505  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [1330/3750]  eta: 0:14:06  Lr: 0.001875  Loss: -0.8157  Acc@1: 81.2500 (82.1751)  Acc@5: 100.0000 (96.7130)  time: 0.3500  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [1340/3750]  eta: 0:14:02  Lr: 0.001875  Loss: -1.1516  Acc@1: 81.2500 (82.1728)  Acc@5: 100.0000 (96.7095)  time: 0.3478  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [1350/3750]  eta: 0:13:59  Lr: 0.001875  Loss: -0.9050  Acc@1: 87.5000 (82.1799)  Acc@5: 100.0000 (96.7200)  time: 0.3505  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [1360/3750]  eta: 0:13:55  Lr: 0.001875  Loss: -0.6229  Acc@1: 87.5000 (82.1914)  Acc@5: 100.0000 (96.7258)  time: 0.3521  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [1370/3750]  eta: 0:13:52  Lr: 0.001875  Loss: -0.7883  Acc@1: 81.2500 (82.2256)  Acc@5: 100.0000 (96.7314)  time: 0.3495  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [1380/3750]  eta: 0:13:48  Lr: 0.001875  Loss: -0.8836  Acc@1: 81.2500 (82.2185)  Acc@5: 100.0000 (96.7189)  time: 0.3482  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [1390/3750]  eta: 0:13:45  Lr: 0.001875  Loss: -1.2576  Acc@1: 81.2500 (82.2250)  Acc@5: 100.0000 (96.7290)  time: 0.3489  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [1400/3750]  eta: 0:13:41  Lr: 0.001875  Loss: -1.1181  Acc@1: 75.0000 (82.1868)  Acc@5: 100.0000 (96.7256)  time: 0.3497  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [1410/3750]  eta: 0:13:38  Lr: 0.001875  Loss: -1.0080  Acc@1: 81.2500 (82.1846)  Acc@5: 100.0000 (96.7355)  time: 0.3487  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1420/3750]  eta: 0:13:34  Lr: 0.001875  Loss: -0.9714  Acc@1: 81.2500 (82.1912)  Acc@5: 100.0000 (96.7233)  time: 0.3486  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1430/3750]  eta: 0:13:31  Lr: 0.001875  Loss: -1.0047  Acc@1: 87.5000 (82.2109)  Acc@5: 93.7500 (96.7156)  time: 0.3487  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [1440/3750]  eta: 0:13:27  Lr: 0.001875  Loss: -1.0215  Acc@1: 87.5000 (82.2085)  Acc@5: 100.0000 (96.7297)  time: 0.3487  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [1450/3750]  eta: 0:13:24  Lr: 0.001875  Loss: -1.0293  Acc@1: 81.2500 (82.2149)  Acc@5: 100.0000 (96.7264)  time: 0.3488  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [1460/3750]  eta: 0:13:20  Lr: 0.001875  Loss: -1.0717  Acc@1: 87.5000 (82.2425)  Acc@5: 100.0000 (96.7360)  time: 0.3495  data: 0.0013  max mem: 2500
Train: Epoch[3/5]  [1470/3750]  eta: 0:13:17  Lr: 0.001875  Loss: -0.3635  Acc@1: 87.5000 (82.2612)  Acc@5: 100.0000 (96.7369)  time: 0.3494  data: 0.0013  max mem: 2500
Train: Epoch[3/5]  [1480/3750]  eta: 0:13:13  Lr: 0.001875  Loss: -1.1317  Acc@1: 81.2500 (82.2797)  Acc@5: 100.0000 (96.7505)  time: 0.3478  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [1490/3750]  eta: 0:13:10  Lr: 0.001875  Loss: -1.0772  Acc@1: 81.2500 (82.2602)  Acc@5: 100.0000 (96.7513)  time: 0.3493  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [1500/3750]  eta: 0:13:06  Lr: 0.001875  Loss: -1.0550  Acc@1: 81.2500 (82.2910)  Acc@5: 100.0000 (96.7522)  time: 0.3501  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [1510/3750]  eta: 0:13:03  Lr: 0.001875  Loss: -1.3015  Acc@1: 87.5000 (82.2924)  Acc@5: 100.0000 (96.7488)  time: 0.3500  data: 0.0013  max mem: 2500
Train: Epoch[3/5]  [1520/3750]  eta: 0:12:59  Lr: 0.001875  Loss: -0.9280  Acc@1: 87.5000 (82.2978)  Acc@5: 100.0000 (96.7497)  time: 0.3504  data: 0.0014  max mem: 2500
Train: Epoch[3/5]  [1530/3750]  eta: 0:12:56  Lr: 0.001875  Loss: -0.6619  Acc@1: 81.2500 (82.3032)  Acc@5: 93.7500 (96.7423)  time: 0.3519  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [1540/3750]  eta: 0:12:52  Lr: 0.001875  Loss: -0.8417  Acc@1: 81.2500 (82.3248)  Acc@5: 100.0000 (96.7554)  time: 0.3516  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [1550/3750]  eta: 0:12:49  Lr: 0.001875  Loss: -1.2997  Acc@1: 87.5000 (82.3420)  Acc@5: 100.0000 (96.7319)  time: 0.3497  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [1560/3750]  eta: 0:12:45  Lr: 0.001875  Loss: -0.8901  Acc@1: 81.2500 (82.3390)  Acc@5: 93.7500 (96.7249)  time: 0.3503  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [1570/3750]  eta: 0:12:42  Lr: 0.001875  Loss: -0.6486  Acc@1: 81.2500 (82.3520)  Acc@5: 93.7500 (96.7218)  time: 0.3504  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1580/3750]  eta: 0:12:38  Lr: 0.001875  Loss: -0.9643  Acc@1: 87.5000 (82.3648)  Acc@5: 100.0000 (96.7307)  time: 0.3492  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1590/3750]  eta: 0:12:35  Lr: 0.001875  Loss: -0.6354  Acc@1: 81.2500 (82.3421)  Acc@5: 100.0000 (96.7395)  time: 0.3487  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [1600/3750]  eta: 0:12:31  Lr: 0.001875  Loss: -1.0934  Acc@1: 81.2500 (82.3392)  Acc@5: 100.0000 (96.7520)  time: 0.3490  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [1610/3750]  eta: 0:12:28  Lr: 0.001875  Loss: -1.2464  Acc@1: 81.2500 (82.3208)  Acc@5: 100.0000 (96.7373)  time: 0.3485  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [1620/3750]  eta: 0:12:24  Lr: 0.001875  Loss: -0.9581  Acc@1: 81.2500 (82.3373)  Acc@5: 93.7500 (96.7458)  time: 0.3483  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [1630/3750]  eta: 0:12:21  Lr: 0.001875  Loss: -0.7796  Acc@1: 81.2500 (82.3153)  Acc@5: 93.7500 (96.7313)  time: 0.3501  data: 0.0012  max mem: 2500
Train: Epoch[3/5]  [1640/3750]  eta: 0:12:17  Lr: 0.001875  Loss: -1.1313  Acc@1: 81.2500 (82.3202)  Acc@5: 93.7500 (96.7398)  time: 0.3498  data: 0.0012  max mem: 2500
Train: Epoch[3/5]  [1650/3750]  eta: 0:12:14  Lr: 0.001875  Loss: -1.1751  Acc@1: 81.2500 (82.3175)  Acc@5: 100.0000 (96.7444)  time: 0.3479  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [1660/3750]  eta: 0:12:10  Lr: 0.001875  Loss: -0.8296  Acc@1: 81.2500 (82.3337)  Acc@5: 100.0000 (96.7527)  time: 0.3486  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [1670/3750]  eta: 0:12:07  Lr: 0.001875  Loss: -0.9187  Acc@1: 81.2500 (82.3160)  Acc@5: 100.0000 (96.7609)  time: 0.3485  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [1680/3750]  eta: 0:12:03  Lr: 0.001875  Loss: -1.1122  Acc@1: 81.2500 (82.3468)  Acc@5: 100.0000 (96.7690)  time: 0.3479  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [1690/3750]  eta: 0:12:00  Lr: 0.001875  Loss: -1.0546  Acc@1: 87.5000 (82.3588)  Acc@5: 100.0000 (96.7734)  time: 0.3492  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [1700/3750]  eta: 0:11:56  Lr: 0.001875  Loss: -0.7401  Acc@1: 81.2500 (82.3486)  Acc@5: 100.0000 (96.7556)  time: 0.3494  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [1710/3750]  eta: 0:11:53  Lr: 0.001875  Loss: -0.7822  Acc@1: 81.2500 (82.3860)  Acc@5: 93.7500 (96.7526)  time: 0.3489  data: 0.0012  max mem: 2500
Train: Epoch[3/5]  [1720/3750]  eta: 0:11:49  Lr: 0.001875  Loss: -1.3614  Acc@1: 87.5000 (82.4085)  Acc@5: 100.0000 (96.7533)  time: 0.3485  data: 0.0012  max mem: 2500
Train: Epoch[3/5]  [1730/3750]  eta: 0:11:46  Lr: 0.001875  Loss: -1.0757  Acc@1: 81.2500 (82.3982)  Acc@5: 100.0000 (96.7504)  time: 0.3483  data: 0.0012  max mem: 2500
Train: Epoch[3/5]  [1740/3750]  eta: 0:11:42  Lr: 0.001875  Loss: -0.5192  Acc@1: 81.2500 (82.3772)  Acc@5: 100.0000 (96.7547)  time: 0.3489  data: 0.0012  max mem: 2500
Train: Epoch[3/5]  [1750/3750]  eta: 0:11:39  Lr: 0.001875  Loss: -0.6504  Acc@1: 81.2500 (82.3529)  Acc@5: 93.7500 (96.7411)  time: 0.3486  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [1760/3750]  eta: 0:11:35  Lr: 0.001875  Loss: -1.1145  Acc@1: 81.2500 (82.3715)  Acc@5: 93.7500 (96.7419)  time: 0.3490  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1770/3750]  eta: 0:11:32  Lr: 0.001875  Loss: -1.1338  Acc@1: 87.5000 (82.3970)  Acc@5: 100.0000 (96.7391)  time: 0.3501  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [1780/3750]  eta: 0:11:28  Lr: 0.001875  Loss: -0.6602  Acc@1: 81.2500 (82.3800)  Acc@5: 100.0000 (96.7399)  time: 0.3505  data: 0.0012  max mem: 2500
Train: Epoch[3/5]  [1790/3750]  eta: 0:11:25  Lr: 0.001875  Loss: -0.5548  Acc@1: 87.5000 (82.4225)  Acc@5: 100.0000 (96.7372)  time: 0.3501  data: 0.0013  max mem: 2500
Train: Epoch[3/5]  [1800/3750]  eta: 0:11:21  Lr: 0.001875  Loss: -0.4713  Acc@1: 87.5000 (82.4299)  Acc@5: 100.0000 (96.7379)  time: 0.3496  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [1810/3750]  eta: 0:11:18  Lr: 0.001875  Loss: -0.8345  Acc@1: 81.2500 (82.4268)  Acc@5: 100.0000 (96.7387)  time: 0.3497  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [1820/3750]  eta: 0:11:14  Lr: 0.001875  Loss: -0.7385  Acc@1: 81.2500 (82.4375)  Acc@5: 100.0000 (96.7532)  time: 0.3494  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [1830/3750]  eta: 0:11:11  Lr: 0.001875  Loss: -1.0959  Acc@1: 81.2500 (82.4447)  Acc@5: 100.0000 (96.7641)  time: 0.3503  data: 0.0022  max mem: 2500
Train: Epoch[3/5]  [1840/3750]  eta: 0:11:07  Lr: 0.001875  Loss: -1.1615  Acc@1: 81.2500 (82.4348)  Acc@5: 100.0000 (96.7545)  time: 0.3515  data: 0.0020  max mem: 2500
Train: Epoch[3/5]  [1850/3750]  eta: 0:11:04  Lr: 0.001875  Loss: -1.3545  Acc@1: 87.5000 (82.4656)  Acc@5: 100.0000 (96.7619)  time: 0.3505  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [1860/3750]  eta: 0:11:00  Lr: 0.001875  Loss: -0.8887  Acc@1: 81.2500 (82.4456)  Acc@5: 100.0000 (96.7625)  time: 0.3492  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1870/3750]  eta: 0:10:57  Lr: 0.001875  Loss: -1.0527  Acc@1: 81.2500 (82.4392)  Acc@5: 100.0000 (96.7664)  time: 0.3492  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1880/3750]  eta: 0:10:53  Lr: 0.001875  Loss: -1.0332  Acc@1: 81.2500 (82.4229)  Acc@5: 93.7500 (96.7637)  time: 0.3490  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [1890/3750]  eta: 0:10:50  Lr: 0.001875  Loss: -0.7902  Acc@1: 81.2500 (82.4299)  Acc@5: 100.0000 (96.7676)  time: 0.3478  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [1900/3750]  eta: 0:10:46  Lr: 0.001875  Loss: -0.4474  Acc@1: 81.2500 (82.4106)  Acc@5: 93.7500 (96.7517)  time: 0.3481  data: 0.0013  max mem: 2500
Train: Epoch[3/5]  [1910/3750]  eta: 0:10:43  Lr: 0.001875  Loss: -1.0557  Acc@1: 81.2500 (82.3947)  Acc@5: 93.7500 (96.7556)  time: 0.3486  data: 0.0012  max mem: 2500
Train: Epoch[3/5]  [1920/3750]  eta: 0:10:39  Lr: 0.001875  Loss: -1.1530  Acc@1: 81.2500 (82.3822)  Acc@5: 100.0000 (96.7562)  time: 0.3485  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [1930/3750]  eta: 0:10:36  Lr: 0.001875  Loss: -1.0482  Acc@1: 81.2500 (82.3828)  Acc@5: 93.7500 (96.7504)  time: 0.3481  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [1940/3750]  eta: 0:10:32  Lr: 0.001875  Loss: -1.3812  Acc@1: 81.2500 (82.3963)  Acc@5: 100.0000 (96.7510)  time: 0.3497  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [1950/3750]  eta: 0:10:29  Lr: 0.001875  Loss: -1.1309  Acc@1: 87.5000 (82.4129)  Acc@5: 93.7500 (96.7389)  time: 0.3509  data: 0.0012  max mem: 2500
Train: Epoch[3/5]  [1960/3750]  eta: 0:10:25  Lr: 0.001875  Loss: -1.0375  Acc@1: 87.5000 (82.4037)  Acc@5: 93.7500 (96.7300)  time: 0.3497  data: 0.0019  max mem: 2500
Train: Epoch[3/5]  [1970/3750]  eta: 0:10:22  Lr: 0.001875  Loss: -0.8096  Acc@1: 87.5000 (82.4137)  Acc@5: 93.7500 (96.7275)  time: 0.3483  data: 0.0013  max mem: 2500
Train: Epoch[3/5]  [1980/3750]  eta: 0:10:18  Lr: 0.001875  Loss: -0.4801  Acc@1: 81.2500 (82.4079)  Acc@5: 93.7500 (96.7125)  time: 0.3478  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [1990/3750]  eta: 0:10:15  Lr: 0.001875  Loss: -1.0361  Acc@1: 81.2500 (82.4146)  Acc@5: 93.7500 (96.7133)  time: 0.3499  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [2000/3750]  eta: 0:10:11  Lr: 0.001875  Loss: -1.2674  Acc@1: 87.5000 (82.4182)  Acc@5: 93.7500 (96.7079)  time: 0.3511  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [2010/3750]  eta: 0:10:08  Lr: 0.001875  Loss: -1.1187  Acc@1: 81.2500 (82.4030)  Acc@5: 100.0000 (96.7149)  time: 0.3496  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [2020/3750]  eta: 0:10:04  Lr: 0.001875  Loss: -1.2361  Acc@1: 81.2500 (82.3942)  Acc@5: 100.0000 (96.7034)  time: 0.3506  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [2030/3750]  eta: 0:10:01  Lr: 0.001875  Loss: -0.9388  Acc@1: 81.2500 (82.4163)  Acc@5: 100.0000 (96.7134)  time: 0.3507  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [2040/3750]  eta: 0:09:57  Lr: 0.001875  Loss: -1.1067  Acc@1: 81.2500 (82.4014)  Acc@5: 100.0000 (96.7112)  time: 0.3482  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [2050/3750]  eta: 0:09:54  Lr: 0.001875  Loss: -0.6934  Acc@1: 87.5000 (82.4110)  Acc@5: 100.0000 (96.7150)  time: 0.3487  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2060/3750]  eta: 0:09:50  Lr: 0.001875  Loss: -1.0463  Acc@1: 87.5000 (82.4327)  Acc@5: 100.0000 (96.7219)  time: 0.3485  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [2070/3750]  eta: 0:09:47  Lr: 0.001875  Loss: -1.0587  Acc@1: 87.5000 (82.4390)  Acc@5: 100.0000 (96.7256)  time: 0.3482  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [2080/3750]  eta: 0:09:43  Lr: 0.001875  Loss: -0.9029  Acc@1: 81.2500 (82.4273)  Acc@5: 100.0000 (96.7173)  time: 0.3484  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [2090/3750]  eta: 0:09:40  Lr: 0.001875  Loss: -0.9089  Acc@1: 81.2500 (82.4307)  Acc@5: 100.0000 (96.7211)  time: 0.3479  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [2100/3750]  eta: 0:09:36  Lr: 0.001875  Loss: -0.5675  Acc@1: 81.2500 (82.3893)  Acc@5: 100.0000 (96.7188)  time: 0.3479  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [2110/3750]  eta: 0:09:33  Lr: 0.001875  Loss: -0.8645  Acc@1: 81.2500 (82.3839)  Acc@5: 100.0000 (96.7166)  time: 0.3489  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [2120/3750]  eta: 0:09:29  Lr: 0.001875  Loss: -1.2550  Acc@1: 81.2500 (82.3874)  Acc@5: 100.0000 (96.7144)  time: 0.3505  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [2130/3750]  eta: 0:09:26  Lr: 0.001875  Loss: -0.7686  Acc@1: 81.2500 (82.3762)  Acc@5: 100.0000 (96.7152)  time: 0.3491  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [2140/3750]  eta: 0:09:22  Lr: 0.001875  Loss: -0.9248  Acc@1: 81.2500 (82.3622)  Acc@5: 93.7500 (96.7071)  time: 0.3481  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [2150/3750]  eta: 0:09:19  Lr: 0.001875  Loss: -0.9940  Acc@1: 81.2500 (82.3832)  Acc@5: 100.0000 (96.7108)  time: 0.3480  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [2160/3750]  eta: 0:09:15  Lr: 0.001875  Loss: -0.6885  Acc@1: 81.2500 (82.3808)  Acc@5: 100.0000 (96.7116)  time: 0.3481  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [2170/3750]  eta: 0:09:12  Lr: 0.001875  Loss: -1.0639  Acc@1: 81.2500 (82.3699)  Acc@5: 100.0000 (96.7123)  time: 0.3506  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [2180/3750]  eta: 0:09:08  Lr: 0.001875  Loss: -1.1121  Acc@1: 81.2500 (82.3676)  Acc@5: 100.0000 (96.7160)  time: 0.3514  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [2190/3750]  eta: 0:09:05  Lr: 0.001875  Loss: -1.0556  Acc@1: 81.2500 (82.3768)  Acc@5: 100.0000 (96.7081)  time: 0.3496  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [2200/3750]  eta: 0:09:01  Lr: 0.001875  Loss: -1.3455  Acc@1: 81.2500 (82.3745)  Acc@5: 93.7500 (96.7032)  time: 0.3484  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [2210/3750]  eta: 0:08:58  Lr: 0.001875  Loss: -0.8799  Acc@1: 81.2500 (82.3694)  Acc@5: 93.7500 (96.6955)  time: 0.3474  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2220/3750]  eta: 0:08:54  Lr: 0.001875  Loss: -0.7374  Acc@1: 81.2500 (82.3784)  Acc@5: 93.7500 (96.6991)  time: 0.3474  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [2230/3750]  eta: 0:08:51  Lr: 0.001875  Loss: -1.3445  Acc@1: 81.2500 (82.3846)  Acc@5: 100.0000 (96.7027)  time: 0.3482  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [2240/3750]  eta: 0:08:47  Lr: 0.001875  Loss: -0.4807  Acc@1: 81.2500 (82.3516)  Acc@5: 100.0000 (96.6979)  time: 0.3480  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [2250/3750]  eta: 0:08:44  Lr: 0.001875  Loss: -0.7239  Acc@1: 75.0000 (82.3412)  Acc@5: 100.0000 (96.6987)  time: 0.3487  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [2260/3750]  eta: 0:08:40  Lr: 0.001875  Loss: -1.4219  Acc@1: 81.2500 (82.3474)  Acc@5: 100.0000 (96.7050)  time: 0.3485  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [2270/3750]  eta: 0:08:37  Lr: 0.001875  Loss: -0.6806  Acc@1: 81.2500 (82.3536)  Acc@5: 100.0000 (96.7113)  time: 0.3482  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [2280/3750]  eta: 0:08:33  Lr: 0.001875  Loss: -0.7701  Acc@1: 75.0000 (82.3186)  Acc@5: 100.0000 (96.7065)  time: 0.3483  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [2290/3750]  eta: 0:08:30  Lr: 0.001875  Loss: -1.1703  Acc@1: 81.2500 (82.3221)  Acc@5: 93.7500 (96.7072)  time: 0.3482  data: 0.0013  max mem: 2500
Train: Epoch[3/5]  [2300/3750]  eta: 0:08:26  Lr: 0.001875  Loss: -0.7766  Acc@1: 81.2500 (82.3175)  Acc@5: 100.0000 (96.7107)  time: 0.3482  data: 0.0017  max mem: 2500
Train: Epoch[3/5]  [2310/3750]  eta: 0:08:23  Lr: 0.001875  Loss: -0.8846  Acc@1: 87.5000 (82.3237)  Acc@5: 100.0000 (96.7087)  time: 0.3484  data: 0.0009  max mem: 2500
Train: Epoch[3/5]  [2320/3750]  eta: 0:08:19  Lr: 0.001875  Loss: -0.9143  Acc@1: 87.5000 (82.3325)  Acc@5: 100.0000 (96.7040)  time: 0.3494  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [2330/3750]  eta: 0:08:16  Lr: 0.001875  Loss: -1.1932  Acc@1: 81.2500 (82.3305)  Acc@5: 93.7500 (96.6994)  time: 0.3503  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [2340/3750]  eta: 0:08:12  Lr: 0.001875  Loss: -1.0003  Acc@1: 81.2500 (82.3339)  Acc@5: 100.0000 (96.7108)  time: 0.3515  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [2350/3750]  eta: 0:08:09  Lr: 0.001875  Loss: -1.2159  Acc@1: 81.2500 (82.3240)  Acc@5: 100.0000 (96.7195)  time: 0.3492  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [2360/3750]  eta: 0:08:05  Lr: 0.001875  Loss: -1.1319  Acc@1: 87.5000 (82.3539)  Acc@5: 100.0000 (96.7175)  time: 0.3471  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [2370/3750]  eta: 0:08:02  Lr: 0.001875  Loss: -1.0984  Acc@1: 87.5000 (82.3677)  Acc@5: 100.0000 (96.7129)  time: 0.3480  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [2380/3750]  eta: 0:07:58  Lr: 0.001875  Loss: -0.4445  Acc@1: 81.2500 (82.3630)  Acc@5: 100.0000 (96.7136)  time: 0.3479  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [2390/3750]  eta: 0:07:55  Lr: 0.001875  Loss: -1.0743  Acc@1: 81.2500 (82.3818)  Acc@5: 100.0000 (96.7195)  time: 0.3474  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [2400/3750]  eta: 0:07:51  Lr: 0.001875  Loss: -0.9384  Acc@1: 87.5000 (82.3823)  Acc@5: 100.0000 (96.7227)  time: 0.3487  data: 0.0021  max mem: 2500
Train: Epoch[3/5]  [2410/3750]  eta: 0:07:48  Lr: 0.001875  Loss: -1.1334  Acc@1: 81.2500 (82.3725)  Acc@5: 100.0000 (96.7234)  time: 0.3497  data: 0.0020  max mem: 2500
Train: Epoch[3/5]  [2420/3750]  eta: 0:07:44  Lr: 0.001875  Loss: -1.2729  Acc@1: 87.5000 (82.3988)  Acc@5: 100.0000 (96.7240)  time: 0.3499  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [2430/3750]  eta: 0:07:41  Lr: 0.001875  Loss: -0.8421  Acc@1: 81.2500 (82.3735)  Acc@5: 100.0000 (96.7220)  time: 0.3503  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [2440/3750]  eta: 0:07:37  Lr: 0.001875  Loss: -1.0245  Acc@1: 75.0000 (82.3459)  Acc@5: 93.7500 (96.7175)  time: 0.3496  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [2450/3750]  eta: 0:07:34  Lr: 0.001875  Loss: -1.1304  Acc@1: 75.0000 (82.3516)  Acc@5: 93.7500 (96.7156)  time: 0.3487  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [2460/3750]  eta: 0:07:30  Lr: 0.001875  Loss: -0.4960  Acc@1: 81.2500 (82.3547)  Acc@5: 93.7500 (96.7087)  time: 0.3480  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2470/3750]  eta: 0:07:27  Lr: 0.001875  Loss: -0.9112  Acc@1: 81.2500 (82.3503)  Acc@5: 93.7500 (96.6992)  time: 0.3483  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [2480/3750]  eta: 0:07:23  Lr: 0.001875  Loss: -0.9402  Acc@1: 81.2500 (82.3408)  Acc@5: 93.7500 (96.6949)  time: 0.3490  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [2490/3750]  eta: 0:07:20  Lr: 0.001875  Loss: -1.1241  Acc@1: 75.0000 (82.3339)  Acc@5: 93.7500 (96.6906)  time: 0.3500  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [2500/3750]  eta: 0:07:16  Lr: 0.001875  Loss: -1.0139  Acc@1: 75.0000 (82.3296)  Acc@5: 100.0000 (96.6888)  time: 0.3511  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [2510/3750]  eta: 0:07:13  Lr: 0.001875  Loss: -1.2936  Acc@1: 87.5000 (82.3477)  Acc@5: 100.0000 (96.6871)  time: 0.3499  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [2520/3750]  eta: 0:07:09  Lr: 0.001875  Loss: -0.5266  Acc@1: 87.5000 (82.3631)  Acc@5: 93.7500 (96.6829)  time: 0.3481  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2530/3750]  eta: 0:07:06  Lr: 0.001875  Loss: -1.0918  Acc@1: 87.5000 (82.3859)  Acc@5: 100.0000 (96.6886)  time: 0.3502  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [2540/3750]  eta: 0:07:02  Lr: 0.001875  Loss: -0.8963  Acc@1: 81.2500 (82.3741)  Acc@5: 93.7500 (96.6770)  time: 0.3532  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [2550/3750]  eta: 0:06:59  Lr: 0.001875  Loss: -0.9601  Acc@1: 75.0000 (82.3476)  Acc@5: 100.0000 (96.6851)  time: 0.3517  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [2560/3750]  eta: 0:06:55  Lr: 0.001875  Loss: -0.9171  Acc@1: 75.0000 (82.3360)  Acc@5: 100.0000 (96.6834)  time: 0.3487  data: 0.0009  max mem: 2500
Train: Epoch[3/5]  [2570/3750]  eta: 0:06:52  Lr: 0.001875  Loss: -0.8309  Acc@1: 81.2500 (82.3342)  Acc@5: 93.7500 (96.6842)  time: 0.3493  data: 0.0009  max mem: 2500
Train: Epoch[3/5]  [2580/3750]  eta: 0:06:48  Lr: 0.001875  Loss: -0.9378  Acc@1: 81.2500 (82.3252)  Acc@5: 100.0000 (96.6849)  time: 0.3501  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [2590/3750]  eta: 0:06:45  Lr: 0.001875  Loss: -0.8893  Acc@1: 81.2500 (82.3355)  Acc@5: 100.0000 (96.6832)  time: 0.3495  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [2600/3750]  eta: 0:06:41  Lr: 0.001875  Loss: -1.3474  Acc@1: 81.2500 (82.3337)  Acc@5: 100.0000 (96.6840)  time: 0.3494  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [2610/3750]  eta: 0:06:38  Lr: 0.001875  Loss: -1.1787  Acc@1: 81.2500 (82.3320)  Acc@5: 100.0000 (96.6847)  time: 0.3483  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [2620/3750]  eta: 0:06:34  Lr: 0.001875  Loss: -1.0981  Acc@1: 87.5000 (82.3612)  Acc@5: 100.0000 (96.6878)  time: 0.3483  data: 0.0012  max mem: 2500
Train: Epoch[3/5]  [2630/3750]  eta: 0:06:31  Lr: 0.001875  Loss: -1.1958  Acc@1: 81.2500 (82.3451)  Acc@5: 93.7500 (96.6790)  time: 0.3502  data: 0.0013  max mem: 2500
Train: Epoch[3/5]  [2640/3750]  eta: 0:06:27  Lr: 0.001875  Loss: -0.6544  Acc@1: 81.2500 (82.3433)  Acc@5: 93.7500 (96.6798)  time: 0.3500  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [2650/3750]  eta: 0:06:24  Lr: 0.001875  Loss: -1.1008  Acc@1: 87.5000 (82.3534)  Acc@5: 100.0000 (96.6829)  time: 0.3487  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2660/3750]  eta: 0:06:20  Lr: 0.001875  Loss: -1.3484  Acc@1: 87.5000 (82.3586)  Acc@5: 100.0000 (96.6789)  time: 0.3498  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [2670/3750]  eta: 0:06:17  Lr: 0.001875  Loss: -1.0198  Acc@1: 81.2500 (82.3521)  Acc@5: 100.0000 (96.6796)  time: 0.3506  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [2680/3750]  eta: 0:06:13  Lr: 0.001875  Loss: -1.3533  Acc@1: 81.2500 (82.3643)  Acc@5: 100.0000 (96.6850)  time: 0.3505  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [2690/3750]  eta: 0:06:10  Lr: 0.001875  Loss: -0.8004  Acc@1: 87.5000 (82.3718)  Acc@5: 100.0000 (96.6927)  time: 0.3498  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [2700/3750]  eta: 0:06:06  Lr: 0.001875  Loss: -1.0552  Acc@1: 81.2500 (82.3630)  Acc@5: 100.0000 (96.6887)  time: 0.3488  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [2710/3750]  eta: 0:06:03  Lr: 0.001875  Loss: -0.6594  Acc@1: 81.2500 (82.3704)  Acc@5: 100.0000 (96.6917)  time: 0.3491  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [2720/3750]  eta: 0:05:59  Lr: 0.001875  Loss: -0.9191  Acc@1: 81.2500 (82.3686)  Acc@5: 100.0000 (96.7039)  time: 0.3490  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [2730/3750]  eta: 0:05:56  Lr: 0.001875  Loss: -1.0178  Acc@1: 87.5000 (82.3828)  Acc@5: 100.0000 (96.7091)  time: 0.3486  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [2740/3750]  eta: 0:05:52  Lr: 0.001875  Loss: -1.1048  Acc@1: 87.5000 (82.3833)  Acc@5: 100.0000 (96.7097)  time: 0.3499  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [2750/3750]  eta: 0:05:49  Lr: 0.001875  Loss: -1.0024  Acc@1: 81.2500 (82.3928)  Acc@5: 100.0000 (96.7103)  time: 0.3517  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [2760/3750]  eta: 0:05:45  Lr: 0.001875  Loss: -0.7872  Acc@1: 87.5000 (82.4090)  Acc@5: 100.0000 (96.7177)  time: 0.3516  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [2770/3750]  eta: 0:05:42  Lr: 0.001875  Loss: -0.5864  Acc@1: 87.5000 (82.4229)  Acc@5: 100.0000 (96.7137)  time: 0.3510  data: 0.0015  max mem: 2500
Train: Epoch[3/5]  [2780/3750]  eta: 0:05:38  Lr: 0.001875  Loss: -0.9420  Acc@1: 81.2500 (82.4299)  Acc@5: 100.0000 (96.7211)  time: 0.3494  data: 0.0015  max mem: 2500
Train: Epoch[3/5]  [2790/3750]  eta: 0:05:35  Lr: 0.001875  Loss: -0.8882  Acc@1: 81.2500 (82.4346)  Acc@5: 100.0000 (96.7126)  time: 0.3482  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [2800/3750]  eta: 0:05:31  Lr: 0.001875  Loss: -1.1190  Acc@1: 81.2500 (82.4237)  Acc@5: 93.7500 (96.7043)  time: 0.3494  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [2810/3750]  eta: 0:05:28  Lr: 0.001875  Loss: -0.8408  Acc@1: 81.2500 (82.3973)  Acc@5: 93.7500 (96.6982)  time: 0.3514  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [2820/3750]  eta: 0:05:24  Lr: 0.001875  Loss: -1.2877  Acc@1: 81.2500 (82.3932)  Acc@5: 100.0000 (96.7033)  time: 0.3509  data: 0.0010  max mem: 2500
Train: Epoch[3/5]  [2830/3750]  eta: 0:05:21  Lr: 0.001875  Loss: -0.7302  Acc@1: 81.2500 (82.3826)  Acc@5: 100.0000 (96.6995)  time: 0.3495  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [2840/3750]  eta: 0:05:17  Lr: 0.001875  Loss: -0.8362  Acc@1: 75.0000 (82.3720)  Acc@5: 93.7500 (96.6913)  time: 0.3490  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [2850/3750]  eta: 0:05:14  Lr: 0.001875  Loss: -1.4041  Acc@1: 81.2500 (82.3921)  Acc@5: 100.0000 (96.6985)  time: 0.3492  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [2860/3750]  eta: 0:05:11  Lr: 0.001875  Loss: -0.8920  Acc@1: 87.5000 (82.3947)  Acc@5: 100.0000 (96.6904)  time: 0.3495  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [2870/3750]  eta: 0:05:07  Lr: 0.001875  Loss: -1.0595  Acc@1: 81.2500 (82.4081)  Acc@5: 100.0000 (96.6998)  time: 0.3490  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [2880/3750]  eta: 0:05:04  Lr: 0.001875  Loss: -0.9405  Acc@1: 81.2500 (82.4128)  Acc@5: 100.0000 (96.6960)  time: 0.3489  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [2890/3750]  eta: 0:05:00  Lr: 0.001875  Loss: -1.0221  Acc@1: 81.2500 (82.4196)  Acc@5: 100.0000 (96.6923)  time: 0.3500  data: 0.0013  max mem: 2500
Train: Epoch[3/5]  [2900/3750]  eta: 0:04:57  Lr: 0.001875  Loss: -0.7623  Acc@1: 81.2500 (82.4263)  Acc@5: 100.0000 (96.6973)  time: 0.3501  data: 0.0014  max mem: 2500
Train: Epoch[3/5]  [2910/3750]  eta: 0:04:53  Lr: 0.001875  Loss: -0.7823  Acc@1: 87.5000 (82.4330)  Acc@5: 100.0000 (96.7000)  time: 0.3500  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [2920/3750]  eta: 0:04:50  Lr: 0.001875  Loss: -1.1120  Acc@1: 81.2500 (82.4290)  Acc@5: 100.0000 (96.6942)  time: 0.3498  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [2930/3750]  eta: 0:04:46  Lr: 0.001875  Loss: -0.7493  Acc@1: 81.2500 (82.4335)  Acc@5: 100.0000 (96.6991)  time: 0.3482  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [2940/3750]  eta: 0:04:43  Lr: 0.001875  Loss: -0.7543  Acc@1: 87.5000 (82.4422)  Acc@5: 100.0000 (96.6976)  time: 0.3498  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [2950/3750]  eta: 0:04:39  Lr: 0.001875  Loss: -0.8590  Acc@1: 87.5000 (82.4466)  Acc@5: 100.0000 (96.7003)  time: 0.3508  data: 0.0011  max mem: 2500
Train: Epoch[3/5]  [2960/3750]  eta: 0:04:36  Lr: 0.001875  Loss: -0.9165  Acc@1: 81.2500 (82.4426)  Acc@5: 100.0000 (96.6988)  time: 0.3507  data: 0.0011  max mem: 2500
Train: Epoch[3/5]  [2970/3750]  eta: 0:04:32  Lr: 0.001875  Loss: -0.8054  Acc@1: 81.2500 (82.4302)  Acc@5: 93.7500 (96.6951)  time: 0.3502  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [2980/3750]  eta: 0:04:29  Lr: 0.001875  Loss: -0.9048  Acc@1: 81.2500 (82.4178)  Acc@5: 100.0000 (96.6978)  time: 0.3492  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [2990/3750]  eta: 0:04:25  Lr: 0.001875  Loss: -1.2503  Acc@1: 75.0000 (82.4076)  Acc@5: 100.0000 (96.6963)  time: 0.3487  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3000/3750]  eta: 0:04:22  Lr: 0.001875  Loss: -1.2158  Acc@1: 87.5000 (82.4163)  Acc@5: 100.0000 (96.7032)  time: 0.3484  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [3010/3750]  eta: 0:04:18  Lr: 0.001875  Loss: -1.0303  Acc@1: 87.5000 (82.4207)  Acc@5: 100.0000 (96.7038)  time: 0.3501  data: 0.0014  max mem: 2500
Train: Epoch[3/5]  [3020/3750]  eta: 0:04:15  Lr: 0.001875  Loss: -1.0029  Acc@1: 81.2500 (82.4044)  Acc@5: 93.7500 (96.6981)  time: 0.3497  data: 0.0015  max mem: 2500
Train: Epoch[3/5]  [3030/3750]  eta: 0:04:11  Lr: 0.001875  Loss: -1.0765  Acc@1: 81.2500 (82.4047)  Acc@5: 93.7500 (96.6966)  time: 0.3502  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [3040/3750]  eta: 0:04:08  Lr: 0.001875  Loss: -1.1050  Acc@1: 81.2500 (82.4030)  Acc@5: 93.7500 (96.6890)  time: 0.3506  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [3050/3750]  eta: 0:04:04  Lr: 0.001875  Loss: -0.8403  Acc@1: 81.2500 (82.4136)  Acc@5: 93.7500 (96.6835)  time: 0.3489  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [3060/3750]  eta: 0:04:01  Lr: 0.001875  Loss: -0.8015  Acc@1: 87.5000 (82.4220)  Acc@5: 100.0000 (96.6882)  time: 0.3487  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [3070/3750]  eta: 0:03:57  Lr: 0.001875  Loss: -1.0142  Acc@1: 87.5000 (82.4304)  Acc@5: 100.0000 (96.6929)  time: 0.3489  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [3080/3750]  eta: 0:03:54  Lr: 0.001875  Loss: -0.6476  Acc@1: 81.2500 (82.4266)  Acc@5: 100.0000 (96.6955)  time: 0.3487  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [3090/3750]  eta: 0:03:50  Lr: 0.001875  Loss: -1.2261  Acc@1: 81.2500 (82.4228)  Acc@5: 93.7500 (96.6900)  time: 0.3479  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [3100/3750]  eta: 0:03:47  Lr: 0.001875  Loss: -1.1242  Acc@1: 87.5000 (82.4371)  Acc@5: 93.7500 (96.6926)  time: 0.3482  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [3110/3750]  eta: 0:03:43  Lr: 0.001875  Loss: -0.9208  Acc@1: 87.5000 (82.4293)  Acc@5: 93.7500 (96.6892)  time: 0.3499  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [3120/3750]  eta: 0:03:40  Lr: 0.001875  Loss: -0.6206  Acc@1: 75.0000 (82.4115)  Acc@5: 100.0000 (96.6898)  time: 0.3499  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [3130/3750]  eta: 0:03:36  Lr: 0.001875  Loss: -0.8938  Acc@1: 81.2500 (82.4078)  Acc@5: 100.0000 (96.6884)  time: 0.3482  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [3140/3750]  eta: 0:03:33  Lr: 0.001875  Loss: -1.2484  Acc@1: 81.2500 (82.4061)  Acc@5: 100.0000 (96.6830)  time: 0.3468  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [3150/3750]  eta: 0:03:29  Lr: 0.001875  Loss: -0.3730  Acc@1: 81.2500 (82.3984)  Acc@5: 100.0000 (96.6856)  time: 0.3470  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3160/3750]  eta: 0:03:26  Lr: 0.001875  Loss: -1.0855  Acc@1: 81.2500 (82.3948)  Acc@5: 100.0000 (96.6901)  time: 0.3481  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [3170/3750]  eta: 0:03:22  Lr: 0.001875  Loss: -1.2496  Acc@1: 81.2500 (82.3912)  Acc@5: 100.0000 (96.6966)  time: 0.3494  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [3180/3750]  eta: 0:03:19  Lr: 0.001875  Loss: -1.4716  Acc@1: 81.2500 (82.3896)  Acc@5: 100.0000 (96.6972)  time: 0.3494  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [3190/3750]  eta: 0:03:15  Lr: 0.001875  Loss: -0.5879  Acc@1: 81.2500 (82.3880)  Acc@5: 100.0000 (96.6938)  time: 0.3488  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [3200/3750]  eta: 0:03:12  Lr: 0.001875  Loss: -1.0361  Acc@1: 81.2500 (82.3864)  Acc@5: 93.7500 (96.6846)  time: 0.3483  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [3210/3750]  eta: 0:03:08  Lr: 0.001875  Loss: -0.9126  Acc@1: 81.2500 (82.3731)  Acc@5: 93.7500 (96.6891)  time: 0.3474  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [3220/3750]  eta: 0:03:05  Lr: 0.001875  Loss: -0.9747  Acc@1: 81.2500 (82.3696)  Acc@5: 100.0000 (96.6897)  time: 0.3475  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [3230/3750]  eta: 0:03:01  Lr: 0.001875  Loss: -1.0385  Acc@1: 81.2500 (82.3719)  Acc@5: 100.0000 (96.6903)  time: 0.3490  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [3240/3750]  eta: 0:02:58  Lr: 0.001875  Loss: -0.9118  Acc@1: 81.2500 (82.3646)  Acc@5: 100.0000 (96.6928)  time: 0.3502  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [3250/3750]  eta: 0:02:54  Lr: 0.001875  Loss: -0.9930  Acc@1: 81.2500 (82.3747)  Acc@5: 100.0000 (96.6933)  time: 0.3514  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [3260/3750]  eta: 0:02:51  Lr: 0.001875  Loss: -0.6498  Acc@1: 81.2500 (82.3674)  Acc@5: 93.7500 (96.6843)  time: 0.3525  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [3270/3750]  eta: 0:02:47  Lr: 0.001875  Loss: -1.1187  Acc@1: 81.2500 (82.3678)  Acc@5: 93.7500 (96.6887)  time: 0.3515  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [3280/3750]  eta: 0:02:44  Lr: 0.001875  Loss: -0.9426  Acc@1: 81.2500 (82.3548)  Acc@5: 93.7500 (96.6778)  time: 0.3488  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [3290/3750]  eta: 0:02:40  Lr: 0.001875  Loss: -0.7868  Acc@1: 81.2500 (82.3515)  Acc@5: 93.7500 (96.6803)  time: 0.3479  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [3300/3750]  eta: 0:02:37  Lr: 0.001875  Loss: -1.1234  Acc@1: 81.2500 (82.3557)  Acc@5: 100.0000 (96.6866)  time: 0.3482  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [3310/3750]  eta: 0:02:33  Lr: 0.001875  Loss: -1.0209  Acc@1: 81.2500 (82.3599)  Acc@5: 100.0000 (96.6796)  time: 0.3479  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3320/3750]  eta: 0:02:30  Lr: 0.001875  Loss: -1.0146  Acc@1: 87.5000 (82.3641)  Acc@5: 100.0000 (96.6821)  time: 0.3503  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [3330/3750]  eta: 0:02:26  Lr: 0.001875  Loss: -1.1283  Acc@1: 87.5000 (82.3608)  Acc@5: 100.0000 (96.6827)  time: 0.3508  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [3340/3750]  eta: 0:02:23  Lr: 0.001875  Loss: -1.0654  Acc@1: 87.5000 (82.3687)  Acc@5: 100.0000 (96.6814)  time: 0.3502  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [3350/3750]  eta: 0:02:19  Lr: 0.001875  Loss: -0.7985  Acc@1: 81.2500 (82.3504)  Acc@5: 93.7500 (96.6726)  time: 0.3502  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [3360/3750]  eta: 0:02:16  Lr: 0.001875  Loss: -0.7688  Acc@1: 81.2500 (82.3564)  Acc@5: 100.0000 (96.6788)  time: 0.3495  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [3370/3750]  eta: 0:02:12  Lr: 0.001875  Loss: -1.1408  Acc@1: 81.2500 (82.3495)  Acc@5: 100.0000 (96.6701)  time: 0.3498  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [3380/3750]  eta: 0:02:09  Lr: 0.001875  Loss: -1.0877  Acc@1: 81.2500 (82.3517)  Acc@5: 93.7500 (96.6726)  time: 0.3493  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [3390/3750]  eta: 0:02:05  Lr: 0.001875  Loss: -1.3185  Acc@1: 81.2500 (82.3448)  Acc@5: 100.0000 (96.6732)  time: 0.3499  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [3400/3750]  eta: 0:02:02  Lr: 0.001875  Loss: -1.0372  Acc@1: 81.2500 (82.3361)  Acc@5: 100.0000 (96.6738)  time: 0.3514  data: 0.0009  max mem: 2500
Train: Epoch[3/5]  [3410/3750]  eta: 0:01:58  Lr: 0.001875  Loss: -0.9475  Acc@1: 81.2500 (82.3329)  Acc@5: 100.0000 (96.6725)  time: 0.3519  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [3420/3750]  eta: 0:01:55  Lr: 0.001875  Loss: -0.5205  Acc@1: 81.2500 (82.3224)  Acc@5: 100.0000 (96.6731)  time: 0.3502  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [3430/3750]  eta: 0:01:51  Lr: 0.001875  Loss: -0.5438  Acc@1: 81.2500 (82.3229)  Acc@5: 100.0000 (96.6719)  time: 0.3490  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [3440/3750]  eta: 0:01:48  Lr: 0.001875  Loss: -1.1656  Acc@1: 81.2500 (82.3198)  Acc@5: 93.7500 (96.6707)  time: 0.3494  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [3450/3750]  eta: 0:01:44  Lr: 0.001875  Loss: -1.0491  Acc@1: 81.2500 (82.2986)  Acc@5: 100.0000 (96.6713)  time: 0.3480  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [3460/3750]  eta: 0:01:41  Lr: 0.001875  Loss: -0.8538  Acc@1: 81.2500 (82.2974)  Acc@5: 100.0000 (96.6718)  time: 0.3474  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [3470/3750]  eta: 0:01:37  Lr: 0.001875  Loss: -0.9216  Acc@1: 81.2500 (82.3034)  Acc@5: 100.0000 (96.6760)  time: 0.3483  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [3480/3750]  eta: 0:01:34  Lr: 0.001875  Loss: -0.9247  Acc@1: 87.5000 (82.3075)  Acc@5: 100.0000 (96.6712)  time: 0.3498  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [3490/3750]  eta: 0:01:30  Lr: 0.001875  Loss: -1.0413  Acc@1: 81.2500 (82.3027)  Acc@5: 100.0000 (96.6718)  time: 0.3496  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [3500/3750]  eta: 0:01:27  Lr: 0.001875  Loss: -0.9074  Acc@1: 81.2500 (82.2961)  Acc@5: 100.0000 (96.6759)  time: 0.3479  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [3510/3750]  eta: 0:01:23  Lr: 0.001875  Loss: -0.9752  Acc@1: 81.2500 (82.2914)  Acc@5: 100.0000 (96.6765)  time: 0.3474  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3520/3750]  eta: 0:01:20  Lr: 0.001875  Loss: -0.8296  Acc@1: 81.2500 (82.2920)  Acc@5: 100.0000 (96.6771)  time: 0.3474  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3530/3750]  eta: 0:01:16  Lr: 0.001875  Loss: -0.4483  Acc@1: 81.2500 (82.2908)  Acc@5: 93.7500 (96.6723)  time: 0.3480  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [3540/3750]  eta: 0:01:13  Lr: 0.001875  Loss: -1.2264  Acc@1: 81.2500 (82.2861)  Acc@5: 93.7500 (96.6694)  time: 0.3471  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [3550/3750]  eta: 0:01:09  Lr: 0.001875  Loss: -0.8305  Acc@1: 81.2500 (82.2955)  Acc@5: 100.0000 (96.6664)  time: 0.3468  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [3560/3750]  eta: 0:01:06  Lr: 0.001875  Loss: -1.1948  Acc@1: 81.2500 (82.2890)  Acc@5: 93.7500 (96.6670)  time: 0.3486  data: 0.0012  max mem: 2500
Train: Epoch[3/5]  [3570/3750]  eta: 0:01:02  Lr: 0.001875  Loss: -1.1119  Acc@1: 81.2500 (82.2949)  Acc@5: 100.0000 (96.6729)  time: 0.3497  data: 0.0013  max mem: 2500
Train: Epoch[3/5]  [3580/3750]  eta: 0:00:59  Lr: 0.001875  Loss: -1.0208  Acc@1: 81.2500 (82.2902)  Acc@5: 100.0000 (96.6699)  time: 0.3497  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [3590/3750]  eta: 0:00:55  Lr: 0.001875  Loss: -0.3938  Acc@1: 81.2500 (82.2838)  Acc@5: 100.0000 (96.6740)  time: 0.3500  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [3600/3750]  eta: 0:00:52  Lr: 0.001875  Loss: -1.0957  Acc@1: 81.2500 (82.2931)  Acc@5: 100.0000 (96.6780)  time: 0.3490  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [3610/3750]  eta: 0:00:48  Lr: 0.001875  Loss: -0.9442  Acc@1: 81.2500 (82.2954)  Acc@5: 100.0000 (96.6768)  time: 0.3476  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [3620/3750]  eta: 0:00:45  Lr: 0.001875  Loss: -1.0031  Acc@1: 81.2500 (82.2891)  Acc@5: 100.0000 (96.6791)  time: 0.3483  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [3630/3750]  eta: 0:00:41  Lr: 0.001875  Loss: -0.9305  Acc@1: 81.2500 (82.2828)  Acc@5: 100.0000 (96.6762)  time: 0.3499  data: 0.0010  max mem: 2500
Train: Epoch[3/5]  [3640/3750]  eta: 0:00:38  Lr: 0.001875  Loss: -1.2126  Acc@1: 87.5000 (82.3057)  Acc@5: 100.0000 (96.6853)  time: 0.3502  data: 0.0010  max mem: 2500
Train: Epoch[3/5]  [3650/3750]  eta: 0:00:34  Lr: 0.001875  Loss: -0.6667  Acc@1: 87.5000 (82.3079)  Acc@5: 100.0000 (96.6824)  time: 0.3493  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3660/3750]  eta: 0:00:31  Lr: 0.001875  Loss: -1.2568  Acc@1: 81.2500 (82.2982)  Acc@5: 93.7500 (96.6778)  time: 0.3489  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3670/3750]  eta: 0:00:27  Lr: 0.001875  Loss: -0.9037  Acc@1: 81.2500 (82.2971)  Acc@5: 100.0000 (96.6801)  time: 0.3484  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3680/3750]  eta: 0:00:24  Lr: 0.001875  Loss: -1.2023  Acc@1: 81.2500 (82.3061)  Acc@5: 100.0000 (96.6840)  time: 0.3475  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [3690/3750]  eta: 0:00:20  Lr: 0.001875  Loss: -1.0025  Acc@1: 81.2500 (82.3015)  Acc@5: 100.0000 (96.6811)  time: 0.3474  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [3700/3750]  eta: 0:00:17  Lr: 0.001875  Loss: -1.2791  Acc@1: 81.2500 (82.3122)  Acc@5: 100.0000 (96.6867)  time: 0.3477  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [3710/3750]  eta: 0:00:13  Lr: 0.001875  Loss: -1.0971  Acc@1: 87.5000 (82.3245)  Acc@5: 100.0000 (96.6855)  time: 0.3481  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [3720/3750]  eta: 0:00:10  Lr: 0.001875  Loss: -1.1591  Acc@1: 87.5000 (82.3300)  Acc@5: 100.0000 (96.6911)  time: 0.3485  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [3730/3750]  eta: 0:00:06  Lr: 0.001875  Loss: -1.1225  Acc@1: 87.5000 (82.3506)  Acc@5: 100.0000 (96.6949)  time: 0.3492  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [3740/3750]  eta: 0:00:03  Lr: 0.001875  Loss: -0.6843  Acc@1: 87.5000 (82.3593)  Acc@5: 100.0000 (96.6987)  time: 0.3497  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [3749/3750]  eta: 0:00:00  Lr: 0.001875  Loss: -0.6912  Acc@1: 87.5000 (82.3583)  Acc@5: 100.0000 (96.7000)  time: 0.3500  data: 0.0014  max mem: 2500
Train: Epoch[3/5] Total time: 0:21:51 (0.3496 s / it)
{0: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 1: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 2: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 3: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 4: {0: 0, 1: 180000, 2: 0, 3: 0, 4: 0}, 5: {0: 0, 1: 180000, 2: 0, 3: 0, 4: 0}, 6: {0: 0, 1: 180000, 2: 0, 3: 0, 4: 0}, 7: {0: 0, 1: 180000, 2: 0, 3: 0, 4: 0}, 8: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 9: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 10: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 11: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 12: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 13: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 14: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 15: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 16: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 17: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 18: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 19: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}}
Averaged stats: Lr: 0.001875  Loss: -0.6912  Acc@1: 87.5000 (82.3583)  Acc@5: 100.0000 (96.7000)
Train: Epoch[4/5]  [   0/3750]  eta: 0:46:19  Lr: 0.001875  Loss: -0.6297  Acc@1: 81.2500 (81.2500)  Acc@5: 93.7500 (93.7500)  time: 0.7412  data: 0.3945  max mem: 2500
Train: Epoch[4/5]  [  10/3750]  eta: 0:24:03  Lr: 0.001875  Loss: -1.1555  Acc@1: 81.2500 (77.2727)  Acc@5: 100.0000 (97.1591)  time: 0.3860  data: 0.0364  max mem: 2500
Train: Epoch[4/5]  [  20/3750]  eta: 0:23:00  Lr: 0.001875  Loss: -0.7530  Acc@1: 81.2500 (78.8690)  Acc@5: 100.0000 (96.1310)  time: 0.3514  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [  30/3750]  eta: 0:22:31  Lr: 0.001875  Loss: -0.8301  Acc@1: 81.2500 (80.8468)  Acc@5: 100.0000 (96.9758)  time: 0.3509  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [  40/3750]  eta: 0:22:16  Lr: 0.001875  Loss: -0.6271  Acc@1: 81.2500 (80.9451)  Acc@5: 100.0000 (97.4085)  time: 0.3498  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [  50/3750]  eta: 0:22:06  Lr: 0.001875  Loss: -1.2431  Acc@1: 81.2500 (80.3922)  Acc@5: 100.0000 (97.1814)  time: 0.3509  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [  60/3750]  eta: 0:21:56  Lr: 0.001875  Loss: -0.9459  Acc@1: 81.2500 (80.9426)  Acc@5: 100.0000 (97.3361)  time: 0.3502  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [  70/3750]  eta: 0:21:49  Lr: 0.001875  Loss: -1.3219  Acc@1: 81.2500 (81.1620)  Acc@5: 100.0000 (97.3592)  time: 0.3491  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [  80/3750]  eta: 0:21:42  Lr: 0.001875  Loss: -1.0516  Acc@1: 81.2500 (81.4815)  Acc@5: 100.0000 (97.4537)  time: 0.3487  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [  90/3750]  eta: 0:21:35  Lr: 0.001875  Loss: -1.3521  Acc@1: 81.2500 (81.4560)  Acc@5: 100.0000 (97.3214)  time: 0.3478  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 100/3750]  eta: 0:21:30  Lr: 0.001875  Loss: -1.3712  Acc@1: 81.2500 (81.8069)  Acc@5: 100.0000 (97.4010)  time: 0.3481  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [ 110/3750]  eta: 0:21:25  Lr: 0.001875  Loss: -1.2811  Acc@1: 81.2500 (81.8131)  Acc@5: 100.0000 (97.4099)  time: 0.3486  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [ 120/3750]  eta: 0:21:20  Lr: 0.001875  Loss: -0.4221  Acc@1: 81.2500 (81.9731)  Acc@5: 100.0000 (97.3657)  time: 0.3486  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [ 130/3750]  eta: 0:21:16  Lr: 0.001875  Loss: -1.1100  Acc@1: 87.5000 (82.2519)  Acc@5: 100.0000 (97.3282)  time: 0.3493  data: 0.0013  max mem: 2500
Train: Epoch[4/5]  [ 140/3750]  eta: 0:21:12  Lr: 0.001875  Loss: -1.4056  Acc@1: 87.5000 (82.4025)  Acc@5: 100.0000 (97.3404)  time: 0.3517  data: 0.0017  max mem: 2500
Train: Epoch[4/5]  [ 150/3750]  eta: 0:21:08  Lr: 0.001875  Loss: -1.1365  Acc@1: 87.5000 (82.5745)  Acc@5: 100.0000 (97.3096)  time: 0.3514  data: 0.0009  max mem: 2500
Train: Epoch[4/5]  [ 160/3750]  eta: 0:21:04  Lr: 0.001875  Loss: -0.9282  Acc@1: 81.2500 (82.3758)  Acc@5: 100.0000 (97.2826)  time: 0.3492  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [ 170/3750]  eta: 0:20:59  Lr: 0.001875  Loss: -1.0640  Acc@1: 81.2500 (82.2368)  Acc@5: 100.0000 (97.2588)  time: 0.3488  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [ 180/3750]  eta: 0:20:56  Lr: 0.001875  Loss: -1.2095  Acc@1: 81.2500 (82.1478)  Acc@5: 100.0000 (97.2030)  time: 0.3497  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [ 190/3750]  eta: 0:20:52  Lr: 0.001875  Loss: -0.8651  Acc@1: 87.5000 (82.1335)  Acc@5: 100.0000 (97.2186)  time: 0.3497  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [ 200/3750]  eta: 0:20:48  Lr: 0.001875  Loss: -1.0919  Acc@1: 87.5000 (82.4627)  Acc@5: 100.0000 (97.2015)  time: 0.3490  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [ 210/3750]  eta: 0:20:44  Lr: 0.001875  Loss: -0.5133  Acc@1: 87.5000 (82.5237)  Acc@5: 100.0000 (97.2156)  time: 0.3489  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [ 220/3750]  eta: 0:20:40  Lr: 0.001875  Loss: -0.6599  Acc@1: 87.5000 (82.7206)  Acc@5: 100.0000 (97.2285)  time: 0.3485  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [ 230/3750]  eta: 0:20:36  Lr: 0.001875  Loss: -1.2030  Acc@1: 87.5000 (82.7110)  Acc@5: 100.0000 (97.1861)  time: 0.3486  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [ 240/3750]  eta: 0:20:32  Lr: 0.001875  Loss: -1.1947  Acc@1: 81.2500 (82.7282)  Acc@5: 100.0000 (97.2251)  time: 0.3487  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 250/3750]  eta: 0:20:28  Lr: 0.001875  Loss: -0.9339  Acc@1: 87.5000 (82.8685)  Acc@5: 100.0000 (97.2361)  time: 0.3495  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 260/3750]  eta: 0:20:25  Lr: 0.001875  Loss: -0.8314  Acc@1: 87.5000 (82.8065)  Acc@5: 100.0000 (97.1743)  time: 0.3501  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 270/3750]  eta: 0:20:21  Lr: 0.001875  Loss: -0.4772  Acc@1: 81.2500 (82.7030)  Acc@5: 93.7500 (97.1402)  time: 0.3500  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [ 280/3750]  eta: 0:20:17  Lr: 0.001875  Loss: -1.0889  Acc@1: 81.2500 (82.7847)  Acc@5: 100.0000 (97.1308)  time: 0.3494  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [ 290/3750]  eta: 0:20:14  Lr: 0.001875  Loss: -1.2169  Acc@1: 81.2500 (82.6460)  Acc@5: 93.7500 (97.0361)  time: 0.3504  data: 0.0013  max mem: 2500
Train: Epoch[4/5]  [ 300/3750]  eta: 0:20:10  Lr: 0.001875  Loss: -1.1073  Acc@1: 81.2500 (82.8073)  Acc@5: 93.7500 (97.0307)  time: 0.3504  data: 0.0012  max mem: 2500
Train: Epoch[4/5]  [ 310/3750]  eta: 0:20:06  Lr: 0.001875  Loss: -0.8248  Acc@1: 87.5000 (82.7974)  Acc@5: 100.0000 (97.0257)  time: 0.3487  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [ 320/3750]  eta: 0:20:02  Lr: 0.001875  Loss: -1.2005  Acc@1: 81.2500 (82.7687)  Acc@5: 100.0000 (97.0405)  time: 0.3484  data: 0.0009  max mem: 2500
Train: Epoch[4/5]  [ 330/3750]  eta: 0:19:59  Lr: 0.001875  Loss: -1.1469  Acc@1: 81.2500 (82.7983)  Acc@5: 100.0000 (97.0733)  time: 0.3489  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [ 340/3750]  eta: 0:19:55  Lr: 0.001875  Loss: -0.9802  Acc@1: 81.2500 (82.7896)  Acc@5: 100.0000 (97.0491)  time: 0.3491  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [ 350/3750]  eta: 0:19:51  Lr: 0.001875  Loss: -0.6788  Acc@1: 81.2500 (82.7101)  Acc@5: 100.0000 (97.0620)  time: 0.3483  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [ 360/3750]  eta: 0:19:48  Lr: 0.001875  Loss: -1.2614  Acc@1: 81.2500 (82.7043)  Acc@5: 100.0000 (97.0914)  time: 0.3512  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [ 370/3750]  eta: 0:19:45  Lr: 0.001875  Loss: -0.9979  Acc@1: 87.5000 (82.7999)  Acc@5: 100.0000 (97.0687)  time: 0.3517  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [ 380/3750]  eta: 0:19:41  Lr: 0.001875  Loss: -1.0175  Acc@1: 87.5000 (82.8740)  Acc@5: 100.0000 (97.0965)  time: 0.3497  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [ 390/3750]  eta: 0:19:37  Lr: 0.001875  Loss: -0.8324  Acc@1: 81.2500 (82.7526)  Acc@5: 100.0000 (97.0748)  time: 0.3484  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [ 400/3750]  eta: 0:19:33  Lr: 0.001875  Loss: -0.9901  Acc@1: 81.2500 (82.8398)  Acc@5: 93.7500 (97.0387)  time: 0.3474  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 410/3750]  eta: 0:19:30  Lr: 0.001875  Loss: -0.5958  Acc@1: 87.5000 (82.8163)  Acc@5: 100.0000 (97.0803)  time: 0.3487  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [ 420/3750]  eta: 0:19:26  Lr: 0.001875  Loss: -1.1245  Acc@1: 81.2500 (82.8385)  Acc@5: 100.0000 (97.1051)  time: 0.3494  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [ 430/3750]  eta: 0:19:23  Lr: 0.001875  Loss: -0.8551  Acc@1: 87.5000 (82.9321)  Acc@5: 100.0000 (97.0708)  time: 0.3493  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [ 440/3750]  eta: 0:19:19  Lr: 0.001875  Loss: -1.2411  Acc@1: 87.5000 (83.0357)  Acc@5: 100.0000 (97.0805)  time: 0.3500  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [ 450/3750]  eta: 0:19:16  Lr: 0.001875  Loss: -1.1728  Acc@1: 81.2500 (82.9268)  Acc@5: 93.7500 (97.0344)  time: 0.3504  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [ 460/3750]  eta: 0:19:12  Lr: 0.001875  Loss: -0.7317  Acc@1: 81.2500 (82.8498)  Acc@5: 93.7500 (97.0580)  time: 0.3500  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [ 470/3750]  eta: 0:19:08  Lr: 0.001875  Loss: -1.0958  Acc@1: 81.2500 (82.8556)  Acc@5: 100.0000 (97.0674)  time: 0.3488  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 480/3750]  eta: 0:19:05  Lr: 0.001875  Loss: -1.2764  Acc@1: 81.2500 (82.8482)  Acc@5: 100.0000 (97.0634)  time: 0.3479  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 490/3750]  eta: 0:19:01  Lr: 0.001875  Loss: -1.1584  Acc@1: 81.2500 (82.8666)  Acc@5: 93.7500 (97.0341)  time: 0.3485  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [ 500/3750]  eta: 0:18:58  Lr: 0.001875  Loss: -0.9803  Acc@1: 81.2500 (82.7969)  Acc@5: 93.7500 (96.9686)  time: 0.3480  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [ 510/3750]  eta: 0:18:54  Lr: 0.001875  Loss: -0.7650  Acc@1: 87.5000 (82.9623)  Acc@5: 93.7500 (96.9912)  time: 0.3481  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [ 520/3750]  eta: 0:18:51  Lr: 0.001875  Loss: -1.2515  Acc@1: 87.5000 (82.8455)  Acc@5: 100.0000 (96.9890)  time: 0.3501  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [ 530/3750]  eta: 0:18:47  Lr: 0.001875  Loss: -1.1144  Acc@1: 81.2500 (82.7095)  Acc@5: 100.0000 (97.0221)  time: 0.3492  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [ 540/3750]  eta: 0:18:43  Lr: 0.001875  Loss: -1.0641  Acc@1: 81.2500 (82.6479)  Acc@5: 100.0000 (97.0079)  time: 0.3473  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 550/3750]  eta: 0:18:40  Lr: 0.001875  Loss: -1.0837  Acc@1: 81.2500 (82.6906)  Acc@5: 100.0000 (97.0281)  time: 0.3477  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 560/3750]  eta: 0:18:36  Lr: 0.001875  Loss: -0.3784  Acc@1: 87.5000 (82.6649)  Acc@5: 100.0000 (97.0143)  time: 0.3480  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 570/3750]  eta: 0:18:32  Lr: 0.001875  Loss: -0.6268  Acc@1: 81.2500 (82.6182)  Acc@5: 100.0000 (97.0337)  time: 0.3482  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [ 580/3750]  eta: 0:18:29  Lr: 0.001875  Loss: -1.4088  Acc@1: 81.2500 (82.6700)  Acc@5: 100.0000 (97.0633)  time: 0.3495  data: 0.0013  max mem: 2500
Train: Epoch[4/5]  [ 590/3750]  eta: 0:18:25  Lr: 0.001875  Loss: -1.0871  Acc@1: 81.2500 (82.6882)  Acc@5: 100.0000 (97.1024)  time: 0.3490  data: 0.0013  max mem: 2500
Train: Epoch[4/5]  [ 600/3750]  eta: 0:18:22  Lr: 0.001875  Loss: -1.2462  Acc@1: 87.5000 (82.7683)  Acc@5: 100.0000 (97.1194)  time: 0.3481  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [ 610/3750]  eta: 0:18:18  Lr: 0.001875  Loss: -1.1376  Acc@1: 81.2500 (82.6718)  Acc@5: 100.0000 (97.1358)  time: 0.3491  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [ 620/3750]  eta: 0:18:15  Lr: 0.001875  Loss: -0.9008  Acc@1: 81.2500 (82.6490)  Acc@5: 100.0000 (97.1417)  time: 0.3483  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [ 630/3750]  eta: 0:18:11  Lr: 0.001875  Loss: -0.9967  Acc@1: 81.2500 (82.6862)  Acc@5: 100.0000 (97.1474)  time: 0.3471  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 640/3750]  eta: 0:18:07  Lr: 0.001875  Loss: -1.2422  Acc@1: 81.2500 (82.6833)  Acc@5: 100.0000 (97.1821)  time: 0.3480  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [ 650/3750]  eta: 0:18:04  Lr: 0.001875  Loss: -0.5572  Acc@1: 81.2500 (82.6901)  Acc@5: 100.0000 (97.1966)  time: 0.3489  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [ 660/3750]  eta: 0:18:00  Lr: 0.001875  Loss: -1.4793  Acc@1: 81.2500 (82.7061)  Acc@5: 100.0000 (97.1918)  time: 0.3485  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [ 670/3750]  eta: 0:17:57  Lr: 0.001875  Loss: -0.9004  Acc@1: 81.2500 (82.6937)  Acc@5: 93.7500 (97.1777)  time: 0.3480  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [ 680/3750]  eta: 0:17:53  Lr: 0.001875  Loss: -1.0057  Acc@1: 81.2500 (82.6083)  Acc@5: 93.7500 (97.1457)  time: 0.3473  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 690/3750]  eta: 0:17:49  Lr: 0.001875  Loss: -0.7803  Acc@1: 75.0000 (82.5525)  Acc@5: 100.0000 (97.1328)  time: 0.3473  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 700/3750]  eta: 0:17:46  Lr: 0.001875  Loss: -0.9950  Acc@1: 75.0000 (82.5428)  Acc@5: 93.7500 (97.0934)  time: 0.3468  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [ 710/3750]  eta: 0:17:42  Lr: 0.001875  Loss: -1.1823  Acc@1: 81.2500 (82.4982)  Acc@5: 93.7500 (97.0904)  time: 0.3477  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [ 720/3750]  eta: 0:17:39  Lr: 0.001875  Loss: -1.1634  Acc@1: 81.2500 (82.5156)  Acc@5: 100.0000 (97.1047)  time: 0.3482  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [ 730/3750]  eta: 0:17:35  Lr: 0.001875  Loss: -0.8850  Acc@1: 81.2500 (82.5154)  Acc@5: 100.0000 (97.0930)  time: 0.3473  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [ 740/3750]  eta: 0:17:32  Lr: 0.001875  Loss: -1.3686  Acc@1: 87.5000 (82.5405)  Acc@5: 100.0000 (97.0901)  time: 0.3476  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [ 750/3750]  eta: 0:17:28  Lr: 0.001875  Loss: -0.5746  Acc@1: 81.2500 (82.4900)  Acc@5: 93.7500 (97.0789)  time: 0.3473  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [ 760/3750]  eta: 0:17:24  Lr: 0.001875  Loss: -1.3148  Acc@1: 81.2500 (82.4573)  Acc@5: 93.7500 (97.0762)  time: 0.3482  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [ 770/3750]  eta: 0:17:21  Lr: 0.001875  Loss: -1.0710  Acc@1: 81.2500 (82.4660)  Acc@5: 100.0000 (97.0898)  time: 0.3486  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [ 780/3750]  eta: 0:17:17  Lr: 0.001875  Loss: -1.1851  Acc@1: 81.2500 (82.4664)  Acc@5: 100.0000 (97.1111)  time: 0.3478  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [ 790/3750]  eta: 0:17:14  Lr: 0.001875  Loss: -0.8355  Acc@1: 81.2500 (82.4905)  Acc@5: 100.0000 (97.1081)  time: 0.3483  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [ 800/3750]  eta: 0:17:10  Lr: 0.001875  Loss: -1.1702  Acc@1: 81.2500 (82.5062)  Acc@5: 100.0000 (97.1052)  time: 0.3494  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [ 810/3750]  eta: 0:17:07  Lr: 0.001875  Loss: -1.1099  Acc@1: 81.2500 (82.4753)  Acc@5: 100.0000 (97.1100)  time: 0.3493  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [ 820/3750]  eta: 0:17:03  Lr: 0.001875  Loss: -1.2460  Acc@1: 81.2500 (82.4833)  Acc@5: 100.0000 (97.1148)  time: 0.3506  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [ 830/3750]  eta: 0:17:00  Lr: 0.001875  Loss: -1.2705  Acc@1: 81.2500 (82.4759)  Acc@5: 100.0000 (97.1270)  time: 0.3512  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [ 840/3750]  eta: 0:16:56  Lr: 0.001875  Loss: -0.8842  Acc@1: 81.2500 (82.4316)  Acc@5: 100.0000 (97.1165)  time: 0.3483  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 850/3750]  eta: 0:16:53  Lr: 0.001875  Loss: -0.9497  Acc@1: 81.2500 (82.4104)  Acc@5: 100.0000 (97.1137)  time: 0.3473  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 860/3750]  eta: 0:16:49  Lr: 0.001875  Loss: -1.1570  Acc@1: 81.2500 (82.4187)  Acc@5: 100.0000 (97.0891)  time: 0.3480  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 870/3750]  eta: 0:16:46  Lr: 0.001875  Loss: -1.1584  Acc@1: 87.5000 (82.4842)  Acc@5: 100.0000 (97.0867)  time: 0.3476  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 880/3750]  eta: 0:16:42  Lr: 0.001875  Loss: -0.9902  Acc@1: 87.5000 (82.4702)  Acc@5: 100.0000 (97.0843)  time: 0.3481  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [ 890/3750]  eta: 0:16:39  Lr: 0.001875  Loss: -0.8182  Acc@1: 81.2500 (82.4776)  Acc@5: 100.0000 (97.0819)  time: 0.3499  data: 0.0012  max mem: 2500
Train: Epoch[4/5]  [ 900/3750]  eta: 0:16:35  Lr: 0.001875  Loss: -0.8747  Acc@1: 87.5000 (82.5819)  Acc@5: 100.0000 (97.1074)  time: 0.3492  data: 0.0012  max mem: 2500
Train: Epoch[4/5]  [ 910/3750]  eta: 0:16:32  Lr: 0.001875  Loss: -1.0676  Acc@1: 87.5000 (82.5672)  Acc@5: 100.0000 (97.1117)  time: 0.3501  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [ 920/3750]  eta: 0:16:28  Lr: 0.001875  Loss: -1.3399  Acc@1: 81.2500 (82.5461)  Acc@5: 93.7500 (97.0820)  time: 0.3511  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [ 930/3750]  eta: 0:16:25  Lr: 0.001875  Loss: -0.8759  Acc@1: 81.2500 (82.5658)  Acc@5: 93.7500 (97.0730)  time: 0.3496  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [ 940/3750]  eta: 0:16:21  Lr: 0.001875  Loss: -0.6013  Acc@1: 87.5000 (82.5518)  Acc@5: 93.7500 (97.0510)  time: 0.3490  data: 0.0011  max mem: 2500
Train: Epoch[4/5]  [ 950/3750]  eta: 0:16:18  Lr: 0.001875  Loss: -1.1862  Acc@1: 87.5000 (82.5447)  Acc@5: 100.0000 (97.0557)  time: 0.3488  data: 0.0009  max mem: 2500
Train: Epoch[4/5]  [ 960/3750]  eta: 0:16:14  Lr: 0.001875  Loss: -0.7621  Acc@1: 87.5000 (82.5637)  Acc@5: 100.0000 (97.0604)  time: 0.3504  data: 0.0018  max mem: 2500
Train: Epoch[4/5]  [ 970/3750]  eta: 0:16:11  Lr: 0.001875  Loss: -1.2176  Acc@1: 87.5000 (82.6017)  Acc@5: 100.0000 (97.0778)  time: 0.3511  data: 0.0020  max mem: 2500
Train: Epoch[4/5]  [ 980/3750]  eta: 0:16:07  Lr: 0.001875  Loss: -1.1734  Acc@1: 81.2500 (82.6070)  Acc@5: 100.0000 (97.0693)  time: 0.3499  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [ 990/3750]  eta: 0:16:04  Lr: 0.001875  Loss: -0.9625  Acc@1: 81.2500 (82.5744)  Acc@5: 100.0000 (97.0737)  time: 0.3511  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [1000/3750]  eta: 0:16:01  Lr: 0.001875  Loss: -0.9624  Acc@1: 81.2500 (82.5674)  Acc@5: 100.0000 (97.0904)  time: 0.3514  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [1010/3750]  eta: 0:15:57  Lr: 0.001875  Loss: -1.3606  Acc@1: 81.2500 (82.5482)  Acc@5: 100.0000 (97.1006)  time: 0.3497  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [1020/3750]  eta: 0:15:54  Lr: 0.001875  Loss: -1.0584  Acc@1: 81.2500 (82.5906)  Acc@5: 100.0000 (97.0923)  time: 0.3486  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1030/3750]  eta: 0:15:50  Lr: 0.001875  Loss: -0.7411  Acc@1: 87.5000 (82.5958)  Acc@5: 100.0000 (97.1084)  time: 0.3482  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1040/3750]  eta: 0:15:46  Lr: 0.001875  Loss: -1.3283  Acc@1: 81.2500 (82.5648)  Acc@5: 100.0000 (97.1122)  time: 0.3481  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1050/3750]  eta: 0:15:43  Lr: 0.001875  Loss: -1.2572  Acc@1: 87.5000 (82.5999)  Acc@5: 100.0000 (97.1039)  time: 0.3484  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1060/3750]  eta: 0:15:39  Lr: 0.001875  Loss: -0.6889  Acc@1: 87.5000 (82.6461)  Acc@5: 100.0000 (97.1136)  time: 0.3496  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [1070/3750]  eta: 0:15:36  Lr: 0.001875  Loss: -1.0251  Acc@1: 87.5000 (82.6856)  Acc@5: 100.0000 (97.1289)  time: 0.3493  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [1080/3750]  eta: 0:15:32  Lr: 0.001875  Loss: -1.1209  Acc@1: 87.5000 (82.6781)  Acc@5: 100.0000 (97.1438)  time: 0.3484  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [1090/3750]  eta: 0:15:29  Lr: 0.001875  Loss: -0.9596  Acc@1: 81.2500 (82.6650)  Acc@5: 100.0000 (97.1357)  time: 0.3499  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [1100/3750]  eta: 0:15:25  Lr: 0.001875  Loss: -0.7658  Acc@1: 75.0000 (82.6067)  Acc@5: 93.7500 (97.1333)  time: 0.3506  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [1110/3750]  eta: 0:15:22  Lr: 0.001875  Loss: -1.2422  Acc@1: 81.2500 (82.6058)  Acc@5: 93.7500 (97.1253)  time: 0.3491  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [1120/3750]  eta: 0:15:18  Lr: 0.001875  Loss: -0.5481  Acc@1: 81.2500 (82.5825)  Acc@5: 93.7500 (97.1120)  time: 0.3483  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [1130/3750]  eta: 0:15:15  Lr: 0.001875  Loss: -1.2666  Acc@1: 87.5000 (82.6260)  Acc@5: 100.0000 (97.1154)  time: 0.3495  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [1140/3750]  eta: 0:15:12  Lr: 0.001875  Loss: -1.0126  Acc@1: 87.5000 (82.6249)  Acc@5: 100.0000 (97.1242)  time: 0.3507  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [1150/3750]  eta: 0:15:08  Lr: 0.001875  Loss: -1.1653  Acc@1: 81.2500 (82.6347)  Acc@5: 100.0000 (97.1329)  time: 0.3499  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1160/3750]  eta: 0:15:05  Lr: 0.001875  Loss: -1.3864  Acc@1: 81.2500 (82.6550)  Acc@5: 100.0000 (97.1361)  time: 0.3512  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [1170/3750]  eta: 0:15:01  Lr: 0.001875  Loss: -1.1816  Acc@1: 87.5000 (82.6751)  Acc@5: 100.0000 (97.1552)  time: 0.3506  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [1180/3750]  eta: 0:14:58  Lr: 0.001875  Loss: -1.3192  Acc@1: 87.5000 (82.6736)  Acc@5: 100.0000 (97.1581)  time: 0.3480  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1190/3750]  eta: 0:14:54  Lr: 0.001875  Loss: -0.8791  Acc@1: 81.2500 (82.6669)  Acc@5: 100.0000 (97.1662)  time: 0.3486  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [1200/3750]  eta: 0:14:51  Lr: 0.001875  Loss: -1.4045  Acc@1: 81.2500 (82.6603)  Acc@5: 100.0000 (97.1690)  time: 0.3485  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [1210/3750]  eta: 0:14:47  Lr: 0.001875  Loss: -0.7216  Acc@1: 87.5000 (82.6951)  Acc@5: 100.0000 (97.1666)  time: 0.3497  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [1220/3750]  eta: 0:14:44  Lr: 0.001875  Loss: -0.9537  Acc@1: 87.5000 (82.6986)  Acc@5: 100.0000 (97.1693)  time: 0.3494  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [1230/3750]  eta: 0:14:40  Lr: 0.001875  Loss: -0.9147  Acc@1: 81.2500 (82.6615)  Acc@5: 100.0000 (97.1517)  time: 0.3477  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [1240/3750]  eta: 0:14:37  Lr: 0.001875  Loss: -0.7720  Acc@1: 81.2500 (82.6652)  Acc@5: 100.0000 (97.1595)  time: 0.3499  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [1250/3750]  eta: 0:14:33  Lr: 0.001875  Loss: -0.7092  Acc@1: 81.2500 (82.6589)  Acc@5: 100.0000 (97.1573)  time: 0.3502  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [1260/3750]  eta: 0:14:30  Lr: 0.001875  Loss: -1.3752  Acc@1: 87.5000 (82.7220)  Acc@5: 100.0000 (97.1749)  time: 0.3486  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [1270/3750]  eta: 0:14:26  Lr: 0.001875  Loss: -1.3809  Acc@1: 87.5000 (82.7105)  Acc@5: 100.0000 (97.1627)  time: 0.3488  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [1280/3750]  eta: 0:14:23  Lr: 0.001875  Loss: -0.6342  Acc@1: 81.2500 (82.7088)  Acc@5: 100.0000 (97.1604)  time: 0.3489  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [1290/3750]  eta: 0:14:19  Lr: 0.001875  Loss: -1.1977  Acc@1: 87.5000 (82.7314)  Acc@5: 93.7500 (97.1485)  time: 0.3490  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [1300/3750]  eta: 0:14:16  Lr: 0.001875  Loss: -0.8012  Acc@1: 87.5000 (82.7344)  Acc@5: 100.0000 (97.1608)  time: 0.3494  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [1310/3750]  eta: 0:14:12  Lr: 0.001875  Loss: -0.6266  Acc@1: 81.2500 (82.7374)  Acc@5: 100.0000 (97.1634)  time: 0.3510  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [1320/3750]  eta: 0:14:09  Lr: 0.001875  Loss: -0.7575  Acc@1: 81.2500 (82.7403)  Acc@5: 100.0000 (97.1518)  time: 0.3496  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [1330/3750]  eta: 0:14:05  Lr: 0.001875  Loss: -0.7976  Acc@1: 87.5000 (82.7385)  Acc@5: 93.7500 (97.1403)  time: 0.3469  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1340/3750]  eta: 0:14:02  Lr: 0.001875  Loss: -1.2492  Acc@1: 87.5000 (82.7787)  Acc@5: 100.0000 (97.1616)  time: 0.3476  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [1350/3750]  eta: 0:13:58  Lr: 0.001875  Loss: -0.6069  Acc@1: 87.5000 (82.8090)  Acc@5: 100.0000 (97.1688)  time: 0.3482  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [1360/3750]  eta: 0:13:55  Lr: 0.001875  Loss: -0.9908  Acc@1: 87.5000 (82.8251)  Acc@5: 100.0000 (97.1666)  time: 0.3496  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [1370/3750]  eta: 0:13:51  Lr: 0.001875  Loss: -0.8560  Acc@1: 81.2500 (82.8228)  Acc@5: 100.0000 (97.1599)  time: 0.3505  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [1380/3750]  eta: 0:13:48  Lr: 0.001875  Loss: -1.0777  Acc@1: 81.2500 (82.8159)  Acc@5: 100.0000 (97.1624)  time: 0.3488  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [1390/3750]  eta: 0:13:44  Lr: 0.001875  Loss: -1.1760  Acc@1: 87.5000 (82.8226)  Acc@5: 100.0000 (97.1603)  time: 0.3474  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [1400/3750]  eta: 0:13:41  Lr: 0.001875  Loss: -1.0639  Acc@1: 81.2500 (82.7891)  Acc@5: 100.0000 (97.1583)  time: 0.3482  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [1410/3750]  eta: 0:13:37  Lr: 0.001875  Loss: -0.8786  Acc@1: 81.2500 (82.7915)  Acc@5: 93.7500 (97.1430)  time: 0.3495  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [1420/3750]  eta: 0:13:34  Lr: 0.001875  Loss: -0.9423  Acc@1: 81.2500 (82.7894)  Acc@5: 93.7500 (97.1411)  time: 0.3487  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [1430/3750]  eta: 0:13:30  Lr: 0.001875  Loss: -1.2167  Acc@1: 81.2500 (82.7524)  Acc@5: 100.0000 (97.1349)  time: 0.3484  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [1440/3750]  eta: 0:13:27  Lr: 0.001875  Loss: -1.2322  Acc@1: 81.2500 (82.7594)  Acc@5: 100.0000 (97.1331)  time: 0.3496  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [1450/3750]  eta: 0:13:23  Lr: 0.001875  Loss: -0.6376  Acc@1: 81.2500 (82.7705)  Acc@5: 100.0000 (97.1313)  time: 0.3491  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [1460/3750]  eta: 0:13:20  Lr: 0.001875  Loss: -0.9732  Acc@1: 81.2500 (82.7858)  Acc@5: 100.0000 (97.1253)  time: 0.3484  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [1470/3750]  eta: 0:13:16  Lr: 0.001875  Loss: -1.1889  Acc@1: 87.5000 (82.7923)  Acc@5: 100.0000 (97.1236)  time: 0.3491  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [1480/3750]  eta: 0:13:12  Lr: 0.001875  Loss: -0.9464  Acc@1: 81.2500 (82.7777)  Acc@5: 93.7500 (97.1134)  time: 0.3484  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [1490/3750]  eta: 0:13:09  Lr: 0.001875  Loss: -1.2692  Acc@1: 81.2500 (82.7842)  Acc@5: 93.7500 (97.1035)  time: 0.3466  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1500/3750]  eta: 0:13:05  Lr: 0.001875  Loss: -1.2775  Acc@1: 81.2500 (82.7781)  Acc@5: 100.0000 (97.1061)  time: 0.3466  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1510/3750]  eta: 0:13:02  Lr: 0.001875  Loss: -0.8915  Acc@1: 81.2500 (82.7680)  Acc@5: 100.0000 (97.1170)  time: 0.3472  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1520/3750]  eta: 0:12:58  Lr: 0.001875  Loss: -1.0172  Acc@1: 87.5000 (82.7704)  Acc@5: 100.0000 (97.1236)  time: 0.3480  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [1530/3750]  eta: 0:12:55  Lr: 0.001875  Loss: -1.1854  Acc@1: 87.5000 (82.8135)  Acc@5: 100.0000 (97.1301)  time: 0.3503  data: 0.0013  max mem: 2500
Train: Epoch[4/5]  [1540/3750]  eta: 0:12:51  Lr: 0.001875  Loss: -1.1105  Acc@1: 87.5000 (82.7993)  Acc@5: 100.0000 (97.1325)  time: 0.3495  data: 0.0014  max mem: 2500
Train: Epoch[4/5]  [1550/3750]  eta: 0:12:48  Lr: 0.001875  Loss: -0.8248  Acc@1: 81.2500 (82.8095)  Acc@5: 100.0000 (97.1430)  time: 0.3483  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [1560/3750]  eta: 0:12:44  Lr: 0.001875  Loss: -1.3755  Acc@1: 81.2500 (82.8035)  Acc@5: 100.0000 (97.1413)  time: 0.3495  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [1570/3750]  eta: 0:12:41  Lr: 0.001875  Loss: -0.4619  Acc@1: 81.2500 (82.7976)  Acc@5: 100.0000 (97.1515)  time: 0.3482  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [1580/3750]  eta: 0:12:37  Lr: 0.001875  Loss: -1.0491  Acc@1: 87.5000 (82.8115)  Acc@5: 100.0000 (97.1656)  time: 0.3475  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [1590/3750]  eta: 0:12:34  Lr: 0.001875  Loss: -0.7107  Acc@1: 81.2500 (82.8135)  Acc@5: 100.0000 (97.1716)  time: 0.3481  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [1600/3750]  eta: 0:12:30  Lr: 0.001875  Loss: -1.0667  Acc@1: 81.2500 (82.8271)  Acc@5: 100.0000 (97.1736)  time: 0.3485  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [1610/3750]  eta: 0:12:27  Lr: 0.001875  Loss: -1.0823  Acc@1: 81.2500 (82.8212)  Acc@5: 100.0000 (97.1679)  time: 0.3503  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [1620/3750]  eta: 0:12:23  Lr: 0.001875  Loss: -1.0886  Acc@1: 87.5000 (82.8462)  Acc@5: 100.0000 (97.1738)  time: 0.3494  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [1630/3750]  eta: 0:12:20  Lr: 0.001875  Loss: -1.2551  Acc@1: 87.5000 (82.8594)  Acc@5: 100.0000 (97.1681)  time: 0.3483  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [1640/3750]  eta: 0:12:16  Lr: 0.001875  Loss: -0.6592  Acc@1: 87.5000 (82.8573)  Acc@5: 100.0000 (97.1702)  time: 0.3475  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [1650/3750]  eta: 0:12:13  Lr: 0.001875  Loss: -1.3426  Acc@1: 81.2500 (82.8740)  Acc@5: 100.0000 (97.1835)  time: 0.3470  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [1660/3750]  eta: 0:12:09  Lr: 0.001875  Loss: -1.2175  Acc@1: 81.2500 (82.8831)  Acc@5: 100.0000 (97.1967)  time: 0.3484  data: 0.0011  max mem: 2500
Train: Epoch[4/5]  [1670/3750]  eta: 0:12:06  Lr: 0.001875  Loss: -0.6669  Acc@1: 81.2500 (82.8658)  Acc@5: 100.0000 (97.1836)  time: 0.3486  data: 0.0020  max mem: 2500
Train: Epoch[4/5]  [1680/3750]  eta: 0:12:02  Lr: 0.001875  Loss: -1.1751  Acc@1: 81.2500 (82.8785)  Acc@5: 93.7500 (97.1743)  time: 0.3477  data: 0.0015  max mem: 2500
Train: Epoch[4/5]  [1690/3750]  eta: 0:11:59  Lr: 0.001875  Loss: -0.8188  Acc@1: 81.2500 (82.8615)  Acc@5: 100.0000 (97.1873)  time: 0.3468  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [1700/3750]  eta: 0:11:55  Lr: 0.001875  Loss: -1.2551  Acc@1: 81.2500 (82.8593)  Acc@5: 100.0000 (97.1928)  time: 0.3480  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [1710/3750]  eta: 0:11:52  Lr: 0.001875  Loss: -0.7523  Acc@1: 81.2500 (82.8572)  Acc@5: 100.0000 (97.1764)  time: 0.3483  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [1720/3750]  eta: 0:11:48  Lr: 0.001875  Loss: -1.0138  Acc@1: 81.2500 (82.8515)  Acc@5: 100.0000 (97.1855)  time: 0.3473  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [1730/3750]  eta: 0:11:45  Lr: 0.001875  Loss: -0.8757  Acc@1: 81.2500 (82.8603)  Acc@5: 100.0000 (97.1873)  time: 0.3481  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [1740/3750]  eta: 0:11:41  Lr: 0.001875  Loss: -0.6974  Acc@1: 81.2500 (82.8331)  Acc@5: 100.0000 (97.1712)  time: 0.3497  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [1750/3750]  eta: 0:11:38  Lr: 0.001875  Loss: -0.9418  Acc@1: 81.2500 (82.8205)  Acc@5: 100.0000 (97.1730)  time: 0.3499  data: 0.0010  max mem: 2500
Train: Epoch[4/5]  [1760/3750]  eta: 0:11:34  Lr: 0.001875  Loss: -1.1986  Acc@1: 87.5000 (82.8507)  Acc@5: 100.0000 (97.1714)  time: 0.3496  data: 0.0010  max mem: 2500
Train: Epoch[4/5]  [1770/3750]  eta: 0:11:31  Lr: 0.001875  Loss: -1.2964  Acc@1: 87.5000 (82.8663)  Acc@5: 100.0000 (97.1732)  time: 0.3490  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [1780/3750]  eta: 0:11:27  Lr: 0.001875  Loss: -0.9658  Acc@1: 87.5000 (82.8537)  Acc@5: 100.0000 (97.1645)  time: 0.3481  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [1790/3750]  eta: 0:11:24  Lr: 0.001875  Loss: -1.1124  Acc@1: 75.0000 (82.8378)  Acc@5: 100.0000 (97.1699)  time: 0.3481  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [1800/3750]  eta: 0:11:20  Lr: 0.001875  Loss: -0.8676  Acc@1: 75.0000 (82.8082)  Acc@5: 93.7500 (97.1544)  time: 0.3488  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [1810/3750]  eta: 0:11:17  Lr: 0.001875  Loss: -0.6259  Acc@1: 81.2500 (82.8168)  Acc@5: 93.7500 (97.1563)  time: 0.3491  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [1820/3750]  eta: 0:11:13  Lr: 0.001875  Loss: -0.8583  Acc@1: 81.2500 (82.8219)  Acc@5: 100.0000 (97.1547)  time: 0.3485  data: 0.0009  max mem: 2500
Train: Epoch[4/5]  [1830/3750]  eta: 0:11:10  Lr: 0.001875  Loss: -0.7539  Acc@1: 81.2500 (82.8270)  Acc@5: 100.0000 (97.1532)  time: 0.3488  data: 0.0012  max mem: 2500
Train: Epoch[4/5]  [1840/3750]  eta: 0:11:06  Lr: 0.001875  Loss: -1.0182  Acc@1: 81.2500 (82.8218)  Acc@5: 93.7500 (97.1449)  time: 0.3491  data: 0.0009  max mem: 2500
Train: Epoch[4/5]  [1850/3750]  eta: 0:11:03  Lr: 0.001875  Loss: -0.6203  Acc@1: 81.2500 (82.8167)  Acc@5: 100.0000 (97.1468)  time: 0.3493  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [1860/3750]  eta: 0:10:59  Lr: 0.001875  Loss: -1.1625  Acc@1: 81.2500 (82.8117)  Acc@5: 100.0000 (97.1521)  time: 0.3491  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [1870/3750]  eta: 0:10:56  Lr: 0.001875  Loss: -1.1069  Acc@1: 81.2500 (82.8267)  Acc@5: 100.0000 (97.1506)  time: 0.3488  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [1880/3750]  eta: 0:10:52  Lr: 0.001875  Loss: -0.7748  Acc@1: 81.2500 (82.8117)  Acc@5: 100.0000 (97.1591)  time: 0.3484  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [1890/3750]  eta: 0:10:49  Lr: 0.001875  Loss: -0.9785  Acc@1: 81.2500 (82.8133)  Acc@5: 100.0000 (97.1609)  time: 0.3476  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1900/3750]  eta: 0:10:45  Lr: 0.001875  Loss: -1.0319  Acc@1: 81.2500 (82.8183)  Acc@5: 93.7500 (97.1561)  time: 0.3479  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [1910/3750]  eta: 0:10:42  Lr: 0.001875  Loss: -1.0805  Acc@1: 81.2500 (82.7904)  Acc@5: 100.0000 (97.1579)  time: 0.3476  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [1920/3750]  eta: 0:10:38  Lr: 0.001875  Loss: -1.0208  Acc@1: 81.2500 (82.7954)  Acc@5: 100.0000 (97.1499)  time: 0.3475  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1930/3750]  eta: 0:10:35  Lr: 0.001875  Loss: -0.5459  Acc@1: 87.5000 (82.8036)  Acc@5: 100.0000 (97.1582)  time: 0.3498  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [1940/3750]  eta: 0:10:31  Lr: 0.001875  Loss: -0.8552  Acc@1: 81.2500 (82.7698)  Acc@5: 100.0000 (97.1535)  time: 0.3501  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [1950/3750]  eta: 0:10:28  Lr: 0.001875  Loss: -0.8968  Acc@1: 81.2500 (82.7781)  Acc@5: 100.0000 (97.1585)  time: 0.3482  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [1960/3750]  eta: 0:10:24  Lr: 0.001875  Loss: -0.9337  Acc@1: 87.5000 (82.7990)  Acc@5: 100.0000 (97.1634)  time: 0.3480  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [1970/3750]  eta: 0:10:21  Lr: 0.001875  Loss: -0.6982  Acc@1: 81.2500 (82.7974)  Acc@5: 100.0000 (97.1683)  time: 0.3484  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1980/3750]  eta: 0:10:17  Lr: 0.001875  Loss: -1.2828  Acc@1: 87.5000 (82.8243)  Acc@5: 100.0000 (97.1700)  time: 0.3493  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [1990/3750]  eta: 0:10:14  Lr: 0.001875  Loss: -0.5992  Acc@1: 87.5000 (82.8572)  Acc@5: 100.0000 (97.1654)  time: 0.3503  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [2000/3750]  eta: 0:10:10  Lr: 0.001875  Loss: -1.0715  Acc@1: 87.5000 (82.8554)  Acc@5: 100.0000 (97.1639)  time: 0.3501  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [2010/3750]  eta: 0:10:07  Lr: 0.001875  Loss: -0.8267  Acc@1: 81.2500 (82.8537)  Acc@5: 100.0000 (97.1718)  time: 0.3489  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [2020/3750]  eta: 0:10:04  Lr: 0.001875  Loss: -0.8858  Acc@1: 81.2500 (82.8488)  Acc@5: 100.0000 (97.1765)  time: 0.3498  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [2030/3750]  eta: 0:10:00  Lr: 0.001875  Loss: -1.1786  Acc@1: 81.2500 (82.8502)  Acc@5: 100.0000 (97.1812)  time: 0.3496  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2040/3750]  eta: 0:09:57  Lr: 0.001875  Loss: -0.7975  Acc@1: 81.2500 (82.8454)  Acc@5: 100.0000 (97.1797)  time: 0.3484  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2050/3750]  eta: 0:09:53  Lr: 0.001875  Loss: -0.7952  Acc@1: 81.2500 (82.8407)  Acc@5: 100.0000 (97.1782)  time: 0.3488  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2060/3750]  eta: 0:09:50  Lr: 0.001875  Loss: -1.1440  Acc@1: 81.2500 (82.8269)  Acc@5: 93.7500 (97.1737)  time: 0.3493  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2070/3750]  eta: 0:09:46  Lr: 0.001875  Loss: -1.1523  Acc@1: 81.2500 (82.8314)  Acc@5: 100.0000 (97.1753)  time: 0.3494  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2080/3750]  eta: 0:09:43  Lr: 0.001875  Loss: -1.1624  Acc@1: 87.5000 (82.8418)  Acc@5: 100.0000 (97.1738)  time: 0.3492  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2090/3750]  eta: 0:09:39  Lr: 0.001875  Loss: -0.6042  Acc@1: 81.2500 (82.8372)  Acc@5: 93.7500 (97.1724)  time: 0.3495  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2100/3750]  eta: 0:09:36  Lr: 0.001875  Loss: -0.3119  Acc@1: 87.5000 (82.8445)  Acc@5: 93.7500 (97.1650)  time: 0.3495  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2110/3750]  eta: 0:09:32  Lr: 0.001875  Loss: -1.1407  Acc@1: 87.5000 (82.8754)  Acc@5: 100.0000 (97.1725)  time: 0.3491  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [2120/3750]  eta: 0:09:29  Lr: 0.001875  Loss: -1.2638  Acc@1: 87.5000 (82.8648)  Acc@5: 100.0000 (97.1770)  time: 0.3501  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [2130/3750]  eta: 0:09:25  Lr: 0.001875  Loss: -0.8330  Acc@1: 75.0000 (82.8338)  Acc@5: 100.0000 (97.1639)  time: 0.3509  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2140/3750]  eta: 0:09:22  Lr: 0.001875  Loss: -1.3469  Acc@1: 81.2500 (82.8468)  Acc@5: 93.7500 (97.1538)  time: 0.3510  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2150/3750]  eta: 0:09:18  Lr: 0.001875  Loss: -1.1260  Acc@1: 81.2500 (82.8307)  Acc@5: 100.0000 (97.1554)  time: 0.3508  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2160/3750]  eta: 0:09:15  Lr: 0.001875  Loss: -0.8964  Acc@1: 75.0000 (82.8089)  Acc@5: 100.0000 (97.1599)  time: 0.3489  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2170/3750]  eta: 0:09:11  Lr: 0.001875  Loss: -0.8766  Acc@1: 81.2500 (82.8247)  Acc@5: 100.0000 (97.1701)  time: 0.3487  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2180/3750]  eta: 0:09:08  Lr: 0.001875  Loss: -0.5554  Acc@1: 87.5000 (82.8318)  Acc@5: 100.0000 (97.1716)  time: 0.3500  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2190/3750]  eta: 0:09:04  Lr: 0.001875  Loss: -1.2148  Acc@1: 87.5000 (82.8303)  Acc@5: 100.0000 (97.1759)  time: 0.3499  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2200/3750]  eta: 0:09:01  Lr: 0.001875  Loss: -1.0348  Acc@1: 81.2500 (82.8231)  Acc@5: 100.0000 (97.1774)  time: 0.3498  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [2210/3750]  eta: 0:08:57  Lr: 0.001875  Loss: -0.8698  Acc@1: 87.5000 (82.8330)  Acc@5: 100.0000 (97.1845)  time: 0.3499  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [2220/3750]  eta: 0:08:54  Lr: 0.001875  Loss: -0.6528  Acc@1: 87.5000 (82.8428)  Acc@5: 100.0000 (97.1803)  time: 0.3508  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [2230/3750]  eta: 0:08:50  Lr: 0.001875  Loss: -1.2409  Acc@1: 81.2500 (82.8552)  Acc@5: 100.0000 (97.1762)  time: 0.3510  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [2240/3750]  eta: 0:08:47  Lr: 0.001875  Loss: -1.3587  Acc@1: 81.2500 (82.8481)  Acc@5: 100.0000 (97.1748)  time: 0.3498  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [2250/3750]  eta: 0:08:43  Lr: 0.001875  Loss: -1.2777  Acc@1: 81.2500 (82.8548)  Acc@5: 100.0000 (97.1846)  time: 0.3501  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [2260/3750]  eta: 0:08:40  Lr: 0.001875  Loss: -1.2505  Acc@1: 81.2500 (82.8560)  Acc@5: 100.0000 (97.1860)  time: 0.3497  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [2270/3750]  eta: 0:08:36  Lr: 0.001875  Loss: -0.9438  Acc@1: 81.2500 (82.8325)  Acc@5: 93.7500 (97.1736)  time: 0.3489  data: 0.0012  max mem: 2500
Train: Epoch[4/5]  [2280/3750]  eta: 0:08:33  Lr: 0.001875  Loss: -0.9563  Acc@1: 81.2500 (82.8420)  Acc@5: 93.7500 (97.1750)  time: 0.3493  data: 0.0012  max mem: 2500
Train: Epoch[4/5]  [2290/3750]  eta: 0:08:29  Lr: 0.001875  Loss: -0.9490  Acc@1: 81.2500 (82.8296)  Acc@5: 100.0000 (97.1710)  time: 0.3495  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2300/3750]  eta: 0:08:26  Lr: 0.001875  Loss: -1.0732  Acc@1: 81.2500 (82.8281)  Acc@5: 93.7500 (97.1670)  time: 0.3501  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2310/3750]  eta: 0:08:22  Lr: 0.001875  Loss: -1.1842  Acc@1: 81.2500 (82.8321)  Acc@5: 100.0000 (97.1657)  time: 0.3497  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [2320/3750]  eta: 0:08:19  Lr: 0.001875  Loss: -1.2040  Acc@1: 87.5000 (82.8495)  Acc@5: 100.0000 (97.1591)  time: 0.3478  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [2330/3750]  eta: 0:08:15  Lr: 0.001875  Loss: -0.6803  Acc@1: 81.2500 (82.8266)  Acc@5: 93.7500 (97.1579)  time: 0.3495  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2340/3750]  eta: 0:08:12  Lr: 0.001875  Loss: -1.0832  Acc@1: 81.2500 (82.8252)  Acc@5: 100.0000 (97.1593)  time: 0.3510  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [2350/3750]  eta: 0:08:08  Lr: 0.001875  Loss: -0.7432  Acc@1: 81.2500 (82.8211)  Acc@5: 100.0000 (97.1555)  time: 0.3496  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [2360/3750]  eta: 0:08:05  Lr: 0.001875  Loss: -0.6320  Acc@1: 87.5000 (82.8251)  Acc@5: 100.0000 (97.1569)  time: 0.3505  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [2370/3750]  eta: 0:08:01  Lr: 0.001875  Loss: -1.2981  Acc@1: 81.2500 (82.8184)  Acc@5: 100.0000 (97.1584)  time: 0.3501  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [2380/3750]  eta: 0:07:58  Lr: 0.001875  Loss: -1.1775  Acc@1: 87.5000 (82.8381)  Acc@5: 100.0000 (97.1572)  time: 0.3487  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2390/3750]  eta: 0:07:54  Lr: 0.001875  Loss: -0.6662  Acc@1: 87.5000 (82.8497)  Acc@5: 100.0000 (97.1560)  time: 0.3501  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2400/3750]  eta: 0:07:51  Lr: 0.001875  Loss: -1.2418  Acc@1: 81.2500 (82.8431)  Acc@5: 100.0000 (97.1548)  time: 0.3497  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2410/3750]  eta: 0:07:47  Lr: 0.001875  Loss: -1.0847  Acc@1: 81.2500 (82.8287)  Acc@5: 93.7500 (97.1407)  time: 0.3489  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [2420/3750]  eta: 0:07:44  Lr: 0.001875  Loss: -1.2304  Acc@1: 81.2500 (82.8299)  Acc@5: 93.7500 (97.1448)  time: 0.3485  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2430/3750]  eta: 0:07:40  Lr: 0.001875  Loss: -0.8218  Acc@1: 81.2500 (82.8260)  Acc@5: 100.0000 (97.1411)  time: 0.3480  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2440/3750]  eta: 0:07:37  Lr: 0.001875  Loss: -1.2117  Acc@1: 81.2500 (82.8400)  Acc@5: 100.0000 (97.1426)  time: 0.3489  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2450/3750]  eta: 0:07:33  Lr: 0.001875  Loss: -0.9534  Acc@1: 87.5000 (82.8437)  Acc@5: 100.0000 (97.1364)  time: 0.3481  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2460/3750]  eta: 0:07:30  Lr: 0.001875  Loss: -1.0291  Acc@1: 87.5000 (82.8627)  Acc@5: 100.0000 (97.1379)  time: 0.3479  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [2470/3750]  eta: 0:07:26  Lr: 0.001875  Loss: -1.1697  Acc@1: 87.5000 (82.8789)  Acc@5: 100.0000 (97.1444)  time: 0.3488  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [2480/3750]  eta: 0:07:23  Lr: 0.001875  Loss: -1.3494  Acc@1: 87.5000 (82.8925)  Acc@5: 100.0000 (97.1433)  time: 0.3495  data: 0.0016  max mem: 2500
Train: Epoch[4/5]  [2490/3750]  eta: 0:07:19  Lr: 0.001875  Loss: -1.0681  Acc@1: 87.5000 (82.8909)  Acc@5: 100.0000 (97.1472)  time: 0.3490  data: 0.0016  max mem: 2500
Train: Epoch[4/5]  [2500/3750]  eta: 0:07:16  Lr: 0.001875  Loss: -1.0702  Acc@1: 81.2500 (82.8818)  Acc@5: 100.0000 (97.1561)  time: 0.3488  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [2510/3750]  eta: 0:07:13  Lr: 0.001875  Loss: -1.4340  Acc@1: 81.2500 (82.8903)  Acc@5: 100.0000 (97.1575)  time: 0.3502  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [2520/3750]  eta: 0:07:09  Lr: 0.001875  Loss: -1.0038  Acc@1: 81.2500 (82.8763)  Acc@5: 100.0000 (97.1589)  time: 0.3491  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [2530/3750]  eta: 0:07:06  Lr: 0.001875  Loss: -1.1029  Acc@1: 81.2500 (82.8872)  Acc@5: 100.0000 (97.1627)  time: 0.3480  data: 0.0011  max mem: 2500
Train: Epoch[4/5]  [2540/3750]  eta: 0:07:02  Lr: 0.001875  Loss: -1.2171  Acc@1: 87.5000 (82.8857)  Acc@5: 100.0000 (97.1616)  time: 0.3482  data: 0.0009  max mem: 2500
Train: Epoch[4/5]  [2550/3750]  eta: 0:06:59  Lr: 0.001875  Loss: -0.9237  Acc@1: 81.2500 (82.8768)  Acc@5: 100.0000 (97.1629)  time: 0.3495  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [2560/3750]  eta: 0:06:55  Lr: 0.001875  Loss: -0.8279  Acc@1: 81.2500 (82.8607)  Acc@5: 100.0000 (97.1642)  time: 0.3498  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [2570/3750]  eta: 0:06:52  Lr: 0.001875  Loss: -1.1135  Acc@1: 81.2500 (82.8544)  Acc@5: 100.0000 (97.1631)  time: 0.3487  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [2580/3750]  eta: 0:06:48  Lr: 0.001875  Loss: -1.0766  Acc@1: 81.2500 (82.8579)  Acc@5: 100.0000 (97.1644)  time: 0.3493  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2590/3750]  eta: 0:06:45  Lr: 0.001875  Loss: -1.1546  Acc@1: 81.2500 (82.8445)  Acc@5: 93.7500 (97.1560)  time: 0.3494  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2600/3750]  eta: 0:06:41  Lr: 0.001875  Loss: -0.7239  Acc@1: 81.2500 (82.8479)  Acc@5: 100.0000 (97.1597)  time: 0.3476  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2610/3750]  eta: 0:06:38  Lr: 0.001875  Loss: -0.9386  Acc@1: 81.2500 (82.8370)  Acc@5: 100.0000 (97.1610)  time: 0.3463  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2620/3750]  eta: 0:06:34  Lr: 0.001875  Loss: -0.8818  Acc@1: 75.0000 (82.8000)  Acc@5: 93.7500 (97.1433)  time: 0.3474  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2630/3750]  eta: 0:06:31  Lr: 0.001875  Loss: -1.3571  Acc@1: 81.2500 (82.8107)  Acc@5: 93.7500 (97.1399)  time: 0.3485  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2640/3750]  eta: 0:06:27  Lr: 0.001875  Loss: -0.4673  Acc@1: 87.5000 (82.8143)  Acc@5: 93.7500 (97.1365)  time: 0.3491  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [2650/3750]  eta: 0:06:24  Lr: 0.001875  Loss: -0.8225  Acc@1: 81.2500 (82.8202)  Acc@5: 100.0000 (97.1402)  time: 0.3494  data: 0.0014  max mem: 2500
Train: Epoch[4/5]  [2660/3750]  eta: 0:06:20  Lr: 0.001875  Loss: -1.1685  Acc@1: 87.5000 (82.8424)  Acc@5: 100.0000 (97.1416)  time: 0.3498  data: 0.0014  max mem: 2500
Train: Epoch[4/5]  [2670/3750]  eta: 0:06:17  Lr: 0.001875  Loss: -1.0954  Acc@1: 87.5000 (82.8482)  Acc@5: 100.0000 (97.1476)  time: 0.3498  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [2680/3750]  eta: 0:06:13  Lr: 0.001875  Loss: -0.8705  Acc@1: 87.5000 (82.8655)  Acc@5: 100.0000 (97.1466)  time: 0.3493  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2690/3750]  eta: 0:06:10  Lr: 0.001875  Loss: -0.9457  Acc@1: 87.5000 (82.8758)  Acc@5: 100.0000 (97.1479)  time: 0.3504  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2700/3750]  eta: 0:06:06  Lr: 0.001875  Loss: -1.2434  Acc@1: 87.5000 (82.8952)  Acc@5: 100.0000 (97.1538)  time: 0.3495  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2710/3750]  eta: 0:06:03  Lr: 0.001875  Loss: -0.7362  Acc@1: 93.7500 (82.9191)  Acc@5: 100.0000 (97.1505)  time: 0.3482  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [2720/3750]  eta: 0:05:59  Lr: 0.001875  Loss: -0.6543  Acc@1: 87.5000 (82.8946)  Acc@5: 100.0000 (97.1495)  time: 0.3488  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [2730/3750]  eta: 0:05:56  Lr: 0.001875  Loss: -1.0769  Acc@1: 75.0000 (82.8749)  Acc@5: 100.0000 (97.1439)  time: 0.3491  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [2740/3750]  eta: 0:05:52  Lr: 0.001875  Loss: -0.9364  Acc@1: 81.2500 (82.8735)  Acc@5: 100.0000 (97.1452)  time: 0.3499  data: 0.0021  max mem: 2500
Train: Epoch[4/5]  [2750/3750]  eta: 0:05:49  Lr: 0.001875  Loss: -1.2771  Acc@1: 81.2500 (82.8403)  Acc@5: 100.0000 (97.1488)  time: 0.3503  data: 0.0021  max mem: 2500
Train: Epoch[4/5]  [2760/3750]  eta: 0:05:45  Lr: 0.001875  Loss: -1.1747  Acc@1: 81.2500 (82.8482)  Acc@5: 100.0000 (97.1478)  time: 0.3505  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [2770/3750]  eta: 0:05:42  Lr: 0.001875  Loss: -1.0416  Acc@1: 81.2500 (82.8492)  Acc@5: 100.0000 (97.1468)  time: 0.3499  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2780/3750]  eta: 0:05:38  Lr: 0.001875  Loss: -1.3168  Acc@1: 87.5000 (82.8591)  Acc@5: 100.0000 (97.1481)  time: 0.3491  data: 0.0012  max mem: 2500
Train: Epoch[4/5]  [2790/3750]  eta: 0:05:35  Lr: 0.001875  Loss: -1.2948  Acc@1: 87.5000 (82.8556)  Acc@5: 100.0000 (97.1493)  time: 0.3491  data: 0.0012  max mem: 2500
Train: Epoch[4/5]  [2800/3750]  eta: 0:05:31  Lr: 0.001875  Loss: -1.4939  Acc@1: 87.5000 (82.8789)  Acc@5: 100.0000 (97.1595)  time: 0.3483  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2810/3750]  eta: 0:05:28  Lr: 0.001875  Loss: -0.5750  Acc@1: 87.5000 (82.8842)  Acc@5: 100.0000 (97.1585)  time: 0.3475  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2820/3750]  eta: 0:05:24  Lr: 0.001875  Loss: -0.6756  Acc@1: 81.2500 (82.8828)  Acc@5: 100.0000 (97.1597)  time: 0.3485  data: 0.0013  max mem: 2500
Train: Epoch[4/5]  [2830/3750]  eta: 0:05:21  Lr: 0.001875  Loss: -0.7881  Acc@1: 81.2500 (82.8815)  Acc@5: 100.0000 (97.1609)  time: 0.3496  data: 0.0014  max mem: 2500
Train: Epoch[4/5]  [2840/3750]  eta: 0:05:17  Lr: 0.001875  Loss: -1.1225  Acc@1: 87.5000 (82.8889)  Acc@5: 100.0000 (97.1599)  time: 0.3482  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [2850/3750]  eta: 0:05:14  Lr: 0.001875  Loss: -0.9756  Acc@1: 87.5000 (82.8985)  Acc@5: 100.0000 (97.1567)  time: 0.3479  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [2860/3750]  eta: 0:05:10  Lr: 0.001875  Loss: -1.0308  Acc@1: 81.2500 (82.9037)  Acc@5: 100.0000 (97.1557)  time: 0.3487  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [2870/3750]  eta: 0:05:07  Lr: 0.001875  Loss: -0.8320  Acc@1: 81.2500 (82.8892)  Acc@5: 100.0000 (97.1569)  time: 0.3483  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [2880/3750]  eta: 0:05:03  Lr: 0.001875  Loss: -0.7133  Acc@1: 81.2500 (82.8944)  Acc@5: 100.0000 (97.1494)  time: 0.3480  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2890/3750]  eta: 0:05:00  Lr: 0.001875  Loss: -0.9998  Acc@1: 81.2500 (82.8909)  Acc@5: 100.0000 (97.1550)  time: 0.3479  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2900/3750]  eta: 0:04:56  Lr: 0.001875  Loss: -0.7849  Acc@1: 81.2500 (82.8831)  Acc@5: 100.0000 (97.1475)  time: 0.3489  data: 0.0015  max mem: 2500
Train: Epoch[4/5]  [2910/3750]  eta: 0:04:53  Lr: 0.001875  Loss: -1.4338  Acc@1: 81.2500 (82.8667)  Acc@5: 100.0000 (97.1509)  time: 0.3487  data: 0.0014  max mem: 2500
Train: Epoch[4/5]  [2920/3750]  eta: 0:04:49  Lr: 0.001875  Loss: -0.9961  Acc@1: 75.0000 (82.8505)  Acc@5: 100.0000 (97.1478)  time: 0.3479  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2930/3750]  eta: 0:04:46  Lr: 0.001875  Loss: -1.3814  Acc@1: 81.2500 (82.8514)  Acc@5: 100.0000 (97.1511)  time: 0.3480  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2940/3750]  eta: 0:04:42  Lr: 0.001875  Loss: -1.2585  Acc@1: 87.5000 (82.8672)  Acc@5: 100.0000 (97.1523)  time: 0.3464  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2950/3750]  eta: 0:04:39  Lr: 0.001875  Loss: -1.1394  Acc@1: 87.5000 (82.8723)  Acc@5: 100.0000 (97.1599)  time: 0.3465  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2960/3750]  eta: 0:04:35  Lr: 0.001875  Loss: -0.7498  Acc@1: 81.2500 (82.8563)  Acc@5: 100.0000 (97.1610)  time: 0.3477  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2970/3750]  eta: 0:04:32  Lr: 0.001875  Loss: -1.0888  Acc@1: 81.2500 (82.8425)  Acc@5: 93.7500 (97.1537)  time: 0.3480  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2980/3750]  eta: 0:04:28  Lr: 0.001875  Loss: -1.0860  Acc@1: 81.2500 (82.8287)  Acc@5: 93.7500 (97.1528)  time: 0.3470  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2990/3750]  eta: 0:04:25  Lr: 0.001875  Loss: -1.0533  Acc@1: 81.2500 (82.8276)  Acc@5: 100.0000 (97.1561)  time: 0.3469  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3000/3750]  eta: 0:04:21  Lr: 0.001875  Loss: -0.4589  Acc@1: 81.2500 (82.8161)  Acc@5: 100.0000 (97.1593)  time: 0.3479  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3010/3750]  eta: 0:04:18  Lr: 0.001875  Loss: -0.4769  Acc@1: 75.0000 (82.8068)  Acc@5: 100.0000 (97.1542)  time: 0.3484  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [3020/3750]  eta: 0:04:14  Lr: 0.001875  Loss: -0.7329  Acc@1: 81.2500 (82.8058)  Acc@5: 93.7500 (97.1491)  time: 0.3483  data: 0.0009  max mem: 2500
Train: Epoch[4/5]  [3030/3750]  eta: 0:04:11  Lr: 0.001875  Loss: -0.9867  Acc@1: 81.2500 (82.7924)  Acc@5: 100.0000 (97.1523)  time: 0.3497  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [3040/3750]  eta: 0:04:07  Lr: 0.001875  Loss: -0.8959  Acc@1: 81.2500 (82.7997)  Acc@5: 100.0000 (97.1535)  time: 0.3491  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [3050/3750]  eta: 0:04:04  Lr: 0.001875  Loss: -0.2659  Acc@1: 87.5000 (82.8007)  Acc@5: 100.0000 (97.1587)  time: 0.3480  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [3060/3750]  eta: 0:04:00  Lr: 0.001875  Loss: -0.8240  Acc@1: 87.5000 (82.8161)  Acc@5: 100.0000 (97.1578)  time: 0.3486  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [3070/3750]  eta: 0:03:57  Lr: 0.001875  Loss: -0.8637  Acc@1: 87.5000 (82.8252)  Acc@5: 100.0000 (97.1569)  time: 0.3486  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [3080/3750]  eta: 0:03:53  Lr: 0.001875  Loss: -1.0154  Acc@1: 87.5000 (82.8363)  Acc@5: 100.0000 (97.1600)  time: 0.3486  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [3090/3750]  eta: 0:03:50  Lr: 0.001875  Loss: -1.0353  Acc@1: 87.5000 (82.8474)  Acc@5: 100.0000 (97.1611)  time: 0.3485  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [3100/3750]  eta: 0:03:46  Lr: 0.001875  Loss: -1.2032  Acc@1: 87.5000 (82.8704)  Acc@5: 100.0000 (97.1662)  time: 0.3503  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [3110/3750]  eta: 0:03:43  Lr: 0.001875  Loss: -0.4148  Acc@1: 87.5000 (82.8853)  Acc@5: 100.0000 (97.1693)  time: 0.3493  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [3120/3750]  eta: 0:03:39  Lr: 0.001875  Loss: -1.0688  Acc@1: 87.5000 (82.8801)  Acc@5: 100.0000 (97.1704)  time: 0.3475  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3130/3750]  eta: 0:03:36  Lr: 0.001875  Loss: -0.7839  Acc@1: 81.2500 (82.8869)  Acc@5: 100.0000 (97.1714)  time: 0.3484  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [3140/3750]  eta: 0:03:32  Lr: 0.001875  Loss: -0.9207  Acc@1: 81.2500 (82.8737)  Acc@5: 100.0000 (97.1585)  time: 0.3484  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [3150/3750]  eta: 0:03:29  Lr: 0.001875  Loss: -0.6776  Acc@1: 81.2500 (82.8844)  Acc@5: 100.0000 (97.1596)  time: 0.3487  data: 0.0012  max mem: 2500
Train: Epoch[4/5]  [3160/3750]  eta: 0:03:25  Lr: 0.001875  Loss: -1.1304  Acc@1: 87.5000 (82.8911)  Acc@5: 100.0000 (97.1647)  time: 0.3493  data: 0.0012  max mem: 2500
Train: Epoch[4/5]  [3170/3750]  eta: 0:03:22  Lr: 0.001875  Loss: -0.7238  Acc@1: 81.2500 (82.8721)  Acc@5: 100.0000 (97.1637)  time: 0.3485  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [3180/3750]  eta: 0:03:18  Lr: 0.001875  Loss: -0.9768  Acc@1: 81.2500 (82.8886)  Acc@5: 100.0000 (97.1707)  time: 0.3486  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [3190/3750]  eta: 0:03:15  Lr: 0.001875  Loss: -1.2977  Acc@1: 87.5000 (82.9031)  Acc@5: 100.0000 (97.1737)  time: 0.3490  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [3200/3750]  eta: 0:03:11  Lr: 0.001875  Loss: -1.0124  Acc@1: 87.5000 (82.9116)  Acc@5: 100.0000 (97.1708)  time: 0.3485  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [3210/3750]  eta: 0:03:08  Lr: 0.001875  Loss: -1.1399  Acc@1: 87.5000 (82.9181)  Acc@5: 100.0000 (97.1738)  time: 0.3483  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [3220/3750]  eta: 0:03:05  Lr: 0.001875  Loss: -0.8199  Acc@1: 81.2500 (82.9129)  Acc@5: 100.0000 (97.1690)  time: 0.3487  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [3230/3750]  eta: 0:03:01  Lr: 0.001875  Loss: -0.8980  Acc@1: 81.2500 (82.9174)  Acc@5: 100.0000 (97.1700)  time: 0.3490  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [3240/3750]  eta: 0:02:58  Lr: 0.001875  Loss: -1.0414  Acc@1: 81.2500 (82.9084)  Acc@5: 100.0000 (97.1729)  time: 0.3515  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [3250/3750]  eta: 0:02:54  Lr: 0.001875  Loss: -0.9778  Acc@1: 81.2500 (82.9110)  Acc@5: 100.0000 (97.1701)  time: 0.3540  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [3260/3750]  eta: 0:02:51  Lr: 0.001875  Loss: -0.9083  Acc@1: 81.2500 (82.9136)  Acc@5: 93.7500 (97.1692)  time: 0.3509  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [3270/3750]  eta: 0:02:47  Lr: 0.001875  Loss: -0.2334  Acc@1: 75.0000 (82.8990)  Acc@5: 100.0000 (97.1683)  time: 0.3470  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3280/3750]  eta: 0:02:44  Lr: 0.001875  Loss: -1.1235  Acc@1: 87.5000 (82.9092)  Acc@5: 100.0000 (97.1693)  time: 0.3474  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [3290/3750]  eta: 0:02:40  Lr: 0.001875  Loss: -0.8617  Acc@1: 87.5000 (82.9003)  Acc@5: 100.0000 (97.1665)  time: 0.3496  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [3300/3750]  eta: 0:02:37  Lr: 0.001875  Loss: -1.3813  Acc@1: 81.2500 (82.8934)  Acc@5: 93.7500 (97.1618)  time: 0.3497  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [3310/3750]  eta: 0:02:33  Lr: 0.001875  Loss: -1.2465  Acc@1: 81.2500 (82.8923)  Acc@5: 93.7500 (97.1553)  time: 0.3493  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [3320/3750]  eta: 0:02:30  Lr: 0.001875  Loss: -0.9668  Acc@1: 87.5000 (82.9080)  Acc@5: 100.0000 (97.1582)  time: 0.3496  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [3330/3750]  eta: 0:02:26  Lr: 0.001875  Loss: -1.2191  Acc@1: 81.2500 (82.8955)  Acc@5: 93.7500 (97.1480)  time: 0.3484  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [3340/3750]  eta: 0:02:23  Lr: 0.001875  Loss: -0.6000  Acc@1: 75.0000 (82.8794)  Acc@5: 93.7500 (97.1453)  time: 0.3503  data: 0.0012  max mem: 2500
Train: Epoch[4/5]  [3350/3750]  eta: 0:02:19  Lr: 0.001875  Loss: -1.3271  Acc@1: 81.2500 (82.8820)  Acc@5: 100.0000 (97.1464)  time: 0.3513  data: 0.0012  max mem: 2500
Train: Epoch[4/5]  [3360/3750]  eta: 0:02:16  Lr: 0.001875  Loss: -1.3072  Acc@1: 81.2500 (82.8864)  Acc@5: 93.7500 (97.1418)  time: 0.3497  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [3370/3750]  eta: 0:02:12  Lr: 0.001875  Loss: -1.2075  Acc@1: 81.2500 (82.8927)  Acc@5: 100.0000 (97.1466)  time: 0.3489  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [3380/3750]  eta: 0:02:09  Lr: 0.001875  Loss: -0.8556  Acc@1: 81.2500 (82.8915)  Acc@5: 100.0000 (97.1403)  time: 0.3502  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [3390/3750]  eta: 0:02:05  Lr: 0.001875  Loss: -1.1151  Acc@1: 81.2500 (82.8904)  Acc@5: 100.0000 (97.1450)  time: 0.3520  data: 0.0011  max mem: 2500
Train: Epoch[4/5]  [3400/3750]  eta: 0:02:02  Lr: 0.001875  Loss: -1.0168  Acc@1: 87.5000 (82.8984)  Acc@5: 100.0000 (97.1442)  time: 0.3509  data: 0.0012  max mem: 2500
Train: Epoch[4/5]  [3410/3750]  eta: 0:01:58  Lr: 0.001875  Loss: -0.5656  Acc@1: 81.2500 (82.8881)  Acc@5: 93.7500 (97.1434)  time: 0.3506  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [3420/3750]  eta: 0:01:55  Lr: 0.001875  Loss: -1.1159  Acc@1: 75.0000 (82.8760)  Acc@5: 93.7500 (97.1335)  time: 0.3512  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [3430/3750]  eta: 0:01:51  Lr: 0.001875  Loss: -0.8916  Acc@1: 81.2500 (82.8658)  Acc@5: 93.7500 (97.1328)  time: 0.3500  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3440/3750]  eta: 0:01:48  Lr: 0.001875  Loss: -1.3906  Acc@1: 87.5000 (82.8811)  Acc@5: 100.0000 (97.1320)  time: 0.3484  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3450/3750]  eta: 0:01:44  Lr: 0.001875  Loss: -0.6886  Acc@1: 87.5000 (82.8926)  Acc@5: 100.0000 (97.1349)  time: 0.3484  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3460/3750]  eta: 0:01:41  Lr: 0.001875  Loss: -1.2103  Acc@1: 87.5000 (82.8951)  Acc@5: 100.0000 (97.1323)  time: 0.3477  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [3470/3750]  eta: 0:01:37  Lr: 0.001875  Loss: -0.9713  Acc@1: 81.2500 (82.8904)  Acc@5: 100.0000 (97.1334)  time: 0.3488  data: 0.0011  max mem: 2500
Train: Epoch[4/5]  [3480/3750]  eta: 0:01:34  Lr: 0.001875  Loss: -1.2581  Acc@1: 81.2500 (82.8857)  Acc@5: 100.0000 (97.1309)  time: 0.3495  data: 0.0013  max mem: 2500
Train: Epoch[4/5]  [3490/3750]  eta: 0:01:30  Lr: 0.001875  Loss: -0.7741  Acc@1: 87.5000 (82.9007)  Acc@5: 100.0000 (97.1373)  time: 0.3503  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [3500/3750]  eta: 0:01:27  Lr: 0.001875  Loss: -1.1870  Acc@1: 81.2500 (82.8888)  Acc@5: 100.0000 (97.1383)  time: 0.3511  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [3510/3750]  eta: 0:01:23  Lr: 0.001875  Loss: -0.8289  Acc@1: 81.2500 (82.8824)  Acc@5: 93.7500 (97.1287)  time: 0.3507  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [3520/3750]  eta: 0:01:20  Lr: 0.001875  Loss: -0.9285  Acc@1: 81.2500 (82.8866)  Acc@5: 93.7500 (97.1315)  time: 0.3516  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [3530/3750]  eta: 0:01:16  Lr: 0.001875  Loss: -0.6749  Acc@1: 87.5000 (82.8979)  Acc@5: 100.0000 (97.1361)  time: 0.3504  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [3540/3750]  eta: 0:01:13  Lr: 0.001875  Loss: -1.2916  Acc@1: 81.2500 (82.8897)  Acc@5: 100.0000 (97.1336)  time: 0.3497  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [3550/3750]  eta: 0:01:09  Lr: 0.001875  Loss: -0.6292  Acc@1: 81.2500 (82.8851)  Acc@5: 100.0000 (97.1311)  time: 0.3494  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [3560/3750]  eta: 0:01:06  Lr: 0.001875  Loss: -0.7319  Acc@1: 81.2500 (82.8910)  Acc@5: 93.7500 (97.1321)  time: 0.3496  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [3570/3750]  eta: 0:01:02  Lr: 0.001875  Loss: -1.3816  Acc@1: 87.5000 (82.8969)  Acc@5: 93.7500 (97.1279)  time: 0.3488  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [3580/3750]  eta: 0:00:59  Lr: 0.001875  Loss: -1.1086  Acc@1: 87.5000 (82.8976)  Acc@5: 93.7500 (97.1272)  time: 0.3505  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [3590/3750]  eta: 0:00:55  Lr: 0.001875  Loss: -0.9062  Acc@1: 81.2500 (82.9017)  Acc@5: 100.0000 (97.1300)  time: 0.3502  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [3600/3750]  eta: 0:00:52  Lr: 0.001875  Loss: -0.7526  Acc@1: 81.2500 (82.8971)  Acc@5: 100.0000 (97.1241)  time: 0.3474  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3610/3750]  eta: 0:00:48  Lr: 0.001875  Loss: -1.3628  Acc@1: 81.2500 (82.8995)  Acc@5: 100.0000 (97.1268)  time: 0.3479  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3620/3750]  eta: 0:00:45  Lr: 0.001875  Loss: -0.9826  Acc@1: 87.5000 (82.9105)  Acc@5: 100.0000 (97.1330)  time: 0.3476  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [3630/3750]  eta: 0:00:41  Lr: 0.001875  Loss: -0.7791  Acc@1: 87.5000 (82.9093)  Acc@5: 100.0000 (97.1323)  time: 0.3497  data: 0.0011  max mem: 2500
Train: Epoch[4/5]  [3640/3750]  eta: 0:00:38  Lr: 0.001875  Loss: -1.0289  Acc@1: 87.5000 (82.9048)  Acc@5: 100.0000 (97.1299)  time: 0.3499  data: 0.0011  max mem: 2500
Train: Epoch[4/5]  [3650/3750]  eta: 0:00:34  Lr: 0.001875  Loss: -0.8034  Acc@1: 81.2500 (82.8951)  Acc@5: 100.0000 (97.1275)  time: 0.3495  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [3660/3750]  eta: 0:00:31  Lr: 0.001875  Loss: -1.0975  Acc@1: 81.2500 (82.8923)  Acc@5: 93.7500 (97.1200)  time: 0.3502  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [3670/3750]  eta: 0:00:27  Lr: 0.001875  Loss: -1.0714  Acc@1: 81.2500 (82.8827)  Acc@5: 93.7500 (97.1159)  time: 0.3503  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [3680/3750]  eta: 0:00:24  Lr: 0.001875  Loss: -0.7536  Acc@1: 81.2500 (82.8885)  Acc@5: 100.0000 (97.1119)  time: 0.3491  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [3690/3750]  eta: 0:00:20  Lr: 0.001875  Loss: -0.7854  Acc@1: 81.2500 (82.8722)  Acc@5: 100.0000 (97.1061)  time: 0.3479  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [3700/3750]  eta: 0:00:17  Lr: 0.001875  Loss: -0.6703  Acc@1: 81.2500 (82.8796)  Acc@5: 100.0000 (97.1089)  time: 0.3482  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [3710/3750]  eta: 0:00:13  Lr: 0.001875  Loss: -0.2551  Acc@1: 87.5000 (82.8870)  Acc@5: 100.0000 (97.1066)  time: 0.3475  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [3720/3750]  eta: 0:00:10  Lr: 0.001875  Loss: -1.3368  Acc@1: 87.5000 (82.8927)  Acc@5: 100.0000 (97.1060)  time: 0.3472  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [3730/3750]  eta: 0:00:06  Lr: 0.001875  Loss: -0.9962  Acc@1: 87.5000 (82.9101)  Acc@5: 100.0000 (97.1087)  time: 0.3474  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [3740/3750]  eta: 0:00:03  Lr: 0.001875  Loss: -1.1886  Acc@1: 81.2500 (82.9023)  Acc@5: 100.0000 (97.1047)  time: 0.3481  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [3749/3750]  eta: 0:00:00  Lr: 0.001875  Loss: -1.1203  Acc@1: 81.2500 (82.9017)  Acc@5: 100.0000 (97.1033)  time: 0.3492  data: 0.0011  max mem: 2500
Train: Epoch[4/5] Total time: 0:21:50 (0.3494 s / it)
{0: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 1: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 2: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 3: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 4: {0: 0, 1: 240000, 2: 0, 3: 0, 4: 0}, 5: {0: 0, 1: 240000, 2: 0, 3: 0, 4: 0}, 6: {0: 0, 1: 240000, 2: 0, 3: 0, 4: 0}, 7: {0: 0, 1: 240000, 2: 0, 3: 0, 4: 0}, 8: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 9: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 10: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 11: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 12: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 13: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 14: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 15: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 16: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 17: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 18: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 19: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}}
Averaged stats: Lr: 0.001875  Loss: -1.1203  Acc@1: 81.2500 (82.9017)  Acc@5: 100.0000 (97.1033)
Train: Epoch[5/5]  [   0/3750]  eta: 0:48:23  Lr: 0.001875  Loss: -1.0009  Acc@1: 75.0000 (75.0000)  Acc@5: 100.0000 (100.0000)  time: 0.7743  data: 0.4285  max mem: 2500
Train: Epoch[5/5]  [  10/3750]  eta: 0:24:02  Lr: 0.001875  Loss: -1.0333  Acc@1: 75.0000 (77.2727)  Acc@5: 100.0000 (95.4545)  time: 0.3856  data: 0.0394  max mem: 2500
Train: Epoch[5/5]  [  20/3750]  eta: 0:22:47  Lr: 0.001875  Loss: -1.2798  Acc@1: 81.2500 (80.3571)  Acc@5: 100.0000 (96.4286)  time: 0.3462  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [  30/3750]  eta: 0:22:21  Lr: 0.001875  Loss: -1.0845  Acc@1: 81.2500 (81.2500)  Acc@5: 100.0000 (96.1694)  time: 0.3468  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [  40/3750]  eta: 0:22:06  Lr: 0.001875  Loss: -0.9979  Acc@1: 87.5000 (82.3171)  Acc@5: 93.7500 (96.3415)  time: 0.3480  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [  50/3750]  eta: 0:21:58  Lr: 0.001875  Loss: -0.7518  Acc@1: 81.2500 (81.7402)  Acc@5: 93.7500 (96.4461)  time: 0.3497  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [  60/3750]  eta: 0:21:50  Lr: 0.001875  Loss: -1.0543  Acc@1: 81.2500 (81.7623)  Acc@5: 93.7500 (96.4139)  time: 0.3502  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [  70/3750]  eta: 0:21:43  Lr: 0.001875  Loss: -1.1972  Acc@1: 81.2500 (82.1303)  Acc@5: 100.0000 (96.8310)  time: 0.3491  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [  80/3750]  eta: 0:21:38  Lr: 0.001875  Loss: -1.4257  Acc@1: 81.2500 (82.5617)  Acc@5: 100.0000 (96.9136)  time: 0.3494  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [  90/3750]  eta: 0:21:32  Lr: 0.001875  Loss: -0.8283  Acc@1: 81.2500 (82.2802)  Acc@5: 100.0000 (96.8407)  time: 0.3490  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [ 100/3750]  eta: 0:21:26  Lr: 0.001875  Loss: -1.1573  Acc@1: 81.2500 (82.7351)  Acc@5: 93.7500 (96.7822)  time: 0.3475  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [ 110/3750]  eta: 0:21:21  Lr: 0.001875  Loss: -0.7673  Acc@1: 81.2500 (82.4887)  Acc@5: 93.7500 (96.6779)  time: 0.3472  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [ 120/3750]  eta: 0:21:17  Lr: 0.001875  Loss: -1.0775  Acc@1: 81.2500 (82.5413)  Acc@5: 93.7500 (96.7459)  time: 0.3486  data: 0.0011  max mem: 2500
Train: Epoch[5/5]  [ 130/3750]  eta: 0:21:12  Lr: 0.001875  Loss: -0.7952  Acc@1: 81.2500 (82.2519)  Acc@5: 93.7500 (96.6126)  time: 0.3491  data: 0.0011  max mem: 2500
Train: Epoch[5/5]  [ 140/3750]  eta: 0:21:09  Lr: 0.001875  Loss: -1.4335  Acc@1: 81.2500 (82.5798)  Acc@5: 100.0000 (96.7199)  time: 0.3499  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [ 150/3750]  eta: 0:21:04  Lr: 0.001875  Loss: -1.1564  Acc@1: 81.2500 (82.3675)  Acc@5: 100.0000 (96.8129)  time: 0.3482  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [ 160/3750]  eta: 0:20:59  Lr: 0.001875  Loss: -1.5293  Acc@1: 81.2500 (82.6087)  Acc@5: 100.0000 (96.8556)  time: 0.3463  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 170/3750]  eta: 0:20:55  Lr: 0.001875  Loss: -1.0364  Acc@1: 87.5000 (82.6754)  Acc@5: 100.0000 (97.0029)  time: 0.3475  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 180/3750]  eta: 0:20:51  Lr: 0.001875  Loss: -1.2232  Acc@1: 87.5000 (82.7348)  Acc@5: 100.0000 (96.8923)  time: 0.3477  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 190/3750]  eta: 0:20:47  Lr: 0.001875  Loss: -1.2088  Acc@1: 81.2500 (82.8207)  Acc@5: 100.0000 (97.0223)  time: 0.3477  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [ 200/3750]  eta: 0:20:43  Lr: 0.001875  Loss: -0.7264  Acc@1: 81.2500 (82.7114)  Acc@5: 100.0000 (97.0460)  time: 0.3483  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [ 210/3750]  eta: 0:20:39  Lr: 0.001875  Loss: -0.8795  Acc@1: 81.2500 (82.7903)  Acc@5: 100.0000 (97.0083)  time: 0.3480  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [ 220/3750]  eta: 0:20:36  Lr: 0.001875  Loss: -0.8349  Acc@1: 81.2500 (82.5509)  Acc@5: 93.7500 (96.8609)  time: 0.3486  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [ 230/3750]  eta: 0:20:33  Lr: 0.001875  Loss: -1.1854  Acc@1: 75.0000 (82.4405)  Acc@5: 93.7500 (96.8074)  time: 0.3515  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [ 240/3750]  eta: 0:20:29  Lr: 0.001875  Loss: -0.9103  Acc@1: 75.0000 (82.3392)  Acc@5: 93.7500 (96.7583)  time: 0.3500  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [ 250/3750]  eta: 0:20:24  Lr: 0.001875  Loss: -0.7757  Acc@1: 81.2500 (82.4452)  Acc@5: 100.0000 (96.8376)  time: 0.3463  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 260/3750]  eta: 0:20:21  Lr: 0.001875  Loss: -1.2566  Acc@1: 87.5000 (82.4952)  Acc@5: 100.0000 (96.9109)  time: 0.3471  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [ 270/3750]  eta: 0:20:17  Lr: 0.001875  Loss: -1.1452  Acc@1: 87.5000 (82.5185)  Acc@5: 100.0000 (96.8635)  time: 0.3481  data: 0.0010  max mem: 2500
Train: Epoch[5/5]  [ 280/3750]  eta: 0:20:13  Lr: 0.001875  Loss: -0.8543  Acc@1: 87.5000 (82.5845)  Acc@5: 100.0000 (96.9084)  time: 0.3475  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [ 290/3750]  eta: 0:20:10  Lr: 0.001875  Loss: -0.9564  Acc@1: 87.5000 (82.6890)  Acc@5: 100.0000 (96.8643)  time: 0.3486  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [ 300/3750]  eta: 0:20:07  Lr: 0.001875  Loss: -0.7440  Acc@1: 81.2500 (82.6204)  Acc@5: 93.7500 (96.8231)  time: 0.3517  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [ 310/3750]  eta: 0:20:03  Lr: 0.001875  Loss: -1.1796  Acc@1: 81.2500 (82.5965)  Acc@5: 93.7500 (96.8449)  time: 0.3512  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 320/3750]  eta: 0:19:59  Lr: 0.001875  Loss: -1.0286  Acc@1: 81.2500 (82.5156)  Acc@5: 100.0000 (96.8458)  time: 0.3475  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [ 330/3750]  eta: 0:19:55  Lr: 0.001875  Loss: -0.8064  Acc@1: 81.2500 (82.5340)  Acc@5: 100.0000 (96.8656)  time: 0.3467  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [ 340/3750]  eta: 0:19:51  Lr: 0.001875  Loss: -1.2769  Acc@1: 81.2500 (82.4963)  Acc@5: 100.0000 (96.8842)  time: 0.3464  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 350/3750]  eta: 0:19:48  Lr: 0.001875  Loss: -1.0514  Acc@1: 81.2500 (82.4430)  Acc@5: 100.0000 (96.8839)  time: 0.3460  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [ 360/3750]  eta: 0:19:44  Lr: 0.001875  Loss: -0.9954  Acc@1: 81.2500 (82.4619)  Acc@5: 100.0000 (96.8490)  time: 0.3478  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [ 370/3750]  eta: 0:19:40  Lr: 0.001875  Loss: -0.6494  Acc@1: 81.2500 (82.3619)  Acc@5: 100.0000 (96.8834)  time: 0.3485  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [ 380/3750]  eta: 0:19:37  Lr: 0.001875  Loss: -0.7117  Acc@1: 81.2500 (82.4803)  Acc@5: 100.0000 (96.9160)  time: 0.3488  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [ 390/3750]  eta: 0:19:33  Lr: 0.001875  Loss: -0.2494  Acc@1: 81.2500 (82.4329)  Acc@5: 100.0000 (96.9150)  time: 0.3493  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [ 400/3750]  eta: 0:19:30  Lr: 0.001875  Loss: -1.2653  Acc@1: 81.2500 (82.5592)  Acc@5: 100.0000 (96.8984)  time: 0.3496  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [ 410/3750]  eta: 0:19:26  Lr: 0.001875  Loss: -1.1678  Acc@1: 87.5000 (82.6338)  Acc@5: 100.0000 (96.9130)  time: 0.3490  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 420/3750]  eta: 0:19:23  Lr: 0.001875  Loss: -0.7931  Acc@1: 87.5000 (82.7197)  Acc@5: 100.0000 (96.9715)  time: 0.3476  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 430/3750]  eta: 0:19:19  Lr: 0.001875  Loss: -0.9113  Acc@1: 87.5000 (82.6856)  Acc@5: 100.0000 (96.9983)  time: 0.3479  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [ 440/3750]  eta: 0:19:16  Lr: 0.001875  Loss: -1.0816  Acc@1: 81.2500 (82.6389)  Acc@5: 100.0000 (96.9529)  time: 0.3489  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [ 450/3750]  eta: 0:19:12  Lr: 0.001875  Loss: -1.0954  Acc@1: 81.2500 (82.6774)  Acc@5: 93.7500 (96.9651)  time: 0.3509  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [ 460/3750]  eta: 0:19:09  Lr: 0.001875  Loss: -1.0183  Acc@1: 81.2500 (82.6871)  Acc@5: 100.0000 (97.0309)  time: 0.3512  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [ 470/3750]  eta: 0:19:05  Lr: 0.001875  Loss: -0.8357  Acc@1: 81.2500 (82.7495)  Acc@5: 100.0000 (97.0011)  time: 0.3491  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [ 480/3750]  eta: 0:19:02  Lr: 0.001875  Loss: -1.0891  Acc@1: 87.5000 (82.8742)  Acc@5: 100.0000 (97.0374)  time: 0.3479  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [ 490/3750]  eta: 0:18:58  Lr: 0.001875  Loss: -0.6305  Acc@1: 87.5000 (82.9557)  Acc@5: 100.0000 (97.0468)  time: 0.3481  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [ 500/3750]  eta: 0:18:55  Lr: 0.001875  Loss: -0.6602  Acc@1: 81.2500 (82.8967)  Acc@5: 100.0000 (97.0684)  time: 0.3487  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [ 510/3750]  eta: 0:18:51  Lr: 0.001875  Loss: -1.0354  Acc@1: 87.5000 (82.9623)  Acc@5: 100.0000 (97.0768)  time: 0.3491  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [ 520/3750]  eta: 0:18:48  Lr: 0.001875  Loss: -1.5508  Acc@1: 87.5000 (83.0374)  Acc@5: 100.0000 (97.0369)  time: 0.3509  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [ 530/3750]  eta: 0:18:45  Lr: 0.001875  Loss: -0.8069  Acc@1: 87.5000 (83.0979)  Acc@5: 100.0000 (97.0574)  time: 0.3521  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 540/3750]  eta: 0:18:41  Lr: 0.001875  Loss: -1.3437  Acc@1: 87.5000 (83.0984)  Acc@5: 100.0000 (97.0656)  time: 0.3513  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [ 550/3750]  eta: 0:18:38  Lr: 0.001875  Loss: -0.8519  Acc@1: 81.2500 (83.0195)  Acc@5: 93.7500 (96.9941)  time: 0.3517  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [ 560/3750]  eta: 0:18:34  Lr: 0.001875  Loss: -1.2869  Acc@1: 81.2500 (82.9768)  Acc@5: 93.7500 (96.9920)  time: 0.3515  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [ 570/3750]  eta: 0:18:31  Lr: 0.001875  Loss: -0.5712  Acc@1: 81.2500 (82.8919)  Acc@5: 100.0000 (96.9790)  time: 0.3499  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [ 580/3750]  eta: 0:18:27  Lr: 0.001875  Loss: -0.9576  Acc@1: 81.2500 (82.8744)  Acc@5: 100.0000 (96.9664)  time: 0.3491  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [ 590/3750]  eta: 0:18:24  Lr: 0.001875  Loss: -0.9586  Acc@1: 81.2500 (82.9420)  Acc@5: 100.0000 (96.9437)  time: 0.3490  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [ 600/3750]  eta: 0:18:20  Lr: 0.001875  Loss: -1.1465  Acc@1: 87.5000 (82.9243)  Acc@5: 100.0000 (96.9738)  time: 0.3484  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [ 610/3750]  eta: 0:18:17  Lr: 0.001875  Loss: -0.8628  Acc@1: 87.5000 (82.9480)  Acc@5: 100.0000 (96.9926)  time: 0.3482  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [ 620/3750]  eta: 0:18:13  Lr: 0.001875  Loss: -1.0998  Acc@1: 81.2500 (82.9610)  Acc@5: 100.0000 (97.0209)  time: 0.3488  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [ 630/3750]  eta: 0:18:10  Lr: 0.001875  Loss: -1.0085  Acc@1: 81.2500 (82.9437)  Acc@5: 100.0000 (96.9790)  time: 0.3484  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 640/3750]  eta: 0:18:06  Lr: 0.001875  Loss: -1.1944  Acc@1: 81.2500 (82.9563)  Acc@5: 93.7500 (96.9871)  time: 0.3500  data: 0.0010  max mem: 2500
Train: Epoch[5/5]  [ 650/3750]  eta: 0:18:03  Lr: 0.001875  Loss: -0.7749  Acc@1: 87.5000 (82.9493)  Acc@5: 100.0000 (96.9854)  time: 0.3498  data: 0.0010  max mem: 2500
Train: Epoch[5/5]  [ 660/3750]  eta: 0:17:59  Lr: 0.001875  Loss: -1.0552  Acc@1: 81.2500 (82.9803)  Acc@5: 100.0000 (96.9837)  time: 0.3478  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 670/3750]  eta: 0:17:56  Lr: 0.001875  Loss: -1.3519  Acc@1: 87.5000 (83.0291)  Acc@5: 100.0000 (96.9821)  time: 0.3479  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [ 680/3750]  eta: 0:17:52  Lr: 0.001875  Loss: -1.1494  Acc@1: 87.5000 (83.0396)  Acc@5: 100.0000 (96.9714)  time: 0.3501  data: 0.0011  max mem: 2500
Train: Epoch[5/5]  [ 690/3750]  eta: 0:17:49  Lr: 0.001875  Loss: -1.1328  Acc@1: 81.2500 (83.0047)  Acc@5: 100.0000 (97.0062)  time: 0.3505  data: 0.0011  max mem: 2500
Train: Epoch[5/5]  [ 700/3750]  eta: 0:17:45  Lr: 0.001875  Loss: -1.0740  Acc@1: 81.2500 (82.9529)  Acc@5: 100.0000 (96.9686)  time: 0.3500  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [ 710/3750]  eta: 0:17:42  Lr: 0.001875  Loss: -0.7663  Acc@1: 81.2500 (82.8938)  Acc@5: 100.0000 (96.9849)  time: 0.3503  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [ 720/3750]  eta: 0:17:38  Lr: 0.001875  Loss: -1.2388  Acc@1: 87.5000 (82.9577)  Acc@5: 100.0000 (97.0094)  time: 0.3500  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [ 730/3750]  eta: 0:17:35  Lr: 0.001875  Loss: -1.3319  Acc@1: 87.5000 (82.9856)  Acc@5: 100.0000 (96.9990)  time: 0.3500  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [ 740/3750]  eta: 0:17:31  Lr: 0.001875  Loss: -0.9361  Acc@1: 87.5000 (82.9960)  Acc@5: 100.0000 (97.0142)  time: 0.3494  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [ 750/3750]  eta: 0:17:28  Lr: 0.001875  Loss: -0.7572  Acc@1: 81.2500 (82.9561)  Acc@5: 100.0000 (97.0373)  time: 0.3490  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [ 760/3750]  eta: 0:17:24  Lr: 0.001875  Loss: -0.8854  Acc@1: 81.2500 (82.9665)  Acc@5: 100.0000 (97.0516)  time: 0.3491  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [ 770/3750]  eta: 0:17:21  Lr: 0.001875  Loss: -1.2255  Acc@1: 81.2500 (83.0010)  Acc@5: 100.0000 (97.0736)  time: 0.3510  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [ 780/3750]  eta: 0:17:18  Lr: 0.001875  Loss: -0.8475  Acc@1: 81.2500 (82.9305)  Acc@5: 100.0000 (97.0711)  time: 0.3517  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [ 790/3750]  eta: 0:17:14  Lr: 0.001875  Loss: -1.0006  Acc@1: 81.2500 (82.9251)  Acc@5: 100.0000 (97.0844)  time: 0.3501  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [ 800/3750]  eta: 0:17:10  Lr: 0.001875  Loss: -1.2189  Acc@1: 81.2500 (82.8730)  Acc@5: 100.0000 (97.0740)  time: 0.3481  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [ 810/3750]  eta: 0:17:07  Lr: 0.001875  Loss: -0.6152  Acc@1: 81.2500 (82.8298)  Acc@5: 100.0000 (97.0946)  time: 0.3478  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 820/3750]  eta: 0:17:03  Lr: 0.001875  Loss: -0.8453  Acc@1: 81.2500 (82.7878)  Acc@5: 100.0000 (97.0996)  time: 0.3484  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [ 830/3750]  eta: 0:17:00  Lr: 0.001875  Loss: -0.9515  Acc@1: 81.2500 (82.7993)  Acc@5: 100.0000 (97.1119)  time: 0.3479  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [ 840/3750]  eta: 0:16:56  Lr: 0.001875  Loss: -1.2162  Acc@1: 87.5000 (82.8032)  Acc@5: 100.0000 (97.1240)  time: 0.3485  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [ 850/3750]  eta: 0:16:53  Lr: 0.001875  Loss: -1.4218  Acc@1: 87.5000 (82.8143)  Acc@5: 100.0000 (97.1284)  time: 0.3493  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [ 860/3750]  eta: 0:16:49  Lr: 0.001875  Loss: -1.0265  Acc@1: 87.5000 (82.8688)  Acc@5: 100.0000 (97.1472)  time: 0.3487  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [ 870/3750]  eta: 0:16:46  Lr: 0.001875  Loss: -1.1979  Acc@1: 87.5000 (82.9291)  Acc@5: 100.0000 (97.1369)  time: 0.3497  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [ 880/3750]  eta: 0:16:42  Lr: 0.001875  Loss: -0.8151  Acc@1: 87.5000 (82.8959)  Acc@5: 93.7500 (97.1339)  time: 0.3503  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [ 890/3750]  eta: 0:16:39  Lr: 0.001875  Loss: -0.8837  Acc@1: 81.2500 (82.9195)  Acc@5: 93.7500 (97.1100)  time: 0.3485  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [ 900/3750]  eta: 0:16:35  Lr: 0.001875  Loss: -1.1104  Acc@1: 81.2500 (82.9009)  Acc@5: 93.7500 (97.0727)  time: 0.3496  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [ 910/3750]  eta: 0:16:32  Lr: 0.001875  Loss: -0.3911  Acc@1: 81.2500 (82.8897)  Acc@5: 93.7500 (97.0431)  time: 0.3505  data: 0.0011  max mem: 2500
Train: Epoch[5/5]  [ 920/3750]  eta: 0:16:28  Lr: 0.001875  Loss: -1.2797  Acc@1: 81.2500 (82.8855)  Acc@5: 93.7500 (97.0413)  time: 0.3508  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [ 930/3750]  eta: 0:16:25  Lr: 0.001875  Loss: -1.2497  Acc@1: 87.5000 (82.9417)  Acc@5: 100.0000 (97.0529)  time: 0.3504  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [ 940/3750]  eta: 0:16:22  Lr: 0.001875  Loss: -1.0778  Acc@1: 87.5000 (82.9636)  Acc@5: 100.0000 (97.0709)  time: 0.3505  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 950/3750]  eta: 0:16:18  Lr: 0.001875  Loss: -1.0878  Acc@1: 81.2500 (82.9522)  Acc@5: 100.0000 (97.0886)  time: 0.3501  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 960/3750]  eta: 0:16:14  Lr: 0.001875  Loss: -0.8894  Acc@1: 81.2500 (82.9279)  Acc@5: 100.0000 (97.0734)  time: 0.3478  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 970/3750]  eta: 0:16:11  Lr: 0.001875  Loss: -0.5724  Acc@1: 75.0000 (82.8785)  Acc@5: 93.7500 (97.0391)  time: 0.3480  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 980/3750]  eta: 0:16:07  Lr: 0.001875  Loss: -1.4088  Acc@1: 81.2500 (82.8746)  Acc@5: 93.7500 (97.0438)  time: 0.3495  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 990/3750]  eta: 0:16:04  Lr: 0.001875  Loss: -0.7535  Acc@1: 81.2500 (82.8645)  Acc@5: 100.0000 (97.0358)  time: 0.3505  data: 0.0011  max mem: 2500
Train: Epoch[5/5]  [1000/3750]  eta: 0:16:00  Lr: 0.001875  Loss: -1.2211  Acc@1: 81.2500 (82.9233)  Acc@5: 100.0000 (97.0405)  time: 0.3493  data: 0.0012  max mem: 2500
Train: Epoch[5/5]  [1010/3750]  eta: 0:15:57  Lr: 0.001875  Loss: -0.6581  Acc@1: 87.5000 (82.9315)  Acc@5: 100.0000 (97.0326)  time: 0.3473  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [1020/3750]  eta: 0:15:53  Lr: 0.001875  Loss: -1.1003  Acc@1: 81.2500 (82.9640)  Acc@5: 100.0000 (97.0311)  time: 0.3477  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [1030/3750]  eta: 0:15:50  Lr: 0.001875  Loss: -1.0324  Acc@1: 81.2500 (82.9534)  Acc@5: 100.0000 (97.0356)  time: 0.3487  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [1040/3750]  eta: 0:15:46  Lr: 0.001875  Loss: -0.7092  Acc@1: 81.2500 (82.8830)  Acc@5: 100.0000 (97.0161)  time: 0.3490  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [1050/3750]  eta: 0:15:43  Lr: 0.001875  Loss: -1.1488  Acc@1: 75.0000 (82.8556)  Acc@5: 93.7500 (97.0147)  time: 0.3483  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [1060/3750]  eta: 0:15:39  Lr: 0.001875  Loss: -1.2108  Acc@1: 81.2500 (82.8640)  Acc@5: 100.0000 (97.0311)  time: 0.3476  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [1070/3750]  eta: 0:15:36  Lr: 0.001875  Loss: -0.7428  Acc@1: 81.2500 (82.8957)  Acc@5: 100.0000 (97.0296)  time: 0.3481  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [1080/3750]  eta: 0:15:32  Lr: 0.001875  Loss: -1.3682  Acc@1: 87.5000 (82.9267)  Acc@5: 100.0000 (97.0224)  time: 0.3482  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [1090/3750]  eta: 0:15:29  Lr: 0.001875  Loss: -0.8438  Acc@1: 81.2500 (82.8827)  Acc@5: 100.0000 (97.0325)  time: 0.3473  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [1100/3750]  eta: 0:15:25  Lr: 0.001875  Loss: -0.7348  Acc@1: 81.2500 (82.8962)  Acc@5: 100.0000 (97.0425)  time: 0.3469  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [1110/3750]  eta: 0:15:22  Lr: 0.001875  Loss: -1.1004  Acc@1: 81.2500 (82.8927)  Acc@5: 100.0000 (97.0410)  time: 0.3490  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [1120/3750]  eta: 0:15:18  Lr: 0.001875  Loss: -0.4550  Acc@1: 81.2500 (82.8947)  Acc@5: 100.0000 (97.0562)  time: 0.3490  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [1130/3750]  eta: 0:15:15  Lr: 0.001875  Loss: -1.0640  Acc@1: 81.2500 (82.8912)  Acc@5: 100.0000 (97.0601)  time: 0.3473  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1140/3750]  eta: 0:15:11  Lr: 0.001875  Loss: -0.4607  Acc@1: 81.2500 (82.8878)  Acc@5: 100.0000 (97.0695)  time: 0.3471  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1150/3750]  eta: 0:15:08  Lr: 0.001875  Loss: -1.0528  Acc@1: 87.5000 (82.9225)  Acc@5: 100.0000 (97.0895)  time: 0.3473  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [1160/3750]  eta: 0:15:04  Lr: 0.001875  Loss: -1.2125  Acc@1: 87.5000 (82.9350)  Acc@5: 100.0000 (97.0876)  time: 0.3481  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [1170/3750]  eta: 0:15:00  Lr: 0.001875  Loss: -1.2383  Acc@1: 81.2500 (82.9152)  Acc@5: 100.0000 (97.1018)  time: 0.3478  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [1180/3750]  eta: 0:14:57  Lr: 0.001875  Loss: -1.3335  Acc@1: 87.5000 (82.9752)  Acc@5: 100.0000 (97.1105)  time: 0.3475  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [1190/3750]  eta: 0:14:53  Lr: 0.001875  Loss: -1.0085  Acc@1: 87.5000 (82.9398)  Acc@5: 100.0000 (97.1033)  time: 0.3486  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [1200/3750]  eta: 0:14:50  Lr: 0.001875  Loss: -1.0761  Acc@1: 87.5000 (82.9621)  Acc@5: 100.0000 (97.1066)  time: 0.3493  data: 0.0013  max mem: 2500
Train: Epoch[5/5]  [1210/3750]  eta: 0:14:46  Lr: 0.001875  Loss: -0.7150  Acc@1: 81.2500 (82.9273)  Acc@5: 100.0000 (97.0840)  time: 0.3482  data: 0.0012  max mem: 2500
Train: Epoch[5/5]  [1220/3750]  eta: 0:14:43  Lr: 0.001875  Loss: -1.2865  Acc@1: 81.2500 (82.8880)  Acc@5: 93.7500 (97.0772)  time: 0.3476  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [1230/3750]  eta: 0:14:39  Lr: 0.001875  Loss: -1.2089  Acc@1: 81.2500 (82.9458)  Acc@5: 100.0000 (97.0857)  time: 0.3492  data: 0.0017  max mem: 2500
Train: Epoch[5/5]  [1240/3750]  eta: 0:14:36  Lr: 0.001875  Loss: -1.0509  Acc@1: 81.2500 (82.9069)  Acc@5: 100.0000 (97.0890)  time: 0.3489  data: 0.0018  max mem: 2500
Train: Epoch[5/5]  [1250/3750]  eta: 0:14:32  Lr: 0.001875  Loss: -1.3304  Acc@1: 81.2500 (82.9536)  Acc@5: 100.0000 (97.0823)  time: 0.3472  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [1260/3750]  eta: 0:14:29  Lr: 0.001875  Loss: -1.2965  Acc@1: 87.5000 (82.9352)  Acc@5: 100.0000 (97.0856)  time: 0.3482  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [1270/3750]  eta: 0:14:25  Lr: 0.001875  Loss: -0.7459  Acc@1: 81.2500 (82.9514)  Acc@5: 100.0000 (97.0840)  time: 0.3489  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [1280/3750]  eta: 0:14:22  Lr: 0.001875  Loss: -1.0543  Acc@1: 87.5000 (82.9918)  Acc@5: 100.0000 (97.1068)  time: 0.3480  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1290/3750]  eta: 0:14:18  Lr: 0.001875  Loss: -1.2615  Acc@1: 87.5000 (83.0074)  Acc@5: 100.0000 (97.0953)  time: 0.3472  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [1300/3750]  eta: 0:14:15  Lr: 0.001875  Loss: -0.5139  Acc@1: 87.5000 (82.9987)  Acc@5: 100.0000 (97.1032)  time: 0.3472  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [1310/3750]  eta: 0:14:11  Lr: 0.001875  Loss: -0.8919  Acc@1: 87.5000 (83.0044)  Acc@5: 100.0000 (97.1110)  time: 0.3478  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [1320/3750]  eta: 0:14:08  Lr: 0.001875  Loss: -0.9979  Acc@1: 87.5000 (83.0100)  Acc@5: 100.0000 (97.1092)  time: 0.3477  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1330/3750]  eta: 0:14:04  Lr: 0.001875  Loss: -1.1692  Acc@1: 81.2500 (83.0015)  Acc@5: 100.0000 (97.1121)  time: 0.3477  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [1340/3750]  eta: 0:14:01  Lr: 0.001875  Loss: -0.9866  Acc@1: 87.5000 (83.0444)  Acc@5: 100.0000 (97.1197)  time: 0.3477  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [1350/3750]  eta: 0:13:57  Lr: 0.001875  Loss: -1.1564  Acc@1: 87.5000 (83.0496)  Acc@5: 100.0000 (97.1225)  time: 0.3490  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [1360/3750]  eta: 0:13:54  Lr: 0.001875  Loss: -0.2733  Acc@1: 81.2500 (83.0226)  Acc@5: 100.0000 (97.1391)  time: 0.3513  data: 0.0015  max mem: 2500
Train: Epoch[5/5]  [1370/3750]  eta: 0:13:50  Lr: 0.001875  Loss: -1.0627  Acc@1: 81.2500 (83.0553)  Acc@5: 100.0000 (97.1462)  time: 0.3500  data: 0.0016  max mem: 2500
Train: Epoch[5/5]  [1380/3750]  eta: 0:13:47  Lr: 0.001875  Loss: -1.0854  Acc@1: 87.5000 (83.0512)  Acc@5: 100.0000 (97.1443)  time: 0.3475  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [1390/3750]  eta: 0:13:43  Lr: 0.001875  Loss: -1.1934  Acc@1: 87.5000 (83.0832)  Acc@5: 100.0000 (97.1603)  time: 0.3474  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [1400/3750]  eta: 0:13:40  Lr: 0.001875  Loss: -0.2838  Acc@1: 81.2500 (83.0389)  Acc@5: 100.0000 (97.1494)  time: 0.3481  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [1410/3750]  eta: 0:13:36  Lr: 0.001875  Loss: -0.9795  Acc@1: 81.2500 (83.0262)  Acc@5: 93.7500 (97.1474)  time: 0.3481  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [1420/3750]  eta: 0:13:33  Lr: 0.001875  Loss: -0.7692  Acc@1: 81.2500 (83.0533)  Acc@5: 100.0000 (97.1631)  time: 0.3478  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [1430/3750]  eta: 0:13:29  Lr: 0.001875  Loss: -1.2521  Acc@1: 87.5000 (83.0625)  Acc@5: 100.0000 (97.1654)  time: 0.3477  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [1440/3750]  eta: 0:13:26  Lr: 0.001875  Loss: -1.2361  Acc@1: 81.2500 (83.0456)  Acc@5: 100.0000 (97.1678)  time: 0.3477  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [1450/3750]  eta: 0:13:22  Lr: 0.001875  Loss: -1.2267  Acc@1: 81.2500 (83.0677)  Acc@5: 100.0000 (97.1744)  time: 0.3471  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1460/3750]  eta: 0:13:19  Lr: 0.001875  Loss: -0.9384  Acc@1: 81.2500 (83.0681)  Acc@5: 100.0000 (97.1809)  time: 0.3481  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1470/3750]  eta: 0:13:15  Lr: 0.001875  Loss: -1.5036  Acc@1: 81.2500 (83.0855)  Acc@5: 100.0000 (97.1873)  time: 0.3489  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1480/3750]  eta: 0:13:12  Lr: 0.001875  Loss: -0.5230  Acc@1: 81.2500 (83.1026)  Acc@5: 100.0000 (97.1767)  time: 0.3476  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1490/3750]  eta: 0:13:08  Lr: 0.001875  Loss: -0.9264  Acc@1: 81.2500 (83.0734)  Acc@5: 100.0000 (97.1705)  time: 0.3485  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1500/3750]  eta: 0:13:05  Lr: 0.001875  Loss: -1.0258  Acc@1: 81.2500 (83.0530)  Acc@5: 100.0000 (97.1769)  time: 0.3494  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [1510/3750]  eta: 0:13:01  Lr: 0.001875  Loss: -0.7611  Acc@1: 81.2500 (83.0162)  Acc@5: 100.0000 (97.1666)  time: 0.3493  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [1520/3750]  eta: 0:12:58  Lr: 0.001875  Loss: -0.8620  Acc@1: 75.0000 (82.9758)  Acc@5: 93.7500 (97.1524)  time: 0.3492  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [1530/3750]  eta: 0:12:54  Lr: 0.001875  Loss: -0.5921  Acc@1: 81.2500 (82.9523)  Acc@5: 100.0000 (97.1587)  time: 0.3483  data: 0.0014  max mem: 2500
Train: Epoch[5/5]  [1540/3750]  eta: 0:12:51  Lr: 0.001875  Loss: -0.7335  Acc@1: 81.2500 (82.9616)  Acc@5: 100.0000 (97.1650)  time: 0.3479  data: 0.0010  max mem: 2500
Train: Epoch[5/5]  [1550/3750]  eta: 0:12:47  Lr: 0.001875  Loss: -0.5111  Acc@1: 81.2500 (82.9828)  Acc@5: 100.0000 (97.1470)  time: 0.3477  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1560/3750]  eta: 0:12:44  Lr: 0.001875  Loss: -1.2516  Acc@1: 87.5000 (83.0037)  Acc@5: 100.0000 (97.1613)  time: 0.3475  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1570/3750]  eta: 0:12:40  Lr: 0.001875  Loss: -0.6137  Acc@1: 87.5000 (83.0124)  Acc@5: 100.0000 (97.1634)  time: 0.3504  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [1580/3750]  eta: 0:12:37  Lr: 0.001875  Loss: -1.1469  Acc@1: 81.2500 (83.0250)  Acc@5: 100.0000 (97.1656)  time: 0.3513  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [1590/3750]  eta: 0:12:33  Lr: 0.001875  Loss: -1.3134  Acc@1: 81.2500 (83.0217)  Acc@5: 100.0000 (97.1559)  time: 0.3502  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [1600/3750]  eta: 0:12:30  Lr: 0.001875  Loss: -0.7668  Acc@1: 81.2500 (82.9989)  Acc@5: 93.7500 (97.1424)  time: 0.3488  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [1610/3750]  eta: 0:12:26  Lr: 0.001875  Loss: -1.1548  Acc@1: 81.2500 (82.9997)  Acc@5: 93.7500 (97.1446)  time: 0.3466  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1620/3750]  eta: 0:12:23  Lr: 0.001875  Loss: -0.9242  Acc@1: 87.5000 (83.0120)  Acc@5: 100.0000 (97.1584)  time: 0.3473  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1630/3750]  eta: 0:12:19  Lr: 0.001875  Loss: -0.9072  Acc@1: 81.2500 (83.0051)  Acc@5: 100.0000 (97.1720)  time: 0.3468  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1640/3750]  eta: 0:12:16  Lr: 0.001875  Loss: -0.9474  Acc@1: 81.2500 (82.9982)  Acc@5: 100.0000 (97.1816)  time: 0.3469  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1650/3750]  eta: 0:12:12  Lr: 0.001875  Loss: -1.2865  Acc@1: 81.2500 (82.9952)  Acc@5: 100.0000 (97.1835)  time: 0.3473  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1660/3750]  eta: 0:12:09  Lr: 0.001875  Loss: -1.1950  Acc@1: 81.2500 (82.9959)  Acc@5: 93.7500 (97.1666)  time: 0.3481  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [1670/3750]  eta: 0:12:05  Lr: 0.001875  Loss: -0.9872  Acc@1: 81.2500 (82.9892)  Acc@5: 93.7500 (97.1574)  time: 0.3498  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [1680/3750]  eta: 0:12:02  Lr: 0.001875  Loss: -0.4961  Acc@1: 81.2500 (83.0012)  Acc@5: 100.0000 (97.1706)  time: 0.3515  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1690/3750]  eta: 0:11:58  Lr: 0.001875  Loss: -0.5191  Acc@1: 81.2500 (82.9834)  Acc@5: 100.0000 (97.1651)  time: 0.3508  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [1700/3750]  eta: 0:11:55  Lr: 0.001875  Loss: -0.8162  Acc@1: 81.2500 (82.9696)  Acc@5: 100.0000 (97.1634)  time: 0.3489  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [1710/3750]  eta: 0:11:51  Lr: 0.001875  Loss: -1.0779  Acc@1: 87.5000 (82.9997)  Acc@5: 100.0000 (97.1654)  time: 0.3485  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [1720/3750]  eta: 0:11:48  Lr: 0.001875  Loss: -1.1797  Acc@1: 87.5000 (83.0222)  Acc@5: 100.0000 (97.1637)  time: 0.3492  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [1730/3750]  eta: 0:11:44  Lr: 0.001875  Loss: -0.8214  Acc@1: 87.5000 (83.0300)  Acc@5: 93.7500 (97.1440)  time: 0.3505  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1740/3750]  eta: 0:11:41  Lr: 0.001875  Loss: -0.8830  Acc@1: 81.2500 (83.0090)  Acc@5: 93.7500 (97.1424)  time: 0.3502  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [1750/3750]  eta: 0:11:37  Lr: 0.001875  Loss: -1.1870  Acc@1: 81.2500 (83.0418)  Acc@5: 100.0000 (97.1516)  time: 0.3492  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [1760/3750]  eta: 0:11:34  Lr: 0.001875  Loss: -1.0441  Acc@1: 87.5000 (83.0317)  Acc@5: 100.0000 (97.1394)  time: 0.3475  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1770/3750]  eta: 0:11:30  Lr: 0.001875  Loss: -0.8917  Acc@1: 81.2500 (83.0110)  Acc@5: 93.7500 (97.1309)  time: 0.3473  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1780/3750]  eta: 0:11:27  Lr: 0.001875  Loss: -1.0535  Acc@1: 81.2500 (83.0117)  Acc@5: 100.0000 (97.1364)  time: 0.3490  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1790/3750]  eta: 0:11:23  Lr: 0.001875  Loss: -0.8822  Acc@1: 87.5000 (83.0332)  Acc@5: 100.0000 (97.1385)  time: 0.3497  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [1800/3750]  eta: 0:11:20  Lr: 0.001875  Loss: -0.9183  Acc@1: 87.5000 (83.0303)  Acc@5: 100.0000 (97.1335)  time: 0.3488  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [1810/3750]  eta: 0:11:16  Lr: 0.001875  Loss: -0.3183  Acc@1: 87.5000 (83.0377)  Acc@5: 100.0000 (97.1287)  time: 0.3475  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [1820/3750]  eta: 0:11:13  Lr: 0.001875  Loss: -0.8541  Acc@1: 87.5000 (83.0450)  Acc@5: 100.0000 (97.1341)  time: 0.3490  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [1830/3750]  eta: 0:11:10  Lr: 0.001875  Loss: -1.2290  Acc@1: 87.5000 (83.0694)  Acc@5: 100.0000 (97.1361)  time: 0.3498  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [1840/3750]  eta: 0:11:06  Lr: 0.001875  Loss: -1.2401  Acc@1: 81.2500 (83.0493)  Acc@5: 100.0000 (97.1313)  time: 0.3487  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1850/3750]  eta: 0:11:03  Lr: 0.001875  Loss: -0.5762  Acc@1: 81.2500 (83.0227)  Acc@5: 93.7500 (97.1266)  time: 0.3488  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [1860/3750]  eta: 0:10:59  Lr: 0.001875  Loss: -0.8548  Acc@1: 81.2500 (82.9997)  Acc@5: 93.7500 (97.1218)  time: 0.3507  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [1870/3750]  eta: 0:10:56  Lr: 0.001875  Loss: -1.0088  Acc@1: 75.0000 (82.9703)  Acc@5: 100.0000 (97.1239)  time: 0.3506  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [1880/3750]  eta: 0:10:52  Lr: 0.001875  Loss: -0.7888  Acc@1: 81.2500 (82.9712)  Acc@5: 100.0000 (97.1159)  time: 0.3488  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [1890/3750]  eta: 0:10:49  Lr: 0.001875  Loss: -1.0926  Acc@1: 81.2500 (82.9852)  Acc@5: 93.7500 (97.1146)  time: 0.3485  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [1900/3750]  eta: 0:10:45  Lr: 0.001875  Loss: -0.4479  Acc@1: 87.5000 (82.9794)  Acc@5: 100.0000 (97.1199)  time: 0.3500  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [1910/3750]  eta: 0:10:42  Lr: 0.001875  Loss: -0.6924  Acc@1: 87.5000 (82.9965)  Acc@5: 100.0000 (97.1187)  time: 0.3491  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [1920/3750]  eta: 0:10:38  Lr: 0.001875  Loss: -1.1994  Acc@1: 87.5000 (83.0102)  Acc@5: 100.0000 (97.1239)  time: 0.3460  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1930/3750]  eta: 0:10:35  Lr: 0.001875  Loss: -1.0339  Acc@1: 87.5000 (83.0043)  Acc@5: 100.0000 (97.1323)  time: 0.3455  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1940/3750]  eta: 0:10:31  Lr: 0.001875  Loss: -1.0802  Acc@1: 81.2500 (83.0146)  Acc@5: 100.0000 (97.1374)  time: 0.3469  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [1950/3750]  eta: 0:10:28  Lr: 0.001875  Loss: -1.1827  Acc@1: 87.5000 (83.0279)  Acc@5: 100.0000 (97.1425)  time: 0.3489  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [1960/3750]  eta: 0:10:24  Lr: 0.001875  Loss: -1.2295  Acc@1: 87.5000 (83.0412)  Acc@5: 100.0000 (97.1443)  time: 0.3489  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [1970/3750]  eta: 0:10:21  Lr: 0.001875  Loss: -0.9119  Acc@1: 81.2500 (83.0321)  Acc@5: 93.7500 (97.1271)  time: 0.3478  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [1980/3750]  eta: 0:10:17  Lr: 0.001875  Loss: -1.0820  Acc@1: 81.2500 (83.0294)  Acc@5: 93.7500 (97.1290)  time: 0.3487  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [1990/3750]  eta: 0:10:14  Lr: 0.001875  Loss: -1.1257  Acc@1: 81.2500 (83.0142)  Acc@5: 100.0000 (97.1246)  time: 0.3492  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [2000/3750]  eta: 0:10:10  Lr: 0.001875  Loss: -1.3166  Acc@1: 87.5000 (83.0335)  Acc@5: 93.7500 (97.1233)  time: 0.3478  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [2010/3750]  eta: 0:10:07  Lr: 0.001875  Loss: -1.1465  Acc@1: 81.2500 (83.0184)  Acc@5: 100.0000 (97.1314)  time: 0.3482  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [2020/3750]  eta: 0:10:03  Lr: 0.001875  Loss: -0.8791  Acc@1: 81.2500 (83.0251)  Acc@5: 100.0000 (97.1394)  time: 0.3488  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [2030/3750]  eta: 0:10:00  Lr: 0.001875  Loss: -1.1171  Acc@1: 87.5000 (83.0348)  Acc@5: 100.0000 (97.1443)  time: 0.3486  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [2040/3750]  eta: 0:09:56  Lr: 0.001875  Loss: -1.0172  Acc@1: 87.5000 (83.0567)  Acc@5: 100.0000 (97.1491)  time: 0.3504  data: 0.0012  max mem: 2500
Train: Epoch[5/5]  [2050/3750]  eta: 0:09:53  Lr: 0.001875  Loss: -0.9701  Acc@1: 87.5000 (83.0570)  Acc@5: 93.7500 (97.1294)  time: 0.3506  data: 0.0010  max mem: 2500
Train: Epoch[5/5]  [2060/3750]  eta: 0:09:49  Lr: 0.001875  Loss: -0.7565  Acc@1: 81.2500 (83.0665)  Acc@5: 93.7500 (97.1312)  time: 0.3490  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [2070/3750]  eta: 0:09:46  Lr: 0.001875  Loss: -0.8684  Acc@1: 87.5000 (83.0698)  Acc@5: 100.0000 (97.1300)  time: 0.3513  data: 0.0013  max mem: 2500
Train: Epoch[5/5]  [2080/3750]  eta: 0:09:42  Lr: 0.001875  Loss: -0.5138  Acc@1: 81.2500 (83.0640)  Acc@5: 100.0000 (97.1378)  time: 0.3513  data: 0.0013  max mem: 2500
Train: Epoch[5/5]  [2090/3750]  eta: 0:09:39  Lr: 0.001875  Loss: -1.2767  Acc@1: 75.0000 (83.0464)  Acc@5: 100.0000 (97.1365)  time: 0.3492  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [2100/3750]  eta: 0:09:35  Lr: 0.001875  Loss: -0.9156  Acc@1: 81.2500 (83.0378)  Acc@5: 100.0000 (97.1353)  time: 0.3500  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2110/3750]  eta: 0:09:32  Lr: 0.001875  Loss: -0.7860  Acc@1: 81.2500 (83.0442)  Acc@5: 93.7500 (97.1311)  time: 0.3494  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [2120/3750]  eta: 0:09:28  Lr: 0.001875  Loss: -1.2782  Acc@1: 81.2500 (83.0416)  Acc@5: 93.7500 (97.1240)  time: 0.3486  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [2130/3750]  eta: 0:09:25  Lr: 0.001875  Loss: -0.7366  Acc@1: 81.2500 (83.0479)  Acc@5: 93.7500 (97.1199)  time: 0.3493  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [2140/3750]  eta: 0:09:21  Lr: 0.001875  Loss: -0.9080  Acc@1: 81.2500 (83.0395)  Acc@5: 93.7500 (97.1188)  time: 0.3496  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [2150/3750]  eta: 0:09:18  Lr: 0.001875  Loss: -0.8326  Acc@1: 81.2500 (83.0399)  Acc@5: 93.7500 (97.1147)  time: 0.3494  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [2160/3750]  eta: 0:09:14  Lr: 0.001875  Loss: -0.8129  Acc@1: 81.2500 (83.0200)  Acc@5: 100.0000 (97.1136)  time: 0.3499  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [2170/3750]  eta: 0:09:11  Lr: 0.001875  Loss: -1.2491  Acc@1: 87.5000 (83.0378)  Acc@5: 100.0000 (97.1240)  time: 0.3505  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [2180/3750]  eta: 0:09:07  Lr: 0.001875  Loss: -0.8007  Acc@1: 81.2500 (83.0238)  Acc@5: 100.0000 (97.1114)  time: 0.3492  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [2190/3750]  eta: 0:09:04  Lr: 0.001875  Loss: -1.2102  Acc@1: 81.2500 (83.0072)  Acc@5: 100.0000 (97.1217)  time: 0.3482  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [2200/3750]  eta: 0:09:00  Lr: 0.001875  Loss: -0.7499  Acc@1: 81.2500 (83.0077)  Acc@5: 100.0000 (97.1320)  time: 0.3501  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [2210/3750]  eta: 0:08:57  Lr: 0.001875  Loss: -0.8056  Acc@1: 81.2500 (82.9969)  Acc@5: 100.0000 (97.1336)  time: 0.3527  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [2220/3750]  eta: 0:08:54  Lr: 0.001875  Loss: -1.0517  Acc@1: 81.2500 (82.9863)  Acc@5: 100.0000 (97.1297)  time: 0.3520  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [2230/3750]  eta: 0:08:50  Lr: 0.001875  Loss: -1.2789  Acc@1: 81.2500 (82.9925)  Acc@5: 93.7500 (97.1257)  time: 0.3497  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [2240/3750]  eta: 0:08:47  Lr: 0.001875  Loss: -1.2692  Acc@1: 81.2500 (82.9903)  Acc@5: 100.0000 (97.1302)  time: 0.3492  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2250/3750]  eta: 0:08:43  Lr: 0.001875  Loss: -1.3303  Acc@1: 87.5000 (83.0048)  Acc@5: 100.0000 (97.1291)  time: 0.3475  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2260/3750]  eta: 0:08:40  Lr: 0.001875  Loss: -0.3835  Acc@1: 87.5000 (83.0053)  Acc@5: 100.0000 (97.1279)  time: 0.3469  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2270/3750]  eta: 0:08:36  Lr: 0.001875  Loss: -1.2185  Acc@1: 81.2500 (82.9976)  Acc@5: 100.0000 (97.1378)  time: 0.3474  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [2280/3750]  eta: 0:08:33  Lr: 0.001875  Loss: -0.8999  Acc@1: 81.2500 (82.9844)  Acc@5: 100.0000 (97.1367)  time: 0.3483  data: 0.0014  max mem: 2500
Train: Epoch[5/5]  [2290/3750]  eta: 0:08:29  Lr: 0.001875  Loss: -0.7957  Acc@1: 81.2500 (82.9851)  Acc@5: 100.0000 (97.1410)  time: 0.3485  data: 0.0013  max mem: 2500
Train: Epoch[5/5]  [2300/3750]  eta: 0:08:26  Lr: 0.001875  Loss: -1.0682  Acc@1: 81.2500 (82.9884)  Acc@5: 100.0000 (97.1507)  time: 0.3489  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [2310/3750]  eta: 0:08:22  Lr: 0.001875  Loss: -1.2568  Acc@1: 81.2500 (82.9890)  Acc@5: 100.0000 (97.1549)  time: 0.3490  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [2320/3750]  eta: 0:08:19  Lr: 0.001875  Loss: -1.1791  Acc@1: 81.2500 (83.0003)  Acc@5: 100.0000 (97.1510)  time: 0.3478  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [2330/3750]  eta: 0:08:15  Lr: 0.001875  Loss: -1.2118  Acc@1: 81.2500 (83.0062)  Acc@5: 100.0000 (97.1525)  time: 0.3491  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [2340/3750]  eta: 0:08:12  Lr: 0.001875  Loss: -1.1096  Acc@1: 87.5000 (83.0308)  Acc@5: 100.0000 (97.1567)  time: 0.3498  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [2350/3750]  eta: 0:08:08  Lr: 0.001875  Loss: -0.8438  Acc@1: 81.2500 (83.0046)  Acc@5: 100.0000 (97.1475)  time: 0.3488  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [2360/3750]  eta: 0:08:05  Lr: 0.001875  Loss: -0.7411  Acc@1: 81.2500 (83.0077)  Acc@5: 93.7500 (97.1437)  time: 0.3494  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [2370/3750]  eta: 0:08:01  Lr: 0.001875  Loss: -0.6430  Acc@1: 87.5000 (83.0161)  Acc@5: 100.0000 (97.1478)  time: 0.3492  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [2380/3750]  eta: 0:07:58  Lr: 0.001875  Loss: -1.2717  Acc@1: 87.5000 (83.0008)  Acc@5: 100.0000 (97.1519)  time: 0.3482  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [2390/3750]  eta: 0:07:54  Lr: 0.001875  Loss: -1.2954  Acc@1: 81.2500 (82.9935)  Acc@5: 100.0000 (97.1455)  time: 0.3485  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [2400/3750]  eta: 0:07:51  Lr: 0.001875  Loss: -0.5638  Acc@1: 81.2500 (82.9863)  Acc@5: 100.0000 (97.1470)  time: 0.3476  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [2410/3750]  eta: 0:07:47  Lr: 0.001875  Loss: -1.2659  Acc@1: 81.2500 (82.9791)  Acc@5: 100.0000 (97.1433)  time: 0.3474  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [2420/3750]  eta: 0:07:44  Lr: 0.001875  Loss: -1.1660  Acc@1: 81.2500 (82.9797)  Acc@5: 100.0000 (97.1422)  time: 0.3487  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [2430/3750]  eta: 0:07:40  Lr: 0.001875  Loss: -0.7977  Acc@1: 81.2500 (82.9828)  Acc@5: 100.0000 (97.1488)  time: 0.3490  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [2440/3750]  eta: 0:07:37  Lr: 0.001875  Loss: -0.3732  Acc@1: 81.2500 (82.9706)  Acc@5: 100.0000 (97.1400)  time: 0.3496  data: 0.0017  max mem: 2500
Train: Epoch[5/5]  [2450/3750]  eta: 0:07:33  Lr: 0.001875  Loss: -1.1626  Acc@1: 81.2500 (82.9661)  Acc@5: 93.7500 (97.1313)  time: 0.3490  data: 0.0015  max mem: 2500
Train: Epoch[5/5]  [2460/3750]  eta: 0:07:30  Lr: 0.001875  Loss: -1.5065  Acc@1: 81.2500 (82.9617)  Acc@5: 100.0000 (97.1353)  time: 0.3475  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [2470/3750]  eta: 0:07:26  Lr: 0.001875  Loss: -1.2575  Acc@1: 81.2500 (82.9649)  Acc@5: 100.0000 (97.1343)  time: 0.3481  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [2480/3750]  eta: 0:07:23  Lr: 0.001875  Loss: -0.8836  Acc@1: 81.2500 (82.9681)  Acc@5: 100.0000 (97.1383)  time: 0.3493  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [2490/3750]  eta: 0:07:19  Lr: 0.001875  Loss: -0.5604  Acc@1: 81.2500 (82.9461)  Acc@5: 100.0000 (97.1246)  time: 0.3493  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [2500/3750]  eta: 0:07:16  Lr: 0.001875  Loss: -1.0238  Acc@1: 81.2500 (82.9518)  Acc@5: 93.7500 (97.1212)  time: 0.3478  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [2510/3750]  eta: 0:07:12  Lr: 0.001875  Loss: -1.1827  Acc@1: 81.2500 (82.9575)  Acc@5: 100.0000 (97.1251)  time: 0.3475  data: 0.0013  max mem: 2500
Train: Epoch[5/5]  [2520/3750]  eta: 0:07:09  Lr: 0.001875  Loss: -1.0386  Acc@1: 81.2500 (82.9482)  Acc@5: 100.0000 (97.1217)  time: 0.3485  data: 0.0013  max mem: 2500
Train: Epoch[5/5]  [2530/3750]  eta: 0:07:05  Lr: 0.001875  Loss: -1.2819  Acc@1: 81.2500 (82.9563)  Acc@5: 100.0000 (97.1232)  time: 0.3498  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [2540/3750]  eta: 0:07:02  Lr: 0.001875  Loss: -1.2562  Acc@1: 81.2500 (82.9570)  Acc@5: 100.0000 (97.1271)  time: 0.3488  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [2550/3750]  eta: 0:06:58  Lr: 0.001875  Loss: -1.1865  Acc@1: 87.5000 (82.9822)  Acc@5: 100.0000 (97.1310)  time: 0.3474  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [2560/3750]  eta: 0:06:55  Lr: 0.001875  Loss: -1.3344  Acc@1: 87.5000 (82.9876)  Acc@5: 100.0000 (97.1349)  time: 0.3473  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [2570/3750]  eta: 0:06:51  Lr: 0.001875  Loss: -1.0150  Acc@1: 87.5000 (82.9833)  Acc@5: 100.0000 (97.1315)  time: 0.3469  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [2580/3750]  eta: 0:06:48  Lr: 0.001875  Loss: -1.1814  Acc@1: 87.5000 (82.9911)  Acc@5: 100.0000 (97.1329)  time: 0.3478  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [2590/3750]  eta: 0:06:44  Lr: 0.001875  Loss: -0.6999  Acc@1: 81.2500 (82.9940)  Acc@5: 100.0000 (97.1367)  time: 0.3488  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [2600/3750]  eta: 0:06:41  Lr: 0.001875  Loss: -0.6836  Acc@1: 81.2500 (82.9561)  Acc@5: 100.0000 (97.1309)  time: 0.3495  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [2610/3750]  eta: 0:06:37  Lr: 0.001875  Loss: -1.1253  Acc@1: 81.2500 (82.9639)  Acc@5: 100.0000 (97.1275)  time: 0.3484  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [2620/3750]  eta: 0:06:34  Lr: 0.001875  Loss: -1.2209  Acc@1: 87.5000 (82.9693)  Acc@5: 100.0000 (97.1313)  time: 0.3490  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [2630/3750]  eta: 0:06:30  Lr: 0.001875  Loss: -0.9444  Acc@1: 87.5000 (82.9818)  Acc@5: 100.0000 (97.1327)  time: 0.3502  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [2640/3750]  eta: 0:06:27  Lr: 0.001875  Loss: -0.9539  Acc@1: 81.2500 (82.9728)  Acc@5: 100.0000 (97.1365)  time: 0.3493  data: 0.0011  max mem: 2500
Train: Epoch[5/5]  [2650/3750]  eta: 0:06:23  Lr: 0.001875  Loss: -0.9513  Acc@1: 75.0000 (82.9404)  Acc@5: 100.0000 (97.1379)  time: 0.3491  data: 0.0011  max mem: 2500
Train: Epoch[5/5]  [2660/3750]  eta: 0:06:20  Lr: 0.001875  Loss: -1.0944  Acc@1: 81.2500 (82.9481)  Acc@5: 100.0000 (97.1392)  time: 0.3492  data: 0.0012  max mem: 2500
Train: Epoch[5/5]  [2670/3750]  eta: 0:06:16  Lr: 0.001875  Loss: -1.2784  Acc@1: 81.2500 (82.9207)  Acc@5: 93.7500 (97.1336)  time: 0.3490  data: 0.0013  max mem: 2500
Train: Epoch[5/5]  [2680/3750]  eta: 0:06:13  Lr: 0.001875  Loss: -0.9504  Acc@1: 81.2500 (82.9238)  Acc@5: 93.7500 (97.1279)  time: 0.3495  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [2690/3750]  eta: 0:06:09  Lr: 0.001875  Loss: -0.5084  Acc@1: 81.2500 (82.9153)  Acc@5: 93.7500 (97.1224)  time: 0.3504  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2700/3750]  eta: 0:06:06  Lr: 0.001875  Loss: -1.0053  Acc@1: 87.5000 (82.9299)  Acc@5: 93.7500 (97.1214)  time: 0.3491  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [2710/3750]  eta: 0:06:02  Lr: 0.001875  Loss: -1.0763  Acc@1: 87.5000 (82.9214)  Acc@5: 93.7500 (97.1159)  time: 0.3474  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [2720/3750]  eta: 0:05:59  Lr: 0.001875  Loss: -1.3326  Acc@1: 81.2500 (82.9107)  Acc@5: 100.0000 (97.1150)  time: 0.3467  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [2730/3750]  eta: 0:05:55  Lr: 0.001875  Loss: -1.1434  Acc@1: 81.2500 (82.9229)  Acc@5: 100.0000 (97.1210)  time: 0.3478  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [2740/3750]  eta: 0:05:52  Lr: 0.001875  Loss: -0.6884  Acc@1: 87.5000 (82.9328)  Acc@5: 100.0000 (97.1270)  time: 0.3484  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [2750/3750]  eta: 0:05:48  Lr: 0.001875  Loss: -1.2591  Acc@1: 87.5000 (82.9471)  Acc@5: 100.0000 (97.1283)  time: 0.3485  data: 0.0012  max mem: 2500
Train: Epoch[5/5]  [2760/3750]  eta: 0:05:45  Lr: 0.001875  Loss: -0.9823  Acc@1: 81.2500 (82.9342)  Acc@5: 100.0000 (97.1251)  time: 0.3497  data: 0.0014  max mem: 2500
Train: Epoch[5/5]  [2770/3750]  eta: 0:05:41  Lr: 0.001875  Loss: -1.2807  Acc@1: 81.2500 (82.9349)  Acc@5: 93.7500 (97.1197)  time: 0.3488  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [2780/3750]  eta: 0:05:38  Lr: 0.001875  Loss: -0.8400  Acc@1: 81.2500 (82.9355)  Acc@5: 93.7500 (97.1143)  time: 0.3476  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [2790/3750]  eta: 0:05:34  Lr: 0.001875  Loss: -1.0927  Acc@1: 81.2500 (82.9317)  Acc@5: 100.0000 (97.1157)  time: 0.3488  data: 0.0013  max mem: 2500
Train: Epoch[5/5]  [2800/3750]  eta: 0:05:31  Lr: 0.001875  Loss: -0.8487  Acc@1: 81.2500 (82.9235)  Acc@5: 100.0000 (97.1126)  time: 0.3491  data: 0.0019  max mem: 2500
Train: Epoch[5/5]  [2810/3750]  eta: 0:05:27  Lr: 0.001875  Loss: -0.9816  Acc@1: 81.2500 (82.9287)  Acc@5: 100.0000 (97.1140)  time: 0.3477  data: 0.0012  max mem: 2500
Train: Epoch[5/5]  [2820/3750]  eta: 0:05:24  Lr: 0.001875  Loss: -1.2423  Acc@1: 81.2500 (82.9205)  Acc@5: 100.0000 (97.1176)  time: 0.3489  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [2830/3750]  eta: 0:05:21  Lr: 0.001875  Loss: -1.2320  Acc@1: 81.2500 (82.9256)  Acc@5: 100.0000 (97.1145)  time: 0.3494  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [2840/3750]  eta: 0:05:17  Lr: 0.001875  Loss: -1.0663  Acc@1: 81.2500 (82.9175)  Acc@5: 100.0000 (97.1247)  time: 0.3480  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [2850/3750]  eta: 0:05:14  Lr: 0.001875  Loss: -0.8580  Acc@1: 81.2500 (82.9270)  Acc@5: 100.0000 (97.1304)  time: 0.3507  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [2860/3750]  eta: 0:05:10  Lr: 0.001875  Loss: -0.9957  Acc@1: 81.2500 (82.9190)  Acc@5: 100.0000 (97.1317)  time: 0.3513  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [2870/3750]  eta: 0:05:07  Lr: 0.001875  Loss: -1.1649  Acc@1: 81.2500 (82.9197)  Acc@5: 100.0000 (97.1286)  time: 0.3475  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2880/3750]  eta: 0:05:03  Lr: 0.001875  Loss: -0.4851  Acc@1: 81.2500 (82.9204)  Acc@5: 100.0000 (97.1299)  time: 0.3490  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [2890/3750]  eta: 0:05:00  Lr: 0.001875  Loss: -1.2115  Acc@1: 81.2500 (82.9125)  Acc@5: 100.0000 (97.1290)  time: 0.3503  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [2900/3750]  eta: 0:04:56  Lr: 0.001875  Loss: -0.8016  Acc@1: 81.2500 (82.9175)  Acc@5: 100.0000 (97.1260)  time: 0.3503  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [2910/3750]  eta: 0:04:53  Lr: 0.001875  Loss: -1.1590  Acc@1: 87.5000 (82.9204)  Acc@5: 93.7500 (97.1187)  time: 0.3508  data: 0.0012  max mem: 2500
Train: Epoch[5/5]  [2920/3750]  eta: 0:04:49  Lr: 0.001875  Loss: -1.0380  Acc@1: 81.2500 (82.9147)  Acc@5: 93.7500 (97.1136)  time: 0.3493  data: 0.0011  max mem: 2500
Train: Epoch[5/5]  [2930/3750]  eta: 0:04:46  Lr: 0.001875  Loss: -0.9950  Acc@1: 81.2500 (82.8962)  Acc@5: 93.7500 (97.1042)  time: 0.3480  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [2940/3750]  eta: 0:04:42  Lr: 0.001875  Loss: -1.4679  Acc@1: 81.2500 (82.8948)  Acc@5: 93.7500 (97.1035)  time: 0.3482  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [2950/3750]  eta: 0:04:39  Lr: 0.001875  Loss: -1.3147  Acc@1: 87.5000 (82.9189)  Acc@5: 100.0000 (97.1069)  time: 0.3491  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [2960/3750]  eta: 0:04:35  Lr: 0.001875  Loss: -1.0666  Acc@1: 87.5000 (82.9196)  Acc@5: 100.0000 (97.1019)  time: 0.3484  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [2970/3750]  eta: 0:04:32  Lr: 0.001875  Loss: -1.3820  Acc@1: 81.2500 (82.9161)  Acc@5: 93.7500 (97.0948)  time: 0.3476  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [2980/3750]  eta: 0:04:28  Lr: 0.001875  Loss: -0.5889  Acc@1: 81.2500 (82.9168)  Acc@5: 100.0000 (97.0857)  time: 0.3485  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [2990/3750]  eta: 0:04:25  Lr: 0.001875  Loss: -0.6646  Acc@1: 81.2500 (82.9133)  Acc@5: 100.0000 (97.0850)  time: 0.3503  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [3000/3750]  eta: 0:04:21  Lr: 0.001875  Loss: -0.9735  Acc@1: 87.5000 (82.9224)  Acc@5: 100.0000 (97.0885)  time: 0.3505  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [3010/3750]  eta: 0:04:18  Lr: 0.001875  Loss: -1.2969  Acc@1: 81.2500 (82.9210)  Acc@5: 100.0000 (97.0919)  time: 0.3503  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [3020/3750]  eta: 0:04:14  Lr: 0.001875  Loss: -0.8671  Acc@1: 81.2500 (82.9196)  Acc@5: 100.0000 (97.0953)  time: 0.3512  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [3030/3750]  eta: 0:04:11  Lr: 0.001875  Loss: -1.2992  Acc@1: 81.2500 (82.9326)  Acc@5: 100.0000 (97.0987)  time: 0.3493  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3040/3750]  eta: 0:04:07  Lr: 0.001875  Loss: -1.0990  Acc@1: 87.5000 (82.9415)  Acc@5: 100.0000 (97.1000)  time: 0.3483  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3050/3750]  eta: 0:04:04  Lr: 0.001875  Loss: -1.3244  Acc@1: 81.2500 (82.9359)  Acc@5: 100.0000 (97.1055)  time: 0.3489  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [3060/3750]  eta: 0:04:00  Lr: 0.001875  Loss: -0.8104  Acc@1: 75.0000 (82.9202)  Acc@5: 100.0000 (97.1067)  time: 0.3490  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [3070/3750]  eta: 0:03:57  Lr: 0.001875  Loss: -0.8817  Acc@1: 75.0000 (82.9026)  Acc@5: 93.7500 (97.0979)  time: 0.3494  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [3080/3750]  eta: 0:03:53  Lr: 0.001875  Loss: -1.1573  Acc@1: 81.2500 (82.9033)  Acc@5: 93.7500 (97.0951)  time: 0.3493  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [3090/3750]  eta: 0:03:50  Lr: 0.001875  Loss: -1.0837  Acc@1: 81.2500 (82.9020)  Acc@5: 93.7500 (97.0944)  time: 0.3500  data: 0.0012  max mem: 2500
Train: Epoch[5/5]  [3100/3750]  eta: 0:03:46  Lr: 0.001875  Loss: -1.1757  Acc@1: 81.2500 (82.9108)  Acc@5: 100.0000 (97.0997)  time: 0.3496  data: 0.0013  max mem: 2500
Train: Epoch[5/5]  [3110/3750]  eta: 0:03:43  Lr: 0.001875  Loss: -0.7936  Acc@1: 87.5000 (82.9295)  Acc@5: 100.0000 (97.1010)  time: 0.3492  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [3120/3750]  eta: 0:03:39  Lr: 0.001875  Loss: -0.5375  Acc@1: 87.5000 (82.9302)  Acc@5: 100.0000 (97.1043)  time: 0.3505  data: 0.0016  max mem: 2500
Train: Epoch[5/5]  [3130/3750]  eta: 0:03:36  Lr: 0.001875  Loss: -1.0815  Acc@1: 81.2500 (82.9328)  Acc@5: 100.0000 (97.0996)  time: 0.3499  data: 0.0015  max mem: 2500
Train: Epoch[5/5]  [3140/3750]  eta: 0:03:32  Lr: 0.001875  Loss: -1.0959  Acc@1: 81.2500 (82.9274)  Acc@5: 100.0000 (97.1048)  time: 0.3497  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [3150/3750]  eta: 0:03:29  Lr: 0.001875  Loss: -1.0806  Acc@1: 81.2500 (82.9261)  Acc@5: 100.0000 (97.1021)  time: 0.3500  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [3160/3750]  eta: 0:03:25  Lr: 0.001875  Loss: -0.5418  Acc@1: 81.2500 (82.9128)  Acc@5: 93.7500 (97.0935)  time: 0.3486  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [3170/3750]  eta: 0:03:22  Lr: 0.001875  Loss: -0.5124  Acc@1: 87.5000 (82.9253)  Acc@5: 100.0000 (97.0967)  time: 0.3478  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [3180/3750]  eta: 0:03:18  Lr: 0.001875  Loss: -0.8142  Acc@1: 87.5000 (82.9299)  Acc@5: 100.0000 (97.0960)  time: 0.3490  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [3190/3750]  eta: 0:03:15  Lr: 0.001875  Loss: -0.1257  Acc@1: 81.2500 (82.9285)  Acc@5: 100.0000 (97.0973)  time: 0.3504  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [3200/3750]  eta: 0:03:11  Lr: 0.001875  Loss: -0.8119  Acc@1: 81.2500 (82.9370)  Acc@5: 100.0000 (97.0986)  time: 0.3488  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [3210/3750]  eta: 0:03:08  Lr: 0.001875  Loss: -1.3106  Acc@1: 87.5000 (82.9492)  Acc@5: 100.0000 (97.1037)  time: 0.3487  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [3220/3750]  eta: 0:03:04  Lr: 0.001875  Loss: -0.9504  Acc@1: 81.2500 (82.9478)  Acc@5: 100.0000 (97.1030)  time: 0.3493  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [3230/3750]  eta: 0:03:01  Lr: 0.001875  Loss: -1.4018  Acc@1: 81.2500 (82.9581)  Acc@5: 100.0000 (97.1100)  time: 0.3475  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3240/3750]  eta: 0:02:57  Lr: 0.001875  Loss: -1.1460  Acc@1: 81.2500 (82.9586)  Acc@5: 100.0000 (97.1074)  time: 0.3481  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [3250/3750]  eta: 0:02:54  Lr: 0.001875  Loss: -1.2736  Acc@1: 81.2500 (82.9610)  Acc@5: 100.0000 (97.1086)  time: 0.3488  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3260/3750]  eta: 0:02:50  Lr: 0.001875  Loss: -1.3628  Acc@1: 87.5000 (82.9653)  Acc@5: 100.0000 (97.1079)  time: 0.3481  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [3270/3750]  eta: 0:02:47  Lr: 0.001875  Loss: -0.6254  Acc@1: 81.2500 (82.9544)  Acc@5: 100.0000 (97.1072)  time: 0.3510  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [3280/3750]  eta: 0:02:44  Lr: 0.001875  Loss: -1.1715  Acc@1: 81.2500 (82.9663)  Acc@5: 100.0000 (97.1064)  time: 0.3523  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [3290/3750]  eta: 0:02:40  Lr: 0.001875  Loss: -1.3325  Acc@1: 81.2500 (82.9706)  Acc@5: 100.0000 (97.1095)  time: 0.3502  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [3300/3750]  eta: 0:02:37  Lr: 0.001875  Loss: -0.9594  Acc@1: 81.2500 (82.9711)  Acc@5: 100.0000 (97.1183)  time: 0.3480  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [3310/3750]  eta: 0:02:33  Lr: 0.001875  Loss: -1.3405  Acc@1: 81.2500 (82.9734)  Acc@5: 100.0000 (97.1195)  time: 0.3473  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [3320/3750]  eta: 0:02:30  Lr: 0.001875  Loss: -1.2286  Acc@1: 81.2500 (82.9664)  Acc@5: 93.7500 (97.1112)  time: 0.3478  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [3330/3750]  eta: 0:02:26  Lr: 0.001875  Loss: -0.5131  Acc@1: 81.2500 (82.9556)  Acc@5: 100.0000 (97.1142)  time: 0.3475  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3340/3750]  eta: 0:02:23  Lr: 0.001875  Loss: -1.3608  Acc@1: 81.2500 (82.9542)  Acc@5: 100.0000 (97.1135)  time: 0.3494  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3350/3750]  eta: 0:02:19  Lr: 0.001875  Loss: -1.2244  Acc@1: 81.2500 (82.9566)  Acc@5: 100.0000 (97.1184)  time: 0.3498  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3360/3750]  eta: 0:02:16  Lr: 0.001875  Loss: -1.3025  Acc@1: 81.2500 (82.9627)  Acc@5: 100.0000 (97.1158)  time: 0.3475  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [3370/3750]  eta: 0:02:12  Lr: 0.001875  Loss: -0.9402  Acc@1: 87.5000 (82.9650)  Acc@5: 100.0000 (97.1170)  time: 0.3469  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [3380/3750]  eta: 0:02:09  Lr: 0.001875  Loss: -0.8942  Acc@1: 81.2500 (82.9636)  Acc@5: 93.7500 (97.1088)  time: 0.3473  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3390/3750]  eta: 0:02:05  Lr: 0.001875  Loss: -0.9538  Acc@1: 81.2500 (82.9623)  Acc@5: 100.0000 (97.1100)  time: 0.3476  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [3400/3750]  eta: 0:02:02  Lr: 0.001875  Loss: -0.7731  Acc@1: 87.5000 (82.9811)  Acc@5: 100.0000 (97.1148)  time: 0.3469  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [3410/3750]  eta: 0:01:58  Lr: 0.001875  Loss: -0.9237  Acc@1: 81.2500 (82.9669)  Acc@5: 100.0000 (97.1214)  time: 0.3466  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [3420/3750]  eta: 0:01:55  Lr: 0.001875  Loss: -1.2521  Acc@1: 81.2500 (82.9746)  Acc@5: 100.0000 (97.1152)  time: 0.3474  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [3430/3750]  eta: 0:01:51  Lr: 0.001875  Loss: -0.4323  Acc@1: 81.2500 (82.9478)  Acc@5: 100.0000 (97.1164)  time: 0.3478  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [3440/3750]  eta: 0:01:48  Lr: 0.001875  Loss: -1.0200  Acc@1: 75.0000 (82.9428)  Acc@5: 100.0000 (97.1229)  time: 0.3488  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [3450/3750]  eta: 0:01:44  Lr: 0.001875  Loss: -0.6252  Acc@1: 81.2500 (82.9361)  Acc@5: 100.0000 (97.1222)  time: 0.3481  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [3460/3750]  eta: 0:01:41  Lr: 0.001875  Loss: -0.9895  Acc@1: 81.2500 (82.9330)  Acc@5: 100.0000 (97.1197)  time: 0.3470  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [3470/3750]  eta: 0:01:37  Lr: 0.001875  Loss: -0.9947  Acc@1: 81.2500 (82.9390)  Acc@5: 100.0000 (97.1190)  time: 0.3470  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [3480/3750]  eta: 0:01:34  Lr: 0.001875  Loss: -0.2164  Acc@1: 81.2500 (82.9323)  Acc@5: 100.0000 (97.1129)  time: 0.3478  data: 0.0014  max mem: 2500
Train: Epoch[5/5]  [3490/3750]  eta: 0:01:30  Lr: 0.001875  Loss: -1.1222  Acc@1: 81.2500 (82.9383)  Acc@5: 100.0000 (97.1176)  time: 0.3498  data: 0.0015  max mem: 2500
Train: Epoch[5/5]  [3500/3750]  eta: 0:01:27  Lr: 0.001875  Loss: -1.0078  Acc@1: 87.5000 (82.9549)  Acc@5: 100.0000 (97.1240)  time: 0.3500  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [3510/3750]  eta: 0:01:23  Lr: 0.001875  Loss: -1.3065  Acc@1: 87.5000 (82.9536)  Acc@5: 100.0000 (97.1251)  time: 0.3481  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [3520/3750]  eta: 0:01:20  Lr: 0.001875  Loss: -0.8203  Acc@1: 81.2500 (82.9612)  Acc@5: 100.0000 (97.1208)  time: 0.3479  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [3530/3750]  eta: 0:01:16  Lr: 0.001875  Loss: -1.0645  Acc@1: 81.2500 (82.9616)  Acc@5: 93.7500 (97.1184)  time: 0.3494  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [3540/3750]  eta: 0:01:13  Lr: 0.001875  Loss: -1.0804  Acc@1: 81.2500 (82.9568)  Acc@5: 100.0000 (97.1195)  time: 0.3482  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [3550/3750]  eta: 0:01:09  Lr: 0.001875  Loss: -0.8322  Acc@1: 81.2500 (82.9520)  Acc@5: 100.0000 (97.1188)  time: 0.3473  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [3560/3750]  eta: 0:01:06  Lr: 0.001875  Loss: -0.7523  Acc@1: 87.5000 (82.9665)  Acc@5: 100.0000 (97.1198)  time: 0.3481  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [3570/3750]  eta: 0:01:02  Lr: 0.001875  Loss: -1.1123  Acc@1: 87.5000 (82.9687)  Acc@5: 100.0000 (97.1157)  time: 0.3480  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [3580/3750]  eta: 0:00:59  Lr: 0.001875  Loss: -1.0361  Acc@1: 81.2500 (82.9691)  Acc@5: 93.7500 (97.1150)  time: 0.3482  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [3590/3750]  eta: 0:00:55  Lr: 0.001875  Loss: -1.2213  Acc@1: 81.2500 (82.9661)  Acc@5: 100.0000 (97.1161)  time: 0.3486  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [3600/3750]  eta: 0:00:52  Lr: 0.001875  Loss: -1.3340  Acc@1: 87.5000 (82.9804)  Acc@5: 100.0000 (97.1206)  time: 0.3474  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [3610/3750]  eta: 0:00:48  Lr: 0.001875  Loss: -1.4111  Acc@1: 87.5000 (82.9877)  Acc@5: 100.0000 (97.1216)  time: 0.3473  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [3620/3750]  eta: 0:00:45  Lr: 0.001875  Loss: -1.1365  Acc@1: 87.5000 (83.0019)  Acc@5: 100.0000 (97.1279)  time: 0.3490  data: 0.0020  max mem: 2500
Train: Epoch[5/5]  [3630/3750]  eta: 0:00:41  Lr: 0.001875  Loss: -1.2288  Acc@1: 87.5000 (83.0160)  Acc@5: 100.0000 (97.1306)  time: 0.3495  data: 0.0018  max mem: 2500
Train: Epoch[5/5]  [3640/3750]  eta: 0:00:38  Lr: 0.001875  Loss: -1.1466  Acc@1: 87.5000 (83.0078)  Acc@5: 100.0000 (97.1299)  time: 0.3491  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [3650/3750]  eta: 0:00:34  Lr: 0.001875  Loss: -1.3987  Acc@1: 81.2500 (83.0184)  Acc@5: 100.0000 (97.1326)  time: 0.3516  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [3660/3750]  eta: 0:00:31  Lr: 0.001875  Loss: -0.9436  Acc@1: 81.2500 (83.0186)  Acc@5: 100.0000 (97.1336)  time: 0.3514  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [3670/3750]  eta: 0:00:27  Lr: 0.001875  Loss: -0.9099  Acc@1: 81.2500 (83.0206)  Acc@5: 100.0000 (97.1346)  time: 0.3493  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [3680/3750]  eta: 0:00:24  Lr: 0.001875  Loss: -1.2348  Acc@1: 87.5000 (83.0277)  Acc@5: 100.0000 (97.1322)  time: 0.3485  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [3690/3750]  eta: 0:00:20  Lr: 0.001875  Loss: -0.6402  Acc@1: 81.2500 (83.0263)  Acc@5: 100.0000 (97.1298)  time: 0.3470  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [3700/3750]  eta: 0:00:17  Lr: 0.001875  Loss: -0.6161  Acc@1: 81.2500 (83.0282)  Acc@5: 93.7500 (97.1258)  time: 0.3474  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [3710/3750]  eta: 0:00:13  Lr: 0.001875  Loss: -1.1389  Acc@1: 81.2500 (83.0150)  Acc@5: 100.0000 (97.1268)  time: 0.3481  data: 0.0013  max mem: 2500
Train: Epoch[5/5]  [3720/3750]  eta: 0:00:10  Lr: 0.001875  Loss: -1.3597  Acc@1: 81.2500 (83.0220)  Acc@5: 100.0000 (97.1261)  time: 0.3480  data: 0.0013  max mem: 2500
Train: Epoch[5/5]  [3730/3750]  eta: 0:00:06  Lr: 0.001875  Loss: -1.3719  Acc@1: 87.5000 (83.0190)  Acc@5: 100.0000 (97.1238)  time: 0.3487  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [3740/3750]  eta: 0:00:03  Lr: 0.001875  Loss: -0.5382  Acc@1: 81.2500 (83.0059)  Acc@5: 100.0000 (97.1198)  time: 0.3483  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [3749/3750]  eta: 0:00:00  Lr: 0.001875  Loss: -1.3103  Acc@1: 81.2500 (83.0150)  Acc@5: 100.0000 (97.1250)  time: 0.3496  data: 0.0012  max mem: 2500
Train: Epoch[5/5] Total time: 0:21:49 (0.3491 s / it)
{0: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 1: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 2: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 3: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 4: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 5: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 6: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 7: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 8: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 9: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 10: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 11: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 12: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 13: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 14: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 15: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 16: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 17: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 18: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 19: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}}
Averaged stats: Lr: 0.001875  Loss: -1.3103  Acc@1: 81.2500 (83.0150)  Acc@5: 100.0000 (97.1250)
Test: [Task 1]  [   0/1627]  eta: 0:17:37  Loss: 1.4785 (1.4785)  Acc@1: 62.5000 (62.5000)  Acc@5: 93.7500 (93.7500)  time: 0.6499  data: 0.4330  max mem: 2500
Test: [Task 1]  [  10/1627]  eta: 0:06:52  Loss: 1.1249 (1.1364)  Acc@1: 68.7500 (67.6136)  Acc@5: 100.0000 (97.1591)  time: 0.2550  data: 0.0397  max mem: 2500
Test: [Task 1]  [  20/1627]  eta: 0:06:18  Loss: 1.1030 (1.0917)  Acc@1: 68.7500 (69.9405)  Acc@5: 100.0000 (95.5357)  time: 0.2150  data: 0.0004  max mem: 2500
Test: [Task 1]  [  30/1627]  eta: 0:06:05  Loss: 1.1065 (1.0911)  Acc@1: 75.0000 (70.3629)  Acc@5: 93.7500 (95.5645)  time: 0.2146  data: 0.0004  max mem: 2500
Test: [Task 1]  [  40/1627]  eta: 0:05:59  Loss: 1.1044 (1.0981)  Acc@1: 75.0000 (70.7317)  Acc@5: 93.7500 (95.2744)  time: 0.2164  data: 0.0004  max mem: 2500
Test: [Task 1]  [  50/1627]  eta: 0:05:54  Loss: 0.9345 (1.0776)  Acc@1: 75.0000 (72.0588)  Acc@5: 100.0000 (95.5882)  time: 0.2180  data: 0.0006  max mem: 2500
Test: [Task 1]  [  60/1627]  eta: 0:05:49  Loss: 1.0324 (1.0972)  Acc@1: 68.7500 (71.1066)  Acc@5: 93.7500 (95.3893)  time: 0.2169  data: 0.0006  max mem: 2500
Test: [Task 1]  [  70/1627]  eta: 0:05:46  Loss: 0.9541 (1.0901)  Acc@1: 62.5000 (71.6549)  Acc@5: 93.7500 (95.5986)  time: 0.2167  data: 0.0005  max mem: 2500
Test: [Task 1]  [  80/1627]  eta: 0:05:42  Loss: 0.8956 (1.0739)  Acc@1: 75.0000 (71.9907)  Acc@5: 100.0000 (95.9105)  time: 0.2170  data: 0.0005  max mem: 2500
Test: [Task 1]  [  90/1627]  eta: 0:05:40  Loss: 1.0075 (1.0922)  Acc@1: 68.7500 (71.2912)  Acc@5: 100.0000 (95.6731)  time: 0.2175  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 100/1627]  eta: 0:05:37  Loss: 1.2875 (1.1187)  Acc@1: 62.5000 (70.5446)  Acc@5: 93.7500 (95.2351)  time: 0.2170  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 110/1627]  eta: 0:05:34  Loss: 1.0673 (1.1174)  Acc@1: 68.7500 (70.4955)  Acc@5: 100.0000 (95.5518)  time: 0.2153  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 120/1627]  eta: 0:05:31  Loss: 1.0653 (1.1145)  Acc@1: 68.7500 (70.4029)  Acc@5: 100.0000 (95.6095)  time: 0.2155  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 130/1627]  eta: 0:05:28  Loss: 1.1086 (1.1190)  Acc@1: 68.7500 (70.3244)  Acc@5: 93.7500 (95.5630)  time: 0.2162  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 140/1627]  eta: 0:05:26  Loss: 1.0728 (1.1190)  Acc@1: 68.7500 (70.3014)  Acc@5: 93.7500 (95.6117)  time: 0.2164  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 150/1627]  eta: 0:05:23  Loss: 0.8669 (1.1048)  Acc@1: 75.0000 (70.8195)  Acc@5: 100.0000 (95.6540)  time: 0.2162  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 160/1627]  eta: 0:05:21  Loss: 0.8181 (1.0969)  Acc@1: 75.0000 (71.1957)  Acc@5: 100.0000 (95.7298)  time: 0.2160  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 170/1627]  eta: 0:05:18  Loss: 0.9969 (1.0930)  Acc@1: 75.0000 (71.1988)  Acc@5: 93.7500 (95.6871)  time: 0.2161  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 180/1627]  eta: 0:05:16  Loss: 1.0426 (1.0984)  Acc@1: 68.7500 (71.0290)  Acc@5: 93.7500 (95.6146)  time: 0.2165  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 190/1627]  eta: 0:05:14  Loss: 1.0705 (1.0948)  Acc@1: 68.7500 (71.2696)  Acc@5: 93.7500 (95.5825)  time: 0.2162  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 200/1627]  eta: 0:05:11  Loss: 1.0968 (1.0945)  Acc@1: 75.0000 (71.2376)  Acc@5: 100.0000 (95.7400)  time: 0.2157  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 210/1627]  eta: 0:05:09  Loss: 1.0968 (1.0935)  Acc@1: 75.0000 (71.5047)  Acc@5: 100.0000 (95.7346)  time: 0.2157  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 220/1627]  eta: 0:05:06  Loss: 0.9922 (1.0969)  Acc@1: 75.0000 (71.3518)  Acc@5: 93.7500 (95.7579)  time: 0.2160  data: 0.0005  max mem: 2500
Test: [Task 1]  [ 230/1627]  eta: 0:05:04  Loss: 1.0601 (1.0919)  Acc@1: 75.0000 (71.6450)  Acc@5: 93.7500 (95.7522)  time: 0.2158  data: 0.0005  max mem: 2500
Test: [Task 1]  [ 240/1627]  eta: 0:05:02  Loss: 0.9758 (1.0867)  Acc@1: 75.0000 (71.8620)  Acc@5: 93.7500 (95.8247)  time: 0.2154  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 250/1627]  eta: 0:05:00  Loss: 0.9195 (1.0903)  Acc@1: 75.0000 (71.8625)  Acc@5: 100.0000 (95.7171)  time: 0.2157  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 260/1627]  eta: 0:04:57  Loss: 1.0097 (1.0897)  Acc@1: 68.7500 (71.8630)  Acc@5: 93.7500 (95.7136)  time: 0.2159  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 270/1627]  eta: 0:04:55  Loss: 0.9872 (1.0825)  Acc@1: 68.7500 (71.9557)  Acc@5: 100.0000 (95.8256)  time: 0.2158  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 280/1627]  eta: 0:04:53  Loss: 0.9052 (1.0824)  Acc@1: 75.0000 (71.9528)  Acc@5: 100.0000 (95.7295)  time: 0.2159  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 290/1627]  eta: 0:04:50  Loss: 1.1283 (1.0823)  Acc@1: 75.0000 (71.9716)  Acc@5: 93.7500 (95.7045)  time: 0.2164  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 300/1627]  eta: 0:04:48  Loss: 1.0620 (1.0831)  Acc@1: 75.0000 (71.9061)  Acc@5: 93.7500 (95.7018)  time: 0.2166  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 310/1627]  eta: 0:04:46  Loss: 0.9711 (1.0852)  Acc@1: 68.7500 (71.8650)  Acc@5: 93.7500 (95.7195)  time: 0.2169  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 320/1627]  eta: 0:04:44  Loss: 1.0653 (1.0848)  Acc@1: 68.7500 (71.7874)  Acc@5: 93.7500 (95.6776)  time: 0.2166  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 330/1627]  eta: 0:04:42  Loss: 1.0635 (1.0829)  Acc@1: 68.7500 (71.7711)  Acc@5: 93.7500 (95.7326)  time: 0.2172  data: 0.0005  max mem: 2500
Test: [Task 1]  [ 340/1627]  eta: 0:04:40  Loss: 0.8832 (1.0830)  Acc@1: 68.7500 (71.7559)  Acc@5: 100.0000 (95.7478)  time: 0.2187  data: 0.0006  max mem: 2500
Test: [Task 1]  [ 350/1627]  eta: 0:04:37  Loss: 1.0575 (1.0850)  Acc@1: 68.7500 (71.6880)  Acc@5: 93.7500 (95.6731)  time: 0.2173  data: 0.0005  max mem: 2500
Test: [Task 1]  [ 360/1627]  eta: 0:04:35  Loss: 1.0428 (1.0838)  Acc@1: 68.7500 (71.6586)  Acc@5: 93.7500 (95.7410)  time: 0.2158  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 370/1627]  eta: 0:04:33  Loss: 0.9735 (1.0833)  Acc@1: 68.7500 (71.6813)  Acc@5: 100.0000 (95.7379)  time: 0.2159  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 380/1627]  eta: 0:04:31  Loss: 0.9801 (1.0818)  Acc@1: 75.0000 (71.8340)  Acc@5: 93.7500 (95.6857)  time: 0.2160  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 390/1627]  eta: 0:04:28  Loss: 1.0041 (1.0827)  Acc@1: 75.0000 (71.8350)  Acc@5: 93.7500 (95.6362)  time: 0.2157  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 400/1627]  eta: 0:04:26  Loss: 1.0201 (1.0834)  Acc@1: 68.7500 (71.8360)  Acc@5: 93.7500 (95.6203)  time: 0.2161  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 410/1627]  eta: 0:04:24  Loss: 0.8739 (1.0830)  Acc@1: 75.0000 (71.8826)  Acc@5: 93.7500 (95.6052)  time: 0.2161  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 420/1627]  eta: 0:04:22  Loss: 0.9726 (1.0820)  Acc@1: 75.0000 (71.9121)  Acc@5: 100.0000 (95.6502)  time: 0.2157  data: 0.0005  max mem: 2500
Test: [Task 1]  [ 430/1627]  eta: 0:04:20  Loss: 0.9667 (1.0803)  Acc@1: 75.0000 (71.9403)  Acc@5: 100.0000 (95.6787)  time: 0.2156  data: 0.0006  max mem: 2500
Test: [Task 1]  [ 440/1627]  eta: 0:04:17  Loss: 1.1403 (1.0804)  Acc@1: 68.7500 (71.9246)  Acc@5: 100.0000 (95.6916)  time: 0.2157  data: 0.0005  max mem: 2500
Test: [Task 1]  [ 450/1627]  eta: 0:04:15  Loss: 1.1461 (1.0835)  Acc@1: 68.7500 (71.7849)  Acc@5: 93.7500 (95.6208)  time: 0.2162  data: 0.0005  max mem: 2500
Test: [Task 1]  [ 460/1627]  eta: 0:04:13  Loss: 1.1228 (1.0837)  Acc@1: 68.7500 (71.8275)  Acc@5: 93.7500 (95.6480)  time: 0.2173  data: 0.0006  max mem: 2500
Test: [Task 1]  [ 470/1627]  eta: 0:04:11  Loss: 1.0126 (1.0817)  Acc@1: 75.0000 (71.8418)  Acc@5: 100.0000 (95.6741)  time: 0.2180  data: 0.0005  max mem: 2500
Test: [Task 1]  [ 480/1627]  eta: 0:04:09  Loss: 1.0601 (1.0856)  Acc@1: 68.7500 (71.7256)  Acc@5: 100.0000 (95.6601)  time: 0.2172  data: 0.0005  max mem: 2500
Test: [Task 1]  [ 490/1627]  eta: 0:04:06  Loss: 1.1327 (1.0856)  Acc@1: 62.5000 (71.6141)  Acc@5: 93.7500 (95.6594)  time: 0.2169  data: 0.0008  max mem: 2500
Test: [Task 1]  [ 500/1627]  eta: 0:04:04  Loss: 1.0508 (1.0873)  Acc@1: 68.7500 (71.5694)  Acc@5: 93.7500 (95.6213)  time: 0.2165  data: 0.0008  max mem: 2500
Test: [Task 1]  [ 510/1627]  eta: 0:04:02  Loss: 1.0711 (1.0932)  Acc@1: 68.7500 (71.4530)  Acc@5: 93.7500 (95.5846)  time: 0.2158  data: 0.0005  max mem: 2500
Test: [Task 1]  [ 520/1627]  eta: 0:04:00  Loss: 1.2582 (1.1002)  Acc@1: 68.7500 (71.3412)  Acc@5: 93.7500 (95.5254)  time: 0.2154  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 530/1627]  eta: 0:03:58  Loss: 1.0674 (1.0965)  Acc@1: 75.0000 (71.4454)  Acc@5: 93.7500 (95.5508)  time: 0.2152  data: 0.0006  max mem: 2500
Test: [Task 1]  [ 540/1627]  eta: 0:03:55  Loss: 1.0111 (1.0971)  Acc@1: 75.0000 (71.4995)  Acc@5: 93.7500 (95.5176)  time: 0.2154  data: 0.0006  max mem: 2500
Test: [Task 1]  [ 550/1627]  eta: 0:03:53  Loss: 1.2046 (1.0991)  Acc@1: 75.0000 (71.5177)  Acc@5: 93.7500 (95.5195)  time: 0.2155  data: 0.0005  max mem: 2500
Test: [Task 1]  [ 560/1627]  eta: 0:03:51  Loss: 1.2198 (1.1007)  Acc@1: 75.0000 (71.5129)  Acc@5: 93.7500 (95.5325)  time: 0.2158  data: 0.0005  max mem: 2500
Test: [Task 1]  [ 570/1627]  eta: 0:03:49  Loss: 1.0927 (1.0979)  Acc@1: 68.7500 (71.5412)  Acc@5: 93.7500 (95.5342)  time: 0.2163  data: 0.0013  max mem: 2500
Test: [Task 1]  [ 580/1627]  eta: 0:03:47  Loss: 1.0196 (1.0983)  Acc@1: 75.0000 (71.5792)  Acc@5: 100.0000 (95.5787)  time: 0.2167  data: 0.0013  max mem: 2500
Test: [Task 1]  [ 590/1627]  eta: 0:03:45  Loss: 1.0810 (1.0976)  Acc@1: 75.0000 (71.5948)  Acc@5: 100.0000 (95.6113)  time: 0.2165  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 600/1627]  eta: 0:03:42  Loss: 1.0810 (1.0995)  Acc@1: 68.7500 (71.5058)  Acc@5: 100.0000 (95.6323)  time: 0.2186  data: 0.0005  max mem: 2500
Test: [Task 1]  [ 610/1627]  eta: 0:03:40  Loss: 1.0816 (1.0974)  Acc@1: 75.0000 (71.5732)  Acc@5: 100.0000 (95.6526)  time: 0.2177  data: 0.0005  max mem: 2500
Test: [Task 1]  [ 620/1627]  eta: 0:03:38  Loss: 1.0142 (1.0990)  Acc@1: 75.0000 (71.5278)  Acc@5: 100.0000 (95.6220)  time: 0.2152  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 630/1627]  eta: 0:03:36  Loss: 1.0058 (1.0986)  Acc@1: 75.0000 (71.5927)  Acc@5: 93.7500 (95.6121)  time: 0.2156  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 640/1627]  eta: 0:03:34  Loss: 0.9931 (1.0986)  Acc@1: 75.0000 (71.5874)  Acc@5: 93.7500 (95.6123)  time: 0.2155  data: 0.0005  max mem: 2500
Test: [Task 1]  [ 650/1627]  eta: 0:03:31  Loss: 0.9963 (1.0975)  Acc@1: 75.0000 (71.6110)  Acc@5: 100.0000 (95.6509)  time: 0.2157  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 660/1627]  eta: 0:03:29  Loss: 0.9962 (1.0959)  Acc@1: 75.0000 (71.6528)  Acc@5: 100.0000 (95.6505)  time: 0.2154  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 670/1627]  eta: 0:03:27  Loss: 1.0482 (1.0954)  Acc@1: 75.0000 (71.6375)  Acc@5: 100.0000 (95.6501)  time: 0.2155  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 680/1627]  eta: 0:03:25  Loss: 1.0778 (1.0950)  Acc@1: 75.0000 (71.6960)  Acc@5: 93.7500 (95.6498)  time: 0.2172  data: 0.0010  max mem: 2500
Test: [Task 1]  [ 690/1627]  eta: 0:03:23  Loss: 1.0612 (1.0929)  Acc@1: 75.0000 (71.7438)  Acc@5: 100.0000 (95.6946)  time: 0.2177  data: 0.0017  max mem: 2500
Test: [Task 1]  [ 700/1627]  eta: 0:03:21  Loss: 1.0612 (1.0922)  Acc@1: 75.0000 (71.8260)  Acc@5: 100.0000 (95.6937)  time: 0.2158  data: 0.0012  max mem: 2500
Test: [Task 1]  [ 710/1627]  eta: 0:03:18  Loss: 0.9218 (1.0897)  Acc@1: 75.0000 (71.9058)  Acc@5: 100.0000 (95.7191)  time: 0.2151  data: 0.0005  max mem: 2500
Test: [Task 1]  [ 720/1627]  eta: 0:03:16  Loss: 0.9179 (1.0885)  Acc@1: 68.7500 (71.8967)  Acc@5: 100.0000 (95.7351)  time: 0.2152  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 730/1627]  eta: 0:03:14  Loss: 1.0957 (1.0890)  Acc@1: 68.7500 (71.8793)  Acc@5: 100.0000 (95.7421)  time: 0.2157  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 740/1627]  eta: 0:03:12  Loss: 1.0989 (1.0900)  Acc@1: 68.7500 (71.8455)  Acc@5: 93.7500 (95.7237)  time: 0.2161  data: 0.0006  max mem: 2500
Test: [Task 1]  [ 750/1627]  eta: 0:03:10  Loss: 1.0567 (1.0890)  Acc@1: 75.0000 (71.9291)  Acc@5: 93.7500 (95.7224)  time: 0.2158  data: 0.0008  max mem: 2500
Test: [Task 1]  [ 760/1627]  eta: 0:03:07  Loss: 1.0567 (1.0920)  Acc@1: 75.0000 (71.8545)  Acc@5: 93.7500 (95.6882)  time: 0.2154  data: 0.0007  max mem: 2500
Test: [Task 1]  [ 770/1627]  eta: 0:03:05  Loss: 0.9486 (1.0887)  Acc@1: 75.0000 (71.9439)  Acc@5: 93.7500 (95.7117)  time: 0.2150  data: 0.0006  max mem: 2500
Test: [Task 1]  [ 780/1627]  eta: 0:03:03  Loss: 0.8042 (1.0870)  Acc@1: 75.0000 (71.9990)  Acc@5: 100.0000 (95.7186)  time: 0.2154  data: 0.0007  max mem: 2500
Test: [Task 1]  [ 790/1627]  eta: 0:03:01  Loss: 0.8702 (1.0885)  Acc@1: 75.0000 (71.9975)  Acc@5: 100.0000 (95.7016)  time: 0.2152  data: 0.0007  max mem: 2500
Test: [Task 1]  [ 800/1627]  eta: 0:02:59  Loss: 0.9708 (1.0870)  Acc@1: 75.0000 (72.0037)  Acc@5: 100.0000 (95.7319)  time: 0.2149  data: 0.0005  max mem: 2500
Test: [Task 1]  [ 810/1627]  eta: 0:02:57  Loss: 0.9552 (1.0864)  Acc@1: 75.0000 (72.0330)  Acc@5: 100.0000 (95.7306)  time: 0.2181  data: 0.0005  max mem: 2500
Test: [Task 1]  [ 820/1627]  eta: 0:02:54  Loss: 0.8968 (1.0853)  Acc@1: 75.0000 (72.0539)  Acc@5: 100.0000 (95.7369)  time: 0.2183  data: 0.0005  max mem: 2500
Test: [Task 1]  [ 830/1627]  eta: 0:02:52  Loss: 0.8968 (1.0846)  Acc@1: 75.0000 (72.0593)  Acc@5: 100.0000 (95.7506)  time: 0.2154  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 840/1627]  eta: 0:02:50  Loss: 0.8477 (1.0822)  Acc@1: 75.0000 (72.1017)  Acc@5: 100.0000 (95.7937)  time: 0.2151  data: 0.0005  max mem: 2500
Test: [Task 1]  [ 850/1627]  eta: 0:02:48  Loss: 1.0257 (1.0837)  Acc@1: 68.7500 (72.0476)  Acc@5: 100.0000 (95.7917)  time: 0.2161  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 860/1627]  eta: 0:02:46  Loss: 1.0545 (1.0831)  Acc@1: 68.7500 (72.0311)  Acc@5: 100.0000 (95.8261)  time: 0.2161  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 870/1627]  eta: 0:02:44  Loss: 0.9938 (1.0817)  Acc@1: 75.0000 (72.0508)  Acc@5: 100.0000 (95.8381)  time: 0.2150  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 880/1627]  eta: 0:02:41  Loss: 1.0818 (1.0842)  Acc@1: 62.5000 (71.9353)  Acc@5: 100.0000 (95.8499)  time: 0.2151  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 890/1627]  eta: 0:02:39  Loss: 1.1912 (1.0866)  Acc@1: 62.5000 (71.8645)  Acc@5: 100.0000 (95.8333)  time: 0.2150  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 900/1627]  eta: 0:02:37  Loss: 1.1824 (1.0868)  Acc@1: 68.7500 (71.8646)  Acc@5: 93.7500 (95.8310)  time: 0.2152  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 910/1627]  eta: 0:02:35  Loss: 1.1645 (1.0881)  Acc@1: 68.7500 (71.8441)  Acc@5: 93.7500 (95.7807)  time: 0.2148  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 920/1627]  eta: 0:02:33  Loss: 1.0517 (1.0879)  Acc@1: 68.7500 (71.8580)  Acc@5: 93.7500 (95.7858)  time: 0.2149  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 930/1627]  eta: 0:02:30  Loss: 1.0517 (1.0887)  Acc@1: 68.7500 (71.8314)  Acc@5: 93.7500 (95.7573)  time: 0.2153  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 940/1627]  eta: 0:02:28  Loss: 1.0360 (1.0874)  Acc@1: 75.0000 (71.8717)  Acc@5: 100.0000 (95.7891)  time: 0.2154  data: 0.0005  max mem: 2500
Test: [Task 1]  [ 950/1627]  eta: 0:02:26  Loss: 1.1038 (1.0882)  Acc@1: 68.7500 (71.8389)  Acc@5: 100.0000 (95.8070)  time: 0.2158  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 960/1627]  eta: 0:02:24  Loss: 1.1266 (1.0876)  Acc@1: 68.7500 (71.8392)  Acc@5: 100.0000 (95.7921)  time: 0.2156  data: 0.0006  max mem: 2500
Test: [Task 1]  [ 970/1627]  eta: 0:02:22  Loss: 0.9843 (1.0868)  Acc@1: 75.0000 (71.8718)  Acc@5: 93.7500 (95.7904)  time: 0.2155  data: 0.0007  max mem: 2500
Test: [Task 1]  [ 980/1627]  eta: 0:02:20  Loss: 1.0205 (1.0868)  Acc@1: 75.0000 (71.8973)  Acc@5: 93.7500 (95.7887)  time: 0.2158  data: 0.0006  max mem: 2500
Test: [Task 1]  [ 990/1627]  eta: 0:02:17  Loss: 1.1234 (1.0896)  Acc@1: 75.0000 (71.8782)  Acc@5: 93.7500 (95.7682)  time: 0.2158  data: 0.0005  max mem: 2500
Test: [Task 1]  [1000/1627]  eta: 0:02:15  Loss: 1.2035 (1.0897)  Acc@1: 75.0000 (71.9031)  Acc@5: 93.7500 (95.7418)  time: 0.2169  data: 0.0016  max mem: 2500
Test: [Task 1]  [1010/1627]  eta: 0:02:13  Loss: 1.0660 (1.0894)  Acc@1: 75.0000 (71.9028)  Acc@5: 93.7500 (95.7468)  time: 0.2168  data: 0.0017  max mem: 2500
Test: [Task 1]  [1020/1627]  eta: 0:02:11  Loss: 1.0057 (1.0888)  Acc@1: 75.0000 (71.9087)  Acc@5: 100.0000 (95.7578)  time: 0.2159  data: 0.0006  max mem: 2500
Test: [Task 1]  [1030/1627]  eta: 0:02:09  Loss: 0.9140 (1.0868)  Acc@1: 75.0000 (71.9750)  Acc@5: 100.0000 (95.7808)  time: 0.2167  data: 0.0008  max mem: 2500
Test: [Task 1]  [1040/1627]  eta: 0:02:07  Loss: 0.8040 (1.0848)  Acc@1: 81.2500 (72.0341)  Acc@5: 100.0000 (95.8093)  time: 0.2165  data: 0.0007  max mem: 2500
Test: [Task 1]  [1050/1627]  eta: 0:02:04  Loss: 0.8959 (1.0834)  Acc@1: 75.0000 (72.0504)  Acc@5: 100.0000 (95.8135)  time: 0.2165  data: 0.0007  max mem: 2500
Test: [Task 1]  [1060/1627]  eta: 0:02:02  Loss: 1.0584 (1.0838)  Acc@1: 68.7500 (72.0606)  Acc@5: 93.7500 (95.8000)  time: 0.2168  data: 0.0007  max mem: 2500
Test: [Task 1]  [1070/1627]  eta: 0:02:00  Loss: 1.1254 (1.0842)  Acc@1: 68.7500 (72.0588)  Acc@5: 93.7500 (95.7866)  time: 0.2163  data: 0.0005  max mem: 2500
Test: [Task 1]  [1080/1627]  eta: 0:01:58  Loss: 1.0476 (1.0849)  Acc@1: 68.7500 (72.0687)  Acc@5: 100.0000 (95.7852)  time: 0.2175  data: 0.0005  max mem: 2500
Test: [Task 1]  [1090/1627]  eta: 0:01:56  Loss: 1.0476 (1.0849)  Acc@1: 75.0000 (72.1127)  Acc@5: 100.0000 (95.7894)  time: 0.2180  data: 0.0006  max mem: 2500
Test: [Task 1]  [1100/1627]  eta: 0:01:54  Loss: 0.9548 (1.0828)  Acc@1: 75.0000 (72.1730)  Acc@5: 100.0000 (95.8050)  time: 0.2187  data: 0.0007  max mem: 2500
Test: [Task 1]  [1110/1627]  eta: 0:01:51  Loss: 0.9463 (1.0827)  Acc@1: 75.0000 (72.1872)  Acc@5: 100.0000 (95.8146)  time: 0.2179  data: 0.0006  max mem: 2500
Test: [Task 1]  [1120/1627]  eta: 0:01:49  Loss: 1.0636 (1.0840)  Acc@1: 68.7500 (72.1231)  Acc@5: 100.0000 (95.8073)  time: 0.2157  data: 0.0004  max mem: 2500
Test: [Task 1]  [1130/1627]  eta: 0:01:47  Loss: 1.0000 (1.0845)  Acc@1: 68.7500 (72.1264)  Acc@5: 100.0000 (95.8057)  time: 0.2162  data: 0.0005  max mem: 2500
Test: [Task 1]  [1140/1627]  eta: 0:01:45  Loss: 0.9819 (1.0856)  Acc@1: 75.0000 (72.1242)  Acc@5: 100.0000 (95.7986)  time: 0.2167  data: 0.0004  max mem: 2500
Test: [Task 1]  [1150/1627]  eta: 0:01:43  Loss: 1.2165 (1.0863)  Acc@1: 68.7500 (72.0786)  Acc@5: 93.7500 (95.8080)  time: 0.2169  data: 0.0004  max mem: 2500
Test: [Task 1]  [1160/1627]  eta: 0:01:41  Loss: 1.1261 (1.0852)  Acc@1: 75.0000 (72.1361)  Acc@5: 100.0000 (95.8226)  time: 0.2173  data: 0.0004  max mem: 2500
Test: [Task 1]  [1170/1627]  eta: 0:01:38  Loss: 1.0325 (1.0845)  Acc@1: 75.0000 (72.1552)  Acc@5: 100.0000 (95.8262)  time: 0.2181  data: 0.0011  max mem: 2500
Test: [Task 1]  [1180/1627]  eta: 0:01:36  Loss: 1.0528 (1.0850)  Acc@1: 75.0000 (72.1687)  Acc@5: 93.7500 (95.8298)  time: 0.2180  data: 0.0012  max mem: 2500
Test: [Task 1]  [1190/1627]  eta: 0:01:34  Loss: 1.1278 (1.0857)  Acc@1: 75.0000 (72.1190)  Acc@5: 93.7500 (95.8281)  time: 0.2171  data: 0.0007  max mem: 2500
Test: [Task 1]  [1200/1627]  eta: 0:01:32  Loss: 1.1149 (1.0857)  Acc@1: 68.7500 (72.0962)  Acc@5: 100.0000 (95.8368)  time: 0.2163  data: 0.0008  max mem: 2500
Test: [Task 1]  [1210/1627]  eta: 0:01:30  Loss: 0.9513 (1.0863)  Acc@1: 68.7500 (72.0685)  Acc@5: 100.0000 (95.8299)  time: 0.2161  data: 0.0006  max mem: 2500
Test: [Task 1]  [1220/1627]  eta: 0:01:28  Loss: 0.9674 (1.0854)  Acc@1: 75.0000 (72.0874)  Acc@5: 100.0000 (95.8436)  time: 0.2171  data: 0.0005  max mem: 2500
Test: [Task 1]  [1230/1627]  eta: 0:01:25  Loss: 1.0503 (1.0860)  Acc@1: 68.7500 (72.0400)  Acc@5: 100.0000 (95.8367)  time: 0.2179  data: 0.0006  max mem: 2500
Test: [Task 1]  [1240/1627]  eta: 0:01:23  Loss: 1.0725 (1.0856)  Acc@1: 68.7500 (72.0588)  Acc@5: 93.7500 (95.8300)  time: 0.2180  data: 0.0006  max mem: 2500
Test: [Task 1]  [1250/1627]  eta: 0:01:21  Loss: 1.1758 (1.0860)  Acc@1: 68.7500 (72.0374)  Acc@5: 93.7500 (95.8233)  time: 0.2176  data: 0.0005  max mem: 2500
Test: [Task 1]  [1260/1627]  eta: 0:01:19  Loss: 1.1707 (1.0858)  Acc@1: 75.0000 (72.0757)  Acc@5: 100.0000 (95.8267)  time: 0.2175  data: 0.0004  max mem: 2500
Test: [Task 1]  [1270/1627]  eta: 0:01:17  Loss: 0.9982 (1.0865)  Acc@1: 75.0000 (72.0397)  Acc@5: 100.0000 (95.8251)  time: 0.2180  data: 0.0011  max mem: 2500
Test: [Task 1]  [1280/1627]  eta: 0:01:15  Loss: 0.9548 (1.0852)  Acc@1: 68.7500 (72.0580)  Acc@5: 93.7500 (95.8285)  time: 0.2173  data: 0.0011  max mem: 2500
Test: [Task 1]  [1290/1627]  eta: 0:01:13  Loss: 1.0440 (1.0855)  Acc@1: 68.7500 (72.0275)  Acc@5: 100.0000 (95.8414)  time: 0.2167  data: 0.0004  max mem: 2500
Test: [Task 1]  [1300/1627]  eta: 0:01:10  Loss: 1.0440 (1.0849)  Acc@1: 75.0000 (72.0696)  Acc@5: 100.0000 (95.8445)  time: 0.2168  data: 0.0004  max mem: 2500
Test: [Task 1]  [1310/1627]  eta: 0:01:08  Loss: 0.8710 (1.0835)  Acc@1: 81.2500 (72.1253)  Acc@5: 100.0000 (95.8476)  time: 0.2171  data: 0.0005  max mem: 2500
Test: [Task 1]  [1320/1627]  eta: 0:01:06  Loss: 0.7733 (1.0820)  Acc@1: 81.2500 (72.1896)  Acc@5: 100.0000 (95.8649)  time: 0.2170  data: 0.0005  max mem: 2500
Test: [Task 1]  [1330/1627]  eta: 0:01:04  Loss: 0.8640 (1.0817)  Acc@1: 75.0000 (72.2107)  Acc@5: 100.0000 (95.8443)  time: 0.2166  data: 0.0004  max mem: 2500
Test: [Task 1]  [1340/1627]  eta: 0:01:02  Loss: 1.0640 (1.0823)  Acc@1: 75.0000 (72.1896)  Acc@5: 93.7500 (95.8520)  time: 0.2174  data: 0.0004  max mem: 2500
Test: [Task 1]  [1350/1627]  eta: 0:01:00  Loss: 1.0171 (1.0817)  Acc@1: 75.0000 (72.2011)  Acc@5: 100.0000 (95.8595)  time: 0.2176  data: 0.0004  max mem: 2500
Test: [Task 1]  [1360/1627]  eta: 0:00:57  Loss: 0.9506 (1.0812)  Acc@1: 75.0000 (72.2079)  Acc@5: 100.0000 (95.8762)  time: 0.2165  data: 0.0004  max mem: 2500
Test: [Task 1]  [1370/1627]  eta: 0:00:55  Loss: 0.9506 (1.0803)  Acc@1: 68.7500 (72.2101)  Acc@5: 100.0000 (95.8880)  time: 0.2162  data: 0.0004  max mem: 2500
Test: [Task 1]  [1380/1627]  eta: 0:00:53  Loss: 0.9912 (1.0805)  Acc@1: 68.7500 (72.2167)  Acc@5: 93.7500 (95.8861)  time: 0.2159  data: 0.0004  max mem: 2500
Test: [Task 1]  [1390/1627]  eta: 0:00:51  Loss: 1.1648 (1.0801)  Acc@1: 68.7500 (72.2052)  Acc@5: 93.7500 (95.8932)  time: 0.2155  data: 0.0003  max mem: 2500
Test: [Task 1]  [1400/1627]  eta: 0:00:49  Loss: 1.1178 (1.0803)  Acc@1: 75.0000 (72.2163)  Acc@5: 93.7500 (95.8779)  time: 0.2161  data: 0.0004  max mem: 2500
Test: [Task 1]  [1410/1627]  eta: 0:00:47  Loss: 0.8487 (1.0795)  Acc@1: 75.0000 (72.2582)  Acc@5: 93.7500 (95.8894)  time: 0.2167  data: 0.0004  max mem: 2500
Test: [Task 1]  [1420/1627]  eta: 0:00:44  Loss: 0.9571 (1.0788)  Acc@1: 75.0000 (72.2686)  Acc@5: 100.0000 (95.9096)  time: 0.2165  data: 0.0004  max mem: 2500
Test: [Task 1]  [1430/1627]  eta: 0:00:42  Loss: 1.1639 (1.0805)  Acc@1: 68.7500 (72.2572)  Acc@5: 100.0000 (95.8770)  time: 0.2163  data: 0.0004  max mem: 2500
Test: [Task 1]  [1440/1627]  eta: 0:00:40  Loss: 1.1270 (1.0800)  Acc@1: 68.7500 (72.2328)  Acc@5: 93.7500 (95.8926)  time: 0.2171  data: 0.0004  max mem: 2500
Test: [Task 1]  [1450/1627]  eta: 0:00:38  Loss: 1.1270 (1.0813)  Acc@1: 68.7500 (72.1959)  Acc@5: 100.0000 (95.8822)  time: 0.2170  data: 0.0009  max mem: 2500
Test: [Task 1]  [1460/1627]  eta: 0:00:36  Loss: 1.1585 (1.0815)  Acc@1: 62.5000 (72.1894)  Acc@5: 93.7500 (95.8718)  time: 0.2167  data: 0.0009  max mem: 2500
Test: [Task 1]  [1470/1627]  eta: 0:00:34  Loss: 1.0919 (1.0818)  Acc@1: 75.0000 (72.1830)  Acc@5: 100.0000 (95.8617)  time: 0.2169  data: 0.0005  max mem: 2500
Test: [Task 1]  [1480/1627]  eta: 0:00:31  Loss: 1.1611 (1.0823)  Acc@1: 75.0000 (72.1683)  Acc@5: 93.7500 (95.8558)  time: 0.2171  data: 0.0006  max mem: 2500
Test: [Task 1]  [1490/1627]  eta: 0:00:29  Loss: 1.1289 (1.0827)  Acc@1: 75.0000 (72.1915)  Acc@5: 93.7500 (95.8501)  time: 0.2170  data: 0.0005  max mem: 2500
Test: [Task 1]  [1500/1627]  eta: 0:00:27  Loss: 1.0871 (1.0830)  Acc@1: 75.0000 (72.1935)  Acc@5: 93.7500 (95.8361)  time: 0.2160  data: 0.0005  max mem: 2500
Test: [Task 1]  [1510/1627]  eta: 0:00:25  Loss: 0.8703 (1.0828)  Acc@1: 68.7500 (72.2038)  Acc@5: 93.7500 (95.8306)  time: 0.2155  data: 0.0005  max mem: 2500
Test: [Task 1]  [1520/1627]  eta: 0:00:23  Loss: 0.8696 (1.0815)  Acc@1: 75.0000 (72.2387)  Acc@5: 100.0000 (95.8498)  time: 0.2160  data: 0.0004  max mem: 2500
Test: [Task 1]  [1530/1627]  eta: 0:00:21  Loss: 0.8496 (1.0808)  Acc@1: 75.0000 (72.2322)  Acc@5: 100.0000 (95.8565)  time: 0.2166  data: 0.0006  max mem: 2500
Test: [Task 1]  [1540/1627]  eta: 0:00:18  Loss: 0.9040 (1.0800)  Acc@1: 68.7500 (72.2421)  Acc@5: 100.0000 (95.8752)  time: 0.2165  data: 0.0006  max mem: 2500
Test: [Task 1]  [1550/1627]  eta: 0:00:16  Loss: 0.9040 (1.0794)  Acc@1: 75.0000 (72.2477)  Acc@5: 100.0000 (95.8817)  time: 0.2168  data: 0.0004  max mem: 2500
Test: [Task 1]  [1560/1627]  eta: 0:00:14  Loss: 0.8142 (1.0785)  Acc@1: 75.0000 (72.2614)  Acc@5: 100.0000 (95.8881)  time: 0.2168  data: 0.0004  max mem: 2500
Test: [Task 1]  [1570/1627]  eta: 0:00:12  Loss: 0.9224 (1.0783)  Acc@1: 75.0000 (72.2828)  Acc@5: 100.0000 (95.8904)  time: 0.2161  data: 0.0005  max mem: 2500
Test: [Task 1]  [1580/1627]  eta: 0:00:10  Loss: 0.9255 (1.0783)  Acc@1: 75.0000 (72.2802)  Acc@5: 100.0000 (95.8887)  time: 0.2191  data: 0.0005  max mem: 2500
Test: [Task 1]  [1590/1627]  eta: 0:00:08  Loss: 0.9314 (1.0781)  Acc@1: 75.0000 (72.2777)  Acc@5: 100.0000 (95.8949)  time: 0.2190  data: 0.0004  max mem: 2500
Test: [Task 1]  [1600/1627]  eta: 0:00:05  Loss: 1.0289 (1.0791)  Acc@1: 68.7500 (72.2400)  Acc@5: 100.0000 (95.8893)  time: 0.2158  data: 0.0003  max mem: 2500
Test: [Task 1]  [1610/1627]  eta: 0:00:03  Loss: 1.0547 (1.0785)  Acc@1: 68.7500 (72.2416)  Acc@5: 100.0000 (95.8993)  time: 0.2166  data: 0.0004  max mem: 2500
Test: [Task 1]  [1620/1627]  eta: 0:00:01  Loss: 0.8909 (1.0774)  Acc@1: 75.0000 (72.2741)  Acc@5: 100.0000 (95.8976)  time: 0.2162  data: 0.0004  max mem: 2500
Test: [Task 1]  [1626/1627]  eta: 0:00:00  Loss: 0.8647 (1.0769)  Acc@1: 75.0000 (72.2918)  Acc@5: 93.7500 (95.9012)  time: 0.2156  data: 0.0003  max mem: 2500
Test: [Task 1] Total time: 0:05:52 (0.2169 s / it)
* Acc@1 72.292 Acc@5 95.901 loss 1.077
Test: [Task 2]  [  0/625]  eta: 0:07:07  Loss: 0.2258 (0.2258)  Acc@1: 93.7500 (93.7500)  Acc@5: 100.0000 (100.0000)  time: 0.6836  data: 0.4660  max mem: 2500
Test: [Task 2]  [ 10/625]  eta: 0:02:38  Loss: 0.2021 (0.2470)  Acc@1: 93.7500 (92.0455)  Acc@5: 100.0000 (99.4318)  time: 0.2579  data: 0.0427  max mem: 2500
Test: [Task 2]  [ 20/625]  eta: 0:02:23  Loss: 0.2021 (0.2600)  Acc@1: 93.7500 (90.7738)  Acc@5: 100.0000 (99.7024)  time: 0.2155  data: 0.0004  max mem: 2500
Test: [Task 2]  [ 30/625]  eta: 0:02:17  Loss: 0.3033 (0.2797)  Acc@1: 93.7500 (90.1210)  Acc@5: 100.0000 (99.7984)  time: 0.2157  data: 0.0004  max mem: 2500
Test: [Task 2]  [ 40/625]  eta: 0:02:12  Loss: 0.2729 (0.2849)  Acc@1: 93.7500 (90.3963)  Acc@5: 100.0000 (99.8476)  time: 0.2155  data: 0.0005  max mem: 2500
Test: [Task 2]  [ 50/625]  eta: 0:02:09  Loss: 0.2957 (0.2965)  Acc@1: 93.7500 (90.3186)  Acc@5: 100.0000 (99.7549)  time: 0.2154  data: 0.0006  max mem: 2500
Test: [Task 2]  [ 60/625]  eta: 0:02:06  Loss: 0.2957 (0.3014)  Acc@1: 87.5000 (89.8566)  Acc@5: 100.0000 (99.7951)  time: 0.2158  data: 0.0006  max mem: 2500
Test: [Task 2]  [ 70/625]  eta: 0:02:03  Loss: 0.2857 (0.3002)  Acc@1: 87.5000 (89.8768)  Acc@5: 100.0000 (99.8239)  time: 0.2163  data: 0.0005  max mem: 2500
Test: [Task 2]  [ 80/625]  eta: 0:02:00  Loss: 0.2512 (0.3050)  Acc@1: 87.5000 (90.0463)  Acc@5: 100.0000 (99.6914)  time: 0.2164  data: 0.0007  max mem: 2500
Test: [Task 2]  [ 90/625]  eta: 0:01:58  Loss: 0.2512 (0.3001)  Acc@1: 93.7500 (90.2473)  Acc@5: 100.0000 (99.7253)  time: 0.2161  data: 0.0006  max mem: 2500
Test: [Task 2]  [100/625]  eta: 0:01:55  Loss: 0.2608 (0.2954)  Acc@1: 87.5000 (90.3465)  Acc@5: 100.0000 (99.6906)  time: 0.2155  data: 0.0004  max mem: 2500
Test: [Task 2]  [110/625]  eta: 0:01:53  Loss: 0.2846 (0.3013)  Acc@1: 87.5000 (90.2590)  Acc@5: 100.0000 (99.6622)  time: 0.2153  data: 0.0004  max mem: 2500
Test: [Task 2]  [120/625]  eta: 0:01:50  Loss: 0.3217 (0.3038)  Acc@1: 87.5000 (90.2376)  Acc@5: 100.0000 (99.5868)  time: 0.2155  data: 0.0007  max mem: 2500
Test: [Task 2]  [130/625]  eta: 0:01:48  Loss: 0.2984 (0.3020)  Acc@1: 93.7500 (90.5057)  Acc@5: 100.0000 (99.6183)  time: 0.2150  data: 0.0007  max mem: 2500
Test: [Task 2]  [140/625]  eta: 0:01:46  Loss: 0.2688 (0.3061)  Acc@1: 93.7500 (90.2926)  Acc@5: 100.0000 (99.5567)  time: 0.2147  data: 0.0004  max mem: 2500
Test: [Task 2]  [150/625]  eta: 0:01:43  Loss: 0.2881 (0.3092)  Acc@1: 87.5000 (89.9834)  Acc@5: 100.0000 (99.5447)  time: 0.2149  data: 0.0004  max mem: 2500
Test: [Task 2]  [160/625]  eta: 0:01:41  Loss: 0.3088 (0.3138)  Acc@1: 87.5000 (89.8292)  Acc@5: 100.0000 (99.5342)  time: 0.2152  data: 0.0004  max mem: 2500
Test: [Task 2]  [170/625]  eta: 0:01:39  Loss: 0.3351 (0.3118)  Acc@1: 93.7500 (90.0950)  Acc@5: 100.0000 (99.4883)  time: 0.2154  data: 0.0005  max mem: 2500
Test: [Task 2]  [180/625]  eta: 0:01:37  Loss: 0.2627 (0.3083)  Acc@1: 93.7500 (90.2624)  Acc@5: 100.0000 (99.5166)  time: 0.2158  data: 0.0004  max mem: 2500
Test: [Task 2]  [190/625]  eta: 0:01:34  Loss: 0.2974 (0.3115)  Acc@1: 87.5000 (90.2160)  Acc@5: 100.0000 (99.4764)  time: 0.2186  data: 0.0006  max mem: 2500
Test: [Task 2]  [200/625]  eta: 0:01:32  Loss: 0.3796 (0.3129)  Acc@1: 87.5000 (90.1430)  Acc@5: 100.0000 (99.5025)  time: 0.2179  data: 0.0006  max mem: 2500
Test: [Task 2]  [210/625]  eta: 0:01:30  Loss: 0.3380 (0.3151)  Acc@1: 87.5000 (90.1066)  Acc@5: 100.0000 (99.4964)  time: 0.2151  data: 0.0004  max mem: 2500
Test: [Task 2]  [220/625]  eta: 0:01:28  Loss: 0.2481 (0.3120)  Acc@1: 93.7500 (90.3281)  Acc@5: 100.0000 (99.5192)  time: 0.2153  data: 0.0003  max mem: 2500
Test: [Task 2]  [230/625]  eta: 0:01:26  Loss: 0.2441 (0.3103)  Acc@1: 93.7500 (90.4762)  Acc@5: 100.0000 (99.5400)  time: 0.2158  data: 0.0004  max mem: 2500
Test: [Task 2]  [240/625]  eta: 0:01:23  Loss: 0.3177 (0.3102)  Acc@1: 93.7500 (90.4824)  Acc@5: 100.0000 (99.5332)  time: 0.2159  data: 0.0004  max mem: 2500
Test: [Task 2]  [250/625]  eta: 0:01:21  Loss: 0.3177 (0.3120)  Acc@1: 93.7500 (90.5378)  Acc@5: 100.0000 (99.5020)  time: 0.2158  data: 0.0004  max mem: 2500
Test: [Task 2]  [260/625]  eta: 0:01:19  Loss: 0.3141 (0.3135)  Acc@1: 87.5000 (90.4454)  Acc@5: 100.0000 (99.4971)  time: 0.2161  data: 0.0004  max mem: 2500
Test: [Task 2]  [270/625]  eta: 0:01:17  Loss: 0.3141 (0.3141)  Acc@1: 87.5000 (90.4520)  Acc@5: 100.0000 (99.4926)  time: 0.2156  data: 0.0004  max mem: 2500
Test: [Task 2]  [280/625]  eta: 0:01:15  Loss: 0.2594 (0.3151)  Acc@1: 87.5000 (90.3247)  Acc@5: 100.0000 (99.4884)  time: 0.2160  data: 0.0005  max mem: 2500
Test: [Task 2]  [290/625]  eta: 0:01:12  Loss: 0.2594 (0.3157)  Acc@1: 87.5000 (90.3136)  Acc@5: 100.0000 (99.4845)  time: 0.2162  data: 0.0005  max mem: 2500
Test: [Task 2]  [300/625]  eta: 0:01:10  Loss: 0.2740 (0.3168)  Acc@1: 87.5000 (90.2409)  Acc@5: 100.0000 (99.5017)  time: 0.2150  data: 0.0004  max mem: 2500
Test: [Task 2]  [310/625]  eta: 0:01:08  Loss: 0.3186 (0.3177)  Acc@1: 87.5000 (90.1326)  Acc@5: 100.0000 (99.4775)  time: 0.2150  data: 0.0004  max mem: 2500
Test: [Task 2]  [320/625]  eta: 0:01:06  Loss: 0.1648 (0.3108)  Acc@1: 93.7500 (90.4011)  Acc@5: 100.0000 (99.4938)  time: 0.2156  data: 0.0007  max mem: 2500
Test: [Task 2]  [330/625]  eta: 0:01:04  Loss: 0.1311 (0.3092)  Acc@1: 93.7500 (90.3512)  Acc@5: 100.0000 (99.5091)  time: 0.2160  data: 0.0008  max mem: 2500
Test: [Task 2]  [340/625]  eta: 0:01:01  Loss: 0.0909 (0.3021)  Acc@1: 93.7500 (90.6158)  Acc@5: 100.0000 (99.5235)  time: 0.2162  data: 0.0006  max mem: 2500
Test: [Task 2]  [350/625]  eta: 0:00:59  Loss: 0.0892 (0.3000)  Acc@1: 100.0000 (90.6161)  Acc@5: 100.0000 (99.5370)  time: 0.2166  data: 0.0013  max mem: 2500
Test: [Task 2]  [360/625]  eta: 0:00:57  Loss: 0.2834 (0.3012)  Acc@1: 87.5000 (90.6337)  Acc@5: 100.0000 (99.5325)  time: 0.2161  data: 0.0013  max mem: 2500
Test: [Task 2]  [370/625]  eta: 0:00:55  Loss: 0.2079 (0.2985)  Acc@1: 93.7500 (90.7008)  Acc@5: 100.0000 (99.5451)  time: 0.2150  data: 0.0005  max mem: 2500
Test: [Task 2]  [380/625]  eta: 0:00:53  Loss: 0.2495 (0.3009)  Acc@1: 93.7500 (90.6168)  Acc@5: 100.0000 (99.5243)  time: 0.2151  data: 0.0004  max mem: 2500
Test: [Task 2]  [390/625]  eta: 0:00:50  Loss: 0.2495 (0.2997)  Acc@1: 93.7500 (90.6170)  Acc@5: 100.0000 (99.5205)  time: 0.2155  data: 0.0004  max mem: 2500
Test: [Task 2]  [400/625]  eta: 0:00:48  Loss: 0.1142 (0.2957)  Acc@1: 93.7500 (90.7419)  Acc@5: 100.0000 (99.5324)  time: 0.2159  data: 0.0006  max mem: 2500
Test: [Task 2]  [410/625]  eta: 0:00:46  Loss: 0.0770 (0.2938)  Acc@1: 93.7500 (90.8303)  Acc@5: 100.0000 (99.5134)  time: 0.2162  data: 0.0010  max mem: 2500
Test: [Task 2]  [420/625]  eta: 0:00:44  Loss: 0.0778 (0.2929)  Acc@1: 100.0000 (90.9145)  Acc@5: 100.0000 (99.5249)  time: 0.2159  data: 0.0007  max mem: 2500
Test: [Task 2]  [430/625]  eta: 0:00:42  Loss: 0.2048 (0.2922)  Acc@1: 93.7500 (90.9223)  Acc@5: 100.0000 (99.5360)  time: 0.2169  data: 0.0004  max mem: 2500
Test: [Task 2]  [440/625]  eta: 0:00:40  Loss: 0.1458 (0.2879)  Acc@1: 93.7500 (91.0856)  Acc@5: 100.0000 (99.5465)  time: 0.2172  data: 0.0004  max mem: 2500
Test: [Task 2]  [450/625]  eta: 0:00:37  Loss: 0.0994 (0.2842)  Acc@1: 93.7500 (91.1724)  Acc@5: 100.0000 (99.5565)  time: 0.2183  data: 0.0005  max mem: 2500
Test: [Task 2]  [460/625]  eta: 0:00:35  Loss: 0.1124 (0.2807)  Acc@1: 100.0000 (91.3368)  Acc@5: 100.0000 (99.5662)  time: 0.2181  data: 0.0004  max mem: 2500
Test: [Task 2]  [470/625]  eta: 0:00:33  Loss: 0.1329 (0.2781)  Acc@1: 100.0000 (91.4942)  Acc@5: 100.0000 (99.5754)  time: 0.2154  data: 0.0004  max mem: 2500
Test: [Task 2]  [480/625]  eta: 0:00:31  Loss: 0.1579 (0.2757)  Acc@1: 100.0000 (91.5800)  Acc@5: 100.0000 (99.5842)  time: 0.2159  data: 0.0006  max mem: 2500
Test: [Task 2]  [490/625]  eta: 0:00:29  Loss: 0.1261 (0.2732)  Acc@1: 100.0000 (91.7133)  Acc@5: 100.0000 (99.5927)  time: 0.2159  data: 0.0006  max mem: 2500
Test: [Task 2]  [500/625]  eta: 0:00:27  Loss: 0.1203 (0.2709)  Acc@1: 100.0000 (91.8164)  Acc@5: 100.0000 (99.6008)  time: 0.2155  data: 0.0004  max mem: 2500
Test: [Task 2]  [510/625]  eta: 0:00:24  Loss: 0.1594 (0.2744)  Acc@1: 93.7500 (91.7074)  Acc@5: 100.0000 (99.6086)  time: 0.2163  data: 0.0004  max mem: 2500
Test: [Task 2]  [520/625]  eta: 0:00:22  Loss: 0.2172 (0.2747)  Acc@1: 93.7500 (91.6747)  Acc@5: 100.0000 (99.6161)  time: 0.2163  data: 0.0005  max mem: 2500
Test: [Task 2]  [530/625]  eta: 0:00:20  Loss: 0.1391 (0.2723)  Acc@1: 93.7500 (91.7844)  Acc@5: 100.0000 (99.6234)  time: 0.2161  data: 0.0006  max mem: 2500
Test: [Task 2]  [540/625]  eta: 0:00:18  Loss: 0.1059 (0.2702)  Acc@1: 100.0000 (91.8669)  Acc@5: 100.0000 (99.6303)  time: 0.2161  data: 0.0006  max mem: 2500
Test: [Task 2]  [550/625]  eta: 0:00:16  Loss: 0.0761 (0.2668)  Acc@1: 100.0000 (91.9918)  Acc@5: 100.0000 (99.6370)  time: 0.2156  data: 0.0005  max mem: 2500
Test: [Task 2]  [560/625]  eta: 0:00:14  Loss: 0.0578 (0.2629)  Acc@1: 100.0000 (92.1346)  Acc@5: 100.0000 (99.6435)  time: 0.2158  data: 0.0005  max mem: 2500
Test: [Task 2]  [570/625]  eta: 0:00:11  Loss: 0.0589 (0.2631)  Acc@1: 100.0000 (92.0972)  Acc@5: 100.0000 (99.6497)  time: 0.2162  data: 0.0005  max mem: 2500
Test: [Task 2]  [580/625]  eta: 0:00:09  Loss: 0.0934 (0.2603)  Acc@1: 93.7500 (92.2009)  Acc@5: 100.0000 (99.6558)  time: 0.2163  data: 0.0005  max mem: 2500
Test: [Task 2]  [590/625]  eta: 0:00:07  Loss: 0.0840 (0.2584)  Acc@1: 100.0000 (92.2695)  Acc@5: 100.0000 (99.6616)  time: 0.2169  data: 0.0005  max mem: 2500
Test: [Task 2]  [600/625]  eta: 0:00:05  Loss: 0.1597 (0.2585)  Acc@1: 93.7500 (92.2525)  Acc@5: 100.0000 (99.6568)  time: 0.2182  data: 0.0006  max mem: 2500
Test: [Task 2]  [610/625]  eta: 0:00:03  Loss: 0.2939 (0.2607)  Acc@1: 87.5000 (92.1952)  Acc@5: 100.0000 (99.6215)  time: 0.2175  data: 0.0007  max mem: 2500
Test: [Task 2]  [620/625]  eta: 0:00:01  Loss: 0.3350 (0.2618)  Acc@1: 87.5000 (92.1598)  Acc@5: 100.0000 (99.6276)  time: 0.2160  data: 0.0005  max mem: 2500
Test: [Task 2]  [624/625]  eta: 0:00:00  Loss: 0.2710 (0.2614)  Acc@1: 93.7500 (92.1800)  Acc@5: 100.0000 (99.6300)  time: 0.2160  data: 0.0004  max mem: 2500
Test: [Task 2] Total time: 0:02:15 (0.2171 s / it)
* Acc@1 92.180 Acc@5 99.630 loss 0.261
{0: {0: 26032, 1: 26032, 2: 26032, 3: 26032, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0, 10: 0, 11: 0, 12: 0, 13: 0, 14: 0, 15: 0, 16: 0, 17: 0, 18: 0, 19: 0}, 1: {0: 0, 1: 0, 2: 0, 3: 0, 4: 10000, 5: 10000, 6: 10000, 7: 10000, 8: 0, 9: 0, 10: 0, 11: 0, 12: 0, 13: 0, 14: 0, 15: 0, 16: 0, 17: 0, 18: 0, 19: 0}}
[Average accuracy till task2]	Acc@1: 82.2359	Acc@5: 97.7656	Loss: 0.6691	Forgetting: 13.6947	Backward: -13.6947
Train: Epoch[1/5]  [   0/3125]  eta: 0:43:37  Lr: 0.001875  Loss: 1.8657  Acc@1: 6.2500 (6.2500)  Acc@5: 56.2500 (56.2500)  time: 0.8377  data: 0.4734  max mem: 2500
Train: Epoch[1/5]  [  10/3125]  eta: 0:20:29  Lr: 0.001875  Loss: 1.7320  Acc@1: 25.0000 (25.0000)  Acc@5: 62.5000 (60.2273)  time: 0.3947  data: 0.0436  max mem: 2502
Train: Epoch[1/5]  [  20/3125]  eta: 0:19:18  Lr: 0.001875  Loss: 1.4841  Acc@1: 37.5000 (38.3929)  Acc@5: 68.7500 (70.2381)  time: 0.3497  data: 0.0009  max mem: 2502
Train: Epoch[1/5]  [  30/3125]  eta: 0:18:51  Lr: 0.001875  Loss: 1.3991  Acc@1: 56.2500 (43.9516)  Acc@5: 87.5000 (76.6129)  time: 0.3494  data: 0.0009  max mem: 2502
Train: Epoch[1/5]  [  40/3125]  eta: 0:18:36  Lr: 0.001875  Loss: 0.9714  Acc@1: 56.2500 (48.3232)  Acc@5: 93.7500 (80.9451)  time: 0.3501  data: 0.0006  max mem: 2502
Train: Epoch[1/5]  [  50/3125]  eta: 0:18:24  Lr: 0.001875  Loss: 0.8524  Acc@1: 68.7500 (53.1863)  Acc@5: 100.0000 (84.1912)  time: 0.3494  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [  60/3125]  eta: 0:18:15  Lr: 0.001875  Loss: 1.0441  Acc@1: 68.7500 (54.9180)  Acc@5: 93.7500 (85.5533)  time: 0.3488  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [  70/3125]  eta: 0:18:08  Lr: 0.001875  Loss: 0.7388  Acc@1: 68.7500 (57.8345)  Acc@5: 93.7500 (87.2359)  time: 0.3496  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [  80/3125]  eta: 0:18:02  Lr: 0.001875  Loss: 0.4768  Acc@1: 75.0000 (59.4907)  Acc@5: 100.0000 (88.4259)  time: 0.3489  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [  90/3125]  eta: 0:17:56  Lr: 0.001875  Loss: 0.3304  Acc@1: 75.0000 (60.9203)  Acc@5: 93.7500 (89.0797)  time: 0.3487  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [ 100/3125]  eta: 0:17:50  Lr: 0.001875  Loss: 0.2919  Acc@1: 81.2500 (62.9332)  Acc@5: 93.7500 (89.7896)  time: 0.3484  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [ 110/3125]  eta: 0:17:45  Lr: 0.001875  Loss: 0.4769  Acc@1: 81.2500 (64.1329)  Acc@5: 93.7500 (90.3153)  time: 0.3479  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [ 120/3125]  eta: 0:17:41  Lr: 0.001875  Loss: 0.5367  Acc@1: 75.0000 (64.9793)  Acc@5: 93.7500 (90.6508)  time: 0.3491  data: 0.0007  max mem: 2502
Train: Epoch[1/5]  [ 130/3125]  eta: 0:17:37  Lr: 0.001875  Loss: 0.2286  Acc@1: 75.0000 (65.6966)  Acc@5: 93.7500 (90.9828)  time: 0.3500  data: 0.0011  max mem: 2502
Train: Epoch[1/5]  [ 140/3125]  eta: 0:17:33  Lr: 0.001875  Loss: 0.2633  Acc@1: 75.0000 (66.5780)  Acc@5: 93.7500 (91.3121)  time: 0.3510  data: 0.0013  max mem: 2502
Train: Epoch[1/5]  [ 150/3125]  eta: 0:17:29  Lr: 0.001875  Loss: -0.3715  Acc@1: 75.0000 (67.4255)  Acc@5: 93.7500 (91.5977)  time: 0.3520  data: 0.0010  max mem: 2502
Train: Epoch[1/5]  [ 160/3125]  eta: 0:17:25  Lr: 0.001875  Loss: -0.2092  Acc@1: 75.0000 (67.8571)  Acc@5: 93.7500 (91.7314)  time: 0.3505  data: 0.0006  max mem: 2502
Train: Epoch[1/5]  [ 170/3125]  eta: 0:17:21  Lr: 0.001875  Loss: -0.1260  Acc@1: 75.0000 (68.4576)  Acc@5: 93.7500 (92.1053)  time: 0.3492  data: 0.0007  max mem: 2502
Train: Epoch[1/5]  [ 180/3125]  eta: 0:17:17  Lr: 0.001875  Loss: 0.0865  Acc@1: 81.2500 (69.2334)  Acc@5: 93.7500 (92.2652)  time: 0.3492  data: 0.0007  max mem: 2502
Train: Epoch[1/5]  [ 190/3125]  eta: 0:17:14  Lr: 0.001875  Loss: -0.2140  Acc@1: 81.2500 (69.6335)  Acc@5: 93.7500 (92.4738)  time: 0.3535  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [ 200/3125]  eta: 0:17:11  Lr: 0.001875  Loss: -0.0367  Acc@1: 81.2500 (70.2736)  Acc@5: 100.0000 (92.7861)  time: 0.3549  data: 0.0006  max mem: 2502
Train: Epoch[1/5]  [ 210/3125]  eta: 0:17:07  Lr: 0.001875  Loss: -0.2648  Acc@1: 81.2500 (70.7642)  Acc@5: 100.0000 (93.0687)  time: 0.3515  data: 0.0007  max mem: 2502
Train: Epoch[1/5]  [ 220/3125]  eta: 0:17:03  Lr: 0.001875  Loss: 0.3234  Acc@1: 75.0000 (71.0407)  Acc@5: 100.0000 (93.2975)  time: 0.3505  data: 0.0006  max mem: 2502
Train: Epoch[1/5]  [ 230/3125]  eta: 0:16:59  Lr: 0.001875  Loss: -0.1787  Acc@1: 81.2500 (71.4556)  Acc@5: 100.0000 (93.3983)  time: 0.3505  data: 0.0006  max mem: 2502
Train: Epoch[1/5]  [ 240/3125]  eta: 0:16:55  Lr: 0.001875  Loss: -0.2413  Acc@1: 81.2500 (71.8361)  Acc@5: 100.0000 (93.5685)  time: 0.3498  data: 0.0006  max mem: 2502
Train: Epoch[1/5]  [ 250/3125]  eta: 0:16:51  Lr: 0.001875  Loss: -0.1784  Acc@1: 81.2500 (71.8875)  Acc@5: 100.0000 (93.6753)  time: 0.3485  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [ 260/3125]  eta: 0:16:48  Lr: 0.001875  Loss: -0.2308  Acc@1: 75.0000 (72.2462)  Acc@5: 100.0000 (93.7979)  time: 0.3498  data: 0.0012  max mem: 2502
Train: Epoch[1/5]  [ 270/3125]  eta: 0:16:44  Lr: 0.001875  Loss: -0.2485  Acc@1: 75.0000 (72.5554)  Acc@5: 100.0000 (93.9345)  time: 0.3499  data: 0.0012  max mem: 2502
Train: Epoch[1/5]  [ 280/3125]  eta: 0:16:40  Lr: 0.001875  Loss: -0.2454  Acc@1: 75.0000 (72.5979)  Acc@5: 100.0000 (94.0391)  time: 0.3495  data: 0.0006  max mem: 2502
Train: Epoch[1/5]  [ 290/3125]  eta: 0:16:36  Lr: 0.001875  Loss: -0.4878  Acc@1: 75.0000 (72.8308)  Acc@5: 100.0000 (94.1581)  time: 0.3494  data: 0.0007  max mem: 2502
Train: Epoch[1/5]  [ 300/3125]  eta: 0:16:33  Lr: 0.001875  Loss: -0.2800  Acc@1: 75.0000 (72.9444)  Acc@5: 100.0000 (94.2691)  time: 0.3488  data: 0.0006  max mem: 2502
Train: Epoch[1/5]  [ 310/3125]  eta: 0:16:29  Lr: 0.001875  Loss: -0.1488  Acc@1: 75.0000 (73.0105)  Acc@5: 100.0000 (94.3529)  time: 0.3496  data: 0.0006  max mem: 2502
Train: Epoch[1/5]  [ 320/3125]  eta: 0:16:25  Lr: 0.001875  Loss: -0.3437  Acc@1: 81.2500 (73.3645)  Acc@5: 100.0000 (94.4704)  time: 0.3497  data: 0.0006  max mem: 2502
Train: Epoch[1/5]  [ 330/3125]  eta: 0:16:22  Lr: 0.001875  Loss: 0.5006  Acc@1: 87.5000 (73.6216)  Acc@5: 100.0000 (94.5619)  time: 0.3492  data: 0.0006  max mem: 2502
Train: Epoch[1/5]  [ 340/3125]  eta: 0:16:18  Lr: 0.001875  Loss: -0.5049  Acc@1: 81.2500 (73.7720)  Acc@5: 100.0000 (94.6114)  time: 0.3492  data: 0.0006  max mem: 2502
Train: Epoch[1/5]  [ 350/3125]  eta: 0:16:14  Lr: 0.001875  Loss: -0.1941  Acc@1: 81.2500 (73.9672)  Acc@5: 100.0000 (94.6759)  time: 0.3496  data: 0.0006  max mem: 2502
Train: Epoch[1/5]  [ 360/3125]  eta: 0:16:11  Lr: 0.001875  Loss: -0.1591  Acc@1: 81.2500 (74.1690)  Acc@5: 100.0000 (94.7715)  time: 0.3503  data: 0.0007  max mem: 2502
Train: Epoch[1/5]  [ 370/3125]  eta: 0:16:07  Lr: 0.001875  Loss: 0.0793  Acc@1: 81.2500 (74.2588)  Acc@5: 100.0000 (94.8282)  time: 0.3492  data: 0.0006  max mem: 2502
Train: Epoch[1/5]  [ 380/3125]  eta: 0:16:03  Lr: 0.001875  Loss: -0.5489  Acc@1: 81.2500 (74.5243)  Acc@5: 100.0000 (94.8819)  time: 0.3494  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [ 390/3125]  eta: 0:16:00  Lr: 0.001875  Loss: 0.0815  Acc@1: 87.5000 (74.5844)  Acc@5: 100.0000 (94.8689)  time: 0.3500  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [ 400/3125]  eta: 0:15:56  Lr: 0.001875  Loss: -0.0543  Acc@1: 81.2500 (74.7506)  Acc@5: 93.7500 (94.8722)  time: 0.3489  data: 0.0006  max mem: 2502
Train: Epoch[1/5]  [ 410/3125]  eta: 0:15:52  Lr: 0.001875  Loss: -0.4314  Acc@1: 87.5000 (75.0912)  Acc@5: 100.0000 (94.9057)  time: 0.3480  data: 0.0007  max mem: 2502
Train: Epoch[1/5]  [ 420/3125]  eta: 0:15:49  Lr: 0.001875  Loss: 0.0724  Acc@1: 87.5000 (75.1485)  Acc@5: 100.0000 (94.9822)  time: 0.3483  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [ 430/3125]  eta: 0:15:45  Lr: 0.001875  Loss: -0.5210  Acc@1: 81.2500 (75.3625)  Acc@5: 100.0000 (95.0406)  time: 0.3498  data: 0.0007  max mem: 2502
Train: Epoch[1/5]  [ 440/3125]  eta: 0:15:42  Lr: 0.001875  Loss: -0.2648  Acc@1: 81.2500 (75.4252)  Acc@5: 100.0000 (95.0680)  time: 0.3506  data: 0.0008  max mem: 2502
Train: Epoch[1/5]  [ 450/3125]  eta: 0:15:38  Lr: 0.001875  Loss: -0.3101  Acc@1: 81.2500 (75.5543)  Acc@5: 100.0000 (95.1497)  time: 0.3496  data: 0.0006  max mem: 2502
Train: Epoch[1/5]  [ 460/3125]  eta: 0:15:34  Lr: 0.001875  Loss: -0.3062  Acc@1: 81.2500 (75.6508)  Acc@5: 100.0000 (95.2142)  time: 0.3481  data: 0.0006  max mem: 2502
Train: Epoch[1/5]  [ 470/3125]  eta: 0:15:31  Lr: 0.001875  Loss: -0.1485  Acc@1: 81.2500 (75.7166)  Acc@5: 100.0000 (95.2893)  time: 0.3486  data: 0.0006  max mem: 2502
Train: Epoch[1/5]  [ 480/3125]  eta: 0:15:27  Lr: 0.001875  Loss: -0.2705  Acc@1: 81.2500 (75.8056)  Acc@5: 100.0000 (95.3352)  time: 0.3484  data: 0.0008  max mem: 2502
Train: Epoch[1/5]  [ 490/3125]  eta: 0:15:24  Lr: 0.001875  Loss: -0.6995  Acc@1: 81.2500 (75.9547)  Acc@5: 100.0000 (95.4048)  time: 0.3493  data: 0.0006  max mem: 2502
Train: Epoch[1/5]  [ 500/3125]  eta: 0:15:20  Lr: 0.001875  Loss: -0.2722  Acc@1: 81.2500 (75.9980)  Acc@5: 100.0000 (95.4716)  time: 0.3508  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [ 510/3125]  eta: 0:15:16  Lr: 0.001875  Loss: -0.6265  Acc@1: 81.2500 (76.0519)  Acc@5: 100.0000 (95.5235)  time: 0.3490  data: 0.0008  max mem: 2502
Train: Epoch[1/5]  [ 520/3125]  eta: 0:15:13  Lr: 0.001875  Loss: -0.4739  Acc@1: 81.2500 (76.1516)  Acc@5: 100.0000 (95.5734)  time: 0.3479  data: 0.0014  max mem: 2502
Train: Epoch[1/5]  [ 530/3125]  eta: 0:15:09  Lr: 0.001875  Loss: -0.1865  Acc@1: 75.0000 (76.1535)  Acc@5: 100.0000 (95.6097)  time: 0.3481  data: 0.0011  max mem: 2502
Train: Epoch[1/5]  [ 540/3125]  eta: 0:15:06  Lr: 0.001875  Loss: -0.1684  Acc@1: 75.0000 (76.1899)  Acc@5: 100.0000 (95.6677)  time: 0.3486  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [ 550/3125]  eta: 0:15:02  Lr: 0.001875  Loss: -0.1811  Acc@1: 81.2500 (76.2137)  Acc@5: 100.0000 (95.7010)  time: 0.3482  data: 0.0007  max mem: 2502
Train: Epoch[1/5]  [ 560/3125]  eta: 0:14:58  Lr: 0.001875  Loss: -0.4763  Acc@1: 81.2500 (76.3369)  Acc@5: 100.0000 (95.7665)  time: 0.3479  data: 0.0007  max mem: 2502
Train: Epoch[1/5]  [ 570/3125]  eta: 0:14:55  Lr: 0.001875  Loss: -0.3350  Acc@1: 81.2500 (76.3463)  Acc@5: 100.0000 (95.8297)  time: 0.3493  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [ 580/3125]  eta: 0:14:51  Lr: 0.001875  Loss: -0.3816  Acc@1: 81.2500 (76.3985)  Acc@5: 100.0000 (95.8369)  time: 0.3501  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [ 590/3125]  eta: 0:14:48  Lr: 0.001875  Loss: -0.3244  Acc@1: 81.2500 (76.4065)  Acc@5: 100.0000 (95.8651)  time: 0.3499  data: 0.0007  max mem: 2502
Train: Epoch[1/5]  [ 600/3125]  eta: 0:14:44  Lr: 0.001875  Loss: -0.3083  Acc@1: 75.0000 (76.4455)  Acc@5: 100.0000 (95.8923)  time: 0.3484  data: 0.0007  max mem: 2502
Train: Epoch[1/5]  [ 610/3125]  eta: 0:14:40  Lr: 0.001875  Loss: -0.5175  Acc@1: 81.2500 (76.6060)  Acc@5: 100.0000 (95.9288)  time: 0.3470  data: 0.0006  max mem: 2502
Train: Epoch[1/5]  [ 620/3125]  eta: 0:14:37  Lr: 0.001875  Loss: -0.4102  Acc@1: 81.2500 (76.5801)  Acc@5: 100.0000 (95.9642)  time: 0.3485  data: 0.0006  max mem: 2502
Train: Epoch[1/5]  [ 630/3125]  eta: 0:14:33  Lr: 0.001875  Loss: -0.3234  Acc@1: 81.2500 (76.6244)  Acc@5: 100.0000 (96.0083)  time: 0.3507  data: 0.0013  max mem: 2502
Train: Epoch[1/5]  [ 640/3125]  eta: 0:14:30  Lr: 0.001875  Loss: -0.3300  Acc@1: 81.2500 (76.7453)  Acc@5: 100.0000 (96.0413)  time: 0.3502  data: 0.0014  max mem: 2502
Train: Epoch[1/5]  [ 650/3125]  eta: 0:14:26  Lr: 0.001875  Loss: -0.5568  Acc@1: 81.2500 (76.7665)  Acc@5: 100.0000 (96.0541)  time: 0.3482  data: 0.0006  max mem: 2502
Train: Epoch[1/5]  [ 660/3125]  eta: 0:14:23  Lr: 0.001875  Loss: -0.0373  Acc@1: 81.2500 (76.8154)  Acc@5: 100.0000 (96.0666)  time: 0.3470  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [ 670/3125]  eta: 0:14:19  Lr: 0.001875  Loss: -0.4506  Acc@1: 81.2500 (76.8629)  Acc@5: 100.0000 (96.1066)  time: 0.3458  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [ 680/3125]  eta: 0:14:15  Lr: 0.001875  Loss: -0.5161  Acc@1: 81.2500 (76.9457)  Acc@5: 100.0000 (96.1270)  time: 0.3463  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [ 690/3125]  eta: 0:14:12  Lr: 0.001875  Loss: -0.5801  Acc@1: 81.2500 (76.9356)  Acc@5: 100.0000 (96.1378)  time: 0.3477  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [ 700/3125]  eta: 0:14:08  Lr: 0.001875  Loss: -0.4240  Acc@1: 81.2500 (77.0328)  Acc@5: 100.0000 (96.1484)  time: 0.3481  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [ 710/3125]  eta: 0:14:05  Lr: 0.001875  Loss: -0.5699  Acc@1: 81.2500 (77.1009)  Acc@5: 100.0000 (96.1762)  time: 0.3480  data: 0.0006  max mem: 2502
Train: Epoch[1/5]  [ 720/3125]  eta: 0:14:01  Lr: 0.001875  Loss: -0.3955  Acc@1: 81.2500 (77.1498)  Acc@5: 100.0000 (96.1859)  time: 0.3471  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [ 730/3125]  eta: 0:13:58  Lr: 0.001875  Loss: -0.6020  Acc@1: 81.2500 (77.2828)  Acc@5: 100.0000 (96.2209)  time: 0.3484  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [ 740/3125]  eta: 0:13:54  Lr: 0.001875  Loss: -0.6465  Acc@1: 81.2500 (77.3448)  Acc@5: 100.0000 (96.2466)  time: 0.3500  data: 0.0012  max mem: 2502
Train: Epoch[1/5]  [ 750/3125]  eta: 0:13:51  Lr: 0.001875  Loss: -0.3474  Acc@1: 81.2500 (77.4301)  Acc@5: 100.0000 (96.2633)  time: 0.3497  data: 0.0012  max mem: 2502
Train: Epoch[1/5]  [ 760/3125]  eta: 0:13:47  Lr: 0.001875  Loss: -0.1965  Acc@1: 81.2500 (77.4639)  Acc@5: 93.7500 (96.2303)  time: 0.3496  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [ 770/3125]  eta: 0:13:43  Lr: 0.001875  Loss: -0.2422  Acc@1: 81.2500 (77.5130)  Acc@5: 100.0000 (96.2549)  time: 0.3489  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [ 780/3125]  eta: 0:13:40  Lr: 0.001875  Loss: -0.5479  Acc@1: 81.2500 (77.6168)  Acc@5: 100.0000 (96.2868)  time: 0.3488  data: 0.0007  max mem: 2502
Train: Epoch[1/5]  [ 790/3125]  eta: 0:13:37  Lr: 0.001875  Loss: -0.0399  Acc@1: 87.5000 (77.7181)  Acc@5: 100.0000 (96.3180)  time: 0.3501  data: 0.0008  max mem: 2502
Train: Epoch[1/5]  [ 800/3125]  eta: 0:13:33  Lr: 0.001875  Loss: -0.4186  Acc@1: 87.5000 (77.7856)  Acc@5: 100.0000 (96.3249)  time: 0.3500  data: 0.0006  max mem: 2502
Train: Epoch[1/5]  [ 810/3125]  eta: 0:13:29  Lr: 0.001875  Loss: -0.5179  Acc@1: 81.2500 (77.8360)  Acc@5: 100.0000 (96.3394)  time: 0.3494  data: 0.0007  max mem: 2502
Train: Epoch[1/5]  [ 820/3125]  eta: 0:13:26  Lr: 0.001875  Loss: -0.3094  Acc@1: 81.2500 (77.8471)  Acc@5: 100.0000 (96.3611)  time: 0.3488  data: 0.0006  max mem: 2502
Train: Epoch[1/5]  [ 830/3125]  eta: 0:13:22  Lr: 0.001875  Loss: -0.4232  Acc@1: 81.2500 (77.8580)  Acc@5: 100.0000 (96.3824)  time: 0.3483  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [ 840/3125]  eta: 0:13:19  Lr: 0.001875  Loss: -0.7602  Acc@1: 81.2500 (77.8983)  Acc@5: 100.0000 (96.3957)  time: 0.3487  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [ 850/3125]  eta: 0:13:15  Lr: 0.001875  Loss: -0.6263  Acc@1: 75.0000 (77.8790)  Acc@5: 100.0000 (96.3939)  time: 0.3489  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [ 860/3125]  eta: 0:13:12  Lr: 0.001875  Loss: -0.5134  Acc@1: 81.2500 (77.9109)  Acc@5: 100.0000 (96.3850)  time: 0.3494  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [ 870/3125]  eta: 0:13:08  Lr: 0.001875  Loss: -0.2140  Acc@1: 81.2500 (77.9133)  Acc@5: 93.7500 (96.3835)  time: 0.3494  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [ 880/3125]  eta: 0:13:05  Lr: 0.001875  Loss: -0.3709  Acc@1: 81.2500 (77.9228)  Acc@5: 100.0000 (96.3961)  time: 0.3488  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [ 890/3125]  eta: 0:13:01  Lr: 0.001875  Loss: -0.3021  Acc@1: 81.2500 (77.9321)  Acc@5: 100.0000 (96.4015)  time: 0.3489  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [ 900/3125]  eta: 0:12:58  Lr: 0.001875  Loss: -0.3569  Acc@1: 81.2500 (77.9759)  Acc@5: 100.0000 (96.4137)  time: 0.3497  data: 0.0006  max mem: 2502
Train: Epoch[1/5]  [ 910/3125]  eta: 0:12:54  Lr: 0.001875  Loss: -0.6020  Acc@1: 81.2500 (77.9844)  Acc@5: 100.0000 (96.4256)  time: 0.3494  data: 0.0006  max mem: 2502
Train: Epoch[1/5]  [ 920/3125]  eta: 0:12:51  Lr: 0.001875  Loss: -0.3648  Acc@1: 81.2500 (78.0537)  Acc@5: 100.0000 (96.4509)  time: 0.3491  data: 0.0006  max mem: 2502
Train: Epoch[1/5]  [ 930/3125]  eta: 0:12:47  Lr: 0.001875  Loss: -0.4910  Acc@1: 81.2500 (78.1216)  Acc@5: 100.0000 (96.4756)  time: 0.3514  data: 0.0007  max mem: 2502
Train: Epoch[1/5]  [ 940/3125]  eta: 0:12:44  Lr: 0.001875  Loss: -0.6345  Acc@1: 81.2500 (78.1947)  Acc@5: 100.0000 (96.4997)  time: 0.3517  data: 0.0007  max mem: 2502
Train: Epoch[1/5]  [ 950/3125]  eta: 0:12:40  Lr: 0.001875  Loss: -0.3567  Acc@1: 81.2500 (78.1940)  Acc@5: 100.0000 (96.5168)  time: 0.3505  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [ 960/3125]  eta: 0:12:37  Lr: 0.001875  Loss: -0.3521  Acc@1: 81.2500 (78.2258)  Acc@5: 100.0000 (96.5466)  time: 0.3504  data: 0.0007  max mem: 2502
Train: Epoch[1/5]  [ 970/3125]  eta: 0:12:33  Lr: 0.001875  Loss: -0.7382  Acc@1: 87.5000 (78.3406)  Acc@5: 100.0000 (96.5757)  time: 0.3488  data: 0.0008  max mem: 2502
Train: Epoch[1/5]  [ 980/3125]  eta: 0:12:30  Lr: 0.001875  Loss: -0.5840  Acc@1: 87.5000 (78.3958)  Acc@5: 100.0000 (96.5915)  time: 0.3486  data: 0.0007  max mem: 2502
Train: Epoch[1/5]  [ 990/3125]  eta: 0:12:26  Lr: 0.001875  Loss: -0.4724  Acc@1: 81.2500 (78.4372)  Acc@5: 100.0000 (96.5943)  time: 0.3495  data: 0.0006  max mem: 2502
Train: Epoch[1/5]  [1000/3125]  eta: 0:12:23  Lr: 0.001875  Loss: -0.3463  Acc@1: 81.2500 (78.4840)  Acc@5: 100.0000 (96.5909)  time: 0.3497  data: 0.0006  max mem: 2502
Train: Epoch[1/5]  [1010/3125]  eta: 0:12:19  Lr: 0.001875  Loss: -0.4456  Acc@1: 81.2500 (78.4743)  Acc@5: 100.0000 (96.5999)  time: 0.3496  data: 0.0007  max mem: 2502
Train: Epoch[1/5]  [1020/3125]  eta: 0:12:16  Lr: 0.001875  Loss: -0.7461  Acc@1: 81.2500 (78.5137)  Acc@5: 100.0000 (96.6026)  time: 0.3499  data: 0.0009  max mem: 2502
Train: Epoch[1/5]  [1030/3125]  eta: 0:12:12  Lr: 0.001875  Loss: -0.3645  Acc@1: 81.2500 (78.5766)  Acc@5: 100.0000 (96.6113)  time: 0.3497  data: 0.0007  max mem: 2502
Train: Epoch[1/5]  [1040/3125]  eta: 0:12:09  Lr: 0.001875  Loss: -0.6195  Acc@1: 81.2500 (78.6023)  Acc@5: 100.0000 (96.6198)  time: 0.3487  data: 0.0006  max mem: 2502
Train: Epoch[1/5]  [1050/3125]  eta: 0:12:05  Lr: 0.001875  Loss: -0.5507  Acc@1: 81.2500 (78.6513)  Acc@5: 100.0000 (96.6401)  time: 0.3484  data: 0.0009  max mem: 2502
Train: Epoch[1/5]  [1060/3125]  eta: 0:12:02  Lr: 0.001875  Loss: -0.2143  Acc@1: 81.2500 (78.6993)  Acc@5: 100.0000 (96.6541)  time: 0.3488  data: 0.0008  max mem: 2502
Train: Epoch[1/5]  [1070/3125]  eta: 0:11:58  Lr: 0.001875  Loss: -0.3267  Acc@1: 81.2500 (78.7173)  Acc@5: 100.0000 (96.6562)  time: 0.3486  data: 0.0006  max mem: 2502
Train: Epoch[1/5]  [1080/3125]  eta: 0:11:55  Lr: 0.001875  Loss: -0.4812  Acc@1: 81.2500 (78.7581)  Acc@5: 100.0000 (96.6813)  time: 0.3489  data: 0.0010  max mem: 2502
Train: Epoch[1/5]  [1090/3125]  eta: 0:11:51  Lr: 0.001875  Loss: -0.6058  Acc@1: 87.5000 (78.7809)  Acc@5: 100.0000 (96.6888)  time: 0.3505  data: 0.0011  max mem: 2502
Train: Epoch[1/5]  [1100/3125]  eta: 0:11:48  Lr: 0.001875  Loss: -0.4657  Acc@1: 81.2500 (78.8034)  Acc@5: 100.0000 (96.7075)  time: 0.3501  data: 0.0006  max mem: 2502
Train: Epoch[1/5]  [1110/3125]  eta: 0:11:44  Lr: 0.001875  Loss: -0.0830  Acc@1: 81.2500 (78.8254)  Acc@5: 100.0000 (96.7259)  time: 0.3488  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [1120/3125]  eta: 0:11:41  Lr: 0.001875  Loss: -0.2638  Acc@1: 81.2500 (78.8470)  Acc@5: 100.0000 (96.7440)  time: 0.3506  data: 0.0006  max mem: 2502
Train: Epoch[1/5]  [1130/3125]  eta: 0:11:37  Lr: 0.001875  Loss: -0.5947  Acc@1: 81.2500 (78.8959)  Acc@5: 100.0000 (96.7396)  time: 0.3497  data: 0.0006  max mem: 2502
Train: Epoch[1/5]  [1140/3125]  eta: 0:11:34  Lr: 0.001875  Loss: -0.1847  Acc@1: 81.2500 (78.8782)  Acc@5: 100.0000 (96.7463)  time: 0.3471  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [1150/3125]  eta: 0:11:30  Lr: 0.001875  Loss: -0.1721  Acc@1: 75.0000 (78.8825)  Acc@5: 100.0000 (96.7528)  time: 0.3482  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [1160/3125]  eta: 0:11:27  Lr: 0.001875  Loss: -0.4452  Acc@1: 81.2500 (78.9137)  Acc@5: 100.0000 (96.7700)  time: 0.3497  data: 0.0006  max mem: 2502
Train: Epoch[1/5]  [1170/3125]  eta: 0:11:23  Lr: 0.001875  Loss: -0.3959  Acc@1: 87.5000 (78.9656)  Acc@5: 100.0000 (96.7709)  time: 0.3492  data: 0.0006  max mem: 2502
Train: Epoch[1/5]  [1180/3125]  eta: 0:11:20  Lr: 0.001875  Loss: -0.7198  Acc@1: 87.5000 (79.0061)  Acc@5: 100.0000 (96.7824)  time: 0.3502  data: 0.0007  max mem: 2502
Train: Epoch[1/5]  [1190/3125]  eta: 0:11:16  Lr: 0.001875  Loss: -0.6432  Acc@1: 93.7500 (79.1037)  Acc@5: 100.0000 (96.7989)  time: 0.3508  data: 0.0015  max mem: 2502
Train: Epoch[1/5]  [1200/3125]  eta: 0:11:13  Lr: 0.001875  Loss: -0.6807  Acc@1: 81.2500 (79.1007)  Acc@5: 100.0000 (96.8047)  time: 0.3491  data: 0.0014  max mem: 2502
Train: Epoch[1/5]  [1210/3125]  eta: 0:11:09  Lr: 0.001875  Loss: -0.3443  Acc@1: 81.2500 (79.1237)  Acc@5: 100.0000 (96.8105)  time: 0.3498  data: 0.0008  max mem: 2502
Train: Epoch[1/5]  [1220/3125]  eta: 0:11:06  Lr: 0.001875  Loss: -0.8977  Acc@1: 87.5000 (79.1871)  Acc@5: 100.0000 (96.8264)  time: 0.3493  data: 0.0008  max mem: 2502
Train: Epoch[1/5]  [1230/3125]  eta: 0:11:02  Lr: 0.001875  Loss: -0.2764  Acc@1: 87.5000 (79.2242)  Acc@5: 100.0000 (96.8369)  time: 0.3497  data: 0.0006  max mem: 2502
Train: Epoch[1/5]  [1240/3125]  eta: 0:10:59  Lr: 0.001875  Loss: -0.2990  Acc@1: 81.2500 (79.2607)  Acc@5: 100.0000 (96.8423)  time: 0.3490  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [1250/3125]  eta: 0:10:55  Lr: 0.001875  Loss: -0.6481  Acc@1: 81.2500 (79.2766)  Acc@5: 100.0000 (96.8525)  time: 0.3476  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [1260/3125]  eta: 0:10:52  Lr: 0.001875  Loss: -0.5275  Acc@1: 87.5000 (79.3269)  Acc@5: 100.0000 (96.8626)  time: 0.3484  data: 0.0006  max mem: 2502
Train: Epoch[1/5]  [1270/3125]  eta: 0:10:48  Lr: 0.001875  Loss: -0.6346  Acc@1: 87.5000 (79.3666)  Acc@5: 100.0000 (96.8725)  time: 0.3483  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [1280/3125]  eta: 0:10:45  Lr: 0.001875  Loss: -0.1631  Acc@1: 81.2500 (79.3862)  Acc@5: 100.0000 (96.8677)  time: 0.3483  data: 0.0009  max mem: 2502
Train: Epoch[1/5]  [1290/3125]  eta: 0:10:41  Lr: 0.001875  Loss: -0.2224  Acc@1: 81.2500 (79.4249)  Acc@5: 100.0000 (96.8774)  time: 0.3474  data: 0.0008  max mem: 2502
Train: Epoch[1/5]  [1300/3125]  eta: 0:10:38  Lr: 0.001875  Loss: -0.4560  Acc@1: 81.2500 (79.4533)  Acc@5: 100.0000 (96.8870)  time: 0.3471  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [1310/3125]  eta: 0:10:34  Lr: 0.001875  Loss: -0.1680  Acc@1: 87.5000 (79.4861)  Acc@5: 100.0000 (96.9012)  time: 0.3475  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [1320/3125]  eta: 0:10:31  Lr: 0.001875  Loss: -0.6237  Acc@1: 87.5000 (79.5420)  Acc@5: 100.0000 (96.8963)  time: 0.3475  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [1330/3125]  eta: 0:10:27  Lr: 0.001875  Loss: -0.5503  Acc@1: 87.5000 (79.6347)  Acc@5: 100.0000 (96.9149)  time: 0.3469  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [1340/3125]  eta: 0:10:23  Lr: 0.001875  Loss: -0.8281  Acc@1: 87.5000 (79.6607)  Acc@5: 100.0000 (96.9333)  time: 0.3473  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [1350/3125]  eta: 0:10:20  Lr: 0.001875  Loss: -0.3751  Acc@1: 81.2500 (79.6678)  Acc@5: 100.0000 (96.9421)  time: 0.3489  data: 0.0006  max mem: 2502
Train: Epoch[1/5]  [1360/3125]  eta: 0:10:16  Lr: 0.001875  Loss: -0.4610  Acc@1: 81.2500 (79.6565)  Acc@5: 100.0000 (96.9462)  time: 0.3492  data: 0.0007  max mem: 2502
Train: Epoch[1/5]  [1370/3125]  eta: 0:10:13  Lr: 0.001875  Loss: -0.4185  Acc@1: 81.2500 (79.7000)  Acc@5: 100.0000 (96.9548)  time: 0.3485  data: 0.0006  max mem: 2502
Train: Epoch[1/5]  [1380/3125]  eta: 0:10:09  Lr: 0.001875  Loss: -0.6067  Acc@1: 81.2500 (79.7294)  Acc@5: 100.0000 (96.9678)  time: 0.3483  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [1390/3125]  eta: 0:10:06  Lr: 0.001875  Loss: -0.1413  Acc@1: 81.2500 (79.7358)  Acc@5: 100.0000 (96.9806)  time: 0.3489  data: 0.0007  max mem: 2502
Train: Epoch[1/5]  [1400/3125]  eta: 0:10:02  Lr: 0.001875  Loss: -0.4382  Acc@1: 81.2500 (79.7511)  Acc@5: 100.0000 (96.9888)  time: 0.3491  data: 0.0007  max mem: 2502
Train: Epoch[1/5]  [1410/3125]  eta: 0:09:59  Lr: 0.001875  Loss: -0.3821  Acc@1: 81.2500 (79.7750)  Acc@5: 100.0000 (96.9968)  time: 0.3489  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [1420/3125]  eta: 0:09:55  Lr: 0.001875  Loss: -0.6488  Acc@1: 81.2500 (79.8030)  Acc@5: 100.0000 (96.9916)  time: 0.3481  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [1430/3125]  eta: 0:09:52  Lr: 0.001875  Loss: 0.1262  Acc@1: 75.0000 (79.7694)  Acc@5: 93.7500 (96.9820)  time: 0.3478  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [1440/3125]  eta: 0:09:48  Lr: 0.001875  Loss: -0.0553  Acc@1: 75.0000 (79.7797)  Acc@5: 93.7500 (96.9726)  time: 0.3480  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [1450/3125]  eta: 0:09:45  Lr: 0.001875  Loss: -0.5941  Acc@1: 81.2500 (79.8156)  Acc@5: 100.0000 (96.9805)  time: 0.3481  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [1460/3125]  eta: 0:09:41  Lr: 0.001875  Loss: -0.5977  Acc@1: 81.2500 (79.8383)  Acc@5: 100.0000 (96.9969)  time: 0.3475  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [1470/3125]  eta: 0:09:38  Lr: 0.001875  Loss: -0.5056  Acc@1: 87.5000 (79.8861)  Acc@5: 100.0000 (97.0131)  time: 0.3472  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [1480/3125]  eta: 0:09:34  Lr: 0.001875  Loss: -0.6591  Acc@1: 81.2500 (79.8869)  Acc@5: 100.0000 (97.0079)  time: 0.3482  data: 0.0006  max mem: 2502
Train: Epoch[1/5]  [1490/3125]  eta: 0:09:31  Lr: 0.001875  Loss: -0.1583  Acc@1: 81.2500 (79.8877)  Acc@5: 100.0000 (97.0070)  time: 0.3488  data: 0.0006  max mem: 2502
Train: Epoch[1/5]  [1500/3125]  eta: 0:09:27  Lr: 0.001875  Loss: -0.5138  Acc@1: 81.2500 (79.8718)  Acc@5: 100.0000 (97.0062)  time: 0.3503  data: 0.0007  max mem: 2502
Train: Epoch[1/5]  [1510/3125]  eta: 0:09:24  Lr: 0.001875  Loss: -0.5583  Acc@1: 87.5000 (79.8933)  Acc@5: 100.0000 (97.0094)  time: 0.3503  data: 0.0008  max mem: 2502
Train: Epoch[1/5]  [1520/3125]  eta: 0:09:20  Lr: 0.001875  Loss: -0.7463  Acc@1: 87.5000 (79.8940)  Acc@5: 100.0000 (97.0085)  time: 0.3486  data: 0.0006  max mem: 2502
Train: Epoch[1/5]  [1530/3125]  eta: 0:09:17  Lr: 0.001875  Loss: -0.2605  Acc@1: 81.2500 (79.9233)  Acc@5: 100.0000 (97.0118)  time: 0.3498  data: 0.0022  max mem: 2502
Train: Epoch[1/5]  [1540/3125]  eta: 0:09:13  Lr: 0.001875  Loss: -0.2958  Acc@1: 87.5000 (79.9643)  Acc@5: 100.0000 (97.0149)  time: 0.3520  data: 0.0024  max mem: 2502
Train: Epoch[1/5]  [1550/3125]  eta: 0:09:10  Lr: 0.001875  Loss: -0.3943  Acc@1: 87.5000 (79.9887)  Acc@5: 100.0000 (97.0301)  time: 0.3516  data: 0.0010  max mem: 2502
Train: Epoch[1/5]  [1560/3125]  eta: 0:09:06  Lr: 0.001875  Loss: -0.6176  Acc@1: 81.2500 (80.0208)  Acc@5: 100.0000 (97.0372)  time: 0.3505  data: 0.0007  max mem: 2502
Train: Epoch[1/5]  [1570/3125]  eta: 0:09:03  Lr: 0.001875  Loss: -0.2860  Acc@1: 81.2500 (80.0485)  Acc@5: 100.0000 (97.0401)  time: 0.3501  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [1580/3125]  eta: 0:08:59  Lr: 0.001875  Loss: -0.6732  Acc@1: 81.2500 (80.0680)  Acc@5: 100.0000 (97.0351)  time: 0.3506  data: 0.0006  max mem: 2502
Train: Epoch[1/5]  [1590/3125]  eta: 0:08:56  Lr: 0.001875  Loss: -0.3196  Acc@1: 87.5000 (80.0911)  Acc@5: 100.0000 (97.0420)  time: 0.3505  data: 0.0006  max mem: 2502
Train: Epoch[1/5]  [1600/3125]  eta: 0:08:52  Lr: 0.001875  Loss: -0.6548  Acc@1: 87.5000 (80.1179)  Acc@5: 100.0000 (97.0487)  time: 0.3489  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [1610/3125]  eta: 0:08:49  Lr: 0.001875  Loss: -0.5251  Acc@1: 81.2500 (80.1210)  Acc@5: 100.0000 (97.0593)  time: 0.3481  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [1620/3125]  eta: 0:08:45  Lr: 0.001875  Loss: -0.6118  Acc@1: 81.2500 (80.1242)  Acc@5: 100.0000 (97.0697)  time: 0.3489  data: 0.0006  max mem: 2502
Train: Epoch[1/5]  [1630/3125]  eta: 0:08:42  Lr: 0.001875  Loss: -0.6046  Acc@1: 81.2500 (80.1502)  Acc@5: 100.0000 (97.0800)  time: 0.3498  data: 0.0007  max mem: 2502
Train: Epoch[1/5]  [1640/3125]  eta: 0:08:38  Lr: 0.001875  Loss: -0.4424  Acc@1: 87.5000 (80.1874)  Acc@5: 100.0000 (97.0826)  time: 0.3500  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [1650/3125]  eta: 0:08:35  Lr: 0.001875  Loss: -0.9068  Acc@1: 87.5000 (80.2165)  Acc@5: 100.0000 (97.0851)  time: 0.3503  data: 0.0006  max mem: 2502
Train: Epoch[1/5]  [1660/3125]  eta: 0:08:32  Lr: 0.001875  Loss: -0.2058  Acc@1: 87.5000 (80.2529)  Acc@5: 100.0000 (97.0838)  time: 0.3501  data: 0.0007  max mem: 2502
Train: Epoch[1/5]  [1670/3125]  eta: 0:08:28  Lr: 0.001875  Loss: -0.6357  Acc@1: 87.5000 (80.2813)  Acc@5: 100.0000 (97.0863)  time: 0.3483  data: 0.0007  max mem: 2502
Train: Epoch[1/5]  [1680/3125]  eta: 0:08:25  Lr: 0.001875  Loss: -0.6218  Acc@1: 81.2500 (80.2945)  Acc@5: 100.0000 (97.0888)  time: 0.3485  data: 0.0007  max mem: 2502
Train: Epoch[1/5]  [1690/3125]  eta: 0:08:21  Lr: 0.001875  Loss: -0.3499  Acc@1: 81.2500 (80.2964)  Acc@5: 100.0000 (97.0986)  time: 0.3497  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [1700/3125]  eta: 0:08:18  Lr: 0.001875  Loss: -0.5114  Acc@1: 81.2500 (80.3167)  Acc@5: 100.0000 (97.1083)  time: 0.3491  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [1710/3125]  eta: 0:08:14  Lr: 0.001875  Loss: -0.3346  Acc@1: 87.5000 (80.3660)  Acc@5: 100.0000 (97.1033)  time: 0.3484  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [1720/3125]  eta: 0:08:11  Lr: 0.001875  Loss: -0.5060  Acc@1: 87.5000 (80.3893)  Acc@5: 100.0000 (97.1129)  time: 0.3492  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [1730/3125]  eta: 0:08:07  Lr: 0.001875  Loss: -0.5683  Acc@1: 87.5000 (80.4412)  Acc@5: 100.0000 (97.1151)  time: 0.3493  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [1740/3125]  eta: 0:08:04  Lr: 0.001875  Loss: -0.7122  Acc@1: 87.5000 (80.4782)  Acc@5: 100.0000 (97.1137)  time: 0.3483  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [1750/3125]  eta: 0:08:00  Lr: 0.001875  Loss: -0.6819  Acc@1: 87.5000 (80.5004)  Acc@5: 100.0000 (97.1195)  time: 0.3484  data: 0.0006  max mem: 2502
Train: Epoch[1/5]  [1760/3125]  eta: 0:07:57  Lr: 0.001875  Loss: 0.0449  Acc@1: 81.2500 (80.5153)  Acc@5: 100.0000 (97.1146)  time: 0.3487  data: 0.0006  max mem: 2502
Train: Epoch[1/5]  [1770/3125]  eta: 0:07:53  Lr: 0.001875  Loss: -0.6398  Acc@1: 81.2500 (80.5301)  Acc@5: 100.0000 (97.1167)  time: 0.3490  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [1780/3125]  eta: 0:07:50  Lr: 0.001875  Loss: -0.7197  Acc@1: 87.5000 (80.5587)  Acc@5: 100.0000 (97.1224)  time: 0.3492  data: 0.0006  max mem: 2502
Train: Epoch[1/5]  [1790/3125]  eta: 0:07:46  Lr: 0.001875  Loss: -0.4600  Acc@1: 87.5000 (80.5800)  Acc@5: 100.0000 (97.1350)  time: 0.3484  data: 0.0006  max mem: 2502
Train: Epoch[1/5]  [1800/3125]  eta: 0:07:43  Lr: 0.001875  Loss: 0.0990  Acc@1: 87.5000 (80.5976)  Acc@5: 100.0000 (97.1474)  time: 0.3483  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [1810/3125]  eta: 0:07:39  Lr: 0.001875  Loss: -0.4104  Acc@1: 87.5000 (80.6322)  Acc@5: 100.0000 (97.1632)  time: 0.3496  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [1820/3125]  eta: 0:07:36  Lr: 0.001875  Loss: -0.2793  Acc@1: 81.2500 (80.6425)  Acc@5: 100.0000 (97.1719)  time: 0.3513  data: 0.0007  max mem: 2502
Train: Epoch[1/5]  [1830/3125]  eta: 0:07:32  Lr: 0.001875  Loss: -0.3981  Acc@1: 81.2500 (80.6629)  Acc@5: 100.0000 (97.1805)  time: 0.3504  data: 0.0006  max mem: 2502
Train: Epoch[1/5]  [1840/3125]  eta: 0:07:29  Lr: 0.001875  Loss: -0.2767  Acc@1: 81.2500 (80.6661)  Acc@5: 100.0000 (97.1788)  time: 0.3490  data: 0.0006  max mem: 2502
Train: Epoch[1/5]  [1850/3125]  eta: 0:07:25  Lr: 0.001875  Loss: -0.2900  Acc@1: 81.2500 (80.6827)  Acc@5: 100.0000 (97.1772)  time: 0.3492  data: 0.0006  max mem: 2502
Train: Epoch[1/5]  [1860/3125]  eta: 0:07:22  Lr: 0.001875  Loss: -0.4372  Acc@1: 87.5000 (80.7227)  Acc@5: 100.0000 (97.1890)  time: 0.3503  data: 0.0007  max mem: 2502
Train: Epoch[1/5]  [1870/3125]  eta: 0:07:18  Lr: 0.001875  Loss: -0.2478  Acc@1: 87.5000 (80.7289)  Acc@5: 100.0000 (97.1940)  time: 0.3502  data: 0.0008  max mem: 2502
Train: Epoch[1/5]  [1880/3125]  eta: 0:07:15  Lr: 0.001875  Loss: -0.2766  Acc@1: 81.2500 (80.7350)  Acc@5: 100.0000 (97.2089)  time: 0.3504  data: 0.0007  max mem: 2502
Train: Epoch[1/5]  [1890/3125]  eta: 0:07:11  Lr: 0.001875  Loss: -0.1165  Acc@1: 81.2500 (80.7476)  Acc@5: 100.0000 (97.2105)  time: 0.3505  data: 0.0006  max mem: 2502
Train: Epoch[1/5]  [1900/3125]  eta: 0:07:08  Lr: 0.001875  Loss: -0.4462  Acc@1: 87.5000 (80.7799)  Acc@5: 100.0000 (97.2153)  time: 0.3480  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [1910/3125]  eta: 0:07:04  Lr: 0.001875  Loss: -0.3048  Acc@1: 87.5000 (80.8019)  Acc@5: 100.0000 (97.2233)  time: 0.3471  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [1920/3125]  eta: 0:07:01  Lr: 0.001875  Loss: -0.2433  Acc@1: 81.2500 (80.8140)  Acc@5: 100.0000 (97.2150)  time: 0.3487  data: 0.0006  max mem: 2502
Train: Epoch[1/5]  [1930/3125]  eta: 0:06:57  Lr: 0.001875  Loss: -0.6289  Acc@1: 81.2500 (80.8228)  Acc@5: 93.7500 (97.2068)  time: 0.3497  data: 0.0008  max mem: 2502
Train: Epoch[1/5]  [1940/3125]  eta: 0:06:54  Lr: 0.001875  Loss: -0.1730  Acc@1: 81.2500 (80.8346)  Acc@5: 100.0000 (97.2018)  time: 0.3490  data: 0.0008  max mem: 2502
Train: Epoch[1/5]  [1950/3125]  eta: 0:06:50  Lr: 0.001875  Loss: -0.3893  Acc@1: 81.2500 (80.8335)  Acc@5: 100.0000 (97.2034)  time: 0.3500  data: 0.0008  max mem: 2502
Train: Epoch[1/5]  [1960/3125]  eta: 0:06:47  Lr: 0.001875  Loss: 0.0882  Acc@1: 81.2500 (80.8420)  Acc@5: 100.0000 (97.2112)  time: 0.3500  data: 0.0007  max mem: 2502
Train: Epoch[1/5]  [1970/3125]  eta: 0:06:43  Lr: 0.001875  Loss: -0.4880  Acc@1: 81.2500 (80.8505)  Acc@5: 100.0000 (97.2191)  time: 0.3483  data: 0.0007  max mem: 2502
Train: Epoch[1/5]  [1980/3125]  eta: 0:06:40  Lr: 0.001875  Loss: -0.5512  Acc@1: 87.5000 (80.8809)  Acc@5: 100.0000 (97.2236)  time: 0.3473  data: 0.0006  max mem: 2502
Train: Epoch[1/5]  [1990/3125]  eta: 0:06:36  Lr: 0.001875  Loss: -0.5373  Acc@1: 87.5000 (80.8670)  Acc@5: 100.0000 (97.2250)  time: 0.3475  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [2000/3125]  eta: 0:06:33  Lr: 0.001875  Loss: -0.5021  Acc@1: 87.5000 (80.8971)  Acc@5: 100.0000 (97.2295)  time: 0.3483  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [2010/3125]  eta: 0:06:29  Lr: 0.001875  Loss: -0.6772  Acc@1: 81.2500 (80.8833)  Acc@5: 100.0000 (97.2277)  time: 0.3488  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [2020/3125]  eta: 0:06:26  Lr: 0.001875  Loss: -0.2941  Acc@1: 75.0000 (80.8727)  Acc@5: 100.0000 (97.2384)  time: 0.3519  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [2030/3125]  eta: 0:06:22  Lr: 0.001875  Loss: -0.6057  Acc@1: 81.2500 (80.8807)  Acc@5: 100.0000 (97.2427)  time: 0.3513  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [2040/3125]  eta: 0:06:19  Lr: 0.001875  Loss: -0.6236  Acc@1: 81.2500 (80.9040)  Acc@5: 100.0000 (97.2562)  time: 0.3478  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [2050/3125]  eta: 0:06:15  Lr: 0.001875  Loss: 0.0347  Acc@1: 87.5000 (80.9239)  Acc@5: 100.0000 (97.2574)  time: 0.3482  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [2060/3125]  eta: 0:06:12  Lr: 0.001875  Loss: -0.4666  Acc@1: 87.5000 (80.9619)  Acc@5: 100.0000 (97.2616)  time: 0.3485  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [2070/3125]  eta: 0:06:08  Lr: 0.001875  Loss: -0.8448  Acc@1: 87.5000 (80.9693)  Acc@5: 100.0000 (97.2688)  time: 0.3480  data: 0.0006  max mem: 2502
Train: Epoch[1/5]  [2080/3125]  eta: 0:06:05  Lr: 0.001875  Loss: -0.3035  Acc@1: 81.2500 (80.9767)  Acc@5: 100.0000 (97.2790)  time: 0.3488  data: 0.0012  max mem: 2502
Train: Epoch[1/5]  [2090/3125]  eta: 0:06:01  Lr: 0.001875  Loss: -0.4531  Acc@1: 81.2500 (80.9840)  Acc@5: 100.0000 (97.2830)  time: 0.3487  data: 0.0012  max mem: 2502
Train: Epoch[1/5]  [2100/3125]  eta: 0:05:58  Lr: 0.001875  Loss: -0.7938  Acc@1: 81.2500 (80.9912)  Acc@5: 100.0000 (97.2930)  time: 0.3488  data: 0.0006  max mem: 2502
Train: Epoch[1/5]  [2110/3125]  eta: 0:05:54  Lr: 0.001875  Loss: -0.6113  Acc@1: 81.2500 (80.9924)  Acc@5: 100.0000 (97.2880)  time: 0.3496  data: 0.0007  max mem: 2502
Train: Epoch[1/5]  [2120/3125]  eta: 0:05:51  Lr: 0.001875  Loss: -0.6503  Acc@1: 87.5000 (80.9995)  Acc@5: 100.0000 (97.2861)  time: 0.3488  data: 0.0006  max mem: 2502
Train: Epoch[1/5]  [2130/3125]  eta: 0:05:47  Lr: 0.001875  Loss: -0.6787  Acc@1: 87.5000 (81.0359)  Acc@5: 100.0000 (97.2929)  time: 0.3482  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [2140/3125]  eta: 0:05:44  Lr: 0.001875  Loss: -0.8410  Acc@1: 87.5000 (81.0778)  Acc@5: 100.0000 (97.2997)  time: 0.3486  data: 0.0007  max mem: 2502
Train: Epoch[1/5]  [2150/3125]  eta: 0:05:40  Lr: 0.001875  Loss: -0.5975  Acc@1: 87.5000 (81.0669)  Acc@5: 100.0000 (97.3094)  time: 0.3490  data: 0.0008  max mem: 2502
Train: Epoch[1/5]  [2160/3125]  eta: 0:05:37  Lr: 0.001875  Loss: 0.0238  Acc@1: 81.2500 (81.0794)  Acc@5: 100.0000 (97.3045)  time: 0.3481  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [2170/3125]  eta: 0:05:33  Lr: 0.001875  Loss: -0.5019  Acc@1: 87.5000 (81.1089)  Acc@5: 100.0000 (97.3083)  time: 0.3478  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [2180/3125]  eta: 0:05:30  Lr: 0.001875  Loss: -0.5021  Acc@1: 87.5000 (81.1239)  Acc@5: 100.0000 (97.3120)  time: 0.3476  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [2190/3125]  eta: 0:05:26  Lr: 0.001875  Loss: -0.2933  Acc@1: 87.5000 (81.1502)  Acc@5: 100.0000 (97.3129)  time: 0.3478  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [2200/3125]  eta: 0:05:23  Lr: 0.001875  Loss: -0.5206  Acc@1: 87.5000 (81.1620)  Acc@5: 100.0000 (97.3166)  time: 0.3489  data: 0.0006  max mem: 2502
Train: Epoch[1/5]  [2210/3125]  eta: 0:05:19  Lr: 0.001875  Loss: -0.5604  Acc@1: 81.2500 (81.1709)  Acc@5: 100.0000 (97.3230)  time: 0.3488  data: 0.0008  max mem: 2502
Train: Epoch[1/5]  [2220/3125]  eta: 0:05:16  Lr: 0.001875  Loss: -0.3538  Acc@1: 81.2500 (81.1796)  Acc@5: 100.0000 (97.3267)  time: 0.3482  data: 0.0007  max mem: 2502
Train: Epoch[1/5]  [2230/3125]  eta: 0:05:12  Lr: 0.001875  Loss: -0.2683  Acc@1: 81.2500 (81.1772)  Acc@5: 93.7500 (97.3162)  time: 0.3483  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [2240/3125]  eta: 0:05:09  Lr: 0.001875  Loss: -0.4946  Acc@1: 81.2500 (81.1775)  Acc@5: 93.7500 (97.3170)  time: 0.3481  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [2250/3125]  eta: 0:05:05  Lr: 0.001875  Loss: -0.3979  Acc@1: 81.2500 (81.1972)  Acc@5: 100.0000 (97.3234)  time: 0.3482  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [2260/3125]  eta: 0:05:02  Lr: 0.001875  Loss: -0.5015  Acc@1: 87.5000 (81.2085)  Acc@5: 100.0000 (97.3270)  time: 0.3492  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [2270/3125]  eta: 0:04:58  Lr: 0.001875  Loss: -0.7584  Acc@1: 81.2500 (81.2060)  Acc@5: 100.0000 (97.3360)  time: 0.3494  data: 0.0008  max mem: 2502
Train: Epoch[1/5]  [2280/3125]  eta: 0:04:55  Lr: 0.001875  Loss: -0.7040  Acc@1: 87.5000 (81.2336)  Acc@5: 100.0000 (97.3367)  time: 0.3489  data: 0.0007  max mem: 2502
Train: Epoch[1/5]  [2290/3125]  eta: 0:04:51  Lr: 0.001875  Loss: -0.3731  Acc@1: 87.5000 (81.2500)  Acc@5: 100.0000 (97.3374)  time: 0.3483  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [2300/3125]  eta: 0:04:48  Lr: 0.001875  Loss: -0.7984  Acc@1: 87.5000 (81.2772)  Acc@5: 100.0000 (97.3463)  time: 0.3480  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [2310/3125]  eta: 0:04:44  Lr: 0.001875  Loss: 0.0070  Acc@1: 81.2500 (81.2662)  Acc@5: 100.0000 (97.3469)  time: 0.3485  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [2320/3125]  eta: 0:04:41  Lr: 0.001875  Loss: -0.6402  Acc@1: 81.2500 (81.2688)  Acc@5: 100.0000 (97.3503)  time: 0.3501  data: 0.0006  max mem: 2502
Train: Epoch[1/5]  [2330/3125]  eta: 0:04:37  Lr: 0.001875  Loss: -0.5332  Acc@1: 81.2500 (81.2768)  Acc@5: 100.0000 (97.3536)  time: 0.3500  data: 0.0006  max mem: 2502
Train: Epoch[1/5]  [2340/3125]  eta: 0:04:34  Lr: 0.001875  Loss: -0.8293  Acc@1: 87.5000 (81.3061)  Acc@5: 100.0000 (97.3542)  time: 0.3493  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [2350/3125]  eta: 0:04:30  Lr: 0.001875  Loss: -0.5294  Acc@1: 87.5000 (81.3218)  Acc@5: 100.0000 (97.3548)  time: 0.3487  data: 0.0006  max mem: 2502
Train: Epoch[1/5]  [2360/3125]  eta: 0:04:27  Lr: 0.001875  Loss: 0.1408  Acc@1: 87.5000 (81.3321)  Acc@5: 100.0000 (97.3608)  time: 0.3491  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [2370/3125]  eta: 0:04:23  Lr: 0.001875  Loss: -0.6217  Acc@1: 87.5000 (81.3423)  Acc@5: 100.0000 (97.3613)  time: 0.3518  data: 0.0009  max mem: 2502
Train: Epoch[1/5]  [2380/3125]  eta: 0:04:20  Lr: 0.001875  Loss: -0.0261  Acc@1: 81.2500 (81.3445)  Acc@5: 100.0000 (97.3541)  time: 0.3520  data: 0.0009  max mem: 2502
Train: Epoch[1/5]  [2390/3125]  eta: 0:04:16  Lr: 0.001875  Loss: -0.6093  Acc@1: 81.2500 (81.3546)  Acc@5: 93.7500 (97.3520)  time: 0.3506  data: 0.0014  max mem: 2502
Train: Epoch[1/5]  [2400/3125]  eta: 0:04:13  Lr: 0.001875  Loss: -0.7787  Acc@1: 87.5000 (81.3697)  Acc@5: 100.0000 (97.3605)  time: 0.3495  data: 0.0014  max mem: 2502
Train: Epoch[1/5]  [2410/3125]  eta: 0:04:09  Lr: 0.001875  Loss: -0.5839  Acc@1: 81.2500 (81.3848)  Acc@5: 100.0000 (97.3662)  time: 0.3485  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [2420/3125]  eta: 0:04:06  Lr: 0.001875  Loss: -0.5326  Acc@1: 81.2500 (81.3946)  Acc@5: 100.0000 (97.3720)  time: 0.3483  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [2430/3125]  eta: 0:04:02  Lr: 0.001875  Loss: -0.1586  Acc@1: 81.2500 (81.3991)  Acc@5: 100.0000 (97.3776)  time: 0.3483  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [2440/3125]  eta: 0:03:59  Lr: 0.001875  Loss: -0.4922  Acc@1: 81.2500 (81.4139)  Acc@5: 100.0000 (97.3832)  time: 0.3483  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [2450/3125]  eta: 0:03:55  Lr: 0.001875  Loss: -0.6701  Acc@1: 81.2500 (81.4132)  Acc@5: 100.0000 (97.3863)  time: 0.3494  data: 0.0006  max mem: 2502
Train: Epoch[1/5]  [2460/3125]  eta: 0:03:52  Lr: 0.001875  Loss: -0.3156  Acc@1: 81.2500 (81.4100)  Acc@5: 100.0000 (97.3918)  time: 0.3495  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [2470/3125]  eta: 0:03:48  Lr: 0.001875  Loss: -0.4071  Acc@1: 81.2500 (81.4245)  Acc@5: 100.0000 (97.4024)  time: 0.3492  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [2480/3125]  eta: 0:03:45  Lr: 0.001875  Loss: -0.5264  Acc@1: 81.2500 (81.4415)  Acc@5: 100.0000 (97.4053)  time: 0.3498  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [2490/3125]  eta: 0:03:41  Lr: 0.001875  Loss: -0.4891  Acc@1: 81.2500 (81.4457)  Acc@5: 93.7500 (97.3956)  time: 0.3483  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [2500/3125]  eta: 0:03:38  Lr: 0.001875  Loss: -0.3499  Acc@1: 87.5000 (81.4749)  Acc@5: 100.0000 (97.4060)  time: 0.3486  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [2510/3125]  eta: 0:03:34  Lr: 0.001875  Loss: -0.8401  Acc@1: 87.5000 (81.5114)  Acc@5: 100.0000 (97.4089)  time: 0.3493  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [2520/3125]  eta: 0:03:31  Lr: 0.001875  Loss: -0.9285  Acc@1: 87.5000 (81.5153)  Acc@5: 100.0000 (97.4018)  time: 0.3486  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [2530/3125]  eta: 0:03:27  Lr: 0.001875  Loss: -0.4259  Acc@1: 81.2500 (81.5167)  Acc@5: 100.0000 (97.4121)  time: 0.3497  data: 0.0006  max mem: 2502
Train: Epoch[1/5]  [2540/3125]  eta: 0:03:24  Lr: 0.001875  Loss: -0.3988  Acc@1: 81.2500 (81.5255)  Acc@5: 100.0000 (97.4149)  time: 0.3499  data: 0.0006  max mem: 2502
Train: Epoch[1/5]  [2550/3125]  eta: 0:03:20  Lr: 0.001875  Loss: -0.7124  Acc@1: 87.5000 (81.5416)  Acc@5: 100.0000 (97.4201)  time: 0.3494  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [2560/3125]  eta: 0:03:17  Lr: 0.001875  Loss: -0.7503  Acc@1: 87.5000 (81.5624)  Acc@5: 100.0000 (97.4229)  time: 0.3493  data: 0.0006  max mem: 2502
Train: Epoch[1/5]  [2570/3125]  eta: 0:03:13  Lr: 0.001875  Loss: -0.7422  Acc@1: 87.5000 (81.5855)  Acc@5: 100.0000 (97.4280)  time: 0.3498  data: 0.0009  max mem: 2502
Train: Epoch[1/5]  [2580/3125]  eta: 0:03:10  Lr: 0.001875  Loss: -0.8028  Acc@1: 87.5000 (81.5963)  Acc@5: 100.0000 (97.4283)  time: 0.3489  data: 0.0008  max mem: 2502
Train: Epoch[1/5]  [2590/3125]  eta: 0:03:06  Lr: 0.001875  Loss: -0.4060  Acc@1: 87.5000 (81.6167)  Acc@5: 100.0000 (97.4334)  time: 0.3480  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [2600/3125]  eta: 0:03:03  Lr: 0.001875  Loss: -0.5227  Acc@1: 87.5000 (81.6393)  Acc@5: 100.0000 (97.4361)  time: 0.3484  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [2610/3125]  eta: 0:02:59  Lr: 0.001875  Loss: -0.2889  Acc@1: 87.5000 (81.6545)  Acc@5: 100.0000 (97.4363)  time: 0.3485  data: 0.0006  max mem: 2502
Train: Epoch[1/5]  [2620/3125]  eta: 0:02:56  Lr: 0.001875  Loss: -0.6620  Acc@1: 81.2500 (81.6578)  Acc@5: 100.0000 (97.4366)  time: 0.3488  data: 0.0006  max mem: 2502
Train: Epoch[1/5]  [2630/3125]  eta: 0:02:52  Lr: 0.001875  Loss: -0.4825  Acc@1: 81.2500 (81.6633)  Acc@5: 100.0000 (97.4368)  time: 0.3517  data: 0.0006  max mem: 2502
Train: Epoch[1/5]  [2640/3125]  eta: 0:02:49  Lr: 0.001875  Loss: -0.6496  Acc@1: 87.5000 (81.6760)  Acc@5: 100.0000 (97.4347)  time: 0.3558  data: 0.0006  max mem: 2502
Train: Epoch[1/5]  [2650/3125]  eta: 0:02:45  Lr: 0.001875  Loss: -0.7322  Acc@1: 81.2500 (81.6791)  Acc@5: 100.0000 (97.4349)  time: 0.3536  data: 0.0006  max mem: 2502
Train: Epoch[1/5]  [2660/3125]  eta: 0:02:42  Lr: 0.001875  Loss: -0.9505  Acc@1: 81.2500 (81.6869)  Acc@5: 100.0000 (97.4305)  time: 0.3524  data: 0.0006  max mem: 2502
Train: Epoch[1/5]  [2670/3125]  eta: 0:02:38  Lr: 0.001875  Loss: -0.2975  Acc@1: 81.2500 (81.7086)  Acc@5: 100.0000 (97.4378)  time: 0.3520  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [2680/3125]  eta: 0:02:35  Lr: 0.001875  Loss: -0.4620  Acc@1: 81.2500 (81.6999)  Acc@5: 100.0000 (97.4450)  time: 0.3502  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [2690/3125]  eta: 0:02:31  Lr: 0.001875  Loss: -0.2854  Acc@1: 81.2500 (81.7192)  Acc@5: 100.0000 (97.4452)  time: 0.3511  data: 0.0007  max mem: 2502
Train: Epoch[1/5]  [2700/3125]  eta: 0:02:28  Lr: 0.001875  Loss: -0.7621  Acc@1: 87.5000 (81.7290)  Acc@5: 100.0000 (97.4523)  time: 0.3506  data: 0.0007  max mem: 2502
Train: Epoch[1/5]  [2710/3125]  eta: 0:02:25  Lr: 0.001875  Loss: -0.7690  Acc@1: 87.5000 (81.7318)  Acc@5: 100.0000 (97.4502)  time: 0.3491  data: 0.0007  max mem: 2502
Train: Epoch[1/5]  [2720/3125]  eta: 0:02:21  Lr: 0.001875  Loss: -0.8122  Acc@1: 81.2500 (81.7278)  Acc@5: 100.0000 (97.4573)  time: 0.3479  data: 0.0007  max mem: 2502
Train: Epoch[1/5]  [2730/3125]  eta: 0:02:18  Lr: 0.001875  Loss: -0.4757  Acc@1: 81.2500 (81.7420)  Acc@5: 100.0000 (97.4574)  time: 0.3495  data: 0.0006  max mem: 2502
Train: Epoch[1/5]  [2740/3125]  eta: 0:02:14  Lr: 0.001875  Loss: -0.5100  Acc@1: 87.5000 (81.7585)  Acc@5: 100.0000 (97.4576)  time: 0.3510  data: 0.0014  max mem: 2502
Train: Epoch[1/5]  [2750/3125]  eta: 0:02:11  Lr: 0.001875  Loss: -0.6207  Acc@1: 87.5000 (81.7680)  Acc@5: 100.0000 (97.4600)  time: 0.3494  data: 0.0012  max mem: 2502
Train: Epoch[1/5]  [2760/3125]  eta: 0:02:07  Lr: 0.001875  Loss: -0.7486  Acc@1: 87.5000 (81.7820)  Acc@5: 100.0000 (97.4647)  time: 0.3486  data: 0.0006  max mem: 2502
Train: Epoch[1/5]  [2770/3125]  eta: 0:02:04  Lr: 0.001875  Loss: -0.2544  Acc@1: 81.2500 (81.7868)  Acc@5: 100.0000 (97.4648)  time: 0.3491  data: 0.0006  max mem: 2502
Train: Epoch[1/5]  [2780/3125]  eta: 0:02:00  Lr: 0.001875  Loss: -0.6062  Acc@1: 81.2500 (81.7961)  Acc@5: 100.0000 (97.4694)  time: 0.3491  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [2790/3125]  eta: 0:01:57  Lr: 0.001875  Loss: -0.2191  Acc@1: 81.2500 (81.8098)  Acc@5: 100.0000 (97.4718)  time: 0.3492  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [2800/3125]  eta: 0:01:53  Lr: 0.001875  Loss: -0.2590  Acc@1: 81.2500 (81.8056)  Acc@5: 100.0000 (97.4741)  time: 0.3508  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [2810/3125]  eta: 0:01:50  Lr: 0.001875  Loss: -0.8143  Acc@1: 81.2500 (81.8170)  Acc@5: 100.0000 (97.4742)  time: 0.3540  data: 0.0008  max mem: 2502
Train: Epoch[1/5]  [2820/3125]  eta: 0:01:46  Lr: 0.001875  Loss: -0.6601  Acc@1: 87.5000 (81.8283)  Acc@5: 100.0000 (97.4809)  time: 0.3536  data: 0.0008  max mem: 2502
Train: Epoch[1/5]  [2830/3125]  eta: 0:01:43  Lr: 0.001875  Loss: -0.4464  Acc@1: 87.5000 (81.8439)  Acc@5: 100.0000 (97.4854)  time: 0.3497  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [2840/3125]  eta: 0:01:39  Lr: 0.001875  Loss: 0.5139  Acc@1: 81.2500 (81.8440)  Acc@5: 100.0000 (97.4833)  time: 0.3485  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [2850/3125]  eta: 0:01:36  Lr: 0.001875  Loss: 0.1363  Acc@1: 81.2500 (81.8551)  Acc@5: 100.0000 (97.4855)  time: 0.3501  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [2860/3125]  eta: 0:01:32  Lr: 0.001875  Loss: -0.5773  Acc@1: 87.5000 (81.8726)  Acc@5: 100.0000 (97.4878)  time: 0.3502  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [2870/3125]  eta: 0:01:29  Lr: 0.001875  Loss: -0.8340  Acc@1: 87.5000 (81.8878)  Acc@5: 100.0000 (97.4900)  time: 0.3507  data: 0.0006  max mem: 2502
Train: Epoch[1/5]  [2880/3125]  eta: 0:01:25  Lr: 0.001875  Loss: -0.2956  Acc@1: 87.5000 (81.9030)  Acc@5: 100.0000 (97.4922)  time: 0.3513  data: 0.0008  max mem: 2502
Train: Epoch[1/5]  [2890/3125]  eta: 0:01:22  Lr: 0.001875  Loss: -0.5014  Acc@1: 87.5000 (81.9159)  Acc@5: 100.0000 (97.4965)  time: 0.3493  data: 0.0008  max mem: 2502
Train: Epoch[1/5]  [2900/3125]  eta: 0:01:18  Lr: 0.001875  Loss: -0.7389  Acc@1: 87.5000 (81.9265)  Acc@5: 100.0000 (97.4987)  time: 0.3485  data: 0.0007  max mem: 2502
Train: Epoch[1/5]  [2910/3125]  eta: 0:01:15  Lr: 0.001875  Loss: -0.3181  Acc@1: 87.5000 (81.9392)  Acc@5: 100.0000 (97.4944)  time: 0.3491  data: 0.0006  max mem: 2502
Train: Epoch[1/5]  [2920/3125]  eta: 0:01:11  Lr: 0.001875  Loss: -0.5664  Acc@1: 87.5000 (81.9518)  Acc@5: 100.0000 (97.4923)  time: 0.3485  data: 0.0006  max mem: 2502
Train: Epoch[1/5]  [2930/3125]  eta: 0:01:08  Lr: 0.001875  Loss: -0.7448  Acc@1: 87.5000 (81.9579)  Acc@5: 100.0000 (97.4945)  time: 0.3482  data: 0.0006  max mem: 2502
Train: Epoch[1/5]  [2940/3125]  eta: 0:01:04  Lr: 0.001875  Loss: -0.3659  Acc@1: 87.5000 (81.9683)  Acc@5: 100.0000 (97.4945)  time: 0.3495  data: 0.0006  max mem: 2502
Train: Epoch[1/5]  [2950/3125]  eta: 0:01:01  Lr: 0.001875  Loss: -0.6083  Acc@1: 87.5000 (81.9743)  Acc@5: 100.0000 (97.4945)  time: 0.3495  data: 0.0006  max mem: 2502
Train: Epoch[1/5]  [2960/3125]  eta: 0:00:57  Lr: 0.001875  Loss: -0.3404  Acc@1: 81.2500 (81.9761)  Acc@5: 100.0000 (97.4966)  time: 0.3496  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [2970/3125]  eta: 0:00:54  Lr: 0.001875  Loss: -0.6276  Acc@1: 87.5000 (81.9989)  Acc@5: 100.0000 (97.4966)  time: 0.3505  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [2980/3125]  eta: 0:00:50  Lr: 0.001875  Loss: -0.5620  Acc@1: 87.5000 (82.0236)  Acc@5: 100.0000 (97.5008)  time: 0.3499  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [2990/3125]  eta: 0:00:47  Lr: 0.001875  Loss: -0.4206  Acc@1: 87.5000 (82.0378)  Acc@5: 100.0000 (97.5071)  time: 0.3492  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [3000/3125]  eta: 0:00:43  Lr: 0.001875  Loss: -0.3599  Acc@1: 81.2500 (82.0393)  Acc@5: 100.0000 (97.5133)  time: 0.3493  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [3010/3125]  eta: 0:00:40  Lr: 0.001875  Loss: -0.3708  Acc@1: 81.2500 (82.0450)  Acc@5: 100.0000 (97.5174)  time: 0.3492  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [3020/3125]  eta: 0:00:36  Lr: 0.001875  Loss: -0.4349  Acc@1: 81.2500 (82.0548)  Acc@5: 100.0000 (97.5215)  time: 0.3485  data: 0.0006  max mem: 2502
Train: Epoch[1/5]  [3030/3125]  eta: 0:00:33  Lr: 0.001875  Loss: -0.8195  Acc@1: 87.5000 (82.0810)  Acc@5: 100.0000 (97.5276)  time: 0.3487  data: 0.0008  max mem: 2502
Train: Epoch[1/5]  [3040/3125]  eta: 0:00:29  Lr: 0.001875  Loss: -0.5966  Acc@1: 87.5000 (82.0885)  Acc@5: 100.0000 (97.5275)  time: 0.3487  data: 0.0011  max mem: 2502
Train: Epoch[1/5]  [3050/3125]  eta: 0:00:26  Lr: 0.001875  Loss: -0.6458  Acc@1: 87.5000 (82.1083)  Acc@5: 100.0000 (97.5356)  time: 0.3489  data: 0.0013  max mem: 2502
Train: Epoch[1/5]  [3060/3125]  eta: 0:00:22  Lr: 0.001875  Loss: -0.2333  Acc@1: 87.5000 (82.1014)  Acc@5: 100.0000 (97.5417)  time: 0.3490  data: 0.0009  max mem: 2502
Train: Epoch[1/5]  [3070/3125]  eta: 0:00:19  Lr: 0.001875  Loss: -0.5903  Acc@1: 87.5000 (82.1312)  Acc@5: 100.0000 (97.5456)  time: 0.3481  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [3080/3125]  eta: 0:00:15  Lr: 0.001875  Loss: -0.5258  Acc@1: 87.5000 (82.1284)  Acc@5: 100.0000 (97.5454)  time: 0.3479  data: 0.0008  max mem: 2502
Train: Epoch[1/5]  [3090/3125]  eta: 0:00:12  Lr: 0.001875  Loss: -0.7159  Acc@1: 81.2500 (82.1275)  Acc@5: 100.0000 (97.5433)  time: 0.3485  data: 0.0009  max mem: 2502
Train: Epoch[1/5]  [3100/3125]  eta: 0:00:08  Lr: 0.001875  Loss: -0.3249  Acc@1: 87.5000 (82.1449)  Acc@5: 100.0000 (97.5492)  time: 0.3487  data: 0.0008  max mem: 2502
Train: Epoch[1/5]  [3110/3125]  eta: 0:00:05  Lr: 0.001875  Loss: -0.3894  Acc@1: 87.5000 (82.1440)  Acc@5: 100.0000 (97.5490)  time: 0.3485  data: 0.0006  max mem: 2502
Train: Epoch[1/5]  [3120/3125]  eta: 0:00:01  Lr: 0.001875  Loss: -0.4572  Acc@1: 81.2500 (82.1471)  Acc@5: 100.0000 (97.5529)  time: 0.3505  data: 0.0015  max mem: 2502
Train: Epoch[1/5]  [3124/3125]  eta: 0:00:00  Lr: 0.001875  Loss: -0.1824  Acc@1: 81.2500 (82.1320)  Acc@5: 100.0000 (97.5520)  time: 0.3508  data: 0.0015  max mem: 2502
Train: Epoch[1/5] Total time: 0:18:12 (0.3496 s / it)
{0: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 1: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 2: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 3: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 4: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 5: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 6: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 7: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 8: {0: 0, 1: 0, 2: 50000, 3: 0, 4: 0}, 9: {0: 0, 1: 0, 2: 50000, 3: 0, 4: 0}, 10: {0: 0, 1: 0, 2: 50000, 3: 0, 4: 0}, 11: {0: 0, 1: 0, 2: 50000, 3: 0, 4: 0}, 12: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 13: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 14: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 15: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 16: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 17: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 18: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 19: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}}
Averaged stats: Lr: 0.001875  Loss: -0.1824  Acc@1: 81.2500 (82.1320)  Acc@5: 100.0000 (97.5520)
Train: Epoch[2/5]  [   0/3125]  eta: 0:42:20  Lr: 0.001875  Loss: -0.6864  Acc@1: 93.7500 (93.7500)  Acc@5: 93.7500 (93.7500)  time: 0.8128  data: 0.4626  max mem: 2502
Train: Epoch[2/5]  [  10/3125]  eta: 0:20:16  Lr: 0.001875  Loss: -0.3097  Acc@1: 87.5000 (85.7955)  Acc@5: 93.7500 (96.5909)  time: 0.3904  data: 0.0424  max mem: 2502
Train: Epoch[2/5]  [  20/3125]  eta: 0:19:09  Lr: 0.001875  Loss: -0.2669  Acc@1: 81.2500 (84.8214)  Acc@5: 100.0000 (98.2143)  time: 0.3481  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [  30/3125]  eta: 0:18:44  Lr: 0.001875  Loss: -0.6164  Acc@1: 87.5000 (84.8790)  Acc@5: 100.0000 (97.9839)  time: 0.3485  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [  40/3125]  eta: 0:18:29  Lr: 0.001875  Loss: -0.7733  Acc@1: 87.5000 (85.2134)  Acc@5: 100.0000 (98.1707)  time: 0.3486  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [  50/3125]  eta: 0:18:20  Lr: 0.001875  Loss: -0.1017  Acc@1: 81.2500 (85.0490)  Acc@5: 100.0000 (98.4069)  time: 0.3490  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [  60/3125]  eta: 0:18:12  Lr: 0.001875  Loss: -0.6931  Acc@1: 87.5000 (85.9631)  Acc@5: 100.0000 (98.5656)  time: 0.3496  data: 0.0007  max mem: 2502
Train: Epoch[2/5]  [  70/3125]  eta: 0:18:05  Lr: 0.001875  Loss: -0.3885  Acc@1: 87.5000 (85.6514)  Acc@5: 100.0000 (98.4155)  time: 0.3490  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [  80/3125]  eta: 0:17:59  Lr: 0.001875  Loss: -0.1463  Acc@1: 81.2500 (84.4907)  Acc@5: 93.7500 (98.0710)  time: 0.3488  data: 0.0007  max mem: 2502
Train: Epoch[2/5]  [  90/3125]  eta: 0:17:54  Lr: 0.001875  Loss: -0.6118  Acc@1: 81.2500 (84.5467)  Acc@5: 100.0000 (98.1456)  time: 0.3498  data: 0.0008  max mem: 2502
Train: Epoch[2/5]  [ 100/3125]  eta: 0:17:49  Lr: 0.001875  Loss: -0.3097  Acc@1: 87.5000 (84.4059)  Acc@5: 100.0000 (98.0817)  time: 0.3501  data: 0.0007  max mem: 2502
Train: Epoch[2/5]  [ 110/3125]  eta: 0:17:44  Lr: 0.001875  Loss: -0.5328  Acc@1: 87.5000 (84.5158)  Acc@5: 100.0000 (98.2545)  time: 0.3491  data: 0.0013  max mem: 2502
Train: Epoch[2/5]  [ 120/3125]  eta: 0:17:40  Lr: 0.001875  Loss: -0.7125  Acc@1: 87.5000 (84.7624)  Acc@5: 100.0000 (98.2438)  time: 0.3483  data: 0.0013  max mem: 2502
Train: Epoch[2/5]  [ 130/3125]  eta: 0:17:35  Lr: 0.001875  Loss: -0.6215  Acc@1: 87.5000 (84.6851)  Acc@5: 100.0000 (98.2824)  time: 0.3483  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [ 140/3125]  eta: 0:17:31  Lr: 0.001875  Loss: -0.3564  Acc@1: 87.5000 (84.8404)  Acc@5: 100.0000 (98.4043)  time: 0.3485  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [ 150/3125]  eta: 0:17:26  Lr: 0.001875  Loss: -0.3617  Acc@1: 87.5000 (84.6854)  Acc@5: 100.0000 (98.4685)  time: 0.3485  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [ 160/3125]  eta: 0:17:23  Lr: 0.001875  Loss: -0.2233  Acc@1: 81.2500 (84.5497)  Acc@5: 100.0000 (98.4860)  time: 0.3505  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [ 170/3125]  eta: 0:17:19  Lr: 0.001875  Loss: -0.6363  Acc@1: 81.2500 (84.6126)  Acc@5: 100.0000 (98.5015)  time: 0.3508  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [ 180/3125]  eta: 0:17:15  Lr: 0.001875  Loss: -0.5970  Acc@1: 87.5000 (84.6685)  Acc@5: 100.0000 (98.4807)  time: 0.3495  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [ 190/3125]  eta: 0:17:11  Lr: 0.001875  Loss: -0.8560  Acc@1: 87.5000 (84.6859)  Acc@5: 100.0000 (98.5275)  time: 0.3487  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [ 200/3125]  eta: 0:17:07  Lr: 0.001875  Loss: -0.5736  Acc@1: 81.2500 (84.7015)  Acc@5: 100.0000 (98.5075)  time: 0.3479  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [ 210/3125]  eta: 0:17:03  Lr: 0.001875  Loss: -0.4559  Acc@1: 87.5000 (84.7156)  Acc@5: 100.0000 (98.5486)  time: 0.3476  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [ 220/3125]  eta: 0:16:59  Lr: 0.001875  Loss: -0.2333  Acc@1: 87.5000 (84.6437)  Acc@5: 100.0000 (98.5294)  time: 0.3472  data: 0.0007  max mem: 2502
Train: Epoch[2/5]  [ 230/3125]  eta: 0:16:55  Lr: 0.001875  Loss: -0.8310  Acc@1: 87.5000 (84.8755)  Acc@5: 100.0000 (98.5390)  time: 0.3484  data: 0.0008  max mem: 2502
Train: Epoch[2/5]  [ 240/3125]  eta: 0:16:51  Lr: 0.001875  Loss: -0.0404  Acc@1: 87.5000 (84.7251)  Acc@5: 100.0000 (98.4180)  time: 0.3487  data: 0.0007  max mem: 2502
Train: Epoch[2/5]  [ 250/3125]  eta: 0:16:48  Lr: 0.001875  Loss: -0.1716  Acc@1: 81.2500 (84.6863)  Acc@5: 100.0000 (98.4064)  time: 0.3486  data: 0.0007  max mem: 2502
Train: Epoch[2/5]  [ 260/3125]  eta: 0:16:44  Lr: 0.001875  Loss: -0.4731  Acc@1: 81.2500 (84.6743)  Acc@5: 100.0000 (98.3956)  time: 0.3483  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [ 270/3125]  eta: 0:16:40  Lr: 0.001875  Loss: -0.5042  Acc@1: 81.2500 (84.7325)  Acc@5: 100.0000 (98.4087)  time: 0.3481  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [ 280/3125]  eta: 0:16:36  Lr: 0.001875  Loss: -0.6645  Acc@1: 81.2500 (84.6975)  Acc@5: 100.0000 (98.4208)  time: 0.3488  data: 0.0009  max mem: 2502
Train: Epoch[2/5]  [ 290/3125]  eta: 0:16:33  Lr: 0.001875  Loss: -0.7579  Acc@1: 87.5000 (84.6864)  Acc@5: 100.0000 (98.3462)  time: 0.3497  data: 0.0009  max mem: 2502
Train: Epoch[2/5]  [ 300/3125]  eta: 0:16:30  Lr: 0.001875  Loss: -0.1172  Acc@1: 87.5000 (84.6346)  Acc@5: 100.0000 (98.2766)  time: 0.3525  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [ 310/3125]  eta: 0:16:26  Lr: 0.001875  Loss: -0.5917  Acc@1: 81.2500 (84.5860)  Acc@5: 100.0000 (98.2516)  time: 0.3510  data: 0.0007  max mem: 2502
Train: Epoch[2/5]  [ 320/3125]  eta: 0:16:22  Lr: 0.001875  Loss: -0.6870  Acc@1: 81.2500 (84.7352)  Acc@5: 100.0000 (98.2477)  time: 0.3476  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [ 330/3125]  eta: 0:16:19  Lr: 0.001875  Loss: -0.2509  Acc@1: 81.2500 (84.6677)  Acc@5: 100.0000 (98.2440)  time: 0.3486  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [ 340/3125]  eta: 0:16:15  Lr: 0.001875  Loss: -0.8205  Acc@1: 81.2500 (84.7507)  Acc@5: 100.0000 (98.2405)  time: 0.3488  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [ 350/3125]  eta: 0:16:11  Lr: 0.001875  Loss: -0.4217  Acc@1: 87.5000 (84.7934)  Acc@5: 100.0000 (98.2372)  time: 0.3484  data: 0.0007  max mem: 2502
Train: Epoch[2/5]  [ 360/3125]  eta: 0:16:08  Lr: 0.001875  Loss: -0.6576  Acc@1: 87.5000 (84.8165)  Acc@5: 100.0000 (98.2168)  time: 0.3480  data: 0.0007  max mem: 2502
Train: Epoch[2/5]  [ 370/3125]  eta: 0:16:04  Lr: 0.001875  Loss: -0.3060  Acc@1: 87.5000 (84.8214)  Acc@5: 100.0000 (98.2648)  time: 0.3485  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [ 380/3125]  eta: 0:16:01  Lr: 0.001875  Loss: -0.3434  Acc@1: 87.5000 (84.8261)  Acc@5: 100.0000 (98.2612)  time: 0.3503  data: 0.0007  max mem: 2502
Train: Epoch[2/5]  [ 390/3125]  eta: 0:15:57  Lr: 0.001875  Loss: -0.5728  Acc@1: 87.5000 (84.8785)  Acc@5: 100.0000 (98.3056)  time: 0.3499  data: 0.0008  max mem: 2502
Train: Epoch[2/5]  [ 400/3125]  eta: 0:15:54  Lr: 0.001875  Loss: -0.2242  Acc@1: 87.5000 (84.8036)  Acc@5: 100.0000 (98.3167)  time: 0.3487  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [ 410/3125]  eta: 0:15:50  Lr: 0.001875  Loss: -0.3498  Acc@1: 87.5000 (84.8844)  Acc@5: 100.0000 (98.3425)  time: 0.3478  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [ 420/3125]  eta: 0:15:46  Lr: 0.001875  Loss: -0.4853  Acc@1: 87.5000 (84.8426)  Acc@5: 100.0000 (98.3373)  time: 0.3472  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [ 430/3125]  eta: 0:15:43  Lr: 0.001875  Loss: -0.0996  Acc@1: 81.2500 (84.6868)  Acc@5: 100.0000 (98.2889)  time: 0.3502  data: 0.0008  max mem: 2502
Train: Epoch[2/5]  [ 440/3125]  eta: 0:15:39  Lr: 0.001875  Loss: -0.3159  Acc@1: 81.2500 (84.7222)  Acc@5: 100.0000 (98.2993)  time: 0.3505  data: 0.0008  max mem: 2502
Train: Epoch[2/5]  [ 450/3125]  eta: 0:15:36  Lr: 0.001875  Loss: -0.5104  Acc@1: 87.5000 (84.7145)  Acc@5: 100.0000 (98.3232)  time: 0.3480  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [ 460/3125]  eta: 0:15:32  Lr: 0.001875  Loss: -0.6222  Acc@1: 81.2500 (84.6665)  Acc@5: 100.0000 (98.2918)  time: 0.3477  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [ 470/3125]  eta: 0:15:28  Lr: 0.001875  Loss: -0.7715  Acc@1: 81.2500 (84.6338)  Acc@5: 100.0000 (98.2882)  time: 0.3475  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [ 480/3125]  eta: 0:15:25  Lr: 0.001875  Loss: -0.7446  Acc@1: 87.5000 (84.6674)  Acc@5: 100.0000 (98.2978)  time: 0.3476  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [ 490/3125]  eta: 0:15:21  Lr: 0.001875  Loss: -0.7503  Acc@1: 87.5000 (84.7505)  Acc@5: 100.0000 (98.3325)  time: 0.3494  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [ 500/3125]  eta: 0:15:18  Lr: 0.001875  Loss: -0.5349  Acc@1: 87.5000 (84.8428)  Acc@5: 100.0000 (98.3533)  time: 0.3503  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [ 510/3125]  eta: 0:15:14  Lr: 0.001875  Loss: -0.5623  Acc@1: 87.5000 (84.7970)  Acc@5: 100.0000 (98.3488)  time: 0.3490  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [ 520/3125]  eta: 0:15:11  Lr: 0.001875  Loss: -0.7240  Acc@1: 87.5000 (84.8968)  Acc@5: 100.0000 (98.3565)  time: 0.3483  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [ 530/3125]  eta: 0:15:07  Lr: 0.001875  Loss: -0.5957  Acc@1: 87.5000 (84.9105)  Acc@5: 100.0000 (98.3875)  time: 0.3486  data: 0.0009  max mem: 2502
Train: Epoch[2/5]  [ 540/3125]  eta: 0:15:04  Lr: 0.001875  Loss: -0.8516  Acc@1: 87.5000 (84.9931)  Acc@5: 100.0000 (98.3595)  time: 0.3489  data: 0.0009  max mem: 2502
Train: Epoch[2/5]  [ 550/3125]  eta: 0:15:00  Lr: 0.001875  Loss: -0.5475  Acc@1: 87.5000 (84.9705)  Acc@5: 93.7500 (98.3326)  time: 0.3491  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [ 560/3125]  eta: 0:14:56  Lr: 0.001875  Loss: -0.2043  Acc@1: 81.2500 (84.9153)  Acc@5: 100.0000 (98.3400)  time: 0.3486  data: 0.0009  max mem: 2502
Train: Epoch[2/5]  [ 570/3125]  eta: 0:14:53  Lr: 0.001875  Loss: -0.3005  Acc@1: 87.5000 (84.9934)  Acc@5: 100.0000 (98.3363)  time: 0.3470  data: 0.0008  max mem: 2502
Train: Epoch[2/5]  [ 580/3125]  eta: 0:14:49  Lr: 0.001875  Loss: -0.7343  Acc@1: 87.5000 (84.9613)  Acc@5: 100.0000 (98.3541)  time: 0.3476  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [ 590/3125]  eta: 0:14:46  Lr: 0.001875  Loss: 0.0136  Acc@1: 81.2500 (84.9302)  Acc@5: 100.0000 (98.3397)  time: 0.3481  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [ 600/3125]  eta: 0:14:42  Lr: 0.001875  Loss: -0.6756  Acc@1: 87.5000 (84.9522)  Acc@5: 100.0000 (98.3465)  time: 0.3486  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [ 610/3125]  eta: 0:14:39  Lr: 0.001875  Loss: -0.7489  Acc@1: 87.5000 (84.9120)  Acc@5: 100.0000 (98.3327)  time: 0.3517  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [ 620/3125]  eta: 0:14:35  Lr: 0.001875  Loss: -0.3804  Acc@1: 87.5000 (84.9134)  Acc@5: 100.0000 (98.3394)  time: 0.3508  data: 0.0007  max mem: 2502
Train: Epoch[2/5]  [ 630/3125]  eta: 0:14:32  Lr: 0.001875  Loss: -0.7288  Acc@1: 87.5000 (84.9544)  Acc@5: 100.0000 (98.3459)  time: 0.3490  data: 0.0007  max mem: 2502
Train: Epoch[2/5]  [ 640/3125]  eta: 0:14:28  Lr: 0.001875  Loss: -0.4725  Acc@1: 87.5000 (84.9161)  Acc@5: 100.0000 (98.3522)  time: 0.3490  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [ 650/3125]  eta: 0:14:25  Lr: 0.001875  Loss: -0.3431  Acc@1: 87.5000 (85.0038)  Acc@5: 100.0000 (98.3775)  time: 0.3478  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [ 660/3125]  eta: 0:14:21  Lr: 0.001875  Loss: -0.2026  Acc@1: 93.7500 (85.0605)  Acc@5: 100.0000 (98.3737)  time: 0.3489  data: 0.0011  max mem: 2502
Train: Epoch[2/5]  [ 670/3125]  eta: 0:14:18  Lr: 0.001875  Loss: -0.8377  Acc@1: 87.5000 (85.1248)  Acc@5: 100.0000 (98.3793)  time: 0.3496  data: 0.0012  max mem: 2502
Train: Epoch[2/5]  [ 680/3125]  eta: 0:14:14  Lr: 0.001875  Loss: -0.1904  Acc@1: 81.2500 (85.1046)  Acc@5: 100.0000 (98.3756)  time: 0.3487  data: 0.0010  max mem: 2502
Train: Epoch[2/5]  [ 690/3125]  eta: 0:14:11  Lr: 0.001875  Loss: -0.3076  Acc@1: 81.2500 (85.1031)  Acc@5: 100.0000 (98.3719)  time: 0.3486  data: 0.0009  max mem: 2502
Train: Epoch[2/5]  [ 700/3125]  eta: 0:14:07  Lr: 0.001875  Loss: -0.4346  Acc@1: 87.5000 (85.0660)  Acc@5: 100.0000 (98.3595)  time: 0.3500  data: 0.0015  max mem: 2502
Train: Epoch[2/5]  [ 710/3125]  eta: 0:14:04  Lr: 0.001875  Loss: -0.3563  Acc@1: 87.5000 (85.0387)  Acc@5: 100.0000 (98.3386)  time: 0.3498  data: 0.0016  max mem: 2502
Train: Epoch[2/5]  [ 720/3125]  eta: 0:14:00  Lr: 0.001875  Loss: -0.2355  Acc@1: 87.5000 (85.0381)  Acc@5: 100.0000 (98.3443)  time: 0.3485  data: 0.0007  max mem: 2502
Train: Epoch[2/5]  [ 730/3125]  eta: 0:13:57  Lr: 0.001875  Loss: -0.5480  Acc@1: 81.2500 (85.0205)  Acc@5: 100.0000 (98.3499)  time: 0.3490  data: 0.0007  max mem: 2502
Train: Epoch[2/5]  [ 740/3125]  eta: 0:13:53  Lr: 0.001875  Loss: -0.7891  Acc@1: 81.2500 (84.9696)  Acc@5: 100.0000 (98.3468)  time: 0.3501  data: 0.0007  max mem: 2502
Train: Epoch[2/5]  [ 750/3125]  eta: 0:13:50  Lr: 0.001875  Loss: -0.8517  Acc@1: 87.5000 (85.0200)  Acc@5: 100.0000 (98.3522)  time: 0.3499  data: 0.0009  max mem: 2502
Train: Epoch[2/5]  [ 760/3125]  eta: 0:13:46  Lr: 0.001875  Loss: -0.4515  Acc@1: 87.5000 (85.0033)  Acc@5: 100.0000 (98.3574)  time: 0.3494  data: 0.0008  max mem: 2502
Train: Epoch[2/5]  [ 770/3125]  eta: 0:13:43  Lr: 0.001875  Loss: -0.6491  Acc@1: 87.5000 (85.0438)  Acc@5: 100.0000 (98.3625)  time: 0.3491  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [ 780/3125]  eta: 0:13:39  Lr: 0.001875  Loss: -0.2716  Acc@1: 87.5000 (85.0192)  Acc@5: 100.0000 (98.3595)  time: 0.3493  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [ 790/3125]  eta: 0:13:36  Lr: 0.001875  Loss: -0.2631  Acc@1: 81.2500 (84.9953)  Acc@5: 100.0000 (98.3486)  time: 0.3487  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [ 800/3125]  eta: 0:13:32  Lr: 0.001875  Loss: -0.3649  Acc@1: 87.5000 (85.0031)  Acc@5: 100.0000 (98.3614)  time: 0.3481  data: 0.0007  max mem: 2502
Train: Epoch[2/5]  [ 810/3125]  eta: 0:13:29  Lr: 0.001875  Loss: -0.1341  Acc@1: 87.5000 (84.9877)  Acc@5: 100.0000 (98.3662)  time: 0.3490  data: 0.0008  max mem: 2502
Train: Epoch[2/5]  [ 820/3125]  eta: 0:13:25  Lr: 0.001875  Loss: -0.4105  Acc@1: 81.2500 (84.9498)  Acc@5: 100.0000 (98.3481)  time: 0.3495  data: 0.0007  max mem: 2502
Train: Epoch[2/5]  [ 830/3125]  eta: 0:13:22  Lr: 0.001875  Loss: -0.4958  Acc@1: 81.2500 (84.9579)  Acc@5: 100.0000 (98.3529)  time: 0.3496  data: 0.0008  max mem: 2502
Train: Epoch[2/5]  [ 840/3125]  eta: 0:13:18  Lr: 0.001875  Loss: -0.3280  Acc@1: 81.2500 (84.9138)  Acc@5: 100.0000 (98.3502)  time: 0.3486  data: 0.0007  max mem: 2502
Train: Epoch[2/5]  [ 850/3125]  eta: 0:13:15  Lr: 0.001875  Loss: -0.6444  Acc@1: 87.5000 (84.9148)  Acc@5: 100.0000 (98.3255)  time: 0.3486  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [ 860/3125]  eta: 0:13:11  Lr: 0.001875  Loss: -0.2958  Acc@1: 81.2500 (84.8868)  Acc@5: 100.0000 (98.3159)  time: 0.3485  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [ 870/3125]  eta: 0:13:07  Lr: 0.001875  Loss: -0.8007  Acc@1: 87.5000 (84.9239)  Acc@5: 100.0000 (98.3137)  time: 0.3477  data: 0.0007  max mem: 2502
Train: Epoch[2/5]  [ 880/3125]  eta: 0:13:04  Lr: 0.001875  Loss: -0.4089  Acc@1: 87.5000 (84.9035)  Acc@5: 100.0000 (98.3045)  time: 0.3477  data: 0.0008  max mem: 2502
Train: Epoch[2/5]  [ 890/3125]  eta: 0:13:00  Lr: 0.001875  Loss: -0.2195  Acc@1: 87.5000 (84.9537)  Acc@5: 100.0000 (98.3095)  time: 0.3484  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [ 900/3125]  eta: 0:12:57  Lr: 0.001875  Loss: 0.0246  Acc@1: 87.5000 (84.9334)  Acc@5: 100.0000 (98.3074)  time: 0.3488  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [ 910/3125]  eta: 0:12:53  Lr: 0.001875  Loss: -0.5777  Acc@1: 87.5000 (84.9753)  Acc@5: 100.0000 (98.3123)  time: 0.3483  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [ 920/3125]  eta: 0:12:50  Lr: 0.001875  Loss: -0.8571  Acc@1: 87.5000 (85.0299)  Acc@5: 100.0000 (98.3238)  time: 0.3481  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [ 930/3125]  eta: 0:12:46  Lr: 0.001875  Loss: -0.6227  Acc@1: 87.5000 (85.0564)  Acc@5: 100.0000 (98.3217)  time: 0.3484  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [ 940/3125]  eta: 0:12:43  Lr: 0.001875  Loss: -0.4377  Acc@1: 81.2500 (85.0292)  Acc@5: 100.0000 (98.2997)  time: 0.3481  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [ 950/3125]  eta: 0:12:39  Lr: 0.001875  Loss: -0.6287  Acc@1: 81.2500 (85.0552)  Acc@5: 100.0000 (98.3044)  time: 0.3478  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [ 960/3125]  eta: 0:12:36  Lr: 0.001875  Loss: -0.4859  Acc@1: 87.5000 (85.0806)  Acc@5: 100.0000 (98.2830)  time: 0.3483  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [ 970/3125]  eta: 0:12:32  Lr: 0.001875  Loss: -0.7048  Acc@1: 87.5000 (85.0798)  Acc@5: 93.7500 (98.2557)  time: 0.3486  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [ 980/3125]  eta: 0:12:29  Lr: 0.001875  Loss: -0.6001  Acc@1: 87.5000 (85.1363)  Acc@5: 100.0000 (98.2671)  time: 0.3490  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [ 990/3125]  eta: 0:12:25  Lr: 0.001875  Loss: -0.6245  Acc@1: 87.5000 (85.1413)  Acc@5: 100.0000 (98.2656)  time: 0.3502  data: 0.0009  max mem: 2502
Train: Epoch[2/5]  [1000/3125]  eta: 0:12:22  Lr: 0.001875  Loss: -0.5020  Acc@1: 87.5000 (85.1773)  Acc@5: 100.0000 (98.2767)  time: 0.3501  data: 0.0008  max mem: 2502
Train: Epoch[2/5]  [1010/3125]  eta: 0:12:18  Lr: 0.001875  Loss: -0.3390  Acc@1: 81.2500 (85.1508)  Acc@5: 100.0000 (98.2690)  time: 0.3490  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [1020/3125]  eta: 0:12:15  Lr: 0.001875  Loss: -0.4384  Acc@1: 81.2500 (85.1738)  Acc@5: 100.0000 (98.2554)  time: 0.3498  data: 0.0009  max mem: 2502
Train: Epoch[2/5]  [1030/3125]  eta: 0:12:11  Lr: 0.001875  Loss: -0.5661  Acc@1: 87.5000 (85.1600)  Acc@5: 100.0000 (98.2602)  time: 0.3510  data: 0.0012  max mem: 2502
Train: Epoch[2/5]  [1040/3125]  eta: 0:12:08  Lr: 0.001875  Loss: -0.7752  Acc@1: 81.2500 (85.1465)  Acc@5: 100.0000 (98.2649)  time: 0.3513  data: 0.0010  max mem: 2502
Train: Epoch[2/5]  [1050/3125]  eta: 0:12:04  Lr: 0.001875  Loss: -0.5900  Acc@1: 81.2500 (85.1570)  Acc@5: 100.0000 (98.2695)  time: 0.3509  data: 0.0007  max mem: 2502
Train: Epoch[2/5]  [1060/3125]  eta: 0:12:01  Lr: 0.001875  Loss: -0.3341  Acc@1: 87.5000 (85.1378)  Acc@5: 100.0000 (98.2681)  time: 0.3496  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [1070/3125]  eta: 0:11:58  Lr: 0.001875  Loss: -0.2939  Acc@1: 81.2500 (85.1132)  Acc@5: 100.0000 (98.2726)  time: 0.3512  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [1080/3125]  eta: 0:11:54  Lr: 0.001875  Loss: -0.7331  Acc@1: 81.2500 (85.1006)  Acc@5: 100.0000 (98.2597)  time: 0.3520  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [1090/3125]  eta: 0:11:51  Lr: 0.001875  Loss: -0.3626  Acc@1: 81.2500 (85.0997)  Acc@5: 100.0000 (98.2642)  time: 0.3493  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [1100/3125]  eta: 0:11:47  Lr: 0.001875  Loss: -0.2311  Acc@1: 87.5000 (85.0931)  Acc@5: 100.0000 (98.2743)  time: 0.3490  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [1110/3125]  eta: 0:11:44  Lr: 0.001875  Loss: -0.6118  Acc@1: 81.2500 (85.0585)  Acc@5: 100.0000 (98.2842)  time: 0.3483  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [1120/3125]  eta: 0:11:40  Lr: 0.001875  Loss: -0.3288  Acc@1: 87.5000 (85.0580)  Acc@5: 100.0000 (98.2716)  time: 0.3483  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [1130/3125]  eta: 0:11:37  Lr: 0.001875  Loss: -0.3828  Acc@1: 87.5000 (85.0630)  Acc@5: 100.0000 (98.2814)  time: 0.3510  data: 0.0014  max mem: 2502
Train: Epoch[2/5]  [1140/3125]  eta: 0:11:33  Lr: 0.001875  Loss: -0.6483  Acc@1: 87.5000 (85.0515)  Acc@5: 100.0000 (98.2800)  time: 0.3505  data: 0.0015  max mem: 2502
Train: Epoch[2/5]  [1150/3125]  eta: 0:11:30  Lr: 0.001875  Loss: -0.8237  Acc@1: 81.2500 (85.0239)  Acc@5: 100.0000 (98.2678)  time: 0.3483  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [1160/3125]  eta: 0:11:26  Lr: 0.001875  Loss: -0.4405  Acc@1: 81.2500 (85.0452)  Acc@5: 100.0000 (98.2720)  time: 0.3483  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [1170/3125]  eta: 0:11:23  Lr: 0.001875  Loss: 0.1779  Acc@1: 87.5000 (85.0288)  Acc@5: 100.0000 (98.2654)  time: 0.3491  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [1180/3125]  eta: 0:11:19  Lr: 0.001875  Loss: 0.2417  Acc@1: 87.5000 (85.0180)  Acc@5: 100.0000 (98.2589)  time: 0.3495  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [1190/3125]  eta: 0:11:16  Lr: 0.001875  Loss: -0.7258  Acc@1: 87.5000 (85.0651)  Acc@5: 100.0000 (98.2683)  time: 0.3494  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [1200/3125]  eta: 0:11:12  Lr: 0.001875  Loss: -0.8580  Acc@1: 93.7500 (85.0958)  Acc@5: 100.0000 (98.2775)  time: 0.3496  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [1210/3125]  eta: 0:11:09  Lr: 0.001875  Loss: -0.0741  Acc@1: 87.5000 (85.1001)  Acc@5: 100.0000 (98.2711)  time: 0.3489  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [1220/3125]  eta: 0:11:05  Lr: 0.001875  Loss: -0.7687  Acc@1: 87.5000 (85.1198)  Acc@5: 100.0000 (98.2596)  time: 0.3497  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [1230/3125]  eta: 0:11:02  Lr: 0.001875  Loss: -0.6384  Acc@1: 87.5000 (85.1137)  Acc@5: 100.0000 (98.2636)  time: 0.3499  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [1240/3125]  eta: 0:10:58  Lr: 0.001875  Loss: -0.7614  Acc@1: 87.5000 (85.1178)  Acc@5: 100.0000 (98.2675)  time: 0.3479  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [1250/3125]  eta: 0:10:55  Lr: 0.001875  Loss: -0.3908  Acc@1: 87.5000 (85.1569)  Acc@5: 100.0000 (98.2664)  time: 0.3488  data: 0.0008  max mem: 2502
Train: Epoch[2/5]  [1260/3125]  eta: 0:10:51  Lr: 0.001875  Loss: -0.5182  Acc@1: 87.5000 (85.1705)  Acc@5: 100.0000 (98.2801)  time: 0.3498  data: 0.0010  max mem: 2502
Train: Epoch[2/5]  [1270/3125]  eta: 0:10:48  Lr: 0.001875  Loss: -0.8735  Acc@1: 87.5000 (85.1544)  Acc@5: 100.0000 (98.2887)  time: 0.3490  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [1280/3125]  eta: 0:10:44  Lr: 0.001875  Loss: -0.5549  Acc@1: 87.5000 (85.1776)  Acc@5: 100.0000 (98.2923)  time: 0.3495  data: 0.0008  max mem: 2502
Train: Epoch[2/5]  [1290/3125]  eta: 0:10:41  Lr: 0.001875  Loss: -0.5110  Acc@1: 81.2500 (85.1569)  Acc@5: 100.0000 (98.2862)  time: 0.3497  data: 0.0008  max mem: 2502
Train: Epoch[2/5]  [1300/3125]  eta: 0:10:37  Lr: 0.001875  Loss: -0.8597  Acc@1: 81.2500 (85.1749)  Acc@5: 100.0000 (98.2994)  time: 0.3488  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [1310/3125]  eta: 0:10:34  Lr: 0.001875  Loss: -0.4956  Acc@1: 87.5000 (85.1545)  Acc@5: 100.0000 (98.2981)  time: 0.3488  data: 0.0007  max mem: 2502
Train: Epoch[2/5]  [1320/3125]  eta: 0:10:30  Lr: 0.001875  Loss: -0.7360  Acc@1: 87.5000 (85.1864)  Acc@5: 100.0000 (98.3062)  time: 0.3501  data: 0.0007  max mem: 2502
Train: Epoch[2/5]  [1330/3125]  eta: 0:10:27  Lr: 0.001875  Loss: -0.2871  Acc@1: 87.5000 (85.1850)  Acc@5: 100.0000 (98.3002)  time: 0.3501  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [1340/3125]  eta: 0:10:23  Lr: 0.001875  Loss: -0.6324  Acc@1: 87.5000 (85.1836)  Acc@5: 100.0000 (98.3035)  time: 0.3499  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [1350/3125]  eta: 0:10:20  Lr: 0.001875  Loss: -0.5281  Acc@1: 81.2500 (85.1730)  Acc@5: 100.0000 (98.3161)  time: 0.3508  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [1360/3125]  eta: 0:10:16  Lr: 0.001875  Loss: -0.0564  Acc@1: 81.2500 (85.1580)  Acc@5: 100.0000 (98.3147)  time: 0.3502  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [1370/3125]  eta: 0:10:13  Lr: 0.001875  Loss: -0.0211  Acc@1: 81.2500 (85.1067)  Acc@5: 100.0000 (98.3224)  time: 0.3492  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [1380/3125]  eta: 0:10:09  Lr: 0.001875  Loss: -0.5872  Acc@1: 81.2500 (85.1195)  Acc@5: 100.0000 (98.3300)  time: 0.3488  data: 0.0008  max mem: 2502
Train: Epoch[2/5]  [1390/3125]  eta: 0:10:06  Lr: 0.001875  Loss: -0.5787  Acc@1: 87.5000 (85.1186)  Acc@5: 100.0000 (98.3240)  time: 0.3485  data: 0.0009  max mem: 2502
Train: Epoch[2/5]  [1400/3125]  eta: 0:10:02  Lr: 0.001875  Loss: -0.2276  Acc@1: 81.2500 (85.0776)  Acc@5: 100.0000 (98.3182)  time: 0.3503  data: 0.0017  max mem: 2502
Train: Epoch[2/5]  [1410/3125]  eta: 0:09:59  Lr: 0.001875  Loss: -0.5675  Acc@1: 81.2500 (85.0682)  Acc@5: 100.0000 (98.3079)  time: 0.3516  data: 0.0028  max mem: 2502
Train: Epoch[2/5]  [1420/3125]  eta: 0:09:55  Lr: 0.001875  Loss: -0.5480  Acc@1: 81.2500 (85.0413)  Acc@5: 100.0000 (98.3067)  time: 0.3500  data: 0.0018  max mem: 2502
Train: Epoch[2/5]  [1430/3125]  eta: 0:09:52  Lr: 0.001875  Loss: -0.1774  Acc@1: 81.2500 (85.0236)  Acc@5: 100.0000 (98.3010)  time: 0.3494  data: 0.0007  max mem: 2502
Train: Epoch[2/5]  [1440/3125]  eta: 0:09:48  Lr: 0.001875  Loss: -0.5842  Acc@1: 87.5000 (85.0104)  Acc@5: 100.0000 (98.2998)  time: 0.3497  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [1450/3125]  eta: 0:09:45  Lr: 0.001875  Loss: -0.8481  Acc@1: 81.2500 (85.0017)  Acc@5: 100.0000 (98.2900)  time: 0.3493  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [1460/3125]  eta: 0:09:41  Lr: 0.001875  Loss: -0.5533  Acc@1: 81.2500 (85.0145)  Acc@5: 100.0000 (98.2974)  time: 0.3487  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [1470/3125]  eta: 0:09:38  Lr: 0.001875  Loss: -0.5470  Acc@1: 87.5000 (85.0527)  Acc@5: 100.0000 (98.3090)  time: 0.3487  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [1480/3125]  eta: 0:09:34  Lr: 0.001875  Loss: -0.7611  Acc@1: 87.5000 (85.0397)  Acc@5: 100.0000 (98.3162)  time: 0.3486  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [1490/3125]  eta: 0:09:31  Lr: 0.001875  Loss: -0.4397  Acc@1: 81.2500 (85.0310)  Acc@5: 100.0000 (98.3065)  time: 0.3489  data: 0.0010  max mem: 2502
Train: Epoch[2/5]  [1500/3125]  eta: 0:09:27  Lr: 0.001875  Loss: -0.1111  Acc@1: 81.2500 (85.0433)  Acc@5: 100.0000 (98.3136)  time: 0.3491  data: 0.0011  max mem: 2502
Train: Epoch[2/5]  [1510/3125]  eta: 0:09:24  Lr: 0.001875  Loss: -0.8703  Acc@1: 87.5000 (85.0678)  Acc@5: 100.0000 (98.3206)  time: 0.3497  data: 0.0008  max mem: 2502
Train: Epoch[2/5]  [1520/3125]  eta: 0:09:20  Lr: 0.001875  Loss: -0.4177  Acc@1: 87.5000 (85.0510)  Acc@5: 100.0000 (98.3111)  time: 0.3496  data: 0.0009  max mem: 2502
Train: Epoch[2/5]  [1530/3125]  eta: 0:09:17  Lr: 0.001875  Loss: -0.5652  Acc@1: 81.2500 (85.0465)  Acc@5: 100.0000 (98.3181)  time: 0.3491  data: 0.0007  max mem: 2502
Train: Epoch[2/5]  [1540/3125]  eta: 0:09:13  Lr: 0.001875  Loss: -0.4241  Acc@1: 81.2500 (85.0584)  Acc@5: 100.0000 (98.3209)  time: 0.3490  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [1550/3125]  eta: 0:09:10  Lr: 0.001875  Loss: -0.3687  Acc@1: 81.2500 (85.0218)  Acc@5: 100.0000 (98.3116)  time: 0.3485  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [1560/3125]  eta: 0:09:06  Lr: 0.001875  Loss: -0.5154  Acc@1: 81.2500 (85.0296)  Acc@5: 100.0000 (98.3104)  time: 0.3491  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [1570/3125]  eta: 0:09:03  Lr: 0.001875  Loss: -0.6868  Acc@1: 87.5000 (85.0294)  Acc@5: 100.0000 (98.3012)  time: 0.3497  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [1580/3125]  eta: 0:08:59  Lr: 0.001875  Loss: -0.8617  Acc@1: 87.5000 (85.0530)  Acc@5: 100.0000 (98.3001)  time: 0.3494  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [1590/3125]  eta: 0:08:56  Lr: 0.001875  Loss: -0.5156  Acc@1: 87.5000 (85.0291)  Acc@5: 100.0000 (98.3030)  time: 0.3492  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [1600/3125]  eta: 0:08:52  Lr: 0.001875  Loss: -0.6393  Acc@1: 81.2500 (85.0289)  Acc@5: 100.0000 (98.2979)  time: 0.3488  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [1610/3125]  eta: 0:08:49  Lr: 0.001875  Loss: -0.5813  Acc@1: 81.2500 (85.0209)  Acc@5: 100.0000 (98.3007)  time: 0.3480  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [1620/3125]  eta: 0:08:45  Lr: 0.001875  Loss: -0.6004  Acc@1: 81.2500 (85.0054)  Acc@5: 100.0000 (98.2842)  time: 0.3487  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [1630/3125]  eta: 0:08:42  Lr: 0.001875  Loss: -0.6027  Acc@1: 87.5000 (85.0322)  Acc@5: 100.0000 (98.2909)  time: 0.3492  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [1640/3125]  eta: 0:08:38  Lr: 0.001875  Loss: -0.6389  Acc@1: 87.5000 (85.0091)  Acc@5: 100.0000 (98.2899)  time: 0.3494  data: 0.0007  max mem: 2502
Train: Epoch[2/5]  [1650/3125]  eta: 0:08:35  Lr: 0.001875  Loss: -0.5858  Acc@1: 87.5000 (85.0280)  Acc@5: 100.0000 (98.2927)  time: 0.3493  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [1660/3125]  eta: 0:08:31  Lr: 0.001875  Loss: -0.3537  Acc@1: 87.5000 (85.0504)  Acc@5: 100.0000 (98.2917)  time: 0.3498  data: 0.0007  max mem: 2502
Train: Epoch[2/5]  [1670/3125]  eta: 0:08:28  Lr: 0.001875  Loss: -0.3609  Acc@1: 87.5000 (85.0576)  Acc@5: 100.0000 (98.2944)  time: 0.3498  data: 0.0007  max mem: 2502
Train: Epoch[2/5]  [1680/3125]  eta: 0:08:24  Lr: 0.001875  Loss: -0.3694  Acc@1: 87.5000 (85.0796)  Acc@5: 100.0000 (98.2786)  time: 0.3514  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [1690/3125]  eta: 0:08:21  Lr: 0.001875  Loss: -0.5204  Acc@1: 87.5000 (85.0976)  Acc@5: 100.0000 (98.2776)  time: 0.3512  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [1700/3125]  eta: 0:08:17  Lr: 0.001875  Loss: -0.6981  Acc@1: 87.5000 (85.0933)  Acc@5: 100.0000 (98.2804)  time: 0.3489  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [1710/3125]  eta: 0:08:14  Lr: 0.001875  Loss: -0.6828  Acc@1: 87.5000 (85.0928)  Acc@5: 100.0000 (98.2905)  time: 0.3496  data: 0.0009  max mem: 2502
Train: Epoch[2/5]  [1720/3125]  eta: 0:08:10  Lr: 0.001875  Loss: -0.5965  Acc@1: 87.5000 (85.1068)  Acc@5: 100.0000 (98.2895)  time: 0.3493  data: 0.0007  max mem: 2502
Train: Epoch[2/5]  [1730/3125]  eta: 0:08:07  Lr: 0.001875  Loss: -0.7645  Acc@1: 87.5000 (85.1386)  Acc@5: 100.0000 (98.2813)  time: 0.3493  data: 0.0007  max mem: 2502
Train: Epoch[2/5]  [1740/3125]  eta: 0:08:03  Lr: 0.001875  Loss: -0.5329  Acc@1: 87.5000 (85.1414)  Acc@5: 100.0000 (98.2876)  time: 0.3497  data: 0.0007  max mem: 2502
Train: Epoch[2/5]  [1750/3125]  eta: 0:08:00  Lr: 0.001875  Loss: -0.3417  Acc@1: 87.5000 (85.1406)  Acc@5: 100.0000 (98.2938)  time: 0.3493  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [1760/3125]  eta: 0:07:56  Lr: 0.001875  Loss: -0.6253  Acc@1: 81.2500 (85.1114)  Acc@5: 100.0000 (98.2929)  time: 0.3496  data: 0.0012  max mem: 2502
Train: Epoch[2/5]  [1770/3125]  eta: 0:07:53  Lr: 0.001875  Loss: -0.4072  Acc@1: 87.5000 (85.1390)  Acc@5: 100.0000 (98.2955)  time: 0.3498  data: 0.0014  max mem: 2502
Train: Epoch[2/5]  [1780/3125]  eta: 0:07:49  Lr: 0.001875  Loss: -0.7697  Acc@1: 93.7500 (85.1663)  Acc@5: 100.0000 (98.3015)  time: 0.3494  data: 0.0007  max mem: 2502
Train: Epoch[2/5]  [1790/3125]  eta: 0:07:46  Lr: 0.001875  Loss: -0.6556  Acc@1: 93.7500 (85.1654)  Acc@5: 100.0000 (98.3110)  time: 0.3484  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [1800/3125]  eta: 0:07:42  Lr: 0.001875  Loss: -0.3948  Acc@1: 87.5000 (85.1749)  Acc@5: 100.0000 (98.3100)  time: 0.3478  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [1810/3125]  eta: 0:07:39  Lr: 0.001875  Loss: -0.6196  Acc@1: 87.5000 (85.1774)  Acc@5: 100.0000 (98.3089)  time: 0.3487  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [1820/3125]  eta: 0:07:35  Lr: 0.001875  Loss: -0.4862  Acc@1: 81.2500 (85.1661)  Acc@5: 100.0000 (98.3045)  time: 0.3494  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [1830/3125]  eta: 0:07:32  Lr: 0.001875  Loss: -0.5268  Acc@1: 81.2500 (85.1891)  Acc@5: 100.0000 (98.3103)  time: 0.3488  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [1840/3125]  eta: 0:07:28  Lr: 0.001875  Loss: -0.5986  Acc@1: 87.5000 (85.2017)  Acc@5: 100.0000 (98.3161)  time: 0.3484  data: 0.0009  max mem: 2502
Train: Epoch[2/5]  [1850/3125]  eta: 0:07:25  Lr: 0.001875  Loss: -0.6340  Acc@1: 87.5000 (85.1871)  Acc@5: 100.0000 (98.3252)  time: 0.3489  data: 0.0009  max mem: 2502
Train: Epoch[2/5]  [1860/3125]  eta: 0:07:21  Lr: 0.001875  Loss: -0.4933  Acc@1: 81.2500 (85.1726)  Acc@5: 100.0000 (98.3208)  time: 0.3490  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [1870/3125]  eta: 0:07:18  Lr: 0.001875  Loss: -0.9121  Acc@1: 87.5000 (85.1851)  Acc@5: 100.0000 (98.3264)  time: 0.3479  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [1880/3125]  eta: 0:07:14  Lr: 0.001875  Loss: -0.3830  Acc@1: 81.2500 (85.1641)  Acc@5: 100.0000 (98.3353)  time: 0.3486  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [1890/3125]  eta: 0:07:11  Lr: 0.001875  Loss: -0.8649  Acc@1: 87.5000 (85.1864)  Acc@5: 100.0000 (98.3408)  time: 0.3497  data: 0.0007  max mem: 2502
Train: Epoch[2/5]  [1900/3125]  eta: 0:07:07  Lr: 0.001875  Loss: -0.0349  Acc@1: 87.5000 (85.1789)  Acc@5: 100.0000 (98.3430)  time: 0.3491  data: 0.0007  max mem: 2502
Train: Epoch[2/5]  [1910/3125]  eta: 0:07:04  Lr: 0.001875  Loss: -0.4227  Acc@1: 87.5000 (85.1975)  Acc@5: 100.0000 (98.3451)  time: 0.3482  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [1920/3125]  eta: 0:07:00  Lr: 0.001875  Loss: -0.7496  Acc@1: 87.5000 (85.2030)  Acc@5: 100.0000 (98.3440)  time: 0.3476  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [1930/3125]  eta: 0:06:57  Lr: 0.001875  Loss: -0.0559  Acc@1: 87.5000 (85.2020)  Acc@5: 100.0000 (98.3493)  time: 0.3481  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [1940/3125]  eta: 0:06:53  Lr: 0.001875  Loss: -0.5308  Acc@1: 87.5000 (85.2106)  Acc@5: 100.0000 (98.3514)  time: 0.3484  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [1950/3125]  eta: 0:06:50  Lr: 0.001875  Loss: -0.3341  Acc@1: 87.5000 (85.2127)  Acc@5: 100.0000 (98.3406)  time: 0.3476  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [1960/3125]  eta: 0:06:46  Lr: 0.001875  Loss: -0.4813  Acc@1: 87.5000 (85.2244)  Acc@5: 100.0000 (98.3395)  time: 0.3480  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [1970/3125]  eta: 0:06:43  Lr: 0.001875  Loss: -0.4226  Acc@1: 87.5000 (85.2232)  Acc@5: 100.0000 (98.3416)  time: 0.3503  data: 0.0007  max mem: 2502
Train: Epoch[2/5]  [1980/3125]  eta: 0:06:39  Lr: 0.001875  Loss: -0.5652  Acc@1: 81.2500 (85.2032)  Acc@5: 100.0000 (98.3405)  time: 0.3505  data: 0.0007  max mem: 2502
Train: Epoch[2/5]  [1990/3125]  eta: 0:06:36  Lr: 0.001875  Loss: -0.4486  Acc@1: 81.2500 (85.2116)  Acc@5: 100.0000 (98.3457)  time: 0.3497  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [2000/3125]  eta: 0:06:32  Lr: 0.001875  Loss: -0.6570  Acc@1: 87.5000 (85.2199)  Acc@5: 100.0000 (98.3477)  time: 0.3494  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [2010/3125]  eta: 0:06:29  Lr: 0.001875  Loss: -0.7447  Acc@1: 87.5000 (85.2219)  Acc@5: 100.0000 (98.3466)  time: 0.3487  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [2020/3125]  eta: 0:06:26  Lr: 0.001875  Loss: -0.4626  Acc@1: 81.2500 (85.2084)  Acc@5: 100.0000 (98.3517)  time: 0.3486  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [2030/3125]  eta: 0:06:22  Lr: 0.001875  Loss: -0.7465  Acc@1: 81.2500 (85.2074)  Acc@5: 100.0000 (98.3475)  time: 0.3488  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [2040/3125]  eta: 0:06:19  Lr: 0.001875  Loss: -0.1008  Acc@1: 81.2500 (85.2033)  Acc@5: 100.0000 (98.3464)  time: 0.3484  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [2050/3125]  eta: 0:06:15  Lr: 0.001875  Loss: -0.7934  Acc@1: 87.5000 (85.2145)  Acc@5: 100.0000 (98.3514)  time: 0.3477  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [2060/3125]  eta: 0:06:12  Lr: 0.001875  Loss: -0.8190  Acc@1: 93.7500 (85.2438)  Acc@5: 100.0000 (98.3533)  time: 0.3481  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [2070/3125]  eta: 0:06:08  Lr: 0.001875  Loss: -0.2213  Acc@1: 87.5000 (85.2336)  Acc@5: 100.0000 (98.3553)  time: 0.3490  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [2080/3125]  eta: 0:06:05  Lr: 0.001875  Loss: -0.7591  Acc@1: 81.2500 (85.2174)  Acc@5: 100.0000 (98.3542)  time: 0.3497  data: 0.0009  max mem: 2502
Train: Epoch[2/5]  [2090/3125]  eta: 0:06:01  Lr: 0.001875  Loss: -0.3001  Acc@1: 81.2500 (85.2015)  Acc@5: 100.0000 (98.3471)  time: 0.3499  data: 0.0008  max mem: 2502
Train: Epoch[2/5]  [2100/3125]  eta: 0:05:58  Lr: 0.001875  Loss: -0.4246  Acc@1: 87.5000 (85.2243)  Acc@5: 100.0000 (98.3460)  time: 0.3486  data: 0.0007  max mem: 2502
Train: Epoch[2/5]  [2110/3125]  eta: 0:05:54  Lr: 0.001875  Loss: -0.2927  Acc@1: 87.5000 (85.2410)  Acc@5: 100.0000 (98.3450)  time: 0.3482  data: 0.0015  max mem: 2502
Train: Epoch[2/5]  [2120/3125]  eta: 0:05:51  Lr: 0.001875  Loss: -0.5879  Acc@1: 87.5000 (85.2517)  Acc@5: 100.0000 (98.3528)  time: 0.3484  data: 0.0014  max mem: 2502
Train: Epoch[2/5]  [2130/3125]  eta: 0:05:47  Lr: 0.001875  Loss: -0.6829  Acc@1: 87.5000 (85.2534)  Acc@5: 100.0000 (98.3458)  time: 0.3480  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [2140/3125]  eta: 0:05:44  Lr: 0.001875  Loss: -0.6897  Acc@1: 87.5000 (85.2522)  Acc@5: 100.0000 (98.3477)  time: 0.3510  data: 0.0007  max mem: 2502
Train: Epoch[2/5]  [2150/3125]  eta: 0:05:40  Lr: 0.001875  Loss: -0.8035  Acc@1: 87.5000 (85.2627)  Acc@5: 100.0000 (98.3438)  time: 0.3534  data: 0.0010  max mem: 2502
Train: Epoch[2/5]  [2160/3125]  eta: 0:05:37  Lr: 0.001875  Loss: -0.4087  Acc@1: 87.5000 (85.2615)  Acc@5: 100.0000 (98.3457)  time: 0.3508  data: 0.0008  max mem: 2502
Train: Epoch[2/5]  [2170/3125]  eta: 0:05:33  Lr: 0.001875  Loss: -0.6531  Acc@1: 87.5000 (85.2602)  Acc@5: 100.0000 (98.3475)  time: 0.3495  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [2180/3125]  eta: 0:05:30  Lr: 0.001875  Loss: -0.4998  Acc@1: 81.2500 (85.2476)  Acc@5: 100.0000 (98.3522)  time: 0.3496  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [2190/3125]  eta: 0:05:26  Lr: 0.001875  Loss: -0.9177  Acc@1: 87.5000 (85.2693)  Acc@5: 100.0000 (98.3541)  time: 0.3480  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [2200/3125]  eta: 0:05:23  Lr: 0.001875  Loss: -0.6234  Acc@1: 87.5000 (85.2624)  Acc@5: 100.0000 (98.3530)  time: 0.3487  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [2210/3125]  eta: 0:05:19  Lr: 0.001875  Loss: -0.7213  Acc@1: 87.5000 (85.2612)  Acc@5: 100.0000 (98.3576)  time: 0.3507  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [2220/3125]  eta: 0:05:16  Lr: 0.001875  Loss: -0.5629  Acc@1: 87.5000 (85.2656)  Acc@5: 100.0000 (98.3594)  time: 0.3500  data: 0.0007  max mem: 2502
Train: Epoch[2/5]  [2230/3125]  eta: 0:05:12  Lr: 0.001875  Loss: -0.2952  Acc@1: 87.5000 (85.2729)  Acc@5: 100.0000 (98.3640)  time: 0.3490  data: 0.0009  max mem: 2502
Train: Epoch[2/5]  [2240/3125]  eta: 0:05:09  Lr: 0.001875  Loss: -0.4304  Acc@1: 87.5000 (85.2912)  Acc@5: 100.0000 (98.3629)  time: 0.3492  data: 0.0008  max mem: 2502
Train: Epoch[2/5]  [2250/3125]  eta: 0:05:05  Lr: 0.001875  Loss: -0.4206  Acc@1: 87.5000 (85.2899)  Acc@5: 100.0000 (98.3646)  time: 0.3489  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [2260/3125]  eta: 0:05:02  Lr: 0.001875  Loss: -0.4106  Acc@1: 87.5000 (85.3107)  Acc@5: 100.0000 (98.3691)  time: 0.3485  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [2270/3125]  eta: 0:04:58  Lr: 0.001875  Loss: -0.3884  Acc@1: 87.5000 (85.3093)  Acc@5: 100.0000 (98.3653)  time: 0.3486  data: 0.0008  max mem: 2502
Train: Epoch[2/5]  [2280/3125]  eta: 0:04:55  Lr: 0.001875  Loss: -0.5290  Acc@1: 87.5000 (85.3189)  Acc@5: 100.0000 (98.3615)  time: 0.3499  data: 0.0012  max mem: 2502
Train: Epoch[2/5]  [2290/3125]  eta: 0:04:51  Lr: 0.001875  Loss: -0.5661  Acc@1: 87.5000 (85.3175)  Acc@5: 100.0000 (98.3659)  time: 0.3505  data: 0.0011  max mem: 2502
Train: Epoch[2/5]  [2300/3125]  eta: 0:04:48  Lr: 0.001875  Loss: -0.4110  Acc@1: 81.2500 (85.3162)  Acc@5: 100.0000 (98.3676)  time: 0.3500  data: 0.0007  max mem: 2502
Train: Epoch[2/5]  [2310/3125]  eta: 0:04:44  Lr: 0.001875  Loss: -0.3739  Acc@1: 87.5000 (85.3337)  Acc@5: 100.0000 (98.3692)  time: 0.3501  data: 0.0007  max mem: 2502
Train: Epoch[2/5]  [2320/3125]  eta: 0:04:41  Lr: 0.001875  Loss: -0.5194  Acc@1: 87.5000 (85.3027)  Acc@5: 100.0000 (98.3628)  time: 0.3494  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [2330/3125]  eta: 0:04:37  Lr: 0.001875  Loss: -0.7773  Acc@1: 81.2500 (85.3067)  Acc@5: 100.0000 (98.3698)  time: 0.3497  data: 0.0009  max mem: 2502
Train: Epoch[2/5]  [2340/3125]  eta: 0:04:34  Lr: 0.001875  Loss: -0.7954  Acc@1: 87.5000 (85.3241)  Acc@5: 100.0000 (98.3768)  time: 0.3519  data: 0.0009  max mem: 2502
Train: Epoch[2/5]  [2350/3125]  eta: 0:04:30  Lr: 0.001875  Loss: -0.6040  Acc@1: 87.5000 (85.3440)  Acc@5: 100.0000 (98.3783)  time: 0.3529  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [2360/3125]  eta: 0:04:27  Lr: 0.001875  Loss: -0.8100  Acc@1: 87.5000 (85.3293)  Acc@5: 100.0000 (98.3640)  time: 0.3503  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [2370/3125]  eta: 0:04:23  Lr: 0.001875  Loss: -0.4070  Acc@1: 81.2500 (85.3279)  Acc@5: 100.0000 (98.3604)  time: 0.3491  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [2380/3125]  eta: 0:04:20  Lr: 0.001875  Loss: -0.7468  Acc@1: 87.5000 (85.3318)  Acc@5: 100.0000 (98.3620)  time: 0.3509  data: 0.0007  max mem: 2502
Train: Epoch[2/5]  [2390/3125]  eta: 0:04:16  Lr: 0.001875  Loss: -0.5075  Acc@1: 87.5000 (85.3382)  Acc@5: 100.0000 (98.3610)  time: 0.3511  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [2400/3125]  eta: 0:04:13  Lr: 0.001875  Loss: -0.7482  Acc@1: 87.5000 (85.3446)  Acc@5: 100.0000 (98.3653)  time: 0.3498  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [2410/3125]  eta: 0:04:09  Lr: 0.001875  Loss: -0.6723  Acc@1: 87.5000 (85.3432)  Acc@5: 100.0000 (98.3643)  time: 0.3480  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [2420/3125]  eta: 0:04:06  Lr: 0.001875  Loss: -0.5424  Acc@1: 87.5000 (85.3573)  Acc@5: 100.0000 (98.3633)  time: 0.3481  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [2430/3125]  eta: 0:04:02  Lr: 0.001875  Loss: -0.4769  Acc@1: 87.5000 (85.3558)  Acc@5: 100.0000 (98.3649)  time: 0.3500  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [2440/3125]  eta: 0:03:59  Lr: 0.001875  Loss: -0.3086  Acc@1: 81.2500 (85.3390)  Acc@5: 100.0000 (98.3690)  time: 0.3517  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [2450/3125]  eta: 0:03:55  Lr: 0.001875  Loss: -0.4708  Acc@1: 87.5000 (85.3478)  Acc@5: 100.0000 (98.3680)  time: 0.3513  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [2460/3125]  eta: 0:03:52  Lr: 0.001875  Loss: -0.6528  Acc@1: 87.5000 (85.3312)  Acc@5: 100.0000 (98.3619)  time: 0.3520  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [2470/3125]  eta: 0:03:48  Lr: 0.001875  Loss: -0.2312  Acc@1: 81.2500 (85.3374)  Acc@5: 100.0000 (98.3585)  time: 0.3514  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [2480/3125]  eta: 0:03:45  Lr: 0.001875  Loss: -0.0985  Acc@1: 87.5000 (85.3461)  Acc@5: 100.0000 (98.3550)  time: 0.3505  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [2490/3125]  eta: 0:03:41  Lr: 0.001875  Loss: -0.4341  Acc@1: 87.5000 (85.3473)  Acc@5: 100.0000 (98.3566)  time: 0.3504  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [2500/3125]  eta: 0:03:38  Lr: 0.001875  Loss: -0.2878  Acc@1: 81.2500 (85.3434)  Acc@5: 100.0000 (98.3557)  time: 0.3495  data: 0.0007  max mem: 2502
Train: Epoch[2/5]  [2510/3125]  eta: 0:03:34  Lr: 0.001875  Loss: -0.5440  Acc@1: 81.2500 (85.3395)  Acc@5: 100.0000 (98.3523)  time: 0.3495  data: 0.0007  max mem: 2502
Train: Epoch[2/5]  [2520/3125]  eta: 0:03:31  Lr: 0.001875  Loss: -0.6111  Acc@1: 87.5000 (85.3406)  Acc@5: 100.0000 (98.3563)  time: 0.3485  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [2530/3125]  eta: 0:03:27  Lr: 0.001875  Loss: -0.2305  Acc@1: 87.5000 (85.3516)  Acc@5: 100.0000 (98.3554)  time: 0.3488  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [2540/3125]  eta: 0:03:24  Lr: 0.001875  Loss: -0.6960  Acc@1: 87.5000 (85.3601)  Acc@5: 100.0000 (98.3520)  time: 0.3498  data: 0.0009  max mem: 2502
Train: Epoch[2/5]  [2550/3125]  eta: 0:03:20  Lr: 0.001875  Loss: -0.4038  Acc@1: 87.5000 (85.3685)  Acc@5: 100.0000 (98.3487)  time: 0.3498  data: 0.0010  max mem: 2502
Train: Epoch[2/5]  [2560/3125]  eta: 0:03:17  Lr: 0.001875  Loss: -0.8394  Acc@1: 87.5000 (85.3792)  Acc@5: 100.0000 (98.3527)  time: 0.3486  data: 0.0007  max mem: 2502
Train: Epoch[2/5]  [2570/3125]  eta: 0:03:13  Lr: 0.001875  Loss: -0.5546  Acc@1: 87.5000 (85.3826)  Acc@5: 100.0000 (98.3542)  time: 0.3480  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [2580/3125]  eta: 0:03:10  Lr: 0.001875  Loss: -0.6812  Acc@1: 87.5000 (85.4054)  Acc@5: 100.0000 (98.3582)  time: 0.3486  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [2590/3125]  eta: 0:03:06  Lr: 0.001875  Loss: -0.2750  Acc@1: 93.7500 (85.4086)  Acc@5: 100.0000 (98.3573)  time: 0.3488  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [2600/3125]  eta: 0:03:03  Lr: 0.001875  Loss: -0.7241  Acc@1: 87.5000 (85.4287)  Acc@5: 100.0000 (98.3588)  time: 0.3490  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [2610/3125]  eta: 0:02:59  Lr: 0.001875  Loss: -0.4933  Acc@1: 87.5000 (85.4270)  Acc@5: 100.0000 (98.3651)  time: 0.3488  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [2620/3125]  eta: 0:02:56  Lr: 0.001875  Loss: -0.8639  Acc@1: 87.5000 (85.4278)  Acc@5: 100.0000 (98.3618)  time: 0.3480  data: 0.0011  max mem: 2502
Train: Epoch[2/5]  [2630/3125]  eta: 0:02:52  Lr: 0.001875  Loss: -0.4557  Acc@1: 81.2500 (85.4285)  Acc@5: 100.0000 (98.3633)  time: 0.3478  data: 0.0014  max mem: 2502
Train: Epoch[2/5]  [2640/3125]  eta: 0:02:49  Lr: 0.001875  Loss: -0.9288  Acc@1: 81.2500 (85.4269)  Acc@5: 100.0000 (98.3600)  time: 0.3482  data: 0.0007  max mem: 2502
Train: Epoch[2/5]  [2650/3125]  eta: 0:02:45  Lr: 0.001875  Loss: -0.1999  Acc@1: 81.2500 (85.4112)  Acc@5: 100.0000 (98.3473)  time: 0.3480  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [2660/3125]  eta: 0:02:42  Lr: 0.001875  Loss: -0.9763  Acc@1: 81.2500 (85.4331)  Acc@5: 93.7500 (98.3441)  time: 0.3485  data: 0.0007  max mem: 2502
Train: Epoch[2/5]  [2670/3125]  eta: 0:02:38  Lr: 0.001875  Loss: -0.3501  Acc@1: 87.5000 (85.4315)  Acc@5: 100.0000 (98.3433)  time: 0.3498  data: 0.0007  max mem: 2502
Train: Epoch[2/5]  [2680/3125]  eta: 0:02:35  Lr: 0.001875  Loss: -0.7942  Acc@1: 87.5000 (85.4462)  Acc@5: 100.0000 (98.3402)  time: 0.3486  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [2690/3125]  eta: 0:02:31  Lr: 0.001875  Loss: -0.2626  Acc@1: 87.5000 (85.4399)  Acc@5: 100.0000 (98.3394)  time: 0.3488  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [2700/3125]  eta: 0:02:28  Lr: 0.001875  Loss: -0.4427  Acc@1: 81.2500 (85.4359)  Acc@5: 100.0000 (98.3432)  time: 0.3497  data: 0.0007  max mem: 2502
Train: Epoch[2/5]  [2710/3125]  eta: 0:02:24  Lr: 0.001875  Loss: -0.3010  Acc@1: 87.5000 (85.4413)  Acc@5: 100.0000 (98.3378)  time: 0.3488  data: 0.0007  max mem: 2502
Train: Epoch[2/5]  [2720/3125]  eta: 0:02:21  Lr: 0.001875  Loss: -0.6311  Acc@1: 87.5000 (85.4442)  Acc@5: 100.0000 (98.3393)  time: 0.3472  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [2730/3125]  eta: 0:02:17  Lr: 0.001875  Loss: -0.8520  Acc@1: 87.5000 (85.4632)  Acc@5: 100.0000 (98.3408)  time: 0.3472  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [2740/3125]  eta: 0:02:14  Lr: 0.001875  Loss: -0.5267  Acc@1: 87.5000 (85.4547)  Acc@5: 100.0000 (98.3423)  time: 0.3489  data: 0.0007  max mem: 2502
Train: Epoch[2/5]  [2750/3125]  eta: 0:02:11  Lr: 0.001875  Loss: -0.1232  Acc@1: 87.5000 (85.4553)  Acc@5: 100.0000 (98.3461)  time: 0.3505  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [2760/3125]  eta: 0:02:07  Lr: 0.001875  Loss: -0.4408  Acc@1: 81.2500 (85.4491)  Acc@5: 100.0000 (98.3407)  time: 0.3510  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [2770/3125]  eta: 0:02:04  Lr: 0.001875  Loss: -0.9322  Acc@1: 87.5000 (85.4610)  Acc@5: 100.0000 (98.3445)  time: 0.3498  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [2780/3125]  eta: 0:02:00  Lr: 0.001875  Loss: -0.5336  Acc@1: 87.5000 (85.4818)  Acc@5: 100.0000 (98.3504)  time: 0.3479  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [2790/3125]  eta: 0:01:57  Lr: 0.001875  Loss: -0.4929  Acc@1: 87.5000 (85.4644)  Acc@5: 100.0000 (98.3496)  time: 0.3473  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [2800/3125]  eta: 0:01:53  Lr: 0.001875  Loss: -0.4402  Acc@1: 87.5000 (85.4717)  Acc@5: 100.0000 (98.3510)  time: 0.3483  data: 0.0011  max mem: 2502
Train: Epoch[2/5]  [2810/3125]  eta: 0:01:50  Lr: 0.001875  Loss: -0.7663  Acc@1: 87.5000 (85.4723)  Acc@5: 100.0000 (98.3502)  time: 0.3484  data: 0.0011  max mem: 2502
Train: Epoch[2/5]  [2820/3125]  eta: 0:01:46  Lr: 0.001875  Loss: -0.8483  Acc@1: 87.5000 (85.4817)  Acc@5: 100.0000 (98.3539)  time: 0.3481  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [2830/3125]  eta: 0:01:43  Lr: 0.001875  Loss: -0.8296  Acc@1: 87.5000 (85.4844)  Acc@5: 100.0000 (98.3531)  time: 0.3482  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [2840/3125]  eta: 0:01:39  Lr: 0.001875  Loss: -0.8724  Acc@1: 87.5000 (85.4915)  Acc@5: 100.0000 (98.3567)  time: 0.3490  data: 0.0013  max mem: 2502
Train: Epoch[2/5]  [2850/3125]  eta: 0:01:36  Lr: 0.001875  Loss: -0.2997  Acc@1: 87.5000 (85.4919)  Acc@5: 100.0000 (98.3602)  time: 0.3493  data: 0.0013  max mem: 2502
Train: Epoch[2/5]  [2860/3125]  eta: 0:01:32  Lr: 0.001875  Loss: -0.0868  Acc@1: 87.5000 (85.4946)  Acc@5: 100.0000 (98.3638)  time: 0.3491  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [2870/3125]  eta: 0:01:29  Lr: 0.001875  Loss: -0.5645  Acc@1: 81.2500 (85.4842)  Acc@5: 100.0000 (98.3608)  time: 0.3498  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [2880/3125]  eta: 0:01:25  Lr: 0.001875  Loss: -0.1956  Acc@1: 81.2500 (85.4825)  Acc@5: 100.0000 (98.3643)  time: 0.3488  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [2890/3125]  eta: 0:01:22  Lr: 0.001875  Loss: -0.4104  Acc@1: 87.5000 (85.4851)  Acc@5: 100.0000 (98.3635)  time: 0.3500  data: 0.0023  max mem: 2502
Train: Epoch[2/5]  [2900/3125]  eta: 0:01:18  Lr: 0.001875  Loss: -0.2999  Acc@1: 87.5000 (85.4835)  Acc@5: 100.0000 (98.3605)  time: 0.3501  data: 0.0022  max mem: 2502
Train: Epoch[2/5]  [2910/3125]  eta: 0:01:15  Lr: 0.001875  Loss: -0.8839  Acc@1: 87.5000 (85.4990)  Acc@5: 100.0000 (98.3640)  time: 0.3485  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [2920/3125]  eta: 0:01:11  Lr: 0.001875  Loss: -0.7244  Acc@1: 87.5000 (85.5080)  Acc@5: 100.0000 (98.3674)  time: 0.3510  data: 0.0007  max mem: 2502
Train: Epoch[2/5]  [2930/3125]  eta: 0:01:08  Lr: 0.001875  Loss: -0.2622  Acc@1: 87.5000 (85.5020)  Acc@5: 100.0000 (98.3645)  time: 0.3519  data: 0.0008  max mem: 2502
Train: Epoch[2/5]  [2940/3125]  eta: 0:01:04  Lr: 0.001875  Loss: -0.0811  Acc@1: 87.5000 (85.5151)  Acc@5: 100.0000 (98.3637)  time: 0.3503  data: 0.0007  max mem: 2502
Train: Epoch[2/5]  [2950/3125]  eta: 0:01:01  Lr: 0.001875  Loss: -0.7122  Acc@1: 93.7500 (85.5240)  Acc@5: 100.0000 (98.3650)  time: 0.3493  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [2960/3125]  eta: 0:00:57  Lr: 0.001875  Loss: -0.4294  Acc@1: 87.5000 (85.5264)  Acc@5: 100.0000 (98.3663)  time: 0.3495  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [2970/3125]  eta: 0:00:54  Lr: 0.001875  Loss: -0.5887  Acc@1: 87.5000 (85.5183)  Acc@5: 100.0000 (98.3633)  time: 0.3505  data: 0.0007  max mem: 2502
Train: Epoch[2/5]  [2980/3125]  eta: 0:00:50  Lr: 0.001875  Loss: -0.2590  Acc@1: 87.5000 (85.5271)  Acc@5: 100.0000 (98.3625)  time: 0.3506  data: 0.0011  max mem: 2502
Train: Epoch[2/5]  [2990/3125]  eta: 0:00:47  Lr: 0.001875  Loss: -0.7180  Acc@1: 87.5000 (85.5274)  Acc@5: 100.0000 (98.3618)  time: 0.3492  data: 0.0010  max mem: 2502
Train: Epoch[2/5]  [3000/3125]  eta: 0:00:43  Lr: 0.001875  Loss: -0.4952  Acc@1: 87.5000 (85.5402)  Acc@5: 100.0000 (98.3651)  time: 0.3501  data: 0.0008  max mem: 2502
Train: Epoch[2/5]  [3010/3125]  eta: 0:00:40  Lr: 0.001875  Loss: -0.2799  Acc@1: 81.2500 (85.5260)  Acc@5: 100.0000 (98.3581)  time: 0.3515  data: 0.0008  max mem: 2502
Train: Epoch[2/5]  [3020/3125]  eta: 0:00:36  Lr: 0.001875  Loss: -0.2795  Acc@1: 81.2500 (85.5325)  Acc@5: 93.7500 (98.3553)  time: 0.3494  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [3030/3125]  eta: 0:00:33  Lr: 0.001875  Loss: -0.7317  Acc@1: 81.2500 (85.5205)  Acc@5: 100.0000 (98.3524)  time: 0.3488  data: 0.0007  max mem: 2502
Train: Epoch[2/5]  [3040/3125]  eta: 0:00:29  Lr: 0.001875  Loss: 0.1561  Acc@1: 81.2500 (85.5208)  Acc@5: 100.0000 (98.3537)  time: 0.3507  data: 0.0011  max mem: 2502
Train: Epoch[2/5]  [3050/3125]  eta: 0:00:26  Lr: 0.001875  Loss: -0.6722  Acc@1: 81.2500 (85.5211)  Acc@5: 100.0000 (98.3510)  time: 0.3500  data: 0.0010  max mem: 2502
Train: Epoch[2/5]  [3060/3125]  eta: 0:00:22  Lr: 0.001875  Loss: -0.6786  Acc@1: 87.5000 (85.5296)  Acc@5: 100.0000 (98.3543)  time: 0.3500  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [3070/3125]  eta: 0:00:19  Lr: 0.001875  Loss: -0.3524  Acc@1: 87.5000 (85.5239)  Acc@5: 100.0000 (98.3535)  time: 0.3531  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [3080/3125]  eta: 0:00:15  Lr: 0.001875  Loss: -0.3484  Acc@1: 87.5000 (85.5242)  Acc@5: 100.0000 (98.3528)  time: 0.3529  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [3090/3125]  eta: 0:00:12  Lr: 0.001875  Loss: -0.2216  Acc@1: 81.2500 (85.5144)  Acc@5: 100.0000 (98.3541)  time: 0.3496  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [3100/3125]  eta: 0:00:08  Lr: 0.001875  Loss: -0.5572  Acc@1: 87.5000 (85.5148)  Acc@5: 100.0000 (98.3554)  time: 0.3489  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [3110/3125]  eta: 0:00:05  Lr: 0.001875  Loss: -0.5563  Acc@1: 87.5000 (85.5111)  Acc@5: 100.0000 (98.3607)  time: 0.3490  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [3120/3125]  eta: 0:00:01  Lr: 0.001875  Loss: -0.4629  Acc@1: 81.2500 (85.5054)  Acc@5: 100.0000 (98.3619)  time: 0.3500  data: 0.0010  max mem: 2502
Train: Epoch[2/5]  [3124/3125]  eta: 0:00:00  Lr: 0.001875  Loss: -0.6613  Acc@1: 81.2500 (85.5000)  Acc@5: 100.0000 (98.3600)  time: 0.3506  data: 0.0009  max mem: 2502
Train: Epoch[2/5] Total time: 0:18:12 (0.3496 s / it)
{0: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 1: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 2: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 3: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 4: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 5: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 6: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 7: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 8: {0: 0, 1: 0, 2: 100000, 3: 0, 4: 0}, 9: {0: 0, 1: 0, 2: 100000, 3: 0, 4: 0}, 10: {0: 0, 1: 0, 2: 100000, 3: 0, 4: 0}, 11: {0: 0, 1: 0, 2: 100000, 3: 0, 4: 0}, 12: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 13: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 14: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 15: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 16: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 17: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 18: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 19: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}}
Averaged stats: Lr: 0.001875  Loss: -0.6613  Acc@1: 81.2500 (85.5000)  Acc@5: 100.0000 (98.3600)
Train: Epoch[3/5]  [   0/3125]  eta: 0:39:29  Lr: 0.001875  Loss: -0.6670  Acc@1: 93.7500 (93.7500)  Acc@5: 100.0000 (100.0000)  time: 0.7582  data: 0.4118  max mem: 2502
Train: Epoch[3/5]  [  10/3125]  eta: 0:20:03  Lr: 0.001875  Loss: -0.5263  Acc@1: 87.5000 (86.9318)  Acc@5: 100.0000 (98.8636)  time: 0.3863  data: 0.0379  max mem: 2502
Train: Epoch[3/5]  [  20/3125]  eta: 0:19:07  Lr: 0.001875  Loss: -0.7093  Acc@1: 87.5000 (86.0119)  Acc@5: 100.0000 (99.1071)  time: 0.3502  data: 0.0008  max mem: 2502
Train: Epoch[3/5]  [  30/3125]  eta: 0:18:44  Lr: 0.001875  Loss: -0.4592  Acc@1: 87.5000 (86.8952)  Acc@5: 100.0000 (98.9919)  time: 0.3506  data: 0.0009  max mem: 2502
Train: Epoch[3/5]  [  40/3125]  eta: 0:18:29  Lr: 0.001875  Loss: -0.5343  Acc@1: 87.5000 (85.9756)  Acc@5: 100.0000 (98.9329)  time: 0.3491  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [  50/3125]  eta: 0:18:19  Lr: 0.001875  Loss: -0.3029  Acc@1: 81.2500 (85.9069)  Acc@5: 100.0000 (98.8971)  time: 0.3489  data: 0.0006  max mem: 2502
Train: Epoch[3/5]  [  60/3125]  eta: 0:18:11  Lr: 0.001875  Loss: -0.7094  Acc@1: 81.2500 (86.1680)  Acc@5: 100.0000 (98.8730)  time: 0.3493  data: 0.0006  max mem: 2502
Train: Epoch[3/5]  [  70/3125]  eta: 0:18:05  Lr: 0.001875  Loss: -0.7568  Acc@1: 81.2500 (85.8275)  Acc@5: 100.0000 (98.8556)  time: 0.3492  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [  80/3125]  eta: 0:17:59  Lr: 0.001875  Loss: 0.0946  Acc@1: 81.2500 (85.4938)  Acc@5: 100.0000 (98.7654)  time: 0.3490  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [  90/3125]  eta: 0:17:54  Lr: 0.001875  Loss: -0.4003  Acc@1: 81.2500 (85.3709)  Acc@5: 100.0000 (98.8324)  time: 0.3496  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [ 100/3125]  eta: 0:17:48  Lr: 0.001875  Loss: -0.4967  Acc@1: 87.5000 (85.6436)  Acc@5: 100.0000 (98.8243)  time: 0.3487  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [ 110/3125]  eta: 0:17:43  Lr: 0.001875  Loss: -0.4128  Acc@1: 87.5000 (85.8671)  Acc@5: 100.0000 (98.8739)  time: 0.3472  data: 0.0006  max mem: 2502
Train: Epoch[3/5]  [ 120/3125]  eta: 0:17:39  Lr: 0.001875  Loss: -0.5997  Acc@1: 87.5000 (86.0537)  Acc@5: 100.0000 (98.7087)  time: 0.3486  data: 0.0008  max mem: 2502
Train: Epoch[3/5]  [ 130/3125]  eta: 0:17:35  Lr: 0.001875  Loss: -0.8777  Acc@1: 87.5000 (86.3550)  Acc@5: 100.0000 (98.6641)  time: 0.3496  data: 0.0008  max mem: 2502
Train: Epoch[3/5]  [ 140/3125]  eta: 0:17:30  Lr: 0.001875  Loss: -0.7416  Acc@1: 87.5000 (86.4362)  Acc@5: 100.0000 (98.7589)  time: 0.3481  data: 0.0006  max mem: 2502
Train: Epoch[3/5]  [ 150/3125]  eta: 0:17:26  Lr: 0.001875  Loss: -0.4235  Acc@1: 87.5000 (86.5066)  Acc@5: 100.0000 (98.8411)  time: 0.3490  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [ 160/3125]  eta: 0:17:22  Lr: 0.001875  Loss: -0.6783  Acc@1: 87.5000 (86.6071)  Acc@5: 100.0000 (98.7966)  time: 0.3506  data: 0.0006  max mem: 2502
Train: Epoch[3/5]  [ 170/3125]  eta: 0:17:18  Lr: 0.001875  Loss: -0.8775  Acc@1: 87.5000 (86.6594)  Acc@5: 100.0000 (98.7939)  time: 0.3495  data: 0.0007  max mem: 2502
Train: Epoch[3/5]  [ 180/3125]  eta: 0:17:14  Lr: 0.001875  Loss: -0.5411  Acc@1: 87.5000 (86.7058)  Acc@5: 100.0000 (98.8260)  time: 0.3486  data: 0.0007  max mem: 2502
Train: Epoch[3/5]  [ 190/3125]  eta: 0:17:10  Lr: 0.001875  Loss: -0.8545  Acc@1: 87.5000 (86.8128)  Acc@5: 100.0000 (98.8220)  time: 0.3479  data: 0.0006  max mem: 2502
Train: Epoch[3/5]  [ 200/3125]  eta: 0:17:07  Lr: 0.001875  Loss: -0.6328  Acc@1: 87.5000 (86.9403)  Acc@5: 100.0000 (98.7873)  time: 0.3495  data: 0.0007  max mem: 2502
Train: Epoch[3/5]  [ 210/3125]  eta: 0:17:03  Lr: 0.001875  Loss: -0.5210  Acc@1: 87.5000 (87.0853)  Acc@5: 100.0000 (98.8152)  time: 0.3501  data: 0.0007  max mem: 2502
Train: Epoch[3/5]  [ 220/3125]  eta: 0:16:59  Lr: 0.001875  Loss: -0.3740  Acc@1: 87.5000 (87.0475)  Acc@5: 100.0000 (98.8405)  time: 0.3494  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [ 230/3125]  eta: 0:16:55  Lr: 0.001875  Loss: -0.5028  Acc@1: 81.2500 (86.9589)  Acc@5: 100.0000 (98.8366)  time: 0.3489  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [ 240/3125]  eta: 0:16:51  Lr: 0.001875  Loss: -0.8096  Acc@1: 87.5000 (86.9813)  Acc@5: 100.0000 (98.7811)  time: 0.3475  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [ 250/3125]  eta: 0:16:48  Lr: 0.001875  Loss: -0.3079  Acc@1: 87.5000 (86.9771)  Acc@5: 100.0000 (98.7799)  time: 0.3475  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [ 260/3125]  eta: 0:16:44  Lr: 0.001875  Loss: -0.1877  Acc@1: 87.5000 (86.9732)  Acc@5: 100.0000 (98.7308)  time: 0.3488  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [ 270/3125]  eta: 0:16:40  Lr: 0.001875  Loss: -0.3761  Acc@1: 87.5000 (86.9465)  Acc@5: 100.0000 (98.7085)  time: 0.3496  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [ 280/3125]  eta: 0:16:37  Lr: 0.001875  Loss: -0.2734  Acc@1: 87.5000 (86.8995)  Acc@5: 100.0000 (98.7100)  time: 0.3491  data: 0.0009  max mem: 2502
Train: Epoch[3/5]  [ 290/3125]  eta: 0:16:33  Lr: 0.001875  Loss: -0.4764  Acc@1: 87.5000 (86.8557)  Acc@5: 100.0000 (98.7113)  time: 0.3484  data: 0.0010  max mem: 2502
Train: Epoch[3/5]  [ 300/3125]  eta: 0:16:29  Lr: 0.001875  Loss: -0.2681  Acc@1: 81.2500 (86.7110)  Acc@5: 100.0000 (98.6919)  time: 0.3476  data: 0.0006  max mem: 2502
Train: Epoch[3/5]  [ 310/3125]  eta: 0:16:26  Lr: 0.001875  Loss: -0.3337  Acc@1: 81.2500 (86.6359)  Acc@5: 100.0000 (98.6937)  time: 0.3488  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [ 320/3125]  eta: 0:16:22  Lr: 0.001875  Loss: -0.6006  Acc@1: 87.5000 (86.6044)  Acc@5: 100.0000 (98.7150)  time: 0.3492  data: 0.0006  max mem: 2502
Train: Epoch[3/5]  [ 330/3125]  eta: 0:16:18  Lr: 0.001875  Loss: -0.5820  Acc@1: 87.5000 (86.6503)  Acc@5: 100.0000 (98.7160)  time: 0.3480  data: 0.0006  max mem: 2502
Train: Epoch[3/5]  [ 340/3125]  eta: 0:16:15  Lr: 0.001875  Loss: -0.4377  Acc@1: 87.5000 (86.5836)  Acc@5: 100.0000 (98.7353)  time: 0.3487  data: 0.0006  max mem: 2502
Train: Epoch[3/5]  [ 350/3125]  eta: 0:16:11  Lr: 0.001875  Loss: -0.3335  Acc@1: 81.2500 (86.4138)  Acc@5: 100.0000 (98.7179)  time: 0.3504  data: 0.0006  max mem: 2502
Train: Epoch[3/5]  [ 360/3125]  eta: 0:16:08  Lr: 0.001875  Loss: -0.4716  Acc@1: 81.2500 (86.3573)  Acc@5: 100.0000 (98.7188)  time: 0.3518  data: 0.0008  max mem: 2502
Train: Epoch[3/5]  [ 370/3125]  eta: 0:16:04  Lr: 0.001875  Loss: -0.1160  Acc@1: 87.5000 (86.4892)  Acc@5: 100.0000 (98.7028)  time: 0.3501  data: 0.0007  max mem: 2502
Train: Epoch[3/5]  [ 380/3125]  eta: 0:16:01  Lr: 0.001875  Loss: -0.7536  Acc@1: 87.5000 (86.5157)  Acc@5: 100.0000 (98.7205)  time: 0.3481  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [ 390/3125]  eta: 0:15:57  Lr: 0.001875  Loss: -0.4580  Acc@1: 87.5000 (86.4450)  Acc@5: 100.0000 (98.7532)  time: 0.3484  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [ 400/3125]  eta: 0:15:53  Lr: 0.001875  Loss: -0.4368  Acc@1: 81.2500 (86.3622)  Acc@5: 100.0000 (98.7375)  time: 0.3473  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [ 410/3125]  eta: 0:15:50  Lr: 0.001875  Loss: -0.7320  Acc@1: 87.5000 (86.3747)  Acc@5: 100.0000 (98.7074)  time: 0.3479  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [ 420/3125]  eta: 0:15:46  Lr: 0.001875  Loss: -0.4502  Acc@1: 87.5000 (86.4014)  Acc@5: 100.0000 (98.7381)  time: 0.3491  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [ 430/3125]  eta: 0:15:42  Lr: 0.001875  Loss: -0.4971  Acc@1: 87.5000 (86.4124)  Acc@5: 100.0000 (98.7094)  time: 0.3483  data: 0.0006  max mem: 2502
Train: Epoch[3/5]  [ 440/3125]  eta: 0:15:39  Lr: 0.001875  Loss: -0.6375  Acc@1: 87.5000 (86.4229)  Acc@5: 100.0000 (98.7387)  time: 0.3488  data: 0.0006  max mem: 2502
Train: Epoch[3/5]  [ 450/3125]  eta: 0:15:35  Lr: 0.001875  Loss: -0.5160  Acc@1: 87.5000 (86.3498)  Acc@5: 100.0000 (98.7528)  time: 0.3494  data: 0.0008  max mem: 2502
Train: Epoch[3/5]  [ 460/3125]  eta: 0:15:32  Lr: 0.001875  Loss: -0.8193  Acc@1: 87.5000 (86.4290)  Acc@5: 100.0000 (98.7527)  time: 0.3499  data: 0.0008  max mem: 2502
Train: Epoch[3/5]  [ 470/3125]  eta: 0:15:28  Lr: 0.001875  Loss: -0.4816  Acc@1: 87.5000 (86.4517)  Acc@5: 100.0000 (98.7659)  time: 0.3500  data: 0.0006  max mem: 2502
Train: Epoch[3/5]  [ 480/3125]  eta: 0:15:25  Lr: 0.001875  Loss: -0.2009  Acc@1: 87.5000 (86.4475)  Acc@5: 100.0000 (98.7396)  time: 0.3499  data: 0.0011  max mem: 2502
Train: Epoch[3/5]  [ 490/3125]  eta: 0:15:21  Lr: 0.001875  Loss: -0.4980  Acc@1: 87.5000 (86.4944)  Acc@5: 100.0000 (98.7525)  time: 0.3503  data: 0.0011  max mem: 2502
Train: Epoch[3/5]  [ 500/3125]  eta: 0:15:18  Lr: 0.001875  Loss: -0.5794  Acc@1: 87.5000 (86.4646)  Acc@5: 100.0000 (98.7650)  time: 0.3503  data: 0.0008  max mem: 2502
Train: Epoch[3/5]  [ 510/3125]  eta: 0:15:15  Lr: 0.001875  Loss: -0.6775  Acc@1: 87.5000 (86.5338)  Acc@5: 100.0000 (98.7769)  time: 0.3506  data: 0.0009  max mem: 2502
Train: Epoch[3/5]  [ 520/3125]  eta: 0:15:11  Lr: 0.001875  Loss: -0.4752  Acc@1: 93.7500 (86.6123)  Acc@5: 100.0000 (98.7764)  time: 0.3531  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [ 530/3125]  eta: 0:15:08  Lr: 0.001875  Loss: -0.2252  Acc@1: 93.7500 (86.5819)  Acc@5: 100.0000 (98.7524)  time: 0.3526  data: 0.0013  max mem: 2502
Train: Epoch[3/5]  [ 540/3125]  eta: 0:15:04  Lr: 0.001875  Loss: -0.5000  Acc@1: 87.5000 (86.5411)  Acc@5: 100.0000 (98.7292)  time: 0.3495  data: 0.0013  max mem: 2502
Train: Epoch[3/5]  [ 550/3125]  eta: 0:15:01  Lr: 0.001875  Loss: -0.5134  Acc@1: 87.5000 (86.5358)  Acc@5: 100.0000 (98.7409)  time: 0.3500  data: 0.0011  max mem: 2502
Train: Epoch[3/5]  [ 560/3125]  eta: 0:14:57  Lr: 0.001875  Loss: -0.2909  Acc@1: 81.2500 (86.4639)  Acc@5: 100.0000 (98.7299)  time: 0.3509  data: 0.0015  max mem: 2502
Train: Epoch[3/5]  [ 570/3125]  eta: 0:14:54  Lr: 0.001875  Loss: -0.2986  Acc@1: 87.5000 (86.5368)  Acc@5: 100.0000 (98.7412)  time: 0.3500  data: 0.0010  max mem: 2502
Train: Epoch[3/5]  [ 580/3125]  eta: 0:14:50  Lr: 0.001875  Loss: -0.6650  Acc@1: 87.5000 (86.5318)  Acc@5: 100.0000 (98.7522)  time: 0.3491  data: 0.0006  max mem: 2502
Train: Epoch[3/5]  [ 590/3125]  eta: 0:14:47  Lr: 0.001875  Loss: -0.7518  Acc@1: 87.5000 (86.5376)  Acc@5: 100.0000 (98.7415)  time: 0.3488  data: 0.0006  max mem: 2502
Train: Epoch[3/5]  [ 600/3125]  eta: 0:14:43  Lr: 0.001875  Loss: -0.5319  Acc@1: 87.5000 (86.5641)  Acc@5: 100.0000 (98.7417)  time: 0.3493  data: 0.0007  max mem: 2502
Train: Epoch[3/5]  [ 610/3125]  eta: 0:14:40  Lr: 0.001875  Loss: -0.9262  Acc@1: 87.5000 (86.5998)  Acc@5: 100.0000 (98.7520)  time: 0.3496  data: 0.0006  max mem: 2502
Train: Epoch[3/5]  [ 620/3125]  eta: 0:14:36  Lr: 0.001875  Loss: -0.6272  Acc@1: 87.5000 (86.6345)  Acc@5: 100.0000 (98.7419)  time: 0.3499  data: 0.0006  max mem: 2502
Train: Epoch[3/5]  [ 630/3125]  eta: 0:14:33  Lr: 0.001875  Loss: -0.3140  Acc@1: 87.5000 (86.6086)  Acc@5: 100.0000 (98.7322)  time: 0.3497  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [ 640/3125]  eta: 0:14:29  Lr: 0.001875  Loss: 0.2614  Acc@1: 87.5000 (86.5640)  Acc@5: 100.0000 (98.7032)  time: 0.3495  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [ 650/3125]  eta: 0:14:26  Lr: 0.001875  Loss: -0.7934  Acc@1: 87.5000 (86.5783)  Acc@5: 100.0000 (98.7231)  time: 0.3492  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [ 660/3125]  eta: 0:14:22  Lr: 0.001875  Loss: -0.0908  Acc@1: 87.5000 (86.5639)  Acc@5: 100.0000 (98.7046)  time: 0.3499  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [ 670/3125]  eta: 0:14:19  Lr: 0.001875  Loss: -0.7568  Acc@1: 81.2500 (86.5313)  Acc@5: 100.0000 (98.7053)  time: 0.3506  data: 0.0009  max mem: 2502
Train: Epoch[3/5]  [ 680/3125]  eta: 0:14:15  Lr: 0.001875  Loss: -0.2724  Acc@1: 81.2500 (86.5088)  Acc@5: 100.0000 (98.6876)  time: 0.3512  data: 0.0024  max mem: 2502
Train: Epoch[3/5]  [ 690/3125]  eta: 0:14:12  Lr: 0.001875  Loss: -0.3422  Acc@1: 81.2500 (86.5322)  Acc@5: 100.0000 (98.6975)  time: 0.3503  data: 0.0020  max mem: 2502
Train: Epoch[3/5]  [ 700/3125]  eta: 0:14:08  Lr: 0.001875  Loss: -0.6045  Acc@1: 87.5000 (86.5014)  Acc@5: 100.0000 (98.7072)  time: 0.3485  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [ 710/3125]  eta: 0:14:05  Lr: 0.001875  Loss: -0.4758  Acc@1: 87.5000 (86.4891)  Acc@5: 100.0000 (98.7166)  time: 0.3489  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [ 720/3125]  eta: 0:14:01  Lr: 0.001875  Loss: -0.4005  Acc@1: 87.5000 (86.5118)  Acc@5: 100.0000 (98.7171)  time: 0.3489  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [ 730/3125]  eta: 0:13:58  Lr: 0.001875  Loss: -0.8050  Acc@1: 93.7500 (86.5766)  Acc@5: 100.0000 (98.7090)  time: 0.3509  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [ 740/3125]  eta: 0:13:54  Lr: 0.001875  Loss: -0.4860  Acc@1: 87.5000 (86.5806)  Acc@5: 100.0000 (98.7264)  time: 0.3518  data: 0.0011  max mem: 2502
Train: Epoch[3/5]  [ 750/3125]  eta: 0:13:51  Lr: 0.001875  Loss: -0.7271  Acc@1: 87.5000 (86.6012)  Acc@5: 100.0000 (98.7267)  time: 0.3515  data: 0.0013  max mem: 2502
Train: Epoch[3/5]  [ 760/3125]  eta: 0:13:47  Lr: 0.001875  Loss: -0.5291  Acc@1: 87.5000 (86.5309)  Acc@5: 100.0000 (98.7106)  time: 0.3512  data: 0.0008  max mem: 2502
Train: Epoch[3/5]  [ 770/3125]  eta: 0:13:44  Lr: 0.001875  Loss: -0.6136  Acc@1: 81.2500 (86.4948)  Acc@5: 100.0000 (98.7192)  time: 0.3493  data: 0.0006  max mem: 2502
Train: Epoch[3/5]  [ 780/3125]  eta: 0:13:40  Lr: 0.001875  Loss: -0.4567  Acc@1: 81.2500 (86.4677)  Acc@5: 100.0000 (98.7276)  time: 0.3485  data: 0.0006  max mem: 2502
Train: Epoch[3/5]  [ 790/3125]  eta: 0:13:37  Lr: 0.001875  Loss: -0.6436  Acc@1: 87.5000 (86.5281)  Acc@5: 100.0000 (98.7358)  time: 0.3487  data: 0.0006  max mem: 2502
Train: Epoch[3/5]  [ 800/3125]  eta: 0:13:33  Lr: 0.001875  Loss: -0.8959  Acc@1: 93.7500 (86.5403)  Acc@5: 100.0000 (98.7203)  time: 0.3497  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [ 810/3125]  eta: 0:13:30  Lr: 0.001875  Loss: -0.7808  Acc@1: 87.5000 (86.5367)  Acc@5: 100.0000 (98.7130)  time: 0.3510  data: 0.0006  max mem: 2502
Train: Epoch[3/5]  [ 820/3125]  eta: 0:13:26  Lr: 0.001875  Loss: -0.4891  Acc@1: 87.5000 (86.5332)  Acc@5: 100.0000 (98.7211)  time: 0.3505  data: 0.0006  max mem: 2502
Train: Epoch[3/5]  [ 830/3125]  eta: 0:13:23  Lr: 0.001875  Loss: -0.4568  Acc@1: 87.5000 (86.5824)  Acc@5: 100.0000 (98.7214)  time: 0.3522  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [ 840/3125]  eta: 0:13:19  Lr: 0.001875  Loss: -0.3646  Acc@1: 87.5000 (86.6008)  Acc@5: 100.0000 (98.7143)  time: 0.3517  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [ 850/3125]  eta: 0:13:16  Lr: 0.001875  Loss: -0.4465  Acc@1: 87.5000 (86.5893)  Acc@5: 100.0000 (98.7221)  time: 0.3499  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [ 860/3125]  eta: 0:13:12  Lr: 0.001875  Loss: -0.5793  Acc@1: 87.5000 (86.5926)  Acc@5: 100.0000 (98.7297)  time: 0.3498  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [ 870/3125]  eta: 0:13:09  Lr: 0.001875  Loss: -0.6153  Acc@1: 81.2500 (86.5959)  Acc@5: 100.0000 (98.7371)  time: 0.3500  data: 0.0013  max mem: 2502
Train: Epoch[3/5]  [ 880/3125]  eta: 0:13:05  Lr: 0.001875  Loss: -0.7659  Acc@1: 87.5000 (86.6061)  Acc@5: 100.0000 (98.7301)  time: 0.3495  data: 0.0013  max mem: 2502
Train: Epoch[3/5]  [ 890/3125]  eta: 0:13:02  Lr: 0.001875  Loss: -0.5107  Acc@1: 87.5000 (86.6162)  Acc@5: 100.0000 (98.7233)  time: 0.3479  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [ 900/3125]  eta: 0:12:58  Lr: 0.001875  Loss: -0.4550  Acc@1: 87.5000 (86.6398)  Acc@5: 100.0000 (98.7306)  time: 0.3491  data: 0.0006  max mem: 2502
Train: Epoch[3/5]  [ 910/3125]  eta: 0:12:55  Lr: 0.001875  Loss: -0.5449  Acc@1: 87.5000 (86.6493)  Acc@5: 100.0000 (98.7102)  time: 0.3501  data: 0.0008  max mem: 2502
Train: Epoch[3/5]  [ 920/3125]  eta: 0:12:51  Lr: 0.001875  Loss: -0.1785  Acc@1: 87.5000 (86.6517)  Acc@5: 100.0000 (98.7106)  time: 0.3497  data: 0.0008  max mem: 2502
Train: Epoch[3/5]  [ 930/3125]  eta: 0:12:48  Lr: 0.001875  Loss: -0.8263  Acc@1: 87.5000 (86.6810)  Acc@5: 100.0000 (98.6976)  time: 0.3492  data: 0.0006  max mem: 2502
Train: Epoch[3/5]  [ 940/3125]  eta: 0:12:44  Lr: 0.001875  Loss: -0.2318  Acc@1: 87.5000 (86.6432)  Acc@5: 100.0000 (98.6849)  time: 0.3485  data: 0.0006  max mem: 2502
Train: Epoch[3/5]  [ 950/3125]  eta: 0:12:41  Lr: 0.001875  Loss: -0.7650  Acc@1: 81.2500 (86.6259)  Acc@5: 100.0000 (98.6725)  time: 0.3491  data: 0.0006  max mem: 2502
Train: Epoch[3/5]  [ 960/3125]  eta: 0:12:37  Lr: 0.001875  Loss: -0.3287  Acc@1: 81.2500 (86.6025)  Acc@5: 100.0000 (98.6733)  time: 0.3495  data: 0.0006  max mem: 2502
Train: Epoch[3/5]  [ 970/3125]  eta: 0:12:34  Lr: 0.001875  Loss: -0.6572  Acc@1: 87.5000 (86.6311)  Acc@5: 100.0000 (98.6740)  time: 0.3488  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [ 980/3125]  eta: 0:12:30  Lr: 0.001875  Loss: -0.4088  Acc@1: 87.5000 (86.6335)  Acc@5: 100.0000 (98.6621)  time: 0.3487  data: 0.0006  max mem: 2502
Train: Epoch[3/5]  [ 990/3125]  eta: 0:12:27  Lr: 0.001875  Loss: -0.8741  Acc@1: 87.5000 (86.6171)  Acc@5: 100.0000 (98.6567)  time: 0.3485  data: 0.0006  max mem: 2502
Train: Epoch[3/5]  [1000/3125]  eta: 0:12:23  Lr: 0.001875  Loss: -0.5289  Acc@1: 87.5000 (86.6633)  Acc@5: 100.0000 (98.6451)  time: 0.3484  data: 0.0006  max mem: 2502
Train: Epoch[3/5]  [1010/3125]  eta: 0:12:19  Lr: 0.001875  Loss: -0.1651  Acc@1: 87.5000 (86.6036)  Acc@5: 100.0000 (98.6461)  time: 0.3489  data: 0.0006  max mem: 2502
Train: Epoch[3/5]  [1020/3125]  eta: 0:12:16  Lr: 0.001875  Loss: -0.1903  Acc@1: 81.2500 (86.5206)  Acc@5: 100.0000 (98.6288)  time: 0.3487  data: 0.0006  max mem: 2502
Train: Epoch[3/5]  [1030/3125]  eta: 0:12:12  Lr: 0.001875  Loss: -0.3650  Acc@1: 87.5000 (86.5664)  Acc@5: 100.0000 (98.6300)  time: 0.3482  data: 0.0008  max mem: 2502
Train: Epoch[3/5]  [1040/3125]  eta: 0:12:09  Lr: 0.001875  Loss: -0.6069  Acc@1: 87.5000 (86.5754)  Acc@5: 100.0000 (98.6431)  time: 0.3482  data: 0.0007  max mem: 2502
Train: Epoch[3/5]  [1050/3125]  eta: 0:12:05  Lr: 0.001875  Loss: -0.5793  Acc@1: 87.5000 (86.6020)  Acc@5: 100.0000 (98.6501)  time: 0.3496  data: 0.0006  max mem: 2502
Train: Epoch[3/5]  [1060/3125]  eta: 0:12:02  Lr: 0.001875  Loss: -0.5024  Acc@1: 87.5000 (86.6223)  Acc@5: 100.0000 (98.6510)  time: 0.3502  data: 0.0006  max mem: 2502
Train: Epoch[3/5]  [1070/3125]  eta: 0:11:58  Lr: 0.001875  Loss: -0.5009  Acc@1: 87.5000 (86.6130)  Acc@5: 100.0000 (98.6578)  time: 0.3486  data: 0.0006  max mem: 2502
Train: Epoch[3/5]  [1080/3125]  eta: 0:11:55  Lr: 0.001875  Loss: -0.3708  Acc@1: 87.5000 (86.6212)  Acc@5: 100.0000 (98.6471)  time: 0.3482  data: 0.0006  max mem: 2502
Train: Epoch[3/5]  [1090/3125]  eta: 0:11:51  Lr: 0.001875  Loss: -0.6109  Acc@1: 87.5000 (86.6063)  Acc@5: 100.0000 (98.6538)  time: 0.3474  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [1100/3125]  eta: 0:11:48  Lr: 0.001875  Loss: -0.7626  Acc@1: 87.5000 (86.6144)  Acc@5: 100.0000 (98.6603)  time: 0.3478  data: 0.0006  max mem: 2502
Train: Epoch[3/5]  [1110/3125]  eta: 0:11:44  Lr: 0.001875  Loss: -0.8979  Acc@1: 87.5000 (86.6055)  Acc@5: 100.0000 (98.6611)  time: 0.3491  data: 0.0007  max mem: 2502
Train: Epoch[3/5]  [1120/3125]  eta: 0:11:41  Lr: 0.001875  Loss: -0.5776  Acc@1: 87.5000 (86.6191)  Acc@5: 100.0000 (98.6619)  time: 0.3495  data: 0.0007  max mem: 2502
Train: Epoch[3/5]  [1130/3125]  eta: 0:11:37  Lr: 0.001875  Loss: -0.3589  Acc@1: 87.5000 (86.6435)  Acc@5: 100.0000 (98.6682)  time: 0.3495  data: 0.0007  max mem: 2502
Train: Epoch[3/5]  [1140/3125]  eta: 0:11:34  Lr: 0.001875  Loss: 0.0926  Acc@1: 87.5000 (86.6236)  Acc@5: 100.0000 (98.6635)  time: 0.3485  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [1150/3125]  eta: 0:11:30  Lr: 0.001875  Loss: -0.7590  Acc@1: 87.5000 (86.6421)  Acc@5: 100.0000 (98.6533)  time: 0.3489  data: 0.0009  max mem: 2502
Train: Epoch[3/5]  [1160/3125]  eta: 0:11:27  Lr: 0.001875  Loss: -0.3665  Acc@1: 87.5000 (86.6225)  Acc@5: 100.0000 (98.6542)  time: 0.3490  data: 0.0009  max mem: 2502
Train: Epoch[3/5]  [1170/3125]  eta: 0:11:23  Lr: 0.001875  Loss: -0.4475  Acc@1: 87.5000 (86.6140)  Acc@5: 100.0000 (98.6550)  time: 0.3482  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [1180/3125]  eta: 0:11:20  Lr: 0.001875  Loss: -0.6892  Acc@1: 87.5000 (86.6427)  Acc@5: 100.0000 (98.6558)  time: 0.3498  data: 0.0006  max mem: 2502
Train: Epoch[3/5]  [1190/3125]  eta: 0:11:16  Lr: 0.001875  Loss: -0.5410  Acc@1: 87.5000 (86.6289)  Acc@5: 100.0000 (98.6566)  time: 0.3499  data: 0.0007  max mem: 2502
Train: Epoch[3/5]  [1200/3125]  eta: 0:11:13  Lr: 0.001875  Loss: -0.7273  Acc@1: 87.5000 (86.6257)  Acc@5: 100.0000 (98.6470)  time: 0.3492  data: 0.0008  max mem: 2502
Train: Epoch[3/5]  [1210/3125]  eta: 0:11:09  Lr: 0.001875  Loss: -0.7391  Acc@1: 87.5000 (86.5762)  Acc@5: 100.0000 (98.6427)  time: 0.3494  data: 0.0007  max mem: 2502
Train: Epoch[3/5]  [1220/3125]  eta: 0:11:06  Lr: 0.001875  Loss: -0.5773  Acc@1: 87.5000 (86.5581)  Acc@5: 100.0000 (98.6486)  time: 0.3492  data: 0.0011  max mem: 2502
Train: Epoch[3/5]  [1230/3125]  eta: 0:11:02  Lr: 0.001875  Loss: -0.6136  Acc@1: 87.5000 (86.6013)  Acc@5: 100.0000 (98.6596)  time: 0.3488  data: 0.0012  max mem: 2502
Train: Epoch[3/5]  [1240/3125]  eta: 0:10:59  Lr: 0.001875  Loss: -0.7546  Acc@1: 87.5000 (86.5683)  Acc@5: 100.0000 (98.6654)  time: 0.3481  data: 0.0006  max mem: 2502
Train: Epoch[3/5]  [1250/3125]  eta: 0:10:55  Lr: 0.001875  Loss: -0.6337  Acc@1: 87.5000 (86.5757)  Acc@5: 100.0000 (98.6661)  time: 0.3505  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [1260/3125]  eta: 0:10:52  Lr: 0.001875  Loss: -0.2656  Acc@1: 87.5000 (86.5781)  Acc@5: 100.0000 (98.6667)  time: 0.3514  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [1270/3125]  eta: 0:10:48  Lr: 0.001875  Loss: -0.4970  Acc@1: 87.5000 (86.6100)  Acc@5: 100.0000 (98.6723)  time: 0.3494  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [1280/3125]  eta: 0:10:45  Lr: 0.001875  Loss: -0.4011  Acc@1: 87.5000 (86.5730)  Acc@5: 100.0000 (98.6680)  time: 0.3512  data: 0.0006  max mem: 2502
Train: Epoch[3/5]  [1290/3125]  eta: 0:10:41  Lr: 0.001875  Loss: -0.5638  Acc@1: 87.5000 (86.6044)  Acc@5: 100.0000 (98.6687)  time: 0.3510  data: 0.0007  max mem: 2502
Train: Epoch[3/5]  [1300/3125]  eta: 0:10:38  Lr: 0.001875  Loss: -0.4180  Acc@1: 87.5000 (86.6017)  Acc@5: 100.0000 (98.6693)  time: 0.3485  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [1310/3125]  eta: 0:10:34  Lr: 0.001875  Loss: -0.4736  Acc@1: 87.5000 (86.5894)  Acc@5: 100.0000 (98.6747)  time: 0.3490  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [1320/3125]  eta: 0:10:31  Lr: 0.001875  Loss: -0.2093  Acc@1: 81.2500 (86.5821)  Acc@5: 100.0000 (98.6752)  time: 0.3499  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [1330/3125]  eta: 0:10:27  Lr: 0.001875  Loss: -0.6887  Acc@1: 81.2500 (86.5374)  Acc@5: 100.0000 (98.6758)  time: 0.3496  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [1340/3125]  eta: 0:10:24  Lr: 0.001875  Loss: -0.1696  Acc@1: 87.5000 (86.5306)  Acc@5: 100.0000 (98.6670)  time: 0.3484  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [1350/3125]  eta: 0:10:20  Lr: 0.001875  Loss: -0.1061  Acc@1: 87.5000 (86.5239)  Acc@5: 100.0000 (98.6584)  time: 0.3476  data: 0.0006  max mem: 2502
Train: Epoch[3/5]  [1360/3125]  eta: 0:10:17  Lr: 0.001875  Loss: -0.6951  Acc@1: 87.5000 (86.5494)  Acc@5: 100.0000 (98.6637)  time: 0.3481  data: 0.0007  max mem: 2502
Train: Epoch[3/5]  [1370/3125]  eta: 0:10:13  Lr: 0.001875  Loss: -0.0612  Acc@1: 87.5000 (86.5108)  Acc@5: 100.0000 (98.6506)  time: 0.3502  data: 0.0019  max mem: 2502
Train: Epoch[3/5]  [1380/3125]  eta: 0:10:10  Lr: 0.001875  Loss: -0.1816  Acc@1: 87.5000 (86.5134)  Acc@5: 100.0000 (98.6513)  time: 0.3522  data: 0.0028  max mem: 2502
Train: Epoch[3/5]  [1390/3125]  eta: 0:10:06  Lr: 0.001875  Loss: -0.1517  Acc@1: 87.5000 (86.5115)  Acc@5: 100.0000 (98.6565)  time: 0.3510  data: 0.0016  max mem: 2502
Train: Epoch[3/5]  [1400/3125]  eta: 0:10:03  Lr: 0.001875  Loss: -0.3817  Acc@1: 87.5000 (86.5007)  Acc@5: 100.0000 (98.6438)  time: 0.3506  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [1410/3125]  eta: 0:09:59  Lr: 0.001875  Loss: -0.6376  Acc@1: 87.5000 (86.4812)  Acc@5: 100.0000 (98.6401)  time: 0.3507  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [1420/3125]  eta: 0:09:56  Lr: 0.001875  Loss: -0.4136  Acc@1: 87.5000 (86.4752)  Acc@5: 100.0000 (98.6365)  time: 0.3487  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [1430/3125]  eta: 0:09:52  Lr: 0.001875  Loss: -0.3545  Acc@1: 81.2500 (86.4212)  Acc@5: 100.0000 (98.6417)  time: 0.3493  data: 0.0006  max mem: 2502
Train: Epoch[3/5]  [1440/3125]  eta: 0:09:49  Lr: 0.001875  Loss: -0.7607  Acc@1: 81.2500 (86.4027)  Acc@5: 100.0000 (98.6338)  time: 0.3503  data: 0.0006  max mem: 2502
Train: Epoch[3/5]  [1450/3125]  eta: 0:09:45  Lr: 0.001875  Loss: -0.2091  Acc@1: 81.2500 (86.3930)  Acc@5: 100.0000 (98.6346)  time: 0.3500  data: 0.0006  max mem: 2502
Train: Epoch[3/5]  [1460/3125]  eta: 0:09:42  Lr: 0.001875  Loss: -0.3132  Acc@1: 87.5000 (86.4006)  Acc@5: 100.0000 (98.6225)  time: 0.3495  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [1470/3125]  eta: 0:09:38  Lr: 0.001875  Loss: -0.5891  Acc@1: 87.5000 (86.4208)  Acc@5: 100.0000 (98.6276)  time: 0.3489  data: 0.0006  max mem: 2502
Train: Epoch[3/5]  [1480/3125]  eta: 0:09:35  Lr: 0.001875  Loss: -0.4632  Acc@1: 87.5000 (86.3943)  Acc@5: 100.0000 (98.6327)  time: 0.3489  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [1490/3125]  eta: 0:09:31  Lr: 0.001875  Loss: -0.7179  Acc@1: 81.2500 (86.3766)  Acc@5: 100.0000 (98.6377)  time: 0.3496  data: 0.0006  max mem: 2502
Train: Epoch[3/5]  [1500/3125]  eta: 0:09:28  Lr: 0.001875  Loss: -0.3361  Acc@1: 81.2500 (86.3716)  Acc@5: 100.0000 (98.6301)  time: 0.3502  data: 0.0012  max mem: 2502
Train: Epoch[3/5]  [1510/3125]  eta: 0:09:24  Lr: 0.001875  Loss: -0.3104  Acc@1: 81.2500 (86.3501)  Acc@5: 100.0000 (98.6267)  time: 0.3496  data: 0.0012  max mem: 2502
Train: Epoch[3/5]  [1520/3125]  eta: 0:09:21  Lr: 0.001875  Loss: -0.7745  Acc@1: 87.5000 (86.3741)  Acc@5: 100.0000 (98.6317)  time: 0.3491  data: 0.0009  max mem: 2502
Train: Epoch[3/5]  [1530/3125]  eta: 0:09:17  Lr: 0.001875  Loss: -0.4979  Acc@1: 87.5000 (86.4019)  Acc@5: 100.0000 (98.6324)  time: 0.3501  data: 0.0011  max mem: 2502
Train: Epoch[3/5]  [1540/3125]  eta: 0:09:14  Lr: 0.001875  Loss: -0.4510  Acc@1: 87.5000 (86.4212)  Acc@5: 100.0000 (98.6332)  time: 0.3498  data: 0.0008  max mem: 2502
Train: Epoch[3/5]  [1550/3125]  eta: 0:09:10  Lr: 0.001875  Loss: -0.7557  Acc@1: 87.5000 (86.4321)  Acc@5: 100.0000 (98.6420)  time: 0.3488  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [1560/3125]  eta: 0:09:07  Lr: 0.001875  Loss: -0.0098  Acc@1: 87.5000 (86.3909)  Acc@5: 100.0000 (98.6467)  time: 0.3489  data: 0.0006  max mem: 2502
Train: Epoch[3/5]  [1570/3125]  eta: 0:09:03  Lr: 0.001875  Loss: -0.4029  Acc@1: 81.2500 (86.3741)  Acc@5: 100.0000 (98.6394)  time: 0.3487  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [1580/3125]  eta: 0:09:00  Lr: 0.001875  Loss: -0.7507  Acc@1: 81.2500 (86.3615)  Acc@5: 100.0000 (98.6361)  time: 0.3489  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [1590/3125]  eta: 0:08:56  Lr: 0.001875  Loss: -0.2828  Acc@1: 81.2500 (86.3372)  Acc@5: 100.0000 (98.6290)  time: 0.3490  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [1600/3125]  eta: 0:08:53  Lr: 0.001875  Loss: -0.4391  Acc@1: 87.5000 (86.3562)  Acc@5: 100.0000 (98.6298)  time: 0.3483  data: 0.0006  max mem: 2502
Train: Epoch[3/5]  [1610/3125]  eta: 0:08:49  Lr: 0.001875  Loss: -0.5706  Acc@1: 87.5000 (86.3594)  Acc@5: 100.0000 (98.6266)  time: 0.3480  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [1620/3125]  eta: 0:08:46  Lr: 0.001875  Loss: -0.7643  Acc@1: 87.5000 (86.3703)  Acc@5: 100.0000 (98.6274)  time: 0.3485  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [1630/3125]  eta: 0:08:42  Lr: 0.001875  Loss: -0.2337  Acc@1: 87.5000 (86.3657)  Acc@5: 100.0000 (98.6281)  time: 0.3506  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [1640/3125]  eta: 0:08:39  Lr: 0.001875  Loss: -0.5361  Acc@1: 81.2500 (86.3498)  Acc@5: 100.0000 (98.6251)  time: 0.3515  data: 0.0009  max mem: 2502
Train: Epoch[3/5]  [1650/3125]  eta: 0:08:35  Lr: 0.001875  Loss: -0.2584  Acc@1: 81.2500 (86.3340)  Acc@5: 100.0000 (98.6183)  time: 0.3499  data: 0.0009  max mem: 2502
Train: Epoch[3/5]  [1660/3125]  eta: 0:08:32  Lr: 0.001875  Loss: -0.4676  Acc@1: 87.5000 (86.3411)  Acc@5: 100.0000 (98.6228)  time: 0.3496  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [1670/3125]  eta: 0:08:28  Lr: 0.001875  Loss: 0.4152  Acc@1: 87.5000 (86.3555)  Acc@5: 100.0000 (98.6124)  time: 0.3515  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [1680/3125]  eta: 0:08:25  Lr: 0.001875  Loss: -0.7455  Acc@1: 87.5000 (86.3511)  Acc@5: 100.0000 (98.6020)  time: 0.3517  data: 0.0006  max mem: 2502
Train: Epoch[3/5]  [1690/3125]  eta: 0:08:21  Lr: 0.001875  Loss: -0.5403  Acc@1: 87.5000 (86.3468)  Acc@5: 100.0000 (98.6029)  time: 0.3505  data: 0.0007  max mem: 2502
Train: Epoch[3/5]  [1700/3125]  eta: 0:08:18  Lr: 0.001875  Loss: -0.3516  Acc@1: 81.2500 (86.3499)  Acc@5: 100.0000 (98.6001)  time: 0.3503  data: 0.0013  max mem: 2502
Train: Epoch[3/5]  [1710/3125]  eta: 0:08:14  Lr: 0.001875  Loss: -0.3596  Acc@1: 87.5000 (86.3494)  Acc@5: 100.0000 (98.5973)  time: 0.3492  data: 0.0013  max mem: 2502
Train: Epoch[3/5]  [1720/3125]  eta: 0:08:11  Lr: 0.001875  Loss: -0.6573  Acc@1: 87.5000 (86.3633)  Acc@5: 100.0000 (98.6018)  time: 0.3492  data: 0.0006  max mem: 2502
Train: Epoch[3/5]  [1730/3125]  eta: 0:08:07  Lr: 0.001875  Loss: -0.5045  Acc@1: 87.5000 (86.3807)  Acc@5: 100.0000 (98.5991)  time: 0.3498  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [1740/3125]  eta: 0:08:04  Lr: 0.001875  Loss: 0.0553  Acc@1: 87.5000 (86.3835)  Acc@5: 100.0000 (98.5964)  time: 0.3489  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [1750/3125]  eta: 0:08:00  Lr: 0.001875  Loss: -0.1225  Acc@1: 81.2500 (86.3756)  Acc@5: 100.0000 (98.5865)  time: 0.3486  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [1760/3125]  eta: 0:07:57  Lr: 0.001875  Loss: -0.6775  Acc@1: 81.2500 (86.3501)  Acc@5: 100.0000 (98.5804)  time: 0.3485  data: 0.0010  max mem: 2502
Train: Epoch[3/5]  [1770/3125]  eta: 0:07:53  Lr: 0.001875  Loss: -0.6391  Acc@1: 81.2500 (86.3425)  Acc@5: 100.0000 (98.5848)  time: 0.3480  data: 0.0010  max mem: 2502
Train: Epoch[3/5]  [1780/3125]  eta: 0:07:50  Lr: 0.001875  Loss: -0.3613  Acc@1: 87.5000 (86.3419)  Acc@5: 100.0000 (98.5787)  time: 0.3481  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [1790/3125]  eta: 0:07:46  Lr: 0.001875  Loss: -0.5078  Acc@1: 87.5000 (86.3554)  Acc@5: 100.0000 (98.5832)  time: 0.3503  data: 0.0017  max mem: 2502
Train: Epoch[3/5]  [1800/3125]  eta: 0:07:43  Lr: 0.001875  Loss: -0.7416  Acc@1: 87.5000 (86.3687)  Acc@5: 100.0000 (98.5841)  time: 0.3511  data: 0.0017  max mem: 2502
Train: Epoch[3/5]  [1810/3125]  eta: 0:07:39  Lr: 0.001875  Loss: -0.2499  Acc@1: 87.5000 (86.3611)  Acc@5: 100.0000 (98.5816)  time: 0.3488  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [1820/3125]  eta: 0:07:36  Lr: 0.001875  Loss: -0.3482  Acc@1: 81.2500 (86.3434)  Acc@5: 100.0000 (98.5722)  time: 0.3492  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [1830/3125]  eta: 0:07:32  Lr: 0.001875  Loss: -0.3951  Acc@1: 87.5000 (86.3497)  Acc@5: 100.0000 (98.5800)  time: 0.3501  data: 0.0007  max mem: 2502
Train: Epoch[3/5]  [1840/3125]  eta: 0:07:29  Lr: 0.001875  Loss: -0.8294  Acc@1: 87.5000 (86.3559)  Acc@5: 100.0000 (98.5775)  time: 0.3489  data: 0.0007  max mem: 2502
Train: Epoch[3/5]  [1850/3125]  eta: 0:07:25  Lr: 0.001875  Loss: -0.5709  Acc@1: 81.2500 (86.3385)  Acc@5: 100.0000 (98.5818)  time: 0.3489  data: 0.0006  max mem: 2502
Train: Epoch[3/5]  [1860/3125]  eta: 0:07:22  Lr: 0.001875  Loss: -0.1415  Acc@1: 81.2500 (86.3212)  Acc@5: 100.0000 (98.5760)  time: 0.3486  data: 0.0008  max mem: 2502
Train: Epoch[3/5]  [1870/3125]  eta: 0:07:18  Lr: 0.001875  Loss: -0.5957  Acc@1: 87.5000 (86.3208)  Acc@5: 100.0000 (98.5803)  time: 0.3486  data: 0.0011  max mem: 2502
Train: Epoch[3/5]  [1880/3125]  eta: 0:07:15  Lr: 0.001875  Loss: -0.8580  Acc@1: 87.5000 (86.3437)  Acc@5: 100.0000 (98.5812)  time: 0.3493  data: 0.0010  max mem: 2502
Train: Epoch[3/5]  [1890/3125]  eta: 0:07:11  Lr: 0.001875  Loss: -0.2701  Acc@1: 93.7500 (86.3432)  Acc@5: 100.0000 (98.5689)  time: 0.3490  data: 0.0006  max mem: 2502
Train: Epoch[3/5]  [1900/3125]  eta: 0:07:08  Lr: 0.001875  Loss: -0.5759  Acc@1: 87.5000 (86.3394)  Acc@5: 100.0000 (98.5698)  time: 0.3488  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [1910/3125]  eta: 0:07:04  Lr: 0.001875  Loss: -0.6880  Acc@1: 87.5000 (86.3455)  Acc@5: 100.0000 (98.5708)  time: 0.3478  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [1920/3125]  eta: 0:07:01  Lr: 0.001875  Loss: -0.8225  Acc@1: 87.5000 (86.3580)  Acc@5: 100.0000 (98.5685)  time: 0.3478  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [1930/3125]  eta: 0:06:57  Lr: 0.001875  Loss: -0.3327  Acc@1: 87.5000 (86.3542)  Acc@5: 100.0000 (98.5597)  time: 0.3491  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [1940/3125]  eta: 0:06:54  Lr: 0.001875  Loss: -0.5891  Acc@1: 81.2500 (86.3344)  Acc@5: 100.0000 (98.5639)  time: 0.3482  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [1950/3125]  eta: 0:06:50  Lr: 0.001875  Loss: -0.6588  Acc@1: 87.5000 (86.3499)  Acc@5: 100.0000 (98.5648)  time: 0.3488  data: 0.0007  max mem: 2502
Train: Epoch[3/5]  [1960/3125]  eta: 0:06:47  Lr: 0.001875  Loss: -0.3261  Acc@1: 87.5000 (86.3526)  Acc@5: 100.0000 (98.5626)  time: 0.3496  data: 0.0008  max mem: 2502
Train: Epoch[3/5]  [1970/3125]  eta: 0:06:43  Lr: 0.001875  Loss: -0.6563  Acc@1: 87.5000 (86.3648)  Acc@5: 100.0000 (98.5635)  time: 0.3496  data: 0.0007  max mem: 2502
Train: Epoch[3/5]  [1980/3125]  eta: 0:06:40  Lr: 0.001875  Loss: -0.6425  Acc@1: 87.5000 (86.3579)  Acc@5: 100.0000 (98.5645)  time: 0.3513  data: 0.0009  max mem: 2502
Train: Epoch[3/5]  [1990/3125]  eta: 0:06:36  Lr: 0.001875  Loss: -0.5716  Acc@1: 87.5000 (86.3511)  Acc@5: 100.0000 (98.5654)  time: 0.3503  data: 0.0008  max mem: 2502
Train: Epoch[3/5]  [2000/3125]  eta: 0:06:33  Lr: 0.001875  Loss: -0.6889  Acc@1: 87.5000 (86.3568)  Acc@5: 100.0000 (98.5695)  time: 0.3484  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [2010/3125]  eta: 0:06:29  Lr: 0.001875  Loss: -0.7047  Acc@1: 87.5000 (86.3408)  Acc@5: 100.0000 (98.5641)  time: 0.3481  data: 0.0006  max mem: 2502
Train: Epoch[3/5]  [2020/3125]  eta: 0:06:26  Lr: 0.001875  Loss: -0.7832  Acc@1: 87.5000 (86.3681)  Acc@5: 100.0000 (98.5589)  time: 0.3480  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [2030/3125]  eta: 0:06:22  Lr: 0.001875  Loss: -0.5054  Acc@1: 93.7500 (86.3829)  Acc@5: 100.0000 (98.5629)  time: 0.3484  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [2040/3125]  eta: 0:06:19  Lr: 0.001875  Loss: -0.2900  Acc@1: 87.5000 (86.3884)  Acc@5: 100.0000 (98.5577)  time: 0.3487  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [2050/3125]  eta: 0:06:15  Lr: 0.001875  Loss: -0.6328  Acc@1: 87.5000 (86.3999)  Acc@5: 100.0000 (98.5617)  time: 0.3497  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [2060/3125]  eta: 0:06:12  Lr: 0.001875  Loss: -0.7479  Acc@1: 87.5000 (86.4022)  Acc@5: 100.0000 (98.5535)  time: 0.3499  data: 0.0006  max mem: 2502
Train: Epoch[3/5]  [2070/3125]  eta: 0:06:08  Lr: 0.001875  Loss: -0.2523  Acc@1: 87.5000 (86.4015)  Acc@5: 100.0000 (98.5575)  time: 0.3490  data: 0.0007  max mem: 2502
Train: Epoch[3/5]  [2080/3125]  eta: 0:06:05  Lr: 0.001875  Loss: -0.5298  Acc@1: 87.5000 (86.4008)  Acc@5: 100.0000 (98.5464)  time: 0.3485  data: 0.0006  max mem: 2502
Train: Epoch[3/5]  [2090/3125]  eta: 0:06:01  Lr: 0.001875  Loss: -0.6956  Acc@1: 87.5000 (86.4269)  Acc@5: 100.0000 (98.5503)  time: 0.3489  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [2100/3125]  eta: 0:05:58  Lr: 0.001875  Loss: -0.6981  Acc@1: 87.5000 (86.4291)  Acc@5: 100.0000 (98.5513)  time: 0.3491  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [2110/3125]  eta: 0:05:54  Lr: 0.001875  Loss: -0.2707  Acc@1: 87.5000 (86.4253)  Acc@5: 100.0000 (98.5552)  time: 0.3488  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [2120/3125]  eta: 0:05:51  Lr: 0.001875  Loss: -0.2924  Acc@1: 87.5000 (86.4127)  Acc@5: 100.0000 (98.5591)  time: 0.3494  data: 0.0006  max mem: 2502
Train: Epoch[3/5]  [2130/3125]  eta: 0:05:47  Lr: 0.001875  Loss: -0.3814  Acc@1: 87.5000 (86.4090)  Acc@5: 100.0000 (98.5599)  time: 0.3505  data: 0.0007  max mem: 2502
Train: Epoch[3/5]  [2140/3125]  eta: 0:05:44  Lr: 0.001875  Loss: -0.1991  Acc@1: 87.5000 (86.4082)  Acc@5: 100.0000 (98.5667)  time: 0.3521  data: 0.0008  max mem: 2502
Train: Epoch[3/5]  [2150/3125]  eta: 0:05:40  Lr: 0.001875  Loss: -0.6856  Acc@1: 87.5000 (86.4075)  Acc@5: 100.0000 (98.5617)  time: 0.3504  data: 0.0007  max mem: 2502
Train: Epoch[3/5]  [2160/3125]  eta: 0:05:37  Lr: 0.001875  Loss: -0.6379  Acc@1: 87.5000 (86.4241)  Acc@5: 100.0000 (98.5597)  time: 0.3490  data: 0.0006  max mem: 2502
Train: Epoch[3/5]  [2170/3125]  eta: 0:05:33  Lr: 0.001875  Loss: -0.6407  Acc@1: 87.5000 (86.4348)  Acc@5: 100.0000 (98.5606)  time: 0.3508  data: 0.0006  max mem: 2502
Train: Epoch[3/5]  [2180/3125]  eta: 0:05:30  Lr: 0.001875  Loss: -0.6219  Acc@1: 87.5000 (86.4569)  Acc@5: 100.0000 (98.5614)  time: 0.3531  data: 0.0006  max mem: 2502
Train: Epoch[3/5]  [2190/3125]  eta: 0:05:26  Lr: 0.001875  Loss: -0.4818  Acc@1: 87.5000 (86.4674)  Acc@5: 100.0000 (98.5594)  time: 0.3523  data: 0.0006  max mem: 2502
Train: Epoch[3/5]  [2200/3125]  eta: 0:05:23  Lr: 0.001875  Loss: -0.6626  Acc@1: 87.5000 (86.4692)  Acc@5: 100.0000 (98.5575)  time: 0.3499  data: 0.0006  max mem: 2502
Train: Epoch[3/5]  [2210/3125]  eta: 0:05:19  Lr: 0.001875  Loss: 0.1483  Acc@1: 87.5000 (86.4711)  Acc@5: 100.0000 (98.5583)  time: 0.3519  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [2220/3125]  eta: 0:05:16  Lr: 0.001875  Loss: -0.6809  Acc@1: 87.5000 (86.4588)  Acc@5: 100.0000 (98.5536)  time: 0.3515  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [2230/3125]  eta: 0:05:12  Lr: 0.001875  Loss: -0.3869  Acc@1: 81.2500 (86.4551)  Acc@5: 100.0000 (98.5545)  time: 0.3502  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [2240/3125]  eta: 0:05:09  Lr: 0.001875  Loss: -0.6284  Acc@1: 81.2500 (86.4541)  Acc@5: 100.0000 (98.5470)  time: 0.3519  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [2250/3125]  eta: 0:05:05  Lr: 0.001875  Loss: -0.6489  Acc@1: 87.5000 (86.4532)  Acc@5: 100.0000 (98.5395)  time: 0.3508  data: 0.0006  max mem: 2502
Train: Epoch[3/5]  [2260/3125]  eta: 0:05:02  Lr: 0.001875  Loss: -0.2643  Acc@1: 87.5000 (86.4385)  Acc@5: 100.0000 (98.5322)  time: 0.3492  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [2270/3125]  eta: 0:04:58  Lr: 0.001875  Loss: -0.0774  Acc@1: 81.2500 (86.4239)  Acc@5: 100.0000 (98.5359)  time: 0.3485  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [2280/3125]  eta: 0:04:55  Lr: 0.001875  Loss: -0.6256  Acc@1: 87.5000 (86.4286)  Acc@5: 100.0000 (98.5423)  time: 0.3496  data: 0.0018  max mem: 2502
Train: Epoch[3/5]  [2290/3125]  eta: 0:04:51  Lr: 0.001875  Loss: -0.8149  Acc@1: 87.5000 (86.4470)  Acc@5: 100.0000 (98.5459)  time: 0.3510  data: 0.0021  max mem: 2502
Train: Epoch[3/5]  [2300/3125]  eta: 0:04:48  Lr: 0.001875  Loss: -0.5905  Acc@1: 87.5000 (86.4515)  Acc@5: 100.0000 (98.5441)  time: 0.3527  data: 0.0018  max mem: 2502
Train: Epoch[3/5]  [2310/3125]  eta: 0:04:44  Lr: 0.001875  Loss: -0.6169  Acc@1: 87.5000 (86.4534)  Acc@5: 100.0000 (98.5450)  time: 0.3510  data: 0.0016  max mem: 2502
Train: Epoch[3/5]  [2320/3125]  eta: 0:04:41  Lr: 0.001875  Loss: -0.7365  Acc@1: 87.5000 (86.4498)  Acc@5: 100.0000 (98.5432)  time: 0.3478  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [2330/3125]  eta: 0:04:37  Lr: 0.001875  Loss: -0.4836  Acc@1: 87.5000 (86.4436)  Acc@5: 100.0000 (98.5468)  time: 0.3475  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [2340/3125]  eta: 0:04:34  Lr: 0.001875  Loss: -0.4776  Acc@1: 81.2500 (86.4374)  Acc@5: 100.0000 (98.5450)  time: 0.3486  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [2350/3125]  eta: 0:04:30  Lr: 0.001875  Loss: -0.5247  Acc@1: 81.2500 (86.4154)  Acc@5: 100.0000 (98.5485)  time: 0.3495  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [2360/3125]  eta: 0:04:27  Lr: 0.001875  Loss: -0.5853  Acc@1: 87.5000 (86.4226)  Acc@5: 100.0000 (98.5520)  time: 0.3484  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [2370/3125]  eta: 0:04:23  Lr: 0.001875  Loss: -0.3172  Acc@1: 87.5000 (86.4166)  Acc@5: 100.0000 (98.5528)  time: 0.3481  data: 0.0007  max mem: 2502
Train: Epoch[3/5]  [2380/3125]  eta: 0:04:20  Lr: 0.001875  Loss: -0.6936  Acc@1: 87.5000 (86.4238)  Acc@5: 100.0000 (98.5589)  time: 0.3492  data: 0.0006  max mem: 2502
Train: Epoch[3/5]  [2390/3125]  eta: 0:04:16  Lr: 0.001875  Loss: -0.4354  Acc@1: 87.5000 (86.4230)  Acc@5: 100.0000 (98.5519)  time: 0.3510  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [2400/3125]  eta: 0:04:13  Lr: 0.001875  Loss: -0.0915  Acc@1: 87.5000 (86.4015)  Acc@5: 100.0000 (98.5527)  time: 0.3517  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [2410/3125]  eta: 0:04:10  Lr: 0.001875  Loss: -0.3365  Acc@1: 81.2500 (86.3775)  Acc@5: 100.0000 (98.5457)  time: 0.3499  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [2420/3125]  eta: 0:04:06  Lr: 0.001875  Loss: -0.5195  Acc@1: 81.2500 (86.3848)  Acc@5: 100.0000 (98.5517)  time: 0.3492  data: 0.0006  max mem: 2502
Train: Epoch[3/5]  [2430/3125]  eta: 0:04:03  Lr: 0.001875  Loss: -0.5021  Acc@1: 87.5000 (86.3919)  Acc@5: 100.0000 (98.5551)  time: 0.3487  data: 0.0006  max mem: 2502
Train: Epoch[3/5]  [2440/3125]  eta: 0:03:59  Lr: 0.001875  Loss: -0.6672  Acc@1: 87.5000 (86.3965)  Acc@5: 100.0000 (98.5559)  time: 0.3476  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [2450/3125]  eta: 0:03:56  Lr: 0.001875  Loss: -0.8475  Acc@1: 87.5000 (86.3984)  Acc@5: 100.0000 (98.5567)  time: 0.3485  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [2460/3125]  eta: 0:03:52  Lr: 0.001875  Loss: -0.3328  Acc@1: 87.5000 (86.4029)  Acc@5: 100.0000 (98.5575)  time: 0.3488  data: 0.0006  max mem: 2502
Train: Epoch[3/5]  [2470/3125]  eta: 0:03:49  Lr: 0.001875  Loss: -0.4181  Acc@1: 87.5000 (86.3997)  Acc@5: 100.0000 (98.5583)  time: 0.3479  data: 0.0009  max mem: 2502
Train: Epoch[3/5]  [2480/3125]  eta: 0:03:45  Lr: 0.001875  Loss: -0.7394  Acc@1: 87.5000 (86.3991)  Acc@5: 100.0000 (98.5590)  time: 0.3480  data: 0.0015  max mem: 2502
Train: Epoch[3/5]  [2490/3125]  eta: 0:03:42  Lr: 0.001875  Loss: -0.7521  Acc@1: 87.5000 (86.3960)  Acc@5: 100.0000 (98.5598)  time: 0.3483  data: 0.0012  max mem: 2502
Train: Epoch[3/5]  [2500/3125]  eta: 0:03:38  Lr: 0.001875  Loss: -0.5933  Acc@1: 87.5000 (86.3979)  Acc@5: 100.0000 (98.5631)  time: 0.3504  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [2510/3125]  eta: 0:03:35  Lr: 0.001875  Loss: -0.6959  Acc@1: 87.5000 (86.4048)  Acc@5: 100.0000 (98.5613)  time: 0.3507  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [2520/3125]  eta: 0:03:31  Lr: 0.001875  Loss: -0.6180  Acc@1: 87.5000 (86.4290)  Acc@5: 100.0000 (98.5670)  time: 0.3485  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [2530/3125]  eta: 0:03:28  Lr: 0.001875  Loss: -0.5697  Acc@1: 93.7500 (86.4308)  Acc@5: 100.0000 (98.5678)  time: 0.3482  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [2540/3125]  eta: 0:03:24  Lr: 0.001875  Loss: -0.5841  Acc@1: 87.5000 (86.4276)  Acc@5: 100.0000 (98.5734)  time: 0.3477  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [2550/3125]  eta: 0:03:21  Lr: 0.001875  Loss: -0.6132  Acc@1: 87.5000 (86.4122)  Acc@5: 100.0000 (98.5667)  time: 0.3487  data: 0.0012  max mem: 2502
Train: Epoch[3/5]  [2560/3125]  eta: 0:03:17  Lr: 0.001875  Loss: -0.2998  Acc@1: 87.5000 (86.4164)  Acc@5: 100.0000 (98.5675)  time: 0.3495  data: 0.0013  max mem: 2502
Train: Epoch[3/5]  [2570/3125]  eta: 0:03:14  Lr: 0.001875  Loss: -0.7229  Acc@1: 87.5000 (86.4012)  Acc@5: 100.0000 (98.5560)  time: 0.3495  data: 0.0010  max mem: 2502
Train: Epoch[3/5]  [2580/3125]  eta: 0:03:10  Lr: 0.001875  Loss: -0.6401  Acc@1: 81.2500 (86.4006)  Acc@5: 100.0000 (98.5543)  time: 0.3485  data: 0.0011  max mem: 2502
Train: Epoch[3/5]  [2590/3125]  eta: 0:03:07  Lr: 0.001875  Loss: -0.4250  Acc@1: 87.5000 (86.4073)  Acc@5: 100.0000 (98.5527)  time: 0.3481  data: 0.0013  max mem: 2502
Train: Epoch[3/5]  [2600/3125]  eta: 0:03:03  Lr: 0.001875  Loss: -0.1864  Acc@1: 87.5000 (86.3995)  Acc@5: 100.0000 (98.5462)  time: 0.3487  data: 0.0015  max mem: 2502
Train: Epoch[3/5]  [2610/3125]  eta: 0:03:00  Lr: 0.001875  Loss: -0.8216  Acc@1: 87.5000 (86.4109)  Acc@5: 100.0000 (98.5494)  time: 0.3482  data: 0.0009  max mem: 2502
Train: Epoch[3/5]  [2620/3125]  eta: 0:02:56  Lr: 0.001875  Loss: -0.6068  Acc@1: 87.5000 (86.4055)  Acc@5: 100.0000 (98.5454)  time: 0.3485  data: 0.0007  max mem: 2502
Train: Epoch[3/5]  [2630/3125]  eta: 0:02:53  Lr: 0.001875  Loss: -0.2258  Acc@1: 87.5000 (86.4263)  Acc@5: 100.0000 (98.5462)  time: 0.3479  data: 0.0007  max mem: 2502
Train: Epoch[3/5]  [2640/3125]  eta: 0:02:49  Lr: 0.001875  Loss: -0.5902  Acc@1: 93.7500 (86.4303)  Acc@5: 100.0000 (98.5422)  time: 0.3484  data: 0.0012  max mem: 2502
Train: Epoch[3/5]  [2650/3125]  eta: 0:02:46  Lr: 0.001875  Loss: -0.5884  Acc@1: 87.5000 (86.4179)  Acc@5: 100.0000 (98.5430)  time: 0.3483  data: 0.0011  max mem: 2502
Train: Epoch[3/5]  [2660/3125]  eta: 0:02:42  Lr: 0.001875  Loss: -0.4877  Acc@1: 87.5000 (86.4407)  Acc@5: 100.0000 (98.5438)  time: 0.3483  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [2670/3125]  eta: 0:02:39  Lr: 0.001875  Loss: -0.6869  Acc@1: 87.5000 (86.4423)  Acc@5: 100.0000 (98.5469)  time: 0.3501  data: 0.0007  max mem: 2502
Train: Epoch[3/5]  [2680/3125]  eta: 0:02:35  Lr: 0.001875  Loss: -0.1364  Acc@1: 87.5000 (86.4416)  Acc@5: 100.0000 (98.5453)  time: 0.3503  data: 0.0008  max mem: 2502
Train: Epoch[3/5]  [2690/3125]  eta: 0:02:32  Lr: 0.001875  Loss: -0.7263  Acc@1: 87.5000 (86.4409)  Acc@5: 100.0000 (98.5461)  time: 0.3494  data: 0.0007  max mem: 2502
Train: Epoch[3/5]  [2700/3125]  eta: 0:02:28  Lr: 0.001875  Loss: -0.6041  Acc@1: 87.5000 (86.4310)  Acc@5: 100.0000 (98.5422)  time: 0.3496  data: 0.0007  max mem: 2502
Train: Epoch[3/5]  [2710/3125]  eta: 0:02:25  Lr: 0.001875  Loss: -0.5859  Acc@1: 87.5000 (86.4395)  Acc@5: 100.0000 (98.5430)  time: 0.3487  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [2720/3125]  eta: 0:02:21  Lr: 0.001875  Loss: -0.7793  Acc@1: 87.5000 (86.4365)  Acc@5: 100.0000 (98.5414)  time: 0.3473  data: 0.0006  max mem: 2502
Train: Epoch[3/5]  [2730/3125]  eta: 0:02:18  Lr: 0.001875  Loss: -0.7319  Acc@1: 87.5000 (86.4450)  Acc@5: 100.0000 (98.5445)  time: 0.3479  data: 0.0006  max mem: 2502
Train: Epoch[3/5]  [2740/3125]  eta: 0:02:14  Lr: 0.001875  Loss: -0.8326  Acc@1: 87.5000 (86.4602)  Acc@5: 100.0000 (98.5452)  time: 0.3490  data: 0.0008  max mem: 2502
Train: Epoch[3/5]  [2750/3125]  eta: 0:02:11  Lr: 0.001875  Loss: -0.9145  Acc@1: 87.5000 (86.4686)  Acc@5: 100.0000 (98.5460)  time: 0.3501  data: 0.0008  max mem: 2502
Train: Epoch[3/5]  [2760/3125]  eta: 0:02:07  Lr: 0.001875  Loss: -0.8535  Acc@1: 87.5000 (86.4768)  Acc@5: 100.0000 (98.5512)  time: 0.3510  data: 0.0006  max mem: 2502
Train: Epoch[3/5]  [2770/3125]  eta: 0:02:04  Lr: 0.001875  Loss: -0.5490  Acc@1: 87.5000 (86.4828)  Acc@5: 100.0000 (98.5565)  time: 0.3499  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [2780/3125]  eta: 0:02:00  Lr: 0.001875  Loss: -0.5427  Acc@1: 87.5000 (86.4774)  Acc@5: 100.0000 (98.5572)  time: 0.3494  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [2790/3125]  eta: 0:01:57  Lr: 0.001875  Loss: -0.7285  Acc@1: 87.5000 (86.4945)  Acc@5: 100.0000 (98.5623)  time: 0.3491  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [2800/3125]  eta: 0:01:53  Lr: 0.001875  Loss: -0.6315  Acc@1: 87.5000 (86.4959)  Acc@5: 100.0000 (98.5586)  time: 0.3489  data: 0.0006  max mem: 2502
Train: Epoch[3/5]  [2810/3125]  eta: 0:01:50  Lr: 0.001875  Loss: -0.7233  Acc@1: 87.5000 (86.4795)  Acc@5: 100.0000 (98.5570)  time: 0.3508  data: 0.0009  max mem: 2502
Train: Epoch[3/5]  [2820/3125]  eta: 0:01:46  Lr: 0.001875  Loss: -0.7912  Acc@1: 87.5000 (86.4786)  Acc@5: 100.0000 (98.5533)  time: 0.3538  data: 0.0009  max mem: 2502
Train: Epoch[3/5]  [2830/3125]  eta: 0:01:43  Lr: 0.001875  Loss: -0.4630  Acc@1: 87.5000 (86.4646)  Acc@5: 100.0000 (98.5562)  time: 0.3530  data: 0.0006  max mem: 2502
Train: Epoch[3/5]  [2840/3125]  eta: 0:01:39  Lr: 0.001875  Loss: -0.4527  Acc@1: 87.5000 (86.4638)  Acc@5: 100.0000 (98.5568)  time: 0.3500  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [2850/3125]  eta: 0:01:36  Lr: 0.001875  Loss: -0.5675  Acc@1: 87.5000 (86.4543)  Acc@5: 100.0000 (98.5553)  time: 0.3500  data: 0.0009  max mem: 2502
Train: Epoch[3/5]  [2860/3125]  eta: 0:01:32  Lr: 0.001875  Loss: -0.1809  Acc@1: 81.2500 (86.4514)  Acc@5: 100.0000 (98.5473)  time: 0.3495  data: 0.0010  max mem: 2502
Train: Epoch[3/5]  [2870/3125]  eta: 0:01:29  Lr: 0.001875  Loss: -0.6905  Acc@1: 81.2500 (86.4572)  Acc@5: 100.0000 (98.5458)  time: 0.3491  data: 0.0007  max mem: 2502
Train: Epoch[3/5]  [2880/3125]  eta: 0:01:25  Lr: 0.001875  Loss: -0.3752  Acc@1: 87.5000 (86.4587)  Acc@5: 100.0000 (98.5465)  time: 0.3496  data: 0.0006  max mem: 2502
Train: Epoch[3/5]  [2890/3125]  eta: 0:01:22  Lr: 0.001875  Loss: -0.8227  Acc@1: 87.5000 (86.4623)  Acc@5: 100.0000 (98.5472)  time: 0.3500  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [2900/3125]  eta: 0:01:18  Lr: 0.001875  Loss: -0.6358  Acc@1: 87.5000 (86.4659)  Acc@5: 100.0000 (98.5458)  time: 0.3505  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [2910/3125]  eta: 0:01:15  Lr: 0.001875  Loss: -0.7648  Acc@1: 87.5000 (86.4565)  Acc@5: 100.0000 (98.5443)  time: 0.3518  data: 0.0006  max mem: 2502
Train: Epoch[3/5]  [2920/3125]  eta: 0:01:11  Lr: 0.001875  Loss: -0.0093  Acc@1: 81.2500 (86.4451)  Acc@5: 100.0000 (98.5429)  time: 0.3514  data: 0.0014  max mem: 2502
Train: Epoch[3/5]  [2930/3125]  eta: 0:01:08  Lr: 0.001875  Loss: -0.6615  Acc@1: 87.5000 (86.4466)  Acc@5: 100.0000 (98.5436)  time: 0.3492  data: 0.0012  max mem: 2502
Train: Epoch[3/5]  [2940/3125]  eta: 0:01:04  Lr: 0.001875  Loss: -0.5595  Acc@1: 87.5000 (86.4438)  Acc@5: 100.0000 (98.5379)  time: 0.3489  data: 0.0006  max mem: 2502
Train: Epoch[3/5]  [2950/3125]  eta: 0:01:01  Lr: 0.001875  Loss: -0.4275  Acc@1: 81.2500 (86.4410)  Acc@5: 100.0000 (98.5407)  time: 0.3502  data: 0.0008  max mem: 2502
Train: Epoch[3/5]  [2960/3125]  eta: 0:00:57  Lr: 0.001875  Loss: -0.3983  Acc@1: 81.2500 (86.4277)  Acc@5: 100.0000 (98.5351)  time: 0.3506  data: 0.0006  max mem: 2502
Train: Epoch[3/5]  [2970/3125]  eta: 0:00:54  Lr: 0.001875  Loss: -0.7030  Acc@1: 87.5000 (86.4292)  Acc@5: 100.0000 (98.5380)  time: 0.3501  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [2980/3125]  eta: 0:00:50  Lr: 0.001875  Loss: -0.5105  Acc@1: 87.5000 (86.4475)  Acc@5: 100.0000 (98.5387)  time: 0.3505  data: 0.0008  max mem: 2502
Train: Epoch[3/5]  [2990/3125]  eta: 0:00:47  Lr: 0.001875  Loss: -0.3612  Acc@1: 93.7500 (86.4573)  Acc@5: 100.0000 (98.5435)  time: 0.3488  data: 0.0008  max mem: 2502
Train: Epoch[3/5]  [3000/3125]  eta: 0:00:43  Lr: 0.001875  Loss: -0.5729  Acc@1: 87.5000 (86.4399)  Acc@5: 100.0000 (98.5442)  time: 0.3476  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [3010/3125]  eta: 0:00:40  Lr: 0.001875  Loss: -0.4009  Acc@1: 87.5000 (86.4372)  Acc@5: 100.0000 (98.5491)  time: 0.3491  data: 0.0006  max mem: 2502
Train: Epoch[3/5]  [3020/3125]  eta: 0:00:36  Lr: 0.001875  Loss: -0.7513  Acc@1: 87.5000 (86.4428)  Acc@5: 100.0000 (98.5518)  time: 0.3488  data: 0.0006  max mem: 2502
Train: Epoch[3/5]  [3030/3125]  eta: 0:00:33  Lr: 0.001875  Loss: -0.3796  Acc@1: 87.5000 (86.4422)  Acc@5: 100.0000 (98.5504)  time: 0.3487  data: 0.0009  max mem: 2502
Train: Epoch[3/5]  [3040/3125]  eta: 0:00:29  Lr: 0.001875  Loss: -0.5796  Acc@1: 87.5000 (86.4395)  Acc@5: 100.0000 (98.5490)  time: 0.3492  data: 0.0014  max mem: 2502
Train: Epoch[3/5]  [3050/3125]  eta: 0:00:26  Lr: 0.001875  Loss: -0.5291  Acc@1: 87.5000 (86.4327)  Acc@5: 100.0000 (98.5517)  time: 0.3492  data: 0.0016  max mem: 2502
Train: Epoch[3/5]  [3060/3125]  eta: 0:00:22  Lr: 0.001875  Loss: -0.4577  Acc@1: 87.5000 (86.4505)  Acc@5: 100.0000 (98.5544)  time: 0.3495  data: 0.0012  max mem: 2502
Train: Epoch[3/5]  [3070/3125]  eta: 0:00:19  Lr: 0.001875  Loss: -0.5364  Acc@1: 93.7500 (86.4621)  Acc@5: 100.0000 (98.5571)  time: 0.3499  data: 0.0007  max mem: 2502
Train: Epoch[3/5]  [3080/3125]  eta: 0:00:15  Lr: 0.001875  Loss: -0.5594  Acc@1: 87.5000 (86.4695)  Acc@5: 100.0000 (98.5597)  time: 0.3492  data: 0.0006  max mem: 2502
Train: Epoch[3/5]  [3090/3125]  eta: 0:00:12  Lr: 0.001875  Loss: -0.6501  Acc@1: 87.5000 (86.4748)  Acc@5: 100.0000 (98.5603)  time: 0.3479  data: 0.0006  max mem: 2502
Train: Epoch[3/5]  [3100/3125]  eta: 0:00:08  Lr: 0.001875  Loss: -0.6841  Acc@1: 87.5000 (86.4822)  Acc@5: 100.0000 (98.5630)  time: 0.3489  data: 0.0006  max mem: 2502
Train: Epoch[3/5]  [3110/3125]  eta: 0:00:05  Lr: 0.001875  Loss: -0.7611  Acc@1: 87.5000 (86.4834)  Acc@5: 100.0000 (98.5656)  time: 0.3495  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [3120/3125]  eta: 0:00:01  Lr: 0.001875  Loss: -0.5519  Acc@1: 87.5000 (86.4867)  Acc@5: 100.0000 (98.5622)  time: 0.3495  data: 0.0009  max mem: 2502
Train: Epoch[3/5]  [3124/3125]  eta: 0:00:00  Lr: 0.001875  Loss: -0.6120  Acc@1: 87.5000 (86.4820)  Acc@5: 100.0000 (98.5620)  time: 0.3525  data: 0.0008  max mem: 2502
Train: Epoch[3/5] Total time: 0:18:13 (0.3498 s / it)
{0: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 1: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 2: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 3: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 4: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 5: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 6: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 7: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 8: {0: 0, 1: 0, 2: 150000, 3: 0, 4: 0}, 9: {0: 0, 1: 0, 2: 150000, 3: 0, 4: 0}, 10: {0: 0, 1: 0, 2: 150000, 3: 0, 4: 0}, 11: {0: 0, 1: 0, 2: 150000, 3: 0, 4: 0}, 12: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 13: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 14: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 15: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 16: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 17: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 18: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 19: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}}
Averaged stats: Lr: 0.001875  Loss: -0.6120  Acc@1: 87.5000 (86.4820)  Acc@5: 100.0000 (98.5620)
Train: Epoch[4/5]  [   0/3125]  eta: 0:35:52  Lr: 0.001875  Loss: -0.2226  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (100.0000)  time: 0.6888  data: 0.3414  max mem: 2502
Train: Epoch[4/5]  [  10/3125]  eta: 0:19:42  Lr: 0.001875  Loss: -0.8575  Acc@1: 87.5000 (88.6364)  Acc@5: 100.0000 (98.8636)  time: 0.3796  data: 0.0315  max mem: 2502
Train: Epoch[4/5]  [  20/3125]  eta: 0:18:55  Lr: 0.001875  Loss: -0.5456  Acc@1: 87.5000 (87.2024)  Acc@5: 100.0000 (98.8095)  time: 0.3495  data: 0.0011  max mem: 2502
Train: Epoch[4/5]  [  30/3125]  eta: 0:18:37  Lr: 0.001875  Loss: -0.3310  Acc@1: 81.2500 (86.8952)  Acc@5: 100.0000 (98.7903)  time: 0.3506  data: 0.0018  max mem: 2502
Train: Epoch[4/5]  [  40/3125]  eta: 0:18:23  Lr: 0.001875  Loss: -0.5417  Acc@1: 87.5000 (87.0427)  Acc@5: 100.0000 (99.0854)  time: 0.3491  data: 0.0012  max mem: 2502
Train: Epoch[4/5]  [  50/3125]  eta: 0:18:13  Lr: 0.001875  Loss: -0.5415  Acc@1: 87.5000 (86.6422)  Acc@5: 100.0000 (98.8971)  time: 0.3476  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [  60/3125]  eta: 0:18:06  Lr: 0.001875  Loss: -0.6075  Acc@1: 87.5000 (86.7828)  Acc@5: 100.0000 (98.7705)  time: 0.3484  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [  70/3125]  eta: 0:18:01  Lr: 0.001875  Loss: -0.4660  Acc@1: 87.5000 (86.9718)  Acc@5: 100.0000 (98.5035)  time: 0.3496  data: 0.0016  max mem: 2502
Train: Epoch[4/5]  [  80/3125]  eta: 0:17:56  Lr: 0.001875  Loss: -0.7996  Acc@1: 87.5000 (86.8827)  Acc@5: 100.0000 (98.5340)  time: 0.3500  data: 0.0018  max mem: 2502
Train: Epoch[4/5]  [  90/3125]  eta: 0:17:51  Lr: 0.001875  Loss: -0.6239  Acc@1: 87.5000 (86.4011)  Acc@5: 100.0000 (98.4203)  time: 0.3494  data: 0.0009  max mem: 2502
Train: Epoch[4/5]  [ 100/3125]  eta: 0:17:46  Lr: 0.001875  Loss: -0.5528  Acc@1: 81.2500 (86.3861)  Acc@5: 100.0000 (98.5767)  time: 0.3486  data: 0.0006  max mem: 2502
Train: Epoch[4/5]  [ 110/3125]  eta: 0:17:41  Lr: 0.001875  Loss: -0.4360  Acc@1: 87.5000 (86.4865)  Acc@5: 100.0000 (98.6486)  time: 0.3479  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [ 120/3125]  eta: 0:17:37  Lr: 0.001875  Loss: -0.2157  Acc@1: 87.5000 (86.5186)  Acc@5: 100.0000 (98.7603)  time: 0.3481  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [ 130/3125]  eta: 0:17:33  Lr: 0.001875  Loss: -0.8039  Acc@1: 87.5000 (86.4504)  Acc@5: 100.0000 (98.8550)  time: 0.3494  data: 0.0006  max mem: 2502
Train: Epoch[4/5]  [ 140/3125]  eta: 0:17:29  Lr: 0.001875  Loss: -0.7684  Acc@1: 87.5000 (86.6135)  Acc@5: 100.0000 (98.7145)  time: 0.3497  data: 0.0008  max mem: 2502
Train: Epoch[4/5]  [ 150/3125]  eta: 0:17:24  Lr: 0.001875  Loss: -0.4368  Acc@1: 87.5000 (86.5480)  Acc@5: 100.0000 (98.7583)  time: 0.3484  data: 0.0009  max mem: 2502
Train: Epoch[4/5]  [ 160/3125]  eta: 0:17:20  Lr: 0.001875  Loss: -0.6516  Acc@1: 87.5000 (86.3354)  Acc@5: 100.0000 (98.7189)  time: 0.3473  data: 0.0006  max mem: 2502
Train: Epoch[4/5]  [ 170/3125]  eta: 0:17:16  Lr: 0.001875  Loss: -0.8408  Acc@1: 87.5000 (86.5132)  Acc@5: 100.0000 (98.7939)  time: 0.3485  data: 0.0007  max mem: 2502
Train: Epoch[4/5]  [ 180/3125]  eta: 0:17:12  Lr: 0.001875  Loss: -0.5326  Acc@1: 87.5000 (86.6713)  Acc@5: 100.0000 (98.8260)  time: 0.3490  data: 0.0006  max mem: 2502
Train: Epoch[4/5]  [ 190/3125]  eta: 0:17:08  Lr: 0.001875  Loss: -0.7765  Acc@1: 93.7500 (87.1728)  Acc@5: 100.0000 (98.8220)  time: 0.3479  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [ 200/3125]  eta: 0:17:05  Lr: 0.001875  Loss: -0.4546  Acc@1: 93.7500 (87.2512)  Acc@5: 100.0000 (98.8495)  time: 0.3476  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [ 210/3125]  eta: 0:17:01  Lr: 0.001875  Loss: -0.7179  Acc@1: 87.5000 (87.3223)  Acc@5: 100.0000 (98.8744)  time: 0.3474  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [ 220/3125]  eta: 0:16:57  Lr: 0.001875  Loss: -0.6179  Acc@1: 87.5000 (87.2455)  Acc@5: 100.0000 (98.8405)  time: 0.3482  data: 0.0006  max mem: 2502
Train: Epoch[4/5]  [ 230/3125]  eta: 0:16:54  Lr: 0.001875  Loss: -0.3895  Acc@1: 81.2500 (87.1212)  Acc@5: 100.0000 (98.8366)  time: 0.3512  data: 0.0026  max mem: 2502
Train: Epoch[4/5]  [ 240/3125]  eta: 0:16:51  Lr: 0.001875  Loss: -0.4239  Acc@1: 81.2500 (87.0591)  Acc@5: 100.0000 (98.8330)  time: 0.3529  data: 0.0026  max mem: 2502
Train: Epoch[4/5]  [ 250/3125]  eta: 0:16:47  Lr: 0.001875  Loss: -0.5726  Acc@1: 87.5000 (87.2012)  Acc@5: 100.0000 (98.7799)  time: 0.3517  data: 0.0007  max mem: 2502
Train: Epoch[4/5]  [ 260/3125]  eta: 0:16:44  Lr: 0.001875  Loss: -0.7543  Acc@1: 81.2500 (86.9013)  Acc@5: 100.0000 (98.7787)  time: 0.3512  data: 0.0017  max mem: 2502
Train: Epoch[4/5]  [ 270/3125]  eta: 0:16:40  Lr: 0.001875  Loss: -0.4326  Acc@1: 81.2500 (86.7851)  Acc@5: 100.0000 (98.6854)  time: 0.3502  data: 0.0016  max mem: 2502
Train: Epoch[4/5]  [ 280/3125]  eta: 0:16:36  Lr: 0.001875  Loss: -0.2911  Acc@1: 81.2500 (86.7215)  Acc@5: 100.0000 (98.7100)  time: 0.3486  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [ 290/3125]  eta: 0:16:33  Lr: 0.001875  Loss: -0.6885  Acc@1: 87.5000 (86.7053)  Acc@5: 100.0000 (98.7328)  time: 0.3483  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [ 300/3125]  eta: 0:16:29  Lr: 0.001875  Loss: -0.7340  Acc@1: 87.5000 (86.7525)  Acc@5: 100.0000 (98.7334)  time: 0.3487  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [ 310/3125]  eta: 0:16:25  Lr: 0.001875  Loss: -0.4072  Acc@1: 87.5000 (86.7765)  Acc@5: 100.0000 (98.7138)  time: 0.3490  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [ 320/3125]  eta: 0:16:22  Lr: 0.001875  Loss: -0.8824  Acc@1: 87.5000 (86.8185)  Acc@5: 100.0000 (98.6760)  time: 0.3497  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [ 330/3125]  eta: 0:16:18  Lr: 0.001875  Loss: -0.2064  Acc@1: 87.5000 (86.8958)  Acc@5: 100.0000 (98.6971)  time: 0.3495  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [ 340/3125]  eta: 0:16:15  Lr: 0.001875  Loss: -0.7504  Acc@1: 87.5000 (86.8952)  Acc@5: 100.0000 (98.7353)  time: 0.3484  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [ 350/3125]  eta: 0:16:11  Lr: 0.001875  Loss: -0.0806  Acc@1: 87.5000 (86.7165)  Acc@5: 100.0000 (98.6823)  time: 0.3485  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [ 360/3125]  eta: 0:16:07  Lr: 0.001875  Loss: -0.6033  Acc@1: 87.5000 (86.7555)  Acc@5: 100.0000 (98.6842)  time: 0.3494  data: 0.0006  max mem: 2502
Train: Epoch[4/5]  [ 370/3125]  eta: 0:16:04  Lr: 0.001875  Loss: -0.6345  Acc@1: 87.5000 (86.7588)  Acc@5: 100.0000 (98.7028)  time: 0.3492  data: 0.0007  max mem: 2502
Train: Epoch[4/5]  [ 380/3125]  eta: 0:16:00  Lr: 0.001875  Loss: -0.5787  Acc@1: 87.5000 (86.8274)  Acc@5: 100.0000 (98.6877)  time: 0.3481  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [ 390/3125]  eta: 0:15:57  Lr: 0.001875  Loss: -0.5857  Acc@1: 93.7500 (86.8926)  Acc@5: 100.0000 (98.6893)  time: 0.3482  data: 0.0012  max mem: 2502
Train: Epoch[4/5]  [ 400/3125]  eta: 0:15:53  Lr: 0.001875  Loss: -0.4100  Acc@1: 87.5000 (86.8921)  Acc@5: 100.0000 (98.6596)  time: 0.3500  data: 0.0015  max mem: 2502
Train: Epoch[4/5]  [ 410/3125]  eta: 0:15:50  Lr: 0.001875  Loss: -0.7445  Acc@1: 81.2500 (86.7853)  Acc@5: 100.0000 (98.6770)  time: 0.3523  data: 0.0015  max mem: 2502
Train: Epoch[4/5]  [ 420/3125]  eta: 0:15:46  Lr: 0.001875  Loss: -0.3373  Acc@1: 81.2500 (86.7280)  Acc@5: 100.0000 (98.6787)  time: 0.3515  data: 0.0013  max mem: 2502
Train: Epoch[4/5]  [ 430/3125]  eta: 0:15:43  Lr: 0.001875  Loss: -0.5664  Acc@1: 87.5000 (86.7604)  Acc@5: 100.0000 (98.6659)  time: 0.3488  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [ 440/3125]  eta: 0:15:39  Lr: 0.001875  Loss: -0.3327  Acc@1: 87.5000 (86.7063)  Acc@5: 100.0000 (98.6253)  time: 0.3478  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [ 450/3125]  eta: 0:15:36  Lr: 0.001875  Loss: -0.8496  Acc@1: 87.5000 (86.7378)  Acc@5: 100.0000 (98.6280)  time: 0.3498  data: 0.0008  max mem: 2502
Train: Epoch[4/5]  [ 460/3125]  eta: 0:15:32  Lr: 0.001875  Loss: -0.3404  Acc@1: 87.5000 (86.7001)  Acc@5: 100.0000 (98.6307)  time: 0.3523  data: 0.0011  max mem: 2502
Train: Epoch[4/5]  [ 470/3125]  eta: 0:15:29  Lr: 0.001875  Loss: 0.0122  Acc@1: 81.2500 (86.6773)  Acc@5: 100.0000 (98.5934)  time: 0.3510  data: 0.0009  max mem: 2502
Train: Epoch[4/5]  [ 480/3125]  eta: 0:15:26  Lr: 0.001875  Loss: -0.4629  Acc@1: 87.5000 (86.7594)  Acc@5: 100.0000 (98.6227)  time: 0.3513  data: 0.0006  max mem: 2502
Train: Epoch[4/5]  [ 490/3125]  eta: 0:15:22  Lr: 0.001875  Loss: -0.5951  Acc@1: 87.5000 (86.7744)  Acc@5: 100.0000 (98.6507)  time: 0.3533  data: 0.0006  max mem: 2502
Train: Epoch[4/5]  [ 500/3125]  eta: 0:15:19  Lr: 0.001875  Loss: -0.2771  Acc@1: 87.5000 (86.8139)  Acc@5: 100.0000 (98.6652)  time: 0.3520  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [ 510/3125]  eta: 0:15:15  Lr: 0.001875  Loss: -0.6276  Acc@1: 87.5000 (86.8028)  Acc@5: 100.0000 (98.6791)  time: 0.3489  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [ 520/3125]  eta: 0:15:11  Lr: 0.001875  Loss: -0.7619  Acc@1: 87.5000 (86.8162)  Acc@5: 100.0000 (98.7044)  time: 0.3478  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [ 530/3125]  eta: 0:15:08  Lr: 0.001875  Loss: -0.5197  Acc@1: 87.5000 (86.7820)  Acc@5: 100.0000 (98.7053)  time: 0.3485  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [ 540/3125]  eta: 0:15:04  Lr: 0.001875  Loss: -0.5790  Acc@1: 81.2500 (86.7029)  Acc@5: 100.0000 (98.6714)  time: 0.3488  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [ 550/3125]  eta: 0:15:01  Lr: 0.001875  Loss: -0.6756  Acc@1: 87.5000 (86.7627)  Acc@5: 100.0000 (98.6956)  time: 0.3487  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [ 560/3125]  eta: 0:14:57  Lr: 0.001875  Loss: -0.1755  Acc@1: 87.5000 (86.7090)  Acc@5: 100.0000 (98.6854)  time: 0.3484  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [ 570/3125]  eta: 0:14:54  Lr: 0.001875  Loss: -0.6516  Acc@1: 87.5000 (86.7557)  Acc@5: 100.0000 (98.7084)  time: 0.3488  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [ 580/3125]  eta: 0:14:50  Lr: 0.001875  Loss: -0.3734  Acc@1: 87.5000 (86.6717)  Acc@5: 100.0000 (98.7091)  time: 0.3492  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [ 590/3125]  eta: 0:14:47  Lr: 0.001875  Loss: -0.7588  Acc@1: 81.2500 (86.6540)  Acc@5: 100.0000 (98.7098)  time: 0.3484  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [ 600/3125]  eta: 0:14:43  Lr: 0.001875  Loss: -0.7041  Acc@1: 87.5000 (86.6577)  Acc@5: 100.0000 (98.6897)  time: 0.3479  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [ 610/3125]  eta: 0:14:39  Lr: 0.001875  Loss: -0.4391  Acc@1: 81.2500 (86.5589)  Acc@5: 100.0000 (98.6804)  time: 0.3479  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [ 620/3125]  eta: 0:14:36  Lr: 0.001875  Loss: -0.7350  Acc@1: 87.5000 (86.6143)  Acc@5: 100.0000 (98.6816)  time: 0.3480  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [ 630/3125]  eta: 0:14:32  Lr: 0.001875  Loss: -0.1018  Acc@1: 87.5000 (86.5987)  Acc@5: 100.0000 (98.6628)  time: 0.3492  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [ 640/3125]  eta: 0:14:29  Lr: 0.001875  Loss: -0.5015  Acc@1: 87.5000 (86.6615)  Acc@5: 100.0000 (98.6349)  time: 0.3493  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [ 650/3125]  eta: 0:14:25  Lr: 0.001875  Loss: -0.3726  Acc@1: 87.5000 (86.6839)  Acc@5: 100.0000 (98.6079)  time: 0.3492  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [ 660/3125]  eta: 0:14:22  Lr: 0.001875  Loss: -0.7582  Acc@1: 87.5000 (86.7152)  Acc@5: 100.0000 (98.6006)  time: 0.3483  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [ 670/3125]  eta: 0:14:18  Lr: 0.001875  Loss: -0.7335  Acc@1: 87.5000 (86.7362)  Acc@5: 100.0000 (98.6121)  time: 0.3471  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [ 680/3125]  eta: 0:14:15  Lr: 0.001875  Loss: -0.6681  Acc@1: 87.5000 (86.7107)  Acc@5: 100.0000 (98.6050)  time: 0.3484  data: 0.0007  max mem: 2502
Train: Epoch[4/5]  [ 690/3125]  eta: 0:14:11  Lr: 0.001875  Loss: -0.5751  Acc@1: 87.5000 (86.6860)  Acc@5: 100.0000 (98.5980)  time: 0.3500  data: 0.0007  max mem: 2502
Train: Epoch[4/5]  [ 700/3125]  eta: 0:14:08  Lr: 0.001875  Loss: -0.5865  Acc@1: 87.5000 (86.6887)  Acc@5: 100.0000 (98.6002)  time: 0.3507  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [ 710/3125]  eta: 0:14:04  Lr: 0.001875  Loss: -0.6390  Acc@1: 87.5000 (86.7001)  Acc@5: 100.0000 (98.5935)  time: 0.3500  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [ 720/3125]  eta: 0:14:01  Lr: 0.001875  Loss: -0.6426  Acc@1: 87.5000 (86.7458)  Acc@5: 100.0000 (98.5784)  time: 0.3498  data: 0.0007  max mem: 2502
Train: Epoch[4/5]  [ 730/3125]  eta: 0:13:57  Lr: 0.001875  Loss: -0.5081  Acc@1: 87.5000 (86.7391)  Acc@5: 100.0000 (98.5722)  time: 0.3499  data: 0.0008  max mem: 2502
Train: Epoch[4/5]  [ 740/3125]  eta: 0:13:54  Lr: 0.001875  Loss: -0.6776  Acc@1: 87.5000 (86.7072)  Acc@5: 100.0000 (98.5746)  time: 0.3492  data: 0.0008  max mem: 2502
Train: Epoch[4/5]  [ 750/3125]  eta: 0:13:50  Lr: 0.001875  Loss: -0.3029  Acc@1: 87.5000 (86.7260)  Acc@5: 100.0000 (98.5686)  time: 0.3487  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [ 760/3125]  eta: 0:13:47  Lr: 0.001875  Loss: -0.5970  Acc@1: 81.2500 (86.6787)  Acc@5: 100.0000 (98.5545)  time: 0.3487  data: 0.0006  max mem: 2502
Train: Epoch[4/5]  [ 770/3125]  eta: 0:13:43  Lr: 0.001875  Loss: 0.2733  Acc@1: 87.5000 (86.6732)  Acc@5: 100.0000 (98.5490)  time: 0.3488  data: 0.0006  max mem: 2502
Train: Epoch[4/5]  [ 780/3125]  eta: 0:13:40  Lr: 0.001875  Loss: -0.5970  Acc@1: 87.5000 (86.7157)  Acc@5: 100.0000 (98.5515)  time: 0.3503  data: 0.0007  max mem: 2502
Train: Epoch[4/5]  [ 790/3125]  eta: 0:13:36  Lr: 0.001875  Loss: -0.5901  Acc@1: 87.5000 (86.7810)  Acc@5: 100.0000 (98.5619)  time: 0.3517  data: 0.0007  max mem: 2502
Train: Epoch[4/5]  [ 800/3125]  eta: 0:13:33  Lr: 0.001875  Loss: -0.3217  Acc@1: 87.5000 (86.7509)  Acc@5: 100.0000 (98.5721)  time: 0.3499  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [ 810/3125]  eta: 0:13:29  Lr: 0.001875  Loss: -0.6281  Acc@1: 87.5000 (86.7756)  Acc@5: 100.0000 (98.5743)  time: 0.3489  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [ 820/3125]  eta: 0:13:26  Lr: 0.001875  Loss: -0.6501  Acc@1: 87.5000 (86.7387)  Acc@5: 100.0000 (98.5840)  time: 0.3485  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [ 830/3125]  eta: 0:13:22  Lr: 0.001875  Loss: -0.7231  Acc@1: 87.5000 (86.7930)  Acc@5: 100.0000 (98.5860)  time: 0.3485  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [ 840/3125]  eta: 0:13:19  Lr: 0.001875  Loss: -0.4050  Acc@1: 87.5000 (86.7940)  Acc@5: 100.0000 (98.5880)  time: 0.3489  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [ 850/3125]  eta: 0:13:15  Lr: 0.001875  Loss: -0.6619  Acc@1: 87.5000 (86.8170)  Acc@5: 100.0000 (98.5972)  time: 0.3489  data: 0.0012  max mem: 2502
Train: Epoch[4/5]  [ 860/3125]  eta: 0:13:12  Lr: 0.001875  Loss: -0.6979  Acc@1: 87.5000 (86.8031)  Acc@5: 100.0000 (98.5918)  time: 0.3512  data: 0.0019  max mem: 2502
Train: Epoch[4/5]  [ 870/3125]  eta: 0:13:08  Lr: 0.001875  Loss: -0.5797  Acc@1: 87.5000 (86.8183)  Acc@5: 100.0000 (98.6007)  time: 0.3517  data: 0.0012  max mem: 2502
Train: Epoch[4/5]  [ 880/3125]  eta: 0:13:05  Lr: 0.001875  Loss: -0.6898  Acc@1: 87.5000 (86.8473)  Acc@5: 100.0000 (98.6166)  time: 0.3507  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [ 890/3125]  eta: 0:13:01  Lr: 0.001875  Loss: -0.6639  Acc@1: 93.7500 (86.8897)  Acc@5: 100.0000 (98.6041)  time: 0.3503  data: 0.0007  max mem: 2502
Train: Epoch[4/5]  [ 900/3125]  eta: 0:12:58  Lr: 0.001875  Loss: -0.4182  Acc@1: 93.7500 (86.9104)  Acc@5: 100.0000 (98.6057)  time: 0.3489  data: 0.0008  max mem: 2502
Train: Epoch[4/5]  [ 910/3125]  eta: 0:12:54  Lr: 0.001875  Loss: -0.4314  Acc@1: 87.5000 (86.9100)  Acc@5: 100.0000 (98.6142)  time: 0.3486  data: 0.0006  max mem: 2502
Train: Epoch[4/5]  [ 920/3125]  eta: 0:12:51  Lr: 0.001875  Loss: -0.6884  Acc@1: 87.5000 (86.9503)  Acc@5: 100.0000 (98.6021)  time: 0.3487  data: 0.0006  max mem: 2502
Train: Epoch[4/5]  [ 930/3125]  eta: 0:12:47  Lr: 0.001875  Loss: -0.2731  Acc@1: 87.5000 (86.9294)  Acc@5: 100.0000 (98.5835)  time: 0.3496  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [ 940/3125]  eta: 0:12:44  Lr: 0.001875  Loss: -0.1326  Acc@1: 81.2500 (86.8690)  Acc@5: 100.0000 (98.5786)  time: 0.3496  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [ 950/3125]  eta: 0:12:40  Lr: 0.001875  Loss: -0.1937  Acc@1: 81.2500 (86.8691)  Acc@5: 100.0000 (98.5739)  time: 0.3492  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [ 960/3125]  eta: 0:12:37  Lr: 0.001875  Loss: -0.0635  Acc@1: 87.5000 (86.8691)  Acc@5: 100.0000 (98.5627)  time: 0.3496  data: 0.0006  max mem: 2502
Train: Epoch[4/5]  [ 970/3125]  eta: 0:12:33  Lr: 0.001875  Loss: -0.6837  Acc@1: 81.2500 (86.8370)  Acc@5: 100.0000 (98.5582)  time: 0.3493  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [ 980/3125]  eta: 0:12:30  Lr: 0.001875  Loss: -0.7792  Acc@1: 93.7500 (86.9011)  Acc@5: 100.0000 (98.5665)  time: 0.3494  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [ 990/3125]  eta: 0:12:26  Lr: 0.001875  Loss: -0.4444  Acc@1: 93.7500 (86.9387)  Acc@5: 100.0000 (98.5684)  time: 0.3491  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [1000/3125]  eta: 0:12:23  Lr: 0.001875  Loss: -0.8112  Acc@1: 87.5000 (86.9755)  Acc@5: 100.0000 (98.5639)  time: 0.3484  data: 0.0006  max mem: 2502
Train: Epoch[4/5]  [1010/3125]  eta: 0:12:19  Lr: 0.001875  Loss: -0.1721  Acc@1: 87.5000 (86.9931)  Acc@5: 100.0000 (98.5720)  time: 0.3495  data: 0.0016  max mem: 2502
Train: Epoch[4/5]  [1020/3125]  eta: 0:12:16  Lr: 0.001875  Loss: -0.7558  Acc@1: 87.5000 (86.9980)  Acc@5: 100.0000 (98.5676)  time: 0.3496  data: 0.0015  max mem: 2502
Train: Epoch[4/5]  [1030/3125]  eta: 0:12:12  Lr: 0.001875  Loss: -0.4615  Acc@1: 87.5000 (86.9968)  Acc@5: 100.0000 (98.5633)  time: 0.3492  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [1040/3125]  eta: 0:12:09  Lr: 0.001875  Loss: -0.2760  Acc@1: 87.5000 (86.9657)  Acc@5: 100.0000 (98.5711)  time: 0.3505  data: 0.0007  max mem: 2502
Train: Epoch[4/5]  [1050/3125]  eta: 0:12:05  Lr: 0.001875  Loss: -0.4264  Acc@1: 81.2500 (86.9588)  Acc@5: 100.0000 (98.5609)  time: 0.3496  data: 0.0008  max mem: 2502
Train: Epoch[4/5]  [1060/3125]  eta: 0:12:02  Lr: 0.001875  Loss: -0.2867  Acc@1: 87.5000 (86.9463)  Acc@5: 100.0000 (98.5686)  time: 0.3483  data: 0.0006  max mem: 2502
Train: Epoch[4/5]  [1070/3125]  eta: 0:11:58  Lr: 0.001875  Loss: -0.5232  Acc@1: 87.5000 (86.9690)  Acc@5: 100.0000 (98.5761)  time: 0.3490  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [1080/3125]  eta: 0:11:55  Lr: 0.001875  Loss: -0.4860  Acc@1: 87.5000 (86.9912)  Acc@5: 100.0000 (98.5777)  time: 0.3492  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [1090/3125]  eta: 0:11:51  Lr: 0.001875  Loss: -0.3519  Acc@1: 87.5000 (86.9901)  Acc@5: 100.0000 (98.5736)  time: 0.3496  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [1100/3125]  eta: 0:11:48  Lr: 0.001875  Loss: -0.0366  Acc@1: 87.5000 (86.9437)  Acc@5: 100.0000 (98.5752)  time: 0.3508  data: 0.0006  max mem: 2502
Train: Epoch[4/5]  [1110/3125]  eta: 0:11:44  Lr: 0.001875  Loss: -0.5721  Acc@1: 87.5000 (86.8868)  Acc@5: 100.0000 (98.5767)  time: 0.3505  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [1120/3125]  eta: 0:11:41  Lr: 0.001875  Loss: -0.5823  Acc@1: 87.5000 (86.8867)  Acc@5: 100.0000 (98.5783)  time: 0.3490  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [1130/3125]  eta: 0:11:37  Lr: 0.001875  Loss: -0.1497  Acc@1: 87.5000 (86.8700)  Acc@5: 100.0000 (98.5743)  time: 0.3502  data: 0.0006  max mem: 2502
Train: Epoch[4/5]  [1140/3125]  eta: 0:11:34  Lr: 0.001875  Loss: -0.6521  Acc@1: 87.5000 (86.8920)  Acc@5: 100.0000 (98.5813)  time: 0.3512  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [1150/3125]  eta: 0:11:30  Lr: 0.001875  Loss: -0.5511  Acc@1: 87.5000 (86.8864)  Acc@5: 100.0000 (98.5719)  time: 0.3501  data: 0.0006  max mem: 2502
Train: Epoch[4/5]  [1160/3125]  eta: 0:11:27  Lr: 0.001875  Loss: -0.2596  Acc@1: 87.5000 (86.9078)  Acc@5: 100.0000 (98.5734)  time: 0.3494  data: 0.0006  max mem: 2502
Train: Epoch[4/5]  [1170/3125]  eta: 0:11:23  Lr: 0.001875  Loss: -0.8748  Acc@1: 93.7500 (86.9449)  Acc@5: 100.0000 (98.5749)  time: 0.3480  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [1180/3125]  eta: 0:11:20  Lr: 0.001875  Loss: -0.2694  Acc@1: 87.5000 (86.9549)  Acc@5: 100.0000 (98.5817)  time: 0.3475  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [1190/3125]  eta: 0:11:16  Lr: 0.001875  Loss: -0.5444  Acc@1: 87.5000 (86.9280)  Acc@5: 100.0000 (98.5674)  time: 0.3481  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [1200/3125]  eta: 0:11:13  Lr: 0.001875  Loss: -0.7241  Acc@1: 81.2500 (86.9276)  Acc@5: 100.0000 (98.5637)  time: 0.3487  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [1210/3125]  eta: 0:11:09  Lr: 0.001875  Loss: -0.7032  Acc@1: 87.5000 (86.9529)  Acc@5: 100.0000 (98.5756)  time: 0.3499  data: 0.0008  max mem: 2502
Train: Epoch[4/5]  [1220/3125]  eta: 0:11:06  Lr: 0.001875  Loss: -0.7282  Acc@1: 81.2500 (86.9062)  Acc@5: 100.0000 (98.5770)  time: 0.3498  data: 0.0009  max mem: 2502
Train: Epoch[4/5]  [1230/3125]  eta: 0:11:02  Lr: 0.001875  Loss: -0.5232  Acc@1: 81.2500 (86.8907)  Acc@5: 100.0000 (98.5733)  time: 0.3485  data: 0.0006  max mem: 2502
Train: Epoch[4/5]  [1240/3125]  eta: 0:10:59  Lr: 0.001875  Loss: -0.4908  Acc@1: 87.5000 (86.8956)  Acc@5: 100.0000 (98.5798)  time: 0.3485  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [1250/3125]  eta: 0:10:55  Lr: 0.001875  Loss: -0.9043  Acc@1: 87.5000 (86.9205)  Acc@5: 100.0000 (98.5911)  time: 0.3489  data: 0.0008  max mem: 2502
Train: Epoch[4/5]  [1260/3125]  eta: 0:10:51  Lr: 0.001875  Loss: -0.7573  Acc@1: 87.5000 (86.9350)  Acc@5: 100.0000 (98.5973)  time: 0.3489  data: 0.0009  max mem: 2502
Train: Epoch[4/5]  [1270/3125]  eta: 0:10:48  Lr: 0.001875  Loss: -0.3606  Acc@1: 87.5000 (86.9493)  Acc@5: 100.0000 (98.6035)  time: 0.3492  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [1280/3125]  eta: 0:10:45  Lr: 0.001875  Loss: -0.7410  Acc@1: 87.5000 (86.9487)  Acc@5: 100.0000 (98.6095)  time: 0.3498  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [1290/3125]  eta: 0:10:41  Lr: 0.001875  Loss: -0.7705  Acc@1: 87.5000 (86.9481)  Acc@5: 100.0000 (98.6154)  time: 0.3492  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [1300/3125]  eta: 0:10:37  Lr: 0.001875  Loss: -0.3826  Acc@1: 87.5000 (86.9475)  Acc@5: 100.0000 (98.6261)  time: 0.3480  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [1310/3125]  eta: 0:10:34  Lr: 0.001875  Loss: -0.4963  Acc@1: 87.5000 (86.9470)  Acc@5: 100.0000 (98.6222)  time: 0.3480  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [1320/3125]  eta: 0:10:30  Lr: 0.001875  Loss: -0.5154  Acc@1: 87.5000 (86.9228)  Acc@5: 100.0000 (98.6232)  time: 0.3491  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [1330/3125]  eta: 0:10:27  Lr: 0.001875  Loss: -0.4657  Acc@1: 87.5000 (86.9365)  Acc@5: 100.0000 (98.6335)  time: 0.3499  data: 0.0007  max mem: 2502
Train: Epoch[4/5]  [1340/3125]  eta: 0:10:24  Lr: 0.001875  Loss: -0.6142  Acc@1: 87.5000 (86.9314)  Acc@5: 100.0000 (98.6111)  time: 0.3509  data: 0.0007  max mem: 2502
Train: Epoch[4/5]  [1350/3125]  eta: 0:10:20  Lr: 0.001875  Loss: -0.7202  Acc@1: 87.5000 (86.9310)  Acc@5: 100.0000 (98.6121)  time: 0.3510  data: 0.0006  max mem: 2502
Train: Epoch[4/5]  [1360/3125]  eta: 0:10:17  Lr: 0.001875  Loss: -0.2414  Acc@1: 87.5000 (86.9168)  Acc@5: 100.0000 (98.6177)  time: 0.3500  data: 0.0013  max mem: 2502
Train: Epoch[4/5]  [1370/3125]  eta: 0:10:13  Lr: 0.001875  Loss: -0.6411  Acc@1: 87.5000 (86.9256)  Acc@5: 100.0000 (98.6233)  time: 0.3496  data: 0.0014  max mem: 2502
Train: Epoch[4/5]  [1380/3125]  eta: 0:10:10  Lr: 0.001875  Loss: -0.8882  Acc@1: 87.5000 (86.9252)  Acc@5: 100.0000 (98.6242)  time: 0.3494  data: 0.0013  max mem: 2502
Train: Epoch[4/5]  [1390/3125]  eta: 0:10:06  Lr: 0.001875  Loss: -0.5059  Acc@1: 87.5000 (86.9204)  Acc@5: 100.0000 (98.6161)  time: 0.3505  data: 0.0015  max mem: 2502
Train: Epoch[4/5]  [1400/3125]  eta: 0:10:03  Lr: 0.001875  Loss: -0.4115  Acc@1: 87.5000 (86.9156)  Acc@5: 100.0000 (98.6171)  time: 0.3505  data: 0.0015  max mem: 2502
Train: Epoch[4/5]  [1410/3125]  eta: 0:09:59  Lr: 0.001875  Loss: -0.3724  Acc@1: 87.5000 (86.9242)  Acc@5: 100.0000 (98.6224)  time: 0.3507  data: 0.0014  max mem: 2502
Train: Epoch[4/5]  [1420/3125]  eta: 0:09:56  Lr: 0.001875  Loss: -0.3439  Acc@1: 81.2500 (86.8842)  Acc@5: 100.0000 (98.6277)  time: 0.3526  data: 0.0007  max mem: 2502
Train: Epoch[4/5]  [1430/3125]  eta: 0:09:52  Lr: 0.001875  Loss: -0.5314  Acc@1: 81.2500 (86.9016)  Acc@5: 100.0000 (98.6286)  time: 0.3526  data: 0.0006  max mem: 2502
Train: Epoch[4/5]  [1440/3125]  eta: 0:09:49  Lr: 0.001875  Loss: -0.6296  Acc@1: 87.5000 (86.8841)  Acc@5: 100.0000 (98.6381)  time: 0.3506  data: 0.0006  max mem: 2502
Train: Epoch[4/5]  [1450/3125]  eta: 0:09:45  Lr: 0.001875  Loss: -0.7963  Acc@1: 87.5000 (86.8754)  Acc@5: 100.0000 (98.6216)  time: 0.3497  data: 0.0014  max mem: 2502
Train: Epoch[4/5]  [1460/3125]  eta: 0:09:42  Lr: 0.001875  Loss: -0.4881  Acc@1: 81.2500 (86.8583)  Acc@5: 100.0000 (98.6225)  time: 0.3510  data: 0.0014  max mem: 2502
Train: Epoch[4/5]  [1470/3125]  eta: 0:09:38  Lr: 0.001875  Loss: -0.3613  Acc@1: 81.2500 (86.8287)  Acc@5: 100.0000 (98.6191)  time: 0.3511  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [1480/3125]  eta: 0:09:35  Lr: 0.001875  Loss: -0.3311  Acc@1: 81.2500 (86.8121)  Acc@5: 100.0000 (98.6158)  time: 0.3500  data: 0.0012  max mem: 2502
Train: Epoch[4/5]  [1490/3125]  eta: 0:09:31  Lr: 0.001875  Loss: -0.4740  Acc@1: 87.5000 (86.8167)  Acc@5: 100.0000 (98.6167)  time: 0.3495  data: 0.0014  max mem: 2502
Train: Epoch[4/5]  [1500/3125]  eta: 0:09:28  Lr: 0.001875  Loss: -0.6018  Acc@1: 87.5000 (86.8254)  Acc@5: 100.0000 (98.6134)  time: 0.3492  data: 0.0007  max mem: 2502
Train: Epoch[4/5]  [1510/3125]  eta: 0:09:24  Lr: 0.001875  Loss: -0.1966  Acc@1: 87.5000 (86.7927)  Acc@5: 100.0000 (98.6185)  time: 0.3494  data: 0.0007  max mem: 2502
Train: Epoch[4/5]  [1520/3125]  eta: 0:09:21  Lr: 0.001875  Loss: -0.6004  Acc@1: 87.5000 (86.7809)  Acc@5: 100.0000 (98.6193)  time: 0.3495  data: 0.0008  max mem: 2502
Train: Epoch[4/5]  [1530/3125]  eta: 0:09:17  Lr: 0.001875  Loss: -0.6252  Acc@1: 87.5000 (86.7938)  Acc@5: 100.0000 (98.6202)  time: 0.3486  data: 0.0006  max mem: 2502
Train: Epoch[4/5]  [1540/3125]  eta: 0:09:14  Lr: 0.001875  Loss: -0.7545  Acc@1: 93.7500 (86.8186)  Acc@5: 100.0000 (98.6170)  time: 0.3486  data: 0.0016  max mem: 2502
Train: Epoch[4/5]  [1550/3125]  eta: 0:09:10  Lr: 0.001875  Loss: -0.7485  Acc@1: 93.7500 (86.8311)  Acc@5: 100.0000 (98.6098)  time: 0.3489  data: 0.0019  max mem: 2502
Train: Epoch[4/5]  [1560/3125]  eta: 0:09:07  Lr: 0.001875  Loss: -0.7096  Acc@1: 87.5000 (86.8274)  Acc@5: 100.0000 (98.6187)  time: 0.3471  data: 0.0009  max mem: 2502
Train: Epoch[4/5]  [1570/3125]  eta: 0:09:03  Lr: 0.001875  Loss: -0.3607  Acc@1: 87.5000 (86.8038)  Acc@5: 100.0000 (98.6195)  time: 0.3472  data: 0.0007  max mem: 2502
Train: Epoch[4/5]  [1580/3125]  eta: 0:09:00  Lr: 0.001875  Loss: -0.4498  Acc@1: 81.2500 (86.8082)  Acc@5: 100.0000 (98.6164)  time: 0.3479  data: 0.0009  max mem: 2502
Train: Epoch[4/5]  [1590/3125]  eta: 0:08:56  Lr: 0.001875  Loss: -0.4182  Acc@1: 81.2500 (86.7890)  Acc@5: 100.0000 (98.6133)  time: 0.3476  data: 0.0007  max mem: 2502
Train: Epoch[4/5]  [1600/3125]  eta: 0:08:53  Lr: 0.001875  Loss: -0.6305  Acc@1: 87.5000 (86.7817)  Acc@5: 100.0000 (98.6102)  time: 0.3486  data: 0.0007  max mem: 2502
Train: Epoch[4/5]  [1610/3125]  eta: 0:08:49  Lr: 0.001875  Loss: -0.5911  Acc@1: 87.5000 (86.7939)  Acc@5: 100.0000 (98.6150)  time: 0.3503  data: 0.0012  max mem: 2502
Train: Epoch[4/5]  [1620/3125]  eta: 0:08:46  Lr: 0.001875  Loss: -0.5358  Acc@1: 87.5000 (86.7829)  Acc@5: 100.0000 (98.6120)  time: 0.3511  data: 0.0011  max mem: 2502
Train: Epoch[4/5]  [1630/3125]  eta: 0:08:42  Lr: 0.001875  Loss: -0.5810  Acc@1: 81.2500 (86.7681)  Acc@5: 100.0000 (98.6128)  time: 0.3494  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [1640/3125]  eta: 0:08:39  Lr: 0.001875  Loss: -0.2478  Acc@1: 81.2500 (86.7535)  Acc@5: 100.0000 (98.6175)  time: 0.3485  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [1650/3125]  eta: 0:08:35  Lr: 0.001875  Loss: -0.8621  Acc@1: 81.2500 (86.7505)  Acc@5: 100.0000 (98.6258)  time: 0.3487  data: 0.0006  max mem: 2502
Train: Epoch[4/5]  [1660/3125]  eta: 0:08:32  Lr: 0.001875  Loss: -0.6217  Acc@1: 81.2500 (86.7512)  Acc@5: 100.0000 (98.6266)  time: 0.3485  data: 0.0007  max mem: 2502
Train: Epoch[4/5]  [1670/3125]  eta: 0:08:28  Lr: 0.001875  Loss: -0.6202  Acc@1: 81.2500 (86.7145)  Acc@5: 100.0000 (98.6198)  time: 0.3482  data: 0.0007  max mem: 2502
Train: Epoch[4/5]  [1680/3125]  eta: 0:08:25  Lr: 0.001875  Loss: -0.4171  Acc@1: 81.2500 (86.6932)  Acc@5: 100.0000 (98.6169)  time: 0.3481  data: 0.0007  max mem: 2502
Train: Epoch[4/5]  [1690/3125]  eta: 0:08:21  Lr: 0.001875  Loss: -0.3696  Acc@1: 87.5000 (86.6906)  Acc@5: 100.0000 (98.6214)  time: 0.3494  data: 0.0013  max mem: 2502
Train: Epoch[4/5]  [1700/3125]  eta: 0:08:18  Lr: 0.001875  Loss: 0.1212  Acc@1: 87.5000 (86.6880)  Acc@5: 100.0000 (98.6111)  time: 0.3497  data: 0.0013  max mem: 2502
Train: Epoch[4/5]  [1710/3125]  eta: 0:08:14  Lr: 0.001875  Loss: -0.5205  Acc@1: 87.5000 (86.7073)  Acc@5: 100.0000 (98.6156)  time: 0.3495  data: 0.0006  max mem: 2502
Train: Epoch[4/5]  [1720/3125]  eta: 0:08:11  Lr: 0.001875  Loss: -0.4973  Acc@1: 87.5000 (86.7010)  Acc@5: 100.0000 (98.6018)  time: 0.3505  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [1730/3125]  eta: 0:08:07  Lr: 0.001875  Loss: -0.3104  Acc@1: 87.5000 (86.6804)  Acc@5: 100.0000 (98.6027)  time: 0.3510  data: 0.0006  max mem: 2502
Train: Epoch[4/5]  [1740/3125]  eta: 0:08:04  Lr: 0.001875  Loss: -0.3708  Acc@1: 81.2500 (86.6743)  Acc@5: 100.0000 (98.5964)  time: 0.3505  data: 0.0006  max mem: 2502
Train: Epoch[4/5]  [1750/3125]  eta: 0:08:00  Lr: 0.001875  Loss: -0.7056  Acc@1: 87.5000 (86.7005)  Acc@5: 100.0000 (98.5901)  time: 0.3519  data: 0.0007  max mem: 2502
Train: Epoch[4/5]  [1760/3125]  eta: 0:07:57  Lr: 0.001875  Loss: 0.0318  Acc@1: 93.7500 (86.7121)  Acc@5: 100.0000 (98.5839)  time: 0.3517  data: 0.0007  max mem: 2502
Train: Epoch[4/5]  [1770/3125]  eta: 0:07:53  Lr: 0.001875  Loss: -0.8253  Acc@1: 93.7500 (86.7201)  Acc@5: 100.0000 (98.5778)  time: 0.3502  data: 0.0007  max mem: 2502
Train: Epoch[4/5]  [1780/3125]  eta: 0:07:50  Lr: 0.001875  Loss: -0.5471  Acc@1: 87.5000 (86.7174)  Acc@5: 100.0000 (98.5858)  time: 0.3491  data: 0.0007  max mem: 2502
Train: Epoch[4/5]  [1790/3125]  eta: 0:07:46  Lr: 0.001875  Loss: -0.5269  Acc@1: 87.5000 (86.7009)  Acc@5: 100.0000 (98.5867)  time: 0.3473  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [1800/3125]  eta: 0:07:43  Lr: 0.001875  Loss: -0.6653  Acc@1: 87.5000 (86.7053)  Acc@5: 100.0000 (98.5841)  time: 0.3473  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [1810/3125]  eta: 0:07:39  Lr: 0.001875  Loss: -0.3084  Acc@1: 87.5000 (86.7097)  Acc@5: 100.0000 (98.5816)  time: 0.3482  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [1820/3125]  eta: 0:07:36  Lr: 0.001875  Loss: -0.5135  Acc@1: 87.5000 (86.7072)  Acc@5: 100.0000 (98.5859)  time: 0.3498  data: 0.0006  max mem: 2502
Train: Epoch[4/5]  [1830/3125]  eta: 0:07:32  Lr: 0.001875  Loss: -0.5901  Acc@1: 87.5000 (86.7149)  Acc@5: 100.0000 (98.5937)  time: 0.3490  data: 0.0007  max mem: 2502
Train: Epoch[4/5]  [1840/3125]  eta: 0:07:29  Lr: 0.001875  Loss: -0.3671  Acc@1: 81.2500 (86.6886)  Acc@5: 100.0000 (98.5945)  time: 0.3471  data: 0.0008  max mem: 2502
Train: Epoch[4/5]  [1850/3125]  eta: 0:07:25  Lr: 0.001875  Loss: -0.6175  Acc@1: 81.2500 (86.6694)  Acc@5: 100.0000 (98.5987)  time: 0.3472  data: 0.0007  max mem: 2502
Train: Epoch[4/5]  [1860/3125]  eta: 0:07:22  Lr: 0.001875  Loss: -0.7749  Acc@1: 81.2500 (86.6705)  Acc@5: 100.0000 (98.5995)  time: 0.3497  data: 0.0010  max mem: 2502
Train: Epoch[4/5]  [1870/3125]  eta: 0:07:18  Lr: 0.001875  Loss: -0.6613  Acc@1: 87.5000 (86.6582)  Acc@5: 100.0000 (98.5970)  time: 0.3497  data: 0.0014  max mem: 2502
Train: Epoch[4/5]  [1880/3125]  eta: 0:07:15  Lr: 0.001875  Loss: -0.5091  Acc@1: 87.5000 (86.6627)  Acc@5: 100.0000 (98.5945)  time: 0.3481  data: 0.0010  max mem: 2502
Train: Epoch[4/5]  [1890/3125]  eta: 0:07:11  Lr: 0.001875  Loss: -0.5640  Acc@1: 87.5000 (86.6671)  Acc@5: 100.0000 (98.5986)  time: 0.3481  data: 0.0008  max mem: 2502
Train: Epoch[4/5]  [1900/3125]  eta: 0:07:08  Lr: 0.001875  Loss: -0.8243  Acc@1: 87.5000 (86.6846)  Acc@5: 100.0000 (98.6027)  time: 0.3480  data: 0.0013  max mem: 2502
Train: Epoch[4/5]  [1910/3125]  eta: 0:07:04  Lr: 0.001875  Loss: -0.8793  Acc@1: 87.5000 (86.6987)  Acc@5: 100.0000 (98.6035)  time: 0.3475  data: 0.0012  max mem: 2502
Train: Epoch[4/5]  [1920/3125]  eta: 0:07:01  Lr: 0.001875  Loss: -0.5045  Acc@1: 87.5000 (86.6931)  Acc@5: 100.0000 (98.6010)  time: 0.3470  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [1930/3125]  eta: 0:06:57  Lr: 0.001875  Loss: -0.7942  Acc@1: 81.2500 (86.6811)  Acc@5: 100.0000 (98.5953)  time: 0.3479  data: 0.0008  max mem: 2502
Train: Epoch[4/5]  [1940/3125]  eta: 0:06:54  Lr: 0.001875  Loss: -0.6985  Acc@1: 81.2500 (86.6660)  Acc@5: 100.0000 (98.5961)  time: 0.3481  data: 0.0009  max mem: 2502
Train: Epoch[4/5]  [1950/3125]  eta: 0:06:50  Lr: 0.001875  Loss: -0.5131  Acc@1: 81.2500 (86.6479)  Acc@5: 100.0000 (98.5969)  time: 0.3475  data: 0.0006  max mem: 2502
Train: Epoch[4/5]  [1960/3125]  eta: 0:06:47  Lr: 0.001875  Loss: -0.4994  Acc@1: 87.5000 (86.6650)  Acc@5: 100.0000 (98.6008)  time: 0.3491  data: 0.0008  max mem: 2502
Train: Epoch[4/5]  [1970/3125]  eta: 0:06:43  Lr: 0.001875  Loss: -0.3170  Acc@1: 87.5000 (86.6502)  Acc@5: 100.0000 (98.5984)  time: 0.3518  data: 0.0009  max mem: 2502
Train: Epoch[4/5]  [1980/3125]  eta: 0:06:40  Lr: 0.001875  Loss: -0.5021  Acc@1: 87.5000 (86.6639)  Acc@5: 100.0000 (98.6023)  time: 0.3512  data: 0.0013  max mem: 2502
Train: Epoch[4/5]  [1990/3125]  eta: 0:06:36  Lr: 0.001875  Loss: -0.4898  Acc@1: 87.5000 (86.6524)  Acc@5: 100.0000 (98.6031)  time: 0.3491  data: 0.0012  max mem: 2502
Train: Epoch[4/5]  [2000/3125]  eta: 0:06:33  Lr: 0.001875  Loss: -0.5962  Acc@1: 87.5000 (86.6567)  Acc@5: 100.0000 (98.6038)  time: 0.3489  data: 0.0007  max mem: 2502
Train: Epoch[4/5]  [2010/3125]  eta: 0:06:29  Lr: 0.001875  Loss: -0.7103  Acc@1: 87.5000 (86.6795)  Acc@5: 100.0000 (98.6077)  time: 0.3490  data: 0.0006  max mem: 2502
Train: Epoch[4/5]  [2020/3125]  eta: 0:06:26  Lr: 0.001875  Loss: -0.5691  Acc@1: 87.5000 (86.6650)  Acc@5: 100.0000 (98.6053)  time: 0.3501  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [2030/3125]  eta: 0:06:22  Lr: 0.001875  Loss: -0.5497  Acc@1: 87.5000 (86.6845)  Acc@5: 100.0000 (98.6029)  time: 0.3501  data: 0.0006  max mem: 2502
Train: Epoch[4/5]  [2040/3125]  eta: 0:06:19  Lr: 0.001875  Loss: -0.6409  Acc@1: 93.7500 (86.6946)  Acc@5: 100.0000 (98.5975)  time: 0.3487  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [2050/3125]  eta: 0:06:15  Lr: 0.001875  Loss: -0.4495  Acc@1: 87.5000 (86.6955)  Acc@5: 100.0000 (98.5952)  time: 0.3501  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [2060/3125]  eta: 0:06:12  Lr: 0.001875  Loss: -0.6274  Acc@1: 87.5000 (86.7115)  Acc@5: 100.0000 (98.5959)  time: 0.3511  data: 0.0006  max mem: 2502
Train: Epoch[4/5]  [2070/3125]  eta: 0:06:08  Lr: 0.001875  Loss: -0.7660  Acc@1: 87.5000 (86.7033)  Acc@5: 100.0000 (98.5907)  time: 0.3508  data: 0.0007  max mem: 2502
Train: Epoch[4/5]  [2080/3125]  eta: 0:06:05  Lr: 0.001875  Loss: -0.1620  Acc@1: 87.5000 (86.6891)  Acc@5: 100.0000 (98.5914)  time: 0.3507  data: 0.0006  max mem: 2502
Train: Epoch[4/5]  [2090/3125]  eta: 0:06:01  Lr: 0.001875  Loss: -0.1468  Acc@1: 87.5000 (86.6930)  Acc@5: 100.0000 (98.5892)  time: 0.3497  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [2100/3125]  eta: 0:05:58  Lr: 0.001875  Loss: -0.6234  Acc@1: 87.5000 (86.6968)  Acc@5: 100.0000 (98.5900)  time: 0.3510  data: 0.0013  max mem: 2502
Train: Epoch[4/5]  [2110/3125]  eta: 0:05:54  Lr: 0.001875  Loss: -0.3948  Acc@1: 87.5000 (86.6977)  Acc@5: 100.0000 (98.5848)  time: 0.3504  data: 0.0013  max mem: 2502
Train: Epoch[4/5]  [2120/3125]  eta: 0:05:51  Lr: 0.001875  Loss: -0.6478  Acc@1: 87.5000 (86.6867)  Acc@5: 100.0000 (98.5767)  time: 0.3504  data: 0.0007  max mem: 2502
Train: Epoch[4/5]  [2130/3125]  eta: 0:05:47  Lr: 0.001875  Loss: -0.5979  Acc@1: 81.2500 (86.6612)  Acc@5: 100.0000 (98.5746)  time: 0.3510  data: 0.0008  max mem: 2502
Train: Epoch[4/5]  [2140/3125]  eta: 0:05:44  Lr: 0.001875  Loss: -0.6895  Acc@1: 87.5000 (86.6593)  Acc@5: 100.0000 (98.5696)  time: 0.3490  data: 0.0007  max mem: 2502
Train: Epoch[4/5]  [2150/3125]  eta: 0:05:40  Lr: 0.001875  Loss: -0.2245  Acc@1: 87.5000 (86.6457)  Acc@5: 100.0000 (98.5733)  time: 0.3479  data: 0.0006  max mem: 2502
Train: Epoch[4/5]  [2160/3125]  eta: 0:05:37  Lr: 0.001875  Loss: -0.5725  Acc@1: 87.5000 (86.6699)  Acc@5: 100.0000 (98.5770)  time: 0.3479  data: 0.0010  max mem: 2502
Train: Epoch[4/5]  [2170/3125]  eta: 0:05:33  Lr: 0.001875  Loss: -0.5618  Acc@1: 93.7500 (86.6795)  Acc@5: 100.0000 (98.5750)  time: 0.3484  data: 0.0010  max mem: 2502
Train: Epoch[4/5]  [2180/3125]  eta: 0:05:30  Lr: 0.001875  Loss: -0.3697  Acc@1: 87.5000 (86.6919)  Acc@5: 100.0000 (98.5758)  time: 0.3476  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [2190/3125]  eta: 0:05:26  Lr: 0.001875  Loss: -0.7235  Acc@1: 87.5000 (86.6984)  Acc@5: 100.0000 (98.5794)  time: 0.3481  data: 0.0009  max mem: 2502
Train: Epoch[4/5]  [2200/3125]  eta: 0:05:23  Lr: 0.001875  Loss: -0.3795  Acc@1: 87.5000 (86.7077)  Acc@5: 100.0000 (98.5802)  time: 0.3487  data: 0.0012  max mem: 2502
Train: Epoch[4/5]  [2210/3125]  eta: 0:05:19  Lr: 0.001875  Loss: -0.9193  Acc@1: 87.5000 (86.7226)  Acc@5: 100.0000 (98.5810)  time: 0.3481  data: 0.0010  max mem: 2502
Train: Epoch[4/5]  [2220/3125]  eta: 0:05:16  Lr: 0.001875  Loss: -0.3653  Acc@1: 87.5000 (86.7121)  Acc@5: 100.0000 (98.5789)  time: 0.3486  data: 0.0007  max mem: 2502
Train: Epoch[4/5]  [2230/3125]  eta: 0:05:12  Lr: 0.001875  Loss: -0.6754  Acc@1: 87.5000 (86.7212)  Acc@5: 100.0000 (98.5769)  time: 0.3512  data: 0.0011  max mem: 2502
Train: Epoch[4/5]  [2240/3125]  eta: 0:05:09  Lr: 0.001875  Loss: -0.7089  Acc@1: 87.5000 (86.7247)  Acc@5: 100.0000 (98.5776)  time: 0.3519  data: 0.0014  max mem: 2502
Train: Epoch[4/5]  [2250/3125]  eta: 0:05:05  Lr: 0.001875  Loss: -0.7346  Acc@1: 87.5000 (86.7170)  Acc@5: 100.0000 (98.5729)  time: 0.3496  data: 0.0007  max mem: 2502
Train: Epoch[4/5]  [2260/3125]  eta: 0:05:02  Lr: 0.001875  Loss: -0.3547  Acc@1: 87.5000 (86.7067)  Acc@5: 100.0000 (98.5681)  time: 0.3485  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [2270/3125]  eta: 0:04:58  Lr: 0.001875  Loss: -0.5712  Acc@1: 87.5000 (86.7294)  Acc@5: 100.0000 (98.5717)  time: 0.3489  data: 0.0006  max mem: 2502
Train: Epoch[4/5]  [2280/3125]  eta: 0:04:55  Lr: 0.001875  Loss: -0.4467  Acc@1: 93.7500 (86.7492)  Acc@5: 100.0000 (98.5752)  time: 0.3485  data: 0.0006  max mem: 2502
Train: Epoch[4/5]  [2290/3125]  eta: 0:04:51  Lr: 0.001875  Loss: -0.7308  Acc@1: 87.5000 (86.7716)  Acc@5: 100.0000 (98.5759)  time: 0.3490  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [2300/3125]  eta: 0:04:48  Lr: 0.001875  Loss: -0.5874  Acc@1: 87.5000 (86.7856)  Acc@5: 100.0000 (98.5767)  time: 0.3490  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [2310/3125]  eta: 0:04:44  Lr: 0.001875  Loss: -0.7394  Acc@1: 87.5000 (86.7833)  Acc@5: 100.0000 (98.5748)  time: 0.3487  data: 0.0006  max mem: 2502
Train: Epoch[4/5]  [2320/3125]  eta: 0:04:41  Lr: 0.001875  Loss: -0.0345  Acc@1: 87.5000 (86.7756)  Acc@5: 100.0000 (98.5701)  time: 0.3484  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [2330/3125]  eta: 0:04:37  Lr: 0.001875  Loss: -0.7140  Acc@1: 81.2500 (86.7761)  Acc@5: 100.0000 (98.5709)  time: 0.3475  data: 0.0007  max mem: 2502
Train: Epoch[4/5]  [2340/3125]  eta: 0:04:34  Lr: 0.001875  Loss: 0.0396  Acc@1: 87.5000 (86.7578)  Acc@5: 100.0000 (98.5610)  time: 0.3475  data: 0.0007  max mem: 2502
Train: Epoch[4/5]  [2350/3125]  eta: 0:04:30  Lr: 0.001875  Loss: -0.4278  Acc@1: 87.5000 (86.7689)  Acc@5: 100.0000 (98.5618)  time: 0.3477  data: 0.0009  max mem: 2502
Train: Epoch[4/5]  [2360/3125]  eta: 0:04:27  Lr: 0.001875  Loss: -0.2944  Acc@1: 87.5000 (86.7667)  Acc@5: 100.0000 (98.5626)  time: 0.3488  data: 0.0021  max mem: 2502
Train: Epoch[4/5]  [2370/3125]  eta: 0:04:23  Lr: 0.001875  Loss: -0.4645  Acc@1: 87.5000 (86.7672)  Acc@5: 100.0000 (98.5581)  time: 0.3490  data: 0.0020  max mem: 2502
Train: Epoch[4/5]  [2380/3125]  eta: 0:04:20  Lr: 0.001875  Loss: -0.7114  Acc@1: 87.5000 (86.7571)  Acc@5: 100.0000 (98.5615)  time: 0.3489  data: 0.0019  max mem: 2502
Train: Epoch[4/5]  [2390/3125]  eta: 0:04:16  Lr: 0.001875  Loss: -0.2722  Acc@1: 87.5000 (86.7707)  Acc@5: 100.0000 (98.5597)  time: 0.3501  data: 0.0027  max mem: 2502
Train: Epoch[4/5]  [2400/3125]  eta: 0:04:13  Lr: 0.001875  Loss: -0.6997  Acc@1: 87.5000 (86.7711)  Acc@5: 100.0000 (98.5553)  time: 0.3488  data: 0.0019  max mem: 2502
Train: Epoch[4/5]  [2410/3125]  eta: 0:04:09  Lr: 0.001875  Loss: -0.2928  Acc@1: 87.5000 (86.7716)  Acc@5: 100.0000 (98.5509)  time: 0.3466  data: 0.0008  max mem: 2502
Train: Epoch[4/5]  [2420/3125]  eta: 0:04:06  Lr: 0.001875  Loss: -0.5842  Acc@1: 81.2500 (86.7617)  Acc@5: 100.0000 (98.5543)  time: 0.3470  data: 0.0009  max mem: 2502
Train: Epoch[4/5]  [2430/3125]  eta: 0:04:02  Lr: 0.001875  Loss: -0.3500  Acc@1: 81.2500 (86.7724)  Acc@5: 100.0000 (98.5577)  time: 0.3464  data: 0.0012  max mem: 2502
Train: Epoch[4/5]  [2440/3125]  eta: 0:03:59  Lr: 0.001875  Loss: -0.6317  Acc@1: 87.5000 (86.7780)  Acc@5: 100.0000 (98.5610)  time: 0.3471  data: 0.0011  max mem: 2502
Train: Epoch[4/5]  [2450/3125]  eta: 0:03:55  Lr: 0.001875  Loss: -0.6838  Acc@1: 87.5000 (86.7835)  Acc@5: 100.0000 (98.5669)  time: 0.3483  data: 0.0011  max mem: 2502
Train: Epoch[4/5]  [2460/3125]  eta: 0:03:52  Lr: 0.001875  Loss: -0.2988  Acc@1: 87.5000 (86.7762)  Acc@5: 100.0000 (98.5651)  time: 0.3474  data: 0.0007  max mem: 2502
Train: Epoch[4/5]  [2470/3125]  eta: 0:03:48  Lr: 0.001875  Loss: -0.7746  Acc@1: 87.5000 (86.7741)  Acc@5: 100.0000 (98.5684)  time: 0.3480  data: 0.0016  max mem: 2502
Train: Epoch[4/5]  [2480/3125]  eta: 0:03:45  Lr: 0.001875  Loss: -0.7128  Acc@1: 87.5000 (86.7619)  Acc@5: 100.0000 (98.5565)  time: 0.3478  data: 0.0016  max mem: 2502
Train: Epoch[4/5]  [2490/3125]  eta: 0:03:41  Lr: 0.001875  Loss: -0.6988  Acc@1: 87.5000 (86.7799)  Acc@5: 100.0000 (98.5598)  time: 0.3472  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [2500/3125]  eta: 0:03:38  Lr: 0.001875  Loss: -0.4766  Acc@1: 87.5000 (86.7878)  Acc@5: 100.0000 (98.5581)  time: 0.3488  data: 0.0008  max mem: 2502
Train: Epoch[4/5]  [2510/3125]  eta: 0:03:34  Lr: 0.001875  Loss: -0.5931  Acc@1: 87.5000 (86.8080)  Acc@5: 100.0000 (98.5539)  time: 0.3482  data: 0.0008  max mem: 2502
Train: Epoch[4/5]  [2520/3125]  eta: 0:03:31  Lr: 0.001875  Loss: -0.5384  Acc@1: 93.7500 (86.8182)  Acc@5: 100.0000 (98.5571)  time: 0.3472  data: 0.0006  max mem: 2502
Train: Epoch[4/5]  [2530/3125]  eta: 0:03:27  Lr: 0.001875  Loss: -0.7368  Acc@1: 87.5000 (86.8283)  Acc@5: 100.0000 (98.5628)  time: 0.3481  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [2540/3125]  eta: 0:03:24  Lr: 0.001875  Loss: -0.8935  Acc@1: 87.5000 (86.8408)  Acc@5: 100.0000 (98.5562)  time: 0.3495  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [2550/3125]  eta: 0:03:20  Lr: 0.001875  Loss: -0.1169  Acc@1: 87.5000 (86.8434)  Acc@5: 100.0000 (98.5569)  time: 0.3484  data: 0.0006  max mem: 2502
Train: Epoch[4/5]  [2560/3125]  eta: 0:03:17  Lr: 0.001875  Loss: -0.6767  Acc@1: 87.5000 (86.8362)  Acc@5: 100.0000 (98.5601)  time: 0.3473  data: 0.0008  max mem: 2502
Train: Epoch[4/5]  [2570/3125]  eta: 0:03:13  Lr: 0.001875  Loss: -0.7034  Acc@1: 87.5000 (86.8461)  Acc@5: 100.0000 (98.5584)  time: 0.3485  data: 0.0014  max mem: 2502
Train: Epoch[4/5]  [2580/3125]  eta: 0:03:10  Lr: 0.001875  Loss: -0.3519  Acc@1: 87.5000 (86.8341)  Acc@5: 100.0000 (98.5592)  time: 0.3485  data: 0.0011  max mem: 2502
Train: Epoch[4/5]  [2590/3125]  eta: 0:03:06  Lr: 0.001875  Loss: -0.5777  Acc@1: 87.5000 (86.8415)  Acc@5: 100.0000 (98.5623)  time: 0.3479  data: 0.0006  max mem: 2502
Train: Epoch[4/5]  [2600/3125]  eta: 0:03:03  Lr: 0.001875  Loss: -0.2369  Acc@1: 87.5000 (86.8368)  Acc@5: 100.0000 (98.5655)  time: 0.3477  data: 0.0010  max mem: 2502
Train: Epoch[4/5]  [2610/3125]  eta: 0:02:59  Lr: 0.001875  Loss: -0.6723  Acc@1: 87.5000 (86.8537)  Acc@5: 100.0000 (98.5686)  time: 0.3479  data: 0.0009  max mem: 2502
Train: Epoch[4/5]  [2620/3125]  eta: 0:02:56  Lr: 0.001875  Loss: -0.1671  Acc@1: 93.7500 (86.8657)  Acc@5: 100.0000 (98.5669)  time: 0.3477  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [2630/3125]  eta: 0:02:52  Lr: 0.001875  Loss: -0.4028  Acc@1: 93.7500 (86.8634)  Acc@5: 100.0000 (98.5652)  time: 0.3482  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [2640/3125]  eta: 0:02:49  Lr: 0.001875  Loss: -0.7321  Acc@1: 93.7500 (86.8800)  Acc@5: 100.0000 (98.5659)  time: 0.3498  data: 0.0006  max mem: 2502
Train: Epoch[4/5]  [2650/3125]  eta: 0:02:45  Lr: 0.001875  Loss: -0.7636  Acc@1: 87.5000 (86.8705)  Acc@5: 100.0000 (98.5666)  time: 0.3503  data: 0.0007  max mem: 2502
Train: Epoch[4/5]  [2660/3125]  eta: 0:02:42  Lr: 0.001875  Loss: -0.7070  Acc@1: 87.5000 (86.8846)  Acc@5: 100.0000 (98.5720)  time: 0.3494  data: 0.0006  max mem: 2502
Train: Epoch[4/5]  [2670/3125]  eta: 0:02:38  Lr: 0.001875  Loss: -0.6867  Acc@1: 87.5000 (86.8729)  Acc@5: 100.0000 (98.5726)  time: 0.3493  data: 0.0007  max mem: 2502
Train: Epoch[4/5]  [2680/3125]  eta: 0:02:35  Lr: 0.001875  Loss: -0.0090  Acc@1: 87.5000 (86.8729)  Acc@5: 100.0000 (98.5733)  time: 0.3495  data: 0.0007  max mem: 2502
Train: Epoch[4/5]  [2690/3125]  eta: 0:02:31  Lr: 0.001875  Loss: -0.1348  Acc@1: 87.5000 (86.8915)  Acc@5: 100.0000 (98.5786)  time: 0.3507  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [2700/3125]  eta: 0:02:28  Lr: 0.001875  Loss: -0.6501  Acc@1: 87.5000 (86.8799)  Acc@5: 100.0000 (98.5769)  time: 0.3520  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [2710/3125]  eta: 0:02:24  Lr: 0.001875  Loss: -0.3934  Acc@1: 87.5000 (86.8914)  Acc@5: 100.0000 (98.5776)  time: 0.3525  data: 0.0006  max mem: 2502
Train: Epoch[4/5]  [2720/3125]  eta: 0:02:21  Lr: 0.001875  Loss: -0.2636  Acc@1: 87.5000 (86.8890)  Acc@5: 100.0000 (98.5713)  time: 0.3511  data: 0.0006  max mem: 2502
Train: Epoch[4/5]  [2730/3125]  eta: 0:02:17  Lr: 0.001875  Loss: -0.6855  Acc@1: 87.5000 (86.9027)  Acc@5: 100.0000 (98.5742)  time: 0.3490  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [2740/3125]  eta: 0:02:14  Lr: 0.001875  Loss: -0.4598  Acc@1: 87.5000 (86.9094)  Acc@5: 100.0000 (98.5726)  time: 0.3489  data: 0.0007  max mem: 2502
Train: Epoch[4/5]  [2750/3125]  eta: 0:02:11  Lr: 0.001875  Loss: -0.6904  Acc@1: 87.5000 (86.9116)  Acc@5: 100.0000 (98.5755)  time: 0.3488  data: 0.0006  max mem: 2502
Train: Epoch[4/5]  [2760/3125]  eta: 0:02:07  Lr: 0.001875  Loss: -0.1941  Acc@1: 87.5000 (86.9069)  Acc@5: 100.0000 (98.5716)  time: 0.3486  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [2770/3125]  eta: 0:02:04  Lr: 0.001875  Loss: -0.5044  Acc@1: 87.5000 (86.9091)  Acc@5: 100.0000 (98.5745)  time: 0.3479  data: 0.0006  max mem: 2502
Train: Epoch[4/5]  [2780/3125]  eta: 0:02:00  Lr: 0.001875  Loss: -0.3808  Acc@1: 87.5000 (86.8999)  Acc@5: 100.0000 (98.5752)  time: 0.3489  data: 0.0010  max mem: 2502
Train: Epoch[4/5]  [2790/3125]  eta: 0:01:57  Lr: 0.001875  Loss: -0.4844  Acc@1: 87.5000 (86.8909)  Acc@5: 100.0000 (98.5691)  time: 0.3506  data: 0.0009  max mem: 2502
Train: Epoch[4/5]  [2800/3125]  eta: 0:01:53  Lr: 0.001875  Loss: -0.5343  Acc@1: 87.5000 (86.8953)  Acc@5: 100.0000 (98.5697)  time: 0.3506  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [2810/3125]  eta: 0:01:50  Lr: 0.001875  Loss: -0.6460  Acc@1: 87.5000 (86.9064)  Acc@5: 100.0000 (98.5681)  time: 0.3500  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [2820/3125]  eta: 0:01:46  Lr: 0.001875  Loss: -0.4613  Acc@1: 87.5000 (86.9129)  Acc@5: 100.0000 (98.5688)  time: 0.3492  data: 0.0006  max mem: 2502
Train: Epoch[4/5]  [2830/3125]  eta: 0:01:43  Lr: 0.001875  Loss: -0.6267  Acc@1: 87.5000 (86.9194)  Acc@5: 100.0000 (98.5694)  time: 0.3487  data: 0.0006  max mem: 2502
Train: Epoch[4/5]  [2840/3125]  eta: 0:01:39  Lr: 0.001875  Loss: -0.5941  Acc@1: 87.5000 (86.9302)  Acc@5: 100.0000 (98.5722)  time: 0.3486  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [2850/3125]  eta: 0:01:36  Lr: 0.001875  Loss: -0.5310  Acc@1: 87.5000 (86.9278)  Acc@5: 100.0000 (98.5751)  time: 0.3493  data: 0.0006  max mem: 2502
Train: Epoch[4/5]  [2860/3125]  eta: 0:01:32  Lr: 0.001875  Loss: -0.7935  Acc@1: 87.5000 (86.9364)  Acc@5: 100.0000 (98.5800)  time: 0.3524  data: 0.0007  max mem: 2502
Train: Epoch[4/5]  [2870/3125]  eta: 0:01:29  Lr: 0.001875  Loss: -0.7649  Acc@1: 93.7500 (86.9405)  Acc@5: 100.0000 (98.5806)  time: 0.3515  data: 0.0006  max mem: 2502
Train: Epoch[4/5]  [2880/3125]  eta: 0:01:25  Lr: 0.001875  Loss: -0.2075  Acc@1: 93.7500 (86.9490)  Acc@5: 100.0000 (98.5725)  time: 0.3488  data: 0.0011  max mem: 2502
Train: Epoch[4/5]  [2890/3125]  eta: 0:01:22  Lr: 0.001875  Loss: -0.4678  Acc@1: 87.5000 (86.9595)  Acc@5: 100.0000 (98.5753)  time: 0.3486  data: 0.0012  max mem: 2502
Train: Epoch[4/5]  [2900/3125]  eta: 0:01:18  Lr: 0.001875  Loss: 0.2243  Acc@1: 93.7500 (86.9657)  Acc@5: 100.0000 (98.5759)  time: 0.3480  data: 0.0006  max mem: 2502
Train: Epoch[4/5]  [2910/3125]  eta: 0:01:15  Lr: 0.001875  Loss: -0.7942  Acc@1: 87.5000 (86.9611)  Acc@5: 100.0000 (98.5744)  time: 0.3491  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [2920/3125]  eta: 0:01:11  Lr: 0.001875  Loss: -0.7638  Acc@1: 87.5000 (86.9608)  Acc@5: 100.0000 (98.5750)  time: 0.3494  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [2930/3125]  eta: 0:01:08  Lr: 0.001875  Loss: -0.4451  Acc@1: 87.5000 (86.9562)  Acc@5: 100.0000 (98.5734)  time: 0.3478  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [2940/3125]  eta: 0:01:04  Lr: 0.001875  Loss: -0.5530  Acc@1: 81.2500 (86.9475)  Acc@5: 100.0000 (98.5740)  time: 0.3495  data: 0.0018  max mem: 2502
Train: Epoch[4/5]  [2950/3125]  eta: 0:01:01  Lr: 0.001875  Loss: -0.2413  Acc@1: 87.5000 (86.9430)  Acc@5: 100.0000 (98.5640)  time: 0.3500  data: 0.0018  max mem: 2502
Train: Epoch[4/5]  [2960/3125]  eta: 0:00:57  Lr: 0.001875  Loss: -0.7300  Acc@1: 87.5000 (86.9512)  Acc@5: 100.0000 (98.5668)  time: 0.3487  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [2970/3125]  eta: 0:00:54  Lr: 0.001875  Loss: -0.5250  Acc@1: 93.7500 (86.9657)  Acc@5: 100.0000 (98.5695)  time: 0.3483  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [2980/3125]  eta: 0:00:50  Lr: 0.001875  Loss: -0.2080  Acc@1: 87.5000 (86.9528)  Acc@5: 100.0000 (98.5659)  time: 0.3472  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [2990/3125]  eta: 0:00:47  Lr: 0.001875  Loss: -0.6648  Acc@1: 87.5000 (86.9525)  Acc@5: 100.0000 (98.5686)  time: 0.3479  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [3000/3125]  eta: 0:00:43  Lr: 0.001875  Loss: -0.6580  Acc@1: 87.5000 (86.9564)  Acc@5: 100.0000 (98.5671)  time: 0.3489  data: 0.0006  max mem: 2502
Train: Epoch[4/5]  [3010/3125]  eta: 0:00:40  Lr: 0.001875  Loss: -0.3604  Acc@1: 87.5000 (86.9603)  Acc@5: 100.0000 (98.5719)  time: 0.3497  data: 0.0007  max mem: 2502
Train: Epoch[4/5]  [3020/3125]  eta: 0:00:36  Lr: 0.001875  Loss: -0.8275  Acc@1: 87.5000 (86.9642)  Acc@5: 100.0000 (98.5684)  time: 0.3503  data: 0.0006  max mem: 2502
Train: Epoch[4/5]  [3030/3125]  eta: 0:00:33  Lr: 0.001875  Loss: -0.7112  Acc@1: 87.5000 (86.9639)  Acc@5: 100.0000 (98.5648)  time: 0.3497  data: 0.0007  max mem: 2502
Train: Epoch[4/5]  [3040/3125]  eta: 0:00:29  Lr: 0.001875  Loss: -0.5407  Acc@1: 87.5000 (86.9492)  Acc@5: 100.0000 (98.5593)  time: 0.3484  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [3050/3125]  eta: 0:00:26  Lr: 0.001875  Loss: -0.6702  Acc@1: 87.5000 (86.9469)  Acc@5: 100.0000 (98.5619)  time: 0.3476  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [3060/3125]  eta: 0:00:22  Lr: 0.001875  Loss: -0.2976  Acc@1: 87.5000 (86.9508)  Acc@5: 100.0000 (98.5666)  time: 0.3471  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [3070/3125]  eta: 0:00:19  Lr: 0.001875  Loss: -0.5122  Acc@1: 87.5000 (86.9607)  Acc@5: 100.0000 (98.5672)  time: 0.3476  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [3080/3125]  eta: 0:00:15  Lr: 0.001875  Loss: -0.7181  Acc@1: 93.7500 (86.9665)  Acc@5: 100.0000 (98.5699)  time: 0.3486  data: 0.0009  max mem: 2502
Train: Epoch[4/5]  [3090/3125]  eta: 0:00:12  Lr: 0.001875  Loss: -0.3925  Acc@1: 87.5000 (86.9763)  Acc@5: 100.0000 (98.5704)  time: 0.3483  data: 0.0014  max mem: 2502
Train: Epoch[4/5]  [3100/3125]  eta: 0:00:08  Lr: 0.001875  Loss: -0.5670  Acc@1: 87.5000 (86.9719)  Acc@5: 100.0000 (98.5730)  time: 0.3483  data: 0.0010  max mem: 2502
Train: Epoch[4/5]  [3110/3125]  eta: 0:00:05  Lr: 0.001875  Loss: -0.4659  Acc@1: 87.5000 (86.9777)  Acc@5: 100.0000 (98.5736)  time: 0.3482  data: 0.0006  max mem: 2502
Train: Epoch[4/5]  [3120/3125]  eta: 0:00:01  Lr: 0.001875  Loss: -0.5073  Acc@1: 87.5000 (86.9873)  Acc@5: 100.0000 (98.5682)  time: 0.3486  data: 0.0013  max mem: 2502
Train: Epoch[4/5]  [3124/3125]  eta: 0:00:00  Lr: 0.001875  Loss: -0.7131  Acc@1: 87.5000 (86.9900)  Acc@5: 100.0000 (98.5680)  time: 0.3488  data: 0.0013  max mem: 2502
Train: Epoch[4/5] Total time: 0:18:12 (0.3495 s / it)
{0: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 1: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 2: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 3: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 4: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 5: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 6: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 7: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 8: {0: 0, 1: 0, 2: 200000, 3: 0, 4: 0}, 9: {0: 0, 1: 0, 2: 200000, 3: 0, 4: 0}, 10: {0: 0, 1: 0, 2: 200000, 3: 0, 4: 0}, 11: {0: 0, 1: 0, 2: 200000, 3: 0, 4: 0}, 12: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 13: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 14: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 15: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 16: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 17: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 18: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 19: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}}
Averaged stats: Lr: 0.001875  Loss: -0.7131  Acc@1: 87.5000 (86.9900)  Acc@5: 100.0000 (98.5680)
Train: Epoch[5/5]  [   0/3125]  eta: 0:38:15  Lr: 0.001875  Loss: -0.4090  Acc@1: 81.2500 (81.2500)  Acc@5: 100.0000 (100.0000)  time: 0.7347  data: 0.3888  max mem: 2502
Train: Epoch[5/5]  [  10/3125]  eta: 0:19:53  Lr: 0.001875  Loss: -0.0515  Acc@1: 81.2500 (81.8182)  Acc@5: 100.0000 (98.2955)  time: 0.3832  data: 0.0358  max mem: 2502
Train: Epoch[5/5]  [  20/3125]  eta: 0:19:00  Lr: 0.001875  Loss: -0.2428  Acc@1: 87.5000 (85.7143)  Acc@5: 100.0000 (98.2143)  time: 0.3488  data: 0.0006  max mem: 2502
Train: Epoch[5/5]  [  30/3125]  eta: 0:18:36  Lr: 0.001875  Loss: -0.6976  Acc@1: 87.5000 (87.9032)  Acc@5: 100.0000 (98.5887)  time: 0.3483  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [  40/3125]  eta: 0:18:23  Lr: 0.001875  Loss: -0.6947  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (98.6280)  time: 0.3479  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [  50/3125]  eta: 0:18:16  Lr: 0.001875  Loss: -0.4690  Acc@1: 87.5000 (87.6225)  Acc@5: 100.0000 (98.5294)  time: 0.3505  data: 0.0006  max mem: 2502
Train: Epoch[5/5]  [  60/3125]  eta: 0:18:08  Lr: 0.001875  Loss: -0.9016  Acc@1: 87.5000 (88.0123)  Acc@5: 100.0000 (98.3607)  time: 0.3502  data: 0.0006  max mem: 2502
Train: Epoch[5/5]  [  70/3125]  eta: 0:18:02  Lr: 0.001875  Loss: -0.4303  Acc@1: 93.7500 (88.1162)  Acc@5: 100.0000 (98.5915)  time: 0.3486  data: 0.0006  max mem: 2502
Train: Epoch[5/5]  [  80/3125]  eta: 0:17:56  Lr: 0.001875  Loss: -0.7610  Acc@1: 87.5000 (87.6543)  Acc@5: 100.0000 (98.3025)  time: 0.3488  data: 0.0006  max mem: 2502
Train: Epoch[5/5]  [  90/3125]  eta: 0:17:52  Lr: 0.001875  Loss: -0.5166  Acc@1: 87.5000 (87.8434)  Acc@5: 100.0000 (98.4890)  time: 0.3491  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [ 100/3125]  eta: 0:17:47  Lr: 0.001875  Loss: -0.8049  Acc@1: 87.5000 (88.0569)  Acc@5: 100.0000 (98.5767)  time: 0.3491  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [ 110/3125]  eta: 0:17:42  Lr: 0.001875  Loss: -0.8268  Acc@1: 87.5000 (88.4572)  Acc@5: 100.0000 (98.5360)  time: 0.3493  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [ 120/3125]  eta: 0:17:37  Lr: 0.001875  Loss: -0.4211  Acc@1: 93.7500 (88.3264)  Acc@5: 100.0000 (98.5021)  time: 0.3485  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [ 130/3125]  eta: 0:17:33  Lr: 0.001875  Loss: -0.7806  Acc@1: 87.5000 (88.4542)  Acc@5: 100.0000 (98.6164)  time: 0.3483  data: 0.0006  max mem: 2502
Train: Epoch[5/5]  [ 140/3125]  eta: 0:17:29  Lr: 0.001875  Loss: -0.0933  Acc@1: 87.5000 (88.2979)  Acc@5: 100.0000 (98.5816)  time: 0.3495  data: 0.0007  max mem: 2502
Train: Epoch[5/5]  [ 150/3125]  eta: 0:17:26  Lr: 0.001875  Loss: -0.4011  Acc@1: 87.5000 (88.3692)  Acc@5: 100.0000 (98.5513)  time: 0.3500  data: 0.0006  max mem: 2502
Train: Epoch[5/5]  [ 160/3125]  eta: 0:17:22  Lr: 0.001875  Loss: -0.7851  Acc@1: 87.5000 (88.1599)  Acc@5: 100.0000 (98.5248)  time: 0.3513  data: 0.0006  max mem: 2502
Train: Epoch[5/5]  [ 170/3125]  eta: 0:17:18  Lr: 0.001875  Loss: -0.4427  Acc@1: 87.5000 (88.1579)  Acc@5: 100.0000 (98.5746)  time: 0.3504  data: 0.0006  max mem: 2502
Train: Epoch[5/5]  [ 180/3125]  eta: 0:17:15  Lr: 0.001875  Loss: -0.6091  Acc@1: 81.2500 (87.8453)  Acc@5: 100.0000 (98.4807)  time: 0.3498  data: 0.0006  max mem: 2502
Train: Epoch[5/5]  [ 190/3125]  eta: 0:17:11  Lr: 0.001875  Loss: -0.5303  Acc@1: 87.5000 (87.9908)  Acc@5: 100.0000 (98.5275)  time: 0.3507  data: 0.0010  max mem: 2502
Train: Epoch[5/5]  [ 200/3125]  eta: 0:17:07  Lr: 0.001875  Loss: -0.5402  Acc@1: 93.7500 (88.0286)  Acc@5: 100.0000 (98.5697)  time: 0.3500  data: 0.0010  max mem: 2502
Train: Epoch[5/5]  [ 210/3125]  eta: 0:17:03  Lr: 0.001875  Loss: -0.5002  Acc@1: 87.5000 (87.6777)  Acc@5: 100.0000 (98.6078)  time: 0.3500  data: 0.0006  max mem: 2502
Train: Epoch[5/5]  [ 220/3125]  eta: 0:17:00  Lr: 0.001875  Loss: -0.6983  Acc@1: 87.5000 (87.6697)  Acc@5: 100.0000 (98.6425)  time: 0.3517  data: 0.0006  max mem: 2502
Train: Epoch[5/5]  [ 230/3125]  eta: 0:16:57  Lr: 0.001875  Loss: -0.4410  Acc@1: 87.5000 (87.4188)  Acc@5: 100.0000 (98.6472)  time: 0.3520  data: 0.0006  max mem: 2502
Train: Epoch[5/5]  [ 240/3125]  eta: 0:16:53  Lr: 0.001875  Loss: -0.5217  Acc@1: 87.5000 (87.5519)  Acc@5: 100.0000 (98.6774)  time: 0.3504  data: 0.0006  max mem: 2502
Train: Epoch[5/5]  [ 250/3125]  eta: 0:16:49  Lr: 0.001875  Loss: -0.6131  Acc@1: 87.5000 (87.6245)  Acc@5: 100.0000 (98.7052)  time: 0.3490  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [ 260/3125]  eta: 0:16:46  Lr: 0.001875  Loss: -0.6547  Acc@1: 87.5000 (87.7155)  Acc@5: 100.0000 (98.7069)  time: 0.3495  data: 0.0017  max mem: 2502
Train: Epoch[5/5]  [ 270/3125]  eta: 0:16:42  Lr: 0.001875  Loss: 0.0058  Acc@1: 87.5000 (87.7768)  Acc@5: 100.0000 (98.7085)  time: 0.3504  data: 0.0017  max mem: 2502
Train: Epoch[5/5]  [ 280/3125]  eta: 0:16:38  Lr: 0.001875  Loss: -0.3936  Acc@1: 87.5000 (87.7669)  Acc@5: 100.0000 (98.6877)  time: 0.3499  data: 0.0007  max mem: 2502
Train: Epoch[5/5]  [ 290/3125]  eta: 0:16:34  Lr: 0.001875  Loss: -0.6525  Acc@1: 87.5000 (87.7792)  Acc@5: 100.0000 (98.6684)  time: 0.3488  data: 0.0006  max mem: 2502
Train: Epoch[5/5]  [ 300/3125]  eta: 0:16:31  Lr: 0.001875  Loss: -0.6218  Acc@1: 87.5000 (87.8115)  Acc@5: 100.0000 (98.5880)  time: 0.3481  data: 0.0006  max mem: 2502
Train: Epoch[5/5]  [ 310/3125]  eta: 0:16:27  Lr: 0.001875  Loss: -0.3468  Acc@1: 87.5000 (87.9421)  Acc@5: 100.0000 (98.5732)  time: 0.3485  data: 0.0006  max mem: 2502
Train: Epoch[5/5]  [ 320/3125]  eta: 0:16:23  Lr: 0.001875  Loss: -0.7217  Acc@1: 87.5000 (87.8894)  Acc@5: 100.0000 (98.5592)  time: 0.3493  data: 0.0006  max mem: 2502
Train: Epoch[5/5]  [ 330/3125]  eta: 0:16:20  Lr: 0.001875  Loss: 0.2869  Acc@1: 87.5000 (87.7644)  Acc@5: 100.0000 (98.5272)  time: 0.3506  data: 0.0006  max mem: 2502
Train: Epoch[5/5]  [ 340/3125]  eta: 0:16:16  Lr: 0.001875  Loss: -0.8682  Acc@1: 87.5000 (87.7199)  Acc@5: 100.0000 (98.5337)  time: 0.3499  data: 0.0006  max mem: 2502
Train: Epoch[5/5]  [ 350/3125]  eta: 0:16:13  Lr: 0.001875  Loss: -0.7250  Acc@1: 81.2500 (87.5890)  Acc@5: 100.0000 (98.5043)  time: 0.3493  data: 0.0007  max mem: 2502
Train: Epoch[5/5]  [ 360/3125]  eta: 0:16:09  Lr: 0.001875  Loss: -0.3715  Acc@1: 81.2500 (87.4134)  Acc@5: 100.0000 (98.4938)  time: 0.3491  data: 0.0006  max mem: 2502
Train: Epoch[5/5]  [ 370/3125]  eta: 0:16:06  Lr: 0.001875  Loss: -0.5636  Acc@1: 87.5000 (87.3989)  Acc@5: 100.0000 (98.4838)  time: 0.3499  data: 0.0015  max mem: 2502
Train: Epoch[5/5]  [ 380/3125]  eta: 0:16:02  Lr: 0.001875  Loss: -0.2758  Acc@1: 81.2500 (87.3360)  Acc@5: 100.0000 (98.4744)  time: 0.3513  data: 0.0015  max mem: 2502
Train: Epoch[5/5]  [ 390/3125]  eta: 0:15:58  Lr: 0.001875  Loss: -0.8761  Acc@1: 87.5000 (87.4201)  Acc@5: 100.0000 (98.4655)  time: 0.3503  data: 0.0006  max mem: 2502
Train: Epoch[5/5]  [ 400/3125]  eta: 0:15:55  Lr: 0.001875  Loss: -0.4958  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (98.4882)  time: 0.3501  data: 0.0007  max mem: 2502
Train: Epoch[5/5]  [ 410/3125]  eta: 0:15:51  Lr: 0.001875  Loss: -0.7210  Acc@1: 87.5000 (87.5152)  Acc@5: 100.0000 (98.5097)  time: 0.3503  data: 0.0008  max mem: 2502
Train: Epoch[5/5]  [ 420/3125]  eta: 0:15:48  Lr: 0.001875  Loss: -0.4881  Acc@1: 87.5000 (87.5148)  Acc@5: 100.0000 (98.4857)  time: 0.3497  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [ 430/3125]  eta: 0:15:44  Lr: 0.001875  Loss: -0.4513  Acc@1: 87.5000 (87.5145)  Acc@5: 100.0000 (98.4774)  time: 0.3492  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [ 440/3125]  eta: 0:15:41  Lr: 0.001875  Loss: -0.5779  Acc@1: 87.5000 (87.5425)  Acc@5: 100.0000 (98.5119)  time: 0.3483  data: 0.0007  max mem: 2502
Train: Epoch[5/5]  [ 450/3125]  eta: 0:15:37  Lr: 0.001875  Loss: -0.5167  Acc@1: 87.5000 (87.5139)  Acc@5: 100.0000 (98.5172)  time: 0.3486  data: 0.0007  max mem: 2502
Train: Epoch[5/5]  [ 460/3125]  eta: 0:15:33  Lr: 0.001875  Loss: -0.8480  Acc@1: 87.5000 (87.5949)  Acc@5: 100.0000 (98.5493)  time: 0.3494  data: 0.0006  max mem: 2502
Train: Epoch[5/5]  [ 470/3125]  eta: 0:15:30  Lr: 0.001875  Loss: -0.6017  Acc@1: 93.7500 (87.6194)  Acc@5: 100.0000 (98.5669)  time: 0.3487  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [ 480/3125]  eta: 0:15:26  Lr: 0.001875  Loss: -0.8414  Acc@1: 81.2500 (87.4870)  Acc@5: 100.0000 (98.5447)  time: 0.3486  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [ 490/3125]  eta: 0:15:23  Lr: 0.001875  Loss: -0.5027  Acc@1: 81.2500 (87.4618)  Acc@5: 100.0000 (98.5616)  time: 0.3512  data: 0.0010  max mem: 2502
Train: Epoch[5/5]  [ 500/3125]  eta: 0:15:19  Lr: 0.001875  Loss: -0.5455  Acc@1: 87.5000 (87.4501)  Acc@5: 100.0000 (98.5404)  time: 0.3519  data: 0.0011  max mem: 2502
Train: Epoch[5/5]  [ 510/3125]  eta: 0:15:16  Lr: 0.001875  Loss: -0.5461  Acc@1: 81.2500 (87.3532)  Acc@5: 100.0000 (98.5690)  time: 0.3493  data: 0.0008  max mem: 2502
Train: Epoch[5/5]  [ 520/3125]  eta: 0:15:12  Lr: 0.001875  Loss: -0.6601  Acc@1: 81.2500 (87.2601)  Acc@5: 100.0000 (98.5365)  time: 0.3508  data: 0.0007  max mem: 2502
Train: Epoch[5/5]  [ 530/3125]  eta: 0:15:09  Lr: 0.001875  Loss: -0.6371  Acc@1: 81.2500 (87.2057)  Acc@5: 100.0000 (98.5287)  time: 0.3513  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [ 540/3125]  eta: 0:15:05  Lr: 0.001875  Loss: -0.7349  Acc@1: 93.7500 (87.2921)  Acc@5: 100.0000 (98.5444)  time: 0.3493  data: 0.0008  max mem: 2502
Train: Epoch[5/5]  [ 550/3125]  eta: 0:15:02  Lr: 0.001875  Loss: -0.3582  Acc@1: 87.5000 (87.2618)  Acc@5: 100.0000 (98.5368)  time: 0.3490  data: 0.0008  max mem: 2502
Train: Epoch[5/5]  [ 560/3125]  eta: 0:14:58  Lr: 0.001875  Loss: -0.5807  Acc@1: 81.2500 (87.1881)  Acc@5: 100.0000 (98.5183)  time: 0.3484  data: 0.0009  max mem: 2502
Train: Epoch[5/5]  [ 570/3125]  eta: 0:14:55  Lr: 0.001875  Loss: -0.4528  Acc@1: 87.5000 (87.2045)  Acc@5: 100.0000 (98.5333)  time: 0.3501  data: 0.0007  max mem: 2502
Train: Epoch[5/5]  [ 580/3125]  eta: 0:14:51  Lr: 0.001875  Loss: -0.4704  Acc@1: 87.5000 (87.2526)  Acc@5: 100.0000 (98.5262)  time: 0.3491  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [ 590/3125]  eta: 0:14:47  Lr: 0.001875  Loss: -0.3687  Acc@1: 87.5000 (87.2250)  Acc@5: 100.0000 (98.5089)  time: 0.3469  data: 0.0007  max mem: 2502
Train: Epoch[5/5]  [ 600/3125]  eta: 0:14:44  Lr: 0.001875  Loss: -0.6210  Acc@1: 87.5000 (87.2712)  Acc@5: 100.0000 (98.5233)  time: 0.3481  data: 0.0009  max mem: 2502
Train: Epoch[5/5]  [ 610/3125]  eta: 0:14:40  Lr: 0.001875  Loss: -0.9092  Acc@1: 87.5000 (87.2545)  Acc@5: 100.0000 (98.5475)  time: 0.3479  data: 0.0010  max mem: 2502
Train: Epoch[5/5]  [ 620/3125]  eta: 0:14:36  Lr: 0.001875  Loss: -0.4203  Acc@1: 81.2500 (87.2081)  Acc@5: 100.0000 (98.5608)  time: 0.3464  data: 0.0007  max mem: 2502
Train: Epoch[5/5]  [ 630/3125]  eta: 0:14:33  Lr: 0.001875  Loss: -0.4904  Acc@1: 87.5000 (87.1434)  Acc@5: 100.0000 (98.5638)  time: 0.3471  data: 0.0011  max mem: 2502
Train: Epoch[5/5]  [ 640/3125]  eta: 0:14:29  Lr: 0.001875  Loss: -0.4950  Acc@1: 87.5000 (87.1782)  Acc@5: 100.0000 (98.5569)  time: 0.3487  data: 0.0021  max mem: 2502
Train: Epoch[5/5]  [ 650/3125]  eta: 0:14:26  Lr: 0.001875  Loss: -0.4822  Acc@1: 87.5000 (87.1256)  Acc@5: 100.0000 (98.5599)  time: 0.3490  data: 0.0019  max mem: 2502
Train: Epoch[5/5]  [ 660/3125]  eta: 0:14:22  Lr: 0.001875  Loss: -0.5860  Acc@1: 87.5000 (87.1312)  Acc@5: 100.0000 (98.5533)  time: 0.3484  data: 0.0012  max mem: 2502
Train: Epoch[5/5]  [ 670/3125]  eta: 0:14:19  Lr: 0.001875  Loss: -0.5892  Acc@1: 87.5000 (87.0995)  Acc@5: 100.0000 (98.5749)  time: 0.3473  data: 0.0008  max mem: 2502
Train: Epoch[5/5]  [ 680/3125]  eta: 0:14:15  Lr: 0.001875  Loss: -0.4064  Acc@1: 87.5000 (87.1237)  Acc@5: 100.0000 (98.5775)  time: 0.3468  data: 0.0007  max mem: 2502
Train: Epoch[5/5]  [ 690/3125]  eta: 0:14:11  Lr: 0.001875  Loss: -0.7975  Acc@1: 93.7500 (87.1563)  Acc@5: 100.0000 (98.5890)  time: 0.3474  data: 0.0010  max mem: 2502
Train: Epoch[5/5]  [ 700/3125]  eta: 0:14:08  Lr: 0.001875  Loss: -0.7195  Acc@1: 93.7500 (87.1790)  Acc@5: 100.0000 (98.5824)  time: 0.3478  data: 0.0012  max mem: 2502
Train: Epoch[5/5]  [ 710/3125]  eta: 0:14:04  Lr: 0.001875  Loss: -0.7626  Acc@1: 87.5000 (87.1748)  Acc@5: 100.0000 (98.5847)  time: 0.3492  data: 0.0009  max mem: 2502
Train: Epoch[5/5]  [ 720/3125]  eta: 0:14:01  Lr: 0.001875  Loss: -0.3731  Acc@1: 87.5000 (87.1619)  Acc@5: 100.0000 (98.5870)  time: 0.3494  data: 0.0012  max mem: 2502
Train: Epoch[5/5]  [ 730/3125]  eta: 0:13:57  Lr: 0.001875  Loss: -0.3643  Acc@1: 87.5000 (87.1580)  Acc@5: 100.0000 (98.5807)  time: 0.3479  data: 0.0013  max mem: 2502
Train: Epoch[5/5]  [ 740/3125]  eta: 0:13:54  Lr: 0.001875  Loss: -0.5760  Acc@1: 87.5000 (87.1289)  Acc@5: 100.0000 (98.5746)  time: 0.3475  data: 0.0012  max mem: 2502
Train: Epoch[5/5]  [ 750/3125]  eta: 0:13:50  Lr: 0.001875  Loss: -0.6184  Acc@1: 87.5000 (87.1172)  Acc@5: 100.0000 (98.5769)  time: 0.3470  data: 0.0011  max mem: 2502
Train: Epoch[5/5]  [ 760/3125]  eta: 0:13:47  Lr: 0.001875  Loss: -0.7206  Acc@1: 87.5000 (87.1304)  Acc@5: 100.0000 (98.5710)  time: 0.3474  data: 0.0011  max mem: 2502
Train: Epoch[5/5]  [ 770/3125]  eta: 0:13:43  Lr: 0.001875  Loss: -0.7549  Acc@1: 87.5000 (87.1190)  Acc@5: 100.0000 (98.5733)  time: 0.3483  data: 0.0011  max mem: 2502
Train: Epoch[5/5]  [ 780/3125]  eta: 0:13:40  Lr: 0.001875  Loss: -0.5904  Acc@1: 87.5000 (87.1559)  Acc@5: 100.0000 (98.5915)  time: 0.3500  data: 0.0017  max mem: 2502
Train: Epoch[5/5]  [ 790/3125]  eta: 0:13:36  Lr: 0.001875  Loss: -0.1353  Acc@1: 87.5000 (87.1839)  Acc@5: 100.0000 (98.5936)  time: 0.3493  data: 0.0017  max mem: 2502
Train: Epoch[5/5]  [ 800/3125]  eta: 0:13:32  Lr: 0.001875  Loss: -0.5716  Acc@1: 87.5000 (87.1957)  Acc@5: 100.0000 (98.6033)  time: 0.3477  data: 0.0009  max mem: 2502
Train: Epoch[5/5]  [ 810/3125]  eta: 0:13:29  Lr: 0.001875  Loss: -0.5295  Acc@1: 87.5000 (87.1917)  Acc@5: 100.0000 (98.6205)  time: 0.3478  data: 0.0006  max mem: 2502
Train: Epoch[5/5]  [ 820/3125]  eta: 0:13:25  Lr: 0.001875  Loss: -0.6675  Acc@1: 87.5000 (87.2107)  Acc@5: 100.0000 (98.6145)  time: 0.3476  data: 0.0010  max mem: 2502
Train: Epoch[5/5]  [ 830/3125]  eta: 0:13:22  Lr: 0.001875  Loss: -0.7889  Acc@1: 87.5000 (87.2142)  Acc@5: 100.0000 (98.5936)  time: 0.3485  data: 0.0012  max mem: 2502
Train: Epoch[5/5]  [ 840/3125]  eta: 0:13:18  Lr: 0.001875  Loss: -0.5135  Acc@1: 87.5000 (87.2473)  Acc@5: 100.0000 (98.5880)  time: 0.3484  data: 0.0006  max mem: 2502
Train: Epoch[5/5]  [ 850/3125]  eta: 0:13:15  Lr: 0.001875  Loss: -0.4098  Acc@1: 93.7500 (87.2870)  Acc@5: 100.0000 (98.5972)  time: 0.3475  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [ 860/3125]  eta: 0:13:11  Lr: 0.001875  Loss: -0.4752  Acc@1: 87.5000 (87.2967)  Acc@5: 100.0000 (98.5990)  time: 0.3479  data: 0.0012  max mem: 2502
Train: Epoch[5/5]  [ 870/3125]  eta: 0:13:08  Lr: 0.001875  Loss: -0.7058  Acc@1: 87.5000 (87.3206)  Acc@5: 100.0000 (98.6007)  time: 0.3487  data: 0.0014  max mem: 2502
Train: Epoch[5/5]  [ 880/3125]  eta: 0:13:04  Lr: 0.001875  Loss: -0.7924  Acc@1: 87.5000 (87.2659)  Acc@5: 100.0000 (98.5812)  time: 0.3489  data: 0.0009  max mem: 2502
Train: Epoch[5/5]  [ 890/3125]  eta: 0:13:01  Lr: 0.001875  Loss: -0.4492  Acc@1: 81.2500 (87.2755)  Acc@5: 100.0000 (98.5831)  time: 0.3480  data: 0.0008  max mem: 2502
Train: Epoch[5/5]  [ 900/3125]  eta: 0:12:57  Lr: 0.001875  Loss: -0.5096  Acc@1: 87.5000 (87.2433)  Acc@5: 100.0000 (98.5780)  time: 0.3472  data: 0.0008  max mem: 2502
Train: Epoch[5/5]  [ 910/3125]  eta: 0:12:54  Lr: 0.001875  Loss: -0.7981  Acc@1: 87.5000 (87.2462)  Acc@5: 100.0000 (98.5730)  time: 0.3484  data: 0.0011  max mem: 2502
Train: Epoch[5/5]  [ 920/3125]  eta: 0:12:50  Lr: 0.001875  Loss: -0.7293  Acc@1: 87.5000 (87.2761)  Acc@5: 100.0000 (98.5681)  time: 0.3494  data: 0.0012  max mem: 2502
Train: Epoch[5/5]  [ 930/3125]  eta: 0:12:47  Lr: 0.001875  Loss: -0.7370  Acc@1: 87.5000 (87.2852)  Acc@5: 100.0000 (98.5768)  time: 0.3494  data: 0.0012  max mem: 2502
Train: Epoch[5/5]  [ 940/3125]  eta: 0:12:43  Lr: 0.001875  Loss: -0.6645  Acc@1: 87.5000 (87.3007)  Acc@5: 100.0000 (98.5654)  time: 0.3499  data: 0.0012  max mem: 2502
Train: Epoch[5/5]  [ 950/3125]  eta: 0:12:40  Lr: 0.001875  Loss: -0.8675  Acc@1: 87.5000 (87.2897)  Acc@5: 100.0000 (98.5607)  time: 0.3491  data: 0.0009  max mem: 2502
Train: Epoch[5/5]  [ 960/3125]  eta: 0:12:36  Lr: 0.001875  Loss: -0.5635  Acc@1: 87.5000 (87.3504)  Acc@5: 100.0000 (98.5627)  time: 0.3487  data: 0.0011  max mem: 2502
Train: Epoch[5/5]  [ 970/3125]  eta: 0:12:33  Lr: 0.001875  Loss: -0.6400  Acc@1: 93.7500 (87.3777)  Acc@5: 100.0000 (98.5775)  time: 0.3504  data: 0.0026  max mem: 2502
Train: Epoch[5/5]  [ 980/3125]  eta: 0:12:29  Lr: 0.001875  Loss: -0.2774  Acc@1: 87.5000 (87.3535)  Acc@5: 100.0000 (98.5665)  time: 0.3500  data: 0.0026  max mem: 2502
Train: Epoch[5/5]  [ 990/3125]  eta: 0:12:26  Lr: 0.001875  Loss: -0.5348  Acc@1: 87.5000 (87.3802)  Acc@5: 100.0000 (98.5747)  time: 0.3485  data: 0.0012  max mem: 2502
Train: Epoch[5/5]  [1000/3125]  eta: 0:12:22  Lr: 0.001875  Loss: -0.7421  Acc@1: 87.5000 (87.3876)  Acc@5: 100.0000 (98.5889)  time: 0.3481  data: 0.0008  max mem: 2502
Train: Epoch[5/5]  [1010/3125]  eta: 0:12:19  Lr: 0.001875  Loss: -0.8316  Acc@1: 81.2500 (87.3578)  Acc@5: 100.0000 (98.5843)  time: 0.3488  data: 0.0010  max mem: 2502
Train: Epoch[5/5]  [1020/3125]  eta: 0:12:15  Lr: 0.001875  Loss: -0.5459  Acc@1: 81.2500 (87.3347)  Acc@5: 100.0000 (98.5676)  time: 0.3495  data: 0.0009  max mem: 2502
Train: Epoch[5/5]  [1030/3125]  eta: 0:12:12  Lr: 0.001875  Loss: -0.6347  Acc@1: 87.5000 (87.3424)  Acc@5: 100.0000 (98.5694)  time: 0.3489  data: 0.0007  max mem: 2502
Train: Epoch[5/5]  [1040/3125]  eta: 0:12:08  Lr: 0.001875  Loss: -0.6754  Acc@1: 87.5000 (87.3439)  Acc@5: 100.0000 (98.5651)  time: 0.3498  data: 0.0009  max mem: 2502
Train: Epoch[5/5]  [1050/3125]  eta: 0:12:05  Lr: 0.001875  Loss: -0.5525  Acc@1: 87.5000 (87.3930)  Acc@5: 100.0000 (98.5668)  time: 0.3505  data: 0.0007  max mem: 2502
Train: Epoch[5/5]  [1060/3125]  eta: 0:12:01  Lr: 0.001875  Loss: -0.4554  Acc@1: 87.5000 (87.3822)  Acc@5: 100.0000 (98.5745)  time: 0.3495  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [1070/3125]  eta: 0:11:58  Lr: 0.001875  Loss: -0.6171  Acc@1: 87.5000 (87.3599)  Acc@5: 100.0000 (98.5878)  time: 0.3488  data: 0.0007  max mem: 2502
Train: Epoch[5/5]  [1080/3125]  eta: 0:11:54  Lr: 0.001875  Loss: -0.6623  Acc@1: 87.5000 (87.3612)  Acc@5: 100.0000 (98.5951)  time: 0.3493  data: 0.0010  max mem: 2502
Train: Epoch[5/5]  [1090/3125]  eta: 0:11:51  Lr: 0.001875  Loss: -0.3588  Acc@1: 87.5000 (87.3568)  Acc@5: 100.0000 (98.6022)  time: 0.3492  data: 0.0010  max mem: 2502
Train: Epoch[5/5]  [1100/3125]  eta: 0:11:47  Lr: 0.001875  Loss: -0.6953  Acc@1: 87.5000 (87.3694)  Acc@5: 100.0000 (98.6092)  time: 0.3483  data: 0.0011  max mem: 2502
Train: Epoch[5/5]  [1110/3125]  eta: 0:11:44  Lr: 0.001875  Loss: -0.5497  Acc@1: 87.5000 (87.3594)  Acc@5: 100.0000 (98.5824)  time: 0.3475  data: 0.0008  max mem: 2502
Train: Epoch[5/5]  [1120/3125]  eta: 0:11:40  Lr: 0.001875  Loss: -0.5761  Acc@1: 87.5000 (87.3885)  Acc@5: 100.0000 (98.5894)  time: 0.3471  data: 0.0008  max mem: 2502
Train: Epoch[5/5]  [1130/3125]  eta: 0:11:37  Lr: 0.001875  Loss: -0.9014  Acc@1: 87.5000 (87.3618)  Acc@5: 100.0000 (98.5798)  time: 0.3480  data: 0.0009  max mem: 2502
Train: Epoch[5/5]  [1140/3125]  eta: 0:11:33  Lr: 0.001875  Loss: -0.2208  Acc@1: 81.2500 (87.3411)  Acc@5: 100.0000 (98.5649)  time: 0.3491  data: 0.0007  max mem: 2502
Train: Epoch[5/5]  [1150/3125]  eta: 0:11:29  Lr: 0.001875  Loss: -0.5832  Acc@1: 81.2500 (87.3154)  Acc@5: 100.0000 (98.5719)  time: 0.3484  data: 0.0008  max mem: 2502
Train: Epoch[5/5]  [1160/3125]  eta: 0:11:26  Lr: 0.001875  Loss: -0.8242  Acc@1: 87.5000 (87.3116)  Acc@5: 100.0000 (98.5788)  time: 0.3481  data: 0.0008  max mem: 2502
Train: Epoch[5/5]  [1170/3125]  eta: 0:11:22  Lr: 0.001875  Loss: -0.6090  Acc@1: 87.5000 (87.3452)  Acc@5: 100.0000 (98.5856)  time: 0.3490  data: 0.0007  max mem: 2502
Train: Epoch[5/5]  [1180/3125]  eta: 0:11:19  Lr: 0.001875  Loss: -0.5607  Acc@1: 87.5000 (87.3095)  Acc@5: 100.0000 (98.5711)  time: 0.3494  data: 0.0010  max mem: 2502
Train: Epoch[5/5]  [1190/3125]  eta: 0:11:16  Lr: 0.001875  Loss: -0.3999  Acc@1: 87.5000 (87.3111)  Acc@5: 100.0000 (98.5726)  time: 0.3494  data: 0.0015  max mem: 2502
Train: Epoch[5/5]  [1200/3125]  eta: 0:11:12  Lr: 0.001875  Loss: -0.5195  Acc@1: 87.5000 (87.3127)  Acc@5: 100.0000 (98.5689)  time: 0.3488  data: 0.0013  max mem: 2502
Train: Epoch[5/5]  [1210/3125]  eta: 0:11:09  Lr: 0.001875  Loss: -0.5672  Acc@1: 93.7500 (87.3297)  Acc@5: 100.0000 (98.5807)  time: 0.3488  data: 0.0009  max mem: 2502
Train: Epoch[5/5]  [1220/3125]  eta: 0:11:05  Lr: 0.001875  Loss: -0.5323  Acc@1: 87.5000 (87.3260)  Acc@5: 100.0000 (98.5872)  time: 0.3488  data: 0.0007  max mem: 2502
Train: Epoch[5/5]  [1230/3125]  eta: 0:11:01  Lr: 0.001875  Loss: -0.8338  Acc@1: 87.5000 (87.3375)  Acc@5: 100.0000 (98.5835)  time: 0.3484  data: 0.0007  max mem: 2502
Train: Epoch[5/5]  [1240/3125]  eta: 0:10:58  Lr: 0.001875  Loss: -0.2231  Acc@1: 81.2500 (87.2683)  Acc@5: 100.0000 (98.5747)  time: 0.3501  data: 0.0019  max mem: 2502
Train: Epoch[5/5]  [1250/3125]  eta: 0:10:55  Lr: 0.001875  Loss: -0.7138  Acc@1: 81.2500 (87.2002)  Acc@5: 100.0000 (98.5711)  time: 0.3500  data: 0.0022  max mem: 2502
Train: Epoch[5/5]  [1260/3125]  eta: 0:10:51  Lr: 0.001875  Loss: -0.5059  Acc@1: 87.5000 (87.2324)  Acc@5: 100.0000 (98.5825)  time: 0.3487  data: 0.0011  max mem: 2502
Train: Epoch[5/5]  [1270/3125]  eta: 0:10:48  Lr: 0.001875  Loss: -0.4451  Acc@1: 87.5000 (87.2050)  Acc@5: 100.0000 (98.5838)  time: 0.3491  data: 0.0008  max mem: 2502
Train: Epoch[5/5]  [1280/3125]  eta: 0:10:44  Lr: 0.001875  Loss: -0.4658  Acc@1: 87.5000 (87.2219)  Acc@5: 100.0000 (98.5851)  time: 0.3490  data: 0.0006  max mem: 2502
Train: Epoch[5/5]  [1290/3125]  eta: 0:10:41  Lr: 0.001875  Loss: -0.6562  Acc@1: 87.5000 (87.2289)  Acc@5: 100.0000 (98.5960)  time: 0.3498  data: 0.0008  max mem: 2502
Train: Epoch[5/5]  [1300/3125]  eta: 0:10:37  Lr: 0.001875  Loss: -0.5111  Acc@1: 87.5000 (87.2262)  Acc@5: 100.0000 (98.6068)  time: 0.3489  data: 0.0007  max mem: 2502
Train: Epoch[5/5]  [1310/3125]  eta: 0:10:34  Lr: 0.001875  Loss: -0.4415  Acc@1: 87.5000 (87.2330)  Acc@5: 100.0000 (98.6079)  time: 0.3483  data: 0.0012  max mem: 2502
Train: Epoch[5/5]  [1320/3125]  eta: 0:10:30  Lr: 0.001875  Loss: -0.4848  Acc@1: 87.5000 (87.2303)  Acc@5: 100.0000 (98.5995)  time: 0.3482  data: 0.0012  max mem: 2502
Train: Epoch[5/5]  [1330/3125]  eta: 0:10:27  Lr: 0.001875  Loss: -0.5801  Acc@1: 87.5000 (87.2511)  Acc@5: 100.0000 (98.6054)  time: 0.3475  data: 0.0007  max mem: 2502
Train: Epoch[5/5]  [1340/3125]  eta: 0:10:23  Lr: 0.001875  Loss: -0.8184  Acc@1: 93.7500 (87.2576)  Acc@5: 100.0000 (98.6111)  time: 0.3476  data: 0.0008  max mem: 2502
Train: Epoch[5/5]  [1350/3125]  eta: 0:10:19  Lr: 0.001875  Loss: -0.5224  Acc@1: 87.5000 (87.2456)  Acc@5: 100.0000 (98.6029)  time: 0.3483  data: 0.0006  max mem: 2502
Train: Epoch[5/5]  [1360/3125]  eta: 0:10:16  Lr: 0.001875  Loss: -0.5861  Acc@1: 87.5000 (87.2428)  Acc@5: 100.0000 (98.6040)  time: 0.3498  data: 0.0009  max mem: 2502
Train: Epoch[5/5]  [1370/3125]  eta: 0:10:13  Lr: 0.001875  Loss: -0.4659  Acc@1: 87.5000 (87.2356)  Acc@5: 100.0000 (98.6050)  time: 0.3501  data: 0.0010  max mem: 2502
Train: Epoch[5/5]  [1380/3125]  eta: 0:10:09  Lr: 0.001875  Loss: -0.6563  Acc@1: 87.5000 (87.2556)  Acc@5: 100.0000 (98.6106)  time: 0.3490  data: 0.0009  max mem: 2502
Train: Epoch[5/5]  [1390/3125]  eta: 0:10:05  Lr: 0.001875  Loss: -0.6372  Acc@1: 87.5000 (87.2843)  Acc@5: 100.0000 (98.6206)  time: 0.3477  data: 0.0008  max mem: 2502
Train: Epoch[5/5]  [1400/3125]  eta: 0:10:02  Lr: 0.001875  Loss: -0.5518  Acc@1: 87.5000 (87.2859)  Acc@5: 100.0000 (98.6215)  time: 0.3480  data: 0.0007  max mem: 2502
Train: Epoch[5/5]  [1410/3125]  eta: 0:09:59  Lr: 0.001875  Loss: -0.6841  Acc@1: 87.5000 (87.2874)  Acc@5: 100.0000 (98.6313)  time: 0.3491  data: 0.0008  max mem: 2502
Train: Epoch[5/5]  [1420/3125]  eta: 0:09:55  Lr: 0.001875  Loss: -0.3852  Acc@1: 87.5000 (87.2801)  Acc@5: 100.0000 (98.6277)  time: 0.3493  data: 0.0010  max mem: 2502
Train: Epoch[5/5]  [1430/3125]  eta: 0:09:52  Lr: 0.001875  Loss: -0.2692  Acc@1: 87.5000 (87.2860)  Acc@5: 100.0000 (98.6198)  time: 0.3492  data: 0.0015  max mem: 2502
Train: Epoch[5/5]  [1440/3125]  eta: 0:09:48  Lr: 0.001875  Loss: -0.7720  Acc@1: 87.5000 (87.2918)  Acc@5: 100.0000 (98.6164)  time: 0.3485  data: 0.0011  max mem: 2502
Train: Epoch[5/5]  [1450/3125]  eta: 0:09:45  Lr: 0.001875  Loss: -0.6594  Acc@1: 87.5000 (87.2846)  Acc@5: 100.0000 (98.6173)  time: 0.3477  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [1460/3125]  eta: 0:09:41  Lr: 0.001875  Loss: -0.8081  Acc@1: 87.5000 (87.2818)  Acc@5: 100.0000 (98.6225)  time: 0.3478  data: 0.0009  max mem: 2502
Train: Epoch[5/5]  [1470/3125]  eta: 0:09:37  Lr: 0.001875  Loss: -0.6773  Acc@1: 87.5000 (87.2748)  Acc@5: 100.0000 (98.6191)  time: 0.3482  data: 0.0010  max mem: 2502
Train: Epoch[5/5]  [1480/3125]  eta: 0:09:34  Lr: 0.001875  Loss: -0.8273  Acc@1: 87.5000 (87.2468)  Acc@5: 100.0000 (98.6158)  time: 0.3479  data: 0.0008  max mem: 2502
Train: Epoch[5/5]  [1490/3125]  eta: 0:09:30  Lr: 0.001875  Loss: -0.6351  Acc@1: 81.2500 (87.2191)  Acc@5: 100.0000 (98.6209)  time: 0.3480  data: 0.0008  max mem: 2502
Train: Epoch[5/5]  [1500/3125]  eta: 0:09:27  Lr: 0.001875  Loss: -0.6689  Acc@1: 87.5000 (87.2210)  Acc@5: 100.0000 (98.6176)  time: 0.3480  data: 0.0011  max mem: 2502
Train: Epoch[5/5]  [1510/3125]  eta: 0:09:23  Lr: 0.001875  Loss: -0.5622  Acc@1: 87.5000 (87.1939)  Acc@5: 100.0000 (98.6226)  time: 0.3488  data: 0.0012  max mem: 2502
Train: Epoch[5/5]  [1520/3125]  eta: 0:09:20  Lr: 0.001875  Loss: -0.2080  Acc@1: 87.5000 (87.2000)  Acc@5: 100.0000 (98.6193)  time: 0.3496  data: 0.0009  max mem: 2502
Train: Epoch[5/5]  [1530/3125]  eta: 0:09:16  Lr: 0.001875  Loss: -0.7224  Acc@1: 87.5000 (87.1938)  Acc@5: 100.0000 (98.6243)  time: 0.3483  data: 0.0006  max mem: 2502
Train: Epoch[5/5]  [1540/3125]  eta: 0:09:13  Lr: 0.001875  Loss: -0.6373  Acc@1: 87.5000 (87.1918)  Acc@5: 100.0000 (98.6210)  time: 0.3496  data: 0.0006  max mem: 2502
Train: Epoch[5/5]  [1550/3125]  eta: 0:09:10  Lr: 0.001875  Loss: -0.2593  Acc@1: 87.5000 (87.2058)  Acc@5: 100.0000 (98.6259)  time: 0.3496  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [1560/3125]  eta: 0:09:06  Lr: 0.001875  Loss: -0.6694  Acc@1: 87.5000 (87.1837)  Acc@5: 100.0000 (98.6267)  time: 0.3474  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [1570/3125]  eta: 0:09:02  Lr: 0.001875  Loss: -0.4437  Acc@1: 81.2500 (87.1698)  Acc@5: 100.0000 (98.6195)  time: 0.3478  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [1580/3125]  eta: 0:08:59  Lr: 0.001875  Loss: -0.4153  Acc@1: 87.5000 (87.1798)  Acc@5: 100.0000 (98.6124)  time: 0.3478  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [1590/3125]  eta: 0:08:55  Lr: 0.001875  Loss: -0.3295  Acc@1: 87.5000 (87.1897)  Acc@5: 100.0000 (98.6172)  time: 0.3476  data: 0.0006  max mem: 2502
Train: Epoch[5/5]  [1600/3125]  eta: 0:08:52  Lr: 0.001875  Loss: -0.7727  Acc@1: 87.5000 (87.1760)  Acc@5: 100.0000 (98.6181)  time: 0.3482  data: 0.0010  max mem: 2502
Train: Epoch[5/5]  [1610/3125]  eta: 0:08:48  Lr: 0.001875  Loss: -0.7897  Acc@1: 87.5000 (87.2090)  Acc@5: 100.0000 (98.6227)  time: 0.3480  data: 0.0011  max mem: 2502
Train: Epoch[5/5]  [1620/3125]  eta: 0:08:45  Lr: 0.001875  Loss: -0.7261  Acc@1: 87.5000 (87.2070)  Acc@5: 100.0000 (98.6197)  time: 0.3479  data: 0.0008  max mem: 2502
Train: Epoch[5/5]  [1630/3125]  eta: 0:08:41  Lr: 0.001875  Loss: -0.7001  Acc@1: 87.5000 (87.2394)  Acc@5: 100.0000 (98.6281)  time: 0.3481  data: 0.0011  max mem: 2502
Train: Epoch[5/5]  [1640/3125]  eta: 0:08:38  Lr: 0.001875  Loss: -0.3180  Acc@1: 93.7500 (87.2524)  Acc@5: 100.0000 (98.6251)  time: 0.3474  data: 0.0010  max mem: 2502
Train: Epoch[5/5]  [1650/3125]  eta: 0:08:34  Lr: 0.001875  Loss: -0.8831  Acc@1: 93.7500 (87.2767)  Acc@5: 100.0000 (98.6296)  time: 0.3480  data: 0.0008  max mem: 2502
Train: Epoch[5/5]  [1660/3125]  eta: 0:08:31  Lr: 0.001875  Loss: -0.6005  Acc@1: 87.5000 (87.2780)  Acc@5: 100.0000 (98.6303)  time: 0.3486  data: 0.0009  max mem: 2502
Train: Epoch[5/5]  [1670/3125]  eta: 0:08:27  Lr: 0.001875  Loss: -0.6736  Acc@1: 87.5000 (87.2980)  Acc@5: 100.0000 (98.6273)  time: 0.3487  data: 0.0008  max mem: 2502
Train: Epoch[5/5]  [1680/3125]  eta: 0:08:24  Lr: 0.001875  Loss: -0.2243  Acc@1: 87.5000 (87.2695)  Acc@5: 100.0000 (98.6169)  time: 0.3484  data: 0.0008  max mem: 2502
Train: Epoch[5/5]  [1690/3125]  eta: 0:08:20  Lr: 0.001875  Loss: -0.4500  Acc@1: 87.5000 (87.2856)  Acc@5: 100.0000 (98.6140)  time: 0.3487  data: 0.0007  max mem: 2502
Train: Epoch[5/5]  [1700/3125]  eta: 0:08:17  Lr: 0.001875  Loss: -0.4234  Acc@1: 87.5000 (87.2832)  Acc@5: 100.0000 (98.6185)  time: 0.3493  data: 0.0007  max mem: 2502
Train: Epoch[5/5]  [1710/3125]  eta: 0:08:14  Lr: 0.001875  Loss: -0.5277  Acc@1: 87.5000 (87.2845)  Acc@5: 100.0000 (98.6192)  time: 0.3489  data: 0.0011  max mem: 2502
Train: Epoch[5/5]  [1720/3125]  eta: 0:08:10  Lr: 0.001875  Loss: 0.0809  Acc@1: 87.5000 (87.3148)  Acc@5: 100.0000 (98.6200)  time: 0.3485  data: 0.0013  max mem: 2502
Train: Epoch[5/5]  [1730/3125]  eta: 0:08:07  Lr: 0.001875  Loss: -0.7555  Acc@1: 93.7500 (87.3086)  Acc@5: 100.0000 (98.6280)  time: 0.3485  data: 0.0013  max mem: 2502
Train: Epoch[5/5]  [1740/3125]  eta: 0:08:03  Lr: 0.001875  Loss: -0.6951  Acc@1: 87.5000 (87.3313)  Acc@5: 100.0000 (98.6323)  time: 0.3485  data: 0.0012  max mem: 2502
Train: Epoch[5/5]  [1750/3125]  eta: 0:08:00  Lr: 0.001875  Loss: -0.7583  Acc@1: 87.5000 (87.3144)  Acc@5: 100.0000 (98.6258)  time: 0.3480  data: 0.0007  max mem: 2502
Train: Epoch[5/5]  [1760/3125]  eta: 0:07:56  Lr: 0.001875  Loss: -0.7572  Acc@1: 87.5000 (87.3225)  Acc@5: 100.0000 (98.6265)  time: 0.3485  data: 0.0008  max mem: 2502
Train: Epoch[5/5]  [1770/3125]  eta: 0:07:53  Lr: 0.001875  Loss: -0.8119  Acc@1: 87.5000 (87.2918)  Acc@5: 100.0000 (98.6166)  time: 0.3487  data: 0.0008  max mem: 2502
Train: Epoch[5/5]  [1780/3125]  eta: 0:07:49  Lr: 0.001875  Loss: -0.7577  Acc@1: 87.5000 (87.3105)  Acc@5: 100.0000 (98.6209)  time: 0.3485  data: 0.0007  max mem: 2502
Train: Epoch[5/5]  [1790/3125]  eta: 0:07:46  Lr: 0.001875  Loss: -0.4075  Acc@1: 87.5000 (87.3081)  Acc@5: 100.0000 (98.6216)  time: 0.3485  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [1800/3125]  eta: 0:07:42  Lr: 0.001875  Loss: -0.3899  Acc@1: 87.5000 (87.2987)  Acc@5: 100.0000 (98.6188)  time: 0.3486  data: 0.0006  max mem: 2502
Train: Epoch[5/5]  [1810/3125]  eta: 0:07:39  Lr: 0.001875  Loss: -0.7560  Acc@1: 87.5000 (87.3033)  Acc@5: 100.0000 (98.6195)  time: 0.3485  data: 0.0006  max mem: 2502
Train: Epoch[5/5]  [1820/3125]  eta: 0:07:35  Lr: 0.001875  Loss: -0.6414  Acc@1: 87.5000 (87.3112)  Acc@5: 100.0000 (98.6203)  time: 0.3483  data: 0.0009  max mem: 2502
Train: Epoch[5/5]  [1830/3125]  eta: 0:07:32  Lr: 0.001875  Loss: -0.2605  Acc@1: 87.5000 (87.3191)  Acc@5: 100.0000 (98.6210)  time: 0.3482  data: 0.0017  max mem: 2502
Train: Epoch[5/5]  [1840/3125]  eta: 0:07:28  Lr: 0.001875  Loss: -0.7188  Acc@1: 93.7500 (87.3506)  Acc@5: 100.0000 (98.6183)  time: 0.3479  data: 0.0014  max mem: 2502
Train: Epoch[5/5]  [1850/3125]  eta: 0:07:25  Lr: 0.001875  Loss: -0.6370  Acc@1: 87.5000 (87.3413)  Acc@5: 100.0000 (98.6190)  time: 0.3473  data: 0.0007  max mem: 2502
Train: Epoch[5/5]  [1860/3125]  eta: 0:07:21  Lr: 0.001875  Loss: -0.5481  Acc@1: 81.2500 (87.3321)  Acc@5: 100.0000 (98.6197)  time: 0.3484  data: 0.0011  max mem: 2502
Train: Epoch[5/5]  [1870/3125]  eta: 0:07:18  Lr: 0.001875  Loss: -0.3537  Acc@1: 81.2500 (87.3129)  Acc@5: 100.0000 (98.6204)  time: 0.3497  data: 0.0020  max mem: 2502
Train: Epoch[5/5]  [1880/3125]  eta: 0:07:14  Lr: 0.001875  Loss: -0.3367  Acc@1: 87.5000 (87.3106)  Acc@5: 100.0000 (98.6178)  time: 0.3488  data: 0.0016  max mem: 2502
Train: Epoch[5/5]  [1890/3125]  eta: 0:07:11  Lr: 0.001875  Loss: -0.7676  Acc@1: 87.5000 (87.3182)  Acc@5: 100.0000 (98.6152)  time: 0.3483  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [1900/3125]  eta: 0:07:07  Lr: 0.001875  Loss: -0.7744  Acc@1: 93.7500 (87.3488)  Acc@5: 100.0000 (98.6159)  time: 0.3490  data: 0.0007  max mem: 2502
Train: Epoch[5/5]  [1910/3125]  eta: 0:07:04  Lr: 0.001875  Loss: -0.6757  Acc@1: 87.5000 (87.3267)  Acc@5: 100.0000 (98.6133)  time: 0.3492  data: 0.0011  max mem: 2502
Train: Epoch[5/5]  [1920/3125]  eta: 0:07:00  Lr: 0.001875  Loss: -0.5405  Acc@1: 87.5000 (87.3308)  Acc@5: 100.0000 (98.6107)  time: 0.3484  data: 0.0010  max mem: 2502
Train: Epoch[5/5]  [1930/3125]  eta: 0:06:57  Lr: 0.001875  Loss: -0.4055  Acc@1: 87.5000 (87.3155)  Acc@5: 100.0000 (98.6147)  time: 0.3476  data: 0.0007  max mem: 2502
Train: Epoch[5/5]  [1940/3125]  eta: 0:06:53  Lr: 0.001875  Loss: -0.6853  Acc@1: 87.5000 (87.3487)  Acc@5: 100.0000 (98.6154)  time: 0.3475  data: 0.0006  max mem: 2502
Train: Epoch[5/5]  [1950/3125]  eta: 0:06:50  Lr: 0.001875  Loss: -0.1878  Acc@1: 87.5000 (87.3206)  Acc@5: 100.0000 (98.6097)  time: 0.3482  data: 0.0011  max mem: 2502
Train: Epoch[5/5]  [1960/3125]  eta: 0:06:46  Lr: 0.001875  Loss: -0.7589  Acc@1: 81.2500 (87.3120)  Acc@5: 100.0000 (98.6104)  time: 0.3488  data: 0.0010  max mem: 2502
Train: Epoch[5/5]  [1970/3125]  eta: 0:06:43  Lr: 0.001875  Loss: -0.4164  Acc@1: 81.2500 (87.3066)  Acc@5: 100.0000 (98.6143)  time: 0.3500  data: 0.0013  max mem: 2502
Train: Epoch[5/5]  [1980/3125]  eta: 0:06:39  Lr: 0.001875  Loss: -0.5945  Acc@1: 87.5000 (87.2918)  Acc@5: 100.0000 (98.6181)  time: 0.3498  data: 0.0013  max mem: 2502
Train: Epoch[5/5]  [1990/3125]  eta: 0:06:36  Lr: 0.001875  Loss: -0.8850  Acc@1: 87.5000 (87.2991)  Acc@5: 100.0000 (98.6219)  time: 0.3483  data: 0.0011  max mem: 2502
Train: Epoch[5/5]  [2000/3125]  eta: 0:06:32  Lr: 0.001875  Loss: -0.6029  Acc@1: 87.5000 (87.3063)  Acc@5: 100.0000 (98.6163)  time: 0.3493  data: 0.0012  max mem: 2502
Train: Epoch[5/5]  [2010/3125]  eta: 0:06:29  Lr: 0.001875  Loss: -0.4906  Acc@1: 87.5000 (87.3228)  Acc@5: 100.0000 (98.6170)  time: 0.3505  data: 0.0007  max mem: 2502
Train: Epoch[5/5]  [2020/3125]  eta: 0:06:25  Lr: 0.001875  Loss: -0.7699  Acc@1: 87.5000 (87.3083)  Acc@5: 100.0000 (98.6176)  time: 0.3498  data: 0.0007  max mem: 2502
Train: Epoch[5/5]  [2030/3125]  eta: 0:06:22  Lr: 0.001875  Loss: 0.3663  Acc@1: 87.5000 (87.3061)  Acc@5: 100.0000 (98.6121)  time: 0.3478  data: 0.0007  max mem: 2502
Train: Epoch[5/5]  [2040/3125]  eta: 0:06:18  Lr: 0.001875  Loss: -0.8380  Acc@1: 81.2500 (87.2826)  Acc@5: 100.0000 (98.6098)  time: 0.3473  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [2050/3125]  eta: 0:06:15  Lr: 0.001875  Loss: -0.0061  Acc@1: 87.5000 (87.2836)  Acc@5: 100.0000 (98.6165)  time: 0.3478  data: 0.0008  max mem: 2502
Train: Epoch[5/5]  [2060/3125]  eta: 0:06:11  Lr: 0.001875  Loss: -0.2950  Acc@1: 87.5000 (87.2817)  Acc@5: 100.0000 (98.6202)  time: 0.3487  data: 0.0008  max mem: 2502
Train: Epoch[5/5]  [2070/3125]  eta: 0:06:08  Lr: 0.001875  Loss: -0.6107  Acc@1: 87.5000 (87.2827)  Acc@5: 100.0000 (98.6208)  time: 0.3485  data: 0.0007  max mem: 2502
Train: Epoch[5/5]  [2080/3125]  eta: 0:06:04  Lr: 0.001875  Loss: -0.5146  Acc@1: 87.5000 (87.2898)  Acc@5: 100.0000 (98.6275)  time: 0.3473  data: 0.0008  max mem: 2502
Train: Epoch[5/5]  [2090/3125]  eta: 0:06:01  Lr: 0.001875  Loss: -0.8282  Acc@1: 87.5000 (87.3027)  Acc@5: 100.0000 (98.6310)  time: 0.3475  data: 0.0006  max mem: 2502
Train: Epoch[5/5]  [2100/3125]  eta: 0:05:57  Lr: 0.001875  Loss: -0.6427  Acc@1: 87.5000 (87.2947)  Acc@5: 100.0000 (98.6316)  time: 0.3488  data: 0.0012  max mem: 2502
Train: Epoch[5/5]  [2110/3125]  eta: 0:05:54  Lr: 0.001875  Loss: -0.3491  Acc@1: 87.5000 (87.2987)  Acc@5: 100.0000 (98.6322)  time: 0.3504  data: 0.0016  max mem: 2502
Train: Epoch[5/5]  [2120/3125]  eta: 0:05:50  Lr: 0.001875  Loss: -0.6664  Acc@1: 87.5000 (87.3026)  Acc@5: 100.0000 (98.6357)  time: 0.3498  data: 0.0012  max mem: 2502
Train: Epoch[5/5]  [2130/3125]  eta: 0:05:47  Lr: 0.001875  Loss: -0.4092  Acc@1: 87.5000 (87.2859)  Acc@5: 100.0000 (98.6274)  time: 0.3489  data: 0.0012  max mem: 2502
Train: Epoch[5/5]  [2140/3125]  eta: 0:05:43  Lr: 0.001875  Loss: -0.2078  Acc@1: 87.5000 (87.3015)  Acc@5: 100.0000 (98.6280)  time: 0.3486  data: 0.0010  max mem: 2502
Train: Epoch[5/5]  [2150/3125]  eta: 0:05:40  Lr: 0.001875  Loss: -0.5212  Acc@1: 87.5000 (87.3024)  Acc@5: 100.0000 (98.6285)  time: 0.3476  data: 0.0009  max mem: 2502
Train: Epoch[5/5]  [2160/3125]  eta: 0:05:36  Lr: 0.001875  Loss: -0.5619  Acc@1: 81.2500 (87.2831)  Acc@5: 100.0000 (98.6262)  time: 0.3483  data: 0.0015  max mem: 2502
Train: Epoch[5/5]  [2170/3125]  eta: 0:05:33  Lr: 0.001875  Loss: -0.8134  Acc@1: 81.2500 (87.2668)  Acc@5: 100.0000 (98.6297)  time: 0.3485  data: 0.0013  max mem: 2502
Train: Epoch[5/5]  [2180/3125]  eta: 0:05:29  Lr: 0.001875  Loss: -0.3582  Acc@1: 81.2500 (87.2478)  Acc@5: 100.0000 (98.6273)  time: 0.3482  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [2190/3125]  eta: 0:05:26  Lr: 0.001875  Loss: -0.4735  Acc@1: 87.5000 (87.2547)  Acc@5: 100.0000 (98.6308)  time: 0.3497  data: 0.0012  max mem: 2502
Train: Epoch[5/5]  [2200/3125]  eta: 0:05:22  Lr: 0.001875  Loss: -0.8873  Acc@1: 87.5000 (87.2672)  Acc@5: 100.0000 (98.6256)  time: 0.3505  data: 0.0012  max mem: 2502
Train: Epoch[5/5]  [2210/3125]  eta: 0:05:19  Lr: 0.001875  Loss: -0.6498  Acc@1: 93.7500 (87.2767)  Acc@5: 100.0000 (98.6234)  time: 0.3493  data: 0.0006  max mem: 2502
Train: Epoch[5/5]  [2220/3125]  eta: 0:05:15  Lr: 0.001875  Loss: -0.6299  Acc@1: 87.5000 (87.2777)  Acc@5: 100.0000 (98.6267)  time: 0.3474  data: 0.0007  max mem: 2502
Train: Epoch[5/5]  [2230/3125]  eta: 0:05:12  Lr: 0.001875  Loss: -0.9230  Acc@1: 87.5000 (87.2927)  Acc@5: 100.0000 (98.6245)  time: 0.3475  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [2240/3125]  eta: 0:05:08  Lr: 0.001875  Loss: -0.8476  Acc@1: 87.5000 (87.2964)  Acc@5: 100.0000 (98.6278)  time: 0.3490  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [2250/3125]  eta: 0:05:05  Lr: 0.001875  Loss: -0.8380  Acc@1: 93.7500 (87.3056)  Acc@5: 100.0000 (98.6284)  time: 0.3489  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [2260/3125]  eta: 0:05:01  Lr: 0.001875  Loss: -0.5240  Acc@1: 93.7500 (87.3259)  Acc@5: 100.0000 (98.6317)  time: 0.3477  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [2270/3125]  eta: 0:04:58  Lr: 0.001875  Loss: -0.4263  Acc@1: 87.5000 (87.3239)  Acc@5: 100.0000 (98.6377)  time: 0.3476  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [2280/3125]  eta: 0:04:54  Lr: 0.001875  Loss: 0.1737  Acc@1: 81.2500 (87.3055)  Acc@5: 100.0000 (98.6327)  time: 0.3491  data: 0.0009  max mem: 2502
Train: Epoch[5/5]  [2290/3125]  eta: 0:04:51  Lr: 0.001875  Loss: -0.5736  Acc@1: 87.5000 (87.3199)  Acc@5: 100.0000 (98.6387)  time: 0.3494  data: 0.0010  max mem: 2502
Train: Epoch[5/5]  [2300/3125]  eta: 0:04:47  Lr: 0.001875  Loss: -0.6466  Acc@1: 87.5000 (87.3071)  Acc@5: 100.0000 (98.6310)  time: 0.3489  data: 0.0014  max mem: 2502
Train: Epoch[5/5]  [2310/3125]  eta: 0:04:44  Lr: 0.001875  Loss: -0.7061  Acc@1: 87.5000 (87.3053)  Acc@5: 100.0000 (98.6315)  time: 0.3487  data: 0.0016  max mem: 2502
Train: Epoch[5/5]  [2320/3125]  eta: 0:04:40  Lr: 0.001875  Loss: -0.7587  Acc@1: 87.5000 (87.3061)  Acc@5: 100.0000 (98.6321)  time: 0.3480  data: 0.0012  max mem: 2502
Train: Epoch[5/5]  [2330/3125]  eta: 0:04:37  Lr: 0.001875  Loss: -0.7855  Acc@1: 87.5000 (87.2828)  Acc@5: 100.0000 (98.6272)  time: 0.3474  data: 0.0011  max mem: 2502
Train: Epoch[5/5]  [2340/3125]  eta: 0:04:33  Lr: 0.001875  Loss: -0.6306  Acc@1: 87.5000 (87.2864)  Acc@5: 100.0000 (98.6224)  time: 0.3474  data: 0.0008  max mem: 2502
Train: Epoch[5/5]  [2350/3125]  eta: 0:04:30  Lr: 0.001875  Loss: -0.7499  Acc@1: 87.5000 (87.2847)  Acc@5: 100.0000 (98.6256)  time: 0.3479  data: 0.0008  max mem: 2502
Train: Epoch[5/5]  [2360/3125]  eta: 0:04:26  Lr: 0.001875  Loss: -0.5308  Acc@1: 87.5000 (87.2803)  Acc@5: 100.0000 (98.6314)  time: 0.3485  data: 0.0009  max mem: 2502
Train: Epoch[5/5]  [2370/3125]  eta: 0:04:23  Lr: 0.001875  Loss: -0.2224  Acc@1: 87.5000 (87.2838)  Acc@5: 100.0000 (98.6345)  time: 0.3484  data: 0.0012  max mem: 2502
Train: Epoch[5/5]  [2380/3125]  eta: 0:04:19  Lr: 0.001875  Loss: -0.7820  Acc@1: 87.5000 (87.2926)  Acc@5: 100.0000 (98.6403)  time: 0.3475  data: 0.0012  max mem: 2502
Train: Epoch[5/5]  [2390/3125]  eta: 0:04:16  Lr: 0.001875  Loss: -0.5119  Acc@1: 87.5000 (87.2961)  Acc@5: 100.0000 (98.6434)  time: 0.3476  data: 0.0012  max mem: 2502
Train: Epoch[5/5]  [2400/3125]  eta: 0:04:12  Lr: 0.001875  Loss: -0.5702  Acc@1: 87.5000 (87.2996)  Acc@5: 100.0000 (98.6412)  time: 0.3485  data: 0.0008  max mem: 2502
Train: Epoch[5/5]  [2410/3125]  eta: 0:04:09  Lr: 0.001875  Loss: -0.4842  Acc@1: 87.5000 (87.3056)  Acc@5: 100.0000 (98.6365)  time: 0.3483  data: 0.0007  max mem: 2502
Train: Epoch[5/5]  [2420/3125]  eta: 0:04:05  Lr: 0.001875  Loss: -0.6615  Acc@1: 87.5000 (87.3115)  Acc@5: 100.0000 (98.6395)  time: 0.3478  data: 0.0011  max mem: 2502
Train: Epoch[5/5]  [2430/3125]  eta: 0:04:02  Lr: 0.001875  Loss: -0.6670  Acc@1: 87.5000 (87.3046)  Acc@5: 100.0000 (98.6348)  time: 0.3477  data: 0.0010  max mem: 2502
Train: Epoch[5/5]  [2440/3125]  eta: 0:03:59  Lr: 0.001875  Loss: -0.5587  Acc@1: 87.5000 (87.3105)  Acc@5: 100.0000 (98.6353)  time: 0.3481  data: 0.0006  max mem: 2502
Train: Epoch[5/5]  [2450/3125]  eta: 0:03:55  Lr: 0.001875  Loss: -0.7504  Acc@1: 87.5000 (87.3266)  Acc@5: 100.0000 (98.6383)  time: 0.3482  data: 0.0007  max mem: 2502
Train: Epoch[5/5]  [2460/3125]  eta: 0:03:52  Lr: 0.001875  Loss: -0.7724  Acc@1: 87.5000 (87.3222)  Acc@5: 100.0000 (98.6413)  time: 0.3475  data: 0.0006  max mem: 2502
Train: Epoch[5/5]  [2470/3125]  eta: 0:03:48  Lr: 0.001875  Loss: -0.3310  Acc@1: 87.5000 (87.3204)  Acc@5: 100.0000 (98.6443)  time: 0.3487  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [2480/3125]  eta: 0:03:45  Lr: 0.001875  Loss: -0.3941  Acc@1: 87.5000 (87.3085)  Acc@5: 100.0000 (98.6447)  time: 0.3496  data: 0.0006  max mem: 2502
Train: Epoch[5/5]  [2490/3125]  eta: 0:03:41  Lr: 0.001875  Loss: -0.5197  Acc@1: 87.5000 (87.3118)  Acc@5: 100.0000 (98.6426)  time: 0.3482  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [2500/3125]  eta: 0:03:38  Lr: 0.001875  Loss: -0.9337  Acc@1: 87.5000 (87.3151)  Acc@5: 100.0000 (98.6455)  time: 0.3476  data: 0.0007  max mem: 2502
Train: Epoch[5/5]  [2510/3125]  eta: 0:03:34  Lr: 0.001875  Loss: -0.4947  Acc@1: 87.5000 (87.3183)  Acc@5: 100.0000 (98.6484)  time: 0.3500  data: 0.0023  max mem: 2502
Train: Epoch[5/5]  [2520/3125]  eta: 0:03:31  Lr: 0.001875  Loss: -0.8902  Acc@1: 87.5000 (87.3265)  Acc@5: 100.0000 (98.6464)  time: 0.3497  data: 0.0022  max mem: 2502
Train: Epoch[5/5]  [2530/3125]  eta: 0:03:27  Lr: 0.001875  Loss: -0.3907  Acc@1: 87.5000 (87.3494)  Acc@5: 100.0000 (98.6492)  time: 0.3483  data: 0.0010  max mem: 2502
Train: Epoch[5/5]  [2540/3125]  eta: 0:03:24  Lr: 0.001875  Loss: -0.6380  Acc@1: 87.5000 (87.3524)  Acc@5: 100.0000 (98.6521)  time: 0.3501  data: 0.0021  max mem: 2502
Train: Epoch[5/5]  [2550/3125]  eta: 0:03:20  Lr: 0.001875  Loss: -0.7525  Acc@1: 87.5000 (87.3579)  Acc@5: 100.0000 (98.6500)  time: 0.3503  data: 0.0027  max mem: 2502
Train: Epoch[5/5]  [2560/3125]  eta: 0:03:17  Lr: 0.001875  Loss: -0.7710  Acc@1: 87.5000 (87.3560)  Acc@5: 100.0000 (98.6455)  time: 0.3488  data: 0.0017  max mem: 2502
Train: Epoch[5/5]  [2570/3125]  eta: 0:03:13  Lr: 0.001875  Loss: -0.5268  Acc@1: 87.5000 (87.3639)  Acc@5: 100.0000 (98.6411)  time: 0.3483  data: 0.0008  max mem: 2502
Train: Epoch[5/5]  [2580/3125]  eta: 0:03:10  Lr: 0.001875  Loss: -0.5911  Acc@1: 87.5000 (87.3813)  Acc@5: 100.0000 (98.6439)  time: 0.3484  data: 0.0007  max mem: 2502
Train: Epoch[5/5]  [2590/3125]  eta: 0:03:06  Lr: 0.001875  Loss: -0.8686  Acc@1: 87.5000 (87.3794)  Acc@5: 100.0000 (98.6443)  time: 0.3486  data: 0.0014  max mem: 2502
Train: Epoch[5/5]  [2600/3125]  eta: 0:03:03  Lr: 0.001875  Loss: -0.3963  Acc@1: 87.5000 (87.3726)  Acc@5: 100.0000 (98.6472)  time: 0.3486  data: 0.0016  max mem: 2502
Train: Epoch[5/5]  [2610/3125]  eta: 0:02:59  Lr: 0.001875  Loss: -0.3115  Acc@1: 87.5000 (87.3731)  Acc@5: 100.0000 (98.6523)  time: 0.3485  data: 0.0008  max mem: 2502
Train: Epoch[5/5]  [2620/3125]  eta: 0:02:56  Lr: 0.001875  Loss: -0.3399  Acc@1: 87.5000 (87.3736)  Acc@5: 100.0000 (98.6575)  time: 0.3484  data: 0.0007  max mem: 2502
Train: Epoch[5/5]  [2630/3125]  eta: 0:02:52  Lr: 0.001875  Loss: -0.2037  Acc@1: 87.5000 (87.3575)  Acc@5: 100.0000 (98.6555)  time: 0.3493  data: 0.0017  max mem: 2502
Train: Epoch[5/5]  [2640/3125]  eta: 0:02:49  Lr: 0.001875  Loss: -0.4407  Acc@1: 87.5000 (87.3533)  Acc@5: 100.0000 (98.6558)  time: 0.3493  data: 0.0018  max mem: 2502
Train: Epoch[5/5]  [2650/3125]  eta: 0:02:45  Lr: 0.001875  Loss: -0.5275  Acc@1: 87.5000 (87.3444)  Acc@5: 100.0000 (98.6538)  time: 0.3494  data: 0.0024  max mem: 2502
Train: Epoch[5/5]  [2660/3125]  eta: 0:02:42  Lr: 0.001875  Loss: -0.6641  Acc@1: 87.5000 (87.3497)  Acc@5: 100.0000 (98.6565)  time: 0.3492  data: 0.0021  max mem: 2502
Train: Epoch[5/5]  [2670/3125]  eta: 0:02:38  Lr: 0.001875  Loss: -0.7397  Acc@1: 87.5000 (87.3456)  Acc@5: 100.0000 (98.6499)  time: 0.3484  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [2680/3125]  eta: 0:02:35  Lr: 0.001875  Loss: -0.5111  Acc@1: 81.2500 (87.3322)  Acc@5: 100.0000 (98.6502)  time: 0.3488  data: 0.0006  max mem: 2502
Train: Epoch[5/5]  [2690/3125]  eta: 0:02:31  Lr: 0.001875  Loss: -0.6073  Acc@1: 81.2500 (87.3351)  Acc@5: 100.0000 (98.6529)  time: 0.3476  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [2700/3125]  eta: 0:02:28  Lr: 0.001875  Loss: -0.5324  Acc@1: 87.5000 (87.3403)  Acc@5: 100.0000 (98.6556)  time: 0.3485  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [2710/3125]  eta: 0:02:24  Lr: 0.001875  Loss: -0.3985  Acc@1: 87.5000 (87.3432)  Acc@5: 100.0000 (98.6559)  time: 0.3488  data: 0.0006  max mem: 2502
Train: Epoch[5/5]  [2720/3125]  eta: 0:02:21  Lr: 0.001875  Loss: -0.5843  Acc@1: 87.5000 (87.3530)  Acc@5: 100.0000 (98.6586)  time: 0.3485  data: 0.0007  max mem: 2502
Train: Epoch[5/5]  [2730/3125]  eta: 0:02:17  Lr: 0.001875  Loss: -0.7801  Acc@1: 87.5000 (87.3558)  Acc@5: 100.0000 (98.6566)  time: 0.3481  data: 0.0006  max mem: 2502
Train: Epoch[5/5]  [2740/3125]  eta: 0:02:14  Lr: 0.001875  Loss: -0.3159  Acc@1: 87.5000 (87.3472)  Acc@5: 100.0000 (98.6592)  time: 0.3472  data: 0.0006  max mem: 2502
Train: Epoch[5/5]  [2750/3125]  eta: 0:02:10  Lr: 0.001875  Loss: -0.4250  Acc@1: 87.5000 (87.3342)  Acc@5: 100.0000 (98.6573)  time: 0.3483  data: 0.0011  max mem: 2502
Train: Epoch[5/5]  [2760/3125]  eta: 0:02:07  Lr: 0.001875  Loss: -0.5951  Acc@1: 81.2500 (87.3280)  Acc@5: 100.0000 (98.6599)  time: 0.3486  data: 0.0012  max mem: 2502
Train: Epoch[5/5]  [2770/3125]  eta: 0:02:03  Lr: 0.001875  Loss: -0.6886  Acc@1: 87.5000 (87.3421)  Acc@5: 100.0000 (98.6625)  time: 0.3479  data: 0.0008  max mem: 2502
Train: Epoch[5/5]  [2780/3125]  eta: 0:02:00  Lr: 0.001875  Loss: -0.4978  Acc@1: 87.5000 (87.3427)  Acc@5: 100.0000 (98.6561)  time: 0.3482  data: 0.0007  max mem: 2502
Train: Epoch[5/5]  [2790/3125]  eta: 0:01:56  Lr: 0.001875  Loss: -0.6560  Acc@1: 87.5000 (87.3500)  Acc@5: 100.0000 (98.6497)  time: 0.3482  data: 0.0010  max mem: 2502
Train: Epoch[5/5]  [2800/3125]  eta: 0:01:53  Lr: 0.001875  Loss: -0.9144  Acc@1: 87.5000 (87.3639)  Acc@5: 100.0000 (98.6523)  time: 0.3471  data: 0.0009  max mem: 2502
Train: Epoch[5/5]  [2810/3125]  eta: 0:01:49  Lr: 0.001875  Loss: -0.6904  Acc@1: 87.5000 (87.3666)  Acc@5: 100.0000 (98.6482)  time: 0.3475  data: 0.0009  max mem: 2502
Train: Epoch[5/5]  [2820/3125]  eta: 0:01:46  Lr: 0.001875  Loss: -0.7067  Acc@1: 93.7500 (87.3826)  Acc@5: 100.0000 (98.6485)  time: 0.3479  data: 0.0008  max mem: 2502
Train: Epoch[5/5]  [2830/3125]  eta: 0:01:42  Lr: 0.001875  Loss: -0.7842  Acc@1: 93.7500 (87.3918)  Acc@5: 100.0000 (98.6423)  time: 0.3483  data: 0.0006  max mem: 2502
Train: Epoch[5/5]  [2840/3125]  eta: 0:01:39  Lr: 0.001875  Loss: -0.7448  Acc@1: 87.5000 (87.3900)  Acc@5: 100.0000 (98.6426)  time: 0.3496  data: 0.0011  max mem: 2502
Train: Epoch[5/5]  [2850/3125]  eta: 0:01:35  Lr: 0.001875  Loss: -0.8266  Acc@1: 87.5000 (87.3970)  Acc@5: 100.0000 (98.6474)  time: 0.3513  data: 0.0025  max mem: 2502
Train: Epoch[5/5]  [2860/3125]  eta: 0:01:32  Lr: 0.001875  Loss: -0.5100  Acc@1: 87.5000 (87.3995)  Acc@5: 100.0000 (98.6456)  time: 0.3509  data: 0.0023  max mem: 2502
Train: Epoch[5/5]  [2870/3125]  eta: 0:01:28  Lr: 0.001875  Loss: -0.6379  Acc@1: 87.5000 (87.4020)  Acc@5: 100.0000 (98.6459)  time: 0.3484  data: 0.0008  max mem: 2502
Train: Epoch[5/5]  [2880/3125]  eta: 0:01:25  Lr: 0.001875  Loss: -0.5834  Acc@1: 87.5000 (87.3980)  Acc@5: 100.0000 (98.6420)  time: 0.3476  data: 0.0006  max mem: 2502
Train: Epoch[5/5]  [2890/3125]  eta: 0:01:21  Lr: 0.001875  Loss: -0.1885  Acc@1: 87.5000 (87.3962)  Acc@5: 100.0000 (98.6380)  time: 0.3490  data: 0.0019  max mem: 2502
Train: Epoch[5/5]  [2900/3125]  eta: 0:01:18  Lr: 0.001875  Loss: -0.5386  Acc@1: 87.5000 (87.4009)  Acc@5: 100.0000 (98.6427)  time: 0.3493  data: 0.0020  max mem: 2502
Train: Epoch[5/5]  [2910/3125]  eta: 0:01:15  Lr: 0.001875  Loss: -0.7647  Acc@1: 87.5000 (87.4012)  Acc@5: 100.0000 (98.6409)  time: 0.3487  data: 0.0009  max mem: 2502
Train: Epoch[5/5]  [2920/3125]  eta: 0:01:11  Lr: 0.001875  Loss: -0.8945  Acc@1: 87.5000 (87.3887)  Acc@5: 100.0000 (98.6434)  time: 0.3491  data: 0.0008  max mem: 2502
Train: Epoch[5/5]  [2930/3125]  eta: 0:01:08  Lr: 0.001875  Loss: -0.8087  Acc@1: 81.2500 (87.3785)  Acc@5: 100.0000 (98.6438)  time: 0.3480  data: 0.0008  max mem: 2502
Train: Epoch[5/5]  [2940/3125]  eta: 0:01:04  Lr: 0.001875  Loss: -0.3326  Acc@1: 81.2500 (87.3704)  Acc@5: 100.0000 (98.6378)  time: 0.3474  data: 0.0007  max mem: 2502
Train: Epoch[5/5]  [2950/3125]  eta: 0:01:01  Lr: 0.001875  Loss: -0.1577  Acc@1: 87.5000 (87.3708)  Acc@5: 100.0000 (98.6361)  time: 0.3480  data: 0.0007  max mem: 2502
Train: Epoch[5/5]  [2960/3125]  eta: 0:00:57  Lr: 0.001875  Loss: -0.6237  Acc@1: 87.5000 (87.3712)  Acc@5: 100.0000 (98.6322)  time: 0.3484  data: 0.0007  max mem: 2502
Train: Epoch[5/5]  [2970/3125]  eta: 0:00:54  Lr: 0.001875  Loss: -0.5763  Acc@1: 87.5000 (87.3801)  Acc@5: 100.0000 (98.6326)  time: 0.3484  data: 0.0006  max mem: 2502
Train: Epoch[5/5]  [2980/3125]  eta: 0:00:50  Lr: 0.001875  Loss: -0.7068  Acc@1: 87.5000 (87.3805)  Acc@5: 100.0000 (98.6351)  time: 0.3474  data: 0.0008  max mem: 2502
Train: Epoch[5/5]  [2990/3125]  eta: 0:00:47  Lr: 0.001875  Loss: -0.2204  Acc@1: 87.5000 (87.3725)  Acc@5: 100.0000 (98.6355)  time: 0.3475  data: 0.0008  max mem: 2502
Train: Epoch[5/5]  [3000/3125]  eta: 0:00:43  Lr: 0.001875  Loss: -0.5706  Acc@1: 87.5000 (87.3688)  Acc@5: 100.0000 (98.6317)  time: 0.3477  data: 0.0008  max mem: 2502
Train: Epoch[5/5]  [3010/3125]  eta: 0:00:40  Lr: 0.001875  Loss: -0.3969  Acc@1: 87.5000 (87.3775)  Acc@5: 100.0000 (98.6342)  time: 0.3488  data: 0.0011  max mem: 2502
Train: Epoch[5/5]  [3020/3125]  eta: 0:00:36  Lr: 0.001875  Loss: -0.7382  Acc@1: 87.5000 (87.3862)  Acc@5: 100.0000 (98.6325)  time: 0.3489  data: 0.0012  max mem: 2502
Train: Epoch[5/5]  [3030/3125]  eta: 0:00:33  Lr: 0.001875  Loss: -0.6826  Acc@1: 87.5000 (87.3618)  Acc@5: 100.0000 (98.6308)  time: 0.3476  data: 0.0010  max mem: 2502
Train: Epoch[5/5]  [3040/3125]  eta: 0:00:29  Lr: 0.001875  Loss: -0.4689  Acc@1: 81.2500 (87.3602)  Acc@5: 100.0000 (98.6292)  time: 0.3486  data: 0.0015  max mem: 2502
Train: Epoch[5/5]  [3050/3125]  eta: 0:00:26  Lr: 0.001875  Loss: -0.6668  Acc@1: 87.5000 (87.3627)  Acc@5: 100.0000 (98.6295)  time: 0.3479  data: 0.0011  max mem: 2502
Train: Epoch[5/5]  [3060/3125]  eta: 0:00:22  Lr: 0.001875  Loss: -0.8728  Acc@1: 87.5000 (87.3754)  Acc@5: 100.0000 (98.6259)  time: 0.3470  data: 0.0007  max mem: 2502
Train: Epoch[5/5]  [3070/3125]  eta: 0:00:19  Lr: 0.001875  Loss: -0.6431  Acc@1: 93.7500 (87.3779)  Acc@5: 100.0000 (98.6263)  time: 0.3482  data: 0.0010  max mem: 2502
Train: Epoch[5/5]  [3080/3125]  eta: 0:00:15  Lr: 0.001875  Loss: -0.7925  Acc@1: 93.7500 (87.3823)  Acc@5: 100.0000 (98.6226)  time: 0.3498  data: 0.0012  max mem: 2502
Train: Epoch[5/5]  [3090/3125]  eta: 0:00:12  Lr: 0.001875  Loss: -0.6817  Acc@1: 87.5000 (87.3787)  Acc@5: 100.0000 (98.6250)  time: 0.3504  data: 0.0022  max mem: 2502
Train: Epoch[5/5]  [3100/3125]  eta: 0:00:08  Lr: 0.001875  Loss: -0.3914  Acc@1: 87.5000 (87.3730)  Acc@5: 100.0000 (98.6275)  time: 0.3486  data: 0.0018  max mem: 2502
Train: Epoch[5/5]  [3110/3125]  eta: 0:00:05  Lr: 0.001875  Loss: -0.4641  Acc@1: 87.5000 (87.3795)  Acc@5: 100.0000 (98.6258)  time: 0.3483  data: 0.0006  max mem: 2502
Train: Epoch[5/5]  [3120/3125]  eta: 0:00:01  Lr: 0.001875  Loss: -0.6225  Acc@1: 87.5000 (87.3839)  Acc@5: 100.0000 (98.6262)  time: 0.3494  data: 0.0013  max mem: 2502
Train: Epoch[5/5]  [3124/3125]  eta: 0:00:00  Lr: 0.001875  Loss: -0.4415  Acc@1: 87.5000 (87.3860)  Acc@5: 100.0000 (98.6280)  time: 0.3487  data: 0.0013  max mem: 2502
Train: Epoch[5/5] Total time: 0:18:10 (0.3491 s / it)
{0: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 1: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 2: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 3: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 4: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 5: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 6: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 7: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 8: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 9: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 10: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 11: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 12: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 13: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 14: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 15: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 16: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 17: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 18: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 19: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}}
Averaged stats: Lr: 0.001875  Loss: -0.4415  Acc@1: 87.5000 (87.3860)  Acc@5: 100.0000 (98.6280)
Test: [Task 1]  [   0/1627]  eta: 0:16:55  Loss: 1.4863 (1.4863)  Acc@1: 62.5000 (62.5000)  Acc@5: 93.7500 (93.7500)  time: 0.6245  data: 0.4064  max mem: 2502
Test: [Task 1]  [  10/1627]  eta: 0:06:50  Loss: 1.1322 (1.1489)  Acc@1: 68.7500 (67.6136)  Acc@5: 93.7500 (94.8864)  time: 0.2541  data: 0.0388  max mem: 2502
Test: [Task 1]  [  20/1627]  eta: 0:06:18  Loss: 1.1160 (1.1076)  Acc@1: 68.7500 (69.6429)  Acc@5: 93.7500 (93.7500)  time: 0.2163  data: 0.0014  max mem: 2502
Test: [Task 1]  [  30/1627]  eta: 0:06:07  Loss: 1.1414 (1.1085)  Acc@1: 75.0000 (69.9597)  Acc@5: 93.7500 (93.7500)  time: 0.2171  data: 0.0007  max mem: 2502
Test: [Task 1]  [  40/1627]  eta: 0:05:59  Loss: 1.1160 (1.1147)  Acc@1: 75.0000 (70.2744)  Acc@5: 93.7500 (93.9024)  time: 0.2171  data: 0.0006  max mem: 2502
Test: [Task 1]  [  50/1627]  eta: 0:05:54  Loss: 0.9461 (1.0931)  Acc@1: 75.0000 (71.6912)  Acc@5: 100.0000 (94.3627)  time: 0.2157  data: 0.0007  max mem: 2502
Test: [Task 1]  [  60/1627]  eta: 0:05:50  Loss: 1.0486 (1.1130)  Acc@1: 68.7500 (70.6967)  Acc@5: 93.7500 (94.1598)  time: 0.2166  data: 0.0007  max mem: 2502
Test: [Task 1]  [  70/1627]  eta: 0:05:46  Loss: 0.9648 (1.1063)  Acc@1: 62.5000 (71.2148)  Acc@5: 93.7500 (94.4542)  time: 0.2166  data: 0.0005  max mem: 2502
Test: [Task 1]  [  80/1627]  eta: 0:05:42  Loss: 0.9101 (1.0901)  Acc@1: 75.0000 (71.5278)  Acc@5: 100.0000 (94.7531)  time: 0.2154  data: 0.0005  max mem: 2502
Test: [Task 1]  [  90/1627]  eta: 0:05:39  Loss: 1.0167 (1.1082)  Acc@1: 68.7500 (70.8791)  Acc@5: 93.7500 (94.4368)  time: 0.2150  data: 0.0004  max mem: 2502
Test: [Task 1]  [ 100/1627]  eta: 0:05:36  Loss: 1.3095 (1.1352)  Acc@1: 62.5000 (70.1733)  Acc@5: 93.7500 (93.9356)  time: 0.2157  data: 0.0005  max mem: 2502
Test: [Task 1]  [ 110/1627]  eta: 0:05:33  Loss: 1.0874 (1.1339)  Acc@1: 68.7500 (70.1014)  Acc@5: 100.0000 (94.3694)  time: 0.2156  data: 0.0006  max mem: 2502
Test: [Task 1]  [ 120/1627]  eta: 0:05:30  Loss: 1.0835 (1.1316)  Acc@1: 68.7500 (69.9897)  Acc@5: 100.0000 (94.4215)  time: 0.2153  data: 0.0005  max mem: 2502
Test: [Task 1]  [ 130/1627]  eta: 0:05:28  Loss: 1.1191 (1.1365)  Acc@1: 68.7500 (69.8950)  Acc@5: 93.7500 (94.4656)  time: 0.2165  data: 0.0004  max mem: 2502
Test: [Task 1]  [ 140/1627]  eta: 0:05:25  Loss: 1.0801 (1.1362)  Acc@1: 68.7500 (69.8582)  Acc@5: 93.7500 (94.4149)  time: 0.2168  data: 0.0012  max mem: 2502
Test: [Task 1]  [ 150/1627]  eta: 0:05:23  Loss: 0.8852 (1.1215)  Acc@1: 75.0000 (70.3642)  Acc@5: 93.7500 (94.5364)  time: 0.2163  data: 0.0017  max mem: 2502
Test: [Task 1]  [ 160/1627]  eta: 0:05:20  Loss: 0.8232 (1.1134)  Acc@1: 75.0000 (70.7298)  Acc@5: 93.7500 (94.6040)  time: 0.2155  data: 0.0008  max mem: 2502
Test: [Task 1]  [ 170/1627]  eta: 0:05:18  Loss: 1.0196 (1.1094)  Acc@1: 75.0000 (70.7237)  Acc@5: 93.7500 (94.5175)  time: 0.2153  data: 0.0009  max mem: 2502
Test: [Task 1]  [ 180/1627]  eta: 0:05:16  Loss: 1.0670 (1.1149)  Acc@1: 68.7500 (70.5456)  Acc@5: 93.7500 (94.4406)  time: 0.2165  data: 0.0016  max mem: 2502
Test: [Task 1]  [ 190/1627]  eta: 0:05:13  Loss: 1.0933 (1.1113)  Acc@1: 68.7500 (70.7788)  Acc@5: 93.7500 (94.4372)  time: 0.2162  data: 0.0013  max mem: 2502
Test: [Task 1]  [ 200/1627]  eta: 0:05:11  Loss: 1.1100 (1.1113)  Acc@1: 68.7500 (70.7090)  Acc@5: 93.7500 (94.5274)  time: 0.2156  data: 0.0009  max mem: 2502
Test: [Task 1]  [ 210/1627]  eta: 0:05:08  Loss: 1.1100 (1.1102)  Acc@1: 75.0000 (70.9716)  Acc@5: 93.7500 (94.5794)  time: 0.2159  data: 0.0010  max mem: 2502
Test: [Task 1]  [ 220/1627]  eta: 0:05:06  Loss: 1.0105 (1.1138)  Acc@1: 75.0000 (70.8428)  Acc@5: 93.7500 (94.6267)  time: 0.2154  data: 0.0009  max mem: 2502
Test: [Task 1]  [ 230/1627]  eta: 0:05:04  Loss: 1.0661 (1.1086)  Acc@1: 75.0000 (71.1310)  Acc@5: 93.7500 (94.6699)  time: 0.2149  data: 0.0006  max mem: 2502
Test: [Task 1]  [ 240/1627]  eta: 0:05:01  Loss: 0.9922 (1.1033)  Acc@1: 75.0000 (71.3693)  Acc@5: 93.7500 (94.6836)  time: 0.2152  data: 0.0006  max mem: 2502
Test: [Task 1]  [ 250/1627]  eta: 0:04:59  Loss: 0.9318 (1.1067)  Acc@1: 75.0000 (71.3894)  Acc@5: 93.7500 (94.5966)  time: 0.2149  data: 0.0006  max mem: 2502
Test: [Task 1]  [ 260/1627]  eta: 0:04:57  Loss: 1.0181 (1.1063)  Acc@1: 68.7500 (71.3841)  Acc@5: 93.7500 (94.5881)  time: 0.2151  data: 0.0007  max mem: 2502
Test: [Task 1]  [ 270/1627]  eta: 0:04:54  Loss: 1.0058 (1.0993)  Acc@1: 68.7500 (71.4483)  Acc@5: 93.7500 (94.6725)  time: 0.2153  data: 0.0008  max mem: 2502
Test: [Task 1]  [ 280/1627]  eta: 0:04:52  Loss: 0.9354 (1.0992)  Acc@1: 75.0000 (71.4635)  Acc@5: 93.7500 (94.5730)  time: 0.2152  data: 0.0007  max mem: 2502
Test: [Task 1]  [ 290/1627]  eta: 0:04:50  Loss: 1.1393 (1.0989)  Acc@1: 75.0000 (71.4991)  Acc@5: 93.7500 (94.5447)  time: 0.2150  data: 0.0008  max mem: 2502
Test: [Task 1]  [ 300/1627]  eta: 0:04:48  Loss: 1.0833 (1.0995)  Acc@1: 75.0000 (71.4493)  Acc@5: 93.7500 (94.5183)  time: 0.2153  data: 0.0005  max mem: 2502
Test: [Task 1]  [ 310/1627]  eta: 0:04:45  Loss: 0.9882 (1.1016)  Acc@1: 68.7500 (71.4228)  Acc@5: 93.7500 (94.5338)  time: 0.2160  data: 0.0007  max mem: 2502
Test: [Task 1]  [ 320/1627]  eta: 0:04:43  Loss: 1.0995 (1.1014)  Acc@1: 68.7500 (71.2812)  Acc@5: 93.7500 (94.5288)  time: 0.2155  data: 0.0008  max mem: 2502
Test: [Task 1]  [ 330/1627]  eta: 0:04:41  Loss: 1.0682 (1.0995)  Acc@1: 68.7500 (71.2613)  Acc@5: 93.7500 (94.5242)  time: 0.2157  data: 0.0005  max mem: 2502
Test: [Task 1]  [ 340/1627]  eta: 0:04:39  Loss: 0.8954 (1.0999)  Acc@1: 68.7500 (71.2060)  Acc@5: 93.7500 (94.5381)  time: 0.2164  data: 0.0010  max mem: 2502
Test: [Task 1]  [ 350/1627]  eta: 0:04:37  Loss: 1.0689 (1.1018)  Acc@1: 68.7500 (71.1538)  Acc@5: 93.7500 (94.4444)  time: 0.2168  data: 0.0020  max mem: 2502
Test: [Task 1]  [ 360/1627]  eta: 0:04:34  Loss: 1.0563 (1.1005)  Acc@1: 68.7500 (71.1392)  Acc@5: 93.7500 (94.4945)  time: 0.2170  data: 0.0018  max mem: 2502
Test: [Task 1]  [ 370/1627]  eta: 0:04:32  Loss: 0.9871 (1.1000)  Acc@1: 68.7500 (71.1590)  Acc@5: 100.0000 (94.5081)  time: 0.2163  data: 0.0013  max mem: 2502
Test: [Task 1]  [ 380/1627]  eta: 0:04:30  Loss: 0.9897 (1.0985)  Acc@1: 75.0000 (71.2762)  Acc@5: 93.7500 (94.4554)  time: 0.2161  data: 0.0015  max mem: 2502
Test: [Task 1]  [ 390/1627]  eta: 0:04:28  Loss: 1.0436 (1.0996)  Acc@1: 75.0000 (71.2596)  Acc@5: 93.7500 (94.4214)  time: 0.2160  data: 0.0011  max mem: 2502
Test: [Task 1]  [ 400/1627]  eta: 0:04:26  Loss: 1.0643 (1.1001)  Acc@1: 68.7500 (71.2594)  Acc@5: 93.7500 (94.4202)  time: 0.2150  data: 0.0007  max mem: 2502
Test: [Task 1]  [ 410/1627]  eta: 0:04:23  Loss: 0.8873 (1.0997)  Acc@1: 75.0000 (71.3047)  Acc@5: 93.7500 (94.4191)  time: 0.2149  data: 0.0008  max mem: 2502
Test: [Task 1]  [ 420/1627]  eta: 0:04:21  Loss: 0.9864 (1.0986)  Acc@1: 75.0000 (71.3480)  Acc@5: 100.0000 (94.4774)  time: 0.2153  data: 0.0007  max mem: 2502
Test: [Task 1]  [ 430/1627]  eta: 0:04:19  Loss: 0.9813 (1.0969)  Acc@1: 75.0000 (71.3747)  Acc@5: 100.0000 (94.5331)  time: 0.2156  data: 0.0014  max mem: 2502
Test: [Task 1]  [ 440/1627]  eta: 0:04:17  Loss: 1.1542 (1.0973)  Acc@1: 68.7500 (71.3435)  Acc@5: 100.0000 (94.5578)  time: 0.2154  data: 0.0014  max mem: 2502
Test: [Task 1]  [ 450/1627]  eta: 0:04:15  Loss: 1.1724 (1.1003)  Acc@1: 68.7500 (71.2167)  Acc@5: 93.7500 (94.4290)  time: 0.2162  data: 0.0012  max mem: 2502
Test: [Task 1]  [ 460/1627]  eta: 0:04:12  Loss: 1.1422 (1.1004)  Acc@1: 68.7500 (71.2717)  Acc@5: 93.7500 (94.4550)  time: 0.2175  data: 0.0014  max mem: 2502
Test: [Task 1]  [ 470/1627]  eta: 0:04:10  Loss: 1.0139 (1.0983)  Acc@1: 75.0000 (71.2978)  Acc@5: 100.0000 (94.4533)  time: 0.2161  data: 0.0006  max mem: 2502
Test: [Task 1]  [ 480/1627]  eta: 0:04:08  Loss: 1.0607 (1.1021)  Acc@1: 68.7500 (71.1928)  Acc@5: 93.7500 (94.4127)  time: 0.2164  data: 0.0012  max mem: 2502
Test: [Task 1]  [ 490/1627]  eta: 0:04:06  Loss: 1.1375 (1.1023)  Acc@1: 62.5000 (71.0794)  Acc@5: 93.7500 (94.4119)  time: 0.2168  data: 0.0013  max mem: 2502
Test: [Task 1]  [ 500/1627]  eta: 0:04:04  Loss: 1.0615 (1.1041)  Acc@1: 68.7500 (71.0454)  Acc@5: 93.7500 (94.3613)  time: 0.2159  data: 0.0006  max mem: 2502
Test: [Task 1]  [ 510/1627]  eta: 0:04:02  Loss: 1.1575 (1.1101)  Acc@1: 68.7500 (70.9149)  Acc@5: 93.7500 (94.3249)  time: 0.2161  data: 0.0007  max mem: 2502
Test: [Task 1]  [ 520/1627]  eta: 0:03:59  Loss: 1.2814 (1.1171)  Acc@1: 68.7500 (70.8013)  Acc@5: 93.7500 (94.2538)  time: 0.2159  data: 0.0007  max mem: 2502
Test: [Task 1]  [ 530/1627]  eta: 0:03:57  Loss: 1.0902 (1.1134)  Acc@1: 75.0000 (70.9157)  Acc@5: 93.7500 (94.2797)  time: 0.2162  data: 0.0006  max mem: 2502
Test: [Task 1]  [ 540/1627]  eta: 0:03:55  Loss: 1.0287 (1.1140)  Acc@1: 75.0000 (70.9681)  Acc@5: 93.7500 (94.2468)  time: 0.2162  data: 0.0007  max mem: 2502
Test: [Task 1]  [ 550/1627]  eta: 0:03:53  Loss: 1.2233 (1.1160)  Acc@1: 75.0000 (70.9846)  Acc@5: 93.7500 (94.2604)  time: 0.2146  data: 0.0007  max mem: 2502
Test: [Task 1]  [ 560/1627]  eta: 0:03:51  Loss: 1.2448 (1.1178)  Acc@1: 68.7500 (70.9559)  Acc@5: 93.7500 (94.2625)  time: 0.2133  data: 0.0004  max mem: 2502
Test: [Task 1]  [ 570/1627]  eta: 0:03:48  Loss: 1.1196 (1.1149)  Acc@1: 68.7500 (70.9939)  Acc@5: 93.7500 (94.2754)  time: 0.2125  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 580/1627]  eta: 0:03:46  Loss: 1.0397 (1.1154)  Acc@1: 75.0000 (71.0198)  Acc@5: 93.7500 (94.3094)  time: 0.2141  data: 0.0005  max mem: 2502
Test: [Task 1]  [ 590/1627]  eta: 0:03:44  Loss: 1.0908 (1.1148)  Acc@1: 68.7500 (71.0131)  Acc@5: 100.0000 (94.3634)  time: 0.2154  data: 0.0012  max mem: 2502
Test: [Task 1]  [ 600/1627]  eta: 0:03:42  Loss: 1.0900 (1.1166)  Acc@1: 68.7500 (70.9339)  Acc@5: 93.7500 (94.3324)  time: 0.2147  data: 0.0011  max mem: 2502
Test: [Task 1]  [ 610/1627]  eta: 0:03:40  Loss: 1.0900 (1.1145)  Acc@1: 68.7500 (70.9902)  Acc@5: 93.7500 (94.3637)  time: 0.2145  data: 0.0009  max mem: 2502
Test: [Task 1]  [ 620/1627]  eta: 0:03:37  Loss: 1.0325 (1.1161)  Acc@1: 75.0000 (70.9340)  Acc@5: 93.7500 (94.3539)  time: 0.2154  data: 0.0015  max mem: 2502
Test: [Task 1]  [ 630/1627]  eta: 0:03:35  Loss: 1.0083 (1.1156)  Acc@1: 75.0000 (71.0083)  Acc@5: 93.7500 (94.3443)  time: 0.2154  data: 0.0013  max mem: 2502
Test: [Task 1]  [ 640/1627]  eta: 0:03:33  Loss: 1.0000 (1.1156)  Acc@1: 75.0000 (70.9926)  Acc@5: 93.7500 (94.3350)  time: 0.2145  data: 0.0006  max mem: 2502
Test: [Task 1]  [ 650/1627]  eta: 0:03:31  Loss: 1.0412 (1.1146)  Acc@1: 68.7500 (70.9965)  Acc@5: 93.7500 (94.3644)  time: 0.2150  data: 0.0007  max mem: 2502
Test: [Task 1]  [ 660/1627]  eta: 0:03:29  Loss: 1.0081 (1.1130)  Acc@1: 75.0000 (71.0287)  Acc@5: 93.7500 (94.3646)  time: 0.2153  data: 0.0007  max mem: 2502
Test: [Task 1]  [ 670/1627]  eta: 0:03:26  Loss: 1.0868 (1.1125)  Acc@1: 75.0000 (71.0227)  Acc@5: 93.7500 (94.3648)  time: 0.2160  data: 0.0015  max mem: 2502
Test: [Task 1]  [ 680/1627]  eta: 0:03:24  Loss: 1.1063 (1.1122)  Acc@1: 75.0000 (71.0811)  Acc@5: 93.7500 (94.3557)  time: 0.2156  data: 0.0015  max mem: 2502
Test: [Task 1]  [ 690/1627]  eta: 0:03:22  Loss: 1.0854 (1.1102)  Acc@1: 75.0000 (71.1288)  Acc@5: 100.0000 (94.4012)  time: 0.2147  data: 0.0007  max mem: 2502
Test: [Task 1]  [ 700/1627]  eta: 0:03:20  Loss: 1.0854 (1.1095)  Acc@1: 75.0000 (71.2108)  Acc@5: 100.0000 (94.4187)  time: 0.2153  data: 0.0013  max mem: 2502
Test: [Task 1]  [ 710/1627]  eta: 0:03:18  Loss: 0.9307 (1.1072)  Acc@1: 75.0000 (71.2904)  Acc@5: 100.0000 (94.4620)  time: 0.2157  data: 0.0022  max mem: 2502
Test: [Task 1]  [ 720/1627]  eta: 0:03:16  Loss: 0.9279 (1.1060)  Acc@1: 68.7500 (71.2899)  Acc@5: 100.0000 (94.4782)  time: 0.2163  data: 0.0017  max mem: 2502
Test: [Task 1]  [ 730/1627]  eta: 0:03:13  Loss: 1.1042 (1.1064)  Acc@1: 68.7500 (71.2808)  Acc@5: 93.7500 (94.4682)  time: 0.2159  data: 0.0007  max mem: 2502
Test: [Task 1]  [ 740/1627]  eta: 0:03:11  Loss: 1.1185 (1.1074)  Acc@1: 68.7500 (71.2551)  Acc@5: 93.7500 (94.4585)  time: 0.2156  data: 0.0009  max mem: 2502
Test: [Task 1]  [ 750/1627]  eta: 0:03:09  Loss: 1.0605 (1.1063)  Acc@1: 75.0000 (71.3465)  Acc@5: 93.7500 (94.4491)  time: 0.2147  data: 0.0006  max mem: 2502
Test: [Task 1]  [ 760/1627]  eta: 0:03:07  Loss: 1.0605 (1.1093)  Acc@1: 75.0000 (71.2631)  Acc@5: 93.7500 (94.4070)  time: 0.2138  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 770/1627]  eta: 0:03:05  Loss: 0.9669 (1.1060)  Acc@1: 75.0000 (71.3521)  Acc@5: 93.7500 (94.4309)  time: 0.2157  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 780/1627]  eta: 0:03:03  Loss: 0.8294 (1.1042)  Acc@1: 75.0000 (71.4149)  Acc@5: 93.7500 (94.4382)  time: 0.2155  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 790/1627]  eta: 0:03:00  Loss: 0.9485 (1.1059)  Acc@1: 75.0000 (71.4049)  Acc@5: 93.7500 (94.4137)  time: 0.2134  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 800/1627]  eta: 0:02:58  Loss: 0.9994 (1.1044)  Acc@1: 68.7500 (71.4107)  Acc@5: 93.7500 (94.4444)  time: 0.2135  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 810/1627]  eta: 0:02:56  Loss: 0.9659 (1.1038)  Acc@1: 75.0000 (71.4319)  Acc@5: 100.0000 (94.4513)  time: 0.2134  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 820/1627]  eta: 0:02:54  Loss: 0.9403 (1.1028)  Acc@1: 68.7500 (71.4525)  Acc@5: 100.0000 (94.4656)  time: 0.2141  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 830/1627]  eta: 0:02:52  Loss: 0.9306 (1.1019)  Acc@1: 68.7500 (71.4651)  Acc@5: 100.0000 (94.4645)  time: 0.2152  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 840/1627]  eta: 0:02:49  Loss: 0.8626 (1.0995)  Acc@1: 75.0000 (71.5071)  Acc@5: 100.0000 (94.5080)  time: 0.2157  data: 0.0004  max mem: 2502
Test: [Task 1]  [ 850/1627]  eta: 0:02:47  Loss: 1.0364 (1.1011)  Acc@1: 68.7500 (71.4600)  Acc@5: 100.0000 (94.4844)  time: 0.2163  data: 0.0006  max mem: 2502
Test: [Task 1]  [ 860/1627]  eta: 0:02:45  Loss: 1.0697 (1.1004)  Acc@1: 68.7500 (71.4431)  Acc@5: 100.0000 (94.5122)  time: 0.2166  data: 0.0013  max mem: 2502
Test: [Task 1]  [ 870/1627]  eta: 0:02:43  Loss: 1.0103 (1.0989)  Acc@1: 75.0000 (71.4696)  Acc@5: 100.0000 (94.5178)  time: 0.2164  data: 0.0019  max mem: 2502
Test: [Task 1]  [ 880/1627]  eta: 0:02:41  Loss: 1.1000 (1.1014)  Acc@1: 62.5000 (71.3465)  Acc@5: 100.0000 (94.5375)  time: 0.2160  data: 0.0012  max mem: 2502
Test: [Task 1]  [ 890/1627]  eta: 0:02:39  Loss: 1.2087 (1.1038)  Acc@1: 62.5000 (71.2823)  Acc@5: 100.0000 (94.5146)  time: 0.2160  data: 0.0008  max mem: 2502
Test: [Task 1]  [ 900/1627]  eta: 0:02:37  Loss: 1.1927 (1.1040)  Acc@1: 62.5000 (71.2819)  Acc@5: 93.7500 (94.5130)  time: 0.2165  data: 0.0012  max mem: 2502
Test: [Task 1]  [ 910/1627]  eta: 0:02:34  Loss: 1.1781 (1.1053)  Acc@1: 68.7500 (71.2610)  Acc@5: 93.7500 (94.4772)  time: 0.2166  data: 0.0009  max mem: 2502
Test: [Task 1]  [ 920/1627]  eta: 0:02:32  Loss: 1.0645 (1.1050)  Acc@1: 68.7500 (71.2744)  Acc@5: 93.7500 (94.4829)  time: 0.2172  data: 0.0014  max mem: 2502
Test: [Task 1]  [ 930/1627]  eta: 0:02:30  Loss: 1.0645 (1.1059)  Acc@1: 68.7500 (71.2473)  Acc@5: 93.7500 (94.4616)  time: 0.2171  data: 0.0018  max mem: 2502
Test: [Task 1]  [ 940/1627]  eta: 0:02:28  Loss: 1.0553 (1.1045)  Acc@1: 75.0000 (71.2938)  Acc@5: 100.0000 (94.4939)  time: 0.2158  data: 0.0009  max mem: 2502
Test: [Task 1]  [ 950/1627]  eta: 0:02:26  Loss: 1.1122 (1.1055)  Acc@1: 68.7500 (71.2671)  Acc@5: 100.0000 (94.4992)  time: 0.2154  data: 0.0004  max mem: 2502
Test: [Task 1]  [ 960/1627]  eta: 0:02:24  Loss: 1.1304 (1.1049)  Acc@1: 68.7500 (71.2734)  Acc@5: 93.7500 (94.4914)  time: 0.2166  data: 0.0013  max mem: 2502
Test: [Task 1]  [ 970/1627]  eta: 0:02:21  Loss: 1.0038 (1.1041)  Acc@1: 75.0000 (71.3054)  Acc@5: 93.7500 (94.4902)  time: 0.2165  data: 0.0014  max mem: 2502
Test: [Task 1]  [ 980/1627]  eta: 0:02:19  Loss: 1.0244 (1.1042)  Acc@1: 75.0000 (71.3175)  Acc@5: 93.7500 (94.5018)  time: 0.2162  data: 0.0010  max mem: 2502
Test: [Task 1]  [ 990/1627]  eta: 0:02:17  Loss: 1.1533 (1.1070)  Acc@1: 68.7500 (71.2916)  Acc@5: 93.7500 (94.4879)  time: 0.2171  data: 0.0009  max mem: 2502
Test: [Task 1]  [1000/1627]  eta: 0:02:15  Loss: 1.2130 (1.1071)  Acc@1: 68.7500 (71.3037)  Acc@5: 93.7500 (94.4493)  time: 0.2160  data: 0.0003  max mem: 2502
Test: [Task 1]  [1010/1627]  eta: 0:02:13  Loss: 1.0780 (1.1068)  Acc@1: 75.0000 (71.3093)  Acc@5: 93.7500 (94.4486)  time: 0.2148  data: 0.0003  max mem: 2502
Test: [Task 1]  [1020/1627]  eta: 0:02:11  Loss: 1.0172 (1.1062)  Acc@1: 75.0000 (71.3210)  Acc@5: 93.7500 (94.4601)  time: 0.2143  data: 0.0003  max mem: 2502
Test: [Task 1]  [1030/1627]  eta: 0:02:08  Loss: 0.9230 (1.1042)  Acc@1: 75.0000 (71.3870)  Acc@5: 100.0000 (94.4896)  time: 0.2137  data: 0.0002  max mem: 2502
Test: [Task 1]  [1040/1627]  eta: 0:02:06  Loss: 0.8100 (1.1021)  Acc@1: 81.2500 (71.4517)  Acc@5: 100.0000 (94.5185)  time: 0.2136  data: 0.0002  max mem: 2502
Test: [Task 1]  [1050/1627]  eta: 0:02:04  Loss: 0.9135 (1.1008)  Acc@1: 75.0000 (71.4676)  Acc@5: 100.0000 (94.5290)  time: 0.2138  data: 0.0002  max mem: 2502
Test: [Task 1]  [1060/1627]  eta: 0:02:02  Loss: 1.0775 (1.1012)  Acc@1: 68.7500 (71.4833)  Acc@5: 93.7500 (94.5040)  time: 0.2144  data: 0.0002  max mem: 2502
Test: [Task 1]  [1070/1627]  eta: 0:02:00  Loss: 1.1353 (1.1015)  Acc@1: 68.7500 (71.4869)  Acc@5: 93.7500 (94.4970)  time: 0.2165  data: 0.0004  max mem: 2502
Test: [Task 1]  [1080/1627]  eta: 0:01:58  Loss: 1.0586 (1.1023)  Acc@1: 68.7500 (71.4905)  Acc@5: 93.7500 (94.5016)  time: 0.2170  data: 0.0006  max mem: 2502
Test: [Task 1]  [1090/1627]  eta: 0:01:55  Loss: 1.0586 (1.1022)  Acc@1: 75.0000 (71.5399)  Acc@5: 93.7500 (94.5062)  time: 0.2162  data: 0.0006  max mem: 2502
Test: [Task 1]  [1100/1627]  eta: 0:01:53  Loss: 0.9749 (1.1001)  Acc@1: 75.0000 (71.5997)  Acc@5: 100.0000 (94.5277)  time: 0.2167  data: 0.0007  max mem: 2502
Test: [Task 1]  [1110/1627]  eta: 0:01:51  Loss: 0.9589 (1.0999)  Acc@1: 75.0000 (71.6134)  Acc@5: 100.0000 (94.5376)  time: 0.2163  data: 0.0007  max mem: 2502
Test: [Task 1]  [1120/1627]  eta: 0:01:49  Loss: 1.0733 (1.1014)  Acc@1: 62.5000 (71.5321)  Acc@5: 100.0000 (94.5417)  time: 0.2160  data: 0.0007  max mem: 2502
Test: [Task 1]  [1130/1627]  eta: 0:01:47  Loss: 1.0183 (1.1019)  Acc@1: 62.5000 (71.5351)  Acc@5: 100.0000 (94.5347)  time: 0.2164  data: 0.0008  max mem: 2502
Test: [Task 1]  [1140/1627]  eta: 0:01:45  Loss: 0.9981 (1.1029)  Acc@1: 68.7500 (71.5326)  Acc@5: 93.7500 (94.5114)  time: 0.2165  data: 0.0008  max mem: 2502
Test: [Task 1]  [1150/1627]  eta: 0:01:43  Loss: 1.2350 (1.1036)  Acc@1: 68.7500 (71.4922)  Acc@5: 93.7500 (94.5211)  time: 0.2170  data: 0.0008  max mem: 2502
Test: [Task 1]  [1160/1627]  eta: 0:01:40  Loss: 1.1438 (1.1025)  Acc@1: 75.0000 (71.5547)  Acc@5: 100.0000 (94.5360)  time: 0.2162  data: 0.0006  max mem: 2502
Test: [Task 1]  [1170/1627]  eta: 0:01:38  Loss: 1.0447 (1.1017)  Acc@1: 75.0000 (71.5734)  Acc@5: 100.0000 (94.5506)  time: 0.2151  data: 0.0003  max mem: 2502
Test: [Task 1]  [1180/1627]  eta: 0:01:36  Loss: 1.0700 (1.1024)  Acc@1: 75.0000 (71.5813)  Acc@5: 93.7500 (94.5597)  time: 0.2154  data: 0.0005  max mem: 2502
Test: [Task 1]  [1190/1627]  eta: 0:01:34  Loss: 1.1393 (1.1030)  Acc@1: 68.7500 (71.5365)  Acc@5: 93.7500 (94.5581)  time: 0.2158  data: 0.0005  max mem: 2502
Test: [Task 1]  [1200/1627]  eta: 0:01:32  Loss: 1.1273 (1.1031)  Acc@1: 68.7500 (71.5185)  Acc@5: 93.7500 (94.5566)  time: 0.2157  data: 0.0004  max mem: 2502
Test: [Task 1]  [1210/1627]  eta: 0:01:30  Loss: 0.9713 (1.1036)  Acc@1: 68.7500 (71.4957)  Acc@5: 93.7500 (94.5293)  time: 0.2160  data: 0.0006  max mem: 2502
Test: [Task 1]  [1220/1627]  eta: 0:01:27  Loss: 0.9935 (1.1028)  Acc@1: 75.0000 (71.5192)  Acc@5: 93.7500 (94.5383)  time: 0.2182  data: 0.0010  max mem: 2502
Test: [Task 1]  [1230/1627]  eta: 0:01:25  Loss: 1.0773 (1.1033)  Acc@1: 68.7500 (71.4764)  Acc@5: 93.7500 (94.5420)  time: 0.2177  data: 0.0010  max mem: 2502
Test: [Task 1]  [1240/1627]  eta: 0:01:23  Loss: 1.0918 (1.1029)  Acc@1: 68.7500 (71.4897)  Acc@5: 93.7500 (94.5407)  time: 0.2153  data: 0.0005  max mem: 2502
Test: [Task 1]  [1250/1627]  eta: 0:01:21  Loss: 1.1891 (1.1033)  Acc@1: 68.7500 (71.4728)  Acc@5: 93.7500 (94.5394)  time: 0.2161  data: 0.0003  max mem: 2502
Test: [Task 1]  [1260/1627]  eta: 0:01:19  Loss: 1.1803 (1.1031)  Acc@1: 68.7500 (71.5107)  Acc@5: 93.7500 (94.5430)  time: 0.2159  data: 0.0003  max mem: 2502
Test: [Task 1]  [1270/1627]  eta: 0:01:17  Loss: 1.0057 (1.1038)  Acc@1: 68.7500 (71.4792)  Acc@5: 93.7500 (94.5319)  time: 0.2143  data: 0.0002  max mem: 2502
Test: [Task 1]  [1280/1627]  eta: 0:01:14  Loss: 0.9771 (1.1025)  Acc@1: 68.7500 (71.4969)  Acc@5: 93.7500 (94.5355)  time: 0.2139  data: 0.0002  max mem: 2502
Test: [Task 1]  [1290/1627]  eta: 0:01:12  Loss: 1.0477 (1.1028)  Acc@1: 68.7500 (71.4611)  Acc@5: 93.7500 (94.5440)  time: 0.2137  data: 0.0002  max mem: 2502
Test: [Task 1]  [1300/1627]  eta: 0:01:10  Loss: 1.0477 (1.1022)  Acc@1: 75.0000 (71.5027)  Acc@5: 93.7500 (94.5523)  time: 0.2142  data: 0.0002  max mem: 2502
Test: [Task 1]  [1310/1627]  eta: 0:01:08  Loss: 0.8816 (1.1008)  Acc@1: 81.2500 (71.5532)  Acc@5: 93.7500 (94.5557)  time: 0.2159  data: 0.0005  max mem: 2502
Test: [Task 1]  [1320/1627]  eta: 0:01:06  Loss: 0.8029 (1.0993)  Acc@1: 81.2500 (71.6219)  Acc@5: 100.0000 (94.5685)  time: 0.2167  data: 0.0009  max mem: 2502
Test: [Task 1]  [1330/1627]  eta: 0:01:04  Loss: 0.8714 (1.0990)  Acc@1: 75.0000 (71.6426)  Acc@5: 93.7500 (94.5530)  time: 0.2176  data: 0.0018  max mem: 2502
Test: [Task 1]  [1340/1627]  eta: 0:01:01  Loss: 1.0674 (1.0996)  Acc@1: 75.0000 (71.6257)  Acc@5: 93.7500 (94.5563)  time: 0.2177  data: 0.0017  max mem: 2502
Test: [Task 1]  [1350/1627]  eta: 0:00:59  Loss: 1.0410 (1.0990)  Acc@1: 75.0000 (71.6368)  Acc@5: 93.7500 (94.5550)  time: 0.2171  data: 0.0008  max mem: 2502
Test: [Task 1]  [1360/1627]  eta: 0:00:57  Loss: 0.9613 (1.0985)  Acc@1: 75.0000 (71.6385)  Acc@5: 93.7500 (94.5674)  time: 0.2164  data: 0.0008  max mem: 2502
Test: [Task 1]  [1370/1627]  eta: 0:00:55  Loss: 0.9613 (1.0976)  Acc@1: 68.7500 (71.6402)  Acc@5: 93.7500 (94.5797)  time: 0.2163  data: 0.0009  max mem: 2502
Test: [Task 1]  [1380/1627]  eta: 0:00:53  Loss: 1.0261 (1.0978)  Acc@1: 68.7500 (71.6419)  Acc@5: 93.7500 (94.5692)  time: 0.2162  data: 0.0007  max mem: 2502
Test: [Task 1]  [1390/1627]  eta: 0:00:51  Loss: 1.1815 (1.0974)  Acc@1: 68.7500 (71.6346)  Acc@5: 93.7500 (94.5812)  time: 0.2156  data: 0.0005  max mem: 2502
Test: [Task 1]  [1400/1627]  eta: 0:00:49  Loss: 1.1315 (1.0976)  Acc@1: 75.0000 (71.6497)  Acc@5: 93.7500 (94.5575)  time: 0.2158  data: 0.0005  max mem: 2502
Test: [Task 1]  [1410/1627]  eta: 0:00:46  Loss: 0.8877 (1.0968)  Acc@1: 75.0000 (71.6912)  Acc@5: 93.7500 (94.5650)  time: 0.2156  data: 0.0005  max mem: 2502
Test: [Task 1]  [1420/1627]  eta: 0:00:44  Loss: 0.9720 (1.0960)  Acc@1: 75.0000 (71.7057)  Acc@5: 100.0000 (94.5857)  time: 0.2157  data: 0.0006  max mem: 2502
Test: [Task 1]  [1430/1627]  eta: 0:00:42  Loss: 1.1781 (1.0977)  Acc@1: 68.7500 (71.6981)  Acc@5: 93.7500 (94.5493)  time: 0.2168  data: 0.0008  max mem: 2502
Test: [Task 1]  [1440/1627]  eta: 0:00:40  Loss: 1.1563 (1.0972)  Acc@1: 68.7500 (71.6733)  Acc@5: 93.7500 (94.5611)  time: 0.2167  data: 0.0008  max mem: 2502
Test: [Task 1]  [1450/1627]  eta: 0:00:38  Loss: 1.1563 (1.0985)  Acc@1: 68.7500 (71.6402)  Acc@5: 93.7500 (94.5598)  time: 0.2164  data: 0.0009  max mem: 2502
Test: [Task 1]  [1460/1627]  eta: 0:00:36  Loss: 1.1731 (1.0987)  Acc@1: 62.5000 (71.6333)  Acc@5: 93.7500 (94.5585)  time: 0.2187  data: 0.0023  max mem: 2502
Test: [Task 1]  [1470/1627]  eta: 0:00:33  Loss: 1.1064 (1.0990)  Acc@1: 75.0000 (71.6264)  Acc@5: 93.7500 (94.5445)  time: 0.2184  data: 0.0020  max mem: 2502
Test: [Task 1]  [1480/1627]  eta: 0:00:31  Loss: 1.1871 (1.0994)  Acc@1: 75.0000 (71.6155)  Acc@5: 93.7500 (94.5476)  time: 0.2164  data: 0.0007  max mem: 2502
Test: [Task 1]  [1490/1627]  eta: 0:00:29  Loss: 1.1526 (1.0999)  Acc@1: 68.7500 (71.6382)  Acc@5: 93.7500 (94.5297)  time: 0.2177  data: 0.0007  max mem: 2502
Test: [Task 1]  [1500/1627]  eta: 0:00:27  Loss: 1.1045 (1.1001)  Acc@1: 68.7500 (71.6397)  Acc@5: 93.7500 (94.5162)  time: 0.2178  data: 0.0005  max mem: 2502
Test: [Task 1]  [1510/1627]  eta: 0:00:25  Loss: 0.8900 (1.0999)  Acc@1: 68.7500 (71.6454)  Acc@5: 93.7500 (94.5111)  time: 0.2160  data: 0.0005  max mem: 2502
Test: [Task 1]  [1520/1627]  eta: 0:00:23  Loss: 0.8863 (1.0985)  Acc@1: 75.0000 (71.6798)  Acc@5: 93.7500 (94.5348)  time: 0.2152  data: 0.0004  max mem: 2502
Test: [Task 1]  [1530/1627]  eta: 0:00:20  Loss: 0.8560 (1.0979)  Acc@1: 75.0000 (71.6729)  Acc@5: 100.0000 (94.5460)  time: 0.2153  data: 0.0003  max mem: 2502
Test: [Task 1]  [1540/1627]  eta: 0:00:18  Loss: 0.9283 (1.0970)  Acc@1: 68.7500 (71.6864)  Acc@5: 100.0000 (94.5733)  time: 0.2149  data: 0.0003  max mem: 2502
Test: [Task 1]  [1550/1627]  eta: 0:00:16  Loss: 0.9267 (1.0965)  Acc@1: 75.0000 (71.6917)  Acc@5: 100.0000 (94.5801)  time: 0.2140  data: 0.0002  max mem: 2502
Test: [Task 1]  [1560/1627]  eta: 0:00:14  Loss: 0.8374 (1.0956)  Acc@1: 75.0000 (71.7088)  Acc@5: 100.0000 (94.5908)  time: 0.2138  data: 0.0002  max mem: 2502
Test: [Task 1]  [1570/1627]  eta: 0:00:12  Loss: 0.9443 (1.0953)  Acc@1: 75.0000 (71.7218)  Acc@5: 100.0000 (94.5894)  time: 0.2139  data: 0.0002  max mem: 2502
Test: [Task 1]  [1580/1627]  eta: 0:00:10  Loss: 0.9672 (1.0954)  Acc@1: 75.0000 (71.7228)  Acc@5: 93.7500 (94.5841)  time: 0.2138  data: 0.0002  max mem: 2502
Test: [Task 1]  [1590/1627]  eta: 0:00:07  Loss: 0.9672 (1.0952)  Acc@1: 68.7500 (71.7159)  Acc@5: 93.7500 (94.5946)  time: 0.2146  data: 0.0003  max mem: 2502
Test: [Task 1]  [1600/1627]  eta: 0:00:05  Loss: 1.0730 (1.0961)  Acc@1: 68.7500 (71.6818)  Acc@5: 100.0000 (94.5815)  time: 0.2162  data: 0.0007  max mem: 2502
Test: [Task 1]  [1610/1627]  eta: 0:00:03  Loss: 1.0672 (1.0955)  Acc@1: 68.7500 (71.6830)  Acc@5: 93.7500 (94.5802)  time: 0.2169  data: 0.0008  max mem: 2502
Test: [Task 1]  [1620/1627]  eta: 0:00:01  Loss: 0.8950 (1.0945)  Acc@1: 75.0000 (71.7073)  Acc@5: 93.7500 (94.5867)  time: 0.2163  data: 0.0005  max mem: 2502
Test: [Task 1]  [1626/1627]  eta: 0:00:00  Loss: 0.8778 (1.0939)  Acc@1: 75.0000 (71.7271)  Acc@5: 93.7500 (94.5797)  time: 0.2155  data: 0.0004  max mem: 2502
Test: [Task 1] Total time: 0:05:51 (0.2162 s / it)
* Acc@1 71.727 Acc@5 94.580 loss 1.094
Test: [Task 2]  [  0/625]  eta: 0:06:17  Loss: 0.2356 (0.2356)  Acc@1: 93.7500 (93.7500)  Acc@5: 100.0000 (100.0000)  time: 0.6033  data: 0.3867  max mem: 2502
Test: [Task 2]  [ 10/625]  eta: 0:02:34  Loss: 0.2328 (0.2620)  Acc@1: 93.7500 (92.0455)  Acc@5: 100.0000 (99.4318)  time: 0.2507  data: 0.0355  max mem: 2502
Test: [Task 2]  [ 20/625]  eta: 0:02:21  Loss: 0.2147 (0.2738)  Acc@1: 93.7500 (90.7738)  Acc@5: 100.0000 (99.7024)  time: 0.2153  data: 0.0003  max mem: 2502
Test: [Task 2]  [ 30/625]  eta: 0:02:16  Loss: 0.3075 (0.2925)  Acc@1: 93.7500 (90.1210)  Acc@5: 100.0000 (99.5968)  time: 0.2166  data: 0.0015  max mem: 2502
Test: [Task 2]  [ 40/625]  eta: 0:02:12  Loss: 0.2873 (0.2972)  Acc@1: 93.7500 (90.3963)  Acc@5: 100.0000 (99.5427)  time: 0.2176  data: 0.0019  max mem: 2502
Test: [Task 2]  [ 50/625]  eta: 0:02:09  Loss: 0.3251 (0.3108)  Acc@1: 87.5000 (90.0735)  Acc@5: 100.0000 (99.5098)  time: 0.2178  data: 0.0009  max mem: 2502
Test: [Task 2]  [ 60/625]  eta: 0:02:06  Loss: 0.3251 (0.3164)  Acc@1: 87.5000 (89.6516)  Acc@5: 100.0000 (99.4877)  time: 0.2180  data: 0.0010  max mem: 2502
Test: [Task 2]  [ 70/625]  eta: 0:02:03  Loss: 0.3022 (0.3147)  Acc@1: 87.5000 (89.7007)  Acc@5: 100.0000 (99.4718)  time: 0.2176  data: 0.0013  max mem: 2502
Test: [Task 2]  [ 80/625]  eta: 0:02:00  Loss: 0.2694 (0.3197)  Acc@1: 87.5000 (89.8920)  Acc@5: 100.0000 (99.3827)  time: 0.2166  data: 0.0010  max mem: 2502
Test: [Task 2]  [ 90/625]  eta: 0:01:58  Loss: 0.2684 (0.3150)  Acc@1: 93.7500 (90.1099)  Acc@5: 100.0000 (99.4505)  time: 0.2155  data: 0.0005  max mem: 2502
Test: [Task 2]  [100/625]  eta: 0:01:55  Loss: 0.2684 (0.3100)  Acc@1: 87.5000 (90.2228)  Acc@5: 100.0000 (99.4431)  time: 0.2155  data: 0.0006  max mem: 2502
Test: [Task 2]  [110/625]  eta: 0:01:53  Loss: 0.2934 (0.3156)  Acc@1: 87.5000 (90.1464)  Acc@5: 100.0000 (99.3243)  time: 0.2166  data: 0.0008  max mem: 2502
Test: [Task 2]  [120/625]  eta: 0:01:50  Loss: 0.3371 (0.3184)  Acc@1: 87.5000 (90.1343)  Acc@5: 100.0000 (99.2252)  time: 0.2163  data: 0.0005  max mem: 2502
Test: [Task 2]  [130/625]  eta: 0:01:48  Loss: 0.3191 (0.3166)  Acc@1: 93.7500 (90.4103)  Acc@5: 100.0000 (99.2844)  time: 0.2156  data: 0.0005  max mem: 2502
Test: [Task 2]  [140/625]  eta: 0:01:46  Loss: 0.2845 (0.3202)  Acc@1: 93.7500 (90.2039)  Acc@5: 100.0000 (99.2465)  time: 0.2157  data: 0.0006  max mem: 2502
Test: [Task 2]  [150/625]  eta: 0:01:44  Loss: 0.2957 (0.3232)  Acc@1: 87.5000 (89.9007)  Acc@5: 100.0000 (99.2550)  time: 0.2161  data: 0.0006  max mem: 2502
Test: [Task 2]  [160/625]  eta: 0:01:41  Loss: 0.3264 (0.3281)  Acc@1: 87.5000 (89.7516)  Acc@5: 100.0000 (99.1848)  time: 0.2161  data: 0.0006  max mem: 2502
Test: [Task 2]  [170/625]  eta: 0:01:39  Loss: 0.3598 (0.3263)  Acc@1: 93.7500 (89.9854)  Acc@5: 100.0000 (99.1594)  time: 0.2152  data: 0.0004  max mem: 2502
Test: [Task 2]  [180/625]  eta: 0:01:37  Loss: 0.2706 (0.3229)  Acc@1: 93.7500 (90.1243)  Acc@5: 100.0000 (99.2058)  time: 0.2158  data: 0.0006  max mem: 2502
Test: [Task 2]  [190/625]  eta: 0:01:34  Loss: 0.3102 (0.3262)  Acc@1: 87.5000 (90.0851)  Acc@5: 100.0000 (99.1819)  time: 0.2157  data: 0.0006  max mem: 2502
Test: [Task 2]  [200/625]  eta: 0:01:32  Loss: 0.3961 (0.3275)  Acc@1: 87.5000 (90.0187)  Acc@5: 100.0000 (99.2226)  time: 0.2145  data: 0.0003  max mem: 2502
Test: [Task 2]  [210/625]  eta: 0:01:30  Loss: 0.3611 (0.3299)  Acc@1: 87.5000 (89.9882)  Acc@5: 100.0000 (99.1706)  time: 0.2141  data: 0.0002  max mem: 2502
Test: [Task 2]  [220/625]  eta: 0:01:28  Loss: 0.2558 (0.3267)  Acc@1: 93.7500 (90.1867)  Acc@5: 100.0000 (99.1799)  time: 0.2139  data: 0.0002  max mem: 2502
Test: [Task 2]  [230/625]  eta: 0:01:25  Loss: 0.2558 (0.3249)  Acc@1: 93.7500 (90.3409)  Acc@5: 100.0000 (99.2154)  time: 0.2136  data: 0.0002  max mem: 2502
Test: [Task 2]  [240/625]  eta: 0:01:23  Loss: 0.3276 (0.3249)  Acc@1: 93.7500 (90.3527)  Acc@5: 100.0000 (99.1961)  time: 0.2148  data: 0.0008  max mem: 2502
Test: [Task 2]  [250/625]  eta: 0:01:21  Loss: 0.3276 (0.3266)  Acc@1: 93.7500 (90.4133)  Acc@5: 100.0000 (99.1783)  time: 0.2167  data: 0.0015  max mem: 2502
Test: [Task 2]  [260/625]  eta: 0:01:19  Loss: 0.3236 (0.3281)  Acc@1: 87.5000 (90.3257)  Acc@5: 100.0000 (99.1619)  time: 0.2169  data: 0.0011  max mem: 2502
Test: [Task 2]  [270/625]  eta: 0:01:17  Loss: 0.3236 (0.3289)  Acc@1: 87.5000 (90.3137)  Acc@5: 100.0000 (99.1697)  time: 0.2165  data: 0.0009  max mem: 2502
Test: [Task 2]  [280/625]  eta: 0:01:14  Loss: 0.2681 (0.3297)  Acc@1: 87.5000 (90.1913)  Acc@5: 100.0000 (99.1770)  time: 0.2164  data: 0.0009  max mem: 2502
Test: [Task 2]  [290/625]  eta: 0:01:12  Loss: 0.2681 (0.3304)  Acc@1: 87.5000 (90.1847)  Acc@5: 100.0000 (99.1624)  time: 0.2158  data: 0.0005  max mem: 2502
Test: [Task 2]  [300/625]  eta: 0:01:10  Loss: 0.2845 (0.3313)  Acc@1: 87.5000 (90.1163)  Acc@5: 100.0000 (99.1902)  time: 0.2158  data: 0.0007  max mem: 2502
Test: [Task 2]  [310/625]  eta: 0:01:08  Loss: 0.3246 (0.3322)  Acc@1: 87.5000 (90.0121)  Acc@5: 100.0000 (99.1760)  time: 0.2166  data: 0.0010  max mem: 2502
Test: [Task 2]  [320/625]  eta: 0:01:06  Loss: 0.1671 (0.3249)  Acc@1: 93.7500 (90.2843)  Acc@5: 100.0000 (99.2017)  time: 0.2168  data: 0.0012  max mem: 2502
Test: [Task 2]  [330/625]  eta: 0:01:04  Loss: 0.1368 (0.3231)  Acc@1: 93.7500 (90.2379)  Acc@5: 100.0000 (99.2258)  time: 0.2171  data: 0.0011  max mem: 2502
Test: [Task 2]  [340/625]  eta: 0:01:01  Loss: 0.0975 (0.3157)  Acc@1: 93.7500 (90.5059)  Acc@5: 100.0000 (99.2485)  time: 0.2175  data: 0.0009  max mem: 2502
Test: [Task 2]  [350/625]  eta: 0:00:59  Loss: 0.0913 (0.3133)  Acc@1: 100.0000 (90.5093)  Acc@5: 100.0000 (99.2699)  time: 0.2163  data: 0.0007  max mem: 2502
Test: [Task 2]  [360/625]  eta: 0:00:57  Loss: 0.2928 (0.3145)  Acc@1: 87.5000 (90.5298)  Acc@5: 100.0000 (99.2555)  time: 0.2158  data: 0.0008  max mem: 2502
Test: [Task 2]  [370/625]  eta: 0:00:55  Loss: 0.2200 (0.3117)  Acc@1: 93.7500 (90.5997)  Acc@5: 100.0000 (99.2756)  time: 0.2166  data: 0.0010  max mem: 2502
Test: [Task 2]  [380/625]  eta: 0:00:53  Loss: 0.2653 (0.3142)  Acc@1: 93.7500 (90.5020)  Acc@5: 100.0000 (99.2290)  time: 0.2165  data: 0.0011  max mem: 2502
Test: [Task 2]  [390/625]  eta: 0:00:51  Loss: 0.2633 (0.3129)  Acc@1: 93.7500 (90.5051)  Acc@5: 100.0000 (99.2327)  time: 0.2158  data: 0.0008  max mem: 2502
Test: [Task 2]  [400/625]  eta: 0:00:48  Loss: 0.1189 (0.3086)  Acc@1: 93.7500 (90.6328)  Acc@5: 100.0000 (99.2519)  time: 0.2158  data: 0.0004  max mem: 2502
Test: [Task 2]  [410/625]  eta: 0:00:46  Loss: 0.0804 (0.3065)  Acc@1: 93.7500 (90.7238)  Acc@5: 100.0000 (99.2397)  time: 0.2159  data: 0.0006  max mem: 2502
Test: [Task 2]  [420/625]  eta: 0:00:44  Loss: 0.0852 (0.3057)  Acc@1: 100.0000 (90.7957)  Acc@5: 100.0000 (99.2577)  time: 0.2158  data: 0.0010  max mem: 2502
Test: [Task 2]  [430/625]  eta: 0:00:42  Loss: 0.2255 (0.3050)  Acc@1: 93.7500 (90.8063)  Acc@5: 100.0000 (99.2749)  time: 0.2160  data: 0.0009  max mem: 2502
Test: [Task 2]  [440/625]  eta: 0:00:40  Loss: 0.1565 (0.3005)  Acc@1: 93.7500 (90.9722)  Acc@5: 100.0000 (99.2914)  time: 0.2160  data: 0.0007  max mem: 2502
Test: [Task 2]  [450/625]  eta: 0:00:37  Loss: 0.1108 (0.2966)  Acc@1: 93.7500 (91.0615)  Acc@5: 100.0000 (99.3071)  time: 0.2160  data: 0.0004  max mem: 2502
Test: [Task 2]  [460/625]  eta: 0:00:35  Loss: 0.1156 (0.2930)  Acc@1: 100.0000 (91.2283)  Acc@5: 100.0000 (99.3221)  time: 0.2156  data: 0.0004  max mem: 2502
Test: [Task 2]  [470/625]  eta: 0:00:33  Loss: 0.1426 (0.2903)  Acc@1: 100.0000 (91.3880)  Acc@5: 100.0000 (99.3365)  time: 0.2159  data: 0.0004  max mem: 2502
Test: [Task 2]  [480/625]  eta: 0:00:31  Loss: 0.1753 (0.2879)  Acc@1: 100.0000 (91.4761)  Acc@5: 100.0000 (99.3503)  time: 0.2149  data: 0.0004  max mem: 2502
Test: [Task 2]  [490/625]  eta: 0:00:29  Loss: 0.1347 (0.2853)  Acc@1: 100.0000 (91.6115)  Acc@5: 100.0000 (99.3635)  time: 0.2135  data: 0.0002  max mem: 2502
Test: [Task 2]  [500/625]  eta: 0:00:27  Loss: 0.1290 (0.2828)  Acc@1: 100.0000 (91.7166)  Acc@5: 100.0000 (99.3762)  time: 0.2135  data: 0.0002  max mem: 2502
Test: [Task 2]  [510/625]  eta: 0:00:24  Loss: 0.1671 (0.2863)  Acc@1: 93.7500 (91.6096)  Acc@5: 100.0000 (99.3885)  time: 0.2135  data: 0.0003  max mem: 2502
Test: [Task 2]  [520/625]  eta: 0:00:22  Loss: 0.2270 (0.2867)  Acc@1: 93.7500 (91.5787)  Acc@5: 100.0000 (99.4002)  time: 0.2142  data: 0.0003  max mem: 2502
Test: [Task 2]  [530/625]  eta: 0:00:20  Loss: 0.1549 (0.2843)  Acc@1: 93.7500 (91.6784)  Acc@5: 100.0000 (99.4115)  time: 0.2153  data: 0.0005  max mem: 2502
Test: [Task 2]  [540/625]  eta: 0:00:18  Loss: 0.1083 (0.2821)  Acc@1: 100.0000 (91.7629)  Acc@5: 100.0000 (99.4224)  time: 0.2155  data: 0.0006  max mem: 2502
Test: [Task 2]  [550/625]  eta: 0:00:16  Loss: 0.0784 (0.2785)  Acc@1: 100.0000 (91.8897)  Acc@5: 100.0000 (99.4328)  time: 0.2160  data: 0.0009  max mem: 2502
Test: [Task 2]  [560/625]  eta: 0:00:14  Loss: 0.0589 (0.2745)  Acc@1: 100.0000 (92.0343)  Acc@5: 100.0000 (99.4430)  time: 0.2169  data: 0.0015  max mem: 2502
Test: [Task 2]  [570/625]  eta: 0:00:11  Loss: 0.0606 (0.2747)  Acc@1: 100.0000 (91.9877)  Acc@5: 100.0000 (99.4527)  time: 0.2171  data: 0.0017  max mem: 2502
Test: [Task 2]  [580/625]  eta: 0:00:09  Loss: 0.0985 (0.2719)  Acc@1: 93.7500 (92.0934)  Acc@5: 100.0000 (99.4621)  time: 0.2173  data: 0.0023  max mem: 2502
Test: [Task 2]  [590/625]  eta: 0:00:07  Loss: 0.0950 (0.2699)  Acc@1: 100.0000 (92.1637)  Acc@5: 100.0000 (99.4712)  time: 0.2172  data: 0.0025  max mem: 2502
Test: [Task 2]  [600/625]  eta: 0:00:05  Loss: 0.1701 (0.2700)  Acc@1: 93.7500 (92.1381)  Acc@5: 100.0000 (99.4696)  time: 0.2163  data: 0.0014  max mem: 2502
Test: [Task 2]  [610/625]  eta: 0:00:03  Loss: 0.3060 (0.2724)  Acc@1: 87.5000 (92.0827)  Acc@5: 100.0000 (99.4272)  time: 0.2160  data: 0.0004  max mem: 2502
Test: [Task 2]  [620/625]  eta: 0:00:01  Loss: 0.3560 (0.2735)  Acc@1: 87.5000 (92.0491)  Acc@5: 100.0000 (99.4364)  time: 0.2168  data: 0.0011  max mem: 2502
Test: [Task 2]  [624/625]  eta: 0:00:00  Loss: 0.2809 (0.2731)  Acc@1: 93.7500 (92.0700)  Acc@5: 100.0000 (99.4400)  time: 0.2168  data: 0.0011  max mem: 2502
Test: [Task 2] Total time: 0:02:15 (0.2168 s / it)
* Acc@1 92.070 Acc@5 99.440 loss 0.273
Test: [Task 3]  [  0/625]  eta: 0:06:12  Loss: 0.0798 (0.0798)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)  time: 0.5960  data: 0.3806  max mem: 2502
Test: [Task 3]  [ 10/625]  eta: 0:02:34  Loss: 0.2553 (0.2100)  Acc@1: 100.0000 (97.1591)  Acc@5: 100.0000 (99.4318)  time: 0.2509  data: 0.0352  max mem: 2502
Test: [Task 3]  [ 20/625]  eta: 0:02:21  Loss: 0.2190 (0.2242)  Acc@1: 100.0000 (96.7262)  Acc@5: 100.0000 (99.4048)  time: 0.2164  data: 0.0007  max mem: 2502
Test: [Task 3]  [ 30/625]  eta: 0:02:15  Loss: 0.1877 (0.2345)  Acc@1: 93.7500 (96.3710)  Acc@5: 100.0000 (99.3952)  time: 0.2162  data: 0.0008  max mem: 2502
Test: [Task 3]  [ 40/625]  eta: 0:02:11  Loss: 0.1276 (0.2047)  Acc@1: 100.0000 (96.9512)  Acc@5: 100.0000 (99.5427)  time: 0.2153  data: 0.0009  max mem: 2502
Test: [Task 3]  [ 50/625]  eta: 0:02:08  Loss: 0.1282 (0.2030)  Acc@1: 100.0000 (96.9363)  Acc@5: 100.0000 (99.6324)  time: 0.2157  data: 0.0009  max mem: 2502
Test: [Task 3]  [ 60/625]  eta: 0:02:05  Loss: 0.1638 (0.1994)  Acc@1: 100.0000 (97.1311)  Acc@5: 100.0000 (99.6926)  time: 0.2162  data: 0.0010  max mem: 2502
Test: [Task 3]  [ 70/625]  eta: 0:02:03  Loss: 0.1352 (0.1909)  Acc@1: 100.0000 (97.2711)  Acc@5: 100.0000 (99.6479)  time: 0.2185  data: 0.0011  max mem: 2502
Test: [Task 3]  [ 80/625]  eta: 0:02:00  Loss: 0.1414 (0.1939)  Acc@1: 100.0000 (97.1451)  Acc@5: 100.0000 (99.6914)  time: 0.2182  data: 0.0009  max mem: 2502
Test: [Task 3]  [ 90/625]  eta: 0:01:57  Loss: 0.1471 (0.1928)  Acc@1: 100.0000 (97.1841)  Acc@5: 100.0000 (99.6566)  time: 0.2149  data: 0.0003  max mem: 2502
Test: [Task 3]  [100/625]  eta: 0:01:55  Loss: 0.1387 (0.1885)  Acc@1: 100.0000 (97.4010)  Acc@5: 100.0000 (99.6906)  time: 0.2143  data: 0.0003  max mem: 2502
Test: [Task 3]  [110/625]  eta: 0:01:52  Loss: 0.1247 (0.1813)  Acc@1: 100.0000 (97.6351)  Acc@5: 100.0000 (99.7185)  time: 0.2134  data: 0.0002  max mem: 2502
Test: [Task 3]  [120/625]  eta: 0:01:50  Loss: 0.1247 (0.1838)  Acc@1: 100.0000 (97.5723)  Acc@5: 100.0000 (99.7417)  time: 0.2131  data: 0.0002  max mem: 2502
Test: [Task 3]  [130/625]  eta: 0:01:48  Loss: 0.1875 (0.1842)  Acc@1: 100.0000 (97.5191)  Acc@5: 100.0000 (99.7137)  time: 0.2136  data: 0.0002  max mem: 2502
Test: [Task 3]  [140/625]  eta: 0:01:45  Loss: 0.1910 (0.1907)  Acc@1: 93.7500 (97.3404)  Acc@5: 100.0000 (99.6454)  time: 0.2137  data: 0.0003  max mem: 2502
Test: [Task 3]  [150/625]  eta: 0:01:43  Loss: 0.1910 (0.1967)  Acc@1: 93.7500 (97.1854)  Acc@5: 100.0000 (99.5861)  time: 0.2139  data: 0.0004  max mem: 2502
Test: [Task 3]  [160/625]  eta: 0:01:41  Loss: 0.1526 (0.1972)  Acc@1: 100.0000 (97.2826)  Acc@5: 100.0000 (99.5342)  time: 0.2147  data: 0.0005  max mem: 2502
Test: [Task 3]  [170/625]  eta: 0:01:38  Loss: 0.1108 (0.1947)  Acc@1: 100.0000 (97.3319)  Acc@5: 100.0000 (99.5614)  time: 0.2149  data: 0.0005  max mem: 2502
Test: [Task 3]  [180/625]  eta: 0:01:36  Loss: 0.1864 (0.1984)  Acc@1: 100.0000 (97.2030)  Acc@5: 100.0000 (99.5166)  time: 0.2155  data: 0.0006  max mem: 2502
Test: [Task 3]  [190/625]  eta: 0:01:34  Loss: 0.2158 (0.1976)  Acc@1: 93.7500 (97.1531)  Acc@5: 100.0000 (99.5419)  time: 0.2159  data: 0.0006  max mem: 2502
Test: [Task 3]  [200/625]  eta: 0:01:32  Loss: 0.2097 (0.1990)  Acc@1: 93.7500 (97.0149)  Acc@5: 100.0000 (99.5336)  time: 0.2158  data: 0.0009  max mem: 2502
Test: [Task 3]  [210/625]  eta: 0:01:30  Loss: 0.2097 (0.1999)  Acc@1: 93.7500 (96.9787)  Acc@5: 100.0000 (99.4964)  time: 0.2161  data: 0.0012  max mem: 2502
Test: [Task 3]  [220/625]  eta: 0:01:27  Loss: 0.1753 (0.2008)  Acc@1: 100.0000 (96.9740)  Acc@5: 100.0000 (99.4344)  time: 0.2161  data: 0.0010  max mem: 2502
Test: [Task 3]  [230/625]  eta: 0:01:25  Loss: 0.1844 (0.2011)  Acc@1: 100.0000 (96.9426)  Acc@5: 100.0000 (99.4589)  time: 0.2171  data: 0.0011  max mem: 2502
Test: [Task 3]  [240/625]  eta: 0:01:23  Loss: 0.1614 (0.2043)  Acc@1: 93.7500 (96.8880)  Acc@5: 100.0000 (99.4295)  time: 0.2179  data: 0.0011  max mem: 2502
Test: [Task 3]  [250/625]  eta: 0:01:21  Loss: 0.1172 (0.2015)  Acc@1: 100.0000 (96.9622)  Acc@5: 100.0000 (99.4522)  time: 0.2167  data: 0.0009  max mem: 2502
Test: [Task 3]  [260/625]  eta: 0:01:19  Loss: 0.1246 (0.2003)  Acc@1: 100.0000 (96.9588)  Acc@5: 100.0000 (99.4492)  time: 0.2154  data: 0.0008  max mem: 2502
Test: [Task 3]  [270/625]  eta: 0:01:17  Loss: 0.1305 (0.1997)  Acc@1: 100.0000 (96.9557)  Acc@5: 100.0000 (99.4465)  time: 0.2151  data: 0.0006  max mem: 2502
Test: [Task 3]  [280/625]  eta: 0:01:14  Loss: 0.1404 (0.1993)  Acc@1: 100.0000 (96.9528)  Acc@5: 100.0000 (99.4440)  time: 0.2155  data: 0.0005  max mem: 2502
Test: [Task 3]  [290/625]  eta: 0:01:12  Loss: 0.1557 (0.1997)  Acc@1: 100.0000 (96.9502)  Acc@5: 100.0000 (99.4416)  time: 0.2162  data: 0.0010  max mem: 2502
Test: [Task 3]  [300/625]  eta: 0:01:10  Loss: 0.1634 (0.2056)  Acc@1: 100.0000 (96.7400)  Acc@5: 100.0000 (99.3355)  time: 0.2154  data: 0.0010  max mem: 2502
Test: [Task 3]  [310/625]  eta: 0:01:08  Loss: 0.1380 (0.2068)  Acc@1: 100.0000 (96.7042)  Acc@5: 100.0000 (99.3167)  time: 0.2152  data: 0.0005  max mem: 2502
Test: [Task 3]  [320/625]  eta: 0:01:06  Loss: 0.1380 (0.2060)  Acc@1: 100.0000 (96.7095)  Acc@5: 100.0000 (99.2991)  time: 0.2158  data: 0.0005  max mem: 2502
Test: [Task 3]  [330/625]  eta: 0:01:03  Loss: 0.2005 (0.2069)  Acc@1: 93.7500 (96.6956)  Acc@5: 100.0000 (99.3014)  time: 0.2152  data: 0.0005  max mem: 2502
Test: [Task 3]  [340/625]  eta: 0:01:01  Loss: 0.1439 (0.2046)  Acc@1: 100.0000 (96.7375)  Acc@5: 100.0000 (99.3218)  time: 0.2152  data: 0.0005  max mem: 2502
Test: [Task 3]  [350/625]  eta: 0:00:59  Loss: 0.1279 (0.2048)  Acc@1: 100.0000 (96.7236)  Acc@5: 100.0000 (99.3234)  time: 0.2162  data: 0.0004  max mem: 2502
Test: [Task 3]  [360/625]  eta: 0:00:57  Loss: 0.1687 (0.2058)  Acc@1: 93.7500 (96.6586)  Acc@5: 100.0000 (99.3421)  time: 0.2149  data: 0.0003  max mem: 2502
Test: [Task 3]  [370/625]  eta: 0:00:55  Loss: 0.1961 (0.2059)  Acc@1: 93.7500 (96.6307)  Acc@5: 100.0000 (99.3261)  time: 0.2133  data: 0.0002  max mem: 2502
Test: [Task 3]  [380/625]  eta: 0:00:53  Loss: 0.1403 (0.2042)  Acc@1: 100.0000 (96.6699)  Acc@5: 100.0000 (99.3438)  time: 0.2132  data: 0.0002  max mem: 2502
Test: [Task 3]  [390/625]  eta: 0:00:50  Loss: 0.1207 (0.2040)  Acc@1: 100.0000 (96.6432)  Acc@5: 100.0000 (99.3606)  time: 0.2133  data: 0.0002  max mem: 2502
Test: [Task 3]  [400/625]  eta: 0:00:48  Loss: 0.1367 (0.2038)  Acc@1: 93.7500 (96.6022)  Acc@5: 100.0000 (99.3610)  time: 0.2136  data: 0.0003  max mem: 2502
Test: [Task 3]  [410/625]  eta: 0:00:46  Loss: 0.1458 (0.2043)  Acc@1: 93.7500 (96.6241)  Acc@5: 100.0000 (99.3613)  time: 0.2146  data: 0.0004  max mem: 2502
Test: [Task 3]  [420/625]  eta: 0:00:44  Loss: 0.1537 (0.2040)  Acc@1: 100.0000 (96.5855)  Acc@5: 100.0000 (99.3616)  time: 0.2153  data: 0.0005  max mem: 2502
Test: [Task 3]  [430/625]  eta: 0:00:42  Loss: 0.1577 (0.2040)  Acc@1: 93.7500 (96.5632)  Acc@5: 100.0000 (99.3619)  time: 0.2155  data: 0.0004  max mem: 2502
Test: [Task 3]  [440/625]  eta: 0:00:39  Loss: 0.1910 (0.2047)  Acc@1: 93.7500 (96.5136)  Acc@5: 100.0000 (99.3622)  time: 0.2160  data: 0.0005  max mem: 2502
Test: [Task 3]  [450/625]  eta: 0:00:37  Loss: 0.1695 (0.2041)  Acc@1: 100.0000 (96.5355)  Acc@5: 100.0000 (99.3764)  time: 0.2155  data: 0.0004  max mem: 2502
Test: [Task 3]  [460/625]  eta: 0:00:35  Loss: 0.1515 (0.2034)  Acc@1: 100.0000 (96.5428)  Acc@5: 100.0000 (99.3764)  time: 0.2157  data: 0.0007  max mem: 2502
Test: [Task 3]  [470/625]  eta: 0:00:33  Loss: 0.1634 (0.2035)  Acc@1: 100.0000 (96.5366)  Acc@5: 100.0000 (99.3763)  time: 0.2164  data: 0.0010  max mem: 2502
Test: [Task 3]  [480/625]  eta: 0:00:31  Loss: 0.1636 (0.2043)  Acc@1: 100.0000 (96.5437)  Acc@5: 100.0000 (99.3763)  time: 0.2165  data: 0.0008  max mem: 2502
Test: [Task 3]  [490/625]  eta: 0:00:29  Loss: 0.1683 (0.2043)  Acc@1: 100.0000 (96.5377)  Acc@5: 100.0000 (99.3635)  time: 0.2171  data: 0.0008  max mem: 2502
Test: [Task 3]  [500/625]  eta: 0:00:27  Loss: 0.1044 (0.2032)  Acc@1: 100.0000 (96.5694)  Acc@5: 100.0000 (99.3762)  time: 0.2195  data: 0.0020  max mem: 2502
Test: [Task 3]  [510/625]  eta: 0:00:24  Loss: 0.1012 (0.2019)  Acc@1: 100.0000 (96.5876)  Acc@5: 100.0000 (99.3885)  time: 0.2186  data: 0.0017  max mem: 2502
Test: [Task 3]  [520/625]  eta: 0:00:22  Loss: 0.1444 (0.2019)  Acc@1: 100.0000 (96.5931)  Acc@5: 100.0000 (99.4002)  time: 0.2154  data: 0.0004  max mem: 2502
Test: [Task 3]  [530/625]  eta: 0:00:20  Loss: 0.1866 (0.2028)  Acc@1: 93.7500 (96.5278)  Acc@5: 100.0000 (99.4115)  time: 0.2157  data: 0.0006  max mem: 2502
Test: [Task 3]  [540/625]  eta: 0:00:18  Loss: 0.1801 (0.2037)  Acc@1: 93.7500 (96.5226)  Acc@5: 100.0000 (99.4108)  time: 0.2163  data: 0.0009  max mem: 2502
Test: [Task 3]  [550/625]  eta: 0:00:16  Loss: 0.1792 (0.2041)  Acc@1: 93.7500 (96.5177)  Acc@5: 100.0000 (99.4102)  time: 0.2161  data: 0.0009  max mem: 2502
Test: [Task 3]  [560/625]  eta: 0:00:14  Loss: 0.1739 (0.2041)  Acc@1: 100.0000 (96.5352)  Acc@5: 100.0000 (99.4207)  time: 0.2157  data: 0.0010  max mem: 2502
Test: [Task 3]  [570/625]  eta: 0:00:11  Loss: 0.1735 (0.2036)  Acc@1: 100.0000 (96.5302)  Acc@5: 100.0000 (99.4308)  time: 0.2185  data: 0.0010  max mem: 2502
Test: [Task 3]  [580/625]  eta: 0:00:09  Loss: 0.2035 (0.2050)  Acc@1: 93.7500 (96.4824)  Acc@5: 100.0000 (99.4299)  time: 0.2182  data: 0.0006  max mem: 2502
Test: [Task 3]  [590/625]  eta: 0:00:07  Loss: 0.1783 (0.2042)  Acc@1: 100.0000 (96.5207)  Acc@5: 100.0000 (99.4395)  time: 0.2157  data: 0.0005  max mem: 2502
Test: [Task 3]  [600/625]  eta: 0:00:05  Loss: 0.1723 (0.2045)  Acc@1: 100.0000 (96.4850)  Acc@5: 100.0000 (99.4280)  time: 0.2172  data: 0.0005  max mem: 2502
Test: [Task 3]  [610/625]  eta: 0:00:03  Loss: 0.1669 (0.2038)  Acc@1: 93.7500 (96.4812)  Acc@5: 100.0000 (99.4374)  time: 0.2158  data: 0.0003  max mem: 2502
Test: [Task 3]  [620/625]  eta: 0:00:01  Loss: 0.1786 (0.2045)  Acc@1: 93.7500 (96.4573)  Acc@5: 100.0000 (99.4364)  time: 0.2135  data: 0.0002  max mem: 2502
Test: [Task 3]  [624/625]  eta: 0:00:00  Loss: 0.1421 (0.2039)  Acc@1: 100.0000 (96.4800)  Acc@5: 100.0000 (99.4400)  time: 0.2136  data: 0.0002  max mem: 2502
Test: [Task 3] Total time: 0:02:15 (0.2166 s / it)
* Acc@1 96.480 Acc@5 99.440 loss 0.204
{0: {0: 26032, 1: 26032, 2: 26032, 3: 26032, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0, 10: 0, 11: 0, 12: 0, 13: 0, 14: 0, 15: 0, 16: 0, 17: 0, 18: 0, 19: 0}, 1: {0: 0, 1: 0, 2: 0, 3: 0, 4: 10000, 5: 10000, 6: 10000, 7: 10000, 8: 0, 9: 0, 10: 0, 11: 0, 12: 0, 13: 0, 14: 0, 15: 0, 16: 0, 17: 0, 18: 0, 19: 0}, 2: {0: 16, 1: 16, 2: 16, 3: 16, 4: 0, 5: 0, 6: 0, 7: 0, 8: 9984, 9: 9984, 10: 9984, 11: 9984, 12: 0, 13: 0, 14: 0, 15: 0, 16: 0, 17: 0, 18: 0, 19: 0}}
[Average accuracy till task3]	Acc@1: 86.7590	Acc@5: 97.8199	Loss: 0.5236	Forgetting: 7.1847	Backward: -7.1847
Train: Epoch[1/5]  [   0/1142]  eta: 0:13:24  Lr: 0.001875  Loss: 1.6677  Acc@1: 12.5000 (12.5000)  Acc@5: 50.0000 (50.0000)  time: 0.7041  data: 0.3480  max mem: 2502
Train: Epoch[1/5]  [  10/1142]  eta: 0:07:11  Lr: 0.001875  Loss: 1.4083  Acc@1: 25.0000 (25.5682)  Acc@5: 75.0000 (64.7727)  time: 0.3809  data: 0.0342  max mem: 2502
Train: Epoch[1/5]  [  20/1142]  eta: 0:06:50  Lr: 0.001875  Loss: 1.1560  Acc@1: 31.2500 (29.4643)  Acc@5: 75.0000 (67.2619)  time: 0.3486  data: 0.0021  max mem: 2502
Train: Epoch[1/5]  [  30/1142]  eta: 0:06:40  Lr: 0.001875  Loss: 1.0455  Acc@1: 37.5000 (33.4677)  Acc@5: 81.2500 (71.9758)  time: 0.3488  data: 0.0017  max mem: 2502
Train: Epoch[1/5]  [  40/1142]  eta: 0:06:33  Lr: 0.001875  Loss: 1.1003  Acc@1: 37.5000 (34.9085)  Acc@5: 87.5000 (76.0671)  time: 0.3485  data: 0.0019  max mem: 2502
Train: Epoch[1/5]  [  50/1142]  eta: 0:06:28  Lr: 0.001875  Loss: 0.8165  Acc@1: 50.0000 (38.6029)  Acc@5: 87.5000 (79.2892)  time: 0.3492  data: 0.0017  max mem: 2502
Train: Epoch[1/5]  [  60/1142]  eta: 0:06:24  Lr: 0.001875  Loss: 0.9289  Acc@1: 50.0000 (39.6516)  Acc@5: 87.5000 (80.6352)  time: 0.3503  data: 0.0020  max mem: 2502
Train: Epoch[1/5]  [  70/1142]  eta: 0:06:19  Lr: 0.001875  Loss: 0.8250  Acc@1: 43.7500 (40.7570)  Acc@5: 87.5000 (81.6021)  time: 0.3491  data: 0.0014  max mem: 2502
Train: Epoch[1/5]  [  80/1142]  eta: 0:06:15  Lr: 0.001875  Loss: 0.4212  Acc@1: 43.7500 (41.8210)  Acc@5: 87.5000 (82.0988)  time: 0.3478  data: 0.0008  max mem: 2502
Train: Epoch[1/5]  [  90/1142]  eta: 0:06:10  Lr: 0.001875  Loss: 0.2452  Acc@1: 50.0000 (42.7885)  Acc@5: 87.5000 (82.5549)  time: 0.3472  data: 0.0008  max mem: 2502
Train: Epoch[1/5]  [ 100/1142]  eta: 0:06:06  Lr: 0.001875  Loss: 0.2124  Acc@1: 50.0000 (44.8020)  Acc@5: 87.5000 (83.1064)  time: 0.3467  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [ 110/1142]  eta: 0:06:02  Lr: 0.001875  Loss: 0.2060  Acc@1: 56.2500 (45.3829)  Acc@5: 87.5000 (83.5586)  time: 0.3464  data: 0.0006  max mem: 2502
Train: Epoch[1/5]  [ 120/1142]  eta: 0:05:58  Lr: 0.001875  Loss: 0.6115  Acc@1: 56.2500 (46.4360)  Acc@5: 93.7500 (84.4008)  time: 0.3458  data: 0.0007  max mem: 2502
Train: Epoch[1/5]  [ 130/1142]  eta: 0:05:54  Lr: 0.001875  Loss: -0.1567  Acc@1: 56.2500 (46.9943)  Acc@5: 93.7500 (84.7805)  time: 0.3443  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [ 140/1142]  eta: 0:05:50  Lr: 0.001875  Loss: 0.0645  Acc@1: 50.0000 (47.0745)  Acc@5: 87.5000 (85.1507)  time: 0.3431  data: 0.0002  max mem: 2502
Train: Epoch[1/5]  [ 150/1142]  eta: 0:05:46  Lr: 0.001875  Loss: 0.3733  Acc@1: 50.0000 (47.5166)  Acc@5: 93.7500 (85.4719)  time: 0.3430  data: 0.0002  max mem: 2502
Train: Epoch[1/5]  [ 160/1142]  eta: 0:05:42  Lr: 0.001875  Loss: 0.3020  Acc@1: 50.0000 (47.5155)  Acc@5: 87.5000 (85.7919)  time: 0.3447  data: 0.0007  max mem: 2502
Train: Epoch[1/5]  [ 170/1142]  eta: 0:05:39  Lr: 0.001875  Loss: 0.0382  Acc@1: 50.0000 (47.9167)  Acc@5: 87.5000 (86.1111)  time: 0.3467  data: 0.0008  max mem: 2502
Train: Epoch[1/5]  [ 180/1142]  eta: 0:05:35  Lr: 0.001875  Loss: 0.2922  Acc@1: 50.0000 (48.2044)  Acc@5: 87.5000 (86.2569)  time: 0.3475  data: 0.0014  max mem: 2502
Train: Epoch[1/5]  [ 190/1142]  eta: 0:05:32  Lr: 0.001875  Loss: 0.4290  Acc@1: 50.0000 (48.1021)  Acc@5: 87.5000 (86.3547)  time: 0.3480  data: 0.0014  max mem: 2502
Train: Epoch[1/5]  [ 200/1142]  eta: 0:05:28  Lr: 0.001875  Loss: 0.0792  Acc@1: 56.2500 (48.9428)  Acc@5: 87.5000 (86.7226)  time: 0.3485  data: 0.0012  max mem: 2502
Train: Epoch[1/5]  [ 210/1142]  eta: 0:05:25  Lr: 0.001875  Loss: 0.2232  Acc@1: 62.5000 (49.3483)  Acc@5: 93.7500 (87.0557)  time: 0.3496  data: 0.0017  max mem: 2502
Train: Epoch[1/5]  [ 220/1142]  eta: 0:05:21  Lr: 0.001875  Loss: -0.1828  Acc@1: 56.2500 (49.8869)  Acc@5: 93.7500 (87.3020)  time: 0.3488  data: 0.0013  max mem: 2502
Train: Epoch[1/5]  [ 230/1142]  eta: 0:05:18  Lr: 0.001875  Loss: 0.4042  Acc@1: 56.2500 (50.1082)  Acc@5: 93.7500 (87.5000)  time: 0.3481  data: 0.0008  max mem: 2502
Train: Epoch[1/5]  [ 240/1142]  eta: 0:05:14  Lr: 0.001875  Loss: 0.2200  Acc@1: 56.2500 (50.6224)  Acc@5: 93.7500 (87.7075)  time: 0.3481  data: 0.0008  max mem: 2502
Train: Epoch[1/5]  [ 250/1142]  eta: 0:05:11  Lr: 0.001875  Loss: 0.1324  Acc@1: 56.2500 (50.9462)  Acc@5: 93.7500 (87.9233)  time: 0.3472  data: 0.0008  max mem: 2502
Train: Epoch[1/5]  [ 260/1142]  eta: 0:05:07  Lr: 0.001875  Loss: 0.1818  Acc@1: 56.2500 (51.1973)  Acc@5: 93.7500 (88.0508)  time: 0.3511  data: 0.0023  max mem: 2502
Train: Epoch[1/5]  [ 270/1142]  eta: 0:05:04  Lr: 0.001875  Loss: -0.5076  Acc@1: 56.2500 (51.5683)  Acc@5: 93.7500 (88.2380)  time: 0.3506  data: 0.0025  max mem: 2502
Train: Epoch[1/5]  [ 280/1142]  eta: 0:05:00  Lr: 0.001875  Loss: -0.1866  Acc@1: 56.2500 (51.7571)  Acc@5: 93.7500 (88.3897)  time: 0.3493  data: 0.0007  max mem: 2502
Train: Epoch[1/5]  [ 290/1142]  eta: 0:04:57  Lr: 0.001875  Loss: -0.0908  Acc@1: 56.2500 (51.9759)  Acc@5: 87.5000 (88.3376)  time: 0.3476  data: 0.0002  max mem: 2502
Train: Epoch[1/5]  [ 300/1142]  eta: 0:04:53  Lr: 0.001875  Loss: -0.2809  Acc@1: 62.5000 (52.2425)  Acc@5: 87.5000 (88.5382)  time: 0.3425  data: 0.0002  max mem: 2502
Train: Epoch[1/5]  [ 310/1142]  eta: 0:04:49  Lr: 0.001875  Loss: -0.1807  Acc@1: 62.5000 (52.4920)  Acc@5: 93.7500 (88.6455)  time: 0.3431  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [ 320/1142]  eta: 0:04:46  Lr: 0.001875  Loss: -0.2594  Acc@1: 62.5000 (52.6869)  Acc@5: 93.7500 (88.6877)  time: 0.3454  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [ 330/1142]  eta: 0:04:42  Lr: 0.001875  Loss: -0.1009  Acc@1: 56.2500 (52.9079)  Acc@5: 93.7500 (88.7462)  time: 0.3477  data: 0.0008  max mem: 2502
Train: Epoch[1/5]  [ 340/1142]  eta: 0:04:39  Lr: 0.001875  Loss: 0.0448  Acc@1: 62.5000 (53.1891)  Acc@5: 93.7500 (88.8196)  time: 0.3477  data: 0.0009  max mem: 2502
Train: Epoch[1/5]  [ 350/1142]  eta: 0:04:35  Lr: 0.001875  Loss: -0.2793  Acc@1: 62.5000 (53.4544)  Acc@5: 93.7500 (88.8711)  time: 0.3473  data: 0.0009  max mem: 2502
Train: Epoch[1/5]  [ 360/1142]  eta: 0:04:32  Lr: 0.001875  Loss: -0.2226  Acc@1: 62.5000 (53.7742)  Acc@5: 93.7500 (89.0062)  time: 0.3474  data: 0.0006  max mem: 2502
Train: Epoch[1/5]  [ 370/1142]  eta: 0:04:28  Lr: 0.001875  Loss: -0.2958  Acc@1: 62.5000 (53.9757)  Acc@5: 93.7500 (89.1341)  time: 0.3476  data: 0.0008  max mem: 2502
Train: Epoch[1/5]  [ 380/1142]  eta: 0:04:25  Lr: 0.001875  Loss: 0.2140  Acc@1: 56.2500 (54.0190)  Acc@5: 93.7500 (89.1896)  time: 0.3477  data: 0.0017  max mem: 2502
Train: Epoch[1/5]  [ 390/1142]  eta: 0:04:21  Lr: 0.001875  Loss: -0.3041  Acc@1: 56.2500 (54.2199)  Acc@5: 93.7500 (89.3382)  time: 0.3474  data: 0.0014  max mem: 2502
Train: Epoch[1/5]  [ 400/1142]  eta: 0:04:18  Lr: 0.001875  Loss: -0.1703  Acc@1: 56.2500 (54.3953)  Acc@5: 93.7500 (89.4483)  time: 0.3480  data: 0.0006  max mem: 2502
Train: Epoch[1/5]  [ 410/1142]  eta: 0:04:14  Lr: 0.001875  Loss: -0.1926  Acc@1: 62.5000 (54.6837)  Acc@5: 93.7500 (89.5225)  time: 0.3501  data: 0.0007  max mem: 2502
Train: Epoch[1/5]  [ 420/1142]  eta: 0:04:11  Lr: 0.001875  Loss: -0.3240  Acc@1: 62.5000 (54.6764)  Acc@5: 93.7500 (89.5338)  time: 0.3499  data: 0.0008  max mem: 2502
Train: Epoch[1/5]  [ 430/1142]  eta: 0:04:07  Lr: 0.001875  Loss: -0.2914  Acc@1: 56.2500 (54.8579)  Acc@5: 93.7500 (89.6027)  time: 0.3471  data: 0.0006  max mem: 2502
Train: Epoch[1/5]  [ 440/1142]  eta: 0:04:04  Lr: 0.001875  Loss: -0.5265  Acc@1: 62.5000 (54.9178)  Acc@5: 93.7500 (89.6684)  time: 0.3486  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [ 450/1142]  eta: 0:04:00  Lr: 0.001875  Loss: -0.3746  Acc@1: 62.5000 (55.1829)  Acc@5: 93.7500 (89.7589)  time: 0.3477  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [ 460/1142]  eta: 0:03:57  Lr: 0.001875  Loss: -0.1606  Acc@1: 62.5000 (55.2332)  Acc@5: 93.7500 (89.8319)  time: 0.3435  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [ 470/1142]  eta: 0:03:53  Lr: 0.001875  Loss: -0.5487  Acc@1: 62.5000 (55.4804)  Acc@5: 93.7500 (89.9416)  time: 0.3430  data: 0.0002  max mem: 2502
Train: Epoch[1/5]  [ 480/1142]  eta: 0:03:50  Lr: 0.001875  Loss: 0.3577  Acc@1: 56.2500 (55.3924)  Acc@5: 93.7500 (90.0078)  time: 0.3448  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [ 490/1142]  eta: 0:03:46  Lr: 0.001875  Loss: -0.0824  Acc@1: 50.0000 (55.4990)  Acc@5: 93.7500 (90.0713)  time: 0.3474  data: 0.0009  max mem: 2502
Train: Epoch[1/5]  [ 500/1142]  eta: 0:03:43  Lr: 0.001875  Loss: -0.0643  Acc@1: 62.5000 (55.7136)  Acc@5: 93.7500 (90.1073)  time: 0.3466  data: 0.0009  max mem: 2502
Train: Epoch[1/5]  [ 510/1142]  eta: 0:03:39  Lr: 0.001875  Loss: -0.7498  Acc@1: 62.5000 (55.8708)  Acc@5: 93.7500 (90.1296)  time: 0.3469  data: 0.0008  max mem: 2502
Train: Epoch[1/5]  [ 520/1142]  eta: 0:03:36  Lr: 0.001875  Loss: -0.1145  Acc@1: 50.0000 (55.8901)  Acc@5: 93.7500 (90.1631)  time: 0.3478  data: 0.0012  max mem: 2502
Train: Epoch[1/5]  [ 530/1142]  eta: 0:03:32  Lr: 0.001875  Loss: 0.1748  Acc@1: 62.5000 (55.9911)  Acc@5: 93.7500 (90.2189)  time: 0.3483  data: 0.0010  max mem: 2502
Train: Epoch[1/5]  [ 540/1142]  eta: 0:03:29  Lr: 0.001875  Loss: -0.1855  Acc@1: 62.5000 (56.0652)  Acc@5: 93.7500 (90.2611)  time: 0.3487  data: 0.0007  max mem: 2502
Train: Epoch[1/5]  [ 550/1142]  eta: 0:03:25  Lr: 0.001875  Loss: -0.4940  Acc@1: 62.5000 (56.1252)  Acc@5: 93.7500 (90.3471)  time: 0.3462  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [ 560/1142]  eta: 0:03:22  Lr: 0.001875  Loss: -0.4914  Acc@1: 56.2500 (56.2054)  Acc@5: 93.7500 (90.3409)  time: 0.3453  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [ 570/1142]  eta: 0:03:18  Lr: 0.001875  Loss: -0.0841  Acc@1: 62.5000 (56.3266)  Acc@5: 93.7500 (90.3568)  time: 0.3470  data: 0.0011  max mem: 2502
Train: Epoch[1/5]  [ 580/1142]  eta: 0:03:15  Lr: 0.001875  Loss: -0.0286  Acc@1: 68.7500 (56.5082)  Acc@5: 93.7500 (90.3722)  time: 0.3473  data: 0.0011  max mem: 2502
Train: Epoch[1/5]  [ 590/1142]  eta: 0:03:12  Lr: 0.001875  Loss: 0.1797  Acc@1: 62.5000 (56.5884)  Acc@5: 93.7500 (90.4188)  time: 0.3472  data: 0.0006  max mem: 2502
Train: Epoch[1/5]  [ 600/1142]  eta: 0:03:08  Lr: 0.001875  Loss: -0.6553  Acc@1: 56.2500 (56.6868)  Acc@5: 93.7500 (90.4534)  time: 0.3471  data: 0.0007  max mem: 2502
Train: Epoch[1/5]  [ 610/1142]  eta: 0:03:05  Lr: 0.001875  Loss: -0.2416  Acc@1: 62.5000 (56.8842)  Acc@5: 93.7500 (90.5176)  time: 0.3457  data: 0.0012  max mem: 2502
Train: Epoch[1/5]  [ 620/1142]  eta: 0:03:01  Lr: 0.001875  Loss: -0.5989  Acc@1: 62.5000 (56.9646)  Acc@5: 93.7500 (90.5294)  time: 0.3441  data: 0.0008  max mem: 2502
Train: Epoch[1/5]  [ 630/1142]  eta: 0:02:57  Lr: 0.001875  Loss: -0.4311  Acc@1: 62.5000 (57.0820)  Acc@5: 93.7500 (90.6200)  time: 0.3435  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [ 640/1142]  eta: 0:02:54  Lr: 0.001875  Loss: -0.1938  Acc@1: 68.7500 (57.2348)  Acc@5: 93.7500 (90.6494)  time: 0.3433  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [ 650/1142]  eta: 0:02:51  Lr: 0.001875  Loss: -0.0879  Acc@1: 68.7500 (57.3157)  Acc@5: 93.7500 (90.6490)  time: 0.3465  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [ 660/1142]  eta: 0:02:47  Lr: 0.001875  Loss: -0.8014  Acc@1: 62.5000 (57.3941)  Acc@5: 93.7500 (90.6297)  time: 0.3498  data: 0.0010  max mem: 2502
Train: Epoch[1/5]  [ 670/1142]  eta: 0:02:44  Lr: 0.001875  Loss: -0.3921  Acc@1: 62.5000 (57.5447)  Acc@5: 93.7500 (90.6949)  time: 0.3484  data: 0.0009  max mem: 2502
Train: Epoch[1/5]  [ 680/1142]  eta: 0:02:40  Lr: 0.001875  Loss: -0.3181  Acc@1: 68.7500 (57.6542)  Acc@5: 93.7500 (90.7305)  time: 0.3479  data: 0.0015  max mem: 2502
Train: Epoch[1/5]  [ 690/1142]  eta: 0:02:37  Lr: 0.001875  Loss: -0.4301  Acc@1: 62.5000 (57.7243)  Acc@5: 93.7500 (90.7833)  time: 0.3479  data: 0.0016  max mem: 2502
Train: Epoch[1/5]  [ 700/1142]  eta: 0:02:33  Lr: 0.001875  Loss: -0.6492  Acc@1: 62.5000 (57.8727)  Acc@5: 93.7500 (90.8345)  time: 0.3477  data: 0.0011  max mem: 2502
Train: Epoch[1/5]  [ 710/1142]  eta: 0:02:30  Lr: 0.001875  Loss: -0.4955  Acc@1: 62.5000 (57.9553)  Acc@5: 93.7500 (90.8579)  time: 0.3481  data: 0.0012  max mem: 2502
Train: Epoch[1/5]  [ 720/1142]  eta: 0:02:26  Lr: 0.001875  Loss: -0.5661  Acc@1: 62.5000 (57.9837)  Acc@5: 93.7500 (90.8460)  time: 0.3475  data: 0.0009  max mem: 2502
Train: Epoch[1/5]  [ 730/1142]  eta: 0:02:23  Lr: 0.001875  Loss: -0.0367  Acc@1: 62.5000 (58.0882)  Acc@5: 87.5000 (90.8516)  time: 0.3461  data: 0.0006  max mem: 2502
Train: Epoch[1/5]  [ 740/1142]  eta: 0:02:19  Lr: 0.001875  Loss: -0.2265  Acc@1: 62.5000 (58.1815)  Acc@5: 93.7500 (90.8823)  time: 0.3460  data: 0.0006  max mem: 2502
Train: Epoch[1/5]  [ 750/1142]  eta: 0:02:16  Lr: 0.001875  Loss: -0.3923  Acc@1: 68.7500 (58.2557)  Acc@5: 93.7500 (90.9454)  time: 0.3465  data: 0.0006  max mem: 2502
Train: Epoch[1/5]  [ 760/1142]  eta: 0:02:12  Lr: 0.001875  Loss: -0.3088  Acc@1: 62.5000 (58.3607)  Acc@5: 93.7500 (90.9987)  time: 0.3467  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [ 770/1142]  eta: 0:02:09  Lr: 0.001875  Loss: -0.5195  Acc@1: 62.5000 (58.4306)  Acc@5: 93.7500 (91.0344)  time: 0.3480  data: 0.0006  max mem: 2502
Train: Epoch[1/5]  [ 780/1142]  eta: 0:02:05  Lr: 0.001875  Loss: -0.4893  Acc@1: 62.5000 (58.5307)  Acc@5: 93.7500 (91.0291)  time: 0.3480  data: 0.0011  max mem: 2502
Train: Epoch[1/5]  [ 790/1142]  eta: 0:02:02  Lr: 0.001875  Loss: -0.4176  Acc@1: 68.7500 (58.6915)  Acc@5: 93.7500 (91.0872)  time: 0.3458  data: 0.0008  max mem: 2502
Train: Epoch[1/5]  [ 800/1142]  eta: 0:01:58  Lr: 0.001875  Loss: -0.8228  Acc@1: 68.7500 (58.7391)  Acc@5: 93.7500 (91.1283)  time: 0.3450  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [ 810/1142]  eta: 0:01:55  Lr: 0.001875  Loss: -0.5224  Acc@1: 68.7500 (58.8009)  Acc@5: 93.7500 (91.1606)  time: 0.3444  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [ 820/1142]  eta: 0:01:51  Lr: 0.001875  Loss: -0.4383  Acc@1: 68.7500 (58.9373)  Acc@5: 93.7500 (91.2302)  time: 0.3435  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [ 830/1142]  eta: 0:01:48  Lr: 0.001875  Loss: -0.2958  Acc@1: 62.5000 (58.9651)  Acc@5: 93.7500 (91.2079)  time: 0.3462  data: 0.0010  max mem: 2502
Train: Epoch[1/5]  [ 840/1142]  eta: 0:01:44  Lr: 0.001875  Loss: -0.7166  Acc@1: 62.5000 (58.9923)  Acc@5: 93.7500 (91.2158)  time: 0.3486  data: 0.0016  max mem: 2502
Train: Epoch[1/5]  [ 850/1142]  eta: 0:01:41  Lr: 0.001875  Loss: -0.7773  Acc@1: 62.5000 (59.1143)  Acc@5: 93.7500 (91.2089)  time: 0.3483  data: 0.0012  max mem: 2502
Train: Epoch[1/5]  [ 860/1142]  eta: 0:01:37  Lr: 0.001875  Loss: -0.1803  Acc@1: 62.5000 (59.1609)  Acc@5: 93.7500 (91.2093)  time: 0.3485  data: 0.0010  max mem: 2502
Train: Epoch[1/5]  [ 870/1142]  eta: 0:01:34  Lr: 0.001875  Loss: -0.4331  Acc@1: 62.5000 (59.1705)  Acc@5: 93.7500 (91.2529)  time: 0.3483  data: 0.0014  max mem: 2502
Train: Epoch[1/5]  [ 880/1142]  eta: 0:01:31  Lr: 0.001875  Loss: -0.4063  Acc@1: 62.5000 (59.2083)  Acc@5: 93.7500 (91.2670)  time: 0.3484  data: 0.0013  max mem: 2502
Train: Epoch[1/5]  [ 890/1142]  eta: 0:01:27  Lr: 0.001875  Loss: -0.3784  Acc@1: 62.5000 (59.2593)  Acc@5: 93.7500 (91.3019)  time: 0.3490  data: 0.0010  max mem: 2502
Train: Epoch[1/5]  [ 900/1142]  eta: 0:01:24  Lr: 0.001875  Loss: -0.3013  Acc@1: 62.5000 (59.3230)  Acc@5: 93.7500 (91.3430)  time: 0.3476  data: 0.0009  max mem: 2502
Train: Epoch[1/5]  [ 910/1142]  eta: 0:01:20  Lr: 0.001875  Loss: -0.0734  Acc@1: 56.2500 (59.3098)  Acc@5: 93.7500 (91.3625)  time: 0.3463  data: 0.0006  max mem: 2502
Train: Epoch[1/5]  [ 920/1142]  eta: 0:01:17  Lr: 0.001875  Loss: -0.4942  Acc@1: 62.5000 (59.3173)  Acc@5: 93.7500 (91.3749)  time: 0.3475  data: 0.0013  max mem: 2502
Train: Epoch[1/5]  [ 930/1142]  eta: 0:01:13  Lr: 0.001875  Loss: -0.2612  Acc@1: 62.5000 (59.2978)  Acc@5: 93.7500 (91.3869)  time: 0.3477  data: 0.0014  max mem: 2502
Train: Epoch[1/5]  [ 940/1142]  eta: 0:01:10  Lr: 0.001875  Loss: -0.4328  Acc@1: 56.2500 (59.3252)  Acc@5: 93.7500 (91.4054)  time: 0.3464  data: 0.0006  max mem: 2502
Train: Epoch[1/5]  [ 950/1142]  eta: 0:01:06  Lr: 0.001875  Loss: -0.4296  Acc@1: 56.2500 (59.3323)  Acc@5: 93.7500 (91.4366)  time: 0.3467  data: 0.0007  max mem: 2502
Train: Epoch[1/5]  [ 960/1142]  eta: 0:01:03  Lr: 0.001875  Loss: 0.0516  Acc@1: 56.2500 (59.4173)  Acc@5: 93.7500 (91.4542)  time: 0.3464  data: 0.0006  max mem: 2502
Train: Epoch[1/5]  [ 970/1142]  eta: 0:00:59  Lr: 0.001875  Loss: -0.0462  Acc@1: 68.7500 (59.5134)  Acc@5: 93.7500 (91.4907)  time: 0.3471  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [ 980/1142]  eta: 0:00:56  Lr: 0.001875  Loss: -0.5137  Acc@1: 68.7500 (59.5948)  Acc@5: 93.7500 (91.4819)  time: 0.3457  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [ 990/1142]  eta: 0:00:52  Lr: 0.001875  Loss: -0.5602  Acc@1: 62.5000 (59.6620)  Acc@5: 93.7500 (91.4985)  time: 0.3429  data: 0.0002  max mem: 2502
Train: Epoch[1/5]  [1000/1142]  eta: 0:00:49  Lr: 0.001875  Loss: -0.0934  Acc@1: 62.5000 (59.7028)  Acc@5: 93.7500 (91.5085)  time: 0.3432  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [1010/1142]  eta: 0:00:45  Lr: 0.001875  Loss: -0.7625  Acc@1: 62.5000 (59.7243)  Acc@5: 93.7500 (91.4998)  time: 0.3450  data: 0.0006  max mem: 2502
Train: Epoch[1/5]  [1020/1142]  eta: 0:00:42  Lr: 0.001875  Loss: -0.5987  Acc@1: 62.5000 (59.7331)  Acc@5: 93.7500 (91.5157)  time: 0.3468  data: 0.0008  max mem: 2502
Train: Epoch[1/5]  [1030/1142]  eta: 0:00:38  Lr: 0.001875  Loss: -0.5531  Acc@1: 62.5000 (59.8024)  Acc@5: 93.7500 (91.4949)  time: 0.3470  data: 0.0007  max mem: 2502
Train: Epoch[1/5]  [1040/1142]  eta: 0:00:35  Lr: 0.001875  Loss: -0.1708  Acc@1: 68.7500 (59.8583)  Acc@5: 93.7500 (91.5046)  time: 0.3466  data: 0.0007  max mem: 2502
Train: Epoch[1/5]  [1050/1142]  eta: 0:00:31  Lr: 0.001875  Loss: -0.3591  Acc@1: 62.5000 (59.8953)  Acc@5: 93.7500 (91.5319)  time: 0.3489  data: 0.0010  max mem: 2502
Train: Epoch[1/5]  [1060/1142]  eta: 0:00:28  Lr: 0.001875  Loss: -0.6099  Acc@1: 62.5000 (59.9317)  Acc@5: 93.7500 (91.5057)  time: 0.3494  data: 0.0010  max mem: 2502
Train: Epoch[1/5]  [1070/1142]  eta: 0:00:25  Lr: 0.001875  Loss: -0.9270  Acc@1: 62.5000 (59.9790)  Acc@5: 93.7500 (91.5324)  time: 0.3473  data: 0.0010  max mem: 2502
Train: Epoch[1/5]  [1080/1142]  eta: 0:00:21  Lr: 0.001875  Loss: -0.2486  Acc@1: 68.7500 (60.0254)  Acc@5: 93.7500 (91.5356)  time: 0.3468  data: 0.0008  max mem: 2502
Train: Epoch[1/5]  [1090/1142]  eta: 0:00:18  Lr: 0.001875  Loss: -0.3282  Acc@1: 62.5000 (60.0023)  Acc@5: 93.7500 (91.5674)  time: 0.3459  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [1100/1142]  eta: 0:00:14  Lr: 0.001875  Loss: -0.4951  Acc@1: 56.2500 (60.0307)  Acc@5: 93.7500 (91.5929)  time: 0.3457  data: 0.0008  max mem: 2502
Train: Epoch[1/5]  [1110/1142]  eta: 0:00:11  Lr: 0.001875  Loss: -0.9004  Acc@1: 68.7500 (60.1091)  Acc@5: 93.7500 (91.6067)  time: 0.3462  data: 0.0010  max mem: 2502
Train: Epoch[1/5]  [1120/1142]  eta: 0:00:07  Lr: 0.001875  Loss: -0.4239  Acc@1: 68.7500 (60.1528)  Acc@5: 93.7500 (91.5923)  time: 0.3490  data: 0.0010  max mem: 2502
Train: Epoch[1/5]  [1130/1142]  eta: 0:00:04  Lr: 0.001875  Loss: -0.5082  Acc@1: 68.7500 (60.2067)  Acc@5: 93.7500 (91.6059)  time: 0.3485  data: 0.0010  max mem: 2502
Train: Epoch[1/5]  [1140/1142]  eta: 0:00:00  Lr: 0.001875  Loss: -0.8883  Acc@1: 68.7500 (60.2816)  Acc@5: 93.7500 (91.6466)  time: 0.3455  data: 0.0007  max mem: 2502
Train: Epoch[1/5]  [1141/1142]  eta: 0:00:00  Lr: 0.001875  Loss: 0.3050  Acc@1: 68.7500 (60.2792)  Acc@5: 93.7500 (91.6343)  time: 0.3380  data: 0.0007  max mem: 2502
Train: Epoch[1/5] Total time: 0:06:36 (0.3474 s / it)
{0: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 1: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 2: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 3: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 4: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 5: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 6: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 7: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 8: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 9: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 10: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 11: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 12: {0: 0, 1: 0, 2: 0, 3: 18265, 4: 0}, 13: {0: 0, 1: 0, 2: 0, 3: 18265, 4: 0}, 14: {0: 0, 1: 0, 2: 0, 3: 18265, 4: 0}, 15: {0: 0, 1: 0, 2: 0, 3: 18265, 4: 0}, 16: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 17: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 18: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 19: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}}
Averaged stats: Lr: 0.001875  Loss: 0.3050  Acc@1: 68.7500 (60.2792)  Acc@5: 93.7500 (91.6343)
Train: Epoch[2/5]  [   0/1142]  eta: 0:11:22  Lr: 0.001875  Loss: -1.1602  Acc@1: 93.7500 (93.7500)  Acc@5: 100.0000 (100.0000)  time: 0.5980  data: 0.2557  max mem: 2502
Train: Epoch[2/5]  [  10/1142]  eta: 0:06:54  Lr: 0.001875  Loss: -0.5661  Acc@1: 75.0000 (73.2955)  Acc@5: 100.0000 (96.0227)  time: 0.3659  data: 0.0235  max mem: 2502
Train: Epoch[2/5]  [  20/1142]  eta: 0:06:38  Lr: 0.001875  Loss: 0.1307  Acc@1: 68.7500 (69.0476)  Acc@5: 93.7500 (94.3452)  time: 0.3427  data: 0.0002  max mem: 2502
Train: Epoch[2/5]  [  30/1142]  eta: 0:06:30  Lr: 0.001875  Loss: -0.3368  Acc@1: 62.5000 (67.9435)  Acc@5: 87.5000 (93.1452)  time: 0.3428  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [  40/1142]  eta: 0:06:25  Lr: 0.001875  Loss: 0.1285  Acc@1: 68.7500 (67.0732)  Acc@5: 93.7500 (92.6829)  time: 0.3448  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [  50/1142]  eta: 0:06:21  Lr: 0.001875  Loss: -0.3993  Acc@1: 75.0000 (67.8922)  Acc@5: 93.7500 (93.0147)  time: 0.3466  data: 0.0008  max mem: 2502
Train: Epoch[2/5]  [  60/1142]  eta: 0:06:17  Lr: 0.001875  Loss: -0.5849  Acc@1: 68.7500 (67.3156)  Acc@5: 93.7500 (92.9303)  time: 0.3471  data: 0.0009  max mem: 2502
Train: Epoch[2/5]  [  70/1142]  eta: 0:06:13  Lr: 0.001875  Loss: -0.6935  Acc@1: 75.0000 (67.9577)  Acc@5: 93.7500 (93.2218)  time: 0.3473  data: 0.0010  max mem: 2502
Train: Epoch[2/5]  [  80/1142]  eta: 0:06:10  Lr: 0.001875  Loss: -0.5042  Acc@1: 68.7500 (67.3611)  Acc@5: 93.7500 (93.2099)  time: 0.3478  data: 0.0010  max mem: 2502
Train: Epoch[2/5]  [  90/1142]  eta: 0:06:07  Lr: 0.001875  Loss: -0.0624  Acc@1: 62.5000 (67.0330)  Acc@5: 93.7500 (93.4066)  time: 0.3496  data: 0.0010  max mem: 2502
Train: Epoch[2/5]  [ 100/1142]  eta: 0:06:03  Lr: 0.001875  Loss: -0.6023  Acc@1: 56.2500 (66.6460)  Acc@5: 93.7500 (93.3787)  time: 0.3502  data: 0.0014  max mem: 2502
Train: Epoch[2/5]  [ 110/1142]  eta: 0:05:59  Lr: 0.001875  Loss: -0.5218  Acc@1: 56.2500 (65.8784)  Acc@5: 93.7500 (93.1306)  time: 0.3478  data: 0.0011  max mem: 2502
Train: Epoch[2/5]  [ 120/1142]  eta: 0:05:56  Lr: 0.001875  Loss: 0.1141  Acc@1: 62.5000 (65.8574)  Acc@5: 93.7500 (92.9752)  time: 0.3467  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [ 130/1142]  eta: 0:05:52  Lr: 0.001875  Loss: -0.6871  Acc@1: 68.7500 (66.1737)  Acc@5: 93.7500 (93.0821)  time: 0.3474  data: 0.0008  max mem: 2502
Train: Epoch[2/5]  [ 140/1142]  eta: 0:05:49  Lr: 0.001875  Loss: -0.4335  Acc@1: 68.7500 (66.3121)  Acc@5: 93.7500 (93.2181)  time: 0.3474  data: 0.0009  max mem: 2502
Train: Epoch[2/5]  [ 150/1142]  eta: 0:05:45  Lr: 0.001875  Loss: 0.6535  Acc@1: 68.7500 (66.1838)  Acc@5: 93.7500 (93.2533)  time: 0.3482  data: 0.0010  max mem: 2502
Train: Epoch[2/5]  [ 160/1142]  eta: 0:05:42  Lr: 0.001875  Loss: -0.9867  Acc@1: 68.7500 (66.6149)  Acc@5: 93.7500 (93.5559)  time: 0.3472  data: 0.0008  max mem: 2502
Train: Epoch[2/5]  [ 170/1142]  eta: 0:05:38  Lr: 0.001875  Loss: -0.0532  Acc@1: 68.7500 (66.6301)  Acc@5: 100.0000 (93.4942)  time: 0.3448  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [ 180/1142]  eta: 0:05:34  Lr: 0.001875  Loss: -0.4002  Acc@1: 68.7500 (66.8163)  Acc@5: 93.7500 (93.4047)  time: 0.3438  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [ 190/1142]  eta: 0:05:30  Lr: 0.001875  Loss: -0.6252  Acc@1: 68.7500 (67.0484)  Acc@5: 93.7500 (93.4228)  time: 0.3434  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [ 200/1142]  eta: 0:05:27  Lr: 0.001875  Loss: -0.8032  Acc@1: 68.7500 (67.0709)  Acc@5: 93.7500 (93.5012)  time: 0.3454  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [ 210/1142]  eta: 0:05:23  Lr: 0.001875  Loss: 0.2869  Acc@1: 68.7500 (66.7950)  Acc@5: 93.7500 (93.4834)  time: 0.3462  data: 0.0008  max mem: 2502
Train: Epoch[2/5]  [ 220/1142]  eta: 0:05:20  Lr: 0.001875  Loss: -0.2396  Acc@1: 62.5000 (66.5441)  Acc@5: 93.7500 (93.3541)  time: 0.3468  data: 0.0015  max mem: 2502
Train: Epoch[2/5]  [ 230/1142]  eta: 0:05:16  Lr: 0.001875  Loss: -0.6075  Acc@1: 62.5000 (66.5584)  Acc@5: 93.7500 (93.3983)  time: 0.3475  data: 0.0013  max mem: 2502
Train: Epoch[2/5]  [ 240/1142]  eta: 0:05:13  Lr: 0.001875  Loss: -0.5786  Acc@1: 68.7500 (66.5716)  Acc@5: 93.7500 (93.4388)  time: 0.3473  data: 0.0007  max mem: 2502
Train: Epoch[2/5]  [ 250/1142]  eta: 0:05:09  Lr: 0.001875  Loss: -0.5830  Acc@1: 68.7500 (66.4841)  Acc@5: 93.7500 (93.5010)  time: 0.3479  data: 0.0007  max mem: 2502
Train: Epoch[2/5]  [ 260/1142]  eta: 0:05:06  Lr: 0.001875  Loss: -0.3799  Acc@1: 62.5000 (66.4033)  Acc@5: 93.7500 (93.5345)  time: 0.3474  data: 0.0011  max mem: 2502
Train: Epoch[2/5]  [ 270/1142]  eta: 0:05:02  Lr: 0.001875  Loss: -0.2576  Acc@1: 62.5000 (66.4207)  Acc@5: 93.7500 (93.6808)  time: 0.3472  data: 0.0012  max mem: 2502
Train: Epoch[2/5]  [ 280/1142]  eta: 0:04:59  Lr: 0.001875  Loss: -0.0272  Acc@1: 62.5000 (66.3701)  Acc@5: 93.7500 (93.6833)  time: 0.3466  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [ 290/1142]  eta: 0:04:56  Lr: 0.001875  Loss: -0.9896  Acc@1: 62.5000 (66.4948)  Acc@5: 93.7500 (93.7070)  time: 0.3474  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [ 300/1142]  eta: 0:04:52  Lr: 0.001875  Loss: -0.8298  Acc@1: 62.5000 (66.4244)  Acc@5: 93.7500 (93.7292)  time: 0.3485  data: 0.0009  max mem: 2502
Train: Epoch[2/5]  [ 310/1142]  eta: 0:04:49  Lr: 0.001875  Loss: -0.4487  Acc@1: 62.5000 (66.3384)  Acc@5: 93.7500 (93.6696)  time: 0.3475  data: 0.0010  max mem: 2502
Train: Epoch[2/5]  [ 320/1142]  eta: 0:04:45  Lr: 0.001875  Loss: -0.5255  Acc@1: 62.5000 (66.1994)  Acc@5: 93.7500 (93.6137)  time: 0.3473  data: 0.0012  max mem: 2502
Train: Epoch[2/5]  [ 330/1142]  eta: 0:04:42  Lr: 0.001875  Loss: -0.4225  Acc@1: 62.5000 (66.1820)  Acc@5: 93.7500 (93.6178)  time: 0.3466  data: 0.0009  max mem: 2502
Train: Epoch[2/5]  [ 340/1142]  eta: 0:04:38  Lr: 0.001875  Loss: -0.2275  Acc@1: 62.5000 (66.0557)  Acc@5: 93.7500 (93.5117)  time: 0.3465  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [ 350/1142]  eta: 0:04:35  Lr: 0.001875  Loss: -0.0093  Acc@1: 62.5000 (65.9900)  Acc@5: 93.7500 (93.4295)  time: 0.3457  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [ 360/1142]  eta: 0:04:31  Lr: 0.001875  Loss: -0.3283  Acc@1: 62.5000 (65.9453)  Acc@5: 93.7500 (93.4730)  time: 0.3432  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [ 370/1142]  eta: 0:04:27  Lr: 0.001875  Loss: -0.1514  Acc@1: 62.5000 (65.9535)  Acc@5: 93.7500 (93.4299)  time: 0.3427  data: 0.0002  max mem: 2502
Train: Epoch[2/5]  [ 380/1142]  eta: 0:04:24  Lr: 0.001875  Loss: -0.6301  Acc@1: 68.7500 (65.8629)  Acc@5: 93.7500 (93.4055)  time: 0.3459  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [ 390/1142]  eta: 0:04:21  Lr: 0.001875  Loss: -0.3078  Acc@1: 68.7500 (65.9687)  Acc@5: 93.7500 (93.4783)  time: 0.3482  data: 0.0009  max mem: 2502
Train: Epoch[2/5]  [ 400/1142]  eta: 0:04:17  Lr: 0.001875  Loss: -0.6332  Acc@1: 68.7500 (65.9289)  Acc@5: 93.7500 (93.3915)  time: 0.3475  data: 0.0010  max mem: 2502
Train: Epoch[2/5]  [ 410/1142]  eta: 0:04:14  Lr: 0.001875  Loss: 0.2249  Acc@1: 56.2500 (65.6022)  Acc@5: 93.7500 (93.3850)  time: 0.3479  data: 0.0010  max mem: 2502
Train: Epoch[2/5]  [ 420/1142]  eta: 0:04:10  Lr: 0.001875  Loss: -0.3167  Acc@1: 56.2500 (65.4543)  Acc@5: 93.7500 (93.3937)  time: 0.3481  data: 0.0013  max mem: 2502
Train: Epoch[2/5]  [ 430/1142]  eta: 0:04:07  Lr: 0.001875  Loss: -0.4460  Acc@1: 62.5000 (65.5162)  Acc@5: 93.7500 (93.4165)  time: 0.3477  data: 0.0010  max mem: 2502
Train: Epoch[2/5]  [ 440/1142]  eta: 0:04:03  Lr: 0.001875  Loss: -0.5434  Acc@1: 68.7500 (65.5896)  Acc@5: 93.7500 (93.4382)  time: 0.3469  data: 0.0008  max mem: 2502
Train: Epoch[2/5]  [ 450/1142]  eta: 0:04:00  Lr: 0.001875  Loss: -0.5699  Acc@1: 68.7500 (65.5488)  Acc@5: 93.7500 (93.3897)  time: 0.3460  data: 0.0007  max mem: 2502
Train: Epoch[2/5]  [ 460/1142]  eta: 0:03:56  Lr: 0.001875  Loss: -0.4145  Acc@1: 62.5000 (65.5369)  Acc@5: 93.7500 (93.3975)  time: 0.3454  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [ 470/1142]  eta: 0:03:53  Lr: 0.001875  Loss: -0.9647  Acc@1: 62.5000 (65.5520)  Acc@5: 93.7500 (93.4183)  time: 0.3466  data: 0.0009  max mem: 2502
Train: Epoch[2/5]  [ 480/1142]  eta: 0:03:49  Lr: 0.001875  Loss: -0.5201  Acc@1: 68.7500 (65.6445)  Acc@5: 100.0000 (93.4901)  time: 0.3499  data: 0.0009  max mem: 2502
Train: Epoch[2/5]  [ 490/1142]  eta: 0:03:46  Lr: 0.001875  Loss: -0.7011  Acc@1: 75.0000 (65.7968)  Acc@5: 100.0000 (93.4954)  time: 0.3485  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [ 500/1142]  eta: 0:03:42  Lr: 0.001875  Loss: -0.8258  Acc@1: 75.0000 (65.8184)  Acc@5: 93.7500 (93.5379)  time: 0.3461  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [ 510/1142]  eta: 0:03:39  Lr: 0.001875  Loss: -0.4652  Acc@1: 62.5000 (65.7901)  Acc@5: 93.7500 (93.4932)  time: 0.3463  data: 0.0009  max mem: 2502
Train: Epoch[2/5]  [ 520/1142]  eta: 0:03:35  Lr: 0.001875  Loss: -0.4967  Acc@1: 62.5000 (65.8469)  Acc@5: 93.7500 (93.5461)  time: 0.3440  data: 0.0009  max mem: 2502
Train: Epoch[2/5]  [ 530/1142]  eta: 0:03:32  Lr: 0.001875  Loss: -0.1344  Acc@1: 68.7500 (65.8310)  Acc@5: 93.7500 (93.5970)  time: 0.3436  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [ 540/1142]  eta: 0:03:28  Lr: 0.001875  Loss: -0.2650  Acc@1: 62.5000 (65.8503)  Acc@5: 93.7500 (93.5421)  time: 0.3458  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [ 550/1142]  eta: 0:03:25  Lr: 0.001875  Loss: -0.7292  Acc@1: 62.5000 (65.8575)  Acc@5: 93.7500 (93.5685)  time: 0.3474  data: 0.0013  max mem: 2502
Train: Epoch[2/5]  [ 560/1142]  eta: 0:03:21  Lr: 0.001875  Loss: -0.3581  Acc@1: 62.5000 (65.8534)  Acc@5: 93.7500 (93.5160)  time: 0.3478  data: 0.0014  max mem: 2502
Train: Epoch[2/5]  [ 570/1142]  eta: 0:03:18  Lr: 0.001875  Loss: -0.2816  Acc@1: 68.7500 (65.9370)  Acc@5: 93.7500 (93.5639)  time: 0.3468  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [ 580/1142]  eta: 0:03:15  Lr: 0.001875  Loss: -0.5194  Acc@1: 68.7500 (65.9101)  Acc@5: 93.7500 (93.5026)  time: 0.3478  data: 0.0008  max mem: 2502
Train: Epoch[2/5]  [ 590/1142]  eta: 0:03:11  Lr: 0.001875  Loss: -0.5542  Acc@1: 68.7500 (65.9687)  Acc@5: 93.7500 (93.5385)  time: 0.3486  data: 0.0008  max mem: 2502
Train: Epoch[2/5]  [ 600/1142]  eta: 0:03:08  Lr: 0.001875  Loss: -0.4054  Acc@1: 62.5000 (65.9214)  Acc@5: 93.7500 (93.5316)  time: 0.3479  data: 0.0007  max mem: 2502
Train: Epoch[2/5]  [ 610/1142]  eta: 0:03:04  Lr: 0.001875  Loss: -0.2943  Acc@1: 62.5000 (65.8449)  Acc@5: 93.7500 (93.5147)  time: 0.3474  data: 0.0009  max mem: 2502
Train: Epoch[2/5]  [ 620/1142]  eta: 0:03:01  Lr: 0.001875  Loss: -0.4622  Acc@1: 62.5000 (65.7810)  Acc@5: 93.7500 (93.5286)  time: 0.3471  data: 0.0008  max mem: 2502
Train: Epoch[2/5]  [ 630/1142]  eta: 0:02:57  Lr: 0.001875  Loss: -0.5685  Acc@1: 62.5000 (65.7488)  Acc@5: 93.7500 (93.5321)  time: 0.3487  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [ 640/1142]  eta: 0:02:54  Lr: 0.001875  Loss: -0.7191  Acc@1: 62.5000 (65.7469)  Acc@5: 93.7500 (93.5452)  time: 0.3478  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [ 650/1142]  eta: 0:02:50  Lr: 0.001875  Loss: -0.2118  Acc@1: 62.5000 (65.7258)  Acc@5: 93.7500 (93.5772)  time: 0.3471  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [ 660/1142]  eta: 0:02:47  Lr: 0.001875  Loss: -0.2627  Acc@1: 62.5000 (65.7243)  Acc@5: 93.7500 (93.5231)  time: 0.3466  data: 0.0010  max mem: 2502
Train: Epoch[2/5]  [ 670/1142]  eta: 0:02:43  Lr: 0.001875  Loss: -0.4081  Acc@1: 62.5000 (65.6762)  Acc@5: 93.7500 (93.5078)  time: 0.3442  data: 0.0010  max mem: 2502
Train: Epoch[2/5]  [ 680/1142]  eta: 0:02:40  Lr: 0.001875  Loss: -0.3275  Acc@1: 62.5000 (65.6571)  Acc@5: 93.7500 (93.4838)  time: 0.3448  data: 0.0012  max mem: 2502
Train: Epoch[2/5]  [ 690/1142]  eta: 0:02:36  Lr: 0.001875  Loss: -0.4692  Acc@1: 62.5000 (65.6295)  Acc@5: 93.7500 (93.4967)  time: 0.3475  data: 0.0022  max mem: 2502
Train: Epoch[2/5]  [ 700/1142]  eta: 0:02:33  Lr: 0.001875  Loss: -0.7649  Acc@1: 68.7500 (65.6651)  Acc@5: 93.7500 (93.5182)  time: 0.3483  data: 0.0014  max mem: 2502
Train: Epoch[2/5]  [ 710/1142]  eta: 0:02:29  Lr: 0.001875  Loss: -0.2534  Acc@1: 62.5000 (65.6382)  Acc@5: 93.7500 (93.4863)  time: 0.3482  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [ 720/1142]  eta: 0:02:26  Lr: 0.001875  Loss: -0.6217  Acc@1: 62.5000 (65.6727)  Acc@5: 93.7500 (93.4986)  time: 0.3488  data: 0.0013  max mem: 2502
Train: Epoch[2/5]  [ 730/1142]  eta: 0:02:23  Lr: 0.001875  Loss: -0.5589  Acc@1: 68.7500 (65.6806)  Acc@5: 93.7500 (93.5277)  time: 0.3482  data: 0.0016  max mem: 2502
Train: Epoch[2/5]  [ 740/1142]  eta: 0:02:19  Lr: 0.001875  Loss: -0.1681  Acc@1: 68.7500 (65.7389)  Acc@5: 93.7500 (93.5476)  time: 0.3494  data: 0.0010  max mem: 2502
Train: Epoch[2/5]  [ 750/1142]  eta: 0:02:16  Lr: 0.001875  Loss: -0.6025  Acc@1: 62.5000 (65.7124)  Acc@5: 93.7500 (93.5503)  time: 0.3489  data: 0.0009  max mem: 2502
Train: Epoch[2/5]  [ 760/1142]  eta: 0:02:12  Lr: 0.001875  Loss: -0.6097  Acc@1: 62.5000 (65.7523)  Acc@5: 93.7500 (93.5611)  time: 0.3470  data: 0.0012  max mem: 2502
Train: Epoch[2/5]  [ 770/1142]  eta: 0:02:09  Lr: 0.001875  Loss: -0.4128  Acc@1: 62.5000 (65.7831)  Acc@5: 93.7500 (93.5311)  time: 0.3489  data: 0.0026  max mem: 2502
Train: Epoch[2/5]  [ 780/1142]  eta: 0:02:05  Lr: 0.001875  Loss: -0.2034  Acc@1: 62.5000 (65.7570)  Acc@5: 93.7500 (93.5019)  time: 0.3489  data: 0.0021  max mem: 2502
Train: Epoch[2/5]  [ 790/1142]  eta: 0:02:02  Lr: 0.001875  Loss: 0.0978  Acc@1: 62.5000 (65.6764)  Acc@5: 93.7500 (93.4576)  time: 0.3487  data: 0.0009  max mem: 2502
Train: Epoch[2/5]  [ 800/1142]  eta: 0:01:58  Lr: 0.001875  Loss: -0.6726  Acc@1: 62.5000 (65.6835)  Acc@5: 87.5000 (93.4379)  time: 0.3488  data: 0.0011  max mem: 2502
Train: Epoch[2/5]  [ 810/1142]  eta: 0:01:55  Lr: 0.001875  Loss: -0.0276  Acc@1: 62.5000 (65.6134)  Acc@5: 93.7500 (93.4263)  time: 0.3466  data: 0.0007  max mem: 2502
Train: Epoch[2/5]  [ 820/1142]  eta: 0:01:51  Lr: 0.001875  Loss: 0.0648  Acc@1: 62.5000 (65.6364)  Acc@5: 93.7500 (93.4607)  time: 0.3444  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [ 830/1142]  eta: 0:01:48  Lr: 0.001875  Loss: -0.1394  Acc@1: 68.7500 (65.6513)  Acc@5: 93.7500 (93.4567)  time: 0.3428  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [ 840/1142]  eta: 0:01:44  Lr: 0.001875  Loss: -0.3740  Acc@1: 62.5000 (65.6510)  Acc@5: 93.7500 (93.4676)  time: 0.3435  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [ 850/1142]  eta: 0:01:41  Lr: 0.001875  Loss: -0.5772  Acc@1: 62.5000 (65.7168)  Acc@5: 93.7500 (93.4783)  time: 0.3459  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [ 860/1142]  eta: 0:01:37  Lr: 0.001875  Loss: -0.4826  Acc@1: 68.7500 (65.7303)  Acc@5: 93.7500 (93.4814)  time: 0.3471  data: 0.0008  max mem: 2502
Train: Epoch[2/5]  [ 870/1142]  eta: 0:01:34  Lr: 0.001875  Loss: -0.4890  Acc@1: 68.7500 (65.7219)  Acc@5: 93.7500 (93.4917)  time: 0.3477  data: 0.0015  max mem: 2502
Train: Epoch[2/5]  [ 880/1142]  eta: 0:01:30  Lr: 0.001875  Loss: -0.5836  Acc@1: 62.5000 (65.7137)  Acc@5: 93.7500 (93.4875)  time: 0.3493  data: 0.0026  max mem: 2502
Train: Epoch[2/5]  [ 890/1142]  eta: 0:01:27  Lr: 0.001875  Loss: -0.1105  Acc@1: 62.5000 (65.6706)  Acc@5: 93.7500 (93.4764)  time: 0.3489  data: 0.0019  max mem: 2502
Train: Epoch[2/5]  [ 900/1142]  eta: 0:01:24  Lr: 0.001875  Loss: -0.0900  Acc@1: 62.5000 (65.6909)  Acc@5: 93.7500 (93.4448)  time: 0.3479  data: 0.0009  max mem: 2502
Train: Epoch[2/5]  [ 910/1142]  eta: 0:01:20  Lr: 0.001875  Loss: -0.5320  Acc@1: 68.7500 (65.7176)  Acc@5: 93.7500 (93.4550)  time: 0.3478  data: 0.0012  max mem: 2502
Train: Epoch[2/5]  [ 920/1142]  eta: 0:01:17  Lr: 0.001875  Loss: -0.4061  Acc@1: 68.7500 (65.7641)  Acc@5: 93.7500 (93.4650)  time: 0.3469  data: 0.0011  max mem: 2502
Train: Epoch[2/5]  [ 930/1142]  eta: 0:01:13  Lr: 0.001875  Loss: -0.6277  Acc@1: 68.7500 (65.7693)  Acc@5: 93.7500 (93.4211)  time: 0.3477  data: 0.0015  max mem: 2502
Train: Epoch[2/5]  [ 940/1142]  eta: 0:01:10  Lr: 0.001875  Loss: -0.5807  Acc@1: 68.7500 (65.7744)  Acc@5: 93.7500 (93.4445)  time: 0.3485  data: 0.0014  max mem: 2502
Train: Epoch[2/5]  [ 950/1142]  eta: 0:01:06  Lr: 0.001875  Loss: -0.4018  Acc@1: 68.7500 (65.7992)  Acc@5: 93.7500 (93.4674)  time: 0.3479  data: 0.0010  max mem: 2502
Train: Epoch[2/5]  [ 960/1142]  eta: 0:01:03  Lr: 0.001875  Loss: -0.5791  Acc@1: 62.5000 (65.7713)  Acc@5: 93.7500 (93.4573)  time: 0.3462  data: 0.0008  max mem: 2502
Train: Epoch[2/5]  [ 970/1142]  eta: 0:00:59  Lr: 0.001875  Loss: -0.4810  Acc@1: 68.7500 (65.8213)  Acc@5: 93.7500 (93.4539)  time: 0.3459  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [ 980/1142]  eta: 0:00:56  Lr: 0.001875  Loss: -0.3612  Acc@1: 68.7500 (65.8767)  Acc@5: 93.7500 (93.4760)  time: 0.3454  data: 0.0010  max mem: 2502
Train: Epoch[2/5]  [ 990/1142]  eta: 0:00:52  Lr: 0.001875  Loss: 0.1556  Acc@1: 62.5000 (65.8489)  Acc@5: 93.7500 (93.4662)  time: 0.3433  data: 0.0010  max mem: 2502
Train: Epoch[2/5]  [1000/1142]  eta: 0:00:49  Lr: 0.001875  Loss: -0.4132  Acc@1: 56.2500 (65.8092)  Acc@5: 93.7500 (93.4690)  time: 0.3441  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [1010/1142]  eta: 0:00:45  Lr: 0.001875  Loss: -0.3237  Acc@1: 62.5000 (65.7765)  Acc@5: 93.7500 (93.4594)  time: 0.3472  data: 0.0009  max mem: 2502
Train: Epoch[2/5]  [1020/1142]  eta: 0:00:42  Lr: 0.001875  Loss: -0.6770  Acc@1: 68.7500 (65.8056)  Acc@5: 93.7500 (93.4745)  time: 0.3477  data: 0.0008  max mem: 2502
Train: Epoch[2/5]  [1030/1142]  eta: 0:00:38  Lr: 0.001875  Loss: -0.3660  Acc@1: 68.7500 (65.8523)  Acc@5: 93.7500 (93.4711)  time: 0.3467  data: 0.0008  max mem: 2502
Train: Epoch[2/5]  [1040/1142]  eta: 0:00:35  Lr: 0.001875  Loss: 0.0550  Acc@1: 68.7500 (65.9102)  Acc@5: 93.7500 (93.4738)  time: 0.3474  data: 0.0011  max mem: 2502
Train: Epoch[2/5]  [1050/1142]  eta: 0:00:31  Lr: 0.001875  Loss: -0.2024  Acc@1: 75.0000 (65.9550)  Acc@5: 93.7500 (93.4883)  time: 0.3476  data: 0.0010  max mem: 2502
Train: Epoch[2/5]  [1060/1142]  eta: 0:00:28  Lr: 0.001875  Loss: -0.0378  Acc@1: 62.5000 (65.9166)  Acc@5: 100.0000 (93.5262)  time: 0.3470  data: 0.0007  max mem: 2502
Train: Epoch[2/5]  [1070/1142]  eta: 0:00:24  Lr: 0.001875  Loss: -0.2430  Acc@1: 62.5000 (65.8905)  Acc@5: 93.7500 (93.5166)  time: 0.3461  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [1080/1142]  eta: 0:00:21  Lr: 0.001875  Loss: -0.9029  Acc@1: 62.5000 (65.8823)  Acc@5: 93.7500 (93.5245)  time: 0.3467  data: 0.0007  max mem: 2502
Train: Epoch[2/5]  [1090/1142]  eta: 0:00:18  Lr: 0.001875  Loss: -0.3251  Acc@1: 68.7500 (65.9143)  Acc@5: 93.7500 (93.5037)  time: 0.3471  data: 0.0011  max mem: 2502
Train: Epoch[2/5]  [1100/1142]  eta: 0:00:14  Lr: 0.001875  Loss: -0.6270  Acc@1: 68.7500 (65.9344)  Acc@5: 93.7500 (93.5173)  time: 0.3472  data: 0.0011  max mem: 2502
Train: Epoch[2/5]  [1110/1142]  eta: 0:00:11  Lr: 0.001875  Loss: 0.1464  Acc@1: 68.7500 (65.9203)  Acc@5: 93.7500 (93.4968)  time: 0.3478  data: 0.0008  max mem: 2502
Train: Epoch[2/5]  [1120/1142]  eta: 0:00:07  Lr: 0.001875  Loss: -0.5989  Acc@1: 68.7500 (65.9010)  Acc@5: 93.7500 (93.4768)  time: 0.3486  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [1130/1142]  eta: 0:00:04  Lr: 0.001875  Loss: -0.7124  Acc@1: 68.7500 (65.8820)  Acc@5: 93.7500 (93.4792)  time: 0.3470  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [1140/1142]  eta: 0:00:00  Lr: 0.001875  Loss: -0.9025  Acc@1: 68.7500 (65.8907)  Acc@5: 93.7500 (93.4926)  time: 0.3434  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [1141/1142]  eta: 0:00:00  Lr: 0.001875  Loss: -1.0065  Acc@1: 68.7500 (65.9075)  Acc@5: 93.7500 (93.4958)  time: 0.3359  data: 0.0003  max mem: 2502
Train: Epoch[2/5] Total time: 0:06:36 (0.3471 s / it)
{0: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 1: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 2: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 3: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 4: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 5: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 6: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 7: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 8: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 9: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 10: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 11: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 12: {0: 0, 1: 0, 2: 0, 3: 36530, 4: 0}, 13: {0: 0, 1: 0, 2: 0, 3: 36530, 4: 0}, 14: {0: 0, 1: 0, 2: 0, 3: 36530, 4: 0}, 15: {0: 0, 1: 0, 2: 0, 3: 36530, 4: 0}, 16: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 17: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 18: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 19: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}}
Averaged stats: Lr: 0.001875  Loss: -1.0065  Acc@1: 68.7500 (65.9075)  Acc@5: 93.7500 (93.4958)
Train: Epoch[3/5]  [   0/1142]  eta: 0:11:08  Lr: 0.001875  Loss: -0.6024  Acc@1: 68.7500 (68.7500)  Acc@5: 93.7500 (93.7500)  time: 0.5858  data: 0.2439  max mem: 2502
Train: Epoch[3/5]  [  10/1142]  eta: 0:06:52  Lr: 0.001875  Loss: -0.6039  Acc@1: 68.7500 (73.8636)  Acc@5: 100.0000 (96.0227)  time: 0.3646  data: 0.0224  max mem: 2502
Train: Epoch[3/5]  [  20/1142]  eta: 0:06:38  Lr: 0.001875  Loss: -1.0752  Acc@1: 68.7500 (70.8333)  Acc@5: 100.0000 (95.5357)  time: 0.3439  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [  30/1142]  eta: 0:06:33  Lr: 0.001875  Loss: -0.6227  Acc@1: 68.7500 (69.3548)  Acc@5: 93.7500 (94.7581)  time: 0.3480  data: 0.0016  max mem: 2502
Train: Epoch[3/5]  [  40/1142]  eta: 0:06:28  Lr: 0.001875  Loss: -0.4205  Acc@1: 68.7500 (69.6646)  Acc@5: 93.7500 (95.1220)  time: 0.3498  data: 0.0018  max mem: 2502
Train: Epoch[3/5]  [  50/1142]  eta: 0:06:23  Lr: 0.001875  Loss: -0.8238  Acc@1: 68.7500 (69.7304)  Acc@5: 100.0000 (95.0980)  time: 0.3480  data: 0.0008  max mem: 2502
Train: Epoch[3/5]  [  60/1142]  eta: 0:06:19  Lr: 0.001875  Loss: -0.5529  Acc@1: 62.5000 (68.2377)  Acc@5: 93.7500 (94.9795)  time: 0.3476  data: 0.0011  max mem: 2502
Train: Epoch[3/5]  [  70/1142]  eta: 0:06:16  Lr: 0.001875  Loss: -0.2700  Acc@1: 62.5000 (67.3415)  Acc@5: 93.7500 (94.5423)  time: 0.3487  data: 0.0014  max mem: 2502
Train: Epoch[3/5]  [  80/1142]  eta: 0:06:12  Lr: 0.001875  Loss: -0.3335  Acc@1: 62.5000 (67.3611)  Acc@5: 93.7500 (94.2130)  time: 0.3488  data: 0.0011  max mem: 2502
Train: Epoch[3/5]  [  90/1142]  eta: 0:06:08  Lr: 0.001875  Loss: -0.6816  Acc@1: 68.7500 (67.2390)  Acc@5: 93.7500 (94.0247)  time: 0.3482  data: 0.0011  max mem: 2502
Train: Epoch[3/5]  [ 100/1142]  eta: 0:06:04  Lr: 0.001875  Loss: 0.1945  Acc@1: 68.7500 (67.0792)  Acc@5: 93.7500 (93.8738)  time: 0.3473  data: 0.0011  max mem: 2502
Train: Epoch[3/5]  [ 110/1142]  eta: 0:06:01  Lr: 0.001875  Loss: 0.0972  Acc@1: 68.7500 (67.0045)  Acc@5: 93.7500 (93.8626)  time: 0.3488  data: 0.0008  max mem: 2502
Train: Epoch[3/5]  [ 120/1142]  eta: 0:05:57  Lr: 0.001875  Loss: -0.7074  Acc@1: 68.7500 (67.4587)  Acc@5: 93.7500 (93.9050)  time: 0.3485  data: 0.0007  max mem: 2502
Train: Epoch[3/5]  [ 130/1142]  eta: 0:05:53  Lr: 0.001875  Loss: -0.5893  Acc@1: 68.7500 (67.3664)  Acc@5: 93.7500 (93.9408)  time: 0.3472  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [ 140/1142]  eta: 0:05:49  Lr: 0.001875  Loss: -0.2953  Acc@1: 62.5000 (67.3316)  Acc@5: 100.0000 (94.1046)  time: 0.3460  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [ 150/1142]  eta: 0:05:45  Lr: 0.001875  Loss: -0.6915  Acc@1: 62.5000 (66.8874)  Acc@5: 93.7500 (93.9570)  time: 0.3436  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [ 160/1142]  eta: 0:05:42  Lr: 0.001875  Loss: -0.9224  Acc@1: 62.5000 (67.0031)  Acc@5: 93.7500 (93.9441)  time: 0.3435  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [ 170/1142]  eta: 0:05:38  Lr: 0.001875  Loss: -0.3324  Acc@1: 75.0000 (67.2880)  Acc@5: 100.0000 (94.2251)  time: 0.3447  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [ 180/1142]  eta: 0:05:35  Lr: 0.001875  Loss: -0.2802  Acc@1: 62.5000 (66.9890)  Acc@5: 93.7500 (93.9917)  time: 0.3474  data: 0.0007  max mem: 2502
Train: Epoch[3/5]  [ 190/1142]  eta: 0:05:31  Lr: 0.001875  Loss: -0.0328  Acc@1: 62.5000 (67.0812)  Acc@5: 87.5000 (94.0118)  time: 0.3484  data: 0.0009  max mem: 2502
Train: Epoch[3/5]  [ 200/1142]  eta: 0:05:28  Lr: 0.001875  Loss: -0.4848  Acc@1: 62.5000 (67.0709)  Acc@5: 93.7500 (93.9366)  time: 0.3481  data: 0.0009  max mem: 2502
Train: Epoch[3/5]  [ 210/1142]  eta: 0:05:24  Lr: 0.001875  Loss: -0.1752  Acc@1: 62.5000 (67.0616)  Acc@5: 93.7500 (93.9573)  time: 0.3475  data: 0.0007  max mem: 2502
Train: Epoch[3/5]  [ 220/1142]  eta: 0:05:21  Lr: 0.001875  Loss: -0.8593  Acc@1: 62.5000 (66.9118)  Acc@5: 93.7500 (93.8631)  time: 0.3483  data: 0.0010  max mem: 2502
Train: Epoch[3/5]  [ 230/1142]  eta: 0:05:17  Lr: 0.001875  Loss: -0.5505  Acc@1: 62.5000 (66.8831)  Acc@5: 93.7500 (93.9123)  time: 0.3500  data: 0.0014  max mem: 2502
Train: Epoch[3/5]  [ 240/1142]  eta: 0:05:14  Lr: 0.001875  Loss: 0.6545  Acc@1: 68.7500 (66.9865)  Acc@5: 93.7500 (93.9056)  time: 0.3495  data: 0.0012  max mem: 2502
Train: Epoch[3/5]  [ 250/1142]  eta: 0:05:10  Lr: 0.001875  Loss: -0.6648  Acc@1: 68.7500 (67.0817)  Acc@5: 93.7500 (93.9492)  time: 0.3481  data: 0.0006  max mem: 2502
Train: Epoch[3/5]  [ 260/1142]  eta: 0:05:07  Lr: 0.001875  Loss: -0.5129  Acc@1: 68.7500 (67.0738)  Acc@5: 93.7500 (93.9416)  time: 0.3479  data: 0.0008  max mem: 2502
Train: Epoch[3/5]  [ 270/1142]  eta: 0:05:03  Lr: 0.001875  Loss: -0.5594  Acc@1: 68.7500 (67.1125)  Acc@5: 93.7500 (93.9114)  time: 0.3480  data: 0.0012  max mem: 2502
Train: Epoch[3/5]  [ 280/1142]  eta: 0:05:00  Lr: 0.001875  Loss: -0.1528  Acc@1: 68.7500 (67.2375)  Acc@5: 93.7500 (93.9279)  time: 0.3469  data: 0.0007  max mem: 2502
Train: Epoch[3/5]  [ 290/1142]  eta: 0:04:56  Lr: 0.001875  Loss: -0.5676  Acc@1: 68.7500 (67.2036)  Acc@5: 93.7500 (93.8789)  time: 0.3472  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [ 300/1142]  eta: 0:04:53  Lr: 0.001875  Loss: -0.3820  Acc@1: 62.5000 (66.9228)  Acc@5: 93.7500 (93.9161)  time: 0.3476  data: 0.0006  max mem: 2502
Train: Epoch[3/5]  [ 310/1142]  eta: 0:04:49  Lr: 0.001875  Loss: 0.6298  Acc@1: 56.2500 (66.8207)  Acc@5: 93.7500 (93.8706)  time: 0.3461  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [ 320/1142]  eta: 0:04:46  Lr: 0.001875  Loss: -0.9337  Acc@1: 62.5000 (66.8224)  Acc@5: 93.7500 (93.9058)  time: 0.3441  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [ 330/1142]  eta: 0:04:42  Lr: 0.001875  Loss: -0.5870  Acc@1: 75.0000 (66.9373)  Acc@5: 93.7500 (93.9011)  time: 0.3432  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [ 340/1142]  eta: 0:04:38  Lr: 0.001875  Loss: -0.4403  Acc@1: 75.0000 (67.0271)  Acc@5: 93.7500 (93.9883)  time: 0.3452  data: 0.0007  max mem: 2502
Train: Epoch[3/5]  [ 350/1142]  eta: 0:04:35  Lr: 0.001875  Loss: 0.0152  Acc@1: 68.7500 (67.0050)  Acc@5: 93.7500 (93.9993)  time: 0.3469  data: 0.0009  max mem: 2502
Train: Epoch[3/5]  [ 360/1142]  eta: 0:04:31  Lr: 0.001875  Loss: -0.4727  Acc@1: 68.7500 (67.0880)  Acc@5: 93.7500 (94.0443)  time: 0.3466  data: 0.0008  max mem: 2502
Train: Epoch[3/5]  [ 370/1142]  eta: 0:04:28  Lr: 0.001875  Loss: -0.8246  Acc@1: 68.7500 (67.3181)  Acc@5: 100.0000 (94.1543)  time: 0.3468  data: 0.0010  max mem: 2502
Train: Epoch[3/5]  [ 380/1142]  eta: 0:04:24  Lr: 0.001875  Loss: -0.2804  Acc@1: 68.7500 (67.4213)  Acc@5: 100.0000 (94.1929)  time: 0.3481  data: 0.0010  max mem: 2502
Train: Epoch[3/5]  [ 390/1142]  eta: 0:04:21  Lr: 0.001875  Loss: -0.6182  Acc@1: 62.5000 (67.3753)  Acc@5: 93.7500 (94.1976)  time: 0.3489  data: 0.0008  max mem: 2502
Train: Epoch[3/5]  [ 400/1142]  eta: 0:04:18  Lr: 0.001875  Loss: 0.1981  Acc@1: 62.5000 (67.1446)  Acc@5: 93.7500 (94.2488)  time: 0.3480  data: 0.0007  max mem: 2502
Train: Epoch[3/5]  [ 410/1142]  eta: 0:04:14  Lr: 0.001875  Loss: -0.0333  Acc@1: 62.5000 (67.0164)  Acc@5: 93.7500 (94.1606)  time: 0.3467  data: 0.0008  max mem: 2502
Train: Epoch[3/5]  [ 420/1142]  eta: 0:04:11  Lr: 0.001875  Loss: -0.1828  Acc@1: 62.5000 (67.0576)  Acc@5: 93.7500 (94.1360)  time: 0.3466  data: 0.0012  max mem: 2502
Train: Epoch[3/5]  [ 430/1142]  eta: 0:04:07  Lr: 0.001875  Loss: -0.1198  Acc@1: 68.7500 (67.1404)  Acc@5: 93.7500 (94.1850)  time: 0.3465  data: 0.0011  max mem: 2502
Train: Epoch[3/5]  [ 440/1142]  eta: 0:04:04  Lr: 0.001875  Loss: -0.0434  Acc@1: 68.7500 (67.1485)  Acc@5: 100.0000 (94.2177)  time: 0.3466  data: 0.0007  max mem: 2502
Train: Epoch[3/5]  [ 450/1142]  eta: 0:04:00  Lr: 0.001875  Loss: -0.4885  Acc@1: 68.7500 (67.2949)  Acc@5: 93.7500 (94.2073)  time: 0.3462  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [ 460/1142]  eta: 0:03:57  Lr: 0.001875  Loss: -0.4074  Acc@1: 68.7500 (67.3265)  Acc@5: 100.0000 (94.2787)  time: 0.3448  data: 0.0009  max mem: 2502
Train: Epoch[3/5]  [ 470/1142]  eta: 0:03:53  Lr: 0.001875  Loss: -0.9313  Acc@1: 68.7500 (67.5027)  Acc@5: 100.0000 (94.3206)  time: 0.3448  data: 0.0015  max mem: 2502
Train: Epoch[3/5]  [ 480/1142]  eta: 0:03:50  Lr: 0.001875  Loss: -0.6560  Acc@1: 75.0000 (67.6065)  Acc@5: 100.0000 (94.3867)  time: 0.3458  data: 0.0011  max mem: 2502
Train: Epoch[3/5]  [ 490/1142]  eta: 0:03:46  Lr: 0.001875  Loss: 0.1323  Acc@1: 68.7500 (67.4262)  Acc@5: 93.7500 (94.3610)  time: 0.3474  data: 0.0014  max mem: 2502
Train: Epoch[3/5]  [ 500/1142]  eta: 0:03:43  Lr: 0.001875  Loss: 0.1805  Acc@1: 62.5000 (67.3154)  Acc@5: 93.7500 (94.2864)  time: 0.3479  data: 0.0014  max mem: 2502
Train: Epoch[3/5]  [ 510/1142]  eta: 0:03:39  Lr: 0.001875  Loss: -0.7380  Acc@1: 62.5000 (67.2701)  Acc@5: 93.7500 (94.2148)  time: 0.3474  data: 0.0007  max mem: 2502
Train: Epoch[3/5]  [ 520/1142]  eta: 0:03:36  Lr: 0.001875  Loss: -0.4233  Acc@1: 62.5000 (67.2745)  Acc@5: 93.7500 (94.1939)  time: 0.3479  data: 0.0010  max mem: 2502
Train: Epoch[3/5]  [ 530/1142]  eta: 0:03:32  Lr: 0.001875  Loss: -0.1838  Acc@1: 68.7500 (67.3023)  Acc@5: 93.7500 (94.1973)  time: 0.3486  data: 0.0014  max mem: 2502
Train: Epoch[3/5]  [ 540/1142]  eta: 0:03:29  Lr: 0.001875  Loss: 0.0539  Acc@1: 68.7500 (67.3521)  Acc@5: 93.7500 (94.1774)  time: 0.3490  data: 0.0013  max mem: 2502
Train: Epoch[3/5]  [ 550/1142]  eta: 0:03:25  Lr: 0.001875  Loss: -0.8493  Acc@1: 68.7500 (67.3662)  Acc@5: 93.7500 (94.2264)  time: 0.3476  data: 0.0008  max mem: 2502
Train: Epoch[3/5]  [ 560/1142]  eta: 0:03:22  Lr: 0.001875  Loss: -0.4704  Acc@1: 68.7500 (67.3908)  Acc@5: 100.0000 (94.2402)  time: 0.3463  data: 0.0007  max mem: 2502
Train: Epoch[3/5]  [ 570/1142]  eta: 0:03:18  Lr: 0.001875  Loss: -0.2478  Acc@1: 62.5000 (67.3271)  Acc@5: 93.7500 (94.2535)  time: 0.3468  data: 0.0008  max mem: 2502
Train: Epoch[3/5]  [ 580/1142]  eta: 0:03:15  Lr: 0.001875  Loss: -0.6551  Acc@1: 62.5000 (67.2009)  Acc@5: 93.7500 (94.2556)  time: 0.3477  data: 0.0008  max mem: 2502
Train: Epoch[3/5]  [ 590/1142]  eta: 0:03:11  Lr: 0.001875  Loss: -0.5806  Acc@1: 62.5000 (67.2483)  Acc@5: 93.7500 (94.2259)  time: 0.3473  data: 0.0008  max mem: 2502
Train: Epoch[3/5]  [ 600/1142]  eta: 0:03:08  Lr: 0.001875  Loss: -0.4534  Acc@1: 68.7500 (67.2525)  Acc@5: 93.7500 (94.2492)  time: 0.3473  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [ 610/1142]  eta: 0:03:04  Lr: 0.001875  Loss: -0.8698  Acc@1: 75.0000 (67.4202)  Acc@5: 93.7500 (94.2308)  time: 0.3452  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [ 620/1142]  eta: 0:03:01  Lr: 0.001875  Loss: -0.1820  Acc@1: 75.0000 (67.4114)  Acc@5: 93.7500 (94.1928)  time: 0.3428  data: 0.0007  max mem: 2502
Train: Epoch[3/5]  [ 630/1142]  eta: 0:02:57  Lr: 0.001875  Loss: 0.0228  Acc@1: 68.7500 (67.5218)  Acc@5: 93.7500 (94.2155)  time: 0.3426  data: 0.0007  max mem: 2502
Train: Epoch[3/5]  [ 640/1142]  eta: 0:02:54  Lr: 0.001875  Loss: 0.2296  Acc@1: 68.7500 (67.4532)  Acc@5: 93.7500 (94.1498)  time: 0.3453  data: 0.0011  max mem: 2502
Train: Epoch[3/5]  [ 650/1142]  eta: 0:02:50  Lr: 0.001875  Loss: -0.7026  Acc@1: 62.5000 (67.3003)  Acc@5: 93.7500 (94.1532)  time: 0.3472  data: 0.0012  max mem: 2502
Train: Epoch[3/5]  [ 660/1142]  eta: 0:02:47  Lr: 0.001875  Loss: -0.6205  Acc@1: 62.5000 (67.3033)  Acc@5: 93.7500 (94.1660)  time: 0.3458  data: 0.0008  max mem: 2502
Train: Epoch[3/5]  [ 670/1142]  eta: 0:02:43  Lr: 0.001875  Loss: -0.1775  Acc@1: 68.7500 (67.3528)  Acc@5: 93.7500 (94.1785)  time: 0.3472  data: 0.0009  max mem: 2502
Train: Epoch[3/5]  [ 680/1142]  eta: 0:02:40  Lr: 0.001875  Loss: -0.7723  Acc@1: 62.5000 (67.3183)  Acc@5: 93.7500 (94.1355)  time: 0.3504  data: 0.0020  max mem: 2502
Train: Epoch[3/5]  [ 690/1142]  eta: 0:02:37  Lr: 0.001875  Loss: -0.4351  Acc@1: 68.7500 (67.3842)  Acc@5: 93.7500 (94.1480)  time: 0.3522  data: 0.0023  max mem: 2502
Train: Epoch[3/5]  [ 700/1142]  eta: 0:02:33  Lr: 0.001875  Loss: -0.5410  Acc@1: 68.7500 (67.3413)  Acc@5: 93.7500 (94.1690)  time: 0.3495  data: 0.0012  max mem: 2502
Train: Epoch[3/5]  [ 710/1142]  eta: 0:02:30  Lr: 0.001875  Loss: -0.7466  Acc@1: 68.7500 (67.3259)  Acc@5: 93.7500 (94.1544)  time: 0.3473  data: 0.0016  max mem: 2502
Train: Epoch[3/5]  [ 720/1142]  eta: 0:02:26  Lr: 0.001875  Loss: -0.1914  Acc@1: 68.7500 (67.4064)  Acc@5: 93.7500 (94.1921)  time: 0.3477  data: 0.0018  max mem: 2502
Train: Epoch[3/5]  [ 730/1142]  eta: 0:02:23  Lr: 0.001875  Loss: -0.5636  Acc@1: 68.7500 (67.3564)  Acc@5: 93.7500 (94.1518)  time: 0.3479  data: 0.0011  max mem: 2502
Train: Epoch[3/5]  [ 740/1142]  eta: 0:02:19  Lr: 0.001875  Loss: -0.5228  Acc@1: 68.7500 (67.3583)  Acc@5: 93.7500 (94.1464)  time: 0.3474  data: 0.0007  max mem: 2502
Train: Epoch[3/5]  [ 750/1142]  eta: 0:02:16  Lr: 0.001875  Loss: -0.3749  Acc@1: 62.5000 (67.3186)  Acc@5: 93.7500 (94.1245)  time: 0.3458  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [ 760/1142]  eta: 0:02:12  Lr: 0.001875  Loss: 0.0912  Acc@1: 62.5000 (67.2388)  Acc@5: 93.7500 (94.1032)  time: 0.3447  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [ 770/1142]  eta: 0:02:09  Lr: 0.001875  Loss: -0.8030  Acc@1: 62.5000 (67.2179)  Acc@5: 87.5000 (94.0499)  time: 0.3442  data: 0.0011  max mem: 2502
Train: Epoch[3/5]  [ 780/1142]  eta: 0:02:05  Lr: 0.001875  Loss: -0.5829  Acc@1: 68.7500 (67.2135)  Acc@5: 93.7500 (94.0221)  time: 0.3444  data: 0.0015  max mem: 2502
Train: Epoch[3/5]  [ 790/1142]  eta: 0:02:02  Lr: 0.001875  Loss: -0.1963  Acc@1: 62.5000 (67.2013)  Acc@5: 93.7500 (94.0107)  time: 0.3444  data: 0.0010  max mem: 2502
Train: Epoch[3/5]  [ 800/1142]  eta: 0:01:58  Lr: 0.001875  Loss: -0.9611  Acc@1: 68.7500 (67.2987)  Acc@5: 93.7500 (94.0309)  time: 0.3450  data: 0.0006  max mem: 2502
Train: Epoch[3/5]  [ 810/1142]  eta: 0:01:55  Lr: 0.001875  Loss: -0.4869  Acc@1: 68.7500 (67.3012)  Acc@5: 93.7500 (94.0506)  time: 0.3456  data: 0.0006  max mem: 2502
Train: Epoch[3/5]  [ 820/1142]  eta: 0:01:51  Lr: 0.001875  Loss: -0.7486  Acc@1: 68.7500 (67.3340)  Acc@5: 93.7500 (94.0393)  time: 0.3460  data: 0.0009  max mem: 2502
Train: Epoch[3/5]  [ 830/1142]  eta: 0:01:48  Lr: 0.001875  Loss: -0.4419  Acc@1: 68.7500 (67.3436)  Acc@5: 93.7500 (94.0283)  time: 0.3479  data: 0.0017  max mem: 2502
Train: Epoch[3/5]  [ 840/1142]  eta: 0:01:44  Lr: 0.001875  Loss: -0.8613  Acc@1: 62.5000 (67.3380)  Acc@5: 93.7500 (94.0547)  time: 0.3487  data: 0.0017  max mem: 2502
Train: Epoch[3/5]  [ 850/1142]  eta: 0:01:41  Lr: 0.001875  Loss: -0.3481  Acc@1: 68.7500 (67.3325)  Acc@5: 93.7500 (94.0438)  time: 0.3487  data: 0.0009  max mem: 2502
Train: Epoch[3/5]  [ 860/1142]  eta: 0:01:37  Lr: 0.001875  Loss: -0.4821  Acc@1: 68.7500 (67.3272)  Acc@5: 93.7500 (94.0041)  time: 0.3472  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [ 870/1142]  eta: 0:01:34  Lr: 0.001875  Loss: -0.5144  Acc@1: 68.7500 (67.3938)  Acc@5: 93.7500 (94.0227)  time: 0.3453  data: 0.0006  max mem: 2502
Train: Epoch[3/5]  [ 880/1142]  eta: 0:01:30  Lr: 0.001875  Loss: -0.3691  Acc@1: 75.0000 (67.4518)  Acc@5: 93.7500 (94.0338)  time: 0.3468  data: 0.0008  max mem: 2502
Train: Epoch[3/5]  [ 890/1142]  eta: 0:01:27  Lr: 0.001875  Loss: -0.7066  Acc@1: 75.0000 (67.4242)  Acc@5: 93.7500 (94.0166)  time: 0.3486  data: 0.0013  max mem: 2502
Train: Epoch[3/5]  [ 900/1142]  eta: 0:01:24  Lr: 0.001875  Loss: -0.6717  Acc@1: 68.7500 (67.4390)  Acc@5: 93.7500 (94.0413)  time: 0.3496  data: 0.0012  max mem: 2502
Train: Epoch[3/5]  [ 910/1142]  eta: 0:01:20  Lr: 0.001875  Loss: -0.2438  Acc@1: 68.7500 (67.4808)  Acc@5: 93.7500 (94.0656)  time: 0.3481  data: 0.0008  max mem: 2502
Train: Epoch[3/5]  [ 920/1142]  eta: 0:01:17  Lr: 0.001875  Loss: -0.3317  Acc@1: 68.7500 (67.4674)  Acc@5: 93.7500 (94.0622)  time: 0.3485  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [ 930/1142]  eta: 0:01:13  Lr: 0.001875  Loss: -0.2087  Acc@1: 68.7500 (67.5148)  Acc@5: 93.7500 (94.0320)  time: 0.3467  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [ 940/1142]  eta: 0:01:10  Lr: 0.001875  Loss: -0.7140  Acc@1: 68.7500 (67.5677)  Acc@5: 93.7500 (94.0622)  time: 0.3433  data: 0.0009  max mem: 2502
Train: Epoch[3/5]  [ 950/1142]  eta: 0:01:06  Lr: 0.001875  Loss: -0.2328  Acc@1: 68.7500 (67.5670)  Acc@5: 100.0000 (94.0786)  time: 0.3443  data: 0.0009  max mem: 2502
Train: Epoch[3/5]  [ 960/1142]  eta: 0:01:03  Lr: 0.001875  Loss: -0.5017  Acc@1: 68.7500 (67.5403)  Acc@5: 93.7500 (94.0947)  time: 0.3464  data: 0.0009  max mem: 2502
Train: Epoch[3/5]  [ 970/1142]  eta: 0:00:59  Lr: 0.001875  Loss: -0.1808  Acc@1: 68.7500 (67.5463)  Acc@5: 93.7500 (94.0847)  time: 0.3474  data: 0.0013  max mem: 2502
Train: Epoch[3/5]  [ 980/1142]  eta: 0:00:56  Lr: 0.001875  Loss: -0.2412  Acc@1: 68.7500 (67.5968)  Acc@5: 93.7500 (94.1068)  time: 0.3474  data: 0.0014  max mem: 2502
Train: Epoch[3/5]  [ 990/1142]  eta: 0:00:52  Lr: 0.001875  Loss: -0.7536  Acc@1: 68.7500 (67.5391)  Acc@5: 93.7500 (94.1032)  time: 0.3475  data: 0.0011  max mem: 2502
Train: Epoch[3/5]  [1000/1142]  eta: 0:00:49  Lr: 0.001875  Loss: -0.6530  Acc@1: 62.5000 (67.5512)  Acc@5: 93.7500 (94.1059)  time: 0.3477  data: 0.0007  max mem: 2502
Train: Epoch[3/5]  [1010/1142]  eta: 0:00:45  Lr: 0.001875  Loss: -0.0298  Acc@1: 68.7500 (67.5940)  Acc@5: 93.7500 (94.1086)  time: 0.3483  data: 0.0010  max mem: 2502
Train: Epoch[3/5]  [1020/1142]  eta: 0:00:42  Lr: 0.001875  Loss: -0.6135  Acc@1: 62.5000 (67.5563)  Acc@5: 93.7500 (94.1112)  time: 0.3481  data: 0.0011  max mem: 2502
Train: Epoch[3/5]  [1030/1142]  eta: 0:00:38  Lr: 0.001875  Loss: -0.4738  Acc@1: 62.5000 (67.5436)  Acc@5: 93.7500 (94.1077)  time: 0.3478  data: 0.0009  max mem: 2502
Train: Epoch[3/5]  [1040/1142]  eta: 0:00:35  Lr: 0.001875  Loss: -0.9743  Acc@1: 68.7500 (67.5913)  Acc@5: 93.7500 (94.1282)  time: 0.3471  data: 0.0008  max mem: 2502
Train: Epoch[3/5]  [1050/1142]  eta: 0:00:31  Lr: 0.001875  Loss: -0.2146  Acc@1: 68.7500 (67.6142)  Acc@5: 93.7500 (94.1246)  time: 0.3476  data: 0.0008  max mem: 2502
Train: Epoch[3/5]  [1060/1142]  eta: 0:00:28  Lr: 0.001875  Loss: -1.0524  Acc@1: 68.7500 (67.6426)  Acc@5: 93.7500 (94.1388)  time: 0.3468  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [1070/1142]  eta: 0:00:24  Lr: 0.001875  Loss: 0.0965  Acc@1: 62.5000 (67.6646)  Acc@5: 93.7500 (94.1293)  time: 0.3455  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [1080/1142]  eta: 0:00:21  Lr: 0.001875  Loss: -0.2797  Acc@1: 62.5000 (67.7324)  Acc@5: 93.7500 (94.1200)  time: 0.3443  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [1090/1142]  eta: 0:00:18  Lr: 0.001875  Loss: -0.7747  Acc@1: 75.0000 (67.7990)  Acc@5: 93.7500 (94.1166)  time: 0.3428  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [1100/1142]  eta: 0:00:14  Lr: 0.001875  Loss: -0.3308  Acc@1: 75.0000 (67.8417)  Acc@5: 93.7500 (94.1020)  time: 0.3437  data: 0.0009  max mem: 2502
Train: Epoch[3/5]  [1110/1142]  eta: 0:00:11  Lr: 0.001875  Loss: -0.2320  Acc@1: 75.0000 (67.8724)  Acc@5: 93.7500 (94.0875)  time: 0.3453  data: 0.0011  max mem: 2502
Train: Epoch[3/5]  [1120/1142]  eta: 0:00:07  Lr: 0.001875  Loss: -0.6526  Acc@1: 68.7500 (67.8914)  Acc@5: 93.7500 (94.1012)  time: 0.3469  data: 0.0006  max mem: 2502
Train: Epoch[3/5]  [1130/1142]  eta: 0:00:04  Lr: 0.001875  Loss: -0.1806  Acc@1: 68.7500 (67.8990)  Acc@5: 93.7500 (94.0981)  time: 0.3476  data: 0.0009  max mem: 2502
Train: Epoch[3/5]  [1140/1142]  eta: 0:00:00  Lr: 0.001875  Loss: -0.5902  Acc@1: 68.7500 (67.9010)  Acc@5: 93.7500 (94.1170)  time: 0.3474  data: 0.0011  max mem: 2502
Train: Epoch[3/5]  [1141/1142]  eta: 0:00:00  Lr: 0.001875  Loss: -1.3595  Acc@1: 68.7500 (67.9168)  Acc@5: 93.7500 (94.1199)  time: 0.3399  data: 0.0011  max mem: 2502
Train: Epoch[3/5] Total time: 0:06:36 (0.3472 s / it)
{0: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 1: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 2: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 3: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 4: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 5: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 6: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 7: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 8: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 9: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 10: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 11: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 12: {0: 0, 1: 0, 2: 0, 3: 54795, 4: 0}, 13: {0: 0, 1: 0, 2: 0, 3: 54795, 4: 0}, 14: {0: 0, 1: 0, 2: 0, 3: 54795, 4: 0}, 15: {0: 0, 1: 0, 2: 0, 3: 54795, 4: 0}, 16: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 17: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 18: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 19: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}}
Averaged stats: Lr: 0.001875  Loss: -1.3595  Acc@1: 68.7500 (67.9168)  Acc@5: 93.7500 (94.1199)
Train: Epoch[4/5]  [   0/1142]  eta: 0:13:27  Lr: 0.001875  Loss: -0.9025  Acc@1: 87.5000 (87.5000)  Acc@5: 93.7500 (93.7500)  time: 0.7069  data: 0.3492  max mem: 2502
Train: Epoch[4/5]  [  10/1142]  eta: 0:07:11  Lr: 0.001875  Loss: -0.3098  Acc@1: 75.0000 (70.4545)  Acc@5: 93.7500 (94.3182)  time: 0.3814  data: 0.0329  max mem: 2502
Train: Epoch[4/5]  [  20/1142]  eta: 0:06:50  Lr: 0.001875  Loss: -0.5281  Acc@1: 75.0000 (70.8333)  Acc@5: 93.7500 (95.5357)  time: 0.3487  data: 0.0009  max mem: 2502
Train: Epoch[4/5]  [  30/1142]  eta: 0:06:41  Lr: 0.001875  Loss: -0.8629  Acc@1: 68.7500 (69.1532)  Acc@5: 100.0000 (95.5645)  time: 0.3493  data: 0.0016  max mem: 2502
Train: Epoch[4/5]  [  40/1142]  eta: 0:06:33  Lr: 0.001875  Loss: -0.2632  Acc@1: 68.7500 (69.2073)  Acc@5: 93.7500 (95.1220)  time: 0.3479  data: 0.0017  max mem: 2502
Train: Epoch[4/5]  [  50/1142]  eta: 0:06:27  Lr: 0.001875  Loss: -0.6522  Acc@1: 68.7500 (69.8529)  Acc@5: 100.0000 (95.0980)  time: 0.3465  data: 0.0007  max mem: 2502
Train: Epoch[4/5]  [  60/1142]  eta: 0:06:22  Lr: 0.001875  Loss: -0.8358  Acc@1: 68.7500 (68.9549)  Acc@5: 93.7500 (94.6721)  time: 0.3468  data: 0.0007  max mem: 2502
Train: Epoch[4/5]  [  70/1142]  eta: 0:06:18  Lr: 0.001875  Loss: -0.2160  Acc@1: 62.5000 (68.9261)  Acc@5: 93.7500 (94.7183)  time: 0.3467  data: 0.0010  max mem: 2502
Train: Epoch[4/5]  [  80/1142]  eta: 0:06:14  Lr: 0.001875  Loss: -0.3703  Acc@1: 68.7500 (68.9815)  Acc@5: 93.7500 (95.0617)  time: 0.3480  data: 0.0010  max mem: 2502
Train: Epoch[4/5]  [  90/1142]  eta: 0:06:10  Lr: 0.001875  Loss: -0.4886  Acc@1: 68.7500 (68.7500)  Acc@5: 93.7500 (94.9863)  time: 0.3486  data: 0.0006  max mem: 2502
Train: Epoch[4/5]  [ 100/1142]  eta: 0:06:06  Lr: 0.001875  Loss: -0.3857  Acc@1: 68.7500 (68.3787)  Acc@5: 93.7500 (94.7401)  time: 0.3478  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [ 110/1142]  eta: 0:06:01  Lr: 0.001875  Loss: -0.7623  Acc@1: 68.7500 (68.9752)  Acc@5: 93.7500 (94.6509)  time: 0.3451  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [ 120/1142]  eta: 0:05:57  Lr: 0.001875  Loss: -0.8652  Acc@1: 75.0000 (69.4731)  Acc@5: 93.7500 (94.7831)  time: 0.3427  data: 0.0002  max mem: 2502
Train: Epoch[4/5]  [ 130/1142]  eta: 0:05:53  Lr: 0.001875  Loss: -0.4656  Acc@1: 62.5000 (68.6069)  Acc@5: 93.7500 (94.7042)  time: 0.3450  data: 0.0009  max mem: 2502
Train: Epoch[4/5]  [ 140/1142]  eta: 0:05:50  Lr: 0.001875  Loss: -0.8455  Acc@1: 62.5000 (69.0160)  Acc@5: 93.7500 (94.7695)  time: 0.3472  data: 0.0010  max mem: 2502
Train: Epoch[4/5]  [ 150/1142]  eta: 0:05:46  Lr: 0.001875  Loss: -0.2238  Acc@1: 75.0000 (69.1639)  Acc@5: 93.7500 (94.7434)  time: 0.3481  data: 0.0007  max mem: 2502
Train: Epoch[4/5]  [ 160/1142]  eta: 0:05:43  Lr: 0.001875  Loss: -1.2239  Acc@1: 75.0000 (69.3323)  Acc@5: 93.7500 (94.6040)  time: 0.3493  data: 0.0008  max mem: 2502
Train: Epoch[4/5]  [ 170/1142]  eta: 0:05:39  Lr: 0.001875  Loss: -0.5524  Acc@1: 68.7500 (69.5541)  Acc@5: 93.7500 (94.7368)  time: 0.3490  data: 0.0007  max mem: 2502
Train: Epoch[4/5]  [ 180/1142]  eta: 0:05:36  Lr: 0.001875  Loss: -0.5911  Acc@1: 68.7500 (69.7859)  Acc@5: 100.0000 (94.7169)  time: 0.3479  data: 0.0007  max mem: 2502
Train: Epoch[4/5]  [ 190/1142]  eta: 0:05:32  Lr: 0.001875  Loss: -0.3592  Acc@1: 68.7500 (69.5026)  Acc@5: 93.7500 (94.7317)  time: 0.3475  data: 0.0012  max mem: 2502
Train: Epoch[4/5]  [ 200/1142]  eta: 0:05:29  Lr: 0.001875  Loss: -0.3667  Acc@1: 62.5000 (69.3408)  Acc@5: 100.0000 (94.8694)  time: 0.3483  data: 0.0020  max mem: 2502
Train: Epoch[4/5]  [ 210/1142]  eta: 0:05:25  Lr: 0.001875  Loss: -0.7825  Acc@1: 62.5000 (69.1055)  Acc@5: 100.0000 (94.8756)  time: 0.3487  data: 0.0019  max mem: 2502
Train: Epoch[4/5]  [ 220/1142]  eta: 0:05:21  Lr: 0.001875  Loss: -0.9565  Acc@1: 68.7500 (69.0894)  Acc@5: 93.7500 (94.8529)  time: 0.3486  data: 0.0014  max mem: 2502
Train: Epoch[4/5]  [ 230/1142]  eta: 0:05:18  Lr: 0.001875  Loss: 0.0412  Acc@1: 68.7500 (69.0206)  Acc@5: 93.7500 (94.6699)  time: 0.3473  data: 0.0009  max mem: 2502
Train: Epoch[4/5]  [ 240/1142]  eta: 0:05:14  Lr: 0.001875  Loss: -1.1724  Acc@1: 75.0000 (69.1649)  Acc@5: 93.7500 (94.6836)  time: 0.3474  data: 0.0016  max mem: 2502
Train: Epoch[4/5]  [ 250/1142]  eta: 0:05:11  Lr: 0.001875  Loss: -0.3681  Acc@1: 68.7500 (69.0986)  Acc@5: 93.7500 (94.6215)  time: 0.3467  data: 0.0015  max mem: 2502
Train: Epoch[4/5]  [ 260/1142]  eta: 0:05:07  Lr: 0.001875  Loss: -0.6792  Acc@1: 68.7500 (69.0374)  Acc@5: 93.7500 (94.5881)  time: 0.3465  data: 0.0016  max mem: 2502
Train: Epoch[4/5]  [ 270/1142]  eta: 0:05:04  Lr: 0.001875  Loss: -0.6705  Acc@1: 62.5000 (68.8884)  Acc@5: 93.7500 (94.6033)  time: 0.3463  data: 0.0015  max mem: 2502
Train: Epoch[4/5]  [ 280/1142]  eta: 0:05:00  Lr: 0.001875  Loss: -0.9418  Acc@1: 62.5000 (69.0169)  Acc@5: 93.7500 (94.5952)  time: 0.3441  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [ 290/1142]  eta: 0:04:56  Lr: 0.001875  Loss: -0.4583  Acc@1: 68.7500 (69.0722)  Acc@5: 100.0000 (94.6735)  time: 0.3442  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [ 300/1142]  eta: 0:04:53  Lr: 0.001875  Loss: -0.1187  Acc@1: 68.7500 (68.9576)  Acc@5: 93.7500 (94.6429)  time: 0.3464  data: 0.0016  max mem: 2502
Train: Epoch[4/5]  [ 310/1142]  eta: 0:04:49  Lr: 0.001875  Loss: -0.4703  Acc@1: 62.5000 (68.6696)  Acc@5: 93.7500 (94.5740)  time: 0.3492  data: 0.0020  max mem: 2502
Train: Epoch[4/5]  [ 320/1142]  eta: 0:04:46  Lr: 0.001875  Loss: -0.2477  Acc@1: 62.5000 (68.6332)  Acc@5: 93.7500 (94.5288)  time: 0.3483  data: 0.0010  max mem: 2502
Train: Epoch[4/5]  [ 330/1142]  eta: 0:04:42  Lr: 0.001875  Loss: -0.7240  Acc@1: 68.7500 (68.6934)  Acc@5: 93.7500 (94.4298)  time: 0.3473  data: 0.0007  max mem: 2502
Train: Epoch[4/5]  [ 340/1142]  eta: 0:04:39  Lr: 0.001875  Loss: -1.0311  Acc@1: 68.7500 (68.8600)  Acc@5: 93.7500 (94.4282)  time: 0.3493  data: 0.0012  max mem: 2502
Train: Epoch[4/5]  [ 350/1142]  eta: 0:04:35  Lr: 0.001875  Loss: -0.2247  Acc@1: 75.0000 (69.0883)  Acc@5: 93.7500 (94.5157)  time: 0.3500  data: 0.0013  max mem: 2502
Train: Epoch[4/5]  [ 360/1142]  eta: 0:04:32  Lr: 0.001875  Loss: 0.1548  Acc@1: 75.0000 (69.0270)  Acc@5: 100.0000 (94.5464)  time: 0.3491  data: 0.0015  max mem: 2502
Train: Epoch[4/5]  [ 370/1142]  eta: 0:04:29  Lr: 0.001875  Loss: -0.5933  Acc@1: 62.5000 (68.8511)  Acc@5: 93.7500 (94.5586)  time: 0.3488  data: 0.0015  max mem: 2502
Train: Epoch[4/5]  [ 380/1142]  eta: 0:04:25  Lr: 0.001875  Loss: -0.5866  Acc@1: 62.5000 (68.8156)  Acc@5: 100.0000 (94.6030)  time: 0.3491  data: 0.0009  max mem: 2502
Train: Epoch[4/5]  [ 390/1142]  eta: 0:04:22  Lr: 0.001875  Loss: 0.2336  Acc@1: 68.7500 (68.7820)  Acc@5: 93.7500 (94.5332)  time: 0.3494  data: 0.0016  max mem: 2502
Train: Epoch[4/5]  [ 400/1142]  eta: 0:04:18  Lr: 0.001875  Loss: -0.2409  Acc@1: 68.7500 (68.5786)  Acc@5: 93.7500 (94.4202)  time: 0.3479  data: 0.0013  max mem: 2502
Train: Epoch[4/5]  [ 410/1142]  eta: 0:04:15  Lr: 0.001875  Loss: -0.2447  Acc@1: 62.5000 (68.5979)  Acc@5: 93.7500 (94.4495)  time: 0.3455  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [ 420/1142]  eta: 0:04:11  Lr: 0.001875  Loss: -1.0215  Acc@1: 68.7500 (68.4382)  Acc@5: 93.7500 (94.4032)  time: 0.3441  data: 0.0010  max mem: 2502
Train: Epoch[4/5]  [ 430/1142]  eta: 0:04:07  Lr: 0.001875  Loss: -0.3891  Acc@1: 68.7500 (68.4165)  Acc@5: 87.5000 (94.3155)  time: 0.3432  data: 0.0010  max mem: 2502
Train: Epoch[4/5]  [ 440/1142]  eta: 0:04:04  Lr: 0.001875  Loss: -0.5143  Acc@1: 68.7500 (68.4949)  Acc@5: 93.7500 (94.3594)  time: 0.3448  data: 0.0017  max mem: 2502
Train: Epoch[4/5]  [ 450/1142]  eta: 0:04:00  Lr: 0.001875  Loss: -0.6297  Acc@1: 68.7500 (68.3481)  Acc@5: 93.7500 (94.3459)  time: 0.3482  data: 0.0023  max mem: 2502
Train: Epoch[4/5]  [ 460/1142]  eta: 0:03:57  Lr: 0.001875  Loss: -0.4573  Acc@1: 68.7500 (68.3568)  Acc@5: 93.7500 (94.3059)  time: 0.3475  data: 0.0009  max mem: 2502
Train: Epoch[4/5]  [ 470/1142]  eta: 0:03:53  Lr: 0.001875  Loss: -0.1736  Acc@1: 68.7500 (68.3121)  Acc@5: 93.7500 (94.2808)  time: 0.3468  data: 0.0007  max mem: 2502
Train: Epoch[4/5]  [ 480/1142]  eta: 0:03:50  Lr: 0.001875  Loss: -0.5192  Acc@1: 68.7500 (68.3732)  Acc@5: 93.7500 (94.3217)  time: 0.3484  data: 0.0014  max mem: 2502
Train: Epoch[4/5]  [ 490/1142]  eta: 0:03:46  Lr: 0.001875  Loss: -0.6285  Acc@1: 62.5000 (68.1645)  Acc@5: 93.7500 (94.3228)  time: 0.3485  data: 0.0014  max mem: 2502
Train: Epoch[4/5]  [ 500/1142]  eta: 0:03:43  Lr: 0.001875  Loss: -0.8073  Acc@1: 62.5000 (68.2136)  Acc@5: 93.7500 (94.3488)  time: 0.3480  data: 0.0011  max mem: 2502
Train: Epoch[4/5]  [ 510/1142]  eta: 0:03:39  Lr: 0.001875  Loss: -0.6881  Acc@1: 75.0000 (68.2363)  Acc@5: 93.7500 (94.3615)  time: 0.3475  data: 0.0009  max mem: 2502
Train: Epoch[4/5]  [ 520/1142]  eta: 0:03:36  Lr: 0.001875  Loss: 0.6589  Acc@1: 68.7500 (68.2821)  Acc@5: 93.7500 (94.3738)  time: 0.3476  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [ 530/1142]  eta: 0:03:33  Lr: 0.001875  Loss: -0.6149  Acc@1: 68.7500 (68.3027)  Acc@5: 93.7500 (94.3974)  time: 0.3475  data: 0.0006  max mem: 2502
Train: Epoch[4/5]  [ 540/1142]  eta: 0:03:29  Lr: 0.001875  Loss: -0.3813  Acc@1: 75.0000 (68.3919)  Acc@5: 93.7500 (94.3738)  time: 0.3478  data: 0.0012  max mem: 2502
Train: Epoch[4/5]  [ 550/1142]  eta: 0:03:26  Lr: 0.001875  Loss: -0.3234  Acc@1: 75.0000 (68.4551)  Acc@5: 93.7500 (94.3625)  time: 0.3483  data: 0.0017  max mem: 2502
Train: Epoch[4/5]  [ 560/1142]  eta: 0:03:22  Lr: 0.001875  Loss: -0.4982  Acc@1: 68.7500 (68.4603)  Acc@5: 93.7500 (94.3182)  time: 0.3474  data: 0.0012  max mem: 2502
Train: Epoch[4/5]  [ 570/1142]  eta: 0:03:19  Lr: 0.001875  Loss: -0.5017  Acc@1: 68.7500 (68.4873)  Acc@5: 93.7500 (94.3192)  time: 0.3471  data: 0.0007  max mem: 2502
Train: Epoch[4/5]  [ 580/1142]  eta: 0:03:15  Lr: 0.001875  Loss: -0.0588  Acc@1: 68.7500 (68.4918)  Acc@5: 93.7500 (94.3524)  time: 0.3473  data: 0.0006  max mem: 2502
Train: Epoch[4/5]  [ 590/1142]  eta: 0:03:12  Lr: 0.001875  Loss: -0.4608  Acc@1: 75.0000 (68.5068)  Acc@5: 93.7500 (94.3211)  time: 0.3450  data: 0.0006  max mem: 2502
Train: Epoch[4/5]  [ 600/1142]  eta: 0:03:08  Lr: 0.001875  Loss: -0.1103  Acc@1: 68.7500 (68.4692)  Acc@5: 93.7500 (94.3116)  time: 0.3427  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [ 610/1142]  eta: 0:03:04  Lr: 0.001875  Loss: -0.0553  Acc@1: 68.7500 (68.3818)  Acc@5: 93.7500 (94.2615)  time: 0.3426  data: 0.0002  max mem: 2502
Train: Epoch[4/5]  [ 620/1142]  eta: 0:03:01  Lr: 0.001875  Loss: -0.2576  Acc@1: 62.5000 (68.3877)  Acc@5: 93.7500 (94.3035)  time: 0.3451  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [ 630/1142]  eta: 0:02:58  Lr: 0.001875  Loss: 0.0764  Acc@1: 68.7500 (68.3736)  Acc@5: 93.7500 (94.2452)  time: 0.3478  data: 0.0007  max mem: 2502
Train: Epoch[4/5]  [ 640/1142]  eta: 0:02:54  Lr: 0.001875  Loss: -0.6976  Acc@1: 68.7500 (68.4380)  Acc@5: 93.7500 (94.2765)  time: 0.3476  data: 0.0009  max mem: 2502
Train: Epoch[4/5]  [ 650/1142]  eta: 0:02:51  Lr: 0.001875  Loss: -0.3065  Acc@1: 68.7500 (68.4812)  Acc@5: 100.0000 (94.2876)  time: 0.3470  data: 0.0009  max mem: 2502
Train: Epoch[4/5]  [ 660/1142]  eta: 0:02:47  Lr: 0.001875  Loss: -0.1386  Acc@1: 62.5000 (68.3151)  Acc@5: 93.7500 (94.2606)  time: 0.3470  data: 0.0012  max mem: 2502
Train: Epoch[4/5]  [ 670/1142]  eta: 0:02:44  Lr: 0.001875  Loss: -0.5220  Acc@1: 62.5000 (68.3961)  Acc@5: 93.7500 (94.3182)  time: 0.3485  data: 0.0022  max mem: 2502
Train: Epoch[4/5]  [ 680/1142]  eta: 0:02:40  Lr: 0.001875  Loss: -0.6632  Acc@1: 68.7500 (68.4655)  Acc@5: 100.0000 (94.3833)  time: 0.3500  data: 0.0027  max mem: 2502
Train: Epoch[4/5]  [ 690/1142]  eta: 0:02:37  Lr: 0.001875  Loss: -0.3513  Acc@1: 68.7500 (68.4696)  Acc@5: 100.0000 (94.3831)  time: 0.3486  data: 0.0018  max mem: 2502
Train: Epoch[4/5]  [ 700/1142]  eta: 0:02:33  Lr: 0.001875  Loss: -0.7158  Acc@1: 75.0000 (68.6252)  Acc@5: 93.7500 (94.4098)  time: 0.3485  data: 0.0014  max mem: 2502
Train: Epoch[4/5]  [ 710/1142]  eta: 0:02:30  Lr: 0.001875  Loss: -0.7874  Acc@1: 75.0000 (68.6797)  Acc@5: 93.7500 (94.4181)  time: 0.3489  data: 0.0012  max mem: 2502
Train: Epoch[4/5]  [ 720/1142]  eta: 0:02:26  Lr: 0.001875  Loss: -0.1247  Acc@1: 68.7500 (68.6633)  Acc@5: 93.7500 (94.4261)  time: 0.3473  data: 0.0008  max mem: 2502
Train: Epoch[4/5]  [ 730/1142]  eta: 0:02:23  Lr: 0.001875  Loss: -0.5130  Acc@1: 68.7500 (68.6474)  Acc@5: 93.7500 (94.3827)  time: 0.3509  data: 0.0021  max mem: 2502
Train: Epoch[4/5]  [ 740/1142]  eta: 0:02:19  Lr: 0.001875  Loss: -0.7926  Acc@1: 68.7500 (68.6404)  Acc@5: 93.7500 (94.3657)  time: 0.3503  data: 0.0018  max mem: 2502
Train: Epoch[4/5]  [ 750/1142]  eta: 0:02:16  Lr: 0.001875  Loss: -0.1532  Acc@1: 68.7500 (68.6585)  Acc@5: 93.7500 (94.3742)  time: 0.3457  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [ 760/1142]  eta: 0:02:12  Lr: 0.001875  Loss: -0.4105  Acc@1: 62.5000 (68.5529)  Acc@5: 93.7500 (94.3249)  time: 0.3452  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [ 770/1142]  eta: 0:02:09  Lr: 0.001875  Loss: -0.6610  Acc@1: 62.5000 (68.4825)  Acc@5: 93.7500 (94.3174)  time: 0.3444  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [ 780/1142]  eta: 0:02:05  Lr: 0.001875  Loss: -0.7763  Acc@1: 62.5000 (68.4459)  Acc@5: 93.7500 (94.3022)  time: 0.3435  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [ 790/1142]  eta: 0:02:02  Lr: 0.001875  Loss: -0.3638  Acc@1: 62.5000 (68.4181)  Acc@5: 93.7500 (94.2557)  time: 0.3442  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [ 800/1142]  eta: 0:01:58  Lr: 0.001875  Loss: -0.2777  Acc@1: 62.5000 (68.3599)  Acc@5: 93.7500 (94.2572)  time: 0.3458  data: 0.0008  max mem: 2502
Train: Epoch[4/5]  [ 810/1142]  eta: 0:01:55  Lr: 0.001875  Loss: -0.8321  Acc@1: 62.5000 (68.3493)  Acc@5: 93.7500 (94.2509)  time: 0.3472  data: 0.0006  max mem: 2502
Train: Epoch[4/5]  [ 820/1142]  eta: 0:01:51  Lr: 0.001875  Loss: -0.3281  Acc@1: 62.5000 (68.3085)  Acc@5: 93.7500 (94.2372)  time: 0.3481  data: 0.0014  max mem: 2502
Train: Epoch[4/5]  [ 830/1142]  eta: 0:01:48  Lr: 0.001875  Loss: -0.6034  Acc@1: 68.7500 (68.3664)  Acc@5: 93.7500 (94.2614)  time: 0.3471  data: 0.0016  max mem: 2502
Train: Epoch[4/5]  [ 840/1142]  eta: 0:01:44  Lr: 0.001875  Loss: -0.6972  Acc@1: 75.0000 (68.3487)  Acc@5: 93.7500 (94.2628)  time: 0.3469  data: 0.0010  max mem: 2502
Train: Epoch[4/5]  [ 850/1142]  eta: 0:01:41  Lr: 0.001875  Loss: -0.6235  Acc@1: 68.7500 (68.3387)  Acc@5: 93.7500 (94.2568)  time: 0.3476  data: 0.0009  max mem: 2502
Train: Epoch[4/5]  [ 860/1142]  eta: 0:01:38  Lr: 0.001875  Loss: -0.5436  Acc@1: 62.5000 (68.2927)  Acc@5: 93.7500 (94.2509)  time: 0.3471  data: 0.0009  max mem: 2502
Train: Epoch[4/5]  [ 870/1142]  eta: 0:01:34  Lr: 0.001875  Loss: -0.6326  Acc@1: 68.7500 (68.3410)  Acc@5: 93.7500 (94.2666)  time: 0.3470  data: 0.0013  max mem: 2502
Train: Epoch[4/5]  [ 880/1142]  eta: 0:01:31  Lr: 0.001875  Loss: -0.0474  Acc@1: 68.7500 (68.2605)  Acc@5: 93.7500 (94.2679)  time: 0.3479  data: 0.0012  max mem: 2502
Train: Epoch[4/5]  [ 890/1142]  eta: 0:01:27  Lr: 0.001875  Loss: -0.9151  Acc@1: 68.7500 (68.3361)  Acc@5: 93.7500 (94.2831)  time: 0.3486  data: 0.0013  max mem: 2502
Train: Epoch[4/5]  [ 900/1142]  eta: 0:01:24  Lr: 0.001875  Loss: -0.1394  Acc@1: 68.7500 (68.3269)  Acc@5: 93.7500 (94.2772)  time: 0.3474  data: 0.0013  max mem: 2502
Train: Epoch[4/5]  [ 910/1142]  eta: 0:01:20  Lr: 0.001875  Loss: -0.3339  Acc@1: 68.7500 (68.3178)  Acc@5: 93.7500 (94.2920)  time: 0.3482  data: 0.0011  max mem: 2502
Train: Epoch[4/5]  [ 920/1142]  eta: 0:01:17  Lr: 0.001875  Loss: -0.7048  Acc@1: 68.7500 (68.2953)  Acc@5: 93.7500 (94.2318)  time: 0.3507  data: 0.0011  max mem: 2502
Train: Epoch[4/5]  [ 930/1142]  eta: 0:01:13  Lr: 0.001875  Loss: -0.5797  Acc@1: 68.7500 (68.3069)  Acc@5: 93.7500 (94.2535)  time: 0.3487  data: 0.0007  max mem: 2502
Train: Epoch[4/5]  [ 940/1142]  eta: 0:01:10  Lr: 0.001875  Loss: -0.1674  Acc@1: 68.7500 (68.3249)  Acc@5: 93.7500 (94.2415)  time: 0.3478  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [ 950/1142]  eta: 0:01:06  Lr: 0.001875  Loss: -0.4209  Acc@1: 68.7500 (68.3360)  Acc@5: 93.7500 (94.2429)  time: 0.3462  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [ 960/1142]  eta: 0:01:03  Lr: 0.001875  Loss: -0.7453  Acc@1: 68.7500 (68.3338)  Acc@5: 93.7500 (94.2573)  time: 0.3431  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [ 970/1142]  eta: 0:00:59  Lr: 0.001875  Loss: -0.5332  Acc@1: 75.0000 (68.3895)  Acc@5: 93.7500 (94.2778)  time: 0.3434  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [ 980/1142]  eta: 0:00:56  Lr: 0.001875  Loss: -0.5329  Acc@1: 75.0000 (68.4888)  Acc@5: 93.7500 (94.3043)  time: 0.3458  data: 0.0011  max mem: 2502
Train: Epoch[4/5]  [ 990/1142]  eta: 0:00:52  Lr: 0.001875  Loss: -0.4855  Acc@1: 75.0000 (68.5356)  Acc@5: 93.7500 (94.3176)  time: 0.3475  data: 0.0013  max mem: 2502
Train: Epoch[4/5]  [1000/1142]  eta: 0:00:49  Lr: 0.001875  Loss: -0.6433  Acc@1: 75.0000 (68.5939)  Acc@5: 100.0000 (94.3432)  time: 0.3475  data: 0.0011  max mem: 2502
Train: Epoch[4/5]  [1010/1142]  eta: 0:00:45  Lr: 0.001875  Loss: -0.7862  Acc@1: 68.7500 (68.6016)  Acc@5: 100.0000 (94.3558)  time: 0.3476  data: 0.0014  max mem: 2502
Train: Epoch[4/5]  [1020/1142]  eta: 0:00:42  Lr: 0.001875  Loss: -0.1498  Acc@1: 68.7500 (68.5970)  Acc@5: 93.7500 (94.3315)  time: 0.3481  data: 0.0013  max mem: 2502
Train: Epoch[4/5]  [1030/1142]  eta: 0:00:38  Lr: 0.001875  Loss: -0.5819  Acc@1: 68.7500 (68.5984)  Acc@5: 93.7500 (94.3259)  time: 0.3491  data: 0.0017  max mem: 2502
Train: Epoch[4/5]  [1040/1142]  eta: 0:00:35  Lr: 0.001875  Loss: -0.7188  Acc@1: 68.7500 (68.6239)  Acc@5: 93.7500 (94.3084)  time: 0.3491  data: 0.0020  max mem: 2502
Train: Epoch[4/5]  [1050/1142]  eta: 0:00:31  Lr: 0.001875  Loss: -0.0546  Acc@1: 68.7500 (68.6846)  Acc@5: 93.7500 (94.3209)  time: 0.3479  data: 0.0018  max mem: 2502
Train: Epoch[4/5]  [1060/1142]  eta: 0:00:28  Lr: 0.001875  Loss: -0.3259  Acc@1: 68.7500 (68.6675)  Acc@5: 93.7500 (94.2978)  time: 0.3476  data: 0.0015  max mem: 2502
Train: Epoch[4/5]  [1070/1142]  eta: 0:00:25  Lr: 0.001875  Loss: -0.1253  Acc@1: 62.5000 (68.6216)  Acc@5: 93.7500 (94.2986)  time: 0.3474  data: 0.0010  max mem: 2502
Train: Epoch[4/5]  [1080/1142]  eta: 0:00:21  Lr: 0.001875  Loss: -0.9484  Acc@1: 68.7500 (68.7095)  Acc@5: 93.7500 (94.3050)  time: 0.3478  data: 0.0015  max mem: 2502
Train: Epoch[4/5]  [1090/1142]  eta: 0:00:18  Lr: 0.001875  Loss: -1.0072  Acc@1: 68.7500 (68.7328)  Acc@5: 93.7500 (94.2942)  time: 0.3476  data: 0.0013  max mem: 2502
Train: Epoch[4/5]  [1100/1142]  eta: 0:00:14  Lr: 0.001875  Loss: -0.5446  Acc@1: 68.7500 (68.7273)  Acc@5: 93.7500 (94.2893)  time: 0.3469  data: 0.0008  max mem: 2502
Train: Epoch[4/5]  [1110/1142]  eta: 0:00:11  Lr: 0.001875  Loss: 0.3112  Acc@1: 68.7500 (68.7050)  Acc@5: 93.7500 (94.2676)  time: 0.3465  data: 0.0006  max mem: 2502
Train: Epoch[4/5]  [1120/1142]  eta: 0:00:07  Lr: 0.001875  Loss: -0.1417  Acc@1: 75.0000 (68.7165)  Acc@5: 93.7500 (94.2908)  time: 0.3466  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [1130/1142]  eta: 0:00:04  Lr: 0.001875  Loss: -0.9020  Acc@1: 75.0000 (68.7500)  Acc@5: 93.7500 (94.2750)  time: 0.3448  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [1140/1142]  eta: 0:00:00  Lr: 0.001875  Loss: -0.6477  Acc@1: 75.0000 (68.7610)  Acc@5: 93.7500 (94.3032)  time: 0.3433  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [1141/1142]  eta: 0:00:00  Lr: 0.001875  Loss: -0.6687  Acc@1: 68.7500 (68.7599)  Acc@5: 93.7500 (94.3060)  time: 0.3358  data: 0.0003  max mem: 2502
Train: Epoch[4/5] Total time: 0:06:36 (0.3476 s / it)
{0: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 1: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 2: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 3: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 4: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 5: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 6: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 7: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 8: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 9: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 10: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 11: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 12: {0: 0, 1: 0, 2: 0, 3: 73060, 4: 0}, 13: {0: 0, 1: 0, 2: 0, 3: 73060, 4: 0}, 14: {0: 0, 1: 0, 2: 0, 3: 73060, 4: 0}, 15: {0: 0, 1: 0, 2: 0, 3: 73060, 4: 0}, 16: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 17: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 18: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 19: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}}
Averaged stats: Lr: 0.001875  Loss: -0.6687  Acc@1: 68.7500 (68.7599)  Acc@5: 93.7500 (94.3060)
Train: Epoch[5/5]  [   0/1142]  eta: 0:11:39  Lr: 0.001875  Loss: -0.4580  Acc@1: 75.0000 (75.0000)  Acc@5: 100.0000 (100.0000)  time: 0.6127  data: 0.2678  max mem: 2502
Train: Epoch[5/5]  [  10/1142]  eta: 0:06:57  Lr: 0.001875  Loss: -0.5234  Acc@1: 75.0000 (71.5909)  Acc@5: 93.7500 (91.4773)  time: 0.3686  data: 0.0247  max mem: 2502
Train: Epoch[5/5]  [  20/1142]  eta: 0:06:42  Lr: 0.001875  Loss: -0.3533  Acc@1: 68.7500 (70.5357)  Acc@5: 93.7500 (91.9643)  time: 0.3465  data: 0.0007  max mem: 2502
Train: Epoch[5/5]  [  30/1142]  eta: 0:06:35  Lr: 0.001875  Loss: 0.2277  Acc@1: 68.7500 (69.9597)  Acc@5: 93.7500 (92.7419)  time: 0.3487  data: 0.0018  max mem: 2502
Train: Epoch[5/5]  [  40/1142]  eta: 0:06:29  Lr: 0.001875  Loss: -0.5135  Acc@1: 68.7500 (69.2073)  Acc@5: 93.7500 (92.9878)  time: 0.3477  data: 0.0016  max mem: 2502
Train: Epoch[5/5]  [  50/1142]  eta: 0:06:25  Lr: 0.001875  Loss: -0.7277  Acc@1: 68.7500 (69.8529)  Acc@5: 93.7500 (93.9951)  time: 0.3480  data: 0.0015  max mem: 2502
Train: Epoch[5/5]  [  60/1142]  eta: 0:06:20  Lr: 0.001875  Loss: -0.9076  Acc@1: 68.7500 (69.7746)  Acc@5: 100.0000 (94.3648)  time: 0.3479  data: 0.0019  max mem: 2502
Train: Epoch[5/5]  [  70/1142]  eta: 0:06:16  Lr: 0.001875  Loss: -1.1144  Acc@1: 68.7500 (70.1585)  Acc@5: 93.7500 (94.4542)  time: 0.3476  data: 0.0011  max mem: 2502
Train: Epoch[5/5]  [  80/1142]  eta: 0:06:13  Lr: 0.001875  Loss: -0.4304  Acc@1: 68.7500 (69.6759)  Acc@5: 93.7500 (94.2901)  time: 0.3509  data: 0.0022  max mem: 2502
Train: Epoch[5/5]  [  90/1142]  eta: 0:06:09  Lr: 0.001875  Loss: -0.8622  Acc@1: 68.7500 (70.1923)  Acc@5: 93.7500 (94.4368)  time: 0.3496  data: 0.0020  max mem: 2502
Train: Epoch[5/5]  [ 100/1142]  eta: 0:06:05  Lr: 0.001875  Loss: -0.5974  Acc@1: 68.7500 (69.7401)  Acc@5: 93.7500 (94.4307)  time: 0.3462  data: 0.0006  max mem: 2502
Train: Epoch[5/5]  [ 110/1142]  eta: 0:06:01  Lr: 0.001875  Loss: -0.4621  Acc@1: 62.5000 (68.9752)  Acc@5: 93.7500 (94.4820)  time: 0.3468  data: 0.0008  max mem: 2502
Train: Epoch[5/5]  [ 120/1142]  eta: 0:05:57  Lr: 0.001875  Loss: -0.3330  Acc@1: 62.5000 (68.1818)  Acc@5: 93.7500 (94.2665)  time: 0.3480  data: 0.0009  max mem: 2502
Train: Epoch[5/5]  [ 130/1142]  eta: 0:05:53  Lr: 0.001875  Loss: -0.1466  Acc@1: 62.5000 (68.1298)  Acc@5: 93.7500 (94.1794)  time: 0.3476  data: 0.0006  max mem: 2502
Train: Epoch[5/5]  [ 140/1142]  eta: 0:05:50  Lr: 0.001875  Loss: -0.4298  Acc@1: 68.7500 (68.3511)  Acc@5: 93.7500 (94.3262)  time: 0.3472  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [ 150/1142]  eta: 0:05:46  Lr: 0.001875  Loss: -0.7270  Acc@1: 68.7500 (68.2119)  Acc@5: 93.7500 (94.3709)  time: 0.3475  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [ 160/1142]  eta: 0:05:42  Lr: 0.001875  Loss: -0.2556  Acc@1: 62.5000 (67.8571)  Acc@5: 93.7500 (94.3323)  time: 0.3464  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [ 170/1142]  eta: 0:05:39  Lr: 0.001875  Loss: -0.8665  Acc@1: 62.5000 (67.8363)  Acc@5: 93.7500 (94.4079)  time: 0.3450  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [ 180/1142]  eta: 0:05:35  Lr: 0.001875  Loss: -0.6607  Acc@1: 68.7500 (67.8522)  Acc@5: 93.7500 (94.3715)  time: 0.3438  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [ 190/1142]  eta: 0:05:31  Lr: 0.001875  Loss: -0.9707  Acc@1: 68.7500 (67.8010)  Acc@5: 93.7500 (94.4045)  time: 0.3433  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [ 200/1142]  eta: 0:05:28  Lr: 0.001875  Loss: -0.2013  Acc@1: 62.5000 (67.6306)  Acc@5: 93.7500 (94.2786)  time: 0.3460  data: 0.0007  max mem: 2502
Train: Epoch[5/5]  [ 210/1142]  eta: 0:05:24  Lr: 0.001875  Loss: -1.0491  Acc@1: 68.7500 (68.0095)  Acc@5: 93.7500 (94.3424)  time: 0.3486  data: 0.0016  max mem: 2502
Train: Epoch[5/5]  [ 220/1142]  eta: 0:05:21  Lr: 0.001875  Loss: -0.5577  Acc@1: 68.7500 (68.2410)  Acc@5: 93.7500 (94.3722)  time: 0.3495  data: 0.0028  max mem: 2502
Train: Epoch[5/5]  [ 230/1142]  eta: 0:05:17  Lr: 0.001875  Loss: -0.4442  Acc@1: 75.0000 (68.4253)  Acc@5: 93.7500 (94.3452)  time: 0.3484  data: 0.0026  max mem: 2502
Train: Epoch[5/5]  [ 240/1142]  eta: 0:05:14  Lr: 0.001875  Loss: -0.6420  Acc@1: 68.7500 (68.4907)  Acc@5: 93.7500 (94.4502)  time: 0.3474  data: 0.0012  max mem: 2502
Train: Epoch[5/5]  [ 250/1142]  eta: 0:05:10  Lr: 0.001875  Loss: -0.4152  Acc@1: 68.7500 (68.3765)  Acc@5: 93.7500 (94.4223)  time: 0.3482  data: 0.0008  max mem: 2502
Train: Epoch[5/5]  [ 260/1142]  eta: 0:05:07  Lr: 0.001875  Loss: -0.1529  Acc@1: 68.7500 (68.5105)  Acc@5: 93.7500 (94.4923)  time: 0.3488  data: 0.0009  max mem: 2502
Train: Epoch[5/5]  [ 270/1142]  eta: 0:05:03  Lr: 0.001875  Loss: -0.8537  Acc@1: 75.0000 (68.7961)  Acc@5: 100.0000 (94.6264)  time: 0.3492  data: 0.0019  max mem: 2502
Train: Epoch[5/5]  [ 280/1142]  eta: 0:05:00  Lr: 0.001875  Loss: -0.4745  Acc@1: 75.0000 (68.9724)  Acc@5: 100.0000 (94.7064)  time: 0.3486  data: 0.0018  max mem: 2502
Train: Epoch[5/5]  [ 290/1142]  eta: 0:04:56  Lr: 0.001875  Loss: -0.4657  Acc@1: 68.7500 (68.9003)  Acc@5: 93.7500 (94.6091)  time: 0.3481  data: 0.0011  max mem: 2502
Train: Epoch[5/5]  [ 300/1142]  eta: 0:04:53  Lr: 0.001875  Loss: -0.6598  Acc@1: 68.7500 (69.0822)  Acc@5: 93.7500 (94.6013)  time: 0.3472  data: 0.0010  max mem: 2502
Train: Epoch[5/5]  [ 310/1142]  eta: 0:04:49  Lr: 0.001875  Loss: -0.7107  Acc@1: 75.0000 (69.1519)  Acc@5: 93.7500 (94.5941)  time: 0.3465  data: 0.0008  max mem: 2502
Train: Epoch[5/5]  [ 320/1142]  eta: 0:04:46  Lr: 0.001875  Loss: -0.5191  Acc@1: 68.7500 (69.1589)  Acc@5: 93.7500 (94.5872)  time: 0.3464  data: 0.0007  max mem: 2502
Train: Epoch[5/5]  [ 330/1142]  eta: 0:04:42  Lr: 0.001875  Loss: -0.6310  Acc@1: 68.7500 (69.1465)  Acc@5: 100.0000 (94.7130)  time: 0.3462  data: 0.0006  max mem: 2502
Train: Epoch[5/5]  [ 340/1142]  eta: 0:04:39  Lr: 0.001875  Loss: -0.5472  Acc@1: 68.7500 (69.1716)  Acc@5: 100.0000 (94.7581)  time: 0.3446  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [ 350/1142]  eta: 0:04:35  Lr: 0.001875  Loss: -0.2289  Acc@1: 68.7500 (69.0527)  Acc@5: 93.7500 (94.6581)  time: 0.3435  data: 0.0006  max mem: 2502
Train: Epoch[5/5]  [ 360/1142]  eta: 0:04:31  Lr: 0.001875  Loss: -0.3296  Acc@1: 68.7500 (69.1136)  Acc@5: 93.7500 (94.6503)  time: 0.3433  data: 0.0006  max mem: 2502
Train: Epoch[5/5]  [ 370/1142]  eta: 0:04:28  Lr: 0.001875  Loss: -0.5744  Acc@1: 68.7500 (69.0701)  Acc@5: 93.7500 (94.6092)  time: 0.3460  data: 0.0010  max mem: 2502
Train: Epoch[5/5]  [ 380/1142]  eta: 0:04:25  Lr: 0.001875  Loss: -0.8638  Acc@1: 68.7500 (69.1437)  Acc@5: 93.7500 (94.6030)  time: 0.3485  data: 0.0013  max mem: 2502
Train: Epoch[5/5]  [ 390/1142]  eta: 0:04:21  Lr: 0.001875  Loss: -1.0107  Acc@1: 75.0000 (69.3095)  Acc@5: 93.7500 (94.6611)  time: 0.3474  data: 0.0015  max mem: 2502
Train: Epoch[5/5]  [ 400/1142]  eta: 0:04:18  Lr: 0.001875  Loss: -0.5987  Acc@1: 75.0000 (69.3579)  Acc@5: 100.0000 (94.6852)  time: 0.3467  data: 0.0012  max mem: 2502
Train: Epoch[5/5]  [ 410/1142]  eta: 0:04:14  Lr: 0.001875  Loss: -0.5031  Acc@1: 68.7500 (69.2974)  Acc@5: 93.7500 (94.6624)  time: 0.3464  data: 0.0006  max mem: 2502
Train: Epoch[5/5]  [ 420/1142]  eta: 0:04:11  Lr: 0.001875  Loss: -0.5016  Acc@1: 68.7500 (69.3290)  Acc@5: 93.7500 (94.7150)  time: 0.3474  data: 0.0007  max mem: 2502
Train: Epoch[5/5]  [ 430/1142]  eta: 0:04:07  Lr: 0.001875  Loss: -0.6634  Acc@1: 68.7500 (69.3590)  Acc@5: 100.0000 (94.7216)  time: 0.3480  data: 0.0007  max mem: 2502
Train: Epoch[5/5]  [ 440/1142]  eta: 0:04:04  Lr: 0.001875  Loss: -0.5739  Acc@1: 68.7500 (69.3311)  Acc@5: 93.7500 (94.6712)  time: 0.3473  data: 0.0008  max mem: 2502
Train: Epoch[5/5]  [ 450/1142]  eta: 0:04:00  Lr: 0.001875  Loss: -0.4153  Acc@1: 62.5000 (69.2489)  Acc@5: 93.7500 (94.6508)  time: 0.3476  data: 0.0009  max mem: 2502
Train: Epoch[5/5]  [ 460/1142]  eta: 0:03:57  Lr: 0.001875  Loss: -0.6840  Acc@1: 68.7500 (69.2652)  Acc@5: 93.7500 (94.6448)  time: 0.3475  data: 0.0007  max mem: 2502
Train: Epoch[5/5]  [ 470/1142]  eta: 0:03:53  Lr: 0.001875  Loss: -0.4327  Acc@1: 68.7500 (69.2410)  Acc@5: 100.0000 (94.6391)  time: 0.3484  data: 0.0007  max mem: 2502
Train: Epoch[5/5]  [ 480/1142]  eta: 0:03:50  Lr: 0.001875  Loss: -0.2410  Acc@1: 62.5000 (69.2178)  Acc@5: 93.7500 (94.5946)  time: 0.3473  data: 0.0007  max mem: 2502
Train: Epoch[5/5]  [ 490/1142]  eta: 0:03:46  Lr: 0.001875  Loss: -0.7836  Acc@1: 68.7500 (69.3101)  Acc@5: 93.7500 (94.6029)  time: 0.3475  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [ 500/1142]  eta: 0:03:43  Lr: 0.001875  Loss: -0.3817  Acc@1: 68.7500 (69.1866)  Acc@5: 93.7500 (94.5609)  time: 0.3474  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [ 510/1142]  eta: 0:03:39  Lr: 0.001875  Loss: -0.6133  Acc@1: 68.7500 (69.2759)  Acc@5: 93.7500 (94.5939)  time: 0.3442  data: 0.0002  max mem: 2502
Train: Epoch[5/5]  [ 520/1142]  eta: 0:03:36  Lr: 0.001875  Loss: -0.9955  Acc@1: 75.0000 (69.2778)  Acc@5: 93.7500 (94.6017)  time: 0.3447  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [ 530/1142]  eta: 0:03:32  Lr: 0.001875  Loss: -0.5150  Acc@1: 68.7500 (69.3856)  Acc@5: 93.7500 (94.6328)  time: 0.3466  data: 0.0011  max mem: 2502
Train: Epoch[5/5]  [ 540/1142]  eta: 0:03:29  Lr: 0.001875  Loss: -0.8037  Acc@1: 68.7500 (69.3738)  Acc@5: 100.0000 (94.6396)  time: 0.3475  data: 0.0013  max mem: 2502
Train: Epoch[5/5]  [ 550/1142]  eta: 0:03:25  Lr: 0.001875  Loss: -0.6696  Acc@1: 62.5000 (69.3058)  Acc@5: 93.7500 (94.6348)  time: 0.3483  data: 0.0010  max mem: 2502
Train: Epoch[5/5]  [ 560/1142]  eta: 0:03:22  Lr: 0.001875  Loss: -0.6104  Acc@1: 62.5000 (69.3516)  Acc@5: 93.7500 (94.6635)  time: 0.3488  data: 0.0006  max mem: 2502
Train: Epoch[5/5]  [ 570/1142]  eta: 0:03:18  Lr: 0.001875  Loss: -0.6448  Acc@1: 68.7500 (69.3630)  Acc@5: 93.7500 (94.6475)  time: 0.3482  data: 0.0006  max mem: 2502
Train: Epoch[5/5]  [ 580/1142]  eta: 0:03:15  Lr: 0.001875  Loss: -0.6496  Acc@1: 68.7500 (69.3954)  Acc@5: 93.7500 (94.6213)  time: 0.3484  data: 0.0008  max mem: 2502
Train: Epoch[5/5]  [ 590/1142]  eta: 0:03:11  Lr: 0.001875  Loss: -0.3095  Acc@1: 68.7500 (69.3316)  Acc@5: 93.7500 (94.6277)  time: 0.3480  data: 0.0009  max mem: 2502
Train: Epoch[5/5]  [ 600/1142]  eta: 0:03:08  Lr: 0.001875  Loss: -0.2471  Acc@1: 68.7500 (69.2908)  Acc@5: 93.7500 (94.6131)  time: 0.3465  data: 0.0008  max mem: 2502
Train: Epoch[5/5]  [ 610/1142]  eta: 0:03:04  Lr: 0.001875  Loss: -0.1229  Acc@1: 62.5000 (69.1899)  Acc@5: 93.7500 (94.6195)  time: 0.3471  data: 0.0006  max mem: 2502
Train: Epoch[5/5]  [ 620/1142]  eta: 0:03:01  Lr: 0.001875  Loss: -0.4730  Acc@1: 68.7500 (69.2230)  Acc@5: 93.7500 (94.5853)  time: 0.3474  data: 0.0006  max mem: 2502
Train: Epoch[5/5]  [ 630/1142]  eta: 0:02:57  Lr: 0.001875  Loss: 0.3034  Acc@1: 75.0000 (69.3146)  Acc@5: 93.7500 (94.6216)  time: 0.3471  data: 0.0006  max mem: 2502
Train: Epoch[5/5]  [ 640/1142]  eta: 0:02:54  Lr: 0.001875  Loss: -0.7459  Acc@1: 75.0000 (69.3935)  Acc@5: 93.7500 (94.6080)  time: 0.3478  data: 0.0006  max mem: 2502
Train: Epoch[5/5]  [ 650/1142]  eta: 0:02:51  Lr: 0.001875  Loss: -1.0330  Acc@1: 75.0000 (69.4316)  Acc@5: 93.7500 (94.5949)  time: 0.3476  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [ 660/1142]  eta: 0:02:47  Lr: 0.001875  Loss: -0.4271  Acc@1: 75.0000 (69.4970)  Acc@5: 93.7500 (94.6010)  time: 0.3455  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [ 670/1142]  eta: 0:02:44  Lr: 0.001875  Loss: -0.3215  Acc@1: 75.0000 (69.5138)  Acc@5: 93.7500 (94.6442)  time: 0.3435  data: 0.0008  max mem: 2502
Train: Epoch[5/5]  [ 680/1142]  eta: 0:02:40  Lr: 0.001875  Loss: -0.7888  Acc@1: 68.7500 (69.5026)  Acc@5: 93.7500 (94.5943)  time: 0.3438  data: 0.0016  max mem: 2502
Train: Epoch[5/5]  [ 690/1142]  eta: 0:02:37  Lr: 0.001875  Loss: -0.6985  Acc@1: 68.7500 (69.5188)  Acc@5: 93.7500 (94.6274)  time: 0.3455  data: 0.0012  max mem: 2502
Train: Epoch[5/5]  [ 700/1142]  eta: 0:02:33  Lr: 0.001875  Loss: -0.3910  Acc@1: 68.7500 (69.6148)  Acc@5: 100.0000 (94.6772)  time: 0.3476  data: 0.0012  max mem: 2502
Train: Epoch[5/5]  [ 710/1142]  eta: 0:02:30  Lr: 0.001875  Loss: -0.4520  Acc@1: 75.0000 (69.6642)  Acc@5: 93.7500 (94.6466)  time: 0.3483  data: 0.0015  max mem: 2502
Train: Epoch[5/5]  [ 720/1142]  eta: 0:02:26  Lr: 0.001875  Loss: -0.6167  Acc@1: 68.7500 (69.6342)  Acc@5: 93.7500 (94.6602)  time: 0.3472  data: 0.0009  max mem: 2502
Train: Epoch[5/5]  [ 730/1142]  eta: 0:02:23  Lr: 0.001875  Loss: 0.0398  Acc@1: 62.5000 (69.5109)  Acc@5: 93.7500 (94.6392)  time: 0.3466  data: 0.0008  max mem: 2502
Train: Epoch[5/5]  [ 740/1142]  eta: 0:02:19  Lr: 0.001875  Loss: -0.6215  Acc@1: 62.5000 (69.4501)  Acc@5: 93.7500 (94.6694)  time: 0.3491  data: 0.0009  max mem: 2502
Train: Epoch[5/5]  [ 750/1142]  eta: 0:02:16  Lr: 0.001875  Loss: -0.2815  Acc@1: 68.7500 (69.5073)  Acc@5: 100.0000 (94.6821)  time: 0.3489  data: 0.0008  max mem: 2502
Train: Epoch[5/5]  [ 760/1142]  eta: 0:02:12  Lr: 0.001875  Loss: -0.7265  Acc@1: 68.7500 (69.5056)  Acc@5: 93.7500 (94.6781)  time: 0.3464  data: 0.0007  max mem: 2502
Train: Epoch[5/5]  [ 770/1142]  eta: 0:02:09  Lr: 0.001875  Loss: -0.7335  Acc@1: 68.7500 (69.5687)  Acc@5: 93.7500 (94.6984)  time: 0.3466  data: 0.0006  max mem: 2502
Train: Epoch[5/5]  [ 780/1142]  eta: 0:02:05  Lr: 0.001875  Loss: -0.6801  Acc@1: 75.0000 (69.6143)  Acc@5: 93.7500 (94.7103)  time: 0.3477  data: 0.0007  max mem: 2502
Train: Epoch[5/5]  [ 790/1142]  eta: 0:02:02  Lr: 0.001875  Loss: -0.4750  Acc@1: 68.7500 (69.6034)  Acc@5: 93.7500 (94.7219)  time: 0.3471  data: 0.0006  max mem: 2502
Train: Epoch[5/5]  [ 800/1142]  eta: 0:01:58  Lr: 0.001875  Loss: -0.5596  Acc@1: 68.7500 (69.5615)  Acc@5: 93.7500 (94.7253)  time: 0.3463  data: 0.0013  max mem: 2502
Train: Epoch[5/5]  [ 810/1142]  eta: 0:01:55  Lr: 0.001875  Loss: -0.4110  Acc@1: 68.7500 (69.5746)  Acc@5: 93.7500 (94.7518)  time: 0.3459  data: 0.0012  max mem: 2502
Train: Epoch[5/5]  [ 820/1142]  eta: 0:01:51  Lr: 0.001875  Loss: -0.3360  Acc@1: 68.7500 (69.5493)  Acc@5: 93.7500 (94.7625)  time: 0.3452  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [ 830/1142]  eta: 0:01:48  Lr: 0.001875  Loss: -0.0051  Acc@1: 68.7500 (69.5021)  Acc@5: 93.7500 (94.7503)  time: 0.3444  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [ 840/1142]  eta: 0:01:44  Lr: 0.001875  Loss: -0.6283  Acc@1: 68.7500 (69.5155)  Acc@5: 93.7500 (94.7458)  time: 0.3436  data: 0.0009  max mem: 2502
Train: Epoch[5/5]  [ 850/1142]  eta: 0:01:41  Lr: 0.001875  Loss: -0.5205  Acc@1: 75.0000 (69.6019)  Acc@5: 93.7500 (94.7488)  time: 0.3438  data: 0.0011  max mem: 2502
Train: Epoch[5/5]  [ 860/1142]  eta: 0:01:37  Lr: 0.001875  Loss: -0.6297  Acc@1: 75.0000 (69.5993)  Acc@5: 100.0000 (94.7880)  time: 0.3455  data: 0.0008  max mem: 2502
Train: Epoch[5/5]  [ 870/1142]  eta: 0:01:34  Lr: 0.001875  Loss: -0.6823  Acc@1: 75.0000 (69.6254)  Acc@5: 100.0000 (94.8192)  time: 0.3470  data: 0.0009  max mem: 2502
Train: Epoch[5/5]  [ 880/1142]  eta: 0:01:30  Lr: 0.001875  Loss: -0.7856  Acc@1: 75.0000 (69.6155)  Acc@5: 100.0000 (94.8141)  time: 0.3474  data: 0.0012  max mem: 2502
Train: Epoch[5/5]  [ 890/1142]  eta: 0:01:27  Lr: 0.001875  Loss: -0.2584  Acc@1: 68.7500 (69.6198)  Acc@5: 100.0000 (94.8162)  time: 0.3475  data: 0.0015  max mem: 2502
Train: Epoch[5/5]  [ 900/1142]  eta: 0:01:24  Lr: 0.001875  Loss: -0.0036  Acc@1: 68.7500 (69.6448)  Acc@5: 93.7500 (94.8252)  time: 0.3473  data: 0.0011  max mem: 2502
Train: Epoch[5/5]  [ 910/1142]  eta: 0:01:20  Lr: 0.001875  Loss: -0.2398  Acc@1: 75.0000 (69.6625)  Acc@5: 93.7500 (94.7859)  time: 0.3476  data: 0.0007  max mem: 2502
Train: Epoch[5/5]  [ 920/1142]  eta: 0:01:17  Lr: 0.001875  Loss: -0.4725  Acc@1: 75.0000 (69.6797)  Acc@5: 93.7500 (94.7611)  time: 0.3473  data: 0.0009  max mem: 2502
Train: Epoch[5/5]  [ 930/1142]  eta: 0:01:13  Lr: 0.001875  Loss: -0.9367  Acc@1: 68.7500 (69.6496)  Acc@5: 93.7500 (94.7704)  time: 0.3473  data: 0.0008  max mem: 2502
Train: Epoch[5/5]  [ 940/1142]  eta: 0:01:10  Lr: 0.001875  Loss: -0.3616  Acc@1: 68.7500 (69.6666)  Acc@5: 93.7500 (94.7795)  time: 0.3473  data: 0.0008  max mem: 2502
Train: Epoch[5/5]  [ 950/1142]  eta: 0:01:06  Lr: 0.001875  Loss: -0.7805  Acc@1: 68.7500 (69.6832)  Acc@5: 93.7500 (94.7884)  time: 0.3471  data: 0.0008  max mem: 2502
Train: Epoch[5/5]  [ 960/1142]  eta: 0:01:03  Lr: 0.001875  Loss: -0.0209  Acc@1: 68.7500 (69.6670)  Acc@5: 93.7500 (94.7906)  time: 0.3499  data: 0.0007  max mem: 2502
Train: Epoch[5/5]  [ 970/1142]  eta: 0:00:59  Lr: 0.001875  Loss: -0.3029  Acc@1: 68.7500 (69.6383)  Acc@5: 93.7500 (94.7992)  time: 0.3500  data: 0.0006  max mem: 2502
Train: Epoch[5/5]  [ 980/1142]  eta: 0:00:56  Lr: 0.001875  Loss: -0.5882  Acc@1: 68.7500 (69.7057)  Acc@5: 93.7500 (94.8076)  time: 0.3455  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [ 990/1142]  eta: 0:00:52  Lr: 0.001875  Loss: -0.2526  Acc@1: 68.7500 (69.6266)  Acc@5: 93.7500 (94.7969)  time: 0.3430  data: 0.0002  max mem: 2502
Train: Epoch[5/5]  [1000/1142]  eta: 0:00:49  Lr: 0.001875  Loss: -0.3160  Acc@1: 62.5000 (69.6241)  Acc@5: 93.7500 (94.7927)  time: 0.3427  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [1010/1142]  eta: 0:00:45  Lr: 0.001875  Loss: -0.2460  Acc@1: 68.7500 (69.6031)  Acc@5: 93.7500 (94.7515)  time: 0.3450  data: 0.0006  max mem: 2502
Train: Epoch[5/5]  [1020/1142]  eta: 0:00:42  Lr: 0.001875  Loss: -0.2982  Acc@1: 68.7500 (69.6254)  Acc@5: 93.7500 (94.7600)  time: 0.3477  data: 0.0009  max mem: 2502
Train: Epoch[5/5]  [1030/1142]  eta: 0:00:38  Lr: 0.001875  Loss: -0.2449  Acc@1: 68.7500 (69.6472)  Acc@5: 93.7500 (94.7139)  time: 0.3480  data: 0.0008  max mem: 2502
Train: Epoch[5/5]  [1040/1142]  eta: 0:00:35  Lr: 0.001875  Loss: -0.1944  Acc@1: 68.7500 (69.6626)  Acc@5: 87.5000 (94.6866)  time: 0.3473  data: 0.0008  max mem: 2502
Train: Epoch[5/5]  [1050/1142]  eta: 0:00:31  Lr: 0.001875  Loss: -0.7458  Acc@1: 68.7500 (69.6777)  Acc@5: 93.7500 (94.6480)  time: 0.3473  data: 0.0011  max mem: 2502
Train: Epoch[5/5]  [1060/1142]  eta: 0:00:28  Lr: 0.001875  Loss: -0.4494  Acc@1: 68.7500 (69.6454)  Acc@5: 93.7500 (94.6513)  time: 0.3479  data: 0.0013  max mem: 2502
Train: Epoch[5/5]  [1070/1142]  eta: 0:00:24  Lr: 0.001875  Loss: -0.2740  Acc@1: 68.7500 (69.6545)  Acc@5: 93.7500 (94.6545)  time: 0.3481  data: 0.0010  max mem: 2502
Train: Epoch[5/5]  [1080/1142]  eta: 0:00:21  Lr: 0.001875  Loss: -0.2632  Acc@1: 62.5000 (69.5710)  Acc@5: 93.7500 (94.6751)  time: 0.3472  data: 0.0007  max mem: 2502
Train: Epoch[5/5]  [1090/1142]  eta: 0:00:18  Lr: 0.001875  Loss: -0.5218  Acc@1: 62.5000 (69.5807)  Acc@5: 93.7500 (94.6609)  time: 0.3469  data: 0.0006  max mem: 2502
Train: Epoch[5/5]  [1100/1142]  eta: 0:00:14  Lr: 0.001875  Loss: -0.8627  Acc@1: 68.7500 (69.6015)  Acc@5: 100.0000 (94.6923)  time: 0.3482  data: 0.0007  max mem: 2502
Train: Epoch[5/5]  [1110/1142]  eta: 0:00:11  Lr: 0.001875  Loss: -0.5189  Acc@1: 75.0000 (69.6332)  Acc@5: 100.0000 (94.7120)  time: 0.3474  data: 0.0008  max mem: 2502
Train: Epoch[5/5]  [1120/1142]  eta: 0:00:07  Lr: 0.001875  Loss: -0.5878  Acc@1: 75.0000 (69.6532)  Acc@5: 93.7500 (94.7145)  time: 0.3468  data: 0.0015  max mem: 2502
Train: Epoch[5/5]  [1130/1142]  eta: 0:00:04  Lr: 0.001875  Loss: -0.5962  Acc@1: 68.7500 (69.6673)  Acc@5: 100.0000 (94.7447)  time: 0.3471  data: 0.0014  max mem: 2502
Train: Epoch[5/5]  [1140/1142]  eta: 0:00:00  Lr: 0.001875  Loss: 0.0153  Acc@1: 68.7500 (69.6648)  Acc@5: 100.0000 (94.7634)  time: 0.3446  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [1141/1142]  eta: 0:00:00  Lr: 0.001875  Loss: -0.8294  Acc@1: 68.7500 (69.6742)  Acc@5: 100.0000 (94.7659)  time: 0.3369  data: 0.0003  max mem: 2502
Train: Epoch[5/5] Total time: 0:06:36 (0.3472 s / it)
{0: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 1: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 2: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 3: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 4: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 5: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 6: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 7: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 8: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 9: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 10: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 11: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 12: {0: 0, 1: 0, 2: 0, 3: 91325, 4: 0}, 13: {0: 0, 1: 0, 2: 0, 3: 91325, 4: 0}, 14: {0: 0, 1: 0, 2: 0, 3: 91325, 4: 0}, 15: {0: 0, 1: 0, 2: 0, 3: 91325, 4: 0}, 16: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 17: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 18: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 19: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}}
Averaged stats: Lr: 0.001875  Loss: -0.8294  Acc@1: 68.7500 (69.6742)  Acc@5: 100.0000 (94.7659)
Test: [Task 1]  [   0/1627]  eta: 0:12:28  Loss: 1.5163 (1.5163)  Acc@1: 62.5000 (62.5000)  Acc@5: 93.7500 (93.7500)  time: 0.4600  data: 0.2448  max mem: 2502
Test: [Task 1]  [  10/1627]  eta: 0:06:20  Loss: 1.2128 (1.1799)  Acc@1: 68.7500 (67.0455)  Acc@5: 93.7500 (94.8864)  time: 0.2351  data: 0.0225  max mem: 2502
Test: [Task 1]  [  20/1627]  eta: 0:06:00  Loss: 1.1582 (1.1394)  Acc@1: 68.7500 (69.3452)  Acc@5: 93.7500 (93.1548)  time: 0.2127  data: 0.0002  max mem: 2502
Test: [Task 1]  [  30/1627]  eta: 0:05:52  Loss: 1.1692 (1.1439)  Acc@1: 68.7500 (69.1532)  Acc@5: 93.7500 (92.9435)  time: 0.2129  data: 0.0002  max mem: 2502
Test: [Task 1]  [  40/1627]  eta: 0:05:48  Loss: 1.1549 (1.1490)  Acc@1: 68.7500 (69.3598)  Acc@5: 93.7500 (92.9878)  time: 0.2144  data: 0.0010  max mem: 2502
Test: [Task 1]  [  50/1627]  eta: 0:05:45  Loss: 0.9744 (1.1280)  Acc@1: 75.0000 (70.7108)  Acc@5: 93.7500 (93.1373)  time: 0.2158  data: 0.0013  max mem: 2502
Test: [Task 1]  [  60/1627]  eta: 0:05:41  Loss: 1.0853 (1.1477)  Acc@1: 68.7500 (69.8770)  Acc@5: 93.7500 (92.7254)  time: 0.2155  data: 0.0005  max mem: 2502
Test: [Task 1]  [  70/1627]  eta: 0:05:39  Loss: 0.9928 (1.1407)  Acc@1: 62.5000 (70.5106)  Acc@5: 93.7500 (92.9577)  time: 0.2161  data: 0.0012  max mem: 2502
Test: [Task 1]  [  80/1627]  eta: 0:05:36  Loss: 0.9325 (1.1242)  Acc@1: 75.0000 (70.7562)  Acc@5: 93.7500 (93.1327)  time: 0.2156  data: 0.0012  max mem: 2502
Test: [Task 1]  [  90/1627]  eta: 0:05:34  Loss: 1.0454 (1.1426)  Acc@1: 68.7500 (70.1236)  Acc@5: 93.7500 (92.7885)  time: 0.2152  data: 0.0008  max mem: 2502
Test: [Task 1]  [ 100/1627]  eta: 0:05:31  Loss: 1.3482 (1.1698)  Acc@1: 62.5000 (69.4926)  Acc@5: 87.5000 (92.2030)  time: 0.2154  data: 0.0007  max mem: 2502
Test: [Task 1]  [ 110/1627]  eta: 0:05:29  Loss: 1.1228 (1.1685)  Acc@1: 68.7500 (69.3131)  Acc@5: 93.7500 (92.7365)  time: 0.2152  data: 0.0005  max mem: 2502
Test: [Task 1]  [ 120/1627]  eta: 0:05:26  Loss: 1.1120 (1.1659)  Acc@1: 68.7500 (69.1632)  Acc@5: 93.7500 (92.7686)  time: 0.2154  data: 0.0006  max mem: 2502
Test: [Task 1]  [ 130/1627]  eta: 0:05:24  Loss: 1.1466 (1.1713)  Acc@1: 68.7500 (69.0840)  Acc@5: 93.7500 (92.7481)  time: 0.2150  data: 0.0006  max mem: 2502
Test: [Task 1]  [ 140/1627]  eta: 0:05:22  Loss: 1.1229 (1.1708)  Acc@1: 68.7500 (69.0603)  Acc@5: 93.7500 (92.6418)  time: 0.2148  data: 0.0008  max mem: 2502
Test: [Task 1]  [ 150/1627]  eta: 0:05:19  Loss: 0.8998 (1.1557)  Acc@1: 75.0000 (69.6192)  Acc@5: 93.7500 (92.7980)  time: 0.2151  data: 0.0008  max mem: 2502
Test: [Task 1]  [ 160/1627]  eta: 0:05:17  Loss: 0.8396 (1.1472)  Acc@1: 75.0000 (69.9146)  Acc@5: 93.7500 (92.8960)  time: 0.2152  data: 0.0007  max mem: 2502
Test: [Task 1]  [ 170/1627]  eta: 0:05:15  Loss: 1.0638 (1.1432)  Acc@1: 75.0000 (69.9561)  Acc@5: 93.7500 (92.8363)  time: 0.2151  data: 0.0005  max mem: 2502
Test: [Task 1]  [ 180/1627]  eta: 0:05:12  Loss: 1.0794 (1.1493)  Acc@1: 68.7500 (69.7514)  Acc@5: 93.7500 (92.7486)  time: 0.2154  data: 0.0004  max mem: 2502
Test: [Task 1]  [ 190/1627]  eta: 0:05:10  Loss: 1.1358 (1.1460)  Acc@1: 68.7500 (69.9607)  Acc@5: 93.7500 (92.7356)  time: 0.2156  data: 0.0008  max mem: 2502
Test: [Task 1]  [ 200/1627]  eta: 0:05:08  Loss: 1.1378 (1.1460)  Acc@1: 68.7500 (69.9005)  Acc@5: 93.7500 (92.7861)  time: 0.2157  data: 0.0012  max mem: 2502
Test: [Task 1]  [ 210/1627]  eta: 0:05:06  Loss: 1.1378 (1.1451)  Acc@1: 75.0000 (70.1422)  Acc@5: 93.7500 (92.8318)  time: 0.2166  data: 0.0010  max mem: 2502
Test: [Task 1]  [ 220/1627]  eta: 0:05:04  Loss: 1.0657 (1.1489)  Acc@1: 75.0000 (70.0509)  Acc@5: 93.7500 (92.7602)  time: 0.2162  data: 0.0004  max mem: 2502
Test: [Task 1]  [ 230/1627]  eta: 0:05:01  Loss: 1.1090 (1.1432)  Acc@1: 75.0000 (70.3734)  Acc@5: 93.7500 (92.8030)  time: 0.2146  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 240/1627]  eta: 0:04:59  Loss: 1.0208 (1.1377)  Acc@1: 75.0000 (70.6172)  Acc@5: 93.7500 (92.8164)  time: 0.2142  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 250/1627]  eta: 0:04:57  Loss: 0.9554 (1.1408)  Acc@1: 75.0000 (70.6175)  Acc@5: 93.7500 (92.7789)  time: 0.2136  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 260/1627]  eta: 0:04:55  Loss: 1.0563 (1.1403)  Acc@1: 68.7500 (70.6418)  Acc@5: 93.7500 (92.7921)  time: 0.2130  data: 0.0002  max mem: 2502
Test: [Task 1]  [ 270/1627]  eta: 0:04:52  Loss: 1.0197 (1.1329)  Acc@1: 68.7500 (70.7103)  Acc@5: 93.7500 (92.9197)  time: 0.2128  data: 0.0002  max mem: 2502
Test: [Task 1]  [ 280/1627]  eta: 0:04:50  Loss: 0.9557 (1.1327)  Acc@1: 75.0000 (70.7295)  Acc@5: 93.7500 (92.7936)  time: 0.2127  data: 0.0002  max mem: 2502
Test: [Task 1]  [ 290/1627]  eta: 0:04:48  Loss: 1.1585 (1.1322)  Acc@1: 75.0000 (70.7474)  Acc@5: 93.7500 (92.7835)  time: 0.2133  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 300/1627]  eta: 0:04:45  Loss: 1.0995 (1.1324)  Acc@1: 75.0000 (70.7226)  Acc@5: 93.7500 (92.7741)  time: 0.2142  data: 0.0005  max mem: 2502
Test: [Task 1]  [ 310/1627]  eta: 0:04:43  Loss: 1.0148 (1.1347)  Acc@1: 68.7500 (70.6592)  Acc@5: 93.7500 (92.7653)  time: 0.2151  data: 0.0010  max mem: 2502
Test: [Task 1]  [ 320/1627]  eta: 0:04:41  Loss: 1.1169 (1.1344)  Acc@1: 68.7500 (70.5218)  Acc@5: 93.7500 (92.7960)  time: 0.2164  data: 0.0017  max mem: 2502
Test: [Task 1]  [ 330/1627]  eta: 0:04:39  Loss: 1.0910 (1.1324)  Acc@1: 68.7500 (70.5060)  Acc@5: 93.7500 (92.8059)  time: 0.2179  data: 0.0028  max mem: 2502
Test: [Task 1]  [ 340/1627]  eta: 0:04:37  Loss: 0.9069 (1.1328)  Acc@1: 68.7500 (70.4545)  Acc@5: 93.7500 (92.8702)  time: 0.2171  data: 0.0022  max mem: 2502
Test: [Task 1]  [ 350/1627]  eta: 0:04:35  Loss: 1.0980 (1.1347)  Acc@1: 68.7500 (70.4060)  Acc@5: 93.7500 (92.7885)  time: 0.2153  data: 0.0007  max mem: 2502
Test: [Task 1]  [ 360/1627]  eta: 0:04:33  Loss: 1.0911 (1.1333)  Acc@1: 68.7500 (70.3947)  Acc@5: 87.5000 (92.7458)  time: 0.2149  data: 0.0005  max mem: 2502
Test: [Task 1]  [ 370/1627]  eta: 0:04:31  Loss: 1.0211 (1.1331)  Acc@1: 68.7500 (70.4009)  Acc@5: 93.7500 (92.7729)  time: 0.2151  data: 0.0005  max mem: 2502
Test: [Task 1]  [ 380/1627]  eta: 0:04:28  Loss: 1.0170 (1.1317)  Acc@1: 75.0000 (70.5217)  Acc@5: 93.7500 (92.7493)  time: 0.2158  data: 0.0012  max mem: 2502
Test: [Task 1]  [ 390/1627]  eta: 0:04:26  Loss: 1.0597 (1.1327)  Acc@1: 75.0000 (70.5083)  Acc@5: 93.7500 (92.7590)  time: 0.2161  data: 0.0012  max mem: 2502
Test: [Task 1]  [ 400/1627]  eta: 0:04:24  Loss: 1.1076 (1.1333)  Acc@1: 68.7500 (70.5112)  Acc@5: 93.7500 (92.7681)  time: 0.2151  data: 0.0004  max mem: 2502
Test: [Task 1]  [ 410/1627]  eta: 0:04:22  Loss: 0.9352 (1.1328)  Acc@1: 75.0000 (70.5748)  Acc@5: 93.7500 (92.7616)  time: 0.2148  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 420/1627]  eta: 0:04:20  Loss: 1.0180 (1.1317)  Acc@1: 75.0000 (70.6354)  Acc@5: 93.7500 (92.7999)  time: 0.2155  data: 0.0006  max mem: 2502
Test: [Task 1]  [ 430/1627]  eta: 0:04:18  Loss: 0.9988 (1.1300)  Acc@1: 75.0000 (70.6787)  Acc@5: 93.7500 (92.8509)  time: 0.2161  data: 0.0006  max mem: 2502
Test: [Task 1]  [ 440/1627]  eta: 0:04:15  Loss: 1.1820 (1.1302)  Acc@1: 68.7500 (70.6633)  Acc@5: 93.7500 (92.8713)  time: 0.2160  data: 0.0004  max mem: 2502
Test: [Task 1]  [ 450/1627]  eta: 0:04:13  Loss: 1.2090 (1.1334)  Acc@1: 68.7500 (70.5238)  Acc@5: 93.7500 (92.7661)  time: 0.2170  data: 0.0014  max mem: 2502
Test: [Task 1]  [ 460/1627]  eta: 0:04:11  Loss: 1.1830 (1.1335)  Acc@1: 68.7500 (70.5803)  Acc@5: 93.7500 (92.8010)  time: 0.2174  data: 0.0017  max mem: 2502
Test: [Task 1]  [ 470/1627]  eta: 0:04:09  Loss: 1.0437 (1.1313)  Acc@1: 75.0000 (70.6210)  Acc@5: 93.7500 (92.8079)  time: 0.2169  data: 0.0014  max mem: 2502
Test: [Task 1]  [ 480/1627]  eta: 0:04:07  Loss: 1.0896 (1.1353)  Acc@1: 68.7500 (70.5301)  Acc@5: 93.7500 (92.7495)  time: 0.2164  data: 0.0014  max mem: 2502
Test: [Task 1]  [ 490/1627]  eta: 0:04:05  Loss: 1.1779 (1.1356)  Acc@1: 62.5000 (70.3921)  Acc@5: 93.7500 (92.7571)  time: 0.2169  data: 0.0017  max mem: 2502
Test: [Task 1]  [ 500/1627]  eta: 0:04:03  Loss: 1.0736 (1.1373)  Acc@1: 68.7500 (70.3468)  Acc@5: 93.7500 (92.7146)  time: 0.2188  data: 0.0014  max mem: 2502
Test: [Task 1]  [ 510/1627]  eta: 0:04:01  Loss: 1.1876 (1.1434)  Acc@1: 62.5000 (70.2177)  Acc@5: 87.5000 (92.6859)  time: 0.2178  data: 0.0012  max mem: 2502
Test: [Task 1]  [ 520/1627]  eta: 0:03:58  Loss: 1.3231 (1.1503)  Acc@1: 62.5000 (70.1176)  Acc@5: 87.5000 (92.5864)  time: 0.2157  data: 0.0012  max mem: 2502
Test: [Task 1]  [ 530/1627]  eta: 0:03:56  Loss: 1.1290 (1.1466)  Acc@1: 68.7500 (70.2331)  Acc@5: 93.7500 (92.6201)  time: 0.2150  data: 0.0004  max mem: 2502
Test: [Task 1]  [ 540/1627]  eta: 0:03:54  Loss: 1.0997 (1.1473)  Acc@1: 75.0000 (70.2518)  Acc@5: 93.7500 (92.5832)  time: 0.2142  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 550/1627]  eta: 0:03:52  Loss: 1.2664 (1.1495)  Acc@1: 68.7500 (70.2473)  Acc@5: 93.7500 (92.5817)  time: 0.2134  data: 0.0002  max mem: 2502
Test: [Task 1]  [ 560/1627]  eta: 0:03:50  Loss: 1.2849 (1.1514)  Acc@1: 68.7500 (70.2094)  Acc@5: 93.7500 (92.5691)  time: 0.2134  data: 0.0002  max mem: 2502
Test: [Task 1]  [ 570/1627]  eta: 0:03:47  Loss: 1.1359 (1.1485)  Acc@1: 68.7500 (70.2496)  Acc@5: 93.7500 (92.5898)  time: 0.2135  data: 0.0002  max mem: 2502
Test: [Task 1]  [ 580/1627]  eta: 0:03:45  Loss: 1.1098 (1.1491)  Acc@1: 68.7500 (70.2453)  Acc@5: 93.7500 (92.6097)  time: 0.2136  data: 0.0002  max mem: 2502
Test: [Task 1]  [ 590/1627]  eta: 0:03:43  Loss: 1.1243 (1.1485)  Acc@1: 68.7500 (70.2517)  Acc@5: 93.7500 (92.6713)  time: 0.2155  data: 0.0007  max mem: 2502
Test: [Task 1]  [ 600/1627]  eta: 0:03:41  Loss: 1.1243 (1.1505)  Acc@1: 68.7500 (70.1643)  Acc@5: 93.7500 (92.6269)  time: 0.2169  data: 0.0010  max mem: 2502
Test: [Task 1]  [ 610/1627]  eta: 0:03:39  Loss: 1.1474 (1.1484)  Acc@1: 68.7500 (70.2332)  Acc@5: 93.7500 (92.6759)  time: 0.2164  data: 0.0010  max mem: 2502
Test: [Task 1]  [ 620/1627]  eta: 0:03:37  Loss: 1.0515 (1.1499)  Acc@1: 75.0000 (70.1691)  Acc@5: 93.7500 (92.6429)  time: 0.2164  data: 0.0008  max mem: 2502
Test: [Task 1]  [ 630/1627]  eta: 0:03:35  Loss: 1.0456 (1.1495)  Acc@1: 75.0000 (70.2159)  Acc@5: 93.7500 (92.6506)  time: 0.2173  data: 0.0009  max mem: 2502
Test: [Task 1]  [ 640/1627]  eta: 0:03:32  Loss: 1.0247 (1.1493)  Acc@1: 75.0000 (70.2028)  Acc@5: 93.7500 (92.6580)  time: 0.2176  data: 0.0011  max mem: 2502
Test: [Task 1]  [ 650/1627]  eta: 0:03:30  Loss: 1.0671 (1.1484)  Acc@1: 68.7500 (70.2189)  Acc@5: 93.7500 (92.6651)  time: 0.2167  data: 0.0011  max mem: 2502
Test: [Task 1]  [ 660/1627]  eta: 0:03:28  Loss: 1.0329 (1.1466)  Acc@1: 75.0000 (70.2629)  Acc@5: 93.7500 (92.6532)  time: 0.2163  data: 0.0009  max mem: 2502
Test: [Task 1]  [ 670/1627]  eta: 0:03:26  Loss: 1.0974 (1.1461)  Acc@1: 75.0000 (70.2683)  Acc@5: 93.7500 (92.6509)  time: 0.2162  data: 0.0006  max mem: 2502
Test: [Task 1]  [ 680/1627]  eta: 0:03:24  Loss: 1.1326 (1.1456)  Acc@1: 75.0000 (70.3377)  Acc@5: 93.7500 (92.6395)  time: 0.2174  data: 0.0013  max mem: 2502
Test: [Task 1]  [ 690/1627]  eta: 0:03:22  Loss: 1.1089 (1.1436)  Acc@1: 75.0000 (70.3871)  Acc@5: 93.7500 (92.6827)  time: 0.2177  data: 0.0012  max mem: 2502
Test: [Task 1]  [ 700/1627]  eta: 0:03:20  Loss: 1.1089 (1.1429)  Acc@1: 75.0000 (70.4708)  Acc@5: 93.7500 (92.7247)  time: 0.2162  data: 0.0007  max mem: 2502
Test: [Task 1]  [ 710/1627]  eta: 0:03:17  Loss: 0.9622 (1.1406)  Acc@1: 75.0000 (70.5520)  Acc@5: 93.7500 (92.7655)  time: 0.2155  data: 0.0007  max mem: 2502
Test: [Task 1]  [ 720/1627]  eta: 0:03:15  Loss: 0.9559 (1.1393)  Acc@1: 68.7500 (70.5444)  Acc@5: 93.7500 (92.7878)  time: 0.2153  data: 0.0005  max mem: 2502
Test: [Task 1]  [ 730/1627]  eta: 0:03:13  Loss: 1.1369 (1.1398)  Acc@1: 68.7500 (70.5369)  Acc@5: 93.7500 (92.8010)  time: 0.2157  data: 0.0005  max mem: 2502
Test: [Task 1]  [ 740/1627]  eta: 0:03:11  Loss: 1.1785 (1.1408)  Acc@1: 68.7500 (70.5213)  Acc@5: 93.7500 (92.7969)  time: 0.2165  data: 0.0008  max mem: 2502
Test: [Task 1]  [ 750/1627]  eta: 0:03:09  Loss: 1.0820 (1.1397)  Acc@1: 75.0000 (70.6142)  Acc@5: 93.7500 (92.8096)  time: 0.2165  data: 0.0007  max mem: 2502
Test: [Task 1]  [ 760/1627]  eta: 0:03:07  Loss: 1.0820 (1.1426)  Acc@1: 75.0000 (70.5322)  Acc@5: 93.7500 (92.7809)  time: 0.2162  data: 0.0008  max mem: 2502
Test: [Task 1]  [ 770/1627]  eta: 0:03:04  Loss: 0.9876 (1.1393)  Acc@1: 75.0000 (70.6307)  Acc@5: 93.7500 (92.8178)  time: 0.2160  data: 0.0007  max mem: 2502
Test: [Task 1]  [ 780/1627]  eta: 0:03:02  Loss: 0.8500 (1.1375)  Acc@1: 75.0000 (70.7026)  Acc@5: 93.7500 (92.8297)  time: 0.2153  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 790/1627]  eta: 0:03:00  Loss: 0.9639 (1.1393)  Acc@1: 75.0000 (70.6858)  Acc@5: 93.7500 (92.7860)  time: 0.2146  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 800/1627]  eta: 0:02:58  Loss: 1.0545 (1.1378)  Acc@1: 68.7500 (70.6851)  Acc@5: 93.7500 (92.8215)  time: 0.2140  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 810/1627]  eta: 0:02:56  Loss: 1.0021 (1.1372)  Acc@1: 75.0000 (70.7075)  Acc@5: 100.0000 (92.8406)  time: 0.2136  data: 0.0002  max mem: 2502
Test: [Task 1]  [ 820/1627]  eta: 0:02:54  Loss: 0.9621 (1.1361)  Acc@1: 68.7500 (70.7369)  Acc@5: 100.0000 (92.8517)  time: 0.2134  data: 0.0002  max mem: 2502
Test: [Task 1]  [ 830/1627]  eta: 0:02:51  Loss: 0.9621 (1.1353)  Acc@1: 68.7500 (70.7356)  Acc@5: 93.7500 (92.8625)  time: 0.2134  data: 0.0002  max mem: 2502
Test: [Task 1]  [ 840/1627]  eta: 0:02:49  Loss: 0.8993 (1.1330)  Acc@1: 68.7500 (70.7342)  Acc@5: 93.7500 (92.9102)  time: 0.2143  data: 0.0005  max mem: 2502
Test: [Task 1]  [ 850/1627]  eta: 0:02:47  Loss: 1.1042 (1.1348)  Acc@1: 62.5000 (70.6595)  Acc@5: 93.7500 (92.8981)  time: 0.2153  data: 0.0009  max mem: 2502
Test: [Task 1]  [ 860/1627]  eta: 0:02:45  Loss: 1.1042 (1.1341)  Acc@1: 62.5000 (70.6446)  Acc@5: 93.7500 (92.9225)  time: 0.2161  data: 0.0010  max mem: 2502
Test: [Task 1]  [ 870/1627]  eta: 0:02:43  Loss: 1.0328 (1.1325)  Acc@1: 68.7500 (70.6587)  Acc@5: 93.7500 (92.9248)  time: 0.2176  data: 0.0013  max mem: 2502
Test: [Task 1]  [ 880/1627]  eta: 0:02:41  Loss: 1.1312 (1.1350)  Acc@1: 62.5000 (70.5236)  Acc@5: 93.7500 (92.9342)  time: 0.2179  data: 0.0011  max mem: 2502
Test: [Task 1]  [ 890/1627]  eta: 0:02:39  Loss: 1.2377 (1.1374)  Acc@1: 62.5000 (70.4545)  Acc@5: 93.7500 (92.9012)  time: 0.2175  data: 0.0012  max mem: 2502
Test: [Task 1]  [ 900/1627]  eta: 0:02:36  Loss: 1.2355 (1.1376)  Acc@1: 62.5000 (70.4426)  Acc@5: 93.7500 (92.8898)  time: 0.2167  data: 0.0013  max mem: 2502
Test: [Task 1]  [ 910/1627]  eta: 0:02:34  Loss: 1.2015 (1.1389)  Acc@1: 68.7500 (70.4308)  Acc@5: 93.7500 (92.8238)  time: 0.2171  data: 0.0009  max mem: 2502
Test: [Task 1]  [ 920/1627]  eta: 0:02:32  Loss: 1.1199 (1.1386)  Acc@1: 68.7500 (70.4533)  Acc@5: 93.7500 (92.8407)  time: 0.2186  data: 0.0011  max mem: 2502
Test: [Task 1]  [ 930/1627]  eta: 0:02:30  Loss: 1.1163 (1.1395)  Acc@1: 68.7500 (70.4283)  Acc@5: 93.7500 (92.8303)  time: 0.2168  data: 0.0009  max mem: 2502
Test: [Task 1]  [ 940/1627]  eta: 0:02:28  Loss: 1.1016 (1.1382)  Acc@1: 75.0000 (70.4702)  Acc@5: 93.7500 (92.8600)  time: 0.2158  data: 0.0006  max mem: 2502
Test: [Task 1]  [ 950/1627]  eta: 0:02:26  Loss: 1.1371 (1.1392)  Acc@1: 68.7500 (70.4324)  Acc@5: 93.7500 (92.8693)  time: 0.2165  data: 0.0008  max mem: 2502
Test: [Task 1]  [ 960/1627]  eta: 0:02:23  Loss: 1.1475 (1.1385)  Acc@1: 68.7500 (70.4344)  Acc@5: 93.7500 (92.8655)  time: 0.2164  data: 0.0008  max mem: 2502
Test: [Task 1]  [ 970/1627]  eta: 0:02:21  Loss: 1.0226 (1.1377)  Acc@1: 75.0000 (70.4622)  Acc@5: 93.7500 (92.8553)  time: 0.2162  data: 0.0005  max mem: 2502
Test: [Task 1]  [ 980/1627]  eta: 0:02:19  Loss: 1.0667 (1.1377)  Acc@1: 75.0000 (70.4702)  Acc@5: 93.7500 (92.8644)  time: 0.2163  data: 0.0006  max mem: 2502
Test: [Task 1]  [ 990/1627]  eta: 0:02:17  Loss: 1.1863 (1.1406)  Acc@1: 68.7500 (70.4402)  Acc@5: 93.7500 (92.8418)  time: 0.2172  data: 0.0013  max mem: 2502
Test: [Task 1]  [1000/1627]  eta: 0:02:15  Loss: 1.2524 (1.1407)  Acc@1: 68.7500 (70.4545)  Acc@5: 93.7500 (92.8009)  time: 0.2210  data: 0.0025  max mem: 2502
Test: [Task 1]  [1010/1627]  eta: 0:02:13  Loss: 1.1097 (1.1404)  Acc@1: 75.0000 (70.4686)  Acc@5: 93.7500 (92.7980)  time: 0.2193  data: 0.0016  max mem: 2502
Test: [Task 1]  [1020/1627]  eta: 0:02:11  Loss: 1.0337 (1.1398)  Acc@1: 75.0000 (70.4885)  Acc@5: 93.7500 (92.8073)  time: 0.2148  data: 0.0003  max mem: 2502
Test: [Task 1]  [1030/1627]  eta: 0:02:08  Loss: 0.9337 (1.1378)  Acc@1: 75.0000 (70.5626)  Acc@5: 93.7500 (92.8346)  time: 0.2176  data: 0.0004  max mem: 2502
Test: [Task 1]  [1040/1627]  eta: 0:02:06  Loss: 0.8364 (1.1357)  Acc@1: 81.2500 (70.6352)  Acc@5: 93.7500 (92.8554)  time: 0.2169  data: 0.0003  max mem: 2502
Test: [Task 1]  [1050/1627]  eta: 0:02:04  Loss: 0.9433 (1.1343)  Acc@1: 75.0000 (70.6529)  Acc@5: 93.7500 (92.8818)  time: 0.2136  data: 0.0002  max mem: 2502
Test: [Task 1]  [1060/1627]  eta: 0:02:02  Loss: 1.1124 (1.1347)  Acc@1: 68.7500 (70.6762)  Acc@5: 93.7500 (92.8664)  time: 0.2136  data: 0.0002  max mem: 2502
Test: [Task 1]  [1070/1627]  eta: 0:02:00  Loss: 1.1648 (1.1350)  Acc@1: 68.7500 (70.6874)  Acc@5: 93.7500 (92.8571)  time: 0.2135  data: 0.0002  max mem: 2502
Test: [Task 1]  [1080/1627]  eta: 0:01:58  Loss: 1.0922 (1.1359)  Acc@1: 68.7500 (70.6811)  Acc@5: 93.7500 (92.8654)  time: 0.2138  data: 0.0005  max mem: 2502
Test: [Task 1]  [1090/1627]  eta: 0:01:55  Loss: 1.0922 (1.1357)  Acc@1: 75.0000 (70.7149)  Acc@5: 93.7500 (92.8563)  time: 0.2155  data: 0.0010  max mem: 2502
Test: [Task 1]  [1100/1627]  eta: 0:01:53  Loss: 0.9970 (1.1336)  Acc@1: 75.0000 (70.7766)  Acc@5: 100.0000 (92.8928)  time: 0.2161  data: 0.0009  max mem: 2502
Test: [Task 1]  [1110/1627]  eta: 0:01:51  Loss: 0.9907 (1.1334)  Acc@1: 75.0000 (70.7977)  Acc@5: 100.0000 (92.9062)  time: 0.2165  data: 0.0009  max mem: 2502
Test: [Task 1]  [1120/1627]  eta: 0:01:49  Loss: 1.1015 (1.1348)  Acc@1: 62.5000 (70.7181)  Acc@5: 93.7500 (92.9193)  time: 0.2167  data: 0.0013  max mem: 2502
Test: [Task 1]  [1130/1627]  eta: 0:01:47  Loss: 1.0562 (1.1354)  Acc@1: 62.5000 (70.7118)  Acc@5: 93.7500 (92.9211)  time: 0.2166  data: 0.0012  max mem: 2502
Test: [Task 1]  [1140/1627]  eta: 0:01:45  Loss: 1.0468 (1.1364)  Acc@1: 68.7500 (70.7055)  Acc@5: 93.7500 (92.8900)  time: 0.2169  data: 0.0011  max mem: 2502
Test: [Task 1]  [1150/1627]  eta: 0:01:42  Loss: 1.2685 (1.1371)  Acc@1: 68.7500 (70.6722)  Acc@5: 93.7500 (92.8866)  time: 0.2159  data: 0.0006  max mem: 2502
Test: [Task 1]  [1160/1627]  eta: 0:01:40  Loss: 1.1671 (1.1360)  Acc@1: 68.7500 (70.7257)  Acc@5: 93.7500 (92.8941)  time: 0.2162  data: 0.0006  max mem: 2502
Test: [Task 1]  [1170/1627]  eta: 0:01:38  Loss: 1.0792 (1.1351)  Acc@1: 75.0000 (70.7462)  Acc@5: 93.7500 (92.9067)  time: 0.2170  data: 0.0008  max mem: 2502
Test: [Task 1]  [1180/1627]  eta: 0:01:36  Loss: 1.0961 (1.1357)  Acc@1: 75.0000 (70.7504)  Acc@5: 93.7500 (92.9191)  time: 0.2164  data: 0.0007  max mem: 2502
Test: [Task 1]  [1190/1627]  eta: 0:01:34  Loss: 1.1798 (1.1364)  Acc@1: 68.7500 (70.7074)  Acc@5: 93.7500 (92.8999)  time: 0.2157  data: 0.0008  max mem: 2502
Test: [Task 1]  [1200/1627]  eta: 0:01:32  Loss: 1.1596 (1.1364)  Acc@1: 68.7500 (70.6859)  Acc@5: 93.7500 (92.8965)  time: 0.2154  data: 0.0009  max mem: 2502
Test: [Task 1]  [1210/1627]  eta: 0:01:30  Loss: 1.0025 (1.1370)  Acc@1: 68.7500 (70.6647)  Acc@5: 93.7500 (92.8675)  time: 0.2155  data: 0.0007  max mem: 2502
Test: [Task 1]  [1220/1627]  eta: 0:01:27  Loss: 1.0067 (1.1361)  Acc@1: 68.7500 (70.6798)  Acc@5: 93.7500 (92.8696)  time: 0.2159  data: 0.0007  max mem: 2502
Test: [Task 1]  [1230/1627]  eta: 0:01:25  Loss: 1.1060 (1.1366)  Acc@1: 68.7500 (70.6387)  Acc@5: 93.7500 (92.8666)  time: 0.2163  data: 0.0008  max mem: 2502
Test: [Task 1]  [1240/1627]  eta: 0:01:23  Loss: 1.1429 (1.1363)  Acc@1: 68.7500 (70.6537)  Acc@5: 93.7500 (92.8687)  time: 0.2178  data: 0.0016  max mem: 2502
Test: [Task 1]  [1250/1627]  eta: 0:01:21  Loss: 1.2227 (1.1367)  Acc@1: 68.7500 (70.6435)  Acc@5: 93.7500 (92.8707)  time: 0.2174  data: 0.0013  max mem: 2502
Test: [Task 1]  [1260/1627]  eta: 0:01:19  Loss: 1.2032 (1.1365)  Acc@1: 68.7500 (70.6879)  Acc@5: 93.7500 (92.8678)  time: 0.2153  data: 0.0006  max mem: 2502
Test: [Task 1]  [1270/1627]  eta: 0:01:17  Loss: 1.0256 (1.1372)  Acc@1: 68.7500 (70.6481)  Acc@5: 93.7500 (92.8501)  time: 0.2149  data: 0.0005  max mem: 2502
Test: [Task 1]  [1280/1627]  eta: 0:01:14  Loss: 0.9999 (1.1359)  Acc@1: 68.7500 (70.6723)  Acc@5: 93.7500 (92.8571)  time: 0.2169  data: 0.0004  max mem: 2502
Test: [Task 1]  [1290/1627]  eta: 0:01:12  Loss: 1.0580 (1.1362)  Acc@1: 68.7500 (70.6381)  Acc@5: 93.7500 (92.8592)  time: 0.2163  data: 0.0003  max mem: 2502
Test: [Task 1]  [1300/1627]  eta: 0:01:10  Loss: 1.0580 (1.1355)  Acc@1: 75.0000 (70.6764)  Acc@5: 93.7500 (92.8661)  time: 0.2135  data: 0.0002  max mem: 2502
Test: [Task 1]  [1310/1627]  eta: 0:01:08  Loss: 0.8993 (1.1342)  Acc@1: 81.2500 (70.7285)  Acc@5: 93.7500 (92.8776)  time: 0.2135  data: 0.0002  max mem: 2502
Test: [Task 1]  [1320/1627]  eta: 0:01:06  Loss: 0.8343 (1.1326)  Acc@1: 81.2500 (70.7986)  Acc@5: 93.7500 (92.8936)  time: 0.2134  data: 0.0002  max mem: 2502
Test: [Task 1]  [1330/1627]  eta: 0:01:04  Loss: 0.9130 (1.1322)  Acc@1: 75.0000 (70.8161)  Acc@5: 93.7500 (92.8860)  time: 0.2135  data: 0.0002  max mem: 2502
Test: [Task 1]  [1340/1627]  eta: 0:01:01  Loss: 1.0784 (1.1329)  Acc@1: 75.0000 (70.8007)  Acc@5: 93.7500 (92.8924)  time: 0.2153  data: 0.0011  max mem: 2502
Test: [Task 1]  [1350/1627]  eta: 0:00:59  Loss: 1.0745 (1.1323)  Acc@1: 75.0000 (70.8179)  Acc@5: 93.7500 (92.8988)  time: 0.2165  data: 0.0014  max mem: 2502
Test: [Task 1]  [1360/1627]  eta: 0:00:57  Loss: 1.0022 (1.1318)  Acc@1: 75.0000 (70.8257)  Acc@5: 93.7500 (92.9142)  time: 0.2176  data: 0.0017  max mem: 2502
Test: [Task 1]  [1370/1627]  eta: 0:00:55  Loss: 1.0022 (1.1309)  Acc@1: 68.7500 (70.8242)  Acc@5: 93.7500 (92.9385)  time: 0.2179  data: 0.0015  max mem: 2502
Test: [Task 1]  [1380/1627]  eta: 0:00:53  Loss: 1.0743 (1.1312)  Acc@1: 68.7500 (70.8273)  Acc@5: 93.7500 (92.9308)  time: 0.2159  data: 0.0004  max mem: 2502
Test: [Task 1]  [1390/1627]  eta: 0:00:51  Loss: 1.2512 (1.1308)  Acc@1: 68.7500 (70.8079)  Acc@5: 93.7500 (92.9457)  time: 0.2156  data: 0.0005  max mem: 2502
Test: [Task 1]  [1400/1627]  eta: 0:00:49  Loss: 1.1810 (1.1310)  Acc@1: 68.7500 (70.8200)  Acc@5: 93.7500 (92.9247)  time: 0.2162  data: 0.0008  max mem: 2502
Test: [Task 1]  [1410/1627]  eta: 0:00:46  Loss: 0.9328 (1.1302)  Acc@1: 75.0000 (70.8584)  Acc@5: 93.7500 (92.9394)  time: 0.2159  data: 0.0007  max mem: 2502
Test: [Task 1]  [1420/1627]  eta: 0:00:44  Loss: 1.0098 (1.1295)  Acc@1: 75.0000 (70.8568)  Acc@5: 93.7500 (92.9627)  time: 0.2164  data: 0.0009  max mem: 2502
Test: [Task 1]  [1430/1627]  eta: 0:00:42  Loss: 1.2028 (1.1312)  Acc@1: 68.7500 (70.8508)  Acc@5: 93.7500 (92.9289)  time: 0.2177  data: 0.0013  max mem: 2502
Test: [Task 1]  [1440/1627]  eta: 0:00:40  Loss: 1.1962 (1.1307)  Acc@1: 68.7500 (70.8232)  Acc@5: 93.7500 (92.9433)  time: 0.2179  data: 0.0016  max mem: 2502
Test: [Task 1]  [1450/1627]  eta: 0:00:38  Loss: 1.1910 (1.1320)  Acc@1: 68.7500 (70.7917)  Acc@5: 93.7500 (92.9230)  time: 0.2163  data: 0.0012  max mem: 2502
Test: [Task 1]  [1460/1627]  eta: 0:00:36  Loss: 1.1910 (1.1323)  Acc@1: 62.5000 (70.7777)  Acc@5: 93.7500 (92.9244)  time: 0.2162  data: 0.0010  max mem: 2502
Test: [Task 1]  [1470/1627]  eta: 0:00:33  Loss: 1.1445 (1.1326)  Acc@1: 75.0000 (70.7724)  Acc@5: 93.7500 (92.9130)  time: 0.2164  data: 0.0011  max mem: 2502
Test: [Task 1]  [1480/1627]  eta: 0:00:31  Loss: 1.2129 (1.1330)  Acc@1: 75.0000 (70.7630)  Acc@5: 93.7500 (92.9144)  time: 0.2157  data: 0.0006  max mem: 2502
Test: [Task 1]  [1490/1627]  eta: 0:00:29  Loss: 1.1759 (1.1334)  Acc@1: 68.7500 (70.7872)  Acc@5: 93.7500 (92.9074)  time: 0.2160  data: 0.0010  max mem: 2502
Test: [Task 1]  [1500/1627]  eta: 0:00:27  Loss: 1.1223 (1.1337)  Acc@1: 68.7500 (70.7903)  Acc@5: 93.7500 (92.8964)  time: 0.2167  data: 0.0016  max mem: 2502
Test: [Task 1]  [1510/1627]  eta: 0:00:25  Loss: 0.9176 (1.1334)  Acc@1: 68.7500 (70.7975)  Acc@5: 93.7500 (92.9021)  time: 0.2176  data: 0.0013  max mem: 2502
Test: [Task 1]  [1520/1627]  eta: 0:00:23  Loss: 0.9176 (1.1321)  Acc@1: 75.0000 (70.8333)  Acc@5: 93.7500 (92.9241)  time: 0.2163  data: 0.0005  max mem: 2502
Test: [Task 1]  [1530/1627]  eta: 0:00:20  Loss: 0.8798 (1.1314)  Acc@1: 75.0000 (70.8279)  Acc@5: 100.0000 (92.9458)  time: 0.2150  data: 0.0003  max mem: 2502
Test: [Task 1]  [1540/1627]  eta: 0:00:18  Loss: 0.9660 (1.1306)  Acc@1: 68.7500 (70.8387)  Acc@5: 100.0000 (92.9672)  time: 0.2156  data: 0.0003  max mem: 2502
Test: [Task 1]  [1550/1627]  eta: 0:00:16  Loss: 0.9497 (1.1301)  Acc@1: 75.0000 (70.8454)  Acc@5: 100.0000 (92.9844)  time: 0.2147  data: 0.0003  max mem: 2502
Test: [Task 1]  [1560/1627]  eta: 0:00:14  Loss: 0.9148 (1.1291)  Acc@1: 75.0000 (70.8680)  Acc@5: 100.0000 (93.0053)  time: 0.2134  data: 0.0002  max mem: 2502
Test: [Task 1]  [1570/1627]  eta: 0:00:12  Loss: 0.9863 (1.1289)  Acc@1: 68.7500 (70.8705)  Acc@5: 100.0000 (93.0021)  time: 0.2134  data: 0.0002  max mem: 2502
Test: [Task 1]  [1580/1627]  eta: 0:00:10  Loss: 1.0231 (1.1290)  Acc@1: 68.7500 (70.8689)  Acc@5: 93.7500 (92.9910)  time: 0.2136  data: 0.0002  max mem: 2502
Test: [Task 1]  [1590/1627]  eta: 0:00:07  Loss: 1.0660 (1.1288)  Acc@1: 68.7500 (70.8635)  Acc@5: 93.7500 (93.0075)  time: 0.2137  data: 0.0002  max mem: 2502
Test: [Task 1]  [1600/1627]  eta: 0:00:05  Loss: 1.1068 (1.1298)  Acc@1: 68.7500 (70.8190)  Acc@5: 93.7500 (92.9849)  time: 0.2153  data: 0.0010  max mem: 2502
Test: [Task 1]  [1610/1627]  eta: 0:00:03  Loss: 1.0976 (1.1292)  Acc@1: 68.7500 (70.8178)  Acc@5: 93.7500 (92.9935)  time: 0.2168  data: 0.0013  max mem: 2502
Test: [Task 1]  [1620/1627]  eta: 0:00:01  Loss: 0.9231 (1.1281)  Acc@1: 75.0000 (70.8475)  Acc@5: 93.7500 (93.0020)  time: 0.2167  data: 0.0008  max mem: 2502
Test: [Task 1]  [1626/1627]  eta: 0:00:00  Loss: 0.9068 (1.1276)  Acc@1: 75.0000 (70.8666)  Acc@5: 93.7500 (92.9971)  time: 0.2171  data: 0.0007  max mem: 2502
Test: [Task 1] Total time: 0:05:51 (0.2161 s / it)
* Acc@1 70.867 Acc@5 92.997 loss 1.128
Test: [Task 2]  [  0/625]  eta: 0:06:11  Loss: 0.2389 (0.2389)  Acc@1: 93.7500 (93.7500)  Acc@5: 100.0000 (100.0000)  time: 0.5938  data: 0.3796  max mem: 2502
Test: [Task 2]  [ 10/625]  eta: 0:02:34  Loss: 0.2389 (0.2684)  Acc@1: 93.7500 (92.0455)  Acc@5: 100.0000 (99.4318)  time: 0.2509  data: 0.0352  max mem: 2502
Test: [Task 2]  [ 20/625]  eta: 0:02:21  Loss: 0.2241 (0.2815)  Acc@1: 93.7500 (90.7738)  Acc@5: 100.0000 (99.7024)  time: 0.2166  data: 0.0010  max mem: 2502
Test: [Task 2]  [ 30/625]  eta: 0:02:16  Loss: 0.3210 (0.3008)  Acc@1: 93.7500 (90.1210)  Acc@5: 100.0000 (99.3952)  time: 0.2165  data: 0.0009  max mem: 2502
Test: [Task 2]  [ 40/625]  eta: 0:02:11  Loss: 0.2941 (0.3054)  Acc@1: 93.7500 (90.3963)  Acc@5: 100.0000 (99.3902)  time: 0.2160  data: 0.0005  max mem: 2502
Test: [Task 2]  [ 50/625]  eta: 0:02:08  Loss: 0.3290 (0.3193)  Acc@1: 87.5000 (90.0735)  Acc@5: 100.0000 (99.3873)  time: 0.2159  data: 0.0006  max mem: 2502
Test: [Task 2]  [ 60/625]  eta: 0:02:05  Loss: 0.3290 (0.3244)  Acc@1: 87.5000 (89.6516)  Acc@5: 100.0000 (99.3852)  time: 0.2164  data: 0.0012  max mem: 2502
Test: [Task 2]  [ 70/625]  eta: 0:02:02  Loss: 0.3088 (0.3227)  Acc@1: 87.5000 (89.7007)  Acc@5: 100.0000 (99.3838)  time: 0.2156  data: 0.0010  max mem: 2502
Test: [Task 2]  [ 80/625]  eta: 0:02:00  Loss: 0.2734 (0.3276)  Acc@1: 87.5000 (89.8920)  Acc@5: 100.0000 (99.1512)  time: 0.2155  data: 0.0008  max mem: 2502
Test: [Task 2]  [ 90/625]  eta: 0:01:57  Loss: 0.2734 (0.3230)  Acc@1: 93.7500 (90.1099)  Acc@5: 100.0000 (99.2445)  time: 0.2162  data: 0.0011  max mem: 2502
Test: [Task 2]  [100/625]  eta: 0:01:55  Loss: 0.2771 (0.3178)  Acc@1: 87.5000 (90.2228)  Acc@5: 100.0000 (99.2574)  time: 0.2158  data: 0.0007  max mem: 2502
Test: [Task 2]  [110/625]  eta: 0:01:52  Loss: 0.3015 (0.3235)  Acc@1: 87.5000 (90.1464)  Acc@5: 100.0000 (99.1554)  time: 0.2152  data: 0.0005  max mem: 2502
Test: [Task 2]  [120/625]  eta: 0:01:50  Loss: 0.3425 (0.3264)  Acc@1: 87.5000 (90.0826)  Acc@5: 100.0000 (99.0702)  time: 0.2159  data: 0.0010  max mem: 2502
Test: [Task 2]  [130/625]  eta: 0:01:48  Loss: 0.3425 (0.3249)  Acc@1: 93.7500 (90.3626)  Acc@5: 100.0000 (99.1412)  time: 0.2174  data: 0.0010  max mem: 2502
Test: [Task 2]  [140/625]  eta: 0:01:46  Loss: 0.2908 (0.3284)  Acc@1: 93.7500 (90.1596)  Acc@5: 100.0000 (99.1135)  time: 0.2167  data: 0.0005  max mem: 2502
Test: [Task 2]  [150/625]  eta: 0:01:43  Loss: 0.3009 (0.3315)  Acc@1: 87.5000 (89.8593)  Acc@5: 100.0000 (99.1308)  time: 0.2151  data: 0.0004  max mem: 2502
Test: [Task 2]  [160/625]  eta: 0:01:41  Loss: 0.3320 (0.3364)  Acc@1: 87.5000 (89.7127)  Acc@5: 100.0000 (99.0683)  time: 0.2146  data: 0.0003  max mem: 2502
Test: [Task 2]  [170/625]  eta: 0:01:39  Loss: 0.3615 (0.3348)  Acc@1: 93.7500 (89.9488)  Acc@5: 100.0000 (99.0497)  time: 0.2138  data: 0.0003  max mem: 2502
Test: [Task 2]  [180/625]  eta: 0:01:36  Loss: 0.2850 (0.3313)  Acc@1: 93.7500 (90.0898)  Acc@5: 100.0000 (99.1022)  time: 0.2132  data: 0.0002  max mem: 2502
Test: [Task 2]  [190/625]  eta: 0:01:34  Loss: 0.3256 (0.3346)  Acc@1: 87.5000 (90.0524)  Acc@5: 100.0000 (99.0838)  time: 0.2131  data: 0.0002  max mem: 2502
Test: [Task 2]  [200/625]  eta: 0:01:32  Loss: 0.4048 (0.3361)  Acc@1: 87.5000 (89.9876)  Acc@5: 100.0000 (99.0672)  time: 0.2131  data: 0.0002  max mem: 2502
Test: [Task 2]  [210/625]  eta: 0:01:30  Loss: 0.3658 (0.3388)  Acc@1: 87.5000 (89.9585)  Acc@5: 100.0000 (98.9929)  time: 0.2142  data: 0.0007  max mem: 2502
Test: [Task 2]  [220/625]  eta: 0:01:27  Loss: 0.2586 (0.3356)  Acc@1: 93.7500 (90.1301)  Acc@5: 100.0000 (99.0102)  time: 0.2153  data: 0.0010  max mem: 2502
Test: [Task 2]  [230/625]  eta: 0:01:25  Loss: 0.2586 (0.3339)  Acc@1: 93.7500 (90.2597)  Acc@5: 100.0000 (99.0530)  time: 0.2154  data: 0.0007  max mem: 2502
Test: [Task 2]  [240/625]  eta: 0:01:23  Loss: 0.3397 (0.3339)  Acc@1: 93.7500 (90.2749)  Acc@5: 100.0000 (99.0145)  time: 0.2149  data: 0.0004  max mem: 2502
Test: [Task 2]  [250/625]  eta: 0:01:21  Loss: 0.3397 (0.3357)  Acc@1: 93.7500 (90.3386)  Acc@5: 100.0000 (98.9791)  time: 0.2157  data: 0.0013  max mem: 2502
Test: [Task 2]  [260/625]  eta: 0:01:19  Loss: 0.3291 (0.3371)  Acc@1: 87.5000 (90.2538)  Acc@5: 100.0000 (98.9703)  time: 0.2162  data: 0.0019  max mem: 2502
Test: [Task 2]  [270/625]  eta: 0:01:16  Loss: 0.3291 (0.3380)  Acc@1: 87.5000 (90.2445)  Acc@5: 100.0000 (98.9852)  time: 0.2156  data: 0.0010  max mem: 2502
Test: [Task 2]  [280/625]  eta: 0:01:14  Loss: 0.2724 (0.3389)  Acc@1: 87.5000 (90.1246)  Acc@5: 100.0000 (98.9991)  time: 0.2167  data: 0.0013  max mem: 2502
Test: [Task 2]  [290/625]  eta: 0:01:12  Loss: 0.2724 (0.3395)  Acc@1: 87.5000 (90.1203)  Acc@5: 100.0000 (98.9905)  time: 0.2175  data: 0.0020  max mem: 2502
Test: [Task 2]  [300/625]  eta: 0:01:10  Loss: 0.3004 (0.3403)  Acc@1: 87.5000 (90.0540)  Acc@5: 100.0000 (99.0241)  time: 0.2165  data: 0.0013  max mem: 2502
Test: [Task 2]  [310/625]  eta: 0:01:08  Loss: 0.3268 (0.3411)  Acc@1: 87.5000 (89.9518)  Acc@5: 100.0000 (99.0153)  time: 0.2162  data: 0.0006  max mem: 2502
Test: [Task 2]  [320/625]  eta: 0:01:06  Loss: 0.1703 (0.3337)  Acc@1: 93.7500 (90.2259)  Acc@5: 100.0000 (99.0460)  time: 0.2159  data: 0.0004  max mem: 2502
Test: [Task 2]  [330/625]  eta: 0:01:03  Loss: 0.1392 (0.3317)  Acc@1: 93.7500 (90.1813)  Acc@5: 100.0000 (99.0748)  time: 0.2153  data: 0.0004  max mem: 2502
Test: [Task 2]  [340/625]  eta: 0:01:01  Loss: 0.0985 (0.3242)  Acc@1: 93.7500 (90.4509)  Acc@5: 100.0000 (99.1019)  time: 0.2156  data: 0.0006  max mem: 2502
Test: [Task 2]  [350/625]  eta: 0:00:59  Loss: 0.0922 (0.3216)  Acc@1: 100.0000 (90.4558)  Acc@5: 100.0000 (99.1275)  time: 0.2163  data: 0.0009  max mem: 2502
Test: [Task 2]  [360/625]  eta: 0:00:57  Loss: 0.2942 (0.3228)  Acc@1: 87.5000 (90.4778)  Acc@5: 100.0000 (99.1170)  time: 0.2163  data: 0.0010  max mem: 2502
Test: [Task 2]  [370/625]  eta: 0:00:55  Loss: 0.2257 (0.3200)  Acc@1: 93.7500 (90.5492)  Acc@5: 100.0000 (99.1408)  time: 0.2160  data: 0.0009  max mem: 2502
Test: [Task 2]  [380/625]  eta: 0:00:53  Loss: 0.2729 (0.3225)  Acc@1: 93.7500 (90.4528)  Acc@5: 100.0000 (99.0978)  time: 0.2157  data: 0.0007  max mem: 2502
Test: [Task 2]  [390/625]  eta: 0:00:50  Loss: 0.2644 (0.3210)  Acc@1: 93.7500 (90.4572)  Acc@5: 100.0000 (99.0889)  time: 0.2154  data: 0.0005  max mem: 2502
Test: [Task 2]  [400/625]  eta: 0:00:48  Loss: 0.1202 (0.3166)  Acc@1: 93.7500 (90.5860)  Acc@5: 100.0000 (99.1116)  time: 0.2151  data: 0.0005  max mem: 2502
Test: [Task 2]  [410/625]  eta: 0:00:46  Loss: 0.0821 (0.3144)  Acc@1: 93.7500 (90.6782)  Acc@5: 100.0000 (99.1028)  time: 0.2150  data: 0.0003  max mem: 2502
Test: [Task 2]  [420/625]  eta: 0:00:44  Loss: 0.0909 (0.3135)  Acc@1: 100.0000 (90.7512)  Acc@5: 100.0000 (99.1241)  time: 0.2146  data: 0.0003  max mem: 2502
Test: [Task 2]  [430/625]  eta: 0:00:42  Loss: 0.2266 (0.3127)  Acc@1: 93.7500 (90.7628)  Acc@5: 100.0000 (99.1444)  time: 0.2139  data: 0.0003  max mem: 2502
Test: [Task 2]  [440/625]  eta: 0:00:40  Loss: 0.1581 (0.3081)  Acc@1: 93.7500 (90.9297)  Acc@5: 100.0000 (99.1638)  time: 0.2135  data: 0.0002  max mem: 2502
Test: [Task 2]  [450/625]  eta: 0:00:37  Loss: 0.1163 (0.3040)  Acc@1: 93.7500 (91.0200)  Acc@5: 100.0000 (99.1824)  time: 0.2136  data: 0.0002  max mem: 2502
Test: [Task 2]  [460/625]  eta: 0:00:35  Loss: 0.1170 (0.3003)  Acc@1: 100.0000 (91.1876)  Acc@5: 100.0000 (99.2001)  time: 0.2134  data: 0.0002  max mem: 2502
Test: [Task 2]  [470/625]  eta: 0:00:33  Loss: 0.1450 (0.2976)  Acc@1: 100.0000 (91.3482)  Acc@5: 100.0000 (99.2171)  time: 0.2144  data: 0.0006  max mem: 2502
Test: [Task 2]  [480/625]  eta: 0:00:31  Loss: 0.1779 (0.2950)  Acc@1: 100.0000 (91.4371)  Acc@5: 100.0000 (99.2334)  time: 0.2158  data: 0.0007  max mem: 2502
Test: [Task 2]  [490/625]  eta: 0:00:29  Loss: 0.1373 (0.2924)  Acc@1: 100.0000 (91.5733)  Acc@5: 100.0000 (99.2490)  time: 0.2164  data: 0.0006  max mem: 2502
Test: [Task 2]  [500/625]  eta: 0:00:27  Loss: 0.1318 (0.2899)  Acc@1: 100.0000 (91.6791)  Acc@5: 100.0000 (99.2640)  time: 0.2165  data: 0.0007  max mem: 2502
Test: [Task 2]  [510/625]  eta: 0:00:24  Loss: 0.1693 (0.2933)  Acc@1: 93.7500 (91.5729)  Acc@5: 100.0000 (99.2784)  time: 0.2163  data: 0.0009  max mem: 2502
Test: [Task 2]  [520/625]  eta: 0:00:22  Loss: 0.2283 (0.2938)  Acc@1: 93.7500 (91.5307)  Acc@5: 100.0000 (99.2802)  time: 0.2163  data: 0.0008  max mem: 2502
Test: [Task 2]  [530/625]  eta: 0:00:20  Loss: 0.1579 (0.2914)  Acc@1: 93.7500 (91.6314)  Acc@5: 100.0000 (99.2938)  time: 0.2160  data: 0.0007  max mem: 2502
Test: [Task 2]  [540/625]  eta: 0:00:18  Loss: 0.1101 (0.2891)  Acc@1: 100.0000 (91.7167)  Acc@5: 100.0000 (99.2953)  time: 0.2162  data: 0.0007  max mem: 2502
Test: [Task 2]  [550/625]  eta: 0:00:16  Loss: 0.0807 (0.2855)  Acc@1: 100.0000 (91.8444)  Acc@5: 100.0000 (99.3081)  time: 0.2167  data: 0.0006  max mem: 2502
Test: [Task 2]  [560/625]  eta: 0:00:14  Loss: 0.0618 (0.2814)  Acc@1: 100.0000 (91.9898)  Acc@5: 100.0000 (99.3204)  time: 0.2172  data: 0.0008  max mem: 2502
Test: [Task 2]  [570/625]  eta: 0:00:11  Loss: 0.0653 (0.2815)  Acc@1: 100.0000 (91.9440)  Acc@5: 100.0000 (99.3323)  time: 0.2183  data: 0.0016  max mem: 2502
Test: [Task 2]  [580/625]  eta: 0:00:09  Loss: 0.1020 (0.2786)  Acc@1: 93.7500 (92.0503)  Acc@5: 100.0000 (99.3438)  time: 0.2179  data: 0.0020  max mem: 2502
Test: [Task 2]  [590/625]  eta: 0:00:07  Loss: 0.0989 (0.2765)  Acc@1: 100.0000 (92.1214)  Acc@5: 100.0000 (99.3549)  time: 0.2163  data: 0.0012  max mem: 2502
Test: [Task 2]  [600/625]  eta: 0:00:05  Loss: 0.1711 (0.2767)  Acc@1: 93.7500 (92.0861)  Acc@5: 100.0000 (99.3552)  time: 0.2167  data: 0.0009  max mem: 2502
Test: [Task 2]  [610/625]  eta: 0:00:03  Loss: 0.3101 (0.2791)  Acc@1: 87.5000 (92.0315)  Acc@5: 100.0000 (99.3146)  time: 0.2170  data: 0.0011  max mem: 2502
Test: [Task 2]  [620/625]  eta: 0:00:01  Loss: 0.3595 (0.2802)  Acc@1: 87.5000 (91.9988)  Acc@5: 100.0000 (99.3156)  time: 0.2161  data: 0.0006  max mem: 2502
Test: [Task 2]  [624/625]  eta: 0:00:00  Loss: 0.2833 (0.2798)  Acc@1: 93.7500 (92.0200)  Acc@5: 100.0000 (99.3200)  time: 0.2162  data: 0.0005  max mem: 2502
Test: [Task 2] Total time: 0:02:15 (0.2166 s / it)
* Acc@1 92.020 Acc@5 99.320 loss 0.280
Test: [Task 3]  [  0/625]  eta: 0:06:56  Loss: 0.0818 (0.0818)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)  time: 0.6660  data: 0.4509  max mem: 2502
Test: [Task 3]  [ 10/625]  eta: 0:02:38  Loss: 0.2605 (0.2141)  Acc@1: 100.0000 (97.1591)  Acc@5: 100.0000 (99.4318)  time: 0.2575  data: 0.0424  max mem: 2502
Test: [Task 3]  [ 20/625]  eta: 0:02:23  Loss: 0.2243 (0.2285)  Acc@1: 100.0000 (96.7262)  Acc@5: 100.0000 (99.4048)  time: 0.2162  data: 0.0013  max mem: 2502
Test: [Task 3]  [ 30/625]  eta: 0:02:17  Loss: 0.1958 (0.2391)  Acc@1: 93.7500 (96.3710)  Acc@5: 100.0000 (99.3952)  time: 0.2171  data: 0.0011  max mem: 2502
Test: [Task 3]  [ 40/625]  eta: 0:02:13  Loss: 0.1289 (0.2089)  Acc@1: 100.0000 (96.9512)  Acc@5: 100.0000 (99.5427)  time: 0.2175  data: 0.0008  max mem: 2502
Test: [Task 3]  [ 50/625]  eta: 0:02:09  Loss: 0.1311 (0.2073)  Acc@1: 100.0000 (96.9363)  Acc@5: 100.0000 (99.6324)  time: 0.2156  data: 0.0003  max mem: 2502
Test: [Task 3]  [ 60/625]  eta: 0:02:06  Loss: 0.1725 (0.2039)  Acc@1: 100.0000 (97.1311)  Acc@5: 100.0000 (99.6926)  time: 0.2151  data: 0.0003  max mem: 2502
Test: [Task 3]  [ 70/625]  eta: 0:02:03  Loss: 0.1409 (0.1952)  Acc@1: 100.0000 (97.2711)  Acc@5: 100.0000 (99.6479)  time: 0.2148  data: 0.0003  max mem: 2502
Test: [Task 3]  [ 80/625]  eta: 0:02:00  Loss: 0.1477 (0.1981)  Acc@1: 100.0000 (97.1451)  Acc@5: 100.0000 (99.6914)  time: 0.2136  data: 0.0002  max mem: 2502
Test: [Task 3]  [ 90/625]  eta: 0:01:57  Loss: 0.1500 (0.1970)  Acc@1: 100.0000 (97.1841)  Acc@5: 100.0000 (99.6566)  time: 0.2134  data: 0.0002  max mem: 2502
Test: [Task 3]  [100/625]  eta: 0:01:55  Loss: 0.1430 (0.1927)  Acc@1: 100.0000 (97.4010)  Acc@5: 100.0000 (99.6906)  time: 0.2134  data: 0.0002  max mem: 2502
Test: [Task 3]  [110/625]  eta: 0:01:52  Loss: 0.1282 (0.1853)  Acc@1: 100.0000 (97.6351)  Acc@5: 100.0000 (99.7185)  time: 0.2135  data: 0.0002  max mem: 2502
Test: [Task 3]  [120/625]  eta: 0:01:50  Loss: 0.1282 (0.1879)  Acc@1: 100.0000 (97.5723)  Acc@5: 100.0000 (99.7417)  time: 0.2147  data: 0.0004  max mem: 2502
Test: [Task 3]  [130/625]  eta: 0:01:48  Loss: 0.1905 (0.1882)  Acc@1: 100.0000 (97.5191)  Acc@5: 100.0000 (99.7137)  time: 0.2162  data: 0.0010  max mem: 2502
Test: [Task 3]  [140/625]  eta: 0:01:45  Loss: 0.2085 (0.1948)  Acc@1: 93.7500 (97.3404)  Acc@5: 100.0000 (99.6454)  time: 0.2164  data: 0.0008  max mem: 2502
Test: [Task 3]  [150/625]  eta: 0:01:43  Loss: 0.2152 (0.2010)  Acc@1: 93.7500 (97.1854)  Acc@5: 100.0000 (99.5861)  time: 0.2159  data: 0.0005  max mem: 2502
Test: [Task 3]  [160/625]  eta: 0:01:41  Loss: 0.1564 (0.2014)  Acc@1: 100.0000 (97.2826)  Acc@5: 100.0000 (99.5342)  time: 0.2160  data: 0.0006  max mem: 2502
Test: [Task 3]  [170/625]  eta: 0:01:39  Loss: 0.1148 (0.1989)  Acc@1: 100.0000 (97.3319)  Acc@5: 100.0000 (99.5614)  time: 0.2161  data: 0.0008  max mem: 2502
Test: [Task 3]  [180/625]  eta: 0:01:36  Loss: 0.1917 (0.2026)  Acc@1: 100.0000 (97.2030)  Acc@5: 100.0000 (99.4820)  time: 0.2163  data: 0.0009  max mem: 2502
Test: [Task 3]  [190/625]  eta: 0:01:34  Loss: 0.2197 (0.2017)  Acc@1: 93.7500 (97.1531)  Acc@5: 100.0000 (99.5092)  time: 0.2165  data: 0.0007  max mem: 2502
Test: [Task 3]  [200/625]  eta: 0:01:32  Loss: 0.2144 (0.2033)  Acc@1: 93.7500 (97.0149)  Acc@5: 100.0000 (99.5025)  time: 0.2163  data: 0.0006  max mem: 2502
Test: [Task 3]  [210/625]  eta: 0:01:30  Loss: 0.2144 (0.2042)  Acc@1: 93.7500 (96.9787)  Acc@5: 100.0000 (99.4372)  time: 0.2163  data: 0.0006  max mem: 2502
Test: [Task 3]  [220/625]  eta: 0:01:28  Loss: 0.1758 (0.2050)  Acc@1: 100.0000 (96.9740)  Acc@5: 100.0000 (99.3778)  time: 0.2162  data: 0.0007  max mem: 2502
Test: [Task 3]  [230/625]  eta: 0:01:25  Loss: 0.1851 (0.2053)  Acc@1: 100.0000 (96.9426)  Acc@5: 100.0000 (99.3777)  time: 0.2169  data: 0.0018  max mem: 2502
Test: [Task 3]  [240/625]  eta: 0:01:23  Loss: 0.1642 (0.2085)  Acc@1: 93.7500 (96.8880)  Acc@5: 100.0000 (99.3517)  time: 0.2167  data: 0.0016  max mem: 2502
Test: [Task 3]  [250/625]  eta: 0:01:21  Loss: 0.1197 (0.2057)  Acc@1: 100.0000 (96.9622)  Acc@5: 100.0000 (99.3775)  time: 0.2153  data: 0.0004  max mem: 2502
Test: [Task 3]  [260/625]  eta: 0:01:19  Loss: 0.1278 (0.2044)  Acc@1: 100.0000 (96.9588)  Acc@5: 100.0000 (99.3774)  time: 0.2154  data: 0.0004  max mem: 2502
Test: [Task 3]  [270/625]  eta: 0:01:17  Loss: 0.1324 (0.2039)  Acc@1: 100.0000 (96.9557)  Acc@5: 100.0000 (99.3773)  time: 0.2153  data: 0.0004  max mem: 2502
Test: [Task 3]  [280/625]  eta: 0:01:14  Loss: 0.1421 (0.2035)  Acc@1: 100.0000 (96.9528)  Acc@5: 100.0000 (99.3772)  time: 0.2154  data: 0.0006  max mem: 2502
Test: [Task 3]  [290/625]  eta: 0:01:12  Loss: 0.1576 (0.2039)  Acc@1: 100.0000 (96.9502)  Acc@5: 100.0000 (99.3771)  time: 0.2154  data: 0.0006  max mem: 2502
Test: [Task 3]  [300/625]  eta: 0:01:10  Loss: 0.1662 (0.2099)  Acc@1: 100.0000 (96.7400)  Acc@5: 100.0000 (99.2733)  time: 0.2160  data: 0.0006  max mem: 2502
Test: [Task 3]  [310/625]  eta: 0:01:08  Loss: 0.1415 (0.2112)  Acc@1: 100.0000 (96.7042)  Acc@5: 100.0000 (99.2564)  time: 0.2168  data: 0.0013  max mem: 2502
Test: [Task 3]  [320/625]  eta: 0:01:06  Loss: 0.1415 (0.2102)  Acc@1: 100.0000 (96.7095)  Acc@5: 100.0000 (99.2407)  time: 0.2160  data: 0.0013  max mem: 2502
Test: [Task 3]  [330/625]  eta: 0:01:04  Loss: 0.2022 (0.2112)  Acc@1: 93.7500 (96.6956)  Acc@5: 100.0000 (99.2447)  time: 0.2152  data: 0.0005  max mem: 2502
Test: [Task 3]  [340/625]  eta: 0:01:01  Loss: 0.1479 (0.2088)  Acc@1: 100.0000 (96.7375)  Acc@5: 100.0000 (99.2669)  time: 0.2141  data: 0.0003  max mem: 2502
Test: [Task 3]  [350/625]  eta: 0:00:59  Loss: 0.1311 (0.2090)  Acc@1: 100.0000 (96.7236)  Acc@5: 100.0000 (99.2699)  time: 0.2133  data: 0.0002  max mem: 2502
Test: [Task 3]  [360/625]  eta: 0:00:57  Loss: 0.1705 (0.2100)  Acc@1: 93.7500 (96.6586)  Acc@5: 100.0000 (99.2902)  time: 0.2135  data: 0.0002  max mem: 2502
Test: [Task 3]  [370/625]  eta: 0:00:55  Loss: 0.1997 (0.2101)  Acc@1: 93.7500 (96.6307)  Acc@5: 100.0000 (99.2756)  time: 0.2134  data: 0.0002  max mem: 2502
Test: [Task 3]  [380/625]  eta: 0:00:53  Loss: 0.1421 (0.2084)  Acc@1: 100.0000 (96.6699)  Acc@5: 100.0000 (99.2946)  time: 0.2133  data: 0.0002  max mem: 2502
Test: [Task 3]  [390/625]  eta: 0:00:50  Loss: 0.1226 (0.2082)  Acc@1: 100.0000 (96.6432)  Acc@5: 100.0000 (99.3127)  time: 0.2141  data: 0.0003  max mem: 2502
Test: [Task 3]  [400/625]  eta: 0:00:48  Loss: 0.1378 (0.2079)  Acc@1: 93.7500 (96.6022)  Acc@5: 100.0000 (99.3142)  time: 0.2155  data: 0.0007  max mem: 2502
Test: [Task 3]  [410/625]  eta: 0:00:46  Loss: 0.1477 (0.2084)  Acc@1: 93.7500 (96.6241)  Acc@5: 100.0000 (99.3157)  time: 0.2163  data: 0.0011  max mem: 2502
Test: [Task 3]  [420/625]  eta: 0:00:44  Loss: 0.1580 (0.2082)  Acc@1: 100.0000 (96.5855)  Acc@5: 100.0000 (99.3171)  time: 0.2161  data: 0.0008  max mem: 2502
Test: [Task 3]  [430/625]  eta: 0:00:42  Loss: 0.1619 (0.2081)  Acc@1: 93.7500 (96.5632)  Acc@5: 100.0000 (99.3184)  time: 0.2152  data: 0.0004  max mem: 2502
Test: [Task 3]  [440/625]  eta: 0:00:40  Loss: 0.1994 (0.2089)  Acc@1: 93.7500 (96.5136)  Acc@5: 100.0000 (99.3056)  time: 0.2152  data: 0.0006  max mem: 2502
Test: [Task 3]  [450/625]  eta: 0:00:37  Loss: 0.1714 (0.2083)  Acc@1: 100.0000 (96.5355)  Acc@5: 100.0000 (99.3210)  time: 0.2160  data: 0.0011  max mem: 2502
Test: [Task 3]  [460/625]  eta: 0:00:35  Loss: 0.1552 (0.2075)  Acc@1: 100.0000 (96.5428)  Acc@5: 100.0000 (99.3221)  time: 0.2160  data: 0.0010  max mem: 2502
Test: [Task 3]  [470/625]  eta: 0:00:33  Loss: 0.1676 (0.2076)  Acc@1: 100.0000 (96.5366)  Acc@5: 100.0000 (99.3232)  time: 0.2167  data: 0.0012  max mem: 2502
Test: [Task 3]  [480/625]  eta: 0:00:31  Loss: 0.1679 (0.2084)  Acc@1: 100.0000 (96.5437)  Acc@5: 100.0000 (99.3243)  time: 0.2172  data: 0.0016  max mem: 2502
Test: [Task 3]  [490/625]  eta: 0:00:29  Loss: 0.1716 (0.2085)  Acc@1: 100.0000 (96.5377)  Acc@5: 100.0000 (99.3126)  time: 0.2172  data: 0.0015  max mem: 2502
Test: [Task 3]  [500/625]  eta: 0:00:27  Loss: 0.1052 (0.2073)  Acc@1: 100.0000 (96.5694)  Acc@5: 100.0000 (99.3263)  time: 0.2170  data: 0.0010  max mem: 2502
Test: [Task 3]  [510/625]  eta: 0:00:24  Loss: 0.1046 (0.2061)  Acc@1: 100.0000 (96.5876)  Acc@5: 100.0000 (99.3395)  time: 0.2161  data: 0.0005  max mem: 2502
Test: [Task 3]  [520/625]  eta: 0:00:22  Loss: 0.1466 (0.2061)  Acc@1: 100.0000 (96.5931)  Acc@5: 100.0000 (99.3522)  time: 0.2159  data: 0.0008  max mem: 2502
Test: [Task 3]  [530/625]  eta: 0:00:20  Loss: 0.1895 (0.2070)  Acc@1: 93.7500 (96.5278)  Acc@5: 100.0000 (99.3644)  time: 0.2156  data: 0.0009  max mem: 2502
Test: [Task 3]  [540/625]  eta: 0:00:18  Loss: 0.1821 (0.2079)  Acc@1: 93.7500 (96.5226)  Acc@5: 100.0000 (99.3646)  time: 0.2162  data: 0.0010  max mem: 2502
Test: [Task 3]  [550/625]  eta: 0:00:16  Loss: 0.1821 (0.2083)  Acc@1: 93.7500 (96.5177)  Acc@5: 100.0000 (99.3648)  time: 0.2168  data: 0.0013  max mem: 2502
Test: [Task 3]  [560/625]  eta: 0:00:14  Loss: 0.1786 (0.2082)  Acc@1: 100.0000 (96.5352)  Acc@5: 100.0000 (99.3650)  time: 0.2161  data: 0.0010  max mem: 2502
Test: [Task 3]  [570/625]  eta: 0:00:11  Loss: 0.1765 (0.2077)  Acc@1: 100.0000 (96.5302)  Acc@5: 100.0000 (99.3761)  time: 0.2160  data: 0.0012  max mem: 2502
Test: [Task 3]  [580/625]  eta: 0:00:09  Loss: 0.2146 (0.2092)  Acc@1: 93.7500 (96.4824)  Acc@5: 100.0000 (99.3761)  time: 0.2170  data: 0.0015  max mem: 2502
Test: [Task 3]  [590/625]  eta: 0:00:07  Loss: 0.1822 (0.2084)  Acc@1: 100.0000 (96.5207)  Acc@5: 100.0000 (99.3866)  time: 0.2163  data: 0.0010  max mem: 2502
Test: [Task 3]  [600/625]  eta: 0:00:05  Loss: 0.1762 (0.2087)  Acc@1: 100.0000 (96.4850)  Acc@5: 100.0000 (99.3760)  time: 0.2147  data: 0.0004  max mem: 2502
Test: [Task 3]  [610/625]  eta: 0:00:03  Loss: 0.1706 (0.2080)  Acc@1: 93.7500 (96.4812)  Acc@5: 100.0000 (99.3863)  time: 0.2146  data: 0.0003  max mem: 2502
Test: [Task 3]  [620/625]  eta: 0:00:01  Loss: 0.1848 (0.2087)  Acc@1: 93.7500 (96.4573)  Acc@5: 100.0000 (99.3861)  time: 0.2144  data: 0.0003  max mem: 2502
Test: [Task 3]  [624/625]  eta: 0:00:00  Loss: 0.1463 (0.2080)  Acc@1: 100.0000 (96.4800)  Acc@5: 100.0000 (99.3900)  time: 0.2142  data: 0.0002  max mem: 2502
Test: [Task 3] Total time: 0:02:15 (0.2165 s / it)
* Acc@1 96.480 Acc@5 99.390 loss 0.208
Test: [Task 4]  [ 0/29]  eta: 0:00:13  Loss: 1.4058 (1.4058)  Acc@1: 56.2500 (56.2500)  Acc@5: 93.7500 (93.7500)  time: 0.4691  data: 0.2564  max mem: 2502
Test: [Task 4]  [10/29]  eta: 0:00:04  Loss: 1.5823 (1.6562)  Acc@1: 56.2500 (54.5455)  Acc@5: 87.5000 (89.2045)  time: 0.2365  data: 0.0235  max mem: 2502
Test: [Task 4]  [20/29]  eta: 0:00:02  Loss: 1.5442 (1.6282)  Acc@1: 56.2500 (57.4405)  Acc@5: 87.5000 (87.2024)  time: 0.2136  data: 0.0003  max mem: 2502
Test: [Task 4]  [28/29]  eta: 0:00:00  Loss: 1.3731 (1.5105)  Acc@1: 62.5000 (60.7843)  Acc@5: 87.5000 (87.7996)  time: 0.2176  data: 0.0002  max mem: 2502
Test: [Task 4] Total time: 0:00:06 (0.2280 s / it)
* Acc@1 60.784 Acc@5 87.800 loss 1.510
{0: {0: 26032, 1: 26032, 2: 26032, 3: 26032, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0, 10: 0, 11: 0, 12: 0, 13: 0, 14: 0, 15: 0, 16: 0, 17: 0, 18: 0, 19: 0}, 1: {0: 0, 1: 0, 2: 0, 3: 0, 4: 10000, 5: 10000, 6: 10000, 7: 10000, 8: 0, 9: 0, 10: 0, 11: 0, 12: 0, 13: 0, 14: 0, 15: 0, 16: 0, 17: 0, 18: 0, 19: 0}, 2: {0: 16, 1: 16, 2: 16, 3: 16, 4: 0, 5: 0, 6: 0, 7: 0, 8: 9984, 9: 9984, 10: 9984, 11: 9984, 12: 0, 13: 0, 14: 0, 15: 0, 16: 0, 17: 0, 18: 0, 19: 0}, 3: {0: 0, 1: 0, 2: 0, 3: 0, 4: 176, 5: 176, 6: 176, 7: 176, 8: 0, 9: 0, 10: 0, 11: 0, 12: 283, 13: 283, 14: 283, 15: 283, 16: 0, 17: 0, 18: 0, 19: 0}}
[Average accuracy till task4]	Acc@1: 80.0377	Acc@5: 94.8767	Loss: 0.7815	Forgetting: 5.0933	Backward: -5.0933
Train: Epoch[1/5]  [   0/3750]  eta: 0:53:08  Lr: 0.001875  Loss: 1.4499  Acc@1: 0.0000 (0.0000)  Acc@5: 37.5000 (37.5000)  time: 0.8502  data: 0.4598  max mem: 2502
Train: Epoch[1/5]  [  10/3750]  eta: 0:24:35  Lr: 0.001875  Loss: 1.1647  Acc@1: 25.0000 (24.4318)  Acc@5: 81.2500 (69.8864)  time: 0.3945  data: 0.0430  max mem: 2503
Train: Epoch[1/5]  [  20/3750]  eta: 0:23:09  Lr: 0.001875  Loss: 1.0053  Acc@1: 31.2500 (32.4405)  Acc@5: 87.5000 (80.6548)  time: 0.3487  data: 0.0012  max mem: 2503
Train: Epoch[1/5]  [  30/3750]  eta: 0:22:37  Lr: 0.001875  Loss: 0.8877  Acc@1: 43.7500 (38.7097)  Acc@5: 93.7500 (85.0806)  time: 0.3487  data: 0.0018  max mem: 2503
Train: Epoch[1/5]  [  40/3750]  eta: 0:22:17  Lr: 0.001875  Loss: 0.5437  Acc@1: 50.0000 (43.2927)  Acc@5: 93.7500 (87.1951)  time: 0.3478  data: 0.0016  max mem: 2503
Train: Epoch[1/5]  [  50/3750]  eta: 0:22:04  Lr: 0.001875  Loss: -0.0309  Acc@1: 68.7500 (48.5294)  Acc@5: 93.7500 (88.8480)  time: 0.3472  data: 0.0011  max mem: 2503
Train: Epoch[1/5]  [  60/3750]  eta: 0:21:55  Lr: 0.001875  Loss: 0.0637  Acc@1: 68.7500 (52.4590)  Acc@5: 100.0000 (90.2664)  time: 0.3484  data: 0.0018  max mem: 2503
Train: Epoch[1/5]  [  70/3750]  eta: 0:21:46  Lr: 0.001875  Loss: 0.3029  Acc@1: 68.7500 (55.0176)  Acc@5: 100.0000 (91.3732)  time: 0.3478  data: 0.0016  max mem: 2503
Train: Epoch[1/5]  [  80/3750]  eta: 0:21:39  Lr: 0.001875  Loss: -0.1729  Acc@1: 62.5000 (56.4043)  Acc@5: 100.0000 (91.9753)  time: 0.3463  data: 0.0008  max mem: 2503
Train: Epoch[1/5]  [  90/3750]  eta: 0:21:32  Lr: 0.001875  Loss: 0.1865  Acc@1: 62.5000 (56.7995)  Acc@5: 100.0000 (92.6511)  time: 0.3463  data: 0.0006  max mem: 2503
Train: Epoch[1/5]  [ 100/3750]  eta: 0:21:27  Lr: 0.001875  Loss: 0.1062  Acc@1: 62.5000 (57.8589)  Acc@5: 100.0000 (93.0693)  time: 0.3479  data: 0.0010  max mem: 2503
Train: Epoch[1/5]  [ 110/3750]  eta: 0:21:21  Lr: 0.001875  Loss: -0.2254  Acc@1: 68.7500 (58.7838)  Acc@5: 100.0000 (93.5248)  time: 0.3474  data: 0.0010  max mem: 2503
Train: Epoch[1/5]  [ 120/3750]  eta: 0:21:16  Lr: 0.001875  Loss: -0.2232  Acc@1: 68.7500 (59.6591)  Acc@5: 100.0000 (93.8533)  time: 0.3460  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [ 130/3750]  eta: 0:21:10  Lr: 0.001875  Loss: -0.1923  Acc@1: 68.7500 (60.4485)  Acc@5: 100.0000 (94.2271)  time: 0.3454  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [ 140/3750]  eta: 0:21:05  Lr: 0.001875  Loss: -0.3087  Acc@1: 75.0000 (61.4805)  Acc@5: 100.0000 (94.5479)  time: 0.3447  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [ 150/3750]  eta: 0:21:00  Lr: 0.001875  Loss: -0.5662  Acc@1: 68.7500 (62.0033)  Acc@5: 100.0000 (94.6192)  time: 0.3447  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [ 160/3750]  eta: 0:20:56  Lr: 0.001875  Loss: -0.3113  Acc@1: 62.5000 (62.2283)  Acc@5: 100.0000 (94.7981)  time: 0.3454  data: 0.0007  max mem: 2503
Train: Epoch[1/5]  [ 170/3750]  eta: 0:20:52  Lr: 0.001875  Loss: -0.0712  Acc@1: 68.7500 (63.0117)  Acc@5: 100.0000 (94.9927)  time: 0.3475  data: 0.0011  max mem: 2503
Train: Epoch[1/5]  [ 180/3750]  eta: 0:20:48  Lr: 0.001875  Loss: -0.2553  Acc@1: 75.0000 (63.5359)  Acc@5: 100.0000 (95.1657)  time: 0.3484  data: 0.0011  max mem: 2503
Train: Epoch[1/5]  [ 190/3750]  eta: 0:20:44  Lr: 0.001875  Loss: -0.4916  Acc@1: 75.0000 (63.9071)  Acc@5: 100.0000 (95.2552)  time: 0.3472  data: 0.0008  max mem: 2503
Train: Epoch[1/5]  [ 200/3750]  eta: 0:20:40  Lr: 0.001875  Loss: -0.2852  Acc@1: 75.0000 (64.3346)  Acc@5: 100.0000 (95.4602)  time: 0.3469  data: 0.0006  max mem: 2503
Train: Epoch[1/5]  [ 210/3750]  eta: 0:20:37  Lr: 0.001875  Loss: -0.3736  Acc@1: 75.0000 (64.6327)  Acc@5: 100.0000 (95.5273)  time: 0.3482  data: 0.0016  max mem: 2503
Train: Epoch[1/5]  [ 220/3750]  eta: 0:20:33  Lr: 0.001875  Loss: -0.2010  Acc@1: 68.7500 (64.8190)  Acc@5: 100.0000 (95.7014)  time: 0.3489  data: 0.0020  max mem: 2503
Train: Epoch[1/5]  [ 230/3750]  eta: 0:20:29  Lr: 0.001875  Loss: -0.0297  Acc@1: 62.5000 (64.9892)  Acc@5: 100.0000 (95.8063)  time: 0.3475  data: 0.0010  max mem: 2503
Train: Epoch[1/5]  [ 240/3750]  eta: 0:20:25  Lr: 0.001875  Loss: -0.4543  Acc@1: 68.7500 (65.2230)  Acc@5: 100.0000 (95.9025)  time: 0.3470  data: 0.0011  max mem: 2503
Train: Epoch[1/5]  [ 250/3750]  eta: 0:20:22  Lr: 0.001875  Loss: -0.6533  Acc@1: 68.7500 (65.5876)  Acc@5: 100.0000 (95.9910)  time: 0.3477  data: 0.0010  max mem: 2503
Train: Epoch[1/5]  [ 260/3750]  eta: 0:20:18  Lr: 0.001875  Loss: -0.4605  Acc@1: 75.0000 (66.0201)  Acc@5: 100.0000 (96.0249)  time: 0.3474  data: 0.0006  max mem: 2503
Train: Epoch[1/5]  [ 270/3750]  eta: 0:20:14  Lr: 0.001875  Loss: -0.2135  Acc@1: 75.0000 (66.1208)  Acc@5: 93.7500 (96.0332)  time: 0.3468  data: 0.0008  max mem: 2503
Train: Epoch[1/5]  [ 280/3750]  eta: 0:20:10  Lr: 0.001875  Loss: 0.0562  Acc@1: 75.0000 (66.5036)  Acc@5: 100.0000 (96.1299)  time: 0.3459  data: 0.0006  max mem: 2503
Train: Epoch[1/5]  [ 290/3750]  eta: 0:20:07  Lr: 0.001875  Loss: -0.6039  Acc@1: 75.0000 (66.7955)  Acc@5: 100.0000 (96.1770)  time: 0.3478  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [ 300/3750]  eta: 0:20:03  Lr: 0.001875  Loss: -0.2352  Acc@1: 75.0000 (67.0473)  Acc@5: 100.0000 (96.2209)  time: 0.3474  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [ 310/3750]  eta: 0:19:59  Lr: 0.001875  Loss: 0.1479  Acc@1: 75.0000 (67.2629)  Acc@5: 100.0000 (96.2621)  time: 0.3437  data: 0.0002  max mem: 2503
Train: Epoch[1/5]  [ 320/3750]  eta: 0:19:55  Lr: 0.001875  Loss: -0.6358  Acc@1: 75.0000 (67.5234)  Acc@5: 100.0000 (96.2812)  time: 0.3432  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [ 330/3750]  eta: 0:19:51  Lr: 0.001875  Loss: -0.0766  Acc@1: 75.0000 (67.6171)  Acc@5: 100.0000 (96.3369)  time: 0.3453  data: 0.0010  max mem: 2503
Train: Epoch[1/5]  [ 340/3750]  eta: 0:19:48  Lr: 0.001875  Loss: -0.4301  Acc@1: 68.7500 (67.5403)  Acc@5: 100.0000 (96.3893)  time: 0.3475  data: 0.0013  max mem: 2503
Train: Epoch[1/5]  [ 350/3750]  eta: 0:19:44  Lr: 0.001875  Loss: -0.4936  Acc@1: 68.7500 (67.6638)  Acc@5: 100.0000 (96.4566)  time: 0.3494  data: 0.0008  max mem: 2503
Train: Epoch[1/5]  [ 360/3750]  eta: 0:19:41  Lr: 0.001875  Loss: -0.4810  Acc@1: 68.7500 (67.8151)  Acc@5: 100.0000 (96.4508)  time: 0.3500  data: 0.0008  max mem: 2503
Train: Epoch[1/5]  [ 370/3750]  eta: 0:19:37  Lr: 0.001875  Loss: -0.7207  Acc@1: 81.2500 (68.0425)  Acc@5: 100.0000 (96.5128)  time: 0.3477  data: 0.0009  max mem: 2503
Train: Epoch[1/5]  [ 380/3750]  eta: 0:19:34  Lr: 0.001875  Loss: -0.4319  Acc@1: 75.0000 (68.0118)  Acc@5: 100.0000 (96.5879)  time: 0.3486  data: 0.0019  max mem: 2503
Train: Epoch[1/5]  [ 390/3750]  eta: 0:19:31  Lr: 0.001875  Loss: -0.2310  Acc@1: 68.7500 (68.1426)  Acc@5: 100.0000 (96.6432)  time: 0.3506  data: 0.0028  max mem: 2503
Train: Epoch[1/5]  [ 400/3750]  eta: 0:19:27  Lr: 0.001875  Loss: -0.0021  Acc@1: 75.0000 (68.2980)  Acc@5: 100.0000 (96.6490)  time: 0.3487  data: 0.0018  max mem: 2503
Train: Epoch[1/5]  [ 410/3750]  eta: 0:19:23  Lr: 0.001875  Loss: -0.4493  Acc@1: 75.0000 (68.5219)  Acc@5: 100.0000 (96.7305)  time: 0.3466  data: 0.0009  max mem: 2503
Train: Epoch[1/5]  [ 420/3750]  eta: 0:19:20  Lr: 0.001875  Loss: -0.3513  Acc@1: 75.0000 (68.5867)  Acc@5: 100.0000 (96.7637)  time: 0.3465  data: 0.0010  max mem: 2503
Train: Epoch[1/5]  [ 430/3750]  eta: 0:19:16  Lr: 0.001875  Loss: -0.1968  Acc@1: 62.5000 (68.5760)  Acc@5: 100.0000 (96.7662)  time: 0.3469  data: 0.0011  max mem: 2503
Train: Epoch[1/5]  [ 440/3750]  eta: 0:19:13  Lr: 0.001875  Loss: -0.1028  Acc@1: 68.7500 (68.6508)  Acc@5: 100.0000 (96.7829)  time: 0.3474  data: 0.0012  max mem: 2503
Train: Epoch[1/5]  [ 450/3750]  eta: 0:19:09  Lr: 0.001875  Loss: -0.7655  Acc@1: 75.0000 (68.9024)  Acc@5: 100.0000 (96.8542)  time: 0.3480  data: 0.0013  max mem: 2503
Train: Epoch[1/5]  [ 460/3750]  eta: 0:19:06  Lr: 0.001875  Loss: -0.5416  Acc@1: 75.0000 (68.9940)  Acc@5: 100.0000 (96.8953)  time: 0.3478  data: 0.0009  max mem: 2503
Train: Epoch[1/5]  [ 470/3750]  eta: 0:19:02  Lr: 0.001875  Loss: -0.2908  Acc@1: 75.0000 (69.1746)  Acc@5: 100.0000 (96.9347)  time: 0.3463  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [ 480/3750]  eta: 0:18:58  Lr: 0.001875  Loss: -0.4714  Acc@1: 75.0000 (69.2568)  Acc@5: 100.0000 (96.9725)  time: 0.3443  data: 0.0002  max mem: 2503
Train: Epoch[1/5]  [ 490/3750]  eta: 0:18:54  Lr: 0.001875  Loss: -0.2528  Acc@1: 75.0000 (69.3865)  Acc@5: 100.0000 (97.0087)  time: 0.3429  data: 0.0002  max mem: 2503
Train: Epoch[1/5]  [ 500/3750]  eta: 0:18:51  Lr: 0.001875  Loss: -0.6610  Acc@1: 75.0000 (69.5734)  Acc@5: 100.0000 (97.0185)  time: 0.3444  data: 0.0009  max mem: 2503
Train: Epoch[1/5]  [ 510/3750]  eta: 0:18:47  Lr: 0.001875  Loss: -1.0080  Acc@1: 75.0000 (69.6918)  Acc@5: 100.0000 (97.0523)  time: 0.3472  data: 0.0013  max mem: 2503
Train: Epoch[1/5]  [ 520/3750]  eta: 0:18:44  Lr: 0.001875  Loss: -0.7998  Acc@1: 75.0000 (69.8656)  Acc@5: 100.0000 (97.0729)  time: 0.3476  data: 0.0008  max mem: 2503
Train: Epoch[1/5]  [ 530/3750]  eta: 0:18:40  Lr: 0.001875  Loss: -0.4447  Acc@1: 75.0000 (69.8682)  Acc@5: 100.0000 (97.1163)  time: 0.3484  data: 0.0015  max mem: 2503
Train: Epoch[1/5]  [ 540/3750]  eta: 0:18:37  Lr: 0.001875  Loss: -0.4267  Acc@1: 75.0000 (70.0555)  Acc@5: 100.0000 (97.1234)  time: 0.3495  data: 0.0018  max mem: 2503
Train: Epoch[1/5]  [ 550/3750]  eta: 0:18:33  Lr: 0.001875  Loss: -0.5432  Acc@1: 75.0000 (70.0998)  Acc@5: 100.0000 (97.1416)  time: 0.3488  data: 0.0011  max mem: 2503
Train: Epoch[1/5]  [ 560/3750]  eta: 0:18:30  Lr: 0.001875  Loss: -0.2956  Acc@1: 68.7500 (70.1092)  Acc@5: 100.0000 (97.1702)  time: 0.3497  data: 0.0010  max mem: 2503
Train: Epoch[1/5]  [ 570/3750]  eta: 0:18:26  Lr: 0.001875  Loss: -0.4026  Acc@1: 68.7500 (70.1511)  Acc@5: 100.0000 (97.1760)  time: 0.3489  data: 0.0009  max mem: 2503
Train: Epoch[1/5]  [ 580/3750]  eta: 0:18:23  Lr: 0.001875  Loss: -0.4114  Acc@1: 75.0000 (70.2775)  Acc@5: 100.0000 (97.1923)  time: 0.3473  data: 0.0013  max mem: 2503
Train: Epoch[1/5]  [ 590/3750]  eta: 0:18:19  Lr: 0.001875  Loss: -0.6121  Acc@1: 75.0000 (70.3997)  Acc@5: 100.0000 (97.2187)  time: 0.3479  data: 0.0013  max mem: 2503
Train: Epoch[1/5]  [ 600/3750]  eta: 0:18:16  Lr: 0.001875  Loss: -0.3404  Acc@1: 75.0000 (70.4971)  Acc@5: 100.0000 (97.2338)  time: 0.3478  data: 0.0006  max mem: 2503
Train: Epoch[1/5]  [ 610/3750]  eta: 0:18:13  Lr: 0.001875  Loss: -0.2749  Acc@1: 75.0000 (70.6117)  Acc@5: 100.0000 (97.2484)  time: 0.3488  data: 0.0019  max mem: 2503
Train: Epoch[1/5]  [ 620/3750]  eta: 0:18:09  Lr: 0.001875  Loss: -0.4548  Acc@1: 75.0000 (70.6824)  Acc@5: 100.0000 (97.2524)  time: 0.3505  data: 0.0023  max mem: 2503
Train: Epoch[1/5]  [ 630/3750]  eta: 0:18:06  Lr: 0.001875  Loss: -0.6125  Acc@1: 75.0000 (70.7607)  Acc@5: 100.0000 (97.2761)  time: 0.3484  data: 0.0009  max mem: 2503
Train: Epoch[1/5]  [ 640/3750]  eta: 0:18:02  Lr: 0.001875  Loss: -0.5001  Acc@1: 75.0000 (70.7976)  Acc@5: 100.0000 (97.2991)  time: 0.3449  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [ 650/3750]  eta: 0:17:58  Lr: 0.001875  Loss: -0.3509  Acc@1: 75.0000 (70.8141)  Acc@5: 100.0000 (97.3118)  time: 0.3437  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [ 660/3750]  eta: 0:17:55  Lr: 0.001875  Loss: -0.1511  Acc@1: 75.0000 (70.8396)  Acc@5: 100.0000 (97.3336)  time: 0.3432  data: 0.0002  max mem: 2503
Train: Epoch[1/5]  [ 670/3750]  eta: 0:17:51  Lr: 0.001875  Loss: -0.4197  Acc@1: 75.0000 (70.8923)  Acc@5: 100.0000 (97.3361)  time: 0.3439  data: 0.0002  max mem: 2503
Train: Epoch[1/5]  [ 680/3750]  eta: 0:17:47  Lr: 0.001875  Loss: -0.7502  Acc@1: 75.0000 (70.9618)  Acc@5: 100.0000 (97.3660)  time: 0.3462  data: 0.0008  max mem: 2503
Train: Epoch[1/5]  [ 690/3750]  eta: 0:17:44  Lr: 0.001875  Loss: -0.5173  Acc@1: 81.2500 (71.0384)  Acc@5: 100.0000 (97.3860)  time: 0.3482  data: 0.0011  max mem: 2503
Train: Epoch[1/5]  [ 700/3750]  eta: 0:17:40  Lr: 0.001875  Loss: -0.3723  Acc@1: 75.0000 (71.1394)  Acc@5: 100.0000 (97.3609)  time: 0.3482  data: 0.0010  max mem: 2503
Train: Epoch[1/5]  [ 710/3750]  eta: 0:17:37  Lr: 0.001875  Loss: -0.1002  Acc@1: 75.0000 (71.2201)  Acc@5: 100.0000 (97.3805)  time: 0.3473  data: 0.0008  max mem: 2503
Train: Epoch[1/5]  [ 720/3750]  eta: 0:17:33  Lr: 0.001875  Loss: -0.7298  Acc@1: 75.0000 (71.2205)  Acc@5: 100.0000 (97.4168)  time: 0.3474  data: 0.0008  max mem: 2503
Train: Epoch[1/5]  [ 730/3750]  eta: 0:17:30  Lr: 0.001875  Loss: -0.5479  Acc@1: 68.7500 (71.2551)  Acc@5: 100.0000 (97.4436)  time: 0.3479  data: 0.0009  max mem: 2503
Train: Epoch[1/5]  [ 740/3750]  eta: 0:17:27  Lr: 0.001875  Loss: -0.9073  Acc@1: 75.0000 (71.3731)  Acc@5: 100.0000 (97.4696)  time: 0.3485  data: 0.0009  max mem: 2503
Train: Epoch[1/5]  [ 750/3750]  eta: 0:17:23  Lr: 0.001875  Loss: 0.1080  Acc@1: 75.0000 (71.3881)  Acc@5: 100.0000 (97.4534)  time: 0.3494  data: 0.0010  max mem: 2503
Train: Epoch[1/5]  [ 760/3750]  eta: 0:17:20  Lr: 0.001875  Loss: -0.4406  Acc@1: 75.0000 (71.5013)  Acc@5: 100.0000 (97.4704)  time: 0.3482  data: 0.0011  max mem: 2503
Train: Epoch[1/5]  [ 770/3750]  eta: 0:17:16  Lr: 0.001875  Loss: -0.9165  Acc@1: 81.2500 (71.5548)  Acc@5: 100.0000 (97.4870)  time: 0.3469  data: 0.0012  max mem: 2503
Train: Epoch[1/5]  [ 780/3750]  eta: 0:17:13  Lr: 0.001875  Loss: -0.6612  Acc@1: 75.0000 (71.5589)  Acc@5: 100.0000 (97.5032)  time: 0.3478  data: 0.0009  max mem: 2503
Train: Epoch[1/5]  [ 790/3750]  eta: 0:17:09  Lr: 0.001875  Loss: -0.1367  Acc@1: 75.0000 (71.5471)  Acc@5: 100.0000 (97.5190)  time: 0.3507  data: 0.0008  max mem: 2503
Train: Epoch[1/5]  [ 800/3750]  eta: 0:17:06  Lr: 0.001875  Loss: -0.6886  Acc@1: 75.0000 (71.6214)  Acc@5: 100.0000 (97.5343)  time: 0.3492  data: 0.0008  max mem: 2503
Train: Epoch[1/5]  [ 810/3750]  eta: 0:17:02  Lr: 0.001875  Loss: -0.2702  Acc@1: 68.7500 (71.6245)  Acc@5: 100.0000 (97.5416)  time: 0.3459  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [ 820/3750]  eta: 0:16:59  Lr: 0.001875  Loss: -0.8170  Acc@1: 75.0000 (71.6961)  Acc@5: 100.0000 (97.5563)  time: 0.3451  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [ 830/3750]  eta: 0:16:55  Lr: 0.001875  Loss: -0.5083  Acc@1: 75.0000 (71.7509)  Acc@5: 100.0000 (97.5557)  time: 0.3435  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [ 840/3750]  eta: 0:16:51  Lr: 0.001875  Loss: -0.4735  Acc@1: 75.0000 (71.7598)  Acc@5: 100.0000 (97.5550)  time: 0.3429  data: 0.0002  max mem: 2503
Train: Epoch[1/5]  [ 850/3750]  eta: 0:16:48  Lr: 0.001875  Loss: -0.7442  Acc@1: 75.0000 (71.7759)  Acc@5: 100.0000 (97.5690)  time: 0.3455  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [ 860/3750]  eta: 0:16:44  Lr: 0.001875  Loss: -0.2024  Acc@1: 75.0000 (71.8133)  Acc@5: 100.0000 (97.5610)  time: 0.3476  data: 0.0007  max mem: 2503
Train: Epoch[1/5]  [ 870/3750]  eta: 0:16:41  Lr: 0.001875  Loss: -0.5800  Acc@1: 68.7500 (71.8355)  Acc@5: 100.0000 (97.5675)  time: 0.3473  data: 0.0007  max mem: 2503
Train: Epoch[1/5]  [ 880/3750]  eta: 0:16:37  Lr: 0.001875  Loss: -0.3785  Acc@1: 68.7500 (71.7934)  Acc@5: 100.0000 (97.5809)  time: 0.3474  data: 0.0008  max mem: 2503
Train: Epoch[1/5]  [ 890/3750]  eta: 0:16:34  Lr: 0.001875  Loss: -0.3251  Acc@1: 75.0000 (71.8715)  Acc@5: 100.0000 (97.5800)  time: 0.3470  data: 0.0006  max mem: 2503
Train: Epoch[1/5]  [ 900/3750]  eta: 0:16:30  Lr: 0.001875  Loss: -0.7177  Acc@1: 75.0000 (71.9409)  Acc@5: 100.0000 (97.5721)  time: 0.3477  data: 0.0013  max mem: 2503
Train: Epoch[1/5]  [ 910/3750]  eta: 0:16:27  Lr: 0.001875  Loss: -0.7889  Acc@1: 75.0000 (72.0088)  Acc@5: 100.0000 (97.5714)  time: 0.3481  data: 0.0018  max mem: 2503
Train: Epoch[1/5]  [ 920/3750]  eta: 0:16:24  Lr: 0.001875  Loss: -0.4651  Acc@1: 75.0000 (72.0413)  Acc@5: 100.0000 (97.5977)  time: 0.3479  data: 0.0020  max mem: 2503
Train: Epoch[1/5]  [ 930/3750]  eta: 0:16:20  Lr: 0.001875  Loss: -0.4728  Acc@1: 75.0000 (72.1335)  Acc@5: 100.0000 (97.6101)  time: 0.3484  data: 0.0020  max mem: 2503
Train: Epoch[1/5]  [ 940/3750]  eta: 0:16:17  Lr: 0.001875  Loss: -0.8675  Acc@1: 81.2500 (72.1971)  Acc@5: 100.0000 (97.6289)  time: 0.3474  data: 0.0011  max mem: 2503
Train: Epoch[1/5]  [ 950/3750]  eta: 0:16:13  Lr: 0.001875  Loss: -0.3507  Acc@1: 75.0000 (72.2266)  Acc@5: 100.0000 (97.6406)  time: 0.3484  data: 0.0019  max mem: 2503
Train: Epoch[1/5]  [ 960/3750]  eta: 0:16:10  Lr: 0.001875  Loss: -0.2372  Acc@1: 75.0000 (72.2945)  Acc@5: 100.0000 (97.6652)  time: 0.3476  data: 0.0018  max mem: 2503
Train: Epoch[1/5]  [ 970/3750]  eta: 0:16:06  Lr: 0.001875  Loss: -0.8715  Acc@1: 75.0000 (72.3674)  Acc@5: 100.0000 (97.6828)  time: 0.3453  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [ 980/3750]  eta: 0:16:02  Lr: 0.001875  Loss: -0.6824  Acc@1: 75.0000 (72.3942)  Acc@5: 100.0000 (97.6937)  time: 0.3446  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [ 990/3750]  eta: 0:15:59  Lr: 0.001875  Loss: -0.7054  Acc@1: 81.2500 (72.4899)  Acc@5: 100.0000 (97.7170)  time: 0.3441  data: 0.0014  max mem: 2503
Train: Epoch[1/5]  [1000/3750]  eta: 0:15:55  Lr: 0.001875  Loss: -0.8068  Acc@1: 81.2500 (72.5649)  Acc@5: 100.0000 (97.7335)  time: 0.3442  data: 0.0013  max mem: 2503
Train: Epoch[1/5]  [1010/3750]  eta: 0:15:52  Lr: 0.001875  Loss: -0.7235  Acc@1: 81.2500 (72.6199)  Acc@5: 100.0000 (97.7498)  time: 0.3457  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [1020/3750]  eta: 0:15:48  Lr: 0.001875  Loss: -0.8379  Acc@1: 81.2500 (72.6371)  Acc@5: 100.0000 (97.7534)  time: 0.3482  data: 0.0010  max mem: 2503
Train: Epoch[1/5]  [1030/3750]  eta: 0:15:45  Lr: 0.001875  Loss: -0.7567  Acc@1: 75.0000 (72.6479)  Acc@5: 100.0000 (97.7692)  time: 0.3472  data: 0.0011  max mem: 2503
Train: Epoch[1/5]  [1040/3750]  eta: 0:15:41  Lr: 0.001875  Loss: -0.6178  Acc@1: 75.0000 (72.6885)  Acc@5: 100.0000 (97.7726)  time: 0.3461  data: 0.0007  max mem: 2503
Train: Epoch[1/5]  [1050/3750]  eta: 0:15:38  Lr: 0.001875  Loss: -0.6769  Acc@1: 75.0000 (72.7343)  Acc@5: 100.0000 (97.7819)  time: 0.3467  data: 0.0008  max mem: 2503
Train: Epoch[1/5]  [1060/3750]  eta: 0:15:35  Lr: 0.001875  Loss: -0.7521  Acc@1: 75.0000 (72.7733)  Acc@5: 100.0000 (97.7969)  time: 0.3496  data: 0.0011  max mem: 2503
Train: Epoch[1/5]  [1070/3750]  eta: 0:15:31  Lr: 0.001875  Loss: -0.5822  Acc@1: 81.2500 (72.8583)  Acc@5: 100.0000 (97.8116)  time: 0.3493  data: 0.0009  max mem: 2503
Train: Epoch[1/5]  [1080/3750]  eta: 0:15:28  Lr: 0.001875  Loss: -0.6539  Acc@1: 75.0000 (72.9012)  Acc@5: 100.0000 (97.8145)  time: 0.3469  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [1090/3750]  eta: 0:15:24  Lr: 0.001875  Loss: -0.0977  Acc@1: 81.2500 (72.9892)  Acc@5: 100.0000 (97.8346)  time: 0.3466  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [1100/3750]  eta: 0:15:21  Lr: 0.001875  Loss: -0.7703  Acc@1: 81.2500 (73.0018)  Acc@5: 100.0000 (97.8485)  time: 0.3459  data: 0.0006  max mem: 2503
Train: Epoch[1/5]  [1110/3750]  eta: 0:15:17  Lr: 0.001875  Loss: -0.8765  Acc@1: 75.0000 (73.0536)  Acc@5: 100.0000 (97.8510)  time: 0.3471  data: 0.0007  max mem: 2503
Train: Epoch[1/5]  [1120/3750]  eta: 0:15:14  Lr: 0.001875  Loss: -0.5007  Acc@1: 81.2500 (73.1155)  Acc@5: 100.0000 (97.8423)  time: 0.3469  data: 0.0009  max mem: 2503
Train: Epoch[1/5]  [1130/3750]  eta: 0:15:10  Lr: 0.001875  Loss: -0.5371  Acc@1: 75.0000 (73.1322)  Acc@5: 100.0000 (97.8504)  time: 0.3463  data: 0.0008  max mem: 2503
Train: Epoch[1/5]  [1140/3750]  eta: 0:15:06  Lr: 0.001875  Loss: -0.6735  Acc@1: 75.0000 (73.1376)  Acc@5: 100.0000 (97.8582)  time: 0.3451  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [1150/3750]  eta: 0:15:03  Lr: 0.001875  Loss: -0.8686  Acc@1: 75.0000 (73.1918)  Acc@5: 100.0000 (97.8606)  time: 0.3438  data: 0.0009  max mem: 2503
Train: Epoch[1/5]  [1160/3750]  eta: 0:14:59  Lr: 0.001875  Loss: -0.8505  Acc@1: 75.0000 (73.2666)  Acc@5: 100.0000 (97.8736)  time: 0.3439  data: 0.0010  max mem: 2503
Train: Epoch[1/5]  [1170/3750]  eta: 0:14:56  Lr: 0.001875  Loss: -0.5593  Acc@1: 81.2500 (73.3454)  Acc@5: 100.0000 (97.8864)  time: 0.3448  data: 0.0007  max mem: 2503
Train: Epoch[1/5]  [1180/3750]  eta: 0:14:52  Lr: 0.001875  Loss: -0.8071  Acc@1: 75.0000 (73.3065)  Acc@5: 100.0000 (97.8831)  time: 0.3465  data: 0.0008  max mem: 2503
Train: Epoch[1/5]  [1190/3750]  eta: 0:14:49  Lr: 0.001875  Loss: -0.9087  Acc@1: 75.0000 (73.3417)  Acc@5: 100.0000 (97.8747)  time: 0.3465  data: 0.0007  max mem: 2503
Train: Epoch[1/5]  [1200/3750]  eta: 0:14:45  Lr: 0.001875  Loss: -0.8159  Acc@1: 75.0000 (73.3607)  Acc@5: 100.0000 (97.8872)  time: 0.3471  data: 0.0012  max mem: 2503
Train: Epoch[1/5]  [1210/3750]  eta: 0:14:42  Lr: 0.001875  Loss: -0.5998  Acc@1: 75.0000 (73.3640)  Acc@5: 100.0000 (97.8633)  time: 0.3483  data: 0.0019  max mem: 2503
Train: Epoch[1/5]  [1220/3750]  eta: 0:14:39  Lr: 0.001875  Loss: -0.3693  Acc@1: 75.0000 (73.3774)  Acc@5: 100.0000 (97.8604)  time: 0.3486  data: 0.0016  max mem: 2503
Train: Epoch[1/5]  [1230/3750]  eta: 0:14:35  Lr: 0.001875  Loss: -0.0694  Acc@1: 68.7500 (73.3448)  Acc@5: 100.0000 (97.8473)  time: 0.3476  data: 0.0011  max mem: 2503
Train: Epoch[1/5]  [1240/3750]  eta: 0:14:32  Lr: 0.001875  Loss: -1.0407  Acc@1: 68.7500 (73.3834)  Acc@5: 100.0000 (97.8596)  time: 0.3464  data: 0.0007  max mem: 2503
Train: Epoch[1/5]  [1250/3750]  eta: 0:14:28  Lr: 0.001875  Loss: -0.3492  Acc@1: 75.0000 (73.3963)  Acc@5: 100.0000 (97.8667)  time: 0.3480  data: 0.0013  max mem: 2503
Train: Epoch[1/5]  [1260/3750]  eta: 0:14:25  Lr: 0.001875  Loss: -0.2576  Acc@1: 75.0000 (73.4487)  Acc@5: 100.0000 (97.8688)  time: 0.3486  data: 0.0016  max mem: 2503
Train: Epoch[1/5]  [1270/3750]  eta: 0:14:21  Lr: 0.001875  Loss: -0.5964  Acc@1: 81.2500 (73.5100)  Acc@5: 100.0000 (97.8806)  time: 0.3475  data: 0.0009  max mem: 2503
Train: Epoch[1/5]  [1280/3750]  eta: 0:14:18  Lr: 0.001875  Loss: -0.6714  Acc@1: 81.2500 (73.5461)  Acc@5: 100.0000 (97.8972)  time: 0.3487  data: 0.0010  max mem: 2503
Train: Epoch[1/5]  [1290/3750]  eta: 0:14:14  Lr: 0.001875  Loss: -0.8308  Acc@1: 81.2500 (73.6009)  Acc@5: 100.0000 (97.9086)  time: 0.3479  data: 0.0007  max mem: 2503
Train: Epoch[1/5]  [1300/3750]  eta: 0:14:11  Lr: 0.001875  Loss: -0.9636  Acc@1: 81.2500 (73.6501)  Acc@5: 100.0000 (97.9151)  time: 0.3470  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [1310/3750]  eta: 0:14:07  Lr: 0.001875  Loss: -0.8455  Acc@1: 81.2500 (73.6747)  Acc@5: 100.0000 (97.9310)  time: 0.3455  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [1320/3750]  eta: 0:14:04  Lr: 0.001875  Loss: -0.4458  Acc@1: 75.0000 (73.6658)  Acc@5: 100.0000 (97.9277)  time: 0.3434  data: 0.0002  max mem: 2503
Train: Epoch[1/5]  [1330/3750]  eta: 0:14:00  Lr: 0.001875  Loss: -0.5972  Acc@1: 75.0000 (73.6570)  Acc@5: 93.7500 (97.9151)  time: 0.3442  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [1340/3750]  eta: 0:13:57  Lr: 0.001875  Loss: -0.6342  Acc@1: 75.0000 (73.6810)  Acc@5: 93.7500 (97.9120)  time: 0.3471  data: 0.0011  max mem: 2503
Train: Epoch[1/5]  [1350/3750]  eta: 0:13:53  Lr: 0.001875  Loss: -0.6235  Acc@1: 81.2500 (73.7370)  Acc@5: 100.0000 (97.9043)  time: 0.3497  data: 0.0016  max mem: 2503
Train: Epoch[1/5]  [1360/3750]  eta: 0:13:50  Lr: 0.001875  Loss: -0.7465  Acc@1: 75.0000 (73.7555)  Acc@5: 100.0000 (97.9151)  time: 0.3489  data: 0.0013  max mem: 2503
Train: Epoch[1/5]  [1370/3750]  eta: 0:13:46  Lr: 0.001875  Loss: -0.2274  Acc@1: 75.0000 (73.7691)  Acc@5: 100.0000 (97.9212)  time: 0.3482  data: 0.0010  max mem: 2503
Train: Epoch[1/5]  [1380/3750]  eta: 0:13:43  Lr: 0.001875  Loss: -0.3453  Acc@1: 75.0000 (73.8052)  Acc@5: 100.0000 (97.9272)  time: 0.3495  data: 0.0008  max mem: 2503
Train: Epoch[1/5]  [1390/3750]  eta: 0:13:39  Lr: 0.001875  Loss: -0.3055  Acc@1: 81.2500 (73.8318)  Acc@5: 100.0000 (97.9331)  time: 0.3491  data: 0.0007  max mem: 2503
Train: Epoch[1/5]  [1400/3750]  eta: 0:13:36  Lr: 0.001875  Loss: -0.4549  Acc@1: 81.2500 (73.8357)  Acc@5: 100.0000 (97.9390)  time: 0.3475  data: 0.0011  max mem: 2503
Train: Epoch[1/5]  [1410/3750]  eta: 0:13:33  Lr: 0.001875  Loss: -0.2201  Acc@1: 81.2500 (73.8882)  Acc@5: 100.0000 (97.9536)  time: 0.3479  data: 0.0016  max mem: 2503
Train: Epoch[1/5]  [1420/3750]  eta: 0:13:29  Lr: 0.001875  Loss: -0.9265  Acc@1: 81.2500 (73.9136)  Acc@5: 100.0000 (97.9592)  time: 0.3492  data: 0.0021  max mem: 2503
Train: Epoch[1/5]  [1430/3750]  eta: 0:13:26  Lr: 0.001875  Loss: -0.7232  Acc@1: 75.0000 (73.9474)  Acc@5: 100.0000 (97.9647)  time: 0.3507  data: 0.0022  max mem: 2503
Train: Epoch[1/5]  [1440/3750]  eta: 0:13:22  Lr: 0.001875  Loss: 0.3851  Acc@1: 68.7500 (73.9157)  Acc@5: 100.0000 (97.9702)  time: 0.3493  data: 0.0013  max mem: 2503
Train: Epoch[1/5]  [1450/3750]  eta: 0:13:19  Lr: 0.001875  Loss: -0.4958  Acc@1: 75.0000 (73.9404)  Acc@5: 100.0000 (97.9712)  time: 0.3468  data: 0.0006  max mem: 2503
Train: Epoch[1/5]  [1460/3750]  eta: 0:13:15  Lr: 0.001875  Loss: -0.5154  Acc@1: 75.0000 (73.9434)  Acc@5: 100.0000 (97.9680)  time: 0.3452  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [1470/3750]  eta: 0:13:12  Lr: 0.001875  Loss: -0.7586  Acc@1: 75.0000 (73.9845)  Acc@5: 100.0000 (97.9648)  time: 0.3434  data: 0.0006  max mem: 2503
Train: Epoch[1/5]  [1480/3750]  eta: 0:13:08  Lr: 0.001875  Loss: -0.0899  Acc@1: 81.2500 (74.0083)  Acc@5: 100.0000 (97.9617)  time: 0.3431  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [1490/3750]  eta: 0:13:05  Lr: 0.001875  Loss: -0.4556  Acc@1: 75.0000 (74.0023)  Acc@5: 100.0000 (97.9754)  time: 0.3447  data: 0.0007  max mem: 2503
Train: Epoch[1/5]  [1500/3750]  eta: 0:13:01  Lr: 0.001875  Loss: -0.6341  Acc@1: 75.0000 (74.0173)  Acc@5: 100.0000 (97.9847)  time: 0.3468  data: 0.0011  max mem: 2503
Train: Epoch[1/5]  [1510/3750]  eta: 0:12:58  Lr: 0.001875  Loss: -0.3363  Acc@1: 75.0000 (73.9990)  Acc@5: 100.0000 (97.9897)  time: 0.3481  data: 0.0017  max mem: 2503
Train: Epoch[1/5]  [1520/3750]  eta: 0:12:54  Lr: 0.001875  Loss: -0.4709  Acc@1: 75.0000 (74.0344)  Acc@5: 100.0000 (97.9947)  time: 0.3479  data: 0.0015  max mem: 2503
Train: Epoch[1/5]  [1530/3750]  eta: 0:12:51  Lr: 0.001875  Loss: -0.4318  Acc@1: 81.2500 (74.0937)  Acc@5: 100.0000 (98.0038)  time: 0.3474  data: 0.0011  max mem: 2503
Train: Epoch[1/5]  [1540/3750]  eta: 0:12:47  Lr: 0.001875  Loss: -0.2842  Acc@1: 81.2500 (74.1361)  Acc@5: 100.0000 (97.9964)  time: 0.3472  data: 0.0012  max mem: 2503
Train: Epoch[1/5]  [1550/3750]  eta: 0:12:44  Lr: 0.001875  Loss: -0.7052  Acc@1: 81.2500 (74.1659)  Acc@5: 100.0000 (97.9973)  time: 0.3469  data: 0.0011  max mem: 2503
Train: Epoch[1/5]  [1560/3750]  eta: 0:12:40  Lr: 0.001875  Loss: -0.3942  Acc@1: 75.0000 (74.1872)  Acc@5: 100.0000 (98.0021)  time: 0.3477  data: 0.0009  max mem: 2503
Train: Epoch[1/5]  [1570/3750]  eta: 0:12:37  Lr: 0.001875  Loss: -0.4923  Acc@1: 75.0000 (74.2242)  Acc@5: 100.0000 (98.0148)  time: 0.3477  data: 0.0008  max mem: 2503
Train: Epoch[1/5]  [1580/3750]  eta: 0:12:33  Lr: 0.001875  Loss: -0.3647  Acc@1: 75.0000 (74.2489)  Acc@5: 100.0000 (98.0115)  time: 0.3469  data: 0.0011  max mem: 2503
Train: Epoch[1/5]  [1590/3750]  eta: 0:12:30  Lr: 0.001875  Loss: -0.9008  Acc@1: 75.0000 (74.2850)  Acc@5: 100.0000 (98.0083)  time: 0.3476  data: 0.0012  max mem: 2503
Train: Epoch[1/5]  [1600/3750]  eta: 0:12:26  Lr: 0.001875  Loss: -0.8329  Acc@1: 81.2500 (74.3364)  Acc@5: 100.0000 (98.0208)  time: 0.3480  data: 0.0012  max mem: 2503
Train: Epoch[1/5]  [1610/3750]  eta: 0:12:23  Lr: 0.001875  Loss: -0.4905  Acc@1: 81.2500 (74.3599)  Acc@5: 100.0000 (98.0175)  time: 0.3466  data: 0.0008  max mem: 2503
Train: Epoch[1/5]  [1620/3750]  eta: 0:12:19  Lr: 0.001875  Loss: -0.1866  Acc@1: 81.2500 (74.3677)  Acc@5: 100.0000 (98.0105)  time: 0.3456  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [1630/3750]  eta: 0:12:16  Lr: 0.001875  Loss: -0.6841  Acc@1: 81.2500 (74.3754)  Acc@5: 100.0000 (98.0035)  time: 0.3443  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [1640/3750]  eta: 0:12:12  Lr: 0.001875  Loss: -0.0832  Acc@1: 75.0000 (74.3868)  Acc@5: 100.0000 (98.0119)  time: 0.3428  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [1650/3750]  eta: 0:12:09  Lr: 0.001875  Loss: -0.7040  Acc@1: 81.2500 (74.4132)  Acc@5: 100.0000 (98.0239)  time: 0.3427  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [1660/3750]  eta: 0:12:05  Lr: 0.001875  Loss: -0.6304  Acc@1: 81.2500 (74.4281)  Acc@5: 100.0000 (98.0245)  time: 0.3443  data: 0.0007  max mem: 2503
Train: Epoch[1/5]  [1670/3750]  eta: 0:12:02  Lr: 0.001875  Loss: -0.5973  Acc@1: 75.0000 (74.4315)  Acc@5: 100.0000 (98.0289)  time: 0.3460  data: 0.0007  max mem: 2503
Train: Epoch[1/5]  [1680/3750]  eta: 0:11:58  Lr: 0.001875  Loss: -0.6103  Acc@1: 75.0000 (74.4572)  Acc@5: 100.0000 (98.0406)  time: 0.3472  data: 0.0013  max mem: 2503
Train: Epoch[1/5]  [1690/3750]  eta: 0:11:55  Lr: 0.001875  Loss: -0.5813  Acc@1: 75.0000 (74.4715)  Acc@5: 100.0000 (98.0485)  time: 0.3475  data: 0.0012  max mem: 2503
Train: Epoch[1/5]  [1700/3750]  eta: 0:11:51  Lr: 0.001875  Loss: -0.7670  Acc@1: 75.0000 (74.5297)  Acc@5: 100.0000 (98.0563)  time: 0.3469  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [1710/3750]  eta: 0:11:48  Lr: 0.001875  Loss: -0.7276  Acc@1: 75.0000 (74.5397)  Acc@5: 100.0000 (98.0603)  time: 0.3477  data: 0.0007  max mem: 2503
Train: Epoch[1/5]  [1720/3750]  eta: 0:11:45  Lr: 0.001875  Loss: -0.2756  Acc@1: 75.0000 (74.5642)  Acc@5: 100.0000 (98.0680)  time: 0.3485  data: 0.0010  max mem: 2503
Train: Epoch[1/5]  [1730/3750]  eta: 0:11:41  Lr: 0.001875  Loss: -0.4104  Acc@1: 81.2500 (74.5920)  Acc@5: 100.0000 (98.0647)  time: 0.3470  data: 0.0008  max mem: 2503
Train: Epoch[1/5]  [1740/3750]  eta: 0:11:38  Lr: 0.001875  Loss: -0.5625  Acc@1: 81.2500 (74.6231)  Acc@5: 100.0000 (98.0686)  time: 0.3456  data: 0.0006  max mem: 2503
Train: Epoch[1/5]  [1750/3750]  eta: 0:11:34  Lr: 0.001875  Loss: -0.4213  Acc@1: 81.2500 (74.6538)  Acc@5: 100.0000 (98.0690)  time: 0.3469  data: 0.0009  max mem: 2503
Train: Epoch[1/5]  [1760/3750]  eta: 0:11:31  Lr: 0.001875  Loss: -0.2112  Acc@1: 81.2500 (74.6806)  Acc@5: 100.0000 (98.0693)  time: 0.3490  data: 0.0010  max mem: 2503
Train: Epoch[1/5]  [1770/3750]  eta: 0:11:27  Lr: 0.001875  Loss: -0.7171  Acc@1: 81.2500 (74.6894)  Acc@5: 100.0000 (98.0625)  time: 0.3492  data: 0.0006  max mem: 2503
Train: Epoch[1/5]  [1780/3750]  eta: 0:11:24  Lr: 0.001875  Loss: -0.5975  Acc@1: 75.0000 (74.6947)  Acc@5: 100.0000 (98.0594)  time: 0.3473  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [1790/3750]  eta: 0:11:20  Lr: 0.001875  Loss: -0.5450  Acc@1: 75.0000 (74.6755)  Acc@5: 100.0000 (98.0667)  time: 0.3442  data: 0.0002  max mem: 2503
Train: Epoch[1/5]  [1800/3750]  eta: 0:11:17  Lr: 0.001875  Loss: -0.4166  Acc@1: 68.7500 (74.6564)  Acc@5: 100.0000 (98.0705)  time: 0.3427  data: 0.0002  max mem: 2503
Train: Epoch[1/5]  [1810/3750]  eta: 0:11:13  Lr: 0.001875  Loss: -0.4206  Acc@1: 68.7500 (74.6618)  Acc@5: 100.0000 (98.0812)  time: 0.3430  data: 0.0002  max mem: 2503
Train: Epoch[1/5]  [1820/3750]  eta: 0:11:10  Lr: 0.001875  Loss: -0.6453  Acc@1: 75.0000 (74.6705)  Acc@5: 100.0000 (98.0917)  time: 0.3448  data: 0.0008  max mem: 2503
Train: Epoch[1/5]  [1830/3750]  eta: 0:11:06  Lr: 0.001875  Loss: -0.3144  Acc@1: 81.2500 (74.6996)  Acc@5: 100.0000 (98.0987)  time: 0.3471  data: 0.0010  max mem: 2503
Train: Epoch[1/5]  [1840/3750]  eta: 0:11:03  Lr: 0.001875  Loss: -0.8938  Acc@1: 81.2500 (74.7318)  Acc@5: 100.0000 (98.1090)  time: 0.3481  data: 0.0008  max mem: 2503
Train: Epoch[1/5]  [1850/3750]  eta: 0:10:59  Lr: 0.001875  Loss: -0.5334  Acc@1: 81.2500 (74.7231)  Acc@5: 100.0000 (98.1024)  time: 0.3479  data: 0.0010  max mem: 2503
Train: Epoch[1/5]  [1860/3750]  eta: 0:10:56  Lr: 0.001875  Loss: -0.5869  Acc@1: 75.0000 (74.7582)  Acc@5: 100.0000 (98.1092)  time: 0.3478  data: 0.0016  max mem: 2503
Train: Epoch[1/5]  [1870/3750]  eta: 0:10:52  Lr: 0.001875  Loss: -0.8679  Acc@1: 81.2500 (74.7929)  Acc@5: 100.0000 (98.1126)  time: 0.3484  data: 0.0016  max mem: 2503
Train: Epoch[1/5]  [1880/3750]  eta: 0:10:49  Lr: 0.001875  Loss: -0.3479  Acc@1: 75.0000 (74.7840)  Acc@5: 100.0000 (98.1160)  time: 0.3477  data: 0.0010  max mem: 2503
Train: Epoch[1/5]  [1890/3750]  eta: 0:10:45  Lr: 0.001875  Loss: -0.5878  Acc@1: 75.0000 (74.8017)  Acc@5: 100.0000 (98.1194)  time: 0.3469  data: 0.0007  max mem: 2503
Train: Epoch[1/5]  [1900/3750]  eta: 0:10:42  Lr: 0.001875  Loss: -0.8246  Acc@1: 75.0000 (74.8192)  Acc@5: 100.0000 (98.1260)  time: 0.3466  data: 0.0007  max mem: 2503
Train: Epoch[1/5]  [1910/3750]  eta: 0:10:38  Lr: 0.001875  Loss: -0.8306  Acc@1: 75.0000 (74.8299)  Acc@5: 100.0000 (98.1325)  time: 0.3463  data: 0.0006  max mem: 2503
Train: Epoch[1/5]  [1920/3750]  eta: 0:10:35  Lr: 0.001875  Loss: -0.3955  Acc@1: 75.0000 (74.8601)  Acc@5: 100.0000 (98.1390)  time: 0.3456  data: 0.0007  max mem: 2503
Train: Epoch[1/5]  [1930/3750]  eta: 0:10:31  Lr: 0.001875  Loss: -0.7324  Acc@1: 81.2500 (74.8997)  Acc@5: 100.0000 (98.1422)  time: 0.3450  data: 0.0007  max mem: 2503
Train: Epoch[1/5]  [1940/3750]  eta: 0:10:28  Lr: 0.001875  Loss: -0.4407  Acc@1: 81.2500 (74.9098)  Acc@5: 100.0000 (98.1356)  time: 0.3455  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [1950/3750]  eta: 0:10:24  Lr: 0.001875  Loss: -0.5823  Acc@1: 75.0000 (74.8975)  Acc@5: 100.0000 (98.1324)  time: 0.3455  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [1960/3750]  eta: 0:10:21  Lr: 0.001875  Loss: -0.9287  Acc@1: 75.0000 (74.9076)  Acc@5: 100.0000 (98.1387)  time: 0.3439  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [1970/3750]  eta: 0:10:17  Lr: 0.001875  Loss: -0.7485  Acc@1: 75.0000 (74.9271)  Acc@5: 100.0000 (98.1386)  time: 0.3429  data: 0.0002  max mem: 2503
Train: Epoch[1/5]  [1980/3750]  eta: 0:10:14  Lr: 0.001875  Loss: -0.6454  Acc@1: 75.0000 (74.9558)  Acc@5: 100.0000 (98.1417)  time: 0.3433  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [1990/3750]  eta: 0:10:10  Lr: 0.001875  Loss: -0.4121  Acc@1: 81.2500 (74.9623)  Acc@5: 100.0000 (98.1479)  time: 0.3446  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [2000/3750]  eta: 0:10:07  Lr: 0.001875  Loss: -0.8791  Acc@1: 75.0000 (74.9688)  Acc@5: 100.0000 (98.1509)  time: 0.3456  data: 0.0007  max mem: 2503
Train: Epoch[1/5]  [2010/3750]  eta: 0:10:03  Lr: 0.001875  Loss: -0.7197  Acc@1: 81.2500 (75.0062)  Acc@5: 100.0000 (98.1601)  time: 0.3453  data: 0.0008  max mem: 2503
Train: Epoch[1/5]  [2020/3750]  eta: 0:10:00  Lr: 0.001875  Loss: -0.6660  Acc@1: 81.2500 (75.0340)  Acc@5: 100.0000 (98.1630)  time: 0.3455  data: 0.0007  max mem: 2503
Train: Epoch[1/5]  [2030/3750]  eta: 0:09:56  Lr: 0.001875  Loss: -0.4396  Acc@1: 81.2500 (75.0339)  Acc@5: 100.0000 (98.1721)  time: 0.3464  data: 0.0006  max mem: 2503
Train: Epoch[1/5]  [2040/3750]  eta: 0:09:53  Lr: 0.001875  Loss: -0.4263  Acc@1: 75.0000 (75.0245)  Acc@5: 100.0000 (98.1719)  time: 0.3458  data: 0.0006  max mem: 2503
Train: Epoch[1/5]  [2050/3750]  eta: 0:09:50  Lr: 0.001875  Loss: -0.5111  Acc@1: 75.0000 (75.0457)  Acc@5: 100.0000 (98.1808)  time: 0.3450  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [2060/3750]  eta: 0:09:46  Lr: 0.001875  Loss: -0.3222  Acc@1: 75.0000 (75.0334)  Acc@5: 100.0000 (98.1805)  time: 0.3461  data: 0.0008  max mem: 2503
Train: Epoch[1/5]  [2070/3750]  eta: 0:09:43  Lr: 0.001875  Loss: -0.6993  Acc@1: 75.0000 (75.0664)  Acc@5: 100.0000 (98.1863)  time: 0.3476  data: 0.0009  max mem: 2503
Train: Epoch[1/5]  [2080/3750]  eta: 0:09:39  Lr: 0.001875  Loss: -0.7428  Acc@1: 81.2500 (75.0841)  Acc@5: 100.0000 (98.1950)  time: 0.3477  data: 0.0009  max mem: 2503
Train: Epoch[1/5]  [2090/3750]  eta: 0:09:36  Lr: 0.001875  Loss: -0.2596  Acc@1: 81.2500 (75.0956)  Acc@5: 100.0000 (98.1917)  time: 0.3471  data: 0.0010  max mem: 2503
Train: Epoch[1/5]  [2100/3750]  eta: 0:09:32  Lr: 0.001875  Loss: -0.8659  Acc@1: 81.2500 (75.1368)  Acc@5: 100.0000 (98.1913)  time: 0.3470  data: 0.0009  max mem: 2503
Train: Epoch[1/5]  [2110/3750]  eta: 0:09:29  Lr: 0.001875  Loss: -0.2553  Acc@1: 87.5000 (75.1658)  Acc@5: 100.0000 (98.1940)  time: 0.3482  data: 0.0009  max mem: 2503
Train: Epoch[1/5]  [2120/3750]  eta: 0:09:25  Lr: 0.001875  Loss: -0.6981  Acc@1: 81.2500 (75.1768)  Acc@5: 100.0000 (98.1907)  time: 0.3486  data: 0.0011  max mem: 2503
Train: Epoch[1/5]  [2130/3750]  eta: 0:09:22  Lr: 0.001875  Loss: -0.7275  Acc@1: 81.2500 (75.2024)  Acc@5: 100.0000 (98.1963)  time: 0.3484  data: 0.0014  max mem: 2503
Train: Epoch[1/5]  [2140/3750]  eta: 0:09:18  Lr: 0.001875  Loss: -0.0187  Acc@1: 81.2500 (75.2043)  Acc@5: 100.0000 (98.1989)  time: 0.3496  data: 0.0012  max mem: 2503
Train: Epoch[1/5]  [2150/3750]  eta: 0:09:15  Lr: 0.001875  Loss: -0.8378  Acc@1: 81.2500 (75.2528)  Acc@5: 100.0000 (98.2072)  time: 0.3490  data: 0.0007  max mem: 2503
Train: Epoch[1/5]  [2160/3750]  eta: 0:09:11  Lr: 0.001875  Loss: -0.6415  Acc@1: 81.2500 (75.2690)  Acc@5: 100.0000 (98.2068)  time: 0.3484  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [2170/3750]  eta: 0:09:08  Lr: 0.001875  Loss: -0.9728  Acc@1: 75.0000 (75.2677)  Acc@5: 100.0000 (98.2007)  time: 0.3462  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [2180/3750]  eta: 0:09:04  Lr: 0.001875  Loss: -0.6808  Acc@1: 75.0000 (75.2636)  Acc@5: 100.0000 (98.2090)  time: 0.3435  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [2190/3750]  eta: 0:09:01  Lr: 0.001875  Loss: -0.5985  Acc@1: 81.2500 (75.2967)  Acc@5: 100.0000 (98.2171)  time: 0.3440  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [2200/3750]  eta: 0:08:57  Lr: 0.001875  Loss: -0.9236  Acc@1: 81.2500 (75.3124)  Acc@5: 100.0000 (98.2224)  time: 0.3470  data: 0.0011  max mem: 2503
Train: Epoch[1/5]  [2210/3750]  eta: 0:08:54  Lr: 0.001875  Loss: -0.4766  Acc@1: 75.0000 (75.3251)  Acc@5: 100.0000 (98.2220)  time: 0.3489  data: 0.0016  max mem: 2503
Train: Epoch[1/5]  [2220/3750]  eta: 0:08:51  Lr: 0.001875  Loss: -0.6299  Acc@1: 81.2500 (75.3602)  Acc@5: 100.0000 (98.2300)  time: 0.3487  data: 0.0010  max mem: 2503
Train: Epoch[1/5]  [2230/3750]  eta: 0:08:47  Lr: 0.001875  Loss: -0.7227  Acc@1: 81.2500 (75.3782)  Acc@5: 100.0000 (98.2323)  time: 0.3490  data: 0.0010  max mem: 2503
Train: Epoch[1/5]  [2240/3750]  eta: 0:08:44  Lr: 0.001875  Loss: -0.7506  Acc@1: 81.2500 (75.4100)  Acc@5: 100.0000 (98.2346)  time: 0.3525  data: 0.0016  max mem: 2503
Train: Epoch[1/5]  [2250/3750]  eta: 0:08:40  Lr: 0.001875  Loss: -0.4172  Acc@1: 75.0000 (75.4220)  Acc@5: 100.0000 (98.2424)  time: 0.3552  data: 0.0019  max mem: 2503
Train: Epoch[1/5]  [2260/3750]  eta: 0:08:37  Lr: 0.001875  Loss: -0.4826  Acc@1: 81.2500 (75.4533)  Acc@5: 100.0000 (98.2447)  time: 0.3517  data: 0.0015  max mem: 2503
Train: Epoch[1/5]  [2270/3750]  eta: 0:08:33  Lr: 0.001875  Loss: -0.2816  Acc@1: 81.2500 (75.4679)  Acc@5: 100.0000 (98.2497)  time: 0.3492  data: 0.0017  max mem: 2503
Train: Epoch[1/5]  [2280/3750]  eta: 0:08:30  Lr: 0.001875  Loss: -0.6142  Acc@1: 81.2500 (75.4740)  Acc@5: 100.0000 (98.2464)  time: 0.3505  data: 0.0019  max mem: 2503
Train: Epoch[1/5]  [2290/3750]  eta: 0:08:26  Lr: 0.001875  Loss: -0.4552  Acc@1: 81.2500 (75.4747)  Acc@5: 100.0000 (98.2513)  time: 0.3499  data: 0.0015  max mem: 2503
Train: Epoch[1/5]  [2300/3750]  eta: 0:08:23  Lr: 0.001875  Loss: -0.8659  Acc@1: 75.0000 (75.5052)  Acc@5: 100.0000 (98.2535)  time: 0.3485  data: 0.0010  max mem: 2503
Train: Epoch[1/5]  [2310/3750]  eta: 0:08:20  Lr: 0.001875  Loss: -0.6925  Acc@1: 75.0000 (75.5111)  Acc@5: 100.0000 (98.2610)  time: 0.3473  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [2320/3750]  eta: 0:08:16  Lr: 0.001875  Loss: -0.6563  Acc@1: 75.0000 (75.5359)  Acc@5: 100.0000 (98.2631)  time: 0.3446  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [2330/3750]  eta: 0:08:13  Lr: 0.001875  Loss: -0.9302  Acc@1: 81.2500 (75.5550)  Acc@5: 100.0000 (98.2652)  time: 0.3434  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [2340/3750]  eta: 0:08:09  Lr: 0.001875  Loss: -0.6201  Acc@1: 75.0000 (75.5607)  Acc@5: 100.0000 (98.2673)  time: 0.3435  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [2350/3750]  eta: 0:08:06  Lr: 0.001875  Loss: -0.4781  Acc@1: 75.0000 (75.5716)  Acc@5: 100.0000 (98.2694)  time: 0.3463  data: 0.0013  max mem: 2503
Train: Epoch[1/5]  [2360/3750]  eta: 0:08:02  Lr: 0.001875  Loss: -0.4551  Acc@1: 81.2500 (75.5797)  Acc@5: 100.0000 (98.2687)  time: 0.3496  data: 0.0019  max mem: 2503
Train: Epoch[1/5]  [2370/3750]  eta: 0:07:59  Lr: 0.001875  Loss: -0.3478  Acc@1: 81.2500 (75.5957)  Acc@5: 100.0000 (98.2681)  time: 0.3497  data: 0.0018  max mem: 2503
Train: Epoch[1/5]  [2380/3750]  eta: 0:07:55  Lr: 0.001875  Loss: -0.7070  Acc@1: 81.2500 (75.6090)  Acc@5: 100.0000 (98.2728)  time: 0.3520  data: 0.0019  max mem: 2503
Train: Epoch[1/5]  [2390/3750]  eta: 0:07:52  Lr: 0.001875  Loss: -0.8169  Acc@1: 75.0000 (75.6221)  Acc@5: 100.0000 (98.2696)  time: 0.3551  data: 0.0016  max mem: 2503
Train: Epoch[1/5]  [2400/3750]  eta: 0:07:48  Lr: 0.001875  Loss: -0.4762  Acc@1: 81.2500 (75.6482)  Acc@5: 100.0000 (98.2716)  time: 0.3524  data: 0.0013  max mem: 2503
Train: Epoch[1/5]  [2410/3750]  eta: 0:07:45  Lr: 0.001875  Loss: -0.6251  Acc@1: 81.2500 (75.6766)  Acc@5: 100.0000 (98.2787)  time: 0.3496  data: 0.0013  max mem: 2503
Train: Epoch[1/5]  [2420/3750]  eta: 0:07:41  Lr: 0.001875  Loss: -0.6574  Acc@1: 81.2500 (75.6893)  Acc@5: 100.0000 (98.2807)  time: 0.3492  data: 0.0016  max mem: 2503
Train: Epoch[1/5]  [2430/3750]  eta: 0:07:38  Lr: 0.001875  Loss: -0.5151  Acc@1: 81.2500 (75.7122)  Acc@5: 100.0000 (98.2800)  time: 0.3489  data: 0.0013  max mem: 2503
Train: Epoch[1/5]  [2440/3750]  eta: 0:07:34  Lr: 0.001875  Loss: -0.6594  Acc@1: 81.2500 (75.7144)  Acc@5: 100.0000 (98.2845)  time: 0.3478  data: 0.0009  max mem: 2503
Train: Epoch[1/5]  [2450/3750]  eta: 0:07:31  Lr: 0.001875  Loss: -0.8229  Acc@1: 81.2500 (75.7318)  Acc@5: 100.0000 (98.2890)  time: 0.3478  data: 0.0010  max mem: 2503
Train: Epoch[1/5]  [2460/3750]  eta: 0:07:28  Lr: 0.001875  Loss: -0.9036  Acc@1: 75.0000 (75.7263)  Acc@5: 100.0000 (98.2883)  time: 0.3461  data: 0.0008  max mem: 2503
Train: Epoch[1/5]  [2470/3750]  eta: 0:07:24  Lr: 0.001875  Loss: -0.9381  Acc@1: 81.2500 (75.7537)  Acc@5: 100.0000 (98.2851)  time: 0.3432  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [2480/3750]  eta: 0:07:21  Lr: 0.001875  Loss: -0.9287  Acc@1: 81.2500 (75.7835)  Acc@5: 100.0000 (98.2920)  time: 0.3432  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [2490/3750]  eta: 0:07:17  Lr: 0.001875  Loss: 0.0369  Acc@1: 81.2500 (75.7878)  Acc@5: 100.0000 (98.2989)  time: 0.3452  data: 0.0006  max mem: 2503
Train: Epoch[1/5]  [2500/3750]  eta: 0:07:14  Lr: 0.001875  Loss: -0.2625  Acc@1: 75.0000 (75.7822)  Acc@5: 100.0000 (98.2957)  time: 0.3490  data: 0.0016  max mem: 2503
Train: Epoch[1/5]  [2510/3750]  eta: 0:07:10  Lr: 0.001875  Loss: -0.5171  Acc@1: 75.0000 (75.8040)  Acc@5: 100.0000 (98.2975)  time: 0.3515  data: 0.0015  max mem: 2503
Train: Epoch[1/5]  [2520/3750]  eta: 0:07:07  Lr: 0.001875  Loss: -0.6941  Acc@1: 81.2500 (75.8330)  Acc@5: 100.0000 (98.2993)  time: 0.3505  data: 0.0012  max mem: 2503
Train: Epoch[1/5]  [2530/3750]  eta: 0:07:03  Lr: 0.001875  Loss: -0.6943  Acc@1: 81.2500 (75.8445)  Acc@5: 100.0000 (98.3011)  time: 0.3506  data: 0.0015  max mem: 2503
Train: Epoch[1/5]  [2540/3750]  eta: 0:07:00  Lr: 0.001875  Loss: -0.3411  Acc@1: 81.2500 (75.8560)  Acc@5: 100.0000 (98.3053)  time: 0.3537  data: 0.0015  max mem: 2503
Train: Epoch[1/5]  [2550/3750]  eta: 0:06:56  Lr: 0.001875  Loss: -0.3865  Acc@1: 81.2500 (75.8600)  Acc@5: 100.0000 (98.3070)  time: 0.3524  data: 0.0017  max mem: 2503
Train: Epoch[1/5]  [2560/3750]  eta: 0:06:53  Lr: 0.001875  Loss: -0.5890  Acc@1: 81.2500 (75.8786)  Acc@5: 100.0000 (98.3112)  time: 0.3493  data: 0.0017  max mem: 2503
Train: Epoch[1/5]  [2570/3750]  eta: 0:06:49  Lr: 0.001875  Loss: -0.3726  Acc@1: 81.2500 (75.9165)  Acc@5: 100.0000 (98.3056)  time: 0.3499  data: 0.0015  max mem: 2503
Train: Epoch[1/5]  [2580/3750]  eta: 0:06:46  Lr: 0.001875  Loss: -0.6103  Acc@1: 81.2500 (75.9032)  Acc@5: 93.7500 (98.2977)  time: 0.3502  data: 0.0017  max mem: 2503
Train: Epoch[1/5]  [2590/3750]  eta: 0:06:42  Lr: 0.001875  Loss: -0.8153  Acc@1: 75.0000 (75.9239)  Acc@5: 100.0000 (98.2970)  time: 0.3477  data: 0.0011  max mem: 2503
Train: Epoch[1/5]  [2600/3750]  eta: 0:06:39  Lr: 0.001875  Loss: -0.5446  Acc@1: 81.2500 (75.9275)  Acc@5: 100.0000 (98.2963)  time: 0.3454  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [2610/3750]  eta: 0:06:35  Lr: 0.001875  Loss: -0.3056  Acc@1: 75.0000 (75.9312)  Acc@5: 100.0000 (98.2957)  time: 0.3442  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [2620/3750]  eta: 0:06:32  Lr: 0.001875  Loss: -0.3152  Acc@1: 75.0000 (75.9371)  Acc@5: 100.0000 (98.2998)  time: 0.3434  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [2630/3750]  eta: 0:06:29  Lr: 0.001875  Loss: -0.5624  Acc@1: 75.0000 (75.9478)  Acc@5: 100.0000 (98.3039)  time: 0.3438  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [2640/3750]  eta: 0:06:25  Lr: 0.001875  Loss: -0.7834  Acc@1: 75.0000 (75.9679)  Acc@5: 100.0000 (98.3008)  time: 0.3471  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [2650/3750]  eta: 0:06:22  Lr: 0.001875  Loss: -0.7969  Acc@1: 81.2500 (75.9973)  Acc@5: 100.0000 (98.3072)  time: 0.3514  data: 0.0007  max mem: 2503
Train: Epoch[1/5]  [2660/3750]  eta: 0:06:18  Lr: 0.001875  Loss: -0.7341  Acc@1: 81.2500 (75.9700)  Acc@5: 100.0000 (98.3089)  time: 0.3519  data: 0.0012  max mem: 2503
Train: Epoch[1/5]  [2670/3750]  eta: 0:06:15  Lr: 0.001875  Loss: -0.7243  Acc@1: 68.7500 (75.9734)  Acc@5: 100.0000 (98.3082)  time: 0.3519  data: 0.0017  max mem: 2503
Train: Epoch[1/5]  [2680/3750]  eta: 0:06:11  Lr: 0.001875  Loss: -0.4095  Acc@1: 81.2500 (75.9861)  Acc@5: 100.0000 (98.3122)  time: 0.3541  data: 0.0017  max mem: 2503
Train: Epoch[1/5]  [2690/3750]  eta: 0:06:08  Lr: 0.001875  Loss: -0.2861  Acc@1: 81.2500 (75.9987)  Acc@5: 100.0000 (98.3161)  time: 0.3524  data: 0.0015  max mem: 2503
Train: Epoch[1/5]  [2700/3750]  eta: 0:06:04  Lr: 0.001875  Loss: -0.1703  Acc@1: 81.2500 (76.0228)  Acc@5: 100.0000 (98.3178)  time: 0.3488  data: 0.0011  max mem: 2503
Train: Epoch[1/5]  [2710/3750]  eta: 0:06:01  Lr: 0.001875  Loss: -0.5059  Acc@1: 81.2500 (76.0121)  Acc@5: 100.0000 (98.3240)  time: 0.3488  data: 0.0009  max mem: 2503
Train: Epoch[1/5]  [2720/3750]  eta: 0:05:57  Lr: 0.001875  Loss: -0.7343  Acc@1: 75.0000 (76.0084)  Acc@5: 100.0000 (98.3255)  time: 0.3492  data: 0.0009  max mem: 2503
Train: Epoch[1/5]  [2730/3750]  eta: 0:05:54  Lr: 0.001875  Loss: -0.7178  Acc@1: 81.2500 (76.0230)  Acc@5: 100.0000 (98.3248)  time: 0.3479  data: 0.0007  max mem: 2503
Train: Epoch[1/5]  [2740/3750]  eta: 0:05:50  Lr: 0.001875  Loss: -0.0547  Acc@1: 81.2500 (76.0306)  Acc@5: 100.0000 (98.3286)  time: 0.3483  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [2750/3750]  eta: 0:05:47  Lr: 0.001875  Loss: -0.8517  Acc@1: 81.2500 (76.0496)  Acc@5: 100.0000 (98.3302)  time: 0.3468  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [2760/3750]  eta: 0:05:43  Lr: 0.001875  Loss: -0.5630  Acc@1: 81.2500 (76.0662)  Acc@5: 100.0000 (98.3317)  time: 0.3439  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [2770/3750]  eta: 0:05:40  Lr: 0.001875  Loss: -0.7339  Acc@1: 81.2500 (76.0691)  Acc@5: 100.0000 (98.3332)  time: 0.3437  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [2780/3750]  eta: 0:05:36  Lr: 0.001875  Loss: -0.6229  Acc@1: 81.2500 (76.0743)  Acc@5: 100.0000 (98.3392)  time: 0.3459  data: 0.0007  max mem: 2503
Train: Epoch[1/5]  [2790/3750]  eta: 0:05:33  Lr: 0.001875  Loss: 0.1545  Acc@1: 75.0000 (76.0794)  Acc@5: 100.0000 (98.3362)  time: 0.3481  data: 0.0012  max mem: 2503
Train: Epoch[1/5]  [2800/3750]  eta: 0:05:30  Lr: 0.001875  Loss: -0.7682  Acc@1: 81.2500 (76.0956)  Acc@5: 100.0000 (98.3376)  time: 0.3477  data: 0.0011  max mem: 2503
Train: Epoch[1/5]  [2810/3750]  eta: 0:05:26  Lr: 0.001875  Loss: -0.4796  Acc@1: 81.2500 (76.1095)  Acc@5: 100.0000 (98.3413)  time: 0.3499  data: 0.0020  max mem: 2503
Train: Epoch[1/5]  [2820/3750]  eta: 0:05:23  Lr: 0.001875  Loss: -0.3284  Acc@1: 81.2500 (76.1211)  Acc@5: 100.0000 (98.3472)  time: 0.3507  data: 0.0022  max mem: 2503
Train: Epoch[1/5]  [2830/3750]  eta: 0:05:19  Lr: 0.001875  Loss: -0.8439  Acc@1: 81.2500 (76.1259)  Acc@5: 100.0000 (98.3508)  time: 0.3504  data: 0.0016  max mem: 2503
Train: Epoch[1/5]  [2840/3750]  eta: 0:05:16  Lr: 0.001875  Loss: -0.9186  Acc@1: 81.2500 (76.1594)  Acc@5: 100.0000 (98.3545)  time: 0.3499  data: 0.0015  max mem: 2503
Train: Epoch[1/5]  [2850/3750]  eta: 0:05:12  Lr: 0.001875  Loss: -1.0704  Acc@1: 81.2500 (76.1882)  Acc@5: 100.0000 (98.3580)  time: 0.3499  data: 0.0023  max mem: 2503
Train: Epoch[1/5]  [2860/3750]  eta: 0:05:09  Lr: 0.001875  Loss: -0.9196  Acc@1: 81.2500 (76.2015)  Acc@5: 100.0000 (98.3572)  time: 0.3504  data: 0.0021  max mem: 2503
Train: Epoch[1/5]  [2870/3750]  eta: 0:05:05  Lr: 0.001875  Loss: -0.4230  Acc@1: 81.2500 (76.2321)  Acc@5: 100.0000 (98.3586)  time: 0.3499  data: 0.0014  max mem: 2503
Train: Epoch[1/5]  [2880/3750]  eta: 0:05:02  Lr: 0.001875  Loss: -0.6510  Acc@1: 81.2500 (76.2192)  Acc@5: 100.0000 (98.3599)  time: 0.3484  data: 0.0014  max mem: 2503
Train: Epoch[1/5]  [2890/3750]  eta: 0:04:58  Lr: 0.001875  Loss: -0.8924  Acc@1: 75.0000 (76.2323)  Acc@5: 100.0000 (98.3613)  time: 0.3467  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [2900/3750]  eta: 0:04:55  Lr: 0.001875  Loss: -0.5463  Acc@1: 75.0000 (76.2323)  Acc@5: 100.0000 (98.3669)  time: 0.3454  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [2910/3750]  eta: 0:04:51  Lr: 0.001875  Loss: -1.0824  Acc@1: 75.0000 (76.2238)  Acc@5: 100.0000 (98.3575)  time: 0.3438  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [2920/3750]  eta: 0:04:48  Lr: 0.001875  Loss: -0.4676  Acc@1: 75.0000 (76.2432)  Acc@5: 100.0000 (98.3610)  time: 0.3437  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [2930/3750]  eta: 0:04:44  Lr: 0.001875  Loss: -0.7612  Acc@1: 75.0000 (76.2389)  Acc@5: 100.0000 (98.3602)  time: 0.3462  data: 0.0007  max mem: 2503
Train: Epoch[1/5]  [2940/3750]  eta: 0:04:41  Lr: 0.001875  Loss: -0.5288  Acc@1: 81.2500 (76.2581)  Acc@5: 100.0000 (98.3594)  time: 0.3494  data: 0.0010  max mem: 2503
Train: Epoch[1/5]  [2950/3750]  eta: 0:04:37  Lr: 0.001875  Loss: -0.4875  Acc@1: 81.2500 (76.2453)  Acc@5: 100.0000 (98.3586)  time: 0.3508  data: 0.0016  max mem: 2503
Train: Epoch[1/5]  [2960/3750]  eta: 0:04:34  Lr: 0.001875  Loss: -0.9020  Acc@1: 68.7500 (76.2327)  Acc@5: 100.0000 (98.3578)  time: 0.3500  data: 0.0017  max mem: 2503
Train: Epoch[1/5]  [2970/3750]  eta: 0:04:31  Lr: 0.001875  Loss: -0.0477  Acc@1: 75.0000 (76.2496)  Acc@5: 100.0000 (98.3633)  time: 0.3513  data: 0.0012  max mem: 2503
Train: Epoch[1/5]  [2980/3750]  eta: 0:04:27  Lr: 0.001875  Loss: -0.6811  Acc@1: 75.0000 (76.2538)  Acc@5: 100.0000 (98.3625)  time: 0.3543  data: 0.0013  max mem: 2503
Train: Epoch[1/5]  [2990/3750]  eta: 0:04:24  Lr: 0.001875  Loss: -0.4836  Acc@1: 75.0000 (76.2538)  Acc@5: 100.0000 (98.3534)  time: 0.3509  data: 0.0011  max mem: 2503
Train: Epoch[1/5]  [3000/3750]  eta: 0:04:20  Lr: 0.001875  Loss: -0.8115  Acc@1: 75.0000 (76.2621)  Acc@5: 100.0000 (98.3568)  time: 0.3478  data: 0.0013  max mem: 2503
Train: Epoch[1/5]  [3010/3750]  eta: 0:04:17  Lr: 0.001875  Loss: -0.6919  Acc@1: 81.2500 (76.2807)  Acc@5: 100.0000 (98.3581)  time: 0.3480  data: 0.0016  max mem: 2503
Train: Epoch[1/5]  [3020/3750]  eta: 0:04:13  Lr: 0.001875  Loss: -0.6114  Acc@1: 81.2500 (76.2972)  Acc@5: 100.0000 (98.3594)  time: 0.3483  data: 0.0011  max mem: 2503
Train: Epoch[1/5]  [3030/3750]  eta: 0:04:10  Lr: 0.001875  Loss: -0.3693  Acc@1: 75.0000 (76.2970)  Acc@5: 100.0000 (98.3607)  time: 0.3507  data: 0.0010  max mem: 2503
Train: Epoch[1/5]  [3040/3750]  eta: 0:04:06  Lr: 0.001875  Loss: -0.6073  Acc@1: 75.0000 (76.3051)  Acc@5: 100.0000 (98.3620)  time: 0.3495  data: 0.0010  max mem: 2503
Train: Epoch[1/5]  [3050/3750]  eta: 0:04:03  Lr: 0.001875  Loss: -0.1799  Acc@1: 81.2500 (76.3151)  Acc@5: 100.0000 (98.3591)  time: 0.3470  data: 0.0006  max mem: 2503
Train: Epoch[1/5]  [3060/3750]  eta: 0:03:59  Lr: 0.001875  Loss: -0.4660  Acc@1: 81.2500 (76.3333)  Acc@5: 100.0000 (98.3625)  time: 0.3455  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [3070/3750]  eta: 0:03:56  Lr: 0.001875  Loss: -0.7796  Acc@1: 81.2500 (76.3371)  Acc@5: 100.0000 (98.3637)  time: 0.3435  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [3080/3750]  eta: 0:03:52  Lr: 0.001875  Loss: -0.4997  Acc@1: 75.0000 (76.3368)  Acc@5: 100.0000 (98.3690)  time: 0.3435  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [3090/3750]  eta: 0:03:49  Lr: 0.001875  Loss: -0.4625  Acc@1: 75.0000 (76.3406)  Acc@5: 100.0000 (98.3703)  time: 0.3467  data: 0.0012  max mem: 2503
Train: Epoch[1/5]  [3100/3750]  eta: 0:03:45  Lr: 0.001875  Loss: -0.5887  Acc@1: 75.0000 (76.3403)  Acc@5: 100.0000 (98.3735)  time: 0.3497  data: 0.0016  max mem: 2503
Train: Epoch[1/5]  [3110/3750]  eta: 0:03:42  Lr: 0.001875  Loss: -0.8753  Acc@1: 75.0000 (76.3420)  Acc@5: 100.0000 (98.3687)  time: 0.3484  data: 0.0012  max mem: 2503
Train: Epoch[1/5]  [3120/3750]  eta: 0:03:38  Lr: 0.001875  Loss: -0.7488  Acc@1: 81.2500 (76.3517)  Acc@5: 100.0000 (98.3659)  time: 0.3489  data: 0.0012  max mem: 2503
Train: Epoch[1/5]  [3130/3750]  eta: 0:03:35  Lr: 0.001875  Loss: -0.5216  Acc@1: 81.2500 (76.3554)  Acc@5: 100.0000 (98.3651)  time: 0.3519  data: 0.0017  max mem: 2503
Train: Epoch[1/5]  [3140/3750]  eta: 0:03:32  Lr: 0.001875  Loss: -0.7971  Acc@1: 75.0000 (76.3630)  Acc@5: 100.0000 (98.3664)  time: 0.3518  data: 0.0019  max mem: 2503
Train: Epoch[1/5]  [3150/3750]  eta: 0:03:28  Lr: 0.001875  Loss: -0.3356  Acc@1: 81.2500 (76.3567)  Acc@5: 100.0000 (98.3696)  time: 0.3507  data: 0.0018  max mem: 2503
Train: Epoch[1/5]  [3160/3750]  eta: 0:03:25  Lr: 0.001875  Loss: -0.8048  Acc@1: 81.2500 (76.3761)  Acc@5: 100.0000 (98.3727)  time: 0.3500  data: 0.0016  max mem: 2503
Train: Epoch[1/5]  [3170/3750]  eta: 0:03:21  Lr: 0.001875  Loss: -0.9628  Acc@1: 81.2500 (76.3955)  Acc@5: 100.0000 (98.3779)  time: 0.3492  data: 0.0017  max mem: 2503
Train: Epoch[1/5]  [3180/3750]  eta: 0:03:18  Lr: 0.001875  Loss: -0.4576  Acc@1: 81.2500 (76.4107)  Acc@5: 100.0000 (98.3790)  time: 0.3482  data: 0.0018  max mem: 2503
Train: Epoch[1/5]  [3190/3750]  eta: 0:03:14  Lr: 0.001875  Loss: -0.6095  Acc@1: 81.2500 (76.4278)  Acc@5: 100.0000 (98.3822)  time: 0.3474  data: 0.0009  max mem: 2503
Train: Epoch[1/5]  [3200/3750]  eta: 0:03:11  Lr: 0.001875  Loss: -0.5313  Acc@1: 81.2500 (76.4312)  Acc@5: 100.0000 (98.3814)  time: 0.3461  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [3210/3750]  eta: 0:03:07  Lr: 0.001875  Loss: -0.6505  Acc@1: 81.2500 (76.4443)  Acc@5: 100.0000 (98.3845)  time: 0.3437  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [3220/3750]  eta: 0:03:04  Lr: 0.001875  Loss: -0.3203  Acc@1: 81.2500 (76.4553)  Acc@5: 100.0000 (98.3856)  time: 0.3433  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [3230/3750]  eta: 0:03:00  Lr: 0.001875  Loss: -1.0143  Acc@1: 81.2500 (76.4721)  Acc@5: 100.0000 (98.3887)  time: 0.3442  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [3240/3750]  eta: 0:02:57  Lr: 0.001875  Loss: -0.3136  Acc@1: 81.2500 (76.4772)  Acc@5: 100.0000 (98.3917)  time: 0.3474  data: 0.0015  max mem: 2503
Train: Epoch[1/5]  [3250/3750]  eta: 0:02:53  Lr: 0.001875  Loss: -0.6692  Acc@1: 81.2500 (76.5034)  Acc@5: 100.0000 (98.3947)  time: 0.3496  data: 0.0019  max mem: 2503
Train: Epoch[1/5]  [3260/3750]  eta: 0:02:50  Lr: 0.001875  Loss: -0.3744  Acc@1: 81.2500 (76.5084)  Acc@5: 100.0000 (98.3958)  time: 0.3492  data: 0.0014  max mem: 2503
Train: Epoch[1/5]  [3270/3750]  eta: 0:02:46  Lr: 0.001875  Loss: -0.5297  Acc@1: 81.2500 (76.5076)  Acc@5: 100.0000 (98.3950)  time: 0.3505  data: 0.0013  max mem: 2503
Train: Epoch[1/5]  [3280/3750]  eta: 0:02:43  Lr: 0.001875  Loss: -0.5966  Acc@1: 81.2500 (76.5163)  Acc@5: 100.0000 (98.3942)  time: 0.3525  data: 0.0015  max mem: 2503
Train: Epoch[1/5]  [3290/3750]  eta: 0:02:39  Lr: 0.001875  Loss: -0.2531  Acc@1: 81.2500 (76.5364)  Acc@5: 100.0000 (98.3990)  time: 0.3516  data: 0.0016  max mem: 2503
Train: Epoch[1/5]  [3300/3750]  eta: 0:02:36  Lr: 0.001875  Loss: -0.7944  Acc@1: 81.2500 (76.5412)  Acc@5: 100.0000 (98.4020)  time: 0.3499  data: 0.0015  max mem: 2503
Train: Epoch[1/5]  [3310/3750]  eta: 0:02:32  Lr: 0.001875  Loss: -0.4433  Acc@1: 81.2500 (76.5498)  Acc@5: 100.0000 (98.4012)  time: 0.3504  data: 0.0014  max mem: 2503
Train: Epoch[1/5]  [3320/3750]  eta: 0:02:29  Lr: 0.001875  Loss: -0.4066  Acc@1: 75.0000 (76.5451)  Acc@5: 100.0000 (98.4022)  time: 0.3514  data: 0.0014  max mem: 2503
Train: Epoch[1/5]  [3330/3750]  eta: 0:02:25  Lr: 0.001875  Loss: -0.6440  Acc@1: 75.0000 (76.5348)  Acc@5: 100.0000 (98.3939)  time: 0.3497  data: 0.0011  max mem: 2503
Train: Epoch[1/5]  [3340/3750]  eta: 0:02:22  Lr: 0.001875  Loss: -0.4467  Acc@1: 75.0000 (76.5396)  Acc@5: 100.0000 (98.3968)  time: 0.3472  data: 0.0007  max mem: 2503
Train: Epoch[1/5]  [3350/3750]  eta: 0:02:19  Lr: 0.001875  Loss: -0.6649  Acc@1: 75.0000 (76.5462)  Acc@5: 100.0000 (98.3997)  time: 0.3456  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [3360/3750]  eta: 0:02:15  Lr: 0.001875  Loss: -0.9292  Acc@1: 81.2500 (76.5527)  Acc@5: 100.0000 (98.4008)  time: 0.3445  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [3370/3750]  eta: 0:02:12  Lr: 0.001875  Loss: -0.5712  Acc@1: 81.2500 (76.5722)  Acc@5: 100.0000 (98.4055)  time: 0.3446  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [3380/3750]  eta: 0:02:08  Lr: 0.001875  Loss: -0.5634  Acc@1: 81.2500 (76.5768)  Acc@5: 100.0000 (98.4084)  time: 0.3457  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [3390/3750]  eta: 0:02:05  Lr: 0.001875  Loss: -0.6557  Acc@1: 81.2500 (76.5943)  Acc@5: 100.0000 (98.4075)  time: 0.3480  data: 0.0009  max mem: 2503
Train: Epoch[1/5]  [3400/3750]  eta: 0:02:01  Lr: 0.001875  Loss: -0.7926  Acc@1: 81.2500 (76.5933)  Acc@5: 100.0000 (98.4122)  time: 0.3492  data: 0.0012  max mem: 2503
Train: Epoch[1/5]  [3410/3750]  eta: 0:01:58  Lr: 0.001875  Loss: -0.6398  Acc@1: 75.0000 (76.5941)  Acc@5: 100.0000 (98.4114)  time: 0.3492  data: 0.0015  max mem: 2503
Train: Epoch[1/5]  [3420/3750]  eta: 0:01:54  Lr: 0.001875  Loss: -0.4985  Acc@1: 81.2500 (76.6059)  Acc@5: 100.0000 (98.4124)  time: 0.3523  data: 0.0017  max mem: 2503
Train: Epoch[1/5]  [3430/3750]  eta: 0:01:51  Lr: 0.001875  Loss: -0.6592  Acc@1: 75.0000 (76.6121)  Acc@5: 100.0000 (98.4115)  time: 0.3545  data: 0.0022  max mem: 2503
Train: Epoch[1/5]  [3440/3750]  eta: 0:01:47  Lr: 0.001875  Loss: -0.6059  Acc@1: 75.0000 (76.6238)  Acc@5: 100.0000 (98.4162)  time: 0.3520  data: 0.0025  max mem: 2503
Train: Epoch[1/5]  [3450/3750]  eta: 0:01:44  Lr: 0.001875  Loss: -0.7528  Acc@1: 81.2500 (76.6245)  Acc@5: 100.0000 (98.4171)  time: 0.3512  data: 0.0030  max mem: 2503
Train: Epoch[1/5]  [3460/3750]  eta: 0:01:40  Lr: 0.001875  Loss: -0.5504  Acc@1: 81.2500 (76.6271)  Acc@5: 100.0000 (98.4199)  time: 0.3510  data: 0.0026  max mem: 2503
Train: Epoch[1/5]  [3470/3750]  eta: 0:01:37  Lr: 0.001875  Loss: -0.0543  Acc@1: 75.0000 (76.6206)  Acc@5: 100.0000 (98.4208)  time: 0.3500  data: 0.0010  max mem: 2503
Train: Epoch[1/5]  [3480/3750]  eta: 0:01:33  Lr: 0.001875  Loss: -0.7276  Acc@1: 81.2500 (76.6428)  Acc@5: 100.0000 (98.4218)  time: 0.3484  data: 0.0007  max mem: 2503
Train: Epoch[1/5]  [3490/3750]  eta: 0:01:30  Lr: 0.001875  Loss: -0.2829  Acc@1: 81.2500 (76.6543)  Acc@5: 100.0000 (98.4227)  time: 0.3475  data: 0.0006  max mem: 2503
Train: Epoch[1/5]  [3500/3750]  eta: 0:01:26  Lr: 0.001875  Loss: -0.4721  Acc@1: 81.2500 (76.6567)  Acc@5: 100.0000 (98.4183)  time: 0.3463  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [3510/3750]  eta: 0:01:23  Lr: 0.001875  Loss: -0.4971  Acc@1: 75.0000 (76.6626)  Acc@5: 100.0000 (98.4121)  time: 0.3440  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [3520/3750]  eta: 0:01:19  Lr: 0.001875  Loss: -0.8431  Acc@1: 81.2500 (76.6739)  Acc@5: 100.0000 (98.4131)  time: 0.3440  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [3530/3750]  eta: 0:01:16  Lr: 0.001875  Loss: -0.9156  Acc@1: 81.2500 (76.6886)  Acc@5: 100.0000 (98.4176)  time: 0.3474  data: 0.0010  max mem: 2503
Train: Epoch[1/5]  [3540/3750]  eta: 0:01:13  Lr: 0.001875  Loss: -0.9095  Acc@1: 81.2500 (76.7050)  Acc@5: 100.0000 (98.4221)  time: 0.3497  data: 0.0015  max mem: 2503
Train: Epoch[1/5]  [3550/3750]  eta: 0:01:09  Lr: 0.001875  Loss: -0.7283  Acc@1: 81.2500 (76.7178)  Acc@5: 100.0000 (98.4195)  time: 0.3493  data: 0.0013  max mem: 2503
Train: Epoch[1/5]  [3560/3750]  eta: 0:01:06  Lr: 0.001875  Loss: -0.5201  Acc@1: 81.2500 (76.7323)  Acc@5: 100.0000 (98.4186)  time: 0.3492  data: 0.0010  max mem: 2503
Train: Epoch[1/5]  [3570/3750]  eta: 0:01:02  Lr: 0.001875  Loss: -0.4336  Acc@1: 81.2500 (76.7327)  Acc@5: 100.0000 (98.4196)  time: 0.3506  data: 0.0019  max mem: 2503
Train: Epoch[1/5]  [3580/3750]  eta: 0:00:59  Lr: 0.001875  Loss: -0.2358  Acc@1: 81.2500 (76.7401)  Acc@5: 100.0000 (98.4222)  time: 0.3510  data: 0.0021  max mem: 2503
Train: Epoch[1/5]  [3590/3750]  eta: 0:00:55  Lr: 0.001875  Loss: -0.9760  Acc@1: 81.2500 (76.7526)  Acc@5: 100.0000 (98.4249)  time: 0.3495  data: 0.0014  max mem: 2503
Train: Epoch[1/5]  [3600/3750]  eta: 0:00:52  Lr: 0.001875  Loss: -1.0015  Acc@1: 81.2500 (76.7651)  Acc@5: 100.0000 (98.4275)  time: 0.3487  data: 0.0015  max mem: 2503
Train: Epoch[1/5]  [3610/3750]  eta: 0:00:48  Lr: 0.001875  Loss: -0.8884  Acc@1: 81.2500 (76.7879)  Acc@5: 100.0000 (98.4284)  time: 0.3489  data: 0.0011  max mem: 2503
Train: Epoch[1/5]  [3620/3750]  eta: 0:00:45  Lr: 0.001875  Loss: -0.6320  Acc@1: 81.2500 (76.7916)  Acc@5: 100.0000 (98.4276)  time: 0.3482  data: 0.0012  max mem: 2503
Train: Epoch[1/5]  [3630/3750]  eta: 0:00:41  Lr: 0.001875  Loss: -0.7144  Acc@1: 75.0000 (76.8022)  Acc@5: 100.0000 (98.4285)  time: 0.3471  data: 0.0008  max mem: 2503
Train: Epoch[1/5]  [3640/3750]  eta: 0:00:38  Lr: 0.001875  Loss: -0.1861  Acc@1: 75.0000 (76.7955)  Acc@5: 100.0000 (98.4311)  time: 0.3460  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [3650/3750]  eta: 0:00:34  Lr: 0.001875  Loss: -0.4428  Acc@1: 81.2500 (76.8197)  Acc@5: 100.0000 (98.4319)  time: 0.3442  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [3660/3750]  eta: 0:00:31  Lr: 0.001875  Loss: -0.5287  Acc@1: 81.2500 (76.8182)  Acc@5: 100.0000 (98.4345)  time: 0.3437  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [3670/3750]  eta: 0:00:27  Lr: 0.001875  Loss: -0.4084  Acc@1: 81.2500 (76.8353)  Acc@5: 100.0000 (98.4337)  time: 0.3443  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [3680/3750]  eta: 0:00:24  Lr: 0.001875  Loss: -0.7636  Acc@1: 81.2500 (76.8371)  Acc@5: 100.0000 (98.4379)  time: 0.3479  data: 0.0015  max mem: 2503
Train: Epoch[1/5]  [3690/3750]  eta: 0:00:20  Lr: 0.001875  Loss: -0.2542  Acc@1: 81.2500 (76.8457)  Acc@5: 100.0000 (98.4337)  time: 0.3507  data: 0.0031  max mem: 2503
Train: Epoch[1/5]  [3700/3750]  eta: 0:00:17  Lr: 0.001875  Loss: -0.7699  Acc@1: 81.2500 (76.8509)  Acc@5: 100.0000 (98.4379)  time: 0.3503  data: 0.0025  max mem: 2503
Train: Epoch[1/5]  [3710/3750]  eta: 0:00:13  Lr: 0.001875  Loss: -0.2892  Acc@1: 81.2500 (76.8711)  Acc@5: 100.0000 (98.4388)  time: 0.3512  data: 0.0022  max mem: 2503
Train: Epoch[1/5]  [3720/3750]  eta: 0:00:10  Lr: 0.001875  Loss: -0.7292  Acc@1: 81.2500 (76.8846)  Acc@5: 100.0000 (98.4413)  time: 0.3527  data: 0.0022  max mem: 2503
Train: Epoch[1/5]  [3730/3750]  eta: 0:00:06  Lr: 0.001875  Loss: -0.3374  Acc@1: 75.0000 (76.8879)  Acc@5: 100.0000 (98.4404)  time: 0.3526  data: 0.0024  max mem: 2503
Train: Epoch[1/5]  [3740/3750]  eta: 0:00:03  Lr: 0.001875  Loss: -0.6193  Acc@1: 75.0000 (76.8962)  Acc@5: 100.0000 (98.4429)  time: 0.3498  data: 0.0025  max mem: 2503
Train: Epoch[1/5]  [3749/3750]  eta: 0:00:00  Lr: 0.001875  Loss: 0.5877  Acc@1: 81.2500 (76.9000)  Acc@5: 100.0000 (98.4417)  time: 0.3482  data: 0.0017  max mem: 2503
Train: Epoch[1/5] Total time: 0:21:44 (0.3479 s / it)
{0: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 1: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 2: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 3: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 4: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 5: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 6: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 7: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 8: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 9: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 10: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 11: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 12: {0: 0, 1: 0, 2: 0, 3: 91325, 4: 0}, 13: {0: 0, 1: 0, 2: 0, 3: 91325, 4: 0}, 14: {0: 0, 1: 0, 2: 0, 3: 91325, 4: 0}, 15: {0: 0, 1: 0, 2: 0, 3: 91325, 4: 0}, 16: {0: 0, 1: 0, 2: 0, 3: 0, 4: 60000}, 17: {0: 0, 1: 0, 2: 0, 3: 0, 4: 60000}, 18: {0: 0, 1: 0, 2: 0, 3: 0, 4: 60000}, 19: {0: 0, 1: 0, 2: 0, 3: 0, 4: 60000}}
Averaged stats: Lr: 0.001875  Loss: 0.5877  Acc@1: 81.2500 (76.9000)  Acc@5: 100.0000 (98.4417)
Train: Epoch[2/5]  [   0/3750]  eta: 0:56:51  Lr: 0.001875  Loss: -0.8139  Acc@1: 81.2500 (81.2500)  Acc@5: 100.0000 (100.0000)  time: 0.9098  data: 0.5542  max mem: 2503
Train: Epoch[2/5]  [  10/3750]  eta: 0:24:48  Lr: 0.001875  Loss: -0.7787  Acc@1: 81.2500 (81.8182)  Acc@5: 100.0000 (99.4318)  time: 0.3979  data: 0.0510  max mem: 2503
Train: Epoch[2/5]  [  20/3750]  eta: 0:23:16  Lr: 0.001875  Loss: -0.5500  Acc@1: 81.2500 (81.5476)  Acc@5: 100.0000 (99.4048)  time: 0.3476  data: 0.0006  max mem: 2503
Train: Epoch[2/5]  [  30/3750]  eta: 0:22:40  Lr: 0.001875  Loss: -0.7333  Acc@1: 81.2500 (81.0484)  Acc@5: 100.0000 (99.1935)  time: 0.3481  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [  40/3750]  eta: 0:22:17  Lr: 0.001875  Loss: -0.7189  Acc@1: 81.2500 (80.3354)  Acc@5: 100.0000 (98.9329)  time: 0.3460  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [  50/3750]  eta: 0:22:02  Lr: 0.001875  Loss: -0.6977  Acc@1: 75.0000 (79.7794)  Acc@5: 100.0000 (99.1422)  time: 0.3442  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [  60/3750]  eta: 0:21:50  Lr: 0.001875  Loss: -0.4895  Acc@1: 81.2500 (79.4057)  Acc@5: 100.0000 (99.2828)  time: 0.3441  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [  70/3750]  eta: 0:21:43  Lr: 0.001875  Loss: -0.7944  Acc@1: 81.2500 (78.8732)  Acc@5: 100.0000 (99.2077)  time: 0.3466  data: 0.0014  max mem: 2503
Train: Epoch[2/5]  [  80/3750]  eta: 0:21:39  Lr: 0.001875  Loss: -0.8365  Acc@1: 81.2500 (79.1667)  Acc@5: 100.0000 (99.3056)  time: 0.3506  data: 0.0026  max mem: 2503
Train: Epoch[2/5]  [  90/3750]  eta: 0:21:34  Lr: 0.001875  Loss: -0.8602  Acc@1: 81.2500 (79.0522)  Acc@5: 100.0000 (99.2445)  time: 0.3512  data: 0.0022  max mem: 2503
Train: Epoch[2/5]  [ 100/3750]  eta: 0:21:30  Lr: 0.001875  Loss: -0.8911  Acc@1: 81.2500 (79.1460)  Acc@5: 100.0000 (99.2574)  time: 0.3513  data: 0.0022  max mem: 2503
Train: Epoch[2/5]  [ 110/3750]  eta: 0:21:26  Lr: 0.001875  Loss: -0.4866  Acc@1: 81.2500 (79.2793)  Acc@5: 100.0000 (99.2117)  time: 0.3525  data: 0.0020  max mem: 2503
Train: Epoch[2/5]  [ 120/3750]  eta: 0:21:21  Lr: 0.001875  Loss: -0.4725  Acc@1: 81.2500 (79.2355)  Acc@5: 100.0000 (99.1736)  time: 0.3512  data: 0.0016  max mem: 2503
Train: Epoch[2/5]  [ 130/3750]  eta: 0:21:17  Lr: 0.001875  Loss: -0.7019  Acc@1: 81.2500 (79.2462)  Acc@5: 100.0000 (99.0935)  time: 0.3501  data: 0.0016  max mem: 2503
Train: Epoch[2/5]  [ 140/3750]  eta: 0:21:12  Lr: 0.001875  Loss: -0.5129  Acc@1: 81.2500 (79.5213)  Acc@5: 100.0000 (99.1578)  time: 0.3486  data: 0.0011  max mem: 2503
Train: Epoch[2/5]  [ 150/3750]  eta: 0:21:08  Lr: 0.001875  Loss: -0.7145  Acc@1: 81.2500 (79.4288)  Acc@5: 100.0000 (99.1308)  time: 0.3479  data: 0.0010  max mem: 2503
Train: Epoch[2/5]  [ 160/3750]  eta: 0:21:03  Lr: 0.001875  Loss: -0.8661  Acc@1: 81.2500 (79.7360)  Acc@5: 100.0000 (99.0683)  time: 0.3486  data: 0.0010  max mem: 2503
Train: Epoch[2/5]  [ 170/3750]  eta: 0:20:59  Lr: 0.001875  Loss: -0.2506  Acc@1: 81.2500 (79.6784)  Acc@5: 100.0000 (99.0863)  time: 0.3497  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [ 180/3750]  eta: 0:20:54  Lr: 0.001875  Loss: -0.6419  Acc@1: 75.0000 (79.4544)  Acc@5: 100.0000 (99.0677)  time: 0.3478  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [ 190/3750]  eta: 0:20:50  Lr: 0.001875  Loss: -0.5139  Acc@1: 75.0000 (79.3848)  Acc@5: 100.0000 (99.0510)  time: 0.3442  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [ 200/3750]  eta: 0:20:45  Lr: 0.001875  Loss: -0.8148  Acc@1: 81.2500 (79.6331)  Acc@5: 100.0000 (99.0361)  time: 0.3444  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [ 210/3750]  eta: 0:20:41  Lr: 0.001875  Loss: -0.6048  Acc@1: 81.2500 (79.6801)  Acc@5: 100.0000 (98.9929)  time: 0.3451  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [ 220/3750]  eta: 0:20:37  Lr: 0.001875  Loss: -0.8555  Acc@1: 81.2500 (79.8360)  Acc@5: 100.0000 (98.9536)  time: 0.3474  data: 0.0010  max mem: 2503
Train: Epoch[2/5]  [ 230/3750]  eta: 0:20:33  Lr: 0.001875  Loss: -0.7442  Acc@1: 81.2500 (79.7348)  Acc@5: 100.0000 (98.9177)  time: 0.3485  data: 0.0012  max mem: 2503
Train: Epoch[2/5]  [ 240/3750]  eta: 0:20:30  Lr: 0.001875  Loss: -0.8407  Acc@1: 81.2500 (79.6680)  Acc@5: 100.0000 (98.8589)  time: 0.3498  data: 0.0015  max mem: 2503
Train: Epoch[2/5]  [ 250/3750]  eta: 0:20:26  Lr: 0.001875  Loss: -0.6538  Acc@1: 81.2500 (79.6813)  Acc@5: 100.0000 (98.8048)  time: 0.3518  data: 0.0017  max mem: 2503
Train: Epoch[2/5]  [ 260/3750]  eta: 0:20:23  Lr: 0.001875  Loss: -0.6544  Acc@1: 81.2500 (79.5498)  Acc@5: 100.0000 (98.8027)  time: 0.3514  data: 0.0011  max mem: 2503
Train: Epoch[2/5]  [ 270/3750]  eta: 0:20:19  Lr: 0.001875  Loss: -0.8578  Acc@1: 81.2500 (79.7279)  Acc@5: 100.0000 (98.8238)  time: 0.3494  data: 0.0010  max mem: 2503
Train: Epoch[2/5]  [ 280/3750]  eta: 0:20:16  Lr: 0.001875  Loss: -0.3265  Acc@1: 81.2500 (79.5596)  Acc@5: 100.0000 (98.7989)  time: 0.3493  data: 0.0012  max mem: 2503
Train: Epoch[2/5]  [ 290/3750]  eta: 0:20:12  Lr: 0.001875  Loss: -0.5212  Acc@1: 75.0000 (79.6607)  Acc@5: 100.0000 (98.7973)  time: 0.3509  data: 0.0017  max mem: 2503
Train: Epoch[2/5]  [ 300/3750]  eta: 0:20:09  Lr: 0.001875  Loss: -0.2580  Acc@1: 75.0000 (79.2982)  Acc@5: 100.0000 (98.7126)  time: 0.3512  data: 0.0026  max mem: 2503
Train: Epoch[2/5]  [ 310/3750]  eta: 0:20:05  Lr: 0.001875  Loss: -0.7390  Acc@1: 75.0000 (79.2605)  Acc@5: 100.0000 (98.6937)  time: 0.3508  data: 0.0019  max mem: 2503
Train: Epoch[2/5]  [ 320/3750]  eta: 0:20:01  Lr: 0.001875  Loss: -0.9010  Acc@1: 81.2500 (79.3030)  Acc@5: 100.0000 (98.7150)  time: 0.3490  data: 0.0007  max mem: 2503
Train: Epoch[2/5]  [ 330/3750]  eta: 0:19:58  Lr: 0.001875  Loss: -0.8469  Acc@1: 81.2500 (79.3995)  Acc@5: 100.0000 (98.7538)  time: 0.3475  data: 0.0006  max mem: 2503
Train: Epoch[2/5]  [ 340/3750]  eta: 0:19:54  Lr: 0.001875  Loss: -0.9715  Acc@1: 81.2500 (79.3988)  Acc@5: 100.0000 (98.7720)  time: 0.3464  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [ 350/3750]  eta: 0:19:50  Lr: 0.001875  Loss: -0.4445  Acc@1: 75.0000 (79.2913)  Acc@5: 100.0000 (98.7714)  time: 0.3451  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [ 360/3750]  eta: 0:19:46  Lr: 0.001875  Loss: -0.3921  Acc@1: 75.0000 (79.2763)  Acc@5: 100.0000 (98.7708)  time: 0.3450  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [ 370/3750]  eta: 0:19:42  Lr: 0.001875  Loss: -0.7349  Acc@1: 81.2500 (79.2453)  Acc@5: 100.0000 (98.7702)  time: 0.3454  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [ 380/3750]  eta: 0:19:38  Lr: 0.001875  Loss: -0.6201  Acc@1: 81.2500 (79.3799)  Acc@5: 100.0000 (98.7533)  time: 0.3479  data: 0.0008  max mem: 2503
Train: Epoch[2/5]  [ 390/3750]  eta: 0:19:35  Lr: 0.001875  Loss: -1.0260  Acc@1: 81.2500 (79.4597)  Acc@5: 100.0000 (98.7532)  time: 0.3497  data: 0.0013  max mem: 2503
Train: Epoch[2/5]  [ 400/3750]  eta: 0:19:31  Lr: 0.001875  Loss: -0.8147  Acc@1: 87.5000 (79.5823)  Acc@5: 100.0000 (98.7375)  time: 0.3495  data: 0.0012  max mem: 2503
Train: Epoch[2/5]  [ 410/3750]  eta: 0:19:28  Lr: 0.001875  Loss: -0.4155  Acc@1: 81.2500 (79.6077)  Acc@5: 100.0000 (98.7074)  time: 0.3494  data: 0.0011  max mem: 2503
Train: Epoch[2/5]  [ 420/3750]  eta: 0:19:25  Lr: 0.001875  Loss: -0.5077  Acc@1: 81.2500 (79.5279)  Acc@5: 100.0000 (98.7084)  time: 0.3524  data: 0.0012  max mem: 2503
Train: Epoch[2/5]  [ 430/3750]  eta: 0:19:21  Lr: 0.001875  Loss: -0.6104  Acc@1: 81.2500 (79.5824)  Acc@5: 100.0000 (98.7094)  time: 0.3522  data: 0.0010  max mem: 2503
Train: Epoch[2/5]  [ 440/3750]  eta: 0:19:17  Lr: 0.001875  Loss: -0.5277  Acc@1: 81.2500 (79.6060)  Acc@5: 100.0000 (98.6820)  time: 0.3481  data: 0.0006  max mem: 2503
Train: Epoch[2/5]  [ 450/3750]  eta: 0:19:14  Lr: 0.001875  Loss: -0.6174  Acc@1: 81.2500 (79.5593)  Acc@5: 100.0000 (98.6973)  time: 0.3468  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [ 460/3750]  eta: 0:19:10  Lr: 0.001875  Loss: -0.7657  Acc@1: 81.2500 (79.5418)  Acc@5: 100.0000 (98.7120)  time: 0.3469  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [ 470/3750]  eta: 0:19:06  Lr: 0.001875  Loss: -0.7789  Acc@1: 75.0000 (79.5382)  Acc@5: 100.0000 (98.7394)  time: 0.3473  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [ 480/3750]  eta: 0:19:02  Lr: 0.001875  Loss: -0.2910  Acc@1: 81.2500 (79.5608)  Acc@5: 100.0000 (98.7526)  time: 0.3459  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [ 490/3750]  eta: 0:18:59  Lr: 0.001875  Loss: -0.5947  Acc@1: 81.2500 (79.5570)  Acc@5: 100.0000 (98.7780)  time: 0.3441  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [ 500/3750]  eta: 0:18:55  Lr: 0.001875  Loss: -0.4303  Acc@1: 81.2500 (79.6033)  Acc@5: 100.0000 (98.7525)  time: 0.3442  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [ 510/3750]  eta: 0:18:51  Lr: 0.001875  Loss: -0.3881  Acc@1: 81.2500 (79.6355)  Acc@5: 100.0000 (98.7402)  time: 0.3468  data: 0.0006  max mem: 2503
Train: Epoch[2/5]  [ 520/3750]  eta: 0:18:48  Lr: 0.001875  Loss: -0.8162  Acc@1: 81.2500 (79.6665)  Acc@5: 100.0000 (98.7644)  time: 0.3487  data: 0.0017  max mem: 2503
Train: Epoch[2/5]  [ 530/3750]  eta: 0:18:44  Lr: 0.001875  Loss: -0.8869  Acc@1: 81.2500 (79.6257)  Acc@5: 100.0000 (98.7641)  time: 0.3488  data: 0.0025  max mem: 2503
Train: Epoch[2/5]  [ 540/3750]  eta: 0:18:40  Lr: 0.001875  Loss: -0.3615  Acc@1: 75.0000 (79.5171)  Acc@5: 100.0000 (98.7754)  time: 0.3473  data: 0.0014  max mem: 2503
Train: Epoch[2/5]  [ 550/3750]  eta: 0:18:37  Lr: 0.001875  Loss: -0.6869  Acc@1: 75.0000 (79.5712)  Acc@5: 100.0000 (98.7750)  time: 0.3467  data: 0.0007  max mem: 2503
Train: Epoch[2/5]  [ 560/3750]  eta: 0:18:33  Lr: 0.001875  Loss: -0.7555  Acc@1: 81.2500 (79.5343)  Acc@5: 100.0000 (98.7968)  time: 0.3478  data: 0.0007  max mem: 2503
Train: Epoch[2/5]  [ 570/3750]  eta: 0:18:30  Lr: 0.001875  Loss: -0.9194  Acc@1: 75.0000 (79.5206)  Acc@5: 100.0000 (98.8069)  time: 0.3475  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [ 580/3750]  eta: 0:18:26  Lr: 0.001875  Loss: -0.7125  Acc@1: 81.2500 (79.6041)  Acc@5: 100.0000 (98.8059)  time: 0.3472  data: 0.0013  max mem: 2503
Train: Epoch[2/5]  [ 590/3750]  eta: 0:18:23  Lr: 0.001875  Loss: -0.2934  Acc@1: 81.2500 (79.6320)  Acc@5: 100.0000 (98.8156)  time: 0.3472  data: 0.0014  max mem: 2503
Train: Epoch[2/5]  [ 600/3750]  eta: 0:18:19  Lr: 0.001875  Loss: -0.5535  Acc@1: 81.2500 (79.6277)  Acc@5: 100.0000 (98.8145)  time: 0.3471  data: 0.0007  max mem: 2503
Train: Epoch[2/5]  [ 610/3750]  eta: 0:18:16  Lr: 0.001875  Loss: -0.6276  Acc@1: 75.0000 (79.6133)  Acc@5: 100.0000 (98.8339)  time: 0.3507  data: 0.0006  max mem: 2503
Train: Epoch[2/5]  [ 620/3750]  eta: 0:18:12  Lr: 0.001875  Loss: -0.5026  Acc@1: 75.0000 (79.5592)  Acc@5: 100.0000 (98.8325)  time: 0.3496  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [ 630/3750]  eta: 0:18:08  Lr: 0.001875  Loss: -0.2300  Acc@1: 75.0000 (79.5166)  Acc@5: 100.0000 (98.8510)  time: 0.3457  data: 0.0006  max mem: 2503
Train: Epoch[2/5]  [ 640/3750]  eta: 0:18:05  Lr: 0.001875  Loss: -0.5695  Acc@1: 75.0000 (79.4657)  Acc@5: 100.0000 (98.8397)  time: 0.3446  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [ 650/3750]  eta: 0:18:01  Lr: 0.001875  Loss: -0.5257  Acc@1: 75.0000 (79.4547)  Acc@5: 100.0000 (98.8287)  time: 0.3435  data: 0.0008  max mem: 2503
Train: Epoch[2/5]  [ 660/3750]  eta: 0:17:57  Lr: 0.001875  Loss: -0.6728  Acc@1: 81.2500 (79.4913)  Acc@5: 100.0000 (98.8275)  time: 0.3445  data: 0.0015  max mem: 2503
Train: Epoch[2/5]  [ 670/3750]  eta: 0:17:54  Lr: 0.001875  Loss: -0.9939  Acc@1: 81.2500 (79.4244)  Acc@5: 100.0000 (98.8077)  time: 0.3470  data: 0.0014  max mem: 2503
Train: Epoch[2/5]  [ 680/3750]  eta: 0:17:50  Lr: 0.001875  Loss: -0.8527  Acc@1: 75.0000 (79.4420)  Acc@5: 100.0000 (98.8069)  time: 0.3488  data: 0.0013  max mem: 2503
Train: Epoch[2/5]  [ 690/3750]  eta: 0:17:47  Lr: 0.001875  Loss: -0.6483  Acc@1: 75.0000 (79.3777)  Acc@5: 100.0000 (98.8061)  time: 0.3480  data: 0.0015  max mem: 2503
Train: Epoch[2/5]  [ 700/3750]  eta: 0:17:43  Lr: 0.001875  Loss: -0.7237  Acc@1: 75.0000 (79.3955)  Acc@5: 100.0000 (98.8142)  time: 0.3482  data: 0.0011  max mem: 2503
Train: Epoch[2/5]  [ 710/3750]  eta: 0:17:40  Lr: 0.001875  Loss: -0.4766  Acc@1: 81.2500 (79.3601)  Acc@5: 100.0000 (98.8133)  time: 0.3479  data: 0.0007  max mem: 2503
Train: Epoch[2/5]  [ 720/3750]  eta: 0:17:36  Lr: 0.001875  Loss: -0.2188  Acc@1: 75.0000 (79.2996)  Acc@5: 100.0000 (98.7951)  time: 0.3474  data: 0.0012  max mem: 2503
Train: Epoch[2/5]  [ 730/3750]  eta: 0:17:33  Lr: 0.001875  Loss: -0.6754  Acc@1: 75.0000 (79.2579)  Acc@5: 100.0000 (98.7945)  time: 0.3484  data: 0.0012  max mem: 2503
Train: Epoch[2/5]  [ 740/3750]  eta: 0:17:29  Lr: 0.001875  Loss: -0.5570  Acc@1: 75.0000 (79.2679)  Acc@5: 100.0000 (98.7686)  time: 0.3482  data: 0.0015  max mem: 2503
Train: Epoch[2/5]  [ 750/3750]  eta: 0:17:26  Lr: 0.001875  Loss: -0.1875  Acc@1: 81.2500 (79.2776)  Acc@5: 100.0000 (98.7600)  time: 0.3473  data: 0.0014  max mem: 2503
Train: Epoch[2/5]  [ 760/3750]  eta: 0:17:22  Lr: 0.001875  Loss: -0.5694  Acc@1: 75.0000 (79.2378)  Acc@5: 100.0000 (98.7599)  time: 0.3469  data: 0.0007  max mem: 2503
Train: Epoch[2/5]  [ 770/3750]  eta: 0:17:18  Lr: 0.001875  Loss: -0.7779  Acc@1: 75.0000 (79.2720)  Acc@5: 100.0000 (98.7759)  time: 0.3473  data: 0.0006  max mem: 2503
Train: Epoch[2/5]  [ 780/3750]  eta: 0:17:15  Lr: 0.001875  Loss: -0.7911  Acc@1: 75.0000 (79.2173)  Acc@5: 100.0000 (98.7836)  time: 0.3470  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [ 790/3750]  eta: 0:17:11  Lr: 0.001875  Loss: -0.8860  Acc@1: 75.0000 (79.2430)  Acc@5: 100.0000 (98.7832)  time: 0.3478  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [ 800/3750]  eta: 0:17:08  Lr: 0.001875  Loss: -0.6708  Acc@1: 81.2500 (79.2603)  Acc@5: 100.0000 (98.7828)  time: 0.3458  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [ 810/3750]  eta: 0:17:04  Lr: 0.001875  Loss: -0.4157  Acc@1: 81.2500 (79.2694)  Acc@5: 100.0000 (98.7978)  time: 0.3424  data: 0.0002  max mem: 2503
Train: Epoch[2/5]  [ 820/3750]  eta: 0:17:00  Lr: 0.001875  Loss: -0.5615  Acc@1: 81.2500 (79.3012)  Acc@5: 100.0000 (98.7972)  time: 0.3426  data: 0.0002  max mem: 2503
Train: Epoch[2/5]  [ 830/3750]  eta: 0:16:57  Lr: 0.001875  Loss: -0.7329  Acc@1: 81.2500 (79.3397)  Acc@5: 100.0000 (98.8042)  time: 0.3448  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [ 840/3750]  eta: 0:16:53  Lr: 0.001875  Loss: -0.6783  Acc@1: 81.2500 (79.3921)  Acc@5: 100.0000 (98.8109)  time: 0.3478  data: 0.0015  max mem: 2503
Train: Epoch[2/5]  [ 850/3750]  eta: 0:16:50  Lr: 0.001875  Loss: -0.4618  Acc@1: 81.2500 (79.3184)  Acc@5: 100.0000 (98.7955)  time: 0.3488  data: 0.0019  max mem: 2503
Train: Epoch[2/5]  [ 860/3750]  eta: 0:16:46  Lr: 0.001875  Loss: -0.2220  Acc@1: 75.0000 (79.3264)  Acc@5: 100.0000 (98.7877)  time: 0.3475  data: 0.0012  max mem: 2503
Train: Epoch[2/5]  [ 870/3750]  eta: 0:16:43  Lr: 0.001875  Loss: -0.6544  Acc@1: 81.2500 (79.3485)  Acc@5: 100.0000 (98.8017)  time: 0.3478  data: 0.0009  max mem: 2503
Train: Epoch[2/5]  [ 880/3750]  eta: 0:16:39  Lr: 0.001875  Loss: -1.0215  Acc@1: 81.2500 (79.3842)  Acc@5: 100.0000 (98.8153)  time: 0.3494  data: 0.0010  max mem: 2503
Train: Epoch[2/5]  [ 890/3750]  eta: 0:16:36  Lr: 0.001875  Loss: -0.7832  Acc@1: 81.2500 (79.3841)  Acc@5: 100.0000 (98.8145)  time: 0.3485  data: 0.0010  max mem: 2503
Train: Epoch[2/5]  [ 900/3750]  eta: 0:16:32  Lr: 0.001875  Loss: -0.7437  Acc@1: 75.0000 (79.3285)  Acc@5: 100.0000 (98.8208)  time: 0.3483  data: 0.0008  max mem: 2503
Train: Epoch[2/5]  [ 910/3750]  eta: 0:16:29  Lr: 0.001875  Loss: -0.5046  Acc@1: 75.0000 (79.2673)  Acc@5: 100.0000 (98.8200)  time: 0.3497  data: 0.0015  max mem: 2503
Train: Epoch[2/5]  [ 920/3750]  eta: 0:16:25  Lr: 0.001875  Loss: -0.8644  Acc@1: 75.0000 (79.2752)  Acc@5: 100.0000 (98.8192)  time: 0.3486  data: 0.0014  max mem: 2503
Train: Epoch[2/5]  [ 930/3750]  eta: 0:16:22  Lr: 0.001875  Loss: -0.4974  Acc@1: 81.2500 (79.2830)  Acc@5: 100.0000 (98.8050)  time: 0.3471  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [ 940/3750]  eta: 0:16:18  Lr: 0.001875  Loss: -0.5532  Acc@1: 81.2500 (79.2641)  Acc@5: 100.0000 (98.7845)  time: 0.3463  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [ 950/3750]  eta: 0:16:15  Lr: 0.001875  Loss: -0.9056  Acc@1: 75.0000 (79.2587)  Acc@5: 100.0000 (98.7842)  time: 0.3448  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [ 960/3750]  eta: 0:16:11  Lr: 0.001875  Loss: -0.2276  Acc@1: 75.0000 (79.2469)  Acc@5: 100.0000 (98.7903)  time: 0.3434  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [ 970/3750]  eta: 0:16:07  Lr: 0.001875  Loss: -0.7068  Acc@1: 81.2500 (79.2418)  Acc@5: 100.0000 (98.8028)  time: 0.3425  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [ 980/3750]  eta: 0:16:04  Lr: 0.001875  Loss: -0.6990  Acc@1: 75.0000 (79.2304)  Acc@5: 100.0000 (98.8086)  time: 0.3428  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [ 990/3750]  eta: 0:16:00  Lr: 0.001875  Loss: -0.5859  Acc@1: 75.0000 (79.2381)  Acc@5: 100.0000 (98.8080)  time: 0.3453  data: 0.0011  max mem: 2503
Train: Epoch[2/5]  [1000/3750]  eta: 0:15:57  Lr: 0.001875  Loss: -0.6071  Acc@1: 81.2500 (79.2707)  Acc@5: 100.0000 (98.8137)  time: 0.3474  data: 0.0013  max mem: 2503
Train: Epoch[2/5]  [1010/3750]  eta: 0:15:53  Lr: 0.001875  Loss: -0.5132  Acc@1: 81.2500 (79.2470)  Acc@5: 100.0000 (98.8131)  time: 0.3474  data: 0.0010  max mem: 2503
Train: Epoch[2/5]  [1020/3750]  eta: 0:15:50  Lr: 0.001875  Loss: -0.7026  Acc@1: 81.2500 (79.2667)  Acc@5: 100.0000 (98.8124)  time: 0.3473  data: 0.0010  max mem: 2503
Train: Epoch[2/5]  [1030/3750]  eta: 0:15:46  Lr: 0.001875  Loss: -0.8615  Acc@1: 81.2500 (79.3162)  Acc@5: 100.0000 (98.8118)  time: 0.3485  data: 0.0008  max mem: 2503
Train: Epoch[2/5]  [1040/3750]  eta: 0:15:43  Lr: 0.001875  Loss: -0.7896  Acc@1: 81.2500 (79.3048)  Acc@5: 100.0000 (98.8232)  time: 0.3488  data: 0.0008  max mem: 2503
Train: Epoch[2/5]  [1050/3750]  eta: 0:15:39  Lr: 0.001875  Loss: -0.5957  Acc@1: 81.2500 (79.3114)  Acc@5: 100.0000 (98.8225)  time: 0.3478  data: 0.0010  max mem: 2503
Train: Epoch[2/5]  [1060/3750]  eta: 0:15:36  Lr: 0.001875  Loss: -0.8102  Acc@1: 81.2500 (79.3002)  Acc@5: 100.0000 (98.8336)  time: 0.3478  data: 0.0015  max mem: 2503
Train: Epoch[2/5]  [1070/3750]  eta: 0:15:32  Lr: 0.001875  Loss: -1.0185  Acc@1: 81.2500 (79.3184)  Acc@5: 100.0000 (98.8329)  time: 0.3478  data: 0.0016  max mem: 2503
Train: Epoch[2/5]  [1080/3750]  eta: 0:15:29  Lr: 0.001875  Loss: -0.8837  Acc@1: 81.2500 (79.3652)  Acc@5: 100.0000 (98.8437)  time: 0.3467  data: 0.0011  max mem: 2503
Train: Epoch[2/5]  [1090/3750]  eta: 0:15:25  Lr: 0.001875  Loss: -0.4664  Acc@1: 81.2500 (79.3595)  Acc@5: 100.0000 (98.8485)  time: 0.3458  data: 0.0007  max mem: 2503
Train: Epoch[2/5]  [1100/3750]  eta: 0:15:22  Lr: 0.001875  Loss: -0.6351  Acc@1: 81.2500 (79.3881)  Acc@5: 100.0000 (98.8420)  time: 0.3450  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [1110/3750]  eta: 0:15:18  Lr: 0.001875  Loss: -0.7565  Acc@1: 75.0000 (79.3317)  Acc@5: 100.0000 (98.8468)  time: 0.3440  data: 0.0002  max mem: 2503
Train: Epoch[2/5]  [1120/3750]  eta: 0:15:15  Lr: 0.001875  Loss: -0.9172  Acc@1: 81.2500 (79.3767)  Acc@5: 100.0000 (98.8515)  time: 0.3443  data: 0.0013  max mem: 2503
Train: Epoch[2/5]  [1130/3750]  eta: 0:15:11  Lr: 0.001875  Loss: -0.7188  Acc@1: 81.2500 (79.3490)  Acc@5: 100.0000 (98.8616)  time: 0.3451  data: 0.0014  max mem: 2503
Train: Epoch[2/5]  [1140/3750]  eta: 0:15:08  Lr: 0.001875  Loss: -0.5830  Acc@1: 81.2500 (79.3712)  Acc@5: 100.0000 (98.8716)  time: 0.3457  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [1150/3750]  eta: 0:15:04  Lr: 0.001875  Loss: -0.4437  Acc@1: 81.2500 (79.4255)  Acc@5: 100.0000 (98.8760)  time: 0.3476  data: 0.0008  max mem: 2503
Train: Epoch[2/5]  [1160/3750]  eta: 0:15:01  Lr: 0.001875  Loss: -0.4440  Acc@1: 81.2500 (79.4197)  Acc@5: 100.0000 (98.8749)  time: 0.3479  data: 0.0007  max mem: 2503
Train: Epoch[2/5]  [1170/3750]  eta: 0:14:57  Lr: 0.001875  Loss: -0.2254  Acc@1: 81.2500 (79.4246)  Acc@5: 100.0000 (98.8845)  time: 0.3465  data: 0.0006  max mem: 2503
Train: Epoch[2/5]  [1180/3750]  eta: 0:14:54  Lr: 0.001875  Loss: -0.9029  Acc@1: 81.2500 (79.4613)  Acc@5: 100.0000 (98.8887)  time: 0.3473  data: 0.0010  max mem: 2503
Train: Epoch[2/5]  [1190/3750]  eta: 0:14:50  Lr: 0.001875  Loss: -0.5349  Acc@1: 87.5000 (79.4815)  Acc@5: 100.0000 (98.8980)  time: 0.3485  data: 0.0016  max mem: 2503
Train: Epoch[2/5]  [1200/3750]  eta: 0:14:47  Lr: 0.001875  Loss: -0.8989  Acc@1: 75.0000 (79.4702)  Acc@5: 100.0000 (98.9020)  time: 0.3489  data: 0.0012  max mem: 2503
Train: Epoch[2/5]  [1210/3750]  eta: 0:14:43  Lr: 0.001875  Loss: -0.6931  Acc@1: 81.2500 (79.4901)  Acc@5: 100.0000 (98.9007)  time: 0.3476  data: 0.0008  max mem: 2503
Train: Epoch[2/5]  [1220/3750]  eta: 0:14:40  Lr: 0.001875  Loss: -0.3247  Acc@1: 81.2500 (79.4994)  Acc@5: 100.0000 (98.9046)  time: 0.3472  data: 0.0008  max mem: 2503
Train: Epoch[2/5]  [1230/3750]  eta: 0:14:36  Lr: 0.001875  Loss: -0.5362  Acc@1: 75.0000 (79.4781)  Acc@5: 100.0000 (98.9135)  time: 0.3479  data: 0.0010  max mem: 2503
Train: Epoch[2/5]  [1240/3750]  eta: 0:14:33  Lr: 0.001875  Loss: -0.5770  Acc@1: 81.2500 (79.5075)  Acc@5: 100.0000 (98.9122)  time: 0.3510  data: 0.0017  max mem: 2503
Train: Epoch[2/5]  [1250/3750]  eta: 0:14:29  Lr: 0.001875  Loss: -0.5187  Acc@1: 81.2500 (79.5114)  Acc@5: 100.0000 (98.9159)  time: 0.3497  data: 0.0013  max mem: 2503
Train: Epoch[2/5]  [1260/3750]  eta: 0:14:26  Lr: 0.001875  Loss: -0.8977  Acc@1: 81.2500 (79.5252)  Acc@5: 100.0000 (98.9245)  time: 0.3461  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [1270/3750]  eta: 0:14:22  Lr: 0.001875  Loss: -0.5361  Acc@1: 81.2500 (79.5535)  Acc@5: 100.0000 (98.9231)  time: 0.3446  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [1280/3750]  eta: 0:14:19  Lr: 0.001875  Loss: -0.6953  Acc@1: 81.2500 (79.5765)  Acc@5: 100.0000 (98.9169)  time: 0.3438  data: 0.0009  max mem: 2503
Train: Epoch[2/5]  [1290/3750]  eta: 0:14:15  Lr: 0.001875  Loss: -0.2740  Acc@1: 75.0000 (79.5653)  Acc@5: 100.0000 (98.8962)  time: 0.3441  data: 0.0010  max mem: 2503
Train: Epoch[2/5]  [1300/3750]  eta: 0:14:12  Lr: 0.001875  Loss: -0.8658  Acc@1: 81.2500 (79.5734)  Acc@5: 100.0000 (98.8951)  time: 0.3453  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [1310/3750]  eta: 0:14:08  Lr: 0.001875  Loss: -0.8604  Acc@1: 81.2500 (79.5957)  Acc@5: 100.0000 (98.9035)  time: 0.3477  data: 0.0007  max mem: 2503
Train: Epoch[2/5]  [1320/3750]  eta: 0:14:05  Lr: 0.001875  Loss: -0.6788  Acc@1: 75.0000 (79.5846)  Acc@5: 100.0000 (98.9118)  time: 0.3484  data: 0.0008  max mem: 2503
Train: Epoch[2/5]  [1330/3750]  eta: 0:14:01  Lr: 0.001875  Loss: -0.2681  Acc@1: 75.0000 (79.5971)  Acc@5: 100.0000 (98.9106)  time: 0.3484  data: 0.0015  max mem: 2503
Train: Epoch[2/5]  [1340/3750]  eta: 0:13:58  Lr: 0.001875  Loss: -0.2555  Acc@1: 75.0000 (79.5721)  Acc@5: 100.0000 (98.9141)  time: 0.3487  data: 0.0017  max mem: 2503
Train: Epoch[2/5]  [1350/3750]  eta: 0:13:54  Lr: 0.001875  Loss: -0.6326  Acc@1: 81.2500 (79.5753)  Acc@5: 100.0000 (98.9175)  time: 0.3482  data: 0.0007  max mem: 2503
Train: Epoch[2/5]  [1360/3750]  eta: 0:13:51  Lr: 0.001875  Loss: -0.7073  Acc@1: 81.2500 (79.6152)  Acc@5: 100.0000 (98.9208)  time: 0.3477  data: 0.0010  max mem: 2503
Train: Epoch[2/5]  [1370/3750]  eta: 0:13:47  Lr: 0.001875  Loss: -0.7172  Acc@1: 81.2500 (79.6271)  Acc@5: 100.0000 (98.9196)  time: 0.3480  data: 0.0013  max mem: 2503
Train: Epoch[2/5]  [1380/3750]  eta: 0:13:44  Lr: 0.001875  Loss: -0.5897  Acc@1: 81.2500 (79.6298)  Acc@5: 100.0000 (98.9229)  time: 0.3485  data: 0.0010  max mem: 2503
Train: Epoch[2/5]  [1390/3750]  eta: 0:13:41  Lr: 0.001875  Loss: -0.5627  Acc@1: 81.2500 (79.6594)  Acc@5: 100.0000 (98.9261)  time: 0.3501  data: 0.0021  max mem: 2503
Train: Epoch[2/5]  [1400/3750]  eta: 0:13:37  Lr: 0.001875  Loss: -0.4354  Acc@1: 81.2500 (79.6618)  Acc@5: 100.0000 (98.9204)  time: 0.3498  data: 0.0021  max mem: 2503
Train: Epoch[2/5]  [1410/3750]  eta: 0:13:34  Lr: 0.001875  Loss: -0.9226  Acc@1: 81.2500 (79.6820)  Acc@5: 100.0000 (98.9015)  time: 0.3470  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [1420/3750]  eta: 0:13:30  Lr: 0.001875  Loss: -0.9436  Acc@1: 81.2500 (79.7062)  Acc@5: 100.0000 (98.9048)  time: 0.3453  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [1430/3750]  eta: 0:13:26  Lr: 0.001875  Loss: -0.1013  Acc@1: 81.2500 (79.7345)  Acc@5: 100.0000 (98.8994)  time: 0.3455  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [1440/3750]  eta: 0:13:23  Lr: 0.001875  Loss: -0.4629  Acc@1: 81.2500 (79.7233)  Acc@5: 100.0000 (98.8940)  time: 0.3447  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [1450/3750]  eta: 0:13:19  Lr: 0.001875  Loss: -0.5410  Acc@1: 75.0000 (79.6563)  Acc@5: 100.0000 (98.8973)  time: 0.3450  data: 0.0012  max mem: 2503
Train: Epoch[2/5]  [1460/3750]  eta: 0:13:16  Lr: 0.001875  Loss: -0.8961  Acc@1: 75.0000 (79.6629)  Acc@5: 100.0000 (98.8963)  time: 0.3485  data: 0.0017  max mem: 2503
Train: Epoch[2/5]  [1470/3750]  eta: 0:13:13  Lr: 0.001875  Loss: -0.4379  Acc@1: 75.0000 (79.6100)  Acc@5: 100.0000 (98.8996)  time: 0.3490  data: 0.0013  max mem: 2503
Train: Epoch[2/5]  [1480/3750]  eta: 0:13:09  Lr: 0.001875  Loss: -0.8743  Acc@1: 81.2500 (79.6210)  Acc@5: 100.0000 (98.8943)  time: 0.3487  data: 0.0013  max mem: 2503
Train: Epoch[2/5]  [1490/3750]  eta: 0:13:06  Lr: 0.001875  Loss: -0.5257  Acc@1: 81.2500 (79.6110)  Acc@5: 100.0000 (98.9017)  time: 0.3485  data: 0.0009  max mem: 2503
Train: Epoch[2/5]  [1500/3750]  eta: 0:13:02  Lr: 0.001875  Loss: -0.6315  Acc@1: 75.0000 (79.6053)  Acc@5: 100.0000 (98.9049)  time: 0.3481  data: 0.0010  max mem: 2503
Train: Epoch[2/5]  [1510/3750]  eta: 0:12:59  Lr: 0.001875  Loss: -0.7642  Acc@1: 75.0000 (79.5872)  Acc@5: 100.0000 (98.8997)  time: 0.3483  data: 0.0010  max mem: 2503
Train: Epoch[2/5]  [1520/3750]  eta: 0:12:55  Lr: 0.001875  Loss: -0.6474  Acc@1: 75.0000 (79.5858)  Acc@5: 100.0000 (98.9029)  time: 0.3477  data: 0.0008  max mem: 2503
Train: Epoch[2/5]  [1530/3750]  eta: 0:12:52  Lr: 0.001875  Loss: -0.3768  Acc@1: 75.0000 (79.5640)  Acc@5: 100.0000 (98.8978)  time: 0.3486  data: 0.0008  max mem: 2503
Train: Epoch[2/5]  [1540/3750]  eta: 0:12:48  Lr: 0.001875  Loss: -0.8698  Acc@1: 81.2500 (79.5912)  Acc@5: 100.0000 (98.9049)  time: 0.3500  data: 0.0008  max mem: 2503
Train: Epoch[2/5]  [1550/3750]  eta: 0:12:45  Lr: 0.001875  Loss: -0.6479  Acc@1: 87.5000 (79.6019)  Acc@5: 100.0000 (98.9120)  time: 0.3508  data: 0.0011  max mem: 2503
Train: Epoch[2/5]  [1560/3750]  eta: 0:12:41  Lr: 0.001875  Loss: -1.0207  Acc@1: 81.2500 (79.6124)  Acc@5: 100.0000 (98.9190)  time: 0.3494  data: 0.0010  max mem: 2503
Train: Epoch[2/5]  [1570/3750]  eta: 0:12:38  Lr: 0.001875  Loss: -0.4693  Acc@1: 81.2500 (79.6308)  Acc@5: 100.0000 (98.9179)  time: 0.3499  data: 0.0010  max mem: 2503
Train: Epoch[2/5]  [1580/3750]  eta: 0:12:34  Lr: 0.001875  Loss: -0.8208  Acc@1: 81.2500 (79.6450)  Acc@5: 100.0000 (98.9208)  time: 0.3490  data: 0.0009  max mem: 2503
Train: Epoch[2/5]  [1590/3750]  eta: 0:12:31  Lr: 0.001875  Loss: -0.5518  Acc@1: 81.2500 (79.6708)  Acc@5: 100.0000 (98.9236)  time: 0.3456  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [1600/3750]  eta: 0:12:27  Lr: 0.001875  Loss: -0.5177  Acc@1: 75.0000 (79.6690)  Acc@5: 100.0000 (98.9265)  time: 0.3452  data: 0.0009  max mem: 2503
Train: Epoch[2/5]  [1610/3750]  eta: 0:12:24  Lr: 0.001875  Loss: -0.8725  Acc@1: 75.0000 (79.6671)  Acc@5: 100.0000 (98.9215)  time: 0.3449  data: 0.0015  max mem: 2503
Train: Epoch[2/5]  [1620/3750]  eta: 0:12:20  Lr: 0.001875  Loss: -0.4618  Acc@1: 81.2500 (79.6846)  Acc@5: 100.0000 (98.9204)  time: 0.3457  data: 0.0017  max mem: 2503
Train: Epoch[2/5]  [1630/3750]  eta: 0:12:17  Lr: 0.001875  Loss: -0.4528  Acc@1: 81.2500 (79.6904)  Acc@5: 100.0000 (98.9194)  time: 0.3486  data: 0.0013  max mem: 2503
Train: Epoch[2/5]  [1640/3750]  eta: 0:12:14  Lr: 0.001875  Loss: -0.6191  Acc@1: 81.2500 (79.7075)  Acc@5: 100.0000 (98.9107)  time: 0.3521  data: 0.0007  max mem: 2503
Train: Epoch[2/5]  [1650/3750]  eta: 0:12:10  Lr: 0.001875  Loss: -0.3937  Acc@1: 75.0000 (79.6979)  Acc@5: 100.0000 (98.9060)  time: 0.3508  data: 0.0007  max mem: 2503
Train: Epoch[2/5]  [1660/3750]  eta: 0:12:07  Lr: 0.001875  Loss: -0.5534  Acc@1: 75.0000 (79.7110)  Acc@5: 100.0000 (98.9088)  time: 0.3478  data: 0.0009  max mem: 2503
Train: Epoch[2/5]  [1670/3750]  eta: 0:12:03  Lr: 0.001875  Loss: -0.8820  Acc@1: 81.2500 (79.7240)  Acc@5: 100.0000 (98.9116)  time: 0.3473  data: 0.0008  max mem: 2503
Train: Epoch[2/5]  [1680/3750]  eta: 0:12:00  Lr: 0.001875  Loss: -0.4395  Acc@1: 81.2500 (79.7293)  Acc@5: 100.0000 (98.9181)  time: 0.3486  data: 0.0007  max mem: 2503
Train: Epoch[2/5]  [1690/3750]  eta: 0:11:56  Lr: 0.001875  Loss: -0.7583  Acc@1: 81.2500 (79.7531)  Acc@5: 100.0000 (98.9171)  time: 0.3482  data: 0.0011  max mem: 2503
Train: Epoch[2/5]  [1700/3750]  eta: 0:11:53  Lr: 0.001875  Loss: -0.7808  Acc@1: 81.2500 (79.7619)  Acc@5: 100.0000 (98.9198)  time: 0.3465  data: 0.0011  max mem: 2503
Train: Epoch[2/5]  [1710/3750]  eta: 0:11:49  Lr: 0.001875  Loss: -0.3846  Acc@1: 75.0000 (79.7268)  Acc@5: 100.0000 (98.9224)  time: 0.3471  data: 0.0011  max mem: 2503
Train: Epoch[2/5]  [1720/3750]  eta: 0:11:46  Lr: 0.001875  Loss: -0.6087  Acc@1: 75.0000 (79.7284)  Acc@5: 100.0000 (98.9250)  time: 0.3473  data: 0.0009  max mem: 2503
Train: Epoch[2/5]  [1730/3750]  eta: 0:11:42  Lr: 0.001875  Loss: -0.4468  Acc@1: 81.2500 (79.7047)  Acc@5: 100.0000 (98.9240)  time: 0.3462  data: 0.0006  max mem: 2503
Train: Epoch[2/5]  [1740/3750]  eta: 0:11:39  Lr: 0.001875  Loss: -0.6289  Acc@1: 81.2500 (79.7063)  Acc@5: 100.0000 (98.9230)  time: 0.3472  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [1750/3750]  eta: 0:11:35  Lr: 0.001875  Loss: -0.2891  Acc@1: 75.0000 (79.6795)  Acc@5: 100.0000 (98.9185)  time: 0.3468  data: 0.0010  max mem: 2503
Train: Epoch[2/5]  [1760/3750]  eta: 0:11:32  Lr: 0.001875  Loss: -0.3258  Acc@1: 68.7500 (79.6777)  Acc@5: 100.0000 (98.9211)  time: 0.3451  data: 0.0015  max mem: 2503
Train: Epoch[2/5]  [1770/3750]  eta: 0:11:28  Lr: 0.001875  Loss: -0.5410  Acc@1: 81.2500 (79.6866)  Acc@5: 100.0000 (98.9272)  time: 0.3446  data: 0.0008  max mem: 2503
Train: Epoch[2/5]  [1780/3750]  eta: 0:11:25  Lr: 0.001875  Loss: -0.6594  Acc@1: 81.2500 (79.6708)  Acc@5: 100.0000 (98.9332)  time: 0.3455  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [1790/3750]  eta: 0:11:21  Lr: 0.001875  Loss: -0.7505  Acc@1: 75.0000 (79.6622)  Acc@5: 100.0000 (98.9322)  time: 0.3473  data: 0.0007  max mem: 2503
Train: Epoch[2/5]  [1800/3750]  eta: 0:11:18  Lr: 0.001875  Loss: -0.4660  Acc@1: 81.2500 (79.6710)  Acc@5: 100.0000 (98.9346)  time: 0.3470  data: 0.0010  max mem: 2503
Train: Epoch[2/5]  [1810/3750]  eta: 0:11:14  Lr: 0.001875  Loss: -0.6203  Acc@1: 81.2500 (79.7004)  Acc@5: 100.0000 (98.9405)  time: 0.3468  data: 0.0009  max mem: 2503
Train: Epoch[2/5]  [1820/3750]  eta: 0:11:11  Lr: 0.001875  Loss: -0.4326  Acc@1: 81.2500 (79.6746)  Acc@5: 100.0000 (98.9429)  time: 0.3475  data: 0.0007  max mem: 2503
Train: Epoch[2/5]  [1830/3750]  eta: 0:11:07  Lr: 0.001875  Loss: -0.1323  Acc@1: 75.0000 (79.6525)  Acc@5: 100.0000 (98.9418)  time: 0.3479  data: 0.0011  max mem: 2503
Train: Epoch[2/5]  [1840/3750]  eta: 0:11:04  Lr: 0.001875  Loss: -0.5380  Acc@1: 75.0000 (79.6340)  Acc@5: 100.0000 (98.9408)  time: 0.3478  data: 0.0014  max mem: 2503
Train: Epoch[2/5]  [1850/3750]  eta: 0:11:00  Lr: 0.001875  Loss: -0.3098  Acc@1: 81.2500 (79.6360)  Acc@5: 100.0000 (98.9398)  time: 0.3479  data: 0.0009  max mem: 2503
Train: Epoch[2/5]  [1860/3750]  eta: 0:10:57  Lr: 0.001875  Loss: -0.8767  Acc@1: 81.2500 (79.6413)  Acc@5: 100.0000 (98.9354)  time: 0.3482  data: 0.0007  max mem: 2503
Train: Epoch[2/5]  [1870/3750]  eta: 0:10:53  Lr: 0.001875  Loss: -0.4138  Acc@1: 81.2500 (79.6566)  Acc@5: 100.0000 (98.9344)  time: 0.3485  data: 0.0008  max mem: 2503
Train: Epoch[2/5]  [1880/3750]  eta: 0:10:50  Lr: 0.001875  Loss: -0.5022  Acc@1: 81.2500 (79.6717)  Acc@5: 100.0000 (98.9367)  time: 0.3485  data: 0.0011  max mem: 2503
Train: Epoch[2/5]  [1890/3750]  eta: 0:10:46  Lr: 0.001875  Loss: -0.8129  Acc@1: 81.2500 (79.6768)  Acc@5: 100.0000 (98.9357)  time: 0.3470  data: 0.0010  max mem: 2503
Train: Epoch[2/5]  [1900/3750]  eta: 0:10:43  Lr: 0.001875  Loss: -0.7975  Acc@1: 81.2500 (79.6719)  Acc@5: 100.0000 (98.9348)  time: 0.3448  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [1910/3750]  eta: 0:10:39  Lr: 0.001875  Loss: -0.1625  Acc@1: 81.2500 (79.6572)  Acc@5: 100.0000 (98.9305)  time: 0.3435  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [1920/3750]  eta: 0:10:36  Lr: 0.001875  Loss: -0.8002  Acc@1: 81.2500 (79.6720)  Acc@5: 100.0000 (98.9361)  time: 0.3432  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [1930/3750]  eta: 0:10:32  Lr: 0.001875  Loss: -0.5449  Acc@1: 81.2500 (79.6576)  Acc@5: 100.0000 (98.9416)  time: 0.3448  data: 0.0008  max mem: 2503
Train: Epoch[2/5]  [1940/3750]  eta: 0:10:29  Lr: 0.001875  Loss: -0.8070  Acc@1: 81.2500 (79.6819)  Acc@5: 100.0000 (98.9438)  time: 0.3469  data: 0.0011  max mem: 2503
Train: Epoch[2/5]  [1950/3750]  eta: 0:10:25  Lr: 0.001875  Loss: -1.0142  Acc@1: 81.2500 (79.6963)  Acc@5: 100.0000 (98.9493)  time: 0.3478  data: 0.0012  max mem: 2503
Train: Epoch[2/5]  [1960/3750]  eta: 0:10:22  Lr: 0.001875  Loss: -0.7382  Acc@1: 81.2500 (79.7106)  Acc@5: 100.0000 (98.9482)  time: 0.3476  data: 0.0011  max mem: 2503
Train: Epoch[2/5]  [1970/3750]  eta: 0:10:18  Lr: 0.001875  Loss: -0.8839  Acc@1: 81.2500 (79.7026)  Acc@5: 100.0000 (98.9441)  time: 0.3470  data: 0.0007  max mem: 2503
Train: Epoch[2/5]  [1980/3750]  eta: 0:10:15  Lr: 0.001875  Loss: -0.3623  Acc@1: 81.2500 (79.7041)  Acc@5: 100.0000 (98.9462)  time: 0.3464  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [1990/3750]  eta: 0:10:11  Lr: 0.001875  Loss: -0.4890  Acc@1: 81.2500 (79.7024)  Acc@5: 100.0000 (98.9327)  time: 0.3473  data: 0.0006  max mem: 2503
Train: Epoch[2/5]  [2000/3750]  eta: 0:10:08  Lr: 0.001875  Loss: -0.6231  Acc@1: 75.0000 (79.6820)  Acc@5: 100.0000 (98.9318)  time: 0.3468  data: 0.0007  max mem: 2503
Train: Epoch[2/5]  [2010/3750]  eta: 0:10:04  Lr: 0.001875  Loss: -0.3564  Acc@1: 75.0000 (79.6619)  Acc@5: 100.0000 (98.9216)  time: 0.3455  data: 0.0007  max mem: 2503
Train: Epoch[2/5]  [2020/3750]  eta: 0:10:01  Lr: 0.001875  Loss: -0.8843  Acc@1: 81.2500 (79.6666)  Acc@5: 100.0000 (98.9176)  time: 0.3470  data: 0.0009  max mem: 2503
Train: Epoch[2/5]  [2030/3750]  eta: 0:09:58  Lr: 0.001875  Loss: -0.9237  Acc@1: 81.2500 (79.6713)  Acc@5: 100.0000 (98.9199)  time: 0.3474  data: 0.0011  max mem: 2503
Train: Epoch[2/5]  [2040/3750]  eta: 0:09:54  Lr: 0.001875  Loss: -0.6679  Acc@1: 81.2500 (79.6821)  Acc@5: 100.0000 (98.9221)  time: 0.3468  data: 0.0009  max mem: 2503
Train: Epoch[2/5]  [2050/3750]  eta: 0:09:51  Lr: 0.001875  Loss: -0.0054  Acc@1: 87.5000 (79.6776)  Acc@5: 100.0000 (98.9121)  time: 0.3476  data: 0.0006  max mem: 2503
Train: Epoch[2/5]  [2060/3750]  eta: 0:09:47  Lr: 0.001875  Loss: -0.5786  Acc@1: 81.2500 (79.6579)  Acc@5: 100.0000 (98.9113)  time: 0.3453  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [2070/3750]  eta: 0:09:44  Lr: 0.001875  Loss: -0.5663  Acc@1: 75.0000 (79.6475)  Acc@5: 100.0000 (98.9136)  time: 0.3429  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [2080/3750]  eta: 0:09:40  Lr: 0.001875  Loss: -0.2882  Acc@1: 81.2500 (79.6552)  Acc@5: 100.0000 (98.9098)  time: 0.3428  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [2090/3750]  eta: 0:09:37  Lr: 0.001875  Loss: -0.4374  Acc@1: 81.2500 (79.6509)  Acc@5: 100.0000 (98.9060)  time: 0.3445  data: 0.0006  max mem: 2503
Train: Epoch[2/5]  [2100/3750]  eta: 0:09:33  Lr: 0.001875  Loss: -0.7693  Acc@1: 81.2500 (79.6823)  Acc@5: 100.0000 (98.9083)  time: 0.3477  data: 0.0009  max mem: 2503
Train: Epoch[2/5]  [2110/3750]  eta: 0:09:30  Lr: 0.001875  Loss: -0.6603  Acc@1: 87.5000 (79.6956)  Acc@5: 100.0000 (98.9134)  time: 0.3479  data: 0.0009  max mem: 2503
Train: Epoch[2/5]  [2120/3750]  eta: 0:09:26  Lr: 0.001875  Loss: -0.6224  Acc@1: 81.2500 (79.6853)  Acc@5: 100.0000 (98.9156)  time: 0.3470  data: 0.0012  max mem: 2503
Train: Epoch[2/5]  [2130/3750]  eta: 0:09:23  Lr: 0.001875  Loss: -0.6034  Acc@1: 81.2500 (79.6780)  Acc@5: 100.0000 (98.9207)  time: 0.3477  data: 0.0016  max mem: 2503
Train: Epoch[2/5]  [2140/3750]  eta: 0:09:19  Lr: 0.001875  Loss: -0.4012  Acc@1: 81.2500 (79.6853)  Acc@5: 100.0000 (98.9170)  time: 0.3484  data: 0.0011  max mem: 2503
Train: Epoch[2/5]  [2150/3750]  eta: 0:09:16  Lr: 0.001875  Loss: -0.8598  Acc@1: 81.2500 (79.6868)  Acc@5: 100.0000 (98.9220)  time: 0.3477  data: 0.0008  max mem: 2503
Train: Epoch[2/5]  [2160/3750]  eta: 0:09:12  Lr: 0.001875  Loss: -0.4646  Acc@1: 81.2500 (79.6882)  Acc@5: 100.0000 (98.9241)  time: 0.3469  data: 0.0008  max mem: 2503
Train: Epoch[2/5]  [2170/3750]  eta: 0:09:09  Lr: 0.001875  Loss: -0.6375  Acc@1: 81.2500 (79.6954)  Acc@5: 100.0000 (98.9175)  time: 0.3481  data: 0.0008  max mem: 2503
Train: Epoch[2/5]  [2180/3750]  eta: 0:09:05  Lr: 0.001875  Loss: -0.4093  Acc@1: 81.2500 (79.6882)  Acc@5: 100.0000 (98.9196)  time: 0.3493  data: 0.0009  max mem: 2503
Train: Epoch[2/5]  [2190/3750]  eta: 0:09:02  Lr: 0.001875  Loss: -0.6739  Acc@1: 81.2500 (79.7039)  Acc@5: 100.0000 (98.9246)  time: 0.3485  data: 0.0011  max mem: 2503
Train: Epoch[2/5]  [2200/3750]  eta: 0:08:58  Lr: 0.001875  Loss: -0.8770  Acc@1: 81.2500 (79.7024)  Acc@5: 100.0000 (98.9266)  time: 0.3461  data: 0.0009  max mem: 2503
Train: Epoch[2/5]  [2210/3750]  eta: 0:08:55  Lr: 0.001875  Loss: -0.7158  Acc@1: 81.2500 (79.7066)  Acc@5: 100.0000 (98.9287)  time: 0.3447  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [2220/3750]  eta: 0:08:51  Lr: 0.001875  Loss: -0.6000  Acc@1: 81.2500 (79.7135)  Acc@5: 100.0000 (98.9222)  time: 0.3438  data: 0.0007  max mem: 2503
Train: Epoch[2/5]  [2230/3750]  eta: 0:08:48  Lr: 0.001875  Loss: -0.6466  Acc@1: 81.2500 (79.7036)  Acc@5: 100.0000 (98.9242)  time: 0.3425  data: 0.0006  max mem: 2503
Train: Epoch[2/5]  [2240/3750]  eta: 0:08:44  Lr: 0.001875  Loss: -0.4681  Acc@1: 81.2500 (79.6994)  Acc@5: 100.0000 (98.9235)  time: 0.3436  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [2250/3750]  eta: 0:08:41  Lr: 0.001875  Loss: -0.6843  Acc@1: 81.2500 (79.7035)  Acc@5: 100.0000 (98.9255)  time: 0.3465  data: 0.0007  max mem: 2503
Train: Epoch[2/5]  [2260/3750]  eta: 0:08:37  Lr: 0.001875  Loss: -0.9982  Acc@1: 81.2500 (79.7103)  Acc@5: 100.0000 (98.9247)  time: 0.3485  data: 0.0015  max mem: 2503
Train: Epoch[2/5]  [2270/3750]  eta: 0:08:34  Lr: 0.001875  Loss: -0.6103  Acc@1: 81.2500 (79.7061)  Acc@5: 100.0000 (98.9184)  time: 0.3484  data: 0.0017  max mem: 2503
Train: Epoch[2/5]  [2280/3750]  eta: 0:08:30  Lr: 0.001875  Loss: -0.7273  Acc@1: 75.0000 (79.6991)  Acc@5: 100.0000 (98.9204)  time: 0.3480  data: 0.0010  max mem: 2503
Train: Epoch[2/5]  [2290/3750]  eta: 0:08:27  Lr: 0.001875  Loss: -0.5814  Acc@1: 81.2500 (79.7059)  Acc@5: 100.0000 (98.9251)  time: 0.3480  data: 0.0008  max mem: 2503
Train: Epoch[2/5]  [2300/3750]  eta: 0:08:23  Lr: 0.001875  Loss: -0.4956  Acc@1: 81.2500 (79.7018)  Acc@5: 100.0000 (98.9189)  time: 0.3471  data: 0.0008  max mem: 2503
Train: Epoch[2/5]  [2310/3750]  eta: 0:08:20  Lr: 0.001875  Loss: -0.6216  Acc@1: 75.0000 (79.7139)  Acc@5: 100.0000 (98.9209)  time: 0.3461  data: 0.0007  max mem: 2503
Train: Epoch[2/5]  [2320/3750]  eta: 0:08:16  Lr: 0.001875  Loss: -0.6670  Acc@1: 87.5000 (79.7340)  Acc@5: 100.0000 (98.9256)  time: 0.3461  data: 0.0007  max mem: 2503
Train: Epoch[2/5]  [2330/3750]  eta: 0:08:13  Lr: 0.001875  Loss: -0.6043  Acc@1: 87.5000 (79.7512)  Acc@5: 100.0000 (98.9275)  time: 0.3468  data: 0.0008  max mem: 2503
Train: Epoch[2/5]  [2340/3750]  eta: 0:08:10  Lr: 0.001875  Loss: -0.5968  Acc@1: 81.2500 (79.7416)  Acc@5: 100.0000 (98.9267)  time: 0.3475  data: 0.0012  max mem: 2503
Train: Epoch[2/5]  [2350/3750]  eta: 0:08:06  Lr: 0.001875  Loss: -0.7948  Acc@1: 75.0000 (79.7347)  Acc@5: 100.0000 (98.9233)  time: 0.3473  data: 0.0011  max mem: 2503
Train: Epoch[2/5]  [2360/3750]  eta: 0:08:03  Lr: 0.001875  Loss: -0.2793  Acc@1: 81.2500 (79.7305)  Acc@5: 100.0000 (98.9279)  time: 0.3472  data: 0.0006  max mem: 2503
Train: Epoch[2/5]  [2370/3750]  eta: 0:07:59  Lr: 0.001875  Loss: -0.8439  Acc@1: 81.2500 (79.7237)  Acc@5: 100.0000 (98.9298)  time: 0.3451  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [2380/3750]  eta: 0:07:56  Lr: 0.001875  Loss: -0.7624  Acc@1: 81.2500 (79.7380)  Acc@5: 100.0000 (98.9316)  time: 0.3426  data: 0.0002  max mem: 2503
Train: Epoch[2/5]  [2390/3750]  eta: 0:07:52  Lr: 0.001875  Loss: -0.7879  Acc@1: 87.5000 (79.7653)  Acc@5: 100.0000 (98.9361)  time: 0.3426  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [2400/3750]  eta: 0:07:49  Lr: 0.001875  Loss: -0.5002  Acc@1: 81.2500 (79.7662)  Acc@5: 100.0000 (98.9405)  time: 0.3446  data: 0.0008  max mem: 2503
Train: Epoch[2/5]  [2410/3750]  eta: 0:07:45  Lr: 0.001875  Loss: -0.4804  Acc@1: 81.2500 (79.7854)  Acc@5: 100.0000 (98.9449)  time: 0.3477  data: 0.0010  max mem: 2503
Train: Epoch[2/5]  [2420/3750]  eta: 0:07:42  Lr: 0.001875  Loss: -0.5587  Acc@1: 81.2500 (79.7785)  Acc@5: 100.0000 (98.9493)  time: 0.3477  data: 0.0009  max mem: 2503
Train: Epoch[2/5]  [2430/3750]  eta: 0:07:38  Lr: 0.001875  Loss: -0.1996  Acc@1: 75.0000 (79.7614)  Acc@5: 100.0000 (98.9382)  time: 0.3471  data: 0.0012  max mem: 2503
Train: Epoch[2/5]  [2440/3750]  eta: 0:07:35  Lr: 0.001875  Loss: -0.7652  Acc@1: 75.0000 (79.7598)  Acc@5: 100.0000 (98.9323)  time: 0.3470  data: 0.0013  max mem: 2503
Train: Epoch[2/5]  [2450/3750]  eta: 0:07:31  Lr: 0.001875  Loss: -0.1588  Acc@1: 81.2500 (79.7634)  Acc@5: 100.0000 (98.9290)  time: 0.3457  data: 0.0006  max mem: 2503
Train: Epoch[2/5]  [2460/3750]  eta: 0:07:28  Lr: 0.001875  Loss: -0.6282  Acc@1: 75.0000 (79.7643)  Acc@5: 100.0000 (98.9308)  time: 0.3457  data: 0.0006  max mem: 2503
Train: Epoch[2/5]  [2470/3750]  eta: 0:07:24  Lr: 0.001875  Loss: -0.5327  Acc@1: 81.2500 (79.7653)  Acc@5: 100.0000 (98.9326)  time: 0.3465  data: 0.0009  max mem: 2503
Train: Epoch[2/5]  [2480/3750]  eta: 0:07:21  Lr: 0.001875  Loss: -0.6398  Acc@1: 81.2500 (79.7587)  Acc@5: 100.0000 (98.9319)  time: 0.3467  data: 0.0008  max mem: 2503
Train: Epoch[2/5]  [2490/3750]  eta: 0:07:17  Lr: 0.001875  Loss: -0.6095  Acc@1: 81.2500 (79.7621)  Acc@5: 100.0000 (98.9337)  time: 0.3475  data: 0.0008  max mem: 2503
Train: Epoch[2/5]  [2500/3750]  eta: 0:07:14  Lr: 0.001875  Loss: -0.8053  Acc@1: 81.2500 (79.7756)  Acc@5: 100.0000 (98.9379)  time: 0.3499  data: 0.0012  max mem: 2503
Train: Epoch[2/5]  [2510/3750]  eta: 0:07:10  Lr: 0.001875  Loss: -0.5372  Acc@1: 81.2500 (79.7815)  Acc@5: 100.0000 (98.9397)  time: 0.3488  data: 0.0008  max mem: 2503
Train: Epoch[2/5]  [2520/3750]  eta: 0:07:07  Lr: 0.001875  Loss: -0.6336  Acc@1: 81.2500 (79.7699)  Acc@5: 100.0000 (98.9315)  time: 0.3452  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [2530/3750]  eta: 0:07:03  Lr: 0.001875  Loss: -0.1678  Acc@1: 75.0000 (79.7437)  Acc@5: 100.0000 (98.9283)  time: 0.3434  data: 0.0002  max mem: 2503
Train: Epoch[2/5]  [2540/3750]  eta: 0:07:00  Lr: 0.001875  Loss: -0.9129  Acc@1: 81.2500 (79.7570)  Acc@5: 100.0000 (98.9300)  time: 0.3428  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [2550/3750]  eta: 0:06:56  Lr: 0.001875  Loss: -0.6838  Acc@1: 81.2500 (79.7824)  Acc@5: 100.0000 (98.9342)  time: 0.3445  data: 0.0014  max mem: 2503
Train: Epoch[2/5]  [2560/3750]  eta: 0:06:53  Lr: 0.001875  Loss: -0.8801  Acc@1: 81.2500 (79.7808)  Acc@5: 100.0000 (98.9286)  time: 0.3466  data: 0.0015  max mem: 2503
Train: Epoch[2/5]  [2570/3750]  eta: 0:06:49  Lr: 0.001875  Loss: -1.0361  Acc@1: 81.2500 (79.7963)  Acc@5: 100.0000 (98.9279)  time: 0.3477  data: 0.0013  max mem: 2503
Train: Epoch[2/5]  [2580/3750]  eta: 0:06:46  Lr: 0.001875  Loss: -0.7277  Acc@1: 81.2500 (79.7874)  Acc@5: 100.0000 (98.9297)  time: 0.3482  data: 0.0012  max mem: 2503
Train: Epoch[2/5]  [2590/3750]  eta: 0:06:42  Lr: 0.001875  Loss: -0.4136  Acc@1: 75.0000 (79.7858)  Acc@5: 100.0000 (98.9290)  time: 0.3476  data: 0.0008  max mem: 2503
Train: Epoch[2/5]  [2600/3750]  eta: 0:06:39  Lr: 0.001875  Loss: -0.2998  Acc@1: 75.0000 (79.7866)  Acc@5: 100.0000 (98.9259)  time: 0.3485  data: 0.0017  max mem: 2503
Train: Epoch[2/5]  [2610/3750]  eta: 0:06:36  Lr: 0.001875  Loss: -0.6284  Acc@1: 81.2500 (79.7874)  Acc@5: 100.0000 (98.9228)  time: 0.3494  data: 0.0016  max mem: 2503
Train: Epoch[2/5]  [2620/3750]  eta: 0:06:32  Lr: 0.001875  Loss: -0.6034  Acc@1: 81.2500 (79.8145)  Acc@5: 100.0000 (98.9269)  time: 0.3491  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [2630/3750]  eta: 0:06:29  Lr: 0.001875  Loss: -1.0753  Acc@1: 87.5000 (79.8342)  Acc@5: 100.0000 (98.9239)  time: 0.3483  data: 0.0007  max mem: 2503
Train: Epoch[2/5]  [2640/3750]  eta: 0:06:25  Lr: 0.001875  Loss: -0.6245  Acc@1: 81.2500 (79.8395)  Acc@5: 100.0000 (98.9232)  time: 0.3479  data: 0.0007  max mem: 2503
Train: Epoch[2/5]  [2650/3750]  eta: 0:06:22  Lr: 0.001875  Loss: -0.7633  Acc@1: 81.2500 (79.8331)  Acc@5: 100.0000 (98.9226)  time: 0.3477  data: 0.0006  max mem: 2503
Train: Epoch[2/5]  [2660/3750]  eta: 0:06:18  Lr: 0.001875  Loss: -0.4828  Acc@1: 75.0000 (79.8196)  Acc@5: 100.0000 (98.9243)  time: 0.3479  data: 0.0008  max mem: 2503
Train: Epoch[2/5]  [2670/3750]  eta: 0:06:15  Lr: 0.001875  Loss: -0.7247  Acc@1: 75.0000 (79.8063)  Acc@5: 100.0000 (98.9189)  time: 0.3481  data: 0.0009  max mem: 2503
Train: Epoch[2/5]  [2680/3750]  eta: 0:06:11  Lr: 0.001875  Loss: -0.4870  Acc@1: 81.2500 (79.8163)  Acc@5: 100.0000 (98.9183)  time: 0.3470  data: 0.0007  max mem: 2503
Train: Epoch[2/5]  [2690/3750]  eta: 0:06:08  Lr: 0.001875  Loss: -0.8166  Acc@1: 81.2500 (79.8147)  Acc@5: 100.0000 (98.9084)  time: 0.3462  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [2700/3750]  eta: 0:06:04  Lr: 0.001875  Loss: -0.2514  Acc@1: 81.2500 (79.8130)  Acc@5: 100.0000 (98.9055)  time: 0.3449  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [2710/3750]  eta: 0:06:01  Lr: 0.001875  Loss: -0.6759  Acc@1: 75.0000 (79.8206)  Acc@5: 100.0000 (98.9072)  time: 0.3439  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [2720/3750]  eta: 0:05:57  Lr: 0.001875  Loss: -0.8361  Acc@1: 81.2500 (79.8374)  Acc@5: 100.0000 (98.9112)  time: 0.3450  data: 0.0006  max mem: 2503
Train: Epoch[2/5]  [2730/3750]  eta: 0:05:54  Lr: 0.001875  Loss: -0.4942  Acc@1: 87.5000 (79.8448)  Acc@5: 100.0000 (98.9107)  time: 0.3474  data: 0.0010  max mem: 2503
Train: Epoch[2/5]  [2740/3750]  eta: 0:05:50  Lr: 0.001875  Loss: -0.9971  Acc@1: 81.2500 (79.8340)  Acc@5: 100.0000 (98.9101)  time: 0.3481  data: 0.0008  max mem: 2503
Train: Epoch[2/5]  [2750/3750]  eta: 0:05:47  Lr: 0.001875  Loss: -0.6455  Acc@1: 81.2500 (79.8346)  Acc@5: 100.0000 (98.9072)  time: 0.3485  data: 0.0008  max mem: 2503
Train: Epoch[2/5]  [2760/3750]  eta: 0:05:43  Lr: 0.001875  Loss: -0.6105  Acc@1: 81.2500 (79.8352)  Acc@5: 100.0000 (98.9066)  time: 0.3481  data: 0.0007  max mem: 2503
Train: Epoch[2/5]  [2770/3750]  eta: 0:05:40  Lr: 0.001875  Loss: -0.5086  Acc@1: 75.0000 (79.8313)  Acc@5: 100.0000 (98.9038)  time: 0.3485  data: 0.0016  max mem: 2503
Train: Epoch[2/5]  [2780/3750]  eta: 0:05:36  Lr: 0.001875  Loss: -0.3634  Acc@1: 81.2500 (79.8386)  Acc@5: 100.0000 (98.8988)  time: 0.3486  data: 0.0017  max mem: 2503
Train: Epoch[2/5]  [2790/3750]  eta: 0:05:33  Lr: 0.001875  Loss: -1.0425  Acc@1: 81.2500 (79.8527)  Acc@5: 100.0000 (98.8982)  time: 0.3486  data: 0.0016  max mem: 2503
Train: Epoch[2/5]  [2800/3750]  eta: 0:05:30  Lr: 0.001875  Loss: -0.1979  Acc@1: 81.2500 (79.8710)  Acc@5: 100.0000 (98.8999)  time: 0.3495  data: 0.0022  max mem: 2503
Train: Epoch[2/5]  [2810/3750]  eta: 0:05:26  Lr: 0.001875  Loss: -0.7568  Acc@1: 81.2500 (79.8871)  Acc@5: 100.0000 (98.8950)  time: 0.3481  data: 0.0014  max mem: 2503
Train: Epoch[2/5]  [2820/3750]  eta: 0:05:23  Lr: 0.001875  Loss: -0.6412  Acc@1: 81.2500 (79.8941)  Acc@5: 100.0000 (98.8945)  time: 0.3480  data: 0.0011  max mem: 2503
Train: Epoch[2/5]  [2830/3750]  eta: 0:05:19  Lr: 0.001875  Loss: -0.6462  Acc@1: 81.2500 (79.9011)  Acc@5: 100.0000 (98.8984)  time: 0.3477  data: 0.0010  max mem: 2503
Train: Epoch[2/5]  [2840/3750]  eta: 0:05:16  Lr: 0.001875  Loss: -0.6771  Acc@1: 81.2500 (79.9124)  Acc@5: 100.0000 (98.8978)  time: 0.3465  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [2850/3750]  eta: 0:05:12  Lr: 0.001875  Loss: -0.2560  Acc@1: 81.2500 (79.8908)  Acc@5: 100.0000 (98.8995)  time: 0.3455  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [2860/3750]  eta: 0:05:09  Lr: 0.001875  Loss: -0.8728  Acc@1: 75.0000 (79.8912)  Acc@5: 100.0000 (98.9034)  time: 0.3444  data: 0.0008  max mem: 2503
Train: Epoch[2/5]  [2870/3750]  eta: 0:05:05  Lr: 0.001875  Loss: -0.8659  Acc@1: 81.2500 (79.8959)  Acc@5: 100.0000 (98.9028)  time: 0.3443  data: 0.0014  max mem: 2503
Train: Epoch[2/5]  [2880/3750]  eta: 0:05:02  Lr: 0.001875  Loss: -0.7881  Acc@1: 81.2500 (79.8920)  Acc@5: 100.0000 (98.9045)  time: 0.3464  data: 0.0015  max mem: 2503
Train: Epoch[2/5]  [2890/3750]  eta: 0:04:58  Lr: 0.001875  Loss: -0.3878  Acc@1: 81.2500 (79.8923)  Acc@5: 100.0000 (98.9039)  time: 0.3482  data: 0.0013  max mem: 2503
Train: Epoch[2/5]  [2900/3750]  eta: 0:04:55  Lr: 0.001875  Loss: -0.8859  Acc@1: 81.2500 (79.8798)  Acc@5: 100.0000 (98.9012)  time: 0.3480  data: 0.0009  max mem: 2503
Train: Epoch[2/5]  [2910/3750]  eta: 0:04:51  Lr: 0.001875  Loss: -0.7748  Acc@1: 75.0000 (79.8673)  Acc@5: 100.0000 (98.9029)  time: 0.3473  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [2920/3750]  eta: 0:04:48  Lr: 0.001875  Loss: -0.4537  Acc@1: 75.0000 (79.8507)  Acc@5: 100.0000 (98.9066)  time: 0.3463  data: 0.0006  max mem: 2503
Train: Epoch[2/5]  [2930/3750]  eta: 0:04:44  Lr: 0.001875  Loss: -0.8518  Acc@1: 75.0000 (79.8405)  Acc@5: 100.0000 (98.9040)  time: 0.3473  data: 0.0010  max mem: 2503
Train: Epoch[2/5]  [2940/3750]  eta: 0:04:41  Lr: 0.001875  Loss: -0.8506  Acc@1: 87.5000 (79.8665)  Acc@5: 100.0000 (98.9056)  time: 0.3477  data: 0.0009  max mem: 2503
Train: Epoch[2/5]  [2950/3750]  eta: 0:04:37  Lr: 0.001875  Loss: -0.3468  Acc@1: 87.5000 (79.8712)  Acc@5: 100.0000 (98.9029)  time: 0.3474  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [2960/3750]  eta: 0:04:34  Lr: 0.001875  Loss: -0.2772  Acc@1: 75.0000 (79.8316)  Acc@5: 100.0000 (98.9045)  time: 0.3480  data: 0.0009  max mem: 2503
Train: Epoch[2/5]  [2970/3750]  eta: 0:04:30  Lr: 0.001875  Loss: -0.7677  Acc@1: 75.0000 (79.8447)  Acc@5: 100.0000 (98.9082)  time: 0.3474  data: 0.0012  max mem: 2503
Train: Epoch[2/5]  [2980/3750]  eta: 0:04:27  Lr: 0.001875  Loss: -0.5743  Acc@1: 81.2500 (79.8411)  Acc@5: 100.0000 (98.9098)  time: 0.3468  data: 0.0009  max mem: 2503
Train: Epoch[2/5]  [2990/3750]  eta: 0:04:24  Lr: 0.001875  Loss: -0.6470  Acc@1: 81.2500 (79.8437)  Acc@5: 100.0000 (98.9113)  time: 0.3475  data: 0.0007  max mem: 2503
Train: Epoch[2/5]  [3000/3750]  eta: 0:04:20  Lr: 0.001875  Loss: -0.5169  Acc@1: 81.2500 (79.8421)  Acc@5: 100.0000 (98.9149)  time: 0.3473  data: 0.0007  max mem: 2503
Train: Epoch[2/5]  [3010/3750]  eta: 0:04:17  Lr: 0.001875  Loss: -0.8795  Acc@1: 81.2500 (79.8593)  Acc@5: 100.0000 (98.9185)  time: 0.3459  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [3020/3750]  eta: 0:04:13  Lr: 0.001875  Loss: -0.5904  Acc@1: 81.2500 (79.8556)  Acc@5: 100.0000 (98.9201)  time: 0.3448  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [3030/3750]  eta: 0:04:10  Lr: 0.001875  Loss: -0.3845  Acc@1: 75.0000 (79.8437)  Acc@5: 100.0000 (98.9216)  time: 0.3439  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [3040/3750]  eta: 0:04:06  Lr: 0.001875  Loss: -0.8812  Acc@1: 75.0000 (79.8298)  Acc@5: 100.0000 (98.9210)  time: 0.3436  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [3050/3750]  eta: 0:04:03  Lr: 0.001875  Loss: -0.9637  Acc@1: 75.0000 (79.8324)  Acc@5: 100.0000 (98.9204)  time: 0.3463  data: 0.0009  max mem: 2503
Train: Epoch[2/5]  [3060/3750]  eta: 0:03:59  Lr: 0.001875  Loss: -0.7622  Acc@1: 81.2500 (79.8269)  Acc@5: 100.0000 (98.9178)  time: 0.3493  data: 0.0015  max mem: 2503
Train: Epoch[2/5]  [3070/3750]  eta: 0:03:56  Lr: 0.001875  Loss: -0.7943  Acc@1: 75.0000 (79.8233)  Acc@5: 100.0000 (98.9173)  time: 0.3494  data: 0.0018  max mem: 2503
Train: Epoch[2/5]  [3080/3750]  eta: 0:03:52  Lr: 0.001875  Loss: -0.5106  Acc@1: 81.2500 (79.8199)  Acc@5: 100.0000 (98.9167)  time: 0.3478  data: 0.0013  max mem: 2503
Train: Epoch[2/5]  [3090/3750]  eta: 0:03:49  Lr: 0.001875  Loss: -0.6964  Acc@1: 81.2500 (79.8346)  Acc@5: 100.0000 (98.9203)  time: 0.3491  data: 0.0016  max mem: 2503
Train: Epoch[2/5]  [3100/3750]  eta: 0:03:45  Lr: 0.001875  Loss: -0.9336  Acc@1: 87.5000 (79.8553)  Acc@5: 100.0000 (98.9157)  time: 0.3507  data: 0.0018  max mem: 2503
Train: Epoch[2/5]  [3110/3750]  eta: 0:03:42  Lr: 0.001875  Loss: -0.5902  Acc@1: 87.5000 (79.8578)  Acc@5: 100.0000 (98.9171)  time: 0.3492  data: 0.0012  max mem: 2503
Train: Epoch[2/5]  [3120/3750]  eta: 0:03:38  Lr: 0.001875  Loss: -0.6914  Acc@1: 81.2500 (79.8722)  Acc@5: 100.0000 (98.9206)  time: 0.3484  data: 0.0017  max mem: 2503
Train: Epoch[2/5]  [3130/3750]  eta: 0:03:35  Lr: 0.001875  Loss: -0.7876  Acc@1: 81.2500 (79.8647)  Acc@5: 100.0000 (98.9201)  time: 0.3482  data: 0.0014  max mem: 2503
Train: Epoch[2/5]  [3140/3750]  eta: 0:03:31  Lr: 0.001875  Loss: -0.6975  Acc@1: 81.2500 (79.8631)  Acc@5: 100.0000 (98.9215)  time: 0.3489  data: 0.0014  max mem: 2503
Train: Epoch[2/5]  [3150/3750]  eta: 0:03:28  Lr: 0.001875  Loss: -0.9073  Acc@1: 81.2500 (79.8675)  Acc@5: 100.0000 (98.9249)  time: 0.3493  data: 0.0018  max mem: 2503
Train: Epoch[2/5]  [3160/3750]  eta: 0:03:24  Lr: 0.001875  Loss: -0.6472  Acc@1: 75.0000 (79.8600)  Acc@5: 100.0000 (98.9264)  time: 0.3477  data: 0.0011  max mem: 2503
Train: Epoch[2/5]  [3170/3750]  eta: 0:03:21  Lr: 0.001875  Loss: -0.7719  Acc@1: 75.0000 (79.8565)  Acc@5: 100.0000 (98.9258)  time: 0.3458  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [3180/3750]  eta: 0:03:18  Lr: 0.001875  Loss: -1.0466  Acc@1: 75.0000 (79.8511)  Acc@5: 100.0000 (98.9233)  time: 0.3451  data: 0.0010  max mem: 2503
Train: Epoch[2/5]  [3190/3750]  eta: 0:03:14  Lr: 0.001875  Loss: -0.3742  Acc@1: 81.2500 (79.8594)  Acc@5: 100.0000 (98.9247)  time: 0.3452  data: 0.0013  max mem: 2503
Train: Epoch[2/5]  [3200/3750]  eta: 0:03:11  Lr: 0.001875  Loss: -0.4370  Acc@1: 81.2500 (79.8598)  Acc@5: 100.0000 (98.9242)  time: 0.3448  data: 0.0006  max mem: 2503
Train: Epoch[2/5]  [3210/3750]  eta: 0:03:07  Lr: 0.001875  Loss: -0.7763  Acc@1: 81.2500 (79.8583)  Acc@5: 100.0000 (98.9236)  time: 0.3464  data: 0.0009  max mem: 2503
Train: Epoch[2/5]  [3220/3750]  eta: 0:03:04  Lr: 0.001875  Loss: -0.8646  Acc@1: 81.2500 (79.8743)  Acc@5: 100.0000 (98.9270)  time: 0.3485  data: 0.0013  max mem: 2503
Train: Epoch[2/5]  [3230/3750]  eta: 0:03:00  Lr: 0.001875  Loss: -0.6326  Acc@1: 87.5000 (79.8824)  Acc@5: 100.0000 (98.9264)  time: 0.3475  data: 0.0009  max mem: 2503
Train: Epoch[2/5]  [3240/3750]  eta: 0:02:57  Lr: 0.001875  Loss: -0.8853  Acc@1: 87.5000 (79.8982)  Acc@5: 100.0000 (98.9278)  time: 0.3478  data: 0.0009  max mem: 2503
Train: Epoch[2/5]  [3250/3750]  eta: 0:02:53  Lr: 0.001875  Loss: -0.8146  Acc@1: 87.5000 (79.8966)  Acc@5: 100.0000 (98.9292)  time: 0.3491  data: 0.0012  max mem: 2503
Train: Epoch[2/5]  [3260/3750]  eta: 0:02:50  Lr: 0.001875  Loss: -0.6725  Acc@1: 75.0000 (79.8969)  Acc@5: 100.0000 (98.9325)  time: 0.3503  data: 0.0014  max mem: 2503
Train: Epoch[2/5]  [3270/3750]  eta: 0:02:46  Lr: 0.001875  Loss: -0.9262  Acc@1: 81.2500 (79.9087)  Acc@5: 100.0000 (98.9338)  time: 0.3499  data: 0.0012  max mem: 2503
Train: Epoch[2/5]  [3280/3750]  eta: 0:02:43  Lr: 0.001875  Loss: -0.7032  Acc@1: 81.2500 (79.9051)  Acc@5: 100.0000 (98.9313)  time: 0.3483  data: 0.0013  max mem: 2503
Train: Epoch[2/5]  [3290/3750]  eta: 0:02:39  Lr: 0.001875  Loss: -0.9869  Acc@1: 75.0000 (79.9054)  Acc@5: 100.0000 (98.9289)  time: 0.3480  data: 0.0013  max mem: 2503
Train: Epoch[2/5]  [3300/3750]  eta: 0:02:36  Lr: 0.001875  Loss: -1.0139  Acc@1: 75.0000 (79.9076)  Acc@5: 100.0000 (98.9284)  time: 0.3480  data: 0.0008  max mem: 2503
Train: Epoch[2/5]  [3310/3750]  eta: 0:02:32  Lr: 0.001875  Loss: -0.8206  Acc@1: 81.2500 (79.9022)  Acc@5: 100.0000 (98.9259)  time: 0.3481  data: 0.0010  max mem: 2503
Train: Epoch[2/5]  [3320/3750]  eta: 0:02:29  Lr: 0.001875  Loss: -0.4999  Acc@1: 81.2500 (79.8969)  Acc@5: 100.0000 (98.9273)  time: 0.3497  data: 0.0020  max mem: 2503
Train: Epoch[2/5]  [3330/3750]  eta: 0:02:25  Lr: 0.001875  Loss: -0.9021  Acc@1: 81.2500 (79.9047)  Acc@5: 100.0000 (98.9249)  time: 0.3484  data: 0.0016  max mem: 2503
Train: Epoch[2/5]  [3340/3750]  eta: 0:02:22  Lr: 0.001875  Loss: -0.4770  Acc@1: 81.2500 (79.9050)  Acc@5: 100.0000 (98.9262)  time: 0.3457  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [3350/3750]  eta: 0:02:18  Lr: 0.001875  Loss: -0.5845  Acc@1: 81.2500 (79.9071)  Acc@5: 100.0000 (98.9294)  time: 0.3446  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [3360/3750]  eta: 0:02:15  Lr: 0.001875  Loss: -0.7831  Acc@1: 81.2500 (79.9037)  Acc@5: 100.0000 (98.9289)  time: 0.3440  data: 0.0002  max mem: 2503
Train: Epoch[2/5]  [3370/3750]  eta: 0:02:12  Lr: 0.001875  Loss: -1.0563  Acc@1: 81.2500 (79.9225)  Acc@5: 100.0000 (98.9302)  time: 0.3438  data: 0.0002  max mem: 2503
Train: Epoch[2/5]  [3380/3750]  eta: 0:02:08  Lr: 0.001875  Loss: -0.8947  Acc@1: 87.5000 (79.9357)  Acc@5: 100.0000 (98.9297)  time: 0.3461  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [3390/3750]  eta: 0:02:05  Lr: 0.001875  Loss: -0.7960  Acc@1: 81.2500 (79.9322)  Acc@5: 100.0000 (98.9328)  time: 0.3478  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [3400/3750]  eta: 0:02:01  Lr: 0.001875  Loss: -0.8692  Acc@1: 75.0000 (79.9269)  Acc@5: 100.0000 (98.9341)  time: 0.3469  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [3410/3750]  eta: 0:01:58  Lr: 0.001875  Loss: -0.8273  Acc@1: 81.2500 (79.9216)  Acc@5: 100.0000 (98.9354)  time: 0.3472  data: 0.0013  max mem: 2503
Train: Epoch[2/5]  [3420/3750]  eta: 0:01:54  Lr: 0.001875  Loss: -0.7632  Acc@1: 81.2500 (79.9309)  Acc@5: 100.0000 (98.9385)  time: 0.3474  data: 0.0015  max mem: 2503
Train: Epoch[2/5]  [3430/3750]  eta: 0:01:51  Lr: 0.001875  Loss: -0.4410  Acc@1: 81.2500 (79.9403)  Acc@5: 100.0000 (98.9416)  time: 0.3476  data: 0.0014  max mem: 2503
Train: Epoch[2/5]  [3440/3750]  eta: 0:01:47  Lr: 0.001875  Loss: -0.9703  Acc@1: 81.2500 (79.9495)  Acc@5: 100.0000 (98.9411)  time: 0.3473  data: 0.0013  max mem: 2503
Train: Epoch[2/5]  [3450/3750]  eta: 0:01:44  Lr: 0.001875  Loss: -0.7111  Acc@1: 75.0000 (79.9406)  Acc@5: 100.0000 (98.9405)  time: 0.3467  data: 0.0009  max mem: 2503
Train: Epoch[2/5]  [3460/3750]  eta: 0:01:40  Lr: 0.001875  Loss: -0.6181  Acc@1: 81.2500 (79.9462)  Acc@5: 100.0000 (98.9418)  time: 0.3475  data: 0.0010  max mem: 2503
Train: Epoch[2/5]  [3470/3750]  eta: 0:01:37  Lr: 0.001875  Loss: -0.8106  Acc@1: 81.2500 (79.9409)  Acc@5: 100.0000 (98.9394)  time: 0.3472  data: 0.0009  max mem: 2503
Train: Epoch[2/5]  [3480/3750]  eta: 0:01:33  Lr: 0.001875  Loss: -0.4681  Acc@1: 81.2500 (79.9465)  Acc@5: 100.0000 (98.9389)  time: 0.3465  data: 0.0006  max mem: 2503
Train: Epoch[2/5]  [3490/3750]  eta: 0:01:30  Lr: 0.001875  Loss: -0.4236  Acc@1: 81.2500 (79.9413)  Acc@5: 100.0000 (98.9383)  time: 0.3474  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [3500/3750]  eta: 0:01:26  Lr: 0.001875  Loss: -0.6756  Acc@1: 81.2500 (79.9414)  Acc@5: 100.0000 (98.9414)  time: 0.3472  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [3510/3750]  eta: 0:01:23  Lr: 0.001875  Loss: -0.7124  Acc@1: 81.2500 (79.9487)  Acc@5: 100.0000 (98.9408)  time: 0.3465  data: 0.0007  max mem: 2503
Train: Epoch[2/5]  [3520/3750]  eta: 0:01:19  Lr: 0.001875  Loss: -0.3972  Acc@1: 81.2500 (79.9418)  Acc@5: 100.0000 (98.9385)  time: 0.3471  data: 0.0007  max mem: 2503
Train: Epoch[2/5]  [3530/3750]  eta: 0:01:16  Lr: 0.001875  Loss: -0.6297  Acc@1: 81.2500 (79.9614)  Acc@5: 100.0000 (98.9397)  time: 0.3474  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [3540/3750]  eta: 0:01:12  Lr: 0.001875  Loss: -0.4804  Acc@1: 87.5000 (79.9862)  Acc@5: 100.0000 (98.9374)  time: 0.3475  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [3550/3750]  eta: 0:01:09  Lr: 0.001875  Loss: -0.8840  Acc@1: 87.5000 (79.9986)  Acc@5: 100.0000 (98.9387)  time: 0.3458  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [3560/3750]  eta: 0:01:05  Lr: 0.001875  Loss: -0.8750  Acc@1: 87.5000 (79.9986)  Acc@5: 100.0000 (98.9381)  time: 0.3438  data: 0.0002  max mem: 2503
Train: Epoch[2/5]  [3570/3750]  eta: 0:01:02  Lr: 0.001875  Loss: -0.3494  Acc@1: 81.2500 (80.0074)  Acc@5: 100.0000 (98.9394)  time: 0.3435  data: 0.0002  max mem: 2503
Train: Epoch[2/5]  [3580/3750]  eta: 0:00:59  Lr: 0.001875  Loss: -0.2909  Acc@1: 81.2500 (80.0056)  Acc@5: 100.0000 (98.9388)  time: 0.3447  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [3590/3750]  eta: 0:00:55  Lr: 0.001875  Loss: -0.8104  Acc@1: 81.2500 (80.0160)  Acc@5: 100.0000 (98.9418)  time: 0.3466  data: 0.0007  max mem: 2503
Train: Epoch[2/5]  [3600/3750]  eta: 0:00:52  Lr: 0.001875  Loss: -0.9376  Acc@1: 81.2500 (80.0177)  Acc@5: 100.0000 (98.9413)  time: 0.3490  data: 0.0016  max mem: 2503
Train: Epoch[2/5]  [3610/3750]  eta: 0:00:48  Lr: 0.001875  Loss: -0.5913  Acc@1: 81.2500 (80.0194)  Acc@5: 100.0000 (98.9425)  time: 0.3495  data: 0.0018  max mem: 2503
Train: Epoch[2/5]  [3620/3750]  eta: 0:00:45  Lr: 0.001875  Loss: -0.7908  Acc@1: 75.0000 (80.0176)  Acc@5: 100.0000 (98.9454)  time: 0.3482  data: 0.0015  max mem: 2503
Train: Epoch[2/5]  [3630/3750]  eta: 0:00:41  Lr: 0.001875  Loss: -0.4843  Acc@1: 75.0000 (80.0055)  Acc@5: 100.0000 (98.9483)  time: 0.3477  data: 0.0014  max mem: 2503
Train: Epoch[2/5]  [3640/3750]  eta: 0:00:38  Lr: 0.001875  Loss: -0.6139  Acc@1: 75.0000 (79.9986)  Acc@5: 100.0000 (98.9409)  time: 0.3483  data: 0.0010  max mem: 2503
Train: Epoch[2/5]  [3650/3750]  eta: 0:00:34  Lr: 0.001875  Loss: -0.8438  Acc@1: 75.0000 (79.9918)  Acc@5: 100.0000 (98.9421)  time: 0.3498  data: 0.0011  max mem: 2503
Train: Epoch[2/5]  [3660/3750]  eta: 0:00:31  Lr: 0.001875  Loss: -0.5796  Acc@1: 81.2500 (79.9781)  Acc@5: 100.0000 (98.9433)  time: 0.3490  data: 0.0012  max mem: 2503
Train: Epoch[2/5]  [3670/3750]  eta: 0:00:27  Lr: 0.001875  Loss: -0.8418  Acc@1: 75.0000 (79.9697)  Acc@5: 100.0000 (98.9461)  time: 0.3479  data: 0.0010  max mem: 2503
Train: Epoch[2/5]  [3680/3750]  eta: 0:00:24  Lr: 0.001875  Loss: -1.0182  Acc@1: 81.2500 (79.9817)  Acc@5: 100.0000 (98.9405)  time: 0.3488  data: 0.0006  max mem: 2503
Train: Epoch[2/5]  [3690/3750]  eta: 0:00:20  Lr: 0.001875  Loss: -0.0041  Acc@1: 81.2500 (79.9834)  Acc@5: 100.0000 (98.9383)  time: 0.3493  data: 0.0008  max mem: 2503
Train: Epoch[2/5]  [3700/3750]  eta: 0:00:17  Lr: 0.001875  Loss: -0.5342  Acc@1: 81.2500 (79.9885)  Acc@5: 100.0000 (98.9395)  time: 0.3482  data: 0.0009  max mem: 2503
Train: Epoch[2/5]  [3710/3750]  eta: 0:00:13  Lr: 0.001875  Loss: -0.5522  Acc@1: 81.2500 (79.9953)  Acc@5: 100.0000 (98.9390)  time: 0.3470  data: 0.0006  max mem: 2503
Train: Epoch[2/5]  [3720/3750]  eta: 0:00:10  Lr: 0.001875  Loss: -0.6082  Acc@1: 81.2500 (80.0003)  Acc@5: 100.0000 (98.9385)  time: 0.3462  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [3730/3750]  eta: 0:00:06  Lr: 0.001875  Loss: -0.8242  Acc@1: 81.2500 (80.0037)  Acc@5: 100.0000 (98.9329)  time: 0.3459  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [3740/3750]  eta: 0:00:03  Lr: 0.001875  Loss: -0.6950  Acc@1: 81.2500 (80.0020)  Acc@5: 100.0000 (98.9358)  time: 0.3457  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [3749/3750]  eta: 0:00:00  Lr: 0.001875  Loss: -1.0412  Acc@1: 81.2500 (80.0067)  Acc@5: 100.0000 (98.9317)  time: 0.3454  data: 0.0006  max mem: 2503
Train: Epoch[2/5] Total time: 0:21:43 (0.3475 s / it)
{0: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 1: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 2: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 3: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 4: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 5: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 6: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 7: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 8: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 9: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 10: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 11: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 12: {0: 0, 1: 0, 2: 0, 3: 91325, 4: 0}, 13: {0: 0, 1: 0, 2: 0, 3: 91325, 4: 0}, 14: {0: 0, 1: 0, 2: 0, 3: 91325, 4: 0}, 15: {0: 0, 1: 0, 2: 0, 3: 91325, 4: 0}, 16: {0: 0, 1: 0, 2: 0, 3: 0, 4: 120000}, 17: {0: 0, 1: 0, 2: 0, 3: 0, 4: 120000}, 18: {0: 0, 1: 0, 2: 0, 3: 0, 4: 120000}, 19: {0: 0, 1: 0, 2: 0, 3: 0, 4: 120000}}
Averaged stats: Lr: 0.001875  Loss: -1.0412  Acc@1: 81.2500 (80.0067)  Acc@5: 100.0000 (98.9317)
Train: Epoch[3/5]  [   0/3750]  eta: 0:44:25  Lr: 0.001875  Loss: -0.9229  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (100.0000)  time: 0.7107  data: 0.3679  max mem: 2503
Train: Epoch[3/5]  [  10/3750]  eta: 0:23:43  Lr: 0.001875  Loss: -0.3419  Acc@1: 87.5000 (82.3864)  Acc@5: 100.0000 (97.7273)  time: 0.3805  data: 0.0347  max mem: 2503
Train: Epoch[3/5]  [  20/3750]  eta: 0:22:37  Lr: 0.001875  Loss: -0.5299  Acc@1: 81.2500 (80.6548)  Acc@5: 100.0000 (98.2143)  time: 0.3465  data: 0.0011  max mem: 2503
Train: Epoch[3/5]  [  30/3750]  eta: 0:22:12  Lr: 0.001875  Loss: -0.5461  Acc@1: 81.2500 (80.4435)  Acc@5: 100.0000 (98.1855)  time: 0.3461  data: 0.0011  max mem: 2503
Train: Epoch[3/5]  [  40/3750]  eta: 0:21:59  Lr: 0.001875  Loss: -0.5818  Acc@1: 81.2500 (80.0305)  Acc@5: 100.0000 (98.1707)  time: 0.3472  data: 0.0013  max mem: 2503
Train: Epoch[3/5]  [  50/3750]  eta: 0:21:50  Lr: 0.001875  Loss: -0.7832  Acc@1: 81.2500 (79.5343)  Acc@5: 100.0000 (98.2843)  time: 0.3478  data: 0.0011  max mem: 2503
Train: Epoch[3/5]  [  60/3750]  eta: 0:21:42  Lr: 0.001875  Loss: -0.8456  Acc@1: 81.2500 (78.8934)  Acc@5: 100.0000 (98.4631)  time: 0.3474  data: 0.0009  max mem: 2503
Train: Epoch[3/5]  [  70/3750]  eta: 0:21:35  Lr: 0.001875  Loss: -0.9792  Acc@1: 81.2500 (79.6655)  Acc@5: 100.0000 (98.5915)  time: 0.3470  data: 0.0008  max mem: 2503
Train: Epoch[3/5]  [  80/3750]  eta: 0:21:30  Lr: 0.001875  Loss: -0.6760  Acc@1: 81.2500 (79.6296)  Acc@5: 100.0000 (98.7654)  time: 0.3472  data: 0.0009  max mem: 2503
Train: Epoch[3/5]  [  90/3750]  eta: 0:21:24  Lr: 0.001875  Loss: -0.8877  Acc@1: 81.2500 (80.0137)  Acc@5: 100.0000 (98.6951)  time: 0.3466  data: 0.0010  max mem: 2503
Train: Epoch[3/5]  [ 100/3750]  eta: 0:21:19  Lr: 0.001875  Loss: -0.8224  Acc@1: 87.5000 (80.1361)  Acc@5: 100.0000 (98.6386)  time: 0.3460  data: 0.0009  max mem: 2503
Train: Epoch[3/5]  [ 110/3750]  eta: 0:21:14  Lr: 0.001875  Loss: -0.5470  Acc@1: 81.2500 (80.2365)  Acc@5: 100.0000 (98.5923)  time: 0.3469  data: 0.0014  max mem: 2503
Train: Epoch[3/5]  [ 120/3750]  eta: 0:21:10  Lr: 0.001875  Loss: -0.7026  Acc@1: 81.2500 (80.5269)  Acc@5: 100.0000 (98.7087)  time: 0.3469  data: 0.0013  max mem: 2503
Train: Epoch[3/5]  [ 130/3750]  eta: 0:21:07  Lr: 0.001875  Loss: -0.5926  Acc@1: 81.2500 (80.5821)  Acc@5: 100.0000 (98.7118)  time: 0.3492  data: 0.0009  max mem: 2503
Train: Epoch[3/5]  [ 140/3750]  eta: 0:21:02  Lr: 0.001875  Loss: -0.9577  Acc@1: 81.2500 (80.8511)  Acc@5: 100.0000 (98.7589)  time: 0.3490  data: 0.0008  max mem: 2503
Train: Epoch[3/5]  [ 150/3750]  eta: 0:20:58  Lr: 0.001875  Loss: -0.8335  Acc@1: 81.2500 (80.8361)  Acc@5: 100.0000 (98.7583)  time: 0.3459  data: 0.0006  max mem: 2503
Train: Epoch[3/5]  [ 160/3750]  eta: 0:20:53  Lr: 0.001875  Loss: -0.9465  Acc@1: 81.2500 (80.8618)  Acc@5: 100.0000 (98.7966)  time: 0.3451  data: 0.0010  max mem: 2503
Train: Epoch[3/5]  [ 170/3750]  eta: 0:20:48  Lr: 0.001875  Loss: -0.6550  Acc@1: 81.2500 (80.7749)  Acc@5: 100.0000 (98.8304)  time: 0.3433  data: 0.0009  max mem: 2503
Train: Epoch[3/5]  [ 180/3750]  eta: 0:20:44  Lr: 0.001875  Loss: -0.7732  Acc@1: 81.2500 (80.7320)  Acc@5: 100.0000 (98.7914)  time: 0.3431  data: 0.0002  max mem: 2503
Train: Epoch[3/5]  [ 190/3750]  eta: 0:20:40  Lr: 0.001875  Loss: -0.2907  Acc@1: 81.2500 (80.6937)  Acc@5: 100.0000 (98.7565)  time: 0.3455  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [ 200/3750]  eta: 0:20:36  Lr: 0.001875  Loss: -0.8241  Acc@1: 87.5000 (80.7525)  Acc@5: 100.0000 (98.7562)  time: 0.3479  data: 0.0008  max mem: 2503
Train: Epoch[3/5]  [ 210/3750]  eta: 0:20:33  Lr: 0.001875  Loss: -0.5871  Acc@1: 81.2500 (80.4799)  Acc@5: 100.0000 (98.7263)  time: 0.3474  data: 0.0011  max mem: 2503
Train: Epoch[3/5]  [ 220/3750]  eta: 0:20:29  Lr: 0.001875  Loss: -0.7646  Acc@1: 81.2500 (80.4581)  Acc@5: 100.0000 (98.6708)  time: 0.3469  data: 0.0011  max mem: 2503
Train: Epoch[3/5]  [ 230/3750]  eta: 0:20:25  Lr: 0.001875  Loss: -0.5200  Acc@1: 81.2500 (80.4924)  Acc@5: 100.0000 (98.6742)  time: 0.3469  data: 0.0009  max mem: 2503
Train: Epoch[3/5]  [ 240/3750]  eta: 0:20:22  Lr: 0.001875  Loss: -1.0209  Acc@1: 81.2500 (80.5757)  Acc@5: 100.0000 (98.7033)  time: 0.3480  data: 0.0015  max mem: 2503
Train: Epoch[3/5]  [ 250/3750]  eta: 0:20:18  Lr: 0.001875  Loss: -0.1286  Acc@1: 81.2500 (80.5279)  Acc@5: 100.0000 (98.7052)  time: 0.3489  data: 0.0018  max mem: 2503
Train: Epoch[3/5]  [ 260/3750]  eta: 0:20:15  Lr: 0.001875  Loss: -0.6867  Acc@1: 81.2500 (80.6274)  Acc@5: 100.0000 (98.7069)  time: 0.3481  data: 0.0010  max mem: 2503
Train: Epoch[3/5]  [ 270/3750]  eta: 0:20:11  Lr: 0.001875  Loss: -0.7289  Acc@1: 81.2500 (80.6734)  Acc@5: 100.0000 (98.6624)  time: 0.3479  data: 0.0011  max mem: 2503
Train: Epoch[3/5]  [ 280/3750]  eta: 0:20:08  Lr: 0.001875  Loss: -0.8798  Acc@1: 81.2500 (80.6495)  Acc@5: 100.0000 (98.6655)  time: 0.3482  data: 0.0013  max mem: 2503
Train: Epoch[3/5]  [ 290/3750]  eta: 0:20:04  Lr: 0.001875  Loss: -0.7451  Acc@1: 75.0000 (80.6271)  Acc@5: 100.0000 (98.6469)  time: 0.3477  data: 0.0010  max mem: 2503
Train: Epoch[3/5]  [ 300/3750]  eta: 0:20:01  Lr: 0.001875  Loss: -0.8726  Acc@1: 81.2500 (80.6894)  Acc@5: 100.0000 (98.6711)  time: 0.3471  data: 0.0010  max mem: 2503
Train: Epoch[3/5]  [ 310/3750]  eta: 0:19:57  Lr: 0.001875  Loss: -1.0079  Acc@1: 81.2500 (80.7476)  Acc@5: 100.0000 (98.6535)  time: 0.3462  data: 0.0008  max mem: 2503
Train: Epoch[3/5]  [ 320/3750]  eta: 0:19:53  Lr: 0.001875  Loss: -0.4139  Acc@1: 81.2500 (80.6854)  Acc@5: 100.0000 (98.6565)  time: 0.3444  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [ 330/3750]  eta: 0:19:49  Lr: 0.001875  Loss: -0.7196  Acc@1: 75.0000 (80.5136)  Acc@5: 100.0000 (98.6971)  time: 0.3438  data: 0.0013  max mem: 2503
Train: Epoch[3/5]  [ 340/3750]  eta: 0:19:45  Lr: 0.001875  Loss: -0.5781  Acc@1: 75.0000 (80.4985)  Acc@5: 100.0000 (98.7353)  time: 0.3438  data: 0.0010  max mem: 2503
Train: Epoch[3/5]  [ 350/3750]  eta: 0:19:41  Lr: 0.001875  Loss: -0.7442  Acc@1: 81.2500 (80.4843)  Acc@5: 100.0000 (98.7536)  time: 0.3446  data: 0.0007  max mem: 2503
Train: Epoch[3/5]  [ 360/3750]  eta: 0:19:38  Lr: 0.001875  Loss: -0.8008  Acc@1: 81.2500 (80.6440)  Acc@5: 100.0000 (98.7708)  time: 0.3472  data: 0.0015  max mem: 2503
Train: Epoch[3/5]  [ 370/3750]  eta: 0:19:35  Lr: 0.001875  Loss: -0.0201  Acc@1: 81.2500 (80.6941)  Acc@5: 100.0000 (98.7534)  time: 0.3477  data: 0.0016  max mem: 2503
Train: Epoch[3/5]  [ 380/3750]  eta: 0:19:31  Lr: 0.001875  Loss: -0.6579  Acc@1: 75.0000 (80.5446)  Acc@5: 100.0000 (98.7697)  time: 0.3479  data: 0.0021  max mem: 2503
Train: Epoch[3/5]  [ 390/3750]  eta: 0:19:28  Lr: 0.001875  Loss: -0.6744  Acc@1: 75.0000 (80.5307)  Acc@5: 100.0000 (98.8012)  time: 0.3475  data: 0.0017  max mem: 2503
Train: Epoch[3/5]  [ 400/3750]  eta: 0:19:24  Lr: 0.001875  Loss: -0.5190  Acc@1: 81.2500 (80.6110)  Acc@5: 100.0000 (98.7999)  time: 0.3482  data: 0.0011  max mem: 2503
Train: Epoch[3/5]  [ 410/3750]  eta: 0:19:21  Lr: 0.001875  Loss: -0.8520  Acc@1: 81.2500 (80.7026)  Acc@5: 100.0000 (98.8291)  time: 0.3498  data: 0.0012  max mem: 2503
Train: Epoch[3/5]  [ 420/3750]  eta: 0:19:17  Lr: 0.001875  Loss: -0.5074  Acc@1: 81.2500 (80.6562)  Acc@5: 100.0000 (98.8420)  time: 0.3476  data: 0.0008  max mem: 2503
Train: Epoch[3/5]  [ 430/3750]  eta: 0:19:14  Lr: 0.001875  Loss: -0.8570  Acc@1: 81.2500 (80.7860)  Acc@5: 100.0000 (98.8544)  time: 0.3464  data: 0.0007  max mem: 2503
Train: Epoch[3/5]  [ 440/3750]  eta: 0:19:10  Lr: 0.001875  Loss: -0.5929  Acc@1: 81.2500 (80.7398)  Acc@5: 100.0000 (98.8804)  time: 0.3479  data: 0.0007  max mem: 2503
Train: Epoch[3/5]  [ 450/3750]  eta: 0:19:07  Lr: 0.001875  Loss: -0.9079  Acc@1: 75.0000 (80.6680)  Acc@5: 100.0000 (98.8914)  time: 0.3488  data: 0.0011  max mem: 2503
Train: Epoch[3/5]  [ 460/3750]  eta: 0:19:04  Lr: 0.001875  Loss: -0.8089  Acc@1: 75.0000 (80.6399)  Acc@5: 100.0000 (98.9018)  time: 0.3492  data: 0.0015  max mem: 2503
Train: Epoch[3/5]  [ 470/3750]  eta: 0:19:00  Lr: 0.001875  Loss: -0.8060  Acc@1: 81.2500 (80.6396)  Acc@5: 100.0000 (98.8986)  time: 0.3479  data: 0.0011  max mem: 2503
Train: Epoch[3/5]  [ 480/3750]  eta: 0:18:56  Lr: 0.001875  Loss: -0.5006  Acc@1: 81.2500 (80.7043)  Acc@5: 100.0000 (98.9085)  time: 0.3450  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [ 490/3750]  eta: 0:18:53  Lr: 0.001875  Loss: -0.6904  Acc@1: 87.5000 (80.7026)  Acc@5: 100.0000 (98.8926)  time: 0.3434  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [ 500/3750]  eta: 0:18:49  Lr: 0.001875  Loss: -0.5769  Acc@1: 81.2500 (80.7260)  Acc@5: 100.0000 (98.8897)  time: 0.3433  data: 0.0006  max mem: 2503
Train: Epoch[3/5]  [ 510/3750]  eta: 0:18:45  Lr: 0.001875  Loss: -0.6141  Acc@1: 81.2500 (80.6874)  Acc@5: 100.0000 (98.8748)  time: 0.3443  data: 0.0009  max mem: 2503
Train: Epoch[3/5]  [ 520/3750]  eta: 0:18:42  Lr: 0.001875  Loss: -0.4964  Acc@1: 81.2500 (80.7342)  Acc@5: 100.0000 (98.8844)  time: 0.3466  data: 0.0011  max mem: 2503
Train: Epoch[3/5]  [ 530/3750]  eta: 0:18:38  Lr: 0.001875  Loss: -0.6045  Acc@1: 81.2500 (80.7674)  Acc@5: 100.0000 (98.9054)  time: 0.3474  data: 0.0010  max mem: 2503
Train: Epoch[3/5]  [ 540/3750]  eta: 0:18:35  Lr: 0.001875  Loss: -0.8822  Acc@1: 81.2500 (80.7186)  Acc@5: 100.0000 (98.8909)  time: 0.3478  data: 0.0017  max mem: 2503
Train: Epoch[3/5]  [ 550/3750]  eta: 0:18:32  Lr: 0.001875  Loss: -0.8699  Acc@1: 81.2500 (80.7736)  Acc@5: 100.0000 (98.8997)  time: 0.3497  data: 0.0033  max mem: 2503
Train: Epoch[3/5]  [ 560/3750]  eta: 0:18:28  Lr: 0.001875  Loss: -0.6179  Acc@1: 75.0000 (80.6930)  Acc@5: 100.0000 (98.8748)  time: 0.3487  data: 0.0022  max mem: 2503
Train: Epoch[3/5]  [ 570/3750]  eta: 0:18:25  Lr: 0.001875  Loss: -0.5444  Acc@1: 75.0000 (80.7137)  Acc@5: 100.0000 (98.8726)  time: 0.3478  data: 0.0007  max mem: 2503
Train: Epoch[3/5]  [ 580/3750]  eta: 0:18:21  Lr: 0.001875  Loss: -0.5824  Acc@1: 81.2500 (80.8090)  Acc@5: 100.0000 (98.8920)  time: 0.3475  data: 0.0009  max mem: 2503
Train: Epoch[3/5]  [ 590/3750]  eta: 0:18:18  Lr: 0.001875  Loss: -0.7492  Acc@1: 81.2500 (80.7424)  Acc@5: 100.0000 (98.9002)  time: 0.3475  data: 0.0012  max mem: 2503
Train: Epoch[3/5]  [ 600/3750]  eta: 0:18:14  Lr: 0.001875  Loss: -0.3998  Acc@1: 81.2500 (80.6572)  Acc@5: 100.0000 (98.8873)  time: 0.3483  data: 0.0019  max mem: 2503
Train: Epoch[3/5]  [ 610/3750]  eta: 0:18:11  Lr: 0.001875  Loss: -0.4104  Acc@1: 81.2500 (80.7181)  Acc@5: 100.0000 (98.8953)  time: 0.3493  data: 0.0024  max mem: 2503
Train: Epoch[3/5]  [ 620/3750]  eta: 0:18:07  Lr: 0.001875  Loss: -0.3044  Acc@1: 75.0000 (80.5656)  Acc@5: 100.0000 (98.8829)  time: 0.3480  data: 0.0015  max mem: 2503
Train: Epoch[3/5]  [ 630/3750]  eta: 0:18:04  Lr: 0.001875  Loss: -0.6166  Acc@1: 68.7500 (80.5864)  Acc@5: 100.0000 (98.9006)  time: 0.3475  data: 0.0013  max mem: 2503
Train: Epoch[3/5]  [ 640/3750]  eta: 0:18:00  Lr: 0.001875  Loss: -0.6547  Acc@1: 81.2500 (80.5480)  Acc@5: 100.0000 (98.8982)  time: 0.3458  data: 0.0011  max mem: 2503
Train: Epoch[3/5]  [ 650/3750]  eta: 0:17:57  Lr: 0.001875  Loss: -0.6953  Acc@1: 81.2500 (80.5012)  Acc@5: 100.0000 (98.9151)  time: 0.3427  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [ 660/3750]  eta: 0:17:53  Lr: 0.001875  Loss: -0.7639  Acc@1: 81.2500 (80.6070)  Acc@5: 100.0000 (98.9221)  time: 0.3429  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [ 670/3750]  eta: 0:17:49  Lr: 0.001875  Loss: -0.7679  Acc@1: 81.2500 (80.5980)  Acc@5: 100.0000 (98.9288)  time: 0.3441  data: 0.0007  max mem: 2503
Train: Epoch[3/5]  [ 680/3750]  eta: 0:17:46  Lr: 0.001875  Loss: -0.3176  Acc@1: 81.2500 (80.5709)  Acc@5: 100.0000 (98.9354)  time: 0.3466  data: 0.0009  max mem: 2503
Train: Epoch[3/5]  [ 690/3750]  eta: 0:17:42  Lr: 0.001875  Loss: -0.6251  Acc@1: 81.2500 (80.6169)  Acc@5: 100.0000 (98.9418)  time: 0.3478  data: 0.0007  max mem: 2503
Train: Epoch[3/5]  [ 700/3750]  eta: 0:17:39  Lr: 0.001875  Loss: -0.8168  Acc@1: 81.2500 (80.5991)  Acc@5: 100.0000 (98.9301)  time: 0.3470  data: 0.0006  max mem: 2503
Train: Epoch[3/5]  [ 710/3750]  eta: 0:17:35  Lr: 0.001875  Loss: -0.9024  Acc@1: 81.2500 (80.5731)  Acc@5: 100.0000 (98.9364)  time: 0.3469  data: 0.0011  max mem: 2503
Train: Epoch[3/5]  [ 720/3750]  eta: 0:17:32  Lr: 0.001875  Loss: -1.0417  Acc@1: 81.2500 (80.5999)  Acc@5: 100.0000 (98.9424)  time: 0.3471  data: 0.0010  max mem: 2503
Train: Epoch[3/5]  [ 730/3750]  eta: 0:17:28  Lr: 0.001875  Loss: -0.4543  Acc@1: 81.2500 (80.6088)  Acc@5: 100.0000 (98.9142)  time: 0.3472  data: 0.0007  max mem: 2503
Train: Epoch[3/5]  [ 740/3750]  eta: 0:17:25  Lr: 0.001875  Loss: -0.7622  Acc@1: 81.2500 (80.6258)  Acc@5: 100.0000 (98.9204)  time: 0.3476  data: 0.0010  max mem: 2503
Train: Epoch[3/5]  [ 750/3750]  eta: 0:17:22  Lr: 0.001875  Loss: -0.5149  Acc@1: 81.2500 (80.5759)  Acc@5: 100.0000 (98.9015)  time: 0.3481  data: 0.0014  max mem: 2503
Train: Epoch[3/5]  [ 760/3750]  eta: 0:17:18  Lr: 0.001875  Loss: -0.8750  Acc@1: 81.2500 (80.5273)  Acc@5: 100.0000 (98.9077)  time: 0.3496  data: 0.0017  max mem: 2503
Train: Epoch[3/5]  [ 770/3750]  eta: 0:17:15  Lr: 0.001875  Loss: 0.0353  Acc@1: 81.2500 (80.5447)  Acc@5: 100.0000 (98.8975)  time: 0.3489  data: 0.0010  max mem: 2503
Train: Epoch[3/5]  [ 780/3750]  eta: 0:17:11  Lr: 0.001875  Loss: -0.7211  Acc@1: 81.2500 (80.5218)  Acc@5: 100.0000 (98.9117)  time: 0.3470  data: 0.0007  max mem: 2503
Train: Epoch[3/5]  [ 790/3750]  eta: 0:17:08  Lr: 0.001875  Loss: -0.6956  Acc@1: 81.2500 (80.5152)  Acc@5: 100.0000 (98.9254)  time: 0.3456  data: 0.0006  max mem: 2503
Train: Epoch[3/5]  [ 800/3750]  eta: 0:17:04  Lr: 0.001875  Loss: -0.3481  Acc@1: 75.0000 (80.4385)  Acc@5: 100.0000 (98.8998)  time: 0.3445  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [ 810/3750]  eta: 0:17:00  Lr: 0.001875  Loss: -1.0022  Acc@1: 75.0000 (80.5025)  Acc@5: 100.0000 (98.9057)  time: 0.3441  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [ 820/3750]  eta: 0:16:57  Lr: 0.001875  Loss: -0.8213  Acc@1: 81.2500 (80.4811)  Acc@5: 100.0000 (98.9038)  time: 0.3443  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [ 830/3750]  eta: 0:16:53  Lr: 0.001875  Loss: -0.7270  Acc@1: 81.2500 (80.5280)  Acc@5: 100.0000 (98.9094)  time: 0.3451  data: 0.0006  max mem: 2503
Train: Epoch[3/5]  [ 840/3750]  eta: 0:16:50  Lr: 0.001875  Loss: -0.5586  Acc@1: 81.2500 (80.4697)  Acc@5: 100.0000 (98.9076)  time: 0.3472  data: 0.0007  max mem: 2503
Train: Epoch[3/5]  [ 850/3750]  eta: 0:16:47  Lr: 0.001875  Loss: -0.6402  Acc@1: 81.2500 (80.4788)  Acc@5: 100.0000 (98.9204)  time: 0.3484  data: 0.0008  max mem: 2503
Train: Epoch[3/5]  [ 860/3750]  eta: 0:16:43  Lr: 0.001875  Loss: -0.5556  Acc@1: 81.2500 (80.4951)  Acc@5: 100.0000 (98.9184)  time: 0.3486  data: 0.0017  max mem: 2503
Train: Epoch[3/5]  [ 870/3750]  eta: 0:16:40  Lr: 0.001875  Loss: -0.6736  Acc@1: 81.2500 (80.4750)  Acc@5: 100.0000 (98.9165)  time: 0.3489  data: 0.0015  max mem: 2503
Train: Epoch[3/5]  [ 880/3750]  eta: 0:16:36  Lr: 0.001875  Loss: -0.3626  Acc@1: 81.2500 (80.4838)  Acc@5: 100.0000 (98.9288)  time: 0.3484  data: 0.0007  max mem: 2503
Train: Epoch[3/5]  [ 890/3750]  eta: 0:16:33  Lr: 0.001875  Loss: -0.6875  Acc@1: 81.2500 (80.4854)  Acc@5: 100.0000 (98.9338)  time: 0.3482  data: 0.0007  max mem: 2503
Train: Epoch[3/5]  [ 900/3750]  eta: 0:16:29  Lr: 0.001875  Loss: -0.6478  Acc@1: 75.0000 (80.4176)  Acc@5: 100.0000 (98.9317)  time: 0.3492  data: 0.0018  max mem: 2503
Train: Epoch[3/5]  [ 910/3750]  eta: 0:16:26  Lr: 0.001875  Loss: -0.7199  Acc@1: 75.0000 (80.4061)  Acc@5: 100.0000 (98.9366)  time: 0.3492  data: 0.0017  max mem: 2503
Train: Epoch[3/5]  [ 920/3750]  eta: 0:16:22  Lr: 0.001875  Loss: -0.5023  Acc@1: 81.2500 (80.4085)  Acc@5: 100.0000 (98.9278)  time: 0.3477  data: 0.0010  max mem: 2503
Train: Epoch[3/5]  [ 930/3750]  eta: 0:16:19  Lr: 0.001875  Loss: -0.8448  Acc@1: 75.0000 (80.3571)  Acc@5: 100.0000 (98.9057)  time: 0.3491  data: 0.0020  max mem: 2503
Train: Epoch[3/5]  [ 940/3750]  eta: 0:16:16  Lr: 0.001875  Loss: -0.3792  Acc@1: 81.2500 (80.4065)  Acc@5: 100.0000 (98.9174)  time: 0.3485  data: 0.0018  max mem: 2503
Train: Epoch[3/5]  [ 950/3750]  eta: 0:16:12  Lr: 0.001875  Loss: -1.0179  Acc@1: 87.5000 (80.4548)  Acc@5: 100.0000 (98.9222)  time: 0.3449  data: 0.0006  max mem: 2503
Train: Epoch[3/5]  [ 960/3750]  eta: 0:16:08  Lr: 0.001875  Loss: -0.8982  Acc@1: 87.5000 (80.5086)  Acc@5: 100.0000 (98.9269)  time: 0.3433  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [ 970/3750]  eta: 0:16:05  Lr: 0.001875  Loss: -0.7183  Acc@1: 87.5000 (80.4905)  Acc@5: 100.0000 (98.9315)  time: 0.3437  data: 0.0009  max mem: 2503
Train: Epoch[3/5]  [ 980/3750]  eta: 0:16:01  Lr: 0.001875  Loss: -0.7758  Acc@1: 75.0000 (80.4664)  Acc@5: 100.0000 (98.9297)  time: 0.3452  data: 0.0016  max mem: 2503
Train: Epoch[3/5]  [ 990/3750]  eta: 0:15:58  Lr: 0.001875  Loss: -0.5559  Acc@1: 75.0000 (80.4364)  Acc@5: 100.0000 (98.9279)  time: 0.3464  data: 0.0014  max mem: 2503
Train: Epoch[3/5]  [1000/3750]  eta: 0:15:54  Lr: 0.001875  Loss: -0.8070  Acc@1: 75.0000 (80.4258)  Acc@5: 100.0000 (98.9386)  time: 0.3476  data: 0.0009  max mem: 2503
Train: Epoch[3/5]  [1010/3750]  eta: 0:15:51  Lr: 0.001875  Loss: -0.2770  Acc@1: 81.2500 (80.4340)  Acc@5: 100.0000 (98.9305)  time: 0.3478  data: 0.0008  max mem: 2503
Train: Epoch[3/5]  [1020/3750]  eta: 0:15:48  Lr: 0.001875  Loss: -0.4077  Acc@1: 81.2500 (80.4481)  Acc@5: 100.0000 (98.9349)  time: 0.3478  data: 0.0009  max mem: 2503
Train: Epoch[3/5]  [1030/3750]  eta: 0:15:44  Lr: 0.001875  Loss: -0.6436  Acc@1: 81.2500 (80.4437)  Acc@5: 100.0000 (98.9452)  time: 0.3480  data: 0.0010  max mem: 2503
Train: Epoch[3/5]  [1040/3750]  eta: 0:15:41  Lr: 0.001875  Loss: -0.9424  Acc@1: 81.2500 (80.4935)  Acc@5: 100.0000 (98.9493)  time: 0.3502  data: 0.0011  max mem: 2503
Train: Epoch[3/5]  [1050/3750]  eta: 0:15:37  Lr: 0.001875  Loss: -0.7236  Acc@1: 81.2500 (80.4948)  Acc@5: 100.0000 (98.9593)  time: 0.3518  data: 0.0019  max mem: 2503
Train: Epoch[3/5]  [1060/3750]  eta: 0:15:34  Lr: 0.001875  Loss: -0.6752  Acc@1: 81.2500 (80.5254)  Acc@5: 100.0000 (98.9574)  time: 0.3496  data: 0.0018  max mem: 2503
Train: Epoch[3/5]  [1070/3750]  eta: 0:15:30  Lr: 0.001875  Loss: -0.8198  Acc@1: 87.5000 (80.5556)  Acc@5: 100.0000 (98.9671)  time: 0.3485  data: 0.0009  max mem: 2503
Train: Epoch[3/5]  [1080/3750]  eta: 0:15:27  Lr: 0.001875  Loss: -0.6958  Acc@1: 81.2500 (80.5562)  Acc@5: 100.0000 (98.9651)  time: 0.3484  data: 0.0007  max mem: 2503
Train: Epoch[3/5]  [1090/3750]  eta: 0:15:23  Lr: 0.001875  Loss: -0.5717  Acc@1: 81.2500 (80.5511)  Acc@5: 100.0000 (98.9402)  time: 0.3469  data: 0.0007  max mem: 2503
Train: Epoch[3/5]  [1100/3750]  eta: 0:15:20  Lr: 0.001875  Loss: -0.6571  Acc@1: 87.5000 (80.5915)  Acc@5: 100.0000 (98.9385)  time: 0.3465  data: 0.0006  max mem: 2503
Train: Epoch[3/5]  [1110/3750]  eta: 0:15:17  Lr: 0.001875  Loss: -0.5288  Acc@1: 81.2500 (80.5862)  Acc@5: 100.0000 (98.9368)  time: 0.3467  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [1120/3750]  eta: 0:15:13  Lr: 0.001875  Loss: -0.6046  Acc@1: 81.2500 (80.6088)  Acc@5: 100.0000 (98.9351)  time: 0.3458  data: 0.0009  max mem: 2503
Train: Epoch[3/5]  [1130/3750]  eta: 0:15:09  Lr: 0.001875  Loss: -0.7783  Acc@1: 81.2500 (80.6421)  Acc@5: 100.0000 (98.9390)  time: 0.3451  data: 0.0018  max mem: 2503
Train: Epoch[3/5]  [1140/3750]  eta: 0:15:06  Lr: 0.001875  Loss: -0.5618  Acc@1: 81.2500 (80.6694)  Acc@5: 100.0000 (98.9428)  time: 0.3453  data: 0.0019  max mem: 2503
Train: Epoch[3/5]  [1150/3750]  eta: 0:15:02  Lr: 0.001875  Loss: -0.4772  Acc@1: 81.2500 (80.6744)  Acc@5: 100.0000 (98.9357)  time: 0.3470  data: 0.0015  max mem: 2503
Train: Epoch[3/5]  [1160/3750]  eta: 0:14:59  Lr: 0.001875  Loss: -0.7369  Acc@1: 81.2500 (80.6417)  Acc@5: 100.0000 (98.9341)  time: 0.3483  data: 0.0011  max mem: 2503
Train: Epoch[3/5]  [1170/3750]  eta: 0:14:56  Lr: 0.001875  Loss: -0.7802  Acc@1: 75.0000 (80.5988)  Acc@5: 100.0000 (98.9325)  time: 0.3484  data: 0.0008  max mem: 2503
Train: Epoch[3/5]  [1180/3750]  eta: 0:14:52  Lr: 0.001875  Loss: -0.4777  Acc@1: 81.2500 (80.6202)  Acc@5: 100.0000 (98.9363)  time: 0.3482  data: 0.0008  max mem: 2503
Train: Epoch[3/5]  [1190/3750]  eta: 0:14:49  Lr: 0.001875  Loss: -0.8026  Acc@1: 81.2500 (80.6150)  Acc@5: 100.0000 (98.9347)  time: 0.3481  data: 0.0009  max mem: 2503
Train: Epoch[3/5]  [1200/3750]  eta: 0:14:45  Lr: 0.001875  Loss: -0.4639  Acc@1: 81.2500 (80.6255)  Acc@5: 100.0000 (98.9228)  time: 0.3484  data: 0.0011  max mem: 2503
Train: Epoch[3/5]  [1210/3750]  eta: 0:14:42  Lr: 0.001875  Loss: -0.7451  Acc@1: 81.2500 (80.6358)  Acc@5: 100.0000 (98.9317)  time: 0.3490  data: 0.0011  max mem: 2503
Train: Epoch[3/5]  [1220/3750]  eta: 0:14:38  Lr: 0.001875  Loss: -0.7143  Acc@1: 81.2500 (80.6613)  Acc@5: 100.0000 (98.9404)  time: 0.3496  data: 0.0014  max mem: 2503
Train: Epoch[3/5]  [1230/3750]  eta: 0:14:35  Lr: 0.001875  Loss: -0.6685  Acc@1: 87.5000 (80.6966)  Acc@5: 100.0000 (98.9389)  time: 0.3490  data: 0.0015  max mem: 2503
Train: Epoch[3/5]  [1240/3750]  eta: 0:14:31  Lr: 0.001875  Loss: -0.6685  Acc@1: 81.2500 (80.6658)  Acc@5: 100.0000 (98.9323)  time: 0.3487  data: 0.0020  max mem: 2503
Train: Epoch[3/5]  [1250/3750]  eta: 0:14:28  Lr: 0.001875  Loss: -0.5756  Acc@1: 75.0000 (80.6655)  Acc@5: 100.0000 (98.9309)  time: 0.3484  data: 0.0018  max mem: 2503
Train: Epoch[3/5]  [1260/3750]  eta: 0:14:25  Lr: 0.001875  Loss: -0.4511  Acc@1: 75.0000 (80.6701)  Acc@5: 100.0000 (98.9344)  time: 0.3467  data: 0.0006  max mem: 2503
Train: Epoch[3/5]  [1270/3750]  eta: 0:14:21  Lr: 0.001875  Loss: -0.5537  Acc@1: 81.2500 (80.6697)  Acc@5: 100.0000 (98.9329)  time: 0.3481  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [1280/3750]  eta: 0:14:18  Lr: 0.001875  Loss: -0.6107  Acc@1: 81.2500 (80.6401)  Acc@5: 100.0000 (98.9364)  time: 0.3465  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [1290/3750]  eta: 0:14:14  Lr: 0.001875  Loss: -0.2347  Acc@1: 75.0000 (80.6303)  Acc@5: 100.0000 (98.9398)  time: 0.3429  data: 0.0002  max mem: 2503
Train: Epoch[3/5]  [1300/3750]  eta: 0:14:10  Lr: 0.001875  Loss: -0.1090  Acc@1: 75.0000 (80.5822)  Acc@5: 100.0000 (98.9431)  time: 0.3434  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [1310/3750]  eta: 0:14:07  Lr: 0.001875  Loss: -0.9276  Acc@1: 81.2500 (80.6207)  Acc@5: 100.0000 (98.9416)  time: 0.3461  data: 0.0007  max mem: 2503
Train: Epoch[3/5]  [1320/3750]  eta: 0:14:04  Lr: 0.001875  Loss: -0.4899  Acc@1: 81.2500 (80.6302)  Acc@5: 100.0000 (98.9449)  time: 0.3483  data: 0.0008  max mem: 2503
Train: Epoch[3/5]  [1330/3750]  eta: 0:14:00  Lr: 0.001875  Loss: -0.8683  Acc@1: 87.5000 (80.6818)  Acc@5: 100.0000 (98.9435)  time: 0.3477  data: 0.0008  max mem: 2503
Train: Epoch[3/5]  [1340/3750]  eta: 0:13:57  Lr: 0.001875  Loss: -0.8312  Acc@1: 87.5000 (80.6954)  Acc@5: 100.0000 (98.9420)  time: 0.3470  data: 0.0007  max mem: 2503
Train: Epoch[3/5]  [1350/3750]  eta: 0:13:53  Lr: 0.001875  Loss: -0.6177  Acc@1: 81.2500 (80.6810)  Acc@5: 100.0000 (98.9499)  time: 0.3484  data: 0.0006  max mem: 2503
Train: Epoch[3/5]  [1360/3750]  eta: 0:13:50  Lr: 0.001875  Loss: -0.8262  Acc@1: 81.2500 (80.6714)  Acc@5: 100.0000 (98.9484)  time: 0.3501  data: 0.0009  max mem: 2503
Train: Epoch[3/5]  [1370/3750]  eta: 0:13:46  Lr: 0.001875  Loss: -0.9575  Acc@1: 81.2500 (80.7030)  Acc@5: 100.0000 (98.9561)  time: 0.3491  data: 0.0012  max mem: 2503
Train: Epoch[3/5]  [1380/3750]  eta: 0:13:43  Lr: 0.001875  Loss: -0.7647  Acc@1: 81.2500 (80.7069)  Acc@5: 100.0000 (98.9546)  time: 0.3479  data: 0.0011  max mem: 2503
Train: Epoch[3/5]  [1390/3750]  eta: 0:13:39  Lr: 0.001875  Loss: -0.2423  Acc@1: 81.2500 (80.6839)  Acc@5: 100.0000 (98.9576)  time: 0.3477  data: 0.0010  max mem: 2503
Train: Epoch[3/5]  [1400/3750]  eta: 0:13:36  Lr: 0.001875  Loss: -0.6997  Acc@1: 75.0000 (80.6522)  Acc@5: 100.0000 (98.9472)  time: 0.3503  data: 0.0012  max mem: 2503
Train: Epoch[3/5]  [1410/3750]  eta: 0:13:32  Lr: 0.001875  Loss: -0.7291  Acc@1: 81.2500 (80.6830)  Acc@5: 100.0000 (98.9546)  time: 0.3495  data: 0.0007  max mem: 2503
Train: Epoch[3/5]  [1420/3750]  eta: 0:13:29  Lr: 0.001875  Loss: -0.8199  Acc@1: 81.2500 (80.6738)  Acc@5: 100.0000 (98.9488)  time: 0.3473  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [1430/3750]  eta: 0:13:25  Lr: 0.001875  Loss: -0.6749  Acc@1: 75.0000 (80.6473)  Acc@5: 100.0000 (98.9474)  time: 0.3463  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [1440/3750]  eta: 0:13:22  Lr: 0.001875  Loss: -0.8910  Acc@1: 87.5000 (80.6862)  Acc@5: 100.0000 (98.9460)  time: 0.3453  data: 0.0017  max mem: 2503
Train: Epoch[3/5]  [1450/3750]  eta: 0:13:18  Lr: 0.001875  Loss: -0.4979  Acc@1: 81.2500 (80.6642)  Acc@5: 100.0000 (98.9533)  time: 0.3450  data: 0.0018  max mem: 2503
Train: Epoch[3/5]  [1460/3750]  eta: 0:13:15  Lr: 0.001875  Loss: -0.4791  Acc@1: 75.0000 (80.6468)  Acc@5: 100.0000 (98.9605)  time: 0.3451  data: 0.0006  max mem: 2503
Train: Epoch[3/5]  [1470/3750]  eta: 0:13:12  Lr: 0.001875  Loss: -0.2629  Acc@1: 81.2500 (80.6637)  Acc@5: 100.0000 (98.9548)  time: 0.3481  data: 0.0009  max mem: 2503
Train: Epoch[3/5]  [1480/3750]  eta: 0:13:08  Lr: 0.001875  Loss: -0.2505  Acc@1: 81.2500 (80.6507)  Acc@5: 100.0000 (98.9534)  time: 0.3479  data: 0.0009  max mem: 2503
Train: Epoch[3/5]  [1490/3750]  eta: 0:13:05  Lr: 0.001875  Loss: -0.4454  Acc@1: 75.0000 (80.6212)  Acc@5: 100.0000 (98.9604)  time: 0.3473  data: 0.0009  max mem: 2503
Train: Epoch[3/5]  [1500/3750]  eta: 0:13:01  Lr: 0.001875  Loss: -0.5889  Acc@1: 81.2500 (80.6546)  Acc@5: 100.0000 (98.9632)  time: 0.3477  data: 0.0008  max mem: 2503
Train: Epoch[3/5]  [1510/3750]  eta: 0:12:58  Lr: 0.001875  Loss: -0.6868  Acc@1: 81.2500 (80.6544)  Acc@5: 100.0000 (98.9618)  time: 0.3488  data: 0.0012  max mem: 2503
Train: Epoch[3/5]  [1520/3750]  eta: 0:12:54  Lr: 0.001875  Loss: -0.6170  Acc@1: 81.2500 (80.6172)  Acc@5: 100.0000 (98.9604)  time: 0.3509  data: 0.0016  max mem: 2503
Train: Epoch[3/5]  [1530/3750]  eta: 0:12:51  Lr: 0.001875  Loss: -0.8182  Acc@1: 75.0000 (80.6172)  Acc@5: 100.0000 (98.9672)  time: 0.3491  data: 0.0012  max mem: 2503
Train: Epoch[3/5]  [1540/3750]  eta: 0:12:47  Lr: 0.001875  Loss: -0.5957  Acc@1: 81.2500 (80.6173)  Acc@5: 100.0000 (98.9495)  time: 0.3472  data: 0.0016  max mem: 2503
Train: Epoch[3/5]  [1550/3750]  eta: 0:12:44  Lr: 0.001875  Loss: -0.6972  Acc@1: 81.2500 (80.6093)  Acc@5: 100.0000 (98.9442)  time: 0.3492  data: 0.0023  max mem: 2503
Train: Epoch[3/5]  [1560/3750]  eta: 0:12:40  Lr: 0.001875  Loss: -0.7595  Acc@1: 75.0000 (80.5734)  Acc@5: 100.0000 (98.9390)  time: 0.3497  data: 0.0014  max mem: 2503
Train: Epoch[3/5]  [1570/3750]  eta: 0:12:37  Lr: 0.001875  Loss: -0.3848  Acc@1: 75.0000 (80.5419)  Acc@5: 100.0000 (98.9378)  time: 0.3475  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [1580/3750]  eta: 0:12:33  Lr: 0.001875  Loss: -1.0452  Acc@1: 75.0000 (80.5503)  Acc@5: 100.0000 (98.9366)  time: 0.3467  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [1590/3750]  eta: 0:12:30  Lr: 0.001875  Loss: -0.6860  Acc@1: 81.2500 (80.5665)  Acc@5: 100.0000 (98.9354)  time: 0.3460  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [1600/3750]  eta: 0:12:26  Lr: 0.001875  Loss: -0.8966  Acc@1: 81.2500 (80.5629)  Acc@5: 100.0000 (98.9343)  time: 0.3456  data: 0.0010  max mem: 2503
Train: Epoch[3/5]  [1610/3750]  eta: 0:12:23  Lr: 0.001875  Loss: -0.9903  Acc@1: 81.2500 (80.5750)  Acc@5: 100.0000 (98.9409)  time: 0.3457  data: 0.0013  max mem: 2503
Train: Epoch[3/5]  [1620/3750]  eta: 0:12:19  Lr: 0.001875  Loss: -0.8197  Acc@1: 81.2500 (80.5753)  Acc@5: 100.0000 (98.9436)  time: 0.3459  data: 0.0006  max mem: 2503
Train: Epoch[3/5]  [1630/3750]  eta: 0:12:16  Lr: 0.001875  Loss: -0.7298  Acc@1: 81.2500 (80.5794)  Acc@5: 100.0000 (98.9385)  time: 0.3464  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [1640/3750]  eta: 0:12:12  Lr: 0.001875  Loss: -0.7492  Acc@1: 81.2500 (80.5987)  Acc@5: 100.0000 (98.9374)  time: 0.3472  data: 0.0006  max mem: 2503
Train: Epoch[3/5]  [1650/3750]  eta: 0:12:09  Lr: 0.001875  Loss: -0.7618  Acc@1: 81.2500 (80.6178)  Acc@5: 100.0000 (98.9363)  time: 0.3482  data: 0.0008  max mem: 2503
Train: Epoch[3/5]  [1660/3750]  eta: 0:12:06  Lr: 0.001875  Loss: -0.7994  Acc@1: 81.2500 (80.6291)  Acc@5: 100.0000 (98.9351)  time: 0.3479  data: 0.0008  max mem: 2503
Train: Epoch[3/5]  [1670/3750]  eta: 0:12:02  Lr: 0.001875  Loss: -0.7496  Acc@1: 81.2500 (80.6478)  Acc@5: 100.0000 (98.9340)  time: 0.3478  data: 0.0007  max mem: 2503
Train: Epoch[3/5]  [1680/3750]  eta: 0:11:59  Lr: 0.001875  Loss: -0.8240  Acc@1: 81.2500 (80.6477)  Acc@5: 100.0000 (98.9329)  time: 0.3490  data: 0.0014  max mem: 2503
Train: Epoch[3/5]  [1690/3750]  eta: 0:11:55  Lr: 0.001875  Loss: -0.6313  Acc@1: 81.2500 (80.6328)  Acc@5: 100.0000 (98.9318)  time: 0.3494  data: 0.0023  max mem: 2503
Train: Epoch[3/5]  [1700/3750]  eta: 0:11:52  Lr: 0.001875  Loss: -0.8055  Acc@1: 81.2500 (80.6401)  Acc@5: 100.0000 (98.9381)  time: 0.3484  data: 0.0017  max mem: 2503
Train: Epoch[3/5]  [1710/3750]  eta: 0:11:48  Lr: 0.001875  Loss: -1.0072  Acc@1: 81.2500 (80.6509)  Acc@5: 100.0000 (98.9334)  time: 0.3499  data: 0.0016  max mem: 2503
Train: Epoch[3/5]  [1720/3750]  eta: 0:11:45  Lr: 0.001875  Loss: -0.3220  Acc@1: 81.2500 (80.6689)  Acc@5: 100.0000 (98.9396)  time: 0.3487  data: 0.0014  max mem: 2503
Train: Epoch[3/5]  [1730/3750]  eta: 0:11:41  Lr: 0.001875  Loss: -0.8119  Acc@1: 87.5000 (80.6831)  Acc@5: 100.0000 (98.9421)  time: 0.3468  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [1740/3750]  eta: 0:11:38  Lr: 0.001875  Loss: -0.7625  Acc@1: 81.2500 (80.6936)  Acc@5: 100.0000 (98.9482)  time: 0.3458  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [1750/3750]  eta: 0:11:34  Lr: 0.001875  Loss: -0.5677  Acc@1: 81.2500 (80.6825)  Acc@5: 100.0000 (98.9542)  time: 0.3437  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [1760/3750]  eta: 0:11:31  Lr: 0.001875  Loss: -0.5423  Acc@1: 81.2500 (80.6999)  Acc@5: 100.0000 (98.9566)  time: 0.3442  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [1770/3750]  eta: 0:11:27  Lr: 0.001875  Loss: -0.9442  Acc@1: 81.2500 (80.7277)  Acc@5: 100.0000 (98.9589)  time: 0.3467  data: 0.0010  max mem: 2503
Train: Epoch[3/5]  [1780/3750]  eta: 0:11:24  Lr: 0.001875  Loss: -0.9913  Acc@1: 81.2500 (80.7201)  Acc@5: 100.0000 (98.9613)  time: 0.3481  data: 0.0010  max mem: 2503
Train: Epoch[3/5]  [1790/3750]  eta: 0:11:20  Lr: 0.001875  Loss: -0.6709  Acc@1: 81.2500 (80.7370)  Acc@5: 100.0000 (98.9671)  time: 0.3472  data: 0.0006  max mem: 2503
Train: Epoch[3/5]  [1800/3750]  eta: 0:11:17  Lr: 0.001875  Loss: -0.6158  Acc@1: 81.2500 (80.7537)  Acc@5: 100.0000 (98.9624)  time: 0.3480  data: 0.0014  max mem: 2503
Train: Epoch[3/5]  [1810/3750]  eta: 0:11:13  Lr: 0.001875  Loss: -0.7324  Acc@1: 81.2500 (80.7668)  Acc@5: 100.0000 (98.9681)  time: 0.3485  data: 0.0016  max mem: 2503
Train: Epoch[3/5]  [1820/3750]  eta: 0:11:10  Lr: 0.001875  Loss: -0.8639  Acc@1: 81.2500 (80.7523)  Acc@5: 100.0000 (98.9703)  time: 0.3491  data: 0.0010  max mem: 2503
Train: Epoch[3/5]  [1830/3750]  eta: 0:11:07  Lr: 0.001875  Loss: -1.0068  Acc@1: 81.2500 (80.7585)  Acc@5: 100.0000 (98.9657)  time: 0.3497  data: 0.0015  max mem: 2503
Train: Epoch[3/5]  [1840/3750]  eta: 0:11:03  Lr: 0.001875  Loss: -0.5188  Acc@1: 81.2500 (80.7476)  Acc@5: 100.0000 (98.9578)  time: 0.3489  data: 0.0014  max mem: 2503
Train: Epoch[3/5]  [1850/3750]  eta: 0:11:00  Lr: 0.001875  Loss: -0.6442  Acc@1: 81.2500 (80.7300)  Acc@5: 100.0000 (98.9566)  time: 0.3482  data: 0.0008  max mem: 2503
Train: Epoch[3/5]  [1860/3750]  eta: 0:10:56  Lr: 0.001875  Loss: -0.9456  Acc@1: 75.0000 (80.6992)  Acc@5: 100.0000 (98.9555)  time: 0.3486  data: 0.0007  max mem: 2503
Train: Epoch[3/5]  [1870/3750]  eta: 0:10:53  Lr: 0.001875  Loss: -0.3495  Acc@1: 75.0000 (80.6888)  Acc@5: 100.0000 (98.9544)  time: 0.3482  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [1880/3750]  eta: 0:10:49  Lr: 0.001875  Loss: -0.1492  Acc@1: 81.2500 (80.6719)  Acc@5: 100.0000 (98.9467)  time: 0.3466  data: 0.0006  max mem: 2503
Train: Epoch[3/5]  [1890/3750]  eta: 0:10:46  Lr: 0.001875  Loss: -0.7568  Acc@1: 81.2500 (80.6683)  Acc@5: 100.0000 (98.9523)  time: 0.3477  data: 0.0006  max mem: 2503
Train: Epoch[3/5]  [1900/3750]  eta: 0:10:42  Lr: 0.001875  Loss: -0.8986  Acc@1: 81.2500 (80.6681)  Acc@5: 100.0000 (98.9446)  time: 0.3465  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [1910/3750]  eta: 0:10:39  Lr: 0.001875  Loss: -0.2951  Acc@1: 81.2500 (80.6580)  Acc@5: 100.0000 (98.9469)  time: 0.3436  data: 0.0006  max mem: 2503
Train: Epoch[3/5]  [1920/3750]  eta: 0:10:35  Lr: 0.001875  Loss: -0.1950  Acc@1: 81.2500 (80.6546)  Acc@5: 100.0000 (98.9459)  time: 0.3435  data: 0.0006  max mem: 2503
Train: Epoch[3/5]  [1930/3750]  eta: 0:10:32  Lr: 0.001875  Loss: -0.6929  Acc@1: 81.2500 (80.6350)  Acc@5: 100.0000 (98.9416)  time: 0.3449  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [1940/3750]  eta: 0:10:28  Lr: 0.001875  Loss: -0.3628  Acc@1: 81.2500 (80.6285)  Acc@5: 100.0000 (98.9438)  time: 0.3475  data: 0.0007  max mem: 2503
Train: Epoch[3/5]  [1950/3750]  eta: 0:10:25  Lr: 0.001875  Loss: -0.7141  Acc@1: 81.2500 (80.6285)  Acc@5: 100.0000 (98.9364)  time: 0.3496  data: 0.0006  max mem: 2503
Train: Epoch[3/5]  [1960/3750]  eta: 0:10:21  Lr: 0.001875  Loss: -0.7918  Acc@1: 75.0000 (80.6126)  Acc@5: 100.0000 (98.9419)  time: 0.3492  data: 0.0007  max mem: 2503
Train: Epoch[3/5]  [1970/3750]  eta: 0:10:18  Lr: 0.001875  Loss: -0.9999  Acc@1: 81.2500 (80.6253)  Acc@5: 100.0000 (98.9409)  time: 0.3481  data: 0.0011  max mem: 2503
Train: Epoch[3/5]  [1980/3750]  eta: 0:10:14  Lr: 0.001875  Loss: -0.4158  Acc@1: 81.2500 (80.6379)  Acc@5: 100.0000 (98.9368)  time: 0.3494  data: 0.0015  max mem: 2503
Train: Epoch[3/5]  [1990/3750]  eta: 0:10:11  Lr: 0.001875  Loss: -0.7914  Acc@1: 81.2500 (80.6410)  Acc@5: 100.0000 (98.9358)  time: 0.3494  data: 0.0012  max mem: 2503
Train: Epoch[3/5]  [2000/3750]  eta: 0:10:08  Lr: 0.001875  Loss: -0.5608  Acc@1: 87.5000 (80.6253)  Acc@5: 100.0000 (98.9412)  time: 0.3480  data: 0.0008  max mem: 2503
Train: Epoch[3/5]  [2010/3750]  eta: 0:10:04  Lr: 0.001875  Loss: -0.6686  Acc@1: 87.5000 (80.6471)  Acc@5: 100.0000 (98.9433)  time: 0.3489  data: 0.0019  max mem: 2503
Train: Epoch[3/5]  [2020/3750]  eta: 0:10:01  Lr: 0.001875  Loss: -0.3787  Acc@1: 81.2500 (80.6346)  Acc@5: 100.0000 (98.9393)  time: 0.3494  data: 0.0020  max mem: 2503
Train: Epoch[3/5]  [2030/3750]  eta: 0:09:57  Lr: 0.001875  Loss: -0.7886  Acc@1: 75.0000 (80.6038)  Acc@5: 100.0000 (98.9414)  time: 0.3483  data: 0.0008  max mem: 2503
Train: Epoch[3/5]  [2040/3750]  eta: 0:09:54  Lr: 0.001875  Loss: -0.8554  Acc@1: 75.0000 (80.6039)  Acc@5: 100.0000 (98.9374)  time: 0.3492  data: 0.0007  max mem: 2503
Train: Epoch[3/5]  [2050/3750]  eta: 0:09:50  Lr: 0.001875  Loss: -0.6544  Acc@1: 81.2500 (80.6131)  Acc@5: 100.0000 (98.9304)  time: 0.3482  data: 0.0008  max mem: 2503
Train: Epoch[3/5]  [2060/3750]  eta: 0:09:47  Lr: 0.001875  Loss: -0.6382  Acc@1: 81.2500 (80.6162)  Acc@5: 100.0000 (98.9265)  time: 0.3446  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [2070/3750]  eta: 0:09:43  Lr: 0.001875  Loss: -0.5316  Acc@1: 81.2500 (80.6162)  Acc@5: 100.0000 (98.9256)  time: 0.3444  data: 0.0011  max mem: 2503
Train: Epoch[3/5]  [2080/3750]  eta: 0:09:40  Lr: 0.001875  Loss: -1.0194  Acc@1: 81.2500 (80.6313)  Acc@5: 100.0000 (98.9278)  time: 0.3453  data: 0.0011  max mem: 2503
Train: Epoch[3/5]  [2090/3750]  eta: 0:09:36  Lr: 0.001875  Loss: -0.6329  Acc@1: 81.2500 (80.6552)  Acc@5: 100.0000 (98.9269)  time: 0.3465  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [2100/3750]  eta: 0:09:33  Lr: 0.001875  Loss: -0.7752  Acc@1: 81.2500 (80.6521)  Acc@5: 100.0000 (98.9291)  time: 0.3474  data: 0.0006  max mem: 2503
Train: Epoch[3/5]  [2110/3750]  eta: 0:09:29  Lr: 0.001875  Loss: -0.6903  Acc@1: 81.2500 (80.6490)  Acc@5: 100.0000 (98.9253)  time: 0.3483  data: 0.0006  max mem: 2503
Train: Epoch[3/5]  [2120/3750]  eta: 0:09:26  Lr: 0.001875  Loss: -0.7296  Acc@1: 81.2500 (80.6548)  Acc@5: 100.0000 (98.9274)  time: 0.3485  data: 0.0009  max mem: 2503
Train: Epoch[3/5]  [2130/3750]  eta: 0:09:22  Lr: 0.001875  Loss: -0.5645  Acc@1: 81.2500 (80.6840)  Acc@5: 100.0000 (98.9324)  time: 0.3469  data: 0.0009  max mem: 2503
Train: Epoch[3/5]  [2140/3750]  eta: 0:09:19  Lr: 0.001875  Loss: -0.8006  Acc@1: 81.2500 (80.6924)  Acc@5: 100.0000 (98.9287)  time: 0.3485  data: 0.0009  max mem: 2503
Train: Epoch[3/5]  [2150/3750]  eta: 0:09:15  Lr: 0.001875  Loss: -0.7899  Acc@1: 81.2500 (80.6892)  Acc@5: 100.0000 (98.9162)  time: 0.3504  data: 0.0014  max mem: 2503
Train: Epoch[3/5]  [2160/3750]  eta: 0:09:12  Lr: 0.001875  Loss: -0.9444  Acc@1: 81.2500 (80.6976)  Acc@5: 100.0000 (98.9154)  time: 0.3499  data: 0.0016  max mem: 2503
Train: Epoch[3/5]  [2170/3750]  eta: 0:09:09  Lr: 0.001875  Loss: -0.5655  Acc@1: 81.2500 (80.6944)  Acc@5: 100.0000 (98.9118)  time: 0.3490  data: 0.0014  max mem: 2503
Train: Epoch[3/5]  [2180/3750]  eta: 0:09:05  Lr: 0.001875  Loss: -0.5355  Acc@1: 81.2500 (80.6769)  Acc@5: 100.0000 (98.9082)  time: 0.3494  data: 0.0011  max mem: 2503
Train: Epoch[3/5]  [2190/3750]  eta: 0:09:02  Lr: 0.001875  Loss: -0.9934  Acc@1: 81.2500 (80.6909)  Acc@5: 100.0000 (98.9103)  time: 0.3483  data: 0.0011  max mem: 2503
Train: Epoch[3/5]  [2200/3750]  eta: 0:08:58  Lr: 0.001875  Loss: -0.9654  Acc@1: 81.2500 (80.6991)  Acc@5: 100.0000 (98.9124)  time: 0.3479  data: 0.0010  max mem: 2503
Train: Epoch[3/5]  [2210/3750]  eta: 0:08:55  Lr: 0.001875  Loss: -0.6899  Acc@1: 81.2500 (80.6846)  Acc@5: 100.0000 (98.9060)  time: 0.3477  data: 0.0006  max mem: 2503
Train: Epoch[3/5]  [2220/3750]  eta: 0:08:51  Lr: 0.001875  Loss: -0.5704  Acc@1: 81.2500 (80.6759)  Acc@5: 100.0000 (98.9053)  time: 0.3463  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [2230/3750]  eta: 0:08:48  Lr: 0.001875  Loss: -0.6426  Acc@1: 75.0000 (80.6617)  Acc@5: 100.0000 (98.9102)  time: 0.3446  data: 0.0002  max mem: 2503
Train: Epoch[3/5]  [2240/3750]  eta: 0:08:44  Lr: 0.001875  Loss: -0.5754  Acc@1: 75.0000 (80.6560)  Acc@5: 100.0000 (98.9123)  time: 0.3445  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [2250/3750]  eta: 0:08:41  Lr: 0.001875  Loss: -0.2381  Acc@1: 75.0000 (80.6364)  Acc@5: 100.0000 (98.9116)  time: 0.3450  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [2260/3750]  eta: 0:08:37  Lr: 0.001875  Loss: -0.4137  Acc@1: 75.0000 (80.6225)  Acc@5: 100.0000 (98.9136)  time: 0.3450  data: 0.0006  max mem: 2503
Train: Epoch[3/5]  [2270/3750]  eta: 0:08:34  Lr: 0.001875  Loss: -0.8761  Acc@1: 81.2500 (80.6335)  Acc@5: 100.0000 (98.9157)  time: 0.3470  data: 0.0012  max mem: 2503
Train: Epoch[3/5]  [2280/3750]  eta: 0:08:30  Lr: 0.001875  Loss: -0.5076  Acc@1: 81.2500 (80.6116)  Acc@5: 100.0000 (98.9122)  time: 0.3478  data: 0.0016  max mem: 2503
Train: Epoch[3/5]  [2290/3750]  eta: 0:08:27  Lr: 0.001875  Loss: -0.5278  Acc@1: 81.2500 (80.6171)  Acc@5: 100.0000 (98.9142)  time: 0.3480  data: 0.0016  max mem: 2503
Train: Epoch[3/5]  [2300/3750]  eta: 0:08:23  Lr: 0.001875  Loss: -0.8948  Acc@1: 81.2500 (80.6253)  Acc@5: 100.0000 (98.9081)  time: 0.3487  data: 0.0014  max mem: 2503
Train: Epoch[3/5]  [2310/3750]  eta: 0:08:20  Lr: 0.001875  Loss: -0.9637  Acc@1: 81.2500 (80.6199)  Acc@5: 100.0000 (98.9101)  time: 0.3496  data: 0.0010  max mem: 2503
Train: Epoch[3/5]  [2320/3750]  eta: 0:08:16  Lr: 0.001875  Loss: -0.7342  Acc@1: 81.2500 (80.6307)  Acc@5: 100.0000 (98.9094)  time: 0.3504  data: 0.0017  max mem: 2503
Train: Epoch[3/5]  [2330/3750]  eta: 0:08:13  Lr: 0.001875  Loss: -0.3779  Acc@1: 81.2500 (80.6306)  Acc@5: 100.0000 (98.9141)  time: 0.3492  data: 0.0016  max mem: 2503
Train: Epoch[3/5]  [2340/3750]  eta: 0:08:09  Lr: 0.001875  Loss: -0.8417  Acc@1: 81.2500 (80.6386)  Acc@5: 100.0000 (98.9187)  time: 0.3481  data: 0.0011  max mem: 2503
Train: Epoch[3/5]  [2350/3750]  eta: 0:08:06  Lr: 0.001875  Loss: -0.1764  Acc@1: 81.2500 (80.6332)  Acc@5: 100.0000 (98.9154)  time: 0.3476  data: 0.0010  max mem: 2503
Train: Epoch[3/5]  [2360/3750]  eta: 0:08:03  Lr: 0.001875  Loss: -0.4582  Acc@1: 81.2500 (80.6438)  Acc@5: 100.0000 (98.9147)  time: 0.3495  data: 0.0010  max mem: 2503
Train: Epoch[3/5]  [2370/3750]  eta: 0:07:59  Lr: 0.001875  Loss: -0.5356  Acc@1: 81.2500 (80.6305)  Acc@5: 100.0000 (98.9140)  time: 0.3489  data: 0.0010  max mem: 2503
Train: Epoch[3/5]  [2380/3750]  eta: 0:07:56  Lr: 0.001875  Loss: -0.4737  Acc@1: 75.0000 (80.6226)  Acc@5: 100.0000 (98.9159)  time: 0.3455  data: 0.0006  max mem: 2503
Train: Epoch[3/5]  [2390/3750]  eta: 0:07:52  Lr: 0.001875  Loss: -0.7780  Acc@1: 81.2500 (80.6148)  Acc@5: 100.0000 (98.9126)  time: 0.3448  data: 0.0010  max mem: 2503
Train: Epoch[3/5]  [2400/3750]  eta: 0:07:49  Lr: 0.001875  Loss: -0.8517  Acc@1: 81.2500 (80.6227)  Acc@5: 100.0000 (98.9145)  time: 0.3447  data: 0.0009  max mem: 2503
Train: Epoch[3/5]  [2410/3750]  eta: 0:07:45  Lr: 0.001875  Loss: -0.2940  Acc@1: 81.2500 (80.5864)  Acc@5: 100.0000 (98.9009)  time: 0.3452  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [2420/3750]  eta: 0:07:42  Lr: 0.001875  Loss: -0.8305  Acc@1: 81.2500 (80.5969)  Acc@5: 100.0000 (98.9028)  time: 0.3481  data: 0.0007  max mem: 2503
Train: Epoch[3/5]  [2430/3750]  eta: 0:07:38  Lr: 0.001875  Loss: -0.8746  Acc@1: 81.2500 (80.5995)  Acc@5: 100.0000 (98.9022)  time: 0.3493  data: 0.0008  max mem: 2503
Train: Epoch[3/5]  [2440/3750]  eta: 0:07:35  Lr: 0.001875  Loss: -0.8015  Acc@1: 75.0000 (80.5894)  Acc@5: 100.0000 (98.9041)  time: 0.3482  data: 0.0009  max mem: 2503
Train: Epoch[3/5]  [2450/3750]  eta: 0:07:31  Lr: 0.001875  Loss: -0.6033  Acc@1: 75.0000 (80.5768)  Acc@5: 100.0000 (98.8933)  time: 0.3478  data: 0.0009  max mem: 2503
Train: Epoch[3/5]  [2460/3750]  eta: 0:07:28  Lr: 0.001875  Loss: -0.8474  Acc@1: 81.2500 (80.5922)  Acc@5: 100.0000 (98.8978)  time: 0.3472  data: 0.0011  max mem: 2503
Train: Epoch[3/5]  [2470/3750]  eta: 0:07:24  Lr: 0.001875  Loss: -0.9687  Acc@1: 81.2500 (80.5823)  Acc@5: 100.0000 (98.8972)  time: 0.3466  data: 0.0009  max mem: 2503
Train: Epoch[3/5]  [2480/3750]  eta: 0:07:21  Lr: 0.001875  Loss: -0.6226  Acc@1: 81.2500 (80.5900)  Acc@5: 100.0000 (98.8966)  time: 0.3468  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [2490/3750]  eta: 0:07:17  Lr: 0.001875  Loss: -0.3722  Acc@1: 81.2500 (80.6052)  Acc@5: 100.0000 (98.8960)  time: 0.3483  data: 0.0014  max mem: 2503
Train: Epoch[3/5]  [2500/3750]  eta: 0:07:14  Lr: 0.001875  Loss: -0.7661  Acc@1: 81.2500 (80.5878)  Acc@5: 100.0000 (98.8979)  time: 0.3483  data: 0.0016  max mem: 2503
Train: Epoch[3/5]  [2510/3750]  eta: 0:07:10  Lr: 0.001875  Loss: -0.8122  Acc@1: 81.2500 (80.6178)  Acc@5: 100.0000 (98.8998)  time: 0.3472  data: 0.0007  max mem: 2503
Train: Epoch[3/5]  [2520/3750]  eta: 0:07:07  Lr: 0.001875  Loss: -0.7674  Acc@1: 81.2500 (80.6203)  Acc@5: 100.0000 (98.9042)  time: 0.3467  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [2530/3750]  eta: 0:07:03  Lr: 0.001875  Loss: -0.6273  Acc@1: 81.2500 (80.6228)  Acc@5: 100.0000 (98.8987)  time: 0.3468  data: 0.0006  max mem: 2503
Train: Epoch[3/5]  [2540/3750]  eta: 0:07:00  Lr: 0.001875  Loss: -0.8770  Acc@1: 81.2500 (80.6203)  Acc@5: 100.0000 (98.8981)  time: 0.3459  data: 0.0006  max mem: 2503
Train: Epoch[3/5]  [2550/3750]  eta: 0:06:56  Lr: 0.001875  Loss: -1.0216  Acc@1: 81.2500 (80.6277)  Acc@5: 100.0000 (98.9024)  time: 0.3436  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [2560/3750]  eta: 0:06:53  Lr: 0.001875  Loss: -0.5070  Acc@1: 81.2500 (80.6521)  Acc@5: 100.0000 (98.9018)  time: 0.3430  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [2570/3750]  eta: 0:06:49  Lr: 0.001875  Loss: -0.8739  Acc@1: 81.2500 (80.6714)  Acc@5: 100.0000 (98.9036)  time: 0.3440  data: 0.0007  max mem: 2503
Train: Epoch[3/5]  [2580/3750]  eta: 0:06:46  Lr: 0.001875  Loss: -0.8258  Acc@1: 81.2500 (80.6664)  Acc@5: 100.0000 (98.9055)  time: 0.3459  data: 0.0010  max mem: 2503
Train: Epoch[3/5]  [2590/3750]  eta: 0:06:42  Lr: 0.001875  Loss: -0.8174  Acc@1: 81.2500 (80.6662)  Acc@5: 100.0000 (98.9049)  time: 0.3482  data: 0.0022  max mem: 2503
Train: Epoch[3/5]  [2600/3750]  eta: 0:06:39  Lr: 0.001875  Loss: -0.1813  Acc@1: 81.2500 (80.6661)  Acc@5: 100.0000 (98.9091)  time: 0.3484  data: 0.0021  max mem: 2503
Train: Epoch[3/5]  [2610/3750]  eta: 0:06:36  Lr: 0.001875  Loss: -0.2958  Acc@1: 81.2500 (80.6899)  Acc@5: 100.0000 (98.9085)  time: 0.3471  data: 0.0009  max mem: 2503
Train: Epoch[3/5]  [2620/3750]  eta: 0:06:32  Lr: 0.001875  Loss: -0.3256  Acc@1: 81.2500 (80.6777)  Acc@5: 100.0000 (98.9031)  time: 0.3478  data: 0.0017  max mem: 2503
Train: Epoch[3/5]  [2630/3750]  eta: 0:06:29  Lr: 0.001875  Loss: -0.8142  Acc@1: 75.0000 (80.6846)  Acc@5: 100.0000 (98.9001)  time: 0.3505  data: 0.0015  max mem: 2503
Train: Epoch[3/5]  [2640/3750]  eta: 0:06:25  Lr: 0.001875  Loss: -0.3639  Acc@1: 81.2500 (80.6678)  Acc@5: 100.0000 (98.9019)  time: 0.3498  data: 0.0007  max mem: 2503
Train: Epoch[3/5]  [2650/3750]  eta: 0:06:22  Lr: 0.001875  Loss: -0.8228  Acc@1: 75.0000 (80.6441)  Acc@5: 100.0000 (98.9037)  time: 0.3480  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [2660/3750]  eta: 0:06:18  Lr: 0.001875  Loss: -0.7708  Acc@1: 75.0000 (80.6323)  Acc@5: 100.0000 (98.9055)  time: 0.3488  data: 0.0008  max mem: 2503
Train: Epoch[3/5]  [2670/3750]  eta: 0:06:15  Lr: 0.001875  Loss: -0.8565  Acc@1: 75.0000 (80.6089)  Acc@5: 100.0000 (98.9072)  time: 0.3494  data: 0.0016  max mem: 2503
Train: Epoch[3/5]  [2680/3750]  eta: 0:06:11  Lr: 0.001875  Loss: -0.9083  Acc@1: 75.0000 (80.6112)  Acc@5: 100.0000 (98.9090)  time: 0.3491  data: 0.0013  max mem: 2503
Train: Epoch[3/5]  [2690/3750]  eta: 0:06:08  Lr: 0.001875  Loss: -0.5583  Acc@1: 81.2500 (80.6136)  Acc@5: 100.0000 (98.9014)  time: 0.3476  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [2700/3750]  eta: 0:06:04  Lr: 0.001875  Loss: -0.4568  Acc@1: 81.2500 (80.5975)  Acc@5: 100.0000 (98.9032)  time: 0.3482  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [2710/3750]  eta: 0:06:01  Lr: 0.001875  Loss: -0.8650  Acc@1: 75.0000 (80.5953)  Acc@5: 100.0000 (98.8980)  time: 0.3464  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [2720/3750]  eta: 0:05:57  Lr: 0.001875  Loss: -0.7123  Acc@1: 75.0000 (80.5793)  Acc@5: 100.0000 (98.8975)  time: 0.3432  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [2730/3750]  eta: 0:05:54  Lr: 0.001875  Loss: -0.7147  Acc@1: 81.2500 (80.5932)  Acc@5: 100.0000 (98.9015)  time: 0.3439  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [2740/3750]  eta: 0:05:50  Lr: 0.001875  Loss: -0.7303  Acc@1: 81.2500 (80.6024)  Acc@5: 100.0000 (98.9009)  time: 0.3458  data: 0.0007  max mem: 2503
Train: Epoch[3/5]  [2750/3750]  eta: 0:05:47  Lr: 0.001875  Loss: -0.4520  Acc@1: 81.2500 (80.6002)  Acc@5: 100.0000 (98.9027)  time: 0.3467  data: 0.0007  max mem: 2503
Train: Epoch[3/5]  [2760/3750]  eta: 0:05:43  Lr: 0.001875  Loss: -0.8050  Acc@1: 81.2500 (80.6094)  Acc@5: 100.0000 (98.9066)  time: 0.3463  data: 0.0009  max mem: 2503
Train: Epoch[3/5]  [2770/3750]  eta: 0:05:40  Lr: 0.001875  Loss: -0.5374  Acc@1: 81.2500 (80.6207)  Acc@5: 100.0000 (98.9083)  time: 0.3458  data: 0.0009  max mem: 2503
Train: Epoch[3/5]  [2780/3750]  eta: 0:05:36  Lr: 0.001875  Loss: -0.8216  Acc@1: 81.2500 (80.6252)  Acc@5: 100.0000 (98.9033)  time: 0.3464  data: 0.0006  max mem: 2503
Train: Epoch[3/5]  [2790/3750]  eta: 0:05:33  Lr: 0.001875  Loss: -0.6352  Acc@1: 81.2500 (80.6342)  Acc@5: 100.0000 (98.8960)  time: 0.3471  data: 0.0008  max mem: 2503
Train: Epoch[3/5]  [2800/3750]  eta: 0:05:30  Lr: 0.001875  Loss: -0.7908  Acc@1: 81.2500 (80.6364)  Acc@5: 100.0000 (98.8977)  time: 0.3483  data: 0.0009  max mem: 2503
Train: Epoch[3/5]  [2810/3750]  eta: 0:05:26  Lr: 0.001875  Loss: -0.6986  Acc@1: 81.2500 (80.6319)  Acc@5: 100.0000 (98.8972)  time: 0.3512  data: 0.0012  max mem: 2503
Train: Epoch[3/5]  [2820/3750]  eta: 0:05:23  Lr: 0.001875  Loss: -0.6524  Acc@1: 81.2500 (80.6363)  Acc@5: 100.0000 (98.8989)  time: 0.3509  data: 0.0013  max mem: 2503
Train: Epoch[3/5]  [2830/3750]  eta: 0:05:19  Lr: 0.001875  Loss: -0.4497  Acc@1: 81.2500 (80.6451)  Acc@5: 100.0000 (98.8984)  time: 0.3481  data: 0.0008  max mem: 2503
Train: Epoch[3/5]  [2840/3750]  eta: 0:05:16  Lr: 0.001875  Loss: -0.9818  Acc@1: 81.2500 (80.6450)  Acc@5: 100.0000 (98.8978)  time: 0.3488  data: 0.0013  max mem: 2503
Train: Epoch[3/5]  [2850/3750]  eta: 0:05:12  Lr: 0.001875  Loss: -0.7333  Acc@1: 81.2500 (80.6449)  Acc@5: 100.0000 (98.8995)  time: 0.3488  data: 0.0013  max mem: 2503
Train: Epoch[3/5]  [2860/3750]  eta: 0:05:09  Lr: 0.001875  Loss: -0.6871  Acc@1: 81.2500 (80.6580)  Acc@5: 100.0000 (98.9012)  time: 0.3469  data: 0.0007  max mem: 2503
Train: Epoch[3/5]  [2870/3750]  eta: 0:05:05  Lr: 0.001875  Loss: -0.3956  Acc@1: 81.2500 (80.6688)  Acc@5: 100.0000 (98.9028)  time: 0.3464  data: 0.0006  max mem: 2503
Train: Epoch[3/5]  [2880/3750]  eta: 0:05:02  Lr: 0.001875  Loss: -0.6145  Acc@1: 81.2500 (80.6838)  Acc@5: 100.0000 (98.9066)  time: 0.3457  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [2890/3750]  eta: 0:04:58  Lr: 0.001875  Loss: -1.0024  Acc@1: 81.2500 (80.6987)  Acc@5: 100.0000 (98.9082)  time: 0.3446  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [2900/3750]  eta: 0:04:55  Lr: 0.001875  Loss: -0.6898  Acc@1: 81.2500 (80.6942)  Acc@5: 100.0000 (98.9077)  time: 0.3443  data: 0.0007  max mem: 2503
Train: Epoch[3/5]  [2910/3750]  eta: 0:04:51  Lr: 0.001875  Loss: -0.6842  Acc@1: 81.2500 (80.6875)  Acc@5: 100.0000 (98.9072)  time: 0.3482  data: 0.0017  max mem: 2503
Train: Epoch[3/5]  [2920/3750]  eta: 0:04:48  Lr: 0.001875  Loss: -0.9478  Acc@1: 81.2500 (80.7044)  Acc@5: 100.0000 (98.9045)  time: 0.3503  data: 0.0013  max mem: 2503
Train: Epoch[3/5]  [2930/3750]  eta: 0:04:44  Lr: 0.001875  Loss: -0.8510  Acc@1: 81.2500 (80.7020)  Acc@5: 100.0000 (98.9040)  time: 0.3488  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [2940/3750]  eta: 0:04:41  Lr: 0.001875  Loss: -0.2866  Acc@1: 81.2500 (80.6890)  Acc@5: 100.0000 (98.9056)  time: 0.3485  data: 0.0009  max mem: 2503
Train: Epoch[3/5]  [2950/3750]  eta: 0:04:37  Lr: 0.001875  Loss: -0.5884  Acc@1: 75.0000 (80.6909)  Acc@5: 100.0000 (98.9029)  time: 0.3480  data: 0.0010  max mem: 2503
Train: Epoch[3/5]  [2960/3750]  eta: 0:04:34  Lr: 0.001875  Loss: -0.6034  Acc@1: 81.2500 (80.6738)  Acc@5: 100.0000 (98.9066)  time: 0.3493  data: 0.0008  max mem: 2503
Train: Epoch[3/5]  [2970/3750]  eta: 0:04:31  Lr: 0.001875  Loss: -0.1655  Acc@1: 75.0000 (80.6484)  Acc@5: 100.0000 (98.9019)  time: 0.3496  data: 0.0009  max mem: 2503
Train: Epoch[3/5]  [2980/3750]  eta: 0:04:27  Lr: 0.001875  Loss: -0.9777  Acc@1: 87.5000 (80.6818)  Acc@5: 100.0000 (98.9056)  time: 0.3486  data: 0.0016  max mem: 2503
Train: Epoch[3/5]  [2990/3750]  eta: 0:04:24  Lr: 0.001875  Loss: -0.4653  Acc@1: 81.2500 (80.6691)  Acc@5: 100.0000 (98.9009)  time: 0.3490  data: 0.0015  max mem: 2503
Train: Epoch[3/5]  [3000/3750]  eta: 0:04:20  Lr: 0.001875  Loss: -0.8908  Acc@1: 81.2500 (80.6835)  Acc@5: 100.0000 (98.9004)  time: 0.3492  data: 0.0015  max mem: 2503
Train: Epoch[3/5]  [3010/3750]  eta: 0:04:17  Lr: 0.001875  Loss: -0.7946  Acc@1: 81.2500 (80.6813)  Acc@5: 100.0000 (98.9040)  time: 0.3480  data: 0.0015  max mem: 2503
Train: Epoch[3/5]  [3020/3750]  eta: 0:04:13  Lr: 0.001875  Loss: -0.3735  Acc@1: 81.2500 (80.6873)  Acc@5: 100.0000 (98.9076)  time: 0.3476  data: 0.0013  max mem: 2503
Train: Epoch[3/5]  [3030/3750]  eta: 0:04:10  Lr: 0.001875  Loss: -0.7112  Acc@1: 81.2500 (80.6871)  Acc@5: 100.0000 (98.9071)  time: 0.3472  data: 0.0011  max mem: 2503
Train: Epoch[3/5]  [3040/3750]  eta: 0:04:06  Lr: 0.001875  Loss: -0.7618  Acc@1: 81.2500 (80.6910)  Acc@5: 100.0000 (98.9066)  time: 0.3456  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [3050/3750]  eta: 0:04:03  Lr: 0.001875  Loss: -0.5205  Acc@1: 75.0000 (80.6764)  Acc@5: 100.0000 (98.9081)  time: 0.3450  data: 0.0011  max mem: 2503
Train: Epoch[3/5]  [3060/3750]  eta: 0:03:59  Lr: 0.001875  Loss: -1.0022  Acc@1: 75.0000 (80.6722)  Acc@5: 100.0000 (98.9097)  time: 0.3444  data: 0.0010  max mem: 2503
Train: Epoch[3/5]  [3070/3750]  eta: 0:03:56  Lr: 0.001875  Loss: -0.7261  Acc@1: 87.5000 (80.6761)  Acc@5: 100.0000 (98.9112)  time: 0.3443  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [3080/3750]  eta: 0:03:52  Lr: 0.001875  Loss: -0.7932  Acc@1: 81.2500 (80.6759)  Acc@5: 100.0000 (98.9127)  time: 0.3460  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [3090/3750]  eta: 0:03:49  Lr: 0.001875  Loss: -0.6659  Acc@1: 81.2500 (80.6859)  Acc@5: 100.0000 (98.9142)  time: 0.3483  data: 0.0014  max mem: 2503
Train: Epoch[3/5]  [3100/3750]  eta: 0:03:45  Lr: 0.001875  Loss: -0.7761  Acc@1: 81.2500 (80.6796)  Acc@5: 100.0000 (98.9137)  time: 0.3486  data: 0.0017  max mem: 2503
Train: Epoch[3/5]  [3110/3750]  eta: 0:03:42  Lr: 0.001875  Loss: -0.7187  Acc@1: 81.2500 (80.6674)  Acc@5: 100.0000 (98.9151)  time: 0.3478  data: 0.0011  max mem: 2503
Train: Epoch[3/5]  [3120/3750]  eta: 0:03:38  Lr: 0.001875  Loss: -0.6592  Acc@1: 81.2500 (80.6693)  Acc@5: 100.0000 (98.9186)  time: 0.3476  data: 0.0009  max mem: 2503
Train: Epoch[3/5]  [3130/3750]  eta: 0:03:35  Lr: 0.001875  Loss: -0.5121  Acc@1: 75.0000 (80.6651)  Acc@5: 100.0000 (98.9181)  time: 0.3493  data: 0.0017  max mem: 2503
Train: Epoch[3/5]  [3140/3750]  eta: 0:03:31  Lr: 0.001875  Loss: -0.4261  Acc@1: 81.2500 (80.6630)  Acc@5: 100.0000 (98.9136)  time: 0.3490  data: 0.0021  max mem: 2503
Train: Epoch[3/5]  [3150/3750]  eta: 0:03:28  Lr: 0.001875  Loss: -0.9966  Acc@1: 81.2500 (80.6728)  Acc@5: 100.0000 (98.9170)  time: 0.3474  data: 0.0011  max mem: 2503
Train: Epoch[3/5]  [3160/3750]  eta: 0:03:24  Lr: 0.001875  Loss: -0.8193  Acc@1: 81.2500 (80.6806)  Acc@5: 100.0000 (98.9185)  time: 0.3479  data: 0.0011  max mem: 2503
Train: Epoch[3/5]  [3170/3750]  eta: 0:03:21  Lr: 0.001875  Loss: -0.4098  Acc@1: 81.2500 (80.6863)  Acc@5: 100.0000 (98.9219)  time: 0.3489  data: 0.0017  max mem: 2503
Train: Epoch[3/5]  [3180/3750]  eta: 0:03:18  Lr: 0.001875  Loss: -0.9627  Acc@1: 81.2500 (80.6979)  Acc@5: 100.0000 (98.9213)  time: 0.3484  data: 0.0015  max mem: 2503
Train: Epoch[3/5]  [3190/3750]  eta: 0:03:14  Lr: 0.001875  Loss: -0.3794  Acc@1: 81.2500 (80.6977)  Acc@5: 100.0000 (98.9208)  time: 0.3490  data: 0.0010  max mem: 2503
Train: Epoch[3/5]  [3200/3750]  eta: 0:03:11  Lr: 0.001875  Loss: -0.4377  Acc@1: 81.2500 (80.6974)  Acc@5: 100.0000 (98.9203)  time: 0.3491  data: 0.0009  max mem: 2503
Train: Epoch[3/5]  [3210/3750]  eta: 0:03:07  Lr: 0.001875  Loss: -0.9921  Acc@1: 81.2500 (80.7031)  Acc@5: 100.0000 (98.9217)  time: 0.3472  data: 0.0006  max mem: 2503
Train: Epoch[3/5]  [3220/3750]  eta: 0:03:04  Lr: 0.001875  Loss: -0.8401  Acc@1: 81.2500 (80.7125)  Acc@5: 100.0000 (98.9211)  time: 0.3459  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [3230/3750]  eta: 0:03:00  Lr: 0.001875  Loss: -0.4517  Acc@1: 81.2500 (80.7122)  Acc@5: 100.0000 (98.9187)  time: 0.3442  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [3240/3750]  eta: 0:02:57  Lr: 0.001875  Loss: -0.8211  Acc@1: 81.2500 (80.7197)  Acc@5: 100.0000 (98.9162)  time: 0.3433  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [3250/3750]  eta: 0:02:53  Lr: 0.001875  Loss: -0.7129  Acc@1: 87.5000 (80.7290)  Acc@5: 100.0000 (98.9196)  time: 0.3444  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [3260/3750]  eta: 0:02:50  Lr: 0.001875  Loss: -0.7033  Acc@1: 81.2500 (80.7344)  Acc@5: 100.0000 (98.9229)  time: 0.3473  data: 0.0007  max mem: 2503
Train: Epoch[3/5]  [3270/3750]  eta: 0:02:46  Lr: 0.001875  Loss: -0.5794  Acc@1: 81.2500 (80.7417)  Acc@5: 100.0000 (98.9262)  time: 0.3480  data: 0.0008  max mem: 2503
Train: Epoch[3/5]  [3280/3750]  eta: 0:02:43  Lr: 0.001875  Loss: -0.8073  Acc@1: 81.2500 (80.7395)  Acc@5: 100.0000 (98.9275)  time: 0.3475  data: 0.0007  max mem: 2503
Train: Epoch[3/5]  [3290/3750]  eta: 0:02:39  Lr: 0.001875  Loss: 0.0709  Acc@1: 75.0000 (80.7201)  Acc@5: 100.0000 (98.9232)  time: 0.3475  data: 0.0008  max mem: 2503
Train: Epoch[3/5]  [3300/3750]  eta: 0:02:36  Lr: 0.001875  Loss: -0.6319  Acc@1: 75.0000 (80.7123)  Acc@5: 100.0000 (98.9208)  time: 0.3483  data: 0.0009  max mem: 2503
Train: Epoch[3/5]  [3310/3750]  eta: 0:02:32  Lr: 0.001875  Loss: -0.6742  Acc@1: 81.2500 (80.7252)  Acc@5: 100.0000 (98.9222)  time: 0.3494  data: 0.0012  max mem: 2503
Train: Epoch[3/5]  [3320/3750]  eta: 0:02:29  Lr: 0.001875  Loss: -0.7347  Acc@1: 81.2500 (80.7306)  Acc@5: 100.0000 (98.9198)  time: 0.3500  data: 0.0013  max mem: 2503
Train: Epoch[3/5]  [3330/3750]  eta: 0:02:25  Lr: 0.001875  Loss: -0.9024  Acc@1: 81.2500 (80.7340)  Acc@5: 100.0000 (98.9230)  time: 0.3489  data: 0.0012  max mem: 2503
Train: Epoch[3/5]  [3340/3750]  eta: 0:02:22  Lr: 0.001875  Loss: -0.3914  Acc@1: 81.2500 (80.7449)  Acc@5: 100.0000 (98.9243)  time: 0.3481  data: 0.0009  max mem: 2503
Train: Epoch[3/5]  [3350/3750]  eta: 0:02:18  Lr: 0.001875  Loss: -0.4202  Acc@1: 81.2500 (80.7483)  Acc@5: 100.0000 (98.9257)  time: 0.3492  data: 0.0011  max mem: 2503
Train: Epoch[3/5]  [3360/3750]  eta: 0:02:15  Lr: 0.001875  Loss: -0.6237  Acc@1: 81.2500 (80.7386)  Acc@5: 100.0000 (98.9270)  time: 0.3488  data: 0.0013  max mem: 2503
Train: Epoch[3/5]  [3370/3750]  eta: 0:02:12  Lr: 0.001875  Loss: -0.3398  Acc@1: 81.2500 (80.7290)  Acc@5: 100.0000 (98.9302)  time: 0.3481  data: 0.0012  max mem: 2503
Train: Epoch[3/5]  [3380/3750]  eta: 0:02:08  Lr: 0.001875  Loss: -0.5210  Acc@1: 81.2500 (80.7232)  Acc@5: 100.0000 (98.9315)  time: 0.3464  data: 0.0007  max mem: 2503
Train: Epoch[3/5]  [3390/3750]  eta: 0:02:05  Lr: 0.001875  Loss: -0.6077  Acc@1: 81.2500 (80.7247)  Acc@5: 100.0000 (98.9310)  time: 0.3457  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [3400/3750]  eta: 0:02:01  Lr: 0.001875  Loss: -0.7648  Acc@1: 81.2500 (80.7281)  Acc@5: 100.0000 (98.9286)  time: 0.3470  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [3410/3750]  eta: 0:01:58  Lr: 0.001875  Loss: -0.9592  Acc@1: 81.2500 (80.7260)  Acc@5: 100.0000 (98.9318)  time: 0.3454  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [3420/3750]  eta: 0:01:54  Lr: 0.001875  Loss: -0.6188  Acc@1: 81.2500 (80.7220)  Acc@5: 100.0000 (98.9331)  time: 0.3442  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [3430/3750]  eta: 0:01:51  Lr: 0.001875  Loss: -0.8263  Acc@1: 81.2500 (80.7235)  Acc@5: 100.0000 (98.9343)  time: 0.3455  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [3440/3750]  eta: 0:01:47  Lr: 0.001875  Loss: -0.9606  Acc@1: 81.2500 (80.7105)  Acc@5: 100.0000 (98.9356)  time: 0.3485  data: 0.0012  max mem: 2503
Train: Epoch[3/5]  [3450/3750]  eta: 0:01:44  Lr: 0.001875  Loss: -0.7910  Acc@1: 87.5000 (80.7338)  Acc@5: 100.0000 (98.9387)  time: 0.3494  data: 0.0016  max mem: 2503
Train: Epoch[3/5]  [3460/3750]  eta: 0:01:40  Lr: 0.001875  Loss: -0.7188  Acc@1: 81.2500 (80.7263)  Acc@5: 100.0000 (98.9382)  time: 0.3484  data: 0.0015  max mem: 2503
Train: Epoch[3/5]  [3470/3750]  eta: 0:01:37  Lr: 0.001875  Loss: -0.7221  Acc@1: 81.2500 (80.7404)  Acc@5: 100.0000 (98.9412)  time: 0.3481  data: 0.0013  max mem: 2503
Train: Epoch[3/5]  [3480/3750]  eta: 0:01:33  Lr: 0.001875  Loss: -0.3377  Acc@1: 87.5000 (80.7455)  Acc@5: 100.0000 (98.9389)  time: 0.3481  data: 0.0013  max mem: 2503
Train: Epoch[3/5]  [3490/3750]  eta: 0:01:30  Lr: 0.001875  Loss: -0.3869  Acc@1: 81.2500 (80.7505)  Acc@5: 100.0000 (98.9383)  time: 0.3504  data: 0.0028  max mem: 2503
Train: Epoch[3/5]  [3500/3750]  eta: 0:01:26  Lr: 0.001875  Loss: -1.0640  Acc@1: 81.2500 (80.7573)  Acc@5: 100.0000 (98.9396)  time: 0.3518  data: 0.0030  max mem: 2503
Train: Epoch[3/5]  [3510/3750]  eta: 0:01:23  Lr: 0.001875  Loss: -0.7887  Acc@1: 87.5000 (80.7605)  Acc@5: 100.0000 (98.9426)  time: 0.3499  data: 0.0017  max mem: 2503
Train: Epoch[3/5]  [3520/3750]  eta: 0:01:19  Lr: 0.001875  Loss: -1.0042  Acc@1: 81.2500 (80.7583)  Acc@5: 100.0000 (98.9421)  time: 0.3488  data: 0.0020  max mem: 2503
Train: Epoch[3/5]  [3530/3750]  eta: 0:01:16  Lr: 0.001875  Loss: -0.7616  Acc@1: 81.2500 (80.7508)  Acc@5: 100.0000 (98.9397)  time: 0.3489  data: 0.0021  max mem: 2503
Train: Epoch[3/5]  [3540/3750]  eta: 0:01:12  Lr: 0.001875  Loss: -0.5712  Acc@1: 81.2500 (80.7470)  Acc@5: 100.0000 (98.9410)  time: 0.3487  data: 0.0012  max mem: 2503
Train: Epoch[3/5]  [3550/3750]  eta: 0:01:09  Lr: 0.001875  Loss: -0.9522  Acc@1: 81.2500 (80.7537)  Acc@5: 100.0000 (98.9422)  time: 0.3490  data: 0.0007  max mem: 2503
Train: Epoch[3/5]  [3560/3750]  eta: 0:01:06  Lr: 0.001875  Loss: -1.1014  Acc@1: 81.2500 (80.7603)  Acc@5: 100.0000 (98.9417)  time: 0.3478  data: 0.0007  max mem: 2503
Train: Epoch[3/5]  [3570/3750]  eta: 0:01:02  Lr: 0.001875  Loss: -0.7026  Acc@1: 87.5000 (80.7757)  Acc@5: 100.0000 (98.9411)  time: 0.3459  data: 0.0006  max mem: 2503
Train: Epoch[3/5]  [3580/3750]  eta: 0:00:59  Lr: 0.001875  Loss: -1.0155  Acc@1: 87.5000 (80.7945)  Acc@5: 100.0000 (98.9423)  time: 0.3445  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [3590/3750]  eta: 0:00:55  Lr: 0.001875  Loss: -0.8302  Acc@1: 87.5000 (80.8010)  Acc@5: 100.0000 (98.9418)  time: 0.3440  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [3600/3750]  eta: 0:00:52  Lr: 0.001875  Loss: -0.5505  Acc@1: 81.2500 (80.7970)  Acc@5: 100.0000 (98.9413)  time: 0.3438  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [3610/3750]  eta: 0:00:48  Lr: 0.001875  Loss: -0.3015  Acc@1: 75.0000 (80.7931)  Acc@5: 100.0000 (98.9407)  time: 0.3455  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [3620/3750]  eta: 0:00:45  Lr: 0.001875  Loss: -0.7668  Acc@1: 81.2500 (80.8099)  Acc@5: 100.0000 (98.9402)  time: 0.3486  data: 0.0008  max mem: 2503
Train: Epoch[3/5]  [3630/3750]  eta: 0:00:41  Lr: 0.001875  Loss: -0.4526  Acc@1: 87.5000 (80.8197)  Acc@5: 100.0000 (98.9414)  time: 0.3502  data: 0.0019  max mem: 2503
Train: Epoch[3/5]  [3640/3750]  eta: 0:00:38  Lr: 0.001875  Loss: -0.5594  Acc@1: 81.2500 (80.8191)  Acc@5: 100.0000 (98.9392)  time: 0.3495  data: 0.0019  max mem: 2503
Train: Epoch[3/5]  [3650/3750]  eta: 0:00:34  Lr: 0.001875  Loss: -0.7471  Acc@1: 75.0000 (80.8203)  Acc@5: 100.0000 (98.9386)  time: 0.3497  data: 0.0013  max mem: 2503
Train: Epoch[3/5]  [3660/3750]  eta: 0:00:31  Lr: 0.001875  Loss: -0.6444  Acc@1: 75.0000 (80.8181)  Acc@5: 100.0000 (98.9381)  time: 0.3510  data: 0.0021  max mem: 2503
Train: Epoch[3/5]  [3670/3750]  eta: 0:00:27  Lr: 0.001875  Loss: -0.4244  Acc@1: 81.2500 (80.8159)  Acc@5: 100.0000 (98.9410)  time: 0.3498  data: 0.0019  max mem: 2503
Train: Epoch[3/5]  [3680/3750]  eta: 0:00:24  Lr: 0.001875  Loss: -0.8133  Acc@1: 81.2500 (80.8204)  Acc@5: 100.0000 (98.9439)  time: 0.3477  data: 0.0009  max mem: 2503
Train: Epoch[3/5]  [3690/3750]  eta: 0:00:20  Lr: 0.001875  Loss: -0.7552  Acc@1: 81.2500 (80.8165)  Acc@5: 100.0000 (98.9417)  time: 0.3463  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [3700/3750]  eta: 0:00:17  Lr: 0.001875  Loss: -0.6667  Acc@1: 81.2500 (80.8143)  Acc@5: 100.0000 (98.9445)  time: 0.3476  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [3710/3750]  eta: 0:00:13  Lr: 0.001875  Loss: -0.5317  Acc@1: 81.2500 (80.8037)  Acc@5: 100.0000 (98.9474)  time: 0.3475  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [3720/3750]  eta: 0:00:10  Lr: 0.001875  Loss: -0.9709  Acc@1: 81.2500 (80.7999)  Acc@5: 100.0000 (98.9485)  time: 0.3456  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [3730/3750]  eta: 0:00:06  Lr: 0.001875  Loss: -0.9520  Acc@1: 81.2500 (80.8027)  Acc@5: 100.0000 (98.9480)  time: 0.3464  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [3740/3750]  eta: 0:00:03  Lr: 0.001875  Loss: 0.0631  Acc@1: 81.2500 (80.7972)  Acc@5: 100.0000 (98.9458)  time: 0.3453  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [3749/3750]  eta: 0:00:00  Lr: 0.001875  Loss: -0.4975  Acc@1: 81.2500 (80.7900)  Acc@5: 100.0000 (98.9433)  time: 0.3435  data: 0.0006  max mem: 2503
Train: Epoch[3/5] Total time: 0:21:43 (0.3476 s / it)
{0: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 1: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 2: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 3: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 4: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 5: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 6: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 7: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 8: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 9: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 10: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 11: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 12: {0: 0, 1: 0, 2: 0, 3: 91325, 4: 0}, 13: {0: 0, 1: 0, 2: 0, 3: 91325, 4: 0}, 14: {0: 0, 1: 0, 2: 0, 3: 91325, 4: 0}, 15: {0: 0, 1: 0, 2: 0, 3: 91325, 4: 0}, 16: {0: 0, 1: 0, 2: 0, 3: 0, 4: 180000}, 17: {0: 0, 1: 0, 2: 0, 3: 0, 4: 180000}, 18: {0: 0, 1: 0, 2: 0, 3: 0, 4: 180000}, 19: {0: 0, 1: 0, 2: 0, 3: 0, 4: 180000}}
Averaged stats: Lr: 0.001875  Loss: -0.4975  Acc@1: 81.2500 (80.7900)  Acc@5: 100.0000 (98.9433)
Train: Epoch[4/5]  [   0/3750]  eta: 0:41:10  Lr: 0.001875  Loss: -0.4999  Acc@1: 81.2500 (81.2500)  Acc@5: 87.5000 (87.5000)  time: 0.6587  data: 0.3142  max mem: 2503
Train: Epoch[4/5]  [  10/3750]  eta: 0:23:24  Lr: 0.001875  Loss: -0.7376  Acc@1: 81.2500 (77.8409)  Acc@5: 100.0000 (96.5909)  time: 0.3756  data: 0.0289  max mem: 2503
Train: Epoch[4/5]  [  20/3750]  eta: 0:22:32  Lr: 0.001875  Loss: -0.8556  Acc@1: 81.2500 (80.0595)  Acc@5: 100.0000 (97.9167)  time: 0.3477  data: 0.0006  max mem: 2503
Train: Epoch[4/5]  [  30/3750]  eta: 0:22:13  Lr: 0.001875  Loss: -0.4269  Acc@1: 81.2500 (80.2419)  Acc@5: 100.0000 (97.7823)  time: 0.3488  data: 0.0014  max mem: 2503
Train: Epoch[4/5]  [  40/3750]  eta: 0:22:01  Lr: 0.001875  Loss: -0.9635  Acc@1: 87.5000 (81.7073)  Acc@5: 100.0000 (98.0183)  time: 0.3495  data: 0.0014  max mem: 2503
Train: Epoch[4/5]  [  50/3750]  eta: 0:21:51  Lr: 0.001875  Loss: -0.3751  Acc@1: 81.2500 (81.1275)  Acc@5: 100.0000 (98.2843)  time: 0.3481  data: 0.0011  max mem: 2503
Train: Epoch[4/5]  [  60/3750]  eta: 0:21:44  Lr: 0.001875  Loss: -0.5099  Acc@1: 75.0000 (79.6107)  Acc@5: 100.0000 (98.3607)  time: 0.3485  data: 0.0012  max mem: 2503
Train: Epoch[4/5]  [  70/3750]  eta: 0:21:38  Lr: 0.001875  Loss: -0.6696  Acc@1: 75.0000 (79.6655)  Acc@5: 100.0000 (98.5035)  time: 0.3494  data: 0.0008  max mem: 2503
Train: Epoch[4/5]  [  80/3750]  eta: 0:21:33  Lr: 0.001875  Loss: -0.6192  Acc@1: 81.2500 (79.8611)  Acc@5: 100.0000 (98.6111)  time: 0.3491  data: 0.0006  max mem: 2503
Train: Epoch[4/5]  [  90/3750]  eta: 0:21:29  Lr: 0.001875  Loss: -0.9905  Acc@1: 81.2500 (79.8764)  Acc@5: 100.0000 (98.6951)  time: 0.3498  data: 0.0016  max mem: 2503
Train: Epoch[4/5]  [ 100/3750]  eta: 0:21:24  Lr: 0.001875  Loss: -0.9607  Acc@1: 81.2500 (80.1980)  Acc@5: 100.0000 (98.8243)  time: 0.3498  data: 0.0022  max mem: 2503
Train: Epoch[4/5]  [ 110/3750]  eta: 0:21:20  Lr: 0.001875  Loss: -0.6412  Acc@1: 81.2500 (80.4617)  Acc@5: 100.0000 (98.7613)  time: 0.3500  data: 0.0013  max mem: 2503
Train: Epoch[4/5]  [ 120/3750]  eta: 0:21:15  Lr: 0.001875  Loss: -0.0952  Acc@1: 81.2500 (79.9587)  Acc@5: 100.0000 (98.7603)  time: 0.3482  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [ 130/3750]  eta: 0:21:10  Lr: 0.001875  Loss: -0.7755  Acc@1: 81.2500 (80.4389)  Acc@5: 100.0000 (98.7595)  time: 0.3457  data: 0.0003  max mem: 2503
Train: Epoch[4/5]  [ 140/3750]  eta: 0:21:05  Lr: 0.001875  Loss: -0.6630  Acc@1: 81.2500 (80.4078)  Acc@5: 100.0000 (98.8475)  time: 0.3454  data: 0.0003  max mem: 2503
Train: Epoch[4/5]  [ 150/3750]  eta: 0:21:00  Lr: 0.001875  Loss: -0.6796  Acc@1: 75.0000 (80.4636)  Acc@5: 100.0000 (98.9238)  time: 0.3447  data: 0.0002  max mem: 2503
Train: Epoch[4/5]  [ 160/3750]  eta: 0:20:55  Lr: 0.001875  Loss: -0.5220  Acc@1: 81.2500 (80.3960)  Acc@5: 100.0000 (98.8742)  time: 0.3449  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [ 170/3750]  eta: 0:20:51  Lr: 0.001875  Loss: -0.6380  Acc@1: 81.2500 (80.6287)  Acc@5: 100.0000 (98.8670)  time: 0.3466  data: 0.0006  max mem: 2503
Train: Epoch[4/5]  [ 180/3750]  eta: 0:20:47  Lr: 0.001875  Loss: -0.6246  Acc@1: 81.2500 (80.5594)  Acc@5: 100.0000 (98.8260)  time: 0.3473  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [ 190/3750]  eta: 0:20:43  Lr: 0.001875  Loss: -0.7031  Acc@1: 81.2500 (80.5628)  Acc@5: 100.0000 (98.8220)  time: 0.3467  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [ 200/3750]  eta: 0:20:39  Lr: 0.001875  Loss: -0.2322  Acc@1: 81.2500 (80.5659)  Acc@5: 100.0000 (98.8806)  time: 0.3466  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [ 210/3750]  eta: 0:20:36  Lr: 0.001875  Loss: -0.9470  Acc@1: 81.2500 (80.6872)  Acc@5: 100.0000 (98.9040)  time: 0.3483  data: 0.0006  max mem: 2503
Train: Epoch[4/5]  [ 220/3750]  eta: 0:20:33  Lr: 0.001875  Loss: 0.2817  Acc@1: 81.2500 (80.5995)  Acc@5: 100.0000 (98.9253)  time: 0.3499  data: 0.0008  max mem: 2503
Train: Epoch[4/5]  [ 230/3750]  eta: 0:20:29  Lr: 0.001875  Loss: -0.8501  Acc@1: 81.2500 (80.6818)  Acc@5: 100.0000 (98.9719)  time: 0.3494  data: 0.0007  max mem: 2503
Train: Epoch[4/5]  [ 240/3750]  eta: 0:20:25  Lr: 0.001875  Loss: -0.7127  Acc@1: 81.2500 (80.8091)  Acc@5: 100.0000 (98.9886)  time: 0.3481  data: 0.0009  max mem: 2503
Train: Epoch[4/5]  [ 250/3750]  eta: 0:20:21  Lr: 0.001875  Loss: -0.8333  Acc@1: 81.2500 (80.8765)  Acc@5: 100.0000 (99.0289)  time: 0.3474  data: 0.0016  max mem: 2503
Train: Epoch[4/5]  [ 260/3750]  eta: 0:20:18  Lr: 0.001875  Loss: -0.0128  Acc@1: 81.2500 (81.0345)  Acc@5: 100.0000 (98.8985)  time: 0.3477  data: 0.0016  max mem: 2503
Train: Epoch[4/5]  [ 270/3750]  eta: 0:20:15  Lr: 0.001875  Loss: -0.5523  Acc@1: 81.2500 (81.1116)  Acc@5: 100.0000 (98.8930)  time: 0.3496  data: 0.0012  max mem: 2503
Train: Epoch[4/5]  [ 280/3750]  eta: 0:20:11  Lr: 0.001875  Loss: -0.8133  Acc@1: 81.2500 (81.1165)  Acc@5: 100.0000 (98.8879)  time: 0.3486  data: 0.0009  max mem: 2503
Train: Epoch[4/5]  [ 290/3750]  eta: 0:20:07  Lr: 0.001875  Loss: -0.6506  Acc@1: 81.2500 (80.9708)  Acc@5: 100.0000 (98.8832)  time: 0.3452  data: 0.0006  max mem: 2503
Train: Epoch[4/5]  [ 300/3750]  eta: 0:20:03  Lr: 0.001875  Loss: -0.1281  Acc@1: 81.2500 (80.8555)  Acc@5: 100.0000 (98.8164)  time: 0.3440  data: 0.0008  max mem: 2503
Train: Epoch[4/5]  [ 310/3750]  eta: 0:19:58  Lr: 0.001875  Loss: -0.6740  Acc@1: 81.2500 (80.9285)  Acc@5: 100.0000 (98.8143)  time: 0.3432  data: 0.0007  max mem: 2503
Train: Epoch[4/5]  [ 320/3750]  eta: 0:19:54  Lr: 0.001875  Loss: -0.7291  Acc@1: 87.5000 (80.9774)  Acc@5: 100.0000 (98.8123)  time: 0.3432  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [ 330/3750]  eta: 0:19:51  Lr: 0.001875  Loss: -0.6363  Acc@1: 81.2500 (80.9668)  Acc@5: 100.0000 (98.8293)  time: 0.3447  data: 0.0006  max mem: 2503
Train: Epoch[4/5]  [ 340/3750]  eta: 0:19:47  Lr: 0.001875  Loss: -0.4571  Acc@1: 81.2500 (81.0301)  Acc@5: 100.0000 (98.8636)  time: 0.3459  data: 0.0006  max mem: 2503
Train: Epoch[4/5]  [ 350/3750]  eta: 0:19:43  Lr: 0.001875  Loss: -0.7055  Acc@1: 81.2500 (81.0719)  Acc@5: 100.0000 (98.8960)  time: 0.3461  data: 0.0007  max mem: 2503
Train: Epoch[4/5]  [ 360/3750]  eta: 0:19:40  Lr: 0.001875  Loss: -0.7317  Acc@1: 81.2500 (81.1115)  Acc@5: 100.0000 (98.9093)  time: 0.3473  data: 0.0013  max mem: 2503
Train: Epoch[4/5]  [ 370/3750]  eta: 0:19:36  Lr: 0.001875  Loss: -0.6483  Acc@1: 87.5000 (81.3005)  Acc@5: 100.0000 (98.9218)  time: 0.3478  data: 0.0012  max mem: 2503
Train: Epoch[4/5]  [ 380/3750]  eta: 0:19:33  Lr: 0.001875  Loss: -0.5563  Acc@1: 81.2500 (81.1844)  Acc@5: 100.0000 (98.8845)  time: 0.3470  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [ 390/3750]  eta: 0:19:29  Lr: 0.001875  Loss: -0.8382  Acc@1: 75.0000 (81.1381)  Acc@5: 100.0000 (98.9130)  time: 0.3471  data: 0.0006  max mem: 2503
Train: Epoch[4/5]  [ 400/3750]  eta: 0:19:26  Lr: 0.001875  Loss: -0.5773  Acc@1: 81.2500 (81.1253)  Acc@5: 100.0000 (98.9246)  time: 0.3472  data: 0.0009  max mem: 2503
Train: Epoch[4/5]  [ 410/3750]  eta: 0:19:22  Lr: 0.001875  Loss: 0.0661  Acc@1: 81.2500 (81.0979)  Acc@5: 100.0000 (98.9203)  time: 0.3478  data: 0.0008  max mem: 2503
Train: Epoch[4/5]  [ 420/3750]  eta: 0:19:19  Lr: 0.001875  Loss: -0.9134  Acc@1: 81.2500 (81.2055)  Acc@5: 100.0000 (98.9460)  time: 0.3481  data: 0.0010  max mem: 2503
Train: Epoch[4/5]  [ 430/3750]  eta: 0:19:15  Lr: 0.001875  Loss: -0.5388  Acc@1: 87.5000 (81.3225)  Acc@5: 100.0000 (98.9414)  time: 0.3478  data: 0.0017  max mem: 2503
Train: Epoch[4/5]  [ 440/3750]  eta: 0:19:11  Lr: 0.001875  Loss: -0.7944  Acc@1: 81.2500 (81.2783)  Acc@5: 100.0000 (98.9512)  time: 0.3469  data: 0.0013  max mem: 2503
Train: Epoch[4/5]  [ 450/3750]  eta: 0:19:08  Lr: 0.001875  Loss: -0.8298  Acc@1: 81.2500 (81.3747)  Acc@5: 100.0000 (98.9745)  time: 0.3455  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [ 460/3750]  eta: 0:19:04  Lr: 0.001875  Loss: -0.6446  Acc@1: 81.2500 (81.3178)  Acc@5: 100.0000 (98.9967)  time: 0.3437  data: 0.0003  max mem: 2503
Train: Epoch[4/5]  [ 470/3750]  eta: 0:19:00  Lr: 0.001875  Loss: -0.7588  Acc@1: 81.2500 (81.3296)  Acc@5: 100.0000 (98.9782)  time: 0.3427  data: 0.0002  max mem: 2503
Train: Epoch[4/5]  [ 480/3750]  eta: 0:18:56  Lr: 0.001875  Loss: -0.2406  Acc@1: 81.2500 (81.3929)  Acc@5: 100.0000 (98.9995)  time: 0.3431  data: 0.0002  max mem: 2503
Train: Epoch[4/5]  [ 490/3750]  eta: 0:18:53  Lr: 0.001875  Loss: -0.7624  Acc@1: 87.5000 (81.4155)  Acc@5: 100.0000 (99.0199)  time: 0.3468  data: 0.0009  max mem: 2503
Train: Epoch[4/5]  [ 500/3750]  eta: 0:18:49  Lr: 0.001875  Loss: -0.5541  Acc@1: 81.2500 (81.4247)  Acc@5: 100.0000 (99.0269)  time: 0.3490  data: 0.0011  max mem: 2503
Train: Epoch[4/5]  [ 510/3750]  eta: 0:18:46  Lr: 0.001875  Loss: -0.5488  Acc@1: 81.2500 (81.3478)  Acc@5: 100.0000 (98.9971)  time: 0.3471  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [ 520/3750]  eta: 0:18:43  Lr: 0.001875  Loss: -0.8003  Acc@1: 81.2500 (81.2980)  Acc@5: 100.0000 (99.0043)  time: 0.3478  data: 0.0013  max mem: 2503
Train: Epoch[4/5]  [ 530/3750]  eta: 0:18:39  Lr: 0.001875  Loss: -0.8695  Acc@1: 81.2500 (81.3206)  Acc@5: 100.0000 (98.9995)  time: 0.3486  data: 0.0015  max mem: 2503
Train: Epoch[4/5]  [ 540/3750]  eta: 0:18:36  Lr: 0.001875  Loss: -0.6523  Acc@1: 81.2500 (81.3193)  Acc@5: 100.0000 (98.9834)  time: 0.3481  data: 0.0008  max mem: 2503
Train: Epoch[4/5]  [ 550/3750]  eta: 0:18:32  Lr: 0.001875  Loss: -0.1832  Acc@1: 81.2500 (81.3067)  Acc@5: 100.0000 (98.9905)  time: 0.3469  data: 0.0007  max mem: 2503
Train: Epoch[4/5]  [ 560/3750]  eta: 0:18:29  Lr: 0.001875  Loss: -0.2797  Acc@1: 81.2500 (81.2723)  Acc@5: 100.0000 (98.9862)  time: 0.3465  data: 0.0008  max mem: 2503
Train: Epoch[4/5]  [ 570/3750]  eta: 0:18:25  Lr: 0.001875  Loss: -0.8762  Acc@1: 81.2500 (81.3704)  Acc@5: 100.0000 (99.0039)  time: 0.3483  data: 0.0018  max mem: 2503
Train: Epoch[4/5]  [ 580/3750]  eta: 0:18:22  Lr: 0.001875  Loss: -0.4725  Acc@1: 81.2500 (81.3145)  Acc@5: 100.0000 (99.0211)  time: 0.3488  data: 0.0017  max mem: 2503
Train: Epoch[4/5]  [ 590/3750]  eta: 0:18:18  Lr: 0.001875  Loss: -0.7754  Acc@1: 81.2500 (81.3558)  Acc@5: 100.0000 (99.0376)  time: 0.3465  data: 0.0006  max mem: 2503
Train: Epoch[4/5]  [ 600/3750]  eta: 0:18:15  Lr: 0.001875  Loss: -0.7015  Acc@1: 87.5000 (81.4060)  Acc@5: 100.0000 (99.0329)  time: 0.3459  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [ 610/3750]  eta: 0:18:11  Lr: 0.001875  Loss: -0.4750  Acc@1: 87.5000 (81.4341)  Acc@5: 100.0000 (99.0282)  time: 0.3450  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [ 620/3750]  eta: 0:18:07  Lr: 0.001875  Loss: -0.9885  Acc@1: 81.2500 (81.4714)  Acc@5: 100.0000 (99.0439)  time: 0.3427  data: 0.0002  max mem: 2503
Train: Epoch[4/5]  [ 630/3750]  eta: 0:18:04  Lr: 0.001875  Loss: -0.6089  Acc@1: 81.2500 (81.4778)  Acc@5: 100.0000 (99.0293)  time: 0.3438  data: 0.0006  max mem: 2503
Train: Epoch[4/5]  [ 640/3750]  eta: 0:18:00  Lr: 0.001875  Loss: -0.4952  Acc@1: 81.2500 (81.4255)  Acc@5: 100.0000 (99.0152)  time: 0.3452  data: 0.0008  max mem: 2503
Train: Epoch[4/5]  [ 650/3750]  eta: 0:17:57  Lr: 0.001875  Loss: -0.8627  Acc@1: 75.0000 (81.4036)  Acc@5: 100.0000 (99.0015)  time: 0.3475  data: 0.0008  max mem: 2503
Train: Epoch[4/5]  [ 660/3750]  eta: 0:17:53  Lr: 0.001875  Loss: -1.0168  Acc@1: 81.2500 (81.4202)  Acc@5: 100.0000 (99.0166)  time: 0.3494  data: 0.0010  max mem: 2503
Train: Epoch[4/5]  [ 670/3750]  eta: 0:17:50  Lr: 0.001875  Loss: -0.5250  Acc@1: 75.0000 (81.3711)  Acc@5: 100.0000 (99.0220)  time: 0.3490  data: 0.0009  max mem: 2503
Train: Epoch[4/5]  [ 680/3750]  eta: 0:17:46  Lr: 0.001875  Loss: -0.6542  Acc@1: 81.2500 (81.4336)  Acc@5: 100.0000 (99.0363)  time: 0.3500  data: 0.0019  max mem: 2503
Train: Epoch[4/5]  [ 690/3750]  eta: 0:17:43  Lr: 0.001875  Loss: -0.8357  Acc@1: 87.5000 (81.5485)  Acc@5: 100.0000 (99.0322)  time: 0.3496  data: 0.0021  max mem: 2503
Train: Epoch[4/5]  [ 700/3750]  eta: 0:17:40  Lr: 0.001875  Loss: -0.5568  Acc@1: 87.5000 (81.5799)  Acc@5: 100.0000 (99.0460)  time: 0.3484  data: 0.0013  max mem: 2503
Train: Epoch[4/5]  [ 710/3750]  eta: 0:17:36  Lr: 0.001875  Loss: -0.7185  Acc@1: 81.2500 (81.6104)  Acc@5: 100.0000 (99.0506)  time: 0.3479  data: 0.0012  max mem: 2503
Train: Epoch[4/5]  [ 720/3750]  eta: 0:17:33  Lr: 0.001875  Loss: -0.7830  Acc@1: 81.2500 (81.5707)  Acc@5: 100.0000 (99.0551)  time: 0.3481  data: 0.0018  max mem: 2503
Train: Epoch[4/5]  [ 730/3750]  eta: 0:17:29  Lr: 0.001875  Loss: -0.5403  Acc@1: 81.2500 (81.5492)  Acc@5: 100.0000 (99.0510)  time: 0.3489  data: 0.0016  max mem: 2503
Train: Epoch[4/5]  [ 740/3750]  eta: 0:17:26  Lr: 0.001875  Loss: -0.9804  Acc@1: 81.2500 (81.5621)  Acc@5: 100.0000 (99.0216)  time: 0.3499  data: 0.0007  max mem: 2503
Train: Epoch[4/5]  [ 750/3750]  eta: 0:17:22  Lr: 0.001875  Loss: -0.6027  Acc@1: 81.2500 (81.5579)  Acc@5: 100.0000 (99.0346)  time: 0.3483  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [ 760/3750]  eta: 0:17:19  Lr: 0.001875  Loss: -0.6612  Acc@1: 81.2500 (81.5785)  Acc@5: 100.0000 (99.0391)  time: 0.3462  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [ 770/3750]  eta: 0:17:15  Lr: 0.001875  Loss: -0.7037  Acc@1: 87.5000 (81.6877)  Acc@5: 100.0000 (99.0516)  time: 0.3462  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [ 780/3750]  eta: 0:17:12  Lr: 0.001875  Loss: -0.5152  Acc@1: 87.5000 (81.6981)  Acc@5: 100.0000 (99.0477)  time: 0.3451  data: 0.0003  max mem: 2503
Train: Epoch[4/5]  [ 790/3750]  eta: 0:17:08  Lr: 0.001875  Loss: -0.3041  Acc@1: 81.2500 (81.6688)  Acc@5: 100.0000 (99.0439)  time: 0.3450  data: 0.0013  max mem: 2503
Train: Epoch[4/5]  [ 800/3750]  eta: 0:17:05  Lr: 0.001875  Loss: -0.8834  Acc@1: 87.5000 (81.7884)  Acc@5: 100.0000 (99.0559)  time: 0.3468  data: 0.0017  max mem: 2503
Train: Epoch[4/5]  [ 810/3750]  eta: 0:17:01  Lr: 0.001875  Loss: -0.4717  Acc@1: 87.5000 (81.7509)  Acc@5: 100.0000 (99.0290)  time: 0.3477  data: 0.0011  max mem: 2503
Train: Epoch[4/5]  [ 820/3750]  eta: 0:16:58  Lr: 0.001875  Loss: -0.4043  Acc@1: 81.2500 (81.7144)  Acc@5: 100.0000 (99.0027)  time: 0.3470  data: 0.0009  max mem: 2503
Train: Epoch[4/5]  [ 830/3750]  eta: 0:16:54  Lr: 0.001875  Loss: -0.5407  Acc@1: 81.2500 (81.6862)  Acc@5: 100.0000 (98.9847)  time: 0.3482  data: 0.0014  max mem: 2503
Train: Epoch[4/5]  [ 840/3750]  eta: 0:16:51  Lr: 0.001875  Loss: -0.5257  Acc@1: 81.2500 (81.6959)  Acc@5: 100.0000 (98.9893)  time: 0.3488  data: 0.0015  max mem: 2503
Train: Epoch[4/5]  [ 850/3750]  eta: 0:16:47  Lr: 0.001875  Loss: -0.3719  Acc@1: 81.2500 (81.6686)  Acc@5: 100.0000 (99.0012)  time: 0.3489  data: 0.0008  max mem: 2503
Train: Epoch[4/5]  [ 860/3750]  eta: 0:16:44  Lr: 0.001875  Loss: -0.7456  Acc@1: 81.2500 (81.7146)  Acc@5: 100.0000 (98.9983)  time: 0.3487  data: 0.0006  max mem: 2503
Train: Epoch[4/5]  [ 870/3750]  eta: 0:16:41  Lr: 0.001875  Loss: -0.8034  Acc@1: 87.5000 (81.7595)  Acc@5: 100.0000 (99.0026)  time: 0.3475  data: 0.0011  max mem: 2503
Train: Epoch[4/5]  [ 880/3750]  eta: 0:16:37  Lr: 0.001875  Loss: -0.7326  Acc@1: 87.5000 (81.7821)  Acc@5: 100.0000 (99.0068)  time: 0.3475  data: 0.0010  max mem: 2503
Train: Epoch[4/5]  [ 890/3750]  eta: 0:16:34  Lr: 0.001875  Loss: -0.8524  Acc@1: 81.2500 (81.7621)  Acc@5: 100.0000 (99.0039)  time: 0.3482  data: 0.0006  max mem: 2503
Train: Epoch[4/5]  [ 900/3750]  eta: 0:16:30  Lr: 0.001875  Loss: -0.5477  Acc@1: 81.2500 (81.7425)  Acc@5: 100.0000 (99.0080)  time: 0.3482  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [ 910/3750]  eta: 0:16:27  Lr: 0.001875  Loss: -0.6227  Acc@1: 81.2500 (81.7577)  Acc@5: 100.0000 (99.0121)  time: 0.3475  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [ 920/3750]  eta: 0:16:23  Lr: 0.001875  Loss: -0.8542  Acc@1: 81.2500 (81.7386)  Acc@5: 100.0000 (99.0228)  time: 0.3469  data: 0.0006  max mem: 2503
Train: Epoch[4/5]  [ 930/3750]  eta: 0:16:20  Lr: 0.001875  Loss: -0.7346  Acc@1: 87.5000 (81.7602)  Acc@5: 100.0000 (99.0333)  time: 0.3458  data: 0.0006  max mem: 2503
Train: Epoch[4/5]  [ 940/3750]  eta: 0:16:16  Lr: 0.001875  Loss: -0.5717  Acc@1: 81.2500 (81.7016)  Acc@5: 100.0000 (99.0369)  time: 0.3444  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [ 950/3750]  eta: 0:16:12  Lr: 0.001875  Loss: -0.8803  Acc@1: 81.2500 (81.7232)  Acc@5: 100.0000 (99.0339)  time: 0.3434  data: 0.0003  max mem: 2503
Train: Epoch[4/5]  [ 960/3750]  eta: 0:16:09  Lr: 0.001875  Loss: -0.5405  Acc@1: 81.2500 (81.6402)  Acc@5: 100.0000 (99.0114)  time: 0.3443  data: 0.0003  max mem: 2503
Train: Epoch[4/5]  [ 970/3750]  eta: 0:16:05  Lr: 0.001875  Loss: -0.0124  Acc@1: 75.0000 (81.6491)  Acc@5: 100.0000 (99.0023)  time: 0.3465  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [ 980/3750]  eta: 0:16:02  Lr: 0.001875  Loss: -1.0766  Acc@1: 81.2500 (81.6514)  Acc@5: 100.0000 (98.9997)  time: 0.3475  data: 0.0008  max mem: 2503
Train: Epoch[4/5]  [ 990/3750]  eta: 0:15:58  Lr: 0.001875  Loss: -0.4326  Acc@1: 81.2500 (81.6158)  Acc@5: 100.0000 (98.9909)  time: 0.3471  data: 0.0006  max mem: 2503
Train: Epoch[4/5]  [1000/3750]  eta: 0:15:55  Lr: 0.001875  Loss: -0.8264  Acc@1: 81.2500 (81.6121)  Acc@5: 100.0000 (98.9885)  time: 0.3469  data: 0.0010  max mem: 2503
Train: Epoch[4/5]  [1010/3750]  eta: 0:15:51  Lr: 0.001875  Loss: -0.7456  Acc@1: 81.2500 (81.6456)  Acc@5: 100.0000 (98.9985)  time: 0.3463  data: 0.0011  max mem: 2503
Train: Epoch[4/5]  [1020/3750]  eta: 0:15:48  Lr: 0.001875  Loss: -0.4389  Acc@1: 87.5000 (81.7091)  Acc@5: 100.0000 (98.9900)  time: 0.3465  data: 0.0009  max mem: 2503
Train: Epoch[4/5]  [1030/3750]  eta: 0:15:44  Lr: 0.001875  Loss: -0.6097  Acc@1: 87.5000 (81.7410)  Acc@5: 100.0000 (98.9937)  time: 0.3460  data: 0.0010  max mem: 2503
Train: Epoch[4/5]  [1040/3750]  eta: 0:15:41  Lr: 0.001875  Loss: -1.0064  Acc@1: 81.2500 (81.7783)  Acc@5: 100.0000 (98.9914)  time: 0.3450  data: 0.0007  max mem: 2503
Train: Epoch[4/5]  [1050/3750]  eta: 0:15:37  Lr: 0.001875  Loss: -0.3698  Acc@1: 81.2500 (81.7436)  Acc@5: 100.0000 (98.9772)  time: 0.3450  data: 0.0006  max mem: 2503
Train: Epoch[4/5]  [1060/3750]  eta: 0:15:34  Lr: 0.001875  Loss: -0.8264  Acc@1: 81.2500 (81.7330)  Acc@5: 100.0000 (98.9809)  time: 0.3451  data: 0.0008  max mem: 2503
Train: Epoch[4/5]  [1070/3750]  eta: 0:15:30  Lr: 0.001875  Loss: -0.9226  Acc@1: 81.2500 (81.7227)  Acc@5: 100.0000 (98.9846)  time: 0.3453  data: 0.0009  max mem: 2503
Train: Epoch[4/5]  [1080/3750]  eta: 0:15:27  Lr: 0.001875  Loss: -0.6837  Acc@1: 87.5000 (81.7704)  Acc@5: 100.0000 (98.9824)  time: 0.3466  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [1090/3750]  eta: 0:15:23  Lr: 0.001875  Loss: -0.7859  Acc@1: 87.5000 (81.7713)  Acc@5: 100.0000 (98.9860)  time: 0.3465  data: 0.0003  max mem: 2503
Train: Epoch[4/5]  [1100/3750]  eta: 0:15:20  Lr: 0.001875  Loss: -0.7903  Acc@1: 81.2500 (81.7382)  Acc@5: 100.0000 (98.9896)  time: 0.3442  data: 0.0003  max mem: 2503
Train: Epoch[4/5]  [1110/3750]  eta: 0:15:16  Lr: 0.001875  Loss: -0.5736  Acc@1: 81.2500 (81.7338)  Acc@5: 100.0000 (98.9874)  time: 0.3428  data: 0.0002  max mem: 2503
Train: Epoch[4/5]  [1120/3750]  eta: 0:15:13  Lr: 0.001875  Loss: -0.1320  Acc@1: 81.2500 (81.6849)  Acc@5: 100.0000 (98.9741)  time: 0.3429  data: 0.0002  max mem: 2503
Train: Epoch[4/5]  [1130/3750]  eta: 0:15:09  Lr: 0.001875  Loss: -0.8103  Acc@1: 81.2500 (81.6589)  Acc@5: 100.0000 (98.9777)  time: 0.3436  data: 0.0003  max mem: 2503
Train: Epoch[4/5]  [1140/3750]  eta: 0:15:05  Lr: 0.001875  Loss: -0.6132  Acc@1: 81.2500 (81.6225)  Acc@5: 100.0000 (98.9812)  time: 0.3445  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [1150/3750]  eta: 0:15:02  Lr: 0.001875  Loss: -0.9704  Acc@1: 75.0000 (81.5704)  Acc@5: 100.0000 (98.9737)  time: 0.3446  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [1160/3750]  eta: 0:14:58  Lr: 0.001875  Loss: -0.9855  Acc@1: 75.0000 (81.5461)  Acc@5: 100.0000 (98.9610)  time: 0.3451  data: 0.0006  max mem: 2503
Train: Epoch[4/5]  [1170/3750]  eta: 0:14:55  Lr: 0.001875  Loss: -0.8853  Acc@1: 81.2500 (81.5649)  Acc@5: 100.0000 (98.9646)  time: 0.3452  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [1180/3750]  eta: 0:14:51  Lr: 0.001875  Loss: -0.4562  Acc@1: 81.2500 (81.5252)  Acc@5: 100.0000 (98.9733)  time: 0.3451  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [1190/3750]  eta: 0:14:48  Lr: 0.001875  Loss: -0.7159  Acc@1: 75.0000 (81.5071)  Acc@5: 100.0000 (98.9767)  time: 0.3461  data: 0.0006  max mem: 2503
Train: Epoch[4/5]  [1200/3750]  eta: 0:14:44  Lr: 0.001875  Loss: -0.6304  Acc@1: 75.0000 (81.4634)  Acc@5: 100.0000 (98.9852)  time: 0.3463  data: 0.0007  max mem: 2503
Train: Epoch[4/5]  [1210/3750]  eta: 0:14:41  Lr: 0.001875  Loss: -0.6245  Acc@1: 81.2500 (81.4306)  Acc@5: 100.0000 (98.9884)  time: 0.3467  data: 0.0009  max mem: 2503
Train: Epoch[4/5]  [1220/3750]  eta: 0:14:38  Lr: 0.001875  Loss: -0.6651  Acc@1: 81.2500 (81.4138)  Acc@5: 100.0000 (98.9916)  time: 0.3482  data: 0.0014  max mem: 2503
Train: Epoch[4/5]  [1230/3750]  eta: 0:14:34  Lr: 0.001875  Loss: -0.4762  Acc@1: 81.2500 (81.4226)  Acc@5: 100.0000 (98.9947)  time: 0.3494  data: 0.0018  max mem: 2503
Train: Epoch[4/5]  [1240/3750]  eta: 0:14:31  Lr: 0.001875  Loss: -0.4993  Acc@1: 75.0000 (81.3961)  Acc@5: 100.0000 (98.9877)  time: 0.3511  data: 0.0031  max mem: 2503
Train: Epoch[4/5]  [1250/3750]  eta: 0:14:27  Lr: 0.001875  Loss: -0.5437  Acc@1: 75.0000 (81.4149)  Acc@5: 100.0000 (98.9908)  time: 0.3503  data: 0.0026  max mem: 2503
Train: Epoch[4/5]  [1260/3750]  eta: 0:14:24  Lr: 0.001875  Loss: -0.8634  Acc@1: 87.5000 (81.4532)  Acc@5: 100.0000 (98.9939)  time: 0.3489  data: 0.0011  max mem: 2503
Train: Epoch[4/5]  [1270/3750]  eta: 0:14:21  Lr: 0.001875  Loss: -0.4433  Acc@1: 87.5000 (81.4762)  Acc@5: 100.0000 (98.9821)  time: 0.3511  data: 0.0008  max mem: 2503
Train: Epoch[4/5]  [1280/3750]  eta: 0:14:17  Lr: 0.001875  Loss: -0.9059  Acc@1: 81.2500 (81.4647)  Acc@5: 100.0000 (98.9754)  time: 0.3497  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [1290/3750]  eta: 0:14:14  Lr: 0.001875  Loss: -0.7615  Acc@1: 81.2500 (81.4582)  Acc@5: 100.0000 (98.9737)  time: 0.3478  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [1300/3750]  eta: 0:14:10  Lr: 0.001875  Loss: -0.4538  Acc@1: 81.2500 (81.4566)  Acc@5: 100.0000 (98.9671)  time: 0.3467  data: 0.0003  max mem: 2503
Train: Epoch[4/5]  [1310/3750]  eta: 0:14:07  Lr: 0.001875  Loss: -0.4487  Acc@1: 81.2500 (81.4598)  Acc@5: 100.0000 (98.9607)  time: 0.3440  data: 0.0003  max mem: 2503
Train: Epoch[4/5]  [1320/3750]  eta: 0:14:03  Lr: 0.001875  Loss: -0.9486  Acc@1: 81.2500 (81.4913)  Acc@5: 100.0000 (98.9591)  time: 0.3448  data: 0.0007  max mem: 2503
Train: Epoch[4/5]  [1330/3750]  eta: 0:14:00  Lr: 0.001875  Loss: -0.7831  Acc@1: 81.2500 (81.4942)  Acc@5: 100.0000 (98.9576)  time: 0.3496  data: 0.0019  max mem: 2503
Train: Epoch[4/5]  [1340/3750]  eta: 0:13:56  Lr: 0.001875  Loss: -0.9648  Acc@1: 81.2500 (81.4970)  Acc@5: 100.0000 (98.9560)  time: 0.3515  data: 0.0020  max mem: 2503
Train: Epoch[4/5]  [1350/3750]  eta: 0:13:53  Lr: 0.001875  Loss: -0.6394  Acc@1: 75.0000 (81.4304)  Acc@5: 100.0000 (98.9452)  time: 0.3487  data: 0.0013  max mem: 2503
Train: Epoch[4/5]  [1360/3750]  eta: 0:13:49  Lr: 0.001875  Loss: -0.8690  Acc@1: 75.0000 (81.4429)  Acc@5: 100.0000 (98.9392)  time: 0.3492  data: 0.0013  max mem: 2503
Train: Epoch[4/5]  [1370/3750]  eta: 0:13:46  Lr: 0.001875  Loss: -0.7823  Acc@1: 81.2500 (81.4551)  Acc@5: 100.0000 (98.9378)  time: 0.3524  data: 0.0019  max mem: 2503
Train: Epoch[4/5]  [1380/3750]  eta: 0:13:43  Lr: 0.001875  Loss: -0.3531  Acc@1: 81.2500 (81.4129)  Acc@5: 100.0000 (98.9274)  time: 0.3522  data: 0.0021  max mem: 2503
Train: Epoch[4/5]  [1390/3750]  eta: 0:13:39  Lr: 0.001875  Loss: -0.5545  Acc@1: 75.0000 (81.3938)  Acc@5: 100.0000 (98.9261)  time: 0.3500  data: 0.0017  max mem: 2503
Train: Epoch[4/5]  [1400/3750]  eta: 0:13:36  Lr: 0.001875  Loss: -0.7003  Acc@1: 75.0000 (81.3526)  Acc@5: 100.0000 (98.9204)  time: 0.3491  data: 0.0011  max mem: 2503
Train: Epoch[4/5]  [1410/3750]  eta: 0:13:32  Lr: 0.001875  Loss: -0.7909  Acc@1: 87.5000 (81.3696)  Acc@5: 100.0000 (98.9281)  time: 0.3498  data: 0.0020  max mem: 2503
Train: Epoch[4/5]  [1420/3750]  eta: 0:13:29  Lr: 0.001875  Loss: -0.5740  Acc@1: 87.5000 (81.3863)  Acc@5: 100.0000 (98.9268)  time: 0.3491  data: 0.0018  max mem: 2503
Train: Epoch[4/5]  [1430/3750]  eta: 0:13:25  Lr: 0.001875  Loss: -0.7671  Acc@1: 81.2500 (81.3854)  Acc@5: 100.0000 (98.9256)  time: 0.3471  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [1440/3750]  eta: 0:13:22  Lr: 0.001875  Loss: -0.6944  Acc@1: 81.2500 (81.3714)  Acc@5: 100.0000 (98.9200)  time: 0.3455  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [1450/3750]  eta: 0:13:18  Lr: 0.001875  Loss: -0.9449  Acc@1: 81.2500 (81.3749)  Acc@5: 100.0000 (98.9188)  time: 0.3440  data: 0.0003  max mem: 2503
Train: Epoch[4/5]  [1460/3750]  eta: 0:13:15  Lr: 0.001875  Loss: -0.6228  Acc@1: 81.2500 (81.3527)  Acc@5: 100.0000 (98.9177)  time: 0.3448  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [1470/3750]  eta: 0:13:11  Lr: 0.001875  Loss: -0.7378  Acc@1: 81.2500 (81.3477)  Acc@5: 100.0000 (98.9208)  time: 0.3472  data: 0.0008  max mem: 2503
Train: Epoch[4/5]  [1480/3750]  eta: 0:13:08  Lr: 0.001875  Loss: -0.7990  Acc@1: 81.2500 (81.3428)  Acc@5: 100.0000 (98.9239)  time: 0.3490  data: 0.0013  max mem: 2503
Train: Epoch[4/5]  [1490/3750]  eta: 0:13:04  Lr: 0.001875  Loss: -0.2118  Acc@1: 81.2500 (81.3296)  Acc@5: 100.0000 (98.9269)  time: 0.3491  data: 0.0015  max mem: 2503
Train: Epoch[4/5]  [1500/3750]  eta: 0:13:01  Lr: 0.001875  Loss: -0.8275  Acc@1: 81.2500 (81.3291)  Acc@5: 100.0000 (98.9216)  time: 0.3503  data: 0.0012  max mem: 2503
Train: Epoch[4/5]  [1510/3750]  eta: 0:12:58  Lr: 0.001875  Loss: -0.7343  Acc@1: 81.2500 (81.3327)  Acc@5: 100.0000 (98.9287)  time: 0.3509  data: 0.0014  max mem: 2503
Train: Epoch[4/5]  [1520/3750]  eta: 0:12:54  Lr: 0.001875  Loss: -0.6413  Acc@1: 87.5000 (81.3568)  Acc@5: 100.0000 (98.9357)  time: 0.3506  data: 0.0015  max mem: 2503
Train: Epoch[4/5]  [1530/3750]  eta: 0:12:51  Lr: 0.001875  Loss: -0.9477  Acc@1: 87.5000 (81.3806)  Acc@5: 100.0000 (98.9386)  time: 0.3504  data: 0.0015  max mem: 2503
Train: Epoch[4/5]  [1540/3750]  eta: 0:12:47  Lr: 0.001875  Loss: -0.4215  Acc@1: 75.0000 (81.3392)  Acc@5: 100.0000 (98.9374)  time: 0.3494  data: 0.0015  max mem: 2503
Train: Epoch[4/5]  [1550/3750]  eta: 0:12:44  Lr: 0.001875  Loss: -0.7234  Acc@1: 75.0000 (81.3185)  Acc@5: 100.0000 (98.9362)  time: 0.3490  data: 0.0012  max mem: 2503
Train: Epoch[4/5]  [1560/3750]  eta: 0:12:40  Lr: 0.001875  Loss: -0.8612  Acc@1: 75.0000 (81.2780)  Acc@5: 100.0000 (98.9350)  time: 0.3484  data: 0.0007  max mem: 2503
Train: Epoch[4/5]  [1570/3750]  eta: 0:12:37  Lr: 0.001875  Loss: -0.7013  Acc@1: 81.2500 (81.2659)  Acc@5: 100.0000 (98.9378)  time: 0.3477  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [1580/3750]  eta: 0:12:33  Lr: 0.001875  Loss: -0.3226  Acc@1: 81.2500 (81.2698)  Acc@5: 100.0000 (98.9326)  time: 0.3461  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [1590/3750]  eta: 0:12:30  Lr: 0.001875  Loss: -1.0402  Acc@1: 81.2500 (81.2736)  Acc@5: 100.0000 (98.9236)  time: 0.3442  data: 0.0003  max mem: 2503
Train: Epoch[4/5]  [1600/3750]  eta: 0:12:26  Lr: 0.001875  Loss: -0.5713  Acc@1: 81.2500 (81.2695)  Acc@5: 100.0000 (98.9265)  time: 0.3451  data: 0.0007  max mem: 2503
Train: Epoch[4/5]  [1610/3750]  eta: 0:12:23  Lr: 0.001875  Loss: -0.7455  Acc@1: 81.2500 (81.2655)  Acc@5: 100.0000 (98.9215)  time: 0.3490  data: 0.0011  max mem: 2503
Train: Epoch[4/5]  [1620/3750]  eta: 0:12:20  Lr: 0.001875  Loss: -0.5752  Acc@1: 81.2500 (81.2500)  Acc@5: 100.0000 (98.9204)  time: 0.3516  data: 0.0021  max mem: 2503
Train: Epoch[4/5]  [1630/3750]  eta: 0:12:16  Lr: 0.001875  Loss: -0.6942  Acc@1: 75.0000 (81.2423)  Acc@5: 100.0000 (98.9232)  time: 0.3504  data: 0.0019  max mem: 2503
Train: Epoch[4/5]  [1640/3750]  eta: 0:12:13  Lr: 0.001875  Loss: -0.9272  Acc@1: 81.2500 (81.2538)  Acc@5: 100.0000 (98.9260)  time: 0.3498  data: 0.0012  max mem: 2503
Train: Epoch[4/5]  [1650/3750]  eta: 0:12:09  Lr: 0.001875  Loss: -0.7115  Acc@1: 87.5000 (81.2689)  Acc@5: 100.0000 (98.9249)  time: 0.3522  data: 0.0016  max mem: 2503
Train: Epoch[4/5]  [1660/3750]  eta: 0:12:06  Lr: 0.001875  Loss: -0.6283  Acc@1: 81.2500 (81.2613)  Acc@5: 100.0000 (98.9238)  time: 0.3518  data: 0.0019  max mem: 2503
Train: Epoch[4/5]  [1670/3750]  eta: 0:12:02  Lr: 0.001875  Loss: -0.8126  Acc@1: 81.2500 (81.2762)  Acc@5: 100.0000 (98.9228)  time: 0.3513  data: 0.0018  max mem: 2503
Train: Epoch[4/5]  [1680/3750]  eta: 0:11:59  Lr: 0.001875  Loss: -0.7660  Acc@1: 87.5000 (81.2946)  Acc@5: 100.0000 (98.9218)  time: 0.3521  data: 0.0015  max mem: 2503
Train: Epoch[4/5]  [1690/3750]  eta: 0:11:56  Lr: 0.001875  Loss: -0.7966  Acc@1: 87.5000 (81.3017)  Acc@5: 100.0000 (98.9134)  time: 0.3489  data: 0.0009  max mem: 2503
Train: Epoch[4/5]  [1700/3750]  eta: 0:11:52  Lr: 0.001875  Loss: -1.0331  Acc@1: 87.5000 (81.3235)  Acc@5: 100.0000 (98.9124)  time: 0.3477  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [1710/3750]  eta: 0:11:49  Lr: 0.001875  Loss: -0.5552  Acc@1: 87.5000 (81.3413)  Acc@5: 100.0000 (98.9188)  time: 0.3462  data: 0.0003  max mem: 2503
Train: Epoch[4/5]  [1720/3750]  eta: 0:11:45  Lr: 0.001875  Loss: -0.2325  Acc@1: 81.2500 (81.3154)  Acc@5: 100.0000 (98.9178)  time: 0.3437  data: 0.0003  max mem: 2503
Train: Epoch[4/5]  [1730/3750]  eta: 0:11:42  Lr: 0.001875  Loss: -0.6459  Acc@1: 81.2500 (81.3114)  Acc@5: 100.0000 (98.9132)  time: 0.3441  data: 0.0003  max mem: 2503
Train: Epoch[4/5]  [1740/3750]  eta: 0:11:38  Lr: 0.001875  Loss: -0.9250  Acc@1: 87.5000 (81.3505)  Acc@5: 100.0000 (98.9194)  time: 0.3457  data: 0.0007  max mem: 2503
Train: Epoch[4/5]  [1750/3750]  eta: 0:11:35  Lr: 0.001875  Loss: -0.5488  Acc@1: 87.5000 (81.3642)  Acc@5: 100.0000 (98.9256)  time: 0.3479  data: 0.0012  max mem: 2503
Train: Epoch[4/5]  [1760/3750]  eta: 0:11:31  Lr: 0.001875  Loss: -0.5667  Acc@1: 81.2500 (81.3600)  Acc@5: 100.0000 (98.9211)  time: 0.3485  data: 0.0013  max mem: 2503
Train: Epoch[4/5]  [1770/3750]  eta: 0:11:28  Lr: 0.001875  Loss: -0.8166  Acc@1: 81.2500 (81.3488)  Acc@5: 100.0000 (98.9236)  time: 0.3504  data: 0.0027  max mem: 2503
Train: Epoch[4/5]  [1780/3750]  eta: 0:11:24  Lr: 0.001875  Loss: -0.9018  Acc@1: 81.2500 (81.3658)  Acc@5: 100.0000 (98.9227)  time: 0.3528  data: 0.0032  max mem: 2503
Train: Epoch[4/5]  [1790/3750]  eta: 0:11:21  Lr: 0.001875  Loss: -0.7590  Acc@1: 81.2500 (81.3756)  Acc@5: 100.0000 (98.9287)  time: 0.3520  data: 0.0018  max mem: 2503
Train: Epoch[4/5]  [1800/3750]  eta: 0:11:17  Lr: 0.001875  Loss: -0.5842  Acc@1: 81.2500 (81.3749)  Acc@5: 100.0000 (98.9311)  time: 0.3498  data: 0.0015  max mem: 2503
Train: Epoch[4/5]  [1810/3750]  eta: 0:11:14  Lr: 0.001875  Loss: -0.6850  Acc@1: 81.2500 (81.3639)  Acc@5: 100.0000 (98.9336)  time: 0.3495  data: 0.0014  max mem: 2503
Train: Epoch[4/5]  [1820/3750]  eta: 0:11:10  Lr: 0.001875  Loss: -0.8801  Acc@1: 81.2500 (81.3598)  Acc@5: 100.0000 (98.9360)  time: 0.3497  data: 0.0014  max mem: 2503
Train: Epoch[4/5]  [1830/3750]  eta: 0:11:07  Lr: 0.001875  Loss: -0.8405  Acc@1: 81.2500 (81.3558)  Acc@5: 100.0000 (98.9384)  time: 0.3496  data: 0.0013  max mem: 2503
Train: Epoch[4/5]  [1840/3750]  eta: 0:11:04  Lr: 0.001875  Loss: -0.8450  Acc@1: 81.2500 (81.3552)  Acc@5: 100.0000 (98.9442)  time: 0.3486  data: 0.0008  max mem: 2503
Train: Epoch[4/5]  [1850/3750]  eta: 0:11:00  Lr: 0.001875  Loss: -0.2463  Acc@1: 81.2500 (81.3277)  Acc@5: 100.0000 (98.9431)  time: 0.3475  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [1860/3750]  eta: 0:10:57  Lr: 0.001875  Loss: -0.3024  Acc@1: 81.2500 (81.3340)  Acc@5: 100.0000 (98.9387)  time: 0.3457  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [1870/3750]  eta: 0:10:53  Lr: 0.001875  Loss: -0.9007  Acc@1: 81.2500 (81.3302)  Acc@5: 100.0000 (98.9344)  time: 0.3439  data: 0.0003  max mem: 2503
Train: Epoch[4/5]  [1880/3750]  eta: 0:10:50  Lr: 0.001875  Loss: -0.7224  Acc@1: 81.2500 (81.3165)  Acc@5: 100.0000 (98.9334)  time: 0.3447  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [1890/3750]  eta: 0:10:46  Lr: 0.001875  Loss: -0.3468  Acc@1: 81.2500 (81.2963)  Acc@5: 100.0000 (98.9391)  time: 0.3465  data: 0.0008  max mem: 2503
Train: Epoch[4/5]  [1900/3750]  eta: 0:10:43  Lr: 0.001875  Loss: -0.6214  Acc@1: 81.2500 (81.3059)  Acc@5: 100.0000 (98.9348)  time: 0.3477  data: 0.0008  max mem: 2503
Train: Epoch[4/5]  [1910/3750]  eta: 0:10:39  Lr: 0.001875  Loss: -0.8366  Acc@1: 81.2500 (81.3056)  Acc@5: 100.0000 (98.9403)  time: 0.3490  data: 0.0016  max mem: 2503
Train: Epoch[4/5]  [1920/3750]  eta: 0:10:36  Lr: 0.001875  Loss: -0.1872  Acc@1: 81.2500 (81.2825)  Acc@5: 100.0000 (98.9328)  time: 0.3492  data: 0.0017  max mem: 2503
Train: Epoch[4/5]  [1930/3750]  eta: 0:10:32  Lr: 0.001875  Loss: -0.8050  Acc@1: 81.2500 (81.2727)  Acc@5: 100.0000 (98.9287)  time: 0.3509  data: 0.0015  max mem: 2503
Train: Epoch[4/5]  [1940/3750]  eta: 0:10:29  Lr: 0.001875  Loss: -0.6710  Acc@1: 81.2500 (81.2661)  Acc@5: 100.0000 (98.9310)  time: 0.3517  data: 0.0014  max mem: 2503
Train: Epoch[4/5]  [1950/3750]  eta: 0:10:25  Lr: 0.001875  Loss: -0.1686  Acc@1: 81.2500 (81.2820)  Acc@5: 100.0000 (98.9300)  time: 0.3494  data: 0.0009  max mem: 2503
Train: Epoch[4/5]  [1960/3750]  eta: 0:10:22  Lr: 0.001875  Loss: -0.8471  Acc@1: 81.2500 (81.3010)  Acc@5: 100.0000 (98.9323)  time: 0.3492  data: 0.0013  max mem: 2503
Train: Epoch[4/5]  [1970/3750]  eta: 0:10:18  Lr: 0.001875  Loss: -0.3076  Acc@1: 75.0000 (81.2595)  Acc@5: 100.0000 (98.9346)  time: 0.3495  data: 0.0014  max mem: 2503
Train: Epoch[4/5]  [1980/3750]  eta: 0:10:15  Lr: 0.001875  Loss: -0.6844  Acc@1: 75.0000 (81.2784)  Acc@5: 100.0000 (98.9368)  time: 0.3497  data: 0.0016  max mem: 2503
Train: Epoch[4/5]  [1990/3750]  eta: 0:10:11  Lr: 0.001875  Loss: -0.4167  Acc@1: 87.5000 (81.2814)  Acc@5: 100.0000 (98.9390)  time: 0.3480  data: 0.0012  max mem: 2503
Train: Epoch[4/5]  [2000/3750]  eta: 0:10:08  Lr: 0.001875  Loss: -0.7686  Acc@1: 81.2500 (81.2812)  Acc@5: 100.0000 (98.9443)  time: 0.3457  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [2010/3750]  eta: 0:10:04  Lr: 0.001875  Loss: -0.7488  Acc@1: 81.2500 (81.2749)  Acc@5: 100.0000 (98.9433)  time: 0.3445  data: 0.0003  max mem: 2503
Train: Epoch[4/5]  [2020/3750]  eta: 0:10:01  Lr: 0.001875  Loss: -0.5668  Acc@1: 81.2500 (81.2716)  Acc@5: 100.0000 (98.9454)  time: 0.3438  data: 0.0003  max mem: 2503
Train: Epoch[4/5]  [2030/3750]  eta: 0:09:57  Lr: 0.001875  Loss: -0.7317  Acc@1: 81.2500 (81.2839)  Acc@5: 100.0000 (98.9476)  time: 0.3443  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [2040/3750]  eta: 0:09:54  Lr: 0.001875  Loss: -0.7281  Acc@1: 81.2500 (81.2898)  Acc@5: 100.0000 (98.9435)  time: 0.3462  data: 0.0009  max mem: 2503
Train: Epoch[4/5]  [2050/3750]  eta: 0:09:50  Lr: 0.001875  Loss: -0.9015  Acc@1: 81.2500 (81.2652)  Acc@5: 100.0000 (98.9426)  time: 0.3487  data: 0.0012  max mem: 2503
Train: Epoch[4/5]  [2060/3750]  eta: 0:09:47  Lr: 0.001875  Loss: -0.2957  Acc@1: 81.2500 (81.2803)  Acc@5: 100.0000 (98.9447)  time: 0.3494  data: 0.0011  max mem: 2503
Train: Epoch[4/5]  [2070/3750]  eta: 0:09:44  Lr: 0.001875  Loss: -0.5718  Acc@1: 81.2500 (81.2741)  Acc@5: 100.0000 (98.9437)  time: 0.3486  data: 0.0010  max mem: 2503
Train: Epoch[4/5]  [2080/3750]  eta: 0:09:40  Lr: 0.001875  Loss: -0.4161  Acc@1: 75.0000 (81.2650)  Acc@5: 100.0000 (98.9428)  time: 0.3513  data: 0.0014  max mem: 2503
Train: Epoch[4/5]  [2090/3750]  eta: 0:09:37  Lr: 0.001875  Loss: -0.7996  Acc@1: 75.0000 (81.2560)  Acc@5: 100.0000 (98.9419)  time: 0.3533  data: 0.0021  max mem: 2503
Train: Epoch[4/5]  [2100/3750]  eta: 0:09:33  Lr: 0.001875  Loss: -0.4676  Acc@1: 81.2500 (81.2411)  Acc@5: 100.0000 (98.9350)  time: 0.3506  data: 0.0017  max mem: 2503
Train: Epoch[4/5]  [2110/3750]  eta: 0:09:30  Lr: 0.001875  Loss: -1.1393  Acc@1: 81.2500 (81.2559)  Acc@5: 100.0000 (98.9371)  time: 0.3491  data: 0.0008  max mem: 2503
Train: Epoch[4/5]  [2120/3750]  eta: 0:09:26  Lr: 0.001875  Loss: -0.5580  Acc@1: 81.2500 (81.2500)  Acc@5: 100.0000 (98.9421)  time: 0.3490  data: 0.0010  max mem: 2503
Train: Epoch[4/5]  [2130/3750]  eta: 0:09:23  Lr: 0.001875  Loss: -0.4527  Acc@1: 81.2500 (81.2383)  Acc@5: 100.0000 (98.9412)  time: 0.3478  data: 0.0008  max mem: 2503
Train: Epoch[4/5]  [2140/3750]  eta: 0:09:19  Lr: 0.001875  Loss: -0.3897  Acc@1: 81.2500 (81.2442)  Acc@5: 100.0000 (98.9403)  time: 0.3480  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [2150/3750]  eta: 0:09:16  Lr: 0.001875  Loss: -0.7419  Acc@1: 81.2500 (81.2500)  Acc@5: 100.0000 (98.9453)  time: 0.3464  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [2160/3750]  eta: 0:09:12  Lr: 0.001875  Loss: -0.4666  Acc@1: 75.0000 (81.2124)  Acc@5: 100.0000 (98.9501)  time: 0.3438  data: 0.0003  max mem: 2503
Train: Epoch[4/5]  [2170/3750]  eta: 0:09:09  Lr: 0.001875  Loss: -0.5221  Acc@1: 75.0000 (81.2183)  Acc@5: 100.0000 (98.9492)  time: 0.3438  data: 0.0003  max mem: 2503
Train: Epoch[4/5]  [2180/3750]  eta: 0:09:05  Lr: 0.001875  Loss: -0.8812  Acc@1: 81.2500 (81.2041)  Acc@5: 100.0000 (98.9512)  time: 0.3457  data: 0.0006  max mem: 2503
Train: Epoch[4/5]  [2190/3750]  eta: 0:09:02  Lr: 0.001875  Loss: -0.8748  Acc@1: 81.2500 (81.2015)  Acc@5: 100.0000 (98.9503)  time: 0.3484  data: 0.0011  max mem: 2503
Train: Epoch[4/5]  [2200/3750]  eta: 0:08:58  Lr: 0.001875  Loss: -0.2419  Acc@1: 81.2500 (81.1932)  Acc@5: 100.0000 (98.9465)  time: 0.3492  data: 0.0012  max mem: 2503
Train: Epoch[4/5]  [2210/3750]  eta: 0:08:55  Lr: 0.001875  Loss: -0.9854  Acc@1: 81.2500 (81.2104)  Acc@5: 100.0000 (98.9513)  time: 0.3507  data: 0.0011  max mem: 2503
Train: Epoch[4/5]  [2220/3750]  eta: 0:08:52  Lr: 0.001875  Loss: -0.2179  Acc@1: 81.2500 (81.2106)  Acc@5: 100.0000 (98.9560)  time: 0.3513  data: 0.0011  max mem: 2503
Train: Epoch[4/5]  [2230/3750]  eta: 0:08:48  Lr: 0.001875  Loss: -0.5430  Acc@1: 81.2500 (81.2192)  Acc@5: 100.0000 (98.9607)  time: 0.3530  data: 0.0013  max mem: 2503
Train: Epoch[4/5]  [2240/3750]  eta: 0:08:45  Lr: 0.001875  Loss: -0.6801  Acc@1: 81.2500 (81.2054)  Acc@5: 100.0000 (98.9653)  time: 0.3521  data: 0.0014  max mem: 2503
Train: Epoch[4/5]  [2250/3750]  eta: 0:08:41  Lr: 0.001875  Loss: -0.3605  Acc@1: 81.2500 (81.2195)  Acc@5: 100.0000 (98.9671)  time: 0.3493  data: 0.0011  max mem: 2503
Train: Epoch[4/5]  [2260/3750]  eta: 0:08:38  Lr: 0.001875  Loss: -0.6857  Acc@1: 87.5000 (81.2224)  Acc@5: 100.0000 (98.9717)  time: 0.3488  data: 0.0008  max mem: 2503
Train: Epoch[4/5]  [2270/3750]  eta: 0:08:34  Lr: 0.001875  Loss: -0.7448  Acc@1: 81.2500 (81.2307)  Acc@5: 100.0000 (98.9735)  time: 0.3476  data: 0.0008  max mem: 2503
Train: Epoch[4/5]  [2280/3750]  eta: 0:08:31  Lr: 0.001875  Loss: -0.5619  Acc@1: 81.2500 (81.2445)  Acc@5: 100.0000 (98.9752)  time: 0.3483  data: 0.0006  max mem: 2503
Train: Epoch[4/5]  [2290/3750]  eta: 0:08:27  Lr: 0.001875  Loss: -0.9161  Acc@1: 87.5000 (81.2473)  Acc@5: 100.0000 (98.9742)  time: 0.3465  data: 0.0003  max mem: 2503
Train: Epoch[4/5]  [2300/3750]  eta: 0:08:24  Lr: 0.001875  Loss: -0.4645  Acc@1: 81.2500 (81.2527)  Acc@5: 100.0000 (98.9733)  time: 0.3435  data: 0.0003  max mem: 2503
Train: Epoch[4/5]  [2310/3750]  eta: 0:08:20  Lr: 0.001875  Loss: -0.4463  Acc@1: 81.2500 (81.2419)  Acc@5: 100.0000 (98.9750)  time: 0.3436  data: 0.0003  max mem: 2503
Train: Epoch[4/5]  [2320/3750]  eta: 0:08:17  Lr: 0.001875  Loss: -0.4485  Acc@1: 75.0000 (81.2419)  Acc@5: 100.0000 (98.9794)  time: 0.3458  data: 0.0010  max mem: 2503
Train: Epoch[4/5]  [2330/3750]  eta: 0:08:13  Lr: 0.001875  Loss: -0.6788  Acc@1: 81.2500 (81.2366)  Acc@5: 100.0000 (98.9838)  time: 0.3496  data: 0.0016  max mem: 2503
Train: Epoch[4/5]  [2340/3750]  eta: 0:08:10  Lr: 0.001875  Loss: -0.9444  Acc@1: 81.2500 (81.2046)  Acc@5: 100.0000 (98.9801)  time: 0.3501  data: 0.0013  max mem: 2503
Train: Epoch[4/5]  [2350/3750]  eta: 0:08:06  Lr: 0.001875  Loss: -0.9037  Acc@1: 81.2500 (81.2154)  Acc@5: 100.0000 (98.9845)  time: 0.3494  data: 0.0010  max mem: 2503
Train: Epoch[4/5]  [2360/3750]  eta: 0:08:03  Lr: 0.001875  Loss: -0.6531  Acc@1: 87.5000 (81.2209)  Acc@5: 100.0000 (98.9861)  time: 0.3522  data: 0.0012  max mem: 2503
Train: Epoch[4/5]  [2370/3750]  eta: 0:07:59  Lr: 0.001875  Loss: -0.3947  Acc@1: 81.2500 (81.2236)  Acc@5: 100.0000 (98.9904)  time: 0.3526  data: 0.0012  max mem: 2503
Train: Epoch[4/5]  [2380/3750]  eta: 0:07:56  Lr: 0.001875  Loss: -0.5081  Acc@1: 81.2500 (81.2316)  Acc@5: 100.0000 (98.9868)  time: 0.3512  data: 0.0020  max mem: 2503
Train: Epoch[4/5]  [2390/3750]  eta: 0:07:53  Lr: 0.001875  Loss: -0.6008  Acc@1: 81.2500 (81.2212)  Acc@5: 100.0000 (98.9832)  time: 0.3510  data: 0.0026  max mem: 2503
Train: Epoch[4/5]  [2400/3750]  eta: 0:07:49  Lr: 0.001875  Loss: -0.4970  Acc@1: 81.2500 (81.2084)  Acc@5: 100.0000 (98.9796)  time: 0.3510  data: 0.0014  max mem: 2503
Train: Epoch[4/5]  [2410/3750]  eta: 0:07:46  Lr: 0.001875  Loss: -0.7506  Acc@1: 81.2500 (81.2111)  Acc@5: 100.0000 (98.9735)  time: 0.3488  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [2420/3750]  eta: 0:07:42  Lr: 0.001875  Loss: -1.0179  Acc@1: 81.2500 (81.2139)  Acc@5: 100.0000 (98.9751)  time: 0.3462  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [2430/3750]  eta: 0:07:39  Lr: 0.001875  Loss: -0.7310  Acc@1: 81.2500 (81.2063)  Acc@5: 100.0000 (98.9793)  time: 0.3454  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [2440/3750]  eta: 0:07:35  Lr: 0.001875  Loss: -0.8101  Acc@1: 81.2500 (81.2193)  Acc@5: 100.0000 (98.9810)  time: 0.3446  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [2450/3750]  eta: 0:07:32  Lr: 0.001875  Loss: 0.0634  Acc@1: 81.2500 (81.2194)  Acc@5: 100.0000 (98.9800)  time: 0.3443  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [2460/3750]  eta: 0:07:28  Lr: 0.001875  Loss: -0.2106  Acc@1: 81.2500 (81.2170)  Acc@5: 100.0000 (98.9740)  time: 0.3484  data: 0.0008  max mem: 2503
Train: Epoch[4/5]  [2470/3750]  eta: 0:07:25  Lr: 0.001875  Loss: -1.0510  Acc@1: 81.2500 (81.2323)  Acc@5: 100.0000 (98.9781)  time: 0.3506  data: 0.0011  max mem: 2503
Train: Epoch[4/5]  [2480/3750]  eta: 0:07:21  Lr: 0.001875  Loss: -0.3761  Acc@1: 75.0000 (81.1996)  Acc@5: 100.0000 (98.9797)  time: 0.3489  data: 0.0010  max mem: 2503
Train: Epoch[4/5]  [2490/3750]  eta: 0:07:18  Lr: 0.001875  Loss: -0.7298  Acc@1: 75.0000 (81.1948)  Acc@5: 100.0000 (98.9813)  time: 0.3503  data: 0.0012  max mem: 2503
Train: Epoch[4/5]  [2500/3750]  eta: 0:07:14  Lr: 0.001875  Loss: -0.6877  Acc@1: 81.2500 (81.2050)  Acc@5: 100.0000 (98.9854)  time: 0.3513  data: 0.0015  max mem: 2503
Train: Epoch[4/5]  [2510/3750]  eta: 0:07:11  Lr: 0.001875  Loss: -0.7181  Acc@1: 81.2500 (81.2102)  Acc@5: 100.0000 (98.9870)  time: 0.3507  data: 0.0019  max mem: 2503
Train: Epoch[4/5]  [2520/3750]  eta: 0:07:07  Lr: 0.001875  Loss: -0.0587  Acc@1: 81.2500 (81.2128)  Acc@5: 100.0000 (98.9860)  time: 0.3489  data: 0.0014  max mem: 2503
Train: Epoch[4/5]  [2530/3750]  eta: 0:07:04  Lr: 0.001875  Loss: -0.0559  Acc@1: 75.0000 (81.1981)  Acc@5: 100.0000 (98.9826)  time: 0.3486  data: 0.0008  max mem: 2503
Train: Epoch[4/5]  [2540/3750]  eta: 0:07:00  Lr: 0.001875  Loss: -0.7412  Acc@1: 81.2500 (81.2033)  Acc@5: 100.0000 (98.9866)  time: 0.3517  data: 0.0016  max mem: 2503
Train: Epoch[4/5]  [2550/3750]  eta: 0:06:57  Lr: 0.001875  Loss: -0.5655  Acc@1: 81.2500 (81.2034)  Acc@5: 100.0000 (98.9881)  time: 0.3517  data: 0.0014  max mem: 2503
Train: Epoch[4/5]  [2560/3750]  eta: 0:06:53  Lr: 0.001875  Loss: -0.5291  Acc@1: 81.2500 (81.1963)  Acc@5: 100.0000 (98.9897)  time: 0.3485  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [2570/3750]  eta: 0:06:50  Lr: 0.001875  Loss: -0.4389  Acc@1: 81.2500 (81.1698)  Acc@5: 100.0000 (98.9936)  time: 0.3464  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [2580/3750]  eta: 0:06:46  Lr: 0.001875  Loss: -0.4258  Acc@1: 75.0000 (81.1677)  Acc@5: 100.0000 (98.9926)  time: 0.3448  data: 0.0003  max mem: 2503
Train: Epoch[4/5]  [2590/3750]  eta: 0:06:43  Lr: 0.001875  Loss: -0.6600  Acc@1: 81.2500 (81.1656)  Acc@5: 100.0000 (98.9965)  time: 0.3446  data: 0.0003  max mem: 2503
Train: Epoch[4/5]  [2600/3750]  eta: 0:06:40  Lr: 0.001875  Loss: -0.7636  Acc@1: 81.2500 (81.1563)  Acc@5: 100.0000 (98.9980)  time: 0.3457  data: 0.0006  max mem: 2503
Train: Epoch[4/5]  [2610/3750]  eta: 0:06:36  Lr: 0.001875  Loss: -0.7080  Acc@1: 81.2500 (81.1375)  Acc@5: 100.0000 (99.0018)  time: 0.3488  data: 0.0009  max mem: 2503
Train: Epoch[4/5]  [2620/3750]  eta: 0:06:33  Lr: 0.001875  Loss: -0.6975  Acc@1: 81.2500 (81.1403)  Acc@5: 100.0000 (99.0032)  time: 0.3495  data: 0.0008  max mem: 2503
Train: Epoch[4/5]  [2630/3750]  eta: 0:06:29  Lr: 0.001875  Loss: -0.6592  Acc@1: 81.2500 (81.1455)  Acc@5: 100.0000 (99.0070)  time: 0.3490  data: 0.0015  max mem: 2503
Train: Epoch[4/5]  [2640/3750]  eta: 0:06:26  Lr: 0.001875  Loss: -0.5190  Acc@1: 75.0000 (81.1340)  Acc@5: 100.0000 (99.0084)  time: 0.3510  data: 0.0022  max mem: 2503
Train: Epoch[4/5]  [2650/3750]  eta: 0:06:22  Lr: 0.001875  Loss: -0.6359  Acc@1: 75.0000 (81.1392)  Acc@5: 100.0000 (99.0098)  time: 0.3526  data: 0.0023  max mem: 2503
Train: Epoch[4/5]  [2660/3750]  eta: 0:06:19  Lr: 0.001875  Loss: -0.8091  Acc@1: 81.2500 (81.1443)  Acc@5: 100.0000 (99.0135)  time: 0.3505  data: 0.0016  max mem: 2503
Train: Epoch[4/5]  [2670/3750]  eta: 0:06:15  Lr: 0.001875  Loss: -0.2486  Acc@1: 81.2500 (81.1377)  Acc@5: 100.0000 (99.0102)  time: 0.3500  data: 0.0017  max mem: 2503
Train: Epoch[4/5]  [2680/3750]  eta: 0:06:12  Lr: 0.001875  Loss: -0.9977  Acc@1: 81.2500 (81.1591)  Acc@5: 100.0000 (99.0069)  time: 0.3517  data: 0.0027  max mem: 2503
Train: Epoch[4/5]  [2690/3750]  eta: 0:06:08  Lr: 0.001875  Loss: -0.4330  Acc@1: 81.2500 (81.1501)  Acc@5: 100.0000 (99.0036)  time: 0.3504  data: 0.0018  max mem: 2503
Train: Epoch[4/5]  [2700/3750]  eta: 0:06:05  Lr: 0.001875  Loss: -0.6498  Acc@1: 81.2500 (81.1389)  Acc@5: 100.0000 (99.0027)  time: 0.3481  data: 0.0009  max mem: 2503
Train: Epoch[4/5]  [2710/3750]  eta: 0:06:01  Lr: 0.001875  Loss: -0.4028  Acc@1: 81.2500 (81.1440)  Acc@5: 100.0000 (99.0041)  time: 0.3476  data: 0.0006  max mem: 2503
Train: Epoch[4/5]  [2720/3750]  eta: 0:05:58  Lr: 0.001875  Loss: -0.8001  Acc@1: 81.2500 (81.1558)  Acc@5: 100.0000 (99.0054)  time: 0.3463  data: 0.0003  max mem: 2503
Train: Epoch[4/5]  [2730/3750]  eta: 0:05:54  Lr: 0.001875  Loss: -0.8912  Acc@1: 81.2500 (81.1562)  Acc@5: 100.0000 (99.0022)  time: 0.3440  data: 0.0003  max mem: 2503
Train: Epoch[4/5]  [2740/3750]  eta: 0:05:51  Lr: 0.001875  Loss: -1.0111  Acc@1: 81.2500 (81.1770)  Acc@5: 100.0000 (99.0058)  time: 0.3439  data: 0.0003  max mem: 2503
Train: Epoch[4/5]  [2750/3750]  eta: 0:05:47  Lr: 0.001875  Loss: -0.2577  Acc@1: 81.2500 (81.1637)  Acc@5: 100.0000 (99.0072)  time: 0.3469  data: 0.0009  max mem: 2503
Train: Epoch[4/5]  [2760/3750]  eta: 0:05:44  Lr: 0.001875  Loss: -0.8061  Acc@1: 81.2500 (81.1572)  Acc@5: 100.0000 (99.0062)  time: 0.3522  data: 0.0028  max mem: 2503
Train: Epoch[4/5]  [2770/3750]  eta: 0:05:40  Lr: 0.001875  Loss: -0.7772  Acc@1: 81.2500 (81.1575)  Acc@5: 100.0000 (99.0053)  time: 0.3529  data: 0.0029  max mem: 2503
Train: Epoch[4/5]  [2780/3750]  eta: 0:05:37  Lr: 0.001875  Loss: -0.7238  Acc@1: 81.2500 (81.1601)  Acc@5: 100.0000 (99.0067)  time: 0.3518  data: 0.0016  max mem: 2503
Train: Epoch[4/5]  [2790/3750]  eta: 0:05:34  Lr: 0.001875  Loss: -0.6139  Acc@1: 81.2500 (81.1582)  Acc@5: 100.0000 (99.0035)  time: 0.3536  data: 0.0017  max mem: 2503
Train: Epoch[4/5]  [2800/3750]  eta: 0:05:30  Lr: 0.001875  Loss: -0.5918  Acc@1: 75.0000 (81.1429)  Acc@5: 100.0000 (99.0048)  time: 0.3521  data: 0.0014  max mem: 2503
Train: Epoch[4/5]  [2810/3750]  eta: 0:05:27  Lr: 0.001875  Loss: -0.5684  Acc@1: 75.0000 (81.1455)  Acc@5: 100.0000 (98.9995)  time: 0.3504  data: 0.0014  max mem: 2503
Train: Epoch[4/5]  [2820/3750]  eta: 0:05:23  Lr: 0.001875  Loss: -0.6262  Acc@1: 81.2500 (81.1437)  Acc@5: 100.0000 (99.0030)  time: 0.3500  data: 0.0014  max mem: 2503
Train: Epoch[4/5]  [2830/3750]  eta: 0:05:20  Lr: 0.001875  Loss: -0.5799  Acc@1: 81.2500 (81.1396)  Acc@5: 100.0000 (99.0043)  time: 0.3499  data: 0.0011  max mem: 2503
Train: Epoch[4/5]  [2840/3750]  eta: 0:05:16  Lr: 0.001875  Loss: -0.5583  Acc@1: 81.2500 (81.1268)  Acc@5: 100.0000 (99.0034)  time: 0.3491  data: 0.0007  max mem: 2503
Train: Epoch[4/5]  [2850/3750]  eta: 0:05:13  Lr: 0.001875  Loss: -0.6757  Acc@1: 81.2500 (81.1382)  Acc@5: 100.0000 (99.0047)  time: 0.3482  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [2860/3750]  eta: 0:05:09  Lr: 0.001875  Loss: -0.5425  Acc@1: 81.2500 (81.1451)  Acc@5: 100.0000 (99.0017)  time: 0.3470  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [2870/3750]  eta: 0:05:06  Lr: 0.001875  Loss: -0.6506  Acc@1: 81.2500 (81.1455)  Acc@5: 100.0000 (99.0030)  time: 0.3447  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [2880/3750]  eta: 0:05:02  Lr: 0.001875  Loss: -0.7483  Acc@1: 81.2500 (81.1567)  Acc@5: 100.0000 (99.0043)  time: 0.3448  data: 0.0003  max mem: 2503
Train: Epoch[4/5]  [2890/3750]  eta: 0:04:59  Lr: 0.001875  Loss: -0.7447  Acc@1: 81.2500 (81.1592)  Acc@5: 100.0000 (99.0034)  time: 0.3474  data: 0.0010  max mem: 2503
Train: Epoch[4/5]  [2900/3750]  eta: 0:04:55  Lr: 0.001875  Loss: -0.6619  Acc@1: 81.2500 (81.1724)  Acc@5: 100.0000 (99.0047)  time: 0.3503  data: 0.0019  max mem: 2503
Train: Epoch[4/5]  [2910/3750]  eta: 0:04:52  Lr: 0.001875  Loss: -0.6782  Acc@1: 81.2500 (81.1791)  Acc@5: 100.0000 (99.0081)  time: 0.3506  data: 0.0019  max mem: 2503
Train: Epoch[4/5]  [2920/3750]  eta: 0:04:48  Lr: 0.001875  Loss: -0.3203  Acc@1: 81.2500 (81.1666)  Acc@5: 100.0000 (99.0072)  time: 0.3505  data: 0.0018  max mem: 2503
Train: Epoch[4/5]  [2930/3750]  eta: 0:04:45  Lr: 0.001875  Loss: -0.4250  Acc@1: 81.2500 (81.1647)  Acc@5: 100.0000 (99.0042)  time: 0.3517  data: 0.0014  max mem: 2503
Train: Epoch[4/5]  [2940/3750]  eta: 0:04:41  Lr: 0.001875  Loss: -0.6431  Acc@1: 81.2500 (81.1735)  Acc@5: 100.0000 (99.0054)  time: 0.3529  data: 0.0013  max mem: 2503
Train: Epoch[4/5]  [2950/3750]  eta: 0:04:38  Lr: 0.001875  Loss: -0.5358  Acc@1: 81.2500 (81.1526)  Acc@5: 100.0000 (99.0046)  time: 0.3514  data: 0.0011  max mem: 2503
Train: Epoch[4/5]  [2960/3750]  eta: 0:04:34  Lr: 0.001875  Loss: -0.7030  Acc@1: 81.2500 (81.1592)  Acc@5: 100.0000 (99.0058)  time: 0.3501  data: 0.0007  max mem: 2503
Train: Epoch[4/5]  [2970/3750]  eta: 0:04:31  Lr: 0.001875  Loss: -0.7878  Acc@1: 87.5000 (81.1680)  Acc@5: 100.0000 (99.0092)  time: 0.3516  data: 0.0014  max mem: 2503
Train: Epoch[4/5]  [2980/3750]  eta: 0:04:27  Lr: 0.001875  Loss: -0.8550  Acc@1: 87.5000 (81.1661)  Acc@5: 100.0000 (99.0083)  time: 0.3498  data: 0.0012  max mem: 2503
Train: Epoch[4/5]  [2990/3750]  eta: 0:04:24  Lr: 0.001875  Loss: -0.2519  Acc@1: 81.2500 (81.1622)  Acc@5: 100.0000 (99.0116)  time: 0.3465  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [3000/3750]  eta: 0:04:21  Lr: 0.001875  Loss: -0.6703  Acc@1: 75.0000 (81.1584)  Acc@5: 100.0000 (99.0045)  time: 0.3456  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [3010/3750]  eta: 0:04:17  Lr: 0.001875  Loss: -0.5792  Acc@1: 81.2500 (81.1607)  Acc@5: 100.0000 (99.0037)  time: 0.3447  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [3020/3750]  eta: 0:04:14  Lr: 0.001875  Loss: -0.8561  Acc@1: 81.2500 (81.1466)  Acc@5: 100.0000 (99.0049)  time: 0.3448  data: 0.0003  max mem: 2503
Train: Epoch[4/5]  [3030/3750]  eta: 0:04:10  Lr: 0.001875  Loss: -0.9193  Acc@1: 81.2500 (81.1345)  Acc@5: 100.0000 (99.0082)  time: 0.3453  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [3040/3750]  eta: 0:04:07  Lr: 0.001875  Loss: -0.8140  Acc@1: 81.2500 (81.1226)  Acc@5: 100.0000 (99.0114)  time: 0.3482  data: 0.0009  max mem: 2503
Train: Epoch[4/5]  [3050/3750]  eta: 0:04:03  Lr: 0.001875  Loss: -0.6377  Acc@1: 81.2500 (81.1271)  Acc@5: 100.0000 (99.0106)  time: 0.3509  data: 0.0009  max mem: 2503
Train: Epoch[4/5]  [3060/3750]  eta: 0:04:00  Lr: 0.001875  Loss: -0.9834  Acc@1: 81.2500 (81.1275)  Acc@5: 100.0000 (99.0138)  time: 0.3502  data: 0.0009  max mem: 2503
Train: Epoch[4/5]  [3070/3750]  eta: 0:03:56  Lr: 0.001875  Loss: -0.6019  Acc@1: 75.0000 (81.1096)  Acc@5: 100.0000 (99.0170)  time: 0.3516  data: 0.0018  max mem: 2503
Train: Epoch[4/5]  [3080/3750]  eta: 0:03:53  Lr: 0.001875  Loss: -0.4553  Acc@1: 75.0000 (81.0999)  Acc@5: 100.0000 (99.0141)  time: 0.3554  data: 0.0018  max mem: 2503
Train: Epoch[4/5]  [3090/3750]  eta: 0:03:49  Lr: 0.001875  Loss: -0.4857  Acc@1: 75.0000 (81.1024)  Acc@5: 100.0000 (99.0173)  time: 0.3537  data: 0.0012  max mem: 2503
Train: Epoch[4/5]  [3100/3750]  eta: 0:03:46  Lr: 0.001875  Loss: -0.7668  Acc@1: 87.5000 (81.1150)  Acc@5: 100.0000 (99.0205)  time: 0.3498  data: 0.0014  max mem: 2503
Train: Epoch[4/5]  [3110/3750]  eta: 0:03:42  Lr: 0.001875  Loss: -0.7625  Acc@1: 87.5000 (81.1295)  Acc@5: 100.0000 (99.0196)  time: 0.3496  data: 0.0012  max mem: 2503
Train: Epoch[4/5]  [3120/3750]  eta: 0:03:39  Lr: 0.001875  Loss: -0.4007  Acc@1: 81.2500 (81.1218)  Acc@5: 100.0000 (99.0207)  time: 0.3511  data: 0.0010  max mem: 2503
Train: Epoch[4/5]  [3130/3750]  eta: 0:03:35  Lr: 0.001875  Loss: -1.1019  Acc@1: 81.2500 (81.1402)  Acc@5: 100.0000 (99.0219)  time: 0.3504  data: 0.0008  max mem: 2503
Train: Epoch[4/5]  [3140/3750]  eta: 0:03:32  Lr: 0.001875  Loss: -0.8820  Acc@1: 87.5000 (81.1406)  Acc@5: 100.0000 (99.0250)  time: 0.3489  data: 0.0012  max mem: 2503
Train: Epoch[4/5]  [3150/3750]  eta: 0:03:28  Lr: 0.001875  Loss: -0.6770  Acc@1: 81.2500 (81.1151)  Acc@5: 100.0000 (99.0281)  time: 0.3469  data: 0.0012  max mem: 2503
Train: Epoch[4/5]  [3160/3750]  eta: 0:03:25  Lr: 0.001875  Loss: -0.3837  Acc@1: 81.2500 (81.1155)  Acc@5: 100.0000 (99.0292)  time: 0.3445  data: 0.0003  max mem: 2503
Train: Epoch[4/5]  [3170/3750]  eta: 0:03:21  Lr: 0.001875  Loss: -0.1842  Acc@1: 81.2500 (81.1179)  Acc@5: 100.0000 (99.0283)  time: 0.3447  data: 0.0003  max mem: 2503
Train: Epoch[4/5]  [3180/3750]  eta: 0:03:18  Lr: 0.001875  Loss: -0.7819  Acc@1: 81.2500 (81.1243)  Acc@5: 100.0000 (99.0314)  time: 0.3462  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [3190/3750]  eta: 0:03:14  Lr: 0.001875  Loss: -0.3910  Acc@1: 81.2500 (81.1286)  Acc@5: 100.0000 (99.0344)  time: 0.3473  data: 0.0006  max mem: 2503
Train: Epoch[4/5]  [3200/3750]  eta: 0:03:11  Lr: 0.001875  Loss: -0.8257  Acc@1: 81.2500 (81.1387)  Acc@5: 100.0000 (99.0335)  time: 0.3495  data: 0.0021  max mem: 2503
Train: Epoch[4/5]  [3210/3750]  eta: 0:03:07  Lr: 0.001875  Loss: -0.7877  Acc@1: 81.2500 (81.1468)  Acc@5: 100.0000 (99.0307)  time: 0.3511  data: 0.0021  max mem: 2503
Train: Epoch[4/5]  [3220/3750]  eta: 0:03:04  Lr: 0.001875  Loss: -0.3415  Acc@1: 81.2500 (81.1491)  Acc@5: 100.0000 (99.0317)  time: 0.3533  data: 0.0014  max mem: 2503
Train: Epoch[4/5]  [3230/3750]  eta: 0:03:01  Lr: 0.001875  Loss: -0.5941  Acc@1: 81.2500 (81.1494)  Acc@5: 100.0000 (99.0347)  time: 0.3540  data: 0.0015  max mem: 2503
Train: Epoch[4/5]  [3240/3750]  eta: 0:02:57  Lr: 0.001875  Loss: -0.6737  Acc@1: 81.2500 (81.1555)  Acc@5: 100.0000 (99.0377)  time: 0.3508  data: 0.0009  max mem: 2503
Train: Epoch[4/5]  [3250/3750]  eta: 0:02:54  Lr: 0.001875  Loss: -0.6907  Acc@1: 81.2500 (81.1635)  Acc@5: 100.0000 (99.0368)  time: 0.3497  data: 0.0017  max mem: 2503
Train: Epoch[4/5]  [3260/3750]  eta: 0:02:50  Lr: 0.001875  Loss: -1.0363  Acc@1: 81.2500 (81.1484)  Acc@5: 100.0000 (99.0398)  time: 0.3499  data: 0.0019  max mem: 2503
Train: Epoch[4/5]  [3270/3750]  eta: 0:02:47  Lr: 0.001875  Loss: -0.4874  Acc@1: 81.2500 (81.1449)  Acc@5: 100.0000 (99.0408)  time: 0.3500  data: 0.0011  max mem: 2503
Train: Epoch[4/5]  [3280/3750]  eta: 0:02:43  Lr: 0.001875  Loss: -0.5124  Acc@1: 81.2500 (81.1357)  Acc@5: 100.0000 (99.0437)  time: 0.3484  data: 0.0011  max mem: 2503
Train: Epoch[4/5]  [3290/3750]  eta: 0:02:40  Lr: 0.001875  Loss: -0.4630  Acc@1: 81.2500 (81.1152)  Acc@5: 100.0000 (99.0409)  time: 0.3465  data: 0.0008  max mem: 2503
Train: Epoch[4/5]  [3300/3750]  eta: 0:02:36  Lr: 0.001875  Loss: -0.7505  Acc@1: 81.2500 (81.1137)  Acc@5: 100.0000 (99.0401)  time: 0.3454  data: 0.0003  max mem: 2503
Train: Epoch[4/5]  [3310/3750]  eta: 0:02:33  Lr: 0.001875  Loss: -1.0320  Acc@1: 87.5000 (81.1330)  Acc@5: 100.0000 (99.0392)  time: 0.3447  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [3320/3750]  eta: 0:02:29  Lr: 0.001875  Loss: -0.7505  Acc@1: 81.2500 (81.1239)  Acc@5: 100.0000 (99.0364)  time: 0.3447  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [3330/3750]  eta: 0:02:26  Lr: 0.001875  Loss: -0.7345  Acc@1: 87.5000 (81.1393)  Acc@5: 100.0000 (99.0393)  time: 0.3476  data: 0.0007  max mem: 2503
Train: Epoch[4/5]  [3340/3750]  eta: 0:02:22  Lr: 0.001875  Loss: -0.7952  Acc@1: 87.5000 (81.1303)  Acc@5: 100.0000 (99.0422)  time: 0.3503  data: 0.0013  max mem: 2503
Train: Epoch[4/5]  [3350/3750]  eta: 0:02:19  Lr: 0.001875  Loss: -0.4090  Acc@1: 75.0000 (81.1120)  Acc@5: 100.0000 (99.0432)  time: 0.3495  data: 0.0012  max mem: 2503
Train: Epoch[4/5]  [3360/3750]  eta: 0:02:15  Lr: 0.001875  Loss: -0.6164  Acc@1: 81.2500 (81.1180)  Acc@5: 100.0000 (99.0442)  time: 0.3506  data: 0.0010  max mem: 2503
Train: Epoch[4/5]  [3370/3750]  eta: 0:02:12  Lr: 0.001875  Loss: -0.8347  Acc@1: 81.2500 (81.1276)  Acc@5: 100.0000 (99.0470)  time: 0.3544  data: 0.0016  max mem: 2503
Train: Epoch[4/5]  [3380/3750]  eta: 0:02:08  Lr: 0.001875  Loss: -0.8402  Acc@1: 87.5000 (81.1409)  Acc@5: 100.0000 (99.0480)  time: 0.3531  data: 0.0017  max mem: 2503
Train: Epoch[4/5]  [3390/3750]  eta: 0:02:05  Lr: 0.001875  Loss: -0.7923  Acc@1: 81.2500 (81.1357)  Acc@5: 100.0000 (99.0508)  time: 0.3489  data: 0.0010  max mem: 2503
Train: Epoch[4/5]  [3400/3750]  eta: 0:02:01  Lr: 0.001875  Loss: -0.2980  Acc@1: 81.2500 (81.1416)  Acc@5: 100.0000 (99.0536)  time: 0.3503  data: 0.0010  max mem: 2503
Train: Epoch[4/5]  [3410/3750]  eta: 0:01:58  Lr: 0.001875  Loss: -0.8385  Acc@1: 75.0000 (81.1327)  Acc@5: 100.0000 (99.0527)  time: 0.3529  data: 0.0018  max mem: 2503
Train: Epoch[4/5]  [3420/3750]  eta: 0:01:54  Lr: 0.001875  Loss: -0.3098  Acc@1: 75.0000 (81.1148)  Acc@5: 100.0000 (99.0536)  time: 0.3504  data: 0.0013  max mem: 2503
Train: Epoch[4/5]  [3430/3750]  eta: 0:01:51  Lr: 0.001875  Loss: -0.8057  Acc@1: 81.2500 (81.1243)  Acc@5: 100.0000 (99.0509)  time: 0.3470  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [3440/3750]  eta: 0:01:47  Lr: 0.001875  Loss: -0.9402  Acc@1: 87.5000 (81.1447)  Acc@5: 100.0000 (99.0519)  time: 0.3452  data: 0.0003  max mem: 2503
Train: Epoch[4/5]  [3450/3750]  eta: 0:01:44  Lr: 0.001875  Loss: -0.5436  Acc@1: 81.2500 (81.1468)  Acc@5: 100.0000 (99.0528)  time: 0.3438  data: 0.0003  max mem: 2503
Train: Epoch[4/5]  [3460/3750]  eta: 0:01:40  Lr: 0.001875  Loss: -0.7577  Acc@1: 81.2500 (81.1507)  Acc@5: 100.0000 (99.0537)  time: 0.3437  data: 0.0003  max mem: 2503
Train: Epoch[4/5]  [3470/3750]  eta: 0:01:37  Lr: 0.001875  Loss: -0.7608  Acc@1: 81.2500 (81.1492)  Acc@5: 100.0000 (99.0511)  time: 0.3464  data: 0.0012  max mem: 2503
Train: Epoch[4/5]  [3480/3750]  eta: 0:01:34  Lr: 0.001875  Loss: -0.6876  Acc@1: 81.2500 (81.1584)  Acc@5: 100.0000 (99.0538)  time: 0.3506  data: 0.0029  max mem: 2503
Train: Epoch[4/5]  [3490/3750]  eta: 0:01:30  Lr: 0.001875  Loss: -0.4716  Acc@1: 81.2500 (81.1372)  Acc@5: 100.0000 (99.0547)  time: 0.3516  data: 0.0030  max mem: 2503
Train: Epoch[4/5]  [3500/3750]  eta: 0:01:27  Lr: 0.001875  Loss: -0.8977  Acc@1: 75.0000 (81.1286)  Acc@5: 100.0000 (99.0538)  time: 0.3516  data: 0.0019  max mem: 2503
Train: Epoch[4/5]  [3510/3750]  eta: 0:01:23  Lr: 0.001875  Loss: -0.5106  Acc@1: 81.2500 (81.1379)  Acc@5: 100.0000 (99.0548)  time: 0.3530  data: 0.0024  max mem: 2503
Train: Epoch[4/5]  [3520/3750]  eta: 0:01:20  Lr: 0.001875  Loss: -0.6942  Acc@1: 81.2500 (81.1364)  Acc@5: 100.0000 (99.0574)  time: 0.3533  data: 0.0024  max mem: 2503
Train: Epoch[4/5]  [3530/3750]  eta: 0:01:16  Lr: 0.001875  Loss: -0.8510  Acc@1: 87.5000 (81.1509)  Acc@5: 100.0000 (99.0583)  time: 0.3511  data: 0.0016  max mem: 2503
Train: Epoch[4/5]  [3540/3750]  eta: 0:01:13  Lr: 0.001875  Loss: -0.5454  Acc@1: 81.2500 (81.1317)  Acc@5: 100.0000 (99.0557)  time: 0.3493  data: 0.0011  max mem: 2503
Train: Epoch[4/5]  [3550/3750]  eta: 0:01:09  Lr: 0.001875  Loss: -0.4073  Acc@1: 75.0000 (81.1268)  Acc@5: 100.0000 (99.0548)  time: 0.3497  data: 0.0012  max mem: 2503
Train: Epoch[4/5]  [3560/3750]  eta: 0:01:06  Lr: 0.001875  Loss: -0.7730  Acc@1: 81.2500 (81.1201)  Acc@5: 100.0000 (99.0540)  time: 0.3495  data: 0.0012  max mem: 2503
Train: Epoch[4/5]  [3570/3750]  eta: 0:01:02  Lr: 0.001875  Loss: -0.3726  Acc@1: 81.2500 (81.1170)  Acc@5: 100.0000 (99.0514)  time: 0.3475  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [3580/3750]  eta: 0:00:59  Lr: 0.001875  Loss: -0.7209  Acc@1: 81.2500 (81.1104)  Acc@5: 100.0000 (99.0523)  time: 0.3452  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [3590/3750]  eta: 0:00:55  Lr: 0.001875  Loss: -0.6359  Acc@1: 81.2500 (81.1212)  Acc@5: 100.0000 (99.0532)  time: 0.3438  data: 0.0003  max mem: 2503
Train: Epoch[4/5]  [3600/3750]  eta: 0:00:52  Lr: 0.001875  Loss: -0.8830  Acc@1: 81.2500 (81.1250)  Acc@5: 100.0000 (99.0541)  time: 0.3437  data: 0.0003  max mem: 2503
Train: Epoch[4/5]  [3610/3750]  eta: 0:00:48  Lr: 0.001875  Loss: -0.9680  Acc@1: 81.2500 (81.1358)  Acc@5: 100.0000 (99.0550)  time: 0.3465  data: 0.0006  max mem: 2503
Train: Epoch[4/5]  [3620/3750]  eta: 0:00:45  Lr: 0.001875  Loss: -0.8499  Acc@1: 87.5000 (81.1516)  Acc@5: 100.0000 (99.0559)  time: 0.3507  data: 0.0016  max mem: 2503
Train: Epoch[4/5]  [3630/3750]  eta: 0:00:41  Lr: 0.001875  Loss: -0.3372  Acc@1: 87.5000 (81.1588)  Acc@5: 100.0000 (99.0550)  time: 0.3501  data: 0.0016  max mem: 2503
Train: Epoch[4/5]  [3640/3750]  eta: 0:00:38  Lr: 0.001875  Loss: -0.7525  Acc@1: 81.2500 (81.1676)  Acc@5: 100.0000 (99.0525)  time: 0.3513  data: 0.0014  max mem: 2503
Train: Epoch[4/5]  [3650/3750]  eta: 0:00:34  Lr: 0.001875  Loss: -0.7451  Acc@1: 81.2500 (81.1524)  Acc@5: 100.0000 (99.0551)  time: 0.3545  data: 0.0025  max mem: 2503
Train: Epoch[4/5]  [3660/3750]  eta: 0:00:31  Lr: 0.001875  Loss: -1.0458  Acc@1: 81.2500 (81.1578)  Acc@5: 100.0000 (99.0508)  time: 0.3516  data: 0.0019  max mem: 2503
Train: Epoch[4/5]  [3670/3750]  eta: 0:00:27  Lr: 0.001875  Loss: -0.6198  Acc@1: 81.2500 (81.1564)  Acc@5: 100.0000 (99.0517)  time: 0.3503  data: 0.0017  max mem: 2503
Train: Epoch[4/5]  [3680/3750]  eta: 0:00:24  Lr: 0.001875  Loss: -0.3589  Acc@1: 81.2500 (81.1515)  Acc@5: 100.0000 (99.0543)  time: 0.3506  data: 0.0021  max mem: 2503
Train: Epoch[4/5]  [3690/3750]  eta: 0:00:20  Lr: 0.001875  Loss: -0.8713  Acc@1: 75.0000 (81.1332)  Acc@5: 100.0000 (99.0501)  time: 0.3503  data: 0.0016  max mem: 2503
Train: Epoch[4/5]  [3700/3750]  eta: 0:00:17  Lr: 0.001875  Loss: -0.5938  Acc@1: 75.0000 (81.1284)  Acc@5: 100.0000 (99.0476)  time: 0.3489  data: 0.0010  max mem: 2503
Train: Epoch[4/5]  [3710/3750]  eta: 0:00:13  Lr: 0.001875  Loss: -0.5652  Acc@1: 75.0000 (81.1237)  Acc@5: 100.0000 (99.0484)  time: 0.3475  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [3720/3750]  eta: 0:00:10  Lr: 0.001875  Loss: -0.8111  Acc@1: 81.2500 (81.1391)  Acc@5: 100.0000 (99.0476)  time: 0.3464  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [3730/3750]  eta: 0:00:06  Lr: 0.001875  Loss: -0.6660  Acc@1: 81.2500 (81.1445)  Acc@5: 100.0000 (99.0485)  time: 0.3440  data: 0.0003  max mem: 2503
Train: Epoch[4/5]  [3740/3750]  eta: 0:00:03  Lr: 0.001875  Loss: -0.6336  Acc@1: 81.2500 (81.1397)  Acc@5: 100.0000 (99.0477)  time: 0.3447  data: 0.0003  max mem: 2503
Train: Epoch[4/5]  [3749/3750]  eta: 0:00:00  Lr: 0.001875  Loss: -1.0255  Acc@1: 81.2500 (81.1400)  Acc@5: 100.0000 (99.0500)  time: 0.3475  data: 0.0012  max mem: 2503
Train: Epoch[4/5] Total time: 0:21:46 (0.3484 s / it)
{0: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 1: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 2: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 3: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 4: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 5: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 6: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 7: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 8: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 9: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 10: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 11: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 12: {0: 0, 1: 0, 2: 0, 3: 91325, 4: 0}, 13: {0: 0, 1: 0, 2: 0, 3: 91325, 4: 0}, 14: {0: 0, 1: 0, 2: 0, 3: 91325, 4: 0}, 15: {0: 0, 1: 0, 2: 0, 3: 91325, 4: 0}, 16: {0: 0, 1: 0, 2: 0, 3: 0, 4: 240000}, 17: {0: 0, 1: 0, 2: 0, 3: 0, 4: 240000}, 18: {0: 0, 1: 0, 2: 0, 3: 0, 4: 240000}, 19: {0: 0, 1: 0, 2: 0, 3: 0, 4: 240000}}
Averaged stats: Lr: 0.001875  Loss: -1.0255  Acc@1: 81.2500 (81.1400)  Acc@5: 100.0000 (99.0500)
Train: Epoch[5/5]  [   0/3750]  eta: 1:00:35  Lr: 0.001875  Loss: -0.8422  Acc@1: 81.2500 (81.2500)  Acc@5: 100.0000 (100.0000)  time: 0.9694  data: 0.6247  max mem: 2503
Train: Epoch[5/5]  [  10/3750]  eta: 0:25:15  Lr: 0.001875  Loss: -0.7792  Acc@1: 87.5000 (84.0909)  Acc@5: 100.0000 (99.4318)  time: 0.4052  data: 0.0578  max mem: 2503
Train: Epoch[5/5]  [  20/3750]  eta: 0:23:33  Lr: 0.001875  Loss: -0.1723  Acc@1: 81.2500 (82.4405)  Acc@5: 100.0000 (98.8095)  time: 0.3493  data: 0.0013  max mem: 2503
Train: Epoch[5/5]  [  30/3750]  eta: 0:22:54  Lr: 0.001875  Loss: -0.6490  Acc@1: 81.2500 (82.8629)  Acc@5: 100.0000 (99.1935)  time: 0.3498  data: 0.0016  max mem: 2503
Train: Epoch[5/5]  [  40/3750]  eta: 0:22:35  Lr: 0.001875  Loss: -0.6024  Acc@1: 81.2500 (82.1646)  Acc@5: 100.0000 (99.2378)  time: 0.3514  data: 0.0016  max mem: 2503
Train: Epoch[5/5]  [  50/3750]  eta: 0:22:20  Lr: 0.001875  Loss: -1.0204  Acc@1: 81.2500 (82.4755)  Acc@5: 100.0000 (99.2647)  time: 0.3511  data: 0.0013  max mem: 2503
Train: Epoch[5/5]  [  60/3750]  eta: 0:22:08  Lr: 0.001875  Loss: -0.4041  Acc@1: 87.5000 (82.1721)  Acc@5: 100.0000 (99.1803)  time: 0.3493  data: 0.0017  max mem: 2503
Train: Epoch[5/5]  [  70/3750]  eta: 0:22:02  Lr: 0.001875  Loss: -0.7647  Acc@1: 81.2500 (81.5141)  Acc@5: 100.0000 (98.9437)  time: 0.3516  data: 0.0023  max mem: 2503
Train: Epoch[5/5]  [  80/3750]  eta: 0:21:53  Lr: 0.001875  Loss: -0.7489  Acc@1: 81.2500 (81.7130)  Acc@5: 100.0000 (98.9969)  time: 0.3513  data: 0.0019  max mem: 2503
Train: Epoch[5/5]  [  90/3750]  eta: 0:21:45  Lr: 0.001875  Loss: -0.6382  Acc@1: 81.2500 (81.6621)  Acc@5: 100.0000 (99.1071)  time: 0.3472  data: 0.0010  max mem: 2503
Train: Epoch[5/5]  [ 100/3750]  eta: 0:21:37  Lr: 0.001875  Loss: -0.6489  Acc@1: 81.2500 (81.6832)  Acc@5: 100.0000 (99.1955)  time: 0.3456  data: 0.0003  max mem: 2503
Train: Epoch[5/5]  [ 110/3750]  eta: 0:21:30  Lr: 0.001875  Loss: -1.0027  Acc@1: 81.2500 (81.8131)  Acc@5: 100.0000 (99.0991)  time: 0.3445  data: 0.0003  max mem: 2503
Train: Epoch[5/5]  [ 120/3750]  eta: 0:21:23  Lr: 0.001875  Loss: -0.5730  Acc@1: 81.2500 (81.7149)  Acc@5: 100.0000 (99.0702)  time: 0.3433  data: 0.0003  max mem: 2503
Train: Epoch[5/5]  [ 130/3750]  eta: 0:21:17  Lr: 0.001875  Loss: -0.3748  Acc@1: 81.2500 (81.5363)  Acc@5: 100.0000 (99.1412)  time: 0.3437  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [ 140/3750]  eta: 0:21:12  Lr: 0.001875  Loss: -0.3329  Acc@1: 81.2500 (81.5603)  Acc@5: 100.0000 (99.1135)  time: 0.3469  data: 0.0011  max mem: 2503
Train: Epoch[5/5]  [ 150/3750]  eta: 0:21:08  Lr: 0.001875  Loss: -0.5538  Acc@1: 81.2500 (81.6639)  Acc@5: 100.0000 (99.1308)  time: 0.3494  data: 0.0014  max mem: 2503
Train: Epoch[5/5]  [ 160/3750]  eta: 0:21:04  Lr: 0.001875  Loss: -0.5571  Acc@1: 81.2500 (81.6382)  Acc@5: 100.0000 (99.0295)  time: 0.3491  data: 0.0010  max mem: 2503
Train: Epoch[5/5]  [ 170/3750]  eta: 0:20:59  Lr: 0.001875  Loss: -0.4256  Acc@1: 81.2500 (81.7251)  Acc@5: 100.0000 (99.0132)  time: 0.3490  data: 0.0011  max mem: 2503
Train: Epoch[5/5]  [ 180/3750]  eta: 0:20:56  Lr: 0.001875  Loss: -0.8492  Acc@1: 81.2500 (81.8370)  Acc@5: 100.0000 (99.0677)  time: 0.3510  data: 0.0014  max mem: 2503
Train: Epoch[5/5]  [ 190/3750]  eta: 0:20:52  Lr: 0.001875  Loss: -0.7200  Acc@1: 81.2500 (81.8390)  Acc@5: 100.0000 (99.0510)  time: 0.3514  data: 0.0015  max mem: 2503
Train: Epoch[5/5]  [ 200/3750]  eta: 0:20:48  Lr: 0.001875  Loss: -0.8252  Acc@1: 81.2500 (81.9341)  Acc@5: 100.0000 (99.0672)  time: 0.3497  data: 0.0014  max mem: 2503
Train: Epoch[5/5]  [ 210/3750]  eta: 0:20:45  Lr: 0.001875  Loss: -0.7928  Acc@1: 81.2500 (81.6055)  Acc@5: 100.0000 (99.1114)  time: 0.3498  data: 0.0023  max mem: 2503
Train: Epoch[5/5]  [ 220/3750]  eta: 0:20:41  Lr: 0.001875  Loss: -0.8959  Acc@1: 75.0000 (81.5894)  Acc@5: 100.0000 (99.0667)  time: 0.3509  data: 0.0024  max mem: 2503
Train: Epoch[5/5]  [ 230/3750]  eta: 0:20:37  Lr: 0.001875  Loss: -0.5767  Acc@1: 81.2500 (81.4394)  Acc@5: 100.0000 (99.1071)  time: 0.3487  data: 0.0011  max mem: 2503
Train: Epoch[5/5]  [ 240/3750]  eta: 0:20:32  Lr: 0.001875  Loss: -0.7954  Acc@1: 81.2500 (81.5093)  Acc@5: 100.0000 (99.1183)  time: 0.3464  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [ 250/3750]  eta: 0:20:28  Lr: 0.001875  Loss: -0.7618  Acc@1: 81.2500 (81.6733)  Acc@5: 100.0000 (99.1534)  time: 0.3449  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [ 260/3750]  eta: 0:20:23  Lr: 0.001875  Loss: -0.4567  Acc@1: 81.2500 (81.6810)  Acc@5: 100.0000 (99.1140)  time: 0.3428  data: 0.0003  max mem: 2503
Train: Epoch[5/5]  [ 270/3750]  eta: 0:20:19  Lr: 0.001875  Loss: -0.8188  Acc@1: 81.2500 (81.4806)  Acc@5: 100.0000 (99.1006)  time: 0.3435  data: 0.0010  max mem: 2503
Train: Epoch[5/5]  [ 280/3750]  eta: 0:20:15  Lr: 0.001875  Loss: -0.6026  Acc@1: 75.0000 (81.2278)  Acc@5: 100.0000 (99.1103)  time: 0.3464  data: 0.0014  max mem: 2503
Train: Epoch[5/5]  [ 290/3750]  eta: 0:20:12  Lr: 0.001875  Loss: -0.9318  Acc@1: 75.0000 (81.3144)  Acc@5: 100.0000 (99.0979)  time: 0.3499  data: 0.0011  max mem: 2503
Train: Epoch[5/5]  [ 300/3750]  eta: 0:20:08  Lr: 0.001875  Loss: -0.9464  Acc@1: 81.2500 (81.4784)  Acc@5: 100.0000 (99.0864)  time: 0.3491  data: 0.0009  max mem: 2503
Train: Epoch[5/5]  [ 310/3750]  eta: 0:20:04  Lr: 0.001875  Loss: -0.5412  Acc@1: 81.2500 (81.5514)  Acc@5: 100.0000 (99.0957)  time: 0.3466  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [ 320/3750]  eta: 0:20:00  Lr: 0.001875  Loss: -0.7842  Acc@1: 81.2500 (81.4058)  Acc@5: 100.0000 (99.0849)  time: 0.3469  data: 0.0007  max mem: 2503
Train: Epoch[5/5]  [ 330/3750]  eta: 0:19:56  Lr: 0.001875  Loss: -0.6820  Acc@1: 75.0000 (81.3444)  Acc@5: 100.0000 (99.0559)  time: 0.3478  data: 0.0009  max mem: 2503
Train: Epoch[5/5]  [ 340/3750]  eta: 0:19:53  Lr: 0.001875  Loss: -0.6471  Acc@1: 75.0000 (81.3233)  Acc@5: 100.0000 (99.0652)  time: 0.3475  data: 0.0009  max mem: 2503
Train: Epoch[5/5]  [ 350/3750]  eta: 0:19:49  Lr: 0.001875  Loss: -0.9384  Acc@1: 75.0000 (81.3568)  Acc@5: 100.0000 (99.0741)  time: 0.3472  data: 0.0010  max mem: 2503
Train: Epoch[5/5]  [ 360/3750]  eta: 0:19:45  Lr: 0.001875  Loss: -1.1133  Acc@1: 87.5000 (81.4751)  Acc@5: 100.0000 (99.0824)  time: 0.3471  data: 0.0008  max mem: 2503
Train: Epoch[5/5]  [ 370/3750]  eta: 0:19:41  Lr: 0.001875  Loss: -0.6837  Acc@1: 81.2500 (81.4690)  Acc@5: 100.0000 (99.0903)  time: 0.3480  data: 0.0011  max mem: 2503
Train: Epoch[5/5]  [ 380/3750]  eta: 0:19:38  Lr: 0.001875  Loss: -0.3126  Acc@1: 81.2500 (81.4797)  Acc@5: 100.0000 (99.0814)  time: 0.3506  data: 0.0013  max mem: 2503
Train: Epoch[5/5]  [ 390/3750]  eta: 0:19:34  Lr: 0.001875  Loss: -0.7688  Acc@1: 87.5000 (81.5537)  Acc@5: 100.0000 (99.0889)  time: 0.3488  data: 0.0008  max mem: 2503
Train: Epoch[5/5]  [ 400/3750]  eta: 0:19:31  Lr: 0.001875  Loss: -0.3912  Acc@1: 81.2500 (81.4370)  Acc@5: 100.0000 (99.0804)  time: 0.3458  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [ 410/3750]  eta: 0:19:27  Lr: 0.001875  Loss: -0.3985  Acc@1: 75.0000 (81.3717)  Acc@5: 100.0000 (99.0724)  time: 0.3449  data: 0.0003  max mem: 2503
Train: Epoch[5/5]  [ 420/3750]  eta: 0:19:23  Lr: 0.001875  Loss: -0.6177  Acc@1: 75.0000 (81.2352)  Acc@5: 100.0000 (99.0499)  time: 0.3432  data: 0.0002  max mem: 2503
Train: Epoch[5/5]  [ 430/3750]  eta: 0:19:19  Lr: 0.001875  Loss: -0.7890  Acc@1: 75.0000 (81.1775)  Acc@5: 100.0000 (99.0574)  time: 0.3443  data: 0.0016  max mem: 2503
Train: Epoch[5/5]  [ 440/3750]  eta: 0:19:15  Lr: 0.001875  Loss: -0.6096  Acc@1: 75.0000 (81.1366)  Acc@5: 100.0000 (98.9796)  time: 0.3464  data: 0.0021  max mem: 2503
Train: Epoch[5/5]  [ 450/3750]  eta: 0:19:12  Lr: 0.001875  Loss: 0.0365  Acc@1: 81.2500 (81.1807)  Acc@5: 100.0000 (98.9745)  time: 0.3482  data: 0.0021  max mem: 2503
Train: Epoch[5/5]  [ 460/3750]  eta: 0:19:08  Lr: 0.001875  Loss: -0.1728  Acc@1: 81.2500 (81.1958)  Acc@5: 100.0000 (98.9696)  time: 0.3479  data: 0.0021  max mem: 2503
Train: Epoch[5/5]  [ 470/3750]  eta: 0:19:04  Lr: 0.001875  Loss: -0.7200  Acc@1: 87.5000 (81.3031)  Acc@5: 100.0000 (98.9384)  time: 0.3469  data: 0.0011  max mem: 2503
Train: Epoch[5/5]  [ 480/3750]  eta: 0:19:01  Lr: 0.001875  Loss: -0.8992  Acc@1: 87.5000 (81.3150)  Acc@5: 100.0000 (98.9215)  time: 0.3472  data: 0.0010  max mem: 2503
Train: Epoch[5/5]  [ 490/3750]  eta: 0:18:57  Lr: 0.001875  Loss: -0.9407  Acc@1: 81.2500 (81.3646)  Acc@5: 100.0000 (98.9308)  time: 0.3479  data: 0.0010  max mem: 2503
Train: Epoch[5/5]  [ 500/3750]  eta: 0:18:54  Lr: 0.001875  Loss: -0.5616  Acc@1: 81.2500 (81.3872)  Acc@5: 100.0000 (98.9396)  time: 0.3483  data: 0.0010  max mem: 2503
Train: Epoch[5/5]  [ 510/3750]  eta: 0:18:50  Lr: 0.001875  Loss: -0.9889  Acc@1: 81.2500 (81.3601)  Acc@5: 100.0000 (98.9237)  time: 0.3483  data: 0.0015  max mem: 2503
Train: Epoch[5/5]  [ 520/3750]  eta: 0:18:47  Lr: 0.001875  Loss: -0.6059  Acc@1: 81.2500 (81.4060)  Acc@5: 100.0000 (98.9323)  time: 0.3479  data: 0.0013  max mem: 2503
Train: Epoch[5/5]  [ 530/3750]  eta: 0:18:43  Lr: 0.001875  Loss: -0.5524  Acc@1: 81.2500 (81.3795)  Acc@5: 100.0000 (98.9407)  time: 0.3475  data: 0.0008  max mem: 2503
Train: Epoch[5/5]  [ 540/3750]  eta: 0:18:39  Lr: 0.001875  Loss: -0.7139  Acc@1: 81.2500 (81.4233)  Acc@5: 100.0000 (98.9603)  time: 0.3481  data: 0.0009  max mem: 2503
Train: Epoch[5/5]  [ 550/3750]  eta: 0:18:36  Lr: 0.001875  Loss: -0.9009  Acc@1: 87.5000 (81.4769)  Acc@5: 100.0000 (98.9791)  time: 0.3464  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [ 560/3750]  eta: 0:18:32  Lr: 0.001875  Loss: -0.7050  Acc@1: 81.2500 (81.4840)  Acc@5: 100.0000 (98.9750)  time: 0.3446  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [ 570/3750]  eta: 0:18:28  Lr: 0.001875  Loss: -0.9939  Acc@1: 87.5000 (81.5455)  Acc@5: 100.0000 (98.9820)  time: 0.3436  data: 0.0003  max mem: 2503
Train: Epoch[5/5]  [ 580/3750]  eta: 0:18:24  Lr: 0.001875  Loss: -0.7329  Acc@1: 87.5000 (81.5512)  Acc@5: 100.0000 (98.9781)  time: 0.3424  data: 0.0002  max mem: 2503
Train: Epoch[5/5]  [ 590/3750]  eta: 0:18:21  Lr: 0.001875  Loss: -0.4669  Acc@1: 81.2500 (81.5250)  Acc@5: 100.0000 (98.9848)  time: 0.3428  data: 0.0006  max mem: 2503
Train: Epoch[5/5]  [ 600/3750]  eta: 0:18:17  Lr: 0.001875  Loss: -0.8888  Acc@1: 81.2500 (81.6140)  Acc@5: 100.0000 (99.0017)  time: 0.3456  data: 0.0009  max mem: 2503
Train: Epoch[5/5]  [ 610/3750]  eta: 0:18:14  Lr: 0.001875  Loss: -0.8888  Acc@1: 87.5000 (81.6899)  Acc@5: 100.0000 (99.0180)  time: 0.3474  data: 0.0008  max mem: 2503
Train: Epoch[5/5]  [ 620/3750]  eta: 0:18:10  Lr: 0.001875  Loss: -0.8369  Acc@1: 81.2500 (81.6928)  Acc@5: 100.0000 (99.0137)  time: 0.3475  data: 0.0007  max mem: 2503
Train: Epoch[5/5]  [ 630/3750]  eta: 0:18:06  Lr: 0.001875  Loss: -0.6805  Acc@1: 81.2500 (81.7155)  Acc@5: 100.0000 (99.0194)  time: 0.3475  data: 0.0008  max mem: 2503
Train: Epoch[5/5]  [ 640/3750]  eta: 0:18:03  Lr: 0.001875  Loss: -0.7960  Acc@1: 81.2500 (81.6205)  Acc@5: 100.0000 (99.0055)  time: 0.3472  data: 0.0008  max mem: 2503
Train: Epoch[5/5]  [ 650/3750]  eta: 0:17:59  Lr: 0.001875  Loss: -0.9969  Acc@1: 81.2500 (81.6916)  Acc@5: 100.0000 (99.0111)  time: 0.3473  data: 0.0008  max mem: 2503
Train: Epoch[5/5]  [ 660/3750]  eta: 0:17:56  Lr: 0.001875  Loss: -0.9551  Acc@1: 81.2500 (81.7039)  Acc@5: 100.0000 (98.9977)  time: 0.3485  data: 0.0010  max mem: 2503
Train: Epoch[5/5]  [ 670/3750]  eta: 0:17:52  Lr: 0.001875  Loss: -0.6249  Acc@1: 81.2500 (81.6226)  Acc@5: 100.0000 (98.9940)  time: 0.3479  data: 0.0009  max mem: 2503
Train: Epoch[5/5]  [ 680/3750]  eta: 0:17:49  Lr: 0.001875  Loss: -0.3376  Acc@1: 75.0000 (81.5712)  Acc@5: 100.0000 (98.9996)  time: 0.3462  data: 0.0006  max mem: 2503
Train: Epoch[5/5]  [ 690/3750]  eta: 0:17:45  Lr: 0.001875  Loss: -0.7935  Acc@1: 81.2500 (81.5394)  Acc@5: 100.0000 (98.9779)  time: 0.3482  data: 0.0018  max mem: 2503
Train: Epoch[5/5]  [ 700/3750]  eta: 0:17:42  Lr: 0.001875  Loss: -0.7765  Acc@1: 81.2500 (81.5264)  Acc@5: 100.0000 (98.9747)  time: 0.3493  data: 0.0020  max mem: 2503
Train: Epoch[5/5]  [ 710/3750]  eta: 0:17:38  Lr: 0.001875  Loss: -0.9393  Acc@1: 81.2500 (81.5225)  Acc@5: 100.0000 (98.9715)  time: 0.3475  data: 0.0006  max mem: 2503
Train: Epoch[5/5]  [ 720/3750]  eta: 0:17:35  Lr: 0.001875  Loss: -0.5117  Acc@1: 81.2500 (81.4754)  Acc@5: 100.0000 (98.9598)  time: 0.3466  data: 0.0003  max mem: 2503
Train: Epoch[5/5]  [ 730/3750]  eta: 0:17:31  Lr: 0.001875  Loss: -0.8279  Acc@1: 81.2500 (81.4723)  Acc@5: 100.0000 (98.9740)  time: 0.3449  data: 0.0003  max mem: 2503
Train: Epoch[5/5]  [ 740/3750]  eta: 0:17:27  Lr: 0.001875  Loss: -0.5584  Acc@1: 81.2500 (81.4524)  Acc@5: 100.0000 (98.9879)  time: 0.3434  data: 0.0002  max mem: 2503
Train: Epoch[5/5]  [ 750/3750]  eta: 0:17:24  Lr: 0.001875  Loss: -0.8735  Acc@1: 81.2500 (81.4997)  Acc@5: 100.0000 (98.9930)  time: 0.3432  data: 0.0002  max mem: 2503
Train: Epoch[5/5]  [ 760/3750]  eta: 0:17:20  Lr: 0.001875  Loss: -0.7805  Acc@1: 81.2500 (81.4964)  Acc@5: 100.0000 (98.9980)  time: 0.3451  data: 0.0006  max mem: 2503
Train: Epoch[5/5]  [ 770/3750]  eta: 0:17:17  Lr: 0.001875  Loss: -0.8098  Acc@1: 81.2500 (81.4851)  Acc@5: 100.0000 (99.0029)  time: 0.3472  data: 0.0010  max mem: 2503
Train: Epoch[5/5]  [ 780/3750]  eta: 0:17:13  Lr: 0.001875  Loss: -0.1700  Acc@1: 81.2500 (81.4741)  Acc@5: 100.0000 (98.9997)  time: 0.3477  data: 0.0012  max mem: 2503
Train: Epoch[5/5]  [ 790/3750]  eta: 0:17:10  Lr: 0.001875  Loss: -0.4872  Acc@1: 81.2500 (81.5028)  Acc@5: 100.0000 (98.9886)  time: 0.3479  data: 0.0010  max mem: 2503
Train: Epoch[5/5]  [ 800/3750]  eta: 0:17:06  Lr: 0.001875  Loss: -0.3253  Acc@1: 81.2500 (81.4841)  Acc@5: 100.0000 (98.9856)  time: 0.3479  data: 0.0008  max mem: 2503
Train: Epoch[5/5]  [ 810/3750]  eta: 0:17:03  Lr: 0.001875  Loss: -0.4440  Acc@1: 81.2500 (81.5043)  Acc@5: 100.0000 (98.9904)  time: 0.3480  data: 0.0009  max mem: 2503
Train: Epoch[5/5]  [ 820/3750]  eta: 0:16:59  Lr: 0.001875  Loss: -0.8484  Acc@1: 81.2500 (81.4936)  Acc@5: 100.0000 (98.9723)  time: 0.3477  data: 0.0008  max mem: 2503
Train: Epoch[5/5]  [ 830/3750]  eta: 0:16:56  Lr: 0.001875  Loss: -0.3561  Acc@1: 81.2500 (81.4756)  Acc@5: 100.0000 (98.9621)  time: 0.3483  data: 0.0007  max mem: 2503
Train: Epoch[5/5]  [ 840/3750]  eta: 0:16:52  Lr: 0.001875  Loss: -0.5815  Acc@1: 81.2500 (81.4729)  Acc@5: 100.0000 (98.9447)  time: 0.3475  data: 0.0006  max mem: 2503
Train: Epoch[5/5]  [ 850/3750]  eta: 0:16:49  Lr: 0.001875  Loss: -0.3432  Acc@1: 81.2500 (81.4997)  Acc@5: 100.0000 (98.9498)  time: 0.3473  data: 0.0009  max mem: 2503
Train: Epoch[5/5]  [ 860/3750]  eta: 0:16:45  Lr: 0.001875  Loss: -0.5699  Acc@1: 81.2500 (81.4823)  Acc@5: 100.0000 (98.9402)  time: 0.3476  data: 0.0010  max mem: 2503
Train: Epoch[5/5]  [ 870/3750]  eta: 0:16:42  Lr: 0.001875  Loss: -0.6530  Acc@1: 81.2500 (81.5227)  Acc@5: 100.0000 (98.9524)  time: 0.3461  data: 0.0006  max mem: 2503
Train: Epoch[5/5]  [ 880/3750]  eta: 0:16:38  Lr: 0.001875  Loss: -0.4139  Acc@1: 87.5000 (81.5480)  Acc@5: 100.0000 (98.9642)  time: 0.3467  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [ 890/3750]  eta: 0:16:35  Lr: 0.001875  Loss: -0.8541  Acc@1: 81.2500 (81.5586)  Acc@5: 100.0000 (98.9548)  time: 0.3455  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [ 900/3750]  eta: 0:16:31  Lr: 0.001875  Loss: -0.8597  Acc@1: 81.2500 (81.5344)  Acc@5: 100.0000 (98.9595)  time: 0.3442  data: 0.0009  max mem: 2503
Train: Epoch[5/5]  [ 910/3750]  eta: 0:16:28  Lr: 0.001875  Loss: -0.8697  Acc@1: 81.2500 (81.5519)  Acc@5: 100.0000 (98.9709)  time: 0.3459  data: 0.0022  max mem: 2503
Train: Epoch[5/5]  [ 920/3750]  eta: 0:16:24  Lr: 0.001875  Loss: -0.7086  Acc@1: 81.2500 (81.5554)  Acc@5: 100.0000 (98.9617)  time: 0.3475  data: 0.0022  max mem: 2503
Train: Epoch[5/5]  [ 930/3750]  eta: 0:16:21  Lr: 0.001875  Loss: -0.6111  Acc@1: 81.2500 (81.5588)  Acc@5: 100.0000 (98.9729)  time: 0.3480  data: 0.0012  max mem: 2503
Train: Epoch[5/5]  [ 940/3750]  eta: 0:16:17  Lr: 0.001875  Loss: -0.5559  Acc@1: 81.2500 (81.5356)  Acc@5: 100.0000 (98.9772)  time: 0.3475  data: 0.0007  max mem: 2503
Train: Epoch[5/5]  [ 950/3750]  eta: 0:16:14  Lr: 0.001875  Loss: -0.4412  Acc@1: 81.2500 (81.5129)  Acc@5: 100.0000 (98.9813)  time: 0.3475  data: 0.0009  max mem: 2503
Train: Epoch[5/5]  [ 960/3750]  eta: 0:16:10  Lr: 0.001875  Loss: -0.6439  Acc@1: 81.2500 (81.5492)  Acc@5: 100.0000 (98.9789)  time: 0.3478  data: 0.0010  max mem: 2503
Train: Epoch[5/5]  [ 970/3750]  eta: 0:16:07  Lr: 0.001875  Loss: -0.8250  Acc@1: 81.2500 (81.5525)  Acc@5: 100.0000 (98.9701)  time: 0.3499  data: 0.0016  max mem: 2503
Train: Epoch[5/5]  [ 980/3750]  eta: 0:16:03  Lr: 0.001875  Loss: -0.8623  Acc@1: 81.2500 (81.5940)  Acc@5: 100.0000 (98.9679)  time: 0.3504  data: 0.0017  max mem: 2503
Train: Epoch[5/5]  [ 990/3750]  eta: 0:16:00  Lr: 0.001875  Loss: -1.0200  Acc@1: 81.2500 (81.6158)  Acc@5: 100.0000 (98.9657)  time: 0.3497  data: 0.0021  max mem: 2503
Train: Epoch[5/5]  [1000/3750]  eta: 0:15:56  Lr: 0.001875  Loss: -0.7834  Acc@1: 81.2500 (81.6371)  Acc@5: 100.0000 (98.9760)  time: 0.3493  data: 0.0022  max mem: 2503
Train: Epoch[5/5]  [1010/3750]  eta: 0:15:53  Lr: 0.001875  Loss: -0.5968  Acc@1: 81.2500 (81.6395)  Acc@5: 100.0000 (98.9800)  time: 0.3476  data: 0.0011  max mem: 2503
Train: Epoch[5/5]  [1020/3750]  eta: 0:15:49  Lr: 0.001875  Loss: -0.8098  Acc@1: 87.5000 (81.6907)  Acc@5: 100.0000 (98.9900)  time: 0.3475  data: 0.0007  max mem: 2503
Train: Epoch[5/5]  [1030/3750]  eta: 0:15:46  Lr: 0.001875  Loss: -0.6089  Acc@1: 81.2500 (81.6743)  Acc@5: 100.0000 (98.9998)  time: 0.3472  data: 0.0008  max mem: 2503
Train: Epoch[5/5]  [1040/3750]  eta: 0:15:42  Lr: 0.001875  Loss: -0.8950  Acc@1: 81.2500 (81.6703)  Acc@5: 100.0000 (98.9914)  time: 0.3462  data: 0.0007  max mem: 2503
Train: Epoch[5/5]  [1050/3750]  eta: 0:15:39  Lr: 0.001875  Loss: -0.8231  Acc@1: 81.2500 (81.6722)  Acc@5: 100.0000 (99.0010)  time: 0.3454  data: 0.0011  max mem: 2503
Train: Epoch[5/5]  [1060/3750]  eta: 0:15:35  Lr: 0.001875  Loss: -0.5899  Acc@1: 75.0000 (81.6388)  Acc@5: 100.0000 (99.0104)  time: 0.3440  data: 0.0012  max mem: 2503
Train: Epoch[5/5]  [1070/3750]  eta: 0:15:32  Lr: 0.001875  Loss: -0.9175  Acc@1: 81.2500 (81.6760)  Acc@5: 100.0000 (99.0138)  time: 0.3438  data: 0.0011  max mem: 2503
Train: Epoch[5/5]  [1080/3750]  eta: 0:15:28  Lr: 0.001875  Loss: -0.4668  Acc@1: 81.2500 (81.6085)  Acc@5: 100.0000 (99.0171)  time: 0.3451  data: 0.0013  max mem: 2503
Train: Epoch[5/5]  [1090/3750]  eta: 0:15:25  Lr: 0.001875  Loss: -0.8151  Acc@1: 81.2500 (81.6567)  Acc@5: 100.0000 (99.0147)  time: 0.3461  data: 0.0009  max mem: 2503
Train: Epoch[5/5]  [1100/3750]  eta: 0:15:21  Lr: 0.001875  Loss: -0.4225  Acc@1: 87.5000 (81.6644)  Acc@5: 100.0000 (99.0123)  time: 0.3474  data: 0.0006  max mem: 2503
Train: Epoch[5/5]  [1110/3750]  eta: 0:15:18  Lr: 0.001875  Loss: -0.5799  Acc@1: 81.2500 (81.7113)  Acc@5: 100.0000 (99.0212)  time: 0.3482  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [1120/3750]  eta: 0:15:14  Lr: 0.001875  Loss: -0.7299  Acc@1: 87.5000 (81.7574)  Acc@5: 100.0000 (99.0243)  time: 0.3492  data: 0.0009  max mem: 2503
Train: Epoch[5/5]  [1130/3750]  eta: 0:15:11  Lr: 0.001875  Loss: -1.0011  Acc@1: 87.5000 (81.7584)  Acc@5: 100.0000 (99.0219)  time: 0.3489  data: 0.0008  max mem: 2503
Train: Epoch[5/5]  [1140/3750]  eta: 0:15:07  Lr: 0.001875  Loss: -0.2896  Acc@1: 75.0000 (81.6937)  Acc@5: 100.0000 (99.0195)  time: 0.3463  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [1150/3750]  eta: 0:15:04  Lr: 0.001875  Loss: -0.9392  Acc@1: 75.0000 (81.6790)  Acc@5: 100.0000 (99.0226)  time: 0.3455  data: 0.0006  max mem: 2503
Train: Epoch[5/5]  [1160/3750]  eta: 0:15:00  Lr: 0.001875  Loss: -0.6820  Acc@1: 81.2500 (81.6807)  Acc@5: 100.0000 (99.0149)  time: 0.3472  data: 0.0008  max mem: 2503
Train: Epoch[5/5]  [1170/3750]  eta: 0:14:57  Lr: 0.001875  Loss: -0.9250  Acc@1: 87.5000 (81.6983)  Acc@5: 100.0000 (99.0073)  time: 0.3478  data: 0.0010  max mem: 2503
Train: Epoch[5/5]  [1180/3750]  eta: 0:14:53  Lr: 0.001875  Loss: -1.0514  Acc@1: 81.2500 (81.6998)  Acc@5: 100.0000 (99.0051)  time: 0.3489  data: 0.0011  max mem: 2503
Train: Epoch[5/5]  [1190/3750]  eta: 0:14:50  Lr: 0.001875  Loss: -0.6216  Acc@1: 81.2500 (81.6908)  Acc@5: 100.0000 (99.0134)  time: 0.3481  data: 0.0007  max mem: 2503
Train: Epoch[5/5]  [1200/3750]  eta: 0:14:46  Lr: 0.001875  Loss: -0.7209  Acc@1: 81.2500 (81.6871)  Acc@5: 100.0000 (99.0164)  time: 0.3450  data: 0.0003  max mem: 2503
Train: Epoch[5/5]  [1210/3750]  eta: 0:14:43  Lr: 0.001875  Loss: -0.7020  Acc@1: 81.2500 (81.6680)  Acc@5: 100.0000 (99.0246)  time: 0.3444  data: 0.0010  max mem: 2503
Train: Epoch[5/5]  [1220/3750]  eta: 0:14:39  Lr: 0.001875  Loss: -0.4146  Acc@1: 81.2500 (81.6697)  Acc@5: 100.0000 (99.0274)  time: 0.3436  data: 0.0010  max mem: 2503
Train: Epoch[5/5]  [1230/3750]  eta: 0:14:36  Lr: 0.001875  Loss: -0.9994  Acc@1: 87.5000 (81.7120)  Acc@5: 100.0000 (99.0201)  time: 0.3445  data: 0.0007  max mem: 2503
Train: Epoch[5/5]  [1240/3750]  eta: 0:14:32  Lr: 0.001875  Loss: -1.0723  Acc@1: 87.5000 (81.7385)  Acc@5: 100.0000 (99.0179)  time: 0.3470  data: 0.0013  max mem: 2503
Train: Epoch[5/5]  [1250/3750]  eta: 0:14:29  Lr: 0.001875  Loss: -0.6469  Acc@1: 81.2500 (81.7446)  Acc@5: 100.0000 (99.0258)  time: 0.3491  data: 0.0009  max mem: 2503
Train: Epoch[5/5]  [1260/3750]  eta: 0:14:25  Lr: 0.001875  Loss: -0.8785  Acc@1: 81.2500 (81.7456)  Acc@5: 100.0000 (99.0335)  time: 0.3497  data: 0.0009  max mem: 2503
Train: Epoch[5/5]  [1270/3750]  eta: 0:14:22  Lr: 0.001875  Loss: -0.4693  Acc@1: 75.0000 (81.7319)  Acc@5: 100.0000 (99.0313)  time: 0.3478  data: 0.0011  max mem: 2503
Train: Epoch[5/5]  [1280/3750]  eta: 0:14:18  Lr: 0.001875  Loss: -0.5103  Acc@1: 75.0000 (81.7233)  Acc@5: 100.0000 (99.0388)  time: 0.3478  data: 0.0010  max mem: 2503
Train: Epoch[5/5]  [1290/3750]  eta: 0:14:15  Lr: 0.001875  Loss: -0.6997  Acc@1: 87.5000 (81.7390)  Acc@5: 100.0000 (99.0414)  time: 0.3492  data: 0.0011  max mem: 2503
Train: Epoch[5/5]  [1300/3750]  eta: 0:14:11  Lr: 0.001875  Loss: -0.7902  Acc@1: 81.2500 (81.7160)  Acc@5: 100.0000 (99.0392)  time: 0.3490  data: 0.0015  max mem: 2503
Train: Epoch[5/5]  [1310/3750]  eta: 0:14:08  Lr: 0.001875  Loss: -0.8454  Acc@1: 81.2500 (81.7220)  Acc@5: 100.0000 (99.0179)  time: 0.3478  data: 0.0016  max mem: 2503
Train: Epoch[5/5]  [1320/3750]  eta: 0:14:04  Lr: 0.001875  Loss: -0.2329  Acc@1: 81.2500 (81.6947)  Acc@5: 100.0000 (99.0206)  time: 0.3475  data: 0.0008  max mem: 2503
Train: Epoch[5/5]  [1330/3750]  eta: 0:14:01  Lr: 0.001875  Loss: -0.6248  Acc@1: 81.2500 (81.6914)  Acc@5: 100.0000 (99.0092)  time: 0.3480  data: 0.0007  max mem: 2503
Train: Epoch[5/5]  [1340/3750]  eta: 0:13:58  Lr: 0.001875  Loss: -0.6940  Acc@1: 81.2500 (81.6788)  Acc@5: 100.0000 (99.0073)  time: 0.3480  data: 0.0006  max mem: 2503
Train: Epoch[5/5]  [1350/3750]  eta: 0:13:54  Lr: 0.001875  Loss: -0.9631  Acc@1: 87.5000 (81.7172)  Acc@5: 100.0000 (99.0100)  time: 0.3469  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [1360/3750]  eta: 0:13:50  Lr: 0.001875  Loss: -0.4962  Acc@1: 87.5000 (81.7551)  Acc@5: 100.0000 (99.0081)  time: 0.3444  data: 0.0003  max mem: 2503
Train: Epoch[5/5]  [1370/3750]  eta: 0:13:47  Lr: 0.001875  Loss: -0.6754  Acc@1: 81.2500 (81.7423)  Acc@5: 100.0000 (99.0153)  time: 0.3430  data: 0.0002  max mem: 2503
Train: Epoch[5/5]  [1380/3750]  eta: 0:13:43  Lr: 0.001875  Loss: -0.7415  Acc@1: 81.2500 (81.7614)  Acc@5: 100.0000 (99.0224)  time: 0.3432  data: 0.0002  max mem: 2503
Train: Epoch[5/5]  [1390/3750]  eta: 0:13:40  Lr: 0.001875  Loss: -0.7235  Acc@1: 81.2500 (81.7218)  Acc@5: 100.0000 (99.0070)  time: 0.3454  data: 0.0006  max mem: 2503
Train: Epoch[5/5]  [1400/3750]  eta: 0:13:36  Lr: 0.001875  Loss: -0.7447  Acc@1: 75.0000 (81.7006)  Acc@5: 100.0000 (99.0096)  time: 0.3490  data: 0.0015  max mem: 2503
Train: Epoch[5/5]  [1410/3750]  eta: 0:13:33  Lr: 0.001875  Loss: -0.4353  Acc@1: 81.2500 (81.6974)  Acc@5: 100.0000 (99.0167)  time: 0.3497  data: 0.0015  max mem: 2503
Train: Epoch[5/5]  [1420/3750]  eta: 0:13:30  Lr: 0.001875  Loss: -1.0274  Acc@1: 81.2500 (81.6942)  Acc@5: 100.0000 (99.0104)  time: 0.3492  data: 0.0014  max mem: 2503
Train: Epoch[5/5]  [1430/3750]  eta: 0:13:26  Lr: 0.001875  Loss: -0.9223  Acc@1: 81.2500 (81.6911)  Acc@5: 100.0000 (99.0173)  time: 0.3503  data: 0.0017  max mem: 2503
Train: Epoch[5/5]  [1440/3750]  eta: 0:13:23  Lr: 0.001875  Loss: -0.5736  Acc@1: 81.2500 (81.6707)  Acc@5: 100.0000 (99.0154)  time: 0.3491  data: 0.0013  max mem: 2503
Train: Epoch[5/5]  [1450/3750]  eta: 0:13:19  Lr: 0.001875  Loss: -0.0901  Acc@1: 81.2500 (81.6721)  Acc@5: 100.0000 (99.0222)  time: 0.3473  data: 0.0008  max mem: 2503
Train: Epoch[5/5]  [1460/3750]  eta: 0:13:16  Lr: 0.001875  Loss: -0.5033  Acc@1: 75.0000 (81.6350)  Acc@5: 100.0000 (99.0289)  time: 0.3484  data: 0.0007  max mem: 2503
Train: Epoch[5/5]  [1470/3750]  eta: 0:13:12  Lr: 0.001875  Loss: -0.8672  Acc@1: 81.2500 (81.6536)  Acc@5: 100.0000 (99.0185)  time: 0.3498  data: 0.0012  max mem: 2503
Train: Epoch[5/5]  [1480/3750]  eta: 0:13:09  Lr: 0.001875  Loss: -0.5771  Acc@1: 81.2500 (81.6256)  Acc@5: 100.0000 (99.0209)  time: 0.3496  data: 0.0010  max mem: 2503
Train: Epoch[5/5]  [1490/3750]  eta: 0:13:05  Lr: 0.001875  Loss: -0.8477  Acc@1: 81.2500 (81.6482)  Acc@5: 100.0000 (99.0233)  time: 0.3472  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [1500/3750]  eta: 0:13:02  Lr: 0.001875  Loss: -0.8613  Acc@1: 81.2500 (81.6497)  Acc@5: 100.0000 (99.0298)  time: 0.3465  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [1510/3750]  eta: 0:12:58  Lr: 0.001875  Loss: -0.6832  Acc@1: 81.2500 (81.6430)  Acc@5: 100.0000 (99.0321)  time: 0.3451  data: 0.0003  max mem: 2503
Train: Epoch[5/5]  [1520/3750]  eta: 0:12:55  Lr: 0.001875  Loss: -0.2577  Acc@1: 81.2500 (81.6321)  Acc@5: 100.0000 (99.0302)  time: 0.3427  data: 0.0002  max mem: 2503
Train: Epoch[5/5]  [1530/3750]  eta: 0:12:51  Lr: 0.001875  Loss: -0.3693  Acc@1: 81.2500 (81.6133)  Acc@5: 100.0000 (99.0325)  time: 0.3434  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [1540/3750]  eta: 0:12:48  Lr: 0.001875  Loss: -0.2302  Acc@1: 75.0000 (81.6312)  Acc@5: 100.0000 (99.0266)  time: 0.3464  data: 0.0015  max mem: 2503
Train: Epoch[5/5]  [1550/3750]  eta: 0:12:44  Lr: 0.001875  Loss: -0.3738  Acc@1: 75.0000 (81.6046)  Acc@5: 100.0000 (99.0248)  time: 0.3487  data: 0.0017  max mem: 2503
Train: Epoch[5/5]  [1560/3750]  eta: 0:12:41  Lr: 0.001875  Loss: -0.3317  Acc@1: 81.2500 (81.6224)  Acc@5: 100.0000 (99.0271)  time: 0.3482  data: 0.0007  max mem: 2503
Train: Epoch[5/5]  [1570/3750]  eta: 0:12:37  Lr: 0.001875  Loss: -0.6367  Acc@1: 81.2500 (81.5961)  Acc@5: 100.0000 (99.0253)  time: 0.3478  data: 0.0011  max mem: 2503
Train: Epoch[5/5]  [1580/3750]  eta: 0:12:34  Lr: 0.001875  Loss: -0.7015  Acc@1: 81.2500 (81.6058)  Acc@5: 100.0000 (99.0196)  time: 0.3481  data: 0.0011  max mem: 2503
Train: Epoch[5/5]  [1590/3750]  eta: 0:12:30  Lr: 0.001875  Loss: -0.8315  Acc@1: 81.2500 (81.6153)  Acc@5: 100.0000 (99.0179)  time: 0.3483  data: 0.0009  max mem: 2503
Train: Epoch[5/5]  [1600/3750]  eta: 0:12:27  Lr: 0.001875  Loss: -0.8287  Acc@1: 81.2500 (81.6131)  Acc@5: 100.0000 (99.0162)  time: 0.3480  data: 0.0012  max mem: 2503
Train: Epoch[5/5]  [1610/3750]  eta: 0:12:23  Lr: 0.001875  Loss: -0.5404  Acc@1: 87.5000 (81.6380)  Acc@5: 100.0000 (99.0223)  time: 0.3475  data: 0.0010  max mem: 2503
Train: Epoch[5/5]  [1620/3750]  eta: 0:12:20  Lr: 0.001875  Loss: -0.7046  Acc@1: 81.2500 (81.6317)  Acc@5: 100.0000 (99.0207)  time: 0.3491  data: 0.0014  max mem: 2503
Train: Epoch[5/5]  [1630/3750]  eta: 0:12:17  Lr: 0.001875  Loss: -0.5452  Acc@1: 81.2500 (81.6102)  Acc@5: 100.0000 (99.0228)  time: 0.3499  data: 0.0016  max mem: 2503
Train: Epoch[5/5]  [1640/3750]  eta: 0:12:13  Lr: 0.001875  Loss: -0.5220  Acc@1: 81.2500 (81.6118)  Acc@5: 100.0000 (99.0212)  time: 0.3483  data: 0.0009  max mem: 2503
Train: Epoch[5/5]  [1650/3750]  eta: 0:12:10  Lr: 0.001875  Loss: -0.2936  Acc@1: 81.2500 (81.6210)  Acc@5: 100.0000 (99.0157)  time: 0.3465  data: 0.0006  max mem: 2503
Train: Epoch[5/5]  [1660/3750]  eta: 0:12:06  Lr: 0.001875  Loss: -0.6229  Acc@1: 81.2500 (81.6150)  Acc@5: 100.0000 (99.0179)  time: 0.3451  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [1670/3750]  eta: 0:12:03  Lr: 0.001875  Loss: -0.8477  Acc@1: 81.2500 (81.6315)  Acc@5: 100.0000 (99.0238)  time: 0.3438  data: 0.0003  max mem: 2503
Train: Epoch[5/5]  [1680/3750]  eta: 0:11:59  Lr: 0.001875  Loss: -0.9960  Acc@1: 81.2500 (81.6515)  Acc@5: 100.0000 (99.0259)  time: 0.3430  data: 0.0003  max mem: 2503
Train: Epoch[5/5]  [1690/3750]  eta: 0:11:55  Lr: 0.001875  Loss: -0.9671  Acc@1: 81.2500 (81.6455)  Acc@5: 100.0000 (99.0242)  time: 0.3450  data: 0.0010  max mem: 2503
Train: Epoch[5/5]  [1700/3750]  eta: 0:11:52  Lr: 0.001875  Loss: -0.6132  Acc@1: 75.0000 (81.6432)  Acc@5: 100.0000 (99.0263)  time: 0.3486  data: 0.0015  max mem: 2503
Train: Epoch[5/5]  [1710/3750]  eta: 0:11:49  Lr: 0.001875  Loss: -0.7365  Acc@1: 81.2500 (81.6518)  Acc@5: 100.0000 (99.0174)  time: 0.3496  data: 0.0013  max mem: 2503
Train: Epoch[5/5]  [1720/3750]  eta: 0:11:45  Lr: 0.001875  Loss: -1.1210  Acc@1: 81.2500 (81.6386)  Acc@5: 100.0000 (99.0195)  time: 0.3479  data: 0.0009  max mem: 2503
Train: Epoch[5/5]  [1730/3750]  eta: 0:11:42  Lr: 0.001875  Loss: -0.8188  Acc@1: 75.0000 (81.6147)  Acc@5: 100.0000 (99.0251)  time: 0.3474  data: 0.0007  max mem: 2503
Train: Epoch[5/5]  [1740/3750]  eta: 0:11:38  Lr: 0.001875  Loss: -0.9118  Acc@1: 75.0000 (81.5839)  Acc@5: 100.0000 (99.0235)  time: 0.3477  data: 0.0006  max mem: 2503
Train: Epoch[5/5]  [1750/3750]  eta: 0:11:35  Lr: 0.001875  Loss: -0.7976  Acc@1: 81.2500 (81.5927)  Acc@5: 100.0000 (99.0184)  time: 0.3475  data: 0.0008  max mem: 2503
Train: Epoch[5/5]  [1760/3750]  eta: 0:11:31  Lr: 0.001875  Loss: -0.7636  Acc@1: 81.2500 (81.5978)  Acc@5: 100.0000 (99.0169)  time: 0.3483  data: 0.0012  max mem: 2503
Train: Epoch[5/5]  [1770/3750]  eta: 0:11:28  Lr: 0.001875  Loss: -0.1686  Acc@1: 75.0000 (81.5535)  Acc@5: 100.0000 (99.0119)  time: 0.3491  data: 0.0017  max mem: 2503
Train: Epoch[5/5]  [1780/3750]  eta: 0:11:24  Lr: 0.001875  Loss: -0.5058  Acc@1: 75.0000 (81.5553)  Acc@5: 100.0000 (99.0104)  time: 0.3485  data: 0.0013  max mem: 2503
Train: Epoch[5/5]  [1790/3750]  eta: 0:11:21  Lr: 0.001875  Loss: -0.3997  Acc@1: 81.2500 (81.5536)  Acc@5: 100.0000 (99.0159)  time: 0.3473  data: 0.0007  max mem: 2503
Train: Epoch[5/5]  [1800/3750]  eta: 0:11:17  Lr: 0.001875  Loss: -0.5806  Acc@1: 81.2500 (81.5380)  Acc@5: 100.0000 (99.0110)  time: 0.3462  data: 0.0006  max mem: 2503
Train: Epoch[5/5]  [1810/3750]  eta: 0:11:14  Lr: 0.001875  Loss: -0.8116  Acc@1: 81.2500 (81.5399)  Acc@5: 100.0000 (99.0026)  time: 0.3450  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [1820/3750]  eta: 0:11:10  Lr: 0.001875  Loss: -0.9798  Acc@1: 75.0000 (81.5383)  Acc@5: 100.0000 (99.0081)  time: 0.3444  data: 0.0003  max mem: 2503
Train: Epoch[5/5]  [1830/3750]  eta: 0:11:07  Lr: 0.001875  Loss: -0.7979  Acc@1: 81.2500 (81.5504)  Acc@5: 100.0000 (99.0135)  time: 0.3443  data: 0.0009  max mem: 2503
Train: Epoch[5/5]  [1840/3750]  eta: 0:11:03  Lr: 0.001875  Loss: -0.7836  Acc@1: 87.5000 (81.5420)  Acc@5: 100.0000 (99.0053)  time: 0.3446  data: 0.0010  max mem: 2503
Train: Epoch[5/5]  [1850/3750]  eta: 0:11:00  Lr: 0.001875  Loss: -0.6868  Acc@1: 81.2500 (81.5640)  Acc@5: 100.0000 (99.0107)  time: 0.3466  data: 0.0008  max mem: 2503
Train: Epoch[5/5]  [1860/3750]  eta: 0:10:56  Lr: 0.001875  Loss: -0.7885  Acc@1: 81.2500 (81.5657)  Acc@5: 100.0000 (99.0093)  time: 0.3480  data: 0.0009  max mem: 2503
Train: Epoch[5/5]  [1870/3750]  eta: 0:10:53  Lr: 0.001875  Loss: -0.8428  Acc@1: 81.2500 (81.5874)  Acc@5: 100.0000 (99.0045)  time: 0.3466  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [1880/3750]  eta: 0:10:49  Lr: 0.001875  Loss: -0.7684  Acc@1: 81.2500 (81.5856)  Acc@5: 100.0000 (99.0098)  time: 0.3469  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [1890/3750]  eta: 0:10:46  Lr: 0.001875  Loss: -0.7523  Acc@1: 81.2500 (81.5937)  Acc@5: 100.0000 (99.0118)  time: 0.3485  data: 0.0009  max mem: 2503
Train: Epoch[5/5]  [1900/3750]  eta: 0:10:42  Lr: 0.001875  Loss: -0.4849  Acc@1: 81.2500 (81.5722)  Acc@5: 100.0000 (99.0104)  time: 0.3499  data: 0.0012  max mem: 2503
Train: Epoch[5/5]  [1910/3750]  eta: 0:10:39  Lr: 0.001875  Loss: -0.6740  Acc@1: 81.2500 (81.5476)  Acc@5: 100.0000 (99.0090)  time: 0.3500  data: 0.0012  max mem: 2503
Train: Epoch[5/5]  [1920/3750]  eta: 0:10:36  Lr: 0.001875  Loss: -0.7537  Acc@1: 81.2500 (81.5688)  Acc@5: 100.0000 (99.0077)  time: 0.3476  data: 0.0008  max mem: 2503
Train: Epoch[5/5]  [1930/3750]  eta: 0:10:32  Lr: 0.001875  Loss: -0.4459  Acc@1: 81.2500 (81.5607)  Acc@5: 100.0000 (99.0063)  time: 0.3480  data: 0.0011  max mem: 2503
Train: Epoch[5/5]  [1940/3750]  eta: 0:10:29  Lr: 0.001875  Loss: -1.0221  Acc@1: 75.0000 (81.5462)  Acc@5: 100.0000 (99.0115)  time: 0.3499  data: 0.0022  max mem: 2503
Train: Epoch[5/5]  [1950/3750]  eta: 0:10:25  Lr: 0.001875  Loss: -0.7190  Acc@1: 75.0000 (81.5447)  Acc@5: 100.0000 (99.0101)  time: 0.3493  data: 0.0017  max mem: 2503
Train: Epoch[5/5]  [1960/3750]  eta: 0:10:22  Lr: 0.001875  Loss: -0.8788  Acc@1: 81.2500 (81.5432)  Acc@5: 100.0000 (99.0120)  time: 0.3472  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [1970/3750]  eta: 0:10:18  Lr: 0.001875  Loss: -0.5960  Acc@1: 81.2500 (81.5512)  Acc@5: 100.0000 (99.0138)  time: 0.3447  data: 0.0003  max mem: 2503
Train: Epoch[5/5]  [1980/3750]  eta: 0:10:15  Lr: 0.001875  Loss: -0.7209  Acc@1: 81.2500 (81.5403)  Acc@5: 100.0000 (99.0125)  time: 0.3434  data: 0.0002  max mem: 2503
Train: Epoch[5/5]  [1990/3750]  eta: 0:10:11  Lr: 0.001875  Loss: -0.7527  Acc@1: 81.2500 (81.5482)  Acc@5: 100.0000 (99.0112)  time: 0.3431  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [2000/3750]  eta: 0:10:08  Lr: 0.001875  Loss: -0.4277  Acc@1: 87.5000 (81.5623)  Acc@5: 100.0000 (99.0099)  time: 0.3443  data: 0.0006  max mem: 2503
Train: Epoch[5/5]  [2010/3750]  eta: 0:10:04  Lr: 0.001875  Loss: -0.7994  Acc@1: 81.2500 (81.5484)  Acc@5: 100.0000 (99.0055)  time: 0.3472  data: 0.0011  max mem: 2503
Train: Epoch[5/5]  [2020/3750]  eta: 0:10:01  Lr: 0.001875  Loss: -0.7373  Acc@1: 81.2500 (81.5778)  Acc@5: 100.0000 (99.0042)  time: 0.3479  data: 0.0010  max mem: 2503
Train: Epoch[5/5]  [2030/3750]  eta: 0:09:57  Lr: 0.001875  Loss: -1.0081  Acc@1: 87.5000 (81.6039)  Acc@5: 100.0000 (99.0060)  time: 0.3468  data: 0.0006  max mem: 2503
Train: Epoch[5/5]  [2040/3750]  eta: 0:09:54  Lr: 0.001875  Loss: -0.6633  Acc@1: 81.2500 (81.5899)  Acc@5: 100.0000 (99.0078)  time: 0.3474  data: 0.0007  max mem: 2503
Train: Epoch[5/5]  [2050/3750]  eta: 0:09:50  Lr: 0.001875  Loss: -0.8002  Acc@1: 81.2500 (81.5974)  Acc@5: 100.0000 (99.0035)  time: 0.3482  data: 0.0008  max mem: 2503
Train: Epoch[5/5]  [2060/3750]  eta: 0:09:47  Lr: 0.001875  Loss: -0.9114  Acc@1: 81.2500 (81.6260)  Acc@5: 100.0000 (99.0053)  time: 0.3493  data: 0.0007  max mem: 2503
Train: Epoch[5/5]  [2070/3750]  eta: 0:09:43  Lr: 0.001875  Loss: -0.6395  Acc@1: 81.2500 (81.6152)  Acc@5: 100.0000 (99.0071)  time: 0.3482  data: 0.0007  max mem: 2503
Train: Epoch[5/5]  [2080/3750]  eta: 0:09:40  Lr: 0.001875  Loss: -0.8568  Acc@1: 81.2500 (81.6224)  Acc@5: 100.0000 (99.0059)  time: 0.3466  data: 0.0007  max mem: 2503
Train: Epoch[5/5]  [2090/3750]  eta: 0:09:36  Lr: 0.001875  Loss: -1.0239  Acc@1: 81.2500 (81.6236)  Acc@5: 100.0000 (99.0017)  time: 0.3474  data: 0.0011  max mem: 2503
Train: Epoch[5/5]  [2100/3750]  eta: 0:09:33  Lr: 0.001875  Loss: -0.5337  Acc@1: 81.2500 (81.6248)  Acc@5: 100.0000 (99.0064)  time: 0.3484  data: 0.0012  max mem: 2503
Train: Epoch[5/5]  [2110/3750]  eta: 0:09:29  Lr: 0.001875  Loss: -0.8857  Acc@1: 81.2500 (81.6112)  Acc@5: 100.0000 (99.0052)  time: 0.3481  data: 0.0009  max mem: 2503
Train: Epoch[5/5]  [2120/3750]  eta: 0:09:26  Lr: 0.001875  Loss: -0.9529  Acc@1: 81.2500 (81.6036)  Acc@5: 100.0000 (99.0099)  time: 0.3473  data: 0.0006  max mem: 2503
Train: Epoch[5/5]  [2130/3750]  eta: 0:09:22  Lr: 0.001875  Loss: -0.9947  Acc@1: 81.2500 (81.6078)  Acc@5: 100.0000 (99.0145)  time: 0.3452  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [2140/3750]  eta: 0:09:19  Lr: 0.001875  Loss: -1.0245  Acc@1: 81.2500 (81.6178)  Acc@5: 100.0000 (99.0162)  time: 0.3434  data: 0.0002  max mem: 2503
Train: Epoch[5/5]  [2150/3750]  eta: 0:09:15  Lr: 0.001875  Loss: -0.5487  Acc@1: 87.5000 (81.6364)  Acc@5: 100.0000 (99.0208)  time: 0.3435  data: 0.0002  max mem: 2503
Train: Epoch[5/5]  [2160/3750]  eta: 0:09:12  Lr: 0.001875  Loss: -0.7544  Acc@1: 87.5000 (81.6404)  Acc@5: 100.0000 (99.0224)  time: 0.3449  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [2170/3750]  eta: 0:09:08  Lr: 0.001875  Loss: -0.4306  Acc@1: 81.2500 (81.6271)  Acc@5: 100.0000 (99.0183)  time: 0.3481  data: 0.0012  max mem: 2503
Train: Epoch[5/5]  [2180/3750]  eta: 0:09:05  Lr: 0.001875  Loss: -0.7902  Acc@1: 81.2500 (81.6225)  Acc@5: 100.0000 (99.0113)  time: 0.3492  data: 0.0014  max mem: 2503
Train: Epoch[5/5]  [2190/3750]  eta: 0:09:02  Lr: 0.001875  Loss: -0.8708  Acc@1: 81.2500 (81.6237)  Acc@5: 100.0000 (99.0102)  time: 0.3497  data: 0.0015  max mem: 2503
Train: Epoch[5/5]  [2200/3750]  eta: 0:08:58  Lr: 0.001875  Loss: -0.9462  Acc@1: 81.2500 (81.6277)  Acc@5: 100.0000 (99.0118)  time: 0.3502  data: 0.0016  max mem: 2503
Train: Epoch[5/5]  [2210/3750]  eta: 0:08:55  Lr: 0.001875  Loss: -0.7871  Acc@1: 81.2500 (81.6288)  Acc@5: 100.0000 (99.0135)  time: 0.3493  data: 0.0017  max mem: 2503
Train: Epoch[5/5]  [2220/3750]  eta: 0:08:51  Lr: 0.001875  Loss: -0.8367  Acc@1: 81.2500 (81.6524)  Acc@5: 100.0000 (99.0066)  time: 0.3494  data: 0.0017  max mem: 2503
Train: Epoch[5/5]  [2230/3750]  eta: 0:08:48  Lr: 0.001875  Loss: -0.9067  Acc@1: 87.5000 (81.6618)  Acc@5: 100.0000 (99.0083)  time: 0.3498  data: 0.0011  max mem: 2503
Train: Epoch[5/5]  [2240/3750]  eta: 0:08:44  Lr: 0.001875  Loss: -0.5044  Acc@1: 81.2500 (81.6572)  Acc@5: 100.0000 (99.0071)  time: 0.3483  data: 0.0009  max mem: 2503
Train: Epoch[5/5]  [2250/3750]  eta: 0:08:41  Lr: 0.001875  Loss: -0.2410  Acc@1: 81.2500 (81.6526)  Acc@5: 100.0000 (99.0032)  time: 0.3476  data: 0.0010  max mem: 2503
Train: Epoch[5/5]  [2260/3750]  eta: 0:08:37  Lr: 0.001875  Loss: -0.9540  Acc@1: 81.2500 (81.6619)  Acc@5: 100.0000 (99.0021)  time: 0.3484  data: 0.0009  max mem: 2503
Train: Epoch[5/5]  [2270/3750]  eta: 0:08:34  Lr: 0.001875  Loss: -0.2719  Acc@1: 81.2500 (81.6518)  Acc@5: 100.0000 (98.9982)  time: 0.3490  data: 0.0016  max mem: 2503
Train: Epoch[5/5]  [2280/3750]  eta: 0:08:30  Lr: 0.001875  Loss: -1.0508  Acc@1: 81.2500 (81.6829)  Acc@5: 100.0000 (98.9972)  time: 0.3490  data: 0.0018  max mem: 2503
Train: Epoch[5/5]  [2290/3750]  eta: 0:08:27  Lr: 0.001875  Loss: -0.9356  Acc@1: 87.5000 (81.6892)  Acc@5: 100.0000 (98.9988)  time: 0.3471  data: 0.0009  max mem: 2503
Train: Epoch[5/5]  [2300/3750]  eta: 0:08:23  Lr: 0.001875  Loss: -0.7102  Acc@1: 81.2500 (81.6900)  Acc@5: 100.0000 (99.0032)  time: 0.3455  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [2310/3750]  eta: 0:08:20  Lr: 0.001875  Loss: -0.6981  Acc@1: 81.2500 (81.6746)  Acc@5: 100.0000 (98.9994)  time: 0.3447  data: 0.0003  max mem: 2503
Train: Epoch[5/5]  [2320/3750]  eta: 0:08:16  Lr: 0.001875  Loss: -0.6111  Acc@1: 81.2500 (81.6755)  Acc@5: 100.0000 (99.0037)  time: 0.3435  data: 0.0002  max mem: 2503
Train: Epoch[5/5]  [2330/3750]  eta: 0:08:13  Lr: 0.001875  Loss: -0.6020  Acc@1: 81.2500 (81.6763)  Acc@5: 100.0000 (98.9945)  time: 0.3433  data: 0.0002  max mem: 2503
Train: Epoch[5/5]  [2340/3750]  eta: 0:08:09  Lr: 0.001875  Loss: -0.3337  Acc@1: 81.2500 (81.6638)  Acc@5: 100.0000 (98.9908)  time: 0.3456  data: 0.0006  max mem: 2503
Train: Epoch[5/5]  [2350/3750]  eta: 0:08:06  Lr: 0.001875  Loss: -0.9517  Acc@1: 81.2500 (81.6700)  Acc@5: 100.0000 (98.9951)  time: 0.3482  data: 0.0012  max mem: 2503
Train: Epoch[5/5]  [2360/3750]  eta: 0:08:02  Lr: 0.001875  Loss: -0.8249  Acc@1: 87.5000 (81.7133)  Acc@5: 100.0000 (98.9994)  time: 0.3480  data: 0.0013  max mem: 2503
Train: Epoch[5/5]  [2370/3750]  eta: 0:07:59  Lr: 0.001875  Loss: -0.6024  Acc@1: 87.5000 (81.7192)  Acc@5: 100.0000 (99.0009)  time: 0.3483  data: 0.0015  max mem: 2503
Train: Epoch[5/5]  [2380/3750]  eta: 0:07:56  Lr: 0.001875  Loss: -0.5547  Acc@1: 81.2500 (81.7199)  Acc@5: 100.0000 (99.0051)  time: 0.3483  data: 0.0013  max mem: 2503
Train: Epoch[5/5]  [2390/3750]  eta: 0:07:52  Lr: 0.001875  Loss: -1.0549  Acc@1: 81.2500 (81.7362)  Acc@5: 100.0000 (99.0067)  time: 0.3471  data: 0.0007  max mem: 2503
Train: Epoch[5/5]  [2400/3750]  eta: 0:07:49  Lr: 0.001875  Loss: -0.7817  Acc@1: 81.2500 (81.7420)  Acc@5: 100.0000 (99.0056)  time: 0.3481  data: 0.0009  max mem: 2503
Train: Epoch[5/5]  [2410/3750]  eta: 0:07:45  Lr: 0.001875  Loss: -0.5049  Acc@1: 81.2500 (81.7348)  Acc@5: 100.0000 (99.0072)  time: 0.3489  data: 0.0016  max mem: 2503
Train: Epoch[5/5]  [2420/3750]  eta: 0:07:42  Lr: 0.001875  Loss: -0.7422  Acc@1: 81.2500 (81.7276)  Acc@5: 100.0000 (99.0061)  time: 0.3493  data: 0.0018  max mem: 2503
Train: Epoch[5/5]  [2430/3750]  eta: 0:07:38  Lr: 0.001875  Loss: -0.5519  Acc@1: 81.2500 (81.7359)  Acc@5: 100.0000 (99.0102)  time: 0.3487  data: 0.0010  max mem: 2503
Train: Epoch[5/5]  [2440/3750]  eta: 0:07:35  Lr: 0.001875  Loss: -0.7014  Acc@1: 81.2500 (81.7365)  Acc@5: 100.0000 (99.0091)  time: 0.3483  data: 0.0008  max mem: 2503
Train: Epoch[5/5]  [2450/3750]  eta: 0:07:31  Lr: 0.001875  Loss: -0.1151  Acc@1: 87.5000 (81.7294)  Acc@5: 100.0000 (99.0106)  time: 0.3520  data: 0.0011  max mem: 2503
Train: Epoch[5/5]  [2460/3750]  eta: 0:07:28  Lr: 0.001875  Loss: -0.7721  Acc@1: 81.2500 (81.7046)  Acc@5: 100.0000 (99.0095)  time: 0.3509  data: 0.0008  max mem: 2503
Train: Epoch[5/5]  [2470/3750]  eta: 0:07:24  Lr: 0.001875  Loss: -1.0007  Acc@1: 81.2500 (81.7280)  Acc@5: 100.0000 (99.0060)  time: 0.3468  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [2480/3750]  eta: 0:07:21  Lr: 0.001875  Loss: -0.5576  Acc@1: 81.2500 (81.7110)  Acc@5: 100.0000 (99.0024)  time: 0.3465  data: 0.0006  max mem: 2503
Train: Epoch[5/5]  [2490/3750]  eta: 0:07:17  Lr: 0.001875  Loss: -0.8600  Acc@1: 81.2500 (81.7117)  Acc@5: 100.0000 (99.0064)  time: 0.3458  data: 0.0007  max mem: 2503
Train: Epoch[5/5]  [2500/3750]  eta: 0:07:14  Lr: 0.001875  Loss: -0.5209  Acc@1: 81.2500 (81.7223)  Acc@5: 100.0000 (99.0079)  time: 0.3457  data: 0.0010  max mem: 2503
Train: Epoch[5/5]  [2510/3750]  eta: 0:07:10  Lr: 0.001875  Loss: -0.8392  Acc@1: 81.2500 (81.7155)  Acc@5: 100.0000 (99.0094)  time: 0.3456  data: 0.0009  max mem: 2503
Train: Epoch[5/5]  [2520/3750]  eta: 0:07:07  Lr: 0.001875  Loss: -0.7040  Acc@1: 87.5000 (81.7359)  Acc@5: 100.0000 (99.0108)  time: 0.3459  data: 0.0007  max mem: 2503
Train: Epoch[5/5]  [2530/3750]  eta: 0:07:03  Lr: 0.001875  Loss: -0.6515  Acc@1: 87.5000 (81.7291)  Acc@5: 100.0000 (99.0147)  time: 0.3481  data: 0.0011  max mem: 2503
Train: Epoch[5/5]  [2540/3750]  eta: 0:07:00  Lr: 0.001875  Loss: -0.7388  Acc@1: 81.2500 (81.7173)  Acc@5: 100.0000 (99.0088)  time: 0.3493  data: 0.0010  max mem: 2503
Train: Epoch[5/5]  [2550/3750]  eta: 0:06:57  Lr: 0.001875  Loss: -0.3841  Acc@1: 81.2500 (81.7155)  Acc@5: 100.0000 (99.0028)  time: 0.3481  data: 0.0008  max mem: 2503
Train: Epoch[5/5]  [2560/3750]  eta: 0:06:53  Lr: 0.001875  Loss: -0.7081  Acc@1: 81.2500 (81.7283)  Acc@5: 100.0000 (99.0043)  time: 0.3477  data: 0.0009  max mem: 2503
Train: Epoch[5/5]  [2570/3750]  eta: 0:06:50  Lr: 0.001875  Loss: -0.5534  Acc@1: 81.2500 (81.7289)  Acc@5: 100.0000 (99.0082)  time: 0.3491  data: 0.0009  max mem: 2503
Train: Epoch[5/5]  [2580/3750]  eta: 0:06:46  Lr: 0.001875  Loss: -0.8084  Acc@1: 81.2500 (81.7295)  Acc@5: 100.0000 (99.0120)  time: 0.3505  data: 0.0019  max mem: 2503
Train: Epoch[5/5]  [2590/3750]  eta: 0:06:43  Lr: 0.001875  Loss: -0.2628  Acc@1: 81.2500 (81.7349)  Acc@5: 100.0000 (99.0158)  time: 0.3497  data: 0.0018  max mem: 2503
Train: Epoch[5/5]  [2600/3750]  eta: 0:06:39  Lr: 0.001875  Loss: -0.6822  Acc@1: 81.2500 (81.7330)  Acc@5: 100.0000 (99.0196)  time: 0.3482  data: 0.0007  max mem: 2503
Train: Epoch[5/5]  [2610/3750]  eta: 0:06:36  Lr: 0.001875  Loss: -0.0976  Acc@1: 81.2500 (81.7120)  Acc@5: 100.0000 (99.0162)  time: 0.3480  data: 0.0007  max mem: 2503
Train: Epoch[5/5]  [2620/3750]  eta: 0:06:32  Lr: 0.001875  Loss: -0.8545  Acc@1: 81.2500 (81.7174)  Acc@5: 100.0000 (99.0176)  time: 0.3476  data: 0.0009  max mem: 2503
Train: Epoch[5/5]  [2630/3750]  eta: 0:06:29  Lr: 0.001875  Loss: -0.9400  Acc@1: 81.2500 (81.7322)  Acc@5: 100.0000 (99.0165)  time: 0.3485  data: 0.0014  max mem: 2503
Train: Epoch[5/5]  [2640/3750]  eta: 0:06:25  Lr: 0.001875  Loss: -0.5226  Acc@1: 81.2500 (81.7091)  Acc@5: 100.0000 (99.0132)  time: 0.3479  data: 0.0010  max mem: 2503
Train: Epoch[5/5]  [2650/3750]  eta: 0:06:22  Lr: 0.001875  Loss: -0.7454  Acc@1: 75.0000 (81.6932)  Acc@5: 100.0000 (99.0145)  time: 0.3478  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [2660/3750]  eta: 0:06:18  Lr: 0.001875  Loss: -0.9318  Acc@1: 75.0000 (81.6869)  Acc@5: 100.0000 (99.0112)  time: 0.3465  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [2670/3750]  eta: 0:06:15  Lr: 0.001875  Loss: -0.7891  Acc@1: 81.2500 (81.6923)  Acc@5: 100.0000 (99.0102)  time: 0.3433  data: 0.0002  max mem: 2503
Train: Epoch[5/5]  [2680/3750]  eta: 0:06:11  Lr: 0.001875  Loss: -0.9003  Acc@1: 81.2500 (81.6836)  Acc@5: 100.0000 (99.0092)  time: 0.3444  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [2690/3750]  eta: 0:06:08  Lr: 0.001875  Loss: -0.8955  Acc@1: 81.2500 (81.6797)  Acc@5: 100.0000 (99.0106)  time: 0.3474  data: 0.0009  max mem: 2503
Train: Epoch[5/5]  [2700/3750]  eta: 0:06:04  Lr: 0.001875  Loss: -1.0374  Acc@1: 81.2500 (81.6966)  Acc@5: 100.0000 (99.0119)  time: 0.3492  data: 0.0012  max mem: 2503
Train: Epoch[5/5]  [2710/3750]  eta: 0:06:01  Lr: 0.001875  Loss: -0.6995  Acc@1: 87.5000 (81.7111)  Acc@5: 100.0000 (99.0133)  time: 0.3497  data: 0.0009  max mem: 2503
Train: Epoch[5/5]  [2720/3750]  eta: 0:05:57  Lr: 0.001875  Loss: -0.4946  Acc@1: 87.5000 (81.7071)  Acc@5: 100.0000 (99.0146)  time: 0.3489  data: 0.0006  max mem: 2503
Train: Epoch[5/5]  [2730/3750]  eta: 0:05:54  Lr: 0.001875  Loss: -0.8152  Acc@1: 81.2500 (81.7008)  Acc@5: 100.0000 (99.0159)  time: 0.3476  data: 0.0006  max mem: 2503
Train: Epoch[5/5]  [2740/3750]  eta: 0:05:51  Lr: 0.001875  Loss: -0.6016  Acc@1: 81.2500 (81.7083)  Acc@5: 100.0000 (99.0127)  time: 0.3483  data: 0.0007  max mem: 2503
Train: Epoch[5/5]  [2750/3750]  eta: 0:05:47  Lr: 0.001875  Loss: -0.5861  Acc@1: 81.2500 (81.7067)  Acc@5: 100.0000 (99.0140)  time: 0.3503  data: 0.0010  max mem: 2503
Train: Epoch[5/5]  [2760/3750]  eta: 0:05:44  Lr: 0.001875  Loss: -0.7751  Acc@1: 81.2500 (81.7027)  Acc@5: 100.0000 (99.0176)  time: 0.3493  data: 0.0010  max mem: 2503
Train: Epoch[5/5]  [2770/3750]  eta: 0:05:40  Lr: 0.001875  Loss: -0.7016  Acc@1: 81.2500 (81.7056)  Acc@5: 100.0000 (99.0211)  time: 0.3478  data: 0.0008  max mem: 2503
Train: Epoch[5/5]  [2780/3750]  eta: 0:05:37  Lr: 0.001875  Loss: -0.9953  Acc@1: 81.2500 (81.7062)  Acc@5: 100.0000 (99.0224)  time: 0.3479  data: 0.0010  max mem: 2503
Train: Epoch[5/5]  [2790/3750]  eta: 0:05:33  Lr: 0.001875  Loss: -0.6856  Acc@1: 81.2500 (81.7091)  Acc@5: 100.0000 (99.0236)  time: 0.3472  data: 0.0009  max mem: 2503
Train: Epoch[5/5]  [2800/3750]  eta: 0:05:30  Lr: 0.001875  Loss: -0.4601  Acc@1: 81.2500 (81.7208)  Acc@5: 100.0000 (99.0227)  time: 0.3470  data: 0.0008  max mem: 2503
Train: Epoch[5/5]  [2810/3750]  eta: 0:05:26  Lr: 0.001875  Loss: -0.7265  Acc@1: 87.5000 (81.7147)  Acc@5: 100.0000 (99.0217)  time: 0.3506  data: 0.0015  max mem: 2503
Train: Epoch[5/5]  [2820/3750]  eta: 0:05:23  Lr: 0.001875  Loss: -0.9228  Acc@1: 81.2500 (81.7197)  Acc@5: 100.0000 (99.0230)  time: 0.3503  data: 0.0012  max mem: 2503
Train: Epoch[5/5]  [2830/3750]  eta: 0:05:19  Lr: 0.001875  Loss: -0.8311  Acc@1: 87.5000 (81.7357)  Acc@5: 100.0000 (99.0242)  time: 0.3457  data: 0.0003  max mem: 2503
Train: Epoch[5/5]  [2840/3750]  eta: 0:05:16  Lr: 0.001875  Loss: -0.8326  Acc@1: 81.2500 (81.7384)  Acc@5: 100.0000 (99.0276)  time: 0.3438  data: 0.0003  max mem: 2503
Train: Epoch[5/5]  [2850/3750]  eta: 0:05:12  Lr: 0.001875  Loss: -0.6895  Acc@1: 81.2500 (81.7345)  Acc@5: 100.0000 (99.0288)  time: 0.3432  data: 0.0002  max mem: 2503
Train: Epoch[5/5]  [2860/3750]  eta: 0:05:09  Lr: 0.001875  Loss: -0.6329  Acc@1: 87.5000 (81.7415)  Acc@5: 100.0000 (99.0279)  time: 0.3437  data: 0.0003  max mem: 2503
Train: Epoch[5/5]  [2870/3750]  eta: 0:05:05  Lr: 0.001875  Loss: -0.4896  Acc@1: 87.5000 (81.7398)  Acc@5: 100.0000 (99.0269)  time: 0.3465  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [2880/3750]  eta: 0:05:02  Lr: 0.001875  Loss: -0.9876  Acc@1: 81.2500 (81.7359)  Acc@5: 100.0000 (99.0216)  time: 0.3487  data: 0.0010  max mem: 2503
Train: Epoch[5/5]  [2890/3750]  eta: 0:04:58  Lr: 0.001875  Loss: -0.9690  Acc@1: 81.2500 (81.7407)  Acc@5: 100.0000 (99.0228)  time: 0.3481  data: 0.0012  max mem: 2503
Train: Epoch[5/5]  [2900/3750]  eta: 0:04:55  Lr: 0.001875  Loss: -0.4762  Acc@1: 87.5000 (81.7606)  Acc@5: 100.0000 (99.0219)  time: 0.3487  data: 0.0011  max mem: 2503
Train: Epoch[5/5]  [2910/3750]  eta: 0:04:51  Lr: 0.001875  Loss: -0.6130  Acc@1: 81.2500 (81.7674)  Acc@5: 100.0000 (99.0252)  time: 0.3488  data: 0.0010  max mem: 2503
Train: Epoch[5/5]  [2920/3750]  eta: 0:04:48  Lr: 0.001875  Loss: -1.0803  Acc@1: 81.2500 (81.7635)  Acc@5: 100.0000 (99.0286)  time: 0.3478  data: 0.0010  max mem: 2503
Train: Epoch[5/5]  [2930/3750]  eta: 0:04:44  Lr: 0.001875  Loss: -0.5571  Acc@1: 81.2500 (81.7618)  Acc@5: 100.0000 (99.0276)  time: 0.3490  data: 0.0013  max mem: 2503
Train: Epoch[5/5]  [2940/3750]  eta: 0:04:41  Lr: 0.001875  Loss: -0.6959  Acc@1: 81.2500 (81.7685)  Acc@5: 100.0000 (99.0267)  time: 0.3495  data: 0.0017  max mem: 2503
Train: Epoch[5/5]  [2950/3750]  eta: 0:04:38  Lr: 0.001875  Loss: -0.8185  Acc@1: 87.5000 (81.7774)  Acc@5: 100.0000 (99.0258)  time: 0.3481  data: 0.0011  max mem: 2503
Train: Epoch[5/5]  [2960/3750]  eta: 0:04:34  Lr: 0.001875  Loss: -0.8975  Acc@1: 81.2500 (81.7819)  Acc@5: 100.0000 (99.0290)  time: 0.3474  data: 0.0006  max mem: 2503
Train: Epoch[5/5]  [2970/3750]  eta: 0:04:31  Lr: 0.001875  Loss: -0.8273  Acc@1: 81.2500 (81.7696)  Acc@5: 100.0000 (99.0302)  time: 0.3480  data: 0.0010  max mem: 2503
Train: Epoch[5/5]  [2980/3750]  eta: 0:04:27  Lr: 0.001875  Loss: -0.7624  Acc@1: 81.2500 (81.7762)  Acc@5: 100.0000 (99.0314)  time: 0.3481  data: 0.0015  max mem: 2503
Train: Epoch[5/5]  [2990/3750]  eta: 0:04:24  Lr: 0.001875  Loss: -0.4827  Acc@1: 81.2500 (81.7808)  Acc@5: 100.0000 (99.0304)  time: 0.3472  data: 0.0011  max mem: 2503
Train: Epoch[5/5]  [3000/3750]  eta: 0:04:20  Lr: 0.001875  Loss: -0.8978  Acc@1: 87.5000 (81.7894)  Acc@5: 100.0000 (99.0337)  time: 0.3450  data: 0.0003  max mem: 2503
Train: Epoch[5/5]  [3010/3750]  eta: 0:04:17  Lr: 0.001875  Loss: -0.7821  Acc@1: 87.5000 (81.8021)  Acc@5: 100.0000 (99.0348)  time: 0.3432  data: 0.0002  max mem: 2503
Train: Epoch[5/5]  [3020/3750]  eta: 0:04:13  Lr: 0.001875  Loss: -0.4466  Acc@1: 81.2500 (81.7900)  Acc@5: 100.0000 (99.0380)  time: 0.3436  data: 0.0003  max mem: 2503
Train: Epoch[5/5]  [3030/3750]  eta: 0:04:10  Lr: 0.001875  Loss: -1.0451  Acc@1: 81.2500 (81.8026)  Acc@5: 100.0000 (99.0412)  time: 0.3443  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [3040/3750]  eta: 0:04:06  Lr: 0.001875  Loss: -0.6741  Acc@1: 81.2500 (81.7967)  Acc@5: 100.0000 (99.0443)  time: 0.3471  data: 0.0006  max mem: 2503
Train: Epoch[5/5]  [3050/3750]  eta: 0:04:03  Lr: 0.001875  Loss: -0.1380  Acc@1: 81.2500 (81.8051)  Acc@5: 100.0000 (99.0474)  time: 0.3491  data: 0.0010  max mem: 2503
Train: Epoch[5/5]  [3060/3750]  eta: 0:03:59  Lr: 0.001875  Loss: -0.8170  Acc@1: 87.5000 (81.8156)  Acc@5: 100.0000 (99.0485)  time: 0.3490  data: 0.0018  max mem: 2503
Train: Epoch[5/5]  [3070/3750]  eta: 0:03:56  Lr: 0.001875  Loss: -0.7156  Acc@1: 81.2500 (81.8076)  Acc@5: 100.0000 (99.0496)  time: 0.3490  data: 0.0018  max mem: 2503
Train: Epoch[5/5]  [3080/3750]  eta: 0:03:52  Lr: 0.001875  Loss: -0.6797  Acc@1: 81.2500 (81.8099)  Acc@5: 100.0000 (99.0527)  time: 0.3484  data: 0.0010  max mem: 2503
Train: Epoch[5/5]  [3090/3750]  eta: 0:03:49  Lr: 0.001875  Loss: -0.3655  Acc@1: 81.2500 (81.8121)  Acc@5: 100.0000 (99.0537)  time: 0.3495  data: 0.0008  max mem: 2503
Train: Epoch[5/5]  [3100/3750]  eta: 0:03:45  Lr: 0.001875  Loss: -0.4440  Acc@1: 81.2500 (81.8163)  Acc@5: 100.0000 (99.0487)  time: 0.3490  data: 0.0007  max mem: 2503
Train: Epoch[5/5]  [3110/3750]  eta: 0:03:42  Lr: 0.001875  Loss: -0.5685  Acc@1: 81.2500 (81.8045)  Acc@5: 100.0000 (99.0497)  time: 0.3482  data: 0.0013  max mem: 2503
Train: Epoch[5/5]  [3120/3750]  eta: 0:03:38  Lr: 0.001875  Loss: -0.4776  Acc@1: 81.2500 (81.8067)  Acc@5: 100.0000 (99.0528)  time: 0.3490  data: 0.0014  max mem: 2503
Train: Epoch[5/5]  [3130/3750]  eta: 0:03:35  Lr: 0.001875  Loss: -0.4716  Acc@1: 81.2500 (81.8049)  Acc@5: 100.0000 (99.0518)  time: 0.3505  data: 0.0014  max mem: 2503
Train: Epoch[5/5]  [3140/3750]  eta: 0:03:32  Lr: 0.001875  Loss: -0.1751  Acc@1: 81.2500 (81.8071)  Acc@5: 100.0000 (99.0528)  time: 0.3502  data: 0.0015  max mem: 2503
Train: Epoch[5/5]  [3150/3750]  eta: 0:03:28  Lr: 0.001875  Loss: -0.7150  Acc@1: 81.2500 (81.7994)  Acc@5: 100.0000 (99.0519)  time: 0.3476  data: 0.0007  max mem: 2503
Train: Epoch[5/5]  [3160/3750]  eta: 0:03:25  Lr: 0.001875  Loss: -0.7750  Acc@1: 81.2500 (81.7997)  Acc@5: 100.0000 (99.0509)  time: 0.3469  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [3170/3750]  eta: 0:03:21  Lr: 0.001875  Loss: -0.6403  Acc@1: 75.0000 (81.7901)  Acc@5: 100.0000 (99.0520)  time: 0.3448  data: 0.0003  max mem: 2503
Train: Epoch[5/5]  [3180/3750]  eta: 0:03:18  Lr: 0.001875  Loss: -0.5827  Acc@1: 75.0000 (81.7884)  Acc@5: 100.0000 (99.0471)  time: 0.3430  data: 0.0002  max mem: 2503
Train: Epoch[5/5]  [3190/3750]  eta: 0:03:14  Lr: 0.001875  Loss: -0.8471  Acc@1: 81.2500 (81.7867)  Acc@5: 100.0000 (99.0461)  time: 0.3431  data: 0.0002  max mem: 2503
Train: Epoch[5/5]  [3200/3750]  eta: 0:03:11  Lr: 0.001875  Loss: -0.4077  Acc@1: 81.2500 (81.7850)  Acc@5: 100.0000 (99.0452)  time: 0.3450  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [3210/3750]  eta: 0:03:07  Lr: 0.001875  Loss: -0.6364  Acc@1: 81.2500 (81.7911)  Acc@5: 100.0000 (99.0482)  time: 0.3468  data: 0.0009  max mem: 2503
Train: Epoch[5/5]  [3220/3750]  eta: 0:03:04  Lr: 0.001875  Loss: -0.7199  Acc@1: 81.2500 (81.7933)  Acc@5: 100.0000 (99.0511)  time: 0.3470  data: 0.0007  max mem: 2503
Train: Epoch[5/5]  [3230/3750]  eta: 0:03:00  Lr: 0.001875  Loss: -0.8808  Acc@1: 87.5000 (81.8071)  Acc@5: 100.0000 (99.0522)  time: 0.3489  data: 0.0009  max mem: 2503
Train: Epoch[5/5]  [3240/3750]  eta: 0:02:57  Lr: 0.001875  Loss: -0.6695  Acc@1: 81.2500 (81.8092)  Acc@5: 100.0000 (99.0531)  time: 0.3493  data: 0.0010  max mem: 2503
Train: Epoch[5/5]  [3250/3750]  eta: 0:02:53  Lr: 0.001875  Loss: -0.5970  Acc@1: 81.2500 (81.8152)  Acc@5: 100.0000 (99.0561)  time: 0.3489  data: 0.0011  max mem: 2503
Train: Epoch[5/5]  [3260/3750]  eta: 0:02:50  Lr: 0.001875  Loss: -0.5666  Acc@1: 81.2500 (81.8077)  Acc@5: 100.0000 (99.0551)  time: 0.3499  data: 0.0014  max mem: 2503
Train: Epoch[5/5]  [3270/3750]  eta: 0:02:46  Lr: 0.001875  Loss: -0.9945  Acc@1: 81.2500 (81.8213)  Acc@5: 100.0000 (99.0542)  time: 0.3484  data: 0.0012  max mem: 2503
Train: Epoch[5/5]  [3280/3750]  eta: 0:02:43  Lr: 0.001875  Loss: -0.7984  Acc@1: 87.5000 (81.8291)  Acc@5: 100.0000 (99.0571)  time: 0.3490  data: 0.0018  max mem: 2503
Train: Epoch[5/5]  [3290/3750]  eta: 0:02:39  Lr: 0.001875  Loss: -0.7511  Acc@1: 81.2500 (81.8311)  Acc@5: 100.0000 (99.0561)  time: 0.3495  data: 0.0020  max mem: 2503
Train: Epoch[5/5]  [3300/3750]  eta: 0:02:36  Lr: 0.001875  Loss: -0.7304  Acc@1: 81.2500 (81.8199)  Acc@5: 100.0000 (99.0590)  time: 0.3489  data: 0.0012  max mem: 2503
Train: Epoch[5/5]  [3310/3750]  eta: 0:02:32  Lr: 0.001875  Loss: -0.8253  Acc@1: 81.2500 (81.8144)  Acc@5: 100.0000 (99.0524)  time: 0.3479  data: 0.0008  max mem: 2503
Train: Epoch[5/5]  [3320/3750]  eta: 0:02:29  Lr: 0.001875  Loss: -0.4697  Acc@1: 81.2500 (81.8033)  Acc@5: 100.0000 (99.0515)  time: 0.3457  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [3330/3750]  eta: 0:02:25  Lr: 0.001875  Loss: -0.8150  Acc@1: 81.2500 (81.7904)  Acc@5: 100.0000 (99.0525)  time: 0.3441  data: 0.0003  max mem: 2503
Train: Epoch[5/5]  [3340/3750]  eta: 0:02:22  Lr: 0.001875  Loss: -0.8715  Acc@1: 81.2500 (81.7906)  Acc@5: 100.0000 (99.0534)  time: 0.3436  data: 0.0008  max mem: 2503
Train: Epoch[5/5]  [3350/3750]  eta: 0:02:19  Lr: 0.001875  Loss: -0.7514  Acc@1: 81.2500 (81.7778)  Acc@5: 100.0000 (99.0544)  time: 0.3444  data: 0.0008  max mem: 2503
Train: Epoch[5/5]  [3360/3750]  eta: 0:02:15  Lr: 0.001875  Loss: -0.6501  Acc@1: 81.2500 (81.7744)  Acc@5: 100.0000 (99.0553)  time: 0.3470  data: 0.0006  max mem: 2503
Train: Epoch[5/5]  [3370/3750]  eta: 0:02:12  Lr: 0.001875  Loss: -0.5585  Acc@1: 75.0000 (81.7636)  Acc@5: 100.0000 (99.0544)  time: 0.3486  data: 0.0012  max mem: 2503
Train: Epoch[5/5]  [3380/3750]  eta: 0:02:08  Lr: 0.001875  Loss: -0.4119  Acc@1: 75.0000 (81.7639)  Acc@5: 100.0000 (99.0461)  time: 0.3476  data: 0.0013  max mem: 2503
Train: Epoch[5/5]  [3390/3750]  eta: 0:02:05  Lr: 0.001875  Loss: -0.5013  Acc@1: 81.2500 (81.7661)  Acc@5: 100.0000 (99.0471)  time: 0.3472  data: 0.0011  max mem: 2503
Train: Epoch[5/5]  [3400/3750]  eta: 0:02:01  Lr: 0.001875  Loss: -0.8171  Acc@1: 81.2500 (81.7756)  Acc@5: 100.0000 (99.0462)  time: 0.3477  data: 0.0009  max mem: 2503
Train: Epoch[5/5]  [3410/3750]  eta: 0:01:58  Lr: 0.001875  Loss: -0.6592  Acc@1: 81.2500 (81.7667)  Acc@5: 100.0000 (99.0454)  time: 0.3489  data: 0.0008  max mem: 2503
Train: Epoch[5/5]  [3420/3750]  eta: 0:01:54  Lr: 0.001875  Loss: -0.6368  Acc@1: 81.2500 (81.7725)  Acc@5: 100.0000 (99.0463)  time: 0.3486  data: 0.0011  max mem: 2503
Train: Epoch[5/5]  [3430/3750]  eta: 0:01:51  Lr: 0.001875  Loss: -0.8095  Acc@1: 81.2500 (81.7819)  Acc@5: 100.0000 (99.0491)  time: 0.3480  data: 0.0012  max mem: 2503
Train: Epoch[5/5]  [3440/3750]  eta: 0:01:47  Lr: 0.001875  Loss: -0.6245  Acc@1: 81.2500 (81.7876)  Acc@5: 100.0000 (99.0519)  time: 0.3480  data: 0.0010  max mem: 2503
Train: Epoch[5/5]  [3450/3750]  eta: 0:01:44  Lr: 0.001875  Loss: -0.7828  Acc@1: 87.5000 (81.7897)  Acc@5: 100.0000 (99.0546)  time: 0.3490  data: 0.0007  max mem: 2503
Train: Epoch[5/5]  [3460/3750]  eta: 0:01:40  Lr: 0.001875  Loss: -0.5247  Acc@1: 81.2500 (81.7881)  Acc@5: 100.0000 (99.0555)  time: 0.3498  data: 0.0009  max mem: 2503
Train: Epoch[5/5]  [3470/3750]  eta: 0:01:37  Lr: 0.001875  Loss: -0.7795  Acc@1: 81.2500 (81.7794)  Acc@5: 100.0000 (99.0511)  time: 0.3482  data: 0.0007  max mem: 2503
Train: Epoch[5/5]  [3480/3750]  eta: 0:01:33  Lr: 0.001875  Loss: -0.4906  Acc@1: 81.2500 (81.7743)  Acc@5: 100.0000 (99.0520)  time: 0.3447  data: 0.0003  max mem: 2503
Train: Epoch[5/5]  [3490/3750]  eta: 0:01:30  Lr: 0.001875  Loss: -0.8035  Acc@1: 81.2500 (81.7692)  Acc@5: 100.0000 (99.0547)  time: 0.3441  data: 0.0008  max mem: 2503
Train: Epoch[5/5]  [3500/3750]  eta: 0:01:26  Lr: 0.001875  Loss: -0.8560  Acc@1: 81.2500 (81.7713)  Acc@5: 100.0000 (99.0538)  time: 0.3450  data: 0.0018  max mem: 2503
Train: Epoch[5/5]  [3510/3750]  eta: 0:01:23  Lr: 0.001875  Loss: -0.7576  Acc@1: 81.2500 (81.7645)  Acc@5: 100.0000 (99.0512)  time: 0.3466  data: 0.0025  max mem: 2503
Train: Epoch[5/5]  [3520/3750]  eta: 0:01:19  Lr: 0.001875  Loss: -0.7241  Acc@1: 81.2500 (81.7630)  Acc@5: 100.0000 (99.0521)  time: 0.3477  data: 0.0018  max mem: 2503
Train: Epoch[5/5]  [3530/3750]  eta: 0:01:16  Lr: 0.001875  Loss: -0.5067  Acc@1: 81.2500 (81.7562)  Acc@5: 100.0000 (99.0548)  time: 0.3476  data: 0.0008  max mem: 2503
Train: Epoch[5/5]  [3540/3750]  eta: 0:01:12  Lr: 0.001875  Loss: -0.9001  Acc@1: 75.0000 (81.7442)  Acc@5: 100.0000 (99.0557)  time: 0.3479  data: 0.0008  max mem: 2503
Train: Epoch[5/5]  [3550/3750]  eta: 0:01:09  Lr: 0.001875  Loss: -0.9969  Acc@1: 81.2500 (81.7463)  Acc@5: 100.0000 (99.0548)  time: 0.3479  data: 0.0007  max mem: 2503
Train: Epoch[5/5]  [3560/3750]  eta: 0:01:06  Lr: 0.001875  Loss: -0.3348  Acc@1: 81.2500 (81.7485)  Acc@5: 100.0000 (99.0540)  time: 0.3502  data: 0.0008  max mem: 2503
Train: Epoch[5/5]  [3570/3750]  eta: 0:01:02  Lr: 0.001875  Loss: -0.8801  Acc@1: 81.2500 (81.7558)  Acc@5: 100.0000 (99.0496)  time: 0.3498  data: 0.0009  max mem: 2503
Train: Epoch[5/5]  [3580/3750]  eta: 0:00:59  Lr: 0.001875  Loss: -0.1836  Acc@1: 81.2500 (81.7439)  Acc@5: 100.0000 (99.0505)  time: 0.3488  data: 0.0017  max mem: 2503
Train: Epoch[5/5]  [3590/3750]  eta: 0:00:55  Lr: 0.001875  Loss: -0.6547  Acc@1: 81.2500 (81.7547)  Acc@5: 100.0000 (99.0532)  time: 0.3499  data: 0.0019  max mem: 2503
Train: Epoch[5/5]  [3600/3750]  eta: 0:00:52  Lr: 0.001875  Loss: -0.8522  Acc@1: 81.2500 (81.7412)  Acc@5: 100.0000 (99.0523)  time: 0.3485  data: 0.0009  max mem: 2503
Train: Epoch[5/5]  [3610/3750]  eta: 0:00:48  Lr: 0.001875  Loss: -0.4632  Acc@1: 81.2500 (81.7433)  Acc@5: 100.0000 (99.0515)  time: 0.3469  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [3620/3750]  eta: 0:00:45  Lr: 0.001875  Loss: -0.6124  Acc@1: 81.2500 (81.7247)  Acc@5: 100.0000 (99.0524)  time: 0.3476  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [3630/3750]  eta: 0:00:41  Lr: 0.001875  Loss: -0.6770  Acc@1: 81.2500 (81.7337)  Acc@5: 100.0000 (99.0533)  time: 0.3476  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [3640/3750]  eta: 0:00:38  Lr: 0.001875  Loss: -0.5801  Acc@1: 81.2500 (81.7392)  Acc@5: 100.0000 (99.0559)  time: 0.3451  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [3650/3750]  eta: 0:00:34  Lr: 0.001875  Loss: -0.7878  Acc@1: 81.2500 (81.7345)  Acc@5: 100.0000 (99.0585)  time: 0.3445  data: 0.0016  max mem: 2503
Train: Epoch[5/5]  [3660/3750]  eta: 0:00:31  Lr: 0.001875  Loss: -0.6167  Acc@1: 81.2500 (81.7331)  Acc@5: 100.0000 (99.0559)  time: 0.3458  data: 0.0022  max mem: 2503
Train: Epoch[5/5]  [3670/3750]  eta: 0:00:27  Lr: 0.001875  Loss: -0.5791  Acc@1: 81.2500 (81.7403)  Acc@5: 100.0000 (99.0585)  time: 0.3471  data: 0.0017  max mem: 2503
Train: Epoch[5/5]  [3680/3750]  eta: 0:00:24  Lr: 0.001875  Loss: -0.7221  Acc@1: 81.2500 (81.7390)  Acc@5: 100.0000 (99.0560)  time: 0.3497  data: 0.0023  max mem: 2503
Train: Epoch[5/5]  [3690/3750]  eta: 0:00:20  Lr: 0.001875  Loss: -0.3570  Acc@1: 81.2500 (81.7411)  Acc@5: 100.0000 (99.0585)  time: 0.3503  data: 0.0026  max mem: 2503
Train: Epoch[5/5]  [3700/3750]  eta: 0:00:17  Lr: 0.001875  Loss: -0.3682  Acc@1: 81.2500 (81.7380)  Acc@5: 100.0000 (99.0577)  time: 0.3475  data: 0.0014  max mem: 2503
Train: Epoch[5/5]  [3710/3750]  eta: 0:00:13  Lr: 0.001875  Loss: -0.3398  Acc@1: 75.0000 (81.7317)  Acc@5: 100.0000 (99.0535)  time: 0.3474  data: 0.0008  max mem: 2503
Train: Epoch[5/5]  [3720/3750]  eta: 0:00:10  Lr: 0.001875  Loss: -0.5565  Acc@1: 81.2500 (81.7388)  Acc@5: 100.0000 (99.0560)  time: 0.3485  data: 0.0011  max mem: 2503
Train: Epoch[5/5]  [3730/3750]  eta: 0:00:06  Lr: 0.001875  Loss: -0.5437  Acc@1: 81.2500 (81.7257)  Acc@5: 100.0000 (99.0535)  time: 0.3484  data: 0.0014  max mem: 2503
Train: Epoch[5/5]  [3740/3750]  eta: 0:00:03  Lr: 0.001875  Loss: -0.7526  Acc@1: 81.2500 (81.7345)  Acc@5: 100.0000 (99.0527)  time: 0.3481  data: 0.0016  max mem: 2503
Train: Epoch[5/5]  [3749/3750]  eta: 0:00:00  Lr: 0.001875  Loss: -0.8338  Acc@1: 87.5000 (81.7467)  Acc@5: 100.0000 (99.0517)  time: 0.3484  data: 0.0021  max mem: 2503
Train: Epoch[5/5] Total time: 0:21:43 (0.3477 s / it)
{0: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 1: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 2: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 3: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 4: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 5: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 6: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 7: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 8: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 9: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 10: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 11: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 12: {0: 0, 1: 0, 2: 0, 3: 91325, 4: 0}, 13: {0: 0, 1: 0, 2: 0, 3: 91325, 4: 0}, 14: {0: 0, 1: 0, 2: 0, 3: 91325, 4: 0}, 15: {0: 0, 1: 0, 2: 0, 3: 91325, 4: 0}, 16: {0: 0, 1: 0, 2: 0, 3: 0, 4: 300000}, 17: {0: 0, 1: 0, 2: 0, 3: 0, 4: 300000}, 18: {0: 0, 1: 0, 2: 0, 3: 0, 4: 300000}, 19: {0: 0, 1: 0, 2: 0, 3: 0, 4: 300000}}
Averaged stats: Lr: 0.001875  Loss: -0.8338  Acc@1: 87.5000 (81.7467)  Acc@5: 100.0000 (99.0517)
Test: [Task 1]  [   0/1627]  eta: 0:17:50  Loss: 1.6989 (1.6989)  Acc@1: 50.0000 (50.0000)  Acc@5: 81.2500 (81.2500)  time: 0.6577  data: 0.4435  max mem: 2503
Test: [Task 1]  [  10/1627]  eta: 0:06:53  Loss: 1.2863 (1.2942)  Acc@1: 62.5000 (63.0682)  Acc@5: 87.5000 (90.3409)  time: 0.2559  data: 0.0411  max mem: 2503
Test: [Task 1]  [  20/1627]  eta: 0:06:22  Loss: 1.2651 (1.2475)  Acc@1: 68.7500 (65.4762)  Acc@5: 87.5000 (89.5833)  time: 0.2170  data: 0.0019  max mem: 2503
Test: [Task 1]  [  30/1627]  eta: 0:06:08  Loss: 1.2651 (1.2533)  Acc@1: 62.5000 (65.1210)  Acc@5: 87.5000 (89.5161)  time: 0.2172  data: 0.0019  max mem: 2503
Test: [Task 1]  [  40/1627]  eta: 0:05:59  Loss: 1.3072 (1.2564)  Acc@1: 62.5000 (65.5488)  Acc@5: 93.7500 (90.2439)  time: 0.2150  data: 0.0006  max mem: 2503
Test: [Task 1]  [  50/1627]  eta: 0:05:53  Loss: 1.0571 (1.2325)  Acc@1: 68.7500 (67.0343)  Acc@5: 93.7500 (90.9314)  time: 0.2141  data: 0.0003  max mem: 2503
Test: [Task 1]  [  60/1627]  eta: 0:05:49  Loss: 1.1620 (1.2534)  Acc@1: 68.7500 (66.2910)  Acc@5: 93.7500 (90.6762)  time: 0.2149  data: 0.0003  max mem: 2503
Test: [Task 1]  [  70/1627]  eta: 0:05:44  Loss: 1.1587 (1.2451)  Acc@1: 62.5000 (66.5493)  Acc@5: 93.7500 (90.9331)  time: 0.2139  data: 0.0002  max mem: 2503
Test: [Task 1]  [  80/1627]  eta: 0:05:40  Loss: 1.0098 (1.2313)  Acc@1: 68.7500 (66.7438)  Acc@5: 93.7500 (91.2037)  time: 0.2123  data: 0.0002  max mem: 2503
Test: [Task 1]  [  90/1627]  eta: 0:05:37  Loss: 1.2435 (1.2519)  Acc@1: 68.7500 (65.9341)  Acc@5: 87.5000 (90.6593)  time: 0.2125  data: 0.0002  max mem: 2503
Test: [Task 1]  [ 100/1627]  eta: 0:05:33  Loss: 1.4768 (1.2778)  Acc@1: 56.2500 (65.4084)  Acc@5: 81.2500 (90.0371)  time: 0.2124  data: 0.0002  max mem: 2503
Test: [Task 1]  [ 110/1627]  eta: 0:05:30  Loss: 1.3129 (1.2789)  Acc@1: 62.5000 (65.0338)  Acc@5: 93.7500 (90.5405)  time: 0.2123  data: 0.0002  max mem: 2503
Test: [Task 1]  [ 120/1627]  eta: 0:05:28  Loss: 1.1991 (1.2750)  Acc@1: 62.5000 (64.7727)  Acc@5: 93.7500 (90.5992)  time: 0.2138  data: 0.0006  max mem: 2503
Test: [Task 1]  [ 130/1627]  eta: 0:05:25  Loss: 1.2967 (1.2830)  Acc@1: 62.5000 (64.5038)  Acc@5: 93.7500 (90.5534)  time: 0.2155  data: 0.0013  max mem: 2503
Test: [Task 1]  [ 140/1627]  eta: 0:05:23  Loss: 1.2763 (1.2814)  Acc@1: 62.5000 (64.4504)  Acc@5: 93.7500 (90.5142)  time: 0.2161  data: 0.0021  max mem: 2503
Test: [Task 1]  [ 150/1627]  eta: 0:05:21  Loss: 0.9954 (1.2643)  Acc@1: 68.7500 (65.0248)  Acc@5: 93.7500 (90.7699)  time: 0.2166  data: 0.0017  max mem: 2503
Test: [Task 1]  [ 160/1627]  eta: 0:05:18  Loss: 0.9714 (1.2547)  Acc@1: 68.7500 (65.3727)  Acc@5: 93.7500 (90.9161)  time: 0.2160  data: 0.0005  max mem: 2503
Test: [Task 1]  [ 170/1627]  eta: 0:05:16  Loss: 1.2090 (1.2496)  Acc@1: 68.7500 (65.4971)  Acc@5: 87.5000 (90.8260)  time: 0.2156  data: 0.0008  max mem: 2503
Test: [Task 1]  [ 180/1627]  eta: 0:05:14  Loss: 1.2090 (1.2548)  Acc@1: 62.5000 (65.4351)  Acc@5: 87.5000 (90.8149)  time: 0.2168  data: 0.0015  max mem: 2503
Test: [Task 1]  [ 190/1627]  eta: 0:05:12  Loss: 1.2103 (1.2512)  Acc@1: 68.7500 (65.5759)  Acc@5: 93.7500 (90.8377)  time: 0.2172  data: 0.0015  max mem: 2503
Test: [Task 1]  [ 200/1627]  eta: 0:05:09  Loss: 1.2421 (1.2521)  Acc@1: 68.7500 (65.4540)  Acc@5: 93.7500 (90.8271)  time: 0.2160  data: 0.0009  max mem: 2503
Test: [Task 1]  [ 210/1627]  eta: 0:05:07  Loss: 1.2421 (1.2519)  Acc@1: 68.7500 (65.6694)  Acc@5: 93.7500 (90.9064)  time: 0.2157  data: 0.0009  max mem: 2503
Test: [Task 1]  [ 220/1627]  eta: 0:05:05  Loss: 1.1232 (1.2559)  Acc@1: 68.7500 (65.5260)  Acc@5: 93.7500 (90.7805)  time: 0.2163  data: 0.0016  max mem: 2503
Test: [Task 1]  [ 230/1627]  eta: 0:05:03  Loss: 1.1561 (1.2506)  Acc@1: 68.7500 (65.8279)  Acc@5: 93.7500 (90.8009)  time: 0.2165  data: 0.0020  max mem: 2503
Test: [Task 1]  [ 240/1627]  eta: 0:05:01  Loss: 1.1317 (1.2450)  Acc@1: 68.7500 (66.0010)  Acc@5: 93.7500 (90.8714)  time: 0.2157  data: 0.0013  max mem: 2503
Test: [Task 1]  [ 250/1627]  eta: 0:04:58  Loss: 1.0633 (1.2473)  Acc@1: 68.7500 (66.1106)  Acc@5: 93.7500 (90.8865)  time: 0.2149  data: 0.0006  max mem: 2503
Test: [Task 1]  [ 260/1627]  eta: 0:04:56  Loss: 1.1706 (1.2467)  Acc@1: 62.5000 (66.1638)  Acc@5: 93.7500 (90.9004)  time: 0.2149  data: 0.0006  max mem: 2503
Test: [Task 1]  [ 270/1627]  eta: 0:04:54  Loss: 1.1001 (1.2388)  Acc@1: 68.7500 (66.3284)  Acc@5: 93.7500 (91.0517)  time: 0.2147  data: 0.0008  max mem: 2503
Test: [Task 1]  [ 280/1627]  eta: 0:04:51  Loss: 1.0703 (1.2390)  Acc@1: 68.7500 (66.3479)  Acc@5: 93.7500 (90.9920)  time: 0.2151  data: 0.0007  max mem: 2503
Test: [Task 1]  [ 290/1627]  eta: 0:04:49  Loss: 1.2419 (1.2389)  Acc@1: 68.7500 (66.3230)  Acc@5: 93.7500 (91.0009)  time: 0.2145  data: 0.0004  max mem: 2503
Test: [Task 1]  [ 300/1627]  eta: 0:04:47  Loss: 1.2023 (1.2383)  Acc@1: 68.7500 (66.4037)  Acc@5: 93.7500 (91.0299)  time: 0.2145  data: 0.0003  max mem: 2503
Test: [Task 1]  [ 310/1627]  eta: 0:04:45  Loss: 1.1215 (1.2417)  Acc@1: 68.7500 (66.3585)  Acc@5: 93.7500 (90.9968)  time: 0.2159  data: 0.0004  max mem: 2503
Test: [Task 1]  [ 320/1627]  eta: 0:04:42  Loss: 1.2813 (1.2412)  Acc@1: 68.7500 (66.3357)  Acc@5: 93.7500 (91.0047)  time: 0.2149  data: 0.0003  max mem: 2503
Test: [Task 1]  [ 330/1627]  eta: 0:04:40  Loss: 1.2138 (1.2394)  Acc@1: 68.7500 (66.3331)  Acc@5: 93.7500 (90.9932)  time: 0.2134  data: 0.0003  max mem: 2503
Test: [Task 1]  [ 340/1627]  eta: 0:04:38  Loss: 0.9934 (1.2395)  Acc@1: 68.7500 (66.3673)  Acc@5: 93.7500 (91.0374)  time: 0.2134  data: 0.0003  max mem: 2503
Test: [Task 1]  [ 350/1627]  eta: 0:04:36  Loss: 1.2170 (1.2423)  Acc@1: 68.7500 (66.3283)  Acc@5: 87.5000 (90.9366)  time: 0.2133  data: 0.0002  max mem: 2503
Test: [Task 1]  [ 360/1627]  eta: 0:04:33  Loss: 1.2068 (1.2405)  Acc@1: 68.7500 (66.3781)  Acc@5: 87.5000 (90.8934)  time: 0.2129  data: 0.0002  max mem: 2503
Test: [Task 1]  [ 370/1627]  eta: 0:04:31  Loss: 1.1393 (1.2410)  Acc@1: 68.7500 (66.3578)  Acc@5: 87.5000 (90.8693)  time: 0.2150  data: 0.0006  max mem: 2503
Test: [Task 1]  [ 380/1627]  eta: 0:04:29  Loss: 1.1342 (1.2394)  Acc@1: 68.7500 (66.5354)  Acc@5: 87.5000 (90.8136)  time: 0.2173  data: 0.0007  max mem: 2503
Test: [Task 1]  [ 390/1627]  eta: 0:04:27  Loss: 1.1398 (1.2410)  Acc@1: 68.7500 (66.5121)  Acc@5: 87.5000 (90.7928)  time: 0.2171  data: 0.0006  max mem: 2503
Test: [Task 1]  [ 400/1627]  eta: 0:04:25  Loss: 1.2376 (1.2415)  Acc@1: 68.7500 (66.4900)  Acc@5: 87.5000 (90.7887)  time: 0.2168  data: 0.0009  max mem: 2503
Test: [Task 1]  [ 410/1627]  eta: 0:04:23  Loss: 1.0435 (1.2408)  Acc@1: 68.7500 (66.5602)  Acc@5: 93.7500 (90.7543)  time: 0.2160  data: 0.0009  max mem: 2503
Test: [Task 1]  [ 420/1627]  eta: 0:04:20  Loss: 1.1083 (1.2404)  Acc@1: 68.7500 (66.5529)  Acc@5: 93.7500 (90.8106)  time: 0.2167  data: 0.0014  max mem: 2503
Test: [Task 1]  [ 430/1627]  eta: 0:04:18  Loss: 1.1083 (1.2384)  Acc@1: 68.7500 (66.5893)  Acc@5: 93.7500 (90.8788)  time: 0.2177  data: 0.0021  max mem: 2503
Test: [Task 1]  [ 440/1627]  eta: 0:04:16  Loss: 1.2685 (1.2384)  Acc@1: 68.7500 (66.6525)  Acc@5: 87.5000 (90.8730)  time: 0.2158  data: 0.0015  max mem: 2503
Test: [Task 1]  [ 450/1627]  eta: 0:04:14  Loss: 1.3073 (1.2417)  Acc@1: 62.5000 (66.5050)  Acc@5: 87.5000 (90.7844)  time: 0.2157  data: 0.0007  max mem: 2503
Test: [Task 1]  [ 460/1627]  eta: 0:04:12  Loss: 1.3185 (1.2419)  Acc@1: 62.5000 (66.5401)  Acc@5: 93.7500 (90.8216)  time: 0.2168  data: 0.0006  max mem: 2503
Test: [Task 1]  [ 470/1627]  eta: 0:04:10  Loss: 1.0990 (1.2397)  Acc@1: 68.7500 (66.5472)  Acc@5: 93.7500 (90.8439)  time: 0.2159  data: 0.0007  max mem: 2503
Test: [Task 1]  [ 480/1627]  eta: 0:04:07  Loss: 1.2073 (1.2438)  Acc@1: 56.2500 (66.4241)  Acc@5: 87.5000 (90.7614)  time: 0.2147  data: 0.0004  max mem: 2503
Test: [Task 1]  [ 490/1627]  eta: 0:04:05  Loss: 1.2856 (1.2440)  Acc@1: 56.2500 (66.3187)  Acc@5: 87.5000 (90.7968)  time: 0.2153  data: 0.0008  max mem: 2503
Test: [Task 1]  [ 500/1627]  eta: 0:04:03  Loss: 1.2195 (1.2461)  Acc@1: 62.5000 (66.2675)  Acc@5: 93.7500 (90.7809)  time: 0.2162  data: 0.0008  max mem: 2503
Test: [Task 1]  [ 510/1627]  eta: 0:04:01  Loss: 1.3238 (1.2527)  Acc@1: 62.5000 (66.0714)  Acc@5: 87.5000 (90.6800)  time: 0.2156  data: 0.0004  max mem: 2503
Test: [Task 1]  [ 520/1627]  eta: 0:03:59  Loss: 1.4223 (1.2597)  Acc@1: 56.2500 (65.9309)  Acc@5: 87.5000 (90.5710)  time: 0.2151  data: 0.0004  max mem: 2503
Test: [Task 1]  [ 530/1627]  eta: 0:03:57  Loss: 1.2500 (1.2559)  Acc@1: 62.5000 (66.0193)  Acc@5: 87.5000 (90.5956)  time: 0.2159  data: 0.0008  max mem: 2503
Test: [Task 1]  [ 540/1627]  eta: 0:03:54  Loss: 1.2213 (1.2567)  Acc@1: 68.7500 (66.0582)  Acc@5: 87.5000 (90.5846)  time: 0.2162  data: 0.0011  max mem: 2503
Test: [Task 1]  [ 550/1627]  eta: 0:03:52  Loss: 1.3553 (1.2591)  Acc@1: 68.7500 (66.0504)  Acc@5: 87.5000 (90.5740)  time: 0.2152  data: 0.0006  max mem: 2503
Test: [Task 1]  [ 560/1627]  eta: 0:03:50  Loss: 1.3804 (1.2612)  Acc@1: 68.7500 (66.0316)  Acc@5: 87.5000 (90.5414)  time: 0.2147  data: 0.0003  max mem: 2503
Test: [Task 1]  [ 570/1627]  eta: 0:03:48  Loss: 1.2129 (1.2582)  Acc@1: 68.7500 (66.1011)  Acc@5: 93.7500 (90.5757)  time: 0.2144  data: 0.0003  max mem: 2503
Test: [Task 1]  [ 580/1627]  eta: 0:03:46  Loss: 1.1747 (1.2591)  Acc@1: 68.7500 (66.0929)  Acc@5: 93.7500 (90.5766)  time: 0.2135  data: 0.0003  max mem: 2503
Test: [Task 1]  [ 590/1627]  eta: 0:03:43  Loss: 1.2435 (1.2584)  Acc@1: 62.5000 (66.0745)  Acc@5: 93.7500 (90.6514)  time: 0.2135  data: 0.0002  max mem: 2503
Test: [Task 1]  [ 600/1627]  eta: 0:03:41  Loss: 1.2435 (1.2609)  Acc@1: 62.5000 (65.9630)  Acc@5: 93.7500 (90.6198)  time: 0.2135  data: 0.0002  max mem: 2503
Test: [Task 1]  [ 610/1627]  eta: 0:03:39  Loss: 1.2302 (1.2584)  Acc@1: 62.5000 (66.0291)  Acc@5: 93.7500 (90.6301)  time: 0.2132  data: 0.0002  max mem: 2503
Test: [Task 1]  [ 620/1627]  eta: 0:03:37  Loss: 1.1827 (1.2597)  Acc@1: 62.5000 (65.9622)  Acc@5: 93.7500 (90.5797)  time: 0.2144  data: 0.0009  max mem: 2503
Test: [Task 1]  [ 630/1627]  eta: 0:03:35  Loss: 1.1496 (1.2589)  Acc@1: 68.7500 (66.0261)  Acc@5: 93.7500 (90.5804)  time: 0.2173  data: 0.0021  max mem: 2503
Test: [Task 1]  [ 640/1627]  eta: 0:03:33  Loss: 1.0825 (1.2587)  Acc@1: 68.7500 (66.0101)  Acc@5: 93.7500 (90.5811)  time: 0.2173  data: 0.0016  max mem: 2503
Test: [Task 1]  [ 650/1627]  eta: 0:03:30  Loss: 1.2198 (1.2577)  Acc@1: 62.5000 (66.0234)  Acc@5: 93.7500 (90.5722)  time: 0.2152  data: 0.0005  max mem: 2503
Test: [Task 1]  [ 660/1627]  eta: 0:03:28  Loss: 1.1588 (1.2558)  Acc@1: 68.7500 (66.1025)  Acc@5: 93.7500 (90.5635)  time: 0.2154  data: 0.0006  max mem: 2503
Test: [Task 1]  [ 670/1627]  eta: 0:03:26  Loss: 1.1902 (1.2550)  Acc@1: 68.7500 (66.1233)  Acc@5: 87.5000 (90.5365)  time: 0.2166  data: 0.0014  max mem: 2503
Test: [Task 1]  [ 680/1627]  eta: 0:03:24  Loss: 1.1902 (1.2546)  Acc@1: 68.7500 (66.1711)  Acc@5: 87.5000 (90.5470)  time: 0.2168  data: 0.0013  max mem: 2503
Test: [Task 1]  [ 690/1627]  eta: 0:03:22  Loss: 1.2446 (1.2531)  Acc@1: 68.7500 (66.1993)  Acc@5: 93.7500 (90.6024)  time: 0.2176  data: 0.0010  max mem: 2503
Test: [Task 1]  [ 700/1627]  eta: 0:03:20  Loss: 1.2500 (1.2524)  Acc@1: 68.7500 (66.2803)  Acc@5: 93.7500 (90.6295)  time: 0.2188  data: 0.0017  max mem: 2503
Test: [Task 1]  [ 710/1627]  eta: 0:03:18  Loss: 1.1028 (1.2499)  Acc@1: 68.7500 (66.3502)  Acc@5: 93.7500 (90.6470)  time: 0.2184  data: 0.0014  max mem: 2503
Test: [Task 1]  [ 720/1627]  eta: 0:03:15  Loss: 1.1055 (1.2490)  Acc@1: 62.5000 (66.3315)  Acc@5: 93.7500 (90.6727)  time: 0.2168  data: 0.0005  max mem: 2503
Test: [Task 1]  [ 730/1627]  eta: 0:03:13  Loss: 1.2352 (1.2496)  Acc@1: 62.5000 (66.3133)  Acc@5: 93.7500 (90.6806)  time: 0.2156  data: 0.0005  max mem: 2503
Test: [Task 1]  [ 740/1627]  eta: 0:03:11  Loss: 1.2604 (1.2503)  Acc@1: 68.7500 (66.3040)  Acc@5: 93.7500 (90.6630)  time: 0.2159  data: 0.0006  max mem: 2503
Test: [Task 1]  [ 750/1627]  eta: 0:03:09  Loss: 1.1821 (1.2492)  Acc@1: 68.7500 (66.3615)  Acc@5: 93.7500 (90.6791)  time: 0.2164  data: 0.0010  max mem: 2503
Test: [Task 1]  [ 760/1627]  eta: 0:03:07  Loss: 1.1493 (1.2525)  Acc@1: 68.7500 (66.2615)  Acc@5: 87.5000 (90.5963)  time: 0.2172  data: 0.0013  max mem: 2503
Test: [Task 1]  [ 770/1627]  eta: 0:03:05  Loss: 1.0301 (1.2489)  Acc@1: 68.7500 (66.3748)  Acc@5: 87.5000 (90.6372)  time: 0.2167  data: 0.0009  max mem: 2503
Test: [Task 1]  [ 780/1627]  eta: 0:03:02  Loss: 0.9719 (1.2470)  Acc@1: 75.0000 (66.4853)  Acc@5: 93.7500 (90.6610)  time: 0.2158  data: 0.0008  max mem: 2503
Test: [Task 1]  [ 790/1627]  eta: 0:03:00  Loss: 1.1000 (1.2491)  Acc@1: 68.7500 (66.4665)  Acc@5: 93.7500 (90.5973)  time: 0.2162  data: 0.0005  max mem: 2503
Test: [Task 1]  [ 800/1627]  eta: 0:02:58  Loss: 1.1429 (1.2473)  Acc@1: 68.7500 (66.5028)  Acc@5: 87.5000 (90.6055)  time: 0.2158  data: 0.0003  max mem: 2503
Test: [Task 1]  [ 810/1627]  eta: 0:02:56  Loss: 1.1139 (1.2467)  Acc@1: 68.7500 (66.4920)  Acc@5: 93.7500 (90.6443)  time: 0.2143  data: 0.0003  max mem: 2503
Test: [Task 1]  [ 820/1627]  eta: 0:02:54  Loss: 1.0811 (1.2455)  Acc@1: 62.5000 (66.5195)  Acc@5: 93.7500 (90.6745)  time: 0.2134  data: 0.0002  max mem: 2503
Test: [Task 1]  [ 830/1627]  eta: 0:02:52  Loss: 1.0618 (1.2445)  Acc@1: 62.5000 (66.5238)  Acc@5: 93.7500 (90.6889)  time: 0.2135  data: 0.0002  max mem: 2503
Test: [Task 1]  [ 840/1627]  eta: 0:02:49  Loss: 1.0284 (1.2422)  Acc@1: 68.7500 (66.5428)  Acc@5: 93.7500 (90.7551)  time: 0.2135  data: 0.0002  max mem: 2503
Test: [Task 1]  [ 850/1627]  eta: 0:02:47  Loss: 1.1881 (1.2440)  Acc@1: 62.5000 (66.4880)  Acc@5: 93.7500 (90.7315)  time: 0.2133  data: 0.0002  max mem: 2503
Test: [Task 1]  [ 860/1627]  eta: 0:02:45  Loss: 1.1881 (1.2432)  Acc@1: 62.5000 (66.4779)  Acc@5: 93.7500 (90.7666)  time: 0.2139  data: 0.0002  max mem: 2503
Test: [Task 1]  [ 870/1627]  eta: 0:02:43  Loss: 1.1347 (1.2415)  Acc@1: 68.7500 (66.5112)  Acc@5: 93.7500 (90.7793)  time: 0.2165  data: 0.0012  max mem: 2503
Test: [Task 1]  [ 880/1627]  eta: 0:02:41  Loss: 1.2501 (1.2440)  Acc@1: 56.2500 (66.3734)  Acc@5: 93.7500 (90.7917)  time: 0.2183  data: 0.0020  max mem: 2503
Test: [Task 1]  [ 890/1627]  eta: 0:02:39  Loss: 1.3410 (1.2464)  Acc@1: 56.2500 (66.3159)  Acc@5: 87.5000 (90.7478)  time: 0.2176  data: 0.0015  max mem: 2503
Test: [Task 1]  [ 900/1627]  eta: 0:02:36  Loss: 1.3410 (1.2466)  Acc@1: 62.5000 (66.3221)  Acc@5: 87.5000 (90.7256)  time: 0.2166  data: 0.0009  max mem: 2503
Test: [Task 1]  [ 910/1627]  eta: 0:02:34  Loss: 1.3207 (1.2479)  Acc@1: 62.5000 (66.2939)  Acc@5: 87.5000 (90.6833)  time: 0.2175  data: 0.0014  max mem: 2503
Test: [Task 1]  [ 920/1627]  eta: 0:02:32  Loss: 1.2096 (1.2476)  Acc@1: 62.5000 (66.3206)  Acc@5: 87.5000 (90.6963)  time: 0.2173  data: 0.0015  max mem: 2503
Test: [Task 1]  [ 930/1627]  eta: 0:02:30  Loss: 1.2367 (1.2485)  Acc@1: 68.7500 (66.2930)  Acc@5: 93.7500 (90.6888)  time: 0.2161  data: 0.0009  max mem: 2503
Test: [Task 1]  [ 940/1627]  eta: 0:02:28  Loss: 1.2257 (1.2471)  Acc@1: 68.7500 (66.3324)  Acc@5: 93.7500 (90.7213)  time: 0.2171  data: 0.0008  max mem: 2503
Test: [Task 1]  [ 950/1627]  eta: 0:02:26  Loss: 1.2257 (1.2484)  Acc@1: 68.7500 (66.2855)  Acc@5: 93.7500 (90.7269)  time: 0.2189  data: 0.0011  max mem: 2503
Test: [Task 1]  [ 960/1627]  eta: 0:02:24  Loss: 1.2220 (1.2476)  Acc@1: 62.5000 (66.2656)  Acc@5: 93.7500 (90.7323)  time: 0.2179  data: 0.0012  max mem: 2503
Test: [Task 1]  [ 970/1627]  eta: 0:02:21  Loss: 1.0922 (1.2469)  Acc@1: 68.7500 (66.2719)  Acc@5: 87.5000 (90.7183)  time: 0.2167  data: 0.0019  max mem: 2503
Test: [Task 1]  [ 980/1627]  eta: 0:02:19  Loss: 1.2420 (1.2468)  Acc@1: 62.5000 (66.2844)  Acc@5: 93.7500 (90.7429)  time: 0.2166  data: 0.0016  max mem: 2503
Test: [Task 1]  [ 990/1627]  eta: 0:02:17  Loss: 1.2892 (1.2500)  Acc@1: 62.5000 (66.2399)  Acc@5: 93.7500 (90.7164)  time: 0.2161  data: 0.0010  max mem: 2503
Test: [Task 1]  [1000/1627]  eta: 0:02:15  Loss: 1.3406 (1.2500)  Acc@1: 62.5000 (66.2587)  Acc@5: 87.5000 (90.6718)  time: 0.2171  data: 0.0018  max mem: 2503
Test: [Task 1]  [1010/1627]  eta: 0:02:13  Loss: 1.2258 (1.2496)  Acc@1: 68.7500 (66.2648)  Acc@5: 87.5000 (90.6775)  time: 0.2177  data: 0.0024  max mem: 2503
Test: [Task 1]  [1020/1627]  eta: 0:02:11  Loss: 1.1508 (1.2490)  Acc@1: 68.7500 (66.2953)  Acc@5: 87.5000 (90.6832)  time: 0.2168  data: 0.0018  max mem: 2503
Test: [Task 1]  [1030/1627]  eta: 0:02:09  Loss: 0.9681 (1.2466)  Acc@1: 75.0000 (66.3737)  Acc@5: 93.7500 (90.7190)  time: 0.2177  data: 0.0008  max mem: 2503
Test: [Task 1]  [1040/1627]  eta: 0:02:06  Loss: 0.9468 (1.2443)  Acc@1: 75.0000 (66.4265)  Acc@5: 93.7500 (90.7541)  time: 0.2172  data: 0.0005  max mem: 2503
Test: [Task 1]  [1050/1627]  eta: 0:02:04  Loss: 1.0528 (1.2429)  Acc@1: 68.7500 (66.4367)  Acc@5: 93.7500 (90.7826)  time: 0.2145  data: 0.0003  max mem: 2503
Test: [Task 1]  [1060/1627]  eta: 0:02:02  Loss: 1.2256 (1.2434)  Acc@1: 68.7500 (66.4526)  Acc@5: 87.5000 (90.7693)  time: 0.2143  data: 0.0003  max mem: 2503
Test: [Task 1]  [1070/1627]  eta: 0:02:00  Loss: 1.2399 (1.2439)  Acc@1: 68.7500 (66.4274)  Acc@5: 87.5000 (90.7680)  time: 0.2138  data: 0.0002  max mem: 2503
Test: [Task 1]  [1080/1627]  eta: 0:01:58  Loss: 1.2315 (1.2448)  Acc@1: 62.5000 (66.4142)  Acc@5: 93.7500 (90.7667)  time: 0.2133  data: 0.0002  max mem: 2503
Test: [Task 1]  [1090/1627]  eta: 0:01:55  Loss: 1.2315 (1.2446)  Acc@1: 68.7500 (66.4528)  Acc@5: 93.7500 (90.7768)  time: 0.2134  data: 0.0002  max mem: 2503
Test: [Task 1]  [1100/1627]  eta: 0:01:53  Loss: 1.1420 (1.2425)  Acc@1: 68.7500 (66.5134)  Acc@5: 93.7500 (90.8152)  time: 0.2135  data: 0.0002  max mem: 2503
Test: [Task 1]  [1110/1627]  eta: 0:01:51  Loss: 1.0951 (1.2423)  Acc@1: 68.7500 (66.5335)  Acc@5: 93.7500 (90.8135)  time: 0.2137  data: 0.0002  max mem: 2503
Test: [Task 1]  [1120/1627]  eta: 0:01:49  Loss: 1.2045 (1.2439)  Acc@1: 62.5000 (66.4474)  Acc@5: 93.7500 (90.8118)  time: 0.2144  data: 0.0003  max mem: 2503
Test: [Task 1]  [1130/1627]  eta: 0:01:47  Loss: 1.2010 (1.2447)  Acc@1: 62.5000 (66.4180)  Acc@5: 93.7500 (90.8046)  time: 0.2154  data: 0.0005  max mem: 2503
Test: [Task 1]  [1140/1627]  eta: 0:01:45  Loss: 1.1380 (1.2456)  Acc@1: 62.5000 (66.4110)  Acc@5: 93.7500 (90.7866)  time: 0.2152  data: 0.0004  max mem: 2503
Test: [Task 1]  [1150/1627]  eta: 0:01:42  Loss: 1.3912 (1.2463)  Acc@1: 68.7500 (66.3988)  Acc@5: 87.5000 (90.7743)  time: 0.2147  data: 0.0004  max mem: 2503
Test: [Task 1]  [1160/1627]  eta: 0:01:40  Loss: 1.2365 (1.2450)  Acc@1: 68.7500 (66.4567)  Acc@5: 93.7500 (90.7838)  time: 0.2157  data: 0.0004  max mem: 2503
Test: [Task 1]  [1170/1627]  eta: 0:01:38  Loss: 1.2122 (1.2442)  Acc@1: 68.7500 (66.4656)  Acc@5: 93.7500 (90.8145)  time: 0.2156  data: 0.0004  max mem: 2503
Test: [Task 1]  [1180/1627]  eta: 0:01:36  Loss: 1.2221 (1.2448)  Acc@1: 68.7500 (66.4744)  Acc@5: 93.7500 (90.8182)  time: 0.2154  data: 0.0005  max mem: 2503
Test: [Task 1]  [1190/1627]  eta: 0:01:34  Loss: 1.2745 (1.2454)  Acc@1: 62.5000 (66.4515)  Acc@5: 87.5000 (90.7798)  time: 0.2187  data: 0.0008  max mem: 2503
Test: [Task 1]  [1200/1627]  eta: 0:01:32  Loss: 1.2776 (1.2454)  Acc@1: 62.5000 (66.4446)  Acc@5: 87.5000 (90.7889)  time: 0.2181  data: 0.0007  max mem: 2503
Test: [Task 1]  [1210/1627]  eta: 0:01:30  Loss: 1.1011 (1.2460)  Acc@1: 68.7500 (66.4172)  Acc@5: 93.7500 (90.7411)  time: 0.2149  data: 0.0003  max mem: 2503
Test: [Task 1]  [1220/1627]  eta: 0:01:27  Loss: 1.0893 (1.2452)  Acc@1: 68.7500 (66.4414)  Acc@5: 93.7500 (90.7555)  time: 0.2148  data: 0.0003  max mem: 2503
Test: [Task 1]  [1230/1627]  eta: 0:01:25  Loss: 1.2272 (1.2457)  Acc@1: 62.5000 (66.4145)  Acc@5: 87.5000 (90.7240)  time: 0.2138  data: 0.0002  max mem: 2503
Test: [Task 1]  [1240/1627]  eta: 0:01:23  Loss: 1.2272 (1.2454)  Acc@1: 62.5000 (66.4132)  Acc@5: 87.5000 (90.7282)  time: 0.2133  data: 0.0002  max mem: 2503
Test: [Task 1]  [1250/1627]  eta: 0:01:21  Loss: 1.3346 (1.2459)  Acc@1: 62.5000 (66.3819)  Acc@5: 93.7500 (90.7374)  time: 0.2133  data: 0.0002  max mem: 2503
Test: [Task 1]  [1260/1627]  eta: 0:01:19  Loss: 1.3179 (1.2457)  Acc@1: 62.5000 (66.4056)  Acc@5: 93.7500 (90.7514)  time: 0.2133  data: 0.0002  max mem: 2503
Test: [Task 1]  [1270/1627]  eta: 0:01:17  Loss: 1.1454 (1.2466)  Acc@1: 62.5000 (66.3601)  Acc@5: 93.7500 (90.7307)  time: 0.2141  data: 0.0004  max mem: 2503
Test: [Task 1]  [1280/1627]  eta: 0:01:14  Loss: 1.1058 (1.2451)  Acc@1: 68.7500 (66.3837)  Acc@5: 87.5000 (90.7494)  time: 0.2168  data: 0.0014  max mem: 2503
Test: [Task 1]  [1290/1627]  eta: 0:01:12  Loss: 1.1339 (1.2454)  Acc@1: 68.7500 (66.3391)  Acc@5: 93.7500 (90.7630)  time: 0.2182  data: 0.0017  max mem: 2503
Test: [Task 1]  [1300/1627]  eta: 0:01:10  Loss: 1.1748 (1.2448)  Acc@1: 68.7500 (66.3624)  Acc@5: 93.7500 (90.7811)  time: 0.2173  data: 0.0010  max mem: 2503
Test: [Task 1]  [1310/1627]  eta: 0:01:08  Loss: 0.9829 (1.2435)  Acc@1: 75.0000 (66.4140)  Acc@5: 93.7500 (90.8038)  time: 0.2168  data: 0.0012  max mem: 2503
Test: [Task 1]  [1320/1627]  eta: 0:01:06  Loss: 0.9661 (1.2418)  Acc@1: 75.0000 (66.4885)  Acc@5: 93.7500 (90.8261)  time: 0.2163  data: 0.0012  max mem: 2503
Test: [Task 1]  [1330/1627]  eta: 0:01:04  Loss: 1.0495 (1.2415)  Acc@1: 75.0000 (66.5101)  Acc@5: 93.7500 (90.8199)  time: 0.2167  data: 0.0009  max mem: 2503
Test: [Task 1]  [1340/1627]  eta: 0:01:01  Loss: 1.1306 (1.2420)  Acc@1: 75.0000 (66.5035)  Acc@5: 93.7500 (90.8231)  time: 0.2170  data: 0.0008  max mem: 2503
Test: [Task 1]  [1350/1627]  eta: 0:00:59  Loss: 1.1306 (1.2413)  Acc@1: 68.7500 (66.5248)  Acc@5: 93.7500 (90.8355)  time: 0.2179  data: 0.0010  max mem: 2503
Test: [Task 1]  [1360/1627]  eta: 0:00:57  Loss: 1.1789 (1.2410)  Acc@1: 68.7500 (66.5366)  Acc@5: 93.7500 (90.8569)  time: 0.2175  data: 0.0012  max mem: 2503
Test: [Task 1]  [1370/1627]  eta: 0:00:55  Loss: 1.1789 (1.2399)  Acc@1: 68.7500 (66.5345)  Acc@5: 93.7500 (90.8871)  time: 0.2166  data: 0.0012  max mem: 2503
Test: [Task 1]  [1380/1627]  eta: 0:00:53  Loss: 1.1824 (1.2401)  Acc@1: 68.7500 (66.5641)  Acc@5: 93.7500 (90.8807)  time: 0.2171  data: 0.0013  max mem: 2503
Test: [Task 1]  [1390/1627]  eta: 0:00:51  Loss: 1.3595 (1.2399)  Acc@1: 68.7500 (66.5663)  Acc@5: 87.5000 (90.8879)  time: 0.2161  data: 0.0008  max mem: 2503
Test: [Task 1]  [1400/1627]  eta: 0:00:49  Loss: 1.2302 (1.2402)  Acc@1: 62.5000 (66.5774)  Acc@5: 87.5000 (90.8771)  time: 0.2158  data: 0.0006  max mem: 2503
Test: [Task 1]  [1410/1627]  eta: 0:00:46  Loss: 1.1013 (1.2397)  Acc@1: 68.7500 (66.5751)  Acc@5: 93.7500 (90.8930)  time: 0.2166  data: 0.0008  max mem: 2503
Test: [Task 1]  [1420/1627]  eta: 0:00:44  Loss: 1.2199 (1.2390)  Acc@1: 62.5000 (66.5684)  Acc@5: 93.7500 (90.9131)  time: 0.2164  data: 0.0007  max mem: 2503
Test: [Task 1]  [1430/1627]  eta: 0:00:42  Loss: 1.3568 (1.2408)  Acc@1: 62.5000 (66.5444)  Acc@5: 93.7500 (90.8761)  time: 0.2162  data: 0.0005  max mem: 2503
Test: [Task 1]  [1440/1627]  eta: 0:00:40  Loss: 1.2882 (1.2403)  Acc@1: 62.5000 (66.5120)  Acc@5: 87.5000 (90.8874)  time: 0.2159  data: 0.0003  max mem: 2503
Test: [Task 1]  [1450/1627]  eta: 0:00:38  Loss: 1.3416 (1.2418)  Acc@1: 62.5000 (66.4757)  Acc@5: 93.7500 (90.8641)  time: 0.2151  data: 0.0003  max mem: 2503
Test: [Task 1]  [1460/1627]  eta: 0:00:36  Loss: 1.3463 (1.2421)  Acc@1: 62.5000 (66.4784)  Acc@5: 93.7500 (90.8753)  time: 0.2146  data: 0.0003  max mem: 2503
Test: [Task 1]  [1470/1627]  eta: 0:00:33  Loss: 1.2787 (1.2426)  Acc@1: 68.7500 (66.4726)  Acc@5: 93.7500 (90.8693)  time: 0.2140  data: 0.0003  max mem: 2503
Test: [Task 1]  [1480/1627]  eta: 0:00:31  Loss: 1.2881 (1.2428)  Acc@1: 68.7500 (66.4796)  Acc@5: 87.5000 (90.8761)  time: 0.2138  data: 0.0002  max mem: 2503
Test: [Task 1]  [1490/1627]  eta: 0:00:29  Loss: 1.2466 (1.2431)  Acc@1: 68.7500 (66.5158)  Acc@5: 87.5000 (90.8744)  time: 0.2134  data: 0.0002  max mem: 2503
Test: [Task 1]  [1500/1627]  eta: 0:00:27  Loss: 1.2354 (1.2432)  Acc@1: 68.7500 (66.5306)  Acc@5: 87.5000 (90.8644)  time: 0.2134  data: 0.0002  max mem: 2503
Test: [Task 1]  [1510/1627]  eta: 0:00:25  Loss: 1.0042 (1.2428)  Acc@1: 68.7500 (66.5412)  Acc@5: 93.7500 (90.8711)  time: 0.2146  data: 0.0003  max mem: 2503
Test: [Task 1]  [1520/1627]  eta: 0:00:23  Loss: 1.0042 (1.2415)  Acc@1: 68.7500 (66.5722)  Acc@5: 93.7500 (90.8941)  time: 0.2159  data: 0.0003  max mem: 2503
Test: [Task 1]  [1530/1627]  eta: 0:00:20  Loss: 0.9393 (1.2407)  Acc@1: 68.7500 (66.5782)  Acc@5: 93.7500 (90.9087)  time: 0.2159  data: 0.0004  max mem: 2503
Test: [Task 1]  [1540/1627]  eta: 0:00:18  Loss: 1.0558 (1.2398)  Acc@1: 68.7500 (66.5923)  Acc@5: 93.7500 (90.9231)  time: 0.2159  data: 0.0005  max mem: 2503
Test: [Task 1]  [1550/1627]  eta: 0:00:16  Loss: 1.0558 (1.2394)  Acc@1: 68.7500 (66.6022)  Acc@5: 93.7500 (90.9292)  time: 0.2168  data: 0.0009  max mem: 2503
Test: [Task 1]  [1560/1627]  eta: 0:00:14  Loss: 1.0460 (1.2383)  Acc@1: 68.7500 (66.6360)  Acc@5: 93.7500 (90.9513)  time: 0.2168  data: 0.0011  max mem: 2503
Test: [Task 1]  [1570/1627]  eta: 0:00:12  Loss: 1.0914 (1.2382)  Acc@1: 68.7500 (66.6335)  Acc@5: 93.7500 (90.9612)  time: 0.2167  data: 0.0016  max mem: 2503
Test: [Task 1]  [1580/1627]  eta: 0:00:10  Loss: 1.1793 (1.2384)  Acc@1: 68.7500 (66.6271)  Acc@5: 93.7500 (90.9511)  time: 0.2168  data: 0.0013  max mem: 2503
Test: [Task 1]  [1590/1627]  eta: 0:00:07  Loss: 1.2187 (1.2382)  Acc@1: 68.7500 (66.6208)  Acc@5: 93.7500 (90.9727)  time: 0.2160  data: 0.0005  max mem: 2503
Test: [Task 1]  [1600/1627]  eta: 0:00:05  Loss: 1.2313 (1.2390)  Acc@1: 62.5000 (66.5756)  Acc@5: 93.7500 (90.9588)  time: 0.2163  data: 0.0008  max mem: 2503
Test: [Task 1]  [1610/1627]  eta: 0:00:03  Loss: 1.1917 (1.2385)  Acc@1: 62.5000 (66.5580)  Acc@5: 93.7500 (90.9606)  time: 0.2167  data: 0.0010  max mem: 2503
Test: [Task 1]  [1620/1627]  eta: 0:00:01  Loss: 1.0469 (1.2373)  Acc@1: 68.7500 (66.6101)  Acc@5: 93.7500 (90.9739)  time: 0.2165  data: 0.0008  max mem: 2503
Test: [Task 1]  [1626/1627]  eta: 0:00:00  Loss: 1.0487 (1.2367)  Acc@1: 68.7500 (66.6295)  Acc@5: 93.7500 (90.9726)  time: 0.2160  data: 0.0004  max mem: 2503
Test: [Task 1] Total time: 0:05:51 (0.2161 s / it)
* Acc@1 66.630 Acc@5 90.973 loss 1.237
Test: [Task 2]  [  0/625]  eta: 0:07:10  Loss: 0.3141 (0.3141)  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (100.0000)  time: 0.6891  data: 0.4706  max mem: 2503
Test: [Task 2]  [ 10/625]  eta: 0:02:38  Loss: 0.3575 (0.3992)  Acc@1: 87.5000 (89.2045)  Acc@5: 100.0000 (98.8636)  time: 0.2580  data: 0.0431  max mem: 2503
Test: [Task 2]  [ 20/625]  eta: 0:02:24  Loss: 0.3575 (0.3886)  Acc@1: 87.5000 (88.0952)  Acc@5: 100.0000 (99.4048)  time: 0.2158  data: 0.0004  max mem: 2503
Test: [Task 2]  [ 30/625]  eta: 0:02:17  Loss: 0.4362 (0.4093)  Acc@1: 87.5000 (87.0968)  Acc@5: 100.0000 (99.1935)  time: 0.2168  data: 0.0012  max mem: 2503
Test: [Task 2]  [ 40/625]  eta: 0:02:13  Loss: 0.4640 (0.4206)  Acc@1: 87.5000 (86.7378)  Acc@5: 100.0000 (99.2378)  time: 0.2176  data: 0.0026  max mem: 2503
Test: [Task 2]  [ 50/625]  eta: 0:02:09  Loss: 0.4778 (0.4375)  Acc@1: 87.5000 (86.1520)  Acc@5: 100.0000 (99.1422)  time: 0.2167  data: 0.0018  max mem: 2503
Test: [Task 2]  [ 60/625]  eta: 0:02:06  Loss: 0.4561 (0.4409)  Acc@1: 87.5000 (85.7582)  Acc@5: 100.0000 (99.1803)  time: 0.2157  data: 0.0007  max mem: 2503
Test: [Task 2]  [ 70/625]  eta: 0:02:03  Loss: 0.4082 (0.4449)  Acc@1: 81.2500 (85.3873)  Acc@5: 100.0000 (99.2077)  time: 0.2169  data: 0.0009  max mem: 2503
Test: [Task 2]  [ 80/625]  eta: 0:02:01  Loss: 0.4243 (0.4535)  Acc@1: 81.2500 (85.1852)  Acc@5: 100.0000 (98.9198)  time: 0.2173  data: 0.0006  max mem: 2503
Test: [Task 2]  [ 90/625]  eta: 0:01:58  Loss: 0.3929 (0.4458)  Acc@1: 81.2500 (85.4396)  Acc@5: 100.0000 (98.9698)  time: 0.2159  data: 0.0004  max mem: 2503
Test: [Task 2]  [100/625]  eta: 0:01:55  Loss: 0.4133 (0.4419)  Acc@1: 87.5000 (85.3960)  Acc@5: 100.0000 (99.0099)  time: 0.2143  data: 0.0003  max mem: 2503
Test: [Task 2]  [110/625]  eta: 0:01:53  Loss: 0.4425 (0.4492)  Acc@1: 87.5000 (85.3604)  Acc@5: 100.0000 (98.8176)  time: 0.2134  data: 0.0002  max mem: 2503
Test: [Task 2]  [120/625]  eta: 0:01:50  Loss: 0.4683 (0.4513)  Acc@1: 87.5000 (85.3306)  Acc@5: 100.0000 (98.7087)  time: 0.2134  data: 0.0002  max mem: 2503
Test: [Task 2]  [130/625]  eta: 0:01:48  Loss: 0.4862 (0.4536)  Acc@1: 87.5000 (85.0668)  Acc@5: 100.0000 (98.8073)  time: 0.2136  data: 0.0002  max mem: 2503
Test: [Task 2]  [140/625]  eta: 0:01:46  Loss: 0.4614 (0.4589)  Acc@1: 81.2500 (84.7518)  Acc@5: 100.0000 (98.8032)  time: 0.2135  data: 0.0002  max mem: 2503
Test: [Task 2]  [150/625]  eta: 0:01:43  Loss: 0.4378 (0.4626)  Acc@1: 81.2500 (84.5199)  Acc@5: 100.0000 (98.7169)  time: 0.2143  data: 0.0003  max mem: 2503
Test: [Task 2]  [160/625]  eta: 0:01:41  Loss: 0.4411 (0.4689)  Acc@1: 81.2500 (84.2003)  Acc@5: 100.0000 (98.6413)  time: 0.2160  data: 0.0007  max mem: 2503
Test: [Task 2]  [170/625]  eta: 0:01:39  Loss: 0.4411 (0.4656)  Acc@1: 81.2500 (84.3933)  Acc@5: 100.0000 (98.6477)  time: 0.2165  data: 0.0011  max mem: 2503
Test: [Task 2]  [180/625]  eta: 0:01:37  Loss: 0.4274 (0.4617)  Acc@1: 93.7500 (84.5649)  Acc@5: 100.0000 (98.6878)  time: 0.2168  data: 0.0010  max mem: 2503
Test: [Task 2]  [190/625]  eta: 0:01:34  Loss: 0.4347 (0.4671)  Acc@1: 81.2500 (84.4568)  Acc@5: 100.0000 (98.6257)  time: 0.2169  data: 0.0008  max mem: 2503
Test: [Task 2]  [200/625]  eta: 0:01:32  Loss: 0.4912 (0.4691)  Acc@1: 81.2500 (84.3905)  Acc@5: 100.0000 (98.6007)  time: 0.2165  data: 0.0008  max mem: 2503
Test: [Task 2]  [210/625]  eta: 0:01:30  Loss: 0.5238 (0.4716)  Acc@1: 81.2500 (84.3009)  Acc@5: 100.0000 (98.5486)  time: 0.2172  data: 0.0008  max mem: 2503
Test: [Task 2]  [220/625]  eta: 0:01:28  Loss: 0.3839 (0.4673)  Acc@1: 87.5000 (84.5871)  Acc@5: 100.0000 (98.5860)  time: 0.2165  data: 0.0008  max mem: 2503
Test: [Task 2]  [230/625]  eta: 0:01:26  Loss: 0.3778 (0.4656)  Acc@1: 87.5000 (84.7132)  Acc@5: 100.0000 (98.6472)  time: 0.2168  data: 0.0008  max mem: 2503
Test: [Task 2]  [240/625]  eta: 0:01:23  Loss: 0.4757 (0.4665)  Acc@1: 81.2500 (84.6732)  Acc@5: 100.0000 (98.6255)  time: 0.2181  data: 0.0010  max mem: 2503
Test: [Task 2]  [250/625]  eta: 0:01:21  Loss: 0.5118 (0.4686)  Acc@1: 87.5000 (84.7610)  Acc@5: 100.0000 (98.5807)  time: 0.2169  data: 0.0010  max mem: 2503
Test: [Task 2]  [260/625]  eta: 0:01:19  Loss: 0.5147 (0.4694)  Acc@1: 87.5000 (84.6983)  Acc@5: 100.0000 (98.5632)  time: 0.2153  data: 0.0005  max mem: 2503
Test: [Task 2]  [270/625]  eta: 0:01:17  Loss: 0.4635 (0.4706)  Acc@1: 87.5000 (84.7555)  Acc@5: 100.0000 (98.5470)  time: 0.2149  data: 0.0006  max mem: 2503
Test: [Task 2]  [280/625]  eta: 0:01:15  Loss: 0.4387 (0.4706)  Acc@1: 81.2500 (84.6753)  Acc@5: 100.0000 (98.5543)  time: 0.2157  data: 0.0009  max mem: 2503
Test: [Task 2]  [290/625]  eta: 0:01:12  Loss: 0.3653 (0.4704)  Acc@1: 81.2500 (84.7509)  Acc@5: 100.0000 (98.5395)  time: 0.2163  data: 0.0009  max mem: 2503
Test: [Task 2]  [300/625]  eta: 0:01:10  Loss: 0.4202 (0.4713)  Acc@1: 81.2500 (84.6138)  Acc@5: 100.0000 (98.5880)  time: 0.2163  data: 0.0008  max mem: 2503
Test: [Task 2]  [310/625]  eta: 0:01:08  Loss: 0.5062 (0.4730)  Acc@1: 81.2500 (84.4855)  Acc@5: 100.0000 (98.5932)  time: 0.2163  data: 0.0007  max mem: 2503
Test: [Task 2]  [320/625]  eta: 0:01:06  Loss: 0.2901 (0.4648)  Acc@1: 93.7500 (84.7936)  Acc@5: 100.0000 (98.6371)  time: 0.2155  data: 0.0005  max mem: 2503
Test: [Task 2]  [330/625]  eta: 0:01:04  Loss: 0.2727 (0.4633)  Acc@1: 93.7500 (84.7432)  Acc@5: 100.0000 (98.6782)  time: 0.2146  data: 0.0003  max mem: 2503
Test: [Task 2]  [340/625]  eta: 0:01:01  Loss: 0.2152 (0.4541)  Acc@1: 87.5000 (85.0257)  Acc@5: 100.0000 (98.7170)  time: 0.2144  data: 0.0003  max mem: 2503
Test: [Task 2]  [350/625]  eta: 0:00:59  Loss: 0.1610 (0.4504)  Acc@1: 93.7500 (85.0605)  Acc@5: 100.0000 (98.7536)  time: 0.2139  data: 0.0002  max mem: 2503
Test: [Task 2]  [360/625]  eta: 0:00:57  Loss: 0.4303 (0.4517)  Acc@1: 87.5000 (85.0069)  Acc@5: 100.0000 (98.7535)  time: 0.2136  data: 0.0002  max mem: 2503
Test: [Task 2]  [370/625]  eta: 0:00:55  Loss: 0.3745 (0.4476)  Acc@1: 87.5000 (85.1415)  Acc@5: 100.0000 (98.7871)  time: 0.2136  data: 0.0002  max mem: 2503
Test: [Task 2]  [380/625]  eta: 0:00:53  Loss: 0.3763 (0.4490)  Acc@1: 87.5000 (85.1378)  Acc@5: 100.0000 (98.7369)  time: 0.2135  data: 0.0002  max mem: 2503
Test: [Task 2]  [390/625]  eta: 0:00:50  Loss: 0.3014 (0.4461)  Acc@1: 87.5000 (85.1982)  Acc@5: 100.0000 (98.7212)  time: 0.2139  data: 0.0004  max mem: 2503
Test: [Task 2]  [400/625]  eta: 0:00:48  Loss: 0.2239 (0.4412)  Acc@1: 93.7500 (85.3335)  Acc@5: 100.0000 (98.7531)  time: 0.2150  data: 0.0009  max mem: 2503
Test: [Task 2]  [410/625]  eta: 0:00:46  Loss: 0.2120 (0.4398)  Acc@1: 93.7500 (85.3710)  Acc@5: 100.0000 (98.7530)  time: 0.2154  data: 0.0009  max mem: 2503
Test: [Task 2]  [420/625]  eta: 0:00:44  Loss: 0.2347 (0.4394)  Acc@1: 87.5000 (85.4068)  Acc@5: 100.0000 (98.7530)  time: 0.2157  data: 0.0005  max mem: 2503
Test: [Task 2]  [430/625]  eta: 0:00:42  Loss: 0.3447 (0.4407)  Acc@1: 87.5000 (85.3538)  Acc@5: 100.0000 (98.7819)  time: 0.2160  data: 0.0004  max mem: 2503
Test: [Task 2]  [440/625]  eta: 0:00:40  Loss: 0.2472 (0.4355)  Acc@1: 87.5000 (85.5300)  Acc@5: 100.0000 (98.8095)  time: 0.2163  data: 0.0012  max mem: 2503
Test: [Task 2]  [450/625]  eta: 0:00:37  Loss: 0.2008 (0.4309)  Acc@1: 93.7500 (85.6292)  Acc@5: 100.0000 (98.8359)  time: 0.2162  data: 0.0012  max mem: 2503
Test: [Task 2]  [460/625]  eta: 0:00:35  Loss: 0.2014 (0.4268)  Acc@1: 93.7500 (85.7646)  Acc@5: 100.0000 (98.8612)  time: 0.2158  data: 0.0007  max mem: 2503
Test: [Task 2]  [470/625]  eta: 0:00:33  Loss: 0.2304 (0.4255)  Acc@1: 87.5000 (85.7617)  Acc@5: 100.0000 (98.8854)  time: 0.2159  data: 0.0007  max mem: 2503
Test: [Task 2]  [480/625]  eta: 0:00:31  Loss: 0.3087 (0.4228)  Acc@1: 87.5000 (85.8368)  Acc@5: 100.0000 (98.9085)  time: 0.2165  data: 0.0016  max mem: 2503
Test: [Task 2]  [490/625]  eta: 0:00:29  Loss: 0.2097 (0.4191)  Acc@1: 93.7500 (86.0107)  Acc@5: 100.0000 (98.9308)  time: 0.2162  data: 0.0015  max mem: 2503
Test: [Task 2]  [500/625]  eta: 0:00:27  Loss: 0.2097 (0.4167)  Acc@1: 93.7500 (86.1028)  Acc@5: 100.0000 (98.9521)  time: 0.2158  data: 0.0007  max mem: 2503
Test: [Task 2]  [510/625]  eta: 0:00:24  Loss: 0.3118 (0.4205)  Acc@1: 81.2500 (85.9711)  Acc@5: 100.0000 (98.9726)  time: 0.2166  data: 0.0012  max mem: 2503
Test: [Task 2]  [520/625]  eta: 0:00:22  Loss: 0.4706 (0.4235)  Acc@1: 75.0000 (85.7845)  Acc@5: 100.0000 (98.9803)  time: 0.2165  data: 0.0010  max mem: 2503
Test: [Task 2]  [530/625]  eta: 0:00:20  Loss: 0.3848 (0.4219)  Acc@1: 87.5000 (85.8404)  Acc@5: 100.0000 (98.9995)  time: 0.2162  data: 0.0006  max mem: 2503
Test: [Task 2]  [540/625]  eta: 0:00:18  Loss: 0.2558 (0.4188)  Acc@1: 93.7500 (86.0097)  Acc@5: 100.0000 (99.0065)  time: 0.2159  data: 0.0008  max mem: 2503
Test: [Task 2]  [550/625]  eta: 0:00:16  Loss: 0.1693 (0.4143)  Acc@1: 93.7500 (86.1842)  Acc@5: 100.0000 (99.0245)  time: 0.2171  data: 0.0020  max mem: 2503
Test: [Task 2]  [560/625]  eta: 0:00:14  Loss: 0.1110 (0.4092)  Acc@1: 93.7500 (86.3636)  Acc@5: 100.0000 (99.0419)  time: 0.2169  data: 0.0017  max mem: 2503
Test: [Task 2]  [570/625]  eta: 0:00:11  Loss: 0.2395 (0.4101)  Acc@1: 93.7500 (86.3398)  Acc@5: 100.0000 (99.0587)  time: 0.2148  data: 0.0003  max mem: 2503
Test: [Task 2]  [580/625]  eta: 0:00:09  Loss: 0.3004 (0.4068)  Acc@1: 87.5000 (86.4350)  Acc@5: 100.0000 (99.0749)  time: 0.2147  data: 0.0004  max mem: 2503
Test: [Task 2]  [590/625]  eta: 0:00:07  Loss: 0.1608 (0.4045)  Acc@1: 93.7500 (86.5271)  Acc@5: 100.0000 (99.0905)  time: 0.2145  data: 0.0003  max mem: 2503
Test: [Task 2]  [600/625]  eta: 0:00:05  Loss: 0.3605 (0.4062)  Acc@1: 87.5000 (86.4705)  Acc@5: 100.0000 (99.0849)  time: 0.2139  data: 0.0002  max mem: 2503
Test: [Task 2]  [610/625]  eta: 0:00:03  Loss: 0.5562 (0.4113)  Acc@1: 81.2500 (86.2930)  Acc@5: 100.0000 (99.0385)  time: 0.2132  data: 0.0002  max mem: 2503
Test: [Task 2]  [620/625]  eta: 0:00:01  Loss: 0.4963 (0.4122)  Acc@1: 81.2500 (86.2520)  Acc@5: 100.0000 (99.0338)  time: 0.2132  data: 0.0002  max mem: 2503
Test: [Task 2]  [624/625]  eta: 0:00:00  Loss: 0.4323 (0.4119)  Acc@1: 87.5000 (86.2400)  Acc@5: 100.0000 (99.0400)  time: 0.2133  data: 0.0002  max mem: 2503
Test: [Task 2] Total time: 0:02:15 (0.2165 s / it)
* Acc@1 86.240 Acc@5 99.040 loss 0.412
Test: [Task 3]  [  0/625]  eta: 0:05:06  Loss: 0.0925 (0.0925)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)  time: 0.4897  data: 0.2751  max mem: 2503
Test: [Task 3]  [ 10/625]  eta: 0:02:27  Loss: 0.2877 (0.2366)  Acc@1: 100.0000 (97.1591)  Acc@5: 100.0000 (99.4318)  time: 0.2401  data: 0.0254  max mem: 2503
Test: [Task 3]  [ 20/625]  eta: 0:02:18  Loss: 0.2501 (0.2488)  Acc@1: 100.0000 (96.7262)  Acc@5: 100.0000 (99.4048)  time: 0.2152  data: 0.0006  max mem: 2503
Test: [Task 3]  [ 30/625]  eta: 0:02:13  Loss: 0.2119 (0.2586)  Acc@1: 93.7500 (96.1694)  Acc@5: 100.0000 (99.3952)  time: 0.2156  data: 0.0007  max mem: 2503
Test: [Task 3]  [ 40/625]  eta: 0:02:09  Loss: 0.1418 (0.2261)  Acc@1: 100.0000 (96.7988)  Acc@5: 100.0000 (99.5427)  time: 0.2155  data: 0.0005  max mem: 2503
Test: [Task 3]  [ 50/625]  eta: 0:02:07  Loss: 0.1470 (0.2233)  Acc@1: 100.0000 (96.8137)  Acc@5: 100.0000 (99.6324)  time: 0.2163  data: 0.0013  max mem: 2503
Test: [Task 3]  [ 60/625]  eta: 0:02:04  Loss: 0.1940 (0.2203)  Acc@1: 100.0000 (96.9262)  Acc@5: 100.0000 (99.6926)  time: 0.2172  data: 0.0017  max mem: 2503
Test: [Task 3]  [ 70/625]  eta: 0:02:02  Loss: 0.1551 (0.2111)  Acc@1: 100.0000 (97.0070)  Acc@5: 100.0000 (99.6479)  time: 0.2168  data: 0.0016  max mem: 2503
Test: [Task 3]  [ 80/625]  eta: 0:01:59  Loss: 0.1601 (0.2143)  Acc@1: 100.0000 (96.9136)  Acc@5: 100.0000 (99.6914)  time: 0.2163  data: 0.0014  max mem: 2503
Test: [Task 3]  [ 90/625]  eta: 0:01:57  Loss: 0.1666 (0.2125)  Acc@1: 100.0000 (96.9780)  Acc@5: 100.0000 (99.5879)  time: 0.2161  data: 0.0010  max mem: 2503
Test: [Task 3]  [100/625]  eta: 0:01:54  Loss: 0.1584 (0.2079)  Acc@1: 100.0000 (97.2153)  Acc@5: 100.0000 (99.6287)  time: 0.2163  data: 0.0010  max mem: 2503
Test: [Task 3]  [110/625]  eta: 0:01:52  Loss: 0.1513 (0.2005)  Acc@1: 100.0000 (97.4662)  Acc@5: 100.0000 (99.6622)  time: 0.2161  data: 0.0007  max mem: 2503
Test: [Task 3]  [120/625]  eta: 0:01:50  Loss: 0.1529 (0.2033)  Acc@1: 100.0000 (97.4174)  Acc@5: 100.0000 (99.6901)  time: 0.2157  data: 0.0005  max mem: 2503
Test: [Task 3]  [130/625]  eta: 0:01:48  Loss: 0.1972 (0.2032)  Acc@1: 93.7500 (97.3282)  Acc@5: 100.0000 (99.5706)  time: 0.2163  data: 0.0007  max mem: 2503
Test: [Task 3]  [140/625]  eta: 0:01:45  Loss: 0.2252 (0.2100)  Acc@1: 93.7500 (97.1631)  Acc@5: 100.0000 (99.4681)  time: 0.2167  data: 0.0010  max mem: 2503
Test: [Task 3]  [150/625]  eta: 0:01:43  Loss: 0.2320 (0.2160)  Acc@1: 93.7500 (97.0199)  Acc@5: 100.0000 (99.4205)  time: 0.2163  data: 0.0007  max mem: 2503
Test: [Task 3]  [160/625]  eta: 0:01:41  Loss: 0.1721 (0.2162)  Acc@1: 100.0000 (97.1273)  Acc@5: 100.0000 (99.3789)  time: 0.2168  data: 0.0015  max mem: 2503
Test: [Task 3]  [170/625]  eta: 0:01:39  Loss: 0.1313 (0.2137)  Acc@1: 100.0000 (97.1857)  Acc@5: 100.0000 (99.4152)  time: 0.2187  data: 0.0015  max mem: 2503
Test: [Task 3]  [180/625]  eta: 0:01:36  Loss: 0.2108 (0.2175)  Acc@1: 100.0000 (97.0304)  Acc@5: 100.0000 (99.3439)  time: 0.2180  data: 0.0004  max mem: 2503
Test: [Task 3]  [190/625]  eta: 0:01:34  Loss: 0.2475 (0.2167)  Acc@1: 93.7500 (96.9895)  Acc@5: 100.0000 (99.3783)  time: 0.2157  data: 0.0003  max mem: 2503
Test: [Task 3]  [200/625]  eta: 0:01:32  Loss: 0.2242 (0.2185)  Acc@1: 93.7500 (96.7662)  Acc@5: 100.0000 (99.3781)  time: 0.2156  data: 0.0003  max mem: 2503
Test: [Task 3]  [210/625]  eta: 0:01:30  Loss: 0.2242 (0.2194)  Acc@1: 93.7500 (96.7417)  Acc@5: 100.0000 (99.3187)  time: 0.2147  data: 0.0003  max mem: 2503
Test: [Task 3]  [220/625]  eta: 0:01:28  Loss: 0.1813 (0.2201)  Acc@1: 100.0000 (96.7477)  Acc@5: 100.0000 (99.2647)  time: 0.2137  data: 0.0003  max mem: 2503
Test: [Task 3]  [230/625]  eta: 0:01:25  Loss: 0.1952 (0.2204)  Acc@1: 100.0000 (96.7262)  Acc@5: 100.0000 (99.2424)  time: 0.2144  data: 0.0005  max mem: 2503
Test: [Task 3]  [240/625]  eta: 0:01:23  Loss: 0.1837 (0.2236)  Acc@1: 93.7500 (96.6805)  Acc@5: 100.0000 (99.2220)  time: 0.2146  data: 0.0004  max mem: 2503
Test: [Task 3]  [250/625]  eta: 0:01:21  Loss: 0.1330 (0.2207)  Acc@1: 100.0000 (96.7131)  Acc@5: 100.0000 (99.2530)  time: 0.2145  data: 0.0004  max mem: 2503
Test: [Task 3]  [260/625]  eta: 0:01:19  Loss: 0.1330 (0.2196)  Acc@1: 100.0000 (96.7193)  Acc@5: 100.0000 (99.2577)  time: 0.2156  data: 0.0006  max mem: 2503
Test: [Task 3]  [270/625]  eta: 0:01:17  Loss: 0.1565 (0.2192)  Acc@1: 93.7500 (96.7020)  Acc@5: 100.0000 (99.2389)  time: 0.2163  data: 0.0007  max mem: 2503
Test: [Task 3]  [280/625]  eta: 0:01:14  Loss: 0.1565 (0.2186)  Acc@1: 100.0000 (96.7082)  Acc@5: 100.0000 (99.2438)  time: 0.2169  data: 0.0012  max mem: 2503
Test: [Task 3]  [290/625]  eta: 0:01:12  Loss: 0.1654 (0.2189)  Acc@1: 100.0000 (96.6924)  Acc@5: 100.0000 (99.2483)  time: 0.2168  data: 0.0013  max mem: 2503
Test: [Task 3]  [300/625]  eta: 0:01:10  Loss: 0.1714 (0.2249)  Acc@1: 93.7500 (96.4909)  Acc@5: 100.0000 (99.1279)  time: 0.2169  data: 0.0015  max mem: 2503
Test: [Task 3]  [310/625]  eta: 0:01:08  Loss: 0.1564 (0.2261)  Acc@1: 100.0000 (96.4630)  Acc@5: 100.0000 (99.1158)  time: 0.2172  data: 0.0015  max mem: 2503
Test: [Task 3]  [320/625]  eta: 0:01:06  Loss: 0.1602 (0.2250)  Acc@1: 100.0000 (96.4759)  Acc@5: 100.0000 (99.1044)  time: 0.2168  data: 0.0010  max mem: 2503
Test: [Task 3]  [330/625]  eta: 0:01:03  Loss: 0.2171 (0.2259)  Acc@1: 93.7500 (96.4690)  Acc@5: 100.0000 (99.1125)  time: 0.2162  data: 0.0007  max mem: 2503
Test: [Task 3]  [340/625]  eta: 0:01:01  Loss: 0.1604 (0.2235)  Acc@1: 100.0000 (96.5176)  Acc@5: 100.0000 (99.1386)  time: 0.2160  data: 0.0006  max mem: 2503
Test: [Task 3]  [350/625]  eta: 0:00:59  Loss: 0.1472 (0.2235)  Acc@1: 100.0000 (96.5100)  Acc@5: 100.0000 (99.1275)  time: 0.2174  data: 0.0017  max mem: 2503
Test: [Task 3]  [360/625]  eta: 0:00:57  Loss: 0.1756 (0.2244)  Acc@1: 93.7500 (96.4508)  Acc@5: 100.0000 (99.1517)  time: 0.2174  data: 0.0020  max mem: 2503
Test: [Task 3]  [370/625]  eta: 0:00:55  Loss: 0.2351 (0.2252)  Acc@1: 93.7500 (96.4117)  Acc@5: 100.0000 (99.1408)  time: 0.2173  data: 0.0017  max mem: 2503
Test: [Task 3]  [380/625]  eta: 0:00:53  Loss: 0.1523 (0.2234)  Acc@1: 93.7500 (96.4567)  Acc@5: 100.0000 (99.1634)  time: 0.2167  data: 0.0013  max mem: 2503
Test: [Task 3]  [390/625]  eta: 0:00:50  Loss: 0.1329 (0.2232)  Acc@1: 100.0000 (96.4354)  Acc@5: 100.0000 (99.1848)  time: 0.2175  data: 0.0018  max mem: 2503
Test: [Task 3]  [400/625]  eta: 0:00:48  Loss: 0.1477 (0.2228)  Acc@1: 93.7500 (96.3996)  Acc@5: 100.0000 (99.1895)  time: 0.2183  data: 0.0018  max mem: 2503
Test: [Task 3]  [410/625]  eta: 0:00:46  Loss: 0.1572 (0.2233)  Acc@1: 93.7500 (96.4112)  Acc@5: 100.0000 (99.1940)  time: 0.2184  data: 0.0014  max mem: 2503
Test: [Task 3]  [420/625]  eta: 0:00:44  Loss: 0.1688 (0.2230)  Acc@1: 100.0000 (96.3777)  Acc@5: 100.0000 (99.1983)  time: 0.2213  data: 0.0015  max mem: 2503
Test: [Task 3]  [430/625]  eta: 0:00:42  Loss: 0.1688 (0.2230)  Acc@1: 93.7500 (96.3602)  Acc@5: 100.0000 (99.2024)  time: 0.2197  data: 0.0014  max mem: 2503
Test: [Task 3]  [440/625]  eta: 0:00:40  Loss: 0.2072 (0.2237)  Acc@1: 93.7500 (96.3152)  Acc@5: 100.0000 (99.1922)  time: 0.2161  data: 0.0013  max mem: 2503
Test: [Task 3]  [450/625]  eta: 0:00:37  Loss: 0.1769 (0.2230)  Acc@1: 100.0000 (96.3415)  Acc@5: 100.0000 (99.2101)  time: 0.2163  data: 0.0005  max mem: 2503
Test: [Task 3]  [460/625]  eta: 0:00:35  Loss: 0.1731 (0.2222)  Acc@1: 100.0000 (96.3530)  Acc@5: 100.0000 (99.2137)  time: 0.2156  data: 0.0003  max mem: 2503
Test: [Task 3]  [470/625]  eta: 0:00:33  Loss: 0.1913 (0.2222)  Acc@1: 100.0000 (96.3508)  Acc@5: 100.0000 (99.2171)  time: 0.2142  data: 0.0003  max mem: 2503
Test: [Task 3]  [480/625]  eta: 0:00:31  Loss: 0.1913 (0.2231)  Acc@1: 100.0000 (96.3488)  Acc@5: 100.0000 (99.2204)  time: 0.2142  data: 0.0003  max mem: 2503
Test: [Task 3]  [490/625]  eta: 0:00:29  Loss: 0.1876 (0.2231)  Acc@1: 93.7500 (96.3340)  Acc@5: 100.0000 (99.2108)  time: 0.2141  data: 0.0003  max mem: 2503
Test: [Task 3]  [500/625]  eta: 0:00:27  Loss: 0.1155 (0.2219)  Acc@1: 100.0000 (96.3698)  Acc@5: 100.0000 (99.2265)  time: 0.2138  data: 0.0003  max mem: 2503
Test: [Task 3]  [510/625]  eta: 0:00:24  Loss: 0.1155 (0.2205)  Acc@1: 100.0000 (96.3919)  Acc@5: 100.0000 (99.2417)  time: 0.2145  data: 0.0005  max mem: 2503
Test: [Task 3]  [520/625]  eta: 0:00:22  Loss: 0.1548 (0.2205)  Acc@1: 100.0000 (96.4012)  Acc@5: 100.0000 (99.2562)  time: 0.2170  data: 0.0015  max mem: 2503
Test: [Task 3]  [530/625]  eta: 0:00:20  Loss: 0.1996 (0.2214)  Acc@1: 93.7500 (96.3277)  Acc@5: 100.0000 (99.2702)  time: 0.2176  data: 0.0018  max mem: 2503
Test: [Task 3]  [540/625]  eta: 0:00:18  Loss: 0.2015 (0.2224)  Acc@1: 93.7500 (96.3147)  Acc@5: 100.0000 (99.2722)  time: 0.2157  data: 0.0008  max mem: 2503
Test: [Task 3]  [550/625]  eta: 0:00:16  Loss: 0.2015 (0.2228)  Acc@1: 93.7500 (96.3022)  Acc@5: 100.0000 (99.2627)  time: 0.2155  data: 0.0006  max mem: 2503
Test: [Task 3]  [560/625]  eta: 0:00:14  Loss: 0.1987 (0.2228)  Acc@1: 93.7500 (96.3235)  Acc@5: 100.0000 (99.2647)  time: 0.2161  data: 0.0007  max mem: 2503
Test: [Task 3]  [570/625]  eta: 0:00:11  Loss: 0.1987 (0.2222)  Acc@1: 100.0000 (96.3222)  Acc@5: 100.0000 (99.2776)  time: 0.2168  data: 0.0013  max mem: 2503
Test: [Task 3]  [580/625]  eta: 0:00:09  Loss: 0.2231 (0.2237)  Acc@1: 93.7500 (96.2672)  Acc@5: 100.0000 (99.2793)  time: 0.2167  data: 0.0015  max mem: 2503
Test: [Task 3]  [590/625]  eta: 0:00:07  Loss: 0.1910 (0.2228)  Acc@1: 100.0000 (96.3092)  Acc@5: 100.0000 (99.2915)  time: 0.2161  data: 0.0008  max mem: 2503
Test: [Task 3]  [600/625]  eta: 0:00:05  Loss: 0.1906 (0.2231)  Acc@1: 100.0000 (96.2666)  Acc@5: 100.0000 (99.2824)  time: 0.2161  data: 0.0009  max mem: 2503
Test: [Task 3]  [610/625]  eta: 0:00:03  Loss: 0.1860 (0.2224)  Acc@1: 93.7500 (96.2664)  Acc@5: 100.0000 (99.2942)  time: 0.2159  data: 0.0009  max mem: 2503
Test: [Task 3]  [620/625]  eta: 0:00:01  Loss: 0.2003 (0.2233)  Acc@1: 93.7500 (96.2460)  Acc@5: 100.0000 (99.2955)  time: 0.2156  data: 0.0005  max mem: 2503
Test: [Task 3]  [624/625]  eta: 0:00:00  Loss: 0.1572 (0.2225)  Acc@1: 100.0000 (96.2700)  Acc@5: 100.0000 (99.3000)  time: 0.2157  data: 0.0004  max mem: 2503
Test: [Task 3] Total time: 0:02:15 (0.2170 s / it)
* Acc@1 96.270 Acc@5 99.300 loss 0.223
Test: [Task 4]  [ 0/29]  eta: 0:00:18  Loss: 1.4949 (1.4949)  Acc@1: 56.2500 (56.2500)  Acc@5: 93.7500 (93.7500)  time: 0.6247  data: 0.4110  max mem: 2503
Test: [Task 4]  [10/29]  eta: 0:00:04  Loss: 1.8319 (1.7787)  Acc@1: 50.0000 (53.9773)  Acc@5: 87.5000 (87.5000)  time: 0.2536  data: 0.0378  max mem: 2503
Test: [Task 4]  [20/29]  eta: 0:00:02  Loss: 1.6474 (1.7524)  Acc@1: 56.2500 (55.9524)  Acc@5: 87.5000 (85.1190)  time: 0.2161  data: 0.0005  max mem: 2503
Test: [Task 4]  [28/29]  eta: 0:00:00  Loss: 1.4786 (1.6485)  Acc@1: 62.5000 (58.8235)  Acc@5: 87.5000 (86.2745)  time: 0.2126  data: 0.0004  max mem: 2503
Test: [Task 4] Total time: 0:00:06 (0.2318 s / it)
* Acc@1 58.824 Acc@5 86.275 loss 1.649
Test: [Task 5]  [  0/625]  eta: 0:06:41  Loss: 0.1735 (0.1735)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)  time: 0.6416  data: 0.4252  max mem: 2503
Test: [Task 5]  [ 10/625]  eta: 0:02:36  Loss: 0.4327 (0.4241)  Acc@1: 87.5000 (89.7727)  Acc@5: 100.0000 (98.2955)  time: 0.2547  data: 0.0399  max mem: 2503
Test: [Task 5]  [ 20/625]  eta: 0:02:22  Loss: 0.3683 (0.3712)  Acc@1: 93.7500 (91.3690)  Acc@5: 100.0000 (98.8095)  time: 0.2153  data: 0.0009  max mem: 2503
Test: [Task 5]  [ 30/625]  eta: 0:02:16  Loss: 0.3639 (0.4001)  Acc@1: 87.5000 (89.7177)  Acc@5: 100.0000 (98.7903)  time: 0.2146  data: 0.0003  max mem: 2503
Test: [Task 5]  [ 40/625]  eta: 0:02:11  Loss: 0.4101 (0.3924)  Acc@1: 87.5000 (89.9390)  Acc@5: 100.0000 (98.9329)  time: 0.2147  data: 0.0003  max mem: 2503
Test: [Task 5]  [ 50/625]  eta: 0:02:08  Loss: 0.4101 (0.4131)  Acc@1: 87.5000 (89.4608)  Acc@5: 100.0000 (98.5294)  time: 0.2144  data: 0.0003  max mem: 2503
Test: [Task 5]  [ 60/625]  eta: 0:02:05  Loss: 0.4337 (0.4063)  Acc@1: 87.5000 (89.7541)  Acc@5: 100.0000 (98.5656)  time: 0.2136  data: 0.0002  max mem: 2503
Test: [Task 5]  [ 70/625]  eta: 0:02:02  Loss: 0.3569 (0.4126)  Acc@1: 87.5000 (89.5246)  Acc@5: 100.0000 (98.4155)  time: 0.2132  data: 0.0002  max mem: 2503
Test: [Task 5]  [ 80/625]  eta: 0:01:59  Loss: 0.3952 (0.4202)  Acc@1: 87.5000 (89.2747)  Acc@5: 100.0000 (98.4568)  time: 0.2132  data: 0.0002  max mem: 2503
Test: [Task 5]  [ 90/625]  eta: 0:01:57  Loss: 0.3416 (0.4086)  Acc@1: 93.7500 (89.6978)  Acc@5: 100.0000 (98.6264)  time: 0.2132  data: 0.0002  max mem: 2503
Test: [Task 5]  [100/625]  eta: 0:01:54  Loss: 0.3442 (0.4131)  Acc@1: 87.5000 (89.2327)  Acc@5: 100.0000 (98.5767)  time: 0.2131  data: 0.0002  max mem: 2503
Test: [Task 5]  [110/625]  eta: 0:01:52  Loss: 0.3995 (0.4168)  Acc@1: 81.2500 (88.9077)  Acc@5: 100.0000 (98.5923)  time: 0.2138  data: 0.0003  max mem: 2503
Test: [Task 5]  [120/625]  eta: 0:01:49  Loss: 0.3371 (0.4057)  Acc@1: 87.5000 (89.2045)  Acc@5: 100.0000 (98.6570)  time: 0.2153  data: 0.0007  max mem: 2503
Test: [Task 5]  [130/625]  eta: 0:01:47  Loss: 0.3777 (0.4098)  Acc@1: 87.5000 (89.0267)  Acc@5: 100.0000 (98.6641)  time: 0.2159  data: 0.0009  max mem: 2503
Test: [Task 5]  [140/625]  eta: 0:01:45  Loss: 0.4296 (0.4065)  Acc@1: 87.5000 (89.3174)  Acc@5: 100.0000 (98.5816)  time: 0.2158  data: 0.0009  max mem: 2503
Test: [Task 5]  [150/625]  eta: 0:01:43  Loss: 0.3244 (0.4076)  Acc@1: 87.5000 (89.3212)  Acc@5: 100.0000 (98.5513)  time: 0.2160  data: 0.0008  max mem: 2503
Test: [Task 5]  [160/625]  eta: 0:01:41  Loss: 0.4664 (0.4121)  Acc@1: 87.5000 (89.2081)  Acc@5: 100.0000 (98.4860)  time: 0.2160  data: 0.0009  max mem: 2503
Test: [Task 5]  [170/625]  eta: 0:01:38  Loss: 0.5020 (0.4188)  Acc@1: 87.5000 (89.0351)  Acc@5: 100.0000 (98.5015)  time: 0.2156  data: 0.0009  max mem: 2503
Test: [Task 5]  [180/625]  eta: 0:01:36  Loss: 0.4963 (0.4201)  Acc@1: 87.5000 (89.1575)  Acc@5: 100.0000 (98.4461)  time: 0.2158  data: 0.0014  max mem: 2503
Test: [Task 5]  [190/625]  eta: 0:01:34  Loss: 0.4486 (0.4289)  Acc@1: 87.5000 (89.0380)  Acc@5: 100.0000 (98.3312)  time: 0.2162  data: 0.0013  max mem: 2503
Test: [Task 5]  [200/625]  eta: 0:01:32  Loss: 0.4301 (0.4267)  Acc@1: 87.5000 (89.0547)  Acc@5: 100.0000 (98.3209)  time: 0.2167  data: 0.0007  max mem: 2503
Test: [Task 5]  [210/625]  eta: 0:01:30  Loss: 0.4897 (0.4335)  Acc@1: 87.5000 (88.8922)  Acc@5: 100.0000 (98.2524)  time: 0.2171  data: 0.0008  max mem: 2503
Test: [Task 5]  [220/625]  eta: 0:01:27  Loss: 0.5478 (0.4340)  Acc@1: 87.5000 (88.8857)  Acc@5: 100.0000 (98.2749)  time: 0.2158  data: 0.0006  max mem: 2503
Test: [Task 5]  [230/625]  eta: 0:01:25  Loss: 0.4835 (0.4358)  Acc@1: 87.5000 (88.8258)  Acc@5: 100.0000 (98.2143)  time: 0.2145  data: 0.0004  max mem: 2503
Test: [Task 5]  [240/625]  eta: 0:01:23  Loss: 0.4705 (0.4359)  Acc@1: 87.5000 (88.7967)  Acc@5: 100.0000 (98.2365)  time: 0.2159  data: 0.0007  max mem: 2503
Test: [Task 5]  [250/625]  eta: 0:01:21  Loss: 0.4049 (0.4358)  Acc@1: 87.5000 (88.8695)  Acc@5: 100.0000 (98.2321)  time: 0.2185  data: 0.0011  max mem: 2503
Test: [Task 5]  [260/625]  eta: 0:01:19  Loss: 0.4098 (0.4369)  Acc@1: 87.5000 (88.8170)  Acc@5: 100.0000 (98.2040)  time: 0.2187  data: 0.0011  max mem: 2503
Test: [Task 5]  [270/625]  eta: 0:01:17  Loss: 0.4248 (0.4352)  Acc@1: 93.7500 (88.9760)  Acc@5: 100.0000 (98.1780)  time: 0.2169  data: 0.0008  max mem: 2503
Test: [Task 5]  [280/625]  eta: 0:01:14  Loss: 0.2855 (0.4316)  Acc@1: 93.7500 (88.9902)  Acc@5: 100.0000 (98.2429)  time: 0.2169  data: 0.0013  max mem: 2503
Test: [Task 5]  [290/625]  eta: 0:01:12  Loss: 0.3046 (0.4297)  Acc@1: 93.7500 (89.0893)  Acc@5: 100.0000 (98.2603)  time: 0.2173  data: 0.0014  max mem: 2503
Test: [Task 5]  [300/625]  eta: 0:01:10  Loss: 0.4565 (0.4330)  Acc@1: 87.5000 (88.8912)  Acc@5: 100.0000 (98.2558)  time: 0.2161  data: 0.0005  max mem: 2503
Test: [Task 5]  [310/625]  eta: 0:01:08  Loss: 0.4749 (0.4328)  Acc@1: 87.5000 (88.8666)  Acc@5: 100.0000 (98.2114)  time: 0.2151  data: 0.0003  max mem: 2503
Test: [Task 5]  [320/625]  eta: 0:01:06  Loss: 0.4094 (0.4325)  Acc@1: 87.5000 (88.8824)  Acc@5: 100.0000 (98.2477)  time: 0.2148  data: 0.0003  max mem: 2503
Test: [Task 5]  [330/625]  eta: 0:01:03  Loss: 0.4190 (0.4327)  Acc@1: 87.5000 (88.8029)  Acc@5: 100.0000 (98.2440)  time: 0.2142  data: 0.0003  max mem: 2503
Test: [Task 5]  [340/625]  eta: 0:01:01  Loss: 0.3289 (0.4307)  Acc@1: 87.5000 (88.8746)  Acc@5: 100.0000 (98.2405)  time: 0.2134  data: 0.0003  max mem: 2503
Test: [Task 5]  [350/625]  eta: 0:00:59  Loss: 0.4541 (0.4362)  Acc@1: 87.5000 (88.7464)  Acc@5: 100.0000 (98.2016)  time: 0.2134  data: 0.0003  max mem: 2503
Test: [Task 5]  [360/625]  eta: 0:00:57  Loss: 0.4238 (0.4345)  Acc@1: 87.5000 (88.7812)  Acc@5: 100.0000 (98.2341)  time: 0.2137  data: 0.0003  max mem: 2503
Test: [Task 5]  [370/625]  eta: 0:00:55  Loss: 0.3075 (0.4314)  Acc@1: 93.7500 (88.8982)  Acc@5: 100.0000 (98.2648)  time: 0.2134  data: 0.0002  max mem: 2503
Test: [Task 5]  [380/625]  eta: 0:00:52  Loss: 0.4074 (0.4332)  Acc@1: 87.5000 (88.8944)  Acc@5: 100.0000 (98.2283)  time: 0.2138  data: 0.0003  max mem: 2503
Test: [Task 5]  [390/625]  eta: 0:00:50  Loss: 0.4417 (0.4333)  Acc@1: 87.5000 (88.8907)  Acc@5: 100.0000 (98.2577)  time: 0.2155  data: 0.0009  max mem: 2503
Test: [Task 5]  [400/625]  eta: 0:00:48  Loss: 0.3963 (0.4318)  Acc@1: 87.5000 (88.9027)  Acc@5: 100.0000 (98.2700)  time: 0.2163  data: 0.0011  max mem: 2503
Test: [Task 5]  [410/625]  eta: 0:00:46  Loss: 0.3875 (0.4318)  Acc@1: 87.5000 (88.8990)  Acc@5: 100.0000 (98.2360)  time: 0.2159  data: 0.0007  max mem: 2503
Test: [Task 5]  [420/625]  eta: 0:00:44  Loss: 0.4461 (0.4325)  Acc@1: 87.5000 (88.8361)  Acc@5: 100.0000 (98.2482)  time: 0.2167  data: 0.0015  max mem: 2503
Test: [Task 5]  [430/625]  eta: 0:00:42  Loss: 0.4197 (0.4311)  Acc@1: 87.5000 (88.8921)  Acc@5: 100.0000 (98.2744)  time: 0.2169  data: 0.0016  max mem: 2503
Test: [Task 5]  [440/625]  eta: 0:00:40  Loss: 0.3372 (0.4304)  Acc@1: 87.5000 (88.8322)  Acc@5: 100.0000 (98.2993)  time: 0.2162  data: 0.0009  max mem: 2503
Test: [Task 5]  [450/625]  eta: 0:00:37  Loss: 0.3629 (0.4297)  Acc@1: 87.5000 (88.7611)  Acc@5: 100.0000 (98.2955)  time: 0.2158  data: 0.0010  max mem: 2503
Test: [Task 5]  [460/625]  eta: 0:00:35  Loss: 0.3534 (0.4285)  Acc@1: 87.5000 (88.8286)  Acc@5: 100.0000 (98.3053)  time: 0.2156  data: 0.0006  max mem: 2503
Test: [Task 5]  [470/625]  eta: 0:00:33  Loss: 0.2960 (0.4247)  Acc@1: 93.7500 (88.9597)  Acc@5: 100.0000 (98.3413)  time: 0.2160  data: 0.0007  max mem: 2503
Test: [Task 5]  [480/625]  eta: 0:00:31  Loss: 0.2942 (0.4245)  Acc@1: 93.7500 (88.9293)  Acc@5: 100.0000 (98.3628)  time: 0.2163  data: 0.0007  max mem: 2503
Test: [Task 5]  [490/625]  eta: 0:00:29  Loss: 0.3775 (0.4239)  Acc@1: 93.7500 (88.9638)  Acc@5: 100.0000 (98.3452)  time: 0.2157  data: 0.0006  max mem: 2503
Test: [Task 5]  [500/625]  eta: 0:00:27  Loss: 0.3638 (0.4246)  Acc@1: 87.5000 (88.9721)  Acc@5: 100.0000 (98.3283)  time: 0.2147  data: 0.0006  max mem: 2503
Test: [Task 5]  [510/625]  eta: 0:00:24  Loss: 0.4377 (0.4251)  Acc@1: 87.5000 (88.9677)  Acc@5: 100.0000 (98.3244)  time: 0.2147  data: 0.0005  max mem: 2503
Test: [Task 5]  [520/625]  eta: 0:00:22  Loss: 0.4192 (0.4238)  Acc@1: 87.5000 (88.9995)  Acc@5: 100.0000 (98.3325)  time: 0.2155  data: 0.0009  max mem: 2503
Test: [Task 5]  [530/625]  eta: 0:00:20  Loss: 0.3817 (0.4220)  Acc@1: 87.5000 (89.0654)  Acc@5: 100.0000 (98.3522)  time: 0.2154  data: 0.0007  max mem: 2503
Test: [Task 5]  [540/625]  eta: 0:00:18  Loss: 0.3452 (0.4209)  Acc@1: 93.7500 (89.0943)  Acc@5: 100.0000 (98.3595)  time: 0.2155  data: 0.0004  max mem: 2503
Test: [Task 5]  [550/625]  eta: 0:00:16  Loss: 0.3454 (0.4219)  Acc@1: 87.5000 (89.0426)  Acc@5: 100.0000 (98.3666)  time: 0.2166  data: 0.0013  max mem: 2503
Test: [Task 5]  [560/625]  eta: 0:00:14  Loss: 0.3454 (0.4223)  Acc@1: 87.5000 (89.0374)  Acc@5: 100.0000 (98.3734)  time: 0.2172  data: 0.0020  max mem: 2503
Test: [Task 5]  [570/625]  eta: 0:00:11  Loss: 0.3348 (0.4217)  Acc@1: 87.5000 (89.0543)  Acc@5: 100.0000 (98.3800)  time: 0.2158  data: 0.0010  max mem: 2503
Test: [Task 5]  [580/625]  eta: 0:00:09  Loss: 0.3971 (0.4231)  Acc@1: 87.5000 (89.0491)  Acc@5: 100.0000 (98.3541)  time: 0.2145  data: 0.0003  max mem: 2503
Test: [Task 5]  [590/625]  eta: 0:00:07  Loss: 0.4606 (0.4226)  Acc@1: 87.5000 (89.0757)  Acc@5: 100.0000 (98.3503)  time: 0.2146  data: 0.0003  max mem: 2503
Test: [Task 5]  [600/625]  eta: 0:00:05  Loss: 0.3920 (0.4217)  Acc@1: 93.7500 (89.1119)  Acc@5: 100.0000 (98.3673)  time: 0.2142  data: 0.0002  max mem: 2503
Test: [Task 5]  [610/625]  eta: 0:00:03  Loss: 0.3201 (0.4206)  Acc@1: 93.7500 (89.1162)  Acc@5: 100.0000 (98.3633)  time: 0.2136  data: 0.0002  max mem: 2503
Test: [Task 5]  [620/625]  eta: 0:00:01  Loss: 0.2844 (0.4188)  Acc@1: 93.7500 (89.2110)  Acc@5: 100.0000 (98.3696)  time: 0.2135  data: 0.0002  max mem: 2503
Test: [Task 5]  [624/625]  eta: 0:00:00  Loss: 0.3043 (0.4191)  Acc@1: 93.7500 (89.2000)  Acc@5: 100.0000 (98.3700)  time: 0.2132  data: 0.0002  max mem: 2503
Test: [Task 5] Total time: 0:02:15 (0.2162 s / it)
* Acc@1 89.200 Acc@5 98.370 loss 0.419
{0: {0: 26032, 1: 26032, 2: 26032, 3: 26032, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0, 10: 0, 11: 0, 12: 0, 13: 0, 14: 0, 15: 0, 16: 0, 17: 0, 18: 0, 19: 0}, 1: {0: 0, 1: 0, 2: 0, 3: 0, 4: 10000, 5: 10000, 6: 10000, 7: 10000, 8: 0, 9: 0, 10: 0, 11: 0, 12: 0, 13: 0, 14: 0, 15: 0, 16: 0, 17: 0, 18: 0, 19: 0}, 2: {0: 16, 1: 16, 2: 16, 3: 16, 4: 0, 5: 0, 6: 0, 7: 0, 8: 9984, 9: 9984, 10: 9984, 11: 9984, 12: 0, 13: 0, 14: 0, 15: 0, 16: 0, 17: 0, 18: 0, 19: 0}, 3: {0: 0, 1: 0, 2: 0, 3: 0, 4: 176, 5: 176, 6: 176, 7: 176, 8: 0, 9: 0, 10: 0, 11: 0, 12: 283, 13: 283, 14: 283, 15: 283, 16: 0, 17: 0, 18: 0, 19: 0}, 4: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0, 10: 0, 11: 0, 12: 0, 13: 0, 14: 0, 15: 0, 16: 10000, 17: 10000, 18: 10000, 19: 10000}}
[Average accuracy till task5]	Acc@1: 79.4326	Acc@5: 94.7914	Loss: 0.7878	Forgetting: 6.8669	Backward: -6.8669
Total training time: 8:48:12
