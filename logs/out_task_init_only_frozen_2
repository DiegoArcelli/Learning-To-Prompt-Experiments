/storagenfs/d.arcelli/Prompting-Based-CL-Methods-Experiments/.env/lib/python3.9/site-packages/torchvision/transforms/transforms.py:329: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.
  warnings.warn(
/storagenfs/d.arcelli/l2p-pytorch/continual_datasets/dataset_utils.py:335: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:199.)
  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)
Namespace(subparser_name='five_datasets_l2p', batch_size=16, epochs=5, model='vit_base_patch16_224', input_size=224, pretrained=True, drop=0.0, drop_path=0.0, opt='adam', opt_eps=1e-08, opt_betas=(0.9, 0.999), clip_grad=1.0, momentum=0.9, weight_decay=0.0, reinit_optimizer=True, sched='constant', lr=0.03, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, unscale_lr=True, color_jitter=None, aa=None, smoothing=0.1, train_interpolation='bicubic', reprob=0.0, remode='pixel', recount=1, data_path='./local_datasets/', dataset='5-datasets', shuffle=False, output_dir='./output_task_init_only_frozen', device='cuda', seed=42, eval=False, num_workers=4, pin_mem=True, world_size=1, dist_url='env://', num_tasks=5, train_mask=True, task_inc=False, prompt_pool=True, size=20, length=10, top_k=4, initializer='uniform', prompt_key=True, prompt_key_init='uniform', use_prompt_mask=False, shared_prompt_pool=False, shared_prompt_key=False, batchwise_prompt=True, embedding_key='cls', predefined_key='', pull_constraint='False', pull_constraint_coeff=0.5, global_pool='token', head_type='prompt', freeze=['blocks', 'patch_embed', 'cls_token', 'norm', 'pos_embed'], print_freq=10, freeze_head=False, train_type='l2p', eval_task_id=False, frequency_penalization=False, class_incremental=False, init_class_prompts=False, task_incremental=True, init_tasks_prompts=True, prompts_per_task=4, prompts_per_class=1)
Not using distributed mode
['SVHN', 'MNIST', 'CIFAR10', 'NotMNIST', 'FashionMNIST']
Using downloaded and verified file: ./local_datasets/train_32x32.mat
Using downloaded and verified file: ./local_datasets/train_32x32.mat
Using downloaded and verified file: ./local_datasets/test_32x32.mat
Using downloaded and verified file: ./local_datasets/test_32x32.mat
[1 9 2 3 2 5 9 3 3 1]
tensor([5, 0, 4, 1, 9, 2, 1, 3, 1, 4])
Files already downloaded and verified
Files already downloaded and verified
[6, 9, 9, 4, 1, 1, 2, 7, 8, 3]
File F/Q3Jvc3NvdmVyIEJvbGRPYmxpcXVlLnR0Zg==.png is broken
File A/RGVtb2NyYXRpY2FCb2xkT2xkc3R5bGUgQm9sZC50dGY=.png is broken
File B/SE1hbi50dGY=.png is broken
[5, 5, 5, 5, 5, 5, 5, 5, 5, 5]
tensor([9, 0, 0, 3, 0, 2, 7, 2, 5, 5])
Creating original model: vit_base_patch16_224
Creating model: vit_base_patch16_224
number of params: 207410
Start training for 5 epochs
Train: Epoch[1/5]  [   0/4579]  eta: 3:03:39  Lr: 0.001875  Loss: 0.9925  Acc@1: 12.5000 (12.5000)  Acc@5: 68.7500 (68.7500)  time: 2.4065  data: 0.4875  max mem: 2497
Train: Epoch[1/5]  [  10/4579]  eta: 0:40:35  Lr: 0.001875  Loss: 1.0578  Acc@1: 18.7500 (15.9091)  Acc@5: 50.0000 (57.9545)  time: 0.5330  data: 0.0447  max mem: 2500
Train: Epoch[1/5]  [  20/4579]  eta: 0:33:41  Lr: 0.001875  Loss: 1.4609  Acc@1: 12.5000 (15.4762)  Acc@5: 56.2500 (60.7143)  time: 0.3452  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [  30/4579]  eta: 0:31:14  Lr: 0.001875  Loss: 0.7329  Acc@1: 18.7500 (18.3468)  Acc@5: 62.5000 (60.8871)  time: 0.3454  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [  40/4579]  eta: 0:30:00  Lr: 0.001875  Loss: 0.8184  Acc@1: 25.0000 (19.5122)  Acc@5: 68.7500 (63.2622)  time: 0.3478  data: 0.0018  max mem: 2500
Train: Epoch[1/5]  [  50/4579]  eta: 0:29:12  Lr: 0.001875  Loss: 0.8901  Acc@1: 25.0000 (20.5882)  Acc@5: 68.7500 (63.2353)  time: 0.3479  data: 0.0025  max mem: 2500
Train: Epoch[1/5]  [  60/4579]  eta: 0:28:38  Lr: 0.001875  Loss: 1.2177  Acc@1: 25.0000 (22.1311)  Acc@5: 68.7500 (64.6516)  time: 0.3463  data: 0.0017  max mem: 2500
Train: Epoch[1/5]  [  70/4579]  eta: 0:28:12  Lr: 0.001875  Loss: 1.0840  Acc@1: 25.0000 (22.6232)  Acc@5: 68.7500 (65.7570)  time: 0.3457  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [  80/4579]  eta: 0:27:52  Lr: 0.001875  Loss: 0.8753  Acc@1: 31.2500 (24.1512)  Acc@5: 75.0000 (67.0525)  time: 0.3459  data: 0.0010  max mem: 2500
Train: Epoch[1/5]  [  90/4579]  eta: 0:27:35  Lr: 0.001875  Loss: 0.7762  Acc@1: 31.2500 (24.7253)  Acc@5: 75.0000 (67.9945)  time: 0.3462  data: 0.0010  max mem: 2500
Train: Epoch[1/5]  [ 100/4579]  eta: 0:27:22  Lr: 0.001875  Loss: 0.9081  Acc@1: 31.2500 (25.4950)  Acc@5: 75.0000 (68.3787)  time: 0.3459  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [ 110/4579]  eta: 0:27:08  Lr: 0.001875  Loss: 0.7867  Acc@1: 37.5000 (26.4077)  Acc@5: 75.0000 (69.2005)  time: 0.3439  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [ 120/4579]  eta: 0:26:57  Lr: 0.001875  Loss: 0.8680  Acc@1: 31.2500 (26.6529)  Acc@5: 75.0000 (69.5764)  time: 0.3434  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [ 130/4579]  eta: 0:26:48  Lr: 0.001875  Loss: 0.7134  Acc@1: 25.0000 (26.8607)  Acc@5: 75.0000 (70.0382)  time: 0.3460  data: 0.0015  max mem: 2500
Train: Epoch[1/5]  [ 140/4579]  eta: 0:26:39  Lr: 0.001875  Loss: 1.1176  Acc@1: 25.0000 (27.1277)  Acc@5: 75.0000 (70.4787)  time: 0.3455  data: 0.0016  max mem: 2500
Train: Epoch[1/5]  [ 150/4579]  eta: 0:26:31  Lr: 0.001875  Loss: 0.3467  Acc@1: 31.2500 (27.4421)  Acc@5: 75.0000 (71.2334)  time: 0.3453  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [ 160/4579]  eta: 0:26:24  Lr: 0.001875  Loss: 0.8298  Acc@1: 37.5000 (27.8727)  Acc@5: 81.2500 (71.7003)  time: 0.3454  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [ 170/4579]  eta: 0:26:16  Lr: 0.001875  Loss: 1.0451  Acc@1: 31.2500 (28.1433)  Acc@5: 81.2500 (72.1857)  time: 0.3444  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [ 180/4579]  eta: 0:26:10  Lr: 0.001875  Loss: 0.8065  Acc@1: 31.2500 (28.6257)  Acc@5: 81.2500 (72.6519)  time: 0.3454  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [ 190/4579]  eta: 0:26:05  Lr: 0.001875  Loss: 0.7254  Acc@1: 37.5000 (29.1558)  Acc@5: 81.2500 (73.3312)  time: 0.3474  data: 0.0013  max mem: 2500
Train: Epoch[1/5]  [ 200/4579]  eta: 0:25:59  Lr: 0.001875  Loss: 0.8709  Acc@1: 43.7500 (29.5709)  Acc@5: 81.2500 (73.4142)  time: 0.3484  data: 0.0021  max mem: 2500
Train: Epoch[1/5]  [ 210/4579]  eta: 0:25:53  Lr: 0.001875  Loss: 0.8848  Acc@1: 37.5000 (29.7097)  Acc@5: 75.0000 (73.5190)  time: 0.3460  data: 0.0012  max mem: 2500
Train: Epoch[1/5]  [ 220/4579]  eta: 0:25:48  Lr: 0.001875  Loss: 0.6870  Acc@1: 37.5000 (29.9491)  Acc@5: 81.2500 (73.8971)  time: 0.3458  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [ 230/4579]  eta: 0:25:44  Lr: 0.001875  Loss: 0.7493  Acc@1: 31.2500 (30.0595)  Acc@5: 81.2500 (74.2695)  time: 0.3495  data: 0.0015  max mem: 2500
Train: Epoch[1/5]  [ 240/4579]  eta: 0:25:39  Lr: 0.001875  Loss: 1.2619  Acc@1: 31.2500 (30.1349)  Acc@5: 75.0000 (74.1961)  time: 0.3492  data: 0.0015  max mem: 2500
Train: Epoch[1/5]  [ 250/4579]  eta: 0:25:33  Lr: 0.001875  Loss: 0.8950  Acc@1: 31.2500 (30.2789)  Acc@5: 75.0000 (74.4273)  time: 0.3458  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [ 260/4579]  eta: 0:25:29  Lr: 0.001875  Loss: 1.0127  Acc@1: 31.2500 (30.4358)  Acc@5: 81.2500 (74.8324)  time: 0.3470  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [ 270/4579]  eta: 0:25:24  Lr: 0.001875  Loss: 0.5557  Acc@1: 31.2500 (30.5812)  Acc@5: 81.2500 (74.8616)  time: 0.3467  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [ 280/4579]  eta: 0:25:20  Lr: 0.001875  Loss: 0.5641  Acc@1: 37.5000 (30.8496)  Acc@5: 75.0000 (74.9333)  time: 0.3467  data: 0.0009  max mem: 2500
Train: Epoch[1/5]  [ 290/4579]  eta: 0:25:15  Lr: 0.001875  Loss: 0.8423  Acc@1: 43.7500 (31.1211)  Acc@5: 81.2500 (75.2148)  time: 0.3475  data: 0.0009  max mem: 2500
Train: Epoch[1/5]  [ 300/4579]  eta: 0:25:11  Lr: 0.001875  Loss: 0.7962  Acc@1: 31.2500 (31.2708)  Acc@5: 87.5000 (75.5399)  time: 0.3464  data: 0.0013  max mem: 2500
Train: Epoch[1/5]  [ 310/4579]  eta: 0:25:06  Lr: 0.001875  Loss: 0.7381  Acc@1: 43.7500 (31.6117)  Acc@5: 87.5000 (75.8240)  time: 0.3476  data: 0.0017  max mem: 2500
Train: Epoch[1/5]  [ 320/4579]  eta: 0:25:02  Lr: 0.001875  Loss: 0.5042  Acc@1: 43.7500 (31.7952)  Acc@5: 87.5000 (76.1682)  time: 0.3464  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [ 330/4579]  eta: 0:24:57  Lr: 0.001875  Loss: 0.2041  Acc@1: 37.5000 (32.0431)  Acc@5: 81.2500 (76.3218)  time: 0.3458  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [ 340/4579]  eta: 0:24:53  Lr: 0.001875  Loss: 0.7256  Acc@1: 37.5000 (32.2214)  Acc@5: 87.5000 (76.6496)  time: 0.3475  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [ 350/4579]  eta: 0:24:49  Lr: 0.001875  Loss: 0.0420  Acc@1: 37.5000 (32.3006)  Acc@5: 87.5000 (76.7984)  time: 0.3483  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 360/4579]  eta: 0:24:45  Lr: 0.001875  Loss: 0.9282  Acc@1: 37.5000 (32.4965)  Acc@5: 81.2500 (77.0429)  time: 0.3473  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [ 370/4579]  eta: 0:24:41  Lr: 0.001875  Loss: 0.7695  Acc@1: 37.5000 (32.7325)  Acc@5: 81.2500 (77.1732)  time: 0.3474  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [ 380/4579]  eta: 0:24:37  Lr: 0.001875  Loss: 0.9993  Acc@1: 37.5000 (32.8740)  Acc@5: 81.2500 (77.2638)  time: 0.3467  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [ 390/4579]  eta: 0:24:33  Lr: 0.001875  Loss: 0.1536  Acc@1: 37.5000 (33.1682)  Acc@5: 81.2500 (77.3977)  time: 0.3460  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [ 400/4579]  eta: 0:24:29  Lr: 0.001875  Loss: 0.2411  Acc@1: 43.7500 (33.4788)  Acc@5: 87.5000 (77.5405)  time: 0.3485  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [ 410/4579]  eta: 0:24:25  Lr: 0.001875  Loss: 0.4320  Acc@1: 43.7500 (33.7287)  Acc@5: 87.5000 (77.7828)  time: 0.3486  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [ 420/4579]  eta: 0:24:21  Lr: 0.001875  Loss: 0.7056  Acc@1: 43.7500 (33.9074)  Acc@5: 81.2500 (77.8504)  time: 0.3482  data: 0.0013  max mem: 2500
Train: Epoch[1/5]  [ 430/4579]  eta: 0:24:18  Lr: 0.001875  Loss: 0.6491  Acc@1: 43.7500 (34.2227)  Acc@5: 81.2500 (78.0452)  time: 0.3501  data: 0.0015  max mem: 2500
Train: Epoch[1/5]  [ 440/4579]  eta: 0:24:14  Lr: 0.001875  Loss: -0.1945  Acc@1: 43.7500 (34.5380)  Acc@5: 87.5000 (78.3022)  time: 0.3483  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [ 450/4579]  eta: 0:24:10  Lr: 0.001875  Loss: 0.1420  Acc@1: 43.7500 (34.7977)  Acc@5: 93.7500 (78.6170)  time: 0.3447  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [ 460/4579]  eta: 0:24:06  Lr: 0.001875  Loss: 0.4092  Acc@1: 50.0000 (35.0461)  Acc@5: 93.7500 (78.8368)  time: 0.3474  data: 0.0011  max mem: 2500
Train: Epoch[1/5]  [ 470/4579]  eta: 0:24:02  Lr: 0.001875  Loss: 0.6670  Acc@1: 43.7500 (35.2044)  Acc@5: 93.7500 (79.0340)  time: 0.3486  data: 0.0009  max mem: 2500
Train: Epoch[1/5]  [ 480/4579]  eta: 0:23:58  Lr: 0.001875  Loss: 0.6524  Acc@1: 43.7500 (35.3430)  Acc@5: 81.2500 (79.0930)  time: 0.3464  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [ 490/4579]  eta: 0:23:54  Lr: 0.001875  Loss: 0.6753  Acc@1: 43.7500 (35.5779)  Acc@5: 81.2500 (79.0606)  time: 0.3468  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [ 500/4579]  eta: 0:23:50  Lr: 0.001875  Loss: 0.7319  Acc@1: 43.7500 (35.7036)  Acc@5: 81.2500 (79.1292)  time: 0.3466  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 510/4579]  eta: 0:23:47  Lr: 0.001875  Loss: 0.5091  Acc@1: 50.0000 (36.0568)  Acc@5: 81.2500 (79.2808)  time: 0.3475  data: 0.0013  max mem: 2500
Train: Epoch[1/5]  [ 520/4579]  eta: 0:23:43  Lr: 0.001875  Loss: -0.0402  Acc@1: 50.0000 (36.3244)  Acc@5: 93.7500 (79.4506)  time: 0.3488  data: 0.0015  max mem: 2500
Train: Epoch[1/5]  [ 530/4579]  eta: 0:23:39  Lr: 0.001875  Loss: 0.4279  Acc@1: 43.7500 (36.3936)  Acc@5: 87.5000 (79.4845)  time: 0.3471  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [ 540/4579]  eta: 0:23:36  Lr: 0.001875  Loss: 0.4639  Acc@1: 43.7500 (36.5989)  Acc@5: 87.5000 (79.6095)  time: 0.3469  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [ 550/4579]  eta: 0:23:32  Lr: 0.001875  Loss: 0.7323  Acc@1: 43.7500 (36.7400)  Acc@5: 87.5000 (79.6847)  time: 0.3473  data: 0.0014  max mem: 2500
Train: Epoch[1/5]  [ 560/4579]  eta: 0:23:28  Lr: 0.001875  Loss: 0.7323  Acc@1: 43.7500 (36.8093)  Acc@5: 87.5000 (79.8351)  time: 0.3470  data: 0.0013  max mem: 2500
Train: Epoch[1/5]  [ 570/4579]  eta: 0:23:25  Lr: 0.001875  Loss: 0.5140  Acc@1: 43.7500 (37.0731)  Acc@5: 87.5000 (80.0022)  time: 0.3495  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [ 580/4579]  eta: 0:23:21  Lr: 0.001875  Loss: 0.4089  Acc@1: 50.0000 (37.1988)  Acc@5: 87.5000 (80.1635)  time: 0.3480  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [ 590/4579]  eta: 0:23:17  Lr: 0.001875  Loss: 0.6149  Acc@1: 43.7500 (37.3414)  Acc@5: 87.5000 (80.2771)  time: 0.3458  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [ 600/4579]  eta: 0:23:13  Lr: 0.001875  Loss: 0.2405  Acc@1: 43.7500 (37.5728)  Acc@5: 87.5000 (80.3869)  time: 0.3466  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [ 610/4579]  eta: 0:23:09  Lr: 0.001875  Loss: 0.1517  Acc@1: 50.0000 (37.6637)  Acc@5: 81.2500 (80.3908)  time: 0.3466  data: 0.0015  max mem: 2500
Train: Epoch[1/5]  [ 620/4579]  eta: 0:23:06  Lr: 0.001875  Loss: 0.7259  Acc@1: 43.7500 (37.8019)  Acc@5: 87.5000 (80.5153)  time: 0.3467  data: 0.0018  max mem: 2500
Train: Epoch[1/5]  [ 630/4579]  eta: 0:23:02  Lr: 0.001875  Loss: 0.6821  Acc@1: 43.7500 (37.8665)  Acc@5: 87.5000 (80.5567)  time: 0.3464  data: 0.0009  max mem: 2500
Train: Epoch[1/5]  [ 640/4579]  eta: 0:22:58  Lr: 0.001875  Loss: -0.1501  Acc@1: 43.7500 (37.9973)  Acc@5: 87.5000 (80.6942)  time: 0.3468  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [ 650/4579]  eta: 0:22:55  Lr: 0.001875  Loss: 0.5311  Acc@1: 50.0000 (38.1336)  Acc@5: 87.5000 (80.7412)  time: 0.3465  data: 0.0009  max mem: 2500
Train: Epoch[1/5]  [ 660/4579]  eta: 0:22:51  Lr: 0.001875  Loss: 0.8928  Acc@1: 50.0000 (38.1902)  Acc@5: 87.5000 (80.7772)  time: 0.3450  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [ 670/4579]  eta: 0:22:47  Lr: 0.001875  Loss: 0.7283  Acc@1: 43.7500 (38.2358)  Acc@5: 87.5000 (80.8681)  time: 0.3448  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [ 680/4579]  eta: 0:22:43  Lr: 0.001875  Loss: 0.7030  Acc@1: 50.0000 (38.3811)  Acc@5: 87.5000 (80.9930)  time: 0.3466  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [ 690/4579]  eta: 0:22:40  Lr: 0.001875  Loss: 0.3842  Acc@1: 50.0000 (38.4859)  Acc@5: 87.5000 (81.1143)  time: 0.3472  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [ 700/4579]  eta: 0:22:36  Lr: 0.001875  Loss: 0.6112  Acc@1: 43.7500 (38.5699)  Acc@5: 87.5000 (81.2143)  time: 0.3473  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [ 710/4579]  eta: 0:22:32  Lr: 0.001875  Loss: 0.3236  Acc@1: 43.7500 (38.5900)  Acc@5: 87.5000 (81.2412)  time: 0.3483  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [ 720/4579]  eta: 0:22:29  Lr: 0.001875  Loss: 0.5118  Acc@1: 43.7500 (38.7223)  Acc@5: 81.2500 (81.2673)  time: 0.3482  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [ 730/4579]  eta: 0:22:25  Lr: 0.001875  Loss: 0.3343  Acc@1: 43.7500 (38.7739)  Acc@5: 81.2500 (81.3184)  time: 0.3466  data: 0.0012  max mem: 2500
Train: Epoch[1/5]  [ 740/4579]  eta: 0:22:22  Lr: 0.001875  Loss: 0.5172  Acc@1: 43.7500 (38.9507)  Acc@5: 81.2500 (81.3681)  time: 0.3465  data: 0.0012  max mem: 2500
Train: Epoch[1/5]  [ 750/4579]  eta: 0:22:18  Lr: 0.001875  Loss: 0.6683  Acc@1: 43.7500 (39.0563)  Acc@5: 87.5000 (81.4497)  time: 0.3464  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [ 760/4579]  eta: 0:22:14  Lr: 0.001875  Loss: 0.2702  Acc@1: 50.0000 (39.2247)  Acc@5: 87.5000 (81.5539)  time: 0.3478  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [ 770/4579]  eta: 0:22:11  Lr: 0.001875  Loss: 0.5030  Acc@1: 43.7500 (39.2996)  Acc@5: 87.5000 (81.6310)  time: 0.3477  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [ 780/4579]  eta: 0:22:07  Lr: 0.001875  Loss: 0.9529  Acc@1: 43.7500 (39.4446)  Acc@5: 87.5000 (81.6661)  time: 0.3457  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [ 790/4579]  eta: 0:22:04  Lr: 0.001875  Loss: 0.2474  Acc@1: 50.0000 (39.5386)  Acc@5: 87.5000 (81.7399)  time: 0.3482  data: 0.0013  max mem: 2500
Train: Epoch[1/5]  [ 800/4579]  eta: 0:22:00  Lr: 0.001875  Loss: 0.7293  Acc@1: 50.0000 (39.6458)  Acc@5: 87.5000 (81.8430)  time: 0.3512  data: 0.0014  max mem: 2500
Train: Epoch[1/5]  [ 810/4579]  eta: 0:21:57  Lr: 0.001875  Loss: 0.3039  Acc@1: 50.0000 (39.7503)  Acc@5: 87.5000 (81.9436)  time: 0.3488  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [ 820/4579]  eta: 0:21:53  Lr: 0.001875  Loss: -0.0125  Acc@1: 50.0000 (39.9361)  Acc@5: 87.5000 (82.0493)  time: 0.3513  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [ 830/4579]  eta: 0:21:50  Lr: 0.001875  Loss: -0.1587  Acc@1: 50.0000 (40.0045)  Acc@5: 93.7500 (82.1375)  time: 0.3520  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [ 840/4579]  eta: 0:21:46  Lr: 0.001875  Loss: 0.8855  Acc@1: 50.0000 (40.0788)  Acc@5: 87.5000 (82.2012)  time: 0.3467  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [ 850/4579]  eta: 0:21:43  Lr: 0.001875  Loss: 0.5708  Acc@1: 50.0000 (40.1513)  Acc@5: 87.5000 (82.2194)  time: 0.3485  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 860/4579]  eta: 0:21:39  Lr: 0.001875  Loss: 0.4050  Acc@1: 50.0000 (40.2512)  Acc@5: 81.2500 (82.2590)  time: 0.3491  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [ 870/4579]  eta: 0:21:35  Lr: 0.001875  Loss: 0.0827  Acc@1: 50.0000 (40.3200)  Acc@5: 87.5000 (82.3551)  time: 0.3466  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [ 880/4579]  eta: 0:21:32  Lr: 0.001875  Loss: 0.8222  Acc@1: 43.7500 (40.4228)  Acc@5: 87.5000 (82.4135)  time: 0.3466  data: 0.0012  max mem: 2500
Train: Epoch[1/5]  [ 890/4579]  eta: 0:21:28  Lr: 0.001875  Loss: 0.5930  Acc@1: 43.7500 (40.4812)  Acc@5: 87.5000 (82.4916)  time: 0.3484  data: 0.0026  max mem: 2500
Train: Epoch[1/5]  [ 900/4579]  eta: 0:21:25  Lr: 0.001875  Loss: 0.4961  Acc@1: 50.0000 (40.6077)  Acc@5: 87.5000 (82.5194)  time: 0.3491  data: 0.0025  max mem: 2500
Train: Epoch[1/5]  [ 910/4579]  eta: 0:21:21  Lr: 0.001875  Loss: 0.3717  Acc@1: 50.0000 (40.6833)  Acc@5: 87.5000 (82.6015)  time: 0.3483  data: 0.0011  max mem: 2500
Train: Epoch[1/5]  [ 920/4579]  eta: 0:21:18  Lr: 0.001875  Loss: 0.6438  Acc@1: 37.5000 (40.6691)  Acc@5: 87.5000 (82.6140)  time: 0.3463  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [ 930/4579]  eta: 0:21:14  Lr: 0.001875  Loss: 0.7616  Acc@1: 37.5000 (40.6552)  Acc@5: 87.5000 (82.6799)  time: 0.3460  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [ 940/4579]  eta: 0:21:11  Lr: 0.001875  Loss: -0.0372  Acc@1: 43.7500 (40.7412)  Acc@5: 87.5000 (82.7378)  time: 0.3489  data: 0.0013  max mem: 2500
Train: Epoch[1/5]  [ 950/4579]  eta: 0:21:07  Lr: 0.001875  Loss: 0.1583  Acc@1: 43.7500 (40.7203)  Acc@5: 87.5000 (82.7550)  time: 0.3483  data: 0.0014  max mem: 2500
Train: Epoch[1/5]  [ 960/4579]  eta: 0:21:03  Lr: 0.001875  Loss: 0.2307  Acc@1: 43.7500 (40.7843)  Acc@5: 87.5000 (82.8174)  time: 0.3474  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [ 970/4579]  eta: 0:21:00  Lr: 0.001875  Loss: 0.2430  Acc@1: 43.7500 (40.8792)  Acc@5: 87.5000 (82.8527)  time: 0.3476  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [ 980/4579]  eta: 0:20:56  Lr: 0.001875  Loss: 0.3243  Acc@1: 50.0000 (40.9850)  Acc@5: 87.5000 (82.8937)  time: 0.3462  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [ 990/4579]  eta: 0:20:53  Lr: 0.001875  Loss: 0.9081  Acc@1: 50.0000 (41.0885)  Acc@5: 87.5000 (82.9402)  time: 0.3464  data: 0.0009  max mem: 2500
Train: Epoch[1/5]  [1000/4579]  eta: 0:20:49  Lr: 0.001875  Loss: 0.1982  Acc@1: 50.0000 (41.2150)  Acc@5: 87.5000 (82.9858)  time: 0.3479  data: 0.0009  max mem: 2500
Train: Epoch[1/5]  [1010/4579]  eta: 0:20:46  Lr: 0.001875  Loss: 0.1436  Acc@1: 50.0000 (41.3019)  Acc@5: 87.5000 (83.0366)  time: 0.3477  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [1020/4579]  eta: 0:20:42  Lr: 0.001875  Loss: 0.5270  Acc@1: 50.0000 (41.4483)  Acc@5: 87.5000 (83.0742)  time: 0.3474  data: 0.0009  max mem: 2500
Train: Epoch[1/5]  [1030/4579]  eta: 0:20:39  Lr: 0.001875  Loss: 0.9969  Acc@1: 50.0000 (41.5252)  Acc@5: 87.5000 (83.0989)  time: 0.3488  data: 0.0019  max mem: 2500
Train: Epoch[1/5]  [1040/4579]  eta: 0:20:35  Lr: 0.001875  Loss: 0.9696  Acc@1: 50.0000 (41.6667)  Acc@5: 87.5000 (83.1652)  time: 0.3477  data: 0.0014  max mem: 2500
Train: Epoch[1/5]  [1050/4579]  eta: 0:20:32  Lr: 0.001875  Loss: 0.2406  Acc@1: 50.0000 (41.7043)  Acc@5: 87.5000 (83.2184)  time: 0.3473  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1060/4579]  eta: 0:20:28  Lr: 0.001875  Loss: 0.0493  Acc@1: 50.0000 (41.7943)  Acc@5: 87.5000 (83.2705)  time: 0.3472  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1070/4579]  eta: 0:20:24  Lr: 0.001875  Loss: 0.0361  Acc@1: 50.0000 (41.8592)  Acc@5: 87.5000 (83.3100)  time: 0.3472  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1080/4579]  eta: 0:20:21  Lr: 0.001875  Loss: 0.3347  Acc@1: 50.0000 (41.9808)  Acc@5: 87.5000 (83.3661)  time: 0.3470  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [1090/4579]  eta: 0:20:17  Lr: 0.001875  Loss: 0.4413  Acc@1: 56.2500 (42.0887)  Acc@5: 87.5000 (83.3925)  time: 0.3458  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [1100/4579]  eta: 0:20:14  Lr: 0.001875  Loss: 0.6254  Acc@1: 50.0000 (42.1605)  Acc@5: 87.5000 (83.4185)  time: 0.3464  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [1110/4579]  eta: 0:20:10  Lr: 0.001875  Loss: -0.0021  Acc@1: 50.0000 (42.2480)  Acc@5: 87.5000 (83.4440)  time: 0.3459  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1120/4579]  eta: 0:20:07  Lr: 0.001875  Loss: 0.2090  Acc@1: 56.2500 (42.3450)  Acc@5: 87.5000 (83.4969)  time: 0.3468  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1130/4579]  eta: 0:20:03  Lr: 0.001875  Loss: 0.0219  Acc@1: 50.0000 (42.3630)  Acc@5: 87.5000 (83.5489)  time: 0.3462  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1140/4579]  eta: 0:19:59  Lr: 0.001875  Loss: 0.0307  Acc@1: 43.7500 (42.4080)  Acc@5: 87.5000 (83.5780)  time: 0.3453  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1150/4579]  eta: 0:19:56  Lr: 0.001875  Loss: 0.2950  Acc@1: 50.0000 (42.4576)  Acc@5: 81.2500 (83.5686)  time: 0.3465  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [1160/4579]  eta: 0:19:52  Lr: 0.001875  Loss: -0.4998  Acc@1: 50.0000 (42.5926)  Acc@5: 87.5000 (83.6240)  time: 0.3477  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1170/4579]  eta: 0:19:49  Lr: 0.001875  Loss: 0.1928  Acc@1: 56.2500 (42.6398)  Acc@5: 87.5000 (83.6358)  time: 0.3473  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1180/4579]  eta: 0:19:45  Lr: 0.001875  Loss: 0.8227  Acc@1: 50.0000 (42.7180)  Acc@5: 87.5000 (83.6791)  time: 0.3481  data: 0.0020  max mem: 2500
Train: Epoch[1/5]  [1190/4579]  eta: 0:19:42  Lr: 0.001875  Loss: 0.0910  Acc@1: 50.0000 (42.7477)  Acc@5: 87.5000 (83.7007)  time: 0.3480  data: 0.0026  max mem: 2500
Train: Epoch[1/5]  [1200/4579]  eta: 0:19:38  Lr: 0.001875  Loss: 0.9876  Acc@1: 50.0000 (42.8445)  Acc@5: 87.5000 (83.7219)  time: 0.3464  data: 0.0010  max mem: 2500
Train: Epoch[1/5]  [1210/4579]  eta: 0:19:35  Lr: 0.001875  Loss: 0.2490  Acc@1: 56.2500 (42.9500)  Acc@5: 87.5000 (83.7892)  time: 0.3476  data: 0.0016  max mem: 2500
Train: Epoch[1/5]  [1220/4579]  eta: 0:19:31  Lr: 0.001875  Loss: 0.4383  Acc@1: 56.2500 (43.0692)  Acc@5: 87.5000 (83.8350)  time: 0.3469  data: 0.0017  max mem: 2500
Train: Epoch[1/5]  [1230/4579]  eta: 0:19:27  Lr: 0.001875  Loss: 0.0356  Acc@1: 56.2500 (43.1458)  Acc@5: 93.7500 (83.9003)  time: 0.3457  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1240/4579]  eta: 0:19:24  Lr: 0.001875  Loss: 0.4409  Acc@1: 56.2500 (43.2464)  Acc@5: 93.7500 (83.9293)  time: 0.3461  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [1250/4579]  eta: 0:19:20  Lr: 0.001875  Loss: 0.5289  Acc@1: 50.0000 (43.2954)  Acc@5: 87.5000 (83.9528)  time: 0.3465  data: 0.0009  max mem: 2500
Train: Epoch[1/5]  [1260/4579]  eta: 0:19:17  Lr: 0.001875  Loss: 0.3233  Acc@1: 43.7500 (43.2940)  Acc@5: 87.5000 (83.9661)  time: 0.3470  data: 0.0009  max mem: 2500
Train: Epoch[1/5]  [1270/4579]  eta: 0:19:13  Lr: 0.001875  Loss: 0.5930  Acc@1: 50.0000 (43.3812)  Acc@5: 87.5000 (84.0087)  time: 0.3479  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1280/4579]  eta: 0:19:10  Lr: 0.001875  Loss: 0.3513  Acc@1: 56.2500 (43.4670)  Acc@5: 87.5000 (84.0457)  time: 0.3491  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [1290/4579]  eta: 0:19:06  Lr: 0.001875  Loss: 0.1832  Acc@1: 56.2500 (43.5515)  Acc@5: 87.5000 (84.0627)  time: 0.3488  data: 0.0013  max mem: 2500
Train: Epoch[1/5]  [1300/4579]  eta: 0:19:03  Lr: 0.001875  Loss: -0.1576  Acc@1: 50.0000 (43.5915)  Acc@5: 87.5000 (84.1084)  time: 0.3471  data: 0.0013  max mem: 2500
Train: Epoch[1/5]  [1310/4579]  eta: 0:18:59  Lr: 0.001875  Loss: 0.0883  Acc@1: 50.0000 (43.7119)  Acc@5: 87.5000 (84.1295)  time: 0.3481  data: 0.0013  max mem: 2500
Train: Epoch[1/5]  [1320/4579]  eta: 0:18:56  Lr: 0.001875  Loss: -0.1385  Acc@1: 56.2500 (43.7831)  Acc@5: 87.5000 (84.1597)  time: 0.3483  data: 0.0021  max mem: 2500
Train: Epoch[1/5]  [1330/4579]  eta: 0:18:52  Lr: 0.001875  Loss: -0.4918  Acc@1: 50.0000 (43.8815)  Acc@5: 93.7500 (84.2271)  time: 0.3489  data: 0.0014  max mem: 2500
Train: Epoch[1/5]  [1340/4579]  eta: 0:18:49  Lr: 0.001875  Loss: 0.4652  Acc@1: 50.0000 (43.9178)  Acc@5: 93.7500 (84.2934)  time: 0.3500  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [1350/4579]  eta: 0:18:45  Lr: 0.001875  Loss: 0.3518  Acc@1: 50.0000 (43.9397)  Acc@5: 93.7500 (84.3079)  time: 0.3489  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [1360/4579]  eta: 0:18:42  Lr: 0.001875  Loss: 0.5351  Acc@1: 50.0000 (44.0072)  Acc@5: 87.5000 (84.3452)  time: 0.3483  data: 0.0009  max mem: 2500
Train: Epoch[1/5]  [1370/4579]  eta: 0:18:38  Lr: 0.001875  Loss: 0.1007  Acc@1: 50.0000 (44.0600)  Acc@5: 87.5000 (84.3818)  time: 0.3484  data: 0.0015  max mem: 2500
Train: Epoch[1/5]  [1380/4579]  eta: 0:18:35  Lr: 0.001875  Loss: 0.0392  Acc@1: 50.0000 (44.1347)  Acc@5: 87.5000 (84.4180)  time: 0.3484  data: 0.0015  max mem: 2500
Train: Epoch[1/5]  [1390/4579]  eta: 0:18:31  Lr: 0.001875  Loss: 0.4271  Acc@1: 50.0000 (44.1634)  Acc@5: 93.7500 (84.4716)  time: 0.3468  data: 0.0011  max mem: 2500
Train: Epoch[1/5]  [1400/4579]  eta: 0:18:28  Lr: 0.001875  Loss: 0.3681  Acc@1: 50.0000 (44.2095)  Acc@5: 93.7500 (84.5111)  time: 0.3465  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [1410/4579]  eta: 0:18:24  Lr: 0.001875  Loss: 0.1490  Acc@1: 50.0000 (44.2372)  Acc@5: 87.5000 (84.5101)  time: 0.3480  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [1420/4579]  eta: 0:18:21  Lr: 0.001875  Loss: 0.4417  Acc@1: 50.0000 (44.3218)  Acc@5: 87.5000 (84.5487)  time: 0.3479  data: 0.0009  max mem: 2500
Train: Epoch[1/5]  [1430/4579]  eta: 0:18:17  Lr: 0.001875  Loss: 0.2655  Acc@1: 50.0000 (44.3571)  Acc@5: 87.5000 (84.5650)  time: 0.3473  data: 0.0014  max mem: 2500
Train: Epoch[1/5]  [1440/4579]  eta: 0:18:14  Lr: 0.001875  Loss: 0.0151  Acc@1: 50.0000 (44.4353)  Acc@5: 87.5000 (84.6027)  time: 0.3473  data: 0.0012  max mem: 2500
Train: Epoch[1/5]  [1450/4579]  eta: 0:18:10  Lr: 0.001875  Loss: 0.0616  Acc@1: 56.2500 (44.5426)  Acc@5: 87.5000 (84.6184)  time: 0.3464  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [1460/4579]  eta: 0:18:07  Lr: 0.001875  Loss: 0.2690  Acc@1: 50.0000 (44.5714)  Acc@5: 87.5000 (84.6295)  time: 0.3453  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1470/4579]  eta: 0:18:03  Lr: 0.001875  Loss: -0.0995  Acc@1: 50.0000 (44.6635)  Acc@5: 87.5000 (84.6575)  time: 0.3462  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1480/4579]  eta: 0:18:00  Lr: 0.001875  Loss: 0.2244  Acc@1: 56.2500 (44.7164)  Acc@5: 87.5000 (84.6641)  time: 0.3471  data: 0.0012  max mem: 2500
Train: Epoch[1/5]  [1490/4579]  eta: 0:17:56  Lr: 0.001875  Loss: -0.0326  Acc@1: 56.2500 (44.7602)  Acc@5: 87.5000 (84.6831)  time: 0.3472  data: 0.0013  max mem: 2500
Train: Epoch[1/5]  [1500/4579]  eta: 0:17:53  Lr: 0.001875  Loss: 0.3160  Acc@1: 56.2500 (44.8118)  Acc@5: 87.5000 (84.6852)  time: 0.3470  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [1510/4579]  eta: 0:17:49  Lr: 0.001875  Loss: -0.0790  Acc@1: 56.2500 (44.9082)  Acc@5: 87.5000 (84.7245)  time: 0.3474  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [1520/4579]  eta: 0:17:46  Lr: 0.001875  Loss: 0.3221  Acc@1: 56.2500 (44.9786)  Acc@5: 93.7500 (84.7592)  time: 0.3476  data: 0.0009  max mem: 2500
Train: Epoch[1/5]  [1530/4579]  eta: 0:17:42  Lr: 0.001875  Loss: 0.3837  Acc@1: 50.0000 (44.9951)  Acc@5: 87.5000 (84.7812)  time: 0.3483  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [1540/4579]  eta: 0:17:39  Lr: 0.001875  Loss: -0.1178  Acc@1: 43.7500 (44.9992)  Acc@5: 87.5000 (84.7988)  time: 0.3473  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1550/4579]  eta: 0:17:35  Lr: 0.001875  Loss: -0.0773  Acc@1: 50.0000 (45.0717)  Acc@5: 93.7500 (84.8364)  time: 0.3467  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1560/4579]  eta: 0:17:32  Lr: 0.001875  Loss: 0.1677  Acc@1: 56.2500 (45.1794)  Acc@5: 93.7500 (84.8775)  time: 0.3477  data: 0.0009  max mem: 2500
Train: Epoch[1/5]  [1570/4579]  eta: 0:17:28  Lr: 0.001875  Loss: 0.8277  Acc@1: 56.2500 (45.1743)  Acc@5: 87.5000 (84.9021)  time: 0.3469  data: 0.0009  max mem: 2500
Train: Epoch[1/5]  [1580/4579]  eta: 0:17:25  Lr: 0.001875  Loss: -0.3336  Acc@1: 50.0000 (45.2404)  Acc@5: 87.5000 (84.9265)  time: 0.3477  data: 0.0018  max mem: 2500
Train: Epoch[1/5]  [1590/4579]  eta: 0:17:21  Lr: 0.001875  Loss: 0.0348  Acc@1: 50.0000 (45.2663)  Acc@5: 87.5000 (84.9309)  time: 0.3486  data: 0.0018  max mem: 2500
Train: Epoch[1/5]  [1600/4579]  eta: 0:17:18  Lr: 0.001875  Loss: 0.2690  Acc@1: 50.0000 (45.3428)  Acc@5: 87.5000 (84.9508)  time: 0.3467  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1610/4579]  eta: 0:17:14  Lr: 0.001875  Loss: 0.7317  Acc@1: 56.2500 (45.4105)  Acc@5: 87.5000 (84.9628)  time: 0.3464  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1620/4579]  eta: 0:17:11  Lr: 0.001875  Loss: 0.5410  Acc@1: 56.2500 (45.4619)  Acc@5: 87.5000 (84.9668)  time: 0.3477  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1630/4579]  eta: 0:17:07  Lr: 0.001875  Loss: 0.2364  Acc@1: 50.0000 (45.5204)  Acc@5: 87.5000 (85.0015)  time: 0.3472  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1640/4579]  eta: 0:17:04  Lr: 0.001875  Loss: 0.3863  Acc@1: 56.2500 (45.5782)  Acc@5: 93.7500 (85.0434)  time: 0.3470  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1650/4579]  eta: 0:17:00  Lr: 0.001875  Loss: -0.1623  Acc@1: 56.2500 (45.6466)  Acc@5: 87.5000 (85.0507)  time: 0.3466  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1660/4579]  eta: 0:16:57  Lr: 0.001875  Loss: 0.3620  Acc@1: 50.0000 (45.6803)  Acc@5: 87.5000 (85.0843)  time: 0.3474  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1670/4579]  eta: 0:16:53  Lr: 0.001875  Loss: -0.2793  Acc@1: 50.0000 (45.7585)  Acc@5: 87.5000 (85.1100)  time: 0.3470  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [1680/4579]  eta: 0:16:50  Lr: 0.001875  Loss: 0.2508  Acc@1: 50.0000 (45.7652)  Acc@5: 87.5000 (85.0944)  time: 0.3479  data: 0.0009  max mem: 2500
Train: Epoch[1/5]  [1690/4579]  eta: 0:16:46  Lr: 0.001875  Loss: 0.0090  Acc@1: 50.0000 (45.8198)  Acc@5: 87.5000 (85.1087)  time: 0.3495  data: 0.0009  max mem: 2500
Train: Epoch[1/5]  [1700/4579]  eta: 0:16:43  Lr: 0.001875  Loss: 0.1763  Acc@1: 56.2500 (45.9068)  Acc@5: 87.5000 (85.1337)  time: 0.3497  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [1710/4579]  eta: 0:16:39  Lr: 0.001875  Loss: 1.0138  Acc@1: 50.0000 (45.9015)  Acc@5: 87.5000 (85.1403)  time: 0.3487  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [1720/4579]  eta: 0:16:36  Lr: 0.001875  Loss: -0.3326  Acc@1: 50.0000 (45.9725)  Acc@5: 87.5000 (85.1576)  time: 0.3474  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [1730/4579]  eta: 0:16:32  Lr: 0.001875  Loss: 0.1220  Acc@1: 56.2500 (46.0211)  Acc@5: 87.5000 (85.1820)  time: 0.3476  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1740/4579]  eta: 0:16:29  Lr: 0.001875  Loss: 0.2909  Acc@1: 56.2500 (46.0547)  Acc@5: 87.5000 (85.2168)  time: 0.3466  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1750/4579]  eta: 0:16:25  Lr: 0.001875  Loss: 0.9077  Acc@1: 56.2500 (46.1415)  Acc@5: 93.7500 (85.2477)  time: 0.3461  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1760/4579]  eta: 0:16:22  Lr: 0.001875  Loss: 0.3093  Acc@1: 56.2500 (46.2095)  Acc@5: 93.7500 (85.2676)  time: 0.3455  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1770/4579]  eta: 0:16:18  Lr: 0.001875  Loss: 0.0547  Acc@1: 56.2500 (46.2874)  Acc@5: 93.7500 (85.3049)  time: 0.3455  data: 0.0012  max mem: 2500
Train: Epoch[1/5]  [1780/4579]  eta: 0:16:15  Lr: 0.001875  Loss: 0.1155  Acc@1: 56.2500 (46.3433)  Acc@5: 93.7500 (85.3278)  time: 0.3466  data: 0.0013  max mem: 2500
Train: Epoch[1/5]  [1790/4579]  eta: 0:16:11  Lr: 0.001875  Loss: 0.4430  Acc@1: 56.2500 (46.3847)  Acc@5: 87.5000 (85.3155)  time: 0.3473  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1800/4579]  eta: 0:16:08  Lr: 0.001875  Loss: 0.2560  Acc@1: 56.2500 (46.4429)  Acc@5: 87.5000 (85.3449)  time: 0.3471  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1810/4579]  eta: 0:16:04  Lr: 0.001875  Loss: 0.4193  Acc@1: 56.2500 (46.4798)  Acc@5: 93.7500 (85.3672)  time: 0.3480  data: 0.0009  max mem: 2500
Train: Epoch[1/5]  [1820/4579]  eta: 0:16:01  Lr: 0.001875  Loss: 0.0340  Acc@1: 56.2500 (46.5129)  Acc@5: 93.7500 (85.3926)  time: 0.3490  data: 0.0011  max mem: 2500
Train: Epoch[1/5]  [1830/4579]  eta: 0:15:57  Lr: 0.001875  Loss: -0.0220  Acc@1: 56.2500 (46.5763)  Acc@5: 87.5000 (85.4076)  time: 0.3469  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [1840/4579]  eta: 0:15:54  Lr: 0.001875  Loss: 0.3049  Acc@1: 62.5000 (46.6492)  Acc@5: 87.5000 (85.4461)  time: 0.3469  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [1850/4579]  eta: 0:15:50  Lr: 0.001875  Loss: 0.2626  Acc@1: 56.2500 (46.7011)  Acc@5: 93.7500 (85.4673)  time: 0.3476  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [1860/4579]  eta: 0:15:47  Lr: 0.001875  Loss: 0.4950  Acc@1: 56.2500 (46.7457)  Acc@5: 87.5000 (85.4883)  time: 0.3466  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1870/4579]  eta: 0:15:43  Lr: 0.001875  Loss: -0.1564  Acc@1: 56.2500 (46.8332)  Acc@5: 93.7500 (85.5224)  time: 0.3466  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1880/4579]  eta: 0:15:40  Lr: 0.001875  Loss: -0.1291  Acc@1: 56.2500 (46.8667)  Acc@5: 93.7500 (85.5363)  time: 0.3457  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1890/4579]  eta: 0:15:36  Lr: 0.001875  Loss: -0.3086  Acc@1: 56.2500 (46.9395)  Acc@5: 87.5000 (85.5467)  time: 0.3467  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [1900/4579]  eta: 0:15:33  Lr: 0.001875  Loss: 0.1954  Acc@1: 56.2500 (46.9884)  Acc@5: 87.5000 (85.5438)  time: 0.3465  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [1910/4579]  eta: 0:15:29  Lr: 0.001875  Loss: 0.5701  Acc@1: 56.2500 (47.0107)  Acc@5: 87.5000 (85.5508)  time: 0.3459  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1920/4579]  eta: 0:15:26  Lr: 0.001875  Loss: 0.2102  Acc@1: 50.0000 (47.0653)  Acc@5: 87.5000 (85.5609)  time: 0.3463  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1930/4579]  eta: 0:15:22  Lr: 0.001875  Loss: -0.0168  Acc@1: 56.2500 (47.1032)  Acc@5: 87.5000 (85.5871)  time: 0.3464  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1940/4579]  eta: 0:15:19  Lr: 0.001875  Loss: 0.3689  Acc@1: 56.2500 (47.1600)  Acc@5: 93.7500 (85.6066)  time: 0.3472  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [1950/4579]  eta: 0:15:15  Lr: 0.001875  Loss: 0.6599  Acc@1: 56.2500 (47.2130)  Acc@5: 87.5000 (85.6292)  time: 0.3479  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [1960/4579]  eta: 0:15:12  Lr: 0.001875  Loss: 0.0935  Acc@1: 56.2500 (47.2686)  Acc@5: 93.7500 (85.6483)  time: 0.3486  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1970/4579]  eta: 0:15:08  Lr: 0.001875  Loss: 0.4444  Acc@1: 56.2500 (47.3015)  Acc@5: 87.5000 (85.6513)  time: 0.3484  data: 0.0009  max mem: 2500
Train: Epoch[1/5]  [1980/4579]  eta: 0:15:05  Lr: 0.001875  Loss: 0.6027  Acc@1: 56.2500 (47.3530)  Acc@5: 87.5000 (85.6764)  time: 0.3469  data: 0.0009  max mem: 2500
Train: Epoch[1/5]  [1990/4579]  eta: 0:15:01  Lr: 0.001875  Loss: 0.0710  Acc@1: 50.0000 (47.3757)  Acc@5: 87.5000 (85.6824)  time: 0.3476  data: 0.0013  max mem: 2500
Train: Epoch[1/5]  [2000/4579]  eta: 0:14:58  Lr: 0.001875  Loss: 0.2890  Acc@1: 56.2500 (47.4419)  Acc@5: 93.7500 (85.7134)  time: 0.3480  data: 0.0011  max mem: 2500
Train: Epoch[1/5]  [2010/4579]  eta: 0:14:54  Lr: 0.001875  Loss: 0.0656  Acc@1: 56.2500 (47.4639)  Acc@5: 93.7500 (85.7161)  time: 0.3482  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2020/4579]  eta: 0:14:51  Lr: 0.001875  Loss: 1.1796  Acc@1: 50.0000 (47.4765)  Acc@5: 87.5000 (85.7094)  time: 0.3495  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [2030/4579]  eta: 0:14:47  Lr: 0.001875  Loss: 0.1431  Acc@1: 50.0000 (47.5320)  Acc@5: 87.5000 (85.7213)  time: 0.3481  data: 0.0013  max mem: 2500
Train: Epoch[1/5]  [2040/4579]  eta: 0:14:44  Lr: 0.001875  Loss: 0.5857  Acc@1: 56.2500 (47.5655)  Acc@5: 87.5000 (85.7055)  time: 0.3471  data: 0.0014  max mem: 2500
Train: Epoch[1/5]  [2050/4579]  eta: 0:14:40  Lr: 0.001875  Loss: 0.2251  Acc@1: 56.2500 (47.6323)  Acc@5: 87.5000 (85.7387)  time: 0.3470  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [2060/4579]  eta: 0:14:37  Lr: 0.001875  Loss: 0.3573  Acc@1: 56.2500 (47.6801)  Acc@5: 93.7500 (85.7684)  time: 0.3473  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2070/4579]  eta: 0:14:33  Lr: 0.001875  Loss: -0.3844  Acc@1: 50.0000 (47.7004)  Acc@5: 93.7500 (85.7859)  time: 0.3530  data: 0.0017  max mem: 2500
Train: Epoch[1/5]  [2080/4579]  eta: 0:14:30  Lr: 0.001875  Loss: 0.3866  Acc@1: 50.0000 (47.7385)  Acc@5: 87.5000 (85.8151)  time: 0.3516  data: 0.0017  max mem: 2500
Train: Epoch[1/5]  [2090/4579]  eta: 0:14:26  Lr: 0.001875  Loss: 0.6822  Acc@1: 50.0000 (47.7523)  Acc@5: 87.5000 (85.8112)  time: 0.3458  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2100/4579]  eta: 0:14:23  Lr: 0.001875  Loss: 0.7091  Acc@1: 50.0000 (47.7957)  Acc@5: 81.2500 (85.8133)  time: 0.3469  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2110/4579]  eta: 0:14:19  Lr: 0.001875  Loss: 0.7695  Acc@1: 56.2500 (47.8535)  Acc@5: 87.5000 (85.8213)  time: 0.3463  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2120/4579]  eta: 0:14:16  Lr: 0.001875  Loss: 0.2999  Acc@1: 56.2500 (47.8901)  Acc@5: 87.5000 (85.8292)  time: 0.3461  data: 0.0009  max mem: 2500
Train: Epoch[1/5]  [2130/4579]  eta: 0:14:12  Lr: 0.001875  Loss: 0.0485  Acc@1: 56.2500 (47.9264)  Acc@5: 87.5000 (85.8458)  time: 0.3467  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [2140/4579]  eta: 0:14:09  Lr: 0.001875  Loss: 0.5178  Acc@1: 56.2500 (47.9566)  Acc@5: 87.5000 (85.8594)  time: 0.3466  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2150/4579]  eta: 0:14:05  Lr: 0.001875  Loss: 0.1151  Acc@1: 56.2500 (48.0126)  Acc@5: 93.7500 (85.8787)  time: 0.3473  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2160/4579]  eta: 0:14:02  Lr: 0.001875  Loss: 0.4024  Acc@1: 62.5000 (48.0709)  Acc@5: 93.7500 (85.9093)  time: 0.3485  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [2170/4579]  eta: 0:13:58  Lr: 0.001875  Loss: 0.1859  Acc@1: 56.2500 (48.0884)  Acc@5: 93.7500 (85.9022)  time: 0.3474  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [2180/4579]  eta: 0:13:55  Lr: 0.001875  Loss: 0.0726  Acc@1: 56.2500 (48.1345)  Acc@5: 87.5000 (85.9210)  time: 0.3462  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2190/4579]  eta: 0:13:51  Lr: 0.001875  Loss: -0.2193  Acc@1: 56.2500 (48.1801)  Acc@5: 87.5000 (85.9254)  time: 0.3478  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2200/4579]  eta: 0:13:48  Lr: 0.001875  Loss: -0.3927  Acc@1: 56.2500 (48.2480)  Acc@5: 87.5000 (85.9524)  time: 0.3478  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2210/4579]  eta: 0:13:44  Lr: 0.001875  Loss: 0.4199  Acc@1: 56.2500 (48.2728)  Acc@5: 87.5000 (85.9424)  time: 0.3464  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2220/4579]  eta: 0:13:41  Lr: 0.001875  Loss: 0.2986  Acc@1: 56.2500 (48.3144)  Acc@5: 81.2500 (85.9438)  time: 0.3456  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2230/4579]  eta: 0:13:37  Lr: 0.001875  Loss: -0.0903  Acc@1: 56.2500 (48.3556)  Acc@5: 87.5000 (85.9704)  time: 0.3461  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2240/4579]  eta: 0:13:34  Lr: 0.001875  Loss: 0.2231  Acc@1: 56.2500 (48.3936)  Acc@5: 87.5000 (85.9689)  time: 0.3476  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2250/4579]  eta: 0:13:30  Lr: 0.001875  Loss: -0.0780  Acc@1: 56.2500 (48.4313)  Acc@5: 87.5000 (85.9951)  time: 0.3470  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2260/4579]  eta: 0:13:27  Lr: 0.001875  Loss: 0.4289  Acc@1: 56.2500 (48.4548)  Acc@5: 93.7500 (86.0156)  time: 0.3480  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2270/4579]  eta: 0:13:23  Lr: 0.001875  Loss: 0.1778  Acc@1: 56.2500 (48.4863)  Acc@5: 87.5000 (86.0249)  time: 0.3515  data: 0.0016  max mem: 2500
Train: Epoch[1/5]  [2280/4579]  eta: 0:13:20  Lr: 0.001875  Loss: 0.6057  Acc@1: 56.2500 (48.5039)  Acc@5: 87.5000 (86.0396)  time: 0.3490  data: 0.0017  max mem: 2500
Train: Epoch[1/5]  [2290/4579]  eta: 0:13:16  Lr: 0.001875  Loss: 0.3749  Acc@1: 56.2500 (48.5296)  Acc@5: 87.5000 (86.0514)  time: 0.3460  data: 0.0012  max mem: 2500
Train: Epoch[1/5]  [2300/4579]  eta: 0:13:13  Lr: 0.001875  Loss: 0.1239  Acc@1: 50.0000 (48.5604)  Acc@5: 87.5000 (86.0631)  time: 0.3465  data: 0.0012  max mem: 2500
Train: Epoch[1/5]  [2310/4579]  eta: 0:13:09  Lr: 0.001875  Loss: -0.4382  Acc@1: 56.2500 (48.5991)  Acc@5: 87.5000 (86.0829)  time: 0.3470  data: 0.0013  max mem: 2500
Train: Epoch[1/5]  [2320/4579]  eta: 0:13:06  Lr: 0.001875  Loss: 0.3078  Acc@1: 56.2500 (48.6105)  Acc@5: 81.2500 (86.0755)  time: 0.3471  data: 0.0012  max mem: 2500
Train: Epoch[1/5]  [2330/4579]  eta: 0:13:02  Lr: 0.001875  Loss: 0.5180  Acc@1: 50.0000 (48.6272)  Acc@5: 87.5000 (86.0763)  time: 0.3483  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2340/4579]  eta: 0:12:59  Lr: 0.001875  Loss: 0.1388  Acc@1: 56.2500 (48.6838)  Acc@5: 93.7500 (86.1090)  time: 0.3479  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2350/4579]  eta: 0:12:56  Lr: 0.001875  Loss: 0.0650  Acc@1: 62.5000 (48.7293)  Acc@5: 93.7500 (86.1336)  time: 0.3483  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2360/4579]  eta: 0:12:52  Lr: 0.001875  Loss: 0.1368  Acc@1: 56.2500 (48.7664)  Acc@5: 93.7500 (86.1579)  time: 0.3485  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2370/4579]  eta: 0:12:49  Lr: 0.001875  Loss: 0.6229  Acc@1: 62.5000 (48.8112)  Acc@5: 87.5000 (86.1662)  time: 0.3472  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [2380/4579]  eta: 0:12:45  Lr: 0.001875  Loss: -0.5361  Acc@1: 62.5000 (48.8608)  Acc@5: 87.5000 (86.1823)  time: 0.3470  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [2390/4579]  eta: 0:12:42  Lr: 0.001875  Loss: -0.0370  Acc@1: 56.2500 (48.8734)  Acc@5: 87.5000 (86.1904)  time: 0.3473  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [2400/4579]  eta: 0:12:38  Lr: 0.001875  Loss: -0.3773  Acc@1: 56.2500 (48.9353)  Acc@5: 93.7500 (86.2349)  time: 0.3472  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2410/4579]  eta: 0:12:35  Lr: 0.001875  Loss: 0.2231  Acc@1: 56.2500 (48.9579)  Acc@5: 93.7500 (86.2401)  time: 0.3457  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [2420/4579]  eta: 0:12:31  Lr: 0.001875  Loss: -0.2825  Acc@1: 56.2500 (49.0009)  Acc@5: 87.5000 (86.2454)  time: 0.3459  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [2430/4579]  eta: 0:12:28  Lr: 0.001875  Loss: 0.7695  Acc@1: 56.2500 (49.0076)  Acc@5: 87.5000 (86.2557)  time: 0.3463  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [2440/4579]  eta: 0:12:24  Lr: 0.001875  Loss: 0.3343  Acc@1: 50.0000 (49.0296)  Acc@5: 87.5000 (86.2556)  time: 0.3460  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2450/4579]  eta: 0:12:21  Lr: 0.001875  Loss: -0.0292  Acc@1: 56.2500 (49.0897)  Acc@5: 87.5000 (86.2837)  time: 0.3474  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2460/4579]  eta: 0:12:17  Lr: 0.001875  Loss: 0.2743  Acc@1: 56.2500 (49.0908)  Acc@5: 87.5000 (86.2886)  time: 0.3487  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [2470/4579]  eta: 0:12:14  Lr: 0.001875  Loss: -0.2854  Acc@1: 50.0000 (49.1147)  Acc@5: 87.5000 (86.2859)  time: 0.3492  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [2480/4579]  eta: 0:12:10  Lr: 0.001875  Loss: 0.0199  Acc@1: 56.2500 (49.1586)  Acc@5: 87.5000 (86.2933)  time: 0.3489  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [2490/4579]  eta: 0:12:07  Lr: 0.001875  Loss: -0.1697  Acc@1: 62.5000 (49.2122)  Acc@5: 93.7500 (86.3233)  time: 0.3481  data: 0.0017  max mem: 2500
Train: Epoch[1/5]  [2500/4579]  eta: 0:12:03  Lr: 0.001875  Loss: 0.3405  Acc@1: 62.5000 (49.2553)  Acc@5: 93.7500 (86.3380)  time: 0.3475  data: 0.0016  max mem: 2500
Train: Epoch[1/5]  [2510/4579]  eta: 0:12:00  Lr: 0.001875  Loss: 0.0144  Acc@1: 56.2500 (49.2832)  Acc@5: 93.7500 (86.3625)  time: 0.3461  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2520/4579]  eta: 0:11:56  Lr: 0.001875  Loss: -0.0509  Acc@1: 56.2500 (49.3207)  Acc@5: 93.7500 (86.3844)  time: 0.3478  data: 0.0010  max mem: 2500
Train: Epoch[1/5]  [2530/4579]  eta: 0:11:53  Lr: 0.001875  Loss: -0.1302  Acc@1: 56.2500 (49.3827)  Acc@5: 93.7500 (86.4110)  time: 0.3475  data: 0.0010  max mem: 2500
Train: Epoch[1/5]  [2540/4579]  eta: 0:11:49  Lr: 0.001875  Loss: 0.4020  Acc@1: 56.2500 (49.4097)  Acc@5: 93.7500 (86.4325)  time: 0.3457  data: 0.0014  max mem: 2500
Train: Epoch[1/5]  [2550/4579]  eta: 0:11:46  Lr: 0.001875  Loss: -0.2138  Acc@1: 56.2500 (49.4438)  Acc@5: 93.7500 (86.4514)  time: 0.3466  data: 0.0015  max mem: 2500
Train: Epoch[1/5]  [2560/4579]  eta: 0:11:42  Lr: 0.001875  Loss: 0.8206  Acc@1: 56.2500 (49.4826)  Acc@5: 93.7500 (86.4628)  time: 0.3466  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [2570/4579]  eta: 0:11:39  Lr: 0.001875  Loss: -0.2413  Acc@1: 56.2500 (49.4968)  Acc@5: 87.5000 (86.4693)  time: 0.3477  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [2580/4579]  eta: 0:11:35  Lr: 0.001875  Loss: 0.1616  Acc@1: 56.2500 (49.5084)  Acc@5: 87.5000 (86.4781)  time: 0.3492  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [2590/4579]  eta: 0:11:32  Lr: 0.001875  Loss: 0.5388  Acc@1: 50.0000 (49.5272)  Acc@5: 87.5000 (86.4628)  time: 0.3473  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [2600/4579]  eta: 0:11:28  Lr: 0.001875  Loss: -0.0893  Acc@1: 50.0000 (49.5338)  Acc@5: 87.5000 (86.4812)  time: 0.3469  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [2610/4579]  eta: 0:11:25  Lr: 0.001875  Loss: 0.0286  Acc@1: 50.0000 (49.5572)  Acc@5: 87.5000 (86.4827)  time: 0.3491  data: 0.0013  max mem: 2500
Train: Epoch[1/5]  [2620/4579]  eta: 0:11:21  Lr: 0.001875  Loss: -0.0584  Acc@1: 50.0000 (49.5732)  Acc@5: 87.5000 (86.5009)  time: 0.3486  data: 0.0013  max mem: 2500
Train: Epoch[1/5]  [2630/4579]  eta: 0:11:18  Lr: 0.001875  Loss: 0.3159  Acc@1: 50.0000 (49.5748)  Acc@5: 87.5000 (86.5070)  time: 0.3462  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2640/4579]  eta: 0:11:14  Lr: 0.001875  Loss: 0.5758  Acc@1: 50.0000 (49.5977)  Acc@5: 87.5000 (86.5250)  time: 0.3463  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2650/4579]  eta: 0:11:11  Lr: 0.001875  Loss: -0.0568  Acc@1: 56.2500 (49.6275)  Acc@5: 93.7500 (86.5334)  time: 0.3473  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2660/4579]  eta: 0:11:07  Lr: 0.001875  Loss: -0.3140  Acc@1: 56.2500 (49.6665)  Acc@5: 87.5000 (86.5511)  time: 0.3478  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2670/4579]  eta: 0:11:04  Lr: 0.001875  Loss: -0.1760  Acc@1: 56.2500 (49.6864)  Acc@5: 87.5000 (86.5617)  time: 0.3477  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [2680/4579]  eta: 0:11:00  Lr: 0.001875  Loss: -0.1160  Acc@1: 56.2500 (49.7133)  Acc@5: 93.7500 (86.5792)  time: 0.3459  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [2690/4579]  eta: 0:10:57  Lr: 0.001875  Loss: 1.1252  Acc@1: 50.0000 (49.6934)  Acc@5: 87.5000 (86.5733)  time: 0.3465  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2700/4579]  eta: 0:10:53  Lr: 0.001875  Loss: -0.1205  Acc@1: 56.2500 (49.7177)  Acc@5: 87.5000 (86.5767)  time: 0.3474  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2710/4579]  eta: 0:10:50  Lr: 0.001875  Loss: 0.3818  Acc@1: 56.2500 (49.7441)  Acc@5: 87.5000 (86.5709)  time: 0.3471  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2720/4579]  eta: 0:10:46  Lr: 0.001875  Loss: 0.2507  Acc@1: 56.2500 (49.7933)  Acc@5: 87.5000 (86.5789)  time: 0.3482  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [2730/4579]  eta: 0:10:43  Lr: 0.001875  Loss: 0.4882  Acc@1: 56.2500 (49.7895)  Acc@5: 87.5000 (86.5754)  time: 0.3486  data: 0.0020  max mem: 2500
Train: Epoch[1/5]  [2740/4579]  eta: 0:10:40  Lr: 0.001875  Loss: 0.4273  Acc@1: 50.0000 (49.8016)  Acc@5: 87.5000 (86.5811)  time: 0.3466  data: 0.0021  max mem: 2500
Train: Epoch[1/5]  [2750/4579]  eta: 0:10:36  Lr: 0.001875  Loss: 0.0368  Acc@1: 50.0000 (49.8251)  Acc@5: 87.5000 (86.5844)  time: 0.3474  data: 0.0011  max mem: 2500
Train: Epoch[1/5]  [2760/4579]  eta: 0:10:33  Lr: 0.001875  Loss: 0.1904  Acc@1: 56.2500 (49.8529)  Acc@5: 87.5000 (86.6013)  time: 0.3497  data: 0.0026  max mem: 2500
Train: Epoch[1/5]  [2770/4579]  eta: 0:10:29  Lr: 0.001875  Loss: 0.4369  Acc@1: 56.2500 (49.8579)  Acc@5: 87.5000 (86.5933)  time: 0.3483  data: 0.0023  max mem: 2500
Train: Epoch[1/5]  [2780/4579]  eta: 0:10:26  Lr: 0.001875  Loss: 0.2276  Acc@1: 50.0000 (49.8899)  Acc@5: 87.5000 (86.6010)  time: 0.3459  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2790/4579]  eta: 0:10:22  Lr: 0.001875  Loss: 0.2935  Acc@1: 50.0000 (49.8970)  Acc@5: 87.5000 (86.5953)  time: 0.3453  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2800/4579]  eta: 0:10:19  Lr: 0.001875  Loss: -0.0766  Acc@1: 50.0000 (49.9130)  Acc@5: 87.5000 (86.5941)  time: 0.3466  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2810/4579]  eta: 0:10:15  Lr: 0.001875  Loss: 0.0167  Acc@1: 50.0000 (49.9422)  Acc@5: 93.7500 (86.6151)  time: 0.3467  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2820/4579]  eta: 0:10:12  Lr: 0.001875  Loss: -0.2241  Acc@1: 62.5000 (49.9911)  Acc@5: 87.5000 (86.6293)  time: 0.3477  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [2830/4579]  eta: 0:10:08  Lr: 0.001875  Loss: 0.0606  Acc@1: 62.5000 (50.0132)  Acc@5: 87.5000 (86.6346)  time: 0.3473  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [2840/4579]  eta: 0:10:05  Lr: 0.001875  Loss: 0.0198  Acc@1: 62.5000 (50.0616)  Acc@5: 93.7500 (86.6530)  time: 0.3475  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [2850/4579]  eta: 0:10:01  Lr: 0.001875  Loss: -0.0735  Acc@1: 62.5000 (50.1052)  Acc@5: 93.7500 (86.6648)  time: 0.3478  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2860/4579]  eta: 0:09:58  Lr: 0.001875  Loss: -0.2379  Acc@1: 62.5000 (50.1464)  Acc@5: 93.7500 (86.6764)  time: 0.3467  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2870/4579]  eta: 0:09:54  Lr: 0.001875  Loss: 0.4573  Acc@1: 62.5000 (50.1720)  Acc@5: 93.7500 (86.6858)  time: 0.3477  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [2880/4579]  eta: 0:09:51  Lr: 0.001875  Loss: -0.3504  Acc@1: 56.2500 (50.2018)  Acc@5: 87.5000 (86.6800)  time: 0.3474  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [2890/4579]  eta: 0:09:47  Lr: 0.001875  Loss: -0.5417  Acc@1: 62.5000 (50.2378)  Acc@5: 87.5000 (86.7044)  time: 0.3472  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [2900/4579]  eta: 0:09:44  Lr: 0.001875  Loss: 0.0596  Acc@1: 62.5000 (50.2844)  Acc@5: 87.5000 (86.7072)  time: 0.3469  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [2910/4579]  eta: 0:09:40  Lr: 0.001875  Loss: 0.1789  Acc@1: 56.2500 (50.3027)  Acc@5: 87.5000 (86.7120)  time: 0.3466  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [2920/4579]  eta: 0:09:37  Lr: 0.001875  Loss: 0.1086  Acc@1: 56.2500 (50.3210)  Acc@5: 93.7500 (86.7233)  time: 0.3475  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [2930/4579]  eta: 0:09:33  Lr: 0.001875  Loss: 0.6025  Acc@1: 56.2500 (50.3454)  Acc@5: 87.5000 (86.7323)  time: 0.3470  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2940/4579]  eta: 0:09:30  Lr: 0.001875  Loss: -0.2636  Acc@1: 56.2500 (50.3655)  Acc@5: 87.5000 (86.7435)  time: 0.3464  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2950/4579]  eta: 0:09:26  Lr: 0.001875  Loss: -0.1726  Acc@1: 62.5000 (50.4066)  Acc@5: 87.5000 (86.7503)  time: 0.3480  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [2960/4579]  eta: 0:09:23  Lr: 0.001875  Loss: 0.2330  Acc@1: 62.5000 (50.4369)  Acc@5: 93.7500 (86.7591)  time: 0.3520  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [2970/4579]  eta: 0:09:19  Lr: 0.001875  Loss: -0.1958  Acc@1: 62.5000 (50.4754)  Acc@5: 93.7500 (86.7742)  time: 0.3500  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [2980/4579]  eta: 0:09:16  Lr: 0.001875  Loss: 0.6606  Acc@1: 56.2500 (50.4906)  Acc@5: 87.5000 (86.7872)  time: 0.3471  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [2990/4579]  eta: 0:09:12  Lr: 0.001875  Loss: -0.2882  Acc@1: 62.5000 (50.5287)  Acc@5: 93.7500 (86.8083)  time: 0.3475  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [3000/4579]  eta: 0:09:09  Lr: 0.001875  Loss: 0.2833  Acc@1: 62.5000 (50.5540)  Acc@5: 87.5000 (86.8086)  time: 0.3469  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3010/4579]  eta: 0:09:05  Lr: 0.001875  Loss: 0.0942  Acc@1: 56.2500 (50.5812)  Acc@5: 87.5000 (86.8233)  time: 0.3482  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3020/4579]  eta: 0:09:02  Lr: 0.001875  Loss: -0.2922  Acc@1: 56.2500 (50.6082)  Acc@5: 87.5000 (86.8235)  time: 0.3481  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [3030/4579]  eta: 0:08:59  Lr: 0.001875  Loss: 0.1819  Acc@1: 62.5000 (50.6372)  Acc@5: 87.5000 (86.8319)  time: 0.3481  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [3040/4579]  eta: 0:08:55  Lr: 0.001875  Loss: -0.0646  Acc@1: 56.2500 (50.6536)  Acc@5: 87.5000 (86.8382)  time: 0.3481  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [3050/4579]  eta: 0:08:52  Lr: 0.001875  Loss: -0.1925  Acc@1: 62.5000 (50.6801)  Acc@5: 93.7500 (86.8547)  time: 0.3477  data: 0.0009  max mem: 2500
Train: Epoch[1/5]  [3060/4579]  eta: 0:08:48  Lr: 0.001875  Loss: 0.5256  Acc@1: 62.5000 (50.7228)  Acc@5: 93.7500 (86.8711)  time: 0.3481  data: 0.0009  max mem: 2500
Train: Epoch[1/5]  [3070/4579]  eta: 0:08:45  Lr: 0.001875  Loss: 0.4914  Acc@1: 56.2500 (50.7347)  Acc@5: 93.7500 (86.8772)  time: 0.3470  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [3080/4579]  eta: 0:08:41  Lr: 0.001875  Loss: 0.1995  Acc@1: 50.0000 (50.7465)  Acc@5: 87.5000 (86.8833)  time: 0.3469  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [3090/4579]  eta: 0:08:38  Lr: 0.001875  Loss: -0.3882  Acc@1: 56.2500 (50.7785)  Acc@5: 87.5000 (86.8894)  time: 0.3482  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [3100/4579]  eta: 0:08:34  Lr: 0.001875  Loss: -0.2602  Acc@1: 62.5000 (50.8082)  Acc@5: 87.5000 (86.9014)  time: 0.3484  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [3110/4579]  eta: 0:08:31  Lr: 0.001875  Loss: 0.4422  Acc@1: 56.2500 (50.8337)  Acc@5: 87.5000 (86.8973)  time: 0.3501  data: 0.0022  max mem: 2500
Train: Epoch[1/5]  [3120/4579]  eta: 0:08:27  Lr: 0.001875  Loss: -0.3799  Acc@1: 56.2500 (50.8731)  Acc@5: 87.5000 (86.9233)  time: 0.3485  data: 0.0020  max mem: 2500
Train: Epoch[1/5]  [3130/4579]  eta: 0:08:24  Lr: 0.001875  Loss: 0.0728  Acc@1: 56.2500 (50.8863)  Acc@5: 93.7500 (86.9291)  time: 0.3484  data: 0.0014  max mem: 2500
Train: Epoch[1/5]  [3140/4579]  eta: 0:08:20  Lr: 0.001875  Loss: 0.0640  Acc@1: 50.0000 (50.8755)  Acc@5: 87.5000 (86.9309)  time: 0.3481  data: 0.0015  max mem: 2500
Train: Epoch[1/5]  [3150/4579]  eta: 0:08:17  Lr: 0.001875  Loss: 0.6683  Acc@1: 50.0000 (50.8827)  Acc@5: 87.5000 (86.9347)  time: 0.3460  data: 0.0009  max mem: 2500
Train: Epoch[1/5]  [3160/4579]  eta: 0:08:13  Lr: 0.001875  Loss: 0.2746  Acc@1: 56.2500 (50.9155)  Acc@5: 87.5000 (86.9484)  time: 0.3497  data: 0.0023  max mem: 2500
Train: Epoch[1/5]  [3170/4579]  eta: 0:08:10  Lr: 0.001875  Loss: 0.2749  Acc@1: 56.2500 (50.9303)  Acc@5: 87.5000 (86.9402)  time: 0.3501  data: 0.0019  max mem: 2500
Train: Epoch[1/5]  [3180/4579]  eta: 0:08:06  Lr: 0.001875  Loss: -0.3174  Acc@1: 56.2500 (50.9470)  Acc@5: 87.5000 (86.9459)  time: 0.3470  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [3190/4579]  eta: 0:08:03  Lr: 0.001875  Loss: 0.4136  Acc@1: 56.2500 (50.9656)  Acc@5: 87.5000 (86.9535)  time: 0.3481  data: 0.0015  max mem: 2500
Train: Epoch[1/5]  [3200/4579]  eta: 0:07:59  Lr: 0.001875  Loss: -0.3199  Acc@1: 56.2500 (50.9743)  Acc@5: 87.5000 (86.9552)  time: 0.3487  data: 0.0013  max mem: 2500
Train: Epoch[1/5]  [3210/4579]  eta: 0:07:56  Lr: 0.001875  Loss: 0.1290  Acc@1: 62.5000 (51.0141)  Acc@5: 87.5000 (86.9686)  time: 0.3465  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [3220/4579]  eta: 0:07:52  Lr: 0.001875  Loss: -0.1171  Acc@1: 62.5000 (51.0595)  Acc@5: 87.5000 (86.9683)  time: 0.3459  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [3230/4579]  eta: 0:07:49  Lr: 0.001875  Loss: -0.1039  Acc@1: 62.5000 (51.0949)  Acc@5: 87.5000 (86.9797)  time: 0.3472  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [3240/4579]  eta: 0:07:45  Lr: 0.001875  Loss: -0.0396  Acc@1: 62.5000 (51.1358)  Acc@5: 93.7500 (87.0044)  time: 0.3469  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [3250/4579]  eta: 0:07:42  Lr: 0.001875  Loss: 0.4725  Acc@1: 62.5000 (51.1843)  Acc@5: 93.7500 (87.0251)  time: 0.3485  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [3260/4579]  eta: 0:07:39  Lr: 0.001875  Loss: -0.0139  Acc@1: 62.5000 (51.2151)  Acc@5: 93.7500 (87.0324)  time: 0.3510  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [3270/4579]  eta: 0:07:35  Lr: 0.001875  Loss: 0.0062  Acc@1: 56.2500 (51.2439)  Acc@5: 93.7500 (87.0510)  time: 0.3487  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [3280/4579]  eta: 0:07:32  Lr: 0.001875  Loss: 0.5108  Acc@1: 56.2500 (51.2591)  Acc@5: 93.7500 (87.0657)  time: 0.3464  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3290/4579]  eta: 0:07:28  Lr: 0.001875  Loss: -0.2786  Acc@1: 56.2500 (51.2800)  Acc@5: 93.7500 (87.0632)  time: 0.3462  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3300/4579]  eta: 0:07:25  Lr: 0.001875  Loss: 0.5890  Acc@1: 56.2500 (51.3007)  Acc@5: 87.5000 (87.0797)  time: 0.3471  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3310/4579]  eta: 0:07:21  Lr: 0.001875  Loss: -0.0332  Acc@1: 56.2500 (51.3157)  Acc@5: 93.7500 (87.0923)  time: 0.3472  data: 0.0009  max mem: 2500
Train: Epoch[1/5]  [3320/4579]  eta: 0:07:18  Lr: 0.001875  Loss: 0.0460  Acc@1: 56.2500 (51.3456)  Acc@5: 87.5000 (87.0916)  time: 0.3473  data: 0.0009  max mem: 2500
Train: Epoch[1/5]  [3330/4579]  eta: 0:07:14  Lr: 0.001875  Loss: -0.4896  Acc@1: 56.2500 (51.3866)  Acc@5: 93.7500 (87.1135)  time: 0.3485  data: 0.0010  max mem: 2500
Train: Epoch[1/5]  [3340/4579]  eta: 0:07:11  Lr: 0.001875  Loss: -0.1628  Acc@1: 56.2500 (51.3937)  Acc@5: 93.7500 (87.1184)  time: 0.3487  data: 0.0010  max mem: 2500
Train: Epoch[1/5]  [3350/4579]  eta: 0:07:07  Lr: 0.001875  Loss: -0.1233  Acc@1: 56.2500 (51.4231)  Acc@5: 87.5000 (87.1195)  time: 0.3472  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [3360/4579]  eta: 0:07:04  Lr: 0.001875  Loss: -0.2475  Acc@1: 56.2500 (51.4393)  Acc@5: 87.5000 (87.1299)  time: 0.3469  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [3370/4579]  eta: 0:07:00  Lr: 0.001875  Loss: 0.2309  Acc@1: 56.2500 (51.4647)  Acc@5: 87.5000 (87.1292)  time: 0.3469  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [3380/4579]  eta: 0:06:57  Lr: 0.001875  Loss: 0.2295  Acc@1: 56.2500 (51.4807)  Acc@5: 87.5000 (87.1303)  time: 0.3480  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3390/4579]  eta: 0:06:53  Lr: 0.001875  Loss: -0.5690  Acc@1: 56.2500 (51.5021)  Acc@5: 87.5000 (87.1369)  time: 0.3486  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3400/4579]  eta: 0:06:50  Lr: 0.001875  Loss: 0.5586  Acc@1: 56.2500 (51.5198)  Acc@5: 93.7500 (87.1564)  time: 0.3478  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [3410/4579]  eta: 0:06:46  Lr: 0.001875  Loss: -0.0121  Acc@1: 56.2500 (51.5410)  Acc@5: 93.7500 (87.1702)  time: 0.3473  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [3420/4579]  eta: 0:06:43  Lr: 0.001875  Loss: -0.0700  Acc@1: 62.5000 (51.5675)  Acc@5: 87.5000 (87.1711)  time: 0.3463  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [3430/4579]  eta: 0:06:39  Lr: 0.001875  Loss: -0.6176  Acc@1: 62.5000 (51.6012)  Acc@5: 87.5000 (87.1758)  time: 0.3478  data: 0.0012  max mem: 2500
Train: Epoch[1/5]  [3440/4579]  eta: 0:06:36  Lr: 0.001875  Loss: -0.0593  Acc@1: 56.2500 (51.6075)  Acc@5: 87.5000 (87.1676)  time: 0.3485  data: 0.0012  max mem: 2500
Train: Epoch[1/5]  [3450/4579]  eta: 0:06:32  Lr: 0.001875  Loss: 0.3949  Acc@1: 56.2500 (51.6300)  Acc@5: 87.5000 (87.1758)  time: 0.3464  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [3460/4579]  eta: 0:06:29  Lr: 0.001875  Loss: -0.0885  Acc@1: 56.2500 (51.6361)  Acc@5: 87.5000 (87.1749)  time: 0.3458  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [3470/4579]  eta: 0:06:25  Lr: 0.001875  Loss: 0.6453  Acc@1: 56.2500 (51.6566)  Acc@5: 87.5000 (87.1849)  time: 0.3470  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [3480/4579]  eta: 0:06:22  Lr: 0.001875  Loss: 0.1976  Acc@1: 50.0000 (51.6500)  Acc@5: 87.5000 (87.1768)  time: 0.3463  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [3490/4579]  eta: 0:06:18  Lr: 0.001875  Loss: -0.2604  Acc@1: 50.0000 (51.6668)  Acc@5: 87.5000 (87.1849)  time: 0.3466  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [3500/4579]  eta: 0:06:15  Lr: 0.001875  Loss: 0.1912  Acc@1: 56.2500 (51.6817)  Acc@5: 93.7500 (87.1983)  time: 0.3471  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [3510/4579]  eta: 0:06:11  Lr: 0.001875  Loss: 0.1082  Acc@1: 56.2500 (51.6876)  Acc@5: 93.7500 (87.2063)  time: 0.3456  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [3520/4579]  eta: 0:06:08  Lr: 0.001875  Loss: 0.1475  Acc@1: 56.2500 (51.7129)  Acc@5: 87.5000 (87.2160)  time: 0.3471  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [3530/4579]  eta: 0:06:04  Lr: 0.001875  Loss: 0.3470  Acc@1: 56.2500 (51.7258)  Acc@5: 87.5000 (87.2274)  time: 0.3490  data: 0.0012  max mem: 2500
Train: Epoch[1/5]  [3540/4579]  eta: 0:06:01  Lr: 0.001875  Loss: -0.2593  Acc@1: 56.2500 (51.7474)  Acc@5: 93.7500 (87.2388)  time: 0.3480  data: 0.0012  max mem: 2500
Train: Epoch[1/5]  [3550/4579]  eta: 0:05:58  Lr: 0.001875  Loss: 0.5124  Acc@1: 62.5000 (51.7724)  Acc@5: 93.7500 (87.2448)  time: 0.3465  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [3560/4579]  eta: 0:05:54  Lr: 0.001875  Loss: 0.2222  Acc@1: 56.2500 (51.7920)  Acc@5: 87.5000 (87.2525)  time: 0.3471  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [3570/4579]  eta: 0:05:51  Lr: 0.001875  Loss: 0.9208  Acc@1: 56.2500 (51.8115)  Acc@5: 87.5000 (87.2462)  time: 0.3475  data: 0.0013  max mem: 2500
Train: Epoch[1/5]  [3580/4579]  eta: 0:05:47  Lr: 0.001875  Loss: -0.2444  Acc@1: 62.5000 (51.8291)  Acc@5: 87.5000 (87.2504)  time: 0.3484  data: 0.0029  max mem: 2500
Train: Epoch[1/5]  [3590/4579]  eta: 0:05:44  Lr: 0.001875  Loss: -0.2699  Acc@1: 62.5000 (51.8362)  Acc@5: 87.5000 (87.2511)  time: 0.3495  data: 0.0030  max mem: 2500
Train: Epoch[1/5]  [3600/4579]  eta: 0:05:40  Lr: 0.001875  Loss: 0.0176  Acc@1: 62.5000 (51.8658)  Acc@5: 87.5000 (87.2587)  time: 0.3478  data: 0.0013  max mem: 2500
Train: Epoch[1/5]  [3610/4579]  eta: 0:05:37  Lr: 0.001875  Loss: -0.1445  Acc@1: 68.7500 (51.9004)  Acc@5: 93.7500 (87.2767)  time: 0.3458  data: 0.0009  max mem: 2500
Train: Epoch[1/5]  [3620/4579]  eta: 0:05:33  Lr: 0.001875  Loss: 0.7034  Acc@1: 56.2500 (51.9004)  Acc@5: 93.7500 (87.2825)  time: 0.3469  data: 0.0010  max mem: 2500
Train: Epoch[1/5]  [3630/4579]  eta: 0:05:30  Lr: 0.001875  Loss: 0.1645  Acc@1: 56.2500 (51.9158)  Acc@5: 87.5000 (87.2934)  time: 0.3472  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [3640/4579]  eta: 0:05:26  Lr: 0.001875  Loss: -0.0528  Acc@1: 62.5000 (51.9414)  Acc@5: 87.5000 (87.3009)  time: 0.3458  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [3650/4579]  eta: 0:05:23  Lr: 0.001875  Loss: -0.0371  Acc@1: 62.5000 (51.9669)  Acc@5: 87.5000 (87.3100)  time: 0.3464  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [3660/4579]  eta: 0:05:19  Lr: 0.001875  Loss: -0.1963  Acc@1: 62.5000 (51.9940)  Acc@5: 93.7500 (87.3225)  time: 0.3468  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [3670/4579]  eta: 0:05:16  Lr: 0.001875  Loss: 0.8394  Acc@1: 62.5000 (52.0226)  Acc@5: 93.7500 (87.3297)  time: 0.3471  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [3680/4579]  eta: 0:05:12  Lr: 0.001875  Loss: -0.0664  Acc@1: 62.5000 (52.0562)  Acc@5: 93.7500 (87.3472)  time: 0.3460  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [3690/4579]  eta: 0:05:09  Lr: 0.001875  Loss: -0.3518  Acc@1: 62.5000 (52.0794)  Acc@5: 93.7500 (87.3628)  time: 0.3464  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3700/4579]  eta: 0:05:05  Lr: 0.001875  Loss: 0.2894  Acc@1: 56.2500 (52.0923)  Acc@5: 93.7500 (87.3700)  time: 0.3477  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3710/4579]  eta: 0:05:02  Lr: 0.001875  Loss: 0.1724  Acc@1: 50.0000 (52.1086)  Acc@5: 87.5000 (87.3754)  time: 0.3476  data: 0.0010  max mem: 2500
Train: Epoch[1/5]  [3720/4579]  eta: 0:04:58  Lr: 0.001875  Loss: -0.0714  Acc@1: 50.0000 (52.0996)  Acc@5: 87.5000 (87.3723)  time: 0.3468  data: 0.0010  max mem: 2500
Train: Epoch[1/5]  [3730/4579]  eta: 0:04:55  Lr: 0.001875  Loss: 0.4217  Acc@1: 56.2500 (52.1157)  Acc@5: 87.5000 (87.3827)  time: 0.3478  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [3740/4579]  eta: 0:04:51  Lr: 0.001875  Loss: 0.0337  Acc@1: 56.2500 (52.1401)  Acc@5: 93.7500 (87.3931)  time: 0.3479  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [3750/4579]  eta: 0:04:48  Lr: 0.001875  Loss: 0.5350  Acc@1: 56.2500 (52.1411)  Acc@5: 93.7500 (87.4017)  time: 0.3458  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [3760/4579]  eta: 0:04:44  Lr: 0.001875  Loss: -0.1967  Acc@1: 56.2500 (52.1553)  Acc@5: 93.7500 (87.4136)  time: 0.3473  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [3770/4579]  eta: 0:04:41  Lr: 0.001875  Loss: -0.2305  Acc@1: 62.5000 (52.1778)  Acc@5: 93.7500 (87.4188)  time: 0.3485  data: 0.0014  max mem: 2500
Train: Epoch[1/5]  [3780/4579]  eta: 0:04:37  Lr: 0.001875  Loss: 0.1184  Acc@1: 62.5000 (52.2018)  Acc@5: 93.7500 (87.4339)  time: 0.3470  data: 0.0012  max mem: 2500
Train: Epoch[1/5]  [3790/4579]  eta: 0:04:34  Lr: 0.001875  Loss: 0.1701  Acc@1: 62.5000 (52.2207)  Acc@5: 93.7500 (87.4456)  time: 0.3463  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [3800/4579]  eta: 0:04:30  Lr: 0.001875  Loss: -0.1161  Acc@1: 62.5000 (52.2461)  Acc@5: 93.7500 (87.4572)  time: 0.3478  data: 0.0014  max mem: 2500
Train: Epoch[1/5]  [3810/4579]  eta: 0:04:27  Lr: 0.001875  Loss: 0.7892  Acc@1: 56.2500 (52.2583)  Acc@5: 87.5000 (87.4606)  time: 0.3486  data: 0.0013  max mem: 2500
Train: Epoch[1/5]  [3820/4579]  eta: 0:04:24  Lr: 0.001875  Loss: -0.2359  Acc@1: 56.2500 (52.2622)  Acc@5: 87.5000 (87.4689)  time: 0.3489  data: 0.0011  max mem: 2500
Train: Epoch[1/5]  [3830/4579]  eta: 0:04:20  Lr: 0.001875  Loss: 0.1419  Acc@1: 56.2500 (52.2726)  Acc@5: 87.5000 (87.4772)  time: 0.3484  data: 0.0011  max mem: 2500
Train: Epoch[1/5]  [3840/4579]  eta: 0:04:17  Lr: 0.001875  Loss: -0.2229  Acc@1: 62.5000 (52.3090)  Acc@5: 87.5000 (87.4821)  time: 0.3476  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [3850/4579]  eta: 0:04:13  Lr: 0.001875  Loss: 0.9806  Acc@1: 62.5000 (52.3241)  Acc@5: 87.5000 (87.4870)  time: 0.3483  data: 0.0021  max mem: 2500
Train: Epoch[1/5]  [3860/4579]  eta: 0:04:10  Lr: 0.001875  Loss: -0.4025  Acc@1: 62.5000 (52.3504)  Acc@5: 87.5000 (87.4870)  time: 0.3489  data: 0.0020  max mem: 2500
Train: Epoch[1/5]  [3870/4579]  eta: 0:04:06  Lr: 0.001875  Loss: 0.0776  Acc@1: 56.2500 (52.3557)  Acc@5: 87.5000 (87.4935)  time: 0.3492  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [3880/4579]  eta: 0:04:03  Lr: 0.001875  Loss: 0.0028  Acc@1: 56.2500 (52.3818)  Acc@5: 87.5000 (87.4984)  time: 0.3480  data: 0.0013  max mem: 2500
Train: Epoch[1/5]  [3890/4579]  eta: 0:03:59  Lr: 0.001875  Loss: 0.1045  Acc@1: 56.2500 (52.3773)  Acc@5: 87.5000 (87.4984)  time: 0.3478  data: 0.0011  max mem: 2500
Train: Epoch[1/5]  [3900/4579]  eta: 0:03:56  Lr: 0.001875  Loss: -0.0392  Acc@1: 56.2500 (52.3952)  Acc@5: 87.5000 (87.5080)  time: 0.3480  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [3910/4579]  eta: 0:03:52  Lr: 0.001875  Loss: 0.0098  Acc@1: 62.5000 (52.4099)  Acc@5: 93.7500 (87.5160)  time: 0.3465  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [3920/4579]  eta: 0:03:49  Lr: 0.001875  Loss: 0.0097  Acc@1: 56.2500 (52.4149)  Acc@5: 87.5000 (87.5143)  time: 0.3465  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [3930/4579]  eta: 0:03:45  Lr: 0.001875  Loss: 0.3603  Acc@1: 56.2500 (52.4262)  Acc@5: 87.5000 (87.5095)  time: 0.3459  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3940/4579]  eta: 0:03:42  Lr: 0.001875  Loss: 0.2436  Acc@1: 56.2500 (52.4391)  Acc@5: 87.5000 (87.5270)  time: 0.3469  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [3950/4579]  eta: 0:03:38  Lr: 0.001875  Loss: -0.6430  Acc@1: 50.0000 (52.4440)  Acc@5: 93.7500 (87.5364)  time: 0.3473  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [3960/4579]  eta: 0:03:35  Lr: 0.001875  Loss: -0.2644  Acc@1: 62.5000 (52.4804)  Acc@5: 93.7500 (87.5552)  time: 0.3479  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [3970/4579]  eta: 0:03:31  Lr: 0.001875  Loss: 0.2202  Acc@1: 62.5000 (52.5057)  Acc@5: 93.7500 (87.5598)  time: 0.3473  data: 0.0009  max mem: 2500
Train: Epoch[1/5]  [3980/4579]  eta: 0:03:28  Lr: 0.001875  Loss: 0.6021  Acc@1: 62.5000 (52.5355)  Acc@5: 93.7500 (87.5691)  time: 0.3502  data: 0.0009  max mem: 2500
Train: Epoch[1/5]  [3990/4579]  eta: 0:03:24  Lr: 0.001875  Loss: 0.4074  Acc@1: 56.2500 (52.5385)  Acc@5: 93.7500 (87.5783)  time: 0.3505  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [4000/4579]  eta: 0:03:21  Lr: 0.001875  Loss: -0.0474  Acc@1: 50.0000 (52.5540)  Acc@5: 93.7500 (87.5875)  time: 0.3476  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [4010/4579]  eta: 0:03:17  Lr: 0.001875  Loss: 0.3911  Acc@1: 56.2500 (52.5648)  Acc@5: 87.5000 (87.5888)  time: 0.3473  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [4020/4579]  eta: 0:03:14  Lr: 0.001875  Loss: -0.3315  Acc@1: 62.5000 (52.5926)  Acc@5: 87.5000 (87.6010)  time: 0.3464  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [4030/4579]  eta: 0:03:10  Lr: 0.001875  Loss: -0.0873  Acc@1: 62.5000 (52.6048)  Acc@5: 93.7500 (87.6070)  time: 0.3475  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [4040/4579]  eta: 0:03:07  Lr: 0.001875  Loss: 0.6249  Acc@1: 62.5000 (52.6216)  Acc@5: 87.5000 (87.6098)  time: 0.3477  data: 0.0011  max mem: 2500
Train: Epoch[1/5]  [4050/4579]  eta: 0:03:04  Lr: 0.001875  Loss: 0.4957  Acc@1: 62.5000 (52.6352)  Acc@5: 87.5000 (87.6111)  time: 0.3482  data: 0.0011  max mem: 2500
Train: Epoch[1/5]  [4060/4579]  eta: 0:03:00  Lr: 0.001875  Loss: 0.7400  Acc@1: 56.2500 (52.6410)  Acc@5: 87.5000 (87.6093)  time: 0.3488  data: 0.0019  max mem: 2500
Train: Epoch[1/5]  [4070/4579]  eta: 0:02:57  Lr: 0.001875  Loss: -0.0781  Acc@1: 56.2500 (52.6637)  Acc@5: 87.5000 (87.6121)  time: 0.3478  data: 0.0020  max mem: 2500
Train: Epoch[1/5]  [4080/4579]  eta: 0:02:53  Lr: 0.001875  Loss: 0.6397  Acc@1: 56.2500 (52.6709)  Acc@5: 87.5000 (87.6164)  time: 0.3472  data: 0.0013  max mem: 2500
Train: Epoch[1/5]  [4090/4579]  eta: 0:02:50  Lr: 0.001875  Loss: -0.0795  Acc@1: 56.2500 (52.6888)  Acc@5: 93.7500 (87.6253)  time: 0.3477  data: 0.0012  max mem: 2500
Train: Epoch[1/5]  [4100/4579]  eta: 0:02:46  Lr: 0.001875  Loss: -0.2271  Acc@1: 62.5000 (52.7067)  Acc@5: 93.7500 (87.6402)  time: 0.3471  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [4110/4579]  eta: 0:02:43  Lr: 0.001875  Loss: 0.3275  Acc@1: 62.5000 (52.7229)  Acc@5: 87.5000 (87.6414)  time: 0.3466  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [4120/4579]  eta: 0:02:39  Lr: 0.001875  Loss: -0.0034  Acc@1: 50.0000 (52.7284)  Acc@5: 87.5000 (87.6517)  time: 0.3457  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [4130/4579]  eta: 0:02:36  Lr: 0.001875  Loss: -0.3609  Acc@1: 56.2500 (52.7521)  Acc@5: 93.7500 (87.6589)  time: 0.3450  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [4140/4579]  eta: 0:02:32  Lr: 0.001875  Loss: -0.3556  Acc@1: 62.5000 (52.7831)  Acc@5: 93.7500 (87.6736)  time: 0.3465  data: 0.0013  max mem: 2500
Train: Epoch[1/5]  [4150/4579]  eta: 0:02:29  Lr: 0.001875  Loss: 0.2835  Acc@1: 62.5000 (52.8020)  Acc@5: 93.7500 (87.6867)  time: 0.3469  data: 0.0013  max mem: 2500
Train: Epoch[1/5]  [4160/4579]  eta: 0:02:25  Lr: 0.001875  Loss: -0.1022  Acc@1: 56.2500 (52.8148)  Acc@5: 87.5000 (87.6848)  time: 0.3455  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [4170/4579]  eta: 0:02:22  Lr: 0.001875  Loss: 0.3420  Acc@1: 56.2500 (52.8141)  Acc@5: 87.5000 (87.6828)  time: 0.3469  data: 0.0011  max mem: 2500
Train: Epoch[1/5]  [4180/4579]  eta: 0:02:18  Lr: 0.001875  Loss: 0.2346  Acc@1: 56.2500 (52.8268)  Acc@5: 87.5000 (87.6928)  time: 0.3473  data: 0.0014  max mem: 2500
Train: Epoch[1/5]  [4190/4579]  eta: 0:02:15  Lr: 0.001875  Loss: 0.4853  Acc@1: 56.2500 (52.8484)  Acc@5: 93.7500 (87.7013)  time: 0.3468  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [4200/4579]  eta: 0:02:11  Lr: 0.001875  Loss: 0.1408  Acc@1: 56.2500 (52.8416)  Acc@5: 87.5000 (87.6994)  time: 0.3465  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [4210/4579]  eta: 0:02:08  Lr: 0.001875  Loss: 1.5856  Acc@1: 56.2500 (52.8675)  Acc@5: 87.5000 (87.6974)  time: 0.3462  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [4220/4579]  eta: 0:02:04  Lr: 0.001875  Loss: 0.2590  Acc@1: 62.5000 (52.8844)  Acc@5: 87.5000 (87.7029)  time: 0.3465  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [4230/4579]  eta: 0:02:01  Lr: 0.001875  Loss: -0.0259  Acc@1: 56.2500 (52.8909)  Acc@5: 93.7500 (87.7024)  time: 0.3462  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [4240/4579]  eta: 0:01:57  Lr: 0.001875  Loss: 0.4744  Acc@1: 62.5000 (52.9120)  Acc@5: 87.5000 (87.7034)  time: 0.3468  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [4250/4579]  eta: 0:01:54  Lr: 0.001875  Loss: 0.3338  Acc@1: 56.2500 (52.9081)  Acc@5: 87.5000 (87.7073)  time: 0.3465  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [4260/4579]  eta: 0:01:50  Lr: 0.001875  Loss: -0.2621  Acc@1: 56.2500 (52.9277)  Acc@5: 87.5000 (87.7039)  time: 0.3448  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [4270/4579]  eta: 0:01:47  Lr: 0.001875  Loss: -0.4843  Acc@1: 62.5000 (52.9501)  Acc@5: 87.5000 (87.7166)  time: 0.3464  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [4280/4579]  eta: 0:01:43  Lr: 0.001875  Loss: -0.3280  Acc@1: 68.7500 (52.9885)  Acc@5: 93.7500 (87.7307)  time: 0.3482  data: 0.0013  max mem: 2500
Train: Epoch[1/5]  [4290/4579]  eta: 0:01:40  Lr: 0.001875  Loss: -0.0174  Acc@1: 62.5000 (53.0034)  Acc@5: 93.7500 (87.7462)  time: 0.3468  data: 0.0013  max mem: 2500
Train: Epoch[1/5]  [4300/4579]  eta: 0:01:37  Lr: 0.001875  Loss: -0.5848  Acc@1: 62.5000 (53.0313)  Acc@5: 93.7500 (87.7558)  time: 0.3476  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [4310/4579]  eta: 0:01:33  Lr: 0.001875  Loss: -0.3074  Acc@1: 62.5000 (53.0373)  Acc@5: 87.5000 (87.7581)  time: 0.3480  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [4320/4579]  eta: 0:01:30  Lr: 0.001875  Loss: 0.3465  Acc@1: 62.5000 (53.0621)  Acc@5: 87.5000 (87.7618)  time: 0.3462  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [4330/4579]  eta: 0:01:26  Lr: 0.001875  Loss: 0.2506  Acc@1: 62.5000 (53.0868)  Acc@5: 87.5000 (87.7655)  time: 0.3461  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [4340/4579]  eta: 0:01:23  Lr: 0.001875  Loss: -0.6297  Acc@1: 62.5000 (53.0955)  Acc@5: 87.5000 (87.7678)  time: 0.3477  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [4350/4579]  eta: 0:01:19  Lr: 0.001875  Loss: 0.1812  Acc@1: 62.5000 (53.1214)  Acc@5: 87.5000 (87.7758)  time: 0.3483  data: 0.0012  max mem: 2500
Train: Epoch[1/5]  [4360/4579]  eta: 0:01:16  Lr: 0.001875  Loss: 0.4686  Acc@1: 62.5000 (53.1472)  Acc@5: 93.7500 (87.7852)  time: 0.3480  data: 0.0017  max mem: 2500
Train: Epoch[1/5]  [4370/4579]  eta: 0:01:12  Lr: 0.001875  Loss: 0.0945  Acc@1: 62.5000 (53.1529)  Acc@5: 87.5000 (87.7888)  time: 0.3472  data: 0.0013  max mem: 2500
Train: Epoch[1/5]  [4380/4579]  eta: 0:01:09  Lr: 0.001875  Loss: -0.2282  Acc@1: 56.2500 (53.1528)  Acc@5: 87.5000 (87.7882)  time: 0.3462  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [4390/4579]  eta: 0:01:05  Lr: 0.001875  Loss: -0.6342  Acc@1: 56.2500 (53.1727)  Acc@5: 93.7500 (87.7975)  time: 0.3479  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [4400/4579]  eta: 0:01:02  Lr: 0.001875  Loss: 0.0788  Acc@1: 62.5000 (53.1953)  Acc@5: 87.5000 (87.8011)  time: 0.3475  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [4410/4579]  eta: 0:00:58  Lr: 0.001875  Loss: 0.2073  Acc@1: 62.5000 (53.2150)  Acc@5: 87.5000 (87.8117)  time: 0.3468  data: 0.0011  max mem: 2500
Train: Epoch[1/5]  [4420/4579]  eta: 0:00:55  Lr: 0.001875  Loss: 0.0963  Acc@1: 62.5000 (53.2459)  Acc@5: 93.7500 (87.8167)  time: 0.3469  data: 0.0012  max mem: 2500
Train: Epoch[1/5]  [4430/4579]  eta: 0:00:51  Lr: 0.001875  Loss: 0.3810  Acc@1: 62.5000 (53.2541)  Acc@5: 93.7500 (87.8258)  time: 0.3454  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [4440/4579]  eta: 0:00:48  Lr: 0.001875  Loss: 0.0037  Acc@1: 56.2500 (53.2833)  Acc@5: 93.7500 (87.8293)  time: 0.3459  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [4450/4579]  eta: 0:00:44  Lr: 0.001875  Loss: 0.5014  Acc@1: 68.7500 (53.3082)  Acc@5: 93.7500 (87.8426)  time: 0.3477  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [4460/4579]  eta: 0:00:41  Lr: 0.001875  Loss: 0.1631  Acc@1: 56.2500 (53.3162)  Acc@5: 93.7500 (87.8362)  time: 0.3472  data: 0.0012  max mem: 2500
Train: Epoch[1/5]  [4470/4579]  eta: 0:00:37  Lr: 0.001875  Loss: -0.4256  Acc@1: 50.0000 (53.3116)  Acc@5: 93.7500 (87.8495)  time: 0.3484  data: 0.0026  max mem: 2500
Train: Epoch[1/5]  [4480/4579]  eta: 0:00:34  Lr: 0.001875  Loss: -0.3426  Acc@1: 50.0000 (53.3307)  Acc@5: 93.7500 (87.8640)  time: 0.3492  data: 0.0018  max mem: 2500
Train: Epoch[1/5]  [4490/4579]  eta: 0:00:30  Lr: 0.001875  Loss: -0.2601  Acc@1: 62.5000 (53.3470)  Acc@5: 93.7500 (87.8716)  time: 0.3468  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [4500/4579]  eta: 0:00:27  Lr: 0.001875  Loss: 0.3184  Acc@1: 62.5000 (53.3604)  Acc@5: 87.5000 (87.8749)  time: 0.3471  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [4510/4579]  eta: 0:00:23  Lr: 0.001875  Loss: 0.0577  Acc@1: 56.2500 (53.3682)  Acc@5: 87.5000 (87.8824)  time: 0.3470  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [4520/4579]  eta: 0:00:20  Lr: 0.001875  Loss: 0.1833  Acc@1: 62.5000 (53.3939)  Acc@5: 93.7500 (87.8912)  time: 0.3472  data: 0.0012  max mem: 2500
Train: Epoch[1/5]  [4530/4579]  eta: 0:00:17  Lr: 0.001875  Loss: 0.5786  Acc@1: 62.5000 (53.3919)  Acc@5: 93.7500 (87.8973)  time: 0.3476  data: 0.0012  max mem: 2500
Train: Epoch[1/5]  [4540/4579]  eta: 0:00:13  Lr: 0.001875  Loss: 0.3244  Acc@1: 50.0000 (53.4037)  Acc@5: 87.5000 (87.9005)  time: 0.3477  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [4550/4579]  eta: 0:00:10  Lr: 0.001875  Loss: -0.1691  Acc@1: 62.5000 (53.4347)  Acc@5: 87.5000 (87.9010)  time: 0.3470  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [4560/4579]  eta: 0:00:06  Lr: 0.001875  Loss: -0.2025  Acc@1: 62.5000 (53.4477)  Acc@5: 87.5000 (87.9042)  time: 0.3470  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [4570/4579]  eta: 0:00:03  Lr: 0.001875  Loss: 0.3230  Acc@1: 62.5000 (53.4743)  Acc@5: 93.7500 (87.9143)  time: 0.3483  data: 0.0013  max mem: 2500
Train: Epoch[1/5]  [4578/4579]  eta: 0:00:00  Lr: 0.001875  Loss: 0.8052  Acc@1: 50.0000 (53.4707)  Acc@5: 93.7500 (87.9165)  time: 0.3454  data: 0.0012  max mem: 2500
Train: Epoch[1/5] Total time: 0:26:33 (0.3480 s / it)
{0: {0: 73257, 1: 0, 2: 0, 3: 0, 4: 0}, 1: {0: 73257, 1: 0, 2: 0, 3: 0, 4: 0}, 2: {0: 73257, 1: 0, 2: 0, 3: 0, 4: 0}, 3: {0: 73257, 1: 0, 2: 0, 3: 0, 4: 0}, 4: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 5: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 6: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 7: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 8: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 9: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 10: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 11: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 12: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 13: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 14: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 15: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 16: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 17: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 18: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 19: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}}
Averaged stats: Lr: 0.001875  Loss: 0.8052  Acc@1: 50.0000 (53.4707)  Acc@5: 93.7500 (87.9165)
Train: Epoch[2/5]  [   0/4579]  eta: 1:03:25  Lr: 0.001875  Loss: -0.2611  Acc@1: 62.5000 (62.5000)  Acc@5: 100.0000 (100.0000)  time: 0.8312  data: 0.4843  max mem: 2500
Train: Epoch[2/5]  [  10/4579]  eta: 0:29:48  Lr: 0.001875  Loss: -0.2545  Acc@1: 62.5000 (65.3409)  Acc@5: 93.7500 (90.9091)  time: 0.3914  data: 0.0445  max mem: 2500
Train: Epoch[2/5]  [  20/4579]  eta: 0:28:07  Lr: 0.001875  Loss: -0.4118  Acc@1: 62.5000 (65.7738)  Acc@5: 87.5000 (90.7738)  time: 0.3472  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [  30/4579]  eta: 0:27:32  Lr: 0.001875  Loss: 0.6472  Acc@1: 56.2500 (63.3065)  Acc@5: 93.7500 (90.3226)  time: 0.3477  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [  40/4579]  eta: 0:27:11  Lr: 0.001875  Loss: 0.6398  Acc@1: 56.2500 (62.0427)  Acc@5: 87.5000 (89.1768)  time: 0.3483  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [  50/4579]  eta: 0:26:55  Lr: 0.001875  Loss: 0.0019  Acc@1: 56.2500 (61.8873)  Acc@5: 87.5000 (88.9706)  time: 0.3468  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [  60/4579]  eta: 0:26:45  Lr: 0.001875  Loss: -0.0412  Acc@1: 56.2500 (61.9877)  Acc@5: 87.5000 (89.4467)  time: 0.3467  data: 0.0011  max mem: 2500
Train: Epoch[2/5]  [  70/4579]  eta: 0:26:40  Lr: 0.001875  Loss: -0.0147  Acc@1: 62.5000 (61.7958)  Acc@5: 87.5000 (89.5246)  time: 0.3501  data: 0.0021  max mem: 2500
Train: Epoch[2/5]  [  80/4579]  eta: 0:26:32  Lr: 0.001875  Loss: 1.0275  Acc@1: 62.5000 (61.1883)  Acc@5: 87.5000 (89.2747)  time: 0.3494  data: 0.0014  max mem: 2500
Train: Epoch[2/5]  [  90/4579]  eta: 0:26:24  Lr: 0.001875  Loss: 0.2250  Acc@1: 62.5000 (61.8132)  Acc@5: 87.5000 (89.4918)  time: 0.3466  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [ 100/4579]  eta: 0:26:20  Lr: 0.001875  Loss: -0.1078  Acc@1: 68.7500 (62.2525)  Acc@5: 93.7500 (89.6658)  time: 0.3489  data: 0.0009  max mem: 2500
Train: Epoch[2/5]  [ 110/4579]  eta: 0:26:14  Lr: 0.001875  Loss: 0.1157  Acc@1: 62.5000 (61.8243)  Acc@5: 93.7500 (89.6396)  time: 0.3496  data: 0.0009  max mem: 2500
Train: Epoch[2/5]  [ 120/4579]  eta: 0:26:09  Lr: 0.001875  Loss: 0.7625  Acc@1: 56.2500 (61.3636)  Acc@5: 87.5000 (89.5145)  time: 0.3472  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [ 130/4579]  eta: 0:26:03  Lr: 0.001875  Loss: 0.1541  Acc@1: 50.0000 (61.0687)  Acc@5: 87.5000 (89.4561)  time: 0.3458  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [ 140/4579]  eta: 0:25:58  Lr: 0.001875  Loss: -0.0137  Acc@1: 56.2500 (60.8156)  Acc@5: 93.7500 (89.4060)  time: 0.3463  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [ 150/4579]  eta: 0:25:53  Lr: 0.001875  Loss: -0.0711  Acc@1: 62.5000 (60.9685)  Acc@5: 93.7500 (89.6937)  time: 0.3473  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [ 160/4579]  eta: 0:25:49  Lr: 0.001875  Loss: 0.1393  Acc@1: 62.5000 (60.7919)  Acc@5: 93.7500 (90.0621)  time: 0.3470  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [ 170/4579]  eta: 0:25:45  Lr: 0.001875  Loss: 0.0150  Acc@1: 56.2500 (60.4167)  Acc@5: 93.7500 (89.9854)  time: 0.3481  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [ 180/4579]  eta: 0:25:41  Lr: 0.001875  Loss: 0.7391  Acc@1: 56.2500 (60.5318)  Acc@5: 93.7500 (90.1588)  time: 0.3481  data: 0.0009  max mem: 2500
Train: Epoch[2/5]  [ 190/4579]  eta: 0:25:36  Lr: 0.001875  Loss: -0.0381  Acc@1: 62.5000 (60.7330)  Acc@5: 93.7500 (90.0524)  time: 0.3465  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [ 200/4579]  eta: 0:25:33  Lr: 0.001875  Loss: 0.0640  Acc@1: 62.5000 (60.6654)  Acc@5: 87.5000 (90.0808)  time: 0.3479  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [ 210/4579]  eta: 0:25:28  Lr: 0.001875  Loss: 0.3296  Acc@1: 62.5000 (61.0190)  Acc@5: 93.7500 (90.0178)  time: 0.3479  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [ 220/4579]  eta: 0:25:24  Lr: 0.001875  Loss: 0.3251  Acc@1: 62.5000 (61.0860)  Acc@5: 93.7500 (90.0735)  time: 0.3474  data: 0.0012  max mem: 2500
Train: Epoch[2/5]  [ 230/4579]  eta: 0:25:21  Lr: 0.001875  Loss: -0.2471  Acc@1: 62.5000 (61.2825)  Acc@5: 93.7500 (90.2868)  time: 0.3498  data: 0.0020  max mem: 2500
Train: Epoch[2/5]  [ 240/4579]  eta: 0:25:17  Lr: 0.001875  Loss: -0.3235  Acc@1: 68.7500 (61.5405)  Acc@5: 93.7500 (90.2490)  time: 0.3488  data: 0.0013  max mem: 2500
Train: Epoch[2/5]  [ 250/4579]  eta: 0:25:14  Lr: 0.001875  Loss: 0.4361  Acc@1: 62.5000 (61.5040)  Acc@5: 93.7500 (90.3386)  time: 0.3499  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [ 260/4579]  eta: 0:25:10  Lr: 0.001875  Loss: -0.1928  Acc@1: 62.5000 (61.6858)  Acc@5: 93.7500 (90.4933)  time: 0.3508  data: 0.0009  max mem: 2500
Train: Epoch[2/5]  [ 270/4579]  eta: 0:25:06  Lr: 0.001875  Loss: -0.2165  Acc@1: 62.5000 (61.6006)  Acc@5: 93.7500 (90.5673)  time: 0.3473  data: 0.0010  max mem: 2500
Train: Epoch[2/5]  [ 280/4579]  eta: 0:25:02  Lr: 0.001875  Loss: 0.1925  Acc@1: 62.5000 (61.7660)  Acc@5: 93.7500 (90.5472)  time: 0.3464  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [ 290/4579]  eta: 0:24:59  Lr: 0.001875  Loss: 0.1551  Acc@1: 62.5000 (61.8342)  Acc@5: 93.7500 (90.5713)  time: 0.3473  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [ 300/4579]  eta: 0:24:55  Lr: 0.001875  Loss: -0.0143  Acc@1: 68.7500 (61.9394)  Acc@5: 93.7500 (90.5939)  time: 0.3471  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [ 310/4579]  eta: 0:24:51  Lr: 0.001875  Loss: 0.1641  Acc@1: 68.7500 (62.1383)  Acc@5: 93.7500 (90.6150)  time: 0.3473  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [ 320/4579]  eta: 0:24:47  Lr: 0.001875  Loss: -0.0116  Acc@1: 62.5000 (61.8964)  Acc@5: 93.7500 (90.6153)  time: 0.3476  data: 0.0009  max mem: 2500
Train: Epoch[2/5]  [ 330/4579]  eta: 0:24:44  Lr: 0.001875  Loss: -0.0542  Acc@1: 56.2500 (61.8580)  Acc@5: 87.5000 (90.5778)  time: 0.3482  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [ 340/4579]  eta: 0:24:40  Lr: 0.001875  Loss: 0.0693  Acc@1: 62.5000 (61.8585)  Acc@5: 87.5000 (90.5059)  time: 0.3481  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [ 350/4579]  eta: 0:24:36  Lr: 0.001875  Loss: 0.1387  Acc@1: 62.5000 (61.8768)  Acc@5: 87.5000 (90.5627)  time: 0.3475  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [ 360/4579]  eta: 0:24:33  Lr: 0.001875  Loss: 0.3948  Acc@1: 56.2500 (61.8940)  Acc@5: 93.7500 (90.5298)  time: 0.3479  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [ 370/4579]  eta: 0:24:29  Lr: 0.001875  Loss: 0.4971  Acc@1: 62.5000 (61.9272)  Acc@5: 93.7500 (90.4987)  time: 0.3474  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [ 380/4579]  eta: 0:24:25  Lr: 0.001875  Loss: 0.2278  Acc@1: 56.2500 (61.8438)  Acc@5: 93.7500 (90.5020)  time: 0.3469  data: 0.0012  max mem: 2500
Train: Epoch[2/5]  [ 390/4579]  eta: 0:24:22  Lr: 0.001875  Loss: 0.3202  Acc@1: 56.2500 (61.8286)  Acc@5: 87.5000 (90.3932)  time: 0.3489  data: 0.0030  max mem: 2500
Train: Epoch[2/5]  [ 400/4579]  eta: 0:24:18  Lr: 0.001875  Loss: -0.7317  Acc@1: 62.5000 (61.8766)  Acc@5: 87.5000 (90.4925)  time: 0.3489  data: 0.0023  max mem: 2500
Train: Epoch[2/5]  [ 410/4579]  eta: 0:24:14  Lr: 0.001875  Loss: -0.1047  Acc@1: 62.5000 (61.8917)  Acc@5: 93.7500 (90.5109)  time: 0.3465  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 420/4579]  eta: 0:24:11  Lr: 0.001875  Loss: 0.0587  Acc@1: 56.2500 (61.8468)  Acc@5: 87.5000 (90.4543)  time: 0.3474  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [ 430/4579]  eta: 0:24:07  Lr: 0.001875  Loss: 0.3581  Acc@1: 56.2500 (61.7604)  Acc@5: 87.5000 (90.4727)  time: 0.3470  data: 0.0010  max mem: 2500
Train: Epoch[2/5]  [ 440/4579]  eta: 0:24:03  Lr: 0.001875  Loss: -0.1363  Acc@1: 56.2500 (61.8622)  Acc@5: 93.7500 (90.5329)  time: 0.3467  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [ 450/4579]  eta: 0:24:00  Lr: 0.001875  Loss: -0.1330  Acc@1: 62.5000 (61.7517)  Acc@5: 87.5000 (90.4241)  time: 0.3469  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [ 460/4579]  eta: 0:23:56  Lr: 0.001875  Loss: -0.3761  Acc@1: 62.5000 (61.8492)  Acc@5: 93.7500 (90.4420)  time: 0.3467  data: 0.0013  max mem: 2500
Train: Epoch[2/5]  [ 470/4579]  eta: 0:23:52  Lr: 0.001875  Loss: 0.7448  Acc@1: 68.7500 (61.8763)  Acc@5: 93.7500 (90.3928)  time: 0.3474  data: 0.0012  max mem: 2500
Train: Epoch[2/5]  [ 480/4579]  eta: 0:23:49  Lr: 0.001875  Loss: -0.7110  Acc@1: 62.5000 (61.9413)  Acc@5: 87.5000 (90.4236)  time: 0.3471  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [ 490/4579]  eta: 0:23:46  Lr: 0.001875  Loss: 0.0373  Acc@1: 62.5000 (61.9017)  Acc@5: 93.7500 (90.4532)  time: 0.3493  data: 0.0021  max mem: 2500
Train: Epoch[2/5]  [ 500/4579]  eta: 0:23:42  Lr: 0.001875  Loss: -0.1826  Acc@1: 62.5000 (61.8139)  Acc@5: 93.7500 (90.4691)  time: 0.3490  data: 0.0023  max mem: 2500
Train: Epoch[2/5]  [ 510/4579]  eta: 0:23:38  Lr: 0.001875  Loss: 0.2612  Acc@1: 62.5000 (61.7661)  Acc@5: 87.5000 (90.4721)  time: 0.3475  data: 0.0016  max mem: 2500
Train: Epoch[2/5]  [ 520/4579]  eta: 0:23:35  Lr: 0.001875  Loss: 0.6265  Acc@1: 56.2500 (61.7322)  Acc@5: 87.5000 (90.3911)  time: 0.3488  data: 0.0017  max mem: 2500
Train: Epoch[2/5]  [ 530/4579]  eta: 0:23:31  Lr: 0.001875  Loss: 0.4422  Acc@1: 56.2500 (61.6172)  Acc@5: 81.2500 (90.2660)  time: 0.3487  data: 0.0014  max mem: 2500
Train: Epoch[2/5]  [ 540/4579]  eta: 0:23:28  Lr: 0.001875  Loss: 0.0337  Acc@1: 56.2500 (61.5758)  Acc@5: 87.5000 (90.2957)  time: 0.3485  data: 0.0011  max mem: 2500
Train: Epoch[2/5]  [ 550/4579]  eta: 0:23:25  Lr: 0.001875  Loss: -0.3325  Acc@1: 62.5000 (61.6152)  Acc@5: 93.7500 (90.3698)  time: 0.3490  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [ 560/4579]  eta: 0:23:21  Lr: 0.001875  Loss: 0.4351  Acc@1: 56.2500 (61.4973)  Acc@5: 93.7500 (90.3855)  time: 0.3478  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [ 570/4579]  eta: 0:23:17  Lr: 0.001875  Loss: 0.0128  Acc@1: 62.5000 (61.5477)  Acc@5: 93.7500 (90.3787)  time: 0.3473  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 580/4579]  eta: 0:23:14  Lr: 0.001875  Loss: 0.3630  Acc@1: 62.5000 (61.4673)  Acc@5: 87.5000 (90.3830)  time: 0.3464  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [ 590/4579]  eta: 0:23:10  Lr: 0.001875  Loss: 0.2189  Acc@1: 56.2500 (61.3473)  Acc@5: 87.5000 (90.4082)  time: 0.3450  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [ 600/4579]  eta: 0:23:06  Lr: 0.001875  Loss: 0.5768  Acc@1: 56.2500 (61.3353)  Acc@5: 87.5000 (90.3910)  time: 0.3464  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [ 610/4579]  eta: 0:23:03  Lr: 0.001875  Loss: -0.6223  Acc@1: 62.5000 (61.4566)  Acc@5: 87.5000 (90.4153)  time: 0.3474  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [ 620/4579]  eta: 0:22:59  Lr: 0.001875  Loss: 0.3985  Acc@1: 68.7500 (61.5238)  Acc@5: 93.7500 (90.4690)  time: 0.3475  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 630/4579]  eta: 0:22:56  Lr: 0.001875  Loss: -0.3464  Acc@1: 62.5000 (61.4996)  Acc@5: 93.7500 (90.5309)  time: 0.3473  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [ 640/4579]  eta: 0:22:52  Lr: 0.001875  Loss: -0.3304  Acc@1: 62.5000 (61.5055)  Acc@5: 93.7500 (90.5324)  time: 0.3477  data: 0.0012  max mem: 2500
Train: Epoch[2/5]  [ 650/4579]  eta: 0:22:48  Lr: 0.001875  Loss: 0.2575  Acc@1: 62.5000 (61.5495)  Acc@5: 93.7500 (90.5434)  time: 0.3464  data: 0.0012  max mem: 2500
Train: Epoch[2/5]  [ 660/4579]  eta: 0:22:45  Lr: 0.001875  Loss: 0.6822  Acc@1: 56.2500 (61.4410)  Acc@5: 87.5000 (90.5068)  time: 0.3455  data: 0.0012  max mem: 2500
Train: Epoch[2/5]  [ 670/4579]  eta: 0:22:41  Lr: 0.001875  Loss: -0.0121  Acc@1: 62.5000 (61.5220)  Acc@5: 87.5000 (90.4993)  time: 0.3479  data: 0.0016  max mem: 2500
Train: Epoch[2/5]  [ 680/4579]  eta: 0:22:38  Lr: 0.001875  Loss: -0.3694  Acc@1: 68.7500 (61.6281)  Acc@5: 93.7500 (90.5470)  time: 0.3476  data: 0.0009  max mem: 2500
Train: Epoch[2/5]  [ 690/4579]  eta: 0:22:34  Lr: 0.001875  Loss: -0.7561  Acc@1: 68.7500 (61.7583)  Acc@5: 93.7500 (90.6205)  time: 0.3461  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [ 700/4579]  eta: 0:22:31  Lr: 0.001875  Loss: -0.5017  Acc@1: 68.7500 (61.8581)  Acc@5: 93.7500 (90.6384)  time: 0.3473  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [ 710/4579]  eta: 0:22:27  Lr: 0.001875  Loss: 0.5493  Acc@1: 62.5000 (61.8583)  Acc@5: 87.5000 (90.6382)  time: 0.3476  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [ 720/4579]  eta: 0:22:23  Lr: 0.001875  Loss: -0.1921  Acc@1: 62.5000 (61.8239)  Acc@5: 93.7500 (90.6467)  time: 0.3466  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [ 730/4579]  eta: 0:22:20  Lr: 0.001875  Loss: 0.1253  Acc@1: 56.2500 (61.7134)  Acc@5: 87.5000 (90.6378)  time: 0.3460  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [ 740/4579]  eta: 0:22:16  Lr: 0.001875  Loss: -0.5165  Acc@1: 50.0000 (61.6650)  Acc@5: 87.5000 (90.6292)  time: 0.3459  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [ 750/4579]  eta: 0:22:13  Lr: 0.001875  Loss: 0.5240  Acc@1: 56.2500 (61.5596)  Acc@5: 93.7500 (90.6208)  time: 0.3472  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [ 760/4579]  eta: 0:22:09  Lr: 0.001875  Loss: -0.5972  Acc@1: 56.2500 (61.5719)  Acc@5: 93.7500 (90.6127)  time: 0.3479  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [ 770/4579]  eta: 0:22:06  Lr: 0.001875  Loss: 0.8233  Acc@1: 56.2500 (61.5597)  Acc@5: 87.5000 (90.5723)  time: 0.3473  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [ 780/4579]  eta: 0:22:02  Lr: 0.001875  Loss: 0.1339  Acc@1: 56.2500 (61.5477)  Acc@5: 87.5000 (90.5730)  time: 0.3477  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [ 790/4579]  eta: 0:21:59  Lr: 0.001875  Loss: -0.0371  Acc@1: 56.2500 (61.4728)  Acc@5: 87.5000 (90.5657)  time: 0.3498  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [ 800/4579]  eta: 0:21:55  Lr: 0.001875  Loss: -0.5043  Acc@1: 56.2500 (61.4856)  Acc@5: 93.7500 (90.5977)  time: 0.3501  data: 0.0020  max mem: 2500
Train: Epoch[2/5]  [ 810/4579]  eta: 0:21:52  Lr: 0.001875  Loss: 0.3202  Acc@1: 56.2500 (61.4134)  Acc@5: 93.7500 (90.5672)  time: 0.3475  data: 0.0018  max mem: 2500
Train: Epoch[2/5]  [ 820/4579]  eta: 0:21:48  Lr: 0.001875  Loss: -0.3875  Acc@1: 62.5000 (61.4418)  Acc@5: 93.7500 (90.6060)  time: 0.3461  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [ 830/4579]  eta: 0:21:45  Lr: 0.001875  Loss: 0.2302  Acc@1: 62.5000 (61.4320)  Acc@5: 93.7500 (90.5535)  time: 0.3458  data: 0.0012  max mem: 2500
Train: Epoch[2/5]  [ 840/4579]  eta: 0:21:41  Lr: 0.001875  Loss: 0.6993  Acc@1: 62.5000 (61.4224)  Acc@5: 87.5000 (90.5321)  time: 0.3465  data: 0.0012  max mem: 2500
Train: Epoch[2/5]  [ 850/4579]  eta: 0:21:38  Lr: 0.001875  Loss: 0.6845  Acc@1: 56.2500 (61.4351)  Acc@5: 87.5000 (90.4891)  time: 0.3460  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [ 860/4579]  eta: 0:21:34  Lr: 0.001875  Loss: 0.4361  Acc@1: 62.5000 (61.4402)  Acc@5: 87.5000 (90.4472)  time: 0.3453  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [ 870/4579]  eta: 0:21:30  Lr: 0.001875  Loss: 0.0695  Acc@1: 62.5000 (61.4165)  Acc@5: 87.5000 (90.3918)  time: 0.3463  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [ 880/4579]  eta: 0:21:27  Lr: 0.001875  Loss: 0.3180  Acc@1: 56.2500 (61.4004)  Acc@5: 87.5000 (90.4299)  time: 0.3473  data: 0.0010  max mem: 2500
Train: Epoch[2/5]  [ 890/4579]  eta: 0:21:24  Lr: 0.001875  Loss: 0.3788  Acc@1: 56.2500 (61.3566)  Acc@5: 93.7500 (90.4321)  time: 0.3493  data: 0.0012  max mem: 2500
Train: Epoch[2/5]  [ 900/4579]  eta: 0:21:20  Lr: 0.001875  Loss: -0.0991  Acc@1: 56.2500 (61.3138)  Acc@5: 87.5000 (90.4481)  time: 0.3513  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [ 910/4579]  eta: 0:21:17  Lr: 0.001875  Loss: 0.0365  Acc@1: 62.5000 (61.3543)  Acc@5: 87.5000 (90.4020)  time: 0.3487  data: 0.0013  max mem: 2500
Train: Epoch[2/5]  [ 920/4579]  eta: 0:21:13  Lr: 0.001875  Loss: -0.0869  Acc@1: 62.5000 (61.3464)  Acc@5: 93.7500 (90.4520)  time: 0.3460  data: 0.0012  max mem: 2500
Train: Epoch[2/5]  [ 930/4579]  eta: 0:21:10  Lr: 0.001875  Loss: 0.0839  Acc@1: 62.5000 (61.3923)  Acc@5: 93.7500 (90.4874)  time: 0.3473  data: 0.0013  max mem: 2500
Train: Epoch[2/5]  [ 940/4579]  eta: 0:21:06  Lr: 0.001875  Loss: 0.4978  Acc@1: 62.5000 (61.4439)  Acc@5: 93.7500 (90.4822)  time: 0.3475  data: 0.0013  max mem: 2500
Train: Epoch[2/5]  [ 950/4579]  eta: 0:21:03  Lr: 0.001875  Loss: -0.1813  Acc@1: 68.7500 (61.4879)  Acc@5: 93.7500 (90.5297)  time: 0.3457  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [ 960/4579]  eta: 0:20:59  Lr: 0.001875  Loss: 0.2838  Acc@1: 62.5000 (61.5114)  Acc@5: 93.7500 (90.5307)  time: 0.3454  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [ 970/4579]  eta: 0:20:55  Lr: 0.001875  Loss: -0.5579  Acc@1: 62.5000 (61.4830)  Acc@5: 87.5000 (90.5188)  time: 0.3456  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 980/4579]  eta: 0:20:52  Lr: 0.001875  Loss: 0.0671  Acc@1: 62.5000 (61.5061)  Acc@5: 87.5000 (90.5390)  time: 0.3458  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [ 990/4579]  eta: 0:20:48  Lr: 0.001875  Loss: 1.0537  Acc@1: 62.5000 (61.4783)  Acc@5: 87.5000 (90.4894)  time: 0.3474  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [1000/4579]  eta: 0:20:45  Lr: 0.001875  Loss: 0.6357  Acc@1: 56.2500 (61.4261)  Acc@5: 87.5000 (90.4783)  time: 0.3468  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [1010/4579]  eta: 0:20:41  Lr: 0.001875  Loss: -0.3254  Acc@1: 62.5000 (61.4800)  Acc@5: 93.7500 (90.5045)  time: 0.3468  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1020/4579]  eta: 0:20:38  Lr: 0.001875  Loss: -0.2076  Acc@1: 62.5000 (61.4961)  Acc@5: 93.7500 (90.5056)  time: 0.3469  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1030/4579]  eta: 0:20:34  Lr: 0.001875  Loss: -0.1684  Acc@1: 62.5000 (61.5361)  Acc@5: 93.7500 (90.5129)  time: 0.3450  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1040/4579]  eta: 0:20:31  Lr: 0.001875  Loss: -0.0496  Acc@1: 62.5000 (61.5934)  Acc@5: 93.7500 (90.5139)  time: 0.3453  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [1050/4579]  eta: 0:20:27  Lr: 0.001875  Loss: 0.6747  Acc@1: 62.5000 (61.5783)  Acc@5: 93.7500 (90.5150)  time: 0.3471  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [1060/4579]  eta: 0:20:24  Lr: 0.001875  Loss: -0.4332  Acc@1: 62.5000 (61.6046)  Acc@5: 87.5000 (90.5160)  time: 0.3471  data: 0.0010  max mem: 2500
Train: Epoch[2/5]  [1070/4579]  eta: 0:20:20  Lr: 0.001875  Loss: 0.4983  Acc@1: 56.2500 (61.5663)  Acc@5: 93.7500 (90.5229)  time: 0.3473  data: 0.0013  max mem: 2500
Train: Epoch[2/5]  [1080/4579]  eta: 0:20:17  Lr: 0.001875  Loss: 0.2189  Acc@1: 56.2500 (61.5518)  Acc@5: 87.5000 (90.5180)  time: 0.3476  data: 0.0016  max mem: 2500
Train: Epoch[2/5]  [1090/4579]  eta: 0:20:13  Lr: 0.001875  Loss: -0.0694  Acc@1: 56.2500 (61.5720)  Acc@5: 93.7500 (90.5247)  time: 0.3474  data: 0.0011  max mem: 2500
Train: Epoch[2/5]  [1100/4579]  eta: 0:20:10  Lr: 0.001875  Loss: 0.1325  Acc@1: 62.5000 (61.6428)  Acc@5: 93.7500 (90.4973)  time: 0.3475  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1110/4579]  eta: 0:20:06  Lr: 0.001875  Loss: -0.2553  Acc@1: 68.7500 (61.7012)  Acc@5: 93.7500 (90.5322)  time: 0.3471  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1120/4579]  eta: 0:20:03  Lr: 0.001875  Loss: -0.0641  Acc@1: 68.7500 (61.6916)  Acc@5: 93.7500 (90.4996)  time: 0.3480  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1130/4579]  eta: 0:19:59  Lr: 0.001875  Loss: 0.7264  Acc@1: 56.2500 (61.6711)  Acc@5: 87.5000 (90.4675)  time: 0.3488  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1140/4579]  eta: 0:19:56  Lr: 0.001875  Loss: -0.1094  Acc@1: 56.2500 (61.6619)  Acc@5: 87.5000 (90.4744)  time: 0.3470  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1150/4579]  eta: 0:19:52  Lr: 0.001875  Loss: -0.0600  Acc@1: 62.5000 (61.6964)  Acc@5: 93.7500 (90.4702)  time: 0.3465  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1160/4579]  eta: 0:19:49  Lr: 0.001875  Loss: 0.1932  Acc@1: 56.2500 (61.6656)  Acc@5: 87.5000 (90.4662)  time: 0.3474  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1170/4579]  eta: 0:19:45  Lr: 0.001875  Loss: 0.2792  Acc@1: 56.2500 (61.6514)  Acc@5: 93.7500 (90.4889)  time: 0.3478  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [1180/4579]  eta: 0:19:42  Lr: 0.001875  Loss: 0.1935  Acc@1: 56.2500 (61.6215)  Acc@5: 93.7500 (90.4901)  time: 0.3474  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [1190/4579]  eta: 0:19:38  Lr: 0.001875  Loss: 0.1059  Acc@1: 62.5000 (61.7024)  Acc@5: 93.7500 (90.4912)  time: 0.3461  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1200/4579]  eta: 0:19:35  Lr: 0.001875  Loss: 0.8741  Acc@1: 68.7500 (61.7194)  Acc@5: 87.5000 (90.4715)  time: 0.3474  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1210/4579]  eta: 0:19:31  Lr: 0.001875  Loss: -0.2332  Acc@1: 62.5000 (61.6949)  Acc@5: 93.7500 (90.4986)  time: 0.3473  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [1220/4579]  eta: 0:19:28  Lr: 0.001875  Loss: 0.6490  Acc@1: 56.2500 (61.6503)  Acc@5: 93.7500 (90.5252)  time: 0.3469  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [1230/4579]  eta: 0:19:24  Lr: 0.001875  Loss: -0.4934  Acc@1: 56.2500 (61.6724)  Acc@5: 93.7500 (90.5565)  time: 0.3475  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [1240/4579]  eta: 0:19:21  Lr: 0.001875  Loss: -0.0688  Acc@1: 62.5000 (61.6992)  Acc@5: 93.7500 (90.5620)  time: 0.3472  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1250/4579]  eta: 0:19:17  Lr: 0.001875  Loss: -0.0697  Acc@1: 62.5000 (61.6707)  Acc@5: 93.7500 (90.5576)  time: 0.3468  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1260/4579]  eta: 0:19:14  Lr: 0.001875  Loss: 0.8197  Acc@1: 56.2500 (61.6376)  Acc@5: 87.5000 (90.5234)  time: 0.3465  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1270/4579]  eta: 0:19:10  Lr: 0.001875  Loss: 0.2964  Acc@1: 56.2500 (61.6247)  Acc@5: 87.5000 (90.5193)  time: 0.3476  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [1280/4579]  eta: 0:19:07  Lr: 0.001875  Loss: -0.2480  Acc@1: 56.2500 (61.5925)  Acc@5: 93.7500 (90.5396)  time: 0.3481  data: 0.0014  max mem: 2500
Train: Epoch[2/5]  [1290/4579]  eta: 0:19:03  Lr: 0.001875  Loss: -0.1691  Acc@1: 62.5000 (61.6479)  Acc@5: 93.7500 (90.5403)  time: 0.3486  data: 0.0012  max mem: 2500
Train: Epoch[2/5]  [1300/4579]  eta: 0:19:00  Lr: 0.001875  Loss: -0.3201  Acc@1: 68.7500 (61.7025)  Acc@5: 93.7500 (90.5746)  time: 0.3478  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1310/4579]  eta: 0:18:56  Lr: 0.001875  Loss: 0.1248  Acc@1: 68.7500 (61.6991)  Acc@5: 93.7500 (90.5940)  time: 0.3462  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1320/4579]  eta: 0:18:53  Lr: 0.001875  Loss: 0.3283  Acc@1: 68.7500 (61.7477)  Acc@5: 93.7500 (90.5942)  time: 0.3467  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [1330/4579]  eta: 0:18:49  Lr: 0.001875  Loss: 0.5217  Acc@1: 62.5000 (61.7017)  Acc@5: 93.7500 (90.5851)  time: 0.3478  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [1340/4579]  eta: 0:18:46  Lr: 0.001875  Loss: 0.5247  Acc@1: 62.5000 (61.7403)  Acc@5: 93.7500 (90.6040)  time: 0.3476  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [1350/4579]  eta: 0:18:42  Lr: 0.001875  Loss: 0.4815  Acc@1: 62.5000 (61.7043)  Acc@5: 93.7500 (90.6088)  time: 0.3474  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [1360/4579]  eta: 0:18:39  Lr: 0.001875  Loss: -0.5776  Acc@1: 62.5000 (61.7239)  Acc@5: 93.7500 (90.6227)  time: 0.3464  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [1370/4579]  eta: 0:18:35  Lr: 0.001875  Loss: 0.3228  Acc@1: 62.5000 (61.7022)  Acc@5: 93.7500 (90.6090)  time: 0.3452  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1380/4579]  eta: 0:18:32  Lr: 0.001875  Loss: 0.3391  Acc@1: 62.5000 (61.6899)  Acc@5: 87.5000 (90.6182)  time: 0.3462  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1390/4579]  eta: 0:18:28  Lr: 0.001875  Loss: 0.3244  Acc@1: 62.5000 (61.7092)  Acc@5: 93.7500 (90.6452)  time: 0.3469  data: 0.0009  max mem: 2500
Train: Epoch[2/5]  [1400/4579]  eta: 0:18:25  Lr: 0.001875  Loss: 0.0098  Acc@1: 62.5000 (61.6970)  Acc@5: 93.7500 (90.6317)  time: 0.3484  data: 0.0020  max mem: 2500
Train: Epoch[2/5]  [1410/4579]  eta: 0:18:21  Lr: 0.001875  Loss: 0.8804  Acc@1: 62.5000 (61.6584)  Acc@5: 87.5000 (90.6272)  time: 0.3483  data: 0.0015  max mem: 2500
Train: Epoch[2/5]  [1420/4579]  eta: 0:18:18  Lr: 0.001875  Loss: 0.2623  Acc@1: 62.5000 (61.6467)  Acc@5: 93.7500 (90.6448)  time: 0.3486  data: 0.0016  max mem: 2500
Train: Epoch[2/5]  [1430/4579]  eta: 0:18:14  Lr: 0.001875  Loss: 0.5325  Acc@1: 62.5000 (61.6134)  Acc@5: 93.7500 (90.6578)  time: 0.3480  data: 0.0018  max mem: 2500
Train: Epoch[2/5]  [1440/4579]  eta: 0:18:11  Lr: 0.001875  Loss: 0.1737  Acc@1: 62.5000 (61.6239)  Acc@5: 87.5000 (90.6358)  time: 0.3467  data: 0.0009  max mem: 2500
Train: Epoch[2/5]  [1450/4579]  eta: 0:18:07  Lr: 0.001875  Loss: -0.2377  Acc@1: 62.5000 (61.5911)  Acc@5: 87.5000 (90.6401)  time: 0.3468  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [1460/4579]  eta: 0:18:04  Lr: 0.001875  Loss: 0.1512  Acc@1: 62.5000 (61.5974)  Acc@5: 87.5000 (90.6229)  time: 0.3468  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [1470/4579]  eta: 0:18:01  Lr: 0.001875  Loss: 0.3748  Acc@1: 62.5000 (61.5908)  Acc@5: 87.5000 (90.6229)  time: 0.3476  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1480/4579]  eta: 0:17:57  Lr: 0.001875  Loss: -0.3368  Acc@1: 56.2500 (61.5716)  Acc@5: 87.5000 (90.6060)  time: 0.3469  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1490/4579]  eta: 0:17:54  Lr: 0.001875  Loss: 0.1390  Acc@1: 56.2500 (61.5568)  Acc@5: 87.5000 (90.6103)  time: 0.3466  data: 0.0011  max mem: 2500
Train: Epoch[2/5]  [1500/4579]  eta: 0:17:50  Lr: 0.001875  Loss: -0.0302  Acc@1: 56.2500 (61.5506)  Acc@5: 87.5000 (90.6104)  time: 0.3473  data: 0.0011  max mem: 2500
Train: Epoch[2/5]  [1510/4579]  eta: 0:17:47  Lr: 0.001875  Loss: -0.3798  Acc@1: 62.5000 (61.5611)  Acc@5: 87.5000 (90.6064)  time: 0.3463  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1520/4579]  eta: 0:17:43  Lr: 0.001875  Loss: 0.3210  Acc@1: 62.5000 (61.5549)  Acc@5: 87.5000 (90.5901)  time: 0.3459  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1530/4579]  eta: 0:17:40  Lr: 0.001875  Loss: 0.0002  Acc@1: 62.5000 (61.5774)  Acc@5: 87.5000 (90.6025)  time: 0.3476  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [1540/4579]  eta: 0:17:36  Lr: 0.001875  Loss: -0.2327  Acc@1: 62.5000 (61.5793)  Acc@5: 93.7500 (90.6149)  time: 0.3497  data: 0.0024  max mem: 2500
Train: Epoch[2/5]  [1550/4579]  eta: 0:17:33  Lr: 0.001875  Loss: 0.0604  Acc@1: 68.7500 (61.6417)  Acc@5: 93.7500 (90.6310)  time: 0.3486  data: 0.0023  max mem: 2500
Train: Epoch[2/5]  [1560/4579]  eta: 0:17:29  Lr: 0.001875  Loss: 0.1335  Acc@1: 68.7500 (61.6312)  Acc@5: 93.7500 (90.6270)  time: 0.3477  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1570/4579]  eta: 0:17:26  Lr: 0.001875  Loss: -0.2013  Acc@1: 56.2500 (61.6248)  Acc@5: 87.5000 (90.6230)  time: 0.3474  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1580/4579]  eta: 0:17:22  Lr: 0.001875  Loss: 0.6337  Acc@1: 56.2500 (61.6145)  Acc@5: 93.7500 (90.6349)  time: 0.3464  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [1590/4579]  eta: 0:17:19  Lr: 0.001875  Loss: -0.3753  Acc@1: 62.5000 (61.6358)  Acc@5: 93.7500 (90.6466)  time: 0.3468  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [1600/4579]  eta: 0:17:15  Lr: 0.001875  Loss: -0.4390  Acc@1: 62.5000 (61.6607)  Acc@5: 93.7500 (90.6387)  time: 0.3464  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [1610/4579]  eta: 0:17:12  Lr: 0.001875  Loss: -0.2649  Acc@1: 62.5000 (61.6465)  Acc@5: 93.7500 (90.6386)  time: 0.3468  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1620/4579]  eta: 0:17:08  Lr: 0.001875  Loss: 0.1544  Acc@1: 56.2500 (61.6402)  Acc@5: 93.7500 (90.6424)  time: 0.3470  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1630/4579]  eta: 0:17:05  Lr: 0.001875  Loss: -0.2354  Acc@1: 56.2500 (61.6378)  Acc@5: 93.7500 (90.6537)  time: 0.3473  data: 0.0010  max mem: 2500
Train: Epoch[2/5]  [1640/4579]  eta: 0:17:01  Lr: 0.001875  Loss: 0.0649  Acc@1: 62.5000 (61.6621)  Acc@5: 93.7500 (90.6612)  time: 0.3481  data: 0.0011  max mem: 2500
Train: Epoch[2/5]  [1650/4579]  eta: 0:16:58  Lr: 0.001875  Loss: -0.1310  Acc@1: 62.5000 (61.6785)  Acc@5: 93.7500 (90.6723)  time: 0.3467  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [1660/4579]  eta: 0:16:54  Lr: 0.001875  Loss: 0.1317  Acc@1: 62.5000 (61.7173)  Acc@5: 93.7500 (90.6908)  time: 0.3459  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1670/4579]  eta: 0:16:51  Lr: 0.001875  Loss: -0.2339  Acc@1: 62.5000 (61.7295)  Acc@5: 93.7500 (90.6905)  time: 0.3467  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1680/4579]  eta: 0:16:47  Lr: 0.001875  Loss: 0.1705  Acc@1: 62.5000 (61.7006)  Acc@5: 87.5000 (90.6938)  time: 0.3479  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [1690/4579]  eta: 0:16:44  Lr: 0.001875  Loss: -0.4332  Acc@1: 56.2500 (61.7090)  Acc@5: 87.5000 (90.6860)  time: 0.3488  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [1700/4579]  eta: 0:16:40  Lr: 0.001875  Loss: -0.5549  Acc@1: 56.2500 (61.6696)  Acc@5: 87.5000 (90.6709)  time: 0.3469  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [1710/4579]  eta: 0:16:37  Lr: 0.001875  Loss: -0.0281  Acc@1: 56.2500 (61.6708)  Acc@5: 87.5000 (90.6816)  time: 0.3458  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [1720/4579]  eta: 0:16:33  Lr: 0.001875  Loss: -0.0084  Acc@1: 56.2500 (61.6320)  Acc@5: 93.7500 (90.6849)  time: 0.3484  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [1730/4579]  eta: 0:16:30  Lr: 0.001875  Loss: -0.0909  Acc@1: 56.2500 (61.6371)  Acc@5: 93.7500 (90.6954)  time: 0.3495  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [1740/4579]  eta: 0:16:26  Lr: 0.001875  Loss: -0.7447  Acc@1: 62.5000 (61.6600)  Acc@5: 93.7500 (90.7022)  time: 0.3481  data: 0.0014  max mem: 2500
Train: Epoch[2/5]  [1750/4579]  eta: 0:16:23  Lr: 0.001875  Loss: -0.5168  Acc@1: 62.5000 (61.7040)  Acc@5: 93.7500 (90.6910)  time: 0.3470  data: 0.0011  max mem: 2500
Train: Epoch[2/5]  [1760/4579]  eta: 0:16:19  Lr: 0.001875  Loss: 0.1571  Acc@1: 68.7500 (61.7369)  Acc@5: 93.7500 (90.7120)  time: 0.3466  data: 0.0013  max mem: 2500
Train: Epoch[2/5]  [1770/4579]  eta: 0:16:16  Lr: 0.001875  Loss: 0.5268  Acc@1: 62.5000 (61.7236)  Acc@5: 93.7500 (90.6762)  time: 0.3468  data: 0.0012  max mem: 2500
Train: Epoch[2/5]  [1780/4579]  eta: 0:16:13  Lr: 0.001875  Loss: -0.5523  Acc@1: 62.5000 (61.7280)  Acc@5: 87.5000 (90.6829)  time: 0.3478  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1790/4579]  eta: 0:16:09  Lr: 0.001875  Loss: -0.2440  Acc@1: 62.5000 (61.7462)  Acc@5: 93.7500 (90.6896)  time: 0.3470  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1800/4579]  eta: 0:16:06  Lr: 0.001875  Loss: -0.2090  Acc@1: 62.5000 (61.7088)  Acc@5: 93.7500 (90.7031)  time: 0.3469  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1810/4579]  eta: 0:16:02  Lr: 0.001875  Loss: -0.0092  Acc@1: 56.2500 (61.6959)  Acc@5: 93.7500 (90.6819)  time: 0.3484  data: 0.0020  max mem: 2500
Train: Epoch[2/5]  [1820/4579]  eta: 0:15:59  Lr: 0.001875  Loss: -0.0356  Acc@1: 62.5000 (61.7209)  Acc@5: 93.7500 (90.6988)  time: 0.3482  data: 0.0026  max mem: 2500
Train: Epoch[2/5]  [1830/4579]  eta: 0:15:55  Lr: 0.001875  Loss: -0.0752  Acc@1: 62.5000 (61.7217)  Acc@5: 93.7500 (90.6950)  time: 0.3474  data: 0.0010  max mem: 2500
Train: Epoch[2/5]  [1840/4579]  eta: 0:15:52  Lr: 0.001875  Loss: 0.0011  Acc@1: 62.5000 (61.7124)  Acc@5: 93.7500 (90.7184)  time: 0.3466  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1850/4579]  eta: 0:15:48  Lr: 0.001875  Loss: 0.2442  Acc@1: 56.2500 (61.6660)  Acc@5: 93.7500 (90.7212)  time: 0.3462  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1860/4579]  eta: 0:15:45  Lr: 0.001875  Loss: 0.1731  Acc@1: 50.0000 (61.6302)  Acc@5: 93.7500 (90.7308)  time: 0.3461  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1870/4579]  eta: 0:15:41  Lr: 0.001875  Loss: 0.0636  Acc@1: 56.2500 (61.6114)  Acc@5: 93.7500 (90.7402)  time: 0.3473  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [1880/4579]  eta: 0:15:38  Lr: 0.001875  Loss: 0.1877  Acc@1: 56.2500 (61.6461)  Acc@5: 93.7500 (90.7596)  time: 0.3487  data: 0.0021  max mem: 2500
Train: Epoch[2/5]  [1890/4579]  eta: 0:15:34  Lr: 0.001875  Loss: 0.0003  Acc@1: 62.5000 (61.6506)  Acc@5: 93.7500 (90.7456)  time: 0.3483  data: 0.0020  max mem: 2500
Train: Epoch[2/5]  [1900/4579]  eta: 0:15:31  Lr: 0.001875  Loss: 0.7093  Acc@1: 56.2500 (61.6386)  Acc@5: 87.5000 (90.7549)  time: 0.3467  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1910/4579]  eta: 0:15:27  Lr: 0.001875  Loss: 0.2900  Acc@1: 56.2500 (61.6268)  Acc@5: 87.5000 (90.7313)  time: 0.3468  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [1920/4579]  eta: 0:15:24  Lr: 0.001875  Loss: -0.0213  Acc@1: 62.5000 (61.6508)  Acc@5: 87.5000 (90.7405)  time: 0.3478  data: 0.0011  max mem: 2500
Train: Epoch[2/5]  [1930/4579]  eta: 0:15:20  Lr: 0.001875  Loss: -0.2896  Acc@1: 62.5000 (61.6293)  Acc@5: 93.7500 (90.7367)  time: 0.3464  data: 0.0010  max mem: 2500
Train: Epoch[2/5]  [1940/4579]  eta: 0:15:17  Lr: 0.001875  Loss: 0.1506  Acc@1: 56.2500 (61.6274)  Acc@5: 87.5000 (90.7361)  time: 0.3456  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1950/4579]  eta: 0:15:13  Lr: 0.001875  Loss: -0.5582  Acc@1: 62.5000 (61.6319)  Acc@5: 93.7500 (90.7451)  time: 0.3460  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1960/4579]  eta: 0:15:10  Lr: 0.001875  Loss: -0.2185  Acc@1: 56.2500 (61.6363)  Acc@5: 93.7500 (90.7541)  time: 0.3472  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1970/4579]  eta: 0:15:06  Lr: 0.001875  Loss: 0.2249  Acc@1: 62.5000 (61.6438)  Acc@5: 93.7500 (90.7503)  time: 0.3470  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1980/4579]  eta: 0:15:03  Lr: 0.001875  Loss: 0.2171  Acc@1: 62.5000 (61.6482)  Acc@5: 87.5000 (90.7338)  time: 0.3474  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1990/4579]  eta: 0:14:59  Lr: 0.001875  Loss: -0.2030  Acc@1: 62.5000 (61.6587)  Acc@5: 87.5000 (90.7302)  time: 0.3480  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [2000/4579]  eta: 0:14:56  Lr: 0.001875  Loss: -0.0342  Acc@1: 62.5000 (61.6723)  Acc@5: 87.5000 (90.7078)  time: 0.3472  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [2010/4579]  eta: 0:14:52  Lr: 0.001875  Loss: 0.0006  Acc@1: 62.5000 (61.6702)  Acc@5: 93.7500 (90.7167)  time: 0.3479  data: 0.0011  max mem: 2500
Train: Epoch[2/5]  [2020/4579]  eta: 0:14:49  Lr: 0.001875  Loss: 0.0743  Acc@1: 62.5000 (61.6836)  Acc@5: 93.7500 (90.7255)  time: 0.3487  data: 0.0016  max mem: 2500
Train: Epoch[2/5]  [2030/4579]  eta: 0:14:45  Lr: 0.001875  Loss: 0.9295  Acc@1: 62.5000 (61.6599)  Acc@5: 93.7500 (90.7158)  time: 0.3471  data: 0.0010  max mem: 2500
Train: Epoch[2/5]  [2040/4579]  eta: 0:14:42  Lr: 0.001875  Loss: 0.3957  Acc@1: 56.2500 (61.6365)  Acc@5: 87.5000 (90.6878)  time: 0.3454  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [2050/4579]  eta: 0:14:38  Lr: 0.001875  Loss: -0.6816  Acc@1: 56.2500 (61.6254)  Acc@5: 87.5000 (90.6722)  time: 0.3460  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [2060/4579]  eta: 0:14:35  Lr: 0.001875  Loss: 0.3832  Acc@1: 62.5000 (61.6479)  Acc@5: 87.5000 (90.6690)  time: 0.3455  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [2070/4579]  eta: 0:14:32  Lr: 0.001875  Loss: -0.1837  Acc@1: 62.5000 (61.6399)  Acc@5: 93.7500 (90.6657)  time: 0.3465  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [2080/4579]  eta: 0:14:28  Lr: 0.001875  Loss: 0.4134  Acc@1: 62.5000 (61.6561)  Acc@5: 93.7500 (90.6806)  time: 0.3468  data: 0.0010  max mem: 2500
Train: Epoch[2/5]  [2090/4579]  eta: 0:14:25  Lr: 0.001875  Loss: -0.4154  Acc@1: 62.5000 (61.6780)  Acc@5: 93.7500 (90.6893)  time: 0.3468  data: 0.0009  max mem: 2500
Train: Epoch[2/5]  [2100/4579]  eta: 0:14:21  Lr: 0.001875  Loss: -0.5513  Acc@1: 62.5000 (61.6909)  Acc@5: 93.7500 (90.6890)  time: 0.3464  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2110/4579]  eta: 0:14:18  Lr: 0.001875  Loss: -0.4486  Acc@1: 62.5000 (61.7125)  Acc@5: 93.7500 (90.6975)  time: 0.3469  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [2120/4579]  eta: 0:14:14  Lr: 0.001875  Loss: -0.6920  Acc@1: 62.5000 (61.7545)  Acc@5: 93.7500 (90.7208)  time: 0.3492  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [2130/4579]  eta: 0:14:11  Lr: 0.001875  Loss: 0.4502  Acc@1: 62.5000 (61.7345)  Acc@5: 93.7500 (90.7145)  time: 0.3476  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [2140/4579]  eta: 0:14:07  Lr: 0.001875  Loss: 0.1999  Acc@1: 56.2500 (61.7060)  Acc@5: 87.5000 (90.7024)  time: 0.3453  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2150/4579]  eta: 0:14:04  Lr: 0.001875  Loss: -0.8977  Acc@1: 56.2500 (61.6864)  Acc@5: 87.5000 (90.6991)  time: 0.3461  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2160/4579]  eta: 0:14:00  Lr: 0.001875  Loss: 0.4383  Acc@1: 56.2500 (61.6960)  Acc@5: 93.7500 (90.7016)  time: 0.3470  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [2170/4579]  eta: 0:13:57  Lr: 0.001875  Loss: 0.4099  Acc@1: 56.2500 (61.6680)  Acc@5: 87.5000 (90.6984)  time: 0.3484  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [2180/4579]  eta: 0:13:53  Lr: 0.001875  Loss: -0.4176  Acc@1: 56.2500 (61.6546)  Acc@5: 87.5000 (90.6895)  time: 0.3476  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [2190/4579]  eta: 0:13:50  Lr: 0.001875  Loss: -0.2991  Acc@1: 62.5000 (61.6728)  Acc@5: 93.7500 (90.7063)  time: 0.3459  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2200/4579]  eta: 0:13:46  Lr: 0.001875  Loss: -0.2457  Acc@1: 62.5000 (61.6964)  Acc@5: 93.7500 (90.6974)  time: 0.3467  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [2210/4579]  eta: 0:13:43  Lr: 0.001875  Loss: 0.0350  Acc@1: 62.5000 (61.7113)  Acc@5: 93.7500 (90.6999)  time: 0.3488  data: 0.0011  max mem: 2500
Train: Epoch[2/5]  [2220/4579]  eta: 0:13:39  Lr: 0.001875  Loss: 0.4253  Acc@1: 62.5000 (61.6924)  Acc@5: 93.7500 (90.6799)  time: 0.3490  data: 0.0014  max mem: 2500
Train: Epoch[2/5]  [2230/4579]  eta: 0:13:36  Lr: 0.001875  Loss: -0.3216  Acc@1: 56.2500 (61.6932)  Acc@5: 93.7500 (90.6768)  time: 0.3478  data: 0.0010  max mem: 2500
Train: Epoch[2/5]  [2240/4579]  eta: 0:13:32  Lr: 0.001875  Loss: 0.5759  Acc@1: 56.2500 (61.6745)  Acc@5: 93.7500 (90.6738)  time: 0.3487  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [2250/4579]  eta: 0:13:29  Lr: 0.001875  Loss: -0.1715  Acc@1: 56.2500 (61.6587)  Acc@5: 87.5000 (90.6597)  time: 0.3473  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [2260/4579]  eta: 0:13:25  Lr: 0.001875  Loss: 0.0097  Acc@1: 62.5000 (61.6707)  Acc@5: 93.7500 (90.6596)  time: 0.3463  data: 0.0013  max mem: 2500
Train: Epoch[2/5]  [2270/4579]  eta: 0:13:22  Lr: 0.001875  Loss: -0.1487  Acc@1: 62.5000 (61.6441)  Acc@5: 93.7500 (90.6622)  time: 0.3459  data: 0.0012  max mem: 2500
Train: Epoch[2/5]  [2280/4579]  eta: 0:13:18  Lr: 0.001875  Loss: -0.2941  Acc@1: 56.2500 (61.6342)  Acc@5: 93.7500 (90.6647)  time: 0.3449  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [2290/4579]  eta: 0:13:15  Lr: 0.001875  Loss: -0.4138  Acc@1: 62.5000 (61.6434)  Acc@5: 93.7500 (90.6700)  time: 0.3464  data: 0.0012  max mem: 2500
Train: Epoch[2/5]  [2300/4579]  eta: 0:13:11  Lr: 0.001875  Loss: -0.6433  Acc@1: 62.5000 (61.6607)  Acc@5: 93.7500 (90.6725)  time: 0.3471  data: 0.0012  max mem: 2500
Train: Epoch[2/5]  [2310/4579]  eta: 0:13:08  Lr: 0.001875  Loss: -0.3376  Acc@1: 62.5000 (61.6833)  Acc@5: 93.7500 (90.6940)  time: 0.3484  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [2320/4579]  eta: 0:13:05  Lr: 0.001875  Loss: 0.0669  Acc@1: 62.5000 (61.6868)  Acc@5: 93.7500 (90.6937)  time: 0.3482  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [2330/4579]  eta: 0:13:01  Lr: 0.001875  Loss: -0.1524  Acc@1: 62.5000 (61.6795)  Acc@5: 87.5000 (90.6853)  time: 0.3468  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [2340/4579]  eta: 0:12:58  Lr: 0.001875  Loss: 0.6009  Acc@1: 62.5000 (61.6830)  Acc@5: 87.5000 (90.6931)  time: 0.3481  data: 0.0011  max mem: 2500
Train: Epoch[2/5]  [2350/4579]  eta: 0:12:54  Lr: 0.001875  Loss: -0.2223  Acc@1: 62.5000 (61.6759)  Acc@5: 93.7500 (90.6928)  time: 0.3481  data: 0.0011  max mem: 2500
Train: Epoch[2/5]  [2360/4579]  eta: 0:12:51  Lr: 0.001875  Loss: -0.7665  Acc@1: 56.2500 (61.6794)  Acc@5: 93.7500 (90.7243)  time: 0.3476  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [2370/4579]  eta: 0:12:47  Lr: 0.001875  Loss: 0.3116  Acc@1: 62.5000 (61.7118)  Acc@5: 93.7500 (90.7370)  time: 0.3462  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [2380/4579]  eta: 0:12:44  Lr: 0.001875  Loss: -0.0269  Acc@1: 62.5000 (61.6863)  Acc@5: 93.7500 (90.7339)  time: 0.3459  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [2390/4579]  eta: 0:12:40  Lr: 0.001875  Loss: -0.3470  Acc@1: 56.2500 (61.6609)  Acc@5: 87.5000 (90.7283)  time: 0.3474  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [2400/4579]  eta: 0:12:37  Lr: 0.001875  Loss: -0.1482  Acc@1: 56.2500 (61.6878)  Acc@5: 87.5000 (90.7330)  time: 0.3486  data: 0.0014  max mem: 2500
Train: Epoch[2/5]  [2410/4579]  eta: 0:12:33  Lr: 0.001875  Loss: 0.3412  Acc@1: 62.5000 (61.6627)  Acc@5: 93.7500 (90.7404)  time: 0.3492  data: 0.0015  max mem: 2500
Train: Epoch[2/5]  [2420/4579]  eta: 0:12:30  Lr: 0.001875  Loss: -0.3553  Acc@1: 62.5000 (61.6816)  Acc@5: 93.7500 (90.7476)  time: 0.3473  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [2430/4579]  eta: 0:12:26  Lr: 0.001875  Loss: -0.1370  Acc@1: 62.5000 (61.6799)  Acc@5: 93.7500 (90.7471)  time: 0.3470  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [2440/4579]  eta: 0:12:23  Lr: 0.001875  Loss: 0.3897  Acc@1: 62.5000 (61.6807)  Acc@5: 87.5000 (90.7261)  time: 0.3470  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [2450/4579]  eta: 0:12:19  Lr: 0.001875  Loss: 0.3817  Acc@1: 62.5000 (61.6968)  Acc@5: 87.5000 (90.7155)  time: 0.3469  data: 0.0009  max mem: 2500
Train: Epoch[2/5]  [2460/4579]  eta: 0:12:16  Lr: 0.001875  Loss: -0.5000  Acc@1: 62.5000 (61.7102)  Acc@5: 87.5000 (90.7228)  time: 0.3468  data: 0.0009  max mem: 2500
Train: Epoch[2/5]  [2470/4579]  eta: 0:12:12  Lr: 0.001875  Loss: 0.2490  Acc@1: 62.5000 (61.7260)  Acc@5: 93.7500 (90.7199)  time: 0.3476  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [2480/4579]  eta: 0:12:09  Lr: 0.001875  Loss: 0.0060  Acc@1: 68.7500 (61.7342)  Acc@5: 87.5000 (90.7245)  time: 0.3486  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [2490/4579]  eta: 0:12:05  Lr: 0.001875  Loss: -0.1369  Acc@1: 62.5000 (61.7448)  Acc@5: 93.7500 (90.7266)  time: 0.3480  data: 0.0010  max mem: 2500
Train: Epoch[2/5]  [2500/4579]  eta: 0:12:02  Lr: 0.001875  Loss: -0.0833  Acc@1: 62.5000 (61.7728)  Acc@5: 93.7500 (90.7337)  time: 0.3485  data: 0.0016  max mem: 2500
Train: Epoch[2/5]  [2510/4579]  eta: 0:11:58  Lr: 0.001875  Loss: 0.2120  Acc@1: 62.5000 (61.7832)  Acc@5: 93.7500 (90.7407)  time: 0.3472  data: 0.0013  max mem: 2500
Train: Epoch[2/5]  [2520/4579]  eta: 0:11:55  Lr: 0.001875  Loss: 0.2609  Acc@1: 62.5000 (61.7736)  Acc@5: 93.7500 (90.7477)  time: 0.3466  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [2530/4579]  eta: 0:11:52  Lr: 0.001875  Loss: -0.1879  Acc@1: 62.5000 (61.7641)  Acc@5: 93.7500 (90.7398)  time: 0.3475  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [2540/4579]  eta: 0:11:48  Lr: 0.001875  Loss: 0.1335  Acc@1: 56.2500 (61.7523)  Acc@5: 93.7500 (90.7345)  time: 0.3469  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [2550/4579]  eta: 0:11:45  Lr: 0.001875  Loss: 0.8505  Acc@1: 62.5000 (61.7429)  Acc@5: 87.5000 (90.7193)  time: 0.3466  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [2560/4579]  eta: 0:11:41  Lr: 0.001875  Loss: 0.0282  Acc@1: 62.5000 (61.7313)  Acc@5: 87.5000 (90.7263)  time: 0.3463  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [2570/4579]  eta: 0:11:38  Lr: 0.001875  Loss: 0.0139  Acc@1: 62.5000 (61.7172)  Acc@5: 93.7500 (90.7356)  time: 0.3467  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [2580/4579]  eta: 0:11:34  Lr: 0.001875  Loss: 0.1321  Acc@1: 62.5000 (61.7227)  Acc@5: 93.7500 (90.7570)  time: 0.3483  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [2590/4579]  eta: 0:11:31  Lr: 0.001875  Loss: 0.0496  Acc@1: 62.5000 (61.7329)  Acc@5: 93.7500 (90.7661)  time: 0.3475  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [2600/4579]  eta: 0:11:27  Lr: 0.001875  Loss: 0.0665  Acc@1: 62.5000 (61.7215)  Acc@5: 93.7500 (90.7608)  time: 0.3488  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [2610/4579]  eta: 0:11:24  Lr: 0.001875  Loss: 0.1174  Acc@1: 62.5000 (61.7388)  Acc@5: 93.7500 (90.7555)  time: 0.3484  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [2620/4579]  eta: 0:11:20  Lr: 0.001875  Loss: 0.1895  Acc@1: 62.5000 (61.7441)  Acc@5: 93.7500 (90.7645)  time: 0.3463  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [2630/4579]  eta: 0:11:17  Lr: 0.001875  Loss: 0.0305  Acc@1: 62.5000 (61.7351)  Acc@5: 93.7500 (90.7687)  time: 0.3465  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [2640/4579]  eta: 0:11:13  Lr: 0.001875  Loss: -0.1225  Acc@1: 56.2500 (61.7380)  Acc@5: 93.7500 (90.7611)  time: 0.3465  data: 0.0010  max mem: 2500
Train: Epoch[2/5]  [2650/4579]  eta: 0:11:10  Lr: 0.001875  Loss: -0.5241  Acc@1: 62.5000 (61.7526)  Acc@5: 87.5000 (90.7676)  time: 0.3480  data: 0.0010  max mem: 2500
Train: Epoch[2/5]  [2660/4579]  eta: 0:11:06  Lr: 0.001875  Loss: 0.2867  Acc@1: 62.5000 (61.7484)  Acc@5: 93.7500 (90.7694)  time: 0.3460  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2670/4579]  eta: 0:11:03  Lr: 0.001875  Loss: 0.2022  Acc@1: 62.5000 (61.7465)  Acc@5: 93.7500 (90.7689)  time: 0.3467  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [2680/4579]  eta: 0:10:59  Lr: 0.001875  Loss: 0.3345  Acc@1: 62.5000 (61.7517)  Acc@5: 87.5000 (90.7590)  time: 0.3475  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [2690/4579]  eta: 0:10:56  Lr: 0.001875  Loss: 0.2816  Acc@1: 56.2500 (61.7312)  Acc@5: 87.5000 (90.7632)  time: 0.3466  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [2700/4579]  eta: 0:10:52  Lr: 0.001875  Loss: -0.2569  Acc@1: 62.5000 (61.7480)  Acc@5: 87.5000 (90.7534)  time: 0.3483  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [2710/4579]  eta: 0:10:49  Lr: 0.001875  Loss: -0.0053  Acc@1: 62.5000 (61.7461)  Acc@5: 93.7500 (90.7599)  time: 0.3471  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [2720/4579]  eta: 0:10:45  Lr: 0.001875  Loss: -0.0511  Acc@1: 62.5000 (61.7604)  Acc@5: 93.7500 (90.7479)  time: 0.3471  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2730/4579]  eta: 0:10:42  Lr: 0.001875  Loss: 0.1811  Acc@1: 62.5000 (61.7585)  Acc@5: 93.7500 (90.7566)  time: 0.3487  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [2740/4579]  eta: 0:10:39  Lr: 0.001875  Loss: 0.2214  Acc@1: 62.5000 (61.7293)  Acc@5: 93.7500 (90.7401)  time: 0.3482  data: 0.0010  max mem: 2500
Train: Epoch[2/5]  [2750/4579]  eta: 0:10:35  Lr: 0.001875  Loss: 0.9340  Acc@1: 56.2500 (61.7071)  Acc@5: 87.5000 (90.7329)  time: 0.3491  data: 0.0011  max mem: 2500
Train: Epoch[2/5]  [2760/4579]  eta: 0:10:32  Lr: 0.001875  Loss: -0.8590  Acc@1: 62.5000 (61.7304)  Acc@5: 93.7500 (90.7438)  time: 0.3485  data: 0.0015  max mem: 2500
Train: Epoch[2/5]  [2770/4579]  eta: 0:10:28  Lr: 0.001875  Loss: 0.4596  Acc@1: 62.5000 (61.7106)  Acc@5: 87.5000 (90.7299)  time: 0.3460  data: 0.0017  max mem: 2500
Train: Epoch[2/5]  [2780/4579]  eta: 0:10:25  Lr: 0.001875  Loss: 0.1874  Acc@1: 62.5000 (61.7179)  Acc@5: 87.5000 (90.7273)  time: 0.3487  data: 0.0010  max mem: 2500
Train: Epoch[2/5]  [2790/4579]  eta: 0:10:21  Lr: 0.001875  Loss: 0.0053  Acc@1: 62.5000 (61.6983)  Acc@5: 87.5000 (90.7247)  time: 0.3491  data: 0.0009  max mem: 2500
Train: Epoch[2/5]  [2800/4579]  eta: 0:10:18  Lr: 0.001875  Loss: -0.0780  Acc@1: 56.2500 (61.7079)  Acc@5: 93.7500 (90.7288)  time: 0.3467  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [2810/4579]  eta: 0:10:14  Lr: 0.001875  Loss: -0.4783  Acc@1: 62.5000 (61.7196)  Acc@5: 93.7500 (90.7417)  time: 0.3461  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [2820/4579]  eta: 0:10:11  Lr: 0.001875  Loss: -0.0673  Acc@1: 62.5000 (61.7312)  Acc@5: 93.7500 (90.7391)  time: 0.3460  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [2830/4579]  eta: 0:10:07  Lr: 0.001875  Loss: -0.2283  Acc@1: 68.7500 (61.7383)  Acc@5: 93.7500 (90.7409)  time: 0.3468  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [2840/4579]  eta: 0:10:04  Lr: 0.001875  Loss: -0.1775  Acc@1: 62.5000 (61.7344)  Acc@5: 87.5000 (90.7339)  time: 0.3461  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [2850/4579]  eta: 0:10:00  Lr: 0.001875  Loss: -0.4456  Acc@1: 62.5000 (61.7437)  Acc@5: 93.7500 (90.7423)  time: 0.3466  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [2860/4579]  eta: 0:09:57  Lr: 0.001875  Loss: 0.5723  Acc@1: 62.5000 (61.7594)  Acc@5: 93.7500 (90.7375)  time: 0.3484  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [2870/4579]  eta: 0:09:53  Lr: 0.001875  Loss: 0.5891  Acc@1: 68.7500 (61.7773)  Acc@5: 93.7500 (90.7436)  time: 0.3482  data: 0.0014  max mem: 2500
Train: Epoch[2/5]  [2880/4579]  eta: 0:09:50  Lr: 0.001875  Loss: 0.3268  Acc@1: 62.5000 (61.7819)  Acc@5: 93.7500 (90.7562)  time: 0.3483  data: 0.0023  max mem: 2500
Train: Epoch[2/5]  [2890/4579]  eta: 0:09:46  Lr: 0.001875  Loss: -0.3333  Acc@1: 62.5000 (61.7801)  Acc@5: 93.7500 (90.7623)  time: 0.3512  data: 0.0018  max mem: 2500
Train: Epoch[2/5]  [2900/4579]  eta: 0:09:43  Lr: 0.001875  Loss: 0.0624  Acc@1: 62.5000 (61.7847)  Acc@5: 93.7500 (90.7618)  time: 0.3515  data: 0.0010  max mem: 2500
Train: Epoch[2/5]  [2910/4579]  eta: 0:09:40  Lr: 0.001875  Loss: -0.3734  Acc@1: 62.5000 (61.7765)  Acc@5: 93.7500 (90.7721)  time: 0.3481  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [2920/4579]  eta: 0:09:36  Lr: 0.001875  Loss: 0.1748  Acc@1: 62.5000 (61.7875)  Acc@5: 93.7500 (90.7673)  time: 0.3458  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [2930/4579]  eta: 0:09:33  Lr: 0.001875  Loss: 0.1407  Acc@1: 62.5000 (61.7835)  Acc@5: 87.5000 (90.7583)  time: 0.3481  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [2940/4579]  eta: 0:09:29  Lr: 0.001875  Loss: 0.4827  Acc@1: 56.2500 (61.7817)  Acc@5: 87.5000 (90.7578)  time: 0.3489  data: 0.0011  max mem: 2500
Train: Epoch[2/5]  [2950/4579]  eta: 0:09:26  Lr: 0.001875  Loss: 0.3605  Acc@1: 56.2500 (61.7714)  Acc@5: 87.5000 (90.7447)  time: 0.3471  data: 0.0009  max mem: 2500
Train: Epoch[2/5]  [2960/4579]  eta: 0:09:22  Lr: 0.001875  Loss: -0.4304  Acc@1: 62.5000 (61.7950)  Acc@5: 87.5000 (90.7421)  time: 0.3481  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [2970/4579]  eta: 0:09:19  Lr: 0.001875  Loss: -0.8390  Acc@1: 68.7500 (61.8100)  Acc@5: 87.5000 (90.7418)  time: 0.3492  data: 0.0014  max mem: 2500
Train: Epoch[2/5]  [2980/4579]  eta: 0:09:15  Lr: 0.001875  Loss: 0.0800  Acc@1: 68.7500 (61.8144)  Acc@5: 93.7500 (90.7518)  time: 0.3485  data: 0.0011  max mem: 2500
Train: Epoch[2/5]  [2990/4579]  eta: 0:09:12  Lr: 0.001875  Loss: -0.3595  Acc@1: 68.7500 (61.8230)  Acc@5: 93.7500 (90.7514)  time: 0.3472  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [3000/4579]  eta: 0:09:08  Lr: 0.001875  Loss: -0.3535  Acc@1: 68.7500 (61.8356)  Acc@5: 93.7500 (90.7510)  time: 0.3475  data: 0.0010  max mem: 2500
Train: Epoch[2/5]  [3010/4579]  eta: 0:09:05  Lr: 0.001875  Loss: -0.0154  Acc@1: 62.5000 (61.8233)  Acc@5: 93.7500 (90.7485)  time: 0.3486  data: 0.0011  max mem: 2500
Train: Epoch[2/5]  [3020/4579]  eta: 0:09:01  Lr: 0.001875  Loss: -0.2921  Acc@1: 62.5000 (61.8214)  Acc@5: 93.7500 (90.7584)  time: 0.3471  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [3030/4579]  eta: 0:08:58  Lr: 0.001875  Loss: -0.0588  Acc@1: 62.5000 (61.8340)  Acc@5: 93.7500 (90.7601)  time: 0.3472  data: 0.0012  max mem: 2500
Train: Epoch[2/5]  [3040/4579]  eta: 0:08:54  Lr: 0.001875  Loss: -0.3247  Acc@1: 68.7500 (61.8444)  Acc@5: 93.7500 (90.7617)  time: 0.3476  data: 0.0014  max mem: 2500
Train: Epoch[2/5]  [3050/4579]  eta: 0:08:51  Lr: 0.001875  Loss: 0.2515  Acc@1: 62.5000 (61.8363)  Acc@5: 87.5000 (90.7612)  time: 0.3465  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [3060/4579]  eta: 0:08:47  Lr: 0.001875  Loss: -0.3120  Acc@1: 62.5000 (61.8487)  Acc@5: 93.7500 (90.7649)  time: 0.3480  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [3070/4579]  eta: 0:08:44  Lr: 0.001875  Loss: -0.9049  Acc@1: 62.5000 (61.8569)  Acc@5: 93.7500 (90.7624)  time: 0.3477  data: 0.0012  max mem: 2500
Train: Epoch[2/5]  [3080/4579]  eta: 0:08:40  Lr: 0.001875  Loss: -0.2582  Acc@1: 62.5000 (61.8651)  Acc@5: 87.5000 (90.7619)  time: 0.3471  data: 0.0013  max mem: 2500
Train: Epoch[2/5]  [3090/4579]  eta: 0:08:37  Lr: 0.001875  Loss: -0.0469  Acc@1: 62.5000 (61.8610)  Acc@5: 93.7500 (90.7696)  time: 0.3469  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [3100/4579]  eta: 0:08:33  Lr: 0.001875  Loss: -0.3759  Acc@1: 62.5000 (61.8591)  Acc@5: 93.7500 (90.7691)  time: 0.3475  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [3110/4579]  eta: 0:08:30  Lr: 0.001875  Loss: 0.0345  Acc@1: 62.5000 (61.8511)  Acc@5: 93.7500 (90.7727)  time: 0.3488  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [3120/4579]  eta: 0:08:27  Lr: 0.001875  Loss: 0.1267  Acc@1: 62.5000 (61.8452)  Acc@5: 93.7500 (90.7622)  time: 0.3478  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [3130/4579]  eta: 0:08:23  Lr: 0.001875  Loss: -0.3918  Acc@1: 62.5000 (61.8512)  Acc@5: 87.5000 (90.7597)  time: 0.3466  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [3140/4579]  eta: 0:08:20  Lr: 0.001875  Loss: -0.1556  Acc@1: 68.7500 (61.8672)  Acc@5: 93.7500 (90.7693)  time: 0.3481  data: 0.0011  max mem: 2500
Train: Epoch[2/5]  [3150/4579]  eta: 0:08:16  Lr: 0.001875  Loss: 0.4836  Acc@1: 68.7500 (61.8653)  Acc@5: 93.7500 (90.7609)  time: 0.3469  data: 0.0010  max mem: 2500
Train: Epoch[2/5]  [3160/4579]  eta: 0:08:13  Lr: 0.001875  Loss: -0.8000  Acc@1: 62.5000 (61.8831)  Acc@5: 93.7500 (90.7683)  time: 0.3464  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [3170/4579]  eta: 0:08:09  Lr: 0.001875  Loss: -0.0675  Acc@1: 68.7500 (61.9008)  Acc@5: 93.7500 (90.7679)  time: 0.3486  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [3180/4579]  eta: 0:08:06  Lr: 0.001875  Loss: 0.4950  Acc@1: 68.7500 (61.9007)  Acc@5: 93.7500 (90.7773)  time: 0.3480  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [3190/4579]  eta: 0:08:02  Lr: 0.001875  Loss: -0.2141  Acc@1: 62.5000 (61.9085)  Acc@5: 93.7500 (90.7788)  time: 0.3483  data: 0.0016  max mem: 2500
Train: Epoch[2/5]  [3200/4579]  eta: 0:07:59  Lr: 0.001875  Loss: -0.1779  Acc@1: 68.7500 (61.9377)  Acc@5: 93.7500 (90.7841)  time: 0.3479  data: 0.0017  max mem: 2500
Train: Epoch[2/5]  [3210/4579]  eta: 0:07:55  Lr: 0.001875  Loss: -0.5051  Acc@1: 62.5000 (61.9355)  Acc@5: 93.7500 (90.7934)  time: 0.3477  data: 0.0014  max mem: 2500
Train: Epoch[2/5]  [3220/4579]  eta: 0:07:52  Lr: 0.001875  Loss: -0.3169  Acc@1: 62.5000 (61.9489)  Acc@5: 93.7500 (90.8045)  time: 0.3499  data: 0.0014  max mem: 2500
Train: Epoch[2/5]  [3230/4579]  eta: 0:07:48  Lr: 0.001875  Loss: 0.0387  Acc@1: 56.2500 (61.9313)  Acc@5: 93.7500 (90.8097)  time: 0.3490  data: 0.0010  max mem: 2500
Train: Epoch[2/5]  [3240/4579]  eta: 0:07:45  Lr: 0.001875  Loss: 0.2979  Acc@1: 62.5000 (61.9543)  Acc@5: 93.7500 (90.8092)  time: 0.3482  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [3250/4579]  eta: 0:07:41  Lr: 0.001875  Loss: 0.3110  Acc@1: 62.5000 (61.9502)  Acc@5: 87.5000 (90.8048)  time: 0.3486  data: 0.0011  max mem: 2500
Train: Epoch[2/5]  [3260/4579]  eta: 0:07:38  Lr: 0.001875  Loss: -0.0850  Acc@1: 56.2500 (61.9461)  Acc@5: 87.5000 (90.7927)  time: 0.3469  data: 0.0010  max mem: 2500
Train: Epoch[2/5]  [3270/4579]  eta: 0:07:34  Lr: 0.001875  Loss: 0.0914  Acc@1: 62.5000 (61.9421)  Acc@5: 87.5000 (90.7960)  time: 0.3466  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [3280/4579]  eta: 0:07:31  Lr: 0.001875  Loss: 0.1500  Acc@1: 62.5000 (61.9457)  Acc@5: 87.5000 (90.7860)  time: 0.3478  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [3290/4579]  eta: 0:07:27  Lr: 0.001875  Loss: 0.2430  Acc@1: 62.5000 (61.9474)  Acc@5: 87.5000 (90.7912)  time: 0.3467  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [3300/4579]  eta: 0:07:24  Lr: 0.001875  Loss: -0.0891  Acc@1: 62.5000 (61.9566)  Acc@5: 93.7500 (90.7982)  time: 0.3463  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [3310/4579]  eta: 0:07:21  Lr: 0.001875  Loss: 0.8729  Acc@1: 68.7500 (61.9564)  Acc@5: 93.7500 (90.7996)  time: 0.3464  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [3320/4579]  eta: 0:07:17  Lr: 0.001875  Loss: -0.6866  Acc@1: 68.7500 (61.9731)  Acc@5: 93.7500 (90.8028)  time: 0.3472  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [3330/4579]  eta: 0:07:14  Lr: 0.001875  Loss: -0.2454  Acc@1: 68.7500 (61.9746)  Acc@5: 93.7500 (90.8042)  time: 0.3481  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [3340/4579]  eta: 0:07:10  Lr: 0.001875  Loss: -0.3162  Acc@1: 62.5000 (61.9856)  Acc@5: 93.7500 (90.8074)  time: 0.3479  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3350/4579]  eta: 0:07:07  Lr: 0.001875  Loss: 0.3122  Acc@1: 62.5000 (61.9871)  Acc@5: 93.7500 (90.8236)  time: 0.3477  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [3360/4579]  eta: 0:07:03  Lr: 0.001875  Loss: 0.2870  Acc@1: 62.5000 (61.9830)  Acc@5: 93.7500 (90.8119)  time: 0.3464  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [3370/4579]  eta: 0:07:00  Lr: 0.001875  Loss: 0.4002  Acc@1: 62.5000 (61.9976)  Acc@5: 87.5000 (90.8113)  time: 0.3471  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [3380/4579]  eta: 0:06:56  Lr: 0.001875  Loss: -0.3753  Acc@1: 62.5000 (61.9935)  Acc@5: 87.5000 (90.7904)  time: 0.3478  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [3390/4579]  eta: 0:06:53  Lr: 0.001875  Loss: 0.4065  Acc@1: 56.2500 (61.9766)  Acc@5: 87.5000 (90.7771)  time: 0.3472  data: 0.0011  max mem: 2500
Train: Epoch[2/5]  [3400/4579]  eta: 0:06:49  Lr: 0.001875  Loss: 0.3831  Acc@1: 56.2500 (61.9781)  Acc@5: 87.5000 (90.7729)  time: 0.3474  data: 0.0011  max mem: 2500
Train: Epoch[2/5]  [3410/4579]  eta: 0:06:46  Lr: 0.001875  Loss: -0.2689  Acc@1: 62.5000 (61.9723)  Acc@5: 87.5000 (90.7670)  time: 0.3485  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [3420/4579]  eta: 0:06:42  Lr: 0.001875  Loss: -0.1476  Acc@1: 62.5000 (61.9720)  Acc@5: 93.7500 (90.7739)  time: 0.3525  data: 0.0034  max mem: 2500
Train: Epoch[2/5]  [3430/4579]  eta: 0:06:39  Lr: 0.001875  Loss: 0.1004  Acc@1: 62.5000 (61.9681)  Acc@5: 93.7500 (90.7716)  time: 0.3513  data: 0.0033  max mem: 2500
Train: Epoch[2/5]  [3440/4579]  eta: 0:06:35  Lr: 0.001875  Loss: -0.0444  Acc@1: 62.5000 (61.9751)  Acc@5: 87.5000 (90.7639)  time: 0.3462  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3450/4579]  eta: 0:06:32  Lr: 0.001875  Loss: -0.1172  Acc@1: 62.5000 (61.9947)  Acc@5: 87.5000 (90.7654)  time: 0.3477  data: 0.0021  max mem: 2500
Train: Epoch[2/5]  [3460/4579]  eta: 0:06:28  Lr: 0.001875  Loss: -0.0944  Acc@1: 62.5000 (61.9908)  Acc@5: 87.5000 (90.7631)  time: 0.3488  data: 0.0022  max mem: 2500
Train: Epoch[2/5]  [3470/4579]  eta: 0:06:25  Lr: 0.001875  Loss: 0.6840  Acc@1: 56.2500 (61.9688)  Acc@5: 87.5000 (90.7519)  time: 0.3479  data: 0.0012  max mem: 2500
Train: Epoch[2/5]  [3480/4579]  eta: 0:06:21  Lr: 0.001875  Loss: 0.2023  Acc@1: 56.2500 (61.9488)  Acc@5: 87.5000 (90.7426)  time: 0.3484  data: 0.0016  max mem: 2500
Train: Epoch[2/5]  [3490/4579]  eta: 0:06:18  Lr: 0.001875  Loss: -0.1624  Acc@1: 62.5000 (61.9647)  Acc@5: 87.5000 (90.7458)  time: 0.3484  data: 0.0011  max mem: 2500
Train: Epoch[2/5]  [3500/4579]  eta: 0:06:15  Lr: 0.001875  Loss: 0.3388  Acc@1: 62.5000 (61.9412)  Acc@5: 93.7500 (90.7312)  time: 0.3474  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [3510/4579]  eta: 0:06:11  Lr: 0.001875  Loss: 0.3357  Acc@1: 56.2500 (61.9375)  Acc@5: 87.5000 (90.7309)  time: 0.3473  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [3520/4579]  eta: 0:06:08  Lr: 0.001875  Loss: 0.4651  Acc@1: 56.2500 (61.9373)  Acc@5: 87.5000 (90.7324)  time: 0.3490  data: 0.0018  max mem: 2500
Train: Epoch[2/5]  [3530/4579]  eta: 0:06:04  Lr: 0.001875  Loss: -0.2468  Acc@1: 56.2500 (61.9460)  Acc@5: 93.7500 (90.7339)  time: 0.3474  data: 0.0018  max mem: 2500
Train: Epoch[2/5]  [3540/4579]  eta: 0:06:01  Lr: 0.001875  Loss: 0.0905  Acc@1: 68.7500 (61.9705)  Acc@5: 93.7500 (90.7424)  time: 0.3464  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [3550/4579]  eta: 0:05:57  Lr: 0.001875  Loss: -0.3025  Acc@1: 62.5000 (61.9579)  Acc@5: 93.7500 (90.7385)  time: 0.3466  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [3560/4579]  eta: 0:05:54  Lr: 0.001875  Loss: 0.1445  Acc@1: 56.2500 (61.9647)  Acc@5: 87.5000 (90.7435)  time: 0.3469  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [3570/4579]  eta: 0:05:50  Lr: 0.001875  Loss: -0.0893  Acc@1: 62.5000 (61.9662)  Acc@5: 87.5000 (90.7344)  time: 0.3474  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [3580/4579]  eta: 0:05:47  Lr: 0.001875  Loss: 0.1498  Acc@1: 62.5000 (61.9781)  Acc@5: 87.5000 (90.7358)  time: 0.3469  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [3590/4579]  eta: 0:05:43  Lr: 0.001875  Loss: 0.3388  Acc@1: 62.5000 (61.9692)  Acc@5: 87.5000 (90.7390)  time: 0.3483  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [3600/4579]  eta: 0:05:40  Lr: 0.001875  Loss: 0.6952  Acc@1: 50.0000 (61.9533)  Acc@5: 87.5000 (90.7317)  time: 0.3484  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [3610/4579]  eta: 0:05:36  Lr: 0.001875  Loss: -0.0640  Acc@1: 68.7500 (61.9652)  Acc@5: 87.5000 (90.7280)  time: 0.3483  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [3620/4579]  eta: 0:05:33  Lr: 0.001875  Loss: 0.0327  Acc@1: 68.7500 (61.9632)  Acc@5: 93.7500 (90.7294)  time: 0.3480  data: 0.0009  max mem: 2500
Train: Epoch[2/5]  [3630/4579]  eta: 0:05:29  Lr: 0.001875  Loss: 0.0888  Acc@1: 62.5000 (61.9630)  Acc@5: 93.7500 (90.7309)  time: 0.3480  data: 0.0009  max mem: 2500
Train: Epoch[2/5]  [3640/4579]  eta: 0:05:26  Lr: 0.001875  Loss: -0.2216  Acc@1: 68.7500 (61.9782)  Acc@5: 93.7500 (90.7323)  time: 0.3472  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [3650/4579]  eta: 0:05:22  Lr: 0.001875  Loss: -0.0066  Acc@1: 68.7500 (61.9950)  Acc@5: 93.7500 (90.7406)  time: 0.3464  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [3660/4579]  eta: 0:05:19  Lr: 0.001875  Loss: 0.7447  Acc@1: 62.5000 (61.9759)  Acc@5: 93.7500 (90.7300)  time: 0.3471  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [3670/4579]  eta: 0:05:15  Lr: 0.001875  Loss: -0.1176  Acc@1: 56.2500 (61.9688)  Acc@5: 87.5000 (90.7212)  time: 0.3472  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [3680/4579]  eta: 0:05:12  Lr: 0.001875  Loss: -0.0937  Acc@1: 62.5000 (61.9703)  Acc@5: 87.5000 (90.7277)  time: 0.3482  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [3690/4579]  eta: 0:05:08  Lr: 0.001875  Loss: -0.2162  Acc@1: 68.7500 (61.9802)  Acc@5: 93.7500 (90.7325)  time: 0.3475  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3700/4579]  eta: 0:05:05  Lr: 0.001875  Loss: -0.4079  Acc@1: 62.5000 (61.9782)  Acc@5: 93.7500 (90.7305)  time: 0.3460  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [3710/4579]  eta: 0:05:02  Lr: 0.001875  Loss: -0.0439  Acc@1: 68.7500 (61.9897)  Acc@5: 93.7500 (90.7353)  time: 0.3478  data: 0.0014  max mem: 2500
Train: Epoch[2/5]  [3720/4579]  eta: 0:04:58  Lr: 0.001875  Loss: 0.0640  Acc@1: 68.7500 (61.9911)  Acc@5: 93.7500 (90.7350)  time: 0.3485  data: 0.0015  max mem: 2500
Train: Epoch[2/5]  [3730/4579]  eta: 0:04:55  Lr: 0.001875  Loss: 0.0093  Acc@1: 62.5000 (61.9924)  Acc@5: 93.7500 (90.7364)  time: 0.3468  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [3740/4579]  eta: 0:04:51  Lr: 0.001875  Loss: -0.2584  Acc@1: 62.5000 (62.0038)  Acc@5: 87.5000 (90.7328)  time: 0.3469  data: 0.0013  max mem: 2500
Train: Epoch[2/5]  [3750/4579]  eta: 0:04:48  Lr: 0.001875  Loss: -0.0334  Acc@1: 62.5000 (62.0201)  Acc@5: 93.7500 (90.7408)  time: 0.3471  data: 0.0013  max mem: 2500
Train: Epoch[2/5]  [3760/4579]  eta: 0:04:44  Lr: 0.001875  Loss: 0.3550  Acc@1: 62.5000 (62.0281)  Acc@5: 93.7500 (90.7471)  time: 0.3470  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [3770/4579]  eta: 0:04:41  Lr: 0.001875  Loss: -0.3331  Acc@1: 62.5000 (62.0276)  Acc@5: 93.7500 (90.7568)  time: 0.3461  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [3780/4579]  eta: 0:04:37  Lr: 0.001875  Loss: -0.1131  Acc@1: 56.2500 (62.0206)  Acc@5: 93.7500 (90.7597)  time: 0.3473  data: 0.0015  max mem: 2500
Train: Epoch[2/5]  [3790/4579]  eta: 0:04:34  Lr: 0.001875  Loss: -0.0322  Acc@1: 62.5000 (62.0268)  Acc@5: 93.7500 (90.7693)  time: 0.3491  data: 0.0023  max mem: 2500
Train: Epoch[2/5]  [3800/4579]  eta: 0:04:30  Lr: 0.001875  Loss: 0.0089  Acc@1: 62.5000 (62.0199)  Acc@5: 93.7500 (90.7787)  time: 0.3469  data: 0.0013  max mem: 2500
Train: Epoch[2/5]  [3810/4579]  eta: 0:04:27  Lr: 0.001875  Loss: -0.7090  Acc@1: 56.2500 (62.0228)  Acc@5: 93.7500 (90.7718)  time: 0.3481  data: 0.0012  max mem: 2500
Train: Epoch[2/5]  [3820/4579]  eta: 0:04:23  Lr: 0.001875  Loss: -0.0175  Acc@1: 62.5000 (62.0289)  Acc@5: 87.5000 (90.7714)  time: 0.3506  data: 0.0011  max mem: 2500
Train: Epoch[2/5]  [3830/4579]  eta: 0:04:20  Lr: 0.001875  Loss: 0.0554  Acc@1: 62.5000 (62.0187)  Acc@5: 87.5000 (90.7629)  time: 0.3503  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [3840/4579]  eta: 0:04:16  Lr: 0.001875  Loss: 0.0863  Acc@1: 62.5000 (62.0135)  Acc@5: 87.5000 (90.7592)  time: 0.3485  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [3850/4579]  eta: 0:04:13  Lr: 0.001875  Loss: 0.1911  Acc@1: 62.5000 (62.0229)  Acc@5: 93.7500 (90.7605)  time: 0.3463  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3860/4579]  eta: 0:04:09  Lr: 0.001875  Loss: 0.4558  Acc@1: 68.7500 (62.0387)  Acc@5: 87.5000 (90.7456)  time: 0.3482  data: 0.0010  max mem: 2500
Train: Epoch[2/5]  [3870/4579]  eta: 0:04:06  Lr: 0.001875  Loss: 0.1240  Acc@1: 68.7500 (62.0592)  Acc@5: 87.5000 (90.7566)  time: 0.3492  data: 0.0011  max mem: 2500
Train: Epoch[2/5]  [3880/4579]  eta: 0:04:02  Lr: 0.001875  Loss: 0.2650  Acc@1: 75.0000 (62.0829)  Acc@5: 93.7500 (90.7659)  time: 0.3461  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [3890/4579]  eta: 0:03:59  Lr: 0.001875  Loss: -0.0768  Acc@1: 62.5000 (62.0856)  Acc@5: 93.7500 (90.7623)  time: 0.3468  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [3900/4579]  eta: 0:03:55  Lr: 0.001875  Loss: -0.2084  Acc@1: 62.5000 (62.0802)  Acc@5: 87.5000 (90.7652)  time: 0.3473  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [3910/4579]  eta: 0:03:52  Lr: 0.001875  Loss: 0.1377  Acc@1: 62.5000 (62.0829)  Acc@5: 87.5000 (90.7600)  time: 0.3464  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [3920/4579]  eta: 0:03:49  Lr: 0.001875  Loss: 0.0284  Acc@1: 62.5000 (62.0888)  Acc@5: 87.5000 (90.7581)  time: 0.3475  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [3930/4579]  eta: 0:03:45  Lr: 0.001875  Loss: -0.0683  Acc@1: 62.5000 (62.0803)  Acc@5: 87.5000 (90.7578)  time: 0.3476  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [3940/4579]  eta: 0:03:42  Lr: 0.001875  Loss: -0.4046  Acc@1: 62.5000 (62.0972)  Acc@5: 93.7500 (90.7622)  time: 0.3466  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [3950/4579]  eta: 0:03:38  Lr: 0.001875  Loss: -0.1788  Acc@1: 62.5000 (62.0998)  Acc@5: 93.7500 (90.7587)  time: 0.3461  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [3960/4579]  eta: 0:03:35  Lr: 0.001875  Loss: 0.1562  Acc@1: 62.5000 (62.0961)  Acc@5: 87.5000 (90.7568)  time: 0.3464  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [3970/4579]  eta: 0:03:31  Lr: 0.001875  Loss: -0.4962  Acc@1: 62.5000 (62.1081)  Acc@5: 93.7500 (90.7643)  time: 0.3486  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [3980/4579]  eta: 0:03:28  Lr: 0.001875  Loss: -0.2332  Acc@1: 62.5000 (62.0997)  Acc@5: 93.7500 (90.7655)  time: 0.3493  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [3990/4579]  eta: 0:03:24  Lr: 0.001875  Loss: 0.0639  Acc@1: 56.2500 (62.0897)  Acc@5: 87.5000 (90.7620)  time: 0.3481  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [4000/4579]  eta: 0:03:21  Lr: 0.001875  Loss: -0.6081  Acc@1: 62.5000 (62.0985)  Acc@5: 93.7500 (90.7695)  time: 0.3494  data: 0.0019  max mem: 2500
Train: Epoch[2/5]  [4010/4579]  eta: 0:03:17  Lr: 0.001875  Loss: 0.1837  Acc@1: 62.5000 (62.1027)  Acc@5: 93.7500 (90.7691)  time: 0.3483  data: 0.0019  max mem: 2500
Train: Epoch[2/5]  [4020/4579]  eta: 0:03:14  Lr: 0.001875  Loss: 0.3853  Acc@1: 62.5000 (62.1005)  Acc@5: 93.7500 (90.7765)  time: 0.3468  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [4030/4579]  eta: 0:03:10  Lr: 0.001875  Loss: -0.0489  Acc@1: 68.7500 (62.1155)  Acc@5: 93.7500 (90.7808)  time: 0.3463  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [4040/4579]  eta: 0:03:07  Lr: 0.001875  Loss: -0.2456  Acc@1: 68.7500 (62.1195)  Acc@5: 93.7500 (90.7820)  time: 0.3463  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [4050/4579]  eta: 0:03:03  Lr: 0.001875  Loss: -0.2515  Acc@1: 62.5000 (62.1297)  Acc@5: 93.7500 (90.7831)  time: 0.3484  data: 0.0012  max mem: 2500
Train: Epoch[2/5]  [4060/4579]  eta: 0:03:00  Lr: 0.001875  Loss: 0.2965  Acc@1: 62.5000 (62.1337)  Acc@5: 93.7500 (90.7843)  time: 0.3482  data: 0.0012  max mem: 2500
Train: Epoch[2/5]  [4070/4579]  eta: 0:02:56  Lr: 0.001875  Loss: -0.0469  Acc@1: 62.5000 (62.1300)  Acc@5: 93.7500 (90.7900)  time: 0.3477  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [4080/4579]  eta: 0:02:53  Lr: 0.001875  Loss: -0.1640  Acc@1: 62.5000 (62.1340)  Acc@5: 93.7500 (90.7912)  time: 0.3482  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [4090/4579]  eta: 0:02:49  Lr: 0.001875  Loss: 0.1265  Acc@1: 68.7500 (62.1410)  Acc@5: 93.7500 (90.7938)  time: 0.3483  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [4100/4579]  eta: 0:02:46  Lr: 0.001875  Loss: 0.2182  Acc@1: 62.5000 (62.1358)  Acc@5: 93.7500 (90.7980)  time: 0.3495  data: 0.0020  max mem: 2500
Train: Epoch[2/5]  [4110/4579]  eta: 0:02:43  Lr: 0.001875  Loss: 0.0814  Acc@1: 62.5000 (62.1412)  Acc@5: 93.7500 (90.8021)  time: 0.3491  data: 0.0024  max mem: 2500
Train: Epoch[2/5]  [4120/4579]  eta: 0:02:39  Lr: 0.001875  Loss: -0.6473  Acc@1: 62.5000 (62.1436)  Acc@5: 93.7500 (90.8062)  time: 0.3466  data: 0.0009  max mem: 2500
Train: Epoch[2/5]  [4130/4579]  eta: 0:02:36  Lr: 0.001875  Loss: 0.3411  Acc@1: 56.2500 (62.1293)  Acc@5: 93.7500 (90.8043)  time: 0.3457  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [4140/4579]  eta: 0:02:32  Lr: 0.001875  Loss: -0.0037  Acc@1: 62.5000 (62.1408)  Acc@5: 93.7500 (90.8084)  time: 0.3468  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [4150/4579]  eta: 0:02:29  Lr: 0.001875  Loss: -0.0770  Acc@1: 62.5000 (62.1281)  Acc@5: 93.7500 (90.8094)  time: 0.3477  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [4160/4579]  eta: 0:02:25  Lr: 0.001875  Loss: -0.5154  Acc@1: 62.5000 (62.1470)  Acc@5: 93.7500 (90.8120)  time: 0.3471  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [4170/4579]  eta: 0:02:22  Lr: 0.001875  Loss: -0.0322  Acc@1: 68.7500 (62.1569)  Acc@5: 93.7500 (90.8146)  time: 0.3474  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [4180/4579]  eta: 0:02:18  Lr: 0.001875  Loss: -0.1350  Acc@1: 68.7500 (62.1681)  Acc@5: 93.7500 (90.8141)  time: 0.3482  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [4190/4579]  eta: 0:02:15  Lr: 0.001875  Loss: 0.0419  Acc@1: 62.5000 (62.1704)  Acc@5: 87.5000 (90.8151)  time: 0.3497  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [4200/4579]  eta: 0:02:11  Lr: 0.001875  Loss: 0.1796  Acc@1: 62.5000 (62.1653)  Acc@5: 87.5000 (90.8132)  time: 0.3510  data: 0.0013  max mem: 2500
Train: Epoch[2/5]  [4210/4579]  eta: 0:02:08  Lr: 0.001875  Loss: 0.1285  Acc@1: 56.2500 (62.1453)  Acc@5: 87.5000 (90.8038)  time: 0.3479  data: 0.0012  max mem: 2500
Train: Epoch[2/5]  [4220/4579]  eta: 0:02:04  Lr: 0.001875  Loss: -0.1304  Acc@1: 56.2500 (62.1520)  Acc@5: 87.5000 (90.8064)  time: 0.3462  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [4230/4579]  eta: 0:02:01  Lr: 0.001875  Loss: -0.2507  Acc@1: 68.7500 (62.1706)  Acc@5: 93.7500 (90.8104)  time: 0.3461  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [4240/4579]  eta: 0:01:57  Lr: 0.001875  Loss: -0.0815  Acc@1: 68.7500 (62.1699)  Acc@5: 93.7500 (90.8041)  time: 0.3469  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [4250/4579]  eta: 0:01:54  Lr: 0.001875  Loss: 0.4785  Acc@1: 62.5000 (62.1589)  Acc@5: 87.5000 (90.8007)  time: 0.3471  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [4260/4579]  eta: 0:01:50  Lr: 0.001875  Loss: 0.0624  Acc@1: 56.2500 (62.1465)  Acc@5: 87.5000 (90.7959)  time: 0.3462  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [4270/4579]  eta: 0:01:47  Lr: 0.001875  Loss: 0.2546  Acc@1: 56.2500 (62.1473)  Acc@5: 93.7500 (90.7999)  time: 0.3477  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [4280/4579]  eta: 0:01:43  Lr: 0.001875  Loss: -0.2676  Acc@1: 56.2500 (62.1365)  Acc@5: 93.7500 (90.7936)  time: 0.3472  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [4290/4579]  eta: 0:01:40  Lr: 0.001875  Loss: -0.2908  Acc@1: 56.2500 (62.1359)  Acc@5: 87.5000 (90.7947)  time: 0.3488  data: 0.0017  max mem: 2500
Train: Epoch[2/5]  [4300/4579]  eta: 0:01:36  Lr: 0.001875  Loss: 0.1155  Acc@1: 62.5000 (62.1353)  Acc@5: 93.7500 (90.7914)  time: 0.3506  data: 0.0019  max mem: 2500
Train: Epoch[2/5]  [4310/4579]  eta: 0:01:33  Lr: 0.001875  Loss: -0.3439  Acc@1: 56.2500 (62.1216)  Acc@5: 93.7500 (90.7895)  time: 0.3497  data: 0.0010  max mem: 2500
Train: Epoch[2/5]  [4320/4579]  eta: 0:01:30  Lr: 0.001875  Loss: -0.3716  Acc@1: 56.2500 (62.1239)  Acc@5: 93.7500 (90.7863)  time: 0.3481  data: 0.0012  max mem: 2500
Train: Epoch[2/5]  [4330/4579]  eta: 0:01:26  Lr: 0.001875  Loss: 0.0409  Acc@1: 62.5000 (62.1291)  Acc@5: 87.5000 (90.7830)  time: 0.3478  data: 0.0011  max mem: 2500
Train: Epoch[2/5]  [4340/4579]  eta: 0:01:23  Lr: 0.001875  Loss: -0.3347  Acc@1: 62.5000 (62.1429)  Acc@5: 87.5000 (90.7841)  time: 0.3488  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [4350/4579]  eta: 0:01:19  Lr: 0.001875  Loss: 0.2065  Acc@1: 68.7500 (62.1495)  Acc@5: 93.7500 (90.7823)  time: 0.3485  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [4360/4579]  eta: 0:01:16  Lr: 0.001875  Loss: 0.2150  Acc@1: 62.5000 (62.1403)  Acc@5: 93.7500 (90.7776)  time: 0.3471  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [4370/4579]  eta: 0:01:12  Lr: 0.001875  Loss: 0.2726  Acc@1: 62.5000 (62.1540)  Acc@5: 93.7500 (90.7844)  time: 0.3456  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [4380/4579]  eta: 0:01:09  Lr: 0.001875  Loss: -0.2226  Acc@1: 68.7500 (62.1533)  Acc@5: 93.7500 (90.7883)  time: 0.3467  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [4390/4579]  eta: 0:01:05  Lr: 0.001875  Loss: 0.4078  Acc@1: 62.5000 (62.1555)  Acc@5: 93.7500 (90.7866)  time: 0.3476  data: 0.0013  max mem: 2500
Train: Epoch[2/5]  [4400/4579]  eta: 0:01:02  Lr: 0.001875  Loss: -0.3151  Acc@1: 68.7500 (62.1563)  Acc@5: 93.7500 (90.7919)  time: 0.3481  data: 0.0013  max mem: 2500
Train: Epoch[2/5]  [4410/4579]  eta: 0:00:58  Lr: 0.001875  Loss: -0.1063  Acc@1: 62.5000 (62.1585)  Acc@5: 93.7500 (90.7915)  time: 0.3472  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [4420/4579]  eta: 0:00:55  Lr: 0.001875  Loss: -0.4811  Acc@1: 62.5000 (62.1607)  Acc@5: 93.7500 (90.8052)  time: 0.3450  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [4430/4579]  eta: 0:00:51  Lr: 0.001875  Loss: 0.0157  Acc@1: 62.5000 (62.1657)  Acc@5: 93.7500 (90.8077)  time: 0.3453  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [4440/4579]  eta: 0:00:48  Lr: 0.001875  Loss: -0.6221  Acc@1: 62.5000 (62.1749)  Acc@5: 93.7500 (90.8073)  time: 0.3464  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [4450/4579]  eta: 0:00:44  Lr: 0.001875  Loss: -0.0268  Acc@1: 62.5000 (62.1798)  Acc@5: 87.5000 (90.8054)  time: 0.3465  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [4460/4579]  eta: 0:00:41  Lr: 0.001875  Loss: 0.1739  Acc@1: 68.7500 (62.2002)  Acc@5: 93.7500 (90.8092)  time: 0.3468  data: 0.0012  max mem: 2500
Train: Epoch[2/5]  [4470/4579]  eta: 0:00:37  Lr: 0.001875  Loss: -0.5472  Acc@1: 75.0000 (62.2134)  Acc@5: 93.7500 (90.8172)  time: 0.3471  data: 0.0019  max mem: 2500
Train: Epoch[2/5]  [4480/4579]  eta: 0:00:34  Lr: 0.001875  Loss: -0.0312  Acc@1: 62.5000 (62.2224)  Acc@5: 93.7500 (90.8196)  time: 0.3485  data: 0.0015  max mem: 2500
Train: Epoch[2/5]  [4490/4579]  eta: 0:00:30  Lr: 0.001875  Loss: -0.2017  Acc@1: 62.5000 (62.2314)  Acc@5: 87.5000 (90.8136)  time: 0.3482  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [4500/4579]  eta: 0:00:27  Lr: 0.001875  Loss: -0.1017  Acc@1: 62.5000 (62.2264)  Acc@5: 87.5000 (90.8048)  time: 0.3475  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [4510/4579]  eta: 0:00:23  Lr: 0.001875  Loss: 0.0915  Acc@1: 62.5000 (62.2381)  Acc@5: 93.7500 (90.8100)  time: 0.3474  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [4520/4579]  eta: 0:00:20  Lr: 0.001875  Loss: 0.0762  Acc@1: 62.5000 (62.2415)  Acc@5: 93.7500 (90.8082)  time: 0.3464  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [4530/4579]  eta: 0:00:17  Lr: 0.001875  Loss: -0.0030  Acc@1: 62.5000 (62.2476)  Acc@5: 87.5000 (90.7995)  time: 0.3474  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [4540/4579]  eta: 0:00:13  Lr: 0.001875  Loss: 0.2708  Acc@1: 62.5000 (62.2481)  Acc@5: 87.5000 (90.8019)  time: 0.3471  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [4550/4579]  eta: 0:00:10  Lr: 0.001875  Loss: -0.2250  Acc@1: 62.5000 (62.2501)  Acc@5: 93.7500 (90.8042)  time: 0.3466  data: 0.0011  max mem: 2500
Train: Epoch[2/5]  [4560/4579]  eta: 0:00:06  Lr: 0.001875  Loss: 0.7866  Acc@1: 62.5000 (62.2479)  Acc@5: 87.5000 (90.7970)  time: 0.3461  data: 0.0011  max mem: 2500
Train: Epoch[2/5]  [4570/4579]  eta: 0:00:03  Lr: 0.001875  Loss: 0.0625  Acc@1: 62.5000 (62.2498)  Acc@5: 87.5000 (90.8021)  time: 0.3460  data: 0.0009  max mem: 2500
Train: Epoch[2/5]  [4578/4579]  eta: 0:00:00  Lr: 0.001875  Loss: -0.0271  Acc@1: 62.5000 (62.2589)  Acc@5: 93.7500 (90.8077)  time: 0.3391  data: 0.0009  max mem: 2500
Train: Epoch[2/5] Total time: 0:26:32 (0.3477 s / it)
{0: {0: 146514, 1: 0, 2: 0, 3: 0, 4: 0}, 1: {0: 146514, 1: 0, 2: 0, 3: 0, 4: 0}, 2: {0: 146514, 1: 0, 2: 0, 3: 0, 4: 0}, 3: {0: 146514, 1: 0, 2: 0, 3: 0, 4: 0}, 4: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 5: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 6: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 7: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 8: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 9: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 10: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 11: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 12: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 13: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 14: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 15: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 16: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 17: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 18: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 19: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}}
Averaged stats: Lr: 0.001875  Loss: -0.0271  Acc@1: 62.5000 (62.2589)  Acc@5: 93.7500 (90.8077)
Train: Epoch[3/5]  [   0/4579]  eta: 1:09:55  Lr: 0.001875  Loss: 0.4726  Acc@1: 50.0000 (50.0000)  Acc@5: 81.2500 (81.2500)  time: 0.9162  data: 0.5671  max mem: 2500
Train: Epoch[3/5]  [  10/4579]  eta: 0:30:24  Lr: 0.001875  Loss: -0.1944  Acc@1: 62.5000 (67.6136)  Acc@5: 93.7500 (94.3182)  time: 0.3993  data: 0.0521  max mem: 2500
Train: Epoch[3/5]  [  20/4579]  eta: 0:28:23  Lr: 0.001875  Loss: 0.1791  Acc@1: 62.5000 (66.0714)  Acc@5: 87.5000 (88.9881)  time: 0.3465  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [  30/4579]  eta: 0:27:42  Lr: 0.001875  Loss: 0.4002  Acc@1: 68.7500 (67.1371)  Acc@5: 87.5000 (89.1129)  time: 0.3467  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [  40/4579]  eta: 0:27:20  Lr: 0.001875  Loss: -0.7408  Acc@1: 68.7500 (66.4634)  Acc@5: 87.5000 (89.3293)  time: 0.3484  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [  50/4579]  eta: 0:27:02  Lr: 0.001875  Loss: 0.2495  Acc@1: 56.2500 (64.2157)  Acc@5: 87.5000 (88.8480)  time: 0.3473  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [  60/4579]  eta: 0:26:52  Lr: 0.001875  Loss: 0.0233  Acc@1: 62.5000 (64.5492)  Acc@5: 87.5000 (89.4467)  time: 0.3478  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [  70/4579]  eta: 0:26:41  Lr: 0.001875  Loss: 0.0954  Acc@1: 62.5000 (63.4683)  Acc@5: 93.7500 (89.5246)  time: 0.3471  data: 0.0009  max mem: 2500
Train: Epoch[3/5]  [  80/4579]  eta: 0:26:32  Lr: 0.001875  Loss: -0.5376  Acc@1: 62.5000 (63.8117)  Acc@5: 87.5000 (89.7377)  time: 0.3452  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [  90/4579]  eta: 0:26:27  Lr: 0.001875  Loss: -0.2584  Acc@1: 62.5000 (63.8049)  Acc@5: 93.7500 (89.9038)  time: 0.3485  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [ 100/4579]  eta: 0:26:20  Lr: 0.001875  Loss: -0.6021  Acc@1: 62.5000 (63.7995)  Acc@5: 93.7500 (90.2228)  time: 0.3485  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [ 110/4579]  eta: 0:26:15  Lr: 0.001875  Loss: -0.1675  Acc@1: 68.7500 (63.9640)  Acc@5: 93.7500 (90.3716)  time: 0.3470  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [ 120/4579]  eta: 0:26:10  Lr: 0.001875  Loss: -0.0911  Acc@1: 62.5000 (64.1012)  Acc@5: 93.7500 (90.7025)  time: 0.3488  data: 0.0012  max mem: 2500
Train: Epoch[3/5]  [ 130/4579]  eta: 0:26:05  Lr: 0.001875  Loss: -0.3271  Acc@1: 62.5000 (64.1221)  Acc@5: 93.7500 (90.6489)  time: 0.3482  data: 0.0010  max mem: 2500
Train: Epoch[3/5]  [ 140/4579]  eta: 0:26:00  Lr: 0.001875  Loss: -0.0539  Acc@1: 62.5000 (64.1401)  Acc@5: 93.7500 (90.8245)  time: 0.3481  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [ 150/4579]  eta: 0:25:56  Lr: 0.001875  Loss: -0.4356  Acc@1: 62.5000 (64.3212)  Acc@5: 93.7500 (90.6871)  time: 0.3492  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [ 160/4579]  eta: 0:25:51  Lr: 0.001875  Loss: 0.1001  Acc@1: 68.7500 (64.5963)  Acc@5: 87.5000 (90.6056)  time: 0.3475  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [ 170/4579]  eta: 0:25:47  Lr: 0.001875  Loss: -0.2725  Acc@1: 62.5000 (64.6930)  Acc@5: 93.7500 (90.7529)  time: 0.3467  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [ 180/4579]  eta: 0:25:42  Lr: 0.001875  Loss: -0.3340  Acc@1: 62.5000 (64.7099)  Acc@5: 93.7500 (90.9185)  time: 0.3467  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [ 190/4579]  eta: 0:25:38  Lr: 0.001875  Loss: -0.4702  Acc@1: 62.5000 (64.3979)  Acc@5: 93.7500 (90.7395)  time: 0.3462  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [ 200/4579]  eta: 0:25:33  Lr: 0.001875  Loss: -0.4128  Acc@1: 62.5000 (64.3035)  Acc@5: 93.7500 (90.9204)  time: 0.3465  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [ 210/4579]  eta: 0:25:29  Lr: 0.001875  Loss: -0.0137  Acc@1: 68.7500 (64.7216)  Acc@5: 93.7500 (91.0545)  time: 0.3465  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [ 220/4579]  eta: 0:25:25  Lr: 0.001875  Loss: 0.3935  Acc@1: 68.7500 (64.6210)  Acc@5: 93.7500 (91.1482)  time: 0.3462  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 230/4579]  eta: 0:25:20  Lr: 0.001875  Loss: -0.6649  Acc@1: 62.5000 (64.6645)  Acc@5: 93.7500 (91.1797)  time: 0.3462  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [ 240/4579]  eta: 0:25:16  Lr: 0.001875  Loss: -0.2505  Acc@1: 68.7500 (64.7822)  Acc@5: 93.7500 (91.2604)  time: 0.3459  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 250/4579]  eta: 0:25:12  Lr: 0.001875  Loss: 0.0614  Acc@1: 68.7500 (64.6912)  Acc@5: 93.7500 (91.2351)  time: 0.3450  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 260/4579]  eta: 0:25:08  Lr: 0.001875  Loss: -0.6298  Acc@1: 62.5000 (64.7270)  Acc@5: 93.7500 (91.3075)  time: 0.3448  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 270/4579]  eta: 0:25:04  Lr: 0.001875  Loss: 0.0839  Acc@1: 62.5000 (64.6910)  Acc@5: 93.7500 (91.3745)  time: 0.3458  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 280/4579]  eta: 0:25:00  Lr: 0.001875  Loss: -0.0304  Acc@1: 62.5000 (64.6575)  Acc@5: 87.5000 (91.3034)  time: 0.3473  data: 0.0012  max mem: 2500
Train: Epoch[3/5]  [ 290/4579]  eta: 0:24:56  Lr: 0.001875  Loss: -0.1655  Acc@1: 68.7500 (64.6692)  Acc@5: 93.7500 (91.4734)  time: 0.3473  data: 0.0015  max mem: 2500
Train: Epoch[3/5]  [ 300/4579]  eta: 0:24:52  Lr: 0.001875  Loss: -0.0947  Acc@1: 62.5000 (64.5556)  Acc@5: 93.7500 (91.4037)  time: 0.3458  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [ 310/4579]  eta: 0:24:48  Lr: 0.001875  Loss: 0.4853  Acc@1: 62.5000 (64.4494)  Acc@5: 93.7500 (91.3585)  time: 0.3459  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [ 320/4579]  eta: 0:24:44  Lr: 0.001875  Loss: 0.1918  Acc@1: 62.5000 (64.5833)  Acc@5: 93.7500 (91.3551)  time: 0.3460  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [ 330/4579]  eta: 0:24:40  Lr: 0.001875  Loss: -0.0162  Acc@1: 62.5000 (64.4826)  Acc@5: 93.7500 (91.3331)  time: 0.3448  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 340/4579]  eta: 0:24:37  Lr: 0.001875  Loss: 0.2407  Acc@1: 62.5000 (64.3878)  Acc@5: 87.5000 (91.2390)  time: 0.3462  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 350/4579]  eta: 0:24:33  Lr: 0.001875  Loss: -0.1381  Acc@1: 62.5000 (64.3519)  Acc@5: 87.5000 (91.2749)  time: 0.3467  data: 0.0011  max mem: 2500
Train: Epoch[3/5]  [ 360/4579]  eta: 0:24:29  Lr: 0.001875  Loss: 0.0676  Acc@1: 62.5000 (64.2659)  Acc@5: 93.7500 (91.3435)  time: 0.3464  data: 0.0011  max mem: 2500
Train: Epoch[3/5]  [ 370/4579]  eta: 0:24:26  Lr: 0.001875  Loss: -0.0043  Acc@1: 56.2500 (64.1004)  Acc@5: 93.7500 (91.3578)  time: 0.3476  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [ 380/4579]  eta: 0:24:22  Lr: 0.001875  Loss: -0.1285  Acc@1: 62.5000 (64.2717)  Acc@5: 93.7500 (91.4206)  time: 0.3473  data: 0.0013  max mem: 2500
Train: Epoch[3/5]  [ 390/4579]  eta: 0:24:18  Lr: 0.001875  Loss: -0.3736  Acc@1: 62.5000 (64.3063)  Acc@5: 93.7500 (91.4322)  time: 0.3462  data: 0.0011  max mem: 2500
Train: Epoch[3/5]  [ 400/4579]  eta: 0:24:15  Lr: 0.001875  Loss: 0.4407  Acc@1: 68.7500 (64.4327)  Acc@5: 93.7500 (91.4744)  time: 0.3469  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 410/4579]  eta: 0:24:11  Lr: 0.001875  Loss: -0.3394  Acc@1: 68.7500 (64.5073)  Acc@5: 93.7500 (91.5754)  time: 0.3466  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [ 420/4579]  eta: 0:24:07  Lr: 0.001875  Loss: 0.0028  Acc@1: 62.5000 (64.4893)  Acc@5: 93.7500 (91.5825)  time: 0.3453  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [ 430/4579]  eta: 0:24:04  Lr: 0.001875  Loss: -0.1537  Acc@1: 62.5000 (64.5012)  Acc@5: 93.7500 (91.5893)  time: 0.3479  data: 0.0013  max mem: 2500
Train: Epoch[3/5]  [ 440/4579]  eta: 0:24:00  Lr: 0.001875  Loss: 0.0439  Acc@1: 62.5000 (64.4274)  Acc@5: 93.7500 (91.5391)  time: 0.3474  data: 0.0014  max mem: 2500
Train: Epoch[3/5]  [ 450/4579]  eta: 0:23:56  Lr: 0.001875  Loss: -0.1531  Acc@1: 68.7500 (64.5233)  Acc@5: 87.5000 (91.4911)  time: 0.3448  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [ 460/4579]  eta: 0:23:53  Lr: 0.001875  Loss: 0.2210  Acc@1: 68.7500 (64.5336)  Acc@5: 87.5000 (91.5130)  time: 0.3450  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 470/4579]  eta: 0:23:49  Lr: 0.001875  Loss: 0.3665  Acc@1: 62.5000 (64.4772)  Acc@5: 93.7500 (91.6003)  time: 0.3456  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [ 480/4579]  eta: 0:23:45  Lr: 0.001875  Loss: 0.0665  Acc@1: 62.5000 (64.5270)  Acc@5: 93.7500 (91.5670)  time: 0.3461  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [ 490/4579]  eta: 0:23:42  Lr: 0.001875  Loss: 0.7269  Acc@1: 62.5000 (64.5621)  Acc@5: 93.7500 (91.5733)  time: 0.3462  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [ 500/4579]  eta: 0:23:38  Lr: 0.001875  Loss: 0.0707  Acc@1: 68.7500 (64.6083)  Acc@5: 93.7500 (91.6292)  time: 0.3461  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [ 510/4579]  eta: 0:23:35  Lr: 0.001875  Loss: 0.3855  Acc@1: 62.5000 (64.5181)  Acc@5: 93.7500 (91.6707)  time: 0.3481  data: 0.0017  max mem: 2500
Train: Epoch[3/5]  [ 520/4579]  eta: 0:23:31  Lr: 0.001875  Loss: 0.3009  Acc@1: 62.5000 (64.5753)  Acc@5: 93.7500 (91.6627)  time: 0.3484  data: 0.0017  max mem: 2500
Train: Epoch[3/5]  [ 530/4579]  eta: 0:23:28  Lr: 0.001875  Loss: -0.2360  Acc@1: 68.7500 (64.7010)  Acc@5: 93.7500 (91.6902)  time: 0.3476  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [ 540/4579]  eta: 0:23:24  Lr: 0.001875  Loss: -0.0942  Acc@1: 68.7500 (64.7643)  Acc@5: 93.7500 (91.7629)  time: 0.3475  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [ 550/4579]  eta: 0:23:21  Lr: 0.001875  Loss: -0.1327  Acc@1: 68.7500 (64.7573)  Acc@5: 93.7500 (91.7083)  time: 0.3456  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [ 560/4579]  eta: 0:23:17  Lr: 0.001875  Loss: -0.4590  Acc@1: 62.5000 (64.7282)  Acc@5: 87.5000 (91.6778)  time: 0.3460  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [ 570/4579]  eta: 0:23:14  Lr: 0.001875  Loss: -0.5365  Acc@1: 62.5000 (64.7767)  Acc@5: 93.7500 (91.7141)  time: 0.3472  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [ 580/4579]  eta: 0:23:10  Lr: 0.001875  Loss: -0.0999  Acc@1: 62.5000 (64.6622)  Acc@5: 93.7500 (91.6846)  time: 0.3460  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [ 590/4579]  eta: 0:23:06  Lr: 0.001875  Loss: -0.2514  Acc@1: 62.5000 (64.6679)  Acc@5: 93.7500 (91.6772)  time: 0.3459  data: 0.0012  max mem: 2500
Train: Epoch[3/5]  [ 600/4579]  eta: 0:23:03  Lr: 0.001875  Loss: 0.3661  Acc@1: 62.5000 (64.6215)  Acc@5: 93.7500 (91.6389)  time: 0.3468  data: 0.0014  max mem: 2500
Train: Epoch[3/5]  [ 610/4579]  eta: 0:22:59  Lr: 0.001875  Loss: -0.0155  Acc@1: 62.5000 (64.5867)  Acc@5: 87.5000 (91.6019)  time: 0.3466  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [ 620/4579]  eta: 0:22:56  Lr: 0.001875  Loss: 0.2359  Acc@1: 62.5000 (64.5431)  Acc@5: 87.5000 (91.5962)  time: 0.3456  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 630/4579]  eta: 0:22:52  Lr: 0.001875  Loss: -0.0054  Acc@1: 62.5000 (64.5800)  Acc@5: 93.7500 (91.6303)  time: 0.3448  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 640/4579]  eta: 0:22:48  Lr: 0.001875  Loss: -0.3689  Acc@1: 62.5000 (64.5671)  Acc@5: 93.7500 (91.5659)  time: 0.3459  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 650/4579]  eta: 0:22:45  Lr: 0.001875  Loss: -0.0581  Acc@1: 68.7500 (64.6601)  Acc@5: 87.5000 (91.5227)  time: 0.3467  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 660/4579]  eta: 0:22:41  Lr: 0.001875  Loss: -0.1805  Acc@1: 68.7500 (64.6842)  Acc@5: 93.7500 (91.5469)  time: 0.3465  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [ 670/4579]  eta: 0:22:38  Lr: 0.001875  Loss: -0.0472  Acc@1: 68.7500 (64.6610)  Acc@5: 93.7500 (91.4959)  time: 0.3462  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [ 680/4579]  eta: 0:22:34  Lr: 0.001875  Loss: -0.3777  Acc@1: 68.7500 (64.7485)  Acc@5: 87.5000 (91.5106)  time: 0.3469  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [ 690/4579]  eta: 0:22:31  Lr: 0.001875  Loss: -0.2864  Acc@1: 62.5000 (64.7250)  Acc@5: 93.7500 (91.5250)  time: 0.3476  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 700/4579]  eta: 0:22:27  Lr: 0.001875  Loss: -0.2706  Acc@1: 56.2500 (64.6576)  Acc@5: 93.7500 (91.5478)  time: 0.3464  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 710/4579]  eta: 0:22:24  Lr: 0.001875  Loss: -0.0061  Acc@1: 62.5000 (64.6976)  Acc@5: 93.7500 (91.5436)  time: 0.3448  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 720/4579]  eta: 0:22:20  Lr: 0.001875  Loss: -0.0931  Acc@1: 68.7500 (64.7278)  Acc@5: 93.7500 (91.6089)  time: 0.3453  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [ 730/4579]  eta: 0:22:17  Lr: 0.001875  Loss: 0.2858  Acc@1: 62.5000 (64.6546)  Acc@5: 100.0000 (91.6553)  time: 0.3457  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [ 740/4579]  eta: 0:22:13  Lr: 0.001875  Loss: -0.1676  Acc@1: 62.5000 (64.7014)  Acc@5: 93.7500 (91.7004)  time: 0.3464  data: 0.0013  max mem: 2500
Train: Epoch[3/5]  [ 750/4579]  eta: 0:22:10  Lr: 0.001875  Loss: -0.0530  Acc@1: 62.5000 (64.6887)  Acc@5: 93.7500 (91.7111)  time: 0.3470  data: 0.0022  max mem: 2500
Train: Epoch[3/5]  [ 760/4579]  eta: 0:22:06  Lr: 0.001875  Loss: 0.1521  Acc@1: 62.5000 (64.5861)  Acc@5: 93.7500 (91.6804)  time: 0.3468  data: 0.0014  max mem: 2500
Train: Epoch[3/5]  [ 770/4579]  eta: 0:22:02  Lr: 0.001875  Loss: -0.0484  Acc@1: 56.2500 (64.5590)  Acc@5: 93.7500 (91.6910)  time: 0.3453  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [ 780/4579]  eta: 0:21:59  Lr: 0.001875  Loss: -0.0450  Acc@1: 62.5000 (64.5246)  Acc@5: 93.7500 (91.7093)  time: 0.3450  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 790/4579]  eta: 0:21:55  Lr: 0.001875  Loss: -0.2102  Acc@1: 62.5000 (64.5228)  Acc@5: 93.7500 (91.7114)  time: 0.3459  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 800/4579]  eta: 0:21:52  Lr: 0.001875  Loss: -0.1688  Acc@1: 62.5000 (64.5443)  Acc@5: 93.7500 (91.7057)  time: 0.3457  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 810/4579]  eta: 0:21:48  Lr: 0.001875  Loss: -0.2204  Acc@1: 62.5000 (64.5114)  Acc@5: 93.7500 (91.7078)  time: 0.3477  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 820/4579]  eta: 0:21:45  Lr: 0.001875  Loss: -0.1820  Acc@1: 62.5000 (64.4641)  Acc@5: 93.7500 (91.7403)  time: 0.3474  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [ 830/4579]  eta: 0:21:41  Lr: 0.001875  Loss: 0.4849  Acc@1: 62.5000 (64.4555)  Acc@5: 93.7500 (91.7644)  time: 0.3464  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [ 840/4579]  eta: 0:21:38  Lr: 0.001875  Loss: 0.4233  Acc@1: 62.5000 (64.4174)  Acc@5: 93.7500 (91.7509)  time: 0.3481  data: 0.0010  max mem: 2500
Train: Epoch[3/5]  [ 850/4579]  eta: 0:21:34  Lr: 0.001875  Loss: -0.2329  Acc@1: 62.5000 (64.4756)  Acc@5: 93.7500 (91.7524)  time: 0.3476  data: 0.0011  max mem: 2500
Train: Epoch[3/5]  [ 860/4579]  eta: 0:21:31  Lr: 0.001875  Loss: 0.0735  Acc@1: 62.5000 (64.4817)  Acc@5: 93.7500 (91.7683)  time: 0.3468  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [ 870/4579]  eta: 0:21:28  Lr: 0.001875  Loss: 0.2234  Acc@1: 62.5000 (64.4231)  Acc@5: 93.7500 (91.7480)  time: 0.3475  data: 0.0010  max mem: 2500
Train: Epoch[3/5]  [ 880/4579]  eta: 0:21:24  Lr: 0.001875  Loss: -0.0504  Acc@1: 62.5000 (64.4367)  Acc@5: 87.5000 (91.7281)  time: 0.3463  data: 0.0009  max mem: 2500
Train: Epoch[3/5]  [ 890/4579]  eta: 0:21:20  Lr: 0.001875  Loss: 0.3345  Acc@1: 62.5000 (64.4781)  Acc@5: 93.7500 (91.7438)  time: 0.3456  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 900/4579]  eta: 0:21:17  Lr: 0.001875  Loss: -0.0334  Acc@1: 68.7500 (64.5463)  Acc@5: 93.7500 (91.7661)  time: 0.3460  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 910/4579]  eta: 0:21:13  Lr: 0.001875  Loss: -0.3910  Acc@1: 68.7500 (64.5170)  Acc@5: 93.7500 (91.7467)  time: 0.3456  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [ 920/4579]  eta: 0:21:10  Lr: 0.001875  Loss: -0.0799  Acc@1: 56.2500 (64.4205)  Acc@5: 93.7500 (91.7277)  time: 0.3471  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [ 930/4579]  eta: 0:21:07  Lr: 0.001875  Loss: -0.4988  Acc@1: 62.5000 (64.4200)  Acc@5: 93.7500 (91.7562)  time: 0.3493  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [ 940/4579]  eta: 0:21:03  Lr: 0.001875  Loss: 0.1859  Acc@1: 62.5000 (64.3929)  Acc@5: 93.7500 (91.7309)  time: 0.3484  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [ 950/4579]  eta: 0:21:00  Lr: 0.001875  Loss: -0.0504  Acc@1: 62.5000 (64.3993)  Acc@5: 87.5000 (91.7127)  time: 0.3462  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [ 960/4579]  eta: 0:20:56  Lr: 0.001875  Loss: 0.1152  Acc@1: 68.7500 (64.4121)  Acc@5: 93.7500 (91.7404)  time: 0.3452  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 970/4579]  eta: 0:20:52  Lr: 0.001875  Loss: 0.1865  Acc@1: 62.5000 (64.3988)  Acc@5: 93.7500 (91.7933)  time: 0.3455  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [ 980/4579]  eta: 0:20:49  Lr: 0.001875  Loss: 0.0363  Acc@1: 62.5000 (64.3986)  Acc@5: 93.7500 (91.7877)  time: 0.3465  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [ 990/4579]  eta: 0:20:45  Lr: 0.001875  Loss: -0.5813  Acc@1: 62.5000 (64.3794)  Acc@5: 87.5000 (91.7571)  time: 0.3462  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1000/4579]  eta: 0:20:42  Lr: 0.001875  Loss: -0.0556  Acc@1: 62.5000 (64.3606)  Acc@5: 87.5000 (91.6958)  time: 0.3450  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1010/4579]  eta: 0:20:38  Lr: 0.001875  Loss: -0.5412  Acc@1: 62.5000 (64.3731)  Acc@5: 93.7500 (91.6914)  time: 0.3457  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1020/4579]  eta: 0:20:35  Lr: 0.001875  Loss: 0.1563  Acc@1: 62.5000 (64.3670)  Acc@5: 93.7500 (91.7177)  time: 0.3484  data: 0.0028  max mem: 2500
Train: Epoch[3/5]  [1030/4579]  eta: 0:20:31  Lr: 0.001875  Loss: -0.2866  Acc@1: 62.5000 (64.3611)  Acc@5: 93.7500 (91.7010)  time: 0.3473  data: 0.0027  max mem: 2500
Train: Epoch[3/5]  [1040/4579]  eta: 0:20:28  Lr: 0.001875  Loss: -0.0030  Acc@1: 62.5000 (64.3492)  Acc@5: 87.5000 (91.6847)  time: 0.3460  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [1050/4579]  eta: 0:20:25  Lr: 0.001875  Loss: -0.1197  Acc@1: 62.5000 (64.3554)  Acc@5: 93.7500 (91.6865)  time: 0.3464  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [1060/4579]  eta: 0:20:21  Lr: 0.001875  Loss: -0.2384  Acc@1: 68.7500 (64.3791)  Acc@5: 93.7500 (91.7236)  time: 0.3460  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [1070/4579]  eta: 0:20:18  Lr: 0.001875  Loss: 0.6905  Acc@1: 68.7500 (64.4083)  Acc@5: 93.7500 (91.7542)  time: 0.3462  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [1080/4579]  eta: 0:20:14  Lr: 0.001875  Loss: 0.0144  Acc@1: 62.5000 (64.3848)  Acc@5: 93.7500 (91.7553)  time: 0.3458  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [1090/4579]  eta: 0:20:10  Lr: 0.001875  Loss: -0.7149  Acc@1: 62.5000 (64.4077)  Acc@5: 93.7500 (91.7851)  time: 0.3455  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [1100/4579]  eta: 0:20:07  Lr: 0.001875  Loss: 0.1104  Acc@1: 68.7500 (64.4698)  Acc@5: 93.7500 (91.8313)  time: 0.3469  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [1110/4579]  eta: 0:20:04  Lr: 0.001875  Loss: 0.0632  Acc@1: 62.5000 (64.4633)  Acc@5: 93.7500 (91.8148)  time: 0.3474  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [1120/4579]  eta: 0:20:00  Lr: 0.001875  Loss: -0.0210  Acc@1: 62.5000 (64.4848)  Acc@5: 93.7500 (91.7875)  time: 0.3472  data: 0.0009  max mem: 2500
Train: Epoch[3/5]  [1130/4579]  eta: 0:19:57  Lr: 0.001875  Loss: -0.0589  Acc@1: 62.5000 (64.4728)  Acc@5: 93.7500 (91.8159)  time: 0.3481  data: 0.0013  max mem: 2500
Train: Epoch[3/5]  [1140/4579]  eta: 0:19:53  Lr: 0.001875  Loss: -0.3949  Acc@1: 62.5000 (64.4993)  Acc@5: 93.7500 (91.8273)  time: 0.3474  data: 0.0014  max mem: 2500
Train: Epoch[3/5]  [1150/4579]  eta: 0:19:50  Lr: 0.001875  Loss: -0.3617  Acc@1: 62.5000 (64.5254)  Acc@5: 93.7500 (91.8060)  time: 0.3475  data: 0.0011  max mem: 2500
Train: Epoch[3/5]  [1160/4579]  eta: 0:19:46  Lr: 0.001875  Loss: -0.0354  Acc@1: 62.5000 (64.4811)  Acc@5: 93.7500 (91.8174)  time: 0.3480  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1170/4579]  eta: 0:19:43  Lr: 0.001875  Loss: -0.2474  Acc@1: 56.2500 (64.4908)  Acc@5: 93.7500 (91.8019)  time: 0.3470  data: 0.0009  max mem: 2500
Train: Epoch[3/5]  [1180/4579]  eta: 0:19:39  Lr: 0.001875  Loss: -0.2779  Acc@1: 62.5000 (64.5216)  Acc@5: 93.7500 (91.8237)  time: 0.3462  data: 0.0010  max mem: 2500
Train: Epoch[3/5]  [1190/4579]  eta: 0:19:36  Lr: 0.001875  Loss: 0.1070  Acc@1: 68.7500 (64.5361)  Acc@5: 93.7500 (91.8188)  time: 0.3471  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [1200/4579]  eta: 0:19:32  Lr: 0.001875  Loss: -0.3374  Acc@1: 62.5000 (64.5192)  Acc@5: 93.7500 (91.8141)  time: 0.3488  data: 0.0012  max mem: 2500
Train: Epoch[3/5]  [1210/4579]  eta: 0:19:29  Lr: 0.001875  Loss: -0.7322  Acc@1: 62.5000 (64.4922)  Acc@5: 93.7500 (91.8198)  time: 0.3486  data: 0.0010  max mem: 2500
Train: Epoch[3/5]  [1220/4579]  eta: 0:19:26  Lr: 0.001875  Loss: 0.4322  Acc@1: 68.7500 (64.4656)  Acc@5: 93.7500 (91.8100)  time: 0.3491  data: 0.0011  max mem: 2500
Train: Epoch[3/5]  [1230/4579]  eta: 0:19:22  Lr: 0.001875  Loss: -0.1537  Acc@1: 68.7500 (64.4547)  Acc@5: 87.5000 (91.8054)  time: 0.3485  data: 0.0018  max mem: 2500
Train: Epoch[3/5]  [1240/4579]  eta: 0:19:19  Lr: 0.001875  Loss: -0.3002  Acc@1: 68.7500 (64.4440)  Acc@5: 93.7500 (91.8161)  time: 0.3469  data: 0.0011  max mem: 2500
Train: Epoch[3/5]  [1250/4579]  eta: 0:19:15  Lr: 0.001875  Loss: -0.3889  Acc@1: 68.7500 (64.4784)  Acc@5: 93.7500 (91.8066)  time: 0.3481  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1260/4579]  eta: 0:19:12  Lr: 0.001875  Loss: 0.2793  Acc@1: 68.7500 (64.4776)  Acc@5: 93.7500 (91.8021)  time: 0.3471  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1270/4579]  eta: 0:19:08  Lr: 0.001875  Loss: 0.4870  Acc@1: 62.5000 (64.4571)  Acc@5: 93.7500 (91.8125)  time: 0.3456  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [1280/4579]  eta: 0:19:05  Lr: 0.001875  Loss: -0.0469  Acc@1: 68.7500 (64.4760)  Acc@5: 93.7500 (91.8130)  time: 0.3471  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [1290/4579]  eta: 0:19:01  Lr: 0.001875  Loss: -0.0621  Acc@1: 68.7500 (64.5091)  Acc@5: 93.7500 (91.7990)  time: 0.3468  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [1300/4579]  eta: 0:18:58  Lr: 0.001875  Loss: 0.2697  Acc@1: 62.5000 (64.5081)  Acc@5: 87.5000 (91.7659)  time: 0.3475  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [1310/4579]  eta: 0:18:54  Lr: 0.001875  Loss: 0.8465  Acc@1: 62.5000 (64.4689)  Acc@5: 87.5000 (91.7477)  time: 0.3491  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [1320/4579]  eta: 0:18:51  Lr: 0.001875  Loss: -0.0960  Acc@1: 56.2500 (64.4162)  Acc@5: 87.5000 (91.6966)  time: 0.3484  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [1330/4579]  eta: 0:18:47  Lr: 0.001875  Loss: -0.1163  Acc@1: 56.2500 (64.4018)  Acc@5: 87.5000 (91.7027)  time: 0.3467  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [1340/4579]  eta: 0:18:44  Lr: 0.001875  Loss: -0.0245  Acc@1: 62.5000 (64.3876)  Acc@5: 93.7500 (91.6946)  time: 0.3460  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1350/4579]  eta: 0:18:40  Lr: 0.001875  Loss: -0.0627  Acc@1: 62.5000 (64.4014)  Acc@5: 93.7500 (91.7330)  time: 0.3463  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1360/4579]  eta: 0:18:37  Lr: 0.001875  Loss: 0.0195  Acc@1: 62.5000 (64.3828)  Acc@5: 93.7500 (91.7157)  time: 0.3465  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [1370/4579]  eta: 0:18:33  Lr: 0.001875  Loss: -0.0665  Acc@1: 68.7500 (64.3827)  Acc@5: 93.7500 (91.7031)  time: 0.3460  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [1380/4579]  eta: 0:18:30  Lr: 0.001875  Loss: 0.1708  Acc@1: 68.7500 (64.3782)  Acc@5: 93.7500 (91.7406)  time: 0.3453  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [1390/4579]  eta: 0:18:27  Lr: 0.001875  Loss: -0.2011  Acc@1: 62.5000 (64.3692)  Acc@5: 93.7500 (91.7550)  time: 0.3472  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [1400/4579]  eta: 0:18:23  Lr: 0.001875  Loss: 0.2554  Acc@1: 62.5000 (64.3514)  Acc@5: 93.7500 (91.7157)  time: 0.3477  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [1410/4579]  eta: 0:18:20  Lr: 0.001875  Loss: 0.1030  Acc@1: 62.5000 (64.3515)  Acc@5: 87.5000 (91.7124)  time: 0.3477  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [1420/4579]  eta: 0:18:16  Lr: 0.001875  Loss: 0.3162  Acc@1: 62.5000 (64.3165)  Acc@5: 87.5000 (91.6960)  time: 0.3476  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [1430/4579]  eta: 0:18:13  Lr: 0.001875  Loss: -0.4308  Acc@1: 62.5000 (64.3213)  Acc@5: 93.7500 (91.7060)  time: 0.3475  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [1440/4579]  eta: 0:18:09  Lr: 0.001875  Loss: 0.4181  Acc@1: 62.5000 (64.3173)  Acc@5: 93.7500 (91.7115)  time: 0.3473  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [1450/4579]  eta: 0:18:06  Lr: 0.001875  Loss: 0.2194  Acc@1: 62.5000 (64.3177)  Acc@5: 93.7500 (91.7040)  time: 0.3466  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [1460/4579]  eta: 0:18:02  Lr: 0.001875  Loss: -0.5084  Acc@1: 62.5000 (64.3010)  Acc@5: 87.5000 (91.6881)  time: 0.3472  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [1470/4579]  eta: 0:17:59  Lr: 0.001875  Loss: -0.3101  Acc@1: 62.5000 (64.2972)  Acc@5: 87.5000 (91.6808)  time: 0.3481  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [1480/4579]  eta: 0:17:55  Lr: 0.001875  Loss: 0.2352  Acc@1: 62.5000 (64.2767)  Acc@5: 93.7500 (91.6948)  time: 0.3470  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [1490/4579]  eta: 0:17:52  Lr: 0.001875  Loss: -0.0623  Acc@1: 62.5000 (64.2773)  Acc@5: 93.7500 (91.6960)  time: 0.3467  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [1500/4579]  eta: 0:17:48  Lr: 0.001875  Loss: -0.2190  Acc@1: 62.5000 (64.2613)  Acc@5: 93.7500 (91.6889)  time: 0.3486  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [1510/4579]  eta: 0:17:45  Lr: 0.001875  Loss: -0.1123  Acc@1: 62.5000 (64.2455)  Acc@5: 93.7500 (91.6818)  time: 0.3502  data: 0.0009  max mem: 2500
Train: Epoch[3/5]  [1520/4579]  eta: 0:17:42  Lr: 0.001875  Loss: -0.7162  Acc@1: 68.7500 (64.3162)  Acc@5: 93.7500 (91.6913)  time: 0.3495  data: 0.0009  max mem: 2500
Train: Epoch[3/5]  [1530/4579]  eta: 0:17:38  Lr: 0.001875  Loss: 0.0729  Acc@1: 68.7500 (64.3370)  Acc@5: 93.7500 (91.6884)  time: 0.3469  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [1540/4579]  eta: 0:17:35  Lr: 0.001875  Loss: -0.0490  Acc@1: 56.2500 (64.3008)  Acc@5: 87.5000 (91.6775)  time: 0.3467  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [1550/4579]  eta: 0:17:31  Lr: 0.001875  Loss: -0.2822  Acc@1: 62.5000 (64.3254)  Acc@5: 93.7500 (91.6788)  time: 0.3468  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [1560/4579]  eta: 0:17:28  Lr: 0.001875  Loss: -0.5883  Acc@1: 62.5000 (64.3458)  Acc@5: 93.7500 (91.6920)  time: 0.3466  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1570/4579]  eta: 0:17:24  Lr: 0.001875  Loss: 0.2059  Acc@1: 68.7500 (64.3539)  Acc@5: 93.7500 (91.6733)  time: 0.3481  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [1580/4579]  eta: 0:17:21  Lr: 0.001875  Loss: 0.3349  Acc@1: 62.5000 (64.3264)  Acc@5: 87.5000 (91.6667)  time: 0.3478  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [1590/4579]  eta: 0:17:17  Lr: 0.001875  Loss: -0.0555  Acc@1: 62.5000 (64.3188)  Acc@5: 87.5000 (91.6523)  time: 0.3465  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [1600/4579]  eta: 0:17:14  Lr: 0.001875  Loss: 0.0210  Acc@1: 62.5000 (64.2879)  Acc@5: 87.5000 (91.6185)  time: 0.3471  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [1610/4579]  eta: 0:17:10  Lr: 0.001875  Loss: 0.1010  Acc@1: 62.5000 (64.2652)  Acc@5: 87.5000 (91.5968)  time: 0.3479  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [1620/4579]  eta: 0:17:07  Lr: 0.001875  Loss: -0.0503  Acc@1: 62.5000 (64.2659)  Acc@5: 93.7500 (91.6024)  time: 0.3472  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [1630/4579]  eta: 0:17:03  Lr: 0.001875  Loss: 0.3753  Acc@1: 62.5000 (64.2397)  Acc@5: 93.7500 (91.6041)  time: 0.3461  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [1640/4579]  eta: 0:17:00  Lr: 0.001875  Loss: -0.0754  Acc@1: 62.5000 (64.2596)  Acc@5: 93.7500 (91.6019)  time: 0.3477  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [1650/4579]  eta: 0:16:56  Lr: 0.001875  Loss: 0.2344  Acc@1: 62.5000 (64.2414)  Acc@5: 93.7500 (91.6225)  time: 0.3482  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [1660/4579]  eta: 0:16:53  Lr: 0.001875  Loss: 0.1309  Acc@1: 62.5000 (64.2836)  Acc@5: 93.7500 (91.6165)  time: 0.3472  data: 0.0011  max mem: 2500
Train: Epoch[3/5]  [1670/4579]  eta: 0:16:49  Lr: 0.001875  Loss: 0.0661  Acc@1: 68.7500 (64.2841)  Acc@5: 93.7500 (91.6106)  time: 0.3468  data: 0.0012  max mem: 2500
Train: Epoch[3/5]  [1680/4579]  eta: 0:16:46  Lr: 0.001875  Loss: -0.6505  Acc@1: 68.7500 (64.2958)  Acc@5: 93.7500 (91.6010)  time: 0.3481  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [1690/4579]  eta: 0:16:43  Lr: 0.001875  Loss: -0.2117  Acc@1: 62.5000 (64.2889)  Acc@5: 87.5000 (91.5915)  time: 0.3482  data: 0.0012  max mem: 2500
Train: Epoch[3/5]  [1700/4579]  eta: 0:16:39  Lr: 0.001875  Loss: -0.8799  Acc@1: 62.5000 (64.2857)  Acc@5: 93.7500 (91.5932)  time: 0.3480  data: 0.0019  max mem: 2500
Train: Epoch[3/5]  [1710/4579]  eta: 0:16:36  Lr: 0.001875  Loss: -0.7854  Acc@1: 62.5000 (64.2972)  Acc@5: 93.7500 (91.5985)  time: 0.3484  data: 0.0012  max mem: 2500
Train: Epoch[3/5]  [1720/4579]  eta: 0:16:32  Lr: 0.001875  Loss: 0.4264  Acc@1: 68.7500 (64.3049)  Acc@5: 93.7500 (91.5856)  time: 0.3462  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [1730/4579]  eta: 0:16:29  Lr: 0.001875  Loss: 0.2996  Acc@1: 62.5000 (64.2873)  Acc@5: 93.7500 (91.5908)  time: 0.3468  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [1740/4579]  eta: 0:16:25  Lr: 0.001875  Loss: 0.0435  Acc@1: 62.5000 (64.2914)  Acc@5: 93.7500 (91.5709)  time: 0.3482  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [1750/4579]  eta: 0:16:22  Lr: 0.001875  Loss: -0.2826  Acc@1: 68.7500 (64.2847)  Acc@5: 93.7500 (91.5655)  time: 0.3479  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1760/4579]  eta: 0:16:18  Lr: 0.001875  Loss: -0.0522  Acc@1: 62.5000 (64.2959)  Acc@5: 93.7500 (91.5708)  time: 0.3471  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [1770/4579]  eta: 0:16:15  Lr: 0.001875  Loss: -0.0752  Acc@1: 68.7500 (64.2928)  Acc@5: 93.7500 (91.5690)  time: 0.3465  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [1780/4579]  eta: 0:16:11  Lr: 0.001875  Loss: 0.4587  Acc@1: 62.5000 (64.3073)  Acc@5: 93.7500 (91.5637)  time: 0.3460  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [1790/4579]  eta: 0:16:08  Lr: 0.001875  Loss: 0.2312  Acc@1: 62.5000 (64.3146)  Acc@5: 93.7500 (91.5724)  time: 0.3456  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [1800/4579]  eta: 0:16:04  Lr: 0.001875  Loss: -0.4124  Acc@1: 68.7500 (64.3219)  Acc@5: 93.7500 (91.5741)  time: 0.3465  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [1810/4579]  eta: 0:16:01  Lr: 0.001875  Loss: -0.1014  Acc@1: 68.7500 (64.3256)  Acc@5: 93.7500 (91.5723)  time: 0.3470  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [1820/4579]  eta: 0:15:57  Lr: 0.001875  Loss: 0.8937  Acc@1: 62.5000 (64.2916)  Acc@5: 87.5000 (91.5740)  time: 0.3466  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1830/4579]  eta: 0:15:54  Lr: 0.001875  Loss: -0.3906  Acc@1: 62.5000 (64.3228)  Acc@5: 87.5000 (91.5688)  time: 0.3469  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [1840/4579]  eta: 0:15:50  Lr: 0.001875  Loss: 0.3864  Acc@1: 62.5000 (64.2789)  Acc@5: 87.5000 (91.5535)  time: 0.3469  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [1850/4579]  eta: 0:15:47  Lr: 0.001875  Loss: 0.2325  Acc@1: 56.2500 (64.2896)  Acc@5: 87.5000 (91.5654)  time: 0.3464  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [1860/4579]  eta: 0:15:43  Lr: 0.001875  Loss: -0.2386  Acc@1: 68.7500 (64.3102)  Acc@5: 93.7500 (91.5502)  time: 0.3470  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [1870/4579]  eta: 0:15:40  Lr: 0.001875  Loss: 0.0022  Acc@1: 62.5000 (64.2805)  Acc@5: 87.5000 (91.5353)  time: 0.3467  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [1880/4579]  eta: 0:15:37  Lr: 0.001875  Loss: 0.5246  Acc@1: 62.5000 (64.2810)  Acc@5: 93.7500 (91.5371)  time: 0.3461  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [1890/4579]  eta: 0:15:33  Lr: 0.001875  Loss: -0.2314  Acc@1: 62.5000 (64.2682)  Acc@5: 93.7500 (91.5389)  time: 0.3458  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [1900/4579]  eta: 0:15:30  Lr: 0.001875  Loss: 0.1234  Acc@1: 62.5000 (64.2589)  Acc@5: 93.7500 (91.5505)  time: 0.3454  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [1910/4579]  eta: 0:15:26  Lr: 0.001875  Loss: 0.0310  Acc@1: 62.5000 (64.2988)  Acc@5: 93.7500 (91.5587)  time: 0.3451  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [1920/4579]  eta: 0:15:22  Lr: 0.001875  Loss: 0.1356  Acc@1: 62.5000 (64.3024)  Acc@5: 93.7500 (91.5571)  time: 0.3445  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1930/4579]  eta: 0:15:19  Lr: 0.001875  Loss: 0.3429  Acc@1: 62.5000 (64.3190)  Acc@5: 93.7500 (91.5523)  time: 0.3476  data: 0.0012  max mem: 2500
Train: Epoch[3/5]  [1940/4579]  eta: 0:15:16  Lr: 0.001875  Loss: -0.3788  Acc@1: 68.7500 (64.3290)  Acc@5: 87.5000 (91.5379)  time: 0.3478  data: 0.0012  max mem: 2500
Train: Epoch[3/5]  [1950/4579]  eta: 0:15:12  Lr: 0.001875  Loss: -0.2028  Acc@1: 62.5000 (64.3132)  Acc@5: 87.5000 (91.5428)  time: 0.3452  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1960/4579]  eta: 0:15:09  Lr: 0.001875  Loss: 0.4129  Acc@1: 62.5000 (64.3039)  Acc@5: 87.5000 (91.5286)  time: 0.3463  data: 0.0009  max mem: 2500
Train: Epoch[3/5]  [1970/4579]  eta: 0:15:05  Lr: 0.001875  Loss: 0.2791  Acc@1: 62.5000 (64.3043)  Acc@5: 87.5000 (91.5367)  time: 0.3463  data: 0.0009  max mem: 2500
Train: Epoch[3/5]  [1980/4579]  eta: 0:15:02  Lr: 0.001875  Loss: -0.1448  Acc@1: 62.5000 (64.3015)  Acc@5: 93.7500 (91.5415)  time: 0.3461  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1990/4579]  eta: 0:14:58  Lr: 0.001875  Loss: -0.0607  Acc@1: 56.2500 (64.2830)  Acc@5: 93.7500 (91.5495)  time: 0.3475  data: 0.0012  max mem: 2500
Train: Epoch[3/5]  [2000/4579]  eta: 0:14:55  Lr: 0.001875  Loss: 1.2723  Acc@1: 56.2500 (64.2647)  Acc@5: 93.7500 (91.5386)  time: 0.3484  data: 0.0017  max mem: 2500
Train: Epoch[3/5]  [2010/4579]  eta: 0:14:51  Lr: 0.001875  Loss: -0.2019  Acc@1: 68.7500 (64.2715)  Acc@5: 93.7500 (91.5341)  time: 0.3469  data: 0.0009  max mem: 2500
Train: Epoch[3/5]  [2020/4579]  eta: 0:14:48  Lr: 0.001875  Loss: 0.0362  Acc@1: 68.7500 (64.2658)  Acc@5: 93.7500 (91.5388)  time: 0.3461  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [2030/4579]  eta: 0:14:44  Lr: 0.001875  Loss: -0.2142  Acc@1: 68.7500 (64.2787)  Acc@5: 93.7500 (91.5436)  time: 0.3476  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [2040/4579]  eta: 0:14:41  Lr: 0.001875  Loss: -0.0157  Acc@1: 62.5000 (64.2700)  Acc@5: 93.7500 (91.5391)  time: 0.3482  data: 0.0009  max mem: 2500
Train: Epoch[3/5]  [2050/4579]  eta: 0:14:37  Lr: 0.001875  Loss: -0.6590  Acc@1: 62.5000 (64.2705)  Acc@5: 93.7500 (91.5346)  time: 0.3472  data: 0.0010  max mem: 2500
Train: Epoch[3/5]  [2060/4579]  eta: 0:14:34  Lr: 0.001875  Loss: -0.1539  Acc@1: 62.5000 (64.2710)  Acc@5: 93.7500 (91.5211)  time: 0.3471  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [2070/4579]  eta: 0:14:30  Lr: 0.001875  Loss: -0.0951  Acc@1: 68.7500 (64.2926)  Acc@5: 93.7500 (91.5258)  time: 0.3468  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [2080/4579]  eta: 0:14:27  Lr: 0.001875  Loss: 0.3855  Acc@1: 68.7500 (64.2810)  Acc@5: 93.7500 (91.5155)  time: 0.3460  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [2090/4579]  eta: 0:14:23  Lr: 0.001875  Loss: 0.3010  Acc@1: 62.5000 (64.2904)  Acc@5: 93.7500 (91.5232)  time: 0.3472  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [2100/4579]  eta: 0:14:20  Lr: 0.001875  Loss: -0.4821  Acc@1: 62.5000 (64.3087)  Acc@5: 93.7500 (91.5249)  time: 0.3509  data: 0.0014  max mem: 2500
Train: Epoch[3/5]  [2110/4579]  eta: 0:14:17  Lr: 0.001875  Loss: -0.0809  Acc@1: 68.7500 (64.3179)  Acc@5: 93.7500 (91.5295)  time: 0.3518  data: 0.0015  max mem: 2500
Train: Epoch[3/5]  [2120/4579]  eta: 0:14:13  Lr: 0.001875  Loss: -0.2124  Acc@1: 62.5000 (64.3211)  Acc@5: 93.7500 (91.5252)  time: 0.3493  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [2130/4579]  eta: 0:14:10  Lr: 0.001875  Loss: 0.1905  Acc@1: 62.5000 (64.3037)  Acc@5: 87.5000 (91.5063)  time: 0.3465  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2140/4579]  eta: 0:14:06  Lr: 0.001875  Loss: -0.6126  Acc@1: 62.5000 (64.2953)  Acc@5: 87.5000 (91.4993)  time: 0.3448  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [2150/4579]  eta: 0:14:03  Lr: 0.001875  Loss: 0.3275  Acc@1: 62.5000 (64.2928)  Acc@5: 87.5000 (91.4981)  time: 0.3455  data: 0.0016  max mem: 2500
Train: Epoch[3/5]  [2160/4579]  eta: 0:13:59  Lr: 0.001875  Loss: -0.0615  Acc@1: 62.5000 (64.2903)  Acc@5: 87.5000 (91.4999)  time: 0.3468  data: 0.0019  max mem: 2500
Train: Epoch[3/5]  [2170/4579]  eta: 0:13:56  Lr: 0.001875  Loss: -0.3174  Acc@1: 68.7500 (64.3137)  Acc@5: 93.7500 (91.5131)  time: 0.3469  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [2180/4579]  eta: 0:13:52  Lr: 0.001875  Loss: 0.0661  Acc@1: 62.5000 (64.2910)  Acc@5: 93.7500 (91.4976)  time: 0.3472  data: 0.0012  max mem: 2500
Train: Epoch[3/5]  [2190/4579]  eta: 0:13:49  Lr: 0.001875  Loss: -0.3071  Acc@1: 62.5000 (64.2914)  Acc@5: 87.5000 (91.4879)  time: 0.3474  data: 0.0013  max mem: 2500
Train: Epoch[3/5]  [2200/4579]  eta: 0:13:45  Lr: 0.001875  Loss: 0.2262  Acc@1: 62.5000 (64.2890)  Acc@5: 87.5000 (91.4755)  time: 0.3489  data: 0.0010  max mem: 2500
Train: Epoch[3/5]  [2210/4579]  eta: 0:13:42  Lr: 0.001875  Loss: -0.2510  Acc@1: 68.7500 (64.3176)  Acc@5: 93.7500 (91.4829)  time: 0.3494  data: 0.0018  max mem: 2500
Train: Epoch[3/5]  [2220/4579]  eta: 0:13:38  Lr: 0.001875  Loss: -0.0321  Acc@1: 68.7500 (64.3404)  Acc@5: 93.7500 (91.5016)  time: 0.3477  data: 0.0012  max mem: 2500
Train: Epoch[3/5]  [2230/4579]  eta: 0:13:35  Lr: 0.001875  Loss: -0.3068  Acc@1: 62.5000 (64.3237)  Acc@5: 93.7500 (91.4976)  time: 0.3469  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2240/4579]  eta: 0:13:32  Lr: 0.001875  Loss: 0.6351  Acc@1: 62.5000 (64.3268)  Acc@5: 93.7500 (91.5049)  time: 0.3467  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [2250/4579]  eta: 0:13:28  Lr: 0.001875  Loss: 0.2830  Acc@1: 62.5000 (64.3297)  Acc@5: 93.7500 (91.5121)  time: 0.3474  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [2260/4579]  eta: 0:13:25  Lr: 0.001875  Loss: -0.4663  Acc@1: 62.5000 (64.3244)  Acc@5: 93.7500 (91.5192)  time: 0.3468  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [2270/4579]  eta: 0:13:21  Lr: 0.001875  Loss: 0.2391  Acc@1: 62.5000 (64.3026)  Acc@5: 93.7500 (91.5070)  time: 0.3475  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [2280/4579]  eta: 0:13:18  Lr: 0.001875  Loss: 0.2368  Acc@1: 56.2500 (64.2892)  Acc@5: 87.5000 (91.4922)  time: 0.3488  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [2290/4579]  eta: 0:13:14  Lr: 0.001875  Loss: 0.2400  Acc@1: 62.5000 (64.2842)  Acc@5: 87.5000 (91.4939)  time: 0.3474  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [2300/4579]  eta: 0:13:11  Lr: 0.001875  Loss: -0.4112  Acc@1: 68.7500 (64.2954)  Acc@5: 87.5000 (91.4820)  time: 0.3473  data: 0.0011  max mem: 2500
Train: Epoch[3/5]  [2310/4579]  eta: 0:13:07  Lr: 0.001875  Loss: -0.8557  Acc@1: 68.7500 (64.2849)  Acc@5: 87.5000 (91.4810)  time: 0.3486  data: 0.0021  max mem: 2500
Train: Epoch[3/5]  [2320/4579]  eta: 0:13:04  Lr: 0.001875  Loss: 0.0097  Acc@1: 62.5000 (64.2773)  Acc@5: 93.7500 (91.4827)  time: 0.3483  data: 0.0016  max mem: 2500
Train: Epoch[3/5]  [2330/4579]  eta: 0:13:00  Lr: 0.001875  Loss: -0.1007  Acc@1: 62.5000 (64.2804)  Acc@5: 93.7500 (91.4763)  time: 0.3479  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [2340/4579]  eta: 0:12:57  Lr: 0.001875  Loss: -0.3987  Acc@1: 68.7500 (64.2914)  Acc@5: 87.5000 (91.4673)  time: 0.3467  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [2350/4579]  eta: 0:12:53  Lr: 0.001875  Loss: 0.5261  Acc@1: 68.7500 (64.2998)  Acc@5: 87.5000 (91.4717)  time: 0.3469  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [2360/4579]  eta: 0:12:50  Lr: 0.001875  Loss: 0.8682  Acc@1: 62.5000 (64.2948)  Acc@5: 93.7500 (91.4628)  time: 0.3472  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [2370/4579]  eta: 0:12:46  Lr: 0.001875  Loss: -0.1501  Acc@1: 68.7500 (64.3373)  Acc@5: 93.7500 (91.4725)  time: 0.3459  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2380/4579]  eta: 0:12:43  Lr: 0.001875  Loss: 0.3048  Acc@1: 62.5000 (64.3138)  Acc@5: 93.7500 (91.4558)  time: 0.3454  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [2390/4579]  eta: 0:12:39  Lr: 0.001875  Loss: -0.3538  Acc@1: 62.5000 (64.3167)  Acc@5: 87.5000 (91.4575)  time: 0.3472  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [2400/4579]  eta: 0:12:36  Lr: 0.001875  Loss: -0.0382  Acc@1: 68.7500 (64.3196)  Acc@5: 93.7500 (91.4567)  time: 0.3472  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [2410/4579]  eta: 0:12:33  Lr: 0.001875  Loss: 0.2295  Acc@1: 68.7500 (64.3016)  Acc@5: 93.7500 (91.4662)  time: 0.3469  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [2420/4579]  eta: 0:12:29  Lr: 0.001875  Loss: 0.3036  Acc@1: 62.5000 (64.3123)  Acc@5: 93.7500 (91.4705)  time: 0.3482  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [2430/4579]  eta: 0:12:26  Lr: 0.001875  Loss: 0.1172  Acc@1: 62.5000 (64.3151)  Acc@5: 93.7500 (91.4696)  time: 0.3471  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [2440/4579]  eta: 0:12:22  Lr: 0.001875  Loss: 0.1953  Acc@1: 62.5000 (64.3230)  Acc@5: 87.5000 (91.4712)  time: 0.3470  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [2450/4579]  eta: 0:12:19  Lr: 0.001875  Loss: 0.1786  Acc@1: 62.5000 (64.3411)  Acc@5: 93.7500 (91.4703)  time: 0.3487  data: 0.0010  max mem: 2500
Train: Epoch[3/5]  [2460/4579]  eta: 0:12:15  Lr: 0.001875  Loss: -0.2136  Acc@1: 62.5000 (64.3209)  Acc@5: 93.7500 (91.4745)  time: 0.3485  data: 0.0013  max mem: 2500
Train: Epoch[3/5]  [2470/4579]  eta: 0:12:12  Lr: 0.001875  Loss: 0.1010  Acc@1: 62.5000 (64.3135)  Acc@5: 93.7500 (91.4711)  time: 0.3469  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [2480/4579]  eta: 0:12:08  Lr: 0.001875  Loss: 0.2952  Acc@1: 68.7500 (64.3213)  Acc@5: 87.5000 (91.4551)  time: 0.3477  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [2490/4579]  eta: 0:12:05  Lr: 0.001875  Loss: -0.0071  Acc@1: 62.5000 (64.3140)  Acc@5: 87.5000 (91.4492)  time: 0.3484  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [2500/4579]  eta: 0:12:01  Lr: 0.001875  Loss: 0.5574  Acc@1: 62.5000 (64.3243)  Acc@5: 87.5000 (91.4434)  time: 0.3471  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [2510/4579]  eta: 0:11:58  Lr: 0.001875  Loss: 0.2636  Acc@1: 62.5000 (64.2896)  Acc@5: 93.7500 (91.4501)  time: 0.3466  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2520/4579]  eta: 0:11:54  Lr: 0.001875  Loss: 0.4532  Acc@1: 62.5000 (64.3024)  Acc@5: 93.7500 (91.4642)  time: 0.3468  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [2530/4579]  eta: 0:11:51  Lr: 0.001875  Loss: -0.0296  Acc@1: 68.7500 (64.3076)  Acc@5: 93.7500 (91.4683)  time: 0.3461  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [2540/4579]  eta: 0:11:47  Lr: 0.001875  Loss: 0.5372  Acc@1: 68.7500 (64.3201)  Acc@5: 87.5000 (91.4674)  time: 0.3471  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [2550/4579]  eta: 0:11:44  Lr: 0.001875  Loss: 0.0298  Acc@1: 62.5000 (64.2959)  Acc@5: 93.7500 (91.4715)  time: 0.3486  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [2560/4579]  eta: 0:11:40  Lr: 0.001875  Loss: -0.2683  Acc@1: 62.5000 (64.2962)  Acc@5: 93.7500 (91.4609)  time: 0.3469  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [2570/4579]  eta: 0:11:37  Lr: 0.001875  Loss: -0.1492  Acc@1: 62.5000 (64.3086)  Acc@5: 93.7500 (91.4673)  time: 0.3481  data: 0.0019  max mem: 2500
Train: Epoch[3/5]  [2580/4579]  eta: 0:11:34  Lr: 0.001875  Loss: -0.2140  Acc@1: 62.5000 (64.2919)  Acc@5: 87.5000 (91.4520)  time: 0.3485  data: 0.0018  max mem: 2500
Train: Epoch[3/5]  [2590/4579]  eta: 0:11:30  Lr: 0.001875  Loss: 0.1650  Acc@1: 62.5000 (64.2874)  Acc@5: 93.7500 (91.4608)  time: 0.3470  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2600/4579]  eta: 0:11:27  Lr: 0.001875  Loss: -0.6504  Acc@1: 68.7500 (64.3190)  Acc@5: 93.7500 (91.4648)  time: 0.3479  data: 0.0019  max mem: 2500
Train: Epoch[3/5]  [2610/4579]  eta: 0:11:23  Lr: 0.001875  Loss: 0.5125  Acc@1: 68.7500 (64.3025)  Acc@5: 93.7500 (91.4712)  time: 0.3475  data: 0.0019  max mem: 2500
Train: Epoch[3/5]  [2620/4579]  eta: 0:11:20  Lr: 0.001875  Loss: -0.5008  Acc@1: 68.7500 (64.3266)  Acc@5: 93.7500 (91.4703)  time: 0.3473  data: 0.0012  max mem: 2500
Train: Epoch[3/5]  [2630/4579]  eta: 0:11:16  Lr: 0.001875  Loss: -0.4253  Acc@1: 75.0000 (64.3505)  Acc@5: 93.7500 (91.4719)  time: 0.3469  data: 0.0012  max mem: 2500
Train: Epoch[3/5]  [2640/4579]  eta: 0:11:13  Lr: 0.001875  Loss: -0.3417  Acc@1: 62.5000 (64.3364)  Acc@5: 87.5000 (91.4592)  time: 0.3466  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2650/4579]  eta: 0:11:09  Lr: 0.001875  Loss: 0.6394  Acc@1: 62.5000 (64.3531)  Acc@5: 87.5000 (91.4561)  time: 0.3475  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [2660/4579]  eta: 0:11:06  Lr: 0.001875  Loss: -0.2035  Acc@1: 62.5000 (64.3414)  Acc@5: 93.7500 (91.4576)  time: 0.3468  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [2670/4579]  eta: 0:11:02  Lr: 0.001875  Loss: -0.4828  Acc@1: 62.5000 (64.3579)  Acc@5: 93.7500 (91.4756)  time: 0.3460  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [2680/4579]  eta: 0:10:59  Lr: 0.001875  Loss: 0.1180  Acc@1: 68.7500 (64.3673)  Acc@5: 93.7500 (91.4794)  time: 0.3456  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [2690/4579]  eta: 0:10:55  Lr: 0.001875  Loss: -0.6634  Acc@1: 68.7500 (64.3836)  Acc@5: 93.7500 (91.4832)  time: 0.3450  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [2700/4579]  eta: 0:10:52  Lr: 0.001875  Loss: -0.1791  Acc@1: 68.7500 (64.4067)  Acc@5: 87.5000 (91.4823)  time: 0.3469  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [2710/4579]  eta: 0:10:48  Lr: 0.001875  Loss: -0.4453  Acc@1: 68.7500 (64.3951)  Acc@5: 93.7500 (91.4884)  time: 0.3475  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [2720/4579]  eta: 0:10:45  Lr: 0.001875  Loss: -0.0420  Acc@1: 62.5000 (64.3904)  Acc@5: 93.7500 (91.4921)  time: 0.3463  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [2730/4579]  eta: 0:10:41  Lr: 0.001875  Loss: 0.1147  Acc@1: 62.5000 (64.3835)  Acc@5: 93.7500 (91.4958)  time: 0.3460  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [2740/4579]  eta: 0:10:38  Lr: 0.001875  Loss: -0.3581  Acc@1: 62.5000 (64.3812)  Acc@5: 93.7500 (91.4972)  time: 0.3465  data: 0.0011  max mem: 2500
Train: Epoch[3/5]  [2750/4579]  eta: 0:10:34  Lr: 0.001875  Loss: 0.1972  Acc@1: 62.5000 (64.3698)  Acc@5: 87.5000 (91.4826)  time: 0.3469  data: 0.0011  max mem: 2500
Train: Epoch[3/5]  [2760/4579]  eta: 0:10:31  Lr: 0.001875  Loss: 0.3680  Acc@1: 62.5000 (64.3562)  Acc@5: 87.5000 (91.4841)  time: 0.3460  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [2770/4579]  eta: 0:10:27  Lr: 0.001875  Loss: 0.1204  Acc@1: 68.7500 (64.3585)  Acc@5: 87.5000 (91.4674)  time: 0.3463  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2780/4579]  eta: 0:10:24  Lr: 0.001875  Loss: 0.1849  Acc@1: 62.5000 (64.3608)  Acc@5: 87.5000 (91.4689)  time: 0.3467  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2790/4579]  eta: 0:10:21  Lr: 0.001875  Loss: 0.2201  Acc@1: 62.5000 (64.3452)  Acc@5: 87.5000 (91.4502)  time: 0.3462  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [2800/4579]  eta: 0:10:17  Lr: 0.001875  Loss: -0.0431  Acc@1: 62.5000 (64.3632)  Acc@5: 87.5000 (91.4473)  time: 0.3463  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [2810/4579]  eta: 0:10:14  Lr: 0.001875  Loss: -0.2984  Acc@1: 68.7500 (64.3832)  Acc@5: 93.7500 (91.4599)  time: 0.3467  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2820/4579]  eta: 0:10:10  Lr: 0.001875  Loss: -0.0334  Acc@1: 68.7500 (64.3655)  Acc@5: 93.7500 (91.4525)  time: 0.3465  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2830/4579]  eta: 0:10:07  Lr: 0.001875  Loss: 0.5212  Acc@1: 62.5000 (64.3611)  Acc@5: 93.7500 (91.4540)  time: 0.3468  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [2840/4579]  eta: 0:10:03  Lr: 0.001875  Loss: -0.9102  Acc@1: 68.7500 (64.3831)  Acc@5: 93.7500 (91.4555)  time: 0.3461  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [2850/4579]  eta: 0:10:00  Lr: 0.001875  Loss: -0.3308  Acc@1: 68.7500 (64.3941)  Acc@5: 93.7500 (91.4569)  time: 0.3448  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2860/4579]  eta: 0:09:56  Lr: 0.001875  Loss: -0.0995  Acc@1: 68.7500 (64.3984)  Acc@5: 93.7500 (91.4584)  time: 0.3450  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [2870/4579]  eta: 0:09:53  Lr: 0.001875  Loss: 0.0764  Acc@1: 62.5000 (64.4048)  Acc@5: 93.7500 (91.4577)  time: 0.3457  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [2880/4579]  eta: 0:09:49  Lr: 0.001875  Loss: -0.2106  Acc@1: 62.5000 (64.4026)  Acc@5: 87.5000 (91.4396)  time: 0.3471  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2890/4579]  eta: 0:09:46  Lr: 0.001875  Loss: -0.2749  Acc@1: 68.7500 (64.4111)  Acc@5: 87.5000 (91.4325)  time: 0.3476  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2900/4579]  eta: 0:09:42  Lr: 0.001875  Loss: -0.0634  Acc@1: 62.5000 (64.4067)  Acc@5: 87.5000 (91.4297)  time: 0.3467  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [2910/4579]  eta: 0:09:39  Lr: 0.001875  Loss: 0.1091  Acc@1: 62.5000 (64.3872)  Acc@5: 87.5000 (91.4291)  time: 0.3466  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [2920/4579]  eta: 0:09:35  Lr: 0.001875  Loss: 0.3544  Acc@1: 56.2500 (64.3722)  Acc@5: 87.5000 (91.4220)  time: 0.3478  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [2930/4579]  eta: 0:09:32  Lr: 0.001875  Loss: -0.2185  Acc@1: 62.5000 (64.3637)  Acc@5: 93.7500 (91.4321)  time: 0.3470  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [2940/4579]  eta: 0:09:28  Lr: 0.001875  Loss: 0.0443  Acc@1: 62.5000 (64.3701)  Acc@5: 93.7500 (91.4230)  time: 0.3468  data: 0.0011  max mem: 2500
Train: Epoch[3/5]  [2950/4579]  eta: 0:09:25  Lr: 0.001875  Loss: -0.0465  Acc@1: 68.7500 (64.3913)  Acc@5: 93.7500 (91.4351)  time: 0.3483  data: 0.0011  max mem: 2500
Train: Epoch[3/5]  [2960/4579]  eta: 0:09:21  Lr: 0.001875  Loss: 0.4462  Acc@1: 68.7500 (64.4060)  Acc@5: 93.7500 (91.4450)  time: 0.3466  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2970/4579]  eta: 0:09:18  Lr: 0.001875  Loss: 0.0864  Acc@1: 62.5000 (64.4101)  Acc@5: 93.7500 (91.4486)  time: 0.3472  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [2980/4579]  eta: 0:09:15  Lr: 0.001875  Loss: 0.4610  Acc@1: 62.5000 (64.4058)  Acc@5: 93.7500 (91.4542)  time: 0.3503  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [2990/4579]  eta: 0:09:11  Lr: 0.001875  Loss: 0.2292  Acc@1: 62.5000 (64.4099)  Acc@5: 87.5000 (91.4452)  time: 0.3488  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [3000/4579]  eta: 0:09:08  Lr: 0.001875  Loss: 0.8287  Acc@1: 68.7500 (64.4223)  Acc@5: 93.7500 (91.4549)  time: 0.3464  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [3010/4579]  eta: 0:09:04  Lr: 0.001875  Loss: 0.6645  Acc@1: 68.7500 (64.4242)  Acc@5: 93.7500 (91.4501)  time: 0.3462  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [3020/4579]  eta: 0:09:01  Lr: 0.001875  Loss: -0.8638  Acc@1: 68.7500 (64.4385)  Acc@5: 93.7500 (91.4556)  time: 0.3460  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [3030/4579]  eta: 0:08:57  Lr: 0.001875  Loss: 0.3937  Acc@1: 62.5000 (64.4342)  Acc@5: 93.7500 (91.4467)  time: 0.3458  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3040/4579]  eta: 0:08:54  Lr: 0.001875  Loss: -0.2577  Acc@1: 62.5000 (64.4402)  Acc@5: 87.5000 (91.4522)  time: 0.3460  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [3050/4579]  eta: 0:08:50  Lr: 0.001875  Loss: 0.0213  Acc@1: 62.5000 (64.4276)  Acc@5: 93.7500 (91.4495)  time: 0.3477  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [3060/4579]  eta: 0:08:47  Lr: 0.001875  Loss: -0.2116  Acc@1: 62.5000 (64.4234)  Acc@5: 87.5000 (91.4427)  time: 0.3485  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [3070/4579]  eta: 0:08:43  Lr: 0.001875  Loss: 0.6429  Acc@1: 68.7500 (64.4436)  Acc@5: 93.7500 (91.4442)  time: 0.3474  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [3080/4579]  eta: 0:08:40  Lr: 0.001875  Loss: -0.1155  Acc@1: 75.0000 (64.4860)  Acc@5: 93.7500 (91.4476)  time: 0.3464  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [3090/4579]  eta: 0:08:36  Lr: 0.001875  Loss: -0.8060  Acc@1: 75.0000 (64.5119)  Acc@5: 93.7500 (91.4449)  time: 0.3452  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [3100/4579]  eta: 0:08:33  Lr: 0.001875  Loss: -0.0968  Acc@1: 68.7500 (64.4893)  Acc@5: 93.7500 (91.4584)  time: 0.3461  data: 0.0009  max mem: 2500
Train: Epoch[3/5]  [3110/4579]  eta: 0:08:29  Lr: 0.001875  Loss: -0.6756  Acc@1: 62.5000 (64.5231)  Acc@5: 100.0000 (91.4778)  time: 0.3472  data: 0.0009  max mem: 2500
Train: Epoch[3/5]  [3120/4579]  eta: 0:08:26  Lr: 0.001875  Loss: -0.6446  Acc@1: 75.0000 (64.5186)  Acc@5: 93.7500 (91.4731)  time: 0.3465  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [3130/4579]  eta: 0:08:22  Lr: 0.001875  Loss: 0.1702  Acc@1: 62.5000 (64.5181)  Acc@5: 93.7500 (91.4784)  time: 0.3468  data: 0.0009  max mem: 2500
Train: Epoch[3/5]  [3140/4579]  eta: 0:08:19  Lr: 0.001875  Loss: -0.3960  Acc@1: 68.7500 (64.5316)  Acc@5: 93.7500 (91.4756)  time: 0.3476  data: 0.0017  max mem: 2500
Train: Epoch[3/5]  [3150/4579]  eta: 0:08:16  Lr: 0.001875  Loss: -0.4237  Acc@1: 68.7500 (64.5331)  Acc@5: 93.7500 (91.4749)  time: 0.3475  data: 0.0014  max mem: 2500
Train: Epoch[3/5]  [3160/4579]  eta: 0:08:12  Lr: 0.001875  Loss: 0.1561  Acc@1: 68.7500 (64.5425)  Acc@5: 93.7500 (91.4782)  time: 0.3466  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [3170/4579]  eta: 0:08:09  Lr: 0.001875  Loss: -0.4688  Acc@1: 56.2500 (64.5163)  Acc@5: 93.7500 (91.4715)  time: 0.3460  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3180/4579]  eta: 0:08:05  Lr: 0.001875  Loss: -0.1422  Acc@1: 56.2500 (64.5178)  Acc@5: 87.5000 (91.4649)  time: 0.3461  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [3190/4579]  eta: 0:08:02  Lr: 0.001875  Loss: -0.5974  Acc@1: 68.7500 (64.5409)  Acc@5: 93.7500 (91.4721)  time: 0.3464  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [3200/4579]  eta: 0:07:58  Lr: 0.001875  Loss: -0.5984  Acc@1: 68.7500 (64.5326)  Acc@5: 93.7500 (91.4773)  time: 0.3469  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [3210/4579]  eta: 0:07:55  Lr: 0.001875  Loss: -0.1365  Acc@1: 62.5000 (64.5360)  Acc@5: 93.7500 (91.4805)  time: 0.3472  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3220/4579]  eta: 0:07:51  Lr: 0.001875  Loss: -0.5383  Acc@1: 68.7500 (64.5316)  Acc@5: 93.7500 (91.4875)  time: 0.3472  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [3230/4579]  eta: 0:07:48  Lr: 0.001875  Loss: 0.1822  Acc@1: 68.7500 (64.5330)  Acc@5: 93.7500 (91.4906)  time: 0.3484  data: 0.0013  max mem: 2500
Train: Epoch[3/5]  [3240/4579]  eta: 0:07:44  Lr: 0.001875  Loss: 0.0793  Acc@1: 62.5000 (64.5364)  Acc@5: 93.7500 (91.4899)  time: 0.3478  data: 0.0011  max mem: 2500
Train: Epoch[3/5]  [3250/4579]  eta: 0:07:41  Lr: 0.001875  Loss: -0.1981  Acc@1: 68.7500 (64.5590)  Acc@5: 93.7500 (91.5007)  time: 0.3468  data: 0.0015  max mem: 2500
Train: Epoch[3/5]  [3260/4579]  eta: 0:07:37  Lr: 0.001875  Loss: -0.4094  Acc@1: 68.7500 (64.5603)  Acc@5: 93.7500 (91.4942)  time: 0.3472  data: 0.0015  max mem: 2500
Train: Epoch[3/5]  [3270/4579]  eta: 0:07:34  Lr: 0.001875  Loss: 0.2248  Acc@1: 62.5000 (64.5617)  Acc@5: 93.7500 (91.4992)  time: 0.3461  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [3280/4579]  eta: 0:07:30  Lr: 0.001875  Loss: -0.1676  Acc@1: 62.5000 (64.5649)  Acc@5: 93.7500 (91.5041)  time: 0.3462  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [3290/4579]  eta: 0:07:27  Lr: 0.001875  Loss: 0.1644  Acc@1: 68.7500 (64.5814)  Acc@5: 93.7500 (91.5014)  time: 0.3469  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3300/4579]  eta: 0:07:23  Lr: 0.001875  Loss: -0.3956  Acc@1: 68.7500 (64.5922)  Acc@5: 93.7500 (91.5101)  time: 0.3471  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3310/4579]  eta: 0:07:20  Lr: 0.001875  Loss: -0.5661  Acc@1: 62.5000 (64.5726)  Acc@5: 93.7500 (91.4980)  time: 0.3472  data: 0.0010  max mem: 2500
Train: Epoch[3/5]  [3320/4579]  eta: 0:07:17  Lr: 0.001875  Loss: -0.0167  Acc@1: 62.5000 (64.5758)  Acc@5: 93.7500 (91.5048)  time: 0.3476  data: 0.0011  max mem: 2500
Train: Epoch[3/5]  [3330/4579]  eta: 0:07:13  Lr: 0.001875  Loss: 0.1671  Acc@1: 62.5000 (64.5733)  Acc@5: 93.7500 (91.4928)  time: 0.3476  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [3340/4579]  eta: 0:07:10  Lr: 0.001875  Loss: -0.0050  Acc@1: 68.7500 (64.5840)  Acc@5: 87.5000 (91.4939)  time: 0.3471  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [3350/4579]  eta: 0:07:06  Lr: 0.001875  Loss: -0.0607  Acc@1: 68.7500 (64.5889)  Acc@5: 93.7500 (91.5007)  time: 0.3480  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [3360/4579]  eta: 0:07:03  Lr: 0.001875  Loss: 0.3217  Acc@1: 68.7500 (64.5864)  Acc@5: 93.7500 (91.4850)  time: 0.3482  data: 0.0013  max mem: 2500
Train: Epoch[3/5]  [3370/4579]  eta: 0:06:59  Lr: 0.001875  Loss: -0.2432  Acc@1: 68.7500 (64.6099)  Acc@5: 87.5000 (91.4881)  time: 0.3478  data: 0.0014  max mem: 2500
Train: Epoch[3/5]  [3380/4579]  eta: 0:06:56  Lr: 0.001875  Loss: 0.3930  Acc@1: 68.7500 (64.5963)  Acc@5: 93.7500 (91.4948)  time: 0.3489  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [3390/4579]  eta: 0:06:52  Lr: 0.001875  Loss: -0.0190  Acc@1: 62.5000 (64.5993)  Acc@5: 93.7500 (91.4959)  time: 0.3477  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [3400/4579]  eta: 0:06:49  Lr: 0.001875  Loss: 0.1533  Acc@1: 62.5000 (64.5931)  Acc@5: 93.7500 (91.4951)  time: 0.3474  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [3410/4579]  eta: 0:06:45  Lr: 0.001875  Loss: -0.0142  Acc@1: 62.5000 (64.6017)  Acc@5: 93.7500 (91.4908)  time: 0.3479  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [3420/4579]  eta: 0:06:42  Lr: 0.001875  Loss: 0.0338  Acc@1: 68.7500 (64.6101)  Acc@5: 93.7500 (91.4955)  time: 0.3475  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [3430/4579]  eta: 0:06:38  Lr: 0.001875  Loss: -0.3854  Acc@1: 68.7500 (64.6131)  Acc@5: 93.7500 (91.4948)  time: 0.3482  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [3440/4579]  eta: 0:06:35  Lr: 0.001875  Loss: 0.4624  Acc@1: 68.7500 (64.6142)  Acc@5: 87.5000 (91.4905)  time: 0.3468  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [3450/4579]  eta: 0:06:31  Lr: 0.001875  Loss: -0.0594  Acc@1: 62.5000 (64.6244)  Acc@5: 93.7500 (91.4988)  time: 0.3460  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [3460/4579]  eta: 0:06:28  Lr: 0.001875  Loss: -0.1619  Acc@1: 68.7500 (64.6345)  Acc@5: 93.7500 (91.4963)  time: 0.3457  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3470/4579]  eta: 0:06:24  Lr: 0.001875  Loss: 0.1694  Acc@1: 62.5000 (64.6175)  Acc@5: 87.5000 (91.4884)  time: 0.3461  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [3480/4579]  eta: 0:06:21  Lr: 0.001875  Loss: -0.3457  Acc@1: 62.5000 (64.6312)  Acc@5: 93.7500 (91.4967)  time: 0.3468  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [3490/4579]  eta: 0:06:18  Lr: 0.001875  Loss: -0.4594  Acc@1: 62.5000 (64.6394)  Acc@5: 93.7500 (91.5032)  time: 0.3465  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [3500/4579]  eta: 0:06:14  Lr: 0.001875  Loss: 0.2587  Acc@1: 62.5000 (64.6173)  Acc@5: 87.5000 (91.4881)  time: 0.3465  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [3510/4579]  eta: 0:06:11  Lr: 0.001875  Loss: -0.0967  Acc@1: 62.5000 (64.6415)  Acc@5: 93.7500 (91.5017)  time: 0.3471  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [3520/4579]  eta: 0:06:07  Lr: 0.001875  Loss: -0.2341  Acc@1: 68.7500 (64.6461)  Acc@5: 93.7500 (91.5028)  time: 0.3478  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [3530/4579]  eta: 0:06:04  Lr: 0.001875  Loss: -0.2614  Acc@1: 62.5000 (64.6400)  Acc@5: 87.5000 (91.4914)  time: 0.3480  data: 0.0020  max mem: 2500
Train: Epoch[3/5]  [3540/4579]  eta: 0:06:00  Lr: 0.001875  Loss: 0.0619  Acc@1: 62.5000 (64.6322)  Acc@5: 93.7500 (91.4978)  time: 0.3476  data: 0.0021  max mem: 2500
Train: Epoch[3/5]  [3550/4579]  eta: 0:05:57  Lr: 0.001875  Loss: 0.1328  Acc@1: 62.5000 (64.6314)  Acc@5: 93.7500 (91.4954)  time: 0.3480  data: 0.0011  max mem: 2500
Train: Epoch[3/5]  [3560/4579]  eta: 0:05:53  Lr: 0.001875  Loss: 0.1336  Acc@1: 68.7500 (64.6219)  Acc@5: 93.7500 (91.4982)  time: 0.3482  data: 0.0009  max mem: 2500
Train: Epoch[3/5]  [3570/4579]  eta: 0:05:50  Lr: 0.001875  Loss: 0.2740  Acc@1: 56.2500 (64.6038)  Acc@5: 93.7500 (91.4905)  time: 0.3465  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [3580/4579]  eta: 0:05:46  Lr: 0.001875  Loss: 0.0297  Acc@1: 56.2500 (64.6049)  Acc@5: 93.7500 (91.4985)  time: 0.3476  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [3590/4579]  eta: 0:05:43  Lr: 0.001875  Loss: 0.1132  Acc@1: 68.7500 (64.6164)  Acc@5: 93.7500 (91.5118)  time: 0.3482  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [3600/4579]  eta: 0:05:39  Lr: 0.001875  Loss: 0.2196  Acc@1: 68.7500 (64.6175)  Acc@5: 93.7500 (91.5058)  time: 0.3479  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [3610/4579]  eta: 0:05:36  Lr: 0.001875  Loss: 0.3642  Acc@1: 62.5000 (64.6255)  Acc@5: 93.7500 (91.5155)  time: 0.3481  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [3620/4579]  eta: 0:05:32  Lr: 0.001875  Loss: 0.2027  Acc@1: 62.5000 (64.6265)  Acc@5: 93.7500 (91.5182)  time: 0.3468  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [3630/4579]  eta: 0:05:29  Lr: 0.001875  Loss: -0.4111  Acc@1: 68.7500 (64.6344)  Acc@5: 93.7500 (91.5158)  time: 0.3476  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [3640/4579]  eta: 0:05:25  Lr: 0.001875  Loss: 0.9812  Acc@1: 68.7500 (64.6440)  Acc@5: 93.7500 (91.5168)  time: 0.3489  data: 0.0013  max mem: 2500
Train: Epoch[3/5]  [3650/4579]  eta: 0:05:22  Lr: 0.001875  Loss: -0.2921  Acc@1: 62.5000 (64.6364)  Acc@5: 93.7500 (91.5177)  time: 0.3475  data: 0.0013  max mem: 2500
Train: Epoch[3/5]  [3660/4579]  eta: 0:05:19  Lr: 0.001875  Loss: -0.3837  Acc@1: 62.5000 (64.6374)  Acc@5: 93.7500 (91.5119)  time: 0.3471  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3670/4579]  eta: 0:05:15  Lr: 0.001875  Loss: 0.7398  Acc@1: 62.5000 (64.6128)  Acc@5: 93.7500 (91.5061)  time: 0.3467  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3680/4579]  eta: 0:05:12  Lr: 0.001875  Loss: 0.1226  Acc@1: 56.2500 (64.6241)  Acc@5: 93.7500 (91.5088)  time: 0.3459  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3690/4579]  eta: 0:05:08  Lr: 0.001875  Loss: -0.1369  Acc@1: 68.7500 (64.6505)  Acc@5: 93.7500 (91.5216)  time: 0.3468  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [3700/4579]  eta: 0:05:05  Lr: 0.001875  Loss: 0.4649  Acc@1: 68.7500 (64.6447)  Acc@5: 93.7500 (91.5175)  time: 0.3456  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [3710/4579]  eta: 0:05:01  Lr: 0.001875  Loss: -0.6485  Acc@1: 62.5000 (64.6322)  Acc@5: 87.5000 (91.5151)  time: 0.3456  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3720/4579]  eta: 0:04:58  Lr: 0.001875  Loss: -0.3446  Acc@1: 62.5000 (64.6332)  Acc@5: 87.5000 (91.5110)  time: 0.3466  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3730/4579]  eta: 0:04:54  Lr: 0.001875  Loss: -0.5258  Acc@1: 62.5000 (64.6241)  Acc@5: 93.7500 (91.5204)  time: 0.3474  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [3740/4579]  eta: 0:04:51  Lr: 0.001875  Loss: 0.7589  Acc@1: 56.2500 (64.5967)  Acc@5: 93.7500 (91.5096)  time: 0.3473  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [3750/4579]  eta: 0:04:47  Lr: 0.001875  Loss: -0.8117  Acc@1: 62.5000 (64.6128)  Acc@5: 93.7500 (91.5089)  time: 0.3461  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [3760/4579]  eta: 0:04:44  Lr: 0.001875  Loss: -0.5298  Acc@1: 68.7500 (64.6121)  Acc@5: 93.7500 (91.5132)  time: 0.3471  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [3770/4579]  eta: 0:04:40  Lr: 0.001875  Loss: 0.0831  Acc@1: 62.5000 (64.6198)  Acc@5: 93.7500 (91.5225)  time: 0.3477  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [3780/4579]  eta: 0:04:37  Lr: 0.001875  Loss: 0.0554  Acc@1: 62.5000 (64.6109)  Acc@5: 93.7500 (91.5201)  time: 0.3467  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [3790/4579]  eta: 0:04:33  Lr: 0.001875  Loss: -0.0147  Acc@1: 62.5000 (64.6235)  Acc@5: 87.5000 (91.5227)  time: 0.3469  data: 0.0009  max mem: 2500
Train: Epoch[3/5]  [3800/4579]  eta: 0:04:30  Lr: 0.001875  Loss: -0.5300  Acc@1: 75.0000 (64.6261)  Acc@5: 93.7500 (91.5269)  time: 0.3469  data: 0.0009  max mem: 2500
Train: Epoch[3/5]  [3810/4579]  eta: 0:04:26  Lr: 0.001875  Loss: -0.2345  Acc@1: 62.5000 (64.6271)  Acc@5: 93.7500 (91.5262)  time: 0.3487  data: 0.0016  max mem: 2500
Train: Epoch[3/5]  [3820/4579]  eta: 0:04:23  Lr: 0.001875  Loss: 0.5350  Acc@1: 62.5000 (64.6248)  Acc@5: 87.5000 (91.5222)  time: 0.3502  data: 0.0029  max mem: 2500
Train: Epoch[3/5]  [3830/4579]  eta: 0:04:20  Lr: 0.001875  Loss: -0.3646  Acc@1: 68.7500 (64.6404)  Acc@5: 93.7500 (91.5362)  time: 0.3483  data: 0.0026  max mem: 2500
Train: Epoch[3/5]  [3840/4579]  eta: 0:04:16  Lr: 0.001875  Loss: -0.0954  Acc@1: 68.7500 (64.6349)  Acc@5: 93.7500 (91.5289)  time: 0.3485  data: 0.0013  max mem: 2500
Train: Epoch[3/5]  [3850/4579]  eta: 0:04:13  Lr: 0.001875  Loss: -0.2176  Acc@1: 62.5000 (64.6277)  Acc@5: 87.5000 (91.5298)  time: 0.3497  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [3860/4579]  eta: 0:04:09  Lr: 0.001875  Loss: 0.5671  Acc@1: 62.5000 (64.6335)  Acc@5: 93.7500 (91.5242)  time: 0.3474  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [3870/4579]  eta: 0:04:06  Lr: 0.001875  Loss: 0.1403  Acc@1: 62.5000 (64.6248)  Acc@5: 93.7500 (91.5219)  time: 0.3474  data: 0.0015  max mem: 2500
Train: Epoch[3/5]  [3880/4579]  eta: 0:04:02  Lr: 0.001875  Loss: -0.2776  Acc@1: 62.5000 (64.6274)  Acc@5: 93.7500 (91.5276)  time: 0.3490  data: 0.0016  max mem: 2500
Train: Epoch[3/5]  [3890/4579]  eta: 0:03:59  Lr: 0.001875  Loss: -0.9039  Acc@1: 62.5000 (64.6379)  Acc@5: 93.7500 (91.5301)  time: 0.3469  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [3900/4579]  eta: 0:03:55  Lr: 0.001875  Loss: -0.4609  Acc@1: 62.5000 (64.6549)  Acc@5: 93.7500 (91.5342)  time: 0.3470  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [3910/4579]  eta: 0:03:52  Lr: 0.001875  Loss: 0.5841  Acc@1: 62.5000 (64.6558)  Acc@5: 93.7500 (91.5367)  time: 0.3474  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [3920/4579]  eta: 0:03:48  Lr: 0.001875  Loss: -0.2929  Acc@1: 62.5000 (64.6662)  Acc@5: 93.7500 (91.5376)  time: 0.3469  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [3930/4579]  eta: 0:03:45  Lr: 0.001875  Loss: 0.4973  Acc@1: 62.5000 (64.6639)  Acc@5: 93.7500 (91.5368)  time: 0.3467  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [3940/4579]  eta: 0:03:41  Lr: 0.001875  Loss: -0.2591  Acc@1: 62.5000 (64.6679)  Acc@5: 93.7500 (91.5393)  time: 0.3460  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [3950/4579]  eta: 0:03:38  Lr: 0.001875  Loss: -0.4982  Acc@1: 68.7500 (64.6862)  Acc@5: 93.7500 (91.5417)  time: 0.3475  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [3960/4579]  eta: 0:03:34  Lr: 0.001875  Loss: 0.5833  Acc@1: 68.7500 (64.6838)  Acc@5: 93.7500 (91.5394)  time: 0.3476  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [3970/4579]  eta: 0:03:31  Lr: 0.001875  Loss: 0.1191  Acc@1: 62.5000 (64.6862)  Acc@5: 93.7500 (91.5481)  time: 0.3465  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [3980/4579]  eta: 0:03:27  Lr: 0.001875  Loss: 0.0680  Acc@1: 62.5000 (64.6948)  Acc@5: 93.7500 (91.5442)  time: 0.3463  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [3990/4579]  eta: 0:03:24  Lr: 0.001875  Loss: -0.1316  Acc@1: 62.5000 (64.6862)  Acc@5: 87.5000 (91.5341)  time: 0.3467  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [4000/4579]  eta: 0:03:20  Lr: 0.001875  Loss: 0.5057  Acc@1: 68.7500 (64.6963)  Acc@5: 87.5000 (91.5256)  time: 0.3474  data: 0.0014  max mem: 2500
Train: Epoch[3/5]  [4010/4579]  eta: 0:03:17  Lr: 0.001875  Loss: 0.1390  Acc@1: 68.7500 (64.6893)  Acc@5: 93.7500 (91.5280)  time: 0.3482  data: 0.0013  max mem: 2500
Train: Epoch[3/5]  [4020/4579]  eta: 0:03:14  Lr: 0.001875  Loss: 0.1675  Acc@1: 62.5000 (64.7025)  Acc@5: 87.5000 (91.5180)  time: 0.3507  data: 0.0013  max mem: 2500
Train: Epoch[3/5]  [4030/4579]  eta: 0:03:10  Lr: 0.001875  Loss: 0.5814  Acc@1: 62.5000 (64.6893)  Acc@5: 87.5000 (91.5204)  time: 0.3486  data: 0.0012  max mem: 2500
Train: Epoch[3/5]  [4040/4579]  eta: 0:03:07  Lr: 0.001875  Loss: -0.2655  Acc@1: 62.5000 (64.6993)  Acc@5: 93.7500 (91.5244)  time: 0.3464  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [4050/4579]  eta: 0:03:03  Lr: 0.001875  Loss: 0.2309  Acc@1: 62.5000 (64.7001)  Acc@5: 93.7500 (91.5299)  time: 0.3491  data: 0.0009  max mem: 2500
Train: Epoch[3/5]  [4060/4579]  eta: 0:03:00  Lr: 0.001875  Loss: -0.0508  Acc@1: 62.5000 (64.7054)  Acc@5: 93.7500 (91.5292)  time: 0.3487  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [4070/4579]  eta: 0:02:56  Lr: 0.001875  Loss: 0.4659  Acc@1: 62.5000 (64.6847)  Acc@5: 93.7500 (91.5270)  time: 0.3469  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [4080/4579]  eta: 0:02:53  Lr: 0.001875  Loss: 0.0482  Acc@1: 62.5000 (64.6946)  Acc@5: 93.7500 (91.5293)  time: 0.3479  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [4090/4579]  eta: 0:02:49  Lr: 0.001875  Loss: 0.2581  Acc@1: 68.7500 (64.6938)  Acc@5: 93.7500 (91.5271)  time: 0.3474  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [4100/4579]  eta: 0:02:46  Lr: 0.001875  Loss: 0.1204  Acc@1: 62.5000 (64.6976)  Acc@5: 93.7500 (91.5326)  time: 0.3464  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [4110/4579]  eta: 0:02:42  Lr: 0.001875  Loss: 0.3420  Acc@1: 62.5000 (64.7014)  Acc@5: 93.7500 (91.5303)  time: 0.3459  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [4120/4579]  eta: 0:02:39  Lr: 0.001875  Loss: -0.2320  Acc@1: 68.7500 (64.7052)  Acc@5: 93.7500 (91.5357)  time: 0.3486  data: 0.0013  max mem: 2500
Train: Epoch[3/5]  [4130/4579]  eta: 0:02:35  Lr: 0.001875  Loss: -0.2464  Acc@1: 62.5000 (64.7074)  Acc@5: 93.7500 (91.5320)  time: 0.3489  data: 0.0014  max mem: 2500
Train: Epoch[3/5]  [4140/4579]  eta: 0:02:32  Lr: 0.001875  Loss: 0.2011  Acc@1: 62.5000 (64.7051)  Acc@5: 93.7500 (91.5344)  time: 0.3459  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [4150/4579]  eta: 0:02:28  Lr: 0.001875  Loss: -0.5369  Acc@1: 68.7500 (64.7209)  Acc@5: 93.7500 (91.5337)  time: 0.3466  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [4160/4579]  eta: 0:02:25  Lr: 0.001875  Loss: 0.2316  Acc@1: 68.7500 (64.7245)  Acc@5: 93.7500 (91.5360)  time: 0.3472  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [4170/4579]  eta: 0:02:21  Lr: 0.001875  Loss: -0.0257  Acc@1: 62.5000 (64.7192)  Acc@5: 93.7500 (91.5353)  time: 0.3488  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [4180/4579]  eta: 0:02:18  Lr: 0.001875  Loss: -0.1130  Acc@1: 62.5000 (64.7199)  Acc@5: 93.7500 (91.5376)  time: 0.3481  data: 0.0012  max mem: 2500
Train: Epoch[3/5]  [4190/4579]  eta: 0:02:15  Lr: 0.001875  Loss: -0.5656  Acc@1: 68.7500 (64.7250)  Acc@5: 93.7500 (91.5354)  time: 0.3459  data: 0.0012  max mem: 2500
Train: Epoch[3/5]  [4200/4579]  eta: 0:02:11  Lr: 0.001875  Loss: -0.1349  Acc@1: 62.5000 (64.7167)  Acc@5: 93.7500 (91.5303)  time: 0.3453  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [4210/4579]  eta: 0:02:08  Lr: 0.001875  Loss: 0.4131  Acc@1: 62.5000 (64.7040)  Acc@5: 87.5000 (91.5296)  time: 0.3470  data: 0.0017  max mem: 2500
Train: Epoch[3/5]  [4220/4579]  eta: 0:02:04  Lr: 0.001875  Loss: 0.2424  Acc@1: 62.5000 (64.7210)  Acc@5: 93.7500 (91.5334)  time: 0.3474  data: 0.0021  max mem: 2500
Train: Epoch[3/5]  [4230/4579]  eta: 0:02:01  Lr: 0.001875  Loss: -0.4600  Acc@1: 68.7500 (64.7261)  Acc@5: 93.7500 (91.5342)  time: 0.3467  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [4240/4579]  eta: 0:01:57  Lr: 0.001875  Loss: 0.4352  Acc@1: 68.7500 (64.7371)  Acc@5: 93.7500 (91.5350)  time: 0.3472  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [4250/4579]  eta: 0:01:54  Lr: 0.001875  Loss: 0.0654  Acc@1: 68.7500 (64.7333)  Acc@5: 93.7500 (91.5358)  time: 0.3469  data: 0.0012  max mem: 2500
Train: Epoch[3/5]  [4260/4579]  eta: 0:01:50  Lr: 0.001875  Loss: -0.3755  Acc@1: 62.5000 (64.7310)  Acc@5: 93.7500 (91.5410)  time: 0.3462  data: 0.0011  max mem: 2500
Train: Epoch[3/5]  [4270/4579]  eta: 0:01:47  Lr: 0.001875  Loss: 0.3256  Acc@1: 62.5000 (64.7302)  Acc@5: 93.7500 (91.5418)  time: 0.3456  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [4280/4579]  eta: 0:01:43  Lr: 0.001875  Loss: 0.2503  Acc@1: 68.7500 (64.7322)  Acc@5: 93.7500 (91.5338)  time: 0.3460  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [4290/4579]  eta: 0:01:40  Lr: 0.001875  Loss: -0.5719  Acc@1: 68.7500 (64.7372)  Acc@5: 87.5000 (91.5317)  time: 0.3460  data: 0.0009  max mem: 2500
Train: Epoch[3/5]  [4300/4579]  eta: 0:01:36  Lr: 0.001875  Loss: -0.1305  Acc@1: 68.7500 (64.7466)  Acc@5: 93.7500 (91.5398)  time: 0.3467  data: 0.0009  max mem: 2500
Train: Epoch[3/5]  [4310/4579]  eta: 0:01:33  Lr: 0.001875  Loss: 0.4938  Acc@1: 62.5000 (64.7457)  Acc@5: 93.7500 (91.5449)  time: 0.3483  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [4320/4579]  eta: 0:01:29  Lr: 0.001875  Loss: 0.0498  Acc@1: 62.5000 (64.7420)  Acc@5: 93.7500 (91.5413)  time: 0.3488  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [4330/4579]  eta: 0:01:26  Lr: 0.001875  Loss: 0.0952  Acc@1: 62.5000 (64.7339)  Acc@5: 87.5000 (91.5435)  time: 0.3481  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [4340/4579]  eta: 0:01:22  Lr: 0.001875  Loss: 0.1593  Acc@1: 68.7500 (64.7460)  Acc@5: 93.7500 (91.5472)  time: 0.3482  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [4350/4579]  eta: 0:01:19  Lr: 0.001875  Loss: -0.0344  Acc@1: 62.5000 (64.7208)  Acc@5: 93.7500 (91.5407)  time: 0.3483  data: 0.0010  max mem: 2500
Train: Epoch[3/5]  [4360/4579]  eta: 0:01:16  Lr: 0.001875  Loss: -0.0748  Acc@1: 56.2500 (64.7271)  Acc@5: 93.7500 (91.5386)  time: 0.3486  data: 0.0018  max mem: 2500
Train: Epoch[3/5]  [4370/4579]  eta: 0:01:12  Lr: 0.001875  Loss: -0.2626  Acc@1: 62.5000 (64.7077)  Acc@5: 87.5000 (91.5323)  time: 0.3483  data: 0.0013  max mem: 2500
Train: Epoch[3/5]  [4380/4579]  eta: 0:01:09  Lr: 0.001875  Loss: 0.0806  Acc@1: 62.5000 (64.7027)  Acc@5: 87.5000 (91.5345)  time: 0.3475  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [4390/4579]  eta: 0:01:05  Lr: 0.001875  Loss: 0.3571  Acc@1: 62.5000 (64.7119)  Acc@5: 93.7500 (91.5310)  time: 0.3470  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [4400/4579]  eta: 0:01:02  Lr: 0.001875  Loss: 0.1416  Acc@1: 62.5000 (64.7097)  Acc@5: 93.7500 (91.5289)  time: 0.3472  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [4410/4579]  eta: 0:00:58  Lr: 0.001875  Loss: -0.4369  Acc@1: 56.2500 (64.6976)  Acc@5: 93.7500 (91.5311)  time: 0.3516  data: 0.0028  max mem: 2500
Train: Epoch[3/5]  [4420/4579]  eta: 0:00:55  Lr: 0.001875  Loss: -0.6133  Acc@1: 56.2500 (64.6927)  Acc@5: 87.5000 (91.5277)  time: 0.3512  data: 0.0028  max mem: 2500
Train: Epoch[3/5]  [4430/4579]  eta: 0:00:51  Lr: 0.001875  Loss: -0.0129  Acc@1: 62.5000 (64.6835)  Acc@5: 93.7500 (91.5228)  time: 0.3473  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [4440/4579]  eta: 0:00:48  Lr: 0.001875  Loss: 0.0237  Acc@1: 68.7500 (64.6898)  Acc@5: 93.7500 (91.5236)  time: 0.3458  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [4450/4579]  eta: 0:00:44  Lr: 0.001875  Loss: 0.5509  Acc@1: 68.7500 (64.6905)  Acc@5: 93.7500 (91.5258)  time: 0.3454  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [4460/4579]  eta: 0:00:41  Lr: 0.001875  Loss: -0.2429  Acc@1: 62.5000 (64.6940)  Acc@5: 93.7500 (91.5252)  time: 0.3469  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [4470/4579]  eta: 0:00:37  Lr: 0.001875  Loss: -0.3580  Acc@1: 68.7500 (64.7101)  Acc@5: 93.7500 (91.5329)  time: 0.3468  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [4480/4579]  eta: 0:00:34  Lr: 0.001875  Loss: -0.2913  Acc@1: 68.7500 (64.7205)  Acc@5: 93.7500 (91.5323)  time: 0.3470  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [4490/4579]  eta: 0:00:30  Lr: 0.001875  Loss: -0.2117  Acc@1: 62.5000 (64.7142)  Acc@5: 87.5000 (91.5275)  time: 0.3485  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [4500/4579]  eta: 0:00:27  Lr: 0.001875  Loss: -0.4517  Acc@1: 62.5000 (64.7120)  Acc@5: 87.5000 (91.5255)  time: 0.3469  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [4510/4579]  eta: 0:00:23  Lr: 0.001875  Loss: 0.3705  Acc@1: 62.5000 (64.7126)  Acc@5: 87.5000 (91.5207)  time: 0.3461  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [4520/4579]  eta: 0:00:20  Lr: 0.001875  Loss: -0.8872  Acc@1: 62.5000 (64.7257)  Acc@5: 87.5000 (91.5243)  time: 0.3481  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [4530/4579]  eta: 0:00:17  Lr: 0.001875  Loss: -0.2699  Acc@1: 68.7500 (64.7401)  Acc@5: 93.7500 (91.5292)  time: 0.3480  data: 0.0010  max mem: 2500
Train: Epoch[3/5]  [4540/4579]  eta: 0:00:13  Lr: 0.001875  Loss: -0.3764  Acc@1: 68.7500 (64.7531)  Acc@5: 93.7500 (91.5313)  time: 0.3471  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [4550/4579]  eta: 0:00:10  Lr: 0.001875  Loss: -0.0635  Acc@1: 62.5000 (64.7426)  Acc@5: 87.5000 (91.5280)  time: 0.3466  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [4560/4579]  eta: 0:00:06  Lr: 0.001875  Loss: 0.4066  Acc@1: 62.5000 (64.7432)  Acc@5: 93.7500 (91.5232)  time: 0.3473  data: 0.0009  max mem: 2500
Train: Epoch[3/5]  [4570/4579]  eta: 0:00:03  Lr: 0.001875  Loss: -0.4016  Acc@1: 62.5000 (64.7369)  Acc@5: 93.7500 (91.5213)  time: 0.3481  data: 0.0015  max mem: 2500
Train: Epoch[3/5]  [4578/4579]  eta: 0:00:00  Lr: 0.001875  Loss: -0.9219  Acc@1: 62.5000 (64.7392)  Acc@5: 93.7500 (91.5230)  time: 0.3408  data: 0.0012  max mem: 2500
Train: Epoch[3/5] Total time: 0:26:30 (0.3474 s / it)
{0: {0: 219771, 1: 0, 2: 0, 3: 0, 4: 0}, 1: {0: 219771, 1: 0, 2: 0, 3: 0, 4: 0}, 2: {0: 219771, 1: 0, 2: 0, 3: 0, 4: 0}, 3: {0: 219771, 1: 0, 2: 0, 3: 0, 4: 0}, 4: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 5: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 6: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 7: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 8: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 9: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 10: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 11: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 12: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 13: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 14: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 15: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 16: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 17: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 18: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 19: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}}
Averaged stats: Lr: 0.001875  Loss: -0.9219  Acc@1: 62.5000 (64.7392)  Acc@5: 93.7500 (91.5230)
Train: Epoch[4/5]  [   0/4579]  eta: 1:06:38  Lr: 0.001875  Loss: -0.0945  Acc@1: 75.0000 (75.0000)  Acc@5: 87.5000 (87.5000)  time: 0.8733  data: 0.5194  max mem: 2500
Train: Epoch[4/5]  [  10/4579]  eta: 0:29:58  Lr: 0.001875  Loss: 0.0692  Acc@1: 75.0000 (67.6136)  Acc@5: 93.7500 (95.4545)  time: 0.3937  data: 0.0477  max mem: 2500
Train: Epoch[4/5]  [  20/4579]  eta: 0:28:13  Lr: 0.001875  Loss: -0.3606  Acc@1: 68.7500 (66.9643)  Acc@5: 93.7500 (94.0476)  time: 0.3464  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [  30/4579]  eta: 0:27:33  Lr: 0.001875  Loss: 0.0743  Acc@1: 68.7500 (67.3387)  Acc@5: 93.7500 (92.9435)  time: 0.3469  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [  40/4579]  eta: 0:27:14  Lr: 0.001875  Loss: 0.6084  Acc@1: 68.7500 (66.1585)  Acc@5: 87.5000 (91.7683)  time: 0.3480  data: 0.0017  max mem: 2500
Train: Epoch[4/5]  [  50/4579]  eta: 0:27:02  Lr: 0.001875  Loss: -0.4144  Acc@1: 68.7500 (66.7892)  Acc@5: 93.7500 (92.2794)  time: 0.3501  data: 0.0024  max mem: 2500
Train: Epoch[4/5]  [  60/4579]  eta: 0:26:52  Lr: 0.001875  Loss: 0.1528  Acc@1: 68.7500 (66.9057)  Acc@5: 93.7500 (91.8033)  time: 0.3506  data: 0.0012  max mem: 2500
Train: Epoch[4/5]  [  70/4579]  eta: 0:26:45  Lr: 0.001875  Loss: -0.3718  Acc@1: 68.7500 (66.4613)  Acc@5: 87.5000 (91.3732)  time: 0.3503  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [  80/4579]  eta: 0:26:37  Lr: 0.001875  Loss: 0.5993  Acc@1: 68.7500 (66.2809)  Acc@5: 93.7500 (91.7438)  time: 0.3497  data: 0.0020  max mem: 2500
Train: Epoch[4/5]  [  90/4579]  eta: 0:26:30  Lr: 0.001875  Loss: -0.2155  Acc@1: 62.5000 (66.1401)  Acc@5: 93.7500 (91.8956)  time: 0.3481  data: 0.0021  max mem: 2500
Train: Epoch[4/5]  [ 100/4579]  eta: 0:26:24  Lr: 0.001875  Loss: -0.0882  Acc@1: 62.5000 (66.0891)  Acc@5: 93.7500 (91.8317)  time: 0.3478  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [ 110/4579]  eta: 0:26:18  Lr: 0.001875  Loss: 0.1950  Acc@1: 62.5000 (66.3851)  Acc@5: 93.7500 (91.8356)  time: 0.3485  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [ 120/4579]  eta: 0:26:11  Lr: 0.001875  Loss: 0.1635  Acc@1: 62.5000 (65.4959)  Acc@5: 93.7500 (91.7872)  time: 0.3465  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [ 130/4579]  eta: 0:26:06  Lr: 0.001875  Loss: -0.4835  Acc@1: 62.5000 (65.6489)  Acc@5: 93.7500 (92.0802)  time: 0.3454  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [ 140/4579]  eta: 0:26:01  Lr: 0.001875  Loss: -0.1192  Acc@1: 68.7500 (65.6472)  Acc@5: 93.7500 (92.0656)  time: 0.3472  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [ 150/4579]  eta: 0:25:57  Lr: 0.001875  Loss: -0.0109  Acc@1: 68.7500 (65.8113)  Acc@5: 87.5000 (91.9288)  time: 0.3494  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [ 160/4579]  eta: 0:25:52  Lr: 0.001875  Loss: 0.0301  Acc@1: 68.7500 (65.8773)  Acc@5: 87.5000 (91.8478)  time: 0.3480  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [ 170/4579]  eta: 0:25:47  Lr: 0.001875  Loss: 0.0842  Acc@1: 68.7500 (65.6798)  Acc@5: 87.5000 (91.8860)  time: 0.3460  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [ 180/4579]  eta: 0:25:43  Lr: 0.001875  Loss: -0.1022  Acc@1: 62.5000 (65.7113)  Acc@5: 93.7500 (91.9199)  time: 0.3480  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [ 190/4579]  eta: 0:25:39  Lr: 0.001875  Loss: 0.3078  Acc@1: 68.7500 (65.8377)  Acc@5: 93.7500 (91.9175)  time: 0.3487  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [ 200/4579]  eta: 0:25:35  Lr: 0.001875  Loss: 0.4908  Acc@1: 62.5000 (65.8582)  Acc@5: 93.7500 (91.8843)  time: 0.3474  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [ 210/4579]  eta: 0:25:30  Lr: 0.001875  Loss: -0.1381  Acc@1: 62.5000 (65.8175)  Acc@5: 93.7500 (92.0320)  time: 0.3470  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [ 220/4579]  eta: 0:25:26  Lr: 0.001875  Loss: 0.9530  Acc@1: 68.7500 (65.8937)  Acc@5: 93.7500 (91.9966)  time: 0.3469  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [ 230/4579]  eta: 0:25:22  Lr: 0.001875  Loss: 0.0437  Acc@1: 62.5000 (65.6656)  Acc@5: 93.7500 (92.0725)  time: 0.3466  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [ 240/4579]  eta: 0:25:19  Lr: 0.001875  Loss: 0.0562  Acc@1: 62.5000 (65.7676)  Acc@5: 93.7500 (92.0902)  time: 0.3485  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [ 250/4579]  eta: 0:25:15  Lr: 0.001875  Loss: 0.8359  Acc@1: 62.5000 (65.6375)  Acc@5: 93.7500 (92.0070)  time: 0.3492  data: 0.0017  max mem: 2500
Train: Epoch[4/5]  [ 260/4579]  eta: 0:25:11  Lr: 0.001875  Loss: -0.2177  Acc@1: 62.5000 (65.6130)  Acc@5: 93.7500 (92.1216)  time: 0.3476  data: 0.0018  max mem: 2500
Train: Epoch[4/5]  [ 270/4579]  eta: 0:25:07  Lr: 0.001875  Loss: 0.8868  Acc@1: 62.5000 (65.4290)  Acc@5: 93.7500 (92.0203)  time: 0.3468  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [ 280/4579]  eta: 0:25:03  Lr: 0.001875  Loss: -0.6303  Acc@1: 62.5000 (65.6584)  Acc@5: 93.7500 (92.0819)  time: 0.3476  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [ 290/4579]  eta: 0:25:00  Lr: 0.001875  Loss: 0.4267  Acc@1: 68.7500 (65.6357)  Acc@5: 93.7500 (92.0103)  time: 0.3491  data: 0.0014  max mem: 2500
Train: Epoch[4/5]  [ 300/4579]  eta: 0:24:55  Lr: 0.001875  Loss: 0.3233  Acc@1: 62.5000 (65.5316)  Acc@5: 87.5000 (91.9435)  time: 0.3478  data: 0.0012  max mem: 2500
Train: Epoch[4/5]  [ 310/4579]  eta: 0:24:51  Lr: 0.001875  Loss: -0.0126  Acc@1: 62.5000 (65.4743)  Acc@5: 87.5000 (91.8609)  time: 0.3457  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [ 320/4579]  eta: 0:24:48  Lr: 0.001875  Loss: 0.2827  Acc@1: 62.5000 (65.5958)  Acc@5: 87.5000 (91.8224)  time: 0.3468  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [ 330/4579]  eta: 0:24:44  Lr: 0.001875  Loss: 0.0288  Acc@1: 62.5000 (65.4456)  Acc@5: 87.5000 (91.6352)  time: 0.3471  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 340/4579]  eta: 0:24:41  Lr: 0.001875  Loss: -0.0719  Acc@1: 62.5000 (65.5059)  Acc@5: 87.5000 (91.5872)  time: 0.3499  data: 0.0030  max mem: 2500
Train: Epoch[4/5]  [ 350/4579]  eta: 0:24:37  Lr: 0.001875  Loss: -0.3090  Acc@1: 68.7500 (65.6161)  Acc@5: 87.5000 (91.5954)  time: 0.3497  data: 0.0030  max mem: 2500
Train: Epoch[4/5]  [ 360/4579]  eta: 0:24:33  Lr: 0.001875  Loss: 0.1175  Acc@1: 68.7500 (65.6337)  Acc@5: 87.5000 (91.4993)  time: 0.3467  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [ 370/4579]  eta: 0:24:30  Lr: 0.001875  Loss: 0.1336  Acc@1: 68.7500 (65.6671)  Acc@5: 87.5000 (91.4420)  time: 0.3478  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [ 380/4579]  eta: 0:24:26  Lr: 0.001875  Loss: 0.1734  Acc@1: 62.5000 (65.6004)  Acc@5: 87.5000 (91.4862)  time: 0.3474  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [ 390/4579]  eta: 0:24:22  Lr: 0.001875  Loss: -0.2673  Acc@1: 62.5000 (65.5051)  Acc@5: 87.5000 (91.4003)  time: 0.3476  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [ 400/4579]  eta: 0:24:18  Lr: 0.001875  Loss: 0.1075  Acc@1: 62.5000 (65.4146)  Acc@5: 87.5000 (91.3653)  time: 0.3469  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [ 410/4579]  eta: 0:24:15  Lr: 0.001875  Loss: -0.1512  Acc@1: 68.7500 (65.5414)  Acc@5: 93.7500 (91.4690)  time: 0.3457  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [ 420/4579]  eta: 0:24:11  Lr: 0.001875  Loss: -0.3917  Acc@1: 75.0000 (65.6770)  Acc@5: 93.7500 (91.5380)  time: 0.3454  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [ 430/4579]  eta: 0:24:07  Lr: 0.001875  Loss: 0.1807  Acc@1: 75.0000 (65.7773)  Acc@5: 93.7500 (91.5893)  time: 0.3449  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [ 440/4579]  eta: 0:24:03  Lr: 0.001875  Loss: -0.6018  Acc@1: 75.0000 (65.9297)  Acc@5: 93.7500 (91.6808)  time: 0.3461  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [ 450/4579]  eta: 0:24:00  Lr: 0.001875  Loss: 0.1905  Acc@1: 62.5000 (65.7982)  Acc@5: 87.5000 (91.6020)  time: 0.3472  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [ 460/4579]  eta: 0:23:56  Lr: 0.001875  Loss: -0.3683  Acc@1: 62.5000 (65.8487)  Acc@5: 93.7500 (91.6486)  time: 0.3463  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [ 470/4579]  eta: 0:23:52  Lr: 0.001875  Loss: 0.2731  Acc@1: 56.2500 (65.6582)  Acc@5: 93.7500 (91.5870)  time: 0.3460  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [ 480/4579]  eta: 0:23:48  Lr: 0.001875  Loss: 0.1284  Acc@1: 56.2500 (65.6185)  Acc@5: 87.5000 (91.5541)  time: 0.3467  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [ 490/4579]  eta: 0:23:45  Lr: 0.001875  Loss: 0.1397  Acc@1: 56.2500 (65.4022)  Acc@5: 87.5000 (91.5097)  time: 0.3479  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [ 500/4579]  eta: 0:23:41  Lr: 0.001875  Loss: -0.1772  Acc@1: 56.2500 (65.2695)  Acc@5: 93.7500 (91.4920)  time: 0.3470  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 510/4579]  eta: 0:23:38  Lr: 0.001875  Loss: -0.1561  Acc@1: 62.5000 (65.1663)  Acc@5: 93.7500 (91.4750)  time: 0.3471  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [ 520/4579]  eta: 0:23:34  Lr: 0.001875  Loss: 0.1711  Acc@1: 62.5000 (65.2351)  Acc@5: 93.7500 (91.5307)  time: 0.3488  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [ 530/4579]  eta: 0:23:30  Lr: 0.001875  Loss: -0.5752  Acc@1: 62.5000 (65.2072)  Acc@5: 93.7500 (91.5254)  time: 0.3467  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [ 540/4579]  eta: 0:23:27  Lr: 0.001875  Loss: -0.4421  Acc@1: 62.5000 (65.2264)  Acc@5: 93.7500 (91.5088)  time: 0.3479  data: 0.0014  max mem: 2500
Train: Epoch[4/5]  [ 550/4579]  eta: 0:23:24  Lr: 0.001875  Loss: -0.5503  Acc@1: 62.5000 (65.2337)  Acc@5: 87.5000 (91.4701)  time: 0.3500  data: 0.0018  max mem: 2500
Train: Epoch[4/5]  [ 560/4579]  eta: 0:23:20  Lr: 0.001875  Loss: -0.2152  Acc@1: 68.7500 (65.2406)  Acc@5: 87.5000 (91.4550)  time: 0.3469  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [ 570/4579]  eta: 0:23:16  Lr: 0.001875  Loss: 0.2961  Acc@1: 62.5000 (65.1817)  Acc@5: 87.5000 (91.4076)  time: 0.3457  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 580/4579]  eta: 0:23:13  Lr: 0.001875  Loss: 0.0016  Acc@1: 62.5000 (65.1786)  Acc@5: 87.5000 (91.4372)  time: 0.3461  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [ 590/4579]  eta: 0:23:09  Lr: 0.001875  Loss: -0.1789  Acc@1: 62.5000 (65.1650)  Acc@5: 93.7500 (91.4446)  time: 0.3470  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [ 600/4579]  eta: 0:23:06  Lr: 0.001875  Loss: -0.6387  Acc@1: 62.5000 (65.1310)  Acc@5: 93.7500 (91.5037)  time: 0.3476  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [ 610/4579]  eta: 0:23:02  Lr: 0.001875  Loss: 0.1943  Acc@1: 62.5000 (65.1596)  Acc@5: 93.7500 (91.5098)  time: 0.3463  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 620/4579]  eta: 0:22:58  Lr: 0.001875  Loss: -0.0260  Acc@1: 62.5000 (65.1067)  Acc@5: 87.5000 (91.4654)  time: 0.3460  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [ 630/4579]  eta: 0:22:55  Lr: 0.001875  Loss: -0.3644  Acc@1: 68.7500 (65.1941)  Acc@5: 93.7500 (91.4917)  time: 0.3462  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [ 640/4579]  eta: 0:22:51  Lr: 0.001875  Loss: 0.0684  Acc@1: 68.7500 (65.1521)  Acc@5: 93.7500 (91.4977)  time: 0.3463  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [ 650/4579]  eta: 0:22:48  Lr: 0.001875  Loss: -0.1521  Acc@1: 62.5000 (65.1498)  Acc@5: 87.5000 (91.4843)  time: 0.3475  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [ 660/4579]  eta: 0:22:44  Lr: 0.001875  Loss: -0.0354  Acc@1: 62.5000 (65.1570)  Acc@5: 93.7500 (91.5280)  time: 0.3478  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [ 670/4579]  eta: 0:22:41  Lr: 0.001875  Loss: 0.1403  Acc@1: 68.7500 (65.1919)  Acc@5: 93.7500 (91.5518)  time: 0.3474  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [ 680/4579]  eta: 0:22:37  Lr: 0.001875  Loss: 0.7215  Acc@1: 62.5000 (65.1340)  Acc@5: 87.5000 (91.5106)  time: 0.3473  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 690/4579]  eta: 0:22:33  Lr: 0.001875  Loss: -0.4777  Acc@1: 62.5000 (65.2044)  Acc@5: 87.5000 (91.5250)  time: 0.3462  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [ 700/4579]  eta: 0:22:30  Lr: 0.001875  Loss: 0.0307  Acc@1: 68.7500 (65.1926)  Acc@5: 93.7500 (91.5745)  time: 0.3455  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 710/4579]  eta: 0:22:26  Lr: 0.001875  Loss: 0.4490  Acc@1: 62.5000 (65.1459)  Acc@5: 93.7500 (91.5963)  time: 0.3471  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [ 720/4579]  eta: 0:22:23  Lr: 0.001875  Loss: -0.6597  Acc@1: 62.5000 (65.1699)  Acc@5: 93.7500 (91.6089)  time: 0.3527  data: 0.0036  max mem: 2500
Train: Epoch[4/5]  [ 730/4579]  eta: 0:22:20  Lr: 0.001875  Loss: 0.3409  Acc@1: 68.7500 (65.2445)  Acc@5: 93.7500 (91.6382)  time: 0.3515  data: 0.0035  max mem: 2500
Train: Epoch[4/5]  [ 740/4579]  eta: 0:22:16  Lr: 0.001875  Loss: -0.4189  Acc@1: 62.5000 (65.2328)  Acc@5: 93.7500 (91.6920)  time: 0.3469  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [ 750/4579]  eta: 0:22:13  Lr: 0.001875  Loss: 0.6312  Acc@1: 62.5000 (65.2547)  Acc@5: 93.7500 (91.6778)  time: 0.3475  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [ 760/4579]  eta: 0:22:09  Lr: 0.001875  Loss: 0.3525  Acc@1: 68.7500 (65.3006)  Acc@5: 93.7500 (91.7132)  time: 0.3476  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [ 770/4579]  eta: 0:22:06  Lr: 0.001875  Loss: -0.3915  Acc@1: 62.5000 (65.2237)  Acc@5: 93.7500 (91.7072)  time: 0.3470  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [ 780/4579]  eta: 0:22:02  Lr: 0.001875  Loss: 0.4068  Acc@1: 62.5000 (65.1649)  Acc@5: 93.7500 (91.7093)  time: 0.3481  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [ 790/4579]  eta: 0:21:59  Lr: 0.001875  Loss: 0.0068  Acc@1: 68.7500 (65.2102)  Acc@5: 87.5000 (91.7035)  time: 0.3477  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [ 800/4579]  eta: 0:21:55  Lr: 0.001875  Loss: -0.1671  Acc@1: 68.7500 (65.1685)  Acc@5: 87.5000 (91.6979)  time: 0.3471  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [ 810/4579]  eta: 0:21:52  Lr: 0.001875  Loss: -0.4624  Acc@1: 68.7500 (65.1665)  Acc@5: 87.5000 (91.6615)  time: 0.3484  data: 0.0016  max mem: 2500
Train: Epoch[4/5]  [ 820/4579]  eta: 0:21:48  Lr: 0.001875  Loss: -0.5504  Acc@1: 68.7500 (65.2558)  Acc@5: 93.7500 (91.6870)  time: 0.3481  data: 0.0014  max mem: 2500
Train: Epoch[4/5]  [ 830/4579]  eta: 0:21:45  Lr: 0.001875  Loss: 0.1017  Acc@1: 68.7500 (65.2602)  Acc@5: 93.7500 (91.6968)  time: 0.3480  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [ 840/4579]  eta: 0:21:41  Lr: 0.001875  Loss: -0.8188  Acc@1: 62.5000 (65.3389)  Acc@5: 93.7500 (91.7286)  time: 0.3475  data: 0.0009  max mem: 2500
Train: Epoch[4/5]  [ 850/4579]  eta: 0:21:38  Lr: 0.001875  Loss: 0.0409  Acc@1: 62.5000 (65.2908)  Acc@5: 93.7500 (91.7156)  time: 0.3472  data: 0.0010  max mem: 2500
Train: Epoch[4/5]  [ 860/4579]  eta: 0:21:34  Lr: 0.001875  Loss: -0.1246  Acc@1: 62.5000 (65.3310)  Acc@5: 93.7500 (91.7610)  time: 0.3470  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [ 870/4579]  eta: 0:21:31  Lr: 0.001875  Loss: 0.0943  Acc@1: 68.7500 (65.3846)  Acc@5: 93.7500 (91.8054)  time: 0.3481  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [ 880/4579]  eta: 0:21:27  Lr: 0.001875  Loss: -0.2158  Acc@1: 62.5000 (65.3661)  Acc@5: 93.7500 (91.7849)  time: 0.3489  data: 0.0015  max mem: 2500
Train: Epoch[4/5]  [ 890/4579]  eta: 0:21:24  Lr: 0.001875  Loss: 0.7736  Acc@1: 62.5000 (65.3549)  Acc@5: 93.7500 (91.7649)  time: 0.3482  data: 0.0014  max mem: 2500
Train: Epoch[4/5]  [ 900/4579]  eta: 0:21:20  Lr: 0.001875  Loss: 0.2223  Acc@1: 68.7500 (65.4342)  Acc@5: 93.7500 (91.8008)  time: 0.3472  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [ 910/4579]  eta: 0:21:17  Lr: 0.001875  Loss: -0.7230  Acc@1: 75.0000 (65.4981)  Acc@5: 93.7500 (91.8222)  time: 0.3453  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [ 920/4579]  eta: 0:21:13  Lr: 0.001875  Loss: -0.0862  Acc@1: 68.7500 (65.4927)  Acc@5: 93.7500 (91.8092)  time: 0.3460  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [ 930/4579]  eta: 0:21:09  Lr: 0.001875  Loss: -0.2796  Acc@1: 62.5000 (65.4404)  Acc@5: 93.7500 (91.8032)  time: 0.3463  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [ 940/4579]  eta: 0:21:06  Lr: 0.001875  Loss: -0.3581  Acc@1: 62.5000 (65.4822)  Acc@5: 93.7500 (91.7973)  time: 0.3474  data: 0.0022  max mem: 2500
Train: Epoch[4/5]  [ 950/4579]  eta: 0:21:03  Lr: 0.001875  Loss: 0.2892  Acc@1: 68.7500 (65.4837)  Acc@5: 93.7500 (91.7915)  time: 0.3489  data: 0.0030  max mem: 2500
Train: Epoch[4/5]  [ 960/4579]  eta: 0:20:59  Lr: 0.001875  Loss: 0.2090  Acc@1: 62.5000 (65.4657)  Acc@5: 93.7500 (91.8054)  time: 0.3488  data: 0.0013  max mem: 2500
Train: Epoch[4/5]  [ 970/4579]  eta: 0:20:56  Lr: 0.001875  Loss: 0.0214  Acc@1: 62.5000 (65.4416)  Acc@5: 93.7500 (91.7868)  time: 0.3489  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [ 980/4579]  eta: 0:20:52  Lr: 0.001875  Loss: -0.3571  Acc@1: 62.5000 (65.4243)  Acc@5: 87.5000 (91.7686)  time: 0.3472  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [ 990/4579]  eta: 0:20:49  Lr: 0.001875  Loss: -0.3746  Acc@1: 68.7500 (65.4579)  Acc@5: 87.5000 (91.7760)  time: 0.3478  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [1000/4579]  eta: 0:20:45  Lr: 0.001875  Loss: 0.4144  Acc@1: 62.5000 (65.3909)  Acc@5: 87.5000 (91.7458)  time: 0.3486  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [1010/4579]  eta: 0:20:42  Lr: 0.001875  Loss: 0.2660  Acc@1: 56.2500 (65.3375)  Acc@5: 87.5000 (91.7161)  time: 0.3479  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [1020/4579]  eta: 0:20:38  Lr: 0.001875  Loss: -0.1447  Acc@1: 62.5000 (65.3404)  Acc@5: 93.7500 (91.7299)  time: 0.3499  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [1030/4579]  eta: 0:20:35  Lr: 0.001875  Loss: -0.0406  Acc@1: 62.5000 (65.3977)  Acc@5: 93.7500 (91.7495)  time: 0.3488  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [1040/4579]  eta: 0:20:31  Lr: 0.001875  Loss: 0.0115  Acc@1: 62.5000 (65.3638)  Acc@5: 93.7500 (91.7207)  time: 0.3471  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [1050/4579]  eta: 0:20:28  Lr: 0.001875  Loss: 0.4957  Acc@1: 56.2500 (65.3187)  Acc@5: 87.5000 (91.6686)  time: 0.3476  data: 0.0009  max mem: 2500
Train: Epoch[4/5]  [1060/4579]  eta: 0:20:24  Lr: 0.001875  Loss: -0.0810  Acc@1: 62.5000 (65.3334)  Acc@5: 87.5000 (91.6942)  time: 0.3466  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [1070/4579]  eta: 0:20:21  Lr: 0.001875  Loss: -0.2712  Acc@1: 68.7500 (65.3186)  Acc@5: 93.7500 (91.7192)  time: 0.3458  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1080/4579]  eta: 0:20:17  Lr: 0.001875  Loss: -0.3414  Acc@1: 62.5000 (65.3157)  Acc@5: 93.7500 (91.7148)  time: 0.3477  data: 0.0023  max mem: 2500
Train: Epoch[4/5]  [1090/4579]  eta: 0:20:14  Lr: 0.001875  Loss: -0.1087  Acc@1: 62.5000 (65.2555)  Acc@5: 93.7500 (91.6762)  time: 0.3511  data: 0.0031  max mem: 2500
Train: Epoch[4/5]  [1100/4579]  eta: 0:20:10  Lr: 0.001875  Loss: -0.4496  Acc@1: 62.5000 (65.2361)  Acc@5: 93.7500 (91.7178)  time: 0.3495  data: 0.0014  max mem: 2500
Train: Epoch[4/5]  [1110/4579]  eta: 0:20:07  Lr: 0.001875  Loss: -0.2619  Acc@1: 68.7500 (65.2734)  Acc@5: 93.7500 (91.6798)  time: 0.3466  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [1120/4579]  eta: 0:20:03  Lr: 0.001875  Loss: -0.1468  Acc@1: 68.7500 (65.2821)  Acc@5: 93.7500 (91.6983)  time: 0.3459  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [1130/4579]  eta: 0:20:00  Lr: 0.001875  Loss: -0.1243  Acc@1: 68.7500 (65.2851)  Acc@5: 93.7500 (91.7164)  time: 0.3460  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [1140/4579]  eta: 0:19:56  Lr: 0.001875  Loss: -0.1228  Acc@1: 62.5000 (65.2553)  Acc@5: 93.7500 (91.6959)  time: 0.3480  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [1150/4579]  eta: 0:19:53  Lr: 0.001875  Loss: -0.3174  Acc@1: 62.5000 (65.2530)  Acc@5: 93.7500 (91.7029)  time: 0.3481  data: 0.0009  max mem: 2500
Train: Epoch[4/5]  [1160/4579]  eta: 0:19:49  Lr: 0.001875  Loss: 0.5051  Acc@1: 62.5000 (65.2186)  Acc@5: 93.7500 (91.6828)  time: 0.3461  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [1170/4579]  eta: 0:19:46  Lr: 0.001875  Loss: -0.3011  Acc@1: 56.2500 (65.1847)  Acc@5: 93.7500 (91.6845)  time: 0.3457  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1180/4579]  eta: 0:19:42  Lr: 0.001875  Loss: 0.0116  Acc@1: 62.5000 (65.1990)  Acc@5: 93.7500 (91.6755)  time: 0.3461  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [1190/4579]  eta: 0:19:39  Lr: 0.001875  Loss: 0.2069  Acc@1: 68.7500 (65.2340)  Acc@5: 93.7500 (91.6877)  time: 0.3473  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [1200/4579]  eta: 0:19:35  Lr: 0.001875  Loss: -0.2788  Acc@1: 68.7500 (65.2581)  Acc@5: 93.7500 (91.7100)  time: 0.3489  data: 0.0011  max mem: 2500
Train: Epoch[4/5]  [1210/4579]  eta: 0:19:32  Lr: 0.001875  Loss: -0.2009  Acc@1: 62.5000 (65.2611)  Acc@5: 93.7500 (91.7114)  time: 0.3484  data: 0.0014  max mem: 2500
Train: Epoch[4/5]  [1220/4579]  eta: 0:19:28  Lr: 0.001875  Loss: -0.6833  Acc@1: 62.5000 (65.2539)  Acc@5: 93.7500 (91.7127)  time: 0.3477  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [1230/4579]  eta: 0:19:25  Lr: 0.001875  Loss: -0.8753  Acc@1: 62.5000 (65.2874)  Acc@5: 93.7500 (91.7547)  time: 0.3477  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1240/4579]  eta: 0:19:21  Lr: 0.001875  Loss: 0.1707  Acc@1: 68.7500 (65.2901)  Acc@5: 100.0000 (91.7859)  time: 0.3486  data: 0.0015  max mem: 2500
Train: Epoch[4/5]  [1250/4579]  eta: 0:19:18  Lr: 0.001875  Loss: 0.3820  Acc@1: 62.5000 (65.2928)  Acc@5: 93.7500 (91.8116)  time: 0.3487  data: 0.0020  max mem: 2500
Train: Epoch[4/5]  [1260/4579]  eta: 0:19:14  Lr: 0.001875  Loss: 0.0206  Acc@1: 68.7500 (65.3301)  Acc@5: 93.7500 (91.8121)  time: 0.3478  data: 0.0009  max mem: 2500
Train: Epoch[4/5]  [1270/4579]  eta: 0:19:11  Lr: 0.001875  Loss: -0.0900  Acc@1: 68.7500 (65.3521)  Acc@5: 93.7500 (91.8175)  time: 0.3474  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [1280/4579]  eta: 0:19:07  Lr: 0.001875  Loss: 0.6130  Acc@1: 62.5000 (65.3445)  Acc@5: 93.7500 (91.8130)  time: 0.3465  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [1290/4579]  eta: 0:19:04  Lr: 0.001875  Loss: 0.0509  Acc@1: 62.5000 (65.3418)  Acc@5: 87.5000 (91.7845)  time: 0.3467  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [1300/4579]  eta: 0:19:00  Lr: 0.001875  Loss: 0.0619  Acc@1: 62.5000 (65.3872)  Acc@5: 93.7500 (91.7900)  time: 0.3476  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [1310/4579]  eta: 0:18:57  Lr: 0.001875  Loss: -0.3075  Acc@1: 68.7500 (65.4033)  Acc@5: 93.7500 (91.8002)  time: 0.3471  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [1320/4579]  eta: 0:18:53  Lr: 0.001875  Loss: -0.3551  Acc@1: 68.7500 (65.4287)  Acc@5: 93.7500 (91.8007)  time: 0.3456  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [1330/4579]  eta: 0:18:50  Lr: 0.001875  Loss: 0.0421  Acc@1: 68.7500 (65.4348)  Acc@5: 93.7500 (91.8201)  time: 0.3464  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [1340/4579]  eta: 0:18:47  Lr: 0.001875  Loss: 0.5775  Acc@1: 56.2500 (65.3990)  Acc@5: 87.5000 (91.7972)  time: 0.3500  data: 0.0011  max mem: 2500
Train: Epoch[4/5]  [1350/4579]  eta: 0:18:43  Lr: 0.001875  Loss: -0.0964  Acc@1: 68.7500 (65.4145)  Acc@5: 87.5000 (91.8024)  time: 0.3484  data: 0.0010  max mem: 2500
Train: Epoch[4/5]  [1360/4579]  eta: 0:18:39  Lr: 0.001875  Loss: 0.1107  Acc@1: 62.5000 (65.4206)  Acc@5: 87.5000 (91.7983)  time: 0.3457  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [1370/4579]  eta: 0:18:36  Lr: 0.001875  Loss: 0.1771  Acc@1: 62.5000 (65.4267)  Acc@5: 87.5000 (91.7898)  time: 0.3476  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [1380/4579]  eta: 0:18:32  Lr: 0.001875  Loss: -0.3309  Acc@1: 62.5000 (65.4055)  Acc@5: 93.7500 (91.7813)  time: 0.3480  data: 0.0014  max mem: 2500
Train: Epoch[4/5]  [1390/4579]  eta: 0:18:29  Lr: 0.001875  Loss: -0.2124  Acc@1: 62.5000 (65.3711)  Acc@5: 87.5000 (91.7595)  time: 0.3474  data: 0.0012  max mem: 2500
Train: Epoch[4/5]  [1400/4579]  eta: 0:18:26  Lr: 0.001875  Loss: 0.5879  Acc@1: 62.5000 (65.3506)  Acc@5: 87.5000 (91.7470)  time: 0.3474  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [1410/4579]  eta: 0:18:22  Lr: 0.001875  Loss: 0.3724  Acc@1: 62.5000 (65.3659)  Acc@5: 93.7500 (91.7479)  time: 0.3524  data: 0.0041  max mem: 2500
Train: Epoch[4/5]  [1420/4579]  eta: 0:18:19  Lr: 0.001875  Loss: -0.1434  Acc@1: 62.5000 (65.3413)  Acc@5: 93.7500 (91.7312)  time: 0.3530  data: 0.0040  max mem: 2500
Train: Epoch[4/5]  [1430/4579]  eta: 0:18:15  Lr: 0.001875  Loss: -0.5675  Acc@1: 68.7500 (65.4044)  Acc@5: 93.7500 (91.7540)  time: 0.3471  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [1440/4579]  eta: 0:18:12  Lr: 0.001875  Loss: -0.1825  Acc@1: 75.0000 (65.4537)  Acc@5: 93.7500 (91.7592)  time: 0.3467  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [1450/4579]  eta: 0:18:08  Lr: 0.001875  Loss: 0.3275  Acc@1: 68.7500 (65.4333)  Acc@5: 87.5000 (91.7341)  time: 0.3476  data: 0.0011  max mem: 2500
Train: Epoch[4/5]  [1460/4579]  eta: 0:18:05  Lr: 0.001875  Loss: -0.2533  Acc@1: 62.5000 (65.4560)  Acc@5: 87.5000 (91.7437)  time: 0.3468  data: 0.0009  max mem: 2500
Train: Epoch[4/5]  [1470/4579]  eta: 0:18:01  Lr: 0.001875  Loss: 0.1301  Acc@1: 62.5000 (65.4359)  Acc@5: 93.7500 (91.7403)  time: 0.3469  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1480/4579]  eta: 0:17:58  Lr: 0.001875  Loss: -0.5380  Acc@1: 62.5000 (65.4034)  Acc@5: 93.7500 (91.7286)  time: 0.3475  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [1490/4579]  eta: 0:17:54  Lr: 0.001875  Loss: -0.7239  Acc@1: 62.5000 (65.4091)  Acc@5: 93.7500 (91.7295)  time: 0.3477  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [1500/4579]  eta: 0:17:51  Lr: 0.001875  Loss: -0.1364  Acc@1: 68.7500 (65.4231)  Acc@5: 93.7500 (91.7347)  time: 0.3470  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [1510/4579]  eta: 0:17:47  Lr: 0.001875  Loss: -0.0015  Acc@1: 62.5000 (65.3830)  Acc@5: 87.5000 (91.7315)  time: 0.3474  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [1520/4579]  eta: 0:17:44  Lr: 0.001875  Loss: 0.0230  Acc@1: 62.5000 (65.3969)  Acc@5: 93.7500 (91.7365)  time: 0.3498  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [1530/4579]  eta: 0:17:40  Lr: 0.001875  Loss: -0.1528  Acc@1: 62.5000 (65.3739)  Acc@5: 93.7500 (91.7293)  time: 0.3484  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [1540/4579]  eta: 0:17:37  Lr: 0.001875  Loss: -0.5342  Acc@1: 68.7500 (65.4242)  Acc@5: 93.7500 (91.7627)  time: 0.3470  data: 0.0011  max mem: 2500
Train: Epoch[4/5]  [1550/4579]  eta: 0:17:33  Lr: 0.001875  Loss: 0.3950  Acc@1: 68.7500 (65.4054)  Acc@5: 93.7500 (91.7513)  time: 0.3476  data: 0.0013  max mem: 2500
Train: Epoch[4/5]  [1560/4579]  eta: 0:17:30  Lr: 0.001875  Loss: 0.9397  Acc@1: 62.5000 (65.3507)  Acc@5: 87.5000 (91.7361)  time: 0.3474  data: 0.0015  max mem: 2500
Train: Epoch[4/5]  [1570/4579]  eta: 0:17:26  Lr: 0.001875  Loss: -0.0700  Acc@1: 56.2500 (65.3445)  Acc@5: 93.7500 (91.7409)  time: 0.3480  data: 0.0014  max mem: 2500
Train: Epoch[4/5]  [1580/4579]  eta: 0:17:23  Lr: 0.001875  Loss: -0.7856  Acc@1: 68.7500 (65.3621)  Acc@5: 93.7500 (91.7615)  time: 0.3483  data: 0.0014  max mem: 2500
Train: Epoch[4/5]  [1590/4579]  eta: 0:17:20  Lr: 0.001875  Loss: -0.0481  Acc@1: 68.7500 (65.3363)  Acc@5: 93.7500 (91.7465)  time: 0.3488  data: 0.0028  max mem: 2500
Train: Epoch[4/5]  [1600/4579]  eta: 0:17:16  Lr: 0.001875  Loss: 0.0923  Acc@1: 56.2500 (65.3068)  Acc@5: 93.7500 (91.7395)  time: 0.3489  data: 0.0021  max mem: 2500
Train: Epoch[4/5]  [1610/4579]  eta: 0:17:13  Lr: 0.001875  Loss: 0.1298  Acc@1: 62.5000 (65.3321)  Acc@5: 93.7500 (91.7481)  time: 0.3477  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [1620/4579]  eta: 0:17:09  Lr: 0.001875  Loss: -0.4651  Acc@1: 68.7500 (65.3378)  Acc@5: 93.7500 (91.7374)  time: 0.3482  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [1630/4579]  eta: 0:17:06  Lr: 0.001875  Loss: 0.5395  Acc@1: 68.7500 (65.3472)  Acc@5: 93.7500 (91.7382)  time: 0.3474  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [1640/4579]  eta: 0:17:02  Lr: 0.001875  Loss: -0.3869  Acc@1: 68.7500 (65.3032)  Acc@5: 87.5000 (91.7009)  time: 0.3455  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [1650/4579]  eta: 0:16:59  Lr: 0.001875  Loss: -0.3890  Acc@1: 68.7500 (65.2975)  Acc@5: 87.5000 (91.7020)  time: 0.3463  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [1660/4579]  eta: 0:16:55  Lr: 0.001875  Loss: 0.1814  Acc@1: 68.7500 (65.3033)  Acc@5: 93.7500 (91.7068)  time: 0.3465  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [1670/4579]  eta: 0:16:52  Lr: 0.001875  Loss: 0.4015  Acc@1: 68.7500 (65.2977)  Acc@5: 93.7500 (91.7003)  time: 0.3460  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [1680/4579]  eta: 0:16:48  Lr: 0.001875  Loss: 0.4138  Acc@1: 62.5000 (65.2513)  Acc@5: 93.7500 (91.7051)  time: 0.3456  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [1690/4579]  eta: 0:16:45  Lr: 0.001875  Loss: -0.7768  Acc@1: 62.5000 (65.2388)  Acc@5: 93.7500 (91.7024)  time: 0.3474  data: 0.0014  max mem: 2500
Train: Epoch[4/5]  [1700/4579]  eta: 0:16:41  Lr: 0.001875  Loss: -0.4517  Acc@1: 62.5000 (65.2851)  Acc@5: 93.7500 (91.7144)  time: 0.3481  data: 0.0011  max mem: 2500
Train: Epoch[4/5]  [1710/4579]  eta: 0:16:38  Lr: 0.001875  Loss: -0.3468  Acc@1: 75.0000 (65.3127)  Acc@5: 93.7500 (91.7227)  time: 0.3463  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [1720/4579]  eta: 0:16:34  Lr: 0.001875  Loss: 0.3952  Acc@1: 68.7500 (65.3399)  Acc@5: 93.7500 (91.7308)  time: 0.3462  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [1730/4579]  eta: 0:16:31  Lr: 0.001875  Loss: -0.2969  Acc@1: 68.7500 (65.3560)  Acc@5: 93.7500 (91.7461)  time: 0.3478  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [1740/4579]  eta: 0:16:27  Lr: 0.001875  Loss: 0.1023  Acc@1: 68.7500 (65.3719)  Acc@5: 93.7500 (91.7433)  time: 0.3466  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [1750/4579]  eta: 0:16:24  Lr: 0.001875  Loss: -0.5740  Acc@1: 62.5000 (65.3519)  Acc@5: 87.5000 (91.7369)  time: 0.3467  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [1760/4579]  eta: 0:16:20  Lr: 0.001875  Loss: 0.0227  Acc@1: 62.5000 (65.3712)  Acc@5: 87.5000 (91.7341)  time: 0.3480  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [1770/4579]  eta: 0:16:17  Lr: 0.001875  Loss: 0.1260  Acc@1: 68.7500 (65.3797)  Acc@5: 87.5000 (91.7384)  time: 0.3463  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [1780/4579]  eta: 0:16:13  Lr: 0.001875  Loss: -0.0381  Acc@1: 62.5000 (65.4162)  Acc@5: 93.7500 (91.7427)  time: 0.3474  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [1790/4579]  eta: 0:16:10  Lr: 0.001875  Loss: 0.4070  Acc@1: 62.5000 (65.3929)  Acc@5: 93.7500 (91.7365)  time: 0.3483  data: 0.0016  max mem: 2500
Train: Epoch[4/5]  [1800/4579]  eta: 0:16:06  Lr: 0.001875  Loss: 0.1033  Acc@1: 56.2500 (65.3873)  Acc@5: 87.5000 (91.7233)  time: 0.3483  data: 0.0017  max mem: 2500
Train: Epoch[4/5]  [1810/4579]  eta: 0:16:03  Lr: 0.001875  Loss: 0.1745  Acc@1: 62.5000 (65.3817)  Acc@5: 87.5000 (91.7104)  time: 0.3484  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [1820/4579]  eta: 0:15:59  Lr: 0.001875  Loss: 1.0159  Acc@1: 62.5000 (65.3521)  Acc@5: 93.7500 (91.6976)  time: 0.3475  data: 0.0013  max mem: 2500
Train: Epoch[4/5]  [1830/4579]  eta: 0:15:56  Lr: 0.001875  Loss: 0.3503  Acc@1: 68.7500 (65.3570)  Acc@5: 93.7500 (91.6951)  time: 0.3474  data: 0.0014  max mem: 2500
Train: Epoch[4/5]  [1840/4579]  eta: 0:15:52  Lr: 0.001875  Loss: 0.0366  Acc@1: 68.7500 (65.3619)  Acc@5: 93.7500 (91.7029)  time: 0.3460  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [1850/4579]  eta: 0:15:49  Lr: 0.001875  Loss: -0.0610  Acc@1: 62.5000 (65.3701)  Acc@5: 93.7500 (91.7139)  time: 0.3460  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1860/4579]  eta: 0:15:45  Lr: 0.001875  Loss: 0.2231  Acc@1: 62.5000 (65.3882)  Acc@5: 93.7500 (91.7114)  time: 0.3468  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [1870/4579]  eta: 0:15:42  Lr: 0.001875  Loss: -0.0261  Acc@1: 62.5000 (65.3628)  Acc@5: 93.7500 (91.7157)  time: 0.3463  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [1880/4579]  eta: 0:15:38  Lr: 0.001875  Loss: -0.6729  Acc@1: 62.5000 (65.3775)  Acc@5: 93.7500 (91.7364)  time: 0.3461  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [1890/4579]  eta: 0:15:35  Lr: 0.001875  Loss: 0.1919  Acc@1: 62.5000 (65.3391)  Acc@5: 93.7500 (91.7273)  time: 0.3474  data: 0.0014  max mem: 2500
Train: Epoch[4/5]  [1900/4579]  eta: 0:15:31  Lr: 0.001875  Loss: 0.0688  Acc@1: 56.2500 (65.3307)  Acc@5: 93.7500 (91.7280)  time: 0.3474  data: 0.0013  max mem: 2500
Train: Epoch[4/5]  [1910/4579]  eta: 0:15:28  Lr: 0.001875  Loss: -0.2565  Acc@1: 68.7500 (65.3356)  Acc@5: 93.7500 (91.7157)  time: 0.3465  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [1920/4579]  eta: 0:15:24  Lr: 0.001875  Loss: -0.2941  Acc@1: 62.5000 (65.3110)  Acc@5: 93.7500 (91.7328)  time: 0.3481  data: 0.0013  max mem: 2500
Train: Epoch[4/5]  [1930/4579]  eta: 0:15:21  Lr: 0.001875  Loss: -0.2849  Acc@1: 62.5000 (65.2997)  Acc@5: 93.7500 (91.7368)  time: 0.3487  data: 0.0013  max mem: 2500
Train: Epoch[4/5]  [1940/4579]  eta: 0:15:17  Lr: 0.001875  Loss: 0.3780  Acc@1: 62.5000 (65.2821)  Acc@5: 93.7500 (91.7343)  time: 0.3458  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [1950/4579]  eta: 0:15:14  Lr: 0.001875  Loss: 0.3200  Acc@1: 62.5000 (65.2902)  Acc@5: 93.7500 (91.7350)  time: 0.3457  data: 0.0011  max mem: 2500
Train: Epoch[4/5]  [1960/4579]  eta: 0:15:10  Lr: 0.001875  Loss: -0.0206  Acc@1: 68.7500 (65.2983)  Acc@5: 93.7500 (91.7421)  time: 0.3473  data: 0.0011  max mem: 2500
Train: Epoch[4/5]  [1970/4579]  eta: 0:15:07  Lr: 0.001875  Loss: 0.4457  Acc@1: 62.5000 (65.2873)  Acc@5: 93.7500 (91.7396)  time: 0.3474  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1980/4579]  eta: 0:15:03  Lr: 0.001875  Loss: -0.4004  Acc@1: 62.5000 (65.2638)  Acc@5: 93.7500 (91.7466)  time: 0.3481  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1990/4579]  eta: 0:15:00  Lr: 0.001875  Loss: -0.1998  Acc@1: 62.5000 (65.2687)  Acc@5: 93.7500 (91.7284)  time: 0.3490  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2000/4579]  eta: 0:14:56  Lr: 0.001875  Loss: 0.5683  Acc@1: 62.5000 (65.2611)  Acc@5: 93.7500 (91.7323)  time: 0.3479  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2010/4579]  eta: 0:14:53  Lr: 0.001875  Loss: -0.2285  Acc@1: 62.5000 (65.2598)  Acc@5: 93.7500 (91.7268)  time: 0.3469  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2020/4579]  eta: 0:14:49  Lr: 0.001875  Loss: -0.3768  Acc@1: 62.5000 (65.2369)  Acc@5: 87.5000 (91.7213)  time: 0.3480  data: 0.0011  max mem: 2500
Train: Epoch[4/5]  [2030/4579]  eta: 0:14:46  Lr: 0.001875  Loss: -0.6739  Acc@1: 62.5000 (65.2265)  Acc@5: 87.5000 (91.7097)  time: 0.3467  data: 0.0011  max mem: 2500
Train: Epoch[4/5]  [2040/4579]  eta: 0:14:42  Lr: 0.001875  Loss: -0.4483  Acc@1: 62.5000 (65.2499)  Acc@5: 93.7500 (91.7228)  time: 0.3460  data: 0.0010  max mem: 2500
Train: Epoch[4/5]  [2050/4579]  eta: 0:14:39  Lr: 0.001875  Loss: 0.2959  Acc@1: 68.7500 (65.2487)  Acc@5: 93.7500 (91.7266)  time: 0.3475  data: 0.0010  max mem: 2500
Train: Epoch[4/5]  [2060/4579]  eta: 0:14:35  Lr: 0.001875  Loss: -0.3747  Acc@1: 68.7500 (65.2687)  Acc@5: 93.7500 (91.7273)  time: 0.3470  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2070/4579]  eta: 0:14:32  Lr: 0.001875  Loss: 0.1498  Acc@1: 68.7500 (65.2795)  Acc@5: 93.7500 (91.7250)  time: 0.3462  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2080/4579]  eta: 0:14:29  Lr: 0.001875  Loss: 0.1505  Acc@1: 68.7500 (65.2871)  Acc@5: 93.7500 (91.7287)  time: 0.3463  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2090/4579]  eta: 0:14:25  Lr: 0.001875  Loss: 0.0172  Acc@1: 62.5000 (65.2618)  Acc@5: 93.7500 (91.7384)  time: 0.3479  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [2100/4579]  eta: 0:14:22  Lr: 0.001875  Loss: 0.9951  Acc@1: 62.5000 (65.2517)  Acc@5: 93.7500 (91.7539)  time: 0.3479  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [2110/4579]  eta: 0:14:18  Lr: 0.001875  Loss: -0.1831  Acc@1: 62.5000 (65.2297)  Acc@5: 93.7500 (91.7338)  time: 0.3465  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [2120/4579]  eta: 0:14:15  Lr: 0.001875  Loss: -0.4107  Acc@1: 62.5000 (65.2817)  Acc@5: 87.5000 (91.7285)  time: 0.3467  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [2130/4579]  eta: 0:14:11  Lr: 0.001875  Loss: 0.1526  Acc@1: 75.0000 (65.2892)  Acc@5: 93.7500 (91.7234)  time: 0.3466  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [2140/4579]  eta: 0:14:08  Lr: 0.001875  Loss: -0.4814  Acc@1: 68.7500 (65.3141)  Acc@5: 93.7500 (91.7299)  time: 0.3469  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2150/4579]  eta: 0:14:04  Lr: 0.001875  Loss: -0.0124  Acc@1: 68.7500 (65.3243)  Acc@5: 93.7500 (91.7306)  time: 0.3464  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2160/4579]  eta: 0:14:01  Lr: 0.001875  Loss: 0.1489  Acc@1: 68.7500 (65.3314)  Acc@5: 87.5000 (91.7313)  time: 0.3464  data: 0.0012  max mem: 2500
Train: Epoch[4/5]  [2170/4579]  eta: 0:13:57  Lr: 0.001875  Loss: 0.1784  Acc@1: 62.5000 (65.3098)  Acc@5: 93.7500 (91.7290)  time: 0.3476  data: 0.0013  max mem: 2500
Train: Epoch[4/5]  [2180/4579]  eta: 0:13:54  Lr: 0.001875  Loss: 0.2692  Acc@1: 62.5000 (65.3026)  Acc@5: 93.7500 (91.7268)  time: 0.3469  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [2190/4579]  eta: 0:13:50  Lr: 0.001875  Loss: 0.1376  Acc@1: 62.5000 (65.3098)  Acc@5: 93.7500 (91.7418)  time: 0.3477  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [2200/4579]  eta: 0:13:47  Lr: 0.001875  Loss: -0.5329  Acc@1: 68.7500 (65.3084)  Acc@5: 93.7500 (91.7254)  time: 0.3505  data: 0.0028  max mem: 2500
Train: Epoch[4/5]  [2210/4579]  eta: 0:13:43  Lr: 0.001875  Loss: 0.2127  Acc@1: 68.7500 (65.3296)  Acc@5: 93.7500 (91.7345)  time: 0.3503  data: 0.0033  max mem: 2500
Train: Epoch[4/5]  [2220/4579]  eta: 0:13:40  Lr: 0.001875  Loss: -0.7012  Acc@1: 68.7500 (65.3591)  Acc@5: 93.7500 (91.7380)  time: 0.3476  data: 0.0012  max mem: 2500
Train: Epoch[4/5]  [2230/4579]  eta: 0:13:36  Lr: 0.001875  Loss: -0.2894  Acc@1: 62.5000 (65.3491)  Acc@5: 93.7500 (91.7330)  time: 0.3470  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2240/4579]  eta: 0:13:33  Lr: 0.001875  Loss: -0.5685  Acc@1: 62.5000 (65.3531)  Acc@5: 87.5000 (91.7280)  time: 0.3479  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2250/4579]  eta: 0:13:29  Lr: 0.001875  Loss: -0.5033  Acc@1: 62.5000 (65.3349)  Acc@5: 87.5000 (91.7176)  time: 0.3470  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2260/4579]  eta: 0:13:26  Lr: 0.001875  Loss: -0.1073  Acc@1: 62.5000 (65.3223)  Acc@5: 93.7500 (91.7293)  time: 0.3461  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2270/4579]  eta: 0:13:22  Lr: 0.001875  Loss: -0.1034  Acc@1: 68.7500 (65.3181)  Acc@5: 93.7500 (91.7300)  time: 0.3460  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2280/4579]  eta: 0:13:19  Lr: 0.001875  Loss: -0.1689  Acc@1: 62.5000 (65.3250)  Acc@5: 93.7500 (91.7470)  time: 0.3464  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2290/4579]  eta: 0:13:15  Lr: 0.001875  Loss: -0.0924  Acc@1: 68.7500 (65.3536)  Acc@5: 93.7500 (91.7585)  time: 0.3468  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2300/4579]  eta: 0:13:12  Lr: 0.001875  Loss: -0.1098  Acc@1: 68.7500 (65.3493)  Acc@5: 93.7500 (91.7726)  time: 0.3470  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2310/4579]  eta: 0:13:08  Lr: 0.001875  Loss: -0.1411  Acc@1: 62.5000 (65.3451)  Acc@5: 93.7500 (91.7703)  time: 0.3469  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2320/4579]  eta: 0:13:05  Lr: 0.001875  Loss: -0.3387  Acc@1: 62.5000 (65.3678)  Acc@5: 93.7500 (91.7708)  time: 0.3459  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2330/4579]  eta: 0:13:01  Lr: 0.001875  Loss: -0.3288  Acc@1: 62.5000 (65.3555)  Acc@5: 93.7500 (91.7712)  time: 0.3456  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2340/4579]  eta: 0:12:58  Lr: 0.001875  Loss: -0.3477  Acc@1: 62.5000 (65.3567)  Acc@5: 93.7500 (91.7663)  time: 0.3470  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2350/4579]  eta: 0:12:54  Lr: 0.001875  Loss: 0.4356  Acc@1: 68.7500 (65.3578)  Acc@5: 93.7500 (91.7721)  time: 0.3474  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2360/4579]  eta: 0:12:51  Lr: 0.001875  Loss: 0.5068  Acc@1: 68.7500 (65.3537)  Acc@5: 93.7500 (91.7884)  time: 0.3464  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2370/4579]  eta: 0:12:48  Lr: 0.001875  Loss: -0.2352  Acc@1: 62.5000 (65.3469)  Acc@5: 93.7500 (91.7835)  time: 0.3475  data: 0.0013  max mem: 2500
Train: Epoch[4/5]  [2380/4579]  eta: 0:12:44  Lr: 0.001875  Loss: -0.2729  Acc@1: 68.7500 (65.3612)  Acc@5: 87.5000 (91.7865)  time: 0.3485  data: 0.0014  max mem: 2500
Train: Epoch[4/5]  [2390/4579]  eta: 0:12:41  Lr: 0.001875  Loss: -0.0032  Acc@1: 68.7500 (65.3675)  Acc@5: 93.7500 (91.7921)  time: 0.3485  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [2400/4579]  eta: 0:12:37  Lr: 0.001875  Loss: -0.5155  Acc@1: 75.0000 (65.3946)  Acc@5: 93.7500 (91.7951)  time: 0.3483  data: 0.0009  max mem: 2500
Train: Epoch[4/5]  [2410/4579]  eta: 0:12:34  Lr: 0.001875  Loss: 0.4335  Acc@1: 62.5000 (65.3800)  Acc@5: 93.7500 (91.7773)  time: 0.3476  data: 0.0016  max mem: 2500
Train: Epoch[4/5]  [2420/4579]  eta: 0:12:30  Lr: 0.001875  Loss: 0.0612  Acc@1: 62.5000 (65.4069)  Acc@5: 93.7500 (91.7777)  time: 0.3486  data: 0.0016  max mem: 2500
Train: Epoch[4/5]  [2430/4579]  eta: 0:12:27  Lr: 0.001875  Loss: -0.5338  Acc@1: 75.0000 (65.4232)  Acc@5: 93.7500 (91.7781)  time: 0.3489  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [2440/4579]  eta: 0:12:23  Lr: 0.001875  Loss: 0.0919  Acc@1: 62.5000 (65.3933)  Acc@5: 87.5000 (91.7734)  time: 0.3477  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2450/4579]  eta: 0:12:20  Lr: 0.001875  Loss: -0.2507  Acc@1: 62.5000 (65.4121)  Acc@5: 93.7500 (91.7814)  time: 0.3467  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [2460/4579]  eta: 0:12:16  Lr: 0.001875  Loss: -0.0355  Acc@1: 62.5000 (65.4129)  Acc@5: 93.7500 (91.7869)  time: 0.3471  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [2470/4579]  eta: 0:12:13  Lr: 0.001875  Loss: -0.6345  Acc@1: 68.7500 (65.4214)  Acc@5: 93.7500 (91.7898)  time: 0.3487  data: 0.0013  max mem: 2500
Train: Epoch[4/5]  [2480/4579]  eta: 0:12:09  Lr: 0.001875  Loss: -0.7607  Acc@1: 62.5000 (65.4046)  Acc@5: 93.7500 (91.7901)  time: 0.3479  data: 0.0011  max mem: 2500
Train: Epoch[4/5]  [2490/4579]  eta: 0:12:06  Lr: 0.001875  Loss: -0.4768  Acc@1: 62.5000 (65.4381)  Acc@5: 93.7500 (91.8030)  time: 0.3471  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2500/4579]  eta: 0:12:02  Lr: 0.001875  Loss: -0.1500  Acc@1: 68.7500 (65.4413)  Acc@5: 93.7500 (91.8058)  time: 0.3488  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [2510/4579]  eta: 0:11:59  Lr: 0.001875  Loss: -0.1634  Acc@1: 62.5000 (65.4421)  Acc@5: 93.7500 (91.8036)  time: 0.3482  data: 0.0014  max mem: 2500
Train: Epoch[4/5]  [2520/4579]  eta: 0:11:55  Lr: 0.001875  Loss: 0.3640  Acc@1: 62.5000 (65.4378)  Acc@5: 87.5000 (91.7890)  time: 0.3474  data: 0.0015  max mem: 2500
Train: Epoch[4/5]  [2530/4579]  eta: 0:11:52  Lr: 0.001875  Loss: 0.5436  Acc@1: 62.5000 (65.4262)  Acc@5: 93.7500 (91.8041)  time: 0.3473  data: 0.0013  max mem: 2500
Train: Epoch[4/5]  [2540/4579]  eta: 0:11:48  Lr: 0.001875  Loss: 0.1194  Acc@1: 62.5000 (65.4196)  Acc@5: 93.7500 (91.8019)  time: 0.3467  data: 0.0011  max mem: 2500
Train: Epoch[4/5]  [2550/4579]  eta: 0:11:45  Lr: 0.001875  Loss: -0.1806  Acc@1: 62.5000 (65.4278)  Acc@5: 93.7500 (91.8047)  time: 0.3476  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2560/4579]  eta: 0:11:41  Lr: 0.001875  Loss: -0.3853  Acc@1: 68.7500 (65.4334)  Acc@5: 93.7500 (91.8074)  time: 0.3468  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2570/4579]  eta: 0:11:38  Lr: 0.001875  Loss: 0.0043  Acc@1: 68.7500 (65.4269)  Acc@5: 93.7500 (91.8150)  time: 0.3456  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2580/4579]  eta: 0:11:35  Lr: 0.001875  Loss: -0.5362  Acc@1: 68.7500 (65.4349)  Acc@5: 93.7500 (91.8128)  time: 0.3483  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [2590/4579]  eta: 0:11:31  Lr: 0.001875  Loss: -0.0161  Acc@1: 68.7500 (65.4405)  Acc@5: 93.7500 (91.8178)  time: 0.3499  data: 0.0014  max mem: 2500
Train: Epoch[4/5]  [2600/4579]  eta: 0:11:28  Lr: 0.001875  Loss: 0.0316  Acc@1: 62.5000 (65.4244)  Acc@5: 93.7500 (91.8277)  time: 0.3474  data: 0.0013  max mem: 2500
Train: Epoch[4/5]  [2610/4579]  eta: 0:11:24  Lr: 0.001875  Loss: -0.3317  Acc@1: 62.5000 (65.3916)  Acc@5: 93.7500 (91.8278)  time: 0.3478  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [2620/4579]  eta: 0:11:21  Lr: 0.001875  Loss: 0.5204  Acc@1: 56.2500 (65.3734)  Acc@5: 93.7500 (91.8280)  time: 0.3486  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [2630/4579]  eta: 0:11:17  Lr: 0.001875  Loss: 0.2253  Acc@1: 62.5000 (65.3863)  Acc@5: 93.7500 (91.8353)  time: 0.3486  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [2640/4579]  eta: 0:11:14  Lr: 0.001875  Loss: -0.4206  Acc@1: 68.7500 (65.3919)  Acc@5: 93.7500 (91.8331)  time: 0.3484  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [2650/4579]  eta: 0:11:10  Lr: 0.001875  Loss: -0.2736  Acc@1: 68.7500 (65.4329)  Acc@5: 93.7500 (91.8403)  time: 0.3471  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [2660/4579]  eta: 0:11:07  Lr: 0.001875  Loss: -0.1170  Acc@1: 75.0000 (65.4383)  Acc@5: 93.7500 (91.8405)  time: 0.3470  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [2670/4579]  eta: 0:11:03  Lr: 0.001875  Loss: 0.1882  Acc@1: 62.5000 (65.4226)  Acc@5: 93.7500 (91.8570)  time: 0.3477  data: 0.0010  max mem: 2500
Train: Epoch[4/5]  [2680/4579]  eta: 0:11:00  Lr: 0.001875  Loss: -0.4427  Acc@1: 62.5000 (65.4094)  Acc@5: 93.7500 (91.8710)  time: 0.3500  data: 0.0028  max mem: 2500
Train: Epoch[4/5]  [2690/4579]  eta: 0:10:56  Lr: 0.001875  Loss: -0.1108  Acc@1: 62.5000 (65.4032)  Acc@5: 93.7500 (91.8734)  time: 0.3486  data: 0.0024  max mem: 2500
Train: Epoch[4/5]  [2700/4579]  eta: 0:10:53  Lr: 0.001875  Loss: -0.1847  Acc@1: 62.5000 (65.3994)  Acc@5: 93.7500 (91.8734)  time: 0.3457  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2710/4579]  eta: 0:10:49  Lr: 0.001875  Loss: 0.0331  Acc@1: 62.5000 (65.4025)  Acc@5: 93.7500 (91.8711)  time: 0.3459  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2720/4579]  eta: 0:10:46  Lr: 0.001875  Loss: 0.4307  Acc@1: 62.5000 (65.3781)  Acc@5: 93.7500 (91.8504)  time: 0.3468  data: 0.0013  max mem: 2500
Train: Epoch[4/5]  [2730/4579]  eta: 0:10:42  Lr: 0.001875  Loss: -0.4445  Acc@1: 56.2500 (65.3584)  Acc@5: 87.5000 (91.8459)  time: 0.3473  data: 0.0015  max mem: 2500
Train: Epoch[4/5]  [2740/4579]  eta: 0:10:39  Lr: 0.001875  Loss: -0.2344  Acc@1: 62.5000 (65.3662)  Acc@5: 87.5000 (91.8460)  time: 0.3479  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [2750/4579]  eta: 0:10:35  Lr: 0.001875  Loss: 0.1907  Acc@1: 68.7500 (65.3581)  Acc@5: 93.7500 (91.8461)  time: 0.3473  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2760/4579]  eta: 0:10:32  Lr: 0.001875  Loss: 0.2189  Acc@1: 62.5000 (65.3703)  Acc@5: 93.7500 (91.8530)  time: 0.3461  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2770/4579]  eta: 0:10:28  Lr: 0.001875  Loss: -0.1739  Acc@1: 68.7500 (65.3803)  Acc@5: 93.7500 (91.8576)  time: 0.3467  data: 0.0011  max mem: 2500
Train: Epoch[4/5]  [2780/4579]  eta: 0:10:25  Lr: 0.001875  Loss: -0.3986  Acc@1: 75.0000 (65.4081)  Acc@5: 93.7500 (91.8554)  time: 0.3478  data: 0.0012  max mem: 2500
Train: Epoch[4/5]  [2790/4579]  eta: 0:10:21  Lr: 0.001875  Loss: -0.5942  Acc@1: 68.7500 (65.3977)  Acc@5: 93.7500 (91.8488)  time: 0.3472  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [2800/4579]  eta: 0:10:18  Lr: 0.001875  Loss: -0.0804  Acc@1: 68.7500 (65.4030)  Acc@5: 93.7500 (91.8489)  time: 0.3463  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2810/4579]  eta: 0:10:15  Lr: 0.001875  Loss: 0.2930  Acc@1: 68.7500 (65.4038)  Acc@5: 93.7500 (91.8534)  time: 0.3464  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2820/4579]  eta: 0:10:11  Lr: 0.001875  Loss: -0.0224  Acc@1: 62.5000 (65.3913)  Acc@5: 93.7500 (91.8668)  time: 0.3457  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2830/4579]  eta: 0:10:08  Lr: 0.001875  Loss: -0.3153  Acc@1: 62.5000 (65.3899)  Acc@5: 93.7500 (91.8514)  time: 0.3461  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2840/4579]  eta: 0:10:04  Lr: 0.001875  Loss: -0.4352  Acc@1: 62.5000 (65.3973)  Acc@5: 93.7500 (91.8559)  time: 0.3467  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [2850/4579]  eta: 0:10:01  Lr: 0.001875  Loss: -0.5333  Acc@1: 75.0000 (65.4222)  Acc@5: 93.7500 (91.8713)  time: 0.3469  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2860/4579]  eta: 0:09:57  Lr: 0.001875  Loss: 0.2677  Acc@1: 68.7500 (65.4076)  Acc@5: 93.7500 (91.8669)  time: 0.3480  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2870/4579]  eta: 0:09:54  Lr: 0.001875  Loss: 0.5469  Acc@1: 62.5000 (65.3866)  Acc@5: 87.5000 (91.8582)  time: 0.3465  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2880/4579]  eta: 0:09:50  Lr: 0.001875  Loss: -0.2979  Acc@1: 62.5000 (65.3918)  Acc@5: 87.5000 (91.8605)  time: 0.3449  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2890/4579]  eta: 0:09:47  Lr: 0.001875  Loss: -0.9240  Acc@1: 68.7500 (65.4121)  Acc@5: 93.7500 (91.8627)  time: 0.3476  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [2900/4579]  eta: 0:09:43  Lr: 0.001875  Loss: -0.0655  Acc@1: 68.7500 (65.4236)  Acc@5: 93.7500 (91.8606)  time: 0.3496  data: 0.0013  max mem: 2500
Train: Epoch[4/5]  [2910/4579]  eta: 0:09:40  Lr: 0.001875  Loss: 0.5554  Acc@1: 68.7500 (65.4393)  Acc@5: 93.7500 (91.8692)  time: 0.3478  data: 0.0018  max mem: 2500
Train: Epoch[4/5]  [2920/4579]  eta: 0:09:36  Lr: 0.001875  Loss: -0.5539  Acc@1: 68.7500 (65.4613)  Acc@5: 93.7500 (91.8671)  time: 0.3476  data: 0.0019  max mem: 2500
Train: Epoch[4/5]  [2930/4579]  eta: 0:09:33  Lr: 0.001875  Loss: 0.0290  Acc@1: 68.7500 (65.4427)  Acc@5: 93.7500 (91.8671)  time: 0.3490  data: 0.0013  max mem: 2500
Train: Epoch[4/5]  [2940/4579]  eta: 0:09:29  Lr: 0.001875  Loss: 0.0839  Acc@1: 62.5000 (65.4391)  Acc@5: 87.5000 (91.8608)  time: 0.3480  data: 0.0013  max mem: 2500
Train: Epoch[4/5]  [2950/4579]  eta: 0:09:26  Lr: 0.001875  Loss: -0.3995  Acc@1: 68.7500 (65.4354)  Acc@5: 93.7500 (91.8735)  time: 0.3468  data: 0.0012  max mem: 2500
Train: Epoch[4/5]  [2960/4579]  eta: 0:09:22  Lr: 0.001875  Loss: -0.7124  Acc@1: 68.7500 (65.4509)  Acc@5: 93.7500 (91.8841)  time: 0.3471  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [2970/4579]  eta: 0:09:19  Lr: 0.001875  Loss: -0.3210  Acc@1: 68.7500 (65.4536)  Acc@5: 93.7500 (91.8840)  time: 0.3479  data: 0.0009  max mem: 2500
Train: Epoch[4/5]  [2980/4579]  eta: 0:09:15  Lr: 0.001875  Loss: -0.4269  Acc@1: 62.5000 (65.4415)  Acc@5: 93.7500 (91.8819)  time: 0.3474  data: 0.0016  max mem: 2500
Train: Epoch[4/5]  [2990/4579]  eta: 0:09:12  Lr: 0.001875  Loss: -0.5617  Acc@1: 68.7500 (65.4463)  Acc@5: 87.5000 (91.8735)  time: 0.3472  data: 0.0013  max mem: 2500
Train: Epoch[4/5]  [3000/4579]  eta: 0:09:08  Lr: 0.001875  Loss: -0.3195  Acc@1: 68.7500 (65.4532)  Acc@5: 87.5000 (91.8715)  time: 0.3482  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [3010/4579]  eta: 0:09:05  Lr: 0.001875  Loss: 0.4691  Acc@1: 68.7500 (65.4600)  Acc@5: 87.5000 (91.8694)  time: 0.3467  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [3020/4579]  eta: 0:09:01  Lr: 0.001875  Loss: -0.2141  Acc@1: 68.7500 (65.4750)  Acc@5: 93.7500 (91.8777)  time: 0.3463  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [3030/4579]  eta: 0:08:58  Lr: 0.001875  Loss: 0.2697  Acc@1: 68.7500 (65.4755)  Acc@5: 93.7500 (91.8797)  time: 0.3467  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [3040/4579]  eta: 0:08:54  Lr: 0.001875  Loss: 0.5121  Acc@1: 62.5000 (65.4678)  Acc@5: 93.7500 (91.8859)  time: 0.3462  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [3050/4579]  eta: 0:08:51  Lr: 0.001875  Loss: -0.9316  Acc@1: 68.7500 (65.4662)  Acc@5: 93.7500 (91.8777)  time: 0.3461  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [3060/4579]  eta: 0:08:48  Lr: 0.001875  Loss: -0.6678  Acc@1: 68.7500 (65.4749)  Acc@5: 93.7500 (91.8858)  time: 0.3467  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [3070/4579]  eta: 0:08:44  Lr: 0.001875  Loss: -0.0321  Acc@1: 62.5000 (65.4754)  Acc@5: 93.7500 (91.8838)  time: 0.3476  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [3080/4579]  eta: 0:08:41  Lr: 0.001875  Loss: -0.0013  Acc@1: 62.5000 (65.4718)  Acc@5: 93.7500 (91.8837)  time: 0.3469  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [3090/4579]  eta: 0:08:37  Lr: 0.001875  Loss: 0.5936  Acc@1: 62.5000 (65.4824)  Acc@5: 93.7500 (91.8797)  time: 0.3459  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [3100/4579]  eta: 0:08:34  Lr: 0.001875  Loss: -0.0345  Acc@1: 68.7500 (65.4869)  Acc@5: 93.7500 (91.8877)  time: 0.3467  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3110/4579]  eta: 0:08:30  Lr: 0.001875  Loss: -0.6510  Acc@1: 68.7500 (65.4874)  Acc@5: 93.7500 (91.8796)  time: 0.3479  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3120/4579]  eta: 0:08:27  Lr: 0.001875  Loss: -0.2676  Acc@1: 68.7500 (65.5038)  Acc@5: 93.7500 (91.8856)  time: 0.3468  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [3130/4579]  eta: 0:08:23  Lr: 0.001875  Loss: -0.5016  Acc@1: 75.0000 (65.5262)  Acc@5: 93.7500 (91.8916)  time: 0.3465  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [3140/4579]  eta: 0:08:20  Lr: 0.001875  Loss: -0.3727  Acc@1: 68.7500 (65.5305)  Acc@5: 93.7500 (91.8836)  time: 0.3458  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [3150/4579]  eta: 0:08:16  Lr: 0.001875  Loss: -0.2865  Acc@1: 68.7500 (65.5288)  Acc@5: 93.7500 (91.8776)  time: 0.3476  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3160/4579]  eta: 0:08:13  Lr: 0.001875  Loss: 0.3407  Acc@1: 68.7500 (65.5172)  Acc@5: 87.5000 (91.8697)  time: 0.3519  data: 0.0024  max mem: 2500
Train: Epoch[4/5]  [3170/4579]  eta: 0:08:09  Lr: 0.001875  Loss: 0.1936  Acc@1: 62.5000 (65.5097)  Acc@5: 87.5000 (91.8677)  time: 0.3536  data: 0.0041  max mem: 2500
Train: Epoch[4/5]  [3180/4579]  eta: 0:08:06  Lr: 0.001875  Loss: -0.7000  Acc@1: 62.5000 (65.4983)  Acc@5: 93.7500 (91.8677)  time: 0.3533  data: 0.0025  max mem: 2500
Train: Epoch[4/5]  [3190/4579]  eta: 0:08:02  Lr: 0.001875  Loss: -0.5757  Acc@1: 68.7500 (65.5222)  Acc@5: 93.7500 (91.8756)  time: 0.3509  data: 0.0009  max mem: 2500
Train: Epoch[4/5]  [3200/4579]  eta: 0:07:59  Lr: 0.001875  Loss: -0.6338  Acc@1: 68.7500 (65.5166)  Acc@5: 93.7500 (91.8775)  time: 0.3485  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [3210/4579]  eta: 0:07:55  Lr: 0.001875  Loss: -0.2995  Acc@1: 62.5000 (65.5111)  Acc@5: 87.5000 (91.8697)  time: 0.3480  data: 0.0011  max mem: 2500
Train: Epoch[4/5]  [3220/4579]  eta: 0:07:52  Lr: 0.001875  Loss: 0.3568  Acc@1: 62.5000 (65.5095)  Acc@5: 87.5000 (91.8659)  time: 0.3473  data: 0.0011  max mem: 2500
Train: Epoch[4/5]  [3230/4579]  eta: 0:07:48  Lr: 0.001875  Loss: -0.2529  Acc@1: 62.5000 (65.5080)  Acc@5: 93.7500 (91.8678)  time: 0.3470  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [3240/4579]  eta: 0:07:45  Lr: 0.001875  Loss: 0.6526  Acc@1: 62.5000 (65.4890)  Acc@5: 87.5000 (91.8428)  time: 0.3480  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3250/4579]  eta: 0:07:42  Lr: 0.001875  Loss: 0.1200  Acc@1: 62.5000 (65.4972)  Acc@5: 87.5000 (91.8467)  time: 0.3471  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [3260/4579]  eta: 0:07:38  Lr: 0.001875  Loss: 0.2772  Acc@1: 62.5000 (65.4650)  Acc@5: 93.7500 (91.8411)  time: 0.3455  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [3270/4579]  eta: 0:07:35  Lr: 0.001875  Loss: 0.1714  Acc@1: 56.2500 (65.4578)  Acc@5: 93.7500 (91.8393)  time: 0.3473  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [3280/4579]  eta: 0:07:31  Lr: 0.001875  Loss: -0.1761  Acc@1: 68.7500 (65.4602)  Acc@5: 93.7500 (91.8413)  time: 0.3482  data: 0.0011  max mem: 2500
Train: Epoch[4/5]  [3290/4579]  eta: 0:07:28  Lr: 0.001875  Loss: 0.1402  Acc@1: 62.5000 (65.4531)  Acc@5: 93.7500 (91.8376)  time: 0.3468  data: 0.0010  max mem: 2500
Train: Epoch[4/5]  [3300/4579]  eta: 0:07:24  Lr: 0.001875  Loss: -0.2250  Acc@1: 62.5000 (65.4688)  Acc@5: 93.7500 (91.8415)  time: 0.3474  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [3310/4579]  eta: 0:07:21  Lr: 0.001875  Loss: -0.0565  Acc@1: 62.5000 (65.4730)  Acc@5: 93.7500 (91.8454)  time: 0.3481  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [3320/4579]  eta: 0:07:17  Lr: 0.001875  Loss: -0.4968  Acc@1: 68.7500 (65.4829)  Acc@5: 93.7500 (91.8473)  time: 0.3467  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [3330/4579]  eta: 0:07:14  Lr: 0.001875  Loss: -0.0222  Acc@1: 68.7500 (65.4833)  Acc@5: 87.5000 (91.8399)  time: 0.3456  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [3340/4579]  eta: 0:07:10  Lr: 0.001875  Loss: -0.0271  Acc@1: 68.7500 (65.5006)  Acc@5: 87.5000 (91.8419)  time: 0.3460  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [3350/4579]  eta: 0:07:07  Lr: 0.001875  Loss: -0.3321  Acc@1: 68.7500 (65.5066)  Acc@5: 93.7500 (91.8383)  time: 0.3475  data: 0.0013  max mem: 2500
Train: Epoch[4/5]  [3360/4579]  eta: 0:07:03  Lr: 0.001875  Loss: 0.0953  Acc@1: 68.7500 (65.5274)  Acc@5: 93.7500 (91.8421)  time: 0.3493  data: 0.0027  max mem: 2500
Train: Epoch[4/5]  [3370/4579]  eta: 0:07:00  Lr: 0.001875  Loss: 0.8916  Acc@1: 68.7500 (65.5258)  Acc@5: 93.7500 (91.8459)  time: 0.3491  data: 0.0019  max mem: 2500
Train: Epoch[4/5]  [3380/4579]  eta: 0:06:56  Lr: 0.001875  Loss: -0.5462  Acc@1: 62.5000 (65.5206)  Acc@5: 93.7500 (91.8441)  time: 0.3479  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [3390/4579]  eta: 0:06:53  Lr: 0.001875  Loss: 0.4139  Acc@1: 62.5000 (65.5338)  Acc@5: 93.7500 (91.8553)  time: 0.3462  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [3400/4579]  eta: 0:06:49  Lr: 0.001875  Loss: 0.1629  Acc@1: 62.5000 (65.5248)  Acc@5: 93.7500 (91.8498)  time: 0.3456  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [3410/4579]  eta: 0:06:46  Lr: 0.001875  Loss: -0.1937  Acc@1: 62.5000 (65.5233)  Acc@5: 93.7500 (91.8609)  time: 0.3474  data: 0.0012  max mem: 2500
Train: Epoch[4/5]  [3420/4579]  eta: 0:06:42  Lr: 0.001875  Loss: -0.1074  Acc@1: 68.7500 (65.5382)  Acc@5: 93.7500 (91.8664)  time: 0.3474  data: 0.0011  max mem: 2500
Train: Epoch[4/5]  [3430/4579]  eta: 0:06:39  Lr: 0.001875  Loss: -0.1011  Acc@1: 68.7500 (65.5257)  Acc@5: 93.7500 (91.8610)  time: 0.3458  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [3440/4579]  eta: 0:06:35  Lr: 0.001875  Loss: -0.4105  Acc@1: 62.5000 (65.5315)  Acc@5: 93.7500 (91.8610)  time: 0.3468  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [3450/4579]  eta: 0:06:32  Lr: 0.001875  Loss: 0.3917  Acc@1: 62.5000 (65.5317)  Acc@5: 93.7500 (91.8592)  time: 0.3483  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [3460/4579]  eta: 0:06:28  Lr: 0.001875  Loss: -0.3409  Acc@1: 62.5000 (65.5320)  Acc@5: 93.7500 (91.8575)  time: 0.3484  data: 0.0010  max mem: 2500
Train: Epoch[4/5]  [3470/4579]  eta: 0:06:25  Lr: 0.001875  Loss: 0.8765  Acc@1: 62.5000 (65.5251)  Acc@5: 93.7500 (91.8575)  time: 0.3471  data: 0.0016  max mem: 2500
Train: Epoch[4/5]  [3480/4579]  eta: 0:06:22  Lr: 0.001875  Loss: -0.3017  Acc@1: 62.5000 (65.5415)  Acc@5: 93.7500 (91.8594)  time: 0.3472  data: 0.0013  max mem: 2500
Train: Epoch[4/5]  [3490/4579]  eta: 0:06:18  Lr: 0.001875  Loss: 0.3842  Acc@1: 68.7500 (65.5543)  Acc@5: 93.7500 (91.8576)  time: 0.3478  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [3500/4579]  eta: 0:06:15  Lr: 0.001875  Loss: -0.0678  Acc@1: 68.7500 (65.5741)  Acc@5: 93.7500 (91.8559)  time: 0.3468  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [3510/4579]  eta: 0:06:11  Lr: 0.001875  Loss: 0.0425  Acc@1: 68.7500 (65.5796)  Acc@5: 93.7500 (91.8577)  time: 0.3463  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [3520/4579]  eta: 0:06:08  Lr: 0.001875  Loss: -0.5303  Acc@1: 62.5000 (65.5886)  Acc@5: 93.7500 (91.8578)  time: 0.3469  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [3530/4579]  eta: 0:06:04  Lr: 0.001875  Loss: -0.3507  Acc@1: 68.7500 (65.5993)  Acc@5: 93.7500 (91.8667)  time: 0.3468  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [3540/4579]  eta: 0:06:01  Lr: 0.001875  Loss: 0.3325  Acc@1: 68.7500 (65.5941)  Acc@5: 93.7500 (91.8579)  time: 0.3459  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3550/4579]  eta: 0:05:57  Lr: 0.001875  Loss: -0.2512  Acc@1: 68.7500 (65.6100)  Acc@5: 93.7500 (91.8720)  time: 0.3473  data: 0.0015  max mem: 2500
Train: Epoch[4/5]  [3560/4579]  eta: 0:05:54  Lr: 0.001875  Loss: -0.1319  Acc@1: 68.7500 (65.6118)  Acc@5: 93.7500 (91.8685)  time: 0.3475  data: 0.0016  max mem: 2500
Train: Epoch[4/5]  [3570/4579]  eta: 0:05:50  Lr: 0.001875  Loss: -0.1959  Acc@1: 68.7500 (65.6154)  Acc@5: 93.7500 (91.8685)  time: 0.3454  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [3580/4579]  eta: 0:05:47  Lr: 0.001875  Loss: -0.8825  Acc@1: 68.7500 (65.6294)  Acc@5: 93.7500 (91.8773)  time: 0.3450  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [3590/4579]  eta: 0:05:43  Lr: 0.001875  Loss: -0.3438  Acc@1: 68.7500 (65.6520)  Acc@5: 93.7500 (91.8807)  time: 0.3458  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3600/4579]  eta: 0:05:40  Lr: 0.001875  Loss: 0.1995  Acc@1: 68.7500 (65.6415)  Acc@5: 93.7500 (91.8773)  time: 0.3477  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [3610/4579]  eta: 0:05:36  Lr: 0.001875  Loss: -0.1588  Acc@1: 62.5000 (65.6311)  Acc@5: 87.5000 (91.8721)  time: 0.3469  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [3620/4579]  eta: 0:05:33  Lr: 0.001875  Loss: -0.9435  Acc@1: 62.5000 (65.6345)  Acc@5: 93.7500 (91.8755)  time: 0.3462  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [3630/4579]  eta: 0:05:29  Lr: 0.001875  Loss: -0.7005  Acc@1: 62.5000 (65.6362)  Acc@5: 93.7500 (91.8824)  time: 0.3492  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [3640/4579]  eta: 0:05:26  Lr: 0.001875  Loss: 0.1465  Acc@1: 68.7500 (65.6516)  Acc@5: 93.7500 (91.8841)  time: 0.3489  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [3650/4579]  eta: 0:05:22  Lr: 0.001875  Loss: 0.2974  Acc@1: 68.7500 (65.6430)  Acc@5: 93.7500 (91.8858)  time: 0.3467  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [3660/4579]  eta: 0:05:19  Lr: 0.001875  Loss: 0.0981  Acc@1: 68.7500 (65.6446)  Acc@5: 93.7500 (91.8909)  time: 0.3475  data: 0.0013  max mem: 2500
Train: Epoch[4/5]  [3670/4579]  eta: 0:05:15  Lr: 0.001875  Loss: 0.1274  Acc@1: 68.7500 (65.6463)  Acc@5: 87.5000 (91.8874)  time: 0.3469  data: 0.0010  max mem: 2500
Train: Epoch[4/5]  [3680/4579]  eta: 0:05:12  Lr: 0.001875  Loss: -0.6888  Acc@1: 68.7500 (65.6513)  Acc@5: 87.5000 (91.8874)  time: 0.3457  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [3690/4579]  eta: 0:05:08  Lr: 0.001875  Loss: -0.1063  Acc@1: 68.7500 (65.6597)  Acc@5: 93.7500 (91.8924)  time: 0.3465  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [3700/4579]  eta: 0:05:05  Lr: 0.001875  Loss: -0.0951  Acc@1: 68.7500 (65.6731)  Acc@5: 93.7500 (91.8941)  time: 0.3469  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [3710/4579]  eta: 0:05:02  Lr: 0.001875  Loss: 0.6289  Acc@1: 68.7500 (65.6713)  Acc@5: 93.7500 (91.8974)  time: 0.3490  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [3720/4579]  eta: 0:04:58  Lr: 0.001875  Loss: 0.2111  Acc@1: 68.7500 (65.6729)  Acc@5: 87.5000 (91.8889)  time: 0.3481  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [3730/4579]  eta: 0:04:55  Lr: 0.001875  Loss: 0.2860  Acc@1: 62.5000 (65.6560)  Acc@5: 87.5000 (91.8839)  time: 0.3462  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [3740/4579]  eta: 0:04:51  Lr: 0.001875  Loss: -0.5814  Acc@1: 68.7500 (65.6592)  Acc@5: 93.7500 (91.8822)  time: 0.3500  data: 0.0024  max mem: 2500
Train: Epoch[4/5]  [3750/4579]  eta: 0:04:48  Lr: 0.001875  Loss: 0.1662  Acc@1: 68.7500 (65.6392)  Acc@5: 93.7500 (91.8838)  time: 0.3526  data: 0.0041  max mem: 2500
Train: Epoch[4/5]  [3760/4579]  eta: 0:04:44  Lr: 0.001875  Loss: 0.1555  Acc@1: 62.5000 (65.6341)  Acc@5: 87.5000 (91.8672)  time: 0.3494  data: 0.0030  max mem: 2500
Train: Epoch[4/5]  [3770/4579]  eta: 0:04:41  Lr: 0.001875  Loss: -0.1329  Acc@1: 68.7500 (65.6391)  Acc@5: 87.5000 (91.8722)  time: 0.3479  data: 0.0014  max mem: 2500
Train: Epoch[4/5]  [3780/4579]  eta: 0:04:37  Lr: 0.001875  Loss: -0.3490  Acc@1: 68.7500 (65.6407)  Acc@5: 93.7500 (91.8755)  time: 0.3500  data: 0.0009  max mem: 2500
Train: Epoch[4/5]  [3790/4579]  eta: 0:04:34  Lr: 0.001875  Loss: 0.0057  Acc@1: 68.7500 (65.6341)  Acc@5: 93.7500 (91.8821)  time: 0.3482  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [3800/4579]  eta: 0:04:30  Lr: 0.001875  Loss: 0.7773  Acc@1: 68.7500 (65.6505)  Acc@5: 93.7500 (91.8821)  time: 0.3465  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [3810/4579]  eta: 0:04:27  Lr: 0.001875  Loss: -0.3719  Acc@1: 68.7500 (65.6586)  Acc@5: 93.7500 (91.8886)  time: 0.3484  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [3820/4579]  eta: 0:04:23  Lr: 0.001875  Loss: -0.0879  Acc@1: 68.7500 (65.6667)  Acc@5: 93.7500 (91.8869)  time: 0.3501  data: 0.0030  max mem: 2500
Train: Epoch[4/5]  [3830/4579]  eta: 0:04:20  Lr: 0.001875  Loss: -0.1940  Acc@1: 62.5000 (65.6552)  Acc@5: 93.7500 (91.8869)  time: 0.3491  data: 0.0030  max mem: 2500
Train: Epoch[4/5]  [3840/4579]  eta: 0:04:16  Lr: 0.001875  Loss: -0.2026  Acc@1: 62.5000 (65.6535)  Acc@5: 93.7500 (91.8804)  time: 0.3484  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [3850/4579]  eta: 0:04:13  Lr: 0.001875  Loss: -0.3432  Acc@1: 68.7500 (65.6713)  Acc@5: 93.7500 (91.8820)  time: 0.3494  data: 0.0009  max mem: 2500
Train: Epoch[4/5]  [3860/4579]  eta: 0:04:09  Lr: 0.001875  Loss: -0.1769  Acc@1: 75.0000 (65.6744)  Acc@5: 93.7500 (91.8739)  time: 0.3486  data: 0.0011  max mem: 2500
Train: Epoch[4/5]  [3870/4579]  eta: 0:04:06  Lr: 0.001875  Loss: 0.1019  Acc@1: 68.7500 (65.6839)  Acc@5: 87.5000 (91.8674)  time: 0.3478  data: 0.0010  max mem: 2500
Train: Epoch[4/5]  [3880/4579]  eta: 0:04:02  Lr: 0.001875  Loss: 0.5393  Acc@1: 62.5000 (65.6822)  Acc@5: 87.5000 (91.8610)  time: 0.3479  data: 0.0013  max mem: 2500
Train: Epoch[4/5]  [3890/4579]  eta: 0:03:59  Lr: 0.001875  Loss: -0.0578  Acc@1: 62.5000 (65.6868)  Acc@5: 93.7500 (91.8675)  time: 0.3472  data: 0.0013  max mem: 2500
Train: Epoch[4/5]  [3900/4579]  eta: 0:03:56  Lr: 0.001875  Loss: 0.0889  Acc@1: 62.5000 (65.6899)  Acc@5: 93.7500 (91.8707)  time: 0.3469  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [3910/4579]  eta: 0:03:52  Lr: 0.001875  Loss: 0.0009  Acc@1: 68.7500 (65.7025)  Acc@5: 93.7500 (91.8739)  time: 0.3466  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [3920/4579]  eta: 0:03:49  Lr: 0.001875  Loss: -0.3872  Acc@1: 68.7500 (65.7071)  Acc@5: 93.7500 (91.8707)  time: 0.3460  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3930/4579]  eta: 0:03:45  Lr: 0.001875  Loss: -0.2525  Acc@1: 62.5000 (65.7037)  Acc@5: 93.7500 (91.8691)  time: 0.3471  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [3940/4579]  eta: 0:03:42  Lr: 0.001875  Loss: -0.7816  Acc@1: 62.5000 (65.7067)  Acc@5: 93.7500 (91.8707)  time: 0.3489  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [3950/4579]  eta: 0:03:38  Lr: 0.001875  Loss: 0.5068  Acc@1: 62.5000 (65.7112)  Acc@5: 93.7500 (91.8612)  time: 0.3537  data: 0.0011  max mem: 2500
Train: Epoch[4/5]  [3960/4579]  eta: 0:03:35  Lr: 0.001875  Loss: -0.2870  Acc@1: 62.5000 (65.7094)  Acc@5: 93.7500 (91.8739)  time: 0.3522  data: 0.0013  max mem: 2500
Train: Epoch[4/5]  [3970/4579]  eta: 0:03:31  Lr: 0.001875  Loss: 0.2058  Acc@1: 62.5000 (65.7092)  Acc@5: 93.7500 (91.8770)  time: 0.3482  data: 0.0012  max mem: 2500
Train: Epoch[4/5]  [3980/4579]  eta: 0:03:28  Lr: 0.001875  Loss: 0.2099  Acc@1: 68.7500 (65.7200)  Acc@5: 93.7500 (91.8786)  time: 0.3478  data: 0.0010  max mem: 2500
Train: Epoch[4/5]  [3990/4579]  eta: 0:03:24  Lr: 0.001875  Loss: -0.2492  Acc@1: 68.7500 (65.7119)  Acc@5: 93.7500 (91.8755)  time: 0.3469  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [4000/4579]  eta: 0:03:21  Lr: 0.001875  Loss: 0.3637  Acc@1: 56.2500 (65.6883)  Acc@5: 87.5000 (91.8739)  time: 0.3482  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [4010/4579]  eta: 0:03:17  Lr: 0.001875  Loss: -0.1948  Acc@1: 62.5000 (65.6897)  Acc@5: 93.7500 (91.8739)  time: 0.3466  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [4020/4579]  eta: 0:03:14  Lr: 0.001875  Loss: -0.3416  Acc@1: 62.5000 (65.6833)  Acc@5: 93.7500 (91.8879)  time: 0.3457  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [4030/4579]  eta: 0:03:10  Lr: 0.001875  Loss: -0.2363  Acc@1: 62.5000 (65.6986)  Acc@5: 100.0000 (91.8941)  time: 0.3461  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [4040/4579]  eta: 0:03:07  Lr: 0.001875  Loss: 0.2910  Acc@1: 62.5000 (65.6985)  Acc@5: 93.7500 (91.8863)  time: 0.3456  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [4050/4579]  eta: 0:03:03  Lr: 0.001875  Loss: 0.0863  Acc@1: 62.5000 (65.6998)  Acc@5: 87.5000 (91.8863)  time: 0.3466  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [4060/4579]  eta: 0:03:00  Lr: 0.001875  Loss: 0.0399  Acc@1: 68.7500 (65.7043)  Acc@5: 93.7500 (91.8816)  time: 0.3489  data: 0.0027  max mem: 2500
Train: Epoch[4/5]  [4070/4579]  eta: 0:02:56  Lr: 0.001875  Loss: 0.6180  Acc@1: 62.5000 (65.6918)  Acc@5: 87.5000 (91.8709)  time: 0.3483  data: 0.0022  max mem: 2500
Train: Epoch[4/5]  [4080/4579]  eta: 0:02:53  Lr: 0.001875  Loss: 0.2497  Acc@1: 62.5000 (65.6932)  Acc@5: 93.7500 (91.8816)  time: 0.3471  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [4090/4579]  eta: 0:02:49  Lr: 0.001875  Loss: 0.0312  Acc@1: 68.7500 (65.7006)  Acc@5: 93.7500 (91.8892)  time: 0.3476  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [4100/4579]  eta: 0:02:46  Lr: 0.001875  Loss: -0.4156  Acc@1: 68.7500 (65.7065)  Acc@5: 93.7500 (91.8922)  time: 0.3463  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [4110/4579]  eta: 0:02:43  Lr: 0.001875  Loss: -0.0390  Acc@1: 62.5000 (65.7063)  Acc@5: 93.7500 (91.8831)  time: 0.3463  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [4120/4579]  eta: 0:02:39  Lr: 0.001875  Loss: -0.6920  Acc@1: 62.5000 (65.7077)  Acc@5: 87.5000 (91.8815)  time: 0.3473  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [4130/4579]  eta: 0:02:36  Lr: 0.001875  Loss: 0.4796  Acc@1: 62.5000 (65.7075)  Acc@5: 87.5000 (91.8724)  time: 0.3478  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [4140/4579]  eta: 0:02:32  Lr: 0.001875  Loss: -0.1011  Acc@1: 68.7500 (65.7223)  Acc@5: 87.5000 (91.8739)  time: 0.3484  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [4150/4579]  eta: 0:02:29  Lr: 0.001875  Loss: -0.1557  Acc@1: 68.7500 (65.7311)  Acc@5: 93.7500 (91.8724)  time: 0.3470  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [4160/4579]  eta: 0:02:25  Lr: 0.001875  Loss: 0.0357  Acc@1: 68.7500 (65.7234)  Acc@5: 93.7500 (91.8709)  time: 0.3483  data: 0.0014  max mem: 2500
Train: Epoch[4/5]  [4170/4579]  eta: 0:02:22  Lr: 0.001875  Loss: -0.2763  Acc@1: 62.5000 (65.7172)  Acc@5: 93.7500 (91.8710)  time: 0.3496  data: 0.0015  max mem: 2500
Train: Epoch[4/5]  [4180/4579]  eta: 0:02:18  Lr: 0.001875  Loss: -0.2664  Acc@1: 62.5000 (65.7304)  Acc@5: 93.7500 (91.8710)  time: 0.3473  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [4190/4579]  eta: 0:02:15  Lr: 0.001875  Loss: -0.4762  Acc@1: 68.7500 (65.7301)  Acc@5: 93.7500 (91.8680)  time: 0.3481  data: 0.0012  max mem: 2500
Train: Epoch[4/5]  [4200/4579]  eta: 0:02:11  Lr: 0.001875  Loss: -0.1992  Acc@1: 62.5000 (65.7254)  Acc@5: 93.7500 (91.8695)  time: 0.3489  data: 0.0019  max mem: 2500
Train: Epoch[4/5]  [4210/4579]  eta: 0:02:08  Lr: 0.001875  Loss: -0.2669  Acc@1: 62.5000 (65.7207)  Acc@5: 93.7500 (91.8651)  time: 0.3479  data: 0.0014  max mem: 2500
Train: Epoch[4/5]  [4220/4579]  eta: 0:02:04  Lr: 0.001875  Loss: 0.4203  Acc@1: 62.5000 (65.7161)  Acc@5: 87.5000 (91.8577)  time: 0.3472  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [4230/4579]  eta: 0:02:01  Lr: 0.001875  Loss: -0.2037  Acc@1: 62.5000 (65.7188)  Acc@5: 93.7500 (91.8592)  time: 0.3470  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [4240/4579]  eta: 0:01:57  Lr: 0.001875  Loss: 0.0660  Acc@1: 62.5000 (65.7112)  Acc@5: 87.5000 (91.8578)  time: 0.3470  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [4250/4579]  eta: 0:01:54  Lr: 0.001875  Loss: -0.0793  Acc@1: 62.5000 (65.7022)  Acc@5: 87.5000 (91.8607)  time: 0.3478  data: 0.0011  max mem: 2500
Train: Epoch[4/5]  [4260/4579]  eta: 0:01:50  Lr: 0.001875  Loss: -0.1375  Acc@1: 62.5000 (65.6991)  Acc@5: 93.7500 (91.8593)  time: 0.3468  data: 0.0011  max mem: 2500
Train: Epoch[4/5]  [4270/4579]  eta: 0:01:47  Lr: 0.001875  Loss: -0.2767  Acc@1: 62.5000 (65.6930)  Acc@5: 93.7500 (91.8506)  time: 0.3450  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [4280/4579]  eta: 0:01:43  Lr: 0.001875  Loss: -0.0437  Acc@1: 62.5000 (65.6812)  Acc@5: 87.5000 (91.8462)  time: 0.3470  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [4290/4579]  eta: 0:01:40  Lr: 0.001875  Loss: 0.1058  Acc@1: 56.2500 (65.6723)  Acc@5: 87.5000 (91.8361)  time: 0.3476  data: 0.0013  max mem: 2500
Train: Epoch[4/5]  [4300/4579]  eta: 0:01:36  Lr: 0.001875  Loss: 0.2823  Acc@1: 62.5000 (65.6809)  Acc@5: 87.5000 (91.8333)  time: 0.3464  data: 0.0013  max mem: 2500
Train: Epoch[4/5]  [4310/4579]  eta: 0:01:33  Lr: 0.001875  Loss: 0.1388  Acc@1: 68.7500 (65.6765)  Acc@5: 93.7500 (91.8290)  time: 0.3472  data: 0.0013  max mem: 2500
Train: Epoch[4/5]  [4320/4579]  eta: 0:01:30  Lr: 0.001875  Loss: -0.3842  Acc@1: 62.5000 (65.6778)  Acc@5: 93.7500 (91.8263)  time: 0.3469  data: 0.0014  max mem: 2500
Train: Epoch[4/5]  [4330/4579]  eta: 0:01:26  Lr: 0.001875  Loss: 0.6916  Acc@1: 62.5000 (65.6733)  Acc@5: 93.7500 (91.8278)  time: 0.3459  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [4340/4579]  eta: 0:01:23  Lr: 0.001875  Loss: -0.0429  Acc@1: 62.5000 (65.6588)  Acc@5: 93.7500 (91.8150)  time: 0.3468  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [4350/4579]  eta: 0:01:19  Lr: 0.001875  Loss: 0.4645  Acc@1: 68.7500 (65.6674)  Acc@5: 93.7500 (91.8223)  time: 0.3479  data: 0.0009  max mem: 2500
Train: Epoch[4/5]  [4360/4579]  eta: 0:01:16  Lr: 0.001875  Loss: -0.2031  Acc@1: 68.7500 (65.6673)  Acc@5: 93.7500 (91.8224)  time: 0.3484  data: 0.0010  max mem: 2500
Train: Epoch[4/5]  [4370/4579]  eta: 0:01:12  Lr: 0.001875  Loss: -0.1318  Acc@1: 62.5000 (65.6586)  Acc@5: 93.7500 (91.8197)  time: 0.3469  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [4380/4579]  eta: 0:01:09  Lr: 0.001875  Loss: -0.2679  Acc@1: 68.7500 (65.6699)  Acc@5: 93.7500 (91.8255)  time: 0.3468  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [4390/4579]  eta: 0:01:05  Lr: 0.001875  Loss: -0.3514  Acc@1: 68.7500 (65.6713)  Acc@5: 93.7500 (91.8256)  time: 0.3486  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [4400/4579]  eta: 0:01:02  Lr: 0.001875  Loss: -0.6501  Acc@1: 62.5000 (65.6768)  Acc@5: 93.7500 (91.8215)  time: 0.3484  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [4410/4579]  eta: 0:00:58  Lr: 0.001875  Loss: -0.0727  Acc@1: 62.5000 (65.6739)  Acc@5: 93.7500 (91.8216)  time: 0.3473  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [4420/4579]  eta: 0:00:55  Lr: 0.001875  Loss: -0.4443  Acc@1: 62.5000 (65.6738)  Acc@5: 93.7500 (91.8245)  time: 0.3490  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [4430/4579]  eta: 0:00:51  Lr: 0.001875  Loss: 0.2195  Acc@1: 62.5000 (65.6723)  Acc@5: 93.7500 (91.8275)  time: 0.3484  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [4440/4579]  eta: 0:00:48  Lr: 0.001875  Loss: 0.1656  Acc@1: 62.5000 (65.6750)  Acc@5: 93.7500 (91.8290)  time: 0.3469  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [4450/4579]  eta: 0:00:44  Lr: 0.001875  Loss: 0.3362  Acc@1: 68.7500 (65.6763)  Acc@5: 93.7500 (91.8263)  time: 0.3477  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [4460/4579]  eta: 0:00:41  Lr: 0.001875  Loss: -0.0127  Acc@1: 68.7500 (65.6901)  Acc@5: 93.7500 (91.8348)  time: 0.3468  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [4470/4579]  eta: 0:00:37  Lr: 0.001875  Loss: -0.2485  Acc@1: 68.7500 (65.6914)  Acc@5: 93.7500 (91.8405)  time: 0.3470  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [4480/4579]  eta: 0:00:34  Lr: 0.001875  Loss: -0.4631  Acc@1: 68.7500 (65.7052)  Acc@5: 93.7500 (91.8405)  time: 0.3477  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [4490/4579]  eta: 0:00:30  Lr: 0.001875  Loss: 0.0328  Acc@1: 68.7500 (65.7148)  Acc@5: 87.5000 (91.8392)  time: 0.3471  data: 0.0011  max mem: 2500
Train: Epoch[4/5]  [4500/4579]  eta: 0:00:27  Lr: 0.001875  Loss: -0.2733  Acc@1: 68.7500 (65.7312)  Acc@5: 87.5000 (91.8421)  time: 0.3463  data: 0.0012  max mem: 2500
Train: Epoch[4/5]  [4510/4579]  eta: 0:00:23  Lr: 0.001875  Loss: -0.2343  Acc@1: 68.7500 (65.7310)  Acc@5: 93.7500 (91.8435)  time: 0.3461  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [4520/4579]  eta: 0:00:20  Lr: 0.001875  Loss: -0.1921  Acc@1: 68.7500 (65.7335)  Acc@5: 93.7500 (91.8450)  time: 0.3454  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [4530/4579]  eta: 0:00:17  Lr: 0.001875  Loss: -0.0422  Acc@1: 68.7500 (65.7347)  Acc@5: 87.5000 (91.8354)  time: 0.3459  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [4540/4579]  eta: 0:00:13  Lr: 0.001875  Loss: -0.3029  Acc@1: 62.5000 (65.7413)  Acc@5: 87.5000 (91.8327)  time: 0.3473  data: 0.0015  max mem: 2500
Train: Epoch[4/5]  [4550/4579]  eta: 0:00:10  Lr: 0.001875  Loss: 0.2567  Acc@1: 68.7500 (65.7438)  Acc@5: 93.7500 (91.8273)  time: 0.3470  data: 0.0015  max mem: 2500
Train: Epoch[4/5]  [4560/4579]  eta: 0:00:06  Lr: 0.001875  Loss: -0.0560  Acc@1: 68.7500 (65.7490)  Acc@5: 93.7500 (91.8288)  time: 0.3480  data: 0.0019  max mem: 2500
Train: Epoch[4/5]  [4570/4579]  eta: 0:00:03  Lr: 0.001875  Loss: 0.7290  Acc@1: 62.5000 (65.7433)  Acc@5: 93.7500 (91.8344)  time: 0.3488  data: 0.0028  max mem: 2500
Train: Epoch[4/5]  [4578/4579]  eta: 0:00:00  Lr: 0.001875  Loss: 0.1347  Acc@1: 62.5000 (65.7412)  Acc@5: 93.7500 (91.8288)  time: 0.3391  data: 0.0021  max mem: 2500
Train: Epoch[4/5] Total time: 0:26:32 (0.3478 s / it)
{0: {0: 293028, 1: 0, 2: 0, 3: 0, 4: 0}, 1: {0: 293028, 1: 0, 2: 0, 3: 0, 4: 0}, 2: {0: 293028, 1: 0, 2: 0, 3: 0, 4: 0}, 3: {0: 293028, 1: 0, 2: 0, 3: 0, 4: 0}, 4: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 5: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 6: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 7: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 8: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 9: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 10: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 11: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 12: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 13: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 14: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 15: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 16: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 17: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 18: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 19: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}}
Averaged stats: Lr: 0.001875  Loss: 0.1347  Acc@1: 62.5000 (65.7412)  Acc@5: 93.7500 (91.8288)
Train: Epoch[5/5]  [   0/4579]  eta: 0:46:09  Lr: 0.001875  Loss: -0.0128  Acc@1: 62.5000 (62.5000)  Acc@5: 87.5000 (87.5000)  time: 0.6049  data: 0.2601  max mem: 2500
Train: Epoch[5/5]  [  10/4579]  eta: 0:28:20  Lr: 0.001875  Loss: -0.2370  Acc@1: 68.7500 (61.9318)  Acc@5: 93.7500 (89.2045)  time: 0.3721  data: 0.0246  max mem: 2500
Train: Epoch[5/5]  [  20/4579]  eta: 0:27:20  Lr: 0.001875  Loss: 0.4687  Acc@1: 62.5000 (61.9048)  Acc@5: 93.7500 (91.9643)  time: 0.3477  data: 0.0015  max mem: 2500
Train: Epoch[5/5]  [  30/4579]  eta: 0:26:58  Lr: 0.001875  Loss: -0.4050  Acc@1: 62.5000 (63.7097)  Acc@5: 93.7500 (91.1290)  time: 0.3469  data: 0.0013  max mem: 2500
Train: Epoch[5/5]  [  40/4579]  eta: 0:26:47  Lr: 0.001875  Loss: -0.1942  Acc@1: 68.7500 (66.3110)  Acc@5: 93.7500 (91.4634)  time: 0.3483  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [  50/4579]  eta: 0:26:36  Lr: 0.001875  Loss: -0.5047  Acc@1: 68.7500 (66.9118)  Acc@5: 93.7500 (92.0343)  time: 0.3476  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [  60/4579]  eta: 0:26:29  Lr: 0.001875  Loss: 0.4563  Acc@1: 68.7500 (66.4959)  Acc@5: 93.7500 (91.5984)  time: 0.3465  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [  70/4579]  eta: 0:26:23  Lr: 0.001875  Loss: 0.0719  Acc@1: 62.5000 (66.3732)  Acc@5: 93.7500 (91.8134)  time: 0.3474  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [  80/4579]  eta: 0:26:19  Lr: 0.001875  Loss: -0.3464  Acc@1: 62.5000 (66.6667)  Acc@5: 93.7500 (92.3611)  time: 0.3493  data: 0.0016  max mem: 2500
Train: Epoch[5/5]  [  90/4579]  eta: 0:26:14  Lr: 0.001875  Loss: 0.1200  Acc@1: 62.5000 (66.0027)  Acc@5: 93.7500 (92.3764)  time: 0.3494  data: 0.0024  max mem: 2500
Train: Epoch[5/5]  [ 100/4579]  eta: 0:26:09  Lr: 0.001875  Loss: 0.1454  Acc@1: 62.5000 (66.0272)  Acc@5: 93.7500 (92.3886)  time: 0.3471  data: 0.0013  max mem: 2500
Train: Epoch[5/5]  [ 110/4579]  eta: 0:26:03  Lr: 0.001875  Loss: -0.6167  Acc@1: 68.7500 (66.5541)  Acc@5: 93.7500 (92.3986)  time: 0.3464  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [ 120/4579]  eta: 0:25:59  Lr: 0.001875  Loss: -0.2857  Acc@1: 68.7500 (66.5289)  Acc@5: 93.7500 (92.3037)  time: 0.3473  data: 0.0012  max mem: 2500
Train: Epoch[5/5]  [ 130/4579]  eta: 0:25:55  Lr: 0.001875  Loss: -0.0686  Acc@1: 62.5000 (66.2214)  Acc@5: 93.7500 (92.1756)  time: 0.3482  data: 0.0013  max mem: 2500
Train: Epoch[5/5]  [ 140/4579]  eta: 0:25:51  Lr: 0.001875  Loss: 0.0795  Acc@1: 62.5000 (66.3564)  Acc@5: 93.7500 (92.1986)  time: 0.3469  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [ 150/4579]  eta: 0:25:46  Lr: 0.001875  Loss: 0.6619  Acc@1: 62.5000 (66.1424)  Acc@5: 93.7500 (92.2185)  time: 0.3453  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [ 160/4579]  eta: 0:25:42  Lr: 0.001875  Loss: -0.2818  Acc@1: 62.5000 (66.1491)  Acc@5: 93.7500 (92.3137)  time: 0.3462  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [ 170/4579]  eta: 0:25:37  Lr: 0.001875  Loss: -0.1155  Acc@1: 68.7500 (66.3377)  Acc@5: 93.7500 (92.2515)  time: 0.3468  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [ 180/4579]  eta: 0:25:34  Lr: 0.001875  Loss: 0.2312  Acc@1: 62.5000 (66.0566)  Acc@5: 87.5000 (91.9199)  time: 0.3470  data: 0.0015  max mem: 2500
Train: Epoch[5/5]  [ 190/4579]  eta: 0:25:30  Lr: 0.001875  Loss: 0.7518  Acc@1: 62.5000 (66.0995)  Acc@5: 87.5000 (91.8848)  time: 0.3474  data: 0.0018  max mem: 2500
Train: Epoch[5/5]  [ 200/4579]  eta: 0:25:26  Lr: 0.001875  Loss: 0.2110  Acc@1: 68.7500 (66.1070)  Acc@5: 93.7500 (91.7910)  time: 0.3460  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [ 210/4579]  eta: 0:25:22  Lr: 0.001875  Loss: 0.2281  Acc@1: 62.5000 (65.7879)  Acc@5: 93.7500 (91.7654)  time: 0.3463  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [ 220/4579]  eta: 0:25:18  Lr: 0.001875  Loss: -0.1106  Acc@1: 62.5000 (65.7240)  Acc@5: 93.7500 (91.7421)  time: 0.3467  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [ 230/4579]  eta: 0:25:15  Lr: 0.001875  Loss: 0.2470  Acc@1: 68.7500 (65.7197)  Acc@5: 93.7500 (91.7208)  time: 0.3474  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [ 240/4579]  eta: 0:25:11  Lr: 0.001875  Loss: -0.1819  Acc@1: 68.7500 (65.9232)  Acc@5: 93.7500 (91.7790)  time: 0.3490  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [ 250/4579]  eta: 0:25:07  Lr: 0.001875  Loss: -0.2426  Acc@1: 68.7500 (66.0857)  Acc@5: 93.7500 (91.9074)  time: 0.3474  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [ 260/4579]  eta: 0:25:03  Lr: 0.001875  Loss: -0.3550  Acc@1: 68.7500 (66.2835)  Acc@5: 93.7500 (91.8822)  time: 0.3459  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 270/4579]  eta: 0:25:00  Lr: 0.001875  Loss: -0.5322  Acc@1: 68.7500 (66.3284)  Acc@5: 93.7500 (91.9742)  time: 0.3466  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [ 280/4579]  eta: 0:24:56  Lr: 0.001875  Loss: -0.1666  Acc@1: 62.5000 (66.3479)  Acc@5: 93.7500 (91.8594)  time: 0.3475  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [ 290/4579]  eta: 0:24:53  Lr: 0.001875  Loss: -0.2646  Acc@1: 68.7500 (66.3230)  Acc@5: 87.5000 (91.9244)  time: 0.3476  data: 0.0012  max mem: 2500
Train: Epoch[5/5]  [ 300/4579]  eta: 0:24:49  Lr: 0.001875  Loss: -0.1307  Acc@1: 68.7500 (66.4452)  Acc@5: 93.7500 (92.0473)  time: 0.3467  data: 0.0011  max mem: 2500
Train: Epoch[5/5]  [ 310/4579]  eta: 0:24:45  Lr: 0.001875  Loss: -0.4449  Acc@1: 68.7500 (66.4590)  Acc@5: 93.7500 (92.0217)  time: 0.3469  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [ 320/4579]  eta: 0:24:42  Lr: 0.001875  Loss: 0.2126  Acc@1: 62.5000 (66.4330)  Acc@5: 87.5000 (91.9003)  time: 0.3467  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [ 330/4579]  eta: 0:24:38  Lr: 0.001875  Loss: 0.5070  Acc@1: 62.5000 (66.5030)  Acc@5: 93.7500 (91.8807)  time: 0.3472  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [ 340/4579]  eta: 0:24:35  Lr: 0.001875  Loss: -0.5874  Acc@1: 68.7500 (66.5506)  Acc@5: 93.7500 (91.8622)  time: 0.3479  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [ 350/4579]  eta: 0:24:31  Lr: 0.001875  Loss: 0.1394  Acc@1: 62.5000 (66.4708)  Acc@5: 93.7500 (91.8269)  time: 0.3475  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [ 360/4579]  eta: 0:24:27  Lr: 0.001875  Loss: -0.2870  Acc@1: 62.5000 (66.4474)  Acc@5: 93.7500 (91.7763)  time: 0.3466  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [ 370/4579]  eta: 0:24:24  Lr: 0.001875  Loss: -0.2216  Acc@1: 62.5000 (66.1725)  Acc@5: 93.7500 (91.7621)  time: 0.3476  data: 0.0013  max mem: 2500
Train: Epoch[5/5]  [ 380/4579]  eta: 0:24:21  Lr: 0.001875  Loss: 0.1215  Acc@1: 62.5000 (66.2566)  Acc@5: 93.7500 (91.7323)  time: 0.3511  data: 0.0028  max mem: 2500
Train: Epoch[5/5]  [ 390/4579]  eta: 0:24:17  Lr: 0.001875  Loss: 0.1455  Acc@1: 62.5000 (66.0646)  Acc@5: 93.7500 (91.6880)  time: 0.3492  data: 0.0020  max mem: 2500
Train: Epoch[5/5]  [ 400/4579]  eta: 0:24:14  Lr: 0.001875  Loss: -0.8513  Acc@1: 62.5000 (66.1627)  Acc@5: 93.7500 (91.7394)  time: 0.3465  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [ 410/4579]  eta: 0:24:10  Lr: 0.001875  Loss: -0.0217  Acc@1: 68.7500 (66.2713)  Acc@5: 93.7500 (91.7123)  time: 0.3462  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [ 420/4579]  eta: 0:24:06  Lr: 0.001875  Loss: -0.5090  Acc@1: 68.7500 (66.2114)  Acc@5: 93.7500 (91.7162)  time: 0.3460  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [ 430/4579]  eta: 0:24:03  Lr: 0.001875  Loss: -0.5768  Acc@1: 68.7500 (66.2848)  Acc@5: 93.7500 (91.7923)  time: 0.3456  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 440/4579]  eta: 0:23:59  Lr: 0.001875  Loss: 0.2835  Acc@1: 68.7500 (66.1848)  Acc@5: 93.7500 (91.7942)  time: 0.3453  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [ 450/4579]  eta: 0:23:55  Lr: 0.001875  Loss: -0.4316  Acc@1: 62.5000 (66.2694)  Acc@5: 93.7500 (91.8653)  time: 0.3449  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 460/4579]  eta: 0:23:51  Lr: 0.001875  Loss: -0.3247  Acc@1: 68.7500 (66.2690)  Acc@5: 93.7500 (91.8520)  time: 0.3446  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [ 470/4579]  eta: 0:23:48  Lr: 0.001875  Loss: -0.2142  Acc@1: 62.5000 (66.1890)  Acc@5: 93.7500 (91.8126)  time: 0.3461  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [ 480/4579]  eta: 0:23:44  Lr: 0.001875  Loss: 0.4345  Acc@1: 56.2500 (66.1642)  Acc@5: 93.7500 (91.8399)  time: 0.3473  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [ 490/4579]  eta: 0:23:41  Lr: 0.001875  Loss: 0.0257  Acc@1: 68.7500 (66.2424)  Acc@5: 93.7500 (91.8534)  time: 0.3469  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [ 500/4579]  eta: 0:23:37  Lr: 0.001875  Loss: -0.1609  Acc@1: 68.7500 (66.1302)  Acc@5: 93.7500 (91.8164)  time: 0.3463  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 510/4579]  eta: 0:23:34  Lr: 0.001875  Loss: -0.0092  Acc@1: 62.5000 (65.9369)  Acc@5: 93.7500 (91.8053)  time: 0.3477  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [ 520/4579]  eta: 0:23:30  Lr: 0.001875  Loss: -0.3365  Acc@1: 62.5000 (65.9189)  Acc@5: 93.7500 (91.8066)  time: 0.3478  data: 0.0014  max mem: 2500
Train: Epoch[5/5]  [ 530/4579]  eta: 0:23:27  Lr: 0.001875  Loss: 0.6043  Acc@1: 62.5000 (65.8781)  Acc@5: 93.7500 (91.8432)  time: 0.3467  data: 0.0013  max mem: 2500
Train: Epoch[5/5]  [ 540/4579]  eta: 0:23:23  Lr: 0.001875  Loss: -0.1975  Acc@1: 62.5000 (65.8041)  Acc@5: 93.7500 (91.7976)  time: 0.3466  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [ 550/4579]  eta: 0:23:20  Lr: 0.001875  Loss: -0.3980  Acc@1: 68.7500 (65.8008)  Acc@5: 87.5000 (91.8103)  time: 0.3459  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [ 560/4579]  eta: 0:23:16  Lr: 0.001875  Loss: -0.1631  Acc@1: 68.7500 (65.8757)  Acc@5: 93.7500 (91.8449)  time: 0.3458  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [ 570/4579]  eta: 0:23:12  Lr: 0.001875  Loss: -0.2997  Acc@1: 62.5000 (65.7837)  Acc@5: 93.7500 (91.8564)  time: 0.3458  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 580/4579]  eta: 0:23:09  Lr: 0.001875  Loss: -0.4755  Acc@1: 62.5000 (65.7164)  Acc@5: 93.7500 (91.8137)  time: 0.3472  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [ 590/4579]  eta: 0:23:06  Lr: 0.001875  Loss: 0.0441  Acc@1: 56.2500 (65.5351)  Acc@5: 93.7500 (91.8147)  time: 0.3496  data: 0.0016  max mem: 2500
Train: Epoch[5/5]  [ 600/4579]  eta: 0:23:02  Lr: 0.001875  Loss: -0.2507  Acc@1: 62.5000 (65.6094)  Acc@5: 93.7500 (91.7533)  time: 0.3479  data: 0.0016  max mem: 2500
Train: Epoch[5/5]  [ 610/4579]  eta: 0:22:59  Lr: 0.001875  Loss: -0.1775  Acc@1: 68.7500 (65.5994)  Acc@5: 93.7500 (91.7349)  time: 0.3465  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [ 620/4579]  eta: 0:22:55  Lr: 0.001875  Loss: -0.5896  Acc@1: 62.5000 (65.6200)  Acc@5: 93.7500 (91.7371)  time: 0.3479  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [ 630/4579]  eta: 0:22:52  Lr: 0.001875  Loss: -0.0757  Acc@1: 68.7500 (65.6696)  Acc@5: 93.7500 (91.7591)  time: 0.3469  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [ 640/4579]  eta: 0:22:48  Lr: 0.001875  Loss: 0.2997  Acc@1: 68.7500 (65.7859)  Acc@5: 93.7500 (91.7707)  time: 0.3456  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [ 650/4579]  eta: 0:22:45  Lr: 0.001875  Loss: -0.1373  Acc@1: 75.0000 (65.8698)  Acc@5: 93.7500 (91.8203)  time: 0.3468  data: 0.0016  max mem: 2500
Train: Epoch[5/5]  [ 660/4579]  eta: 0:22:41  Lr: 0.001875  Loss: -0.3134  Acc@1: 68.7500 (65.8756)  Acc@5: 93.7500 (91.8211)  time: 0.3476  data: 0.0016  max mem: 2500
Train: Epoch[5/5]  [ 670/4579]  eta: 0:22:38  Lr: 0.001875  Loss: 0.1947  Acc@1: 68.7500 (65.9463)  Acc@5: 93.7500 (91.8778)  time: 0.3478  data: 0.0013  max mem: 2500
Train: Epoch[5/5]  [ 680/4579]  eta: 0:22:34  Lr: 0.001875  Loss: -0.4422  Acc@1: 68.7500 (65.9141)  Acc@5: 93.7500 (91.8227)  time: 0.3483  data: 0.0019  max mem: 2500
Train: Epoch[5/5]  [ 690/4579]  eta: 0:22:31  Lr: 0.001875  Loss: 0.0787  Acc@1: 62.5000 (65.8828)  Acc@5: 87.5000 (91.7601)  time: 0.3491  data: 0.0012  max mem: 2500
Train: Epoch[5/5]  [ 700/4579]  eta: 0:22:27  Lr: 0.001875  Loss: 0.1424  Acc@1: 62.5000 (65.8880)  Acc@5: 87.5000 (91.7707)  time: 0.3487  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [ 710/4579]  eta: 0:22:24  Lr: 0.001875  Loss: -0.2702  Acc@1: 62.5000 (65.8579)  Acc@5: 93.7500 (91.7722)  time: 0.3469  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [ 720/4579]  eta: 0:22:21  Lr: 0.001875  Loss: 0.1886  Acc@1: 62.5000 (65.8287)  Acc@5: 93.7500 (91.7909)  time: 0.3476  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [ 730/4579]  eta: 0:22:17  Lr: 0.001875  Loss: 0.1459  Acc@1: 62.5000 (65.8516)  Acc@5: 93.7500 (91.7835)  time: 0.3490  data: 0.0011  max mem: 2500
Train: Epoch[5/5]  [ 740/4579]  eta: 0:22:14  Lr: 0.001875  Loss: -0.4639  Acc@1: 68.7500 (65.9413)  Acc@5: 93.7500 (91.8185)  time: 0.3469  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [ 750/4579]  eta: 0:22:10  Lr: 0.001875  Loss: -0.0818  Acc@1: 75.0000 (66.0370)  Acc@5: 93.7500 (91.8442)  time: 0.3459  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 760/4579]  eta: 0:22:07  Lr: 0.001875  Loss: 0.1973  Acc@1: 75.0000 (66.0644)  Acc@5: 93.7500 (91.8693)  time: 0.3470  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 770/4579]  eta: 0:22:03  Lr: 0.001875  Loss: -0.3768  Acc@1: 62.5000 (66.0911)  Acc@5: 93.7500 (91.8855)  time: 0.3472  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [ 780/4579]  eta: 0:22:00  Lr: 0.001875  Loss: 0.1641  Acc@1: 68.7500 (66.1732)  Acc@5: 93.7500 (91.8774)  time: 0.3474  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [ 790/4579]  eta: 0:21:56  Lr: 0.001875  Loss: -0.0558  Acc@1: 68.7500 (66.0872)  Acc@5: 87.5000 (91.8300)  time: 0.3468  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [ 800/4579]  eta: 0:21:53  Lr: 0.001875  Loss: 0.1351  Acc@1: 62.5000 (66.0971)  Acc@5: 87.5000 (91.8149)  time: 0.3465  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [ 810/4579]  eta: 0:21:49  Lr: 0.001875  Loss: 0.0763  Acc@1: 62.5000 (66.0373)  Acc@5: 87.5000 (91.7771)  time: 0.3474  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [ 820/4579]  eta: 0:21:46  Lr: 0.001875  Loss: -0.9438  Acc@1: 62.5000 (66.0780)  Acc@5: 87.5000 (91.7555)  time: 0.3482  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [ 830/4579]  eta: 0:21:42  Lr: 0.001875  Loss: -0.3489  Acc@1: 62.5000 (66.0575)  Acc@5: 93.7500 (91.7644)  time: 0.3490  data: 0.0016  max mem: 2500
Train: Epoch[5/5]  [ 840/4579]  eta: 0:21:39  Lr: 0.001875  Loss: -0.7799  Acc@1: 68.7500 (66.0895)  Acc@5: 93.7500 (91.7732)  time: 0.3479  data: 0.0015  max mem: 2500
Train: Epoch[5/5]  [ 850/4579]  eta: 0:21:35  Lr: 0.001875  Loss: -0.4593  Acc@1: 68.7500 (66.1134)  Acc@5: 93.7500 (91.8038)  time: 0.3462  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 860/4579]  eta: 0:21:32  Lr: 0.001875  Loss: -0.2017  Acc@1: 68.7500 (66.1150)  Acc@5: 93.7500 (91.8409)  time: 0.3479  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [ 870/4579]  eta: 0:21:29  Lr: 0.001875  Loss: -0.2522  Acc@1: 62.5000 (66.0448)  Acc@5: 93.7500 (91.8485)  time: 0.3509  data: 0.0010  max mem: 2500
Train: Epoch[5/5]  [ 880/4579]  eta: 0:21:25  Lr: 0.001875  Loss: 0.9131  Acc@1: 62.5000 (65.9974)  Acc@5: 93.7500 (91.8346)  time: 0.3514  data: 0.0013  max mem: 2500
Train: Epoch[5/5]  [ 890/4579]  eta: 0:21:22  Lr: 0.001875  Loss: -0.6261  Acc@1: 68.7500 (66.0494)  Acc@5: 87.5000 (91.8140)  time: 0.3477  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [ 900/4579]  eta: 0:21:18  Lr: 0.001875  Loss: 0.6537  Acc@1: 68.7500 (65.9614)  Acc@5: 87.5000 (91.7661)  time: 0.3477  data: 0.0013  max mem: 2500
Train: Epoch[5/5]  [ 910/4579]  eta: 0:21:15  Lr: 0.001875  Loss: -0.2950  Acc@1: 68.7500 (66.0332)  Acc@5: 93.7500 (91.8085)  time: 0.3486  data: 0.0013  max mem: 2500
Train: Epoch[5/5]  [ 920/4579]  eta: 0:21:11  Lr: 0.001875  Loss: -0.0392  Acc@1: 68.7500 (66.0084)  Acc@5: 93.7500 (91.7820)  time: 0.3482  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [ 930/4579]  eta: 0:21:08  Lr: 0.001875  Loss: -0.4291  Acc@1: 68.7500 (66.0714)  Acc@5: 93.7500 (91.8099)  time: 0.3478  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 940/4579]  eta: 0:21:04  Lr: 0.001875  Loss: 0.0641  Acc@1: 62.5000 (66.0069)  Acc@5: 93.7500 (91.7973)  time: 0.3473  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [ 950/4579]  eta: 0:21:01  Lr: 0.001875  Loss: 0.6794  Acc@1: 62.5000 (65.9963)  Acc@5: 93.7500 (91.7850)  time: 0.3478  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [ 960/4579]  eta: 0:20:57  Lr: 0.001875  Loss: -0.7339  Acc@1: 68.7500 (66.0250)  Acc@5: 93.7500 (91.8119)  time: 0.3483  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [ 970/4579]  eta: 0:20:54  Lr: 0.001875  Loss: -0.4708  Acc@1: 68.7500 (65.9887)  Acc@5: 93.7500 (91.7933)  time: 0.3482  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [ 980/4579]  eta: 0:20:50  Lr: 0.001875  Loss: -0.5033  Acc@1: 62.5000 (65.9913)  Acc@5: 87.5000 (91.7813)  time: 0.3463  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [ 990/4579]  eta: 0:20:47  Lr: 0.001875  Loss: 0.1180  Acc@1: 62.5000 (65.9561)  Acc@5: 87.5000 (91.7571)  time: 0.3452  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [1000/4579]  eta: 0:20:43  Lr: 0.001875  Loss: -0.1547  Acc@1: 62.5000 (65.9278)  Acc@5: 87.5000 (91.7145)  time: 0.3472  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [1010/4579]  eta: 0:20:40  Lr: 0.001875  Loss: 0.0984  Acc@1: 68.7500 (65.9928)  Acc@5: 93.7500 (91.7161)  time: 0.3488  data: 0.0013  max mem: 2500
Train: Epoch[5/5]  [1020/4579]  eta: 0:20:36  Lr: 0.001875  Loss: -0.4838  Acc@1: 68.7500 (66.0137)  Acc@5: 93.7500 (91.7238)  time: 0.3469  data: 0.0012  max mem: 2500
Train: Epoch[5/5]  [1030/4579]  eta: 0:20:33  Lr: 0.001875  Loss: 0.1997  Acc@1: 68.7500 (66.0403)  Acc@5: 87.5000 (91.7010)  time: 0.3461  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [1040/4579]  eta: 0:20:29  Lr: 0.001875  Loss: 0.6414  Acc@1: 62.5000 (65.9882)  Acc@5: 87.5000 (91.6907)  time: 0.3467  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [1050/4579]  eta: 0:20:26  Lr: 0.001875  Loss: -0.6637  Acc@1: 62.5000 (65.9907)  Acc@5: 93.7500 (91.6627)  time: 0.3481  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [1060/4579]  eta: 0:20:23  Lr: 0.001875  Loss: 0.4462  Acc@1: 68.7500 (66.0403)  Acc@5: 93.7500 (91.6883)  time: 0.3489  data: 0.0011  max mem: 2500
Train: Epoch[5/5]  [1070/4579]  eta: 0:20:19  Lr: 0.001875  Loss: -0.3023  Acc@1: 68.7500 (66.1123)  Acc@5: 93.7500 (91.7134)  time: 0.3484  data: 0.0014  max mem: 2500
Train: Epoch[5/5]  [1080/4579]  eta: 0:20:16  Lr: 0.001875  Loss: 0.0290  Acc@1: 68.7500 (66.1482)  Acc@5: 93.7500 (91.7148)  time: 0.3469  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [1090/4579]  eta: 0:20:12  Lr: 0.001875  Loss: -0.1970  Acc@1: 68.7500 (66.1549)  Acc@5: 93.7500 (91.6991)  time: 0.3477  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [1100/4579]  eta: 0:20:09  Lr: 0.001875  Loss: -0.3997  Acc@1: 62.5000 (66.1614)  Acc@5: 93.7500 (91.6837)  time: 0.3484  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [1110/4579]  eta: 0:20:05  Lr: 0.001875  Loss: -0.0765  Acc@1: 75.0000 (66.2579)  Acc@5: 93.7500 (91.7135)  time: 0.3462  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [1120/4579]  eta: 0:20:02  Lr: 0.001875  Loss: -0.3109  Acc@1: 75.0000 (66.2913)  Acc@5: 93.7500 (91.7150)  time: 0.3466  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [1130/4579]  eta: 0:19:58  Lr: 0.001875  Loss: 0.1339  Acc@1: 68.7500 (66.2412)  Acc@5: 93.7500 (91.7330)  time: 0.3468  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [1140/4579]  eta: 0:19:55  Lr: 0.001875  Loss: -0.2739  Acc@1: 68.7500 (66.2796)  Acc@5: 93.7500 (91.7507)  time: 0.3469  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [1150/4579]  eta: 0:19:51  Lr: 0.001875  Loss: -0.5518  Acc@1: 68.7500 (66.2685)  Acc@5: 93.7500 (91.7897)  time: 0.3494  data: 0.0017  max mem: 2500
Train: Epoch[5/5]  [1160/4579]  eta: 0:19:48  Lr: 0.001875  Loss: 0.1693  Acc@1: 62.5000 (66.2037)  Acc@5: 93.7500 (91.7743)  time: 0.3491  data: 0.0014  max mem: 2500
Train: Epoch[5/5]  [1170/4579]  eta: 0:19:44  Lr: 0.001875  Loss: -0.3646  Acc@1: 56.2500 (66.1934)  Acc@5: 87.5000 (91.7805)  time: 0.3470  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [1180/4579]  eta: 0:19:41  Lr: 0.001875  Loss: -0.2943  Acc@1: 68.7500 (66.2309)  Acc@5: 93.7500 (91.8025)  time: 0.3479  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [1190/4579]  eta: 0:19:37  Lr: 0.001875  Loss: 0.2001  Acc@1: 62.5000 (66.1629)  Acc@5: 93.7500 (91.8188)  time: 0.3480  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [1200/4579]  eta: 0:19:34  Lr: 0.001875  Loss: -0.2099  Acc@1: 62.5000 (66.2000)  Acc@5: 93.7500 (91.8349)  time: 0.3470  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [1210/4579]  eta: 0:19:30  Lr: 0.001875  Loss: 0.5462  Acc@1: 68.7500 (66.1746)  Acc@5: 93.7500 (91.8353)  time: 0.3461  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [1220/4579]  eta: 0:19:27  Lr: 0.001875  Loss: -0.0174  Acc@1: 62.5000 (66.1650)  Acc@5: 87.5000 (91.7998)  time: 0.3471  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [1230/4579]  eta: 0:19:23  Lr: 0.001875  Loss: -0.0646  Acc@1: 68.7500 (66.2266)  Acc@5: 93.7500 (91.8207)  time: 0.3472  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [1240/4579]  eta: 0:19:20  Lr: 0.001875  Loss: -0.3908  Acc@1: 68.7500 (66.2319)  Acc@5: 93.7500 (91.8564)  time: 0.3454  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1250/4579]  eta: 0:19:16  Lr: 0.001875  Loss: -0.4560  Acc@1: 62.5000 (66.1871)  Acc@5: 93.7500 (91.8465)  time: 0.3456  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [1260/4579]  eta: 0:19:13  Lr: 0.001875  Loss: -0.5362  Acc@1: 62.5000 (66.1727)  Acc@5: 93.7500 (91.8616)  time: 0.3480  data: 0.0013  max mem: 2500
Train: Epoch[5/5]  [1270/4579]  eta: 0:19:09  Lr: 0.001875  Loss: -0.3662  Acc@1: 68.7500 (66.1979)  Acc@5: 93.7500 (91.8716)  time: 0.3489  data: 0.0013  max mem: 2500
Train: Epoch[5/5]  [1280/4579]  eta: 0:19:06  Lr: 0.001875  Loss: -0.2358  Acc@1: 62.5000 (66.1397)  Acc@5: 93.7500 (91.8716)  time: 0.3469  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [1290/4579]  eta: 0:19:02  Lr: 0.001875  Loss: 0.0600  Acc@1: 62.5000 (66.1454)  Acc@5: 93.7500 (91.8958)  time: 0.3469  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [1300/4579]  eta: 0:18:59  Lr: 0.001875  Loss: 0.8170  Acc@1: 68.7500 (66.1703)  Acc@5: 93.7500 (91.9101)  time: 0.3474  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [1310/4579]  eta: 0:18:55  Lr: 0.001875  Loss: -0.5121  Acc@1: 68.7500 (66.2185)  Acc@5: 93.7500 (91.9098)  time: 0.3461  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [1320/4579]  eta: 0:18:52  Lr: 0.001875  Loss: -0.1735  Acc@1: 62.5000 (66.1998)  Acc@5: 87.5000 (91.9048)  time: 0.3470  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [1330/4579]  eta: 0:18:49  Lr: 0.001875  Loss: 0.0894  Acc@1: 62.5000 (66.1908)  Acc@5: 93.7500 (91.9140)  time: 0.3473  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [1340/4579]  eta: 0:18:45  Lr: 0.001875  Loss: -0.2421  Acc@1: 68.7500 (66.1959)  Acc@5: 93.7500 (91.8997)  time: 0.3453  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [1350/4579]  eta: 0:18:42  Lr: 0.001875  Loss: 0.0608  Acc@1: 62.5000 (66.1732)  Acc@5: 93.7500 (91.9041)  time: 0.3467  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [1360/4579]  eta: 0:18:38  Lr: 0.001875  Loss: -0.9229  Acc@1: 68.7500 (66.2151)  Acc@5: 93.7500 (91.9177)  time: 0.3520  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [1370/4579]  eta: 0:18:35  Lr: 0.001875  Loss: -0.0708  Acc@1: 68.7500 (66.1834)  Acc@5: 93.7500 (91.8992)  time: 0.3520  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [1380/4579]  eta: 0:18:31  Lr: 0.001875  Loss: -0.2372  Acc@1: 68.7500 (66.2201)  Acc@5: 93.7500 (91.9261)  time: 0.3478  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [1390/4579]  eta: 0:18:28  Lr: 0.001875  Loss: -0.4382  Acc@1: 62.5000 (66.1934)  Acc@5: 93.7500 (91.9393)  time: 0.3469  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [1400/4579]  eta: 0:18:24  Lr: 0.001875  Loss: -0.1512  Acc@1: 62.5000 (66.2072)  Acc@5: 93.7500 (91.9299)  time: 0.3469  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [1410/4579]  eta: 0:18:21  Lr: 0.001875  Loss: -0.0822  Acc@1: 62.5000 (66.1898)  Acc@5: 93.7500 (91.9516)  time: 0.3475  data: 0.0017  max mem: 2500
Train: Epoch[5/5]  [1420/4579]  eta: 0:18:17  Lr: 0.001875  Loss: 0.1317  Acc@1: 62.5000 (66.1858)  Acc@5: 93.7500 (91.9379)  time: 0.3462  data: 0.0017  max mem: 2500
Train: Epoch[5/5]  [1430/4579]  eta: 0:18:14  Lr: 0.001875  Loss: -0.2593  Acc@1: 62.5000 (66.1862)  Acc@5: 87.5000 (91.9287)  time: 0.3453  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [1440/4579]  eta: 0:18:10  Lr: 0.001875  Loss: -0.3023  Acc@1: 68.7500 (66.2214)  Acc@5: 93.7500 (91.9457)  time: 0.3470  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [1450/4579]  eta: 0:18:07  Lr: 0.001875  Loss: -0.4437  Acc@1: 68.7500 (66.2259)  Acc@5: 93.7500 (91.9366)  time: 0.3471  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [1460/4579]  eta: 0:18:03  Lr: 0.001875  Loss: 0.1649  Acc@1: 68.7500 (66.2260)  Acc@5: 93.7500 (91.9233)  time: 0.3480  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [1470/4579]  eta: 0:18:00  Lr: 0.001875  Loss: -0.1341  Acc@1: 68.7500 (66.2007)  Acc@5: 87.5000 (91.9060)  time: 0.3492  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [1480/4579]  eta: 0:17:56  Lr: 0.001875  Loss: -0.5654  Acc@1: 68.7500 (66.2643)  Acc@5: 93.7500 (91.9185)  time: 0.3485  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [1490/4579]  eta: 0:17:53  Lr: 0.001875  Loss: -0.3795  Acc@1: 68.7500 (66.2601)  Acc@5: 93.7500 (91.9182)  time: 0.3486  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [1500/4579]  eta: 0:17:50  Lr: 0.001875  Loss: -0.2687  Acc@1: 68.7500 (66.2850)  Acc@5: 93.7500 (91.9304)  time: 0.3484  data: 0.0017  max mem: 2500
Train: Epoch[5/5]  [1510/4579]  eta: 0:17:46  Lr: 0.001875  Loss: -0.4431  Acc@1: 68.7500 (66.2558)  Acc@5: 93.7500 (91.9424)  time: 0.3480  data: 0.0017  max mem: 2500
Train: Epoch[5/5]  [1520/4579]  eta: 0:17:43  Lr: 0.001875  Loss: 0.4719  Acc@1: 62.5000 (66.2558)  Acc@5: 93.7500 (91.9420)  time: 0.3468  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [1530/4579]  eta: 0:17:39  Lr: 0.001875  Loss: 0.0604  Acc@1: 68.7500 (66.2557)  Acc@5: 93.7500 (91.9497)  time: 0.3463  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [1540/4579]  eta: 0:17:36  Lr: 0.001875  Loss: -0.3859  Acc@1: 68.7500 (66.2881)  Acc@5: 93.7500 (91.9533)  time: 0.3477  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1550/4579]  eta: 0:17:32  Lr: 0.001875  Loss: -0.3600  Acc@1: 68.7500 (66.3080)  Acc@5: 93.7500 (91.9528)  time: 0.3478  data: 0.0012  max mem: 2500
Train: Epoch[5/5]  [1560/4579]  eta: 0:17:29  Lr: 0.001875  Loss: 0.1606  Acc@1: 62.5000 (66.2596)  Acc@5: 93.7500 (91.9443)  time: 0.3470  data: 0.0012  max mem: 2500
Train: Epoch[5/5]  [1570/4579]  eta: 0:17:25  Lr: 0.001875  Loss: 0.2769  Acc@1: 56.2500 (66.2237)  Acc@5: 93.7500 (91.9359)  time: 0.3481  data: 0.0011  max mem: 2500
Train: Epoch[5/5]  [1580/4579]  eta: 0:17:22  Lr: 0.001875  Loss: 0.0888  Acc@1: 62.5000 (66.2239)  Acc@5: 93.7500 (91.9434)  time: 0.3482  data: 0.0012  max mem: 2500
Train: Epoch[5/5]  [1590/4579]  eta: 0:17:18  Lr: 0.001875  Loss: 0.3078  Acc@1: 56.2500 (66.1259)  Acc@5: 93.7500 (91.9351)  time: 0.3456  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [1600/4579]  eta: 0:17:15  Lr: 0.001875  Loss: 0.6608  Acc@1: 56.2500 (66.1032)  Acc@5: 87.5000 (91.9113)  time: 0.3461  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [1610/4579]  eta: 0:17:11  Lr: 0.001875  Loss: -0.1844  Acc@1: 68.7500 (66.1002)  Acc@5: 93.7500 (91.9421)  time: 0.3475  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [1620/4579]  eta: 0:17:08  Lr: 0.001875  Loss: -0.0378  Acc@1: 68.7500 (66.0973)  Acc@5: 93.7500 (91.9456)  time: 0.3464  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1630/4579]  eta: 0:17:04  Lr: 0.001875  Loss: 0.3637  Acc@1: 62.5000 (66.0714)  Acc@5: 87.5000 (91.9413)  time: 0.3469  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [1640/4579]  eta: 0:17:01  Lr: 0.001875  Loss: -0.4822  Acc@1: 62.5000 (66.0839)  Acc@5: 93.7500 (91.9485)  time: 0.3472  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [1650/4579]  eta: 0:16:57  Lr: 0.001875  Loss: -0.5838  Acc@1: 68.7500 (66.1228)  Acc@5: 100.0000 (91.9859)  time: 0.3464  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1660/4579]  eta: 0:16:54  Lr: 0.001875  Loss: 0.2313  Acc@1: 68.7500 (66.1123)  Acc@5: 93.7500 (91.9777)  time: 0.3471  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [1670/4579]  eta: 0:16:50  Lr: 0.001875  Loss: 0.0318  Acc@1: 68.7500 (66.1168)  Acc@5: 93.7500 (91.9846)  time: 0.3464  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [1680/4579]  eta: 0:16:47  Lr: 0.001875  Loss: -0.5067  Acc@1: 62.5000 (66.1065)  Acc@5: 93.7500 (92.0100)  time: 0.3472  data: 0.0014  max mem: 2500
Train: Epoch[5/5]  [1690/4579]  eta: 0:16:43  Lr: 0.001875  Loss: 0.1790  Acc@1: 62.5000 (66.0815)  Acc@5: 93.7500 (92.0092)  time: 0.3479  data: 0.0014  max mem: 2500
Train: Epoch[5/5]  [1700/4579]  eta: 0:16:40  Lr: 0.001875  Loss: -0.1314  Acc@1: 68.7500 (66.0825)  Acc@5: 93.7500 (92.0084)  time: 0.3458  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [1710/4579]  eta: 0:16:36  Lr: 0.001875  Loss: -0.1609  Acc@1: 68.7500 (66.1127)  Acc@5: 93.7500 (92.0039)  time: 0.3457  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [1720/4579]  eta: 0:16:33  Lr: 0.001875  Loss: 0.0055  Acc@1: 68.7500 (66.1171)  Acc@5: 93.7500 (92.0177)  time: 0.3455  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1730/4579]  eta: 0:16:29  Lr: 0.001875  Loss: 0.4072  Acc@1: 62.5000 (66.0817)  Acc@5: 87.5000 (92.0025)  time: 0.3452  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [1740/4579]  eta: 0:16:26  Lr: 0.001875  Loss: -0.0934  Acc@1: 62.5000 (66.0719)  Acc@5: 87.5000 (92.0017)  time: 0.3466  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [1750/4579]  eta: 0:16:22  Lr: 0.001875  Loss: -0.4107  Acc@1: 62.5000 (66.0694)  Acc@5: 93.7500 (92.0010)  time: 0.3471  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [1760/4579]  eta: 0:16:19  Lr: 0.001875  Loss: 0.0228  Acc@1: 62.5000 (66.0491)  Acc@5: 87.5000 (91.9967)  time: 0.3461  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [1770/4579]  eta: 0:16:15  Lr: 0.001875  Loss: -0.2751  Acc@1: 62.5000 (66.0503)  Acc@5: 93.7500 (92.0031)  time: 0.3465  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [1780/4579]  eta: 0:16:12  Lr: 0.001875  Loss: -0.0596  Acc@1: 68.7500 (66.0830)  Acc@5: 93.7500 (92.0234)  time: 0.3476  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [1790/4579]  eta: 0:16:08  Lr: 0.001875  Loss: -0.1944  Acc@1: 68.7500 (66.0734)  Acc@5: 93.7500 (92.0331)  time: 0.3472  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [1800/4579]  eta: 0:16:05  Lr: 0.001875  Loss: 0.2145  Acc@1: 62.5000 (66.0918)  Acc@5: 93.7500 (92.0461)  time: 0.3477  data: 0.0013  max mem: 2500
Train: Epoch[5/5]  [1810/4579]  eta: 0:16:02  Lr: 0.001875  Loss: -0.1391  Acc@1: 62.5000 (66.0823)  Acc@5: 93.7500 (92.0313)  time: 0.3477  data: 0.0013  max mem: 2500
Train: Epoch[5/5]  [1820/4579]  eta: 0:15:58  Lr: 0.001875  Loss: 0.0419  Acc@1: 68.7500 (66.1038)  Acc@5: 93.7500 (92.0339)  time: 0.3467  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1830/4579]  eta: 0:15:55  Lr: 0.001875  Loss: 0.3078  Acc@1: 68.7500 (66.1046)  Acc@5: 93.7500 (92.0365)  time: 0.3458  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1840/4579]  eta: 0:15:51  Lr: 0.001875  Loss: -0.0601  Acc@1: 68.7500 (66.1393)  Acc@5: 93.7500 (92.0322)  time: 0.3466  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [1850/4579]  eta: 0:15:48  Lr: 0.001875  Loss: 0.0262  Acc@1: 68.7500 (66.1365)  Acc@5: 93.7500 (92.0313)  time: 0.3469  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [1860/4579]  eta: 0:15:44  Lr: 0.001875  Loss: -0.3497  Acc@1: 68.7500 (66.1607)  Acc@5: 93.7500 (92.0339)  time: 0.3466  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [1870/4579]  eta: 0:15:41  Lr: 0.001875  Loss: -0.1851  Acc@1: 68.7500 (66.2079)  Acc@5: 93.7500 (92.0464)  time: 0.3469  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [1880/4579]  eta: 0:15:37  Lr: 0.001875  Loss: -0.6285  Acc@1: 68.7500 (66.2181)  Acc@5: 93.7500 (92.0654)  time: 0.3484  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [1890/4579]  eta: 0:15:34  Lr: 0.001875  Loss: -0.1256  Acc@1: 62.5000 (66.2150)  Acc@5: 93.7500 (92.0611)  time: 0.3489  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [1900/4579]  eta: 0:15:30  Lr: 0.001875  Loss: -0.2848  Acc@1: 68.7500 (66.2217)  Acc@5: 93.7500 (92.0733)  time: 0.3489  data: 0.0014  max mem: 2500
Train: Epoch[5/5]  [1910/4579]  eta: 0:15:27  Lr: 0.001875  Loss: -0.5414  Acc@1: 68.7500 (66.2153)  Acc@5: 87.5000 (92.0657)  time: 0.3488  data: 0.0014  max mem: 2500
Train: Epoch[5/5]  [1920/4579]  eta: 0:15:23  Lr: 0.001875  Loss: 0.6549  Acc@1: 62.5000 (66.2350)  Acc@5: 87.5000 (92.0517)  time: 0.3463  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [1930/4579]  eta: 0:15:20  Lr: 0.001875  Loss: -0.3333  Acc@1: 68.7500 (66.2448)  Acc@5: 93.7500 (92.0572)  time: 0.3462  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [1940/4579]  eta: 0:15:16  Lr: 0.001875  Loss: 0.1224  Acc@1: 62.5000 (66.2352)  Acc@5: 93.7500 (92.0595)  time: 0.3474  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [1950/4579]  eta: 0:15:13  Lr: 0.001875  Loss: -0.2669  Acc@1: 62.5000 (66.2064)  Acc@5: 93.7500 (92.0650)  time: 0.3478  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [1960/4579]  eta: 0:15:09  Lr: 0.001875  Loss: -0.0781  Acc@1: 62.5000 (66.2194)  Acc@5: 93.7500 (92.0767)  time: 0.3472  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [1970/4579]  eta: 0:15:06  Lr: 0.001875  Loss: -0.4368  Acc@1: 62.5000 (66.2100)  Acc@5: 93.7500 (92.0821)  time: 0.3471  data: 0.0014  max mem: 2500
Train: Epoch[5/5]  [1980/4579]  eta: 0:15:02  Lr: 0.001875  Loss: -0.2009  Acc@1: 62.5000 (66.2260)  Acc@5: 93.7500 (92.0684)  time: 0.3491  data: 0.0018  max mem: 2500
Train: Epoch[5/5]  [1990/4579]  eta: 0:14:59  Lr: 0.001875  Loss: -0.4574  Acc@1: 68.7500 (66.2450)  Acc@5: 93.7500 (92.0737)  time: 0.3499  data: 0.0012  max mem: 2500
Train: Epoch[5/5]  [2000/4579]  eta: 0:14:56  Lr: 0.001875  Loss: -0.0734  Acc@1: 62.5000 (66.2200)  Acc@5: 93.7500 (92.0727)  time: 0.3483  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [2010/4579]  eta: 0:14:52  Lr: 0.001875  Loss: 0.2856  Acc@1: 62.5000 (66.2544)  Acc@5: 93.7500 (92.0842)  time: 0.3482  data: 0.0015  max mem: 2500
Train: Epoch[5/5]  [2020/4579]  eta: 0:14:49  Lr: 0.001875  Loss: -0.4669  Acc@1: 68.7500 (66.2543)  Acc@5: 93.7500 (92.0955)  time: 0.3493  data: 0.0016  max mem: 2500
Train: Epoch[5/5]  [2030/4579]  eta: 0:14:45  Lr: 0.001875  Loss: 0.0083  Acc@1: 68.7500 (66.2697)  Acc@5: 93.7500 (92.1160)  time: 0.3500  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [2040/4579]  eta: 0:14:42  Lr: 0.001875  Loss: 0.3258  Acc@1: 75.0000 (66.2972)  Acc@5: 100.0000 (92.1331)  time: 0.3491  data: 0.0020  max mem: 2500
Train: Epoch[5/5]  [2050/4579]  eta: 0:14:38  Lr: 0.001875  Loss: -0.5843  Acc@1: 62.5000 (66.2847)  Acc@5: 93.7500 (92.1380)  time: 0.3502  data: 0.0035  max mem: 2500
Train: Epoch[5/5]  [2060/4579]  eta: 0:14:35  Lr: 0.001875  Loss: -0.4384  Acc@1: 62.5000 (66.2906)  Acc@5: 93.7500 (92.1337)  time: 0.3502  data: 0.0029  max mem: 2500
Train: Epoch[5/5]  [2070/4579]  eta: 0:14:31  Lr: 0.001875  Loss: -0.5409  Acc@1: 62.5000 (66.2814)  Acc@5: 93.7500 (92.1264)  time: 0.3483  data: 0.0020  max mem: 2500
Train: Epoch[5/5]  [2080/4579]  eta: 0:14:28  Lr: 0.001875  Loss: -0.0928  Acc@1: 62.5000 (66.2752)  Acc@5: 93.7500 (92.1342)  time: 0.3477  data: 0.0010  max mem: 2500
Train: Epoch[5/5]  [2090/4579]  eta: 0:14:24  Lr: 0.001875  Loss: -0.5603  Acc@1: 62.5000 (66.2751)  Acc@5: 93.7500 (92.1389)  time: 0.3470  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [2100/4579]  eta: 0:14:21  Lr: 0.001875  Loss: -0.2337  Acc@1: 68.7500 (66.2988)  Acc@5: 93.7500 (92.1555)  time: 0.3467  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [2110/4579]  eta: 0:14:17  Lr: 0.001875  Loss: 1.2911  Acc@1: 62.5000 (66.2719)  Acc@5: 93.7500 (92.1335)  time: 0.3470  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [2120/4579]  eta: 0:14:14  Lr: 0.001875  Loss: -0.5239  Acc@1: 62.5000 (66.2836)  Acc@5: 93.7500 (92.1381)  time: 0.3461  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [2130/4579]  eta: 0:14:10  Lr: 0.001875  Loss: 0.5376  Acc@1: 62.5000 (66.2629)  Acc@5: 93.7500 (92.1281)  time: 0.3466  data: 0.0011  max mem: 2500
Train: Epoch[5/5]  [2140/4579]  eta: 0:14:07  Lr: 0.001875  Loss: -0.3163  Acc@1: 62.5000 (66.2512)  Acc@5: 87.5000 (92.1094)  time: 0.3474  data: 0.0011  max mem: 2500
Train: Epoch[5/5]  [2150/4579]  eta: 0:14:04  Lr: 0.001875  Loss: 0.1010  Acc@1: 62.5000 (66.2483)  Acc@5: 87.5000 (92.1025)  time: 0.3462  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [2160/4579]  eta: 0:14:00  Lr: 0.001875  Loss: -0.4701  Acc@1: 62.5000 (66.2454)  Acc@5: 93.7500 (92.1130)  time: 0.3464  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [2170/4579]  eta: 0:13:57  Lr: 0.001875  Loss: 0.1815  Acc@1: 68.7500 (66.2569)  Acc@5: 93.7500 (92.1234)  time: 0.3473  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [2180/4579]  eta: 0:13:53  Lr: 0.001875  Loss: -0.0463  Acc@1: 68.7500 (66.2454)  Acc@5: 93.7500 (92.1280)  time: 0.3482  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [2190/4579]  eta: 0:13:50  Lr: 0.001875  Loss: 0.2855  Acc@1: 62.5000 (66.2397)  Acc@5: 93.7500 (92.1383)  time: 0.3490  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [2200/4579]  eta: 0:13:46  Lr: 0.001875  Loss: 0.4140  Acc@1: 62.5000 (66.2341)  Acc@5: 93.7500 (92.1399)  time: 0.3509  data: 0.0027  max mem: 2500
Train: Epoch[5/5]  [2210/4579]  eta: 0:13:43  Lr: 0.001875  Loss: -0.2043  Acc@1: 62.5000 (66.2087)  Acc@5: 93.7500 (92.1387)  time: 0.3490  data: 0.0023  max mem: 2500
Train: Epoch[5/5]  [2220/4579]  eta: 0:13:39  Lr: 0.001875  Loss: 0.0514  Acc@1: 62.5000 (66.2145)  Acc@5: 93.7500 (92.1347)  time: 0.3481  data: 0.0016  max mem: 2500
Train: Epoch[5/5]  [2230/4579]  eta: 0:13:36  Lr: 0.001875  Loss: -0.4359  Acc@1: 68.7500 (66.2371)  Acc@5: 87.5000 (92.1196)  time: 0.3485  data: 0.0016  max mem: 2500
Train: Epoch[5/5]  [2240/4579]  eta: 0:13:32  Lr: 0.001875  Loss: -0.5596  Acc@1: 68.7500 (66.2400)  Acc@5: 87.5000 (92.1213)  time: 0.3465  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [2250/4579]  eta: 0:13:29  Lr: 0.001875  Loss: 1.0612  Acc@1: 62.5000 (66.2150)  Acc@5: 87.5000 (92.1063)  time: 0.3477  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [2260/4579]  eta: 0:13:25  Lr: 0.001875  Loss: -0.4247  Acc@1: 68.7500 (66.2428)  Acc@5: 87.5000 (92.1108)  time: 0.3472  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [2270/4579]  eta: 0:13:22  Lr: 0.001875  Loss: -0.1947  Acc@1: 62.5000 (66.2236)  Acc@5: 93.7500 (92.1125)  time: 0.3460  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [2280/4579]  eta: 0:13:18  Lr: 0.001875  Loss: -0.1523  Acc@1: 62.5000 (66.2155)  Acc@5: 93.7500 (92.1224)  time: 0.3465  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [2290/4579]  eta: 0:13:15  Lr: 0.001875  Loss: 0.4955  Acc@1: 56.2500 (66.1938)  Acc@5: 93.7500 (92.1186)  time: 0.3465  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [2300/4579]  eta: 0:13:11  Lr: 0.001875  Loss: 0.3292  Acc@1: 62.5000 (66.1832)  Acc@5: 93.7500 (92.1013)  time: 0.3493  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [2310/4579]  eta: 0:13:08  Lr: 0.001875  Loss: -0.5290  Acc@1: 68.7500 (66.2132)  Acc@5: 93.7500 (92.0976)  time: 0.3510  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [2320/4579]  eta: 0:13:05  Lr: 0.001875  Loss: -0.7132  Acc@1: 68.7500 (66.2134)  Acc@5: 93.7500 (92.1020)  time: 0.3494  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [2330/4579]  eta: 0:13:01  Lr: 0.001875  Loss: -0.1646  Acc@1: 62.5000 (66.2135)  Acc@5: 93.7500 (92.1118)  time: 0.3472  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [2340/4579]  eta: 0:12:58  Lr: 0.001875  Loss: 0.2750  Acc@1: 68.7500 (66.2270)  Acc@5: 93.7500 (92.1134)  time: 0.3469  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [2350/4579]  eta: 0:12:54  Lr: 0.001875  Loss: -0.5837  Acc@1: 68.7500 (66.2351)  Acc@5: 93.7500 (92.1097)  time: 0.3485  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [2360/4579]  eta: 0:12:51  Lr: 0.001875  Loss: -0.5485  Acc@1: 68.7500 (66.2458)  Acc@5: 93.7500 (92.1193)  time: 0.3467  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [2370/4579]  eta: 0:12:47  Lr: 0.001875  Loss: -0.1954  Acc@1: 68.7500 (66.2695)  Acc@5: 93.7500 (92.1157)  time: 0.3452  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2380/4579]  eta: 0:12:44  Lr: 0.001875  Loss: -0.4898  Acc@1: 68.7500 (66.2615)  Acc@5: 93.7500 (92.1042)  time: 0.3457  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [2390/4579]  eta: 0:12:40  Lr: 0.001875  Loss: -0.2768  Acc@1: 62.5000 (66.2563)  Acc@5: 93.7500 (92.1032)  time: 0.3469  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2400/4579]  eta: 0:12:37  Lr: 0.001875  Loss: -0.3253  Acc@1: 68.7500 (66.2589)  Acc@5: 93.7500 (92.0970)  time: 0.3470  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2410/4579]  eta: 0:12:33  Lr: 0.001875  Loss: -0.4766  Acc@1: 68.7500 (66.2536)  Acc@5: 93.7500 (92.1013)  time: 0.3476  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [2420/4579]  eta: 0:12:30  Lr: 0.001875  Loss: -0.8106  Acc@1: 68.7500 (66.2665)  Acc@5: 93.7500 (92.1030)  time: 0.3472  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2430/4579]  eta: 0:12:26  Lr: 0.001875  Loss: -0.4777  Acc@1: 62.5000 (66.2665)  Acc@5: 93.7500 (92.1149)  time: 0.3465  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [2440/4579]  eta: 0:12:23  Lr: 0.001875  Loss: -0.4325  Acc@1: 62.5000 (66.2869)  Acc@5: 93.7500 (92.1164)  time: 0.3466  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [2450/4579]  eta: 0:12:19  Lr: 0.001875  Loss: -0.1467  Acc@1: 62.5000 (66.2459)  Acc@5: 93.7500 (92.1078)  time: 0.3467  data: 0.0012  max mem: 2500
Train: Epoch[5/5]  [2460/4579]  eta: 0:12:16  Lr: 0.001875  Loss: -0.3978  Acc@1: 62.5000 (66.2612)  Acc@5: 93.7500 (92.1170)  time: 0.3480  data: 0.0014  max mem: 2500
Train: Epoch[5/5]  [2470/4579]  eta: 0:12:12  Lr: 0.001875  Loss: -0.0781  Acc@1: 68.7500 (66.2637)  Acc@5: 93.7500 (92.1186)  time: 0.3483  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [2480/4579]  eta: 0:12:09  Lr: 0.001875  Loss: -0.5933  Acc@1: 62.5000 (66.2661)  Acc@5: 93.7500 (92.1277)  time: 0.3481  data: 0.0010  max mem: 2500
Train: Epoch[5/5]  [2490/4579]  eta: 0:12:05  Lr: 0.001875  Loss: -0.2278  Acc@1: 62.5000 (66.2635)  Acc@5: 93.7500 (92.1342)  time: 0.3480  data: 0.0011  max mem: 2500
Train: Epoch[5/5]  [2500/4579]  eta: 0:12:02  Lr: 0.001875  Loss: -0.2592  Acc@1: 62.5000 (66.2660)  Acc@5: 93.7500 (92.1256)  time: 0.3473  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [2510/4579]  eta: 0:11:58  Lr: 0.001875  Loss: 0.6677  Acc@1: 68.7500 (66.2659)  Acc@5: 93.7500 (92.1321)  time: 0.3461  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [2520/4579]  eta: 0:11:55  Lr: 0.001875  Loss: -0.0202  Acc@1: 68.7500 (66.2758)  Acc@5: 93.7500 (92.1410)  time: 0.3468  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2530/4579]  eta: 0:11:51  Lr: 0.001875  Loss: -0.0279  Acc@1: 68.7500 (66.2683)  Acc@5: 93.7500 (92.1449)  time: 0.3470  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [2540/4579]  eta: 0:11:48  Lr: 0.001875  Loss: -0.0825  Acc@1: 68.7500 (66.2780)  Acc@5: 93.7500 (92.1365)  time: 0.3463  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [2550/4579]  eta: 0:11:45  Lr: 0.001875  Loss: -0.0753  Acc@1: 68.7500 (66.2877)  Acc@5: 93.7500 (92.1354)  time: 0.3464  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2560/4579]  eta: 0:11:41  Lr: 0.001875  Loss: -0.1057  Acc@1: 62.5000 (66.2925)  Acc@5: 93.7500 (92.1393)  time: 0.3470  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [2570/4579]  eta: 0:11:38  Lr: 0.001875  Loss: -0.4054  Acc@1: 68.7500 (66.2899)  Acc@5: 93.7500 (92.1383)  time: 0.3467  data: 0.0011  max mem: 2500
Train: Epoch[5/5]  [2580/4579]  eta: 0:11:34  Lr: 0.001875  Loss: -0.5712  Acc@1: 68.7500 (66.3091)  Acc@5: 93.7500 (92.1445)  time: 0.3476  data: 0.0011  max mem: 2500
Train: Epoch[5/5]  [2590/4579]  eta: 0:11:31  Lr: 0.001875  Loss: -0.4212  Acc@1: 62.5000 (66.2847)  Acc@5: 93.7500 (92.1218)  time: 0.3486  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [2600/4579]  eta: 0:11:27  Lr: 0.001875  Loss: -0.0899  Acc@1: 56.2500 (66.2702)  Acc@5: 87.5000 (92.1136)  time: 0.3475  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [2610/4579]  eta: 0:11:24  Lr: 0.001875  Loss: 0.1338  Acc@1: 62.5000 (66.2677)  Acc@5: 93.7500 (92.1127)  time: 0.3474  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2620/4579]  eta: 0:11:20  Lr: 0.001875  Loss: -0.4000  Acc@1: 62.5000 (66.2653)  Acc@5: 93.7500 (92.1046)  time: 0.3473  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2630/4579]  eta: 0:11:17  Lr: 0.001875  Loss: -0.5740  Acc@1: 68.7500 (66.3056)  Acc@5: 93.7500 (92.1228)  time: 0.3476  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [2640/4579]  eta: 0:11:13  Lr: 0.001875  Loss: 0.1356  Acc@1: 75.0000 (66.3385)  Acc@5: 93.7500 (92.1289)  time: 0.3479  data: 0.0013  max mem: 2500
Train: Epoch[5/5]  [2650/4579]  eta: 0:11:10  Lr: 0.001875  Loss: -0.0759  Acc@1: 75.0000 (66.3618)  Acc@5: 93.7500 (92.1303)  time: 0.3470  data: 0.0012  max mem: 2500
Train: Epoch[5/5]  [2660/4579]  eta: 0:11:06  Lr: 0.001875  Loss: -0.3537  Acc@1: 68.7500 (66.3613)  Acc@5: 93.7500 (92.1294)  time: 0.3480  data: 0.0012  max mem: 2500
Train: Epoch[5/5]  [2670/4579]  eta: 0:11:03  Lr: 0.001875  Loss: -0.8140  Acc@1: 68.7500 (66.3726)  Acc@5: 93.7500 (92.1425)  time: 0.3479  data: 0.0011  max mem: 2500
Train: Epoch[5/5]  [2680/4579]  eta: 0:10:59  Lr: 0.001875  Loss: -0.2547  Acc@1: 62.5000 (66.3535)  Acc@5: 93.7500 (92.1461)  time: 0.3470  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [2690/4579]  eta: 0:10:56  Lr: 0.001875  Loss: 0.3898  Acc@1: 62.5000 (66.3554)  Acc@5: 93.7500 (92.1335)  time: 0.3479  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [2700/4579]  eta: 0:10:52  Lr: 0.001875  Loss: -0.3030  Acc@1: 62.5000 (66.3597)  Acc@5: 87.5000 (92.1349)  time: 0.3487  data: 0.0019  max mem: 2500
Train: Epoch[5/5]  [2710/4579]  eta: 0:10:49  Lr: 0.001875  Loss: -0.0921  Acc@1: 68.7500 (66.3754)  Acc@5: 93.7500 (92.1408)  time: 0.3484  data: 0.0018  max mem: 2500
Train: Epoch[5/5]  [2720/4579]  eta: 0:10:45  Lr: 0.001875  Loss: -0.0406  Acc@1: 68.7500 (66.3956)  Acc@5: 93.7500 (92.1536)  time: 0.3479  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [2730/4579]  eta: 0:10:42  Lr: 0.001875  Loss: 0.0735  Acc@1: 68.7500 (66.3837)  Acc@5: 93.7500 (92.1526)  time: 0.3480  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [2740/4579]  eta: 0:10:39  Lr: 0.001875  Loss: -0.4649  Acc@1: 68.7500 (66.3968)  Acc@5: 93.7500 (92.1653)  time: 0.3476  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [2750/4579]  eta: 0:10:35  Lr: 0.001875  Loss: 0.0077  Acc@1: 75.0000 (66.4190)  Acc@5: 93.7500 (92.1506)  time: 0.3464  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [2760/4579]  eta: 0:10:32  Lr: 0.001875  Loss: -0.2238  Acc@1: 68.7500 (66.4026)  Acc@5: 93.7500 (92.1564)  time: 0.3467  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [2770/4579]  eta: 0:10:28  Lr: 0.001875  Loss: -0.6869  Acc@1: 62.5000 (66.4043)  Acc@5: 93.7500 (92.1621)  time: 0.3483  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [2780/4579]  eta: 0:10:25  Lr: 0.001875  Loss: -0.2856  Acc@1: 68.7500 (66.3992)  Acc@5: 93.7500 (92.1544)  time: 0.3475  data: 0.0013  max mem: 2500
Train: Epoch[5/5]  [2790/4579]  eta: 0:10:21  Lr: 0.001875  Loss: 0.2028  Acc@1: 68.7500 (66.3942)  Acc@5: 93.7500 (92.1578)  time: 0.3473  data: 0.0012  max mem: 2500
Train: Epoch[5/5]  [2800/4579]  eta: 0:10:18  Lr: 0.001875  Loss: -0.0521  Acc@1: 68.7500 (66.3937)  Acc@5: 93.7500 (92.1479)  time: 0.3468  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [2810/4579]  eta: 0:10:14  Lr: 0.001875  Loss: 0.9230  Acc@1: 62.5000 (66.3821)  Acc@5: 87.5000 (92.1425)  time: 0.3490  data: 0.0018  max mem: 2500
Train: Epoch[5/5]  [2820/4579]  eta: 0:10:11  Lr: 0.001875  Loss: 0.1310  Acc@1: 62.5000 (66.3905)  Acc@5: 93.7500 (92.1460)  time: 0.3501  data: 0.0015  max mem: 2500
Train: Epoch[5/5]  [2830/4579]  eta: 0:10:07  Lr: 0.001875  Loss: -0.0013  Acc@1: 68.7500 (66.3922)  Acc@5: 93.7500 (92.1450)  time: 0.3473  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [2840/4579]  eta: 0:10:04  Lr: 0.001875  Loss: -0.2497  Acc@1: 62.5000 (66.3829)  Acc@5: 93.7500 (92.1419)  time: 0.3468  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [2850/4579]  eta: 0:10:00  Lr: 0.001875  Loss: -0.5100  Acc@1: 62.5000 (66.3824)  Acc@5: 93.7500 (92.1409)  time: 0.3473  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [2860/4579]  eta: 0:09:57  Lr: 0.001875  Loss: -0.3533  Acc@1: 62.5000 (66.3732)  Acc@5: 93.7500 (92.1444)  time: 0.3468  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [2870/4579]  eta: 0:09:53  Lr: 0.001875  Loss: 0.3308  Acc@1: 62.5000 (66.3684)  Acc@5: 93.7500 (92.1391)  time: 0.3463  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [2880/4579]  eta: 0:09:50  Lr: 0.001875  Loss: 0.1147  Acc@1: 62.5000 (66.3615)  Acc@5: 93.7500 (92.1360)  time: 0.3454  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [2890/4579]  eta: 0:09:46  Lr: 0.001875  Loss: -0.2743  Acc@1: 68.7500 (66.3698)  Acc@5: 93.7500 (92.1416)  time: 0.3465  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [2900/4579]  eta: 0:09:43  Lr: 0.001875  Loss: -0.4997  Acc@1: 75.0000 (66.4060)  Acc@5: 93.7500 (92.1493)  time: 0.3480  data: 0.0011  max mem: 2500
Train: Epoch[5/5]  [2910/4579]  eta: 0:09:39  Lr: 0.001875  Loss: -0.4639  Acc@1: 75.0000 (66.4140)  Acc@5: 93.7500 (92.1612)  time: 0.3473  data: 0.0011  max mem: 2500
Train: Epoch[5/5]  [2920/4579]  eta: 0:09:36  Lr: 0.001875  Loss: -0.3847  Acc@1: 68.7500 (66.4242)  Acc@5: 93.7500 (92.1709)  time: 0.3513  data: 0.0028  max mem: 2500
Train: Epoch[5/5]  [2930/4579]  eta: 0:09:33  Lr: 0.001875  Loss: -0.6423  Acc@1: 62.5000 (66.4044)  Acc@5: 93.7500 (92.1742)  time: 0.3516  data: 0.0028  max mem: 2500
Train: Epoch[5/5]  [2940/4579]  eta: 0:09:29  Lr: 0.001875  Loss: 0.2395  Acc@1: 62.5000 (66.3869)  Acc@5: 93.7500 (92.1774)  time: 0.3478  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2950/4579]  eta: 0:09:26  Lr: 0.001875  Loss: 0.1535  Acc@1: 62.5000 (66.3758)  Acc@5: 93.7500 (92.1827)  time: 0.3468  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2960/4579]  eta: 0:09:22  Lr: 0.001875  Loss: 0.9324  Acc@1: 62.5000 (66.3522)  Acc@5: 93.7500 (92.1775)  time: 0.3472  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [2970/4579]  eta: 0:09:19  Lr: 0.001875  Loss: -0.2435  Acc@1: 68.7500 (66.3602)  Acc@5: 93.7500 (92.1828)  time: 0.3478  data: 0.0011  max mem: 2500
Train: Epoch[5/5]  [2980/4579]  eta: 0:09:15  Lr: 0.001875  Loss: 0.3526  Acc@1: 68.7500 (66.3620)  Acc@5: 93.7500 (92.1859)  time: 0.3479  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [2990/4579]  eta: 0:09:12  Lr: 0.001875  Loss: 0.2755  Acc@1: 62.5000 (66.3428)  Acc@5: 93.7500 (92.1786)  time: 0.3483  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [3000/4579]  eta: 0:09:08  Lr: 0.001875  Loss: 0.0635  Acc@1: 62.5000 (66.3362)  Acc@5: 87.5000 (92.1651)  time: 0.3470  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [3010/4579]  eta: 0:09:05  Lr: 0.001875  Loss: -0.3557  Acc@1: 68.7500 (66.3380)  Acc@5: 87.5000 (92.1621)  time: 0.3469  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [3020/4579]  eta: 0:09:01  Lr: 0.001875  Loss: -0.2054  Acc@1: 68.7500 (66.3543)  Acc@5: 93.7500 (92.1715)  time: 0.3470  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3030/4579]  eta: 0:08:58  Lr: 0.001875  Loss: 0.1624  Acc@1: 68.7500 (66.3416)  Acc@5: 93.7500 (92.1622)  time: 0.3467  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3040/4579]  eta: 0:08:54  Lr: 0.001875  Loss: 0.1837  Acc@1: 62.5000 (66.3289)  Acc@5: 93.7500 (92.1551)  time: 0.3474  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [3050/4579]  eta: 0:08:51  Lr: 0.001875  Loss: 0.0785  Acc@1: 62.5000 (66.3164)  Acc@5: 87.5000 (92.1522)  time: 0.3466  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3060/4579]  eta: 0:08:47  Lr: 0.001875  Loss: -0.3242  Acc@1: 68.7500 (66.3223)  Acc@5: 93.7500 (92.1615)  time: 0.3457  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [3070/4579]  eta: 0:08:44  Lr: 0.001875  Loss: -0.4659  Acc@1: 68.7500 (66.3139)  Acc@5: 93.7500 (92.1585)  time: 0.3475  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [3080/4579]  eta: 0:08:40  Lr: 0.001875  Loss: 0.6843  Acc@1: 62.5000 (66.3117)  Acc@5: 93.7500 (92.1515)  time: 0.3473  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [3090/4579]  eta: 0:08:37  Lr: 0.001875  Loss: -0.3668  Acc@1: 62.5000 (66.3155)  Acc@5: 93.7500 (92.1466)  time: 0.3471  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [3100/4579]  eta: 0:08:33  Lr: 0.001875  Loss: 0.0856  Acc@1: 62.5000 (66.2992)  Acc@5: 93.7500 (92.1437)  time: 0.3485  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [3110/4579]  eta: 0:08:30  Lr: 0.001875  Loss: 0.2421  Acc@1: 62.5000 (66.2850)  Acc@5: 93.7500 (92.1468)  time: 0.3468  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [3120/4579]  eta: 0:08:26  Lr: 0.001875  Loss: 0.3651  Acc@1: 62.5000 (66.2788)  Acc@5: 93.7500 (92.1439)  time: 0.3472  data: 0.0011  max mem: 2500
Train: Epoch[5/5]  [3130/4579]  eta: 0:08:23  Lr: 0.001875  Loss: 0.3160  Acc@1: 62.5000 (66.2688)  Acc@5: 93.7500 (92.1411)  time: 0.3496  data: 0.0015  max mem: 2500
Train: Epoch[5/5]  [3140/4579]  eta: 0:08:20  Lr: 0.001875  Loss: -0.1046  Acc@1: 68.7500 (66.2767)  Acc@5: 93.7500 (92.1502)  time: 0.3496  data: 0.0019  max mem: 2500
Train: Epoch[5/5]  [3150/4579]  eta: 0:08:16  Lr: 0.001875  Loss: -0.0973  Acc@1: 68.7500 (66.2706)  Acc@5: 93.7500 (92.1434)  time: 0.3488  data: 0.0016  max mem: 2500
Train: Epoch[5/5]  [3160/4579]  eta: 0:08:13  Lr: 0.001875  Loss: -0.3666  Acc@1: 62.5000 (66.2686)  Acc@5: 93.7500 (92.1405)  time: 0.3471  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [3170/4579]  eta: 0:08:09  Lr: 0.001875  Loss: 0.1062  Acc@1: 62.5000 (66.2528)  Acc@5: 93.7500 (92.1377)  time: 0.3465  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [3180/4579]  eta: 0:08:06  Lr: 0.001875  Loss: -0.0915  Acc@1: 68.7500 (66.2645)  Acc@5: 93.7500 (92.1467)  time: 0.3466  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [3190/4579]  eta: 0:08:02  Lr: 0.001875  Loss: 0.0442  Acc@1: 68.7500 (66.2547)  Acc@5: 93.7500 (92.1518)  time: 0.3465  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [3200/4579]  eta: 0:07:59  Lr: 0.001875  Loss: 0.2363  Acc@1: 68.7500 (66.2703)  Acc@5: 93.7500 (92.1548)  time: 0.3480  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [3210/4579]  eta: 0:07:55  Lr: 0.001875  Loss: -0.4323  Acc@1: 68.7500 (66.2819)  Acc@5: 93.7500 (92.1637)  time: 0.3470  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [3220/4579]  eta: 0:07:52  Lr: 0.001875  Loss: -0.4498  Acc@1: 68.7500 (66.2760)  Acc@5: 93.7500 (92.1628)  time: 0.3456  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3230/4579]  eta: 0:07:48  Lr: 0.001875  Loss: 0.3420  Acc@1: 56.2500 (66.2585)  Acc@5: 93.7500 (92.1638)  time: 0.3505  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [3240/4579]  eta: 0:07:45  Lr: 0.001875  Loss: 0.1532  Acc@1: 68.7500 (66.2681)  Acc@5: 93.7500 (92.1629)  time: 0.3511  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [3250/4579]  eta: 0:07:41  Lr: 0.001875  Loss: -0.1449  Acc@1: 62.5000 (66.2565)  Acc@5: 93.7500 (92.1620)  time: 0.3477  data: 0.0011  max mem: 2500
Train: Epoch[5/5]  [3260/4579]  eta: 0:07:38  Lr: 0.001875  Loss: -0.0851  Acc@1: 62.5000 (66.2508)  Acc@5: 87.5000 (92.1535)  time: 0.3481  data: 0.0012  max mem: 2500
Train: Epoch[5/5]  [3270/4579]  eta: 0:07:34  Lr: 0.001875  Loss: -0.2550  Acc@1: 68.7500 (66.2775)  Acc@5: 87.5000 (92.1565)  time: 0.3485  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [3280/4579]  eta: 0:07:31  Lr: 0.001875  Loss: -0.0322  Acc@1: 68.7500 (66.2812)  Acc@5: 93.7500 (92.1575)  time: 0.3469  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [3290/4579]  eta: 0:07:27  Lr: 0.001875  Loss: -0.0531  Acc@1: 68.7500 (66.3001)  Acc@5: 93.7500 (92.1642)  time: 0.3459  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [3300/4579]  eta: 0:07:24  Lr: 0.001875  Loss: -0.6134  Acc@1: 75.0000 (66.3284)  Acc@5: 93.7500 (92.1728)  time: 0.3465  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [3310/4579]  eta: 0:07:20  Lr: 0.001875  Loss: 0.0829  Acc@1: 68.7500 (66.3300)  Acc@5: 93.7500 (92.1700)  time: 0.3482  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [3320/4579]  eta: 0:07:17  Lr: 0.001875  Loss: -0.2771  Acc@1: 62.5000 (66.3317)  Acc@5: 93.7500 (92.1786)  time: 0.3481  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [3330/4579]  eta: 0:07:14  Lr: 0.001875  Loss: -0.0784  Acc@1: 62.5000 (66.3258)  Acc@5: 93.7500 (92.1833)  time: 0.3462  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3340/4579]  eta: 0:07:10  Lr: 0.001875  Loss: -0.3115  Acc@1: 62.5000 (66.3087)  Acc@5: 93.7500 (92.1917)  time: 0.3462  data: 0.0012  max mem: 2500
Train: Epoch[5/5]  [3350/4579]  eta: 0:07:07  Lr: 0.001875  Loss: -0.6833  Acc@1: 68.7500 (66.3384)  Acc@5: 93.7500 (92.2020)  time: 0.3462  data: 0.0011  max mem: 2500
Train: Epoch[5/5]  [3360/4579]  eta: 0:07:03  Lr: 0.001875  Loss: -0.2036  Acc@1: 68.7500 (66.3307)  Acc@5: 93.7500 (92.1991)  time: 0.3474  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [3370/4579]  eta: 0:07:00  Lr: 0.001875  Loss: 0.0535  Acc@1: 62.5000 (66.3156)  Acc@5: 87.5000 (92.1889)  time: 0.3476  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [3380/4579]  eta: 0:06:56  Lr: 0.001875  Loss: -0.1727  Acc@1: 62.5000 (66.3154)  Acc@5: 87.5000 (92.1861)  time: 0.3467  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [3390/4579]  eta: 0:06:53  Lr: 0.001875  Loss: -0.3147  Acc@1: 62.5000 (66.3097)  Acc@5: 93.7500 (92.1852)  time: 0.3469  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [3400/4579]  eta: 0:06:49  Lr: 0.001875  Loss: 0.0901  Acc@1: 62.5000 (66.3114)  Acc@5: 93.7500 (92.1880)  time: 0.3467  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [3410/4579]  eta: 0:06:46  Lr: 0.001875  Loss: 0.0619  Acc@1: 68.7500 (66.3204)  Acc@5: 93.7500 (92.1962)  time: 0.3458  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [3420/4579]  eta: 0:06:42  Lr: 0.001875  Loss: 0.5786  Acc@1: 62.5000 (66.3074)  Acc@5: 93.7500 (92.1916)  time: 0.3477  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [3430/4579]  eta: 0:06:39  Lr: 0.001875  Loss: 0.1806  Acc@1: 62.5000 (66.3072)  Acc@5: 93.7500 (92.1943)  time: 0.3482  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [3440/4579]  eta: 0:06:35  Lr: 0.001875  Loss: -0.2937  Acc@1: 62.5000 (66.3088)  Acc@5: 93.7500 (92.1934)  time: 0.3466  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [3450/4579]  eta: 0:06:32  Lr: 0.001875  Loss: 0.1220  Acc@1: 68.7500 (66.3177)  Acc@5: 93.7500 (92.1979)  time: 0.3474  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [3460/4579]  eta: 0:06:28  Lr: 0.001875  Loss: -0.4359  Acc@1: 68.7500 (66.3175)  Acc@5: 93.7500 (92.2024)  time: 0.3467  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [3470/4579]  eta: 0:06:25  Lr: 0.001875  Loss: 0.7366  Acc@1: 62.5000 (66.3173)  Acc@5: 93.7500 (92.2033)  time: 0.3464  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [3480/4579]  eta: 0:06:21  Lr: 0.001875  Loss: -0.1100  Acc@1: 62.5000 (66.3172)  Acc@5: 93.7500 (92.2095)  time: 0.3466  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [3490/4579]  eta: 0:06:18  Lr: 0.001875  Loss: -0.1426  Acc@1: 68.7500 (66.3223)  Acc@5: 93.7500 (92.2139)  time: 0.3473  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [3500/4579]  eta: 0:06:14  Lr: 0.001875  Loss: 0.4895  Acc@1: 62.5000 (66.3275)  Acc@5: 93.7500 (92.2112)  time: 0.3481  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [3510/4579]  eta: 0:06:11  Lr: 0.001875  Loss: 0.7454  Acc@1: 68.7500 (66.3255)  Acc@5: 87.5000 (92.2013)  time: 0.3476  data: 0.0010  max mem: 2500
Train: Epoch[5/5]  [3520/4579]  eta: 0:06:07  Lr: 0.001875  Loss: 0.2577  Acc@1: 68.7500 (66.3270)  Acc@5: 87.5000 (92.1933)  time: 0.3477  data: 0.0011  max mem: 2500
Train: Epoch[5/5]  [3530/4579]  eta: 0:06:04  Lr: 0.001875  Loss: -0.0444  Acc@1: 62.5000 (66.3250)  Acc@5: 93.7500 (92.1924)  time: 0.3492  data: 0.0027  max mem: 2500
Train: Epoch[5/5]  [3540/4579]  eta: 0:06:01  Lr: 0.001875  Loss: -0.5825  Acc@1: 62.5000 (66.3125)  Acc@5: 87.5000 (92.1809)  time: 0.3503  data: 0.0028  max mem: 2500
Train: Epoch[5/5]  [3550/4579]  eta: 0:05:57  Lr: 0.001875  Loss: 0.0529  Acc@1: 62.5000 (66.2841)  Acc@5: 87.5000 (92.1677)  time: 0.3483  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [3560/4579]  eta: 0:05:54  Lr: 0.001875  Loss: 0.0295  Acc@1: 56.2500 (66.2612)  Acc@5: 87.5000 (92.1581)  time: 0.3469  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [3570/4579]  eta: 0:05:50  Lr: 0.001875  Loss: -0.1188  Acc@1: 62.5000 (66.2752)  Acc@5: 87.5000 (92.1556)  time: 0.3473  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [3580/4579]  eta: 0:05:47  Lr: 0.001875  Loss: -0.3074  Acc@1: 68.7500 (66.2821)  Acc@5: 93.7500 (92.1618)  time: 0.3464  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [3590/4579]  eta: 0:05:43  Lr: 0.001875  Loss: -0.1698  Acc@1: 68.7500 (66.2785)  Acc@5: 93.7500 (92.1575)  time: 0.3472  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [3600/4579]  eta: 0:05:40  Lr: 0.001875  Loss: 0.0292  Acc@1: 68.7500 (66.2923)  Acc@5: 93.7500 (92.1584)  time: 0.3467  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [3610/4579]  eta: 0:05:36  Lr: 0.001875  Loss: 0.0673  Acc@1: 68.7500 (66.2940)  Acc@5: 93.7500 (92.1594)  time: 0.3460  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [3620/4579]  eta: 0:05:33  Lr: 0.001875  Loss: -0.2090  Acc@1: 68.7500 (66.3025)  Acc@5: 87.5000 (92.1569)  time: 0.3483  data: 0.0010  max mem: 2500
Train: Epoch[5/5]  [3630/4579]  eta: 0:05:29  Lr: 0.001875  Loss: -0.0606  Acc@1: 68.7500 (66.3127)  Acc@5: 93.7500 (92.1561)  time: 0.3475  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [3640/4579]  eta: 0:05:26  Lr: 0.001875  Loss: -0.6424  Acc@1: 62.5000 (66.2988)  Acc@5: 93.7500 (92.1622)  time: 0.3473  data: 0.0013  max mem: 2500
Train: Epoch[5/5]  [3650/4579]  eta: 0:05:22  Lr: 0.001875  Loss: 0.1497  Acc@1: 62.5000 (66.2866)  Acc@5: 93.7500 (92.1580)  time: 0.3487  data: 0.0014  max mem: 2500
Train: Epoch[5/5]  [3660/4579]  eta: 0:05:19  Lr: 0.001875  Loss: 0.0908  Acc@1: 62.5000 (66.2848)  Acc@5: 93.7500 (92.1572)  time: 0.3478  data: 0.0011  max mem: 2500
Train: Epoch[5/5]  [3670/4579]  eta: 0:05:15  Lr: 0.001875  Loss: -0.4619  Acc@1: 62.5000 (66.2881)  Acc@5: 93.7500 (92.1615)  time: 0.3482  data: 0.0014  max mem: 2500
Train: Epoch[5/5]  [3680/4579]  eta: 0:05:12  Lr: 0.001875  Loss: -0.2038  Acc@1: 68.7500 (66.2914)  Acc@5: 93.7500 (92.1642)  time: 0.3478  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [3690/4579]  eta: 0:05:08  Lr: 0.001875  Loss: 0.1197  Acc@1: 68.7500 (66.2913)  Acc@5: 93.7500 (92.1701)  time: 0.3468  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3700/4579]  eta: 0:05:05  Lr: 0.001875  Loss: 0.2967  Acc@1: 68.7500 (66.3030)  Acc@5: 93.7500 (92.1710)  time: 0.3466  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3710/4579]  eta: 0:05:01  Lr: 0.001875  Loss: -0.2034  Acc@1: 62.5000 (66.2945)  Acc@5: 93.7500 (92.1736)  time: 0.3468  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [3720/4579]  eta: 0:04:58  Lr: 0.001875  Loss: 0.2149  Acc@1: 62.5000 (66.2910)  Acc@5: 93.7500 (92.1795)  time: 0.3499  data: 0.0015  max mem: 2500
Train: Epoch[5/5]  [3730/4579]  eta: 0:04:55  Lr: 0.001875  Loss: -0.0672  Acc@1: 62.5000 (66.2976)  Acc@5: 93.7500 (92.1787)  time: 0.3491  data: 0.0013  max mem: 2500
Train: Epoch[5/5]  [3740/4579]  eta: 0:04:51  Lr: 0.001875  Loss: 0.4891  Acc@1: 68.7500 (66.3058)  Acc@5: 93.7500 (92.1846)  time: 0.3461  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [3750/4579]  eta: 0:04:48  Lr: 0.001875  Loss: 0.0653  Acc@1: 68.7500 (66.3140)  Acc@5: 93.7500 (92.1854)  time: 0.3467  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [3760/4579]  eta: 0:04:44  Lr: 0.001875  Loss: 0.2287  Acc@1: 68.7500 (66.3088)  Acc@5: 93.7500 (92.1813)  time: 0.3474  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [3770/4579]  eta: 0:04:41  Lr: 0.001875  Loss: -0.4312  Acc@1: 68.7500 (66.3120)  Acc@5: 93.7500 (92.1788)  time: 0.3473  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [3780/4579]  eta: 0:04:37  Lr: 0.001875  Loss: -0.2005  Acc@1: 68.7500 (66.3118)  Acc@5: 87.5000 (92.1714)  time: 0.3481  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [3790/4579]  eta: 0:04:34  Lr: 0.001875  Loss: -0.1783  Acc@1: 68.7500 (66.3001)  Acc@5: 93.7500 (92.1723)  time: 0.3493  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [3800/4579]  eta: 0:04:30  Lr: 0.001875  Loss: -0.6236  Acc@1: 68.7500 (66.3197)  Acc@5: 93.7500 (92.1764)  time: 0.3479  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [3810/4579]  eta: 0:04:27  Lr: 0.001875  Loss: 0.0818  Acc@1: 68.7500 (66.3179)  Acc@5: 93.7500 (92.1805)  time: 0.3479  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [3820/4579]  eta: 0:04:23  Lr: 0.001875  Loss: -0.1013  Acc@1: 62.5000 (66.3161)  Acc@5: 93.7500 (92.1765)  time: 0.3493  data: 0.0019  max mem: 2500
Train: Epoch[5/5]  [3830/4579]  eta: 0:04:20  Lr: 0.001875  Loss: 0.2650  Acc@1: 62.5000 (66.3126)  Acc@5: 93.7500 (92.1822)  time: 0.3491  data: 0.0020  max mem: 2500
Train: Epoch[5/5]  [3840/4579]  eta: 0:04:16  Lr: 0.001875  Loss: 0.0161  Acc@1: 68.7500 (66.3174)  Acc@5: 93.7500 (92.1847)  time: 0.3477  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [3850/4579]  eta: 0:04:13  Lr: 0.001875  Loss: -0.1716  Acc@1: 68.7500 (66.3091)  Acc@5: 93.7500 (92.1903)  time: 0.3460  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [3860/4579]  eta: 0:04:09  Lr: 0.001875  Loss: -0.2668  Acc@1: 68.7500 (66.3251)  Acc@5: 93.7500 (92.1895)  time: 0.3463  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [3870/4579]  eta: 0:04:06  Lr: 0.001875  Loss: -0.2437  Acc@1: 75.0000 (66.3459)  Acc@5: 93.7500 (92.2000)  time: 0.3474  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3880/4579]  eta: 0:04:02  Lr: 0.001875  Loss: -0.4737  Acc@1: 75.0000 (66.3440)  Acc@5: 93.7500 (92.2072)  time: 0.3477  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [3890/4579]  eta: 0:03:59  Lr: 0.001875  Loss: -0.4505  Acc@1: 68.7500 (66.3551)  Acc@5: 93.7500 (92.2208)  time: 0.3486  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [3900/4579]  eta: 0:03:55  Lr: 0.001875  Loss: -0.3568  Acc@1: 68.7500 (66.3724)  Acc@5: 93.7500 (92.2264)  time: 0.3486  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [3910/4579]  eta: 0:03:52  Lr: 0.001875  Loss: 0.1697  Acc@1: 68.7500 (66.3657)  Acc@5: 93.7500 (92.2286)  time: 0.3480  data: 0.0010  max mem: 2500
Train: Epoch[5/5]  [3920/4579]  eta: 0:03:49  Lr: 0.001875  Loss: -0.0765  Acc@1: 62.5000 (66.3734)  Acc@5: 93.7500 (92.2277)  time: 0.3494  data: 0.0015  max mem: 2500
Train: Epoch[5/5]  [3930/4579]  eta: 0:03:45  Lr: 0.001875  Loss: 0.1073  Acc@1: 75.0000 (66.3874)  Acc@5: 93.7500 (92.2269)  time: 0.3505  data: 0.0013  max mem: 2500
Train: Epoch[5/5]  [3940/4579]  eta: 0:03:42  Lr: 0.001875  Loss: 0.1075  Acc@1: 68.7500 (66.3759)  Acc@5: 93.7500 (92.2275)  time: 0.3479  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [3950/4579]  eta: 0:03:38  Lr: 0.001875  Loss: -0.5078  Acc@1: 68.7500 (66.3914)  Acc@5: 93.7500 (92.2219)  time: 0.3460  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [3960/4579]  eta: 0:03:35  Lr: 0.001875  Loss: -0.2460  Acc@1: 68.7500 (66.3832)  Acc@5: 93.7500 (92.2210)  time: 0.3478  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [3970/4579]  eta: 0:03:31  Lr: 0.001875  Loss: -0.4314  Acc@1: 62.5000 (66.3844)  Acc@5: 93.7500 (92.2265)  time: 0.3474  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [3980/4579]  eta: 0:03:28  Lr: 0.001875  Loss: 0.2807  Acc@1: 68.7500 (66.3951)  Acc@5: 93.7500 (92.2240)  time: 0.3474  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [3990/4579]  eta: 0:03:24  Lr: 0.001875  Loss: 0.7252  Acc@1: 68.7500 (66.3900)  Acc@5: 93.7500 (92.2200)  time: 0.3473  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [4000/4579]  eta: 0:03:21  Lr: 0.001875  Loss: -0.4109  Acc@1: 62.5000 (66.3803)  Acc@5: 87.5000 (92.2098)  time: 0.3456  data: 0.0012  max mem: 2500
Train: Epoch[5/5]  [4010/4579]  eta: 0:03:17  Lr: 0.001875  Loss: -0.1907  Acc@1: 68.7500 (66.3940)  Acc@5: 93.7500 (92.2152)  time: 0.3470  data: 0.0020  max mem: 2500
Train: Epoch[5/5]  [4020/4579]  eta: 0:03:14  Lr: 0.001875  Loss: 0.0334  Acc@1: 75.0000 (66.4029)  Acc@5: 93.7500 (92.2174)  time: 0.3468  data: 0.0013  max mem: 2500
Train: Epoch[5/5]  [4030/4579]  eta: 0:03:10  Lr: 0.001875  Loss: 0.3559  Acc@1: 62.5000 (66.3886)  Acc@5: 93.7500 (92.2166)  time: 0.3455  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [4040/4579]  eta: 0:03:07  Lr: 0.001875  Loss: -0.3075  Acc@1: 62.5000 (66.3836)  Acc@5: 93.7500 (92.2126)  time: 0.3472  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [4050/4579]  eta: 0:03:03  Lr: 0.001875  Loss: -0.6477  Acc@1: 68.7500 (66.3987)  Acc@5: 93.7500 (92.2149)  time: 0.3478  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [4060/4579]  eta: 0:03:00  Lr: 0.001875  Loss: -0.0151  Acc@1: 68.7500 (66.3999)  Acc@5: 93.7500 (92.2079)  time: 0.3467  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [4070/4579]  eta: 0:02:56  Lr: 0.001875  Loss: -0.4358  Acc@1: 68.7500 (66.4134)  Acc@5: 93.7500 (92.2086)  time: 0.3458  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [4080/4579]  eta: 0:02:53  Lr: 0.001875  Loss: -0.3762  Acc@1: 75.0000 (66.4267)  Acc@5: 93.7500 (92.2185)  time: 0.3458  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [4090/4579]  eta: 0:02:49  Lr: 0.001875  Loss: 0.0107  Acc@1: 68.7500 (66.4294)  Acc@5: 93.7500 (92.2100)  time: 0.3463  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [4100/4579]  eta: 0:02:46  Lr: 0.001875  Loss: 0.3272  Acc@1: 68.7500 (66.4320)  Acc@5: 93.7500 (92.2077)  time: 0.3463  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [4110/4579]  eta: 0:02:42  Lr: 0.001875  Loss: 0.0715  Acc@1: 68.7500 (66.4391)  Acc@5: 93.7500 (92.2038)  time: 0.3479  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [4120/4579]  eta: 0:02:39  Lr: 0.001875  Loss: -0.2842  Acc@1: 68.7500 (66.4372)  Acc@5: 93.7500 (92.2000)  time: 0.3473  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [4130/4579]  eta: 0:02:36  Lr: 0.001875  Loss: -0.0043  Acc@1: 62.5000 (66.4352)  Acc@5: 93.7500 (92.2038)  time: 0.3478  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [4140/4579]  eta: 0:02:32  Lr: 0.001875  Loss: -0.5208  Acc@1: 75.0000 (66.4483)  Acc@5: 93.7500 (92.2060)  time: 0.3479  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [4150/4579]  eta: 0:02:29  Lr: 0.001875  Loss: -0.0185  Acc@1: 75.0000 (66.4539)  Acc@5: 93.7500 (92.2037)  time: 0.3477  data: 0.0015  max mem: 2500
Train: Epoch[5/5]  [4160/4579]  eta: 0:02:25  Lr: 0.001875  Loss: -0.3529  Acc@1: 68.7500 (66.4624)  Acc@5: 93.7500 (92.2014)  time: 0.3487  data: 0.0015  max mem: 2500
Train: Epoch[5/5]  [4170/4579]  eta: 0:02:22  Lr: 0.001875  Loss: 0.3336  Acc@1: 68.7500 (66.4574)  Acc@5: 87.5000 (92.1961)  time: 0.3482  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [4180/4579]  eta: 0:02:18  Lr: 0.001875  Loss: 0.8120  Acc@1: 62.5000 (66.4330)  Acc@5: 87.5000 (92.1819)  time: 0.3473  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [4190/4579]  eta: 0:02:15  Lr: 0.001875  Loss: 0.2184  Acc@1: 62.5000 (66.4415)  Acc@5: 87.5000 (92.1737)  time: 0.3465  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [4200/4579]  eta: 0:02:11  Lr: 0.001875  Loss: -0.6022  Acc@1: 68.7500 (66.4440)  Acc@5: 93.7500 (92.1804)  time: 0.3481  data: 0.0019  max mem: 2500
Train: Epoch[5/5]  [4210/4579]  eta: 0:02:08  Lr: 0.001875  Loss: -0.1992  Acc@1: 68.7500 (66.4376)  Acc@5: 93.7500 (92.1871)  time: 0.3480  data: 0.0019  max mem: 2500
Train: Epoch[5/5]  [4220/4579]  eta: 0:02:04  Lr: 0.001875  Loss: 0.2685  Acc@1: 68.7500 (66.4357)  Acc@5: 93.7500 (92.1790)  time: 0.3467  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [4230/4579]  eta: 0:02:01  Lr: 0.001875  Loss: 0.1842  Acc@1: 68.7500 (66.4500)  Acc@5: 93.7500 (92.1901)  time: 0.3493  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [4240/4579]  eta: 0:01:57  Lr: 0.001875  Loss: 0.0186  Acc@1: 68.7500 (66.4495)  Acc@5: 93.7500 (92.1952)  time: 0.3503  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [4250/4579]  eta: 0:01:54  Lr: 0.001875  Loss: -0.2335  Acc@1: 68.7500 (66.4491)  Acc@5: 93.7500 (92.1974)  time: 0.3490  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [4260/4579]  eta: 0:01:50  Lr: 0.001875  Loss: -0.8414  Acc@1: 68.7500 (66.4721)  Acc@5: 93.7500 (92.2055)  time: 0.3481  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [4270/4579]  eta: 0:01:47  Lr: 0.001875  Loss: -0.5196  Acc@1: 68.7500 (66.4745)  Acc@5: 93.7500 (92.2091)  time: 0.3478  data: 0.0013  max mem: 2500
Train: Epoch[5/5]  [4280/4579]  eta: 0:01:43  Lr: 0.001875  Loss: 0.7277  Acc@1: 68.7500 (66.4783)  Acc@5: 93.7500 (92.2068)  time: 0.3487  data: 0.0012  max mem: 2500
Train: Epoch[5/5]  [4290/4579]  eta: 0:01:40  Lr: 0.001875  Loss: -0.0566  Acc@1: 68.7500 (66.4880)  Acc@5: 93.7500 (92.2075)  time: 0.3471  data: 0.0010  max mem: 2500
Train: Epoch[5/5]  [4300/4579]  eta: 0:01:36  Lr: 0.001875  Loss: -0.6585  Acc@1: 68.7500 (66.4773)  Acc@5: 93.7500 (92.2009)  time: 0.3469  data: 0.0017  max mem: 2500
Train: Epoch[5/5]  [4310/4579]  eta: 0:01:33  Lr: 0.001875  Loss: 0.0818  Acc@1: 56.2500 (66.4550)  Acc@5: 87.5000 (92.1944)  time: 0.3483  data: 0.0012  max mem: 2500
Train: Epoch[5/5]  [4320/4579]  eta: 0:01:30  Lr: 0.001875  Loss: -0.0700  Acc@1: 62.5000 (66.4574)  Acc@5: 93.7500 (92.1922)  time: 0.3479  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [4330/4579]  eta: 0:01:26  Lr: 0.001875  Loss: -0.2809  Acc@1: 75.0000 (66.4685)  Acc@5: 93.7500 (92.1915)  time: 0.3474  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [4340/4579]  eta: 0:01:23  Lr: 0.001875  Loss: 0.0789  Acc@1: 68.7500 (66.4680)  Acc@5: 93.7500 (92.1907)  time: 0.3478  data: 0.0011  max mem: 2500
Train: Epoch[5/5]  [4350/4579]  eta: 0:01:19  Lr: 0.001875  Loss: -0.6448  Acc@1: 68.7500 (66.4747)  Acc@5: 93.7500 (92.1943)  time: 0.3470  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [4360/4579]  eta: 0:01:16  Lr: 0.001875  Loss: -0.5197  Acc@1: 68.7500 (66.4827)  Acc@5: 93.7500 (92.1879)  time: 0.3478  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [4370/4579]  eta: 0:01:12  Lr: 0.001875  Loss: -0.4841  Acc@1: 62.5000 (66.4965)  Acc@5: 93.7500 (92.1914)  time: 0.3492  data: 0.0013  max mem: 2500
Train: Epoch[5/5]  [4380/4579]  eta: 0:01:09  Lr: 0.001875  Loss: -0.1841  Acc@1: 68.7500 (66.5102)  Acc@5: 93.7500 (92.1993)  time: 0.3475  data: 0.0012  max mem: 2500
Train: Epoch[5/5]  [4390/4579]  eta: 0:01:05  Lr: 0.001875  Loss: -0.0643  Acc@1: 68.7500 (66.4982)  Acc@5: 93.7500 (92.2014)  time: 0.3463  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [4400/4579]  eta: 0:01:02  Lr: 0.001875  Loss: 0.0400  Acc@1: 56.2500 (66.4920)  Acc@5: 93.7500 (92.1978)  time: 0.3489  data: 0.0014  max mem: 2500
Train: Epoch[5/5]  [4410/4579]  eta: 0:00:58  Lr: 0.001875  Loss: -0.2988  Acc@1: 56.2500 (66.4801)  Acc@5: 87.5000 (92.1871)  time: 0.3486  data: 0.0019  max mem: 2500
Train: Epoch[5/5]  [4420/4579]  eta: 0:00:55  Lr: 0.001875  Loss: 0.4450  Acc@1: 62.5000 (66.4895)  Acc@5: 93.7500 (92.1893)  time: 0.3463  data: 0.0018  max mem: 2500
Train: Epoch[5/5]  [4430/4579]  eta: 0:00:51  Lr: 0.001875  Loss: 0.2069  Acc@1: 75.0000 (66.5016)  Acc@5: 93.7500 (92.1956)  time: 0.3469  data: 0.0011  max mem: 2500
Train: Epoch[5/5]  [4440/4579]  eta: 0:00:48  Lr: 0.001875  Loss: 0.6027  Acc@1: 68.7500 (66.5011)  Acc@5: 93.7500 (92.1949)  time: 0.3470  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [4450/4579]  eta: 0:00:44  Lr: 0.001875  Loss: 0.2057  Acc@1: 68.7500 (66.5033)  Acc@5: 93.7500 (92.1900)  time: 0.3473  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [4460/4579]  eta: 0:00:41  Lr: 0.001875  Loss: -0.2352  Acc@1: 68.7500 (66.5098)  Acc@5: 93.7500 (92.1963)  time: 0.3479  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [4470/4579]  eta: 0:00:37  Lr: 0.001875  Loss: -0.3296  Acc@1: 68.7500 (66.5190)  Acc@5: 93.7500 (92.1899)  time: 0.3472  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [4480/4579]  eta: 0:00:34  Lr: 0.001875  Loss: -0.1388  Acc@1: 68.7500 (66.5379)  Acc@5: 93.7500 (92.1976)  time: 0.3470  data: 0.0012  max mem: 2500
Train: Epoch[5/5]  [4490/4579]  eta: 0:00:30  Lr: 0.001875  Loss: -0.3015  Acc@1: 68.7500 (66.5303)  Acc@5: 93.7500 (92.1899)  time: 0.3468  data: 0.0012  max mem: 2500
Train: Epoch[5/5]  [4500/4579]  eta: 0:00:27  Lr: 0.001875  Loss: -0.3483  Acc@1: 62.5000 (66.5310)  Acc@5: 93.7500 (92.1865)  time: 0.3469  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [4510/4579]  eta: 0:00:23  Lr: 0.001875  Loss: -0.4415  Acc@1: 68.7500 (66.5360)  Acc@5: 93.7500 (92.1899)  time: 0.3468  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [4520/4579]  eta: 0:00:20  Lr: 0.001875  Loss: 0.1083  Acc@1: 68.7500 (66.5381)  Acc@5: 93.7500 (92.1948)  time: 0.3471  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [4530/4579]  eta: 0:00:17  Lr: 0.001875  Loss: -0.6995  Acc@1: 68.7500 (66.5375)  Acc@5: 93.7500 (92.1927)  time: 0.3475  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [4540/4579]  eta: 0:00:13  Lr: 0.001875  Loss: -0.3001  Acc@1: 62.5000 (66.5272)  Acc@5: 87.5000 (92.1851)  time: 0.3462  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [4550/4579]  eta: 0:00:10  Lr: 0.001875  Loss: 1.2273  Acc@1: 62.5000 (66.5170)  Acc@5: 87.5000 (92.1817)  time: 0.3457  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [4560/4579]  eta: 0:00:06  Lr: 0.001875  Loss: -0.4498  Acc@1: 62.5000 (66.5219)  Acc@5: 87.5000 (92.1783)  time: 0.3467  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [4570/4579]  eta: 0:00:03  Lr: 0.001875  Loss: -0.3050  Acc@1: 62.5000 (66.5240)  Acc@5: 87.5000 (92.1735)  time: 0.3484  data: 0.0011  max mem: 2500
Train: Epoch[5/5]  [4578/4579]  eta: 0:00:00  Lr: 0.001875  Loss: -0.0075  Acc@1: 68.7500 (66.5288)  Acc@5: 93.7500 (92.1741)  time: 0.3400  data: 0.0009  max mem: 2500
Train: Epoch[5/5] Total time: 0:26:32 (0.3477 s / it)
{0: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 1: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 2: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 3: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 4: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 5: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 6: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 7: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 8: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 9: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 10: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 11: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 12: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 13: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 14: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 15: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 16: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 17: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 18: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 19: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}}
Averaged stats: Lr: 0.001875  Loss: -0.0075  Acc@1: 68.7500 (66.5288)  Acc@5: 93.7500 (92.1741)
Test: [Task 1]  [   0/1627]  eta: 0:14:37  Loss: 1.0104 (1.0104)  Acc@1: 87.5000 (87.5000)  Acc@5: 93.7500 (93.7500)  time: 0.5396  data: 0.3245  max mem: 2500
Test: [Task 1]  [  10/1627]  eta: 0:06:34  Loss: 0.9714 (0.8946)  Acc@1: 87.5000 (86.3636)  Acc@5: 100.0000 (97.7273)  time: 0.2437  data: 0.0298  max mem: 2500
Test: [Task 1]  [  20/1627]  eta: 0:06:10  Loss: 0.8557 (0.8618)  Acc@1: 87.5000 (86.6071)  Acc@5: 100.0000 (97.9167)  time: 0.2153  data: 0.0004  max mem: 2500
Test: [Task 1]  [  30/1627]  eta: 0:06:01  Loss: 0.8606 (0.8824)  Acc@1: 87.5000 (86.0887)  Acc@5: 100.0000 (97.9839)  time: 0.2173  data: 0.0013  max mem: 2500
Test: [Task 1]  [  40/1627]  eta: 0:05:55  Loss: 0.9558 (0.8878)  Acc@1: 81.2500 (85.3659)  Acc@5: 100.0000 (97.7134)  time: 0.2172  data: 0.0012  max mem: 2500
Test: [Task 1]  [  50/1627]  eta: 0:05:50  Loss: 0.8468 (0.8757)  Acc@1: 87.5000 (85.7843)  Acc@5: 100.0000 (97.5490)  time: 0.2157  data: 0.0004  max mem: 2500
Test: [Task 1]  [  60/1627]  eta: 0:05:47  Loss: 0.8936 (0.8883)  Acc@1: 87.5000 (85.5533)  Acc@5: 100.0000 (97.5410)  time: 0.2169  data: 0.0014  max mem: 2500
Test: [Task 1]  [  70/1627]  eta: 0:05:43  Loss: 0.8323 (0.8813)  Acc@1: 87.5000 (85.7394)  Acc@5: 100.0000 (97.7113)  time: 0.2170  data: 0.0014  max mem: 2500
Test: [Task 1]  [  80/1627]  eta: 0:05:40  Loss: 0.7085 (0.8650)  Acc@1: 87.5000 (85.9568)  Acc@5: 100.0000 (97.9938)  time: 0.2159  data: 0.0005  max mem: 2500
Test: [Task 1]  [  90/1627]  eta: 0:05:37  Loss: 0.8092 (0.8763)  Acc@1: 87.5000 (85.5082)  Acc@5: 100.0000 (97.9396)  time: 0.2158  data: 0.0005  max mem: 2500
Test: [Task 1]  [ 100/1627]  eta: 0:05:35  Loss: 1.0104 (0.8970)  Acc@1: 81.2500 (85.1485)  Acc@5: 100.0000 (97.5866)  time: 0.2156  data: 0.0005  max mem: 2500
Test: [Task 1]  [ 110/1627]  eta: 0:05:32  Loss: 0.9248 (0.8952)  Acc@1: 81.2500 (85.1351)  Acc@5: 100.0000 (97.6914)  time: 0.2164  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 120/1627]  eta: 0:05:29  Loss: 0.8863 (0.8961)  Acc@1: 87.5000 (85.2789)  Acc@5: 100.0000 (97.5207)  time: 0.2156  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 130/1627]  eta: 0:05:27  Loss: 0.9583 (0.9000)  Acc@1: 87.5000 (85.2576)  Acc@5: 93.7500 (97.4237)  time: 0.2151  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 140/1627]  eta: 0:05:24  Loss: 0.8626 (0.8980)  Acc@1: 87.5000 (85.2837)  Acc@5: 100.0000 (97.4734)  time: 0.2156  data: 0.0007  max mem: 2500
Test: [Task 1]  [ 150/1627]  eta: 0:05:22  Loss: 0.6851 (0.8869)  Acc@1: 87.5000 (85.5132)  Acc@5: 100.0000 (97.4338)  time: 0.2160  data: 0.0008  max mem: 2500
Test: [Task 1]  [ 160/1627]  eta: 0:05:19  Loss: 0.6927 (0.8808)  Acc@1: 87.5000 (85.6755)  Acc@5: 100.0000 (97.4379)  time: 0.2157  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 170/1627]  eta: 0:05:17  Loss: 0.7427 (0.8760)  Acc@1: 87.5000 (85.6725)  Acc@5: 100.0000 (97.4415)  time: 0.2159  data: 0.0011  max mem: 2500
Test: [Task 1]  [ 180/1627]  eta: 0:05:15  Loss: 0.8219 (0.8816)  Acc@1: 81.2500 (85.5663)  Acc@5: 100.0000 (97.4793)  time: 0.2180  data: 0.0020  max mem: 2500
Test: [Task 1]  [ 190/1627]  eta: 0:05:13  Loss: 0.9026 (0.8783)  Acc@1: 87.5000 (85.5039)  Acc@5: 100.0000 (97.5131)  time: 0.2192  data: 0.0027  max mem: 2500
Test: [Task 1]  [ 200/1627]  eta: 0:05:11  Loss: 0.7875 (0.8798)  Acc@1: 81.2500 (85.4167)  Acc@5: 100.0000 (97.5435)  time: 0.2186  data: 0.0018  max mem: 2500
Test: [Task 1]  [ 210/1627]  eta: 0:05:08  Loss: 0.7875 (0.8781)  Acc@1: 81.2500 (85.5154)  Acc@5: 100.0000 (97.5118)  time: 0.2164  data: 0.0006  max mem: 2500
Test: [Task 1]  [ 220/1627]  eta: 0:05:06  Loss: 0.7833 (0.8830)  Acc@1: 87.5000 (85.3507)  Acc@5: 100.0000 (97.5396)  time: 0.2159  data: 0.0006  max mem: 2500
Test: [Task 1]  [ 230/1627]  eta: 0:05:04  Loss: 0.7984 (0.8781)  Acc@1: 81.2500 (85.4437)  Acc@5: 100.0000 (97.5649)  time: 0.2170  data: 0.0009  max mem: 2500
Test: [Task 1]  [ 240/1627]  eta: 0:05:02  Loss: 0.7852 (0.8741)  Acc@1: 87.5000 (85.5550)  Acc@5: 100.0000 (97.6141)  time: 0.2171  data: 0.0011  max mem: 2500
Test: [Task 1]  [ 250/1627]  eta: 0:04:59  Loss: 0.8100 (0.8793)  Acc@1: 87.5000 (85.5329)  Acc@5: 100.0000 (97.5100)  time: 0.2167  data: 0.0006  max mem: 2500
Test: [Task 1]  [ 260/1627]  eta: 0:04:57  Loss: 0.8787 (0.8790)  Acc@1: 87.5000 (85.5125)  Acc@5: 100.0000 (97.5096)  time: 0.2158  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 270/1627]  eta: 0:04:55  Loss: 0.8011 (0.8732)  Acc@1: 87.5000 (85.6089)  Acc@5: 100.0000 (97.5784)  time: 0.2158  data: 0.0005  max mem: 2500
Test: [Task 1]  [ 280/1627]  eta: 0:04:53  Loss: 0.7527 (0.8741)  Acc@1: 87.5000 (85.4760)  Acc@5: 100.0000 (97.5534)  time: 0.2164  data: 0.0007  max mem: 2500
Test: [Task 1]  [ 290/1627]  eta: 0:04:50  Loss: 0.7594 (0.8729)  Acc@1: 81.2500 (85.5455)  Acc@5: 100.0000 (97.5301)  time: 0.2166  data: 0.0006  max mem: 2500
Test: [Task 1]  [ 300/1627]  eta: 0:04:48  Loss: 0.7081 (0.8699)  Acc@1: 87.5000 (85.6105)  Acc@5: 100.0000 (97.5498)  time: 0.2172  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 310/1627]  eta: 0:04:46  Loss: 0.7770 (0.8708)  Acc@1: 87.5000 (85.5908)  Acc@5: 100.0000 (97.5482)  time: 0.2160  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 320/1627]  eta: 0:04:44  Loss: 0.8415 (0.8696)  Acc@1: 87.5000 (85.7087)  Acc@5: 100.0000 (97.5662)  time: 0.2154  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 330/1627]  eta: 0:04:41  Loss: 0.7829 (0.8676)  Acc@1: 87.5000 (85.6495)  Acc@5: 100.0000 (97.5831)  time: 0.2172  data: 0.0008  max mem: 2500
Test: [Task 1]  [ 340/1627]  eta: 0:04:39  Loss: 0.6718 (0.8681)  Acc@1: 81.2500 (85.6855)  Acc@5: 100.0000 (97.5806)  time: 0.2177  data: 0.0011  max mem: 2500
Test: [Task 1]  [ 350/1627]  eta: 0:04:37  Loss: 0.7404 (0.8693)  Acc@1: 87.5000 (85.6481)  Acc@5: 100.0000 (97.5249)  time: 0.2179  data: 0.0011  max mem: 2500
Test: [Task 1]  [ 360/1627]  eta: 0:04:35  Loss: 0.7404 (0.8684)  Acc@1: 87.5000 (85.5263)  Acc@5: 100.0000 (97.5416)  time: 0.2166  data: 0.0008  max mem: 2500
Test: [Task 1]  [ 370/1627]  eta: 0:04:33  Loss: 0.7442 (0.8682)  Acc@1: 87.5000 (85.5458)  Acc@5: 100.0000 (97.5573)  time: 0.2154  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 380/1627]  eta: 0:04:31  Loss: 0.8023 (0.8665)  Acc@1: 87.5000 (85.6135)  Acc@5: 100.0000 (97.5558)  time: 0.2171  data: 0.0005  max mem: 2500
Test: [Task 1]  [ 390/1627]  eta: 0:04:28  Loss: 0.8437 (0.8682)  Acc@1: 87.5000 (85.5818)  Acc@5: 100.0000 (97.5543)  time: 0.2181  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 400/1627]  eta: 0:04:26  Loss: 0.8670 (0.8693)  Acc@1: 87.5000 (85.6141)  Acc@5: 100.0000 (97.5530)  time: 0.2165  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 410/1627]  eta: 0:04:24  Loss: 0.7803 (0.8695)  Acc@1: 87.5000 (85.6448)  Acc@5: 100.0000 (97.5213)  time: 0.2154  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 420/1627]  eta: 0:04:22  Loss: 0.7034 (0.8680)  Acc@1: 87.5000 (85.6740)  Acc@5: 100.0000 (97.5356)  time: 0.2162  data: 0.0007  max mem: 2500
Test: [Task 1]  [ 430/1627]  eta: 0:04:20  Loss: 0.6887 (0.8657)  Acc@1: 87.5000 (85.7164)  Acc@5: 100.0000 (97.5783)  time: 0.2159  data: 0.0007  max mem: 2500
Test: [Task 1]  [ 440/1627]  eta: 0:04:17  Loss: 0.8728 (0.8649)  Acc@1: 87.5000 (85.6859)  Acc@5: 100.0000 (97.6049)  time: 0.2151  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 450/1627]  eta: 0:04:15  Loss: 0.8919 (0.8678)  Acc@1: 81.2500 (85.5322)  Acc@5: 100.0000 (97.5748)  time: 0.2158  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 460/1627]  eta: 0:04:13  Loss: 0.8748 (0.8665)  Acc@1: 81.2500 (85.4799)  Acc@5: 100.0000 (97.5868)  time: 0.2167  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 470/1627]  eta: 0:04:11  Loss: 0.7011 (0.8639)  Acc@1: 87.5000 (85.4963)  Acc@5: 100.0000 (97.5849)  time: 0.2158  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 480/1627]  eta: 0:04:08  Loss: 0.7864 (0.8675)  Acc@1: 87.5000 (85.4730)  Acc@5: 100.0000 (97.5832)  time: 0.2152  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 490/1627]  eta: 0:04:06  Loss: 0.9061 (0.8683)  Acc@1: 87.5000 (85.4379)  Acc@5: 100.0000 (97.5815)  time: 0.2165  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 500/1627]  eta: 0:04:04  Loss: 0.7504 (0.8696)  Acc@1: 87.5000 (85.3917)  Acc@5: 100.0000 (97.5674)  time: 0.2171  data: 0.0005  max mem: 2500
Test: [Task 1]  [ 510/1627]  eta: 0:04:02  Loss: 0.9090 (0.8742)  Acc@1: 81.2500 (85.3229)  Acc@5: 93.7500 (97.5294)  time: 0.2160  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 520/1627]  eta: 0:04:00  Loss: 1.0566 (0.8803)  Acc@1: 81.2500 (85.3167)  Acc@5: 100.0000 (97.4808)  time: 0.2153  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 530/1627]  eta: 0:03:58  Loss: 0.8672 (0.8772)  Acc@1: 87.5000 (85.3696)  Acc@5: 100.0000 (97.5165)  time: 0.2155  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 540/1627]  eta: 0:03:55  Loss: 0.8672 (0.8778)  Acc@1: 87.5000 (85.3974)  Acc@5: 100.0000 (97.4931)  time: 0.2159  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 550/1627]  eta: 0:03:53  Loss: 0.9603 (0.8796)  Acc@1: 87.5000 (85.3789)  Acc@5: 100.0000 (97.5159)  time: 0.2170  data: 0.0007  max mem: 2500
Test: [Task 1]  [ 560/1627]  eta: 0:03:51  Loss: 1.0204 (0.8818)  Acc@1: 81.2500 (85.3387)  Acc@5: 100.0000 (97.5267)  time: 0.2178  data: 0.0007  max mem: 2500
Test: [Task 1]  [ 570/1627]  eta: 0:03:49  Loss: 0.8352 (0.8786)  Acc@1: 87.5000 (85.4203)  Acc@5: 100.0000 (97.5153)  time: 0.2162  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 580/1627]  eta: 0:03:47  Loss: 0.8127 (0.8795)  Acc@1: 87.5000 (85.3916)  Acc@5: 100.0000 (97.5366)  time: 0.2153  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 590/1627]  eta: 0:03:44  Loss: 0.8127 (0.8781)  Acc@1: 87.5000 (85.4167)  Acc@5: 100.0000 (97.5465)  time: 0.2162  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 600/1627]  eta: 0:03:42  Loss: 0.7977 (0.8794)  Acc@1: 87.5000 (85.3577)  Acc@5: 100.0000 (97.5562)  time: 0.2166  data: 0.0005  max mem: 2500
Test: [Task 1]  [ 610/1627]  eta: 0:03:40  Loss: 0.8594 (0.8786)  Acc@1: 87.5000 (85.4644)  Acc@5: 100.0000 (97.5552)  time: 0.2173  data: 0.0009  max mem: 2500
Test: [Task 1]  [ 620/1627]  eta: 0:03:38  Loss: 0.8209 (0.8801)  Acc@1: 87.5000 (85.4267)  Acc@5: 100.0000 (97.5342)  time: 0.2167  data: 0.0008  max mem: 2500
Test: [Task 1]  [ 630/1627]  eta: 0:03:36  Loss: 0.7856 (0.8798)  Acc@1: 87.5000 (85.4992)  Acc@5: 100.0000 (97.5139)  time: 0.2158  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 640/1627]  eta: 0:03:34  Loss: 0.6990 (0.8793)  Acc@1: 87.5000 (85.5109)  Acc@5: 100.0000 (97.5137)  time: 0.2162  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 650/1627]  eta: 0:03:31  Loss: 0.7011 (0.8783)  Acc@1: 87.5000 (85.5127)  Acc@5: 100.0000 (97.5326)  time: 0.2171  data: 0.0009  max mem: 2500
Test: [Task 1]  [ 660/1627]  eta: 0:03:29  Loss: 0.7639 (0.8769)  Acc@1: 87.5000 (85.5333)  Acc@5: 100.0000 (97.5511)  time: 0.2198  data: 0.0022  max mem: 2500
Test: [Task 1]  [ 670/1627]  eta: 0:03:27  Loss: 0.8379 (0.8776)  Acc@1: 81.2500 (85.5067)  Acc@5: 100.0000 (97.5503)  time: 0.2203  data: 0.0021  max mem: 2500
Test: [Task 1]  [ 680/1627]  eta: 0:03:25  Loss: 0.9034 (0.8776)  Acc@1: 81.2500 (85.4717)  Acc@5: 100.0000 (97.5496)  time: 0.2175  data: 0.0008  max mem: 2500
Test: [Task 1]  [ 690/1627]  eta: 0:03:23  Loss: 0.8004 (0.8757)  Acc@1: 87.5000 (85.5101)  Acc@5: 100.0000 (97.5760)  time: 0.2161  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 700/1627]  eta: 0:03:21  Loss: 0.8379 (0.8764)  Acc@1: 87.5000 (85.4939)  Acc@5: 100.0000 (97.5660)  time: 0.2183  data: 0.0005  max mem: 2500
Test: [Task 1]  [ 710/1627]  eta: 0:03:18  Loss: 0.7968 (0.8741)  Acc@1: 87.5000 (85.5837)  Acc@5: 100.0000 (97.5826)  time: 0.2174  data: 0.0005  max mem: 2500
Test: [Task 1]  [ 720/1627]  eta: 0:03:16  Loss: 0.7479 (0.8722)  Acc@1: 87.5000 (85.6016)  Acc@5: 100.0000 (97.5902)  time: 0.2149  data: 0.0005  max mem: 2500
Test: [Task 1]  [ 730/1627]  eta: 0:03:14  Loss: 0.8062 (0.8734)  Acc@1: 87.5000 (85.5677)  Acc@5: 100.0000 (97.5804)  time: 0.2153  data: 0.0005  max mem: 2500
Test: [Task 1]  [ 740/1627]  eta: 0:03:12  Loss: 0.9293 (0.8750)  Acc@1: 81.2500 (85.5432)  Acc@5: 93.7500 (97.5455)  time: 0.2156  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 750/1627]  eta: 0:03:10  Loss: 0.8126 (0.8743)  Acc@1: 87.5000 (85.5776)  Acc@5: 100.0000 (97.5616)  time: 0.2165  data: 0.0005  max mem: 2500
Test: [Task 1]  [ 760/1627]  eta: 0:03:08  Loss: 0.8691 (0.8772)  Acc@1: 81.2500 (85.5207)  Acc@5: 100.0000 (97.5443)  time: 0.2162  data: 0.0005  max mem: 2500
Test: [Task 1]  [ 770/1627]  eta: 0:03:05  Loss: 0.7112 (0.8741)  Acc@1: 87.5000 (85.5788)  Acc@5: 100.0000 (97.5600)  time: 0.2156  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 780/1627]  eta: 0:03:03  Loss: 0.5882 (0.8724)  Acc@1: 93.7500 (85.6354)  Acc@5: 100.0000 (97.5752)  time: 0.2157  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 790/1627]  eta: 0:03:01  Loss: 0.6958 (0.8747)  Acc@1: 87.5000 (85.5800)  Acc@5: 100.0000 (97.5585)  time: 0.2167  data: 0.0010  max mem: 2500
Test: [Task 1]  [ 800/1627]  eta: 0:02:59  Loss: 0.7554 (0.8735)  Acc@1: 87.5000 (85.6273)  Acc@5: 100.0000 (97.5811)  time: 0.2168  data: 0.0009  max mem: 2500
Test: [Task 1]  [ 810/1627]  eta: 0:02:57  Loss: 0.7495 (0.8730)  Acc@1: 87.5000 (85.6736)  Acc@5: 100.0000 (97.5879)  time: 0.2178  data: 0.0010  max mem: 2500
Test: [Task 1]  [ 820/1627]  eta: 0:02:55  Loss: 0.7346 (0.8717)  Acc@1: 87.5000 (85.7339)  Acc@5: 100.0000 (97.5944)  time: 0.2225  data: 0.0021  max mem: 2500
Test: [Task 1]  [ 830/1627]  eta: 0:02:52  Loss: 0.7123 (0.8716)  Acc@1: 87.5000 (85.7476)  Acc@5: 100.0000 (97.6008)  time: 0.2221  data: 0.0025  max mem: 2500
Test: [Task 1]  [ 840/1627]  eta: 0:02:50  Loss: 0.7000 (0.8695)  Acc@1: 87.5000 (85.8130)  Acc@5: 100.0000 (97.6219)  time: 0.2181  data: 0.0016  max mem: 2500
Test: [Task 1]  [ 850/1627]  eta: 0:02:48  Loss: 0.7657 (0.8705)  Acc@1: 87.5000 (85.7961)  Acc@5: 100.0000 (97.6351)  time: 0.2168  data: 0.0006  max mem: 2500
Test: [Task 1]  [ 860/1627]  eta: 0:02:46  Loss: 0.7541 (0.8697)  Acc@1: 87.5000 (85.8449)  Acc@5: 100.0000 (97.6553)  time: 0.2162  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 870/1627]  eta: 0:02:44  Loss: 0.7362 (0.8681)  Acc@1: 87.5000 (85.8568)  Acc@5: 100.0000 (97.6607)  time: 0.2163  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 880/1627]  eta: 0:02:42  Loss: 0.8526 (0.8695)  Acc@1: 87.5000 (85.8400)  Acc@5: 100.0000 (97.6802)  time: 0.2160  data: 0.0005  max mem: 2500
Test: [Task 1]  [ 890/1627]  eta: 0:02:39  Loss: 0.9195 (0.8710)  Acc@1: 87.5000 (85.8446)  Acc@5: 100.0000 (97.6641)  time: 0.2160  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 900/1627]  eta: 0:02:37  Loss: 0.8126 (0.8714)  Acc@1: 87.5000 (85.8352)  Acc@5: 100.0000 (97.6554)  time: 0.2168  data: 0.0005  max mem: 2500
Test: [Task 1]  [ 910/1627]  eta: 0:02:35  Loss: 0.8407 (0.8720)  Acc@1: 87.5000 (85.8672)  Acc@5: 93.7500 (97.6262)  time: 0.2171  data: 0.0006  max mem: 2500
Test: [Task 1]  [ 920/1627]  eta: 0:02:33  Loss: 0.7971 (0.8712)  Acc@1: 87.5000 (85.8849)  Acc@5: 100.0000 (97.6249)  time: 0.2175  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 930/1627]  eta: 0:02:31  Loss: 0.7910 (0.8711)  Acc@1: 87.5000 (85.8821)  Acc@5: 100.0000 (97.6302)  time: 0.2165  data: 0.0005  max mem: 2500
Test: [Task 1]  [ 940/1627]  eta: 0:02:29  Loss: 0.7961 (0.8700)  Acc@1: 87.5000 (85.9126)  Acc@5: 100.0000 (97.6421)  time: 0.2166  data: 0.0011  max mem: 2500
Test: [Task 1]  [ 950/1627]  eta: 0:02:26  Loss: 0.8591 (0.8707)  Acc@1: 81.2500 (85.8504)  Acc@5: 100.0000 (97.6538)  time: 0.2168  data: 0.0010  max mem: 2500
Test: [Task 1]  [ 960/1627]  eta: 0:02:24  Loss: 0.8946 (0.8705)  Acc@1: 81.2500 (85.8156)  Acc@5: 100.0000 (97.6522)  time: 0.2152  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 970/1627]  eta: 0:02:22  Loss: 0.7362 (0.8696)  Acc@1: 87.5000 (85.8200)  Acc@5: 100.0000 (97.6571)  time: 0.2158  data: 0.0005  max mem: 2500
Test: [Task 1]  [ 980/1627]  eta: 0:02:20  Loss: 0.8187 (0.8701)  Acc@1: 87.5000 (85.8180)  Acc@5: 100.0000 (97.6363)  time: 0.2186  data: 0.0014  max mem: 2500
Test: [Task 1]  [ 990/1627]  eta: 0:02:18  Loss: 1.0279 (0.8724)  Acc@1: 87.5000 (85.8035)  Acc@5: 93.7500 (97.6350)  time: 0.2177  data: 0.0012  max mem: 2500
Test: [Task 1]  [1000/1627]  eta: 0:02:16  Loss: 1.0479 (0.8732)  Acc@1: 81.2500 (85.7892)  Acc@5: 100.0000 (97.6274)  time: 0.2154  data: 0.0006  max mem: 2500
Test: [Task 1]  [1010/1627]  eta: 0:02:13  Loss: 0.9223 (0.8733)  Acc@1: 87.5000 (85.7690)  Acc@5: 100.0000 (97.6137)  time: 0.2167  data: 0.0008  max mem: 2500
Test: [Task 1]  [1020/1627]  eta: 0:02:11  Loss: 0.8569 (0.8732)  Acc@1: 87.5000 (85.7676)  Acc@5: 100.0000 (97.6126)  time: 0.2173  data: 0.0006  max mem: 2500
Test: [Task 1]  [1030/1627]  eta: 0:02:09  Loss: 0.7225 (0.8711)  Acc@1: 87.5000 (85.8147)  Acc@5: 100.0000 (97.6297)  time: 0.2168  data: 0.0005  max mem: 2500
Test: [Task 1]  [1040/1627]  eta: 0:02:07  Loss: 0.6321 (0.8701)  Acc@1: 87.5000 (85.8069)  Acc@5: 100.0000 (97.6465)  time: 0.2162  data: 0.0004  max mem: 2500
Test: [Task 1]  [1050/1627]  eta: 0:02:05  Loss: 0.7142 (0.8689)  Acc@1: 87.5000 (85.8111)  Acc@5: 100.0000 (97.6451)  time: 0.2163  data: 0.0007  max mem: 2500
Test: [Task 1]  [1060/1627]  eta: 0:02:03  Loss: 0.7766 (0.8696)  Acc@1: 81.2500 (85.7799)  Acc@5: 93.7500 (97.6261)  time: 0.2172  data: 0.0007  max mem: 2500
Test: [Task 1]  [1070/1627]  eta: 0:02:00  Loss: 0.8764 (0.8703)  Acc@1: 87.5000 (85.7901)  Acc@5: 100.0000 (97.6190)  time: 0.2172  data: 0.0004  max mem: 2500
Test: [Task 1]  [1080/1627]  eta: 0:01:58  Loss: 0.8428 (0.8705)  Acc@1: 87.5000 (85.7886)  Acc@5: 100.0000 (97.6064)  time: 0.2158  data: 0.0003  max mem: 2500
Test: [Task 1]  [1090/1627]  eta: 0:01:56  Loss: 0.7688 (0.8703)  Acc@1: 87.5000 (85.8100)  Acc@5: 100.0000 (97.6111)  time: 0.2156  data: 0.0007  max mem: 2500
Test: [Task 1]  [1100/1627]  eta: 0:01:54  Loss: 0.7650 (0.8690)  Acc@1: 87.5000 (85.8311)  Acc@5: 100.0000 (97.6215)  time: 0.2159  data: 0.0008  max mem: 2500
Test: [Task 1]  [1110/1627]  eta: 0:01:52  Loss: 0.8106 (0.8695)  Acc@1: 87.5000 (85.8292)  Acc@5: 100.0000 (97.6148)  time: 0.2154  data: 0.0004  max mem: 2500
Test: [Task 1]  [1120/1627]  eta: 0:01:49  Loss: 0.8357 (0.8705)  Acc@1: 87.5000 (85.7939)  Acc@5: 100.0000 (97.6249)  time: 0.2156  data: 0.0005  max mem: 2500
Test: [Task 1]  [1130/1627]  eta: 0:01:47  Loss: 0.8936 (0.8705)  Acc@1: 87.5000 (85.7980)  Acc@5: 100.0000 (97.6238)  time: 0.2173  data: 0.0014  max mem: 2500
Test: [Task 1]  [1140/1627]  eta: 0:01:45  Loss: 0.9079 (0.8715)  Acc@1: 87.5000 (85.8184)  Acc@5: 100.0000 (97.6227)  time: 0.2177  data: 0.0014  max mem: 2500
Test: [Task 1]  [1150/1627]  eta: 0:01:43  Loss: 0.9691 (0.8724)  Acc@1: 81.2500 (85.7678)  Acc@5: 100.0000 (97.6162)  time: 0.2181  data: 0.0006  max mem: 2500
Test: [Task 1]  [1160/1627]  eta: 0:01:41  Loss: 0.9565 (0.8716)  Acc@1: 81.2500 (85.8096)  Acc@5: 100.0000 (97.6260)  time: 0.2178  data: 0.0005  max mem: 2500
Test: [Task 1]  [1170/1627]  eta: 0:01:39  Loss: 0.8853 (0.8709)  Acc@1: 93.7500 (85.8454)  Acc@5: 100.0000 (97.6356)  time: 0.2165  data: 0.0004  max mem: 2500
Test: [Task 1]  [1180/1627]  eta: 0:01:36  Loss: 0.8833 (0.8716)  Acc@1: 87.5000 (85.8383)  Acc@5: 100.0000 (97.6450)  time: 0.2169  data: 0.0004  max mem: 2500
Test: [Task 1]  [1190/1627]  eta: 0:01:34  Loss: 0.8833 (0.8718)  Acc@1: 87.5000 (85.8470)  Acc@5: 100.0000 (97.6543)  time: 0.2174  data: 0.0005  max mem: 2500
Test: [Task 1]  [1200/1627]  eta: 0:01:32  Loss: 0.8748 (0.8719)  Acc@1: 87.5000 (85.8503)  Acc@5: 100.0000 (97.6426)  time: 0.2181  data: 0.0014  max mem: 2500
Test: [Task 1]  [1210/1627]  eta: 0:01:30  Loss: 0.7739 (0.8725)  Acc@1: 87.5000 (85.8278)  Acc@5: 100.0000 (97.6414)  time: 0.2170  data: 0.0014  max mem: 2500
Test: [Task 1]  [1220/1627]  eta: 0:01:28  Loss: 0.7553 (0.8717)  Acc@1: 87.5000 (85.8057)  Acc@5: 100.0000 (97.6556)  time: 0.2160  data: 0.0004  max mem: 2500
Test: [Task 1]  [1230/1627]  eta: 0:01:26  Loss: 0.8679 (0.8722)  Acc@1: 81.2500 (85.7738)  Acc@5: 100.0000 (97.6594)  time: 0.2158  data: 0.0004  max mem: 2500
Test: [Task 1]  [1240/1627]  eta: 0:01:23  Loss: 0.8334 (0.8713)  Acc@1: 87.5000 (85.7927)  Acc@5: 100.0000 (97.6682)  time: 0.2149  data: 0.0004  max mem: 2500
Test: [Task 1]  [1250/1627]  eta: 0:01:21  Loss: 0.8234 (0.8715)  Acc@1: 87.5000 (85.8163)  Acc@5: 100.0000 (97.6769)  time: 0.2154  data: 0.0004  max mem: 2500
Test: [Task 1]  [1260/1627]  eta: 0:01:19  Loss: 0.8572 (0.8713)  Acc@1: 87.5000 (85.8247)  Acc@5: 100.0000 (97.6705)  time: 0.2155  data: 0.0004  max mem: 2500
Test: [Task 1]  [1270/1627]  eta: 0:01:17  Loss: 0.8236 (0.8719)  Acc@1: 81.2500 (85.7986)  Acc@5: 100.0000 (97.6790)  time: 0.2160  data: 0.0004  max mem: 2500
Test: [Task 1]  [1280/1627]  eta: 0:01:15  Loss: 0.6919 (0.8702)  Acc@1: 81.2500 (85.8070)  Acc@5: 100.0000 (97.6971)  time: 0.2183  data: 0.0013  max mem: 2500
Test: [Task 1]  [1290/1627]  eta: 0:01:13  Loss: 0.6919 (0.8703)  Acc@1: 87.5000 (85.7959)  Acc@5: 100.0000 (97.7053)  time: 0.2186  data: 0.0022  max mem: 2500
Test: [Task 1]  [1300/1627]  eta: 0:01:10  Loss: 0.8993 (0.8699)  Acc@1: 81.2500 (85.8090)  Acc@5: 100.0000 (97.7037)  time: 0.2175  data: 0.0015  max mem: 2500
Test: [Task 1]  [1310/1627]  eta: 0:01:08  Loss: 0.6793 (0.8685)  Acc@1: 87.5000 (85.8314)  Acc@5: 100.0000 (97.7069)  time: 0.2174  data: 0.0006  max mem: 2500
Test: [Task 1]  [1320/1627]  eta: 0:01:06  Loss: 0.6347 (0.8670)  Acc@1: 87.5000 (85.8630)  Acc@5: 100.0000 (97.7101)  time: 0.2170  data: 0.0005  max mem: 2500
Test: [Task 1]  [1330/1627]  eta: 0:01:04  Loss: 0.6506 (0.8670)  Acc@1: 87.5000 (85.8518)  Acc@5: 100.0000 (97.7226)  time: 0.2165  data: 0.0004  max mem: 2500
Test: [Task 1]  [1340/1627]  eta: 0:01:02  Loss: 0.8357 (0.8677)  Acc@1: 81.2500 (85.8315)  Acc@5: 100.0000 (97.7209)  time: 0.2160  data: 0.0004  max mem: 2500
Test: [Task 1]  [1350/1627]  eta: 0:01:00  Loss: 0.7675 (0.8671)  Acc@1: 87.5000 (85.8392)  Acc@5: 100.0000 (97.7285)  time: 0.2161  data: 0.0004  max mem: 2500
Test: [Task 1]  [1360/1627]  eta: 0:00:57  Loss: 0.7639 (0.8666)  Acc@1: 87.5000 (85.8560)  Acc@5: 100.0000 (97.7360)  time: 0.2164  data: 0.0004  max mem: 2500
Test: [Task 1]  [1370/1627]  eta: 0:00:55  Loss: 0.7639 (0.8656)  Acc@1: 87.5000 (85.8634)  Acc@5: 100.0000 (97.7434)  time: 0.2161  data: 0.0003  max mem: 2500
Test: [Task 1]  [1380/1627]  eta: 0:00:53  Loss: 0.8205 (0.8657)  Acc@1: 81.2500 (85.8391)  Acc@5: 100.0000 (97.7462)  time: 0.2159  data: 0.0004  max mem: 2500
Test: [Task 1]  [1390/1627]  eta: 0:00:51  Loss: 0.9204 (0.8650)  Acc@1: 81.2500 (85.8375)  Acc@5: 100.0000 (97.7534)  time: 0.2165  data: 0.0004  max mem: 2500
Test: [Task 1]  [1400/1627]  eta: 0:00:49  Loss: 0.6965 (0.8655)  Acc@1: 81.2500 (85.8048)  Acc@5: 100.0000 (97.7471)  time: 0.2168  data: 0.0004  max mem: 2500
Test: [Task 1]  [1410/1627]  eta: 0:00:47  Loss: 0.7274 (0.8650)  Acc@1: 87.5000 (85.8301)  Acc@5: 100.0000 (97.7543)  time: 0.2159  data: 0.0004  max mem: 2500
Test: [Task 1]  [1420/1627]  eta: 0:00:44  Loss: 0.7637 (0.8647)  Acc@1: 87.5000 (85.8418)  Acc@5: 100.0000 (97.7657)  time: 0.2167  data: 0.0006  max mem: 2500
Test: [Task 1]  [1430/1627]  eta: 0:00:42  Loss: 0.9851 (0.8666)  Acc@1: 81.2500 (85.7923)  Acc@5: 100.0000 (97.7376)  time: 0.2183  data: 0.0009  max mem: 2500
Test: [Task 1]  [1440/1627]  eta: 0:00:40  Loss: 0.8775 (0.8663)  Acc@1: 81.2500 (85.7781)  Acc@5: 100.0000 (97.7446)  time: 0.2180  data: 0.0008  max mem: 2500
Test: [Task 1]  [1450/1627]  eta: 0:00:38  Loss: 0.8775 (0.8675)  Acc@1: 81.2500 (85.7641)  Acc@5: 100.0000 (97.7386)  time: 0.2181  data: 0.0020  max mem: 2500
Test: [Task 1]  [1460/1627]  eta: 0:00:36  Loss: 0.9945 (0.8678)  Acc@1: 81.2500 (85.7461)  Acc@5: 100.0000 (97.7327)  time: 0.2179  data: 0.0021  max mem: 2500
Test: [Task 1]  [1470/1627]  eta: 0:00:34  Loss: 0.8335 (0.8681)  Acc@1: 81.2500 (85.7452)  Acc@5: 100.0000 (97.7226)  time: 0.2184  data: 0.0023  max mem: 2500
Test: [Task 1]  [1480/1627]  eta: 0:00:31  Loss: 0.9155 (0.8685)  Acc@1: 87.5000 (85.7698)  Acc@5: 100.0000 (97.7085)  time: 0.2182  data: 0.0023  max mem: 2500
Test: [Task 1]  [1490/1627]  eta: 0:00:29  Loss: 1.0005 (0.8690)  Acc@1: 87.5000 (85.7730)  Acc@5: 100.0000 (97.7071)  time: 0.2177  data: 0.0007  max mem: 2500
Test: [Task 1]  [1500/1627]  eta: 0:00:27  Loss: 0.9784 (0.8694)  Acc@1: 87.5000 (85.7678)  Acc@5: 93.7500 (97.6890)  time: 0.2191  data: 0.0012  max mem: 2500
Test: [Task 1]  [1510/1627]  eta: 0:00:25  Loss: 0.7682 (0.8695)  Acc@1: 87.5000 (85.7751)  Acc@5: 93.7500 (97.6795)  time: 0.2185  data: 0.0016  max mem: 2500
Test: [Task 1]  [1520/1627]  eta: 0:00:23  Loss: 0.6917 (0.8683)  Acc@1: 87.5000 (85.8029)  Acc@5: 100.0000 (97.6824)  time: 0.2161  data: 0.0008  max mem: 2500
Test: [Task 1]  [1530/1627]  eta: 0:00:21  Loss: 0.6742 (0.8678)  Acc@1: 87.5000 (85.8018)  Acc@5: 100.0000 (97.6813)  time: 0.2156  data: 0.0004  max mem: 2500
Test: [Task 1]  [1540/1627]  eta: 0:00:18  Loss: 0.6553 (0.8666)  Acc@1: 87.5000 (85.8209)  Acc@5: 100.0000 (97.6922)  time: 0.2168  data: 0.0005  max mem: 2500
Test: [Task 1]  [1550/1627]  eta: 0:00:16  Loss: 0.6261 (0.8660)  Acc@1: 87.5000 (85.8438)  Acc@5: 100.0000 (97.6950)  time: 0.2177  data: 0.0006  max mem: 2500
Test: [Task 1]  [1560/1627]  eta: 0:00:14  Loss: 0.6320 (0.8653)  Acc@1: 87.5000 (85.8544)  Acc@5: 100.0000 (97.6978)  time: 0.2179  data: 0.0005  max mem: 2500
Test: [Task 1]  [1570/1627]  eta: 0:00:12  Loss: 0.6964 (0.8654)  Acc@1: 87.5000 (85.8768)  Acc@5: 100.0000 (97.6886)  time: 0.2160  data: 0.0004  max mem: 2500
Test: [Task 1]  [1580/1627]  eta: 0:00:10  Loss: 0.8388 (0.8655)  Acc@1: 87.5000 (85.8752)  Acc@5: 100.0000 (97.6874)  time: 0.2160  data: 0.0005  max mem: 2500
Test: [Task 1]  [1590/1627]  eta: 0:00:08  Loss: 0.8083 (0.8653)  Acc@1: 87.5000 (85.8697)  Acc@5: 100.0000 (97.6901)  time: 0.2172  data: 0.0009  max mem: 2500
Test: [Task 1]  [1600/1627]  eta: 0:00:05  Loss: 0.8425 (0.8661)  Acc@1: 81.2500 (85.8409)  Acc@5: 100.0000 (97.6850)  time: 0.2180  data: 0.0017  max mem: 2500
Test: [Task 1]  [1610/1627]  eta: 0:00:03  Loss: 0.8413 (0.8658)  Acc@1: 87.5000 (85.8589)  Acc@5: 100.0000 (97.6917)  time: 0.2185  data: 0.0027  max mem: 2500
Test: [Task 1]  [1620/1627]  eta: 0:00:01  Loss: 0.7747 (0.8650)  Acc@1: 87.5000 (85.8691)  Acc@5: 100.0000 (97.6905)  time: 0.2176  data: 0.0018  max mem: 2500
Test: [Task 1]  [1626/1627]  eta: 0:00:00  Loss: 0.8010 (0.8646)  Acc@1: 87.5000 (85.8789)  Acc@5: 100.0000 (97.6836)  time: 0.2170  data: 0.0004  max mem: 2500
Test: [Task 1] Total time: 0:05:53 (0.2172 s / it)
* Acc@1 85.879 Acc@5 97.684 loss 0.865
{0: {0: 26032, 1: 26032, 2: 26032, 3: 26032, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0, 10: 0, 11: 0, 12: 0, 13: 0, 14: 0, 15: 0, 16: 0, 17: 0, 18: 0, 19: 0}}
[Average accuracy till task1]	Acc@1: 85.8789	Acc@5: 97.6836	Loss: 0.8646
Transfering parameters  (slice(4, 8, None), slice(0, 4, None))
Train: Epoch[1/5]  [   0/3750]  eta: 0:56:35  Lr: 0.001875  Loss: 0.7955  Acc@1: 25.0000 (25.0000)  Acc@5: 43.7500 (43.7500)  time: 0.9055  data: 0.5394  max mem: 2500
Train: Epoch[1/5]  [  10/3750]  eta: 0:24:48  Lr: 0.001875  Loss: 0.6299  Acc@1: 25.0000 (25.5682)  Acc@5: 62.5000 (61.3636)  time: 0.3980  data: 0.0501  max mem: 2500
Train: Epoch[1/5]  [  20/3750]  eta: 0:23:10  Lr: 0.001875  Loss: 0.5389  Acc@1: 25.0000 (26.7857)  Acc@5: 68.7500 (66.6667)  time: 0.3462  data: 0.0009  max mem: 2500
Train: Epoch[1/5]  [  30/3750]  eta: 0:22:36  Lr: 0.001875  Loss: 0.4527  Acc@1: 37.5000 (32.4597)  Acc@5: 75.0000 (72.3790)  time: 0.3461  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [  40/3750]  eta: 0:22:17  Lr: 0.001875  Loss: 0.4660  Acc@1: 50.0000 (38.5671)  Acc@5: 87.5000 (77.1341)  time: 0.3474  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [  50/3750]  eta: 0:22:03  Lr: 0.001875  Loss: 0.1333  Acc@1: 56.2500 (42.4020)  Acc@5: 93.7500 (79.6569)  time: 0.3469  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [  60/3750]  eta: 0:21:53  Lr: 0.001875  Loss: -0.0659  Acc@1: 56.2500 (45.1844)  Acc@5: 93.7500 (81.8648)  time: 0.3468  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [  70/3750]  eta: 0:21:45  Lr: 0.001875  Loss: 0.5663  Acc@1: 56.2500 (46.6549)  Acc@5: 93.7500 (83.5387)  time: 0.3471  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [  80/3750]  eta: 0:21:38  Lr: 0.001875  Loss: -0.5675  Acc@1: 62.5000 (48.9969)  Acc@5: 93.7500 (85.0309)  time: 0.3468  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [  90/3750]  eta: 0:21:31  Lr: 0.001875  Loss: -0.0181  Acc@1: 62.5000 (51.0989)  Acc@5: 93.7500 (85.7830)  time: 0.3471  data: 0.0013  max mem: 2500
Train: Epoch[1/5]  [ 100/3750]  eta: 0:21:26  Lr: 0.001875  Loss: -0.2460  Acc@1: 68.7500 (53.1559)  Acc@5: 93.7500 (87.0050)  time: 0.3478  data: 0.0013  max mem: 2500
Train: Epoch[1/5]  [ 110/3750]  eta: 0:21:21  Lr: 0.001875  Loss: -0.1246  Acc@1: 75.0000 (55.1802)  Acc@5: 100.0000 (87.6689)  time: 0.3473  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [ 120/3750]  eta: 0:21:16  Lr: 0.001875  Loss: -0.3410  Acc@1: 75.0000 (56.5083)  Acc@5: 93.7500 (88.0165)  time: 0.3467  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 130/3750]  eta: 0:21:11  Lr: 0.001875  Loss: -0.2513  Acc@1: 68.7500 (57.3950)  Acc@5: 93.7500 (88.4542)  time: 0.3466  data: 0.0010  max mem: 2500
Train: Epoch[1/5]  [ 140/3750]  eta: 0:21:06  Lr: 0.001875  Loss: -0.5260  Acc@1: 68.7500 (58.2890)  Acc@5: 93.7500 (88.8741)  time: 0.3463  data: 0.0011  max mem: 2500
Train: Epoch[1/5]  [ 150/3750]  eta: 0:21:02  Lr: 0.001875  Loss: -0.1167  Acc@1: 68.7500 (59.0232)  Acc@5: 93.7500 (89.2798)  time: 0.3476  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [ 160/3750]  eta: 0:20:58  Lr: 0.001875  Loss: -0.4141  Acc@1: 68.7500 (59.6661)  Acc@5: 100.0000 (89.7904)  time: 0.3483  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [ 170/3750]  eta: 0:20:53  Lr: 0.001875  Loss: -0.1167  Acc@1: 68.7500 (60.2339)  Acc@5: 93.7500 (90.0950)  time: 0.3471  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [ 180/3750]  eta: 0:20:49  Lr: 0.001875  Loss: -0.4390  Acc@1: 75.0000 (61.0497)  Acc@5: 93.7500 (90.2970)  time: 0.3463  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [ 190/3750]  eta: 0:20:45  Lr: 0.001875  Loss: -0.1447  Acc@1: 68.7500 (61.3220)  Acc@5: 93.7500 (90.3469)  time: 0.3464  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [ 200/3750]  eta: 0:20:41  Lr: 0.001875  Loss: -0.5534  Acc@1: 68.7500 (61.8470)  Acc@5: 93.7500 (90.6716)  time: 0.3478  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [ 210/3750]  eta: 0:20:38  Lr: 0.001875  Loss: -0.6245  Acc@1: 75.0000 (62.4408)  Acc@5: 100.0000 (90.8175)  time: 0.3492  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [ 220/3750]  eta: 0:20:34  Lr: 0.001875  Loss: -0.2969  Acc@1: 75.0000 (62.9808)  Acc@5: 93.7500 (90.9785)  time: 0.3474  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [ 230/3750]  eta: 0:20:30  Lr: 0.001875  Loss: -0.2672  Acc@1: 68.7500 (63.2576)  Acc@5: 93.7500 (91.0985)  time: 0.3458  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [ 240/3750]  eta: 0:20:26  Lr: 0.001875  Loss: -0.0744  Acc@1: 68.7500 (63.5892)  Acc@5: 93.7500 (91.2604)  time: 0.3470  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [ 250/3750]  eta: 0:20:22  Lr: 0.001875  Loss: -0.5154  Acc@1: 75.0000 (64.1185)  Acc@5: 93.7500 (91.2600)  time: 0.3488  data: 0.0014  max mem: 2500
Train: Epoch[1/5]  [ 260/3750]  eta: 0:20:19  Lr: 0.001875  Loss: -0.6627  Acc@1: 81.2500 (64.6552)  Acc@5: 93.7500 (91.4033)  time: 0.3489  data: 0.0019  max mem: 2500
Train: Epoch[1/5]  [ 270/3750]  eta: 0:20:15  Lr: 0.001875  Loss: -0.8414  Acc@1: 75.0000 (65.1061)  Acc@5: 100.0000 (91.6282)  time: 0.3476  data: 0.0014  max mem: 2500
Train: Epoch[1/5]  [ 280/3750]  eta: 0:20:11  Lr: 0.001875  Loss: -0.1302  Acc@1: 75.0000 (65.2802)  Acc@5: 100.0000 (91.7037)  time: 0.3481  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [ 290/3750]  eta: 0:20:08  Lr: 0.001875  Loss: -0.3918  Acc@1: 75.0000 (65.5928)  Acc@5: 93.7500 (91.7741)  time: 0.3480  data: 0.0014  max mem: 2500
Train: Epoch[1/5]  [ 300/3750]  eta: 0:20:04  Lr: 0.001875  Loss: -0.6559  Acc@1: 75.0000 (65.9261)  Acc@5: 93.7500 (91.8189)  time: 0.3478  data: 0.0020  max mem: 2500
Train: Epoch[1/5]  [ 310/3750]  eta: 0:20:01  Lr: 0.001875  Loss: -0.7482  Acc@1: 75.0000 (66.1977)  Acc@5: 93.7500 (91.9212)  time: 0.3486  data: 0.0018  max mem: 2500
Train: Epoch[1/5]  [ 320/3750]  eta: 0:19:57  Lr: 0.001875  Loss: -0.5544  Acc@1: 75.0000 (66.5109)  Acc@5: 93.7500 (92.0755)  time: 0.3485  data: 0.0013  max mem: 2500
Train: Epoch[1/5]  [ 330/3750]  eta: 0:19:53  Lr: 0.001875  Loss: -0.5506  Acc@1: 75.0000 (66.5974)  Acc@5: 93.7500 (92.2205)  time: 0.3487  data: 0.0010  max mem: 2500
Train: Epoch[1/5]  [ 340/3750]  eta: 0:19:50  Lr: 0.001875  Loss: -0.6818  Acc@1: 75.0000 (66.9721)  Acc@5: 93.7500 (92.3204)  time: 0.3485  data: 0.0010  max mem: 2500
Train: Epoch[1/5]  [ 350/3750]  eta: 0:19:46  Lr: 0.001875  Loss: -0.2662  Acc@1: 75.0000 (67.0584)  Acc@5: 93.7500 (92.3611)  time: 0.3490  data: 0.0013  max mem: 2500
Train: Epoch[1/5]  [ 360/3750]  eta: 0:19:43  Lr: 0.001875  Loss: 0.1015  Acc@1: 68.7500 (67.2784)  Acc@5: 93.7500 (92.4515)  time: 0.3491  data: 0.0013  max mem: 2500
Train: Epoch[1/5]  [ 370/3750]  eta: 0:19:39  Lr: 0.001875  Loss: -0.2795  Acc@1: 75.0000 (67.5202)  Acc@5: 93.7500 (92.4528)  time: 0.3475  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [ 380/3750]  eta: 0:19:35  Lr: 0.001875  Loss: -0.9636  Acc@1: 75.0000 (67.7822)  Acc@5: 93.7500 (92.6181)  time: 0.3462  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [ 390/3750]  eta: 0:19:32  Lr: 0.001875  Loss: -1.1565  Acc@1: 81.2500 (67.9348)  Acc@5: 100.0000 (92.6151)  time: 0.3465  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [ 400/3750]  eta: 0:19:28  Lr: 0.001875  Loss: -0.2439  Acc@1: 75.0000 (68.0798)  Acc@5: 93.7500 (92.6746)  time: 0.3473  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [ 410/3750]  eta: 0:19:24  Lr: 0.001875  Loss: -0.2839  Acc@1: 68.7500 (68.1873)  Acc@5: 93.7500 (92.7464)  time: 0.3465  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [ 420/3750]  eta: 0:19:21  Lr: 0.001875  Loss: -0.7085  Acc@1: 75.0000 (68.3640)  Acc@5: 93.7500 (92.8147)  time: 0.3452  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [ 430/3750]  eta: 0:19:17  Lr: 0.001875  Loss: -0.5952  Acc@1: 75.0000 (68.3295)  Acc@5: 93.7500 (92.7784)  time: 0.3461  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 440/3750]  eta: 0:19:13  Lr: 0.001875  Loss: -0.8611  Acc@1: 75.0000 (68.4807)  Acc@5: 93.7500 (92.8146)  time: 0.3467  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [ 450/3750]  eta: 0:19:10  Lr: 0.001875  Loss: -0.9631  Acc@1: 75.0000 (68.6114)  Acc@5: 93.7500 (92.8908)  time: 0.3469  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [ 460/3750]  eta: 0:19:06  Lr: 0.001875  Loss: -0.7394  Acc@1: 75.0000 (68.8042)  Acc@5: 93.7500 (92.9637)  time: 0.3494  data: 0.0013  max mem: 2500
Train: Epoch[1/5]  [ 470/3750]  eta: 0:19:03  Lr: 0.001875  Loss: -0.2926  Acc@1: 75.0000 (68.8960)  Acc@5: 93.7500 (92.9538)  time: 0.3489  data: 0.0012  max mem: 2500
Train: Epoch[1/5]  [ 480/3750]  eta: 0:18:59  Lr: 0.001875  Loss: -0.2523  Acc@1: 81.2500 (69.1528)  Acc@5: 93.7500 (93.0094)  time: 0.3473  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [ 490/3750]  eta: 0:18:56  Lr: 0.001875  Loss: -0.2010  Acc@1: 81.2500 (69.2592)  Acc@5: 100.0000 (93.1008)  time: 0.3486  data: 0.0010  max mem: 2500
Train: Epoch[1/5]  [ 500/3750]  eta: 0:18:52  Lr: 0.001875  Loss: -0.8861  Acc@1: 68.7500 (69.2615)  Acc@5: 100.0000 (93.1512)  time: 0.3483  data: 0.0018  max mem: 2500
Train: Epoch[1/5]  [ 510/3750]  eta: 0:18:49  Lr: 0.001875  Loss: -0.7383  Acc@1: 75.0000 (69.4227)  Acc@5: 93.7500 (93.2241)  time: 0.3465  data: 0.0012  max mem: 2500
Train: Epoch[1/5]  [ 520/3750]  eta: 0:18:45  Lr: 0.001875  Loss: -0.7406  Acc@1: 81.2500 (69.5777)  Acc@5: 93.7500 (93.2342)  time: 0.3454  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [ 530/3750]  eta: 0:18:41  Lr: 0.001875  Loss: -0.6434  Acc@1: 75.0000 (69.7269)  Acc@5: 93.7500 (93.2792)  time: 0.3464  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [ 540/3750]  eta: 0:18:38  Lr: 0.001875  Loss: -0.2211  Acc@1: 75.0000 (69.8013)  Acc@5: 93.7500 (93.3341)  time: 0.3472  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [ 550/3750]  eta: 0:18:34  Lr: 0.001875  Loss: -0.9381  Acc@1: 68.7500 (69.7368)  Acc@5: 93.7500 (93.3076)  time: 0.3466  data: 0.0013  max mem: 2500
Train: Epoch[1/5]  [ 560/3750]  eta: 0:18:31  Lr: 0.001875  Loss: -0.4907  Acc@1: 68.7500 (69.8418)  Acc@5: 93.7500 (93.3601)  time: 0.3475  data: 0.0013  max mem: 2500
Train: Epoch[1/5]  [ 570/3750]  eta: 0:18:27  Lr: 0.001875  Loss: -0.8535  Acc@1: 75.0000 (69.9212)  Acc@5: 100.0000 (93.4216)  time: 0.3473  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [ 580/3750]  eta: 0:18:24  Lr: 0.001875  Loss: -0.1422  Acc@1: 75.0000 (69.9548)  Acc@5: 100.0000 (93.4596)  time: 0.3464  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [ 590/3750]  eta: 0:18:20  Lr: 0.001875  Loss: -0.5153  Acc@1: 75.0000 (70.1248)  Acc@5: 93.7500 (93.4750)  time: 0.3477  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [ 600/3750]  eta: 0:18:17  Lr: 0.001875  Loss: -0.8550  Acc@1: 75.0000 (70.1539)  Acc@5: 93.7500 (93.4796)  time: 0.3473  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [ 610/3750]  eta: 0:18:13  Lr: 0.001875  Loss: -0.8277  Acc@1: 68.7500 (70.1616)  Acc@5: 93.7500 (93.4943)  time: 0.3459  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [ 620/3750]  eta: 0:18:09  Lr: 0.001875  Loss: -0.6043  Acc@1: 68.7500 (70.1791)  Acc@5: 93.7500 (93.5085)  time: 0.3472  data: 0.0016  max mem: 2500
Train: Epoch[1/5]  [ 630/3750]  eta: 0:18:06  Lr: 0.001875  Loss: -0.5683  Acc@1: 75.0000 (70.2754)  Acc@5: 93.7500 (93.5222)  time: 0.3474  data: 0.0015  max mem: 2500
Train: Epoch[1/5]  [ 640/3750]  eta: 0:18:02  Lr: 0.001875  Loss: -0.5415  Acc@1: 75.0000 (70.2321)  Acc@5: 93.7500 (93.4867)  time: 0.3474  data: 0.0013  max mem: 2500
Train: Epoch[1/5]  [ 650/3750]  eta: 0:17:59  Lr: 0.001875  Loss: -0.5105  Acc@1: 75.0000 (70.2861)  Acc@5: 87.5000 (93.4812)  time: 0.3471  data: 0.0014  max mem: 2500
Train: Epoch[1/5]  [ 660/3750]  eta: 0:17:55  Lr: 0.001875  Loss: -0.5286  Acc@1: 75.0000 (70.4331)  Acc@5: 100.0000 (93.5609)  time: 0.3467  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [ 670/3750]  eta: 0:17:52  Lr: 0.001875  Loss: -0.7612  Acc@1: 75.0000 (70.4825)  Acc@5: 100.0000 (93.6196)  time: 0.3461  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 680/3750]  eta: 0:17:48  Lr: 0.001875  Loss: -0.5412  Acc@1: 75.0000 (70.5305)  Acc@5: 93.7500 (93.6490)  time: 0.3462  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 690/3750]  eta: 0:17:45  Lr: 0.001875  Loss: -0.6396  Acc@1: 68.7500 (70.5680)  Acc@5: 93.7500 (93.6686)  time: 0.3466  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 700/3750]  eta: 0:17:41  Lr: 0.001875  Loss: -0.7399  Acc@1: 75.0000 (70.6491)  Acc@5: 93.7500 (93.6787)  time: 0.3464  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 710/3750]  eta: 0:17:38  Lr: 0.001875  Loss: -0.6684  Acc@1: 75.0000 (70.8070)  Acc@5: 100.0000 (93.7324)  time: 0.3489  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [ 720/3750]  eta: 0:17:34  Lr: 0.001875  Loss: -0.5832  Acc@1: 75.0000 (70.8044)  Acc@5: 100.0000 (93.7327)  time: 0.3482  data: 0.0013  max mem: 2500
Train: Epoch[1/5]  [ 730/3750]  eta: 0:17:31  Lr: 0.001875  Loss: -1.1188  Acc@1: 75.0000 (70.8276)  Acc@5: 93.7500 (93.7415)  time: 0.3456  data: 0.0011  max mem: 2500
Train: Epoch[1/5]  [ 740/3750]  eta: 0:17:27  Lr: 0.001875  Loss: -0.4516  Acc@1: 75.0000 (70.9430)  Acc@5: 93.7500 (93.7753)  time: 0.3465  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [ 750/3750]  eta: 0:17:23  Lr: 0.001875  Loss: -0.8016  Acc@1: 75.0000 (71.0220)  Acc@5: 93.7500 (93.7916)  time: 0.3469  data: 0.0011  max mem: 2500
Train: Epoch[1/5]  [ 760/3750]  eta: 0:17:20  Lr: 0.001875  Loss: -0.9605  Acc@1: 75.0000 (71.1235)  Acc@5: 93.7500 (93.7911)  time: 0.3474  data: 0.0015  max mem: 2500
Train: Epoch[1/5]  [ 770/3750]  eta: 0:17:17  Lr: 0.001875  Loss: -0.8355  Acc@1: 75.0000 (71.2143)  Acc@5: 93.7500 (93.8067)  time: 0.3480  data: 0.0011  max mem: 2500
Train: Epoch[1/5]  [ 780/3750]  eta: 0:17:13  Lr: 0.001875  Loss: -0.2579  Acc@1: 75.0000 (71.2708)  Acc@5: 93.7500 (93.8380)  time: 0.3463  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 790/3750]  eta: 0:17:09  Lr: 0.001875  Loss: -1.0200  Acc@1: 75.0000 (71.2863)  Acc@5: 93.7500 (93.8606)  time: 0.3468  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [ 800/3750]  eta: 0:17:06  Lr: 0.001875  Loss: -1.0403  Acc@1: 75.0000 (71.3795)  Acc@5: 100.0000 (93.8826)  time: 0.3474  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 810/3750]  eta: 0:17:02  Lr: 0.001875  Loss: -0.3634  Acc@1: 75.0000 (71.4319)  Acc@5: 93.7500 (93.8887)  time: 0.3460  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 820/3750]  eta: 0:16:59  Lr: 0.001875  Loss: -1.1749  Acc@1: 81.2500 (71.5971)  Acc@5: 93.7500 (93.9327)  time: 0.3457  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 830/3750]  eta: 0:16:55  Lr: 0.001875  Loss: -1.1992  Acc@1: 75.0000 (71.6080)  Acc@5: 93.7500 (93.9079)  time: 0.3466  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [ 840/3750]  eta: 0:16:52  Lr: 0.001875  Loss: -0.6227  Acc@1: 75.0000 (71.6855)  Acc@5: 93.7500 (93.9061)  time: 0.3488  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [ 850/3750]  eta: 0:16:48  Lr: 0.001875  Loss: -0.5887  Acc@1: 75.0000 (71.7391)  Acc@5: 100.0000 (93.9483)  time: 0.3488  data: 0.0017  max mem: 2500
Train: Epoch[1/5]  [ 860/3750]  eta: 0:16:45  Lr: 0.001875  Loss: -0.5882  Acc@1: 75.0000 (71.7625)  Acc@5: 93.7500 (93.9533)  time: 0.3474  data: 0.0015  max mem: 2500
Train: Epoch[1/5]  [ 870/3750]  eta: 0:16:41  Lr: 0.001875  Loss: -0.5018  Acc@1: 75.0000 (71.7710)  Acc@5: 93.7500 (93.9366)  time: 0.3482  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [ 880/3750]  eta: 0:16:38  Lr: 0.001875  Loss: -0.8967  Acc@1: 75.0000 (71.8076)  Acc@5: 93.7500 (93.9557)  time: 0.3482  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [ 890/3750]  eta: 0:16:34  Lr: 0.001875  Loss: -0.6692  Acc@1: 75.0000 (71.8996)  Acc@5: 93.7500 (93.9885)  time: 0.3472  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [ 900/3750]  eta: 0:16:31  Lr: 0.001875  Loss: -0.5775  Acc@1: 75.0000 (71.9617)  Acc@5: 100.0000 (93.9928)  time: 0.3483  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [ 910/3750]  eta: 0:16:28  Lr: 0.001875  Loss: -1.0547  Acc@1: 75.0000 (72.0088)  Acc@5: 93.7500 (94.0038)  time: 0.3493  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [ 920/3750]  eta: 0:16:24  Lr: 0.001875  Loss: -0.3459  Acc@1: 75.0000 (72.0684)  Acc@5: 93.7500 (94.0350)  time: 0.3482  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [ 930/3750]  eta: 0:16:21  Lr: 0.001875  Loss: -0.7476  Acc@1: 75.0000 (72.0999)  Acc@5: 93.7500 (94.0185)  time: 0.3480  data: 0.0014  max mem: 2500
Train: Epoch[1/5]  [ 940/3750]  eta: 0:16:17  Lr: 0.001875  Loss: -0.7521  Acc@1: 75.0000 (72.1307)  Acc@5: 93.7500 (94.0157)  time: 0.3509  data: 0.0027  max mem: 2500
Train: Epoch[1/5]  [ 950/3750]  eta: 0:16:14  Lr: 0.001875  Loss: -0.4471  Acc@1: 75.0000 (72.1872)  Acc@5: 93.7500 (94.0523)  time: 0.3498  data: 0.0019  max mem: 2500
Train: Epoch[1/5]  [ 960/3750]  eta: 0:16:10  Lr: 0.001875  Loss: -0.4435  Acc@1: 81.2500 (72.2685)  Acc@5: 100.0000 (94.0817)  time: 0.3473  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [ 970/3750]  eta: 0:16:07  Lr: 0.001875  Loss: -0.6264  Acc@1: 75.0000 (72.3095)  Acc@5: 93.7500 (94.0783)  time: 0.3489  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [ 980/3750]  eta: 0:16:03  Lr: 0.001875  Loss: -0.7938  Acc@1: 75.0000 (72.3815)  Acc@5: 100.0000 (94.1131)  time: 0.3477  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [ 990/3750]  eta: 0:16:00  Lr: 0.001875  Loss: -0.7237  Acc@1: 81.2500 (72.4521)  Acc@5: 93.7500 (94.1221)  time: 0.3464  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [1000/3750]  eta: 0:15:56  Lr: 0.001875  Loss: -0.6340  Acc@1: 75.0000 (72.4838)  Acc@5: 93.7500 (94.1059)  time: 0.3480  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [1010/3750]  eta: 0:15:53  Lr: 0.001875  Loss: -0.8199  Acc@1: 75.0000 (72.4777)  Acc@5: 93.7500 (94.0838)  time: 0.3475  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [1020/3750]  eta: 0:15:49  Lr: 0.001875  Loss: -0.8371  Acc@1: 75.0000 (72.5575)  Acc@5: 93.7500 (94.1173)  time: 0.3458  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [1030/3750]  eta: 0:15:46  Lr: 0.001875  Loss: -0.7760  Acc@1: 75.0000 (72.5873)  Acc@5: 100.0000 (94.1198)  time: 0.3470  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [1040/3750]  eta: 0:15:42  Lr: 0.001875  Loss: -0.6894  Acc@1: 81.2500 (72.6405)  Acc@5: 100.0000 (94.1583)  time: 0.3481  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [1050/3750]  eta: 0:15:39  Lr: 0.001875  Loss: -0.9752  Acc@1: 81.2500 (72.6867)  Acc@5: 100.0000 (94.1782)  time: 0.3485  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [1060/3750]  eta: 0:15:35  Lr: 0.001875  Loss: -0.6679  Acc@1: 75.0000 (72.6967)  Acc@5: 100.0000 (94.1977)  time: 0.3489  data: 0.0011  max mem: 2500
Train: Epoch[1/5]  [1070/3750]  eta: 0:15:32  Lr: 0.001875  Loss: -0.8263  Acc@1: 75.0000 (72.7474)  Acc@5: 93.7500 (94.2227)  time: 0.3474  data: 0.0010  max mem: 2500
Train: Epoch[1/5]  [1080/3750]  eta: 0:15:28  Lr: 0.001875  Loss: -1.0404  Acc@1: 81.2500 (72.7567)  Acc@5: 93.7500 (94.2241)  time: 0.3471  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [1090/3750]  eta: 0:15:25  Lr: 0.001875  Loss: -1.2671  Acc@1: 75.0000 (72.8002)  Acc@5: 100.0000 (94.2484)  time: 0.3487  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [1100/3750]  eta: 0:15:22  Lr: 0.001875  Loss: -0.7027  Acc@1: 75.0000 (72.8315)  Acc@5: 100.0000 (94.2723)  time: 0.3508  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [1110/3750]  eta: 0:15:18  Lr: 0.001875  Loss: -0.7205  Acc@1: 81.2500 (72.8848)  Acc@5: 93.7500 (94.2957)  time: 0.3487  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [1120/3750]  eta: 0:15:15  Lr: 0.001875  Loss: -0.4124  Acc@1: 81.2500 (72.9761)  Acc@5: 100.0000 (94.3020)  time: 0.3475  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [1130/3750]  eta: 0:15:11  Lr: 0.001875  Loss: -0.8683  Acc@1: 81.2500 (73.0603)  Acc@5: 100.0000 (94.3247)  time: 0.3504  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [1140/3750]  eta: 0:15:08  Lr: 0.001875  Loss: -0.6623  Acc@1: 75.0000 (73.0938)  Acc@5: 93.7500 (94.3252)  time: 0.3485  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1150/3750]  eta: 0:15:04  Lr: 0.001875  Loss: -0.5248  Acc@1: 75.0000 (73.1103)  Acc@5: 100.0000 (94.3636)  time: 0.3472  data: 0.0011  max mem: 2500
Train: Epoch[1/5]  [1160/3750]  eta: 0:15:01  Lr: 0.001875  Loss: -0.8279  Acc@1: 75.0000 (73.1051)  Acc@5: 100.0000 (94.3745)  time: 0.3471  data: 0.0010  max mem: 2500
Train: Epoch[1/5]  [1170/3750]  eta: 0:14:57  Lr: 0.001875  Loss: -0.5402  Acc@1: 75.0000 (73.1106)  Acc@5: 93.7500 (94.3905)  time: 0.3468  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1180/3750]  eta: 0:14:54  Lr: 0.001875  Loss: -0.6987  Acc@1: 75.0000 (73.1689)  Acc@5: 100.0000 (94.4168)  time: 0.3483  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [1190/3750]  eta: 0:14:50  Lr: 0.001875  Loss: 0.0022  Acc@1: 81.2500 (73.2053)  Acc@5: 100.0000 (94.4427)  time: 0.3478  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [1200/3750]  eta: 0:14:47  Lr: 0.001875  Loss: -0.5843  Acc@1: 81.2500 (73.2775)  Acc@5: 100.0000 (94.4473)  time: 0.3489  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [1210/3750]  eta: 0:14:43  Lr: 0.001875  Loss: -0.9802  Acc@1: 81.2500 (73.3123)  Acc@5: 93.7500 (94.4261)  time: 0.3479  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1220/3750]  eta: 0:14:40  Lr: 0.001875  Loss: -1.0189  Acc@1: 81.2500 (73.3466)  Acc@5: 93.7500 (94.4462)  time: 0.3463  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1230/3750]  eta: 0:14:36  Lr: 0.001875  Loss: -0.8477  Acc@1: 75.0000 (73.3448)  Acc@5: 93.7500 (94.4608)  time: 0.3481  data: 0.0009  max mem: 2500
Train: Epoch[1/5]  [1240/3750]  eta: 0:14:33  Lr: 0.001875  Loss: -0.6431  Acc@1: 75.0000 (73.3834)  Acc@5: 100.0000 (94.4803)  time: 0.3483  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [1250/3750]  eta: 0:14:29  Lr: 0.001875  Loss: -0.1546  Acc@1: 75.0000 (73.3763)  Acc@5: 100.0000 (94.4994)  time: 0.3484  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [1260/3750]  eta: 0:14:26  Lr: 0.001875  Loss: -0.8075  Acc@1: 75.0000 (73.4437)  Acc@5: 93.7500 (94.4984)  time: 0.3472  data: 0.0012  max mem: 2500
Train: Epoch[1/5]  [1270/3750]  eta: 0:14:22  Lr: 0.001875  Loss: -0.7158  Acc@1: 81.2500 (73.4461)  Acc@5: 93.7500 (94.5171)  time: 0.3480  data: 0.0010  max mem: 2500
Train: Epoch[1/5]  [1280/3750]  eta: 0:14:19  Lr: 0.001875  Loss: -0.9346  Acc@1: 81.2500 (73.4973)  Acc@5: 100.0000 (94.5209)  time: 0.3495  data: 0.0010  max mem: 2500
Train: Epoch[1/5]  [1290/3750]  eta: 0:14:15  Lr: 0.001875  Loss: -0.6608  Acc@1: 81.2500 (73.5283)  Acc@5: 93.7500 (94.5343)  time: 0.3467  data: 0.0009  max mem: 2500
Train: Epoch[1/5]  [1300/3750]  eta: 0:14:12  Lr: 0.001875  Loss: -0.4954  Acc@1: 75.0000 (73.5924)  Acc@5: 93.7500 (94.5427)  time: 0.3469  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1310/3750]  eta: 0:14:09  Lr: 0.001875  Loss: -0.8493  Acc@1: 81.2500 (73.6365)  Acc@5: 100.0000 (94.5652)  time: 0.3497  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [1320/3750]  eta: 0:14:05  Lr: 0.001875  Loss: -1.0149  Acc@1: 81.2500 (73.6705)  Acc@5: 100.0000 (94.5780)  time: 0.3481  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [1330/3750]  eta: 0:14:02  Lr: 0.001875  Loss: -0.2278  Acc@1: 81.2500 (73.7087)  Acc@5: 93.7500 (94.5858)  time: 0.3488  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [1340/3750]  eta: 0:13:58  Lr: 0.001875  Loss: -0.8767  Acc@1: 75.0000 (73.6950)  Acc@5: 93.7500 (94.5843)  time: 0.3503  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [1350/3750]  eta: 0:13:55  Lr: 0.001875  Loss: -0.5518  Acc@1: 75.0000 (73.7232)  Acc@5: 100.0000 (94.5920)  time: 0.3486  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [1360/3750]  eta: 0:13:51  Lr: 0.001875  Loss: -0.5393  Acc@1: 81.2500 (73.7601)  Acc@5: 100.0000 (94.6087)  time: 0.3486  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1370/3750]  eta: 0:13:48  Lr: 0.001875  Loss: -0.5420  Acc@1: 75.0000 (73.7965)  Acc@5: 100.0000 (94.6162)  time: 0.3491  data: 0.0014  max mem: 2500
Train: Epoch[1/5]  [1380/3750]  eta: 0:13:44  Lr: 0.001875  Loss: -0.8107  Acc@1: 75.0000 (73.8233)  Acc@5: 100.0000 (94.6370)  time: 0.3500  data: 0.0014  max mem: 2500
Train: Epoch[1/5]  [1390/3750]  eta: 0:13:41  Lr: 0.001875  Loss: -0.5394  Acc@1: 75.0000 (73.8228)  Acc@5: 93.7500 (94.6352)  time: 0.3497  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [1400/3750]  eta: 0:13:37  Lr: 0.001875  Loss: -1.1663  Acc@1: 75.0000 (73.8446)  Acc@5: 93.7500 (94.6378)  time: 0.3475  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1410/3750]  eta: 0:13:34  Lr: 0.001875  Loss: -0.9391  Acc@1: 81.2500 (73.8793)  Acc@5: 93.7500 (94.6359)  time: 0.3466  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1420/3750]  eta: 0:13:30  Lr: 0.001875  Loss: -0.3889  Acc@1: 81.2500 (73.8784)  Acc@5: 100.0000 (94.6385)  time: 0.3468  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1430/3750]  eta: 0:13:27  Lr: 0.001875  Loss: -0.8970  Acc@1: 75.0000 (73.9037)  Acc@5: 100.0000 (94.6716)  time: 0.3470  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [1440/3750]  eta: 0:13:23  Lr: 0.001875  Loss: -0.6194  Acc@1: 75.0000 (73.9027)  Acc@5: 100.0000 (94.6999)  time: 0.3471  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [1450/3750]  eta: 0:13:20  Lr: 0.001875  Loss: -0.9288  Acc@1: 81.2500 (73.9404)  Acc@5: 100.0000 (94.7192)  time: 0.3484  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [1460/3750]  eta: 0:13:16  Lr: 0.001875  Loss: -0.7970  Acc@1: 81.2500 (73.9776)  Acc@5: 100.0000 (94.7425)  time: 0.3478  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [1470/3750]  eta: 0:13:13  Lr: 0.001875  Loss: -0.8912  Acc@1: 81.2500 (74.0270)  Acc@5: 100.0000 (94.7612)  time: 0.3463  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1480/3750]  eta: 0:13:09  Lr: 0.001875  Loss: -0.6404  Acc@1: 81.2500 (74.0589)  Acc@5: 100.0000 (94.7586)  time: 0.3476  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [1490/3750]  eta: 0:13:06  Lr: 0.001875  Loss: -0.5890  Acc@1: 81.2500 (74.1113)  Acc@5: 93.7500 (94.7770)  time: 0.3492  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [1500/3750]  eta: 0:13:03  Lr: 0.001875  Loss: -0.5559  Acc@1: 81.2500 (74.1381)  Acc@5: 100.0000 (94.7910)  time: 0.3497  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [1510/3750]  eta: 0:12:59  Lr: 0.001875  Loss: -0.7438  Acc@1: 81.2500 (74.1686)  Acc@5: 100.0000 (94.7965)  time: 0.3496  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [1520/3750]  eta: 0:12:56  Lr: 0.001875  Loss: -0.5726  Acc@1: 81.2500 (74.2152)  Acc@5: 93.7500 (94.8019)  time: 0.3481  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [1530/3750]  eta: 0:12:52  Lr: 0.001875  Loss: -0.4200  Acc@1: 75.0000 (74.2203)  Acc@5: 100.0000 (94.8114)  time: 0.3497  data: 0.0016  max mem: 2500
Train: Epoch[1/5]  [1540/3750]  eta: 0:12:49  Lr: 0.001875  Loss: -1.1249  Acc@1: 75.0000 (74.2578)  Acc@5: 100.0000 (94.8329)  time: 0.3513  data: 0.0015  max mem: 2500
Train: Epoch[1/5]  [1550/3750]  eta: 0:12:45  Lr: 0.001875  Loss: -0.6998  Acc@1: 81.2500 (74.2747)  Acc@5: 100.0000 (94.8420)  time: 0.3474  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [1560/3750]  eta: 0:12:42  Lr: 0.001875  Loss: -1.0266  Acc@1: 81.2500 (74.3234)  Acc@5: 100.0000 (94.8551)  time: 0.3459  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1570/3750]  eta: 0:12:38  Lr: 0.001875  Loss: -1.3181  Acc@1: 81.2500 (74.3714)  Acc@5: 100.0000 (94.8679)  time: 0.3461  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1580/3750]  eta: 0:12:35  Lr: 0.001875  Loss: -0.5399  Acc@1: 75.0000 (74.3477)  Acc@5: 93.7500 (94.8490)  time: 0.3458  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1590/3750]  eta: 0:12:31  Lr: 0.001875  Loss: -0.9388  Acc@1: 75.0000 (74.3715)  Acc@5: 93.7500 (94.8499)  time: 0.3464  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1600/3750]  eta: 0:12:28  Lr: 0.001875  Loss: -0.6169  Acc@1: 81.2500 (74.3715)  Acc@5: 93.7500 (94.8626)  time: 0.3474  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [1610/3750]  eta: 0:12:24  Lr: 0.001875  Loss: -0.4286  Acc@1: 75.0000 (74.3831)  Acc@5: 93.7500 (94.8673)  time: 0.3477  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [1620/3750]  eta: 0:12:21  Lr: 0.001875  Loss: -0.4511  Acc@1: 75.0000 (74.3638)  Acc@5: 93.7500 (94.8643)  time: 0.3473  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1630/3750]  eta: 0:12:17  Lr: 0.001875  Loss: -0.1655  Acc@1: 75.0000 (74.3792)  Acc@5: 93.7500 (94.8728)  time: 0.3491  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [1640/3750]  eta: 0:12:14  Lr: 0.001875  Loss: -0.6221  Acc@1: 75.0000 (74.3868)  Acc@5: 100.0000 (94.8850)  time: 0.3493  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [1650/3750]  eta: 0:12:10  Lr: 0.001875  Loss: -0.8704  Acc@1: 75.0000 (74.4208)  Acc@5: 100.0000 (94.8932)  time: 0.3465  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [1660/3750]  eta: 0:12:07  Lr: 0.001875  Loss: -0.7869  Acc@1: 81.2500 (74.4431)  Acc@5: 100.0000 (94.8901)  time: 0.3471  data: 0.0011  max mem: 2500
Train: Epoch[1/5]  [1670/3750]  eta: 0:12:03  Lr: 0.001875  Loss: -1.0013  Acc@1: 81.2500 (74.4876)  Acc@5: 93.7500 (94.8870)  time: 0.3472  data: 0.0011  max mem: 2500
Train: Epoch[1/5]  [1680/3750]  eta: 0:12:00  Lr: 0.001875  Loss: -0.9251  Acc@1: 81.2500 (74.5167)  Acc@5: 93.7500 (94.8952)  time: 0.3462  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [1690/3750]  eta: 0:11:56  Lr: 0.001875  Loss: -1.0690  Acc@1: 81.2500 (74.5528)  Acc@5: 93.7500 (94.9069)  time: 0.3473  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [1700/3750]  eta: 0:11:53  Lr: 0.001875  Loss: -0.9705  Acc@1: 81.2500 (74.6215)  Acc@5: 100.0000 (94.9258)  time: 0.3481  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1710/3750]  eta: 0:11:49  Lr: 0.001875  Loss: -0.8580  Acc@1: 81.2500 (74.6457)  Acc@5: 100.0000 (94.9372)  time: 0.3477  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1720/3750]  eta: 0:11:46  Lr: 0.001875  Loss: -0.5945  Acc@1: 81.2500 (74.6732)  Acc@5: 100.0000 (94.9448)  time: 0.3474  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [1730/3750]  eta: 0:11:42  Lr: 0.001875  Loss: -0.3950  Acc@1: 81.2500 (74.6967)  Acc@5: 100.0000 (94.9668)  time: 0.3512  data: 0.0013  max mem: 2500
Train: Epoch[1/5]  [1740/3750]  eta: 0:11:39  Lr: 0.001875  Loss: -1.0383  Acc@1: 81.2500 (74.7308)  Acc@5: 100.0000 (94.9670)  time: 0.3535  data: 0.0014  max mem: 2500
Train: Epoch[1/5]  [1750/3750]  eta: 0:11:36  Lr: 0.001875  Loss: -0.8863  Acc@1: 87.5000 (74.8037)  Acc@5: 100.0000 (94.9743)  time: 0.3485  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [1760/3750]  eta: 0:11:32  Lr: 0.001875  Loss: -1.1021  Acc@1: 81.2500 (74.7942)  Acc@5: 100.0000 (94.9815)  time: 0.3476  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [1770/3750]  eta: 0:11:29  Lr: 0.001875  Loss: -1.0232  Acc@1: 75.0000 (74.8059)  Acc@5: 100.0000 (94.9746)  time: 0.3479  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [1780/3750]  eta: 0:11:25  Lr: 0.001875  Loss: -0.9061  Acc@1: 75.0000 (74.8280)  Acc@5: 100.0000 (94.9888)  time: 0.3475  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [1790/3750]  eta: 0:11:22  Lr: 0.001875  Loss: -0.5267  Acc@1: 81.2500 (74.8569)  Acc@5: 100.0000 (95.0133)  time: 0.3493  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [1800/3750]  eta: 0:11:18  Lr: 0.001875  Loss: -0.9598  Acc@1: 81.2500 (74.8994)  Acc@5: 100.0000 (95.0271)  time: 0.3490  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [1810/3750]  eta: 0:11:15  Lr: 0.001875  Loss: -1.1676  Acc@1: 81.2500 (74.9344)  Acc@5: 93.7500 (95.0131)  time: 0.3475  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [1820/3750]  eta: 0:11:11  Lr: 0.001875  Loss: -0.6777  Acc@1: 81.2500 (74.9588)  Acc@5: 93.7500 (95.0199)  time: 0.3468  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [1830/3750]  eta: 0:11:08  Lr: 0.001875  Loss: -1.0429  Acc@1: 81.2500 (74.9727)  Acc@5: 100.0000 (95.0300)  time: 0.3493  data: 0.0012  max mem: 2500
Train: Epoch[1/5]  [1840/3750]  eta: 0:11:04  Lr: 0.001875  Loss: -1.0059  Acc@1: 75.0000 (75.0068)  Acc@5: 100.0000 (95.0536)  time: 0.3483  data: 0.0010  max mem: 2500
Train: Epoch[1/5]  [1850/3750]  eta: 0:11:01  Lr: 0.001875  Loss: -0.9858  Acc@1: 81.2500 (75.0270)  Acc@5: 100.0000 (95.0635)  time: 0.3460  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [1860/3750]  eta: 0:10:57  Lr: 0.001875  Loss: -0.2359  Acc@1: 75.0000 (75.0067)  Acc@5: 93.7500 (95.0598)  time: 0.3477  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [1870/3750]  eta: 0:10:54  Lr: 0.001875  Loss: -0.8362  Acc@1: 75.0000 (75.0367)  Acc@5: 93.7500 (95.0695)  time: 0.3484  data: 0.0009  max mem: 2500
Train: Epoch[1/5]  [1880/3750]  eta: 0:10:50  Lr: 0.001875  Loss: -0.8944  Acc@1: 81.2500 (75.0665)  Acc@5: 100.0000 (95.0791)  time: 0.3483  data: 0.0010  max mem: 2500
Train: Epoch[1/5]  [1890/3750]  eta: 0:10:47  Lr: 0.001875  Loss: -0.1743  Acc@1: 75.0000 (75.0661)  Acc@5: 100.0000 (95.0853)  time: 0.3475  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [1900/3750]  eta: 0:10:43  Lr: 0.001875  Loss: -1.0613  Acc@1: 81.2500 (75.1315)  Acc@5: 100.0000 (95.1013)  time: 0.3485  data: 0.0019  max mem: 2500
Train: Epoch[1/5]  [1910/3750]  eta: 0:10:40  Lr: 0.001875  Loss: -0.9153  Acc@1: 81.2500 (75.1210)  Acc@5: 100.0000 (95.0877)  time: 0.3495  data: 0.0019  max mem: 2500
Train: Epoch[1/5]  [1920/3750]  eta: 0:10:36  Lr: 0.001875  Loss: -0.2093  Acc@1: 75.0000 (75.1301)  Acc@5: 93.7500 (95.0709)  time: 0.3485  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1930/3750]  eta: 0:10:33  Lr: 0.001875  Loss: -0.5781  Acc@1: 75.0000 (75.1327)  Acc@5: 93.7500 (95.0770)  time: 0.3501  data: 0.0011  max mem: 2500
Train: Epoch[1/5]  [1940/3750]  eta: 0:10:29  Lr: 0.001875  Loss: -1.0536  Acc@1: 75.0000 (75.1352)  Acc@5: 93.7500 (95.0670)  time: 0.3486  data: 0.0014  max mem: 2500
Train: Epoch[1/5]  [1950/3750]  eta: 0:10:26  Lr: 0.001875  Loss: -1.1679  Acc@1: 75.0000 (75.1538)  Acc@5: 100.0000 (95.0826)  time: 0.3463  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [1960/3750]  eta: 0:10:22  Lr: 0.001875  Loss: -0.5298  Acc@1: 75.0000 (75.1657)  Acc@5: 100.0000 (95.0886)  time: 0.3463  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1970/3750]  eta: 0:10:19  Lr: 0.001875  Loss: -0.6044  Acc@1: 81.2500 (75.2061)  Acc@5: 100.0000 (95.0945)  time: 0.3466  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1980/3750]  eta: 0:10:15  Lr: 0.001875  Loss: -0.5051  Acc@1: 81.2500 (75.2335)  Acc@5: 93.7500 (95.0877)  time: 0.3476  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [1990/3750]  eta: 0:10:12  Lr: 0.001875  Loss: -0.6422  Acc@1: 81.2500 (75.2386)  Acc@5: 93.7500 (95.0841)  time: 0.3475  data: 0.0015  max mem: 2500
Train: Epoch[1/5]  [2000/3750]  eta: 0:10:08  Lr: 0.001875  Loss: -0.6745  Acc@1: 75.0000 (75.2499)  Acc@5: 93.7500 (95.0806)  time: 0.3472  data: 0.0017  max mem: 2500
Train: Epoch[1/5]  [2010/3750]  eta: 0:10:05  Lr: 0.001875  Loss: -0.5454  Acc@1: 81.2500 (75.2859)  Acc@5: 93.7500 (95.0646)  time: 0.3474  data: 0.0012  max mem: 2500
Train: Epoch[1/5]  [2020/3750]  eta: 0:10:02  Lr: 0.001875  Loss: -1.2190  Acc@1: 81.2500 (75.3340)  Acc@5: 93.7500 (95.0798)  time: 0.3497  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [2030/3750]  eta: 0:09:58  Lr: 0.001875  Loss: -0.7369  Acc@1: 81.2500 (75.3354)  Acc@5: 93.7500 (95.0794)  time: 0.3496  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [2040/3750]  eta: 0:09:55  Lr: 0.001875  Loss: -0.2601  Acc@1: 81.2500 (75.3644)  Acc@5: 93.7500 (95.0821)  time: 0.3475  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [2050/3750]  eta: 0:09:51  Lr: 0.001875  Loss: -1.2245  Acc@1: 81.2500 (75.3809)  Acc@5: 100.0000 (95.0939)  time: 0.3480  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [2060/3750]  eta: 0:09:48  Lr: 0.001875  Loss: -0.7765  Acc@1: 68.7500 (75.3487)  Acc@5: 100.0000 (95.0934)  time: 0.3498  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [2070/3750]  eta: 0:09:44  Lr: 0.001875  Loss: -0.5839  Acc@1: 68.7500 (75.3621)  Acc@5: 93.7500 (95.0869)  time: 0.3502  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [2080/3750]  eta: 0:09:41  Lr: 0.001875  Loss: -0.8048  Acc@1: 75.0000 (75.3874)  Acc@5: 100.0000 (95.1015)  time: 0.3479  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [2090/3750]  eta: 0:09:37  Lr: 0.001875  Loss: -0.5696  Acc@1: 75.0000 (75.3945)  Acc@5: 100.0000 (95.0921)  time: 0.3460  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [2100/3750]  eta: 0:09:34  Lr: 0.001875  Loss: -0.9709  Acc@1: 75.0000 (75.4075)  Acc@5: 100.0000 (95.0976)  time: 0.3472  data: 0.0014  max mem: 2500
Train: Epoch[1/5]  [2110/3750]  eta: 0:09:30  Lr: 0.001875  Loss: -0.8433  Acc@1: 81.2500 (75.4352)  Acc@5: 93.7500 (95.0971)  time: 0.3486  data: 0.0014  max mem: 2500
Train: Epoch[1/5]  [2120/3750]  eta: 0:09:27  Lr: 0.001875  Loss: -0.1989  Acc@1: 81.2500 (75.4538)  Acc@5: 93.7500 (95.1025)  time: 0.3479  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [2130/3750]  eta: 0:09:23  Lr: 0.001875  Loss: -0.7935  Acc@1: 81.2500 (75.4751)  Acc@5: 93.7500 (95.1079)  time: 0.3482  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [2140/3750]  eta: 0:09:20  Lr: 0.001875  Loss: -0.8057  Acc@1: 81.2500 (75.5109)  Acc@5: 93.7500 (95.1045)  time: 0.3478  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [2150/3750]  eta: 0:09:16  Lr: 0.001875  Loss: -1.1175  Acc@1: 81.2500 (75.5114)  Acc@5: 93.7500 (95.1156)  time: 0.3467  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [2160/3750]  eta: 0:09:13  Lr: 0.001875  Loss: -0.7909  Acc@1: 81.2500 (75.5351)  Acc@5: 100.0000 (95.1267)  time: 0.3476  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [2170/3750]  eta: 0:09:09  Lr: 0.001875  Loss: -1.0699  Acc@1: 81.2500 (75.5614)  Acc@5: 100.0000 (95.1376)  time: 0.3476  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [2180/3750]  eta: 0:09:06  Lr: 0.001875  Loss: -0.7466  Acc@1: 81.2500 (75.5731)  Acc@5: 100.0000 (95.1456)  time: 0.3465  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [2190/3750]  eta: 0:09:02  Lr: 0.001875  Loss: -1.4346  Acc@1: 81.2500 (75.6133)  Acc@5: 93.7500 (95.1506)  time: 0.3479  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2200/3750]  eta: 0:08:59  Lr: 0.001875  Loss: -0.8808  Acc@1: 81.2500 (75.6446)  Acc@5: 100.0000 (95.1641)  time: 0.3475  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2210/3750]  eta: 0:08:55  Lr: 0.001875  Loss: -0.7666  Acc@1: 81.2500 (75.6671)  Acc@5: 93.7500 (95.1634)  time: 0.3464  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [2220/3750]  eta: 0:08:52  Lr: 0.001875  Loss: -0.7863  Acc@1: 81.2500 (75.6894)  Acc@5: 93.7500 (95.1711)  time: 0.3484  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [2230/3750]  eta: 0:08:48  Lr: 0.001875  Loss: -0.8256  Acc@1: 81.2500 (75.7004)  Acc@5: 93.7500 (95.1703)  time: 0.3484  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [2240/3750]  eta: 0:08:45  Lr: 0.001875  Loss: -0.7594  Acc@1: 81.2500 (75.7279)  Acc@5: 93.7500 (95.1751)  time: 0.3474  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [2250/3750]  eta: 0:08:41  Lr: 0.001875  Loss: -0.9573  Acc@1: 87.5000 (75.7802)  Acc@5: 100.0000 (95.1855)  time: 0.3479  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2260/3750]  eta: 0:08:38  Lr: 0.001875  Loss: -0.6481  Acc@1: 87.5000 (75.7906)  Acc@5: 100.0000 (95.1847)  time: 0.3483  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [2270/3750]  eta: 0:08:35  Lr: 0.001875  Loss: -0.9156  Acc@1: 81.2500 (75.8366)  Acc@5: 100.0000 (95.1976)  time: 0.3485  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [2280/3750]  eta: 0:08:31  Lr: 0.001875  Loss: -0.6511  Acc@1: 81.2500 (75.8439)  Acc@5: 100.0000 (95.1940)  time: 0.3485  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2290/3750]  eta: 0:08:28  Lr: 0.001875  Loss: -0.7628  Acc@1: 81.2500 (75.8757)  Acc@5: 93.7500 (95.1931)  time: 0.3481  data: 0.0009  max mem: 2500
Train: Epoch[1/5]  [2300/3750]  eta: 0:08:24  Lr: 0.001875  Loss: -1.1658  Acc@1: 81.2500 (75.8963)  Acc@5: 93.7500 (95.2032)  time: 0.3480  data: 0.0009  max mem: 2500
Train: Epoch[1/5]  [2310/3750]  eta: 0:08:21  Lr: 0.001875  Loss: -0.9197  Acc@1: 81.2500 (75.9276)  Acc@5: 100.0000 (95.2104)  time: 0.3480  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [2320/3750]  eta: 0:08:17  Lr: 0.001875  Loss: -1.0282  Acc@1: 81.2500 (75.9425)  Acc@5: 100.0000 (95.2176)  time: 0.3464  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2330/3750]  eta: 0:08:14  Lr: 0.001875  Loss: -0.8516  Acc@1: 81.2500 (75.9760)  Acc@5: 100.0000 (95.2301)  time: 0.3468  data: 0.0010  max mem: 2500
Train: Epoch[1/5]  [2340/3750]  eta: 0:08:10  Lr: 0.001875  Loss: -0.8073  Acc@1: 81.2500 (75.9985)  Acc@5: 100.0000 (95.2291)  time: 0.3477  data: 0.0010  max mem: 2500
Train: Epoch[1/5]  [2350/3750]  eta: 0:08:07  Lr: 0.001875  Loss: -0.8928  Acc@1: 81.2500 (76.0182)  Acc@5: 100.0000 (95.2334)  time: 0.3469  data: 0.0011  max mem: 2500
Train: Epoch[1/5]  [2360/3750]  eta: 0:08:03  Lr: 0.001875  Loss: -0.8902  Acc@1: 81.2500 (76.0403)  Acc@5: 100.0000 (95.2377)  time: 0.3479  data: 0.0011  max mem: 2500
Train: Epoch[1/5]  [2370/3750]  eta: 0:08:00  Lr: 0.001875  Loss: -1.0936  Acc@1: 81.2500 (76.0623)  Acc@5: 100.0000 (95.2499)  time: 0.3476  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [2380/3750]  eta: 0:07:56  Lr: 0.001875  Loss: -0.5408  Acc@1: 81.2500 (76.0684)  Acc@5: 100.0000 (95.2541)  time: 0.3462  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [2390/3750]  eta: 0:07:53  Lr: 0.001875  Loss: -0.8550  Acc@1: 81.2500 (76.0874)  Acc@5: 100.0000 (95.2635)  time: 0.3471  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2400/3750]  eta: 0:07:49  Lr: 0.001875  Loss: -1.1024  Acc@1: 81.2500 (76.1219)  Acc@5: 100.0000 (95.2728)  time: 0.3487  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [2410/3750]  eta: 0:07:46  Lr: 0.001875  Loss: -0.9589  Acc@1: 87.5000 (76.1639)  Acc@5: 100.0000 (95.2898)  time: 0.3482  data: 0.0009  max mem: 2500
Train: Epoch[1/5]  [2420/3750]  eta: 0:07:42  Lr: 0.001875  Loss: 0.6198  Acc@1: 81.2500 (76.1591)  Acc@5: 100.0000 (95.2783)  time: 0.3471  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [2430/3750]  eta: 0:07:39  Lr: 0.001875  Loss: -1.0162  Acc@1: 81.2500 (76.1852)  Acc@5: 100.0000 (95.2874)  time: 0.3475  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2440/3750]  eta: 0:07:35  Lr: 0.001875  Loss: -0.0971  Acc@1: 81.2500 (76.1957)  Acc@5: 100.0000 (95.2888)  time: 0.3476  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2450/3750]  eta: 0:07:32  Lr: 0.001875  Loss: -0.8014  Acc@1: 75.0000 (76.2061)  Acc@5: 100.0000 (95.3055)  time: 0.3474  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2460/3750]  eta: 0:07:28  Lr: 0.001875  Loss: 0.1597  Acc@1: 75.0000 (76.1962)  Acc@5: 100.0000 (95.3093)  time: 0.3467  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2470/3750]  eta: 0:07:25  Lr: 0.001875  Loss: -0.7167  Acc@1: 81.2500 (76.2267)  Acc@5: 100.0000 (95.3182)  time: 0.3471  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2480/3750]  eta: 0:07:21  Lr: 0.001875  Loss: -0.9230  Acc@1: 87.5000 (76.2596)  Acc@5: 100.0000 (95.3219)  time: 0.3475  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2490/3750]  eta: 0:07:18  Lr: 0.001875  Loss: -0.3908  Acc@1: 81.2500 (76.2821)  Acc@5: 100.0000 (95.3307)  time: 0.3468  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2500/3750]  eta: 0:07:14  Lr: 0.001875  Loss: -0.5416  Acc@1: 81.2500 (76.2970)  Acc@5: 100.0000 (95.3419)  time: 0.3485  data: 0.0014  max mem: 2500
Train: Epoch[1/5]  [2510/3750]  eta: 0:07:11  Lr: 0.001875  Loss: -1.0252  Acc@1: 81.2500 (76.3068)  Acc@5: 100.0000 (95.3529)  time: 0.3485  data: 0.0014  max mem: 2500
Train: Epoch[1/5]  [2520/3750]  eta: 0:07:07  Lr: 0.001875  Loss: -0.6998  Acc@1: 81.2500 (76.3288)  Acc@5: 100.0000 (95.3540)  time: 0.3469  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2530/3750]  eta: 0:07:04  Lr: 0.001875  Loss: -0.8164  Acc@1: 81.2500 (76.3359)  Acc@5: 93.7500 (95.3427)  time: 0.3474  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2540/3750]  eta: 0:07:01  Lr: 0.001875  Loss: -0.9568  Acc@1: 81.2500 (76.3504)  Acc@5: 93.7500 (95.3463)  time: 0.3484  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [2550/3750]  eta: 0:06:57  Lr: 0.001875  Loss: -0.9102  Acc@1: 81.2500 (76.3647)  Acc@5: 93.7500 (95.3352)  time: 0.3470  data: 0.0009  max mem: 2500
Train: Epoch[1/5]  [2560/3750]  eta: 0:06:54  Lr: 0.001875  Loss: -0.6502  Acc@1: 81.2500 (76.3862)  Acc@5: 100.0000 (95.3461)  time: 0.3462  data: 0.0010  max mem: 2500
Train: Epoch[1/5]  [2570/3750]  eta: 0:06:50  Lr: 0.001875  Loss: -0.7690  Acc@1: 81.2500 (76.4002)  Acc@5: 100.0000 (95.3471)  time: 0.3474  data: 0.0009  max mem: 2500
Train: Epoch[1/5]  [2580/3750]  eta: 0:06:47  Lr: 0.001875  Loss: -0.7054  Acc@1: 81.2500 (76.3948)  Acc@5: 93.7500 (95.3506)  time: 0.3467  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [2590/3750]  eta: 0:06:43  Lr: 0.001875  Loss: -0.9781  Acc@1: 81.2500 (76.4111)  Acc@5: 100.0000 (95.3638)  time: 0.3459  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2600/3750]  eta: 0:06:40  Lr: 0.001875  Loss: -0.9230  Acc@1: 81.2500 (76.4297)  Acc@5: 100.0000 (95.3696)  time: 0.3474  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [2610/3750]  eta: 0:06:36  Lr: 0.001875  Loss: -0.5644  Acc@1: 81.2500 (76.4458)  Acc@5: 100.0000 (95.3801)  time: 0.3474  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2620/3750]  eta: 0:06:33  Lr: 0.001875  Loss: -0.7184  Acc@1: 75.0000 (76.4379)  Acc@5: 100.0000 (95.3763)  time: 0.3471  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2630/3750]  eta: 0:06:29  Lr: 0.001875  Loss: -0.3630  Acc@1: 75.0000 (76.4419)  Acc@5: 100.0000 (95.3796)  time: 0.3488  data: 0.0023  max mem: 2500
Train: Epoch[1/5]  [2640/3750]  eta: 0:06:26  Lr: 0.001875  Loss: -0.6886  Acc@1: 75.0000 (76.4412)  Acc@5: 93.7500 (95.3782)  time: 0.3480  data: 0.0028  max mem: 2500
Train: Epoch[1/5]  [2650/3750]  eta: 0:06:22  Lr: 0.001875  Loss: -1.2432  Acc@1: 75.0000 (76.4688)  Acc@5: 100.0000 (95.3885)  time: 0.3461  data: 0.0010  max mem: 2500
Train: Epoch[1/5]  [2660/3750]  eta: 0:06:19  Lr: 0.001875  Loss: -1.3199  Acc@1: 81.2500 (76.4821)  Acc@5: 100.0000 (95.3918)  time: 0.3466  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [2670/3750]  eta: 0:06:15  Lr: 0.001875  Loss: -0.8598  Acc@1: 81.2500 (76.4976)  Acc@5: 100.0000 (95.3903)  time: 0.3469  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [2680/3750]  eta: 0:06:12  Lr: 0.001875  Loss: -0.7914  Acc@1: 81.2500 (76.5106)  Acc@5: 100.0000 (95.3958)  time: 0.3479  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [2690/3750]  eta: 0:06:08  Lr: 0.001875  Loss: -1.2533  Acc@1: 81.2500 (76.5213)  Acc@5: 100.0000 (95.4037)  time: 0.3512  data: 0.0012  max mem: 2500
Train: Epoch[1/5]  [2700/3750]  eta: 0:06:05  Lr: 0.001875  Loss: -1.0114  Acc@1: 81.2500 (76.5272)  Acc@5: 100.0000 (95.4114)  time: 0.3505  data: 0.0016  max mem: 2500
Train: Epoch[1/5]  [2710/3750]  eta: 0:06:01  Lr: 0.001875  Loss: -0.6801  Acc@1: 81.2500 (76.5262)  Acc@5: 100.0000 (95.4122)  time: 0.3469  data: 0.0009  max mem: 2500
Train: Epoch[1/5]  [2720/3750]  eta: 0:05:58  Lr: 0.001875  Loss: -0.8322  Acc@1: 75.0000 (76.5206)  Acc@5: 100.0000 (95.4176)  time: 0.3456  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2730/3750]  eta: 0:05:54  Lr: 0.001875  Loss: -0.6642  Acc@1: 81.2500 (76.5333)  Acc@5: 100.0000 (95.4275)  time: 0.3471  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [2740/3750]  eta: 0:05:51  Lr: 0.001875  Loss: -0.7402  Acc@1: 81.2500 (76.5414)  Acc@5: 100.0000 (95.4237)  time: 0.3487  data: 0.0011  max mem: 2500
Train: Epoch[1/5]  [2750/3750]  eta: 0:05:47  Lr: 0.001875  Loss: -0.7873  Acc@1: 81.2500 (76.5653)  Acc@5: 100.0000 (95.4312)  time: 0.3494  data: 0.0010  max mem: 2500
Train: Epoch[1/5]  [2760/3750]  eta: 0:05:44  Lr: 0.001875  Loss: -1.0659  Acc@1: 81.2500 (76.5936)  Acc@5: 100.0000 (95.4410)  time: 0.3485  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2770/3750]  eta: 0:05:40  Lr: 0.001875  Loss: -0.7585  Acc@1: 81.2500 (76.5856)  Acc@5: 100.0000 (95.4461)  time: 0.3476  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [2780/3750]  eta: 0:05:37  Lr: 0.001875  Loss: -0.7849  Acc@1: 75.0000 (76.5934)  Acc@5: 100.0000 (95.4513)  time: 0.3468  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [2790/3750]  eta: 0:05:33  Lr: 0.001875  Loss: -0.8010  Acc@1: 81.2500 (76.5966)  Acc@5: 93.7500 (95.4541)  time: 0.3462  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [2800/3750]  eta: 0:05:30  Lr: 0.001875  Loss: -0.8975  Acc@1: 81.2500 (76.6133)  Acc@5: 93.7500 (95.4570)  time: 0.3462  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [2810/3750]  eta: 0:05:27  Lr: 0.001875  Loss: -1.1689  Acc@1: 81.2500 (76.6298)  Acc@5: 93.7500 (95.4620)  time: 0.3462  data: 0.0011  max mem: 2500
Train: Epoch[1/5]  [2820/3750]  eta: 0:05:23  Lr: 0.001875  Loss: -0.6678  Acc@1: 81.2500 (76.6417)  Acc@5: 100.0000 (95.4737)  time: 0.3474  data: 0.0011  max mem: 2500
Train: Epoch[1/5]  [2830/3750]  eta: 0:05:20  Lr: 0.001875  Loss: -0.9213  Acc@1: 75.0000 (76.6425)  Acc@5: 100.0000 (95.4786)  time: 0.3470  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2840/3750]  eta: 0:05:16  Lr: 0.001875  Loss: -1.1826  Acc@1: 75.0000 (76.6499)  Acc@5: 93.7500 (95.4725)  time: 0.3466  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2850/3750]  eta: 0:05:13  Lr: 0.001875  Loss: -0.5385  Acc@1: 81.2500 (76.6770)  Acc@5: 93.7500 (95.4665)  time: 0.3460  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [2860/3750]  eta: 0:05:09  Lr: 0.001875  Loss: -0.8548  Acc@1: 87.5000 (76.7214)  Acc@5: 93.7500 (95.4758)  time: 0.3465  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [2870/3750]  eta: 0:05:06  Lr: 0.001875  Loss: -0.8057  Acc@1: 87.5000 (76.7416)  Acc@5: 100.0000 (95.4741)  time: 0.3472  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [2880/3750]  eta: 0:05:02  Lr: 0.001875  Loss: -1.1171  Acc@1: 81.2500 (76.7594)  Acc@5: 100.0000 (95.4703)  time: 0.3478  data: 0.0016  max mem: 2500
Train: Epoch[1/5]  [2890/3750]  eta: 0:04:59  Lr: 0.001875  Loss: -0.5674  Acc@1: 81.2500 (76.7619)  Acc@5: 100.0000 (95.4730)  time: 0.3487  data: 0.0016  max mem: 2500
Train: Epoch[1/5]  [2900/3750]  eta: 0:04:55  Lr: 0.001875  Loss: -0.6466  Acc@1: 81.2500 (76.7752)  Acc@5: 100.0000 (95.4800)  time: 0.3467  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2910/3750]  eta: 0:04:52  Lr: 0.001875  Loss: -0.7761  Acc@1: 81.2500 (76.7971)  Acc@5: 100.0000 (95.4912)  time: 0.3467  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2920/3750]  eta: 0:04:48  Lr: 0.001875  Loss: -0.7194  Acc@1: 81.2500 (76.8144)  Acc@5: 100.0000 (95.4981)  time: 0.3480  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2930/3750]  eta: 0:04:45  Lr: 0.001875  Loss: -0.3691  Acc@1: 81.2500 (76.8274)  Acc@5: 93.7500 (95.4943)  time: 0.3471  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2940/3750]  eta: 0:04:41  Lr: 0.001875  Loss: -0.7914  Acc@1: 75.0000 (76.8149)  Acc@5: 93.7500 (95.4947)  time: 0.3470  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2950/3750]  eta: 0:04:38  Lr: 0.001875  Loss: -0.9850  Acc@1: 75.0000 (76.8341)  Acc@5: 100.0000 (95.5036)  time: 0.3481  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2960/3750]  eta: 0:04:34  Lr: 0.001875  Loss: -0.4810  Acc@1: 75.0000 (76.8343)  Acc@5: 100.0000 (95.5083)  time: 0.3491  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2970/3750]  eta: 0:04:31  Lr: 0.001875  Loss: -0.8313  Acc@1: 75.0000 (76.8428)  Acc@5: 100.0000 (95.5150)  time: 0.3490  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2980/3750]  eta: 0:04:27  Lr: 0.001875  Loss: -0.4348  Acc@1: 81.2500 (76.8513)  Acc@5: 100.0000 (95.5174)  time: 0.3483  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [2990/3750]  eta: 0:04:24  Lr: 0.001875  Loss: -0.9234  Acc@1: 81.2500 (76.8681)  Acc@5: 93.7500 (95.5178)  time: 0.3489  data: 0.0015  max mem: 2500
Train: Epoch[1/5]  [3000/3750]  eta: 0:04:20  Lr: 0.001875  Loss: -1.0454  Acc@1: 81.2500 (76.8681)  Acc@5: 93.7500 (95.5161)  time: 0.3494  data: 0.0018  max mem: 2500
Train: Epoch[1/5]  [3010/3750]  eta: 0:04:17  Lr: 0.001875  Loss: -0.6853  Acc@1: 81.2500 (76.8765)  Acc@5: 93.7500 (95.5102)  time: 0.3491  data: 0.0011  max mem: 2500
Train: Epoch[1/5]  [3020/3750]  eta: 0:04:13  Lr: 0.001875  Loss: -0.6478  Acc@1: 81.2500 (76.8847)  Acc@5: 93.7500 (95.5168)  time: 0.3483  data: 0.0015  max mem: 2500
Train: Epoch[1/5]  [3030/3750]  eta: 0:04:10  Lr: 0.001875  Loss: -1.0231  Acc@1: 81.2500 (76.8971)  Acc@5: 93.7500 (95.5110)  time: 0.3473  data: 0.0014  max mem: 2500
Train: Epoch[1/5]  [3040/3750]  eta: 0:04:06  Lr: 0.001875  Loss: -1.1727  Acc@1: 81.2500 (76.9175)  Acc@5: 100.0000 (95.5257)  time: 0.3468  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [3050/3750]  eta: 0:04:03  Lr: 0.001875  Loss: -0.7753  Acc@1: 81.2500 (76.9215)  Acc@5: 100.0000 (95.5240)  time: 0.3465  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [3060/3750]  eta: 0:04:00  Lr: 0.001875  Loss: -0.6847  Acc@1: 75.0000 (76.9418)  Acc@5: 100.0000 (95.5345)  time: 0.3482  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [3070/3750]  eta: 0:03:56  Lr: 0.001875  Loss: -0.0576  Acc@1: 87.5000 (76.9558)  Acc@5: 100.0000 (95.5409)  time: 0.3473  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [3080/3750]  eta: 0:03:53  Lr: 0.001875  Loss: -0.0454  Acc@1: 87.5000 (76.9819)  Acc@5: 100.0000 (95.5453)  time: 0.3478  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [3090/3750]  eta: 0:03:49  Lr: 0.001875  Loss: -0.8579  Acc@1: 81.2500 (76.9977)  Acc@5: 100.0000 (95.5516)  time: 0.3495  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [3100/3750]  eta: 0:03:46  Lr: 0.001875  Loss: -0.8229  Acc@1: 81.2500 (77.0094)  Acc@5: 100.0000 (95.5619)  time: 0.3463  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [3110/3750]  eta: 0:03:42  Lr: 0.001875  Loss: -1.3679  Acc@1: 81.2500 (77.0110)  Acc@5: 100.0000 (95.5722)  time: 0.3461  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [3120/3750]  eta: 0:03:39  Lr: 0.001875  Loss: -0.4429  Acc@1: 75.0000 (77.0126)  Acc@5: 100.0000 (95.5763)  time: 0.3468  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [3130/3750]  eta: 0:03:35  Lr: 0.001875  Loss: -0.3727  Acc@1: 75.0000 (77.0221)  Acc@5: 100.0000 (95.5745)  time: 0.3458  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [3140/3750]  eta: 0:03:32  Lr: 0.001875  Loss: -0.6779  Acc@1: 81.2500 (77.0356)  Acc@5: 93.7500 (95.5707)  time: 0.3481  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [3150/3750]  eta: 0:03:28  Lr: 0.001875  Loss: -0.7415  Acc@1: 81.2500 (77.0390)  Acc@5: 93.7500 (95.5728)  time: 0.3489  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [3160/3750]  eta: 0:03:25  Lr: 0.001875  Loss: -0.8935  Acc@1: 75.0000 (77.0326)  Acc@5: 93.7500 (95.5690)  time: 0.3502  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [3170/3750]  eta: 0:03:21  Lr: 0.001875  Loss: -1.2113  Acc@1: 75.0000 (77.0498)  Acc@5: 93.7500 (95.5751)  time: 0.3496  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [3180/3750]  eta: 0:03:18  Lr: 0.001875  Loss: -0.8036  Acc@1: 81.2500 (77.0473)  Acc@5: 100.0000 (95.5792)  time: 0.3464  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [3190/3750]  eta: 0:03:14  Lr: 0.001875  Loss: -0.3084  Acc@1: 81.2500 (77.0487)  Acc@5: 93.7500 (95.5754)  time: 0.3471  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [3200/3750]  eta: 0:03:11  Lr: 0.001875  Loss: -1.3507  Acc@1: 81.2500 (77.0658)  Acc@5: 100.0000 (95.5873)  time: 0.3472  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [3210/3750]  eta: 0:03:07  Lr: 0.001875  Loss: -0.6497  Acc@1: 81.2500 (77.0885)  Acc@5: 100.0000 (95.5874)  time: 0.3482  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [3220/3750]  eta: 0:03:04  Lr: 0.001875  Loss: -0.6958  Acc@1: 81.2500 (77.0820)  Acc@5: 100.0000 (95.5953)  time: 0.3481  data: 0.0013  max mem: 2500
Train: Epoch[1/5]  [3230/3750]  eta: 0:03:00  Lr: 0.001875  Loss: -0.3963  Acc@1: 81.2500 (77.0930)  Acc@5: 100.0000 (95.6031)  time: 0.3471  data: 0.0013  max mem: 2500
Train: Epoch[1/5]  [3240/3750]  eta: 0:02:57  Lr: 0.001875  Loss: -0.4808  Acc@1: 81.2500 (77.1116)  Acc@5: 100.0000 (95.6032)  time: 0.3476  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [3250/3750]  eta: 0:02:53  Lr: 0.001875  Loss: -0.9101  Acc@1: 81.2500 (77.1263)  Acc@5: 93.7500 (95.6052)  time: 0.3476  data: 0.0009  max mem: 2500
Train: Epoch[1/5]  [3260/3750]  eta: 0:02:50  Lr: 0.001875  Loss: -0.8996  Acc@1: 81.2500 (77.1389)  Acc@5: 93.7500 (95.6110)  time: 0.3476  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [3270/3750]  eta: 0:02:46  Lr: 0.001875  Loss: -0.8064  Acc@1: 81.2500 (77.1496)  Acc@5: 93.7500 (95.6072)  time: 0.3482  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [3280/3750]  eta: 0:02:43  Lr: 0.001875  Loss: -0.7852  Acc@1: 81.2500 (77.1564)  Acc@5: 93.7500 (95.6130)  time: 0.3499  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [3290/3750]  eta: 0:02:40  Lr: 0.001875  Loss: -1.0008  Acc@1: 81.2500 (77.1669)  Acc@5: 100.0000 (95.6149)  time: 0.3497  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [3300/3750]  eta: 0:02:36  Lr: 0.001875  Loss: -0.7366  Acc@1: 81.2500 (77.1868)  Acc@5: 100.0000 (95.6131)  time: 0.3468  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [3310/3750]  eta: 0:02:33  Lr: 0.001875  Loss: -0.5015  Acc@1: 81.2500 (77.1934)  Acc@5: 100.0000 (95.6188)  time: 0.3477  data: 0.0009  max mem: 2500
Train: Epoch[1/5]  [3320/3750]  eta: 0:02:29  Lr: 0.001875  Loss: -0.6603  Acc@1: 81.2500 (77.1925)  Acc@5: 100.0000 (95.6150)  time: 0.3505  data: 0.0014  max mem: 2500
Train: Epoch[1/5]  [3330/3750]  eta: 0:02:26  Lr: 0.001875  Loss: -1.1118  Acc@1: 81.2500 (77.2103)  Acc@5: 100.0000 (95.6207)  time: 0.3487  data: 0.0012  max mem: 2500
Train: Epoch[1/5]  [3340/3750]  eta: 0:02:22  Lr: 0.001875  Loss: -0.8837  Acc@1: 81.2500 (77.2074)  Acc@5: 93.7500 (95.6151)  time: 0.3466  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [3350/3750]  eta: 0:02:19  Lr: 0.001875  Loss: -0.8842  Acc@1: 81.2500 (77.2176)  Acc@5: 93.7500 (95.6170)  time: 0.3461  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [3360/3750]  eta: 0:02:15  Lr: 0.001875  Loss: -0.8960  Acc@1: 81.2500 (77.2371)  Acc@5: 93.7500 (95.6189)  time: 0.3460  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [3370/3750]  eta: 0:02:12  Lr: 0.001875  Loss: -1.2862  Acc@1: 81.2500 (77.2508)  Acc@5: 100.0000 (95.6244)  time: 0.3490  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [3380/3750]  eta: 0:02:08  Lr: 0.001875  Loss: -0.6349  Acc@1: 81.2500 (77.2663)  Acc@5: 100.0000 (95.6281)  time: 0.3509  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [3390/3750]  eta: 0:02:05  Lr: 0.001875  Loss: -1.1391  Acc@1: 81.2500 (77.2744)  Acc@5: 100.0000 (95.6300)  time: 0.3490  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [3400/3750]  eta: 0:02:01  Lr: 0.001875  Loss: -0.4746  Acc@1: 81.2500 (77.2824)  Acc@5: 93.7500 (95.6300)  time: 0.3470  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3410/3750]  eta: 0:01:58  Lr: 0.001875  Loss: -0.8854  Acc@1: 81.2500 (77.2977)  Acc@5: 93.7500 (95.6299)  time: 0.3465  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3420/3750]  eta: 0:01:54  Lr: 0.001875  Loss: -0.9536  Acc@1: 81.2500 (77.3093)  Acc@5: 100.0000 (95.6372)  time: 0.3467  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [3430/3750]  eta: 0:01:51  Lr: 0.001875  Loss: -0.5261  Acc@1: 75.0000 (77.3062)  Acc@5: 100.0000 (95.6427)  time: 0.3475  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [3440/3750]  eta: 0:01:47  Lr: 0.001875  Loss: -0.7443  Acc@1: 75.0000 (77.3049)  Acc@5: 100.0000 (95.6426)  time: 0.3464  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [3450/3750]  eta: 0:01:44  Lr: 0.001875  Loss: -0.5712  Acc@1: 81.2500 (77.3254)  Acc@5: 93.7500 (95.6389)  time: 0.3460  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [3460/3750]  eta: 0:01:40  Lr: 0.001875  Loss: -1.0725  Acc@1: 81.2500 (77.3187)  Acc@5: 93.7500 (95.6389)  time: 0.3462  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [3470/3750]  eta: 0:01:37  Lr: 0.001875  Loss: -0.9501  Acc@1: 75.0000 (77.3282)  Acc@5: 100.0000 (95.6461)  time: 0.3479  data: 0.0010  max mem: 2500
Train: Epoch[1/5]  [3480/3750]  eta: 0:01:33  Lr: 0.001875  Loss: -0.8217  Acc@1: 81.2500 (77.3341)  Acc@5: 93.7500 (95.6388)  time: 0.3490  data: 0.0009  max mem: 2500
Train: Epoch[1/5]  [3490/3750]  eta: 0:01:30  Lr: 0.001875  Loss: -1.2053  Acc@1: 81.2500 (77.3399)  Acc@5: 93.7500 (95.6352)  time: 0.3477  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [3500/3750]  eta: 0:01:26  Lr: 0.001875  Loss: -0.8997  Acc@1: 81.2500 (77.3511)  Acc@5: 93.7500 (95.6405)  time: 0.3478  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [3510/3750]  eta: 0:01:23  Lr: 0.001875  Loss: -1.1719  Acc@1: 81.2500 (77.3658)  Acc@5: 100.0000 (95.6476)  time: 0.3473  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [3520/3750]  eta: 0:01:20  Lr: 0.001875  Loss: -0.8632  Acc@1: 81.2500 (77.3892)  Acc@5: 100.0000 (95.6529)  time: 0.3469  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [3530/3750]  eta: 0:01:16  Lr: 0.001875  Loss: -0.2864  Acc@1: 81.2500 (77.3807)  Acc@5: 100.0000 (95.6563)  time: 0.3475  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [3540/3750]  eta: 0:01:13  Lr: 0.001875  Loss: -0.8411  Acc@1: 75.0000 (77.3952)  Acc@5: 100.0000 (95.6651)  time: 0.3479  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3550/3750]  eta: 0:01:09  Lr: 0.001875  Loss: -0.7324  Acc@1: 81.2500 (77.4007)  Acc@5: 100.0000 (95.6632)  time: 0.3473  data: 0.0009  max mem: 2500
Train: Epoch[1/5]  [3560/3750]  eta: 0:01:06  Lr: 0.001875  Loss: -1.1334  Acc@1: 81.2500 (77.4045)  Acc@5: 100.0000 (95.6666)  time: 0.3468  data: 0.0009  max mem: 2500
Train: Epoch[1/5]  [3570/3750]  eta: 0:01:02  Lr: 0.001875  Loss: -1.0833  Acc@1: 81.2500 (77.4363)  Acc@5: 100.0000 (95.6752)  time: 0.3523  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [3580/3750]  eta: 0:00:59  Lr: 0.001875  Loss: -0.4567  Acc@1: 87.5000 (77.4417)  Acc@5: 100.0000 (95.6751)  time: 0.3541  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [3590/3750]  eta: 0:00:55  Lr: 0.001875  Loss: -1.0856  Acc@1: 87.5000 (77.4697)  Acc@5: 100.0000 (95.6802)  time: 0.3494  data: 0.0011  max mem: 2500
Train: Epoch[1/5]  [3600/3750]  eta: 0:00:52  Lr: 0.001875  Loss: -0.4342  Acc@1: 87.5000 (77.4872)  Acc@5: 100.0000 (95.6870)  time: 0.3464  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [3610/3750]  eta: 0:00:48  Lr: 0.001875  Loss: -1.2600  Acc@1: 81.2500 (77.5062)  Acc@5: 100.0000 (95.6937)  time: 0.3458  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [3620/3750]  eta: 0:00:45  Lr: 0.001875  Loss: -0.6549  Acc@1: 81.2500 (77.5079)  Acc@5: 100.0000 (95.6952)  time: 0.3471  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [3630/3750]  eta: 0:00:41  Lr: 0.001875  Loss: -0.8275  Acc@1: 81.2500 (77.5182)  Acc@5: 100.0000 (95.6985)  time: 0.3466  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [3640/3750]  eta: 0:00:38  Lr: 0.001875  Loss: -0.9328  Acc@1: 81.2500 (77.5130)  Acc@5: 100.0000 (95.6983)  time: 0.3472  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [3650/3750]  eta: 0:00:34  Lr: 0.001875  Loss: -1.1424  Acc@1: 81.2500 (77.5318)  Acc@5: 100.0000 (95.7049)  time: 0.3472  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [3660/3750]  eta: 0:00:31  Lr: 0.001875  Loss: -0.8319  Acc@1: 81.2500 (77.5335)  Acc@5: 100.0000 (95.7064)  time: 0.3458  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [3670/3750]  eta: 0:00:27  Lr: 0.001875  Loss: 0.2228  Acc@1: 75.0000 (77.5232)  Acc@5: 93.7500 (95.7045)  time: 0.3465  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [3680/3750]  eta: 0:00:24  Lr: 0.001875  Loss: -0.4471  Acc@1: 81.2500 (77.5384)  Acc@5: 93.7500 (95.7060)  time: 0.3467  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [3690/3750]  eta: 0:00:20  Lr: 0.001875  Loss: -0.8444  Acc@1: 81.2500 (77.5535)  Acc@5: 93.7500 (95.7075)  time: 0.3464  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [3700/3750]  eta: 0:00:17  Lr: 0.001875  Loss: -0.9188  Acc@1: 81.2500 (77.5686)  Acc@5: 100.0000 (95.7106)  time: 0.3469  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [3710/3750]  eta: 0:00:13  Lr: 0.001875  Loss: -0.7424  Acc@1: 81.2500 (77.5852)  Acc@5: 100.0000 (95.7205)  time: 0.3471  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [3720/3750]  eta: 0:00:10  Lr: 0.001875  Loss: -1.1148  Acc@1: 81.2500 (77.5850)  Acc@5: 100.0000 (95.7135)  time: 0.3480  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [3730/3750]  eta: 0:00:06  Lr: 0.001875  Loss: -1.1896  Acc@1: 81.2500 (77.5881)  Acc@5: 93.7500 (95.7183)  time: 0.3492  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [3740/3750]  eta: 0:00:03  Lr: 0.001875  Loss: -0.5197  Acc@1: 81.2500 (77.5829)  Acc@5: 100.0000 (95.7181)  time: 0.3486  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [3749/3750]  eta: 0:00:00  Lr: 0.001875  Loss: -0.4973  Acc@1: 81.2500 (77.5917)  Acc@5: 100.0000 (95.7233)  time: 0.3484  data: 0.0016  max mem: 2500
Train: Epoch[1/5] Total time: 0:21:45 (0.3481 s / it)
{0: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 1: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 2: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 3: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 4: {0: 0, 1: 60000, 2: 0, 3: 0, 4: 0}, 5: {0: 0, 1: 60000, 2: 0, 3: 0, 4: 0}, 6: {0: 0, 1: 60000, 2: 0, 3: 0, 4: 0}, 7: {0: 0, 1: 60000, 2: 0, 3: 0, 4: 0}, 8: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 9: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 10: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 11: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 12: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 13: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 14: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 15: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 16: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 17: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 18: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 19: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}}
Averaged stats: Lr: 0.001875  Loss: -0.4973  Acc@1: 81.2500 (77.5917)  Acc@5: 100.0000 (95.7233)
Train: Epoch[2/5]  [   0/3750]  eta: 1:00:27  Lr: 0.001875  Loss: -1.0972  Acc@1: 87.5000 (87.5000)  Acc@5: 93.7500 (93.7500)  time: 0.9673  data: 0.6249  max mem: 2500
Train: Epoch[2/5]  [  10/3750]  eta: 0:25:09  Lr: 0.001875  Loss: -0.8346  Acc@1: 81.2500 (77.8409)  Acc@5: 93.7500 (94.8864)  time: 0.4037  data: 0.0577  max mem: 2500
Train: Epoch[2/5]  [  20/3750]  eta: 0:23:27  Lr: 0.001875  Loss: -0.8726  Acc@1: 81.2500 (80.6548)  Acc@5: 100.0000 (96.1310)  time: 0.3480  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [  30/3750]  eta: 0:22:51  Lr: 0.001875  Loss: -0.9906  Acc@1: 81.2500 (80.4435)  Acc@5: 100.0000 (96.1694)  time: 0.3493  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [  40/3750]  eta: 0:22:26  Lr: 0.001875  Loss: -1.0629  Acc@1: 87.5000 (81.7073)  Acc@5: 93.7500 (96.0366)  time: 0.3479  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [  50/3750]  eta: 0:22:12  Lr: 0.001875  Loss: -0.2154  Acc@1: 81.2500 (81.1275)  Acc@5: 93.7500 (95.8333)  time: 0.3468  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [  60/3750]  eta: 0:22:01  Lr: 0.001875  Loss: -0.5526  Acc@1: 75.0000 (80.5328)  Acc@5: 93.7500 (96.0041)  time: 0.3477  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [  70/3750]  eta: 0:21:51  Lr: 0.001875  Loss: -0.8333  Acc@1: 81.2500 (80.8099)  Acc@5: 93.7500 (95.9507)  time: 0.3467  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [  80/3750]  eta: 0:21:42  Lr: 0.001875  Loss: -0.8124  Acc@1: 81.2500 (80.6327)  Acc@5: 100.0000 (96.2963)  time: 0.3457  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [  90/3750]  eta: 0:21:35  Lr: 0.001875  Loss: -0.9091  Acc@1: 81.2500 (80.8379)  Acc@5: 100.0000 (96.0852)  time: 0.3454  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [ 100/3750]  eta: 0:21:29  Lr: 0.001875  Loss: -0.4548  Acc@1: 81.2500 (80.8787)  Acc@5: 93.7500 (95.9777)  time: 0.3471  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [ 110/3750]  eta: 0:21:24  Lr: 0.001875  Loss: -0.5673  Acc@1: 81.2500 (80.2928)  Acc@5: 100.0000 (95.9459)  time: 0.3478  data: 0.0009  max mem: 2500
Train: Epoch[2/5]  [ 120/3750]  eta: 0:21:19  Lr: 0.001875  Loss: -0.8843  Acc@1: 75.0000 (80.0103)  Acc@5: 100.0000 (95.9194)  time: 0.3475  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [ 130/3750]  eta: 0:21:14  Lr: 0.001875  Loss: -0.9628  Acc@1: 75.0000 (79.8187)  Acc@5: 93.7500 (95.9924)  time: 0.3483  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [ 140/3750]  eta: 0:21:09  Lr: 0.001875  Loss: -0.5081  Acc@1: 75.0000 (79.2110)  Acc@5: 93.7500 (95.9220)  time: 0.3467  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 150/3750]  eta: 0:21:04  Lr: 0.001875  Loss: -0.4765  Acc@1: 75.0000 (79.3874)  Acc@5: 100.0000 (95.9851)  time: 0.3454  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 160/3750]  eta: 0:20:59  Lr: 0.001875  Loss: -0.9554  Acc@1: 81.2500 (79.7360)  Acc@5: 100.0000 (96.1180)  time: 0.3460  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [ 170/3750]  eta: 0:20:55  Lr: 0.001875  Loss: -0.8003  Acc@1: 81.2500 (79.9342)  Acc@5: 100.0000 (96.1257)  time: 0.3464  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [ 180/3750]  eta: 0:20:51  Lr: 0.001875  Loss: -1.1826  Acc@1: 81.2500 (80.1796)  Acc@5: 100.0000 (96.1671)  time: 0.3467  data: 0.0009  max mem: 2500
Train: Epoch[2/5]  [ 190/3750]  eta: 0:20:47  Lr: 0.001875  Loss: -1.0443  Acc@1: 81.2500 (80.2356)  Acc@5: 100.0000 (96.2042)  time: 0.3488  data: 0.0010  max mem: 2500
Train: Epoch[2/5]  [ 200/3750]  eta: 0:20:43  Lr: 0.001875  Loss: -1.1399  Acc@1: 81.2500 (80.3172)  Acc@5: 100.0000 (96.2065)  time: 0.3475  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [ 210/3750]  eta: 0:20:40  Lr: 0.001875  Loss: -1.2289  Acc@1: 75.0000 (80.3021)  Acc@5: 100.0000 (96.1789)  time: 0.3488  data: 0.0034  max mem: 2500
Train: Epoch[2/5]  [ 220/3750]  eta: 0:20:35  Lr: 0.001875  Loss: -1.1381  Acc@1: 81.2500 (80.3733)  Acc@5: 100.0000 (96.2104)  time: 0.3491  data: 0.0034  max mem: 2500
Train: Epoch[2/5]  [ 230/3750]  eta: 0:20:31  Lr: 0.001875  Loss: -0.8307  Acc@1: 81.2500 (80.3030)  Acc@5: 100.0000 (96.2392)  time: 0.3455  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [ 240/3750]  eta: 0:20:27  Lr: 0.001875  Loss: -1.0848  Acc@1: 81.2500 (80.2905)  Acc@5: 100.0000 (96.2137)  time: 0.3462  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [ 250/3750]  eta: 0:20:23  Lr: 0.001875  Loss: -0.6227  Acc@1: 81.2500 (80.4532)  Acc@5: 100.0000 (96.2649)  time: 0.3470  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [ 260/3750]  eta: 0:20:20  Lr: 0.001875  Loss: -0.9072  Acc@1: 81.2500 (80.4598)  Acc@5: 100.0000 (96.2165)  time: 0.3481  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [ 270/3750]  eta: 0:20:16  Lr: 0.001875  Loss: -1.0607  Acc@1: 81.2500 (80.5120)  Acc@5: 93.7500 (96.1716)  time: 0.3490  data: 0.0014  max mem: 2500
Train: Epoch[2/5]  [ 280/3750]  eta: 0:20:13  Lr: 0.001875  Loss: -1.0126  Acc@1: 81.2500 (80.4270)  Acc@5: 93.7500 (96.2411)  time: 0.3489  data: 0.0013  max mem: 2500
Train: Epoch[2/5]  [ 290/3750]  eta: 0:20:09  Lr: 0.001875  Loss: -0.6501  Acc@1: 81.2500 (80.2835)  Acc@5: 100.0000 (96.1985)  time: 0.3485  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [ 300/3750]  eta: 0:20:05  Lr: 0.001875  Loss: -1.1868  Acc@1: 81.2500 (80.3779)  Acc@5: 100.0000 (96.2417)  time: 0.3477  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [ 310/3750]  eta: 0:20:01  Lr: 0.001875  Loss: -1.0636  Acc@1: 81.2500 (80.4260)  Acc@5: 100.0000 (96.2621)  time: 0.3470  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [ 320/3750]  eta: 0:19:58  Lr: 0.001875  Loss: -0.2918  Acc@1: 81.2500 (80.2960)  Acc@5: 93.7500 (96.2617)  time: 0.3479  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [ 330/3750]  eta: 0:19:54  Lr: 0.001875  Loss: -1.0236  Acc@1: 81.2500 (80.2870)  Acc@5: 93.7500 (96.1669)  time: 0.3471  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [ 340/3750]  eta: 0:19:50  Lr: 0.001875  Loss: -0.5230  Acc@1: 81.2500 (80.2236)  Acc@5: 93.7500 (96.1694)  time: 0.3454  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 350/3750]  eta: 0:19:46  Lr: 0.001875  Loss: -1.0255  Acc@1: 75.0000 (80.1638)  Acc@5: 93.7500 (96.1717)  time: 0.3460  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [ 360/3750]  eta: 0:19:43  Lr: 0.001875  Loss: -0.4393  Acc@1: 75.0000 (80.1939)  Acc@5: 93.7500 (96.1219)  time: 0.3464  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [ 370/3750]  eta: 0:19:39  Lr: 0.001875  Loss: -1.3358  Acc@1: 75.0000 (80.1381)  Acc@5: 100.0000 (96.1759)  time: 0.3464  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [ 380/3750]  eta: 0:19:35  Lr: 0.001875  Loss: -0.9213  Acc@1: 81.2500 (80.1837)  Acc@5: 100.0000 (96.2106)  time: 0.3475  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [ 390/3750]  eta: 0:19:32  Lr: 0.001875  Loss: -1.3399  Acc@1: 81.2500 (80.3229)  Acc@5: 100.0000 (96.2596)  time: 0.3484  data: 0.0009  max mem: 2500
Train: Epoch[2/5]  [ 400/3750]  eta: 0:19:28  Lr: 0.001875  Loss: -1.1938  Acc@1: 81.2500 (80.2837)  Acc@5: 100.0000 (96.2749)  time: 0.3487  data: 0.0010  max mem: 2500
Train: Epoch[2/5]  [ 410/3750]  eta: 0:19:25  Lr: 0.001875  Loss: -0.3805  Acc@1: 81.2500 (80.3528)  Acc@5: 100.0000 (96.2743)  time: 0.3479  data: 0.0009  max mem: 2500
Train: Epoch[2/5]  [ 420/3750]  eta: 0:19:21  Lr: 0.001875  Loss: -0.8147  Acc@1: 81.2500 (80.3741)  Acc@5: 100.0000 (96.2886)  time: 0.3482  data: 0.0009  max mem: 2500
Train: Epoch[2/5]  [ 430/3750]  eta: 0:19:18  Lr: 0.001875  Loss: -0.6174  Acc@1: 81.2500 (80.4379)  Acc@5: 93.7500 (96.2877)  time: 0.3480  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [ 440/3750]  eta: 0:19:14  Lr: 0.001875  Loss: -1.1154  Acc@1: 81.2500 (80.4563)  Acc@5: 93.7500 (96.2868)  time: 0.3469  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 450/3750]  eta: 0:19:10  Lr: 0.001875  Loss: -0.7790  Acc@1: 81.2500 (80.4878)  Acc@5: 93.7500 (96.2860)  time: 0.3472  data: 0.0010  max mem: 2500
Train: Epoch[2/5]  [ 460/3750]  eta: 0:19:07  Lr: 0.001875  Loss: -1.1319  Acc@1: 81.2500 (80.5721)  Acc@5: 100.0000 (96.2988)  time: 0.3467  data: 0.0010  max mem: 2500
Train: Epoch[2/5]  [ 470/3750]  eta: 0:19:03  Lr: 0.001875  Loss: -1.1280  Acc@1: 87.5000 (80.6263)  Acc@5: 100.0000 (96.3243)  time: 0.3474  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [ 480/3750]  eta: 0:19:00  Lr: 0.001875  Loss: -0.8670  Acc@1: 87.5000 (80.7043)  Acc@5: 100.0000 (96.3488)  time: 0.3481  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [ 490/3750]  eta: 0:18:56  Lr: 0.001875  Loss: -0.6429  Acc@1: 81.2500 (80.6645)  Acc@5: 100.0000 (96.3086)  time: 0.3462  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [ 500/3750]  eta: 0:18:53  Lr: 0.001875  Loss: -1.2594  Acc@1: 81.2500 (80.7759)  Acc@5: 100.0000 (96.3074)  time: 0.3485  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [ 510/3750]  eta: 0:18:49  Lr: 0.001875  Loss: -0.3940  Acc@1: 81.2500 (80.6996)  Acc@5: 93.7500 (96.2940)  time: 0.3486  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [ 520/3750]  eta: 0:18:45  Lr: 0.001875  Loss: -0.8514  Acc@1: 75.0000 (80.7222)  Acc@5: 100.0000 (96.3292)  time: 0.3465  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [ 530/3750]  eta: 0:18:42  Lr: 0.001875  Loss: -0.3383  Acc@1: 81.2500 (80.7203)  Acc@5: 100.0000 (96.3041)  time: 0.3485  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [ 540/3750]  eta: 0:18:38  Lr: 0.001875  Loss: -1.2732  Acc@1: 81.2500 (80.7879)  Acc@5: 100.0000 (96.3262)  time: 0.3469  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [ 550/3750]  eta: 0:18:35  Lr: 0.001875  Loss: -0.6652  Acc@1: 81.2500 (80.8190)  Acc@5: 100.0000 (96.3475)  time: 0.3477  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [ 560/3750]  eta: 0:18:31  Lr: 0.001875  Loss: -0.3817  Acc@1: 81.2500 (80.8824)  Acc@5: 100.0000 (96.3458)  time: 0.3504  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [ 570/3750]  eta: 0:18:28  Lr: 0.001875  Loss: -1.2445  Acc@1: 81.2500 (80.8997)  Acc@5: 100.0000 (96.3660)  time: 0.3499  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [ 580/3750]  eta: 0:18:24  Lr: 0.001875  Loss: -0.9311  Acc@1: 75.0000 (80.8627)  Acc@5: 100.0000 (96.3318)  time: 0.3491  data: 0.0009  max mem: 2500
Train: Epoch[2/5]  [ 590/3750]  eta: 0:18:21  Lr: 0.001875  Loss: -1.0376  Acc@1: 81.2500 (80.8164)  Acc@5: 93.7500 (96.3198)  time: 0.3471  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [ 600/3750]  eta: 0:18:17  Lr: 0.001875  Loss: -0.8422  Acc@1: 81.2500 (80.8860)  Acc@5: 93.7500 (96.2874)  time: 0.3473  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [ 610/3750]  eta: 0:18:14  Lr: 0.001875  Loss: -1.1037  Acc@1: 81.2500 (80.8101)  Acc@5: 100.0000 (96.3073)  time: 0.3480  data: 0.0009  max mem: 2500
Train: Epoch[2/5]  [ 620/3750]  eta: 0:18:10  Lr: 0.001875  Loss: -0.9564  Acc@1: 81.2500 (80.8072)  Acc@5: 100.0000 (96.3466)  time: 0.3470  data: 0.0010  max mem: 2500
Train: Epoch[2/5]  [ 630/3750]  eta: 0:18:07  Lr: 0.001875  Loss: -0.8498  Acc@1: 81.2500 (80.8142)  Acc@5: 100.0000 (96.3154)  time: 0.3478  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [ 640/3750]  eta: 0:18:03  Lr: 0.001875  Loss: -1.0794  Acc@1: 81.2500 (80.9185)  Acc@5: 93.7500 (96.3046)  time: 0.3473  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [ 650/3750]  eta: 0:18:00  Lr: 0.001875  Loss: -1.0653  Acc@1: 87.5000 (80.9812)  Acc@5: 93.7500 (96.3134)  time: 0.3461  data: 0.0011  max mem: 2500
Train: Epoch[2/5]  [ 660/3750]  eta: 0:17:56  Lr: 0.001875  Loss: -0.9068  Acc@1: 87.5000 (81.0609)  Acc@5: 100.0000 (96.3219)  time: 0.3459  data: 0.0009  max mem: 2500
Train: Epoch[2/5]  [ 670/3750]  eta: 0:17:52  Lr: 0.001875  Loss: -1.1521  Acc@1: 87.5000 (81.0358)  Acc@5: 100.0000 (96.3580)  time: 0.3456  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [ 680/3750]  eta: 0:17:49  Lr: 0.001875  Loss: -0.6209  Acc@1: 81.2500 (81.0114)  Acc@5: 100.0000 (96.3565)  time: 0.3463  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [ 690/3750]  eta: 0:17:45  Lr: 0.001875  Loss: -0.2663  Acc@1: 81.2500 (80.9877)  Acc@5: 93.7500 (96.3278)  time: 0.3478  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [ 700/3750]  eta: 0:17:42  Lr: 0.001875  Loss: -1.2202  Acc@1: 87.5000 (81.0628)  Acc@5: 100.0000 (96.3534)  time: 0.3486  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [ 710/3750]  eta: 0:17:38  Lr: 0.001875  Loss: -0.8070  Acc@1: 87.5000 (81.1621)  Acc@5: 100.0000 (96.3695)  time: 0.3485  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [ 720/3750]  eta: 0:17:35  Lr: 0.001875  Loss: -0.6855  Acc@1: 87.5000 (81.1633)  Acc@5: 100.0000 (96.3766)  time: 0.3477  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [ 730/3750]  eta: 0:17:31  Lr: 0.001875  Loss: -0.8541  Acc@1: 87.5000 (81.1816)  Acc@5: 100.0000 (96.3577)  time: 0.3479  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [ 740/3750]  eta: 0:17:28  Lr: 0.001875  Loss: -0.9458  Acc@1: 81.2500 (81.1741)  Acc@5: 93.7500 (96.3141)  time: 0.3474  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [ 750/3750]  eta: 0:17:24  Lr: 0.001875  Loss: -0.7901  Acc@1: 81.2500 (81.1751)  Acc@5: 100.0000 (96.3382)  time: 0.3460  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 760/3750]  eta: 0:17:21  Lr: 0.001875  Loss: -0.6836  Acc@1: 81.2500 (81.1679)  Acc@5: 100.0000 (96.3371)  time: 0.3460  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 770/3750]  eta: 0:17:17  Lr: 0.001875  Loss: -0.8666  Acc@1: 81.2500 (81.1365)  Acc@5: 100.0000 (96.3359)  time: 0.3458  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 780/3750]  eta: 0:17:14  Lr: 0.001875  Loss: -1.0472  Acc@1: 81.2500 (81.1620)  Acc@5: 100.0000 (96.3268)  time: 0.3465  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [ 790/3750]  eta: 0:17:10  Lr: 0.001875  Loss: -0.9372  Acc@1: 81.2500 (81.1473)  Acc@5: 100.0000 (96.3654)  time: 0.3473  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [ 800/3750]  eta: 0:17:07  Lr: 0.001875  Loss: -0.9179  Acc@1: 81.2500 (81.1642)  Acc@5: 100.0000 (96.3795)  time: 0.3474  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [ 810/3750]  eta: 0:17:03  Lr: 0.001875  Loss: -0.7361  Acc@1: 81.2500 (81.1806)  Acc@5: 93.7500 (96.3548)  time: 0.3469  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [ 820/3750]  eta: 0:17:00  Lr: 0.001875  Loss: -0.8834  Acc@1: 81.2500 (81.1739)  Acc@5: 93.7500 (96.3307)  time: 0.3473  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [ 830/3750]  eta: 0:16:56  Lr: 0.001875  Loss: -0.7909  Acc@1: 81.2500 (81.1372)  Acc@5: 93.7500 (96.3072)  time: 0.3483  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [ 840/3750]  eta: 0:16:53  Lr: 0.001875  Loss: -0.9624  Acc@1: 75.0000 (81.1608)  Acc@5: 100.0000 (96.3213)  time: 0.3481  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [ 850/3750]  eta: 0:16:49  Lr: 0.001875  Loss: -1.0426  Acc@1: 75.0000 (81.0884)  Acc@5: 100.0000 (96.3352)  time: 0.3468  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [ 860/3750]  eta: 0:16:45  Lr: 0.001875  Loss: 0.1217  Acc@1: 75.0000 (81.0467)  Acc@5: 100.0000 (96.3124)  time: 0.3463  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [ 870/3750]  eta: 0:16:42  Lr: 0.001875  Loss: -0.9388  Acc@1: 81.2500 (81.0634)  Acc@5: 100.0000 (96.3404)  time: 0.3470  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [ 880/3750]  eta: 0:16:38  Lr: 0.001875  Loss: -0.9872  Acc@1: 81.2500 (81.0443)  Acc@5: 100.0000 (96.3607)  time: 0.3475  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [ 890/3750]  eta: 0:16:35  Lr: 0.001875  Loss: -1.1631  Acc@1: 81.2500 (81.0396)  Acc@5: 100.0000 (96.3594)  time: 0.3497  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [ 900/3750]  eta: 0:16:32  Lr: 0.001875  Loss: -0.5879  Acc@1: 75.0000 (80.9309)  Acc@5: 93.7500 (96.3374)  time: 0.3505  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [ 910/3750]  eta: 0:16:28  Lr: 0.001875  Loss: -0.7714  Acc@1: 75.0000 (80.9138)  Acc@5: 93.7500 (96.3364)  time: 0.3488  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [ 920/3750]  eta: 0:16:25  Lr: 0.001875  Loss: -1.1611  Acc@1: 75.0000 (80.8836)  Acc@5: 100.0000 (96.3423)  time: 0.3503  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [ 930/3750]  eta: 0:16:21  Lr: 0.001875  Loss: -1.2312  Acc@1: 75.0000 (80.8539)  Acc@5: 93.7500 (96.3413)  time: 0.3503  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [ 940/3750]  eta: 0:16:18  Lr: 0.001875  Loss: -0.6897  Acc@1: 81.2500 (80.8648)  Acc@5: 100.0000 (96.3536)  time: 0.3498  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [ 950/3750]  eta: 0:16:15  Lr: 0.001875  Loss: -1.2220  Acc@1: 81.2500 (80.8951)  Acc@5: 100.0000 (96.3525)  time: 0.3502  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [ 960/3750]  eta: 0:16:11  Lr: 0.001875  Loss: -1.2998  Acc@1: 81.2500 (80.9183)  Acc@5: 100.0000 (96.3580)  time: 0.3482  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [ 970/3750]  eta: 0:16:07  Lr: 0.001875  Loss: -1.1506  Acc@1: 81.2500 (80.9539)  Acc@5: 100.0000 (96.3762)  time: 0.3460  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [ 980/3750]  eta: 0:16:04  Lr: 0.001875  Loss: -0.8871  Acc@1: 81.2500 (80.9888)  Acc@5: 100.0000 (96.3685)  time: 0.3460  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [ 990/3750]  eta: 0:16:00  Lr: 0.001875  Loss: -0.2633  Acc@1: 81.2500 (80.9473)  Acc@5: 100.0000 (96.3799)  time: 0.3470  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [1000/3750]  eta: 0:15:57  Lr: 0.001875  Loss: -1.3959  Acc@1: 81.2500 (80.9690)  Acc@5: 100.0000 (96.3786)  time: 0.3462  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1010/3750]  eta: 0:15:53  Lr: 0.001875  Loss: -0.7152  Acc@1: 75.0000 (80.9409)  Acc@5: 93.7500 (96.3526)  time: 0.3481  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1020/3750]  eta: 0:15:50  Lr: 0.001875  Loss: -0.8058  Acc@1: 75.0000 (80.8766)  Acc@5: 93.7500 (96.3577)  time: 0.3487  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1030/3750]  eta: 0:15:46  Lr: 0.001875  Loss: -1.0433  Acc@1: 81.2500 (80.8620)  Acc@5: 100.0000 (96.3809)  time: 0.3474  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [1040/3750]  eta: 0:15:43  Lr: 0.001875  Loss: -0.4907  Acc@1: 81.2500 (80.8898)  Acc@5: 100.0000 (96.3677)  time: 0.3470  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [1050/3750]  eta: 0:15:39  Lr: 0.001875  Loss: -0.9548  Acc@1: 87.5000 (80.9289)  Acc@5: 100.0000 (96.3784)  time: 0.3481  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [1060/3750]  eta: 0:15:36  Lr: 0.001875  Loss: -0.9409  Acc@1: 81.2500 (80.9378)  Acc@5: 100.0000 (96.3713)  time: 0.3481  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [1070/3750]  eta: 0:15:32  Lr: 0.001875  Loss: -0.8967  Acc@1: 81.2500 (80.8999)  Acc@5: 100.0000 (96.3702)  time: 0.3462  data: 0.0009  max mem: 2500
Train: Epoch[2/5]  [1080/3750]  eta: 0:15:29  Lr: 0.001875  Loss: -0.8920  Acc@1: 75.0000 (80.8279)  Acc@5: 93.7500 (96.3518)  time: 0.3481  data: 0.0009  max mem: 2500
Train: Epoch[2/5]  [1090/3750]  eta: 0:15:26  Lr: 0.001875  Loss: -0.2929  Acc@1: 75.0000 (80.7745)  Acc@5: 93.7500 (96.3451)  time: 0.3495  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [1100/3750]  eta: 0:15:22  Lr: 0.001875  Loss: -0.8103  Acc@1: 81.2500 (80.7788)  Acc@5: 100.0000 (96.3442)  time: 0.3482  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [1110/3750]  eta: 0:15:19  Lr: 0.001875  Loss: -0.6153  Acc@1: 81.2500 (80.7550)  Acc@5: 100.0000 (96.3546)  time: 0.3480  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1120/3750]  eta: 0:15:15  Lr: 0.001875  Loss: -1.0917  Acc@1: 81.2500 (80.7761)  Acc@5: 100.0000 (96.3760)  time: 0.3478  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [1130/3750]  eta: 0:15:12  Lr: 0.001875  Loss: -0.9051  Acc@1: 87.5000 (80.8245)  Acc@5: 100.0000 (96.3859)  time: 0.3476  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [1140/3750]  eta: 0:15:08  Lr: 0.001875  Loss: -1.0286  Acc@1: 81.2500 (80.8008)  Acc@5: 100.0000 (96.3848)  time: 0.3484  data: 0.0012  max mem: 2500
Train: Epoch[2/5]  [1150/3750]  eta: 0:15:05  Lr: 0.001875  Loss: -1.1163  Acc@1: 81.2500 (80.8590)  Acc@5: 100.0000 (96.3944)  time: 0.3484  data: 0.0011  max mem: 2500
Train: Epoch[2/5]  [1160/3750]  eta: 0:15:01  Lr: 0.001875  Loss: -1.2071  Acc@1: 87.5000 (80.8839)  Acc@5: 100.0000 (96.3986)  time: 0.3478  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [1170/3750]  eta: 0:14:58  Lr: 0.001875  Loss: -0.6960  Acc@1: 81.2500 (80.9084)  Acc@5: 100.0000 (96.4026)  time: 0.3473  data: 0.0009  max mem: 2500
Train: Epoch[2/5]  [1180/3750]  eta: 0:14:54  Lr: 0.001875  Loss: -0.5910  Acc@1: 81.2500 (80.9166)  Acc@5: 100.0000 (96.4066)  time: 0.3482  data: 0.0009  max mem: 2500
Train: Epoch[2/5]  [1190/3750]  eta: 0:14:51  Lr: 0.001875  Loss: -0.8946  Acc@1: 81.2500 (80.9246)  Acc@5: 100.0000 (96.4053)  time: 0.3479  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [1200/3750]  eta: 0:14:47  Lr: 0.001875  Loss: -1.1730  Acc@1: 81.2500 (80.9586)  Acc@5: 100.0000 (96.4092)  time: 0.3468  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [1210/3750]  eta: 0:14:44  Lr: 0.001875  Loss: -0.9580  Acc@1: 81.2500 (80.9300)  Acc@5: 100.0000 (96.4182)  time: 0.3465  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1220/3750]  eta: 0:14:40  Lr: 0.001875  Loss: -1.2158  Acc@1: 81.2500 (80.9531)  Acc@5: 100.0000 (96.4322)  time: 0.3479  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1230/3750]  eta: 0:14:37  Lr: 0.001875  Loss: -1.3477  Acc@1: 81.2500 (80.9606)  Acc@5: 100.0000 (96.4460)  time: 0.3487  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [1240/3750]  eta: 0:14:33  Lr: 0.001875  Loss: -0.7710  Acc@1: 81.2500 (80.9629)  Acc@5: 100.0000 (96.4494)  time: 0.3464  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [1250/3750]  eta: 0:14:30  Lr: 0.001875  Loss: -1.4565  Acc@1: 81.2500 (80.9452)  Acc@5: 100.0000 (96.4528)  time: 0.3463  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [1260/3750]  eta: 0:14:26  Lr: 0.001875  Loss: -1.1144  Acc@1: 81.2500 (80.9130)  Acc@5: 100.0000 (96.4810)  time: 0.3474  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [1270/3750]  eta: 0:14:23  Lr: 0.001875  Loss: -0.5525  Acc@1: 75.0000 (80.8910)  Acc@5: 100.0000 (96.4792)  time: 0.3479  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [1280/3750]  eta: 0:14:19  Lr: 0.001875  Loss: -1.1069  Acc@1: 75.0000 (80.8841)  Acc@5: 100.0000 (96.4871)  time: 0.3485  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [1290/3750]  eta: 0:14:16  Lr: 0.001875  Loss: -1.3070  Acc@1: 81.2500 (80.9402)  Acc@5: 100.0000 (96.4901)  time: 0.3482  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [1300/3750]  eta: 0:14:12  Lr: 0.001875  Loss: -0.8366  Acc@1: 81.2500 (80.9185)  Acc@5: 93.7500 (96.4787)  time: 0.3483  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [1310/3750]  eta: 0:14:09  Lr: 0.001875  Loss: -0.9945  Acc@1: 81.2500 (80.8877)  Acc@5: 93.7500 (96.4674)  time: 0.3469  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [1320/3750]  eta: 0:14:05  Lr: 0.001875  Loss: -0.8577  Acc@1: 75.0000 (80.8762)  Acc@5: 93.7500 (96.4563)  time: 0.3469  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [1330/3750]  eta: 0:14:02  Lr: 0.001875  Loss: -0.6000  Acc@1: 81.2500 (80.8931)  Acc@5: 100.0000 (96.4688)  time: 0.3503  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [1340/3750]  eta: 0:13:58  Lr: 0.001875  Loss: -0.7755  Acc@1: 87.5000 (80.9471)  Acc@5: 100.0000 (96.4952)  time: 0.3506  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [1350/3750]  eta: 0:13:55  Lr: 0.001875  Loss: -0.7544  Acc@1: 81.2500 (80.9724)  Acc@5: 100.0000 (96.4933)  time: 0.3498  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [1360/3750]  eta: 0:13:51  Lr: 0.001875  Loss: -0.7294  Acc@1: 81.2500 (80.9377)  Acc@5: 93.7500 (96.4916)  time: 0.3491  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [1370/3750]  eta: 0:13:48  Lr: 0.001875  Loss: -1.0542  Acc@1: 81.2500 (80.9400)  Acc@5: 93.7500 (96.4898)  time: 0.3482  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [1380/3750]  eta: 0:13:45  Lr: 0.001875  Loss: -0.5259  Acc@1: 81.2500 (80.8925)  Acc@5: 93.7500 (96.4835)  time: 0.3496  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [1390/3750]  eta: 0:13:41  Lr: 0.001875  Loss: -0.7605  Acc@1: 81.2500 (80.9265)  Acc@5: 100.0000 (96.4953)  time: 0.3478  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [1400/3750]  eta: 0:13:37  Lr: 0.001875  Loss: -0.4667  Acc@1: 81.2500 (80.9199)  Acc@5: 100.0000 (96.5114)  time: 0.3450  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1410/3750]  eta: 0:13:34  Lr: 0.001875  Loss: -1.4069  Acc@1: 81.2500 (80.9754)  Acc@5: 100.0000 (96.5229)  time: 0.3460  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [1420/3750]  eta: 0:13:30  Lr: 0.001875  Loss: -1.3368  Acc@1: 87.5000 (81.0037)  Acc@5: 100.0000 (96.5385)  time: 0.3470  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [1430/3750]  eta: 0:13:27  Lr: 0.001875  Loss: -0.7500  Acc@1: 87.5000 (81.0404)  Acc@5: 100.0000 (96.5365)  time: 0.3478  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [1440/3750]  eta: 0:13:23  Lr: 0.001875  Loss: -0.8870  Acc@1: 81.2500 (81.0418)  Acc@5: 100.0000 (96.5389)  time: 0.3473  data: 0.0010  max mem: 2500
Train: Epoch[2/5]  [1450/3750]  eta: 0:13:20  Lr: 0.001875  Loss: -0.8826  Acc@1: 81.2500 (81.0476)  Acc@5: 100.0000 (96.5498)  time: 0.3464  data: 0.0009  max mem: 2500
Train: Epoch[2/5]  [1460/3750]  eta: 0:13:17  Lr: 0.001875  Loss: -0.9002  Acc@1: 81.2500 (81.0447)  Acc@5: 100.0000 (96.5606)  time: 0.3475  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [1470/3750]  eta: 0:13:13  Lr: 0.001875  Loss: -0.9693  Acc@1: 81.2500 (81.0503)  Acc@5: 100.0000 (96.5712)  time: 0.3483  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [1480/3750]  eta: 0:13:10  Lr: 0.001875  Loss: -0.5487  Acc@1: 75.0000 (81.0263)  Acc@5: 100.0000 (96.5606)  time: 0.3478  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [1490/3750]  eta: 0:13:06  Lr: 0.001875  Loss: -1.1916  Acc@1: 81.2500 (81.0404)  Acc@5: 100.0000 (96.5669)  time: 0.3467  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [1500/3750]  eta: 0:13:03  Lr: 0.001875  Loss: -1.0720  Acc@1: 81.2500 (81.0543)  Acc@5: 100.0000 (96.5690)  time: 0.3476  data: 0.0011  max mem: 2500
Train: Epoch[2/5]  [1510/3750]  eta: 0:12:59  Lr: 0.001875  Loss: -0.8040  Acc@1: 81.2500 (81.0597)  Acc@5: 100.0000 (96.5793)  time: 0.3494  data: 0.0011  max mem: 2500
Train: Epoch[2/5]  [1520/3750]  eta: 0:12:56  Lr: 0.001875  Loss: -0.4613  Acc@1: 81.2500 (81.0651)  Acc@5: 93.7500 (96.5689)  time: 0.3478  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [1530/3750]  eta: 0:12:52  Lr: 0.001875  Loss: -1.2954  Acc@1: 81.2500 (81.0418)  Acc@5: 93.7500 (96.5505)  time: 0.3461  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1540/3750]  eta: 0:12:49  Lr: 0.001875  Loss: -1.0814  Acc@1: 81.2500 (81.0350)  Acc@5: 93.7500 (96.5485)  time: 0.3488  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [1550/3750]  eta: 0:12:45  Lr: 0.001875  Loss: -0.8654  Acc@1: 81.2500 (81.0284)  Acc@5: 100.0000 (96.5506)  time: 0.3500  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [1560/3750]  eta: 0:12:42  Lr: 0.001875  Loss: -0.7854  Acc@1: 81.2500 (81.0378)  Acc@5: 100.0000 (96.5447)  time: 0.3484  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1570/3750]  eta: 0:12:38  Lr: 0.001875  Loss: -0.6475  Acc@1: 81.2500 (81.0471)  Acc@5: 93.7500 (96.5428)  time: 0.3498  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [1580/3750]  eta: 0:12:35  Lr: 0.001875  Loss: -1.1247  Acc@1: 81.2500 (81.0563)  Acc@5: 100.0000 (96.5528)  time: 0.3552  data: 0.0015  max mem: 2500
Train: Epoch[2/5]  [1590/3750]  eta: 0:12:31  Lr: 0.001875  Loss: -0.5661  Acc@1: 81.2500 (81.0575)  Acc@5: 100.0000 (96.5509)  time: 0.3529  data: 0.0016  max mem: 2500
Train: Epoch[2/5]  [1600/3750]  eta: 0:12:28  Lr: 0.001875  Loss: -0.6567  Acc@1: 81.2500 (81.0392)  Acc@5: 93.7500 (96.5412)  time: 0.3476  data: 0.0010  max mem: 2500
Train: Epoch[2/5]  [1610/3750]  eta: 0:12:24  Lr: 0.001875  Loss: -1.3722  Acc@1: 81.2500 (81.0715)  Acc@5: 93.7500 (96.5394)  time: 0.3477  data: 0.0009  max mem: 2500
Train: Epoch[2/5]  [1620/3750]  eta: 0:12:21  Lr: 0.001875  Loss: -0.8219  Acc@1: 87.5000 (81.0726)  Acc@5: 93.7500 (96.5338)  time: 0.3466  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [1630/3750]  eta: 0:12:17  Lr: 0.001875  Loss: -0.5640  Acc@1: 75.0000 (81.0316)  Acc@5: 93.7500 (96.5282)  time: 0.3467  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [1640/3750]  eta: 0:12:14  Lr: 0.001875  Loss: -1.1698  Acc@1: 75.0000 (81.0367)  Acc@5: 100.0000 (96.5303)  time: 0.3487  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [1650/3750]  eta: 0:12:11  Lr: 0.001875  Loss: -0.9097  Acc@1: 81.2500 (81.0380)  Acc@5: 100.0000 (96.5248)  time: 0.3482  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [1660/3750]  eta: 0:12:07  Lr: 0.001875  Loss: -0.3400  Acc@1: 75.0000 (81.0318)  Acc@5: 100.0000 (96.5269)  time: 0.3468  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1670/3750]  eta: 0:12:04  Lr: 0.001875  Loss: -0.9158  Acc@1: 81.2500 (81.0368)  Acc@5: 100.0000 (96.5328)  time: 0.3486  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1680/3750]  eta: 0:12:00  Lr: 0.001875  Loss: -1.0403  Acc@1: 81.2500 (81.0306)  Acc@5: 100.0000 (96.5348)  time: 0.3484  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1690/3750]  eta: 0:11:57  Lr: 0.001875  Loss: -1.0031  Acc@1: 81.2500 (81.0319)  Acc@5: 100.0000 (96.5479)  time: 0.3467  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1700/3750]  eta: 0:11:53  Lr: 0.001875  Loss: -0.8550  Acc@1: 81.2500 (81.0479)  Acc@5: 100.0000 (96.5388)  time: 0.3477  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [1710/3750]  eta: 0:11:50  Lr: 0.001875  Loss: -0.9919  Acc@1: 81.2500 (81.0454)  Acc@5: 93.7500 (96.5298)  time: 0.3486  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1720/3750]  eta: 0:11:46  Lr: 0.001875  Loss: -0.4604  Acc@1: 81.2500 (81.0321)  Acc@5: 93.7500 (96.5318)  time: 0.3477  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1730/3750]  eta: 0:11:43  Lr: 0.001875  Loss: -0.8318  Acc@1: 81.2500 (81.0550)  Acc@5: 100.0000 (96.5302)  time: 0.3472  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1740/3750]  eta: 0:11:39  Lr: 0.001875  Loss: -0.8530  Acc@1: 81.2500 (81.0274)  Acc@5: 100.0000 (96.5214)  time: 0.3496  data: 0.0014  max mem: 2500
Train: Epoch[2/5]  [1750/3750]  eta: 0:11:36  Lr: 0.001875  Loss: -1.2198  Acc@1: 81.2500 (81.0323)  Acc@5: 100.0000 (96.5270)  time: 0.3493  data: 0.0013  max mem: 2500
Train: Epoch[2/5]  [1760/3750]  eta: 0:11:32  Lr: 0.001875  Loss: -0.4200  Acc@1: 81.2500 (81.0158)  Acc@5: 100.0000 (96.5077)  time: 0.3464  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1770/3750]  eta: 0:11:29  Lr: 0.001875  Loss: -1.1950  Acc@1: 81.2500 (81.0100)  Acc@5: 93.7500 (96.5027)  time: 0.3470  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1780/3750]  eta: 0:11:25  Lr: 0.001875  Loss: -0.4317  Acc@1: 81.2500 (81.0149)  Acc@5: 93.7500 (96.4978)  time: 0.3467  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [1790/3750]  eta: 0:11:22  Lr: 0.001875  Loss: -1.0389  Acc@1: 87.5000 (81.0371)  Acc@5: 100.0000 (96.5103)  time: 0.3456  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [1800/3750]  eta: 0:11:18  Lr: 0.001875  Loss: -0.6321  Acc@1: 81.2500 (81.0383)  Acc@5: 100.0000 (96.5158)  time: 0.3480  data: 0.0009  max mem: 2500
Train: Epoch[2/5]  [1810/3750]  eta: 0:11:15  Lr: 0.001875  Loss: -1.1154  Acc@1: 81.2500 (81.0636)  Acc@5: 100.0000 (96.5247)  time: 0.3491  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1820/3750]  eta: 0:11:11  Lr: 0.001875  Loss: -0.4709  Acc@1: 81.2500 (81.0750)  Acc@5: 100.0000 (96.5335)  time: 0.3486  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1830/3750]  eta: 0:11:08  Lr: 0.001875  Loss: -1.1207  Acc@1: 81.2500 (81.0623)  Acc@5: 100.0000 (96.5285)  time: 0.3488  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [1840/3750]  eta: 0:11:04  Lr: 0.001875  Loss: -1.0415  Acc@1: 81.2500 (81.0870)  Acc@5: 93.7500 (96.5236)  time: 0.3515  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [1850/3750]  eta: 0:11:01  Lr: 0.001875  Loss: -1.0686  Acc@1: 87.5000 (81.0947)  Acc@5: 93.7500 (96.5154)  time: 0.3520  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [1860/3750]  eta: 0:10:57  Lr: 0.001875  Loss: -0.2798  Acc@1: 81.2500 (81.0754)  Acc@5: 93.7500 (96.5073)  time: 0.3489  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [1870/3750]  eta: 0:10:54  Lr: 0.001875  Loss: -0.9535  Acc@1: 75.0000 (81.0496)  Acc@5: 93.7500 (96.4925)  time: 0.3480  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1880/3750]  eta: 0:10:51  Lr: 0.001875  Loss: -1.0329  Acc@1: 75.0000 (81.0373)  Acc@5: 93.7500 (96.4912)  time: 0.3490  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1890/3750]  eta: 0:10:47  Lr: 0.001875  Loss: -0.9468  Acc@1: 81.2500 (81.0352)  Acc@5: 100.0000 (96.4999)  time: 0.3481  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1900/3750]  eta: 0:10:44  Lr: 0.001875  Loss: -0.2951  Acc@1: 81.2500 (81.0429)  Acc@5: 100.0000 (96.5018)  time: 0.3470  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [1910/3750]  eta: 0:10:40  Lr: 0.001875  Loss: -0.4893  Acc@1: 81.2500 (81.0113)  Acc@5: 100.0000 (96.4940)  time: 0.3483  data: 0.0009  max mem: 2500
Train: Epoch[2/5]  [1920/3750]  eta: 0:10:37  Lr: 0.001875  Loss: -0.4932  Acc@1: 75.0000 (81.0060)  Acc@5: 100.0000 (96.4992)  time: 0.3483  data: 0.0009  max mem: 2500
Train: Epoch[2/5]  [1930/3750]  eta: 0:10:33  Lr: 0.001875  Loss: -0.5930  Acc@1: 81.2500 (81.0137)  Acc@5: 100.0000 (96.4882)  time: 0.3477  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [1940/3750]  eta: 0:10:30  Lr: 0.001875  Loss: -0.8554  Acc@1: 87.5000 (81.0407)  Acc@5: 100.0000 (96.4934)  time: 0.3476  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [1950/3750]  eta: 0:10:26  Lr: 0.001875  Loss: -0.4882  Acc@1: 87.5000 (81.0514)  Acc@5: 100.0000 (96.4986)  time: 0.3479  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1960/3750]  eta: 0:10:23  Lr: 0.001875  Loss: -0.6572  Acc@1: 81.2500 (81.0460)  Acc@5: 100.0000 (96.4973)  time: 0.3484  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [1970/3750]  eta: 0:10:19  Lr: 0.001875  Loss: -1.0663  Acc@1: 81.2500 (81.0407)  Acc@5: 93.7500 (96.4961)  time: 0.3484  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [1980/3750]  eta: 0:10:16  Lr: 0.001875  Loss: -0.6933  Acc@1: 87.5000 (81.0796)  Acc@5: 100.0000 (96.5043)  time: 0.3486  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [1990/3750]  eta: 0:10:12  Lr: 0.001875  Loss: -0.8983  Acc@1: 87.5000 (81.0993)  Acc@5: 100.0000 (96.5062)  time: 0.3486  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [2000/3750]  eta: 0:10:09  Lr: 0.001875  Loss: -0.6383  Acc@1: 87.5000 (81.1188)  Acc@5: 100.0000 (96.5111)  time: 0.3488  data: 0.0010  max mem: 2500
Train: Epoch[2/5]  [2010/3750]  eta: 0:10:05  Lr: 0.001875  Loss: -0.8016  Acc@1: 87.5000 (81.1319)  Acc@5: 100.0000 (96.5254)  time: 0.3486  data: 0.0010  max mem: 2500
Train: Epoch[2/5]  [2020/3750]  eta: 0:10:02  Lr: 0.001875  Loss: -0.8512  Acc@1: 81.2500 (81.1387)  Acc@5: 100.0000 (96.5302)  time: 0.3476  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [2030/3750]  eta: 0:09:58  Lr: 0.001875  Loss: -1.1092  Acc@1: 81.2500 (81.1577)  Acc@5: 93.7500 (96.5288)  time: 0.3493  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [2040/3750]  eta: 0:09:55  Lr: 0.001875  Loss: -1.1112  Acc@1: 81.2500 (81.1551)  Acc@5: 100.0000 (96.5336)  time: 0.3509  data: 0.0019  max mem: 2500
Train: Epoch[2/5]  [2050/3750]  eta: 0:09:51  Lr: 0.001875  Loss: -0.2412  Acc@1: 75.0000 (81.1159)  Acc@5: 100.0000 (96.5200)  time: 0.3493  data: 0.0018  max mem: 2500
Train: Epoch[2/5]  [2060/3750]  eta: 0:09:48  Lr: 0.001875  Loss: -1.0433  Acc@1: 81.2500 (81.1135)  Acc@5: 93.7500 (96.5156)  time: 0.3475  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [2070/3750]  eta: 0:09:44  Lr: 0.001875  Loss: -0.5142  Acc@1: 81.2500 (81.1112)  Acc@5: 100.0000 (96.5174)  time: 0.3476  data: 0.0012  max mem: 2500
Train: Epoch[2/5]  [2080/3750]  eta: 0:09:41  Lr: 0.001875  Loss: -1.3367  Acc@1: 81.2500 (81.1269)  Acc@5: 100.0000 (96.5191)  time: 0.3488  data: 0.0012  max mem: 2500
Train: Epoch[2/5]  [2090/3750]  eta: 0:09:37  Lr: 0.001875  Loss: -0.7872  Acc@1: 87.5000 (81.1185)  Acc@5: 93.7500 (96.5178)  time: 0.3484  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [2100/3750]  eta: 0:09:34  Lr: 0.001875  Loss: -0.6833  Acc@1: 81.2500 (81.1102)  Acc@5: 100.0000 (96.5284)  time: 0.3496  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [2110/3750]  eta: 0:09:31  Lr: 0.001875  Loss: -0.8306  Acc@1: 81.2500 (81.1316)  Acc@5: 100.0000 (96.5301)  time: 0.3513  data: 0.0012  max mem: 2500
Train: Epoch[2/5]  [2120/3750]  eta: 0:09:27  Lr: 0.001875  Loss: -1.1506  Acc@1: 87.5000 (81.1557)  Acc@5: 100.0000 (96.5347)  time: 0.3501  data: 0.0012  max mem: 2500
Train: Epoch[2/5]  [2130/3750]  eta: 0:09:24  Lr: 0.001875  Loss: -0.6081  Acc@1: 81.2500 (81.1649)  Acc@5: 100.0000 (96.5363)  time: 0.3472  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [2140/3750]  eta: 0:09:20  Lr: 0.001875  Loss: -0.8253  Acc@1: 81.2500 (81.1741)  Acc@5: 93.7500 (96.5320)  time: 0.3485  data: 0.0011  max mem: 2500
Train: Epoch[2/5]  [2150/3750]  eta: 0:09:17  Lr: 0.001875  Loss: -0.6325  Acc@1: 81.2500 (81.1977)  Acc@5: 93.7500 (96.5191)  time: 0.3495  data: 0.0012  max mem: 2500
Train: Epoch[2/5]  [2160/3750]  eta: 0:09:13  Lr: 0.001875  Loss: -0.7859  Acc@1: 81.2500 (81.2037)  Acc@5: 93.7500 (96.5178)  time: 0.3483  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [2170/3750]  eta: 0:09:10  Lr: 0.001875  Loss: -0.8624  Acc@1: 81.2500 (81.2212)  Acc@5: 100.0000 (96.5195)  time: 0.3497  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [2180/3750]  eta: 0:09:06  Lr: 0.001875  Loss: -0.3376  Acc@1: 81.2500 (81.2156)  Acc@5: 93.7500 (96.5125)  time: 0.3482  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [2190/3750]  eta: 0:09:03  Lr: 0.001875  Loss: -0.7730  Acc@1: 75.0000 (81.2015)  Acc@5: 93.7500 (96.5113)  time: 0.3473  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [2200/3750]  eta: 0:08:59  Lr: 0.001875  Loss: -1.0891  Acc@1: 75.0000 (81.1847)  Acc@5: 93.7500 (96.5073)  time: 0.3480  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [2210/3750]  eta: 0:08:56  Lr: 0.001875  Loss: -0.7549  Acc@1: 81.2500 (81.1793)  Acc@5: 93.7500 (96.4948)  time: 0.3481  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [2220/3750]  eta: 0:08:52  Lr: 0.001875  Loss: -0.1788  Acc@1: 81.2500 (81.1740)  Acc@5: 93.7500 (96.4937)  time: 0.3489  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [2230/3750]  eta: 0:08:49  Lr: 0.001875  Loss: -0.9924  Acc@1: 81.2500 (81.1940)  Acc@5: 100.0000 (96.4954)  time: 0.3473  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [2240/3750]  eta: 0:08:45  Lr: 0.001875  Loss: -0.8476  Acc@1: 81.2500 (81.1970)  Acc@5: 100.0000 (96.5027)  time: 0.3476  data: 0.0011  max mem: 2500
Train: Epoch[2/5]  [2250/3750]  eta: 0:08:42  Lr: 0.001875  Loss: -0.5023  Acc@1: 81.2500 (81.1861)  Acc@5: 93.7500 (96.4904)  time: 0.3489  data: 0.0017  max mem: 2500
Train: Epoch[2/5]  [2260/3750]  eta: 0:08:38  Lr: 0.001875  Loss: -0.6926  Acc@1: 75.0000 (81.1920)  Acc@5: 93.7500 (96.4949)  time: 0.3481  data: 0.0014  max mem: 2500
Train: Epoch[2/5]  [2270/3750]  eta: 0:08:35  Lr: 0.001875  Loss: -0.6716  Acc@1: 87.5000 (81.2060)  Acc@5: 100.0000 (96.4911)  time: 0.3466  data: 0.0009  max mem: 2500
Train: Epoch[2/5]  [2280/3750]  eta: 0:08:31  Lr: 0.001875  Loss: -0.6072  Acc@1: 81.2500 (81.2007)  Acc@5: 93.7500 (96.4928)  time: 0.3469  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [2290/3750]  eta: 0:08:28  Lr: 0.001875  Loss: -0.9330  Acc@1: 81.2500 (81.2118)  Acc@5: 93.7500 (96.4917)  time: 0.3485  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [2300/3750]  eta: 0:08:24  Lr: 0.001875  Loss: -1.0592  Acc@1: 81.2500 (81.2065)  Acc@5: 100.0000 (96.4988)  time: 0.3468  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [2310/3750]  eta: 0:08:21  Lr: 0.001875  Loss: -0.4019  Acc@1: 81.2500 (81.2203)  Acc@5: 100.0000 (96.5031)  time: 0.3460  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [2320/3750]  eta: 0:08:17  Lr: 0.001875  Loss: -0.6645  Acc@1: 81.2500 (81.2069)  Acc@5: 100.0000 (96.4994)  time: 0.3467  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [2330/3750]  eta: 0:08:14  Lr: 0.001875  Loss: -0.6339  Acc@1: 75.0000 (81.1910)  Acc@5: 100.0000 (96.5010)  time: 0.3475  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [2340/3750]  eta: 0:08:10  Lr: 0.001875  Loss: -1.0090  Acc@1: 81.2500 (81.1966)  Acc@5: 100.0000 (96.5079)  time: 0.3483  data: 0.0017  max mem: 2500
Train: Epoch[2/5]  [2350/3750]  eta: 0:08:07  Lr: 0.001875  Loss: -0.6894  Acc@1: 81.2500 (81.1782)  Acc@5: 100.0000 (96.5015)  time: 0.3492  data: 0.0018  max mem: 2500
Train: Epoch[2/5]  [2360/3750]  eta: 0:08:03  Lr: 0.001875  Loss: -0.9683  Acc@1: 81.2500 (81.1865)  Acc@5: 93.7500 (96.5031)  time: 0.3504  data: 0.0009  max mem: 2500
Train: Epoch[2/5]  [2370/3750]  eta: 0:08:00  Lr: 0.001875  Loss: -1.1267  Acc@1: 81.2500 (81.1920)  Acc@5: 100.0000 (96.5046)  time: 0.3487  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [2380/3750]  eta: 0:07:56  Lr: 0.001875  Loss: -1.0921  Acc@1: 81.2500 (81.2001)  Acc@5: 100.0000 (96.5114)  time: 0.3467  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [2390/3750]  eta: 0:07:53  Lr: 0.001875  Loss: -0.3206  Acc@1: 81.2500 (81.1925)  Acc@5: 100.0000 (96.5130)  time: 0.3480  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [2400/3750]  eta: 0:07:50  Lr: 0.001875  Loss: -0.7616  Acc@1: 81.2500 (81.1953)  Acc@5: 100.0000 (96.5223)  time: 0.3486  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [2410/3750]  eta: 0:07:46  Lr: 0.001875  Loss: -0.5293  Acc@1: 81.2500 (81.2059)  Acc@5: 100.0000 (96.5315)  time: 0.3485  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [2420/3750]  eta: 0:07:43  Lr: 0.001875  Loss: -0.5150  Acc@1: 81.2500 (81.1984)  Acc@5: 100.0000 (96.5355)  time: 0.3485  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [2430/3750]  eta: 0:07:39  Lr: 0.001875  Loss: -0.6664  Acc@1: 81.2500 (81.1934)  Acc@5: 100.0000 (96.5369)  time: 0.3500  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [2440/3750]  eta: 0:07:36  Lr: 0.001875  Loss: -0.6971  Acc@1: 81.2500 (81.2090)  Acc@5: 100.0000 (96.5434)  time: 0.3507  data: 0.0010  max mem: 2500
Train: Epoch[2/5]  [2450/3750]  eta: 0:07:32  Lr: 0.001875  Loss: -0.5308  Acc@1: 81.2500 (81.2041)  Acc@5: 100.0000 (96.5448)  time: 0.3474  data: 0.0009  max mem: 2500
Train: Epoch[2/5]  [2460/3750]  eta: 0:07:29  Lr: 0.001875  Loss: -0.8888  Acc@1: 81.2500 (81.2246)  Acc@5: 93.7500 (96.5410)  time: 0.3465  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [2470/3750]  eta: 0:07:25  Lr: 0.001875  Loss: -0.8311  Acc@1: 81.2500 (81.2298)  Acc@5: 93.7500 (96.5399)  time: 0.3465  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [2480/3750]  eta: 0:07:22  Lr: 0.001875  Loss: -1.0254  Acc@1: 81.2500 (81.2273)  Acc@5: 100.0000 (96.5437)  time: 0.3459  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [2490/3750]  eta: 0:07:18  Lr: 0.001875  Loss: -1.0013  Acc@1: 81.2500 (81.2425)  Acc@5: 100.0000 (96.5501)  time: 0.3485  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [2500/3750]  eta: 0:07:15  Lr: 0.001875  Loss: -0.9097  Acc@1: 81.2500 (81.2425)  Acc@5: 100.0000 (96.5539)  time: 0.3500  data: 0.0009  max mem: 2500
Train: Epoch[2/5]  [2510/3750]  eta: 0:07:11  Lr: 0.001875  Loss: -0.5987  Acc@1: 75.0000 (81.2201)  Acc@5: 93.7500 (96.5427)  time: 0.3476  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [2520/3750]  eta: 0:07:08  Lr: 0.001875  Loss: -1.2032  Acc@1: 75.0000 (81.1955)  Acc@5: 93.7500 (96.5416)  time: 0.3468  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [2530/3750]  eta: 0:07:04  Lr: 0.001875  Loss: -0.9099  Acc@1: 75.0000 (81.1932)  Acc@5: 100.0000 (96.5478)  time: 0.3497  data: 0.0009  max mem: 2500
Train: Epoch[2/5]  [2540/3750]  eta: 0:07:01  Lr: 0.001875  Loss: -0.9883  Acc@1: 81.2500 (81.2033)  Acc@5: 100.0000 (96.5516)  time: 0.3493  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [2550/3750]  eta: 0:06:57  Lr: 0.001875  Loss: -1.0318  Acc@1: 87.5000 (81.2181)  Acc@5: 100.0000 (96.5602)  time: 0.3470  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [2560/3750]  eta: 0:06:54  Lr: 0.001875  Loss: -0.9052  Acc@1: 87.5000 (81.2280)  Acc@5: 100.0000 (96.5712)  time: 0.3478  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [2570/3750]  eta: 0:06:50  Lr: 0.001875  Loss: -0.7647  Acc@1: 81.2500 (81.2257)  Acc@5: 100.0000 (96.5748)  time: 0.3485  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [2580/3750]  eta: 0:06:47  Lr: 0.001875  Loss: -1.2622  Acc@1: 87.5000 (81.2379)  Acc@5: 100.0000 (96.5808)  time: 0.3476  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [2590/3750]  eta: 0:06:43  Lr: 0.001875  Loss: -0.8469  Acc@1: 81.2500 (81.2331)  Acc@5: 100.0000 (96.5843)  time: 0.3474  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [2600/3750]  eta: 0:06:40  Lr: 0.001875  Loss: -1.2498  Acc@1: 81.2500 (81.2308)  Acc@5: 93.7500 (96.5782)  time: 0.3481  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [2610/3750]  eta: 0:06:36  Lr: 0.001875  Loss: -0.9320  Acc@1: 81.2500 (81.2380)  Acc@5: 93.7500 (96.5698)  time: 0.3470  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2620/3750]  eta: 0:06:33  Lr: 0.001875  Loss: -0.5769  Acc@1: 81.2500 (81.2357)  Acc@5: 93.7500 (96.5686)  time: 0.3461  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [2630/3750]  eta: 0:06:29  Lr: 0.001875  Loss: -0.7495  Acc@1: 81.2500 (81.2429)  Acc@5: 93.7500 (96.5602)  time: 0.3516  data: 0.0030  max mem: 2500
Train: Epoch[2/5]  [2640/3750]  eta: 0:06:26  Lr: 0.001875  Loss: -0.6572  Acc@1: 81.2500 (81.2500)  Acc@5: 93.7500 (96.5591)  time: 0.3538  data: 0.0038  max mem: 2500
Train: Epoch[2/5]  [2650/3750]  eta: 0:06:23  Lr: 0.001875  Loss: -0.9495  Acc@1: 81.2500 (81.2453)  Acc@5: 100.0000 (96.5603)  time: 0.3490  data: 0.0015  max mem: 2500
Train: Epoch[2/5]  [2660/3750]  eta: 0:06:19  Lr: 0.001875  Loss: -0.6292  Acc@1: 81.2500 (81.2406)  Acc@5: 100.0000 (96.5567)  time: 0.3460  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [2670/3750]  eta: 0:06:16  Lr: 0.001875  Loss: -0.8264  Acc@1: 81.2500 (81.2336)  Acc@5: 93.7500 (96.5556)  time: 0.3470  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [2680/3750]  eta: 0:06:12  Lr: 0.001875  Loss: -0.8757  Acc@1: 81.2500 (81.2267)  Acc@5: 100.0000 (96.5545)  time: 0.3476  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [2690/3750]  eta: 0:06:09  Lr: 0.001875  Loss: -1.2249  Acc@1: 81.2500 (81.2361)  Acc@5: 100.0000 (96.5533)  time: 0.3476  data: 0.0013  max mem: 2500
Train: Epoch[2/5]  [2700/3750]  eta: 0:06:05  Lr: 0.001875  Loss: -0.8508  Acc@1: 81.2500 (81.2338)  Acc@5: 100.0000 (96.5545)  time: 0.3479  data: 0.0014  max mem: 2500
Train: Epoch[2/5]  [2710/3750]  eta: 0:06:02  Lr: 0.001875  Loss: -1.0822  Acc@1: 81.2500 (81.2223)  Acc@5: 100.0000 (96.5603)  time: 0.3460  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [2720/3750]  eta: 0:05:58  Lr: 0.001875  Loss: -1.1487  Acc@1: 75.0000 (81.2132)  Acc@5: 100.0000 (96.5661)  time: 0.3465  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [2730/3750]  eta: 0:05:55  Lr: 0.001875  Loss: -0.5481  Acc@1: 81.2500 (81.2225)  Acc@5: 100.0000 (96.5603)  time: 0.3483  data: 0.0009  max mem: 2500
Train: Epoch[2/5]  [2740/3750]  eta: 0:05:51  Lr: 0.001875  Loss: -0.4440  Acc@1: 81.2500 (81.2204)  Acc@5: 93.7500 (96.5569)  time: 0.3474  data: 0.0009  max mem: 2500
Train: Epoch[2/5]  [2750/3750]  eta: 0:05:48  Lr: 0.001875  Loss: -0.9951  Acc@1: 81.2500 (81.2341)  Acc@5: 100.0000 (96.5603)  time: 0.3464  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [2760/3750]  eta: 0:05:44  Lr: 0.001875  Loss: -0.6062  Acc@1: 81.2500 (81.2206)  Acc@5: 100.0000 (96.5637)  time: 0.3476  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [2770/3750]  eta: 0:05:41  Lr: 0.001875  Loss: -0.6836  Acc@1: 81.2500 (81.2117)  Acc@5: 100.0000 (96.5649)  time: 0.3475  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [2780/3750]  eta: 0:05:37  Lr: 0.001875  Loss: -0.9903  Acc@1: 81.2500 (81.2028)  Acc@5: 100.0000 (96.5615)  time: 0.3467  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [2790/3750]  eta: 0:05:34  Lr: 0.001875  Loss: -1.0837  Acc@1: 87.5000 (81.2231)  Acc@5: 100.0000 (96.5626)  time: 0.3481  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [2800/3750]  eta: 0:05:30  Lr: 0.001875  Loss: -0.2753  Acc@1: 87.5000 (81.2255)  Acc@5: 93.7500 (96.5526)  time: 0.3481  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [2810/3750]  eta: 0:05:27  Lr: 0.001875  Loss: -1.0410  Acc@1: 81.2500 (81.2344)  Acc@5: 93.7500 (96.5515)  time: 0.3467  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [2820/3750]  eta: 0:05:23  Lr: 0.001875  Loss: -0.8444  Acc@1: 81.2500 (81.2278)  Acc@5: 93.7500 (96.5504)  time: 0.3463  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [2830/3750]  eta: 0:05:20  Lr: 0.001875  Loss: -0.7450  Acc@1: 81.2500 (81.2235)  Acc@5: 93.7500 (96.5494)  time: 0.3482  data: 0.0011  max mem: 2500
Train: Epoch[2/5]  [2840/3750]  eta: 0:05:16  Lr: 0.001875  Loss: -0.9388  Acc@1: 81.2500 (81.2456)  Acc@5: 100.0000 (96.5527)  time: 0.3491  data: 0.0011  max mem: 2500
Train: Epoch[2/5]  [2850/3750]  eta: 0:05:13  Lr: 0.001875  Loss: -0.6391  Acc@1: 81.2500 (81.2522)  Acc@5: 100.0000 (96.5560)  time: 0.3485  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [2860/3750]  eta: 0:05:09  Lr: 0.001875  Loss: -1.1475  Acc@1: 81.2500 (81.2434)  Acc@5: 100.0000 (96.5593)  time: 0.3477  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [2870/3750]  eta: 0:05:06  Lr: 0.001875  Loss: -1.2080  Acc@1: 81.2500 (81.2718)  Acc@5: 100.0000 (96.5648)  time: 0.3483  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [2880/3750]  eta: 0:05:02  Lr: 0.001875  Loss: -1.0885  Acc@1: 87.5000 (81.2674)  Acc@5: 100.0000 (96.5680)  time: 0.3485  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [2890/3750]  eta: 0:04:59  Lr: 0.001875  Loss: -0.6958  Acc@1: 81.2500 (81.2695)  Acc@5: 93.7500 (96.5604)  time: 0.3466  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [2900/3750]  eta: 0:04:55  Lr: 0.001875  Loss: -1.2300  Acc@1: 87.5000 (81.2845)  Acc@5: 100.0000 (96.5680)  time: 0.3469  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [2910/3750]  eta: 0:04:52  Lr: 0.001875  Loss: -0.6101  Acc@1: 87.5000 (81.2758)  Acc@5: 100.0000 (96.5648)  time: 0.3465  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [2920/3750]  eta: 0:04:48  Lr: 0.001875  Loss: -0.9640  Acc@1: 81.2500 (81.2821)  Acc@5: 93.7500 (96.5551)  time: 0.3466  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [2930/3750]  eta: 0:04:45  Lr: 0.001875  Loss: -0.3635  Acc@1: 81.2500 (81.2628)  Acc@5: 93.7500 (96.5519)  time: 0.3481  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [2940/3750]  eta: 0:04:41  Lr: 0.001875  Loss: -0.6526  Acc@1: 75.0000 (81.2479)  Acc@5: 93.7500 (96.5552)  time: 0.3485  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [2950/3750]  eta: 0:04:38  Lr: 0.001875  Loss: -1.2977  Acc@1: 81.2500 (81.2648)  Acc@5: 100.0000 (96.5647)  time: 0.3488  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [2960/3750]  eta: 0:04:35  Lr: 0.001875  Loss: -0.8167  Acc@1: 81.2500 (81.2542)  Acc@5: 100.0000 (96.5721)  time: 0.3492  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [2970/3750]  eta: 0:04:31  Lr: 0.001875  Loss: -0.9005  Acc@1: 81.2500 (81.2563)  Acc@5: 100.0000 (96.5689)  time: 0.3476  data: 0.0014  max mem: 2500
Train: Epoch[2/5]  [2980/3750]  eta: 0:04:28  Lr: 0.001875  Loss: -0.8393  Acc@1: 81.2500 (81.2563)  Acc@5: 100.0000 (96.5762)  time: 0.3465  data: 0.0013  max mem: 2500
Train: Epoch[2/5]  [2990/3750]  eta: 0:04:24  Lr: 0.001875  Loss: -1.1377  Acc@1: 81.2500 (81.2584)  Acc@5: 100.0000 (96.5751)  time: 0.3465  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3000/3750]  eta: 0:04:21  Lr: 0.001875  Loss: -1.0909  Acc@1: 87.5000 (81.2687)  Acc@5: 100.0000 (96.5782)  time: 0.3471  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3010/3750]  eta: 0:04:17  Lr: 0.001875  Loss: -1.1773  Acc@1: 87.5000 (81.2811)  Acc@5: 100.0000 (96.5771)  time: 0.3479  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [3020/3750]  eta: 0:04:14  Lr: 0.001875  Loss: -0.7848  Acc@1: 81.2500 (81.2831)  Acc@5: 100.0000 (96.5802)  time: 0.3472  data: 0.0011  max mem: 2500
Train: Epoch[2/5]  [3030/3750]  eta: 0:04:10  Lr: 0.001875  Loss: -0.8737  Acc@1: 81.2500 (81.2974)  Acc@5: 100.0000 (96.5791)  time: 0.3481  data: 0.0011  max mem: 2500
Train: Epoch[2/5]  [3040/3750]  eta: 0:04:07  Lr: 0.001875  Loss: -0.9626  Acc@1: 81.2500 (81.2911)  Acc@5: 100.0000 (96.5842)  time: 0.3495  data: 0.0009  max mem: 2500
Train: Epoch[2/5]  [3050/3750]  eta: 0:04:03  Lr: 0.001875  Loss: -0.5128  Acc@1: 87.5000 (81.3033)  Acc@5: 100.0000 (96.5851)  time: 0.3488  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [3060/3750]  eta: 0:04:00  Lr: 0.001875  Loss: -1.0491  Acc@1: 87.5000 (81.3010)  Acc@5: 100.0000 (96.5881)  time: 0.3486  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [3070/3750]  eta: 0:03:56  Lr: 0.001875  Loss: -1.1962  Acc@1: 87.5000 (81.3192)  Acc@5: 100.0000 (96.5891)  time: 0.3475  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [3080/3750]  eta: 0:03:53  Lr: 0.001875  Loss: -1.2128  Acc@1: 87.5000 (81.3251)  Acc@5: 100.0000 (96.5920)  time: 0.3461  data: 0.0011  max mem: 2500
Train: Epoch[2/5]  [3090/3750]  eta: 0:03:49  Lr: 0.001875  Loss: -0.9039  Acc@1: 81.2500 (81.3268)  Acc@5: 100.0000 (96.5990)  time: 0.3471  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [3100/3750]  eta: 0:03:46  Lr: 0.001875  Loss: -1.0652  Acc@1: 81.2500 (81.3306)  Acc@5: 100.0000 (96.5979)  time: 0.3484  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [3110/3750]  eta: 0:03:42  Lr: 0.001875  Loss: -0.9236  Acc@1: 87.5000 (81.3545)  Acc@5: 100.0000 (96.6088)  time: 0.3482  data: 0.0013  max mem: 2500
Train: Epoch[2/5]  [3120/3750]  eta: 0:03:39  Lr: 0.001875  Loss: -0.4967  Acc@1: 81.2500 (81.3501)  Acc@5: 100.0000 (96.6117)  time: 0.3497  data: 0.0024  max mem: 2500
Train: Epoch[2/5]  [3130/3750]  eta: 0:03:35  Lr: 0.001875  Loss: -1.1519  Acc@1: 81.2500 (81.3458)  Acc@5: 100.0000 (96.6065)  time: 0.3497  data: 0.0017  max mem: 2500
Train: Epoch[2/5]  [3140/3750]  eta: 0:03:32  Lr: 0.001875  Loss: -1.2274  Acc@1: 81.2500 (81.3574)  Acc@5: 93.7500 (96.6094)  time: 0.3477  data: 0.0010  max mem: 2500
Train: Epoch[2/5]  [3150/3750]  eta: 0:03:28  Lr: 0.001875  Loss: -0.7231  Acc@1: 81.2500 (81.3512)  Acc@5: 100.0000 (96.6062)  time: 0.3472  data: 0.0010  max mem: 2500
Train: Epoch[2/5]  [3160/3750]  eta: 0:03:25  Lr: 0.001875  Loss: -1.0027  Acc@1: 81.2500 (81.3607)  Acc@5: 100.0000 (96.6170)  time: 0.3475  data: 0.0012  max mem: 2500
Train: Epoch[2/5]  [3170/3750]  eta: 0:03:21  Lr: 0.001875  Loss: -0.9347  Acc@1: 87.5000 (81.3742)  Acc@5: 100.0000 (96.6217)  time: 0.3473  data: 0.0012  max mem: 2500
Train: Epoch[2/5]  [3180/3750]  eta: 0:03:18  Lr: 0.001875  Loss: -1.0551  Acc@1: 81.2500 (81.3718)  Acc@5: 100.0000 (96.6225)  time: 0.3477  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [3190/3750]  eta: 0:03:14  Lr: 0.001875  Loss: -0.8111  Acc@1: 81.2500 (81.3714)  Acc@5: 100.0000 (96.6214)  time: 0.3484  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [3200/3750]  eta: 0:03:11  Lr: 0.001875  Loss: -1.0593  Acc@1: 87.5000 (81.3808)  Acc@5: 100.0000 (96.6221)  time: 0.3485  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [3210/3750]  eta: 0:03:07  Lr: 0.001875  Loss: -0.6320  Acc@1: 87.5000 (81.3785)  Acc@5: 100.0000 (96.6229)  time: 0.3500  data: 0.0022  max mem: 2500
Train: Epoch[2/5]  [3220/3750]  eta: 0:03:04  Lr: 0.001875  Loss: -0.9395  Acc@1: 87.5000 (81.3936)  Acc@5: 100.0000 (96.6276)  time: 0.3502  data: 0.0032  max mem: 2500
Train: Epoch[2/5]  [3230/3750]  eta: 0:03:01  Lr: 0.001875  Loss: -0.8628  Acc@1: 81.2500 (81.3854)  Acc@5: 100.0000 (96.6264)  time: 0.3497  data: 0.0016  max mem: 2500
Train: Epoch[2/5]  [3240/3750]  eta: 0:02:57  Lr: 0.001875  Loss: -0.2455  Acc@1: 81.2500 (81.3715)  Acc@5: 93.7500 (96.6176)  time: 0.3480  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [3250/3750]  eta: 0:02:54  Lr: 0.001875  Loss: -0.8670  Acc@1: 81.2500 (81.3692)  Acc@5: 93.7500 (96.6107)  time: 0.3471  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [3260/3750]  eta: 0:02:50  Lr: 0.001875  Loss: -0.4656  Acc@1: 81.2500 (81.3612)  Acc@5: 93.7500 (96.6019)  time: 0.3478  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [3270/3750]  eta: 0:02:47  Lr: 0.001875  Loss: -1.2364  Acc@1: 81.2500 (81.3532)  Acc@5: 93.7500 (96.5951)  time: 0.3464  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3280/3750]  eta: 0:02:43  Lr: 0.001875  Loss: -0.9414  Acc@1: 81.2500 (81.3414)  Acc@5: 100.0000 (96.5997)  time: 0.3464  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3290/3750]  eta: 0:02:40  Lr: 0.001875  Loss: -0.8123  Acc@1: 75.0000 (81.3336)  Acc@5: 100.0000 (96.5987)  time: 0.3472  data: 0.0010  max mem: 2500
Train: Epoch[2/5]  [3300/3750]  eta: 0:02:36  Lr: 0.001875  Loss: -0.9890  Acc@1: 81.2500 (81.3333)  Acc@5: 100.0000 (96.5995)  time: 0.3462  data: 0.0011  max mem: 2500
Train: Epoch[2/5]  [3310/3750]  eta: 0:02:33  Lr: 0.001875  Loss: -1.3973  Acc@1: 87.5000 (81.3463)  Acc@5: 100.0000 (96.5966)  time: 0.3478  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [3320/3750]  eta: 0:02:29  Lr: 0.001875  Loss: -0.7878  Acc@1: 81.2500 (81.3272)  Acc@5: 100.0000 (96.5974)  time: 0.3481  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [3330/3750]  eta: 0:02:26  Lr: 0.001875  Loss: -0.8429  Acc@1: 81.2500 (81.3269)  Acc@5: 93.7500 (96.5964)  time: 0.3471  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [3340/3750]  eta: 0:02:22  Lr: 0.001875  Loss: -0.6019  Acc@1: 81.2500 (81.3173)  Acc@5: 93.7500 (96.5935)  time: 0.3473  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [3350/3750]  eta: 0:02:19  Lr: 0.001875  Loss: -0.6800  Acc@1: 81.2500 (81.3246)  Acc@5: 93.7500 (96.5924)  time: 0.3487  data: 0.0013  max mem: 2500
Train: Epoch[2/5]  [3360/3750]  eta: 0:02:15  Lr: 0.001875  Loss: -1.1442  Acc@1: 81.2500 (81.3411)  Acc@5: 100.0000 (96.6007)  time: 0.3479  data: 0.0012  max mem: 2500
Train: Epoch[2/5]  [3370/3750]  eta: 0:02:12  Lr: 0.001875  Loss: -0.9667  Acc@1: 87.5000 (81.3408)  Acc@5: 100.0000 (96.5960)  time: 0.3465  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3380/3750]  eta: 0:02:08  Lr: 0.001875  Loss: -0.6508  Acc@1: 87.5000 (81.3535)  Acc@5: 93.7500 (96.5949)  time: 0.3492  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [3390/3750]  eta: 0:02:05  Lr: 0.001875  Loss: -0.5265  Acc@1: 75.0000 (81.3366)  Acc@5: 93.7500 (96.5902)  time: 0.3479  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [3400/3750]  eta: 0:02:01  Lr: 0.001875  Loss: -0.7477  Acc@1: 75.0000 (81.3253)  Acc@5: 93.7500 (96.5911)  time: 0.3462  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [3410/3750]  eta: 0:01:58  Lr: 0.001875  Loss: -0.3064  Acc@1: 81.2500 (81.3343)  Acc@5: 100.0000 (96.5919)  time: 0.3487  data: 0.0018  max mem: 2500
Train: Epoch[2/5]  [3420/3750]  eta: 0:01:54  Lr: 0.001875  Loss: -0.6317  Acc@1: 81.2500 (81.3267)  Acc@5: 100.0000 (96.5964)  time: 0.3489  data: 0.0015  max mem: 2500
Train: Epoch[2/5]  [3430/3750]  eta: 0:01:51  Lr: 0.001875  Loss: -0.9887  Acc@1: 81.2500 (81.3229)  Acc@5: 100.0000 (96.6008)  time: 0.3467  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [3440/3750]  eta: 0:01:47  Lr: 0.001875  Loss: -1.2524  Acc@1: 87.5000 (81.3354)  Acc@5: 100.0000 (96.6053)  time: 0.3470  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [3450/3750]  eta: 0:01:44  Lr: 0.001875  Loss: -0.8360  Acc@1: 81.2500 (81.3424)  Acc@5: 100.0000 (96.6097)  time: 0.3493  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [3460/3750]  eta: 0:01:40  Lr: 0.001875  Loss: -1.1787  Acc@1: 81.2500 (81.3547)  Acc@5: 100.0000 (96.6159)  time: 0.3494  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [3470/3750]  eta: 0:01:37  Lr: 0.001875  Loss: -0.9502  Acc@1: 81.2500 (81.3526)  Acc@5: 100.0000 (96.6166)  time: 0.3481  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [3480/3750]  eta: 0:01:33  Lr: 0.001875  Loss: -0.9936  Acc@1: 81.2500 (81.3541)  Acc@5: 100.0000 (96.6138)  time: 0.3464  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [3490/3750]  eta: 0:01:30  Lr: 0.001875  Loss: -1.2657  Acc@1: 87.5000 (81.3717)  Acc@5: 100.0000 (96.6163)  time: 0.3470  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3500/3750]  eta: 0:01:27  Lr: 0.001875  Loss: -0.9983  Acc@1: 87.5000 (81.3750)  Acc@5: 100.0000 (96.6206)  time: 0.3479  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [3510/3750]  eta: 0:01:23  Lr: 0.001875  Loss: -0.7004  Acc@1: 81.2500 (81.3817)  Acc@5: 100.0000 (96.6213)  time: 0.3486  data: 0.0018  max mem: 2500
Train: Epoch[2/5]  [3520/3750]  eta: 0:01:20  Lr: 0.001875  Loss: -0.5696  Acc@1: 81.2500 (81.3689)  Acc@5: 100.0000 (96.6203)  time: 0.3495  data: 0.0028  max mem: 2500
Train: Epoch[2/5]  [3530/3750]  eta: 0:01:16  Lr: 0.001875  Loss: -1.3153  Acc@1: 81.2500 (81.3721)  Acc@5: 93.7500 (96.6192)  time: 0.3487  data: 0.0021  max mem: 2500
Train: Epoch[2/5]  [3540/3750]  eta: 0:01:13  Lr: 0.001875  Loss: -1.2257  Acc@1: 87.5000 (81.3788)  Acc@5: 100.0000 (96.6235)  time: 0.3481  data: 0.0011  max mem: 2500
Train: Epoch[2/5]  [3550/3750]  eta: 0:01:09  Lr: 0.001875  Loss: -1.2892  Acc@1: 87.5000 (81.3838)  Acc@5: 100.0000 (96.6224)  time: 0.3499  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [3560/3750]  eta: 0:01:06  Lr: 0.001875  Loss: -1.1443  Acc@1: 87.5000 (81.3834)  Acc@5: 100.0000 (96.6249)  time: 0.3480  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [3570/3750]  eta: 0:01:02  Lr: 0.001875  Loss: -0.8106  Acc@1: 81.2500 (81.3865)  Acc@5: 100.0000 (96.6291)  time: 0.3450  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [3580/3750]  eta: 0:00:59  Lr: 0.001875  Loss: -0.9600  Acc@1: 81.2500 (81.3966)  Acc@5: 100.0000 (96.6263)  time: 0.3475  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [3590/3750]  eta: 0:00:55  Lr: 0.001875  Loss: -0.5890  Acc@1: 81.2500 (81.3840)  Acc@5: 93.7500 (96.6270)  time: 0.3482  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [3600/3750]  eta: 0:00:52  Lr: 0.001875  Loss: -1.0554  Acc@1: 81.2500 (81.3784)  Acc@5: 100.0000 (96.6294)  time: 0.3471  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [3610/3750]  eta: 0:00:48  Lr: 0.001875  Loss: -0.4771  Acc@1: 81.2500 (81.3867)  Acc@5: 100.0000 (96.6318)  time: 0.3489  data: 0.0024  max mem: 2500
Train: Epoch[2/5]  [3620/3750]  eta: 0:00:45  Lr: 0.001875  Loss: -0.8546  Acc@1: 81.2500 (81.3829)  Acc@5: 93.7500 (96.6239)  time: 0.3490  data: 0.0023  max mem: 2500
Train: Epoch[2/5]  [3630/3750]  eta: 0:00:41  Lr: 0.001875  Loss: -0.7640  Acc@1: 81.2500 (81.3739)  Acc@5: 93.7500 (96.6246)  time: 0.3461  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [3640/3750]  eta: 0:00:38  Lr: 0.001875  Loss: -0.6980  Acc@1: 81.2500 (81.3787)  Acc@5: 93.7500 (96.6235)  time: 0.3459  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [3650/3750]  eta: 0:00:34  Lr: 0.001875  Loss: -0.9731  Acc@1: 81.2500 (81.3698)  Acc@5: 93.7500 (96.6259)  time: 0.3456  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [3660/3750]  eta: 0:00:31  Lr: 0.001875  Loss: -1.1213  Acc@1: 81.2500 (81.3610)  Acc@5: 100.0000 (96.6232)  time: 0.3465  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3670/3750]  eta: 0:00:27  Lr: 0.001875  Loss: -0.4576  Acc@1: 81.2500 (81.3709)  Acc@5: 93.7500 (96.6205)  time: 0.3480  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [3680/3750]  eta: 0:00:24  Lr: 0.001875  Loss: -0.7917  Acc@1: 87.5000 (81.3790)  Acc@5: 93.7500 (96.6212)  time: 0.3471  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [3690/3750]  eta: 0:00:20  Lr: 0.001875  Loss: -1.2278  Acc@1: 87.5000 (81.3922)  Acc@5: 100.0000 (96.6235)  time: 0.3457  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [3700/3750]  eta: 0:00:17  Lr: 0.001875  Loss: -0.9009  Acc@1: 81.2500 (81.3902)  Acc@5: 100.0000 (96.6225)  time: 0.3475  data: 0.0014  max mem: 2500
Train: Epoch[2/5]  [3710/3750]  eta: 0:00:13  Lr: 0.001875  Loss: -0.6229  Acc@1: 81.2500 (81.3729)  Acc@5: 93.7500 (96.6232)  time: 0.3481  data: 0.0012  max mem: 2500
Train: Epoch[2/5]  [3720/3750]  eta: 0:00:10  Lr: 0.001875  Loss: -0.8095  Acc@1: 75.0000 (81.3743)  Acc@5: 100.0000 (96.6323)  time: 0.3481  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [3730/3750]  eta: 0:00:06  Lr: 0.001875  Loss: -0.7898  Acc@1: 81.2500 (81.3874)  Acc@5: 100.0000 (96.6363)  time: 0.3477  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [3740/3750]  eta: 0:00:03  Lr: 0.001875  Loss: -0.8404  Acc@1: 87.5000 (81.3937)  Acc@5: 100.0000 (96.6369)  time: 0.3470  data: 0.0011  max mem: 2500
Train: Epoch[2/5]  [3749/3750]  eta: 0:00:00  Lr: 0.001875  Loss: -1.2086  Acc@1: 87.5000 (81.4083)  Acc@5: 93.7500 (96.6383)  time: 0.3484  data: 0.0015  max mem: 2500
Train: Epoch[2/5] Total time: 0:21:46 (0.3483 s / it)
{0: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 1: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 2: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 3: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 4: {0: 0, 1: 120000, 2: 0, 3: 0, 4: 0}, 5: {0: 0, 1: 120000, 2: 0, 3: 0, 4: 0}, 6: {0: 0, 1: 120000, 2: 0, 3: 0, 4: 0}, 7: {0: 0, 1: 120000, 2: 0, 3: 0, 4: 0}, 8: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 9: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 10: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 11: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 12: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 13: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 14: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 15: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 16: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 17: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 18: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 19: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}}
Averaged stats: Lr: 0.001875  Loss: -1.2086  Acc@1: 87.5000 (81.4083)  Acc@5: 93.7500 (96.6383)
Train: Epoch[3/5]  [   0/3750]  eta: 1:01:08  Lr: 0.001875  Loss: -0.6960  Acc@1: 75.0000 (75.0000)  Acc@5: 100.0000 (100.0000)  time: 0.9783  data: 0.6265  max mem: 2500
Train: Epoch[3/5]  [  10/3750]  eta: 0:25:08  Lr: 0.001875  Loss: -1.3798  Acc@1: 81.2500 (81.2500)  Acc@5: 93.7500 (96.0227)  time: 0.4035  data: 0.0579  max mem: 2500
Train: Epoch[3/5]  [  20/3750]  eta: 0:23:21  Lr: 0.001875  Loss: -0.7021  Acc@1: 81.2500 (82.1429)  Acc@5: 93.7500 (96.4286)  time: 0.3456  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [  30/3750]  eta: 0:22:41  Lr: 0.001875  Loss: -0.9950  Acc@1: 81.2500 (81.2500)  Acc@5: 100.0000 (96.5726)  time: 0.3456  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [  40/3750]  eta: 0:22:20  Lr: 0.001875  Loss: -1.1942  Acc@1: 81.2500 (80.7927)  Acc@5: 100.0000 (96.3415)  time: 0.3462  data: 0.0009  max mem: 2500
Train: Epoch[3/5]  [  50/3750]  eta: 0:22:12  Lr: 0.001875  Loss: -0.8207  Acc@1: 81.2500 (81.8627)  Acc@5: 100.0000 (96.4461)  time: 0.3511  data: 0.0024  max mem: 2500
Train: Epoch[3/5]  [  60/3750]  eta: 0:22:00  Lr: 0.001875  Loss: -0.9341  Acc@1: 87.5000 (82.2746)  Acc@5: 100.0000 (96.7213)  time: 0.3506  data: 0.0024  max mem: 2500
Train: Epoch[3/5]  [  70/3750]  eta: 0:21:53  Lr: 0.001875  Loss: -1.2850  Acc@1: 87.5000 (83.2746)  Acc@5: 100.0000 (96.7430)  time: 0.3482  data: 0.0012  max mem: 2500
Train: Epoch[3/5]  [  80/3750]  eta: 0:21:45  Lr: 0.001875  Loss: -0.8353  Acc@1: 81.2500 (82.7160)  Acc@5: 100.0000 (96.7593)  time: 0.3494  data: 0.0017  max mem: 2500
Train: Epoch[3/5]  [  90/3750]  eta: 0:21:39  Lr: 0.001875  Loss: -0.7273  Acc@1: 81.2500 (82.5549)  Acc@5: 100.0000 (96.9780)  time: 0.3486  data: 0.0011  max mem: 2500
Train: Epoch[3/5]  [ 100/3750]  eta: 0:21:32  Lr: 0.001875  Loss: -0.7433  Acc@1: 87.5000 (82.9208)  Acc@5: 100.0000 (97.0297)  time: 0.3476  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [ 110/3750]  eta: 0:21:26  Lr: 0.001875  Loss: -1.1083  Acc@1: 87.5000 (83.2770)  Acc@5: 100.0000 (97.1847)  time: 0.3456  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [ 120/3750]  eta: 0:21:20  Lr: 0.001875  Loss: -1.2753  Acc@1: 81.2500 (83.1095)  Acc@5: 100.0000 (97.2624)  time: 0.3461  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [ 130/3750]  eta: 0:21:15  Lr: 0.001875  Loss: -0.7542  Acc@1: 81.2500 (83.3015)  Acc@5: 100.0000 (97.2328)  time: 0.3465  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [ 140/3750]  eta: 0:21:10  Lr: 0.001875  Loss: -1.2524  Acc@1: 81.2500 (83.2447)  Acc@5: 100.0000 (97.2518)  time: 0.3473  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [ 150/3750]  eta: 0:21:07  Lr: 0.001875  Loss: -0.9584  Acc@1: 87.5000 (83.4023)  Acc@5: 93.7500 (97.1854)  time: 0.3497  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [ 160/3750]  eta: 0:21:02  Lr: 0.001875  Loss: -1.1632  Acc@1: 81.2500 (83.4627)  Acc@5: 93.7500 (97.1273)  time: 0.3492  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [ 170/3750]  eta: 0:20:57  Lr: 0.001875  Loss: -0.4472  Acc@1: 81.2500 (83.2237)  Acc@5: 93.7500 (97.0395)  time: 0.3469  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [ 180/3750]  eta: 0:20:53  Lr: 0.001875  Loss: -0.9510  Acc@1: 81.2500 (83.3564)  Acc@5: 100.0000 (97.0649)  time: 0.3471  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [ 190/3750]  eta: 0:20:49  Lr: 0.001875  Loss: -0.6455  Acc@1: 81.2500 (83.2461)  Acc@5: 100.0000 (97.0550)  time: 0.3478  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [ 200/3750]  eta: 0:20:44  Lr: 0.001875  Loss: -0.8070  Acc@1: 81.2500 (83.1157)  Acc@5: 100.0000 (97.0149)  time: 0.3465  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [ 210/3750]  eta: 0:20:41  Lr: 0.001875  Loss: -0.5132  Acc@1: 81.2500 (83.0273)  Acc@5: 93.7500 (96.8898)  time: 0.3467  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [ 220/3750]  eta: 0:20:37  Lr: 0.001875  Loss: -1.0868  Acc@1: 81.2500 (83.0034)  Acc@5: 93.7500 (96.8043)  time: 0.3480  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [ 230/3750]  eta: 0:20:33  Lr: 0.001875  Loss: -0.8757  Acc@1: 81.2500 (82.8734)  Acc@5: 93.7500 (96.7262)  time: 0.3477  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [ 240/3750]  eta: 0:20:29  Lr: 0.001875  Loss: -1.1112  Acc@1: 81.2500 (82.7541)  Acc@5: 93.7500 (96.7064)  time: 0.3483  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [ 250/3750]  eta: 0:20:25  Lr: 0.001875  Loss: -0.9904  Acc@1: 81.2500 (82.7938)  Acc@5: 93.7500 (96.6882)  time: 0.3482  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [ 260/3750]  eta: 0:20:21  Lr: 0.001875  Loss: -0.9773  Acc@1: 81.2500 (82.7826)  Acc@5: 93.7500 (96.6715)  time: 0.3463  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [ 270/3750]  eta: 0:20:17  Lr: 0.001875  Loss: -0.4783  Acc@1: 81.2500 (82.7952)  Acc@5: 93.7500 (96.6559)  time: 0.3478  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [ 280/3750]  eta: 0:20:14  Lr: 0.001875  Loss: -1.0527  Acc@1: 81.2500 (82.7847)  Acc@5: 100.0000 (96.7082)  time: 0.3488  data: 0.0017  max mem: 2500
Train: Epoch[3/5]  [ 290/3750]  eta: 0:20:10  Lr: 0.001875  Loss: -0.7162  Acc@1: 81.2500 (82.7749)  Acc@5: 100.0000 (96.7139)  time: 0.3479  data: 0.0017  max mem: 2500
Train: Epoch[3/5]  [ 300/3750]  eta: 0:20:06  Lr: 0.001875  Loss: -0.9837  Acc@1: 81.2500 (82.8073)  Acc@5: 100.0000 (96.7400)  time: 0.3469  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [ 310/3750]  eta: 0:20:02  Lr: 0.001875  Loss: -0.9867  Acc@1: 81.2500 (82.7572)  Acc@5: 100.0000 (96.7645)  time: 0.3465  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [ 320/3750]  eta: 0:19:58  Lr: 0.001875  Loss: -1.3631  Acc@1: 81.2500 (82.7687)  Acc@5: 100.0000 (96.7679)  time: 0.3473  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [ 330/3750]  eta: 0:19:55  Lr: 0.001875  Loss: -0.4298  Acc@1: 81.2500 (82.6473)  Acc@5: 93.7500 (96.7334)  time: 0.3470  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [ 340/3750]  eta: 0:19:51  Lr: 0.001875  Loss: -1.2410  Acc@1: 81.2500 (82.7713)  Acc@5: 93.7500 (96.7009)  time: 0.3491  data: 0.0015  max mem: 2500
Train: Epoch[3/5]  [ 350/3750]  eta: 0:19:47  Lr: 0.001875  Loss: -1.0302  Acc@1: 87.5000 (82.7635)  Acc@5: 100.0000 (96.7415)  time: 0.3484  data: 0.0015  max mem: 2500
Train: Epoch[3/5]  [ 360/3750]  eta: 0:19:44  Lr: 0.001875  Loss: -0.7455  Acc@1: 87.5000 (82.8082)  Acc@5: 100.0000 (96.7278)  time: 0.3470  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [ 370/3750]  eta: 0:19:40  Lr: 0.001875  Loss: -1.1083  Acc@1: 81.2500 (82.7662)  Acc@5: 93.7500 (96.7150)  time: 0.3475  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [ 380/3750]  eta: 0:19:37  Lr: 0.001875  Loss: -0.6533  Acc@1: 81.2500 (82.6936)  Acc@5: 93.7500 (96.7192)  time: 0.3477  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [ 390/3750]  eta: 0:19:33  Lr: 0.001875  Loss: -0.7991  Acc@1: 81.2500 (82.5767)  Acc@5: 93.7500 (96.6592)  time: 0.3485  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [ 400/3750]  eta: 0:19:29  Lr: 0.001875  Loss: -0.8276  Acc@1: 81.2500 (82.4345)  Acc@5: 93.7500 (96.6490)  time: 0.3474  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [ 410/3750]  eta: 0:19:26  Lr: 0.001875  Loss: -0.8858  Acc@1: 81.2500 (82.4057)  Acc@5: 100.0000 (96.6697)  time: 0.3482  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [ 420/3750]  eta: 0:19:22  Lr: 0.001875  Loss: -0.7645  Acc@1: 81.2500 (82.3040)  Acc@5: 100.0000 (96.6597)  time: 0.3494  data: 0.0016  max mem: 2500
Train: Epoch[3/5]  [ 430/3750]  eta: 0:19:18  Lr: 0.001875  Loss: -0.5453  Acc@1: 81.2500 (82.2796)  Acc@5: 100.0000 (96.6792)  time: 0.3465  data: 0.0011  max mem: 2500
Train: Epoch[3/5]  [ 440/3750]  eta: 0:19:15  Lr: 0.001875  Loss: -1.0414  Acc@1: 81.2500 (82.3554)  Acc@5: 100.0000 (96.7120)  time: 0.3456  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [ 450/3750]  eta: 0:19:11  Lr: 0.001875  Loss: -1.0007  Acc@1: 87.5000 (82.4002)  Acc@5: 100.0000 (96.7433)  time: 0.3464  data: 0.0012  max mem: 2500
Train: Epoch[3/5]  [ 460/3750]  eta: 0:19:07  Lr: 0.001875  Loss: -0.9871  Acc@1: 81.2500 (82.3753)  Acc@5: 100.0000 (96.7598)  time: 0.3458  data: 0.0011  max mem: 2500
Train: Epoch[3/5]  [ 470/3750]  eta: 0:19:04  Lr: 0.001875  Loss: -1.2874  Acc@1: 81.2500 (82.3514)  Acc@5: 100.0000 (96.7622)  time: 0.3478  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [ 480/3750]  eta: 0:19:00  Lr: 0.001875  Loss: -0.7509  Acc@1: 81.2500 (82.4324)  Acc@5: 100.0000 (96.7646)  time: 0.3489  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [ 490/3750]  eta: 0:18:57  Lr: 0.001875  Loss: -1.1292  Acc@1: 87.5000 (82.5866)  Acc@5: 100.0000 (96.7668)  time: 0.3476  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [ 500/3750]  eta: 0:18:53  Lr: 0.001875  Loss: -0.8287  Acc@1: 81.2500 (82.4975)  Acc@5: 93.7500 (96.7315)  time: 0.3483  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [ 510/3750]  eta: 0:18:50  Lr: 0.001875  Loss: -0.8379  Acc@1: 81.2500 (82.4853)  Acc@5: 93.7500 (96.7221)  time: 0.3476  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [ 520/3750]  eta: 0:18:46  Lr: 0.001875  Loss: -1.0821  Acc@1: 81.2500 (82.4016)  Acc@5: 93.7500 (96.6531)  time: 0.3463  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [ 530/3750]  eta: 0:18:43  Lr: 0.001875  Loss: -0.4185  Acc@1: 81.2500 (82.3917)  Acc@5: 93.7500 (96.6808)  time: 0.3480  data: 0.0016  max mem: 2500
Train: Epoch[3/5]  [ 540/3750]  eta: 0:18:39  Lr: 0.001875  Loss: -1.0983  Acc@1: 81.2500 (82.3244)  Acc@5: 93.7500 (96.6266)  time: 0.3481  data: 0.0018  max mem: 2500
Train: Epoch[3/5]  [ 550/3750]  eta: 0:18:35  Lr: 0.001875  Loss: -0.7768  Acc@1: 75.0000 (82.2936)  Acc@5: 93.7500 (96.5858)  time: 0.3473  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [ 560/3750]  eta: 0:18:32  Lr: 0.001875  Loss: -0.9560  Acc@1: 81.2500 (82.2750)  Acc@5: 93.7500 (96.5575)  time: 0.3468  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [ 570/3750]  eta: 0:18:28  Lr: 0.001875  Loss: -0.6559  Acc@1: 81.2500 (82.2789)  Acc@5: 100.0000 (96.5630)  time: 0.3459  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [ 580/3750]  eta: 0:18:25  Lr: 0.001875  Loss: -1.0810  Acc@1: 81.2500 (82.1966)  Acc@5: 100.0000 (96.5469)  time: 0.3470  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [ 590/3750]  eta: 0:18:21  Lr: 0.001875  Loss: -1.0472  Acc@1: 81.2500 (82.2229)  Acc@5: 100.0000 (96.5948)  time: 0.3480  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [ 600/3750]  eta: 0:18:17  Lr: 0.001875  Loss: -0.4343  Acc@1: 81.2500 (82.2067)  Acc@5: 100.0000 (96.5994)  time: 0.3472  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 610/3750]  eta: 0:18:14  Lr: 0.001875  Loss: -0.8159  Acc@1: 81.2500 (82.1809)  Acc@5: 100.0000 (96.6448)  time: 0.3470  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [ 620/3750]  eta: 0:18:11  Lr: 0.001875  Loss: -1.1803  Acc@1: 81.2500 (82.2564)  Acc@5: 100.0000 (96.6687)  time: 0.3496  data: 0.0009  max mem: 2500
Train: Epoch[3/5]  [ 630/3750]  eta: 0:18:07  Lr: 0.001875  Loss: -0.8952  Acc@1: 87.5000 (82.3296)  Acc@5: 100.0000 (96.6918)  time: 0.3523  data: 0.0009  max mem: 2500
Train: Epoch[3/5]  [ 640/3750]  eta: 0:18:04  Lr: 0.001875  Loss: -0.4364  Acc@1: 87.5000 (82.3518)  Acc@5: 100.0000 (96.6751)  time: 0.3499  data: 0.0012  max mem: 2500
Train: Epoch[3/5]  [ 650/3750]  eta: 0:18:00  Lr: 0.001875  Loss: -0.9984  Acc@1: 81.2500 (82.3253)  Acc@5: 100.0000 (96.6782)  time: 0.3482  data: 0.0011  max mem: 2500
Train: Epoch[3/5]  [ 660/3750]  eta: 0:17:57  Lr: 0.001875  Loss: -0.8064  Acc@1: 81.2500 (82.3279)  Acc@5: 100.0000 (96.6906)  time: 0.3486  data: 0.0016  max mem: 2500
Train: Epoch[3/5]  [ 670/3750]  eta: 0:17:53  Lr: 0.001875  Loss: -0.6433  Acc@1: 81.2500 (82.2839)  Acc@5: 93.7500 (96.6654)  time: 0.3493  data: 0.0030  max mem: 2500
Train: Epoch[3/5]  [ 680/3750]  eta: 0:17:50  Lr: 0.001875  Loss: -1.1339  Acc@1: 75.0000 (82.1953)  Acc@5: 93.7500 (96.6777)  time: 0.3490  data: 0.0021  max mem: 2500
Train: Epoch[3/5]  [ 690/3750]  eta: 0:17:46  Lr: 0.001875  Loss: -0.9305  Acc@1: 75.0000 (82.1726)  Acc@5: 100.0000 (96.6715)  time: 0.3459  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [ 700/3750]  eta: 0:17:43  Lr: 0.001875  Loss: -1.4143  Acc@1: 81.2500 (82.2129)  Acc@5: 93.7500 (96.6476)  time: 0.3466  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [ 710/3750]  eta: 0:17:39  Lr: 0.001875  Loss: -0.9510  Acc@1: 81.2500 (82.1642)  Acc@5: 93.7500 (96.6421)  time: 0.3464  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [ 720/3750]  eta: 0:17:36  Lr: 0.001875  Loss: -0.6162  Acc@1: 81.2500 (82.1949)  Acc@5: 100.0000 (96.6540)  time: 0.3466  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [ 730/3750]  eta: 0:17:32  Lr: 0.001875  Loss: -1.0568  Acc@1: 81.2500 (82.1563)  Acc@5: 100.0000 (96.6570)  time: 0.3474  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [ 740/3750]  eta: 0:17:28  Lr: 0.001875  Loss: -0.5647  Acc@1: 81.2500 (82.1272)  Acc@5: 100.0000 (96.6684)  time: 0.3471  data: 0.0009  max mem: 2500
Train: Epoch[3/5]  [ 750/3750]  eta: 0:17:25  Lr: 0.001875  Loss: -1.2341  Acc@1: 87.5000 (82.2154)  Acc@5: 100.0000 (96.7044)  time: 0.3491  data: 0.0012  max mem: 2500
Train: Epoch[3/5]  [ 760/3750]  eta: 0:17:21  Lr: 0.001875  Loss: -1.1821  Acc@1: 87.5000 (82.2438)  Acc@5: 100.0000 (96.7231)  time: 0.3479  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [ 770/3750]  eta: 0:17:18  Lr: 0.001875  Loss: -1.0815  Acc@1: 81.2500 (82.2471)  Acc@5: 100.0000 (96.7250)  time: 0.3464  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 780/3750]  eta: 0:17:14  Lr: 0.001875  Loss: -1.1264  Acc@1: 87.5000 (82.2743)  Acc@5: 100.0000 (96.7270)  time: 0.3482  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [ 790/3750]  eta: 0:17:11  Lr: 0.001875  Loss: -0.6715  Acc@1: 81.2500 (82.2535)  Acc@5: 100.0000 (96.7051)  time: 0.3482  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [ 800/3750]  eta: 0:17:07  Lr: 0.001875  Loss: -1.0086  Acc@1: 81.2500 (82.2097)  Acc@5: 93.7500 (96.6994)  time: 0.3474  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [ 810/3750]  eta: 0:17:04  Lr: 0.001875  Loss: -0.4070  Acc@1: 81.2500 (82.2133)  Acc@5: 93.7500 (96.6939)  time: 0.3467  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [ 820/3750]  eta: 0:17:00  Lr: 0.001875  Loss: -1.1065  Acc@1: 87.5000 (82.2244)  Acc@5: 93.7500 (96.6809)  time: 0.3479  data: 0.0010  max mem: 2500
Train: Epoch[3/5]  [ 830/3750]  eta: 0:16:57  Lr: 0.001875  Loss: -0.7255  Acc@1: 81.2500 (82.2277)  Acc@5: 100.0000 (96.7058)  time: 0.3496  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [ 840/3750]  eta: 0:16:53  Lr: 0.001875  Loss: -0.2953  Acc@1: 75.0000 (82.1715)  Acc@5: 100.0000 (96.7152)  time: 0.3477  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [ 850/3750]  eta: 0:16:50  Lr: 0.001875  Loss: -0.6853  Acc@1: 75.0000 (82.1680)  Acc@5: 100.0000 (96.7171)  time: 0.3471  data: 0.0011  max mem: 2500
Train: Epoch[3/5]  [ 860/3750]  eta: 0:16:46  Lr: 0.001875  Loss: -0.8014  Acc@1: 87.5000 (82.1864)  Acc@5: 100.0000 (96.7334)  time: 0.3476  data: 0.0011  max mem: 2500
Train: Epoch[3/5]  [ 870/3750]  eta: 0:16:43  Lr: 0.001875  Loss: -0.9275  Acc@1: 87.5000 (82.1972)  Acc@5: 100.0000 (96.7207)  time: 0.3477  data: 0.0011  max mem: 2500
Train: Epoch[3/5]  [ 880/3750]  eta: 0:16:39  Lr: 0.001875  Loss: -0.8591  Acc@1: 81.2500 (82.1935)  Acc@5: 100.0000 (96.7154)  time: 0.3486  data: 0.0011  max mem: 2500
Train: Epoch[3/5]  [ 890/3750]  eta: 0:16:36  Lr: 0.001875  Loss: -0.7971  Acc@1: 75.0000 (82.1689)  Acc@5: 100.0000 (96.7172)  time: 0.3476  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [ 900/3750]  eta: 0:16:32  Lr: 0.001875  Loss: -0.1910  Acc@1: 75.0000 (82.1518)  Acc@5: 100.0000 (96.7328)  time: 0.3477  data: 0.0009  max mem: 2500
Train: Epoch[3/5]  [ 910/3750]  eta: 0:16:29  Lr: 0.001875  Loss: -1.0639  Acc@1: 81.2500 (82.1556)  Acc@5: 100.0000 (96.7412)  time: 0.3464  data: 0.0009  max mem: 2500
Train: Epoch[3/5]  [ 920/3750]  eta: 0:16:25  Lr: 0.001875  Loss: -0.8948  Acc@1: 81.2500 (82.1797)  Acc@5: 100.0000 (96.7427)  time: 0.3460  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [ 930/3750]  eta: 0:16:22  Lr: 0.001875  Loss: -1.3100  Acc@1: 81.2500 (82.1496)  Acc@5: 100.0000 (96.7441)  time: 0.3472  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [ 940/3750]  eta: 0:16:18  Lr: 0.001875  Loss: -0.9579  Acc@1: 75.0000 (82.1467)  Acc@5: 100.0000 (96.7588)  time: 0.3465  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [ 950/3750]  eta: 0:16:15  Lr: 0.001875  Loss: -0.8607  Acc@1: 81.2500 (82.1569)  Acc@5: 93.7500 (96.7206)  time: 0.3463  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [ 960/3750]  eta: 0:16:11  Lr: 0.001875  Loss: -0.7715  Acc@1: 81.2500 (82.1670)  Acc@5: 93.7500 (96.7222)  time: 0.3459  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [ 970/3750]  eta: 0:16:08  Lr: 0.001875  Loss: -1.3236  Acc@1: 81.2500 (82.1640)  Acc@5: 100.0000 (96.7302)  time: 0.3469  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 980/3750]  eta: 0:16:04  Lr: 0.001875  Loss: -1.1590  Acc@1: 81.2500 (82.1356)  Acc@5: 100.0000 (96.7380)  time: 0.3480  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [ 990/3750]  eta: 0:16:01  Lr: 0.001875  Loss: -0.8753  Acc@1: 81.2500 (82.1771)  Acc@5: 100.0000 (96.7394)  time: 0.3462  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [1000/3750]  eta: 0:15:57  Lr: 0.001875  Loss: -0.9171  Acc@1: 81.2500 (82.1491)  Acc@5: 93.7500 (96.7283)  time: 0.3454  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [1010/3750]  eta: 0:15:53  Lr: 0.001875  Loss: -0.7611  Acc@1: 81.2500 (82.1402)  Acc@5: 100.0000 (96.7235)  time: 0.3469  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [1020/3750]  eta: 0:15:50  Lr: 0.001875  Loss: -0.3909  Acc@1: 81.2500 (82.1805)  Acc@5: 100.0000 (96.7311)  time: 0.3471  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [1030/3750]  eta: 0:15:46  Lr: 0.001875  Loss: -0.9084  Acc@1: 81.2500 (82.1593)  Acc@5: 100.0000 (96.7386)  time: 0.3470  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [1040/3750]  eta: 0:15:43  Lr: 0.001875  Loss: -0.8458  Acc@1: 81.2500 (82.1386)  Acc@5: 100.0000 (96.7339)  time: 0.3481  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [1050/3750]  eta: 0:15:40  Lr: 0.001875  Loss: -0.8980  Acc@1: 81.2500 (82.0647)  Acc@5: 93.7500 (96.7353)  time: 0.3483  data: 0.0010  max mem: 2500
Train: Epoch[3/5]  [1060/3750]  eta: 0:15:36  Lr: 0.001875  Loss: -1.0254  Acc@1: 81.2500 (82.0570)  Acc@5: 100.0000 (96.7542)  time: 0.3473  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [1070/3750]  eta: 0:15:33  Lr: 0.001875  Loss: -0.8562  Acc@1: 81.2500 (82.0670)  Acc@5: 100.0000 (96.7437)  time: 0.3486  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1080/3750]  eta: 0:15:29  Lr: 0.001875  Loss: -0.9841  Acc@1: 81.2500 (82.0652)  Acc@5: 100.0000 (96.7623)  time: 0.3483  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1090/3750]  eta: 0:15:26  Lr: 0.001875  Loss: -1.0294  Acc@1: 81.2500 (82.0577)  Acc@5: 100.0000 (96.7747)  time: 0.3472  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1100/3750]  eta: 0:15:22  Lr: 0.001875  Loss: -1.0722  Acc@1: 87.5000 (82.0901)  Acc@5: 100.0000 (96.7757)  time: 0.3470  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [1110/3750]  eta: 0:15:19  Lr: 0.001875  Loss: -0.9381  Acc@1: 87.5000 (82.1051)  Acc@5: 100.0000 (96.7934)  time: 0.3492  data: 0.0024  max mem: 2500
Train: Epoch[3/5]  [1120/3750]  eta: 0:15:15  Lr: 0.001875  Loss: -0.5216  Acc@1: 81.2500 (82.1253)  Acc@5: 100.0000 (96.7942)  time: 0.3498  data: 0.0024  max mem: 2500
Train: Epoch[3/5]  [1130/3750]  eta: 0:15:12  Lr: 0.001875  Loss: -0.6029  Acc@1: 81.2500 (82.1065)  Acc@5: 100.0000 (96.7893)  time: 0.3459  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [1140/3750]  eta: 0:15:08  Lr: 0.001875  Loss: -0.9587  Acc@1: 87.5000 (82.1374)  Acc@5: 100.0000 (96.8065)  time: 0.3460  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [1150/3750]  eta: 0:15:05  Lr: 0.001875  Loss: -1.1143  Acc@1: 81.2500 (82.1134)  Acc@5: 100.0000 (96.8017)  time: 0.3476  data: 0.0012  max mem: 2500
Train: Epoch[3/5]  [1160/3750]  eta: 0:15:01  Lr: 0.001875  Loss: -1.1672  Acc@1: 81.2500 (82.1329)  Acc@5: 100.0000 (96.7969)  time: 0.3482  data: 0.0019  max mem: 2500
Train: Epoch[3/5]  [1170/3750]  eta: 0:14:58  Lr: 0.001875  Loss: -0.7553  Acc@1: 81.2500 (82.1200)  Acc@5: 100.0000 (96.7923)  time: 0.3482  data: 0.0013  max mem: 2500
Train: Epoch[3/5]  [1180/3750]  eta: 0:14:54  Lr: 0.001875  Loss: -0.9726  Acc@1: 81.2500 (82.1444)  Acc@5: 100.0000 (96.8088)  time: 0.3486  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [1190/3750]  eta: 0:14:51  Lr: 0.001875  Loss: -1.2499  Acc@1: 87.5000 (82.1421)  Acc@5: 100.0000 (96.8042)  time: 0.3498  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1200/3750]  eta: 0:14:47  Lr: 0.001875  Loss: -1.2366  Acc@1: 87.5000 (82.1971)  Acc@5: 93.7500 (96.7995)  time: 0.3487  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [1210/3750]  eta: 0:14:44  Lr: 0.001875  Loss: -0.7223  Acc@1: 87.5000 (82.1635)  Acc@5: 100.0000 (96.8105)  time: 0.3476  data: 0.0013  max mem: 2500
Train: Epoch[3/5]  [1220/3750]  eta: 0:14:40  Lr: 0.001875  Loss: -1.2632  Acc@1: 81.2500 (82.2021)  Acc@5: 100.0000 (96.8213)  time: 0.3471  data: 0.0012  max mem: 2500
Train: Epoch[3/5]  [1230/3750]  eta: 0:14:37  Lr: 0.001875  Loss: -0.9530  Acc@1: 81.2500 (82.1893)  Acc@5: 100.0000 (96.8166)  time: 0.3466  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [1240/3750]  eta: 0:14:33  Lr: 0.001875  Loss: -1.1825  Acc@1: 81.2500 (82.1666)  Acc@5: 93.7500 (96.8020)  time: 0.3473  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [1250/3750]  eta: 0:14:30  Lr: 0.001875  Loss: -0.9202  Acc@1: 81.2500 (82.1193)  Acc@5: 93.7500 (96.7976)  time: 0.3489  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [1260/3750]  eta: 0:14:26  Lr: 0.001875  Loss: -1.1533  Acc@1: 81.2500 (82.1273)  Acc@5: 100.0000 (96.8130)  time: 0.3483  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [1270/3750]  eta: 0:14:23  Lr: 0.001875  Loss: -1.1318  Acc@1: 81.2500 (82.1253)  Acc@5: 100.0000 (96.8086)  time: 0.3473  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [1280/3750]  eta: 0:14:19  Lr: 0.001875  Loss: -1.1370  Acc@1: 81.2500 (82.1087)  Acc@5: 93.7500 (96.8043)  time: 0.3482  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [1290/3750]  eta: 0:14:16  Lr: 0.001875  Loss: -0.8793  Acc@1: 81.2500 (82.1069)  Acc@5: 100.0000 (96.8000)  time: 0.3475  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [1300/3750]  eta: 0:14:12  Lr: 0.001875  Loss: -1.0905  Acc@1: 81.2500 (82.0811)  Acc@5: 100.0000 (96.8053)  time: 0.3490  data: 0.0019  max mem: 2500
Train: Epoch[3/5]  [1310/3750]  eta: 0:14:09  Lr: 0.001875  Loss: -0.7423  Acc@1: 81.2500 (82.1129)  Acc@5: 100.0000 (96.8154)  time: 0.3501  data: 0.0032  max mem: 2500
Train: Epoch[3/5]  [1320/3750]  eta: 0:14:05  Lr: 0.001875  Loss: -0.4943  Acc@1: 81.2500 (82.1158)  Acc@5: 100.0000 (96.8064)  time: 0.3488  data: 0.0031  max mem: 2500
Train: Epoch[3/5]  [1330/3750]  eta: 0:14:02  Lr: 0.001875  Loss: -0.6034  Acc@1: 87.5000 (82.1375)  Acc@5: 93.7500 (96.8022)  time: 0.3476  data: 0.0018  max mem: 2500
Train: Epoch[3/5]  [1340/3750]  eta: 0:13:58  Lr: 0.001875  Loss: -0.9368  Acc@1: 87.5000 (82.1449)  Acc@5: 93.7500 (96.7841)  time: 0.3461  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [1350/3750]  eta: 0:13:55  Lr: 0.001875  Loss: -0.8278  Acc@1: 87.5000 (82.1660)  Acc@5: 100.0000 (96.7940)  time: 0.3475  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [1360/3750]  eta: 0:13:52  Lr: 0.001875  Loss: -0.6143  Acc@1: 87.5000 (82.1684)  Acc@5: 100.0000 (96.7946)  time: 0.3499  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [1370/3750]  eta: 0:13:48  Lr: 0.001875  Loss: -0.7460  Acc@1: 87.5000 (82.2119)  Acc@5: 100.0000 (96.7952)  time: 0.3489  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [1380/3750]  eta: 0:13:45  Lr: 0.001875  Loss: -0.7397  Acc@1: 81.2500 (82.2094)  Acc@5: 100.0000 (96.7686)  time: 0.3466  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [1390/3750]  eta: 0:13:41  Lr: 0.001875  Loss: -1.1064  Acc@1: 81.2500 (82.2340)  Acc@5: 100.0000 (96.7829)  time: 0.3475  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [1400/3750]  eta: 0:13:38  Lr: 0.001875  Loss: -1.1171  Acc@1: 81.2500 (82.2047)  Acc@5: 100.0000 (96.7791)  time: 0.3474  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [1410/3750]  eta: 0:13:34  Lr: 0.001875  Loss: -0.8643  Acc@1: 75.0000 (82.1891)  Acc@5: 100.0000 (96.7842)  time: 0.3483  data: 0.0010  max mem: 2500
Train: Epoch[3/5]  [1420/3750]  eta: 0:13:31  Lr: 0.001875  Loss: -0.9888  Acc@1: 81.2500 (82.2044)  Acc@5: 100.0000 (96.7716)  time: 0.3496  data: 0.0010  max mem: 2500
Train: Epoch[3/5]  [1430/3750]  eta: 0:13:27  Lr: 0.001875  Loss: -0.8488  Acc@1: 87.5000 (82.2371)  Acc@5: 93.7500 (96.7593)  time: 0.3466  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [1440/3750]  eta: 0:13:24  Lr: 0.001875  Loss: -1.0408  Acc@1: 87.5000 (82.2346)  Acc@5: 93.7500 (96.7644)  time: 0.3456  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [1450/3750]  eta: 0:13:20  Lr: 0.001875  Loss: -0.8942  Acc@1: 87.5000 (82.2450)  Acc@5: 100.0000 (96.7609)  time: 0.3484  data: 0.0022  max mem: 2500
Train: Epoch[3/5]  [1460/3750]  eta: 0:13:17  Lr: 0.001875  Loss: -0.9509  Acc@1: 87.5000 (82.2895)  Acc@5: 100.0000 (96.7659)  time: 0.3481  data: 0.0019  max mem: 2500
Train: Epoch[3/5]  [1470/3750]  eta: 0:13:13  Lr: 0.001875  Loss: -0.2771  Acc@1: 87.5000 (82.2782)  Acc@5: 100.0000 (96.7709)  time: 0.3466  data: 0.0009  max mem: 2500
Train: Epoch[3/5]  [1480/3750]  eta: 0:13:10  Lr: 0.001875  Loss: -1.1001  Acc@1: 81.2500 (82.3050)  Acc@5: 100.0000 (96.7800)  time: 0.3467  data: 0.0009  max mem: 2500
Train: Epoch[3/5]  [1490/3750]  eta: 0:13:06  Lr: 0.001875  Loss: -1.0414  Acc@1: 81.2500 (82.2812)  Acc@5: 100.0000 (96.7807)  time: 0.3481  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [1500/3750]  eta: 0:13:03  Lr: 0.001875  Loss: -0.9702  Acc@1: 81.2500 (82.2910)  Acc@5: 100.0000 (96.7771)  time: 0.3488  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [1510/3750]  eta: 0:12:59  Lr: 0.001875  Loss: -1.2937  Acc@1: 81.2500 (82.2924)  Acc@5: 93.7500 (96.7695)  time: 0.3497  data: 0.0022  max mem: 2500
Train: Epoch[3/5]  [1520/3750]  eta: 0:12:56  Lr: 0.001875  Loss: -0.8514  Acc@1: 81.2500 (82.2978)  Acc@5: 100.0000 (96.7702)  time: 0.3500  data: 0.0021  max mem: 2500
Train: Epoch[3/5]  [1530/3750]  eta: 0:12:52  Lr: 0.001875  Loss: -0.5672  Acc@1: 87.5000 (82.3073)  Acc@5: 100.0000 (96.7668)  time: 0.3477  data: 0.0010  max mem: 2500
Train: Epoch[3/5]  [1540/3750]  eta: 0:12:49  Lr: 0.001875  Loss: -0.6711  Acc@1: 87.5000 (82.3288)  Acc@5: 100.0000 (96.7756)  time: 0.3481  data: 0.0009  max mem: 2500
Train: Epoch[3/5]  [1550/3750]  eta: 0:12:45  Lr: 0.001875  Loss: -1.2580  Acc@1: 87.5000 (82.3420)  Acc@5: 100.0000 (96.7682)  time: 0.3489  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [1560/3750]  eta: 0:12:42  Lr: 0.001875  Loss: -0.8550  Acc@1: 81.2500 (82.3430)  Acc@5: 100.0000 (96.7569)  time: 0.3497  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [1570/3750]  eta: 0:12:38  Lr: 0.001875  Loss: -0.6368  Acc@1: 81.2500 (82.3520)  Acc@5: 93.7500 (96.7616)  time: 0.3487  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [1580/3750]  eta: 0:12:35  Lr: 0.001875  Loss: -0.7631  Acc@1: 81.2500 (82.3727)  Acc@5: 100.0000 (96.7702)  time: 0.3479  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [1590/3750]  eta: 0:12:31  Lr: 0.001875  Loss: -0.4651  Acc@1: 81.2500 (82.3578)  Acc@5: 100.0000 (96.7748)  time: 0.3481  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [1600/3750]  eta: 0:12:28  Lr: 0.001875  Loss: -0.9775  Acc@1: 81.2500 (82.3509)  Acc@5: 100.0000 (96.7872)  time: 0.3480  data: 0.0009  max mem: 2500
Train: Epoch[3/5]  [1610/3750]  eta: 0:12:24  Lr: 0.001875  Loss: -1.1966  Acc@1: 81.2500 (82.3479)  Acc@5: 100.0000 (96.7683)  time: 0.3471  data: 0.0009  max mem: 2500
Train: Epoch[3/5]  [1620/3750]  eta: 0:12:21  Lr: 0.001875  Loss: -0.8975  Acc@1: 81.2500 (82.3604)  Acc@5: 93.7500 (96.7728)  time: 0.3469  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [1630/3750]  eta: 0:12:17  Lr: 0.001875  Loss: -0.7286  Acc@1: 81.2500 (82.3306)  Acc@5: 100.0000 (96.7581)  time: 0.3467  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [1640/3750]  eta: 0:12:14  Lr: 0.001875  Loss: -0.9944  Acc@1: 81.2500 (82.3278)  Acc@5: 100.0000 (96.7588)  time: 0.3465  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [1650/3750]  eta: 0:12:10  Lr: 0.001875  Loss: -1.1003  Acc@1: 81.2500 (82.3327)  Acc@5: 100.0000 (96.7633)  time: 0.3465  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [1660/3750]  eta: 0:12:07  Lr: 0.001875  Loss: -0.7060  Acc@1: 81.2500 (82.3563)  Acc@5: 100.0000 (96.7602)  time: 0.3459  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [1670/3750]  eta: 0:12:03  Lr: 0.001875  Loss: -0.8804  Acc@1: 81.2500 (82.3422)  Acc@5: 100.0000 (96.7721)  time: 0.3468  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [1680/3750]  eta: 0:12:00  Lr: 0.001875  Loss: -1.0951  Acc@1: 81.2500 (82.3580)  Acc@5: 100.0000 (96.7839)  time: 0.3466  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [1690/3750]  eta: 0:11:56  Lr: 0.001875  Loss: -0.8427  Acc@1: 81.2500 (82.3662)  Acc@5: 100.0000 (96.7844)  time: 0.3461  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [1700/3750]  eta: 0:11:53  Lr: 0.001875  Loss: -0.6918  Acc@1: 81.2500 (82.3633)  Acc@5: 93.7500 (96.7703)  time: 0.3486  data: 0.0014  max mem: 2500
Train: Epoch[3/5]  [1710/3750]  eta: 0:11:49  Lr: 0.001875  Loss: -0.6232  Acc@1: 87.5000 (82.3933)  Acc@5: 93.7500 (96.7672)  time: 0.3483  data: 0.0014  max mem: 2500
Train: Epoch[3/5]  [1720/3750]  eta: 0:11:46  Lr: 0.001875  Loss: -1.3473  Acc@1: 87.5000 (82.4157)  Acc@5: 100.0000 (96.7679)  time: 0.3463  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [1730/3750]  eta: 0:11:42  Lr: 0.001875  Loss: -0.9264  Acc@1: 87.5000 (82.4126)  Acc@5: 100.0000 (96.7685)  time: 0.3466  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [1740/3750]  eta: 0:11:39  Lr: 0.001875  Loss: -0.4526  Acc@1: 81.2500 (82.3880)  Acc@5: 100.0000 (96.7619)  time: 0.3454  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [1750/3750]  eta: 0:11:35  Lr: 0.001875  Loss: -0.6507  Acc@1: 81.2500 (82.3744)  Acc@5: 93.7500 (96.7554)  time: 0.3461  data: 0.0009  max mem: 2500
Train: Epoch[3/5]  [1760/3750]  eta: 0:11:32  Lr: 0.001875  Loss: -1.0893  Acc@1: 87.5000 (82.3999)  Acc@5: 93.7500 (96.7526)  time: 0.3466  data: 0.0009  max mem: 2500
Train: Epoch[3/5]  [1770/3750]  eta: 0:11:29  Lr: 0.001875  Loss: -1.0574  Acc@1: 87.5000 (82.4181)  Acc@5: 93.7500 (96.7497)  time: 0.3477  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [1780/3750]  eta: 0:11:25  Lr: 0.001875  Loss: -0.5510  Acc@1: 87.5000 (82.3975)  Acc@5: 93.7500 (96.7469)  time: 0.3479  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [1790/3750]  eta: 0:11:22  Lr: 0.001875  Loss: -0.3796  Acc@1: 87.5000 (82.4295)  Acc@5: 100.0000 (96.7476)  time: 0.3466  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [1800/3750]  eta: 0:11:18  Lr: 0.001875  Loss: -0.3515  Acc@1: 87.5000 (82.4264)  Acc@5: 100.0000 (96.7518)  time: 0.3473  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [1810/3750]  eta: 0:11:15  Lr: 0.001875  Loss: -0.8477  Acc@1: 87.5000 (82.4303)  Acc@5: 100.0000 (96.7490)  time: 0.3466  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [1820/3750]  eta: 0:11:11  Lr: 0.001875  Loss: -0.4853  Acc@1: 87.5000 (82.4375)  Acc@5: 100.0000 (96.7566)  time: 0.3459  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [1830/3750]  eta: 0:11:08  Lr: 0.001875  Loss: -1.1113  Acc@1: 87.5000 (82.4515)  Acc@5: 100.0000 (96.7641)  time: 0.3455  data: 0.0009  max mem: 2500
Train: Epoch[3/5]  [1840/3750]  eta: 0:11:04  Lr: 0.001875  Loss: -1.0440  Acc@1: 81.2500 (82.4416)  Acc@5: 100.0000 (96.7545)  time: 0.3468  data: 0.0013  max mem: 2500
Train: Epoch[3/5]  [1850/3750]  eta: 0:11:01  Lr: 0.001875  Loss: -1.2387  Acc@1: 87.5000 (82.4689)  Acc@5: 100.0000 (96.7653)  time: 0.3477  data: 0.0016  max mem: 2500
Train: Epoch[3/5]  [1860/3750]  eta: 0:10:57  Lr: 0.001875  Loss: -0.8227  Acc@1: 81.2500 (82.4523)  Acc@5: 100.0000 (96.7591)  time: 0.3479  data: 0.0015  max mem: 2500
Train: Epoch[3/5]  [1870/3750]  eta: 0:10:54  Lr: 0.001875  Loss: -0.9612  Acc@1: 81.2500 (82.4459)  Acc@5: 100.0000 (96.7664)  time: 0.3478  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [1880/3750]  eta: 0:10:50  Lr: 0.001875  Loss: -1.0015  Acc@1: 81.2500 (82.4229)  Acc@5: 100.0000 (96.7604)  time: 0.3471  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1890/3750]  eta: 0:10:47  Lr: 0.001875  Loss: -0.8057  Acc@1: 81.2500 (82.4332)  Acc@5: 100.0000 (96.7676)  time: 0.3476  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [1900/3750]  eta: 0:10:43  Lr: 0.001875  Loss: -0.2858  Acc@1: 81.2500 (82.4040)  Acc@5: 100.0000 (96.7681)  time: 0.3468  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [1910/3750]  eta: 0:10:40  Lr: 0.001875  Loss: -1.0218  Acc@1: 81.2500 (82.3914)  Acc@5: 100.0000 (96.7720)  time: 0.3463  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [1920/3750]  eta: 0:10:36  Lr: 0.001875  Loss: -0.9982  Acc@1: 81.2500 (82.3887)  Acc@5: 100.0000 (96.7693)  time: 0.3474  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [1930/3750]  eta: 0:10:33  Lr: 0.001875  Loss: -0.9956  Acc@1: 81.2500 (82.3958)  Acc@5: 100.0000 (96.7730)  time: 0.3469  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [1940/3750]  eta: 0:10:29  Lr: 0.001875  Loss: -1.2479  Acc@1: 87.5000 (82.4156)  Acc@5: 100.0000 (96.7704)  time: 0.3467  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [1950/3750]  eta: 0:10:26  Lr: 0.001875  Loss: -1.0398  Acc@1: 87.5000 (82.4289)  Acc@5: 93.7500 (96.7613)  time: 0.3480  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [1960/3750]  eta: 0:10:22  Lr: 0.001875  Loss: -0.9581  Acc@1: 81.2500 (82.4324)  Acc@5: 93.7500 (96.7555)  time: 0.3470  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [1970/3750]  eta: 0:10:19  Lr: 0.001875  Loss: -0.7173  Acc@1: 81.2500 (82.4169)  Acc@5: 100.0000 (96.7434)  time: 0.3473  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [1980/3750]  eta: 0:10:15  Lr: 0.001875  Loss: -0.2497  Acc@1: 81.2500 (82.4142)  Acc@5: 93.7500 (96.7346)  time: 0.3474  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [1990/3750]  eta: 0:10:12  Lr: 0.001875  Loss: -0.9807  Acc@1: 81.2500 (82.4115)  Acc@5: 93.7500 (96.7322)  time: 0.3467  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [2000/3750]  eta: 0:10:08  Lr: 0.001875  Loss: -1.1588  Acc@1: 81.2500 (82.4150)  Acc@5: 93.7500 (96.7266)  time: 0.3475  data: 0.0010  max mem: 2500
Train: Epoch[3/5]  [2010/3750]  eta: 0:10:05  Lr: 0.001875  Loss: -1.0383  Acc@1: 81.2500 (82.3875)  Acc@5: 93.7500 (96.7336)  time: 0.3463  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [2020/3750]  eta: 0:10:01  Lr: 0.001875  Loss: -1.2319  Acc@1: 81.2500 (82.3757)  Acc@5: 93.7500 (96.7188)  time: 0.3465  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [2030/3750]  eta: 0:09:58  Lr: 0.001875  Loss: -0.8039  Acc@1: 81.2500 (82.3886)  Acc@5: 100.0000 (96.7288)  time: 0.3476  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [2040/3750]  eta: 0:09:54  Lr: 0.001875  Loss: -1.1040  Acc@1: 81.2500 (82.3800)  Acc@5: 100.0000 (96.7265)  time: 0.3471  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [2050/3750]  eta: 0:09:51  Lr: 0.001875  Loss: -0.6454  Acc@1: 81.2500 (82.3775)  Acc@5: 93.7500 (96.7303)  time: 0.3464  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [2060/3750]  eta: 0:09:47  Lr: 0.001875  Loss: -0.9299  Acc@1: 87.5000 (82.3993)  Acc@5: 100.0000 (96.7431)  time: 0.3468  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [2070/3750]  eta: 0:09:44  Lr: 0.001875  Loss: -0.9963  Acc@1: 87.5000 (82.4149)  Acc@5: 100.0000 (96.7498)  time: 0.3478  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [2080/3750]  eta: 0:09:40  Lr: 0.001875  Loss: -0.8952  Acc@1: 87.5000 (82.4093)  Acc@5: 100.0000 (96.7414)  time: 0.3475  data: 0.0009  max mem: 2500
Train: Epoch[3/5]  [2090/3750]  eta: 0:09:37  Lr: 0.001875  Loss: -0.7309  Acc@1: 81.2500 (82.4097)  Acc@5: 93.7500 (96.7360)  time: 0.3472  data: 0.0009  max mem: 2500
Train: Epoch[3/5]  [2100/3750]  eta: 0:09:33  Lr: 0.001875  Loss: -0.5982  Acc@1: 81.2500 (82.3774)  Acc@5: 93.7500 (96.7307)  time: 0.3468  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [2110/3750]  eta: 0:09:30  Lr: 0.001875  Loss: -0.9249  Acc@1: 81.2500 (82.3751)  Acc@5: 93.7500 (96.7225)  time: 0.3462  data: 0.0011  max mem: 2500
Train: Epoch[3/5]  [2120/3750]  eta: 0:09:26  Lr: 0.001875  Loss: -1.2121  Acc@1: 81.2500 (82.3727)  Acc@5: 100.0000 (96.7232)  time: 0.3457  data: 0.0011  max mem: 2500
Train: Epoch[3/5]  [2130/3750]  eta: 0:09:23  Lr: 0.001875  Loss: -0.5790  Acc@1: 81.2500 (82.3733)  Acc@5: 100.0000 (96.7240)  time: 0.3462  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [2140/3750]  eta: 0:09:19  Lr: 0.001875  Loss: -0.7312  Acc@1: 81.2500 (82.3651)  Acc@5: 100.0000 (96.7188)  time: 0.3470  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [2150/3750]  eta: 0:09:16  Lr: 0.001875  Loss: -0.8739  Acc@1: 81.2500 (82.3861)  Acc@5: 100.0000 (96.7225)  time: 0.3485  data: 0.0009  max mem: 2500
Train: Epoch[3/5]  [2160/3750]  eta: 0:09:13  Lr: 0.001875  Loss: -0.5171  Acc@1: 87.5000 (82.3895)  Acc@5: 100.0000 (96.7232)  time: 0.3478  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [2170/3750]  eta: 0:09:09  Lr: 0.001875  Loss: -0.9875  Acc@1: 81.2500 (82.3958)  Acc@5: 100.0000 (96.7239)  time: 0.3474  data: 0.0015  max mem: 2500
Train: Epoch[3/5]  [2180/3750]  eta: 0:09:06  Lr: 0.001875  Loss: -1.0398  Acc@1: 81.2500 (82.3991)  Acc@5: 100.0000 (96.7303)  time: 0.3513  data: 0.0031  max mem: 2500
Train: Epoch[3/5]  [2190/3750]  eta: 0:09:02  Lr: 0.001875  Loss: -0.9508  Acc@1: 87.5000 (82.4053)  Acc@5: 100.0000 (96.7224)  time: 0.3496  data: 0.0021  max mem: 2500
Train: Epoch[3/5]  [2200/3750]  eta: 0:08:59  Lr: 0.001875  Loss: -1.2578  Acc@1: 81.2500 (82.4029)  Acc@5: 93.7500 (96.7174)  time: 0.3473  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [2210/3750]  eta: 0:08:55  Lr: 0.001875  Loss: -0.7531  Acc@1: 81.2500 (82.4033)  Acc@5: 93.7500 (96.7153)  time: 0.3482  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [2220/3750]  eta: 0:08:52  Lr: 0.001875  Loss: -0.6668  Acc@1: 81.2500 (82.4150)  Acc@5: 93.7500 (96.7188)  time: 0.3475  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [2230/3750]  eta: 0:08:48  Lr: 0.001875  Loss: -1.2999  Acc@1: 87.5000 (82.4238)  Acc@5: 100.0000 (96.7279)  time: 0.3468  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [2240/3750]  eta: 0:08:45  Lr: 0.001875  Loss: -0.2947  Acc@1: 81.2500 (82.3963)  Acc@5: 100.0000 (96.7258)  time: 0.3476  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [2250/3750]  eta: 0:08:41  Lr: 0.001875  Loss: -0.6692  Acc@1: 81.2500 (82.3967)  Acc@5: 93.7500 (96.7237)  time: 0.3485  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2260/3750]  eta: 0:08:38  Lr: 0.001875  Loss: -1.3773  Acc@1: 81.2500 (82.4027)  Acc@5: 100.0000 (96.7326)  time: 0.3471  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [2270/3750]  eta: 0:08:34  Lr: 0.001875  Loss: -0.5998  Acc@1: 81.2500 (82.4086)  Acc@5: 100.0000 (96.7388)  time: 0.3467  data: 0.0010  max mem: 2500
Train: Epoch[3/5]  [2280/3750]  eta: 0:08:31  Lr: 0.001875  Loss: -0.6597  Acc@1: 81.2500 (82.3789)  Acc@5: 100.0000 (96.7311)  time: 0.3478  data: 0.0017  max mem: 2500
Train: Epoch[3/5]  [2290/3750]  eta: 0:08:27  Lr: 0.001875  Loss: -0.9793  Acc@1: 81.2500 (82.3821)  Acc@5: 100.0000 (96.7318)  time: 0.3482  data: 0.0014  max mem: 2500
Train: Epoch[3/5]  [2300/3750]  eta: 0:08:24  Lr: 0.001875  Loss: -0.6818  Acc@1: 81.2500 (82.3745)  Acc@5: 100.0000 (96.7351)  time: 0.3473  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [2310/3750]  eta: 0:08:20  Lr: 0.001875  Loss: -0.8679  Acc@1: 81.2500 (82.3723)  Acc@5: 100.0000 (96.7303)  time: 0.3474  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [2320/3750]  eta: 0:08:17  Lr: 0.001875  Loss: -0.9119  Acc@1: 87.5000 (82.3837)  Acc@5: 93.7500 (96.7229)  time: 0.3483  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [2330/3750]  eta: 0:08:13  Lr: 0.001875  Loss: -1.0917  Acc@1: 81.2500 (82.3788)  Acc@5: 93.7500 (96.7181)  time: 0.3469  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [2340/3750]  eta: 0:08:10  Lr: 0.001875  Loss: -0.8329  Acc@1: 81.2500 (82.3793)  Acc@5: 93.7500 (96.7188)  time: 0.3456  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [2350/3750]  eta: 0:08:06  Lr: 0.001875  Loss: -1.3348  Acc@1: 81.2500 (82.3745)  Acc@5: 100.0000 (96.7248)  time: 0.3477  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [2360/3750]  eta: 0:08:03  Lr: 0.001875  Loss: -1.0956  Acc@1: 87.5000 (82.4068)  Acc@5: 100.0000 (96.7307)  time: 0.3480  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [2370/3750]  eta: 0:07:59  Lr: 0.001875  Loss: -0.9927  Acc@1: 87.5000 (82.4151)  Acc@5: 100.0000 (96.7340)  time: 0.3467  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [2380/3750]  eta: 0:07:56  Lr: 0.001875  Loss: -0.3954  Acc@1: 81.2500 (82.4050)  Acc@5: 100.0000 (96.7293)  time: 0.3479  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [2390/3750]  eta: 0:07:53  Lr: 0.001875  Loss: -1.0143  Acc@1: 81.2500 (82.4158)  Acc@5: 100.0000 (96.7378)  time: 0.3477  data: 0.0009  max mem: 2500
Train: Epoch[3/5]  [2400/3750]  eta: 0:07:49  Lr: 0.001875  Loss: -0.7776  Acc@1: 81.2500 (82.4188)  Acc@5: 100.0000 (96.7357)  time: 0.3462  data: 0.0009  max mem: 2500
Train: Epoch[3/5]  [2410/3750]  eta: 0:07:46  Lr: 0.001875  Loss: -0.9901  Acc@1: 81.2500 (82.4062)  Acc@5: 93.7500 (96.7285)  time: 0.3465  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [2420/3750]  eta: 0:07:42  Lr: 0.001875  Loss: -1.0961  Acc@1: 81.2500 (82.4298)  Acc@5: 100.0000 (96.7266)  time: 0.3486  data: 0.0013  max mem: 2500
Train: Epoch[3/5]  [2430/3750]  eta: 0:07:39  Lr: 0.001875  Loss: -0.8369  Acc@1: 81.2500 (82.4095)  Acc@5: 93.7500 (96.7195)  time: 0.3472  data: 0.0013  max mem: 2500
Train: Epoch[3/5]  [2440/3750]  eta: 0:07:35  Lr: 0.001875  Loss: -0.9296  Acc@1: 75.0000 (82.3817)  Acc@5: 93.7500 (96.7073)  time: 0.3472  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [2450/3750]  eta: 0:07:32  Lr: 0.001875  Loss: -1.0472  Acc@1: 81.2500 (82.3822)  Acc@5: 93.7500 (96.7054)  time: 0.3474  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [2460/3750]  eta: 0:07:28  Lr: 0.001875  Loss: -0.4209  Acc@1: 81.2500 (82.3928)  Acc@5: 93.7500 (96.6934)  time: 0.3465  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [2470/3750]  eta: 0:07:25  Lr: 0.001875  Loss: -0.8631  Acc@1: 81.2500 (82.3857)  Acc@5: 93.7500 (96.6891)  time: 0.3469  data: 0.0009  max mem: 2500
Train: Epoch[3/5]  [2480/3750]  eta: 0:07:21  Lr: 0.001875  Loss: -1.0173  Acc@1: 81.2500 (82.3861)  Acc@5: 93.7500 (96.6873)  time: 0.3468  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [2490/3750]  eta: 0:07:18  Lr: 0.001875  Loss: -1.0131  Acc@1: 81.2500 (82.3816)  Acc@5: 93.7500 (96.6805)  time: 0.3495  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [2500/3750]  eta: 0:07:14  Lr: 0.001875  Loss: -0.9187  Acc@1: 81.2500 (82.3795)  Acc@5: 93.7500 (96.6813)  time: 0.3483  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [2510/3750]  eta: 0:07:11  Lr: 0.001875  Loss: -1.2422  Acc@1: 87.5000 (82.4049)  Acc@5: 100.0000 (96.6821)  time: 0.3457  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [2520/3750]  eta: 0:07:07  Lr: 0.001875  Loss: -0.3754  Acc@1: 87.5000 (82.4177)  Acc@5: 100.0000 (96.6853)  time: 0.3467  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2530/3750]  eta: 0:07:04  Lr: 0.001875  Loss: -0.9112  Acc@1: 87.5000 (82.4279)  Acc@5: 100.0000 (96.6886)  time: 0.3471  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2540/3750]  eta: 0:07:00  Lr: 0.001875  Loss: -0.8522  Acc@1: 81.2500 (82.4159)  Acc@5: 93.7500 (96.6795)  time: 0.3471  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2550/3750]  eta: 0:06:57  Lr: 0.001875  Loss: -0.8268  Acc@1: 81.2500 (82.3966)  Acc@5: 100.0000 (96.6876)  time: 0.3468  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2560/3750]  eta: 0:06:53  Lr: 0.001875  Loss: -0.8576  Acc@1: 75.0000 (82.3921)  Acc@5: 100.0000 (96.6834)  time: 0.3464  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [2570/3750]  eta: 0:06:50  Lr: 0.001875  Loss: -0.8195  Acc@1: 81.2500 (82.3901)  Acc@5: 100.0000 (96.6890)  time: 0.3474  data: 0.0010  max mem: 2500
Train: Epoch[3/5]  [2580/3750]  eta: 0:06:46  Lr: 0.001875  Loss: -0.8141  Acc@1: 81.2500 (82.3881)  Acc@5: 100.0000 (96.6946)  time: 0.3490  data: 0.0021  max mem: 2500
Train: Epoch[3/5]  [2590/3750]  eta: 0:06:43  Lr: 0.001875  Loss: -0.7698  Acc@1: 81.2500 (82.3958)  Acc@5: 100.0000 (96.6953)  time: 0.3494  data: 0.0016  max mem: 2500
Train: Epoch[3/5]  [2600/3750]  eta: 0:06:39  Lr: 0.001875  Loss: -1.2316  Acc@1: 81.2500 (82.4034)  Acc@5: 100.0000 (96.6984)  time: 0.3478  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [2610/3750]  eta: 0:06:36  Lr: 0.001875  Loss: -1.1159  Acc@1: 81.2500 (82.4086)  Acc@5: 100.0000 (96.7015)  time: 0.3477  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [2620/3750]  eta: 0:06:32  Lr: 0.001875  Loss: -1.0272  Acc@1: 87.5000 (82.4232)  Acc@5: 100.0000 (96.7021)  time: 0.3479  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [2630/3750]  eta: 0:06:29  Lr: 0.001875  Loss: -1.1721  Acc@1: 81.2500 (82.4211)  Acc@5: 93.7500 (96.6980)  time: 0.3479  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [2640/3750]  eta: 0:06:26  Lr: 0.001875  Loss: -0.4889  Acc@1: 81.2500 (82.4214)  Acc@5: 93.7500 (96.6940)  time: 0.3477  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [2650/3750]  eta: 0:06:22  Lr: 0.001875  Loss: -0.9964  Acc@1: 87.5000 (82.4359)  Acc@5: 100.0000 (96.6994)  time: 0.3478  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [2660/3750]  eta: 0:06:19  Lr: 0.001875  Loss: -1.2117  Acc@1: 87.5000 (82.4408)  Acc@5: 100.0000 (96.7024)  time: 0.3494  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [2670/3750]  eta: 0:06:15  Lr: 0.001875  Loss: -0.9356  Acc@1: 81.2500 (82.4293)  Acc@5: 100.0000 (96.7030)  time: 0.3478  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [2680/3750]  eta: 0:06:12  Lr: 0.001875  Loss: -1.2956  Acc@1: 81.2500 (82.4389)  Acc@5: 100.0000 (96.7037)  time: 0.3484  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [2690/3750]  eta: 0:06:08  Lr: 0.001875  Loss: -0.7853  Acc@1: 87.5000 (82.4415)  Acc@5: 100.0000 (96.7066)  time: 0.3493  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [2700/3750]  eta: 0:06:05  Lr: 0.001875  Loss: -1.0543  Acc@1: 81.2500 (82.4417)  Acc@5: 100.0000 (96.7049)  time: 0.3469  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [2710/3750]  eta: 0:06:01  Lr: 0.001875  Loss: -0.4779  Acc@1: 81.2500 (82.4511)  Acc@5: 100.0000 (96.7079)  time: 0.3460  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [2720/3750]  eta: 0:05:58  Lr: 0.001875  Loss: -0.8738  Acc@1: 87.5000 (82.4582)  Acc@5: 100.0000 (96.7177)  time: 0.3470  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [2730/3750]  eta: 0:05:54  Lr: 0.001875  Loss: -1.0017  Acc@1: 87.5000 (82.4767)  Acc@5: 100.0000 (96.7205)  time: 0.3479  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [2740/3750]  eta: 0:05:51  Lr: 0.001875  Loss: -0.9830  Acc@1: 81.2500 (82.4767)  Acc@5: 100.0000 (96.7211)  time: 0.3475  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2750/3750]  eta: 0:05:47  Lr: 0.001875  Loss: -1.0330  Acc@1: 81.2500 (82.4836)  Acc@5: 93.7500 (96.7194)  time: 0.3475  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [2760/3750]  eta: 0:05:44  Lr: 0.001875  Loss: -0.6481  Acc@1: 87.5000 (82.4973)  Acc@5: 100.0000 (96.7222)  time: 0.3473  data: 0.0013  max mem: 2500
Train: Epoch[3/5]  [2770/3750]  eta: 0:05:40  Lr: 0.001875  Loss: -0.6087  Acc@1: 87.5000 (82.5063)  Acc@5: 100.0000 (96.7205)  time: 0.3477  data: 0.0013  max mem: 2500
Train: Epoch[3/5]  [2780/3750]  eta: 0:05:37  Lr: 0.001875  Loss: -0.8805  Acc@1: 87.5000 (82.5198)  Acc@5: 100.0000 (96.7300)  time: 0.3487  data: 0.0012  max mem: 2500
Train: Epoch[3/5]  [2790/3750]  eta: 0:05:33  Lr: 0.001875  Loss: -0.8690  Acc@1: 87.5000 (82.5197)  Acc@5: 100.0000 (96.7238)  time: 0.3498  data: 0.0016  max mem: 2500
Train: Epoch[3/5]  [2800/3750]  eta: 0:05:30  Lr: 0.001875  Loss: -1.0445  Acc@1: 81.2500 (82.5085)  Acc@5: 100.0000 (96.7177)  time: 0.3480  data: 0.0009  max mem: 2500
Train: Epoch[3/5]  [2810/3750]  eta: 0:05:26  Lr: 0.001875  Loss: -0.6112  Acc@1: 75.0000 (82.4862)  Acc@5: 100.0000 (96.7182)  time: 0.3470  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [2820/3750]  eta: 0:05:23  Lr: 0.001875  Loss: -1.1872  Acc@1: 81.2500 (82.4840)  Acc@5: 100.0000 (96.7232)  time: 0.3474  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [2830/3750]  eta: 0:05:19  Lr: 0.001875  Loss: -0.5663  Acc@1: 81.2500 (82.4775)  Acc@5: 100.0000 (96.7171)  time: 0.3468  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [2840/3750]  eta: 0:05:16  Lr: 0.001875  Loss: -0.7924  Acc@1: 81.2500 (82.4644)  Acc@5: 93.7500 (96.7045)  time: 0.3468  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [2850/3750]  eta: 0:05:12  Lr: 0.001875  Loss: -1.3159  Acc@1: 81.2500 (82.4820)  Acc@5: 100.0000 (96.7139)  time: 0.3474  data: 0.0014  max mem: 2500
Train: Epoch[3/5]  [2860/3750]  eta: 0:05:09  Lr: 0.001875  Loss: -0.8157  Acc@1: 81.2500 (82.4799)  Acc@5: 100.0000 (96.7123)  time: 0.3496  data: 0.0014  max mem: 2500
Train: Epoch[3/5]  [2870/3750]  eta: 0:05:06  Lr: 0.001875  Loss: -1.0363  Acc@1: 87.5000 (82.4952)  Acc@5: 100.0000 (96.7215)  time: 0.3543  data: 0.0010  max mem: 2500
Train: Epoch[3/5]  [2880/3750]  eta: 0:05:02  Lr: 0.001875  Loss: -0.7984  Acc@1: 87.5000 (82.4996)  Acc@5: 100.0000 (96.7221)  time: 0.3522  data: 0.0010  max mem: 2500
Train: Epoch[3/5]  [2890/3750]  eta: 0:04:59  Lr: 0.001875  Loss: -0.9793  Acc@1: 87.5000 (82.5169)  Acc@5: 100.0000 (96.7226)  time: 0.3473  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [2900/3750]  eta: 0:04:55  Lr: 0.001875  Loss: -0.7415  Acc@1: 81.2500 (82.5190)  Acc@5: 100.0000 (96.7274)  time: 0.3486  data: 0.0010  max mem: 2500
Train: Epoch[3/5]  [2910/3750]  eta: 0:04:52  Lr: 0.001875  Loss: -0.7517  Acc@1: 81.2500 (82.5167)  Acc@5: 100.0000 (96.7258)  time: 0.3480  data: 0.0009  max mem: 2500
Train: Epoch[3/5]  [2920/3750]  eta: 0:04:48  Lr: 0.001875  Loss: -0.9946  Acc@1: 87.5000 (82.5167)  Acc@5: 93.7500 (96.7156)  time: 0.3467  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [2930/3750]  eta: 0:04:45  Lr: 0.001875  Loss: -0.5706  Acc@1: 81.2500 (82.5166)  Acc@5: 100.0000 (96.7204)  time: 0.3484  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [2940/3750]  eta: 0:04:41  Lr: 0.001875  Loss: -0.5049  Acc@1: 87.5000 (82.5272)  Acc@5: 100.0000 (96.7188)  time: 0.3484  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [2950/3750]  eta: 0:04:38  Lr: 0.001875  Loss: -0.8702  Acc@1: 81.2500 (82.5313)  Acc@5: 100.0000 (96.7236)  time: 0.3469  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [2960/3750]  eta: 0:04:34  Lr: 0.001875  Loss: -0.8734  Acc@1: 81.2500 (82.5249)  Acc@5: 100.0000 (96.7241)  time: 0.3483  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [2970/3750]  eta: 0:04:31  Lr: 0.001875  Loss: -0.7478  Acc@1: 81.2500 (82.5143)  Acc@5: 93.7500 (96.7204)  time: 0.3498  data: 0.0013  max mem: 2500
Train: Epoch[3/5]  [2980/3750]  eta: 0:04:27  Lr: 0.001875  Loss: -0.9550  Acc@1: 81.2500 (82.5059)  Acc@5: 100.0000 (96.7251)  time: 0.3485  data: 0.0013  max mem: 2500
Train: Epoch[3/5]  [2990/3750]  eta: 0:04:24  Lr: 0.001875  Loss: -1.1661  Acc@1: 81.2500 (82.4975)  Acc@5: 100.0000 (96.7193)  time: 0.3469  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [3000/3750]  eta: 0:04:20  Lr: 0.001875  Loss: -1.1738  Acc@1: 81.2500 (82.5037)  Acc@5: 100.0000 (96.7261)  time: 0.3468  data: 0.0013  max mem: 2500
Train: Epoch[3/5]  [3010/3750]  eta: 0:04:17  Lr: 0.001875  Loss: -0.9968  Acc@1: 87.5000 (82.5100)  Acc@5: 100.0000 (96.7287)  time: 0.3474  data: 0.0012  max mem: 2500
Train: Epoch[3/5]  [3020/3750]  eta: 0:04:13  Lr: 0.001875  Loss: -0.8056  Acc@1: 81.2500 (82.5037)  Acc@5: 100.0000 (96.7250)  time: 0.3493  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3030/3750]  eta: 0:04:10  Lr: 0.001875  Loss: -0.9245  Acc@1: 81.2500 (82.4975)  Acc@5: 93.7500 (96.7234)  time: 0.3489  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [3040/3750]  eta: 0:04:06  Lr: 0.001875  Loss: -1.1353  Acc@1: 81.2500 (82.4914)  Acc@5: 100.0000 (96.7260)  time: 0.3476  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [3050/3750]  eta: 0:04:03  Lr: 0.001875  Loss: -0.7047  Acc@1: 81.2500 (82.4873)  Acc@5: 100.0000 (96.7183)  time: 0.3470  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [3060/3750]  eta: 0:03:59  Lr: 0.001875  Loss: -0.7260  Acc@1: 81.2500 (82.4935)  Acc@5: 100.0000 (96.7208)  time: 0.3470  data: 0.0013  max mem: 2500
Train: Epoch[3/5]  [3070/3750]  eta: 0:03:56  Lr: 0.001875  Loss: -1.0360  Acc@1: 87.5000 (82.4996)  Acc@5: 100.0000 (96.7254)  time: 0.3481  data: 0.0014  max mem: 2500
Train: Epoch[3/5]  [3080/3750]  eta: 0:03:53  Lr: 0.001875  Loss: -0.5777  Acc@1: 81.2500 (82.4935)  Acc@5: 100.0000 (96.7300)  time: 0.3473  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [3090/3750]  eta: 0:03:49  Lr: 0.001875  Loss: -1.1360  Acc@1: 81.2500 (82.4976)  Acc@5: 100.0000 (96.7264)  time: 0.3462  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3100/3750]  eta: 0:03:46  Lr: 0.001875  Loss: -1.1132  Acc@1: 87.5000 (82.5056)  Acc@5: 100.0000 (96.7309)  time: 0.3471  data: 0.0011  max mem: 2500
Train: Epoch[3/5]  [3110/3750]  eta: 0:03:42  Lr: 0.001875  Loss: -0.7741  Acc@1: 81.2500 (82.4976)  Acc@5: 100.0000 (96.7273)  time: 0.3474  data: 0.0012  max mem: 2500
Train: Epoch[3/5]  [3120/3750]  eta: 0:03:39  Lr: 0.001875  Loss: -0.5600  Acc@1: 75.0000 (82.4836)  Acc@5: 93.7500 (96.7278)  time: 0.3460  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [3130/3750]  eta: 0:03:35  Lr: 0.001875  Loss: -0.7734  Acc@1: 75.0000 (82.4796)  Acc@5: 100.0000 (96.7283)  time: 0.3465  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [3140/3750]  eta: 0:03:32  Lr: 0.001875  Loss: -1.1628  Acc@1: 81.2500 (82.4777)  Acc@5: 100.0000 (96.7208)  time: 0.3475  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [3150/3750]  eta: 0:03:28  Lr: 0.001875  Loss: -0.5003  Acc@1: 81.2500 (82.4738)  Acc@5: 100.0000 (96.7272)  time: 0.3464  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [3160/3750]  eta: 0:03:25  Lr: 0.001875  Loss: -1.0655  Acc@1: 81.2500 (82.4660)  Acc@5: 100.0000 (96.7317)  time: 0.3479  data: 0.0010  max mem: 2500
Train: Epoch[3/5]  [3170/3750]  eta: 0:03:21  Lr: 0.001875  Loss: -1.2534  Acc@1: 81.2500 (82.4740)  Acc@5: 100.0000 (96.7380)  time: 0.3498  data: 0.0011  max mem: 2500
Train: Epoch[3/5]  [3180/3750]  eta: 0:03:18  Lr: 0.001875  Loss: -1.3955  Acc@1: 87.5000 (82.4682)  Acc@5: 100.0000 (96.7404)  time: 0.3477  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [3190/3750]  eta: 0:03:14  Lr: 0.001875  Loss: -0.3374  Acc@1: 81.2500 (82.4683)  Acc@5: 100.0000 (96.7389)  time: 0.3472  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [3200/3750]  eta: 0:03:11  Lr: 0.001875  Loss: -0.9604  Acc@1: 81.2500 (82.4645)  Acc@5: 93.7500 (96.7334)  time: 0.3490  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [3210/3750]  eta: 0:03:07  Lr: 0.001875  Loss: -0.8273  Acc@1: 81.2500 (82.4626)  Acc@5: 93.7500 (96.7358)  time: 0.3493  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [3220/3750]  eta: 0:03:04  Lr: 0.001875  Loss: -0.8200  Acc@1: 81.2500 (82.4511)  Acc@5: 93.7500 (96.7324)  time: 0.3477  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [3230/3750]  eta: 0:03:00  Lr: 0.001875  Loss: -0.9086  Acc@1: 75.0000 (82.4513)  Acc@5: 100.0000 (96.7348)  time: 0.3463  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [3240/3750]  eta: 0:02:57  Lr: 0.001875  Loss: -0.8344  Acc@1: 81.2500 (82.4475)  Acc@5: 100.0000 (96.7390)  time: 0.3468  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [3250/3750]  eta: 0:02:53  Lr: 0.001875  Loss: -0.9594  Acc@1: 81.2500 (82.4516)  Acc@5: 100.0000 (96.7433)  time: 0.3477  data: 0.0011  max mem: 2500
Train: Epoch[3/5]  [3260/3750]  eta: 0:02:50  Lr: 0.001875  Loss: -0.7427  Acc@1: 81.2500 (82.4421)  Acc@5: 100.0000 (96.7380)  time: 0.3471  data: 0.0015  max mem: 2500
Train: Epoch[3/5]  [3270/3750]  eta: 0:02:46  Lr: 0.001875  Loss: -1.0028  Acc@1: 81.2500 (82.4404)  Acc@5: 100.0000 (96.7403)  time: 0.3498  data: 0.0035  max mem: 2500
Train: Epoch[3/5]  [3280/3750]  eta: 0:02:43  Lr: 0.001875  Loss: -0.7930  Acc@1: 81.2500 (82.4272)  Acc@5: 93.7500 (96.7312)  time: 0.3499  data: 0.0030  max mem: 2500
Train: Epoch[3/5]  [3290/3750]  eta: 0:02:39  Lr: 0.001875  Loss: -0.7715  Acc@1: 81.2500 (82.4123)  Acc@5: 93.7500 (96.7297)  time: 0.3475  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [3300/3750]  eta: 0:02:36  Lr: 0.001875  Loss: -0.9798  Acc@1: 81.2500 (82.4220)  Acc@5: 100.0000 (96.7377)  time: 0.3474  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [3310/3750]  eta: 0:02:33  Lr: 0.001875  Loss: -0.9607  Acc@1: 87.5000 (82.4260)  Acc@5: 100.0000 (96.7325)  time: 0.3467  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [3320/3750]  eta: 0:02:29  Lr: 0.001875  Loss: -0.9829  Acc@1: 87.5000 (82.4243)  Acc@5: 93.7500 (96.7329)  time: 0.3471  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [3330/3750]  eta: 0:02:26  Lr: 0.001875  Loss: -0.9506  Acc@1: 81.2500 (82.4133)  Acc@5: 100.0000 (96.7371)  time: 0.3471  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [3340/3750]  eta: 0:02:22  Lr: 0.001875  Loss: -1.0179  Acc@1: 81.2500 (82.4192)  Acc@5: 100.0000 (96.7356)  time: 0.3479  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [3350/3750]  eta: 0:02:19  Lr: 0.001875  Loss: -0.7690  Acc@1: 81.2500 (82.4008)  Acc@5: 93.7500 (96.7305)  time: 0.3498  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [3360/3750]  eta: 0:02:15  Lr: 0.001875  Loss: -0.8102  Acc@1: 81.2500 (82.4066)  Acc@5: 100.0000 (96.7346)  time: 0.3509  data: 0.0009  max mem: 2500
Train: Epoch[3/5]  [3370/3750]  eta: 0:02:12  Lr: 0.001875  Loss: -1.0210  Acc@1: 81.2500 (82.3995)  Acc@5: 93.7500 (96.7202)  time: 0.3496  data: 0.0020  max mem: 2500
Train: Epoch[3/5]  [3380/3750]  eta: 0:02:08  Lr: 0.001875  Loss: -1.0506  Acc@1: 81.2500 (82.4017)  Acc@5: 100.0000 (96.7262)  time: 0.3480  data: 0.0016  max mem: 2500
Train: Epoch[3/5]  [3390/3750]  eta: 0:02:05  Lr: 0.001875  Loss: -1.2351  Acc@1: 81.2500 (82.4019)  Acc@5: 100.0000 (96.7303)  time: 0.3469  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [3400/3750]  eta: 0:02:01  Lr: 0.001875  Loss: -0.9850  Acc@1: 81.2500 (82.3949)  Acc@5: 100.0000 (96.7326)  time: 0.3464  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [3410/3750]  eta: 0:01:58  Lr: 0.001875  Loss: -0.8445  Acc@1: 81.2500 (82.3860)  Acc@5: 100.0000 (96.7293)  time: 0.3473  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3420/3750]  eta: 0:01:54  Lr: 0.001875  Loss: -0.2557  Acc@1: 81.2500 (82.3754)  Acc@5: 100.0000 (96.7334)  time: 0.3470  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [3430/3750]  eta: 0:01:51  Lr: 0.001875  Loss: -0.3594  Acc@1: 87.5000 (82.3794)  Acc@5: 100.0000 (96.7302)  time: 0.3459  data: 0.0012  max mem: 2500
Train: Epoch[3/5]  [3440/3750]  eta: 0:01:47  Lr: 0.001875  Loss: -1.0690  Acc@1: 87.5000 (82.3761)  Acc@5: 100.0000 (96.7324)  time: 0.3476  data: 0.0011  max mem: 2500
Train: Epoch[3/5]  [3450/3750]  eta: 0:01:44  Lr: 0.001875  Loss: -1.0827  Acc@1: 81.2500 (82.3529)  Acc@5: 100.0000 (96.7328)  time: 0.3482  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [3460/3750]  eta: 0:01:40  Lr: 0.001875  Loss: -0.8405  Acc@1: 81.2500 (82.3534)  Acc@5: 100.0000 (96.7369)  time: 0.3502  data: 0.0017  max mem: 2500
Train: Epoch[3/5]  [3470/3750]  eta: 0:01:37  Lr: 0.001875  Loss: -0.9538  Acc@1: 81.2500 (82.3592)  Acc@5: 100.0000 (96.7373)  time: 0.3498  data: 0.0017  max mem: 2500
Train: Epoch[3/5]  [3480/3750]  eta: 0:01:33  Lr: 0.001875  Loss: -0.9152  Acc@1: 81.2500 (82.3614)  Acc@5: 100.0000 (96.7341)  time: 0.3464  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [3490/3750]  eta: 0:01:30  Lr: 0.001875  Loss: -0.9980  Acc@1: 87.5000 (82.3600)  Acc@5: 100.0000 (96.7380)  time: 0.3472  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [3500/3750]  eta: 0:01:26  Lr: 0.001875  Loss: -0.8483  Acc@1: 81.2500 (82.3497)  Acc@5: 100.0000 (96.7402)  time: 0.3466  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3510/3750]  eta: 0:01:23  Lr: 0.001875  Loss: -0.9338  Acc@1: 81.2500 (82.3537)  Acc@5: 100.0000 (96.7424)  time: 0.3469  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3520/3750]  eta: 0:01:19  Lr: 0.001875  Loss: -0.7693  Acc@1: 81.2500 (82.3594)  Acc@5: 100.0000 (96.7445)  time: 0.3472  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3530/3750]  eta: 0:01:16  Lr: 0.001875  Loss: -0.1228  Acc@1: 81.2500 (82.3474)  Acc@5: 100.0000 (96.7378)  time: 0.3465  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3540/3750]  eta: 0:01:13  Lr: 0.001875  Loss: -1.1717  Acc@1: 81.2500 (82.3496)  Acc@5: 100.0000 (96.7364)  time: 0.3473  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [3550/3750]  eta: 0:01:09  Lr: 0.001875  Loss: -0.6962  Acc@1: 81.2500 (82.3624)  Acc@5: 100.0000 (96.7333)  time: 0.3475  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [3560/3750]  eta: 0:01:06  Lr: 0.001875  Loss: -1.0486  Acc@1: 81.2500 (82.3540)  Acc@5: 93.7500 (96.7320)  time: 0.3476  data: 0.0009  max mem: 2500
Train: Epoch[3/5]  [3570/3750]  eta: 0:01:02  Lr: 0.001875  Loss: -1.1324  Acc@1: 81.2500 (82.3614)  Acc@5: 100.0000 (96.7376)  time: 0.3477  data: 0.0009  max mem: 2500
Train: Epoch[3/5]  [3580/3750]  eta: 0:00:59  Lr: 0.001875  Loss: -0.9032  Acc@1: 81.2500 (82.3583)  Acc@5: 100.0000 (96.7328)  time: 0.3476  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3590/3750]  eta: 0:00:55  Lr: 0.001875  Loss: -0.1976  Acc@1: 81.2500 (82.3482)  Acc@5: 93.7500 (96.7314)  time: 0.3475  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3600/3750]  eta: 0:00:52  Lr: 0.001875  Loss: -0.9392  Acc@1: 87.5000 (82.3573)  Acc@5: 100.0000 (96.7335)  time: 0.3470  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [3610/3750]  eta: 0:00:48  Lr: 0.001875  Loss: -0.6751  Acc@1: 87.5000 (82.3629)  Acc@5: 100.0000 (96.7339)  time: 0.3467  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3620/3750]  eta: 0:00:45  Lr: 0.001875  Loss: -1.0020  Acc@1: 81.2500 (82.3650)  Acc@5: 100.0000 (96.7361)  time: 0.3481  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [3630/3750]  eta: 0:00:41  Lr: 0.001875  Loss: -0.9582  Acc@1: 81.2500 (82.3637)  Acc@5: 100.0000 (96.7347)  time: 0.3498  data: 0.0011  max mem: 2500
Train: Epoch[3/5]  [3640/3750]  eta: 0:00:38  Lr: 0.001875  Loss: -1.0807  Acc@1: 87.5000 (82.3881)  Acc@5: 100.0000 (96.7420)  time: 0.3479  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [3650/3750]  eta: 0:00:34  Lr: 0.001875  Loss: -0.6306  Acc@1: 87.5000 (82.3952)  Acc@5: 100.0000 (96.7389)  time: 0.3472  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [3660/3750]  eta: 0:00:31  Lr: 0.001875  Loss: -1.1255  Acc@1: 81.2500 (82.3853)  Acc@5: 100.0000 (96.7359)  time: 0.3487  data: 0.0011  max mem: 2500
Train: Epoch[3/5]  [3670/3750]  eta: 0:00:27  Lr: 0.001875  Loss: -0.7652  Acc@1: 81.2500 (82.3890)  Acc@5: 100.0000 (96.7379)  time: 0.3488  data: 0.0012  max mem: 2500
Train: Epoch[3/5]  [3680/3750]  eta: 0:00:24  Lr: 0.001875  Loss: -1.1222  Acc@1: 87.5000 (82.3995)  Acc@5: 100.0000 (96.7417)  time: 0.3476  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [3690/3750]  eta: 0:00:20  Lr: 0.001875  Loss: -1.0248  Acc@1: 81.2500 (82.3981)  Acc@5: 100.0000 (96.7353)  time: 0.3475  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [3700/3750]  eta: 0:00:17  Lr: 0.001875  Loss: -1.1952  Acc@1: 81.2500 (82.4017)  Acc@5: 100.0000 (96.7391)  time: 0.3487  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [3710/3750]  eta: 0:00:13  Lr: 0.001875  Loss: -0.9478  Acc@1: 87.5000 (82.4121)  Acc@5: 100.0000 (96.7394)  time: 0.3477  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [3720/3750]  eta: 0:00:10  Lr: 0.001875  Loss: -1.0922  Acc@1: 87.5000 (82.4123)  Acc@5: 100.0000 (96.7465)  time: 0.3472  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [3730/3750]  eta: 0:00:06  Lr: 0.001875  Loss: -1.0546  Acc@1: 87.5000 (82.4243)  Acc@5: 100.0000 (96.7485)  time: 0.3484  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [3740/3750]  eta: 0:00:03  Lr: 0.001875  Loss: -0.6138  Acc@1: 87.5000 (82.4278)  Acc@5: 100.0000 (96.7522)  time: 0.3468  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [3749/3750]  eta: 0:00:00  Lr: 0.001875  Loss: -0.5580  Acc@1: 81.2500 (82.4283)  Acc@5: 100.0000 (96.7550)  time: 0.3470  data: 0.0011  max mem: 2500
Train: Epoch[3/5] Total time: 0:21:45 (0.3480 s / it)
{0: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 1: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 2: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 3: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 4: {0: 0, 1: 180000, 2: 0, 3: 0, 4: 0}, 5: {0: 0, 1: 180000, 2: 0, 3: 0, 4: 0}, 6: {0: 0, 1: 180000, 2: 0, 3: 0, 4: 0}, 7: {0: 0, 1: 180000, 2: 0, 3: 0, 4: 0}, 8: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 9: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 10: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 11: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 12: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 13: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 14: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 15: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 16: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 17: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 18: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 19: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}}
Averaged stats: Lr: 0.001875  Loss: -0.5580  Acc@1: 81.2500 (82.4283)  Acc@5: 100.0000 (96.7550)
Train: Epoch[4/5]  [   0/3750]  eta: 1:07:22  Lr: 0.001875  Loss: -0.5673  Acc@1: 75.0000 (75.0000)  Acc@5: 93.7500 (93.7500)  time: 1.0781  data: 0.7018  max mem: 2500
Train: Epoch[4/5]  [  10/3750]  eta: 0:26:05  Lr: 0.001875  Loss: -1.0951  Acc@1: 75.0000 (77.2727)  Acc@5: 100.0000 (96.0227)  time: 0.4186  data: 0.0664  max mem: 2500
Train: Epoch[4/5]  [  20/3750]  eta: 0:23:53  Lr: 0.001875  Loss: -0.6465  Acc@1: 75.0000 (78.8690)  Acc@5: 100.0000 (95.8333)  time: 0.3496  data: 0.0017  max mem: 2500
Train: Epoch[4/5]  [  30/3750]  eta: 0:23:04  Lr: 0.001875  Loss: -0.6642  Acc@1: 81.2500 (79.8387)  Acc@5: 100.0000 (96.5726)  time: 0.3465  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [  40/3750]  eta: 0:22:38  Lr: 0.001875  Loss: -0.6765  Acc@1: 81.2500 (79.8780)  Acc@5: 100.0000 (96.9512)  time: 0.3473  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [  50/3750]  eta: 0:22:24  Lr: 0.001875  Loss: -1.1629  Acc@1: 81.2500 (79.1667)  Acc@5: 100.0000 (96.9363)  time: 0.3500  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [  60/3750]  eta: 0:22:11  Lr: 0.001875  Loss: -0.8461  Acc@1: 75.0000 (79.3033)  Acc@5: 100.0000 (97.0287)  time: 0.3501  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [  70/3750]  eta: 0:22:00  Lr: 0.001875  Loss: -1.2046  Acc@1: 81.2500 (79.9296)  Acc@5: 100.0000 (97.0070)  time: 0.3472  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [  80/3750]  eta: 0:21:52  Lr: 0.001875  Loss: -1.0976  Acc@1: 87.5000 (80.3241)  Acc@5: 100.0000 (97.2222)  time: 0.3473  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [  90/3750]  eta: 0:21:44  Lr: 0.001875  Loss: -1.2484  Acc@1: 81.2500 (80.3571)  Acc@5: 100.0000 (97.1841)  time: 0.3481  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [ 100/3750]  eta: 0:21:38  Lr: 0.001875  Loss: -1.3073  Acc@1: 81.2500 (80.8787)  Acc@5: 100.0000 (97.2153)  time: 0.3478  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [ 110/3750]  eta: 0:21:31  Lr: 0.001875  Loss: -1.2356  Acc@1: 81.2500 (81.1374)  Acc@5: 100.0000 (97.2973)  time: 0.3478  data: 0.0012  max mem: 2500
Train: Epoch[4/5]  [ 120/3750]  eta: 0:21:27  Lr: 0.001875  Loss: -0.1163  Acc@1: 81.2500 (81.2500)  Acc@5: 100.0000 (97.2624)  time: 0.3489  data: 0.0012  max mem: 2500
Train: Epoch[4/5]  [ 130/3750]  eta: 0:21:21  Lr: 0.001875  Loss: -1.1413  Acc@1: 81.2500 (81.3454)  Acc@5: 100.0000 (97.3282)  time: 0.3490  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [ 140/3750]  eta: 0:21:16  Lr: 0.001875  Loss: -1.3740  Acc@1: 87.5000 (81.7819)  Acc@5: 100.0000 (97.3848)  time: 0.3480  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [ 150/3750]  eta: 0:21:11  Lr: 0.001875  Loss: -1.0541  Acc@1: 87.5000 (81.7881)  Acc@5: 100.0000 (97.3924)  time: 0.3485  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [ 160/3750]  eta: 0:21:07  Lr: 0.001875  Loss: -1.0702  Acc@1: 81.2500 (81.8711)  Acc@5: 100.0000 (97.3991)  time: 0.3489  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [ 170/3750]  eta: 0:21:03  Lr: 0.001875  Loss: -0.9117  Acc@1: 81.2500 (81.7617)  Acc@5: 100.0000 (97.3319)  time: 0.3495  data: 0.0009  max mem: 2500
Train: Epoch[4/5]  [ 180/3750]  eta: 0:20:58  Lr: 0.001875  Loss: -1.1277  Acc@1: 81.2500 (81.7334)  Acc@5: 100.0000 (97.3066)  time: 0.3476  data: 0.0009  max mem: 2500
Train: Epoch[4/5]  [ 190/3750]  eta: 0:20:54  Lr: 0.001875  Loss: -0.8359  Acc@1: 87.5000 (81.8717)  Acc@5: 100.0000 (97.2840)  time: 0.3474  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [ 200/3750]  eta: 0:20:49  Lr: 0.001875  Loss: -1.0746  Acc@1: 87.5000 (82.2450)  Acc@5: 100.0000 (97.2948)  time: 0.3475  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [ 210/3750]  eta: 0:20:45  Lr: 0.001875  Loss: -0.5944  Acc@1: 87.5000 (82.4052)  Acc@5: 100.0000 (97.3341)  time: 0.3471  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [ 220/3750]  eta: 0:20:41  Lr: 0.001875  Loss: -0.6834  Acc@1: 87.5000 (82.5792)  Acc@5: 100.0000 (97.3416)  time: 0.3480  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [ 230/3750]  eta: 0:20:36  Lr: 0.001875  Loss: -1.1309  Acc@1: 87.5000 (82.4675)  Acc@5: 100.0000 (97.3214)  time: 0.3468  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [ 240/3750]  eta: 0:20:32  Lr: 0.001875  Loss: -1.0585  Acc@1: 81.2500 (82.4429)  Acc@5: 100.0000 (97.3548)  time: 0.3471  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [ 250/3750]  eta: 0:20:28  Lr: 0.001875  Loss: -0.9341  Acc@1: 87.5000 (82.5946)  Acc@5: 100.0000 (97.3855)  time: 0.3481  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [ 260/3750]  eta: 0:20:24  Lr: 0.001875  Loss: -0.7972  Acc@1: 87.5000 (82.5192)  Acc@5: 100.0000 (97.3180)  time: 0.3483  data: 0.0010  max mem: 2500
Train: Epoch[4/5]  [ 270/3750]  eta: 0:20:20  Lr: 0.001875  Loss: -0.4218  Acc@1: 81.2500 (82.4031)  Acc@5: 93.7500 (97.2786)  time: 0.3478  data: 0.0010  max mem: 2500
Train: Epoch[4/5]  [ 280/3750]  eta: 0:20:16  Lr: 0.001875  Loss: -0.9488  Acc@1: 81.2500 (82.5178)  Acc@5: 100.0000 (97.2865)  time: 0.3464  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [ 290/3750]  eta: 0:20:12  Lr: 0.001875  Loss: -1.2064  Acc@1: 81.2500 (82.3883)  Acc@5: 100.0000 (97.2509)  time: 0.3455  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [ 300/3750]  eta: 0:20:09  Lr: 0.001875  Loss: -0.9445  Acc@1: 81.2500 (82.5789)  Acc@5: 93.7500 (97.2176)  time: 0.3473  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [ 310/3750]  eta: 0:20:05  Lr: 0.001875  Loss: -0.6821  Acc@1: 87.5000 (82.5764)  Acc@5: 100.0000 (97.2669)  time: 0.3497  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [ 320/3750]  eta: 0:20:01  Lr: 0.001875  Loss: -1.1827  Acc@1: 81.2500 (82.5156)  Acc@5: 100.0000 (97.2936)  time: 0.3492  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [ 330/3750]  eta: 0:19:57  Lr: 0.001875  Loss: -1.0384  Acc@1: 87.5000 (82.6662)  Acc@5: 100.0000 (97.3565)  time: 0.3474  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [ 340/3750]  eta: 0:19:54  Lr: 0.001875  Loss: -0.9130  Acc@1: 87.5000 (82.6613)  Acc@5: 100.0000 (97.3240)  time: 0.3473  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [ 350/3750]  eta: 0:19:50  Lr: 0.001875  Loss: -0.6461  Acc@1: 81.2500 (82.6033)  Acc@5: 93.7500 (97.2934)  time: 0.3483  data: 0.0013  max mem: 2500
Train: Epoch[4/5]  [ 360/3750]  eta: 0:19:46  Lr: 0.001875  Loss: -1.2948  Acc@1: 81.2500 (82.6177)  Acc@5: 100.0000 (97.3338)  time: 0.3483  data: 0.0012  max mem: 2500
Train: Epoch[4/5]  [ 370/3750]  eta: 0:19:42  Lr: 0.001875  Loss: -0.8778  Acc@1: 81.2500 (82.6988)  Acc@5: 100.0000 (97.2877)  time: 0.3468  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 380/3750]  eta: 0:19:39  Lr: 0.001875  Loss: -1.0437  Acc@1: 87.5000 (82.8248)  Acc@5: 100.0000 (97.3261)  time: 0.3463  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [ 390/3750]  eta: 0:19:35  Lr: 0.001875  Loss: -0.8251  Acc@1: 87.5000 (82.6886)  Acc@5: 100.0000 (97.2986)  time: 0.3483  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [ 400/3750]  eta: 0:19:31  Lr: 0.001875  Loss: -0.9730  Acc@1: 81.2500 (82.7774)  Acc@5: 93.7500 (97.2569)  time: 0.3480  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [ 410/3750]  eta: 0:19:28  Lr: 0.001875  Loss: -0.6816  Acc@1: 81.2500 (82.7707)  Acc@5: 100.0000 (97.3084)  time: 0.3466  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [ 420/3750]  eta: 0:19:24  Lr: 0.001875  Loss: -0.8764  Acc@1: 81.2500 (82.7643)  Acc@5: 100.0000 (97.3278)  time: 0.3475  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [ 430/3750]  eta: 0:19:20  Lr: 0.001875  Loss: -0.7696  Acc@1: 81.2500 (82.8306)  Acc@5: 100.0000 (97.2883)  time: 0.3486  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [ 440/3750]  eta: 0:19:17  Lr: 0.001875  Loss: -1.2248  Acc@1: 87.5000 (82.9223)  Acc@5: 100.0000 (97.3214)  time: 0.3475  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [ 450/3750]  eta: 0:19:13  Lr: 0.001875  Loss: -1.0602  Acc@1: 87.5000 (82.8298)  Acc@5: 100.0000 (97.3115)  time: 0.3482  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [ 460/3750]  eta: 0:19:10  Lr: 0.001875  Loss: -0.7410  Acc@1: 75.0000 (82.7142)  Acc@5: 100.0000 (97.3427)  time: 0.3501  data: 0.0016  max mem: 2500
Train: Epoch[4/5]  [ 470/3750]  eta: 0:19:06  Lr: 0.001875  Loss: -1.0279  Acc@1: 81.2500 (82.7097)  Acc@5: 100.0000 (97.3461)  time: 0.3477  data: 0.0013  max mem: 2500
Train: Epoch[4/5]  [ 480/3750]  eta: 0:19:02  Lr: 0.001875  Loss: -1.1624  Acc@1: 81.2500 (82.6663)  Acc@5: 100.0000 (97.3233)  time: 0.3469  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [ 490/3750]  eta: 0:18:59  Lr: 0.001875  Loss: -1.0895  Acc@1: 87.5000 (82.7520)  Acc@5: 93.7500 (97.2887)  time: 0.3493  data: 0.0012  max mem: 2500
Train: Epoch[4/5]  [ 500/3750]  eta: 0:18:55  Lr: 0.001875  Loss: -0.8401  Acc@1: 87.5000 (82.6971)  Acc@5: 93.7500 (97.2181)  time: 0.3483  data: 0.0012  max mem: 2500
Train: Epoch[4/5]  [ 510/3750]  eta: 0:18:52  Lr: 0.001875  Loss: -0.6372  Acc@1: 87.5000 (82.8400)  Acc@5: 93.7500 (97.2358)  time: 0.3489  data: 0.0009  max mem: 2500
Train: Epoch[4/5]  [ 520/3750]  eta: 0:18:48  Lr: 0.001875  Loss: -1.0819  Acc@1: 87.5000 (82.7015)  Acc@5: 100.0000 (97.1809)  time: 0.3484  data: 0.0012  max mem: 2500
Train: Epoch[4/5]  [ 530/3750]  eta: 0:18:44  Lr: 0.001875  Loss: -1.1341  Acc@1: 81.2500 (82.6742)  Acc@5: 100.0000 (97.2105)  time: 0.3458  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [ 540/3750]  eta: 0:18:41  Lr: 0.001875  Loss: -1.0010  Acc@1: 81.2500 (82.6363)  Acc@5: 100.0000 (97.2043)  time: 0.3471  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [ 550/3750]  eta: 0:18:37  Lr: 0.001875  Loss: -0.8952  Acc@1: 81.2500 (82.7019)  Acc@5: 100.0000 (97.2096)  time: 0.3483  data: 0.0012  max mem: 2500
Train: Epoch[4/5]  [ 560/3750]  eta: 0:18:34  Lr: 0.001875  Loss: -0.4626  Acc@1: 87.5000 (82.7206)  Acc@5: 100.0000 (97.1925)  time: 0.3490  data: 0.0013  max mem: 2500
Train: Epoch[4/5]  [ 570/3750]  eta: 0:18:30  Lr: 0.001875  Loss: -0.3954  Acc@1: 87.5000 (82.6620)  Acc@5: 100.0000 (97.2088)  time: 0.3475  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [ 580/3750]  eta: 0:18:26  Lr: 0.001875  Loss: -1.2203  Acc@1: 87.5000 (82.7238)  Acc@5: 100.0000 (97.2139)  time: 0.3454  data: 0.0009  max mem: 2500
Train: Epoch[4/5]  [ 590/3750]  eta: 0:18:23  Lr: 0.001875  Loss: -0.9689  Acc@1: 87.5000 (82.7728)  Acc@5: 100.0000 (97.2504)  time: 0.3465  data: 0.0009  max mem: 2500
Train: Epoch[4/5]  [ 600/3750]  eta: 0:18:19  Lr: 0.001875  Loss: -1.0842  Acc@1: 87.5000 (82.8723)  Acc@5: 100.0000 (97.2754)  time: 0.3483  data: 0.0009  max mem: 2500
Train: Epoch[4/5]  [ 610/3750]  eta: 0:18:16  Lr: 0.001875  Loss: -1.0065  Acc@1: 81.2500 (82.8151)  Acc@5: 100.0000 (97.2995)  time: 0.3481  data: 0.0010  max mem: 2500
Train: Epoch[4/5]  [ 620/3750]  eta: 0:18:12  Lr: 0.001875  Loss: -0.8580  Acc@1: 81.2500 (82.7597)  Acc@5: 100.0000 (97.2927)  time: 0.3475  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [ 630/3750]  eta: 0:18:09  Lr: 0.001875  Loss: -1.0524  Acc@1: 81.2500 (82.8249)  Acc@5: 100.0000 (97.3059)  time: 0.3467  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [ 640/3750]  eta: 0:18:05  Lr: 0.001875  Loss: -1.1589  Acc@1: 87.5000 (82.8686)  Acc@5: 100.0000 (97.3381)  time: 0.3461  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [ 650/3750]  eta: 0:18:01  Lr: 0.001875  Loss: -0.4473  Acc@1: 87.5000 (82.8725)  Acc@5: 100.0000 (97.3502)  time: 0.3474  data: 0.0014  max mem: 2500
Train: Epoch[4/5]  [ 660/3750]  eta: 0:17:58  Lr: 0.001875  Loss: -1.4036  Acc@1: 81.2500 (82.9047)  Acc@5: 100.0000 (97.3525)  time: 0.3479  data: 0.0013  max mem: 2500
Train: Epoch[4/5]  [ 670/3750]  eta: 0:17:54  Lr: 0.001875  Loss: -0.7490  Acc@1: 81.2500 (82.8893)  Acc@5: 100.0000 (97.3361)  time: 0.3487  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 680/3750]  eta: 0:17:51  Lr: 0.001875  Loss: -0.9535  Acc@1: 81.2500 (82.8010)  Acc@5: 93.7500 (97.2926)  time: 0.3479  data: 0.0011  max mem: 2500
Train: Epoch[4/5]  [ 690/3750]  eta: 0:17:47  Lr: 0.001875  Loss: -0.6411  Acc@1: 81.2500 (82.7876)  Acc@5: 93.7500 (97.2865)  time: 0.3467  data: 0.0012  max mem: 2500
Train: Epoch[4/5]  [ 700/3750]  eta: 0:17:44  Lr: 0.001875  Loss: -0.8956  Acc@1: 81.2500 (82.7657)  Acc@5: 93.7500 (97.2361)  time: 0.3482  data: 0.0012  max mem: 2500
Train: Epoch[4/5]  [ 710/3750]  eta: 0:17:40  Lr: 0.001875  Loss: -1.0662  Acc@1: 81.2500 (82.7532)  Acc@5: 93.7500 (97.2486)  time: 0.3481  data: 0.0013  max mem: 2500
Train: Epoch[4/5]  [ 720/3750]  eta: 0:17:37  Lr: 0.001875  Loss: -1.0005  Acc@1: 87.5000 (82.7757)  Acc@5: 100.0000 (97.2521)  time: 0.3469  data: 0.0013  max mem: 2500
Train: Epoch[4/5]  [ 730/3750]  eta: 0:17:33  Lr: 0.001875  Loss: -0.7245  Acc@1: 81.2500 (82.7890)  Acc@5: 100.0000 (97.2127)  time: 0.3456  data: 0.0011  max mem: 2500
Train: Epoch[4/5]  [ 740/3750]  eta: 0:17:29  Lr: 0.001875  Loss: -1.3011  Acc@1: 87.5000 (82.8104)  Acc@5: 93.7500 (97.2166)  time: 0.3461  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [ 750/3750]  eta: 0:17:26  Lr: 0.001875  Loss: -0.3550  Acc@1: 81.2500 (82.7730)  Acc@5: 93.7500 (97.1871)  time: 0.3471  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [ 760/3750]  eta: 0:17:22  Lr: 0.001875  Loss: -1.1811  Acc@1: 81.2500 (82.7283)  Acc@5: 100.0000 (97.1994)  time: 0.3474  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [ 770/3750]  eta: 0:17:19  Lr: 0.001875  Loss: -0.9014  Acc@1: 81.2500 (82.7416)  Acc@5: 100.0000 (97.1871)  time: 0.3468  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [ 780/3750]  eta: 0:17:15  Lr: 0.001875  Loss: -1.1903  Acc@1: 81.2500 (82.7465)  Acc@5: 93.7500 (97.1831)  time: 0.3462  data: 0.0009  max mem: 2500
Train: Epoch[4/5]  [ 790/3750]  eta: 0:17:12  Lr: 0.001875  Loss: -0.7486  Acc@1: 81.2500 (82.7513)  Acc@5: 100.0000 (97.1871)  time: 0.3467  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [ 800/3750]  eta: 0:17:08  Lr: 0.001875  Loss: -1.1171  Acc@1: 87.5000 (82.7637)  Acc@5: 100.0000 (97.1910)  time: 0.3478  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [ 810/3750]  eta: 0:17:04  Lr: 0.001875  Loss: -0.9690  Acc@1: 81.2500 (82.7219)  Acc@5: 100.0000 (97.1948)  time: 0.3478  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [ 820/3750]  eta: 0:17:01  Lr: 0.001875  Loss: -1.1678  Acc@1: 81.2500 (82.7269)  Acc@5: 100.0000 (97.1985)  time: 0.3467  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [ 830/3750]  eta: 0:16:57  Lr: 0.001875  Loss: -1.0849  Acc@1: 81.2500 (82.7016)  Acc@5: 100.0000 (97.2097)  time: 0.3484  data: 0.0010  max mem: 2500
Train: Epoch[4/5]  [ 840/3750]  eta: 0:16:54  Lr: 0.001875  Loss: -0.9288  Acc@1: 81.2500 (82.6694)  Acc@5: 100.0000 (97.2206)  time: 0.3481  data: 0.0010  max mem: 2500
Train: Epoch[4/5]  [ 850/3750]  eta: 0:16:50  Lr: 0.001875  Loss: -0.8635  Acc@1: 81.2500 (82.6234)  Acc@5: 100.0000 (97.1945)  time: 0.3482  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [ 860/3750]  eta: 0:16:47  Lr: 0.001875  Loss: -0.9440  Acc@1: 81.2500 (82.6147)  Acc@5: 93.7500 (97.1690)  time: 0.3478  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [ 870/3750]  eta: 0:16:43  Lr: 0.001875  Loss: -1.0420  Acc@1: 87.5000 (82.6636)  Acc@5: 93.7500 (97.1656)  time: 0.3470  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [ 880/3750]  eta: 0:16:40  Lr: 0.001875  Loss: -0.9288  Acc@1: 81.2500 (82.6476)  Acc@5: 100.0000 (97.1552)  time: 0.3474  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [ 890/3750]  eta: 0:16:36  Lr: 0.001875  Loss: -0.6178  Acc@1: 81.2500 (82.6880)  Acc@5: 100.0000 (97.1591)  time: 0.3484  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [ 900/3750]  eta: 0:16:33  Lr: 0.001875  Loss: -0.7123  Acc@1: 87.5000 (82.7622)  Acc@5: 100.0000 (97.1698)  time: 0.3507  data: 0.0009  max mem: 2500
Train: Epoch[4/5]  [ 910/3750]  eta: 0:16:30  Lr: 0.001875  Loss: -0.8793  Acc@1: 87.5000 (82.7456)  Acc@5: 100.0000 (97.1734)  time: 0.3493  data: 0.0009  max mem: 2500
Train: Epoch[4/5]  [ 920/3750]  eta: 0:16:26  Lr: 0.001875  Loss: -1.2217  Acc@1: 75.0000 (82.7158)  Acc@5: 100.0000 (97.1634)  time: 0.3483  data: 0.0015  max mem: 2500
Train: Epoch[4/5]  [ 930/3750]  eta: 0:16:23  Lr: 0.001875  Loss: -0.8292  Acc@1: 81.2500 (82.7403)  Acc@5: 93.7500 (97.1603)  time: 0.3493  data: 0.0016  max mem: 2500
Train: Epoch[4/5]  [ 940/3750]  eta: 0:16:19  Lr: 0.001875  Loss: -0.5652  Acc@1: 87.5000 (82.7179)  Acc@5: 93.7500 (97.1506)  time: 0.3488  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [ 950/3750]  eta: 0:16:16  Lr: 0.001875  Loss: -1.0257  Acc@1: 81.2500 (82.6958)  Acc@5: 100.0000 (97.1609)  time: 0.3473  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [ 960/3750]  eta: 0:16:12  Lr: 0.001875  Loss: -0.6869  Acc@1: 87.5000 (82.7393)  Acc@5: 100.0000 (97.1579)  time: 0.3465  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [ 970/3750]  eta: 0:16:08  Lr: 0.001875  Loss: -1.1340  Acc@1: 87.5000 (82.8012)  Acc@5: 100.0000 (97.1743)  time: 0.3471  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [ 980/3750]  eta: 0:16:05  Lr: 0.001875  Loss: -1.0078  Acc@1: 87.5000 (82.8173)  Acc@5: 100.0000 (97.1840)  time: 0.3493  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [ 990/3750]  eta: 0:16:02  Lr: 0.001875  Loss: -0.9537  Acc@1: 81.2500 (82.7952)  Acc@5: 100.0000 (97.1683)  time: 0.3494  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [1000/3750]  eta: 0:15:58  Lr: 0.001875  Loss: -0.8437  Acc@1: 75.0000 (82.7735)  Acc@5: 100.0000 (97.1778)  time: 0.3477  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [1010/3750]  eta: 0:15:55  Lr: 0.001875  Loss: -1.2809  Acc@1: 81.2500 (82.7831)  Acc@5: 100.0000 (97.1872)  time: 0.3493  data: 0.0015  max mem: 2500
Train: Epoch[4/5]  [1020/3750]  eta: 0:15:51  Lr: 0.001875  Loss: -1.0037  Acc@1: 87.5000 (82.8232)  Acc@5: 100.0000 (97.1903)  time: 0.3506  data: 0.0018  max mem: 2500
Train: Epoch[4/5]  [1030/3750]  eta: 0:15:48  Lr: 0.001875  Loss: -0.6709  Acc@1: 87.5000 (82.8019)  Acc@5: 100.0000 (97.1993)  time: 0.3487  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [1040/3750]  eta: 0:15:44  Lr: 0.001875  Loss: -1.2318  Acc@1: 81.2500 (82.7810)  Acc@5: 100.0000 (97.1962)  time: 0.3479  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [1050/3750]  eta: 0:15:41  Lr: 0.001875  Loss: -1.2557  Acc@1: 87.5000 (82.8199)  Acc@5: 100.0000 (97.1931)  time: 0.3486  data: 0.0012  max mem: 2500
Train: Epoch[4/5]  [1060/3750]  eta: 0:15:37  Lr: 0.001875  Loss: -0.5045  Acc@1: 87.5000 (82.8640)  Acc@5: 100.0000 (97.2019)  time: 0.3473  data: 0.0012  max mem: 2500
Train: Epoch[4/5]  [1070/3750]  eta: 0:15:34  Lr: 0.001875  Loss: -1.0132  Acc@1: 87.5000 (82.8898)  Acc@5: 100.0000 (97.2047)  time: 0.3483  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [1080/3750]  eta: 0:15:30  Lr: 0.001875  Loss: -1.0646  Acc@1: 81.2500 (82.9036)  Acc@5: 100.0000 (97.2132)  time: 0.3492  data: 0.0016  max mem: 2500
Train: Epoch[4/5]  [1090/3750]  eta: 0:15:27  Lr: 0.001875  Loss: -0.8950  Acc@1: 81.2500 (82.8655)  Acc@5: 100.0000 (97.2101)  time: 0.3482  data: 0.0017  max mem: 2500
Train: Epoch[4/5]  [1100/3750]  eta: 0:15:23  Lr: 0.001875  Loss: -0.6797  Acc@1: 75.0000 (82.8111)  Acc@5: 93.7500 (97.2071)  time: 0.3484  data: 0.0012  max mem: 2500
Train: Epoch[4/5]  [1110/3750]  eta: 0:15:20  Lr: 0.001875  Loss: -1.2105  Acc@1: 81.2500 (82.8083)  Acc@5: 93.7500 (97.1928)  time: 0.3469  data: 0.0010  max mem: 2500
Train: Epoch[4/5]  [1120/3750]  eta: 0:15:16  Lr: 0.001875  Loss: -0.3602  Acc@1: 81.2500 (82.7888)  Acc@5: 93.7500 (97.1789)  time: 0.3460  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [1130/3750]  eta: 0:15:13  Lr: 0.001875  Loss: -1.0943  Acc@1: 87.5000 (82.8305)  Acc@5: 100.0000 (97.1983)  time: 0.3481  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [1140/3750]  eta: 0:15:09  Lr: 0.001875  Loss: -0.9285  Acc@1: 87.5000 (82.8221)  Acc@5: 100.0000 (97.2064)  time: 0.3476  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [1150/3750]  eta: 0:15:06  Lr: 0.001875  Loss: -1.0266  Acc@1: 81.2500 (82.8193)  Acc@5: 100.0000 (97.2089)  time: 0.3472  data: 0.0009  max mem: 2500
Train: Epoch[4/5]  [1160/3750]  eta: 0:15:02  Lr: 0.001875  Loss: -1.1220  Acc@1: 87.5000 (82.8542)  Acc@5: 100.0000 (97.2168)  time: 0.3473  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [1170/3750]  eta: 0:14:59  Lr: 0.001875  Loss: -1.1769  Acc@1: 87.5000 (82.8832)  Acc@5: 100.0000 (97.2299)  time: 0.3458  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [1180/3750]  eta: 0:14:55  Lr: 0.001875  Loss: -1.2414  Acc@1: 87.5000 (82.8747)  Acc@5: 100.0000 (97.2428)  time: 0.3466  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [1190/3750]  eta: 0:14:52  Lr: 0.001875  Loss: -0.7240  Acc@1: 81.2500 (82.8401)  Acc@5: 100.0000 (97.2450)  time: 0.3479  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [1200/3750]  eta: 0:14:48  Lr: 0.001875  Loss: -1.3669  Acc@1: 81.2500 (82.8372)  Acc@5: 100.0000 (97.2575)  time: 0.3475  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [1210/3750]  eta: 0:14:45  Lr: 0.001875  Loss: -0.7546  Acc@1: 87.5000 (82.8860)  Acc@5: 100.0000 (97.2595)  time: 0.3470  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [1220/3750]  eta: 0:14:41  Lr: 0.001875  Loss: -0.9027  Acc@1: 87.5000 (82.8778)  Acc@5: 100.0000 (97.2512)  time: 0.3472  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [1230/3750]  eta: 0:14:37  Lr: 0.001875  Loss: -0.7262  Acc@1: 81.2500 (82.8493)  Acc@5: 100.0000 (97.2329)  time: 0.3470  data: 0.0011  max mem: 2500
Train: Epoch[4/5]  [1240/3750]  eta: 0:14:34  Lr: 0.001875  Loss: -0.6870  Acc@1: 81.2500 (82.8364)  Acc@5: 100.0000 (97.2452)  time: 0.3460  data: 0.0011  max mem: 2500
Train: Epoch[4/5]  [1250/3750]  eta: 0:14:30  Lr: 0.001875  Loss: -0.6618  Acc@1: 81.2500 (82.8187)  Acc@5: 100.0000 (97.2272)  time: 0.3467  data: 0.0011  max mem: 2500
Train: Epoch[4/5]  [1260/3750]  eta: 0:14:27  Lr: 0.001875  Loss: -1.2694  Acc@1: 87.5000 (82.8707)  Acc@5: 100.0000 (97.2492)  time: 0.3465  data: 0.0011  max mem: 2500
Train: Epoch[4/5]  [1270/3750]  eta: 0:14:23  Lr: 0.001875  Loss: -1.3261  Acc@1: 87.5000 (82.8531)  Acc@5: 100.0000 (97.2413)  time: 0.3452  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [1280/3750]  eta: 0:14:20  Lr: 0.001875  Loss: -0.6411  Acc@1: 81.2500 (82.8649)  Acc@5: 93.7500 (97.2385)  time: 0.3470  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [1290/3750]  eta: 0:14:16  Lr: 0.001875  Loss: -1.1233  Acc@1: 87.5000 (82.8621)  Acc@5: 93.7500 (97.2163)  time: 0.3479  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [1300/3750]  eta: 0:14:13  Lr: 0.001875  Loss: -0.6776  Acc@1: 81.2500 (82.8689)  Acc@5: 100.0000 (97.2281)  time: 0.3492  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [1310/3750]  eta: 0:14:09  Lr: 0.001875  Loss: -0.7480  Acc@1: 81.2500 (82.8804)  Acc@5: 100.0000 (97.2349)  time: 0.3494  data: 0.0010  max mem: 2500
Train: Epoch[4/5]  [1320/3750]  eta: 0:14:06  Lr: 0.001875  Loss: -0.6224  Acc@1: 87.5000 (82.8965)  Acc@5: 100.0000 (97.2322)  time: 0.3490  data: 0.0009  max mem: 2500
Train: Epoch[4/5]  [1330/3750]  eta: 0:14:02  Lr: 0.001875  Loss: -0.7345  Acc@1: 87.5000 (82.8935)  Acc@5: 100.0000 (97.2201)  time: 0.3483  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [1340/3750]  eta: 0:13:59  Lr: 0.001875  Loss: -1.1360  Acc@1: 87.5000 (82.9372)  Acc@5: 100.0000 (97.2362)  time: 0.3476  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [1350/3750]  eta: 0:13:55  Lr: 0.001875  Loss: -0.5385  Acc@1: 87.5000 (82.9617)  Acc@5: 100.0000 (97.2428)  time: 0.3467  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [1360/3750]  eta: 0:13:52  Lr: 0.001875  Loss: -1.0053  Acc@1: 87.5000 (82.9767)  Acc@5: 100.0000 (97.2309)  time: 0.3471  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [1370/3750]  eta: 0:13:48  Lr: 0.001875  Loss: -0.8116  Acc@1: 81.2500 (82.9641)  Acc@5: 93.7500 (97.2146)  time: 0.3473  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [1380/3750]  eta: 0:13:45  Lr: 0.001875  Loss: -0.8932  Acc@1: 81.2500 (82.9698)  Acc@5: 93.7500 (97.2076)  time: 0.3470  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [1390/3750]  eta: 0:13:41  Lr: 0.001875  Loss: -1.1388  Acc@1: 87.5000 (82.9799)  Acc@5: 100.0000 (97.2008)  time: 0.3472  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [1400/3750]  eta: 0:13:38  Lr: 0.001875  Loss: -1.0252  Acc@1: 81.2500 (82.9541)  Acc@5: 100.0000 (97.1806)  time: 0.3466  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [1410/3750]  eta: 0:13:35  Lr: 0.001875  Loss: -0.7293  Acc@1: 81.2500 (82.9465)  Acc@5: 93.7500 (97.1696)  time: 0.3499  data: 0.0010  max mem: 2500
Train: Epoch[4/5]  [1420/3750]  eta: 0:13:31  Lr: 0.001875  Loss: -0.9858  Acc@1: 81.2500 (82.9390)  Acc@5: 100.0000 (97.1587)  time: 0.3518  data: 0.0019  max mem: 2500
Train: Epoch[4/5]  [1430/3750]  eta: 0:13:28  Lr: 0.001875  Loss: -1.1242  Acc@1: 81.2500 (82.9009)  Acc@5: 100.0000 (97.1567)  time: 0.3495  data: 0.0015  max mem: 2500
Train: Epoch[4/5]  [1440/3750]  eta: 0:13:24  Lr: 0.001875  Loss: -1.1396  Acc@1: 75.0000 (82.8851)  Acc@5: 100.0000 (97.1504)  time: 0.3464  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [1450/3750]  eta: 0:13:21  Lr: 0.001875  Loss: -0.6887  Acc@1: 81.2500 (82.9170)  Acc@5: 100.0000 (97.1528)  time: 0.3468  data: 0.0012  max mem: 2500
Train: Epoch[4/5]  [1460/3750]  eta: 0:13:17  Lr: 0.001875  Loss: -0.8714  Acc@1: 87.5000 (82.9269)  Acc@5: 100.0000 (97.1595)  time: 0.3487  data: 0.0013  max mem: 2500
Train: Epoch[4/5]  [1470/3750]  eta: 0:13:14  Lr: 0.001875  Loss: -1.2096  Acc@1: 87.5000 (82.9283)  Acc@5: 100.0000 (97.1575)  time: 0.3475  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [1480/3750]  eta: 0:13:10  Lr: 0.001875  Loss: -0.8796  Acc@1: 81.2500 (82.9085)  Acc@5: 100.0000 (97.1388)  time: 0.3457  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [1490/3750]  eta: 0:13:07  Lr: 0.001875  Loss: -1.2099  Acc@1: 81.2500 (82.8974)  Acc@5: 93.7500 (97.1328)  time: 0.3467  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [1500/3750]  eta: 0:13:03  Lr: 0.001875  Loss: -1.2753  Acc@1: 81.2500 (82.8989)  Acc@5: 100.0000 (97.1352)  time: 0.3471  data: 0.0012  max mem: 2500
Train: Epoch[4/5]  [1510/3750]  eta: 0:13:00  Lr: 0.001875  Loss: -0.8192  Acc@1: 81.2500 (82.8921)  Acc@5: 100.0000 (97.1459)  time: 0.3482  data: 0.0013  max mem: 2500
Train: Epoch[4/5]  [1520/3750]  eta: 0:12:56  Lr: 0.001875  Loss: -0.8690  Acc@1: 81.2500 (82.8978)  Acc@5: 100.0000 (97.1524)  time: 0.3504  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [1530/3750]  eta: 0:12:53  Lr: 0.001875  Loss: -1.1142  Acc@1: 87.5000 (82.9401)  Acc@5: 100.0000 (97.1587)  time: 0.3489  data: 0.0013  max mem: 2500
Train: Epoch[4/5]  [1540/3750]  eta: 0:12:49  Lr: 0.001875  Loss: -0.9720  Acc@1: 87.5000 (82.9291)  Acc@5: 100.0000 (97.1528)  time: 0.3468  data: 0.0010  max mem: 2500
Train: Epoch[4/5]  [1550/3750]  eta: 0:12:46  Lr: 0.001875  Loss: -0.5823  Acc@1: 81.2500 (82.9263)  Acc@5: 100.0000 (97.1551)  time: 0.3463  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [1560/3750]  eta: 0:12:42  Lr: 0.001875  Loss: -1.2959  Acc@1: 81.2500 (82.9156)  Acc@5: 100.0000 (97.1453)  time: 0.3469  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [1570/3750]  eta: 0:12:39  Lr: 0.001875  Loss: -0.4802  Acc@1: 81.2500 (82.9249)  Acc@5: 100.0000 (97.1555)  time: 0.3469  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [1580/3750]  eta: 0:12:35  Lr: 0.001875  Loss: -0.9335  Acc@1: 87.5000 (82.9341)  Acc@5: 100.0000 (97.1695)  time: 0.3459  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [1590/3750]  eta: 0:12:32  Lr: 0.001875  Loss: -0.6650  Acc@1: 87.5000 (82.9470)  Acc@5: 100.0000 (97.1677)  time: 0.3470  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [1600/3750]  eta: 0:12:28  Lr: 0.001875  Loss: -0.9242  Acc@1: 81.2500 (82.9599)  Acc@5: 100.0000 (97.1697)  time: 0.3480  data: 0.0009  max mem: 2500
Train: Epoch[4/5]  [1610/3750]  eta: 0:12:25  Lr: 0.001875  Loss: -0.9570  Acc@1: 81.2500 (82.9570)  Acc@5: 100.0000 (97.1718)  time: 0.3471  data: 0.0009  max mem: 2500
Train: Epoch[4/5]  [1620/3750]  eta: 0:12:21  Lr: 0.001875  Loss: -1.0148  Acc@1: 81.2500 (82.9696)  Acc@5: 100.0000 (97.1815)  time: 0.3471  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [1630/3750]  eta: 0:12:18  Lr: 0.001875  Loss: -1.2569  Acc@1: 81.2500 (82.9897)  Acc@5: 100.0000 (97.1796)  time: 0.3467  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [1640/3750]  eta: 0:12:14  Lr: 0.001875  Loss: -0.5376  Acc@1: 87.5000 (83.0058)  Acc@5: 100.0000 (97.1702)  time: 0.3471  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [1650/3750]  eta: 0:12:11  Lr: 0.001875  Loss: -1.2169  Acc@1: 87.5000 (83.0254)  Acc@5: 100.0000 (97.1873)  time: 0.3488  data: 0.0009  max mem: 2500
Train: Epoch[4/5]  [1660/3750]  eta: 0:12:07  Lr: 0.001875  Loss: -1.1425  Acc@1: 87.5000 (83.0336)  Acc@5: 100.0000 (97.1930)  time: 0.3481  data: 0.0010  max mem: 2500
Train: Epoch[4/5]  [1670/3750]  eta: 0:12:04  Lr: 0.001875  Loss: -0.5975  Acc@1: 81.2500 (83.0192)  Acc@5: 93.7500 (97.1761)  time: 0.3464  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [1680/3750]  eta: 0:12:00  Lr: 0.001875  Loss: -1.0705  Acc@1: 81.2500 (83.0347)  Acc@5: 93.7500 (97.1706)  time: 0.3458  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [1690/3750]  eta: 0:11:57  Lr: 0.001875  Loss: -0.7046  Acc@1: 81.2500 (83.0130)  Acc@5: 100.0000 (97.1836)  time: 0.3481  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [1700/3750]  eta: 0:11:53  Lr: 0.001875  Loss: -1.2131  Acc@1: 81.2500 (83.0284)  Acc@5: 100.0000 (97.1928)  time: 0.3501  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [1710/3750]  eta: 0:11:50  Lr: 0.001875  Loss: -0.5230  Acc@1: 81.2500 (83.0070)  Acc@5: 100.0000 (97.1837)  time: 0.3479  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [1720/3750]  eta: 0:11:46  Lr: 0.001875  Loss: -0.8615  Acc@1: 81.2500 (82.9895)  Acc@5: 100.0000 (97.1855)  time: 0.3461  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [1730/3750]  eta: 0:11:43  Lr: 0.001875  Loss: -0.8820  Acc@1: 81.2500 (83.0084)  Acc@5: 100.0000 (97.1909)  time: 0.3492  data: 0.0022  max mem: 2500
Train: Epoch[4/5]  [1740/3750]  eta: 0:11:39  Lr: 0.001875  Loss: -0.7336  Acc@1: 81.2500 (82.9839)  Acc@5: 100.0000 (97.1819)  time: 0.3501  data: 0.0021  max mem: 2500
Train: Epoch[4/5]  [1750/3750]  eta: 0:11:36  Lr: 0.001875  Loss: -0.8945  Acc@1: 81.2500 (82.9669)  Acc@5: 93.7500 (97.1766)  time: 0.3475  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [1760/3750]  eta: 0:11:32  Lr: 0.001875  Loss: -1.1481  Acc@1: 87.5000 (82.9891)  Acc@5: 100.0000 (97.1784)  time: 0.3478  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [1770/3750]  eta: 0:11:29  Lr: 0.001875  Loss: -1.2778  Acc@1: 87.5000 (83.0145)  Acc@5: 100.0000 (97.1803)  time: 0.3492  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [1780/3750]  eta: 0:11:25  Lr: 0.001875  Loss: -0.7993  Acc@1: 81.2500 (82.9976)  Acc@5: 100.0000 (97.1750)  time: 0.3480  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [1790/3750]  eta: 0:11:22  Lr: 0.001875  Loss: -1.0206  Acc@1: 75.0000 (82.9774)  Acc@5: 100.0000 (97.1734)  time: 0.3473  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [1800/3750]  eta: 0:11:18  Lr: 0.001875  Loss: -0.8011  Acc@1: 75.0000 (82.9331)  Acc@5: 93.7500 (97.1578)  time: 0.3480  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [1810/3750]  eta: 0:11:15  Lr: 0.001875  Loss: -0.4173  Acc@1: 81.2500 (82.9376)  Acc@5: 93.7500 (97.1597)  time: 0.3476  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [1820/3750]  eta: 0:11:11  Lr: 0.001875  Loss: -0.8248  Acc@1: 87.5000 (82.9592)  Acc@5: 100.0000 (97.1685)  time: 0.3472  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [1830/3750]  eta: 0:11:08  Lr: 0.001875  Loss: -0.7291  Acc@1: 87.5000 (82.9635)  Acc@5: 100.0000 (97.1703)  time: 0.3470  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [1840/3750]  eta: 0:11:04  Lr: 0.001875  Loss: -0.8954  Acc@1: 81.2500 (82.9576)  Acc@5: 93.7500 (97.1585)  time: 0.3485  data: 0.0011  max mem: 2500
Train: Epoch[4/5]  [1850/3750]  eta: 0:11:01  Lr: 0.001875  Loss: -0.3927  Acc@1: 81.2500 (82.9619)  Acc@5: 93.7500 (97.1637)  time: 0.3490  data: 0.0010  max mem: 2500
Train: Epoch[4/5]  [1860/3750]  eta: 0:10:58  Lr: 0.001875  Loss: -1.0640  Acc@1: 81.2500 (82.9594)  Acc@5: 100.0000 (97.1588)  time: 0.3481  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [1870/3750]  eta: 0:10:54  Lr: 0.001875  Loss: -1.0251  Acc@1: 81.2500 (82.9870)  Acc@5: 93.7500 (97.1539)  time: 0.3484  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [1880/3750]  eta: 0:10:51  Lr: 0.001875  Loss: -0.7387  Acc@1: 81.2500 (82.9612)  Acc@5: 100.0000 (97.1624)  time: 0.3485  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [1890/3750]  eta: 0:10:47  Lr: 0.001875  Loss: -1.1309  Acc@1: 81.2500 (82.9753)  Acc@5: 100.0000 (97.1609)  time: 0.3486  data: 0.0014  max mem: 2500
Train: Epoch[4/5]  [1900/3750]  eta: 0:10:44  Lr: 0.001875  Loss: -0.8970  Acc@1: 87.5000 (82.9826)  Acc@5: 93.7500 (97.1528)  time: 0.3480  data: 0.0013  max mem: 2500
Train: Epoch[4/5]  [1910/3750]  eta: 0:10:40  Lr: 0.001875  Loss: -0.9334  Acc@1: 81.2500 (82.9441)  Acc@5: 93.7500 (97.1514)  time: 0.3461  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1920/3750]  eta: 0:10:37  Lr: 0.001875  Loss: -0.9622  Acc@1: 81.2500 (82.9483)  Acc@5: 100.0000 (97.1532)  time: 0.3460  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [1930/3750]  eta: 0:10:33  Lr: 0.001875  Loss: -0.4315  Acc@1: 87.5000 (82.9525)  Acc@5: 100.0000 (97.1582)  time: 0.3469  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [1940/3750]  eta: 0:10:30  Lr: 0.001875  Loss: -0.7326  Acc@1: 81.2500 (82.9212)  Acc@5: 100.0000 (97.1567)  time: 0.3465  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [1950/3750]  eta: 0:10:26  Lr: 0.001875  Loss: -0.7640  Acc@1: 81.2500 (82.9286)  Acc@5: 100.0000 (97.1649)  time: 0.3474  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [1960/3750]  eta: 0:10:23  Lr: 0.001875  Loss: -0.6579  Acc@1: 87.5000 (82.9456)  Acc@5: 100.0000 (97.1730)  time: 0.3473  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [1970/3750]  eta: 0:10:19  Lr: 0.001875  Loss: -0.6432  Acc@1: 81.2500 (82.9560)  Acc@5: 100.0000 (97.1747)  time: 0.3470  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [1980/3750]  eta: 0:10:16  Lr: 0.001875  Loss: -1.2288  Acc@1: 87.5000 (82.9789)  Acc@5: 100.0000 (97.1763)  time: 0.3468  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [1990/3750]  eta: 0:10:12  Lr: 0.001875  Loss: -0.5316  Acc@1: 87.5000 (82.9985)  Acc@5: 100.0000 (97.1779)  time: 0.3460  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2000/3750]  eta: 0:10:09  Lr: 0.001875  Loss: -1.0935  Acc@1: 87.5000 (82.9929)  Acc@5: 100.0000 (97.1795)  time: 0.3467  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2010/3750]  eta: 0:10:05  Lr: 0.001875  Loss: -0.7505  Acc@1: 81.2500 (82.9811)  Acc@5: 93.7500 (97.1718)  time: 0.3460  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [2020/3750]  eta: 0:10:02  Lr: 0.001875  Loss: -1.0328  Acc@1: 81.2500 (82.9880)  Acc@5: 100.0000 (97.1827)  time: 0.3461  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2030/3750]  eta: 0:09:58  Lr: 0.001875  Loss: -1.0768  Acc@1: 87.5000 (83.0010)  Acc@5: 100.0000 (97.1873)  time: 0.3465  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2040/3750]  eta: 0:09:55  Lr: 0.001875  Loss: -0.8565  Acc@1: 81.2500 (82.9863)  Acc@5: 100.0000 (97.1889)  time: 0.3464  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2050/3750]  eta: 0:09:51  Lr: 0.001875  Loss: -0.8232  Acc@1: 81.2500 (82.9839)  Acc@5: 100.0000 (97.1813)  time: 0.3463  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2060/3750]  eta: 0:09:48  Lr: 0.001875  Loss: -1.1029  Acc@1: 81.2500 (82.9785)  Acc@5: 100.0000 (97.1828)  time: 0.3452  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2070/3750]  eta: 0:09:44  Lr: 0.001875  Loss: -1.1168  Acc@1: 87.5000 (82.9823)  Acc@5: 100.0000 (97.1783)  time: 0.3444  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2080/3750]  eta: 0:09:41  Lr: 0.001875  Loss: -0.9762  Acc@1: 81.2500 (82.9799)  Acc@5: 93.7500 (97.1708)  time: 0.3458  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2090/3750]  eta: 0:09:37  Lr: 0.001875  Loss: -0.7573  Acc@1: 81.2500 (82.9776)  Acc@5: 100.0000 (97.1724)  time: 0.3463  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2100/3750]  eta: 0:09:34  Lr: 0.001875  Loss: -0.2291  Acc@1: 81.2500 (82.9754)  Acc@5: 100.0000 (97.1740)  time: 0.3467  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2110/3750]  eta: 0:09:30  Lr: 0.001875  Loss: -1.1003  Acc@1: 87.5000 (83.0057)  Acc@5: 100.0000 (97.1844)  time: 0.3470  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2120/3750]  eta: 0:09:27  Lr: 0.001875  Loss: -1.2022  Acc@1: 87.5000 (83.0033)  Acc@5: 100.0000 (97.1859)  time: 0.3481  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [2130/3750]  eta: 0:09:23  Lr: 0.001875  Loss: -0.7527  Acc@1: 81.2500 (82.9745)  Acc@5: 100.0000 (97.1815)  time: 0.3481  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [2140/3750]  eta: 0:09:20  Lr: 0.001875  Loss: -1.2792  Acc@1: 81.2500 (82.9782)  Acc@5: 100.0000 (97.1771)  time: 0.3457  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2150/3750]  eta: 0:09:16  Lr: 0.001875  Loss: -1.0365  Acc@1: 81.2500 (82.9701)  Acc@5: 100.0000 (97.1786)  time: 0.3475  data: 0.0019  max mem: 2500
Train: Epoch[4/5]  [2160/3750]  eta: 0:09:13  Lr: 0.001875  Loss: -0.7501  Acc@1: 81.2500 (82.9564)  Acc@5: 100.0000 (97.1830)  time: 0.3481  data: 0.0019  max mem: 2500
Train: Epoch[4/5]  [2170/3750]  eta: 0:09:09  Lr: 0.001875  Loss: -0.7555  Acc@1: 81.2500 (82.9744)  Acc@5: 100.0000 (97.1931)  time: 0.3449  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2180/3750]  eta: 0:09:06  Lr: 0.001875  Loss: -0.3737  Acc@1: 87.5000 (82.9751)  Acc@5: 100.0000 (97.1974)  time: 0.3460  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2190/3750]  eta: 0:09:02  Lr: 0.001875  Loss: -1.1823  Acc@1: 87.5000 (82.9844)  Acc@5: 100.0000 (97.2016)  time: 0.3496  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2200/3750]  eta: 0:08:59  Lr: 0.001875  Loss: -0.9640  Acc@1: 81.2500 (82.9765)  Acc@5: 100.0000 (97.2030)  time: 0.3479  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [2210/3750]  eta: 0:08:55  Lr: 0.001875  Loss: -0.7344  Acc@1: 81.2500 (82.9772)  Acc@5: 100.0000 (97.2100)  time: 0.3478  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [2220/3750]  eta: 0:08:52  Lr: 0.001875  Loss: -0.6095  Acc@1: 81.2500 (82.9722)  Acc@5: 100.0000 (97.2085)  time: 0.3502  data: 0.0015  max mem: 2500
Train: Epoch[4/5]  [2230/3750]  eta: 0:08:48  Lr: 0.001875  Loss: -1.2570  Acc@1: 81.2500 (82.9925)  Acc@5: 100.0000 (97.2098)  time: 0.3482  data: 0.0017  max mem: 2500
Train: Epoch[4/5]  [2240/3750]  eta: 0:08:45  Lr: 0.001875  Loss: -1.3774  Acc@1: 81.2500 (82.9959)  Acc@5: 100.0000 (97.2083)  time: 0.3468  data: 0.0009  max mem: 2500
Train: Epoch[4/5]  [2250/3750]  eta: 0:08:41  Lr: 0.001875  Loss: -1.1808  Acc@1: 81.2500 (83.0020)  Acc@5: 100.0000 (97.2151)  time: 0.3483  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [2260/3750]  eta: 0:08:38  Lr: 0.001875  Loss: -1.1576  Acc@1: 81.2500 (83.0025)  Acc@5: 100.0000 (97.2192)  time: 0.3483  data: 0.0010  max mem: 2500
Train: Epoch[4/5]  [2270/3750]  eta: 0:08:34  Lr: 0.001875  Loss: -0.7845  Acc@1: 81.2500 (82.9783)  Acc@5: 100.0000 (97.2066)  time: 0.3475  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [2280/3750]  eta: 0:08:31  Lr: 0.001875  Loss: -0.8546  Acc@1: 81.2500 (82.9954)  Acc@5: 100.0000 (97.2079)  time: 0.3473  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [2290/3750]  eta: 0:08:28  Lr: 0.001875  Loss: -0.8462  Acc@1: 81.2500 (82.9878)  Acc@5: 100.0000 (97.2010)  time: 0.3470  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [2300/3750]  eta: 0:08:24  Lr: 0.001875  Loss: -0.9481  Acc@1: 81.2500 (82.9829)  Acc@5: 100.0000 (97.1969)  time: 0.3483  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [2310/3750]  eta: 0:08:21  Lr: 0.001875  Loss: -1.0466  Acc@1: 81.2500 (82.9836)  Acc@5: 100.0000 (97.1928)  time: 0.3476  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [2320/3750]  eta: 0:08:17  Lr: 0.001875  Loss: -1.0954  Acc@1: 87.5000 (82.9949)  Acc@5: 100.0000 (97.1860)  time: 0.3482  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [2330/3750]  eta: 0:08:14  Lr: 0.001875  Loss: -0.5825  Acc@1: 81.2500 (82.9606)  Acc@5: 100.0000 (97.1900)  time: 0.3491  data: 0.0010  max mem: 2500
Train: Epoch[4/5]  [2340/3750]  eta: 0:08:10  Lr: 0.001875  Loss: -1.0101  Acc@1: 81.2500 (82.9694)  Acc@5: 100.0000 (97.1914)  time: 0.3475  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [2350/3750]  eta: 0:08:07  Lr: 0.001875  Loss: -0.7357  Acc@1: 81.2500 (82.9647)  Acc@5: 100.0000 (97.1900)  time: 0.3482  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2360/3750]  eta: 0:08:03  Lr: 0.001875  Loss: -0.5893  Acc@1: 81.2500 (82.9627)  Acc@5: 100.0000 (97.1887)  time: 0.3474  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2370/3750]  eta: 0:08:00  Lr: 0.001875  Loss: -1.2424  Acc@1: 81.2500 (82.9608)  Acc@5: 100.0000 (97.1953)  time: 0.3469  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [2380/3750]  eta: 0:07:56  Lr: 0.001875  Loss: -1.1426  Acc@1: 81.2500 (82.9720)  Acc@5: 100.0000 (97.1966)  time: 0.3478  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [2390/3750]  eta: 0:07:53  Lr: 0.001875  Loss: -0.5545  Acc@1: 87.5000 (82.9752)  Acc@5: 100.0000 (97.1978)  time: 0.3472  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2400/3750]  eta: 0:07:49  Lr: 0.001875  Loss: -1.1737  Acc@1: 81.2500 (82.9654)  Acc@5: 100.0000 (97.1991)  time: 0.3478  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2410/3750]  eta: 0:07:46  Lr: 0.001875  Loss: -0.9394  Acc@1: 81.2500 (82.9609)  Acc@5: 93.7500 (97.1822)  time: 0.3485  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2420/3750]  eta: 0:07:42  Lr: 0.001875  Loss: -1.1237  Acc@1: 87.5000 (82.9719)  Acc@5: 93.7500 (97.1861)  time: 0.3499  data: 0.0015  max mem: 2500
Train: Epoch[4/5]  [2430/3750]  eta: 0:07:39  Lr: 0.001875  Loss: -0.7009  Acc@1: 81.2500 (82.9648)  Acc@5: 100.0000 (97.1797)  time: 0.3502  data: 0.0016  max mem: 2500
Train: Epoch[4/5]  [2440/3750]  eta: 0:07:35  Lr: 0.001875  Loss: -1.0944  Acc@1: 81.2500 (82.9783)  Acc@5: 93.7500 (97.1835)  time: 0.3473  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [2450/3750]  eta: 0:07:32  Lr: 0.001875  Loss: -0.9269  Acc@1: 87.5000 (82.9865)  Acc@5: 100.0000 (97.1823)  time: 0.3465  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [2460/3750]  eta: 0:07:28  Lr: 0.001875  Loss: -0.9635  Acc@1: 87.5000 (83.0074)  Acc@5: 100.0000 (97.1836)  time: 0.3467  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2470/3750]  eta: 0:07:25  Lr: 0.001875  Loss: -1.0889  Acc@1: 87.5000 (83.0256)  Acc@5: 100.0000 (97.1899)  time: 0.3476  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2480/3750]  eta: 0:07:21  Lr: 0.001875  Loss: -1.1997  Acc@1: 87.5000 (83.0336)  Acc@5: 100.0000 (97.1937)  time: 0.3480  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2490/3750]  eta: 0:07:18  Lr: 0.001875  Loss: -0.9054  Acc@1: 87.5000 (83.0389)  Acc@5: 100.0000 (97.1949)  time: 0.3471  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [2500/3750]  eta: 0:07:14  Lr: 0.001875  Loss: -1.0140  Acc@1: 81.2500 (83.0293)  Acc@5: 100.0000 (97.2011)  time: 0.3474  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [2510/3750]  eta: 0:07:11  Lr: 0.001875  Loss: -1.3895  Acc@1: 81.2500 (83.0322)  Acc@5: 100.0000 (97.1973)  time: 0.3478  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2520/3750]  eta: 0:07:08  Lr: 0.001875  Loss: -0.9006  Acc@1: 81.2500 (83.0201)  Acc@5: 100.0000 (97.1961)  time: 0.3502  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [2530/3750]  eta: 0:07:04  Lr: 0.001875  Loss: -0.8104  Acc@1: 81.2500 (83.0230)  Acc@5: 100.0000 (97.2022)  time: 0.3504  data: 0.0010  max mem: 2500
Train: Epoch[4/5]  [2540/3750]  eta: 0:07:01  Lr: 0.001875  Loss: -1.0953  Acc@1: 81.2500 (83.0185)  Acc@5: 100.0000 (97.1935)  time: 0.3485  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [2550/3750]  eta: 0:06:57  Lr: 0.001875  Loss: -0.8192  Acc@1: 81.2500 (83.0140)  Acc@5: 93.7500 (97.1923)  time: 0.3472  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2560/3750]  eta: 0:06:54  Lr: 0.001875  Loss: -0.8148  Acc@1: 81.2500 (82.9974)  Acc@5: 100.0000 (97.1959)  time: 0.3473  data: 0.0013  max mem: 2500
Train: Epoch[4/5]  [2570/3750]  eta: 0:06:50  Lr: 0.001875  Loss: -1.0935  Acc@1: 81.2500 (82.9930)  Acc@5: 100.0000 (97.1995)  time: 0.3486  data: 0.0014  max mem: 2500
Train: Epoch[4/5]  [2580/3750]  eta: 0:06:47  Lr: 0.001875  Loss: -0.9835  Acc@1: 81.2500 (82.9911)  Acc@5: 100.0000 (97.2055)  time: 0.3472  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2590/3750]  eta: 0:06:43  Lr: 0.001875  Loss: -1.0581  Acc@1: 81.2500 (82.9820)  Acc@5: 100.0000 (97.1970)  time: 0.3473  data: 0.0009  max mem: 2500
Train: Epoch[4/5]  [2600/3750]  eta: 0:06:40  Lr: 0.001875  Loss: -0.4731  Acc@1: 81.2500 (83.0017)  Acc@5: 100.0000 (97.2030)  time: 0.3497  data: 0.0011  max mem: 2500
Train: Epoch[4/5]  [2610/3750]  eta: 0:06:36  Lr: 0.001875  Loss: -0.8620  Acc@1: 81.2500 (82.9926)  Acc@5: 100.0000 (97.2065)  time: 0.3490  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [2620/3750]  eta: 0:06:33  Lr: 0.001875  Loss: -0.8725  Acc@1: 75.0000 (82.9502)  Acc@5: 100.0000 (97.2005)  time: 0.3472  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2630/3750]  eta: 0:06:29  Lr: 0.001875  Loss: -1.2922  Acc@1: 81.2500 (82.9604)  Acc@5: 100.0000 (97.2016)  time: 0.3479  data: 0.0017  max mem: 2500
Train: Epoch[4/5]  [2640/3750]  eta: 0:06:26  Lr: 0.001875  Loss: -0.5559  Acc@1: 81.2500 (82.9586)  Acc@5: 100.0000 (97.2028)  time: 0.3482  data: 0.0018  max mem: 2500
Train: Epoch[4/5]  [2650/3750]  eta: 0:06:22  Lr: 0.001875  Loss: -0.7497  Acc@1: 81.2500 (82.9593)  Acc@5: 100.0000 (97.2039)  time: 0.3474  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [2660/3750]  eta: 0:06:19  Lr: 0.001875  Loss: -1.0862  Acc@1: 87.5000 (82.9787)  Acc@5: 100.0000 (97.2073)  time: 0.3465  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2670/3750]  eta: 0:06:15  Lr: 0.001875  Loss: -1.0642  Acc@1: 87.5000 (82.9886)  Acc@5: 100.0000 (97.2108)  time: 0.3465  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2680/3750]  eta: 0:06:12  Lr: 0.001875  Loss: -0.8967  Acc@1: 87.5000 (83.0031)  Acc@5: 100.0000 (97.2095)  time: 0.3456  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2690/3750]  eta: 0:06:08  Lr: 0.001875  Loss: -0.6779  Acc@1: 87.5000 (83.0082)  Acc@5: 93.7500 (97.2060)  time: 0.3461  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2700/3750]  eta: 0:06:05  Lr: 0.001875  Loss: -1.2167  Acc@1: 87.5000 (83.0341)  Acc@5: 100.0000 (97.2094)  time: 0.3470  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2710/3750]  eta: 0:06:01  Lr: 0.001875  Loss: -0.6856  Acc@1: 87.5000 (83.0598)  Acc@5: 100.0000 (97.2104)  time: 0.3463  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2720/3750]  eta: 0:05:58  Lr: 0.001875  Loss: -0.6123  Acc@1: 87.5000 (83.0462)  Acc@5: 100.0000 (97.2046)  time: 0.3483  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2730/3750]  eta: 0:05:54  Lr: 0.001875  Loss: -0.9926  Acc@1: 75.0000 (83.0190)  Acc@5: 100.0000 (97.1988)  time: 0.3504  data: 0.0010  max mem: 2500
Train: Epoch[4/5]  [2740/3750]  eta: 0:05:51  Lr: 0.001875  Loss: -0.8574  Acc@1: 81.2500 (83.0240)  Acc@5: 100.0000 (97.2045)  time: 0.3495  data: 0.0015  max mem: 2500
Train: Epoch[4/5]  [2750/3750]  eta: 0:05:47  Lr: 0.001875  Loss: -1.1782  Acc@1: 81.2500 (83.0016)  Acc@5: 100.0000 (97.2078)  time: 0.3485  data: 0.0010  max mem: 2500
Train: Epoch[4/5]  [2760/3750]  eta: 0:05:44  Lr: 0.001875  Loss: -1.0924  Acc@1: 81.2500 (83.0157)  Acc@5: 100.0000 (97.2089)  time: 0.3486  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [2770/3750]  eta: 0:05:41  Lr: 0.001875  Loss: -0.8343  Acc@1: 81.2500 (83.0093)  Acc@5: 100.0000 (97.2099)  time: 0.3498  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [2780/3750]  eta: 0:05:37  Lr: 0.001875  Loss: -1.1508  Acc@1: 81.2500 (83.0120)  Acc@5: 100.0000 (97.2110)  time: 0.3482  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [2790/3750]  eta: 0:05:34  Lr: 0.001875  Loss: -1.3178  Acc@1: 81.2500 (83.0079)  Acc@5: 100.0000 (97.2120)  time: 0.3471  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2800/3750]  eta: 0:05:30  Lr: 0.001875  Loss: -1.3752  Acc@1: 87.5000 (83.0239)  Acc@5: 100.0000 (97.2175)  time: 0.3472  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [2810/3750]  eta: 0:05:27  Lr: 0.001875  Loss: -0.3865  Acc@1: 87.5000 (83.0309)  Acc@5: 100.0000 (97.2141)  time: 0.3477  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [2820/3750]  eta: 0:05:23  Lr: 0.001875  Loss: -0.5308  Acc@1: 81.2500 (83.0246)  Acc@5: 100.0000 (97.2129)  time: 0.3486  data: 0.0009  max mem: 2500
Train: Epoch[4/5]  [2830/3750]  eta: 0:05:20  Lr: 0.001875  Loss: -0.6761  Acc@1: 81.2500 (83.0294)  Acc@5: 100.0000 (97.2117)  time: 0.3468  data: 0.0009  max mem: 2500
Train: Epoch[4/5]  [2840/3750]  eta: 0:05:16  Lr: 0.001875  Loss: -1.0073  Acc@1: 87.5000 (83.0341)  Acc@5: 100.0000 (97.2127)  time: 0.3466  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [2850/3750]  eta: 0:05:13  Lr: 0.001875  Loss: -0.8709  Acc@1: 87.5000 (83.0454)  Acc@5: 100.0000 (97.2071)  time: 0.3469  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [2860/3750]  eta: 0:05:09  Lr: 0.001875  Loss: -0.8999  Acc@1: 81.2500 (83.0501)  Acc@5: 100.0000 (97.2103)  time: 0.3478  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2870/3750]  eta: 0:05:06  Lr: 0.001875  Loss: -0.8242  Acc@1: 81.2500 (83.0351)  Acc@5: 100.0000 (97.2026)  time: 0.3475  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2880/3750]  eta: 0:05:02  Lr: 0.001875  Loss: -0.5925  Acc@1: 81.2500 (83.0441)  Acc@5: 93.7500 (97.1928)  time: 0.3472  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2890/3750]  eta: 0:04:59  Lr: 0.001875  Loss: -0.9286  Acc@1: 87.5000 (83.0487)  Acc@5: 100.0000 (97.1939)  time: 0.3476  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [2900/3750]  eta: 0:04:55  Lr: 0.001875  Loss: -0.7804  Acc@1: 81.2500 (83.0274)  Acc@5: 93.7500 (97.1842)  time: 0.3457  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2910/3750]  eta: 0:04:52  Lr: 0.001875  Loss: -1.3707  Acc@1: 75.0000 (83.0063)  Acc@5: 93.7500 (97.1874)  time: 0.3473  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [2920/3750]  eta: 0:04:48  Lr: 0.001875  Loss: -0.9766  Acc@1: 75.0000 (82.9874)  Acc@5: 100.0000 (97.1820)  time: 0.3518  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [2930/3750]  eta: 0:04:45  Lr: 0.001875  Loss: -1.3918  Acc@1: 81.2500 (82.9879)  Acc@5: 100.0000 (97.1831)  time: 0.3499  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [2940/3750]  eta: 0:04:41  Lr: 0.001875  Loss: -1.2349  Acc@1: 87.5000 (83.0011)  Acc@5: 100.0000 (97.1842)  time: 0.3471  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2950/3750]  eta: 0:04:38  Lr: 0.001875  Loss: -1.1218  Acc@1: 87.5000 (83.0079)  Acc@5: 100.0000 (97.1895)  time: 0.3467  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2960/3750]  eta: 0:04:34  Lr: 0.001875  Loss: -0.7274  Acc@1: 81.2500 (82.9914)  Acc@5: 100.0000 (97.1906)  time: 0.3468  data: 0.0009  max mem: 2500
Train: Epoch[4/5]  [2970/3750]  eta: 0:04:31  Lr: 0.001875  Loss: -0.9176  Acc@1: 81.2500 (82.9792)  Acc@5: 93.7500 (97.1853)  time: 0.3483  data: 0.0011  max mem: 2500
Train: Epoch[4/5]  [2980/3750]  eta: 0:04:27  Lr: 0.001875  Loss: -1.0263  Acc@1: 81.2500 (82.9776)  Acc@5: 100.0000 (97.1884)  time: 0.3473  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [2990/3750]  eta: 0:04:24  Lr: 0.001875  Loss: -0.9838  Acc@1: 81.2500 (82.9697)  Acc@5: 100.0000 (97.1916)  time: 0.3481  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [3000/3750]  eta: 0:04:20  Lr: 0.001875  Loss: -0.4484  Acc@1: 81.2500 (82.9557)  Acc@5: 100.0000 (97.1947)  time: 0.3484  data: 0.0013  max mem: 2500
Train: Epoch[4/5]  [3010/3750]  eta: 0:04:17  Lr: 0.001875  Loss: -0.3977  Acc@1: 75.0000 (82.9542)  Acc@5: 100.0000 (97.1957)  time: 0.3471  data: 0.0012  max mem: 2500
Train: Epoch[4/5]  [3020/3750]  eta: 0:04:13  Lr: 0.001875  Loss: -0.7169  Acc@1: 81.2500 (82.9485)  Acc@5: 100.0000 (97.1905)  time: 0.3478  data: 0.0014  max mem: 2500
Train: Epoch[4/5]  [3030/3750]  eta: 0:04:10  Lr: 0.001875  Loss: -0.9123  Acc@1: 81.2500 (82.9388)  Acc@5: 100.0000 (97.1956)  time: 0.3480  data: 0.0022  max mem: 2500
Train: Epoch[4/5]  [3040/3750]  eta: 0:04:07  Lr: 0.001875  Loss: -0.7292  Acc@1: 81.2500 (82.9435)  Acc@5: 100.0000 (97.1966)  time: 0.3472  data: 0.0013  max mem: 2500
Train: Epoch[4/5]  [3050/3750]  eta: 0:04:03  Lr: 0.001875  Loss: -0.0804  Acc@1: 87.5000 (82.9482)  Acc@5: 100.0000 (97.2017)  time: 0.3460  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [3060/3750]  eta: 0:04:00  Lr: 0.001875  Loss: -0.8742  Acc@1: 87.5000 (82.9692)  Acc@5: 100.0000 (97.2007)  time: 0.3473  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [3070/3750]  eta: 0:03:56  Lr: 0.001875  Loss: -0.7171  Acc@1: 87.5000 (82.9677)  Acc@5: 100.0000 (97.1976)  time: 0.3486  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [3080/3750]  eta: 0:03:53  Lr: 0.001875  Loss: -0.8907  Acc@1: 87.5000 (82.9783)  Acc@5: 100.0000 (97.2026)  time: 0.3470  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [3090/3750]  eta: 0:03:49  Lr: 0.001875  Loss: -0.9270  Acc@1: 87.5000 (82.9829)  Acc@5: 100.0000 (97.2056)  time: 0.3478  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [3100/3750]  eta: 0:03:46  Lr: 0.001875  Loss: -1.1102  Acc@1: 87.5000 (83.0015)  Acc@5: 100.0000 (97.2126)  time: 0.3486  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [3110/3750]  eta: 0:03:42  Lr: 0.001875  Loss: -0.1584  Acc@1: 87.5000 (83.0039)  Acc@5: 100.0000 (97.2155)  time: 0.3467  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [3120/3750]  eta: 0:03:39  Lr: 0.001875  Loss: -0.8737  Acc@1: 81.2500 (82.9982)  Acc@5: 100.0000 (97.2204)  time: 0.3462  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [3130/3750]  eta: 0:03:35  Lr: 0.001875  Loss: -0.8369  Acc@1: 81.2500 (82.9986)  Acc@5: 100.0000 (97.2253)  time: 0.3481  data: 0.0009  max mem: 2500
Train: Epoch[4/5]  [3140/3750]  eta: 0:03:32  Lr: 0.001875  Loss: -0.8112  Acc@1: 81.2500 (82.9851)  Acc@5: 100.0000 (97.2143)  time: 0.3477  data: 0.0009  max mem: 2500
Train: Epoch[4/5]  [3150/3750]  eta: 0:03:28  Lr: 0.001875  Loss: -0.7019  Acc@1: 81.2500 (82.9975)  Acc@5: 100.0000 (97.2132)  time: 0.3466  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [3160/3750]  eta: 0:03:25  Lr: 0.001875  Loss: -1.1109  Acc@1: 87.5000 (83.0018)  Acc@5: 100.0000 (97.2121)  time: 0.3468  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [3170/3750]  eta: 0:03:21  Lr: 0.001875  Loss: -0.5626  Acc@1: 81.2500 (82.9884)  Acc@5: 100.0000 (97.2071)  time: 0.3462  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3180/3750]  eta: 0:03:18  Lr: 0.001875  Loss: -0.8989  Acc@1: 87.5000 (83.0046)  Acc@5: 100.0000 (97.2100)  time: 0.3463  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3190/3750]  eta: 0:03:14  Lr: 0.001875  Loss: -1.2023  Acc@1: 87.5000 (83.0128)  Acc@5: 100.0000 (97.2129)  time: 0.3462  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [3200/3750]  eta: 0:03:11  Lr: 0.001875  Loss: -0.7479  Acc@1: 87.5000 (83.0170)  Acc@5: 100.0000 (97.2099)  time: 0.3475  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [3210/3750]  eta: 0:03:07  Lr: 0.001875  Loss: -0.9059  Acc@1: 87.5000 (83.0349)  Acc@5: 100.0000 (97.2127)  time: 0.3488  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [3220/3750]  eta: 0:03:04  Lr: 0.001875  Loss: -0.6532  Acc@1: 81.2500 (83.0235)  Acc@5: 100.0000 (97.2058)  time: 0.3483  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [3230/3750]  eta: 0:03:00  Lr: 0.001875  Loss: -0.7236  Acc@1: 81.2500 (83.0296)  Acc@5: 100.0000 (97.2106)  time: 0.3481  data: 0.0012  max mem: 2500
Train: Epoch[4/5]  [3240/3750]  eta: 0:02:57  Lr: 0.001875  Loss: -0.9485  Acc@1: 81.2500 (83.0106)  Acc@5: 100.0000 (97.2115)  time: 0.3479  data: 0.0009  max mem: 2500
Train: Epoch[4/5]  [3250/3750]  eta: 0:02:53  Lr: 0.001875  Loss: -0.8745  Acc@1: 81.2500 (83.0168)  Acc@5: 100.0000 (97.2124)  time: 0.3467  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [3260/3750]  eta: 0:02:50  Lr: 0.001875  Loss: -0.7469  Acc@1: 87.5000 (83.0228)  Acc@5: 100.0000 (97.2152)  time: 0.3452  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3270/3750]  eta: 0:02:46  Lr: 0.001875  Loss: -0.2941  Acc@1: 81.2500 (83.0136)  Acc@5: 100.0000 (97.2199)  time: 0.3468  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [3280/3750]  eta: 0:02:43  Lr: 0.001875  Loss: -1.1068  Acc@1: 87.5000 (83.0235)  Acc@5: 100.0000 (97.2207)  time: 0.3477  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [3290/3750]  eta: 0:02:40  Lr: 0.001875  Loss: -0.7600  Acc@1: 87.5000 (83.0105)  Acc@5: 100.0000 (97.2216)  time: 0.3475  data: 0.0011  max mem: 2500
Train: Epoch[4/5]  [3300/3750]  eta: 0:02:36  Lr: 0.001875  Loss: -1.2835  Acc@1: 81.2500 (83.0070)  Acc@5: 100.0000 (97.2186)  time: 0.3505  data: 0.0024  max mem: 2500
Train: Epoch[4/5]  [3310/3750]  eta: 0:02:33  Lr: 0.001875  Loss: -1.1082  Acc@1: 81.2500 (83.0055)  Acc@5: 100.0000 (97.2157)  time: 0.3500  data: 0.0027  max mem: 2500
Train: Epoch[4/5]  [3320/3750]  eta: 0:02:29  Lr: 0.001875  Loss: -0.9326  Acc@1: 87.5000 (83.0190)  Acc@5: 100.0000 (97.2185)  time: 0.3483  data: 0.0014  max mem: 2500
Train: Epoch[4/5]  [3330/3750]  eta: 0:02:26  Lr: 0.001875  Loss: -1.1982  Acc@1: 81.2500 (83.0137)  Acc@5: 93.7500 (97.2080)  time: 0.3476  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [3340/3750]  eta: 0:02:22  Lr: 0.001875  Loss: -0.4641  Acc@1: 81.2500 (82.9935)  Acc@5: 93.7500 (97.2052)  time: 0.3466  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [3350/3750]  eta: 0:02:19  Lr: 0.001875  Loss: -1.2380  Acc@1: 81.2500 (83.0032)  Acc@5: 100.0000 (97.2079)  time: 0.3472  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [3360/3750]  eta: 0:02:15  Lr: 0.001875  Loss: -1.2770  Acc@1: 87.5000 (83.0110)  Acc@5: 100.0000 (97.2032)  time: 0.3476  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [3370/3750]  eta: 0:02:12  Lr: 0.001875  Loss: -1.1625  Acc@1: 87.5000 (83.0113)  Acc@5: 100.0000 (97.2078)  time: 0.3469  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [3380/3750]  eta: 0:02:08  Lr: 0.001875  Loss: -0.7672  Acc@1: 81.2500 (83.0098)  Acc@5: 100.0000 (97.2068)  time: 0.3463  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [3390/3750]  eta: 0:02:05  Lr: 0.001875  Loss: -1.0240  Acc@1: 81.2500 (83.0046)  Acc@5: 100.0000 (97.2058)  time: 0.3475  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [3400/3750]  eta: 0:02:01  Lr: 0.001875  Loss: -0.9328  Acc@1: 87.5000 (83.0142)  Acc@5: 100.0000 (97.2049)  time: 0.3479  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [3410/3750]  eta: 0:01:58  Lr: 0.001875  Loss: -0.5420  Acc@1: 81.2500 (82.9907)  Acc@5: 100.0000 (97.2076)  time: 0.3470  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [3420/3750]  eta: 0:01:54  Lr: 0.001875  Loss: -0.9906  Acc@1: 75.0000 (82.9783)  Acc@5: 100.0000 (97.2029)  time: 0.3454  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [3430/3750]  eta: 0:01:51  Lr: 0.001875  Loss: -0.7816  Acc@1: 81.2500 (82.9696)  Acc@5: 93.7500 (97.1983)  time: 0.3467  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [3440/3750]  eta: 0:01:47  Lr: 0.001875  Loss: -1.2638  Acc@1: 81.2500 (82.9828)  Acc@5: 93.7500 (97.2010)  time: 0.3500  data: 0.0016  max mem: 2500
Train: Epoch[4/5]  [3450/3750]  eta: 0:01:44  Lr: 0.001875  Loss: -0.5267  Acc@1: 87.5000 (82.9868)  Acc@5: 100.0000 (97.2055)  time: 0.3483  data: 0.0015  max mem: 2500
Train: Epoch[4/5]  [3460/3750]  eta: 0:01:40  Lr: 0.001875  Loss: -1.1972  Acc@1: 81.2500 (82.9854)  Acc@5: 100.0000 (97.2010)  time: 0.3479  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [3470/3750]  eta: 0:01:37  Lr: 0.001875  Loss: -0.9653  Acc@1: 81.2500 (82.9858)  Acc@5: 100.0000 (97.2054)  time: 0.3481  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [3480/3750]  eta: 0:01:33  Lr: 0.001875  Loss: -1.0933  Acc@1: 81.2500 (82.9736)  Acc@5: 100.0000 (97.2009)  time: 0.3464  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3490/3750]  eta: 0:01:30  Lr: 0.001875  Loss: -0.7741  Acc@1: 81.2500 (82.9812)  Acc@5: 100.0000 (97.2071)  time: 0.3484  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [3500/3750]  eta: 0:01:26  Lr: 0.001875  Loss: -1.0983  Acc@1: 87.5000 (82.9781)  Acc@5: 100.0000 (97.2062)  time: 0.3480  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [3510/3750]  eta: 0:01:23  Lr: 0.001875  Loss: -0.6532  Acc@1: 81.2500 (82.9749)  Acc@5: 93.7500 (97.1999)  time: 0.3469  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [3520/3750]  eta: 0:01:20  Lr: 0.001875  Loss: -0.8798  Acc@1: 81.2500 (82.9754)  Acc@5: 100.0000 (97.2043)  time: 0.3474  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [3530/3750]  eta: 0:01:16  Lr: 0.001875  Loss: -0.5788  Acc@1: 87.5000 (82.9882)  Acc@5: 100.0000 (97.2051)  time: 0.3481  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [3540/3750]  eta: 0:01:13  Lr: 0.001875  Loss: -1.1494  Acc@1: 81.2500 (82.9744)  Acc@5: 100.0000 (97.2024)  time: 0.3482  data: 0.0012  max mem: 2500
Train: Epoch[4/5]  [3550/3750]  eta: 0:01:09  Lr: 0.001875  Loss: -0.3463  Acc@1: 81.2500 (82.9713)  Acc@5: 100.0000 (97.2015)  time: 0.3475  data: 0.0017  max mem: 2500
Train: Epoch[4/5]  [3560/3750]  eta: 0:01:06  Lr: 0.001875  Loss: -0.5700  Acc@1: 81.2500 (82.9665)  Acc@5: 93.7500 (97.2006)  time: 0.3480  data: 0.0012  max mem: 2500
Train: Epoch[4/5]  [3570/3750]  eta: 0:01:02  Lr: 0.001875  Loss: -1.3616  Acc@1: 81.2500 (82.9687)  Acc@5: 93.7500 (97.1979)  time: 0.3483  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [3580/3750]  eta: 0:00:59  Lr: 0.001875  Loss: -1.0549  Acc@1: 81.2500 (82.9674)  Acc@5: 93.7500 (97.1970)  time: 0.3469  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [3590/3750]  eta: 0:00:55  Lr: 0.001875  Loss: -0.8015  Acc@1: 81.2500 (82.9765)  Acc@5: 100.0000 (97.2031)  time: 0.3471  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [3600/3750]  eta: 0:00:52  Lr: 0.001875  Loss: -0.6668  Acc@1: 81.2500 (82.9752)  Acc@5: 100.0000 (97.1987)  time: 0.3480  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [3610/3750]  eta: 0:00:48  Lr: 0.001875  Loss: -1.2976  Acc@1: 87.5000 (82.9843)  Acc@5: 100.0000 (97.2013)  time: 0.3473  data: 0.0010  max mem: 2500
Train: Epoch[4/5]  [3620/3750]  eta: 0:00:45  Lr: 0.001875  Loss: -0.9354  Acc@1: 87.5000 (82.9916)  Acc@5: 100.0000 (97.2073)  time: 0.3473  data: 0.0010  max mem: 2500
Train: Epoch[4/5]  [3630/3750]  eta: 0:00:41  Lr: 0.001875  Loss: -0.6199  Acc@1: 87.5000 (82.9954)  Acc@5: 100.0000 (97.2046)  time: 0.3491  data: 0.0009  max mem: 2500
Train: Epoch[4/5]  [3640/3750]  eta: 0:00:38  Lr: 0.001875  Loss: -0.9515  Acc@1: 87.5000 (82.9923)  Acc@5: 93.7500 (97.2020)  time: 0.3490  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [3650/3750]  eta: 0:00:34  Lr: 0.001875  Loss: -0.5882  Acc@1: 81.2500 (82.9875)  Acc@5: 93.7500 (97.1925)  time: 0.3477  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3660/3750]  eta: 0:00:31  Lr: 0.001875  Loss: -0.9998  Acc@1: 81.2500 (82.9811)  Acc@5: 93.7500 (97.1917)  time: 0.3480  data: 0.0010  max mem: 2500
Train: Epoch[4/5]  [3670/3750]  eta: 0:00:27  Lr: 0.001875  Loss: -1.1430  Acc@1: 81.2500 (82.9713)  Acc@5: 100.0000 (97.1874)  time: 0.3479  data: 0.0010  max mem: 2500
Train: Epoch[4/5]  [3680/3750]  eta: 0:00:24  Lr: 0.001875  Loss: -0.7621  Acc@1: 81.2500 (82.9734)  Acc@5: 100.0000 (97.1832)  time: 0.3467  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [3690/3750]  eta: 0:00:20  Lr: 0.001875  Loss: -0.6482  Acc@1: 81.2500 (82.9619)  Acc@5: 100.0000 (97.1789)  time: 0.3475  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [3700/3750]  eta: 0:00:17  Lr: 0.001875  Loss: -0.5062  Acc@1: 81.2500 (82.9658)  Acc@5: 100.0000 (97.1798)  time: 0.3488  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [3710/3750]  eta: 0:00:13  Lr: 0.001875  Loss: -0.2425  Acc@1: 81.2500 (82.9780)  Acc@5: 100.0000 (97.1756)  time: 0.3475  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [3720/3750]  eta: 0:00:10  Lr: 0.001875  Loss: -1.2286  Acc@1: 87.5000 (82.9817)  Acc@5: 100.0000 (97.1731)  time: 0.3477  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [3730/3750]  eta: 0:00:06  Lr: 0.001875  Loss: -0.9340  Acc@1: 87.5000 (82.9972)  Acc@5: 100.0000 (97.1774)  time: 0.3518  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [3740/3750]  eta: 0:00:03  Lr: 0.001875  Loss: -1.1682  Acc@1: 81.2500 (82.9892)  Acc@5: 100.0000 (97.1732)  time: 0.3520  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [3749/3750]  eta: 0:00:00  Lr: 0.001875  Loss: -0.9338  Acc@1: 81.2500 (82.9883)  Acc@5: 93.7500 (97.1717)  time: 0.3482  data: 0.0011  max mem: 2500
Train: Epoch[4/5] Total time: 0:21:45 (0.3482 s / it)
{0: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 1: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 2: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 3: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 4: {0: 0, 1: 240000, 2: 0, 3: 0, 4: 0}, 5: {0: 0, 1: 240000, 2: 0, 3: 0, 4: 0}, 6: {0: 0, 1: 240000, 2: 0, 3: 0, 4: 0}, 7: {0: 0, 1: 240000, 2: 0, 3: 0, 4: 0}, 8: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 9: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 10: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 11: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 12: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 13: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 14: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 15: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 16: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 17: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 18: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 19: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}}
Averaged stats: Lr: 0.001875  Loss: -0.9338  Acc@1: 81.2500 (82.9883)  Acc@5: 93.7500 (97.1717)
Train: Epoch[5/5]  [   0/3750]  eta: 1:02:53  Lr: 0.001875  Loss: -0.9183  Acc@1: 81.2500 (81.2500)  Acc@5: 100.0000 (100.0000)  time: 1.0063  data: 0.6552  max mem: 2500
Train: Epoch[5/5]  [  10/3750]  eta: 0:25:36  Lr: 0.001875  Loss: -0.9592  Acc@1: 81.2500 (80.6818)  Acc@5: 100.0000 (97.1591)  time: 0.4109  data: 0.0599  max mem: 2500
Train: Epoch[5/5]  [  20/3750]  eta: 0:23:37  Lr: 0.001875  Loss: -1.1345  Acc@1: 81.2500 (82.7381)  Acc@5: 100.0000 (97.6190)  time: 0.3486  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [  30/3750]  eta: 0:22:54  Lr: 0.001875  Loss: -1.0496  Acc@1: 87.5000 (82.2581)  Acc@5: 100.0000 (96.9758)  time: 0.3465  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [  40/3750]  eta: 0:22:32  Lr: 0.001875  Loss: -1.0524  Acc@1: 81.2500 (82.9268)  Acc@5: 100.0000 (97.1037)  time: 0.3486  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [  50/3750]  eta: 0:22:16  Lr: 0.001875  Loss: -0.7360  Acc@1: 81.2500 (81.9853)  Acc@5: 100.0000 (97.0588)  time: 0.3489  data: 0.0013  max mem: 2500
Train: Epoch[5/5]  [  60/3750]  eta: 0:22:04  Lr: 0.001875  Loss: -0.8941  Acc@1: 81.2500 (82.3770)  Acc@5: 100.0000 (97.0287)  time: 0.3472  data: 0.0013  max mem: 2500
Train: Epoch[5/5]  [  70/3750]  eta: 0:21:57  Lr: 0.001875  Loss: -1.1590  Acc@1: 81.2500 (82.7465)  Acc@5: 100.0000 (97.2711)  time: 0.3491  data: 0.0017  max mem: 2500
Train: Epoch[5/5]  [  80/3750]  eta: 0:21:51  Lr: 0.001875  Loss: -1.3314  Acc@1: 81.2500 (83.0247)  Acc@5: 100.0000 (97.5309)  time: 0.3524  data: 0.0031  max mem: 2500
Train: Epoch[5/5]  [  90/3750]  eta: 0:21:42  Lr: 0.001875  Loss: -0.7525  Acc@1: 81.2500 (82.8297)  Acc@5: 100.0000 (97.5275)  time: 0.3491  data: 0.0019  max mem: 2500
Train: Epoch[5/5]  [ 100/3750]  eta: 0:21:36  Lr: 0.001875  Loss: -1.0810  Acc@1: 81.2500 (83.2921)  Acc@5: 100.0000 (97.4629)  time: 0.3462  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [ 110/3750]  eta: 0:21:30  Lr: 0.001875  Loss: -0.7822  Acc@1: 81.2500 (83.1644)  Acc@5: 93.7500 (97.2973)  time: 0.3477  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [ 120/3750]  eta: 0:21:24  Lr: 0.001875  Loss: -1.1009  Acc@1: 81.2500 (83.0062)  Acc@5: 100.0000 (97.3657)  time: 0.3470  data: 0.0010  max mem: 2500
Train: Epoch[5/5]  [ 130/3750]  eta: 0:21:19  Lr: 0.001875  Loss: -0.8199  Acc@1: 81.2500 (82.9676)  Acc@5: 93.7500 (97.0897)  time: 0.3481  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [ 140/3750]  eta: 0:21:14  Lr: 0.001875  Loss: -1.3466  Acc@1: 87.5000 (83.4220)  Acc@5: 93.7500 (97.1631)  time: 0.3495  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [ 150/3750]  eta: 0:21:09  Lr: 0.001875  Loss: -1.1078  Acc@1: 87.5000 (83.3195)  Acc@5: 100.0000 (97.2682)  time: 0.3479  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [ 160/3750]  eta: 0:21:04  Lr: 0.001875  Loss: -1.4805  Acc@1: 87.5000 (83.5404)  Acc@5: 100.0000 (97.3214)  time: 0.3462  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [ 170/3750]  eta: 0:21:00  Lr: 0.001875  Loss: -0.9220  Acc@1: 87.5000 (83.4795)  Acc@5: 100.0000 (97.3684)  time: 0.3469  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [ 180/3750]  eta: 0:20:56  Lr: 0.001875  Loss: -1.0722  Acc@1: 81.2500 (83.2873)  Acc@5: 100.0000 (97.2721)  time: 0.3481  data: 0.0015  max mem: 2500
Train: Epoch[5/5]  [ 190/3750]  eta: 0:20:51  Lr: 0.001875  Loss: -1.0773  Acc@1: 81.2500 (83.2461)  Acc@5: 100.0000 (97.3168)  time: 0.3481  data: 0.0016  max mem: 2500
Train: Epoch[5/5]  [ 200/3750]  eta: 0:20:47  Lr: 0.001875  Loss: -0.6873  Acc@1: 81.2500 (83.0224)  Acc@5: 100.0000 (97.2948)  time: 0.3469  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [ 210/3750]  eta: 0:20:42  Lr: 0.001875  Loss: -0.7342  Acc@1: 81.2500 (83.0569)  Acc@5: 100.0000 (97.2453)  time: 0.3456  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [ 220/3750]  eta: 0:20:38  Lr: 0.001875  Loss: -0.8020  Acc@1: 81.2500 (82.8620)  Acc@5: 93.7500 (97.1437)  time: 0.3459  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [ 230/3750]  eta: 0:20:34  Lr: 0.001875  Loss: -1.1231  Acc@1: 81.2500 (82.8734)  Acc@5: 93.7500 (97.1591)  time: 0.3465  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [ 240/3750]  eta: 0:20:30  Lr: 0.001875  Loss: -0.7172  Acc@1: 81.2500 (82.7282)  Acc@5: 100.0000 (97.0954)  time: 0.3476  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [ 250/3750]  eta: 0:20:26  Lr: 0.001875  Loss: -0.6420  Acc@1: 81.2500 (82.8436)  Acc@5: 100.0000 (97.1365)  time: 0.3478  data: 0.0010  max mem: 2500
Train: Epoch[5/5]  [ 260/3750]  eta: 0:20:22  Lr: 0.001875  Loss: -1.1470  Acc@1: 81.2500 (82.9262)  Acc@5: 100.0000 (97.1743)  time: 0.3476  data: 0.0010  max mem: 2500
Train: Epoch[5/5]  [ 270/3750]  eta: 0:20:18  Lr: 0.001875  Loss: -0.9582  Acc@1: 81.2500 (82.9336)  Acc@5: 100.0000 (97.1633)  time: 0.3468  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [ 280/3750]  eta: 0:20:15  Lr: 0.001875  Loss: -0.7333  Acc@1: 81.2500 (82.8292)  Acc@5: 100.0000 (97.1753)  time: 0.3502  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [ 290/3750]  eta: 0:20:11  Lr: 0.001875  Loss: -0.9118  Acc@1: 81.2500 (82.7964)  Acc@5: 100.0000 (97.1649)  time: 0.3512  data: 0.0015  max mem: 2500
Train: Epoch[5/5]  [ 300/3750]  eta: 0:20:08  Lr: 0.001875  Loss: -0.6949  Acc@1: 81.2500 (82.7658)  Acc@5: 93.7500 (97.1138)  time: 0.3478  data: 0.0012  max mem: 2500
Train: Epoch[5/5]  [ 310/3750]  eta: 0:20:04  Lr: 0.001875  Loss: -1.0892  Acc@1: 81.2500 (82.7773)  Acc@5: 93.7500 (97.1262)  time: 0.3468  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [ 320/3750]  eta: 0:20:00  Lr: 0.001875  Loss: -0.9311  Acc@1: 81.2500 (82.7492)  Acc@5: 100.0000 (97.1184)  time: 0.3462  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [ 330/3750]  eta: 0:19:56  Lr: 0.001875  Loss: -0.7417  Acc@1: 87.5000 (82.8172)  Acc@5: 100.0000 (97.1299)  time: 0.3470  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [ 340/3750]  eta: 0:19:52  Lr: 0.001875  Loss: -1.0928  Acc@1: 87.5000 (82.7529)  Acc@5: 100.0000 (97.1774)  time: 0.3471  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [ 350/3750]  eta: 0:19:48  Lr: 0.001875  Loss: -0.9165  Acc@1: 81.2500 (82.7635)  Acc@5: 100.0000 (97.1154)  time: 0.3468  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [ 360/3750]  eta: 0:19:45  Lr: 0.001875  Loss: -0.9354  Acc@1: 81.2500 (82.7735)  Acc@5: 93.7500 (97.1260)  time: 0.3480  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [ 370/3750]  eta: 0:19:42  Lr: 0.001875  Loss: -0.5066  Acc@1: 81.2500 (82.7325)  Acc@5: 100.0000 (97.1361)  time: 0.3502  data: 0.0012  max mem: 2500
Train: Epoch[5/5]  [ 380/3750]  eta: 0:19:38  Lr: 0.001875  Loss: -0.5075  Acc@1: 81.2500 (82.8084)  Acc@5: 100.0000 (97.1129)  time: 0.3494  data: 0.0017  max mem: 2500
Train: Epoch[5/5]  [ 390/3750]  eta: 0:19:34  Lr: 0.001875  Loss: -0.3310  Acc@1: 87.5000 (82.7366)  Acc@5: 100.0000 (97.1068)  time: 0.3488  data: 0.0015  max mem: 2500
Train: Epoch[5/5]  [ 400/3750]  eta: 0:19:31  Lr: 0.001875  Loss: -1.2011  Acc@1: 81.2500 (82.8086)  Acc@5: 100.0000 (97.1010)  time: 0.3490  data: 0.0011  max mem: 2500
Train: Epoch[5/5]  [ 410/3750]  eta: 0:19:27  Lr: 0.001875  Loss: -1.0295  Acc@1: 87.5000 (82.8771)  Acc@5: 100.0000 (97.1259)  time: 0.3485  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [ 420/3750]  eta: 0:19:24  Lr: 0.001875  Loss: -0.7735  Acc@1: 87.5000 (83.0166)  Acc@5: 100.0000 (97.1942)  time: 0.3488  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [ 430/3750]  eta: 0:19:20  Lr: 0.001875  Loss: -0.8394  Acc@1: 87.5000 (82.9901)  Acc@5: 100.0000 (97.2303)  time: 0.3470  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [ 440/3750]  eta: 0:19:16  Lr: 0.001875  Loss: -0.9877  Acc@1: 81.2500 (82.9223)  Acc@5: 100.0000 (97.1797)  time: 0.3453  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 450/3750]  eta: 0:19:12  Lr: 0.001875  Loss: -0.9266  Acc@1: 81.2500 (82.9268)  Acc@5: 93.7500 (97.1452)  time: 0.3464  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [ 460/3750]  eta: 0:19:09  Lr: 0.001875  Loss: -0.8691  Acc@1: 81.2500 (82.9176)  Acc@5: 100.0000 (97.1800)  time: 0.3489  data: 0.0010  max mem: 2500
Train: Epoch[5/5]  [ 470/3750]  eta: 0:19:05  Lr: 0.001875  Loss: -0.6813  Acc@1: 81.2500 (82.9618)  Acc@5: 100.0000 (97.1470)  time: 0.3478  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [ 480/3750]  eta: 0:19:02  Lr: 0.001875  Loss: -1.0511  Acc@1: 87.5000 (83.0431)  Acc@5: 100.0000 (97.1674)  time: 0.3472  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [ 490/3750]  eta: 0:18:58  Lr: 0.001875  Loss: -0.6333  Acc@1: 87.5000 (83.1085)  Acc@5: 100.0000 (97.1996)  time: 0.3493  data: 0.0016  max mem: 2500
Train: Epoch[5/5]  [ 500/3750]  eta: 0:18:55  Lr: 0.001875  Loss: -0.5525  Acc@1: 81.2500 (82.9965)  Acc@5: 100.0000 (97.2305)  time: 0.3486  data: 0.0015  max mem: 2500
Train: Epoch[5/5]  [ 510/3750]  eta: 0:18:51  Lr: 0.001875  Loss: -0.9324  Acc@1: 81.2500 (83.0846)  Acc@5: 100.0000 (97.2480)  time: 0.3474  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [ 520/3750]  eta: 0:18:47  Lr: 0.001875  Loss: -1.5151  Acc@1: 87.5000 (83.1334)  Acc@5: 100.0000 (97.2409)  time: 0.3463  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [ 530/3750]  eta: 0:18:44  Lr: 0.001875  Loss: -0.7732  Acc@1: 81.2500 (83.1921)  Acc@5: 100.0000 (97.2575)  time: 0.3473  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [ 540/3750]  eta: 0:18:40  Lr: 0.001875  Loss: -1.2538  Acc@1: 81.2500 (83.1446)  Acc@5: 100.0000 (97.2620)  time: 0.3479  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [ 550/3750]  eta: 0:18:37  Lr: 0.001875  Loss: -0.8100  Acc@1: 75.0000 (83.0309)  Acc@5: 93.7500 (97.1756)  time: 0.3480  data: 0.0016  max mem: 2500
Train: Epoch[5/5]  [ 560/3750]  eta: 0:18:33  Lr: 0.001875  Loss: -1.2938  Acc@1: 81.2500 (83.0102)  Acc@5: 93.7500 (97.1814)  time: 0.3481  data: 0.0016  max mem: 2500
Train: Epoch[5/5]  [ 570/3750]  eta: 0:18:29  Lr: 0.001875  Loss: -0.4701  Acc@1: 81.2500 (82.9685)  Acc@5: 100.0000 (97.1651)  time: 0.3470  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [ 580/3750]  eta: 0:18:26  Lr: 0.001875  Loss: -0.9948  Acc@1: 81.2500 (82.9712)  Acc@5: 100.0000 (97.1493)  time: 0.3477  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [ 590/3750]  eta: 0:18:22  Lr: 0.001875  Loss: -0.8037  Acc@1: 81.2500 (83.0478)  Acc@5: 100.0000 (97.1235)  time: 0.3486  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [ 600/3750]  eta: 0:18:19  Lr: 0.001875  Loss: -1.0139  Acc@1: 81.2500 (82.9971)  Acc@5: 100.0000 (97.1610)  time: 0.3482  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 610/3750]  eta: 0:18:15  Lr: 0.001875  Loss: -0.7315  Acc@1: 81.2500 (83.0196)  Acc@5: 100.0000 (97.1768)  time: 0.3477  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 620/3750]  eta: 0:18:12  Lr: 0.001875  Loss: -0.9833  Acc@1: 87.5000 (83.0616)  Acc@5: 100.0000 (97.2021)  time: 0.3484  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [ 630/3750]  eta: 0:18:08  Lr: 0.001875  Loss: -0.8787  Acc@1: 81.2500 (83.0329)  Acc@5: 100.0000 (97.1771)  time: 0.3471  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [ 640/3750]  eta: 0:18:04  Lr: 0.001875  Loss: -1.0873  Acc@1: 81.2500 (83.0733)  Acc@5: 93.7500 (97.1724)  time: 0.3455  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [ 650/3750]  eta: 0:18:01  Lr: 0.001875  Loss: -0.6476  Acc@1: 87.5000 (83.0741)  Acc@5: 100.0000 (97.1774)  time: 0.3453  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [ 660/3750]  eta: 0:17:57  Lr: 0.001875  Loss: -0.9478  Acc@1: 81.2500 (83.1033)  Acc@5: 100.0000 (97.1823)  time: 0.3466  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [ 670/3750]  eta: 0:17:54  Lr: 0.001875  Loss: -1.2697  Acc@1: 81.2500 (83.1501)  Acc@5: 100.0000 (97.1870)  time: 0.3469  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [ 680/3750]  eta: 0:17:50  Lr: 0.001875  Loss: -1.0633  Acc@1: 81.2500 (83.1222)  Acc@5: 100.0000 (97.1457)  time: 0.3463  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [ 690/3750]  eta: 0:17:47  Lr: 0.001875  Loss: -1.0185  Acc@1: 87.5000 (83.1313)  Acc@5: 100.0000 (97.1690)  time: 0.3478  data: 0.0010  max mem: 2500
Train: Epoch[5/5]  [ 700/3750]  eta: 0:17:43  Lr: 0.001875  Loss: -1.0680  Acc@1: 81.2500 (83.1045)  Acc@5: 100.0000 (97.1291)  time: 0.3478  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [ 710/3750]  eta: 0:17:39  Lr: 0.001875  Loss: -0.6450  Acc@1: 81.2500 (83.1048)  Acc@5: 93.7500 (97.1255)  time: 0.3465  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [ 720/3750]  eta: 0:17:36  Lr: 0.001875  Loss: -1.1786  Acc@1: 87.5000 (83.1831)  Acc@5: 100.0000 (97.1481)  time: 0.3480  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [ 730/3750]  eta: 0:17:33  Lr: 0.001875  Loss: -1.3053  Acc@1: 87.5000 (83.2079)  Acc@5: 100.0000 (97.1358)  time: 0.3509  data: 0.0011  max mem: 2500
Train: Epoch[5/5]  [ 740/3750]  eta: 0:17:29  Lr: 0.001875  Loss: -0.7894  Acc@1: 81.2500 (83.1731)  Acc@5: 100.0000 (97.1238)  time: 0.3482  data: 0.0010  max mem: 2500
Train: Epoch[5/5]  [ 750/3750]  eta: 0:17:26  Lr: 0.001875  Loss: -0.7133  Acc@1: 81.2500 (83.1558)  Acc@5: 100.0000 (97.1372)  time: 0.3472  data: 0.0010  max mem: 2500
Train: Epoch[5/5]  [ 760/3750]  eta: 0:17:22  Lr: 0.001875  Loss: -0.8877  Acc@1: 81.2500 (83.2129)  Acc@5: 100.0000 (97.1748)  time: 0.3473  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [ 770/3750]  eta: 0:17:19  Lr: 0.001875  Loss: -1.1569  Acc@1: 87.5000 (83.2442)  Acc@5: 100.0000 (97.1952)  time: 0.3485  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [ 780/3750]  eta: 0:17:15  Lr: 0.001875  Loss: -0.9500  Acc@1: 87.5000 (83.2506)  Acc@5: 100.0000 (97.1751)  time: 0.3507  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [ 790/3750]  eta: 0:17:11  Lr: 0.001875  Loss: -0.9285  Acc@1: 87.5000 (83.2570)  Acc@5: 100.0000 (97.1950)  time: 0.3476  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [ 800/3750]  eta: 0:17:08  Lr: 0.001875  Loss: -1.1703  Acc@1: 81.2500 (83.1929)  Acc@5: 100.0000 (97.1832)  time: 0.3480  data: 0.0014  max mem: 2500
Train: Epoch[5/5]  [ 810/3750]  eta: 0:17:05  Lr: 0.001875  Loss: -0.6010  Acc@1: 81.2500 (83.1843)  Acc@5: 100.0000 (97.1871)  time: 0.3487  data: 0.0022  max mem: 2500
Train: Epoch[5/5]  [ 820/3750]  eta: 0:17:01  Lr: 0.001875  Loss: -0.7274  Acc@1: 87.5000 (83.1836)  Acc@5: 100.0000 (97.1985)  time: 0.3490  data: 0.0020  max mem: 2500
Train: Epoch[5/5]  [ 830/3750]  eta: 0:16:58  Lr: 0.001875  Loss: -0.8065  Acc@1: 81.2500 (83.1754)  Acc@5: 100.0000 (97.2022)  time: 0.3488  data: 0.0011  max mem: 2500
Train: Epoch[5/5]  [ 840/3750]  eta: 0:16:54  Lr: 0.001875  Loss: -1.0990  Acc@1: 81.2500 (83.1748)  Acc@5: 100.0000 (97.2057)  time: 0.3471  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [ 850/3750]  eta: 0:16:50  Lr: 0.001875  Loss: -1.3584  Acc@1: 87.5000 (83.2109)  Acc@5: 100.0000 (97.2239)  time: 0.3463  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [ 860/3750]  eta: 0:16:47  Lr: 0.001875  Loss: -0.9379  Acc@1: 87.5000 (83.2753)  Acc@5: 100.0000 (97.2416)  time: 0.3472  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [ 870/3750]  eta: 0:16:44  Lr: 0.001875  Loss: -1.1221  Acc@1: 87.5000 (83.3525)  Acc@5: 100.0000 (97.2302)  time: 0.3512  data: 0.0012  max mem: 2500
Train: Epoch[5/5]  [ 880/3750]  eta: 0:16:40  Lr: 0.001875  Loss: -0.6567  Acc@1: 81.2500 (83.3073)  Acc@5: 93.7500 (97.2049)  time: 0.3520  data: 0.0013  max mem: 2500
Train: Epoch[5/5]  [ 890/3750]  eta: 0:16:37  Lr: 0.001875  Loss: -0.9039  Acc@1: 81.2500 (83.3053)  Acc@5: 93.7500 (97.1871)  time: 0.3509  data: 0.0012  max mem: 2500
Train: Epoch[5/5]  [ 900/3750]  eta: 0:16:33  Lr: 0.001875  Loss: -1.1420  Acc@1: 81.2500 (83.2894)  Acc@5: 93.7500 (97.1421)  time: 0.3490  data: 0.0011  max mem: 2500
Train: Epoch[5/5]  [ 910/3750]  eta: 0:16:30  Lr: 0.001875  Loss: -0.2803  Acc@1: 81.2500 (83.2807)  Acc@5: 93.7500 (97.1048)  time: 0.3473  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [ 920/3750]  eta: 0:16:26  Lr: 0.001875  Loss: -1.1822  Acc@1: 81.2500 (83.2587)  Acc@5: 93.7500 (97.0955)  time: 0.3491  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [ 930/3750]  eta: 0:16:23  Lr: 0.001875  Loss: -1.1849  Acc@1: 81.2500 (83.3110)  Acc@5: 100.0000 (97.0999)  time: 0.3479  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [ 940/3750]  eta: 0:16:19  Lr: 0.001875  Loss: -1.0341  Acc@1: 87.5000 (83.3156)  Acc@5: 100.0000 (97.1241)  time: 0.3470  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [ 950/3750]  eta: 0:16:16  Lr: 0.001875  Loss: -1.0387  Acc@1: 81.2500 (83.3070)  Acc@5: 100.0000 (97.1346)  time: 0.3484  data: 0.0011  max mem: 2500
Train: Epoch[5/5]  [ 960/3750]  eta: 0:16:12  Lr: 0.001875  Loss: -0.8125  Acc@1: 81.2500 (83.2726)  Acc@5: 100.0000 (97.1254)  time: 0.3476  data: 0.0011  max mem: 2500
Train: Epoch[5/5]  [ 970/3750]  eta: 0:16:09  Lr: 0.001875  Loss: -0.5246  Acc@1: 75.0000 (83.2067)  Acc@5: 93.7500 (97.1035)  time: 0.3485  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [ 980/3750]  eta: 0:16:06  Lr: 0.001875  Loss: -1.2657  Acc@1: 75.0000 (83.1868)  Acc@5: 93.7500 (97.0948)  time: 0.3552  data: 0.0027  max mem: 2500
Train: Epoch[5/5]  [ 990/3750]  eta: 0:16:02  Lr: 0.001875  Loss: -0.5589  Acc@1: 81.2500 (83.1799)  Acc@5: 100.0000 (97.0926)  time: 0.3549  data: 0.0026  max mem: 2500
Train: Epoch[5/5]  [1000/3750]  eta: 0:15:59  Lr: 0.001875  Loss: -1.1735  Acc@1: 81.2500 (83.2355)  Acc@5: 100.0000 (97.0904)  time: 0.3483  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [1010/3750]  eta: 0:15:55  Lr: 0.001875  Loss: -0.6919  Acc@1: 87.5000 (83.2097)  Acc@5: 93.7500 (97.0697)  time: 0.3481  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [1020/3750]  eta: 0:15:52  Lr: 0.001875  Loss: -1.0033  Acc@1: 87.5000 (83.2333)  Acc@5: 93.7500 (97.0617)  time: 0.3480  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [1030/3750]  eta: 0:15:48  Lr: 0.001875  Loss: -0.8888  Acc@1: 81.2500 (83.2020)  Acc@5: 100.0000 (97.0781)  time: 0.3463  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [1040/3750]  eta: 0:15:44  Lr: 0.001875  Loss: -0.6641  Acc@1: 75.0000 (83.1112)  Acc@5: 100.0000 (97.0641)  time: 0.3470  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [1050/3750]  eta: 0:15:41  Lr: 0.001875  Loss: -1.0471  Acc@1: 75.0000 (83.0875)  Acc@5: 93.7500 (97.0683)  time: 0.3476  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [1060/3750]  eta: 0:15:37  Lr: 0.001875  Loss: -1.0875  Acc@1: 81.2500 (83.0761)  Acc@5: 100.0000 (97.0900)  time: 0.3468  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [1070/3750]  eta: 0:15:34  Lr: 0.001875  Loss: -0.5201  Acc@1: 81.2500 (83.0999)  Acc@5: 100.0000 (97.0822)  time: 0.3459  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [1080/3750]  eta: 0:15:30  Lr: 0.001875  Loss: -1.3534  Acc@1: 87.5000 (83.1406)  Acc@5: 100.0000 (97.0802)  time: 0.3450  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [1090/3750]  eta: 0:15:27  Lr: 0.001875  Loss: -0.7323  Acc@1: 81.2500 (83.0946)  Acc@5: 100.0000 (97.0841)  time: 0.3464  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [1100/3750]  eta: 0:15:23  Lr: 0.001875  Loss: -0.7532  Acc@1: 81.2500 (83.0892)  Acc@5: 100.0000 (97.0992)  time: 0.3467  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [1110/3750]  eta: 0:15:20  Lr: 0.001875  Loss: -0.9618  Acc@1: 81.2500 (83.0671)  Acc@5: 100.0000 (97.0916)  time: 0.3470  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [1120/3750]  eta: 0:15:16  Lr: 0.001875  Loss: -0.3448  Acc@1: 81.2500 (83.0676)  Acc@5: 100.0000 (97.0897)  time: 0.3468  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [1130/3750]  eta: 0:15:13  Lr: 0.001875  Loss: -0.9996  Acc@1: 81.2500 (83.0515)  Acc@5: 100.0000 (97.0878)  time: 0.3454  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [1140/3750]  eta: 0:15:09  Lr: 0.001875  Loss: -0.3519  Acc@1: 81.2500 (83.0631)  Acc@5: 100.0000 (97.0859)  time: 0.3478  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [1150/3750]  eta: 0:15:06  Lr: 0.001875  Loss: -1.0232  Acc@1: 87.5000 (83.0854)  Acc@5: 100.0000 (97.1003)  time: 0.3476  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [1160/3750]  eta: 0:15:02  Lr: 0.001875  Loss: -1.2720  Acc@1: 87.5000 (83.1019)  Acc@5: 100.0000 (97.0984)  time: 0.3471  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [1170/3750]  eta: 0:14:59  Lr: 0.001875  Loss: -1.0935  Acc@1: 87.5000 (83.1020)  Acc@5: 100.0000 (97.1072)  time: 0.3469  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [1180/3750]  eta: 0:14:55  Lr: 0.001875  Loss: -1.2350  Acc@1: 87.5000 (83.1446)  Acc@5: 100.0000 (97.1158)  time: 0.3467  data: 0.0011  max mem: 2500
Train: Epoch[5/5]  [1190/3750]  eta: 0:14:52  Lr: 0.001875  Loss: -0.8159  Acc@1: 81.2500 (83.0972)  Acc@5: 100.0000 (97.1138)  time: 0.3488  data: 0.0012  max mem: 2500
Train: Epoch[5/5]  [1200/3750]  eta: 0:14:48  Lr: 0.001875  Loss: -1.0080  Acc@1: 81.2500 (83.1182)  Acc@5: 100.0000 (97.1274)  time: 0.3475  data: 0.0014  max mem: 2500
Train: Epoch[5/5]  [1210/3750]  eta: 0:14:45  Lr: 0.001875  Loss: -0.7889  Acc@1: 81.2500 (83.1028)  Acc@5: 100.0000 (97.1150)  time: 0.3466  data: 0.0021  max mem: 2500
Train: Epoch[5/5]  [1220/3750]  eta: 0:14:41  Lr: 0.001875  Loss: -1.2269  Acc@1: 81.2500 (83.0774)  Acc@5: 100.0000 (97.1079)  time: 0.3464  data: 0.0012  max mem: 2500
Train: Epoch[5/5]  [1230/3750]  eta: 0:14:37  Lr: 0.001875  Loss: -1.0492  Acc@1: 87.5000 (83.1286)  Acc@5: 100.0000 (97.1212)  time: 0.3464  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [1240/3750]  eta: 0:14:34  Lr: 0.001875  Loss: -0.9194  Acc@1: 81.2500 (83.0882)  Acc@5: 100.0000 (97.1243)  time: 0.3472  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [1250/3750]  eta: 0:14:31  Lr: 0.001875  Loss: -1.2970  Acc@1: 81.2500 (83.1135)  Acc@5: 100.0000 (97.1223)  time: 0.3482  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [1260/3750]  eta: 0:14:27  Lr: 0.001875  Loss: -1.3863  Acc@1: 87.5000 (83.1285)  Acc@5: 100.0000 (97.1203)  time: 0.3480  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [1270/3750]  eta: 0:14:23  Lr: 0.001875  Loss: -0.6747  Acc@1: 87.5000 (83.1481)  Acc@5: 100.0000 (97.1037)  time: 0.3470  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [1280/3750]  eta: 0:14:20  Lr: 0.001875  Loss: -0.8580  Acc@1: 81.2500 (83.1626)  Acc@5: 100.0000 (97.1263)  time: 0.3482  data: 0.0012  max mem: 2500
Train: Epoch[5/5]  [1290/3750]  eta: 0:14:17  Lr: 0.001875  Loss: -1.1052  Acc@1: 81.2500 (83.1623)  Acc@5: 100.0000 (97.1195)  time: 0.3487  data: 0.0012  max mem: 2500
Train: Epoch[5/5]  [1300/3750]  eta: 0:14:13  Lr: 0.001875  Loss: -0.4475  Acc@1: 87.5000 (83.1524)  Acc@5: 100.0000 (97.1176)  time: 0.3467  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [1310/3750]  eta: 0:14:09  Lr: 0.001875  Loss: -0.8864  Acc@1: 87.5000 (83.1569)  Acc@5: 100.0000 (97.1253)  time: 0.3459  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [1320/3750]  eta: 0:14:06  Lr: 0.001875  Loss: -0.9190  Acc@1: 81.2500 (83.1709)  Acc@5: 100.0000 (97.1329)  time: 0.3476  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [1330/3750]  eta: 0:14:03  Lr: 0.001875  Loss: -1.1368  Acc@1: 87.5000 (83.1799)  Acc@5: 100.0000 (97.1403)  time: 0.3491  data: 0.0013  max mem: 2500
Train: Epoch[5/5]  [1340/3750]  eta: 0:13:59  Lr: 0.001875  Loss: -1.0867  Acc@1: 87.5000 (83.2168)  Acc@5: 100.0000 (97.1430)  time: 0.3485  data: 0.0011  max mem: 2500
Train: Epoch[5/5]  [1350/3750]  eta: 0:13:55  Lr: 0.001875  Loss: -1.1813  Acc@1: 87.5000 (83.2161)  Acc@5: 100.0000 (97.1456)  time: 0.3461  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [1360/3750]  eta: 0:13:52  Lr: 0.001875  Loss: -0.3761  Acc@1: 81.2500 (83.1925)  Acc@5: 100.0000 (97.1528)  time: 0.3456  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [1370/3750]  eta: 0:13:48  Lr: 0.001875  Loss: -0.9473  Acc@1: 81.2500 (83.2239)  Acc@5: 100.0000 (97.1645)  time: 0.3468  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [1380/3750]  eta: 0:13:45  Lr: 0.001875  Loss: -0.9270  Acc@1: 87.5000 (83.2051)  Acc@5: 100.0000 (97.1669)  time: 0.3494  data: 0.0016  max mem: 2500
Train: Epoch[5/5]  [1390/3750]  eta: 0:13:42  Lr: 0.001875  Loss: -1.1257  Acc@1: 81.2500 (83.2315)  Acc@5: 100.0000 (97.1828)  time: 0.3500  data: 0.0019  max mem: 2500
Train: Epoch[5/5]  [1400/3750]  eta: 0:13:38  Lr: 0.001875  Loss: -0.3830  Acc@1: 81.2500 (83.1817)  Acc@5: 100.0000 (97.1717)  time: 0.3483  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [1410/3750]  eta: 0:13:35  Lr: 0.001875  Loss: -1.0526  Acc@1: 81.2500 (83.1813)  Acc@5: 93.7500 (97.1696)  time: 0.3492  data: 0.0012  max mem: 2500
Train: Epoch[5/5]  [1420/3750]  eta: 0:13:31  Lr: 0.001875  Loss: -0.7549  Acc@1: 87.5000 (83.1897)  Acc@5: 100.0000 (97.1807)  time: 0.3487  data: 0.0019  max mem: 2500
Train: Epoch[5/5]  [1430/3750]  eta: 0:13:28  Lr: 0.001875  Loss: -1.2691  Acc@1: 87.5000 (83.1979)  Acc@5: 100.0000 (97.1873)  time: 0.3469  data: 0.0012  max mem: 2500
Train: Epoch[5/5]  [1440/3750]  eta: 0:13:24  Lr: 0.001875  Loss: -1.2762  Acc@1: 87.5000 (83.2191)  Acc@5: 100.0000 (97.1851)  time: 0.3463  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [1450/3750]  eta: 0:13:21  Lr: 0.001875  Loss: -1.1204  Acc@1: 87.5000 (83.2486)  Acc@5: 100.0000 (97.1916)  time: 0.3473  data: 0.0014  max mem: 2500
Train: Epoch[5/5]  [1460/3750]  eta: 0:13:17  Lr: 0.001875  Loss: -0.7555  Acc@1: 81.2500 (83.2478)  Acc@5: 100.0000 (97.1980)  time: 0.3484  data: 0.0013  max mem: 2500
Train: Epoch[5/5]  [1470/3750]  eta: 0:13:14  Lr: 0.001875  Loss: -1.4272  Acc@1: 81.2500 (83.2682)  Acc@5: 100.0000 (97.2043)  time: 0.3486  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [1480/3750]  eta: 0:13:10  Lr: 0.001875  Loss: -0.4820  Acc@1: 81.2500 (83.2630)  Acc@5: 100.0000 (97.1978)  time: 0.3469  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [1490/3750]  eta: 0:13:07  Lr: 0.001875  Loss: -0.9043  Acc@1: 75.0000 (83.2369)  Acc@5: 100.0000 (97.1915)  time: 0.3446  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [1500/3750]  eta: 0:13:03  Lr: 0.001875  Loss: -0.9833  Acc@1: 75.0000 (83.1987)  Acc@5: 100.0000 (97.1935)  time: 0.3474  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [1510/3750]  eta: 0:13:00  Lr: 0.001875  Loss: -0.6300  Acc@1: 81.2500 (83.1651)  Acc@5: 100.0000 (97.1832)  time: 0.3482  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [1520/3750]  eta: 0:12:56  Lr: 0.001875  Loss: -0.6251  Acc@1: 81.2500 (83.1197)  Acc@5: 93.7500 (97.1606)  time: 0.3465  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [1530/3750]  eta: 0:12:53  Lr: 0.001875  Loss: -0.4338  Acc@1: 81.2500 (83.1115)  Acc@5: 93.7500 (97.1587)  time: 0.3478  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [1540/3750]  eta: 0:12:49  Lr: 0.001875  Loss: -0.5741  Acc@1: 81.2500 (83.1116)  Acc@5: 100.0000 (97.1690)  time: 0.3485  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [1550/3750]  eta: 0:12:46  Lr: 0.001875  Loss: -0.2938  Acc@1: 81.2500 (83.1359)  Acc@5: 100.0000 (97.1510)  time: 0.3468  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [1560/3750]  eta: 0:12:42  Lr: 0.001875  Loss: -1.1165  Acc@1: 87.5000 (83.1438)  Acc@5: 100.0000 (97.1573)  time: 0.3465  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [1570/3750]  eta: 0:12:39  Lr: 0.001875  Loss: -0.5685  Acc@1: 87.5000 (83.1477)  Acc@5: 100.0000 (97.1475)  time: 0.3470  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [1580/3750]  eta: 0:12:35  Lr: 0.001875  Loss: -1.1399  Acc@1: 81.2500 (83.1475)  Acc@5: 100.0000 (97.1497)  time: 0.3478  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [1590/3750]  eta: 0:12:32  Lr: 0.001875  Loss: -1.2871  Acc@1: 81.2500 (83.1435)  Acc@5: 100.0000 (97.1441)  time: 0.3484  data: 0.0010  max mem: 2500
Train: Epoch[5/5]  [1600/3750]  eta: 0:12:28  Lr: 0.001875  Loss: -0.6658  Acc@1: 81.2500 (83.1160)  Acc@5: 93.7500 (97.1307)  time: 0.3462  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [1610/3750]  eta: 0:12:25  Lr: 0.001875  Loss: -0.9753  Acc@1: 81.2500 (83.1006)  Acc@5: 93.7500 (97.1252)  time: 0.3449  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [1620/3750]  eta: 0:12:21  Lr: 0.001875  Loss: -0.8975  Acc@1: 81.2500 (83.1084)  Acc@5: 100.0000 (97.1353)  time: 0.3471  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [1630/3750]  eta: 0:12:18  Lr: 0.001875  Loss: -0.7765  Acc@1: 81.2500 (83.0970)  Acc@5: 100.0000 (97.1528)  time: 0.3495  data: 0.0013  max mem: 2500
Train: Epoch[5/5]  [1640/3750]  eta: 0:12:14  Lr: 0.001875  Loss: -0.9501  Acc@1: 81.2500 (83.0972)  Acc@5: 100.0000 (97.1549)  time: 0.3473  data: 0.0013  max mem: 2500
Train: Epoch[5/5]  [1650/3750]  eta: 0:12:11  Lr: 0.001875  Loss: -1.1741  Acc@1: 81.2500 (83.1012)  Acc@5: 100.0000 (97.1532)  time: 0.3457  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [1660/3750]  eta: 0:12:07  Lr: 0.001875  Loss: -1.1135  Acc@1: 81.2500 (83.1088)  Acc@5: 100.0000 (97.1440)  time: 0.3467  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [1670/3750]  eta: 0:12:04  Lr: 0.001875  Loss: -0.9130  Acc@1: 81.2500 (83.0940)  Acc@5: 93.7500 (97.1312)  time: 0.3475  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [1680/3750]  eta: 0:12:00  Lr: 0.001875  Loss: -0.3165  Acc@1: 81.2500 (83.1164)  Acc@5: 100.0000 (97.1446)  time: 0.3484  data: 0.0010  max mem: 2500
Train: Epoch[5/5]  [1690/3750]  eta: 0:11:57  Lr: 0.001875  Loss: -0.2916  Acc@1: 87.5000 (83.1054)  Acc@5: 100.0000 (97.1430)  time: 0.3483  data: 0.0010  max mem: 2500
Train: Epoch[5/5]  [1700/3750]  eta: 0:11:53  Lr: 0.001875  Loss: -0.6400  Acc@1: 81.2500 (83.0982)  Acc@5: 100.0000 (97.1414)  time: 0.3461  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [1710/3750]  eta: 0:11:50  Lr: 0.001875  Loss: -1.0701  Acc@1: 87.5000 (83.1166)  Acc@5: 100.0000 (97.1435)  time: 0.3449  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [1720/3750]  eta: 0:11:46  Lr: 0.001875  Loss: -1.1314  Acc@1: 87.5000 (83.1312)  Acc@5: 100.0000 (97.1419)  time: 0.3456  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [1730/3750]  eta: 0:11:43  Lr: 0.001875  Loss: -0.7479  Acc@1: 87.5000 (83.1311)  Acc@5: 93.7500 (97.1259)  time: 0.3469  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [1740/3750]  eta: 0:11:39  Lr: 0.001875  Loss: -0.8579  Acc@1: 81.2500 (83.1132)  Acc@5: 93.7500 (97.1281)  time: 0.3468  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [1750/3750]  eta: 0:11:36  Lr: 0.001875  Loss: -1.0922  Acc@1: 81.2500 (83.1346)  Acc@5: 100.0000 (97.1338)  time: 0.3463  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [1760/3750]  eta: 0:11:32  Lr: 0.001875  Loss: -0.9850  Acc@1: 87.5000 (83.1310)  Acc@5: 100.0000 (97.1217)  time: 0.3477  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [1770/3750]  eta: 0:11:29  Lr: 0.001875  Loss: -0.8271  Acc@1: 81.2500 (83.1239)  Acc@5: 93.7500 (97.1132)  time: 0.3473  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [1780/3750]  eta: 0:11:25  Lr: 0.001875  Loss: -0.9096  Acc@1: 81.2500 (83.1275)  Acc@5: 100.0000 (97.1189)  time: 0.3484  data: 0.0011  max mem: 2500
Train: Epoch[5/5]  [1790/3750]  eta: 0:11:22  Lr: 0.001875  Loss: -0.7738  Acc@1: 87.5000 (83.1554)  Acc@5: 100.0000 (97.1210)  time: 0.3511  data: 0.0020  max mem: 2500
Train: Epoch[5/5]  [1800/3750]  eta: 0:11:18  Lr: 0.001875  Loss: -0.7748  Acc@1: 87.5000 (83.1621)  Acc@5: 100.0000 (97.1197)  time: 0.3481  data: 0.0014  max mem: 2500
Train: Epoch[5/5]  [1810/3750]  eta: 0:11:15  Lr: 0.001875  Loss: -0.1494  Acc@1: 87.5000 (83.1757)  Acc@5: 100.0000 (97.1218)  time: 0.3460  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [1820/3750]  eta: 0:11:11  Lr: 0.001875  Loss: -0.7972  Acc@1: 87.5000 (83.1755)  Acc@5: 100.0000 (97.1238)  time: 0.3473  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [1830/3750]  eta: 0:11:08  Lr: 0.001875  Loss: -1.1917  Acc@1: 87.5000 (83.1957)  Acc@5: 100.0000 (97.1293)  time: 0.3480  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [1840/3750]  eta: 0:11:04  Lr: 0.001875  Loss: -1.0898  Acc@1: 87.5000 (83.1851)  Acc@5: 100.0000 (97.1347)  time: 0.3475  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [1850/3750]  eta: 0:11:01  Lr: 0.001875  Loss: -0.5527  Acc@1: 81.2500 (83.1611)  Acc@5: 100.0000 (97.1299)  time: 0.3461  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [1860/3750]  eta: 0:10:57  Lr: 0.001875  Loss: -0.7385  Acc@1: 81.2500 (83.1408)  Acc@5: 93.7500 (97.1252)  time: 0.3467  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [1870/3750]  eta: 0:10:54  Lr: 0.001875  Loss: -0.9488  Acc@1: 75.0000 (83.1040)  Acc@5: 93.7500 (97.1138)  time: 0.3477  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [1880/3750]  eta: 0:10:50  Lr: 0.001875  Loss: -0.7352  Acc@1: 81.2500 (83.1041)  Acc@5: 100.0000 (97.1159)  time: 0.3470  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [1890/3750]  eta: 0:10:47  Lr: 0.001875  Loss: -0.9953  Acc@1: 87.5000 (83.1306)  Acc@5: 100.0000 (97.1113)  time: 0.3472  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [1900/3750]  eta: 0:10:43  Lr: 0.001875  Loss: -0.5040  Acc@1: 87.5000 (83.1207)  Acc@5: 100.0000 (97.1166)  time: 0.3470  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [1910/3750]  eta: 0:10:40  Lr: 0.001875  Loss: -0.7942  Acc@1: 81.2500 (83.1338)  Acc@5: 100.0000 (97.1154)  time: 0.3468  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [1920/3750]  eta: 0:10:36  Lr: 0.001875  Loss: -1.0953  Acc@1: 87.5000 (83.1435)  Acc@5: 100.0000 (97.1141)  time: 0.3474  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [1930/3750]  eta: 0:10:33  Lr: 0.001875  Loss: -0.9975  Acc@1: 81.2500 (83.1402)  Acc@5: 100.0000 (97.1226)  time: 0.3468  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [1940/3750]  eta: 0:10:29  Lr: 0.001875  Loss: -0.8874  Acc@1: 87.5000 (83.1562)  Acc@5: 100.0000 (97.1278)  time: 0.3469  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [1950/3750]  eta: 0:10:26  Lr: 0.001875  Loss: -1.1532  Acc@1: 87.5000 (83.1657)  Acc@5: 100.0000 (97.1361)  time: 0.3484  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [1960/3750]  eta: 0:10:22  Lr: 0.001875  Loss: -1.0388  Acc@1: 87.5000 (83.1687)  Acc@5: 100.0000 (97.1379)  time: 0.3481  data: 0.0010  max mem: 2500
Train: Epoch[5/5]  [1970/3750]  eta: 0:10:19  Lr: 0.001875  Loss: -0.8917  Acc@1: 87.5000 (83.1653)  Acc@5: 93.7500 (97.1239)  time: 0.3486  data: 0.0015  max mem: 2500
Train: Epoch[5/5]  [1980/3750]  eta: 0:10:16  Lr: 0.001875  Loss: -1.0469  Acc@1: 81.2500 (83.1588)  Acc@5: 93.7500 (97.1321)  time: 0.3494  data: 0.0011  max mem: 2500
Train: Epoch[5/5]  [1990/3750]  eta: 0:10:12  Lr: 0.001875  Loss: -1.0626  Acc@1: 81.2500 (83.1617)  Acc@5: 100.0000 (97.1340)  time: 0.3469  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [2000/3750]  eta: 0:10:09  Lr: 0.001875  Loss: -1.2226  Acc@1: 87.5000 (83.1803)  Acc@5: 93.7500 (97.1264)  time: 0.3476  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [2010/3750]  eta: 0:10:05  Lr: 0.001875  Loss: -0.9914  Acc@1: 81.2500 (83.1707)  Acc@5: 93.7500 (97.1283)  time: 0.3491  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [2020/3750]  eta: 0:10:02  Lr: 0.001875  Loss: -0.8006  Acc@1: 87.5000 (83.1921)  Acc@5: 100.0000 (97.1394)  time: 0.3475  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [2030/3750]  eta: 0:09:58  Lr: 0.001875  Loss: -0.9559  Acc@1: 87.5000 (83.2041)  Acc@5: 100.0000 (97.1443)  time: 0.3477  data: 0.0010  max mem: 2500
Train: Epoch[5/5]  [2040/3750]  eta: 0:09:55  Lr: 0.001875  Loss: -1.0242  Acc@1: 87.5000 (83.2282)  Acc@5: 100.0000 (97.1521)  time: 0.3475  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [2050/3750]  eta: 0:09:51  Lr: 0.001875  Loss: -0.8907  Acc@1: 87.5000 (83.2338)  Acc@5: 100.0000 (97.1325)  time: 0.3472  data: 0.0012  max mem: 2500
Train: Epoch[5/5]  [2060/3750]  eta: 0:09:48  Lr: 0.001875  Loss: -0.6086  Acc@1: 87.5000 (83.2424)  Acc@5: 93.7500 (97.1282)  time: 0.3484  data: 0.0013  max mem: 2500
Train: Epoch[5/5]  [2070/3750]  eta: 0:09:44  Lr: 0.001875  Loss: -0.7392  Acc@1: 87.5000 (83.2327)  Acc@5: 100.0000 (97.1240)  time: 0.3507  data: 0.0018  max mem: 2500
Train: Epoch[5/5]  [2080/3750]  eta: 0:09:41  Lr: 0.001875  Loss: -0.4458  Acc@1: 81.2500 (83.2292)  Acc@5: 100.0000 (97.1288)  time: 0.3504  data: 0.0019  max mem: 2500
Train: Epoch[5/5]  [2090/3750]  eta: 0:09:37  Lr: 0.001875  Loss: -1.2324  Acc@1: 81.2500 (83.2108)  Acc@5: 100.0000 (97.1335)  time: 0.3474  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [2100/3750]  eta: 0:09:34  Lr: 0.001875  Loss: -0.8843  Acc@1: 81.2500 (83.2104)  Acc@5: 100.0000 (97.1293)  time: 0.3469  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [2110/3750]  eta: 0:09:30  Lr: 0.001875  Loss: -0.7180  Acc@1: 81.2500 (83.1981)  Acc@5: 93.7500 (97.1163)  time: 0.3467  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [2120/3750]  eta: 0:09:27  Lr: 0.001875  Loss: -1.1047  Acc@1: 81.2500 (83.1860)  Acc@5: 93.7500 (97.1093)  time: 0.3487  data: 0.0011  max mem: 2500
Train: Epoch[5/5]  [2130/3750]  eta: 0:09:23  Lr: 0.001875  Loss: -0.6840  Acc@1: 81.2500 (83.1916)  Acc@5: 100.0000 (97.1111)  time: 0.3497  data: 0.0011  max mem: 2500
Train: Epoch[5/5]  [2140/3750]  eta: 0:09:20  Lr: 0.001875  Loss: -0.9051  Acc@1: 81.2500 (83.1854)  Acc@5: 100.0000 (97.1158)  time: 0.3496  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [2150/3750]  eta: 0:09:16  Lr: 0.001875  Loss: -0.7661  Acc@1: 81.2500 (83.1910)  Acc@5: 100.0000 (97.1118)  time: 0.3503  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [2160/3750]  eta: 0:09:13  Lr: 0.001875  Loss: -0.7284  Acc@1: 81.2500 (83.1733)  Acc@5: 100.0000 (97.1107)  time: 0.3491  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [2170/3750]  eta: 0:09:09  Lr: 0.001875  Loss: -1.1455  Acc@1: 87.5000 (83.2019)  Acc@5: 100.0000 (97.1154)  time: 0.3500  data: 0.0018  max mem: 2500
Train: Epoch[5/5]  [2180/3750]  eta: 0:09:06  Lr: 0.001875  Loss: -0.6932  Acc@1: 87.5000 (83.1872)  Acc@5: 100.0000 (97.1086)  time: 0.3489  data: 0.0019  max mem: 2500
Train: Epoch[5/5]  [2190/3750]  eta: 0:09:03  Lr: 0.001875  Loss: -1.1811  Acc@1: 75.0000 (83.1641)  Acc@5: 100.0000 (97.1132)  time: 0.3477  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [2200/3750]  eta: 0:08:59  Lr: 0.001875  Loss: -0.7493  Acc@1: 81.2500 (83.1639)  Acc@5: 100.0000 (97.1235)  time: 0.3488  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [2210/3750]  eta: 0:08:56  Lr: 0.001875  Loss: -0.7629  Acc@1: 81.2500 (83.1609)  Acc@5: 100.0000 (97.1252)  time: 0.3480  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [2220/3750]  eta: 0:08:52  Lr: 0.001875  Loss: -0.8417  Acc@1: 81.2500 (83.1495)  Acc@5: 100.0000 (97.1240)  time: 0.3473  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [2230/3750]  eta: 0:08:49  Lr: 0.001875  Loss: -1.1727  Acc@1: 81.2500 (83.1522)  Acc@5: 93.7500 (97.1229)  time: 0.3471  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [2240/3750]  eta: 0:08:45  Lr: 0.001875  Loss: -1.1778  Acc@1: 81.2500 (83.1521)  Acc@5: 100.0000 (97.1246)  time: 0.3471  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [2250/3750]  eta: 0:08:42  Lr: 0.001875  Loss: -1.2125  Acc@1: 81.2500 (83.1603)  Acc@5: 100.0000 (97.1235)  time: 0.3475  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [2260/3750]  eta: 0:08:38  Lr: 0.001875  Loss: -0.0885  Acc@1: 81.2500 (83.1601)  Acc@5: 100.0000 (97.1196)  time: 0.3471  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [2270/3750]  eta: 0:08:35  Lr: 0.001875  Loss: -1.1800  Acc@1: 87.5000 (83.1682)  Acc@5: 100.0000 (97.1296)  time: 0.3474  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [2280/3750]  eta: 0:08:31  Lr: 0.001875  Loss: -0.7610  Acc@1: 81.2500 (83.1598)  Acc@5: 100.0000 (97.1312)  time: 0.3474  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [2290/3750]  eta: 0:08:28  Lr: 0.001875  Loss: -0.5664  Acc@1: 81.2500 (83.1542)  Acc@5: 100.0000 (97.1328)  time: 0.3476  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [2300/3750]  eta: 0:08:24  Lr: 0.001875  Loss: -0.8458  Acc@1: 81.2500 (83.1568)  Acc@5: 100.0000 (97.1398)  time: 0.3476  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [2310/3750]  eta: 0:08:21  Lr: 0.001875  Loss: -1.1546  Acc@1: 81.2500 (83.1539)  Acc@5: 100.0000 (97.1441)  time: 0.3497  data: 0.0020  max mem: 2500
Train: Epoch[5/5]  [2320/3750]  eta: 0:08:17  Lr: 0.001875  Loss: -1.0629  Acc@1: 81.2500 (83.1700)  Acc@5: 100.0000 (97.1375)  time: 0.3511  data: 0.0023  max mem: 2500
Train: Epoch[5/5]  [2330/3750]  eta: 0:08:14  Lr: 0.001875  Loss: -1.1718  Acc@1: 87.5000 (83.1751)  Acc@5: 100.0000 (97.1418)  time: 0.3492  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [2340/3750]  eta: 0:08:10  Lr: 0.001875  Loss: -0.9855  Acc@1: 87.5000 (83.1990)  Acc@5: 100.0000 (97.1513)  time: 0.3493  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [2350/3750]  eta: 0:08:07  Lr: 0.001875  Loss: -0.7517  Acc@1: 81.2500 (83.1694)  Acc@5: 100.0000 (97.1501)  time: 0.3479  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [2360/3750]  eta: 0:08:03  Lr: 0.001875  Loss: -0.6445  Acc@1: 81.2500 (83.1745)  Acc@5: 100.0000 (97.1490)  time: 0.3458  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [2370/3750]  eta: 0:08:00  Lr: 0.001875  Loss: -0.5172  Acc@1: 87.5000 (83.1796)  Acc@5: 100.0000 (97.1505)  time: 0.3468  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [2380/3750]  eta: 0:07:56  Lr: 0.001875  Loss: -1.3016  Acc@1: 81.2500 (83.1531)  Acc@5: 100.0000 (97.1441)  time: 0.3487  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [2390/3750]  eta: 0:07:53  Lr: 0.001875  Loss: -1.2917  Acc@1: 81.2500 (83.1399)  Acc@5: 93.7500 (97.1325)  time: 0.3474  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [2400/3750]  eta: 0:07:49  Lr: 0.001875  Loss: -0.3230  Acc@1: 81.2500 (83.1320)  Acc@5: 100.0000 (97.1366)  time: 0.3478  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [2410/3750]  eta: 0:07:46  Lr: 0.001875  Loss: -1.1857  Acc@1: 81.2500 (83.1268)  Acc@5: 100.0000 (97.1355)  time: 0.3475  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [2420/3750]  eta: 0:07:42  Lr: 0.001875  Loss: -1.1160  Acc@1: 81.2500 (83.1294)  Acc@5: 100.0000 (97.1396)  time: 0.3460  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [2430/3750]  eta: 0:07:39  Lr: 0.001875  Loss: -0.7194  Acc@1: 81.2500 (83.1294)  Acc@5: 100.0000 (97.1462)  time: 0.3478  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [2440/3750]  eta: 0:07:35  Lr: 0.001875  Loss: -0.3572  Acc@1: 81.2500 (83.1217)  Acc@5: 100.0000 (97.1349)  time: 0.3473  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [2450/3750]  eta: 0:07:32  Lr: 0.001875  Loss: -1.0439  Acc@1: 81.2500 (83.1115)  Acc@5: 93.7500 (97.1185)  time: 0.3463  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2460/3750]  eta: 0:07:28  Lr: 0.001875  Loss: -1.3780  Acc@1: 81.2500 (83.1014)  Acc@5: 93.7500 (97.1201)  time: 0.3469  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [2470/3750]  eta: 0:07:25  Lr: 0.001875  Loss: -1.1906  Acc@1: 81.2500 (83.1065)  Acc@5: 100.0000 (97.1191)  time: 0.3479  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [2480/3750]  eta: 0:07:22  Lr: 0.001875  Loss: -0.6574  Acc@1: 81.2500 (83.1116)  Acc@5: 100.0000 (97.1257)  time: 0.3498  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [2490/3750]  eta: 0:07:18  Lr: 0.001875  Loss: -0.3499  Acc@1: 81.2500 (83.0916)  Acc@5: 100.0000 (97.1121)  time: 0.3490  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [2500/3750]  eta: 0:07:15  Lr: 0.001875  Loss: -0.8264  Acc@1: 81.2500 (83.0843)  Acc@5: 93.7500 (97.1162)  time: 0.3476  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [2510/3750]  eta: 0:07:11  Lr: 0.001875  Loss: -1.0551  Acc@1: 87.5000 (83.0944)  Acc@5: 100.0000 (97.1152)  time: 0.3474  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [2520/3750]  eta: 0:07:08  Lr: 0.001875  Loss: -0.8571  Acc@1: 81.2500 (83.0871)  Acc@5: 100.0000 (97.1118)  time: 0.3466  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [2530/3750]  eta: 0:07:04  Lr: 0.001875  Loss: -1.1543  Acc@1: 81.2500 (83.0946)  Acc@5: 100.0000 (97.1158)  time: 0.3460  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [2540/3750]  eta: 0:07:01  Lr: 0.001875  Loss: -1.0587  Acc@1: 87.5000 (83.0972)  Acc@5: 100.0000 (97.1222)  time: 0.3475  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [2550/3750]  eta: 0:06:57  Lr: 0.001875  Loss: -1.1582  Acc@1: 87.5000 (83.1292)  Acc@5: 100.0000 (97.1261)  time: 0.3496  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [2560/3750]  eta: 0:06:54  Lr: 0.001875  Loss: -1.2488  Acc@1: 87.5000 (83.1267)  Acc@5: 100.0000 (97.1300)  time: 0.3484  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [2570/3750]  eta: 0:06:50  Lr: 0.001875  Loss: -0.8290  Acc@1: 87.5000 (83.1170)  Acc@5: 100.0000 (97.1217)  time: 0.3464  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [2580/3750]  eta: 0:06:47  Lr: 0.001875  Loss: -1.0890  Acc@1: 87.5000 (83.1291)  Acc@5: 100.0000 (97.1184)  time: 0.3469  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [2590/3750]  eta: 0:06:43  Lr: 0.001875  Loss: -0.6547  Acc@1: 87.5000 (83.1363)  Acc@5: 100.0000 (97.1174)  time: 0.3470  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [2600/3750]  eta: 0:06:40  Lr: 0.001875  Loss: -0.6295  Acc@1: 81.2500 (83.1051)  Acc@5: 100.0000 (97.1117)  time: 0.3452  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [2610/3750]  eta: 0:06:36  Lr: 0.001875  Loss: -1.0007  Acc@1: 81.2500 (83.1099)  Acc@5: 100.0000 (97.1084)  time: 0.3444  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [2620/3750]  eta: 0:06:33  Lr: 0.001875  Loss: -1.1313  Acc@1: 87.5000 (83.1100)  Acc@5: 100.0000 (97.1123)  time: 0.3465  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2630/3750]  eta: 0:06:29  Lr: 0.001875  Loss: -0.7957  Acc@1: 87.5000 (83.1172)  Acc@5: 100.0000 (97.1137)  time: 0.3475  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2640/3750]  eta: 0:06:26  Lr: 0.001875  Loss: -0.9218  Acc@1: 81.2500 (83.0959)  Acc@5: 100.0000 (97.1199)  time: 0.3462  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2650/3750]  eta: 0:06:22  Lr: 0.001875  Loss: -0.8782  Acc@1: 75.0000 (83.0701)  Acc@5: 100.0000 (97.1214)  time: 0.3470  data: 0.0010  max mem: 2500
Train: Epoch[5/5]  [2660/3750]  eta: 0:06:19  Lr: 0.001875  Loss: -1.0442  Acc@1: 81.2500 (83.0726)  Acc@5: 100.0000 (97.1228)  time: 0.3476  data: 0.0011  max mem: 2500
Train: Epoch[5/5]  [2670/3750]  eta: 0:06:15  Lr: 0.001875  Loss: -1.2065  Acc@1: 81.2500 (83.0518)  Acc@5: 100.0000 (97.1172)  time: 0.3489  data: 0.0017  max mem: 2500
Train: Epoch[5/5]  [2680/3750]  eta: 0:06:12  Lr: 0.001875  Loss: -0.7825  Acc@1: 81.2500 (83.0660)  Acc@5: 100.0000 (97.1163)  time: 0.3501  data: 0.0017  max mem: 2500
Train: Epoch[5/5]  [2690/3750]  eta: 0:06:08  Lr: 0.001875  Loss: -0.2627  Acc@1: 87.5000 (83.0639)  Acc@5: 100.0000 (97.1131)  time: 0.3479  data: 0.0010  max mem: 2500
Train: Epoch[5/5]  [2700/3750]  eta: 0:06:05  Lr: 0.001875  Loss: -0.9484  Acc@1: 87.5000 (83.0803)  Acc@5: 93.7500 (97.1076)  time: 0.3469  data: 0.0010  max mem: 2500
Train: Epoch[5/5]  [2710/3750]  eta: 0:06:01  Lr: 0.001875  Loss: -1.0430  Acc@1: 87.5000 (83.0736)  Acc@5: 93.7500 (97.1021)  time: 0.3472  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [2720/3750]  eta: 0:05:58  Lr: 0.001875  Loss: -1.2814  Acc@1: 81.2500 (83.0669)  Acc@5: 100.0000 (97.1035)  time: 0.3464  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2730/3750]  eta: 0:05:54  Lr: 0.001875  Loss: -1.0688  Acc@1: 87.5000 (83.0831)  Acc@5: 100.0000 (97.1119)  time: 0.3463  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [2740/3750]  eta: 0:05:51  Lr: 0.001875  Loss: -0.6361  Acc@1: 87.5000 (83.0764)  Acc@5: 100.0000 (97.1156)  time: 0.3480  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [2750/3750]  eta: 0:05:47  Lr: 0.001875  Loss: -1.1597  Acc@1: 87.5000 (83.0880)  Acc@5: 100.0000 (97.1192)  time: 0.3490  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [2760/3750]  eta: 0:05:44  Lr: 0.001875  Loss: -0.9046  Acc@1: 87.5000 (83.0881)  Acc@5: 100.0000 (97.1183)  time: 0.3492  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [2770/3750]  eta: 0:05:41  Lr: 0.001875  Loss: -1.2368  Acc@1: 87.5000 (83.0927)  Acc@5: 100.0000 (97.1197)  time: 0.3475  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [2780/3750]  eta: 0:05:37  Lr: 0.001875  Loss: -0.6605  Acc@1: 81.2500 (83.0884)  Acc@5: 100.0000 (97.1166)  time: 0.3474  data: 0.0010  max mem: 2500
Train: Epoch[5/5]  [2790/3750]  eta: 0:05:34  Lr: 0.001875  Loss: -1.0571  Acc@1: 81.2500 (83.0818)  Acc@5: 100.0000 (97.1157)  time: 0.3486  data: 0.0011  max mem: 2500
Train: Epoch[5/5]  [2800/3750]  eta: 0:05:30  Lr: 0.001875  Loss: -0.7842  Acc@1: 75.0000 (83.0685)  Acc@5: 100.0000 (97.1126)  time: 0.3469  data: 0.0010  max mem: 2500
Train: Epoch[5/5]  [2810/3750]  eta: 0:05:27  Lr: 0.001875  Loss: -0.9506  Acc@1: 87.5000 (83.0799)  Acc@5: 100.0000 (97.1162)  time: 0.3466  data: 0.0010  max mem: 2500
Train: Epoch[5/5]  [2820/3750]  eta: 0:05:23  Lr: 0.001875  Loss: -1.1437  Acc@1: 87.5000 (83.0689)  Acc@5: 100.0000 (97.1176)  time: 0.3474  data: 0.0012  max mem: 2500
Train: Epoch[5/5]  [2830/3750]  eta: 0:05:20  Lr: 0.001875  Loss: -1.1497  Acc@1: 81.2500 (83.0669)  Acc@5: 100.0000 (97.1190)  time: 0.3490  data: 0.0021  max mem: 2500
Train: Epoch[5/5]  [2840/3750]  eta: 0:05:16  Lr: 0.001875  Loss: -1.0813  Acc@1: 87.5000 (83.0759)  Acc@5: 100.0000 (97.1247)  time: 0.3492  data: 0.0015  max mem: 2500
Train: Epoch[5/5]  [2850/3750]  eta: 0:05:13  Lr: 0.001875  Loss: -0.7064  Acc@1: 87.5000 (83.0827)  Acc@5: 100.0000 (97.1260)  time: 0.3471  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [2860/3750]  eta: 0:05:09  Lr: 0.001875  Loss: -0.9649  Acc@1: 87.5000 (83.0807)  Acc@5: 100.0000 (97.1295)  time: 0.3476  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [2870/3750]  eta: 0:05:06  Lr: 0.001875  Loss: -0.9739  Acc@1: 81.2500 (83.0786)  Acc@5: 100.0000 (97.1286)  time: 0.3484  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [2880/3750]  eta: 0:05:02  Lr: 0.001875  Loss: -0.3066  Acc@1: 81.2500 (83.0745)  Acc@5: 100.0000 (97.1277)  time: 0.3478  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [2890/3750]  eta: 0:04:59  Lr: 0.001875  Loss: -1.1301  Acc@1: 81.2500 (83.0703)  Acc@5: 100.0000 (97.1290)  time: 0.3477  data: 0.0012  max mem: 2500
Train: Epoch[5/5]  [2900/3750]  eta: 0:04:55  Lr: 0.001875  Loss: -0.6491  Acc@1: 81.2500 (83.0791)  Acc@5: 100.0000 (97.1260)  time: 0.3477  data: 0.0018  max mem: 2500
Train: Epoch[5/5]  [2910/3750]  eta: 0:04:52  Lr: 0.001875  Loss: -1.1080  Acc@1: 81.2500 (83.0857)  Acc@5: 93.7500 (97.1208)  time: 0.3469  data: 0.0011  max mem: 2500
Train: Epoch[5/5]  [2920/3750]  eta: 0:04:48  Lr: 0.001875  Loss: -0.8642  Acc@1: 81.2500 (83.0816)  Acc@5: 93.7500 (97.1179)  time: 0.3458  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [2930/3750]  eta: 0:04:45  Lr: 0.001875  Loss: -1.0446  Acc@1: 81.2500 (83.0689)  Acc@5: 93.7500 (97.1128)  time: 0.3475  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [2940/3750]  eta: 0:04:41  Lr: 0.001875  Loss: -1.3958  Acc@1: 81.2500 (83.0670)  Acc@5: 100.0000 (97.1141)  time: 0.3478  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [2950/3750]  eta: 0:04:38  Lr: 0.001875  Loss: -1.1980  Acc@1: 87.5000 (83.0884)  Acc@5: 100.0000 (97.1111)  time: 0.3467  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [2960/3750]  eta: 0:04:34  Lr: 0.001875  Loss: -0.9614  Acc@1: 87.5000 (83.0927)  Acc@5: 93.7500 (97.1040)  time: 0.3472  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [2970/3750]  eta: 0:04:31  Lr: 0.001875  Loss: -1.2799  Acc@1: 87.5000 (83.0907)  Acc@5: 93.7500 (97.1011)  time: 0.3476  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [2980/3750]  eta: 0:04:27  Lr: 0.001875  Loss: -0.4348  Acc@1: 81.2500 (83.0950)  Acc@5: 100.0000 (97.0983)  time: 0.3474  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [2990/3750]  eta: 0:04:24  Lr: 0.001875  Loss: -0.5929  Acc@1: 81.2500 (83.0868)  Acc@5: 100.0000 (97.0955)  time: 0.3478  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [3000/3750]  eta: 0:04:20  Lr: 0.001875  Loss: -0.9527  Acc@1: 81.2500 (83.0931)  Acc@5: 93.7500 (97.0926)  time: 0.3476  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3010/3750]  eta: 0:04:17  Lr: 0.001875  Loss: -1.2190  Acc@1: 87.5000 (83.0953)  Acc@5: 100.0000 (97.0961)  time: 0.3463  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3020/3750]  eta: 0:04:13  Lr: 0.001875  Loss: -0.7046  Acc@1: 81.2500 (83.1016)  Acc@5: 100.0000 (97.0974)  time: 0.3471  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [3030/3750]  eta: 0:04:10  Lr: 0.001875  Loss: -1.2897  Acc@1: 87.5000 (83.1182)  Acc@5: 100.0000 (97.0987)  time: 0.3485  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [3040/3750]  eta: 0:04:07  Lr: 0.001875  Loss: -1.1801  Acc@1: 87.5000 (83.1305)  Acc@5: 100.0000 (97.0980)  time: 0.3473  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [3050/3750]  eta: 0:04:03  Lr: 0.001875  Loss: -1.3396  Acc@1: 87.5000 (83.1285)  Acc@5: 100.0000 (97.0993)  time: 0.3459  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [3060/3750]  eta: 0:04:00  Lr: 0.001875  Loss: -0.7200  Acc@1: 81.2500 (83.1183)  Acc@5: 100.0000 (97.1006)  time: 0.3464  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [3070/3750]  eta: 0:03:56  Lr: 0.001875  Loss: -0.8078  Acc@1: 75.0000 (83.1000)  Acc@5: 100.0000 (97.0917)  time: 0.3475  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [3080/3750]  eta: 0:03:53  Lr: 0.001875  Loss: -1.0973  Acc@1: 81.2500 (83.1061)  Acc@5: 93.7500 (97.0890)  time: 0.3485  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [3090/3750]  eta: 0:03:49  Lr: 0.001875  Loss: -1.1047  Acc@1: 87.5000 (83.1042)  Acc@5: 93.7500 (97.0843)  time: 0.3481  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [3100/3750]  eta: 0:03:46  Lr: 0.001875  Loss: -1.2142  Acc@1: 87.5000 (83.1183)  Acc@5: 100.0000 (97.0917)  time: 0.3476  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [3110/3750]  eta: 0:03:42  Lr: 0.001875  Loss: -0.7145  Acc@1: 87.5000 (83.1304)  Acc@5: 100.0000 (97.0970)  time: 0.3478  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [3120/3750]  eta: 0:03:39  Lr: 0.001875  Loss: -0.5702  Acc@1: 81.2500 (83.1244)  Acc@5: 100.0000 (97.0983)  time: 0.3481  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [3130/3750]  eta: 0:03:35  Lr: 0.001875  Loss: -0.8805  Acc@1: 81.2500 (83.1244)  Acc@5: 93.7500 (97.0936)  time: 0.3470  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [3140/3750]  eta: 0:03:32  Lr: 0.001875  Loss: -0.9541  Acc@1: 81.2500 (83.1224)  Acc@5: 100.0000 (97.0969)  time: 0.3476  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [3150/3750]  eta: 0:03:28  Lr: 0.001875  Loss: -1.0293  Acc@1: 81.2500 (83.1204)  Acc@5: 100.0000 (97.0942)  time: 0.3527  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [3160/3750]  eta: 0:03:25  Lr: 0.001875  Loss: -0.4618  Acc@1: 81.2500 (83.1046)  Acc@5: 93.7500 (97.0895)  time: 0.3530  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [3170/3750]  eta: 0:03:21  Lr: 0.001875  Loss: -0.5430  Acc@1: 81.2500 (83.1165)  Acc@5: 100.0000 (97.0948)  time: 0.3498  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [3180/3750]  eta: 0:03:18  Lr: 0.001875  Loss: -0.7501  Acc@1: 87.5000 (83.1283)  Acc@5: 100.0000 (97.0901)  time: 0.3473  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [3190/3750]  eta: 0:03:14  Lr: 0.001875  Loss: -0.0117  Acc@1: 81.2500 (83.1146)  Acc@5: 100.0000 (97.0895)  time: 0.3457  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [3200/3750]  eta: 0:03:11  Lr: 0.001875  Loss: -0.6861  Acc@1: 81.2500 (83.1205)  Acc@5: 100.0000 (97.0908)  time: 0.3485  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [3210/3750]  eta: 0:03:07  Lr: 0.001875  Loss: -1.1597  Acc@1: 81.2500 (83.1225)  Acc@5: 100.0000 (97.0940)  time: 0.3480  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [3220/3750]  eta: 0:03:04  Lr: 0.001875  Loss: -0.7946  Acc@1: 81.2500 (83.1167)  Acc@5: 100.0000 (97.0914)  time: 0.3453  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [3230/3750]  eta: 0:03:00  Lr: 0.001875  Loss: -1.3037  Acc@1: 81.2500 (83.1302)  Acc@5: 100.0000 (97.0965)  time: 0.3459  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [3240/3750]  eta: 0:02:57  Lr: 0.001875  Loss: -1.1068  Acc@1: 81.2500 (83.1283)  Acc@5: 100.0000 (97.0939)  time: 0.3462  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [3250/3750]  eta: 0:02:53  Lr: 0.001875  Loss: -1.1978  Acc@1: 81.2500 (83.1398)  Acc@5: 100.0000 (97.0951)  time: 0.3479  data: 0.0013  max mem: 2500
Train: Epoch[5/5]  [3260/3750]  eta: 0:02:50  Lr: 0.001875  Loss: -1.2479  Acc@1: 87.5000 (83.1321)  Acc@5: 100.0000 (97.0944)  time: 0.3491  data: 0.0012  max mem: 2500
Train: Epoch[5/5]  [3270/3750]  eta: 0:02:47  Lr: 0.001875  Loss: -0.5557  Acc@1: 81.2500 (83.1302)  Acc@5: 100.0000 (97.0938)  time: 0.3472  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [3280/3750]  eta: 0:02:43  Lr: 0.001875  Loss: -1.0514  Acc@1: 87.5000 (83.1416)  Acc@5: 100.0000 (97.0950)  time: 0.3472  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [3290/3750]  eta: 0:02:40  Lr: 0.001875  Loss: -1.2903  Acc@1: 87.5000 (83.1491)  Acc@5: 100.0000 (97.1000)  time: 0.3485  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [3300/3750]  eta: 0:02:36  Lr: 0.001875  Loss: -0.8400  Acc@1: 81.2500 (83.1453)  Acc@5: 100.0000 (97.1050)  time: 0.3481  data: 0.0012  max mem: 2500
Train: Epoch[5/5]  [3310/3750]  eta: 0:02:33  Lr: 0.001875  Loss: -1.3270  Acc@1: 81.2500 (83.1471)  Acc@5: 100.0000 (97.1062)  time: 0.3475  data: 0.0013  max mem: 2500
Train: Epoch[5/5]  [3320/3750]  eta: 0:02:29  Lr: 0.001875  Loss: -1.2345  Acc@1: 81.2500 (83.1338)  Acc@5: 100.0000 (97.1018)  time: 0.3466  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [3330/3750]  eta: 0:02:26  Lr: 0.001875  Loss: -0.4320  Acc@1: 81.2500 (83.1338)  Acc@5: 100.0000 (97.1011)  time: 0.3479  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [3340/3750]  eta: 0:02:22  Lr: 0.001875  Loss: -1.3203  Acc@1: 81.2500 (83.1357)  Acc@5: 100.0000 (97.1060)  time: 0.3483  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [3350/3750]  eta: 0:02:19  Lr: 0.001875  Loss: -1.0771  Acc@1: 87.5000 (83.1412)  Acc@5: 100.0000 (97.1072)  time: 0.3468  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [3360/3750]  eta: 0:02:15  Lr: 0.001875  Loss: -1.2007  Acc@1: 87.5000 (83.1505)  Acc@5: 100.0000 (97.1028)  time: 0.3482  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [3370/3750]  eta: 0:02:12  Lr: 0.001875  Loss: -0.8150  Acc@1: 87.5000 (83.1578)  Acc@5: 93.7500 (97.1021)  time: 0.3475  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [3380/3750]  eta: 0:02:08  Lr: 0.001875  Loss: -0.9374  Acc@1: 87.5000 (83.1596)  Acc@5: 100.0000 (97.1014)  time: 0.3463  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [3390/3750]  eta: 0:02:05  Lr: 0.001875  Loss: -0.9159  Acc@1: 81.2500 (83.1576)  Acc@5: 100.0000 (97.1026)  time: 0.3460  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [3400/3750]  eta: 0:02:01  Lr: 0.001875  Loss: -0.6213  Acc@1: 93.7500 (83.1814)  Acc@5: 100.0000 (97.1075)  time: 0.3459  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [3410/3750]  eta: 0:01:58  Lr: 0.001875  Loss: -0.7727  Acc@1: 87.5000 (83.1703)  Acc@5: 100.0000 (97.1105)  time: 0.3471  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [3420/3750]  eta: 0:01:54  Lr: 0.001875  Loss: -1.2469  Acc@1: 81.2500 (83.1756)  Acc@5: 100.0000 (97.1025)  time: 0.3468  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [3430/3750]  eta: 0:01:51  Lr: 0.001875  Loss: -0.1902  Acc@1: 81.2500 (83.1536)  Acc@5: 93.7500 (97.0963)  time: 0.3473  data: 0.0012  max mem: 2500
Train: Epoch[5/5]  [3440/3750]  eta: 0:01:47  Lr: 0.001875  Loss: -0.8920  Acc@1: 75.0000 (83.1444)  Acc@5: 100.0000 (97.1011)  time: 0.3471  data: 0.0012  max mem: 2500
Train: Epoch[5/5]  [3450/3750]  eta: 0:01:44  Lr: 0.001875  Loss: -0.7433  Acc@1: 81.2500 (83.1389)  Acc@5: 100.0000 (97.1005)  time: 0.3464  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [3460/3750]  eta: 0:01:40  Lr: 0.001875  Loss: -0.9384  Acc@1: 81.2500 (83.1371)  Acc@5: 100.0000 (97.0980)  time: 0.3470  data: 0.0010  max mem: 2500
Train: Epoch[5/5]  [3470/3750]  eta: 0:01:37  Lr: 0.001875  Loss: -0.9700  Acc@1: 81.2500 (83.1443)  Acc@5: 100.0000 (97.0992)  time: 0.3480  data: 0.0021  max mem: 2500
Train: Epoch[5/5]  [3480/3750]  eta: 0:01:33  Lr: 0.001875  Loss: -0.1426  Acc@1: 81.2500 (83.1352)  Acc@5: 100.0000 (97.0931)  time: 0.3489  data: 0.0021  max mem: 2500
Train: Epoch[5/5]  [3490/3750]  eta: 0:01:30  Lr: 0.001875  Loss: -0.9225  Acc@1: 87.5000 (83.1388)  Acc@5: 100.0000 (97.0979)  time: 0.3486  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [3500/3750]  eta: 0:01:26  Lr: 0.001875  Loss: -0.9978  Acc@1: 87.5000 (83.1584)  Acc@5: 100.0000 (97.1026)  time: 0.3476  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [3510/3750]  eta: 0:01:23  Lr: 0.001875  Loss: -1.1926  Acc@1: 87.5000 (83.1512)  Acc@5: 100.0000 (97.1073)  time: 0.3475  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [3520/3750]  eta: 0:01:20  Lr: 0.001875  Loss: -0.8045  Acc@1: 81.2500 (83.1582)  Acc@5: 100.0000 (97.1031)  time: 0.3470  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [3530/3750]  eta: 0:01:16  Lr: 0.001875  Loss: -1.0290  Acc@1: 81.2500 (83.1652)  Acc@5: 100.0000 (97.1078)  time: 0.3478  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [3540/3750]  eta: 0:01:13  Lr: 0.001875  Loss: -1.0408  Acc@1: 81.2500 (83.1598)  Acc@5: 100.0000 (97.1089)  time: 0.3493  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [3550/3750]  eta: 0:01:09  Lr: 0.001875  Loss: -0.8440  Acc@1: 81.2500 (83.1562)  Acc@5: 100.0000 (97.1100)  time: 0.3493  data: 0.0014  max mem: 2500
Train: Epoch[5/5]  [3560/3750]  eta: 0:01:06  Lr: 0.001875  Loss: -0.6686  Acc@1: 81.2500 (83.1631)  Acc@5: 100.0000 (97.1128)  time: 0.3502  data: 0.0014  max mem: 2500
Train: Epoch[5/5]  [3570/3750]  eta: 0:01:02  Lr: 0.001875  Loss: -0.9650  Acc@1: 81.2500 (83.1647)  Acc@5: 100.0000 (97.1104)  time: 0.3493  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [3580/3750]  eta: 0:00:59  Lr: 0.001875  Loss: -1.0525  Acc@1: 81.2500 (83.1629)  Acc@5: 93.7500 (97.1080)  time: 0.3470  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [3590/3750]  eta: 0:00:55  Lr: 0.001875  Loss: -1.1852  Acc@1: 81.2500 (83.1558)  Acc@5: 100.0000 (97.1126)  time: 0.3468  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [3600/3750]  eta: 0:00:52  Lr: 0.001875  Loss: -1.2760  Acc@1: 87.5000 (83.1644)  Acc@5: 100.0000 (97.1154)  time: 0.3470  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [3610/3750]  eta: 0:00:48  Lr: 0.001875  Loss: -1.3948  Acc@1: 87.5000 (83.1712)  Acc@5: 100.0000 (97.1164)  time: 0.3471  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [3620/3750]  eta: 0:00:45  Lr: 0.001875  Loss: -1.0275  Acc@1: 87.5000 (83.1883)  Acc@5: 100.0000 (97.1210)  time: 0.3469  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [3630/3750]  eta: 0:00:41  Lr: 0.001875  Loss: -1.1038  Acc@1: 93.7500 (83.2054)  Acc@5: 100.0000 (97.1220)  time: 0.3474  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [3640/3750]  eta: 0:00:38  Lr: 0.001875  Loss: -1.0275  Acc@1: 87.5000 (83.2017)  Acc@5: 93.7500 (97.1196)  time: 0.3497  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [3650/3750]  eta: 0:00:34  Lr: 0.001875  Loss: -1.3045  Acc@1: 81.2500 (83.2067)  Acc@5: 100.0000 (97.1224)  time: 0.3485  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [3660/3750]  eta: 0:00:31  Lr: 0.001875  Loss: -0.8552  Acc@1: 81.2500 (83.2030)  Acc@5: 100.0000 (97.1234)  time: 0.3495  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [3670/3750]  eta: 0:00:27  Lr: 0.001875  Loss: -0.8890  Acc@1: 81.2500 (83.2062)  Acc@5: 100.0000 (97.1210)  time: 0.3491  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [3680/3750]  eta: 0:00:24  Lr: 0.001875  Loss: -1.1221  Acc@1: 87.5000 (83.2162)  Acc@5: 100.0000 (97.1203)  time: 0.3457  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [3690/3750]  eta: 0:00:20  Lr: 0.001875  Loss: -0.5662  Acc@1: 87.5000 (83.2125)  Acc@5: 100.0000 (97.1214)  time: 0.3458  data: 0.0010  max mem: 2500
Train: Epoch[5/5]  [3700/3750]  eta: 0:00:17  Lr: 0.001875  Loss: -0.5337  Acc@1: 81.2500 (83.2123)  Acc@5: 100.0000 (97.1156)  time: 0.3480  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [3710/3750]  eta: 0:00:13  Lr: 0.001875  Loss: -0.9725  Acc@1: 81.2500 (83.2020)  Acc@5: 100.0000 (97.1167)  time: 0.3483  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [3720/3750]  eta: 0:00:10  Lr: 0.001875  Loss: -1.3907  Acc@1: 81.2500 (83.2135)  Acc@5: 100.0000 (97.1194)  time: 0.3465  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [3730/3750]  eta: 0:00:06  Lr: 0.001875  Loss: -1.2659  Acc@1: 87.5000 (83.2066)  Acc@5: 100.0000 (97.1187)  time: 0.3465  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [3740/3750]  eta: 0:00:03  Lr: 0.001875  Loss: -0.3807  Acc@1: 81.2500 (83.1947)  Acc@5: 100.0000 (97.1181)  time: 0.3461  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [3749/3750]  eta: 0:00:00  Lr: 0.001875  Loss: -1.2248  Acc@1: 81.2500 (83.2067)  Acc@5: 100.0000 (97.1183)  time: 0.3478  data: 0.0012  max mem: 2500
Train: Epoch[5/5] Total time: 0:21:45 (0.3482 s / it)
{0: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 1: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 2: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 3: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 4: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 5: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 6: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 7: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 8: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 9: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 10: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 11: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 12: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 13: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 14: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 15: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 16: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 17: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 18: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 19: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}}
Averaged stats: Lr: 0.001875  Loss: -1.2248  Acc@1: 81.2500 (83.2067)  Acc@5: 100.0000 (97.1183)
Test: [Task 1]  [   0/1627]  eta: 0:29:27  Loss: 1.2300 (1.2300)  Acc@1: 68.7500 (68.7500)  Acc@5: 93.7500 (93.7500)  time: 1.0866  data: 0.8636  max mem: 2500
Test: [Task 1]  [  10/1627]  eta: 0:07:58  Loss: 1.1861 (1.0813)  Acc@1: 75.0000 (73.2955)  Acc@5: 100.0000 (96.0227)  time: 0.2961  data: 0.0792  max mem: 2500
Test: [Task 1]  [  20/1627]  eta: 0:06:55  Loss: 1.0713 (1.0267)  Acc@1: 75.0000 (75.5952)  Acc@5: 100.0000 (95.8333)  time: 0.2171  data: 0.0009  max mem: 2500
Test: [Task 1]  [  30/1627]  eta: 0:06:30  Loss: 1.0545 (1.0440)  Acc@1: 75.0000 (75.2016)  Acc@5: 93.7500 (95.9677)  time: 0.2164  data: 0.0007  max mem: 2500
Test: [Task 1]  [  40/1627]  eta: 0:06:17  Loss: 1.0870 (1.0538)  Acc@1: 75.0000 (75.0000)  Acc@5: 93.7500 (95.8841)  time: 0.2161  data: 0.0004  max mem: 2500
Test: [Task 1]  [  50/1627]  eta: 0:06:08  Loss: 0.9341 (1.0395)  Acc@1: 75.0000 (75.2451)  Acc@5: 100.0000 (95.9559)  time: 0.2171  data: 0.0012  max mem: 2500
Test: [Task 1]  [  60/1627]  eta: 0:06:02  Loss: 1.0930 (1.0583)  Acc@1: 68.7500 (74.5902)  Acc@5: 93.7500 (95.9016)  time: 0.2172  data: 0.0013  max mem: 2500
Test: [Task 1]  [  70/1627]  eta: 0:05:56  Loss: 1.0089 (1.0492)  Acc@1: 68.7500 (75.0880)  Acc@5: 93.7500 (96.1268)  time: 0.2168  data: 0.0007  max mem: 2500
Test: [Task 1]  [  80/1627]  eta: 0:05:52  Loss: 0.8373 (1.0339)  Acc@1: 81.2500 (74.9228)  Acc@5: 100.0000 (96.2963)  time: 0.2182  data: 0.0009  max mem: 2500
Test: [Task 1]  [  90/1627]  eta: 0:05:48  Loss: 0.9760 (1.0438)  Acc@1: 75.0000 (74.6566)  Acc@5: 100.0000 (96.4286)  time: 0.2181  data: 0.0008  max mem: 2500
Test: [Task 1]  [ 100/1627]  eta: 0:05:44  Loss: 1.1106 (1.0637)  Acc@1: 68.7500 (74.0718)  Acc@5: 100.0000 (96.1015)  time: 0.2171  data: 0.0005  max mem: 2500
Test: [Task 1]  [ 110/1627]  eta: 0:05:40  Loss: 1.1076 (1.0637)  Acc@1: 68.7500 (73.9302)  Acc@5: 100.0000 (96.2838)  time: 0.2160  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 120/1627]  eta: 0:05:37  Loss: 1.1194 (1.0663)  Acc@1: 75.0000 (73.9669)  Acc@5: 100.0000 (96.1777)  time: 0.2152  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 130/1627]  eta: 0:05:34  Loss: 1.1726 (1.0691)  Acc@1: 75.0000 (73.9504)  Acc@5: 93.7500 (96.0878)  time: 0.2153  data: 0.0007  max mem: 2500
Test: [Task 1]  [ 140/1627]  eta: 0:05:31  Loss: 0.9926 (1.0678)  Acc@1: 81.2500 (74.0691)  Acc@5: 93.7500 (96.0550)  time: 0.2148  data: 0.0007  max mem: 2500
Test: [Task 1]  [ 150/1627]  eta: 0:05:28  Loss: 0.8200 (1.0540)  Acc@1: 81.2500 (74.4205)  Acc@5: 100.0000 (96.0679)  time: 0.2158  data: 0.0007  max mem: 2500
Test: [Task 1]  [ 160/1627]  eta: 0:05:25  Loss: 0.8075 (1.0473)  Acc@1: 75.0000 (74.7671)  Acc@5: 100.0000 (96.0792)  time: 0.2167  data: 0.0007  max mem: 2500
Test: [Task 1]  [ 170/1627]  eta: 0:05:23  Loss: 0.8879 (1.0416)  Acc@1: 75.0000 (74.8904)  Acc@5: 100.0000 (96.0161)  time: 0.2172  data: 0.0009  max mem: 2500
Test: [Task 1]  [ 180/1627]  eta: 0:05:20  Loss: 1.0030 (1.0470)  Acc@1: 75.0000 (74.7238)  Acc@5: 93.7500 (96.0290)  time: 0.2169  data: 0.0008  max mem: 2500
Test: [Task 1]  [ 190/1627]  eta: 0:05:17  Loss: 1.0093 (1.0424)  Acc@1: 75.0000 (74.8364)  Acc@5: 100.0000 (96.0406)  time: 0.2158  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 200/1627]  eta: 0:05:15  Loss: 1.0514 (1.0432)  Acc@1: 75.0000 (74.7201)  Acc@5: 100.0000 (96.0821)  time: 0.2161  data: 0.0005  max mem: 2500
Test: [Task 1]  [ 210/1627]  eta: 0:05:12  Loss: 0.9829 (1.0401)  Acc@1: 75.0000 (74.9408)  Acc@5: 100.0000 (96.0900)  time: 0.2162  data: 0.0007  max mem: 2500
Test: [Task 1]  [ 220/1627]  eta: 0:05:10  Loss: 0.9243 (1.0450)  Acc@1: 81.2500 (74.7738)  Acc@5: 93.7500 (96.0407)  time: 0.2162  data: 0.0007  max mem: 2500
Test: [Task 1]  [ 230/1627]  eta: 0:05:07  Loss: 0.9741 (1.0401)  Acc@1: 75.0000 (74.9729)  Acc@5: 93.7500 (96.0498)  time: 0.2169  data: 0.0005  max mem: 2500
Test: [Task 1]  [ 240/1627]  eta: 0:05:05  Loss: 0.9543 (1.0349)  Acc@1: 75.0000 (75.0778)  Acc@5: 93.7500 (96.0840)  time: 0.2170  data: 0.0005  max mem: 2500
Test: [Task 1]  [ 250/1627]  eta: 0:05:02  Loss: 0.9140 (1.0398)  Acc@1: 75.0000 (75.0000)  Acc@5: 93.7500 (95.9661)  time: 0.2160  data: 0.0005  max mem: 2500
Test: [Task 1]  [ 260/1627]  eta: 0:05:00  Loss: 1.0208 (1.0397)  Acc@1: 75.0000 (75.0239)  Acc@5: 93.7500 (95.9291)  time: 0.2151  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 270/1627]  eta: 0:04:58  Loss: 0.9087 (1.0332)  Acc@1: 81.2500 (75.2076)  Acc@5: 100.0000 (96.0332)  time: 0.2165  data: 0.0006  max mem: 2500
Test: [Task 1]  [ 280/1627]  eta: 0:04:55  Loss: 0.8640 (1.0327)  Acc@1: 75.0000 (75.2224)  Acc@5: 100.0000 (95.9520)  time: 0.2166  data: 0.0009  max mem: 2500
Test: [Task 1]  [ 290/1627]  eta: 0:04:53  Loss: 1.0187 (1.0321)  Acc@1: 75.0000 (75.3651)  Acc@5: 93.7500 (95.9622)  time: 0.2158  data: 0.0007  max mem: 2500
Test: [Task 1]  [ 300/1627]  eta: 0:04:51  Loss: 0.9257 (1.0303)  Acc@1: 81.2500 (75.3530)  Acc@5: 100.0000 (96.0133)  time: 0.2166  data: 0.0005  max mem: 2500
Test: [Task 1]  [ 310/1627]  eta: 0:04:48  Loss: 0.8812 (1.0303)  Acc@1: 81.2500 (75.4421)  Acc@5: 100.0000 (96.0410)  time: 0.2158  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 320/1627]  eta: 0:04:46  Loss: 0.9876 (1.0292)  Acc@1: 75.0000 (75.4673)  Acc@5: 100.0000 (96.0475)  time: 0.2159  data: 0.0006  max mem: 2500
Test: [Task 1]  [ 330/1627]  eta: 0:04:44  Loss: 0.8983 (1.0273)  Acc@1: 75.0000 (75.4343)  Acc@5: 100.0000 (96.0536)  time: 0.2186  data: 0.0028  max mem: 2500
Test: [Task 1]  [ 340/1627]  eta: 0:04:42  Loss: 0.8903 (1.0286)  Acc@1: 75.0000 (75.4032)  Acc@5: 100.0000 (96.0777)  time: 0.2191  data: 0.0026  max mem: 2500
Test: [Task 1]  [ 350/1627]  eta: 0:04:39  Loss: 0.9277 (1.0299)  Acc@1: 75.0000 (75.3739)  Acc@5: 93.7500 (95.9758)  time: 0.2181  data: 0.0010  max mem: 2500
Test: [Task 1]  [ 360/1627]  eta: 0:04:37  Loss: 0.9277 (1.0289)  Acc@1: 75.0000 (75.4328)  Acc@5: 93.7500 (95.9488)  time: 0.2168  data: 0.0009  max mem: 2500
Test: [Task 1]  [ 370/1627]  eta: 0:04:35  Loss: 0.9506 (1.0289)  Acc@1: 81.2500 (75.3706)  Acc@5: 100.0000 (95.9569)  time: 0.2157  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 380/1627]  eta: 0:04:32  Loss: 0.9737 (1.0272)  Acc@1: 75.0000 (75.4921)  Acc@5: 100.0000 (95.9810)  time: 0.2156  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 390/1627]  eta: 0:04:30  Loss: 0.9633 (1.0287)  Acc@1: 75.0000 (75.5115)  Acc@5: 93.7500 (95.9559)  time: 0.2160  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 400/1627]  eta: 0:04:28  Loss: 1.0586 (1.0297)  Acc@1: 75.0000 (75.4208)  Acc@5: 93.7500 (95.9788)  time: 0.2165  data: 0.0009  max mem: 2500
Test: [Task 1]  [ 410/1627]  eta: 0:04:26  Loss: 0.8939 (1.0292)  Acc@1: 68.7500 (75.4866)  Acc@5: 100.0000 (95.9398)  time: 0.2166  data: 0.0009  max mem: 2500
Test: [Task 1]  [ 420/1627]  eta: 0:04:23  Loss: 0.8785 (1.0274)  Acc@1: 81.2500 (75.6087)  Acc@5: 100.0000 (95.9768)  time: 0.2170  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 430/1627]  eta: 0:04:21  Loss: 0.8471 (1.0253)  Acc@1: 81.2500 (75.6381)  Acc@5: 100.0000 (96.0122)  time: 0.2170  data: 0.0006  max mem: 2500
Test: [Task 1]  [ 440/1627]  eta: 0:04:19  Loss: 0.9999 (1.0239)  Acc@1: 75.0000 (75.6519)  Acc@5: 100.0000 (96.0601)  time: 0.2165  data: 0.0006  max mem: 2500
Test: [Task 1]  [ 450/1627]  eta: 0:04:17  Loss: 1.0606 (1.0269)  Acc@1: 68.7500 (75.4850)  Acc@5: 100.0000 (96.0366)  time: 0.2160  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 460/1627]  eta: 0:04:14  Loss: 1.0753 (1.0268)  Acc@1: 68.7500 (75.4474)  Acc@5: 93.7500 (96.0412)  time: 0.2159  data: 0.0005  max mem: 2500
Test: [Task 1]  [ 470/1627]  eta: 0:04:12  Loss: 0.9582 (1.0244)  Acc@1: 75.0000 (75.4777)  Acc@5: 100.0000 (96.0722)  time: 0.2160  data: 0.0007  max mem: 2500
Test: [Task 1]  [ 480/1627]  eta: 0:04:10  Loss: 0.9775 (1.0282)  Acc@1: 75.0000 (75.3248)  Acc@5: 100.0000 (96.0889)  time: 0.2171  data: 0.0013  max mem: 2500
Test: [Task 1]  [ 490/1627]  eta: 0:04:08  Loss: 1.0351 (1.0293)  Acc@1: 68.7500 (75.2419)  Acc@5: 100.0000 (96.0922)  time: 0.2203  data: 0.0028  max mem: 2500
Test: [Task 1]  [ 500/1627]  eta: 0:04:06  Loss: 0.9343 (1.0307)  Acc@1: 75.0000 (75.1996)  Acc@5: 93.7500 (96.0329)  time: 0.2196  data: 0.0021  max mem: 2500
Test: [Task 1]  [ 510/1627]  eta: 0:04:03  Loss: 1.0455 (1.0353)  Acc@1: 75.0000 (75.1590)  Acc@5: 93.7500 (96.0127)  time: 0.2173  data: 0.0005  max mem: 2500
Test: [Task 1]  [ 520/1627]  eta: 0:04:01  Loss: 1.2017 (1.0419)  Acc@1: 68.7500 (75.0840)  Acc@5: 93.7500 (95.9453)  time: 0.2173  data: 0.0005  max mem: 2500
Test: [Task 1]  [ 530/1627]  eta: 0:03:59  Loss: 1.0239 (1.0380)  Acc@1: 75.0000 (75.2001)  Acc@5: 93.7500 (95.9746)  time: 0.2184  data: 0.0007  max mem: 2500
Test: [Task 1]  [ 540/1627]  eta: 0:03:57  Loss: 0.9722 (1.0386)  Acc@1: 75.0000 (75.2079)  Acc@5: 93.7500 (95.9450)  time: 0.2191  data: 0.0008  max mem: 2500
Test: [Task 1]  [ 550/1627]  eta: 0:03:55  Loss: 1.1237 (1.0400)  Acc@1: 75.0000 (75.1815)  Acc@5: 93.7500 (95.9732)  time: 0.2169  data: 0.0012  max mem: 2500
Test: [Task 1]  [ 560/1627]  eta: 0:03:52  Loss: 1.1607 (1.0424)  Acc@1: 75.0000 (75.1560)  Acc@5: 100.0000 (96.0004)  time: 0.2159  data: 0.0012  max mem: 2500
Test: [Task 1]  [ 570/1627]  eta: 0:03:50  Loss: 1.0369 (1.0394)  Acc@1: 81.2500 (75.2518)  Acc@5: 100.0000 (96.0158)  time: 0.2164  data: 0.0005  max mem: 2500
Test: [Task 1]  [ 580/1627]  eta: 0:03:48  Loss: 0.9688 (1.0401)  Acc@1: 75.0000 (75.1936)  Acc@5: 100.0000 (96.0413)  time: 0.2169  data: 0.0005  max mem: 2500
Test: [Task 1]  [ 590/1627]  eta: 0:03:46  Loss: 1.0090 (1.0395)  Acc@1: 68.7500 (75.1481)  Acc@5: 100.0000 (96.0660)  time: 0.2163  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 600/1627]  eta: 0:03:44  Loss: 0.9928 (1.0407)  Acc@1: 75.0000 (75.1040)  Acc@5: 100.0000 (96.0899)  time: 0.2162  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 610/1627]  eta: 0:03:41  Loss: 0.9928 (1.0394)  Acc@1: 81.2500 (75.2353)  Acc@5: 100.0000 (96.0822)  time: 0.2169  data: 0.0005  max mem: 2500
Test: [Task 1]  [ 620/1627]  eta: 0:03:39  Loss: 0.9404 (1.0403)  Acc@1: 81.2500 (75.2717)  Acc@5: 93.7500 (96.0548)  time: 0.2166  data: 0.0006  max mem: 2500
Test: [Task 1]  [ 630/1627]  eta: 0:03:37  Loss: 0.9250 (1.0403)  Acc@1: 81.2500 (75.2872)  Acc@5: 93.7500 (96.0479)  time: 0.2157  data: 0.0005  max mem: 2500
Test: [Task 1]  [ 640/1627]  eta: 0:03:35  Loss: 0.8503 (1.0400)  Acc@1: 81.2500 (75.2730)  Acc@5: 100.0000 (96.0218)  time: 0.2173  data: 0.0015  max mem: 2500
Test: [Task 1]  [ 650/1627]  eta: 0:03:33  Loss: 0.9607 (1.0389)  Acc@1: 75.0000 (75.2976)  Acc@5: 100.0000 (96.0637)  time: 0.2183  data: 0.0018  max mem: 2500
Test: [Task 1]  [ 660/1627]  eta: 0:03:30  Loss: 0.8880 (1.0373)  Acc@1: 75.0000 (75.3498)  Acc@5: 100.0000 (96.0949)  time: 0.2169  data: 0.0007  max mem: 2500
Test: [Task 1]  [ 670/1627]  eta: 0:03:28  Loss: 0.9942 (1.0378)  Acc@1: 75.0000 (75.3633)  Acc@5: 100.0000 (96.0693)  time: 0.2182  data: 0.0005  max mem: 2500
Test: [Task 1]  [ 680/1627]  eta: 0:03:26  Loss: 1.0278 (1.0379)  Acc@1: 75.0000 (75.3212)  Acc@5: 93.7500 (96.0628)  time: 0.2181  data: 0.0006  max mem: 2500
Test: [Task 1]  [ 690/1627]  eta: 0:03:24  Loss: 0.9390 (1.0360)  Acc@1: 75.0000 (75.3889)  Acc@5: 100.0000 (96.0926)  time: 0.2165  data: 0.0006  max mem: 2500
Test: [Task 1]  [ 700/1627]  eta: 0:03:22  Loss: 1.0163 (1.0365)  Acc@1: 75.0000 (75.4012)  Acc@5: 100.0000 (96.0859)  time: 0.2159  data: 0.0005  max mem: 2500
Test: [Task 1]  [ 710/1627]  eta: 0:03:19  Loss: 0.9315 (1.0344)  Acc@1: 75.0000 (75.4483)  Acc@5: 100.0000 (96.0970)  time: 0.2160  data: 0.0005  max mem: 2500
Test: [Task 1]  [ 720/1627]  eta: 0:03:17  Loss: 0.9222 (1.0324)  Acc@1: 81.2500 (75.5028)  Acc@5: 93.7500 (96.0992)  time: 0.2157  data: 0.0005  max mem: 2500
Test: [Task 1]  [ 730/1627]  eta: 0:03:15  Loss: 0.9438 (1.0336)  Acc@1: 81.2500 (75.4275)  Acc@5: 93.7500 (96.1012)  time: 0.2155  data: 0.0005  max mem: 2500
Test: [Task 1]  [ 740/1627]  eta: 0:03:13  Loss: 1.0443 (1.0351)  Acc@1: 75.0000 (75.4133)  Acc@5: 93.7500 (96.0611)  time: 0.2166  data: 0.0006  max mem: 2500
Test: [Task 1]  [ 750/1627]  eta: 0:03:11  Loss: 0.9548 (1.0342)  Acc@1: 81.2500 (75.5077)  Acc@5: 93.7500 (96.0719)  time: 0.2162  data: 0.0006  max mem: 2500
Test: [Task 1]  [ 760/1627]  eta: 0:03:08  Loss: 0.9918 (1.0372)  Acc@1: 75.0000 (75.4106)  Acc@5: 93.7500 (96.0332)  time: 0.2155  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 770/1627]  eta: 0:03:06  Loss: 0.8359 (1.0340)  Acc@1: 75.0000 (75.5269)  Acc@5: 93.7500 (96.0522)  time: 0.2159  data: 0.0005  max mem: 2500
Test: [Task 1]  [ 780/1627]  eta: 0:03:04  Loss: 0.6935 (1.0322)  Acc@1: 87.5000 (75.6082)  Acc@5: 100.0000 (96.0787)  time: 0.2163  data: 0.0007  max mem: 2500
Test: [Task 1]  [ 790/1627]  eta: 0:03:02  Loss: 0.8265 (1.0344)  Acc@1: 81.2500 (75.5452)  Acc@5: 100.0000 (96.0651)  time: 0.2160  data: 0.0006  max mem: 2500
Test: [Task 1]  [ 800/1627]  eta: 0:03:00  Loss: 0.9082 (1.0332)  Acc@1: 75.0000 (75.5306)  Acc@5: 93.7500 (96.0830)  time: 0.2166  data: 0.0012  max mem: 2500
Test: [Task 1]  [ 810/1627]  eta: 0:02:57  Loss: 0.8995 (1.0325)  Acc@1: 81.2500 (75.6396)  Acc@5: 100.0000 (96.1082)  time: 0.2174  data: 0.0013  max mem: 2500
Test: [Task 1]  [ 820/1627]  eta: 0:02:55  Loss: 0.8459 (1.0311)  Acc@1: 81.2500 (75.6928)  Acc@5: 100.0000 (96.1252)  time: 0.2168  data: 0.0008  max mem: 2500
Test: [Task 1]  [ 830/1627]  eta: 0:02:53  Loss: 0.8445 (1.0311)  Acc@1: 81.2500 (75.6619)  Acc@5: 100.0000 (96.1342)  time: 0.2169  data: 0.0007  max mem: 2500
Test: [Task 1]  [ 840/1627]  eta: 0:02:51  Loss: 0.8927 (1.0288)  Acc@1: 75.0000 (75.6986)  Acc@5: 100.0000 (96.1578)  time: 0.2162  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 850/1627]  eta: 0:02:49  Loss: 0.8982 (1.0297)  Acc@1: 75.0000 (75.6683)  Acc@5: 100.0000 (96.1516)  time: 0.2167  data: 0.0006  max mem: 2500
Test: [Task 1]  [ 860/1627]  eta: 0:02:47  Loss: 0.8982 (1.0291)  Acc@1: 75.0000 (75.7041)  Acc@5: 100.0000 (96.1818)  time: 0.2188  data: 0.0008  max mem: 2500
Test: [Task 1]  [ 870/1627]  eta: 0:02:44  Loss: 0.9289 (1.0275)  Acc@1: 81.2500 (75.7606)  Acc@5: 100.0000 (96.1825)  time: 0.2187  data: 0.0006  max mem: 2500
Test: [Task 1]  [ 880/1627]  eta: 0:02:42  Loss: 1.0095 (1.0295)  Acc@1: 75.0000 (75.6527)  Acc@5: 100.0000 (96.2046)  time: 0.2164  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 890/1627]  eta: 0:02:40  Loss: 1.1576 (1.0311)  Acc@1: 68.7500 (75.6664)  Acc@5: 100.0000 (96.1841)  time: 0.2159  data: 0.0005  max mem: 2500
Test: [Task 1]  [ 900/1627]  eta: 0:02:38  Loss: 1.0634 (1.0319)  Acc@1: 75.0000 (75.6382)  Acc@5: 93.7500 (96.1709)  time: 0.2174  data: 0.0005  max mem: 2500
Test: [Task 1]  [ 910/1627]  eta: 0:02:36  Loss: 1.0226 (1.0323)  Acc@1: 75.0000 (75.7066)  Acc@5: 93.7500 (96.1306)  time: 0.2175  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 920/1627]  eta: 0:02:33  Loss: 0.9657 (1.0317)  Acc@1: 81.2500 (75.7193)  Acc@5: 93.7500 (96.1387)  time: 0.2172  data: 0.0005  max mem: 2500
Test: [Task 1]  [ 930/1627]  eta: 0:02:31  Loss: 0.9835 (1.0321)  Acc@1: 75.0000 (75.6915)  Acc@5: 100.0000 (96.1265)  time: 0.2167  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 940/1627]  eta: 0:02:29  Loss: 0.9890 (1.0310)  Acc@1: 75.0000 (75.7173)  Acc@5: 100.0000 (96.1477)  time: 0.2163  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 950/1627]  eta: 0:02:27  Loss: 1.0783 (1.0317)  Acc@1: 68.7500 (75.6703)  Acc@5: 100.0000 (96.1554)  time: 0.2164  data: 0.0005  max mem: 2500
Test: [Task 1]  [ 960/1627]  eta: 0:02:25  Loss: 1.0345 (1.0312)  Acc@1: 68.7500 (75.6764)  Acc@5: 100.0000 (96.1629)  time: 0.2175  data: 0.0016  max mem: 2500
Test: [Task 1]  [ 970/1627]  eta: 0:02:23  Loss: 0.8595 (1.0304)  Acc@1: 81.2500 (75.7016)  Acc@5: 100.0000 (96.1637)  time: 0.2180  data: 0.0017  max mem: 2500
Test: [Task 1]  [ 980/1627]  eta: 0:02:20  Loss: 1.0515 (1.0311)  Acc@1: 75.0000 (75.6626)  Acc@5: 93.7500 (96.1583)  time: 0.2171  data: 0.0006  max mem: 2500
Test: [Task 1]  [ 990/1627]  eta: 0:02:18  Loss: 1.1359 (1.0336)  Acc@1: 68.7500 (75.6307)  Acc@5: 93.7500 (96.1529)  time: 0.2166  data: 0.0009  max mem: 2500
Test: [Task 1]  [1000/1627]  eta: 0:02:16  Loss: 1.2428 (1.0344)  Acc@1: 81.2500 (75.6369)  Acc@5: 93.7500 (96.1351)  time: 0.2163  data: 0.0009  max mem: 2500
Test: [Task 1]  [1010/1627]  eta: 0:02:14  Loss: 1.0674 (1.0343)  Acc@1: 75.0000 (75.6306)  Acc@5: 93.7500 (96.1239)  time: 0.2168  data: 0.0008  max mem: 2500
Test: [Task 1]  [1020/1627]  eta: 0:02:12  Loss: 0.9916 (1.0342)  Acc@1: 75.0000 (75.5999)  Acc@5: 93.7500 (96.1251)  time: 0.2170  data: 0.0009  max mem: 2500
Test: [Task 1]  [1030/1627]  eta: 0:02:09  Loss: 0.8616 (1.0318)  Acc@1: 81.2500 (75.6668)  Acc@5: 100.0000 (96.1506)  time: 0.2172  data: 0.0006  max mem: 2500
Test: [Task 1]  [1040/1627]  eta: 0:02:07  Loss: 0.7679 (1.0306)  Acc@1: 75.0000 (75.6784)  Acc@5: 100.0000 (96.1695)  time: 0.2172  data: 0.0008  max mem: 2500
Test: [Task 1]  [1050/1627]  eta: 0:02:05  Loss: 0.8875 (1.0293)  Acc@1: 75.0000 (75.6898)  Acc@5: 100.0000 (96.1703)  time: 0.2163  data: 0.0007  max mem: 2500
Test: [Task 1]  [1060/1627]  eta: 0:02:03  Loss: 1.0030 (1.0298)  Acc@1: 75.0000 (75.7010)  Acc@5: 93.7500 (96.1416)  time: 0.2159  data: 0.0010  max mem: 2500
Test: [Task 1]  [1070/1627]  eta: 0:02:01  Loss: 1.0030 (1.0305)  Acc@1: 75.0000 (75.6769)  Acc@5: 93.7500 (96.1310)  time: 0.2167  data: 0.0011  max mem: 2500
Test: [Task 1]  [1080/1627]  eta: 0:01:59  Loss: 0.9936 (1.0308)  Acc@1: 75.0000 (75.6649)  Acc@5: 93.7500 (96.1263)  time: 0.2166  data: 0.0005  max mem: 2500
Test: [Task 1]  [1090/1627]  eta: 0:01:56  Loss: 0.9891 (1.0303)  Acc@1: 75.0000 (75.6989)  Acc@5: 100.0000 (96.1274)  time: 0.2158  data: 0.0004  max mem: 2500
Test: [Task 1]  [1100/1627]  eta: 0:01:54  Loss: 0.8674 (1.0287)  Acc@1: 81.2500 (75.7266)  Acc@5: 100.0000 (96.1342)  time: 0.2168  data: 0.0007  max mem: 2500
Test: [Task 1]  [1110/1627]  eta: 0:01:52  Loss: 0.9526 (1.0291)  Acc@1: 75.0000 (75.7144)  Acc@5: 100.0000 (96.1296)  time: 0.2174  data: 0.0007  max mem: 2500
Test: [Task 1]  [1120/1627]  eta: 0:01:50  Loss: 0.9898 (1.0303)  Acc@1: 75.0000 (75.6635)  Acc@5: 100.0000 (96.1307)  time: 0.2159  data: 0.0004  max mem: 2500
Test: [Task 1]  [1130/1627]  eta: 0:01:48  Loss: 1.0463 (1.0303)  Acc@1: 75.0000 (75.6852)  Acc@5: 93.7500 (96.1262)  time: 0.2180  data: 0.0021  max mem: 2500
Test: [Task 1]  [1140/1627]  eta: 0:01:45  Loss: 1.0463 (1.0314)  Acc@1: 75.0000 (75.6628)  Acc@5: 93.7500 (96.1163)  time: 0.2189  data: 0.0024  max mem: 2500
Test: [Task 1]  [1150/1627]  eta: 0:01:43  Loss: 1.1497 (1.0324)  Acc@1: 75.0000 (75.6190)  Acc@5: 93.7500 (96.1121)  time: 0.2166  data: 0.0008  max mem: 2500
Test: [Task 1]  [1160/1627]  eta: 0:01:41  Loss: 1.1418 (1.0315)  Acc@1: 75.0000 (75.6783)  Acc@5: 100.0000 (96.1240)  time: 0.2169  data: 0.0006  max mem: 2500
Test: [Task 1]  [1170/1627]  eta: 0:01:39  Loss: 0.9944 (1.0309)  Acc@1: 81.2500 (75.7045)  Acc@5: 100.0000 (96.1198)  time: 0.2171  data: 0.0005  max mem: 2500
Test: [Task 1]  [1180/1627]  eta: 0:01:37  Loss: 1.0855 (1.0318)  Acc@1: 75.0000 (75.6933)  Acc@5: 100.0000 (96.1262)  time: 0.2165  data: 0.0008  max mem: 2500
Test: [Task 1]  [1190/1627]  eta: 0:01:35  Loss: 1.0977 (1.0321)  Acc@1: 75.0000 (75.6874)  Acc@5: 93.7500 (96.1115)  time: 0.2158  data: 0.0008  max mem: 2500
Test: [Task 1]  [1200/1627]  eta: 0:01:32  Loss: 1.0491 (1.0321)  Acc@1: 75.0000 (75.6869)  Acc@5: 93.7500 (96.1074)  time: 0.2185  data: 0.0014  max mem: 2500
Test: [Task 1]  [1210/1627]  eta: 0:01:30  Loss: 0.9210 (1.0326)  Acc@1: 75.0000 (75.6709)  Acc@5: 100.0000 (96.1034)  time: 0.2198  data: 0.0016  max mem: 2500
Test: [Task 1]  [1220/1627]  eta: 0:01:28  Loss: 0.9243 (1.0318)  Acc@1: 75.0000 (75.6603)  Acc@5: 100.0000 (96.0995)  time: 0.2172  data: 0.0005  max mem: 2500
Test: [Task 1]  [1230/1627]  eta: 0:01:26  Loss: 1.0520 (1.0320)  Acc@1: 75.0000 (75.6346)  Acc@5: 100.0000 (96.1058)  time: 0.2159  data: 0.0004  max mem: 2500
Test: [Task 1]  [1240/1627]  eta: 0:01:24  Loss: 0.9574 (1.0311)  Acc@1: 75.0000 (75.6698)  Acc@5: 100.0000 (96.1070)  time: 0.2157  data: 0.0006  max mem: 2500
Test: [Task 1]  [1250/1627]  eta: 0:01:21  Loss: 0.9574 (1.0312)  Acc@1: 81.2500 (75.6845)  Acc@5: 100.0000 (96.1081)  time: 0.2164  data: 0.0011  max mem: 2500
Test: [Task 1]  [1260/1627]  eta: 0:01:19  Loss: 1.0478 (1.0309)  Acc@1: 81.2500 (75.7286)  Acc@5: 93.7500 (96.1043)  time: 0.2167  data: 0.0010  max mem: 2500
Test: [Task 1]  [1270/1627]  eta: 0:01:17  Loss: 1.0410 (1.0314)  Acc@1: 75.0000 (75.7179)  Acc@5: 93.7500 (96.1005)  time: 0.2153  data: 0.0004  max mem: 2500
Test: [Task 1]  [1280/1627]  eta: 0:01:15  Loss: 0.8711 (1.0297)  Acc@1: 75.0000 (75.7562)  Acc@5: 100.0000 (96.1114)  time: 0.2159  data: 0.0004  max mem: 2500
Test: [Task 1]  [1290/1627]  eta: 0:01:13  Loss: 0.9669 (1.0298)  Acc@1: 75.0000 (75.7407)  Acc@5: 100.0000 (96.1222)  time: 0.2176  data: 0.0014  max mem: 2500
Test: [Task 1]  [1300/1627]  eta: 0:01:11  Loss: 0.9699 (1.0293)  Acc@1: 75.0000 (75.7734)  Acc@5: 100.0000 (96.1184)  time: 0.2174  data: 0.0016  max mem: 2500
Test: [Task 1]  [1310/1627]  eta: 0:01:08  Loss: 0.8300 (1.0279)  Acc@1: 81.2500 (75.8009)  Acc@5: 93.7500 (96.1194)  time: 0.2163  data: 0.0005  max mem: 2500
Test: [Task 1]  [1320/1627]  eta: 0:01:06  Loss: 0.7792 (1.0264)  Acc@1: 81.2500 (75.8611)  Acc@5: 100.0000 (96.1346)  time: 0.2157  data: 0.0005  max mem: 2500
Test: [Task 1]  [1330/1627]  eta: 0:01:04  Loss: 0.8634 (1.0261)  Acc@1: 81.2500 (75.8781)  Acc@5: 100.0000 (96.1307)  time: 0.2161  data: 0.0007  max mem: 2500
Test: [Task 1]  [1340/1627]  eta: 0:01:02  Loss: 1.0129 (1.0272)  Acc@1: 75.0000 (75.8249)  Acc@5: 93.7500 (96.1223)  time: 0.2165  data: 0.0008  max mem: 2500
Test: [Task 1]  [1350/1627]  eta: 0:01:00  Loss: 0.9818 (1.0267)  Acc@1: 75.0000 (75.8235)  Acc@5: 100.0000 (96.1371)  time: 0.2162  data: 0.0006  max mem: 2500
Test: [Task 1]  [1360/1627]  eta: 0:00:58  Loss: 0.9301 (1.0261)  Acc@1: 75.0000 (75.8496)  Acc@5: 100.0000 (96.1425)  time: 0.2165  data: 0.0012  max mem: 2500
Test: [Task 1]  [1370/1627]  eta: 0:00:55  Loss: 0.8771 (1.0254)  Acc@1: 75.0000 (75.8525)  Acc@5: 100.0000 (96.1570)  time: 0.2166  data: 0.0011  max mem: 2500
Test: [Task 1]  [1380/1627]  eta: 0:00:53  Loss: 0.9785 (1.0258)  Acc@1: 75.0000 (75.8282)  Acc@5: 100.0000 (96.1441)  time: 0.2168  data: 0.0006  max mem: 2500
Test: [Task 1]  [1390/1627]  eta: 0:00:51  Loss: 1.0904 (1.0252)  Acc@1: 68.7500 (75.8223)  Acc@5: 93.7500 (96.1538)  time: 0.2171  data: 0.0006  max mem: 2500
Test: [Task 1]  [1400/1627]  eta: 0:00:49  Loss: 0.9828 (1.0255)  Acc@1: 68.7500 (75.8164)  Acc@5: 93.7500 (96.1411)  time: 0.2174  data: 0.0008  max mem: 2500
Test: [Task 1]  [1410/1627]  eta: 0:00:47  Loss: 0.8521 (1.0248)  Acc@1: 75.0000 (75.8283)  Acc@5: 100.0000 (96.1508)  time: 0.2175  data: 0.0007  max mem: 2500
Test: [Task 1]  [1420/1627]  eta: 0:00:45  Loss: 0.9165 (1.0243)  Acc@1: 75.0000 (75.8445)  Acc@5: 100.0000 (96.1603)  time: 0.2176  data: 0.0005  max mem: 2500
Test: [Task 1]  [1430/1627]  eta: 0:00:42  Loss: 1.1001 (1.0260)  Acc@1: 75.0000 (75.8124)  Acc@5: 93.7500 (96.1260)  time: 0.2179  data: 0.0005  max mem: 2500
Test: [Task 1]  [1440/1627]  eta: 0:00:40  Loss: 1.0027 (1.0257)  Acc@1: 75.0000 (75.8111)  Acc@5: 93.7500 (96.1312)  time: 0.2176  data: 0.0017  max mem: 2500
Test: [Task 1]  [1450/1627]  eta: 0:00:38  Loss: 1.0503 (1.0270)  Acc@1: 68.7500 (75.7624)  Acc@5: 93.7500 (96.1104)  time: 0.2172  data: 0.0022  max mem: 2500
Test: [Task 1]  [1460/1627]  eta: 0:00:36  Loss: 1.1396 (1.0274)  Acc@1: 68.7500 (75.7401)  Acc@5: 93.7500 (96.0986)  time: 0.2178  data: 0.0009  max mem: 2500
Test: [Task 1]  [1470/1627]  eta: 0:00:34  Loss: 1.0139 (1.0277)  Acc@1: 68.7500 (75.7138)  Acc@5: 100.0000 (96.0953)  time: 0.2184  data: 0.0006  max mem: 2500
Test: [Task 1]  [1480/1627]  eta: 0:00:31  Loss: 1.1172 (1.0283)  Acc@1: 68.7500 (75.7005)  Acc@5: 93.7500 (96.0795)  time: 0.2181  data: 0.0011  max mem: 2500
Test: [Task 1]  [1490/1627]  eta: 0:00:29  Loss: 1.1311 (1.0287)  Acc@1: 75.0000 (75.7168)  Acc@5: 93.7500 (96.0807)  time: 0.2173  data: 0.0011  max mem: 2500
Test: [Task 1]  [1500/1627]  eta: 0:00:27  Loss: 1.1311 (1.0291)  Acc@1: 75.0000 (75.7079)  Acc@5: 93.7500 (96.0693)  time: 0.2159  data: 0.0005  max mem: 2500
Test: [Task 1]  [1510/1627]  eta: 0:00:25  Loss: 0.8464 (1.0294)  Acc@1: 75.0000 (75.6866)  Acc@5: 93.7500 (96.0622)  time: 0.2160  data: 0.0005  max mem: 2500
Test: [Task 1]  [1520/1627]  eta: 0:00:23  Loss: 0.8464 (1.0281)  Acc@1: 75.0000 (75.7191)  Acc@5: 100.0000 (96.0717)  time: 0.2184  data: 0.0005  max mem: 2500
Test: [Task 1]  [1530/1627]  eta: 0:00:21  Loss: 0.8422 (1.0275)  Acc@1: 81.2500 (75.7103)  Acc@5: 100.0000 (96.0810)  time: 0.2196  data: 0.0010  max mem: 2500
Test: [Task 1]  [1540/1627]  eta: 0:00:18  Loss: 0.8013 (1.0265)  Acc@1: 81.2500 (75.7138)  Acc@5: 100.0000 (96.1024)  time: 0.2183  data: 0.0010  max mem: 2500
Test: [Task 1]  [1550/1627]  eta: 0:00:16  Loss: 0.7964 (1.0261)  Acc@1: 81.2500 (75.7415)  Acc@5: 100.0000 (96.1033)  time: 0.2184  data: 0.0010  max mem: 2500
Test: [Task 1]  [1560/1627]  eta: 0:00:14  Loss: 0.7808 (1.0253)  Acc@1: 81.2500 (75.7687)  Acc@5: 100.0000 (96.1083)  time: 0.2178  data: 0.0010  max mem: 2500
Test: [Task 1]  [1570/1627]  eta: 0:00:12  Loss: 0.8662 (1.0254)  Acc@1: 81.2500 (75.7917)  Acc@5: 100.0000 (96.1012)  time: 0.2162  data: 0.0005  max mem: 2500
Test: [Task 1]  [1580/1627]  eta: 0:00:10  Loss: 0.9596 (1.0253)  Acc@1: 81.2500 (75.8025)  Acc@5: 100.0000 (96.1022)  time: 0.2157  data: 0.0005  max mem: 2500
Test: [Task 1]  [1590/1627]  eta: 0:00:08  Loss: 0.9596 (1.0250)  Acc@1: 75.0000 (75.7896)  Acc@5: 100.0000 (96.1109)  time: 0.2166  data: 0.0005  max mem: 2500
Test: [Task 1]  [1600/1627]  eta: 0:00:05  Loss: 1.0307 (1.0260)  Acc@1: 75.0000 (75.7456)  Acc@5: 93.7500 (96.1079)  time: 0.2173  data: 0.0005  max mem: 2500
Test: [Task 1]  [1610/1627]  eta: 0:00:03  Loss: 0.9944 (1.0255)  Acc@1: 75.0000 (75.7682)  Acc@5: 93.7500 (96.1127)  time: 0.2165  data: 0.0005  max mem: 2500
Test: [Task 1]  [1620/1627]  eta: 0:00:01  Loss: 0.9321 (1.0245)  Acc@1: 81.2500 (75.8097)  Acc@5: 93.7500 (96.1097)  time: 0.2160  data: 0.0004  max mem: 2500
Test: [Task 1]  [1626/1627]  eta: 0:00:00  Loss: 0.9321 (1.0240)  Acc@1: 81.2500 (75.8451)  Acc@5: 93.7500 (96.1010)  time: 0.2162  data: 0.0003  max mem: 2500
Test: [Task 1] Total time: 0:05:54 (0.2176 s / it)
* Acc@1 75.845 Acc@5 96.101 loss 1.024
Test: [Task 2]  [  0/625]  eta: 0:08:09  Loss: 0.2892 (0.2892)  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (100.0000)  time: 0.7832  data: 0.5618  max mem: 2500
Test: [Task 2]  [ 10/625]  eta: 0:02:44  Loss: 0.2079 (0.2497)  Acc@1: 93.7500 (93.7500)  Acc@5: 100.0000 (99.4318)  time: 0.2675  data: 0.0514  max mem: 2500
Test: [Task 2]  [ 20/625]  eta: 0:02:26  Loss: 0.2079 (0.2744)  Acc@1: 93.7500 (92.2619)  Acc@5: 100.0000 (99.7024)  time: 0.2156  data: 0.0004  max mem: 2500
Test: [Task 2]  [ 30/625]  eta: 0:02:19  Loss: 0.3035 (0.2954)  Acc@1: 93.7500 (91.3306)  Acc@5: 100.0000 (99.5968)  time: 0.2167  data: 0.0007  max mem: 2500
Test: [Task 2]  [ 40/625]  eta: 0:02:14  Loss: 0.3035 (0.3115)  Acc@1: 93.7500 (91.1585)  Acc@5: 100.0000 (99.6951)  time: 0.2178  data: 0.0007  max mem: 2500
Test: [Task 2]  [ 50/625]  eta: 0:02:10  Loss: 0.3379 (0.3296)  Acc@1: 87.5000 (90.4412)  Acc@5: 100.0000 (99.7549)  time: 0.2169  data: 0.0005  max mem: 2500
Test: [Task 2]  [ 60/625]  eta: 0:02:07  Loss: 0.3443 (0.3347)  Acc@1: 87.5000 (90.1639)  Acc@5: 100.0000 (99.6926)  time: 0.2168  data: 0.0010  max mem: 2500
Test: [Task 2]  [ 70/625]  eta: 0:02:04  Loss: 0.3330 (0.3317)  Acc@1: 87.5000 (90.0528)  Acc@5: 100.0000 (99.6479)  time: 0.2167  data: 0.0010  max mem: 2500
Test: [Task 2]  [ 80/625]  eta: 0:02:02  Loss: 0.2876 (0.3385)  Acc@1: 87.5000 (89.8148)  Acc@5: 100.0000 (99.5370)  time: 0.2174  data: 0.0006  max mem: 2500
Test: [Task 2]  [ 90/625]  eta: 0:01:59  Loss: 0.2778 (0.3317)  Acc@1: 93.7500 (90.2473)  Acc@5: 100.0000 (99.5879)  time: 0.2187  data: 0.0005  max mem: 2500
Test: [Task 2]  [100/625]  eta: 0:01:56  Loss: 0.2725 (0.3243)  Acc@1: 93.7500 (90.5941)  Acc@5: 100.0000 (99.5668)  time: 0.2164  data: 0.0004  max mem: 2500
Test: [Task 2]  [110/625]  eta: 0:01:54  Loss: 0.2841 (0.3271)  Acc@1: 93.7500 (90.5968)  Acc@5: 100.0000 (99.4932)  time: 0.2153  data: 0.0005  max mem: 2500
Test: [Task 2]  [120/625]  eta: 0:01:51  Loss: 0.3410 (0.3284)  Acc@1: 87.5000 (90.4442)  Acc@5: 100.0000 (99.4835)  time: 0.2165  data: 0.0005  max mem: 2500
Test: [Task 2]  [130/625]  eta: 0:01:49  Loss: 0.3314 (0.3280)  Acc@1: 87.5000 (90.4580)  Acc@5: 100.0000 (99.5229)  time: 0.2159  data: 0.0004  max mem: 2500
Test: [Task 2]  [140/625]  eta: 0:01:47  Loss: 0.2783 (0.3304)  Acc@1: 93.7500 (90.2039)  Acc@5: 100.0000 (99.5567)  time: 0.2171  data: 0.0008  max mem: 2500
Test: [Task 2]  [150/625]  eta: 0:01:44  Loss: 0.2917 (0.3336)  Acc@1: 87.5000 (89.9421)  Acc@5: 100.0000 (99.5447)  time: 0.2175  data: 0.0008  max mem: 2500
Test: [Task 2]  [160/625]  eta: 0:01:42  Loss: 0.3230 (0.3358)  Acc@1: 87.5000 (89.9068)  Acc@5: 100.0000 (99.5730)  time: 0.2168  data: 0.0012  max mem: 2500
Test: [Task 2]  [170/625]  eta: 0:01:40  Loss: 0.3045 (0.3342)  Acc@1: 87.5000 (89.9488)  Acc@5: 100.0000 (99.5614)  time: 0.2165  data: 0.0014  max mem: 2500
Test: [Task 2]  [180/625]  eta: 0:01:37  Loss: 0.2780 (0.3317)  Acc@1: 93.7500 (90.0552)  Acc@5: 100.0000 (99.5856)  time: 0.2173  data: 0.0006  max mem: 2500
Test: [Task 2]  [190/625]  eta: 0:01:35  Loss: 0.3622 (0.3363)  Acc@1: 87.5000 (89.9542)  Acc@5: 100.0000 (99.5746)  time: 0.2184  data: 0.0005  max mem: 2500
Test: [Task 2]  [200/625]  eta: 0:01:33  Loss: 0.3865 (0.3369)  Acc@1: 87.5000 (89.8943)  Acc@5: 100.0000 (99.5958)  time: 0.2172  data: 0.0012  max mem: 2500
Test: [Task 2]  [210/625]  eta: 0:01:31  Loss: 0.3218 (0.3399)  Acc@1: 87.5000 (89.7808)  Acc@5: 100.0000 (99.5853)  time: 0.2177  data: 0.0013  max mem: 2500
Test: [Task 2]  [220/625]  eta: 0:01:28  Loss: 0.2548 (0.3362)  Acc@1: 93.7500 (89.9604)  Acc@5: 100.0000 (99.6041)  time: 0.2181  data: 0.0005  max mem: 2500
Test: [Task 2]  [230/625]  eta: 0:01:26  Loss: 0.2548 (0.3339)  Acc@1: 93.7500 (90.0162)  Acc@5: 100.0000 (99.6212)  time: 0.2169  data: 0.0005  max mem: 2500
Test: [Task 2]  [240/625]  eta: 0:01:24  Loss: 0.3089 (0.3339)  Acc@1: 87.5000 (90.0156)  Acc@5: 100.0000 (99.6110)  time: 0.2161  data: 0.0005  max mem: 2500
Test: [Task 2]  [250/625]  eta: 0:01:22  Loss: 0.3281 (0.3354)  Acc@1: 87.5000 (90.0647)  Acc@5: 100.0000 (99.5767)  time: 0.2163  data: 0.0005  max mem: 2500
Test: [Task 2]  [260/625]  eta: 0:01:19  Loss: 0.3722 (0.3363)  Acc@1: 87.5000 (90.0383)  Acc@5: 100.0000 (99.5450)  time: 0.2166  data: 0.0004  max mem: 2500
Test: [Task 2]  [270/625]  eta: 0:01:17  Loss: 0.3782 (0.3361)  Acc@1: 87.5000 (89.9908)  Acc@5: 100.0000 (99.5387)  time: 0.2155  data: 0.0004  max mem: 2500
Test: [Task 2]  [280/625]  eta: 0:01:15  Loss: 0.3558 (0.3370)  Acc@1: 87.5000 (89.9021)  Acc@5: 100.0000 (99.5329)  time: 0.2182  data: 0.0009  max mem: 2500
Test: [Task 2]  [290/625]  eta: 0:01:13  Loss: 0.3558 (0.3372)  Acc@1: 87.5000 (89.9485)  Acc@5: 100.0000 (99.5275)  time: 0.2191  data: 0.0009  max mem: 2500
Test: [Task 2]  [300/625]  eta: 0:01:11  Loss: 0.3223 (0.3382)  Acc@1: 87.5000 (89.8256)  Acc@5: 100.0000 (99.5432)  time: 0.2167  data: 0.0005  max mem: 2500
Test: [Task 2]  [310/625]  eta: 0:01:08  Loss: 0.3317 (0.3394)  Acc@1: 87.5000 (89.7106)  Acc@5: 100.0000 (99.5378)  time: 0.2157  data: 0.0005  max mem: 2500
Test: [Task 2]  [320/625]  eta: 0:01:06  Loss: 0.1864 (0.3322)  Acc@1: 93.7500 (89.9533)  Acc@5: 100.0000 (99.5522)  time: 0.2154  data: 0.0004  max mem: 2500
Test: [Task 2]  [330/625]  eta: 0:01:04  Loss: 0.1336 (0.3296)  Acc@1: 93.7500 (89.9924)  Acc@5: 100.0000 (99.5657)  time: 0.2156  data: 0.0004  max mem: 2500
Test: [Task 2]  [340/625]  eta: 0:01:02  Loss: 0.1330 (0.3226)  Acc@1: 100.0000 (90.2676)  Acc@5: 100.0000 (99.5784)  time: 0.2161  data: 0.0006  max mem: 2500
Test: [Task 2]  [350/625]  eta: 0:01:00  Loss: 0.1239 (0.3201)  Acc@1: 100.0000 (90.2778)  Acc@5: 100.0000 (99.5905)  time: 0.2160  data: 0.0006  max mem: 2500
Test: [Task 2]  [360/625]  eta: 0:00:57  Loss: 0.3351 (0.3220)  Acc@1: 87.5000 (90.2008)  Acc@5: 100.0000 (99.5845)  time: 0.2151  data: 0.0004  max mem: 2500
Test: [Task 2]  [370/625]  eta: 0:00:55  Loss: 0.2683 (0.3197)  Acc@1: 93.7500 (90.2796)  Acc@5: 100.0000 (99.5957)  time: 0.2153  data: 0.0003  max mem: 2500
Test: [Task 2]  [380/625]  eta: 0:00:53  Loss: 0.2697 (0.3222)  Acc@1: 93.7500 (90.1903)  Acc@5: 100.0000 (99.5571)  time: 0.2157  data: 0.0004  max mem: 2500
Test: [Task 2]  [390/625]  eta: 0:00:51  Loss: 0.2169 (0.3202)  Acc@1: 93.7500 (90.2494)  Acc@5: 100.0000 (99.5524)  time: 0.2163  data: 0.0009  max mem: 2500
Test: [Task 2]  [400/625]  eta: 0:00:49  Loss: 0.1265 (0.3155)  Acc@1: 93.7500 (90.3990)  Acc@5: 100.0000 (99.5636)  time: 0.2165  data: 0.0009  max mem: 2500
Test: [Task 2]  [410/625]  eta: 0:00:46  Loss: 0.0963 (0.3137)  Acc@1: 100.0000 (90.5109)  Acc@5: 100.0000 (99.5438)  time: 0.2167  data: 0.0005  max mem: 2500
Test: [Task 2]  [420/625]  eta: 0:00:44  Loss: 0.1099 (0.3127)  Acc@1: 100.0000 (90.5879)  Acc@5: 100.0000 (99.5546)  time: 0.2164  data: 0.0004  max mem: 2500
Test: [Task 2]  [430/625]  eta: 0:00:42  Loss: 0.2122 (0.3110)  Acc@1: 93.7500 (90.6323)  Acc@5: 100.0000 (99.5650)  time: 0.2161  data: 0.0005  max mem: 2500
Test: [Task 2]  [440/625]  eta: 0:00:40  Loss: 0.1450 (0.3066)  Acc@1: 93.7500 (90.7738)  Acc@5: 100.0000 (99.5748)  time: 0.2169  data: 0.0010  max mem: 2500
Test: [Task 2]  [450/625]  eta: 0:00:38  Loss: 0.1148 (0.3023)  Acc@1: 93.7500 (90.8675)  Acc@5: 100.0000 (99.5843)  time: 0.2171  data: 0.0010  max mem: 2500
Test: [Task 2]  [460/625]  eta: 0:00:35  Loss: 0.1240 (0.2987)  Acc@1: 100.0000 (91.0385)  Acc@5: 100.0000 (99.5933)  time: 0.2161  data: 0.0004  max mem: 2500
Test: [Task 2]  [470/625]  eta: 0:00:33  Loss: 0.1315 (0.2959)  Acc@1: 100.0000 (91.1757)  Acc@5: 100.0000 (99.6019)  time: 0.2162  data: 0.0005  max mem: 2500
Test: [Task 2]  [480/625]  eta: 0:00:31  Loss: 0.1548 (0.2935)  Acc@1: 93.7500 (91.2682)  Acc@5: 100.0000 (99.6102)  time: 0.2173  data: 0.0007  max mem: 2500
Test: [Task 2]  [490/625]  eta: 0:00:29  Loss: 0.1398 (0.2908)  Acc@1: 100.0000 (91.3951)  Acc@5: 100.0000 (99.6181)  time: 0.2173  data: 0.0013  max mem: 2500
Test: [Task 2]  [500/625]  eta: 0:00:27  Loss: 0.1159 (0.2881)  Acc@1: 100.0000 (91.5045)  Acc@5: 100.0000 (99.6257)  time: 0.2164  data: 0.0011  max mem: 2500
Test: [Task 2]  [510/625]  eta: 0:00:25  Loss: 0.1341 (0.2910)  Acc@1: 93.7500 (91.4017)  Acc@5: 100.0000 (99.6331)  time: 0.2162  data: 0.0004  max mem: 2500
Test: [Task 2]  [520/625]  eta: 0:00:22  Loss: 0.1930 (0.2907)  Acc@1: 93.7500 (91.4227)  Acc@5: 100.0000 (99.6401)  time: 0.2177  data: 0.0011  max mem: 2500
Test: [Task 2]  [530/625]  eta: 0:00:20  Loss: 0.1743 (0.2883)  Acc@1: 93.7500 (91.5137)  Acc@5: 100.0000 (99.6469)  time: 0.2172  data: 0.0011  max mem: 2500
Test: [Task 2]  [540/625]  eta: 0:00:18  Loss: 0.1389 (0.2864)  Acc@1: 93.7500 (91.5896)  Acc@5: 100.0000 (99.6534)  time: 0.2160  data: 0.0005  max mem: 2500
Test: [Task 2]  [550/625]  eta: 0:00:16  Loss: 0.1035 (0.2828)  Acc@1: 100.0000 (91.7083)  Acc@5: 100.0000 (99.6597)  time: 0.2160  data: 0.0005  max mem: 2500
Test: [Task 2]  [560/625]  eta: 0:00:14  Loss: 0.0520 (0.2786)  Acc@1: 100.0000 (91.8561)  Acc@5: 100.0000 (99.6658)  time: 0.2161  data: 0.0005  max mem: 2500
Test: [Task 2]  [570/625]  eta: 0:00:11  Loss: 0.0520 (0.2778)  Acc@1: 100.0000 (91.8783)  Acc@5: 100.0000 (99.6716)  time: 0.2163  data: 0.0006  max mem: 2500
Test: [Task 2]  [580/625]  eta: 0:00:09  Loss: 0.1127 (0.2750)  Acc@1: 100.0000 (91.9750)  Acc@5: 100.0000 (99.6773)  time: 0.2163  data: 0.0006  max mem: 2500
Test: [Task 2]  [590/625]  eta: 0:00:07  Loss: 0.1166 (0.2727)  Acc@1: 100.0000 (92.1003)  Acc@5: 100.0000 (99.6827)  time: 0.2162  data: 0.0007  max mem: 2500
Test: [Task 2]  [600/625]  eta: 0:00:05  Loss: 0.1674 (0.2717)  Acc@1: 100.0000 (92.1485)  Acc@5: 100.0000 (99.6880)  time: 0.2159  data: 0.0009  max mem: 2500
Test: [Task 2]  [610/625]  eta: 0:00:03  Loss: 0.2415 (0.2735)  Acc@1: 93.7500 (92.1236)  Acc@5: 100.0000 (99.6420)  time: 0.2187  data: 0.0018  max mem: 2500
Test: [Task 2]  [620/625]  eta: 0:00:01  Loss: 0.3294 (0.2743)  Acc@1: 87.5000 (92.1196)  Acc@5: 100.0000 (99.6477)  time: 0.2201  data: 0.0023  max mem: 2500
Test: [Task 2]  [624/625]  eta: 0:00:00  Loss: 0.2422 (0.2738)  Acc@1: 93.7500 (92.1100)  Acc@5: 100.0000 (99.6500)  time: 0.2190  data: 0.0016  max mem: 2500
Test: [Task 2] Total time: 0:02:16 (0.2181 s / it)
* Acc@1 92.110 Acc@5 99.650 loss 0.274
{0: {0: 26032, 1: 26032, 2: 26032, 3: 26032, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0, 10: 0, 11: 0, 12: 0, 13: 0, 14: 0, 15: 0, 16: 0, 17: 0, 18: 0, 19: 0}, 1: {0: 0, 1: 0, 2: 0, 3: 0, 4: 10000, 5: 10000, 6: 10000, 7: 10000, 8: 0, 9: 0, 10: 0, 11: 0, 12: 0, 13: 0, 14: 0, 15: 0, 16: 0, 17: 0, 18: 0, 19: 0}}
[Average accuracy till task2]	Acc@1: 83.9776	Acc@5: 97.8755	Loss: 0.6489	Forgetting: 10.0338	Backward: -10.0338
Transfering parameters  (slice(8, 12, None), slice(4, 8, None))
Train: Epoch[1/5]  [   0/3125]  eta: 0:36:23  Lr: 0.001875  Loss: 1.5927  Acc@1: 6.2500 (6.2500)  Acc@5: 56.2500 (56.2500)  time: 0.6987  data: 0.3357  max mem: 2500
Train: Epoch[1/5]  [  10/3125]  eta: 0:19:53  Lr: 0.001875  Loss: 1.4767  Acc@1: 25.0000 (21.0227)  Acc@5: 62.5000 (60.7955)  time: 0.3832  data: 0.0311  max mem: 2501
Train: Epoch[1/5]  [  20/3125]  eta: 0:18:55  Lr: 0.001875  Loss: 1.3408  Acc@1: 31.2500 (32.4405)  Acc@5: 68.7500 (71.4286)  time: 0.3492  data: 0.0006  max mem: 2501
Train: Epoch[1/5]  [  30/3125]  eta: 0:18:33  Lr: 0.001875  Loss: 1.1342  Acc@1: 50.0000 (38.9113)  Acc@5: 87.5000 (77.2177)  time: 0.3468  data: 0.0006  max mem: 2501
Train: Epoch[1/5]  [  40/3125]  eta: 0:18:20  Lr: 0.001875  Loss: 0.7991  Acc@1: 56.2500 (44.8171)  Acc@5: 93.7500 (81.0976)  time: 0.3470  data: 0.0007  max mem: 2501
Train: Epoch[1/5]  [  50/3125]  eta: 0:18:10  Lr: 0.001875  Loss: 0.5988  Acc@1: 68.7500 (50.0000)  Acc@5: 93.7500 (84.0686)  time: 0.3469  data: 0.0005  max mem: 2501
Train: Epoch[1/5]  [  60/3125]  eta: 0:18:05  Lr: 0.001875  Loss: 0.8889  Acc@1: 68.7500 (52.0492)  Acc@5: 93.7500 (85.2459)  time: 0.3488  data: 0.0017  max mem: 2501
Train: Epoch[1/5]  [  70/3125]  eta: 0:17:57  Lr: 0.001875  Loss: 0.5642  Acc@1: 68.7500 (54.6655)  Acc@5: 93.7500 (87.0599)  time: 0.3480  data: 0.0017  max mem: 2501
Train: Epoch[1/5]  [  80/3125]  eta: 0:17:52  Lr: 0.001875  Loss: 0.4516  Acc@1: 68.7500 (56.4043)  Acc@5: 100.0000 (87.8858)  time: 0.3459  data: 0.0005  max mem: 2501
Train: Epoch[1/5]  [  90/3125]  eta: 0:17:47  Lr: 0.001875  Loss: 0.2018  Acc@1: 68.7500 (57.7610)  Acc@5: 93.7500 (88.7363)  time: 0.3476  data: 0.0007  max mem: 2501
Train: Epoch[1/5]  [ 100/3125]  eta: 0:17:43  Lr: 0.001875  Loss: 0.1298  Acc@1: 75.0000 (60.0248)  Acc@5: 93.7500 (89.4802)  time: 0.3488  data: 0.0008  max mem: 2501
Train: Epoch[1/5]  [ 110/3125]  eta: 0:17:38  Lr: 0.001875  Loss: 0.3076  Acc@1: 81.2500 (61.3739)  Acc@5: 100.0000 (90.1464)  time: 0.3474  data: 0.0006  max mem: 2501
Train: Epoch[1/5]  [ 120/3125]  eta: 0:17:33  Lr: 0.001875  Loss: 0.2431  Acc@1: 75.0000 (62.3967)  Acc@5: 93.7500 (90.4442)  time: 0.3470  data: 0.0006  max mem: 2501
Train: Epoch[1/5]  [ 130/3125]  eta: 0:17:29  Lr: 0.001875  Loss: 0.1645  Acc@1: 75.0000 (63.2634)  Acc@5: 93.7500 (90.8397)  time: 0.3479  data: 0.0005  max mem: 2501
Train: Epoch[1/5]  [ 140/3125]  eta: 0:17:25  Lr: 0.001875  Loss: 0.0915  Acc@1: 81.2500 (64.6277)  Acc@5: 100.0000 (91.1791)  time: 0.3471  data: 0.0007  max mem: 2501
Train: Epoch[1/5]  [ 150/3125]  eta: 0:17:21  Lr: 0.001875  Loss: -0.3874  Acc@1: 81.2500 (65.6457)  Acc@5: 100.0000 (91.6805)  time: 0.3480  data: 0.0007  max mem: 2501
Train: Epoch[1/5]  [ 160/3125]  eta: 0:17:17  Lr: 0.001875  Loss: -0.1801  Acc@1: 75.0000 (66.3043)  Acc@5: 93.7500 (91.8478)  time: 0.3485  data: 0.0009  max mem: 2501
Train: Epoch[1/5]  [ 170/3125]  eta: 0:17:13  Lr: 0.001875  Loss: -0.0693  Acc@1: 75.0000 (66.9591)  Acc@5: 93.7500 (92.0322)  time: 0.3470  data: 0.0008  max mem: 2501
Train: Epoch[1/5]  [ 180/3125]  eta: 0:17:09  Lr: 0.001875  Loss: 0.1463  Acc@1: 75.0000 (67.6450)  Acc@5: 93.7500 (92.2652)  time: 0.3465  data: 0.0005  max mem: 2501
Train: Epoch[1/5]  [ 190/3125]  eta: 0:17:06  Lr: 0.001875  Loss: -0.0561  Acc@1: 75.0000 (67.8010)  Acc@5: 93.7500 (92.4411)  time: 0.3484  data: 0.0008  max mem: 2501
Train: Epoch[1/5]  [ 200/3125]  eta: 0:17:02  Lr: 0.001875  Loss: 0.0850  Acc@1: 75.0000 (68.3769)  Acc@5: 100.0000 (92.7239)  time: 0.3491  data: 0.0008  max mem: 2501
Train: Epoch[1/5]  [ 210/3125]  eta: 0:16:58  Lr: 0.001875  Loss: -0.3094  Acc@1: 81.2500 (68.9573)  Acc@5: 100.0000 (92.9799)  time: 0.3470  data: 0.0005  max mem: 2501
Train: Epoch[1/5]  [ 220/3125]  eta: 0:16:54  Lr: 0.001875  Loss: 0.1667  Acc@1: 81.2500 (69.4005)  Acc@5: 100.0000 (93.2127)  time: 0.3471  data: 0.0005  max mem: 2501
Train: Epoch[1/5]  [ 230/3125]  eta: 0:16:51  Lr: 0.001875  Loss: -0.1723  Acc@1: 81.2500 (69.8052)  Acc@5: 100.0000 (93.3442)  time: 0.3478  data: 0.0005  max mem: 2501
Train: Epoch[1/5]  [ 240/3125]  eta: 0:16:47  Lr: 0.001875  Loss: -0.1651  Acc@1: 81.2500 (70.3320)  Acc@5: 100.0000 (93.5685)  time: 0.3472  data: 0.0005  max mem: 2501
Train: Epoch[1/5]  [ 250/3125]  eta: 0:16:43  Lr: 0.001875  Loss: -0.0155  Acc@1: 75.0000 (70.4681)  Acc@5: 100.0000 (93.7251)  time: 0.3478  data: 0.0006  max mem: 2501
Train: Epoch[1/5]  [ 260/3125]  eta: 0:16:39  Lr: 0.001875  Loss: -0.1471  Acc@1: 75.0000 (70.7615)  Acc@5: 100.0000 (93.8937)  time: 0.3473  data: 0.0007  max mem: 2501
Train: Epoch[1/5]  [ 270/3125]  eta: 0:16:36  Lr: 0.001875  Loss: -0.0655  Acc@1: 81.2500 (71.1255)  Acc@5: 100.0000 (94.0959)  time: 0.3467  data: 0.0007  max mem: 2501
Train: Epoch[1/5]  [ 280/3125]  eta: 0:16:32  Lr: 0.001875  Loss: 0.0197  Acc@1: 75.0000 (71.1966)  Acc@5: 100.0000 (94.1504)  time: 0.3479  data: 0.0009  max mem: 2501
Train: Epoch[1/5]  [ 290/3125]  eta: 0:16:28  Lr: 0.001875  Loss: -0.3036  Acc@1: 75.0000 (71.4777)  Acc@5: 100.0000 (94.2869)  time: 0.3471  data: 0.0007  max mem: 2501
Train: Epoch[1/5]  [ 300/3125]  eta: 0:16:25  Lr: 0.001875  Loss: -0.1408  Acc@1: 81.2500 (71.5947)  Acc@5: 100.0000 (94.4145)  time: 0.3463  data: 0.0005  max mem: 2501
Train: Epoch[1/5]  [ 310/3125]  eta: 0:16:21  Lr: 0.001875  Loss: 0.0577  Acc@1: 75.0000 (71.8248)  Acc@5: 100.0000 (94.5539)  time: 0.3492  data: 0.0005  max mem: 2501
Train: Epoch[1/5]  [ 320/3125]  eta: 0:16:18  Lr: 0.001875  Loss: -0.2528  Acc@1: 81.2500 (72.1573)  Acc@5: 100.0000 (94.6456)  time: 0.3490  data: 0.0008  max mem: 2501
Train: Epoch[1/5]  [ 330/3125]  eta: 0:16:14  Lr: 0.001875  Loss: 0.5954  Acc@1: 87.5000 (72.4887)  Acc@5: 100.0000 (94.7319)  time: 0.3469  data: 0.0009  max mem: 2501
Train: Epoch[1/5]  [ 340/3125]  eta: 0:16:11  Lr: 0.001875  Loss: -0.3582  Acc@1: 81.2500 (72.6906)  Acc@5: 100.0000 (94.8497)  time: 0.3476  data: 0.0008  max mem: 2501
Train: Epoch[1/5]  [ 350/3125]  eta: 0:16:07  Lr: 0.001875  Loss: -0.1578  Acc@1: 81.2500 (72.8632)  Acc@5: 100.0000 (94.9074)  time: 0.3464  data: 0.0006  max mem: 2501
Train: Epoch[1/5]  [ 360/3125]  eta: 0:16:03  Lr: 0.001875  Loss: 0.1808  Acc@1: 75.0000 (72.9917)  Acc@5: 93.7500 (94.9273)  time: 0.3449  data: 0.0005  max mem: 2501
Train: Epoch[1/5]  [ 370/3125]  eta: 0:16:00  Lr: 0.001875  Loss: 0.2698  Acc@1: 75.0000 (73.0964)  Acc@5: 93.7500 (94.9798)  time: 0.3473  data: 0.0010  max mem: 2501
Train: Epoch[1/5]  [ 380/3125]  eta: 0:15:56  Lr: 0.001875  Loss: -0.3776  Acc@1: 81.2500 (73.4088)  Acc@5: 100.0000 (95.0295)  time: 0.3485  data: 0.0011  max mem: 2501
Train: Epoch[1/5]  [ 390/3125]  eta: 0:15:52  Lr: 0.001875  Loss: 0.1176  Acc@1: 81.2500 (73.5934)  Acc@5: 100.0000 (95.0448)  time: 0.3466  data: 0.0004  max mem: 2501
Train: Epoch[1/5]  [ 400/3125]  eta: 0:15:49  Lr: 0.001875  Loss: 0.0184  Acc@1: 81.2500 (73.7531)  Acc@5: 93.7500 (95.0436)  time: 0.3473  data: 0.0006  max mem: 2501
Train: Epoch[1/5]  [ 410/3125]  eta: 0:15:45  Lr: 0.001875  Loss: -0.2842  Acc@1: 87.5000 (74.1180)  Acc@5: 100.0000 (95.0882)  time: 0.3481  data: 0.0006  max mem: 2501
Train: Epoch[1/5]  [ 420/3125]  eta: 0:15:42  Lr: 0.001875  Loss: 0.2597  Acc@1: 87.5000 (74.2726)  Acc@5: 100.0000 (95.1603)  time: 0.3473  data: 0.0004  max mem: 2501
Train: Epoch[1/5]  [ 430/3125]  eta: 0:15:38  Lr: 0.001875  Loss: -0.3306  Acc@1: 87.5000 (74.5650)  Acc@5: 100.0000 (95.2146)  time: 0.3476  data: 0.0005  max mem: 2501
Train: Epoch[1/5]  [ 440/3125]  eta: 0:15:35  Lr: 0.001875  Loss: -0.1326  Acc@1: 81.2500 (74.6315)  Acc@5: 100.0000 (95.2523)  time: 0.3484  data: 0.0007  max mem: 2501
Train: Epoch[1/5]  [ 450/3125]  eta: 0:15:31  Lr: 0.001875  Loss: -0.0054  Acc@1: 75.0000 (74.7783)  Acc@5: 100.0000 (95.3437)  time: 0.3477  data: 0.0007  max mem: 2501
Train: Epoch[1/5]  [ 460/3125]  eta: 0:15:28  Lr: 0.001875  Loss: -0.2020  Acc@1: 75.0000 (74.8780)  Acc@5: 100.0000 (95.4176)  time: 0.3470  data: 0.0006  max mem: 2501
Train: Epoch[1/5]  [ 470/3125]  eta: 0:15:24  Lr: 0.001875  Loss: 0.1938  Acc@1: 75.0000 (74.9867)  Acc@5: 100.0000 (95.4751)  time: 0.3469  data: 0.0005  max mem: 2501
Train: Epoch[1/5]  [ 480/3125]  eta: 0:15:21  Lr: 0.001875  Loss: -0.0875  Acc@1: 81.2500 (75.0910)  Acc@5: 100.0000 (95.5042)  time: 0.3478  data: 0.0006  max mem: 2501
Train: Epoch[1/5]  [ 490/3125]  eta: 0:15:17  Lr: 0.001875  Loss: -0.4501  Acc@1: 81.2500 (75.2928)  Acc@5: 100.0000 (95.5575)  time: 0.3473  data: 0.0008  max mem: 2501
Train: Epoch[1/5]  [ 500/3125]  eta: 0:15:14  Lr: 0.001875  Loss: -0.1419  Acc@1: 81.2500 (75.3867)  Acc@5: 100.0000 (95.6337)  time: 0.3481  data: 0.0010  max mem: 2501
Train: Epoch[1/5]  [ 510/3125]  eta: 0:15:10  Lr: 0.001875  Loss: -0.5515  Acc@1: 81.2500 (75.5382)  Acc@5: 100.0000 (95.7069)  time: 0.3491  data: 0.0008  max mem: 2501
Train: Epoch[1/5]  [ 520/3125]  eta: 0:15:07  Lr: 0.001875  Loss: -0.1730  Acc@1: 81.2500 (75.5998)  Acc@5: 100.0000 (95.7414)  time: 0.3486  data: 0.0005  max mem: 2501
Train: Epoch[1/5]  [ 530/3125]  eta: 0:15:03  Lr: 0.001875  Loss: -0.0352  Acc@1: 75.0000 (75.6827)  Acc@5: 100.0000 (95.7863)  time: 0.3489  data: 0.0007  max mem: 2501
Train: Epoch[1/5]  [ 540/3125]  eta: 0:15:00  Lr: 0.001875  Loss: -0.0188  Acc@1: 81.2500 (75.7625)  Acc@5: 100.0000 (95.8179)  time: 0.3476  data: 0.0008  max mem: 2501
Train: Epoch[1/5]  [ 550/3125]  eta: 0:14:56  Lr: 0.001875  Loss: -0.0757  Acc@1: 81.2500 (75.8961)  Acc@5: 100.0000 (95.8485)  time: 0.3484  data: 0.0010  max mem: 2501
Train: Epoch[1/5]  [ 560/3125]  eta: 0:14:53  Lr: 0.001875  Loss: -0.3868  Acc@1: 81.2500 (76.0250)  Acc@5: 100.0000 (95.9225)  time: 0.3503  data: 0.0010  max mem: 2501
Train: Epoch[1/5]  [ 570/3125]  eta: 0:14:50  Lr: 0.001875  Loss: -0.2777  Acc@1: 81.2500 (76.0836)  Acc@5: 100.0000 (95.9610)  time: 0.3518  data: 0.0015  max mem: 2501
Train: Epoch[1/5]  [ 580/3125]  eta: 0:14:46  Lr: 0.001875  Loss: -0.0283  Acc@1: 75.0000 (76.1725)  Acc@5: 100.0000 (95.9660)  time: 0.3527  data: 0.0026  max mem: 2501
Train: Epoch[1/5]  [ 590/3125]  eta: 0:14:43  Lr: 0.001875  Loss: -0.0730  Acc@1: 81.2500 (76.2267)  Acc@5: 100.0000 (96.0131)  time: 0.3505  data: 0.0017  max mem: 2501
Train: Epoch[1/5]  [ 600/3125]  eta: 0:14:39  Lr: 0.001875  Loss: 0.0465  Acc@1: 81.2500 (76.2479)  Acc@5: 100.0000 (96.0275)  time: 0.3478  data: 0.0006  max mem: 2501
Train: Epoch[1/5]  [ 610/3125]  eta: 0:14:36  Lr: 0.001875  Loss: -0.3903  Acc@1: 81.2500 (76.4116)  Acc@5: 100.0000 (96.0822)  time: 0.3476  data: 0.0006  max mem: 2501
Train: Epoch[1/5]  [ 620/3125]  eta: 0:14:32  Lr: 0.001875  Loss: -0.1583  Acc@1: 81.2500 (76.4090)  Acc@5: 100.0000 (96.1051)  time: 0.3490  data: 0.0005  max mem: 2501
Train: Epoch[1/5]  [ 630/3125]  eta: 0:14:29  Lr: 0.001875  Loss: -0.2068  Acc@1: 81.2500 (76.4659)  Acc@5: 100.0000 (96.1470)  time: 0.3475  data: 0.0005  max mem: 2501
Train: Epoch[1/5]  [ 640/3125]  eta: 0:14:25  Lr: 0.001875  Loss: -0.0234  Acc@1: 81.2500 (76.5406)  Acc@5: 100.0000 (96.1681)  time: 0.3462  data: 0.0006  max mem: 2501
Train: Epoch[1/5]  [ 650/3125]  eta: 0:14:22  Lr: 0.001875  Loss: -0.4726  Acc@1: 81.2500 (76.5841)  Acc@5: 100.0000 (96.1886)  time: 0.3456  data: 0.0006  max mem: 2501
Train: Epoch[1/5]  [ 660/3125]  eta: 0:14:18  Lr: 0.001875  Loss: 0.3291  Acc@1: 81.2500 (76.6452)  Acc@5: 100.0000 (96.2273)  time: 0.3456  data: 0.0007  max mem: 2501
Train: Epoch[1/5]  [ 670/3125]  eta: 0:14:15  Lr: 0.001875  Loss: -0.1852  Acc@1: 87.5000 (76.6952)  Acc@5: 100.0000 (96.2649)  time: 0.3464  data: 0.0007  max mem: 2501
Train: Epoch[1/5]  [ 680/3125]  eta: 0:14:11  Lr: 0.001875  Loss: -0.4921  Acc@1: 87.5000 (76.8172)  Acc@5: 100.0000 (96.2922)  time: 0.3494  data: 0.0011  max mem: 2501
Train: Epoch[1/5]  [ 690/3125]  eta: 0:14:08  Lr: 0.001875  Loss: -0.3086  Acc@1: 81.2500 (76.7818)  Acc@5: 100.0000 (96.3007)  time: 0.3502  data: 0.0012  max mem: 2501
Train: Epoch[1/5]  [ 700/3125]  eta: 0:14:04  Lr: 0.001875  Loss: -0.2129  Acc@1: 81.2500 (76.8991)  Acc@5: 100.0000 (96.2999)  time: 0.3486  data: 0.0005  max mem: 2501
Train: Epoch[1/5]  [ 710/3125]  eta: 0:14:01  Lr: 0.001875  Loss: -0.3087  Acc@1: 81.2500 (76.9954)  Acc@5: 100.0000 (96.3344)  time: 0.3486  data: 0.0004  max mem: 2501
Train: Epoch[1/5]  [ 720/3125]  eta: 0:13:57  Lr: 0.001875  Loss: -0.1398  Acc@1: 81.2500 (77.0631)  Acc@5: 100.0000 (96.3592)  time: 0.3472  data: 0.0006  max mem: 2501
Train: Epoch[1/5]  [ 730/3125]  eta: 0:13:54  Lr: 0.001875  Loss: -0.3129  Acc@1: 87.5000 (77.2144)  Acc@5: 100.0000 (96.3919)  time: 0.3474  data: 0.0006  max mem: 2501
Train: Epoch[1/5]  [ 740/3125]  eta: 0:13:50  Lr: 0.001875  Loss: -0.3747  Acc@1: 87.5000 (77.2689)  Acc@5: 100.0000 (96.4322)  time: 0.3473  data: 0.0005  max mem: 2501
Train: Epoch[1/5]  [ 750/3125]  eta: 0:13:47  Lr: 0.001875  Loss: -0.1352  Acc@1: 81.2500 (77.3718)  Acc@5: 100.0000 (96.4464)  time: 0.3461  data: 0.0005  max mem: 2501
Train: Epoch[1/5]  [ 760/3125]  eta: 0:13:43  Lr: 0.001875  Loss: -0.1058  Acc@1: 81.2500 (77.4064)  Acc@5: 100.0000 (96.4274)  time: 0.3450  data: 0.0005  max mem: 2501
Train: Epoch[1/5]  [ 770/3125]  eta: 0:13:40  Lr: 0.001875  Loss: -0.0455  Acc@1: 81.2500 (77.4805)  Acc@5: 93.7500 (96.4332)  time: 0.3461  data: 0.0006  max mem: 2501
Train: Epoch[1/5]  [ 780/3125]  eta: 0:13:36  Lr: 0.001875  Loss: -0.3744  Acc@1: 87.5000 (77.5848)  Acc@5: 100.0000 (96.4549)  time: 0.3478  data: 0.0007  max mem: 2501
Train: Epoch[1/5]  [ 790/3125]  eta: 0:13:33  Lr: 0.001875  Loss: 0.0696  Acc@1: 87.5000 (77.6786)  Acc@5: 100.0000 (96.4918)  time: 0.3475  data: 0.0007  max mem: 2501
Train: Epoch[1/5]  [ 800/3125]  eta: 0:13:29  Lr: 0.001875  Loss: -0.2581  Acc@1: 87.5000 (77.7622)  Acc@5: 100.0000 (96.4966)  time: 0.3460  data: 0.0006  max mem: 2501
Train: Epoch[1/5]  [ 810/3125]  eta: 0:13:25  Lr: 0.001875  Loss: -0.2708  Acc@1: 81.2500 (77.8052)  Acc@5: 100.0000 (96.5012)  time: 0.3466  data: 0.0005  max mem: 2501
Train: Epoch[1/5]  [ 820/3125]  eta: 0:13:22  Lr: 0.001875  Loss: -0.0930  Acc@1: 81.2500 (77.8395)  Acc@5: 100.0000 (96.5210)  time: 0.3468  data: 0.0005  max mem: 2501
Train: Epoch[1/5]  [ 830/3125]  eta: 0:13:18  Lr: 0.001875  Loss: -0.1032  Acc@1: 81.2500 (77.8881)  Acc@5: 100.0000 (96.5478)  time: 0.3479  data: 0.0006  max mem: 2501
Train: Epoch[1/5]  [ 840/3125]  eta: 0:13:15  Lr: 0.001875  Loss: -0.5462  Acc@1: 81.2500 (77.9727)  Acc@5: 100.0000 (96.5740)  time: 0.3486  data: 0.0006  max mem: 2501
Train: Epoch[1/5]  [ 850/3125]  eta: 0:13:11  Lr: 0.001875  Loss: -0.3809  Acc@1: 81.2500 (77.9965)  Acc@5: 100.0000 (96.5408)  time: 0.3466  data: 0.0005  max mem: 2501
Train: Epoch[1/5]  [ 860/3125]  eta: 0:13:08  Lr: 0.001875  Loss: -0.1617  Acc@1: 81.2500 (77.9907)  Acc@5: 93.7500 (96.5375)  time: 0.3470  data: 0.0006  max mem: 2501
Train: Epoch[1/5]  [ 870/3125]  eta: 0:13:04  Lr: 0.001875  Loss: -0.0759  Acc@1: 81.2500 (78.0066)  Acc@5: 100.0000 (96.5413)  time: 0.3480  data: 0.0008  max mem: 2501
Train: Epoch[1/5]  [ 880/3125]  eta: 0:13:01  Lr: 0.001875  Loss: -0.2941  Acc@1: 81.2500 (78.0505)  Acc@5: 100.0000 (96.5522)  time: 0.3482  data: 0.0008  max mem: 2501
Train: Epoch[1/5]  [ 890/3125]  eta: 0:12:58  Lr: 0.001875  Loss: -0.2080  Acc@1: 81.2500 (78.1004)  Acc@5: 100.0000 (96.5558)  time: 0.3494  data: 0.0013  max mem: 2501
Train: Epoch[1/5]  [ 900/3125]  eta: 0:12:54  Lr: 0.001875  Loss: -0.1330  Acc@1: 81.2500 (78.1146)  Acc@5: 100.0000 (96.5663)  time: 0.3483  data: 0.0012  max mem: 2501
Train: Epoch[1/5]  [ 910/3125]  eta: 0:12:51  Lr: 0.001875  Loss: -0.5020  Acc@1: 81.2500 (78.1216)  Acc@5: 100.0000 (96.5766)  time: 0.3473  data: 0.0004  max mem: 2501
Train: Epoch[1/5]  [ 920/3125]  eta: 0:12:47  Lr: 0.001875  Loss: -0.1255  Acc@1: 81.2500 (78.1895)  Acc@5: 100.0000 (96.6069)  time: 0.3481  data: 0.0008  max mem: 2501
Train: Epoch[1/5]  [ 930/3125]  eta: 0:12:44  Lr: 0.001875  Loss: -0.1478  Acc@1: 81.2500 (78.2425)  Acc@5: 100.0000 (96.6367)  time: 0.3467  data: 0.0008  max mem: 2501
Train: Epoch[1/5]  [ 940/3125]  eta: 0:12:40  Lr: 0.001875  Loss: -0.3597  Acc@1: 81.2500 (78.3143)  Acc@5: 100.0000 (96.6525)  time: 0.3476  data: 0.0014  max mem: 2501
Train: Epoch[1/5]  [ 950/3125]  eta: 0:12:37  Lr: 0.001875  Loss: -0.2343  Acc@1: 81.2500 (78.3452)  Acc@5: 100.0000 (96.6614)  time: 0.3468  data: 0.0013  max mem: 2501
Train: Epoch[1/5]  [ 960/3125]  eta: 0:12:33  Lr: 0.001875  Loss: -0.4563  Acc@1: 81.2500 (78.4274)  Acc@5: 100.0000 (96.6896)  time: 0.3462  data: 0.0005  max mem: 2501
Train: Epoch[1/5]  [ 970/3125]  eta: 0:12:30  Lr: 0.001875  Loss: -0.3714  Acc@1: 87.5000 (78.5273)  Acc@5: 100.0000 (96.7173)  time: 0.3481  data: 0.0014  max mem: 2501
Train: Epoch[1/5]  [ 980/3125]  eta: 0:12:26  Lr: 0.001875  Loss: -0.1239  Acc@1: 87.5000 (78.5487)  Acc@5: 100.0000 (96.7444)  time: 0.3474  data: 0.0014  max mem: 2501
Train: Epoch[1/5]  [ 990/3125]  eta: 0:12:23  Lr: 0.001875  Loss: -0.3479  Acc@1: 81.2500 (78.5822)  Acc@5: 100.0000 (96.7394)  time: 0.3459  data: 0.0005  max mem: 2501
Train: Epoch[1/5]  [1000/3125]  eta: 0:12:19  Lr: 0.001875  Loss: -0.2445  Acc@1: 81.2500 (78.5839)  Acc@5: 100.0000 (96.7470)  time: 0.3446  data: 0.0005  max mem: 2501
Train: Epoch[1/5]  [1010/3125]  eta: 0:12:15  Lr: 0.001875  Loss: -0.3424  Acc@1: 75.0000 (78.5670)  Acc@5: 100.0000 (96.7483)  time: 0.3456  data: 0.0005  max mem: 2501
Train: Epoch[1/5]  [1020/3125]  eta: 0:12:12  Lr: 0.001875  Loss: -0.6286  Acc@1: 81.2500 (78.6300)  Acc@5: 100.0000 (96.7556)  time: 0.3473  data: 0.0005  max mem: 2501
Train: Epoch[1/5]  [1030/3125]  eta: 0:12:08  Lr: 0.001875  Loss: -0.0327  Acc@1: 87.5000 (78.6979)  Acc@5: 100.0000 (96.7689)  time: 0.3476  data: 0.0005  max mem: 2501
Train: Epoch[1/5]  [1040/3125]  eta: 0:12:05  Lr: 0.001875  Loss: -0.3942  Acc@1: 87.5000 (78.7164)  Acc@5: 100.0000 (96.7819)  time: 0.3484  data: 0.0007  max mem: 2501
Train: Epoch[1/5]  [1050/3125]  eta: 0:12:01  Lr: 0.001875  Loss: -0.3793  Acc@1: 81.2500 (78.7345)  Acc@5: 100.0000 (96.7888)  time: 0.3472  data: 0.0007  max mem: 2501
Train: Epoch[1/5]  [1060/3125]  eta: 0:11:58  Lr: 0.001875  Loss: 0.0498  Acc@1: 87.5000 (78.7936)  Acc@5: 100.0000 (96.8073)  time: 0.3478  data: 0.0006  max mem: 2501
Train: Epoch[1/5]  [1070/3125]  eta: 0:11:55  Lr: 0.001875  Loss: -0.1156  Acc@1: 81.2500 (78.7932)  Acc@5: 100.0000 (96.8079)  time: 0.3505  data: 0.0015  max mem: 2501
Train: Epoch[1/5]  [1080/3125]  eta: 0:11:51  Lr: 0.001875  Loss: -0.1396  Acc@1: 81.2500 (78.8333)  Acc@5: 100.0000 (96.8201)  time: 0.3501  data: 0.0020  max mem: 2501
Train: Epoch[1/5]  [1090/3125]  eta: 0:11:48  Lr: 0.001875  Loss: -0.3295  Acc@1: 81.2500 (78.8669)  Acc@5: 100.0000 (96.8320)  time: 0.3482  data: 0.0010  max mem: 2501
Train: Epoch[1/5]  [1100/3125]  eta: 0:11:44  Lr: 0.001875  Loss: -0.2439  Acc@1: 81.2500 (78.9282)  Acc@5: 100.0000 (96.8495)  time: 0.3464  data: 0.0006  max mem: 2501
Train: Epoch[1/5]  [1110/3125]  eta: 0:11:41  Lr: 0.001875  Loss: -0.1081  Acc@1: 81.2500 (78.9604)  Acc@5: 100.0000 (96.8609)  time: 0.3455  data: 0.0006  max mem: 2501
Train: Epoch[1/5]  [1120/3125]  eta: 0:11:37  Lr: 0.001875  Loss: -0.3782  Acc@1: 81.2500 (78.9920)  Acc@5: 100.0000 (96.8722)  time: 0.3469  data: 0.0006  max mem: 2501
Train: Epoch[1/5]  [1130/3125]  eta: 0:11:34  Lr: 0.001875  Loss: -0.3611  Acc@1: 87.5000 (79.0340)  Acc@5: 100.0000 (96.8612)  time: 0.3475  data: 0.0006  max mem: 2501
Train: Epoch[1/5]  [1140/3125]  eta: 0:11:30  Lr: 0.001875  Loss: -0.0285  Acc@1: 81.2500 (79.0370)  Acc@5: 100.0000 (96.8668)  time: 0.3480  data: 0.0006  max mem: 2501
Train: Epoch[1/5]  [1150/3125]  eta: 0:11:27  Lr: 0.001875  Loss: 0.2268  Acc@1: 81.2500 (79.0291)  Acc@5: 100.0000 (96.8723)  time: 0.3498  data: 0.0010  max mem: 2501
Train: Epoch[1/5]  [1160/3125]  eta: 0:11:23  Lr: 0.001875  Loss: -0.1711  Acc@1: 81.2500 (79.0644)  Acc@5: 100.0000 (96.8777)  time: 0.3494  data: 0.0010  max mem: 2501
Train: Epoch[1/5]  [1170/3125]  eta: 0:11:20  Lr: 0.001875  Loss: -0.2856  Acc@1: 87.5000 (79.1097)  Acc@5: 100.0000 (96.8883)  time: 0.3490  data: 0.0013  max mem: 2501
Train: Epoch[1/5]  [1180/3125]  eta: 0:11:16  Lr: 0.001875  Loss: -0.5151  Acc@1: 87.5000 (79.1384)  Acc@5: 100.0000 (96.8935)  time: 0.3488  data: 0.0015  max mem: 2501
Train: Epoch[1/5]  [1190/3125]  eta: 0:11:13  Lr: 0.001875  Loss: -0.3114  Acc@1: 87.5000 (79.2296)  Acc@5: 100.0000 (96.9091)  time: 0.3486  data: 0.0009  max mem: 2501
Train: Epoch[1/5]  [1200/3125]  eta: 0:11:09  Lr: 0.001875  Loss: -0.5186  Acc@1: 81.2500 (79.2517)  Acc@5: 100.0000 (96.9140)  time: 0.3474  data: 0.0006  max mem: 2501
Train: Epoch[1/5]  [1210/3125]  eta: 0:11:06  Lr: 0.001875  Loss: -0.1232  Acc@1: 81.2500 (79.2733)  Acc@5: 100.0000 (96.9189)  time: 0.3470  data: 0.0012  max mem: 2501
Train: Epoch[1/5]  [1220/3125]  eta: 0:11:02  Lr: 0.001875  Loss: -0.6850  Acc@1: 81.2500 (79.3305)  Acc@5: 100.0000 (96.9339)  time: 0.3485  data: 0.0013  max mem: 2501
Train: Epoch[1/5]  [1230/3125]  eta: 0:10:59  Lr: 0.001875  Loss: -0.0530  Acc@1: 81.2500 (79.3664)  Acc@5: 100.0000 (96.9537)  time: 0.3477  data: 0.0007  max mem: 2501
Train: Epoch[1/5]  [1240/3125]  eta: 0:10:55  Lr: 0.001875  Loss: 0.0430  Acc@1: 81.2500 (79.3614)  Acc@5: 100.0000 (96.9581)  time: 0.3473  data: 0.0007  max mem: 2501
Train: Epoch[1/5]  [1250/3125]  eta: 0:10:52  Lr: 0.001875  Loss: -0.4514  Acc@1: 81.2500 (79.4015)  Acc@5: 100.0000 (96.9724)  time: 0.3465  data: 0.0005  max mem: 2501
Train: Epoch[1/5]  [1260/3125]  eta: 0:10:48  Lr: 0.001875  Loss: -0.2551  Acc@1: 87.5000 (79.4756)  Acc@5: 100.0000 (96.9766)  time: 0.3471  data: 0.0008  max mem: 2501
Train: Epoch[1/5]  [1270/3125]  eta: 0:10:45  Lr: 0.001875  Loss: -0.4715  Acc@1: 87.5000 (79.5142)  Acc@5: 100.0000 (96.9906)  time: 0.3479  data: 0.0009  max mem: 2501
Train: Epoch[1/5]  [1280/3125]  eta: 0:10:42  Lr: 0.001875  Loss: -0.1027  Acc@1: 81.2500 (79.5570)  Acc@5: 100.0000 (96.9897)  time: 0.3489  data: 0.0017  max mem: 2501
Train: Epoch[1/5]  [1290/3125]  eta: 0:10:38  Lr: 0.001875  Loss: 0.0084  Acc@1: 81.2500 (79.5749)  Acc@5: 100.0000 (96.9936)  time: 0.3498  data: 0.0015  max mem: 2501
Train: Epoch[1/5]  [1300/3125]  eta: 0:10:35  Lr: 0.001875  Loss: -0.1991  Acc@1: 81.2500 (79.6166)  Acc@5: 100.0000 (97.0023)  time: 0.3480  data: 0.0006  max mem: 2501
Train: Epoch[1/5]  [1310/3125]  eta: 0:10:31  Lr: 0.001875  Loss: 0.2423  Acc@1: 87.5000 (79.6720)  Acc@5: 100.0000 (97.0204)  time: 0.3480  data: 0.0011  max mem: 2501
Train: Epoch[1/5]  [1320/3125]  eta: 0:10:28  Lr: 0.001875  Loss: -0.4351  Acc@1: 87.5000 (79.7123)  Acc@5: 100.0000 (97.0240)  time: 0.3466  data: 0.0009  max mem: 2501
Train: Epoch[1/5]  [1330/3125]  eta: 0:10:24  Lr: 0.001875  Loss: -0.3895  Acc@1: 87.5000 (79.7943)  Acc@5: 100.0000 (97.0464)  time: 0.3478  data: 0.0016  max mem: 2501
Train: Epoch[1/5]  [1340/3125]  eta: 0:10:21  Lr: 0.001875  Loss: -0.5201  Acc@1: 87.5000 (79.8285)  Acc@5: 100.0000 (97.0591)  time: 0.3499  data: 0.0016  max mem: 2501
Train: Epoch[1/5]  [1350/3125]  eta: 0:10:17  Lr: 0.001875  Loss: -0.1746  Acc@1: 81.2500 (79.8436)  Acc@5: 100.0000 (97.0670)  time: 0.3473  data: 0.0005  max mem: 2501
Train: Epoch[1/5]  [1360/3125]  eta: 0:10:14  Lr: 0.001875  Loss: -0.2944  Acc@1: 81.2500 (79.8448)  Acc@5: 100.0000 (97.0656)  time: 0.3463  data: 0.0005  max mem: 2501
Train: Epoch[1/5]  [1370/3125]  eta: 0:10:10  Lr: 0.001875  Loss: -0.4082  Acc@1: 81.2500 (79.8869)  Acc@5: 100.0000 (97.0824)  time: 0.3478  data: 0.0006  max mem: 2501
Train: Epoch[1/5]  [1380/3125]  eta: 0:10:07  Lr: 0.001875  Loss: -0.5724  Acc@1: 87.5000 (79.9375)  Acc@5: 100.0000 (97.0990)  time: 0.3481  data: 0.0005  max mem: 2501
Train: Epoch[1/5]  [1390/3125]  eta: 0:10:03  Lr: 0.001875  Loss: 0.2821  Acc@1: 81.2500 (79.9380)  Acc@5: 100.0000 (97.1154)  time: 0.3484  data: 0.0007  max mem: 2501
Train: Epoch[1/5]  [1400/3125]  eta: 0:10:00  Lr: 0.001875  Loss: -0.1456  Acc@1: 81.2500 (79.9518)  Acc@5: 100.0000 (97.1137)  time: 0.3479  data: 0.0007  max mem: 2501
Train: Epoch[1/5]  [1410/3125]  eta: 0:09:56  Lr: 0.001875  Loss: -0.2886  Acc@1: 81.2500 (79.9832)  Acc@5: 100.0000 (97.1253)  time: 0.3473  data: 0.0006  max mem: 2501
Train: Epoch[1/5]  [1420/3125]  eta: 0:09:53  Lr: 0.001875  Loss: -0.5321  Acc@1: 81.2500 (80.0097)  Acc@5: 100.0000 (97.1235)  time: 0.3487  data: 0.0007  max mem: 2501
Train: Epoch[1/5]  [1430/3125]  eta: 0:09:49  Lr: 0.001875  Loss: 0.3145  Acc@1: 81.2500 (79.9965)  Acc@5: 93.7500 (97.1043)  time: 0.3472  data: 0.0006  max mem: 2501
Train: Epoch[1/5]  [1440/3125]  eta: 0:09:46  Lr: 0.001875  Loss: 0.3628  Acc@1: 81.2500 (79.9922)  Acc@5: 93.7500 (97.0940)  time: 0.3460  data: 0.0006  max mem: 2501
Train: Epoch[1/5]  [1450/3125]  eta: 0:09:42  Lr: 0.001875  Loss: -0.3854  Acc@1: 81.2500 (80.0310)  Acc@5: 100.0000 (97.0968)  time: 0.3478  data: 0.0007  max mem: 2501
Train: Epoch[1/5]  [1460/3125]  eta: 0:09:39  Lr: 0.001875  Loss: -0.3116  Acc@1: 87.5000 (80.0479)  Acc@5: 100.0000 (97.1081)  time: 0.3505  data: 0.0024  max mem: 2501
Train: Epoch[1/5]  [1470/3125]  eta: 0:09:35  Lr: 0.001875  Loss: -0.2150  Acc@1: 87.5000 (80.0858)  Acc@5: 100.0000 (97.1193)  time: 0.3519  data: 0.0033  max mem: 2501
Train: Epoch[1/5]  [1480/3125]  eta: 0:09:32  Lr: 0.001875  Loss: -0.5232  Acc@1: 87.5000 (80.0810)  Acc@5: 100.0000 (97.1008)  time: 0.3485  data: 0.0018  max mem: 2501
Train: Epoch[1/5]  [1490/3125]  eta: 0:09:28  Lr: 0.001875  Loss: -0.0747  Acc@1: 75.0000 (80.0763)  Acc@5: 93.7500 (97.0909)  time: 0.3465  data: 0.0008  max mem: 2501
Train: Epoch[1/5]  [1500/3125]  eta: 0:09:25  Lr: 0.001875  Loss: -0.2423  Acc@1: 81.2500 (80.0633)  Acc@5: 93.7500 (97.0936)  time: 0.3463  data: 0.0006  max mem: 2501
Train: Epoch[1/5]  [1510/3125]  eta: 0:09:21  Lr: 0.001875  Loss: -0.4567  Acc@1: 81.2500 (80.0836)  Acc@5: 100.0000 (97.0963)  time: 0.3475  data: 0.0010  max mem: 2501
Train: Epoch[1/5]  [1520/3125]  eta: 0:09:18  Lr: 0.001875  Loss: -0.4332  Acc@1: 81.2500 (80.0789)  Acc@5: 100.0000 (97.0948)  time: 0.3489  data: 0.0009  max mem: 2501
Train: Epoch[1/5]  [1530/3125]  eta: 0:09:15  Lr: 0.001875  Loss: -0.0799  Acc@1: 87.5000 (80.1151)  Acc@5: 100.0000 (97.0975)  time: 0.3470  data: 0.0006  max mem: 2501
Train: Epoch[1/5]  [1540/3125]  eta: 0:09:11  Lr: 0.001875  Loss: -0.0463  Acc@1: 87.5000 (80.1509)  Acc@5: 100.0000 (97.1001)  time: 0.3480  data: 0.0007  max mem: 2501
Train: Epoch[1/5]  [1550/3125]  eta: 0:09:08  Lr: 0.001875  Loss: -0.1952  Acc@1: 87.5000 (80.1942)  Acc@5: 100.0000 (97.1148)  time: 0.3480  data: 0.0006  max mem: 2501
Train: Epoch[1/5]  [1560/3125]  eta: 0:09:04  Lr: 0.001875  Loss: -0.3758  Acc@1: 87.5000 (80.2250)  Acc@5: 100.0000 (97.1292)  time: 0.3514  data: 0.0015  max mem: 2501
Train: Epoch[1/5]  [1570/3125]  eta: 0:09:01  Lr: 0.001875  Loss: -0.1737  Acc@1: 87.5000 (80.2355)  Acc@5: 100.0000 (97.1316)  time: 0.3525  data: 0.0029  max mem: 2501
Train: Epoch[1/5]  [1580/3125]  eta: 0:08:57  Lr: 0.001875  Loss: -0.4747  Acc@1: 81.2500 (80.2498)  Acc@5: 100.0000 (97.1379)  time: 0.3495  data: 0.0030  max mem: 2501
Train: Epoch[1/5]  [1590/3125]  eta: 0:08:54  Lr: 0.001875  Loss: -0.0451  Acc@1: 81.2500 (80.2718)  Acc@5: 100.0000 (97.1480)  time: 0.3484  data: 0.0017  max mem: 2501
Train: Epoch[1/5]  [1600/3125]  eta: 0:08:50  Lr: 0.001875  Loss: -0.4488  Acc@1: 87.5000 (80.2936)  Acc@5: 100.0000 (97.1541)  time: 0.3472  data: 0.0005  max mem: 2501
Train: Epoch[1/5]  [1610/3125]  eta: 0:08:47  Lr: 0.001875  Loss: -0.4398  Acc@1: 87.5000 (80.2995)  Acc@5: 100.0000 (97.1601)  time: 0.3482  data: 0.0006  max mem: 2501
Train: Epoch[1/5]  [1620/3125]  eta: 0:08:43  Lr: 0.001875  Loss: -0.3504  Acc@1: 81.2500 (80.3169)  Acc@5: 100.0000 (97.1700)  time: 0.3468  data: 0.0006  max mem: 2501
Train: Epoch[1/5]  [1630/3125]  eta: 0:08:40  Lr: 0.001875  Loss: -0.4037  Acc@1: 87.5000 (80.3418)  Acc@5: 100.0000 (97.1758)  time: 0.3462  data: 0.0005  max mem: 2501
Train: Epoch[1/5]  [1640/3125]  eta: 0:08:36  Lr: 0.001875  Loss: -0.4131  Acc@1: 87.5000 (80.3892)  Acc@5: 100.0000 (97.1740)  time: 0.3472  data: 0.0006  max mem: 2501
Train: Epoch[1/5]  [1650/3125]  eta: 0:08:33  Lr: 0.001875  Loss: -0.7087  Acc@1: 87.5000 (80.4247)  Acc@5: 100.0000 (97.1760)  time: 0.3486  data: 0.0006  max mem: 2501
Train: Epoch[1/5]  [1660/3125]  eta: 0:08:29  Lr: 0.001875  Loss: 0.0600  Acc@1: 87.5000 (80.4523)  Acc@5: 100.0000 (97.1741)  time: 0.3516  data: 0.0015  max mem: 2501
Train: Epoch[1/5]  [1670/3125]  eta: 0:08:26  Lr: 0.001875  Loss: -0.5117  Acc@1: 87.5000 (80.4832)  Acc@5: 100.0000 (97.1873)  time: 0.3517  data: 0.0016  max mem: 2501
Train: Epoch[1/5]  [1680/3125]  eta: 0:08:22  Lr: 0.001875  Loss: -0.3643  Acc@1: 81.2500 (80.4952)  Acc@5: 100.0000 (97.1966)  time: 0.3497  data: 0.0012  max mem: 2501
Train: Epoch[1/5]  [1690/3125]  eta: 0:08:19  Lr: 0.001875  Loss: -0.2458  Acc@1: 81.2500 (80.5071)  Acc@5: 100.0000 (97.2058)  time: 0.3491  data: 0.0011  max mem: 2501
Train: Epoch[1/5]  [1700/3125]  eta: 0:08:15  Lr: 0.001875  Loss: -0.3288  Acc@1: 81.2500 (80.5298)  Acc@5: 100.0000 (97.2112)  time: 0.3472  data: 0.0005  max mem: 2501
Train: Epoch[1/5]  [1710/3125]  eta: 0:08:12  Lr: 0.001875  Loss: -0.1682  Acc@1: 87.5000 (80.5633)  Acc@5: 100.0000 (97.2056)  time: 0.3477  data: 0.0006  max mem: 2501
Train: Epoch[1/5]  [1720/3125]  eta: 0:08:09  Lr: 0.001875  Loss: -0.2349  Acc@1: 87.5000 (80.5963)  Acc@5: 100.0000 (97.2109)  time: 0.3483  data: 0.0006  max mem: 2501
Train: Epoch[1/5]  [1730/3125]  eta: 0:08:05  Lr: 0.001875  Loss: -0.2498  Acc@1: 87.5000 (80.6398)  Acc@5: 100.0000 (97.2162)  time: 0.3475  data: 0.0009  max mem: 2501
Train: Epoch[1/5]  [1740/3125]  eta: 0:08:02  Lr: 0.001875  Loss: -0.4541  Acc@1: 87.5000 (80.6613)  Acc@5: 100.0000 (97.2214)  time: 0.3485  data: 0.0009  max mem: 2501
Train: Epoch[1/5]  [1750/3125]  eta: 0:07:58  Lr: 0.001875  Loss: -0.5130  Acc@1: 87.5000 (80.7039)  Acc@5: 100.0000 (97.2230)  time: 0.3470  data: 0.0005  max mem: 2501
Train: Epoch[1/5]  [1760/3125]  eta: 0:07:55  Lr: 0.001875  Loss: 0.2549  Acc@1: 81.2500 (80.7034)  Acc@5: 100.0000 (97.2210)  time: 0.3478  data: 0.0009  max mem: 2501
Train: Epoch[1/5]  [1770/3125]  eta: 0:07:51  Lr: 0.001875  Loss: -0.4103  Acc@1: 81.2500 (80.7242)  Acc@5: 93.7500 (97.2120)  time: 0.3512  data: 0.0013  max mem: 2501
Train: Epoch[1/5]  [1780/3125]  eta: 0:07:48  Lr: 0.001875  Loss: -0.4955  Acc@1: 87.5000 (80.7447)  Acc@5: 93.7500 (97.2136)  time: 0.3488  data: 0.0010  max mem: 2501
Train: Epoch[1/5]  [1790/3125]  eta: 0:07:44  Lr: 0.001875  Loss: -0.1623  Acc@1: 87.5000 (80.7719)  Acc@5: 100.0000 (97.2257)  time: 0.3473  data: 0.0008  max mem: 2501
Train: Epoch[1/5]  [1800/3125]  eta: 0:07:41  Lr: 0.001875  Loss: 0.3265  Acc@1: 87.5000 (80.7850)  Acc@5: 100.0000 (97.2307)  time: 0.3484  data: 0.0015  max mem: 2501
Train: Epoch[1/5]  [1810/3125]  eta: 0:07:37  Lr: 0.001875  Loss: -0.2652  Acc@1: 87.5000 (80.8083)  Acc@5: 100.0000 (97.2425)  time: 0.3479  data: 0.0012  max mem: 2501
Train: Epoch[1/5]  [1820/3125]  eta: 0:07:34  Lr: 0.001875  Loss: -0.0941  Acc@1: 87.5000 (80.8175)  Acc@5: 100.0000 (97.2474)  time: 0.3488  data: 0.0004  max mem: 2501
Train: Epoch[1/5]  [1830/3125]  eta: 0:07:30  Lr: 0.001875  Loss: -0.0487  Acc@1: 81.2500 (80.8404)  Acc@5: 100.0000 (97.2454)  time: 0.3492  data: 0.0010  max mem: 2501
Train: Epoch[1/5]  [1840/3125]  eta: 0:07:27  Lr: 0.001875  Loss: -0.3091  Acc@1: 81.2500 (80.8630)  Acc@5: 100.0000 (97.2535)  time: 0.3474  data: 0.0010  max mem: 2501
Train: Epoch[1/5]  [1850/3125]  eta: 0:07:23  Lr: 0.001875  Loss: -0.1919  Acc@1: 81.2500 (80.8853)  Acc@5: 100.0000 (97.2582)  time: 0.3478  data: 0.0005  max mem: 2501
Train: Epoch[1/5]  [1860/3125]  eta: 0:07:20  Lr: 0.001875  Loss: -0.0855  Acc@1: 81.2500 (80.9074)  Acc@5: 100.0000 (97.2663)  time: 0.3490  data: 0.0031  max mem: 2501
Train: Epoch[1/5]  [1870/3125]  eta: 0:07:16  Lr: 0.001875  Loss: -0.1486  Acc@1: 87.5000 (80.9193)  Acc@5: 100.0000 (97.2608)  time: 0.3480  data: 0.0034  max mem: 2501
Train: Epoch[1/5]  [1880/3125]  eta: 0:07:13  Lr: 0.001875  Loss: -0.1361  Acc@1: 81.2500 (80.9111)  Acc@5: 100.0000 (97.2687)  time: 0.3484  data: 0.0009  max mem: 2501
Train: Epoch[1/5]  [1890/3125]  eta: 0:07:09  Lr: 0.001875  Loss: 0.1975  Acc@1: 81.2500 (80.9294)  Acc@5: 100.0000 (97.2634)  time: 0.3481  data: 0.0006  max mem: 2501
Train: Epoch[1/5]  [1900/3125]  eta: 0:07:06  Lr: 0.001875  Loss: -0.1096  Acc@1: 87.5000 (80.9607)  Acc@5: 100.0000 (97.2613)  time: 0.3481  data: 0.0009  max mem: 2501
Train: Epoch[1/5]  [1910/3125]  eta: 0:07:02  Lr: 0.001875  Loss: -0.1474  Acc@1: 87.5000 (80.9851)  Acc@5: 100.0000 (97.2691)  time: 0.3489  data: 0.0010  max mem: 2501
Train: Epoch[1/5]  [1920/3125]  eta: 0:06:59  Lr: 0.001875  Loss: 0.0674  Acc@1: 81.2500 (80.9865)  Acc@5: 100.0000 (97.2736)  time: 0.3468  data: 0.0006  max mem: 2501
Train: Epoch[1/5]  [1930/3125]  eta: 0:06:55  Lr: 0.001875  Loss: -0.3455  Acc@1: 81.2500 (81.0040)  Acc@5: 100.0000 (97.2650)  time: 0.3471  data: 0.0007  max mem: 2501
Train: Epoch[1/5]  [1940/3125]  eta: 0:06:52  Lr: 0.001875  Loss: 0.2208  Acc@1: 81.2500 (81.0085)  Acc@5: 100.0000 (97.2598)  time: 0.3483  data: 0.0006  max mem: 2501
Train: Epoch[1/5]  [1950/3125]  eta: 0:06:49  Lr: 0.001875  Loss: -0.0796  Acc@1: 81.2500 (81.0001)  Acc@5: 100.0000 (97.2578)  time: 0.3484  data: 0.0007  max mem: 2501
Train: Epoch[1/5]  [1960/3125]  eta: 0:06:45  Lr: 0.001875  Loss: 0.3778  Acc@1: 81.2500 (81.0110)  Acc@5: 100.0000 (97.2686)  time: 0.3492  data: 0.0007  max mem: 2501
Train: Epoch[1/5]  [1970/3125]  eta: 0:06:42  Lr: 0.001875  Loss: -0.3160  Acc@1: 87.5000 (81.0185)  Acc@5: 100.0000 (97.2730)  time: 0.3568  data: 0.0011  max mem: 2501
Train: Epoch[1/5]  [1980/3125]  eta: 0:06:38  Lr: 0.001875  Loss: -0.3524  Acc@1: 87.5000 (81.0512)  Acc@5: 100.0000 (97.2773)  time: 0.3570  data: 0.0015  max mem: 2501
Train: Epoch[1/5]  [1990/3125]  eta: 0:06:35  Lr: 0.001875  Loss: -0.3152  Acc@1: 81.2500 (81.0460)  Acc@5: 100.0000 (97.2815)  time: 0.3497  data: 0.0008  max mem: 2501
Train: Epoch[1/5]  [2000/3125]  eta: 0:06:31  Lr: 0.001875  Loss: -0.2848  Acc@1: 87.5000 (81.0970)  Acc@5: 100.0000 (97.2857)  time: 0.3481  data: 0.0005  max mem: 2501
Train: Epoch[1/5]  [2010/3125]  eta: 0:06:28  Lr: 0.001875  Loss: -0.4198  Acc@1: 87.5000 (81.0884)  Acc@5: 100.0000 (97.2868)  time: 0.3485  data: 0.0008  max mem: 2501
Train: Epoch[1/5]  [2020/3125]  eta: 0:06:24  Lr: 0.001875  Loss: -0.1829  Acc@1: 81.2500 (81.0861)  Acc@5: 100.0000 (97.2940)  time: 0.3478  data: 0.0007  max mem: 2501
Train: Epoch[1/5]  [2030/3125]  eta: 0:06:21  Lr: 0.001875  Loss: -0.5088  Acc@1: 81.2500 (81.0961)  Acc@5: 100.0000 (97.3043)  time: 0.3463  data: 0.0005  max mem: 2501
Train: Epoch[1/5]  [2040/3125]  eta: 0:06:17  Lr: 0.001875  Loss: -0.4634  Acc@1: 81.2500 (81.1153)  Acc@5: 100.0000 (97.3144)  time: 0.3491  data: 0.0006  max mem: 2501
Train: Epoch[1/5]  [2050/3125]  eta: 0:06:14  Lr: 0.001875  Loss: 0.3820  Acc@1: 81.2500 (81.1129)  Acc@5: 100.0000 (97.3214)  time: 0.3491  data: 0.0006  max mem: 2501
Train: Epoch[1/5]  [2060/3125]  eta: 0:06:10  Lr: 0.001875  Loss: -0.1025  Acc@1: 81.2500 (81.1378)  Acc@5: 100.0000 (97.3223)  time: 0.3485  data: 0.0006  max mem: 2501
Train: Epoch[1/5]  [2070/3125]  eta: 0:06:07  Lr: 0.001875  Loss: -0.5574  Acc@1: 81.2500 (81.1474)  Acc@5: 100.0000 (97.3322)  time: 0.3491  data: 0.0006  max mem: 2501
Train: Epoch[1/5]  [2080/3125]  eta: 0:06:03  Lr: 0.001875  Loss: -0.1579  Acc@1: 87.5000 (81.1659)  Acc@5: 100.0000 (97.3390)  time: 0.3487  data: 0.0008  max mem: 2501
Train: Epoch[1/5]  [2090/3125]  eta: 0:06:00  Lr: 0.001875  Loss: -0.1210  Acc@1: 87.5000 (81.1872)  Acc@5: 100.0000 (97.3398)  time: 0.3489  data: 0.0007  max mem: 2501
Train: Epoch[1/5]  [2100/3125]  eta: 0:05:56  Lr: 0.001875  Loss: -0.6173  Acc@1: 81.2500 (81.1846)  Acc@5: 100.0000 (97.3465)  time: 0.3481  data: 0.0006  max mem: 2501
Train: Epoch[1/5]  [2110/3125]  eta: 0:05:53  Lr: 0.001875  Loss: -0.3154  Acc@1: 81.2500 (81.1878)  Acc@5: 100.0000 (97.3502)  time: 0.3477  data: 0.0006  max mem: 2501
Train: Epoch[1/5]  [2120/3125]  eta: 0:05:49  Lr: 0.001875  Loss: -0.4225  Acc@1: 87.5000 (81.2029)  Acc@5: 100.0000 (97.3538)  time: 0.3465  data: 0.0005  max mem: 2501
Train: Epoch[1/5]  [2130/3125]  eta: 0:05:46  Lr: 0.001875  Loss: -0.5510  Acc@1: 87.5000 (81.2412)  Acc@5: 100.0000 (97.3633)  time: 0.3456  data: 0.0007  max mem: 2501
Train: Epoch[1/5]  [2140/3125]  eta: 0:05:42  Lr: 0.001875  Loss: -0.5258  Acc@1: 87.5000 (81.2734)  Acc@5: 100.0000 (97.3698)  time: 0.3467  data: 0.0007  max mem: 2501
Train: Epoch[1/5]  [2150/3125]  eta: 0:05:39  Lr: 0.001875  Loss: -0.4318  Acc@1: 87.5000 (81.2732)  Acc@5: 100.0000 (97.3733)  time: 0.3469  data: 0.0004  max mem: 2501
Train: Epoch[1/5]  [2160/3125]  eta: 0:05:35  Lr: 0.001875  Loss: -0.0695  Acc@1: 81.2500 (81.2876)  Acc@5: 100.0000 (97.3710)  time: 0.3468  data: 0.0006  max mem: 2501
Train: Epoch[1/5]  [2170/3125]  eta: 0:05:32  Lr: 0.001875  Loss: -0.2713  Acc@1: 87.5000 (81.3076)  Acc@5: 100.0000 (97.3716)  time: 0.3466  data: 0.0007  max mem: 2501
Train: Epoch[1/5]  [2180/3125]  eta: 0:05:28  Lr: 0.001875  Loss: -0.1160  Acc@1: 87.5000 (81.3274)  Acc@5: 100.0000 (97.3751)  time: 0.3456  data: 0.0005  max mem: 2501
Train: Epoch[1/5]  [2190/3125]  eta: 0:05:25  Lr: 0.001875  Loss: -0.0517  Acc@1: 87.5000 (81.3641)  Acc@5: 100.0000 (97.3728)  time: 0.3479  data: 0.0006  max mem: 2501
Train: Epoch[1/5]  [2200/3125]  eta: 0:05:22  Lr: 0.001875  Loss: -0.5105  Acc@1: 87.5000 (81.3835)  Acc@5: 100.0000 (97.3819)  time: 0.3484  data: 0.0006  max mem: 2501
Train: Epoch[1/5]  [2210/3125]  eta: 0:05:18  Lr: 0.001875  Loss: -0.2473  Acc@1: 87.5000 (81.4026)  Acc@5: 100.0000 (97.3796)  time: 0.3472  data: 0.0006  max mem: 2501
Train: Epoch[1/5]  [2220/3125]  eta: 0:05:15  Lr: 0.001875  Loss: -0.1910  Acc@1: 87.5000 (81.4160)  Acc@5: 100.0000 (97.3773)  time: 0.3482  data: 0.0006  max mem: 2501
Train: Epoch[1/5]  [2230/3125]  eta: 0:05:11  Lr: 0.001875  Loss: 0.0606  Acc@1: 87.5000 (81.4265)  Acc@5: 100.0000 (97.3751)  time: 0.3514  data: 0.0032  max mem: 2501
Train: Epoch[1/5]  [2240/3125]  eta: 0:05:08  Lr: 0.001875  Loss: -0.2616  Acc@1: 81.2500 (81.4201)  Acc@5: 100.0000 (97.3812)  time: 0.3510  data: 0.0036  max mem: 2501
Train: Epoch[1/5]  [2250/3125]  eta: 0:05:04  Lr: 0.001875  Loss: -0.1259  Acc@1: 81.2500 (81.4499)  Acc@5: 100.0000 (97.3900)  time: 0.3473  data: 0.0008  max mem: 2501
Train: Epoch[1/5]  [2260/3125]  eta: 0:05:01  Lr: 0.001875  Loss: -0.2950  Acc@1: 81.2500 (81.4463)  Acc@5: 100.0000 (97.3933)  time: 0.3472  data: 0.0006  max mem: 2501
Train: Epoch[1/5]  [2270/3125]  eta: 0:04:57  Lr: 0.001875  Loss: -0.5583  Acc@1: 81.2500 (81.4454)  Acc@5: 100.0000 (97.4020)  time: 0.3471  data: 0.0010  max mem: 2501
Train: Epoch[1/5]  [2280/3125]  eta: 0:04:54  Lr: 0.001875  Loss: -0.5441  Acc@1: 81.2500 (81.4637)  Acc@5: 100.0000 (97.4052)  time: 0.3466  data: 0.0011  max mem: 2501
Train: Epoch[1/5]  [2290/3125]  eta: 0:04:50  Lr: 0.001875  Loss: -0.3981  Acc@1: 87.5000 (81.4873)  Acc@5: 100.0000 (97.4056)  time: 0.3462  data: 0.0007  max mem: 2501
Train: Epoch[1/5]  [2300/3125]  eta: 0:04:47  Lr: 0.001875  Loss: -0.5792  Acc@1: 87.5000 (81.5189)  Acc@5: 100.0000 (97.4169)  time: 0.3465  data: 0.0005  max mem: 2501
Train: Epoch[1/5]  [2310/3125]  eta: 0:04:43  Lr: 0.001875  Loss: 0.2678  Acc@1: 81.2500 (81.5177)  Acc@5: 100.0000 (97.4199)  time: 0.3466  data: 0.0005  max mem: 2501
Train: Epoch[1/5]  [2320/3125]  eta: 0:04:40  Lr: 0.001875  Loss: -0.5694  Acc@1: 81.2500 (81.5247)  Acc@5: 100.0000 (97.4230)  time: 0.3476  data: 0.0005  max mem: 2501
Train: Epoch[1/5]  [2330/3125]  eta: 0:04:36  Lr: 0.001875  Loss: -0.3492  Acc@1: 87.5000 (81.5449)  Acc@5: 100.0000 (97.4260)  time: 0.3490  data: 0.0013  max mem: 2501
Train: Epoch[1/5]  [2340/3125]  eta: 0:04:33  Lr: 0.001875  Loss: -0.5958  Acc@1: 87.5000 (81.5570)  Acc@5: 100.0000 (97.4263)  time: 0.3489  data: 0.0016  max mem: 2501
Train: Epoch[1/5]  [2350/3125]  eta: 0:04:29  Lr: 0.001875  Loss: -0.4416  Acc@1: 81.2500 (81.5690)  Acc@5: 100.0000 (97.4293)  time: 0.3476  data: 0.0009  max mem: 2501
Train: Epoch[1/5]  [2360/3125]  eta: 0:04:26  Lr: 0.001875  Loss: 0.3147  Acc@1: 87.5000 (81.5783)  Acc@5: 100.0000 (97.4375)  time: 0.3470  data: 0.0006  max mem: 2501
Train: Epoch[1/5]  [2370/3125]  eta: 0:04:22  Lr: 0.001875  Loss: -0.2671  Acc@1: 87.5000 (81.5769)  Acc@5: 100.0000 (97.4404)  time: 0.3464  data: 0.0005  max mem: 2501
Train: Epoch[1/5]  [2380/3125]  eta: 0:04:19  Lr: 0.001875  Loss: 0.1199  Acc@1: 87.5000 (81.5860)  Acc@5: 100.0000 (97.4354)  time: 0.3465  data: 0.0004  max mem: 2501
Train: Epoch[1/5]  [2390/3125]  eta: 0:04:15  Lr: 0.001875  Loss: -0.3943  Acc@1: 87.5000 (81.5924)  Acc@5: 93.7500 (97.4305)  time: 0.3476  data: 0.0004  max mem: 2501
Train: Epoch[1/5]  [2400/3125]  eta: 0:04:12  Lr: 0.001875  Loss: -0.4338  Acc@1: 87.5000 (81.6014)  Acc@5: 100.0000 (97.4360)  time: 0.3477  data: 0.0004  max mem: 2501
Train: Epoch[1/5]  [2410/3125]  eta: 0:04:08  Lr: 0.001875  Loss: -0.1943  Acc@1: 87.5000 (81.6311)  Acc@5: 100.0000 (97.4362)  time: 0.3474  data: 0.0005  max mem: 2501
Train: Epoch[1/5]  [2420/3125]  eta: 0:04:05  Lr: 0.001875  Loss: -0.3736  Acc@1: 87.5000 (81.6476)  Acc@5: 100.0000 (97.4417)  time: 0.3487  data: 0.0007  max mem: 2501
Train: Epoch[1/5]  [2430/3125]  eta: 0:04:01  Lr: 0.001875  Loss: 0.1716  Acc@1: 81.2500 (81.6434)  Acc@5: 100.0000 (97.4445)  time: 0.3490  data: 0.0006  max mem: 2501
Train: Epoch[1/5]  [2440/3125]  eta: 0:03:58  Lr: 0.001875  Loss: -0.3303  Acc@1: 81.2500 (81.6520)  Acc@5: 100.0000 (97.4498)  time: 0.3480  data: 0.0005  max mem: 2501
Train: Epoch[1/5]  [2450/3125]  eta: 0:03:54  Lr: 0.001875  Loss: -0.4002  Acc@1: 81.2500 (81.6503)  Acc@5: 100.0000 (97.4500)  time: 0.3483  data: 0.0005  max mem: 2501
Train: Epoch[1/5]  [2460/3125]  eta: 0:03:51  Lr: 0.001875  Loss: -0.0410  Acc@1: 81.2500 (81.6487)  Acc@5: 100.0000 (97.4553)  time: 0.3489  data: 0.0006  max mem: 2501
Train: Epoch[1/5]  [2470/3125]  eta: 0:03:48  Lr: 0.001875  Loss: -0.1718  Acc@1: 81.2500 (81.6623)  Acc@5: 100.0000 (97.4605)  time: 0.3488  data: 0.0006  max mem: 2501
Train: Epoch[1/5]  [2480/3125]  eta: 0:03:44  Lr: 0.001875  Loss: -0.2874  Acc@1: 87.5000 (81.6833)  Acc@5: 100.0000 (97.4657)  time: 0.3480  data: 0.0007  max mem: 2501
Train: Epoch[1/5]  [2490/3125]  eta: 0:03:41  Lr: 0.001875  Loss: -0.3871  Acc@1: 81.2500 (81.6790)  Acc@5: 100.0000 (97.4584)  time: 0.3480  data: 0.0007  max mem: 2501
Train: Epoch[1/5]  [2500/3125]  eta: 0:03:37  Lr: 0.001875  Loss: -0.0584  Acc@1: 87.5000 (81.7098)  Acc@5: 93.7500 (97.4560)  time: 0.3478  data: 0.0005  max mem: 2501
Train: Epoch[1/5]  [2510/3125]  eta: 0:03:34  Lr: 0.001875  Loss: -0.5373  Acc@1: 87.5000 (81.7503)  Acc@5: 100.0000 (97.4637)  time: 0.3473  data: 0.0006  max mem: 2501
Train: Epoch[1/5]  [2520/3125]  eta: 0:03:30  Lr: 0.001875  Loss: -0.7088  Acc@1: 87.5000 (81.7458)  Acc@5: 100.0000 (97.4613)  time: 0.3486  data: 0.0005  max mem: 2501
Train: Epoch[1/5]  [2530/3125]  eta: 0:03:27  Lr: 0.001875  Loss: -0.2221  Acc@1: 81.2500 (81.7463)  Acc@5: 100.0000 (97.4714)  time: 0.3499  data: 0.0007  max mem: 2501
Train: Epoch[1/5]  [2540/3125]  eta: 0:03:23  Lr: 0.001875  Loss: -0.2441  Acc@1: 81.2500 (81.7518)  Acc@5: 100.0000 (97.4788)  time: 0.3499  data: 0.0008  max mem: 2501
Train: Epoch[1/5]  [2550/3125]  eta: 0:03:20  Lr: 0.001875  Loss: -0.5114  Acc@1: 87.5000 (81.7694)  Acc@5: 100.0000 (97.4863)  time: 0.3491  data: 0.0007  max mem: 2501
Train: Epoch[1/5]  [2560/3125]  eta: 0:03:16  Lr: 0.001875  Loss: -0.5247  Acc@1: 87.5000 (81.7893)  Acc@5: 100.0000 (97.4912)  time: 0.3470  data: 0.0005  max mem: 2501
Train: Epoch[1/5]  [2570/3125]  eta: 0:03:13  Lr: 0.001875  Loss: -0.4889  Acc@1: 87.5000 (81.8164)  Acc@5: 100.0000 (97.4961)  time: 0.3467  data: 0.0007  max mem: 2501
Train: Epoch[1/5]  [2580/3125]  eta: 0:03:09  Lr: 0.001875  Loss: -0.7178  Acc@1: 93.7500 (81.8384)  Acc@5: 100.0000 (97.4961)  time: 0.3471  data: 0.0008  max mem: 2501
Train: Epoch[1/5]  [2590/3125]  eta: 0:03:06  Lr: 0.001875  Loss: -0.1330  Acc@1: 87.5000 (81.8506)  Acc@5: 100.0000 (97.4986)  time: 0.3460  data: 0.0007  max mem: 2501
Train: Epoch[1/5]  [2600/3125]  eta: 0:03:02  Lr: 0.001875  Loss: -0.3611  Acc@1: 87.5000 (81.8748)  Acc@5: 100.0000 (97.5010)  time: 0.3453  data: 0.0005  max mem: 2501
Train: Epoch[1/5]  [2610/3125]  eta: 0:02:59  Lr: 0.001875  Loss: 0.0123  Acc@1: 87.5000 (81.8939)  Acc@5: 100.0000 (97.5010)  time: 0.3454  data: 0.0005  max mem: 2501
Train: Epoch[1/5]  [2620/3125]  eta: 0:02:55  Lr: 0.001875  Loss: -0.4924  Acc@1: 87.5000 (81.9010)  Acc@5: 100.0000 (97.5010)  time: 0.3465  data: 0.0004  max mem: 2501
Train: Epoch[1/5]  [2630/3125]  eta: 0:02:52  Lr: 0.001875  Loss: -0.3103  Acc@1: 81.2500 (81.8938)  Acc@5: 100.0000 (97.4986)  time: 0.3463  data: 0.0012  max mem: 2501
Train: Epoch[1/5]  [2640/3125]  eta: 0:02:48  Lr: 0.001875  Loss: -0.4551  Acc@1: 81.2500 (81.9079)  Acc@5: 100.0000 (97.4962)  time: 0.3469  data: 0.0012  max mem: 2501
Train: Epoch[1/5]  [2650/3125]  eta: 0:02:45  Lr: 0.001875  Loss: -0.4558  Acc@1: 81.2500 (81.9078)  Acc@5: 93.7500 (97.4892)  time: 0.3479  data: 0.0005  max mem: 2501
Train: Epoch[1/5]  [2660/3125]  eta: 0:02:41  Lr: 0.001875  Loss: -0.6273  Acc@1: 81.2500 (81.9123)  Acc@5: 93.7500 (97.4821)  time: 0.3471  data: 0.0012  max mem: 2501
Train: Epoch[1/5]  [2670/3125]  eta: 0:02:38  Lr: 0.001875  Loss: -0.2565  Acc@1: 87.5000 (81.9356)  Acc@5: 100.0000 (97.4916)  time: 0.3467  data: 0.0014  max mem: 2501
Train: Epoch[1/5]  [2680/3125]  eta: 0:02:34  Lr: 0.001875  Loss: -0.1197  Acc@1: 81.2500 (81.9261)  Acc@5: 100.0000 (97.5009)  time: 0.3477  data: 0.0008  max mem: 2501
Train: Epoch[1/5]  [2690/3125]  eta: 0:02:31  Lr: 0.001875  Loss: -0.1547  Acc@1: 81.2500 (81.9468)  Acc@5: 100.0000 (97.4986)  time: 0.3477  data: 0.0005  max mem: 2501
Train: Epoch[1/5]  [2700/3125]  eta: 0:02:27  Lr: 0.001875  Loss: -0.5806  Acc@1: 87.5000 (81.9627)  Acc@5: 100.0000 (97.5056)  time: 0.3480  data: 0.0005  max mem: 2501
Train: Epoch[1/5]  [2710/3125]  eta: 0:02:24  Lr: 0.001875  Loss: -0.5497  Acc@1: 87.5000 (81.9693)  Acc@5: 100.0000 (97.5032)  time: 0.3478  data: 0.0006  max mem: 2501
Train: Epoch[1/5]  [2720/3125]  eta: 0:02:20  Lr: 0.001875  Loss: -0.5584  Acc@1: 87.5000 (81.9598)  Acc@5: 100.0000 (97.5101)  time: 0.3456  data: 0.0006  max mem: 2501
Train: Epoch[1/5]  [2730/3125]  eta: 0:02:17  Lr: 0.001875  Loss: -0.2989  Acc@1: 87.5000 (81.9778)  Acc@5: 100.0000 (97.5124)  time: 0.3459  data: 0.0005  max mem: 2501
Train: Epoch[1/5]  [2740/3125]  eta: 0:02:13  Lr: 0.001875  Loss: -0.3714  Acc@1: 87.5000 (81.9911)  Acc@5: 100.0000 (97.5169)  time: 0.3487  data: 0.0006  max mem: 2501
Train: Epoch[1/5]  [2750/3125]  eta: 0:02:10  Lr: 0.001875  Loss: -0.4450  Acc@1: 87.5000 (81.9997)  Acc@5: 100.0000 (97.5214)  time: 0.3494  data: 0.0007  max mem: 2501
Train: Epoch[1/5]  [2760/3125]  eta: 0:02:07  Lr: 0.001875  Loss: -0.6247  Acc@1: 87.5000 (82.0151)  Acc@5: 100.0000 (97.5258)  time: 0.3474  data: 0.0009  max mem: 2501
Train: Epoch[1/5]  [2770/3125]  eta: 0:02:03  Lr: 0.001875  Loss: -0.1963  Acc@1: 87.5000 (82.0304)  Acc@5: 100.0000 (97.5257)  time: 0.3475  data: 0.0009  max mem: 2501
Train: Epoch[1/5]  [2780/3125]  eta: 0:02:00  Lr: 0.001875  Loss: -0.4743  Acc@1: 81.2500 (82.0433)  Acc@5: 100.0000 (97.5324)  time: 0.3479  data: 0.0007  max mem: 2501
Train: Epoch[1/5]  [2790/3125]  eta: 0:01:56  Lr: 0.001875  Loss: -0.0610  Acc@1: 81.2500 (82.0606)  Acc@5: 100.0000 (97.5322)  time: 0.3468  data: 0.0006  max mem: 2501
Train: Epoch[1/5]  [2800/3125]  eta: 0:01:53  Lr: 0.001875  Loss: -0.0728  Acc@1: 81.2500 (82.0533)  Acc@5: 100.0000 (97.5388)  time: 0.3476  data: 0.0005  max mem: 2501
Train: Epoch[1/5]  [2810/3125]  eta: 0:01:49  Lr: 0.001875  Loss: -0.6527  Acc@1: 81.2500 (82.0638)  Acc@5: 100.0000 (97.5409)  time: 0.3472  data: 0.0006  max mem: 2501
Train: Epoch[1/5]  [2820/3125]  eta: 0:01:46  Lr: 0.001875  Loss: -0.5157  Acc@1: 81.2500 (82.0764)  Acc@5: 100.0000 (97.5474)  time: 0.3456  data: 0.0006  max mem: 2501
Train: Epoch[1/5]  [2830/3125]  eta: 0:01:42  Lr: 0.001875  Loss: -0.3365  Acc@1: 81.2500 (82.0867)  Acc@5: 100.0000 (97.5495)  time: 0.3465  data: 0.0006  max mem: 2501
Train: Epoch[1/5]  [2840/3125]  eta: 0:01:39  Lr: 0.001875  Loss: 0.6948  Acc@1: 81.2500 (82.0882)  Acc@5: 100.0000 (97.5493)  time: 0.3470  data: 0.0006  max mem: 2501
Train: Epoch[1/5]  [2850/3125]  eta: 0:01:35  Lr: 0.001875  Loss: 0.4761  Acc@1: 87.5000 (82.0940)  Acc@5: 100.0000 (97.5535)  time: 0.3471  data: 0.0006  max mem: 2501
Train: Epoch[1/5]  [2860/3125]  eta: 0:01:32  Lr: 0.001875  Loss: -0.4175  Acc@1: 87.5000 (82.1042)  Acc@5: 100.0000 (97.5555)  time: 0.3470  data: 0.0006  max mem: 2501
Train: Epoch[1/5]  [2870/3125]  eta: 0:01:28  Lr: 0.001875  Loss: -0.6755  Acc@1: 87.5000 (82.1317)  Acc@5: 100.0000 (97.5553)  time: 0.3463  data: 0.0005  max mem: 2501
Train: Epoch[1/5]  [2880/3125]  eta: 0:01:25  Lr: 0.001875  Loss: -0.1629  Acc@1: 87.5000 (82.1460)  Acc@5: 100.0000 (97.5594)  time: 0.3481  data: 0.0006  max mem: 2501
Train: Epoch[1/5]  [2890/3125]  eta: 0:01:21  Lr: 0.001875  Loss: -0.2618  Acc@1: 87.5000 (82.1688)  Acc@5: 100.0000 (97.5657)  time: 0.3477  data: 0.0006  max mem: 2501
Train: Epoch[1/5]  [2900/3125]  eta: 0:01:18  Lr: 0.001875  Loss: -0.6488  Acc@1: 87.5000 (82.1850)  Acc@5: 100.0000 (97.5590)  time: 0.3471  data: 0.0004  max mem: 2501
Train: Epoch[1/5]  [2910/3125]  eta: 0:01:14  Lr: 0.001875  Loss: 0.0028  Acc@1: 87.5000 (82.1925)  Acc@5: 93.7500 (97.5588)  time: 0.3489  data: 0.0005  max mem: 2501
Train: Epoch[1/5]  [2920/3125]  eta: 0:01:11  Lr: 0.001875  Loss: -0.3684  Acc@1: 87.5000 (82.2107)  Acc@5: 100.0000 (97.5586)  time: 0.3477  data: 0.0005  max mem: 2501
Train: Epoch[1/5]  [2930/3125]  eta: 0:01:07  Lr: 0.001875  Loss: -0.6772  Acc@1: 87.5000 (82.2160)  Acc@5: 100.0000 (97.5584)  time: 0.3476  data: 0.0004  max mem: 2501
Train: Epoch[1/5]  [2940/3125]  eta: 0:01:04  Lr: 0.001875  Loss: 0.0059  Acc@1: 81.2500 (82.2254)  Acc@5: 100.0000 (97.5582)  time: 0.3487  data: 0.0009  max mem: 2501
Train: Epoch[1/5]  [2950/3125]  eta: 0:01:00  Lr: 0.001875  Loss: -0.3580  Acc@1: 87.5000 (82.2348)  Acc@5: 100.0000 (97.5601)  time: 0.3482  data: 0.0012  max mem: 2501
Train: Epoch[1/5]  [2960/3125]  eta: 0:00:57  Lr: 0.001875  Loss: -0.2495  Acc@1: 81.2500 (82.2294)  Acc@5: 100.0000 (97.5621)  time: 0.3474  data: 0.0008  max mem: 2501
Train: Epoch[1/5]  [2970/3125]  eta: 0:00:53  Lr: 0.001875  Loss: -0.4092  Acc@1: 87.5000 (82.2556)  Acc@5: 100.0000 (97.5640)  time: 0.3478  data: 0.0007  max mem: 2501
Train: Epoch[1/5]  [2980/3125]  eta: 0:00:50  Lr: 0.001875  Loss: -0.3208  Acc@1: 87.5000 (82.2752)  Acc@5: 100.0000 (97.5679)  time: 0.3473  data: 0.0006  max mem: 2501
Train: Epoch[1/5]  [2990/3125]  eta: 0:00:46  Lr: 0.001875  Loss: -0.2326  Acc@1: 87.5000 (82.2885)  Acc@5: 100.0000 (97.5740)  time: 0.3469  data: 0.0006  max mem: 2501
Train: Epoch[1/5]  [3000/3125]  eta: 0:00:43  Lr: 0.001875  Loss: -0.2500  Acc@1: 87.5000 (82.3038)  Acc@5: 100.0000 (97.5800)  time: 0.3481  data: 0.0007  max mem: 2501
Train: Epoch[1/5]  [3010/3125]  eta: 0:00:40  Lr: 0.001875  Loss: -0.0846  Acc@1: 87.5000 (82.3024)  Acc@5: 100.0000 (97.5859)  time: 0.3481  data: 0.0006  max mem: 2501
Train: Epoch[1/5]  [3020/3125]  eta: 0:00:36  Lr: 0.001875  Loss: -0.1182  Acc@1: 75.0000 (82.2927)  Acc@5: 100.0000 (97.5877)  time: 0.3470  data: 0.0005  max mem: 2501
Train: Epoch[1/5]  [3030/3125]  eta: 0:00:33  Lr: 0.001875  Loss: -0.6568  Acc@1: 87.5000 (82.3161)  Acc@5: 100.0000 (97.5957)  time: 0.3458  data: 0.0005  max mem: 2501
Train: Epoch[1/5]  [3040/3125]  eta: 0:00:29  Lr: 0.001875  Loss: -0.3362  Acc@1: 87.5000 (82.3269)  Acc@5: 100.0000 (97.5954)  time: 0.3471  data: 0.0005  max mem: 2501
Train: Epoch[1/5]  [3050/3125]  eta: 0:00:26  Lr: 0.001875  Loss: -0.4237  Acc@1: 87.5000 (82.3500)  Acc@5: 100.0000 (97.6032)  time: 0.3506  data: 0.0009  max mem: 2501
Train: Epoch[1/5]  [3060/3125]  eta: 0:00:22  Lr: 0.001875  Loss: -0.0844  Acc@1: 87.5000 (82.3505)  Acc@5: 100.0000 (97.6090)  time: 0.3496  data: 0.0010  max mem: 2501
Train: Epoch[1/5]  [3070/3125]  eta: 0:00:19  Lr: 0.001875  Loss: -0.3966  Acc@1: 87.5000 (82.3734)  Acc@5: 100.0000 (97.6127)  time: 0.3462  data: 0.0006  max mem: 2501
Train: Epoch[1/5]  [3080/3125]  eta: 0:00:15  Lr: 0.001875  Loss: -0.4487  Acc@1: 87.5000 (82.3759)  Acc@5: 100.0000 (97.6144)  time: 0.3476  data: 0.0006  max mem: 2501
Train: Epoch[1/5]  [3090/3125]  eta: 0:00:12  Lr: 0.001875  Loss: -0.5853  Acc@1: 81.2500 (82.3763)  Acc@5: 100.0000 (97.6120)  time: 0.3483  data: 0.0007  max mem: 2501
Train: Epoch[1/5]  [3100/3125]  eta: 0:00:08  Lr: 0.001875  Loss: -0.0413  Acc@1: 87.5000 (82.3887)  Acc@5: 100.0000 (97.6177)  time: 0.3473  data: 0.0005  max mem: 2501
Train: Epoch[1/5]  [3110/3125]  eta: 0:00:05  Lr: 0.001875  Loss: -0.2773  Acc@1: 81.2500 (82.3851)  Acc@5: 100.0000 (97.6193)  time: 0.3459  data: 0.0005  max mem: 2501
Train: Epoch[1/5]  [3120/3125]  eta: 0:00:01  Lr: 0.001875  Loss: -0.2694  Acc@1: 81.2500 (82.3835)  Acc@5: 100.0000 (97.6250)  time: 0.3462  data: 0.0009  max mem: 2501
Train: Epoch[1/5]  [3124/3125]  eta: 0:00:00  Lr: 0.001875  Loss: -0.0842  Acc@1: 81.2500 (82.3780)  Acc@5: 100.0000 (97.6240)  time: 0.3474  data: 0.0009  max mem: 2501
Train: Epoch[1/5] Total time: 0:18:08 (0.3482 s / it)
{0: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 1: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 2: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 3: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 4: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 5: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 6: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 7: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 8: {0: 0, 1: 0, 2: 50000, 3: 0, 4: 0}, 9: {0: 0, 1: 0, 2: 50000, 3: 0, 4: 0}, 10: {0: 0, 1: 0, 2: 50000, 3: 0, 4: 0}, 11: {0: 0, 1: 0, 2: 50000, 3: 0, 4: 0}, 12: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 13: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 14: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 15: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 16: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 17: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 18: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 19: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}}
Averaged stats: Lr: 0.001875  Loss: -0.0842  Acc@1: 81.2500 (82.3780)  Acc@5: 100.0000 (97.6240)
Train: Epoch[2/5]  [   0/3125]  eta: 0:34:45  Lr: 0.001875  Loss: -0.3788  Acc@1: 87.5000 (87.5000)  Acc@5: 93.7500 (93.7500)  time: 0.6674  data: 0.3248  max mem: 2501
Train: Epoch[2/5]  [  10/3125]  eta: 0:19:36  Lr: 0.001875  Loss: -0.1414  Acc@1: 81.2500 (85.2273)  Acc@5: 93.7500 (96.0227)  time: 0.3777  data: 0.0301  max mem: 2501
Train: Epoch[2/5]  [  20/3125]  eta: 0:18:47  Lr: 0.001875  Loss: -0.0960  Acc@1: 81.2500 (83.9286)  Acc@5: 100.0000 (97.6190)  time: 0.3480  data: 0.0007  max mem: 2501
Train: Epoch[2/5]  [  30/3125]  eta: 0:18:30  Lr: 0.001875  Loss: -0.3741  Acc@1: 81.2500 (84.4758)  Acc@5: 100.0000 (97.7823)  time: 0.3484  data: 0.0007  max mem: 2501
Train: Epoch[2/5]  [  40/3125]  eta: 0:18:19  Lr: 0.001875  Loss: -0.6088  Acc@1: 81.2500 (85.2134)  Acc@5: 100.0000 (98.0183)  time: 0.3491  data: 0.0006  max mem: 2501
Train: Epoch[2/5]  [  50/3125]  eta: 0:18:11  Lr: 0.001875  Loss: 0.0352  Acc@1: 87.5000 (85.5392)  Acc@5: 100.0000 (98.2843)  time: 0.3490  data: 0.0007  max mem: 2501
Train: Epoch[2/5]  [  60/3125]  eta: 0:18:04  Lr: 0.001875  Loss: -0.4273  Acc@1: 87.5000 (86.2705)  Acc@5: 100.0000 (98.4631)  time: 0.3489  data: 0.0009  max mem: 2501
Train: Epoch[2/5]  [  70/3125]  eta: 0:17:58  Lr: 0.001875  Loss: -0.1247  Acc@1: 87.5000 (85.4754)  Acc@5: 100.0000 (98.2394)  time: 0.3483  data: 0.0007  max mem: 2501
Train: Epoch[2/5]  [  80/3125]  eta: 0:17:54  Lr: 0.001875  Loss: -0.0917  Acc@1: 81.2500 (84.2593)  Acc@5: 93.7500 (97.9167)  time: 0.3497  data: 0.0005  max mem: 2501
Train: Epoch[2/5]  [  90/3125]  eta: 0:17:49  Lr: 0.001875  Loss: -0.4911  Acc@1: 81.2500 (84.2720)  Acc@5: 100.0000 (97.8022)  time: 0.3497  data: 0.0006  max mem: 2501
Train: Epoch[2/5]  [ 100/3125]  eta: 0:17:44  Lr: 0.001875  Loss: -0.0383  Acc@1: 87.5000 (84.0965)  Acc@5: 100.0000 (97.5248)  time: 0.3480  data: 0.0007  max mem: 2501
Train: Epoch[2/5]  [ 110/3125]  eta: 0:17:40  Lr: 0.001875  Loss: -0.3078  Acc@1: 87.5000 (84.3468)  Acc@5: 100.0000 (97.7477)  time: 0.3485  data: 0.0009  max mem: 2501
Train: Epoch[2/5]  [ 120/3125]  eta: 0:17:35  Lr: 0.001875  Loss: -0.3865  Acc@1: 87.5000 (84.5558)  Acc@5: 100.0000 (97.7789)  time: 0.3482  data: 0.0008  max mem: 2501
Train: Epoch[2/5]  [ 130/3125]  eta: 0:17:30  Lr: 0.001875  Loss: -0.5246  Acc@1: 87.5000 (84.5420)  Acc@5: 100.0000 (97.9008)  time: 0.3468  data: 0.0006  max mem: 2501
Train: Epoch[2/5]  [ 140/3125]  eta: 0:17:27  Lr: 0.001875  Loss: -0.2548  Acc@1: 87.5000 (84.6631)  Acc@5: 100.0000 (98.0496)  time: 0.3483  data: 0.0018  max mem: 2501
Train: Epoch[2/5]  [ 150/3125]  eta: 0:17:23  Lr: 0.001875  Loss: -0.1764  Acc@1: 87.5000 (84.7268)  Acc@5: 100.0000 (98.0960)  time: 0.3487  data: 0.0017  max mem: 2501
Train: Epoch[2/5]  [ 160/3125]  eta: 0:17:18  Lr: 0.001875  Loss: 0.1571  Acc@1: 87.5000 (84.6273)  Acc@5: 100.0000 (98.0978)  time: 0.3470  data: 0.0005  max mem: 2501
Train: Epoch[2/5]  [ 170/3125]  eta: 0:17:15  Lr: 0.001875  Loss: -0.4685  Acc@1: 87.5000 (84.7953)  Acc@5: 100.0000 (98.0994)  time: 0.3487  data: 0.0013  max mem: 2501
Train: Epoch[2/5]  [ 180/3125]  eta: 0:17:11  Lr: 0.001875  Loss: -0.3738  Acc@1: 87.5000 (85.0138)  Acc@5: 100.0000 (98.1008)  time: 0.3502  data: 0.0016  max mem: 2501
Train: Epoch[2/5]  [ 190/3125]  eta: 0:17:07  Lr: 0.001875  Loss: -0.6707  Acc@1: 87.5000 (85.0458)  Acc@5: 100.0000 (98.1675)  time: 0.3472  data: 0.0007  max mem: 2501
Train: Epoch[2/5]  [ 200/3125]  eta: 0:17:03  Lr: 0.001875  Loss: -0.2012  Acc@1: 87.5000 (85.0124)  Acc@5: 100.0000 (98.1654)  time: 0.3455  data: 0.0005  max mem: 2501
Train: Epoch[2/5]  [ 210/3125]  eta: 0:16:59  Lr: 0.001875  Loss: -0.1722  Acc@1: 87.5000 (85.2784)  Acc@5: 100.0000 (98.2524)  time: 0.3466  data: 0.0006  max mem: 2501
Train: Epoch[2/5]  [ 220/3125]  eta: 0:16:55  Lr: 0.001875  Loss: 0.0167  Acc@1: 87.5000 (85.2376)  Acc@5: 100.0000 (98.2466)  time: 0.3474  data: 0.0006  max mem: 2501
Train: Epoch[2/5]  [ 230/3125]  eta: 0:16:51  Lr: 0.001875  Loss: -0.6342  Acc@1: 87.5000 (85.3355)  Acc@5: 100.0000 (98.2413)  time: 0.3469  data: 0.0007  max mem: 2501
Train: Epoch[2/5]  [ 240/3125]  eta: 0:16:48  Lr: 0.001875  Loss: 0.2515  Acc@1: 81.2500 (85.2178)  Acc@5: 100.0000 (98.1587)  time: 0.3480  data: 0.0006  max mem: 2501
Train: Epoch[2/5]  [ 250/3125]  eta: 0:16:44  Lr: 0.001875  Loss: 0.0361  Acc@1: 81.2500 (85.1096)  Acc@5: 100.0000 (98.1574)  time: 0.3500  data: 0.0007  max mem: 2501
Train: Epoch[2/5]  [ 260/3125]  eta: 0:16:41  Lr: 0.001875  Loss: -0.3309  Acc@1: 81.2500 (85.1054)  Acc@5: 100.0000 (98.1801)  time: 0.3497  data: 0.0006  max mem: 2501
Train: Epoch[2/5]  [ 270/3125]  eta: 0:16:37  Lr: 0.001875  Loss: -0.2678  Acc@1: 87.5000 (85.1707)  Acc@5: 100.0000 (98.2011)  time: 0.3486  data: 0.0005  max mem: 2501
Train: Epoch[2/5]  [ 280/3125]  eta: 0:16:33  Lr: 0.001875  Loss: -0.4214  Acc@1: 81.2500 (85.1423)  Acc@5: 100.0000 (98.1984)  time: 0.3467  data: 0.0008  max mem: 2501
Train: Epoch[2/5]  [ 290/3125]  eta: 0:16:30  Lr: 0.001875  Loss: -0.5700  Acc@1: 87.5000 (85.1160)  Acc@5: 100.0000 (98.1744)  time: 0.3467  data: 0.0008  max mem: 2501
Train: Epoch[2/5]  [ 300/3125]  eta: 0:16:26  Lr: 0.001875  Loss: 0.0330  Acc@1: 81.2500 (84.9875)  Acc@5: 100.0000 (98.0689)  time: 0.3478  data: 0.0005  max mem: 2501
Train: Epoch[2/5]  [ 310/3125]  eta: 0:16:22  Lr: 0.001875  Loss: -0.2635  Acc@1: 81.2500 (84.9879)  Acc@5: 100.0000 (98.0506)  time: 0.3472  data: 0.0005  max mem: 2501
Train: Epoch[2/5]  [ 320/3125]  eta: 0:16:19  Lr: 0.001875  Loss: -0.5199  Acc@1: 87.5000 (85.1441)  Acc@5: 100.0000 (98.0530)  time: 0.3465  data: 0.0004  max mem: 2501
Train: Epoch[2/5]  [ 330/3125]  eta: 0:16:15  Lr: 0.001875  Loss: -0.1519  Acc@1: 81.2500 (85.0453)  Acc@5: 100.0000 (98.0551)  time: 0.3464  data: 0.0004  max mem: 2501
Train: Epoch[2/5]  [ 340/3125]  eta: 0:16:11  Lr: 0.001875  Loss: -0.5731  Acc@1: 87.5000 (85.1723)  Acc@5: 100.0000 (98.0572)  time: 0.3471  data: 0.0005  max mem: 2501
Train: Epoch[2/5]  [ 350/3125]  eta: 0:16:08  Lr: 0.001875  Loss: -0.0363  Acc@1: 87.5000 (85.1674)  Acc@5: 100.0000 (98.0591)  time: 0.3484  data: 0.0007  max mem: 2501
Train: Epoch[2/5]  [ 360/3125]  eta: 0:16:04  Lr: 0.001875  Loss: -0.3991  Acc@1: 87.5000 (85.2147)  Acc@5: 100.0000 (98.0783)  time: 0.3485  data: 0.0012  max mem: 2501
Train: Epoch[2/5]  [ 370/3125]  eta: 0:16:01  Lr: 0.001875  Loss: -0.1244  Acc@1: 87.5000 (85.2594)  Acc@5: 100.0000 (98.1301)  time: 0.3481  data: 0.0011  max mem: 2501
Train: Epoch[2/5]  [ 380/3125]  eta: 0:15:57  Lr: 0.001875  Loss: -0.0049  Acc@1: 87.5000 (85.2690)  Acc@5: 100.0000 (98.0971)  time: 0.3489  data: 0.0004  max mem: 2501
Train: Epoch[2/5]  [ 390/3125]  eta: 0:15:54  Lr: 0.001875  Loss: -0.2650  Acc@1: 87.5000 (85.3421)  Acc@5: 100.0000 (98.1298)  time: 0.3484  data: 0.0005  max mem: 2501
Train: Epoch[2/5]  [ 400/3125]  eta: 0:15:50  Lr: 0.001875  Loss: -0.0363  Acc@1: 87.5000 (85.2868)  Acc@5: 100.0000 (98.1297)  time: 0.3466  data: 0.0007  max mem: 2501
Train: Epoch[2/5]  [ 410/3125]  eta: 0:15:46  Lr: 0.001875  Loss: -0.1609  Acc@1: 87.5000 (85.3558)  Acc@5: 100.0000 (98.1296)  time: 0.3474  data: 0.0007  max mem: 2501
Train: Epoch[2/5]  [ 420/3125]  eta: 0:15:43  Lr: 0.001875  Loss: -0.2506  Acc@1: 87.5000 (85.3622)  Acc@5: 100.0000 (98.1295)  time: 0.3486  data: 0.0007  max mem: 2501
Train: Epoch[2/5]  [ 430/3125]  eta: 0:15:39  Lr: 0.001875  Loss: 0.1797  Acc@1: 81.2500 (85.2523)  Acc@5: 100.0000 (98.1003)  time: 0.3474  data: 0.0008  max mem: 2501
Train: Epoch[2/5]  [ 440/3125]  eta: 0:15:36  Lr: 0.001875  Loss: -0.1922  Acc@1: 81.2500 (85.2183)  Acc@5: 100.0000 (98.1151)  time: 0.3470  data: 0.0008  max mem: 2501
Train: Epoch[2/5]  [ 450/3125]  eta: 0:15:32  Lr: 0.001875  Loss: -0.3713  Acc@1: 87.5000 (85.2550)  Acc@5: 100.0000 (98.1430)  time: 0.3487  data: 0.0007  max mem: 2501
Train: Epoch[2/5]  [ 460/3125]  eta: 0:15:29  Lr: 0.001875  Loss: -0.4143  Acc@1: 87.5000 (85.2766)  Acc@5: 100.0000 (98.1697)  time: 0.3486  data: 0.0005  max mem: 2501
Train: Epoch[2/5]  [ 470/3125]  eta: 0:15:25  Lr: 0.001875  Loss: -0.5765  Acc@1: 87.5000 (85.3105)  Acc@5: 100.0000 (98.1688)  time: 0.3465  data: 0.0006  max mem: 2501
Train: Epoch[2/5]  [ 480/3125]  eta: 0:15:22  Lr: 0.001875  Loss: -0.5103  Acc@1: 87.5000 (85.2651)  Acc@5: 100.0000 (98.1809)  time: 0.3467  data: 0.0006  max mem: 2501
Train: Epoch[2/5]  [ 490/3125]  eta: 0:15:18  Lr: 0.001875  Loss: -0.5470  Acc@1: 87.5000 (85.3488)  Acc@5: 100.0000 (98.2179)  time: 0.3471  data: 0.0005  max mem: 2501
Train: Epoch[2/5]  [ 500/3125]  eta: 0:15:14  Lr: 0.001875  Loss: -0.3518  Acc@1: 87.5000 (85.3792)  Acc@5: 100.0000 (98.2535)  time: 0.3467  data: 0.0005  max mem: 2501
Train: Epoch[2/5]  [ 510/3125]  eta: 0:15:11  Lr: 0.001875  Loss: -0.1586  Acc@1: 87.5000 (85.3596)  Acc@5: 100.0000 (98.2632)  time: 0.3469  data: 0.0007  max mem: 2501
Train: Epoch[2/5]  [ 520/3125]  eta: 0:15:07  Lr: 0.001875  Loss: -0.6202  Acc@1: 87.5000 (85.4966)  Acc@5: 100.0000 (98.2726)  time: 0.3473  data: 0.0008  max mem: 2501
Train: Epoch[2/5]  [ 530/3125]  eta: 0:15:04  Lr: 0.001875  Loss: -0.5117  Acc@1: 87.5000 (85.5226)  Acc@5: 100.0000 (98.2933)  time: 0.3471  data: 0.0006  max mem: 2501
Train: Epoch[2/5]  [ 540/3125]  eta: 0:15:00  Lr: 0.001875  Loss: -0.6122  Acc@1: 87.5000 (85.5938)  Acc@5: 100.0000 (98.2902)  time: 0.3485  data: 0.0014  max mem: 2501
Train: Epoch[2/5]  [ 550/3125]  eta: 0:14:57  Lr: 0.001875  Loss: -0.3259  Acc@1: 87.5000 (85.4923)  Acc@5: 100.0000 (98.2645)  time: 0.3488  data: 0.0021  max mem: 2501
Train: Epoch[2/5]  [ 560/3125]  eta: 0:14:53  Lr: 0.001875  Loss: 0.1452  Acc@1: 81.2500 (85.4167)  Acc@5: 100.0000 (98.2620)  time: 0.3470  data: 0.0012  max mem: 2501
Train: Epoch[2/5]  [ 570/3125]  eta: 0:14:50  Lr: 0.001875  Loss: -0.1042  Acc@1: 87.5000 (85.4969)  Acc@5: 100.0000 (98.2487)  time: 0.3473  data: 0.0005  max mem: 2501
Train: Epoch[2/5]  [ 580/3125]  eta: 0:14:46  Lr: 0.001875  Loss: -0.5749  Acc@1: 87.5000 (85.5422)  Acc@5: 100.0000 (98.2358)  time: 0.3471  data: 0.0006  max mem: 2501
Train: Epoch[2/5]  [ 590/3125]  eta: 0:14:43  Lr: 0.001875  Loss: -0.0584  Acc@1: 87.5000 (85.5224)  Acc@5: 100.0000 (98.2234)  time: 0.3463  data: 0.0006  max mem: 2501
Train: Epoch[2/5]  [ 600/3125]  eta: 0:14:39  Lr: 0.001875  Loss: -0.4909  Acc@1: 87.5000 (85.5449)  Acc@5: 100.0000 (98.2321)  time: 0.3472  data: 0.0007  max mem: 2501
Train: Epoch[2/5]  [ 610/3125]  eta: 0:14:36  Lr: 0.001875  Loss: -0.4274  Acc@1: 87.5000 (85.4951)  Acc@5: 100.0000 (98.2099)  time: 0.3470  data: 0.0008  max mem: 2501
Train: Epoch[2/5]  [ 620/3125]  eta: 0:14:32  Lr: 0.001875  Loss: -0.2780  Acc@1: 81.2500 (85.4771)  Acc@5: 100.0000 (98.2287)  time: 0.3460  data: 0.0007  max mem: 2501
Train: Epoch[2/5]  [ 630/3125]  eta: 0:14:28  Lr: 0.001875  Loss: -0.5581  Acc@1: 81.2500 (85.4992)  Acc@5: 100.0000 (98.2369)  time: 0.3461  data: 0.0005  max mem: 2501
Train: Epoch[2/5]  [ 640/3125]  eta: 0:14:25  Lr: 0.001875  Loss: -0.2921  Acc@1: 81.2500 (85.4329)  Acc@5: 100.0000 (98.2254)  time: 0.3488  data: 0.0023  max mem: 2501
Train: Epoch[2/5]  [ 650/3125]  eta: 0:14:22  Lr: 0.001875  Loss: -0.1491  Acc@1: 87.5000 (85.5031)  Acc@5: 100.0000 (98.2527)  time: 0.3506  data: 0.0023  max mem: 2501
Train: Epoch[2/5]  [ 660/3125]  eta: 0:14:18  Lr: 0.001875  Loss: -0.2438  Acc@1: 93.7500 (85.5995)  Acc@5: 100.0000 (98.2697)  time: 0.3480  data: 0.0018  max mem: 2501
Train: Epoch[2/5]  [ 670/3125]  eta: 0:14:15  Lr: 0.001875  Loss: -0.6407  Acc@1: 87.5000 (85.6744)  Acc@5: 100.0000 (98.2675)  time: 0.3470  data: 0.0018  max mem: 2501
Train: Epoch[2/5]  [ 680/3125]  eta: 0:14:11  Lr: 0.001875  Loss: -0.0503  Acc@1: 87.5000 (85.6553)  Acc@5: 100.0000 (98.2746)  time: 0.3487  data: 0.0007  max mem: 2501
Train: Epoch[2/5]  [ 690/3125]  eta: 0:14:08  Lr: 0.001875  Loss: -0.0690  Acc@1: 87.5000 (85.6639)  Acc@5: 100.0000 (98.2724)  time: 0.3478  data: 0.0011  max mem: 2501
Train: Epoch[2/5]  [ 700/3125]  eta: 0:14:04  Lr: 0.001875  Loss: -0.1231  Acc@1: 87.5000 (85.6277)  Acc@5: 100.0000 (98.2614)  time: 0.3479  data: 0.0009  max mem: 2501
Train: Epoch[2/5]  [ 710/3125]  eta: 0:14:01  Lr: 0.001875  Loss: -0.0226  Acc@1: 81.2500 (85.5837)  Acc@5: 100.0000 (98.2419)  time: 0.3480  data: 0.0005  max mem: 2501
Train: Epoch[2/5]  [ 720/3125]  eta: 0:13:57  Lr: 0.001875  Loss: -0.1287  Acc@1: 81.2500 (85.5583)  Acc@5: 100.0000 (98.2490)  time: 0.3462  data: 0.0005  max mem: 2501
Train: Epoch[2/5]  [ 730/3125]  eta: 0:13:54  Lr: 0.001875  Loss: -0.2023  Acc@1: 81.2500 (85.5250)  Acc@5: 100.0000 (98.2644)  time: 0.3472  data: 0.0006  max mem: 2501
Train: Epoch[2/5]  [ 740/3125]  eta: 0:13:50  Lr: 0.001875  Loss: -0.5129  Acc@1: 81.2500 (85.4673)  Acc@5: 100.0000 (98.2540)  time: 0.3476  data: 0.0007  max mem: 2501
Train: Epoch[2/5]  [ 750/3125]  eta: 0:13:46  Lr: 0.001875  Loss: -0.5374  Acc@1: 87.5000 (85.5193)  Acc@5: 100.0000 (98.2607)  time: 0.3474  data: 0.0012  max mem: 2501
Train: Epoch[2/5]  [ 760/3125]  eta: 0:13:43  Lr: 0.001875  Loss: -0.4563  Acc@1: 87.5000 (85.5371)  Acc@5: 100.0000 (98.2589)  time: 0.3481  data: 0.0012  max mem: 2501
Train: Epoch[2/5]  [ 770/3125]  eta: 0:13:40  Lr: 0.001875  Loss: -0.3649  Acc@1: 87.5000 (85.5707)  Acc@5: 100.0000 (98.2652)  time: 0.3479  data: 0.0007  max mem: 2501
Train: Epoch[2/5]  [ 780/3125]  eta: 0:13:36  Lr: 0.001875  Loss: -0.1867  Acc@1: 87.5000 (85.5554)  Acc@5: 100.0000 (98.2554)  time: 0.3469  data: 0.0005  max mem: 2501
Train: Epoch[2/5]  [ 790/3125]  eta: 0:13:32  Lr: 0.001875  Loss: 0.0552  Acc@1: 81.2500 (85.4930)  Acc@5: 100.0000 (98.2459)  time: 0.3472  data: 0.0007  max mem: 2501
Train: Epoch[2/5]  [ 800/3125]  eta: 0:13:29  Lr: 0.001875  Loss: -0.2423  Acc@1: 81.2500 (85.4791)  Acc@5: 100.0000 (98.2600)  time: 0.3486  data: 0.0007  max mem: 2501
Train: Epoch[2/5]  [ 810/3125]  eta: 0:13:25  Lr: 0.001875  Loss: 0.0248  Acc@1: 81.2500 (85.4501)  Acc@5: 100.0000 (98.2737)  time: 0.3475  data: 0.0005  max mem: 2501
Train: Epoch[2/5]  [ 820/3125]  eta: 0:13:22  Lr: 0.001875  Loss: -0.0025  Acc@1: 81.2500 (85.3913)  Acc@5: 100.0000 (98.2719)  time: 0.3469  data: 0.0005  max mem: 2501
Train: Epoch[2/5]  [ 830/3125]  eta: 0:13:18  Lr: 0.001875  Loss: -0.0864  Acc@1: 81.2500 (85.4091)  Acc@5: 100.0000 (98.2777)  time: 0.3469  data: 0.0005  max mem: 2501
Train: Epoch[2/5]  [ 840/3125]  eta: 0:13:15  Lr: 0.001875  Loss: -0.3521  Acc@1: 87.5000 (85.4340)  Acc@5: 100.0000 (98.2759)  time: 0.3472  data: 0.0006  max mem: 2501
Train: Epoch[2/5]  [ 850/3125]  eta: 0:13:11  Lr: 0.001875  Loss: -0.4434  Acc@1: 87.5000 (85.4216)  Acc@5: 100.0000 (98.2447)  time: 0.3466  data: 0.0006  max mem: 2501
Train: Epoch[2/5]  [ 860/3125]  eta: 0:13:08  Lr: 0.001875  Loss: -0.1191  Acc@1: 81.2500 (85.3659)  Acc@5: 93.7500 (98.2288)  time: 0.3461  data: 0.0008  max mem: 2501
Train: Epoch[2/5]  [ 870/3125]  eta: 0:13:04  Lr: 0.001875  Loss: -0.5791  Acc@1: 81.2500 (85.3401)  Acc@5: 100.0000 (98.2348)  time: 0.3469  data: 0.0008  max mem: 2501
Train: Epoch[2/5]  [ 880/3125]  eta: 0:13:01  Lr: 0.001875  Loss: -0.3434  Acc@1: 81.2500 (85.3079)  Acc@5: 100.0000 (98.2335)  time: 0.3459  data: 0.0005  max mem: 2501
Train: Epoch[2/5]  [ 890/3125]  eta: 0:12:57  Lr: 0.001875  Loss: -0.2553  Acc@1: 87.5000 (85.3676)  Acc@5: 100.0000 (98.2464)  time: 0.3461  data: 0.0005  max mem: 2501
Train: Epoch[2/5]  [ 900/3125]  eta: 0:12:54  Lr: 0.001875  Loss: 0.1658  Acc@1: 87.5000 (85.3565)  Acc@5: 100.0000 (98.2450)  time: 0.3459  data: 0.0005  max mem: 2501
Train: Epoch[2/5]  [ 910/3125]  eta: 0:12:50  Lr: 0.001875  Loss: -0.3067  Acc@1: 87.5000 (85.3869)  Acc@5: 100.0000 (98.2574)  time: 0.3468  data: 0.0005  max mem: 2501
Train: Epoch[2/5]  [ 920/3125]  eta: 0:12:47  Lr: 0.001875  Loss: -0.6870  Acc@1: 87.5000 (85.4235)  Acc@5: 100.0000 (98.2628)  time: 0.3492  data: 0.0016  max mem: 2501
Train: Epoch[2/5]  [ 930/3125]  eta: 0:12:43  Lr: 0.001875  Loss: -0.3729  Acc@1: 87.5000 (85.4525)  Acc@5: 100.0000 (98.2680)  time: 0.3496  data: 0.0017  max mem: 2501
Train: Epoch[2/5]  [ 940/3125]  eta: 0:12:40  Lr: 0.001875  Loss: -0.2495  Acc@1: 87.5000 (85.4344)  Acc@5: 100.0000 (98.2731)  time: 0.3493  data: 0.0008  max mem: 2501
Train: Epoch[2/5]  [ 950/3125]  eta: 0:12:36  Lr: 0.001875  Loss: -0.4540  Acc@1: 87.5000 (85.4627)  Acc@5: 100.0000 (98.2650)  time: 0.3485  data: 0.0007  max mem: 2501
Train: Epoch[2/5]  [ 960/3125]  eta: 0:12:33  Lr: 0.001875  Loss: -0.0916  Acc@1: 87.5000 (85.4709)  Acc@5: 100.0000 (98.2505)  time: 0.3466  data: 0.0005  max mem: 2501
Train: Epoch[2/5]  [ 970/3125]  eta: 0:12:29  Lr: 0.001875  Loss: -0.5602  Acc@1: 87.5000 (85.4982)  Acc@5: 93.7500 (98.2170)  time: 0.3471  data: 0.0006  max mem: 2501
Train: Epoch[2/5]  [ 980/3125]  eta: 0:12:26  Lr: 0.001875  Loss: -0.3654  Acc@1: 87.5000 (85.5505)  Acc@5: 100.0000 (98.2288)  time: 0.3479  data: 0.0007  max mem: 2501
Train: Epoch[2/5]  [ 990/3125]  eta: 0:12:22  Lr: 0.001875  Loss: -0.2696  Acc@1: 87.5000 (85.5449)  Acc@5: 100.0000 (98.2278)  time: 0.3470  data: 0.0005  max mem: 2501
Train: Epoch[2/5]  [1000/3125]  eta: 0:12:19  Lr: 0.001875  Loss: -0.3559  Acc@1: 87.5000 (85.5832)  Acc@5: 100.0000 (98.2330)  time: 0.3477  data: 0.0008  max mem: 2501
Train: Epoch[2/5]  [1010/3125]  eta: 0:12:16  Lr: 0.001875  Loss: -0.1444  Acc@1: 87.5000 (85.5650)  Acc@5: 100.0000 (98.2319)  time: 0.3483  data: 0.0016  max mem: 2501
Train: Epoch[2/5]  [1020/3125]  eta: 0:12:12  Lr: 0.001875  Loss: -0.2700  Acc@1: 87.5000 (85.5840)  Acc@5: 100.0000 (98.2125)  time: 0.3481  data: 0.0015  max mem: 2501
Train: Epoch[2/5]  [1030/3125]  eta: 0:12:09  Lr: 0.001875  Loss: -0.3944  Acc@1: 87.5000 (85.5723)  Acc@5: 100.0000 (98.2299)  time: 0.3486  data: 0.0007  max mem: 2501
Train: Epoch[2/5]  [1040/3125]  eta: 0:12:05  Lr: 0.001875  Loss: -0.4202  Acc@1: 81.2500 (85.5488)  Acc@5: 100.0000 (98.2409)  time: 0.3474  data: 0.0005  max mem: 2501
Train: Epoch[2/5]  [1050/3125]  eta: 0:12:02  Lr: 0.001875  Loss: -0.4741  Acc@1: 87.5000 (85.5435)  Acc@5: 100.0000 (98.2517)  time: 0.3475  data: 0.0005  max mem: 2501
Train: Epoch[2/5]  [1060/3125]  eta: 0:11:58  Lr: 0.001875  Loss: -0.3530  Acc@1: 87.5000 (85.4972)  Acc@5: 100.0000 (98.2564)  time: 0.3470  data: 0.0005  max mem: 2501
Train: Epoch[2/5]  [1070/3125]  eta: 0:11:55  Lr: 0.001875  Loss: -0.1620  Acc@1: 81.2500 (85.4750)  Acc@5: 100.0000 (98.2610)  time: 0.3465  data: 0.0013  max mem: 2501
Train: Epoch[2/5]  [1080/3125]  eta: 0:11:51  Lr: 0.001875  Loss: -0.3370  Acc@1: 87.5000 (85.4648)  Acc@5: 100.0000 (98.2539)  time: 0.3469  data: 0.0013  max mem: 2501
Train: Epoch[2/5]  [1090/3125]  eta: 0:11:48  Lr: 0.001875  Loss: -0.0553  Acc@1: 87.5000 (85.5007)  Acc@5: 100.0000 (98.2642)  time: 0.3469  data: 0.0005  max mem: 2501
Train: Epoch[2/5]  [1100/3125]  eta: 0:11:44  Lr: 0.001875  Loss: -0.0214  Acc@1: 87.5000 (85.5075)  Acc@5: 100.0000 (98.2686)  time: 0.3472  data: 0.0005  max mem: 2501
Train: Epoch[2/5]  [1110/3125]  eta: 0:11:41  Lr: 0.001875  Loss: -0.5328  Acc@1: 87.5000 (85.4748)  Acc@5: 100.0000 (98.2842)  time: 0.3476  data: 0.0016  max mem: 2501
Train: Epoch[2/5]  [1120/3125]  eta: 0:11:37  Lr: 0.001875  Loss: -0.0528  Acc@1: 87.5000 (85.4706)  Acc@5: 100.0000 (98.2661)  time: 0.3488  data: 0.0027  max mem: 2501
Train: Epoch[2/5]  [1130/3125]  eta: 0:11:34  Lr: 0.001875  Loss: -0.1502  Acc@1: 87.5000 (85.4885)  Acc@5: 100.0000 (98.2759)  time: 0.3496  data: 0.0016  max mem: 2501
Train: Epoch[2/5]  [1140/3125]  eta: 0:11:30  Lr: 0.001875  Loss: -0.5407  Acc@1: 81.2500 (85.4623)  Acc@5: 100.0000 (98.2745)  time: 0.3492  data: 0.0006  max mem: 2501
Train: Epoch[2/5]  [1150/3125]  eta: 0:11:27  Lr: 0.001875  Loss: -0.6247  Acc@1: 81.2500 (85.4637)  Acc@5: 100.0000 (98.2678)  time: 0.3475  data: 0.0006  max mem: 2501
Train: Epoch[2/5]  [1160/3125]  eta: 0:11:23  Lr: 0.001875  Loss: -0.2171  Acc@1: 87.5000 (85.4974)  Acc@5: 100.0000 (98.2666)  time: 0.3472  data: 0.0008  max mem: 2501
Train: Epoch[2/5]  [1170/3125]  eta: 0:11:20  Lr: 0.001875  Loss: 0.4008  Acc@1: 87.5000 (85.4665)  Acc@5: 100.0000 (98.2494)  time: 0.3490  data: 0.0008  max mem: 2501
Train: Epoch[2/5]  [1180/3125]  eta: 0:11:16  Lr: 0.001875  Loss: 0.2838  Acc@1: 81.2500 (85.4467)  Acc@5: 100.0000 (98.2377)  time: 0.3506  data: 0.0005  max mem: 2501
Train: Epoch[2/5]  [1190/3125]  eta: 0:11:13  Lr: 0.001875  Loss: -0.4843  Acc@1: 87.5000 (85.4691)  Acc@5: 100.0000 (98.2420)  time: 0.3497  data: 0.0007  max mem: 2501
Train: Epoch[2/5]  [1200/3125]  eta: 0:11:09  Lr: 0.001875  Loss: -0.6539  Acc@1: 87.5000 (85.5017)  Acc@5: 100.0000 (98.2515)  time: 0.3492  data: 0.0007  max mem: 2501
Train: Epoch[2/5]  [1210/3125]  eta: 0:11:06  Lr: 0.001875  Loss: 0.0999  Acc@1: 87.5000 (85.5285)  Acc@5: 100.0000 (98.2453)  time: 0.3500  data: 0.0005  max mem: 2501
Train: Epoch[2/5]  [1220/3125]  eta: 0:11:03  Lr: 0.001875  Loss: -0.5611  Acc@1: 87.5000 (85.5446)  Acc@5: 100.0000 (98.2238)  time: 0.3496  data: 0.0010  max mem: 2501
Train: Epoch[2/5]  [1230/3125]  eta: 0:10:59  Lr: 0.001875  Loss: -0.2969  Acc@1: 87.5000 (85.5453)  Acc@5: 100.0000 (98.2331)  time: 0.3485  data: 0.0010  max mem: 2501
Train: Epoch[2/5]  [1240/3125]  eta: 0:10:56  Lr: 0.001875  Loss: -0.5838  Acc@1: 87.5000 (85.5308)  Acc@5: 100.0000 (98.2423)  time: 0.3491  data: 0.0006  max mem: 2501
Train: Epoch[2/5]  [1250/3125]  eta: 0:10:52  Lr: 0.001875  Loss: -0.1829  Acc@1: 87.5000 (85.5466)  Acc@5: 100.0000 (98.2414)  time: 0.3487  data: 0.0006  max mem: 2501
Train: Epoch[2/5]  [1260/3125]  eta: 0:10:49  Lr: 0.001875  Loss: -0.3620  Acc@1: 87.5000 (85.5373)  Acc@5: 100.0000 (98.2554)  time: 0.3496  data: 0.0005  max mem: 2501
Train: Epoch[2/5]  [1270/3125]  eta: 0:10:45  Lr: 0.001875  Loss: -0.6833  Acc@1: 87.5000 (85.5380)  Acc@5: 100.0000 (98.2592)  time: 0.3495  data: 0.0008  max mem: 2501
Train: Epoch[2/5]  [1280/3125]  eta: 0:10:42  Lr: 0.001875  Loss: -0.4459  Acc@1: 87.5000 (85.5484)  Acc@5: 100.0000 (98.2582)  time: 0.3480  data: 0.0008  max mem: 2501
Train: Epoch[2/5]  [1290/3125]  eta: 0:10:38  Lr: 0.001875  Loss: -0.4237  Acc@1: 87.5000 (85.5296)  Acc@5: 100.0000 (98.2572)  time: 0.3476  data: 0.0007  max mem: 2501
Train: Epoch[2/5]  [1300/3125]  eta: 0:10:35  Lr: 0.001875  Loss: -0.5876  Acc@1: 87.5000 (85.5544)  Acc@5: 100.0000 (98.2706)  time: 0.3480  data: 0.0007  max mem: 2501
Train: Epoch[2/5]  [1310/3125]  eta: 0:10:31  Lr: 0.001875  Loss: -0.3293  Acc@1: 87.5000 (85.5454)  Acc@5: 100.0000 (98.2742)  time: 0.3490  data: 0.0006  max mem: 2501
Train: Epoch[2/5]  [1320/3125]  eta: 0:10:28  Lr: 0.001875  Loss: -0.4074  Acc@1: 87.5000 (85.5649)  Acc@5: 100.0000 (98.2826)  time: 0.3487  data: 0.0007  max mem: 2501
Train: Epoch[2/5]  [1330/3125]  eta: 0:10:24  Lr: 0.001875  Loss: -0.0910  Acc@1: 87.5000 (85.5607)  Acc@5: 100.0000 (98.2861)  time: 0.3491  data: 0.0006  max mem: 2501
Train: Epoch[2/5]  [1340/3125]  eta: 0:10:21  Lr: 0.001875  Loss: -0.4221  Acc@1: 87.5000 (85.5611)  Acc@5: 100.0000 (98.2895)  time: 0.3492  data: 0.0005  max mem: 2501
Train: Epoch[2/5]  [1350/3125]  eta: 0:10:17  Lr: 0.001875  Loss: -0.2537  Acc@1: 87.5000 (85.5524)  Acc@5: 100.0000 (98.2976)  time: 0.3485  data: 0.0008  max mem: 2501
Train: Epoch[2/5]  [1360/3125]  eta: 0:10:14  Lr: 0.001875  Loss: 0.4330  Acc@1: 81.2500 (85.5070)  Acc@5: 100.0000 (98.3009)  time: 0.3472  data: 0.0008  max mem: 2501
Train: Epoch[2/5]  [1370/3125]  eta: 0:10:10  Lr: 0.001875  Loss: 0.2572  Acc@1: 81.2500 (85.4668)  Acc@5: 100.0000 (98.2996)  time: 0.3460  data: 0.0005  max mem: 2501
Train: Epoch[2/5]  [1380/3125]  eta: 0:10:07  Lr: 0.001875  Loss: -0.4316  Acc@1: 81.2500 (85.4861)  Acc@5: 100.0000 (98.3074)  time: 0.3476  data: 0.0005  max mem: 2501
Train: Epoch[2/5]  [1390/3125]  eta: 0:10:03  Lr: 0.001875  Loss: -0.4083  Acc@1: 87.5000 (85.4960)  Acc@5: 100.0000 (98.2926)  time: 0.3480  data: 0.0005  max mem: 2501
Train: Epoch[2/5]  [1400/3125]  eta: 0:10:00  Lr: 0.001875  Loss: 0.1035  Acc@1: 81.2500 (85.4524)  Acc@5: 100.0000 (98.2825)  time: 0.3481  data: 0.0004  max mem: 2501
Train: Epoch[2/5]  [1410/3125]  eta: 0:09:57  Lr: 0.001875  Loss: -0.2050  Acc@1: 81.2500 (85.4447)  Acc@5: 100.0000 (98.2681)  time: 0.3500  data: 0.0005  max mem: 2501
Train: Epoch[2/5]  [1420/3125]  eta: 0:09:53  Lr: 0.001875  Loss: -0.2916  Acc@1: 81.2500 (85.3624)  Acc@5: 100.0000 (98.2627)  time: 0.3507  data: 0.0007  max mem: 2501
Train: Epoch[2/5]  [1430/3125]  eta: 0:09:50  Lr: 0.001875  Loss: -0.1238  Acc@1: 81.2500 (85.3817)  Acc@5: 100.0000 (98.2617)  time: 0.3501  data: 0.0011  max mem: 2501
Train: Epoch[2/5]  [1440/3125]  eta: 0:09:46  Lr: 0.001875  Loss: -0.4619  Acc@1: 87.5000 (85.3617)  Acc@5: 100.0000 (98.2608)  time: 0.3499  data: 0.0014  max mem: 2501
Train: Epoch[2/5]  [1450/3125]  eta: 0:09:43  Lr: 0.001875  Loss: -0.6126  Acc@1: 81.2500 (85.3463)  Acc@5: 100.0000 (98.2512)  time: 0.3484  data: 0.0009  max mem: 2501
Train: Epoch[2/5]  [1460/3125]  eta: 0:09:39  Lr: 0.001875  Loss: -0.3964  Acc@1: 87.5000 (85.3867)  Acc@5: 100.0000 (98.2503)  time: 0.3463  data: 0.0005  max mem: 2501
Train: Epoch[2/5]  [1470/3125]  eta: 0:09:36  Lr: 0.001875  Loss: -0.3414  Acc@1: 87.5000 (85.4011)  Acc@5: 100.0000 (98.2622)  time: 0.3460  data: 0.0006  max mem: 2501
Train: Epoch[2/5]  [1480/3125]  eta: 0:09:32  Lr: 0.001875  Loss: -0.5000  Acc@1: 87.5000 (85.3942)  Acc@5: 100.0000 (98.2613)  time: 0.3466  data: 0.0006  max mem: 2501
Train: Epoch[2/5]  [1490/3125]  eta: 0:09:29  Lr: 0.001875  Loss: -0.2411  Acc@1: 87.5000 (85.3957)  Acc@5: 100.0000 (98.2520)  time: 0.3476  data: 0.0006  max mem: 2501
Train: Epoch[2/5]  [1500/3125]  eta: 0:09:25  Lr: 0.001875  Loss: -0.0137  Acc@1: 87.5000 (85.4056)  Acc@5: 100.0000 (98.2553)  time: 0.3481  data: 0.0006  max mem: 2501
Train: Epoch[2/5]  [1510/3125]  eta: 0:09:22  Lr: 0.001875  Loss: -0.7077  Acc@1: 87.5000 (85.4360)  Acc@5: 100.0000 (98.2627)  time: 0.3482  data: 0.0006  max mem: 2501
Train: Epoch[2/5]  [1520/3125]  eta: 0:09:18  Lr: 0.001875  Loss: -0.2797  Acc@1: 87.5000 (85.4290)  Acc@5: 100.0000 (98.2577)  time: 0.3473  data: 0.0012  max mem: 2501
Train: Epoch[2/5]  [1530/3125]  eta: 0:09:15  Lr: 0.001875  Loss: -0.3539  Acc@1: 81.2500 (85.4262)  Acc@5: 100.0000 (98.2487)  time: 0.3487  data: 0.0015  max mem: 2501
Train: Epoch[2/5]  [1540/3125]  eta: 0:09:11  Lr: 0.001875  Loss: -0.0544  Acc@1: 87.5000 (85.4396)  Acc@5: 100.0000 (98.2519)  time: 0.3502  data: 0.0008  max mem: 2501
Train: Epoch[2/5]  [1550/3125]  eta: 0:09:08  Lr: 0.001875  Loss: -0.1689  Acc@1: 81.2500 (85.4046)  Acc@5: 100.0000 (98.2431)  time: 0.3481  data: 0.0005  max mem: 2501
Train: Epoch[2/5]  [1560/3125]  eta: 0:09:04  Lr: 0.001875  Loss: -0.2670  Acc@1: 81.2500 (85.3900)  Acc@5: 100.0000 (98.2503)  time: 0.3468  data: 0.0005  max mem: 2501
Train: Epoch[2/5]  [1570/3125]  eta: 0:09:01  Lr: 0.001875  Loss: -0.4721  Acc@1: 87.5000 (85.3954)  Acc@5: 100.0000 (98.2535)  time: 0.3474  data: 0.0008  max mem: 2501
Train: Epoch[2/5]  [1580/3125]  eta: 0:08:57  Lr: 0.001875  Loss: -0.6960  Acc@1: 87.5000 (85.4127)  Acc@5: 100.0000 (98.2527)  time: 0.3478  data: 0.0008  max mem: 2501
Train: Epoch[2/5]  [1590/3125]  eta: 0:08:54  Lr: 0.001875  Loss: -0.3100  Acc@1: 87.5000 (85.3944)  Acc@5: 100.0000 (98.2637)  time: 0.3472  data: 0.0006  max mem: 2501
Train: Epoch[2/5]  [1600/3125]  eta: 0:08:50  Lr: 0.001875  Loss: -0.3645  Acc@1: 81.2500 (85.3958)  Acc@5: 100.0000 (98.2628)  time: 0.3483  data: 0.0006  max mem: 2501
Train: Epoch[2/5]  [1610/3125]  eta: 0:08:47  Lr: 0.001875  Loss: -0.3087  Acc@1: 87.5000 (85.3856)  Acc@5: 100.0000 (98.2658)  time: 0.3536  data: 0.0008  max mem: 2501
Train: Epoch[2/5]  [1620/3125]  eta: 0:08:44  Lr: 0.001875  Loss: -0.3503  Acc@1: 81.2500 (85.3717)  Acc@5: 100.0000 (98.2457)  time: 0.3533  data: 0.0010  max mem: 2501
Train: Epoch[2/5]  [1630/3125]  eta: 0:08:40  Lr: 0.001875  Loss: -0.5064  Acc@1: 81.2500 (85.3886)  Acc@5: 100.0000 (98.2488)  time: 0.3476  data: 0.0008  max mem: 2501
Train: Epoch[2/5]  [1640/3125]  eta: 0:08:37  Lr: 0.001875  Loss: -0.4664  Acc@1: 87.5000 (85.3824)  Acc@5: 100.0000 (98.2480)  time: 0.3468  data: 0.0006  max mem: 2501
Train: Epoch[2/5]  [1650/3125]  eta: 0:08:33  Lr: 0.001875  Loss: -0.3932  Acc@1: 87.5000 (85.4066)  Acc@5: 100.0000 (98.2473)  time: 0.3487  data: 0.0008  max mem: 2501
Train: Epoch[2/5]  [1660/3125]  eta: 0:08:30  Lr: 0.001875  Loss: -0.0719  Acc@1: 87.5000 (85.4116)  Acc@5: 100.0000 (98.2390)  time: 0.3480  data: 0.0011  max mem: 2501
Train: Epoch[2/5]  [1670/3125]  eta: 0:08:26  Lr: 0.001875  Loss: -0.1205  Acc@1: 87.5000 (85.3980)  Acc@5: 100.0000 (98.2383)  time: 0.3463  data: 0.0009  max mem: 2501
Train: Epoch[2/5]  [1680/3125]  eta: 0:08:23  Lr: 0.001875  Loss: -0.2884  Acc@1: 87.5000 (85.4179)  Acc@5: 100.0000 (98.2377)  time: 0.3468  data: 0.0005  max mem: 2501
Train: Epoch[2/5]  [1690/3125]  eta: 0:08:19  Lr: 0.001875  Loss: -0.2009  Acc@1: 87.5000 (85.4376)  Acc@5: 100.0000 (98.2333)  time: 0.3468  data: 0.0004  max mem: 2501
Train: Epoch[2/5]  [1700/3125]  eta: 0:08:16  Lr: 0.001875  Loss: -0.4720  Acc@1: 87.5000 (85.4350)  Acc@5: 100.0000 (98.2400)  time: 0.3468  data: 0.0005  max mem: 2501
Train: Epoch[2/5]  [1710/3125]  eta: 0:08:12  Lr: 0.001875  Loss: -0.3524  Acc@1: 81.2500 (85.4252)  Acc@5: 100.0000 (98.2503)  time: 0.3485  data: 0.0009  max mem: 2501
Train: Epoch[2/5]  [1720/3125]  eta: 0:08:09  Lr: 0.001875  Loss: -0.3944  Acc@1: 87.5000 (85.4372)  Acc@5: 100.0000 (98.2568)  time: 0.3473  data: 0.0009  max mem: 2501
Train: Epoch[2/5]  [1730/3125]  eta: 0:08:05  Lr: 0.001875  Loss: -0.6525  Acc@1: 87.5000 (85.4780)  Acc@5: 100.0000 (98.2561)  time: 0.3454  data: 0.0005  max mem: 2501
Train: Epoch[2/5]  [1740/3125]  eta: 0:08:02  Lr: 0.001875  Loss: -0.3210  Acc@1: 87.5000 (85.4861)  Acc@5: 100.0000 (98.2625)  time: 0.3470  data: 0.0006  max mem: 2501
Train: Epoch[2/5]  [1750/3125]  eta: 0:07:58  Lr: 0.001875  Loss: -0.2491  Acc@1: 81.2500 (85.4833)  Acc@5: 100.0000 (98.2688)  time: 0.3481  data: 0.0008  max mem: 2501
Train: Epoch[2/5]  [1760/3125]  eta: 0:07:55  Lr: 0.001875  Loss: -0.4527  Acc@1: 81.2500 (85.4628)  Acc@5: 100.0000 (98.2751)  time: 0.3470  data: 0.0007  max mem: 2501
Train: Epoch[2/5]  [1770/3125]  eta: 0:07:51  Lr: 0.001875  Loss: -0.1954  Acc@1: 87.5000 (85.4884)  Acc@5: 100.0000 (98.2778)  time: 0.3468  data: 0.0007  max mem: 2501
Train: Epoch[2/5]  [1780/3125]  eta: 0:07:48  Lr: 0.001875  Loss: -0.6772  Acc@1: 87.5000 (85.5138)  Acc@5: 100.0000 (98.2770)  time: 0.3491  data: 0.0008  max mem: 2501
Train: Epoch[2/5]  [1790/3125]  eta: 0:07:44  Lr: 0.001875  Loss: -0.5038  Acc@1: 87.5000 (85.5248)  Acc@5: 100.0000 (98.2796)  time: 0.3486  data: 0.0014  max mem: 2501
Train: Epoch[2/5]  [1800/3125]  eta: 0:07:41  Lr: 0.001875  Loss: -0.3160  Acc@1: 87.5000 (85.5289)  Acc@5: 100.0000 (98.2787)  time: 0.3482  data: 0.0014  max mem: 2501
Train: Epoch[2/5]  [1810/3125]  eta: 0:07:37  Lr: 0.001875  Loss: -0.5201  Acc@1: 87.5000 (85.5329)  Acc@5: 100.0000 (98.2779)  time: 0.3504  data: 0.0011  max mem: 2501
Train: Epoch[2/5]  [1820/3125]  eta: 0:07:34  Lr: 0.001875  Loss: -0.2873  Acc@1: 87.5000 (85.5299)  Acc@5: 100.0000 (98.2736)  time: 0.3487  data: 0.0010  max mem: 2501
Train: Epoch[2/5]  [1830/3125]  eta: 0:07:30  Lr: 0.001875  Loss: -0.1745  Acc@1: 87.5000 (85.5543)  Acc@5: 100.0000 (98.2762)  time: 0.3460  data: 0.0006  max mem: 2501
Train: Epoch[2/5]  [1840/3125]  eta: 0:07:27  Lr: 0.001875  Loss: -0.4684  Acc@1: 87.5000 (85.5649)  Acc@5: 100.0000 (98.2788)  time: 0.3464  data: 0.0005  max mem: 2501
Train: Epoch[2/5]  [1850/3125]  eta: 0:07:23  Lr: 0.001875  Loss: -0.4467  Acc@1: 87.5000 (85.5619)  Acc@5: 100.0000 (98.2881)  time: 0.3467  data: 0.0005  max mem: 2501
Train: Epoch[2/5]  [1860/3125]  eta: 0:07:20  Lr: 0.001875  Loss: -0.3649  Acc@1: 81.2500 (85.5286)  Acc@5: 100.0000 (98.2839)  time: 0.3459  data: 0.0006  max mem: 2501
Train: Epoch[2/5]  [1870/3125]  eta: 0:07:16  Lr: 0.001875  Loss: -0.6766  Acc@1: 81.2500 (85.5392)  Acc@5: 100.0000 (98.2863)  time: 0.3451  data: 0.0006  max mem: 2501
Train: Epoch[2/5]  [1880/3125]  eta: 0:07:13  Lr: 0.001875  Loss: -0.2233  Acc@1: 81.2500 (85.5197)  Acc@5: 100.0000 (98.2888)  time: 0.3458  data: 0.0006  max mem: 2501
Train: Epoch[2/5]  [1890/3125]  eta: 0:07:09  Lr: 0.001875  Loss: -0.5422  Acc@1: 87.5000 (85.5301)  Acc@5: 100.0000 (98.2912)  time: 0.3461  data: 0.0005  max mem: 2501
Train: Epoch[2/5]  [1900/3125]  eta: 0:07:06  Lr: 0.001875  Loss: 0.1132  Acc@1: 87.5000 (85.5109)  Acc@5: 100.0000 (98.2904)  time: 0.3459  data: 0.0004  max mem: 2501
Train: Epoch[2/5]  [1910/3125]  eta: 0:07:02  Lr: 0.001875  Loss: -0.2765  Acc@1: 87.5000 (85.5246)  Acc@5: 100.0000 (98.2928)  time: 0.3480  data: 0.0011  max mem: 2501
Train: Epoch[2/5]  [1920/3125]  eta: 0:06:59  Lr: 0.001875  Loss: -0.5599  Acc@1: 87.5000 (85.5251)  Acc@5: 100.0000 (98.2887)  time: 0.3488  data: 0.0012  max mem: 2501
Train: Epoch[2/5]  [1930/3125]  eta: 0:06:55  Lr: 0.001875  Loss: 0.0840  Acc@1: 87.5000 (85.5192)  Acc@5: 100.0000 (98.2943)  time: 0.3459  data: 0.0006  max mem: 2501
Train: Epoch[2/5]  [1940/3125]  eta: 0:06:52  Lr: 0.001875  Loss: -0.3184  Acc@1: 87.5000 (85.5294)  Acc@5: 100.0000 (98.2998)  time: 0.3457  data: 0.0012  max mem: 2501
Train: Epoch[2/5]  [1950/3125]  eta: 0:06:48  Lr: 0.001875  Loss: -0.2744  Acc@1: 87.5000 (85.5299)  Acc@5: 100.0000 (98.2957)  time: 0.3467  data: 0.0012  max mem: 2501
Train: Epoch[2/5]  [1960/3125]  eta: 0:06:45  Lr: 0.001875  Loss: -0.2881  Acc@1: 87.5000 (85.5399)  Acc@5: 100.0000 (98.2949)  time: 0.3461  data: 0.0004  max mem: 2501
Train: Epoch[2/5]  [1970/3125]  eta: 0:06:41  Lr: 0.001875  Loss: -0.1911  Acc@1: 87.5000 (85.5245)  Acc@5: 100.0000 (98.2940)  time: 0.3463  data: 0.0004  max mem: 2501
Train: Epoch[2/5]  [1980/3125]  eta: 0:06:38  Lr: 0.001875  Loss: -0.3470  Acc@1: 81.2500 (85.5124)  Acc@5: 100.0000 (98.2963)  time: 0.3484  data: 0.0006  max mem: 2501
Train: Epoch[2/5]  [1990/3125]  eta: 0:06:34  Lr: 0.001875  Loss: -0.2625  Acc@1: 87.5000 (85.5035)  Acc@5: 100.0000 (98.2955)  time: 0.3488  data: 0.0011  max mem: 2501
Train: Epoch[2/5]  [2000/3125]  eta: 0:06:31  Lr: 0.001875  Loss: -0.4670  Acc@1: 87.5000 (85.5166)  Acc@5: 100.0000 (98.2977)  time: 0.3477  data: 0.0012  max mem: 2501
Train: Epoch[2/5]  [2010/3125]  eta: 0:06:27  Lr: 0.001875  Loss: -0.5682  Acc@1: 87.5000 (85.5234)  Acc@5: 100.0000 (98.3000)  time: 0.3473  data: 0.0007  max mem: 2501
Train: Epoch[2/5]  [2020/3125]  eta: 0:06:24  Lr: 0.001875  Loss: -0.3206  Acc@1: 87.5000 (85.5115)  Acc@5: 100.0000 (98.3022)  time: 0.3471  data: 0.0005  max mem: 2501
Train: Epoch[2/5]  [2030/3125]  eta: 0:06:21  Lr: 0.001875  Loss: -0.3986  Acc@1: 87.5000 (85.5121)  Acc@5: 100.0000 (98.2983)  time: 0.3477  data: 0.0005  max mem: 2501
Train: Epoch[2/5]  [2040/3125]  eta: 0:06:17  Lr: 0.001875  Loss: 0.0002  Acc@1: 81.2500 (85.5034)  Acc@5: 100.0000 (98.3005)  time: 0.3468  data: 0.0011  max mem: 2501
Train: Epoch[2/5]  [2050/3125]  eta: 0:06:14  Lr: 0.001875  Loss: -0.5948  Acc@1: 81.2500 (85.5071)  Acc@5: 100.0000 (98.3057)  time: 0.3459  data: 0.0011  max mem: 2501
Train: Epoch[2/5]  [2060/3125]  eta: 0:06:10  Lr: 0.001875  Loss: -0.5679  Acc@1: 87.5000 (85.5228)  Acc@5: 100.0000 (98.3018)  time: 0.3469  data: 0.0006  max mem: 2501
Train: Epoch[2/5]  [2070/3125]  eta: 0:06:07  Lr: 0.001875  Loss: -0.1618  Acc@1: 87.5000 (85.5112)  Acc@5: 100.0000 (98.3009)  time: 0.3475  data: 0.0009  max mem: 2501
Train: Epoch[2/5]  [2080/3125]  eta: 0:06:03  Lr: 0.001875  Loss: -0.6197  Acc@1: 81.2500 (85.5058)  Acc@5: 100.0000 (98.3031)  time: 0.3481  data: 0.0009  max mem: 2501
Train: Epoch[2/5]  [2090/3125]  eta: 0:06:00  Lr: 0.001875  Loss: -0.3226  Acc@1: 81.2500 (85.4884)  Acc@5: 100.0000 (98.3022)  time: 0.3474  data: 0.0006  max mem: 2501
Train: Epoch[2/5]  [2100/3125]  eta: 0:05:56  Lr: 0.001875  Loss: -0.2652  Acc@1: 87.5000 (85.5099)  Acc@5: 100.0000 (98.3014)  time: 0.3483  data: 0.0013  max mem: 2501
Train: Epoch[2/5]  [2110/3125]  eta: 0:05:53  Lr: 0.001875  Loss: -0.2219  Acc@1: 87.5000 (85.5282)  Acc@5: 100.0000 (98.3065)  time: 0.3493  data: 0.0012  max mem: 2501
Train: Epoch[2/5]  [2120/3125]  eta: 0:05:49  Lr: 0.001875  Loss: -0.1198  Acc@1: 87.5000 (85.5434)  Acc@5: 100.0000 (98.3086)  time: 0.3464  data: 0.0005  max mem: 2501
Train: Epoch[2/5]  [2130/3125]  eta: 0:05:46  Lr: 0.001875  Loss: -0.5105  Acc@1: 87.5000 (85.5379)  Acc@5: 100.0000 (98.3107)  time: 0.3462  data: 0.0005  max mem: 2501
Train: Epoch[2/5]  [2140/3125]  eta: 0:05:42  Lr: 0.001875  Loss: -0.4587  Acc@1: 87.5000 (85.5295)  Acc@5: 100.0000 (98.3127)  time: 0.3461  data: 0.0006  max mem: 2501
Train: Epoch[2/5]  [2150/3125]  eta: 0:05:39  Lr: 0.001875  Loss: -0.5504  Acc@1: 87.5000 (85.5503)  Acc@5: 100.0000 (98.3118)  time: 0.3456  data: 0.0006  max mem: 2501
Train: Epoch[2/5]  [2160/3125]  eta: 0:05:35  Lr: 0.001875  Loss: -0.0574  Acc@1: 87.5000 (85.5420)  Acc@5: 100.0000 (98.3139)  time: 0.3468  data: 0.0008  max mem: 2501
Train: Epoch[2/5]  [2170/3125]  eta: 0:05:32  Lr: 0.001875  Loss: -0.5586  Acc@1: 81.2500 (85.5366)  Acc@5: 100.0000 (98.3159)  time: 0.3465  data: 0.0007  max mem: 2501
Train: Epoch[2/5]  [2180/3125]  eta: 0:05:28  Lr: 0.001875  Loss: -0.2544  Acc@1: 81.2500 (85.5198)  Acc@5: 100.0000 (98.3150)  time: 0.3463  data: 0.0005  max mem: 2501
Train: Epoch[2/5]  [2190/3125]  eta: 0:05:25  Lr: 0.001875  Loss: -0.6796  Acc@1: 81.2500 (85.5346)  Acc@5: 100.0000 (98.3198)  time: 0.3478  data: 0.0006  max mem: 2501
Train: Epoch[2/5]  [2200/3125]  eta: 0:05:21  Lr: 0.001875  Loss: -0.4567  Acc@1: 87.5000 (85.5350)  Acc@5: 100.0000 (98.3189)  time: 0.3483  data: 0.0012  max mem: 2501
Train: Epoch[2/5]  [2210/3125]  eta: 0:05:18  Lr: 0.001875  Loss: -0.5641  Acc@1: 87.5000 (85.5326)  Acc@5: 100.0000 (98.3237)  time: 0.3471  data: 0.0010  max mem: 2501
Train: Epoch[2/5]  [2220/3125]  eta: 0:05:14  Lr: 0.001875  Loss: -0.5161  Acc@1: 87.5000 (85.5386)  Acc@5: 100.0000 (98.3256)  time: 0.3468  data: 0.0004  max mem: 2501
Train: Epoch[2/5]  [2230/3125]  eta: 0:05:11  Lr: 0.001875  Loss: 0.1851  Acc@1: 87.5000 (85.5334)  Acc@5: 100.0000 (98.3275)  time: 0.3474  data: 0.0007  max mem: 2501
Train: Epoch[2/5]  [2240/3125]  eta: 0:05:07  Lr: 0.001875  Loss: -0.2433  Acc@1: 87.5000 (85.5366)  Acc@5: 100.0000 (98.3294)  time: 0.3468  data: 0.0006  max mem: 2501
Train: Epoch[2/5]  [2250/3125]  eta: 0:05:04  Lr: 0.001875  Loss: -0.2019  Acc@1: 87.5000 (85.5314)  Acc@5: 100.0000 (98.3285)  time: 0.3475  data: 0.0012  max mem: 2501
Train: Epoch[2/5]  [2260/3125]  eta: 0:05:00  Lr: 0.001875  Loss: -0.3523  Acc@1: 87.5000 (85.5512)  Acc@5: 100.0000 (98.3331)  time: 0.3489  data: 0.0013  max mem: 2501
Train: Epoch[2/5]  [2270/3125]  eta: 0:04:57  Lr: 0.001875  Loss: -0.0673  Acc@1: 87.5000 (85.5488)  Acc@5: 100.0000 (98.3350)  time: 0.3477  data: 0.0005  max mem: 2501
Train: Epoch[2/5]  [2280/3125]  eta: 0:04:53  Lr: 0.001875  Loss: -0.3296  Acc@1: 87.5000 (85.5546)  Acc@5: 100.0000 (98.3423)  time: 0.3469  data: 0.0007  max mem: 2501
Train: Epoch[2/5]  [2290/3125]  eta: 0:04:50  Lr: 0.001875  Loss: -0.5159  Acc@1: 81.2500 (85.5467)  Acc@5: 100.0000 (98.3468)  time: 0.3489  data: 0.0007  max mem: 2501
Train: Epoch[2/5]  [2300/3125]  eta: 0:04:47  Lr: 0.001875  Loss: -0.0750  Acc@1: 81.2500 (85.5498)  Acc@5: 100.0000 (98.3404)  time: 0.3478  data: 0.0006  max mem: 2501
Train: Epoch[2/5]  [2310/3125]  eta: 0:04:43  Lr: 0.001875  Loss: -0.1834  Acc@1: 87.5000 (85.5636)  Acc@5: 100.0000 (98.3395)  time: 0.3460  data: 0.0006  max mem: 2501
Train: Epoch[2/5]  [2320/3125]  eta: 0:04:40  Lr: 0.001875  Loss: -0.3831  Acc@1: 87.5000 (85.5369)  Acc@5: 100.0000 (98.3439)  time: 0.3474  data: 0.0007  max mem: 2501
Train: Epoch[2/5]  [2330/3125]  eta: 0:04:36  Lr: 0.001875  Loss: -0.6117  Acc@1: 81.2500 (85.5454)  Acc@5: 100.0000 (98.3510)  time: 0.3468  data: 0.0006  max mem: 2501
Train: Epoch[2/5]  [2340/3125]  eta: 0:04:33  Lr: 0.001875  Loss: -0.6520  Acc@1: 87.5000 (85.5697)  Acc@5: 100.0000 (98.3581)  time: 0.3453  data: 0.0005  max mem: 2501
Train: Epoch[2/5]  [2350/3125]  eta: 0:04:29  Lr: 0.001875  Loss: -0.3743  Acc@1: 87.5000 (85.5859)  Acc@5: 100.0000 (98.3597)  time: 0.3462  data: 0.0007  max mem: 2501
Train: Epoch[2/5]  [2360/3125]  eta: 0:04:26  Lr: 0.001875  Loss: -0.6156  Acc@1: 87.5000 (85.5702)  Acc@5: 100.0000 (98.3508)  time: 0.3478  data: 0.0007  max mem: 2501
Train: Epoch[2/5]  [2370/3125]  eta: 0:04:22  Lr: 0.001875  Loss: -0.1562  Acc@1: 81.2500 (85.5678)  Acc@5: 100.0000 (98.3499)  time: 0.3469  data: 0.0006  max mem: 2501
Train: Epoch[2/5]  [2380/3125]  eta: 0:04:19  Lr: 0.001875  Loss: -0.5221  Acc@1: 87.5000 (85.5733)  Acc@5: 100.0000 (98.3515)  time: 0.3462  data: 0.0006  max mem: 2501
Train: Epoch[2/5]  [2390/3125]  eta: 0:04:15  Lr: 0.001875  Loss: -0.4814  Acc@1: 87.5000 (85.5787)  Acc@5: 100.0000 (98.3506)  time: 0.3490  data: 0.0006  max mem: 2501
Train: Epoch[2/5]  [2400/3125]  eta: 0:04:12  Lr: 0.001875  Loss: -0.6040  Acc@1: 81.2500 (85.5737)  Acc@5: 100.0000 (98.3549)  time: 0.3500  data: 0.0006  max mem: 2501
Train: Epoch[2/5]  [2410/3125]  eta: 0:04:08  Lr: 0.001875  Loss: -0.5256  Acc@1: 81.2500 (85.5765)  Acc@5: 100.0000 (98.3565)  time: 0.3492  data: 0.0006  max mem: 2501
Train: Epoch[2/5]  [2420/3125]  eta: 0:04:05  Lr: 0.001875  Loss: -0.3224  Acc@1: 93.7500 (85.5871)  Acc@5: 100.0000 (98.3607)  time: 0.3488  data: 0.0008  max mem: 2501
Train: Epoch[2/5]  [2430/3125]  eta: 0:04:01  Lr: 0.001875  Loss: -0.3022  Acc@1: 87.5000 (85.5846)  Acc@5: 100.0000 (98.3623)  time: 0.3476  data: 0.0013  max mem: 2501
Train: Epoch[2/5]  [2440/3125]  eta: 0:03:58  Lr: 0.001875  Loss: -0.0715  Acc@1: 81.2500 (85.5566)  Acc@5: 100.0000 (98.3613)  time: 0.3473  data: 0.0013  max mem: 2501
Train: Epoch[2/5]  [2450/3125]  eta: 0:03:54  Lr: 0.001875  Loss: -0.3401  Acc@1: 81.2500 (85.5595)  Acc@5: 100.0000 (98.3578)  time: 0.3464  data: 0.0006  max mem: 2501
Train: Epoch[2/5]  [2460/3125]  eta: 0:03:51  Lr: 0.001875  Loss: -0.4505  Acc@1: 87.5000 (85.5445)  Acc@5: 100.0000 (98.3543)  time: 0.3460  data: 0.0006  max mem: 2501
Train: Epoch[2/5]  [2470/3125]  eta: 0:03:47  Lr: 0.001875  Loss: -0.0347  Acc@1: 87.5000 (85.5499)  Acc@5: 100.0000 (98.3585)  time: 0.3488  data: 0.0007  max mem: 2501
Train: Epoch[2/5]  [2480/3125]  eta: 0:03:44  Lr: 0.001875  Loss: 0.1833  Acc@1: 87.5000 (85.5527)  Acc@5: 100.0000 (98.3525)  time: 0.3504  data: 0.0006  max mem: 2501
Train: Epoch[2/5]  [2490/3125]  eta: 0:03:40  Lr: 0.001875  Loss: -0.1660  Acc@1: 87.5000 (85.5555)  Acc@5: 100.0000 (98.3541)  time: 0.3479  data: 0.0006  max mem: 2501
Train: Epoch[2/5]  [2500/3125]  eta: 0:03:37  Lr: 0.001875  Loss: -0.1384  Acc@1: 81.2500 (85.5483)  Acc@5: 100.0000 (98.3532)  time: 0.3471  data: 0.0007  max mem: 2501
Train: Epoch[2/5]  [2510/3125]  eta: 0:03:33  Lr: 0.001875  Loss: -0.3076  Acc@1: 81.2500 (85.5312)  Acc@5: 100.0000 (98.3523)  time: 0.3470  data: 0.0009  max mem: 2501
Train: Epoch[2/5]  [2520/3125]  eta: 0:03:30  Lr: 0.001875  Loss: -0.4235  Acc@1: 81.2500 (85.5266)  Acc@5: 100.0000 (98.3563)  time: 0.3460  data: 0.0008  max mem: 2501
Train: Epoch[2/5]  [2530/3125]  eta: 0:03:26  Lr: 0.001875  Loss: -0.1820  Acc@1: 87.5000 (85.5393)  Acc@5: 100.0000 (98.3579)  time: 0.3475  data: 0.0007  max mem: 2501
Train: Epoch[2/5]  [2540/3125]  eta: 0:03:23  Lr: 0.001875  Loss: -0.3638  Acc@1: 87.5000 (85.5470)  Acc@5: 100.0000 (98.3520)  time: 0.3471  data: 0.0007  max mem: 2501
Train: Epoch[2/5]  [2550/3125]  eta: 0:03:20  Lr: 0.001875  Loss: -0.0452  Acc@1: 87.5000 (85.5473)  Acc@5: 93.7500 (98.3462)  time: 0.3467  data: 0.0006  max mem: 2501
Train: Epoch[2/5]  [2560/3125]  eta: 0:03:16  Lr: 0.001875  Loss: -0.5199  Acc@1: 87.5000 (85.5623)  Acc@5: 100.0000 (98.3454)  time: 0.3501  data: 0.0006  max mem: 2501
Train: Epoch[2/5]  [2570/3125]  eta: 0:03:13  Lr: 0.001875  Loss: -0.2575  Acc@1: 87.5000 (85.5650)  Acc@5: 100.0000 (98.3421)  time: 0.3501  data: 0.0009  max mem: 2501
Train: Epoch[2/5]  [2580/3125]  eta: 0:03:09  Lr: 0.001875  Loss: -0.4426  Acc@1: 93.7500 (85.5846)  Acc@5: 100.0000 (98.3461)  time: 0.3484  data: 0.0013  max mem: 2501
Train: Epoch[2/5]  [2590/3125]  eta: 0:03:06  Lr: 0.001875  Loss: -0.0664  Acc@1: 87.5000 (85.5871)  Acc@5: 100.0000 (98.3356)  time: 0.3475  data: 0.0008  max mem: 2501
Train: Epoch[2/5]  [2600/3125]  eta: 0:03:02  Lr: 0.001875  Loss: -0.5038  Acc@1: 87.5000 (85.6017)  Acc@5: 100.0000 (98.3396)  time: 0.3460  data: 0.0005  max mem: 2501
Train: Epoch[2/5]  [2610/3125]  eta: 0:02:59  Lr: 0.001875  Loss: -0.4086  Acc@1: 87.5000 (85.6114)  Acc@5: 100.0000 (98.3412)  time: 0.3476  data: 0.0005  max mem: 2501
Train: Epoch[2/5]  [2620/3125]  eta: 0:02:55  Lr: 0.001875  Loss: -0.6441  Acc@1: 87.5000 (85.5971)  Acc@5: 100.0000 (98.3308)  time: 0.3482  data: 0.0005  max mem: 2501
Train: Epoch[2/5]  [2630/3125]  eta: 0:02:52  Lr: 0.001875  Loss: -0.1617  Acc@1: 81.2500 (85.6020)  Acc@5: 100.0000 (98.3300)  time: 0.3473  data: 0.0005  max mem: 2501
Train: Epoch[2/5]  [2640/3125]  eta: 0:02:48  Lr: 0.001875  Loss: -0.6852  Acc@1: 81.2500 (85.6044)  Acc@5: 100.0000 (98.3245)  time: 0.3495  data: 0.0013  max mem: 2501
Train: Epoch[2/5]  [2650/3125]  eta: 0:02:45  Lr: 0.001875  Loss: -0.0298  Acc@1: 81.2500 (85.5833)  Acc@5: 100.0000 (98.3167)  time: 0.3485  data: 0.0012  max mem: 2501
Train: Epoch[2/5]  [2660/3125]  eta: 0:02:41  Lr: 0.001875  Loss: -0.7356  Acc@1: 87.5000 (85.6046)  Acc@5: 100.0000 (98.3183)  time: 0.3459  data: 0.0006  max mem: 2501
Train: Epoch[2/5]  [2670/3125]  eta: 0:02:38  Lr: 0.001875  Loss: -0.1482  Acc@1: 87.5000 (85.6070)  Acc@5: 100.0000 (98.3129)  time: 0.3483  data: 0.0007  max mem: 2501
Train: Epoch[2/5]  [2680/3125]  eta: 0:02:34  Lr: 0.001875  Loss: -0.5395  Acc@1: 87.5000 (85.6164)  Acc@5: 100.0000 (98.3099)  time: 0.3515  data: 0.0022  max mem: 2501
Train: Epoch[2/5]  [2690/3125]  eta: 0:02:31  Lr: 0.001875  Loss: 0.0398  Acc@1: 87.5000 (85.6048)  Acc@5: 100.0000 (98.3045)  time: 0.3503  data: 0.0022  max mem: 2501
Train: Epoch[2/5]  [2700/3125]  eta: 0:02:27  Lr: 0.001875  Loss: -0.0825  Acc@1: 81.2500 (85.5979)  Acc@5: 100.0000 (98.3039)  time: 0.3482  data: 0.0007  max mem: 2501
Train: Epoch[2/5]  [2710/3125]  eta: 0:02:24  Lr: 0.001875  Loss: -0.2421  Acc@1: 81.2500 (85.6026)  Acc@5: 100.0000 (98.3032)  time: 0.3467  data: 0.0005  max mem: 2501
Train: Epoch[2/5]  [2720/3125]  eta: 0:02:20  Lr: 0.001875  Loss: -0.5224  Acc@1: 87.5000 (85.6073)  Acc@5: 100.0000 (98.3049)  time: 0.3465  data: 0.0006  max mem: 2501
Train: Epoch[2/5]  [2730/3125]  eta: 0:02:17  Lr: 0.001875  Loss: -0.5483  Acc@1: 87.5000 (85.6188)  Acc@5: 100.0000 (98.3042)  time: 0.3469  data: 0.0006  max mem: 2501
Train: Epoch[2/5]  [2740/3125]  eta: 0:02:13  Lr: 0.001875  Loss: -0.3448  Acc@1: 87.5000 (85.6052)  Acc@5: 100.0000 (98.3058)  time: 0.3467  data: 0.0005  max mem: 2501
Train: Epoch[2/5]  [2750/3125]  eta: 0:02:10  Lr: 0.001875  Loss: 0.0758  Acc@1: 87.5000 (85.6075)  Acc@5: 100.0000 (98.3120)  time: 0.3482  data: 0.0006  max mem: 2501
Train: Epoch[2/5]  [2760/3125]  eta: 0:02:06  Lr: 0.001875  Loss: -0.2361  Acc@1: 81.2500 (85.5985)  Acc@5: 100.0000 (98.3068)  time: 0.3474  data: 0.0006  max mem: 2501
Train: Epoch[2/5]  [2770/3125]  eta: 0:02:03  Lr: 0.001875  Loss: -0.7344  Acc@1: 87.5000 (85.6121)  Acc@5: 100.0000 (98.3106)  time: 0.3459  data: 0.0005  max mem: 2501
Train: Epoch[2/5]  [2780/3125]  eta: 0:02:00  Lr: 0.001875  Loss: -0.2501  Acc@1: 87.5000 (85.6414)  Acc@5: 100.0000 (98.3145)  time: 0.3466  data: 0.0006  max mem: 2501
Train: Epoch[2/5]  [2790/3125]  eta: 0:01:56  Lr: 0.001875  Loss: -0.2140  Acc@1: 87.5000 (85.6302)  Acc@5: 100.0000 (98.3138)  time: 0.3477  data: 0.0009  max mem: 2501
Train: Epoch[2/5]  [2800/3125]  eta: 0:01:53  Lr: 0.001875  Loss: -0.2257  Acc@1: 87.5000 (85.6346)  Acc@5: 100.0000 (98.3109)  time: 0.3476  data: 0.0015  max mem: 2501
Train: Epoch[2/5]  [2810/3125]  eta: 0:01:49  Lr: 0.001875  Loss: -0.5967  Acc@1: 87.5000 (85.6412)  Acc@5: 100.0000 (98.3124)  time: 0.3479  data: 0.0013  max mem: 2501
Train: Epoch[2/5]  [2820/3125]  eta: 0:01:46  Lr: 0.001875  Loss: -0.6935  Acc@1: 87.5000 (85.6523)  Acc@5: 100.0000 (98.3140)  time: 0.3479  data: 0.0005  max mem: 2501
Train: Epoch[2/5]  [2830/3125]  eta: 0:01:42  Lr: 0.001875  Loss: -0.5988  Acc@1: 87.5000 (85.6477)  Acc@5: 100.0000 (98.3177)  time: 0.3473  data: 0.0005  max mem: 2501
Train: Epoch[2/5]  [2840/3125]  eta: 0:01:39  Lr: 0.001875  Loss: -0.6671  Acc@1: 87.5000 (85.6609)  Acc@5: 100.0000 (98.3237)  time: 0.3472  data: 0.0007  max mem: 2501
Train: Epoch[2/5]  [2850/3125]  eta: 0:01:35  Lr: 0.001875  Loss: -0.1728  Acc@1: 87.5000 (85.6607)  Acc@5: 100.0000 (98.3230)  time: 0.3476  data: 0.0007  max mem: 2501
Train: Epoch[2/5]  [2860/3125]  eta: 0:01:32  Lr: 0.001875  Loss: -0.0077  Acc@1: 87.5000 (85.6693)  Acc@5: 100.0000 (98.3244)  time: 0.3470  data: 0.0005  max mem: 2501
Train: Epoch[2/5]  [2870/3125]  eta: 0:01:28  Lr: 0.001875  Loss: -0.1295  Acc@1: 87.5000 (85.6648)  Acc@5: 100.0000 (98.3216)  time: 0.3487  data: 0.0007  max mem: 2501
Train: Epoch[2/5]  [2880/3125]  eta: 0:01:25  Lr: 0.001875  Loss: -0.0594  Acc@1: 87.5000 (85.6690)  Acc@5: 100.0000 (98.3252)  time: 0.3521  data: 0.0012  max mem: 2501
Train: Epoch[2/5]  [2890/3125]  eta: 0:01:21  Lr: 0.001875  Loss: -0.0216  Acc@1: 87.5000 (85.6754)  Acc@5: 100.0000 (98.3245)  time: 0.3493  data: 0.0010  max mem: 2501
Train: Epoch[2/5]  [2900/3125]  eta: 0:01:18  Lr: 0.001875  Loss: -0.2767  Acc@1: 81.2500 (85.6644)  Acc@5: 100.0000 (98.3239)  time: 0.3476  data: 0.0006  max mem: 2501
Train: Epoch[2/5]  [2910/3125]  eta: 0:01:14  Lr: 0.001875  Loss: -0.7268  Acc@1: 87.5000 (85.6836)  Acc@5: 100.0000 (98.3275)  time: 0.3490  data: 0.0007  max mem: 2501
Train: Epoch[2/5]  [2920/3125]  eta: 0:01:11  Lr: 0.001875  Loss: -0.5410  Acc@1: 93.7500 (85.7005)  Acc@5: 100.0000 (98.3289)  time: 0.3475  data: 0.0007  max mem: 2501
Train: Epoch[2/5]  [2930/3125]  eta: 0:01:07  Lr: 0.001875  Loss: -0.1140  Acc@1: 93.7500 (85.6981)  Acc@5: 100.0000 (98.3282)  time: 0.3464  data: 0.0006  max mem: 2501
Train: Epoch[2/5]  [2940/3125]  eta: 0:01:04  Lr: 0.001875  Loss: 0.3060  Acc@1: 87.5000 (85.7085)  Acc@5: 100.0000 (98.3275)  time: 0.3459  data: 0.0005  max mem: 2501
Train: Epoch[2/5]  [2950/3125]  eta: 0:01:00  Lr: 0.001875  Loss: -0.3947  Acc@1: 87.5000 (85.7188)  Acc@5: 100.0000 (98.3290)  time: 0.3460  data: 0.0009  max mem: 2501
Train: Epoch[2/5]  [2960/3125]  eta: 0:00:57  Lr: 0.001875  Loss: -0.1972  Acc@1: 87.5000 (85.7227)  Acc@5: 100.0000 (98.3283)  time: 0.3474  data: 0.0010  max mem: 2501
Train: Epoch[2/5]  [2970/3125]  eta: 0:00:53  Lr: 0.001875  Loss: -0.3292  Acc@1: 87.5000 (85.7266)  Acc@5: 100.0000 (98.3234)  time: 0.3482  data: 0.0005  max mem: 2501
Train: Epoch[2/5]  [2980/3125]  eta: 0:00:50  Lr: 0.001875  Loss: 0.1034  Acc@1: 87.5000 (85.7263)  Acc@5: 100.0000 (98.3227)  time: 0.3475  data: 0.0006  max mem: 2501
Train: Epoch[2/5]  [2990/3125]  eta: 0:00:46  Lr: 0.001875  Loss: -0.6099  Acc@1: 87.5000 (85.7238)  Acc@5: 100.0000 (98.3220)  time: 0.3472  data: 0.0007  max mem: 2501
Train: Epoch[2/5]  [3000/3125]  eta: 0:00:43  Lr: 0.001875  Loss: -0.3713  Acc@1: 87.5000 (85.7339)  Acc@5: 100.0000 (98.3256)  time: 0.3479  data: 0.0011  max mem: 2501
Train: Epoch[2/5]  [3010/3125]  eta: 0:00:40  Lr: 0.001875  Loss: -0.2291  Acc@1: 87.5000 (85.7232)  Acc@5: 100.0000 (98.3187)  time: 0.3493  data: 0.0011  max mem: 2501
Train: Epoch[2/5]  [3020/3125]  eta: 0:00:36  Lr: 0.001875  Loss: -0.0962  Acc@1: 87.5000 (85.7332)  Acc@5: 100.0000 (98.3139)  time: 0.3489  data: 0.0006  max mem: 2501
Train: Epoch[2/5]  [3030/3125]  eta: 0:00:33  Lr: 0.001875  Loss: -0.6277  Acc@1: 87.5000 (85.7287)  Acc@5: 100.0000 (98.3112)  time: 0.3469  data: 0.0006  max mem: 2501
Train: Epoch[2/5]  [3040/3125]  eta: 0:00:29  Lr: 0.001875  Loss: 0.3152  Acc@1: 87.5000 (85.7304)  Acc@5: 100.0000 (98.3147)  time: 0.3489  data: 0.0008  max mem: 2501
Train: Epoch[2/5]  [3050/3125]  eta: 0:00:26  Lr: 0.001875  Loss: -0.5416  Acc@1: 87.5000 (85.7383)  Acc@5: 100.0000 (98.3120)  time: 0.3483  data: 0.0007  max mem: 2501
Train: Epoch[2/5]  [3060/3125]  eta: 0:00:22  Lr: 0.001875  Loss: -0.4256  Acc@1: 87.5000 (85.7400)  Acc@5: 100.0000 (98.3114)  time: 0.3465  data: 0.0007  max mem: 2501
Train: Epoch[2/5]  [3070/3125]  eta: 0:00:19  Lr: 0.001875  Loss: -0.1173  Acc@1: 87.5000 (85.7274)  Acc@5: 100.0000 (98.3088)  time: 0.3475  data: 0.0007  max mem: 2501
Train: Epoch[2/5]  [3080/3125]  eta: 0:00:15  Lr: 0.001875  Loss: -0.1695  Acc@1: 81.2500 (85.7270)  Acc@5: 100.0000 (98.3082)  time: 0.3475  data: 0.0005  max mem: 2501
Train: Epoch[2/5]  [3090/3125]  eta: 0:00:12  Lr: 0.001875  Loss: -0.1603  Acc@1: 81.2500 (85.7186)  Acc@5: 100.0000 (98.3137)  time: 0.3506  data: 0.0012  max mem: 2501
Train: Epoch[2/5]  [3100/3125]  eta: 0:00:08  Lr: 0.001875  Loss: -0.3134  Acc@1: 87.5000 (85.7223)  Acc@5: 100.0000 (98.3151)  time: 0.3504  data: 0.0014  max mem: 2501
Train: Epoch[2/5]  [3110/3125]  eta: 0:00:05  Lr: 0.001875  Loss: -0.4852  Acc@1: 87.5000 (85.7281)  Acc@5: 100.0000 (98.3205)  time: 0.3469  data: 0.0010  max mem: 2501
Train: Epoch[2/5]  [3120/3125]  eta: 0:00:01  Lr: 0.001875  Loss: -0.2026  Acc@1: 87.5000 (85.7237)  Acc@5: 100.0000 (98.3219)  time: 0.3473  data: 0.0021  max mem: 2501
Train: Epoch[2/5]  [3124/3125]  eta: 0:00:00  Lr: 0.001875  Loss: -0.4008  Acc@1: 87.5000 (85.7180)  Acc@5: 100.0000 (98.3200)  time: 0.3467  data: 0.0018  max mem: 2501
Train: Epoch[2/5] Total time: 0:18:07 (0.3481 s / it)
{0: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 1: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 2: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 3: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 4: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 5: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 6: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 7: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 8: {0: 0, 1: 0, 2: 100000, 3: 0, 4: 0}, 9: {0: 0, 1: 0, 2: 100000, 3: 0, 4: 0}, 10: {0: 0, 1: 0, 2: 100000, 3: 0, 4: 0}, 11: {0: 0, 1: 0, 2: 100000, 3: 0, 4: 0}, 12: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 13: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 14: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 15: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 16: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 17: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 18: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 19: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}}
Averaged stats: Lr: 0.001875  Loss: -0.4008  Acc@1: 87.5000 (85.7180)  Acc@5: 100.0000 (98.3200)
Train: Epoch[3/5]  [   0/3125]  eta: 0:44:43  Lr: 0.001875  Loss: -0.4558  Acc@1: 93.7500 (93.7500)  Acc@5: 100.0000 (100.0000)  time: 0.8588  data: 0.5111  max mem: 2501
Train: Epoch[3/5]  [  10/3125]  eta: 0:20:21  Lr: 0.001875  Loss: -0.3659  Acc@1: 87.5000 (86.3636)  Acc@5: 100.0000 (98.2955)  time: 0.3920  data: 0.0469  max mem: 2501
Train: Epoch[3/5]  [  20/3125]  eta: 0:19:12  Lr: 0.001875  Loss: -0.5824  Acc@1: 87.5000 (85.7143)  Acc@5: 100.0000 (98.5119)  time: 0.3467  data: 0.0006  max mem: 2501
Train: Epoch[3/5]  [  30/3125]  eta: 0:18:47  Lr: 0.001875  Loss: -0.3326  Acc@1: 87.5000 (85.2823)  Acc@5: 100.0000 (98.5887)  time: 0.3490  data: 0.0013  max mem: 2501
Train: Epoch[3/5]  [  40/3125]  eta: 0:18:31  Lr: 0.001875  Loss: -0.3775  Acc@1: 87.5000 (84.6037)  Acc@5: 100.0000 (98.6280)  time: 0.3493  data: 0.0014  max mem: 2501
Train: Epoch[3/5]  [  50/3125]  eta: 0:18:21  Lr: 0.001875  Loss: -0.1584  Acc@1: 81.2500 (84.8039)  Acc@5: 100.0000 (98.6520)  time: 0.3485  data: 0.0009  max mem: 2501
Train: Epoch[3/5]  [  60/3125]  eta: 0:18:13  Lr: 0.001875  Loss: -0.5734  Acc@1: 87.5000 (85.2459)  Acc@5: 100.0000 (98.7705)  time: 0.3488  data: 0.0012  max mem: 2501
Train: Epoch[3/5]  [  70/3125]  eta: 0:18:06  Lr: 0.001875  Loss: -0.5465  Acc@1: 87.5000 (85.3873)  Acc@5: 100.0000 (98.9437)  time: 0.3491  data: 0.0010  max mem: 2501
Train: Epoch[3/5]  [  80/3125]  eta: 0:17:59  Lr: 0.001875  Loss: 0.0651  Acc@1: 87.5000 (85.4938)  Acc@5: 100.0000 (98.7654)  time: 0.3479  data: 0.0006  max mem: 2501
Train: Epoch[3/5]  [  90/3125]  eta: 0:17:53  Lr: 0.001875  Loss: -0.1502  Acc@1: 87.5000 (85.3022)  Acc@5: 100.0000 (98.9011)  time: 0.3467  data: 0.0006  max mem: 2501
Train: Epoch[3/5]  [ 100/3125]  eta: 0:17:47  Lr: 0.001875  Loss: -0.3767  Acc@1: 87.5000 (85.6436)  Acc@5: 100.0000 (98.8861)  time: 0.3467  data: 0.0005  max mem: 2501
Train: Epoch[3/5]  [ 110/3125]  eta: 0:17:42  Lr: 0.001875  Loss: -0.1908  Acc@1: 87.5000 (85.6982)  Acc@5: 100.0000 (98.9302)  time: 0.3465  data: 0.0005  max mem: 2501
Train: Epoch[3/5]  [ 120/3125]  eta: 0:17:37  Lr: 0.001875  Loss: -0.4217  Acc@1: 87.5000 (85.6921)  Acc@5: 100.0000 (98.8120)  time: 0.3470  data: 0.0007  max mem: 2501
Train: Epoch[3/5]  [ 130/3125]  eta: 0:17:33  Lr: 0.001875  Loss: -0.5625  Acc@1: 87.5000 (85.8779)  Acc@5: 100.0000 (98.8073)  time: 0.3475  data: 0.0008  max mem: 2501
Train: Epoch[3/5]  [ 140/3125]  eta: 0:17:28  Lr: 0.001875  Loss: -0.5479  Acc@1: 87.5000 (85.8156)  Acc@5: 100.0000 (98.8475)  time: 0.3464  data: 0.0008  max mem: 2501
Train: Epoch[3/5]  [ 150/3125]  eta: 0:17:24  Lr: 0.001875  Loss: -0.3346  Acc@1: 81.2500 (85.8444)  Acc@5: 100.0000 (98.8411)  time: 0.3475  data: 0.0006  max mem: 2501
Train: Epoch[3/5]  [ 160/3125]  eta: 0:17:19  Lr: 0.001875  Loss: -0.4766  Acc@1: 87.5000 (86.1413)  Acc@5: 100.0000 (98.8354)  time: 0.3477  data: 0.0006  max mem: 2501
Train: Epoch[3/5]  [ 170/3125]  eta: 0:17:16  Lr: 0.001875  Loss: -0.6819  Acc@1: 87.5000 (86.2208)  Acc@5: 100.0000 (98.8304)  time: 0.3487  data: 0.0005  max mem: 2501
Train: Epoch[3/5]  [ 180/3125]  eta: 0:17:12  Lr: 0.001875  Loss: -0.4130  Acc@1: 87.5000 (86.3605)  Acc@5: 100.0000 (98.8260)  time: 0.3500  data: 0.0006  max mem: 2501
Train: Epoch[3/5]  [ 190/3125]  eta: 0:17:08  Lr: 0.001875  Loss: -0.6138  Acc@1: 87.5000 (86.5183)  Acc@5: 100.0000 (98.8220)  time: 0.3484  data: 0.0010  max mem: 2501
Train: Epoch[3/5]  [ 200/3125]  eta: 0:17:04  Lr: 0.001875  Loss: -0.3535  Acc@1: 87.5000 (86.5983)  Acc@5: 100.0000 (98.7873)  time: 0.3474  data: 0.0010  max mem: 2501
Train: Epoch[3/5]  [ 210/3125]  eta: 0:17:00  Lr: 0.001875  Loss: -0.1848  Acc@1: 87.5000 (86.6410)  Acc@5: 100.0000 (98.7855)  time: 0.3471  data: 0.0006  max mem: 2501
Train: Epoch[3/5]  [ 220/3125]  eta: 0:16:56  Lr: 0.001875  Loss: -0.1048  Acc@1: 87.5000 (86.6516)  Acc@5: 100.0000 (98.7839)  time: 0.3466  data: 0.0005  max mem: 2501
Train: Epoch[3/5]  [ 230/3125]  eta: 0:16:53  Lr: 0.001875  Loss: -0.2525  Acc@1: 81.2500 (86.4719)  Acc@5: 100.0000 (98.7825)  time: 0.3474  data: 0.0006  max mem: 2501
Train: Epoch[3/5]  [ 240/3125]  eta: 0:16:49  Lr: 0.001875  Loss: -0.6555  Acc@1: 87.5000 (86.5405)  Acc@5: 100.0000 (98.7293)  time: 0.3469  data: 0.0005  max mem: 2501
Train: Epoch[3/5]  [ 250/3125]  eta: 0:16:45  Lr: 0.001875  Loss: -0.0379  Acc@1: 87.5000 (86.5538)  Acc@5: 100.0000 (98.7799)  time: 0.3457  data: 0.0005  max mem: 2501
Train: Epoch[3/5]  [ 260/3125]  eta: 0:16:41  Lr: 0.001875  Loss: 0.0417  Acc@1: 87.5000 (86.4943)  Acc@5: 100.0000 (98.7787)  time: 0.3472  data: 0.0006  max mem: 2501
Train: Epoch[3/5]  [ 270/3125]  eta: 0:16:37  Lr: 0.001875  Loss: -0.1623  Acc@1: 87.5000 (86.4391)  Acc@5: 100.0000 (98.7315)  time: 0.3474  data: 0.0005  max mem: 2501
Train: Epoch[3/5]  [ 280/3125]  eta: 0:16:33  Lr: 0.001875  Loss: -0.2304  Acc@1: 87.5000 (86.3879)  Acc@5: 100.0000 (98.7100)  time: 0.3463  data: 0.0005  max mem: 2501
Train: Epoch[3/5]  [ 290/3125]  eta: 0:16:30  Lr: 0.001875  Loss: -0.2634  Acc@1: 87.5000 (86.3832)  Acc@5: 100.0000 (98.7328)  time: 0.3465  data: 0.0005  max mem: 2501
Train: Epoch[3/5]  [ 300/3125]  eta: 0:16:26  Lr: 0.001875  Loss: -0.1128  Acc@1: 81.2500 (86.1919)  Acc@5: 100.0000 (98.7334)  time: 0.3483  data: 0.0005  max mem: 2501
Train: Epoch[3/5]  [ 310/3125]  eta: 0:16:22  Lr: 0.001875  Loss: -0.1099  Acc@1: 81.2500 (86.1736)  Acc@5: 100.0000 (98.7540)  time: 0.3484  data: 0.0006  max mem: 2501
Train: Epoch[3/5]  [ 320/3125]  eta: 0:16:19  Lr: 0.001875  Loss: -0.4020  Acc@1: 87.5000 (86.0981)  Acc@5: 100.0000 (98.7734)  time: 0.3471  data: 0.0006  max mem: 2501
Train: Epoch[3/5]  [ 330/3125]  eta: 0:16:15  Lr: 0.001875  Loss: -0.3990  Acc@1: 87.5000 (86.2160)  Acc@5: 100.0000 (98.7915)  time: 0.3457  data: 0.0005  max mem: 2501
Train: Epoch[3/5]  [ 340/3125]  eta: 0:16:11  Lr: 0.001875  Loss: -0.2156  Acc@1: 87.5000 (86.1254)  Acc@5: 100.0000 (98.7903)  time: 0.3457  data: 0.0010  max mem: 2501
Train: Epoch[3/5]  [ 350/3125]  eta: 0:16:08  Lr: 0.001875  Loss: -0.2653  Acc@1: 81.2500 (86.0399)  Acc@5: 100.0000 (98.8070)  time: 0.3468  data: 0.0011  max mem: 2501
Train: Epoch[3/5]  [ 360/3125]  eta: 0:16:04  Lr: 0.001875  Loss: -0.3406  Acc@1: 81.2500 (85.9765)  Acc@5: 100.0000 (98.8054)  time: 0.3461  data: 0.0006  max mem: 2501
Train: Epoch[3/5]  [ 370/3125]  eta: 0:16:00  Lr: 0.001875  Loss: 0.1962  Acc@1: 87.5000 (86.1186)  Acc@5: 100.0000 (98.7871)  time: 0.3461  data: 0.0005  max mem: 2501
Train: Epoch[3/5]  [ 380/3125]  eta: 0:15:57  Lr: 0.001875  Loss: -0.6439  Acc@1: 87.5000 (86.1220)  Acc@5: 100.0000 (98.7861)  time: 0.3485  data: 0.0005  max mem: 2501
Train: Epoch[3/5]  [ 390/3125]  eta: 0:15:53  Lr: 0.001875  Loss: -0.2735  Acc@1: 81.2500 (86.0934)  Acc@5: 100.0000 (98.8171)  time: 0.3472  data: 0.0005  max mem: 2501
Train: Epoch[3/5]  [ 400/3125]  eta: 0:15:49  Lr: 0.001875  Loss: -0.2529  Acc@1: 81.2500 (86.0037)  Acc@5: 100.0000 (98.7999)  time: 0.3453  data: 0.0005  max mem: 2501
Train: Epoch[3/5]  [ 410/3125]  eta: 0:15:46  Lr: 0.001875  Loss: -0.5542  Acc@1: 87.5000 (86.1010)  Acc@5: 100.0000 (98.7987)  time: 0.3473  data: 0.0006  max mem: 2501
Train: Epoch[3/5]  [ 420/3125]  eta: 0:15:42  Lr: 0.001875  Loss: -0.3258  Acc@1: 87.5000 (86.1490)  Acc@5: 100.0000 (98.8272)  time: 0.3488  data: 0.0005  max mem: 2501
Train: Epoch[3/5]  [ 430/3125]  eta: 0:15:39  Lr: 0.001875  Loss: -0.2471  Acc@1: 87.5000 (86.1659)  Acc@5: 100.0000 (98.7964)  time: 0.3471  data: 0.0005  max mem: 2501
Train: Epoch[3/5]  [ 440/3125]  eta: 0:15:35  Lr: 0.001875  Loss: -0.3746  Acc@1: 81.2500 (86.1678)  Acc@5: 100.0000 (98.8095)  time: 0.3460  data: 0.0006  max mem: 2501
Train: Epoch[3/5]  [ 450/3125]  eta: 0:15:32  Lr: 0.001875  Loss: -0.3565  Acc@1: 81.2500 (86.1142)  Acc@5: 100.0000 (98.8221)  time: 0.3469  data: 0.0006  max mem: 2501
Train: Epoch[3/5]  [ 460/3125]  eta: 0:15:28  Lr: 0.001875  Loss: -0.6788  Acc@1: 87.5000 (86.2256)  Acc@5: 100.0000 (98.8205)  time: 0.3473  data: 0.0005  max mem: 2501
Train: Epoch[3/5]  [ 470/3125]  eta: 0:15:24  Lr: 0.001875  Loss: -0.4054  Acc@1: 93.7500 (86.2792)  Acc@5: 100.0000 (98.8323)  time: 0.3470  data: 0.0004  max mem: 2501
Train: Epoch[3/5]  [ 480/3125]  eta: 0:15:21  Lr: 0.001875  Loss: 0.0103  Acc@1: 93.7500 (86.3306)  Acc@5: 100.0000 (98.8046)  time: 0.3470  data: 0.0005  max mem: 2501
Train: Epoch[3/5]  [ 490/3125]  eta: 0:15:17  Lr: 0.001875  Loss: -0.3236  Acc@1: 87.5000 (86.3671)  Acc@5: 100.0000 (98.8289)  time: 0.3472  data: 0.0006  max mem: 2501
Train: Epoch[3/5]  [ 500/3125]  eta: 0:15:14  Lr: 0.001875  Loss: -0.2796  Acc@1: 87.5000 (86.4022)  Acc@5: 100.0000 (98.8273)  time: 0.3454  data: 0.0005  max mem: 2501
Train: Epoch[3/5]  [ 510/3125]  eta: 0:15:10  Lr: 0.001875  Loss: -0.4028  Acc@1: 87.5000 (86.4726)  Acc@5: 100.0000 (98.8381)  time: 0.3457  data: 0.0005  max mem: 2501
Train: Epoch[3/5]  [ 520/3125]  eta: 0:15:07  Lr: 0.001875  Loss: -0.2587  Acc@1: 87.5000 (86.4683)  Acc@5: 100.0000 (98.8364)  time: 0.3497  data: 0.0005  max mem: 2501
Train: Epoch[3/5]  [ 530/3125]  eta: 0:15:05  Lr: 0.001875  Loss: 0.0564  Acc@1: 81.2500 (86.3818)  Acc@5: 100.0000 (98.7994)  time: 0.3624  data: 0.0005  max mem: 2501
Train: Epoch[3/5]  [ 540/3125]  eta: 0:15:02  Lr: 0.001875  Loss: -0.3848  Acc@1: 87.5000 (86.3447)  Acc@5: 100.0000 (98.7870)  time: 0.3706  data: 0.0014  max mem: 2501
Train: Epoch[3/5]  [ 550/3125]  eta: 0:14:58  Lr: 0.001875  Loss: -0.2908  Acc@1: 87.5000 (86.3203)  Acc@5: 100.0000 (98.8090)  time: 0.3578  data: 0.0021  max mem: 2501
Train: Epoch[3/5]  [ 560/3125]  eta: 0:14:55  Lr: 0.001875  Loss: -0.1749  Acc@1: 87.5000 (86.2857)  Acc@5: 100.0000 (98.8079)  time: 0.3520  data: 0.0013  max mem: 2501
Train: Epoch[3/5]  [ 570/3125]  eta: 0:14:53  Lr: 0.001875  Loss: -0.1437  Acc@1: 87.5000 (86.3616)  Acc@5: 100.0000 (98.7960)  time: 0.3629  data: 0.0006  max mem: 2501
Train: Epoch[3/5]  [ 580/3125]  eta: 0:14:50  Lr: 0.001875  Loss: -0.6147  Acc@1: 87.5000 (86.3597)  Acc@5: 100.0000 (98.8167)  time: 0.3659  data: 0.0013  max mem: 2501
Train: Epoch[3/5]  [ 590/3125]  eta: 0:14:46  Lr: 0.001875  Loss: -0.5756  Acc@1: 87.5000 (86.3684)  Acc@5: 100.0000 (98.8050)  time: 0.3558  data: 0.0012  max mem: 2501
Train: Epoch[3/5]  [ 600/3125]  eta: 0:14:43  Lr: 0.001875  Loss: -0.3499  Acc@1: 87.5000 (86.3977)  Acc@5: 100.0000 (98.8041)  time: 0.3537  data: 0.0005  max mem: 2501
Train: Epoch[3/5]  [ 610/3125]  eta: 0:14:40  Lr: 0.001875  Loss: -0.6807  Acc@1: 87.5000 (86.3850)  Acc@5: 100.0000 (98.8134)  time: 0.3636  data: 0.0005  max mem: 2501
Train: Epoch[3/5]  [ 620/3125]  eta: 0:14:37  Lr: 0.001875  Loss: -0.5491  Acc@1: 87.5000 (86.3829)  Acc@5: 100.0000 (98.8023)  time: 0.3598  data: 0.0009  max mem: 2501
Train: Epoch[3/5]  [ 630/3125]  eta: 0:14:34  Lr: 0.001875  Loss: -0.2377  Acc@1: 87.5000 (86.3411)  Acc@5: 100.0000 (98.7916)  time: 0.3559  data: 0.0010  max mem: 2501
Train: Epoch[3/5]  [ 640/3125]  eta: 0:14:31  Lr: 0.001875  Loss: 0.2597  Acc@1: 87.5000 (86.3007)  Acc@5: 100.0000 (98.7910)  time: 0.3697  data: 0.0006  max mem: 2501
Train: Epoch[3/5]  [ 650/3125]  eta: 0:14:28  Lr: 0.001875  Loss: -0.6918  Acc@1: 87.5000 (86.3095)  Acc@5: 100.0000 (98.7999)  time: 0.3661  data: 0.0011  max mem: 2501
Train: Epoch[3/5]  [ 660/3125]  eta: 0:14:25  Lr: 0.001875  Loss: 0.0570  Acc@1: 87.5000 (86.2992)  Acc@5: 100.0000 (98.7897)  time: 0.3538  data: 0.0013  max mem: 2501
Train: Epoch[3/5]  [ 670/3125]  eta: 0:14:22  Lr: 0.001875  Loss: -0.6216  Acc@1: 81.2500 (86.2891)  Acc@5: 100.0000 (98.7798)  time: 0.3624  data: 0.0008  max mem: 2501
Train: Epoch[3/5]  [ 680/3125]  eta: 0:14:19  Lr: 0.001875  Loss: -0.0183  Acc@1: 81.2500 (86.2885)  Acc@5: 100.0000 (98.7610)  time: 0.3684  data: 0.0007  max mem: 2501
Train: Epoch[3/5]  [ 690/3125]  eta: 0:14:15  Lr: 0.001875  Loss: -0.2783  Acc@1: 87.5000 (86.2699)  Acc@5: 100.0000 (98.7699)  time: 0.3555  data: 0.0006  max mem: 2501
Train: Epoch[3/5]  [ 700/3125]  eta: 0:14:12  Lr: 0.001875  Loss: -0.4733  Acc@1: 87.5000 (86.2874)  Acc@5: 100.0000 (98.7785)  time: 0.3507  data: 0.0004  max mem: 2501
Train: Epoch[3/5]  [ 710/3125]  eta: 0:14:09  Lr: 0.001875  Loss: -0.2422  Acc@1: 87.5000 (86.2957)  Acc@5: 100.0000 (98.7781)  time: 0.3612  data: 0.0005  max mem: 2501
Train: Epoch[3/5]  [ 720/3125]  eta: 0:14:05  Lr: 0.001875  Loss: -0.1879  Acc@1: 87.5000 (86.3124)  Acc@5: 100.0000 (98.7864)  time: 0.3565  data: 0.0006  max mem: 2501
Train: Epoch[3/5]  [ 730/3125]  eta: 0:14:02  Lr: 0.001875  Loss: -0.5950  Acc@1: 87.5000 (86.3800)  Acc@5: 100.0000 (98.7859)  time: 0.3529  data: 0.0005  max mem: 2501
Train: Epoch[3/5]  [ 740/3125]  eta: 0:13:59  Lr: 0.001875  Loss: -0.2454  Acc@1: 87.5000 (86.4035)  Acc@5: 100.0000 (98.7939)  time: 0.3700  data: 0.0006  max mem: 2501
Train: Epoch[3/5]  [ 750/3125]  eta: 0:13:56  Lr: 0.001875  Loss: -0.5027  Acc@1: 87.5000 (86.4348)  Acc@5: 100.0000 (98.7933)  time: 0.3675  data: 0.0008  max mem: 2501
Train: Epoch[3/5]  [ 760/3125]  eta: 0:13:52  Lr: 0.001875  Loss: -0.4024  Acc@1: 87.5000 (86.3913)  Acc@5: 100.0000 (98.7845)  time: 0.3536  data: 0.0007  max mem: 2501
Train: Epoch[3/5]  [ 770/3125]  eta: 0:13:49  Lr: 0.001875  Loss: -0.3307  Acc@1: 81.2500 (86.3813)  Acc@5: 100.0000 (98.7922)  time: 0.3632  data: 0.0006  max mem: 2501
Train: Epoch[3/5]  [ 780/3125]  eta: 0:13:46  Lr: 0.001875  Loss: -0.2000  Acc@1: 81.2500 (86.3716)  Acc@5: 100.0000 (98.7996)  time: 0.3670  data: 0.0008  max mem: 2501
Train: Epoch[3/5]  [ 790/3125]  eta: 0:13:43  Lr: 0.001875  Loss: -0.4497  Acc@1: 87.5000 (86.4333)  Acc@5: 100.0000 (98.8069)  time: 0.3562  data: 0.0008  max mem: 2501
Train: Epoch[3/5]  [ 800/3125]  eta: 0:13:39  Lr: 0.001875  Loss: -0.5982  Acc@1: 93.7500 (86.4466)  Acc@5: 100.0000 (98.7984)  time: 0.3556  data: 0.0005  max mem: 2501
Train: Epoch[3/5]  [ 810/3125]  eta: 0:13:36  Lr: 0.001875  Loss: -0.5479  Acc@1: 87.5000 (86.4519)  Acc@5: 100.0000 (98.7824)  time: 0.3599  data: 0.0005  max mem: 2501
Train: Epoch[3/5]  [ 820/3125]  eta: 0:13:32  Lr: 0.001875  Loss: -0.3124  Acc@1: 87.5000 (86.4571)  Acc@5: 100.0000 (98.7896)  time: 0.3551  data: 0.0005  max mem: 2501
Train: Epoch[3/5]  [ 830/3125]  eta: 0:13:29  Lr: 0.001875  Loss: 0.0250  Acc@1: 87.5000 (86.4997)  Acc@5: 100.0000 (98.7816)  time: 0.3560  data: 0.0008  max mem: 2501
Train: Epoch[3/5]  [ 840/3125]  eta: 0:13:26  Lr: 0.001875  Loss: -0.1206  Acc@1: 87.5000 (86.5190)  Acc@5: 100.0000 (98.7738)  time: 0.3656  data: 0.0014  max mem: 2501
Train: Epoch[3/5]  [ 850/3125]  eta: 0:13:23  Lr: 0.001875  Loss: -0.2875  Acc@1: 87.5000 (86.4938)  Acc@5: 100.0000 (98.7735)  time: 0.3636  data: 0.0012  max mem: 2501
Train: Epoch[3/5]  [ 860/3125]  eta: 0:13:19  Lr: 0.001875  Loss: -0.3117  Acc@1: 87.5000 (86.4692)  Acc@5: 100.0000 (98.7732)  time: 0.3582  data: 0.0007  max mem: 2501
Train: Epoch[3/5]  [ 870/3125]  eta: 0:13:16  Lr: 0.001875  Loss: -0.5055  Acc@1: 87.5000 (86.4811)  Acc@5: 100.0000 (98.7801)  time: 0.3645  data: 0.0008  max mem: 2501
Train: Epoch[3/5]  [ 880/3125]  eta: 0:13:13  Lr: 0.001875  Loss: -0.4986  Acc@1: 87.5000 (86.5139)  Acc@5: 100.0000 (98.7727)  time: 0.3680  data: 0.0007  max mem: 2501
Train: Epoch[3/5]  [ 890/3125]  eta: 0:13:09  Lr: 0.001875  Loss: -0.4148  Acc@1: 87.5000 (86.5109)  Acc@5: 100.0000 (98.7795)  time: 0.3566  data: 0.0006  max mem: 2501
Train: Epoch[3/5]  [ 900/3125]  eta: 0:13:06  Lr: 0.001875  Loss: -0.3845  Acc@1: 87.5000 (86.5497)  Acc@5: 100.0000 (98.7861)  time: 0.3542  data: 0.0005  max mem: 2501
Train: Epoch[3/5]  [ 910/3125]  eta: 0:13:03  Lr: 0.001875  Loss: -0.4856  Acc@1: 87.5000 (86.5464)  Acc@5: 100.0000 (98.7857)  time: 0.3650  data: 0.0006  max mem: 2501
Train: Epoch[3/5]  [ 920/3125]  eta: 0:12:59  Lr: 0.001875  Loss: 0.0861  Acc@1: 87.5000 (86.5499)  Acc@5: 100.0000 (98.7853)  time: 0.3590  data: 0.0007  max mem: 2501
Train: Epoch[3/5]  [ 930/3125]  eta: 0:12:56  Lr: 0.001875  Loss: -0.6816  Acc@1: 87.5000 (86.5736)  Acc@5: 100.0000 (98.7782)  time: 0.3552  data: 0.0009  max mem: 2501
Train: Epoch[3/5]  [ 940/3125]  eta: 0:12:52  Lr: 0.001875  Loss: -0.0486  Acc@1: 87.5000 (86.5768)  Acc@5: 100.0000 (98.7779)  time: 0.3636  data: 0.0011  max mem: 2501
Train: Epoch[3/5]  [ 950/3125]  eta: 0:12:49  Lr: 0.001875  Loss: -0.5055  Acc@1: 87.5000 (86.5536)  Acc@5: 100.0000 (98.7776)  time: 0.3633  data: 0.0009  max mem: 2501
Train: Epoch[3/5]  [ 960/3125]  eta: 0:12:45  Lr: 0.001875  Loss: -0.0262  Acc@1: 81.2500 (86.5440)  Acc@5: 100.0000 (98.7708)  time: 0.3558  data: 0.0006  max mem: 2501
Train: Epoch[3/5]  [ 970/3125]  eta: 0:12:42  Lr: 0.001875  Loss: -0.5720  Acc@1: 87.5000 (86.5860)  Acc@5: 100.0000 (98.7770)  time: 0.3583  data: 0.0015  max mem: 2501
Train: Epoch[3/5]  [ 980/3125]  eta: 0:12:39  Lr: 0.001875  Loss: -0.0292  Acc@1: 87.5000 (86.5889)  Acc@5: 100.0000 (98.7704)  time: 0.3746  data: 0.0022  max mem: 2501
Train: Epoch[3/5]  [ 990/3125]  eta: 0:12:36  Lr: 0.001875  Loss: -0.5370  Acc@1: 87.5000 (86.5855)  Acc@5: 100.0000 (98.7702)  time: 0.3680  data: 0.0022  max mem: 2501
Train: Epoch[3/5]  [1000/3125]  eta: 0:12:32  Lr: 0.001875  Loss: -0.3257  Acc@1: 87.5000 (86.6009)  Acc@5: 100.0000 (98.7512)  time: 0.3563  data: 0.0024  max mem: 2501
Train: Epoch[3/5]  [1010/3125]  eta: 0:12:29  Lr: 0.001875  Loss: 0.0699  Acc@1: 87.5000 (86.5418)  Acc@5: 100.0000 (98.7389)  time: 0.3633  data: 0.0015  max mem: 2501
Train: Epoch[3/5]  [1020/3125]  eta: 0:12:25  Lr: 0.001875  Loss: -0.0243  Acc@1: 81.2500 (86.4594)  Acc@5: 100.0000 (98.7329)  time: 0.3574  data: 0.0006  max mem: 2501
Train: Epoch[3/5]  [1030/3125]  eta: 0:12:22  Lr: 0.001875  Loss: -0.1611  Acc@1: 81.2500 (86.5058)  Acc@5: 100.0000 (98.7270)  time: 0.3529  data: 0.0016  max mem: 2501
Train: Epoch[3/5]  [1040/3125]  eta: 0:12:19  Lr: 0.001875  Loss: -0.4897  Acc@1: 87.5000 (86.5334)  Acc@5: 100.0000 (98.7392)  time: 0.3641  data: 0.0016  max mem: 2501
Train: Epoch[3/5]  [1050/3125]  eta: 0:12:15  Lr: 0.001875  Loss: -0.4663  Acc@1: 87.5000 (86.5604)  Acc@5: 100.0000 (98.7452)  time: 0.3695  data: 0.0010  max mem: 2501
Train: Epoch[3/5]  [1060/3125]  eta: 0:12:12  Lr: 0.001875  Loss: -0.2865  Acc@1: 87.5000 (86.5634)  Acc@5: 100.0000 (98.7453)  time: 0.3575  data: 0.0010  max mem: 2501
Train: Epoch[3/5]  [1070/3125]  eta: 0:12:08  Lr: 0.001875  Loss: -0.2906  Acc@1: 87.5000 (86.5663)  Acc@5: 100.0000 (98.7512)  time: 0.3534  data: 0.0006  max mem: 2501
Train: Epoch[3/5]  [1080/3125]  eta: 0:12:05  Lr: 0.001875  Loss: -0.2540  Acc@1: 87.5000 (86.5865)  Acc@5: 100.0000 (98.7512)  time: 0.3716  data: 0.0007  max mem: 2501
Train: Epoch[3/5]  [1090/3125]  eta: 0:12:02  Lr: 0.001875  Loss: -0.3594  Acc@1: 87.5000 (86.5662)  Acc@5: 100.0000 (98.7569)  time: 0.3659  data: 0.0007  max mem: 2501
Train: Epoch[3/5]  [1100/3125]  eta: 0:11:58  Lr: 0.001875  Loss: -0.5742  Acc@1: 87.5000 (86.5917)  Acc@5: 100.0000 (98.7568)  time: 0.3503  data: 0.0006  max mem: 2501
Train: Epoch[3/5]  [1110/3125]  eta: 0:11:55  Lr: 0.001875  Loss: -0.6243  Acc@1: 87.5000 (86.5774)  Acc@5: 100.0000 (98.7568)  time: 0.3616  data: 0.0005  max mem: 2501
Train: Epoch[3/5]  [1120/3125]  eta: 0:11:51  Lr: 0.001875  Loss: -0.2856  Acc@1: 87.5000 (86.5912)  Acc@5: 100.0000 (98.7567)  time: 0.3593  data: 0.0007  max mem: 2501
Train: Epoch[3/5]  [1130/3125]  eta: 0:11:48  Lr: 0.001875  Loss: -0.2827  Acc@1: 87.5000 (86.5937)  Acc@5: 100.0000 (98.7677)  time: 0.3522  data: 0.0008  max mem: 2501
Train: Epoch[3/5]  [1140/3125]  eta: 0:11:44  Lr: 0.001875  Loss: 0.2479  Acc@1: 87.5000 (86.5688)  Acc@5: 100.0000 (98.7621)  time: 0.3632  data: 0.0006  max mem: 2501
Train: Epoch[3/5]  [1150/3125]  eta: 0:11:41  Lr: 0.001875  Loss: -0.4733  Acc@1: 81.2500 (86.5497)  Acc@5: 100.0000 (98.7511)  time: 0.3676  data: 0.0011  max mem: 2501
Train: Epoch[3/5]  [1160/3125]  eta: 0:11:37  Lr: 0.001875  Loss: -0.1229  Acc@1: 81.2500 (86.5041)  Acc@5: 100.0000 (98.7457)  time: 0.3567  data: 0.0016  max mem: 2501
Train: Epoch[3/5]  [1170/3125]  eta: 0:11:34  Lr: 0.001875  Loss: -0.2652  Acc@1: 87.5000 (86.5126)  Acc@5: 100.0000 (98.7511)  time: 0.3527  data: 0.0012  max mem: 2501
Train: Epoch[3/5]  [1180/3125]  eta: 0:11:30  Lr: 0.001875  Loss: -0.4806  Acc@1: 87.5000 (86.5315)  Acc@5: 100.0000 (98.7511)  time: 0.3602  data: 0.0006  max mem: 2501
Train: Epoch[3/5]  [1190/3125]  eta: 0:11:27  Lr: 0.001875  Loss: -0.3102  Acc@1: 81.2500 (86.5187)  Acc@5: 100.0000 (98.7615)  time: 0.3566  data: 0.0009  max mem: 2501
Train: Epoch[3/5]  [1200/3125]  eta: 0:11:23  Lr: 0.001875  Loss: -0.5436  Acc@1: 81.2500 (86.5269)  Acc@5: 100.0000 (98.7510)  time: 0.3550  data: 0.0015  max mem: 2501
Train: Epoch[3/5]  [1210/3125]  eta: 0:11:20  Lr: 0.001875  Loss: -0.4800  Acc@1: 81.2500 (86.4730)  Acc@5: 100.0000 (98.7407)  time: 0.3599  data: 0.0011  max mem: 2501
Train: Epoch[3/5]  [1220/3125]  eta: 0:11:16  Lr: 0.001875  Loss: -0.1282  Acc@1: 81.2500 (86.4711)  Acc@5: 100.0000 (98.7510)  time: 0.3572  data: 0.0005  max mem: 2501
Train: Epoch[3/5]  [1230/3125]  eta: 0:11:13  Lr: 0.001875  Loss: -0.3379  Acc@1: 87.5000 (86.5100)  Acc@5: 100.0000 (98.7612)  time: 0.3561  data: 0.0006  max mem: 2501
Train: Epoch[3/5]  [1240/3125]  eta: 0:11:09  Lr: 0.001875  Loss: -0.5931  Acc@1: 87.5000 (86.4776)  Acc@5: 100.0000 (98.7560)  time: 0.3600  data: 0.0006  max mem: 2501
Train: Epoch[3/5]  [1250/3125]  eta: 0:11:06  Lr: 0.001875  Loss: -0.5511  Acc@1: 87.5000 (86.4958)  Acc@5: 100.0000 (98.7560)  time: 0.3654  data: 0.0008  max mem: 2501
Train: Epoch[3/5]  [1260/3125]  eta: 0:11:02  Lr: 0.001875  Loss: 0.0186  Acc@1: 87.5000 (86.5186)  Acc@5: 100.0000 (98.7559)  time: 0.3604  data: 0.0008  max mem: 2501
Train: Epoch[3/5]  [1270/3125]  eta: 0:10:59  Lr: 0.001875  Loss: -0.3853  Acc@1: 87.5000 (86.5460)  Acc@5: 100.0000 (98.7559)  time: 0.3561  data: 0.0007  max mem: 2501
Train: Epoch[3/5]  [1280/3125]  eta: 0:10:55  Lr: 0.001875  Loss: -0.0320  Acc@1: 87.5000 (86.5193)  Acc@5: 100.0000 (98.7363)  time: 0.3605  data: 0.0007  max mem: 2501
Train: Epoch[3/5]  [1290/3125]  eta: 0:10:52  Lr: 0.001875  Loss: -0.3788  Acc@1: 87.5000 (86.5414)  Acc@5: 100.0000 (98.7364)  time: 0.3568  data: 0.0011  max mem: 2501
Train: Epoch[3/5]  [1300/3125]  eta: 0:10:48  Lr: 0.001875  Loss: -0.1670  Acc@1: 87.5000 (86.5344)  Acc@5: 100.0000 (98.7221)  time: 0.3571  data: 0.0016  max mem: 2501
Train: Epoch[3/5]  [1310/3125]  eta: 0:10:45  Lr: 0.001875  Loss: -0.4677  Acc@1: 87.5000 (86.5275)  Acc@5: 100.0000 (98.7271)  time: 0.3650  data: 0.0011  max mem: 2501
Train: Epoch[3/5]  [1320/3125]  eta: 0:10:41  Lr: 0.001875  Loss: 0.0987  Acc@1: 87.5000 (86.5206)  Acc@5: 100.0000 (98.7273)  time: 0.3618  data: 0.0007  max mem: 2501
Train: Epoch[3/5]  [1330/3125]  eta: 0:10:38  Lr: 0.001875  Loss: -0.5173  Acc@1: 81.2500 (86.4576)  Acc@5: 100.0000 (98.7228)  time: 0.3565  data: 0.0008  max mem: 2501
Train: Epoch[3/5]  [1340/3125]  eta: 0:10:35  Lr: 0.001875  Loss: -0.1836  Acc@1: 87.5000 (86.4793)  Acc@5: 100.0000 (98.7183)  time: 0.3697  data: 0.0012  max mem: 2501
Train: Epoch[3/5]  [1350/3125]  eta: 0:10:31  Lr: 0.001875  Loss: -0.0062  Acc@1: 87.5000 (86.4545)  Acc@5: 100.0000 (98.7232)  time: 0.3631  data: 0.0011  max mem: 2501
Train: Epoch[3/5]  [1360/3125]  eta: 0:10:27  Lr: 0.001875  Loss: -0.4275  Acc@1: 87.5000 (86.4759)  Acc@5: 100.0000 (98.7280)  time: 0.3498  data: 0.0005  max mem: 2501
Train: Epoch[3/5]  [1370/3125]  eta: 0:10:24  Lr: 0.001875  Loss: 0.0785  Acc@1: 87.5000 (86.4561)  Acc@5: 100.0000 (98.7099)  time: 0.3622  data: 0.0006  max mem: 2501
Train: Epoch[3/5]  [1380/3125]  eta: 0:10:20  Lr: 0.001875  Loss: 0.0372  Acc@1: 81.2500 (86.4455)  Acc@5: 100.0000 (98.7192)  time: 0.3582  data: 0.0006  max mem: 2501
Train: Epoch[3/5]  [1390/3125]  eta: 0:10:17  Lr: 0.001875  Loss: 0.2184  Acc@1: 87.5000 (86.4576)  Acc@5: 100.0000 (98.7194)  time: 0.3523  data: 0.0005  max mem: 2501
Train: Epoch[3/5]  [1400/3125]  eta: 0:10:13  Lr: 0.001875  Loss: -0.0955  Acc@1: 87.5000 (86.4383)  Acc@5: 100.0000 (98.7063)  time: 0.3604  data: 0.0004  max mem: 2501
Train: Epoch[3/5]  [1410/3125]  eta: 0:10:10  Lr: 0.001875  Loss: -0.4494  Acc@1: 87.5000 (86.4281)  Acc@5: 100.0000 (98.7110)  time: 0.3564  data: 0.0005  max mem: 2501
Train: Epoch[3/5]  [1420/3125]  eta: 0:10:06  Lr: 0.001875  Loss: -0.1370  Acc@1: 87.5000 (86.4268)  Acc@5: 100.0000 (98.7069)  time: 0.3560  data: 0.0009  max mem: 2501
Train: Epoch[3/5]  [1430/3125]  eta: 0:10:03  Lr: 0.001875  Loss: -0.2054  Acc@1: 87.5000 (86.3994)  Acc@5: 100.0000 (98.7116)  time: 0.3695  data: 0.0029  max mem: 2501
Train: Epoch[3/5]  [1440/3125]  eta: 0:09:59  Lr: 0.001875  Loss: -0.6659  Acc@1: 81.2500 (86.3853)  Acc@5: 100.0000 (98.7075)  time: 0.3630  data: 0.0026  max mem: 2501
Train: Epoch[3/5]  [1450/3125]  eta: 0:09:56  Lr: 0.001875  Loss: 0.0193  Acc@1: 87.5000 (86.3887)  Acc@5: 100.0000 (98.7121)  time: 0.3536  data: 0.0006  max mem: 2501
Train: Epoch[3/5]  [1460/3125]  eta: 0:09:52  Lr: 0.001875  Loss: -0.2430  Acc@1: 87.5000 (86.3835)  Acc@5: 100.0000 (98.7038)  time: 0.3633  data: 0.0006  max mem: 2501
Train: Epoch[3/5]  [1470/3125]  eta: 0:09:49  Lr: 0.001875  Loss: -0.3911  Acc@1: 87.5000 (86.4038)  Acc@5: 100.0000 (98.7084)  time: 0.3588  data: 0.0006  max mem: 2501
Train: Epoch[3/5]  [1480/3125]  eta: 0:09:45  Lr: 0.001875  Loss: -0.1983  Acc@1: 87.5000 (86.3901)  Acc@5: 100.0000 (98.7129)  time: 0.3545  data: 0.0006  max mem: 2501
Train: Epoch[3/5]  [1490/3125]  eta: 0:09:42  Lr: 0.001875  Loss: -0.3892  Acc@1: 81.2500 (86.3850)  Acc@5: 100.0000 (98.7173)  time: 0.3636  data: 0.0005  max mem: 2501
Train: Epoch[3/5]  [1500/3125]  eta: 0:09:38  Lr: 0.001875  Loss: -0.1861  Acc@1: 87.5000 (86.3882)  Acc@5: 100.0000 (98.7175)  time: 0.3579  data: 0.0008  max mem: 2501
Train: Epoch[3/5]  [1510/3125]  eta: 0:09:34  Lr: 0.001875  Loss: -0.0290  Acc@1: 87.5000 (86.3749)  Acc@5: 100.0000 (98.7136)  time: 0.3538  data: 0.0009  max mem: 2501
Train: Epoch[3/5]  [1520/3125]  eta: 0:09:31  Lr: 0.001875  Loss: -0.5183  Acc@1: 87.5000 (86.3864)  Acc@5: 100.0000 (98.7138)  time: 0.3639  data: 0.0007  max mem: 2501
Train: Epoch[3/5]  [1530/3125]  eta: 0:09:28  Lr: 0.001875  Loss: -0.2396  Acc@1: 87.5000 (86.3815)  Acc@5: 100.0000 (98.7182)  time: 0.3703  data: 0.0019  max mem: 2501
Train: Epoch[3/5]  [1540/3125]  eta: 0:09:24  Lr: 0.001875  Loss: -0.1991  Acc@1: 87.5000 (86.3968)  Acc@5: 100.0000 (98.7224)  time: 0.3610  data: 0.0022  max mem: 2501
Train: Epoch[3/5]  [1550/3125]  eta: 0:09:20  Lr: 0.001875  Loss: -0.5914  Acc@1: 87.5000 (86.4039)  Acc@5: 100.0000 (98.7226)  time: 0.3541  data: 0.0008  max mem: 2501
Train: Epoch[3/5]  [1560/3125]  eta: 0:09:17  Lr: 0.001875  Loss: 0.1008  Acc@1: 87.5000 (86.3709)  Acc@5: 100.0000 (98.7228)  time: 0.3631  data: 0.0005  max mem: 2501
Train: Epoch[3/5]  [1570/3125]  eta: 0:09:13  Lr: 0.001875  Loss: -0.4304  Acc@1: 87.5000 (86.3542)  Acc@5: 100.0000 (98.7150)  time: 0.3596  data: 0.0005  max mem: 2501
Train: Epoch[3/5]  [1580/3125]  eta: 0:09:10  Lr: 0.001875  Loss: -0.5936  Acc@1: 81.2500 (86.3417)  Acc@5: 100.0000 (98.7073)  time: 0.3544  data: 0.0005  max mem: 2501
Train: Epoch[3/5]  [1590/3125]  eta: 0:09:06  Lr: 0.001875  Loss: -0.0692  Acc@1: 81.2500 (86.3294)  Acc@5: 100.0000 (98.7076)  time: 0.3595  data: 0.0006  max mem: 2501
Train: Epoch[3/5]  [1600/3125]  eta: 0:09:03  Lr: 0.001875  Loss: -0.1840  Acc@1: 87.5000 (86.3562)  Acc@5: 100.0000 (98.7039)  time: 0.3581  data: 0.0006  max mem: 2501
Train: Epoch[3/5]  [1610/3125]  eta: 0:08:59  Lr: 0.001875  Loss: -0.3675  Acc@1: 93.7500 (86.3633)  Acc@5: 100.0000 (98.7081)  time: 0.3606  data: 0.0005  max mem: 2501
Train: Epoch[3/5]  [1620/3125]  eta: 0:08:56  Lr: 0.001875  Loss: -0.6372  Acc@1: 87.5000 (86.3703)  Acc@5: 100.0000 (98.7006)  time: 0.3647  data: 0.0005  max mem: 2501
Train: Epoch[3/5]  [1630/3125]  eta: 0:08:52  Lr: 0.001875  Loss: -0.0956  Acc@1: 87.5000 (86.3734)  Acc@5: 100.0000 (98.6971)  time: 0.3580  data: 0.0006  max mem: 2501
Train: Epoch[3/5]  [1640/3125]  eta: 0:08:49  Lr: 0.001875  Loss: -0.1222  Acc@1: 81.2500 (86.3612)  Acc@5: 100.0000 (98.6974)  time: 0.3620  data: 0.0006  max mem: 2501
Train: Epoch[3/5]  [1650/3125]  eta: 0:08:45  Lr: 0.001875  Loss: 0.1947  Acc@1: 87.5000 (86.3605)  Acc@5: 100.0000 (98.6788)  time: 0.3588  data: 0.0005  max mem: 2501
Train: Epoch[3/5]  [1660/3125]  eta: 0:08:42  Lr: 0.001875  Loss: -0.1905  Acc@1: 87.5000 (86.3599)  Acc@5: 100.0000 (98.6793)  time: 0.3507  data: 0.0004  max mem: 2501
Train: Epoch[3/5]  [1670/3125]  eta: 0:08:38  Lr: 0.001875  Loss: 0.4872  Acc@1: 87.5000 (86.3443)  Acc@5: 100.0000 (98.6722)  time: 0.3622  data: 0.0005  max mem: 2501
Train: Epoch[3/5]  [1680/3125]  eta: 0:08:34  Lr: 0.001875  Loss: -0.5513  Acc@1: 87.5000 (86.3400)  Acc@5: 100.0000 (98.6689)  time: 0.3591  data: 0.0006  max mem: 2501
Train: Epoch[3/5]  [1690/3125]  eta: 0:08:31  Lr: 0.001875  Loss: -0.3363  Acc@1: 87.5000 (86.3468)  Acc@5: 100.0000 (98.6731)  time: 0.3519  data: 0.0005  max mem: 2501
Train: Epoch[3/5]  [1700/3125]  eta: 0:08:27  Lr: 0.001875  Loss: -0.1940  Acc@1: 87.5000 (86.3352)  Acc@5: 100.0000 (98.6772)  time: 0.3629  data: 0.0004  max mem: 2501
Train: Epoch[3/5]  [1710/3125]  eta: 0:08:24  Lr: 0.001875  Loss: -0.1827  Acc@1: 81.2500 (86.3421)  Acc@5: 100.0000 (98.6777)  time: 0.3673  data: 0.0006  max mem: 2501
Train: Epoch[3/5]  [1720/3125]  eta: 0:08:20  Lr: 0.001875  Loss: -0.3582  Acc@1: 87.5000 (86.3597)  Acc@5: 100.0000 (98.6854)  time: 0.3583  data: 0.0012  max mem: 2501
Train: Epoch[3/5]  [1730/3125]  eta: 0:08:17  Lr: 0.001875  Loss: -0.3593  Acc@1: 87.5000 (86.3735)  Acc@5: 100.0000 (98.6857)  time: 0.3546  data: 0.0012  max mem: 2501
Train: Epoch[3/5]  [1740/3125]  eta: 0:08:13  Lr: 0.001875  Loss: 0.2828  Acc@1: 87.5000 (86.3764)  Acc@5: 100.0000 (98.6861)  time: 0.3591  data: 0.0007  max mem: 2501
Train: Epoch[3/5]  [1750/3125]  eta: 0:08:10  Lr: 0.001875  Loss: 0.0732  Acc@1: 87.5000 (86.3792)  Acc@5: 100.0000 (98.6793)  time: 0.3570  data: 0.0006  max mem: 2501
Train: Epoch[3/5]  [1760/3125]  eta: 0:08:06  Lr: 0.001875  Loss: -0.4682  Acc@1: 87.5000 (86.3678)  Acc@5: 100.0000 (98.6691)  time: 0.3599  data: 0.0005  max mem: 2501
Train: Epoch[3/5]  [1770/3125]  eta: 0:08:03  Lr: 0.001875  Loss: -0.4137  Acc@1: 81.2500 (86.3672)  Acc@5: 100.0000 (98.6695)  time: 0.3605  data: 0.0005  max mem: 2501
Train: Epoch[3/5]  [1780/3125]  eta: 0:07:59  Lr: 0.001875  Loss: -0.2874  Acc@1: 87.5000 (86.3735)  Acc@5: 100.0000 (98.6665)  time: 0.3532  data: 0.0005  max mem: 2501
Train: Epoch[3/5]  [1790/3125]  eta: 0:07:55  Lr: 0.001875  Loss: -0.2787  Acc@1: 87.5000 (86.3903)  Acc@5: 100.0000 (98.6704)  time: 0.3559  data: 0.0005  max mem: 2501
Train: Epoch[3/5]  [1800/3125]  eta: 0:07:52  Lr: 0.001875  Loss: -0.5545  Acc@1: 87.5000 (86.3999)  Acc@5: 100.0000 (98.6709)  time: 0.3623  data: 0.0014  max mem: 2501
Train: Epoch[3/5]  [1810/3125]  eta: 0:07:48  Lr: 0.001875  Loss: -0.0299  Acc@1: 87.5000 (86.3956)  Acc@5: 100.0000 (98.6644)  time: 0.3659  data: 0.0021  max mem: 2501
Train: Epoch[3/5]  [1820/3125]  eta: 0:07:45  Lr: 0.001875  Loss: -0.2652  Acc@1: 81.2500 (86.3914)  Acc@5: 100.0000 (98.6580)  time: 0.3591  data: 0.0017  max mem: 2501
Train: Epoch[3/5]  [1830/3125]  eta: 0:07:41  Lr: 0.001875  Loss: -0.1340  Acc@1: 87.5000 (86.3940)  Acc@5: 100.0000 (98.6653)  time: 0.3561  data: 0.0013  max mem: 2501
Train: Epoch[3/5]  [1840/3125]  eta: 0:07:38  Lr: 0.001875  Loss: -0.5961  Acc@1: 87.5000 (86.4034)  Acc@5: 100.0000 (98.6692)  time: 0.3616  data: 0.0008  max mem: 2501
Train: Epoch[3/5]  [1850/3125]  eta: 0:07:34  Lr: 0.001875  Loss: -0.3573  Acc@1: 87.5000 (86.3925)  Acc@5: 100.0000 (98.6730)  time: 0.3583  data: 0.0006  max mem: 2501
Train: Epoch[3/5]  [1860/3125]  eta: 0:07:31  Lr: 0.001875  Loss: -0.0398  Acc@1: 87.5000 (86.3951)  Acc@5: 100.0000 (98.6701)  time: 0.3574  data: 0.0005  max mem: 2501
Train: Epoch[3/5]  [1870/3125]  eta: 0:07:27  Lr: 0.001875  Loss: -0.2852  Acc@1: 87.5000 (86.3843)  Acc@5: 100.0000 (98.6705)  time: 0.3612  data: 0.0007  max mem: 2501
Train: Epoch[3/5]  [1880/3125]  eta: 0:07:24  Lr: 0.001875  Loss: -0.6416  Acc@1: 87.5000 (86.4035)  Acc@5: 100.0000 (98.6709)  time: 0.3574  data: 0.0009  max mem: 2501
Train: Epoch[3/5]  [1890/3125]  eta: 0:07:20  Lr: 0.001875  Loss: 0.0745  Acc@1: 87.5000 (86.3994)  Acc@5: 100.0000 (98.6614)  time: 0.3573  data: 0.0007  max mem: 2501
Train: Epoch[3/5]  [1900/3125]  eta: 0:07:17  Lr: 0.001875  Loss: -0.3113  Acc@1: 87.5000 (86.4019)  Acc@5: 100.0000 (98.6586)  time: 0.3672  data: 0.0006  max mem: 2501
Train: Epoch[3/5]  [1910/3125]  eta: 0:07:13  Lr: 0.001875  Loss: -0.4047  Acc@1: 87.5000 (86.3978)  Acc@5: 100.0000 (98.6558)  time: 0.3597  data: 0.0007  max mem: 2501
Train: Epoch[3/5]  [1920/3125]  eta: 0:07:09  Lr: 0.001875  Loss: -0.5384  Acc@1: 87.5000 (86.4133)  Acc@5: 100.0000 (98.6563)  time: 0.3512  data: 0.0006  max mem: 2501
Train: Epoch[3/5]  [1930/3125]  eta: 0:07:06  Lr: 0.001875  Loss: -0.1230  Acc@1: 87.5000 (86.4190)  Acc@5: 100.0000 (98.6503)  time: 0.3619  data: 0.0005  max mem: 2501
Train: Epoch[3/5]  [1940/3125]  eta: 0:07:02  Lr: 0.001875  Loss: -0.3887  Acc@1: 87.5000 (86.4052)  Acc@5: 100.0000 (98.6573)  time: 0.3591  data: 0.0004  max mem: 2501
Train: Epoch[3/5]  [1950/3125]  eta: 0:06:59  Lr: 0.001875  Loss: -0.4104  Acc@1: 87.5000 (86.4076)  Acc@5: 100.0000 (98.6577)  time: 0.3567  data: 0.0005  max mem: 2501
Train: Epoch[3/5]  [1960/3125]  eta: 0:06:55  Lr: 0.001875  Loss: 0.0030  Acc@1: 87.5000 (86.3941)  Acc@5: 100.0000 (98.6582)  time: 0.3647  data: 0.0006  max mem: 2501
Train: Epoch[3/5]  [1970/3125]  eta: 0:06:52  Lr: 0.001875  Loss: -0.3705  Acc@1: 87.5000 (86.3997)  Acc@5: 100.0000 (98.6587)  time: 0.3568  data: 0.0008  max mem: 2501
Train: Epoch[3/5]  [1980/3125]  eta: 0:06:48  Lr: 0.001875  Loss: -0.4646  Acc@1: 87.5000 (86.3863)  Acc@5: 100.0000 (98.6654)  time: 0.3519  data: 0.0007  max mem: 2501
Train: Epoch[3/5]  [1990/3125]  eta: 0:06:45  Lr: 0.001875  Loss: -0.3782  Acc@1: 81.2500 (86.3605)  Acc@5: 100.0000 (98.6627)  time: 0.3628  data: 0.0005  max mem: 2501
Train: Epoch[3/5]  [2000/3125]  eta: 0:06:41  Lr: 0.001875  Loss: -0.5372  Acc@1: 87.5000 (86.3724)  Acc@5: 100.0000 (98.6632)  time: 0.3677  data: 0.0010  max mem: 2501
Train: Epoch[3/5]  [2010/3125]  eta: 0:06:37  Lr: 0.001875  Loss: -0.4530  Acc@1: 87.5000 (86.3532)  Acc@5: 100.0000 (98.6605)  time: 0.3585  data: 0.0013  max mem: 2501
Train: Epoch[3/5]  [2020/3125]  eta: 0:06:34  Lr: 0.001875  Loss: -0.6182  Acc@1: 87.5000 (86.3836)  Acc@5: 100.0000 (98.6548)  time: 0.3537  data: 0.0009  max mem: 2501
Train: Epoch[3/5]  [2030/3125]  eta: 0:06:30  Lr: 0.001875  Loss: -0.0524  Acc@1: 87.5000 (86.3922)  Acc@5: 100.0000 (98.6552)  time: 0.3641  data: 0.0007  max mem: 2501
Train: Epoch[3/5]  [2040/3125]  eta: 0:06:27  Lr: 0.001875  Loss: -0.0367  Acc@1: 87.5000 (86.4037)  Acc@5: 100.0000 (98.6587)  time: 0.3584  data: 0.0008  max mem: 2501
Train: Epoch[3/5]  [2050/3125]  eta: 0:06:23  Lr: 0.001875  Loss: -0.4840  Acc@1: 87.5000 (86.4213)  Acc@5: 100.0000 (98.6592)  time: 0.3508  data: 0.0007  max mem: 2501
Train: Epoch[3/5]  [2060/3125]  eta: 0:06:20  Lr: 0.001875  Loss: -0.5482  Acc@1: 87.5000 (86.4265)  Acc@5: 100.0000 (98.6566)  time: 0.3633  data: 0.0006  max mem: 2501
Train: Epoch[3/5]  [2070/3125]  eta: 0:06:16  Lr: 0.001875  Loss: -0.1550  Acc@1: 87.5000 (86.4287)  Acc@5: 100.0000 (98.6601)  time: 0.3590  data: 0.0006  max mem: 2501
Train: Epoch[3/5]  [2080/3125]  eta: 0:06:12  Lr: 0.001875  Loss: -0.3756  Acc@1: 87.5000 (86.4188)  Acc@5: 100.0000 (98.6515)  time: 0.3535  data: 0.0004  max mem: 2501
Train: Epoch[3/5]  [2090/3125]  eta: 0:06:09  Lr: 0.001875  Loss: -0.4601  Acc@1: 87.5000 (86.4419)  Acc@5: 100.0000 (98.6549)  time: 0.3649  data: 0.0005  max mem: 2501
Train: Epoch[3/5]  [2100/3125]  eta: 0:06:05  Lr: 0.001875  Loss: -0.4667  Acc@1: 87.5000 (86.4440)  Acc@5: 100.0000 (98.6554)  time: 0.3647  data: 0.0005  max mem: 2501
Train: Epoch[3/5]  [2110/3125]  eta: 0:06:02  Lr: 0.001875  Loss: -0.0555  Acc@1: 87.5000 (86.4371)  Acc@5: 100.0000 (98.6588)  time: 0.3550  data: 0.0005  max mem: 2501
Train: Epoch[3/5]  [2120/3125]  eta: 0:05:58  Lr: 0.001875  Loss: -0.0683  Acc@1: 87.5000 (86.4244)  Acc@5: 100.0000 (98.6592)  time: 0.3576  data: 0.0005  max mem: 2501
Train: Epoch[3/5]  [2130/3125]  eta: 0:05:55  Lr: 0.001875  Loss: -0.1483  Acc@1: 87.5000 (86.4207)  Acc@5: 100.0000 (98.6597)  time: 0.3617  data: 0.0006  max mem: 2501
Train: Epoch[3/5]  [2140/3125]  eta: 0:05:51  Lr: 0.001875  Loss: -0.0448  Acc@1: 87.5000 (86.4257)  Acc@5: 100.0000 (98.6659)  time: 0.3556  data: 0.0011  max mem: 2501
Train: Epoch[3/5]  [2150/3125]  eta: 0:05:48  Lr: 0.001875  Loss: -0.4427  Acc@1: 87.5000 (86.4104)  Acc@5: 100.0000 (98.6605)  time: 0.3566  data: 0.0009  max mem: 2501
Train: Epoch[3/5]  [2160/3125]  eta: 0:05:44  Lr: 0.001875  Loss: -0.4290  Acc@1: 87.5000 (86.4212)  Acc@5: 100.0000 (98.6609)  time: 0.3589  data: 0.0006  max mem: 2501
Train: Epoch[3/5]  [2170/3125]  eta: 0:05:40  Lr: 0.001875  Loss: -0.3666  Acc@1: 87.5000 (86.4463)  Acc@5: 100.0000 (98.6613)  time: 0.3561  data: 0.0006  max mem: 2501
Train: Epoch[3/5]  [2180/3125]  eta: 0:05:37  Lr: 0.001875  Loss: -0.3273  Acc@1: 93.7500 (86.4684)  Acc@5: 100.0000 (98.6617)  time: 0.3626  data: 0.0006  max mem: 2501
Train: Epoch[3/5]  [2190/3125]  eta: 0:05:33  Lr: 0.001875  Loss: -0.2404  Acc@1: 93.7500 (86.4845)  Acc@5: 100.0000 (98.6593)  time: 0.3689  data: 0.0006  max mem: 2501
Train: Epoch[3/5]  [2200/3125]  eta: 0:05:30  Lr: 0.001875  Loss: -0.4103  Acc@1: 87.5000 (86.4891)  Acc@5: 100.0000 (98.6569)  time: 0.3586  data: 0.0007  max mem: 2501
Train: Epoch[3/5]  [2210/3125]  eta: 0:05:26  Lr: 0.001875  Loss: 0.3951  Acc@1: 87.5000 (86.4993)  Acc@5: 100.0000 (98.6573)  time: 0.3521  data: 0.0007  max mem: 2501
Train: Epoch[3/5]  [2220/3125]  eta: 0:05:23  Lr: 0.001875  Loss: -0.5077  Acc@1: 87.5000 (86.4898)  Acc@5: 100.0000 (98.6577)  time: 0.3591  data: 0.0006  max mem: 2501
Train: Epoch[3/5]  [2230/3125]  eta: 0:05:19  Lr: 0.001875  Loss: -0.0869  Acc@1: 81.2500 (86.4803)  Acc@5: 100.0000 (98.6581)  time: 0.3568  data: 0.0012  max mem: 2501
Train: Epoch[3/5]  [2240/3125]  eta: 0:05:15  Lr: 0.001875  Loss: -0.1453  Acc@1: 81.2500 (86.4820)  Acc@5: 100.0000 (98.6529)  time: 0.3565  data: 0.0012  max mem: 2501
Train: Epoch[3/5]  [2250/3125]  eta: 0:05:12  Lr: 0.001875  Loss: -0.4384  Acc@1: 87.5000 (86.4893)  Acc@5: 100.0000 (98.6478)  time: 0.3628  data: 0.0008  max mem: 2501
Train: Epoch[3/5]  [2260/3125]  eta: 0:05:08  Lr: 0.001875  Loss: -0.2773  Acc@1: 87.5000 (86.4800)  Acc@5: 100.0000 (98.6455)  time: 0.3573  data: 0.0008  max mem: 2501
Train: Epoch[3/5]  [2270/3125]  eta: 0:05:05  Lr: 0.001875  Loss: 0.3192  Acc@1: 81.2500 (86.4597)  Acc@5: 100.0000 (98.6432)  time: 0.3565  data: 0.0007  max mem: 2501
Train: Epoch[3/5]  [2280/3125]  eta: 0:05:01  Lr: 0.001875  Loss: -0.3359  Acc@1: 81.2500 (86.4615)  Acc@5: 100.0000 (98.6492)  time: 0.3720  data: 0.0013  max mem: 2501
Train: Epoch[3/5]  [2290/3125]  eta: 0:04:58  Lr: 0.001875  Loss: -0.5678  Acc@1: 87.5000 (86.4688)  Acc@5: 100.0000 (98.6551)  time: 0.3672  data: 0.0012  max mem: 2501
Train: Epoch[3/5]  [2300/3125]  eta: 0:04:54  Lr: 0.001875  Loss: -0.3553  Acc@1: 87.5000 (86.4733)  Acc@5: 100.0000 (98.6500)  time: 0.3539  data: 0.0006  max mem: 2501
Train: Epoch[3/5]  [2310/3125]  eta: 0:04:51  Lr: 0.001875  Loss: -0.4451  Acc@1: 87.5000 (86.4669)  Acc@5: 100.0000 (98.6559)  time: 0.3625  data: 0.0005  max mem: 2501
Train: Epoch[3/5]  [2320/3125]  eta: 0:04:47  Lr: 0.001875  Loss: -0.6556  Acc@1: 87.5000 (86.4579)  Acc@5: 100.0000 (98.6563)  time: 0.3572  data: 0.0006  max mem: 2501
Train: Epoch[3/5]  [2330/3125]  eta: 0:04:43  Lr: 0.001875  Loss: -0.4212  Acc@1: 87.5000 (86.4516)  Acc@5: 100.0000 (98.6567)  time: 0.3522  data: 0.0007  max mem: 2501
Train: Epoch[3/5]  [2340/3125]  eta: 0:04:40  Lr: 0.001875  Loss: -0.4396  Acc@1: 87.5000 (86.4454)  Acc@5: 100.0000 (98.6598)  time: 0.3637  data: 0.0006  max mem: 2501
Train: Epoch[3/5]  [2350/3125]  eta: 0:04:36  Lr: 0.001875  Loss: -0.4094  Acc@1: 81.2500 (86.4340)  Acc@5: 100.0000 (98.6601)  time: 0.3588  data: 0.0006  max mem: 2501
Train: Epoch[3/5]  [2360/3125]  eta: 0:04:33  Lr: 0.001875  Loss: -0.3500  Acc@1: 87.5000 (86.4438)  Acc@5: 100.0000 (98.6605)  time: 0.3529  data: 0.0006  max mem: 2501
Train: Epoch[3/5]  [2370/3125]  eta: 0:04:29  Lr: 0.001875  Loss: -0.1669  Acc@1: 87.5000 (86.4377)  Acc@5: 100.0000 (98.6609)  time: 0.3660  data: 0.0007  max mem: 2501
Train: Epoch[3/5]  [2380/3125]  eta: 0:04:26  Lr: 0.001875  Loss: -0.5799  Acc@1: 87.5000 (86.4448)  Acc@5: 100.0000 (98.6665)  time: 0.3709  data: 0.0009  max mem: 2501
Train: Epoch[3/5]  [2390/3125]  eta: 0:04:22  Lr: 0.001875  Loss: -0.2907  Acc@1: 87.5000 (86.4361)  Acc@5: 100.0000 (98.6616)  time: 0.3581  data: 0.0008  max mem: 2501
Train: Epoch[3/5]  [2400/3125]  eta: 0:04:19  Lr: 0.001875  Loss: -0.0377  Acc@1: 81.2500 (86.4223)  Acc@5: 100.0000 (98.6646)  time: 0.3553  data: 0.0008  max mem: 2501
Train: Epoch[3/5]  [2410/3125]  eta: 0:04:15  Lr: 0.001875  Loss: -0.0049  Acc@1: 81.2500 (86.3879)  Acc@5: 100.0000 (98.6572)  time: 0.3627  data: 0.0010  max mem: 2501
Train: Epoch[3/5]  [2420/3125]  eta: 0:04:11  Lr: 0.001875  Loss: -0.3384  Acc@1: 81.2500 (86.3925)  Acc@5: 100.0000 (98.6627)  time: 0.3582  data: 0.0009  max mem: 2501
Train: Epoch[3/5]  [2430/3125]  eta: 0:04:08  Lr: 0.001875  Loss: -0.1866  Acc@1: 87.5000 (86.3919)  Acc@5: 100.0000 (98.6657)  time: 0.3539  data: 0.0007  max mem: 2501
Train: Epoch[3/5]  [2440/3125]  eta: 0:04:04  Lr: 0.001875  Loss: -0.3949  Acc@1: 87.5000 (86.3990)  Acc@5: 100.0000 (98.6686)  time: 0.3597  data: 0.0006  max mem: 2501
Train: Epoch[3/5]  [2450/3125]  eta: 0:04:01  Lr: 0.001875  Loss: -0.6643  Acc@1: 87.5000 (86.3882)  Acc@5: 100.0000 (98.6689)  time: 0.3590  data: 0.0005  max mem: 2501
Train: Epoch[3/5]  [2460/3125]  eta: 0:03:57  Lr: 0.001875  Loss: -0.0739  Acc@1: 87.5000 (86.3978)  Acc@5: 100.0000 (98.6718)  time: 0.3572  data: 0.0006  max mem: 2501
Train: Epoch[3/5]  [2470/3125]  eta: 0:03:54  Lr: 0.001875  Loss: -0.3158  Acc@1: 87.5000 (86.3972)  Acc@5: 100.0000 (98.6721)  time: 0.3696  data: 0.0009  max mem: 2501
Train: Epoch[3/5]  [2480/3125]  eta: 0:03:50  Lr: 0.001875  Loss: -0.4717  Acc@1: 87.5000 (86.3991)  Acc@5: 100.0000 (98.6724)  time: 0.3626  data: 0.0009  max mem: 2501
Train: Epoch[3/5]  [2490/3125]  eta: 0:03:46  Lr: 0.001875  Loss: -0.5410  Acc@1: 87.5000 (86.4111)  Acc@5: 100.0000 (98.6752)  time: 0.3521  data: 0.0005  max mem: 2501
Train: Epoch[3/5]  [2500/3125]  eta: 0:03:43  Lr: 0.001875  Loss: -0.5073  Acc@1: 87.5000 (86.4179)  Acc@5: 100.0000 (98.6730)  time: 0.3618  data: 0.0005  max mem: 2501
Train: Epoch[3/5]  [2510/3125]  eta: 0:03:39  Lr: 0.001875  Loss: -0.5483  Acc@1: 87.5000 (86.4347)  Acc@5: 100.0000 (98.6783)  time: 0.3570  data: 0.0009  max mem: 2501
Train: Epoch[3/5]  [2520/3125]  eta: 0:03:36  Lr: 0.001875  Loss: -0.4571  Acc@1: 93.7500 (86.4587)  Acc@5: 100.0000 (98.6836)  time: 0.3544  data: 0.0015  max mem: 2501
Train: Epoch[3/5]  [2530/3125]  eta: 0:03:32  Lr: 0.001875  Loss: -0.3055  Acc@1: 93.7500 (86.4653)  Acc@5: 100.0000 (98.6838)  time: 0.3634  data: 0.0010  max mem: 2501
Train: Epoch[3/5]  [2540/3125]  eta: 0:03:29  Lr: 0.001875  Loss: -0.4473  Acc@1: 87.5000 (86.4694)  Acc@5: 100.0000 (98.6890)  time: 0.3587  data: 0.0005  max mem: 2501
Train: Epoch[3/5]  [2550/3125]  eta: 0:03:25  Lr: 0.001875  Loss: -0.3515  Acc@1: 87.5000 (86.4563)  Acc@5: 100.0000 (98.6794)  time: 0.3548  data: 0.0005  max mem: 2501
Train: Epoch[3/5]  [2560/3125]  eta: 0:03:21  Lr: 0.001875  Loss: -0.1359  Acc@1: 81.2500 (86.4506)  Acc@5: 100.0000 (98.6797)  time: 0.3648  data: 0.0010  max mem: 2501
Train: Epoch[3/5]  [2570/3125]  eta: 0:03:18  Lr: 0.001875  Loss: -0.5666  Acc@1: 81.2500 (86.4425)  Acc@5: 100.0000 (98.6727)  time: 0.3638  data: 0.0010  max mem: 2501
Train: Epoch[3/5]  [2580/3125]  eta: 0:03:14  Lr: 0.001875  Loss: -0.4918  Acc@1: 87.5000 (86.4515)  Acc@5: 100.0000 (98.6730)  time: 0.3544  data: 0.0006  max mem: 2501
Train: Epoch[3/5]  [2590/3125]  eta: 0:03:11  Lr: 0.001875  Loss: -0.4515  Acc@1: 87.5000 (86.4555)  Acc@5: 100.0000 (98.6757)  time: 0.3593  data: 0.0007  max mem: 2501
Train: Epoch[3/5]  [2600/3125]  eta: 0:03:07  Lr: 0.001875  Loss: 0.0395  Acc@1: 87.5000 (86.4355)  Acc@5: 100.0000 (98.6712)  time: 0.3599  data: 0.0006  max mem: 2501
Train: Epoch[3/5]  [2610/3125]  eta: 0:03:04  Lr: 0.001875  Loss: -0.5633  Acc@1: 87.5000 (86.4324)  Acc@5: 100.0000 (98.6715)  time: 0.3532  data: 0.0006  max mem: 2501
Train: Epoch[3/5]  [2620/3125]  eta: 0:03:00  Lr: 0.001875  Loss: -0.3897  Acc@1: 81.2500 (86.4269)  Acc@5: 100.0000 (98.6646)  time: 0.3636  data: 0.0008  max mem: 2501
Train: Epoch[3/5]  [2630/3125]  eta: 0:02:56  Lr: 0.001875  Loss: -0.0978  Acc@1: 87.5000 (86.4476)  Acc@5: 100.0000 (98.6673)  time: 0.3618  data: 0.0011  max mem: 2501
Train: Epoch[3/5]  [2640/3125]  eta: 0:02:53  Lr: 0.001875  Loss: -0.3570  Acc@1: 93.7500 (86.4611)  Acc@5: 100.0000 (98.6629)  time: 0.3518  data: 0.0009  max mem: 2501
Train: Epoch[3/5]  [2650/3125]  eta: 0:02:49  Lr: 0.001875  Loss: -0.3484  Acc@1: 87.5000 (86.4532)  Acc@5: 100.0000 (98.6562)  time: 0.3642  data: 0.0011  max mem: 2501
Train: Epoch[3/5]  [2660/3125]  eta: 0:02:46  Lr: 0.001875  Loss: -0.2704  Acc@1: 87.5000 (86.4736)  Acc@5: 100.0000 (98.6542)  time: 0.3705  data: 0.0011  max mem: 2501
Train: Epoch[3/5]  [2670/3125]  eta: 0:02:42  Lr: 0.001875  Loss: -0.5856  Acc@1: 87.5000 (86.4751)  Acc@5: 100.0000 (98.6569)  time: 0.3573  data: 0.0021  max mem: 2501
Train: Epoch[3/5]  [2680/3125]  eta: 0:02:39  Lr: 0.001875  Loss: -0.0022  Acc@1: 87.5000 (86.4859)  Acc@5: 100.0000 (98.6526)  time: 0.3530  data: 0.0022  max mem: 2501
Train: Epoch[3/5]  [2690/3125]  eta: 0:02:35  Lr: 0.001875  Loss: -0.5612  Acc@1: 87.5000 (86.4827)  Acc@5: 100.0000 (98.6506)  time: 0.3621  data: 0.0007  max mem: 2501
Train: Epoch[3/5]  [2700/3125]  eta: 0:02:31  Lr: 0.001875  Loss: -0.4210  Acc@1: 87.5000 (86.4703)  Acc@5: 100.0000 (98.6486)  time: 0.3585  data: 0.0013  max mem: 2501
Train: Epoch[3/5]  [2710/3125]  eta: 0:02:28  Lr: 0.001875  Loss: -0.3509  Acc@1: 87.5000 (86.4856)  Acc@5: 100.0000 (98.6513)  time: 0.3541  data: 0.0014  max mem: 2501
Train: Epoch[3/5]  [2720/3125]  eta: 0:02:24  Lr: 0.001875  Loss: -0.5518  Acc@1: 87.5000 (86.4916)  Acc@5: 100.0000 (98.6540)  time: 0.3623  data: 0.0006  max mem: 2501
Train: Epoch[3/5]  [2730/3125]  eta: 0:02:21  Lr: 0.001875  Loss: -0.6020  Acc@1: 87.5000 (86.4953)  Acc@5: 100.0000 (98.6589)  time: 0.3576  data: 0.0006  max mem: 2501
Train: Epoch[3/5]  [2740/3125]  eta: 0:02:17  Lr: 0.001875  Loss: -0.6785  Acc@1: 87.5000 (86.5104)  Acc@5: 100.0000 (98.6570)  time: 0.3536  data: 0.0006  max mem: 2501
Train: Epoch[3/5]  [2750/3125]  eta: 0:02:14  Lr: 0.001875  Loss: -0.7477  Acc@1: 87.5000 (86.5231)  Acc@5: 100.0000 (98.6550)  time: 0.3628  data: 0.0009  max mem: 2501
Train: Epoch[3/5]  [2760/3125]  eta: 0:02:10  Lr: 0.001875  Loss: -0.6812  Acc@1: 93.7500 (86.5425)  Acc@5: 100.0000 (98.6599)  time: 0.3649  data: 0.0018  max mem: 2501
Train: Epoch[3/5]  [2770/3125]  eta: 0:02:06  Lr: 0.001875  Loss: -0.3658  Acc@1: 93.7500 (86.5549)  Acc@5: 100.0000 (98.6625)  time: 0.3567  data: 0.0013  max mem: 2501
Train: Epoch[3/5]  [2780/3125]  eta: 0:02:03  Lr: 0.001875  Loss: -0.4451  Acc@1: 93.7500 (86.5606)  Acc@5: 100.0000 (98.6628)  time: 0.3562  data: 0.0005  max mem: 2501
Train: Epoch[3/5]  [2790/3125]  eta: 0:01:59  Lr: 0.001875  Loss: -0.5163  Acc@1: 93.7500 (86.5841)  Acc@5: 100.0000 (98.6676)  time: 0.3597  data: 0.0005  max mem: 2501
Train: Epoch[3/5]  [2800/3125]  eta: 0:01:56  Lr: 0.001875  Loss: -0.3448  Acc@1: 87.5000 (86.5896)  Acc@5: 100.0000 (98.6701)  time: 0.3584  data: 0.0007  max mem: 2501
Train: Epoch[3/5]  [2810/3125]  eta: 0:01:52  Lr: 0.001875  Loss: -0.5871  Acc@1: 87.5000 (86.5751)  Acc@5: 100.0000 (98.6637)  time: 0.3648  data: 0.0006  max mem: 2501
Train: Epoch[3/5]  [2820/3125]  eta: 0:01:49  Lr: 0.001875  Loss: -0.6927  Acc@1: 87.5000 (86.5739)  Acc@5: 100.0000 (98.6552)  time: 0.3577  data: 0.0004  max mem: 2501
Train: Epoch[3/5]  [2830/3125]  eta: 0:01:45  Lr: 0.001875  Loss: -0.4091  Acc@1: 81.2500 (86.5706)  Acc@5: 100.0000 (98.6555)  time: 0.3516  data: 0.0006  max mem: 2501
Train: Epoch[3/5]  [2840/3125]  eta: 0:01:41  Lr: 0.001875  Loss: -0.2672  Acc@1: 87.5000 (86.5716)  Acc@5: 100.0000 (98.6580)  time: 0.3648  data: 0.0006  max mem: 2501
Train: Epoch[3/5]  [2850/3125]  eta: 0:01:38  Lr: 0.001875  Loss: -0.4788  Acc@1: 87.5000 (86.5639)  Acc@5: 100.0000 (98.6562)  time: 0.3665  data: 0.0006  max mem: 2501
Train: Epoch[3/5]  [2860/3125]  eta: 0:01:34  Lr: 0.001875  Loss: -0.0133  Acc@1: 81.2500 (86.5606)  Acc@5: 100.0000 (98.6543)  time: 0.3575  data: 0.0009  max mem: 2501
Train: Epoch[3/5]  [2870/3125]  eta: 0:01:31  Lr: 0.001875  Loss: -0.5729  Acc@1: 81.2500 (86.5574)  Acc@5: 100.0000 (98.6525)  time: 0.3558  data: 0.0009  max mem: 2501
Train: Epoch[3/5]  [2880/3125]  eta: 0:01:27  Lr: 0.001875  Loss: 0.0111  Acc@1: 87.5000 (86.5541)  Acc@5: 100.0000 (98.6463)  time: 0.3611  data: 0.0006  max mem: 2501
Train: Epoch[3/5]  [2890/3125]  eta: 0:01:24  Lr: 0.001875  Loss: -0.5984  Acc@1: 87.5000 (86.5509)  Acc@5: 100.0000 (98.6467)  time: 0.3578  data: 0.0005  max mem: 2501
Train: Epoch[3/5]  [2900/3125]  eta: 0:01:20  Lr: 0.001875  Loss: -0.3571  Acc@1: 87.5000 (86.5585)  Acc@5: 100.0000 (98.6470)  time: 0.3562  data: 0.0005  max mem: 2501
Train: Epoch[3/5]  [2910/3125]  eta: 0:01:16  Lr: 0.001875  Loss: -0.5545  Acc@1: 87.5000 (86.5489)  Acc@5: 100.0000 (98.6495)  time: 0.3598  data: 0.0007  max mem: 2501
Train: Epoch[3/5]  [2920/3125]  eta: 0:01:13  Lr: 0.001875  Loss: 0.1062  Acc@1: 81.2500 (86.5393)  Acc@5: 100.0000 (98.6413)  time: 0.3579  data: 0.0013  max mem: 2501
Train: Epoch[3/5]  [2930/3125]  eta: 0:01:09  Lr: 0.001875  Loss: -0.5069  Acc@1: 93.7500 (86.5575)  Acc@5: 100.0000 (98.6438)  time: 0.3636  data: 0.0011  max mem: 2501
Train: Epoch[3/5]  [2940/3125]  eta: 0:01:06  Lr: 0.001875  Loss: -0.2331  Acc@1: 93.7500 (86.5479)  Acc@5: 100.0000 (98.6420)  time: 0.3636  data: 0.0021  max mem: 2501
Train: Epoch[3/5]  [2950/3125]  eta: 0:01:02  Lr: 0.001875  Loss: -0.2194  Acc@1: 81.2500 (86.5491)  Acc@5: 100.0000 (98.6382)  time: 0.3587  data: 0.0021  max mem: 2501
Train: Epoch[3/5]  [2960/3125]  eta: 0:00:59  Lr: 0.001875  Loss: -0.3379  Acc@1: 87.5000 (86.5480)  Acc@5: 100.0000 (98.6343)  time: 0.3573  data: 0.0006  max mem: 2501
Train: Epoch[3/5]  [2970/3125]  eta: 0:00:55  Lr: 0.001875  Loss: -0.6518  Acc@1: 87.5000 (86.5512)  Acc@5: 100.0000 (98.6368)  time: 0.3579  data: 0.0007  max mem: 2501
Train: Epoch[3/5]  [2980/3125]  eta: 0:00:51  Lr: 0.001875  Loss: -0.2508  Acc@1: 87.5000 (86.5607)  Acc@5: 100.0000 (98.6393)  time: 0.3593  data: 0.0006  max mem: 2501
Train: Epoch[3/5]  [2990/3125]  eta: 0:00:48  Lr: 0.001875  Loss: -0.1937  Acc@1: 87.5000 (86.5639)  Acc@5: 100.0000 (98.6418)  time: 0.3558  data: 0.0005  max mem: 2501
Train: Epoch[3/5]  [3000/3125]  eta: 0:00:44  Lr: 0.001875  Loss: -0.3427  Acc@1: 87.5000 (86.5420)  Acc@5: 100.0000 (98.6421)  time: 0.3623  data: 0.0012  max mem: 2501
Train: Epoch[3/5]  [3010/3125]  eta: 0:00:41  Lr: 0.001875  Loss: -0.1059  Acc@1: 87.5000 (86.5389)  Acc@5: 100.0000 (98.6425)  time: 0.3574  data: 0.0012  max mem: 2501
Train: Epoch[3/5]  [3020/3125]  eta: 0:00:37  Lr: 0.001875  Loss: -0.5236  Acc@1: 87.5000 (86.5442)  Acc@5: 100.0000 (98.6449)  time: 0.3525  data: 0.0009  max mem: 2501
Train: Epoch[3/5]  [3030/3125]  eta: 0:00:33  Lr: 0.001875  Loss: -0.1098  Acc@1: 93.7500 (86.5453)  Acc@5: 100.0000 (98.6452)  time: 0.3643  data: 0.0010  max mem: 2501
Train: Epoch[3/5]  [3040/3125]  eta: 0:00:30  Lr: 0.001875  Loss: -0.3450  Acc@1: 87.5000 (86.5484)  Acc@5: 100.0000 (98.6476)  time: 0.3680  data: 0.0020  max mem: 2501
Train: Epoch[3/5]  [3050/3125]  eta: 0:00:26  Lr: 0.001875  Loss: -0.0627  Acc@1: 87.5000 (86.5331)  Acc@5: 100.0000 (98.6459)  time: 0.3578  data: 0.0021  max mem: 2501
Train: Epoch[3/5]  [3060/3125]  eta: 0:00:23  Lr: 0.001875  Loss: -0.2443  Acc@1: 87.5000 (86.5424)  Acc@5: 100.0000 (98.6483)  time: 0.3526  data: 0.0007  max mem: 2501
Train: Epoch[3/5]  [3070/3125]  eta: 0:00:19  Lr: 0.001875  Loss: -0.5597  Acc@1: 87.5000 (86.5516)  Acc@5: 100.0000 (98.6507)  time: 0.3637  data: 0.0006  max mem: 2501
Train: Epoch[3/5]  [3080/3125]  eta: 0:00:16  Lr: 0.001875  Loss: -0.4201  Acc@1: 87.5000 (86.5547)  Acc@5: 100.0000 (98.6510)  time: 0.3585  data: 0.0005  max mem: 2501
Train: Epoch[3/5]  [3090/3125]  eta: 0:00:12  Lr: 0.001875  Loss: -0.5310  Acc@1: 87.5000 (86.5658)  Acc@5: 100.0000 (98.6513)  time: 0.3516  data: 0.0006  max mem: 2501
Train: Epoch[3/5]  [3100/3125]  eta: 0:00:08  Lr: 0.001875  Loss: -0.4475  Acc@1: 93.7500 (86.5769)  Acc@5: 100.0000 (98.6537)  time: 0.3639  data: 0.0006  max mem: 2501
Train: Epoch[3/5]  [3110/3125]  eta: 0:00:05  Lr: 0.001875  Loss: -0.4840  Acc@1: 87.5000 (86.5819)  Acc@5: 100.0000 (98.6540)  time: 0.3608  data: 0.0010  max mem: 2501
Train: Epoch[3/5]  [3120/3125]  eta: 0:00:01  Lr: 0.001875  Loss: -0.3758  Acc@1: 87.5000 (86.5788)  Acc@5: 100.0000 (98.6543)  time: 0.3541  data: 0.0015  max mem: 2501
Train: Epoch[3/5]  [3124/3125]  eta: 0:00:00  Lr: 0.001875  Loss: -0.3793  Acc@1: 81.2500 (86.5780)  Acc@5: 100.0000 (98.6560)  time: 0.3558  data: 0.0014  max mem: 2501
Train: Epoch[3/5] Total time: 0:18:38 (0.3580 s / it)
{0: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 1: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 2: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 3: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 4: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 5: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 6: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 7: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 8: {0: 0, 1: 0, 2: 150000, 3: 0, 4: 0}, 9: {0: 0, 1: 0, 2: 150000, 3: 0, 4: 0}, 10: {0: 0, 1: 0, 2: 150000, 3: 0, 4: 0}, 11: {0: 0, 1: 0, 2: 150000, 3: 0, 4: 0}, 12: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 13: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 14: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 15: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 16: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 17: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 18: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 19: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}}
Averaged stats: Lr: 0.001875  Loss: -0.3793  Acc@1: 81.2500 (86.5780)  Acc@5: 100.0000 (98.6560)
Train: Epoch[4/5]  [   0/3125]  eta: 0:51:41  Lr: 0.001875  Loss: -0.1063  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (100.0000)  time: 0.9923  data: 0.5918  max mem: 2501
Train: Epoch[4/5]  [  10/3125]  eta: 0:22:08  Lr: 0.001875  Loss: -0.6953  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (97.1591)  time: 0.4264  data: 0.0546  max mem: 2501
Train: Epoch[4/5]  [  20/3125]  eta: 0:20:08  Lr: 0.001875  Loss: -0.0451  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (98.2143)  time: 0.3591  data: 0.0007  max mem: 2501
Train: Epoch[4/5]  [  30/3125]  eta: 0:19:32  Lr: 0.001875  Loss: -0.1906  Acc@1: 87.5000 (87.2984)  Acc@5: 100.0000 (98.5887)  time: 0.3528  data: 0.0004  max mem: 2501
Train: Epoch[4/5]  [  40/3125]  eta: 0:19:21  Lr: 0.001875  Loss: -0.2476  Acc@1: 87.5000 (87.6524)  Acc@5: 100.0000 (98.7805)  time: 0.3628  data: 0.0005  max mem: 2501
Train: Epoch[4/5]  [  50/3125]  eta: 0:18:58  Lr: 0.001875  Loss: -0.3812  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (98.8971)  time: 0.3569  data: 0.0006  max mem: 2501
Train: Epoch[4/5]  [  60/3125]  eta: 0:18:48  Lr: 0.001875  Loss: -0.4454  Acc@1: 87.5000 (87.2951)  Acc@5: 100.0000 (98.7705)  time: 0.3515  data: 0.0006  max mem: 2501
Train: Epoch[4/5]  [  70/3125]  eta: 0:18:45  Lr: 0.001875  Loss: -0.4200  Acc@1: 87.5000 (87.2359)  Acc@5: 100.0000 (98.5035)  time: 0.3633  data: 0.0006  max mem: 2501
Train: Epoch[4/5]  [  80/3125]  eta: 0:18:33  Lr: 0.001875  Loss: -0.6018  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (98.5340)  time: 0.3582  data: 0.0008  max mem: 2501
Train: Epoch[4/5]  [  90/3125]  eta: 0:18:27  Lr: 0.001875  Loss: -0.3835  Acc@1: 87.5000 (87.2940)  Acc@5: 100.0000 (98.6264)  time: 0.3522  data: 0.0007  max mem: 2501
Train: Epoch[4/5]  [ 100/3125]  eta: 0:18:24  Lr: 0.001875  Loss: -0.4084  Acc@1: 87.5000 (87.2525)  Acc@5: 100.0000 (98.7005)  time: 0.3632  data: 0.0007  max mem: 2501
Train: Epoch[4/5]  [ 110/3125]  eta: 0:18:21  Lr: 0.001875  Loss: -0.2057  Acc@1: 81.2500 (87.1059)  Acc@5: 100.0000 (98.7613)  time: 0.3681  data: 0.0009  max mem: 2501
Train: Epoch[4/5]  [ 120/3125]  eta: 0:18:13  Lr: 0.001875  Loss: -0.0044  Acc@1: 87.5000 (87.1384)  Acc@5: 100.0000 (98.7603)  time: 0.3564  data: 0.0007  max mem: 2501
Train: Epoch[4/5]  [ 130/3125]  eta: 0:18:08  Lr: 0.001875  Loss: -0.6801  Acc@1: 87.5000 (87.1660)  Acc@5: 100.0000 (98.7595)  time: 0.3523  data: 0.0005  max mem: 2501
Train: Epoch[4/5]  [ 140/3125]  eta: 0:18:05  Lr: 0.001875  Loss: -0.5983  Acc@1: 87.5000 (87.1897)  Acc@5: 100.0000 (98.6702)  time: 0.3619  data: 0.0014  max mem: 2501
Train: Epoch[4/5]  [ 150/3125]  eta: 0:17:58  Lr: 0.001875  Loss: -0.2637  Acc@1: 81.2500 (87.0033)  Acc@5: 100.0000 (98.6755)  time: 0.3566  data: 0.0015  max mem: 2501
Train: Epoch[4/5]  [ 160/3125]  eta: 0:17:53  Lr: 0.001875  Loss: -0.4284  Acc@1: 81.2500 (86.7624)  Acc@5: 100.0000 (98.6025)  time: 0.3529  data: 0.0009  max mem: 2501
Train: Epoch[4/5]  [ 170/3125]  eta: 0:17:51  Lr: 0.001875  Loss: -0.6446  Acc@1: 81.2500 (86.8056)  Acc@5: 100.0000 (98.6842)  time: 0.3626  data: 0.0007  max mem: 2501
Train: Epoch[4/5]  [ 180/3125]  eta: 0:17:46  Lr: 0.001875  Loss: -0.4246  Acc@1: 87.5000 (86.9475)  Acc@5: 100.0000 (98.6878)  time: 0.3602  data: 0.0004  max mem: 2501
Train: Epoch[4/5]  [ 190/3125]  eta: 0:17:41  Lr: 0.001875  Loss: -0.5642  Acc@1: 93.7500 (87.3691)  Acc@5: 100.0000 (98.7238)  time: 0.3558  data: 0.0005  max mem: 2501
Train: Epoch[4/5]  [ 200/3125]  eta: 0:17:39  Lr: 0.001875  Loss: -0.2248  Acc@1: 93.7500 (87.3756)  Acc@5: 100.0000 (98.7873)  time: 0.3641  data: 0.0016  max mem: 2501
Train: Epoch[4/5]  [ 210/3125]  eta: 0:17:36  Lr: 0.001875  Loss: -0.5077  Acc@1: 87.5000 (87.5296)  Acc@5: 100.0000 (98.8152)  time: 0.3681  data: 0.0020  max mem: 2501
Train: Epoch[4/5]  [ 220/3125]  eta: 0:17:31  Lr: 0.001875  Loss: -0.5512  Acc@1: 87.5000 (87.4717)  Acc@5: 100.0000 (98.7839)  time: 0.3615  data: 0.0010  max mem: 2501
Train: Epoch[4/5]  [ 230/3125]  eta: 0:17:27  Lr: 0.001875  Loss: -0.1890  Acc@1: 81.2500 (87.2835)  Acc@5: 100.0000 (98.7825)  time: 0.3580  data: 0.0007  max mem: 2501
Train: Epoch[4/5]  [ 240/3125]  eta: 0:17:24  Lr: 0.001875  Loss: 0.2517  Acc@1: 81.2500 (87.1629)  Acc@5: 100.0000 (98.7552)  time: 0.3604  data: 0.0006  max mem: 2501
Train: Epoch[4/5]  [ 250/3125]  eta: 0:17:19  Lr: 0.001875  Loss: -0.4967  Acc@1: 87.5000 (87.3008)  Acc@5: 100.0000 (98.7799)  time: 0.3563  data: 0.0006  max mem: 2501
Train: Epoch[4/5]  [ 260/3125]  eta: 0:17:15  Lr: 0.001875  Loss: -0.5154  Acc@1: 87.5000 (86.9971)  Acc@5: 100.0000 (98.7548)  time: 0.3568  data: 0.0009  max mem: 2501
Train: Epoch[4/5]  [ 270/3125]  eta: 0:17:12  Lr: 0.001875  Loss: -0.1724  Acc@1: 81.2500 (86.8773)  Acc@5: 100.0000 (98.7085)  time: 0.3617  data: 0.0008  max mem: 2501
Train: Epoch[4/5]  [ 280/3125]  eta: 0:17:07  Lr: 0.001875  Loss: -0.2685  Acc@1: 81.2500 (86.8327)  Acc@5: 100.0000 (98.7322)  time: 0.3578  data: 0.0007  max mem: 2501
Train: Epoch[4/5]  [ 290/3125]  eta: 0:17:04  Lr: 0.001875  Loss: -0.5806  Acc@1: 87.5000 (86.7698)  Acc@5: 100.0000 (98.7113)  time: 0.3570  data: 0.0007  max mem: 2501
Train: Epoch[4/5]  [ 300/3125]  eta: 0:17:02  Lr: 0.001875  Loss: -0.5492  Acc@1: 87.5000 (86.7110)  Acc@5: 100.0000 (98.7126)  time: 0.3685  data: 0.0006  max mem: 2501
Train: Epoch[4/5]  [ 310/3125]  eta: 0:16:57  Lr: 0.001875  Loss: -0.2221  Acc@1: 87.5000 (86.7765)  Acc@5: 100.0000 (98.7138)  time: 0.3639  data: 0.0007  max mem: 2501
Train: Epoch[4/5]  [ 320/3125]  eta: 0:16:53  Lr: 0.001875  Loss: -0.7315  Acc@1: 87.5000 (86.7991)  Acc@5: 100.0000 (98.6760)  time: 0.3547  data: 0.0008  max mem: 2501
Train: Epoch[4/5]  [ 330/3125]  eta: 0:16:50  Lr: 0.001875  Loss: 0.0848  Acc@1: 87.5000 (86.9147)  Acc@5: 100.0000 (98.6971)  time: 0.3619  data: 0.0008  max mem: 2501
Train: Epoch[4/5]  [ 340/3125]  eta: 0:16:45  Lr: 0.001875  Loss: -0.5365  Acc@1: 87.5000 (86.9318)  Acc@5: 100.0000 (98.7353)  time: 0.3558  data: 0.0006  max mem: 2501
Train: Epoch[4/5]  [ 350/3125]  eta: 0:16:41  Lr: 0.001875  Loss: 0.1006  Acc@1: 87.5000 (86.7877)  Acc@5: 100.0000 (98.7179)  time: 0.3496  data: 0.0005  max mem: 2501
Train: Epoch[4/5]  [ 360/3125]  eta: 0:16:37  Lr: 0.001875  Loss: -0.4434  Acc@1: 87.5000 (86.8767)  Acc@5: 100.0000 (98.7361)  time: 0.3557  data: 0.0005  max mem: 2501
Train: Epoch[4/5]  [ 370/3125]  eta: 0:16:33  Lr: 0.001875  Loss: -0.4610  Acc@1: 87.5000 (86.8767)  Acc@5: 100.0000 (98.7365)  time: 0.3609  data: 0.0011  max mem: 2501
Train: Epoch[4/5]  [ 380/3125]  eta: 0:16:29  Lr: 0.001875  Loss: -0.3372  Acc@1: 87.5000 (86.9915)  Acc@5: 100.0000 (98.7041)  time: 0.3567  data: 0.0010  max mem: 2501
Train: Epoch[4/5]  [ 390/3125]  eta: 0:16:25  Lr: 0.001875  Loss: -0.5322  Acc@1: 93.7500 (87.0844)  Acc@5: 100.0000 (98.7052)  time: 0.3554  data: 0.0006  max mem: 2501
Train: Epoch[4/5]  [ 400/3125]  eta: 0:16:22  Lr: 0.001875  Loss: -0.1286  Acc@1: 93.7500 (87.1103)  Acc@5: 100.0000 (98.7219)  time: 0.3624  data: 0.0009  max mem: 2501
Train: Epoch[4/5]  [ 410/3125]  eta: 0:16:19  Lr: 0.001875  Loss: -0.5545  Acc@1: 81.2500 (87.0286)  Acc@5: 100.0000 (98.7226)  time: 0.3644  data: 0.0008  max mem: 2501
Train: Epoch[4/5]  [ 420/3125]  eta: 0:16:15  Lr: 0.001875  Loss: -0.2865  Acc@1: 81.2500 (86.9804)  Acc@5: 100.0000 (98.6936)  time: 0.3592  data: 0.0008  max mem: 2501
Train: Epoch[4/5]  [ 430/3125]  eta: 0:16:12  Lr: 0.001875  Loss: -0.3386  Acc@1: 81.2500 (86.9345)  Acc@5: 100.0000 (98.6659)  time: 0.3620  data: 0.0008  max mem: 2501
Train: Epoch[4/5]  [ 440/3125]  eta: 0:16:07  Lr: 0.001875  Loss: -0.1944  Acc@1: 81.2500 (86.8906)  Acc@5: 100.0000 (98.6395)  time: 0.3592  data: 0.0004  max mem: 2501
Train: Epoch[4/5]  [ 450/3125]  eta: 0:16:03  Lr: 0.001875  Loss: -0.7104  Acc@1: 87.5000 (86.9180)  Acc@5: 100.0000 (98.6280)  time: 0.3521  data: 0.0005  max mem: 2501
Train: Epoch[4/5]  [ 460/3125]  eta: 0:16:00  Lr: 0.001875  Loss: -0.2177  Acc@1: 87.5000 (86.9306)  Acc@5: 100.0000 (98.6307)  time: 0.3633  data: 0.0006  max mem: 2501
Train: Epoch[4/5]  [ 470/3125]  eta: 0:15:56  Lr: 0.001875  Loss: 0.1284  Acc@1: 87.5000 (86.9029)  Acc@5: 100.0000 (98.6332)  time: 0.3597  data: 0.0005  max mem: 2501
Train: Epoch[4/5]  [ 480/3125]  eta: 0:15:52  Lr: 0.001875  Loss: -0.1934  Acc@1: 87.5000 (86.9673)  Acc@5: 100.0000 (98.6486)  time: 0.3525  data: 0.0005  max mem: 2501
Train: Epoch[4/5]  [ 490/3125]  eta: 0:15:49  Lr: 0.001875  Loss: -0.4624  Acc@1: 87.5000 (86.9399)  Acc@5: 100.0000 (98.6762)  time: 0.3612  data: 0.0005  max mem: 2501
Train: Epoch[4/5]  [ 500/3125]  eta: 0:15:46  Lr: 0.001875  Loss: -0.0920  Acc@1: 87.5000 (86.9511)  Acc@5: 100.0000 (98.6901)  time: 0.3700  data: 0.0012  max mem: 2501
Train: Epoch[4/5]  [ 510/3125]  eta: 0:15:42  Lr: 0.001875  Loss: -0.4548  Acc@1: 87.5000 (86.9741)  Acc@5: 100.0000 (98.7035)  time: 0.3644  data: 0.0013  max mem: 2501
Train: Epoch[4/5]  [ 520/3125]  eta: 0:15:39  Lr: 0.001875  Loss: -0.4282  Acc@1: 87.5000 (86.9602)  Acc@5: 100.0000 (98.7284)  time: 0.3579  data: 0.0007  max mem: 2501
Train: Epoch[4/5]  [ 530/3125]  eta: 0:15:35  Lr: 0.001875  Loss: -0.3952  Acc@1: 87.5000 (86.9468)  Acc@5: 100.0000 (98.7288)  time: 0.3614  data: 0.0010  max mem: 2501
Train: Epoch[4/5]  [ 540/3125]  eta: 0:15:31  Lr: 0.001875  Loss: -0.3861  Acc@1: 87.5000 (86.8646)  Acc@5: 100.0000 (98.7061)  time: 0.3564  data: 0.0009  max mem: 2501
Train: Epoch[4/5]  [ 550/3125]  eta: 0:15:28  Lr: 0.001875  Loss: -0.5118  Acc@1: 87.5000 (86.9555)  Acc@5: 100.0000 (98.7296)  time: 0.3565  data: 0.0006  max mem: 2501
Train: Epoch[4/5]  [ 560/3125]  eta: 0:15:24  Lr: 0.001875  Loss: -0.0930  Acc@1: 87.5000 (86.8984)  Acc@5: 100.0000 (98.7299)  time: 0.3619  data: 0.0007  max mem: 2501
Train: Epoch[4/5]  [ 570/3125]  eta: 0:15:20  Lr: 0.001875  Loss: -0.5331  Acc@1: 87.5000 (86.9527)  Acc@5: 100.0000 (98.7412)  time: 0.3580  data: 0.0006  max mem: 2501
Train: Epoch[4/5]  [ 580/3125]  eta: 0:15:17  Lr: 0.001875  Loss: -0.3015  Acc@1: 87.5000 (86.8976)  Acc@5: 100.0000 (98.7522)  time: 0.3613  data: 0.0005  max mem: 2501
Train: Epoch[4/5]  [ 590/3125]  eta: 0:15:14  Lr: 0.001875  Loss: -0.5230  Acc@1: 87.5000 (86.8866)  Acc@5: 100.0000 (98.7521)  time: 0.3680  data: 0.0009  max mem: 2501
Train: Epoch[4/5]  [ 600/3125]  eta: 0:15:10  Lr: 0.001875  Loss: -0.5957  Acc@1: 87.5000 (86.8656)  Acc@5: 100.0000 (98.7209)  time: 0.3583  data: 0.0012  max mem: 2501
Train: Epoch[4/5]  [ 610/3125]  eta: 0:15:06  Lr: 0.001875  Loss: -0.1658  Acc@1: 87.5000 (86.8249)  Acc@5: 93.7500 (98.6804)  time: 0.3527  data: 0.0009  max mem: 2501
Train: Epoch[4/5]  [ 620/3125]  eta: 0:15:02  Lr: 0.001875  Loss: -0.7250  Acc@1: 87.5000 (86.9062)  Acc@5: 100.0000 (98.6916)  time: 0.3620  data: 0.0006  max mem: 2501
Train: Epoch[4/5]  [ 630/3125]  eta: 0:14:58  Lr: 0.001875  Loss: 0.0924  Acc@1: 87.5000 (86.8661)  Acc@5: 100.0000 (98.6727)  time: 0.3561  data: 0.0007  max mem: 2501
Train: Epoch[4/5]  [ 640/3125]  eta: 0:14:55  Lr: 0.001875  Loss: -0.2974  Acc@1: 87.5000 (86.8955)  Acc@5: 100.0000 (98.6544)  time: 0.3520  data: 0.0007  max mem: 2501
Train: Epoch[4/5]  [ 650/3125]  eta: 0:14:51  Lr: 0.001875  Loss: -0.1416  Acc@1: 87.5000 (86.9048)  Acc@5: 100.0000 (98.6559)  time: 0.3653  data: 0.0005  max mem: 2501
Train: Epoch[4/5]  [ 660/3125]  eta: 0:14:47  Lr: 0.001875  Loss: -0.5886  Acc@1: 87.5000 (86.9327)  Acc@5: 100.0000 (98.6573)  time: 0.3592  data: 0.0006  max mem: 2501
Train: Epoch[4/5]  [ 670/3125]  eta: 0:14:44  Lr: 0.001875  Loss: -0.4016  Acc@1: 87.5000 (86.9504)  Acc@5: 100.0000 (98.6680)  time: 0.3525  data: 0.0006  max mem: 2501
Train: Epoch[4/5]  [ 680/3125]  eta: 0:14:40  Lr: 0.001875  Loss: -0.3444  Acc@1: 87.5000 (86.8759)  Acc@5: 100.0000 (98.6601)  time: 0.3628  data: 0.0007  max mem: 2501
Train: Epoch[4/5]  [ 690/3125]  eta: 0:14:37  Lr: 0.001875  Loss: -0.3735  Acc@1: 87.5000 (86.8216)  Acc@5: 100.0000 (98.6523)  time: 0.3684  data: 0.0017  max mem: 2501
Train: Epoch[4/5]  [ 700/3125]  eta: 0:14:33  Lr: 0.001875  Loss: -0.2928  Acc@1: 87.5000 (86.8046)  Acc@5: 100.0000 (98.6626)  time: 0.3614  data: 0.0023  max mem: 2501
Train: Epoch[4/5]  [ 710/3125]  eta: 0:14:30  Lr: 0.001875  Loss: -0.4303  Acc@1: 87.5000 (86.8231)  Acc@5: 100.0000 (98.6551)  time: 0.3564  data: 0.0013  max mem: 2501
Train: Epoch[4/5]  [ 720/3125]  eta: 0:14:26  Lr: 0.001875  Loss: -0.2775  Acc@1: 87.5000 (86.8672)  Acc@5: 100.0000 (98.6477)  time: 0.3586  data: 0.0006  max mem: 2501
Train: Epoch[4/5]  [ 730/3125]  eta: 0:14:22  Lr: 0.001875  Loss: -0.4102  Acc@1: 87.5000 (86.9186)  Acc@5: 100.0000 (98.6491)  time: 0.3556  data: 0.0005  max mem: 2501
Train: Epoch[4/5]  [ 740/3125]  eta: 0:14:19  Lr: 0.001875  Loss: -0.5353  Acc@1: 87.5000 (86.8590)  Acc@5: 100.0000 (98.6336)  time: 0.3622  data: 0.0006  max mem: 2501
Train: Epoch[4/5]  [ 750/3125]  eta: 0:14:15  Lr: 0.001875  Loss: -0.1522  Acc@1: 81.2500 (86.9008)  Acc@5: 100.0000 (98.6268)  time: 0.3583  data: 0.0006  max mem: 2501
Train: Epoch[4/5]  [ 760/3125]  eta: 0:14:11  Lr: 0.001875  Loss: -0.4158  Acc@1: 87.5000 (86.8676)  Acc@5: 100.0000 (98.6202)  time: 0.3515  data: 0.0005  max mem: 2501
Train: Epoch[4/5]  [ 770/3125]  eta: 0:14:08  Lr: 0.001875  Loss: 0.7542  Acc@1: 87.5000 (86.8515)  Acc@5: 100.0000 (98.6057)  time: 0.3684  data: 0.0006  max mem: 2501
Train: Epoch[4/5]  [ 780/3125]  eta: 0:14:04  Lr: 0.001875  Loss: -0.3746  Acc@1: 87.5000 (86.9238)  Acc@5: 100.0000 (98.6156)  time: 0.3631  data: 0.0005  max mem: 2501
Train: Epoch[4/5]  [ 790/3125]  eta: 0:14:00  Lr: 0.001875  Loss: -0.4161  Acc@1: 93.7500 (86.9627)  Acc@5: 100.0000 (98.6173)  time: 0.3497  data: 0.0006  max mem: 2501
Train: Epoch[4/5]  [ 800/3125]  eta: 0:13:57  Lr: 0.001875  Loss: -0.1275  Acc@1: 87.5000 (86.9226)  Acc@5: 100.0000 (98.6111)  time: 0.3583  data: 0.0010  max mem: 2501
Train: Epoch[4/5]  [ 810/3125]  eta: 0:13:53  Lr: 0.001875  Loss: -0.4158  Acc@1: 87.5000 (86.9374)  Acc@5: 100.0000 (98.6051)  time: 0.3622  data: 0.0013  max mem: 2501
Train: Epoch[4/5]  [ 820/3125]  eta: 0:13:49  Lr: 0.001875  Loss: -0.3823  Acc@1: 87.5000 (86.8758)  Acc@5: 100.0000 (98.6145)  time: 0.3557  data: 0.0009  max mem: 2501
Train: Epoch[4/5]  [ 830/3125]  eta: 0:13:46  Lr: 0.001875  Loss: -0.4898  Acc@1: 87.5000 (86.8908)  Acc@5: 100.0000 (98.6236)  time: 0.3594  data: 0.0006  max mem: 2501
Train: Epoch[4/5]  [ 840/3125]  eta: 0:13:42  Lr: 0.001875  Loss: -0.2057  Acc@1: 87.5000 (86.8683)  Acc@5: 100.0000 (98.6103)  time: 0.3598  data: 0.0006  max mem: 2501
Train: Epoch[4/5]  [ 850/3125]  eta: 0:13:38  Lr: 0.001875  Loss: -0.3955  Acc@1: 87.5000 (86.9051)  Acc@5: 100.0000 (98.6266)  time: 0.3559  data: 0.0005  max mem: 2501
Train: Epoch[4/5]  [ 860/3125]  eta: 0:13:35  Lr: 0.001875  Loss: -0.5481  Acc@1: 87.5000 (86.8975)  Acc@5: 100.0000 (98.6426)  time: 0.3642  data: 0.0005  max mem: 2501
Train: Epoch[4/5]  [ 870/3125]  eta: 0:13:32  Lr: 0.001875  Loss: -0.4362  Acc@1: 93.7500 (86.9546)  Acc@5: 100.0000 (98.6438)  time: 0.3657  data: 0.0017  max mem: 2501
Train: Epoch[4/5]  [ 880/3125]  eta: 0:13:28  Lr: 0.001875  Loss: -0.5614  Acc@1: 93.7500 (86.9821)  Acc@5: 100.0000 (98.6592)  time: 0.3549  data: 0.0017  max mem: 2501
Train: Epoch[4/5]  [ 890/3125]  eta: 0:13:24  Lr: 0.001875  Loss: -0.5963  Acc@1: 93.7500 (87.0300)  Acc@5: 100.0000 (98.6602)  time: 0.3521  data: 0.0005  max mem: 2501
Train: Epoch[4/5]  [ 900/3125]  eta: 0:13:20  Lr: 0.001875  Loss: -0.3033  Acc@1: 93.7500 (87.0422)  Acc@5: 100.0000 (98.6681)  time: 0.3622  data: 0.0007  max mem: 2501
Train: Epoch[4/5]  [ 910/3125]  eta: 0:13:17  Lr: 0.001875  Loss: -0.0320  Acc@1: 87.5000 (87.0266)  Acc@5: 100.0000 (98.6690)  time: 0.3582  data: 0.0014  max mem: 2501
Train: Epoch[4/5]  [ 920/3125]  eta: 0:13:13  Lr: 0.001875  Loss: -0.5009  Acc@1: 87.5000 (87.0318)  Acc@5: 100.0000 (98.6631)  time: 0.3542  data: 0.0011  max mem: 2501
Train: Epoch[4/5]  [ 930/3125]  eta: 0:13:10  Lr: 0.001875  Loss: 0.0153  Acc@1: 87.5000 (87.0368)  Acc@5: 100.0000 (98.6574)  time: 0.3619  data: 0.0004  max mem: 2501
Train: Epoch[4/5]  [ 940/3125]  eta: 0:13:06  Lr: 0.001875  Loss: 0.0794  Acc@1: 87.5000 (86.9952)  Acc@5: 100.0000 (98.6650)  time: 0.3585  data: 0.0006  max mem: 2501
Train: Epoch[4/5]  [ 950/3125]  eta: 0:13:02  Lr: 0.001875  Loss: 0.1863  Acc@1: 87.5000 (86.9940)  Acc@5: 100.0000 (98.6593)  time: 0.3555  data: 0.0006  max mem: 2501
Train: Epoch[4/5]  [ 960/3125]  eta: 0:12:59  Lr: 0.001875  Loss: 0.2574  Acc@1: 87.5000 (86.9732)  Acc@5: 100.0000 (98.6602)  time: 0.3668  data: 0.0005  max mem: 2501
Train: Epoch[4/5]  [ 970/3125]  eta: 0:12:55  Lr: 0.001875  Loss: -0.4689  Acc@1: 81.2500 (86.9400)  Acc@5: 100.0000 (98.6612)  time: 0.3609  data: 0.0011  max mem: 2501
Train: Epoch[4/5]  [ 980/3125]  eta: 0:12:51  Lr: 0.001875  Loss: -0.6296  Acc@1: 87.5000 (87.0285)  Acc@5: 100.0000 (98.6748)  time: 0.3521  data: 0.0012  max mem: 2501
Train: Epoch[4/5]  [ 990/3125]  eta: 0:12:48  Lr: 0.001875  Loss: -0.3275  Acc@1: 93.7500 (87.0774)  Acc@5: 100.0000 (98.6756)  time: 0.3644  data: 0.0006  max mem: 2501
Train: Epoch[4/5]  [1000/3125]  eta: 0:12:44  Lr: 0.001875  Loss: -0.6382  Acc@1: 93.7500 (87.1254)  Acc@5: 100.0000 (98.6701)  time: 0.3654  data: 0.0004  max mem: 2501
Train: Epoch[4/5]  [1010/3125]  eta: 0:12:41  Lr: 0.001875  Loss: 0.0993  Acc@1: 93.7500 (87.1662)  Acc@5: 100.0000 (98.6771)  time: 0.3554  data: 0.0004  max mem: 2501
Train: Epoch[4/5]  [1020/3125]  eta: 0:12:37  Lr: 0.001875  Loss: -0.6132  Acc@1: 87.5000 (87.1572)  Acc@5: 100.0000 (98.6716)  time: 0.3577  data: 0.0005  max mem: 2501
Train: Epoch[4/5]  [1030/3125]  eta: 0:12:33  Lr: 0.001875  Loss: -0.1554  Acc@1: 87.5000 (87.1726)  Acc@5: 100.0000 (98.6785)  time: 0.3593  data: 0.0007  max mem: 2501
Train: Epoch[4/5]  [1040/3125]  eta: 0:12:30  Lr: 0.001875  Loss: -0.0534  Acc@1: 87.5000 (87.1698)  Acc@5: 100.0000 (98.6912)  time: 0.3537  data: 0.0006  max mem: 2501
Train: Epoch[4/5]  [1050/3125]  eta: 0:12:26  Lr: 0.001875  Loss: -0.1575  Acc@1: 87.5000 (87.1610)  Acc@5: 100.0000 (98.6858)  time: 0.3612  data: 0.0005  max mem: 2501
Train: Epoch[4/5]  [1060/3125]  eta: 0:12:23  Lr: 0.001875  Loss: -0.1032  Acc@1: 87.5000 (87.1583)  Acc@5: 100.0000 (98.6864)  time: 0.3691  data: 0.0010  max mem: 2501
Train: Epoch[4/5]  [1070/3125]  eta: 0:12:19  Lr: 0.001875  Loss: -0.2578  Acc@1: 87.5000 (87.1965)  Acc@5: 100.0000 (98.6870)  time: 0.3589  data: 0.0020  max mem: 2501
Train: Epoch[4/5]  [1080/3125]  eta: 0:12:15  Lr: 0.001875  Loss: -0.2756  Acc@1: 87.5000 (87.2340)  Acc@5: 100.0000 (98.6818)  time: 0.3535  data: 0.0016  max mem: 2501
Train: Epoch[4/5]  [1090/3125]  eta: 0:12:12  Lr: 0.001875  Loss: -0.1843  Acc@1: 87.5000 (87.2193)  Acc@5: 100.0000 (98.6767)  time: 0.3669  data: 0.0005  max mem: 2501
Train: Epoch[4/5]  [1100/3125]  eta: 0:12:08  Lr: 0.001875  Loss: -0.0419  Acc@1: 87.5000 (87.1935)  Acc@5: 100.0000 (98.6660)  time: 0.3655  data: 0.0007  max mem: 2501
Train: Epoch[4/5]  [1110/3125]  eta: 0:12:05  Lr: 0.001875  Loss: -0.2389  Acc@1: 81.2500 (87.1287)  Acc@5: 100.0000 (98.6442)  time: 0.3555  data: 0.0007  max mem: 2501
Train: Epoch[4/5]  [1120/3125]  eta: 0:12:01  Lr: 0.001875  Loss: -0.1927  Acc@1: 87.5000 (87.0986)  Acc@5: 100.0000 (98.6563)  time: 0.3654  data: 0.0023  max mem: 2501
Train: Epoch[4/5]  [1130/3125]  eta: 0:11:57  Lr: 0.001875  Loss: 0.0046  Acc@1: 81.2500 (87.0579)  Acc@5: 100.0000 (98.6627)  time: 0.3598  data: 0.0023  max mem: 2501
Train: Epoch[4/5]  [1140/3125]  eta: 0:11:54  Lr: 0.001875  Loss: -0.5998  Acc@1: 87.5000 (87.0837)  Acc@5: 100.0000 (98.6689)  time: 0.3512  data: 0.0006  max mem: 2501
Train: Epoch[4/5]  [1150/3125]  eta: 0:11:50  Lr: 0.001875  Loss: -0.3805  Acc@1: 87.5000 (87.0927)  Acc@5: 100.0000 (98.6642)  time: 0.3633  data: 0.0012  max mem: 2501
Train: Epoch[4/5]  [1160/3125]  eta: 0:11:47  Lr: 0.001875  Loss: -0.0038  Acc@1: 87.5000 (87.1124)  Acc@5: 100.0000 (98.6596)  time: 0.3673  data: 0.0013  max mem: 2501
Train: Epoch[4/5]  [1170/3125]  eta: 0:11:43  Lr: 0.001875  Loss: -0.7140  Acc@1: 87.5000 (87.1531)  Acc@5: 100.0000 (98.6657)  time: 0.3579  data: 0.0009  max mem: 2501
Train: Epoch[4/5]  [1180/3125]  eta: 0:11:39  Lr: 0.001875  Loss: 0.0600  Acc@1: 87.5000 (87.1560)  Acc@5: 100.0000 (98.6558)  time: 0.3533  data: 0.0006  max mem: 2501
Train: Epoch[4/5]  [1190/3125]  eta: 0:11:36  Lr: 0.001875  Loss: -0.3156  Acc@1: 87.5000 (87.1274)  Acc@5: 100.0000 (98.6461)  time: 0.3713  data: 0.0017  max mem: 2501
Train: Epoch[4/5]  [1200/3125]  eta: 0:11:33  Lr: 0.001875  Loss: -0.4554  Acc@1: 87.5000 (87.1253)  Acc@5: 100.0000 (98.6522)  time: 0.3691  data: 0.0018  max mem: 2501
Train: Epoch[4/5]  [1210/3125]  eta: 0:11:29  Lr: 0.001875  Loss: -0.4318  Acc@1: 93.7500 (87.1491)  Acc@5: 100.0000 (98.6530)  time: 0.3519  data: 0.0005  max mem: 2501
Train: Epoch[4/5]  [1220/3125]  eta: 0:11:25  Lr: 0.001875  Loss: -0.5401  Acc@1: 87.5000 (87.1007)  Acc@5: 100.0000 (98.6538)  time: 0.3609  data: 0.0005  max mem: 2501
Train: Epoch[4/5]  [1230/3125]  eta: 0:11:22  Lr: 0.001875  Loss: -0.2880  Acc@1: 87.5000 (87.0989)  Acc@5: 100.0000 (98.6444)  time: 0.3574  data: 0.0005  max mem: 2501
Train: Epoch[4/5]  [1240/3125]  eta: 0:11:18  Lr: 0.001875  Loss: -0.2122  Acc@1: 87.5000 (87.0870)  Acc@5: 100.0000 (98.6503)  time: 0.3514  data: 0.0005  max mem: 2501
Train: Epoch[4/5]  [1250/3125]  eta: 0:11:15  Lr: 0.001875  Loss: -0.6811  Acc@1: 87.5000 (87.0953)  Acc@5: 100.0000 (98.6561)  time: 0.3650  data: 0.0006  max mem: 2501
Train: Epoch[4/5]  [1260/3125]  eta: 0:11:11  Lr: 0.001875  Loss: -0.6935  Acc@1: 87.5000 (87.1134)  Acc@5: 100.0000 (98.6667)  time: 0.3686  data: 0.0005  max mem: 2501
Train: Epoch[4/5]  [1270/3125]  eta: 0:11:07  Lr: 0.001875  Loss: -0.2262  Acc@1: 87.5000 (87.1410)  Acc@5: 100.0000 (98.6723)  time: 0.3572  data: 0.0005  max mem: 2501
Train: Epoch[4/5]  [1280/3125]  eta: 0:11:04  Lr: 0.001875  Loss: -0.5552  Acc@1: 87.5000 (87.1487)  Acc@5: 100.0000 (98.6778)  time: 0.3530  data: 0.0006  max mem: 2501
Train: Epoch[4/5]  [1290/3125]  eta: 0:11:00  Lr: 0.001875  Loss: -0.5587  Acc@1: 87.5000 (87.1514)  Acc@5: 100.0000 (98.6784)  time: 0.3713  data: 0.0007  max mem: 2501
Train: Epoch[4/5]  [1300/3125]  eta: 0:10:57  Lr: 0.001875  Loss: 0.3136  Acc@1: 87.5000 (87.1541)  Acc@5: 100.0000 (98.6837)  time: 0.3666  data: 0.0008  max mem: 2501
Train: Epoch[4/5]  [1310/3125]  eta: 0:10:53  Lr: 0.001875  Loss: -0.2499  Acc@1: 87.5000 (87.1424)  Acc@5: 100.0000 (98.6842)  time: 0.3514  data: 0.0007  max mem: 2501
Train: Epoch[4/5]  [1320/3125]  eta: 0:10:49  Lr: 0.001875  Loss: -0.2523  Acc@1: 87.5000 (87.1168)  Acc@5: 100.0000 (98.6847)  time: 0.3637  data: 0.0006  max mem: 2501
Train: Epoch[4/5]  [1330/3125]  eta: 0:10:46  Lr: 0.001875  Loss: -0.2785  Acc@1: 87.5000 (87.1196)  Acc@5: 100.0000 (98.6758)  time: 0.3606  data: 0.0007  max mem: 2501
Train: Epoch[4/5]  [1340/3125]  eta: 0:10:42  Lr: 0.001875  Loss: -0.3973  Acc@1: 87.5000 (87.1085)  Acc@5: 100.0000 (98.6670)  time: 0.3510  data: 0.0005  max mem: 2501
Train: Epoch[4/5]  [1350/3125]  eta: 0:10:39  Lr: 0.001875  Loss: -0.5311  Acc@1: 87.5000 (87.1114)  Acc@5: 100.0000 (98.6677)  time: 0.3626  data: 0.0006  max mem: 2501
Train: Epoch[4/5]  [1360/3125]  eta: 0:10:35  Lr: 0.001875  Loss: -0.1447  Acc@1: 87.5000 (87.1097)  Acc@5: 100.0000 (98.6729)  time: 0.3686  data: 0.0009  max mem: 2501
Train: Epoch[4/5]  [1370/3125]  eta: 0:10:31  Lr: 0.001875  Loss: -0.4372  Acc@1: 87.5000 (87.1171)  Acc@5: 100.0000 (98.6780)  time: 0.3568  data: 0.0008  max mem: 2501
Train: Epoch[4/5]  [1380/3125]  eta: 0:10:28  Lr: 0.001875  Loss: -0.6478  Acc@1: 87.5000 (87.1153)  Acc@5: 100.0000 (98.6740)  time: 0.3534  data: 0.0007  max mem: 2501
Train: Epoch[4/5]  [1390/3125]  eta: 0:10:24  Lr: 0.001875  Loss: -0.3561  Acc@1: 87.5000 (87.0956)  Acc@5: 100.0000 (98.6700)  time: 0.3617  data: 0.0007  max mem: 2501
Train: Epoch[4/5]  [1400/3125]  eta: 0:10:20  Lr: 0.001875  Loss: -0.1821  Acc@1: 87.5000 (87.1074)  Acc@5: 100.0000 (98.6661)  time: 0.3560  data: 0.0005  max mem: 2501
Train: Epoch[4/5]  [1410/3125]  eta: 0:10:17  Lr: 0.001875  Loss: -0.2986  Acc@1: 87.5000 (87.1102)  Acc@5: 100.0000 (98.6756)  time: 0.3523  data: 0.0005  max mem: 2501
Train: Epoch[4/5]  [1420/3125]  eta: 0:10:13  Lr: 0.001875  Loss: -0.0635  Acc@1: 81.2500 (87.0690)  Acc@5: 100.0000 (98.6761)  time: 0.3628  data: 0.0011  max mem: 2501
Train: Epoch[4/5]  [1430/3125]  eta: 0:10:10  Lr: 0.001875  Loss: -0.2623  Acc@1: 81.2500 (87.0851)  Acc@5: 100.0000 (98.6810)  time: 0.3593  data: 0.0013  max mem: 2501
Train: Epoch[4/5]  [1440/3125]  eta: 0:10:06  Lr: 0.001875  Loss: -0.5656  Acc@1: 87.5000 (87.0880)  Acc@5: 100.0000 (98.6901)  time: 0.3553  data: 0.0008  max mem: 2501
Train: Epoch[4/5]  [1450/3125]  eta: 0:10:02  Lr: 0.001875  Loss: -0.5629  Acc@1: 87.5000 (87.0822)  Acc@5: 100.0000 (98.6733)  time: 0.3621  data: 0.0009  max mem: 2501
Train: Epoch[4/5]  [1460/3125]  eta: 0:09:59  Lr: 0.001875  Loss: 0.0021  Acc@1: 81.2500 (87.0722)  Acc@5: 100.0000 (98.6739)  time: 0.3651  data: 0.0008  max mem: 2501
Train: Epoch[4/5]  [1470/3125]  eta: 0:09:55  Lr: 0.001875  Loss: -0.1919  Acc@1: 81.2500 (87.0411)  Acc@5: 100.0000 (98.6659)  time: 0.3575  data: 0.0006  max mem: 2501
Train: Epoch[4/5]  [1480/3125]  eta: 0:09:52  Lr: 0.001875  Loss: -0.0997  Acc@1: 81.2500 (87.0273)  Acc@5: 100.0000 (98.6580)  time: 0.3553  data: 0.0007  max mem: 2501
Train: Epoch[4/5]  [1490/3125]  eta: 0:09:48  Lr: 0.001875  Loss: 0.0227  Acc@1: 87.5000 (87.0305)  Acc@5: 100.0000 (98.6628)  time: 0.3619  data: 0.0006  max mem: 2501
Train: Epoch[4/5]  [1500/3125]  eta: 0:09:44  Lr: 0.001875  Loss: -0.4091  Acc@1: 93.7500 (87.0420)  Acc@5: 100.0000 (98.6634)  time: 0.3567  data: 0.0006  max mem: 2501
Train: Epoch[4/5]  [1510/3125]  eta: 0:09:41  Lr: 0.001875  Loss: -0.1463  Acc@1: 87.5000 (87.0367)  Acc@5: 100.0000 (98.6681)  time: 0.3559  data: 0.0007  max mem: 2501
Train: Epoch[4/5]  [1520/3125]  eta: 0:09:37  Lr: 0.001875  Loss: -0.4287  Acc@1: 87.5000 (87.0274)  Acc@5: 100.0000 (98.6645)  time: 0.3614  data: 0.0005  max mem: 2501
Train: Epoch[4/5]  [1530/3125]  eta: 0:09:33  Lr: 0.001875  Loss: -0.4696  Acc@1: 87.5000 (87.0387)  Acc@5: 100.0000 (98.6651)  time: 0.3559  data: 0.0004  max mem: 2501
Train: Epoch[4/5]  [1540/3125]  eta: 0:09:30  Lr: 0.001875  Loss: -0.4123  Acc@1: 87.5000 (87.0539)  Acc@5: 100.0000 (98.6575)  time: 0.3552  data: 0.0004  max mem: 2501
Train: Epoch[4/5]  [1550/3125]  eta: 0:09:26  Lr: 0.001875  Loss: -0.5500  Acc@1: 93.7500 (87.0809)  Acc@5: 100.0000 (98.6581)  time: 0.3653  data: 0.0008  max mem: 2501
Train: Epoch[4/5]  [1560/3125]  eta: 0:09:23  Lr: 0.001875  Loss: -0.5089  Acc@1: 87.5000 (87.0756)  Acc@5: 100.0000 (98.6627)  time: 0.3632  data: 0.0009  max mem: 2501
Train: Epoch[4/5]  [1570/3125]  eta: 0:09:19  Lr: 0.001875  Loss: -0.2386  Acc@1: 81.2500 (87.0504)  Acc@5: 100.0000 (98.6673)  time: 0.3542  data: 0.0007  max mem: 2501
Train: Epoch[4/5]  [1580/3125]  eta: 0:09:16  Lr: 0.001875  Loss: -0.2000  Acc@1: 81.2500 (87.0493)  Acc@5: 100.0000 (98.6717)  time: 0.3619  data: 0.0006  max mem: 2501
Train: Epoch[4/5]  [1590/3125]  eta: 0:09:12  Lr: 0.001875  Loss: -0.0654  Acc@1: 87.5000 (87.0443)  Acc@5: 100.0000 (98.6761)  time: 0.3595  data: 0.0005  max mem: 2501
Train: Epoch[4/5]  [1600/3125]  eta: 0:09:08  Lr: 0.001875  Loss: -0.4122  Acc@1: 87.5000 (87.0394)  Acc@5: 100.0000 (98.6766)  time: 0.3526  data: 0.0005  max mem: 2501
Train: Epoch[4/5]  [1610/3125]  eta: 0:09:05  Lr: 0.001875  Loss: -0.4268  Acc@1: 87.5000 (87.0461)  Acc@5: 100.0000 (98.6771)  time: 0.3604  data: 0.0006  max mem: 2501
Train: Epoch[4/5]  [1620/3125]  eta: 0:09:01  Lr: 0.001875  Loss: -0.3036  Acc@1: 87.5000 (87.0373)  Acc@5: 100.0000 (98.6698)  time: 0.3559  data: 0.0006  max mem: 2501
Train: Epoch[4/5]  [1630/3125]  eta: 0:08:57  Lr: 0.001875  Loss: -0.4183  Acc@1: 87.5000 (87.0210)  Acc@5: 100.0000 (98.6626)  time: 0.3533  data: 0.0005  max mem: 2501
Train: Epoch[4/5]  [1640/3125]  eta: 0:08:54  Lr: 0.001875  Loss: 0.0389  Acc@1: 87.5000 (87.0163)  Acc@5: 100.0000 (98.6670)  time: 0.3638  data: 0.0009  max mem: 2501
Train: Epoch[4/5]  [1650/3125]  eta: 0:08:50  Lr: 0.001875  Loss: -0.7123  Acc@1: 87.5000 (87.0154)  Acc@5: 100.0000 (98.6713)  time: 0.3693  data: 0.0013  max mem: 2501
Train: Epoch[4/5]  [1660/3125]  eta: 0:08:47  Lr: 0.001875  Loss: -0.4988  Acc@1: 87.5000 (87.0259)  Acc@5: 100.0000 (98.6755)  time: 0.3604  data: 0.0009  max mem: 2501
Train: Epoch[4/5]  [1670/3125]  eta: 0:08:43  Lr: 0.001875  Loss: -0.4777  Acc@1: 81.2500 (86.9988)  Acc@5: 100.0000 (98.6722)  time: 0.3608  data: 0.0006  max mem: 2501
Train: Epoch[4/5]  [1680/3125]  eta: 0:08:39  Lr: 0.001875  Loss: -0.2455  Acc@1: 81.2500 (87.0018)  Acc@5: 100.0000 (98.6689)  time: 0.3600  data: 0.0010  max mem: 2501
Train: Epoch[4/5]  [1690/3125]  eta: 0:08:36  Lr: 0.001875  Loss: -0.1215  Acc@1: 87.5000 (87.0158)  Acc@5: 100.0000 (98.6768)  time: 0.3520  data: 0.0009  max mem: 2501
Train: Epoch[4/5]  [1700/3125]  eta: 0:08:32  Lr: 0.001875  Loss: 0.1662  Acc@1: 87.5000 (87.0260)  Acc@5: 100.0000 (98.6662)  time: 0.3628  data: 0.0009  max mem: 2501
Train: Epoch[4/5]  [1710/3125]  eta: 0:08:29  Lr: 0.001875  Loss: -0.2261  Acc@1: 87.5000 (87.0324)  Acc@5: 100.0000 (98.6704)  time: 0.3592  data: 0.0009  max mem: 2501
Train: Epoch[4/5]  [1720/3125]  eta: 0:08:25  Lr: 0.001875  Loss: -0.3442  Acc@1: 87.5000 (87.0352)  Acc@5: 100.0000 (98.6672)  time: 0.3512  data: 0.0005  max mem: 2501
Train: Epoch[4/5]  [1730/3125]  eta: 0:08:21  Lr: 0.001875  Loss: -0.1326  Acc@1: 87.5000 (87.0270)  Acc@5: 100.0000 (98.6677)  time: 0.3639  data: 0.0006  max mem: 2501
Train: Epoch[4/5]  [1740/3125]  eta: 0:08:18  Lr: 0.001875  Loss: -0.3804  Acc@1: 81.2500 (87.0046)  Acc@5: 100.0000 (98.6610)  time: 0.3607  data: 0.0016  max mem: 2501
Train: Epoch[4/5]  [1750/3125]  eta: 0:08:14  Lr: 0.001875  Loss: -0.3947  Acc@1: 87.5000 (87.0181)  Acc@5: 100.0000 (98.6543)  time: 0.3546  data: 0.0018  max mem: 2501
Train: Epoch[4/5]  [1760/3125]  eta: 0:08:11  Lr: 0.001875  Loss: 0.2971  Acc@1: 87.5000 (87.0315)  Acc@5: 100.0000 (98.6478)  time: 0.3563  data: 0.0008  max mem: 2501
Train: Epoch[4/5]  [1770/3125]  eta: 0:08:07  Lr: 0.001875  Loss: -0.5551  Acc@1: 87.5000 (87.0342)  Acc@5: 100.0000 (98.6413)  time: 0.3588  data: 0.0005  max mem: 2501
Train: Epoch[4/5]  [1780/3125]  eta: 0:08:03  Lr: 0.001875  Loss: -0.3294  Acc@1: 87.5000 (87.0262)  Acc@5: 100.0000 (98.6419)  time: 0.3593  data: 0.0006  max mem: 2501
Train: Epoch[4/5]  [1790/3125]  eta: 0:08:00  Lr: 0.001875  Loss: -0.2451  Acc@1: 87.5000 (87.0045)  Acc@5: 100.0000 (98.6390)  time: 0.3542  data: 0.0006  max mem: 2501
Train: Epoch[4/5]  [1800/3125]  eta: 0:07:56  Lr: 0.001875  Loss: -0.5481  Acc@1: 87.5000 (87.0107)  Acc@5: 100.0000 (98.6396)  time: 0.3609  data: 0.0005  max mem: 2501
Train: Epoch[4/5]  [1810/3125]  eta: 0:07:52  Lr: 0.001875  Loss: -0.2191  Acc@1: 87.5000 (87.0134)  Acc@5: 100.0000 (98.6334)  time: 0.3577  data: 0.0004  max mem: 2501
Train: Epoch[4/5]  [1820/3125]  eta: 0:07:49  Lr: 0.001875  Loss: -0.2835  Acc@1: 87.5000 (87.0126)  Acc@5: 100.0000 (98.6409)  time: 0.3519  data: 0.0005  max mem: 2501
Train: Epoch[4/5]  [1830/3125]  eta: 0:07:45  Lr: 0.001875  Loss: -0.4707  Acc@1: 87.5000 (87.0289)  Acc@5: 100.0000 (98.6483)  time: 0.3690  data: 0.0009  max mem: 2501
Train: Epoch[4/5]  [1840/3125]  eta: 0:07:42  Lr: 0.001875  Loss: 0.0674  Acc@1: 87.5000 (87.0043)  Acc@5: 100.0000 (98.6454)  time: 0.3670  data: 0.0010  max mem: 2501
Train: Epoch[4/5]  [1850/3125]  eta: 0:07:38  Lr: 0.001875  Loss: -0.4268  Acc@1: 87.5000 (86.9935)  Acc@5: 100.0000 (98.6460)  time: 0.3538  data: 0.0005  max mem: 2501
Train: Epoch[4/5]  [1860/3125]  eta: 0:07:35  Lr: 0.001875  Loss: -0.6222  Acc@1: 87.5000 (86.9962)  Acc@5: 100.0000 (98.6466)  time: 0.3573  data: 0.0006  max mem: 2501
Train: Epoch[4/5]  [1870/3125]  eta: 0:07:31  Lr: 0.001875  Loss: -0.5535  Acc@1: 87.5000 (87.0056)  Acc@5: 100.0000 (98.6438)  time: 0.3583  data: 0.0012  max mem: 2501
Train: Epoch[4/5]  [1880/3125]  eta: 0:07:27  Lr: 0.001875  Loss: -0.3684  Acc@1: 81.2500 (86.9983)  Acc@5: 100.0000 (98.6477)  time: 0.3580  data: 0.0019  max mem: 2501
Train: Epoch[4/5]  [1890/3125]  eta: 0:07:24  Lr: 0.001875  Loss: -0.4106  Acc@1: 81.2500 (86.9943)  Acc@5: 100.0000 (98.6515)  time: 0.3630  data: 0.0012  max mem: 2501
Train: Epoch[4/5]  [1900/3125]  eta: 0:07:20  Lr: 0.001875  Loss: -0.6611  Acc@1: 87.5000 (87.0068)  Acc@5: 100.0000 (98.6553)  time: 0.3568  data: 0.0007  max mem: 2501
Train: Epoch[4/5]  [1910/3125]  eta: 0:07:16  Lr: 0.001875  Loss: -0.6505  Acc@1: 87.5000 (87.0225)  Acc@5: 100.0000 (98.6558)  time: 0.3524  data: 0.0011  max mem: 2501
Train: Epoch[4/5]  [1920/3125]  eta: 0:07:13  Lr: 0.001875  Loss: -0.3384  Acc@1: 81.2500 (87.0087)  Acc@5: 100.0000 (98.6530)  time: 0.3656  data: 0.0012  max mem: 2501
Train: Epoch[4/5]  [1930/3125]  eta: 0:07:09  Lr: 0.001875  Loss: -0.5205  Acc@1: 87.5000 (86.9918)  Acc@5: 100.0000 (98.6471)  time: 0.3664  data: 0.0012  max mem: 2501
Train: Epoch[4/5]  [1940/3125]  eta: 0:07:06  Lr: 0.001875  Loss: -0.4721  Acc@1: 87.5000 (86.9816)  Acc@5: 100.0000 (98.6444)  time: 0.3568  data: 0.0018  max mem: 2501
Train: Epoch[4/5]  [1950/3125]  eta: 0:07:02  Lr: 0.001875  Loss: -0.3469  Acc@1: 87.5000 (86.9522)  Acc@5: 100.0000 (98.6481)  time: 0.3549  data: 0.0014  max mem: 2501
Train: Epoch[4/5]  [1960/3125]  eta: 0:06:59  Lr: 0.001875  Loss: -0.3860  Acc@1: 87.5000 (86.9741)  Acc@5: 100.0000 (98.6550)  time: 0.3602  data: 0.0005  max mem: 2501
Train: Epoch[4/5]  [1970/3125]  eta: 0:06:55  Lr: 0.001875  Loss: -0.0550  Acc@1: 87.5000 (86.9451)  Acc@5: 100.0000 (98.6555)  time: 0.3583  data: 0.0005  max mem: 2501
Train: Epoch[4/5]  [1980/3125]  eta: 0:06:51  Lr: 0.001875  Loss: -0.3191  Acc@1: 87.5000 (86.9573)  Acc@5: 100.0000 (98.6591)  time: 0.3582  data: 0.0004  max mem: 2501
Train: Epoch[4/5]  [1990/3125]  eta: 0:06:48  Lr: 0.001875  Loss: -0.1395  Acc@1: 87.5000 (86.9601)  Acc@5: 100.0000 (98.6596)  time: 0.3601  data: 0.0005  max mem: 2501
Train: Epoch[4/5]  [2000/3125]  eta: 0:06:44  Lr: 0.001875  Loss: -0.5210  Acc@1: 87.5000 (86.9659)  Acc@5: 100.0000 (98.6600)  time: 0.3550  data: 0.0006  max mem: 2501
Train: Epoch[4/5]  [2010/3125]  eta: 0:06:41  Lr: 0.001875  Loss: -0.5489  Acc@1: 87.5000 (86.9841)  Acc@5: 100.0000 (98.6636)  time: 0.3624  data: 0.0009  max mem: 2501
Train: Epoch[4/5]  [2020/3125]  eta: 0:06:37  Lr: 0.001875  Loss: -0.3665  Acc@1: 87.5000 (86.9557)  Acc@5: 100.0000 (98.6609)  time: 0.3685  data: 0.0009  max mem: 2501
Train: Epoch[4/5]  [2030/3125]  eta: 0:06:33  Lr: 0.001875  Loss: -0.3966  Acc@1: 87.5000 (86.9738)  Acc@5: 100.0000 (98.6645)  time: 0.3559  data: 0.0006  max mem: 2501
Train: Epoch[4/5]  [2040/3125]  eta: 0:06:30  Lr: 0.001875  Loss: -0.4007  Acc@1: 87.5000 (86.9794)  Acc@5: 100.0000 (98.6587)  time: 0.3525  data: 0.0008  max mem: 2501
Train: Epoch[4/5]  [2050/3125]  eta: 0:06:26  Lr: 0.001875  Loss: -0.2237  Acc@1: 87.5000 (86.9759)  Acc@5: 100.0000 (98.6592)  time: 0.3615  data: 0.0008  max mem: 2501
Train: Epoch[4/5]  [2060/3125]  eta: 0:06:23  Lr: 0.001875  Loss: -0.5142  Acc@1: 87.5000 (86.9936)  Acc@5: 100.0000 (98.6596)  time: 0.3583  data: 0.0005  max mem: 2501
Train: Epoch[4/5]  [2070/3125]  eta: 0:06:19  Lr: 0.001875  Loss: -0.7049  Acc@1: 87.5000 (86.9990)  Acc@5: 100.0000 (98.6570)  time: 0.3566  data: 0.0005  max mem: 2501
Train: Epoch[4/5]  [2080/3125]  eta: 0:06:15  Lr: 0.001875  Loss: -0.2253  Acc@1: 87.5000 (86.9984)  Acc@5: 100.0000 (98.6575)  time: 0.3604  data: 0.0004  max mem: 2501
Train: Epoch[4/5]  [2090/3125]  eta: 0:06:12  Lr: 0.001875  Loss: 0.0943  Acc@1: 87.5000 (87.0008)  Acc@5: 100.0000 (98.6549)  time: 0.3557  data: 0.0005  max mem: 2501
Train: Epoch[4/5]  [2100/3125]  eta: 0:06:08  Lr: 0.001875  Loss: -0.3338  Acc@1: 87.5000 (87.0121)  Acc@5: 100.0000 (98.6554)  time: 0.3578  data: 0.0010  max mem: 2501
Train: Epoch[4/5]  [2110/3125]  eta: 0:06:05  Lr: 0.001875  Loss: -0.1787  Acc@1: 87.5000 (87.0085)  Acc@5: 100.0000 (98.6529)  time: 0.3616  data: 0.0020  max mem: 2501
Train: Epoch[4/5]  [2120/3125]  eta: 0:06:01  Lr: 0.001875  Loss: -0.2948  Acc@1: 87.5000 (87.0079)  Acc@5: 100.0000 (98.6475)  time: 0.3635  data: 0.0021  max mem: 2501
Train: Epoch[4/5]  [2130/3125]  eta: 0:05:57  Lr: 0.001875  Loss: -0.5192  Acc@1: 81.2500 (86.9897)  Acc@5: 100.0000 (98.6391)  time: 0.3598  data: 0.0010  max mem: 2501
Train: Epoch[4/5]  [2140/3125]  eta: 0:05:54  Lr: 0.001875  Loss: -0.4679  Acc@1: 87.5000 (86.9921)  Acc@5: 100.0000 (98.6397)  time: 0.3569  data: 0.0005  max mem: 2501
Train: Epoch[4/5]  [2150/3125]  eta: 0:05:50  Lr: 0.001875  Loss: 0.0003  Acc@1: 87.5000 (87.0031)  Acc@5: 100.0000 (98.6431)  time: 0.3608  data: 0.0006  max mem: 2501
Train: Epoch[4/5]  [2160/3125]  eta: 0:05:47  Lr: 0.001875  Loss: -0.3673  Acc@1: 87.5000 (87.0170)  Acc@5: 100.0000 (98.6465)  time: 0.3561  data: 0.0006  max mem: 2501
Train: Epoch[4/5]  [2170/3125]  eta: 0:05:43  Lr: 0.001875  Loss: -0.3695  Acc@1: 87.5000 (87.0221)  Acc@5: 100.0000 (98.6469)  time: 0.3633  data: 0.0005  max mem: 2501
Train: Epoch[4/5]  [2180/3125]  eta: 0:05:39  Lr: 0.001875  Loss: -0.0609  Acc@1: 87.5000 (87.0272)  Acc@5: 100.0000 (98.6474)  time: 0.3608  data: 0.0005  max mem: 2501
Train: Epoch[4/5]  [2190/3125]  eta: 0:05:36  Lr: 0.001875  Loss: -0.5660  Acc@1: 87.5000 (87.0407)  Acc@5: 100.0000 (98.6507)  time: 0.3517  data: 0.0005  max mem: 2501
Train: Epoch[4/5]  [2200/3125]  eta: 0:05:32  Lr: 0.001875  Loss: -0.2367  Acc@1: 87.5000 (87.0542)  Acc@5: 100.0000 (98.6512)  time: 0.3615  data: 0.0006  max mem: 2501
Train: Epoch[4/5]  [2210/3125]  eta: 0:05:29  Lr: 0.001875  Loss: -0.5636  Acc@1: 93.7500 (87.0703)  Acc@5: 100.0000 (98.6573)  time: 0.3660  data: 0.0007  max mem: 2501
Train: Epoch[4/5]  [2220/3125]  eta: 0:05:25  Lr: 0.001875  Loss: -0.2819  Acc@1: 87.5000 (87.0554)  Acc@5: 100.0000 (98.6521)  time: 0.3568  data: 0.0007  max mem: 2501
Train: Epoch[4/5]  [2230/3125]  eta: 0:05:21  Lr: 0.001875  Loss: -0.5022  Acc@1: 87.5000 (87.0574)  Acc@5: 100.0000 (98.6525)  time: 0.3544  data: 0.0006  max mem: 2501
Train: Epoch[4/5]  [2240/3125]  eta: 0:05:18  Lr: 0.001875  Loss: -0.5392  Acc@1: 87.5000 (87.0566)  Acc@5: 100.0000 (98.6585)  time: 0.3632  data: 0.0006  max mem: 2501
Train: Epoch[4/5]  [2250/3125]  eta: 0:05:14  Lr: 0.001875  Loss: -0.5355  Acc@1: 87.5000 (87.0530)  Acc@5: 100.0000 (98.6562)  time: 0.3585  data: 0.0006  max mem: 2501
Train: Epoch[4/5]  [2260/3125]  eta: 0:05:11  Lr: 0.001875  Loss: -0.1115  Acc@1: 87.5000 (87.0439)  Acc@5: 100.0000 (98.6538)  time: 0.3548  data: 0.0006  max mem: 2501
Train: Epoch[4/5]  [2270/3125]  eta: 0:05:07  Lr: 0.001875  Loss: -0.3973  Acc@1: 87.5000 (87.0624)  Acc@5: 100.0000 (98.6570)  time: 0.3593  data: 0.0005  max mem: 2501
Train: Epoch[4/5]  [2280/3125]  eta: 0:05:03  Lr: 0.001875  Loss: -0.2052  Acc@1: 93.7500 (87.0890)  Acc@5: 100.0000 (98.6574)  time: 0.3531  data: 0.0005  max mem: 2501
Train: Epoch[4/5]  [2290/3125]  eta: 0:05:00  Lr: 0.001875  Loss: -0.4144  Acc@1: 93.7500 (87.1017)  Acc@5: 100.0000 (98.6578)  time: 0.3524  data: 0.0005  max mem: 2501
Train: Epoch[4/5]  [2300/3125]  eta: 0:04:56  Lr: 0.001875  Loss: -0.3628  Acc@1: 87.5000 (87.1116)  Acc@5: 100.0000 (98.6582)  time: 0.3657  data: 0.0007  max mem: 2501
Train: Epoch[4/5]  [2310/3125]  eta: 0:04:53  Lr: 0.001875  Loss: -0.4530  Acc@1: 87.5000 (87.1079)  Acc@5: 100.0000 (98.6559)  time: 0.3685  data: 0.0010  max mem: 2501
Train: Epoch[4/5]  [2320/3125]  eta: 0:04:49  Lr: 0.001875  Loss: 0.2511  Acc@1: 87.5000 (87.1069)  Acc@5: 100.0000 (98.6536)  time: 0.3553  data: 0.0016  max mem: 2501
Train: Epoch[4/5]  [2330/3125]  eta: 0:04:45  Lr: 0.001875  Loss: -0.6062  Acc@1: 87.5000 (87.1193)  Acc@5: 100.0000 (98.6513)  time: 0.3514  data: 0.0014  max mem: 2501
Train: Epoch[4/5]  [2340/3125]  eta: 0:04:42  Lr: 0.001875  Loss: 0.3910  Acc@1: 87.5000 (87.0995)  Acc@5: 100.0000 (98.6437)  time: 0.3622  data: 0.0007  max mem: 2501
Train: Epoch[4/5]  [2350/3125]  eta: 0:04:38  Lr: 0.001875  Loss: -0.3374  Acc@1: 87.5000 (87.1119)  Acc@5: 100.0000 (98.6442)  time: 0.3577  data: 0.0014  max mem: 2501
Train: Epoch[4/5]  [2360/3125]  eta: 0:04:35  Lr: 0.001875  Loss: -0.2965  Acc@1: 87.5000 (87.1188)  Acc@5: 100.0000 (98.6446)  time: 0.3526  data: 0.0015  max mem: 2501
Train: Epoch[4/5]  [2370/3125]  eta: 0:04:31  Lr: 0.001875  Loss: -0.1370  Acc@1: 87.5000 (87.1178)  Acc@5: 100.0000 (98.6398)  time: 0.3630  data: 0.0011  max mem: 2501
Train: Epoch[4/5]  [2380/3125]  eta: 0:04:27  Lr: 0.001875  Loss: -0.5267  Acc@1: 87.5000 (87.1141)  Acc@5: 100.0000 (98.6429)  time: 0.3576  data: 0.0009  max mem: 2501
Train: Epoch[4/5]  [2390/3125]  eta: 0:04:24  Lr: 0.001875  Loss: -0.0668  Acc@1: 87.5000 (87.1131)  Acc@5: 100.0000 (98.6460)  time: 0.3522  data: 0.0006  max mem: 2501
Train: Epoch[4/5]  [2400/3125]  eta: 0:04:20  Lr: 0.001875  Loss: -0.5035  Acc@1: 87.5000 (87.1069)  Acc@5: 100.0000 (98.6438)  time: 0.3648  data: 0.0006  max mem: 2501
Train: Epoch[4/5]  [2410/3125]  eta: 0:04:17  Lr: 0.001875  Loss: -0.1449  Acc@1: 87.5000 (87.1112)  Acc@5: 100.0000 (98.6468)  time: 0.3722  data: 0.0011  max mem: 2501
Train: Epoch[4/5]  [2420/3125]  eta: 0:04:13  Lr: 0.001875  Loss: -0.2155  Acc@1: 87.5000 (87.1050)  Acc@5: 100.0000 (98.6498)  time: 0.3587  data: 0.0010  max mem: 2501
Train: Epoch[4/5]  [2430/3125]  eta: 0:04:09  Lr: 0.001875  Loss: -0.1746  Acc@1: 87.5000 (87.1169)  Acc@5: 100.0000 (98.6554)  time: 0.3524  data: 0.0004  max mem: 2501
Train: Epoch[4/5]  [2440/3125]  eta: 0:04:06  Lr: 0.001875  Loss: -0.5023  Acc@1: 87.5000 (87.1134)  Acc@5: 100.0000 (98.6558)  time: 0.3651  data: 0.0005  max mem: 2501
Train: Epoch[4/5]  [2450/3125]  eta: 0:04:02  Lr: 0.001875  Loss: -0.4512  Acc@1: 87.5000 (87.1201)  Acc@5: 100.0000 (98.6613)  time: 0.3595  data: 0.0007  max mem: 2501
Train: Epoch[4/5]  [2460/3125]  eta: 0:03:59  Lr: 0.001875  Loss: -0.2256  Acc@1: 87.5000 (87.1114)  Acc@5: 100.0000 (98.6616)  time: 0.3530  data: 0.0007  max mem: 2501
Train: Epoch[4/5]  [2470/3125]  eta: 0:03:55  Lr: 0.001875  Loss: -0.5533  Acc@1: 87.5000 (87.1206)  Acc@5: 100.0000 (98.6645)  time: 0.3608  data: 0.0005  max mem: 2501
Train: Epoch[4/5]  [2480/3125]  eta: 0:03:51  Lr: 0.001875  Loss: -0.3993  Acc@1: 87.5000 (87.1095)  Acc@5: 100.0000 (98.6573)  time: 0.3561  data: 0.0005  max mem: 2501
Train: Epoch[4/5]  [2490/3125]  eta: 0:03:48  Lr: 0.001875  Loss: -0.1673  Acc@1: 87.5000 (87.1211)  Acc@5: 100.0000 (98.6602)  time: 0.3532  data: 0.0011  max mem: 2501
Train: Epoch[4/5]  [2500/3125]  eta: 0:03:44  Lr: 0.001875  Loss: -0.1244  Acc@1: 87.5000 (87.1227)  Acc@5: 100.0000 (98.6655)  time: 0.3698  data: 0.0011  max mem: 2501
Train: Epoch[4/5]  [2510/3125]  eta: 0:03:41  Lr: 0.001875  Loss: -0.5865  Acc@1: 87.5000 (87.1341)  Acc@5: 100.0000 (98.6609)  time: 0.3650  data: 0.0006  max mem: 2501
Train: Epoch[4/5]  [2520/3125]  eta: 0:03:37  Lr: 0.001875  Loss: -0.2703  Acc@1: 93.7500 (87.1380)  Acc@5: 100.0000 (98.6588)  time: 0.3518  data: 0.0007  max mem: 2501
Train: Epoch[4/5]  [2530/3125]  eta: 0:03:33  Lr: 0.001875  Loss: -0.4999  Acc@1: 87.5000 (87.1444)  Acc@5: 100.0000 (98.6641)  time: 0.3628  data: 0.0008  max mem: 2501
Train: Epoch[4/5]  [2540/3125]  eta: 0:03:30  Lr: 0.001875  Loss: -0.6549  Acc@1: 87.5000 (87.1532)  Acc@5: 100.0000 (98.6570)  time: 0.3607  data: 0.0007  max mem: 2501
Train: Epoch[4/5]  [2550/3125]  eta: 0:03:26  Lr: 0.001875  Loss: 0.0240  Acc@1: 87.5000 (87.1668)  Acc@5: 100.0000 (98.6549)  time: 0.3555  data: 0.0005  max mem: 2501
Train: Epoch[4/5]  [2560/3125]  eta: 0:03:23  Lr: 0.001875  Loss: -0.3819  Acc@1: 87.5000 (87.1705)  Acc@5: 100.0000 (98.6578)  time: 0.3602  data: 0.0005  max mem: 2501
Train: Epoch[4/5]  [2570/3125]  eta: 0:03:19  Lr: 0.001875  Loss: -0.5498  Acc@1: 87.5000 (87.1791)  Acc@5: 100.0000 (98.6557)  time: 0.3565  data: 0.0009  max mem: 2501
Train: Epoch[4/5]  [2580/3125]  eta: 0:03:15  Lr: 0.001875  Loss: -0.0829  Acc@1: 87.5000 (87.1682)  Acc@5: 100.0000 (98.6536)  time: 0.3566  data: 0.0008  max mem: 2501
Train: Epoch[4/5]  [2590/3125]  eta: 0:03:12  Lr: 0.001875  Loss: -0.2611  Acc@1: 87.5000 (87.1695)  Acc@5: 100.0000 (98.6516)  time: 0.3692  data: 0.0004  max mem: 2501
Train: Epoch[4/5]  [2600/3125]  eta: 0:03:08  Lr: 0.001875  Loss: -0.1341  Acc@1: 87.5000 (87.1708)  Acc@5: 100.0000 (98.6568)  time: 0.3633  data: 0.0006  max mem: 2501
Train: Epoch[4/5]  [2610/3125]  eta: 0:03:05  Lr: 0.001875  Loss: -0.5692  Acc@1: 87.5000 (87.1792)  Acc@5: 100.0000 (98.6523)  time: 0.3531  data: 0.0007  max mem: 2501
Train: Epoch[4/5]  [2620/3125]  eta: 0:03:01  Lr: 0.001875  Loss: -0.1265  Acc@1: 87.5000 (87.1900)  Acc@5: 100.0000 (98.6551)  time: 0.3628  data: 0.0007  max mem: 2501
Train: Epoch[4/5]  [2630/3125]  eta: 0:02:57  Lr: 0.001875  Loss: -0.1748  Acc@1: 87.5000 (87.1912)  Acc@5: 100.0000 (98.6555)  time: 0.3583  data: 0.0008  max mem: 2501
Train: Epoch[4/5]  [2640/3125]  eta: 0:02:54  Lr: 0.001875  Loss: -0.5384  Acc@1: 93.7500 (87.2113)  Acc@5: 100.0000 (98.6582)  time: 0.3541  data: 0.0006  max mem: 2501
Train: Epoch[4/5]  [2650/3125]  eta: 0:02:50  Lr: 0.001875  Loss: -0.5838  Acc@1: 87.5000 (87.2077)  Acc@5: 100.0000 (98.6538)  time: 0.3636  data: 0.0005  max mem: 2501
Train: Epoch[4/5]  [2660/3125]  eta: 0:02:47  Lr: 0.001875  Loss: -0.5554  Acc@1: 87.5000 (87.2228)  Acc@5: 100.0000 (98.6565)  time: 0.3588  data: 0.0007  max mem: 2501
Train: Epoch[4/5]  [2670/3125]  eta: 0:02:43  Lr: 0.001875  Loss: -0.5608  Acc@1: 87.5000 (87.2028)  Acc@5: 100.0000 (98.6569)  time: 0.3543  data: 0.0006  max mem: 2501
Train: Epoch[4/5]  [2680/3125]  eta: 0:02:40  Lr: 0.001875  Loss: 0.5275  Acc@1: 81.2500 (87.1993)  Acc@5: 100.0000 (98.6549)  time: 0.3635  data: 0.0006  max mem: 2501
Train: Epoch[4/5]  [2690/3125]  eta: 0:02:36  Lr: 0.001875  Loss: -0.0640  Acc@1: 87.5000 (87.2027)  Acc@5: 100.0000 (98.6576)  time: 0.3678  data: 0.0007  max mem: 2501
Train: Epoch[4/5]  [2700/3125]  eta: 0:02:32  Lr: 0.001875  Loss: -0.6501  Acc@1: 87.5000 (87.1969)  Acc@5: 100.0000 (98.6556)  time: 0.3592  data: 0.0011  max mem: 2501
Train: Epoch[4/5]  [2710/3125]  eta: 0:02:29  Lr: 0.001875  Loss: -0.3567  Acc@1: 87.5000 (87.1980)  Acc@5: 100.0000 (98.6559)  time: 0.3554  data: 0.0011  max mem: 2501
Train: Epoch[4/5]  [2720/3125]  eta: 0:02:25  Lr: 0.001875  Loss: -0.1626  Acc@1: 87.5000 (87.1991)  Acc@5: 100.0000 (98.6517)  time: 0.3625  data: 0.0006  max mem: 2501
Train: Epoch[4/5]  [2730/3125]  eta: 0:02:22  Lr: 0.001875  Loss: -0.4723  Acc@1: 93.7500 (87.2139)  Acc@5: 100.0000 (98.6543)  time: 0.3568  data: 0.0005  max mem: 2501
Train: Epoch[4/5]  [2740/3125]  eta: 0:02:18  Lr: 0.001875  Loss: -0.3469  Acc@1: 93.7500 (87.2287)  Acc@5: 100.0000 (98.6501)  time: 0.3537  data: 0.0005  max mem: 2501
Train: Epoch[4/5]  [2750/3125]  eta: 0:02:14  Lr: 0.001875  Loss: -0.3423  Acc@1: 87.5000 (87.2183)  Acc@5: 100.0000 (98.6528)  time: 0.3632  data: 0.0006  max mem: 2501
Train: Epoch[4/5]  [2760/3125]  eta: 0:02:11  Lr: 0.001875  Loss: -0.0955  Acc@1: 81.2500 (87.1989)  Acc@5: 100.0000 (98.6486)  time: 0.3588  data: 0.0005  max mem: 2501
Train: Epoch[4/5]  [2770/3125]  eta: 0:02:07  Lr: 0.001875  Loss: -0.1977  Acc@1: 87.5000 (87.2045)  Acc@5: 100.0000 (98.6535)  time: 0.3546  data: 0.0007  max mem: 2501
Train: Epoch[4/5]  [2780/3125]  eta: 0:02:04  Lr: 0.001875  Loss: -0.3581  Acc@1: 87.5000 (87.1966)  Acc@5: 100.0000 (98.6471)  time: 0.3614  data: 0.0009  max mem: 2501
Train: Epoch[4/5]  [2790/3125]  eta: 0:02:00  Lr: 0.001875  Loss: -0.3276  Acc@1: 87.5000 (87.1910)  Acc@5: 100.0000 (98.6430)  time: 0.3658  data: 0.0013  max mem: 2501
Train: Epoch[4/5]  [2800/3125]  eta: 0:01:56  Lr: 0.001875  Loss: -0.2087  Acc@1: 93.7500 (87.2055)  Acc@5: 100.0000 (98.6433)  time: 0.3588  data: 0.0018  max mem: 2501
Train: Epoch[4/5]  [2810/3125]  eta: 0:01:53  Lr: 0.001875  Loss: -0.4603  Acc@1: 93.7500 (87.2154)  Acc@5: 100.0000 (98.6437)  time: 0.3539  data: 0.0012  max mem: 2501
Train: Epoch[4/5]  [2820/3125]  eta: 0:01:49  Lr: 0.001875  Loss: -0.0802  Acc@1: 87.5000 (87.2275)  Acc@5: 100.0000 (98.6463)  time: 0.3624  data: 0.0005  max mem: 2501
Train: Epoch[4/5]  [2830/3125]  eta: 0:01:46  Lr: 0.001875  Loss: -0.4080  Acc@1: 87.5000 (87.2307)  Acc@5: 100.0000 (98.6445)  time: 0.3580  data: 0.0005  max mem: 2501
Train: Epoch[4/5]  [2840/3125]  eta: 0:01:42  Lr: 0.001875  Loss: -0.1957  Acc@1: 87.5000 (87.2382)  Acc@5: 100.0000 (98.6448)  time: 0.3534  data: 0.0005  max mem: 2501
Train: Epoch[4/5]  [2850/3125]  eta: 0:01:38  Lr: 0.001875  Loss: -0.4698  Acc@1: 87.5000 (87.2413)  Acc@5: 100.0000 (98.6474)  time: 0.3587  data: 0.0005  max mem: 2501
Train: Epoch[4/5]  [2860/3125]  eta: 0:01:35  Lr: 0.001875  Loss: -0.5799  Acc@1: 87.5000 (87.2466)  Acc@5: 100.0000 (98.6499)  time: 0.3563  data: 0.0012  max mem: 2501
Train: Epoch[4/5]  [2870/3125]  eta: 0:01:31  Lr: 0.001875  Loss: -0.6492  Acc@1: 87.5000 (87.2540)  Acc@5: 100.0000 (98.6503)  time: 0.3582  data: 0.0012  max mem: 2501
Train: Epoch[4/5]  [2880/3125]  eta: 0:01:28  Lr: 0.001875  Loss: -0.0186  Acc@1: 87.5000 (87.2570)  Acc@5: 100.0000 (98.6485)  time: 0.3721  data: 0.0015  max mem: 2501
Train: Epoch[4/5]  [2890/3125]  eta: 0:01:24  Lr: 0.001875  Loss: -0.4220  Acc@1: 87.5000 (87.2665)  Acc@5: 100.0000 (98.6531)  time: 0.3661  data: 0.0016  max mem: 2501
Train: Epoch[4/5]  [2900/3125]  eta: 0:01:20  Lr: 0.001875  Loss: 0.5810  Acc@1: 87.5000 (87.2738)  Acc@5: 100.0000 (98.6535)  time: 0.3528  data: 0.0014  max mem: 2501
Train: Epoch[4/5]  [2910/3125]  eta: 0:01:17  Lr: 0.001875  Loss: -0.5552  Acc@1: 87.5000 (87.2638)  Acc@5: 100.0000 (98.6560)  time: 0.3611  data: 0.0015  max mem: 2501
Train: Epoch[4/5]  [2920/3125]  eta: 0:01:13  Lr: 0.001875  Loss: -0.6992  Acc@1: 87.5000 (87.2625)  Acc@5: 100.0000 (98.6563)  time: 0.3574  data: 0.0012  max mem: 2501
Train: Epoch[4/5]  [2930/3125]  eta: 0:01:10  Lr: 0.001875  Loss: -0.2816  Acc@1: 81.2500 (87.2462)  Acc@5: 100.0000 (98.6545)  time: 0.3535  data: 0.0010  max mem: 2501
Train: Epoch[4/5]  [2940/3125]  eta: 0:01:06  Lr: 0.001875  Loss: -0.3127  Acc@1: 87.5000 (87.2365)  Acc@5: 100.0000 (98.6569)  time: 0.3617  data: 0.0005  max mem: 2501
Train: Epoch[4/5]  [2950/3125]  eta: 0:01:02  Lr: 0.001875  Loss: -0.1209  Acc@1: 87.5000 (87.2353)  Acc@5: 100.0000 (98.6488)  time: 0.3554  data: 0.0006  max mem: 2501
Train: Epoch[4/5]  [2960/3125]  eta: 0:00:59  Lr: 0.001875  Loss: -0.4830  Acc@1: 93.7500 (87.2425)  Acc@5: 100.0000 (98.6533)  time: 0.3531  data: 0.0006  max mem: 2501
Train: Epoch[4/5]  [2970/3125]  eta: 0:00:55  Lr: 0.001875  Loss: -0.2992  Acc@1: 93.7500 (87.2560)  Acc@5: 100.0000 (98.6558)  time: 0.3625  data: 0.0011  max mem: 2501
Train: Epoch[4/5]  [2980/3125]  eta: 0:00:52  Lr: 0.001875  Loss: 0.1553  Acc@1: 87.5000 (87.2484)  Acc@5: 100.0000 (98.6519)  time: 0.3654  data: 0.0012  max mem: 2501
Train: Epoch[4/5]  [2990/3125]  eta: 0:00:48  Lr: 0.001875  Loss: -0.4442  Acc@1: 87.5000 (87.2513)  Acc@5: 100.0000 (98.6522)  time: 0.3566  data: 0.0008  max mem: 2501
Train: Epoch[4/5]  [3000/3125]  eta: 0:00:44  Lr: 0.001875  Loss: -0.3901  Acc@1: 87.5000 (87.2605)  Acc@5: 100.0000 (98.6484)  time: 0.3541  data: 0.0008  max mem: 2501
Train: Epoch[4/5]  [3010/3125]  eta: 0:00:41  Lr: 0.001875  Loss: -0.1901  Acc@1: 87.5000 (87.2634)  Acc@5: 100.0000 (98.6508)  time: 0.3625  data: 0.0007  max mem: 2501
Train: Epoch[4/5]  [3020/3125]  eta: 0:00:37  Lr: 0.001875  Loss: -0.6931  Acc@1: 87.5000 (87.2621)  Acc@5: 100.0000 (98.6532)  time: 0.3569  data: 0.0005  max mem: 2501
Train: Epoch[4/5]  [3030/3125]  eta: 0:00:34  Lr: 0.001875  Loss: -0.4868  Acc@1: 87.5000 (87.2670)  Acc@5: 100.0000 (98.6514)  time: 0.3537  data: 0.0005  max mem: 2501
Train: Epoch[4/5]  [3040/3125]  eta: 0:00:30  Lr: 0.001875  Loss: -0.3025  Acc@1: 87.5000 (87.2657)  Acc@5: 100.0000 (98.6456)  time: 0.3627  data: 0.0007  max mem: 2501
Train: Epoch[4/5]  [3050/3125]  eta: 0:00:26  Lr: 0.001875  Loss: -0.4213  Acc@1: 87.5000 (87.2706)  Acc@5: 100.0000 (98.6418)  time: 0.3588  data: 0.0006  max mem: 2501
Train: Epoch[4/5]  [3060/3125]  eta: 0:00:23  Lr: 0.001875  Loss: -0.1895  Acc@1: 87.5000 (87.2672)  Acc@5: 100.0000 (98.6422)  time: 0.3547  data: 0.0005  max mem: 2501
Train: Epoch[4/5]  [3070/3125]  eta: 0:00:19  Lr: 0.001875  Loss: -0.3786  Acc@1: 87.5000 (87.2741)  Acc@5: 100.0000 (98.6446)  time: 0.3627  data: 0.0007  max mem: 2501
Train: Epoch[4/5]  [3080/3125]  eta: 0:00:16  Lr: 0.001875  Loss: -0.4849  Acc@1: 87.5000 (87.2789)  Acc@5: 100.0000 (98.6469)  time: 0.3658  data: 0.0009  max mem: 2501
Train: Epoch[4/5]  [3090/3125]  eta: 0:00:12  Lr: 0.001875  Loss: -0.2871  Acc@1: 87.5000 (87.2897)  Acc@5: 100.0000 (98.6453)  time: 0.3572  data: 0.0007  max mem: 2501
Train: Epoch[4/5]  [3100/3125]  eta: 0:00:08  Lr: 0.001875  Loss: -0.3589  Acc@1: 87.5000 (87.2823)  Acc@5: 100.0000 (98.6456)  time: 0.3553  data: 0.0005  max mem: 2501
Train: Epoch[4/5]  [3110/3125]  eta: 0:00:05  Lr: 0.001875  Loss: -0.2878  Acc@1: 87.5000 (87.2830)  Acc@5: 100.0000 (98.6459)  time: 0.3597  data: 0.0005  max mem: 2501
Train: Epoch[4/5]  [3120/3125]  eta: 0:00:01  Lr: 0.001875  Loss: -0.3765  Acc@1: 87.5000 (87.2917)  Acc@5: 100.0000 (98.6443)  time: 0.3574  data: 0.0011  max mem: 2501
Train: Epoch[4/5]  [3124/3125]  eta: 0:00:00  Lr: 0.001875  Loss: -0.4919  Acc@1: 87.5000 (87.2940)  Acc@5: 100.0000 (98.6440)  time: 0.3538  data: 0.0010  max mem: 2501
Train: Epoch[4/5] Total time: 0:18:44 (0.3597 s / it)
{0: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 1: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 2: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 3: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 4: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 5: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 6: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 7: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 8: {0: 0, 1: 0, 2: 200000, 3: 0, 4: 0}, 9: {0: 0, 1: 0, 2: 200000, 3: 0, 4: 0}, 10: {0: 0, 1: 0, 2: 200000, 3: 0, 4: 0}, 11: {0: 0, 1: 0, 2: 200000, 3: 0, 4: 0}, 12: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 13: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 14: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 15: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 16: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 17: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 18: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 19: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}}
Averaged stats: Lr: 0.001875  Loss: -0.4919  Acc@1: 87.5000 (87.2940)  Acc@5: 100.0000 (98.6440)
Train: Epoch[5/5]  [   0/3125]  eta: 0:43:12  Lr: 0.001875  Loss: -0.2399  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (100.0000)  time: 0.8297  data: 0.4673  max mem: 2501
Train: Epoch[5/5]  [  10/3125]  eta: 0:21:12  Lr: 0.001875  Loss: 0.3543  Acc@1: 87.5000 (82.9545)  Acc@5: 100.0000 (97.7273)  time: 0.4084  data: 0.0437  max mem: 2501
Train: Epoch[5/5]  [  20/3125]  eta: 0:19:45  Lr: 0.001875  Loss: -0.1088  Acc@1: 87.5000 (85.7143)  Acc@5: 100.0000 (97.6190)  time: 0.3595  data: 0.0015  max mem: 2501
Train: Epoch[5/5]  [  30/3125]  eta: 0:19:21  Lr: 0.001875  Loss: -0.5137  Acc@1: 87.5000 (87.7016)  Acc@5: 100.0000 (98.3871)  time: 0.3568  data: 0.0011  max mem: 2501
Train: Epoch[5/5]  [  40/3125]  eta: 0:19:13  Lr: 0.001875  Loss: -0.5263  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (98.4756)  time: 0.3653  data: 0.0009  max mem: 2501
Train: Epoch[5/5]  [  50/3125]  eta: 0:19:00  Lr: 0.001875  Loss: -0.3233  Acc@1: 87.5000 (87.2549)  Acc@5: 100.0000 (98.6520)  time: 0.3641  data: 0.0011  max mem: 2501
Train: Epoch[5/5]  [  60/3125]  eta: 0:18:46  Lr: 0.001875  Loss: -0.7046  Acc@1: 87.5000 (87.7049)  Acc@5: 100.0000 (98.5656)  time: 0.3549  data: 0.0008  max mem: 2501
Train: Epoch[5/5]  [  70/3125]  eta: 0:18:44  Lr: 0.001875  Loss: -0.2336  Acc@1: 87.5000 (87.9401)  Acc@5: 100.0000 (98.7676)  time: 0.3606  data: 0.0009  max mem: 2501
Train: Epoch[5/5]  [  80/3125]  eta: 0:18:31  Lr: 0.001875  Loss: -0.5965  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (98.5340)  time: 0.3577  data: 0.0008  max mem: 2501
Train: Epoch[5/5]  [  90/3125]  eta: 0:18:26  Lr: 0.001875  Loss: -0.3812  Acc@1: 87.5000 (87.7060)  Acc@5: 100.0000 (98.5577)  time: 0.3520  data: 0.0010  max mem: 2501
Train: Epoch[5/5]  [ 100/3125]  eta: 0:18:22  Lr: 0.001875  Loss: -0.5622  Acc@1: 87.5000 (88.0569)  Acc@5: 100.0000 (98.6386)  time: 0.3613  data: 0.0010  max mem: 2501
Train: Epoch[5/5]  [ 110/3125]  eta: 0:18:14  Lr: 0.001875  Loss: -0.6711  Acc@1: 93.7500 (88.4009)  Acc@5: 100.0000 (98.5923)  time: 0.3569  data: 0.0005  max mem: 2501
Train: Epoch[5/5]  [ 120/3125]  eta: 0:18:10  Lr: 0.001875  Loss: -0.1773  Acc@1: 87.5000 (88.3264)  Acc@5: 100.0000 (98.6054)  time: 0.3558  data: 0.0013  max mem: 2501
Train: Epoch[5/5]  [ 130/3125]  eta: 0:18:10  Lr: 0.001875  Loss: -0.5726  Acc@1: 87.5000 (88.5496)  Acc@5: 100.0000 (98.6641)  time: 0.3699  data: 0.0020  max mem: 2501
Train: Epoch[5/5]  [ 140/3125]  eta: 0:18:05  Lr: 0.001875  Loss: 0.2372  Acc@1: 87.5000 (88.3422)  Acc@5: 100.0000 (98.6702)  time: 0.3669  data: 0.0011  max mem: 2501
Train: Epoch[5/5]  [ 150/3125]  eta: 0:17:59  Lr: 0.001875  Loss: -0.2556  Acc@1: 87.5000 (88.3278)  Acc@5: 100.0000 (98.7169)  time: 0.3555  data: 0.0005  max mem: 2501
Train: Epoch[5/5]  [ 160/3125]  eta: 0:17:57  Lr: 0.001875  Loss: -0.6663  Acc@1: 87.5000 (88.2764)  Acc@5: 100.0000 (98.6801)  time: 0.3620  data: 0.0006  max mem: 2501
Train: Epoch[5/5]  [ 170/3125]  eta: 0:17:51  Lr: 0.001875  Loss: -0.2608  Acc@1: 87.5000 (88.2310)  Acc@5: 100.0000 (98.7208)  time: 0.3593  data: 0.0009  max mem: 2501
Train: Epoch[5/5]  [ 180/3125]  eta: 0:17:46  Lr: 0.001875  Loss: -0.4186  Acc@1: 87.5000 (87.9834)  Acc@5: 100.0000 (98.6878)  time: 0.3517  data: 0.0007  max mem: 2501
Train: Epoch[5/5]  [ 190/3125]  eta: 0:17:43  Lr: 0.001875  Loss: -0.3255  Acc@1: 87.5000 (88.0236)  Acc@5: 100.0000 (98.7238)  time: 0.3613  data: 0.0008  max mem: 2501
Train: Epoch[5/5]  [ 200/3125]  eta: 0:17:37  Lr: 0.001875  Loss: -0.4212  Acc@1: 87.5000 (88.1530)  Acc@5: 100.0000 (98.7251)  time: 0.3582  data: 0.0008  max mem: 2501
Train: Epoch[5/5]  [ 210/3125]  eta: 0:17:34  Lr: 0.001875  Loss: -0.3527  Acc@1: 87.5000 (88.0036)  Acc@5: 100.0000 (98.7559)  time: 0.3537  data: 0.0006  max mem: 2501
Train: Epoch[5/5]  [ 220/3125]  eta: 0:17:33  Lr: 0.001875  Loss: -0.5832  Acc@1: 87.5000 (87.9242)  Acc@5: 100.0000 (98.7839)  time: 0.3730  data: 0.0007  max mem: 2501
Train: Epoch[5/5]  [ 230/3125]  eta: 0:17:28  Lr: 0.001875  Loss: -0.0799  Acc@1: 81.2500 (87.6623)  Acc@5: 100.0000 (98.7825)  time: 0.3669  data: 0.0007  max mem: 2501
Train: Epoch[5/5]  [ 240/3125]  eta: 0:17:24  Lr: 0.001875  Loss: -0.2624  Acc@1: 87.5000 (87.7334)  Acc@5: 100.0000 (98.8330)  time: 0.3534  data: 0.0014  max mem: 2501
Train: Epoch[5/5]  [ 250/3125]  eta: 0:17:20  Lr: 0.001875  Loss: -0.2638  Acc@1: 87.5000 (87.8237)  Acc@5: 100.0000 (98.8546)  time: 0.3625  data: 0.0014  max mem: 2501
Train: Epoch[5/5]  [ 260/3125]  eta: 0:17:16  Lr: 0.001875  Loss: -0.3542  Acc@1: 87.5000 (87.8352)  Acc@5: 100.0000 (98.8506)  time: 0.3578  data: 0.0006  max mem: 2501
Train: Epoch[5/5]  [ 270/3125]  eta: 0:17:12  Lr: 0.001875  Loss: 0.3222  Acc@1: 87.5000 (87.8690)  Acc@5: 100.0000 (98.8699)  time: 0.3541  data: 0.0007  max mem: 2501
Train: Epoch[5/5]  [ 280/3125]  eta: 0:17:08  Lr: 0.001875  Loss: -0.1907  Acc@1: 87.5000 (87.8336)  Acc@5: 100.0000 (98.8434)  time: 0.3603  data: 0.0008  max mem: 2501
Train: Epoch[5/5]  [ 290/3125]  eta: 0:17:04  Lr: 0.001875  Loss: -0.3730  Acc@1: 87.5000 (87.8651)  Acc@5: 100.0000 (98.8617)  time: 0.3580  data: 0.0007  max mem: 2501
Train: Epoch[5/5]  [ 300/3125]  eta: 0:17:00  Lr: 0.001875  Loss: -0.4592  Acc@1: 87.5000 (87.8322)  Acc@5: 100.0000 (98.7957)  time: 0.3574  data: 0.0007  max mem: 2501
Train: Epoch[5/5]  [ 310/3125]  eta: 0:16:56  Lr: 0.001875  Loss: -0.0922  Acc@1: 87.5000 (87.8818)  Acc@5: 100.0000 (98.7741)  time: 0.3612  data: 0.0013  max mem: 2501
Train: Epoch[5/5]  [ 320/3125]  eta: 0:16:54  Lr: 0.001875  Loss: -0.6357  Acc@1: 87.5000 (87.7726)  Acc@5: 100.0000 (98.7539)  time: 0.3669  data: 0.0019  max mem: 2501
Train: Epoch[5/5]  [ 330/3125]  eta: 0:16:49  Lr: 0.001875  Loss: 0.3816  Acc@1: 81.2500 (87.5944)  Acc@5: 100.0000 (98.6405)  time: 0.3620  data: 0.0012  max mem: 2501
Train: Epoch[5/5]  [ 340/3125]  eta: 0:16:46  Lr: 0.001875  Loss: -0.6599  Acc@1: 87.5000 (87.6100)  Acc@5: 100.0000 (98.6804)  time: 0.3568  data: 0.0006  max mem: 2501
Train: Epoch[5/5]  [ 350/3125]  eta: 0:16:43  Lr: 0.001875  Loss: -0.5017  Acc@1: 87.5000 (87.5890)  Acc@5: 100.0000 (98.6645)  time: 0.3642  data: 0.0008  max mem: 2501
Train: Epoch[5/5]  [ 360/3125]  eta: 0:16:38  Lr: 0.001875  Loss: -0.1586  Acc@1: 87.5000 (87.4307)  Acc@5: 100.0000 (98.6842)  time: 0.3577  data: 0.0007  max mem: 2501
Train: Epoch[5/5]  [ 370/3125]  eta: 0:16:34  Lr: 0.001875  Loss: -0.4397  Acc@1: 81.2500 (87.4158)  Acc@5: 100.0000 (98.6691)  time: 0.3534  data: 0.0004  max mem: 2501
Train: Epoch[5/5]  [ 380/3125]  eta: 0:16:31  Lr: 0.001875  Loss: -0.1950  Acc@1: 87.5000 (87.3688)  Acc@5: 100.0000 (98.6713)  time: 0.3614  data: 0.0005  max mem: 2501
Train: Epoch[5/5]  [ 390/3125]  eta: 0:16:27  Lr: 0.001875  Loss: -0.6483  Acc@1: 87.5000 (87.4041)  Acc@5: 100.0000 (98.6733)  time: 0.3586  data: 0.0008  max mem: 2501
Train: Epoch[5/5]  [ 400/3125]  eta: 0:16:23  Lr: 0.001875  Loss: -0.2228  Acc@1: 87.5000 (87.4532)  Acc@5: 100.0000 (98.7064)  time: 0.3566  data: 0.0008  max mem: 2501
Train: Epoch[5/5]  [ 410/3125]  eta: 0:16:20  Lr: 0.001875  Loss: -0.5959  Acc@1: 87.5000 (87.4848)  Acc@5: 100.0000 (98.7074)  time: 0.3676  data: 0.0006  max mem: 2501
Train: Epoch[5/5]  [ 420/3125]  eta: 0:16:16  Lr: 0.001875  Loss: -0.3049  Acc@1: 87.5000 (87.4852)  Acc@5: 100.0000 (98.6936)  time: 0.3627  data: 0.0016  max mem: 2501
Train: Epoch[5/5]  [ 430/3125]  eta: 0:16:12  Lr: 0.001875  Loss: -0.2521  Acc@1: 87.5000 (87.5290)  Acc@5: 100.0000 (98.6949)  time: 0.3537  data: 0.0016  max mem: 2501
Train: Epoch[5/5]  [ 440/3125]  eta: 0:16:09  Lr: 0.001875  Loss: -0.3478  Acc@1: 87.5000 (87.5709)  Acc@5: 100.0000 (98.6961)  time: 0.3629  data: 0.0006  max mem: 2501
Train: Epoch[5/5]  [ 450/3125]  eta: 0:16:05  Lr: 0.001875  Loss: -0.3454  Acc@1: 87.5000 (87.5693)  Acc@5: 100.0000 (98.7251)  time: 0.3581  data: 0.0007  max mem: 2501
Train: Epoch[5/5]  [ 460/3125]  eta: 0:16:01  Lr: 0.001875  Loss: -0.6676  Acc@1: 93.7500 (87.6491)  Acc@5: 100.0000 (98.7527)  time: 0.3516  data: 0.0007  max mem: 2501
Train: Epoch[5/5]  [ 470/3125]  eta: 0:15:57  Lr: 0.001875  Loss: -0.3431  Acc@1: 93.7500 (87.6858)  Acc@5: 100.0000 (98.7659)  time: 0.3602  data: 0.0007  max mem: 2501
Train: Epoch[5/5]  [ 480/3125]  eta: 0:15:53  Lr: 0.001875  Loss: -0.6103  Acc@1: 87.5000 (87.6040)  Acc@5: 100.0000 (98.7396)  time: 0.3568  data: 0.0007  max mem: 2501
Train: Epoch[5/5]  [ 490/3125]  eta: 0:15:49  Lr: 0.001875  Loss: -0.2891  Acc@1: 87.5000 (87.6018)  Acc@5: 100.0000 (98.7271)  time: 0.3539  data: 0.0005  max mem: 2501
Train: Epoch[5/5]  [ 500/3125]  eta: 0:15:46  Lr: 0.001875  Loss: -0.3438  Acc@1: 87.5000 (87.6123)  Acc@5: 100.0000 (98.7400)  time: 0.3653  data: 0.0021  max mem: 2501
Train: Epoch[5/5]  [ 510/3125]  eta: 0:15:43  Lr: 0.001875  Loss: -0.3310  Acc@1: 87.5000 (87.5367)  Acc@5: 100.0000 (98.7402)  time: 0.3680  data: 0.0021  max mem: 2501
Train: Epoch[5/5]  [ 520/3125]  eta: 0:15:39  Lr: 0.001875  Loss: -0.3902  Acc@1: 81.2500 (87.4880)  Acc@5: 100.0000 (98.7164)  time: 0.3572  data: 0.0004  max mem: 2501
Train: Epoch[5/5]  [ 530/3125]  eta: 0:15:35  Lr: 0.001875  Loss: -0.4120  Acc@1: 81.2500 (87.4529)  Acc@5: 100.0000 (98.6817)  time: 0.3558  data: 0.0005  max mem: 2501
Train: Epoch[5/5]  [ 540/3125]  eta: 0:15:31  Lr: 0.001875  Loss: -0.6448  Acc@1: 87.5000 (87.5462)  Acc@5: 100.0000 (98.6945)  time: 0.3600  data: 0.0005  max mem: 2501
Train: Epoch[5/5]  [ 550/3125]  eta: 0:15:28  Lr: 0.001875  Loss: -0.0997  Acc@1: 87.5000 (87.5227)  Acc@5: 100.0000 (98.6842)  time: 0.3569  data: 0.0004  max mem: 2501
Train: Epoch[5/5]  [ 560/3125]  eta: 0:15:24  Lr: 0.001875  Loss: -0.2164  Acc@1: 87.5000 (87.4666)  Acc@5: 100.0000 (98.6854)  time: 0.3610  data: 0.0004  max mem: 2501
Train: Epoch[5/5]  [ 570/3125]  eta: 0:15:20  Lr: 0.001875  Loss: -0.2672  Acc@1: 87.5000 (87.5219)  Acc@5: 100.0000 (98.6865)  time: 0.3566  data: 0.0008  max mem: 2501
Train: Epoch[5/5]  [ 580/3125]  eta: 0:15:16  Lr: 0.001875  Loss: -0.2992  Acc@1: 87.5000 (87.5430)  Acc@5: 100.0000 (98.6769)  time: 0.3519  data: 0.0008  max mem: 2501
Train: Epoch[5/5]  [ 590/3125]  eta: 0:15:13  Lr: 0.001875  Loss: -0.2077  Acc@1: 87.5000 (87.4683)  Acc@5: 100.0000 (98.6569)  time: 0.3635  data: 0.0009  max mem: 2501
Train: Epoch[5/5]  [ 600/3125]  eta: 0:15:10  Lr: 0.001875  Loss: -0.4465  Acc@1: 87.5000 (87.5312)  Acc@5: 100.0000 (98.6585)  time: 0.3673  data: 0.0010  max mem: 2501
Train: Epoch[5/5]  [ 610/3125]  eta: 0:15:06  Lr: 0.001875  Loss: -0.7425  Acc@1: 87.5000 (87.5511)  Acc@5: 100.0000 (98.6804)  time: 0.3575  data: 0.0007  max mem: 2501
Train: Epoch[5/5]  [ 620/3125]  eta: 0:15:02  Lr: 0.001875  Loss: -0.2596  Acc@1: 81.2500 (87.4295)  Acc@5: 100.0000 (98.6816)  time: 0.3550  data: 0.0006  max mem: 2501
Train: Epoch[5/5]  [ 630/3125]  eta: 0:14:59  Lr: 0.001875  Loss: -0.2806  Acc@1: 81.2500 (87.4208)  Acc@5: 100.0000 (98.6727)  time: 0.3618  data: 0.0005  max mem: 2501
Train: Epoch[5/5]  [ 640/3125]  eta: 0:14:55  Lr: 0.001875  Loss: -0.2083  Acc@1: 87.5000 (87.4122)  Acc@5: 100.0000 (98.6544)  time: 0.3558  data: 0.0006  max mem: 2501
Train: Epoch[5/5]  [ 650/3125]  eta: 0:14:51  Lr: 0.001875  Loss: -0.3245  Acc@1: 87.5000 (87.3656)  Acc@5: 100.0000 (98.6463)  time: 0.3556  data: 0.0004  max mem: 2501
Train: Epoch[5/5]  [ 660/3125]  eta: 0:14:47  Lr: 0.001875  Loss: -0.4942  Acc@1: 87.5000 (87.3109)  Acc@5: 100.0000 (98.6384)  time: 0.3590  data: 0.0005  max mem: 2501
Train: Epoch[5/5]  [ 670/3125]  eta: 0:14:43  Lr: 0.001875  Loss: -0.4001  Acc@1: 87.5000 (87.2671)  Acc@5: 100.0000 (98.6308)  time: 0.3548  data: 0.0006  max mem: 2501
Train: Epoch[5/5]  [ 680/3125]  eta: 0:14:40  Lr: 0.001875  Loss: -0.1319  Acc@1: 87.5000 (87.2614)  Acc@5: 100.0000 (98.6233)  time: 0.3586  data: 0.0005  max mem: 2501
Train: Epoch[5/5]  [ 690/3125]  eta: 0:14:37  Lr: 0.001875  Loss: -0.5573  Acc@1: 87.5000 (87.2739)  Acc@5: 100.0000 (98.6252)  time: 0.3692  data: 0.0006  max mem: 2501
Train: Epoch[5/5]  [ 700/3125]  eta: 0:14:33  Lr: 0.001875  Loss: -0.4718  Acc@1: 93.7500 (87.3039)  Acc@5: 100.0000 (98.6091)  time: 0.3630  data: 0.0006  max mem: 2501
Train: Epoch[5/5]  [ 710/3125]  eta: 0:14:29  Lr: 0.001875  Loss: -0.7107  Acc@1: 87.5000 (87.2890)  Acc@5: 100.0000 (98.6111)  time: 0.3531  data: 0.0008  max mem: 2501
Train: Epoch[5/5]  [ 720/3125]  eta: 0:14:26  Lr: 0.001875  Loss: -0.2268  Acc@1: 87.5000 (87.2399)  Acc@5: 100.0000 (98.6217)  time: 0.3626  data: 0.0012  max mem: 2501
Train: Epoch[5/5]  [ 730/3125]  eta: 0:14:22  Lr: 0.001875  Loss: -0.2792  Acc@1: 87.5000 (87.2264)  Acc@5: 100.0000 (98.6149)  time: 0.3580  data: 0.0008  max mem: 2501
Train: Epoch[5/5]  [ 740/3125]  eta: 0:14:18  Lr: 0.001875  Loss: -0.3519  Acc@1: 87.5000 (87.2217)  Acc@5: 100.0000 (98.6083)  time: 0.3502  data: 0.0010  max mem: 2501
Train: Epoch[5/5]  [ 750/3125]  eta: 0:14:15  Lr: 0.001875  Loss: -0.4352  Acc@1: 87.5000 (87.1921)  Acc@5: 100.0000 (98.6102)  time: 0.3598  data: 0.0011  max mem: 2501
Train: Epoch[5/5]  [ 760/3125]  eta: 0:14:11  Lr: 0.001875  Loss: -0.4345  Acc@1: 87.5000 (87.2290)  Acc@5: 100.0000 (98.5956)  time: 0.3580  data: 0.0013  max mem: 2501
Train: Epoch[5/5]  [ 770/3125]  eta: 0:14:07  Lr: 0.001875  Loss: -0.4782  Acc@1: 87.5000 (87.2244)  Acc@5: 100.0000 (98.6057)  time: 0.3502  data: 0.0017  max mem: 2501
Train: Epoch[5/5]  [ 780/3125]  eta: 0:14:03  Lr: 0.001875  Loss: -0.3381  Acc@1: 87.5000 (87.2519)  Acc@5: 100.0000 (98.6236)  time: 0.3555  data: 0.0009  max mem: 2501
Train: Epoch[5/5]  [ 790/3125]  eta: 0:14:00  Lr: 0.001875  Loss: 0.0518  Acc@1: 87.5000 (87.3025)  Acc@5: 100.0000 (98.6252)  time: 0.3705  data: 0.0014  max mem: 2501
Train: Epoch[5/5]  [ 800/3125]  eta: 0:13:56  Lr: 0.001875  Loss: -0.2540  Acc@1: 87.5000 (87.2971)  Acc@5: 100.0000 (98.6345)  time: 0.3631  data: 0.0014  max mem: 2501
Train: Epoch[5/5]  [ 810/3125]  eta: 0:13:53  Lr: 0.001875  Loss: -0.2886  Acc@1: 87.5000 (87.3073)  Acc@5: 100.0000 (98.6514)  time: 0.3512  data: 0.0006  max mem: 2501
Train: Epoch[5/5]  [ 820/3125]  eta: 0:13:49  Lr: 0.001875  Loss: -0.3645  Acc@1: 87.5000 (87.3021)  Acc@5: 100.0000 (98.6297)  time: 0.3610  data: 0.0008  max mem: 2501
Train: Epoch[5/5]  [ 830/3125]  eta: 0:13:45  Lr: 0.001875  Loss: -0.5391  Acc@1: 87.5000 (87.2819)  Acc@5: 93.7500 (98.6086)  time: 0.3567  data: 0.0008  max mem: 2501
Train: Epoch[5/5]  [ 840/3125]  eta: 0:13:42  Lr: 0.001875  Loss: -0.3604  Acc@1: 87.5000 (87.3068)  Acc@5: 100.0000 (98.6103)  time: 0.3533  data: 0.0005  max mem: 2501
Train: Epoch[5/5]  [ 850/3125]  eta: 0:13:38  Lr: 0.001875  Loss: -0.3140  Acc@1: 93.7500 (87.3531)  Acc@5: 100.0000 (98.6193)  time: 0.3645  data: 0.0006  max mem: 2501
Train: Epoch[5/5]  [ 860/3125]  eta: 0:13:34  Lr: 0.001875  Loss: -0.2261  Acc@1: 93.7500 (87.3693)  Acc@5: 100.0000 (98.6208)  time: 0.3580  data: 0.0007  max mem: 2501
Train: Epoch[5/5]  [ 870/3125]  eta: 0:13:31  Lr: 0.001875  Loss: -0.3425  Acc@1: 93.7500 (87.3780)  Acc@5: 100.0000 (98.6151)  time: 0.3519  data: 0.0005  max mem: 2501
Train: Epoch[5/5]  [ 880/3125]  eta: 0:13:27  Lr: 0.001875  Loss: -0.6816  Acc@1: 81.2500 (87.3297)  Acc@5: 100.0000 (98.5953)  time: 0.3651  data: 0.0011  max mem: 2501
Train: Epoch[5/5]  [ 890/3125]  eta: 0:13:24  Lr: 0.001875  Loss: -0.2631  Acc@1: 81.2500 (87.3246)  Acc@5: 100.0000 (98.5901)  time: 0.3695  data: 0.0019  max mem: 2501
Train: Epoch[5/5]  [ 900/3125]  eta: 0:13:20  Lr: 0.001875  Loss: -0.2830  Acc@1: 87.5000 (87.2780)  Acc@5: 100.0000 (98.5988)  time: 0.3575  data: 0.0012  max mem: 2501
Train: Epoch[5/5]  [ 910/3125]  eta: 0:13:16  Lr: 0.001875  Loss: -0.5292  Acc@1: 87.5000 (87.2599)  Acc@5: 100.0000 (98.5936)  time: 0.3536  data: 0.0005  max mem: 2501
Train: Epoch[5/5]  [ 920/3125]  eta: 0:13:13  Lr: 0.001875  Loss: -0.5003  Acc@1: 87.5000 (87.2693)  Acc@5: 100.0000 (98.6021)  time: 0.3615  data: 0.0005  max mem: 2501
Train: Epoch[5/5]  [ 930/3125]  eta: 0:13:09  Lr: 0.001875  Loss: -0.4899  Acc@1: 87.5000 (87.2650)  Acc@5: 100.0000 (98.6104)  time: 0.3568  data: 0.0005  max mem: 2501
Train: Epoch[5/5]  [ 940/3125]  eta: 0:13:05  Lr: 0.001875  Loss: -0.4561  Acc@1: 87.5000 (87.2742)  Acc@5: 100.0000 (98.5853)  time: 0.3538  data: 0.0005  max mem: 2501
Train: Epoch[5/5]  [ 950/3125]  eta: 0:13:02  Lr: 0.001875  Loss: -0.5072  Acc@1: 87.5000 (87.2503)  Acc@5: 100.0000 (98.5804)  time: 0.3596  data: 0.0005  max mem: 2501
Train: Epoch[5/5]  [ 960/3125]  eta: 0:12:58  Lr: 0.001875  Loss: -0.4454  Acc@1: 87.5000 (87.2984)  Acc@5: 100.0000 (98.5952)  time: 0.3570  data: 0.0005  max mem: 2501
Train: Epoch[5/5]  [ 970/3125]  eta: 0:12:55  Lr: 0.001875  Loss: -0.4680  Acc@1: 93.7500 (87.3133)  Acc@5: 100.0000 (98.6032)  time: 0.3611  data: 0.0005  max mem: 2501
Train: Epoch[5/5]  [ 980/3125]  eta: 0:12:51  Lr: 0.001875  Loss: -0.1536  Acc@1: 87.5000 (87.3089)  Acc@5: 100.0000 (98.6111)  time: 0.3598  data: 0.0014  max mem: 2501
Train: Epoch[5/5]  [ 990/3125]  eta: 0:12:47  Lr: 0.001875  Loss: -0.1924  Acc@1: 87.5000 (87.3108)  Acc@5: 100.0000 (98.6125)  time: 0.3587  data: 0.0014  max mem: 2501
Train: Epoch[5/5]  [1000/3125]  eta: 0:12:44  Lr: 0.001875  Loss: -0.4863  Acc@1: 87.5000 (87.3439)  Acc@5: 100.0000 (98.6201)  time: 0.3586  data: 0.0005  max mem: 2501
Train: Epoch[5/5]  [1010/3125]  eta: 0:12:40  Lr: 0.001875  Loss: -0.6661  Acc@1: 87.5000 (87.3331)  Acc@5: 100.0000 (98.6152)  time: 0.3537  data: 0.0004  max mem: 2501
Train: Epoch[5/5]  [1020/3125]  eta: 0:12:37  Lr: 0.001875  Loss: -0.4098  Acc@1: 87.5000 (87.3347)  Acc@5: 100.0000 (98.5921)  time: 0.3607  data: 0.0006  max mem: 2501
Train: Epoch[5/5]  [1030/3125]  eta: 0:12:33  Lr: 0.001875  Loss: -0.4568  Acc@1: 87.5000 (87.3606)  Acc@5: 100.0000 (98.5997)  time: 0.3582  data: 0.0005  max mem: 2501
Train: Epoch[5/5]  [1040/3125]  eta: 0:12:29  Lr: 0.001875  Loss: -0.4291  Acc@1: 87.5000 (87.3439)  Acc@5: 100.0000 (98.5771)  time: 0.3556  data: 0.0005  max mem: 2501
Train: Epoch[5/5]  [1050/3125]  eta: 0:12:26  Lr: 0.001875  Loss: -0.3491  Acc@1: 87.5000 (87.3989)  Acc@5: 100.0000 (98.5787)  time: 0.3598  data: 0.0005  max mem: 2501
Train: Epoch[5/5]  [1060/3125]  eta: 0:12:22  Lr: 0.001875  Loss: -0.2254  Acc@1: 87.5000 (87.3704)  Acc@5: 100.0000 (98.5803)  time: 0.3566  data: 0.0005  max mem: 2501
Train: Epoch[5/5]  [1070/3125]  eta: 0:12:19  Lr: 0.001875  Loss: -0.4571  Acc@1: 81.2500 (87.3483)  Acc@5: 100.0000 (98.5936)  time: 0.3628  data: 0.0006  max mem: 2501
Train: Epoch[5/5]  [1080/3125]  eta: 0:12:15  Lr: 0.001875  Loss: -0.6143  Acc@1: 87.5000 (87.3612)  Acc@5: 100.0000 (98.6066)  time: 0.3694  data: 0.0012  max mem: 2501
Train: Epoch[5/5]  [1090/3125]  eta: 0:12:11  Lr: 0.001875  Loss: -0.2385  Acc@1: 87.5000 (87.3740)  Acc@5: 100.0000 (98.6194)  time: 0.3576  data: 0.0013  max mem: 2501
Train: Epoch[5/5]  [1100/3125]  eta: 0:12:08  Lr: 0.001875  Loss: -0.4274  Acc@1: 87.5000 (87.4035)  Acc@5: 100.0000 (98.6262)  time: 0.3507  data: 0.0006  max mem: 2501
Train: Epoch[5/5]  [1110/3125]  eta: 0:12:04  Lr: 0.001875  Loss: -0.3125  Acc@1: 87.5000 (87.3931)  Acc@5: 100.0000 (98.5992)  time: 0.3599  data: 0.0004  max mem: 2501
Train: Epoch[5/5]  [1120/3125]  eta: 0:12:00  Lr: 0.001875  Loss: -0.4180  Acc@1: 87.5000 (87.4164)  Acc@5: 100.0000 (98.6062)  time: 0.3584  data: 0.0005  max mem: 2501
Train: Epoch[5/5]  [1130/3125]  eta: 0:11:57  Lr: 0.001875  Loss: -0.6771  Acc@1: 87.5000 (87.3895)  Acc@5: 100.0000 (98.6019)  time: 0.3536  data: 0.0013  max mem: 2501
Train: Epoch[5/5]  [1140/3125]  eta: 0:11:53  Lr: 0.001875  Loss: -0.0512  Acc@1: 81.2500 (87.3521)  Acc@5: 100.0000 (98.5868)  time: 0.3639  data: 0.0013  max mem: 2501
Train: Epoch[5/5]  [1150/3125]  eta: 0:11:49  Lr: 0.001875  Loss: -0.3012  Acc@1: 81.2500 (87.3154)  Acc@5: 100.0000 (98.5936)  time: 0.3572  data: 0.0005  max mem: 2501
Train: Epoch[5/5]  [1160/3125]  eta: 0:11:46  Lr: 0.001875  Loss: -0.6188  Acc@1: 87.5000 (87.3062)  Acc@5: 100.0000 (98.5950)  time: 0.3513  data: 0.0005  max mem: 2501
Train: Epoch[5/5]  [1170/3125]  eta: 0:11:42  Lr: 0.001875  Loss: -0.4783  Acc@1: 87.5000 (87.3506)  Acc@5: 100.0000 (98.6070)  time: 0.3662  data: 0.0020  max mem: 2501
Train: Epoch[5/5]  [1180/3125]  eta: 0:11:39  Lr: 0.001875  Loss: -0.3090  Acc@1: 87.5000 (87.3412)  Acc@5: 100.0000 (98.5923)  time: 0.3683  data: 0.0021  max mem: 2501
Train: Epoch[5/5]  [1190/3125]  eta: 0:11:35  Lr: 0.001875  Loss: -0.1854  Acc@1: 87.5000 (87.3583)  Acc@5: 100.0000 (98.5936)  time: 0.3555  data: 0.0006  max mem: 2501
Train: Epoch[5/5]  [1200/3125]  eta: 0:11:32  Lr: 0.001875  Loss: -0.3225  Acc@1: 87.5000 (87.3647)  Acc@5: 100.0000 (98.5949)  time: 0.3555  data: 0.0004  max mem: 2501
Train: Epoch[5/5]  [1210/3125]  eta: 0:11:28  Lr: 0.001875  Loss: -0.3301  Acc@1: 93.7500 (87.3658)  Acc@5: 100.0000 (98.6065)  time: 0.3717  data: 0.0007  max mem: 2501
Train: Epoch[5/5]  [1220/3125]  eta: 0:11:25  Lr: 0.001875  Loss: -0.2469  Acc@1: 87.5000 (87.3618)  Acc@5: 100.0000 (98.6077)  time: 0.3643  data: 0.0007  max mem: 2501
Train: Epoch[5/5]  [1230/3125]  eta: 0:11:21  Lr: 0.001875  Loss: -0.7447  Acc@1: 87.5000 (87.3883)  Acc@5: 100.0000 (98.6089)  time: 0.3522  data: 0.0005  max mem: 2501
Train: Epoch[5/5]  [1240/3125]  eta: 0:11:17  Lr: 0.001875  Loss: -0.1522  Acc@1: 87.5000 (87.3489)  Acc@5: 100.0000 (98.6100)  time: 0.3633  data: 0.0010  max mem: 2501
Train: Epoch[5/5]  [1250/3125]  eta: 0:11:14  Lr: 0.001875  Loss: -0.2936  Acc@1: 81.2500 (87.2602)  Acc@5: 100.0000 (98.6011)  time: 0.3595  data: 0.0010  max mem: 2501
Train: Epoch[5/5]  [1260/3125]  eta: 0:11:10  Lr: 0.001875  Loss: -0.4847  Acc@1: 87.5000 (87.2918)  Acc@5: 100.0000 (98.6073)  time: 0.3538  data: 0.0006  max mem: 2501
Train: Epoch[5/5]  [1270/3125]  eta: 0:11:07  Lr: 0.001875  Loss: -0.2730  Acc@1: 87.5000 (87.2836)  Acc@5: 100.0000 (98.6035)  time: 0.3609  data: 0.0006  max mem: 2501
Train: Epoch[5/5]  [1280/3125]  eta: 0:11:03  Lr: 0.001875  Loss: 0.0232  Acc@1: 87.5000 (87.2853)  Acc@5: 100.0000 (98.5997)  time: 0.3664  data: 0.0012  max mem: 2501
Train: Epoch[5/5]  [1290/3125]  eta: 0:10:59  Lr: 0.001875  Loss: -0.5106  Acc@1: 93.7500 (87.3015)  Acc@5: 100.0000 (98.6057)  time: 0.3609  data: 0.0021  max mem: 2501
Train: Epoch[5/5]  [1300/3125]  eta: 0:10:56  Lr: 0.001875  Loss: -0.3030  Acc@1: 87.5000 (87.3030)  Acc@5: 100.0000 (98.6164)  time: 0.3558  data: 0.0014  max mem: 2501
Train: Epoch[5/5]  [1310/3125]  eta: 0:10:52  Lr: 0.001875  Loss: -0.3015  Acc@1: 87.5000 (87.3141)  Acc@5: 100.0000 (98.6175)  time: 0.3693  data: 0.0007  max mem: 2501
Train: Epoch[5/5]  [1320/3125]  eta: 0:10:49  Lr: 0.001875  Loss: -0.3635  Acc@1: 87.5000 (87.3155)  Acc@5: 100.0000 (98.6090)  time: 0.3638  data: 0.0011  max mem: 2501
Train: Epoch[5/5]  [1330/3125]  eta: 0:10:45  Lr: 0.001875  Loss: -0.2034  Acc@1: 87.5000 (87.3075)  Acc@5: 100.0000 (98.6148)  time: 0.3524  data: 0.0009  max mem: 2501
Train: Epoch[5/5]  [1340/3125]  eta: 0:10:42  Lr: 0.001875  Loss: -0.6360  Acc@1: 93.7500 (87.3182)  Acc@5: 100.0000 (98.6251)  time: 0.3617  data: 0.0007  max mem: 2501
Train: Epoch[5/5]  [1350/3125]  eta: 0:10:38  Lr: 0.001875  Loss: -0.1172  Acc@1: 87.5000 (87.2872)  Acc@5: 100.0000 (98.6168)  time: 0.3577  data: 0.0008  max mem: 2501
Train: Epoch[5/5]  [1360/3125]  eta: 0:10:34  Lr: 0.001875  Loss: -0.4157  Acc@1: 87.5000 (87.2979)  Acc@5: 100.0000 (98.6177)  time: 0.3537  data: 0.0007  max mem: 2501
Train: Epoch[5/5]  [1370/3125]  eta: 0:10:31  Lr: 0.001875  Loss: -0.3255  Acc@1: 87.5000 (87.3040)  Acc@5: 100.0000 (98.6233)  time: 0.3602  data: 0.0009  max mem: 2501
Train: Epoch[5/5]  [1380/3125]  eta: 0:10:27  Lr: 0.001875  Loss: -0.4005  Acc@1: 87.5000 (87.3099)  Acc@5: 100.0000 (98.6287)  time: 0.3663  data: 0.0017  max mem: 2501
Train: Epoch[5/5]  [1390/3125]  eta: 0:10:23  Lr: 0.001875  Loss: -0.4527  Acc@1: 87.5000 (87.3248)  Acc@5: 100.0000 (98.6341)  time: 0.3596  data: 0.0013  max mem: 2501
Train: Epoch[5/5]  [1400/3125]  eta: 0:10:20  Lr: 0.001875  Loss: -0.3123  Acc@1: 87.5000 (87.3171)  Acc@5: 100.0000 (98.6349)  time: 0.3543  data: 0.0006  max mem: 2501
Train: Epoch[5/5]  [1410/3125]  eta: 0:10:17  Lr: 0.001875  Loss: -0.4383  Acc@1: 87.5000 (87.3228)  Acc@5: 100.0000 (98.6446)  time: 0.3703  data: 0.0007  max mem: 2501
Train: Epoch[5/5]  [1420/3125]  eta: 0:10:13  Lr: 0.001875  Loss: -0.2488  Acc@1: 87.5000 (87.3153)  Acc@5: 100.0000 (98.6453)  time: 0.3648  data: 0.0005  max mem: 2501
Train: Epoch[5/5]  [1430/3125]  eta: 0:10:09  Lr: 0.001875  Loss: -0.1381  Acc@1: 87.5000 (87.3297)  Acc@5: 100.0000 (98.6329)  time: 0.3536  data: 0.0006  max mem: 2501
Train: Epoch[5/5]  [1440/3125]  eta: 0:10:06  Lr: 0.001875  Loss: -0.6554  Acc@1: 87.5000 (87.3439)  Acc@5: 100.0000 (98.6338)  time: 0.3626  data: 0.0006  max mem: 2501
Train: Epoch[5/5]  [1450/3125]  eta: 0:10:02  Lr: 0.001875  Loss: -0.5052  Acc@1: 87.5000 (87.3277)  Acc@5: 100.0000 (98.6389)  time: 0.3592  data: 0.0014  max mem: 2501
Train: Epoch[5/5]  [1460/3125]  eta: 0:09:58  Lr: 0.001875  Loss: -0.5690  Acc@1: 81.2500 (87.3203)  Acc@5: 100.0000 (98.6439)  time: 0.3571  data: 0.0013  max mem: 2501
Train: Epoch[5/5]  [1470/3125]  eta: 0:09:55  Lr: 0.001875  Loss: -0.5083  Acc@1: 87.5000 (87.3046)  Acc@5: 100.0000 (98.6361)  time: 0.3638  data: 0.0007  max mem: 2501
Train: Epoch[5/5]  [1480/3125]  eta: 0:09:51  Lr: 0.001875  Loss: -0.5445  Acc@1: 87.5000 (87.2890)  Acc@5: 100.0000 (98.6369)  time: 0.3663  data: 0.0006  max mem: 2501
Train: Epoch[5/5]  [1490/3125]  eta: 0:09:48  Lr: 0.001875  Loss: -0.5814  Acc@1: 87.5000 (87.2862)  Acc@5: 100.0000 (98.6377)  time: 0.3596  data: 0.0005  max mem: 2501
Train: Epoch[5/5]  [1500/3125]  eta: 0:09:44  Lr: 0.001875  Loss: -0.4250  Acc@1: 87.5000 (87.2793)  Acc@5: 100.0000 (98.6342)  time: 0.3552  data: 0.0006  max mem: 2501
Train: Epoch[5/5]  [1510/3125]  eta: 0:09:41  Lr: 0.001875  Loss: -0.4255  Acc@1: 87.5000 (87.2435)  Acc@5: 100.0000 (98.6309)  time: 0.3669  data: 0.0006  max mem: 2501
Train: Epoch[5/5]  [1520/3125]  eta: 0:09:37  Lr: 0.001875  Loss: -0.0574  Acc@1: 87.5000 (87.2493)  Acc@5: 100.0000 (98.6275)  time: 0.3624  data: 0.0005  max mem: 2501
Train: Epoch[5/5]  [1530/3125]  eta: 0:09:33  Lr: 0.001875  Loss: -0.5676  Acc@1: 87.5000 (87.2510)  Acc@5: 100.0000 (98.6324)  time: 0.3555  data: 0.0005  max mem: 2501
Train: Epoch[5/5]  [1540/3125]  eta: 0:09:30  Lr: 0.001875  Loss: -0.4684  Acc@1: 87.5000 (87.2526)  Acc@5: 100.0000 (98.6372)  time: 0.3605  data: 0.0008  max mem: 2501
Train: Epoch[5/5]  [1550/3125]  eta: 0:09:26  Lr: 0.001875  Loss: -0.1752  Acc@1: 87.5000 (87.2663)  Acc@5: 100.0000 (98.6380)  time: 0.3549  data: 0.0007  max mem: 2501
Train: Epoch[5/5]  [1560/3125]  eta: 0:09:22  Lr: 0.001875  Loss: -0.4662  Acc@1: 87.5000 (87.2518)  Acc@5: 100.0000 (98.6427)  time: 0.3551  data: 0.0006  max mem: 2501
Train: Epoch[5/5]  [1570/3125]  eta: 0:09:19  Lr: 0.001875  Loss: -0.1036  Acc@1: 87.5000 (87.2533)  Acc@5: 100.0000 (98.6354)  time: 0.3625  data: 0.0012  max mem: 2501
Train: Epoch[5/5]  [1580/3125]  eta: 0:09:15  Lr: 0.001875  Loss: -0.1596  Acc@1: 87.5000 (87.2628)  Acc@5: 100.0000 (98.6322)  time: 0.3650  data: 0.0011  max mem: 2501
Train: Epoch[5/5]  [1590/3125]  eta: 0:09:12  Lr: 0.001875  Loss: -0.1222  Acc@1: 93.7500 (87.2879)  Acc@5: 100.0000 (98.6369)  time: 0.3587  data: 0.0005  max mem: 2501
Train: Epoch[5/5]  [1600/3125]  eta: 0:09:08  Lr: 0.001875  Loss: -0.6505  Acc@1: 87.5000 (87.2853)  Acc@5: 100.0000 (98.6415)  time: 0.3615  data: 0.0004  max mem: 2501
Train: Epoch[5/5]  [1610/3125]  eta: 0:09:05  Lr: 0.001875  Loss: -0.5554  Acc@1: 93.7500 (87.3215)  Acc@5: 100.0000 (98.6460)  time: 0.3666  data: 0.0006  max mem: 2501
Train: Epoch[5/5]  [1620/3125]  eta: 0:09:01  Lr: 0.001875  Loss: -0.4217  Acc@1: 87.5000 (87.3188)  Acc@5: 100.0000 (98.6467)  time: 0.3571  data: 0.0006  max mem: 2501
Train: Epoch[5/5]  [1630/3125]  eta: 0:08:57  Lr: 0.001875  Loss: -0.5937  Acc@1: 87.5000 (87.3429)  Acc@5: 100.0000 (98.6550)  time: 0.3567  data: 0.0005  max mem: 2501
Train: Epoch[5/5]  [1640/3125]  eta: 0:08:54  Lr: 0.001875  Loss: -0.0737  Acc@1: 93.7500 (87.3705)  Acc@5: 100.0000 (98.6517)  time: 0.3599  data: 0.0006  max mem: 2501
Train: Epoch[5/5]  [1650/3125]  eta: 0:08:50  Lr: 0.001875  Loss: -0.6560  Acc@1: 93.7500 (87.3789)  Acc@5: 100.0000 (98.6523)  time: 0.3561  data: 0.0006  max mem: 2501
Train: Epoch[5/5]  [1660/3125]  eta: 0:08:47  Lr: 0.001875  Loss: -0.4389  Acc@1: 87.5000 (87.3645)  Acc@5: 100.0000 (98.6529)  time: 0.3553  data: 0.0005  max mem: 2501
Train: Epoch[5/5]  [1670/3125]  eta: 0:08:43  Lr: 0.001875  Loss: -0.5199  Acc@1: 87.5000 (87.3691)  Acc@5: 100.0000 (98.6460)  time: 0.3687  data: 0.0015  max mem: 2501
Train: Epoch[5/5]  [1680/3125]  eta: 0:08:39  Lr: 0.001875  Loss: -0.1922  Acc@1: 87.5000 (87.3587)  Acc@5: 100.0000 (98.6504)  time: 0.3639  data: 0.0016  max mem: 2501
Train: Epoch[5/5]  [1690/3125]  eta: 0:08:36  Lr: 0.001875  Loss: -0.3102  Acc@1: 87.5000 (87.3743)  Acc@5: 100.0000 (98.6473)  time: 0.3507  data: 0.0006  max mem: 2501
Train: Epoch[5/5]  [1700/3125]  eta: 0:08:32  Lr: 0.001875  Loss: -0.1681  Acc@1: 87.5000 (87.3567)  Acc@5: 100.0000 (98.6515)  time: 0.3631  data: 0.0006  max mem: 2501
Train: Epoch[5/5]  [1710/3125]  eta: 0:08:29  Lr: 0.001875  Loss: -0.4412  Acc@1: 87.5000 (87.3612)  Acc@5: 100.0000 (98.6558)  time: 0.3666  data: 0.0006  max mem: 2501
Train: Epoch[5/5]  [1720/3125]  eta: 0:08:25  Lr: 0.001875  Loss: 0.5646  Acc@1: 87.5000 (87.3802)  Acc@5: 100.0000 (98.6563)  time: 0.3572  data: 0.0006  max mem: 2501
Train: Epoch[5/5]  [1730/3125]  eta: 0:08:21  Lr: 0.001875  Loss: -0.5022  Acc@1: 87.5000 (87.3592)  Acc@5: 100.0000 (98.6605)  time: 0.3617  data: 0.0005  max mem: 2501
Train: Epoch[5/5]  [1740/3125]  eta: 0:08:18  Lr: 0.001875  Loss: -0.4187  Acc@1: 87.5000 (87.3815)  Acc@5: 100.0000 (98.6646)  time: 0.3582  data: 0.0006  max mem: 2501
Train: Epoch[5/5]  [1750/3125]  eta: 0:08:14  Lr: 0.001875  Loss: -0.5188  Acc@1: 93.7500 (87.3858)  Acc@5: 100.0000 (98.6543)  time: 0.3497  data: 0.0008  max mem: 2501
Train: Epoch[5/5]  [1760/3125]  eta: 0:08:11  Lr: 0.001875  Loss: -0.3925  Acc@1: 87.5000 (87.3864)  Acc@5: 100.0000 (98.6584)  time: 0.3612  data: 0.0007  max mem: 2501
Train: Epoch[5/5]  [1770/3125]  eta: 0:08:07  Lr: 0.001875  Loss: -0.6445  Acc@1: 87.5000 (87.3694)  Acc@5: 100.0000 (98.6519)  time: 0.3682  data: 0.0006  max mem: 2501
Train: Epoch[5/5]  [1780/3125]  eta: 0:08:03  Lr: 0.001875  Loss: -0.5717  Acc@1: 93.7500 (87.3807)  Acc@5: 100.0000 (98.6560)  time: 0.3569  data: 0.0007  max mem: 2501
Train: Epoch[5/5]  [1790/3125]  eta: 0:08:00  Lr: 0.001875  Loss: -0.0024  Acc@1: 87.5000 (87.3779)  Acc@5: 100.0000 (98.6530)  time: 0.3506  data: 0.0005  max mem: 2501
Train: Epoch[5/5]  [1800/3125]  eta: 0:07:56  Lr: 0.001875  Loss: -0.2290  Acc@1: 87.5000 (87.3647)  Acc@5: 100.0000 (98.6501)  time: 0.3605  data: 0.0005  max mem: 2501
Train: Epoch[5/5]  [1810/3125]  eta: 0:07:52  Lr: 0.001875  Loss: -0.6004  Acc@1: 87.5000 (87.3689)  Acc@5: 100.0000 (98.6541)  time: 0.3569  data: 0.0005  max mem: 2501
Train: Epoch[5/5]  [1820/3125]  eta: 0:07:49  Lr: 0.001875  Loss: -0.2748  Acc@1: 87.5000 (87.3764)  Acc@5: 100.0000 (98.6580)  time: 0.3531  data: 0.0006  max mem: 2501
Train: Epoch[5/5]  [1830/3125]  eta: 0:07:45  Lr: 0.001875  Loss: -0.1359  Acc@1: 87.5000 (87.3942)  Acc@5: 100.0000 (98.6585)  time: 0.3610  data: 0.0006  max mem: 2501
Train: Epoch[5/5]  [1840/3125]  eta: 0:07:42  Lr: 0.001875  Loss: -0.4851  Acc@1: 93.7500 (87.4151)  Acc@5: 100.0000 (98.6590)  time: 0.3559  data: 0.0004  max mem: 2501
Train: Epoch[5/5]  [1850/3125]  eta: 0:07:38  Lr: 0.001875  Loss: -0.4431  Acc@1: 87.5000 (87.4122)  Acc@5: 100.0000 (98.6595)  time: 0.3545  data: 0.0005  max mem: 2501
Train: Epoch[5/5]  [1860/3125]  eta: 0:07:35  Lr: 0.001875  Loss: -0.4150  Acc@1: 87.5000 (87.4060)  Acc@5: 100.0000 (98.6566)  time: 0.3690  data: 0.0007  max mem: 2501
Train: Epoch[5/5]  [1870/3125]  eta: 0:07:31  Lr: 0.001875  Loss: -0.0477  Acc@1: 87.5000 (87.3964)  Acc@5: 100.0000 (98.6571)  time: 0.3643  data: 0.0006  max mem: 2501
Train: Epoch[5/5]  [1880/3125]  eta: 0:07:27  Lr: 0.001875  Loss: -0.2374  Acc@1: 87.5000 (87.3970)  Acc@5: 100.0000 (98.6543)  time: 0.3516  data: 0.0005  max mem: 2501
Train: Epoch[5/5]  [1890/3125]  eta: 0:07:24  Lr: 0.001875  Loss: -0.4406  Acc@1: 87.5000 (87.3975)  Acc@5: 100.0000 (98.6416)  time: 0.3620  data: 0.0005  max mem: 2501
Train: Epoch[5/5]  [1900/3125]  eta: 0:07:20  Lr: 0.001875  Loss: -0.6372  Acc@1: 87.5000 (87.4211)  Acc@5: 100.0000 (98.6422)  time: 0.3585  data: 0.0005  max mem: 2501
Train: Epoch[5/5]  [1910/3125]  eta: 0:07:16  Lr: 0.001875  Loss: -0.4461  Acc@1: 87.5000 (87.4150)  Acc@5: 100.0000 (98.6395)  time: 0.3512  data: 0.0006  max mem: 2501
Train: Epoch[5/5]  [1920/3125]  eta: 0:07:13  Lr: 0.001875  Loss: -0.1242  Acc@1: 87.5000 (87.4122)  Acc@5: 100.0000 (98.6335)  time: 0.3643  data: 0.0006  max mem: 2501
Train: Epoch[5/5]  [1930/3125]  eta: 0:07:09  Lr: 0.001875  Loss: -0.2023  Acc@1: 81.2500 (87.3932)  Acc@5: 100.0000 (98.6309)  time: 0.3590  data: 0.0007  max mem: 2501
Train: Epoch[5/5]  [1940/3125]  eta: 0:07:06  Lr: 0.001875  Loss: -0.3953  Acc@1: 93.7500 (87.4259)  Acc@5: 100.0000 (98.6315)  time: 0.3499  data: 0.0011  max mem: 2501
Train: Epoch[5/5]  [1950/3125]  eta: 0:07:02  Lr: 0.001875  Loss: -0.1455  Acc@1: 87.5000 (87.4071)  Acc@5: 100.0000 (98.6321)  time: 0.3620  data: 0.0008  max mem: 2501
Train: Epoch[5/5]  [1960/3125]  eta: 0:06:59  Lr: 0.001875  Loss: -0.6237  Acc@1: 87.5000 (87.3948)  Acc@5: 100.0000 (98.6327)  time: 0.3682  data: 0.0009  max mem: 2501
Train: Epoch[5/5]  [1970/3125]  eta: 0:06:55  Lr: 0.001875  Loss: -0.1648  Acc@1: 81.2500 (87.3827)  Acc@5: 100.0000 (98.6365)  time: 0.3561  data: 0.0009  max mem: 2501
Train: Epoch[5/5]  [1980/3125]  eta: 0:06:51  Lr: 0.001875  Loss: -0.4243  Acc@1: 87.5000 (87.3675)  Acc@5: 100.0000 (98.6402)  time: 0.3518  data: 0.0005  max mem: 2501
Train: Epoch[5/5]  [1990/3125]  eta: 0:06:48  Lr: 0.001875  Loss: -0.6835  Acc@1: 87.5000 (87.3713)  Acc@5: 100.0000 (98.6439)  time: 0.3621  data: 0.0006  max mem: 2501
Train: Epoch[5/5]  [2000/3125]  eta: 0:06:44  Lr: 0.001875  Loss: -0.2050  Acc@1: 87.5000 (87.3751)  Acc@5: 100.0000 (98.6351)  time: 0.3570  data: 0.0006  max mem: 2501
Train: Epoch[5/5]  [2010/3125]  eta: 0:06:40  Lr: 0.001875  Loss: -0.2576  Acc@1: 87.5000 (87.3881)  Acc@5: 100.0000 (98.6387)  time: 0.3527  data: 0.0008  max mem: 2501
Train: Epoch[5/5]  [2020/3125]  eta: 0:06:37  Lr: 0.001875  Loss: -0.6628  Acc@1: 87.5000 (87.3763)  Acc@5: 100.0000 (98.6393)  time: 0.3619  data: 0.0009  max mem: 2501
Train: Epoch[5/5]  [2030/3125]  eta: 0:06:33  Lr: 0.001875  Loss: 0.5926  Acc@1: 93.7500 (87.3892)  Acc@5: 100.0000 (98.6337)  time: 0.3569  data: 0.0006  max mem: 2501
Train: Epoch[5/5]  [2040/3125]  eta: 0:06:30  Lr: 0.001875  Loss: -0.6679  Acc@1: 93.7500 (87.3744)  Acc@5: 100.0000 (98.6312)  time: 0.3545  data: 0.0006  max mem: 2501
Train: Epoch[5/5]  [2050/3125]  eta: 0:06:26  Lr: 0.001875  Loss: 0.1078  Acc@1: 87.5000 (87.3720)  Acc@5: 100.0000 (98.6318)  time: 0.3623  data: 0.0010  max mem: 2501
Train: Epoch[5/5]  [2060/3125]  eta: 0:06:22  Lr: 0.001875  Loss: -0.2527  Acc@1: 87.5000 (87.3726)  Acc@5: 100.0000 (98.6354)  time: 0.3665  data: 0.0011  max mem: 2501
Train: Epoch[5/5]  [2070/3125]  eta: 0:06:19  Lr: 0.001875  Loss: -0.3904  Acc@1: 87.5000 (87.3702)  Acc@5: 100.0000 (98.6389)  time: 0.3596  data: 0.0008  max mem: 2501
Train: Epoch[5/5]  [2080/3125]  eta: 0:06:15  Lr: 0.001875  Loss: -0.2398  Acc@1: 87.5000 (87.3709)  Acc@5: 100.0000 (98.6425)  time: 0.3559  data: 0.0009  max mem: 2501
Train: Epoch[5/5]  [2090/3125]  eta: 0:06:12  Lr: 0.001875  Loss: -0.5465  Acc@1: 87.5000 (87.3775)  Acc@5: 100.0000 (98.6460)  time: 0.3619  data: 0.0008  max mem: 2501
Train: Epoch[5/5]  [2100/3125]  eta: 0:06:08  Lr: 0.001875  Loss: -0.4362  Acc@1: 87.5000 (87.3721)  Acc@5: 100.0000 (98.6495)  time: 0.3589  data: 0.0005  max mem: 2501
Train: Epoch[5/5]  [2110/3125]  eta: 0:06:04  Lr: 0.001875  Loss: -0.0464  Acc@1: 87.5000 (87.3697)  Acc@5: 100.0000 (98.6559)  time: 0.3576  data: 0.0009  max mem: 2501
Train: Epoch[5/5]  [2120/3125]  eta: 0:06:01  Lr: 0.001875  Loss: -0.4577  Acc@1: 87.5000 (87.3615)  Acc@5: 100.0000 (98.6622)  time: 0.3586  data: 0.0009  max mem: 2501
Train: Epoch[5/5]  [2130/3125]  eta: 0:05:57  Lr: 0.001875  Loss: -0.4513  Acc@1: 87.5000 (87.3563)  Acc@5: 100.0000 (98.6509)  time: 0.3560  data: 0.0007  max mem: 2501
Train: Epoch[5/5]  [2140/3125]  eta: 0:05:54  Lr: 0.001875  Loss: -0.0956  Acc@1: 87.5000 (87.3745)  Acc@5: 100.0000 (98.6543)  time: 0.3618  data: 0.0007  max mem: 2501
Train: Epoch[5/5]  [2150/3125]  eta: 0:05:50  Lr: 0.001875  Loss: -0.3117  Acc@1: 87.5000 (87.3663)  Acc@5: 100.0000 (98.6489)  time: 0.3721  data: 0.0017  max mem: 2501
Train: Epoch[5/5]  [2160/3125]  eta: 0:05:47  Lr: 0.001875  Loss: -0.2838  Acc@1: 81.2500 (87.3380)  Acc@5: 100.0000 (98.6465)  time: 0.3635  data: 0.0019  max mem: 2501
Train: Epoch[5/5]  [2170/3125]  eta: 0:05:43  Lr: 0.001875  Loss: -0.6258  Acc@1: 87.5000 (87.3330)  Acc@5: 100.0000 (98.6469)  time: 0.3559  data: 0.0008  max mem: 2501
Train: Epoch[5/5]  [2180/3125]  eta: 0:05:39  Lr: 0.001875  Loss: -0.1343  Acc@1: 87.5000 (87.3252)  Acc@5: 100.0000 (98.6503)  time: 0.3651  data: 0.0007  max mem: 2501
Train: Epoch[5/5]  [2190/3125]  eta: 0:05:36  Lr: 0.001875  Loss: -0.2443  Acc@1: 87.5000 (87.3317)  Acc@5: 100.0000 (98.6507)  time: 0.3583  data: 0.0005  max mem: 2501
Train: Epoch[5/5]  [2200/3125]  eta: 0:05:32  Lr: 0.001875  Loss: -0.7297  Acc@1: 87.5000 (87.3438)  Acc@5: 100.0000 (98.6455)  time: 0.3509  data: 0.0005  max mem: 2501
Train: Epoch[5/5]  [2210/3125]  eta: 0:05:29  Lr: 0.001875  Loss: -0.4088  Acc@1: 87.5000 (87.3502)  Acc@5: 100.0000 (98.6460)  time: 0.3605  data: 0.0005  max mem: 2501
Train: Epoch[5/5]  [2220/3125]  eta: 0:05:25  Lr: 0.001875  Loss: -0.4133  Acc@1: 87.5000 (87.3509)  Acc@5: 100.0000 (98.6493)  time: 0.3565  data: 0.0007  max mem: 2501
Train: Epoch[5/5]  [2230/3125]  eta: 0:05:21  Lr: 0.001875  Loss: -0.7314  Acc@1: 87.5000 (87.3655)  Acc@5: 100.0000 (98.6497)  time: 0.3528  data: 0.0007  max mem: 2501
Train: Epoch[5/5]  [2240/3125]  eta: 0:05:18  Lr: 0.001875  Loss: -0.6659  Acc@1: 87.5000 (87.3578)  Acc@5: 100.0000 (98.6502)  time: 0.3625  data: 0.0006  max mem: 2501
Train: Epoch[5/5]  [2250/3125]  eta: 0:05:14  Lr: 0.001875  Loss: -0.7081  Acc@1: 87.5000 (87.3695)  Acc@5: 100.0000 (98.6506)  time: 0.3655  data: 0.0008  max mem: 2501
Train: Epoch[5/5]  [2260/3125]  eta: 0:05:11  Lr: 0.001875  Loss: -0.1840  Acc@1: 87.5000 (87.3922)  Acc@5: 100.0000 (98.6538)  time: 0.3564  data: 0.0009  max mem: 2501
Train: Epoch[5/5]  [2270/3125]  eta: 0:05:07  Lr: 0.001875  Loss: -0.3371  Acc@1: 93.7500 (87.3982)  Acc@5: 100.0000 (98.6570)  time: 0.3533  data: 0.0006  max mem: 2501
Train: Epoch[5/5]  [2280/3125]  eta: 0:05:03  Lr: 0.001875  Loss: 0.3633  Acc@1: 81.2500 (87.3712)  Acc@5: 100.0000 (98.6574)  time: 0.3631  data: 0.0008  max mem: 2501
Train: Epoch[5/5]  [2290/3125]  eta: 0:05:00  Lr: 0.001875  Loss: -0.1785  Acc@1: 87.5000 (87.3909)  Acc@5: 100.0000 (98.6605)  time: 0.3593  data: 0.0007  max mem: 2501
Train: Epoch[5/5]  [2300/3125]  eta: 0:04:56  Lr: 0.001875  Loss: -0.2822  Acc@1: 87.5000 (87.3968)  Acc@5: 100.0000 (98.6528)  time: 0.3551  data: 0.0006  max mem: 2501
Train: Epoch[5/5]  [2310/3125]  eta: 0:04:53  Lr: 0.001875  Loss: -0.5149  Acc@1: 87.5000 (87.4053)  Acc@5: 100.0000 (98.6559)  time: 0.3595  data: 0.0006  max mem: 2501
Train: Epoch[5/5]  [2320/3125]  eta: 0:04:49  Lr: 0.001875  Loss: -0.4520  Acc@1: 87.5000 (87.4058)  Acc@5: 100.0000 (98.6563)  time: 0.3564  data: 0.0005  max mem: 2501
Train: Epoch[5/5]  [2330/3125]  eta: 0:04:45  Lr: 0.001875  Loss: -0.6420  Acc@1: 87.5000 (87.3874)  Acc@5: 100.0000 (98.6486)  time: 0.3606  data: 0.0005  max mem: 2501
Train: Epoch[5/5]  [2340/3125]  eta: 0:04:42  Lr: 0.001875  Loss: -0.3113  Acc@1: 87.5000 (87.3932)  Acc@5: 100.0000 (98.6464)  time: 0.3688  data: 0.0004  max mem: 2501
Train: Epoch[5/5]  [2350/3125]  eta: 0:04:38  Lr: 0.001875  Loss: -0.5610  Acc@1: 87.5000 (87.3937)  Acc@5: 100.0000 (98.6522)  time: 0.3591  data: 0.0010  max mem: 2501
Train: Epoch[5/5]  [2360/3125]  eta: 0:04:35  Lr: 0.001875  Loss: -0.3431  Acc@1: 87.5000 (87.4100)  Acc@5: 100.0000 (98.6579)  time: 0.3538  data: 0.0011  max mem: 2501
Train: Epoch[5/5]  [2370/3125]  eta: 0:04:31  Lr: 0.001875  Loss: 0.0857  Acc@1: 87.5000 (87.4104)  Acc@5: 100.0000 (98.6609)  time: 0.3627  data: 0.0011  max mem: 2501
Train: Epoch[5/5]  [2380/3125]  eta: 0:04:27  Lr: 0.001875  Loss: -0.5565  Acc@1: 87.5000 (87.4186)  Acc@5: 100.0000 (98.6665)  time: 0.3571  data: 0.0011  max mem: 2501
Train: Epoch[5/5]  [2390/3125]  eta: 0:04:24  Lr: 0.001875  Loss: -0.3466  Acc@1: 87.5000 (87.4216)  Acc@5: 100.0000 (98.6695)  time: 0.3515  data: 0.0005  max mem: 2501
Train: Epoch[5/5]  [2400/3125]  eta: 0:04:20  Lr: 0.001875  Loss: -0.4331  Acc@1: 87.5000 (87.4297)  Acc@5: 100.0000 (98.6672)  time: 0.3620  data: 0.0004  max mem: 2501
Train: Epoch[5/5]  [2410/3125]  eta: 0:04:17  Lr: 0.001875  Loss: -0.2892  Acc@1: 87.5000 (87.4300)  Acc@5: 100.0000 (98.6598)  time: 0.3582  data: 0.0010  max mem: 2501
Train: Epoch[5/5]  [2420/3125]  eta: 0:04:13  Lr: 0.001875  Loss: -0.3981  Acc@1: 87.5000 (87.4355)  Acc@5: 100.0000 (98.6627)  time: 0.3533  data: 0.0011  max mem: 2501
Train: Epoch[5/5]  [2430/3125]  eta: 0:04:09  Lr: 0.001875  Loss: -0.6088  Acc@1: 87.5000 (87.4280)  Acc@5: 100.0000 (98.6605)  time: 0.3628  data: 0.0013  max mem: 2501
Train: Epoch[5/5]  [2440/3125]  eta: 0:04:06  Lr: 0.001875  Loss: -0.3320  Acc@1: 87.5000 (87.4283)  Acc@5: 100.0000 (98.6609)  time: 0.3659  data: 0.0013  max mem: 2501
Train: Epoch[5/5]  [2450/3125]  eta: 0:04:02  Lr: 0.001875  Loss: -0.5710  Acc@1: 87.5000 (87.4388)  Acc@5: 100.0000 (98.6664)  time: 0.3577  data: 0.0006  max mem: 2501
Train: Epoch[5/5]  [2460/3125]  eta: 0:03:59  Lr: 0.001875  Loss: -0.3884  Acc@1: 87.5000 (87.4238)  Acc@5: 100.0000 (98.6692)  time: 0.3535  data: 0.0005  max mem: 2501
Train: Epoch[5/5]  [2470/3125]  eta: 0:03:55  Lr: 0.001875  Loss: -0.0506  Acc@1: 87.5000 (87.4266)  Acc@5: 100.0000 (98.6696)  time: 0.3576  data: 0.0004  max mem: 2501
Train: Epoch[5/5]  [2480/3125]  eta: 0:03:51  Lr: 0.001875  Loss: -0.0637  Acc@1: 87.5000 (87.4093)  Acc@5: 100.0000 (98.6674)  time: 0.3555  data: 0.0004  max mem: 2501
Train: Epoch[5/5]  [2490/3125]  eta: 0:03:48  Lr: 0.001875  Loss: -0.3805  Acc@1: 87.5000 (87.4197)  Acc@5: 100.0000 (98.6652)  time: 0.3552  data: 0.0005  max mem: 2501
Train: Epoch[5/5]  [2500/3125]  eta: 0:03:44  Lr: 0.001875  Loss: -0.7486  Acc@1: 87.5000 (87.4275)  Acc@5: 100.0000 (98.6680)  time: 0.3587  data: 0.0005  max mem: 2501
Train: Epoch[5/5]  [2510/3125]  eta: 0:03:41  Lr: 0.001875  Loss: -0.3874  Acc@1: 87.5000 (87.4278)  Acc@5: 100.0000 (98.6684)  time: 0.3562  data: 0.0007  max mem: 2501
Train: Epoch[5/5]  [2520/3125]  eta: 0:03:37  Lr: 0.001875  Loss: -0.6823  Acc@1: 87.5000 (87.4355)  Acc@5: 100.0000 (98.6637)  time: 0.3571  data: 0.0015  max mem: 2501
Train: Epoch[5/5]  [2530/3125]  eta: 0:03:33  Lr: 0.001875  Loss: -0.3136  Acc@1: 93.7500 (87.4630)  Acc@5: 100.0000 (98.6690)  time: 0.3641  data: 0.0022  max mem: 2501
Train: Epoch[5/5]  [2540/3125]  eta: 0:03:30  Lr: 0.001875  Loss: -0.5016  Acc@1: 93.7500 (87.4754)  Acc@5: 100.0000 (98.6742)  time: 0.3641  data: 0.0015  max mem: 2501
Train: Epoch[5/5]  [2550/3125]  eta: 0:03:26  Lr: 0.001875  Loss: -0.5716  Acc@1: 87.5000 (87.4902)  Acc@5: 100.0000 (98.6721)  time: 0.3577  data: 0.0007  max mem: 2501
Train: Epoch[5/5]  [2560/3125]  eta: 0:03:23  Lr: 0.001875  Loss: -0.5326  Acc@1: 87.5000 (87.4927)  Acc@5: 100.0000 (98.6700)  time: 0.3612  data: 0.0006  max mem: 2501
Train: Epoch[5/5]  [2570/3125]  eta: 0:03:19  Lr: 0.001875  Loss: -0.2239  Acc@1: 87.5000 (87.4878)  Acc@5: 100.0000 (98.6678)  time: 0.3583  data: 0.0007  max mem: 2501
Train: Epoch[5/5]  [2580/3125]  eta: 0:03:15  Lr: 0.001875  Loss: -0.4068  Acc@1: 87.5000 (87.5048)  Acc@5: 100.0000 (98.6706)  time: 0.3513  data: 0.0006  max mem: 2501
Train: Epoch[5/5]  [2590/3125]  eta: 0:03:12  Lr: 0.001875  Loss: -0.8008  Acc@1: 87.5000 (87.4976)  Acc@5: 100.0000 (98.6709)  time: 0.3618  data: 0.0005  max mem: 2501
Train: Epoch[5/5]  [2600/3125]  eta: 0:03:08  Lr: 0.001875  Loss: -0.1642  Acc@1: 87.5000 (87.4928)  Acc@5: 100.0000 (98.6688)  time: 0.3614  data: 0.0005  max mem: 2501
Train: Epoch[5/5]  [2610/3125]  eta: 0:03:05  Lr: 0.001875  Loss: 0.0274  Acc@1: 87.5000 (87.4904)  Acc@5: 100.0000 (98.6715)  time: 0.3546  data: 0.0006  max mem: 2501
Train: Epoch[5/5]  [2620/3125]  eta: 0:03:01  Lr: 0.001875  Loss: -0.2902  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (98.6766)  time: 0.3618  data: 0.0008  max mem: 2501
Train: Epoch[5/5]  [2630/3125]  eta: 0:02:57  Lr: 0.001875  Loss: 0.0004  Acc@1: 87.5000 (87.4905)  Acc@5: 100.0000 (98.6697)  time: 0.3663  data: 0.0013  max mem: 2501
Train: Epoch[5/5]  [2640/3125]  eta: 0:02:54  Lr: 0.001875  Loss: -0.2075  Acc@1: 87.5000 (87.4882)  Acc@5: 100.0000 (98.6700)  time: 0.3566  data: 0.0011  max mem: 2501
Train: Epoch[5/5]  [2650/3125]  eta: 0:02:50  Lr: 0.001875  Loss: -0.2108  Acc@1: 87.5000 (87.4835)  Acc@5: 100.0000 (98.6703)  time: 0.3554  data: 0.0008  max mem: 2501
Train: Epoch[5/5]  [2660/3125]  eta: 0:02:47  Lr: 0.001875  Loss: -0.4213  Acc@1: 87.5000 (87.4812)  Acc@5: 100.0000 (98.6706)  time: 0.3598  data: 0.0011  max mem: 2501
Train: Epoch[5/5]  [2670/3125]  eta: 0:02:43  Lr: 0.001875  Loss: -0.5426  Acc@1: 87.5000 (87.4743)  Acc@5: 100.0000 (98.6615)  time: 0.3561  data: 0.0008  max mem: 2501
Train: Epoch[5/5]  [2680/3125]  eta: 0:02:39  Lr: 0.001875  Loss: -0.3410  Acc@1: 87.5000 (87.4627)  Acc@5: 100.0000 (98.6595)  time: 0.3585  data: 0.0006  max mem: 2501
Train: Epoch[5/5]  [2690/3125]  eta: 0:02:36  Lr: 0.001875  Loss: -0.4266  Acc@1: 81.2500 (87.4512)  Acc@5: 100.0000 (98.6622)  time: 0.3595  data: 0.0006  max mem: 2501
Train: Epoch[5/5]  [2700/3125]  eta: 0:02:32  Lr: 0.001875  Loss: -0.2425  Acc@1: 87.5000 (87.4607)  Acc@5: 100.0000 (98.6602)  time: 0.3547  data: 0.0005  max mem: 2501
Train: Epoch[5/5]  [2710/3125]  eta: 0:02:29  Lr: 0.001875  Loss: -0.2289  Acc@1: 87.5000 (87.4608)  Acc@5: 100.0000 (98.6605)  time: 0.3611  data: 0.0005  max mem: 2501
Train: Epoch[5/5]  [2720/3125]  eta: 0:02:25  Lr: 0.001875  Loss: -0.3157  Acc@1: 87.5000 (87.4724)  Acc@5: 100.0000 (98.6586)  time: 0.3697  data: 0.0014  max mem: 2501
Train: Epoch[5/5]  [2730/3125]  eta: 0:02:21  Lr: 0.001875  Loss: -0.5428  Acc@1: 93.7500 (87.4748)  Acc@5: 100.0000 (98.6589)  time: 0.3589  data: 0.0015  max mem: 2501
Train: Epoch[5/5]  [2740/3125]  eta: 0:02:18  Lr: 0.001875  Loss: -0.2237  Acc@1: 87.5000 (87.4635)  Acc@5: 100.0000 (98.6638)  time: 0.3513  data: 0.0006  max mem: 2501
Train: Epoch[5/5]  [2750/3125]  eta: 0:02:14  Lr: 0.001875  Loss: -0.1887  Acc@1: 87.5000 (87.4546)  Acc@5: 100.0000 (98.6619)  time: 0.3632  data: 0.0005  max mem: 2501
Train: Epoch[5/5]  [2760/3125]  eta: 0:02:11  Lr: 0.001875  Loss: -0.3624  Acc@1: 87.5000 (87.4502)  Acc@5: 100.0000 (98.6644)  time: 0.3596  data: 0.0006  max mem: 2501
Train: Epoch[5/5]  [2770/3125]  eta: 0:02:07  Lr: 0.001875  Loss: -0.4235  Acc@1: 87.5000 (87.4594)  Acc@5: 100.0000 (98.6670)  time: 0.3522  data: 0.0008  max mem: 2501
Train: Epoch[5/5]  [2780/3125]  eta: 0:02:04  Lr: 0.001875  Loss: -0.2871  Acc@1: 87.5000 (87.4663)  Acc@5: 100.0000 (98.6561)  time: 0.3624  data: 0.0006  max mem: 2501
Train: Epoch[5/5]  [2790/3125]  eta: 0:02:00  Lr: 0.001875  Loss: -0.4726  Acc@1: 87.5000 (87.4754)  Acc@5: 100.0000 (98.6542)  time: 0.3573  data: 0.0005  max mem: 2501
Train: Epoch[5/5]  [2800/3125]  eta: 0:01:56  Lr: 0.001875  Loss: -0.7396  Acc@1: 87.5000 (87.4888)  Acc@5: 100.0000 (98.6567)  time: 0.3524  data: 0.0005  max mem: 2501
Train: Epoch[5/5]  [2810/3125]  eta: 0:01:53  Lr: 0.001875  Loss: -0.5556  Acc@1: 87.5000 (87.4889)  Acc@5: 100.0000 (98.6548)  time: 0.3619  data: 0.0005  max mem: 2501
Train: Epoch[5/5]  [2820/3125]  eta: 0:01:49  Lr: 0.001875  Loss: -0.4561  Acc@1: 93.7500 (87.5000)  Acc@5: 100.0000 (98.6530)  time: 0.3638  data: 0.0006  max mem: 2501
Train: Epoch[5/5]  [2830/3125]  eta: 0:01:46  Lr: 0.001875  Loss: -0.6214  Acc@1: 93.7500 (87.5132)  Acc@5: 100.0000 (98.6489)  time: 0.3543  data: 0.0005  max mem: 2501
Train: Epoch[5/5]  [2840/3125]  eta: 0:01:42  Lr: 0.001875  Loss: -0.6196  Acc@1: 87.5000 (87.5176)  Acc@5: 100.0000 (98.6514)  time: 0.3508  data: 0.0005  max mem: 2501
Train: Epoch[5/5]  [2850/3125]  eta: 0:01:38  Lr: 0.001875  Loss: -0.5573  Acc@1: 87.5000 (87.5241)  Acc@5: 100.0000 (98.6518)  time: 0.3630  data: 0.0007  max mem: 2501
Train: Epoch[5/5]  [2860/3125]  eta: 0:01:35  Lr: 0.001875  Loss: -0.1410  Acc@1: 87.5000 (87.5218)  Acc@5: 100.0000 (98.6478)  time: 0.3605  data: 0.0007  max mem: 2501
Train: Epoch[5/5]  [2870/3125]  eta: 0:01:31  Lr: 0.001875  Loss: -0.5419  Acc@1: 87.5000 (87.5218)  Acc@5: 100.0000 (98.6438)  time: 0.3523  data: 0.0007  max mem: 2501
Train: Epoch[5/5]  [2880/3125]  eta: 0:01:28  Lr: 0.001875  Loss: -0.4158  Acc@1: 87.5000 (87.5130)  Acc@5: 100.0000 (98.6420)  time: 0.3604  data: 0.0006  max mem: 2501
Train: Epoch[5/5]  [2890/3125]  eta: 0:01:24  Lr: 0.001875  Loss: -0.1114  Acc@1: 87.5000 (87.5130)  Acc@5: 100.0000 (98.6359)  time: 0.3578  data: 0.0011  max mem: 2501
Train: Epoch[5/5]  [2900/3125]  eta: 0:01:20  Lr: 0.001875  Loss: -0.4887  Acc@1: 87.5000 (87.5194)  Acc@5: 100.0000 (98.6406)  time: 0.3538  data: 0.0010  max mem: 2501
Train: Epoch[5/5]  [2910/3125]  eta: 0:01:17  Lr: 0.001875  Loss: -0.6391  Acc@1: 87.5000 (87.5193)  Acc@5: 100.0000 (98.6388)  time: 0.3630  data: 0.0014  max mem: 2501
Train: Epoch[5/5]  [2920/3125]  eta: 0:01:13  Lr: 0.001875  Loss: -0.7147  Acc@1: 87.5000 (87.5171)  Acc@5: 100.0000 (98.6349)  time: 0.3679  data: 0.0017  max mem: 2501
Train: Epoch[5/5]  [2930/3125]  eta: 0:01:10  Lr: 0.001875  Loss: -0.6151  Acc@1: 87.5000 (87.5043)  Acc@5: 100.0000 (98.6353)  time: 0.3585  data: 0.0009  max mem: 2501
Train: Epoch[5/5]  [2940/3125]  eta: 0:01:06  Lr: 0.001875  Loss: 0.0827  Acc@1: 81.2500 (87.4872)  Acc@5: 100.0000 (98.6357)  time: 0.3553  data: 0.0006  max mem: 2501
Train: Epoch[5/5]  [2950/3125]  eta: 0:01:02  Lr: 0.001875  Loss: 0.0563  Acc@1: 87.5000 (87.4873)  Acc@5: 100.0000 (98.6318)  time: 0.3635  data: 0.0006  max mem: 2501
Train: Epoch[5/5]  [2960/3125]  eta: 0:00:59  Lr: 0.001875  Loss: -0.3673  Acc@1: 87.5000 (87.4831)  Acc@5: 100.0000 (98.6322)  time: 0.3580  data: 0.0006  max mem: 2501
Train: Epoch[5/5]  [2970/3125]  eta: 0:00:55  Lr: 0.001875  Loss: -0.3775  Acc@1: 87.5000 (87.4916)  Acc@5: 100.0000 (98.6326)  time: 0.3555  data: 0.0010  max mem: 2501
Train: Epoch[5/5]  [2980/3125]  eta: 0:00:52  Lr: 0.001875  Loss: -0.4447  Acc@1: 87.5000 (87.4937)  Acc@5: 100.0000 (98.6351)  time: 0.3621  data: 0.0009  max mem: 2501
Train: Epoch[5/5]  [2990/3125]  eta: 0:00:48  Lr: 0.001875  Loss: 0.0202  Acc@1: 87.5000 (87.4875)  Acc@5: 100.0000 (98.6355)  time: 0.3578  data: 0.0006  max mem: 2501
Train: Epoch[5/5]  [3000/3125]  eta: 0:00:44  Lr: 0.001875  Loss: -0.4523  Acc@1: 87.5000 (87.4833)  Acc@5: 100.0000 (98.6338)  time: 0.3557  data: 0.0006  max mem: 2501
Train: Epoch[5/5]  [3010/3125]  eta: 0:00:41  Lr: 0.001875  Loss: -0.1058  Acc@1: 87.5000 (87.4938)  Acc@5: 100.0000 (98.6363)  time: 0.3651  data: 0.0017  max mem: 2501
Train: Epoch[5/5]  [3020/3125]  eta: 0:00:37  Lr: 0.001875  Loss: -0.4829  Acc@1: 87.5000 (87.5083)  Acc@5: 100.0000 (98.6366)  time: 0.3695  data: 0.0025  max mem: 2501
Train: Epoch[5/5]  [3030/3125]  eta: 0:00:34  Lr: 0.001875  Loss: -0.5100  Acc@1: 87.5000 (87.4938)  Acc@5: 100.0000 (98.6349)  time: 0.3570  data: 0.0012  max mem: 2501
Train: Epoch[5/5]  [3040/3125]  eta: 0:00:30  Lr: 0.001875  Loss: -0.2680  Acc@1: 87.5000 (87.4897)  Acc@5: 100.0000 (98.6292)  time: 0.3525  data: 0.0005  max mem: 2501
Train: Epoch[5/5]  [3050/3125]  eta: 0:00:26  Lr: 0.001875  Loss: -0.4160  Acc@1: 87.5000 (87.4959)  Acc@5: 100.0000 (98.6316)  time: 0.3637  data: 0.0006  max mem: 2501
Train: Epoch[5/5]  [3060/3125]  eta: 0:00:23  Lr: 0.001875  Loss: -0.6444  Acc@1: 87.5000 (87.5020)  Acc@5: 100.0000 (98.6279)  time: 0.3576  data: 0.0006  max mem: 2501
Train: Epoch[5/5]  [3070/3125]  eta: 0:00:19  Lr: 0.001875  Loss: -0.3705  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (98.6283)  time: 0.3525  data: 0.0005  max mem: 2501
Train: Epoch[5/5]  [3080/3125]  eta: 0:00:16  Lr: 0.001875  Loss: -0.6125  Acc@1: 87.5000 (87.4980)  Acc@5: 100.0000 (98.6267)  time: 0.3620  data: 0.0005  max mem: 2501
Train: Epoch[5/5]  [3090/3125]  eta: 0:00:12  Lr: 0.001875  Loss: -0.5161  Acc@1: 87.5000 (87.4960)  Acc@5: 100.0000 (98.6291)  time: 0.3585  data: 0.0005  max mem: 2501
Train: Epoch[5/5]  [3100/3125]  eta: 0:00:08  Lr: 0.001875  Loss: -0.3328  Acc@1: 87.5000 (87.4899)  Acc@5: 100.0000 (98.6315)  time: 0.3548  data: 0.0005  max mem: 2501
Train: Epoch[5/5]  [3110/3125]  eta: 0:00:05  Lr: 0.001875  Loss: -0.3551  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (98.6299)  time: 0.3658  data: 0.0007  max mem: 2501
Train: Epoch[5/5]  [3120/3125]  eta: 0:00:01  Lr: 0.001875  Loss: -0.4411  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (98.6302)  time: 0.3669  data: 0.0010  max mem: 2501
Train: Epoch[5/5]  [3124/3125]  eta: 0:00:00  Lr: 0.001875  Loss: -0.3916  Acc@1: 87.5000 (87.5020)  Acc@5: 100.0000 (98.6300)  time: 0.3586  data: 0.0010  max mem: 2501
Train: Epoch[5/5] Total time: 0:18:43 (0.3596 s / it)
{0: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 1: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 2: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 3: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 4: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 5: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 6: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 7: {0: 0, 1: 300000, 2: 0, 3: 0, 4: 0}, 8: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 9: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 10: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 11: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 12: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 13: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 14: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 15: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 16: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 17: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 18: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 19: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}}
Averaged stats: Lr: 0.001875  Loss: -0.3916  Acc@1: 87.5000 (87.5020)  Acc@5: 100.0000 (98.6300)
Test: [Task 1]  [   0/1627]  eta: 0:21:17  Loss: 1.2279 (1.2279)  Acc@1: 68.7500 (68.7500)  Acc@5: 93.7500 (93.7500)  time: 0.7849  data: 0.5649  max mem: 2501
Test: [Task 1]  [  10/1627]  eta: 0:07:25  Loss: 1.1963 (1.0893)  Acc@1: 75.0000 (73.2955)  Acc@5: 93.7500 (95.4545)  time: 0.2753  data: 0.0519  max mem: 2501
Test: [Task 1]  [  20/1627]  eta: 0:06:43  Loss: 1.0836 (1.0385)  Acc@1: 75.0000 (75.2976)  Acc@5: 93.7500 (94.9405)  time: 0.2241  data: 0.0005  max mem: 2501
Test: [Task 1]  [  30/1627]  eta: 0:06:31  Loss: 1.0742 (1.0586)  Acc@1: 75.0000 (74.5968)  Acc@5: 93.7500 (94.9597)  time: 0.2282  data: 0.0004  max mem: 2501
Test: [Task 1]  [  40/1627]  eta: 0:06:17  Loss: 1.0950 (1.0672)  Acc@1: 75.0000 (74.2378)  Acc@5: 93.7500 (94.9695)  time: 0.2236  data: 0.0004  max mem: 2501
Test: [Task 1]  [  50/1627]  eta: 0:06:10  Loss: 0.9391 (1.0516)  Acc@1: 75.0000 (74.5098)  Acc@5: 93.7500 (94.9755)  time: 0.2191  data: 0.0004  max mem: 2501
Test: [Task 1]  [  60/1627]  eta: 0:06:04  Loss: 1.1028 (1.0708)  Acc@1: 68.7500 (73.8730)  Acc@5: 93.7500 (94.6721)  time: 0.2232  data: 0.0005  max mem: 2501
Test: [Task 1]  [  70/1627]  eta: 0:06:03  Loss: 1.0205 (1.0627)  Acc@1: 68.7500 (74.2077)  Acc@5: 93.7500 (94.8944)  time: 0.2289  data: 0.0005  max mem: 2501
Test: [Task 1]  [  80/1627]  eta: 0:05:58  Loss: 0.9065 (1.0471)  Acc@1: 75.0000 (74.1512)  Acc@5: 93.7500 (95.0617)  time: 0.2276  data: 0.0004  max mem: 2501
Test: [Task 1]  [  90/1627]  eta: 0:05:53  Loss: 0.9798 (1.0566)  Acc@1: 68.7500 (73.9011)  Acc@5: 93.7500 (95.0549)  time: 0.2181  data: 0.0004  max mem: 2501
Test: [Task 1]  [ 100/1627]  eta: 0:05:50  Loss: 1.1212 (1.0764)  Acc@1: 68.7500 (73.3911)  Acc@5: 93.7500 (94.4926)  time: 0.2202  data: 0.0005  max mem: 2501
Test: [Task 1]  [ 110/1627]  eta: 0:05:47  Loss: 1.1187 (1.0762)  Acc@1: 68.7500 (73.3108)  Acc@5: 93.7500 (94.7635)  time: 0.2248  data: 0.0006  max mem: 2501
Test: [Task 1]  [ 120/1627]  eta: 0:05:45  Loss: 1.1316 (1.0792)  Acc@1: 68.7500 (73.3471)  Acc@5: 93.7500 (94.6281)  time: 0.2308  data: 0.0013  max mem: 2501
Test: [Task 1]  [ 130/1627]  eta: 0:05:43  Loss: 1.1747 (1.0821)  Acc@1: 75.0000 (73.3302)  Acc@5: 93.7500 (94.6088)  time: 0.2304  data: 0.0016  max mem: 2501
Test: [Task 1]  [ 140/1627]  eta: 0:05:40  Loss: 1.0232 (1.0804)  Acc@1: 81.2500 (73.4929)  Acc@5: 93.7500 (94.5479)  time: 0.2261  data: 0.0010  max mem: 2501
Test: [Task 1]  [ 150/1627]  eta: 0:05:37  Loss: 0.8181 (1.0665)  Acc@1: 81.2500 (73.8411)  Acc@5: 93.7500 (94.6192)  time: 0.2221  data: 0.0005  max mem: 2501
Test: [Task 1]  [ 160/1627]  eta: 0:05:34  Loss: 0.8180 (1.0595)  Acc@1: 75.0000 (74.2236)  Acc@5: 100.0000 (94.6817)  time: 0.2203  data: 0.0006  max mem: 2501
Test: [Task 1]  [ 170/1627]  eta: 0:05:31  Loss: 0.8875 (1.0535)  Acc@1: 75.0000 (74.3421)  Acc@5: 93.7500 (94.6637)  time: 0.2248  data: 0.0007  max mem: 2501
Test: [Task 1]  [ 180/1627]  eta: 0:05:30  Loss: 1.0039 (1.0587)  Acc@1: 75.0000 (74.1367)  Acc@5: 93.7500 (94.6823)  time: 0.2316  data: 0.0009  max mem: 2501
Test: [Task 1]  [ 190/1627]  eta: 0:05:27  Loss: 1.0151 (1.0539)  Acc@1: 75.0000 (74.2474)  Acc@5: 93.7500 (94.7317)  time: 0.2272  data: 0.0010  max mem: 2501
Test: [Task 1]  [ 200/1627]  eta: 0:05:24  Loss: 1.0532 (1.0548)  Acc@1: 75.0000 (74.1294)  Acc@5: 93.7500 (94.7450)  time: 0.2165  data: 0.0007  max mem: 2501
Test: [Task 1]  [ 210/1627]  eta: 0:05:21  Loss: 0.9873 (1.0515)  Acc@1: 75.0000 (74.3483)  Acc@5: 93.7500 (94.7275)  time: 0.2198  data: 0.0004  max mem: 2501
Test: [Task 1]  [ 220/1627]  eta: 0:05:19  Loss: 0.9279 (1.0565)  Acc@1: 81.2500 (74.2081)  Acc@5: 93.7500 (94.7115)  time: 0.2241  data: 0.0004  max mem: 2501
Test: [Task 1]  [ 230/1627]  eta: 0:05:17  Loss: 0.9873 (1.0515)  Acc@1: 75.0000 (74.3777)  Acc@5: 93.7500 (94.7511)  time: 0.2272  data: 0.0004  max mem: 2501
Test: [Task 1]  [ 240/1627]  eta: 0:05:14  Loss: 0.9679 (1.0462)  Acc@1: 75.0000 (74.5073)  Acc@5: 93.7500 (94.7614)  time: 0.2235  data: 0.0007  max mem: 2501
Test: [Task 1]  [ 250/1627]  eta: 0:05:11  Loss: 0.9266 (1.0510)  Acc@1: 75.0000 (74.4273)  Acc@5: 93.7500 (94.6962)  time: 0.2208  data: 0.0011  max mem: 2501
Test: [Task 1]  [ 260/1627]  eta: 0:05:09  Loss: 1.0356 (1.0509)  Acc@1: 75.0000 (74.4732)  Acc@5: 93.7500 (94.6360)  time: 0.2232  data: 0.0008  max mem: 2501
Test: [Task 1]  [ 270/1627]  eta: 0:05:07  Loss: 0.9239 (1.0442)  Acc@1: 81.2500 (74.6541)  Acc@5: 93.7500 (94.7417)  time: 0.2281  data: 0.0004  max mem: 2501
Test: [Task 1]  [ 280/1627]  eta: 0:05:05  Loss: 0.8811 (1.0438)  Acc@1: 75.0000 (74.6664)  Acc@5: 93.7500 (94.6619)  time: 0.2332  data: 0.0004  max mem: 2501
Test: [Task 1]  [ 290/1627]  eta: 0:05:02  Loss: 1.0241 (1.0430)  Acc@1: 75.0000 (74.8282)  Acc@5: 93.7500 (94.7165)  time: 0.2251  data: 0.0005  max mem: 2501
Test: [Task 1]  [ 300/1627]  eta: 0:05:00  Loss: 0.9302 (1.0410)  Acc@1: 81.2500 (74.8131)  Acc@5: 100.0000 (94.8090)  time: 0.2171  data: 0.0005  max mem: 2501
Test: [Task 1]  [ 310/1627]  eta: 0:04:57  Loss: 0.8943 (1.0410)  Acc@1: 81.2500 (74.9196)  Acc@5: 100.0000 (94.8151)  time: 0.2191  data: 0.0004  max mem: 2501
Test: [Task 1]  [ 320/1627]  eta: 0:04:55  Loss: 0.9950 (1.0400)  Acc@1: 75.0000 (74.9221)  Acc@5: 93.7500 (94.8209)  time: 0.2243  data: 0.0005  max mem: 2501
Test: [Task 1]  [ 330/1627]  eta: 0:04:53  Loss: 0.9014 (1.0380)  Acc@1: 75.0000 (74.9056)  Acc@5: 93.7500 (94.8640)  time: 0.2306  data: 0.0005  max mem: 2501
Test: [Task 1]  [ 340/1627]  eta: 0:04:50  Loss: 0.9011 (1.0394)  Acc@1: 75.0000 (74.8717)  Acc@5: 100.0000 (94.9230)  time: 0.2254  data: 0.0005  max mem: 2501
Test: [Task 1]  [ 350/1627]  eta: 0:04:48  Loss: 0.9280 (1.0406)  Acc@1: 75.0000 (74.8575)  Acc@5: 93.7500 (94.8540)  time: 0.2188  data: 0.0005  max mem: 2501
Test: [Task 1]  [ 360/1627]  eta: 0:04:46  Loss: 0.9280 (1.0395)  Acc@1: 75.0000 (74.9307)  Acc@5: 93.7500 (94.8061)  time: 0.2230  data: 0.0004  max mem: 2501
Test: [Task 1]  [ 370/1627]  eta: 0:04:44  Loss: 0.9617 (1.0395)  Acc@1: 81.2500 (74.8821)  Acc@5: 93.7500 (94.8282)  time: 0.2309  data: 0.0008  max mem: 2501
Test: [Task 1]  [ 380/1627]  eta: 0:04:41  Loss: 0.9798 (1.0378)  Acc@1: 75.0000 (75.0000)  Acc@5: 100.0000 (94.8819)  time: 0.2267  data: 0.0010  max mem: 2501
Test: [Task 1]  [ 390/1627]  eta: 0:04:39  Loss: 0.9689 (1.0393)  Acc@1: 75.0000 (75.0160)  Acc@5: 93.7500 (94.8529)  time: 0.2163  data: 0.0006  max mem: 2501
Test: [Task 1]  [ 400/1627]  eta: 0:04:36  Loss: 1.0804 (1.0405)  Acc@1: 75.0000 (74.9221)  Acc@5: 93.7500 (94.8722)  time: 0.2200  data: 0.0004  max mem: 2501
Test: [Task 1]  [ 410/1627]  eta: 0:04:34  Loss: 0.8969 (1.0399)  Acc@1: 68.7500 (75.0000)  Acc@5: 93.7500 (94.8297)  time: 0.2245  data: 0.0004  max mem: 2501
Test: [Task 1]  [ 420/1627]  eta: 0:04:32  Loss: 0.8838 (1.0380)  Acc@1: 81.2500 (75.1188)  Acc@5: 100.0000 (94.8931)  time: 0.2299  data: 0.0005  max mem: 2501
Test: [Task 1]  [ 430/1627]  eta: 0:04:30  Loss: 0.8574 (1.0359)  Acc@1: 81.2500 (75.1595)  Acc@5: 100.0000 (94.9101)  time: 0.2292  data: 0.0013  max mem: 2501
Test: [Task 1]  [ 440/1627]  eta: 0:04:28  Loss: 1.0130 (1.0347)  Acc@1: 75.0000 (75.1701)  Acc@5: 100.0000 (94.9546)  time: 0.2258  data: 0.0012  max mem: 2501
Test: [Task 1]  [ 450/1627]  eta: 0:04:25  Loss: 1.0569 (1.0377)  Acc@1: 68.7500 (75.0000)  Acc@5: 93.7500 (94.8725)  time: 0.2219  data: 0.0004  max mem: 2501
Test: [Task 1]  [ 460/1627]  eta: 0:04:23  Loss: 1.0938 (1.0376)  Acc@1: 68.7500 (74.9593)  Acc@5: 93.7500 (94.8753)  time: 0.2188  data: 0.0004  max mem: 2501
Test: [Task 1]  [ 470/1627]  eta: 0:04:20  Loss: 0.9603 (1.0350)  Acc@1: 75.0000 (75.0000)  Acc@5: 100.0000 (94.8912)  time: 0.2221  data: 0.0004  max mem: 2501
Test: [Task 1]  [ 480/1627]  eta: 0:04:18  Loss: 0.9777 (1.0388)  Acc@1: 75.0000 (74.8441)  Acc@5: 100.0000 (94.9194)  time: 0.2284  data: 0.0004  max mem: 2501
Test: [Task 1]  [ 490/1627]  eta: 0:04:16  Loss: 1.0572 (1.0401)  Acc@1: 68.7500 (74.7581)  Acc@5: 100.0000 (94.9211)  time: 0.2259  data: 0.0004  max mem: 2501
Test: [Task 1]  [ 500/1627]  eta: 0:04:13  Loss: 0.9434 (1.0415)  Acc@1: 75.0000 (74.7255)  Acc@5: 93.7500 (94.8852)  time: 0.2178  data: 0.0004  max mem: 2501
Test: [Task 1]  [ 510/1627]  eta: 0:04:11  Loss: 1.0514 (1.0462)  Acc@1: 75.0000 (74.6942)  Acc@5: 93.7500 (94.8386)  time: 0.2209  data: 0.0004  max mem: 2501
Test: [Task 1]  [ 520/1627]  eta: 0:04:09  Loss: 1.1984 (1.0527)  Acc@1: 68.7500 (74.6041)  Acc@5: 93.7500 (94.7817)  time: 0.2251  data: 0.0005  max mem: 2501
Test: [Task 1]  [ 530/1627]  eta: 0:04:07  Loss: 1.0375 (1.0489)  Acc@1: 75.0000 (74.7175)  Acc@5: 93.7500 (94.7976)  time: 0.2302  data: 0.0004  max mem: 2501
Test: [Task 1]  [ 540/1627]  eta: 0:04:04  Loss: 0.9712 (1.0496)  Acc@1: 75.0000 (74.7343)  Acc@5: 93.7500 (94.7782)  time: 0.2258  data: 0.0006  max mem: 2501
Test: [Task 1]  [ 550/1627]  eta: 0:04:02  Loss: 1.1344 (1.0510)  Acc@1: 75.0000 (74.7164)  Acc@5: 93.7500 (94.7709)  time: 0.2204  data: 0.0007  max mem: 2501
Test: [Task 1]  [ 560/1627]  eta: 0:04:00  Loss: 1.1673 (1.0535)  Acc@1: 75.0000 (74.6881)  Acc@5: 93.7500 (94.7750)  time: 0.2227  data: 0.0005  max mem: 2501
Test: [Task 1]  [ 570/1627]  eta: 0:03:58  Loss: 1.0735 (1.0505)  Acc@1: 75.0000 (74.7811)  Acc@5: 93.7500 (94.8008)  time: 0.2278  data: 0.0004  max mem: 2501
Test: [Task 1]  [ 580/1627]  eta: 0:03:56  Loss: 0.9710 (1.0514)  Acc@1: 75.0000 (74.7203)  Acc@5: 100.0000 (94.8257)  time: 0.2352  data: 0.0008  max mem: 2501
Test: [Task 1]  [ 590/1627]  eta: 0:03:53  Loss: 1.0392 (1.0508)  Acc@1: 68.7500 (74.6722)  Acc@5: 100.0000 (94.8498)  time: 0.2275  data: 0.0010  max mem: 2501
Test: [Task 1]  [ 600/1627]  eta: 0:03:51  Loss: 0.9908 (1.0519)  Acc@1: 75.0000 (74.6360)  Acc@5: 100.0000 (94.8627)  time: 0.2166  data: 0.0007  max mem: 2501
Test: [Task 1]  [ 610/1627]  eta: 0:03:49  Loss: 0.9908 (1.0506)  Acc@1: 81.2500 (74.7647)  Acc@5: 93.7500 (94.8650)  time: 0.2210  data: 0.0004  max mem: 2501
Test: [Task 1]  [ 620/1627]  eta: 0:03:46  Loss: 0.9531 (1.0514)  Acc@1: 81.2500 (74.8088)  Acc@5: 93.7500 (94.8068)  time: 0.2254  data: 0.0005  max mem: 2501
Test: [Task 1]  [ 630/1627]  eta: 0:03:44  Loss: 0.9231 (1.0514)  Acc@1: 81.2500 (74.8316)  Acc@5: 93.7500 (94.8098)  time: 0.2273  data: 0.0005  max mem: 2501
Test: [Task 1]  [ 640/1627]  eta: 0:03:42  Loss: 0.8535 (1.0510)  Acc@1: 81.2500 (74.8147)  Acc@5: 93.7500 (94.7738)  time: 0.2238  data: 0.0006  max mem: 2501
Test: [Task 1]  [ 650/1627]  eta: 0:03:40  Loss: 0.9814 (1.0501)  Acc@1: 75.0000 (74.8272)  Acc@5: 100.0000 (94.8253)  time: 0.2201  data: 0.0006  max mem: 2501
Test: [Task 1]  [ 660/1627]  eta: 0:03:37  Loss: 0.9765 (1.0487)  Acc@1: 75.0000 (74.8676)  Acc@5: 100.0000 (94.8657)  time: 0.2227  data: 0.0004  max mem: 2501
Test: [Task 1]  [ 670/1627]  eta: 0:03:35  Loss: 1.0034 (1.0492)  Acc@1: 75.0000 (74.8882)  Acc@5: 93.7500 (94.8305)  time: 0.2289  data: 0.0011  max mem: 2501
Test: [Task 1]  [ 680/1627]  eta: 0:03:33  Loss: 1.0607 (1.0495)  Acc@1: 75.0000 (74.8532)  Acc@5: 87.5000 (94.7504)  time: 0.2256  data: 0.0010  max mem: 2501
Test: [Task 1]  [ 690/1627]  eta: 0:03:30  Loss: 0.9496 (1.0475)  Acc@1: 75.0000 (74.9186)  Acc@5: 93.7500 (94.7721)  time: 0.2169  data: 0.0006  max mem: 2501
Test: [Task 1]  [ 700/1627]  eta: 0:03:28  Loss: 1.0232 (1.0481)  Acc@1: 75.0000 (74.9287)  Acc@5: 93.7500 (94.7753)  time: 0.2205  data: 0.0008  max mem: 2501
Test: [Task 1]  [ 710/1627]  eta: 0:03:26  Loss: 0.9380 (1.0461)  Acc@1: 75.0000 (74.9648)  Acc@5: 93.7500 (94.7961)  time: 0.2228  data: 0.0006  max mem: 2501
Test: [Task 1]  [ 720/1627]  eta: 0:03:24  Loss: 0.9297 (1.0440)  Acc@1: 81.2500 (75.0173)  Acc@5: 93.7500 (94.8162)  time: 0.2295  data: 0.0005  max mem: 2501
Test: [Task 1]  [ 730/1627]  eta: 0:03:21  Loss: 0.9483 (1.0452)  Acc@1: 81.2500 (74.9487)  Acc@5: 93.7500 (94.8102)  time: 0.2269  data: 0.0010  max mem: 2501
Test: [Task 1]  [ 740/1627]  eta: 0:03:19  Loss: 1.0397 (1.0467)  Acc@1: 68.7500 (74.9325)  Acc@5: 93.7500 (94.7790)  time: 0.2278  data: 0.0018  max mem: 2501
Test: [Task 1]  [ 750/1627]  eta: 0:03:17  Loss: 0.9572 (1.0457)  Acc@1: 81.2500 (75.0333)  Acc@5: 93.7500 (94.7820)  time: 0.2274  data: 0.0020  max mem: 2501
Test: [Task 1]  [ 760/1627]  eta: 0:03:15  Loss: 0.9971 (1.0486)  Acc@1: 75.0000 (74.9425)  Acc@5: 93.7500 (94.7191)  time: 0.2183  data: 0.0012  max mem: 2501
Test: [Task 1]  [ 770/1627]  eta: 0:03:12  Loss: 0.8415 (1.0454)  Acc@1: 75.0000 (75.0567)  Acc@5: 93.7500 (94.7471)  time: 0.2232  data: 0.0004  max mem: 2501
Test: [Task 1]  [ 780/1627]  eta: 0:03:10  Loss: 0.7565 (1.0436)  Acc@1: 87.5000 (75.1440)  Acc@5: 100.0000 (94.7823)  time: 0.2330  data: 0.0007  max mem: 2501
Test: [Task 1]  [ 790/1627]  eta: 0:03:08  Loss: 0.8211 (1.0459)  Acc@1: 81.2500 (75.0790)  Acc@5: 93.7500 (94.7456)  time: 0.2272  data: 0.0007  max mem: 2501
Test: [Task 1]  [ 800/1627]  eta: 0:03:06  Loss: 0.9166 (1.0447)  Acc@1: 75.0000 (75.0624)  Acc@5: 93.7500 (94.7800)  time: 0.2167  data: 0.0005  max mem: 2501
Test: [Task 1]  [ 810/1627]  eta: 0:03:03  Loss: 0.9026 (1.0440)  Acc@1: 81.2500 (75.1618)  Acc@5: 100.0000 (94.8135)  time: 0.2219  data: 0.0006  max mem: 2501
Test: [Task 1]  [ 820/1627]  eta: 0:03:01  Loss: 0.8557 (1.0427)  Acc@1: 81.2500 (75.2208)  Acc@5: 100.0000 (94.8234)  time: 0.2255  data: 0.0005  max mem: 2501
Test: [Task 1]  [ 830/1627]  eta: 0:02:59  Loss: 0.8621 (1.0426)  Acc@1: 81.2500 (75.1955)  Acc@5: 100.0000 (94.8406)  time: 0.2279  data: 0.0005  max mem: 2501
Test: [Task 1]  [ 840/1627]  eta: 0:02:57  Loss: 0.9021 (1.0402)  Acc@1: 75.0000 (75.2155)  Acc@5: 100.0000 (94.8796)  time: 0.2240  data: 0.0007  max mem: 2501
Test: [Task 1]  [ 850/1627]  eta: 0:02:54  Loss: 0.9083 (1.0411)  Acc@1: 75.0000 (75.1910)  Acc@5: 100.0000 (94.8810)  time: 0.2192  data: 0.0006  max mem: 2501
Test: [Task 1]  [ 860/1627]  eta: 0:02:52  Loss: 0.9083 (1.0405)  Acc@1: 75.0000 (75.2250)  Acc@5: 100.0000 (94.9187)  time: 0.2219  data: 0.0004  max mem: 2501
Test: [Task 1]  [ 870/1627]  eta: 0:02:50  Loss: 0.9369 (1.0388)  Acc@1: 81.2500 (75.2870)  Acc@5: 100.0000 (94.9268)  time: 0.2293  data: 0.0004  max mem: 2501
Test: [Task 1]  [ 880/1627]  eta: 0:02:48  Loss: 1.0350 (1.0410)  Acc@1: 75.0000 (75.1561)  Acc@5: 100.0000 (94.9560)  time: 0.2330  data: 0.0020  max mem: 2501
Test: [Task 1]  [ 890/1627]  eta: 0:02:46  Loss: 1.1590 (1.0426)  Acc@1: 68.7500 (75.1613)  Acc@5: 100.0000 (94.9355)  time: 0.2365  data: 0.0021  max mem: 2501
Test: [Task 1]  [ 900/1627]  eta: 0:02:43  Loss: 1.0721 (1.0434)  Acc@1: 75.0000 (75.1318)  Acc@5: 93.7500 (94.9223)  time: 0.2295  data: 0.0014  max mem: 2501
Test: [Task 1]  [ 910/1627]  eta: 0:02:41  Loss: 1.0211 (1.0438)  Acc@1: 75.0000 (75.2058)  Acc@5: 93.7500 (94.8889)  time: 0.2180  data: 0.0012  max mem: 2501
Test: [Task 1]  [ 920/1627]  eta: 0:02:39  Loss: 0.9713 (1.0431)  Acc@1: 81.2500 (75.2239)  Acc@5: 93.7500 (94.8969)  time: 0.2218  data: 0.0006  max mem: 2501
Test: [Task 1]  [ 930/1627]  eta: 0:02:36  Loss: 0.9871 (1.0435)  Acc@1: 75.0000 (75.1947)  Acc@5: 100.0000 (94.8845)  time: 0.2279  data: 0.0006  max mem: 2501
Test: [Task 1]  [ 940/1627]  eta: 0:02:34  Loss: 1.0246 (1.0424)  Acc@1: 75.0000 (75.2125)  Acc@5: 100.0000 (94.9123)  time: 0.2287  data: 0.0007  max mem: 2501
Test: [Task 1]  [ 950/1627]  eta: 0:02:32  Loss: 1.0993 (1.0432)  Acc@1: 68.7500 (75.1577)  Acc@5: 100.0000 (94.9330)  time: 0.2209  data: 0.0008  max mem: 2501
Test: [Task 1]  [ 960/1627]  eta: 0:02:30  Loss: 1.0472 (1.0427)  Acc@1: 68.7500 (75.1626)  Acc@5: 100.0000 (94.9467)  time: 0.2207  data: 0.0004  max mem: 2501
Test: [Task 1]  [ 970/1627]  eta: 0:02:27  Loss: 0.8656 (1.0419)  Acc@1: 81.2500 (75.1931)  Acc@5: 93.7500 (94.9408)  time: 0.2242  data: 0.0004  max mem: 2501
Test: [Task 1]  [ 980/1627]  eta: 0:02:25  Loss: 1.0616 (1.0426)  Acc@1: 68.7500 (75.1465)  Acc@5: 93.7500 (94.9286)  time: 0.2271  data: 0.0004  max mem: 2501
Test: [Task 1]  [ 990/1627]  eta: 0:02:23  Loss: 1.1403 (1.0451)  Acc@1: 68.7500 (75.1135)  Acc@5: 93.7500 (94.9041)  time: 0.2246  data: 0.0009  max mem: 2501
Test: [Task 1]  [1000/1627]  eta: 0:02:21  Loss: 1.2688 (1.0459)  Acc@1: 75.0000 (75.0999)  Acc@5: 93.7500 (94.8739)  time: 0.2201  data: 0.0010  max mem: 2501
Test: [Task 1]  [1010/1627]  eta: 0:02:18  Loss: 1.0805 (1.0457)  Acc@1: 75.0000 (75.0989)  Acc@5: 93.7500 (94.8689)  time: 0.2230  data: 0.0004  max mem: 2501
Test: [Task 1]  [1020/1627]  eta: 0:02:16  Loss: 1.0223 (1.0456)  Acc@1: 75.0000 (75.0735)  Acc@5: 93.7500 (94.8641)  time: 0.2298  data: 0.0005  max mem: 2501
Test: [Task 1]  [1030/1627]  eta: 0:02:14  Loss: 0.8711 (1.0432)  Acc@1: 81.2500 (75.1455)  Acc@5: 93.7500 (94.8957)  time: 0.2311  data: 0.0006  max mem: 2501
Test: [Task 1]  [1040/1627]  eta: 0:02:12  Loss: 0.7741 (1.0420)  Acc@1: 75.0000 (75.1621)  Acc@5: 100.0000 (94.9268)  time: 0.2241  data: 0.0008  max mem: 2501
Test: [Task 1]  [1050/1627]  eta: 0:02:09  Loss: 0.8959 (1.0407)  Acc@1: 75.0000 (75.1784)  Acc@5: 100.0000 (94.9393)  time: 0.2193  data: 0.0009  max mem: 2501
Test: [Task 1]  [1060/1627]  eta: 0:02:07  Loss: 1.0011 (1.0412)  Acc@1: 75.0000 (75.1944)  Acc@5: 93.7500 (94.9105)  time: 0.2188  data: 0.0005  max mem: 2501
Test: [Task 1]  [1070/1627]  eta: 0:02:05  Loss: 1.0011 (1.0418)  Acc@1: 75.0000 (75.1634)  Acc@5: 93.7500 (94.8996)  time: 0.2225  data: 0.0004  max mem: 2501
Test: [Task 1]  [1080/1627]  eta: 0:02:03  Loss: 0.9967 (1.0422)  Acc@1: 75.0000 (75.1503)  Acc@5: 93.7500 (94.8948)  time: 0.2297  data: 0.0004  max mem: 2501
Test: [Task 1]  [1090/1627]  eta: 0:02:00  Loss: 0.9947 (1.0416)  Acc@1: 75.0000 (75.1833)  Acc@5: 93.7500 (94.9015)  time: 0.2262  data: 0.0010  max mem: 2501
Test: [Task 1]  [1100/1627]  eta: 0:01:58  Loss: 0.8731 (1.0401)  Acc@1: 81.2500 (75.2157)  Acc@5: 100.0000 (94.9080)  time: 0.2177  data: 0.0012  max mem: 2501
Test: [Task 1]  [1110/1627]  eta: 0:01:56  Loss: 0.9711 (1.0405)  Acc@1: 75.0000 (75.2081)  Acc@5: 100.0000 (94.8976)  time: 0.2212  data: 0.0006  max mem: 2501
Test: [Task 1]  [1120/1627]  eta: 0:01:54  Loss: 1.0006 (1.0417)  Acc@1: 68.7500 (75.1505)  Acc@5: 100.0000 (94.9041)  time: 0.2247  data: 0.0004  max mem: 2501
Test: [Task 1]  [1130/1627]  eta: 0:01:51  Loss: 1.1274 (1.0418)  Acc@1: 75.0000 (75.1603)  Acc@5: 93.7500 (94.9050)  time: 0.2266  data: 0.0004  max mem: 2501
Test: [Task 1]  [1140/1627]  eta: 0:01:49  Loss: 1.1210 (1.0428)  Acc@1: 75.0000 (75.1424)  Acc@5: 93.7500 (94.8784)  time: 0.2213  data: 0.0004  max mem: 2501
Test: [Task 1]  [1150/1627]  eta: 0:01:47  Loss: 1.1578 (1.0438)  Acc@1: 75.0000 (75.1032)  Acc@5: 93.7500 (94.8632)  time: 0.2185  data: 0.0004  max mem: 2501
Test: [Task 1]  [1160/1627]  eta: 0:01:45  Loss: 1.1527 (1.0429)  Acc@1: 75.0000 (75.1615)  Acc@5: 93.7500 (94.8697)  time: 0.2231  data: 0.0004  max mem: 2501
Test: [Task 1]  [1170/1627]  eta: 0:01:42  Loss: 1.0103 (1.0423)  Acc@1: 81.2500 (75.1921)  Acc@5: 93.7500 (94.8602)  time: 0.2303  data: 0.0004  max mem: 2501
Test: [Task 1]  [1180/1627]  eta: 0:01:40  Loss: 1.0924 (1.0432)  Acc@1: 75.0000 (75.1799)  Acc@5: 93.7500 (94.8772)  time: 0.2282  data: 0.0020  max mem: 2501
Test: [Task 1]  [1190/1627]  eta: 0:01:38  Loss: 1.1071 (1.0435)  Acc@1: 75.0000 (75.1732)  Acc@5: 93.7500 (94.8678)  time: 0.2274  data: 0.0021  max mem: 2501
Test: [Task 1]  [1200/1627]  eta: 0:01:36  Loss: 1.0609 (1.0435)  Acc@1: 75.0000 (75.1613)  Acc@5: 93.7500 (94.8689)  time: 0.2264  data: 0.0012  max mem: 2501
Test: [Task 1]  [1210/1627]  eta: 0:01:33  Loss: 0.9342 (1.0440)  Acc@1: 75.0000 (75.1445)  Acc@5: 100.0000 (94.8648)  time: 0.2185  data: 0.0015  max mem: 2501
Test: [Task 1]  [1220/1627]  eta: 0:01:31  Loss: 0.9342 (1.0432)  Acc@1: 75.0000 (75.1382)  Acc@5: 100.0000 (94.8659)  time: 0.2209  data: 0.0009  max mem: 2501
Test: [Task 1]  [1230/1627]  eta: 0:01:29  Loss: 1.0605 (1.0434)  Acc@1: 75.0000 (75.1168)  Acc@5: 93.7500 (94.8721)  time: 0.2250  data: 0.0006  max mem: 2501
Test: [Task 1]  [1240/1627]  eta: 0:01:27  Loss: 0.9709 (1.0426)  Acc@1: 75.0000 (75.1461)  Acc@5: 93.7500 (94.8680)  time: 0.2289  data: 0.0007  max mem: 2501
Test: [Task 1]  [1250/1627]  eta: 0:01:24  Loss: 0.9709 (1.0427)  Acc@1: 81.2500 (75.1599)  Acc@5: 93.7500 (94.8641)  time: 0.2241  data: 0.0018  max mem: 2501
Test: [Task 1]  [1260/1627]  eta: 0:01:22  Loss: 1.0536 (1.0424)  Acc@1: 81.2500 (75.2082)  Acc@5: 93.7500 (94.8652)  time: 0.2203  data: 0.0016  max mem: 2501
Test: [Task 1]  [1270/1627]  eta: 0:01:20  Loss: 1.0398 (1.0429)  Acc@1: 75.0000 (75.1918)  Acc@5: 93.7500 (94.8367)  time: 0.2242  data: 0.0005  max mem: 2501
Test: [Task 1]  [1280/1627]  eta: 0:01:18  Loss: 0.8913 (1.0412)  Acc@1: 75.0000 (75.2342)  Acc@5: 93.7500 (94.8429)  time: 0.2321  data: 0.0005  max mem: 2501
Test: [Task 1]  [1290/1627]  eta: 0:01:15  Loss: 0.9686 (1.0412)  Acc@1: 75.0000 (75.2130)  Acc@5: 100.0000 (94.8538)  time: 0.2271  data: 0.0004  max mem: 2501
Test: [Task 1]  [1300/1627]  eta: 0:01:13  Loss: 0.9692 (1.0408)  Acc@1: 75.0000 (75.2498)  Acc@5: 100.0000 (94.8501)  time: 0.2164  data: 0.0004  max mem: 2501
Test: [Task 1]  [1310/1627]  eta: 0:01:11  Loss: 0.8457 (1.0393)  Acc@1: 81.2500 (75.2813)  Acc@5: 93.7500 (94.8560)  time: 0.2209  data: 0.0004  max mem: 2501
Test: [Task 1]  [1320/1627]  eta: 0:01:09  Loss: 0.7860 (1.0378)  Acc@1: 81.2500 (75.3454)  Acc@5: 100.0000 (94.8713)  time: 0.2238  data: 0.0004  max mem: 2501
Test: [Task 1]  [1330/1627]  eta: 0:01:06  Loss: 0.8636 (1.0375)  Acc@1: 81.2500 (75.3663)  Acc@5: 93.7500 (94.8582)  time: 0.2284  data: 0.0018  max mem: 2501
Test: [Task 1]  [1340/1627]  eta: 0:01:04  Loss: 1.0127 (1.0387)  Acc@1: 75.0000 (75.3169)  Acc@5: 93.7500 (94.8359)  time: 0.2354  data: 0.0025  max mem: 2501
Test: [Task 1]  [1350/1627]  eta: 0:01:02  Loss: 0.9905 (1.0382)  Acc@1: 75.0000 (75.3146)  Acc@5: 93.7500 (94.8418)  time: 0.2273  data: 0.0011  max mem: 2501
Test: [Task 1]  [1360/1627]  eta: 0:01:00  Loss: 0.9361 (1.0376)  Acc@1: 75.0000 (75.3352)  Acc@5: 93.7500 (94.8475)  time: 0.2162  data: 0.0004  max mem: 2501
Test: [Task 1]  [1370/1627]  eta: 0:00:57  Loss: 0.8940 (1.0369)  Acc@1: 75.0000 (75.3419)  Acc@5: 100.0000 (94.8714)  time: 0.2194  data: 0.0004  max mem: 2501
Test: [Task 1]  [1380/1627]  eta: 0:00:55  Loss: 0.9879 (1.0372)  Acc@1: 75.0000 (75.3213)  Acc@5: 100.0000 (94.8633)  time: 0.2235  data: 0.0005  max mem: 2501
Test: [Task 1]  [1390/1627]  eta: 0:00:53  Loss: 1.0966 (1.0367)  Acc@1: 68.7500 (75.3145)  Acc@5: 93.7500 (94.8688)  time: 0.2273  data: 0.0009  max mem: 2501
Test: [Task 1]  [1400/1627]  eta: 0:00:51  Loss: 0.9942 (1.0370)  Acc@1: 68.7500 (75.3078)  Acc@5: 93.7500 (94.8608)  time: 0.2240  data: 0.0008  max mem: 2501
Test: [Task 1]  [1410/1627]  eta: 0:00:48  Loss: 0.8695 (1.0363)  Acc@1: 75.0000 (75.3234)  Acc@5: 93.7500 (94.8662)  time: 0.2184  data: 0.0004  max mem: 2501
Test: [Task 1]  [1420/1627]  eta: 0:00:46  Loss: 0.9257 (1.0357)  Acc@1: 75.0000 (75.3431)  Acc@5: 100.0000 (94.8760)  time: 0.2224  data: 0.0006  max mem: 2501
Test: [Task 1]  [1430/1627]  eta: 0:00:44  Loss: 1.1072 (1.0374)  Acc@1: 75.0000 (75.3145)  Acc@5: 93.7500 (94.8419)  time: 0.2261  data: 0.0007  max mem: 2501
Test: [Task 1]  [1440/1627]  eta: 0:00:42  Loss: 1.0092 (1.0371)  Acc@1: 75.0000 (75.3123)  Acc@5: 93.7500 (94.8517)  time: 0.2292  data: 0.0005  max mem: 2501
Test: [Task 1]  [1450/1627]  eta: 0:00:39  Loss: 1.0698 (1.0384)  Acc@1: 68.7500 (75.2671)  Acc@5: 93.7500 (94.8355)  time: 0.2235  data: 0.0006  max mem: 2501
Test: [Task 1]  [1460/1627]  eta: 0:00:37  Loss: 1.1511 (1.0387)  Acc@1: 68.7500 (75.2481)  Acc@5: 93.7500 (94.8280)  time: 0.2185  data: 0.0005  max mem: 2501
Test: [Task 1]  [1470/1627]  eta: 0:00:35  Loss: 1.0150 (1.0391)  Acc@1: 68.7500 (75.2209)  Acc@5: 93.7500 (94.8207)  time: 0.2230  data: 0.0005  max mem: 2501
Test: [Task 1]  [1480/1627]  eta: 0:00:33  Loss: 1.1285 (1.0396)  Acc@1: 68.7500 (75.2110)  Acc@5: 93.7500 (94.8093)  time: 0.2324  data: 0.0007  max mem: 2501
Test: [Task 1]  [1490/1627]  eta: 0:00:30  Loss: 1.1337 (1.0400)  Acc@1: 75.0000 (75.2305)  Acc@5: 93.7500 (94.7980)  time: 0.2301  data: 0.0025  max mem: 2501
Test: [Task 1]  [1500/1627]  eta: 0:00:28  Loss: 1.1337 (1.0405)  Acc@1: 75.0000 (75.2207)  Acc@5: 93.7500 (94.7868)  time: 0.2301  data: 0.0031  max mem: 2501
Test: [Task 1]  [1510/1627]  eta: 0:00:26  Loss: 0.8806 (1.0408)  Acc@1: 75.0000 (75.1985)  Acc@5: 93.7500 (94.7799)  time: 0.2287  data: 0.0016  max mem: 2501
Test: [Task 1]  [1520/1627]  eta: 0:00:24  Loss: 0.8806 (1.0395)  Acc@1: 75.0000 (75.2342)  Acc@5: 100.0000 (94.7937)  time: 0.2196  data: 0.0008  max mem: 2501
Test: [Task 1]  [1530/1627]  eta: 0:00:21  Loss: 0.8435 (1.0389)  Acc@1: 81.2500 (75.2245)  Acc@5: 100.0000 (94.8073)  time: 0.2220  data: 0.0004  max mem: 2501
Test: [Task 1]  [1540/1627]  eta: 0:00:19  Loss: 0.8097 (1.0379)  Acc@1: 81.2500 (75.2312)  Acc@5: 100.0000 (94.8248)  time: 0.2323  data: 0.0004  max mem: 2501
Test: [Task 1]  [1550/1627]  eta: 0:00:17  Loss: 0.8118 (1.0375)  Acc@1: 81.2500 (75.2579)  Acc@5: 100.0000 (94.8219)  time: 0.2282  data: 0.0004  max mem: 2501
Test: [Task 1]  [1560/1627]  eta: 0:00:15  Loss: 0.8118 (1.0367)  Acc@1: 81.2500 (75.2843)  Acc@5: 93.7500 (94.8230)  time: 0.2156  data: 0.0004  max mem: 2501
Test: [Task 1]  [1570/1627]  eta: 0:00:12  Loss: 0.9130 (1.0369)  Acc@1: 81.2500 (75.3024)  Acc@5: 100.0000 (94.8242)  time: 0.2201  data: 0.0004  max mem: 2501
Test: [Task 1]  [1580/1627]  eta: 0:00:10  Loss: 0.9826 (1.0367)  Acc@1: 75.0000 (75.3163)  Acc@5: 100.0000 (94.8292)  time: 0.2254  data: 0.0005  max mem: 2501
Test: [Task 1]  [1590/1627]  eta: 0:00:08  Loss: 0.9826 (1.0364)  Acc@1: 75.0000 (75.3064)  Acc@5: 100.0000 (94.8460)  time: 0.2319  data: 0.0005  max mem: 2501
Test: [Task 1]  [1600/1627]  eta: 0:00:06  Loss: 1.0548 (1.0374)  Acc@1: 75.0000 (75.2655)  Acc@5: 93.7500 (94.8314)  time: 0.2254  data: 0.0005  max mem: 2501
Test: [Task 1]  [1610/1627]  eta: 0:00:03  Loss: 0.9949 (1.0369)  Acc@1: 75.0000 (75.2871)  Acc@5: 93.7500 (94.8324)  time: 0.2186  data: 0.0006  max mem: 2501
Test: [Task 1]  [1620/1627]  eta: 0:00:01  Loss: 0.9400 (1.0360)  Acc@1: 81.2500 (75.3239)  Acc@5: 93.7500 (94.8373)  time: 0.2227  data: 0.0004  max mem: 2501
Test: [Task 1]  [1626/1627]  eta: 0:00:00  Loss: 0.9487 (1.0354)  Acc@1: 81.2500 (75.3611)  Acc@5: 93.7500 (94.8294)  time: 0.2239  data: 0.0004  max mem: 2501
Test: [Task 1] Total time: 0:06:06 (0.2251 s / it)
* Acc@1 75.361 Acc@5 94.829 loss 1.035
Test: [Task 2]  [  0/625]  eta: 0:07:33  Loss: 0.2925 (0.2925)  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (100.0000)  time: 0.7260  data: 0.4485  max mem: 2501
Test: [Task 2]  [ 10/625]  eta: 0:02:46  Loss: 0.2228 (0.2609)  Acc@1: 93.7500 (93.7500)  Acc@5: 100.0000 (99.4318)  time: 0.2703  data: 0.0412  max mem: 2501
Test: [Task 2]  [ 20/625]  eta: 0:02:33  Loss: 0.2228 (0.2847)  Acc@1: 93.7500 (92.2619)  Acc@5: 100.0000 (99.7024)  time: 0.2297  data: 0.0006  max mem: 2501
Test: [Task 2]  [ 30/625]  eta: 0:02:23  Loss: 0.3114 (0.3055)  Acc@1: 93.7500 (91.3306)  Acc@5: 100.0000 (99.3952)  time: 0.2255  data: 0.0005  max mem: 2501
Test: [Task 2]  [ 40/625]  eta: 0:02:18  Loss: 0.3114 (0.3213)  Acc@1: 93.7500 (91.1585)  Acc@5: 100.0000 (99.5427)  time: 0.2189  data: 0.0005  max mem: 2501
Test: [Task 2]  [ 50/625]  eta: 0:02:14  Loss: 0.3560 (0.3404)  Acc@1: 87.5000 (90.4412)  Acc@5: 100.0000 (99.3873)  time: 0.2228  data: 0.0004  max mem: 2501
Test: [Task 2]  [ 60/625]  eta: 0:02:12  Loss: 0.3560 (0.3453)  Acc@1: 87.5000 (90.1639)  Acc@5: 100.0000 (99.3852)  time: 0.2303  data: 0.0004  max mem: 2501
Test: [Task 2]  [ 70/625]  eta: 0:02:08  Loss: 0.3469 (0.3423)  Acc@1: 87.5000 (90.0528)  Acc@5: 100.0000 (99.3838)  time: 0.2268  data: 0.0005  max mem: 2501
Test: [Task 2]  [ 80/625]  eta: 0:02:05  Loss: 0.2980 (0.3492)  Acc@1: 87.5000 (89.8148)  Acc@5: 100.0000 (99.2284)  time: 0.2185  data: 0.0008  max mem: 2501
Test: [Task 2]  [ 90/625]  eta: 0:02:02  Loss: 0.2851 (0.3429)  Acc@1: 93.7500 (90.1786)  Acc@5: 100.0000 (99.3132)  time: 0.2220  data: 0.0008  max mem: 2501
Test: [Task 2]  [100/625]  eta: 0:02:00  Loss: 0.2851 (0.3353)  Acc@1: 93.7500 (90.5322)  Acc@5: 100.0000 (99.3193)  time: 0.2244  data: 0.0005  max mem: 2501
Test: [Task 2]  [110/625]  eta: 0:01:58  Loss: 0.2884 (0.3379)  Acc@1: 93.7500 (90.5405)  Acc@5: 100.0000 (99.2117)  time: 0.2320  data: 0.0005  max mem: 2501
Test: [Task 2]  [120/625]  eta: 0:01:55  Loss: 0.3530 (0.3394)  Acc@1: 87.5000 (90.3926)  Acc@5: 100.0000 (99.1219)  time: 0.2295  data: 0.0005  max mem: 2501
Test: [Task 2]  [130/625]  eta: 0:01:53  Loss: 0.3436 (0.3390)  Acc@1: 87.5000 (90.4103)  Acc@5: 100.0000 (99.1889)  time: 0.2185  data: 0.0006  max mem: 2501
Test: [Task 2]  [140/625]  eta: 0:01:50  Loss: 0.2821 (0.3412)  Acc@1: 93.7500 (90.1596)  Acc@5: 100.0000 (99.2465)  time: 0.2200  data: 0.0006  max mem: 2501
Test: [Task 2]  [150/625]  eta: 0:01:48  Loss: 0.3044 (0.3444)  Acc@1: 87.5000 (89.9007)  Acc@5: 100.0000 (99.2550)  time: 0.2247  data: 0.0006  max mem: 2501
Test: [Task 2]  [160/625]  eta: 0:01:46  Loss: 0.3341 (0.3468)  Acc@1: 87.5000 (89.8680)  Acc@5: 100.0000 (99.1848)  time: 0.2290  data: 0.0005  max mem: 2501
Test: [Task 2]  [170/625]  eta: 0:01:44  Loss: 0.3167 (0.3453)  Acc@1: 87.5000 (89.8757)  Acc@5: 100.0000 (99.1959)  time: 0.2336  data: 0.0016  max mem: 2501
Test: [Task 2]  [180/625]  eta: 0:01:41  Loss: 0.2920 (0.3429)  Acc@1: 93.7500 (89.9862)  Acc@5: 100.0000 (99.2403)  time: 0.2252  data: 0.0019  max mem: 2501
Test: [Task 2]  [190/625]  eta: 0:01:38  Loss: 0.3771 (0.3477)  Acc@1: 87.5000 (89.8887)  Acc@5: 100.0000 (99.2474)  time: 0.2174  data: 0.0009  max mem: 2501
Test: [Task 2]  [200/625]  eta: 0:01:36  Loss: 0.3979 (0.3483)  Acc@1: 87.5000 (89.8321)  Acc@5: 100.0000 (99.2537)  time: 0.2220  data: 0.0006  max mem: 2501
Test: [Task 2]  [210/625]  eta: 0:01:34  Loss: 0.3364 (0.3514)  Acc@1: 87.5000 (89.7216)  Acc@5: 100.0000 (99.2002)  time: 0.2302  data: 0.0004  max mem: 2501
Test: [Task 2]  [220/625]  eta: 0:01:31  Loss: 0.2616 (0.3476)  Acc@1: 93.7500 (89.9038)  Acc@5: 100.0000 (99.2364)  time: 0.2258  data: 0.0004  max mem: 2501
Test: [Task 2]  [230/625]  eta: 0:01:29  Loss: 0.2607 (0.3453)  Acc@1: 93.7500 (89.9621)  Acc@5: 100.0000 (99.2695)  time: 0.2163  data: 0.0004  max mem: 2501
Test: [Task 2]  [240/625]  eta: 0:01:27  Loss: 0.3269 (0.3453)  Acc@1: 87.5000 (89.9637)  Acc@5: 100.0000 (99.2739)  time: 0.2194  data: 0.0004  max mem: 2501
Test: [Task 2]  [250/625]  eta: 0:01:24  Loss: 0.3435 (0.3468)  Acc@1: 87.5000 (90.0149)  Acc@5: 100.0000 (99.2281)  time: 0.2229  data: 0.0004  max mem: 2501
Test: [Task 2]  [260/625]  eta: 0:01:22  Loss: 0.3794 (0.3477)  Acc@1: 87.5000 (89.9904)  Acc@5: 100.0000 (99.2098)  time: 0.2282  data: 0.0004  max mem: 2501
Test: [Task 2]  [270/625]  eta: 0:01:20  Loss: 0.3829 (0.3475)  Acc@1: 87.5000 (89.9216)  Acc@5: 100.0000 (99.1697)  time: 0.2243  data: 0.0005  max mem: 2501
Test: [Task 2]  [280/625]  eta: 0:01:17  Loss: 0.3613 (0.3484)  Acc@1: 87.5000 (89.8354)  Acc@5: 100.0000 (99.1770)  time: 0.2163  data: 0.0006  max mem: 2501
Test: [Task 2]  [290/625]  eta: 0:01:15  Loss: 0.3613 (0.3487)  Acc@1: 87.5000 (89.8840)  Acc@5: 100.0000 (99.1838)  time: 0.2189  data: 0.0005  max mem: 2501
Test: [Task 2]  [300/625]  eta: 0:01:13  Loss: 0.3254 (0.3497)  Acc@1: 87.5000 (89.7633)  Acc@5: 100.0000 (99.2110)  time: 0.2224  data: 0.0004  max mem: 2501
Test: [Task 2]  [310/625]  eta: 0:01:11  Loss: 0.3451 (0.3507)  Acc@1: 87.5000 (89.6503)  Acc@5: 100.0000 (99.2162)  time: 0.2316  data: 0.0011  max mem: 2501
Test: [Task 2]  [320/625]  eta: 0:01:08  Loss: 0.1963 (0.3434)  Acc@1: 93.7500 (89.8754)  Acc@5: 100.0000 (99.2407)  time: 0.2330  data: 0.0019  max mem: 2501
Test: [Task 2]  [330/625]  eta: 0:01:06  Loss: 0.1490 (0.3406)  Acc@1: 93.7500 (89.9169)  Acc@5: 100.0000 (99.2636)  time: 0.2309  data: 0.0013  max mem: 2501
Test: [Task 2]  [340/625]  eta: 0:01:04  Loss: 0.1362 (0.3335)  Acc@1: 100.0000 (90.1943)  Acc@5: 100.0000 (99.2852)  time: 0.2261  data: 0.0010  max mem: 2501
Test: [Task 2]  [350/625]  eta: 0:01:02  Loss: 0.1274 (0.3308)  Acc@1: 100.0000 (90.2066)  Acc@5: 100.0000 (99.3056)  time: 0.2177  data: 0.0008  max mem: 2501
Test: [Task 2]  [360/625]  eta: 0:00:59  Loss: 0.3376 (0.3326)  Acc@1: 87.5000 (90.1316)  Acc@5: 100.0000 (99.3075)  time: 0.2209  data: 0.0004  max mem: 2501
Test: [Task 2]  [370/625]  eta: 0:00:57  Loss: 0.2777 (0.3302)  Acc@1: 93.7500 (90.2123)  Acc@5: 100.0000 (99.3261)  time: 0.2247  data: 0.0004  max mem: 2501
Test: [Task 2]  [380/625]  eta: 0:00:55  Loss: 0.2794 (0.3327)  Acc@1: 93.7500 (90.1247)  Acc@5: 100.0000 (99.2782)  time: 0.2277  data: 0.0004  max mem: 2501
Test: [Task 2]  [390/625]  eta: 0:00:53  Loss: 0.2240 (0.3305)  Acc@1: 93.7500 (90.1854)  Acc@5: 100.0000 (99.2807)  time: 0.2227  data: 0.0006  max mem: 2501
Test: [Task 2]  [400/625]  eta: 0:00:50  Loss: 0.1281 (0.3256)  Acc@1: 93.7500 (90.3367)  Acc@5: 100.0000 (99.2986)  time: 0.2192  data: 0.0006  max mem: 2501
Test: [Task 2]  [410/625]  eta: 0:00:48  Loss: 0.0989 (0.3238)  Acc@1: 100.0000 (90.4501)  Acc@5: 100.0000 (99.2853)  time: 0.2226  data: 0.0005  max mem: 2501
Test: [Task 2]  [420/625]  eta: 0:00:46  Loss: 0.1156 (0.3229)  Acc@1: 100.0000 (90.5285)  Acc@5: 100.0000 (99.3023)  time: 0.2295  data: 0.0012  max mem: 2501
Test: [Task 2]  [430/625]  eta: 0:00:43  Loss: 0.2210 (0.3211)  Acc@1: 93.7500 (90.5742)  Acc@5: 100.0000 (99.3184)  time: 0.2254  data: 0.0011  max mem: 2501
Test: [Task 2]  [440/625]  eta: 0:00:41  Loss: 0.1490 (0.3165)  Acc@1: 93.7500 (90.7171)  Acc@5: 100.0000 (99.3339)  time: 0.2165  data: 0.0004  max mem: 2501
Test: [Task 2]  [450/625]  eta: 0:00:39  Loss: 0.1200 (0.3121)  Acc@1: 93.7500 (90.8121)  Acc@5: 100.0000 (99.3487)  time: 0.2203  data: 0.0004  max mem: 2501
Test: [Task 2]  [460/625]  eta: 0:00:37  Loss: 0.1264 (0.3083)  Acc@1: 100.0000 (90.9843)  Acc@5: 100.0000 (99.3628)  time: 0.2248  data: 0.0012  max mem: 2501
Test: [Task 2]  [470/625]  eta: 0:00:34  Loss: 0.1359 (0.3055)  Acc@1: 100.0000 (91.1226)  Acc@5: 100.0000 (99.3763)  time: 0.2298  data: 0.0011  max mem: 2501
Test: [Task 2]  [480/625]  eta: 0:00:32  Loss: 0.1651 (0.3031)  Acc@1: 93.7500 (91.2162)  Acc@5: 100.0000 (99.3893)  time: 0.2267  data: 0.0006  max mem: 2501
Test: [Task 2]  [490/625]  eta: 0:00:30  Loss: 0.1425 (0.3003)  Acc@1: 100.0000 (91.3442)  Acc@5: 100.0000 (99.4017)  time: 0.2277  data: 0.0019  max mem: 2501
Test: [Task 2]  [500/625]  eta: 0:00:28  Loss: 0.1209 (0.2975)  Acc@1: 100.0000 (91.4546)  Acc@5: 100.0000 (99.4012)  time: 0.2251  data: 0.0018  max mem: 2501
Test: [Task 2]  [510/625]  eta: 0:00:25  Loss: 0.1403 (0.3004)  Acc@1: 93.7500 (91.3527)  Acc@5: 100.0000 (99.4129)  time: 0.2188  data: 0.0005  max mem: 2501
Test: [Task 2]  [520/625]  eta: 0:00:23  Loss: 0.2003 (0.3002)  Acc@1: 93.7500 (91.3748)  Acc@5: 100.0000 (99.4242)  time: 0.2233  data: 0.0005  max mem: 2501
Test: [Task 2]  [530/625]  eta: 0:00:21  Loss: 0.1807 (0.2977)  Acc@1: 93.7500 (91.4666)  Acc@5: 100.0000 (99.4350)  time: 0.2241  data: 0.0006  max mem: 2501
Test: [Task 2]  [540/625]  eta: 0:00:19  Loss: 0.1407 (0.2957)  Acc@1: 93.7500 (91.5434)  Acc@5: 100.0000 (99.4455)  time: 0.2249  data: 0.0005  max mem: 2501
Test: [Task 2]  [550/625]  eta: 0:00:16  Loss: 0.1051 (0.2920)  Acc@1: 100.0000 (91.6629)  Acc@5: 100.0000 (99.4555)  time: 0.2223  data: 0.0013  max mem: 2501
Test: [Task 2]  [560/625]  eta: 0:00:14  Loss: 0.0565 (0.2877)  Acc@1: 100.0000 (91.8115)  Acc@5: 100.0000 (99.4652)  time: 0.2214  data: 0.0014  max mem: 2501
Test: [Task 2]  [570/625]  eta: 0:00:12  Loss: 0.0567 (0.2868)  Acc@1: 100.0000 (91.8345)  Acc@5: 100.0000 (99.4746)  time: 0.2240  data: 0.0006  max mem: 2501
Test: [Task 2]  [580/625]  eta: 0:00:10  Loss: 0.1176 (0.2840)  Acc@1: 100.0000 (91.9320)  Acc@5: 100.0000 (99.4836)  time: 0.2286  data: 0.0005  max mem: 2501
Test: [Task 2]  [590/625]  eta: 0:00:07  Loss: 0.1211 (0.2816)  Acc@1: 100.0000 (92.0580)  Acc@5: 100.0000 (99.4924)  time: 0.2254  data: 0.0006  max mem: 2501
Test: [Task 2]  [600/625]  eta: 0:00:05  Loss: 0.1744 (0.2806)  Acc@1: 100.0000 (92.1069)  Acc@5: 100.0000 (99.5008)  time: 0.2185  data: 0.0006  max mem: 2501
Test: [Task 2]  [610/625]  eta: 0:00:03  Loss: 0.2504 (0.2825)  Acc@1: 93.7500 (92.0827)  Acc@5: 100.0000 (99.4476)  time: 0.2222  data: 0.0004  max mem: 2501
Test: [Task 2]  [620/625]  eta: 0:00:01  Loss: 0.3411 (0.2834)  Acc@1: 87.5000 (92.0793)  Acc@5: 100.0000 (99.4565)  time: 0.2274  data: 0.0004  max mem: 2501
Test: [Task 2]  [624/625]  eta: 0:00:00  Loss: 0.2507 (0.2829)  Acc@1: 93.7500 (92.0700)  Acc@5: 100.0000 (99.4600)  time: 0.2298  data: 0.0003  max mem: 2501
Test: [Task 2] Total time: 0:02:21 (0.2257 s / it)
* Acc@1 92.070 Acc@5 99.460 loss 0.283
Test: [Task 3]  [  0/625]  eta: 0:08:25  Loss: 0.1139 (0.1139)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)  time: 0.8087  data: 0.5923  max mem: 2501
Test: [Task 3]  [ 10/625]  eta: 0:02:55  Loss: 0.2333 (0.2060)  Acc@1: 100.0000 (97.1591)  Acc@5: 100.0000 (100.0000)  time: 0.2849  data: 0.0546  max mem: 2501
Test: [Task 3]  [ 20/625]  eta: 0:02:32  Loss: 0.2333 (0.2236)  Acc@1: 93.7500 (96.4286)  Acc@5: 100.0000 (99.7024)  time: 0.2249  data: 0.0006  max mem: 2501
Test: [Task 3]  [ 30/625]  eta: 0:02:23  Loss: 0.2128 (0.2203)  Acc@1: 93.7500 (96.1694)  Acc@5: 100.0000 (99.5968)  time: 0.2175  data: 0.0005  max mem: 2501
Test: [Task 3]  [ 40/625]  eta: 0:02:18  Loss: 0.1365 (0.1941)  Acc@1: 100.0000 (96.7988)  Acc@5: 100.0000 (99.6951)  time: 0.2212  data: 0.0010  max mem: 2501
Test: [Task 3]  [ 50/625]  eta: 0:02:15  Loss: 0.1025 (0.1914)  Acc@1: 100.0000 (96.9363)  Acc@5: 100.0000 (99.6324)  time: 0.2246  data: 0.0009  max mem: 2501
Test: [Task 3]  [ 60/625]  eta: 0:02:12  Loss: 0.1682 (0.1897)  Acc@1: 100.0000 (96.9262)  Acc@5: 100.0000 (99.6926)  time: 0.2262  data: 0.0004  max mem: 2501
Test: [Task 3]  [ 70/625]  eta: 0:02:08  Loss: 0.1166 (0.1801)  Acc@1: 100.0000 (97.0951)  Acc@5: 100.0000 (99.6479)  time: 0.2219  data: 0.0007  max mem: 2501
Test: [Task 3]  [ 80/625]  eta: 0:02:05  Loss: 0.1139 (0.1796)  Acc@1: 100.0000 (97.0679)  Acc@5: 100.0000 (99.6914)  time: 0.2191  data: 0.0008  max mem: 2501
Test: [Task 3]  [ 90/625]  eta: 0:02:02  Loss: 0.1372 (0.1807)  Acc@1: 100.0000 (97.1841)  Acc@5: 100.0000 (99.6566)  time: 0.2230  data: 0.0005  max mem: 2501
Test: [Task 3]  [100/625]  eta: 0:02:00  Loss: 0.1311 (0.1783)  Acc@1: 100.0000 (97.2153)  Acc@5: 100.0000 (99.6906)  time: 0.2283  data: 0.0006  max mem: 2501
Test: [Task 3]  [110/625]  eta: 0:01:57  Loss: 0.1121 (0.1732)  Acc@1: 100.0000 (97.4662)  Acc@5: 100.0000 (99.7185)  time: 0.2244  data: 0.0004  max mem: 2501
Test: [Task 3]  [120/625]  eta: 0:01:55  Loss: 0.1305 (0.1746)  Acc@1: 100.0000 (97.4690)  Acc@5: 100.0000 (99.7417)  time: 0.2178  data: 0.0009  max mem: 2501
Test: [Task 3]  [130/625]  eta: 0:01:52  Loss: 0.1370 (0.1744)  Acc@1: 100.0000 (97.5191)  Acc@5: 100.0000 (99.7137)  time: 0.2223  data: 0.0009  max mem: 2501
Test: [Task 3]  [140/625]  eta: 0:01:50  Loss: 0.1729 (0.1796)  Acc@1: 100.0000 (97.4734)  Acc@5: 100.0000 (99.6454)  time: 0.2269  data: 0.0004  max mem: 2501
Test: [Task 3]  [150/625]  eta: 0:01:48  Loss: 0.1792 (0.1862)  Acc@1: 93.7500 (97.3096)  Acc@5: 100.0000 (99.5861)  time: 0.2303  data: 0.0012  max mem: 2501
Test: [Task 3]  [160/625]  eta: 0:01:46  Loss: 0.1665 (0.1880)  Acc@1: 100.0000 (97.2826)  Acc@5: 100.0000 (99.5342)  time: 0.2329  data: 0.0013  max mem: 2501
Test: [Task 3]  [170/625]  eta: 0:01:43  Loss: 0.1362 (0.1865)  Acc@1: 100.0000 (97.2953)  Acc@5: 100.0000 (99.5614)  time: 0.2258  data: 0.0006  max mem: 2501
Test: [Task 3]  [180/625]  eta: 0:01:41  Loss: 0.2129 (0.1902)  Acc@1: 93.7500 (97.1340)  Acc@5: 100.0000 (99.5856)  time: 0.2171  data: 0.0005  max mem: 2501
Test: [Task 3]  [190/625]  eta: 0:01:38  Loss: 0.1936 (0.1891)  Acc@1: 93.7500 (97.1859)  Acc@5: 100.0000 (99.5746)  time: 0.2178  data: 0.0004  max mem: 2501
Test: [Task 3]  [200/625]  eta: 0:01:36  Loss: 0.1936 (0.1922)  Acc@1: 100.0000 (97.1082)  Acc@5: 100.0000 (99.5336)  time: 0.2214  data: 0.0004  max mem: 2501
Test: [Task 3]  [210/625]  eta: 0:01:34  Loss: 0.1833 (0.1935)  Acc@1: 100.0000 (97.0972)  Acc@5: 100.0000 (99.4964)  time: 0.2294  data: 0.0004  max mem: 2501
Test: [Task 3]  [220/625]  eta: 0:01:31  Loss: 0.1590 (0.1934)  Acc@1: 100.0000 (97.0588)  Acc@5: 100.0000 (99.4910)  time: 0.2284  data: 0.0008  max mem: 2501
Test: [Task 3]  [230/625]  eta: 0:01:29  Loss: 0.1626 (0.1945)  Acc@1: 100.0000 (96.9697)  Acc@5: 100.0000 (99.4859)  time: 0.2190  data: 0.0009  max mem: 2501
Test: [Task 3]  [240/625]  eta: 0:01:27  Loss: 0.2108 (0.1968)  Acc@1: 93.7500 (96.9139)  Acc@5: 100.0000 (99.4554)  time: 0.2202  data: 0.0005  max mem: 2501
Test: [Task 3]  [250/625]  eta: 0:01:24  Loss: 0.1283 (0.1948)  Acc@1: 100.0000 (96.9871)  Acc@5: 100.0000 (99.4771)  time: 0.2241  data: 0.0004  max mem: 2501
Test: [Task 3]  [260/625]  eta: 0:01:22  Loss: 0.1181 (0.1935)  Acc@1: 100.0000 (96.9828)  Acc@5: 100.0000 (99.4732)  time: 0.2278  data: 0.0005  max mem: 2501
Test: [Task 3]  [270/625]  eta: 0:01:20  Loss: 0.1370 (0.1923)  Acc@1: 93.7500 (96.9557)  Acc@5: 100.0000 (99.4926)  time: 0.2236  data: 0.0006  max mem: 2501
Test: [Task 3]  [280/625]  eta: 0:01:17  Loss: 0.1509 (0.1923)  Acc@1: 93.7500 (96.9306)  Acc@5: 100.0000 (99.4884)  time: 0.2186  data: 0.0015  max mem: 2501
Test: [Task 3]  [290/625]  eta: 0:01:15  Loss: 0.1476 (0.1919)  Acc@1: 100.0000 (96.9287)  Acc@5: 100.0000 (99.5060)  time: 0.2231  data: 0.0013  max mem: 2501
Test: [Task 3]  [300/625]  eta: 0:01:13  Loss: 0.1476 (0.1931)  Acc@1: 100.0000 (96.8439)  Acc@5: 100.0000 (99.5017)  time: 0.2252  data: 0.0004  max mem: 2501
Test: [Task 3]  [310/625]  eta: 0:01:11  Loss: 0.1617 (0.1950)  Acc@1: 100.0000 (96.8248)  Acc@5: 100.0000 (99.4373)  time: 0.2292  data: 0.0005  max mem: 2501
Test: [Task 3]  [320/625]  eta: 0:01:08  Loss: 0.1487 (0.1942)  Acc@1: 100.0000 (96.8458)  Acc@5: 100.0000 (99.4354)  time: 0.2256  data: 0.0012  max mem: 2501
Test: [Task 3]  [330/625]  eta: 0:01:06  Loss: 0.1692 (0.1955)  Acc@1: 93.7500 (96.8089)  Acc@5: 100.0000 (99.4335)  time: 0.2246  data: 0.0011  max mem: 2501
Test: [Task 3]  [340/625]  eta: 0:01:04  Loss: 0.1428 (0.1936)  Acc@1: 93.7500 (96.8292)  Acc@5: 100.0000 (99.4501)  time: 0.2233  data: 0.0005  max mem: 2501
Test: [Task 3]  [350/625]  eta: 0:01:01  Loss: 0.1422 (0.1937)  Acc@1: 93.7500 (96.7949)  Acc@5: 100.0000 (99.4480)  time: 0.2177  data: 0.0005  max mem: 2501
Test: [Task 3]  [360/625]  eta: 0:00:59  Loss: 0.1602 (0.1945)  Acc@1: 93.7500 (96.7625)  Acc@5: 100.0000 (99.4460)  time: 0.2227  data: 0.0004  max mem: 2501
Test: [Task 3]  [370/625]  eta: 0:00:57  Loss: 0.2262 (0.1951)  Acc@1: 93.7500 (96.7318)  Acc@5: 100.0000 (99.4609)  time: 0.2327  data: 0.0005  max mem: 2501
Test: [Task 3]  [380/625]  eta: 0:00:55  Loss: 0.1902 (0.1936)  Acc@1: 100.0000 (96.7684)  Acc@5: 100.0000 (99.4751)  time: 0.2284  data: 0.0006  max mem: 2501
Test: [Task 3]  [390/625]  eta: 0:00:52  Loss: 0.1347 (0.1934)  Acc@1: 100.0000 (96.7711)  Acc@5: 100.0000 (99.4885)  time: 0.2171  data: 0.0006  max mem: 2501
Test: [Task 3]  [400/625]  eta: 0:00:50  Loss: 0.1132 (0.1928)  Acc@1: 93.7500 (96.7425)  Acc@5: 100.0000 (99.4857)  time: 0.2196  data: 0.0005  max mem: 2501
Test: [Task 3]  [410/625]  eta: 0:00:48  Loss: 0.1645 (0.1939)  Acc@1: 93.7500 (96.7457)  Acc@5: 100.0000 (99.4526)  time: 0.2226  data: 0.0004  max mem: 2501
Test: [Task 3]  [420/625]  eta: 0:00:46  Loss: 0.1841 (0.1942)  Acc@1: 100.0000 (96.7191)  Acc@5: 100.0000 (99.4507)  time: 0.2303  data: 0.0004  max mem: 2501
Test: [Task 3]  [430/625]  eta: 0:00:43  Loss: 0.1454 (0.1939)  Acc@1: 100.0000 (96.7372)  Acc@5: 100.0000 (99.4490)  time: 0.2271  data: 0.0005  max mem: 2501
Test: [Task 3]  [440/625]  eta: 0:00:41  Loss: 0.1454 (0.1952)  Acc@1: 100.0000 (96.6978)  Acc@5: 100.0000 (99.4473)  time: 0.2158  data: 0.0005  max mem: 2501
Test: [Task 3]  [450/625]  eta: 0:00:39  Loss: 0.1496 (0.1954)  Acc@1: 100.0000 (96.7018)  Acc@5: 100.0000 (99.4457)  time: 0.2192  data: 0.0010  max mem: 2501
Test: [Task 3]  [460/625]  eta: 0:00:37  Loss: 0.1317 (0.1949)  Acc@1: 100.0000 (96.7326)  Acc@5: 100.0000 (99.4441)  time: 0.2233  data: 0.0011  max mem: 2501
Test: [Task 3]  [470/625]  eta: 0:00:34  Loss: 0.1507 (0.1949)  Acc@1: 100.0000 (96.7224)  Acc@5: 100.0000 (99.4427)  time: 0.2310  data: 0.0006  max mem: 2501
Test: [Task 3]  [480/625]  eta: 0:00:32  Loss: 0.1871 (0.1961)  Acc@1: 100.0000 (96.7126)  Acc@5: 100.0000 (99.4413)  time: 0.2279  data: 0.0010  max mem: 2501
Test: [Task 3]  [490/625]  eta: 0:00:30  Loss: 0.1740 (0.1966)  Acc@1: 100.0000 (96.7032)  Acc@5: 100.0000 (99.4272)  time: 0.2268  data: 0.0010  max mem: 2501
Test: [Task 3]  [500/625]  eta: 0:00:28  Loss: 0.1134 (0.1959)  Acc@1: 100.0000 (96.7315)  Acc@5: 100.0000 (99.4261)  time: 0.2263  data: 0.0005  max mem: 2501
Test: [Task 3]  [510/625]  eta: 0:00:25  Loss: 0.1030 (0.1950)  Acc@1: 100.0000 (96.7466)  Acc@5: 100.0000 (99.4374)  time: 0.2192  data: 0.0006  max mem: 2501
Test: [Task 3]  [520/625]  eta: 0:00:23  Loss: 0.1464 (0.1953)  Acc@1: 100.0000 (96.7131)  Acc@5: 100.0000 (99.4482)  time: 0.2238  data: 0.0007  max mem: 2501
Test: [Task 3]  [530/625]  eta: 0:00:21  Loss: 0.1870 (0.1960)  Acc@1: 93.7500 (96.7043)  Acc@5: 100.0000 (99.4468)  time: 0.2311  data: 0.0006  max mem: 2501
Test: [Task 3]  [540/625]  eta: 0:00:19  Loss: 0.1845 (0.1966)  Acc@1: 93.7500 (96.7075)  Acc@5: 100.0000 (99.4455)  time: 0.2263  data: 0.0005  max mem: 2501
Test: [Task 3]  [550/625]  eta: 0:00:16  Loss: 0.1983 (0.1974)  Acc@1: 93.7500 (96.6765)  Acc@5: 100.0000 (99.4442)  time: 0.2165  data: 0.0005  max mem: 2501
Test: [Task 3]  [560/625]  eta: 0:00:14  Loss: 0.1674 (0.1972)  Acc@1: 100.0000 (96.7023)  Acc@5: 100.0000 (99.4541)  time: 0.2200  data: 0.0004  max mem: 2501
Test: [Task 3]  [570/625]  eta: 0:00:12  Loss: 0.1546 (0.1968)  Acc@1: 100.0000 (96.6944)  Acc@5: 100.0000 (99.4527)  time: 0.2235  data: 0.0005  max mem: 2501
Test: [Task 3]  [580/625]  eta: 0:00:10  Loss: 0.2074 (0.1988)  Acc@1: 93.7500 (96.6330)  Acc@5: 100.0000 (99.4406)  time: 0.2299  data: 0.0010  max mem: 2501
Test: [Task 3]  [590/625]  eta: 0:00:07  Loss: 0.1498 (0.1979)  Acc@1: 100.0000 (96.6688)  Acc@5: 100.0000 (99.4501)  time: 0.2257  data: 0.0008  max mem: 2501
Test: [Task 3]  [600/625]  eta: 0:00:05  Loss: 0.1498 (0.1980)  Acc@1: 100.0000 (96.6202)  Acc@5: 100.0000 (99.4384)  time: 0.2178  data: 0.0006  max mem: 2501
Test: [Task 3]  [610/625]  eta: 0:00:03  Loss: 0.1770 (0.1974)  Acc@1: 93.7500 (96.6244)  Acc@5: 100.0000 (99.4476)  time: 0.2221  data: 0.0008  max mem: 2501
Test: [Task 3]  [620/625]  eta: 0:00:01  Loss: 0.1947 (0.1982)  Acc@1: 93.7500 (96.5781)  Acc@5: 100.0000 (99.4465)  time: 0.2265  data: 0.0005  max mem: 2501
Test: [Task 3]  [624/625]  eta: 0:00:00  Loss: 0.1716 (0.1976)  Acc@1: 100.0000 (96.6000)  Acc@5: 100.0000 (99.4500)  time: 0.2305  data: 0.0003  max mem: 2501
Test: [Task 3] Total time: 0:02:20 (0.2254 s / it)
* Acc@1 96.600 Acc@5 99.450 loss 0.198
{0: {0: 26032, 1: 26032, 2: 26032, 3: 26032, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0, 10: 0, 11: 0, 12: 0, 13: 0, 14: 0, 15: 0, 16: 0, 17: 0, 18: 0, 19: 0}, 1: {0: 0, 1: 0, 2: 0, 3: 0, 4: 10000, 5: 10000, 6: 10000, 7: 10000, 8: 0, 9: 0, 10: 0, 11: 0, 12: 0, 13: 0, 14: 0, 15: 0, 16: 0, 17: 0, 18: 0, 19: 0}, 2: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 10000, 9: 10000, 10: 10000, 11: 10000, 12: 0, 13: 0, 14: 0, 15: 0, 16: 0, 17: 0, 18: 0, 19: 0}}
[Average accuracy till task3]	Acc@1: 88.0104	Acc@5: 97.9131	Loss: 0.5053	Forgetting: 5.2789	Backward: -5.2789
Transfering parameters  (slice(12, 16, None), slice(8, 12, None))
Train: Epoch[1/5]  [   0/1142]  eta: 0:18:02  Lr: 0.001875  Loss: 1.1640  Acc@1: 12.5000 (12.5000)  Acc@5: 37.5000 (37.5000)  time: 0.9482  data: 0.5836  max mem: 2501
Train: Epoch[1/5]  [  10/1142]  eta: 0:07:41  Lr: 0.001875  Loss: 1.1080  Acc@1: 18.7500 (21.5909)  Acc@5: 56.2500 (61.3636)  time: 0.4073  data: 0.0537  max mem: 2501
Train: Epoch[1/5]  [  20/1142]  eta: 0:07:10  Lr: 0.001875  Loss: 0.9615  Acc@1: 31.2500 (30.6548)  Acc@5: 75.0000 (71.1310)  time: 0.3552  data: 0.0006  max mem: 2501
Train: Epoch[1/5]  [  30/1142]  eta: 0:06:59  Lr: 0.001875  Loss: 0.6075  Acc@1: 43.7500 (35.8871)  Acc@5: 87.5000 (77.4194)  time: 0.3602  data: 0.0005  max mem: 2501
Train: Epoch[1/5]  [  40/1142]  eta: 0:06:48  Lr: 0.001875  Loss: 0.7671  Acc@1: 43.7500 (37.9573)  Acc@5: 87.5000 (78.8110)  time: 0.3571  data: 0.0006  max mem: 2501
Train: Epoch[1/5]  [  50/1142]  eta: 0:06:42  Lr: 0.001875  Loss: 0.7267  Acc@1: 43.7500 (40.1961)  Acc@5: 87.5000 (80.5147)  time: 0.3546  data: 0.0005  max mem: 2501
Train: Epoch[1/5]  [  60/1142]  eta: 0:06:38  Lr: 0.001875  Loss: 0.5387  Acc@1: 50.0000 (42.1107)  Acc@5: 87.5000 (81.7623)  time: 0.3626  data: 0.0004  max mem: 2501
Train: Epoch[1/5]  [  70/1142]  eta: 0:06:31  Lr: 0.001875  Loss: 0.9493  Acc@1: 50.0000 (43.9261)  Acc@5: 87.5000 (82.7465)  time: 0.3591  data: 0.0005  max mem: 2501
Train: Epoch[1/5]  [  80/1142]  eta: 0:06:27  Lr: 0.001875  Loss: 0.4269  Acc@1: 56.2500 (45.0617)  Acc@5: 87.5000 (83.4105)  time: 0.3549  data: 0.0005  max mem: 2501
Train: Epoch[1/5]  [  90/1142]  eta: 0:06:23  Lr: 0.001875  Loss: 0.1932  Acc@1: 50.0000 (45.4670)  Acc@5: 87.5000 (83.7912)  time: 0.3617  data: 0.0008  max mem: 2501
Train: Epoch[1/5]  [ 100/1142]  eta: 0:06:19  Lr: 0.001875  Loss: 0.8362  Acc@1: 43.7500 (45.6064)  Acc@5: 87.5000 (83.9109)  time: 0.3628  data: 0.0017  max mem: 2501
Train: Epoch[1/5]  [ 110/1142]  eta: 0:06:14  Lr: 0.001875  Loss: 0.5271  Acc@1: 50.0000 (46.5090)  Acc@5: 87.5000 (84.4032)  time: 0.3563  data: 0.0019  max mem: 2501
Train: Epoch[1/5]  [ 120/1142]  eta: 0:06:10  Lr: 0.001875  Loss: 0.4187  Acc@1: 56.2500 (47.3657)  Acc@5: 93.7500 (85.0723)  time: 0.3541  data: 0.0012  max mem: 2501
Train: Epoch[1/5]  [ 130/1142]  eta: 0:06:07  Lr: 0.001875  Loss: 0.0835  Acc@1: 56.2500 (47.9008)  Acc@5: 93.7500 (85.5916)  time: 0.3630  data: 0.0007  max mem: 2501
Train: Epoch[1/5]  [ 140/1142]  eta: 0:06:02  Lr: 0.001875  Loss: 1.0028  Acc@1: 50.0000 (48.0940)  Acc@5: 87.5000 (85.6383)  time: 0.3589  data: 0.0010  max mem: 2501
Train: Epoch[1/5]  [ 150/1142]  eta: 0:05:59  Lr: 0.001875  Loss: 0.2686  Acc@1: 50.0000 (48.2616)  Acc@5: 87.5000 (85.9685)  time: 0.3545  data: 0.0010  max mem: 2501
Train: Epoch[1/5]  [ 160/1142]  eta: 0:05:56  Lr: 0.001875  Loss: 0.8862  Acc@1: 50.0000 (48.4084)  Acc@5: 87.5000 (86.0637)  time: 0.3671  data: 0.0005  max mem: 2501
Train: Epoch[1/5]  [ 170/1142]  eta: 0:05:51  Lr: 0.001875  Loss: 0.2415  Acc@1: 56.2500 (49.0497)  Acc@5: 93.7500 (86.5497)  time: 0.3593  data: 0.0005  max mem: 2501
Train: Epoch[1/5]  [ 180/1142]  eta: 0:05:47  Lr: 0.001875  Loss: 0.9037  Acc@1: 62.5000 (49.5166)  Acc@5: 93.7500 (86.6022)  time: 0.3513  data: 0.0004  max mem: 2501
Train: Epoch[1/5]  [ 190/1142]  eta: 0:05:44  Lr: 0.001875  Loss: 0.1426  Acc@1: 56.2500 (49.9018)  Acc@5: 87.5000 (86.8128)  time: 0.3650  data: 0.0010  max mem: 2501
Train: Epoch[1/5]  [ 200/1142]  eta: 0:05:40  Lr: 0.001875  Loss: 0.1124  Acc@1: 56.2500 (50.5286)  Acc@5: 93.7500 (87.0958)  time: 0.3662  data: 0.0012  max mem: 2501
Train: Epoch[1/5]  [ 210/1142]  eta: 0:05:36  Lr: 0.001875  Loss: 0.5328  Acc@1: 56.2500 (50.7405)  Acc@5: 93.7500 (87.3815)  time: 0.3553  data: 0.0007  max mem: 2501
Train: Epoch[1/5]  [ 220/1142]  eta: 0:05:33  Lr: 0.001875  Loss: 0.6640  Acc@1: 50.0000 (50.6222)  Acc@5: 87.5000 (87.4717)  time: 0.3552  data: 0.0005  max mem: 2501
Train: Epoch[1/5]  [ 230/1142]  eta: 0:05:29  Lr: 0.001875  Loss: -0.0723  Acc@1: 56.2500 (50.9740)  Acc@5: 87.5000 (87.6082)  time: 0.3611  data: 0.0005  max mem: 2501
Train: Epoch[1/5]  [ 240/1142]  eta: 0:05:25  Lr: 0.001875  Loss: -0.1623  Acc@1: 56.2500 (51.3745)  Acc@5: 93.7500 (87.8112)  time: 0.3568  data: 0.0005  max mem: 2501
Train: Epoch[1/5]  [ 250/1142]  eta: 0:05:21  Lr: 0.001875  Loss: 0.2058  Acc@1: 62.5000 (51.5189)  Acc@5: 93.7500 (88.0229)  time: 0.3548  data: 0.0006  max mem: 2501
Train: Epoch[1/5]  [ 260/1142]  eta: 0:05:18  Lr: 0.001875  Loss: -0.0349  Acc@1: 56.2500 (51.8199)  Acc@5: 87.5000 (87.9789)  time: 0.3596  data: 0.0006  max mem: 2501
Train: Epoch[1/5]  [ 270/1142]  eta: 0:05:14  Lr: 0.001875  Loss: 0.0351  Acc@1: 62.5000 (52.1218)  Acc@5: 93.7500 (88.1458)  time: 0.3565  data: 0.0004  max mem: 2501
Train: Epoch[1/5]  [ 280/1142]  eta: 0:05:10  Lr: 0.001875  Loss: 0.7340  Acc@1: 62.5000 (52.1797)  Acc@5: 93.7500 (88.2785)  time: 0.3554  data: 0.0005  max mem: 2501
Train: Epoch[1/5]  [ 290/1142]  eta: 0:05:07  Lr: 0.001875  Loss: 0.7214  Acc@1: 62.5000 (52.5773)  Acc@5: 93.7500 (88.3591)  time: 0.3626  data: 0.0007  max mem: 2501
Train: Epoch[1/5]  [ 300/1142]  eta: 0:05:03  Lr: 0.001875  Loss: 0.0836  Acc@1: 62.5000 (52.8654)  Acc@5: 93.7500 (88.4759)  time: 0.3670  data: 0.0009  max mem: 2501
Train: Epoch[1/5]  [ 310/1142]  eta: 0:04:59  Lr: 0.001875  Loss: 0.0312  Acc@1: 56.2500 (53.0949)  Acc@5: 93.7500 (88.6857)  time: 0.3586  data: 0.0008  max mem: 2501
Train: Epoch[1/5]  [ 320/1142]  eta: 0:04:56  Lr: 0.001875  Loss: 0.3760  Acc@1: 56.2500 (53.2126)  Acc@5: 93.7500 (88.7266)  time: 0.3533  data: 0.0005  max mem: 2501
Train: Epoch[1/5]  [ 330/1142]  eta: 0:04:52  Lr: 0.001875  Loss: 0.2298  Acc@1: 56.2500 (53.4177)  Acc@5: 87.5000 (88.8029)  time: 0.3621  data: 0.0007  max mem: 2501
Train: Epoch[1/5]  [ 340/1142]  eta: 0:04:48  Lr: 0.001875  Loss: 0.3439  Acc@1: 62.5000 (53.6290)  Acc@5: 93.7500 (88.9296)  time: 0.3587  data: 0.0007  max mem: 2501
Train: Epoch[1/5]  [ 350/1142]  eta: 0:04:45  Lr: 0.001875  Loss: -0.1835  Acc@1: 62.5000 (53.6859)  Acc@5: 93.7500 (89.0491)  time: 0.3535  data: 0.0004  max mem: 2501
Train: Epoch[1/5]  [ 360/1142]  eta: 0:04:41  Lr: 0.001875  Loss: 0.1404  Acc@1: 62.5000 (53.9647)  Acc@5: 93.7500 (89.1447)  time: 0.3588  data: 0.0008  max mem: 2501
Train: Epoch[1/5]  [ 370/1142]  eta: 0:04:37  Lr: 0.001875  Loss: -0.1931  Acc@1: 62.5000 (54.0937)  Acc@5: 93.7500 (89.1846)  time: 0.3575  data: 0.0008  max mem: 2501
Train: Epoch[1/5]  [ 380/1142]  eta: 0:04:34  Lr: 0.001875  Loss: 0.0107  Acc@1: 56.2500 (54.1339)  Acc@5: 93.7500 (89.2552)  time: 0.3607  data: 0.0007  max mem: 2501
Train: Epoch[1/5]  [ 390/1142]  eta: 0:04:31  Lr: 0.001875  Loss: 0.5453  Acc@1: 56.2500 (54.2359)  Acc@5: 93.7500 (89.3702)  time: 0.3718  data: 0.0011  max mem: 2501
Train: Epoch[1/5]  [ 400/1142]  eta: 0:04:27  Lr: 0.001875  Loss: 0.3194  Acc@1: 62.5000 (54.5355)  Acc@5: 93.7500 (89.5106)  time: 0.3611  data: 0.0009  max mem: 2501
Train: Epoch[1/5]  [ 410/1142]  eta: 0:04:23  Lr: 0.001875  Loss: 0.3656  Acc@1: 68.7500 (54.8054)  Acc@5: 93.7500 (89.6442)  time: 0.3518  data: 0.0008  max mem: 2501
Train: Epoch[1/5]  [ 420/1142]  eta: 0:04:20  Lr: 0.001875  Loss: 0.1025  Acc@1: 62.5000 (54.8842)  Acc@5: 93.7500 (89.7120)  time: 0.3620  data: 0.0010  max mem: 2501
Train: Epoch[1/5]  [ 430/1142]  eta: 0:04:16  Lr: 0.001875  Loss: 0.1297  Acc@1: 62.5000 (55.0319)  Acc@5: 93.7500 (89.7187)  time: 0.3568  data: 0.0007  max mem: 2501
Train: Epoch[1/5]  [ 440/1142]  eta: 0:04:12  Lr: 0.001875  Loss: 0.0501  Acc@1: 62.5000 (55.1871)  Acc@5: 93.7500 (89.8243)  time: 0.3527  data: 0.0005  max mem: 2501
Train: Epoch[1/5]  [ 450/1142]  eta: 0:04:09  Lr: 0.001875  Loss: 0.0379  Acc@1: 62.5000 (55.2799)  Acc@5: 93.7500 (89.9529)  time: 0.3590  data: 0.0004  max mem: 2501
Train: Epoch[1/5]  [ 460/1142]  eta: 0:04:05  Lr: 0.001875  Loss: -0.1494  Acc@1: 56.2500 (55.4230)  Acc@5: 93.7500 (90.0081)  time: 0.3580  data: 0.0006  max mem: 2501
Train: Epoch[1/5]  [ 470/1142]  eta: 0:04:02  Lr: 0.001875  Loss: -0.1564  Acc@1: 56.2500 (55.4936)  Acc@5: 93.7500 (90.0743)  time: 0.3634  data: 0.0006  max mem: 2501
Train: Epoch[1/5]  [ 480/1142]  eta: 0:03:58  Lr: 0.001875  Loss: -0.0756  Acc@1: 56.2500 (55.5353)  Acc@5: 93.7500 (90.1637)  time: 0.3683  data: 0.0008  max mem: 2501
Train: Epoch[1/5]  [ 490/1142]  eta: 0:03:54  Lr: 0.001875  Loss: -0.0306  Acc@1: 56.2500 (55.6263)  Acc@5: 100.0000 (90.2877)  time: 0.3555  data: 0.0008  max mem: 2501
Train: Epoch[1/5]  [ 500/1142]  eta: 0:03:51  Lr: 0.001875  Loss: -0.0004  Acc@1: 62.5000 (55.7884)  Acc@5: 93.7500 (90.3069)  time: 0.3505  data: 0.0006  max mem: 2501
Train: Epoch[1/5]  [ 510/1142]  eta: 0:03:47  Lr: 0.001875  Loss: 0.0365  Acc@1: 62.5000 (55.9442)  Acc@5: 93.7500 (90.3620)  time: 0.3636  data: 0.0007  max mem: 2501
Train: Epoch[1/5]  [ 520/1142]  eta: 0:03:43  Lr: 0.001875  Loss: -0.1758  Acc@1: 62.5000 (56.0221)  Acc@5: 93.7500 (90.3911)  time: 0.3584  data: 0.0006  max mem: 2501
Train: Epoch[1/5]  [ 530/1142]  eta: 0:03:40  Lr: 0.001875  Loss: -0.0366  Acc@1: 62.5000 (56.1323)  Acc@5: 93.7500 (90.4426)  time: 0.3505  data: 0.0005  max mem: 2501
Train: Epoch[1/5]  [ 540/1142]  eta: 0:03:36  Lr: 0.001875  Loss: 0.2009  Acc@1: 62.5000 (56.2731)  Acc@5: 93.7500 (90.4228)  time: 0.3620  data: 0.0005  max mem: 2501
Train: Epoch[1/5]  [ 550/1142]  eta: 0:03:32  Lr: 0.001875  Loss: -0.1664  Acc@1: 62.5000 (56.4769)  Acc@5: 87.5000 (90.4152)  time: 0.3574  data: 0.0008  max mem: 2501
Train: Epoch[1/5]  [ 560/1142]  eta: 0:03:29  Lr: 0.001875  Loss: -0.2954  Acc@1: 62.5000 (56.5842)  Acc@5: 87.5000 (90.4412)  time: 0.3503  data: 0.0008  max mem: 2501
Train: Epoch[1/5]  [ 570/1142]  eta: 0:03:25  Lr: 0.001875  Loss: 0.1024  Acc@1: 56.2500 (56.6331)  Acc@5: 87.5000 (90.4225)  time: 0.3603  data: 0.0005  max mem: 2501
Train: Epoch[1/5]  [ 580/1142]  eta: 0:03:22  Lr: 0.001875  Loss: 0.2239  Acc@1: 56.2500 (56.7341)  Acc@5: 87.5000 (90.4152)  time: 0.3671  data: 0.0006  max mem: 2501
Train: Epoch[1/5]  [ 590/1142]  eta: 0:03:18  Lr: 0.001875  Loss: 0.2322  Acc@1: 56.2500 (56.7893)  Acc@5: 87.5000 (90.4399)  time: 0.3580  data: 0.0005  max mem: 2501
Train: Epoch[1/5]  [ 600/1142]  eta: 0:03:14  Lr: 0.001875  Loss: -0.0779  Acc@1: 62.5000 (56.8428)  Acc@5: 93.7500 (90.4534)  time: 0.3549  data: 0.0005  max mem: 2501
Train: Epoch[1/5]  [ 610/1142]  eta: 0:03:11  Lr: 0.001875  Loss: 0.2518  Acc@1: 62.5000 (56.8331)  Acc@5: 93.7500 (90.4869)  time: 0.3601  data: 0.0007  max mem: 2501
Train: Epoch[1/5]  [ 620/1142]  eta: 0:03:07  Lr: 0.001875  Loss: -0.4168  Acc@1: 50.0000 (56.7935)  Acc@5: 93.7500 (90.5093)  time: 0.3568  data: 0.0007  max mem: 2501
Train: Epoch[1/5]  [ 630/1142]  eta: 0:03:04  Lr: 0.001875  Loss: -0.3027  Acc@1: 56.2500 (56.9136)  Acc@5: 93.7500 (90.5804)  time: 0.3598  data: 0.0006  max mem: 2501
Train: Epoch[1/5]  [ 640/1142]  eta: 0:03:00  Lr: 0.001875  Loss: 0.3966  Acc@1: 62.5000 (56.9325)  Acc@5: 93.7500 (90.5519)  time: 0.3626  data: 0.0011  max mem: 2501
Train: Epoch[1/5]  [ 650/1142]  eta: 0:02:56  Lr: 0.001875  Loss: 0.3098  Acc@1: 62.5000 (57.0084)  Acc@5: 87.5000 (90.5818)  time: 0.3557  data: 0.0010  max mem: 2501
Train: Epoch[1/5]  [ 660/1142]  eta: 0:02:53  Lr: 0.001875  Loss: -0.3429  Acc@1: 62.5000 (57.1010)  Acc@5: 87.5000 (90.5635)  time: 0.3602  data: 0.0006  max mem: 2501
Train: Epoch[1/5]  [ 670/1142]  eta: 0:02:49  Lr: 0.001875  Loss: 0.5473  Acc@1: 62.5000 (57.2280)  Acc@5: 93.7500 (90.5924)  time: 0.3688  data: 0.0006  max mem: 2501
Train: Epoch[1/5]  [ 680/1142]  eta: 0:02:46  Lr: 0.001875  Loss: -0.1037  Acc@1: 62.5000 (57.3421)  Acc@5: 93.7500 (90.6663)  time: 0.3589  data: 0.0005  max mem: 2501
Train: Epoch[1/5]  [ 690/1142]  eta: 0:02:42  Lr: 0.001875  Loss: 0.1694  Acc@1: 56.2500 (57.3716)  Acc@5: 93.7500 (90.6567)  time: 0.3536  data: 0.0005  max mem: 2501
Train: Epoch[1/5]  [ 700/1142]  eta: 0:02:39  Lr: 0.001875  Loss: -0.6030  Acc@1: 62.5000 (57.5695)  Acc@5: 93.7500 (90.7364)  time: 0.3641  data: 0.0007  max mem: 2501
Train: Epoch[1/5]  [ 710/1142]  eta: 0:02:35  Lr: 0.001875  Loss: 0.0820  Acc@1: 68.7500 (57.6916)  Acc@5: 93.7500 (90.7788)  time: 0.3602  data: 0.0007  max mem: 2501
Train: Epoch[1/5]  [ 720/1142]  eta: 0:02:31  Lr: 0.001875  Loss: -0.4042  Acc@1: 68.7500 (57.8363)  Acc@5: 93.7500 (90.8287)  time: 0.3535  data: 0.0005  max mem: 2501
Train: Epoch[1/5]  [ 730/1142]  eta: 0:02:28  Lr: 0.001875  Loss: -0.0475  Acc@1: 68.7500 (57.9001)  Acc@5: 93.7500 (90.8259)  time: 0.3589  data: 0.0004  max mem: 2501
Train: Epoch[1/5]  [ 740/1142]  eta: 0:02:24  Lr: 0.001875  Loss: 0.1235  Acc@1: 62.5000 (57.9622)  Acc@5: 87.5000 (90.8232)  time: 0.3559  data: 0.0004  max mem: 2501
Train: Epoch[1/5]  [ 750/1142]  eta: 0:02:20  Lr: 0.001875  Loss: -0.1413  Acc@1: 62.5000 (58.0975)  Acc@5: 93.7500 (90.8955)  time: 0.3570  data: 0.0005  max mem: 2501
Train: Epoch[1/5]  [ 760/1142]  eta: 0:02:17  Lr: 0.001875  Loss: -0.4282  Acc@1: 62.5000 (58.1143)  Acc@5: 93.7500 (90.9083)  time: 0.3698  data: 0.0008  max mem: 2501
Train: Epoch[1/5]  [ 770/1142]  eta: 0:02:13  Lr: 0.001875  Loss: -0.0122  Acc@1: 56.2500 (58.1712)  Acc@5: 93.7500 (90.9776)  time: 0.3638  data: 0.0011  max mem: 2501
Train: Epoch[1/5]  [ 780/1142]  eta: 0:02:10  Lr: 0.001875  Loss: -0.0073  Acc@1: 62.5000 (58.2506)  Acc@5: 93.7500 (90.9971)  time: 0.3550  data: 0.0021  max mem: 2501
Train: Epoch[1/5]  [ 790/1142]  eta: 0:02:06  Lr: 0.001875  Loss: 0.0221  Acc@1: 62.5000 (58.2332)  Acc@5: 93.7500 (91.0319)  time: 0.3634  data: 0.0020  max mem: 2501
Train: Epoch[1/5]  [ 800/1142]  eta: 0:02:02  Lr: 0.001875  Loss: -0.0125  Acc@1: 56.2500 (58.2319)  Acc@5: 93.7500 (91.0581)  time: 0.3587  data: 0.0009  max mem: 2501
Train: Epoch[1/5]  [ 810/1142]  eta: 0:01:59  Lr: 0.001875  Loss: -0.4575  Acc@1: 62.5000 (58.3539)  Acc@5: 93.7500 (91.0912)  time: 0.3537  data: 0.0005  max mem: 2501
Train: Epoch[1/5]  [ 820/1142]  eta: 0:01:55  Lr: 0.001875  Loss: -0.3571  Acc@1: 62.5000 (58.4120)  Acc@5: 93.7500 (91.1312)  time: 0.3614  data: 0.0004  max mem: 2501
Train: Epoch[1/5]  [ 830/1142]  eta: 0:01:52  Lr: 0.001875  Loss: 0.0596  Acc@1: 68.7500 (58.5289)  Acc@5: 93.7500 (91.1402)  time: 0.3583  data: 0.0007  max mem: 2501
Train: Epoch[1/5]  [ 840/1142]  eta: 0:01:48  Lr: 0.001875  Loss: 0.2062  Acc@1: 62.5000 (58.5612)  Acc@5: 93.7500 (91.1787)  time: 0.3561  data: 0.0007  max mem: 2501
Train: Epoch[1/5]  [ 850/1142]  eta: 0:01:45  Lr: 0.001875  Loss: -0.1024  Acc@1: 62.5000 (58.6589)  Acc@5: 93.7500 (91.1868)  time: 0.3659  data: 0.0010  max mem: 2501
Train: Epoch[1/5]  [ 860/1142]  eta: 0:01:41  Lr: 0.001875  Loss: -0.5675  Acc@1: 68.7500 (58.7471)  Acc@5: 93.7500 (91.2093)  time: 0.3646  data: 0.0010  max mem: 2501
Train: Epoch[1/5]  [ 870/1142]  eta: 0:01:37  Lr: 0.001875  Loss: -0.1080  Acc@1: 68.7500 (58.8045)  Acc@5: 93.7500 (91.2026)  time: 0.3541  data: 0.0005  max mem: 2501
Train: Epoch[1/5]  [ 880/1142]  eta: 0:01:34  Lr: 0.001875  Loss: -0.1654  Acc@1: 68.7500 (58.8890)  Acc@5: 93.7500 (91.2174)  time: 0.3545  data: 0.0004  max mem: 2501
Train: Epoch[1/5]  [ 890/1142]  eta: 0:01:30  Lr: 0.001875  Loss: -0.3114  Acc@1: 62.5000 (58.9296)  Acc@5: 93.7500 (91.1897)  time: 0.3606  data: 0.0005  max mem: 2501
Train: Epoch[1/5]  [ 900/1142]  eta: 0:01:27  Lr: 0.001875  Loss: -0.1700  Acc@1: 68.7500 (59.0178)  Acc@5: 93.7500 (91.2181)  time: 0.3572  data: 0.0006  max mem: 2501
Train: Epoch[1/5]  [ 910/1142]  eta: 0:01:23  Lr: 0.001875  Loss: 0.2103  Acc@1: 68.7500 (59.0834)  Acc@5: 93.7500 (91.2527)  time: 0.3555  data: 0.0006  max mem: 2501
Train: Epoch[1/5]  [ 920/1142]  eta: 0:01:19  Lr: 0.001875  Loss: -0.3984  Acc@1: 56.2500 (59.1205)  Acc@5: 93.7500 (91.2731)  time: 0.3598  data: 0.0014  max mem: 2501
Train: Epoch[1/5]  [ 930/1142]  eta: 0:01:16  Lr: 0.001875  Loss: -0.3356  Acc@1: 62.5000 (59.2105)  Acc@5: 93.7500 (91.3064)  time: 0.3577  data: 0.0019  max mem: 2501
Train: Epoch[1/5]  [ 940/1142]  eta: 0:01:12  Lr: 0.001875  Loss: -0.0371  Acc@1: 68.7500 (59.3185)  Acc@5: 93.7500 (91.2792)  time: 0.3626  data: 0.0011  max mem: 2501
Train: Epoch[1/5]  [ 950/1142]  eta: 0:01:09  Lr: 0.001875  Loss: 0.1073  Acc@1: 68.7500 (59.3914)  Acc@5: 87.5000 (91.2986)  time: 0.3696  data: 0.0015  max mem: 2501
Train: Epoch[1/5]  [ 960/1142]  eta: 0:01:05  Lr: 0.001875  Loss: -0.1815  Acc@1: 68.7500 (59.4953)  Acc@5: 93.7500 (91.3306)  time: 0.3574  data: 0.0016  max mem: 2501
Train: Epoch[1/5]  [ 970/1142]  eta: 0:01:01  Lr: 0.001875  Loss: -0.1168  Acc@1: 68.7500 (59.5778)  Acc@5: 93.7500 (91.3620)  time: 0.3514  data: 0.0007  max mem: 2501
Train: Epoch[1/5]  [ 980/1142]  eta: 0:00:58  Lr: 0.001875  Loss: -0.2889  Acc@1: 68.7500 (59.6075)  Acc@5: 93.7500 (91.3672)  time: 0.3641  data: 0.0004  max mem: 2501
Train: Epoch[1/5]  [ 990/1142]  eta: 0:00:54  Lr: 0.001875  Loss: -0.1256  Acc@1: 62.5000 (59.6241)  Acc@5: 93.7500 (91.4165)  time: 0.3588  data: 0.0005  max mem: 2501
Train: Epoch[1/5]  [1000/1142]  eta: 0:00:51  Lr: 0.001875  Loss: 0.3255  Acc@1: 62.5000 (59.6966)  Acc@5: 93.7500 (91.4585)  time: 0.3519  data: 0.0006  max mem: 2501
Train: Epoch[1/5]  [1010/1142]  eta: 0:00:47  Lr: 0.001875  Loss: 0.2097  Acc@1: 62.5000 (59.7181)  Acc@5: 93.7500 (91.4627)  time: 0.3631  data: 0.0006  max mem: 2501
Train: Epoch[1/5]  [1020/1142]  eta: 0:00:43  Lr: 0.001875  Loss: 0.1465  Acc@1: 62.5000 (59.7760)  Acc@5: 93.7500 (91.4912)  time: 0.3571  data: 0.0005  max mem: 2501
Train: Epoch[1/5]  [1030/1142]  eta: 0:00:40  Lr: 0.001875  Loss: -0.1725  Acc@1: 62.5000 (59.8084)  Acc@5: 93.7500 (91.5434)  time: 0.3515  data: 0.0005  max mem: 2501
Train: Epoch[1/5]  [1040/1142]  eta: 0:00:36  Lr: 0.001875  Loss: -0.2742  Acc@1: 62.5000 (59.8523)  Acc@5: 93.7500 (91.5346)  time: 0.3636  data: 0.0007  max mem: 2501
Train: Epoch[1/5]  [1050/1142]  eta: 0:00:33  Lr: 0.001875  Loss: -0.1143  Acc@1: 62.5000 (59.8180)  Acc@5: 93.7500 (91.5557)  time: 0.3699  data: 0.0012  max mem: 2501
Train: Epoch[1/5]  [1060/1142]  eta: 0:00:29  Lr: 0.001875  Loss: -0.1680  Acc@1: 50.0000 (59.8139)  Acc@5: 93.7500 (91.5705)  time: 0.3588  data: 0.0012  max mem: 2501
Train: Epoch[1/5]  [1070/1142]  eta: 0:00:25  Lr: 0.001875  Loss: 0.0092  Acc@1: 62.5000 (59.9031)  Acc@5: 93.7500 (91.6141)  time: 0.3527  data: 0.0009  max mem: 2501
Train: Epoch[1/5]  [1080/1142]  eta: 0:00:22  Lr: 0.001875  Loss: -0.1233  Acc@1: 75.0000 (60.0312)  Acc@5: 100.0000 (91.6512)  time: 0.3643  data: 0.0015  max mem: 2501
Train: Epoch[1/5]  [1090/1142]  eta: 0:00:18  Lr: 0.001875  Loss: -0.0635  Acc@1: 68.7500 (60.0596)  Acc@5: 93.7500 (91.6304)  time: 0.3584  data: 0.0012  max mem: 2501
Train: Epoch[1/5]  [1100/1142]  eta: 0:00:15  Lr: 0.001875  Loss: -0.3863  Acc@1: 68.7500 (60.1442)  Acc@5: 93.7500 (91.6553)  time: 0.3526  data: 0.0007  max mem: 2501
Train: Epoch[1/5]  [1110/1142]  eta: 0:00:11  Lr: 0.001875  Loss: 0.2035  Acc@1: 62.5000 (60.1654)  Acc@5: 93.7500 (91.6742)  time: 0.3625  data: 0.0006  max mem: 2501
Train: Epoch[1/5]  [1120/1142]  eta: 0:00:07  Lr: 0.001875  Loss: -0.1779  Acc@1: 62.5000 (60.2141)  Acc@5: 93.7500 (91.6760)  time: 0.3566  data: 0.0005  max mem: 2501
Train: Epoch[1/5]  [1130/1142]  eta: 0:00:04  Lr: 0.001875  Loss: -0.2738  Acc@1: 62.5000 (60.2343)  Acc@5: 93.7500 (91.6998)  time: 0.3528  data: 0.0008  max mem: 2501
Train: Epoch[1/5]  [1140/1142]  eta: 0:00:00  Lr: 0.001875  Loss: -0.1695  Acc@1: 68.7500 (60.3309)  Acc@5: 93.7500 (91.7287)  time: 0.3626  data: 0.0010  max mem: 2501
Train: Epoch[1/5]  [1141/1142]  eta: 0:00:00  Lr: 0.001875  Loss: 0.4928  Acc@1: 68.7500 (60.3318)  Acc@5: 93.7500 (91.7159)  time: 0.3725  data: 0.0010  max mem: 2501
Train: Epoch[1/5] Total time: 0:06:51 (0.3600 s / it)
{0: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 1: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 2: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 3: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 4: {0: 0, 1: 300000, 2: 0, 3: 64, 4: 0}, 5: {0: 0, 1: 300000, 2: 0, 3: 64, 4: 0}, 6: {0: 0, 1: 300000, 2: 0, 3: 64, 4: 0}, 7: {0: 0, 1: 300000, 2: 0, 3: 64, 4: 0}, 8: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 9: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 10: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 11: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 12: {0: 0, 1: 0, 2: 0, 3: 18200, 4: 0}, 13: {0: 0, 1: 0, 2: 0, 3: 18200, 4: 0}, 14: {0: 0, 1: 0, 2: 0, 3: 18200, 4: 0}, 15: {0: 0, 1: 0, 2: 0, 3: 18200, 4: 0}, 16: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 17: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 18: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 19: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}}
Averaged stats: Lr: 0.001875  Loss: 0.4928  Acc@1: 68.7500 (60.3318)  Acc@5: 93.7500 (91.7159)
Train: Epoch[2/5]  [   0/1142]  eta: 0:21:03  Lr: 0.001875  Loss: -0.8567  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (100.0000)  time: 1.1062  data: 0.6486  max mem: 2502
Train: Epoch[2/5]  [  10/1142]  eta: 0:07:50  Lr: 0.001875  Loss: -0.4918  Acc@1: 68.7500 (66.4773)  Acc@5: 93.7500 (95.4545)  time: 0.4158  data: 0.0594  max mem: 2502
Train: Epoch[2/5]  [  20/1142]  eta: 0:07:13  Lr: 0.001875  Loss: -0.2956  Acc@1: 68.7500 (67.5595)  Acc@5: 93.7500 (95.5357)  time: 0.3501  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [  30/1142]  eta: 0:07:00  Lr: 0.001875  Loss: -0.1681  Acc@1: 68.7500 (66.7339)  Acc@5: 93.7500 (94.7581)  time: 0.3573  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [  40/1142]  eta: 0:06:51  Lr: 0.001875  Loss: 0.0316  Acc@1: 62.5000 (67.0732)  Acc@5: 93.7500 (94.5122)  time: 0.3609  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [  50/1142]  eta: 0:06:45  Lr: 0.001875  Loss: -0.3824  Acc@1: 62.5000 (66.2990)  Acc@5: 93.7500 (94.2402)  time: 0.3604  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [  60/1142]  eta: 0:06:41  Lr: 0.001875  Loss: 0.1727  Acc@1: 56.2500 (65.4713)  Acc@5: 93.7500 (93.3402)  time: 0.3669  data: 0.0007  max mem: 2502
Train: Epoch[2/5]  [  70/1142]  eta: 0:06:34  Lr: 0.001875  Loss: -0.1340  Acc@1: 62.5000 (65.0528)  Acc@5: 93.7500 (93.3099)  time: 0.3605  data: 0.0008  max mem: 2502
Train: Epoch[2/5]  [  80/1142]  eta: 0:06:29  Lr: 0.001875  Loss: -0.3309  Acc@1: 62.5000 (65.5864)  Acc@5: 93.7500 (93.7500)  time: 0.3531  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [  90/1142]  eta: 0:06:26  Lr: 0.001875  Loss: -0.3310  Acc@1: 62.5000 (65.7967)  Acc@5: 100.0000 (94.0934)  time: 0.3634  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [ 100/1142]  eta: 0:06:21  Lr: 0.001875  Loss: -0.1390  Acc@1: 62.5000 (65.4703)  Acc@5: 93.7500 (93.9356)  time: 0.3646  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [ 110/1142]  eta: 0:06:16  Lr: 0.001875  Loss: -0.6765  Acc@1: 62.5000 (65.8784)  Acc@5: 93.7500 (93.9189)  time: 0.3566  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [ 120/1142]  eta: 0:06:13  Lr: 0.001875  Loss: -0.0567  Acc@1: 75.0000 (66.0640)  Acc@5: 93.7500 (93.9566)  time: 0.3615  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [ 130/1142]  eta: 0:06:08  Lr: 0.001875  Loss: 0.2519  Acc@1: 62.5000 (65.8874)  Acc@5: 93.7500 (93.9408)  time: 0.3592  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [ 140/1142]  eta: 0:06:04  Lr: 0.001875  Loss: -0.1806  Acc@1: 62.5000 (65.6915)  Acc@5: 93.7500 (93.9716)  time: 0.3514  data: 0.0007  max mem: 2502
Train: Epoch[2/5]  [ 150/1142]  eta: 0:06:00  Lr: 0.001875  Loss: 0.6220  Acc@1: 62.5000 (65.4801)  Acc@5: 93.7500 (93.8328)  time: 0.3610  data: 0.0009  max mem: 2502
Train: Epoch[2/5]  [ 160/1142]  eta: 0:05:56  Lr: 0.001875  Loss: -0.1347  Acc@1: 62.5000 (65.5668)  Acc@5: 93.7500 (93.8276)  time: 0.3576  data: 0.0009  max mem: 2502
Train: Epoch[2/5]  [ 170/1142]  eta: 0:05:52  Lr: 0.001875  Loss: 0.2788  Acc@1: 62.5000 (65.7529)  Acc@5: 93.7500 (93.7500)  time: 0.3528  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [ 180/1142]  eta: 0:05:49  Lr: 0.001875  Loss: 0.3096  Acc@1: 68.7500 (65.6077)  Acc@5: 93.7500 (93.7500)  time: 0.3628  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [ 190/1142]  eta: 0:05:45  Lr: 0.001875  Loss: -0.2234  Acc@1: 68.7500 (65.5759)  Acc@5: 93.7500 (93.6191)  time: 0.3671  data: 0.0011  max mem: 2502
Train: Epoch[2/5]  [ 200/1142]  eta: 0:05:41  Lr: 0.001875  Loss: -0.5720  Acc@1: 68.7500 (65.8582)  Acc@5: 93.7500 (93.7189)  time: 0.3577  data: 0.0013  max mem: 2502
Train: Epoch[2/5]  [ 210/1142]  eta: 0:05:37  Lr: 0.001875  Loss: -0.4708  Acc@1: 62.5000 (65.7583)  Acc@5: 100.0000 (93.9870)  time: 0.3543  data: 0.0007  max mem: 2502
Train: Epoch[2/5]  [ 220/1142]  eta: 0:05:33  Lr: 0.001875  Loss: 0.1477  Acc@1: 62.5000 (65.5260)  Acc@5: 100.0000 (93.9762)  time: 0.3594  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [ 230/1142]  eta: 0:05:29  Lr: 0.001875  Loss: -0.3948  Acc@1: 62.5000 (65.5303)  Acc@5: 93.7500 (93.9935)  time: 0.3545  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [ 240/1142]  eta: 0:05:26  Lr: 0.001875  Loss: -0.6535  Acc@1: 68.7500 (65.7158)  Acc@5: 93.7500 (93.9315)  time: 0.3558  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [ 250/1142]  eta: 0:05:22  Lr: 0.001875  Loss: -0.3052  Acc@1: 68.7500 (65.8118)  Acc@5: 93.7500 (93.9492)  time: 0.3611  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [ 260/1142]  eta: 0:05:18  Lr: 0.001875  Loss: -0.1422  Acc@1: 62.5000 (65.6609)  Acc@5: 93.7500 (93.7739)  time: 0.3558  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [ 270/1142]  eta: 0:05:14  Lr: 0.001875  Loss: -0.1634  Acc@1: 62.5000 (65.6827)  Acc@5: 93.7500 (93.7961)  time: 0.3559  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [ 280/1142]  eta: 0:05:11  Lr: 0.001875  Loss: 0.3437  Acc@1: 62.5000 (65.7251)  Acc@5: 93.7500 (93.7722)  time: 0.3698  data: 0.0008  max mem: 2502
Train: Epoch[2/5]  [ 290/1142]  eta: 0:05:07  Lr: 0.001875  Loss: -0.4087  Acc@1: 62.5000 (65.7646)  Acc@5: 93.7500 (93.7500)  time: 0.3638  data: 0.0011  max mem: 2502
Train: Epoch[2/5]  [ 300/1142]  eta: 0:05:04  Lr: 0.001875  Loss: -0.3301  Acc@1: 62.5000 (65.8015)  Acc@5: 93.7500 (93.7500)  time: 0.3533  data: 0.0010  max mem: 2502
Train: Epoch[2/5]  [ 310/1142]  eta: 0:05:00  Lr: 0.001875  Loss: -0.0600  Acc@1: 62.5000 (65.6551)  Acc@5: 93.7500 (93.6696)  time: 0.3625  data: 0.0020  max mem: 2502
Train: Epoch[2/5]  [ 320/1142]  eta: 0:04:56  Lr: 0.001875  Loss: -0.3964  Acc@1: 62.5000 (65.4400)  Acc@5: 93.7500 (93.6721)  time: 0.3580  data: 0.0021  max mem: 2502
Train: Epoch[2/5]  [ 330/1142]  eta: 0:04:53  Lr: 0.001875  Loss: 0.0835  Acc@1: 62.5000 (65.2568)  Acc@5: 93.7500 (93.5989)  time: 0.3550  data: 0.0007  max mem: 2502
Train: Epoch[2/5]  [ 340/1142]  eta: 0:04:49  Lr: 0.001875  Loss: -0.0412  Acc@1: 62.5000 (65.3043)  Acc@5: 93.7500 (93.6034)  time: 0.3626  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [ 350/1142]  eta: 0:04:45  Lr: 0.001875  Loss: -0.1691  Acc@1: 68.7500 (65.4024)  Acc@5: 93.7500 (93.6610)  time: 0.3580  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [ 360/1142]  eta: 0:04:42  Lr: 0.001875  Loss: 0.0984  Acc@1: 68.7500 (65.5644)  Acc@5: 100.0000 (93.7846)  time: 0.3566  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [ 370/1142]  eta: 0:04:38  Lr: 0.001875  Loss: 0.1497  Acc@1: 68.7500 (65.6166)  Acc@5: 100.0000 (93.7837)  time: 0.3604  data: 0.0007  max mem: 2502
Train: Epoch[2/5]  [ 380/1142]  eta: 0:04:35  Lr: 0.001875  Loss: -0.2484  Acc@1: 68.7500 (65.6332)  Acc@5: 93.7500 (93.7500)  time: 0.3620  data: 0.0013  max mem: 2502
Train: Epoch[2/5]  [ 390/1142]  eta: 0:04:31  Lr: 0.001875  Loss: -0.1333  Acc@1: 62.5000 (65.5850)  Acc@5: 93.7500 (93.6701)  time: 0.3595  data: 0.0011  max mem: 2502
Train: Epoch[2/5]  [ 400/1142]  eta: 0:04:27  Lr: 0.001875  Loss: 0.1705  Acc@1: 62.5000 (65.5860)  Acc@5: 93.7500 (93.6253)  time: 0.3612  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [ 410/1142]  eta: 0:04:23  Lr: 0.001875  Loss: 0.4964  Acc@1: 68.7500 (65.5262)  Acc@5: 93.7500 (93.5675)  time: 0.3585  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [ 420/1142]  eta: 0:04:20  Lr: 0.001875  Loss: -0.4420  Acc@1: 62.5000 (65.4097)  Acc@5: 93.7500 (93.5422)  time: 0.3526  data: 0.0012  max mem: 2502
Train: Epoch[2/5]  [ 430/1142]  eta: 0:04:16  Lr: 0.001875  Loss: -0.3417  Acc@1: 68.7500 (65.5742)  Acc@5: 100.0000 (93.6630)  time: 0.3635  data: 0.0012  max mem: 2502
Train: Epoch[2/5]  [ 440/1142]  eta: 0:04:13  Lr: 0.001875  Loss: -0.3577  Acc@1: 68.7500 (65.5329)  Acc@5: 93.7500 (93.5658)  time: 0.3579  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [ 450/1142]  eta: 0:04:09  Lr: 0.001875  Loss: -0.4808  Acc@1: 62.5000 (65.5488)  Acc@5: 87.5000 (93.5283)  time: 0.3514  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [ 460/1142]  eta: 0:04:05  Lr: 0.001875  Loss: -0.2733  Acc@1: 68.7500 (65.6589)  Acc@5: 93.7500 (93.5738)  time: 0.3620  data: 0.0014  max mem: 2502
Train: Epoch[2/5]  [ 470/1142]  eta: 0:04:02  Lr: 0.001875  Loss: -0.4521  Acc@1: 68.7500 (65.6184)  Acc@5: 93.7500 (93.6173)  time: 0.3681  data: 0.0025  max mem: 2502
Train: Epoch[2/5]  [ 480/1142]  eta: 0:03:58  Lr: 0.001875  Loss: 0.2532  Acc@1: 62.5000 (65.5405)  Acc@5: 93.7500 (93.6071)  time: 0.3589  data: 0.0015  max mem: 2502
Train: Epoch[2/5]  [ 490/1142]  eta: 0:03:54  Lr: 0.001875  Loss: -0.4224  Acc@1: 62.5000 (65.5295)  Acc@5: 93.7500 (93.6100)  time: 0.3532  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [ 500/1142]  eta: 0:03:51  Lr: 0.001875  Loss: -0.3843  Acc@1: 62.5000 (65.5564)  Acc@5: 93.7500 (93.6502)  time: 0.3631  data: 0.0010  max mem: 2502
Train: Epoch[2/5]  [ 510/1142]  eta: 0:03:47  Lr: 0.001875  Loss: 0.0479  Acc@1: 68.7500 (65.5822)  Acc@5: 93.7500 (93.6766)  time: 0.3578  data: 0.0008  max mem: 2502
Train: Epoch[2/5]  [ 520/1142]  eta: 0:03:44  Lr: 0.001875  Loss: 0.2516  Acc@1: 68.7500 (65.5830)  Acc@5: 93.7500 (93.6780)  time: 0.3536  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [ 530/1142]  eta: 0:03:40  Lr: 0.001875  Loss: 0.4089  Acc@1: 62.5000 (65.5014)  Acc@5: 93.7500 (93.6441)  time: 0.3641  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [ 540/1142]  eta: 0:03:36  Lr: 0.001875  Loss: 0.1517  Acc@1: 62.5000 (65.5615)  Acc@5: 93.7500 (93.6345)  time: 0.3597  data: 0.0008  max mem: 2502
Train: Epoch[2/5]  [ 550/1142]  eta: 0:03:33  Lr: 0.001875  Loss: -0.3940  Acc@1: 68.7500 (65.7101)  Acc@5: 93.7500 (93.7046)  time: 0.3569  data: 0.0011  max mem: 2502
Train: Epoch[2/5]  [ 560/1142]  eta: 0:03:29  Lr: 0.001875  Loss: 0.2237  Acc@1: 68.7500 (65.7086)  Acc@5: 100.0000 (93.7277)  time: 0.3677  data: 0.0010  max mem: 2502
Train: Epoch[2/5]  [ 570/1142]  eta: 0:03:26  Lr: 0.001875  Loss: 0.3201  Acc@1: 68.7500 (65.7290)  Acc@5: 93.7500 (93.7281)  time: 0.3687  data: 0.0009  max mem: 2502
Train: Epoch[2/5]  [ 580/1142]  eta: 0:03:22  Lr: 0.001875  Loss: -0.2748  Acc@1: 62.5000 (65.6304)  Acc@5: 93.7500 (93.6962)  time: 0.3569  data: 0.0010  max mem: 2502
Train: Epoch[2/5]  [ 590/1142]  eta: 0:03:18  Lr: 0.001875  Loss: -0.1473  Acc@1: 62.5000 (65.6409)  Acc@5: 93.7500 (93.6865)  time: 0.3519  data: 0.0009  max mem: 2502
Train: Epoch[2/5]  [ 600/1142]  eta: 0:03:15  Lr: 0.001875  Loss: -0.2246  Acc@1: 68.7500 (65.6718)  Acc@5: 93.7500 (93.6980)  time: 0.3624  data: 0.0007  max mem: 2502
Train: Epoch[2/5]  [ 610/1142]  eta: 0:03:11  Lr: 0.001875  Loss: -0.2298  Acc@1: 68.7500 (65.5687)  Acc@5: 93.7500 (93.6682)  time: 0.3594  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [ 620/1142]  eta: 0:03:08  Lr: 0.001875  Loss: -0.7241  Acc@1: 68.7500 (65.6200)  Acc@5: 93.7500 (93.6795)  time: 0.3586  data: 0.0010  max mem: 2502
Train: Epoch[2/5]  [ 630/1142]  eta: 0:03:04  Lr: 0.001875  Loss: -0.1030  Acc@1: 68.7500 (65.6894)  Acc@5: 93.7500 (93.7005)  time: 0.3644  data: 0.0012  max mem: 2502
Train: Epoch[2/5]  [ 640/1142]  eta: 0:03:01  Lr: 0.001875  Loss: -0.4306  Acc@1: 68.7500 (65.7274)  Acc@5: 93.7500 (93.7110)  time: 0.3665  data: 0.0016  max mem: 2502
Train: Epoch[2/5]  [ 650/1142]  eta: 0:02:57  Lr: 0.001875  Loss: -0.0821  Acc@1: 68.7500 (65.7546)  Acc@5: 93.7500 (93.7116)  time: 0.3631  data: 0.0022  max mem: 2502
Train: Epoch[2/5]  [ 660/1142]  eta: 0:02:53  Lr: 0.001875  Loss: 0.1662  Acc@1: 62.5000 (65.7337)  Acc@5: 93.7500 (93.6554)  time: 0.3557  data: 0.0016  max mem: 2502
Train: Epoch[2/5]  [ 670/1142]  eta: 0:02:50  Lr: 0.001875  Loss: 0.0401  Acc@1: 62.5000 (65.7135)  Acc@5: 93.7500 (93.6569)  time: 0.3647  data: 0.0014  max mem: 2502
Train: Epoch[2/5]  [ 680/1142]  eta: 0:02:46  Lr: 0.001875  Loss: -0.2166  Acc@1: 62.5000 (65.7214)  Acc@5: 93.7500 (93.6858)  time: 0.3741  data: 0.0029  max mem: 2502
Train: Epoch[2/5]  [ 690/1142]  eta: 0:02:43  Lr: 0.001875  Loss: 0.4030  Acc@1: 68.7500 (65.7200)  Acc@5: 93.7500 (93.6776)  time: 0.3697  data: 0.0053  max mem: 2502
Train: Epoch[2/5]  [ 700/1142]  eta: 0:02:39  Lr: 0.001875  Loss: -0.5350  Acc@1: 68.7500 (65.7275)  Acc@5: 93.7500 (93.6341)  time: 0.3726  data: 0.0061  max mem: 2502
Train: Epoch[2/5]  [ 710/1142]  eta: 0:02:36  Lr: 0.001875  Loss: -0.1008  Acc@1: 68.7500 (65.7261)  Acc@5: 93.7500 (93.6269)  time: 0.3722  data: 0.0046  max mem: 2502
Train: Epoch[2/5]  [ 720/1142]  eta: 0:02:32  Lr: 0.001875  Loss: -0.0291  Acc@1: 68.7500 (65.6987)  Acc@5: 93.7500 (93.6113)  time: 0.3634  data: 0.0038  max mem: 2502
Train: Epoch[2/5]  [ 730/1142]  eta: 0:02:28  Lr: 0.001875  Loss: -0.2626  Acc@1: 62.5000 (65.6635)  Acc@5: 87.5000 (93.5534)  time: 0.3690  data: 0.0031  max mem: 2502
Train: Epoch[2/5]  [ 740/1142]  eta: 0:02:25  Lr: 0.001875  Loss: -0.2456  Acc@1: 62.5000 (65.6630)  Acc@5: 87.5000 (93.5476)  time: 0.3625  data: 0.0023  max mem: 2502
Train: Epoch[2/5]  [ 750/1142]  eta: 0:02:21  Lr: 0.001875  Loss: -0.1246  Acc@1: 62.5000 (65.5792)  Acc@5: 93.7500 (93.5170)  time: 0.3562  data: 0.0033  max mem: 2502
Train: Epoch[2/5]  [ 760/1142]  eta: 0:02:18  Lr: 0.001875  Loss: -0.5945  Acc@1: 62.5000 (65.6291)  Acc@5: 93.7500 (93.5529)  time: 0.3652  data: 0.0048  max mem: 2502
Train: Epoch[2/5]  [ 770/1142]  eta: 0:02:14  Lr: 0.001875  Loss: -0.3931  Acc@1: 68.7500 (65.7020)  Acc@5: 100.0000 (93.5879)  time: 0.3736  data: 0.0032  max mem: 2502
Train: Epoch[2/5]  [ 780/1142]  eta: 0:02:10  Lr: 0.001875  Loss: 0.0713  Acc@1: 68.7500 (65.7010)  Acc@5: 93.7500 (93.5419)  time: 0.3659  data: 0.0009  max mem: 2502
Train: Epoch[2/5]  [ 790/1142]  eta: 0:02:07  Lr: 0.001875  Loss: -0.3404  Acc@1: 68.7500 (65.7475)  Acc@5: 93.7500 (93.5841)  time: 0.3606  data: 0.0008  max mem: 2502
Train: Epoch[2/5]  [ 800/1142]  eta: 0:02:03  Lr: 0.001875  Loss: -0.3370  Acc@1: 68.7500 (65.7225)  Acc@5: 93.7500 (93.5705)  time: 0.3650  data: 0.0010  max mem: 2502
Train: Epoch[2/5]  [ 810/1142]  eta: 0:02:00  Lr: 0.001875  Loss: -0.2639  Acc@1: 62.5000 (65.7445)  Acc@5: 93.7500 (93.6036)  time: 0.3704  data: 0.0028  max mem: 2502
Train: Epoch[2/5]  [ 820/1142]  eta: 0:01:56  Lr: 0.001875  Loss: -0.3240  Acc@1: 62.5000 (65.7125)  Acc@5: 93.7500 (93.5825)  time: 0.3801  data: 0.0056  max mem: 2502
Train: Epoch[2/5]  [ 830/1142]  eta: 0:01:52  Lr: 0.001875  Loss: 0.1199  Acc@1: 62.5000 (65.7566)  Acc@5: 93.7500 (93.5996)  time: 0.3708  data: 0.0045  max mem: 2502
Train: Epoch[2/5]  [ 840/1142]  eta: 0:01:49  Lr: 0.001875  Loss: -0.3686  Acc@1: 68.7500 (65.7996)  Acc@5: 93.7500 (93.6311)  time: 0.3575  data: 0.0017  max mem: 2502
Train: Epoch[2/5]  [ 850/1142]  eta: 0:01:45  Lr: 0.001875  Loss: -0.5808  Acc@1: 68.7500 (65.8123)  Acc@5: 93.7500 (93.6398)  time: 0.3611  data: 0.0029  max mem: 2502
Train: Epoch[2/5]  [ 860/1142]  eta: 0:01:42  Lr: 0.001875  Loss: -0.5319  Acc@1: 62.5000 (65.8028)  Acc@5: 93.7500 (93.6121)  time: 0.3730  data: 0.0040  max mem: 2502
Train: Epoch[2/5]  [ 870/1142]  eta: 0:01:38  Lr: 0.001875  Loss: -0.2224  Acc@1: 68.7500 (65.8152)  Acc@5: 93.7500 (93.6065)  time: 0.3707  data: 0.0031  max mem: 2502
Train: Epoch[2/5]  [ 880/1142]  eta: 0:01:34  Lr: 0.001875  Loss: -0.2366  Acc@1: 68.7500 (65.8414)  Acc@5: 93.7500 (93.6152)  time: 0.3614  data: 0.0038  max mem: 2502
Train: Epoch[2/5]  [ 890/1142]  eta: 0:01:31  Lr: 0.001875  Loss: -0.1375  Acc@1: 62.5000 (65.7969)  Acc@5: 93.7500 (93.5887)  time: 0.3596  data: 0.0041  max mem: 2502
Train: Epoch[2/5]  [ 900/1142]  eta: 0:01:27  Lr: 0.001875  Loss: -0.0535  Acc@1: 62.5000 (65.8366)  Acc@5: 93.7500 (93.6182)  time: 0.3702  data: 0.0031  max mem: 2502
Train: Epoch[2/5]  [ 910/1142]  eta: 0:01:24  Lr: 0.001875  Loss: -0.7697  Acc@1: 68.7500 (65.8411)  Acc@5: 93.7500 (93.6196)  time: 0.3691  data: 0.0024  max mem: 2502
Train: Epoch[2/5]  [ 920/1142]  eta: 0:01:20  Lr: 0.001875  Loss: -0.0629  Acc@1: 68.7500 (65.8659)  Acc@5: 93.7500 (93.6279)  time: 0.3573  data: 0.0015  max mem: 2502
Train: Epoch[2/5]  [ 930/1142]  eta: 0:01:16  Lr: 0.001875  Loss: -0.0404  Acc@1: 62.5000 (65.7760)  Acc@5: 93.7500 (93.5889)  time: 0.3583  data: 0.0019  max mem: 2502
Train: Epoch[2/5]  [ 940/1142]  eta: 0:01:13  Lr: 0.001875  Loss: -0.0363  Acc@1: 62.5000 (65.8077)  Acc@5: 93.7500 (93.5773)  time: 0.3725  data: 0.0033  max mem: 2502
Train: Epoch[2/5]  [ 950/1142]  eta: 0:01:09  Lr: 0.001875  Loss: -0.0224  Acc@1: 62.5000 (65.8254)  Acc@5: 93.7500 (93.5857)  time: 0.3832  data: 0.0055  max mem: 2502
Train: Epoch[2/5]  [ 960/1142]  eta: 0:01:05  Lr: 0.001875  Loss: 0.1144  Acc@1: 62.5000 (65.8364)  Acc@5: 93.7500 (93.6004)  time: 0.3667  data: 0.0040  max mem: 2502
Train: Epoch[2/5]  [ 970/1142]  eta: 0:01:02  Lr: 0.001875  Loss: 0.0233  Acc@1: 68.7500 (65.8664)  Acc@5: 93.7500 (93.5891)  time: 0.3546  data: 0.0015  max mem: 2502
Train: Epoch[2/5]  [ 980/1142]  eta: 0:00:58  Lr: 0.001875  Loss: -0.0811  Acc@1: 68.7500 (65.9404)  Acc@5: 93.7500 (93.6162)  time: 0.3576  data: 0.0017  max mem: 2502
Train: Epoch[2/5]  [ 990/1142]  eta: 0:00:55  Lr: 0.001875  Loss: -0.0403  Acc@1: 68.7500 (65.9687)  Acc@5: 93.7500 (93.6428)  time: 0.3647  data: 0.0029  max mem: 2502
Train: Epoch[2/5]  [1000/1142]  eta: 0:00:51  Lr: 0.001875  Loss: -0.2798  Acc@1: 68.7500 (65.9840)  Acc@5: 93.7500 (93.6314)  time: 0.3696  data: 0.0033  max mem: 2502
Train: Epoch[2/5]  [1010/1142]  eta: 0:00:47  Lr: 0.001875  Loss: 0.0527  Acc@1: 68.7500 (66.0176)  Acc@5: 93.7500 (93.6696)  time: 0.3624  data: 0.0022  max mem: 2502
Train: Epoch[2/5]  [1020/1142]  eta: 0:00:44  Lr: 0.001875  Loss: -0.3720  Acc@1: 68.7500 (66.0321)  Acc@5: 100.0000 (93.6765)  time: 0.3589  data: 0.0015  max mem: 2502
Train: Epoch[2/5]  [1030/1142]  eta: 0:00:40  Lr: 0.001875  Loss: 0.2261  Acc@1: 68.7500 (66.0281)  Acc@5: 93.7500 (93.6712)  time: 0.3711  data: 0.0013  max mem: 2502
Train: Epoch[2/5]  [1040/1142]  eta: 0:00:36  Lr: 0.001875  Loss: 0.1229  Acc@1: 62.5000 (66.0243)  Acc@5: 93.7500 (93.6659)  time: 0.3651  data: 0.0017  max mem: 2502
Train: Epoch[2/5]  [1050/1142]  eta: 0:00:33  Lr: 0.001875  Loss: 0.4921  Acc@1: 62.5000 (66.0324)  Acc@5: 93.7500 (93.6608)  time: 0.3536  data: 0.0014  max mem: 2502
Train: Epoch[2/5]  [1060/1142]  eta: 0:00:29  Lr: 0.001875  Loss: -0.0187  Acc@1: 62.5000 (66.0521)  Acc@5: 93.7500 (93.6675)  time: 0.3614  data: 0.0015  max mem: 2502
Train: Epoch[2/5]  [1070/1142]  eta: 0:00:26  Lr: 0.001875  Loss: 0.1768  Acc@1: 68.7500 (66.0423)  Acc@5: 93.7500 (93.6741)  time: 0.3730  data: 0.0015  max mem: 2502
Train: Epoch[2/5]  [1080/1142]  eta: 0:00:22  Lr: 0.001875  Loss: 0.9776  Acc@1: 68.7500 (66.0210)  Acc@5: 93.7500 (93.6748)  time: 0.3743  data: 0.0027  max mem: 2502
Train: Epoch[2/5]  [1090/1142]  eta: 0:00:18  Lr: 0.001875  Loss: 0.0201  Acc@1: 68.7500 (66.0346)  Acc@5: 93.7500 (93.6870)  time: 0.3635  data: 0.0035  max mem: 2502
Train: Epoch[2/5]  [1100/1142]  eta: 0:00:15  Lr: 0.001875  Loss: 0.1047  Acc@1: 68.7500 (66.0139)  Acc@5: 93.7500 (93.6989)  time: 0.3592  data: 0.0032  max mem: 2502
Train: Epoch[2/5]  [1110/1142]  eta: 0:00:11  Lr: 0.001875  Loss: -0.3557  Acc@1: 68.7500 (66.0272)  Acc@5: 93.7500 (93.7219)  time: 0.3649  data: 0.0047  max mem: 2502
Train: Epoch[2/5]  [1120/1142]  eta: 0:00:07  Lr: 0.001875  Loss: -0.5480  Acc@1: 68.7500 (66.0348)  Acc@5: 93.7500 (93.6887)  time: 0.3711  data: 0.0034  max mem: 2502
Train: Epoch[2/5]  [1130/1142]  eta: 0:00:04  Lr: 0.001875  Loss: -0.5261  Acc@1: 62.5000 (66.0201)  Acc@5: 93.7500 (93.6726)  time: 0.3655  data: 0.0021  max mem: 2502
Train: Epoch[2/5]  [1140/1142]  eta: 0:00:00  Lr: 0.001875  Loss: 0.0132  Acc@1: 62.5000 (66.0386)  Acc@5: 93.7500 (93.6952)  time: 0.3559  data: 0.0022  max mem: 2502
Train: Epoch[2/5]  [1141/1142]  eta: 0:00:00  Lr: 0.001875  Loss: -0.7055  Acc@1: 68.7500 (66.0534)  Acc@5: 100.0000 (93.6980)  time: 0.3462  data: 0.0017  max mem: 2502
Train: Epoch[2/5] Total time: 0:06:54 (0.3630 s / it)
{0: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 1: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 2: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 3: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 4: {0: 0, 1: 300000, 2: 0, 3: 208, 4: 0}, 5: {0: 0, 1: 300000, 2: 0, 3: 208, 4: 0}, 6: {0: 0, 1: 300000, 2: 0, 3: 208, 4: 0}, 7: {0: 0, 1: 300000, 2: 0, 3: 208, 4: 0}, 8: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 9: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 10: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 11: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 12: {0: 0, 1: 0, 2: 0, 3: 36320, 4: 0}, 13: {0: 0, 1: 0, 2: 0, 3: 36320, 4: 0}, 14: {0: 0, 1: 0, 2: 0, 3: 36320, 4: 0}, 15: {0: 0, 1: 0, 2: 0, 3: 36320, 4: 0}, 16: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 17: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 18: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 19: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}}
Averaged stats: Lr: 0.001875  Loss: -0.7055  Acc@1: 68.7500 (66.0534)  Acc@5: 100.0000 (93.6980)
Train: Epoch[3/5]  [   0/1142]  eta: 0:22:11  Lr: 0.001875  Loss: -0.1168  Acc@1: 56.2500 (56.2500)  Acc@5: 93.7500 (93.7500)  time: 1.1655  data: 0.7972  max mem: 2502
Train: Epoch[3/5]  [  10/1142]  eta: 0:08:18  Lr: 0.001875  Loss: -0.1658  Acc@1: 68.7500 (75.0000)  Acc@5: 93.7500 (95.4545)  time: 0.4404  data: 0.0771  max mem: 2502
Train: Epoch[3/5]  [  20/1142]  eta: 0:07:39  Lr: 0.001875  Loss: -0.3782  Acc@1: 68.7500 (73.5119)  Acc@5: 93.7500 (95.2381)  time: 0.3718  data: 0.0040  max mem: 2502
Train: Epoch[3/5]  [  30/1142]  eta: 0:07:15  Lr: 0.001875  Loss: -0.1103  Acc@1: 68.7500 (71.7742)  Acc@5: 93.7500 (93.9516)  time: 0.3649  data: 0.0026  max mem: 2502
Train: Epoch[3/5]  [  40/1142]  eta: 0:07:03  Lr: 0.001875  Loss: -0.0052  Acc@1: 68.7500 (71.6463)  Acc@5: 93.7500 (93.5976)  time: 0.3570  data: 0.0017  max mem: 2502
Train: Epoch[3/5]  [  50/1142]  eta: 0:06:57  Lr: 0.001875  Loss: -0.4746  Acc@1: 62.5000 (69.9755)  Acc@5: 93.7500 (93.8725)  time: 0.3674  data: 0.0008  max mem: 2502
Train: Epoch[3/5]  [  60/1142]  eta: 0:06:49  Lr: 0.001875  Loss: -0.2262  Acc@1: 62.5000 (68.6475)  Acc@5: 93.7500 (94.0574)  time: 0.3673  data: 0.0013  max mem: 2502
Train: Epoch[3/5]  [  70/1142]  eta: 0:06:42  Lr: 0.001875  Loss: 0.0146  Acc@1: 62.5000 (67.7817)  Acc@5: 93.7500 (93.7500)  time: 0.3587  data: 0.0015  max mem: 2502
Train: Epoch[3/5]  [  80/1142]  eta: 0:06:36  Lr: 0.001875  Loss: -0.0742  Acc@1: 62.5000 (67.5154)  Acc@5: 93.7500 (93.9815)  time: 0.3563  data: 0.0006  max mem: 2502
Train: Epoch[3/5]  [  90/1142]  eta: 0:06:31  Lr: 0.001875  Loss: -0.3051  Acc@1: 68.7500 (67.5137)  Acc@5: 93.7500 (93.6813)  time: 0.3614  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [ 100/1142]  eta: 0:06:25  Lr: 0.001875  Loss: -0.4093  Acc@1: 68.7500 (67.7599)  Acc@5: 93.7500 (93.6881)  time: 0.3587  data: 0.0007  max mem: 2502
Train: Epoch[3/5]  [ 110/1142]  eta: 0:06:20  Lr: 0.001875  Loss: -0.1126  Acc@1: 68.7500 (67.7928)  Acc@5: 93.7500 (93.7500)  time: 0.3516  data: 0.0008  max mem: 2502
Train: Epoch[3/5]  [ 120/1142]  eta: 0:06:17  Lr: 0.001875  Loss: -0.3303  Acc@1: 68.7500 (67.9236)  Acc@5: 93.7500 (93.6983)  time: 0.3626  data: 0.0009  max mem: 2502
Train: Epoch[3/5]  [ 130/1142]  eta: 0:06:11  Lr: 0.001875  Loss: 0.1954  Acc@1: 68.7500 (68.3206)  Acc@5: 93.7500 (93.5592)  time: 0.3587  data: 0.0009  max mem: 2502
Train: Epoch[3/5]  [ 140/1142]  eta: 0:06:07  Lr: 0.001875  Loss: -0.2535  Acc@1: 68.7500 (68.0851)  Acc@5: 93.7500 (93.5284)  time: 0.3520  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [ 150/1142]  eta: 0:06:03  Lr: 0.001875  Loss: 0.0989  Acc@1: 62.5000 (68.2119)  Acc@5: 93.7500 (93.5430)  time: 0.3637  data: 0.0008  max mem: 2502
Train: Epoch[3/5]  [ 160/1142]  eta: 0:06:00  Lr: 0.001875  Loss: 0.0552  Acc@1: 68.7500 (68.2065)  Acc@5: 93.7500 (93.6335)  time: 0.3670  data: 0.0014  max mem: 2502
Train: Epoch[3/5]  [ 170/1142]  eta: 0:05:55  Lr: 0.001875  Loss: -0.4958  Acc@1: 62.5000 (68.1287)  Acc@5: 93.7500 (93.6769)  time: 0.3584  data: 0.0024  max mem: 2502
Train: Epoch[3/5]  [ 180/1142]  eta: 0:05:51  Lr: 0.001875  Loss: -0.1029  Acc@1: 68.7500 (68.1630)  Acc@5: 93.7500 (93.6119)  time: 0.3529  data: 0.0018  max mem: 2502
Train: Epoch[3/5]  [ 190/1142]  eta: 0:05:47  Lr: 0.001875  Loss: -0.4803  Acc@1: 68.7500 (68.1283)  Acc@5: 93.7500 (93.5537)  time: 0.3614  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [ 200/1142]  eta: 0:05:43  Lr: 0.001875  Loss: -0.3100  Acc@1: 68.7500 (68.1592)  Acc@5: 93.7500 (93.6256)  time: 0.3600  data: 0.0007  max mem: 2502
Train: Epoch[3/5]  [ 210/1142]  eta: 0:05:39  Lr: 0.001875  Loss: -0.0315  Acc@1: 68.7500 (68.0983)  Acc@5: 100.0000 (93.7500)  time: 0.3534  data: 0.0008  max mem: 2502
Train: Epoch[3/5]  [ 220/1142]  eta: 0:05:35  Lr: 0.001875  Loss: -0.1912  Acc@1: 68.7500 (68.1844)  Acc@5: 93.7500 (93.7783)  time: 0.3612  data: 0.0011  max mem: 2502
Train: Epoch[3/5]  [ 230/1142]  eta: 0:05:31  Lr: 0.001875  Loss: 0.0915  Acc@1: 62.5000 (67.7489)  Acc@5: 93.7500 (93.7500)  time: 0.3561  data: 0.0010  max mem: 2502
Train: Epoch[3/5]  [ 240/1142]  eta: 0:05:27  Lr: 0.001875  Loss: 0.2352  Acc@1: 62.5000 (67.8423)  Acc@5: 93.7500 (93.8278)  time: 0.3529  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [ 250/1142]  eta: 0:05:24  Lr: 0.001875  Loss: -0.2994  Acc@1: 68.7500 (67.8536)  Acc@5: 100.0000 (93.8994)  time: 0.3659  data: 0.0008  max mem: 2502
Train: Epoch[3/5]  [ 260/1142]  eta: 0:05:20  Lr: 0.001875  Loss: -0.3260  Acc@1: 68.7500 (67.7921)  Acc@5: 93.7500 (93.9416)  time: 0.3670  data: 0.0010  max mem: 2502
Train: Epoch[3/5]  [ 270/1142]  eta: 0:05:16  Lr: 0.001875  Loss: -0.3922  Acc@1: 68.7500 (67.8044)  Acc@5: 93.7500 (94.0268)  time: 0.3566  data: 0.0006  max mem: 2502
Train: Epoch[3/5]  [ 280/1142]  eta: 0:05:13  Lr: 0.001875  Loss: 0.2975  Acc@1: 62.5000 (67.7714)  Acc@5: 93.7500 (94.0169)  time: 0.3565  data: 0.0016  max mem: 2502
Train: Epoch[3/5]  [ 290/1142]  eta: 0:05:09  Lr: 0.001875  Loss: 0.1228  Acc@1: 62.5000 (67.5258)  Acc@5: 93.7500 (93.9863)  time: 0.3682  data: 0.0027  max mem: 2502
Train: Epoch[3/5]  [ 300/1142]  eta: 0:05:05  Lr: 0.001875  Loss: 0.0514  Acc@1: 62.5000 (67.5042)  Acc@5: 93.7500 (93.9369)  time: 0.3634  data: 0.0030  max mem: 2502
Train: Epoch[3/5]  [ 310/1142]  eta: 0:05:02  Lr: 0.001875  Loss: 0.2024  Acc@1: 62.5000 (67.3834)  Acc@5: 93.7500 (93.9711)  time: 0.3577  data: 0.0028  max mem: 2502
Train: Epoch[3/5]  [ 320/1142]  eta: 0:04:58  Lr: 0.001875  Loss: -0.2151  Acc@1: 62.5000 (67.3676)  Acc@5: 93.7500 (93.9642)  time: 0.3640  data: 0.0022  max mem: 2502
Train: Epoch[3/5]  [ 330/1142]  eta: 0:04:54  Lr: 0.001875  Loss: -0.4645  Acc@1: 62.5000 (67.3716)  Acc@5: 93.7500 (94.0144)  time: 0.3651  data: 0.0017  max mem: 2502
Train: Epoch[3/5]  [ 340/1142]  eta: 0:04:51  Lr: 0.001875  Loss: 0.4932  Acc@1: 68.7500 (67.5403)  Acc@5: 93.7500 (93.9883)  time: 0.3592  data: 0.0024  max mem: 2502
Train: Epoch[3/5]  [ 350/1142]  eta: 0:04:47  Lr: 0.001875  Loss: -0.0719  Acc@1: 68.7500 (67.5570)  Acc@5: 93.7500 (94.0349)  time: 0.3585  data: 0.0022  max mem: 2502
Train: Epoch[3/5]  [ 360/1142]  eta: 0:04:44  Lr: 0.001875  Loss: 0.1180  Acc@1: 62.5000 (67.5381)  Acc@5: 93.7500 (94.0270)  time: 0.3751  data: 0.0017  max mem: 2502
Train: Epoch[3/5]  [ 370/1142]  eta: 0:04:40  Lr: 0.001875  Loss: -0.0804  Acc@1: 68.7500 (67.4697)  Acc@5: 93.7500 (93.9522)  time: 0.3760  data: 0.0044  max mem: 2502
Train: Epoch[3/5]  [ 380/1142]  eta: 0:04:37  Lr: 0.001875  Loss: -0.1489  Acc@1: 68.7500 (67.5033)  Acc@5: 93.7500 (93.9961)  time: 0.3719  data: 0.0067  max mem: 2502
Train: Epoch[3/5]  [ 390/1142]  eta: 0:04:33  Lr: 0.001875  Loss: -0.4109  Acc@1: 68.7500 (67.3593)  Acc@5: 93.7500 (93.9098)  time: 0.3696  data: 0.0046  max mem: 2502
Train: Epoch[3/5]  [ 400/1142]  eta: 0:04:29  Lr: 0.001875  Loss: 0.0443  Acc@1: 68.7500 (67.4096)  Acc@5: 93.7500 (93.9838)  time: 0.3564  data: 0.0019  max mem: 2502
Train: Epoch[3/5]  [ 410/1142]  eta: 0:04:26  Lr: 0.001875  Loss: -0.1477  Acc@1: 68.7500 (67.2749)  Acc@5: 100.0000 (94.0237)  time: 0.3561  data: 0.0014  max mem: 2502
Train: Epoch[3/5]  [ 420/1142]  eta: 0:04:22  Lr: 0.001875  Loss: -0.0277  Acc@1: 62.5000 (67.2209)  Acc@5: 93.7500 (94.0172)  time: 0.3614  data: 0.0011  max mem: 2502
Train: Epoch[3/5]  [ 430/1142]  eta: 0:04:18  Lr: 0.001875  Loss: 0.1876  Acc@1: 68.7500 (67.2999)  Acc@5: 93.7500 (93.9965)  time: 0.3672  data: 0.0024  max mem: 2502
Train: Epoch[3/5]  [ 440/1142]  eta: 0:04:15  Lr: 0.001875  Loss: 0.4317  Acc@1: 75.0000 (67.4178)  Acc@5: 93.7500 (94.0051)  time: 0.3636  data: 0.0031  max mem: 2502
Train: Epoch[3/5]  [ 450/1142]  eta: 0:04:11  Lr: 0.001875  Loss: -0.2558  Acc@1: 75.0000 (67.4196)  Acc@5: 93.7500 (93.9717)  time: 0.3565  data: 0.0019  max mem: 2502
Train: Epoch[3/5]  [ 460/1142]  eta: 0:04:07  Lr: 0.001875  Loss: -0.2062  Acc@1: 68.7500 (67.5027)  Acc@5: 93.7500 (93.9805)  time: 0.3603  data: 0.0022  max mem: 2502
Train: Epoch[3/5]  [ 470/1142]  eta: 0:04:04  Lr: 0.001875  Loss: -0.3127  Acc@1: 68.7500 (67.5690)  Acc@5: 93.7500 (93.9358)  time: 0.3656  data: 0.0022  max mem: 2502
Train: Epoch[3/5]  [ 480/1142]  eta: 0:04:00  Lr: 0.001875  Loss: 0.0253  Acc@1: 68.7500 (67.5936)  Acc@5: 93.7500 (93.8410)  time: 0.3601  data: 0.0017  max mem: 2502
Train: Epoch[3/5]  [ 490/1142]  eta: 0:03:56  Lr: 0.001875  Loss: 0.2937  Acc@1: 68.7500 (67.5535)  Acc@5: 93.7500 (93.8518)  time: 0.3546  data: 0.0021  max mem: 2502
Train: Epoch[3/5]  [ 500/1142]  eta: 0:03:53  Lr: 0.001875  Loss: 0.5306  Acc@1: 75.0000 (67.6397)  Acc@5: 93.7500 (93.8872)  time: 0.3630  data: 0.0016  max mem: 2502
Train: Epoch[3/5]  [ 510/1142]  eta: 0:03:49  Lr: 0.001875  Loss: -0.0637  Acc@1: 68.7500 (67.6737)  Acc@5: 93.7500 (93.9090)  time: 0.3741  data: 0.0021  max mem: 2502
Train: Epoch[3/5]  [ 520/1142]  eta: 0:03:46  Lr: 0.001875  Loss: -0.2845  Acc@1: 68.7500 (67.6703)  Acc@5: 93.7500 (93.9539)  time: 0.3777  data: 0.0048  max mem: 2502
Train: Epoch[3/5]  [ 530/1142]  eta: 0:03:42  Lr: 0.001875  Loss: -0.0648  Acc@1: 68.7500 (67.6907)  Acc@5: 93.7500 (93.9854)  time: 0.3693  data: 0.0068  max mem: 2502
Train: Epoch[3/5]  [ 540/1142]  eta: 0:03:38  Lr: 0.001875  Loss: -0.1448  Acc@1: 68.7500 (67.6525)  Acc@5: 93.7500 (93.9926)  time: 0.3589  data: 0.0060  max mem: 2502
Train: Epoch[3/5]  [ 550/1142]  eta: 0:03:35  Lr: 0.001875  Loss: -0.4231  Acc@1: 68.7500 (67.6611)  Acc@5: 93.7500 (93.9201)  time: 0.3587  data: 0.0046  max mem: 2502
Train: Epoch[3/5]  [ 560/1142]  eta: 0:03:31  Lr: 0.001875  Loss: 0.4785  Acc@1: 68.7500 (67.7028)  Acc@5: 93.7500 (93.9171)  time: 0.3671  data: 0.0044  max mem: 2502
Train: Epoch[3/5]  [ 570/1142]  eta: 0:03:28  Lr: 0.001875  Loss: -0.2541  Acc@1: 68.7500 (67.7211)  Acc@5: 93.7500 (93.9361)  time: 0.3776  data: 0.0043  max mem: 2502
Train: Epoch[3/5]  [ 580/1142]  eta: 0:03:24  Lr: 0.001875  Loss: -0.6479  Acc@1: 68.7500 (67.7065)  Acc@5: 93.7500 (93.9544)  time: 0.3680  data: 0.0039  max mem: 2502
Train: Epoch[3/5]  [ 590/1142]  eta: 0:03:20  Lr: 0.001875  Loss: -0.0802  Acc@1: 68.7500 (67.7876)  Acc@5: 93.7500 (93.9298)  time: 0.3590  data: 0.0037  max mem: 2502
Train: Epoch[3/5]  [ 600/1142]  eta: 0:03:17  Lr: 0.001875  Loss: -0.1430  Acc@1: 75.0000 (67.9181)  Acc@5: 93.7500 (93.9684)  time: 0.3649  data: 0.0039  max mem: 2502
Train: Epoch[3/5]  [ 610/1142]  eta: 0:03:13  Lr: 0.001875  Loss: -0.2984  Acc@1: 68.7500 (67.9214)  Acc@5: 93.7500 (93.9750)  time: 0.3703  data: 0.0035  max mem: 2502
Train: Epoch[3/5]  [ 620/1142]  eta: 0:03:10  Lr: 0.001875  Loss: -0.2998  Acc@1: 62.5000 (67.9247)  Acc@5: 93.7500 (94.0117)  time: 0.3651  data: 0.0028  max mem: 2502
Train: Epoch[3/5]  [ 630/1142]  eta: 0:03:06  Lr: 0.001875  Loss: -0.2699  Acc@1: 68.7500 (67.9873)  Acc@5: 93.7500 (93.9976)  time: 0.3556  data: 0.0022  max mem: 2502
Train: Epoch[3/5]  [ 640/1142]  eta: 0:03:02  Lr: 0.001875  Loss: -0.3565  Acc@1: 62.5000 (67.8627)  Acc@5: 93.7500 (93.9645)  time: 0.3656  data: 0.0016  max mem: 2502
Train: Epoch[3/5]  [ 650/1142]  eta: 0:02:59  Lr: 0.001875  Loss: -0.0302  Acc@1: 62.5000 (67.8091)  Acc@5: 93.7500 (93.9324)  time: 0.3801  data: 0.0031  max mem: 2502
Train: Epoch[3/5]  [ 660/1142]  eta: 0:02:55  Lr: 0.001875  Loss: -0.2241  Acc@1: 68.7500 (67.8612)  Acc@5: 93.7500 (93.9297)  time: 0.3775  data: 0.0030  max mem: 2502
Train: Epoch[3/5]  [ 670/1142]  eta: 0:02:52  Lr: 0.001875  Loss: -0.2960  Acc@1: 68.7500 (67.8744)  Acc@5: 93.7500 (93.9363)  time: 0.3706  data: 0.0026  max mem: 2502
Train: Epoch[3/5]  [ 680/1142]  eta: 0:02:48  Lr: 0.001875  Loss: -0.0990  Acc@1: 62.5000 (67.8414)  Acc@5: 93.7500 (93.9336)  time: 0.3604  data: 0.0027  max mem: 2502
Train: Epoch[3/5]  [ 690/1142]  eta: 0:02:44  Lr: 0.001875  Loss: 0.0621  Acc@1: 68.7500 (67.9179)  Acc@5: 93.7500 (93.9128)  time: 0.3554  data: 0.0024  max mem: 2502
Train: Epoch[3/5]  [ 700/1142]  eta: 0:02:41  Lr: 0.001875  Loss: -0.4219  Acc@1: 75.0000 (67.9832)  Acc@5: 93.7500 (93.9551)  time: 0.3654  data: 0.0019  max mem: 2502
Train: Epoch[3/5]  [ 710/1142]  eta: 0:02:37  Lr: 0.001875  Loss: 0.1603  Acc@1: 68.7500 (67.9940)  Acc@5: 93.7500 (93.9610)  time: 0.3659  data: 0.0010  max mem: 2502
Train: Epoch[3/5]  [ 720/1142]  eta: 0:02:33  Lr: 0.001875  Loss: 0.0333  Acc@1: 68.7500 (68.0565)  Acc@5: 100.0000 (94.0014)  time: 0.3608  data: 0.0021  max mem: 2502
Train: Epoch[3/5]  [ 730/1142]  eta: 0:02:30  Lr: 0.001875  Loss: -0.2788  Acc@1: 68.7500 (67.9549)  Acc@5: 93.7500 (93.9808)  time: 0.3604  data: 0.0020  max mem: 2502
Train: Epoch[3/5]  [ 740/1142]  eta: 0:02:26  Lr: 0.001875  Loss: -0.4636  Acc@1: 56.2500 (67.9150)  Acc@5: 93.7500 (93.9946)  time: 0.3664  data: 0.0030  max mem: 2502
Train: Epoch[3/5]  [ 750/1142]  eta: 0:02:22  Lr: 0.001875  Loss: -0.1198  Acc@1: 62.5000 (67.9011)  Acc@5: 93.7500 (93.9997)  time: 0.3619  data: 0.0040  max mem: 2502
Train: Epoch[3/5]  [ 760/1142]  eta: 0:02:19  Lr: 0.001875  Loss: 0.1109  Acc@1: 68.7500 (67.9534)  Acc@5: 93.7500 (94.0375)  time: 0.3565  data: 0.0034  max mem: 2502
Train: Epoch[3/5]  [ 770/1142]  eta: 0:02:15  Lr: 0.001875  Loss: 0.2437  Acc@1: 68.7500 (67.9150)  Acc@5: 93.7500 (94.0418)  time: 0.3632  data: 0.0040  max mem: 2502
Train: Epoch[3/5]  [ 780/1142]  eta: 0:02:11  Lr: 0.001875  Loss: -0.1115  Acc@1: 62.5000 (67.8697)  Acc@5: 93.7500 (94.0381)  time: 0.3680  data: 0.0040  max mem: 2502
Train: Epoch[3/5]  [ 790/1142]  eta: 0:02:08  Lr: 0.001875  Loss: -0.1700  Acc@1: 68.7500 (67.9441)  Acc@5: 93.7500 (94.0582)  time: 0.3719  data: 0.0043  max mem: 2502
Train: Epoch[3/5]  [ 800/1142]  eta: 0:02:04  Lr: 0.001875  Loss: -0.4377  Acc@1: 68.7500 (67.9541)  Acc@5: 100.0000 (94.0699)  time: 0.3829  data: 0.0056  max mem: 2502
Train: Epoch[3/5]  [ 810/1142]  eta: 0:02:01  Lr: 0.001875  Loss: 0.1165  Acc@1: 68.7500 (67.9871)  Acc@5: 93.7500 (94.0428)  time: 0.3740  data: 0.0051  max mem: 2502
Train: Epoch[3/5]  [ 820/1142]  eta: 0:01:57  Lr: 0.001875  Loss: 0.3836  Acc@1: 68.7500 (67.9963)  Acc@5: 93.7500 (94.0317)  time: 0.3590  data: 0.0038  max mem: 2502
Train: Epoch[3/5]  [ 830/1142]  eta: 0:01:53  Lr: 0.001875  Loss: -0.4198  Acc@1: 68.7500 (68.0656)  Acc@5: 93.7500 (94.0734)  time: 0.3603  data: 0.0034  max mem: 2502
Train: Epoch[3/5]  [ 840/1142]  eta: 0:01:50  Lr: 0.001875  Loss: -0.4020  Acc@1: 68.7500 (68.0217)  Acc@5: 93.7500 (94.0398)  time: 0.3664  data: 0.0049  max mem: 2502
Train: Epoch[3/5]  [ 850/1142]  eta: 0:01:46  Lr: 0.001875  Loss: -0.1033  Acc@1: 68.7500 (67.9935)  Acc@5: 93.7500 (94.0291)  time: 0.3634  data: 0.0047  max mem: 2502
Train: Epoch[3/5]  [ 860/1142]  eta: 0:01:42  Lr: 0.001875  Loss: -0.5811  Acc@1: 68.7500 (68.0241)  Acc@5: 93.7500 (94.0549)  time: 0.3577  data: 0.0028  max mem: 2502
Train: Epoch[3/5]  [ 870/1142]  eta: 0:01:39  Lr: 0.001875  Loss: 0.0888  Acc@1: 75.0000 (68.0755)  Acc@5: 93.7500 (94.0370)  time: 0.3647  data: 0.0019  max mem: 2502
Train: Epoch[3/5]  [ 880/1142]  eta: 0:01:35  Lr: 0.001875  Loss: -0.2305  Acc@1: 68.7500 (68.1186)  Acc@5: 100.0000 (94.0976)  time: 0.3621  data: 0.0007  max mem: 2502
Train: Epoch[3/5]  [ 890/1142]  eta: 0:01:31  Lr: 0.001875  Loss: -0.8792  Acc@1: 68.7500 (68.1257)  Acc@5: 100.0000 (94.1007)  time: 0.3577  data: 0.0007  max mem: 2502
Train: Epoch[3/5]  [ 900/1142]  eta: 0:01:28  Lr: 0.001875  Loss: -0.0890  Acc@1: 68.7500 (68.0841)  Acc@5: 93.7500 (94.0622)  time: 0.3626  data: 0.0007  max mem: 2502
Train: Epoch[3/5]  [ 910/1142]  eta: 0:01:24  Lr: 0.001875  Loss: -0.4452  Acc@1: 68.7500 (68.1325)  Acc@5: 93.7500 (94.0862)  time: 0.3677  data: 0.0009  max mem: 2502
Train: Epoch[3/5]  [ 920/1142]  eta: 0:01:20  Lr: 0.001875  Loss: 0.0741  Acc@1: 68.7500 (68.1257)  Acc@5: 93.7500 (94.0893)  time: 0.3572  data: 0.0009  max mem: 2502
Train: Epoch[3/5]  [ 930/1142]  eta: 0:01:17  Lr: 0.001875  Loss: -0.2832  Acc@1: 68.7500 (68.1324)  Acc@5: 93.7500 (94.0924)  time: 0.3526  data: 0.0007  max mem: 2502
Train: Epoch[3/5]  [ 940/1142]  eta: 0:01:13  Lr: 0.001875  Loss: -0.0389  Acc@1: 68.7500 (68.1190)  Acc@5: 87.5000 (94.0356)  time: 0.3635  data: 0.0007  max mem: 2502
Train: Epoch[3/5]  [ 950/1142]  eta: 0:01:09  Lr: 0.001875  Loss: -0.0503  Acc@1: 68.7500 (68.1191)  Acc@5: 93.7500 (94.0589)  time: 0.3586  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [ 960/1142]  eta: 0:01:06  Lr: 0.001875  Loss: -0.4904  Acc@1: 68.7500 (68.1191)  Acc@5: 93.7500 (94.0557)  time: 0.3538  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [ 970/1142]  eta: 0:01:02  Lr: 0.001875  Loss: 0.4820  Acc@1: 62.5000 (68.1256)  Acc@5: 93.7500 (94.0654)  time: 0.3637  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [ 980/1142]  eta: 0:00:58  Lr: 0.001875  Loss: -0.4473  Acc@1: 68.7500 (68.1766)  Acc@5: 93.7500 (94.0940)  time: 0.3582  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [ 990/1142]  eta: 0:00:55  Lr: 0.001875  Loss: -0.1774  Acc@1: 68.7500 (68.1824)  Acc@5: 93.7500 (94.0969)  time: 0.3533  data: 0.0006  max mem: 2502
Train: Epoch[3/5]  [1000/1142]  eta: 0:00:51  Lr: 0.001875  Loss: -0.2870  Acc@1: 68.7500 (68.2505)  Acc@5: 100.0000 (94.1309)  time: 0.3646  data: 0.0006  max mem: 2502
Train: Epoch[3/5]  [1010/1142]  eta: 0:00:48  Lr: 0.001875  Loss: -0.3946  Acc@1: 68.7500 (68.2554)  Acc@5: 100.0000 (94.1333)  time: 0.3703  data: 0.0011  max mem: 2502
Train: Epoch[3/5]  [1020/1142]  eta: 0:00:44  Lr: 0.001875  Loss: -0.0397  Acc@1: 68.7500 (68.2725)  Acc@5: 93.7500 (94.1234)  time: 0.3590  data: 0.0011  max mem: 2502
Train: Epoch[3/5]  [1030/1142]  eta: 0:00:40  Lr: 0.001875  Loss: -0.2678  Acc@1: 62.5000 (68.2347)  Acc@5: 93.7500 (94.1380)  time: 0.3533  data: 0.0010  max mem: 2502
Train: Epoch[3/5]  [1040/1142]  eta: 0:00:37  Lr: 0.001875  Loss: -0.0832  Acc@1: 68.7500 (68.2697)  Acc@5: 93.7500 (94.1342)  time: 0.3627  data: 0.0009  max mem: 2502
Train: Epoch[3/5]  [1050/1142]  eta: 0:00:33  Lr: 0.001875  Loss: 0.0139  Acc@1: 68.7500 (68.2445)  Acc@5: 93.7500 (94.1246)  time: 0.3563  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [1060/1142]  eta: 0:00:29  Lr: 0.001875  Loss: -0.5522  Acc@1: 68.7500 (68.2729)  Acc@5: 93.7500 (94.1093)  time: 0.3518  data: 0.0006  max mem: 2502
Train: Epoch[3/5]  [1070/1142]  eta: 0:00:26  Lr: 0.001875  Loss: 0.4966  Acc@1: 68.7500 (68.2715)  Acc@5: 93.7500 (94.1060)  time: 0.3634  data: 0.0009  max mem: 2502
Train: Epoch[3/5]  [1080/1142]  eta: 0:00:22  Lr: 0.001875  Loss: -0.4693  Acc@1: 68.7500 (68.2470)  Acc@5: 93.7500 (94.1142)  time: 0.3590  data: 0.0010  max mem: 2502
Train: Epoch[3/5]  [1090/1142]  eta: 0:00:18  Lr: 0.001875  Loss: -0.0354  Acc@1: 68.7500 (68.2459)  Acc@5: 93.7500 (94.1052)  time: 0.3523  data: 0.0007  max mem: 2502
Train: Epoch[3/5]  [1100/1142]  eta: 0:00:15  Lr: 0.001875  Loss: 0.0082  Acc@1: 68.7500 (68.2391)  Acc@5: 93.7500 (94.1247)  time: 0.3646  data: 0.0009  max mem: 2502
Train: Epoch[3/5]  [1110/1142]  eta: 0:00:11  Lr: 0.001875  Loss: -0.2748  Acc@1: 68.7500 (68.2662)  Acc@5: 93.7500 (94.1325)  time: 0.3700  data: 0.0011  max mem: 2502
Train: Epoch[3/5]  [1120/1142]  eta: 0:00:07  Lr: 0.001875  Loss: -0.3385  Acc@1: 68.7500 (68.2259)  Acc@5: 93.7500 (94.0957)  time: 0.3576  data: 0.0009  max mem: 2502
Train: Epoch[3/5]  [1130/1142]  eta: 0:00:04  Lr: 0.001875  Loss: -0.1854  Acc@1: 68.7500 (68.2527)  Acc@5: 93.7500 (94.0981)  time: 0.3538  data: 0.0006  max mem: 2502
Train: Epoch[3/5]  [1140/1142]  eta: 0:00:00  Lr: 0.001875  Loss: -0.3598  Acc@1: 75.0000 (68.2625)  Acc@5: 93.7500 (94.1006)  time: 0.3631  data: 0.0007  max mem: 2502
Train: Epoch[3/5]  [1141/1142]  eta: 0:00:00  Lr: 0.001875  Loss: 0.0337  Acc@1: 75.0000 (68.2600)  Acc@5: 93.7500 (94.0977)  time: 0.3541  data: 0.0007  max mem: 2502
Train: Epoch[3/5] Total time: 0:06:55 (0.3636 s / it)
{0: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 1: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 2: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 3: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 4: {0: 0, 1: 300000, 2: 0, 3: 256, 4: 0}, 5: {0: 0, 1: 300000, 2: 0, 3: 256, 4: 0}, 6: {0: 0, 1: 300000, 2: 0, 3: 256, 4: 0}, 7: {0: 0, 1: 300000, 2: 0, 3: 256, 4: 0}, 8: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 9: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 10: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 11: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 12: {0: 0, 1: 0, 2: 0, 3: 54536, 4: 0}, 13: {0: 0, 1: 0, 2: 0, 3: 54536, 4: 0}, 14: {0: 0, 1: 0, 2: 0, 3: 54536, 4: 0}, 15: {0: 0, 1: 0, 2: 0, 3: 54536, 4: 0}, 16: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 17: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 18: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 19: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}}
Averaged stats: Lr: 0.001875  Loss: 0.0337  Acc@1: 75.0000 (68.2600)  Acc@5: 93.7500 (94.0977)
Train: Epoch[4/5]  [   0/1142]  eta: 0:16:50  Lr: 0.001875  Loss: -0.0677  Acc@1: 81.2500 (81.2500)  Acc@5: 87.5000 (87.5000)  time: 0.8849  data: 0.5439  max mem: 2502
Train: Epoch[4/5]  [  10/1142]  eta: 0:07:34  Lr: 0.001875  Loss: 0.4529  Acc@1: 68.7500 (67.0455)  Acc@5: 93.7500 (89.7727)  time: 0.4012  data: 0.0500  max mem: 2502
Train: Epoch[4/5]  [  20/1142]  eta: 0:07:08  Lr: 0.001875  Loss: -0.4659  Acc@1: 68.7500 (68.7500)  Acc@5: 93.7500 (91.9643)  time: 0.3566  data: 0.0007  max mem: 2502
Train: Epoch[4/5]  [  30/1142]  eta: 0:06:58  Lr: 0.001875  Loss: -0.1773  Acc@1: 68.7500 (67.7419)  Acc@5: 93.7500 (93.3468)  time: 0.3624  data: 0.0012  max mem: 2502
Train: Epoch[4/5]  [  40/1142]  eta: 0:06:48  Lr: 0.001875  Loss: -0.1384  Acc@1: 68.7500 (68.2927)  Acc@5: 93.7500 (93.4451)  time: 0.3587  data: 0.0012  max mem: 2502
Train: Epoch[4/5]  [  50/1142]  eta: 0:06:42  Lr: 0.001875  Loss: -0.4080  Acc@1: 68.7500 (67.8922)  Acc@5: 93.7500 (93.5049)  time: 0.3559  data: 0.0007  max mem: 2502
Train: Epoch[4/5]  [  60/1142]  eta: 0:06:38  Lr: 0.001875  Loss: 0.0867  Acc@1: 62.5000 (66.7008)  Acc@5: 93.7500 (92.8279)  time: 0.3625  data: 0.0009  max mem: 2502
Train: Epoch[4/5]  [  70/1142]  eta: 0:06:33  Lr: 0.001875  Loss: -0.0408  Acc@1: 68.7500 (67.7817)  Acc@5: 93.7500 (93.3979)  time: 0.3642  data: 0.0008  max mem: 2502
Train: Epoch[4/5]  [  80/1142]  eta: 0:06:27  Lr: 0.001875  Loss: 0.2019  Acc@1: 68.7500 (67.1296)  Acc@5: 93.7500 (93.3642)  time: 0.3570  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [  90/1142]  eta: 0:06:23  Lr: 0.001875  Loss: -0.2016  Acc@1: 62.5000 (66.8269)  Acc@5: 93.7500 (93.4066)  time: 0.3572  data: 0.0006  max mem: 2502
Train: Epoch[4/5]  [ 100/1142]  eta: 0:06:20  Lr: 0.001875  Loss: 0.0309  Acc@1: 62.5000 (66.3985)  Acc@5: 93.7500 (93.3168)  time: 0.3632  data: 0.0010  max mem: 2502
Train: Epoch[4/5]  [ 110/1142]  eta: 0:06:15  Lr: 0.001875  Loss: 0.0957  Acc@1: 62.5000 (66.1599)  Acc@5: 93.7500 (93.5811)  time: 0.3609  data: 0.0016  max mem: 2502
Train: Epoch[4/5]  [ 120/1142]  eta: 0:06:12  Lr: 0.001875  Loss: 0.3926  Acc@1: 62.5000 (66.4773)  Acc@5: 93.7500 (93.5950)  time: 0.3610  data: 0.0014  max mem: 2502
Train: Epoch[4/5]  [ 130/1142]  eta: 0:06:08  Lr: 0.001875  Loss: -0.2660  Acc@1: 68.7500 (66.3645)  Acc@5: 93.7500 (93.6546)  time: 0.3653  data: 0.0013  max mem: 2502
Train: Epoch[4/5]  [ 140/1142]  eta: 0:06:04  Lr: 0.001875  Loss: 0.0338  Acc@1: 68.7500 (66.6667)  Acc@5: 93.7500 (93.5727)  time: 0.3594  data: 0.0020  max mem: 2502
Train: Epoch[4/5]  [ 150/1142]  eta: 0:06:00  Lr: 0.001875  Loss: 0.2581  Acc@1: 62.5000 (66.5149)  Acc@5: 93.7500 (93.5017)  time: 0.3560  data: 0.0029  max mem: 2502
Train: Epoch[4/5]  [ 160/1142]  eta: 0:05:56  Lr: 0.001875  Loss: -0.7019  Acc@1: 68.7500 (67.0031)  Acc@5: 93.7500 (93.7500)  time: 0.3608  data: 0.0021  max mem: 2502
Train: Epoch[4/5]  [ 170/1142]  eta: 0:05:53  Lr: 0.001875  Loss: 0.3125  Acc@1: 68.7500 (66.9225)  Acc@5: 93.7500 (93.7135)  time: 0.3688  data: 0.0019  max mem: 2502
Train: Epoch[4/5]  [ 180/1142]  eta: 0:05:49  Lr: 0.001875  Loss: 0.3786  Acc@1: 68.7500 (66.9544)  Acc@5: 93.7500 (93.6809)  time: 0.3667  data: 0.0026  max mem: 2502
Train: Epoch[4/5]  [ 190/1142]  eta: 0:05:46  Lr: 0.001875  Loss: -0.5250  Acc@1: 68.7500 (67.0157)  Acc@5: 93.7500 (93.6846)  time: 0.3637  data: 0.0025  max mem: 2502
Train: Epoch[4/5]  [ 200/1142]  eta: 0:05:42  Lr: 0.001875  Loss: -0.3932  Acc@1: 68.7500 (67.4751)  Acc@5: 93.7500 (93.6256)  time: 0.3617  data: 0.0024  max mem: 2502
Train: Epoch[4/5]  [ 210/1142]  eta: 0:05:38  Lr: 0.001875  Loss: 0.1397  Acc@1: 75.0000 (67.5652)  Acc@5: 93.7500 (93.7204)  time: 0.3577  data: 0.0021  max mem: 2502
Train: Epoch[4/5]  [ 220/1142]  eta: 0:05:35  Lr: 0.001875  Loss: -0.4179  Acc@1: 68.7500 (67.5905)  Acc@5: 93.7500 (93.8348)  time: 0.3680  data: 0.0014  max mem: 2502
Train: Epoch[4/5]  [ 230/1142]  eta: 0:05:31  Lr: 0.001875  Loss: -0.1253  Acc@1: 68.7500 (67.4784)  Acc@5: 93.7500 (93.8312)  time: 0.3667  data: 0.0020  max mem: 2502
Train: Epoch[4/5]  [ 240/1142]  eta: 0:05:27  Lr: 0.001875  Loss: -0.3367  Acc@1: 68.7500 (67.6608)  Acc@5: 93.7500 (93.8797)  time: 0.3584  data: 0.0025  max mem: 2502
Train: Epoch[4/5]  [ 250/1142]  eta: 0:05:24  Lr: 0.001875  Loss: -0.2716  Acc@1: 68.7500 (67.5797)  Acc@5: 93.7500 (93.8247)  time: 0.3605  data: 0.0026  max mem: 2502
Train: Epoch[4/5]  [ 260/1142]  eta: 0:05:20  Lr: 0.001875  Loss: -0.1955  Acc@1: 75.0000 (67.8879)  Acc@5: 93.7500 (93.8937)  time: 0.3686  data: 0.0027  max mem: 2502
Train: Epoch[4/5]  [ 270/1142]  eta: 0:05:16  Lr: 0.001875  Loss: -0.0387  Acc@1: 75.0000 (67.9197)  Acc@5: 100.0000 (94.0268)  time: 0.3653  data: 0.0037  max mem: 2502
Train: Epoch[4/5]  [ 280/1142]  eta: 0:05:13  Lr: 0.001875  Loss: -0.4226  Acc@1: 68.7500 (68.0160)  Acc@5: 93.7500 (93.9947)  time: 0.3568  data: 0.0031  max mem: 2502
Train: Epoch[4/5]  [ 290/1142]  eta: 0:05:09  Lr: 0.001875  Loss: -0.1230  Acc@1: 68.7500 (67.8479)  Acc@5: 93.7500 (94.0936)  time: 0.3585  data: 0.0016  max mem: 2502
Train: Epoch[4/5]  [ 300/1142]  eta: 0:05:06  Lr: 0.001875  Loss: -0.3745  Acc@1: 68.7500 (67.9610)  Acc@5: 100.0000 (94.0822)  time: 0.3713  data: 0.0034  max mem: 2502
Train: Epoch[4/5]  [ 310/1142]  eta: 0:05:02  Lr: 0.001875  Loss: -0.2940  Acc@1: 68.7500 (68.0265)  Acc@5: 93.7500 (94.0514)  time: 0.3759  data: 0.0058  max mem: 2502
Train: Epoch[4/5]  [ 320/1142]  eta: 0:04:59  Lr: 0.001875  Loss: -0.5447  Acc@1: 75.0000 (68.3217)  Acc@5: 93.7500 (94.1589)  time: 0.3782  data: 0.0052  max mem: 2502
Train: Epoch[4/5]  [ 330/1142]  eta: 0:04:56  Lr: 0.001875  Loss: 0.8764  Acc@1: 68.7500 (68.1835)  Acc@5: 93.7500 (94.1276)  time: 0.3743  data: 0.0044  max mem: 2502
Train: Epoch[4/5]  [ 340/1142]  eta: 0:04:52  Lr: 0.001875  Loss: -0.0047  Acc@1: 68.7500 (68.2001)  Acc@5: 93.7500 (94.1899)  time: 0.3619  data: 0.0038  max mem: 2502
Train: Epoch[4/5]  [ 350/1142]  eta: 0:04:48  Lr: 0.001875  Loss: -0.4233  Acc@1: 68.7500 (68.0912)  Acc@5: 93.7500 (94.1774)  time: 0.3633  data: 0.0023  max mem: 2502
Train: Epoch[4/5]  [ 360/1142]  eta: 0:04:45  Lr: 0.001875  Loss: 0.5861  Acc@1: 68.7500 (68.0575)  Acc@5: 93.7500 (94.2001)  time: 0.3675  data: 0.0015  max mem: 2502
Train: Epoch[4/5]  [ 370/1142]  eta: 0:04:41  Lr: 0.001875  Loss: -0.3646  Acc@1: 68.7500 (68.0593)  Acc@5: 93.7500 (94.1375)  time: 0.3641  data: 0.0024  max mem: 2502
Train: Epoch[4/5]  [ 380/1142]  eta: 0:04:37  Lr: 0.001875  Loss: -0.2617  Acc@1: 68.7500 (67.9790)  Acc@5: 93.7500 (94.1437)  time: 0.3612  data: 0.0049  max mem: 2502
Train: Epoch[4/5]  [ 390/1142]  eta: 0:04:34  Lr: 0.001875  Loss: 0.0839  Acc@1: 68.7500 (67.9987)  Acc@5: 93.7500 (94.1816)  time: 0.3658  data: 0.0045  max mem: 2502
Train: Epoch[4/5]  [ 400/1142]  eta: 0:04:30  Lr: 0.001875  Loss: -0.0470  Acc@1: 68.7500 (67.8928)  Acc@5: 93.7500 (94.1552)  time: 0.3699  data: 0.0036  max mem: 2502
Train: Epoch[4/5]  [ 410/1142]  eta: 0:04:26  Lr: 0.001875  Loss: -0.5625  Acc@1: 68.7500 (68.1113)  Acc@5: 93.7500 (94.2518)  time: 0.3641  data: 0.0035  max mem: 2502
Train: Epoch[4/5]  [ 420/1142]  eta: 0:04:23  Lr: 0.001875  Loss: -0.5523  Acc@1: 75.0000 (68.1859)  Acc@5: 100.0000 (94.3141)  time: 0.3594  data: 0.0023  max mem: 2502
Train: Epoch[4/5]  [ 430/1142]  eta: 0:04:19  Lr: 0.001875  Loss: -0.2431  Acc@1: 68.7500 (68.2860)  Acc@5: 93.7500 (94.2865)  time: 0.3650  data: 0.0020  max mem: 2502
Train: Epoch[4/5]  [ 440/1142]  eta: 0:04:16  Lr: 0.001875  Loss: -0.5587  Acc@1: 75.0000 (68.3673)  Acc@5: 93.7500 (94.3311)  time: 0.3682  data: 0.0043  max mem: 2502
Train: Epoch[4/5]  [ 450/1142]  eta: 0:04:12  Lr: 0.001875  Loss: -0.5807  Acc@1: 75.0000 (68.3204)  Acc@5: 93.7500 (94.3459)  time: 0.3717  data: 0.0055  max mem: 2502
Train: Epoch[4/5]  [ 460/1142]  eta: 0:04:08  Lr: 0.001875  Loss: 0.0806  Acc@1: 68.7500 (68.3297)  Acc@5: 93.7500 (94.3059)  time: 0.3652  data: 0.0044  max mem: 2502
Train: Epoch[4/5]  [ 470/1142]  eta: 0:04:04  Lr: 0.001875  Loss: -0.2609  Acc@1: 68.7500 (68.4581)  Acc@5: 93.7500 (94.3206)  time: 0.3577  data: 0.0040  max mem: 2502
Train: Epoch[4/5]  [ 480/1142]  eta: 0:04:01  Lr: 0.001875  Loss: -0.2809  Acc@1: 68.7500 (68.4381)  Acc@5: 93.7500 (94.3217)  time: 0.3610  data: 0.0035  max mem: 2502
Train: Epoch[4/5]  [ 490/1142]  eta: 0:03:57  Lr: 0.001875  Loss: 0.0687  Acc@1: 75.0000 (68.5209)  Acc@5: 93.7500 (94.3228)  time: 0.3668  data: 0.0017  max mem: 2502
Train: Epoch[4/5]  [ 500/1142]  eta: 0:03:54  Lr: 0.001875  Loss: -0.0195  Acc@1: 75.0000 (68.5753)  Acc@5: 93.7500 (94.3114)  time: 0.3656  data: 0.0010  max mem: 2502
Train: Epoch[4/5]  [ 510/1142]  eta: 0:03:50  Lr: 0.001875  Loss: -0.3261  Acc@1: 68.7500 (68.5054)  Acc@5: 93.7500 (94.3249)  time: 0.3601  data: 0.0022  max mem: 2502
Train: Epoch[4/5]  [ 520/1142]  eta: 0:03:46  Lr: 0.001875  Loss: -0.4226  Acc@1: 68.7500 (68.5821)  Acc@5: 100.0000 (94.3738)  time: 0.3664  data: 0.0035  max mem: 2502
Train: Epoch[4/5]  [ 530/1142]  eta: 0:03:43  Lr: 0.001875  Loss: -0.1281  Acc@1: 75.0000 (68.7147)  Acc@5: 93.7500 (94.2797)  time: 0.3694  data: 0.0035  max mem: 2502
Train: Epoch[4/5]  [ 540/1142]  eta: 0:03:39  Lr: 0.001875  Loss: -0.3186  Acc@1: 75.0000 (68.6460)  Acc@5: 93.7500 (94.3045)  time: 0.3630  data: 0.0048  max mem: 2502
Train: Epoch[4/5]  [ 550/1142]  eta: 0:03:35  Lr: 0.001875  Loss: 0.4877  Acc@1: 62.5000 (68.6252)  Acc@5: 93.7500 (94.2604)  time: 0.3597  data: 0.0046  max mem: 2502
Train: Epoch[4/5]  [ 560/1142]  eta: 0:03:32  Lr: 0.001875  Loss: -0.0084  Acc@1: 62.5000 (68.6275)  Acc@5: 93.7500 (94.2291)  time: 0.3628  data: 0.0029  max mem: 2502
Train: Epoch[4/5]  [ 570/1142]  eta: 0:03:28  Lr: 0.001875  Loss: -0.4010  Acc@1: 68.7500 (68.6624)  Acc@5: 93.7500 (94.2644)  time: 0.3702  data: 0.0026  max mem: 2502
Train: Epoch[4/5]  [ 580/1142]  eta: 0:03:25  Lr: 0.001875  Loss: 0.0671  Acc@1: 68.7500 (68.6317)  Acc@5: 93.7500 (94.2664)  time: 0.3741  data: 0.0034  max mem: 2502
Train: Epoch[4/5]  [ 590/1142]  eta: 0:03:21  Lr: 0.001875  Loss: -0.8235  Acc@1: 68.7500 (68.6865)  Acc@5: 93.7500 (94.2047)  time: 0.3636  data: 0.0033  max mem: 2502
Train: Epoch[4/5]  [ 600/1142]  eta: 0:03:17  Lr: 0.001875  Loss: -0.1148  Acc@1: 68.7500 (68.6564)  Acc@5: 93.7500 (94.1868)  time: 0.3559  data: 0.0031  max mem: 2502
Train: Epoch[4/5]  [ 610/1142]  eta: 0:03:13  Lr: 0.001875  Loss: 0.1102  Acc@1: 62.5000 (68.5863)  Acc@5: 93.7500 (94.1899)  time: 0.3596  data: 0.0035  max mem: 2502
Train: Epoch[4/5]  [ 620/1142]  eta: 0:03:10  Lr: 0.001875  Loss: -0.4406  Acc@1: 68.7500 (68.6192)  Acc@5: 93.7500 (94.2130)  time: 0.3671  data: 0.0020  max mem: 2502
Train: Epoch[4/5]  [ 630/1142]  eta: 0:03:06  Lr: 0.001875  Loss: 0.0740  Acc@1: 68.7500 (68.5618)  Acc@5: 93.7500 (94.1858)  time: 0.3650  data: 0.0020  max mem: 2502
Train: Epoch[4/5]  [ 640/1142]  eta: 0:03:02  Lr: 0.001875  Loss: -0.3984  Acc@1: 68.7500 (68.6135)  Acc@5: 93.7500 (94.2278)  time: 0.3570  data: 0.0021  max mem: 2502
Train: Epoch[4/5]  [ 650/1142]  eta: 0:02:59  Lr: 0.001875  Loss: -0.5226  Acc@1: 75.0000 (68.6348)  Acc@5: 100.0000 (94.2588)  time: 0.3597  data: 0.0024  max mem: 2502
Train: Epoch[4/5]  [ 660/1142]  eta: 0:02:55  Lr: 0.001875  Loss: 0.3904  Acc@1: 68.7500 (68.5609)  Acc@5: 93.7500 (94.2606)  time: 0.3588  data: 0.0020  max mem: 2502
Train: Epoch[4/5]  [ 670/1142]  eta: 0:02:51  Lr: 0.001875  Loss: -0.5920  Acc@1: 68.7500 (68.5544)  Acc@5: 93.7500 (94.2344)  time: 0.3558  data: 0.0006  max mem: 2502
Train: Epoch[4/5]  [ 680/1142]  eta: 0:02:48  Lr: 0.001875  Loss: -0.1521  Acc@1: 68.7500 (68.5206)  Acc@5: 93.7500 (94.2548)  time: 0.3635  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [ 690/1142]  eta: 0:02:44  Lr: 0.001875  Loss: -0.4534  Acc@1: 68.7500 (68.5420)  Acc@5: 93.7500 (94.2836)  time: 0.3688  data: 0.0008  max mem: 2502
Train: Epoch[4/5]  [ 700/1142]  eta: 0:02:40  Lr: 0.001875  Loss: -0.3630  Acc@1: 75.0000 (68.5717)  Acc@5: 93.7500 (94.2671)  time: 0.3558  data: 0.0007  max mem: 2502
Train: Epoch[4/5]  [ 710/1142]  eta: 0:02:37  Lr: 0.001875  Loss: -0.3347  Acc@1: 68.7500 (68.6094)  Acc@5: 93.7500 (94.2950)  time: 0.3529  data: 0.0006  max mem: 2502
Train: Epoch[4/5]  [ 720/1142]  eta: 0:02:33  Lr: 0.001875  Loss: -0.1147  Acc@1: 62.5000 (68.5940)  Acc@5: 100.0000 (94.3395)  time: 0.3624  data: 0.0006  max mem: 2502
Train: Epoch[4/5]  [ 730/1142]  eta: 0:02:29  Lr: 0.001875  Loss: -0.0757  Acc@1: 68.7500 (68.6303)  Acc@5: 93.7500 (94.3314)  time: 0.3554  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [ 740/1142]  eta: 0:02:26  Lr: 0.001875  Loss: -0.3483  Acc@1: 75.0000 (68.6319)  Acc@5: 93.7500 (94.3067)  time: 0.3529  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [ 750/1142]  eta: 0:02:22  Lr: 0.001875  Loss: 0.3084  Acc@1: 68.7500 (68.5752)  Acc@5: 93.7500 (94.2826)  time: 0.3645  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [ 760/1142]  eta: 0:02:18  Lr: 0.001875  Loss: -0.0123  Acc@1: 62.5000 (68.5365)  Acc@5: 93.7500 (94.2346)  time: 0.3590  data: 0.0007  max mem: 2502
Train: Epoch[4/5]  [ 770/1142]  eta: 0:02:15  Lr: 0.001875  Loss: -0.3857  Acc@1: 62.5000 (68.5068)  Acc@5: 93.7500 (94.2445)  time: 0.3529  data: 0.0007  max mem: 2502
Train: Epoch[4/5]  [ 780/1142]  eta: 0:02:11  Lr: 0.001875  Loss: -0.3855  Acc@1: 68.7500 (68.5499)  Acc@5: 93.7500 (94.2622)  time: 0.3646  data: 0.0012  max mem: 2502
Train: Epoch[4/5]  [ 790/1142]  eta: 0:02:08  Lr: 0.001875  Loss: -0.2951  Acc@1: 75.0000 (68.6315)  Acc@5: 93.7500 (94.2636)  time: 0.3771  data: 0.0030  max mem: 2502
Train: Epoch[4/5]  [ 800/1142]  eta: 0:02:04  Lr: 0.001875  Loss: -0.1150  Acc@1: 68.7500 (68.6174)  Acc@5: 93.7500 (94.2416)  time: 0.3638  data: 0.0025  max mem: 2502
Train: Epoch[4/5]  [ 810/1142]  eta: 0:02:00  Lr: 0.001875  Loss: -0.0692  Acc@1: 62.5000 (68.5111)  Acc@5: 93.7500 (94.2895)  time: 0.3532  data: 0.0007  max mem: 2502
Train: Epoch[4/5]  [ 820/1142]  eta: 0:01:57  Lr: 0.001875  Loss: 0.4428  Acc@1: 62.5000 (68.5292)  Acc@5: 100.0000 (94.3057)  time: 0.3639  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [ 830/1142]  eta: 0:01:53  Lr: 0.001875  Loss: -0.4532  Acc@1: 62.5000 (68.4792)  Acc@5: 93.7500 (94.2765)  time: 0.3589  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [ 840/1142]  eta: 0:01:49  Lr: 0.001875  Loss: -0.4518  Acc@1: 62.5000 (68.4379)  Acc@5: 93.7500 (94.2851)  time: 0.3549  data: 0.0007  max mem: 2502
Train: Epoch[4/5]  [ 850/1142]  eta: 0:01:46  Lr: 0.001875  Loss: -0.2005  Acc@1: 68.7500 (68.4415)  Acc@5: 93.7500 (94.2641)  time: 0.3631  data: 0.0006  max mem: 2502
Train: Epoch[4/5]  [ 860/1142]  eta: 0:01:42  Lr: 0.001875  Loss: -0.8374  Acc@1: 68.7500 (68.4814)  Acc@5: 93.7500 (94.2944)  time: 0.3577  data: 0.0011  max mem: 2502
Train: Epoch[4/5]  [ 870/1142]  eta: 0:01:38  Lr: 0.001875  Loss: 0.2292  Acc@1: 68.7500 (68.4989)  Acc@5: 100.0000 (94.2810)  time: 0.3532  data: 0.0011  max mem: 2502
Train: Epoch[4/5]  [ 880/1142]  eta: 0:01:35  Lr: 0.001875  Loss: -0.4539  Acc@1: 68.7500 (68.4804)  Acc@5: 93.7500 (94.2821)  time: 0.3643  data: 0.0008  max mem: 2502
Train: Epoch[4/5]  [ 890/1142]  eta: 0:01:31  Lr: 0.001875  Loss: -0.2633  Acc@1: 68.7500 (68.4975)  Acc@5: 93.7500 (94.2971)  time: 0.3694  data: 0.0008  max mem: 2502
Train: Epoch[4/5]  [ 900/1142]  eta: 0:01:27  Lr: 0.001875  Loss: -0.6027  Acc@1: 68.7500 (68.5488)  Acc@5: 93.7500 (94.2911)  time: 0.3589  data: 0.0006  max mem: 2502
Train: Epoch[4/5]  [ 910/1142]  eta: 0:01:24  Lr: 0.001875  Loss: 0.1237  Acc@1: 68.7500 (68.5305)  Acc@5: 93.7500 (94.2577)  time: 0.3545  data: 0.0007  max mem: 2502
Train: Epoch[4/5]  [ 920/1142]  eta: 0:01:20  Lr: 0.001875  Loss: -0.7711  Acc@1: 68.7500 (68.5803)  Acc@5: 93.7500 (94.2793)  time: 0.3611  data: 0.0006  max mem: 2502
Train: Epoch[4/5]  [ 930/1142]  eta: 0:01:16  Lr: 0.001875  Loss: -0.4610  Acc@1: 75.0000 (68.6224)  Acc@5: 93.7500 (94.2736)  time: 0.3565  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [ 940/1142]  eta: 0:01:13  Lr: 0.001875  Loss: 0.0756  Acc@1: 75.0000 (68.6371)  Acc@5: 93.7500 (94.2481)  time: 0.3555  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [ 950/1142]  eta: 0:01:09  Lr: 0.001875  Loss: 0.3875  Acc@1: 68.7500 (68.6711)  Acc@5: 93.7500 (94.2692)  time: 0.3624  data: 0.0009  max mem: 2502
Train: Epoch[4/5]  [ 960/1142]  eta: 0:01:06  Lr: 0.001875  Loss: -0.4150  Acc@1: 68.7500 (68.6980)  Acc@5: 93.7500 (94.2703)  time: 0.3588  data: 0.0009  max mem: 2502
Train: Epoch[4/5]  [ 970/1142]  eta: 0:01:02  Lr: 0.001875  Loss: -0.2357  Acc@1: 62.5000 (68.6470)  Acc@5: 87.5000 (94.2134)  time: 0.3563  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [ 980/1142]  eta: 0:00:58  Lr: 0.001875  Loss: -0.6361  Acc@1: 62.5000 (68.6162)  Acc@5: 87.5000 (94.1896)  time: 0.3688  data: 0.0006  max mem: 2502
Train: Epoch[4/5]  [ 990/1142]  eta: 0:00:55  Lr: 0.001875  Loss: -0.0239  Acc@1: 68.7500 (68.6554)  Acc@5: 93.7500 (94.1536)  time: 0.3649  data: 0.0006  max mem: 2502
Train: Epoch[4/5]  [1000/1142]  eta: 0:00:51  Lr: 0.001875  Loss: -0.6050  Acc@1: 75.0000 (68.7188)  Acc@5: 93.7500 (94.1558)  time: 0.3539  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [1010/1142]  eta: 0:00:47  Lr: 0.001875  Loss: -0.4314  Acc@1: 68.7500 (68.7315)  Acc@5: 93.7500 (94.1642)  time: 0.3646  data: 0.0013  max mem: 2502
Train: Epoch[4/5]  [1020/1142]  eta: 0:00:44  Lr: 0.001875  Loss: 0.2983  Acc@1: 68.7500 (68.6888)  Acc@5: 93.7500 (94.1540)  time: 0.3615  data: 0.0025  max mem: 2502
Train: Epoch[4/5]  [1030/1142]  eta: 0:00:40  Lr: 0.001875  Loss: 0.4501  Acc@1: 62.5000 (68.7076)  Acc@5: 100.0000 (94.1804)  time: 0.3553  data: 0.0021  max mem: 2502
Train: Epoch[4/5]  [1040/1142]  eta: 0:00:37  Lr: 0.001875  Loss: -0.6375  Acc@1: 68.7500 (68.7260)  Acc@5: 100.0000 (94.1943)  time: 0.3640  data: 0.0009  max mem: 2502
Train: Epoch[4/5]  [1050/1142]  eta: 0:00:33  Lr: 0.001875  Loss: 0.0397  Acc@1: 68.7500 (68.7322)  Acc@5: 93.7500 (94.2079)  time: 0.3583  data: 0.0006  max mem: 2502
Train: Epoch[4/5]  [1060/1142]  eta: 0:00:29  Lr: 0.001875  Loss: -0.5249  Acc@1: 68.7500 (68.7441)  Acc@5: 93.7500 (94.2271)  time: 0.3532  data: 0.0008  max mem: 2502
Train: Epoch[4/5]  [1070/1142]  eta: 0:00:26  Lr: 0.001875  Loss: -0.1062  Acc@1: 75.0000 (68.7967)  Acc@5: 93.7500 (94.2344)  time: 0.3607  data: 0.0007  max mem: 2502
Train: Epoch[4/5]  [1080/1142]  eta: 0:00:22  Lr: 0.001875  Loss: -0.5720  Acc@1: 68.7500 (68.7847)  Acc@5: 100.0000 (94.2588)  time: 0.3650  data: 0.0006  max mem: 2502
Train: Epoch[4/5]  [1090/1142]  eta: 0:00:18  Lr: 0.001875  Loss: -0.2116  Acc@1: 68.7500 (68.7557)  Acc@5: 93.7500 (94.2541)  time: 0.3581  data: 0.0007  max mem: 2502
Train: Epoch[4/5]  [1100/1142]  eta: 0:00:15  Lr: 0.001875  Loss: -0.1286  Acc@1: 68.7500 (68.7216)  Acc@5: 93.7500 (94.2439)  time: 0.3541  data: 0.0006  max mem: 2502
Train: Epoch[4/5]  [1110/1142]  eta: 0:00:11  Lr: 0.001875  Loss: -0.5028  Acc@1: 62.5000 (68.6881)  Acc@5: 93.7500 (94.2450)  time: 0.3608  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [1120/1142]  eta: 0:00:07  Lr: 0.001875  Loss: -0.0226  Acc@1: 68.7500 (68.6998)  Acc@5: 93.7500 (94.2574)  time: 0.3577  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [1130/1142]  eta: 0:00:04  Lr: 0.001875  Loss: -0.2110  Acc@1: 68.7500 (68.7555)  Acc@5: 100.0000 (94.2695)  time: 0.3573  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [1140/1142]  eta: 0:00:00  Lr: 0.001875  Loss: -0.1428  Acc@1: 75.0000 (68.7719)  Acc@5: 100.0000 (94.2868)  time: 0.3611  data: 0.0008  max mem: 2502
Train: Epoch[4/5]  [1141/1142]  eta: 0:00:00  Lr: 0.001875  Loss: -0.2736  Acc@1: 68.7500 (68.7582)  Acc@5: 100.0000 (94.2893)  time: 0.3526  data: 0.0008  max mem: 2502
Train: Epoch[4/5] Total time: 0:06:54 (0.3627 s / it)
{0: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 1: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 2: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 3: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 4: {0: 0, 1: 300000, 2: 0, 3: 336, 4: 0}, 5: {0: 0, 1: 300000, 2: 0, 3: 336, 4: 0}, 6: {0: 0, 1: 300000, 2: 0, 3: 336, 4: 0}, 7: {0: 0, 1: 300000, 2: 0, 3: 336, 4: 0}, 8: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 9: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 10: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 11: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 12: {0: 0, 1: 0, 2: 0, 3: 72720, 4: 0}, 13: {0: 0, 1: 0, 2: 0, 3: 72720, 4: 0}, 14: {0: 0, 1: 0, 2: 0, 3: 72720, 4: 0}, 15: {0: 0, 1: 0, 2: 0, 3: 72720, 4: 0}, 16: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 17: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 18: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 19: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}}
Averaged stats: Lr: 0.001875  Loss: -0.2736  Acc@1: 68.7500 (68.7582)  Acc@5: 100.0000 (94.2893)
Train: Epoch[5/5]  [   0/1142]  eta: 0:19:58  Lr: 0.001875  Loss: 0.2274  Acc@1: 62.5000 (62.5000)  Acc@5: 87.5000 (87.5000)  time: 1.0495  data: 0.6805  max mem: 2502
Train: Epoch[5/5]  [  10/1142]  eta: 0:07:53  Lr: 0.001875  Loss: -0.3134  Acc@1: 75.0000 (72.1591)  Acc@5: 93.7500 (92.6136)  time: 0.4186  data: 0.0624  max mem: 2502
Train: Epoch[5/5]  [  20/1142]  eta: 0:07:24  Lr: 0.001875  Loss: -0.1697  Acc@1: 75.0000 (72.6190)  Acc@5: 93.7500 (92.8571)  time: 0.3634  data: 0.0006  max mem: 2502
Train: Epoch[5/5]  [  30/1142]  eta: 0:07:08  Lr: 0.001875  Loss: -0.1560  Acc@1: 68.7500 (69.5565)  Acc@5: 93.7500 (93.1452)  time: 0.3673  data: 0.0007  max mem: 2502
Train: Epoch[5/5]  [  40/1142]  eta: 0:06:55  Lr: 0.001875  Loss: 0.0071  Acc@1: 68.7500 (68.5976)  Acc@5: 93.7500 (93.7500)  time: 0.3569  data: 0.0014  max mem: 2502
Train: Epoch[5/5]  [  50/1142]  eta: 0:06:48  Lr: 0.001875  Loss: -0.2575  Acc@1: 68.7500 (69.2402)  Acc@5: 93.7500 (93.6275)  time: 0.3555  data: 0.0013  max mem: 2502
Train: Epoch[5/5]  [  60/1142]  eta: 0:06:43  Lr: 0.001875  Loss: -0.5021  Acc@1: 68.7500 (69.0574)  Acc@5: 93.7500 (93.7500)  time: 0.3641  data: 0.0007  max mem: 2502
Train: Epoch[5/5]  [  70/1142]  eta: 0:06:36  Lr: 0.001875  Loss: -0.3485  Acc@1: 62.5000 (68.5739)  Acc@5: 93.7500 (94.2782)  time: 0.3589  data: 0.0006  max mem: 2502
Train: Epoch[5/5]  [  80/1142]  eta: 0:06:31  Lr: 0.001875  Loss: -0.5101  Acc@1: 62.5000 (68.2870)  Acc@5: 100.0000 (94.1358)  time: 0.3544  data: 0.0006  max mem: 2502
Train: Epoch[5/5]  [  90/1142]  eta: 0:06:27  Lr: 0.001875  Loss: -0.3472  Acc@1: 75.0000 (69.7115)  Acc@5: 93.7500 (94.3681)  time: 0.3634  data: 0.0006  max mem: 2502
Train: Epoch[5/5]  [ 100/1142]  eta: 0:06:21  Lr: 0.001875  Loss: 0.6931  Acc@1: 75.0000 (69.9876)  Acc@5: 100.0000 (94.3688)  time: 0.3583  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [ 110/1142]  eta: 0:06:17  Lr: 0.001875  Loss: -0.1833  Acc@1: 75.0000 (69.9887)  Acc@5: 93.7500 (94.2005)  time: 0.3535  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [ 120/1142]  eta: 0:06:13  Lr: 0.001875  Loss: -0.2596  Acc@1: 68.7500 (69.6281)  Acc@5: 93.7500 (94.2665)  time: 0.3638  data: 0.0013  max mem: 2502
Train: Epoch[5/5]  [ 130/1142]  eta: 0:06:10  Lr: 0.001875  Loss: -0.3301  Acc@1: 68.7500 (69.4656)  Acc@5: 93.7500 (94.2271)  time: 0.3659  data: 0.0012  max mem: 2502
Train: Epoch[5/5]  [ 140/1142]  eta: 0:06:05  Lr: 0.001875  Loss: -0.1005  Acc@1: 68.7500 (69.4149)  Acc@5: 93.7500 (94.2819)  time: 0.3581  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [ 150/1142]  eta: 0:06:01  Lr: 0.001875  Loss: -0.1544  Acc@1: 68.7500 (69.4123)  Acc@5: 93.7500 (94.3295)  time: 0.3571  data: 0.0006  max mem: 2502
Train: Epoch[5/5]  [ 160/1142]  eta: 0:05:57  Lr: 0.001875  Loss: -0.5065  Acc@1: 68.7500 (68.7500)  Acc@5: 93.7500 (94.5264)  time: 0.3609  data: 0.0007  max mem: 2502
Train: Epoch[5/5]  [ 170/1142]  eta: 0:05:53  Lr: 0.001875  Loss: -0.3712  Acc@1: 62.5000 (68.6038)  Acc@5: 100.0000 (94.6272)  time: 0.3570  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [ 180/1142]  eta: 0:05:49  Lr: 0.001875  Loss: -0.8313  Acc@1: 75.0000 (68.8881)  Acc@5: 93.7500 (94.7169)  time: 0.3577  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [ 190/1142]  eta: 0:05:45  Lr: 0.001875  Loss: -0.5397  Acc@1: 75.0000 (68.8482)  Acc@5: 93.7500 (94.6335)  time: 0.3581  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [ 200/1142]  eta: 0:05:41  Lr: 0.001875  Loss: -0.0690  Acc@1: 68.7500 (68.8122)  Acc@5: 93.7500 (94.6517)  time: 0.3557  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [ 210/1142]  eta: 0:05:38  Lr: 0.001875  Loss: -0.1395  Acc@1: 68.7500 (68.7204)  Acc@5: 100.0000 (94.6979)  time: 0.3655  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [ 220/1142]  eta: 0:05:35  Lr: 0.001875  Loss: -0.4295  Acc@1: 62.5000 (68.3541)  Acc@5: 93.7500 (94.6267)  time: 0.3718  data: 0.0020  max mem: 2502
Train: Epoch[5/5]  [ 230/1142]  eta: 0:05:30  Lr: 0.001875  Loss: -0.2116  Acc@1: 62.5000 (68.5877)  Acc@5: 93.7500 (94.6970)  time: 0.3582  data: 0.0020  max mem: 2502
Train: Epoch[5/5]  [ 240/1142]  eta: 0:05:26  Lr: 0.001875  Loss: 0.0930  Acc@1: 75.0000 (68.8019)  Acc@5: 100.0000 (94.6836)  time: 0.3505  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [ 250/1142]  eta: 0:05:23  Lr: 0.001875  Loss: 0.2827  Acc@1: 62.5000 (68.6504)  Acc@5: 93.7500 (94.6464)  time: 0.3642  data: 0.0008  max mem: 2502
Train: Epoch[5/5]  [ 260/1142]  eta: 0:05:19  Lr: 0.001875  Loss: 0.1010  Acc@1: 62.5000 (68.6063)  Acc@5: 93.7500 (94.6839)  time: 0.3596  data: 0.0006  max mem: 2502
Train: Epoch[5/5]  [ 270/1142]  eta: 0:05:15  Lr: 0.001875  Loss: -0.5877  Acc@1: 68.7500 (68.6347)  Acc@5: 100.0000 (94.7417)  time: 0.3520  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [ 280/1142]  eta: 0:05:12  Lr: 0.001875  Loss: -0.5552  Acc@1: 68.7500 (68.5943)  Acc@5: 100.0000 (94.8399)  time: 0.3619  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [ 290/1142]  eta: 0:05:08  Lr: 0.001875  Loss: -0.3747  Acc@1: 75.0000 (68.7715)  Acc@5: 93.7500 (94.7380)  time: 0.3570  data: 0.0006  max mem: 2502
Train: Epoch[5/5]  [ 300/1142]  eta: 0:05:04  Lr: 0.001875  Loss: -0.1910  Acc@1: 75.0000 (68.6047)  Acc@5: 93.7500 (94.7259)  time: 0.3535  data: 0.0008  max mem: 2502
Train: Epoch[5/5]  [ 310/1142]  eta: 0:05:01  Lr: 0.001875  Loss: -0.1912  Acc@1: 68.7500 (68.7299)  Acc@5: 93.7500 (94.7347)  time: 0.3660  data: 0.0015  max mem: 2502
Train: Epoch[5/5]  [ 320/1142]  eta: 0:04:57  Lr: 0.001875  Loss: -0.2058  Acc@1: 68.7500 (68.7500)  Acc@5: 93.7500 (94.7235)  time: 0.3669  data: 0.0013  max mem: 2502
Train: Epoch[5/5]  [ 330/1142]  eta: 0:04:53  Lr: 0.001875  Loss: -0.2649  Acc@1: 68.7500 (68.6934)  Acc@5: 93.7500 (94.6375)  time: 0.3556  data: 0.0007  max mem: 2502
Train: Epoch[5/5]  [ 340/1142]  eta: 0:04:50  Lr: 0.001875  Loss: -0.3086  Acc@1: 68.7500 (68.7500)  Acc@5: 93.7500 (94.6114)  time: 0.3625  data: 0.0013  max mem: 2502
Train: Epoch[5/5]  [ 350/1142]  eta: 0:04:46  Lr: 0.001875  Loss: 0.2484  Acc@1: 68.7500 (68.7144)  Acc@5: 93.7500 (94.6403)  time: 0.3624  data: 0.0014  max mem: 2502
Train: Epoch[5/5]  [ 360/1142]  eta: 0:04:42  Lr: 0.001875  Loss: -0.1455  Acc@1: 68.7500 (68.8366)  Acc@5: 93.7500 (94.6330)  time: 0.3525  data: 0.0006  max mem: 2502
Train: Epoch[5/5]  [ 370/1142]  eta: 0:04:39  Lr: 0.001875  Loss: -0.2415  Acc@1: 68.7500 (68.8342)  Acc@5: 93.7500 (94.6260)  time: 0.3566  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [ 380/1142]  eta: 0:04:35  Lr: 0.001875  Loss: -0.5424  Acc@1: 68.7500 (68.8320)  Acc@5: 93.7500 (94.6030)  time: 0.3600  data: 0.0007  max mem: 2502
Train: Epoch[5/5]  [ 390/1142]  eta: 0:04:31  Lr: 0.001875  Loss: -0.2763  Acc@1: 75.0000 (68.9738)  Acc@5: 93.7500 (94.6132)  time: 0.3579  data: 0.0007  max mem: 2502
Train: Epoch[5/5]  [ 400/1142]  eta: 0:04:28  Lr: 0.001875  Loss: 0.2237  Acc@1: 75.0000 (68.8747)  Acc@5: 93.7500 (94.6072)  time: 0.3583  data: 0.0006  max mem: 2502
Train: Epoch[5/5]  [ 410/1142]  eta: 0:04:24  Lr: 0.001875  Loss: -0.5980  Acc@1: 68.7500 (68.8869)  Acc@5: 93.7500 (94.5712)  time: 0.3709  data: 0.0012  max mem: 2502
Train: Epoch[5/5]  [ 420/1142]  eta: 0:04:20  Lr: 0.001875  Loss: -0.2373  Acc@1: 68.7500 (68.8094)  Acc@5: 93.7500 (94.5368)  time: 0.3655  data: 0.0012  max mem: 2502
Train: Epoch[5/5]  [ 430/1142]  eta: 0:04:17  Lr: 0.001875  Loss: -0.1145  Acc@1: 68.7500 (68.8950)  Acc@5: 93.7500 (94.6201)  time: 0.3530  data: 0.0006  max mem: 2502
Train: Epoch[5/5]  [ 440/1142]  eta: 0:04:13  Lr: 0.001875  Loss: -0.3531  Acc@1: 68.7500 (68.9626)  Acc@5: 100.0000 (94.6712)  time: 0.3606  data: 0.0006  max mem: 2502
Train: Epoch[5/5]  [ 450/1142]  eta: 0:04:09  Lr: 0.001875  Loss: 0.1674  Acc@1: 75.0000 (69.0272)  Acc@5: 93.7500 (94.6231)  time: 0.3587  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [ 460/1142]  eta: 0:04:06  Lr: 0.001875  Loss: -0.1185  Acc@1: 68.7500 (68.9940)  Acc@5: 93.7500 (94.6584)  time: 0.3547  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [ 470/1142]  eta: 0:04:02  Lr: 0.001875  Loss: -0.1048  Acc@1: 68.7500 (69.0552)  Acc@5: 93.7500 (94.6656)  time: 0.3619  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [ 480/1142]  eta: 0:03:58  Lr: 0.001875  Loss: -0.1638  Acc@1: 68.7500 (68.9969)  Acc@5: 93.7500 (94.6336)  time: 0.3571  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [ 490/1142]  eta: 0:03:55  Lr: 0.001875  Loss: -0.1673  Acc@1: 68.7500 (69.0428)  Acc@5: 93.7500 (94.6283)  time: 0.3541  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [ 500/1142]  eta: 0:03:51  Lr: 0.001875  Loss: -0.5133  Acc@1: 75.0000 (69.1742)  Acc@5: 100.0000 (94.6732)  time: 0.3653  data: 0.0007  max mem: 2502
Train: Epoch[5/5]  [ 510/1142]  eta: 0:03:48  Lr: 0.001875  Loss: -0.0156  Acc@1: 68.7500 (69.1292)  Acc@5: 93.7500 (94.6795)  time: 0.3648  data: 0.0022  max mem: 2502
Train: Epoch[5/5]  [ 520/1142]  eta: 0:03:44  Lr: 0.001875  Loss: -0.8268  Acc@1: 68.7500 (69.0859)  Acc@5: 93.7500 (94.6257)  time: 0.3576  data: 0.0020  max mem: 2502
Train: Epoch[5/5]  [ 530/1142]  eta: 0:03:40  Lr: 0.001875  Loss: -0.4238  Acc@1: 75.0000 (69.2561)  Acc@5: 93.7500 (94.6798)  time: 0.3554  data: 0.0006  max mem: 2502
Train: Epoch[5/5]  [ 540/1142]  eta: 0:03:37  Lr: 0.001875  Loss: -0.1702  Acc@1: 68.7500 (69.2352)  Acc@5: 93.7500 (94.6511)  time: 0.3621  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [ 550/1142]  eta: 0:03:33  Lr: 0.001875  Loss: 0.2025  Acc@1: 68.7500 (69.1583)  Acc@5: 93.7500 (94.5554)  time: 0.3589  data: 0.0007  max mem: 2502
Train: Epoch[5/5]  [ 560/1142]  eta: 0:03:29  Lr: 0.001875  Loss: -0.4854  Acc@1: 62.5000 (69.1288)  Acc@5: 93.7500 (94.5633)  time: 0.3511  data: 0.0007  max mem: 2502
Train: Epoch[5/5]  [ 570/1142]  eta: 0:03:26  Lr: 0.001875  Loss: 0.1461  Acc@1: 68.7500 (69.1331)  Acc@5: 93.7500 (94.6038)  time: 0.3565  data: 0.0006  max mem: 2502
Train: Epoch[5/5]  [ 580/1142]  eta: 0:03:22  Lr: 0.001875  Loss: -0.1238  Acc@1: 68.7500 (69.1695)  Acc@5: 100.0000 (94.6644)  time: 0.3610  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [ 590/1142]  eta: 0:03:19  Lr: 0.001875  Loss: -0.2800  Acc@1: 68.7500 (69.1413)  Acc@5: 100.0000 (94.6912)  time: 0.3585  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [ 600/1142]  eta: 0:03:15  Lr: 0.001875  Loss: -0.7150  Acc@1: 68.7500 (69.0828)  Acc@5: 93.7500 (94.6443)  time: 0.3585  data: 0.0007  max mem: 2502
Train: Epoch[5/5]  [ 610/1142]  eta: 0:03:12  Lr: 0.001875  Loss: 0.2070  Acc@1: 68.7500 (69.0160)  Acc@5: 93.7500 (94.6399)  time: 0.3737  data: 0.0022  max mem: 2502
Train: Epoch[5/5]  [ 620/1142]  eta: 0:03:08  Lr: 0.001875  Loss: -0.2216  Acc@1: 68.7500 (69.0721)  Acc@5: 93.7500 (94.6055)  time: 0.3669  data: 0.0025  max mem: 2502
Train: Epoch[5/5]  [ 630/1142]  eta: 0:03:04  Lr: 0.001875  Loss: -0.1933  Acc@1: 75.0000 (69.0571)  Acc@5: 93.7500 (94.6018)  time: 0.3537  data: 0.0009  max mem: 2502
Train: Epoch[5/5]  [ 640/1142]  eta: 0:03:01  Lr: 0.001875  Loss: -0.4663  Acc@1: 75.0000 (69.2083)  Acc@5: 100.0000 (94.6568)  time: 0.3656  data: 0.0010  max mem: 2502
Train: Epoch[5/5]  [ 650/1142]  eta: 0:02:57  Lr: 0.001875  Loss: -0.4711  Acc@1: 75.0000 (69.2204)  Acc@5: 93.7500 (94.6429)  time: 0.3594  data: 0.0010  max mem: 2502
Train: Epoch[5/5]  [ 660/1142]  eta: 0:02:53  Lr: 0.001875  Loss: -0.5811  Acc@1: 68.7500 (69.2228)  Acc@5: 93.7500 (94.6293)  time: 0.3487  data: 0.0008  max mem: 2502
Train: Epoch[5/5]  [ 670/1142]  eta: 0:02:50  Lr: 0.001875  Loss: -0.1839  Acc@1: 62.5000 (69.2623)  Acc@5: 93.7500 (94.6349)  time: 0.3558  data: 0.0009  max mem: 2502
Train: Epoch[5/5]  [ 680/1142]  eta: 0:02:46  Lr: 0.001875  Loss: -0.5668  Acc@1: 68.7500 (69.1905)  Acc@5: 93.7500 (94.5668)  time: 0.3633  data: 0.0011  max mem: 2502
Train: Epoch[5/5]  [ 690/1142]  eta: 0:02:42  Lr: 0.001875  Loss: -0.1866  Acc@1: 75.0000 (69.2656)  Acc@5: 93.7500 (94.6183)  time: 0.3588  data: 0.0010  max mem: 2502
Train: Epoch[5/5]  [ 700/1142]  eta: 0:02:39  Lr: 0.001875  Loss: -0.2642  Acc@1: 68.7500 (69.2136)  Acc@5: 100.0000 (94.6059)  time: 0.3543  data: 0.0006  max mem: 2502
Train: Epoch[5/5]  [ 710/1142]  eta: 0:02:35  Lr: 0.001875  Loss: -0.4136  Acc@1: 68.7500 (69.3126)  Acc@5: 93.7500 (94.6203)  time: 0.3698  data: 0.0006  max mem: 2502
Train: Epoch[5/5]  [ 720/1142]  eta: 0:02:32  Lr: 0.001875  Loss: -0.4921  Acc@1: 81.2500 (69.4435)  Acc@5: 100.0000 (94.6342)  time: 0.3638  data: 0.0006  max mem: 2502
Train: Epoch[5/5]  [ 730/1142]  eta: 0:02:28  Lr: 0.001875  Loss: 0.0286  Acc@1: 75.0000 (69.3656)  Acc@5: 93.7500 (94.6306)  time: 0.3515  data: 0.0008  max mem: 2502
Train: Epoch[5/5]  [ 740/1142]  eta: 0:02:24  Lr: 0.001875  Loss: -0.2810  Acc@1: 68.7500 (69.3995)  Acc@5: 93.7500 (94.6103)  time: 0.3623  data: 0.0008  max mem: 2502
Train: Epoch[5/5]  [ 750/1142]  eta: 0:02:21  Lr: 0.001875  Loss: 0.2771  Acc@1: 75.0000 (69.3575)  Acc@5: 93.7500 (94.6072)  time: 0.3592  data: 0.0006  max mem: 2502
Train: Epoch[5/5]  [ 760/1142]  eta: 0:02:17  Lr: 0.001875  Loss: 0.0310  Acc@1: 68.7500 (69.2346)  Acc@5: 93.7500 (94.5959)  time: 0.3538  data: 0.0006  max mem: 2502
Train: Epoch[5/5]  [ 770/1142]  eta: 0:02:14  Lr: 0.001875  Loss: -0.2921  Acc@1: 68.7500 (69.2202)  Acc@5: 93.7500 (94.5850)  time: 0.3621  data: 0.0006  max mem: 2502
Train: Epoch[5/5]  [ 780/1142]  eta: 0:02:10  Lr: 0.001875  Loss: -0.4954  Acc@1: 68.7500 (69.3422)  Acc@5: 93.7500 (94.6063)  time: 0.3573  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [ 790/1142]  eta: 0:02:06  Lr: 0.001875  Loss: -0.3918  Acc@1: 75.0000 (69.3663)  Acc@5: 100.0000 (94.6350)  time: 0.3514  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [ 800/1142]  eta: 0:02:03  Lr: 0.001875  Loss: 0.2592  Acc@1: 75.0000 (69.3898)  Acc@5: 93.7500 (94.6083)  time: 0.3649  data: 0.0006  max mem: 2502
Train: Epoch[5/5]  [ 810/1142]  eta: 0:01:59  Lr: 0.001875  Loss: -0.6201  Acc@1: 75.0000 (69.3819)  Acc@5: 93.7500 (94.6131)  time: 0.3618  data: 0.0012  max mem: 2502
Train: Epoch[5/5]  [ 820/1142]  eta: 0:01:56  Lr: 0.001875  Loss: -0.4434  Acc@1: 75.0000 (69.3819)  Acc@5: 93.7500 (94.6026)  time: 0.3569  data: 0.0018  max mem: 2502
Train: Epoch[5/5]  [ 830/1142]  eta: 0:01:52  Lr: 0.001875  Loss: -0.3728  Acc@1: 68.7500 (69.3592)  Acc@5: 93.7500 (94.6224)  time: 0.3592  data: 0.0012  max mem: 2502
Train: Epoch[5/5]  [ 840/1142]  eta: 0:01:48  Lr: 0.001875  Loss: -0.0617  Acc@1: 68.7500 (69.3891)  Acc@5: 93.7500 (94.6269)  time: 0.3575  data: 0.0010  max mem: 2502
Train: Epoch[5/5]  [ 850/1142]  eta: 0:01:45  Lr: 0.001875  Loss: -0.0157  Acc@1: 68.7500 (69.3449)  Acc@5: 93.7500 (94.6460)  time: 0.3647  data: 0.0011  max mem: 2502
Train: Epoch[5/5]  [ 860/1142]  eta: 0:01:41  Lr: 0.001875  Loss: -0.2289  Acc@1: 68.7500 (69.4106)  Acc@5: 93.7500 (94.6501)  time: 0.3594  data: 0.0008  max mem: 2502
Train: Epoch[5/5]  [ 870/1142]  eta: 0:01:37  Lr: 0.001875  Loss: -0.6857  Acc@1: 68.7500 (69.3384)  Acc@5: 93.7500 (94.6470)  time: 0.3536  data: 0.0006  max mem: 2502
Train: Epoch[5/5]  [ 880/1142]  eta: 0:01:34  Lr: 0.001875  Loss: -0.4531  Acc@1: 68.7500 (69.3956)  Acc@5: 93.7500 (94.6439)  time: 0.3630  data: 0.0008  max mem: 2502
Train: Epoch[5/5]  [ 890/1142]  eta: 0:01:30  Lr: 0.001875  Loss: -0.3526  Acc@1: 75.0000 (69.4585)  Acc@5: 93.7500 (94.6689)  time: 0.3594  data: 0.0012  max mem: 2502
Train: Epoch[5/5]  [ 900/1142]  eta: 0:01:27  Lr: 0.001875  Loss: 0.0634  Acc@1: 68.7500 (69.4575)  Acc@5: 100.0000 (94.6865)  time: 0.3548  data: 0.0010  max mem: 2502
Train: Epoch[5/5]  [ 910/1142]  eta: 0:01:23  Lr: 0.001875  Loss: -0.2381  Acc@1: 68.7500 (69.4772)  Acc@5: 93.7500 (94.6693)  time: 0.3646  data: 0.0006  max mem: 2502
Train: Epoch[5/5]  [ 920/1142]  eta: 0:01:20  Lr: 0.001875  Loss: -0.4059  Acc@1: 75.0000 (69.5440)  Acc@5: 93.7500 (94.6593)  time: 0.3682  data: 0.0006  max mem: 2502
Train: Epoch[5/5]  [ 930/1142]  eta: 0:01:16  Lr: 0.001875  Loss: -0.1729  Acc@1: 75.0000 (69.5086)  Acc@5: 93.7500 (94.6361)  time: 0.3588  data: 0.0007  max mem: 2502
Train: Epoch[5/5]  [ 940/1142]  eta: 0:01:12  Lr: 0.001875  Loss: -0.0306  Acc@1: 62.5000 (69.5271)  Acc@5: 93.7500 (94.6533)  time: 0.3532  data: 0.0006  max mem: 2502
Train: Epoch[5/5]  [ 950/1142]  eta: 0:01:09  Lr: 0.001875  Loss: -0.0826  Acc@1: 68.7500 (69.5386)  Acc@5: 93.7500 (94.6569)  time: 0.3642  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [ 960/1142]  eta: 0:01:05  Lr: 0.001875  Loss: -0.1200  Acc@1: 68.7500 (69.5304)  Acc@5: 93.7500 (94.6605)  time: 0.3622  data: 0.0006  max mem: 2502
Train: Epoch[5/5]  [ 970/1142]  eta: 0:01:01  Lr: 0.001875  Loss: 0.0157  Acc@1: 68.7500 (69.5417)  Acc@5: 93.7500 (94.6704)  time: 0.3525  data: 0.0006  max mem: 2502
Train: Epoch[5/5]  [ 980/1142]  eta: 0:00:58  Lr: 0.001875  Loss: -0.2705  Acc@1: 68.7500 (69.5273)  Acc@5: 93.7500 (94.6483)  time: 0.3613  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [ 990/1142]  eta: 0:00:54  Lr: 0.001875  Loss: -0.0157  Acc@1: 68.7500 (69.5320)  Acc@5: 93.7500 (94.6582)  time: 0.3589  data: 0.0012  max mem: 2502
Train: Epoch[5/5]  [1000/1142]  eta: 0:00:51  Lr: 0.001875  Loss: 0.2240  Acc@1: 75.0000 (69.5929)  Acc@5: 93.7500 (94.6429)  time: 0.3541  data: 0.0013  max mem: 2502
Train: Epoch[5/5]  [1010/1142]  eta: 0:00:47  Lr: 0.001875  Loss: 0.2015  Acc@1: 68.7500 (69.5846)  Acc@5: 93.7500 (94.6340)  time: 0.3657  data: 0.0007  max mem: 2502
Train: Epoch[5/5]  [1020/1142]  eta: 0:00:43  Lr: 0.001875  Loss: -0.0806  Acc@1: 68.7500 (69.6131)  Acc@5: 93.7500 (94.6437)  time: 0.3664  data: 0.0007  max mem: 2502
Train: Epoch[5/5]  [1030/1142]  eta: 0:00:40  Lr: 0.001875  Loss: -0.5543  Acc@1: 62.5000 (69.6169)  Acc@5: 93.7500 (94.6532)  time: 0.3571  data: 0.0008  max mem: 2502
Train: Epoch[5/5]  [1040/1142]  eta: 0:00:36  Lr: 0.001875  Loss: -0.5684  Acc@1: 62.5000 (69.6206)  Acc@5: 93.7500 (94.6566)  time: 0.3614  data: 0.0008  max mem: 2502
Train: Epoch[5/5]  [1050/1142]  eta: 0:00:33  Lr: 0.001875  Loss: 0.0534  Acc@1: 68.7500 (69.6242)  Acc@5: 93.7500 (94.6420)  time: 0.3596  data: 0.0006  max mem: 2502
Train: Epoch[5/5]  [1060/1142]  eta: 0:00:29  Lr: 0.001875  Loss: -0.3468  Acc@1: 68.7500 (69.6159)  Acc@5: 93.7500 (94.6454)  time: 0.3539  data: 0.0006  max mem: 2502
Train: Epoch[5/5]  [1070/1142]  eta: 0:00:25  Lr: 0.001875  Loss: -0.2193  Acc@1: 68.7500 (69.6370)  Acc@5: 93.7500 (94.6370)  time: 0.3646  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [1080/1142]  eta: 0:00:22  Lr: 0.001875  Loss: -0.3564  Acc@1: 68.7500 (69.6115)  Acc@5: 93.7500 (94.6230)  time: 0.3599  data: 0.0006  max mem: 2502
Train: Epoch[5/5]  [1090/1142]  eta: 0:00:18  Lr: 0.001875  Loss: 0.0329  Acc@1: 62.5000 (69.5864)  Acc@5: 93.7500 (94.6208)  time: 0.3510  data: 0.0006  max mem: 2502
Train: Epoch[5/5]  [1100/1142]  eta: 0:00:15  Lr: 0.001875  Loss: -0.5812  Acc@1: 68.7500 (69.6242)  Acc@5: 93.7500 (94.6412)  time: 0.3621  data: 0.0006  max mem: 2502
Train: Epoch[5/5]  [1110/1142]  eta: 0:00:11  Lr: 0.001875  Loss: -0.6507  Acc@1: 75.0000 (69.6332)  Acc@5: 93.7500 (94.6557)  time: 0.3603  data: 0.0017  max mem: 2502
Train: Epoch[5/5]  [1120/1142]  eta: 0:00:07  Lr: 0.001875  Loss: -0.5229  Acc@1: 62.5000 (69.5584)  Acc@5: 93.7500 (94.6699)  time: 0.3581  data: 0.0019  max mem: 2502
Train: Epoch[5/5]  [1130/1142]  eta: 0:00:04  Lr: 0.001875  Loss: -0.3854  Acc@1: 75.0000 (69.6176)  Acc@5: 93.7500 (94.6894)  time: 0.3576  data: 0.0007  max mem: 2502
Train: Epoch[5/5]  [1140/1142]  eta: 0:00:00  Lr: 0.001875  Loss: 0.4552  Acc@1: 75.0000 (69.5826)  Acc@5: 93.7500 (94.6483)  time: 0.3545  data: 0.0006  max mem: 2502
Train: Epoch[5/5]  [1141/1142]  eta: 0:00:00  Lr: 0.001875  Loss: -0.4853  Acc@1: 75.0000 (69.5850)  Acc@5: 93.7500 (94.6507)  time: 0.3474  data: 0.0006  max mem: 2502
Train: Epoch[5/5] Total time: 0:06:51 (0.3603 s / it)
{0: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 1: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 2: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 3: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 4: {0: 0, 1: 300000, 2: 0, 3: 352, 4: 0}, 5: {0: 0, 1: 300000, 2: 0, 3: 352, 4: 0}, 6: {0: 0, 1: 300000, 2: 0, 3: 352, 4: 0}, 7: {0: 0, 1: 300000, 2: 0, 3: 352, 4: 0}, 8: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 9: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 10: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 11: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 12: {0: 0, 1: 0, 2: 0, 3: 90968, 4: 0}, 13: {0: 0, 1: 0, 2: 0, 3: 90968, 4: 0}, 14: {0: 0, 1: 0, 2: 0, 3: 90968, 4: 0}, 15: {0: 0, 1: 0, 2: 0, 3: 90968, 4: 0}, 16: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 17: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 18: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, 19: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}}
Averaged stats: Lr: 0.001875  Loss: -0.4853  Acc@1: 75.0000 (69.5850)  Acc@5: 93.7500 (94.6507)
Test: [Task 1]  [   0/1627]  eta: 0:26:26  Loss: 1.2530 (1.2530)  Acc@1: 68.7500 (68.7500)  Acc@5: 93.7500 (93.7500)  time: 0.9752  data: 0.7489  max mem: 2502
Test: [Task 1]  [  10/1627]  eta: 0:07:41  Loss: 1.2379 (1.1196)  Acc@1: 68.7500 (72.7273)  Acc@5: 93.7500 (93.1818)  time: 0.2854  data: 0.0691  max mem: 2502
Test: [Task 1]  [  20/1627]  eta: 0:06:46  Loss: 1.1177 (1.0690)  Acc@1: 75.0000 (75.0000)  Acc@5: 93.7500 (93.4524)  time: 0.2166  data: 0.0008  max mem: 2502
Test: [Task 1]  [  30/1627]  eta: 0:06:27  Loss: 1.1198 (1.0936)  Acc@1: 75.0000 (73.7903)  Acc@5: 93.7500 (93.9516)  time: 0.2194  data: 0.0004  max mem: 2502
Test: [Task 1]  [  40/1627]  eta: 0:06:18  Loss: 1.1423 (1.1019)  Acc@1: 68.7500 (73.6280)  Acc@5: 93.7500 (94.0549)  time: 0.2236  data: 0.0008  max mem: 2502
Test: [Task 1]  [  50/1627]  eta: 0:06:13  Loss: 0.9789 (1.0862)  Acc@1: 75.0000 (74.0196)  Acc@5: 93.7500 (93.9951)  time: 0.2282  data: 0.0008  max mem: 2502
Test: [Task 1]  [  60/1627]  eta: 0:06:05  Loss: 1.1316 (1.1063)  Acc@1: 68.7500 (73.3607)  Acc@5: 93.7500 (93.5451)  time: 0.2232  data: 0.0004  max mem: 2502
Test: [Task 1]  [  70/1627]  eta: 0:06:00  Loss: 1.0383 (1.0981)  Acc@1: 68.7500 (73.5915)  Acc@5: 93.7500 (93.7500)  time: 0.2182  data: 0.0004  max mem: 2502
Test: [Task 1]  [  80/1627]  eta: 0:05:57  Loss: 0.9403 (1.0829)  Acc@1: 75.0000 (73.3796)  Acc@5: 93.7500 (93.9043)  time: 0.2226  data: 0.0005  max mem: 2502
Test: [Task 1]  [  90/1627]  eta: 0:05:55  Loss: 1.0077 (1.0927)  Acc@1: 68.7500 (73.0082)  Acc@5: 93.7500 (93.6126)  time: 0.2297  data: 0.0005  max mem: 2502
Test: [Task 1]  [ 100/1627]  eta: 0:05:53  Loss: 1.1555 (1.1126)  Acc@1: 68.7500 (72.4629)  Acc@5: 93.7500 (93.0074)  time: 0.2346  data: 0.0005  max mem: 2502
Test: [Task 1]  [ 110/1627]  eta: 0:05:49  Loss: 1.1651 (1.1129)  Acc@1: 68.7500 (72.2410)  Acc@5: 93.7500 (93.3559)  time: 0.2258  data: 0.0007  max mem: 2502
Test: [Task 1]  [ 120/1627]  eta: 0:05:45  Loss: 1.1932 (1.1158)  Acc@1: 68.7500 (72.2624)  Acc@5: 93.7500 (93.1818)  time: 0.2175  data: 0.0009  max mem: 2502
Test: [Task 1]  [ 130/1627]  eta: 0:05:42  Loss: 1.2215 (1.1193)  Acc@1: 75.0000 (72.2805)  Acc@5: 93.7500 (93.1775)  time: 0.2206  data: 0.0007  max mem: 2502
Test: [Task 1]  [ 140/1627]  eta: 0:05:39  Loss: 1.0477 (1.1175)  Acc@1: 81.2500 (72.4734)  Acc@5: 93.7500 (93.0408)  time: 0.2236  data: 0.0005  max mem: 2502
Test: [Task 1]  [ 150/1627]  eta: 0:05:37  Loss: 0.8365 (1.1031)  Acc@1: 81.2500 (72.8477)  Acc@5: 93.7500 (93.2119)  time: 0.2280  data: 0.0011  max mem: 2502
Test: [Task 1]  [ 160/1627]  eta: 0:05:34  Loss: 0.8278 (1.0959)  Acc@1: 75.0000 (73.1366)  Acc@5: 93.7500 (93.2842)  time: 0.2251  data: 0.0012  max mem: 2502
Test: [Task 1]  [ 170/1627]  eta: 0:05:31  Loss: 0.9151 (1.0899)  Acc@1: 75.0000 (73.1725)  Acc@5: 93.7500 (93.2749)  time: 0.2170  data: 0.0005  max mem: 2502
Test: [Task 1]  [ 180/1627]  eta: 0:05:28  Loss: 1.0389 (1.0955)  Acc@1: 75.0000 (72.9282)  Acc@5: 93.7500 (93.2666)  time: 0.2205  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 190/1627]  eta: 0:05:26  Loss: 1.0527 (1.0911)  Acc@1: 75.0000 (73.1021)  Acc@5: 93.7500 (93.3246)  time: 0.2243  data: 0.0004  max mem: 2502
Test: [Task 1]  [ 200/1627]  eta: 0:05:24  Loss: 1.0857 (1.0921)  Acc@1: 75.0000 (73.0410)  Acc@5: 93.7500 (93.2525)  time: 0.2272  data: 0.0004  max mem: 2502
Test: [Task 1]  [ 210/1627]  eta: 0:05:21  Loss: 1.0208 (1.0891)  Acc@1: 75.0000 (73.1931)  Acc@5: 93.7500 (93.2464)  time: 0.2238  data: 0.0007  max mem: 2502
Test: [Task 1]  [ 220/1627]  eta: 0:05:18  Loss: 0.9734 (1.0940)  Acc@1: 81.2500 (73.0769)  Acc@5: 93.7500 (93.1844)  time: 0.2208  data: 0.0018  max mem: 2502
Test: [Task 1]  [ 230/1627]  eta: 0:05:16  Loss: 1.0175 (1.0886)  Acc@1: 75.0000 (73.1872)  Acc@5: 93.7500 (93.2359)  time: 0.2267  data: 0.0037  max mem: 2502
Test: [Task 1]  [ 240/1627]  eta: 0:05:14  Loss: 0.9891 (1.0833)  Acc@1: 75.0000 (73.3143)  Acc@5: 93.7500 (93.2573)  time: 0.2287  data: 0.0032  max mem: 2502
Test: [Task 1]  [ 250/1627]  eta: 0:05:12  Loss: 0.9556 (1.0880)  Acc@1: 75.0000 (73.2072)  Acc@5: 93.7500 (93.2022)  time: 0.2311  data: 0.0018  max mem: 2502
Test: [Task 1]  [ 260/1627]  eta: 0:05:10  Loss: 1.0805 (1.0880)  Acc@1: 68.7500 (73.2998)  Acc@5: 93.7500 (93.1513)  time: 0.2352  data: 0.0041  max mem: 2502
Test: [Task 1]  [ 270/1627]  eta: 0:05:08  Loss: 0.9488 (1.0811)  Acc@1: 81.2500 (73.5009)  Acc@5: 93.7500 (93.2887)  time: 0.2337  data: 0.0057  max mem: 2502
Test: [Task 1]  [ 280/1627]  eta: 0:05:06  Loss: 0.9228 (1.0807)  Acc@1: 75.0000 (73.5098)  Acc@5: 93.7500 (93.2162)  time: 0.2281  data: 0.0050  max mem: 2502
Test: [Task 1]  [ 290/1627]  eta: 0:05:05  Loss: 1.0635 (1.0798)  Acc@1: 75.0000 (73.6254)  Acc@5: 93.7500 (93.2990)  time: 0.2357  data: 0.0044  max mem: 2502
Test: [Task 1]  [ 300/1627]  eta: 0:05:02  Loss: 0.9933 (1.0774)  Acc@1: 75.0000 (73.6503)  Acc@5: 100.0000 (93.3970)  time: 0.2362  data: 0.0051  max mem: 2502
Test: [Task 1]  [ 310/1627]  eta: 0:05:00  Loss: 0.9306 (1.0777)  Acc@1: 81.2500 (73.7741)  Acc@5: 93.7500 (93.3682)  time: 0.2254  data: 0.0043  max mem: 2502
Test: [Task 1]  [ 320/1627]  eta: 0:04:57  Loss: 1.0468 (1.0766)  Acc@1: 75.0000 (73.7734)  Acc@5: 93.7500 (93.4190)  time: 0.2251  data: 0.0033  max mem: 2502
Test: [Task 1]  [ 330/1627]  eta: 0:04:55  Loss: 0.9406 (1.0744)  Acc@1: 75.0000 (73.7915)  Acc@5: 93.7500 (93.4668)  time: 0.2264  data: 0.0040  max mem: 2502
Test: [Task 1]  [ 340/1627]  eta: 0:04:53  Loss: 0.9248 (1.0758)  Acc@1: 75.0000 (73.7537)  Acc@5: 100.0000 (93.5301)  time: 0.2282  data: 0.0044  max mem: 2502
Test: [Task 1]  [ 350/1627]  eta: 0:04:51  Loss: 0.9455 (1.0769)  Acc@1: 75.0000 (73.7179)  Acc@5: 93.7500 (93.4651)  time: 0.2325  data: 0.0059  max mem: 2502
Test: [Task 1]  [ 360/1627]  eta: 0:04:49  Loss: 0.9455 (1.0757)  Acc@1: 75.0000 (73.8054)  Acc@5: 93.7500 (93.4211)  time: 0.2368  data: 0.0040  max mem: 2502
Test: [Task 1]  [ 370/1627]  eta: 0:04:46  Loss: 0.9993 (1.0758)  Acc@1: 81.2500 (73.7534)  Acc@5: 93.7500 (93.4299)  time: 0.2305  data: 0.0036  max mem: 2502
Test: [Task 1]  [ 380/1627]  eta: 0:04:44  Loss: 1.0193 (1.0741)  Acc@1: 75.0000 (73.8681)  Acc@5: 93.7500 (93.4219)  time: 0.2211  data: 0.0040  max mem: 2502
Test: [Task 1]  [ 390/1627]  eta: 0:04:41  Loss: 0.9846 (1.0754)  Acc@1: 75.0000 (73.8811)  Acc@5: 93.7500 (93.3664)  time: 0.2207  data: 0.0016  max mem: 2502
Test: [Task 1]  [ 400/1627]  eta: 0:04:39  Loss: 1.1265 (1.0766)  Acc@1: 68.7500 (73.7999)  Acc@5: 93.7500 (93.3448)  time: 0.2254  data: 0.0039  max mem: 2502
Test: [Task 1]  [ 410/1627]  eta: 0:04:37  Loss: 0.9432 (1.0758)  Acc@1: 68.7500 (73.8899)  Acc@5: 93.7500 (93.3090)  time: 0.2273  data: 0.0044  max mem: 2502
Test: [Task 1]  [ 420/1627]  eta: 0:04:35  Loss: 0.8938 (1.0738)  Acc@1: 81.2500 (74.0053)  Acc@5: 93.7500 (93.3640)  time: 0.2350  data: 0.0045  max mem: 2502
Test: [Task 1]  [ 430/1627]  eta: 0:04:33  Loss: 0.8878 (1.0718)  Acc@1: 81.2500 (74.0719)  Acc@5: 100.0000 (93.4020)  time: 0.2342  data: 0.0063  max mem: 2502
Test: [Task 1]  [ 440/1627]  eta: 0:04:30  Loss: 1.0446 (1.0705)  Acc@1: 75.0000 (74.0930)  Acc@5: 93.7500 (93.4382)  time: 0.2245  data: 0.0047  max mem: 2502
Test: [Task 1]  [ 450/1627]  eta: 0:04:28  Loss: 1.0974 (1.0736)  Acc@1: 68.7500 (73.9329)  Acc@5: 93.7500 (93.3065)  time: 0.2242  data: 0.0046  max mem: 2502
Test: [Task 1]  [ 460/1627]  eta: 0:04:26  Loss: 1.1350 (1.0735)  Acc@1: 68.7500 (73.8747)  Acc@5: 87.5000 (93.3297)  time: 0.2263  data: 0.0042  max mem: 2502
Test: [Task 1]  [ 470/1627]  eta: 0:04:23  Loss: 1.0058 (1.0708)  Acc@1: 75.0000 (73.9252)  Acc@5: 93.7500 (93.3386)  time: 0.2272  data: 0.0032  max mem: 2502
Test: [Task 1]  [ 480/1627]  eta: 0:04:21  Loss: 1.0080 (1.0749)  Acc@1: 75.0000 (73.7396)  Acc@5: 93.7500 (93.3472)  time: 0.2250  data: 0.0023  max mem: 2502
Test: [Task 1]  [ 490/1627]  eta: 0:04:19  Loss: 1.0954 (1.0763)  Acc@1: 68.7500 (73.6380)  Acc@5: 93.7500 (93.3299)  time: 0.2311  data: 0.0052  max mem: 2502
Test: [Task 1]  [ 500/1627]  eta: 0:04:17  Loss: 0.9636 (1.0778)  Acc@1: 68.7500 (73.5654)  Acc@5: 93.7500 (93.3258)  time: 0.2381  data: 0.0074  max mem: 2502
Test: [Task 1]  [ 510/1627]  eta: 0:04:14  Loss: 1.0997 (1.0826)  Acc@1: 68.7500 (73.5445)  Acc@5: 93.7500 (93.2363)  time: 0.2317  data: 0.0059  max mem: 2502
Test: [Task 1]  [ 520/1627]  eta: 0:04:13  Loss: 1.2366 (1.0891)  Acc@1: 68.7500 (73.4405)  Acc@5: 87.5000 (93.1982)  time: 0.2379  data: 0.0081  max mem: 2502
Test: [Task 1]  [ 530/1627]  eta: 0:04:10  Loss: 1.0980 (1.0852)  Acc@1: 75.0000 (73.5640)  Acc@5: 93.7500 (93.2439)  time: 0.2368  data: 0.0082  max mem: 2502
Test: [Task 1]  [ 540/1627]  eta: 0:04:08  Loss: 1.0088 (1.0860)  Acc@1: 75.0000 (73.5906)  Acc@5: 93.7500 (93.2186)  time: 0.2218  data: 0.0045  max mem: 2502
Test: [Task 1]  [ 550/1627]  eta: 0:04:05  Loss: 1.1820 (1.0875)  Acc@1: 75.0000 (73.5594)  Acc@5: 93.7500 (93.1828)  time: 0.2206  data: 0.0026  max mem: 2502
Test: [Task 1]  [ 560/1627]  eta: 0:04:03  Loss: 1.1931 (1.0901)  Acc@1: 75.0000 (73.5183)  Acc@5: 93.7500 (93.1930)  time: 0.2259  data: 0.0043  max mem: 2502
Test: [Task 1]  [ 570/1627]  eta: 0:04:01  Loss: 1.1104 (1.0871)  Acc@1: 75.0000 (73.6208)  Acc@5: 93.7500 (93.2465)  time: 0.2287  data: 0.0052  max mem: 2502
Test: [Task 1]  [ 580/1627]  eta: 0:03:58  Loss: 1.0103 (1.0882)  Acc@1: 75.0000 (73.5370)  Acc@5: 93.7500 (93.2659)  time: 0.2279  data: 0.0061  max mem: 2502
Test: [Task 1]  [ 590/1627]  eta: 0:03:56  Loss: 1.1087 (1.0876)  Acc@1: 68.7500 (73.5089)  Acc@5: 93.7500 (93.2847)  time: 0.2309  data: 0.0049  max mem: 2502
Test: [Task 1]  [ 600/1627]  eta: 0:03:54  Loss: 1.0119 (1.0889)  Acc@1: 75.0000 (73.4921)  Acc@5: 93.7500 (93.2404)  time: 0.2304  data: 0.0025  max mem: 2502
Test: [Task 1]  [ 610/1627]  eta: 0:03:52  Loss: 1.0119 (1.0875)  Acc@1: 75.0000 (73.5884)  Acc@5: 93.7500 (93.2590)  time: 0.2251  data: 0.0026  max mem: 2502
Test: [Task 1]  [ 620/1627]  eta: 0:03:49  Loss: 0.9774 (1.0883)  Acc@1: 75.0000 (73.6111)  Acc@5: 93.7500 (93.2065)  time: 0.2214  data: 0.0031  max mem: 2502
Test: [Task 1]  [ 630/1627]  eta: 0:03:47  Loss: 0.9372 (1.0882)  Acc@1: 75.0000 (73.6133)  Acc@5: 93.7500 (93.2349)  time: 0.2262  data: 0.0035  max mem: 2502
Test: [Task 1]  [ 640/1627]  eta: 0:03:45  Loss: 0.8949 (1.0878)  Acc@1: 75.0000 (73.5959)  Acc@5: 93.7500 (93.2235)  time: 0.2312  data: 0.0046  max mem: 2502
Test: [Task 1]  [ 650/1627]  eta: 0:03:42  Loss: 1.0097 (1.0869)  Acc@1: 75.0000 (73.6079)  Acc@5: 93.7500 (93.2316)  time: 0.2299  data: 0.0045  max mem: 2502
Test: [Task 1]  [ 660/1627]  eta: 0:03:40  Loss: 0.9913 (1.0854)  Acc@1: 75.0000 (73.6573)  Acc@5: 93.7500 (93.2678)  time: 0.2319  data: 0.0024  max mem: 2502
Test: [Task 1]  [ 670/1627]  eta: 0:03:38  Loss: 1.0303 (1.0858)  Acc@1: 75.0000 (73.6773)  Acc@5: 93.7500 (93.2377)  time: 0.2285  data: 0.0032  max mem: 2502
Test: [Task 1]  [ 680/1627]  eta: 0:03:36  Loss: 1.1129 (1.0860)  Acc@1: 75.0000 (73.6509)  Acc@5: 87.5000 (93.1626)  time: 0.2244  data: 0.0037  max mem: 2502
Test: [Task 1]  [ 690/1627]  eta: 0:03:33  Loss: 0.9720 (1.0839)  Acc@1: 75.0000 (73.7156)  Acc@5: 93.7500 (93.2073)  time: 0.2276  data: 0.0037  max mem: 2502
Test: [Task 1]  [ 700/1627]  eta: 0:03:31  Loss: 1.0381 (1.0845)  Acc@1: 75.0000 (73.7429)  Acc@5: 93.7500 (93.1883)  time: 0.2310  data: 0.0060  max mem: 2502
Test: [Task 1]  [ 710/1627]  eta: 0:03:29  Loss: 0.9990 (1.0826)  Acc@1: 75.0000 (73.7605)  Acc@5: 93.7500 (93.2138)  time: 0.2321  data: 0.0060  max mem: 2502
Test: [Task 1]  [ 720/1627]  eta: 0:03:27  Loss: 0.9722 (1.0804)  Acc@1: 75.0000 (73.8124)  Acc@5: 93.7500 (93.2472)  time: 0.2287  data: 0.0031  max mem: 2502
Test: [Task 1]  [ 730/1627]  eta: 0:03:24  Loss: 0.9873 (1.0816)  Acc@1: 81.2500 (73.7517)  Acc@5: 93.7500 (93.2370)  time: 0.2346  data: 0.0025  max mem: 2502
Test: [Task 1]  [ 740/1627]  eta: 0:03:22  Loss: 1.0767 (1.0830)  Acc@1: 68.7500 (73.7433)  Acc@5: 93.7500 (93.2102)  time: 0.2405  data: 0.0078  max mem: 2502
Test: [Task 1]  [ 750/1627]  eta: 0:03:20  Loss: 0.9890 (1.0819)  Acc@1: 75.0000 (73.8432)  Acc@5: 93.7500 (93.2091)  time: 0.2307  data: 0.0085  max mem: 2502
Test: [Task 1]  [ 760/1627]  eta: 0:03:18  Loss: 1.0306 (1.0848)  Acc@1: 75.0000 (73.7516)  Acc@5: 87.5000 (93.1505)  time: 0.2309  data: 0.0063  max mem: 2502
Test: [Task 1]  [ 770/1627]  eta: 0:03:16  Loss: 0.8702 (1.0815)  Acc@1: 75.0000 (73.8813)  Acc@5: 93.7500 (93.1826)  time: 0.2410  data: 0.0074  max mem: 2502
Test: [Task 1]  [ 780/1627]  eta: 0:03:13  Loss: 0.7663 (1.0796)  Acc@1: 87.5000 (73.9757)  Acc@5: 100.0000 (93.2378)  time: 0.2334  data: 0.0057  max mem: 2502
Test: [Task 1]  [ 790/1627]  eta: 0:03:11  Loss: 0.8773 (1.0820)  Acc@1: 75.0000 (73.9017)  Acc@5: 93.7500 (93.2048)  time: 0.2270  data: 0.0061  max mem: 2502
Test: [Task 1]  [ 800/1627]  eta: 0:03:09  Loss: 0.9906 (1.0809)  Acc@1: 75.0000 (73.8920)  Acc@5: 93.7500 (93.2506)  time: 0.2287  data: 0.0050  max mem: 2502
Test: [Task 1]  [ 810/1627]  eta: 0:03:06  Loss: 0.9566 (1.0803)  Acc@1: 81.2500 (73.9827)  Acc@5: 100.0000 (93.2722)  time: 0.2282  data: 0.0033  max mem: 2502
Test: [Task 1]  [ 820/1627]  eta: 0:03:04  Loss: 0.9014 (1.0787)  Acc@1: 81.2500 (74.0484)  Acc@5: 100.0000 (93.2932)  time: 0.2289  data: 0.0037  max mem: 2502
Test: [Task 1]  [ 830/1627]  eta: 0:03:02  Loss: 0.8801 (1.0787)  Acc@1: 81.2500 (74.0072)  Acc@5: 93.7500 (93.3063)  time: 0.2319  data: 0.0031  max mem: 2502
Test: [Task 1]  [ 840/1627]  eta: 0:03:00  Loss: 0.9508 (1.0765)  Acc@1: 68.7500 (74.0042)  Acc@5: 100.0000 (93.3561)  time: 0.2287  data: 0.0034  max mem: 2502
Test: [Task 1]  [ 850/1627]  eta: 0:02:57  Loss: 0.9732 (1.0776)  Acc@1: 68.7500 (73.9498)  Acc@5: 100.0000 (93.3608)  time: 0.2202  data: 0.0029  max mem: 2502
Test: [Task 1]  [ 860/1627]  eta: 0:02:55  Loss: 0.9758 (1.0769)  Acc@1: 75.0000 (73.9910)  Acc@5: 93.7500 (93.3943)  time: 0.2238  data: 0.0052  max mem: 2502
Test: [Task 1]  [ 870/1627]  eta: 0:02:53  Loss: 0.9643 (1.0751)  Acc@1: 81.2500 (74.0528)  Acc@5: 100.0000 (93.4056)  time: 0.2289  data: 0.0053  max mem: 2502
Test: [Task 1]  [ 880/1627]  eta: 0:02:50  Loss: 1.0856 (1.0774)  Acc@1: 75.0000 (73.9217)  Acc@5: 93.7500 (93.4237)  time: 0.2280  data: 0.0024  max mem: 2502
Test: [Task 1]  [ 890/1627]  eta: 0:02:48  Loss: 1.2042 (1.0789)  Acc@1: 68.7500 (73.9268)  Acc@5: 93.7500 (93.4063)  time: 0.2257  data: 0.0017  max mem: 2502
Test: [Task 1]  [ 900/1627]  eta: 0:02:46  Loss: 1.0830 (1.0796)  Acc@1: 68.7500 (73.8971)  Acc@5: 93.7500 (93.3824)  time: 0.2296  data: 0.0009  max mem: 2502
Test: [Task 1]  [ 910/1627]  eta: 0:02:43  Loss: 1.0390 (1.0800)  Acc@1: 75.0000 (73.9709)  Acc@5: 93.7500 (93.3589)  time: 0.2278  data: 0.0013  max mem: 2502
Test: [Task 1]  [ 920/1627]  eta: 0:02:41  Loss: 1.0132 (1.0793)  Acc@1: 81.2500 (73.9957)  Acc@5: 93.7500 (93.3768)  time: 0.2212  data: 0.0026  max mem: 2502
Test: [Task 1]  [ 930/1627]  eta: 0:02:39  Loss: 1.0234 (1.0795)  Acc@1: 75.0000 (73.9796)  Acc@5: 93.7500 (93.3606)  time: 0.2257  data: 0.0046  max mem: 2502
Test: [Task 1]  [ 940/1627]  eta: 0:02:36  Loss: 1.0815 (1.0785)  Acc@1: 75.0000 (73.9904)  Acc@5: 93.7500 (93.3913)  time: 0.2267  data: 0.0041  max mem: 2502
Test: [Task 1]  [ 950/1627]  eta: 0:02:34  Loss: 1.1405 (1.0794)  Acc@1: 68.7500 (73.9222)  Acc@5: 93.7500 (93.4214)  time: 0.2233  data: 0.0017  max mem: 2502
Test: [Task 1]  [ 960/1627]  eta: 0:02:32  Loss: 1.0684 (1.0788)  Acc@1: 68.7500 (73.9334)  Acc@5: 93.7500 (93.4378)  time: 0.2301  data: 0.0026  max mem: 2502
Test: [Task 1]  [ 970/1627]  eta: 0:02:30  Loss: 0.9187 (1.0780)  Acc@1: 81.2500 (73.9701)  Acc@5: 93.7500 (93.4346)  time: 0.2443  data: 0.0044  max mem: 2502
Test: [Task 1]  [ 980/1627]  eta: 0:02:28  Loss: 1.0863 (1.0786)  Acc@1: 68.7500 (73.9233)  Acc@5: 93.7500 (93.4123)  time: 0.2428  data: 0.0070  max mem: 2502
Test: [Task 1]  [ 990/1627]  eta: 0:02:25  Loss: 1.1575 (1.0811)  Acc@1: 68.7500 (73.8963)  Acc@5: 93.7500 (93.3716)  time: 0.2305  data: 0.0070  max mem: 2502
Test: [Task 1]  [1000/1627]  eta: 0:02:23  Loss: 1.2917 (1.0820)  Acc@1: 75.0000 (73.8824)  Acc@5: 93.7500 (93.3379)  time: 0.2242  data: 0.0036  max mem: 2502
Test: [Task 1]  [1010/1627]  eta: 0:02:21  Loss: 1.1035 (1.0818)  Acc@1: 75.0000 (73.8811)  Acc@5: 93.7500 (93.3420)  time: 0.2276  data: 0.0041  max mem: 2502
Test: [Task 1]  [1020/1627]  eta: 0:02:18  Loss: 1.0417 (1.0817)  Acc@1: 75.0000 (73.8553)  Acc@5: 93.7500 (93.3460)  time: 0.2338  data: 0.0035  max mem: 2502
Test: [Task 1]  [1030/1627]  eta: 0:02:16  Loss: 0.9023 (1.0792)  Acc@1: 81.2500 (73.9331)  Acc@5: 93.7500 (93.3681)  time: 0.2290  data: 0.0025  max mem: 2502
Test: [Task 1]  [1040/1627]  eta: 0:02:14  Loss: 0.8031 (1.0779)  Acc@1: 75.0000 (73.9493)  Acc@5: 100.0000 (93.3958)  time: 0.2261  data: 0.0032  max mem: 2502
Test: [Task 1]  [1050/1627]  eta: 0:02:12  Loss: 0.9227 (1.0767)  Acc@1: 75.0000 (73.9772)  Acc@5: 100.0000 (93.4170)  time: 0.2293  data: 0.0029  max mem: 2502
Test: [Task 1]  [1060/1627]  eta: 0:02:09  Loss: 1.0271 (1.0771)  Acc@1: 75.0000 (73.9868)  Acc@5: 93.7500 (93.3907)  time: 0.2299  data: 0.0026  max mem: 2502
Test: [Task 1]  [1070/1627]  eta: 0:02:07  Loss: 1.0271 (1.0777)  Acc@1: 75.0000 (73.9613)  Acc@5: 93.7500 (93.3824)  time: 0.2316  data: 0.0035  max mem: 2502
Test: [Task 1]  [1080/1627]  eta: 0:02:05  Loss: 1.0405 (1.0781)  Acc@1: 75.0000 (73.9593)  Acc@5: 93.7500 (93.3742)  time: 0.2308  data: 0.0050  max mem: 2502
Test: [Task 1]  [1090/1627]  eta: 0:02:02  Loss: 1.0187 (1.0776)  Acc@1: 75.0000 (73.9975)  Acc@5: 93.7500 (93.3834)  time: 0.2336  data: 0.0044  max mem: 2502
Test: [Task 1]  [1100/1627]  eta: 0:02:00  Loss: 0.8905 (1.0759)  Acc@1: 75.0000 (74.0293)  Acc@5: 100.0000 (93.3980)  time: 0.2304  data: 0.0032  max mem: 2502
Test: [Task 1]  [1110/1627]  eta: 0:01:58  Loss: 0.9928 (1.0764)  Acc@1: 75.0000 (74.0212)  Acc@5: 93.7500 (93.3900)  time: 0.2210  data: 0.0027  max mem: 2502
Test: [Task 1]  [1120/1627]  eta: 0:01:55  Loss: 1.0463 (1.0777)  Acc@1: 68.7500 (73.9574)  Acc@5: 93.7500 (93.3932)  time: 0.2202  data: 0.0019  max mem: 2502
Test: [Task 1]  [1130/1627]  eta: 0:01:53  Loss: 1.1546 (1.0778)  Acc@1: 75.0000 (73.9666)  Acc@5: 93.7500 (93.3908)  time: 0.2248  data: 0.0034  max mem: 2502
Test: [Task 1]  [1140/1627]  eta: 0:01:51  Loss: 1.1546 (1.0788)  Acc@1: 75.0000 (73.9483)  Acc@5: 93.7500 (93.3775)  time: 0.2272  data: 0.0042  max mem: 2502
Test: [Task 1]  [1150/1627]  eta: 0:01:49  Loss: 1.2021 (1.0797)  Acc@1: 68.7500 (73.9140)  Acc@5: 93.7500 (93.3536)  time: 0.2256  data: 0.0025  max mem: 2502
Test: [Task 1]  [1160/1627]  eta: 0:01:46  Loss: 1.1752 (1.0788)  Acc@1: 68.7500 (73.9826)  Acc@5: 93.7500 (93.3516)  time: 0.2314  data: 0.0024  max mem: 2502
Test: [Task 1]  [1170/1627]  eta: 0:01:44  Loss: 1.0378 (1.0781)  Acc@1: 75.0000 (74.0179)  Acc@5: 93.7500 (93.3497)  time: 0.2315  data: 0.0023  max mem: 2502
Test: [Task 1]  [1180/1627]  eta: 0:01:42  Loss: 1.1200 (1.0792)  Acc@1: 75.0000 (74.0104)  Acc@5: 93.7500 (93.3743)  time: 0.2238  data: 0.0024  max mem: 2502
Test: [Task 1]  [1190/1627]  eta: 0:01:39  Loss: 1.1308 (1.0794)  Acc@1: 75.0000 (74.0082)  Acc@5: 93.7500 (93.3722)  time: 0.2234  data: 0.0038  max mem: 2502
Test: [Task 1]  [1200/1627]  eta: 0:01:37  Loss: 1.1011 (1.0793)  Acc@1: 75.0000 (73.9956)  Acc@5: 93.7500 (93.3857)  time: 0.2302  data: 0.0048  max mem: 2502
Test: [Task 1]  [1210/1627]  eta: 0:01:35  Loss: 0.9678 (1.0799)  Acc@1: 75.0000 (73.9730)  Acc@5: 93.7500 (93.3578)  time: 0.2311  data: 0.0033  max mem: 2502
Test: [Task 1]  [1220/1627]  eta: 0:01:33  Loss: 0.9491 (1.0791)  Acc@1: 75.0000 (73.9660)  Acc@5: 93.7500 (93.3661)  time: 0.2290  data: 0.0032  max mem: 2502
Test: [Task 1]  [1230/1627]  eta: 0:01:30  Loss: 1.0973 (1.0792)  Acc@1: 75.0000 (73.9439)  Acc@5: 93.7500 (93.3591)  time: 0.2337  data: 0.0044  max mem: 2502
Test: [Task 1]  [1240/1627]  eta: 0:01:28  Loss: 0.9930 (1.0784)  Acc@1: 75.0000 (73.9726)  Acc@5: 93.7500 (93.3622)  time: 0.2379  data: 0.0045  max mem: 2502
Test: [Task 1]  [1250/1627]  eta: 0:01:26  Loss: 0.9932 (1.0786)  Acc@1: 75.0000 (73.9858)  Acc@5: 93.7500 (93.3553)  time: 0.2337  data: 0.0061  max mem: 2502
Test: [Task 1]  [1260/1627]  eta: 0:01:24  Loss: 1.0840 (1.0783)  Acc@1: 75.0000 (74.0385)  Acc@5: 93.7500 (93.3634)  time: 0.2394  data: 0.0068  max mem: 2502
Test: [Task 1]  [1270/1627]  eta: 0:01:21  Loss: 1.0571 (1.0788)  Acc@1: 75.0000 (74.0264)  Acc@5: 93.7500 (93.3419)  time: 0.2383  data: 0.0067  max mem: 2502
Test: [Task 1]  [1280/1627]  eta: 0:01:19  Loss: 0.9204 (1.0770)  Acc@1: 75.0000 (74.0681)  Acc@5: 93.7500 (93.3548)  time: 0.2283  data: 0.0067  max mem: 2502
Test: [Task 1]  [1290/1627]  eta: 0:01:17  Loss: 0.9832 (1.0771)  Acc@1: 75.0000 (74.0366)  Acc@5: 93.7500 (93.3675)  time: 0.2298  data: 0.0051  max mem: 2502
Test: [Task 1]  [1300/1627]  eta: 0:01:14  Loss: 0.9958 (1.0767)  Acc@1: 75.0000 (74.0776)  Acc@5: 93.7500 (93.3657)  time: 0.2255  data: 0.0025  max mem: 2502
Test: [Task 1]  [1310/1627]  eta: 0:01:12  Loss: 0.8943 (1.0753)  Acc@1: 81.2500 (74.1180)  Acc@5: 93.7500 (93.3734)  time: 0.2230  data: 0.0010  max mem: 2502
Test: [Task 1]  [1320/1627]  eta: 0:01:10  Loss: 0.8101 (1.0736)  Acc@1: 81.2500 (74.1768)  Acc@5: 93.7500 (93.3904)  time: 0.2304  data: 0.0021  max mem: 2502
Test: [Task 1]  [1330/1627]  eta: 0:01:08  Loss: 0.8836 (1.0733)  Acc@1: 81.2500 (74.2064)  Acc@5: 93.7500 (93.3837)  time: 0.2380  data: 0.0026  max mem: 2502
Test: [Task 1]  [1340/1627]  eta: 0:01:05  Loss: 1.0284 (1.0745)  Acc@1: 75.0000 (74.1611)  Acc@5: 93.7500 (93.3678)  time: 0.2327  data: 0.0036  max mem: 2502
Test: [Task 1]  [1350/1627]  eta: 0:01:03  Loss: 1.0424 (1.0740)  Acc@1: 68.7500 (74.1580)  Acc@5: 93.7500 (93.3707)  time: 0.2279  data: 0.0042  max mem: 2502
Test: [Task 1]  [1360/1627]  eta: 0:01:01  Loss: 0.9883 (1.0735)  Acc@1: 75.0000 (74.1780)  Acc@5: 93.7500 (93.3826)  time: 0.2316  data: 0.0047  max mem: 2502
Test: [Task 1]  [1370/1627]  eta: 0:00:58  Loss: 0.9499 (1.0727)  Acc@1: 75.0000 (74.1840)  Acc@5: 93.7500 (93.3990)  time: 0.2319  data: 0.0060  max mem: 2502
Test: [Task 1]  [1380/1627]  eta: 0:00:56  Loss: 1.0432 (1.0732)  Acc@1: 68.7500 (74.1582)  Acc@5: 93.7500 (93.3970)  time: 0.2315  data: 0.0047  max mem: 2502
Test: [Task 1]  [1390/1627]  eta: 0:00:54  Loss: 1.1178 (1.0726)  Acc@1: 68.7500 (74.1508)  Acc@5: 93.7500 (93.4130)  time: 0.2374  data: 0.0045  max mem: 2502
Test: [Task 1]  [1400/1627]  eta: 0:00:52  Loss: 1.0208 (1.0729)  Acc@1: 68.7500 (74.1479)  Acc@5: 93.7500 (93.3976)  time: 0.2374  data: 0.0063  max mem: 2502
Test: [Task 1]  [1410/1627]  eta: 0:00:49  Loss: 0.8998 (1.0723)  Acc@1: 75.0000 (74.1495)  Acc@5: 93.7500 (93.4089)  time: 0.2299  data: 0.0041  max mem: 2502
Test: [Task 1]  [1420/1627]  eta: 0:00:47  Loss: 0.9791 (1.0717)  Acc@1: 75.0000 (74.1555)  Acc@5: 93.7500 (93.4245)  time: 0.2258  data: 0.0025  max mem: 2502
Test: [Task 1]  [1430/1627]  eta: 0:00:45  Loss: 1.1823 (1.0734)  Acc@1: 68.7500 (74.1352)  Acc@5: 93.7500 (93.3919)  time: 0.2286  data: 0.0049  max mem: 2502
Test: [Task 1]  [1440/1627]  eta: 0:00:42  Loss: 1.0658 (1.0731)  Acc@1: 68.7500 (74.1282)  Acc@5: 87.5000 (93.3943)  time: 0.2320  data: 0.0070  max mem: 2502
Test: [Task 1]  [1450/1627]  eta: 0:00:40  Loss: 1.1106 (1.0745)  Acc@1: 68.7500 (74.0696)  Acc@5: 93.7500 (93.3796)  time: 0.2319  data: 0.0077  max mem: 2502
Test: [Task 1]  [1460/1627]  eta: 0:00:38  Loss: 1.1848 (1.0748)  Acc@1: 68.7500 (74.0460)  Acc@5: 93.7500 (93.3693)  time: 0.2372  data: 0.0060  max mem: 2502
Test: [Task 1]  [1470/1627]  eta: 0:00:36  Loss: 1.0505 (1.0753)  Acc@1: 68.7500 (74.0143)  Acc@5: 93.7500 (93.3591)  time: 0.2386  data: 0.0045  max mem: 2502
Test: [Task 1]  [1480/1627]  eta: 0:00:33  Loss: 1.1776 (1.0758)  Acc@1: 68.7500 (73.9998)  Acc@5: 93.7500 (93.3575)  time: 0.2315  data: 0.0054  max mem: 2502
Test: [Task 1]  [1490/1627]  eta: 0:00:31  Loss: 1.1776 (1.0761)  Acc@1: 75.0000 (74.0233)  Acc@5: 93.7500 (93.3476)  time: 0.2333  data: 0.0059  max mem: 2502
Test: [Task 1]  [1500/1627]  eta: 0:00:29  Loss: 1.1618 (1.0766)  Acc@1: 75.0000 (74.0048)  Acc@5: 93.7500 (93.3419)  time: 0.2356  data: 0.0057  max mem: 2502
Test: [Task 1]  [1510/1627]  eta: 0:00:26  Loss: 0.8994 (1.0769)  Acc@1: 68.7500 (73.9825)  Acc@5: 93.7500 (93.3364)  time: 0.2295  data: 0.0057  max mem: 2502
Test: [Task 1]  [1520/1627]  eta: 0:00:24  Loss: 0.8994 (1.0756)  Acc@1: 75.0000 (74.0261)  Acc@5: 93.7500 (93.3473)  time: 0.2289  data: 0.0061  max mem: 2502
Test: [Task 1]  [1530/1627]  eta: 0:00:22  Loss: 0.8886 (1.0751)  Acc@1: 81.2500 (74.0243)  Acc@5: 100.0000 (93.3663)  time: 0.2281  data: 0.0047  max mem: 2502
Test: [Task 1]  [1540/1627]  eta: 0:00:19  Loss: 0.8473 (1.0740)  Acc@1: 75.0000 (74.0226)  Acc@5: 100.0000 (93.3809)  time: 0.2264  data: 0.0024  max mem: 2502
Test: [Task 1]  [1550/1627]  eta: 0:00:17  Loss: 0.8867 (1.0737)  Acc@1: 81.2500 (74.0490)  Acc@5: 93.7500 (93.3793)  time: 0.2312  data: 0.0046  max mem: 2502
Test: [Task 1]  [1560/1627]  eta: 0:00:15  Loss: 0.8867 (1.0729)  Acc@1: 81.2500 (74.0791)  Acc@5: 93.7500 (93.3857)  time: 0.2356  data: 0.0064  max mem: 2502
Test: [Task 1]  [1570/1627]  eta: 0:00:13  Loss: 0.9673 (1.0731)  Acc@1: 75.0000 (74.0850)  Acc@5: 93.7500 (93.3840)  time: 0.2305  data: 0.0059  max mem: 2502
Test: [Task 1]  [1580/1627]  eta: 0:00:10  Loss: 1.0154 (1.0730)  Acc@1: 75.0000 (74.0868)  Acc@5: 93.7500 (93.3863)  time: 0.2251  data: 0.0052  max mem: 2502
Test: [Task 1]  [1590/1627]  eta: 0:00:08  Loss: 1.0976 (1.0728)  Acc@1: 75.0000 (74.0808)  Acc@5: 93.7500 (93.3964)  time: 0.2291  data: 0.0058  max mem: 2502
Test: [Task 1]  [1600/1627]  eta: 0:00:06  Loss: 1.0883 (1.0738)  Acc@1: 68.7500 (74.0240)  Acc@5: 93.7500 (93.3752)  time: 0.2303  data: 0.0069  max mem: 2502
Test: [Task 1]  [1610/1627]  eta: 0:00:03  Loss: 1.0369 (1.0732)  Acc@1: 68.7500 (74.0417)  Acc@5: 93.7500 (93.3737)  time: 0.2254  data: 0.0036  max mem: 2502
Test: [Task 1]  [1620/1627]  eta: 0:00:01  Loss: 0.9792 (1.0723)  Acc@1: 75.0000 (74.0785)  Acc@5: 93.7500 (93.3837)  time: 0.2240  data: 0.0014  max mem: 2502
Test: [Task 1]  [1626/1627]  eta: 0:00:00  Loss: 0.9792 (1.0718)  Acc@1: 81.2500 (74.1165)  Acc@5: 93.7500 (93.3735)  time: 0.2328  data: 0.0012  max mem: 2502
Test: [Task 1] Total time: 0:06:13 (0.2298 s / it)
* Acc@1 74.116 Acc@5 93.374 loss 1.072
Test: [Task 2]  [  0/625]  eta: 0:11:03  Loss: 0.5327 (0.5327)  Acc@1: 81.2500 (81.2500)  Acc@5: 100.0000 (100.0000)  time: 1.0620  data: 0.8321  max mem: 2502
Test: [Task 2]  [ 10/625]  eta: 0:03:06  Loss: 0.6037 (0.5876)  Acc@1: 81.2500 (84.0909)  Acc@5: 100.0000 (98.8636)  time: 0.3029  data: 0.0796  max mem: 2502
Test: [Task 2]  [ 20/625]  eta: 0:02:39  Loss: 0.6358 (0.6343)  Acc@1: 81.2500 (81.8452)  Acc@5: 100.0000 (98.8095)  time: 0.2245  data: 0.0042  max mem: 2502
Test: [Task 2]  [ 30/625]  eta: 0:02:30  Loss: 0.6383 (0.6484)  Acc@1: 81.2500 (82.4597)  Acc@5: 100.0000 (98.3871)  time: 0.2262  data: 0.0032  max mem: 2502
Test: [Task 2]  [ 40/625]  eta: 0:02:24  Loss: 0.7048 (0.6756)  Acc@1: 81.2500 (82.9268)  Acc@5: 100.0000 (97.8659)  time: 0.2281  data: 0.0015  max mem: 2502
Test: [Task 2]  [ 50/625]  eta: 0:02:19  Loss: 0.7223 (0.6866)  Acc@1: 81.2500 (82.3529)  Acc@5: 93.7500 (97.3039)  time: 0.2270  data: 0.0029  max mem: 2502
Test: [Task 2]  [ 60/625]  eta: 0:02:18  Loss: 0.7223 (0.6953)  Acc@1: 75.0000 (81.3525)  Acc@5: 93.7500 (97.4385)  time: 0.2405  data: 0.0063  max mem: 2502
Test: [Task 2]  [ 70/625]  eta: 0:02:15  Loss: 0.7059 (0.6897)  Acc@1: 81.2500 (81.6021)  Acc@5: 100.0000 (97.4472)  time: 0.2492  data: 0.0085  max mem: 2502
Test: [Task 2]  [ 80/625]  eta: 0:02:12  Loss: 0.6810 (0.6984)  Acc@1: 81.2500 (81.4815)  Acc@5: 100.0000 (97.3765)  time: 0.2391  data: 0.0093  max mem: 2502
Test: [Task 2]  [ 90/625]  eta: 0:02:10  Loss: 0.6932 (0.7005)  Acc@1: 81.2500 (81.4560)  Acc@5: 100.0000 (97.4588)  time: 0.2395  data: 0.0073  max mem: 2502
Test: [Task 2]  [100/625]  eta: 0:02:07  Loss: 0.6837 (0.7001)  Acc@1: 81.2500 (81.4975)  Acc@5: 100.0000 (97.4629)  time: 0.2382  data: 0.0054  max mem: 2502
Test: [Task 2]  [110/625]  eta: 0:02:03  Loss: 0.6837 (0.6991)  Acc@1: 81.2500 (81.4189)  Acc@5: 93.7500 (97.2973)  time: 0.2275  data: 0.0061  max mem: 2502
Test: [Task 2]  [120/625]  eta: 0:02:01  Loss: 0.6590 (0.6965)  Acc@1: 81.2500 (81.6116)  Acc@5: 93.7500 (97.2624)  time: 0.2288  data: 0.0067  max mem: 2502
Test: [Task 2]  [130/625]  eta: 0:01:58  Loss: 0.6783 (0.6961)  Acc@1: 81.2500 (81.6317)  Acc@5: 100.0000 (97.2805)  time: 0.2326  data: 0.0065  max mem: 2502
Test: [Task 2]  [140/625]  eta: 0:01:55  Loss: 0.6783 (0.6983)  Acc@1: 81.2500 (81.6046)  Acc@5: 100.0000 (97.2074)  time: 0.2316  data: 0.0068  max mem: 2502
Test: [Task 2]  [150/625]  eta: 0:01:53  Loss: 0.7423 (0.7034)  Acc@1: 75.0000 (81.0017)  Acc@5: 100.0000 (97.2682)  time: 0.2297  data: 0.0048  max mem: 2502
Test: [Task 2]  [160/625]  eta: 0:01:50  Loss: 0.6968 (0.7027)  Acc@1: 75.0000 (80.8618)  Acc@5: 100.0000 (97.3602)  time: 0.2316  data: 0.0024  max mem: 2502
Test: [Task 2]  [170/625]  eta: 0:01:48  Loss: 0.6861 (0.7035)  Acc@1: 81.2500 (80.9211)  Acc@5: 100.0000 (97.3319)  time: 0.2358  data: 0.0033  max mem: 2502
Test: [Task 2]  [180/625]  eta: 0:01:45  Loss: 0.6919 (0.7042)  Acc@1: 81.2500 (80.9392)  Acc@5: 100.0000 (97.3066)  time: 0.2374  data: 0.0062  max mem: 2502
Test: [Task 2]  [190/625]  eta: 0:01:43  Loss: 0.6738 (0.7023)  Acc@1: 81.2500 (81.0537)  Acc@5: 93.7500 (97.2840)  time: 0.2307  data: 0.0055  max mem: 2502
Test: [Task 2]  [200/625]  eta: 0:01:40  Loss: 0.7504 (0.7057)  Acc@1: 81.2500 (80.8147)  Acc@5: 100.0000 (97.2637)  time: 0.2255  data: 0.0027  max mem: 2502
Test: [Task 2]  [210/625]  eta: 0:01:38  Loss: 0.7697 (0.7088)  Acc@1: 81.2500 (80.8945)  Acc@5: 100.0000 (97.1860)  time: 0.2288  data: 0.0033  max mem: 2502
Test: [Task 2]  [220/625]  eta: 0:01:35  Loss: 0.6528 (0.7073)  Acc@1: 81.2500 (80.9389)  Acc@5: 100.0000 (97.1719)  time: 0.2293  data: 0.0034  max mem: 2502
Test: [Task 2]  [230/625]  eta: 0:01:33  Loss: 0.6528 (0.7092)  Acc@1: 81.2500 (80.8442)  Acc@5: 100.0000 (97.2132)  time: 0.2345  data: 0.0043  max mem: 2502
Test: [Task 2]  [240/625]  eta: 0:01:30  Loss: 0.7248 (0.7069)  Acc@1: 81.2500 (80.9907)  Acc@5: 100.0000 (97.2251)  time: 0.2376  data: 0.0052  max mem: 2502
Test: [Task 2]  [250/625]  eta: 0:01:28  Loss: 0.6397 (0.7028)  Acc@1: 81.2500 (81.2500)  Acc@5: 93.7500 (97.1614)  time: 0.2346  data: 0.0057  max mem: 2502
Test: [Task 2]  [260/625]  eta: 0:01:26  Loss: 0.6316 (0.7033)  Acc@1: 81.2500 (81.2739)  Acc@5: 93.7500 (97.1504)  time: 0.2321  data: 0.0067  max mem: 2502
Test: [Task 2]  [270/625]  eta: 0:01:23  Loss: 0.6922 (0.7048)  Acc@1: 81.2500 (81.3192)  Acc@5: 93.7500 (97.0710)  time: 0.2359  data: 0.0063  max mem: 2502
Test: [Task 2]  [280/625]  eta: 0:01:21  Loss: 0.6236 (0.7040)  Acc@1: 81.2500 (81.3390)  Acc@5: 100.0000 (97.1308)  time: 0.2376  data: 0.0070  max mem: 2502
Test: [Task 2]  [290/625]  eta: 0:01:19  Loss: 0.6433 (0.7073)  Acc@1: 81.2500 (81.3574)  Acc@5: 100.0000 (97.1005)  time: 0.2409  data: 0.0059  max mem: 2502
Test: [Task 2]  [300/625]  eta: 0:01:16  Loss: 0.7025 (0.7086)  Acc@1: 81.2500 (81.2292)  Acc@5: 100.0000 (97.1553)  time: 0.2456  data: 0.0060  max mem: 2502
Test: [Task 2]  [310/625]  eta: 0:01:14  Loss: 0.7514 (0.7136)  Acc@1: 75.0000 (80.8481)  Acc@5: 100.0000 (97.2066)  time: 0.2333  data: 0.0050  max mem: 2502
Test: [Task 2]  [320/625]  eta: 0:01:12  Loss: 0.6166 (0.7054)  Acc@1: 75.0000 (80.9774)  Acc@5: 100.0000 (97.2741)  time: 0.2344  data: 0.0040  max mem: 2502
Test: [Task 2]  [330/625]  eta: 0:01:09  Loss: 0.5291 (0.7055)  Acc@1: 81.2500 (81.0045)  Acc@5: 100.0000 (97.3187)  time: 0.2376  data: 0.0055  max mem: 2502
Test: [Task 2]  [340/625]  eta: 0:01:07  Loss: 0.5836 (0.6971)  Acc@1: 87.5000 (81.2867)  Acc@5: 100.0000 (97.3974)  time: 0.2281  data: 0.0056  max mem: 2502
Test: [Task 2]  [350/625]  eta: 0:01:04  Loss: 0.4905 (0.6951)  Acc@1: 87.5000 (81.2322)  Acc@5: 100.0000 (97.4181)  time: 0.2266  data: 0.0062  max mem: 2502
Test: [Task 2]  [360/625]  eta: 0:01:02  Loss: 0.6737 (0.6992)  Acc@1: 81.2500 (81.1981)  Acc@5: 100.0000 (97.4377)  time: 0.2267  data: 0.0046  max mem: 2502
Test: [Task 2]  [370/625]  eta: 0:00:59  Loss: 0.6408 (0.6927)  Acc@1: 87.5000 (81.4185)  Acc@5: 100.0000 (97.5067)  time: 0.2270  data: 0.0016  max mem: 2502
Test: [Task 2]  [380/625]  eta: 0:00:57  Loss: 0.6015 (0.6948)  Acc@1: 81.2500 (81.2664)  Acc@5: 100.0000 (97.5230)  time: 0.2281  data: 0.0005  max mem: 2502
Test: [Task 2]  [390/625]  eta: 0:00:55  Loss: 0.6204 (0.6930)  Acc@1: 75.0000 (81.2020)  Acc@5: 100.0000 (97.4744)  time: 0.2238  data: 0.0010  max mem: 2502
Test: [Task 2]  [400/625]  eta: 0:00:52  Loss: 0.4426 (0.6855)  Acc@1: 87.5000 (81.4526)  Acc@5: 100.0000 (97.5218)  time: 0.2212  data: 0.0009  max mem: 2502
Test: [Task 2]  [410/625]  eta: 0:00:50  Loss: 0.3616 (0.6808)  Acc@1: 93.7500 (81.6606)  Acc@5: 100.0000 (97.5365)  time: 0.2238  data: 0.0003  max mem: 2502
Test: [Task 2]  [420/625]  eta: 0:00:47  Loss: 0.4834 (0.6828)  Acc@1: 81.2500 (81.5618)  Acc@5: 100.0000 (97.5356)  time: 0.2278  data: 0.0004  max mem: 2502
Test: [Task 2]  [430/625]  eta: 0:00:45  Loss: 0.6023 (0.6810)  Acc@1: 81.2500 (81.6125)  Acc@5: 100.0000 (97.5493)  time: 0.2231  data: 0.0004  max mem: 2502
Test: [Task 2]  [440/625]  eta: 0:00:43  Loss: 0.3844 (0.6729)  Acc@1: 87.5000 (81.8452)  Acc@5: 100.0000 (97.6049)  time: 0.2169  data: 0.0004  max mem: 2502
Test: [Task 2]  [450/625]  eta: 0:00:40  Loss: 0.3663 (0.6673)  Acc@1: 87.5000 (81.9429)  Acc@5: 100.0000 (97.6580)  time: 0.2212  data: 0.0005  max mem: 2502
Test: [Task 2]  [460/625]  eta: 0:00:38  Loss: 0.4445 (0.6640)  Acc@1: 87.5000 (82.0228)  Acc@5: 100.0000 (97.7088)  time: 0.2282  data: 0.0004  max mem: 2502
Test: [Task 2]  [470/625]  eta: 0:00:36  Loss: 0.5443 (0.6627)  Acc@1: 87.5000 (82.0594)  Acc@5: 100.0000 (97.7574)  time: 0.2249  data: 0.0010  max mem: 2502
Test: [Task 2]  [480/625]  eta: 0:00:33  Loss: 0.5620 (0.6612)  Acc@1: 87.5000 (82.1336)  Acc@5: 100.0000 (97.7521)  time: 0.2175  data: 0.0014  max mem: 2502
Test: [Task 2]  [490/625]  eta: 0:00:31  Loss: 0.4289 (0.6561)  Acc@1: 87.5000 (82.3447)  Acc@5: 100.0000 (97.7979)  time: 0.2272  data: 0.0008  max mem: 2502
Test: [Task 2]  [500/625]  eta: 0:00:29  Loss: 0.4437 (0.6545)  Acc@1: 87.5000 (82.3728)  Acc@5: 100.0000 (97.8293)  time: 0.2266  data: 0.0005  max mem: 2502
Test: [Task 2]  [510/625]  eta: 0:00:26  Loss: 0.5481 (0.6567)  Acc@1: 81.2500 (82.3141)  Acc@5: 100.0000 (97.8474)  time: 0.2162  data: 0.0004  max mem: 2502
Test: [Task 2]  [520/625]  eta: 0:00:24  Loss: 0.7042 (0.6621)  Acc@1: 75.0000 (82.2097)  Acc@5: 100.0000 (97.8167)  time: 0.2192  data: 0.0004  max mem: 2502
Test: [Task 2]  [530/625]  eta: 0:00:21  Loss: 0.6269 (0.6611)  Acc@1: 81.2500 (82.1916)  Acc@5: 100.0000 (97.8578)  time: 0.2233  data: 0.0004  max mem: 2502
Test: [Task 2]  [540/625]  eta: 0:00:19  Loss: 0.5059 (0.6582)  Acc@1: 81.2500 (82.2897)  Acc@5: 100.0000 (97.8743)  time: 0.2268  data: 0.0004  max mem: 2502
Test: [Task 2]  [550/625]  eta: 0:00:17  Loss: 0.3592 (0.6523)  Acc@1: 93.7500 (82.4977)  Acc@5: 100.0000 (97.9015)  time: 0.2226  data: 0.0005  max mem: 2502
Test: [Task 2]  [560/625]  eta: 0:00:15  Loss: 0.3089 (0.6463)  Acc@1: 93.7500 (82.6983)  Acc@5: 100.0000 (97.9389)  time: 0.2186  data: 0.0005  max mem: 2502
Test: [Task 2]  [570/625]  eta: 0:00:12  Loss: 0.3656 (0.6465)  Acc@1: 87.5000 (82.7167)  Acc@5: 100.0000 (97.9422)  time: 0.2235  data: 0.0006  max mem: 2502
Test: [Task 2]  [580/625]  eta: 0:00:10  Loss: 0.4667 (0.6419)  Acc@1: 87.5000 (82.8636)  Acc@5: 100.0000 (97.9669)  time: 0.2302  data: 0.0006  max mem: 2502
Test: [Task 2]  [590/625]  eta: 0:00:08  Loss: 0.4429 (0.6394)  Acc@1: 87.5000 (82.9209)  Acc@5: 100.0000 (97.9907)  time: 0.2258  data: 0.0005  max mem: 2502
Test: [Task 2]  [600/625]  eta: 0:00:05  Loss: 0.5442 (0.6399)  Acc@1: 87.5000 (82.9451)  Acc@5: 100.0000 (97.9929)  time: 0.2165  data: 0.0006  max mem: 2502
Test: [Task 2]  [610/625]  eta: 0:00:03  Loss: 0.7845 (0.6452)  Acc@1: 81.2500 (82.7844)  Acc@5: 100.0000 (97.9542)  time: 0.2188  data: 0.0006  max mem: 2502
Test: [Task 2]  [620/625]  eta: 0:00:01  Loss: 0.8089 (0.6471)  Acc@1: 75.0000 (82.6791)  Acc@5: 100.0000 (97.9771)  time: 0.2215  data: 0.0004  max mem: 2502
Test: [Task 2]  [624/625]  eta: 0:00:00  Loss: 0.6965 (0.6462)  Acc@1: 81.2500 (82.7000)  Acc@5: 100.0000 (97.9900)  time: 0.2225  data: 0.0003  max mem: 2502
Test: [Task 2] Total time: 0:02:24 (0.2307 s / it)
* Acc@1 82.700 Acc@5 97.990 loss 0.646
Test: [Task 3]  [  0/625]  eta: 0:10:03  Loss: 0.1150 (0.1150)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)  time: 0.9651  data: 0.7023  max mem: 2502
Test: [Task 3]  [ 10/625]  eta: 0:02:55  Loss: 0.2369 (0.2111)  Acc@1: 100.0000 (97.1591)  Acc@5: 100.0000 (100.0000)  time: 0.2850  data: 0.0651  max mem: 2502
Test: [Task 3]  [ 20/625]  eta: 0:02:38  Loss: 0.2369 (0.2287)  Acc@1: 93.7500 (96.4286)  Acc@5: 100.0000 (99.7024)  time: 0.2271  data: 0.0009  max mem: 2502
Test: [Task 3]  [ 30/625]  eta: 0:02:27  Loss: 0.2239 (0.2255)  Acc@1: 93.7500 (96.1694)  Acc@5: 100.0000 (99.5968)  time: 0.2263  data: 0.0005  max mem: 2502
Test: [Task 3]  [ 40/625]  eta: 0:02:20  Loss: 0.1406 (0.1989)  Acc@1: 100.0000 (96.7988)  Acc@5: 100.0000 (99.6951)  time: 0.2176  data: 0.0005  max mem: 2502
Test: [Task 3]  [ 50/625]  eta: 0:02:16  Loss: 0.1063 (0.1961)  Acc@1: 100.0000 (96.9363)  Acc@5: 100.0000 (99.6324)  time: 0.2222  data: 0.0004  max mem: 2502
Test: [Task 3]  [ 60/625]  eta: 0:02:13  Loss: 0.1751 (0.1946)  Acc@1: 100.0000 (96.9262)  Acc@5: 100.0000 (99.6926)  time: 0.2267  data: 0.0004  max mem: 2502
Test: [Task 3]  [ 70/625]  eta: 0:02:09  Loss: 0.1220 (0.1847)  Acc@1: 100.0000 (97.0951)  Acc@5: 100.0000 (99.6479)  time: 0.2253  data: 0.0004  max mem: 2502
Test: [Task 3]  [ 80/625]  eta: 0:02:06  Loss: 0.1183 (0.1840)  Acc@1: 100.0000 (97.0679)  Acc@5: 100.0000 (99.6914)  time: 0.2203  data: 0.0006  max mem: 2502
Test: [Task 3]  [ 90/625]  eta: 0:02:03  Loss: 0.1390 (0.1852)  Acc@1: 100.0000 (97.1841)  Acc@5: 100.0000 (99.6566)  time: 0.2197  data: 0.0006  max mem: 2502
Test: [Task 3]  [100/625]  eta: 0:02:00  Loss: 0.1337 (0.1827)  Acc@1: 100.0000 (97.2153)  Acc@5: 100.0000 (99.6906)  time: 0.2216  data: 0.0004  max mem: 2502
Test: [Task 3]  [110/625]  eta: 0:01:58  Loss: 0.1164 (0.1777)  Acc@1: 100.0000 (97.4662)  Acc@5: 100.0000 (99.7185)  time: 0.2300  data: 0.0009  max mem: 2502
Test: [Task 3]  [120/625]  eta: 0:01:55  Loss: 0.1337 (0.1791)  Acc@1: 100.0000 (97.4690)  Acc@5: 100.0000 (99.7417)  time: 0.2276  data: 0.0011  max mem: 2502
Test: [Task 3]  [130/625]  eta: 0:01:53  Loss: 0.1426 (0.1789)  Acc@1: 100.0000 (97.5191)  Acc@5: 100.0000 (99.6660)  time: 0.2179  data: 0.0010  max mem: 2502
Test: [Task 3]  [140/625]  eta: 0:01:50  Loss: 0.1768 (0.1842)  Acc@1: 100.0000 (97.4291)  Acc@5: 100.0000 (99.6011)  time: 0.2202  data: 0.0025  max mem: 2502
Test: [Task 3]  [150/625]  eta: 0:01:48  Loss: 0.2079 (0.1908)  Acc@1: 93.7500 (97.2682)  Acc@5: 100.0000 (99.5447)  time: 0.2219  data: 0.0022  max mem: 2502
Test: [Task 3]  [160/625]  eta: 0:01:45  Loss: 0.1684 (0.1927)  Acc@1: 100.0000 (97.2438)  Acc@5: 100.0000 (99.4953)  time: 0.2226  data: 0.0007  max mem: 2502
Test: [Task 3]  [170/625]  eta: 0:01:43  Loss: 0.1413 (0.1911)  Acc@1: 100.0000 (97.2588)  Acc@5: 100.0000 (99.5249)  time: 0.2305  data: 0.0011  max mem: 2502
Test: [Task 3]  [180/625]  eta: 0:01:41  Loss: 0.2196 (0.1949)  Acc@1: 93.7500 (97.0994)  Acc@5: 100.0000 (99.5511)  time: 0.2277  data: 0.0018  max mem: 2502
Test: [Task 3]  [190/625]  eta: 0:01:39  Loss: 0.1992 (0.1938)  Acc@1: 93.7500 (97.1531)  Acc@5: 100.0000 (99.5419)  time: 0.2251  data: 0.0015  max mem: 2502
Test: [Task 3]  [200/625]  eta: 0:01:36  Loss: 0.1992 (0.1969)  Acc@1: 100.0000 (97.0771)  Acc@5: 100.0000 (99.5025)  time: 0.2246  data: 0.0011  max mem: 2502
Test: [Task 3]  [210/625]  eta: 0:01:34  Loss: 0.1904 (0.1982)  Acc@1: 100.0000 (97.0675)  Acc@5: 100.0000 (99.4668)  time: 0.2198  data: 0.0010  max mem: 2502
Test: [Task 3]  [220/625]  eta: 0:01:31  Loss: 0.1647 (0.1981)  Acc@1: 100.0000 (97.0305)  Acc@5: 100.0000 (99.4627)  time: 0.2233  data: 0.0007  max mem: 2502
Test: [Task 3]  [230/625]  eta: 0:01:29  Loss: 0.1657 (0.1992)  Acc@1: 100.0000 (96.9426)  Acc@5: 100.0000 (99.4589)  time: 0.2249  data: 0.0005  max mem: 2502
Test: [Task 3]  [240/625]  eta: 0:01:27  Loss: 0.2161 (0.2015)  Acc@1: 93.7500 (96.8880)  Acc@5: 100.0000 (99.4295)  time: 0.2267  data: 0.0004  max mem: 2502
Test: [Task 3]  [250/625]  eta: 0:01:24  Loss: 0.1335 (0.1994)  Acc@1: 100.0000 (96.9373)  Acc@5: 100.0000 (99.4522)  time: 0.2219  data: 0.0004  max mem: 2502
Test: [Task 3]  [260/625]  eta: 0:01:22  Loss: 0.1215 (0.1982)  Acc@1: 100.0000 (96.9349)  Acc@5: 100.0000 (99.4492)  time: 0.2184  data: 0.0004  max mem: 2502
Test: [Task 3]  [270/625]  eta: 0:01:20  Loss: 0.1409 (0.1970)  Acc@1: 93.7500 (96.9096)  Acc@5: 100.0000 (99.4696)  time: 0.2218  data: 0.0004  max mem: 2502
Test: [Task 3]  [280/625]  eta: 0:01:18  Loss: 0.1539 (0.1970)  Acc@1: 93.7500 (96.8639)  Acc@5: 100.0000 (99.4440)  time: 0.2288  data: 0.0004  max mem: 2502
Test: [Task 3]  [290/625]  eta: 0:01:15  Loss: 0.1541 (0.1966)  Acc@1: 93.7500 (96.8643)  Acc@5: 100.0000 (99.4631)  time: 0.2252  data: 0.0004  max mem: 2502
Test: [Task 3]  [300/625]  eta: 0:01:13  Loss: 0.1541 (0.1978)  Acc@1: 100.0000 (96.7816)  Acc@5: 100.0000 (99.4601)  time: 0.2167  data: 0.0005  max mem: 2502
Test: [Task 3]  [310/625]  eta: 0:01:11  Loss: 0.1721 (0.1996)  Acc@1: 100.0000 (96.7645)  Acc@5: 100.0000 (99.3971)  time: 0.2218  data: 0.0005  max mem: 2502
Test: [Task 3]  [320/625]  eta: 0:01:08  Loss: 0.1535 (0.1989)  Acc@1: 100.0000 (96.7874)  Acc@5: 100.0000 (99.3769)  time: 0.2261  data: 0.0012  max mem: 2502
Test: [Task 3]  [330/625]  eta: 0:01:06  Loss: 0.1735 (0.2002)  Acc@1: 93.7500 (96.7523)  Acc@5: 100.0000 (99.3769)  time: 0.2281  data: 0.0028  max mem: 2502
Test: [Task 3]  [340/625]  eta: 0:01:04  Loss: 0.1452 (0.1983)  Acc@1: 93.7500 (96.7742)  Acc@5: 100.0000 (99.3952)  time: 0.2339  data: 0.0021  max mem: 2502
Test: [Task 3]  [350/625]  eta: 0:01:02  Loss: 0.1448 (0.1984)  Acc@1: 93.7500 (96.7415)  Acc@5: 100.0000 (99.3946)  time: 0.2269  data: 0.0010  max mem: 2502
Test: [Task 3]  [360/625]  eta: 0:00:59  Loss: 0.1640 (0.1992)  Acc@1: 93.7500 (96.7105)  Acc@5: 100.0000 (99.3940)  time: 0.2175  data: 0.0009  max mem: 2502
Test: [Task 3]  [370/625]  eta: 0:00:57  Loss: 0.2284 (0.1998)  Acc@1: 93.7500 (96.6813)  Acc@5: 100.0000 (99.4104)  time: 0.2221  data: 0.0003  max mem: 2502
Test: [Task 3]  [380/625]  eta: 0:00:55  Loss: 0.1997 (0.1983)  Acc@1: 100.0000 (96.7192)  Acc@5: 100.0000 (99.4259)  time: 0.2272  data: 0.0004  max mem: 2502
Test: [Task 3]  [390/625]  eta: 0:00:53  Loss: 0.1386 (0.1981)  Acc@1: 100.0000 (96.7231)  Acc@5: 100.0000 (99.4405)  time: 0.2284  data: 0.0004  max mem: 2502
Test: [Task 3]  [400/625]  eta: 0:00:50  Loss: 0.1147 (0.1974)  Acc@1: 93.7500 (96.6958)  Acc@5: 100.0000 (99.4389)  time: 0.2221  data: 0.0005  max mem: 2502
Test: [Task 3]  [410/625]  eta: 0:00:48  Loss: 0.1693 (0.1986)  Acc@1: 93.7500 (96.7001)  Acc@5: 100.0000 (99.4069)  time: 0.2203  data: 0.0005  max mem: 2502
Test: [Task 3]  [420/625]  eta: 0:00:46  Loss: 0.1868 (0.1989)  Acc@1: 100.0000 (96.6746)  Acc@5: 100.0000 (99.4062)  time: 0.2235  data: 0.0005  max mem: 2502
Test: [Task 3]  [430/625]  eta: 0:00:44  Loss: 0.1501 (0.1985)  Acc@1: 100.0000 (96.6937)  Acc@5: 100.0000 (99.4055)  time: 0.2294  data: 0.0012  max mem: 2502
Test: [Task 3]  [440/625]  eta: 0:00:41  Loss: 0.1501 (0.1999)  Acc@1: 100.0000 (96.6553)  Acc@5: 100.0000 (99.4048)  time: 0.2271  data: 0.0019  max mem: 2502
Test: [Task 3]  [450/625]  eta: 0:00:39  Loss: 0.1529 (0.2000)  Acc@1: 100.0000 (96.6602)  Acc@5: 100.0000 (99.4041)  time: 0.2198  data: 0.0024  max mem: 2502
Test: [Task 3]  [460/625]  eta: 0:00:37  Loss: 0.1363 (0.1995)  Acc@1: 100.0000 (96.6920)  Acc@5: 100.0000 (99.4035)  time: 0.2242  data: 0.0031  max mem: 2502
Test: [Task 3]  [470/625]  eta: 0:00:34  Loss: 0.1544 (0.1995)  Acc@1: 100.0000 (96.6826)  Acc@5: 100.0000 (99.4029)  time: 0.2271  data: 0.0024  max mem: 2502
Test: [Task 3]  [480/625]  eta: 0:00:32  Loss: 0.1950 (0.2007)  Acc@1: 100.0000 (96.6736)  Acc@5: 100.0000 (99.4023)  time: 0.2341  data: 0.0017  max mem: 2502
Test: [Task 3]  [490/625]  eta: 0:00:30  Loss: 0.1785 (0.2012)  Acc@1: 100.0000 (96.6650)  Acc@5: 100.0000 (99.3890)  time: 0.2366  data: 0.0051  max mem: 2502
Test: [Task 3]  [500/625]  eta: 0:00:28  Loss: 0.1156 (0.2004)  Acc@1: 100.0000 (96.6941)  Acc@5: 100.0000 (99.3887)  time: 0.2318  data: 0.0103  max mem: 2502
Test: [Task 3]  [510/625]  eta: 0:00:26  Loss: 0.1075 (0.1996)  Acc@1: 100.0000 (96.7099)  Acc@5: 100.0000 (99.4007)  time: 0.2336  data: 0.0084  max mem: 2502
Test: [Task 3]  [520/625]  eta: 0:00:23  Loss: 0.1489 (0.1999)  Acc@1: 100.0000 (96.6771)  Acc@5: 100.0000 (99.4122)  time: 0.2414  data: 0.0057  max mem: 2502
Test: [Task 3]  [530/625]  eta: 0:00:21  Loss: 0.1919 (0.2006)  Acc@1: 93.7500 (96.6573)  Acc@5: 100.0000 (99.4115)  time: 0.2329  data: 0.0047  max mem: 2502
Test: [Task 3]  [540/625]  eta: 0:00:19  Loss: 0.1879 (0.2012)  Acc@1: 93.7500 (96.6613)  Acc@5: 100.0000 (99.4108)  time: 0.2197  data: 0.0014  max mem: 2502
Test: [Task 3]  [550/625]  eta: 0:00:16  Loss: 0.2030 (0.2020)  Acc@1: 93.7500 (96.6311)  Acc@5: 100.0000 (99.4102)  time: 0.2213  data: 0.0004  max mem: 2502
Test: [Task 3]  [560/625]  eta: 0:00:14  Loss: 0.1737 (0.2018)  Acc@1: 100.0000 (96.6578)  Acc@5: 100.0000 (99.4207)  time: 0.2293  data: 0.0009  max mem: 2502
Test: [Task 3]  [570/625]  eta: 0:00:12  Loss: 0.1590 (0.2014)  Acc@1: 100.0000 (96.6506)  Acc@5: 100.0000 (99.4199)  time: 0.2277  data: 0.0009  max mem: 2502
Test: [Task 3]  [580/625]  eta: 0:00:10  Loss: 0.2118 (0.2034)  Acc@1: 93.7500 (96.5899)  Acc@5: 100.0000 (99.4083)  time: 0.2167  data: 0.0005  max mem: 2502
Test: [Task 3]  [590/625]  eta: 0:00:07  Loss: 0.1531 (0.2025)  Acc@1: 100.0000 (96.6265)  Acc@5: 100.0000 (99.4184)  time: 0.2187  data: 0.0005  max mem: 2502
Test: [Task 3]  [600/625]  eta: 0:00:05  Loss: 0.1531 (0.2026)  Acc@1: 100.0000 (96.5786)  Acc@5: 100.0000 (99.4072)  time: 0.2228  data: 0.0004  max mem: 2502
Test: [Task 3]  [610/625]  eta: 0:00:03  Loss: 0.1799 (0.2020)  Acc@1: 93.7500 (96.5835)  Acc@5: 100.0000 (99.4169)  time: 0.2313  data: 0.0008  max mem: 2502
Test: [Task 3]  [620/625]  eta: 0:00:01  Loss: 0.2004 (0.2029)  Acc@1: 93.7500 (96.5378)  Acc@5: 100.0000 (99.4163)  time: 0.2286  data: 0.0009  max mem: 2502
Test: [Task 3]  [624/625]  eta: 0:00:00  Loss: 0.1743 (0.2022)  Acc@1: 100.0000 (96.5600)  Acc@5: 100.0000 (99.4200)  time: 0.2261  data: 0.0005  max mem: 2502
Test: [Task 3] Total time: 0:02:21 (0.2267 s / it)
* Acc@1 96.560 Acc@5 99.420 loss 0.202
Test: [Task 4]  [ 0/29]  eta: 0:00:23  Loss: 1.4893 (1.4893)  Acc@1: 43.7500 (43.7500)  Acc@5: 93.7500 (93.7500)  time: 0.8235  data: 0.6088  max mem: 2502
Test: [Task 4]  [10/29]  eta: 0:00:05  Loss: 1.5468 (1.3739)  Acc@1: 56.2500 (60.7955)  Acc@5: 87.5000 (89.7727)  time: 0.2765  data: 0.0556  max mem: 2502
Test: [Task 4]  [20/29]  eta: 0:00:02  Loss: 1.5071 (1.3757)  Acc@1: 68.7500 (63.3929)  Acc@5: 87.5000 (87.5000)  time: 0.2231  data: 0.0004  max mem: 2502
Test: [Task 4]  [28/29]  eta: 0:00:00  Loss: 1.3405 (1.3037)  Acc@1: 68.7500 (66.0131)  Acc@5: 87.5000 (88.2353)  time: 0.2326  data: 0.0004  max mem: 2502
Test: [Task 4] Total time: 0:00:07 (0.2612 s / it)
* Acc@1 66.013 Acc@5 88.235 loss 1.304
{0: {0: 26032, 1: 26032, 2: 26032, 3: 26032, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0, 10: 0, 11: 0, 12: 0, 13: 0, 14: 0, 15: 0, 16: 0, 17: 0, 18: 0, 19: 0}, 1: {0: 0, 1: 0, 2: 0, 3: 0, 4: 10000, 5: 10000, 6: 10000, 7: 10000, 8: 0, 9: 0, 10: 0, 11: 0, 12: 0, 13: 0, 14: 0, 15: 0, 16: 0, 17: 0, 18: 0, 19: 0}, 2: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 10000, 9: 10000, 10: 10000, 11: 10000, 12: 0, 13: 0, 14: 0, 15: 0, 16: 0, 17: 0, 18: 0, 19: 0}, 3: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0, 10: 0, 11: 0, 12: 459, 13: 459, 14: 459, 15: 459, 16: 0, 17: 0, 18: 0, 19: 0}}
[Average accuracy till task4]	Acc@1: 79.8474	Acc@5: 94.7547	Loss: 0.8060	Forgetting: 7.0708	Backward: -7.0708
Transfering parameters  (slice(16, 20, None), slice(12, 16, None))
Train: Epoch[1/5]  [   0/3750]  eta: 1:17:56  Lr: 0.001875  Loss: 1.2163  Acc@1: 6.2500 (6.2500)  Acc@5: 31.2500 (31.2500)  time: 1.2471  data: 0.8761  max mem: 2502
Train: Epoch[1/5]  [  10/3750]  eta: 0:26:51  Lr: 0.001875  Loss: 0.9834  Acc@1: 18.7500 (25.0000)  Acc@5: 75.0000 (69.8864)  time: 0.4310  data: 0.0815  max mem: 2503
Train: Epoch[1/5]  [  20/3750]  eta: 0:24:34  Lr: 0.001875  Loss: 0.9097  Acc@1: 37.5000 (35.1190)  Acc@5: 87.5000 (80.6548)  time: 0.3529  data: 0.0020  max mem: 2503
Train: Epoch[1/5]  [  30/3750]  eta: 0:23:59  Lr: 0.001875  Loss: 0.7656  Acc@1: 43.7500 (39.9194)  Acc@5: 93.7500 (85.0806)  time: 0.3627  data: 0.0030  max mem: 2503
Train: Epoch[1/5]  [  40/3750]  eta: 0:23:20  Lr: 0.001875  Loss: 0.4021  Acc@1: 50.0000 (43.5976)  Acc@5: 93.7500 (87.0427)  time: 0.3584  data: 0.0022  max mem: 2503
Train: Epoch[1/5]  [  50/3750]  eta: 0:23:02  Lr: 0.001875  Loss: -0.0574  Acc@1: 56.2500 (48.2843)  Acc@5: 93.7500 (89.0931)  time: 0.3532  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [  60/3750]  eta: 0:22:54  Lr: 0.001875  Loss: -0.0662  Acc@1: 68.7500 (52.5615)  Acc@5: 100.0000 (90.4713)  time: 0.3624  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [  70/3750]  eta: 0:22:37  Lr: 0.001875  Loss: 0.1930  Acc@1: 75.0000 (54.6655)  Acc@5: 100.0000 (91.5493)  time: 0.3570  data: 0.0006  max mem: 2503
Train: Epoch[1/5]  [  80/3750]  eta: 0:22:29  Lr: 0.001875  Loss: -0.2349  Acc@1: 68.7500 (56.4043)  Acc@5: 100.0000 (92.1296)  time: 0.3531  data: 0.0007  max mem: 2503
Train: Epoch[1/5]  [  90/3750]  eta: 0:22:24  Lr: 0.001875  Loss: 0.0202  Acc@1: 68.7500 (57.1429)  Acc@5: 93.7500 (92.5824)  time: 0.3616  data: 0.0015  max mem: 2503
Train: Epoch[1/5]  [ 100/3750]  eta: 0:22:21  Lr: 0.001875  Loss: 0.0175  Acc@1: 68.7500 (58.1064)  Acc@5: 100.0000 (93.0693)  time: 0.3664  data: 0.0016  max mem: 2503
Train: Epoch[1/5]  [ 110/3750]  eta: 0:22:10  Lr: 0.001875  Loss: -0.1972  Acc@1: 68.7500 (58.7275)  Acc@5: 100.0000 (93.6374)  time: 0.3575  data: 0.0009  max mem: 2503
Train: Epoch[1/5]  [ 120/3750]  eta: 0:22:05  Lr: 0.001875  Loss: -0.2576  Acc@1: 68.7500 (59.9174)  Acc@5: 100.0000 (94.0599)  time: 0.3533  data: 0.0007  max mem: 2503
Train: Epoch[1/5]  [ 130/3750]  eta: 0:22:01  Lr: 0.001875  Loss: -0.1715  Acc@1: 68.7500 (60.6870)  Acc@5: 100.0000 (94.3225)  time: 0.3618  data: 0.0006  max mem: 2503
Train: Epoch[1/5]  [ 140/3750]  eta: 0:21:53  Lr: 0.001875  Loss: -0.2802  Acc@1: 75.0000 (61.4805)  Acc@5: 100.0000 (94.5922)  time: 0.3571  data: 0.0007  max mem: 2503
Train: Epoch[1/5]  [ 150/3750]  eta: 0:21:49  Lr: 0.001875  Loss: -0.6152  Acc@1: 68.7500 (62.0033)  Acc@5: 100.0000 (94.7434)  time: 0.3547  data: 0.0006  max mem: 2503
Train: Epoch[1/5]  [ 160/3750]  eta: 0:21:45  Lr: 0.001875  Loss: -0.2253  Acc@1: 62.5000 (62.3059)  Acc@5: 100.0000 (94.9146)  time: 0.3607  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [ 170/3750]  eta: 0:21:39  Lr: 0.001875  Loss: -0.0421  Acc@1: 75.0000 (63.1579)  Acc@5: 100.0000 (95.0658)  time: 0.3579  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [ 180/3750]  eta: 0:21:37  Lr: 0.001875  Loss: -0.2085  Acc@1: 75.0000 (63.8122)  Acc@5: 100.0000 (95.2693)  time: 0.3614  data: 0.0013  max mem: 2503
Train: Epoch[1/5]  [ 190/3750]  eta: 0:21:33  Lr: 0.001875  Loss: -0.4931  Acc@1: 75.0000 (64.2670)  Acc@5: 100.0000 (95.3861)  time: 0.3678  data: 0.0020  max mem: 2503
Train: Epoch[1/5]  [ 200/3750]  eta: 0:21:27  Lr: 0.001875  Loss: -0.2902  Acc@1: 75.0000 (64.9254)  Acc@5: 100.0000 (95.5846)  time: 0.3578  data: 0.0013  max mem: 2503
Train: Epoch[1/5]  [ 210/3750]  eta: 0:21:23  Lr: 0.001875  Loss: -0.2185  Acc@1: 75.0000 (65.1659)  Acc@5: 100.0000 (95.7346)  time: 0.3533  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [ 220/3750]  eta: 0:21:19  Lr: 0.001875  Loss: -0.2405  Acc@1: 68.7500 (65.2432)  Acc@5: 100.0000 (95.8710)  time: 0.3607  data: 0.0012  max mem: 2503
Train: Epoch[1/5]  [ 230/3750]  eta: 0:21:14  Lr: 0.001875  Loss: -0.0735  Acc@1: 62.5000 (65.3139)  Acc@5: 100.0000 (95.9145)  time: 0.3572  data: 0.0013  max mem: 2503
Train: Epoch[1/5]  [ 240/3750]  eta: 0:21:10  Lr: 0.001875  Loss: -0.4047  Acc@1: 68.7500 (65.6120)  Acc@5: 100.0000 (96.0581)  time: 0.3553  data: 0.0006  max mem: 2503
Train: Epoch[1/5]  [ 250/3750]  eta: 0:21:07  Lr: 0.001875  Loss: -0.5613  Acc@1: 68.7500 (65.9612)  Acc@5: 100.0000 (96.1155)  time: 0.3632  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [ 260/3750]  eta: 0:21:02  Lr: 0.001875  Loss: -0.3787  Acc@1: 75.0000 (66.3314)  Acc@5: 100.0000 (96.1446)  time: 0.3595  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [ 270/3750]  eta: 0:21:00  Lr: 0.001875  Loss: -0.1252  Acc@1: 75.0000 (66.5590)  Acc@5: 93.7500 (96.1485)  time: 0.3627  data: 0.0006  max mem: 2503
Train: Epoch[1/5]  [ 280/3750]  eta: 0:20:55  Lr: 0.001875  Loss: 0.1675  Acc@1: 75.0000 (66.8594)  Acc@5: 100.0000 (96.2189)  time: 0.3620  data: 0.0007  max mem: 2503
Train: Epoch[1/5]  [ 290/3750]  eta: 0:20:52  Lr: 0.001875  Loss: -0.5153  Acc@1: 75.0000 (67.1392)  Acc@5: 100.0000 (96.2629)  time: 0.3577  data: 0.0006  max mem: 2503
Train: Epoch[1/5]  [ 300/3750]  eta: 0:20:47  Lr: 0.001875  Loss: -0.0259  Acc@1: 75.0000 (67.3173)  Acc@5: 100.0000 (96.3040)  time: 0.3592  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [ 310/3750]  eta: 0:20:43  Lr: 0.001875  Loss: 0.2407  Acc@1: 75.0000 (67.5241)  Acc@5: 100.0000 (96.3826)  time: 0.3567  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [ 320/3750]  eta: 0:20:40  Lr: 0.001875  Loss: -0.4064  Acc@1: 75.0000 (67.7960)  Acc@5: 100.0000 (96.4369)  time: 0.3600  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [ 330/3750]  eta: 0:20:35  Lr: 0.001875  Loss: 0.1037  Acc@1: 75.0000 (67.8625)  Acc@5: 100.0000 (96.4690)  time: 0.3561  data: 0.0007  max mem: 2503
Train: Epoch[1/5]  [ 340/3750]  eta: 0:20:32  Lr: 0.001875  Loss: -0.3704  Acc@1: 68.7500 (67.7603)  Acc@5: 100.0000 (96.4993)  time: 0.3582  data: 0.0007  max mem: 2503
Train: Epoch[1/5]  [ 350/3750]  eta: 0:20:27  Lr: 0.001875  Loss: -0.4025  Acc@1: 68.7500 (67.8419)  Acc@5: 100.0000 (96.5634)  time: 0.3596  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [ 360/3750]  eta: 0:20:23  Lr: 0.001875  Loss: -0.3818  Acc@1: 75.0000 (68.0055)  Acc@5: 100.0000 (96.5201)  time: 0.3530  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [ 370/3750]  eta: 0:20:19  Lr: 0.001875  Loss: -0.6361  Acc@1: 81.2500 (68.1941)  Acc@5: 100.0000 (96.5802)  time: 0.3551  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [ 380/3750]  eta: 0:20:15  Lr: 0.001875  Loss: -0.3737  Acc@1: 68.7500 (68.1594)  Acc@5: 100.0000 (96.6535)  time: 0.3592  data: 0.0009  max mem: 2503
Train: Epoch[1/5]  [ 390/3750]  eta: 0:20:12  Lr: 0.001875  Loss: -0.0990  Acc@1: 68.7500 (68.3344)  Acc@5: 100.0000 (96.7072)  time: 0.3640  data: 0.0014  max mem: 2503
Train: Epoch[1/5]  [ 400/3750]  eta: 0:20:08  Lr: 0.001875  Loss: 0.1277  Acc@1: 75.0000 (68.4850)  Acc@5: 100.0000 (96.7113)  time: 0.3598  data: 0.0009  max mem: 2503
Train: Epoch[1/5]  [ 410/3750]  eta: 0:20:04  Lr: 0.001875  Loss: -0.4299  Acc@1: 75.0000 (68.7044)  Acc@5: 100.0000 (96.7914)  time: 0.3568  data: 0.0006  max mem: 2503
Train: Epoch[1/5]  [ 420/3750]  eta: 0:20:01  Lr: 0.001875  Loss: -0.3418  Acc@1: 75.0000 (68.8391)  Acc@5: 100.0000 (96.8082)  time: 0.3626  data: 0.0007  max mem: 2503
Train: Epoch[1/5]  [ 430/3750]  eta: 0:19:57  Lr: 0.001875  Loss: -0.0904  Acc@1: 68.7500 (68.8515)  Acc@5: 100.0000 (96.8242)  time: 0.3585  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [ 440/3750]  eta: 0:19:53  Lr: 0.001875  Loss: -0.0832  Acc@1: 68.7500 (68.9626)  Acc@5: 100.0000 (96.8821)  time: 0.3564  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [ 450/3750]  eta: 0:19:50  Lr: 0.001875  Loss: -0.7268  Acc@1: 75.0000 (69.2489)  Acc@5: 100.0000 (96.9374)  time: 0.3630  data: 0.0007  max mem: 2503
Train: Epoch[1/5]  [ 460/3750]  eta: 0:19:46  Lr: 0.001875  Loss: -0.4992  Acc@1: 75.0000 (69.3465)  Acc@5: 100.0000 (96.9631)  time: 0.3596  data: 0.0007  max mem: 2503
Train: Epoch[1/5]  [ 470/3750]  eta: 0:19:42  Lr: 0.001875  Loss: -0.2060  Acc@1: 75.0000 (69.5196)  Acc@5: 100.0000 (97.0011)  time: 0.3579  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [ 480/3750]  eta: 0:19:39  Lr: 0.001875  Loss: -0.3270  Acc@1: 75.0000 (69.6336)  Acc@5: 100.0000 (97.0504)  time: 0.3629  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [ 490/3750]  eta: 0:19:36  Lr: 0.001875  Loss: -0.1954  Acc@1: 75.0000 (69.7047)  Acc@5: 100.0000 (97.0978)  time: 0.3658  data: 0.0007  max mem: 2503
Train: Epoch[1/5]  [ 500/3750]  eta: 0:19:32  Lr: 0.001875  Loss: -0.5780  Acc@1: 75.0000 (69.8852)  Acc@5: 100.0000 (97.1058)  time: 0.3619  data: 0.0008  max mem: 2503
Train: Epoch[1/5]  [ 510/3750]  eta: 0:19:28  Lr: 0.001875  Loss: -0.9321  Acc@1: 75.0000 (69.9242)  Acc@5: 100.0000 (97.1135)  time: 0.3591  data: 0.0012  max mem: 2503
Train: Epoch[1/5]  [ 520/3750]  eta: 0:19:24  Lr: 0.001875  Loss: -0.6805  Acc@1: 75.0000 (70.0696)  Acc@5: 100.0000 (97.1329)  time: 0.3582  data: 0.0011  max mem: 2503
Train: Epoch[1/5]  [ 530/3750]  eta: 0:19:20  Lr: 0.001875  Loss: -0.3380  Acc@1: 75.0000 (70.0447)  Acc@5: 100.0000 (97.1751)  time: 0.3534  data: 0.0006  max mem: 2503
Train: Epoch[1/5]  [ 540/3750]  eta: 0:19:17  Lr: 0.001875  Loss: -0.2667  Acc@1: 68.7500 (70.1363)  Acc@5: 100.0000 (97.1927)  time: 0.3615  data: 0.0007  max mem: 2503
Train: Epoch[1/5]  [ 550/3750]  eta: 0:19:13  Lr: 0.001875  Loss: -0.4899  Acc@1: 75.0000 (70.2246)  Acc@5: 100.0000 (97.2096)  time: 0.3581  data: 0.0008  max mem: 2503
Train: Epoch[1/5]  [ 560/3750]  eta: 0:19:09  Lr: 0.001875  Loss: -0.1017  Acc@1: 75.0000 (70.2763)  Acc@5: 100.0000 (97.2259)  time: 0.3513  data: 0.0008  max mem: 2503
Train: Epoch[1/5]  [ 570/3750]  eta: 0:19:06  Lr: 0.001875  Loss: -0.2609  Acc@1: 75.0000 (70.3152)  Acc@5: 100.0000 (97.2526)  time: 0.3638  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [ 580/3750]  eta: 0:19:03  Lr: 0.001875  Loss: -0.3127  Acc@1: 75.0000 (70.4927)  Acc@5: 100.0000 (97.2676)  time: 0.3685  data: 0.0010  max mem: 2503
Train: Epoch[1/5]  [ 590/3750]  eta: 0:18:58  Lr: 0.001875  Loss: -0.5385  Acc@1: 75.0000 (70.6218)  Acc@5: 100.0000 (97.2821)  time: 0.3567  data: 0.0010  max mem: 2503
Train: Epoch[1/5]  [ 600/3750]  eta: 0:18:54  Lr: 0.001875  Loss: -0.3699  Acc@1: 75.0000 (70.7779)  Acc@5: 100.0000 (97.3274)  time: 0.3510  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [ 610/3750]  eta: 0:18:51  Lr: 0.001875  Loss: -0.1516  Acc@1: 75.0000 (70.8777)  Acc@5: 100.0000 (97.3097)  time: 0.3597  data: 0.0006  max mem: 2503
Train: Epoch[1/5]  [ 620/3750]  eta: 0:18:47  Lr: 0.001875  Loss: -0.3600  Acc@1: 75.0000 (70.9239)  Acc@5: 100.0000 (97.3229)  time: 0.3615  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [ 630/3750]  eta: 0:18:43  Lr: 0.001875  Loss: -0.5432  Acc@1: 75.0000 (70.9687)  Acc@5: 100.0000 (97.3257)  time: 0.3560  data: 0.0006  max mem: 2503
Train: Epoch[1/5]  [ 640/3750]  eta: 0:18:40  Lr: 0.001875  Loss: -0.4383  Acc@1: 75.0000 (71.0218)  Acc@5: 100.0000 (97.3479)  time: 0.3620  data: 0.0006  max mem: 2503
Train: Epoch[1/5]  [ 650/3750]  eta: 0:18:36  Lr: 0.001875  Loss: -0.2771  Acc@1: 75.0000 (71.0637)  Acc@5: 100.0000 (97.3694)  time: 0.3606  data: 0.0006  max mem: 2503
Train: Epoch[1/5]  [ 660/3750]  eta: 0:18:32  Lr: 0.001875  Loss: 0.0457  Acc@1: 75.0000 (71.0666)  Acc@5: 100.0000 (97.3903)  time: 0.3529  data: 0.0007  max mem: 2503
Train: Epoch[1/5]  [ 670/3750]  eta: 0:18:29  Lr: 0.001875  Loss: -0.3027  Acc@1: 68.7500 (71.0600)  Acc@5: 100.0000 (97.4013)  time: 0.3629  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [ 680/3750]  eta: 0:18:26  Lr: 0.001875  Loss: -0.5108  Acc@1: 68.7500 (71.1362)  Acc@5: 100.0000 (97.4211)  time: 0.3691  data: 0.0006  max mem: 2503
Train: Epoch[1/5]  [ 690/3750]  eta: 0:18:22  Lr: 0.001875  Loss: -0.4245  Acc@1: 81.2500 (71.2102)  Acc@5: 100.0000 (97.4403)  time: 0.3569  data: 0.0006  max mem: 2503
Train: Epoch[1/5]  [ 700/3750]  eta: 0:18:18  Lr: 0.001875  Loss: -0.0445  Acc@1: 81.2500 (71.3178)  Acc@5: 100.0000 (97.4055)  time: 0.3511  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [ 710/3750]  eta: 0:18:15  Lr: 0.001875  Loss: 0.0443  Acc@1: 81.2500 (71.4135)  Acc@5: 93.7500 (97.4156)  time: 0.3615  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [ 720/3750]  eta: 0:18:11  Lr: 0.001875  Loss: -0.6859  Acc@1: 75.0000 (71.4286)  Acc@5: 100.0000 (97.4515)  time: 0.3583  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [ 730/3750]  eta: 0:18:07  Lr: 0.001875  Loss: -0.5039  Acc@1: 75.0000 (71.4945)  Acc@5: 100.0000 (97.4607)  time: 0.3526  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [ 740/3750]  eta: 0:18:03  Lr: 0.001875  Loss: -0.6654  Acc@1: 75.0000 (71.5756)  Acc@5: 100.0000 (97.4865)  time: 0.3597  data: 0.0006  max mem: 2503
Train: Epoch[1/5]  [ 750/3750]  eta: 0:17:59  Lr: 0.001875  Loss: 0.1309  Acc@1: 75.0000 (71.5962)  Acc@5: 100.0000 (97.4700)  time: 0.3566  data: 0.0007  max mem: 2503
Train: Epoch[1/5]  [ 760/3750]  eta: 0:17:56  Lr: 0.001875  Loss: -0.3749  Acc@1: 75.0000 (71.7066)  Acc@5: 100.0000 (97.4951)  time: 0.3553  data: 0.0007  max mem: 2503
Train: Epoch[1/5]  [ 770/3750]  eta: 0:17:52  Lr: 0.001875  Loss: -0.8141  Acc@1: 81.2500 (71.8142)  Acc@5: 100.0000 (97.5113)  time: 0.3624  data: 0.0010  max mem: 2503
Train: Epoch[1/5]  [ 780/3750]  eta: 0:17:49  Lr: 0.001875  Loss: -0.5147  Acc@1: 75.0000 (71.8230)  Acc@5: 100.0000 (97.5192)  time: 0.3662  data: 0.0011  max mem: 2503
Train: Epoch[1/5]  [ 790/3750]  eta: 0:17:45  Lr: 0.001875  Loss: -0.0289  Acc@1: 75.0000 (71.8157)  Acc@5: 100.0000 (97.5348)  time: 0.3608  data: 0.0009  max mem: 2503
Train: Epoch[1/5]  [ 800/3750]  eta: 0:17:42  Lr: 0.001875  Loss: -0.6010  Acc@1: 75.0000 (71.8633)  Acc@5: 100.0000 (97.5421)  time: 0.3617  data: 0.0006  max mem: 2503
Train: Epoch[1/5]  [ 810/3750]  eta: 0:17:38  Lr: 0.001875  Loss: -0.0977  Acc@1: 68.7500 (71.8557)  Acc@5: 100.0000 (97.5493)  time: 0.3659  data: 0.0006  max mem: 2503
Train: Epoch[1/5]  [ 820/3750]  eta: 0:17:38  Lr: 0.001875  Loss: -0.6702  Acc@1: 75.0000 (71.9397)  Acc@5: 100.0000 (97.5639)  time: 0.4108  data: 0.0006  max mem: 2503
Train: Epoch[1/5]  [ 830/3750]  eta: 0:17:42  Lr: 0.001875  Loss: -0.4040  Acc@1: 81.2500 (72.0217)  Acc@5: 100.0000 (97.5782)  time: 0.5063  data: 0.0006  max mem: 2503
Train: Epoch[1/5]  [ 840/3750]  eta: 0:17:43  Lr: 0.001875  Loss: -0.3896  Acc@1: 75.0000 (72.0422)  Acc@5: 100.0000 (97.5773)  time: 0.5331  data: 0.0006  max mem: 2503
Train: Epoch[1/5]  [ 850/3750]  eta: 0:17:45  Lr: 0.001875  Loss: -0.5913  Acc@1: 75.0000 (72.0917)  Acc@5: 100.0000 (97.5837)  time: 0.5258  data: 0.0009  max mem: 2503
Train: Epoch[1/5]  [ 860/3750]  eta: 0:17:46  Lr: 0.001875  Loss: -0.1896  Acc@1: 75.0000 (72.1400)  Acc@5: 100.0000 (97.5900)  time: 0.5235  data: 0.0009  max mem: 2503
Train: Epoch[1/5]  [ 870/3750]  eta: 0:17:48  Lr: 0.001875  Loss: -0.3924  Acc@1: 75.0000 (72.1513)  Acc@5: 100.0000 (97.5962)  time: 0.5163  data: 0.0006  max mem: 2503
Train: Epoch[1/5]  [ 880/3750]  eta: 0:17:49  Lr: 0.001875  Loss: -0.3788  Acc@1: 75.0000 (72.1268)  Acc@5: 100.0000 (97.6022)  time: 0.5303  data: 0.0006  max mem: 2503
Train: Epoch[1/5]  [ 890/3750]  eta: 0:17:48  Lr: 0.001875  Loss: -0.1833  Acc@1: 75.0000 (72.1591)  Acc@5: 100.0000 (97.6080)  time: 0.4891  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [ 900/3750]  eta: 0:17:44  Lr: 0.001875  Loss: -0.6554  Acc@1: 75.0000 (72.2322)  Acc@5: 100.0000 (97.5999)  time: 0.4074  data: 0.0007  max mem: 2503
Train: Epoch[1/5]  [ 910/3750]  eta: 0:17:40  Lr: 0.001875  Loss: -0.7054  Acc@1: 75.0000 (72.2626)  Acc@5: 100.0000 (97.6194)  time: 0.3609  data: 0.0010  max mem: 2503
Train: Epoch[1/5]  [ 920/3750]  eta: 0:17:35  Lr: 0.001875  Loss: -0.2527  Acc@1: 75.0000 (72.2991)  Acc@5: 100.0000 (97.6384)  time: 0.3497  data: 0.0009  max mem: 2503
Train: Epoch[1/5]  [ 930/3750]  eta: 0:17:31  Lr: 0.001875  Loss: -0.3554  Acc@1: 75.0000 (72.3751)  Acc@5: 100.0000 (97.6437)  time: 0.3573  data: 0.0014  max mem: 2503
Train: Epoch[1/5]  [ 940/3750]  eta: 0:17:27  Lr: 0.001875  Loss: -0.7685  Acc@1: 75.0000 (72.4163)  Acc@5: 100.0000 (97.6621)  time: 0.3673  data: 0.0034  max mem: 2503
Train: Epoch[1/5]  [ 950/3750]  eta: 0:17:24  Lr: 0.001875  Loss: -0.2246  Acc@1: 75.0000 (72.4632)  Acc@5: 100.0000 (97.6801)  time: 0.3739  data: 0.0046  max mem: 2503
Train: Epoch[1/5]  [ 960/3750]  eta: 0:17:20  Lr: 0.001875  Loss: -0.0266  Acc@1: 81.2500 (72.5351)  Acc@5: 100.0000 (97.7042)  time: 0.3728  data: 0.0030  max mem: 2503
Train: Epoch[1/5]  [ 970/3750]  eta: 0:17:16  Lr: 0.001875  Loss: -0.7910  Acc@1: 75.0000 (72.5863)  Acc@5: 100.0000 (97.7085)  time: 0.3671  data: 0.0019  max mem: 2503
Train: Epoch[1/5]  [ 980/3750]  eta: 0:17:12  Lr: 0.001875  Loss: -0.7190  Acc@1: 75.0000 (72.6300)  Acc@5: 100.0000 (97.7192)  time: 0.3704  data: 0.0032  max mem: 2503
Train: Epoch[1/5]  [ 990/3750]  eta: 0:17:09  Lr: 0.001875  Loss: -0.5329  Acc@1: 81.2500 (72.7170)  Acc@5: 100.0000 (97.7422)  time: 0.3723  data: 0.0031  max mem: 2503
Train: Epoch[1/5]  [1000/3750]  eta: 0:17:04  Lr: 0.001875  Loss: -0.6734  Acc@1: 81.2500 (72.7960)  Acc@5: 100.0000 (97.7585)  time: 0.3620  data: 0.0013  max mem: 2503
Train: Epoch[1/5]  [1010/3750]  eta: 0:17:00  Lr: 0.001875  Loss: -0.6147  Acc@1: 75.0000 (72.8363)  Acc@5: 100.0000 (97.7807)  time: 0.3556  data: 0.0010  max mem: 2503
Train: Epoch[1/5]  [1020/3750]  eta: 0:16:56  Lr: 0.001875  Loss: -0.7906  Acc@1: 75.0000 (72.8575)  Acc@5: 100.0000 (97.7902)  time: 0.3651  data: 0.0009  max mem: 2503
Train: Epoch[1/5]  [1030/3750]  eta: 0:16:52  Lr: 0.001875  Loss: -0.7307  Acc@1: 75.0000 (72.8540)  Acc@5: 100.0000 (97.7995)  time: 0.3602  data: 0.0013  max mem: 2503
Train: Epoch[1/5]  [1040/3750]  eta: 0:16:48  Lr: 0.001875  Loss: -0.4206  Acc@1: 75.0000 (72.8746)  Acc@5: 100.0000 (97.7966)  time: 0.3521  data: 0.0016  max mem: 2503
Train: Epoch[1/5]  [1050/3750]  eta: 0:16:44  Lr: 0.001875  Loss: -0.5333  Acc@1: 75.0000 (72.8830)  Acc@5: 100.0000 (97.8116)  time: 0.3647  data: 0.0008  max mem: 2503
Train: Epoch[1/5]  [1060/3750]  eta: 0:16:40  Lr: 0.001875  Loss: -0.6692  Acc@1: 75.0000 (72.9383)  Acc@5: 100.0000 (97.8322)  time: 0.3700  data: 0.0006  max mem: 2503
Train: Epoch[1/5]  [1070/3750]  eta: 0:16:36  Lr: 0.001875  Loss: -0.4408  Acc@1: 81.2500 (73.0217)  Acc@5: 100.0000 (97.8466)  time: 0.3558  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [1080/3750]  eta: 0:16:32  Lr: 0.001875  Loss: -0.4373  Acc@1: 81.2500 (73.0516)  Acc@5: 100.0000 (97.8492)  time: 0.3515  data: 0.0016  max mem: 2503
Train: Epoch[1/5]  [1090/3750]  eta: 0:16:28  Lr: 0.001875  Loss: 0.0773  Acc@1: 81.2500 (73.1324)  Acc@5: 100.0000 (97.8689)  time: 0.3572  data: 0.0017  max mem: 2503
Train: Epoch[1/5]  [1100/3750]  eta: 0:16:24  Lr: 0.001875  Loss: -0.6227  Acc@1: 81.2500 (73.1551)  Acc@5: 100.0000 (97.8826)  time: 0.3582  data: 0.0012  max mem: 2503
Train: Epoch[1/5]  [1110/3750]  eta: 0:16:20  Lr: 0.001875  Loss: -0.7768  Acc@1: 75.0000 (73.1998)  Acc@5: 100.0000 (97.8904)  time: 0.3532  data: 0.0010  max mem: 2503
Train: Epoch[1/5]  [1120/3750]  eta: 0:16:16  Lr: 0.001875  Loss: -0.4778  Acc@1: 81.2500 (73.2438)  Acc@5: 100.0000 (97.8814)  time: 0.3567  data: 0.0010  max mem: 2503
Train: Epoch[1/5]  [1130/3750]  eta: 0:16:12  Lr: 0.001875  Loss: -0.4145  Acc@1: 75.0000 (73.2427)  Acc@5: 100.0000 (97.8890)  time: 0.3712  data: 0.0038  max mem: 2503
Train: Epoch[1/5]  [1140/3750]  eta: 0:16:08  Lr: 0.001875  Loss: -0.5371  Acc@1: 75.0000 (73.2691)  Acc@5: 100.0000 (97.8966)  time: 0.3603  data: 0.0033  max mem: 2503
Train: Epoch[1/5]  [1150/3750]  eta: 0:16:04  Lr: 0.001875  Loss: -0.7943  Acc@1: 81.2500 (73.3275)  Acc@5: 100.0000 (97.8931)  time: 0.3522  data: 0.0006  max mem: 2503
Train: Epoch[1/5]  [1160/3750]  eta: 0:16:00  Lr: 0.001875  Loss: -0.7122  Acc@1: 81.2500 (73.4065)  Acc@5: 100.0000 (97.9059)  time: 0.3680  data: 0.0008  max mem: 2503
Train: Epoch[1/5]  [1170/3750]  eta: 0:15:56  Lr: 0.001875  Loss: -0.3975  Acc@1: 81.2500 (73.4682)  Acc@5: 100.0000 (97.9184)  time: 0.3717  data: 0.0008  max mem: 2503
Train: Epoch[1/5]  [1180/3750]  eta: 0:15:52  Lr: 0.001875  Loss: -0.7104  Acc@1: 75.0000 (73.4388)  Acc@5: 100.0000 (97.9202)  time: 0.3611  data: 0.0009  max mem: 2503
Train: Epoch[1/5]  [1190/3750]  eta: 0:15:48  Lr: 0.001875  Loss: -0.8438  Acc@1: 81.2500 (73.4939)  Acc@5: 100.0000 (97.9219)  time: 0.3580  data: 0.0017  max mem: 2503
Train: Epoch[1/5]  [1200/3750]  eta: 0:15:45  Lr: 0.001875  Loss: -0.6588  Acc@1: 81.2500 (73.5325)  Acc@5: 100.0000 (97.9288)  time: 0.3665  data: 0.0025  max mem: 2503
Train: Epoch[1/5]  [1210/3750]  eta: 0:15:41  Lr: 0.001875  Loss: -0.5637  Acc@1: 75.0000 (73.5085)  Acc@5: 100.0000 (97.9098)  time: 0.3622  data: 0.0026  max mem: 2503
Train: Epoch[1/5]  [1220/3750]  eta: 0:15:37  Lr: 0.001875  Loss: -0.4113  Acc@1: 75.0000 (73.5207)  Acc@5: 100.0000 (97.9115)  time: 0.3559  data: 0.0020  max mem: 2503
Train: Epoch[1/5]  [1230/3750]  eta: 0:15:36  Lr: 0.001875  Loss: -0.0149  Acc@1: 75.0000 (73.5022)  Acc@5: 100.0000 (97.8879)  time: 0.4441  data: 0.0012  max mem: 2503
Train: Epoch[1/5]  [1240/3750]  eta: 0:15:32  Lr: 0.001875  Loss: -0.8471  Acc@1: 75.0000 (73.5445)  Acc@5: 100.0000 (97.8999)  time: 0.4370  data: 0.0010  max mem: 2503
Train: Epoch[1/5]  [1250/3750]  eta: 0:15:28  Lr: 0.001875  Loss: -0.1836  Acc@1: 75.0000 (73.5462)  Acc@5: 100.0000 (97.9117)  time: 0.3496  data: 0.0010  max mem: 2503
Train: Epoch[1/5]  [1260/3750]  eta: 0:15:24  Lr: 0.001875  Loss: -0.1897  Acc@1: 75.0000 (73.5726)  Acc@5: 100.0000 (97.9233)  time: 0.3618  data: 0.0012  max mem: 2503
Train: Epoch[1/5]  [1270/3750]  eta: 0:15:20  Lr: 0.001875  Loss: -0.4122  Acc@1: 81.2500 (73.6379)  Acc@5: 100.0000 (97.9396)  time: 0.3603  data: 0.0010  max mem: 2503
Train: Epoch[1/5]  [1280/3750]  eta: 0:15:16  Lr: 0.001875  Loss: -0.6408  Acc@1: 81.2500 (73.6729)  Acc@5: 100.0000 (97.9508)  time: 0.3580  data: 0.0012  max mem: 2503
Train: Epoch[1/5]  [1290/3750]  eta: 0:15:12  Lr: 0.001875  Loss: -0.6975  Acc@1: 81.2500 (73.7413)  Acc@5: 100.0000 (97.9619)  time: 0.3588  data: 0.0012  max mem: 2503
Train: Epoch[1/5]  [1300/3750]  eta: 0:15:08  Lr: 0.001875  Loss: -0.8968  Acc@1: 81.2500 (73.7990)  Acc@5: 100.0000 (97.9727)  time: 0.3556  data: 0.0006  max mem: 2503
Train: Epoch[1/5]  [1310/3750]  eta: 0:15:04  Lr: 0.001875  Loss: -0.7697  Acc@1: 81.2500 (73.8463)  Acc@5: 100.0000 (97.9786)  time: 0.3596  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [1320/3750]  eta: 0:15:00  Lr: 0.001875  Loss: -0.2198  Acc@1: 75.0000 (73.8456)  Acc@5: 100.0000 (97.9750)  time: 0.3557  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [1330/3750]  eta: 0:14:57  Lr: 0.001875  Loss: -0.4308  Acc@1: 75.0000 (73.8261)  Acc@5: 93.7500 (97.9574)  time: 0.3605  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [1340/3750]  eta: 0:14:53  Lr: 0.001875  Loss: -0.6239  Acc@1: 75.0000 (73.8488)  Acc@5: 93.7500 (97.9540)  time: 0.3617  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [1350/3750]  eta: 0:14:49  Lr: 0.001875  Loss: -0.5639  Acc@1: 75.0000 (73.8758)  Acc@5: 100.0000 (97.9552)  time: 0.3540  data: 0.0006  max mem: 2503
Train: Epoch[1/5]  [1360/3750]  eta: 0:14:45  Lr: 0.001875  Loss: -0.6153  Acc@1: 75.0000 (73.8933)  Acc@5: 100.0000 (97.9657)  time: 0.3616  data: 0.0006  max mem: 2503
Train: Epoch[1/5]  [1370/3750]  eta: 0:14:41  Lr: 0.001875  Loss: -0.3565  Acc@1: 75.0000 (73.9196)  Acc@5: 100.0000 (97.9668)  time: 0.3708  data: 0.0024  max mem: 2503
Train: Epoch[1/5]  [1380/3750]  eta: 0:14:37  Lr: 0.001875  Loss: -0.2054  Acc@1: 81.2500 (73.9727)  Acc@5: 100.0000 (97.9770)  time: 0.3655  data: 0.0036  max mem: 2503
Train: Epoch[1/5]  [1390/3750]  eta: 0:14:34  Lr: 0.001875  Loss: -0.1126  Acc@1: 81.2500 (73.9801)  Acc@5: 100.0000 (97.9781)  time: 0.3656  data: 0.0021  max mem: 2503
Train: Epoch[1/5]  [1400/3750]  eta: 0:14:30  Lr: 0.001875  Loss: -0.2640  Acc@1: 75.0000 (73.9873)  Acc@5: 100.0000 (97.9836)  time: 0.3615  data: 0.0015  max mem: 2503
Train: Epoch[1/5]  [1410/3750]  eta: 0:14:26  Lr: 0.001875  Loss: -0.0558  Acc@1: 75.0000 (74.0167)  Acc@5: 100.0000 (97.9890)  time: 0.3547  data: 0.0015  max mem: 2503
Train: Epoch[1/5]  [1420/3750]  eta: 0:14:22  Lr: 0.001875  Loss: -0.7785  Acc@1: 81.2500 (74.0368)  Acc@5: 100.0000 (97.9944)  time: 0.3632  data: 0.0014  max mem: 2503
Train: Epoch[1/5]  [1430/3750]  eta: 0:14:22  Lr: 0.001875  Loss: -0.6201  Acc@1: 75.0000 (74.0653)  Acc@5: 100.0000 (97.9997)  time: 0.4739  data: 0.0011  max mem: 2503
Train: Epoch[1/5]  [1440/3750]  eta: 0:14:23  Lr: 0.001875  Loss: 0.4259  Acc@1: 75.0000 (74.0415)  Acc@5: 100.0000 (97.9962)  time: 0.6377  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [1450/3750]  eta: 0:14:24  Lr: 0.001875  Loss: -0.3452  Acc@1: 75.0000 (74.0782)  Acc@5: 100.0000 (97.9928)  time: 0.6901  data: 0.0010  max mem: 2503
Train: Epoch[1/5]  [1460/3750]  eta: 0:14:25  Lr: 0.001875  Loss: -0.4808  Acc@1: 81.2500 (74.1016)  Acc@5: 100.0000 (97.9851)  time: 0.6599  data: 0.0010  max mem: 2503
Train: Epoch[1/5]  [1470/3750]  eta: 0:14:22  Lr: 0.001875  Loss: -0.6949  Acc@1: 81.2500 (74.1247)  Acc@5: 100.0000 (97.9903)  time: 0.5566  data: 0.0011  max mem: 2503
Train: Epoch[1/5]  [1480/3750]  eta: 0:14:18  Lr: 0.001875  Loss: -0.1512  Acc@1: 81.2500 (74.1518)  Acc@5: 100.0000 (97.9828)  time: 0.4146  data: 0.0011  max mem: 2503
Train: Epoch[1/5]  [1490/3750]  eta: 0:14:14  Lr: 0.001875  Loss: -0.2224  Acc@1: 75.0000 (74.1742)  Acc@5: 100.0000 (97.9879)  time: 0.3545  data: 0.0006  max mem: 2503
Train: Epoch[1/5]  [1500/3750]  eta: 0:14:10  Lr: 0.001875  Loss: -0.5096  Acc@1: 75.0000 (74.1964)  Acc@5: 100.0000 (98.0013)  time: 0.3610  data: 0.0010  max mem: 2503
Train: Epoch[1/5]  [1510/3750]  eta: 0:14:06  Lr: 0.001875  Loss: -0.4237  Acc@1: 75.0000 (74.1893)  Acc@5: 100.0000 (98.0146)  time: 0.3622  data: 0.0009  max mem: 2503
Train: Epoch[1/5]  [1520/3750]  eta: 0:14:02  Lr: 0.001875  Loss: -0.3989  Acc@1: 75.0000 (74.2110)  Acc@5: 100.0000 (98.0235)  time: 0.3615  data: 0.0016  max mem: 2503
Train: Epoch[1/5]  [1530/3750]  eta: 0:13:58  Lr: 0.001875  Loss: -0.2266  Acc@1: 75.0000 (74.2652)  Acc@5: 100.0000 (98.0282)  time: 0.3672  data: 0.0024  max mem: 2503
Train: Epoch[1/5]  [1540/3750]  eta: 0:13:55  Lr: 0.001875  Loss: -0.2241  Acc@1: 81.2500 (74.2943)  Acc@5: 100.0000 (98.0208)  time: 0.3840  data: 0.0013  max mem: 2503
Train: Epoch[1/5]  [1550/3750]  eta: 0:13:51  Lr: 0.001875  Loss: -0.6936  Acc@1: 81.2500 (74.3391)  Acc@5: 100.0000 (98.0214)  time: 0.3789  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [1560/3750]  eta: 0:13:47  Lr: 0.001875  Loss: -0.3884  Acc@1: 81.2500 (74.3674)  Acc@5: 100.0000 (98.0301)  time: 0.3615  data: 0.0006  max mem: 2503
Train: Epoch[1/5]  [1570/3750]  eta: 0:13:43  Lr: 0.001875  Loss: -0.5181  Acc@1: 81.2500 (74.4271)  Acc@5: 100.0000 (98.0426)  time: 0.3654  data: 0.0011  max mem: 2503
Train: Epoch[1/5]  [1580/3750]  eta: 0:13:39  Lr: 0.001875  Loss: -0.1506  Acc@1: 81.2500 (74.4584)  Acc@5: 100.0000 (98.0392)  time: 0.3641  data: 0.0010  max mem: 2503
Train: Epoch[1/5]  [1590/3750]  eta: 0:13:35  Lr: 0.001875  Loss: -0.8330  Acc@1: 75.0000 (74.4579)  Acc@5: 100.0000 (98.0358)  time: 0.3622  data: 0.0012  max mem: 2503
Train: Epoch[1/5]  [1600/3750]  eta: 0:13:32  Lr: 0.001875  Loss: -0.8286  Acc@1: 81.2500 (74.5237)  Acc@5: 100.0000 (98.0481)  time: 0.4000  data: 0.0012  max mem: 2503
Train: Epoch[1/5]  [1610/3750]  eta: 0:13:28  Lr: 0.001875  Loss: -0.4623  Acc@1: 81.2500 (74.5306)  Acc@5: 100.0000 (98.0447)  time: 0.3959  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [1620/3750]  eta: 0:13:24  Lr: 0.001875  Loss: 0.0749  Acc@1: 75.0000 (74.5103)  Acc@5: 100.0000 (98.0413)  time: 0.3643  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [1630/3750]  eta: 0:13:20  Lr: 0.001875  Loss: -0.6361  Acc@1: 75.0000 (74.5363)  Acc@5: 100.0000 (98.0342)  time: 0.3590  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [1640/3750]  eta: 0:13:16  Lr: 0.001875  Loss: -0.0196  Acc@1: 75.0000 (74.5582)  Acc@5: 100.0000 (98.0385)  time: 0.3510  data: 0.0006  max mem: 2503
Train: Epoch[1/5]  [1650/3750]  eta: 0:13:12  Lr: 0.001875  Loss: -0.7445  Acc@1: 81.2500 (74.5987)  Acc@5: 100.0000 (98.0504)  time: 0.3639  data: 0.0021  max mem: 2503
Train: Epoch[1/5]  [1660/3750]  eta: 0:13:08  Lr: 0.001875  Loss: -0.5767  Acc@1: 81.2500 (74.6200)  Acc@5: 100.0000 (98.0471)  time: 0.3682  data: 0.0026  max mem: 2503
Train: Epoch[1/5]  [1670/3750]  eta: 0:13:04  Lr: 0.001875  Loss: -0.5694  Acc@1: 81.2500 (74.6372)  Acc@5: 100.0000 (98.0551)  time: 0.3564  data: 0.0012  max mem: 2503
Train: Epoch[1/5]  [1680/3750]  eta: 0:13:00  Lr: 0.001875  Loss: -0.4147  Acc@1: 81.2500 (74.6431)  Acc@5: 100.0000 (98.0666)  time: 0.3539  data: 0.0012  max mem: 2503
Train: Epoch[1/5]  [1690/3750]  eta: 0:12:56  Lr: 0.001875  Loss: -0.5059  Acc@1: 81.2500 (74.6637)  Acc@5: 100.0000 (98.0670)  time: 0.3621  data: 0.0010  max mem: 2503
Train: Epoch[1/5]  [1700/3750]  eta: 0:12:52  Lr: 0.001875  Loss: -0.6377  Acc@1: 81.2500 (74.7354)  Acc@5: 100.0000 (98.0783)  time: 0.3583  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [1710/3750]  eta: 0:12:48  Lr: 0.001875  Loss: -0.5882  Acc@1: 81.2500 (74.7589)  Acc@5: 100.0000 (98.0823)  time: 0.3584  data: 0.0006  max mem: 2503
Train: Epoch[1/5]  [1720/3750]  eta: 0:12:44  Lr: 0.001875  Loss: -0.2662  Acc@1: 81.2500 (74.7894)  Acc@5: 100.0000 (98.0861)  time: 0.3599  data: 0.0006  max mem: 2503
Train: Epoch[1/5]  [1730/3750]  eta: 0:12:40  Lr: 0.001875  Loss: -0.1231  Acc@1: 75.0000 (74.8086)  Acc@5: 100.0000 (98.0864)  time: 0.3553  data: 0.0011  max mem: 2503
Train: Epoch[1/5]  [1740/3750]  eta: 0:12:36  Lr: 0.001875  Loss: -0.4918  Acc@1: 75.0000 (74.8349)  Acc@5: 100.0000 (98.0938)  time: 0.3624  data: 0.0010  max mem: 2503
Train: Epoch[1/5]  [1750/3750]  eta: 0:12:32  Lr: 0.001875  Loss: -0.1556  Acc@1: 75.0000 (74.8608)  Acc@5: 100.0000 (98.0939)  time: 0.3674  data: 0.0010  max mem: 2503
Train: Epoch[1/5]  [1760/3750]  eta: 0:12:28  Lr: 0.001875  Loss: -0.1826  Acc@1: 75.0000 (74.8793)  Acc@5: 100.0000 (98.0977)  time: 0.3560  data: 0.0011  max mem: 2503
Train: Epoch[1/5]  [1770/3750]  eta: 0:12:24  Lr: 0.001875  Loss: -0.6531  Acc@1: 75.0000 (74.8800)  Acc@5: 100.0000 (98.0978)  time: 0.3507  data: 0.0006  max mem: 2503
Train: Epoch[1/5]  [1780/3750]  eta: 0:12:20  Lr: 0.001875  Loss: -0.5926  Acc@1: 75.0000 (74.8842)  Acc@5: 100.0000 (98.0945)  time: 0.3630  data: 0.0010  max mem: 2503
Train: Epoch[1/5]  [1790/3750]  eta: 0:12:16  Lr: 0.001875  Loss: -0.4763  Acc@1: 75.0000 (74.8709)  Acc@5: 100.0000 (98.0981)  time: 0.3648  data: 0.0010  max mem: 2503
Train: Epoch[1/5]  [1800/3750]  eta: 0:12:12  Lr: 0.001875  Loss: -0.2599  Acc@1: 75.0000 (74.8647)  Acc@5: 100.0000 (98.1017)  time: 0.3587  data: 0.0008  max mem: 2503
Train: Epoch[1/5]  [1810/3750]  eta: 0:12:09  Lr: 0.001875  Loss: -0.3307  Acc@1: 75.0000 (74.8827)  Acc@5: 100.0000 (98.1088)  time: 0.3668  data: 0.0012  max mem: 2503
Train: Epoch[1/5]  [1820/3750]  eta: 0:12:04  Lr: 0.001875  Loss: -0.6514  Acc@1: 81.2500 (74.8970)  Acc@5: 100.0000 (98.1192)  time: 0.3623  data: 0.0025  max mem: 2503
Train: Epoch[1/5]  [1830/3750]  eta: 0:12:01  Lr: 0.001875  Loss: -0.2959  Acc@1: 81.2500 (74.9317)  Acc@5: 100.0000 (98.1260)  time: 0.3552  data: 0.0021  max mem: 2503
Train: Epoch[1/5]  [1840/3750]  eta: 0:12:00  Lr: 0.001875  Loss: -0.7793  Acc@1: 87.5000 (74.9694)  Acc@5: 100.0000 (98.1362)  time: 0.5157  data: 0.0022  max mem: 2503
Train: Epoch[1/5]  [1850/3750]  eta: 0:11:59  Lr: 0.001875  Loss: -0.4311  Acc@1: 81.2500 (74.9662)  Acc@5: 100.0000 (98.1260)  time: 0.6753  data: 0.0022  max mem: 2503
Train: Epoch[1/5]  [1860/3750]  eta: 0:11:59  Lr: 0.001875  Loss: -0.4030  Acc@1: 75.0000 (74.9798)  Acc@5: 100.0000 (98.1361)  time: 0.6914  data: 0.0006  max mem: 2503
Train: Epoch[1/5]  [1870/3750]  eta: 0:11:58  Lr: 0.001875  Loss: -0.8496  Acc@1: 75.0000 (75.0100)  Acc@5: 100.0000 (98.1360)  time: 0.6955  data: 0.0006  max mem: 2503
Train: Epoch[1/5]  [1880/3750]  eta: 0:11:57  Lr: 0.001875  Loss: -0.1622  Acc@1: 75.0000 (75.0100)  Acc@5: 100.0000 (98.1360)  time: 0.6967  data: 0.0006  max mem: 2503
Train: Epoch[1/5]  [1890/3750]  eta: 0:11:57  Lr: 0.001875  Loss: -0.4561  Acc@1: 81.2500 (75.0331)  Acc@5: 100.0000 (98.1392)  time: 0.7010  data: 0.0007  max mem: 2503
Train: Epoch[1/5]  [1900/3750]  eta: 0:11:55  Lr: 0.001875  Loss: -0.8069  Acc@1: 81.2500 (75.0526)  Acc@5: 100.0000 (98.1457)  time: 0.6762  data: 0.0008  max mem: 2503
Train: Epoch[1/5]  [1910/3750]  eta: 0:11:54  Lr: 0.001875  Loss: -0.7809  Acc@1: 81.2500 (75.0621)  Acc@5: 100.0000 (98.1521)  time: 0.6723  data: 0.0006  max mem: 2503
Train: Epoch[1/5]  [1920/3750]  eta: 0:11:53  Lr: 0.001875  Loss: -0.2648  Acc@1: 81.2500 (75.0846)  Acc@5: 100.0000 (98.1585)  time: 0.6926  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [1930/3750]  eta: 0:11:52  Lr: 0.001875  Loss: -0.6303  Acc@1: 81.2500 (75.1198)  Acc@5: 100.0000 (98.1616)  time: 0.6934  data: 0.0006  max mem: 2503
Train: Epoch[1/5]  [1940/3750]  eta: 0:11:51  Lr: 0.001875  Loss: -0.4123  Acc@1: 75.0000 (75.1224)  Acc@5: 100.0000 (98.1614)  time: 0.6912  data: 0.0008  max mem: 2503
Train: Epoch[1/5]  [1950/3750]  eta: 0:11:50  Lr: 0.001875  Loss: -0.5501  Acc@1: 75.0000 (75.1281)  Acc@5: 100.0000 (98.1548)  time: 0.6879  data: 0.0007  max mem: 2503
Train: Epoch[1/5]  [1960/3750]  eta: 0:11:49  Lr: 0.001875  Loss: -0.8093  Acc@1: 75.0000 (75.1402)  Acc@5: 100.0000 (98.1610)  time: 0.6859  data: 0.0007  max mem: 2503
Train: Epoch[1/5]  [1970/3750]  eta: 0:11:47  Lr: 0.001875  Loss: -0.6366  Acc@1: 75.0000 (75.1459)  Acc@5: 100.0000 (98.1640)  time: 0.6912  data: 0.0006  max mem: 2503
Train: Epoch[1/5]  [1980/3750]  eta: 0:11:46  Lr: 0.001875  Loss: -0.5767  Acc@1: 75.0000 (75.1609)  Acc@5: 100.0000 (98.1670)  time: 0.6886  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [1990/3750]  eta: 0:11:45  Lr: 0.001875  Loss: -0.3186  Acc@1: 81.2500 (75.1758)  Acc@5: 100.0000 (98.1699)  time: 0.6875  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [2000/3750]  eta: 0:11:43  Lr: 0.001875  Loss: -0.7801  Acc@1: 81.2500 (75.1780)  Acc@5: 100.0000 (98.1728)  time: 0.6905  data: 0.0007  max mem: 2503
Train: Epoch[1/5]  [2010/3750]  eta: 0:11:41  Lr: 0.001875  Loss: -0.6036  Acc@1: 81.2500 (75.2238)  Acc@5: 100.0000 (98.1819)  time: 0.6733  data: 0.0009  max mem: 2503
Train: Epoch[1/5]  [2020/3750]  eta: 0:11:40  Lr: 0.001875  Loss: -0.5515  Acc@1: 81.2500 (75.2474)  Acc@5: 100.0000 (98.1878)  time: 0.6739  data: 0.0009  max mem: 2503
Train: Epoch[1/5]  [2030/3750]  eta: 0:11:38  Lr: 0.001875  Loss: -0.2209  Acc@1: 81.2500 (75.2431)  Acc@5: 100.0000 (98.1936)  time: 0.6879  data: 0.0008  max mem: 2503
Train: Epoch[1/5]  [2040/3750]  eta: 0:11:37  Lr: 0.001875  Loss: -0.4239  Acc@1: 75.0000 (75.2572)  Acc@5: 100.0000 (98.1933)  time: 0.6944  data: 0.0006  max mem: 2503
Train: Epoch[1/5]  [2050/3750]  eta: 0:11:35  Lr: 0.001875  Loss: -0.2448  Acc@1: 81.2500 (75.2743)  Acc@5: 100.0000 (98.1990)  time: 0.6846  data: 0.0008  max mem: 2503
Train: Epoch[1/5]  [2060/3750]  eta: 0:11:33  Lr: 0.001875  Loss: -0.1929  Acc@1: 75.0000 (75.2669)  Acc@5: 100.0000 (98.1987)  time: 0.6745  data: 0.0008  max mem: 2503
Train: Epoch[1/5]  [2070/3750]  eta: 0:11:31  Lr: 0.001875  Loss: -0.5965  Acc@1: 75.0000 (75.2897)  Acc@5: 100.0000 (98.2044)  time: 0.6843  data: 0.0006  max mem: 2503
Train: Epoch[1/5]  [2080/3750]  eta: 0:11:29  Lr: 0.001875  Loss: -0.5539  Acc@1: 81.2500 (75.3003)  Acc@5: 100.0000 (98.2070)  time: 0.6901  data: 0.0006  max mem: 2503
Train: Epoch[1/5]  [2090/3750]  eta: 0:11:27  Lr: 0.001875  Loss: -0.0374  Acc@1: 81.2500 (75.3168)  Acc@5: 100.0000 (98.2126)  time: 0.6903  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [2100/3750]  eta: 0:11:25  Lr: 0.001875  Loss: -0.7403  Acc@1: 81.2500 (75.3451)  Acc@5: 100.0000 (98.2151)  time: 0.6843  data: 0.0006  max mem: 2503
Train: Epoch[1/5]  [2110/3750]  eta: 0:11:23  Lr: 0.001875  Loss: -0.1456  Acc@1: 81.2500 (75.3849)  Acc@5: 100.0000 (98.2147)  time: 0.6947  data: 0.0006  max mem: 2503
Train: Epoch[1/5]  [2120/3750]  eta: 0:11:21  Lr: 0.001875  Loss: -0.6199  Acc@1: 81.2500 (75.3890)  Acc@5: 100.0000 (98.2113)  time: 0.6845  data: 0.0006  max mem: 2503
Train: Epoch[1/5]  [2130/3750]  eta: 0:11:19  Lr: 0.001875  Loss: -0.5821  Acc@1: 75.0000 (75.4077)  Acc@5: 100.0000 (98.2168)  time: 0.6815  data: 0.0008  max mem: 2503
Train: Epoch[1/5]  [2140/3750]  eta: 0:11:16  Lr: 0.001875  Loss: -0.0644  Acc@1: 75.0000 (75.4058)  Acc@5: 100.0000 (98.2135)  time: 0.6785  data: 0.0006  max mem: 2503
Train: Epoch[1/5]  [2150/3750]  eta: 0:11:14  Lr: 0.001875  Loss: -0.6988  Acc@1: 81.2500 (75.4591)  Acc@5: 100.0000 (98.2218)  time: 0.6693  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [2160/3750]  eta: 0:11:12  Lr: 0.001875  Loss: -0.6363  Acc@1: 81.2500 (75.4772)  Acc@5: 100.0000 (98.2213)  time: 0.6755  data: 0.0010  max mem: 2503
Train: Epoch[1/5]  [2170/3750]  eta: 0:11:09  Lr: 0.001875  Loss: -0.8335  Acc@1: 81.2500 (75.4923)  Acc@5: 100.0000 (98.2209)  time: 0.6679  data: 0.0010  max mem: 2503
Train: Epoch[1/5]  [2180/3750]  eta: 0:11:07  Lr: 0.001875  Loss: -0.5566  Acc@1: 75.0000 (75.4900)  Acc@5: 100.0000 (98.2262)  time: 0.6806  data: 0.0008  max mem: 2503
Train: Epoch[1/5]  [2190/3750]  eta: 0:11:03  Lr: 0.001875  Loss: -0.4783  Acc@1: 81.2500 (75.5192)  Acc@5: 100.0000 (98.2343)  time: 0.5573  data: 0.0010  max mem: 2503
Train: Epoch[1/5]  [2200/3750]  eta: 0:10:58  Lr: 0.001875  Loss: -0.8268  Acc@1: 81.2500 (75.5338)  Acc@5: 100.0000 (98.2366)  time: 0.3953  data: 0.0014  max mem: 2503
Train: Epoch[1/5]  [2210/3750]  eta: 0:10:53  Lr: 0.001875  Loss: -0.4586  Acc@1: 75.0000 (75.5343)  Acc@5: 100.0000 (98.2361)  time: 0.3668  data: 0.0028  max mem: 2503
Train: Epoch[1/5]  [2220/3750]  eta: 0:10:49  Lr: 0.001875  Loss: -0.5368  Acc@1: 81.2500 (75.5684)  Acc@5: 100.0000 (98.2440)  time: 0.3693  data: 0.0031  max mem: 2503
Train: Epoch[1/5]  [2230/3750]  eta: 0:10:44  Lr: 0.001875  Loss: -0.6262  Acc@1: 81.2500 (75.6107)  Acc@5: 100.0000 (98.2463)  time: 0.3826  data: 0.0032  max mem: 2503
Train: Epoch[1/5]  [2240/3750]  eta: 0:10:40  Lr: 0.001875  Loss: -0.6301  Acc@1: 81.2500 (75.6275)  Acc@5: 100.0000 (98.2458)  time: 0.3792  data: 0.0030  max mem: 2503
Train: Epoch[1/5]  [2250/3750]  eta: 0:10:35  Lr: 0.001875  Loss: -0.3076  Acc@1: 81.2500 (75.6358)  Acc@5: 100.0000 (98.2536)  time: 0.3670  data: 0.0037  max mem: 2503
Train: Epoch[1/5]  [2260/3750]  eta: 0:10:31  Lr: 0.001875  Loss: -0.4436  Acc@1: 81.2500 (75.6717)  Acc@5: 100.0000 (98.2557)  time: 0.3727  data: 0.0060  max mem: 2503
Train: Epoch[1/5]  [2270/3750]  eta: 0:10:26  Lr: 0.001875  Loss: -0.3068  Acc@1: 81.2500 (75.6825)  Acc@5: 100.0000 (98.2579)  time: 0.3803  data: 0.0068  max mem: 2503
Train: Epoch[1/5]  [2280/3750]  eta: 0:10:22  Lr: 0.001875  Loss: -0.5212  Acc@1: 81.2500 (75.7014)  Acc@5: 100.0000 (98.2546)  time: 0.3766  data: 0.0046  max mem: 2503
Train: Epoch[1/5]  [2290/3750]  eta: 0:10:17  Lr: 0.001875  Loss: -0.5106  Acc@1: 81.2500 (75.7148)  Acc@5: 100.0000 (98.2568)  time: 0.3901  data: 0.0048  max mem: 2503
Train: Epoch[1/5]  [2300/3750]  eta: 0:10:13  Lr: 0.001875  Loss: -0.8568  Acc@1: 81.2500 (75.7497)  Acc@5: 100.0000 (98.2616)  time: 0.3889  data: 0.0051  max mem: 2503
Train: Epoch[1/5]  [2310/3750]  eta: 0:10:08  Lr: 0.001875  Loss: -0.6508  Acc@1: 81.2500 (75.7708)  Acc@5: 100.0000 (98.2691)  time: 0.3693  data: 0.0026  max mem: 2503
Train: Epoch[1/5]  [2320/3750]  eta: 0:10:03  Lr: 0.001875  Loss: -0.5438  Acc@1: 81.2500 (75.8025)  Acc@5: 100.0000 (98.2739)  time: 0.3627  data: 0.0030  max mem: 2503
Train: Epoch[1/5]  [2330/3750]  eta: 0:09:59  Lr: 0.001875  Loss: -0.8877  Acc@1: 81.2500 (75.8205)  Acc@5: 100.0000 (98.2760)  time: 0.3681  data: 0.0032  max mem: 2503
Train: Epoch[1/5]  [2340/3750]  eta: 0:09:54  Lr: 0.001875  Loss: -0.5243  Acc@1: 75.0000 (75.8223)  Acc@5: 100.0000 (98.2780)  time: 0.3766  data: 0.0028  max mem: 2503
Train: Epoch[1/5]  [2350/3750]  eta: 0:09:50  Lr: 0.001875  Loss: -0.4026  Acc@1: 75.0000 (75.8241)  Acc@5: 100.0000 (98.2853)  time: 0.3753  data: 0.0027  max mem: 2503
Train: Epoch[1/5]  [2360/3750]  eta: 0:09:45  Lr: 0.001875  Loss: -0.3084  Acc@1: 75.0000 (75.8312)  Acc@5: 100.0000 (98.2899)  time: 0.3684  data: 0.0032  max mem: 2503
Train: Epoch[1/5]  [2370/3750]  eta: 0:09:41  Lr: 0.001875  Loss: -0.2810  Acc@1: 81.2500 (75.8435)  Acc@5: 100.0000 (98.2892)  time: 0.3638  data: 0.0035  max mem: 2503
Train: Epoch[1/5]  [2380/3750]  eta: 0:09:36  Lr: 0.001875  Loss: -0.6030  Acc@1: 81.2500 (75.8636)  Acc@5: 100.0000 (98.2885)  time: 0.3654  data: 0.0040  max mem: 2503
Train: Epoch[1/5]  [2390/3750]  eta: 0:09:32  Lr: 0.001875  Loss: -0.7862  Acc@1: 81.2500 (75.8861)  Acc@5: 100.0000 (98.2905)  time: 0.3682  data: 0.0032  max mem: 2503
Train: Epoch[1/5]  [2400/3750]  eta: 0:09:27  Lr: 0.001875  Loss: -0.4483  Acc@1: 81.2500 (75.9111)  Acc@5: 100.0000 (98.2950)  time: 0.3676  data: 0.0032  max mem: 2503
Train: Epoch[1/5]  [2410/3750]  eta: 0:09:23  Lr: 0.001875  Loss: -0.5049  Acc@1: 81.2500 (75.9358)  Acc@5: 100.0000 (98.3021)  time: 0.3609  data: 0.0028  max mem: 2503
Train: Epoch[1/5]  [2420/3750]  eta: 0:09:18  Lr: 0.001875  Loss: -0.5310  Acc@1: 81.2500 (75.9603)  Acc@5: 100.0000 (98.3039)  time: 0.3651  data: 0.0037  max mem: 2503
Train: Epoch[1/5]  [2430/3750]  eta: 0:09:14  Lr: 0.001875  Loss: -0.2983  Acc@1: 75.0000 (75.9667)  Acc@5: 100.0000 (98.3032)  time: 0.3755  data: 0.0044  max mem: 2503
Train: Epoch[1/5]  [2440/3750]  eta: 0:09:09  Lr: 0.001875  Loss: -0.6709  Acc@1: 75.0000 (75.9704)  Acc@5: 100.0000 (98.3101)  time: 0.3743  data: 0.0027  max mem: 2503
Train: Epoch[1/5]  [2450/3750]  eta: 0:09:05  Lr: 0.001875  Loss: -0.7429  Acc@1: 81.2500 (75.9868)  Acc@5: 100.0000 (98.3170)  time: 0.3732  data: 0.0047  max mem: 2503
Train: Epoch[1/5]  [2460/3750]  eta: 0:09:00  Lr: 0.001875  Loss: -0.7894  Acc@1: 81.2500 (75.9803)  Acc@5: 100.0000 (98.3213)  time: 0.3700  data: 0.0051  max mem: 2503
Train: Epoch[1/5]  [2470/3750]  eta: 0:08:56  Lr: 0.001875  Loss: -0.8674  Acc@1: 81.2500 (75.9991)  Acc@5: 100.0000 (98.3180)  time: 0.3623  data: 0.0029  max mem: 2503
Train: Epoch[1/5]  [2480/3750]  eta: 0:08:52  Lr: 0.001875  Loss: -0.8103  Acc@1: 81.2500 (76.0328)  Acc@5: 100.0000 (98.3222)  time: 0.3666  data: 0.0030  max mem: 2503
Train: Epoch[1/5]  [2490/3750]  eta: 0:08:47  Lr: 0.001875  Loss: 0.2013  Acc@1: 81.2500 (76.0187)  Acc@5: 100.0000 (98.3265)  time: 0.3785  data: 0.0057  max mem: 2503
Train: Epoch[1/5]  [2500/3750]  eta: 0:08:43  Lr: 0.001875  Loss: -0.0665  Acc@1: 75.0000 (76.0196)  Acc@5: 100.0000 (98.3232)  time: 0.3815  data: 0.0073  max mem: 2503
Train: Epoch[1/5]  [2510/3750]  eta: 0:08:38  Lr: 0.001875  Loss: -0.4451  Acc@1: 75.0000 (76.0230)  Acc@5: 100.0000 (98.3274)  time: 0.3732  data: 0.0054  max mem: 2503
Train: Epoch[1/5]  [2520/3750]  eta: 0:08:34  Lr: 0.001875  Loss: -0.5165  Acc@1: 81.2500 (76.0462)  Acc@5: 100.0000 (98.3315)  time: 0.3669  data: 0.0025  max mem: 2503
Train: Epoch[1/5]  [2530/3750]  eta: 0:08:30  Lr: 0.001875  Loss: -0.7064  Acc@1: 81.2500 (76.0668)  Acc@5: 100.0000 (98.3307)  time: 0.3727  data: 0.0012  max mem: 2503
Train: Epoch[1/5]  [2540/3750]  eta: 0:08:25  Lr: 0.001875  Loss: -0.2790  Acc@1: 81.2500 (76.0823)  Acc@5: 100.0000 (98.3348)  time: 0.3670  data: 0.0017  max mem: 2503
Train: Epoch[1/5]  [2550/3750]  eta: 0:08:21  Lr: 0.001875  Loss: -0.3399  Acc@1: 81.2500 (76.1001)  Acc@5: 100.0000 (98.3340)  time: 0.3603  data: 0.0038  max mem: 2503
Train: Epoch[1/5]  [2560/3750]  eta: 0:08:16  Lr: 0.001875  Loss: -0.5572  Acc@1: 81.2500 (76.1177)  Acc@5: 100.0000 (98.3356)  time: 0.3721  data: 0.0063  max mem: 2503
Train: Epoch[1/5]  [2570/3750]  eta: 0:08:12  Lr: 0.001875  Loss: -0.2984  Acc@1: 81.2500 (76.1547)  Acc@5: 100.0000 (98.3348)  time: 0.3759  data: 0.0044  max mem: 2503
Train: Epoch[1/5]  [2580/3750]  eta: 0:08:08  Lr: 0.001875  Loss: -0.5252  Acc@1: 81.2500 (76.1430)  Acc@5: 100.0000 (98.3364)  time: 0.3757  data: 0.0066  max mem: 2503
Train: Epoch[1/5]  [2590/3750]  eta: 0:08:03  Lr: 0.001875  Loss: -0.7045  Acc@1: 75.0000 (76.1627)  Acc@5: 100.0000 (98.3356)  time: 0.3789  data: 0.0068  max mem: 2503
Train: Epoch[1/5]  [2600/3750]  eta: 0:07:59  Lr: 0.001875  Loss: -0.4465  Acc@1: 81.2500 (76.1702)  Acc@5: 100.0000 (98.3372)  time: 0.3754  data: 0.0030  max mem: 2503
Train: Epoch[1/5]  [2610/3750]  eta: 0:07:54  Lr: 0.001875  Loss: -0.1294  Acc@1: 81.2500 (76.1753)  Acc@5: 100.0000 (98.3412)  time: 0.3686  data: 0.0025  max mem: 2503
Train: Epoch[1/5]  [2620/3750]  eta: 0:07:50  Lr: 0.001875  Loss: -0.1033  Acc@1: 75.0000 (76.1828)  Acc@5: 100.0000 (98.3451)  time: 0.3680  data: 0.0024  max mem: 2503
Train: Epoch[1/5]  [2630/3750]  eta: 0:07:46  Lr: 0.001875  Loss: -0.5497  Acc@1: 75.0000 (76.1996)  Acc@5: 100.0000 (98.3490)  time: 0.3691  data: 0.0046  max mem: 2503
Train: Epoch[1/5]  [2640/3750]  eta: 0:07:41  Lr: 0.001875  Loss: -0.6284  Acc@1: 75.0000 (76.2117)  Acc@5: 100.0000 (98.3434)  time: 0.3731  data: 0.0042  max mem: 2503
Train: Epoch[1/5]  [2650/3750]  eta: 0:07:37  Lr: 0.001875  Loss: -0.6949  Acc@1: 81.2500 (76.2425)  Acc@5: 100.0000 (98.3497)  time: 0.3676  data: 0.0020  max mem: 2503
Train: Epoch[1/5]  [2660/3750]  eta: 0:07:33  Lr: 0.001875  Loss: -0.5269  Acc@1: 81.2500 (76.2260)  Acc@5: 100.0000 (98.3535)  time: 0.3610  data: 0.0022  max mem: 2503
Train: Epoch[1/5]  [2670/3750]  eta: 0:07:28  Lr: 0.001875  Loss: -0.6171  Acc@1: 75.0000 (76.2191)  Acc@5: 100.0000 (98.3550)  time: 0.3644  data: 0.0027  max mem: 2503
Train: Epoch[1/5]  [2680/3750]  eta: 0:07:24  Lr: 0.001875  Loss: -0.3155  Acc@1: 75.0000 (76.2309)  Acc@5: 100.0000 (98.3565)  time: 0.3752  data: 0.0032  max mem: 2503
Train: Epoch[1/5]  [2690/3750]  eta: 0:07:20  Lr: 0.001875  Loss: -0.1677  Acc@1: 75.0000 (76.2356)  Acc@5: 100.0000 (98.3580)  time: 0.3700  data: 0.0043  max mem: 2503
Train: Epoch[1/5]  [2700/3750]  eta: 0:07:15  Lr: 0.001875  Loss: -0.2587  Acc@1: 81.2500 (76.2495)  Acc@5: 100.0000 (98.3617)  time: 0.3600  data: 0.0054  max mem: 2503
Train: Epoch[1/5]  [2710/3750]  eta: 0:07:11  Lr: 0.001875  Loss: -0.3084  Acc@1: 75.0000 (76.2541)  Acc@5: 100.0000 (98.3655)  time: 0.3651  data: 0.0049  max mem: 2503
Train: Epoch[1/5]  [2720/3750]  eta: 0:07:07  Lr: 0.001875  Loss: -0.6347  Acc@1: 75.0000 (76.2449)  Acc@5: 100.0000 (98.3623)  time: 0.3759  data: 0.0027  max mem: 2503
Train: Epoch[1/5]  [2730/3750]  eta: 0:07:02  Lr: 0.001875  Loss: -0.6064  Acc@1: 81.2500 (76.2656)  Acc@5: 100.0000 (98.3591)  time: 0.3759  data: 0.0023  max mem: 2503
Train: Epoch[1/5]  [2740/3750]  eta: 0:06:58  Lr: 0.001875  Loss: -0.0096  Acc@1: 81.2500 (76.2701)  Acc@5: 100.0000 (98.3651)  time: 0.3737  data: 0.0023  max mem: 2503
Train: Epoch[1/5]  [2750/3750]  eta: 0:06:54  Lr: 0.001875  Loss: -0.7369  Acc@1: 81.2500 (76.2836)  Acc@5: 100.0000 (98.3642)  time: 0.3713  data: 0.0025  max mem: 2503
Train: Epoch[1/5]  [2760/3750]  eta: 0:06:49  Lr: 0.001875  Loss: -0.4528  Acc@1: 81.2500 (76.2948)  Acc@5: 100.0000 (98.3656)  time: 0.3609  data: 0.0016  max mem: 2503
Train: Epoch[1/5]  [2770/3750]  eta: 0:06:45  Lr: 0.001875  Loss: -0.5867  Acc@1: 75.0000 (76.2992)  Acc@5: 100.0000 (98.3625)  time: 0.3641  data: 0.0022  max mem: 2503
Train: Epoch[1/5]  [2780/3750]  eta: 0:06:41  Lr: 0.001875  Loss: -0.4814  Acc@1: 75.0000 (76.2990)  Acc@5: 100.0000 (98.3661)  time: 0.3766  data: 0.0054  max mem: 2503
Train: Epoch[1/5]  [2790/3750]  eta: 0:06:36  Lr: 0.001875  Loss: 0.0956  Acc@1: 81.2500 (76.3055)  Acc@5: 100.0000 (98.3653)  time: 0.3708  data: 0.0047  max mem: 2503
Train: Epoch[1/5]  [2800/3750]  eta: 0:06:32  Lr: 0.001875  Loss: -0.6643  Acc@1: 81.2500 (76.3187)  Acc@5: 100.0000 (98.3667)  time: 0.3607  data: 0.0041  max mem: 2503
Train: Epoch[1/5]  [2810/3750]  eta: 0:06:28  Lr: 0.001875  Loss: -0.5273  Acc@1: 75.0000 (76.3340)  Acc@5: 100.0000 (98.3702)  time: 0.3633  data: 0.0043  max mem: 2503
Train: Epoch[1/5]  [2820/3750]  eta: 0:06:24  Lr: 0.001875  Loss: -0.2972  Acc@1: 81.2500 (76.3537)  Acc@5: 100.0000 (98.3738)  time: 0.3700  data: 0.0037  max mem: 2503
Train: Epoch[1/5]  [2830/3750]  eta: 0:06:19  Lr: 0.001875  Loss: -0.7724  Acc@1: 81.2500 (76.3644)  Acc@5: 100.0000 (98.3773)  time: 0.3641  data: 0.0032  max mem: 2503
Train: Epoch[1/5]  [2840/3750]  eta: 0:06:15  Lr: 0.001875  Loss: -0.8134  Acc@1: 81.2500 (76.3904)  Acc@5: 100.0000 (98.3809)  time: 0.3604  data: 0.0018  max mem: 2503
Train: Epoch[1/5]  [2850/3750]  eta: 0:06:11  Lr: 0.001875  Loss: -0.9725  Acc@1: 81.2500 (76.4184)  Acc@5: 100.0000 (98.3865)  time: 0.3690  data: 0.0025  max mem: 2503
Train: Epoch[1/5]  [2860/3750]  eta: 0:06:07  Lr: 0.001875  Loss: -0.8232  Acc@1: 81.2500 (76.4331)  Acc@5: 100.0000 (98.3878)  time: 0.3771  data: 0.0034  max mem: 2503
Train: Epoch[1/5]  [2870/3750]  eta: 0:06:02  Lr: 0.001875  Loss: -0.2452  Acc@1: 81.2500 (76.4629)  Acc@5: 100.0000 (98.3891)  time: 0.3744  data: 0.0045  max mem: 2503
Train: Epoch[1/5]  [2880/3750]  eta: 0:05:58  Lr: 0.001875  Loss: -0.6226  Acc@1: 81.2500 (76.4513)  Acc@5: 100.0000 (98.3903)  time: 0.3735  data: 0.0053  max mem: 2503
Train: Epoch[1/5]  [2890/3750]  eta: 0:05:54  Lr: 0.001875  Loss: -0.8390  Acc@1: 81.2500 (76.4722)  Acc@5: 100.0000 (98.3894)  time: 0.3721  data: 0.0054  max mem: 2503
Train: Epoch[1/5]  [2900/3750]  eta: 0:05:50  Lr: 0.001875  Loss: -0.5278  Acc@1: 75.0000 (76.4693)  Acc@5: 100.0000 (98.3950)  time: 0.3635  data: 0.0036  max mem: 2503
Train: Epoch[1/5]  [2910/3750]  eta: 0:05:45  Lr: 0.001875  Loss: -1.0103  Acc@1: 75.0000 (76.4664)  Acc@5: 100.0000 (98.3876)  time: 0.3694  data: 0.0041  max mem: 2503
Train: Epoch[1/5]  [2920/3750]  eta: 0:05:41  Lr: 0.001875  Loss: -0.3087  Acc@1: 75.0000 (76.4849)  Acc@5: 100.0000 (98.3931)  time: 0.3759  data: 0.0054  max mem: 2503
Train: Epoch[1/5]  [2930/3750]  eta: 0:05:37  Lr: 0.001875  Loss: -0.6995  Acc@1: 81.2500 (76.4991)  Acc@5: 100.0000 (98.3965)  time: 0.3681  data: 0.0030  max mem: 2503
Train: Epoch[1/5]  [2940/3750]  eta: 0:05:33  Lr: 0.001875  Loss: -0.3792  Acc@1: 81.2500 (76.5046)  Acc@5: 100.0000 (98.3977)  time: 0.3579  data: 0.0022  max mem: 2503
Train: Epoch[1/5]  [2950/3750]  eta: 0:05:28  Lr: 0.001875  Loss: -0.4946  Acc@1: 81.2500 (76.5080)  Acc@5: 100.0000 (98.3925)  time: 0.3667  data: 0.0048  max mem: 2503
Train: Epoch[1/5]  [2960/3750]  eta: 0:05:24  Lr: 0.001875  Loss: -0.8471  Acc@1: 75.0000 (76.4986)  Acc@5: 100.0000 (98.3937)  time: 0.3725  data: 0.0052  max mem: 2503
Train: Epoch[1/5]  [2970/3750]  eta: 0:05:20  Lr: 0.001875  Loss: -0.0004  Acc@1: 75.0000 (76.5041)  Acc@5: 100.0000 (98.3991)  time: 0.3791  data: 0.0051  max mem: 2503
Train: Epoch[1/5]  [2980/3750]  eta: 0:05:16  Lr: 0.001875  Loss: -0.6978  Acc@1: 75.0000 (76.5075)  Acc@5: 100.0000 (98.3982)  time: 0.3730  data: 0.0052  max mem: 2503
Train: Epoch[1/5]  [2990/3750]  eta: 0:05:12  Lr: 0.001875  Loss: -0.4271  Acc@1: 81.2500 (76.5150)  Acc@5: 100.0000 (98.3931)  time: 0.3642  data: 0.0038  max mem: 2503
Train: Epoch[1/5]  [3000/3750]  eta: 0:05:07  Lr: 0.001875  Loss: -0.6628  Acc@1: 81.2500 (76.5287)  Acc@5: 100.0000 (98.3985)  time: 0.3689  data: 0.0041  max mem: 2503
Train: Epoch[1/5]  [3010/3750]  eta: 0:05:03  Lr: 0.001875  Loss: -0.5429  Acc@1: 81.2500 (76.5423)  Acc@5: 100.0000 (98.4038)  time: 0.3762  data: 0.0049  max mem: 2503
Train: Epoch[1/5]  [3020/3750]  eta: 0:04:59  Lr: 0.001875  Loss: -0.3987  Acc@1: 81.2500 (76.5516)  Acc@5: 100.0000 (98.4049)  time: 0.3759  data: 0.0046  max mem: 2503
Train: Epoch[1/5]  [3030/3750]  eta: 0:04:55  Lr: 0.001875  Loss: -0.3381  Acc@1: 75.0000 (76.5548)  Acc@5: 100.0000 (98.4061)  time: 0.3749  data: 0.0039  max mem: 2503
Train: Epoch[1/5]  [3040/3750]  eta: 0:04:51  Lr: 0.001875  Loss: -0.4725  Acc@1: 81.2500 (76.5661)  Acc@5: 100.0000 (98.4092)  time: 0.3713  data: 0.0032  max mem: 2503
Train: Epoch[1/5]  [3050/3750]  eta: 0:04:46  Lr: 0.001875  Loss: -0.0422  Acc@1: 81.2500 (76.5794)  Acc@5: 100.0000 (98.4083)  time: 0.3644  data: 0.0019  max mem: 2503
Train: Epoch[1/5]  [3060/3750]  eta: 0:04:42  Lr: 0.001875  Loss: -0.4815  Acc@1: 75.0000 (76.5947)  Acc@5: 100.0000 (98.4135)  time: 0.3685  data: 0.0013  max mem: 2503
Train: Epoch[1/5]  [3070/3750]  eta: 0:04:38  Lr: 0.001875  Loss: -0.6452  Acc@1: 81.2500 (76.6017)  Acc@5: 100.0000 (98.4105)  time: 0.3725  data: 0.0024  max mem: 2503
Train: Epoch[1/5]  [3080/3750]  eta: 0:04:34  Lr: 0.001875  Loss: -0.5072  Acc@1: 81.2500 (76.6086)  Acc@5: 100.0000 (98.4137)  time: 0.3672  data: 0.0028  max mem: 2503
Train: Epoch[1/5]  [3090/3750]  eta: 0:04:30  Lr: 0.001875  Loss: -0.4249  Acc@1: 75.0000 (76.6055)  Acc@5: 100.0000 (98.4168)  time: 0.3615  data: 0.0037  max mem: 2503
Train: Epoch[1/5]  [3100/3750]  eta: 0:04:25  Lr: 0.001875  Loss: -0.4625  Acc@1: 75.0000 (76.5983)  Acc@5: 100.0000 (98.4219)  time: 0.3682  data: 0.0037  max mem: 2503
Train: Epoch[1/5]  [3110/3750]  eta: 0:04:21  Lr: 0.001875  Loss: -0.7838  Acc@1: 75.0000 (76.5951)  Acc@5: 100.0000 (98.4169)  time: 0.3780  data: 0.0038  max mem: 2503
Train: Epoch[1/5]  [3120/3750]  eta: 0:04:17  Lr: 0.001875  Loss: -0.5732  Acc@1: 81.2500 (76.5980)  Acc@5: 100.0000 (98.4140)  time: 0.3718  data: 0.0049  max mem: 2503
Train: Epoch[1/5]  [3130/3750]  eta: 0:04:13  Lr: 0.001875  Loss: -0.2339  Acc@1: 81.2500 (76.5969)  Acc@5: 100.0000 (98.4190)  time: 0.3589  data: 0.0028  max mem: 2503
Train: Epoch[1/5]  [3140/3750]  eta: 0:04:09  Lr: 0.001875  Loss: -0.7348  Acc@1: 75.0000 (76.5978)  Acc@5: 100.0000 (98.4221)  time: 0.3622  data: 0.0023  max mem: 2503
Train: Epoch[1/5]  [3150/3750]  eta: 0:04:05  Lr: 0.001875  Loss: -0.2949  Acc@1: 81.2500 (76.6027)  Acc@5: 100.0000 (98.4251)  time: 0.3674  data: 0.0024  max mem: 2503
Train: Epoch[1/5]  [3160/3750]  eta: 0:04:00  Lr: 0.001875  Loss: -0.7358  Acc@1: 81.2500 (76.6273)  Acc@5: 100.0000 (98.4281)  time: 0.3827  data: 0.0055  max mem: 2503
Train: Epoch[1/5]  [3170/3750]  eta: 0:03:56  Lr: 0.001875  Loss: -0.7550  Acc@1: 81.2500 (76.6458)  Acc@5: 100.0000 (98.4331)  time: 0.3810  data: 0.0095  max mem: 2503
Train: Epoch[1/5]  [3180/3750]  eta: 0:03:52  Lr: 0.001875  Loss: -0.4895  Acc@1: 81.2500 (76.6681)  Acc@5: 100.0000 (98.4380)  time: 0.3725  data: 0.0073  max mem: 2503
Train: Epoch[1/5]  [3190/3750]  eta: 0:03:48  Lr: 0.001875  Loss: -0.6237  Acc@1: 87.5000 (76.6825)  Acc@5: 100.0000 (98.4409)  time: 0.3708  data: 0.0041  max mem: 2503
Train: Epoch[1/5]  [3200/3750]  eta: 0:03:44  Lr: 0.001875  Loss: -0.3480  Acc@1: 81.2500 (76.6889)  Acc@5: 100.0000 (98.4419)  time: 0.3629  data: 0.0040  max mem: 2503
Train: Epoch[1/5]  [3210/3750]  eta: 0:03:40  Lr: 0.001875  Loss: -0.5618  Acc@1: 81.2500 (76.7031)  Acc@5: 100.0000 (98.4409)  time: 0.3638  data: 0.0038  max mem: 2503
Train: Epoch[1/5]  [3220/3750]  eta: 0:03:36  Lr: 0.001875  Loss: -0.0808  Acc@1: 81.2500 (76.7056)  Acc@5: 100.0000 (98.4419)  time: 0.3746  data: 0.0061  max mem: 2503
Train: Epoch[1/5]  [3230/3750]  eta: 0:03:31  Lr: 0.001875  Loss: -1.0002  Acc@1: 81.2500 (76.7255)  Acc@5: 100.0000 (98.4428)  time: 0.3709  data: 0.0063  max mem: 2503
Train: Epoch[1/5]  [3240/3750]  eta: 0:03:27  Lr: 0.001875  Loss: -0.2884  Acc@1: 81.2500 (76.7298)  Acc@5: 100.0000 (98.4476)  time: 0.3579  data: 0.0018  max mem: 2503
Train: Epoch[1/5]  [3250/3750]  eta: 0:03:23  Lr: 0.001875  Loss: -0.5410  Acc@1: 75.0000 (76.7437)  Acc@5: 100.0000 (98.4505)  time: 0.3661  data: 0.0022  max mem: 2503
Train: Epoch[1/5]  [3260/3750]  eta: 0:03:19  Lr: 0.001875  Loss: -0.2215  Acc@1: 81.2500 (76.7556)  Acc@5: 100.0000 (98.4495)  time: 0.3743  data: 0.0033  max mem: 2503
Train: Epoch[1/5]  [3270/3750]  eta: 0:03:15  Lr: 0.001875  Loss: -0.6102  Acc@1: 81.2500 (76.7502)  Acc@5: 100.0000 (98.4485)  time: 0.3727  data: 0.0045  max mem: 2503
Train: Epoch[1/5]  [3280/3750]  eta: 0:03:11  Lr: 0.001875  Loss: -0.5545  Acc@1: 75.0000 (76.7525)  Acc@5: 100.0000 (98.4437)  time: 0.3670  data: 0.0043  max mem: 2503
Train: Epoch[1/5]  [3290/3750]  eta: 0:03:07  Lr: 0.001875  Loss: -0.1620  Acc@1: 75.0000 (76.7643)  Acc@5: 100.0000 (98.4484)  time: 0.3633  data: 0.0020  max mem: 2503
Train: Epoch[1/5]  [3300/3750]  eta: 0:03:03  Lr: 0.001875  Loss: -0.7499  Acc@1: 81.2500 (76.7684)  Acc@5: 100.0000 (98.4493)  time: 0.3726  data: 0.0027  max mem: 2503
Train: Epoch[1/5]  [3310/3750]  eta: 0:02:58  Lr: 0.001875  Loss: -0.4681  Acc@1: 81.2500 (76.7763)  Acc@5: 100.0000 (98.4502)  time: 0.3767  data: 0.0044  max mem: 2503
Train: Epoch[1/5]  [3320/3750]  eta: 0:02:54  Lr: 0.001875  Loss: -0.3783  Acc@1: 75.0000 (76.7747)  Acc@5: 100.0000 (98.4493)  time: 0.3746  data: 0.0077  max mem: 2503
Train: Epoch[1/5]  [3330/3750]  eta: 0:02:50  Lr: 0.001875  Loss: -0.6352  Acc@1: 75.0000 (76.7750)  Acc@5: 100.0000 (98.4445)  time: 0.3808  data: 0.0090  max mem: 2503
Train: Epoch[1/5]  [3340/3750]  eta: 0:02:46  Lr: 0.001875  Loss: -0.5070  Acc@1: 75.0000 (76.7865)  Acc@5: 100.0000 (98.4492)  time: 0.3749  data: 0.0065  max mem: 2503
Train: Epoch[1/5]  [3350/3750]  eta: 0:02:42  Lr: 0.001875  Loss: -0.6248  Acc@1: 75.0000 (76.7980)  Acc@5: 100.0000 (98.4482)  time: 0.3633  data: 0.0036  max mem: 2503
Train: Epoch[1/5]  [3360/3750]  eta: 0:02:38  Lr: 0.001875  Loss: -0.7006  Acc@1: 75.0000 (76.7963)  Acc@5: 100.0000 (98.4528)  time: 0.3634  data: 0.0039  max mem: 2503
Train: Epoch[1/5]  [3370/3750]  eta: 0:02:34  Lr: 0.001875  Loss: -0.4902  Acc@1: 81.2500 (76.8114)  Acc@5: 100.0000 (98.4574)  time: 0.3731  data: 0.0044  max mem: 2503
Train: Epoch[1/5]  [3380/3750]  eta: 0:02:30  Lr: 0.001875  Loss: -0.4943  Acc@1: 81.2500 (76.8079)  Acc@5: 100.0000 (98.4564)  time: 0.3719  data: 0.0046  max mem: 2503
Train: Epoch[1/5]  [3390/3750]  eta: 0:02:26  Lr: 0.001875  Loss: -0.5711  Acc@1: 75.0000 (76.8228)  Acc@5: 100.0000 (98.4592)  time: 0.3624  data: 0.0053  max mem: 2503
Train: Epoch[1/5]  [3400/3750]  eta: 0:02:21  Lr: 0.001875  Loss: -0.7366  Acc@1: 81.2500 (76.8230)  Acc@5: 100.0000 (98.4618)  time: 0.3647  data: 0.0040  max mem: 2503
Train: Epoch[1/5]  [3410/3750]  eta: 0:02:17  Lr: 0.001875  Loss: -0.4778  Acc@1: 75.0000 (76.8250)  Acc@5: 100.0000 (98.4590)  time: 0.3737  data: 0.0031  max mem: 2503
Train: Epoch[1/5]  [3420/3750]  eta: 0:02:13  Lr: 0.001875  Loss: -0.3519  Acc@1: 75.0000 (76.8361)  Acc@5: 100.0000 (98.4599)  time: 0.3690  data: 0.0029  max mem: 2503
Train: Epoch[1/5]  [3430/3750]  eta: 0:02:09  Lr: 0.001875  Loss: -0.5788  Acc@1: 81.2500 (76.8471)  Acc@5: 100.0000 (98.4644)  time: 0.3618  data: 0.0037  max mem: 2503
Train: Epoch[1/5]  [3440/3750]  eta: 0:02:05  Lr: 0.001875  Loss: -0.4909  Acc@1: 81.2500 (76.8563)  Acc@5: 100.0000 (98.4670)  time: 0.3697  data: 0.0083  max mem: 2503
Train: Epoch[1/5]  [3450/3750]  eta: 0:02:01  Lr: 0.001875  Loss: -0.6538  Acc@1: 81.2500 (76.8563)  Acc@5: 100.0000 (98.4678)  time: 0.3802  data: 0.0074  max mem: 2503
Train: Epoch[1/5]  [3460/3750]  eta: 0:01:57  Lr: 0.001875  Loss: -0.3685  Acc@1: 81.2500 (76.8636)  Acc@5: 100.0000 (98.4687)  time: 0.3781  data: 0.0046  max mem: 2503
Train: Epoch[1/5]  [3470/3750]  eta: 0:01:53  Lr: 0.001875  Loss: 0.0255  Acc@1: 75.0000 (76.8637)  Acc@5: 100.0000 (98.4695)  time: 0.3788  data: 0.0047  max mem: 2503
Train: Epoch[1/5]  [3480/3750]  eta: 0:01:49  Lr: 0.001875  Loss: -0.7188  Acc@1: 81.2500 (76.8906)  Acc@5: 100.0000 (98.4703)  time: 0.3704  data: 0.0033  max mem: 2503
Train: Epoch[1/5]  [3490/3750]  eta: 0:01:45  Lr: 0.001875  Loss: -0.2397  Acc@1: 81.2500 (76.8977)  Acc@5: 100.0000 (98.4693)  time: 0.3587  data: 0.0056  max mem: 2503
Train: Epoch[1/5]  [3500/3750]  eta: 0:01:41  Lr: 0.001875  Loss: -0.3340  Acc@1: 81.2500 (76.9012)  Acc@5: 100.0000 (98.4647)  time: 0.3603  data: 0.0044  max mem: 2503
Train: Epoch[1/5]  [3510/3750]  eta: 0:01:37  Lr: 0.001875  Loss: -0.4438  Acc@1: 75.0000 (76.8994)  Acc@5: 100.0000 (98.4620)  time: 0.3589  data: 0.0020  max mem: 2503
Train: Epoch[1/5]  [3520/3750]  eta: 0:01:33  Lr: 0.001875  Loss: -0.7725  Acc@1: 75.0000 (76.9029)  Acc@5: 100.0000 (98.4628)  time: 0.3670  data: 0.0023  max mem: 2503
Train: Epoch[1/5]  [3530/3750]  eta: 0:01:28  Lr: 0.001875  Loss: -0.8499  Acc@1: 75.0000 (76.9134)  Acc@5: 100.0000 (98.4671)  time: 0.3696  data: 0.0026  max mem: 2503
Train: Epoch[1/5]  [3540/3750]  eta: 0:01:24  Lr: 0.001875  Loss: -0.8310  Acc@1: 81.2500 (76.9292)  Acc@5: 100.0000 (98.4715)  time: 0.3610  data: 0.0033  max mem: 2503
Train: Epoch[1/5]  [3550/3750]  eta: 0:01:20  Lr: 0.001875  Loss: -0.6487  Acc@1: 81.2500 (76.9466)  Acc@5: 100.0000 (98.4723)  time: 0.3604  data: 0.0035  max mem: 2503
Train: Epoch[1/5]  [3560/3750]  eta: 0:01:16  Lr: 0.001875  Loss: -0.4628  Acc@1: 81.2500 (76.9587)  Acc@5: 100.0000 (98.4748)  time: 0.3662  data: 0.0023  max mem: 2503
Train: Epoch[1/5]  [3570/3750]  eta: 0:01:12  Lr: 0.001875  Loss: -0.2456  Acc@1: 81.2500 (76.9602)  Acc@5: 100.0000 (98.4756)  time: 0.3717  data: 0.0025  max mem: 2503
Train: Epoch[1/5]  [3580/3750]  eta: 0:01:08  Lr: 0.001875  Loss: -0.2270  Acc@1: 81.2500 (76.9652)  Acc@5: 100.0000 (98.4798)  time: 0.3694  data: 0.0033  max mem: 2503
Train: Epoch[1/5]  [3590/3750]  eta: 0:01:04  Lr: 0.001875  Loss: -0.8259  Acc@1: 81.2500 (76.9772)  Acc@5: 100.0000 (98.4823)  time: 0.3618  data: 0.0026  max mem: 2503
Train: Epoch[1/5]  [3600/3750]  eta: 0:01:00  Lr: 0.001875  Loss: -0.9621  Acc@1: 81.2500 (76.9856)  Acc@5: 100.0000 (98.4831)  time: 0.3603  data: 0.0028  max mem: 2503
Train: Epoch[1/5]  [3610/3750]  eta: 0:00:56  Lr: 0.001875  Loss: -0.8209  Acc@1: 81.2500 (77.0078)  Acc@5: 100.0000 (98.4821)  time: 0.3719  data: 0.0028  max mem: 2503
Train: Epoch[1/5]  [3620/3750]  eta: 0:00:52  Lr: 0.001875  Loss: -0.4696  Acc@1: 81.2500 (77.0126)  Acc@5: 100.0000 (98.4845)  time: 0.3817  data: 0.0038  max mem: 2503
Train: Epoch[1/5]  [3630/3750]  eta: 0:00:48  Lr: 0.001875  Loss: -0.5377  Acc@1: 75.0000 (77.0208)  Acc@5: 100.0000 (98.4870)  time: 0.3838  data: 0.0076  max mem: 2503
Train: Epoch[1/5]  [3640/3750]  eta: 0:00:44  Lr: 0.001875  Loss: -0.1580  Acc@1: 75.0000 (77.0273)  Acc@5: 100.0000 (98.4894)  time: 0.3733  data: 0.0069  max mem: 2503
Train: Epoch[1/5]  [3650/3750]  eta: 0:00:40  Lr: 0.001875  Loss: -0.3389  Acc@1: 81.2500 (77.0474)  Acc@5: 100.0000 (98.4901)  time: 0.3612  data: 0.0038  max mem: 2503
Train: Epoch[1/5]  [3660/3750]  eta: 0:00:36  Lr: 0.001875  Loss: -0.5191  Acc@1: 81.2500 (77.0503)  Acc@5: 100.0000 (98.4926)  time: 0.3691  data: 0.0037  max mem: 2503
Train: Epoch[1/5]  [3670/3750]  eta: 0:00:32  Lr: 0.001875  Loss: -0.3267  Acc@1: 81.2500 (77.0652)  Acc@5: 100.0000 (98.4933)  time: 0.3727  data: 0.0028  max mem: 2503
Train: Epoch[1/5]  [3680/3750]  eta: 0:00:28  Lr: 0.001875  Loss: -0.6652  Acc@1: 81.2500 (77.0664)  Acc@5: 100.0000 (98.4974)  time: 0.3649  data: 0.0025  max mem: 2503
Train: Epoch[1/5]  [3690/3750]  eta: 0:00:24  Lr: 0.001875  Loss: -0.1227  Acc@1: 81.2500 (77.0692)  Acc@5: 100.0000 (98.4930)  time: 0.3627  data: 0.0050  max mem: 2503
Train: Epoch[1/5]  [3700/3750]  eta: 0:00:20  Lr: 0.001875  Loss: -0.5983  Acc@1: 81.2500 (77.0771)  Acc@5: 100.0000 (98.4970)  time: 0.4414  data: 0.0040  max mem: 2503
Train: Epoch[1/5]  [3710/3750]  eta: 0:00:16  Lr: 0.001875  Loss: -0.0918  Acc@1: 81.2500 (77.1019)  Acc@5: 100.0000 (98.4960)  time: 0.5963  data: 0.0015  max mem: 2503
Train: Epoch[1/5]  [3720/3750]  eta: 0:00:12  Lr: 0.001875  Loss: -0.5520  Acc@1: 81.2500 (77.1063)  Acc@5: 100.0000 (98.4950)  time: 0.6495  data: 0.0017  max mem: 2503
Train: Epoch[1/5]  [3730/3750]  eta: 0:00:08  Lr: 0.001875  Loss: -0.2286  Acc@1: 81.2500 (77.1157)  Acc@5: 100.0000 (98.4957)  time: 0.6401  data: 0.0016  max mem: 2503
Train: Epoch[1/5]  [3740/3750]  eta: 0:00:04  Lr: 0.001875  Loss: -0.5309  Acc@1: 81.2500 (77.1218)  Acc@5: 100.0000 (98.4981)  time: 0.6658  data: 0.0013  max mem: 2503
Train: Epoch[1/5]  [3749/3750]  eta: 0:00:00  Lr: 0.001875  Loss: 0.5963  Acc@1: 81.2500 (77.1300)  Acc@5: 100.0000 (98.4983)  time: 0.6695  data: 0.0016  max mem: 2503
Train: Epoch[1/5] Total time: 0:25:25 (0.4067 s / it)
{0: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 1: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 2: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 3: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 4: {0: 0, 1: 300000, 2: 0, 3: 352, 4: 0}, 5: {0: 0, 1: 300000, 2: 0, 3: 352, 4: 0}, 6: {0: 0, 1: 300000, 2: 0, 3: 352, 4: 0}, 7: {0: 0, 1: 300000, 2: 0, 3: 352, 4: 0}, 8: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 9: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 10: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 11: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 12: {0: 0, 1: 0, 2: 0, 3: 90968, 4: 0}, 13: {0: 0, 1: 0, 2: 0, 3: 90968, 4: 0}, 14: {0: 0, 1: 0, 2: 0, 3: 90968, 4: 0}, 15: {0: 0, 1: 0, 2: 0, 3: 90968, 4: 0}, 16: {0: 0, 1: 0, 2: 0, 3: 0, 4: 60000}, 17: {0: 0, 1: 0, 2: 0, 3: 0, 4: 60000}, 18: {0: 0, 1: 0, 2: 0, 3: 0, 4: 60000}, 19: {0: 0, 1: 0, 2: 0, 3: 0, 4: 60000}}
Averaged stats: Lr: 0.001875  Loss: 0.5963  Acc@1: 81.2500 (77.1300)  Acc@5: 100.0000 (98.4983)
Train: Epoch[2/5]  [   0/3750]  eta: 1:06:03  Lr: 0.001875  Loss: -0.7032  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (100.0000)  time: 1.0571  data: 0.3665  max mem: 2503
Train: Epoch[2/5]  [  10/3750]  eta: 0:44:22  Lr: 0.001875  Loss: -0.6854  Acc@1: 81.2500 (79.5455)  Acc@5: 100.0000 (98.8636)  time: 0.7119  data: 0.0341  max mem: 2503
Train: Epoch[2/5]  [  20/3750]  eta: 0:43:37  Lr: 0.001875  Loss: -0.4680  Acc@1: 75.0000 (79.7619)  Acc@5: 100.0000 (99.1071)  time: 0.6840  data: 0.0007  max mem: 2503
Train: Epoch[2/5]  [  30/3750]  eta: 0:42:27  Lr: 0.001875  Loss: -0.6512  Acc@1: 75.0000 (79.8387)  Acc@5: 100.0000 (99.1935)  time: 0.6698  data: 0.0014  max mem: 2503
Train: Epoch[2/5]  [  40/3750]  eta: 0:42:18  Lr: 0.001875  Loss: -0.6695  Acc@1: 75.0000 (79.4207)  Acc@5: 100.0000 (98.9329)  time: 0.6658  data: 0.0013  max mem: 2503
Train: Epoch[2/5]  [  50/3750]  eta: 0:42:05  Lr: 0.001875  Loss: -0.6789  Acc@1: 75.0000 (78.9216)  Acc@5: 100.0000 (99.1422)  time: 0.6793  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [  60/3750]  eta: 0:41:53  Lr: 0.001875  Loss: -0.3576  Acc@1: 81.2500 (78.6885)  Acc@5: 100.0000 (99.0779)  time: 0.6748  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [  70/3750]  eta: 0:41:52  Lr: 0.001875  Loss: -0.8042  Acc@1: 81.2500 (78.6972)  Acc@5: 100.0000 (99.0317)  time: 0.6829  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [  80/3750]  eta: 0:41:40  Lr: 0.001875  Loss: -0.7633  Acc@1: 81.2500 (78.9352)  Acc@5: 100.0000 (99.0741)  time: 0.6823  data: 0.0006  max mem: 2503
Train: Epoch[2/5]  [  90/3750]  eta: 0:41:34  Lr: 0.001875  Loss: -0.7481  Acc@1: 81.2500 (78.9148)  Acc@5: 100.0000 (99.1071)  time: 0.6776  data: 0.0007  max mem: 2503
Train: Epoch[2/5]  [ 100/3750]  eta: 0:41:26  Lr: 0.001875  Loss: -0.7941  Acc@1: 75.0000 (78.8985)  Acc@5: 100.0000 (99.1337)  time: 0.6801  data: 0.0008  max mem: 2503
Train: Epoch[2/5]  [ 110/3750]  eta: 0:41:19  Lr: 0.001875  Loss: -0.3800  Acc@1: 75.0000 (79.0541)  Acc@5: 100.0000 (99.2117)  time: 0.6796  data: 0.0007  max mem: 2503
Train: Epoch[2/5]  [ 120/3750]  eta: 0:41:08  Lr: 0.001875  Loss: -0.2103  Acc@1: 75.0000 (79.1322)  Acc@5: 100.0000 (99.1219)  time: 0.6749  data: 0.0006  max mem: 2503
Train: Epoch[2/5]  [ 130/3750]  eta: 0:41:00  Lr: 0.001875  Loss: -0.6693  Acc@1: 81.2500 (79.1031)  Acc@5: 100.0000 (98.9981)  time: 0.6712  data: 0.0007  max mem: 2503
Train: Epoch[2/5]  [ 140/3750]  eta: 0:40:52  Lr: 0.001875  Loss: -0.4519  Acc@1: 81.2500 (79.3883)  Acc@5: 100.0000 (99.0691)  time: 0.6744  data: 0.0013  max mem: 2503
Train: Epoch[2/5]  [ 150/3750]  eta: 0:40:45  Lr: 0.001875  Loss: -0.6061  Acc@1: 81.2500 (79.3874)  Acc@5: 100.0000 (99.0066)  time: 0.6772  data: 0.0018  max mem: 2503
Train: Epoch[2/5]  [ 160/3750]  eta: 0:40:36  Lr: 0.001875  Loss: -0.7354  Acc@1: 81.2500 (79.4643)  Acc@5: 100.0000 (98.9519)  time: 0.6741  data: 0.0011  max mem: 2503
Train: Epoch[2/5]  [ 170/3750]  eta: 0:40:33  Lr: 0.001875  Loss: -0.2494  Acc@1: 81.2500 (79.4225)  Acc@5: 100.0000 (98.9401)  time: 0.6825  data: 0.0009  max mem: 2503
Train: Epoch[2/5]  [ 180/3750]  eta: 0:40:25  Lr: 0.001875  Loss: -0.5390  Acc@1: 81.2500 (79.2818)  Acc@5: 100.0000 (98.9296)  time: 0.6864  data: 0.0015  max mem: 2503
Train: Epoch[2/5]  [ 190/3750]  eta: 0:40:17  Lr: 0.001875  Loss: -0.4993  Acc@1: 75.0000 (79.0576)  Acc@5: 100.0000 (98.8874)  time: 0.6738  data: 0.0022  max mem: 2503
Train: Epoch[2/5]  [ 200/3750]  eta: 0:40:10  Lr: 0.001875  Loss: -0.8205  Acc@1: 81.2500 (79.2910)  Acc@5: 100.0000 (98.9117)  time: 0.6738  data: 0.0017  max mem: 2503
Train: Epoch[2/5]  [ 210/3750]  eta: 0:39:59  Lr: 0.001875  Loss: -0.4095  Acc@1: 81.2500 (79.2950)  Acc@5: 100.0000 (98.9040)  time: 0.6668  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [ 220/3750]  eta: 0:39:53  Lr: 0.001875  Loss: -0.7393  Acc@1: 81.2500 (79.4118)  Acc@5: 100.0000 (98.8405)  time: 0.6701  data: 0.0011  max mem: 2503
Train: Epoch[2/5]  [ 230/3750]  eta: 0:39:49  Lr: 0.001875  Loss: -0.6607  Acc@1: 75.0000 (79.3019)  Acc@5: 100.0000 (98.8366)  time: 0.6891  data: 0.0011  max mem: 2503
Train: Epoch[2/5]  [ 240/3750]  eta: 0:39:41  Lr: 0.001875  Loss: -0.7122  Acc@1: 75.0000 (79.2790)  Acc@5: 100.0000 (98.8330)  time: 0.6820  data: 0.0013  max mem: 2503
Train: Epoch[2/5]  [ 250/3750]  eta: 0:39:36  Lr: 0.001875  Loss: -0.6976  Acc@1: 81.2500 (79.3576)  Acc@5: 100.0000 (98.8297)  time: 0.6794  data: 0.0012  max mem: 2503
Train: Epoch[2/5]  [ 260/3750]  eta: 0:39:30  Lr: 0.001875  Loss: -0.5980  Acc@1: 81.2500 (79.2146)  Acc@5: 100.0000 (98.8027)  time: 0.6873  data: 0.0013  max mem: 2503
Train: Epoch[2/5]  [ 270/3750]  eta: 0:39:22  Lr: 0.001875  Loss: -0.7830  Acc@1: 81.2500 (79.5203)  Acc@5: 100.0000 (98.8469)  time: 0.6766  data: 0.0019  max mem: 2503
Train: Epoch[2/5]  [ 280/3750]  eta: 0:39:16  Lr: 0.001875  Loss: -0.3599  Acc@1: 81.2500 (79.4484)  Acc@5: 100.0000 (98.8212)  time: 0.6766  data: 0.0012  max mem: 2503
Train: Epoch[2/5]  [ 290/3750]  eta: 0:39:06  Lr: 0.001875  Loss: -0.4069  Acc@1: 81.2500 (79.6392)  Acc@5: 100.0000 (98.8187)  time: 0.6720  data: 0.0006  max mem: 2503
Train: Epoch[2/5]  [ 300/3750]  eta: 0:38:47  Lr: 0.001875  Loss: -0.1065  Acc@1: 81.2500 (79.2982)  Acc@5: 100.0000 (98.7749)  time: 0.6145  data: 0.0006  max mem: 2503
Train: Epoch[2/5]  [ 310/3750]  eta: 0:38:24  Lr: 0.001875  Loss: -0.6449  Acc@1: 75.0000 (79.3207)  Acc@5: 100.0000 (98.7339)  time: 0.5494  data: 0.0006  max mem: 2503
Train: Epoch[2/5]  [ 320/3750]  eta: 0:38:19  Lr: 0.001875  Loss: -0.7523  Acc@1: 81.2500 (79.3224)  Acc@5: 100.0000 (98.7539)  time: 0.6064  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [ 330/3750]  eta: 0:37:49  Lr: 0.001875  Loss: -0.7513  Acc@1: 81.2500 (79.3807)  Acc@5: 100.0000 (98.7915)  time: 0.5618  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [ 340/3750]  eta: 0:37:11  Lr: 0.001875  Loss: -0.9454  Acc@1: 81.2500 (79.2705)  Acc@5: 100.0000 (98.8087)  time: 0.3962  data: 0.0006  max mem: 2503
Train: Epoch[2/5]  [ 350/3750]  eta: 0:36:36  Lr: 0.001875  Loss: -0.1590  Acc@1: 75.0000 (79.2557)  Acc@5: 100.0000 (98.8248)  time: 0.3556  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [ 360/3750]  eta: 0:36:01  Lr: 0.001875  Loss: -0.3166  Acc@1: 81.2500 (79.2590)  Acc@5: 100.0000 (98.8573)  time: 0.3542  data: 0.0008  max mem: 2503
Train: Epoch[2/5]  [ 370/3750]  eta: 0:35:29  Lr: 0.001875  Loss: -0.5433  Acc@1: 81.2500 (79.2116)  Acc@5: 100.0000 (98.8544)  time: 0.3520  data: 0.0023  max mem: 2503
Train: Epoch[2/5]  [ 380/3750]  eta: 0:34:59  Lr: 0.001875  Loss: -0.5621  Acc@1: 81.2500 (79.3635)  Acc@5: 100.0000 (98.8025)  time: 0.3557  data: 0.0036  max mem: 2503
Train: Epoch[2/5]  [ 390/3750]  eta: 0:34:29  Lr: 0.001875  Loss: -0.9214  Acc@1: 87.5000 (79.4437)  Acc@5: 100.0000 (98.7852)  time: 0.3529  data: 0.0021  max mem: 2503
Train: Epoch[2/5]  [ 400/3750]  eta: 0:34:03  Lr: 0.001875  Loss: -0.6950  Acc@1: 87.5000 (79.5355)  Acc@5: 100.0000 (98.7843)  time: 0.3615  data: 0.0010  max mem: 2503
Train: Epoch[2/5]  [ 410/3750]  eta: 0:34:02  Lr: 0.001875  Loss: -0.2985  Acc@1: 87.5000 (79.6077)  Acc@5: 100.0000 (98.7682)  time: 0.5268  data: 0.0009  max mem: 2503
Train: Epoch[2/5]  [ 420/3750]  eta: 0:34:03  Lr: 0.001875  Loss: -0.4093  Acc@1: 81.2500 (79.5279)  Acc@5: 100.0000 (98.7381)  time: 0.6888  data: 0.0006  max mem: 2503
Train: Epoch[2/5]  [ 430/3750]  eta: 0:34:02  Lr: 0.001875  Loss: -0.5691  Acc@1: 81.2500 (79.5679)  Acc@5: 100.0000 (98.7239)  time: 0.6880  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [ 440/3750]  eta: 0:34:00  Lr: 0.001875  Loss: -0.5787  Acc@1: 81.2500 (79.5777)  Acc@5: 100.0000 (98.7103)  time: 0.6748  data: 0.0006  max mem: 2503
Train: Epoch[2/5]  [ 450/3750]  eta: 0:33:58  Lr: 0.001875  Loss: -0.5213  Acc@1: 81.2500 (79.5593)  Acc@5: 100.0000 (98.7251)  time: 0.6715  data: 0.0007  max mem: 2503
Train: Epoch[2/5]  [ 460/3750]  eta: 0:33:56  Lr: 0.001875  Loss: -0.6370  Acc@1: 81.2500 (79.6095)  Acc@5: 100.0000 (98.7256)  time: 0.6745  data: 0.0006  max mem: 2503
Train: Epoch[2/5]  [ 470/3750]  eta: 0:33:54  Lr: 0.001875  Loss: -0.6516  Acc@1: 81.2500 (79.6444)  Acc@5: 100.0000 (98.7527)  time: 0.6817  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [ 480/3750]  eta: 0:33:53  Lr: 0.001875  Loss: -0.2139  Acc@1: 81.2500 (79.6778)  Acc@5: 100.0000 (98.7786)  time: 0.6872  data: 0.0006  max mem: 2503
Train: Epoch[2/5]  [ 490/3750]  eta: 0:33:51  Lr: 0.001875  Loss: -0.5196  Acc@1: 81.2500 (79.6716)  Acc@5: 100.0000 (98.7907)  time: 0.6871  data: 0.0007  max mem: 2503
Train: Epoch[2/5]  [ 500/3750]  eta: 0:33:47  Lr: 0.001875  Loss: -0.4032  Acc@1: 81.2500 (79.7405)  Acc@5: 100.0000 (98.7650)  time: 0.6760  data: 0.0007  max mem: 2503
Train: Epoch[2/5]  [ 510/3750]  eta: 0:33:45  Lr: 0.001875  Loss: -0.1991  Acc@1: 87.5000 (79.7578)  Acc@5: 100.0000 (98.7524)  time: 0.6780  data: 0.0012  max mem: 2503
Train: Epoch[2/5]  [ 520/3750]  eta: 0:33:42  Lr: 0.001875  Loss: -0.6574  Acc@1: 81.2500 (79.7625)  Acc@5: 100.0000 (98.7764)  time: 0.6845  data: 0.0012  max mem: 2503
Train: Epoch[2/5]  [ 530/3750]  eta: 0:33:39  Lr: 0.001875  Loss: -0.8364  Acc@1: 81.2500 (79.7905)  Acc@5: 100.0000 (98.7641)  time: 0.6788  data: 0.0009  max mem: 2503
Train: Epoch[2/5]  [ 540/3750]  eta: 0:33:36  Lr: 0.001875  Loss: -0.2925  Acc@1: 75.0000 (79.7019)  Acc@5: 100.0000 (98.7754)  time: 0.6789  data: 0.0007  max mem: 2503
Train: Epoch[2/5]  [ 550/3750]  eta: 0:33:31  Lr: 0.001875  Loss: -0.6670  Acc@1: 75.0000 (79.7414)  Acc@5: 100.0000 (98.7750)  time: 0.6684  data: 0.0006  max mem: 2503
Train: Epoch[2/5]  [ 560/3750]  eta: 0:33:28  Lr: 0.001875  Loss: -0.7153  Acc@1: 81.2500 (79.7014)  Acc@5: 100.0000 (98.7857)  time: 0.6711  data: 0.0006  max mem: 2503
Train: Epoch[2/5]  [ 570/3750]  eta: 0:33:25  Lr: 0.001875  Loss: -0.7396  Acc@1: 75.0000 (79.6848)  Acc@5: 100.0000 (98.7960)  time: 0.6827  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [ 580/3750]  eta: 0:33:22  Lr: 0.001875  Loss: -0.6270  Acc@1: 81.2500 (79.7547)  Acc@5: 100.0000 (98.7952)  time: 0.6854  data: 0.0006  max mem: 2503
Train: Epoch[2/5]  [ 590/3750]  eta: 0:33:18  Lr: 0.001875  Loss: -0.0646  Acc@1: 81.2500 (79.7589)  Acc@5: 100.0000 (98.8050)  time: 0.6872  data: 0.0007  max mem: 2503
Train: Epoch[2/5]  [ 600/3750]  eta: 0:33:13  Lr: 0.001875  Loss: -0.5251  Acc@1: 81.2500 (79.7733)  Acc@5: 100.0000 (98.8041)  time: 0.6717  data: 0.0008  max mem: 2503
Train: Epoch[2/5]  [ 610/3750]  eta: 0:33:10  Lr: 0.001875  Loss: -0.5020  Acc@1: 81.2500 (79.7770)  Acc@5: 100.0000 (98.8236)  time: 0.6735  data: 0.0006  max mem: 2503
Train: Epoch[2/5]  [ 620/3750]  eta: 0:33:06  Lr: 0.001875  Loss: -0.2717  Acc@1: 81.2500 (79.7403)  Acc@5: 100.0000 (98.8225)  time: 0.6882  data: 0.0006  max mem: 2503
Train: Epoch[2/5]  [ 630/3750]  eta: 0:33:03  Lr: 0.001875  Loss: 0.0299  Acc@1: 75.0000 (79.6850)  Acc@5: 100.0000 (98.8411)  time: 0.6898  data: 0.0011  max mem: 2503
Train: Epoch[2/5]  [ 640/3750]  eta: 0:32:59  Lr: 0.001875  Loss: -0.4223  Acc@1: 75.0000 (79.6217)  Acc@5: 100.0000 (98.8397)  time: 0.6905  data: 0.0010  max mem: 2503
Train: Epoch[2/5]  [ 650/3750]  eta: 0:32:54  Lr: 0.001875  Loss: -0.4357  Acc@1: 75.0000 (79.6083)  Acc@5: 100.0000 (98.8287)  time: 0.6768  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [ 660/3750]  eta: 0:32:50  Lr: 0.001875  Loss: -0.4940  Acc@1: 81.2500 (79.6142)  Acc@5: 100.0000 (98.8464)  time: 0.6776  data: 0.0011  max mem: 2503
Train: Epoch[2/5]  [ 670/3750]  eta: 0:32:46  Lr: 0.001875  Loss: -0.8971  Acc@1: 81.2500 (79.5455)  Acc@5: 100.0000 (98.8357)  time: 0.6888  data: 0.0012  max mem: 2503
Train: Epoch[2/5]  [ 680/3750]  eta: 0:32:42  Lr: 0.001875  Loss: -0.7046  Acc@1: 75.0000 (79.5613)  Acc@5: 100.0000 (98.8253)  time: 0.6861  data: 0.0007  max mem: 2503
Train: Epoch[2/5]  [ 690/3750]  eta: 0:32:38  Lr: 0.001875  Loss: -0.5894  Acc@1: 81.2500 (79.5315)  Acc@5: 100.0000 (98.8242)  time: 0.6890  data: 0.0006  max mem: 2503
Train: Epoch[2/5]  [ 700/3750]  eta: 0:32:32  Lr: 0.001875  Loss: -0.4952  Acc@1: 81.2500 (79.5560)  Acc@5: 100.0000 (98.8231)  time: 0.6708  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [ 710/3750]  eta: 0:32:27  Lr: 0.001875  Loss: -0.3703  Acc@1: 81.2500 (79.5183)  Acc@5: 100.0000 (98.8133)  time: 0.6695  data: 0.0007  max mem: 2503
Train: Epoch[2/5]  [ 720/3750]  eta: 0:32:23  Lr: 0.001875  Loss: -0.2976  Acc@1: 75.0000 (79.4469)  Acc@5: 100.0000 (98.7864)  time: 0.6877  data: 0.0008  max mem: 2503
Train: Epoch[2/5]  [ 730/3750]  eta: 0:32:18  Lr: 0.001875  Loss: -0.5810  Acc@1: 75.0000 (79.4118)  Acc@5: 100.0000 (98.7859)  time: 0.6814  data: 0.0010  max mem: 2503
Train: Epoch[2/5]  [ 740/3750]  eta: 0:32:14  Lr: 0.001875  Loss: -0.5569  Acc@1: 75.0000 (79.3860)  Acc@5: 100.0000 (98.7686)  time: 0.6845  data: 0.0008  max mem: 2503
Train: Epoch[2/5]  [ 750/3750]  eta: 0:32:08  Lr: 0.001875  Loss: -0.0904  Acc@1: 81.2500 (79.4108)  Acc@5: 100.0000 (98.7766)  time: 0.6741  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [ 760/3750]  eta: 0:31:50  Lr: 0.001875  Loss: -0.5489  Acc@1: 81.2500 (79.3693)  Acc@5: 100.0000 (98.7763)  time: 0.5008  data: 0.0006  max mem: 2503
Train: Epoch[2/5]  [ 770/3750]  eta: 0:31:32  Lr: 0.001875  Loss: -0.6466  Acc@1: 81.2500 (79.3855)  Acc@5: 100.0000 (98.7922)  time: 0.3459  data: 0.0006  max mem: 2503
Train: Epoch[2/5]  [ 780/3750]  eta: 0:31:14  Lr: 0.001875  Loss: -0.7920  Acc@1: 81.2500 (79.3614)  Acc@5: 100.0000 (98.7916)  time: 0.3454  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [ 790/3750]  eta: 0:30:58  Lr: 0.001875  Loss: -0.7542  Acc@1: 81.2500 (79.3616)  Acc@5: 100.0000 (98.7832)  time: 0.3490  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [ 800/3750]  eta: 0:30:41  Lr: 0.001875  Loss: -0.5547  Acc@1: 81.2500 (79.3773)  Acc@5: 100.0000 (98.7906)  time: 0.3522  data: 0.0018  max mem: 2503
Train: Epoch[2/5]  [ 810/3750]  eta: 0:30:26  Lr: 0.001875  Loss: -0.2412  Acc@1: 75.0000 (79.3696)  Acc@5: 100.0000 (98.7978)  time: 0.3584  data: 0.0034  max mem: 2503
Train: Epoch[2/5]  [ 820/3750]  eta: 0:30:10  Lr: 0.001875  Loss: -0.4638  Acc@1: 81.2500 (79.4153)  Acc@5: 100.0000 (98.7972)  time: 0.3588  data: 0.0034  max mem: 2503
Train: Epoch[2/5]  [ 830/3750]  eta: 0:29:54  Lr: 0.001875  Loss: -0.6964  Acc@1: 81.2500 (79.4750)  Acc@5: 100.0000 (98.8117)  time: 0.3517  data: 0.0026  max mem: 2503
Train: Epoch[2/5]  [ 840/3750]  eta: 0:29:39  Lr: 0.001875  Loss: -0.5662  Acc@1: 81.2500 (79.5036)  Acc@5: 100.0000 (98.8184)  time: 0.3517  data: 0.0031  max mem: 2503
Train: Epoch[2/5]  [ 850/3750]  eta: 0:29:24  Lr: 0.001875  Loss: -0.2506  Acc@1: 81.2500 (79.4653)  Acc@5: 100.0000 (98.8029)  time: 0.3551  data: 0.0036  max mem: 2503
Train: Epoch[2/5]  [ 860/3750]  eta: 0:29:10  Lr: 0.001875  Loss: -0.1697  Acc@1: 75.0000 (79.4643)  Acc@5: 100.0000 (98.8095)  time: 0.3605  data: 0.0049  max mem: 2503
Train: Epoch[2/5]  [ 870/3750]  eta: 0:28:56  Lr: 0.001875  Loss: -0.4392  Acc@1: 81.2500 (79.4848)  Acc@5: 100.0000 (98.8232)  time: 0.3635  data: 0.0073  max mem: 2503
Train: Epoch[2/5]  [ 880/3750]  eta: 0:28:42  Lr: 0.001875  Loss: -0.9206  Acc@1: 81.2500 (79.5119)  Acc@5: 100.0000 (98.8295)  time: 0.3607  data: 0.0062  max mem: 2503
Train: Epoch[2/5]  [ 890/3750]  eta: 0:28:28  Lr: 0.001875  Loss: -0.6590  Acc@1: 81.2500 (79.5314)  Acc@5: 100.0000 (98.8356)  time: 0.3572  data: 0.0029  max mem: 2503
Train: Epoch[2/5]  [ 900/3750]  eta: 0:28:15  Lr: 0.001875  Loss: -0.4880  Acc@1: 81.2500 (79.4950)  Acc@5: 100.0000 (98.8416)  time: 0.3563  data: 0.0021  max mem: 2503
Train: Epoch[2/5]  [ 910/3750]  eta: 0:28:01  Lr: 0.001875  Loss: -0.4936  Acc@1: 75.0000 (79.4457)  Acc@5: 100.0000 (98.8337)  time: 0.3561  data: 0.0031  max mem: 2503
Train: Epoch[2/5]  [ 920/3750]  eta: 0:27:48  Lr: 0.001875  Loss: -0.7010  Acc@1: 81.2500 (79.4517)  Acc@5: 100.0000 (98.8396)  time: 0.3575  data: 0.0026  max mem: 2503
Train: Epoch[2/5]  [ 930/3750]  eta: 0:27:35  Lr: 0.001875  Loss: -0.2945  Acc@1: 81.2500 (79.4441)  Acc@5: 100.0000 (98.8252)  time: 0.3617  data: 0.0052  max mem: 2503
Train: Epoch[2/5]  [ 940/3750]  eta: 0:27:23  Lr: 0.001875  Loss: -0.4382  Acc@1: 75.0000 (79.4434)  Acc@5: 100.0000 (98.8045)  time: 0.3627  data: 0.0060  max mem: 2503
Train: Epoch[2/5]  [ 950/3750]  eta: 0:27:10  Lr: 0.001875  Loss: -0.7726  Acc@1: 75.0000 (79.4164)  Acc@5: 100.0000 (98.8105)  time: 0.3548  data: 0.0021  max mem: 2503
Train: Epoch[2/5]  [ 960/3750]  eta: 0:26:57  Lr: 0.001875  Loss: -0.2224  Acc@1: 75.0000 (79.3900)  Acc@5: 100.0000 (98.8098)  time: 0.3506  data: 0.0017  max mem: 2503
Train: Epoch[2/5]  [ 970/3750]  eta: 0:26:45  Lr: 0.001875  Loss: -0.5393  Acc@1: 75.0000 (79.3769)  Acc@5: 100.0000 (98.8221)  time: 0.3547  data: 0.0027  max mem: 2503
Train: Epoch[2/5]  [ 980/3750]  eta: 0:26:33  Lr: 0.001875  Loss: -0.5758  Acc@1: 81.2500 (79.3897)  Acc@5: 100.0000 (98.8214)  time: 0.3582  data: 0.0039  max mem: 2503
Train: Epoch[2/5]  [ 990/3750]  eta: 0:26:21  Lr: 0.001875  Loss: -0.4800  Acc@1: 81.2500 (79.3958)  Acc@5: 100.0000 (98.8269)  time: 0.3592  data: 0.0041  max mem: 2503
Train: Epoch[2/5]  [1000/3750]  eta: 0:26:10  Lr: 0.001875  Loss: -0.4619  Acc@1: 81.2500 (79.4018)  Acc@5: 100.0000 (98.8262)  time: 0.3630  data: 0.0024  max mem: 2503
Train: Epoch[2/5]  [1010/3750]  eta: 0:25:59  Lr: 0.001875  Loss: -0.3900  Acc@1: 81.2500 (79.3769)  Acc@5: 100.0000 (98.8316)  time: 0.3677  data: 0.0040  max mem: 2503
Train: Epoch[2/5]  [1020/3750]  eta: 0:25:48  Lr: 0.001875  Loss: -0.6220  Acc@1: 81.2500 (79.4258)  Acc@5: 100.0000 (98.8308)  time: 0.3647  data: 0.0059  max mem: 2503
Train: Epoch[2/5]  [1030/3750]  eta: 0:25:36  Lr: 0.001875  Loss: -0.7335  Acc@1: 87.5000 (79.4677)  Acc@5: 100.0000 (98.8361)  time: 0.3589  data: 0.0037  max mem: 2503
Train: Epoch[2/5]  [1040/3750]  eta: 0:25:25  Lr: 0.001875  Loss: -0.7942  Acc@1: 81.2500 (79.4729)  Acc@5: 100.0000 (98.8413)  time: 0.3545  data: 0.0021  max mem: 2503
Train: Epoch[2/5]  [1050/3750]  eta: 0:25:14  Lr: 0.001875  Loss: -0.4866  Acc@1: 81.2500 (79.4838)  Acc@5: 100.0000 (98.8344)  time: 0.3534  data: 0.0026  max mem: 2503
Train: Epoch[2/5]  [1060/3750]  eta: 0:25:03  Lr: 0.001875  Loss: -0.7044  Acc@1: 81.2500 (79.4298)  Acc@5: 100.0000 (98.8395)  time: 0.3561  data: 0.0019  max mem: 2503
Train: Epoch[2/5]  [1070/3750]  eta: 0:24:53  Lr: 0.001875  Loss: -0.9733  Acc@1: 81.2500 (79.4526)  Acc@5: 100.0000 (98.8329)  time: 0.3557  data: 0.0014  max mem: 2503
Train: Epoch[2/5]  [1080/3750]  eta: 0:24:42  Lr: 0.001875  Loss: -0.7779  Acc@1: 81.2500 (79.5097)  Acc@5: 100.0000 (98.8437)  time: 0.3564  data: 0.0037  max mem: 2503
Train: Epoch[2/5]  [1090/3750]  eta: 0:24:32  Lr: 0.001875  Loss: -0.3545  Acc@1: 81.2500 (79.5027)  Acc@5: 100.0000 (98.8428)  time: 0.3600  data: 0.0033  max mem: 2503
Train: Epoch[2/5]  [1100/3750]  eta: 0:24:22  Lr: 0.001875  Loss: -0.5497  Acc@1: 81.2500 (79.5300)  Acc@5: 100.0000 (98.8476)  time: 0.3621  data: 0.0033  max mem: 2503
Train: Epoch[2/5]  [1110/3750]  eta: 0:24:12  Lr: 0.001875  Loss: -0.6091  Acc@1: 81.2500 (79.5061)  Acc@5: 100.0000 (98.8524)  time: 0.3591  data: 0.0032  max mem: 2503
Train: Epoch[2/5]  [1120/3750]  eta: 0:24:02  Lr: 0.001875  Loss: -0.8388  Acc@1: 81.2500 (79.5495)  Acc@5: 100.0000 (98.8570)  time: 0.3550  data: 0.0021  max mem: 2503
Train: Epoch[2/5]  [1130/3750]  eta: 0:23:52  Lr: 0.001875  Loss: -0.7364  Acc@1: 81.2500 (79.5038)  Acc@5: 100.0000 (98.8616)  time: 0.3552  data: 0.0031  max mem: 2503
Train: Epoch[2/5]  [1140/3750]  eta: 0:23:42  Lr: 0.001875  Loss: -0.5700  Acc@1: 81.2500 (79.5465)  Acc@5: 100.0000 (98.8606)  time: 0.3549  data: 0.0030  max mem: 2503
Train: Epoch[2/5]  [1150/3750]  eta: 0:23:32  Lr: 0.001875  Loss: -0.3205  Acc@1: 81.2500 (79.5938)  Acc@5: 100.0000 (98.8543)  time: 0.3557  data: 0.0023  max mem: 2503
Train: Epoch[2/5]  [1160/3750]  eta: 0:23:23  Lr: 0.001875  Loss: -0.4401  Acc@1: 81.2500 (79.6081)  Acc@5: 100.0000 (98.8641)  time: 0.3598  data: 0.0018  max mem: 2503
Train: Epoch[2/5]  [1170/3750]  eta: 0:23:13  Lr: 0.001875  Loss: -0.1394  Acc@1: 81.2500 (79.6221)  Acc@5: 100.0000 (98.8738)  time: 0.3628  data: 0.0040  max mem: 2503
Train: Epoch[2/5]  [1180/3750]  eta: 0:23:04  Lr: 0.001875  Loss: -0.8045  Acc@1: 81.2500 (79.6518)  Acc@5: 100.0000 (98.8622)  time: 0.3601  data: 0.0041  max mem: 2503
Train: Epoch[2/5]  [1190/3750]  eta: 0:22:55  Lr: 0.001875  Loss: -0.4808  Acc@1: 81.2500 (79.6862)  Acc@5: 100.0000 (98.8717)  time: 0.3563  data: 0.0019  max mem: 2503
Train: Epoch[2/5]  [1200/3750]  eta: 0:22:46  Lr: 0.001875  Loss: -0.8076  Acc@1: 81.2500 (79.7044)  Acc@5: 100.0000 (98.8759)  time: 0.3614  data: 0.0022  max mem: 2503
Train: Epoch[2/5]  [1210/3750]  eta: 0:22:36  Lr: 0.001875  Loss: -0.5688  Acc@1: 81.2500 (79.7327)  Acc@5: 100.0000 (98.8646)  time: 0.3606  data: 0.0018  max mem: 2503
Train: Epoch[2/5]  [1220/3750]  eta: 0:22:27  Lr: 0.001875  Loss: -0.1909  Acc@1: 81.2500 (79.7195)  Acc@5: 100.0000 (98.8636)  time: 0.3552  data: 0.0025  max mem: 2503
Train: Epoch[2/5]  [1230/3750]  eta: 0:22:19  Lr: 0.001875  Loss: -0.4406  Acc@1: 75.0000 (79.7065)  Acc@5: 100.0000 (98.8729)  time: 0.3633  data: 0.0029  max mem: 2503
Train: Epoch[2/5]  [1240/3750]  eta: 0:22:10  Lr: 0.001875  Loss: -0.5551  Acc@1: 81.2500 (79.7240)  Acc@5: 100.0000 (98.8719)  time: 0.3675  data: 0.0033  max mem: 2503
Train: Epoch[2/5]  [1250/3750]  eta: 0:22:01  Lr: 0.001875  Loss: -0.3287  Acc@1: 81.2500 (79.7262)  Acc@5: 100.0000 (98.8759)  time: 0.3625  data: 0.0048  max mem: 2503
Train: Epoch[2/5]  [1260/3750]  eta: 0:21:53  Lr: 0.001875  Loss: -0.7840  Acc@1: 81.2500 (79.7433)  Acc@5: 100.0000 (98.8848)  time: 0.3571  data: 0.0034  max mem: 2503
Train: Epoch[2/5]  [1270/3750]  eta: 0:21:44  Lr: 0.001875  Loss: -0.2526  Acc@1: 81.2500 (79.7502)  Acc@5: 100.0000 (98.8788)  time: 0.3551  data: 0.0017  max mem: 2503
Train: Epoch[2/5]  [1280/3750]  eta: 0:21:35  Lr: 0.001875  Loss: -0.5853  Acc@1: 81.2500 (79.7814)  Acc@5: 100.0000 (98.8778)  time: 0.3564  data: 0.0017  max mem: 2503
Train: Epoch[2/5]  [1290/3750]  eta: 0:21:27  Lr: 0.001875  Loss: -0.1780  Acc@1: 81.2500 (79.7928)  Acc@5: 100.0000 (98.8672)  time: 0.3580  data: 0.0042  max mem: 2503
Train: Epoch[2/5]  [1300/3750]  eta: 0:21:19  Lr: 0.001875  Loss: -0.7935  Acc@1: 81.2500 (79.7992)  Acc@5: 100.0000 (98.8711)  time: 0.3595  data: 0.0054  max mem: 2503
Train: Epoch[2/5]  [1310/3750]  eta: 0:21:11  Lr: 0.001875  Loss: -0.8036  Acc@1: 81.2500 (79.8293)  Acc@5: 100.0000 (98.8797)  time: 0.3603  data: 0.0045  max mem: 2503
Train: Epoch[2/5]  [1320/3750]  eta: 0:21:02  Lr: 0.001875  Loss: -0.5329  Acc@1: 81.2500 (79.8401)  Acc@5: 100.0000 (98.8882)  time: 0.3631  data: 0.0038  max mem: 2503
Train: Epoch[2/5]  [1330/3750]  eta: 0:20:54  Lr: 0.001875  Loss: -0.2001  Acc@1: 81.2500 (79.8601)  Acc@5: 100.0000 (98.8871)  time: 0.3616  data: 0.0050  max mem: 2503
Train: Epoch[2/5]  [1340/3750]  eta: 0:20:46  Lr: 0.001875  Loss: -0.0371  Acc@1: 75.0000 (79.8192)  Acc@5: 100.0000 (98.8861)  time: 0.3563  data: 0.0046  max mem: 2503
Train: Epoch[2/5]  [1350/3750]  eta: 0:20:38  Lr: 0.001875  Loss: -0.5448  Acc@1: 81.2500 (79.8251)  Acc@5: 100.0000 (98.8851)  time: 0.3594  data: 0.0033  max mem: 2503
Train: Epoch[2/5]  [1360/3750]  eta: 0:20:30  Lr: 0.001875  Loss: -0.6501  Acc@1: 81.2500 (79.8815)  Acc@5: 100.0000 (98.8887)  time: 0.3575  data: 0.0031  max mem: 2503
Train: Epoch[2/5]  [1370/3750]  eta: 0:20:22  Lr: 0.001875  Loss: -0.7376  Acc@1: 87.5000 (79.8824)  Acc@5: 100.0000 (98.8877)  time: 0.3531  data: 0.0018  max mem: 2503
Train: Epoch[2/5]  [1380/3750]  eta: 0:20:14  Lr: 0.001875  Loss: -0.5299  Acc@1: 81.2500 (79.8832)  Acc@5: 100.0000 (98.8957)  time: 0.3561  data: 0.0027  max mem: 2503
Train: Epoch[2/5]  [1390/3750]  eta: 0:20:07  Lr: 0.001875  Loss: -0.5025  Acc@1: 81.2500 (79.9110)  Acc@5: 100.0000 (98.8992)  time: 0.3550  data: 0.0031  max mem: 2503
Train: Epoch[2/5]  [1400/3750]  eta: 0:19:59  Lr: 0.001875  Loss: -0.4083  Acc@1: 81.2500 (79.9161)  Acc@5: 100.0000 (98.8936)  time: 0.3544  data: 0.0025  max mem: 2503
Train: Epoch[2/5]  [1410/3750]  eta: 0:19:51  Lr: 0.001875  Loss: -0.7078  Acc@1: 81.2500 (79.9256)  Acc@5: 100.0000 (98.8749)  time: 0.3552  data: 0.0029  max mem: 2503
Train: Epoch[2/5]  [1420/3750]  eta: 0:19:44  Lr: 0.001875  Loss: -0.8482  Acc@1: 87.5000 (79.9657)  Acc@5: 100.0000 (98.8784)  time: 0.3581  data: 0.0049  max mem: 2503
Train: Epoch[2/5]  [1430/3750]  eta: 0:19:36  Lr: 0.001875  Loss: -0.0829  Acc@1: 87.5000 (79.9921)  Acc@5: 100.0000 (98.8819)  time: 0.3639  data: 0.0071  max mem: 2503
Train: Epoch[2/5]  [1440/3750]  eta: 0:19:29  Lr: 0.001875  Loss: -0.3415  Acc@1: 81.2500 (79.9792)  Acc@5: 100.0000 (98.8723)  time: 0.3624  data: 0.0045  max mem: 2503
Train: Epoch[2/5]  [1450/3750]  eta: 0:19:22  Lr: 0.001875  Loss: -0.3071  Acc@1: 75.0000 (79.9363)  Acc@5: 100.0000 (98.8715)  time: 0.3596  data: 0.0041  max mem: 2503
Train: Epoch[2/5]  [1460/3750]  eta: 0:19:14  Lr: 0.001875  Loss: -0.8283  Acc@1: 75.0000 (79.9196)  Acc@5: 100.0000 (98.8664)  time: 0.3673  data: 0.0067  max mem: 2503
Train: Epoch[2/5]  [1470/3750]  eta: 0:19:07  Lr: 0.001875  Loss: -0.3890  Acc@1: 75.0000 (79.8819)  Acc@5: 100.0000 (98.8741)  time: 0.3715  data: 0.0064  max mem: 2503
Train: Epoch[2/5]  [1480/3750]  eta: 0:19:00  Lr: 0.001875  Loss: -0.7537  Acc@1: 81.2500 (79.8996)  Acc@5: 100.0000 (98.8732)  time: 0.3659  data: 0.0044  max mem: 2503
Train: Epoch[2/5]  [1490/3750]  eta: 0:18:53  Lr: 0.001875  Loss: -0.3617  Acc@1: 81.2500 (79.8877)  Acc@5: 100.0000 (98.8808)  time: 0.3581  data: 0.0032  max mem: 2503
Train: Epoch[2/5]  [1500/3750]  eta: 0:18:46  Lr: 0.001875  Loss: -0.4518  Acc@1: 75.0000 (79.8676)  Acc@5: 100.0000 (98.8841)  time: 0.3556  data: 0.0028  max mem: 2503
Train: Epoch[2/5]  [1510/3750]  eta: 0:18:39  Lr: 0.001875  Loss: -0.6113  Acc@1: 75.0000 (79.8478)  Acc@5: 100.0000 (98.8708)  time: 0.3580  data: 0.0015  max mem: 2503
Train: Epoch[2/5]  [1520/3750]  eta: 0:18:31  Lr: 0.001875  Loss: -0.6278  Acc@1: 81.2500 (79.8611)  Acc@5: 100.0000 (98.8741)  time: 0.3567  data: 0.0016  max mem: 2503
Train: Epoch[2/5]  [1530/3750]  eta: 0:18:24  Lr: 0.001875  Loss: -0.3663  Acc@1: 81.2500 (79.8334)  Acc@5: 100.0000 (98.8651)  time: 0.3544  data: 0.0027  max mem: 2503
Train: Epoch[2/5]  [1540/3750]  eta: 0:18:17  Lr: 0.001875  Loss: -0.6999  Acc@1: 81.2500 (79.8670)  Acc@5: 100.0000 (98.8725)  time: 0.3563  data: 0.0044  max mem: 2503
Train: Epoch[2/5]  [1550/3750]  eta: 0:18:10  Lr: 0.001875  Loss: -0.4942  Acc@1: 81.2500 (79.8598)  Acc@5: 100.0000 (98.8757)  time: 0.3530  data: 0.0031  max mem: 2503
Train: Epoch[2/5]  [1560/3750]  eta: 0:18:03  Lr: 0.001875  Loss: -0.8854  Acc@1: 81.2500 (79.8847)  Acc@5: 100.0000 (98.8829)  time: 0.3544  data: 0.0025  max mem: 2503
Train: Epoch[2/5]  [1570/3750]  eta: 0:17:57  Lr: 0.001875  Loss: -0.3561  Acc@1: 81.2500 (79.8934)  Acc@5: 100.0000 (98.8861)  time: 0.3611  data: 0.0044  max mem: 2503
Train: Epoch[2/5]  [1580/3750]  eta: 0:17:50  Lr: 0.001875  Loss: -0.6074  Acc@1: 81.2500 (79.9178)  Acc@5: 100.0000 (98.8852)  time: 0.3607  data: 0.0052  max mem: 2503
Train: Epoch[2/5]  [1590/3750]  eta: 0:17:43  Lr: 0.001875  Loss: -0.4447  Acc@1: 81.2500 (79.9340)  Acc@5: 100.0000 (98.8883)  time: 0.3580  data: 0.0045  max mem: 2503
Train: Epoch[2/5]  [1600/3750]  eta: 0:17:36  Lr: 0.001875  Loss: -0.4586  Acc@1: 81.2500 (79.9344)  Acc@5: 100.0000 (98.8874)  time: 0.3522  data: 0.0025  max mem: 2503
Train: Epoch[2/5]  [1610/3750]  eta: 0:17:29  Lr: 0.001875  Loss: -0.7654  Acc@1: 81.2500 (79.9271)  Acc@5: 100.0000 (98.8866)  time: 0.3538  data: 0.0045  max mem: 2503
Train: Epoch[2/5]  [1620/3750]  eta: 0:17:23  Lr: 0.001875  Loss: -0.4898  Acc@1: 81.2500 (79.9391)  Acc@5: 100.0000 (98.8857)  time: 0.3682  data: 0.0053  max mem: 2503
Train: Epoch[2/5]  [1630/3750]  eta: 0:17:16  Lr: 0.001875  Loss: -0.1829  Acc@1: 81.2500 (79.9280)  Acc@5: 100.0000 (98.8887)  time: 0.3670  data: 0.0041  max mem: 2503
Train: Epoch[2/5]  [1640/3750]  eta: 0:17:10  Lr: 0.001875  Loss: -0.4767  Acc@1: 81.2500 (79.9398)  Acc@5: 100.0000 (98.8803)  time: 0.3556  data: 0.0051  max mem: 2503
Train: Epoch[2/5]  [1650/3750]  eta: 0:17:03  Lr: 0.001875  Loss: -0.2835  Acc@1: 75.0000 (79.9364)  Acc@5: 100.0000 (98.8795)  time: 0.3546  data: 0.0059  max mem: 2503
Train: Epoch[2/5]  [1660/3750]  eta: 0:16:57  Lr: 0.001875  Loss: -0.3341  Acc@1: 75.0000 (79.9255)  Acc@5: 100.0000 (98.8825)  time: 0.3584  data: 0.0035  max mem: 2503
Train: Epoch[2/5]  [1670/3750]  eta: 0:16:50  Lr: 0.001875  Loss: -0.6542  Acc@1: 81.2500 (79.9297)  Acc@5: 100.0000 (98.8854)  time: 0.3585  data: 0.0015  max mem: 2503
Train: Epoch[2/5]  [1680/3750]  eta: 0:16:44  Lr: 0.001875  Loss: -0.3456  Acc@1: 81.2500 (79.9115)  Acc@5: 100.0000 (98.8883)  time: 0.3571  data: 0.0039  max mem: 2503
Train: Epoch[2/5]  [1690/3750]  eta: 0:16:37  Lr: 0.001875  Loss: -0.5529  Acc@1: 81.2500 (79.9379)  Acc@5: 100.0000 (98.8875)  time: 0.3570  data: 0.0041  max mem: 2503
Train: Epoch[2/5]  [1700/3750]  eta: 0:16:31  Lr: 0.001875  Loss: -0.7239  Acc@1: 87.5000 (79.9530)  Acc@5: 100.0000 (98.8904)  time: 0.3556  data: 0.0021  max mem: 2503
Train: Epoch[2/5]  [1710/3750]  eta: 0:16:25  Lr: 0.001875  Loss: -0.3924  Acc@1: 75.0000 (79.9277)  Acc@5: 100.0000 (98.8932)  time: 0.3566  data: 0.0022  max mem: 2503
Train: Epoch[2/5]  [1720/3750]  eta: 0:16:18  Lr: 0.001875  Loss: -0.4749  Acc@1: 75.0000 (79.9208)  Acc@5: 100.0000 (98.8996)  time: 0.3566  data: 0.0025  max mem: 2503
Train: Epoch[2/5]  [1730/3750]  eta: 0:16:12  Lr: 0.001875  Loss: -0.3862  Acc@1: 81.2500 (79.8960)  Acc@5: 100.0000 (98.8988)  time: 0.3591  data: 0.0042  max mem: 2503
Train: Epoch[2/5]  [1740/3750]  eta: 0:16:06  Lr: 0.001875  Loss: -0.4840  Acc@1: 75.0000 (79.8966)  Acc@5: 100.0000 (98.8979)  time: 0.3617  data: 0.0038  max mem: 2503
Train: Epoch[2/5]  [1750/3750]  eta: 0:16:00  Lr: 0.001875  Loss: -0.2047  Acc@1: 75.0000 (79.8794)  Acc@5: 100.0000 (98.9006)  time: 0.3613  data: 0.0022  max mem: 2503
Train: Epoch[2/5]  [1760/3750]  eta: 0:15:54  Lr: 0.001875  Loss: -0.1317  Acc@1: 81.2500 (79.8765)  Acc@5: 100.0000 (98.9033)  time: 0.3568  data: 0.0022  max mem: 2503
Train: Epoch[2/5]  [1770/3750]  eta: 0:15:48  Lr: 0.001875  Loss: -0.3481  Acc@1: 81.2500 (79.9019)  Acc@5: 100.0000 (98.9095)  time: 0.3629  data: 0.0031  max mem: 2503
Train: Epoch[2/5]  [1780/3750]  eta: 0:15:42  Lr: 0.001875  Loss: -0.6226  Acc@1: 81.2500 (79.9024)  Acc@5: 100.0000 (98.9121)  time: 0.3718  data: 0.0040  max mem: 2503
Train: Epoch[2/5]  [1790/3750]  eta: 0:15:36  Lr: 0.001875  Loss: -0.6499  Acc@1: 81.2500 (79.8960)  Acc@5: 100.0000 (98.9077)  time: 0.3663  data: 0.0027  max mem: 2503
Train: Epoch[2/5]  [1800/3750]  eta: 0:15:29  Lr: 0.001875  Loss: -0.3887  Acc@1: 81.2500 (79.8827)  Acc@5: 100.0000 (98.9069)  time: 0.3596  data: 0.0019  max mem: 2503
Train: Epoch[2/5]  [1810/3750]  eta: 0:15:23  Lr: 0.001875  Loss: -0.5330  Acc@1: 81.2500 (79.9144)  Acc@5: 100.0000 (98.9129)  time: 0.3539  data: 0.0014  max mem: 2503
Train: Epoch[2/5]  [1820/3750]  eta: 0:15:17  Lr: 0.001875  Loss: -0.4071  Acc@1: 81.2500 (79.8874)  Acc@5: 100.0000 (98.9154)  time: 0.3542  data: 0.0014  max mem: 2503
Train: Epoch[2/5]  [1830/3750]  eta: 0:15:11  Lr: 0.001875  Loss: -0.1650  Acc@1: 75.0000 (79.8676)  Acc@5: 100.0000 (98.9179)  time: 0.3552  data: 0.0025  max mem: 2503
Train: Epoch[2/5]  [1840/3750]  eta: 0:15:05  Lr: 0.001875  Loss: -0.4144  Acc@1: 75.0000 (79.8513)  Acc@5: 100.0000 (98.9170)  time: 0.3548  data: 0.0048  max mem: 2503
Train: Epoch[2/5]  [1850/3750]  eta: 0:14:59  Lr: 0.001875  Loss: -0.2463  Acc@1: 81.2500 (79.8690)  Acc@5: 100.0000 (98.9161)  time: 0.3592  data: 0.0043  max mem: 2503
Train: Epoch[2/5]  [1860/3750]  eta: 0:14:53  Lr: 0.001875  Loss: -0.8137  Acc@1: 81.2500 (79.8731)  Acc@5: 100.0000 (98.9119)  time: 0.3578  data: 0.0013  max mem: 2503
Train: Epoch[2/5]  [1870/3750]  eta: 0:14:47  Lr: 0.001875  Loss: -0.2800  Acc@1: 81.2500 (79.8771)  Acc@5: 100.0000 (98.9077)  time: 0.3532  data: 0.0009  max mem: 2503
Train: Epoch[2/5]  [1880/3750]  eta: 0:14:42  Lr: 0.001875  Loss: -0.5084  Acc@1: 81.2500 (79.8910)  Acc@5: 100.0000 (98.9102)  time: 0.3549  data: 0.0023  max mem: 2503
Train: Epoch[2/5]  [1890/3750]  eta: 0:14:36  Lr: 0.001875  Loss: -0.7667  Acc@1: 81.2500 (79.8883)  Acc@5: 100.0000 (98.9093)  time: 0.3576  data: 0.0035  max mem: 2503
Train: Epoch[2/5]  [1900/3750]  eta: 0:14:30  Lr: 0.001875  Loss: -0.6777  Acc@1: 81.2500 (79.8790)  Acc@5: 100.0000 (98.9052)  time: 0.3577  data: 0.0036  max mem: 2503
Train: Epoch[2/5]  [1910/3750]  eta: 0:14:24  Lr: 0.001875  Loss: 0.0798  Acc@1: 81.2500 (79.8698)  Acc@5: 100.0000 (98.9011)  time: 0.3626  data: 0.0050  max mem: 2503
Train: Epoch[2/5]  [1920/3750]  eta: 0:14:18  Lr: 0.001875  Loss: -0.7639  Acc@1: 87.5000 (79.8900)  Acc@5: 100.0000 (98.9068)  time: 0.3602  data: 0.0042  max mem: 2503
Train: Epoch[2/5]  [1930/3750]  eta: 0:14:13  Lr: 0.001875  Loss: -0.4701  Acc@1: 81.2500 (79.8647)  Acc@5: 100.0000 (98.9125)  time: 0.3656  data: 0.0048  max mem: 2503
Train: Epoch[2/5]  [1940/3750]  eta: 0:14:07  Lr: 0.001875  Loss: -0.6919  Acc@1: 81.2500 (79.8847)  Acc@5: 100.0000 (98.9149)  time: 0.3682  data: 0.0047  max mem: 2503
Train: Epoch[2/5]  [1950/3750]  eta: 0:14:01  Lr: 0.001875  Loss: -0.9159  Acc@1: 81.2500 (79.8949)  Acc@5: 100.0000 (98.9204)  time: 0.3554  data: 0.0024  max mem: 2503
Train: Epoch[2/5]  [1960/3750]  eta: 0:13:56  Lr: 0.001875  Loss: -0.6426  Acc@1: 81.2500 (79.9146)  Acc@5: 100.0000 (98.9196)  time: 0.3598  data: 0.0029  max mem: 2503
Train: Epoch[2/5]  [1970/3750]  eta: 0:13:50  Lr: 0.001875  Loss: -0.7857  Acc@1: 81.2500 (79.9055)  Acc@5: 100.0000 (98.9187)  time: 0.3617  data: 0.0028  max mem: 2503
Train: Epoch[2/5]  [1980/3750]  eta: 0:13:45  Lr: 0.001875  Loss: -0.2895  Acc@1: 81.2500 (79.9123)  Acc@5: 100.0000 (98.9242)  time: 0.3577  data: 0.0042  max mem: 2503
Train: Epoch[2/5]  [1990/3750]  eta: 0:13:39  Lr: 0.001875  Loss: -0.4990  Acc@1: 81.2500 (79.9159)  Acc@5: 100.0000 (98.9139)  time: 0.3604  data: 0.0063  max mem: 2503
Train: Epoch[2/5]  [2000/3750]  eta: 0:13:33  Lr: 0.001875  Loss: -0.4583  Acc@1: 75.0000 (79.8913)  Acc@5: 100.0000 (98.9162)  time: 0.3619  data: 0.0061  max mem: 2503
Train: Epoch[2/5]  [2010/3750]  eta: 0:13:28  Lr: 0.001875  Loss: -0.3363  Acc@1: 75.0000 (79.8763)  Acc@5: 100.0000 (98.9122)  time: 0.3581  data: 0.0051  max mem: 2503
Train: Epoch[2/5]  [2020/3750]  eta: 0:13:22  Lr: 0.001875  Loss: -0.7676  Acc@1: 81.2500 (79.8800)  Acc@5: 100.0000 (98.9114)  time: 0.3565  data: 0.0045  max mem: 2503
Train: Epoch[2/5]  [2030/3750]  eta: 0:13:17  Lr: 0.001875  Loss: -0.8007  Acc@1: 81.2500 (79.8898)  Acc@5: 100.0000 (98.9137)  time: 0.3612  data: 0.0030  max mem: 2503
Train: Epoch[2/5]  [2040/3750]  eta: 0:13:11  Lr: 0.001875  Loss: -0.4503  Acc@1: 81.2500 (79.8965)  Acc@5: 100.0000 (98.9160)  time: 0.3592  data: 0.0036  max mem: 2503
Train: Epoch[2/5]  [2050/3750]  eta: 0:13:06  Lr: 0.001875  Loss: 0.1173  Acc@1: 81.2500 (79.8940)  Acc@5: 100.0000 (98.9091)  time: 0.3593  data: 0.0053  max mem: 2503
Train: Epoch[2/5]  [2060/3750]  eta: 0:13:00  Lr: 0.001875  Loss: -0.5754  Acc@1: 75.0000 (79.8641)  Acc@5: 100.0000 (98.9053)  time: 0.3621  data: 0.0045  max mem: 2503
Train: Epoch[2/5]  [2070/3750]  eta: 0:12:55  Lr: 0.001875  Loss: -0.5092  Acc@1: 75.0000 (79.8588)  Acc@5: 100.0000 (98.9015)  time: 0.3579  data: 0.0032  max mem: 2503
Train: Epoch[2/5]  [2080/3750]  eta: 0:12:49  Lr: 0.001875  Loss: -0.1771  Acc@1: 75.0000 (79.8564)  Acc@5: 100.0000 (98.8948)  time: 0.3558  data: 0.0027  max mem: 2503
Train: Epoch[2/5]  [2090/3750]  eta: 0:12:44  Lr: 0.001875  Loss: -0.3056  Acc@1: 75.0000 (79.8601)  Acc@5: 100.0000 (98.8911)  time: 0.3634  data: 0.0039  max mem: 2503
Train: Epoch[2/5]  [2100/3750]  eta: 0:12:39  Lr: 0.001875  Loss: -0.7318  Acc@1: 81.2500 (79.8905)  Acc@5: 100.0000 (98.8934)  time: 0.3634  data: 0.0041  max mem: 2503
Train: Epoch[2/5]  [2110/3750]  eta: 0:12:33  Lr: 0.001875  Loss: -0.5382  Acc@1: 87.5000 (79.9059)  Acc@5: 100.0000 (98.8957)  time: 0.3628  data: 0.0028  max mem: 2503
Train: Epoch[2/5]  [2120/3750]  eta: 0:12:28  Lr: 0.001875  Loss: -0.5204  Acc@1: 81.2500 (79.8945)  Acc@5: 100.0000 (98.8950)  time: 0.3673  data: 0.0027  max mem: 2503
Train: Epoch[2/5]  [2130/3750]  eta: 0:12:23  Lr: 0.001875  Loss: -0.5333  Acc@1: 81.2500 (79.9097)  Acc@5: 100.0000 (98.9002)  time: 0.3616  data: 0.0047  max mem: 2503
Train: Epoch[2/5]  [2140/3750]  eta: 0:12:17  Lr: 0.001875  Loss: -0.3843  Acc@1: 81.2500 (79.9072)  Acc@5: 100.0000 (98.8936)  time: 0.3577  data: 0.0044  max mem: 2503
Train: Epoch[2/5]  [2150/3750]  eta: 0:12:12  Lr: 0.001875  Loss: -0.6757  Acc@1: 81.2500 (79.9076)  Acc@5: 100.0000 (98.8988)  time: 0.3574  data: 0.0032  max mem: 2503
Train: Epoch[2/5]  [2160/3750]  eta: 0:12:07  Lr: 0.001875  Loss: -0.3043  Acc@1: 81.2500 (79.9080)  Acc@5: 100.0000 (98.9010)  time: 0.3562  data: 0.0031  max mem: 2503
Train: Epoch[2/5]  [2170/3750]  eta: 0:12:01  Lr: 0.001875  Loss: -0.5778  Acc@1: 81.2500 (79.9200)  Acc@5: 100.0000 (98.8945)  time: 0.3605  data: 0.0065  max mem: 2503
Train: Epoch[2/5]  [2180/3750]  eta: 0:11:56  Lr: 0.001875  Loss: -0.1708  Acc@1: 81.2500 (79.9261)  Acc@5: 100.0000 (98.8967)  time: 0.3641  data: 0.0074  max mem: 2503
Train: Epoch[2/5]  [2190/3750]  eta: 0:11:51  Lr: 0.001875  Loss: -0.4952  Acc@1: 81.2500 (79.9407)  Acc@5: 100.0000 (98.9018)  time: 0.3612  data: 0.0042  max mem: 2503
Train: Epoch[2/5]  [2200/3750]  eta: 0:11:46  Lr: 0.001875  Loss: -0.7489  Acc@1: 81.2500 (79.9296)  Acc@5: 100.0000 (98.8982)  time: 0.3606  data: 0.0053  max mem: 2503
Train: Epoch[2/5]  [2210/3750]  eta: 0:11:40  Lr: 0.001875  Loss: -0.6289  Acc@1: 81.2500 (79.9214)  Acc@5: 100.0000 (98.9004)  time: 0.3568  data: 0.0036  max mem: 2503
Train: Epoch[2/5]  [2220/3750]  eta: 0:11:35  Lr: 0.001875  Loss: -0.4999  Acc@1: 81.2500 (79.9190)  Acc@5: 100.0000 (98.8997)  time: 0.3736  data: 0.0020  max mem: 2503
Train: Epoch[2/5]  [2230/3750]  eta: 0:11:32  Lr: 0.001875  Loss: -0.5911  Acc@1: 81.2500 (79.9053)  Acc@5: 100.0000 (98.9018)  time: 0.5345  data: 0.0021  max mem: 2503
Train: Epoch[2/5]  [2240/3750]  eta: 0:11:29  Lr: 0.001875  Loss: -0.4854  Acc@1: 75.0000 (79.8862)  Acc@5: 100.0000 (98.9039)  time: 0.6806  data: 0.0006  max mem: 2503
Train: Epoch[2/5]  [2250/3750]  eta: 0:11:26  Lr: 0.001875  Loss: -0.5313  Acc@1: 75.0000 (79.8839)  Acc@5: 100.0000 (98.9060)  time: 0.6863  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [2260/3750]  eta: 0:11:23  Lr: 0.001875  Loss: -0.8789  Acc@1: 75.0000 (79.8900)  Acc@5: 100.0000 (98.9081)  time: 0.6906  data: 0.0006  max mem: 2503
Train: Epoch[2/5]  [2270/3750]  eta: 0:11:20  Lr: 0.001875  Loss: -0.5360  Acc@1: 75.0000 (79.8795)  Acc@5: 100.0000 (98.9047)  time: 0.6869  data: 0.0006  max mem: 2503
Train: Epoch[2/5]  [2280/3750]  eta: 0:11:16  Lr: 0.001875  Loss: -0.6833  Acc@1: 75.0000 (79.8745)  Acc@5: 100.0000 (98.9012)  time: 0.6353  data: 0.0008  max mem: 2503
Train: Epoch[2/5]  [2290/3750]  eta: 0:11:13  Lr: 0.001875  Loss: -0.5056  Acc@1: 81.2500 (79.8805)  Acc@5: 100.0000 (98.9033)  time: 0.6379  data: 0.0008  max mem: 2503
Train: Epoch[2/5]  [2300/3750]  eta: 0:11:10  Lr: 0.001875  Loss: -0.2978  Acc@1: 81.2500 (79.8674)  Acc@5: 100.0000 (98.8999)  time: 0.6857  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [2310/3750]  eta: 0:11:07  Lr: 0.001875  Loss: -0.3693  Acc@1: 75.0000 (79.8761)  Acc@5: 100.0000 (98.9020)  time: 0.6819  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [2320/3750]  eta: 0:11:03  Lr: 0.001875  Loss: -0.7413  Acc@1: 81.2500 (79.8874)  Acc@5: 100.0000 (98.9067)  time: 0.6778  data: 0.0006  max mem: 2503
Train: Epoch[2/5]  [2330/3750]  eta: 0:11:00  Lr: 0.001875  Loss: -0.5032  Acc@1: 81.2500 (79.8933)  Acc@5: 100.0000 (98.9087)  time: 0.6689  data: 0.0012  max mem: 2503
Train: Epoch[2/5]  [2340/3750]  eta: 0:10:57  Lr: 0.001875  Loss: -0.4792  Acc@1: 81.2500 (79.8884)  Acc@5: 100.0000 (98.9081)  time: 0.6710  data: 0.0012  max mem: 2503
Train: Epoch[2/5]  [2350/3750]  eta: 0:10:53  Lr: 0.001875  Loss: -0.7255  Acc@1: 81.2500 (79.8782)  Acc@5: 100.0000 (98.9047)  time: 0.6910  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [2360/3750]  eta: 0:10:50  Lr: 0.001875  Loss: -0.1587  Acc@1: 75.0000 (79.8576)  Acc@5: 100.0000 (98.9094)  time: 0.6888  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [2370/3750]  eta: 0:10:46  Lr: 0.001875  Loss: -0.7561  Acc@1: 75.0000 (79.8635)  Acc@5: 100.0000 (98.9087)  time: 0.6800  data: 0.0012  max mem: 2503
Train: Epoch[2/5]  [2380/3750]  eta: 0:10:43  Lr: 0.001875  Loss: -0.6507  Acc@1: 87.5000 (79.8798)  Acc@5: 100.0000 (98.9106)  time: 0.6853  data: 0.0012  max mem: 2503
Train: Epoch[2/5]  [2390/3750]  eta: 0:10:39  Lr: 0.001875  Loss: -0.6328  Acc@1: 87.5000 (79.8986)  Acc@5: 100.0000 (98.9126)  time: 0.6493  data: 0.0007  max mem: 2503
Train: Epoch[2/5]  [2400/3750]  eta: 0:10:36  Lr: 0.001875  Loss: -0.2996  Acc@1: 81.2500 (79.8938)  Acc@5: 100.0000 (98.9171)  time: 0.6393  data: 0.0007  max mem: 2503
Train: Epoch[2/5]  [2410/3750]  eta: 0:10:32  Lr: 0.001875  Loss: -0.4429  Acc@1: 81.2500 (79.9124)  Acc@5: 100.0000 (98.9216)  time: 0.6794  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [2420/3750]  eta: 0:10:29  Lr: 0.001875  Loss: -0.5504  Acc@1: 81.2500 (79.9127)  Acc@5: 100.0000 (98.9261)  time: 0.6928  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [2430/3750]  eta: 0:10:25  Lr: 0.001875  Loss: -0.2084  Acc@1: 75.0000 (79.8951)  Acc@5: 100.0000 (98.9176)  time: 0.6833  data: 0.0021  max mem: 2503
Train: Epoch[2/5]  [2440/3750]  eta: 0:10:21  Lr: 0.001875  Loss: -0.5998  Acc@1: 75.0000 (79.8751)  Acc@5: 100.0000 (98.9144)  time: 0.6687  data: 0.0023  max mem: 2503
Train: Epoch[2/5]  [2450/3750]  eta: 0:10:18  Lr: 0.001875  Loss: -0.1666  Acc@1: 75.0000 (79.8858)  Acc@5: 100.0000 (98.9163)  time: 0.6742  data: 0.0008  max mem: 2503
Train: Epoch[2/5]  [2460/3750]  eta: 0:10:14  Lr: 0.001875  Loss: -0.4486  Acc@1: 81.2500 (79.8888)  Acc@5: 100.0000 (98.9181)  time: 0.6821  data: 0.0008  max mem: 2503
Train: Epoch[2/5]  [2470/3750]  eta: 0:10:10  Lr: 0.001875  Loss: -0.4885  Acc@1: 81.2500 (79.8968)  Acc@5: 100.0000 (98.9200)  time: 0.6852  data: 0.0007  max mem: 2503
Train: Epoch[2/5]  [2480/3750]  eta: 0:10:07  Lr: 0.001875  Loss: -0.6121  Acc@1: 81.2500 (79.8922)  Acc@5: 100.0000 (98.9193)  time: 0.6870  data: 0.0010  max mem: 2503
Train: Epoch[2/5]  [2490/3750]  eta: 0:10:03  Lr: 0.001875  Loss: -0.4604  Acc@1: 81.2500 (79.8976)  Acc@5: 100.0000 (98.9186)  time: 0.6826  data: 0.0010  max mem: 2503
Train: Epoch[2/5]  [2500/3750]  eta: 0:09:59  Lr: 0.001875  Loss: -0.5910  Acc@1: 81.2500 (79.9105)  Acc@5: 100.0000 (98.9229)  time: 0.6870  data: 0.0006  max mem: 2503
Train: Epoch[2/5]  [2510/3750]  eta: 0:09:55  Lr: 0.001875  Loss: -0.4773  Acc@1: 81.2500 (79.9059)  Acc@5: 100.0000 (98.9247)  time: 0.6870  data: 0.0006  max mem: 2503
Train: Epoch[2/5]  [2520/3750]  eta: 0:09:51  Lr: 0.001875  Loss: -0.5890  Acc@1: 75.0000 (79.8939)  Acc@5: 100.0000 (98.9240)  time: 0.6821  data: 0.0006  max mem: 2503
Train: Epoch[2/5]  [2530/3750]  eta: 0:09:48  Lr: 0.001875  Loss: -0.1362  Acc@1: 75.0000 (79.8795)  Acc@5: 100.0000 (98.9234)  time: 0.6762  data: 0.0007  max mem: 2503
Train: Epoch[2/5]  [2540/3750]  eta: 0:09:44  Lr: 0.001875  Loss: -0.8394  Acc@1: 81.2500 (79.8873)  Acc@5: 100.0000 (98.9251)  time: 0.6755  data: 0.0010  max mem: 2503
Train: Epoch[2/5]  [2550/3750]  eta: 0:09:40  Lr: 0.001875  Loss: -0.6615  Acc@1: 81.2500 (79.9098)  Acc@5: 100.0000 (98.9293)  time: 0.6859  data: 0.0013  max mem: 2503
Train: Epoch[2/5]  [2560/3750]  eta: 0:09:36  Lr: 0.001875  Loss: -0.7754  Acc@1: 81.2500 (79.9053)  Acc@5: 100.0000 (98.9286)  time: 0.6921  data: 0.0014  max mem: 2503
Train: Epoch[2/5]  [2570/3750]  eta: 0:09:32  Lr: 0.001875  Loss: -0.9527  Acc@1: 81.2500 (79.9178)  Acc@5: 100.0000 (98.9255)  time: 0.6876  data: 0.0012  max mem: 2503
Train: Epoch[2/5]  [2580/3750]  eta: 0:09:27  Lr: 0.001875  Loss: -0.5978  Acc@1: 81.2500 (79.9036)  Acc@5: 100.0000 (98.9297)  time: 0.5444  data: 0.0018  max mem: 2503
Train: Epoch[2/5]  [2590/3750]  eta: 0:09:23  Lr: 0.001875  Loss: -0.5522  Acc@1: 81.2500 (79.9161)  Acc@5: 100.0000 (98.9290)  time: 0.5219  data: 0.0016  max mem: 2503
Train: Epoch[2/5]  [2600/3750]  eta: 0:09:18  Lr: 0.001875  Loss: -0.1456  Acc@1: 81.2500 (79.9116)  Acc@5: 100.0000 (98.9283)  time: 0.6144  data: 0.0009  max mem: 2503
Train: Epoch[2/5]  [2610/3750]  eta: 0:09:13  Lr: 0.001875  Loss: -0.5819  Acc@1: 81.2500 (79.9071)  Acc@5: 100.0000 (98.9276)  time: 0.5115  data: 0.0010  max mem: 2503
Train: Epoch[2/5]  [2620/3750]  eta: 0:09:08  Lr: 0.001875  Loss: -0.5275  Acc@1: 87.5000 (79.9385)  Acc@5: 100.0000 (98.9317)  time: 0.3913  data: 0.0007  max mem: 2503
Train: Epoch[2/5]  [2630/3750]  eta: 0:09:02  Lr: 0.001875  Loss: -0.9747  Acc@1: 87.5000 (79.9601)  Acc@5: 100.0000 (98.9286)  time: 0.3558  data: 0.0007  max mem: 2503
Train: Epoch[2/5]  [2640/3750]  eta: 0:08:57  Lr: 0.001875  Loss: -0.4022  Acc@1: 81.2500 (79.9673)  Acc@5: 100.0000 (98.9280)  time: 0.3522  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [2650/3750]  eta: 0:08:51  Lr: 0.001875  Loss: -0.6397  Acc@1: 81.2500 (79.9627)  Acc@5: 100.0000 (98.9296)  time: 0.3477  data: 0.0006  max mem: 2503
Train: Epoch[2/5]  [2660/3750]  eta: 0:08:46  Lr: 0.001875  Loss: -0.2738  Acc@1: 81.2500 (79.9582)  Acc@5: 100.0000 (98.9313)  time: 0.3487  data: 0.0020  max mem: 2503
Train: Epoch[2/5]  [2670/3750]  eta: 0:08:41  Lr: 0.001875  Loss: -0.5794  Acc@1: 81.2500 (79.9560)  Acc@5: 100.0000 (98.9236)  time: 0.3486  data: 0.0023  max mem: 2503
Train: Epoch[2/5]  [2680/3750]  eta: 0:08:36  Lr: 0.001875  Loss: -0.3772  Acc@1: 81.2500 (79.9562)  Acc@5: 100.0000 (98.9183)  time: 0.4634  data: 0.0007  max mem: 2503
Train: Epoch[2/5]  [2690/3750]  eta: 0:08:32  Lr: 0.001875  Loss: -0.6886  Acc@1: 75.0000 (79.9447)  Acc@5: 100.0000 (98.9154)  time: 0.6193  data: 0.0006  max mem: 2503
Train: Epoch[2/5]  [2700/3750]  eta: 0:08:28  Lr: 0.001875  Loss: -0.1292  Acc@1: 81.2500 (79.9519)  Acc@5: 100.0000 (98.9124)  time: 0.6751  data: 0.0006  max mem: 2503
Train: Epoch[2/5]  [2710/3750]  eta: 0:08:24  Lr: 0.001875  Loss: -0.4831  Acc@1: 75.0000 (79.9474)  Acc@5: 100.0000 (98.9165)  time: 0.6849  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [2720/3750]  eta: 0:08:20  Lr: 0.001875  Loss: -0.6325  Acc@1: 81.2500 (79.9591)  Acc@5: 100.0000 (98.9204)  time: 0.6794  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [2730/3750]  eta: 0:08:16  Lr: 0.001875  Loss: -0.4042  Acc@1: 81.2500 (79.9684)  Acc@5: 100.0000 (98.9221)  time: 0.6887  data: 0.0006  max mem: 2503
Train: Epoch[2/5]  [2740/3750]  eta: 0:08:12  Lr: 0.001875  Loss: -0.9262  Acc@1: 81.2500 (79.9526)  Acc@5: 100.0000 (98.9192)  time: 0.6805  data: 0.0007  max mem: 2503
Train: Epoch[2/5]  [2750/3750]  eta: 0:08:07  Lr: 0.001875  Loss: -0.4904  Acc@1: 81.2500 (79.9618)  Acc@5: 100.0000 (98.9163)  time: 0.6635  data: 0.0006  max mem: 2503
Train: Epoch[2/5]  [2760/3750]  eta: 0:08:03  Lr: 0.001875  Loss: -0.5507  Acc@1: 81.2500 (79.9688)  Acc@5: 100.0000 (98.9180)  time: 0.6778  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [2770/3750]  eta: 0:07:59  Lr: 0.001875  Loss: -0.4792  Acc@1: 81.2500 (79.9666)  Acc@5: 100.0000 (98.9151)  time: 0.6813  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [2780/3750]  eta: 0:07:55  Lr: 0.001875  Loss: -0.2544  Acc@1: 75.0000 (79.9600)  Acc@5: 100.0000 (98.9078)  time: 0.6799  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [2790/3750]  eta: 0:07:51  Lr: 0.001875  Loss: -0.9571  Acc@1: 75.0000 (79.9691)  Acc@5: 100.0000 (98.9027)  time: 0.6804  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [2800/3750]  eta: 0:07:46  Lr: 0.001875  Loss: -0.1515  Acc@1: 81.2500 (79.9848)  Acc@5: 100.0000 (98.9022)  time: 0.6779  data: 0.0009  max mem: 2503
Train: Epoch[2/5]  [2810/3750]  eta: 0:07:42  Lr: 0.001875  Loss: -0.7294  Acc@1: 87.5000 (80.0049)  Acc@5: 100.0000 (98.9016)  time: 0.6816  data: 0.0013  max mem: 2503
Train: Epoch[2/5]  [2820/3750]  eta: 0:07:38  Lr: 0.001875  Loss: -0.5173  Acc@1: 81.2500 (80.0027)  Acc@5: 100.0000 (98.8989)  time: 0.6822  data: 0.0010  max mem: 2503
Train: Epoch[2/5]  [2830/3750]  eta: 0:07:33  Lr: 0.001875  Loss: -0.6396  Acc@1: 81.2500 (80.0203)  Acc@5: 100.0000 (98.9028)  time: 0.6926  data: 0.0006  max mem: 2503
Train: Epoch[2/5]  [2840/3750]  eta: 0:07:29  Lr: 0.001875  Loss: -0.6246  Acc@1: 87.5000 (80.0268)  Acc@5: 100.0000 (98.9044)  time: 0.6907  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [2850/3750]  eta: 0:07:25  Lr: 0.001875  Loss: -0.2610  Acc@1: 75.0000 (80.0158)  Acc@5: 100.0000 (98.9061)  time: 0.6794  data: 0.0006  max mem: 2503
Train: Epoch[2/5]  [2860/3750]  eta: 0:07:20  Lr: 0.001875  Loss: -0.7722  Acc@1: 75.0000 (80.0135)  Acc@5: 100.0000 (98.9099)  time: 0.6792  data: 0.0010  max mem: 2503
Train: Epoch[2/5]  [2870/3750]  eta: 0:07:16  Lr: 0.001875  Loss: -0.7217  Acc@1: 81.2500 (80.0200)  Acc@5: 100.0000 (98.9094)  time: 0.6849  data: 0.0009  max mem: 2503
Train: Epoch[2/5]  [2880/3750]  eta: 0:07:12  Lr: 0.001875  Loss: -0.6368  Acc@1: 81.2500 (80.0156)  Acc@5: 100.0000 (98.9110)  time: 0.6868  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [2890/3750]  eta: 0:07:07  Lr: 0.001875  Loss: -0.2559  Acc@1: 81.2500 (80.0091)  Acc@5: 100.0000 (98.9126)  time: 0.6859  data: 0.0008  max mem: 2503
Train: Epoch[2/5]  [2900/3750]  eta: 0:07:03  Lr: 0.001875  Loss: -0.8233  Acc@1: 81.2500 (79.9918)  Acc@5: 100.0000 (98.9099)  time: 0.6586  data: 0.0012  max mem: 2503
Train: Epoch[2/5]  [2910/3750]  eta: 0:06:58  Lr: 0.001875  Loss: -0.6113  Acc@1: 81.2500 (79.9940)  Acc@5: 100.0000 (98.9115)  time: 0.6626  data: 0.0016  max mem: 2503
Train: Epoch[2/5]  [2920/3750]  eta: 0:06:54  Lr: 0.001875  Loss: -0.2543  Acc@1: 75.0000 (79.9769)  Acc@5: 100.0000 (98.9088)  time: 0.6917  data: 0.0016  max mem: 2503
Train: Epoch[2/5]  [2930/3750]  eta: 0:06:49  Lr: 0.001875  Loss: -0.7884  Acc@1: 75.0000 (79.9642)  Acc@5: 100.0000 (98.9104)  time: 0.6826  data: 0.0010  max mem: 2503
Train: Epoch[2/5]  [2940/3750]  eta: 0:06:45  Lr: 0.001875  Loss: -0.7153  Acc@1: 81.2500 (79.9877)  Acc@5: 100.0000 (98.9119)  time: 0.6835  data: 0.0007  max mem: 2503
Train: Epoch[2/5]  [2950/3750]  eta: 0:06:40  Lr: 0.001875  Loss: -0.2035  Acc@1: 81.2500 (79.9898)  Acc@5: 100.0000 (98.9114)  time: 0.6790  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [2960/3750]  eta: 0:06:36  Lr: 0.001875  Loss: -0.3447  Acc@1: 75.0000 (79.9624)  Acc@5: 100.0000 (98.9108)  time: 0.6782  data: 0.0006  max mem: 2503
Train: Epoch[2/5]  [2970/3750]  eta: 0:06:31  Lr: 0.001875  Loss: -0.7760  Acc@1: 75.0000 (79.9836)  Acc@5: 100.0000 (98.9124)  time: 0.6830  data: 0.0011  max mem: 2503
Train: Epoch[2/5]  [2980/3750]  eta: 0:06:27  Lr: 0.001875  Loss: -0.3380  Acc@1: 81.2500 (79.9795)  Acc@5: 100.0000 (98.9056)  time: 0.6846  data: 0.0010  max mem: 2503
Train: Epoch[2/5]  [2990/3750]  eta: 0:06:22  Lr: 0.001875  Loss: -0.4473  Acc@1: 75.0000 (79.9733)  Acc@5: 100.0000 (98.9050)  time: 0.6955  data: 0.0006  max mem: 2503
Train: Epoch[2/5]  [3000/3750]  eta: 0:06:18  Lr: 0.001875  Loss: -0.4788  Acc@1: 81.2500 (79.9775)  Acc@5: 100.0000 (98.9045)  time: 0.6830  data: 0.0006  max mem: 2503
Train: Epoch[2/5]  [3010/3750]  eta: 0:06:13  Lr: 0.001875  Loss: -0.7566  Acc@1: 81.2500 (79.9942)  Acc@5: 100.0000 (98.9061)  time: 0.6644  data: 0.0006  max mem: 2503
Train: Epoch[2/5]  [3020/3750]  eta: 0:06:08  Lr: 0.001875  Loss: -0.3906  Acc@1: 81.2500 (79.9983)  Acc@5: 100.0000 (98.9076)  time: 0.6720  data: 0.0012  max mem: 2503
Train: Epoch[2/5]  [3030/3750]  eta: 0:06:03  Lr: 0.001875  Loss: -0.3304  Acc@1: 81.2500 (79.9880)  Acc@5: 100.0000 (98.9092)  time: 0.5833  data: 0.0014  max mem: 2503
Train: Epoch[2/5]  [3040/3750]  eta: 0:05:58  Lr: 0.001875  Loss: -0.8185  Acc@1: 81.2500 (79.9819)  Acc@5: 100.0000 (98.9066)  time: 0.4167  data: 0.0007  max mem: 2503
Train: Epoch[2/5]  [3050/3750]  eta: 0:05:52  Lr: 0.001875  Loss: -0.9537  Acc@1: 81.2500 (79.9840)  Acc@5: 100.0000 (98.9061)  time: 0.3503  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [3060/3750]  eta: 0:05:47  Lr: 0.001875  Loss: -0.5080  Acc@1: 75.0000 (79.9596)  Acc@5: 100.0000 (98.9056)  time: 0.3586  data: 0.0031  max mem: 2503
Train: Epoch[2/5]  [3070/3750]  eta: 0:05:42  Lr: 0.001875  Loss: -0.7175  Acc@1: 75.0000 (79.9455)  Acc@5: 100.0000 (98.9051)  time: 0.3603  data: 0.0055  max mem: 2503
Train: Epoch[2/5]  [3080/3750]  eta: 0:05:36  Lr: 0.001875  Loss: -0.4471  Acc@1: 81.2500 (79.9517)  Acc@5: 100.0000 (98.9066)  time: 0.3542  data: 0.0044  max mem: 2503
Train: Epoch[2/5]  [3090/3750]  eta: 0:05:31  Lr: 0.001875  Loss: -0.6454  Acc@1: 81.2500 (79.9600)  Acc@5: 100.0000 (98.9101)  time: 0.3553  data: 0.0040  max mem: 2503
Train: Epoch[2/5]  [3100/3750]  eta: 0:05:26  Lr: 0.001875  Loss: -0.8277  Acc@1: 81.2500 (79.9762)  Acc@5: 100.0000 (98.9076)  time: 0.3553  data: 0.0028  max mem: 2503
Train: Epoch[2/5]  [3110/3750]  eta: 0:05:20  Lr: 0.001875  Loss: -0.5703  Acc@1: 87.5000 (79.9863)  Acc@5: 100.0000 (98.9091)  time: 0.3574  data: 0.0030  max mem: 2503
Train: Epoch[2/5]  [3120/3750]  eta: 0:05:15  Lr: 0.001875  Loss: -0.5085  Acc@1: 81.2500 (79.9904)  Acc@5: 100.0000 (98.9126)  time: 0.3550  data: 0.0034  max mem: 2503
Train: Epoch[2/5]  [3130/3750]  eta: 0:05:10  Lr: 0.001875  Loss: -0.6843  Acc@1: 81.2500 (79.9784)  Acc@5: 100.0000 (98.9101)  time: 0.3499  data: 0.0027  max mem: 2503
Train: Epoch[2/5]  [3140/3750]  eta: 0:05:04  Lr: 0.001875  Loss: -0.5468  Acc@1: 75.0000 (79.9706)  Acc@5: 100.0000 (98.9116)  time: 0.3500  data: 0.0027  max mem: 2503
Train: Epoch[2/5]  [3150/3750]  eta: 0:04:59  Lr: 0.001875  Loss: -0.8169  Acc@1: 81.2500 (79.9786)  Acc@5: 100.0000 (98.9130)  time: 0.3520  data: 0.0014  max mem: 2503
Train: Epoch[2/5]  [3160/3750]  eta: 0:04:54  Lr: 0.001875  Loss: -0.5398  Acc@1: 81.2500 (79.9688)  Acc@5: 100.0000 (98.9145)  time: 0.3511  data: 0.0007  max mem: 2503
Train: Epoch[2/5]  [3170/3750]  eta: 0:04:49  Lr: 0.001875  Loss: -0.6133  Acc@1: 81.2500 (79.9728)  Acc@5: 100.0000 (98.9140)  time: 0.3516  data: 0.0015  max mem: 2503
Train: Epoch[2/5]  [3180/3750]  eta: 0:04:43  Lr: 0.001875  Loss: -0.8972  Acc@1: 75.0000 (79.9650)  Acc@5: 100.0000 (98.9095)  time: 0.3599  data: 0.0034  max mem: 2503
Train: Epoch[2/5]  [3190/3750]  eta: 0:04:38  Lr: 0.001875  Loss: -0.1847  Acc@1: 75.0000 (79.9769)  Acc@5: 100.0000 (98.9090)  time: 0.3591  data: 0.0027  max mem: 2503
Train: Epoch[2/5]  [3200/3750]  eta: 0:04:33  Lr: 0.001875  Loss: -0.3602  Acc@1: 81.2500 (79.9711)  Acc@5: 100.0000 (98.9046)  time: 0.3557  data: 0.0022  max mem: 2503
Train: Epoch[2/5]  [3210/3750]  eta: 0:04:28  Lr: 0.001875  Loss: -0.5856  Acc@1: 81.2500 (79.9829)  Acc@5: 100.0000 (98.9042)  time: 0.3586  data: 0.0030  max mem: 2503
Train: Epoch[2/5]  [3220/3750]  eta: 0:04:23  Lr: 0.001875  Loss: -0.7442  Acc@1: 81.2500 (79.9965)  Acc@5: 100.0000 (98.9056)  time: 0.3609  data: 0.0037  max mem: 2503
Train: Epoch[2/5]  [3230/3750]  eta: 0:04:17  Lr: 0.001875  Loss: -0.6611  Acc@1: 81.2500 (79.9965)  Acc@5: 100.0000 (98.9071)  time: 0.3621  data: 0.0048  max mem: 2503
Train: Epoch[2/5]  [3240/3750]  eta: 0:04:12  Lr: 0.001875  Loss: -0.7656  Acc@1: 81.2500 (80.0081)  Acc@5: 100.0000 (98.9066)  time: 0.3575  data: 0.0040  max mem: 2503
Train: Epoch[2/5]  [3250/3750]  eta: 0:04:07  Lr: 0.001875  Loss: -0.7288  Acc@1: 81.2500 (80.0042)  Acc@5: 100.0000 (98.9080)  time: 0.3543  data: 0.0036  max mem: 2503
Train: Epoch[2/5]  [3260/3750]  eta: 0:04:02  Lr: 0.001875  Loss: -0.5776  Acc@1: 81.2500 (80.0100)  Acc@5: 100.0000 (98.9114)  time: 0.3587  data: 0.0049  max mem: 2503
Train: Epoch[2/5]  [3270/3750]  eta: 0:03:57  Lr: 0.001875  Loss: -0.7839  Acc@1: 87.5000 (80.0214)  Acc@5: 100.0000 (98.9128)  time: 0.3621  data: 0.0044  max mem: 2503
Train: Epoch[2/5]  [3280/3750]  eta: 0:03:52  Lr: 0.001875  Loss: -0.6883  Acc@1: 81.2500 (80.0061)  Acc@5: 100.0000 (98.9085)  time: 0.3565  data: 0.0025  max mem: 2503
Train: Epoch[2/5]  [3290/3750]  eta: 0:03:46  Lr: 0.001875  Loss: -0.9079  Acc@1: 75.0000 (80.0061)  Acc@5: 100.0000 (98.9099)  time: 0.3531  data: 0.0043  max mem: 2503
Train: Epoch[2/5]  [3300/3750]  eta: 0:03:41  Lr: 0.001875  Loss: -0.9431  Acc@1: 75.0000 (80.0098)  Acc@5: 100.0000 (98.9094)  time: 0.3573  data: 0.0044  max mem: 2503
Train: Epoch[2/5]  [3310/3750]  eta: 0:03:36  Lr: 0.001875  Loss: -0.7592  Acc@1: 81.2500 (80.0098)  Acc@5: 100.0000 (98.9052)  time: 0.3573  data: 0.0028  max mem: 2503
Train: Epoch[2/5]  [3320/3750]  eta: 0:03:31  Lr: 0.001875  Loss: -0.5404  Acc@1: 81.2500 (80.0154)  Acc@5: 100.0000 (98.9085)  time: 0.3547  data: 0.0022  max mem: 2503
Train: Epoch[2/5]  [3330/3750]  eta: 0:03:26  Lr: 0.001875  Loss: -0.8118  Acc@1: 87.5000 (80.0323)  Acc@5: 100.0000 (98.9080)  time: 0.3559  data: 0.0020  max mem: 2503
Train: Epoch[2/5]  [3340/3750]  eta: 0:03:21  Lr: 0.001875  Loss: -0.2904  Acc@1: 81.2500 (80.0322)  Acc@5: 100.0000 (98.9094)  time: 0.3558  data: 0.0026  max mem: 2503
Train: Epoch[2/5]  [3350/3750]  eta: 0:03:16  Lr: 0.001875  Loss: -0.5245  Acc@1: 81.2500 (80.0265)  Acc@5: 100.0000 (98.9108)  time: 0.3557  data: 0.0018  max mem: 2503
Train: Epoch[2/5]  [3360/3750]  eta: 0:03:11  Lr: 0.001875  Loss: -0.7270  Acc@1: 81.2500 (80.0190)  Acc@5: 100.0000 (98.9103)  time: 0.3573  data: 0.0037  max mem: 2503
Train: Epoch[2/5]  [3370/3750]  eta: 0:03:06  Lr: 0.001875  Loss: -1.0016  Acc@1: 81.2500 (80.0375)  Acc@5: 100.0000 (98.9135)  time: 0.3631  data: 0.0072  max mem: 2503
Train: Epoch[2/5]  [3380/3750]  eta: 0:03:01  Lr: 0.001875  Loss: -0.7999  Acc@1: 87.5000 (80.0484)  Acc@5: 100.0000 (98.9149)  time: 0.3619  data: 0.0046  max mem: 2503
Train: Epoch[2/5]  [3390/3750]  eta: 0:02:56  Lr: 0.001875  Loss: -0.7088  Acc@1: 81.2500 (80.0464)  Acc@5: 100.0000 (98.9144)  time: 0.3549  data: 0.0017  max mem: 2503
Train: Epoch[2/5]  [3400/3750]  eta: 0:02:51  Lr: 0.001875  Loss: -0.7883  Acc@1: 75.0000 (80.0445)  Acc@5: 100.0000 (98.9158)  time: 0.3525  data: 0.0020  max mem: 2503
Train: Epoch[2/5]  [3410/3750]  eta: 0:02:46  Lr: 0.001875  Loss: -0.6825  Acc@1: 75.0000 (80.0388)  Acc@5: 100.0000 (98.9189)  time: 0.3558  data: 0.0020  max mem: 2503
Train: Epoch[2/5]  [3420/3750]  eta: 0:02:41  Lr: 0.001875  Loss: -0.6036  Acc@1: 81.2500 (80.0424)  Acc@5: 100.0000 (98.9221)  time: 0.3579  data: 0.0018  max mem: 2503
Train: Epoch[2/5]  [3430/3750]  eta: 0:02:36  Lr: 0.001875  Loss: -0.1594  Acc@1: 81.2500 (80.0532)  Acc@5: 100.0000 (98.9234)  time: 0.3536  data: 0.0024  max mem: 2503
Train: Epoch[2/5]  [3440/3750]  eta: 0:02:31  Lr: 0.001875  Loss: -0.9468  Acc@1: 81.2500 (80.0658)  Acc@5: 100.0000 (98.9247)  time: 0.3530  data: 0.0029  max mem: 2503
Train: Epoch[2/5]  [3450/3750]  eta: 0:02:26  Lr: 0.001875  Loss: -0.5970  Acc@1: 81.2500 (80.0547)  Acc@5: 100.0000 (98.9260)  time: 0.3526  data: 0.0017  max mem: 2503
Train: Epoch[2/5]  [3460/3750]  eta: 0:02:21  Lr: 0.001875  Loss: -0.5435  Acc@1: 81.2500 (80.0581)  Acc@5: 100.0000 (98.9291)  time: 0.3536  data: 0.0036  max mem: 2503
Train: Epoch[2/5]  [3470/3750]  eta: 0:02:16  Lr: 0.001875  Loss: -0.7514  Acc@1: 81.2500 (80.0544)  Acc@5: 100.0000 (98.9268)  time: 0.3545  data: 0.0059  max mem: 2503
Train: Epoch[2/5]  [3480/3750]  eta: 0:02:11  Lr: 0.001875  Loss: -0.3594  Acc@1: 81.2500 (80.0596)  Acc@5: 100.0000 (98.9263)  time: 0.3568  data: 0.0049  max mem: 2503
Train: Epoch[2/5]  [3490/3750]  eta: 0:02:06  Lr: 0.001875  Loss: -0.4038  Acc@1: 87.5000 (80.0684)  Acc@5: 100.0000 (98.9276)  time: 0.3587  data: 0.0041  max mem: 2503
Train: Epoch[2/5]  [3500/3750]  eta: 0:02:01  Lr: 0.001875  Loss: -0.5215  Acc@1: 81.2500 (80.0700)  Acc@5: 100.0000 (98.9307)  time: 0.3573  data: 0.0043  max mem: 2503
Train: Epoch[2/5]  [3510/3750]  eta: 0:01:56  Lr: 0.001875  Loss: -0.5960  Acc@1: 81.2500 (80.0769)  Acc@5: 100.0000 (98.9284)  time: 0.3549  data: 0.0052  max mem: 2503
Train: Epoch[2/5]  [3520/3750]  eta: 0:01:51  Lr: 0.001875  Loss: -0.3021  Acc@1: 81.2500 (80.0767)  Acc@5: 100.0000 (98.9261)  time: 0.3589  data: 0.0040  max mem: 2503
Train: Epoch[2/5]  [3530/3750]  eta: 0:01:46  Lr: 0.001875  Loss: -0.4953  Acc@1: 87.5000 (80.0942)  Acc@5: 100.0000 (98.9274)  time: 0.3676  data: 0.0036  max mem: 2503
Train: Epoch[2/5]  [3540/3750]  eta: 0:01:41  Lr: 0.001875  Loss: -0.3654  Acc@1: 87.5000 (80.1080)  Acc@5: 100.0000 (98.9269)  time: 0.3661  data: 0.0080  max mem: 2503
Train: Epoch[2/5]  [3550/3750]  eta: 0:01:36  Lr: 0.001875  Loss: -0.7698  Acc@1: 81.2500 (80.1130)  Acc@5: 100.0000 (98.9281)  time: 0.3569  data: 0.0068  max mem: 2503
Train: Epoch[2/5]  [3560/3750]  eta: 0:01:31  Lr: 0.001875  Loss: -0.8230  Acc@1: 87.5000 (80.1162)  Acc@5: 100.0000 (98.9294)  time: 0.3560  data: 0.0028  max mem: 2503
Train: Epoch[2/5]  [3570/3750]  eta: 0:01:26  Lr: 0.001875  Loss: -0.3465  Acc@1: 81.2500 (80.1229)  Acc@5: 100.0000 (98.9289)  time: 0.3550  data: 0.0022  max mem: 2503
Train: Epoch[2/5]  [3580/3750]  eta: 0:01:21  Lr: 0.001875  Loss: -0.2688  Acc@1: 81.2500 (80.1243)  Acc@5: 100.0000 (98.9266)  time: 0.3523  data: 0.0027  max mem: 2503
Train: Epoch[2/5]  [3590/3750]  eta: 0:01:17  Lr: 0.001875  Loss: -0.7112  Acc@1: 81.2500 (80.1413)  Acc@5: 100.0000 (98.9296)  time: 0.3528  data: 0.0031  max mem: 2503
Train: Epoch[2/5]  [3600/3750]  eta: 0:01:12  Lr: 0.001875  Loss: -0.7986  Acc@1: 81.2500 (80.1340)  Acc@5: 100.0000 (98.9291)  time: 0.3545  data: 0.0025  max mem: 2503
Train: Epoch[2/5]  [3610/3750]  eta: 0:01:07  Lr: 0.001875  Loss: -0.4992  Acc@1: 81.2500 (80.1284)  Acc@5: 100.0000 (98.9321)  time: 0.3606  data: 0.0027  max mem: 2503
Train: Epoch[2/5]  [3620/3750]  eta: 0:01:02  Lr: 0.001875  Loss: -0.7922  Acc@1: 81.2500 (80.1281)  Acc@5: 100.0000 (98.9350)  time: 0.3592  data: 0.0034  max mem: 2503
Train: Epoch[2/5]  [3630/3750]  eta: 0:00:57  Lr: 0.001875  Loss: -0.3196  Acc@1: 75.0000 (80.1122)  Acc@5: 100.0000 (98.9362)  time: 0.3568  data: 0.0031  max mem: 2503
Train: Epoch[2/5]  [3640/3750]  eta: 0:00:52  Lr: 0.001875  Loss: -0.5552  Acc@1: 75.0000 (80.1119)  Acc@5: 100.0000 (98.9271)  time: 0.3635  data: 0.0049  max mem: 2503
Train: Epoch[2/5]  [3650/3750]  eta: 0:00:47  Lr: 0.001875  Loss: -0.6517  Acc@1: 81.2500 (80.1048)  Acc@5: 100.0000 (98.9267)  time: 0.3632  data: 0.0066  max mem: 2503
Train: Epoch[2/5]  [3660/3750]  eta: 0:00:43  Lr: 0.001875  Loss: -0.5955  Acc@1: 81.2500 (80.0891)  Acc@5: 100.0000 (98.9296)  time: 0.3582  data: 0.0057  max mem: 2503
Train: Epoch[2/5]  [3670/3750]  eta: 0:00:38  Lr: 0.001875  Loss: -0.7376  Acc@1: 75.0000 (80.0770)  Acc@5: 100.0000 (98.9325)  time: 0.3629  data: 0.0045  max mem: 2503
Train: Epoch[2/5]  [3680/3750]  eta: 0:00:33  Lr: 0.001875  Loss: -0.9084  Acc@1: 81.2500 (80.0818)  Acc@5: 100.0000 (98.9286)  time: 0.3607  data: 0.0046  max mem: 2503
Train: Epoch[2/5]  [3690/3750]  eta: 0:00:28  Lr: 0.001875  Loss: -0.0434  Acc@1: 81.2500 (80.0799)  Acc@5: 100.0000 (98.9298)  time: 0.3574  data: 0.0063  max mem: 2503
Train: Epoch[2/5]  [3700/3750]  eta: 0:00:23  Lr: 0.001875  Loss: -0.4432  Acc@1: 81.2500 (80.0814)  Acc@5: 100.0000 (98.9310)  time: 0.3605  data: 0.0051  max mem: 2503
Train: Epoch[2/5]  [3710/3750]  eta: 0:00:19  Lr: 0.001875  Loss: -0.4085  Acc@1: 81.2500 (80.0947)  Acc@5: 100.0000 (98.9289)  time: 0.3567  data: 0.0021  max mem: 2503
Train: Epoch[2/5]  [3720/3750]  eta: 0:00:14  Lr: 0.001875  Loss: -0.5058  Acc@1: 81.2500 (80.0944)  Acc@5: 100.0000 (98.9284)  time: 0.3541  data: 0.0017  max mem: 2503
Train: Epoch[2/5]  [3730/3750]  eta: 0:00:09  Lr: 0.001875  Loss: -0.8021  Acc@1: 81.2500 (80.0992)  Acc@5: 100.0000 (98.9246)  time: 0.3575  data: 0.0029  max mem: 2503
Train: Epoch[2/5]  [3740/3750]  eta: 0:00:04  Lr: 0.001875  Loss: -0.6348  Acc@1: 81.2500 (80.0972)  Acc@5: 100.0000 (98.9258)  time: 0.3594  data: 0.0023  max mem: 2503
Train: Epoch[2/5]  [3749/3750]  eta: 0:00:00  Lr: 0.001875  Loss: -0.9398  Acc@1: 81.2500 (80.0967)  Acc@5: 100.0000 (98.9233)  time: 0.3580  data: 0.0032  max mem: 2503
Train: Epoch[2/5] Total time: 0:29:48 (0.4770 s / it)
{0: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 1: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 2: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 3: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 4: {0: 0, 1: 300000, 2: 0, 3: 352, 4: 0}, 5: {0: 0, 1: 300000, 2: 0, 3: 352, 4: 0}, 6: {0: 0, 1: 300000, 2: 0, 3: 352, 4: 0}, 7: {0: 0, 1: 300000, 2: 0, 3: 352, 4: 0}, 8: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 9: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 10: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 11: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 12: {0: 0, 1: 0, 2: 0, 3: 90968, 4: 0}, 13: {0: 0, 1: 0, 2: 0, 3: 90968, 4: 0}, 14: {0: 0, 1: 0, 2: 0, 3: 90968, 4: 0}, 15: {0: 0, 1: 0, 2: 0, 3: 90968, 4: 0}, 16: {0: 0, 1: 0, 2: 0, 3: 0, 4: 120000}, 17: {0: 0, 1: 0, 2: 0, 3: 0, 4: 120000}, 18: {0: 0, 1: 0, 2: 0, 3: 0, 4: 120000}, 19: {0: 0, 1: 0, 2: 0, 3: 0, 4: 120000}}
Averaged stats: Lr: 0.001875  Loss: -0.9398  Acc@1: 81.2500 (80.0967)  Acc@5: 100.0000 (98.9233)
Train: Epoch[3/5]  [   0/3750]  eta: 1:20:32  Lr: 0.001875  Loss: -0.7906  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (100.0000)  time: 1.2886  data: 0.8904  max mem: 2503
Train: Epoch[3/5]  [  10/3750]  eta: 0:27:26  Lr: 0.001875  Loss: -0.2290  Acc@1: 81.2500 (81.2500)  Acc@5: 100.0000 (98.2955)  time: 0.4403  data: 0.0835  max mem: 2503
Train: Epoch[3/5]  [  20/3750]  eta: 0:24:59  Lr: 0.001875  Loss: -0.4917  Acc@1: 81.2500 (80.3571)  Acc@5: 100.0000 (98.8095)  time: 0.3578  data: 0.0044  max mem: 2503
Train: Epoch[3/5]  [  30/3750]  eta: 0:24:02  Lr: 0.001875  Loss: -0.3603  Acc@1: 81.2500 (79.4355)  Acc@5: 100.0000 (98.5887)  time: 0.3588  data: 0.0047  max mem: 2503
Train: Epoch[3/5]  [  40/3750]  eta: 0:23:33  Lr: 0.001875  Loss: -0.3615  Acc@1: 75.0000 (79.5732)  Acc@5: 100.0000 (98.4756)  time: 0.3589  data: 0.0028  max mem: 2503
Train: Epoch[3/5]  [  50/3750]  eta: 0:23:13  Lr: 0.001875  Loss: -0.6348  Acc@1: 81.2500 (79.5343)  Acc@5: 100.0000 (98.4069)  time: 0.3598  data: 0.0038  max mem: 2503
Train: Epoch[3/5]  [  60/3750]  eta: 0:23:02  Lr: 0.001875  Loss: -0.7325  Acc@1: 81.2500 (78.8934)  Acc@5: 100.0000 (98.6680)  time: 0.3613  data: 0.0045  max mem: 2503
Train: Epoch[3/5]  [  70/3750]  eta: 0:22:56  Lr: 0.001875  Loss: -0.8619  Acc@1: 81.2500 (79.5775)  Acc@5: 100.0000 (98.7676)  time: 0.3670  data: 0.0053  max mem: 2503
Train: Epoch[3/5]  [  80/3750]  eta: 0:22:45  Lr: 0.001875  Loss: -0.6176  Acc@1: 81.2500 (79.6296)  Acc@5: 100.0000 (98.9198)  time: 0.3650  data: 0.0072  max mem: 2503
Train: Epoch[3/5]  [  90/3750]  eta: 0:22:35  Lr: 0.001875  Loss: -0.8256  Acc@1: 81.2500 (79.9451)  Acc@5: 100.0000 (98.8324)  time: 0.3571  data: 0.0055  max mem: 2503
Train: Epoch[3/5]  [ 100/3750]  eta: 0:22:26  Lr: 0.001875  Loss: -0.7630  Acc@1: 81.2500 (80.3218)  Acc@5: 100.0000 (98.7005)  time: 0.3552  data: 0.0027  max mem: 2503
Train: Epoch[3/5]  [ 110/3750]  eta: 0:22:17  Lr: 0.001875  Loss: -0.4007  Acc@1: 81.2500 (80.4617)  Acc@5: 100.0000 (98.7050)  time: 0.3547  data: 0.0021  max mem: 2503
Train: Epoch[3/5]  [ 120/3750]  eta: 0:22:13  Lr: 0.001875  Loss: -0.5892  Acc@1: 81.2500 (80.5269)  Acc@5: 100.0000 (98.8120)  time: 0.3602  data: 0.0039  max mem: 2503
Train: Epoch[3/5]  [ 130/3750]  eta: 0:22:07  Lr: 0.001875  Loss: -0.4599  Acc@1: 81.2500 (80.4389)  Acc@5: 100.0000 (98.7595)  time: 0.3624  data: 0.0046  max mem: 2503
Train: Epoch[3/5]  [ 140/3750]  eta: 0:22:01  Lr: 0.001875  Loss: -0.8493  Acc@1: 81.2500 (80.6738)  Acc@5: 100.0000 (98.8475)  time: 0.3587  data: 0.0045  max mem: 2503
Train: Epoch[3/5]  [ 150/3750]  eta: 0:21:56  Lr: 0.001875  Loss: -0.7214  Acc@1: 81.2500 (80.5050)  Acc@5: 100.0000 (98.8825)  time: 0.3592  data: 0.0038  max mem: 2503
Train: Epoch[3/5]  [ 160/3750]  eta: 0:21:50  Lr: 0.001875  Loss: -0.7676  Acc@1: 75.0000 (80.4736)  Acc@5: 100.0000 (98.9130)  time: 0.3566  data: 0.0024  max mem: 2503
Train: Epoch[3/5]  [ 170/3750]  eta: 0:21:44  Lr: 0.001875  Loss: -0.5596  Acc@1: 81.2500 (80.4825)  Acc@5: 100.0000 (98.9401)  time: 0.3535  data: 0.0025  max mem: 2503
Train: Epoch[3/5]  [ 180/3750]  eta: 0:21:38  Lr: 0.001875  Loss: -0.6219  Acc@1: 81.2500 (80.4558)  Acc@5: 100.0000 (98.8950)  time: 0.3531  data: 0.0025  max mem: 2503
Train: Epoch[3/5]  [ 190/3750]  eta: 0:21:32  Lr: 0.001875  Loss: -0.2434  Acc@1: 81.2500 (80.3338)  Acc@5: 100.0000 (98.8874)  time: 0.3522  data: 0.0028  max mem: 2503
Train: Epoch[3/5]  [ 200/3750]  eta: 0:21:28  Lr: 0.001875  Loss: -0.7328  Acc@1: 81.2500 (80.2861)  Acc@5: 100.0000 (98.8806)  time: 0.3555  data: 0.0021  max mem: 2503
Train: Epoch[3/5]  [ 210/3750]  eta: 0:21:26  Lr: 0.001875  Loss: -0.5410  Acc@1: 81.2500 (80.0948)  Acc@5: 100.0000 (98.8744)  time: 0.3657  data: 0.0073  max mem: 2503
Train: Epoch[3/5]  [ 220/3750]  eta: 0:21:20  Lr: 0.001875  Loss: -0.7493  Acc@1: 81.2500 (80.1471)  Acc@5: 100.0000 (98.8122)  time: 0.3620  data: 0.0080  max mem: 2503
Train: Epoch[3/5]  [ 230/3750]  eta: 0:21:15  Lr: 0.001875  Loss: -0.4059  Acc@1: 81.2500 (80.3030)  Acc@5: 100.0000 (98.8095)  time: 0.3524  data: 0.0027  max mem: 2503
Train: Epoch[3/5]  [ 240/3750]  eta: 0:21:11  Lr: 0.001875  Loss: -0.8904  Acc@1: 87.5000 (80.4979)  Acc@5: 100.0000 (98.8330)  time: 0.3558  data: 0.0046  max mem: 2503
Train: Epoch[3/5]  [ 250/3750]  eta: 0:21:07  Lr: 0.001875  Loss: -0.0070  Acc@1: 81.2500 (80.4283)  Acc@5: 100.0000 (98.8048)  time: 0.3594  data: 0.0041  max mem: 2503
Train: Epoch[3/5]  [ 260/3750]  eta: 0:21:02  Lr: 0.001875  Loss: -0.5289  Acc@1: 81.2500 (80.5556)  Acc@5: 100.0000 (98.8027)  time: 0.3569  data: 0.0017  max mem: 2503
Train: Epoch[3/5]  [ 270/3750]  eta: 0:20:58  Lr: 0.001875  Loss: -0.5369  Acc@1: 87.5000 (80.6504)  Acc@5: 100.0000 (98.8007)  time: 0.3539  data: 0.0012  max mem: 2503
Train: Epoch[3/5]  [ 280/3750]  eta: 0:20:53  Lr: 0.001875  Loss: -0.8049  Acc@1: 81.2500 (80.6940)  Acc@5: 100.0000 (98.7989)  time: 0.3549  data: 0.0038  max mem: 2503
Train: Epoch[3/5]  [ 290/3750]  eta: 0:20:49  Lr: 0.001875  Loss: -0.7302  Acc@1: 81.2500 (80.6701)  Acc@5: 100.0000 (98.8187)  time: 0.3545  data: 0.0059  max mem: 2503
Train: Epoch[3/5]  [ 300/3750]  eta: 0:20:45  Lr: 0.001875  Loss: -0.8086  Acc@1: 81.2500 (80.7309)  Acc@5: 100.0000 (98.8580)  time: 0.3587  data: 0.0056  max mem: 2503
Train: Epoch[3/5]  [ 310/3750]  eta: 0:20:41  Lr: 0.001875  Loss: -0.9068  Acc@1: 81.2500 (80.8079)  Acc@5: 100.0000 (98.8344)  time: 0.3588  data: 0.0044  max mem: 2503
Train: Epoch[3/5]  [ 320/3750]  eta: 0:20:37  Lr: 0.001875  Loss: -0.0997  Acc@1: 81.2500 (80.7243)  Acc@5: 100.0000 (98.7928)  time: 0.3553  data: 0.0039  max mem: 2503
Train: Epoch[3/5]  [ 330/3750]  eta: 0:20:33  Lr: 0.001875  Loss: -0.7115  Acc@1: 81.2500 (80.7779)  Acc@5: 100.0000 (98.8293)  time: 0.3554  data: 0.0039  max mem: 2503
Train: Epoch[3/5]  [ 340/3750]  eta: 0:20:29  Lr: 0.001875  Loss: -0.3321  Acc@1: 81.2500 (80.8468)  Acc@5: 100.0000 (98.8453)  time: 0.3570  data: 0.0042  max mem: 2503
Train: Epoch[3/5]  [ 350/3750]  eta: 0:20:25  Lr: 0.001875  Loss: -0.5922  Acc@1: 81.2500 (80.7870)  Acc@5: 100.0000 (98.8604)  time: 0.3603  data: 0.0055  max mem: 2503
Train: Epoch[3/5]  [ 360/3750]  eta: 0:20:22  Lr: 0.001875  Loss: -0.5697  Acc@1: 81.2500 (80.8864)  Acc@5: 100.0000 (98.8747)  time: 0.3626  data: 0.0073  max mem: 2503
Train: Epoch[3/5]  [ 370/3750]  eta: 0:20:18  Lr: 0.001875  Loss: -0.0534  Acc@1: 81.2500 (80.9299)  Acc@5: 100.0000 (98.8713)  time: 0.3596  data: 0.0059  max mem: 2503
Train: Epoch[3/5]  [ 380/3750]  eta: 0:20:15  Lr: 0.001875  Loss: -0.5069  Acc@1: 75.0000 (80.6594)  Acc@5: 100.0000 (98.8681)  time: 0.3602  data: 0.0041  max mem: 2503
Train: Epoch[3/5]  [ 390/3750]  eta: 0:20:11  Lr: 0.001875  Loss: -0.6111  Acc@1: 75.0000 (80.6586)  Acc@5: 100.0000 (98.8811)  time: 0.3609  data: 0.0052  max mem: 2503
Train: Epoch[3/5]  [ 400/3750]  eta: 0:20:07  Lr: 0.001875  Loss: -0.5423  Acc@1: 81.2500 (80.7045)  Acc@5: 100.0000 (98.8934)  time: 0.3540  data: 0.0029  max mem: 2503
Train: Epoch[3/5]  [ 410/3750]  eta: 0:20:03  Lr: 0.001875  Loss: -0.8523  Acc@1: 81.2500 (80.8698)  Acc@5: 100.0000 (98.9203)  time: 0.3538  data: 0.0019  max mem: 2503
Train: Epoch[3/5]  [ 420/3750]  eta: 0:19:59  Lr: 0.001875  Loss: -0.4113  Acc@1: 87.5000 (80.9234)  Acc@5: 100.0000 (98.9311)  time: 0.3574  data: 0.0043  max mem: 2503
Train: Epoch[3/5]  [ 430/3750]  eta: 0:19:55  Lr: 0.001875  Loss: -0.7412  Acc@1: 87.5000 (81.0035)  Acc@5: 100.0000 (98.9269)  time: 0.3606  data: 0.0069  max mem: 2503
Train: Epoch[3/5]  [ 440/3750]  eta: 0:19:51  Lr: 0.001875  Loss: -0.4165  Acc@1: 81.2500 (80.9807)  Acc@5: 100.0000 (98.9512)  time: 0.3554  data: 0.0045  max mem: 2503
Train: Epoch[3/5]  [ 450/3750]  eta: 0:19:47  Lr: 0.001875  Loss: -0.7004  Acc@1: 81.2500 (80.8897)  Acc@5: 100.0000 (98.9606)  time: 0.3540  data: 0.0023  max mem: 2503
Train: Epoch[3/5]  [ 460/3750]  eta: 0:19:44  Lr: 0.001875  Loss: -0.7165  Acc@1: 81.2500 (80.8704)  Acc@5: 100.0000 (98.9561)  time: 0.3588  data: 0.0046  max mem: 2503
Train: Epoch[3/5]  [ 470/3750]  eta: 0:19:40  Lr: 0.001875  Loss: -0.8017  Acc@1: 81.2500 (80.9448)  Acc@5: 100.0000 (98.9650)  time: 0.3598  data: 0.0049  max mem: 2503
Train: Epoch[3/5]  [ 480/3750]  eta: 0:19:37  Lr: 0.001875  Loss: -0.4697  Acc@1: 81.2500 (80.9901)  Acc@5: 100.0000 (98.9735)  time: 0.3622  data: 0.0038  max mem: 2503
Train: Epoch[3/5]  [ 490/3750]  eta: 0:19:33  Lr: 0.001875  Loss: -0.6322  Acc@1: 81.2500 (81.0336)  Acc@5: 100.0000 (98.9689)  time: 0.3614  data: 0.0027  max mem: 2503
Train: Epoch[3/5]  [ 500/3750]  eta: 0:19:30  Lr: 0.001875  Loss: -0.5542  Acc@1: 81.2500 (81.0379)  Acc@5: 100.0000 (98.9521)  time: 0.3627  data: 0.0034  max mem: 2503
Train: Epoch[3/5]  [ 510/3750]  eta: 0:19:26  Lr: 0.001875  Loss: -0.4967  Acc@1: 81.2500 (81.0543)  Acc@5: 100.0000 (98.9237)  time: 0.3649  data: 0.0043  max mem: 2503
Train: Epoch[3/5]  [ 520/3750]  eta: 0:19:23  Lr: 0.001875  Loss: -0.4298  Acc@1: 81.2500 (81.0821)  Acc@5: 100.0000 (98.9323)  time: 0.3592  data: 0.0047  max mem: 2503
Train: Epoch[3/5]  [ 530/3750]  eta: 0:19:19  Lr: 0.001875  Loss: -0.4618  Acc@1: 81.2500 (81.1441)  Acc@5: 100.0000 (98.9289)  time: 0.3544  data: 0.0038  max mem: 2503
Train: Epoch[3/5]  [ 540/3750]  eta: 0:19:15  Lr: 0.001875  Loss: -0.6640  Acc@1: 81.2500 (81.0652)  Acc@5: 100.0000 (98.9372)  time: 0.3543  data: 0.0022  max mem: 2503
Train: Epoch[3/5]  [ 550/3750]  eta: 0:19:11  Lr: 0.001875  Loss: -0.7947  Acc@1: 81.2500 (81.1139)  Acc@5: 100.0000 (98.9564)  time: 0.3538  data: 0.0018  max mem: 2503
Train: Epoch[3/5]  [ 560/3750]  eta: 0:19:07  Lr: 0.001875  Loss: -0.5705  Acc@1: 81.2500 (80.9938)  Acc@5: 100.0000 (98.9416)  time: 0.3556  data: 0.0041  max mem: 2503
Train: Epoch[3/5]  [ 570/3750]  eta: 0:19:03  Lr: 0.001875  Loss: -0.5456  Acc@1: 81.2500 (81.0311)  Acc@5: 100.0000 (98.9492)  time: 0.3549  data: 0.0052  max mem: 2503
Train: Epoch[3/5]  [ 580/3750]  eta: 0:18:59  Lr: 0.001875  Loss: -0.5182  Acc@1: 81.2500 (81.0886)  Acc@5: 100.0000 (98.9673)  time: 0.3533  data: 0.0030  max mem: 2503
Train: Epoch[3/5]  [ 590/3750]  eta: 0:18:56  Lr: 0.001875  Loss: -0.6464  Acc@1: 81.2500 (81.0491)  Acc@5: 100.0000 (98.9742)  time: 0.3600  data: 0.0028  max mem: 2503
Train: Epoch[3/5]  [ 600/3750]  eta: 0:18:52  Lr: 0.001875  Loss: -0.2818  Acc@1: 81.2500 (81.0108)  Acc@5: 100.0000 (98.9705)  time: 0.3582  data: 0.0020  max mem: 2503
Train: Epoch[3/5]  [ 610/3750]  eta: 0:18:48  Lr: 0.001875  Loss: -0.2916  Acc@1: 81.2500 (81.0556)  Acc@5: 100.0000 (98.9669)  time: 0.3531  data: 0.0011  max mem: 2503
Train: Epoch[3/5]  [ 620/3750]  eta: 0:18:44  Lr: 0.001875  Loss: -0.2324  Acc@1: 75.0000 (80.9380)  Acc@5: 100.0000 (98.9432)  time: 0.3552  data: 0.0017  max mem: 2503
Train: Epoch[3/5]  [ 630/3750]  eta: 0:18:53  Lr: 0.001875  Loss: -0.5125  Acc@1: 75.0000 (80.9628)  Acc@5: 100.0000 (98.9600)  time: 0.4796  data: 0.0056  max mem: 2503
Train: Epoch[3/5]  [ 640/3750]  eta: 0:19:03  Lr: 0.001875  Loss: -0.5727  Acc@1: 81.2500 (80.8697)  Acc@5: 100.0000 (98.9567)  time: 0.6298  data: 0.0047  max mem: 2503
Train: Epoch[3/5]  [ 650/3750]  eta: 0:19:15  Lr: 0.001875  Loss: -0.5981  Acc@1: 75.0000 (80.8468)  Acc@5: 100.0000 (98.9727)  time: 0.6777  data: 0.0007  max mem: 2503
Train: Epoch[3/5]  [ 660/3750]  eta: 0:19:26  Lr: 0.001875  Loss: -0.6871  Acc@1: 81.2500 (80.9380)  Acc@5: 100.0000 (98.9788)  time: 0.6934  data: 0.0006  max mem: 2503
Train: Epoch[3/5]  [ 670/3750]  eta: 0:19:37  Lr: 0.001875  Loss: -0.7091  Acc@1: 87.5000 (80.9426)  Acc@5: 100.0000 (98.9940)  time: 0.6877  data: 0.0006  max mem: 2503
Train: Epoch[3/5]  [ 680/3750]  eta: 0:19:46  Lr: 0.001875  Loss: -0.1588  Acc@1: 87.5000 (80.9930)  Acc@5: 100.0000 (99.0088)  time: 0.6845  data: 0.0007  max mem: 2503
Train: Epoch[3/5]  [ 690/3750]  eta: 0:19:55  Lr: 0.001875  Loss: -0.4700  Acc@1: 87.5000 (81.0148)  Acc@5: 100.0000 (99.0141)  time: 0.6696  data: 0.0008  max mem: 2503
Train: Epoch[3/5]  [ 700/3750]  eta: 0:20:04  Lr: 0.001875  Loss: -0.7664  Acc@1: 81.2500 (80.9914)  Acc@5: 100.0000 (99.0014)  time: 0.6756  data: 0.0008  max mem: 2503
Train: Epoch[3/5]  [ 710/3750]  eta: 0:20:12  Lr: 0.001875  Loss: -0.7530  Acc@1: 81.2500 (80.9951)  Acc@5: 100.0000 (99.0155)  time: 0.6882  data: 0.0007  max mem: 2503
Train: Epoch[3/5]  [ 720/3750]  eta: 0:20:20  Lr: 0.001875  Loss: -0.8965  Acc@1: 81.2500 (81.0246)  Acc@5: 100.0000 (99.0291)  time: 0.6850  data: 0.0007  max mem: 2503
Train: Epoch[3/5]  [ 730/3750]  eta: 0:20:28  Lr: 0.001875  Loss: -0.3354  Acc@1: 81.2500 (81.0021)  Acc@5: 100.0000 (99.0082)  time: 0.6921  data: 0.0006  max mem: 2503
Train: Epoch[3/5]  [ 740/3750]  eta: 0:20:34  Lr: 0.001875  Loss: -0.7733  Acc@1: 81.2500 (81.0223)  Acc@5: 100.0000 (99.0047)  time: 0.6701  data: 0.0007  max mem: 2503
Train: Epoch[3/5]  [ 750/3750]  eta: 0:20:41  Lr: 0.001875  Loss: -0.4795  Acc@1: 81.2500 (80.9754)  Acc@5: 100.0000 (98.9847)  time: 0.6662  data: 0.0007  max mem: 2503
Train: Epoch[3/5]  [ 760/3750]  eta: 0:20:48  Lr: 0.001875  Loss: -0.6572  Acc@1: 81.2500 (80.9051)  Acc@5: 100.0000 (98.9816)  time: 0.6908  data: 0.0010  max mem: 2503
Train: Epoch[3/5]  [ 770/3750]  eta: 0:20:54  Lr: 0.001875  Loss: 0.1181  Acc@1: 81.2500 (80.9339)  Acc@5: 100.0000 (98.9624)  time: 0.6931  data: 0.0013  max mem: 2503
Train: Epoch[3/5]  [ 780/3750]  eta: 0:21:00  Lr: 0.001875  Loss: -0.6456  Acc@1: 81.2500 (80.8739)  Acc@5: 100.0000 (98.9757)  time: 0.6904  data: 0.0010  max mem: 2503
Train: Epoch[3/5]  [ 790/3750]  eta: 0:21:03  Lr: 0.001875  Loss: -0.5813  Acc@1: 75.0000 (80.8549)  Acc@5: 100.0000 (98.9886)  time: 0.6432  data: 0.0009  max mem: 2503
Train: Epoch[3/5]  [ 800/3750]  eta: 0:21:08  Lr: 0.001875  Loss: -0.2835  Acc@1: 81.2500 (80.8130)  Acc@5: 100.0000 (98.9388)  time: 0.6430  data: 0.0008  max mem: 2503
Train: Epoch[3/5]  [ 810/3750]  eta: 0:21:13  Lr: 0.001875  Loss: -0.8184  Acc@1: 81.2500 (80.8416)  Acc@5: 100.0000 (98.9442)  time: 0.6919  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [ 820/3750]  eta: 0:21:18  Lr: 0.001875  Loss: -0.7401  Acc@1: 81.2500 (80.8313)  Acc@5: 100.0000 (98.9342)  time: 0.6957  data: 0.0007  max mem: 2503
Train: Epoch[3/5]  [ 830/3750]  eta: 0:21:23  Lr: 0.001875  Loss: -0.6620  Acc@1: 81.2500 (80.8514)  Acc@5: 100.0000 (98.9320)  time: 0.6936  data: 0.0007  max mem: 2503
Train: Epoch[3/5]  [ 840/3750]  eta: 0:21:26  Lr: 0.001875  Loss: -0.4759  Acc@1: 81.2500 (80.8190)  Acc@5: 100.0000 (98.9373)  time: 0.6812  data: 0.0011  max mem: 2503
Train: Epoch[3/5]  [ 850/3750]  eta: 0:21:30  Lr: 0.001875  Loss: -0.5424  Acc@1: 81.2500 (80.8314)  Acc@5: 100.0000 (98.9498)  time: 0.6737  data: 0.0013  max mem: 2503
Train: Epoch[3/5]  [ 860/3750]  eta: 0:21:34  Lr: 0.001875  Loss: -0.2397  Acc@1: 81.2500 (80.8508)  Acc@5: 100.0000 (98.9474)  time: 0.6855  data: 0.0008  max mem: 2503
Train: Epoch[3/5]  [ 870/3750]  eta: 0:21:38  Lr: 0.001875  Loss: -0.4890  Acc@1: 81.2500 (80.8410)  Acc@5: 100.0000 (98.9524)  time: 0.6939  data: 0.0008  max mem: 2503
Train: Epoch[3/5]  [ 880/3750]  eta: 0:21:41  Lr: 0.001875  Loss: -0.3207  Acc@1: 81.2500 (80.8669)  Acc@5: 100.0000 (98.9642)  time: 0.6931  data: 0.0007  max mem: 2503
Train: Epoch[3/5]  [ 890/3750]  eta: 0:21:44  Lr: 0.001875  Loss: -0.5131  Acc@1: 81.2500 (80.8782)  Acc@5: 100.0000 (98.9689)  time: 0.6849  data: 0.0006  max mem: 2503
Train: Epoch[3/5]  [ 900/3750]  eta: 0:21:46  Lr: 0.001875  Loss: -0.6096  Acc@1: 81.2500 (80.8407)  Acc@5: 100.0000 (98.9734)  time: 0.6790  data: 0.0007  max mem: 2503
Train: Epoch[3/5]  [ 910/3750]  eta: 0:21:49  Lr: 0.001875  Loss: -0.5788  Acc@1: 75.0000 (80.7972)  Acc@5: 100.0000 (98.9846)  time: 0.6856  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [ 920/3750]  eta: 0:21:51  Lr: 0.001875  Loss: -0.3197  Acc@1: 81.2500 (80.8360)  Acc@5: 100.0000 (98.9753)  time: 0.6926  data: 0.0007  max mem: 2503
Train: Epoch[3/5]  [ 930/3750]  eta: 0:21:53  Lr: 0.001875  Loss: -0.7538  Acc@1: 81.2500 (80.7935)  Acc@5: 100.0000 (98.9527)  time: 0.6877  data: 0.0012  max mem: 2503
Train: Epoch[3/5]  [ 940/3750]  eta: 0:21:55  Lr: 0.001875  Loss: -0.2423  Acc@1: 81.2500 (80.8050)  Acc@5: 100.0000 (98.9639)  time: 0.6859  data: 0.0010  max mem: 2503
Train: Epoch[3/5]  [ 950/3750]  eta: 0:21:56  Lr: 0.001875  Loss: -0.9520  Acc@1: 81.2500 (80.8360)  Acc@5: 100.0000 (98.9616)  time: 0.6715  data: 0.0006  max mem: 2503
Train: Epoch[3/5]  [ 960/3750]  eta: 0:21:58  Lr: 0.001875  Loss: -0.8240  Acc@1: 81.2500 (80.8533)  Acc@5: 100.0000 (98.9659)  time: 0.6764  data: 0.0006  max mem: 2503
Train: Epoch[3/5]  [ 970/3750]  eta: 0:21:59  Lr: 0.001875  Loss: -0.5893  Acc@1: 81.2500 (80.8509)  Acc@5: 100.0000 (98.9701)  time: 0.6901  data: 0.0008  max mem: 2503
Train: Epoch[3/5]  [ 980/3750]  eta: 0:21:52  Lr: 0.001875  Loss: -0.6328  Acc@1: 81.2500 (80.8104)  Acc@5: 100.0000 (98.9679)  time: 0.5368  data: 0.0008  max mem: 2503
Train: Epoch[3/5]  [ 990/3750]  eta: 0:21:50  Lr: 0.001875  Loss: -0.3648  Acc@1: 81.2500 (80.8085)  Acc@5: 100.0000 (98.9594)  time: 0.4714  data: 0.0010  max mem: 2503
Train: Epoch[3/5]  [1000/3750]  eta: 0:21:51  Lr: 0.001875  Loss: -0.7491  Acc@1: 81.2500 (80.7817)  Acc@5: 100.0000 (98.9448)  time: 0.6160  data: 0.0010  max mem: 2503
Train: Epoch[3/5]  [1010/3750]  eta: 0:21:44  Lr: 0.001875  Loss: -0.0952  Acc@1: 81.2500 (80.8049)  Acc@5: 100.0000 (98.9491)  time: 0.5540  data: 0.0007  max mem: 2503
Train: Epoch[3/5]  [1020/3750]  eta: 0:21:36  Lr: 0.001875  Loss: -0.3518  Acc@1: 87.5000 (80.8337)  Acc@5: 100.0000 (98.9532)  time: 0.3876  data: 0.0007  max mem: 2503
Train: Epoch[3/5]  [1030/3750]  eta: 0:21:28  Lr: 0.001875  Loss: -0.5913  Acc@1: 81.2500 (80.8135)  Acc@5: 100.0000 (98.9573)  time: 0.3540  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [1040/3750]  eta: 0:21:20  Lr: 0.001875  Loss: -0.7772  Acc@1: 81.2500 (80.8718)  Acc@5: 100.0000 (98.9613)  time: 0.3530  data: 0.0006  max mem: 2503
Train: Epoch[3/5]  [1050/3750]  eta: 0:21:12  Lr: 0.001875  Loss: -0.6786  Acc@1: 81.2500 (80.8694)  Acc@5: 100.0000 (98.9712)  time: 0.3478  data: 0.0008  max mem: 2503
Train: Epoch[3/5]  [1060/3750]  eta: 0:21:05  Lr: 0.001875  Loss: -0.5413  Acc@1: 81.2500 (80.8789)  Acc@5: 100.0000 (98.9750)  time: 0.3546  data: 0.0053  max mem: 2503
Train: Epoch[3/5]  [1070/3750]  eta: 0:20:57  Lr: 0.001875  Loss: -0.6897  Acc@1: 87.5000 (80.9349)  Acc@5: 100.0000 (98.9788)  time: 0.3543  data: 0.0061  max mem: 2503
Train: Epoch[3/5]  [1080/3750]  eta: 0:20:49  Lr: 0.001875  Loss: -0.6479  Acc@1: 87.5000 (80.9378)  Acc@5: 100.0000 (98.9709)  time: 0.3471  data: 0.0023  max mem: 2503
Train: Epoch[3/5]  [1090/3750]  eta: 0:20:43  Lr: 0.001875  Loss: -0.4819  Acc@1: 81.2500 (80.9235)  Acc@5: 100.0000 (98.9516)  time: 0.3761  data: 0.0020  max mem: 2503
Train: Epoch[3/5]  [1100/3750]  eta: 0:20:43  Lr: 0.001875  Loss: -0.6375  Acc@1: 87.5000 (80.9662)  Acc@5: 100.0000 (98.9555)  time: 0.5218  data: 0.0019  max mem: 2503
Train: Epoch[3/5]  [1110/3750]  eta: 0:20:43  Lr: 0.001875  Loss: -0.3783  Acc@1: 81.2500 (80.9462)  Acc@5: 100.0000 (98.9536)  time: 0.6572  data: 0.0013  max mem: 2503
Train: Epoch[3/5]  [1120/3750]  eta: 0:20:44  Lr: 0.001875  Loss: -0.5224  Acc@1: 81.2500 (80.9545)  Acc@5: 100.0000 (98.9518)  time: 0.6886  data: 0.0008  max mem: 2503
Train: Epoch[3/5]  [1130/3750]  eta: 0:20:44  Lr: 0.001875  Loss: -0.7132  Acc@1: 87.5000 (81.0069)  Acc@5: 100.0000 (98.9556)  time: 0.6885  data: 0.0006  max mem: 2503
Train: Epoch[3/5]  [1140/3750]  eta: 0:20:43  Lr: 0.001875  Loss: -0.4393  Acc@1: 81.2500 (81.0090)  Acc@5: 100.0000 (98.9592)  time: 0.6648  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [1150/3750]  eta: 0:20:42  Lr: 0.001875  Loss: -0.4075  Acc@1: 81.2500 (81.0056)  Acc@5: 100.0000 (98.9574)  time: 0.6502  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [1160/3750]  eta: 0:20:42  Lr: 0.001875  Loss: -0.6029  Acc@1: 81.2500 (80.9432)  Acc@5: 100.0000 (98.9556)  time: 0.6668  data: 0.0007  max mem: 2503
Train: Epoch[3/5]  [1170/3750]  eta: 0:20:42  Lr: 0.001875  Loss: -0.6964  Acc@1: 68.7500 (80.8924)  Acc@5: 100.0000 (98.9539)  time: 0.6840  data: 0.0009  max mem: 2503
Train: Epoch[3/5]  [1180/3750]  eta: 0:20:41  Lr: 0.001875  Loss: -0.5010  Acc@1: 75.0000 (80.8954)  Acc@5: 100.0000 (98.9575)  time: 0.6799  data: 0.0009  max mem: 2503
Train: Epoch[3/5]  [1190/3750]  eta: 0:20:41  Lr: 0.001875  Loss: -0.7064  Acc@1: 81.2500 (80.8722)  Acc@5: 100.0000 (98.9557)  time: 0.6853  data: 0.0006  max mem: 2503
Train: Epoch[3/5]  [1200/3750]  eta: 0:20:40  Lr: 0.001875  Loss: -0.4983  Acc@1: 81.2500 (80.8597)  Acc@5: 100.0000 (98.9436)  time: 0.6902  data: 0.0006  max mem: 2503
Train: Epoch[3/5]  [1210/3750]  eta: 0:20:39  Lr: 0.001875  Loss: -0.6073  Acc@1: 81.2500 (80.8629)  Acc@5: 100.0000 (98.9472)  time: 0.6740  data: 0.0010  max mem: 2503
Train: Epoch[3/5]  [1220/3750]  eta: 0:20:38  Lr: 0.001875  Loss: -0.7557  Acc@1: 81.2500 (80.8866)  Acc@5: 100.0000 (98.9507)  time: 0.6766  data: 0.0011  max mem: 2503
Train: Epoch[3/5]  [1230/3750]  eta: 0:20:37  Lr: 0.001875  Loss: -0.6644  Acc@1: 81.2500 (80.9149)  Acc@5: 100.0000 (98.9490)  time: 0.6865  data: 0.0007  max mem: 2503
Train: Epoch[3/5]  [1240/3750]  eta: 0:20:36  Lr: 0.001875  Loss: -0.6715  Acc@1: 81.2500 (80.8723)  Acc@5: 100.0000 (98.9474)  time: 0.6809  data: 0.0006  max mem: 2503
Train: Epoch[3/5]  [1250/3750]  eta: 0:20:35  Lr: 0.001875  Loss: -0.4315  Acc@1: 75.0000 (80.8653)  Acc@5: 100.0000 (98.9508)  time: 0.6776  data: 0.0007  max mem: 2503
Train: Epoch[3/5]  [1260/3750]  eta: 0:20:33  Lr: 0.001875  Loss: -0.3963  Acc@1: 81.2500 (80.8535)  Acc@5: 100.0000 (98.9542)  time: 0.6680  data: 0.0006  max mem: 2503
Train: Epoch[3/5]  [1270/3750]  eta: 0:20:32  Lr: 0.001875  Loss: -0.3922  Acc@1: 81.2500 (80.8468)  Acc@5: 100.0000 (98.9526)  time: 0.6704  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [1280/3750]  eta: 0:20:30  Lr: 0.001875  Loss: -0.4714  Acc@1: 75.0000 (80.8158)  Acc@5: 100.0000 (98.9510)  time: 0.6738  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [1290/3750]  eta: 0:20:29  Lr: 0.001875  Loss: -0.2870  Acc@1: 81.2500 (80.8240)  Acc@5: 100.0000 (98.9495)  time: 0.6780  data: 0.0011  max mem: 2503
Train: Epoch[3/5]  [1300/3750]  eta: 0:20:27  Lr: 0.001875  Loss: 0.1093  Acc@1: 75.0000 (80.7552)  Acc@5: 100.0000 (98.9431)  time: 0.6861  data: 0.0011  max mem: 2503
Train: Epoch[3/5]  [1310/3750]  eta: 0:20:25  Lr: 0.001875  Loss: -0.8252  Acc@1: 75.0000 (80.7542)  Acc@5: 100.0000 (98.9464)  time: 0.6739  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [1320/3750]  eta: 0:20:24  Lr: 0.001875  Loss: -0.2439  Acc@1: 81.2500 (80.7579)  Acc@5: 100.0000 (98.9449)  time: 0.6745  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [1330/3750]  eta: 0:20:22  Lr: 0.001875  Loss: -0.7980  Acc@1: 87.5000 (80.8180)  Acc@5: 100.0000 (98.9482)  time: 0.6900  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [1340/3750]  eta: 0:20:20  Lr: 0.001875  Loss: -0.7322  Acc@1: 87.5000 (80.8259)  Acc@5: 100.0000 (98.9467)  time: 0.6868  data: 0.0006  max mem: 2503
Train: Epoch[3/5]  [1350/3750]  eta: 0:20:18  Lr: 0.001875  Loss: -0.6760  Acc@1: 81.2500 (80.8105)  Acc@5: 100.0000 (98.9545)  time: 0.6765  data: 0.0006  max mem: 2503
Train: Epoch[3/5]  [1360/3750]  eta: 0:20:16  Lr: 0.001875  Loss: -0.7583  Acc@1: 81.2500 (80.8275)  Acc@5: 100.0000 (98.9530)  time: 0.6665  data: 0.0011  max mem: 2503
Train: Epoch[3/5]  [1370/3750]  eta: 0:20:14  Lr: 0.001875  Loss: -0.8666  Acc@1: 87.5000 (80.8625)  Acc@5: 100.0000 (98.9561)  time: 0.6744  data: 0.0012  max mem: 2503
Train: Epoch[3/5]  [1380/3750]  eta: 0:20:12  Lr: 0.001875  Loss: -0.6980  Acc@1: 87.5000 (80.8608)  Acc@5: 100.0000 (98.9410)  time: 0.6837  data: 0.0017  max mem: 2503
Train: Epoch[3/5]  [1390/3750]  eta: 0:20:09  Lr: 0.001875  Loss: -0.0276  Acc@1: 75.0000 (80.8187)  Acc@5: 100.0000 (98.9396)  time: 0.6815  data: 0.0018  max mem: 2503
Train: Epoch[3/5]  [1400/3750]  eta: 0:20:07  Lr: 0.001875  Loss: -0.5938  Acc@1: 68.7500 (80.7682)  Acc@5: 100.0000 (98.9293)  time: 0.6859  data: 0.0008  max mem: 2503
Train: Epoch[3/5]  [1410/3750]  eta: 0:20:04  Lr: 0.001875  Loss: -0.5610  Acc@1: 75.0000 (80.7938)  Acc@5: 100.0000 (98.9369)  time: 0.6720  data: 0.0010  max mem: 2503
Train: Epoch[3/5]  [1420/3750]  eta: 0:20:02  Lr: 0.001875  Loss: -0.7472  Acc@1: 81.2500 (80.7750)  Acc@5: 100.0000 (98.9312)  time: 0.6765  data: 0.0009  max mem: 2503
Train: Epoch[3/5]  [1430/3750]  eta: 0:20:00  Lr: 0.001875  Loss: -0.5670  Acc@1: 75.0000 (80.7521)  Acc@5: 100.0000 (98.9212)  time: 0.6882  data: 0.0006  max mem: 2503
Train: Epoch[3/5]  [1440/3750]  eta: 0:19:57  Lr: 0.001875  Loss: -0.7332  Acc@1: 81.2500 (80.7989)  Acc@5: 100.0000 (98.9200)  time: 0.6843  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [1450/3750]  eta: 0:19:51  Lr: 0.001875  Loss: -0.3530  Acc@1: 81.2500 (80.7848)  Acc@5: 100.0000 (98.9188)  time: 0.5700  data: 0.0019  max mem: 2503
Train: Epoch[3/5]  [1460/3750]  eta: 0:19:43  Lr: 0.001875  Loss: -0.4225  Acc@1: 81.2500 (80.7495)  Acc@5: 100.0000 (98.9262)  time: 0.3991  data: 0.0019  max mem: 2503
Train: Epoch[3/5]  [1470/3750]  eta: 0:19:35  Lr: 0.001875  Loss: -0.3137  Acc@1: 81.2500 (80.7699)  Acc@5: 100.0000 (98.9208)  time: 0.3501  data: 0.0010  max mem: 2503
Train: Epoch[3/5]  [1480/3750]  eta: 0:19:28  Lr: 0.001875  Loss: -0.0972  Acc@1: 81.2500 (80.7436)  Acc@5: 100.0000 (98.9239)  time: 0.3561  data: 0.0022  max mem: 2503
Train: Epoch[3/5]  [1490/3750]  eta: 0:19:20  Lr: 0.001875  Loss: -0.3400  Acc@1: 75.0000 (80.7218)  Acc@5: 100.0000 (98.9311)  time: 0.3574  data: 0.0030  max mem: 2503
Train: Epoch[3/5]  [1500/3750]  eta: 0:19:13  Lr: 0.001875  Loss: -0.4927  Acc@1: 81.2500 (80.7628)  Acc@5: 100.0000 (98.9340)  time: 0.3525  data: 0.0021  max mem: 2503
Train: Epoch[3/5]  [1510/3750]  eta: 0:19:05  Lr: 0.001875  Loss: -0.5425  Acc@1: 87.5000 (80.7702)  Acc@5: 100.0000 (98.9370)  time: 0.3527  data: 0.0030  max mem: 2503
Train: Epoch[3/5]  [1520/3750]  eta: 0:18:58  Lr: 0.001875  Loss: -0.4274  Acc@1: 81.2500 (80.7446)  Acc@5: 100.0000 (98.9398)  time: 0.3556  data: 0.0030  max mem: 2503
Train: Epoch[3/5]  [1530/3750]  eta: 0:18:51  Lr: 0.001875  Loss: -0.5596  Acc@1: 75.0000 (80.7397)  Acc@5: 100.0000 (98.9427)  time: 0.3591  data: 0.0008  max mem: 2503
Train: Epoch[3/5]  [1540/3750]  eta: 0:18:43  Lr: 0.001875  Loss: -0.3711  Acc@1: 75.0000 (80.7309)  Acc@5: 100.0000 (98.9293)  time: 0.3610  data: 0.0023  max mem: 2503
Train: Epoch[3/5]  [1550/3750]  eta: 0:18:36  Lr: 0.001875  Loss: -0.4878  Acc@1: 81.2500 (80.7261)  Acc@5: 100.0000 (98.9281)  time: 0.3564  data: 0.0040  max mem: 2503
Train: Epoch[3/5]  [1560/3750]  eta: 0:18:29  Lr: 0.001875  Loss: -0.6404  Acc@1: 81.2500 (80.7135)  Acc@5: 100.0000 (98.9270)  time: 0.3527  data: 0.0024  max mem: 2503
Train: Epoch[3/5]  [1570/3750]  eta: 0:18:22  Lr: 0.001875  Loss: -0.1007  Acc@1: 81.2500 (80.6930)  Acc@5: 100.0000 (98.9258)  time: 0.3523  data: 0.0020  max mem: 2503
Train: Epoch[3/5]  [1580/3750]  eta: 0:18:15  Lr: 0.001875  Loss: -0.9114  Acc@1: 81.2500 (80.6966)  Acc@5: 100.0000 (98.9208)  time: 0.3547  data: 0.0027  max mem: 2503
Train: Epoch[3/5]  [1590/3750]  eta: 0:18:07  Lr: 0.001875  Loss: -0.6038  Acc@1: 81.2500 (80.7157)  Acc@5: 100.0000 (98.9197)  time: 0.3560  data: 0.0028  max mem: 2503
Train: Epoch[3/5]  [1600/3750]  eta: 0:18:00  Lr: 0.001875  Loss: -0.8427  Acc@1: 81.2500 (80.7074)  Acc@5: 100.0000 (98.9225)  time: 0.3531  data: 0.0024  max mem: 2503
Train: Epoch[3/5]  [1610/3750]  eta: 0:17:53  Lr: 0.001875  Loss: -0.9117  Acc@1: 81.2500 (80.7146)  Acc@5: 100.0000 (98.9292)  time: 0.3534  data: 0.0027  max mem: 2503
Train: Epoch[3/5]  [1620/3750]  eta: 0:17:46  Lr: 0.001875  Loss: -0.7388  Acc@1: 81.2500 (80.7179)  Acc@5: 100.0000 (98.9281)  time: 0.3551  data: 0.0031  max mem: 2503
Train: Epoch[3/5]  [1630/3750]  eta: 0:17:40  Lr: 0.001875  Loss: -0.6138  Acc@1: 81.2500 (80.7059)  Acc@5: 100.0000 (98.9232)  time: 0.3556  data: 0.0041  max mem: 2503
Train: Epoch[3/5]  [1640/3750]  eta: 0:17:33  Lr: 0.001875  Loss: -0.7228  Acc@1: 81.2500 (80.7282)  Acc@5: 100.0000 (98.9222)  time: 0.3536  data: 0.0045  max mem: 2503
Train: Epoch[3/5]  [1650/3750]  eta: 0:17:26  Lr: 0.001875  Loss: -0.5487  Acc@1: 81.2500 (80.7352)  Acc@5: 100.0000 (98.9211)  time: 0.3515  data: 0.0026  max mem: 2503
Train: Epoch[3/5]  [1660/3750]  eta: 0:17:19  Lr: 0.001875  Loss: -0.7125  Acc@1: 81.2500 (80.7383)  Acc@5: 100.0000 (98.9238)  time: 0.3529  data: 0.0032  max mem: 2503
Train: Epoch[3/5]  [1670/3750]  eta: 0:17:12  Lr: 0.001875  Loss: -0.6441  Acc@1: 81.2500 (80.7600)  Acc@5: 100.0000 (98.9265)  time: 0.3548  data: 0.0027  max mem: 2503
Train: Epoch[3/5]  [1680/3750]  eta: 0:17:06  Lr: 0.001875  Loss: -0.8696  Acc@1: 81.2500 (80.7741)  Acc@5: 100.0000 (98.9255)  time: 0.3565  data: 0.0041  max mem: 2503
Train: Epoch[3/5]  [1690/3750]  eta: 0:16:59  Lr: 0.001875  Loss: -0.6024  Acc@1: 81.2500 (80.7695)  Acc@5: 100.0000 (98.9245)  time: 0.3535  data: 0.0041  max mem: 2503
Train: Epoch[3/5]  [1700/3750]  eta: 0:16:52  Lr: 0.001875  Loss: -0.6402  Acc@1: 81.2500 (80.7797)  Acc@5: 100.0000 (98.9308)  time: 0.3519  data: 0.0023  max mem: 2503
Train: Epoch[3/5]  [1710/3750]  eta: 0:16:46  Lr: 0.001875  Loss: -0.8971  Acc@1: 81.2500 (80.7897)  Acc@5: 100.0000 (98.9334)  time: 0.3524  data: 0.0038  max mem: 2503
Train: Epoch[3/5]  [1720/3750]  eta: 0:16:39  Lr: 0.001875  Loss: -0.2345  Acc@1: 81.2500 (80.7997)  Acc@5: 100.0000 (98.9396)  time: 0.3529  data: 0.0041  max mem: 2503
Train: Epoch[3/5]  [1730/3750]  eta: 0:16:32  Lr: 0.001875  Loss: -0.7206  Acc@1: 81.2500 (80.7951)  Acc@5: 100.0000 (98.9457)  time: 0.3555  data: 0.0045  max mem: 2503
Train: Epoch[3/5]  [1740/3750]  eta: 0:16:26  Lr: 0.001875  Loss: -0.7311  Acc@1: 81.2500 (80.8120)  Acc@5: 100.0000 (98.9482)  time: 0.3572  data: 0.0042  max mem: 2503
Train: Epoch[3/5]  [1750/3750]  eta: 0:16:20  Lr: 0.001875  Loss: -0.5411  Acc@1: 81.2500 (80.7967)  Acc@5: 100.0000 (98.9506)  time: 0.3544  data: 0.0029  max mem: 2503
Train: Epoch[3/5]  [1760/3750]  eta: 0:16:13  Lr: 0.001875  Loss: -0.3642  Acc@1: 87.5000 (80.8348)  Acc@5: 100.0000 (98.9530)  time: 0.3527  data: 0.0033  max mem: 2503
Train: Epoch[3/5]  [1770/3750]  eta: 0:16:07  Lr: 0.001875  Loss: -0.7774  Acc@1: 87.5000 (80.8547)  Acc@5: 100.0000 (98.9554)  time: 0.3555  data: 0.0063  max mem: 2503
Train: Epoch[3/5]  [1780/3750]  eta: 0:16:00  Lr: 0.001875  Loss: -0.9300  Acc@1: 81.2500 (80.8499)  Acc@5: 100.0000 (98.9542)  time: 0.3600  data: 0.0079  max mem: 2503
Train: Epoch[3/5]  [1790/3750]  eta: 0:15:54  Lr: 0.001875  Loss: -0.5523  Acc@1: 81.2500 (80.8487)  Acc@5: 100.0000 (98.9601)  time: 0.3593  data: 0.0050  max mem: 2503
Train: Epoch[3/5]  [1800/3750]  eta: 0:15:48  Lr: 0.001875  Loss: -0.4770  Acc@1: 81.2500 (80.8509)  Acc@5: 100.0000 (98.9659)  time: 0.3563  data: 0.0028  max mem: 2503
Train: Epoch[3/5]  [1810/3750]  eta: 0:15:42  Lr: 0.001875  Loss: -0.7470  Acc@1: 81.2500 (80.8669)  Acc@5: 100.0000 (98.9716)  time: 0.3555  data: 0.0032  max mem: 2503
Train: Epoch[3/5]  [1820/3750]  eta: 0:15:35  Lr: 0.001875  Loss: -0.7300  Acc@1: 81.2500 (80.8622)  Acc@5: 100.0000 (98.9738)  time: 0.3557  data: 0.0034  max mem: 2503
Train: Epoch[3/5]  [1830/3750]  eta: 0:15:29  Lr: 0.001875  Loss: -0.8616  Acc@1: 81.2500 (80.8711)  Acc@5: 100.0000 (98.9726)  time: 0.3583  data: 0.0031  max mem: 2503
Train: Epoch[3/5]  [1840/3750]  eta: 0:15:23  Lr: 0.001875  Loss: -0.3471  Acc@1: 81.2500 (80.8528)  Acc@5: 100.0000 (98.9713)  time: 0.3559  data: 0.0021  max mem: 2503
Train: Epoch[3/5]  [1850/3750]  eta: 0:15:17  Lr: 0.001875  Loss: -0.5813  Acc@1: 75.0000 (80.8381)  Acc@5: 100.0000 (98.9702)  time: 0.3527  data: 0.0017  max mem: 2503
Train: Epoch[3/5]  [1860/3750]  eta: 0:15:11  Lr: 0.001875  Loss: -0.8300  Acc@1: 75.0000 (80.8168)  Acc@5: 100.0000 (98.9757)  time: 0.3568  data: 0.0041  max mem: 2503
Train: Epoch[3/5]  [1870/3750]  eta: 0:15:05  Lr: 0.001875  Loss: -0.3748  Acc@1: 81.2500 (80.8091)  Acc@5: 100.0000 (98.9778)  time: 0.3614  data: 0.0037  max mem: 2503
Train: Epoch[3/5]  [1880/3750]  eta: 0:14:59  Lr: 0.001875  Loss: -0.0920  Acc@1: 81.2500 (80.8014)  Acc@5: 100.0000 (98.9666)  time: 0.3586  data: 0.0019  max mem: 2503
Train: Epoch[3/5]  [1890/3750]  eta: 0:14:53  Lr: 0.001875  Loss: -0.5556  Acc@1: 81.2500 (80.7939)  Acc@5: 100.0000 (98.9721)  time: 0.3582  data: 0.0035  max mem: 2503
Train: Epoch[3/5]  [1900/3750]  eta: 0:14:47  Lr: 0.001875  Loss: -0.7940  Acc@1: 81.2500 (80.7864)  Acc@5: 100.0000 (98.9709)  time: 0.3582  data: 0.0028  max mem: 2503
Train: Epoch[3/5]  [1910/3750]  eta: 0:14:41  Lr: 0.001875  Loss: -0.3846  Acc@1: 81.2500 (80.7823)  Acc@5: 100.0000 (98.9731)  time: 0.3641  data: 0.0025  max mem: 2503
Train: Epoch[3/5]  [1920/3750]  eta: 0:14:35  Lr: 0.001875  Loss: -0.1300  Acc@1: 81.2500 (80.7847)  Acc@5: 100.0000 (98.9719)  time: 0.3679  data: 0.0036  max mem: 2503
Train: Epoch[3/5]  [1930/3750]  eta: 0:14:29  Lr: 0.001875  Loss: -0.5805  Acc@1: 81.2500 (80.7872)  Acc@5: 100.0000 (98.9675)  time: 0.3602  data: 0.0029  max mem: 2503
Train: Epoch[3/5]  [1940/3750]  eta: 0:14:23  Lr: 0.001875  Loss: -0.2435  Acc@1: 81.2500 (80.7734)  Acc@5: 100.0000 (98.9696)  time: 0.3542  data: 0.0017  max mem: 2503
Train: Epoch[3/5]  [1950/3750]  eta: 0:14:17  Lr: 0.001875  Loss: -0.4897  Acc@1: 81.2500 (80.7599)  Acc@5: 100.0000 (98.9621)  time: 0.3520  data: 0.0027  max mem: 2503
Train: Epoch[3/5]  [1960/3750]  eta: 0:14:11  Lr: 0.001875  Loss: -0.6461  Acc@1: 75.0000 (80.7401)  Acc@5: 100.0000 (98.9674)  time: 0.3555  data: 0.0032  max mem: 2503
Train: Epoch[3/5]  [1970/3750]  eta: 0:14:05  Lr: 0.001875  Loss: -0.9601  Acc@1: 81.2500 (80.7617)  Acc@5: 100.0000 (98.9663)  time: 0.3602  data: 0.0041  max mem: 2503
Train: Epoch[3/5]  [1980/3750]  eta: 0:14:00  Lr: 0.001875  Loss: -0.4051  Acc@1: 81.2500 (80.7831)  Acc@5: 100.0000 (98.9620)  time: 0.3614  data: 0.0052  max mem: 2503
Train: Epoch[3/5]  [1990/3750]  eta: 0:13:54  Lr: 0.001875  Loss: -0.6887  Acc@1: 81.2500 (80.7697)  Acc@5: 100.0000 (98.9641)  time: 0.3582  data: 0.0038  max mem: 2503
Train: Epoch[3/5]  [2000/3750]  eta: 0:13:48  Lr: 0.001875  Loss: -0.3578  Acc@1: 75.0000 (80.7565)  Acc@5: 100.0000 (98.9630)  time: 0.3554  data: 0.0033  max mem: 2503
Train: Epoch[3/5]  [2010/3750]  eta: 0:13:42  Lr: 0.001875  Loss: -0.5901  Acc@1: 81.2500 (80.7807)  Acc@5: 100.0000 (98.9651)  time: 0.3551  data: 0.0039  max mem: 2503
Train: Epoch[3/5]  [2020/3750]  eta: 0:13:37  Lr: 0.001875  Loss: -0.1871  Acc@1: 81.2500 (80.7738)  Acc@5: 100.0000 (98.9640)  time: 0.3527  data: 0.0028  max mem: 2503
Train: Epoch[3/5]  [2030/3750]  eta: 0:13:31  Lr: 0.001875  Loss: -0.7639  Acc@1: 81.2500 (80.7669)  Acc@5: 100.0000 (98.9629)  time: 0.3523  data: 0.0017  max mem: 2503
Train: Epoch[3/5]  [2040/3750]  eta: 0:13:25  Lr: 0.001875  Loss: -0.7652  Acc@1: 81.2500 (80.7662)  Acc@5: 100.0000 (98.9650)  time: 0.3578  data: 0.0039  max mem: 2503
Train: Epoch[3/5]  [2050/3750]  eta: 0:13:20  Lr: 0.001875  Loss: -0.5569  Acc@1: 81.2500 (80.7685)  Acc@5: 100.0000 (98.9578)  time: 0.3661  data: 0.0041  max mem: 2503
Train: Epoch[3/5]  [2060/3750]  eta: 0:13:14  Lr: 0.001875  Loss: -0.6424  Acc@1: 81.2500 (80.7709)  Acc@5: 100.0000 (98.9568)  time: 0.3702  data: 0.0024  max mem: 2503
Train: Epoch[3/5]  [2070/3750]  eta: 0:13:08  Lr: 0.001875  Loss: -0.4008  Acc@1: 81.2500 (80.7641)  Acc@5: 100.0000 (98.9498)  time: 0.3610  data: 0.0028  max mem: 2503
Train: Epoch[3/5]  [2080/3750]  eta: 0:13:03  Lr: 0.001875  Loss: -0.9382  Acc@1: 81.2500 (80.7815)  Acc@5: 100.0000 (98.9518)  time: 0.3540  data: 0.0029  max mem: 2503
Train: Epoch[3/5]  [2090/3750]  eta: 0:12:57  Lr: 0.001875  Loss: -0.5413  Acc@1: 81.2500 (80.7927)  Acc@5: 100.0000 (98.9479)  time: 0.3558  data: 0.0019  max mem: 2503
Train: Epoch[3/5]  [2100/3750]  eta: 0:12:52  Lr: 0.001875  Loss: -0.6603  Acc@1: 81.2500 (80.7740)  Acc@5: 100.0000 (98.9529)  time: 0.3598  data: 0.0034  max mem: 2503
Train: Epoch[3/5]  [2110/3750]  eta: 0:12:46  Lr: 0.001875  Loss: -0.6238  Acc@1: 81.2500 (80.7822)  Acc@5: 100.0000 (98.9549)  time: 0.3602  data: 0.0030  max mem: 2503
Train: Epoch[3/5]  [2120/3750]  eta: 0:12:41  Lr: 0.001875  Loss: -0.5184  Acc@1: 81.2500 (80.7756)  Acc@5: 100.0000 (98.9539)  time: 0.3563  data: 0.0027  max mem: 2503
Train: Epoch[3/5]  [2130/3750]  eta: 0:12:35  Lr: 0.001875  Loss: -0.4750  Acc@1: 81.2500 (80.7954)  Acc@5: 100.0000 (98.9588)  time: 0.3598  data: 0.0037  max mem: 2503
Train: Epoch[3/5]  [2140/3750]  eta: 0:12:30  Lr: 0.001875  Loss: -0.7141  Acc@1: 81.2500 (80.7975)  Acc@5: 100.0000 (98.9549)  time: 0.3631  data: 0.0033  max mem: 2503
Train: Epoch[3/5]  [2150/3750]  eta: 0:12:24  Lr: 0.001875  Loss: -0.7152  Acc@1: 81.2500 (80.7967)  Acc@5: 100.0000 (98.9424)  time: 0.3598  data: 0.0025  max mem: 2503
Train: Epoch[3/5]  [2160/3750]  eta: 0:12:19  Lr: 0.001875  Loss: -0.9255  Acc@1: 81.2500 (80.8075)  Acc@5: 100.0000 (98.9444)  time: 0.3574  data: 0.0013  max mem: 2503
Train: Epoch[3/5]  [2170/3750]  eta: 0:12:13  Lr: 0.001875  Loss: -0.4581  Acc@1: 81.2500 (80.7980)  Acc@5: 100.0000 (98.9348)  time: 0.3580  data: 0.0042  max mem: 2503
Train: Epoch[3/5]  [2180/3750]  eta: 0:12:08  Lr: 0.001875  Loss: -0.5027  Acc@1: 81.2500 (80.7944)  Acc@5: 100.0000 (98.9340)  time: 0.3595  data: 0.0052  max mem: 2503
Train: Epoch[3/5]  [2190/3750]  eta: 0:12:03  Lr: 0.001875  Loss: -0.9170  Acc@1: 81.2500 (80.8050)  Acc@5: 100.0000 (98.9331)  time: 0.3613  data: 0.0046  max mem: 2503
Train: Epoch[3/5]  [2200/3750]  eta: 0:11:57  Lr: 0.001875  Loss: -0.8542  Acc@1: 87.5000 (80.8212)  Acc@5: 100.0000 (98.9295)  time: 0.3589  data: 0.0032  max mem: 2503
Train: Epoch[3/5]  [2210/3750]  eta: 0:11:52  Lr: 0.001875  Loss: -0.6160  Acc@1: 81.2500 (80.7949)  Acc@5: 100.0000 (98.9287)  time: 0.3648  data: 0.0039  max mem: 2503
Train: Epoch[3/5]  [2220/3750]  eta: 0:11:47  Lr: 0.001875  Loss: -0.4817  Acc@1: 81.2500 (80.7969)  Acc@5: 100.0000 (98.9278)  time: 0.3694  data: 0.0065  max mem: 2503
Train: Epoch[3/5]  [2230/3750]  eta: 0:11:41  Lr: 0.001875  Loss: -0.5518  Acc@1: 81.2500 (80.7794)  Acc@5: 100.0000 (98.9242)  time: 0.3607  data: 0.0034  max mem: 2503
Train: Epoch[3/5]  [2240/3750]  eta: 0:11:36  Lr: 0.001875  Loss: -0.6190  Acc@1: 81.2500 (80.7787)  Acc@5: 100.0000 (98.9263)  time: 0.3583  data: 0.0025  max mem: 2503
Train: Epoch[3/5]  [2250/3750]  eta: 0:11:31  Lr: 0.001875  Loss: -0.1813  Acc@1: 81.2500 (80.7697)  Acc@5: 100.0000 (98.9283)  time: 0.3592  data: 0.0041  max mem: 2503
Train: Epoch[3/5]  [2260/3750]  eta: 0:11:25  Lr: 0.001875  Loss: -0.4216  Acc@1: 75.0000 (80.7497)  Acc@5: 100.0000 (98.9302)  time: 0.3573  data: 0.0024  max mem: 2503
Train: Epoch[3/5]  [2270/3750]  eta: 0:11:20  Lr: 0.001875  Loss: -0.7111  Acc@1: 81.2500 (80.7546)  Acc@5: 100.0000 (98.9239)  time: 0.3573  data: 0.0045  max mem: 2503
Train: Epoch[3/5]  [2280/3750]  eta: 0:11:15  Lr: 0.001875  Loss: -0.3253  Acc@1: 81.2500 (80.7321)  Acc@5: 100.0000 (98.9259)  time: 0.3552  data: 0.0045  max mem: 2503
Train: Epoch[3/5]  [2290/3750]  eta: 0:11:10  Lr: 0.001875  Loss: -0.3970  Acc@1: 81.2500 (80.7344)  Acc@5: 100.0000 (98.9279)  time: 0.3535  data: 0.0015  max mem: 2503
Train: Epoch[3/5]  [2300/3750]  eta: 0:11:04  Lr: 0.001875  Loss: -0.8128  Acc@1: 81.2500 (80.7448)  Acc@5: 100.0000 (98.9244)  time: 0.3550  data: 0.0026  max mem: 2503
Train: Epoch[3/5]  [2310/3750]  eta: 0:10:59  Lr: 0.001875  Loss: -0.8094  Acc@1: 81.2500 (80.7416)  Acc@5: 100.0000 (98.9209)  time: 0.3568  data: 0.0043  max mem: 2503
Train: Epoch[3/5]  [2320/3750]  eta: 0:10:54  Lr: 0.001875  Loss: -0.5299  Acc@1: 81.2500 (80.7384)  Acc@5: 100.0000 (98.9175)  time: 0.3589  data: 0.0053  max mem: 2503
Train: Epoch[3/5]  [2330/3750]  eta: 0:10:49  Lr: 0.001875  Loss: -0.4075  Acc@1: 81.2500 (80.7486)  Acc@5: 100.0000 (98.9195)  time: 0.3554  data: 0.0035  max mem: 2503
Train: Epoch[3/5]  [2340/3750]  eta: 0:10:44  Lr: 0.001875  Loss: -0.7368  Acc@1: 81.2500 (80.7481)  Acc@5: 100.0000 (98.9241)  time: 0.3524  data: 0.0019  max mem: 2503
Train: Epoch[3/5]  [2350/3750]  eta: 0:10:38  Lr: 0.001875  Loss: -0.1235  Acc@1: 81.2500 (80.7449)  Acc@5: 100.0000 (98.9207)  time: 0.3572  data: 0.0032  max mem: 2503
Train: Epoch[3/5]  [2360/3750]  eta: 0:10:33  Lr: 0.001875  Loss: -0.4513  Acc@1: 81.2500 (80.7603)  Acc@5: 100.0000 (98.9199)  time: 0.3651  data: 0.0043  max mem: 2503
Train: Epoch[3/5]  [2370/3750]  eta: 0:10:28  Lr: 0.001875  Loss: -0.3991  Acc@1: 81.2500 (80.7439)  Acc@5: 100.0000 (98.9192)  time: 0.3722  data: 0.0057  max mem: 2503
Train: Epoch[3/5]  [2380/3750]  eta: 0:10:23  Lr: 0.001875  Loss: -0.3129  Acc@1: 75.0000 (80.7329)  Acc@5: 100.0000 (98.9185)  time: 0.3733  data: 0.0064  max mem: 2503
Train: Epoch[3/5]  [2390/3750]  eta: 0:10:18  Lr: 0.001875  Loss: -0.6345  Acc@1: 81.2500 (80.7246)  Acc@5: 100.0000 (98.9152)  time: 0.3645  data: 0.0033  max mem: 2503
Train: Epoch[3/5]  [2400/3750]  eta: 0:10:13  Lr: 0.001875  Loss: -0.7468  Acc@1: 81.2500 (80.7320)  Acc@5: 100.0000 (98.9145)  time: 0.3549  data: 0.0020  max mem: 2503
Train: Epoch[3/5]  [2410/3750]  eta: 0:10:08  Lr: 0.001875  Loss: -0.1933  Acc@1: 81.2500 (80.7004)  Acc@5: 100.0000 (98.9061)  time: 0.3521  data: 0.0020  max mem: 2503
Train: Epoch[3/5]  [2420/3750]  eta: 0:10:03  Lr: 0.001875  Loss: -0.7996  Acc@1: 81.2500 (80.7105)  Acc@5: 100.0000 (98.9080)  time: 0.3578  data: 0.0023  max mem: 2503
Train: Epoch[3/5]  [2430/3750]  eta: 0:09:58  Lr: 0.001875  Loss: -0.7713  Acc@1: 81.2500 (80.7075)  Acc@5: 100.0000 (98.9099)  time: 0.3616  data: 0.0046  max mem: 2503
Train: Epoch[3/5]  [2440/3750]  eta: 0:09:53  Lr: 0.001875  Loss: -0.7140  Acc@1: 75.0000 (80.6918)  Acc@5: 100.0000 (98.9118)  time: 0.3591  data: 0.0058  max mem: 2503
Train: Epoch[3/5]  [2450/3750]  eta: 0:09:48  Lr: 0.001875  Loss: -0.5136  Acc@1: 75.0000 (80.6814)  Acc@5: 100.0000 (98.9035)  time: 0.3547  data: 0.0037  max mem: 2503
Train: Epoch[3/5]  [2460/3750]  eta: 0:09:43  Lr: 0.001875  Loss: -0.8353  Acc@1: 81.2500 (80.6964)  Acc@5: 100.0000 (98.9080)  time: 0.3570  data: 0.0046  max mem: 2503
Train: Epoch[3/5]  [2470/3750]  eta: 0:09:38  Lr: 0.001875  Loss: -0.7968  Acc@1: 81.2500 (80.6860)  Acc@5: 100.0000 (98.9073)  time: 0.3584  data: 0.0051  max mem: 2503
Train: Epoch[3/5]  [2480/3750]  eta: 0:09:33  Lr: 0.001875  Loss: -0.3988  Acc@1: 81.2500 (80.6907)  Acc@5: 100.0000 (98.9067)  time: 0.3572  data: 0.0022  max mem: 2503
Train: Epoch[3/5]  [2490/3750]  eta: 0:09:28  Lr: 0.001875  Loss: -0.2710  Acc@1: 81.2500 (80.7080)  Acc@5: 100.0000 (98.9061)  time: 0.3584  data: 0.0019  max mem: 2503
Train: Epoch[3/5]  [2500/3750]  eta: 0:09:23  Lr: 0.001875  Loss: -0.7178  Acc@1: 81.2500 (80.6952)  Acc@5: 100.0000 (98.9079)  time: 0.3537  data: 0.0020  max mem: 2503
Train: Epoch[3/5]  [2510/3750]  eta: 0:09:18  Lr: 0.001875  Loss: -0.7544  Acc@1: 81.2500 (80.7173)  Acc@5: 100.0000 (98.9098)  time: 0.3592  data: 0.0029  max mem: 2503
Train: Epoch[3/5]  [2520/3750]  eta: 0:09:13  Lr: 0.001875  Loss: -0.6323  Acc@1: 87.5000 (80.7244)  Acc@5: 100.0000 (98.9141)  time: 0.3680  data: 0.0036  max mem: 2503
Train: Epoch[3/5]  [2530/3750]  eta: 0:09:08  Lr: 0.001875  Loss: -0.4310  Acc@1: 81.2500 (80.7191)  Acc@5: 100.0000 (98.9110)  time: 0.3637  data: 0.0021  max mem: 2503
Train: Epoch[3/5]  [2540/3750]  eta: 0:09:03  Lr: 0.001875  Loss: -0.8553  Acc@1: 81.2500 (80.7138)  Acc@5: 100.0000 (98.9104)  time: 0.3577  data: 0.0013  max mem: 2503
Train: Epoch[3/5]  [2550/3750]  eta: 0:08:58  Lr: 0.001875  Loss: -0.9430  Acc@1: 87.5000 (80.7257)  Acc@5: 100.0000 (98.9146)  time: 0.3588  data: 0.0033  max mem: 2503
Train: Epoch[3/5]  [2560/3750]  eta: 0:08:53  Lr: 0.001875  Loss: -0.4524  Acc@1: 87.5000 (80.7424)  Acc@5: 100.0000 (98.9140)  time: 0.3579  data: 0.0038  max mem: 2503
Train: Epoch[3/5]  [2570/3750]  eta: 0:08:48  Lr: 0.001875  Loss: -0.7445  Acc@1: 81.2500 (80.7589)  Acc@5: 100.0000 (98.9158)  time: 0.3548  data: 0.0027  max mem: 2503
Train: Epoch[3/5]  [2580/3750]  eta: 0:08:43  Lr: 0.001875  Loss: -0.7613  Acc@1: 81.2500 (80.7681)  Acc@5: 100.0000 (98.9176)  time: 0.3550  data: 0.0035  max mem: 2503
Train: Epoch[3/5]  [2590/3750]  eta: 0:08:39  Lr: 0.001875  Loss: -0.6794  Acc@1: 81.2500 (80.7700)  Acc@5: 100.0000 (98.9169)  time: 0.3656  data: 0.0056  max mem: 2503
Train: Epoch[3/5]  [2600/3750]  eta: 0:08:34  Lr: 0.001875  Loss: -0.1226  Acc@1: 81.2500 (80.7622)  Acc@5: 100.0000 (98.9211)  time: 0.3683  data: 0.0046  max mem: 2503
Train: Epoch[3/5]  [2610/3750]  eta: 0:08:29  Lr: 0.001875  Loss: -0.1738  Acc@1: 87.5000 (80.7856)  Acc@5: 100.0000 (98.9228)  time: 0.3594  data: 0.0029  max mem: 2503
Train: Epoch[3/5]  [2620/3750]  eta: 0:08:24  Lr: 0.001875  Loss: -0.2117  Acc@1: 81.2500 (80.7826)  Acc@5: 100.0000 (98.9174)  time: 0.3571  data: 0.0033  max mem: 2503
Train: Epoch[3/5]  [2630/3750]  eta: 0:08:19  Lr: 0.001875  Loss: -0.8123  Acc@1: 81.2500 (80.7963)  Acc@5: 100.0000 (98.9120)  time: 0.3575  data: 0.0024  max mem: 2503
Train: Epoch[3/5]  [2640/3750]  eta: 0:08:14  Lr: 0.001875  Loss: -0.1731  Acc@1: 75.0000 (80.7814)  Acc@5: 100.0000 (98.9138)  time: 0.3596  data: 0.0028  max mem: 2503
Train: Epoch[3/5]  [2650/3750]  eta: 0:08:10  Lr: 0.001875  Loss: -0.6899  Acc@1: 75.0000 (80.7667)  Acc@5: 100.0000 (98.9108)  time: 0.3626  data: 0.0063  max mem: 2503
Train: Epoch[3/5]  [2660/3750]  eta: 0:08:05  Lr: 0.001875  Loss: -0.6992  Acc@1: 75.0000 (80.7662)  Acc@5: 100.0000 (98.9125)  time: 0.3655  data: 0.0057  max mem: 2503
Train: Epoch[3/5]  [2670/3750]  eta: 0:08:00  Lr: 0.001875  Loss: -0.7624  Acc@1: 75.0000 (80.7446)  Acc@5: 100.0000 (98.9143)  time: 0.3630  data: 0.0036  max mem: 2503
Train: Epoch[3/5]  [2680/3750]  eta: 0:07:55  Lr: 0.001875  Loss: -0.8456  Acc@1: 75.0000 (80.7488)  Acc@5: 100.0000 (98.9137)  time: 0.3636  data: 0.0040  max mem: 2503
Train: Epoch[3/5]  [2690/3750]  eta: 0:07:50  Lr: 0.001875  Loss: -0.5179  Acc@1: 81.2500 (80.7460)  Acc@5: 100.0000 (98.9084)  time: 0.3628  data: 0.0039  max mem: 2503
Train: Epoch[3/5]  [2700/3750]  eta: 0:07:46  Lr: 0.001875  Loss: -0.3724  Acc@1: 81.2500 (80.7386)  Acc@5: 100.0000 (98.9101)  time: 0.3579  data: 0.0043  max mem: 2503
Train: Epoch[3/5]  [2710/3750]  eta: 0:07:41  Lr: 0.001875  Loss: -0.7400  Acc@1: 81.2500 (80.7313)  Acc@5: 100.0000 (98.9049)  time: 0.3605  data: 0.0035  max mem: 2503
Train: Epoch[3/5]  [2720/3750]  eta: 0:07:36  Lr: 0.001875  Loss: -0.5905  Acc@1: 75.0000 (80.7102)  Acc@5: 100.0000 (98.9067)  time: 0.3605  data: 0.0032  max mem: 2503
Train: Epoch[3/5]  [2730/3750]  eta: 0:07:31  Lr: 0.001875  Loss: -0.6448  Acc@1: 75.0000 (80.7213)  Acc@5: 100.0000 (98.9107)  time: 0.3578  data: 0.0041  max mem: 2503
Train: Epoch[3/5]  [2740/3750]  eta: 0:07:27  Lr: 0.001875  Loss: -0.6039  Acc@1: 81.2500 (80.7301)  Acc@5: 100.0000 (98.9146)  time: 0.3566  data: 0.0045  max mem: 2503
Train: Epoch[3/5]  [2750/3750]  eta: 0:07:22  Lr: 0.001875  Loss: -0.1167  Acc@1: 81.2500 (80.7229)  Acc@5: 100.0000 (98.9163)  time: 0.3552  data: 0.0039  max mem: 2503
Train: Epoch[3/5]  [2760/3750]  eta: 0:07:17  Lr: 0.001875  Loss: -0.6244  Acc@1: 75.0000 (80.7339)  Acc@5: 100.0000 (98.9202)  time: 0.3533  data: 0.0032  max mem: 2503
Train: Epoch[3/5]  [2770/3750]  eta: 0:07:12  Lr: 0.001875  Loss: -0.4007  Acc@1: 81.2500 (80.7470)  Acc@5: 100.0000 (98.9241)  time: 0.3533  data: 0.0031  max mem: 2503
Train: Epoch[3/5]  [2780/3750]  eta: 0:07:08  Lr: 0.001875  Loss: -0.5707  Acc@1: 81.2500 (80.7511)  Acc@5: 100.0000 (98.9145)  time: 0.3560  data: 0.0026  max mem: 2503
Train: Epoch[3/5]  [2790/3750]  eta: 0:07:03  Lr: 0.001875  Loss: -0.6134  Acc@1: 81.2500 (80.7708)  Acc@5: 100.0000 (98.9117)  time: 0.3577  data: 0.0026  max mem: 2503
Train: Epoch[3/5]  [2800/3750]  eta: 0:06:58  Lr: 0.001875  Loss: -0.6160  Acc@1: 81.2500 (80.7725)  Acc@5: 100.0000 (98.9111)  time: 0.3571  data: 0.0044  max mem: 2503
Train: Epoch[3/5]  [2810/3750]  eta: 0:06:54  Lr: 0.001875  Loss: -0.4315  Acc@1: 81.2500 (80.7675)  Acc@5: 100.0000 (98.9128)  time: 0.3539  data: 0.0040  max mem: 2503
Train: Epoch[3/5]  [2820/3750]  eta: 0:06:49  Lr: 0.001875  Loss: -0.6106  Acc@1: 81.2500 (80.7759)  Acc@5: 100.0000 (98.9144)  time: 0.3506  data: 0.0019  max mem: 2503
Train: Epoch[3/5]  [2830/3750]  eta: 0:06:44  Lr: 0.001875  Loss: -0.3537  Acc@1: 81.2500 (80.7886)  Acc@5: 100.0000 (98.9072)  time: 0.3597  data: 0.0028  max mem: 2503
Train: Epoch[3/5]  [2840/3750]  eta: 0:06:40  Lr: 0.001875  Loss: -0.8596  Acc@1: 81.2500 (80.7924)  Acc@5: 100.0000 (98.9066)  time: 0.3733  data: 0.0099  max mem: 2503
Train: Epoch[3/5]  [2850/3750]  eta: 0:06:35  Lr: 0.001875  Loss: -0.5457  Acc@1: 81.2500 (80.7787)  Acc@5: 100.0000 (98.9083)  time: 0.3723  data: 0.0099  max mem: 2503
Train: Epoch[3/5]  [2860/3750]  eta: 0:06:30  Lr: 0.001875  Loss: -0.5238  Acc@1: 81.2500 (80.7912)  Acc@5: 100.0000 (98.9099)  time: 0.3607  data: 0.0031  max mem: 2503
Train: Epoch[3/5]  [2870/3750]  eta: 0:06:26  Lr: 0.001875  Loss: -0.2946  Acc@1: 81.2500 (80.7928)  Acc@5: 100.0000 (98.9072)  time: 0.3591  data: 0.0017  max mem: 2503
Train: Epoch[3/5]  [2880/3750]  eta: 0:06:21  Lr: 0.001875  Loss: -0.5048  Acc@1: 81.2500 (80.8096)  Acc@5: 100.0000 (98.9088)  time: 0.3638  data: 0.0035  max mem: 2503
Train: Epoch[3/5]  [2890/3750]  eta: 0:06:17  Lr: 0.001875  Loss: -0.8507  Acc@1: 81.2500 (80.8133)  Acc@5: 100.0000 (98.9061)  time: 0.3613  data: 0.0070  max mem: 2503
Train: Epoch[3/5]  [2900/3750]  eta: 0:06:13  Lr: 0.001875  Loss: -0.6153  Acc@1: 81.2500 (80.8234)  Acc@5: 100.0000 (98.9034)  time: 0.4985  data: 0.0046  max mem: 2503
Train: Epoch[3/5]  [2910/3750]  eta: 0:06:09  Lr: 0.001875  Loss: -0.7433  Acc@1: 81.2500 (80.8163)  Acc@5: 100.0000 (98.9050)  time: 0.6560  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [2920/3750]  eta: 0:06:05  Lr: 0.001875  Loss: -0.8452  Acc@1: 81.2500 (80.8242)  Acc@5: 100.0000 (98.9045)  time: 0.6833  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [2930/3750]  eta: 0:06:02  Lr: 0.001875  Loss: -0.7806  Acc@1: 81.2500 (80.8193)  Acc@5: 100.0000 (98.9018)  time: 0.6787  data: 0.0009  max mem: 2503
Train: Epoch[3/5]  [2940/3750]  eta: 0:05:58  Lr: 0.001875  Loss: -0.2799  Acc@1: 81.2500 (80.8016)  Acc@5: 100.0000 (98.9034)  time: 0.6403  data: 0.0013  max mem: 2503
Train: Epoch[3/5]  [2950/3750]  eta: 0:05:54  Lr: 0.001875  Loss: -0.5517  Acc@1: 81.2500 (80.8052)  Acc@5: 100.0000 (98.9029)  time: 0.6467  data: 0.0008  max mem: 2503
Train: Epoch[3/5]  [2960/3750]  eta: 0:05:50  Lr: 0.001875  Loss: -0.5857  Acc@1: 81.2500 (80.7772)  Acc@5: 100.0000 (98.9066)  time: 0.6702  data: 0.0006  max mem: 2503
Train: Epoch[3/5]  [2970/3750]  eta: 0:05:46  Lr: 0.001875  Loss: -0.0955  Acc@1: 75.0000 (80.7619)  Acc@5: 100.0000 (98.9061)  time: 0.6762  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [2980/3750]  eta: 0:05:42  Lr: 0.001875  Loss: -0.8665  Acc@1: 87.5000 (80.7908)  Acc@5: 100.0000 (98.9098)  time: 0.6803  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [2990/3750]  eta: 0:05:38  Lr: 0.001875  Loss: -0.3630  Acc@1: 81.2500 (80.7819)  Acc@5: 100.0000 (98.9050)  time: 0.6776  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [3000/3750]  eta: 0:05:35  Lr: 0.001875  Loss: -0.7548  Acc@1: 81.2500 (80.7960)  Acc@5: 100.0000 (98.9045)  time: 0.6681  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [3010/3750]  eta: 0:05:31  Lr: 0.001875  Loss: -0.6281  Acc@1: 81.2500 (80.7871)  Acc@5: 100.0000 (98.9040)  time: 0.6647  data: 0.0008  max mem: 2503
Train: Epoch[3/5]  [3020/3750]  eta: 0:05:27  Lr: 0.001875  Loss: -0.2786  Acc@1: 81.2500 (80.7804)  Acc@5: 100.0000 (98.9056)  time: 0.6725  data: 0.0008  max mem: 2503
Train: Epoch[3/5]  [3030/3750]  eta: 0:05:23  Lr: 0.001875  Loss: -0.4218  Acc@1: 81.2500 (80.7819)  Acc@5: 100.0000 (98.9051)  time: 0.6788  data: 0.0007  max mem: 2503
Train: Epoch[3/5]  [3040/3750]  eta: 0:05:19  Lr: 0.001875  Loss: -0.7364  Acc@1: 81.2500 (80.7835)  Acc@5: 100.0000 (98.9025)  time: 0.6921  data: 0.0006  max mem: 2503
Train: Epoch[3/5]  [3050/3750]  eta: 0:05:15  Lr: 0.001875  Loss: -0.4850  Acc@1: 81.2500 (80.7829)  Acc@5: 100.0000 (98.9020)  time: 0.6634  data: 0.0007  max mem: 2503
Train: Epoch[3/5]  [3060/3750]  eta: 0:05:11  Lr: 0.001875  Loss: -0.9342  Acc@1: 81.2500 (80.7906)  Acc@5: 100.0000 (98.9015)  time: 0.6672  data: 0.0009  max mem: 2503
Train: Epoch[3/5]  [3070/3750]  eta: 0:05:07  Lr: 0.001875  Loss: -0.5426  Acc@1: 87.5000 (80.7982)  Acc@5: 100.0000 (98.9010)  time: 0.6788  data: 0.0010  max mem: 2503
Train: Epoch[3/5]  [3080/3750]  eta: 0:05:03  Lr: 0.001875  Loss: -0.7023  Acc@1: 81.2500 (80.8017)  Acc@5: 100.0000 (98.9005)  time: 0.6749  data: 0.0010  max mem: 2503
Train: Epoch[3/5]  [3090/3750]  eta: 0:04:59  Lr: 0.001875  Loss: -0.5123  Acc@1: 81.2500 (80.8132)  Acc@5: 100.0000 (98.9021)  time: 0.6886  data: 0.0008  max mem: 2503
Train: Epoch[3/5]  [3100/3750]  eta: 0:04:55  Lr: 0.001875  Loss: -0.6612  Acc@1: 81.2500 (80.8106)  Acc@5: 100.0000 (98.9036)  time: 0.6753  data: 0.0006  max mem: 2503
Train: Epoch[3/5]  [3110/3750]  eta: 0:04:51  Lr: 0.001875  Loss: -0.6652  Acc@1: 81.2500 (80.8140)  Acc@5: 100.0000 (98.9071)  time: 0.6743  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [3120/3750]  eta: 0:04:47  Lr: 0.001875  Loss: -0.5536  Acc@1: 81.2500 (80.8295)  Acc@5: 100.0000 (98.9106)  time: 0.6799  data: 0.0013  max mem: 2503
Train: Epoch[3/5]  [3130/3750]  eta: 0:04:42  Lr: 0.001875  Loss: -0.3502  Acc@1: 81.2500 (80.8308)  Acc@5: 100.0000 (98.9081)  time: 0.6828  data: 0.0013  max mem: 2503
Train: Epoch[3/5]  [3140/3750]  eta: 0:04:38  Lr: 0.001875  Loss: -0.2550  Acc@1: 81.2500 (80.8262)  Acc@5: 100.0000 (98.9016)  time: 0.6877  data: 0.0006  max mem: 2503
Train: Epoch[3/5]  [3150/3750]  eta: 0:04:34  Lr: 0.001875  Loss: -0.9165  Acc@1: 81.2500 (80.8335)  Acc@5: 100.0000 (98.9051)  time: 0.6844  data: 0.0013  max mem: 2503
Train: Epoch[3/5]  [3160/3750]  eta: 0:04:30  Lr: 0.001875  Loss: -0.6864  Acc@1: 81.2500 (80.8387)  Acc@5: 100.0000 (98.9046)  time: 0.6775  data: 0.0013  max mem: 2503
Train: Epoch[3/5]  [3170/3750]  eta: 0:04:26  Lr: 0.001875  Loss: -0.1737  Acc@1: 81.2500 (80.8420)  Acc@5: 100.0000 (98.9081)  time: 0.6769  data: 0.0011  max mem: 2503
Train: Epoch[3/5]  [3180/3750]  eta: 0:04:22  Lr: 0.001875  Loss: -0.8803  Acc@1: 81.2500 (80.8492)  Acc@5: 100.0000 (98.9076)  time: 0.6820  data: 0.0010  max mem: 2503
Train: Epoch[3/5]  [3190/3750]  eta: 0:04:17  Lr: 0.001875  Loss: -0.3673  Acc@1: 81.2500 (80.8387)  Acc@5: 100.0000 (98.9051)  time: 0.6813  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [3200/3750]  eta: 0:04:13  Lr: 0.001875  Loss: -0.3466  Acc@1: 75.0000 (80.8244)  Acc@5: 100.0000 (98.9027)  time: 0.6758  data: 0.0006  max mem: 2503
Train: Epoch[3/5]  [3210/3750]  eta: 0:04:09  Lr: 0.001875  Loss: -0.8876  Acc@1: 75.0000 (80.8276)  Acc@5: 100.0000 (98.9042)  time: 0.6697  data: 0.0014  max mem: 2503
Train: Epoch[3/5]  [3220/3750]  eta: 0:04:05  Lr: 0.001875  Loss: -0.6979  Acc@1: 81.2500 (80.8348)  Acc@5: 100.0000 (98.9037)  time: 0.6750  data: 0.0015  max mem: 2503
Train: Epoch[3/5]  [3230/3750]  eta: 0:04:00  Lr: 0.001875  Loss: -0.3923  Acc@1: 81.2500 (80.8399)  Acc@5: 100.0000 (98.9032)  time: 0.6785  data: 0.0009  max mem: 2503
Train: Epoch[3/5]  [3240/3750]  eta: 0:03:56  Lr: 0.001875  Loss: -0.5731  Acc@1: 81.2500 (80.8489)  Acc@5: 100.0000 (98.9047)  time: 0.6776  data: 0.0007  max mem: 2503
Train: Epoch[3/5]  [3250/3750]  eta: 0:03:52  Lr: 0.001875  Loss: -0.6220  Acc@1: 87.5000 (80.8636)  Acc@5: 100.0000 (98.9061)  time: 0.6225  data: 0.0006  max mem: 2503
Train: Epoch[3/5]  [3260/3750]  eta: 0:03:47  Lr: 0.001875  Loss: -0.6225  Acc@1: 81.2500 (80.8628)  Acc@5: 100.0000 (98.9075)  time: 0.5596  data: 0.0006  max mem: 2503
Train: Epoch[3/5]  [3270/3750]  eta: 0:03:43  Lr: 0.001875  Loss: -0.4462  Acc@1: 81.2500 (80.8755)  Acc@5: 100.0000 (98.9090)  time: 0.6280  data: 0.0007  max mem: 2503
Train: Epoch[3/5]  [3280/3750]  eta: 0:03:38  Lr: 0.001875  Loss: -0.7761  Acc@1: 81.2500 (80.8747)  Acc@5: 100.0000 (98.9123)  time: 0.5491  data: 0.0006  max mem: 2503
Train: Epoch[3/5]  [3290/3750]  eta: 0:03:33  Lr: 0.001875  Loss: 0.1621  Acc@1: 81.2500 (80.8588)  Acc@5: 100.0000 (98.9099)  time: 0.3750  data: 0.0010  max mem: 2503
Train: Epoch[3/5]  [3300/3750]  eta: 0:03:28  Lr: 0.001875  Loss: -0.5810  Acc@1: 81.2500 (80.8600)  Acc@5: 100.0000 (98.9075)  time: 0.3553  data: 0.0010  max mem: 2503
Train: Epoch[3/5]  [3310/3750]  eta: 0:03:24  Lr: 0.001875  Loss: -0.4426  Acc@1: 81.2500 (80.8706)  Acc@5: 100.0000 (98.9089)  time: 0.3535  data: 0.0016  max mem: 2503
Train: Epoch[3/5]  [3320/3750]  eta: 0:03:19  Lr: 0.001875  Loss: -0.4862  Acc@1: 81.2500 (80.8698)  Acc@5: 100.0000 (98.9085)  time: 0.3488  data: 0.0017  max mem: 2503
Train: Epoch[3/5]  [3330/3750]  eta: 0:03:14  Lr: 0.001875  Loss: -0.7745  Acc@1: 81.2500 (80.8672)  Acc@5: 100.0000 (98.9099)  time: 0.3508  data: 0.0014  max mem: 2503
Train: Epoch[3/5]  [3340/3750]  eta: 0:03:09  Lr: 0.001875  Loss: -0.3163  Acc@1: 81.2500 (80.8796)  Acc@5: 100.0000 (98.9113)  time: 0.3549  data: 0.0031  max mem: 2503
Train: Epoch[3/5]  [3350/3750]  eta: 0:03:05  Lr: 0.001875  Loss: -0.3526  Acc@1: 87.5000 (80.8919)  Acc@5: 100.0000 (98.9126)  time: 0.3575  data: 0.0042  max mem: 2503
Train: Epoch[3/5]  [3360/3750]  eta: 0:03:00  Lr: 0.001875  Loss: -0.5705  Acc@1: 81.2500 (80.8855)  Acc@5: 100.0000 (98.9159)  time: 0.4992  data: 0.0025  max mem: 2503
Train: Epoch[3/5]  [3370/3750]  eta: 0:02:56  Lr: 0.001875  Loss: -0.2645  Acc@1: 75.0000 (80.8681)  Acc@5: 100.0000 (98.9154)  time: 0.6640  data: 0.0014  max mem: 2503
Train: Epoch[3/5]  [3380/3750]  eta: 0:02:51  Lr: 0.001875  Loss: -0.3711  Acc@1: 81.2500 (80.8766)  Acc@5: 100.0000 (98.9167)  time: 0.6813  data: 0.0014  max mem: 2503
Train: Epoch[3/5]  [3390/3750]  eta: 0:02:47  Lr: 0.001875  Loss: -0.5197  Acc@1: 81.2500 (80.8814)  Acc@5: 100.0000 (98.9144)  time: 0.6570  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [3400/3750]  eta: 0:02:42  Lr: 0.001875  Loss: -0.5750  Acc@1: 81.2500 (80.8825)  Acc@5: 100.0000 (98.9158)  time: 0.6439  data: 0.0007  max mem: 2503
Train: Epoch[3/5]  [3410/3750]  eta: 0:02:38  Lr: 0.001875  Loss: -0.8265  Acc@1: 81.2500 (80.8872)  Acc@5: 100.0000 (98.9189)  time: 0.6573  data: 0.0009  max mem: 2503
Train: Epoch[3/5]  [3420/3750]  eta: 0:02:34  Lr: 0.001875  Loss: -0.4078  Acc@1: 81.2500 (80.8828)  Acc@5: 100.0000 (98.9221)  time: 0.6645  data: 0.0006  max mem: 2503
Train: Epoch[3/5]  [3430/3750]  eta: 0:02:29  Lr: 0.001875  Loss: -0.6954  Acc@1: 81.2500 (80.8820)  Acc@5: 100.0000 (98.9216)  time: 0.6716  data: 0.0009  max mem: 2503
Train: Epoch[3/5]  [3440/3750]  eta: 0:02:25  Lr: 0.001875  Loss: -0.6482  Acc@1: 75.0000 (80.8649)  Acc@5: 100.0000 (98.9193)  time: 0.6847  data: 0.0009  max mem: 2503
Train: Epoch[3/5]  [3450/3750]  eta: 0:02:20  Lr: 0.001875  Loss: -0.6782  Acc@1: 81.2500 (80.8842)  Acc@5: 100.0000 (98.9224)  time: 0.6826  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [3460/3750]  eta: 0:02:16  Lr: 0.001875  Loss: -0.5037  Acc@1: 87.5000 (80.8816)  Acc@5: 100.0000 (98.9237)  time: 0.6767  data: 0.0007  max mem: 2503
Train: Epoch[3/5]  [3470/3750]  eta: 0:02:11  Lr: 0.001875  Loss: -0.5452  Acc@1: 81.2500 (80.8899)  Acc@5: 100.0000 (98.9268)  time: 0.6783  data: 0.0019  max mem: 2503
Train: Epoch[3/5]  [3480/3750]  eta: 0:02:06  Lr: 0.001875  Loss: -0.2270  Acc@1: 87.5000 (80.8981)  Acc@5: 100.0000 (98.9245)  time: 0.6750  data: 0.0018  max mem: 2503
Train: Epoch[3/5]  [3490/3750]  eta: 0:02:02  Lr: 0.001875  Loss: -0.2693  Acc@1: 81.2500 (80.9009)  Acc@5: 100.0000 (98.9240)  time: 0.6712  data: 0.0013  max mem: 2503
Train: Epoch[3/5]  [3500/3750]  eta: 0:01:57  Lr: 0.001875  Loss: -0.9459  Acc@1: 81.2500 (80.9108)  Acc@5: 100.0000 (98.9271)  time: 0.6776  data: 0.0012  max mem: 2503
Train: Epoch[3/5]  [3510/3750]  eta: 0:01:53  Lr: 0.001875  Loss: -0.8027  Acc@1: 81.2500 (80.9082)  Acc@5: 100.0000 (98.9301)  time: 0.6710  data: 0.0006  max mem: 2503
Train: Epoch[3/5]  [3520/3750]  eta: 0:01:48  Lr: 0.001875  Loss: -0.7687  Acc@1: 81.2500 (80.9092)  Acc@5: 100.0000 (98.9225)  time: 0.6712  data: 0.0006  max mem: 2503
Train: Epoch[3/5]  [3530/3750]  eta: 0:01:44  Lr: 0.001875  Loss: -0.6857  Acc@1: 81.2500 (80.9013)  Acc@5: 100.0000 (98.9203)  time: 0.6815  data: 0.0013  max mem: 2503
Train: Epoch[3/5]  [3540/3750]  eta: 0:01:39  Lr: 0.001875  Loss: -0.5047  Acc@1: 75.0000 (80.9023)  Acc@5: 100.0000 (98.9198)  time: 0.6828  data: 0.0017  max mem: 2503
Train: Epoch[3/5]  [3550/3750]  eta: 0:01:34  Lr: 0.001875  Loss: -0.9389  Acc@1: 87.5000 (80.9156)  Acc@5: 100.0000 (98.9193)  time: 0.6771  data: 0.0011  max mem: 2503
Train: Epoch[3/5]  [3560/3750]  eta: 0:01:30  Lr: 0.001875  Loss: -1.0462  Acc@1: 87.5000 (80.9253)  Acc@5: 100.0000 (98.9188)  time: 0.6402  data: 0.0019  max mem: 2503
Train: Epoch[3/5]  [3570/3750]  eta: 0:01:25  Lr: 0.001875  Loss: -0.6094  Acc@1: 87.5000 (80.9332)  Acc@5: 100.0000 (98.9184)  time: 0.6461  data: 0.0019  max mem: 2503
Train: Epoch[3/5]  [3580/3750]  eta: 0:01:20  Lr: 0.001875  Loss: -0.9546  Acc@1: 87.5000 (80.9533)  Acc@5: 100.0000 (98.9196)  time: 0.6779  data: 0.0009  max mem: 2503
Train: Epoch[3/5]  [3590/3750]  eta: 0:01:16  Lr: 0.001875  Loss: -0.7562  Acc@1: 87.5000 (80.9611)  Acc@5: 100.0000 (98.9209)  time: 0.6778  data: 0.0016  max mem: 2503
Train: Epoch[3/5]  [3600/3750]  eta: 0:01:11  Lr: 0.001875  Loss: -0.4234  Acc@1: 87.5000 (80.9601)  Acc@5: 100.0000 (98.9187)  time: 0.6831  data: 0.0013  max mem: 2503
Train: Epoch[3/5]  [3610/3750]  eta: 0:01:06  Lr: 0.001875  Loss: -0.0971  Acc@1: 81.2500 (80.9575)  Acc@5: 100.0000 (98.9182)  time: 0.6768  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [3620/3750]  eta: 0:01:02  Lr: 0.001875  Loss: -0.7157  Acc@1: 81.2500 (80.9687)  Acc@5: 100.0000 (98.9195)  time: 0.6707  data: 0.0008  max mem: 2503
Train: Epoch[3/5]  [3630/3750]  eta: 0:00:57  Lr: 0.001875  Loss: -0.3436  Acc@1: 87.5000 (80.9763)  Acc@5: 100.0000 (98.9208)  time: 0.6843  data: 0.0008  max mem: 2503
Train: Epoch[3/5]  [3640/3750]  eta: 0:00:52  Lr: 0.001875  Loss: -0.3522  Acc@1: 81.2500 (80.9754)  Acc@5: 100.0000 (98.9203)  time: 0.6905  data: 0.0007  max mem: 2503
Train: Epoch[3/5]  [3650/3750]  eta: 0:00:47  Lr: 0.001875  Loss: -0.6892  Acc@1: 81.2500 (80.9727)  Acc@5: 100.0000 (98.9198)  time: 0.6867  data: 0.0007  max mem: 2503
Train: Epoch[3/5]  [3660/3750]  eta: 0:00:43  Lr: 0.001875  Loss: -0.5506  Acc@1: 81.2500 (80.9786)  Acc@5: 100.0000 (98.9211)  time: 0.6591  data: 0.0010  max mem: 2503
Train: Epoch[3/5]  [3670/3750]  eta: 0:00:38  Lr: 0.001875  Loss: -0.3991  Acc@1: 81.2500 (80.9759)  Acc@5: 100.0000 (98.9206)  time: 0.6578  data: 0.0011  max mem: 2503
Train: Epoch[3/5]  [3680/3750]  eta: 0:00:33  Lr: 0.001875  Loss: -0.7159  Acc@1: 81.2500 (80.9817)  Acc@5: 100.0000 (98.9235)  time: 0.6771  data: 0.0020  max mem: 2503
Train: Epoch[3/5]  [3690/3750]  eta: 0:00:28  Lr: 0.001875  Loss: -0.6626  Acc@1: 81.2500 (80.9723)  Acc@5: 100.0000 (98.9214)  time: 0.6735  data: 0.0019  max mem: 2503
Train: Epoch[3/5]  [3700/3750]  eta: 0:00:24  Lr: 0.001875  Loss: -0.5074  Acc@1: 75.0000 (80.9697)  Acc@5: 100.0000 (98.9226)  time: 0.6768  data: 0.0006  max mem: 2503
Train: Epoch[3/5]  [3710/3750]  eta: 0:00:19  Lr: 0.001875  Loss: -0.3852  Acc@1: 81.2500 (80.9586)  Acc@5: 100.0000 (98.9238)  time: 0.6377  data: 0.0006  max mem: 2503
Train: Epoch[3/5]  [3720/3750]  eta: 0:00:14  Lr: 0.001875  Loss: -0.8650  Acc@1: 81.2500 (80.9577)  Acc@5: 100.0000 (98.9267)  time: 0.4725  data: 0.0006  max mem: 2503
Train: Epoch[3/5]  [3730/3750]  eta: 0:00:09  Lr: 0.001875  Loss: -0.8690  Acc@1: 81.2500 (80.9619)  Acc@5: 100.0000 (98.9296)  time: 0.3527  data: 0.0020  max mem: 2503
Train: Epoch[3/5]  [3740/3750]  eta: 0:00:04  Lr: 0.001875  Loss: 0.2572  Acc@1: 81.2500 (80.9543)  Acc@5: 100.0000 (98.9274)  time: 0.3601  data: 0.0030  max mem: 2503
Train: Epoch[3/5]  [3749/3750]  eta: 0:00:00  Lr: 0.001875  Loss: -0.4424  Acc@1: 75.0000 (80.9467)  Acc@5: 100.0000 (98.9250)  time: 0.3593  data: 0.0030  max mem: 2503
Train: Epoch[3/5] Total time: 0:30:06 (0.4817 s / it)
{0: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 1: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 2: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 3: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 4: {0: 0, 1: 300000, 2: 0, 3: 352, 4: 0}, 5: {0: 0, 1: 300000, 2: 0, 3: 352, 4: 0}, 6: {0: 0, 1: 300000, 2: 0, 3: 352, 4: 0}, 7: {0: 0, 1: 300000, 2: 0, 3: 352, 4: 0}, 8: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 9: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 10: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 11: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 12: {0: 0, 1: 0, 2: 0, 3: 90968, 4: 0}, 13: {0: 0, 1: 0, 2: 0, 3: 90968, 4: 0}, 14: {0: 0, 1: 0, 2: 0, 3: 90968, 4: 0}, 15: {0: 0, 1: 0, 2: 0, 3: 90968, 4: 0}, 16: {0: 0, 1: 0, 2: 0, 3: 0, 4: 180000}, 17: {0: 0, 1: 0, 2: 0, 3: 0, 4: 180000}, 18: {0: 0, 1: 0, 2: 0, 3: 0, 4: 180000}, 19: {0: 0, 1: 0, 2: 0, 3: 0, 4: 180000}}
Averaged stats: Lr: 0.001875  Loss: -0.4424  Acc@1: 75.0000 (80.9467)  Acc@5: 100.0000 (98.9250)
Train: Epoch[4/5]  [   0/3750]  eta: 1:25:39  Lr: 0.001875  Loss: -0.4336  Acc@1: 81.2500 (81.2500)  Acc@5: 93.7500 (93.7500)  time: 1.3706  data: 1.0095  max mem: 2503
Train: Epoch[4/5]  [  10/3750]  eta: 0:28:13  Lr: 0.001875  Loss: -0.5850  Acc@1: 81.2500 (78.9773)  Acc@5: 100.0000 (97.7273)  time: 0.4527  data: 0.0941  max mem: 2503
Train: Epoch[4/5]  [  20/3750]  eta: 0:25:15  Lr: 0.001875  Loss: -0.7965  Acc@1: 81.2500 (81.5476)  Acc@5: 100.0000 (98.5119)  time: 0.3580  data: 0.0027  max mem: 2503
Train: Epoch[4/5]  [  30/3750]  eta: 0:24:11  Lr: 0.001875  Loss: -0.3312  Acc@1: 81.2500 (80.4435)  Acc@5: 100.0000 (98.3871)  time: 0.3557  data: 0.0018  max mem: 2503
Train: Epoch[4/5]  [  40/3750]  eta: 0:23:37  Lr: 0.001875  Loss: -0.8180  Acc@1: 81.2500 (81.4024)  Acc@5: 100.0000 (98.6280)  time: 0.3568  data: 0.0018  max mem: 2503
Train: Epoch[4/5]  [  50/3750]  eta: 0:23:13  Lr: 0.001875  Loss: -0.3662  Acc@1: 81.2500 (80.2696)  Acc@5: 100.0000 (98.7745)  time: 0.3558  data: 0.0022  max mem: 2503
Train: Epoch[4/5]  [  60/3750]  eta: 0:22:58  Lr: 0.001875  Loss: -0.4629  Acc@1: 68.7500 (78.6885)  Acc@5: 100.0000 (98.6680)  time: 0.3559  data: 0.0020  max mem: 2503
Train: Epoch[4/5]  [  70/3750]  eta: 0:22:46  Lr: 0.001875  Loss: -0.6480  Acc@1: 81.2500 (79.2254)  Acc@5: 100.0000 (98.7676)  time: 0.3577  data: 0.0018  max mem: 2503
Train: Epoch[4/5]  [  80/3750]  eta: 0:22:42  Lr: 0.001875  Loss: -0.4001  Acc@1: 81.2500 (79.1667)  Acc@5: 100.0000 (98.8426)  time: 0.3638  data: 0.0031  max mem: 2503
Train: Epoch[4/5]  [  90/3750]  eta: 0:22:35  Lr: 0.001875  Loss: -0.9028  Acc@1: 81.2500 (79.2582)  Acc@5: 100.0000 (98.8324)  time: 0.3668  data: 0.0041  max mem: 2503
Train: Epoch[4/5]  [ 100/3750]  eta: 0:22:29  Lr: 0.001875  Loss: -0.8105  Acc@1: 81.2500 (79.5173)  Acc@5: 100.0000 (98.8861)  time: 0.3633  data: 0.0038  max mem: 2503
Train: Epoch[4/5]  [ 110/3750]  eta: 0:22:24  Lr: 0.001875  Loss: -0.5573  Acc@1: 81.2500 (79.7860)  Acc@5: 100.0000 (98.8739)  time: 0.3647  data: 0.0050  max mem: 2503
Train: Epoch[4/5]  [ 120/3750]  eta: 0:22:20  Lr: 0.001875  Loss: -0.0969  Acc@1: 75.0000 (79.1322)  Acc@5: 100.0000 (98.8636)  time: 0.3672  data: 0.0035  max mem: 2503
Train: Epoch[4/5]  [ 130/3750]  eta: 0:22:15  Lr: 0.001875  Loss: -0.6126  Acc@1: 81.2500 (79.6756)  Acc@5: 100.0000 (98.9027)  time: 0.3673  data: 0.0041  max mem: 2503
Train: Epoch[4/5]  [ 140/3750]  eta: 0:22:10  Lr: 0.001875  Loss: -0.4365  Acc@1: 81.2500 (79.6099)  Acc@5: 100.0000 (98.9805)  time: 0.3657  data: 0.0056  max mem: 2503
Train: Epoch[4/5]  [ 150/3750]  eta: 0:22:03  Lr: 0.001875  Loss: -0.5644  Acc@1: 75.0000 (79.7599)  Acc@5: 100.0000 (98.8825)  time: 0.3590  data: 0.0040  max mem: 2503
Train: Epoch[4/5]  [ 160/3750]  eta: 0:21:58  Lr: 0.001875  Loss: -0.4414  Acc@1: 81.2500 (79.8913)  Acc@5: 100.0000 (98.8354)  time: 0.3563  data: 0.0034  max mem: 2503
Train: Epoch[4/5]  [ 170/3750]  eta: 0:21:52  Lr: 0.001875  Loss: -0.4274  Acc@1: 81.2500 (80.2266)  Acc@5: 100.0000 (98.8304)  time: 0.3579  data: 0.0029  max mem: 2503
Train: Epoch[4/5]  [ 180/3750]  eta: 0:21:46  Lr: 0.001875  Loss: -0.5185  Acc@1: 81.2500 (80.1450)  Acc@5: 100.0000 (98.7914)  time: 0.3565  data: 0.0018  max mem: 2503
Train: Epoch[4/5]  [ 190/3750]  eta: 0:21:42  Lr: 0.001875  Loss: -0.6092  Acc@1: 81.2500 (80.3010)  Acc@5: 100.0000 (98.7565)  time: 0.3598  data: 0.0025  max mem: 2503
Train: Epoch[4/5]  [ 200/3750]  eta: 0:21:38  Lr: 0.001875  Loss: -0.0625  Acc@1: 81.2500 (80.2550)  Acc@5: 100.0000 (98.8184)  time: 0.3643  data: 0.0045  max mem: 2503
Train: Epoch[4/5]  [ 210/3750]  eta: 0:21:34  Lr: 0.001875  Loss: -0.8747  Acc@1: 81.2500 (80.3318)  Acc@5: 100.0000 (98.8448)  time: 0.3648  data: 0.0069  max mem: 2503
Train: Epoch[4/5]  [ 220/3750]  eta: 0:21:29  Lr: 0.001875  Loss: 0.5937  Acc@1: 81.2500 (80.2319)  Acc@5: 100.0000 (98.8122)  time: 0.3614  data: 0.0058  max mem: 2503
Train: Epoch[4/5]  [ 230/3750]  eta: 0:21:26  Lr: 0.001875  Loss: -0.7047  Acc@1: 81.2500 (80.2760)  Acc@5: 100.0000 (98.8636)  time: 0.3626  data: 0.0035  max mem: 2503
Train: Epoch[4/5]  [ 240/3750]  eta: 0:21:24  Lr: 0.001875  Loss: -0.6385  Acc@1: 81.2500 (80.3942)  Acc@5: 100.0000 (98.8589)  time: 0.3708  data: 0.0029  max mem: 2503
Train: Epoch[4/5]  [ 250/3750]  eta: 0:21:21  Lr: 0.001875  Loss: -0.6872  Acc@1: 81.2500 (80.5279)  Acc@5: 100.0000 (98.9044)  time: 0.3750  data: 0.0040  max mem: 2503
Train: Epoch[4/5]  [ 260/3750]  eta: 0:21:17  Lr: 0.001875  Loss: 0.0631  Acc@1: 81.2500 (80.6753)  Acc@5: 100.0000 (98.8985)  time: 0.3695  data: 0.0039  max mem: 2503
Train: Epoch[4/5]  [ 270/3750]  eta: 0:21:14  Lr: 0.001875  Loss: -0.4159  Acc@1: 81.2500 (80.7657)  Acc@5: 100.0000 (98.8930)  time: 0.3657  data: 0.0027  max mem: 2503
Train: Epoch[4/5]  [ 280/3750]  eta: 0:21:09  Lr: 0.001875  Loss: -0.6268  Acc@1: 81.2500 (80.7607)  Acc@5: 100.0000 (98.8879)  time: 0.3621  data: 0.0025  max mem: 2503
Train: Epoch[4/5]  [ 290/3750]  eta: 0:21:05  Lr: 0.001875  Loss: -0.5915  Acc@1: 81.2500 (80.7131)  Acc@5: 100.0000 (98.9046)  time: 0.3605  data: 0.0013  max mem: 2503
Train: Epoch[4/5]  [ 300/3750]  eta: 0:21:01  Lr: 0.001875  Loss: 0.3000  Acc@1: 75.0000 (80.5648)  Acc@5: 100.0000 (98.8580)  time: 0.3647  data: 0.0047  max mem: 2503
Train: Epoch[4/5]  [ 310/3750]  eta: 0:20:56  Lr: 0.001875  Loss: -0.5796  Acc@1: 81.2500 (80.6873)  Acc@5: 100.0000 (98.8545)  time: 0.3583  data: 0.0052  max mem: 2503
Train: Epoch[4/5]  [ 320/3750]  eta: 0:20:53  Lr: 0.001875  Loss: -0.5702  Acc@1: 87.5000 (80.8217)  Acc@5: 100.0000 (98.8512)  time: 0.3615  data: 0.0028  max mem: 2503
Train: Epoch[4/5]  [ 330/3750]  eta: 0:20:49  Lr: 0.001875  Loss: -0.4589  Acc@1: 81.2500 (80.8535)  Acc@5: 100.0000 (98.8482)  time: 0.3651  data: 0.0031  max mem: 2503
Train: Epoch[4/5]  [ 340/3750]  eta: 0:20:44  Lr: 0.001875  Loss: -0.3404  Acc@1: 81.2500 (80.9201)  Acc@5: 100.0000 (98.8820)  time: 0.3579  data: 0.0031  max mem: 2503
Train: Epoch[4/5]  [ 350/3750]  eta: 0:20:41  Lr: 0.001875  Loss: -0.7012  Acc@1: 81.2500 (80.9829)  Acc@5: 100.0000 (98.9138)  time: 0.3609  data: 0.0034  max mem: 2503
Train: Epoch[4/5]  [ 360/3750]  eta: 0:20:38  Lr: 0.001875  Loss: -0.6177  Acc@1: 81.2500 (80.9903)  Acc@5: 100.0000 (98.9093)  time: 0.3681  data: 0.0046  max mem: 2503
Train: Epoch[4/5]  [ 370/3750]  eta: 0:20:34  Lr: 0.001875  Loss: -0.4483  Acc@1: 87.5000 (81.1321)  Acc@5: 100.0000 (98.9050)  time: 0.3675  data: 0.0035  max mem: 2503
Train: Epoch[4/5]  [ 380/3750]  eta: 0:20:30  Lr: 0.001875  Loss: -0.5433  Acc@1: 81.2500 (80.9875)  Acc@5: 100.0000 (98.8845)  time: 0.3638  data: 0.0036  max mem: 2503
Train: Epoch[4/5]  [ 390/3750]  eta: 0:20:27  Lr: 0.001875  Loss: -0.7700  Acc@1: 75.0000 (80.9143)  Acc@5: 100.0000 (98.8971)  time: 0.3662  data: 0.0051  max mem: 2503
Train: Epoch[4/5]  [ 400/3750]  eta: 0:20:23  Lr: 0.001875  Loss: -0.5498  Acc@1: 81.2500 (80.8603)  Acc@5: 100.0000 (98.8934)  time: 0.3696  data: 0.0047  max mem: 2503
Train: Epoch[4/5]  [ 410/3750]  eta: 0:20:19  Lr: 0.001875  Loss: 0.2770  Acc@1: 81.2500 (80.8090)  Acc@5: 100.0000 (98.8899)  time: 0.3642  data: 0.0040  max mem: 2503
Train: Epoch[4/5]  [ 420/3750]  eta: 0:20:15  Lr: 0.001875  Loss: -0.8717  Acc@1: 81.2500 (80.8640)  Acc@5: 100.0000 (98.9163)  time: 0.3578  data: 0.0024  max mem: 2503
Train: Epoch[4/5]  [ 430/3750]  eta: 0:20:11  Lr: 0.001875  Loss: -0.5015  Acc@1: 81.2500 (80.9310)  Acc@5: 100.0000 (98.9124)  time: 0.3589  data: 0.0031  max mem: 2503
Train: Epoch[4/5]  [ 440/3750]  eta: 0:20:08  Lr: 0.001875  Loss: -0.7509  Acc@1: 81.2500 (80.9382)  Acc@5: 100.0000 (98.9229)  time: 0.3646  data: 0.0037  max mem: 2503
Train: Epoch[4/5]  [ 450/3750]  eta: 0:20:03  Lr: 0.001875  Loss: -0.7237  Acc@1: 87.5000 (81.0698)  Acc@5: 100.0000 (98.9468)  time: 0.3624  data: 0.0027  max mem: 2503
Train: Epoch[4/5]  [ 460/3750]  eta: 0:19:59  Lr: 0.001875  Loss: -0.5430  Acc@1: 81.2500 (81.0195)  Acc@5: 100.0000 (98.9696)  time: 0.3579  data: 0.0034  max mem: 2503
Train: Epoch[4/5]  [ 470/3750]  eta: 0:19:55  Lr: 0.001875  Loss: -0.7034  Acc@1: 81.2500 (81.0377)  Acc@5: 100.0000 (98.9650)  time: 0.3592  data: 0.0036  max mem: 2503
Train: Epoch[4/5]  [ 480/3750]  eta: 0:19:51  Lr: 0.001875  Loss: -0.1635  Acc@1: 81.2500 (81.0941)  Acc@5: 100.0000 (98.9735)  time: 0.3582  data: 0.0022  max mem: 2503
Train: Epoch[4/5]  [ 490/3750]  eta: 0:19:47  Lr: 0.001875  Loss: -0.6012  Acc@1: 81.2500 (81.1354)  Acc@5: 100.0000 (98.9817)  time: 0.3604  data: 0.0022  max mem: 2503
Train: Epoch[4/5]  [ 500/3750]  eta: 0:19:44  Lr: 0.001875  Loss: -0.4503  Acc@1: 81.2500 (81.1627)  Acc@5: 100.0000 (98.9770)  time: 0.3631  data: 0.0022  max mem: 2503
Train: Epoch[4/5]  [ 510/3750]  eta: 0:19:40  Lr: 0.001875  Loss: -0.4618  Acc@1: 81.2500 (81.0910)  Acc@5: 100.0000 (98.9604)  time: 0.3648  data: 0.0025  max mem: 2503
Train: Epoch[4/5]  [ 520/3750]  eta: 0:19:36  Lr: 0.001875  Loss: -0.6950  Acc@1: 81.2500 (81.0341)  Acc@5: 100.0000 (98.9683)  time: 0.3625  data: 0.0033  max mem: 2503
Train: Epoch[4/5]  [ 530/3750]  eta: 0:19:32  Lr: 0.001875  Loss: -0.8363  Acc@1: 81.2500 (81.0381)  Acc@5: 100.0000 (98.9524)  time: 0.3613  data: 0.0048  max mem: 2503
Train: Epoch[4/5]  [ 540/3750]  eta: 0:19:29  Lr: 0.001875  Loss: -0.5804  Acc@1: 75.0000 (81.0074)  Acc@5: 100.0000 (98.9256)  time: 0.3677  data: 0.0065  max mem: 2503
Train: Epoch[4/5]  [ 550/3750]  eta: 0:19:26  Lr: 0.001875  Loss: -0.1669  Acc@1: 81.2500 (81.0118)  Acc@5: 100.0000 (98.9338)  time: 0.3719  data: 0.0071  max mem: 2503
Train: Epoch[4/5]  [ 560/3750]  eta: 0:19:22  Lr: 0.001875  Loss: -0.2375  Acc@1: 81.2500 (80.9938)  Acc@5: 100.0000 (98.9193)  time: 0.3686  data: 0.0055  max mem: 2503
Train: Epoch[4/5]  [ 570/3750]  eta: 0:19:19  Lr: 0.001875  Loss: -0.7077  Acc@1: 81.2500 (81.0311)  Acc@5: 100.0000 (98.9383)  time: 0.3632  data: 0.0035  max mem: 2503
Train: Epoch[4/5]  [ 580/3750]  eta: 0:19:15  Lr: 0.001875  Loss: -0.4443  Acc@1: 81.2500 (81.0026)  Acc@5: 100.0000 (98.9458)  time: 0.3604  data: 0.0029  max mem: 2503
Train: Epoch[4/5]  [ 590/3750]  eta: 0:19:11  Lr: 0.001875  Loss: -0.6285  Acc@1: 81.2500 (81.0596)  Acc@5: 100.0000 (98.9530)  time: 0.3574  data: 0.0030  max mem: 2503
Train: Epoch[4/5]  [ 600/3750]  eta: 0:19:07  Lr: 0.001875  Loss: -0.4485  Acc@1: 81.2500 (81.0628)  Acc@5: 100.0000 (98.9497)  time: 0.3624  data: 0.0034  max mem: 2503
Train: Epoch[4/5]  [ 610/3750]  eta: 0:19:03  Lr: 0.001875  Loss: -0.4698  Acc@1: 81.2500 (81.0556)  Acc@5: 100.0000 (98.9669)  time: 0.3627  data: 0.0026  max mem: 2503
Train: Epoch[4/5]  [ 620/3750]  eta: 0:19:00  Lr: 0.001875  Loss: -0.8720  Acc@1: 87.5000 (81.0990)  Acc@5: 100.0000 (98.9835)  time: 0.3611  data: 0.0024  max mem: 2503
Train: Epoch[4/5]  [ 630/3750]  eta: 0:18:56  Lr: 0.001875  Loss: -0.5515  Acc@1: 81.2500 (81.0816)  Acc@5: 100.0000 (98.9798)  time: 0.3610  data: 0.0023  max mem: 2503
Train: Epoch[4/5]  [ 640/3750]  eta: 0:18:52  Lr: 0.001875  Loss: -0.4034  Acc@1: 81.2500 (81.0745)  Acc@5: 100.0000 (98.9665)  time: 0.3586  data: 0.0027  max mem: 2503
Train: Epoch[4/5]  [ 650/3750]  eta: 0:18:48  Lr: 0.001875  Loss: -0.7179  Acc@1: 81.2500 (81.0388)  Acc@5: 100.0000 (98.9439)  time: 0.3589  data: 0.0026  max mem: 2503
Train: Epoch[4/5]  [ 660/3750]  eta: 0:18:44  Lr: 0.001875  Loss: -0.9717  Acc@1: 81.2500 (81.1082)  Acc@5: 100.0000 (98.9599)  time: 0.3568  data: 0.0018  max mem: 2503
Train: Epoch[4/5]  [ 670/3750]  eta: 0:18:40  Lr: 0.001875  Loss: -0.4289  Acc@1: 81.2500 (81.0917)  Acc@5: 100.0000 (98.9661)  time: 0.3553  data: 0.0024  max mem: 2503
Train: Epoch[4/5]  [ 680/3750]  eta: 0:18:36  Lr: 0.001875  Loss: -0.6274  Acc@1: 81.2500 (81.1674)  Acc@5: 100.0000 (98.9813)  time: 0.3590  data: 0.0045  max mem: 2503
Train: Epoch[4/5]  [ 690/3750]  eta: 0:18:32  Lr: 0.001875  Loss: -0.7338  Acc@1: 87.5000 (81.3133)  Acc@5: 100.0000 (98.9870)  time: 0.3609  data: 0.0043  max mem: 2503
Train: Epoch[4/5]  [ 700/3750]  eta: 0:18:29  Lr: 0.001875  Loss: -0.4006  Acc@1: 87.5000 (81.3392)  Acc@5: 100.0000 (99.0014)  time: 0.3670  data: 0.0035  max mem: 2503
Train: Epoch[4/5]  [ 710/3750]  eta: 0:18:26  Lr: 0.001875  Loss: -0.6209  Acc@1: 81.2500 (81.3555)  Acc@5: 100.0000 (99.0067)  time: 0.3733  data: 0.0049  max mem: 2503
Train: Epoch[4/5]  [ 720/3750]  eta: 0:18:22  Lr: 0.001875  Loss: -0.6260  Acc@1: 75.0000 (81.3367)  Acc@5: 100.0000 (99.0118)  time: 0.3646  data: 0.0052  max mem: 2503
Train: Epoch[4/5]  [ 730/3750]  eta: 0:18:18  Lr: 0.001875  Loss: -0.4653  Acc@1: 81.2500 (81.3526)  Acc@5: 100.0000 (99.0082)  time: 0.3617  data: 0.0040  max mem: 2503
Train: Epoch[4/5]  [ 740/3750]  eta: 0:18:15  Lr: 0.001875  Loss: -0.9804  Acc@1: 81.2500 (81.3512)  Acc@5: 100.0000 (99.0047)  time: 0.3686  data: 0.0028  max mem: 2503
Train: Epoch[4/5]  [ 750/3750]  eta: 0:18:12  Lr: 0.001875  Loss: -0.6866  Acc@1: 81.2500 (81.3415)  Acc@5: 100.0000 (99.0097)  time: 0.3718  data: 0.0026  max mem: 2503
Train: Epoch[4/5]  [ 760/3750]  eta: 0:18:08  Lr: 0.001875  Loss: -0.5734  Acc@1: 81.2500 (81.3321)  Acc@5: 100.0000 (99.0227)  time: 0.3647  data: 0.0041  max mem: 2503
Train: Epoch[4/5]  [ 770/3750]  eta: 0:18:04  Lr: 0.001875  Loss: -0.5831  Acc@1: 87.5000 (81.4527)  Acc@5: 100.0000 (99.0353)  time: 0.3582  data: 0.0050  max mem: 2503
Train: Epoch[4/5]  [ 780/3750]  eta: 0:18:00  Lr: 0.001875  Loss: -0.5081  Acc@1: 87.5000 (81.4581)  Acc@5: 100.0000 (99.0397)  time: 0.3578  data: 0.0037  max mem: 2503
Train: Epoch[4/5]  [ 790/3750]  eta: 0:17:56  Lr: 0.001875  Loss: -0.3224  Acc@1: 87.5000 (81.4238)  Acc@5: 100.0000 (99.0360)  time: 0.3554  data: 0.0028  max mem: 2503
Train: Epoch[4/5]  [ 800/3750]  eta: 0:17:52  Lr: 0.001875  Loss: -0.7560  Acc@1: 87.5000 (81.5309)  Acc@5: 100.0000 (99.0481)  time: 0.3544  data: 0.0040  max mem: 2503
Train: Epoch[4/5]  [ 810/3750]  eta: 0:17:48  Lr: 0.001875  Loss: -0.4364  Acc@1: 81.2500 (81.5043)  Acc@5: 100.0000 (99.0290)  time: 0.3571  data: 0.0040  max mem: 2503
Train: Epoch[4/5]  [ 820/3750]  eta: 0:17:45  Lr: 0.001875  Loss: -0.3223  Acc@1: 81.2500 (81.4632)  Acc@5: 100.0000 (99.0027)  time: 0.3650  data: 0.0024  max mem: 2503
Train: Epoch[4/5]  [ 830/3750]  eta: 0:17:41  Lr: 0.001875  Loss: -0.3919  Acc@1: 81.2500 (81.4455)  Acc@5: 100.0000 (98.9922)  time: 0.3652  data: 0.0025  max mem: 2503
Train: Epoch[4/5]  [ 840/3750]  eta: 0:17:38  Lr: 0.001875  Loss: -0.4699  Acc@1: 81.2500 (81.4581)  Acc@5: 100.0000 (98.9967)  time: 0.3622  data: 0.0051  max mem: 2503
Train: Epoch[4/5]  [ 850/3750]  eta: 0:17:34  Lr: 0.001875  Loss: -0.1951  Acc@1: 81.2500 (81.4116)  Acc@5: 100.0000 (99.0085)  time: 0.3656  data: 0.0054  max mem: 2503
Train: Epoch[4/5]  [ 860/3750]  eta: 0:17:30  Lr: 0.001875  Loss: -0.6281  Acc@1: 81.2500 (81.4460)  Acc@5: 100.0000 (99.0055)  time: 0.3645  data: 0.0047  max mem: 2503
Train: Epoch[4/5]  [ 870/3750]  eta: 0:17:27  Lr: 0.001875  Loss: -0.7185  Acc@1: 87.5000 (81.4796)  Acc@5: 100.0000 (99.0098)  time: 0.3634  data: 0.0044  max mem: 2503
Train: Epoch[4/5]  [ 880/3750]  eta: 0:17:23  Lr: 0.001875  Loss: -0.6263  Acc@1: 87.5000 (81.5338)  Acc@5: 100.0000 (99.0139)  time: 0.3665  data: 0.0019  max mem: 2503
Train: Epoch[4/5]  [ 890/3750]  eta: 0:17:19  Lr: 0.001875  Loss: -0.7300  Acc@1: 81.2500 (81.5025)  Acc@5: 100.0000 (98.9969)  time: 0.3641  data: 0.0029  max mem: 2503
Train: Epoch[4/5]  [ 900/3750]  eta: 0:17:16  Lr: 0.001875  Loss: -0.4300  Acc@1: 75.0000 (81.4442)  Acc@5: 100.0000 (99.0011)  time: 0.3613  data: 0.0040  max mem: 2503
Train: Epoch[4/5]  [ 910/3750]  eta: 0:17:12  Lr: 0.001875  Loss: -0.5598  Acc@1: 75.0000 (81.4284)  Acc@5: 100.0000 (98.9984)  time: 0.3678  data: 0.0033  max mem: 2503
Train: Epoch[4/5]  [ 920/3750]  eta: 0:17:09  Lr: 0.001875  Loss: -0.7784  Acc@1: 75.0000 (81.3789)  Acc@5: 100.0000 (99.0024)  time: 0.3680  data: 0.0032  max mem: 2503
Train: Epoch[4/5]  [ 930/3750]  eta: 0:17:05  Lr: 0.001875  Loss: -0.6231  Acc@1: 81.2500 (81.3910)  Acc@5: 100.0000 (99.0132)  time: 0.3626  data: 0.0039  max mem: 2503
Train: Epoch[4/5]  [ 940/3750]  eta: 0:17:01  Lr: 0.001875  Loss: -0.4902  Acc@1: 81.2500 (81.3363)  Acc@5: 100.0000 (99.0236)  time: 0.3586  data: 0.0041  max mem: 2503
Train: Epoch[4/5]  [ 950/3750]  eta: 0:16:57  Lr: 0.001875  Loss: -0.8221  Acc@1: 81.2500 (81.3749)  Acc@5: 100.0000 (99.0142)  time: 0.3562  data: 0.0049  max mem: 2503
Train: Epoch[4/5]  [ 960/3750]  eta: 0:16:54  Lr: 0.001875  Loss: -0.6319  Acc@1: 81.2500 (81.3150)  Acc@5: 100.0000 (99.0049)  time: 0.3596  data: 0.0034  max mem: 2503
Train: Epoch[4/5]  [ 970/3750]  eta: 0:16:50  Lr: 0.001875  Loss: -0.1084  Acc@1: 75.0000 (81.3272)  Acc@5: 100.0000 (99.0023)  time: 0.3632  data: 0.0018  max mem: 2503
Train: Epoch[4/5]  [ 980/3750]  eta: 0:16:46  Lr: 0.001875  Loss: -0.9326  Acc@1: 75.0000 (81.3265)  Acc@5: 100.0000 (99.0061)  time: 0.3634  data: 0.0017  max mem: 2503
Train: Epoch[4/5]  [ 990/3750]  eta: 0:16:43  Lr: 0.001875  Loss: -0.3319  Acc@1: 75.0000 (81.3194)  Acc@5: 100.0000 (98.9909)  time: 0.3620  data: 0.0022  max mem: 2503
Train: Epoch[4/5]  [1000/3750]  eta: 0:16:39  Lr: 0.001875  Loss: -0.6766  Acc@1: 81.2500 (81.2937)  Acc@5: 100.0000 (98.9948)  time: 0.3682  data: 0.0042  max mem: 2503
Train: Epoch[4/5]  [1010/3750]  eta: 0:16:37  Lr: 0.001875  Loss: -0.6581  Acc@1: 87.5000 (81.3242)  Acc@5: 100.0000 (98.9923)  time: 0.3850  data: 0.0058  max mem: 2503
Train: Epoch[4/5]  [1020/3750]  eta: 0:16:33  Lr: 0.001875  Loss: -0.3365  Acc@1: 87.5000 (81.3969)  Acc@5: 100.0000 (98.9838)  time: 0.3748  data: 0.0047  max mem: 2503
Train: Epoch[4/5]  [1030/3750]  eta: 0:16:29  Lr: 0.001875  Loss: -0.5342  Acc@1: 87.5000 (81.4440)  Acc@5: 100.0000 (98.9876)  time: 0.3576  data: 0.0024  max mem: 2503
Train: Epoch[4/5]  [1040/3750]  eta: 0:16:25  Lr: 0.001875  Loss: -0.9258  Acc@1: 87.5000 (81.5142)  Acc@5: 100.0000 (98.9854)  time: 0.3570  data: 0.0021  max mem: 2503
Train: Epoch[4/5]  [1050/3750]  eta: 0:16:21  Lr: 0.001875  Loss: -0.4868  Acc@1: 87.5000 (81.4938)  Acc@5: 100.0000 (98.9772)  time: 0.3593  data: 0.0046  max mem: 2503
Train: Epoch[4/5]  [1060/3750]  eta: 0:16:18  Lr: 0.001875  Loss: -0.7109  Acc@1: 81.2500 (81.4915)  Acc@5: 100.0000 (98.9750)  time: 0.3631  data: 0.0053  max mem: 2503
Train: Epoch[4/5]  [1070/3750]  eta: 0:16:14  Lr: 0.001875  Loss: -0.8948  Acc@1: 81.2500 (81.4893)  Acc@5: 100.0000 (98.9729)  time: 0.3620  data: 0.0044  max mem: 2503
Train: Epoch[4/5]  [1080/3750]  eta: 0:16:10  Lr: 0.001875  Loss: -0.5843  Acc@1: 81.2500 (81.5275)  Acc@5: 100.0000 (98.9766)  time: 0.3584  data: 0.0050  max mem: 2503
Train: Epoch[4/5]  [1090/3750]  eta: 0:16:06  Lr: 0.001875  Loss: -0.6831  Acc@1: 87.5000 (81.5307)  Acc@5: 100.0000 (98.9803)  time: 0.3562  data: 0.0045  max mem: 2503
Train: Epoch[4/5]  [1100/3750]  eta: 0:16:03  Lr: 0.001875  Loss: -0.5786  Acc@1: 81.2500 (81.5168)  Acc@5: 100.0000 (98.9839)  time: 0.3550  data: 0.0039  max mem: 2503
Train: Epoch[4/5]  [1110/3750]  eta: 0:15:59  Lr: 0.001875  Loss: -0.4105  Acc@1: 81.2500 (81.5257)  Acc@5: 100.0000 (98.9930)  time: 0.3574  data: 0.0033  max mem: 2503
Train: Epoch[4/5]  [1120/3750]  eta: 0:15:55  Lr: 0.001875  Loss: 0.0975  Acc@1: 81.2500 (81.4786)  Acc@5: 100.0000 (98.9853)  time: 0.3616  data: 0.0047  max mem: 2503
Train: Epoch[4/5]  [1130/3750]  eta: 0:15:51  Lr: 0.001875  Loss: -0.7443  Acc@1: 81.2500 (81.4545)  Acc@5: 100.0000 (98.9777)  time: 0.3589  data: 0.0055  max mem: 2503
Train: Epoch[4/5]  [1140/3750]  eta: 0:15:48  Lr: 0.001875  Loss: -0.5840  Acc@1: 81.2500 (81.4143)  Acc@5: 100.0000 (98.9812)  time: 0.3552  data: 0.0029  max mem: 2503
Train: Epoch[4/5]  [1150/3750]  eta: 0:15:44  Lr: 0.001875  Loss: -0.8130  Acc@1: 81.2500 (81.3858)  Acc@5: 100.0000 (98.9737)  time: 0.3628  data: 0.0022  max mem: 2503
Train: Epoch[4/5]  [1160/3750]  eta: 0:15:41  Lr: 0.001875  Loss: -0.9106  Acc@1: 81.2500 (81.4007)  Acc@5: 100.0000 (98.9664)  time: 0.3718  data: 0.0040  max mem: 2503
Train: Epoch[4/5]  [1170/3750]  eta: 0:15:37  Lr: 0.001875  Loss: -0.7829  Acc@1: 81.2500 (81.4261)  Acc@5: 100.0000 (98.9699)  time: 0.3688  data: 0.0047  max mem: 2503
Train: Epoch[4/5]  [1180/3750]  eta: 0:15:33  Lr: 0.001875  Loss: -0.3009  Acc@1: 81.2500 (81.3876)  Acc@5: 100.0000 (98.9680)  time: 0.3619  data: 0.0029  max mem: 2503
Train: Epoch[4/5]  [1190/3750]  eta: 0:15:30  Lr: 0.001875  Loss: -0.7738  Acc@1: 81.2500 (81.4022)  Acc@5: 100.0000 (98.9715)  time: 0.3573  data: 0.0012  max mem: 2503
Train: Epoch[4/5]  [1200/3750]  eta: 0:15:26  Lr: 0.001875  Loss: -0.4935  Acc@1: 81.2500 (81.3905)  Acc@5: 100.0000 (98.9800)  time: 0.3610  data: 0.0029  max mem: 2503
Train: Epoch[4/5]  [1210/3750]  eta: 0:15:22  Lr: 0.001875  Loss: -0.4751  Acc@1: 81.2500 (81.3635)  Acc@5: 100.0000 (98.9833)  time: 0.3616  data: 0.0043  max mem: 2503
Train: Epoch[4/5]  [1220/3750]  eta: 0:15:18  Lr: 0.001875  Loss: -0.7112  Acc@1: 81.2500 (81.3370)  Acc@5: 100.0000 (98.9762)  time: 0.3565  data: 0.0026  max mem: 2503
Train: Epoch[4/5]  [1230/3750]  eta: 0:15:15  Lr: 0.001875  Loss: -0.4321  Acc@1: 81.2500 (81.3262)  Acc@5: 100.0000 (98.9795)  time: 0.3569  data: 0.0019  max mem: 2503
Train: Epoch[4/5]  [1240/3750]  eta: 0:15:11  Lr: 0.001875  Loss: -0.4630  Acc@1: 75.0000 (81.3004)  Acc@5: 100.0000 (98.9776)  time: 0.3573  data: 0.0020  max mem: 2503
Train: Epoch[4/5]  [1250/3750]  eta: 0:15:07  Lr: 0.001875  Loss: -0.4123  Acc@1: 81.2500 (81.3199)  Acc@5: 100.0000 (98.9758)  time: 0.3561  data: 0.0016  max mem: 2503
Train: Epoch[4/5]  [1260/3750]  eta: 0:15:04  Lr: 0.001875  Loss: -0.8469  Acc@1: 87.5000 (81.3541)  Acc@5: 100.0000 (98.9839)  time: 0.3599  data: 0.0023  max mem: 2503
Train: Epoch[4/5]  [1270/3750]  eta: 0:15:00  Lr: 0.001875  Loss: -0.4010  Acc@1: 87.5000 (81.3680)  Acc@5: 100.0000 (98.9821)  time: 0.3610  data: 0.0018  max mem: 2503
Train: Epoch[4/5]  [1280/3750]  eta: 0:14:56  Lr: 0.001875  Loss: -0.8400  Acc@1: 81.2500 (81.3622)  Acc@5: 100.0000 (98.9754)  time: 0.3596  data: 0.0027  max mem: 2503
Train: Epoch[4/5]  [1290/3750]  eta: 0:14:53  Lr: 0.001875  Loss: -0.6708  Acc@1: 81.2500 (81.3759)  Acc@5: 100.0000 (98.9737)  time: 0.3645  data: 0.0041  max mem: 2503
Train: Epoch[4/5]  [1300/3750]  eta: 0:14:49  Lr: 0.001875  Loss: -0.3921  Acc@1: 81.2500 (81.3701)  Acc@5: 100.0000 (98.9671)  time: 0.3719  data: 0.0043  max mem: 2503
Train: Epoch[4/5]  [1310/3750]  eta: 0:14:46  Lr: 0.001875  Loss: -0.1084  Acc@1: 81.2500 (81.3549)  Acc@5: 100.0000 (98.9655)  time: 0.3667  data: 0.0047  max mem: 2503
Train: Epoch[4/5]  [1320/3750]  eta: 0:14:42  Lr: 0.001875  Loss: -0.8939  Acc@1: 81.2500 (81.3825)  Acc@5: 100.0000 (98.9639)  time: 0.3593  data: 0.0055  max mem: 2503
Train: Epoch[4/5]  [1330/3750]  eta: 0:14:38  Lr: 0.001875  Loss: -0.7410  Acc@1: 87.5000 (81.4003)  Acc@5: 100.0000 (98.9622)  time: 0.3643  data: 0.0065  max mem: 2503
Train: Epoch[4/5]  [1340/3750]  eta: 0:14:34  Lr: 0.001875  Loss: -0.8651  Acc@1: 87.5000 (81.4364)  Acc@5: 100.0000 (98.9560)  time: 0.3597  data: 0.0045  max mem: 2503
Train: Epoch[4/5]  [1350/3750]  eta: 0:14:31  Lr: 0.001875  Loss: -0.5313  Acc@1: 75.0000 (81.3472)  Acc@5: 100.0000 (98.9545)  time: 0.3615  data: 0.0029  max mem: 2503
Train: Epoch[4/5]  [1360/3750]  eta: 0:14:27  Lr: 0.001875  Loss: -0.7684  Acc@1: 75.0000 (81.3556)  Acc@5: 100.0000 (98.9484)  time: 0.3652  data: 0.0038  max mem: 2503
Train: Epoch[4/5]  [1370/3750]  eta: 0:14:24  Lr: 0.001875  Loss: -0.6261  Acc@1: 81.2500 (81.3959)  Acc@5: 100.0000 (98.9561)  time: 0.3622  data: 0.0039  max mem: 2503
Train: Epoch[4/5]  [1380/3750]  eta: 0:14:20  Lr: 0.001875  Loss: -0.1737  Acc@1: 81.2500 (81.3677)  Acc@5: 100.0000 (98.9455)  time: 0.3596  data: 0.0023  max mem: 2503
Train: Epoch[4/5]  [1390/3750]  eta: 0:14:16  Lr: 0.001875  Loss: -0.4551  Acc@1: 75.0000 (81.3578)  Acc@5: 100.0000 (98.9531)  time: 0.3644  data: 0.0049  max mem: 2503
Train: Epoch[4/5]  [1400/3750]  eta: 0:14:13  Lr: 0.001875  Loss: -0.5144  Acc@1: 75.0000 (81.3125)  Acc@5: 100.0000 (98.9516)  time: 0.3652  data: 0.0047  max mem: 2503
Train: Epoch[4/5]  [1410/3750]  eta: 0:14:09  Lr: 0.001875  Loss: -0.7057  Acc@1: 75.0000 (81.3253)  Acc@5: 100.0000 (98.9591)  time: 0.3552  data: 0.0014  max mem: 2503
Train: Epoch[4/5]  [1420/3750]  eta: 0:14:05  Lr: 0.001875  Loss: -0.4198  Acc@1: 81.2500 (81.3116)  Acc@5: 100.0000 (98.9576)  time: 0.3550  data: 0.0022  max mem: 2503
Train: Epoch[4/5]  [1430/3750]  eta: 0:14:01  Lr: 0.001875  Loss: -0.6397  Acc@1: 81.2500 (81.3199)  Acc@5: 100.0000 (98.9561)  time: 0.3566  data: 0.0029  max mem: 2503
Train: Epoch[4/5]  [1440/3750]  eta: 0:13:58  Lr: 0.001875  Loss: -0.6402  Acc@1: 81.2500 (81.2890)  Acc@5: 100.0000 (98.9547)  time: 0.3585  data: 0.0029  max mem: 2503
Train: Epoch[4/5]  [1450/3750]  eta: 0:13:54  Lr: 0.001875  Loss: -0.9176  Acc@1: 81.2500 (81.2931)  Acc@5: 100.0000 (98.9490)  time: 0.3607  data: 0.0021  max mem: 2503
Train: Epoch[4/5]  [1460/3750]  eta: 0:13:54  Lr: 0.001875  Loss: -0.5077  Acc@1: 81.2500 (81.2757)  Acc@5: 100.0000 (98.9519)  time: 0.4587  data: 0.0020  max mem: 2503
Train: Epoch[4/5]  [1470/3750]  eta: 0:13:55  Lr: 0.001875  Loss: -0.5682  Acc@1: 81.2500 (81.2712)  Acc@5: 100.0000 (98.9548)  time: 0.6140  data: 0.0016  max mem: 2503
Train: Epoch[4/5]  [1480/3750]  eta: 0:13:56  Lr: 0.001875  Loss: -0.6680  Acc@1: 81.2500 (81.2584)  Acc@5: 100.0000 (98.9534)  time: 0.6834  data: 0.0006  max mem: 2503
Train: Epoch[4/5]  [1490/3750]  eta: 0:13:57  Lr: 0.001875  Loss: -0.2772  Acc@1: 81.2500 (81.2458)  Acc@5: 100.0000 (98.9562)  time: 0.6907  data: 0.0013  max mem: 2503
Train: Epoch[4/5]  [1500/3750]  eta: 0:13:58  Lr: 0.001875  Loss: -0.7491  Acc@1: 81.2500 (81.2500)  Acc@5: 100.0000 (98.9507)  time: 0.6710  data: 0.0017  max mem: 2503
Train: Epoch[4/5]  [1510/3750]  eta: 0:13:59  Lr: 0.001875  Loss: -0.6876  Acc@1: 81.2500 (81.2500)  Acc@5: 100.0000 (98.9535)  time: 0.6718  data: 0.0016  max mem: 2503
Train: Epoch[4/5]  [1520/3750]  eta: 0:14:00  Lr: 0.001875  Loss: -0.5133  Acc@1: 87.5000 (81.2829)  Acc@5: 100.0000 (98.9563)  time: 0.6878  data: 0.0013  max mem: 2503
Train: Epoch[4/5]  [1530/3750]  eta: 0:14:00  Lr: 0.001875  Loss: -0.6167  Acc@1: 87.5000 (81.3031)  Acc@5: 100.0000 (98.9631)  time: 0.6845  data: 0.0008  max mem: 2503
Train: Epoch[4/5]  [1540/3750]  eta: 0:14:01  Lr: 0.001875  Loss: -0.3202  Acc@1: 81.2500 (81.2824)  Acc@5: 100.0000 (98.9698)  time: 0.6768  data: 0.0007  max mem: 2503
Train: Epoch[4/5]  [1550/3750]  eta: 0:14:00  Lr: 0.001875  Loss: -0.7711  Acc@1: 75.0000 (81.2701)  Acc@5: 100.0000 (98.9724)  time: 0.6549  data: 0.0007  max mem: 2503
Train: Epoch[4/5]  [1560/3750]  eta: 0:14:00  Lr: 0.001875  Loss: -0.7744  Acc@1: 75.0000 (81.2380)  Acc@5: 100.0000 (98.9710)  time: 0.6427  data: 0.0007  max mem: 2503
Train: Epoch[4/5]  [1570/3750]  eta: 0:14:01  Lr: 0.001875  Loss: -0.4961  Acc@1: 75.0000 (81.2182)  Acc@5: 100.0000 (98.9736)  time: 0.6627  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [1580/3750]  eta: 0:14:01  Lr: 0.001875  Loss: -0.2547  Acc@1: 81.2500 (81.2263)  Acc@5: 100.0000 (98.9682)  time: 0.6744  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [1590/3750]  eta: 0:14:01  Lr: 0.001875  Loss: -0.8745  Acc@1: 81.2500 (81.2107)  Acc@5: 100.0000 (98.9747)  time: 0.6832  data: 0.0011  max mem: 2503
Train: Epoch[4/5]  [1600/3750]  eta: 0:14:00  Lr: 0.001875  Loss: -0.3354  Acc@1: 81.2500 (81.2149)  Acc@5: 100.0000 (98.9733)  time: 0.6712  data: 0.0015  max mem: 2503
Train: Epoch[4/5]  [1610/3750]  eta: 0:14:00  Lr: 0.001875  Loss: -0.6438  Acc@1: 81.2500 (81.2228)  Acc@5: 100.0000 (98.9758)  time: 0.6582  data: 0.0011  max mem: 2503
Train: Epoch[4/5]  [1620/3750]  eta: 0:14:00  Lr: 0.001875  Loss: -0.3913  Acc@1: 81.2500 (81.2076)  Acc@5: 100.0000 (98.9744)  time: 0.6726  data: 0.0006  max mem: 2503
Train: Epoch[4/5]  [1630/3750]  eta: 0:14:00  Lr: 0.001875  Loss: -0.6719  Acc@1: 75.0000 (81.2002)  Acc@5: 100.0000 (98.9807)  time: 0.6806  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [1640/3750]  eta: 0:14:00  Lr: 0.001875  Loss: -0.7742  Acc@1: 87.5000 (81.2233)  Acc@5: 100.0000 (98.9793)  time: 0.6822  data: 0.0010  max mem: 2503
Train: Epoch[4/5]  [1650/3750]  eta: 0:13:59  Lr: 0.001875  Loss: -0.5095  Acc@1: 81.2500 (81.2386)  Acc@5: 100.0000 (98.9741)  time: 0.6644  data: 0.0010  max mem: 2503
Train: Epoch[4/5]  [1660/3750]  eta: 0:13:58  Lr: 0.001875  Loss: -0.5094  Acc@1: 81.2500 (81.1973)  Acc@5: 100.0000 (98.9728)  time: 0.6583  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [1670/3750]  eta: 0:13:57  Lr: 0.001875  Loss: -0.7072  Acc@1: 81.2500 (81.2201)  Acc@5: 100.0000 (98.9714)  time: 0.6666  data: 0.0007  max mem: 2503
Train: Epoch[4/5]  [1680/3750]  eta: 0:13:57  Lr: 0.001875  Loss: -0.5594  Acc@1: 87.5000 (81.2351)  Acc@5: 100.0000 (98.9701)  time: 0.6692  data: 0.0007  max mem: 2503
Train: Epoch[4/5]  [1690/3750]  eta: 0:13:56  Lr: 0.001875  Loss: -0.7041  Acc@1: 87.5000 (81.2611)  Acc@5: 100.0000 (98.9614)  time: 0.6762  data: 0.0006  max mem: 2503
Train: Epoch[4/5]  [1700/3750]  eta: 0:13:55  Lr: 0.001875  Loss: -0.8030  Acc@1: 87.5000 (81.2757)  Acc@5: 100.0000 (98.9602)  time: 0.6768  data: 0.0006  max mem: 2503
Train: Epoch[4/5]  [1710/3750]  eta: 0:13:54  Lr: 0.001875  Loss: -0.5019  Acc@1: 81.2500 (81.2792)  Acc@5: 100.0000 (98.9662)  time: 0.6671  data: 0.0006  max mem: 2503
Train: Epoch[4/5]  [1720/3750]  eta: 0:13:53  Lr: 0.001875  Loss: -0.2003  Acc@1: 81.2500 (81.2609)  Acc@5: 100.0000 (98.9686)  time: 0.6750  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [1730/3750]  eta: 0:13:52  Lr: 0.001875  Loss: -0.6029  Acc@1: 75.0000 (81.2500)  Acc@5: 100.0000 (98.9637)  time: 0.6795  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [1740/3750]  eta: 0:13:51  Lr: 0.001875  Loss: -0.8807  Acc@1: 87.5000 (81.2967)  Acc@5: 100.0000 (98.9697)  time: 0.6789  data: 0.0007  max mem: 2503
Train: Epoch[4/5]  [1750/3750]  eta: 0:13:50  Lr: 0.001875  Loss: -0.4194  Acc@1: 87.5000 (81.3035)  Acc@5: 100.0000 (98.9756)  time: 0.6927  data: 0.0008  max mem: 2503
Train: Epoch[4/5]  [1760/3750]  eta: 0:13:49  Lr: 0.001875  Loss: -0.3996  Acc@1: 81.2500 (81.2997)  Acc@5: 100.0000 (98.9779)  time: 0.6588  data: 0.0010  max mem: 2503
Train: Epoch[4/5]  [1770/3750]  eta: 0:13:47  Lr: 0.001875  Loss: -0.7744  Acc@1: 81.2500 (81.2959)  Acc@5: 100.0000 (98.9730)  time: 0.6328  data: 0.0009  max mem: 2503
Train: Epoch[4/5]  [1780/3750]  eta: 0:13:46  Lr: 0.001875  Loss: -0.7154  Acc@1: 81.2500 (81.2991)  Acc@5: 100.0000 (98.9718)  time: 0.6695  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [1790/3750]  eta: 0:13:45  Lr: 0.001875  Loss: -0.6281  Acc@1: 81.2500 (81.3058)  Acc@5: 100.0000 (98.9775)  time: 0.6907  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [1800/3750]  eta: 0:13:43  Lr: 0.001875  Loss: -0.5276  Acc@1: 81.2500 (81.3125)  Acc@5: 100.0000 (98.9797)  time: 0.6832  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [1810/3750]  eta: 0:13:41  Lr: 0.001875  Loss: -0.5327  Acc@1: 81.2500 (81.2983)  Acc@5: 100.0000 (98.9750)  time: 0.6665  data: 0.0012  max mem: 2503
Train: Epoch[4/5]  [1820/3750]  eta: 0:13:37  Lr: 0.001875  Loss: -0.8146  Acc@1: 81.2500 (81.3015)  Acc@5: 100.0000 (98.9738)  time: 0.5089  data: 0.0023  max mem: 2503
Train: Epoch[4/5]  [1830/3750]  eta: 0:13:33  Lr: 0.001875  Loss: -0.6925  Acc@1: 81.2500 (81.3012)  Acc@5: 100.0000 (98.9691)  time: 0.4274  data: 0.0016  max mem: 2503
Train: Epoch[4/5]  [1840/3750]  eta: 0:13:32  Lr: 0.001875  Loss: -0.8182  Acc@1: 87.5000 (81.2975)  Acc@5: 100.0000 (98.9747)  time: 0.5942  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [1850/3750]  eta: 0:13:28  Lr: 0.001875  Loss: -0.2280  Acc@1: 81.2500 (81.2736)  Acc@5: 100.0000 (98.9769)  time: 0.5778  data: 0.0009  max mem: 2503
Train: Epoch[4/5]  [1860/3750]  eta: 0:13:23  Lr: 0.001875  Loss: -0.3434  Acc@1: 81.2500 (81.2769)  Acc@5: 100.0000 (98.9757)  time: 0.4052  data: 0.0009  max mem: 2503
Train: Epoch[4/5]  [1870/3750]  eta: 0:13:18  Lr: 0.001875  Loss: -0.7848  Acc@1: 81.2500 (81.2734)  Acc@5: 100.0000 (98.9711)  time: 0.3546  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [1880/3750]  eta: 0:13:13  Lr: 0.001875  Loss: -0.5825  Acc@1: 75.0000 (81.2500)  Acc@5: 100.0000 (98.9700)  time: 0.3568  data: 0.0013  max mem: 2503
Train: Epoch[4/5]  [1890/3750]  eta: 0:13:08  Lr: 0.001875  Loss: -0.2971  Acc@1: 75.0000 (81.2335)  Acc@5: 100.0000 (98.9754)  time: 0.3565  data: 0.0022  max mem: 2503
Train: Epoch[4/5]  [1900/3750]  eta: 0:13:03  Lr: 0.001875  Loss: -0.5152  Acc@1: 81.2500 (81.2401)  Acc@5: 100.0000 (98.9742)  time: 0.3570  data: 0.0032  max mem: 2503
Train: Epoch[4/5]  [1910/3750]  eta: 0:12:58  Lr: 0.001875  Loss: -0.6203  Acc@1: 81.2500 (81.2336)  Acc@5: 100.0000 (98.9796)  time: 0.3513  data: 0.0025  max mem: 2503
Train: Epoch[4/5]  [1920/3750]  eta: 0:12:53  Lr: 0.001875  Loss: -0.1988  Acc@1: 81.2500 (81.2207)  Acc@5: 100.0000 (98.9719)  time: 0.3480  data: 0.0016  max mem: 2503
Train: Epoch[4/5]  [1930/3750]  eta: 0:12:49  Lr: 0.001875  Loss: -0.7873  Acc@1: 81.2500 (81.2176)  Acc@5: 100.0000 (98.9675)  time: 0.3999  data: 0.0019  max mem: 2503
Train: Epoch[4/5]  [1940/3750]  eta: 0:12:47  Lr: 0.001875  Loss: -0.5772  Acc@1: 81.2500 (81.2242)  Acc@5: 100.0000 (98.9728)  time: 0.5646  data: 0.0012  max mem: 2503
Train: Epoch[4/5]  [1950/3750]  eta: 0:12:46  Lr: 0.001875  Loss: -0.1448  Acc@1: 81.2500 (81.2372)  Acc@5: 100.0000 (98.9749)  time: 0.6816  data: 0.0015  max mem: 2503
Train: Epoch[4/5]  [1960/3750]  eta: 0:12:43  Lr: 0.001875  Loss: -0.7611  Acc@1: 81.2500 (81.2436)  Acc@5: 100.0000 (98.9769)  time: 0.6682  data: 0.0013  max mem: 2503
Train: Epoch[4/5]  [1970/3750]  eta: 0:12:41  Lr: 0.001875  Loss: -0.1420  Acc@1: 75.0000 (81.2024)  Acc@5: 100.0000 (98.9821)  time: 0.6678  data: 0.0006  max mem: 2503
Train: Epoch[4/5]  [1980/3750]  eta: 0:12:39  Lr: 0.001875  Loss: -0.4939  Acc@1: 75.0000 (81.2185)  Acc@5: 100.0000 (98.9841)  time: 0.6849  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [1990/3750]  eta: 0:12:37  Lr: 0.001875  Loss: -0.1742  Acc@1: 87.5000 (81.2343)  Acc@5: 100.0000 (98.9892)  time: 0.6805  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [2000/3750]  eta: 0:12:35  Lr: 0.001875  Loss: -0.6598  Acc@1: 81.2500 (81.2344)  Acc@5: 100.0000 (98.9911)  time: 0.6806  data: 0.0006  max mem: 2503
Train: Epoch[4/5]  [2010/3750]  eta: 0:12:33  Lr: 0.001875  Loss: -0.7018  Acc@1: 81.2500 (81.2189)  Acc@5: 100.0000 (98.9899)  time: 0.6737  data: 0.0014  max mem: 2503
Train: Epoch[4/5]  [2020/3750]  eta: 0:12:31  Lr: 0.001875  Loss: -0.5458  Acc@1: 81.2500 (81.2191)  Acc@5: 100.0000 (98.9918)  time: 0.6734  data: 0.0018  max mem: 2503
Train: Epoch[4/5]  [2030/3750]  eta: 0:12:28  Lr: 0.001875  Loss: -0.6491  Acc@1: 87.5000 (81.2377)  Acc@5: 100.0000 (98.9937)  time: 0.6805  data: 0.0010  max mem: 2503
Train: Epoch[4/5]  [2040/3750]  eta: 0:12:26  Lr: 0.001875  Loss: -0.5676  Acc@1: 81.2500 (81.2439)  Acc@5: 100.0000 (98.9895)  time: 0.6796  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [2050/3750]  eta: 0:12:24  Lr: 0.001875  Loss: -0.7512  Acc@1: 81.2500 (81.2104)  Acc@5: 100.0000 (98.9913)  time: 0.6807  data: 0.0012  max mem: 2503
Train: Epoch[4/5]  [2060/3750]  eta: 0:12:21  Lr: 0.001875  Loss: -0.2582  Acc@1: 81.2500 (81.2197)  Acc@5: 100.0000 (98.9962)  time: 0.6723  data: 0.0013  max mem: 2503
Train: Epoch[4/5]  [2070/3750]  eta: 0:12:18  Lr: 0.001875  Loss: -0.5788  Acc@1: 81.2500 (81.2138)  Acc@5: 100.0000 (98.9981)  time: 0.6416  data: 0.0016  max mem: 2503
Train: Epoch[4/5]  [2080/3750]  eta: 0:12:16  Lr: 0.001875  Loss: -0.3493  Acc@1: 81.2500 (81.2080)  Acc@5: 100.0000 (98.9969)  time: 0.6555  data: 0.0019  max mem: 2503
Train: Epoch[4/5]  [2090/3750]  eta: 0:12:14  Lr: 0.001875  Loss: -0.7527  Acc@1: 75.0000 (81.1962)  Acc@5: 100.0000 (98.9927)  time: 0.6923  data: 0.0009  max mem: 2503
Train: Epoch[4/5]  [2100/3750]  eta: 0:12:11  Lr: 0.001875  Loss: -0.4192  Acc@1: 75.0000 (81.1965)  Acc@5: 100.0000 (98.9886)  time: 0.6926  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [2110/3750]  eta: 0:12:09  Lr: 0.001875  Loss: -1.0830  Acc@1: 81.2500 (81.1997)  Acc@5: 100.0000 (98.9904)  time: 0.6924  data: 0.0007  max mem: 2503
Train: Epoch[4/5]  [2120/3750]  eta: 0:12:06  Lr: 0.001875  Loss: -0.5268  Acc@1: 81.2500 (81.1999)  Acc@5: 100.0000 (98.9922)  time: 0.6582  data: 0.0011  max mem: 2503
Train: Epoch[4/5]  [2130/3750]  eta: 0:12:03  Lr: 0.001875  Loss: -0.3438  Acc@1: 81.2500 (81.1943)  Acc@5: 100.0000 (98.9823)  time: 0.6297  data: 0.0016  max mem: 2503
Train: Epoch[4/5]  [2140/3750]  eta: 0:12:00  Lr: 0.001875  Loss: -0.3469  Acc@1: 81.2500 (81.1916)  Acc@5: 100.0000 (98.9841)  time: 0.6605  data: 0.0012  max mem: 2503
Train: Epoch[4/5]  [2150/3750]  eta: 0:11:57  Lr: 0.001875  Loss: -0.6003  Acc@1: 81.2500 (81.1977)  Acc@5: 100.0000 (98.9888)  time: 0.6813  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [2160/3750]  eta: 0:11:54  Lr: 0.001875  Loss: -0.3091  Acc@1: 75.0000 (81.1632)  Acc@5: 100.0000 (98.9935)  time: 0.6832  data: 0.0006  max mem: 2503
Train: Epoch[4/5]  [2170/3750]  eta: 0:11:52  Lr: 0.001875  Loss: -0.4445  Acc@1: 75.0000 (81.1694)  Acc@5: 100.0000 (98.9924)  time: 0.6934  data: 0.0007  max mem: 2503
Train: Epoch[4/5]  [2180/3750]  eta: 0:11:49  Lr: 0.001875  Loss: -0.8997  Acc@1: 81.2500 (81.1612)  Acc@5: 100.0000 (98.9942)  time: 0.6731  data: 0.0015  max mem: 2503
Train: Epoch[4/5]  [2190/3750]  eta: 0:11:46  Lr: 0.001875  Loss: -0.8225  Acc@1: 75.0000 (81.1673)  Acc@5: 100.0000 (98.9930)  time: 0.6686  data: 0.0015  max mem: 2503
Train: Epoch[4/5]  [2200/3750]  eta: 0:11:43  Lr: 0.001875  Loss: -0.2059  Acc@1: 81.2500 (81.1648)  Acc@5: 100.0000 (98.9919)  time: 0.6763  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [2210/3750]  eta: 0:11:40  Lr: 0.001875  Loss: -0.8374  Acc@1: 81.2500 (81.1963)  Acc@5: 100.0000 (98.9965)  time: 0.6670  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [2220/3750]  eta: 0:11:37  Lr: 0.001875  Loss: 0.0044  Acc@1: 87.5000 (81.1937)  Acc@5: 100.0000 (98.9982)  time: 0.6800  data: 0.0006  max mem: 2503
Train: Epoch[4/5]  [2230/3750]  eta: 0:11:34  Lr: 0.001875  Loss: -0.5288  Acc@1: 81.2500 (81.2024)  Acc@5: 100.0000 (99.0027)  time: 0.6699  data: 0.0006  max mem: 2503
Train: Epoch[4/5]  [2240/3750]  eta: 0:11:30  Lr: 0.001875  Loss: -0.4887  Acc@1: 81.2500 (81.1859)  Acc@5: 100.0000 (99.0044)  time: 0.6598  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [2250/3750]  eta: 0:11:27  Lr: 0.001875  Loss: -0.3611  Acc@1: 81.2500 (81.1945)  Acc@5: 100.0000 (99.0032)  time: 0.6840  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [2260/3750]  eta: 0:11:24  Lr: 0.001875  Loss: -0.5757  Acc@1: 87.5000 (81.2030)  Acc@5: 100.0000 (99.0076)  time: 0.6856  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [2270/3750]  eta: 0:11:21  Lr: 0.001875  Loss: -0.6531  Acc@1: 81.2500 (81.2005)  Acc@5: 100.0000 (99.0037)  time: 0.6832  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [2280/3750]  eta: 0:11:18  Lr: 0.001875  Loss: -0.4587  Acc@1: 81.2500 (81.2089)  Acc@5: 100.0000 (99.0026)  time: 0.6600  data: 0.0013  max mem: 2503
Train: Epoch[4/5]  [2290/3750]  eta: 0:11:12  Lr: 0.001875  Loss: -0.7797  Acc@1: 81.2500 (81.2091)  Acc@5: 100.0000 (98.9988)  time: 0.4887  data: 0.0013  max mem: 2503
Train: Epoch[4/5]  [2300/3750]  eta: 0:11:07  Lr: 0.001875  Loss: -0.4626  Acc@1: 81.2500 (81.2174)  Acc@5: 100.0000 (99.0004)  time: 0.3469  data: 0.0006  max mem: 2503
Train: Epoch[4/5]  [2310/3750]  eta: 0:11:02  Lr: 0.001875  Loss: -0.4712  Acc@1: 81.2500 (81.2230)  Acc@5: 100.0000 (99.0021)  time: 0.3514  data: 0.0007  max mem: 2503
Train: Epoch[4/5]  [2320/3750]  eta: 0:10:57  Lr: 0.001875  Loss: -0.4740  Acc@1: 81.2500 (81.2285)  Acc@5: 100.0000 (99.0037)  time: 0.3604  data: 0.0013  max mem: 2503
Train: Epoch[4/5]  [2330/3750]  eta: 0:10:51  Lr: 0.001875  Loss: -0.5016  Acc@1: 81.2500 (81.2071)  Acc@5: 100.0000 (99.0079)  time: 0.3583  data: 0.0029  max mem: 2503
Train: Epoch[4/5]  [2340/3750]  eta: 0:10:46  Lr: 0.001875  Loss: -0.9085  Acc@1: 75.0000 (81.1806)  Acc@5: 100.0000 (98.9988)  time: 0.3542  data: 0.0024  max mem: 2503
Train: Epoch[4/5]  [2350/3750]  eta: 0:10:41  Lr: 0.001875  Loss: -0.7299  Acc@1: 81.2500 (81.1889)  Acc@5: 100.0000 (99.0031)  time: 0.3541  data: 0.0018  max mem: 2503
Train: Epoch[4/5]  [2360/3750]  eta: 0:10:36  Lr: 0.001875  Loss: -0.5679  Acc@1: 81.2500 (81.1865)  Acc@5: 100.0000 (99.0073)  time: 0.3557  data: 0.0026  max mem: 2503
Train: Epoch[4/5]  [2370/3750]  eta: 0:10:31  Lr: 0.001875  Loss: -0.2513  Acc@1: 75.0000 (81.1841)  Acc@5: 100.0000 (99.0115)  time: 0.3591  data: 0.0024  max mem: 2503
Train: Epoch[4/5]  [2380/3750]  eta: 0:10:25  Lr: 0.001875  Loss: -0.4508  Acc@1: 81.2500 (81.1844)  Acc@5: 100.0000 (99.0078)  time: 0.3565  data: 0.0023  max mem: 2503
Train: Epoch[4/5]  [2390/3750]  eta: 0:10:20  Lr: 0.001875  Loss: -0.4574  Acc@1: 81.2500 (81.1664)  Acc@5: 100.0000 (99.0067)  time: 0.3550  data: 0.0021  max mem: 2503
Train: Epoch[4/5]  [2400/3750]  eta: 0:10:15  Lr: 0.001875  Loss: -0.4948  Acc@1: 75.0000 (81.1459)  Acc@5: 100.0000 (99.0030)  time: 0.3562  data: 0.0022  max mem: 2503
Train: Epoch[4/5]  [2410/3750]  eta: 0:10:10  Lr: 0.001875  Loss: -0.6778  Acc@1: 75.0000 (81.1385)  Acc@5: 100.0000 (98.9968)  time: 0.3611  data: 0.0020  max mem: 2503
Train: Epoch[4/5]  [2420/3750]  eta: 0:10:05  Lr: 0.001875  Loss: -0.9573  Acc@1: 81.2500 (81.1493)  Acc@5: 100.0000 (98.9983)  time: 0.3680  data: 0.0023  max mem: 2503
Train: Epoch[4/5]  [2430/3750]  eta: 0:10:00  Lr: 0.001875  Loss: -0.5675  Acc@1: 81.2500 (81.1523)  Acc@5: 100.0000 (98.9999)  time: 0.3642  data: 0.0038  max mem: 2503
Train: Epoch[4/5]  [2440/3750]  eta: 0:09:55  Lr: 0.001875  Loss: -0.5900  Acc@1: 81.2500 (81.1553)  Acc@5: 100.0000 (99.0040)  time: 0.3581  data: 0.0035  max mem: 2503
Train: Epoch[4/5]  [2450/3750]  eta: 0:09:50  Lr: 0.001875  Loss: 0.2375  Acc@1: 81.2500 (81.1531)  Acc@5: 100.0000 (99.0004)  time: 0.3559  data: 0.0032  max mem: 2503
Train: Epoch[4/5]  [2460/3750]  eta: 0:09:45  Lr: 0.001875  Loss: -0.0572  Acc@1: 81.2500 (81.1586)  Acc@5: 100.0000 (98.9969)  time: 0.3523  data: 0.0027  max mem: 2503
Train: Epoch[4/5]  [2470/3750]  eta: 0:09:40  Lr: 0.001875  Loss: -0.9695  Acc@1: 81.2500 (81.1817)  Acc@5: 100.0000 (98.9984)  time: 0.3563  data: 0.0011  max mem: 2503
Train: Epoch[4/5]  [2480/3750]  eta: 0:09:35  Lr: 0.001875  Loss: -0.2515  Acc@1: 81.2500 (81.1593)  Acc@5: 100.0000 (99.0024)  time: 0.3585  data: 0.0012  max mem: 2503
Train: Epoch[4/5]  [2490/3750]  eta: 0:09:30  Lr: 0.001875  Loss: -0.5661  Acc@1: 75.0000 (81.1421)  Acc@5: 100.0000 (99.0014)  time: 0.3557  data: 0.0019  max mem: 2503
Train: Epoch[4/5]  [2500/3750]  eta: 0:09:25  Lr: 0.001875  Loss: -0.6265  Acc@1: 81.2500 (81.1500)  Acc@5: 100.0000 (99.0054)  time: 0.3555  data: 0.0016  max mem: 2503
Train: Epoch[4/5]  [2510/3750]  eta: 0:09:20  Lr: 0.001875  Loss: -0.5514  Acc@1: 87.5000 (81.1679)  Acc@5: 100.0000 (99.0094)  time: 0.3567  data: 0.0027  max mem: 2503
Train: Epoch[4/5]  [2520/3750]  eta: 0:09:15  Lr: 0.001875  Loss: 0.0088  Acc@1: 81.2500 (81.1583)  Acc@5: 100.0000 (99.0059)  time: 0.3658  data: 0.0051  max mem: 2503
Train: Epoch[4/5]  [2530/3750]  eta: 0:09:10  Lr: 0.001875  Loss: -0.1301  Acc@1: 75.0000 (81.1463)  Acc@5: 100.0000 (99.0098)  time: 0.3700  data: 0.0049  max mem: 2503
Train: Epoch[4/5]  [2540/3750]  eta: 0:09:05  Lr: 0.001875  Loss: -0.7598  Acc@1: 75.0000 (81.1393)  Acc@5: 100.0000 (99.0137)  time: 0.3617  data: 0.0031  max mem: 2503
Train: Epoch[4/5]  [2550/3750]  eta: 0:09:00  Lr: 0.001875  Loss: -0.5243  Acc@1: 81.2500 (81.1422)  Acc@5: 100.0000 (99.0151)  time: 0.3612  data: 0.0030  max mem: 2503
Train: Epoch[4/5]  [2560/3750]  eta: 0:08:55  Lr: 0.001875  Loss: -0.6123  Acc@1: 81.2500 (81.1353)  Acc@5: 100.0000 (99.0189)  time: 0.3640  data: 0.0030  max mem: 2503
Train: Epoch[4/5]  [2570/3750]  eta: 0:08:50  Lr: 0.001875  Loss: -0.1989  Acc@1: 81.2500 (81.1212)  Acc@5: 100.0000 (99.0228)  time: 0.3591  data: 0.0030  max mem: 2503
Train: Epoch[4/5]  [2580/3750]  eta: 0:08:45  Lr: 0.001875  Loss: -0.4219  Acc@1: 81.2500 (81.1265)  Acc@5: 100.0000 (99.0265)  time: 0.3545  data: 0.0031  max mem: 2503
Train: Epoch[4/5]  [2590/3750]  eta: 0:08:40  Lr: 0.001875  Loss: -0.4223  Acc@1: 87.5000 (81.1366)  Acc@5: 100.0000 (99.0303)  time: 0.3548  data: 0.0031  max mem: 2503
Train: Epoch[4/5]  [2600/3750]  eta: 0:08:35  Lr: 0.001875  Loss: -0.7587  Acc@1: 81.2500 (81.1299)  Acc@5: 100.0000 (99.0316)  time: 0.3660  data: 0.0055  max mem: 2503
Train: Epoch[4/5]  [2610/3750]  eta: 0:08:31  Lr: 0.001875  Loss: -0.8009  Acc@1: 81.2500 (81.1112)  Acc@5: 100.0000 (99.0353)  time: 0.3683  data: 0.0064  max mem: 2503
Train: Epoch[4/5]  [2620/3750]  eta: 0:08:26  Lr: 0.001875  Loss: -0.5281  Acc@1: 81.2500 (81.1117)  Acc@5: 100.0000 (99.0366)  time: 0.3580  data: 0.0033  max mem: 2503
Train: Epoch[4/5]  [2630/3750]  eta: 0:08:21  Lr: 0.001875  Loss: -0.6031  Acc@1: 81.2500 (81.1146)  Acc@5: 100.0000 (99.0403)  time: 0.3537  data: 0.0021  max mem: 2503
Train: Epoch[4/5]  [2640/3750]  eta: 0:08:16  Lr: 0.001875  Loss: -0.4924  Acc@1: 81.2500 (81.1080)  Acc@5: 100.0000 (99.0416)  time: 0.3569  data: 0.0027  max mem: 2503
Train: Epoch[4/5]  [2650/3750]  eta: 0:08:11  Lr: 0.001875  Loss: -0.4829  Acc@1: 81.2500 (81.1062)  Acc@5: 100.0000 (99.0428)  time: 0.3569  data: 0.0022  max mem: 2503
Train: Epoch[4/5]  [2660/3750]  eta: 0:08:06  Lr: 0.001875  Loss: -0.6842  Acc@1: 81.2500 (81.1138)  Acc@5: 100.0000 (99.0464)  time: 0.3580  data: 0.0026  max mem: 2503
Train: Epoch[4/5]  [2670/3750]  eta: 0:08:01  Lr: 0.001875  Loss: -0.0397  Acc@1: 81.2500 (81.1073)  Acc@5: 100.0000 (99.0430)  time: 0.3612  data: 0.0037  max mem: 2503
Train: Epoch[4/5]  [2680/3750]  eta: 0:07:57  Lr: 0.001875  Loss: -0.8408  Acc@1: 81.2500 (81.1264)  Acc@5: 100.0000 (99.0395)  time: 0.3621  data: 0.0041  max mem: 2503
Train: Epoch[4/5]  [2690/3750]  eta: 0:07:52  Lr: 0.001875  Loss: -0.4119  Acc@1: 81.2500 (81.1223)  Acc@5: 100.0000 (99.0361)  time: 0.3688  data: 0.0051  max mem: 2503
Train: Epoch[4/5]  [2700/3750]  eta: 0:07:47  Lr: 0.001875  Loss: -0.5128  Acc@1: 81.2500 (81.1135)  Acc@5: 100.0000 (99.0328)  time: 0.3647  data: 0.0051  max mem: 2503
Train: Epoch[4/5]  [2710/3750]  eta: 0:07:42  Lr: 0.001875  Loss: -0.1534  Acc@1: 81.2500 (81.1140)  Acc@5: 100.0000 (99.0363)  time: 0.3560  data: 0.0040  max mem: 2503
Train: Epoch[4/5]  [2720/3750]  eta: 0:07:38  Lr: 0.001875  Loss: -0.7288  Acc@1: 81.2500 (81.1214)  Acc@5: 100.0000 (99.0376)  time: 0.3553  data: 0.0040  max mem: 2503
Train: Epoch[4/5]  [2730/3750]  eta: 0:07:33  Lr: 0.001875  Loss: -0.8121  Acc@1: 81.2500 (81.1173)  Acc@5: 100.0000 (99.0319)  time: 0.3585  data: 0.0027  max mem: 2503
Train: Epoch[4/5]  [2740/3750]  eta: 0:07:28  Lr: 0.001875  Loss: -0.9370  Acc@1: 81.2500 (81.1383)  Acc@5: 100.0000 (99.0355)  time: 0.3583  data: 0.0015  max mem: 2503
Train: Epoch[4/5]  [2750/3750]  eta: 0:07:23  Lr: 0.001875  Loss: -0.3032  Acc@1: 87.5000 (81.1478)  Acc@5: 100.0000 (99.0344)  time: 0.3556  data: 0.0021  max mem: 2503
Train: Epoch[4/5]  [2760/3750]  eta: 0:07:19  Lr: 0.001875  Loss: -0.6327  Acc@1: 87.5000 (81.1391)  Acc@5: 100.0000 (99.0289)  time: 0.3564  data: 0.0023  max mem: 2503
Train: Epoch[4/5]  [2770/3750]  eta: 0:07:14  Lr: 0.001875  Loss: -0.6835  Acc@1: 81.2500 (81.1417)  Acc@5: 100.0000 (99.0279)  time: 0.3553  data: 0.0014  max mem: 2503
Train: Epoch[4/5]  [2780/3750]  eta: 0:07:09  Lr: 0.001875  Loss: -0.6889  Acc@1: 81.2500 (81.1421)  Acc@5: 100.0000 (99.0291)  time: 0.3559  data: 0.0034  max mem: 2503
Train: Epoch[4/5]  [2790/3750]  eta: 0:07:04  Lr: 0.001875  Loss: -0.4168  Acc@1: 81.2500 (81.1313)  Acc@5: 100.0000 (99.0259)  time: 0.3541  data: 0.0034  max mem: 2503
Train: Epoch[4/5]  [2800/3750]  eta: 0:07:00  Lr: 0.001875  Loss: -0.4453  Acc@1: 75.0000 (81.1273)  Acc@5: 100.0000 (99.0294)  time: 0.3536  data: 0.0018  max mem: 2503
Train: Epoch[4/5]  [2810/3750]  eta: 0:06:55  Lr: 0.001875  Loss: -0.5258  Acc@1: 81.2500 (81.1255)  Acc@5: 100.0000 (99.0261)  time: 0.3537  data: 0.0026  max mem: 2503
Train: Epoch[4/5]  [2820/3750]  eta: 0:06:50  Lr: 0.001875  Loss: -0.5563  Acc@1: 81.2500 (81.1304)  Acc@5: 100.0000 (99.0296)  time: 0.3523  data: 0.0020  max mem: 2503
Train: Epoch[4/5]  [2830/3750]  eta: 0:06:45  Lr: 0.001875  Loss: -0.5408  Acc@1: 81.2500 (81.1286)  Acc@5: 100.0000 (99.0286)  time: 0.3579  data: 0.0041  max mem: 2503
Train: Epoch[4/5]  [2840/3750]  eta: 0:06:41  Lr: 0.001875  Loss: -0.4449  Acc@1: 81.2500 (81.1114)  Acc@5: 100.0000 (99.0298)  time: 0.3584  data: 0.0040  max mem: 2503
Train: Epoch[4/5]  [2850/3750]  eta: 0:06:36  Lr: 0.001875  Loss: -0.6494  Acc@1: 81.2500 (81.1229)  Acc@5: 100.0000 (99.0310)  time: 0.3578  data: 0.0011  max mem: 2503
Train: Epoch[4/5]  [2860/3750]  eta: 0:06:31  Lr: 0.001875  Loss: -0.4076  Acc@1: 81.2500 (81.1233)  Acc@5: 100.0000 (99.0279)  time: 0.3591  data: 0.0012  max mem: 2503
Train: Epoch[4/5]  [2870/3750]  eta: 0:06:27  Lr: 0.001875  Loss: -0.5320  Acc@1: 81.2500 (81.1194)  Acc@5: 100.0000 (99.0269)  time: 0.3565  data: 0.0013  max mem: 2503
Train: Epoch[4/5]  [2880/3750]  eta: 0:06:22  Lr: 0.001875  Loss: -0.5881  Acc@1: 87.5000 (81.1307)  Acc@5: 100.0000 (99.0281)  time: 0.3556  data: 0.0025  max mem: 2503
Train: Epoch[4/5]  [2890/3750]  eta: 0:06:17  Lr: 0.001875  Loss: -0.5731  Acc@1: 81.2500 (81.1311)  Acc@5: 100.0000 (99.0293)  time: 0.3553  data: 0.0031  max mem: 2503
Train: Epoch[4/5]  [2900/3750]  eta: 0:06:13  Lr: 0.001875  Loss: -0.6199  Acc@1: 81.2500 (81.1337)  Acc@5: 100.0000 (99.0284)  time: 0.3561  data: 0.0018  max mem: 2503
Train: Epoch[4/5]  [2910/3750]  eta: 0:06:08  Lr: 0.001875  Loss: -0.5681  Acc@1: 81.2500 (81.1319)  Acc@5: 100.0000 (99.0317)  time: 0.3619  data: 0.0015  max mem: 2503
Train: Epoch[4/5]  [2920/3750]  eta: 0:06:04  Lr: 0.001875  Loss: -0.1085  Acc@1: 75.0000 (81.1173)  Acc@5: 100.0000 (99.0286)  time: 0.3604  data: 0.0020  max mem: 2503
Train: Epoch[4/5]  [2930/3750]  eta: 0:05:59  Lr: 0.001875  Loss: -0.2760  Acc@1: 75.0000 (81.1093)  Acc@5: 100.0000 (99.0255)  time: 0.3615  data: 0.0048  max mem: 2503
Train: Epoch[4/5]  [2940/3750]  eta: 0:05:54  Lr: 0.001875  Loss: -0.5703  Acc@1: 81.2500 (81.1204)  Acc@5: 100.0000 (99.0267)  time: 0.3596  data: 0.0046  max mem: 2503
Train: Epoch[4/5]  [2950/3750]  eta: 0:05:50  Lr: 0.001875  Loss: -0.4027  Acc@1: 81.2500 (81.1039)  Acc@5: 100.0000 (99.0279)  time: 0.3508  data: 0.0016  max mem: 2503
Train: Epoch[4/5]  [2960/3750]  eta: 0:05:45  Lr: 0.001875  Loss: -0.5186  Acc@1: 81.2500 (81.1044)  Acc@5: 100.0000 (99.0290)  time: 0.3520  data: 0.0015  max mem: 2503
Train: Epoch[4/5]  [2970/3750]  eta: 0:05:41  Lr: 0.001875  Loss: -0.6530  Acc@1: 81.2500 (81.1133)  Acc@5: 100.0000 (99.0323)  time: 0.3523  data: 0.0022  max mem: 2503
Train: Epoch[4/5]  [2980/3750]  eta: 0:05:36  Lr: 0.001875  Loss: -0.8064  Acc@1: 87.5000 (81.1179)  Acc@5: 100.0000 (99.0314)  time: 0.3656  data: 0.0024  max mem: 2503
Train: Epoch[4/5]  [2990/3750]  eta: 0:05:31  Lr: 0.001875  Loss: -0.2821  Acc@1: 81.2500 (81.1142)  Acc@5: 100.0000 (99.0346)  time: 0.3684  data: 0.0029  max mem: 2503
Train: Epoch[4/5]  [3000/3750]  eta: 0:05:27  Lr: 0.001875  Loss: -0.6516  Acc@1: 75.0000 (81.1105)  Acc@5: 100.0000 (99.0295)  time: 0.3578  data: 0.0029  max mem: 2503
Train: Epoch[4/5]  [3010/3750]  eta: 0:05:22  Lr: 0.001875  Loss: -0.5593  Acc@1: 81.2500 (81.1172)  Acc@5: 100.0000 (99.0306)  time: 0.3547  data: 0.0030  max mem: 2503
Train: Epoch[4/5]  [3020/3750]  eta: 0:05:18  Lr: 0.001875  Loss: -0.7246  Acc@1: 81.2500 (81.0969)  Acc@5: 100.0000 (99.0318)  time: 0.3547  data: 0.0037  max mem: 2503
Train: Epoch[4/5]  [3030/3750]  eta: 0:05:13  Lr: 0.001875  Loss: -0.8426  Acc@1: 81.2500 (81.0850)  Acc@5: 100.0000 (99.0329)  time: 0.3589  data: 0.0044  max mem: 2503
Train: Epoch[4/5]  [3040/3750]  eta: 0:05:09  Lr: 0.001875  Loss: -0.8133  Acc@1: 81.2500 (81.0774)  Acc@5: 100.0000 (99.0361)  time: 0.3566  data: 0.0038  max mem: 2503
Train: Epoch[4/5]  [3050/3750]  eta: 0:05:04  Lr: 0.001875  Loss: -0.5310  Acc@1: 81.2500 (81.0820)  Acc@5: 100.0000 (99.0331)  time: 0.3521  data: 0.0020  max mem: 2503
Train: Epoch[4/5]  [3060/3750]  eta: 0:05:00  Lr: 0.001875  Loss: -0.8551  Acc@1: 81.2500 (81.0907)  Acc@5: 100.0000 (99.0363)  time: 0.3572  data: 0.0014  max mem: 2503
Train: Epoch[4/5]  [3070/3750]  eta: 0:04:55  Lr: 0.001875  Loss: -0.5205  Acc@1: 81.2500 (81.0790)  Acc@5: 100.0000 (99.0374)  time: 0.3610  data: 0.0010  max mem: 2503
Train: Epoch[4/5]  [3080/3750]  eta: 0:04:51  Lr: 0.001875  Loss: -0.3596  Acc@1: 75.0000 (81.0715)  Acc@5: 100.0000 (99.0324)  time: 0.3594  data: 0.0013  max mem: 2503
Train: Epoch[4/5]  [3090/3750]  eta: 0:04:46  Lr: 0.001875  Loss: -0.3845  Acc@1: 81.2500 (81.0781)  Acc@5: 100.0000 (99.0355)  time: 0.3564  data: 0.0017  max mem: 2503
Train: Epoch[4/5]  [3100/3750]  eta: 0:04:42  Lr: 0.001875  Loss: -0.4973  Acc@1: 81.2500 (81.0847)  Acc@5: 100.0000 (99.0386)  time: 0.3519  data: 0.0012  max mem: 2503
Train: Epoch[4/5]  [3110/3750]  eta: 0:04:37  Lr: 0.001875  Loss: -0.7205  Acc@1: 81.2500 (81.1013)  Acc@5: 100.0000 (99.0397)  time: 0.3561  data: 0.0026  max mem: 2503
Train: Epoch[4/5]  [3120/3750]  eta: 0:04:33  Lr: 0.001875  Loss: -0.2646  Acc@1: 87.5000 (81.1018)  Acc@5: 100.0000 (99.0388)  time: 0.3623  data: 0.0037  max mem: 2503
Train: Epoch[4/5]  [3130/3750]  eta: 0:04:28  Lr: 0.001875  Loss: -1.0212  Acc@1: 87.5000 (81.1183)  Acc@5: 100.0000 (99.0378)  time: 0.3636  data: 0.0042  max mem: 2503
Train: Epoch[4/5]  [3140/3750]  eta: 0:04:24  Lr: 0.001875  Loss: -0.7762  Acc@1: 87.5000 (81.1266)  Acc@5: 100.0000 (99.0389)  time: 0.3582  data: 0.0036  max mem: 2503
Train: Epoch[4/5]  [3150/3750]  eta: 0:04:19  Lr: 0.001875  Loss: -0.6556  Acc@1: 81.2500 (81.1072)  Acc@5: 100.0000 (99.0420)  time: 0.3570  data: 0.0015  max mem: 2503
Train: Epoch[4/5]  [3160/3750]  eta: 0:04:15  Lr: 0.001875  Loss: -0.2041  Acc@1: 81.2500 (81.1076)  Acc@5: 100.0000 (99.0410)  time: 0.3569  data: 0.0012  max mem: 2503
Train: Epoch[4/5]  [3170/3750]  eta: 0:04:10  Lr: 0.001875  Loss: -0.0019  Acc@1: 81.2500 (81.1081)  Acc@5: 100.0000 (99.0382)  time: 0.3534  data: 0.0015  max mem: 2503
Train: Epoch[4/5]  [3180/3750]  eta: 0:04:06  Lr: 0.001875  Loss: -0.6422  Acc@1: 81.2500 (81.1105)  Acc@5: 100.0000 (99.0373)  time: 0.3549  data: 0.0017  max mem: 2503
Train: Epoch[4/5]  [3190/3750]  eta: 0:04:01  Lr: 0.001875  Loss: -0.3214  Acc@1: 87.5000 (81.1149)  Acc@5: 100.0000 (99.0403)  time: 0.3578  data: 0.0014  max mem: 2503
Train: Epoch[4/5]  [3200/3750]  eta: 0:03:57  Lr: 0.001875  Loss: -0.7409  Acc@1: 87.5000 (81.1231)  Acc@5: 100.0000 (99.0394)  time: 0.3555  data: 0.0016  max mem: 2503
Train: Epoch[4/5]  [3210/3750]  eta: 0:03:52  Lr: 0.001875  Loss: -0.7061  Acc@1: 81.2500 (81.1215)  Acc@5: 100.0000 (99.0385)  time: 0.3496  data: 0.0014  max mem: 2503
Train: Epoch[4/5]  [3220/3750]  eta: 0:03:48  Lr: 0.001875  Loss: -0.3279  Acc@1: 81.2500 (81.1161)  Acc@5: 100.0000 (99.0395)  time: 0.3524  data: 0.0018  max mem: 2503
Train: Epoch[4/5]  [3230/3750]  eta: 0:03:44  Lr: 0.001875  Loss: -0.4530  Acc@1: 75.0000 (81.1127)  Acc@5: 100.0000 (99.0405)  time: 0.3576  data: 0.0023  max mem: 2503
Train: Epoch[4/5]  [3240/3750]  eta: 0:03:39  Lr: 0.001875  Loss: -0.5299  Acc@1: 81.2500 (81.1131)  Acc@5: 100.0000 (99.0416)  time: 0.3538  data: 0.0020  max mem: 2503
Train: Epoch[4/5]  [3250/3750]  eta: 0:03:35  Lr: 0.001875  Loss: -0.5083  Acc@1: 81.2500 (81.1250)  Acc@5: 100.0000 (99.0407)  time: 0.3520  data: 0.0020  max mem: 2503
Train: Epoch[4/5]  [3260/3750]  eta: 0:03:30  Lr: 0.001875  Loss: -0.9521  Acc@1: 81.2500 (81.1043)  Acc@5: 100.0000 (99.0436)  time: 0.3551  data: 0.0025  max mem: 2503
Train: Epoch[4/5]  [3270/3750]  eta: 0:03:26  Lr: 0.001875  Loss: -0.3608  Acc@1: 75.0000 (81.1048)  Acc@5: 100.0000 (99.0427)  time: 0.3515  data: 0.0018  max mem: 2503
Train: Epoch[4/5]  [3280/3750]  eta: 0:03:21  Lr: 0.001875  Loss: -0.4880  Acc@1: 81.2500 (81.0957)  Acc@5: 100.0000 (99.0456)  time: 0.3524  data: 0.0021  max mem: 2503
Train: Epoch[4/5]  [3290/3750]  eta: 0:03:17  Lr: 0.001875  Loss: -0.3548  Acc@1: 75.0000 (81.0753)  Acc@5: 100.0000 (99.0390)  time: 0.3573  data: 0.0030  max mem: 2503
Train: Epoch[4/5]  [3300/3750]  eta: 0:03:13  Lr: 0.001875  Loss: -0.6367  Acc@1: 75.0000 (81.0682)  Acc@5: 100.0000 (99.0382)  time: 0.3547  data: 0.0018  max mem: 2503
Train: Epoch[4/5]  [3310/3750]  eta: 0:03:08  Lr: 0.001875  Loss: -0.9379  Acc@1: 81.2500 (81.0763)  Acc@5: 100.0000 (99.0373)  time: 0.3540  data: 0.0028  max mem: 2503
Train: Epoch[4/5]  [3320/3750]  eta: 0:03:04  Lr: 0.001875  Loss: -0.5732  Acc@1: 81.2500 (81.0712)  Acc@5: 100.0000 (99.0364)  time: 0.3528  data: 0.0027  max mem: 2503
Train: Epoch[4/5]  [3330/3750]  eta: 0:02:59  Lr: 0.001875  Loss: -0.6452  Acc@1: 81.2500 (81.0849)  Acc@5: 100.0000 (99.0375)  time: 0.3558  data: 0.0029  max mem: 2503
Train: Epoch[4/5]  [3340/3750]  eta: 0:02:55  Lr: 0.001875  Loss: -0.6818  Acc@1: 87.5000 (81.0910)  Acc@5: 100.0000 (99.0403)  time: 0.3605  data: 0.0036  max mem: 2503
Train: Epoch[4/5]  [3350/3750]  eta: 0:02:51  Lr: 0.001875  Loss: -0.1763  Acc@1: 81.2500 (81.0728)  Acc@5: 100.0000 (99.0432)  time: 0.3575  data: 0.0021  max mem: 2503
Train: Epoch[4/5]  [3360/3750]  eta: 0:02:46  Lr: 0.001875  Loss: -0.5059  Acc@1: 81.2500 (81.0826)  Acc@5: 100.0000 (99.0423)  time: 0.3569  data: 0.0020  max mem: 2503
Train: Epoch[4/5]  [3370/3750]  eta: 0:02:42  Lr: 0.001875  Loss: -0.6695  Acc@1: 81.2500 (81.0906)  Acc@5: 100.0000 (99.0452)  time: 0.3587  data: 0.0018  max mem: 2503
Train: Epoch[4/5]  [3380/3750]  eta: 0:02:38  Lr: 0.001875  Loss: -0.6551  Acc@1: 81.2500 (81.0984)  Acc@5: 100.0000 (99.0443)  time: 0.3584  data: 0.0025  max mem: 2503
Train: Epoch[4/5]  [3390/3750]  eta: 0:02:33  Lr: 0.001875  Loss: -0.6713  Acc@1: 81.2500 (81.0933)  Acc@5: 100.0000 (99.0471)  time: 0.3614  data: 0.0040  max mem: 2503
Train: Epoch[4/5]  [3400/3750]  eta: 0:02:29  Lr: 0.001875  Loss: -0.2581  Acc@1: 81.2500 (81.0956)  Acc@5: 100.0000 (99.0499)  time: 0.3589  data: 0.0029  max mem: 2503
Train: Epoch[4/5]  [3410/3750]  eta: 0:02:25  Lr: 0.001875  Loss: -0.6925  Acc@1: 81.2500 (81.0869)  Acc@5: 100.0000 (99.0509)  time: 0.3547  data: 0.0035  max mem: 2503
Train: Epoch[4/5]  [3420/3750]  eta: 0:02:20  Lr: 0.001875  Loss: -0.1372  Acc@1: 75.0000 (81.0746)  Acc@5: 100.0000 (99.0482)  time: 0.3617  data: 0.0045  max mem: 2503
Train: Epoch[4/5]  [3430/3750]  eta: 0:02:16  Lr: 0.001875  Loss: -0.7876  Acc@1: 81.2500 (81.0897)  Acc@5: 100.0000 (99.0473)  time: 0.3637  data: 0.0062  max mem: 2503
Train: Epoch[4/5]  [3440/3750]  eta: 0:02:12  Lr: 0.001875  Loss: -0.8839  Acc@1: 81.2500 (81.1011)  Acc@5: 100.0000 (99.0446)  time: 0.3609  data: 0.0063  max mem: 2503
Train: Epoch[4/5]  [3450/3750]  eta: 0:02:07  Lr: 0.001875  Loss: -0.4705  Acc@1: 81.2500 (81.1051)  Acc@5: 100.0000 (99.0456)  time: 0.3576  data: 0.0037  max mem: 2503
Train: Epoch[4/5]  [3460/3750]  eta: 0:02:03  Lr: 0.001875  Loss: -0.7083  Acc@1: 81.2500 (81.1001)  Acc@5: 100.0000 (99.0483)  time: 0.3575  data: 0.0035  max mem: 2503
Train: Epoch[4/5]  [3470/3750]  eta: 0:01:59  Lr: 0.001875  Loss: -0.6631  Acc@1: 81.2500 (81.1059)  Acc@5: 100.0000 (99.0457)  time: 0.3583  data: 0.0039  max mem: 2503
Train: Epoch[4/5]  [3480/3750]  eta: 0:01:54  Lr: 0.001875  Loss: -0.5676  Acc@1: 87.5000 (81.1171)  Acc@5: 100.0000 (99.0484)  time: 0.3567  data: 0.0043  max mem: 2503
Train: Epoch[4/5]  [3490/3750]  eta: 0:01:50  Lr: 0.001875  Loss: -0.4859  Acc@1: 75.0000 (81.1014)  Acc@5: 100.0000 (99.0458)  time: 0.3622  data: 0.0028  max mem: 2503
Train: Epoch[4/5]  [3500/3750]  eta: 0:01:46  Lr: 0.001875  Loss: -0.8178  Acc@1: 75.0000 (81.0947)  Acc@5: 100.0000 (99.0449)  time: 0.3620  data: 0.0025  max mem: 2503
Train: Epoch[4/5]  [3510/3750]  eta: 0:01:41  Lr: 0.001875  Loss: -0.5274  Acc@1: 81.2500 (81.1005)  Acc@5: 100.0000 (99.0459)  time: 0.3548  data: 0.0036  max mem: 2503
Train: Epoch[4/5]  [3520/3750]  eta: 0:01:37  Lr: 0.001875  Loss: -0.6101  Acc@1: 81.2500 (81.0973)  Acc@5: 100.0000 (99.0486)  time: 0.3548  data: 0.0027  max mem: 2503
Train: Epoch[4/5]  [3530/3750]  eta: 0:01:33  Lr: 0.001875  Loss: -0.7650  Acc@1: 87.5000 (81.1155)  Acc@5: 100.0000 (99.0477)  time: 0.3560  data: 0.0033  max mem: 2503
Train: Epoch[4/5]  [3540/3750]  eta: 0:01:29  Lr: 0.001875  Loss: -0.4658  Acc@1: 81.2500 (81.1053)  Acc@5: 100.0000 (99.0433)  time: 0.3565  data: 0.0047  max mem: 2503
Train: Epoch[4/5]  [3550/3750]  eta: 0:01:24  Lr: 0.001875  Loss: -0.3268  Acc@1: 81.2500 (81.1110)  Acc@5: 100.0000 (99.0443)  time: 0.3586  data: 0.0028  max mem: 2503
Train: Epoch[4/5]  [3560/3750]  eta: 0:01:20  Lr: 0.001875  Loss: -0.6851  Acc@1: 81.2500 (81.1113)  Acc@5: 100.0000 (99.0452)  time: 0.3555  data: 0.0014  max mem: 2503
Train: Epoch[4/5]  [3570/3750]  eta: 0:01:16  Lr: 0.001875  Loss: -0.2084  Acc@1: 81.2500 (81.1082)  Acc@5: 100.0000 (99.0409)  time: 0.3597  data: 0.0024  max mem: 2503
Train: Epoch[4/5]  [3580/3750]  eta: 0:01:12  Lr: 0.001875  Loss: -0.6652  Acc@1: 81.2500 (81.1104)  Acc@5: 100.0000 (99.0418)  time: 0.3674  data: 0.0034  max mem: 2503
Train: Epoch[4/5]  [3590/3750]  eta: 0:01:07  Lr: 0.001875  Loss: -0.5469  Acc@1: 87.5000 (81.1247)  Acc@5: 100.0000 (99.0445)  time: 0.3599  data: 0.0024  max mem: 2503
Train: Epoch[4/5]  [3600/3750]  eta: 0:01:03  Lr: 0.001875  Loss: -0.8462  Acc@1: 87.5000 (81.1354)  Acc@5: 100.0000 (99.0454)  time: 0.3518  data: 0.0013  max mem: 2503
Train: Epoch[4/5]  [3610/3750]  eta: 0:00:59  Lr: 0.001875  Loss: -0.8536  Acc@1: 87.5000 (81.1479)  Acc@5: 100.0000 (99.0463)  time: 0.3517  data: 0.0010  max mem: 2503
Train: Epoch[4/5]  [3620/3750]  eta: 0:00:54  Lr: 0.001875  Loss: -0.8118  Acc@1: 87.5000 (81.1585)  Acc@5: 100.0000 (99.0472)  time: 0.3544  data: 0.0017  max mem: 2503
Train: Epoch[4/5]  [3630/3750]  eta: 0:00:50  Lr: 0.001875  Loss: -0.2018  Acc@1: 81.2500 (81.1588)  Acc@5: 100.0000 (99.0464)  time: 0.3564  data: 0.0021  max mem: 2503
Train: Epoch[4/5]  [3640/3750]  eta: 0:00:46  Lr: 0.001875  Loss: -0.7159  Acc@1: 81.2500 (81.1659)  Acc@5: 100.0000 (99.0473)  time: 0.3589  data: 0.0029  max mem: 2503
Train: Epoch[4/5]  [3650/3750]  eta: 0:00:42  Lr: 0.001875  Loss: -0.7456  Acc@1: 81.2500 (81.1627)  Acc@5: 100.0000 (99.0499)  time: 0.3573  data: 0.0029  max mem: 2503
Train: Epoch[4/5]  [3660/3750]  eta: 0:00:37  Lr: 0.001875  Loss: -0.9520  Acc@1: 81.2500 (81.1646)  Acc@5: 100.0000 (99.0508)  time: 0.3525  data: 0.0020  max mem: 2503
Train: Epoch[4/5]  [3670/3750]  eta: 0:00:33  Lr: 0.001875  Loss: -0.5462  Acc@1: 81.2500 (81.1564)  Acc@5: 100.0000 (99.0483)  time: 0.3558  data: 0.0022  max mem: 2503
Train: Epoch[4/5]  [3680/3750]  eta: 0:00:29  Lr: 0.001875  Loss: -0.2507  Acc@1: 75.0000 (81.1549)  Acc@5: 100.0000 (99.0509)  time: 0.3627  data: 0.0015  max mem: 2503
Train: Epoch[4/5]  [3690/3750]  eta: 0:00:25  Lr: 0.001875  Loss: -0.7447  Acc@1: 75.0000 (81.1416)  Acc@5: 100.0000 (99.0450)  time: 0.3659  data: 0.0019  max mem: 2503
Train: Epoch[4/5]  [3700/3750]  eta: 0:00:21  Lr: 0.001875  Loss: -0.3797  Acc@1: 81.2500 (81.1436)  Acc@5: 100.0000 (99.0425)  time: 0.3606  data: 0.0028  max mem: 2503
Train: Epoch[4/5]  [3710/3750]  eta: 0:00:16  Lr: 0.001875  Loss: -0.5010  Acc@1: 81.2500 (81.1489)  Acc@5: 100.0000 (99.0417)  time: 0.3581  data: 0.0029  max mem: 2503
Train: Epoch[4/5]  [3720/3750]  eta: 0:00:12  Lr: 0.001875  Loss: -0.6012  Acc@1: 87.5000 (81.1576)  Acc@5: 100.0000 (99.0443)  time: 0.3605  data: 0.0033  max mem: 2503
Train: Epoch[4/5]  [3730/3750]  eta: 0:00:08  Lr: 0.001875  Loss: -0.4769  Acc@1: 81.2500 (81.1595)  Acc@5: 100.0000 (99.0452)  time: 0.4914  data: 0.0022  max mem: 2503
Train: Epoch[4/5]  [3740/3750]  eta: 0:00:04  Lr: 0.001875  Loss: -0.5066  Acc@1: 81.2500 (81.1648)  Acc@5: 100.0000 (99.0460)  time: 0.6499  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [3749/3750]  eta: 0:00:00  Lr: 0.001875  Loss: -0.9093  Acc@1: 81.2500 (81.1650)  Acc@5: 100.0000 (99.0467)  time: 0.6785  data: 0.0018  max mem: 2503
Train: Epoch[4/5] Total time: 0:26:27 (0.4234 s / it)
{0: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 1: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 2: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 3: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 4: {0: 0, 1: 300000, 2: 0, 3: 352, 4: 0}, 5: {0: 0, 1: 300000, 2: 0, 3: 352, 4: 0}, 6: {0: 0, 1: 300000, 2: 0, 3: 352, 4: 0}, 7: {0: 0, 1: 300000, 2: 0, 3: 352, 4: 0}, 8: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 9: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 10: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 11: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 12: {0: 0, 1: 0, 2: 0, 3: 90968, 4: 0}, 13: {0: 0, 1: 0, 2: 0, 3: 90968, 4: 0}, 14: {0: 0, 1: 0, 2: 0, 3: 90968, 4: 0}, 15: {0: 0, 1: 0, 2: 0, 3: 90968, 4: 0}, 16: {0: 0, 1: 0, 2: 0, 3: 0, 4: 240000}, 17: {0: 0, 1: 0, 2: 0, 3: 0, 4: 240000}, 18: {0: 0, 1: 0, 2: 0, 3: 0, 4: 240000}, 19: {0: 0, 1: 0, 2: 0, 3: 0, 4: 240000}}
Averaged stats: Lr: 0.001875  Loss: -0.9093  Acc@1: 81.2500 (81.1650)  Acc@5: 100.0000 (99.0467)
Train: Epoch[5/5]  [   0/3750]  eta: 1:21:24  Lr: 0.001875  Loss: -0.7140  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (100.0000)  time: 1.3025  data: 0.5910  max mem: 2503
Train: Epoch[5/5]  [  10/3750]  eta: 0:46:35  Lr: 0.001875  Loss: -0.6502  Acc@1: 87.5000 (86.3636)  Acc@5: 100.0000 (99.4318)  time: 0.7474  data: 0.0542  max mem: 2503
Train: Epoch[5/5]  [  20/3750]  eta: 0:44:05  Lr: 0.001875  Loss: -0.2181  Acc@1: 87.5000 (83.6310)  Acc@5: 100.0000 (98.8095)  time: 0.6797  data: 0.0006  max mem: 2503
Train: Epoch[5/5]  [  30/3750]  eta: 0:43:42  Lr: 0.001875  Loss: -0.3702  Acc@1: 81.2500 (83.0645)  Acc@5: 100.0000 (99.1935)  time: 0.6817  data: 0.0011  max mem: 2503
Train: Epoch[5/5]  [  40/3750]  eta: 0:43:26  Lr: 0.001875  Loss: -0.4364  Acc@1: 81.2500 (81.8598)  Acc@5: 100.0000 (99.2378)  time: 0.6955  data: 0.0009  max mem: 2503
Train: Epoch[5/5]  [  50/3750]  eta: 0:43:11  Lr: 0.001875  Loss: -0.8729  Acc@1: 81.2500 (82.3529)  Acc@5: 100.0000 (99.3873)  time: 0.6936  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [  60/3750]  eta: 0:42:58  Lr: 0.001875  Loss: -0.1878  Acc@1: 87.5000 (82.1721)  Acc@5: 100.0000 (99.2828)  time: 0.6908  data: 0.0008  max mem: 2503
Train: Epoch[5/5]  [  70/3750]  eta: 0:42:47  Lr: 0.001875  Loss: -0.6063  Acc@1: 81.2500 (81.6021)  Acc@5: 100.0000 (99.0317)  time: 0.6909  data: 0.0008  max mem: 2503
Train: Epoch[5/5]  [  80/3750]  eta: 0:42:31  Lr: 0.001875  Loss: -0.6746  Acc@1: 81.2500 (81.9444)  Acc@5: 100.0000 (99.0741)  time: 0.6844  data: 0.0012  max mem: 2503
Train: Epoch[5/5]  [  90/3750]  eta: 0:42:12  Lr: 0.001875  Loss: -0.6625  Acc@1: 87.5000 (82.2802)  Acc@5: 100.0000 (99.1758)  time: 0.6714  data: 0.0013  max mem: 2503
Train: Epoch[5/5]  [ 100/3750]  eta: 0:42:05  Lr: 0.001875  Loss: -0.3833  Acc@1: 81.2500 (82.3639)  Acc@5: 100.0000 (99.0099)  time: 0.6790  data: 0.0006  max mem: 2503
Train: Epoch[5/5]  [ 110/3750]  eta: 0:41:57  Lr: 0.001875  Loss: -0.8322  Acc@1: 81.2500 (82.2072)  Acc@5: 100.0000 (98.9865)  time: 0.6904  data: 0.0006  max mem: 2503
Train: Epoch[5/5]  [ 120/3750]  eta: 0:41:46  Lr: 0.001875  Loss: -0.4646  Acc@1: 81.2500 (82.2314)  Acc@5: 100.0000 (98.9669)  time: 0.6837  data: 0.0007  max mem: 2503
Train: Epoch[5/5]  [ 130/3750]  eta: 0:41:34  Lr: 0.001875  Loss: -0.2679  Acc@1: 81.2500 (81.8702)  Acc@5: 100.0000 (99.0458)  time: 0.6750  data: 0.0007  max mem: 2503
Train: Epoch[5/5]  [ 140/3750]  eta: 0:41:22  Lr: 0.001875  Loss: -0.4318  Acc@1: 81.2500 (82.2695)  Acc@5: 100.0000 (99.0248)  time: 0.6696  data: 0.0007  max mem: 2503
Train: Epoch[5/5]  [ 150/3750]  eta: 0:41:15  Lr: 0.001875  Loss: -0.3958  Acc@1: 81.2500 (82.2434)  Acc@5: 100.0000 (99.0480)  time: 0.6773  data: 0.0007  max mem: 2503
Train: Epoch[5/5]  [ 160/3750]  eta: 0:41:07  Lr: 0.001875  Loss: -0.4299  Acc@1: 81.2500 (82.1429)  Acc@5: 100.0000 (99.0683)  time: 0.6846  data: 0.0007  max mem: 2503
Train: Epoch[5/5]  [ 170/3750]  eta: 0:41:00  Lr: 0.001875  Loss: -0.3702  Acc@1: 81.2500 (82.2734)  Acc@5: 100.0000 (99.0497)  time: 0.6860  data: 0.0006  max mem: 2503
Train: Epoch[5/5]  [ 180/3750]  eta: 0:40:54  Lr: 0.001875  Loss: -0.8314  Acc@1: 87.5000 (82.3895)  Acc@5: 100.0000 (99.0331)  time: 0.6905  data: 0.0006  max mem: 2503
Train: Epoch[5/5]  [ 190/3750]  eta: 0:40:42  Lr: 0.001875  Loss: -0.6525  Acc@1: 81.2500 (82.2644)  Acc@5: 100.0000 (99.0510)  time: 0.6738  data: 0.0006  max mem: 2503
Train: Epoch[5/5]  [ 200/3750]  eta: 0:40:33  Lr: 0.001875  Loss: -0.6315  Acc@1: 81.2500 (82.3072)  Acc@5: 100.0000 (99.0983)  time: 0.6663  data: 0.0006  max mem: 2503
Train: Epoch[5/5]  [ 210/3750]  eta: 0:40:26  Lr: 0.001875  Loss: -0.7197  Acc@1: 81.2500 (82.0201)  Acc@5: 100.0000 (99.1410)  time: 0.6805  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [ 220/3750]  eta: 0:40:20  Lr: 0.001875  Loss: -0.6680  Acc@1: 75.0000 (81.8722)  Acc@5: 100.0000 (99.1233)  time: 0.6865  data: 0.0006  max mem: 2503
Train: Epoch[5/5]  [ 230/3750]  eta: 0:40:11  Lr: 0.001875  Loss: -0.4327  Acc@1: 81.2500 (81.7370)  Acc@5: 100.0000 (99.1342)  time: 0.6813  data: 0.0007  max mem: 2503
Train: Epoch[5/5]  [ 240/3750]  eta: 0:39:59  Lr: 0.001875  Loss: -0.7149  Acc@1: 81.2500 (81.7168)  Acc@5: 100.0000 (99.1442)  time: 0.6615  data: 0.0016  max mem: 2503
Train: Epoch[5/5]  [ 250/3750]  eta: 0:39:52  Lr: 0.001875  Loss: -0.6639  Acc@1: 81.2500 (81.7978)  Acc@5: 100.0000 (99.1783)  time: 0.6664  data: 0.0015  max mem: 2503
Train: Epoch[5/5]  [ 260/3750]  eta: 0:39:45  Lr: 0.001875  Loss: -0.3304  Acc@1: 81.2500 (81.8487)  Acc@5: 100.0000 (99.1858)  time: 0.6813  data: 0.0006  max mem: 2503
Train: Epoch[5/5]  [ 270/3750]  eta: 0:39:39  Lr: 0.001875  Loss: -0.6399  Acc@1: 81.2500 (81.6651)  Acc@5: 100.0000 (99.1697)  time: 0.6872  data: 0.0006  max mem: 2503
Train: Epoch[5/5]  [ 280/3750]  eta: 0:39:32  Lr: 0.001875  Loss: -0.5456  Acc@1: 75.0000 (81.5169)  Acc@5: 100.0000 (99.1993)  time: 0.6867  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [ 290/3750]  eta: 0:39:22  Lr: 0.001875  Loss: -0.9168  Acc@1: 81.2500 (81.6581)  Acc@5: 100.0000 (99.2053)  time: 0.6689  data: 0.0019  max mem: 2503
Train: Epoch[5/5]  [ 300/3750]  eta: 0:39:16  Lr: 0.001875  Loss: -0.9021  Acc@1: 87.5000 (81.7691)  Acc@5: 100.0000 (99.1902)  time: 0.6726  data: 0.0021  max mem: 2503
Train: Epoch[5/5]  [ 310/3750]  eta: 0:39:07  Lr: 0.001875  Loss: -0.4448  Acc@1: 87.5000 (81.9534)  Acc@5: 100.0000 (99.1760)  time: 0.6756  data: 0.0009  max mem: 2503
Train: Epoch[5/5]  [ 320/3750]  eta: 0:38:45  Lr: 0.001875  Loss: -0.5294  Acc@1: 81.2500 (81.7757)  Acc@5: 100.0000 (99.1822)  time: 0.6035  data: 0.0008  max mem: 2503
Train: Epoch[5/5]  [ 330/3750]  eta: 0:38:16  Lr: 0.001875  Loss: -0.5557  Acc@1: 81.2500 (81.7221)  Acc@5: 100.0000 (99.1692)  time: 0.5040  data: 0.0006  max mem: 2503
Train: Epoch[5/5]  [ 340/3750]  eta: 0:38:11  Lr: 0.001875  Loss: -0.5091  Acc@1: 75.0000 (81.7082)  Acc@5: 100.0000 (99.1752)  time: 0.5781  data: 0.0013  max mem: 2503
Train: Epoch[5/5]  [ 350/3750]  eta: 0:37:48  Lr: 0.001875  Loss: -0.7624  Acc@1: 75.0000 (81.6595)  Acc@5: 100.0000 (99.1987)  time: 0.5927  data: 0.0016  max mem: 2503
Train: Epoch[5/5]  [ 360/3750]  eta: 0:37:11  Lr: 0.001875  Loss: -0.9576  Acc@1: 81.2500 (81.7694)  Acc@5: 100.0000 (99.2036)  time: 0.4219  data: 0.0007  max mem: 2503
Train: Epoch[5/5]  [ 370/3750]  eta: 0:36:37  Lr: 0.001875  Loss: -0.5334  Acc@1: 81.2500 (81.7385)  Acc@5: 100.0000 (99.2082)  time: 0.3519  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [ 380/3750]  eta: 0:36:04  Lr: 0.001875  Loss: -0.2388  Acc@1: 81.2500 (81.8077)  Acc@5: 100.0000 (99.1962)  time: 0.3534  data: 0.0007  max mem: 2503
Train: Epoch[5/5]  [ 390/3750]  eta: 0:35:32  Lr: 0.001875  Loss: -0.7450  Acc@1: 87.5000 (81.8734)  Acc@5: 100.0000 (99.2008)  time: 0.3505  data: 0.0015  max mem: 2503
Train: Epoch[5/5]  [ 400/3750]  eta: 0:35:03  Lr: 0.001875  Loss: -0.2199  Acc@1: 81.2500 (81.7488)  Acc@5: 100.0000 (99.1584)  time: 0.3547  data: 0.0034  max mem: 2503
Train: Epoch[5/5]  [ 410/3750]  eta: 0:34:48  Lr: 0.001875  Loss: -0.2898  Acc@1: 81.2500 (81.6910)  Acc@5: 100.0000 (99.1788)  time: 0.4428  data: 0.0027  max mem: 2503
Train: Epoch[5/5]  [ 420/3750]  eta: 0:34:46  Lr: 0.001875  Loss: -0.5681  Acc@1: 81.2500 (81.6063)  Acc@5: 100.0000 (99.1835)  time: 0.6003  data: 0.0009  max mem: 2503
Train: Epoch[5/5]  [ 430/3750]  eta: 0:34:42  Lr: 0.001875  Loss: -0.6587  Acc@1: 81.2500 (81.5255)  Acc@5: 100.0000 (99.1879)  time: 0.6664  data: 0.0008  max mem: 2503
Train: Epoch[5/5]  [ 440/3750]  eta: 0:34:40  Lr: 0.001875  Loss: -0.5367  Acc@1: 75.0000 (81.4626)  Acc@5: 100.0000 (99.1355)  time: 0.6674  data: 0.0007  max mem: 2503
Train: Epoch[5/5]  [ 450/3750]  eta: 0:34:34  Lr: 0.001875  Loss: 0.2637  Acc@1: 81.2500 (81.4717)  Acc@5: 100.0000 (99.1269)  time: 0.6559  data: 0.0009  max mem: 2503
Train: Epoch[5/5]  [ 460/3750]  eta: 0:34:29  Lr: 0.001875  Loss: -0.0794  Acc@1: 81.2500 (81.4534)  Acc@5: 100.0000 (99.1323)  time: 0.6399  data: 0.0008  max mem: 2503
Train: Epoch[5/5]  [ 470/3750]  eta: 0:34:24  Lr: 0.001875  Loss: -0.6068  Acc@1: 87.5000 (81.5552)  Acc@5: 100.0000 (99.0844)  time: 0.6498  data: 0.0017  max mem: 2503
Train: Epoch[5/5]  [ 480/3750]  eta: 0:34:20  Lr: 0.001875  Loss: -0.7688  Acc@1: 87.5000 (81.5359)  Acc@5: 100.0000 (99.0774)  time: 0.6600  data: 0.0024  max mem: 2503
Train: Epoch[5/5]  [ 490/3750]  eta: 0:34:18  Lr: 0.001875  Loss: -0.7997  Acc@1: 87.5000 (81.6446)  Acc@5: 100.0000 (99.0962)  time: 0.6749  data: 0.0012  max mem: 2503
Train: Epoch[5/5]  [ 500/3750]  eta: 0:34:14  Lr: 0.001875  Loss: -0.5449  Acc@1: 87.5000 (81.6492)  Acc@5: 100.0000 (99.0893)  time: 0.6783  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [ 510/3750]  eta: 0:34:11  Lr: 0.001875  Loss: -0.9150  Acc@1: 81.2500 (81.5925)  Acc@5: 100.0000 (99.0582)  time: 0.6760  data: 0.0007  max mem: 2503
Train: Epoch[5/5]  [ 520/3750]  eta: 0:34:06  Lr: 0.001875  Loss: -0.5946  Acc@1: 81.2500 (81.6459)  Acc@5: 100.0000 (99.0643)  time: 0.6707  data: 0.0007  max mem: 2503
Train: Epoch[5/5]  [ 530/3750]  eta: 0:34:02  Lr: 0.001875  Loss: -0.4812  Acc@1: 81.2500 (81.6384)  Acc@5: 100.0000 (99.0702)  time: 0.6634  data: 0.0012  max mem: 2503
Train: Epoch[5/5]  [ 540/3750]  eta: 0:33:57  Lr: 0.001875  Loss: -0.6343  Acc@1: 81.2500 (81.6774)  Acc@5: 100.0000 (99.0873)  time: 0.6669  data: 0.0012  max mem: 2503
Train: Epoch[5/5]  [ 550/3750]  eta: 0:33:53  Lr: 0.001875  Loss: -0.7830  Acc@1: 81.2500 (81.6583)  Acc@5: 100.0000 (99.1039)  time: 0.6686  data: 0.0012  max mem: 2503
Train: Epoch[5/5]  [ 560/3750]  eta: 0:33:50  Lr: 0.001875  Loss: -0.5522  Acc@1: 81.2500 (81.6511)  Acc@5: 100.0000 (99.0976)  time: 0.6824  data: 0.0012  max mem: 2503
Train: Epoch[5/5]  [ 570/3750]  eta: 0:33:45  Lr: 0.001875  Loss: -0.9569  Acc@1: 81.2500 (81.7097)  Acc@5: 100.0000 (99.0915)  time: 0.6781  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [ 580/3750]  eta: 0:33:40  Lr: 0.001875  Loss: -0.7439  Acc@1: 87.5000 (81.7233)  Acc@5: 100.0000 (99.0964)  time: 0.6607  data: 0.0019  max mem: 2503
Train: Epoch[5/5]  [ 590/3750]  eta: 0:33:36  Lr: 0.001875  Loss: -0.4217  Acc@1: 81.2500 (81.7047)  Acc@5: 100.0000 (99.1011)  time: 0.6738  data: 0.0020  max mem: 2503
Train: Epoch[5/5]  [ 600/3750]  eta: 0:33:32  Lr: 0.001875  Loss: -0.8290  Acc@1: 81.2500 (81.8220)  Acc@5: 100.0000 (99.1161)  time: 0.6815  data: 0.0007  max mem: 2503
Train: Epoch[5/5]  [ 610/3750]  eta: 0:33:27  Lr: 0.001875  Loss: -0.7775  Acc@1: 87.5000 (81.8740)  Acc@5: 100.0000 (99.1305)  time: 0.6750  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [ 620/3750]  eta: 0:33:23  Lr: 0.001875  Loss: -0.7474  Acc@1: 87.5000 (81.8639)  Acc@5: 100.0000 (99.1244)  time: 0.6744  data: 0.0006  max mem: 2503
Train: Epoch[5/5]  [ 630/3750]  eta: 0:33:16  Lr: 0.001875  Loss: -0.5063  Acc@1: 81.2500 (81.8641)  Acc@5: 100.0000 (99.1284)  time: 0.6571  data: 0.0007  max mem: 2503
Train: Epoch[5/5]  [ 640/3750]  eta: 0:33:11  Lr: 0.001875  Loss: -0.7271  Acc@1: 81.2500 (81.8350)  Acc@5: 100.0000 (99.1225)  time: 0.6502  data: 0.0009  max mem: 2503
Train: Epoch[5/5]  [ 650/3750]  eta: 0:33:06  Lr: 0.001875  Loss: -0.9038  Acc@1: 87.5000 (81.9028)  Acc@5: 100.0000 (99.1167)  time: 0.6677  data: 0.0011  max mem: 2503
Train: Epoch[5/5]  [ 660/3750]  eta: 0:33:01  Lr: 0.001875  Loss: -0.7992  Acc@1: 81.2500 (81.8835)  Acc@5: 100.0000 (99.1112)  time: 0.6695  data: 0.0008  max mem: 2503
Train: Epoch[5/5]  [ 670/3750]  eta: 0:32:56  Lr: 0.001875  Loss: -0.5787  Acc@1: 81.2500 (81.8461)  Acc@5: 100.0000 (99.1151)  time: 0.6697  data: 0.0012  max mem: 2503
Train: Epoch[5/5]  [ 680/3750]  eta: 0:32:50  Lr: 0.001875  Loss: -0.0943  Acc@1: 81.2500 (81.8007)  Acc@5: 100.0000 (99.1006)  time: 0.6673  data: 0.0013  max mem: 2503
Train: Epoch[5/5]  [ 690/3750]  eta: 0:32:45  Lr: 0.001875  Loss: -0.6038  Acc@1: 81.2500 (81.7927)  Acc@5: 100.0000 (99.0865)  time: 0.6581  data: 0.0013  max mem: 2503
Train: Epoch[5/5]  [ 700/3750]  eta: 0:32:39  Lr: 0.001875  Loss: -0.7102  Acc@1: 81.2500 (81.7939)  Acc@5: 100.0000 (99.0906)  time: 0.6646  data: 0.0011  max mem: 2503
Train: Epoch[5/5]  [ 710/3750]  eta: 0:32:34  Lr: 0.001875  Loss: -0.9655  Acc@1: 81.2500 (81.8126)  Acc@5: 100.0000 (99.0770)  time: 0.6741  data: 0.0006  max mem: 2503
Train: Epoch[5/5]  [ 720/3750]  eta: 0:32:30  Lr: 0.001875  Loss: -0.4498  Acc@1: 81.2500 (81.7614)  Acc@5: 100.0000 (99.0725)  time: 0.6775  data: 0.0008  max mem: 2503
Train: Epoch[5/5]  [ 730/3750]  eta: 0:32:24  Lr: 0.001875  Loss: -0.7396  Acc@1: 81.2500 (81.7459)  Acc@5: 100.0000 (99.0766)  time: 0.6754  data: 0.0010  max mem: 2503
Train: Epoch[5/5]  [ 740/3750]  eta: 0:32:18  Lr: 0.001875  Loss: -0.3448  Acc@1: 81.2500 (81.7223)  Acc@5: 100.0000 (99.0891)  time: 0.6564  data: 0.0010  max mem: 2503
Train: Epoch[5/5]  [ 750/3750]  eta: 0:32:13  Lr: 0.001875  Loss: -0.8639  Acc@1: 81.2500 (81.7577)  Acc@5: 100.0000 (99.0929)  time: 0.6602  data: 0.0007  max mem: 2503
Train: Epoch[5/5]  [ 760/3750]  eta: 0:32:07  Lr: 0.001875  Loss: -0.6670  Acc@1: 81.2500 (81.7428)  Acc@5: 100.0000 (99.1048)  time: 0.6691  data: 0.0006  max mem: 2503
Train: Epoch[5/5]  [ 770/3750]  eta: 0:31:56  Lr: 0.001875  Loss: -0.7429  Acc@1: 81.2500 (81.7121)  Acc@5: 100.0000 (99.1002)  time: 0.6010  data: 0.0006  max mem: 2503
Train: Epoch[5/5]  [ 780/3750]  eta: 0:31:39  Lr: 0.001875  Loss: -0.1226  Acc@1: 81.2500 (81.7141)  Acc@5: 100.0000 (99.0957)  time: 0.4465  data: 0.0007  max mem: 2503
Train: Epoch[5/5]  [ 790/3750]  eta: 0:31:22  Lr: 0.001875  Loss: -0.3464  Acc@1: 81.2500 (81.7320)  Acc@5: 100.0000 (99.0992)  time: 0.3510  data: 0.0007  max mem: 2503
Train: Epoch[5/5]  [ 800/3750]  eta: 0:31:06  Lr: 0.001875  Loss: -0.3130  Acc@1: 81.2500 (81.7104)  Acc@5: 100.0000 (99.0949)  time: 0.3656  data: 0.0019  max mem: 2503
Train: Epoch[5/5]  [ 810/3750]  eta: 0:30:50  Lr: 0.001875  Loss: -0.3469  Acc@1: 81.2500 (81.7432)  Acc@5: 100.0000 (99.1060)  time: 0.3784  data: 0.0042  max mem: 2503
Train: Epoch[5/5]  [ 820/3750]  eta: 0:30:35  Lr: 0.001875  Loss: -0.7060  Acc@1: 81.2500 (81.7372)  Acc@5: 100.0000 (99.0865)  time: 0.3751  data: 0.0044  max mem: 2503
Train: Epoch[5/5]  [ 830/3750]  eta: 0:30:19  Lr: 0.001875  Loss: -0.2300  Acc@1: 81.2500 (81.7238)  Acc@5: 100.0000 (99.0900)  time: 0.3699  data: 0.0045  max mem: 2503
Train: Epoch[5/5]  [ 840/3750]  eta: 0:30:04  Lr: 0.001875  Loss: -0.4542  Acc@1: 81.2500 (81.7108)  Acc@5: 100.0000 (99.0636)  time: 0.3661  data: 0.0067  max mem: 2503
Train: Epoch[5/5]  [ 850/3750]  eta: 0:29:49  Lr: 0.001875  Loss: -0.3511  Acc@1: 81.2500 (81.7641)  Acc@5: 100.0000 (99.0599)  time: 0.3608  data: 0.0053  max mem: 2503
Train: Epoch[5/5]  [ 860/3750]  eta: 0:29:34  Lr: 0.001875  Loss: -0.5131  Acc@1: 81.2500 (81.7509)  Acc@5: 100.0000 (99.0491)  time: 0.3565  data: 0.0030  max mem: 2503
Train: Epoch[5/5]  [ 870/3750]  eta: 0:29:20  Lr: 0.001875  Loss: -0.4411  Acc@1: 81.2500 (81.8241)  Acc@5: 100.0000 (99.0528)  time: 0.3622  data: 0.0056  max mem: 2503
Train: Epoch[5/5]  [ 880/3750]  eta: 0:29:06  Lr: 0.001875  Loss: -0.3226  Acc@1: 87.5000 (81.8317)  Acc@5: 100.0000 (99.0636)  time: 0.3663  data: 0.0049  max mem: 2503
Train: Epoch[5/5]  [ 890/3750]  eta: 0:28:52  Lr: 0.001875  Loss: -0.8685  Acc@1: 81.2500 (81.8603)  Acc@5: 100.0000 (99.0600)  time: 0.3665  data: 0.0019  max mem: 2503
Train: Epoch[5/5]  [ 900/3750]  eta: 0:28:38  Lr: 0.001875  Loss: -0.6947  Acc@1: 81.2500 (81.8535)  Acc@5: 100.0000 (99.0566)  time: 0.3626  data: 0.0033  max mem: 2503
Train: Epoch[5/5]  [ 910/3750]  eta: 0:28:25  Lr: 0.001875  Loss: -0.6128  Acc@1: 81.2500 (81.8675)  Acc@5: 100.0000 (99.0670)  time: 0.3592  data: 0.0056  max mem: 2503
Train: Epoch[5/5]  [ 920/3750]  eta: 0:28:12  Lr: 0.001875  Loss: -0.5881  Acc@1: 81.2500 (81.8879)  Acc@5: 100.0000 (99.0635)  time: 0.3683  data: 0.0052  max mem: 2503
Train: Epoch[5/5]  [ 930/3750]  eta: 0:27:59  Lr: 0.001875  Loss: -0.4982  Acc@1: 81.2500 (81.9079)  Acc@5: 100.0000 (99.0669)  time: 0.3747  data: 0.0044  max mem: 2503
Train: Epoch[5/5]  [ 940/3750]  eta: 0:27:46  Lr: 0.001875  Loss: -0.3475  Acc@1: 81.2500 (81.8743)  Acc@5: 100.0000 (99.0701)  time: 0.3675  data: 0.0042  max mem: 2503
Train: Epoch[5/5]  [ 950/3750]  eta: 0:27:33  Lr: 0.001875  Loss: -0.2933  Acc@1: 81.2500 (81.8349)  Acc@5: 100.0000 (99.0668)  time: 0.3655  data: 0.0050  max mem: 2503
Train: Epoch[5/5]  [ 960/3750]  eta: 0:27:21  Lr: 0.001875  Loss: -0.4640  Acc@1: 81.2500 (81.8939)  Acc@5: 100.0000 (99.0700)  time: 0.3726  data: 0.0065  max mem: 2503
Train: Epoch[5/5]  [ 970/3750]  eta: 0:27:09  Lr: 0.001875  Loss: -0.6402  Acc@1: 81.2500 (81.8937)  Acc@5: 100.0000 (99.0602)  time: 0.3731  data: 0.0053  max mem: 2503
Train: Epoch[5/5]  [ 980/3750]  eta: 0:26:57  Lr: 0.001875  Loss: -0.6938  Acc@1: 81.2500 (81.9253)  Acc@5: 100.0000 (99.0571)  time: 0.3657  data: 0.0034  max mem: 2503
Train: Epoch[5/5]  [ 990/3750]  eta: 0:26:45  Lr: 0.001875  Loss: -0.9301  Acc@1: 81.2500 (81.9374)  Acc@5: 100.0000 (99.0540)  time: 0.3574  data: 0.0022  max mem: 2503
Train: Epoch[5/5]  [1000/3750]  eta: 0:26:33  Lr: 0.001875  Loss: -0.6623  Acc@1: 81.2500 (81.9618)  Acc@5: 100.0000 (99.0634)  time: 0.3609  data: 0.0023  max mem: 2503
Train: Epoch[5/5]  [1010/3750]  eta: 0:26:21  Lr: 0.001875  Loss: -0.4346  Acc@1: 81.2500 (81.9547)  Acc@5: 100.0000 (99.0665)  time: 0.3626  data: 0.0033  max mem: 2503
Train: Epoch[5/5]  [1020/3750]  eta: 0:26:10  Lr: 0.001875  Loss: -0.7203  Acc@1: 81.2500 (81.9907)  Acc@5: 100.0000 (99.0757)  time: 0.3607  data: 0.0037  max mem: 2503
Train: Epoch[5/5]  [1030/3750]  eta: 0:25:58  Lr: 0.001875  Loss: -0.4074  Acc@1: 81.2500 (81.9774)  Acc@5: 100.0000 (99.0846)  time: 0.3637  data: 0.0042  max mem: 2503
Train: Epoch[5/5]  [1040/3750]  eta: 0:25:47  Lr: 0.001875  Loss: -0.8133  Acc@1: 81.2500 (82.0125)  Acc@5: 100.0000 (99.0754)  time: 0.3647  data: 0.0045  max mem: 2503
Train: Epoch[5/5]  [1050/3750]  eta: 0:25:36  Lr: 0.001875  Loss: -0.7246  Acc@1: 81.2500 (82.0171)  Acc@5: 100.0000 (99.0842)  time: 0.3659  data: 0.0028  max mem: 2503
Train: Epoch[5/5]  [1060/3750]  eta: 0:25:25  Lr: 0.001875  Loss: -0.5177  Acc@1: 81.2500 (81.9863)  Acc@5: 100.0000 (99.0928)  time: 0.3608  data: 0.0019  max mem: 2503
Train: Epoch[5/5]  [1070/3750]  eta: 0:25:14  Lr: 0.001875  Loss: -0.8162  Acc@1: 81.2500 (81.9853)  Acc@5: 100.0000 (99.0955)  time: 0.3554  data: 0.0022  max mem: 2503
Train: Epoch[5/5]  [1080/3750]  eta: 0:25:04  Lr: 0.001875  Loss: -0.4897  Acc@1: 81.2500 (81.9496)  Acc@5: 100.0000 (99.0981)  time: 0.3616  data: 0.0031  max mem: 2503
Train: Epoch[5/5]  [1090/3750]  eta: 0:24:53  Lr: 0.001875  Loss: -0.7747  Acc@1: 81.2500 (81.9833)  Acc@5: 100.0000 (99.0891)  time: 0.3684  data: 0.0042  max mem: 2503
Train: Epoch[5/5]  [1100/3750]  eta: 0:24:43  Lr: 0.001875  Loss: -0.2654  Acc@1: 81.2500 (81.9766)  Acc@5: 100.0000 (99.0861)  time: 0.3656  data: 0.0043  max mem: 2503
Train: Epoch[5/5]  [1110/3750]  eta: 0:24:33  Lr: 0.001875  Loss: -0.5353  Acc@1: 81.2500 (82.0151)  Acc@5: 100.0000 (99.0943)  time: 0.3625  data: 0.0052  max mem: 2503
Train: Epoch[5/5]  [1120/3750]  eta: 0:24:23  Lr: 0.001875  Loss: -0.6380  Acc@1: 87.5000 (82.0640)  Acc@5: 100.0000 (99.0968)  time: 0.3676  data: 0.0047  max mem: 2503
Train: Epoch[5/5]  [1130/3750]  eta: 0:24:12  Lr: 0.001875  Loss: -0.8637  Acc@1: 87.5000 (82.0734)  Acc@5: 100.0000 (99.0937)  time: 0.3640  data: 0.0025  max mem: 2503
Train: Epoch[5/5]  [1140/3750]  eta: 0:24:02  Lr: 0.001875  Loss: -0.3116  Acc@1: 75.0000 (81.9895)  Acc@5: 100.0000 (99.0962)  time: 0.3568  data: 0.0022  max mem: 2503
Train: Epoch[5/5]  [1150/3750]  eta: 0:23:52  Lr: 0.001875  Loss: -0.8784  Acc@1: 75.0000 (81.9722)  Acc@5: 100.0000 (99.0932)  time: 0.3586  data: 0.0037  max mem: 2503
Train: Epoch[5/5]  [1160/3750]  eta: 0:23:43  Lr: 0.001875  Loss: -0.5002  Acc@1: 81.2500 (81.9660)  Acc@5: 100.0000 (99.0902)  time: 0.3607  data: 0.0043  max mem: 2503
Train: Epoch[5/5]  [1170/3750]  eta: 0:23:33  Lr: 0.001875  Loss: -0.8527  Acc@1: 87.5000 (81.9865)  Acc@5: 100.0000 (99.0766)  time: 0.3613  data: 0.0058  max mem: 2503
Train: Epoch[5/5]  [1180/3750]  eta: 0:23:23  Lr: 0.001875  Loss: -0.9436  Acc@1: 87.5000 (81.9909)  Acc@5: 100.0000 (99.0845)  time: 0.3582  data: 0.0044  max mem: 2503
Train: Epoch[5/5]  [1190/3750]  eta: 0:23:14  Lr: 0.001875  Loss: -0.6871  Acc@1: 81.2500 (82.0162)  Acc@5: 100.0000 (99.0869)  time: 0.3565  data: 0.0031  max mem: 2503
Train: Epoch[5/5]  [1200/3750]  eta: 0:23:05  Lr: 0.001875  Loss: -0.5326  Acc@1: 81.2500 (82.0046)  Acc@5: 100.0000 (99.0893)  time: 0.3610  data: 0.0031  max mem: 2503
Train: Epoch[5/5]  [1210/3750]  eta: 0:22:55  Lr: 0.001875  Loss: -0.5846  Acc@1: 81.2500 (81.9777)  Acc@5: 100.0000 (99.0917)  time: 0.3651  data: 0.0022  max mem: 2503
Train: Epoch[5/5]  [1220/3750]  eta: 0:22:47  Lr: 0.001875  Loss: -0.4242  Acc@1: 81.2500 (81.9769)  Acc@5: 100.0000 (99.0940)  time: 0.3698  data: 0.0040  max mem: 2503
Train: Epoch[5/5]  [1230/3750]  eta: 0:22:38  Lr: 0.001875  Loss: -0.9502  Acc@1: 81.2500 (82.0268)  Acc@5: 100.0000 (99.0912)  time: 0.3788  data: 0.0053  max mem: 2503
Train: Epoch[5/5]  [1240/3750]  eta: 0:22:29  Lr: 0.001875  Loss: -0.9101  Acc@1: 87.5000 (82.0256)  Acc@5: 100.0000 (99.0985)  time: 0.3781  data: 0.0037  max mem: 2503
Train: Epoch[5/5]  [1250/3750]  eta: 0:22:20  Lr: 0.001875  Loss: -0.6249  Acc@1: 81.2500 (82.0344)  Acc@5: 100.0000 (99.1057)  time: 0.3667  data: 0.0032  max mem: 2503
Train: Epoch[5/5]  [1260/3750]  eta: 0:22:11  Lr: 0.001875  Loss: -0.7622  Acc@1: 81.2500 (82.0331)  Acc@5: 100.0000 (99.1128)  time: 0.3603  data: 0.0054  max mem: 2503
Train: Epoch[5/5]  [1270/3750]  eta: 0:22:03  Lr: 0.001875  Loss: -0.4454  Acc@1: 75.0000 (82.0122)  Acc@5: 100.0000 (99.1100)  time: 0.3589  data: 0.0045  max mem: 2503
Train: Epoch[5/5]  [1280/3750]  eta: 0:21:54  Lr: 0.001875  Loss: -0.3301  Acc@1: 81.2500 (82.0111)  Acc@5: 100.0000 (99.1169)  time: 0.3644  data: 0.0037  max mem: 2503
Train: Epoch[5/5]  [1290/3750]  eta: 0:21:46  Lr: 0.001875  Loss: -0.5678  Acc@1: 81.2500 (82.0052)  Acc@5: 100.0000 (99.1189)  time: 0.3647  data: 0.0037  max mem: 2503
Train: Epoch[5/5]  [1300/3750]  eta: 0:21:37  Lr: 0.001875  Loss: -0.5429  Acc@1: 81.2500 (81.9706)  Acc@5: 100.0000 (99.1113)  time: 0.3593  data: 0.0028  max mem: 2503
Train: Epoch[5/5]  [1310/3750]  eta: 0:21:28  Lr: 0.001875  Loss: -0.7121  Acc@1: 75.0000 (81.9413)  Acc@5: 100.0000 (99.0990)  time: 0.3586  data: 0.0028  max mem: 2503
Train: Epoch[5/5]  [1320/3750]  eta: 0:21:20  Lr: 0.001875  Loss: -0.0646  Acc@1: 75.0000 (81.9218)  Acc@5: 100.0000 (99.1058)  time: 0.3593  data: 0.0020  max mem: 2503
Train: Epoch[5/5]  [1330/3750]  eta: 0:21:12  Lr: 0.001875  Loss: -0.5563  Acc@1: 81.2500 (81.9356)  Acc@5: 100.0000 (99.1078)  time: 0.3607  data: 0.0023  max mem: 2503
Train: Epoch[5/5]  [1340/3750]  eta: 0:21:04  Lr: 0.001875  Loss: -0.6005  Acc@1: 81.2500 (81.9072)  Acc@5: 100.0000 (99.1005)  time: 0.3603  data: 0.0031  max mem: 2503
Train: Epoch[5/5]  [1350/3750]  eta: 0:20:56  Lr: 0.001875  Loss: -0.8817  Acc@1: 81.2500 (81.9301)  Acc@5: 100.0000 (99.1025)  time: 0.3627  data: 0.0039  max mem: 2503
Train: Epoch[5/5]  [1360/3750]  eta: 0:20:48  Lr: 0.001875  Loss: -0.3218  Acc@1: 87.5000 (81.9664)  Acc@5: 100.0000 (99.1045)  time: 0.3683  data: 0.0070  max mem: 2503
Train: Epoch[5/5]  [1370/3750]  eta: 0:20:40  Lr: 0.001875  Loss: -0.6677  Acc@1: 81.2500 (81.9703)  Acc@5: 100.0000 (99.1065)  time: 0.3668  data: 0.0064  max mem: 2503
Train: Epoch[5/5]  [1380/3750]  eta: 0:20:32  Lr: 0.001875  Loss: -0.5732  Acc@1: 81.2500 (81.9877)  Acc@5: 100.0000 (99.1130)  time: 0.3588  data: 0.0037  max mem: 2503
Train: Epoch[5/5]  [1390/3750]  eta: 0:20:24  Lr: 0.001875  Loss: -0.5760  Acc@1: 81.2500 (81.9689)  Acc@5: 100.0000 (99.1014)  time: 0.3558  data: 0.0037  max mem: 2503
Train: Epoch[5/5]  [1400/3750]  eta: 0:20:16  Lr: 0.001875  Loss: -0.6507  Acc@1: 81.2500 (81.9638)  Acc@5: 100.0000 (99.1033)  time: 0.3593  data: 0.0037  max mem: 2503
Train: Epoch[5/5]  [1410/3750]  eta: 0:20:08  Lr: 0.001875  Loss: -0.2102  Acc@1: 81.2500 (81.9720)  Acc@5: 100.0000 (99.1052)  time: 0.3601  data: 0.0039  max mem: 2503
Train: Epoch[5/5]  [1420/3750]  eta: 0:20:00  Lr: 0.001875  Loss: -0.8762  Acc@1: 81.2500 (81.9537)  Acc@5: 100.0000 (99.0939)  time: 0.3607  data: 0.0038  max mem: 2503
Train: Epoch[5/5]  [1430/3750]  eta: 0:19:53  Lr: 0.001875  Loss: -0.7467  Acc@1: 81.2500 (81.9488)  Acc@5: 100.0000 (99.0959)  time: 0.3626  data: 0.0045  max mem: 2503
Train: Epoch[5/5]  [1440/3750]  eta: 0:19:45  Lr: 0.001875  Loss: -0.5313  Acc@1: 81.2500 (81.9136)  Acc@5: 100.0000 (99.0935)  time: 0.3589  data: 0.0046  max mem: 2503
Train: Epoch[5/5]  [1450/3750]  eta: 0:19:37  Lr: 0.001875  Loss: 0.0152  Acc@1: 81.2500 (81.9133)  Acc@5: 100.0000 (99.0998)  time: 0.3568  data: 0.0026  max mem: 2503
Train: Epoch[5/5]  [1460/3750]  eta: 0:19:30  Lr: 0.001875  Loss: -0.4795  Acc@1: 81.2500 (81.8660)  Acc@5: 100.0000 (99.1059)  time: 0.3581  data: 0.0021  max mem: 2503
Train: Epoch[5/5]  [1470/3750]  eta: 0:19:23  Lr: 0.001875  Loss: -0.6823  Acc@1: 81.2500 (81.8703)  Acc@5: 100.0000 (99.0865)  time: 0.3672  data: 0.0040  max mem: 2503
Train: Epoch[5/5]  [1480/3750]  eta: 0:19:15  Lr: 0.001875  Loss: -0.5499  Acc@1: 81.2500 (81.8577)  Acc@5: 100.0000 (99.0885)  time: 0.3726  data: 0.0035  max mem: 2503
Train: Epoch[5/5]  [1490/3750]  eta: 0:19:08  Lr: 0.001875  Loss: -0.7849  Acc@1: 81.2500 (81.8788)  Acc@5: 100.0000 (99.0946)  time: 0.3644  data: 0.0017  max mem: 2503
Train: Epoch[5/5]  [1500/3750]  eta: 0:19:01  Lr: 0.001875  Loss: -0.5791  Acc@1: 87.5000 (81.8954)  Acc@5: 100.0000 (99.1006)  time: 0.3606  data: 0.0025  max mem: 2503
Train: Epoch[5/5]  [1510/3750]  eta: 0:18:54  Lr: 0.001875  Loss: -0.5168  Acc@1: 87.5000 (81.9077)  Acc@5: 100.0000 (99.0983)  time: 0.3641  data: 0.0047  max mem: 2503
Train: Epoch[5/5]  [1520/3750]  eta: 0:18:46  Lr: 0.001875  Loss: 0.0298  Acc@1: 87.5000 (81.9075)  Acc@5: 100.0000 (99.1001)  time: 0.3649  data: 0.0056  max mem: 2503
Train: Epoch[5/5]  [1530/3750]  eta: 0:18:39  Lr: 0.001875  Loss: -0.4242  Acc@1: 81.2500 (81.8991)  Acc@5: 100.0000 (99.0978)  time: 0.3595  data: 0.0042  max mem: 2503
Train: Epoch[5/5]  [1540/3750]  eta: 0:18:32  Lr: 0.001875  Loss: -0.1353  Acc@1: 81.2500 (81.9070)  Acc@5: 100.0000 (99.0874)  time: 0.3568  data: 0.0031  max mem: 2503
Train: Epoch[5/5]  [1550/3750]  eta: 0:18:25  Lr: 0.001875  Loss: -0.3709  Acc@1: 81.2500 (81.8907)  Acc@5: 100.0000 (99.0893)  time: 0.3608  data: 0.0033  max mem: 2503
Train: Epoch[5/5]  [1560/3750]  eta: 0:18:18  Lr: 0.001875  Loss: -0.2861  Acc@1: 81.2500 (81.9106)  Acc@5: 100.0000 (99.0911)  time: 0.3673  data: 0.0026  max mem: 2503
Train: Epoch[5/5]  [1570/3750]  eta: 0:18:11  Lr: 0.001875  Loss: -0.6132  Acc@1: 81.2500 (81.8865)  Acc@5: 100.0000 (99.0850)  time: 0.3706  data: 0.0021  max mem: 2503
Train: Epoch[5/5]  [1580/3750]  eta: 0:18:05  Lr: 0.001875  Loss: -0.5806  Acc@1: 75.0000 (81.8865)  Acc@5: 100.0000 (99.0868)  time: 0.3711  data: 0.0035  max mem: 2503
Train: Epoch[5/5]  [1590/3750]  eta: 0:17:58  Lr: 0.001875  Loss: -0.7458  Acc@1: 81.2500 (81.8903)  Acc@5: 100.0000 (99.0886)  time: 0.3666  data: 0.0037  max mem: 2503
Train: Epoch[5/5]  [1600/3750]  eta: 0:17:51  Lr: 0.001875  Loss: -0.6189  Acc@1: 81.2500 (81.8941)  Acc@5: 100.0000 (99.0865)  time: 0.3600  data: 0.0027  max mem: 2503
Train: Epoch[5/5]  [1610/3750]  eta: 0:17:44  Lr: 0.001875  Loss: -0.4573  Acc@1: 81.2500 (81.9018)  Acc@5: 100.0000 (99.0883)  time: 0.3750  data: 0.0044  max mem: 2503
Train: Epoch[5/5]  [1620/3750]  eta: 0:17:38  Lr: 0.001875  Loss: -0.5357  Acc@1: 81.2500 (81.8939)  Acc@5: 100.0000 (99.0824)  time: 0.3783  data: 0.0058  max mem: 2503
Train: Epoch[5/5]  [1630/3750]  eta: 0:17:31  Lr: 0.001875  Loss: -0.4093  Acc@1: 81.2500 (81.8823)  Acc@5: 100.0000 (99.0842)  time: 0.3658  data: 0.0045  max mem: 2503
Train: Epoch[5/5]  [1640/3750]  eta: 0:17:24  Lr: 0.001875  Loss: -0.3880  Acc@1: 87.5000 (81.9051)  Acc@5: 100.0000 (99.0821)  time: 0.3607  data: 0.0040  max mem: 2503
Train: Epoch[5/5]  [1650/3750]  eta: 0:17:18  Lr: 0.001875  Loss: -0.1577  Acc@1: 81.2500 (81.8860)  Acc@5: 100.0000 (99.0801)  time: 0.3568  data: 0.0036  max mem: 2503
Train: Epoch[5/5]  [1660/3750]  eta: 0:17:11  Lr: 0.001875  Loss: -0.6600  Acc@1: 81.2500 (81.8934)  Acc@5: 100.0000 (99.0819)  time: 0.3617  data: 0.0021  max mem: 2503
Train: Epoch[5/5]  [1670/3750]  eta: 0:17:04  Lr: 0.001875  Loss: -0.8128  Acc@1: 81.2500 (81.9120)  Acc@5: 100.0000 (99.0874)  time: 0.3632  data: 0.0031  max mem: 2503
Train: Epoch[5/5]  [1680/3750]  eta: 0:16:58  Lr: 0.001875  Loss: -0.8789  Acc@1: 81.2500 (81.9192)  Acc@5: 100.0000 (99.0928)  time: 0.3598  data: 0.0037  max mem: 2503
Train: Epoch[5/5]  [1690/3750]  eta: 0:16:51  Lr: 0.001875  Loss: -0.7983  Acc@1: 81.2500 (81.9190)  Acc@5: 100.0000 (99.0945)  time: 0.3595  data: 0.0021  max mem: 2503
Train: Epoch[5/5]  [1700/3750]  eta: 0:16:45  Lr: 0.001875  Loss: -0.4259  Acc@1: 81.2500 (81.9297)  Acc@5: 100.0000 (99.0961)  time: 0.3604  data: 0.0012  max mem: 2503
Train: Epoch[5/5]  [1710/3750]  eta: 0:16:38  Lr: 0.001875  Loss: -0.6245  Acc@1: 81.2500 (81.9331)  Acc@5: 100.0000 (99.0868)  time: 0.3614  data: 0.0017  max mem: 2503
Train: Epoch[5/5]  [1720/3750]  eta: 0:16:32  Lr: 0.001875  Loss: -0.9367  Acc@1: 81.2500 (81.9182)  Acc@5: 100.0000 (99.0885)  time: 0.3691  data: 0.0032  max mem: 2503
Train: Epoch[5/5]  [1730/3750]  eta: 0:16:26  Lr: 0.001875  Loss: -0.7517  Acc@1: 81.2500 (81.9180)  Acc@5: 100.0000 (99.0937)  time: 0.3701  data: 0.0034  max mem: 2503
Train: Epoch[5/5]  [1740/3750]  eta: 0:16:19  Lr: 0.001875  Loss: -0.7269  Acc@1: 81.2500 (81.8998)  Acc@5: 100.0000 (99.0953)  time: 0.3605  data: 0.0021  max mem: 2503
Train: Epoch[5/5]  [1750/3750]  eta: 0:16:13  Lr: 0.001875  Loss: -0.7103  Acc@1: 81.2500 (81.9282)  Acc@5: 100.0000 (99.0898)  time: 0.3586  data: 0.0023  max mem: 2503
Train: Epoch[5/5]  [1760/3750]  eta: 0:16:07  Lr: 0.001875  Loss: -0.7034  Acc@1: 87.5000 (81.9350)  Acc@5: 100.0000 (99.0843)  time: 0.3592  data: 0.0031  max mem: 2503
Train: Epoch[5/5]  [1770/3750]  eta: 0:16:01  Lr: 0.001875  Loss: -0.0030  Acc@1: 81.2500 (81.9170)  Acc@5: 100.0000 (99.0824)  time: 0.3616  data: 0.0022  max mem: 2503
Train: Epoch[5/5]  [1780/3750]  eta: 0:15:54  Lr: 0.001875  Loss: -0.4653  Acc@1: 81.2500 (81.9027)  Acc@5: 100.0000 (99.0841)  time: 0.3648  data: 0.0034  max mem: 2503
Train: Epoch[5/5]  [1790/3750]  eta: 0:15:48  Lr: 0.001875  Loss: -0.4690  Acc@1: 81.2500 (81.9200)  Acc@5: 100.0000 (99.0892)  time: 0.3604  data: 0.0032  max mem: 2503
Train: Epoch[5/5]  [1800/3750]  eta: 0:15:42  Lr: 0.001875  Loss: -0.3376  Acc@1: 81.2500 (81.8989)  Acc@5: 100.0000 (99.0873)  time: 0.3593  data: 0.0024  max mem: 2503
Train: Epoch[5/5]  [1810/3750]  eta: 0:15:36  Lr: 0.001875  Loss: -0.6990  Acc@1: 81.2500 (81.9126)  Acc@5: 100.0000 (99.0785)  time: 0.3655  data: 0.0051  max mem: 2503
Train: Epoch[5/5]  [1820/3750]  eta: 0:15:30  Lr: 0.001875  Loss: -0.8832  Acc@1: 81.2500 (81.9090)  Acc@5: 100.0000 (99.0802)  time: 0.3661  data: 0.0058  max mem: 2503
Train: Epoch[5/5]  [1830/3750]  eta: 0:15:24  Lr: 0.001875  Loss: -0.6553  Acc@1: 81.2500 (81.9190)  Acc@5: 100.0000 (99.0852)  time: 0.3655  data: 0.0041  max mem: 2503
Train: Epoch[5/5]  [1840/3750]  eta: 0:15:18  Lr: 0.001875  Loss: -0.6423  Acc@1: 81.2500 (81.9154)  Acc@5: 100.0000 (99.0834)  time: 0.3659  data: 0.0040  max mem: 2503
Train: Epoch[5/5]  [1850/3750]  eta: 0:15:12  Lr: 0.001875  Loss: -0.6277  Acc@1: 81.2500 (81.9287)  Acc@5: 100.0000 (99.0850)  time: 0.3671  data: 0.0031  max mem: 2503
Train: Epoch[5/5]  [1860/3750]  eta: 0:15:06  Lr: 0.001875  Loss: -0.6479  Acc@1: 81.2500 (81.9116)  Acc@5: 100.0000 (99.0865)  time: 0.3741  data: 0.0065  max mem: 2503
Train: Epoch[5/5]  [1870/3750]  eta: 0:15:00  Lr: 0.001875  Loss: -0.8120  Acc@1: 81.2500 (81.9381)  Acc@5: 100.0000 (99.0814)  time: 0.3691  data: 0.0074  max mem: 2503
Train: Epoch[5/5]  [1880/3750]  eta: 0:14:54  Lr: 0.001875  Loss: -0.6667  Acc@1: 81.2500 (81.9179)  Acc@5: 100.0000 (99.0863)  time: 0.3624  data: 0.0033  max mem: 2503
Train: Epoch[5/5]  [1890/3750]  eta: 0:14:48  Lr: 0.001875  Loss: -0.5940  Acc@1: 81.2500 (81.9276)  Acc@5: 100.0000 (99.0845)  time: 0.3622  data: 0.0036  max mem: 2503
Train: Epoch[5/5]  [1900/3750]  eta: 0:14:42  Lr: 0.001875  Loss: -0.5089  Acc@1: 81.2500 (81.9010)  Acc@5: 100.0000 (99.0827)  time: 0.3577  data: 0.0030  max mem: 2503
Train: Epoch[5/5]  [1910/3750]  eta: 0:14:36  Lr: 0.001875  Loss: -0.5753  Acc@1: 81.2500 (81.8878)  Acc@5: 100.0000 (99.0842)  time: 0.3530  data: 0.0015  max mem: 2503
Train: Epoch[5/5]  [1920/3750]  eta: 0:14:30  Lr: 0.001875  Loss: -0.6946  Acc@1: 81.2500 (81.8974)  Acc@5: 100.0000 (99.0825)  time: 0.3582  data: 0.0023  max mem: 2503
Train: Epoch[5/5]  [1930/3750]  eta: 0:14:25  Lr: 0.001875  Loss: -0.5201  Acc@1: 81.2500 (81.8909)  Acc@5: 100.0000 (99.0808)  time: 0.3667  data: 0.0049  max mem: 2503
Train: Epoch[5/5]  [1940/3750]  eta: 0:14:19  Lr: 0.001875  Loss: -0.8905  Acc@1: 81.2500 (81.8876)  Acc@5: 100.0000 (99.0855)  time: 0.3688  data: 0.0042  max mem: 2503
Train: Epoch[5/5]  [1950/3750]  eta: 0:14:13  Lr: 0.001875  Loss: -0.6933  Acc@1: 81.2500 (81.9035)  Acc@5: 100.0000 (99.0870)  time: 0.3660  data: 0.0034  max mem: 2503
Train: Epoch[5/5]  [1960/3750]  eta: 0:14:07  Lr: 0.001875  Loss: -0.8569  Acc@1: 87.5000 (81.8970)  Acc@5: 100.0000 (99.0885)  time: 0.3590  data: 0.0035  max mem: 2503
Train: Epoch[5/5]  [1970/3750]  eta: 0:14:01  Lr: 0.001875  Loss: -0.4380  Acc@1: 81.2500 (81.8969)  Acc@5: 100.0000 (99.0868)  time: 0.3589  data: 0.0027  max mem: 2503
Train: Epoch[5/5]  [1980/3750]  eta: 0:13:56  Lr: 0.001875  Loss: -0.5423  Acc@1: 81.2500 (81.8747)  Acc@5: 100.0000 (99.0819)  time: 0.3597  data: 0.0020  max mem: 2503
Train: Epoch[5/5]  [1990/3750]  eta: 0:13:50  Lr: 0.001875  Loss: -0.7071  Acc@1: 81.2500 (81.8778)  Acc@5: 100.0000 (99.0834)  time: 0.3635  data: 0.0026  max mem: 2503
Train: Epoch[5/5]  [2000/3750]  eta: 0:13:44  Lr: 0.001875  Loss: -0.4384  Acc@1: 81.2500 (81.8903)  Acc@5: 100.0000 (99.0817)  time: 0.3697  data: 0.0057  max mem: 2503
Train: Epoch[5/5]  [2010/3750]  eta: 0:13:39  Lr: 0.001875  Loss: -0.7325  Acc@1: 81.2500 (81.8778)  Acc@5: 100.0000 (99.0738)  time: 0.3690  data: 0.0053  max mem: 2503
Train: Epoch[5/5]  [2020/3750]  eta: 0:13:33  Lr: 0.001875  Loss: -0.6844  Acc@1: 81.2500 (81.9025)  Acc@5: 100.0000 (99.0753)  time: 0.3653  data: 0.0029  max mem: 2503
Train: Epoch[5/5]  [2030/3750]  eta: 0:13:28  Lr: 0.001875  Loss: -0.9244  Acc@1: 87.5000 (81.9301)  Acc@5: 100.0000 (99.0768)  time: 0.3611  data: 0.0025  max mem: 2503
Train: Epoch[5/5]  [2040/3750]  eta: 0:13:22  Lr: 0.001875  Loss: -0.6101  Acc@1: 87.5000 (81.9268)  Acc@5: 100.0000 (99.0752)  time: 0.3609  data: 0.0029  max mem: 2503
Train: Epoch[5/5]  [2050/3750]  eta: 0:13:16  Lr: 0.001875  Loss: -0.7536  Acc@1: 81.2500 (81.9204)  Acc@5: 100.0000 (99.0767)  time: 0.3602  data: 0.0030  max mem: 2503
Train: Epoch[5/5]  [2060/3750]  eta: 0:13:11  Lr: 0.001875  Loss: -0.8266  Acc@1: 81.2500 (81.9444)  Acc@5: 100.0000 (99.0811)  time: 0.3573  data: 0.0022  max mem: 2503
Train: Epoch[5/5]  [2070/3750]  eta: 0:13:06  Lr: 0.001875  Loss: -0.6075  Acc@1: 81.2500 (81.9290)  Acc@5: 100.0000 (99.0796)  time: 0.4407  data: 0.0014  max mem: 2503
Train: Epoch[5/5]  [2080/3750]  eta: 0:13:03  Lr: 0.001875  Loss: -0.8158  Acc@1: 81.2500 (81.9378)  Acc@5: 100.0000 (99.0750)  time: 0.5985  data: 0.0007  max mem: 2503
Train: Epoch[5/5]  [2090/3750]  eta: 0:13:00  Lr: 0.001875  Loss: -0.8959  Acc@1: 87.5000 (81.9434)  Acc@5: 100.0000 (99.0704)  time: 0.6684  data: 0.0006  max mem: 2503
Train: Epoch[5/5]  [2100/3750]  eta: 0:12:57  Lr: 0.001875  Loss: -0.4938  Acc@1: 81.2500 (81.9372)  Acc@5: 100.0000 (99.0748)  time: 0.6735  data: 0.0007  max mem: 2503
Train: Epoch[5/5]  [2110/3750]  eta: 0:12:54  Lr: 0.001875  Loss: -0.8071  Acc@1: 81.2500 (81.9250)  Acc@5: 100.0000 (99.0792)  time: 0.6689  data: 0.0007  max mem: 2503
Train: Epoch[5/5]  [2120/3750]  eta: 0:12:51  Lr: 0.001875  Loss: -0.8575  Acc@1: 81.2500 (81.9071)  Acc@5: 100.0000 (99.0806)  time: 0.6645  data: 0.0006  max mem: 2503
Train: Epoch[5/5]  [2130/3750]  eta: 0:12:47  Lr: 0.001875  Loss: -0.8547  Acc@1: 81.2500 (81.9070)  Acc@5: 100.0000 (99.0849)  time: 0.6614  data: 0.0007  max mem: 2503
Train: Epoch[5/5]  [2140/3750]  eta: 0:12:44  Lr: 0.001875  Loss: -0.9477  Acc@1: 81.2500 (81.9156)  Acc@5: 100.0000 (99.0863)  time: 0.6675  data: 0.0007  max mem: 2503
Train: Epoch[5/5]  [2150/3750]  eta: 0:12:41  Lr: 0.001875  Loss: -0.5033  Acc@1: 87.5000 (81.9386)  Acc@5: 100.0000 (99.0905)  time: 0.6878  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [2160/3750]  eta: 0:12:38  Lr: 0.001875  Loss: -0.7608  Acc@1: 87.5000 (81.9528)  Acc@5: 100.0000 (99.0947)  time: 0.6835  data: 0.0006  max mem: 2503
Train: Epoch[5/5]  [2170/3750]  eta: 0:12:35  Lr: 0.001875  Loss: -0.3000  Acc@1: 81.2500 (81.9467)  Acc@5: 100.0000 (99.0874)  time: 0.6797  data: 0.0008  max mem: 2503
Train: Epoch[5/5]  [2180/3750]  eta: 0:12:31  Lr: 0.001875  Loss: -0.6655  Acc@1: 81.2500 (81.9435)  Acc@5: 100.0000 (99.0830)  time: 0.6802  data: 0.0009  max mem: 2503
Train: Epoch[5/5]  [2190/3750]  eta: 0:12:28  Lr: 0.001875  Loss: -0.7430  Acc@1: 81.2500 (81.9346)  Acc@5: 100.0000 (99.0815)  time: 0.6772  data: 0.0008  max mem: 2503
Train: Epoch[5/5]  [2200/3750]  eta: 0:12:24  Lr: 0.001875  Loss: -0.8984  Acc@1: 81.2500 (81.9372)  Acc@5: 100.0000 (99.0856)  time: 0.6735  data: 0.0008  max mem: 2503
Train: Epoch[5/5]  [2210/3750]  eta: 0:12:21  Lr: 0.001875  Loss: -0.7090  Acc@1: 75.0000 (81.9313)  Acc@5: 100.0000 (99.0898)  time: 0.6646  data: 0.0018  max mem: 2503
Train: Epoch[5/5]  [2220/3750]  eta: 0:12:17  Lr: 0.001875  Loss: -0.6263  Acc@1: 81.2500 (81.9507)  Acc@5: 100.0000 (99.0826)  time: 0.6730  data: 0.0016  max mem: 2503
Train: Epoch[5/5]  [2230/3750]  eta: 0:12:14  Lr: 0.001875  Loss: -0.9123  Acc@1: 87.5000 (81.9644)  Acc@5: 100.0000 (99.0839)  time: 0.6859  data: 0.0006  max mem: 2503
Train: Epoch[5/5]  [2240/3750]  eta: 0:12:10  Lr: 0.001875  Loss: -0.3937  Acc@1: 87.5000 (81.9556)  Acc@5: 100.0000 (99.0852)  time: 0.6759  data: 0.0006  max mem: 2503
Train: Epoch[5/5]  [2250/3750]  eta: 0:12:07  Lr: 0.001875  Loss: -0.1241  Acc@1: 81.2500 (81.9525)  Acc@5: 100.0000 (99.0810)  time: 0.6732  data: 0.0007  max mem: 2503
Train: Epoch[5/5]  [2260/3750]  eta: 0:12:03  Lr: 0.001875  Loss: -0.8420  Acc@1: 81.2500 (81.9549)  Acc@5: 100.0000 (99.0795)  time: 0.6720  data: 0.0007  max mem: 2503
Train: Epoch[5/5]  [2270/3750]  eta: 0:12:00  Lr: 0.001875  Loss: -0.2080  Acc@1: 81.2500 (81.9435)  Acc@5: 100.0000 (99.0753)  time: 0.6694  data: 0.0007  max mem: 2503
Train: Epoch[5/5]  [2280/3750]  eta: 0:11:56  Lr: 0.001875  Loss: -0.9450  Acc@1: 87.5000 (81.9843)  Acc@5: 100.0000 (99.0794)  time: 0.6825  data: 0.0007  max mem: 2503
Train: Epoch[5/5]  [2290/3750]  eta: 0:11:52  Lr: 0.001875  Loss: -0.7589  Acc@1: 87.5000 (81.9893)  Acc@5: 100.0000 (99.0834)  time: 0.6793  data: 0.0012  max mem: 2503
Train: Epoch[5/5]  [2300/3750]  eta: 0:11:49  Lr: 0.001875  Loss: -0.5585  Acc@1: 81.2500 (81.9915)  Acc@5: 100.0000 (99.0819)  time: 0.6705  data: 0.0013  max mem: 2503
Train: Epoch[5/5]  [2310/3750]  eta: 0:11:45  Lr: 0.001875  Loss: -0.6106  Acc@1: 81.2500 (81.9748)  Acc@5: 100.0000 (99.0805)  time: 0.6759  data: 0.0007  max mem: 2503
Train: Epoch[5/5]  [2320/3750]  eta: 0:11:41  Lr: 0.001875  Loss: -0.5634  Acc@1: 81.2500 (81.9824)  Acc@5: 100.0000 (99.0818)  time: 0.6807  data: 0.0007  max mem: 2503
Train: Epoch[5/5]  [2330/3750]  eta: 0:11:37  Lr: 0.001875  Loss: -0.4924  Acc@1: 81.2500 (81.9686)  Acc@5: 100.0000 (99.0750)  time: 0.6788  data: 0.0009  max mem: 2503
Train: Epoch[5/5]  [2340/3750]  eta: 0:11:34  Lr: 0.001875  Loss: -0.1647  Acc@1: 75.0000 (81.9522)  Acc@5: 100.0000 (99.0736)  time: 0.6779  data: 0.0008  max mem: 2503
Train: Epoch[5/5]  [2350/3750]  eta: 0:11:30  Lr: 0.001875  Loss: -0.8829  Acc@1: 87.5000 (81.9545)  Acc@5: 100.0000 (99.0775)  time: 0.6792  data: 0.0006  max mem: 2503
Train: Epoch[5/5]  [2360/3750]  eta: 0:11:26  Lr: 0.001875  Loss: -0.8610  Acc@1: 87.5000 (81.9912)  Acc@5: 100.0000 (99.0814)  time: 0.6795  data: 0.0006  max mem: 2503
Train: Epoch[5/5]  [2370/3750]  eta: 0:11:22  Lr: 0.001875  Loss: -0.4864  Acc@1: 87.5000 (81.9881)  Acc@5: 100.0000 (99.0827)  time: 0.6722  data: 0.0007  max mem: 2503
Train: Epoch[5/5]  [2380/3750]  eta: 0:11:18  Lr: 0.001875  Loss: -0.4181  Acc@1: 81.2500 (81.9902)  Acc@5: 100.0000 (99.0865)  time: 0.6634  data: 0.0007  max mem: 2503
Train: Epoch[5/5]  [2390/3750]  eta: 0:11:14  Lr: 0.001875  Loss: -1.0056  Acc@1: 87.5000 (82.0107)  Acc@5: 100.0000 (99.0877)  time: 0.6665  data: 0.0007  max mem: 2503
Train: Epoch[5/5]  [2400/3750]  eta: 0:11:10  Lr: 0.001875  Loss: -0.6751  Acc@1: 87.5000 (82.0179)  Acc@5: 100.0000 (99.0863)  time: 0.6524  data: 0.0008  max mem: 2503
Train: Epoch[5/5]  [2410/3750]  eta: 0:11:06  Lr: 0.001875  Loss: -0.3947  Acc@1: 81.2500 (82.0095)  Acc@5: 100.0000 (99.0875)  time: 0.6566  data: 0.0014  max mem: 2503
Train: Epoch[5/5]  [2420/3750]  eta: 0:11:02  Lr: 0.001875  Loss: -0.6557  Acc@1: 81.2500 (82.0064)  Acc@5: 100.0000 (99.0835)  time: 0.6619  data: 0.0018  max mem: 2503
Train: Epoch[5/5]  [2430/3750]  eta: 0:10:56  Lr: 0.001875  Loss: -0.4840  Acc@1: 81.2500 (82.0161)  Acc@5: 100.0000 (99.0873)  time: 0.4984  data: 0.0022  max mem: 2503
Train: Epoch[5/5]  [2440/3750]  eta: 0:10:51  Lr: 0.001875  Loss: -0.6165  Acc@1: 81.2500 (82.0079)  Acc@5: 100.0000 (99.0859)  time: 0.4615  data: 0.0021  max mem: 2503
Train: Epoch[5/5]  [2450/3750]  eta: 0:10:47  Lr: 0.001875  Loss: -0.0973  Acc@1: 87.5000 (82.0099)  Acc@5: 100.0000 (99.0871)  time: 0.6163  data: 0.0011  max mem: 2503
Train: Epoch[5/5]  [2460/3750]  eta: 0:10:42  Lr: 0.001875  Loss: -0.7001  Acc@1: 81.2500 (81.9966)  Acc@5: 100.0000 (99.0857)  time: 0.5437  data: 0.0007  max mem: 2503
Train: Epoch[5/5]  [2470/3750]  eta: 0:10:36  Lr: 0.001875  Loss: -0.8397  Acc@1: 81.2500 (82.0164)  Acc@5: 100.0000 (99.0793)  time: 0.3898  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [2480/3750]  eta: 0:10:31  Lr: 0.001875  Loss: -0.5280  Acc@1: 81.2500 (82.0057)  Acc@5: 100.0000 (99.0780)  time: 0.3536  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [2490/3750]  eta: 0:10:25  Lr: 0.001875  Loss: -0.6909  Acc@1: 81.2500 (82.0027)  Acc@5: 100.0000 (99.0792)  time: 0.3517  data: 0.0006  max mem: 2503
Train: Epoch[5/5]  [2500/3750]  eta: 0:10:19  Lr: 0.001875  Loss: -0.5113  Acc@1: 81.2500 (82.0172)  Acc@5: 100.0000 (99.0829)  time: 0.3578  data: 0.0022  max mem: 2503
Train: Epoch[5/5]  [2510/3750]  eta: 0:10:14  Lr: 0.001875  Loss: -0.7064  Acc@1: 81.2500 (81.9967)  Acc@5: 100.0000 (99.0840)  time: 0.3624  data: 0.0026  max mem: 2503
Train: Epoch[5/5]  [2520/3750]  eta: 0:10:09  Lr: 0.001875  Loss: -0.6856  Acc@1: 81.2500 (82.0086)  Acc@5: 100.0000 (99.0852)  time: 0.4282  data: 0.0022  max mem: 2503
Train: Epoch[5/5]  [2530/3750]  eta: 0:10:05  Lr: 0.001875  Loss: -0.5391  Acc@1: 81.2500 (82.0007)  Acc@5: 100.0000 (99.0888)  time: 0.5947  data: 0.0019  max mem: 2503
Train: Epoch[5/5]  [2540/3750]  eta: 0:10:01  Lr: 0.001875  Loss: -0.7416  Acc@1: 81.2500 (81.9928)  Acc@5: 100.0000 (99.0875)  time: 0.6885  data: 0.0006  max mem: 2503
Train: Epoch[5/5]  [2550/3750]  eta: 0:09:56  Lr: 0.001875  Loss: -0.0912  Acc@1: 81.2500 (81.9850)  Acc@5: 100.0000 (99.0812)  time: 0.6628  data: 0.0007  max mem: 2503
Train: Epoch[5/5]  [2560/3750]  eta: 0:09:52  Lr: 0.001875  Loss: -0.4624  Acc@1: 81.2500 (81.9919)  Acc@5: 100.0000 (99.0775)  time: 0.6581  data: 0.0014  max mem: 2503
Train: Epoch[5/5]  [2570/3750]  eta: 0:09:48  Lr: 0.001875  Loss: -0.3764  Acc@1: 81.2500 (81.9769)  Acc@5: 100.0000 (99.0787)  time: 0.6796  data: 0.0013  max mem: 2503
Train: Epoch[5/5]  [2580/3750]  eta: 0:09:44  Lr: 0.001875  Loss: -0.6654  Acc@1: 81.2500 (81.9716)  Acc@5: 100.0000 (99.0822)  time: 0.6838  data: 0.0013  max mem: 2503
Train: Epoch[5/5]  [2590/3750]  eta: 0:09:40  Lr: 0.001875  Loss: -0.2568  Acc@1: 81.2500 (81.9809)  Acc@5: 100.0000 (99.0858)  time: 0.6856  data: 0.0013  max mem: 2503
Train: Epoch[5/5]  [2600/3750]  eta: 0:09:35  Lr: 0.001875  Loss: -0.6907  Acc@1: 81.2500 (81.9733)  Acc@5: 100.0000 (99.0893)  time: 0.6663  data: 0.0012  max mem: 2503
Train: Epoch[5/5]  [2610/3750]  eta: 0:09:31  Lr: 0.001875  Loss: -0.0647  Acc@1: 81.2500 (81.9466)  Acc@5: 100.0000 (99.0880)  time: 0.6641  data: 0.0012  max mem: 2503
Train: Epoch[5/5]  [2620/3750]  eta: 0:09:27  Lr: 0.001875  Loss: -0.7106  Acc@1: 81.2500 (81.9487)  Acc@5: 100.0000 (99.0891)  time: 0.6742  data: 0.0006  max mem: 2503
Train: Epoch[5/5]  [2630/3750]  eta: 0:09:23  Lr: 0.001875  Loss: -0.8035  Acc@1: 81.2500 (81.9674)  Acc@5: 100.0000 (99.0878)  time: 0.6717  data: 0.0006  max mem: 2503
Train: Epoch[5/5]  [2640/3750]  eta: 0:09:18  Lr: 0.001875  Loss: -0.5063  Acc@1: 81.2500 (81.9458)  Acc@5: 100.0000 (99.0842)  time: 0.6692  data: 0.0009  max mem: 2503
Train: Epoch[5/5]  [2650/3750]  eta: 0:09:14  Lr: 0.001875  Loss: -0.7431  Acc@1: 81.2500 (81.9502)  Acc@5: 100.0000 (99.0829)  time: 0.6668  data: 0.0010  max mem: 2503
Train: Epoch[5/5]  [2660/3750]  eta: 0:09:09  Lr: 0.001875  Loss: -0.8320  Acc@1: 81.2500 (81.9476)  Acc@5: 100.0000 (99.0793)  time: 0.6670  data: 0.0006  max mem: 2503
Train: Epoch[5/5]  [2670/3750]  eta: 0:09:05  Lr: 0.001875  Loss: -0.6822  Acc@1: 81.2500 (81.9520)  Acc@5: 100.0000 (99.0804)  time: 0.6632  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [2680/3750]  eta: 0:09:01  Lr: 0.001875  Loss: -0.6762  Acc@1: 81.2500 (81.9330)  Acc@5: 100.0000 (99.0815)  time: 0.6608  data: 0.0006  max mem: 2503
Train: Epoch[5/5]  [2690/3750]  eta: 0:08:56  Lr: 0.001875  Loss: -0.8128  Acc@1: 81.2500 (81.9328)  Acc@5: 100.0000 (99.0803)  time: 0.6532  data: 0.0006  max mem: 2503
Train: Epoch[5/5]  [2700/3750]  eta: 0:08:52  Lr: 0.001875  Loss: -0.8568  Acc@1: 81.2500 (81.9488)  Acc@5: 100.0000 (99.0814)  time: 0.6683  data: 0.0006  max mem: 2503
Train: Epoch[5/5]  [2710/3750]  eta: 0:08:47  Lr: 0.001875  Loss: -0.7429  Acc@1: 87.5000 (81.9647)  Acc@5: 100.0000 (99.0801)  time: 0.6745  data: 0.0007  max mem: 2503
Train: Epoch[5/5]  [2720/3750]  eta: 0:08:43  Lr: 0.001875  Loss: -0.3375  Acc@1: 87.5000 (81.9621)  Acc@5: 100.0000 (99.0835)  time: 0.6644  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [2730/3750]  eta: 0:08:38  Lr: 0.001875  Loss: -0.6557  Acc@1: 81.2500 (81.9503)  Acc@5: 100.0000 (99.0846)  time: 0.6684  data: 0.0008  max mem: 2503
Train: Epoch[5/5]  [2740/3750]  eta: 0:08:34  Lr: 0.001875  Loss: -0.5806  Acc@1: 81.2500 (81.9705)  Acc@5: 100.0000 (99.0811)  time: 0.6696  data: 0.0009  max mem: 2503
Train: Epoch[5/5]  [2750/3750]  eta: 0:08:29  Lr: 0.001875  Loss: -0.5024  Acc@1: 81.2500 (81.9747)  Acc@5: 100.0000 (99.0822)  time: 0.6702  data: 0.0007  max mem: 2503
Train: Epoch[5/5]  [2760/3750]  eta: 0:08:25  Lr: 0.001875  Loss: -0.6216  Acc@1: 81.2500 (81.9698)  Acc@5: 100.0000 (99.0832)  time: 0.6754  data: 0.0007  max mem: 2503
Train: Epoch[5/5]  [2770/3750]  eta: 0:08:20  Lr: 0.001875  Loss: -0.6301  Acc@1: 81.2500 (81.9740)  Acc@5: 100.0000 (99.0843)  time: 0.6811  data: 0.0014  max mem: 2503
Train: Epoch[5/5]  [2780/3750]  eta: 0:08:16  Lr: 0.001875  Loss: -0.9355  Acc@1: 81.2500 (81.9692)  Acc@5: 100.0000 (99.0853)  time: 0.6734  data: 0.0014  max mem: 2503
Train: Epoch[5/5]  [2790/3750]  eta: 0:08:11  Lr: 0.001875  Loss: -0.4588  Acc@1: 81.2500 (81.9643)  Acc@5: 100.0000 (99.0886)  time: 0.6736  data: 0.0009  max mem: 2503
Train: Epoch[5/5]  [2800/3750]  eta: 0:08:07  Lr: 0.001875  Loss: -0.4217  Acc@1: 81.2500 (81.9707)  Acc@5: 100.0000 (99.0896)  time: 0.6857  data: 0.0016  max mem: 2503
Train: Epoch[5/5]  [2810/3750]  eta: 0:08:02  Lr: 0.001875  Loss: -0.6407  Acc@1: 81.2500 (81.9637)  Acc@5: 100.0000 (99.0884)  time: 0.6856  data: 0.0013  max mem: 2503
Train: Epoch[5/5]  [2820/3750]  eta: 0:07:57  Lr: 0.001875  Loss: -0.8903  Acc@1: 81.2500 (81.9811)  Acc@5: 100.0000 (99.0872)  time: 0.6683  data: 0.0007  max mem: 2503
Train: Epoch[5/5]  [2830/3750]  eta: 0:07:53  Lr: 0.001875  Loss: -0.7826  Acc@1: 87.5000 (82.0006)  Acc@5: 100.0000 (99.0904)  time: 0.6671  data: 0.0007  max mem: 2503
Train: Epoch[5/5]  [2840/3750]  eta: 0:07:48  Lr: 0.001875  Loss: -0.6704  Acc@1: 87.5000 (82.0046)  Acc@5: 100.0000 (99.0936)  time: 0.6810  data: 0.0006  max mem: 2503
Train: Epoch[5/5]  [2850/3750]  eta: 0:07:44  Lr: 0.001875  Loss: -0.4527  Acc@1: 81.2500 (81.9954)  Acc@5: 100.0000 (99.0968)  time: 0.6828  data: 0.0006  max mem: 2503
Train: Epoch[5/5]  [2860/3750]  eta: 0:07:39  Lr: 0.001875  Loss: -0.6187  Acc@1: 81.2500 (81.9927)  Acc@5: 100.0000 (99.0956)  time: 0.6789  data: 0.0007  max mem: 2503
Train: Epoch[5/5]  [2870/3750]  eta: 0:07:34  Lr: 0.001875  Loss: -0.4109  Acc@1: 81.2500 (81.9923)  Acc@5: 100.0000 (99.0966)  time: 0.6786  data: 0.0007  max mem: 2503
Train: Epoch[5/5]  [2880/3750]  eta: 0:07:29  Lr: 0.001875  Loss: -0.6717  Acc@1: 81.2500 (81.9876)  Acc@5: 100.0000 (99.0932)  time: 0.5500  data: 0.0007  max mem: 2503
Train: Epoch[5/5]  [2890/3750]  eta: 0:07:23  Lr: 0.001875  Loss: -0.8052  Acc@1: 81.2500 (81.9958)  Acc@5: 100.0000 (99.0942)  time: 0.3844  data: 0.0007  max mem: 2503
Train: Epoch[5/5]  [2900/3750]  eta: 0:07:18  Lr: 0.001875  Loss: -0.3918  Acc@1: 87.5000 (82.0148)  Acc@5: 100.0000 (99.0908)  time: 0.3570  data: 0.0014  max mem: 2503
Train: Epoch[5/5]  [2910/3750]  eta: 0:07:12  Lr: 0.001875  Loss: -0.6562  Acc@1: 87.5000 (82.0165)  Acc@5: 100.0000 (99.0918)  time: 0.3608  data: 0.0028  max mem: 2503
Train: Epoch[5/5]  [2920/3750]  eta: 0:07:06  Lr: 0.001875  Loss: -0.9809  Acc@1: 81.2500 (82.0224)  Acc@5: 100.0000 (99.0949)  time: 0.3628  data: 0.0021  max mem: 2503
Train: Epoch[5/5]  [2930/3750]  eta: 0:07:01  Lr: 0.001875  Loss: -0.4382  Acc@1: 81.2500 (82.0177)  Acc@5: 100.0000 (99.0959)  time: 0.3637  data: 0.0025  max mem: 2503
Train: Epoch[5/5]  [2940/3750]  eta: 0:06:55  Lr: 0.001875  Loss: -0.6693  Acc@1: 81.2500 (82.0235)  Acc@5: 100.0000 (99.0968)  time: 0.3653  data: 0.0030  max mem: 2503
Train: Epoch[5/5]  [2950/3750]  eta: 0:06:50  Lr: 0.001875  Loss: -0.5910  Acc@1: 87.5000 (82.0273)  Acc@5: 100.0000 (99.0978)  time: 0.3712  data: 0.0058  max mem: 2503
Train: Epoch[5/5]  [2960/3750]  eta: 0:06:44  Lr: 0.001875  Loss: -0.8043  Acc@1: 81.2500 (82.0289)  Acc@5: 100.0000 (99.1008)  time: 0.3743  data: 0.0072  max mem: 2503
Train: Epoch[5/5]  [2970/3750]  eta: 0:06:39  Lr: 0.001875  Loss: -0.7072  Acc@1: 81.2500 (82.0115)  Acc@5: 100.0000 (99.0996)  time: 0.3687  data: 0.0042  max mem: 2503
Train: Epoch[5/5]  [2980/3750]  eta: 0:06:33  Lr: 0.001875  Loss: -0.7101  Acc@1: 81.2500 (82.0195)  Acc@5: 100.0000 (99.1006)  time: 0.3637  data: 0.0045  max mem: 2503
Train: Epoch[5/5]  [2990/3750]  eta: 0:06:28  Lr: 0.001875  Loss: -0.5220  Acc@1: 81.2500 (82.0169)  Acc@5: 100.0000 (99.1015)  time: 0.3658  data: 0.0063  max mem: 2503
Train: Epoch[5/5]  [3000/3750]  eta: 0:06:22  Lr: 0.001875  Loss: -0.6423  Acc@1: 81.2500 (82.0143)  Acc@5: 100.0000 (99.1024)  time: 0.3624  data: 0.0045  max mem: 2503
Train: Epoch[5/5]  [3010/3750]  eta: 0:06:17  Lr: 0.001875  Loss: -0.6376  Acc@1: 81.2500 (82.0242)  Acc@5: 100.0000 (99.1033)  time: 0.3579  data: 0.0021  max mem: 2503
Train: Epoch[5/5]  [3020/3750]  eta: 0:06:11  Lr: 0.001875  Loss: -0.3142  Acc@1: 81.2500 (82.0031)  Acc@5: 100.0000 (99.1021)  time: 0.3622  data: 0.0047  max mem: 2503
Train: Epoch[5/5]  [3030/3750]  eta: 0:06:06  Lr: 0.001875  Loss: -0.8923  Acc@1: 81.2500 (82.0068)  Acc@5: 100.0000 (99.1051)  time: 0.3622  data: 0.0054  max mem: 2503
Train: Epoch[5/5]  [3040/3750]  eta: 0:06:00  Lr: 0.001875  Loss: -0.5111  Acc@1: 81.2500 (82.0002)  Acc@5: 100.0000 (99.1080)  time: 0.3584  data: 0.0039  max mem: 2503
Train: Epoch[5/5]  [3050/3750]  eta: 0:05:55  Lr: 0.001875  Loss: -0.1576  Acc@1: 81.2500 (82.0018)  Acc@5: 100.0000 (99.1109)  time: 0.3646  data: 0.0029  max mem: 2503
Train: Epoch[5/5]  [3060/3750]  eta: 0:05:50  Lr: 0.001875  Loss: -0.7728  Acc@1: 81.2500 (82.0116)  Acc@5: 100.0000 (99.1098)  time: 0.3638  data: 0.0023  max mem: 2503
Train: Epoch[5/5]  [3070/3750]  eta: 0:05:44  Lr: 0.001875  Loss: -0.5986  Acc@1: 81.2500 (82.0010)  Acc@5: 100.0000 (99.1066)  time: 0.3636  data: 0.0034  max mem: 2503
Train: Epoch[5/5]  [3080/3750]  eta: 0:05:39  Lr: 0.001875  Loss: -0.5195  Acc@1: 81.2500 (82.0127)  Acc@5: 100.0000 (99.1054)  time: 0.3632  data: 0.0028  max mem: 2503
Train: Epoch[5/5]  [3090/3750]  eta: 0:05:34  Lr: 0.001875  Loss: -0.2985  Acc@1: 81.2500 (82.0103)  Acc@5: 100.0000 (99.1063)  time: 0.3625  data: 0.0027  max mem: 2503
Train: Epoch[5/5]  [3100/3750]  eta: 0:05:28  Lr: 0.001875  Loss: -0.4250  Acc@1: 81.2500 (82.0078)  Acc@5: 100.0000 (99.1011)  time: 0.3646  data: 0.0038  max mem: 2503
Train: Epoch[5/5]  [3110/3750]  eta: 0:05:23  Lr: 0.001875  Loss: -0.3576  Acc@1: 81.2500 (81.9913)  Acc@5: 100.0000 (99.1000)  time: 0.3670  data: 0.0038  max mem: 2503
Train: Epoch[5/5]  [3120/3750]  eta: 0:05:18  Lr: 0.001875  Loss: -0.4395  Acc@1: 81.2500 (81.9849)  Acc@5: 100.0000 (99.1008)  time: 0.3702  data: 0.0037  max mem: 2503
Train: Epoch[5/5]  [3130/3750]  eta: 0:05:12  Lr: 0.001875  Loss: -0.4182  Acc@1: 75.0000 (81.9706)  Acc@5: 100.0000 (99.0977)  time: 0.3624  data: 0.0028  max mem: 2503
Train: Epoch[5/5]  [3140/3750]  eta: 0:05:07  Lr: 0.001875  Loss: 0.0648  Acc@1: 81.2500 (81.9663)  Acc@5: 100.0000 (99.0986)  time: 0.3599  data: 0.0037  max mem: 2503
Train: Epoch[5/5]  [3150/3750]  eta: 0:05:02  Lr: 0.001875  Loss: -0.5704  Acc@1: 81.2500 (81.9601)  Acc@5: 100.0000 (99.0995)  time: 0.3646  data: 0.0038  max mem: 2503
Train: Epoch[5/5]  [3160/3750]  eta: 0:04:56  Lr: 0.001875  Loss: -0.5998  Acc@1: 81.2500 (81.9598)  Acc@5: 100.0000 (99.1004)  time: 0.3666  data: 0.0058  max mem: 2503
Train: Epoch[5/5]  [3170/3750]  eta: 0:04:51  Lr: 0.001875  Loss: -0.4936  Acc@1: 81.2500 (81.9596)  Acc@5: 100.0000 (99.1032)  time: 0.3656  data: 0.0080  max mem: 2503
Train: Epoch[5/5]  [3180/3750]  eta: 0:04:46  Lr: 0.001875  Loss: -0.4396  Acc@1: 81.2500 (81.9534)  Acc@5: 100.0000 (99.1001)  time: 0.3614  data: 0.0045  max mem: 2503
Train: Epoch[5/5]  [3190/3750]  eta: 0:04:40  Lr: 0.001875  Loss: -0.7584  Acc@1: 81.2500 (81.9551)  Acc@5: 100.0000 (99.1029)  time: 0.3644  data: 0.0033  max mem: 2503
Train: Epoch[5/5]  [3200/3750]  eta: 0:04:35  Lr: 0.001875  Loss: -0.3135  Acc@1: 81.2500 (81.9568)  Acc@5: 100.0000 (99.1018)  time: 0.3697  data: 0.0046  max mem: 2503
Train: Epoch[5/5]  [3210/3750]  eta: 0:04:30  Lr: 0.001875  Loss: -0.5926  Acc@1: 81.2500 (81.9624)  Acc@5: 100.0000 (99.1046)  time: 0.3678  data: 0.0044  max mem: 2503
Train: Epoch[5/5]  [3220/3750]  eta: 0:04:25  Lr: 0.001875  Loss: -0.6453  Acc@1: 81.2500 (81.9641)  Acc@5: 100.0000 (99.1055)  time: 0.3627  data: 0.0035  max mem: 2503
Train: Epoch[5/5]  [3230/3750]  eta: 0:04:19  Lr: 0.001875  Loss: -0.8203  Acc@1: 81.2500 (81.9793)  Acc@5: 100.0000 (99.1063)  time: 0.3591  data: 0.0028  max mem: 2503
Train: Epoch[5/5]  [3240/3750]  eta: 0:04:14  Lr: 0.001875  Loss: -0.5752  Acc@1: 87.5000 (81.9905)  Acc@5: 100.0000 (99.1091)  time: 0.3622  data: 0.0039  max mem: 2503
Train: Epoch[5/5]  [3250/3750]  eta: 0:04:09  Lr: 0.001875  Loss: -0.3993  Acc@1: 81.2500 (81.9805)  Acc@5: 100.0000 (99.1118)  time: 0.3670  data: 0.0039  max mem: 2503
Train: Epoch[5/5]  [3260/3750]  eta: 0:04:04  Lr: 0.001875  Loss: -0.4444  Acc@1: 75.0000 (81.9841)  Acc@5: 100.0000 (99.1107)  time: 0.3669  data: 0.0034  max mem: 2503
Train: Epoch[5/5]  [3270/3750]  eta: 0:03:59  Lr: 0.001875  Loss: -0.8077  Acc@1: 81.2500 (81.9990)  Acc@5: 100.0000 (99.1096)  time: 0.3684  data: 0.0059  max mem: 2503
Train: Epoch[5/5]  [3280/3750]  eta: 0:03:54  Lr: 0.001875  Loss: -0.6271  Acc@1: 87.5000 (82.0062)  Acc@5: 100.0000 (99.1104)  time: 0.3738  data: 0.0122  max mem: 2503
Train: Epoch[5/5]  [3290/3750]  eta: 0:03:48  Lr: 0.001875  Loss: -0.6787  Acc@1: 81.2500 (82.0040)  Acc@5: 100.0000 (99.1112)  time: 0.3658  data: 0.0085  max mem: 2503
Train: Epoch[5/5]  [3300/3750]  eta: 0:03:43  Lr: 0.001875  Loss: -0.6319  Acc@1: 81.2500 (82.0073)  Acc@5: 100.0000 (99.1101)  time: 0.3574  data: 0.0015  max mem: 2503
Train: Epoch[5/5]  [3310/3750]  eta: 0:03:38  Lr: 0.001875  Loss: -0.6639  Acc@1: 81.2500 (81.9994)  Acc@5: 100.0000 (99.1053)  time: 0.3601  data: 0.0029  max mem: 2503
Train: Epoch[5/5]  [3320/3750]  eta: 0:03:33  Lr: 0.001875  Loss: -0.3720  Acc@1: 81.2500 (81.9915)  Acc@5: 100.0000 (99.1023)  time: 0.3680  data: 0.0037  max mem: 2503
Train: Epoch[5/5]  [3330/3750]  eta: 0:03:28  Lr: 0.001875  Loss: -0.7775  Acc@1: 81.2500 (81.9743)  Acc@5: 100.0000 (99.1031)  time: 0.3728  data: 0.0036  max mem: 2503
Train: Epoch[5/5]  [3340/3750]  eta: 0:03:23  Lr: 0.001875  Loss: -0.7252  Acc@1: 81.2500 (81.9740)  Acc@5: 100.0000 (99.1039)  time: 0.3693  data: 0.0038  max mem: 2503
Train: Epoch[5/5]  [3350/3750]  eta: 0:03:18  Lr: 0.001875  Loss: -0.6771  Acc@1: 81.2500 (81.9625)  Acc@5: 100.0000 (99.1047)  time: 0.3620  data: 0.0035  max mem: 2503
Train: Epoch[5/5]  [3360/3750]  eta: 0:03:12  Lr: 0.001875  Loss: -0.5702  Acc@1: 81.2500 (81.9641)  Acc@5: 100.0000 (99.1055)  time: 0.3572  data: 0.0040  max mem: 2503
Train: Epoch[5/5]  [3370/3750]  eta: 0:03:07  Lr: 0.001875  Loss: -0.5466  Acc@1: 81.2500 (81.9582)  Acc@5: 100.0000 (99.1026)  time: 0.3621  data: 0.0049  max mem: 2503
Train: Epoch[5/5]  [3380/3750]  eta: 0:03:02  Lr: 0.001875  Loss: -0.2864  Acc@1: 81.2500 (81.9580)  Acc@5: 100.0000 (99.0942)  time: 0.3641  data: 0.0034  max mem: 2503
Train: Epoch[5/5]  [3390/3750]  eta: 0:02:57  Lr: 0.001875  Loss: -0.3902  Acc@1: 81.2500 (81.9651)  Acc@5: 100.0000 (99.0932)  time: 0.3637  data: 0.0035  max mem: 2503
Train: Epoch[5/5]  [3400/3750]  eta: 0:02:52  Lr: 0.001875  Loss: -0.8634  Acc@1: 81.2500 (81.9667)  Acc@5: 100.0000 (99.0922)  time: 0.3689  data: 0.0058  max mem: 2503
Train: Epoch[5/5]  [3410/3750]  eta: 0:02:47  Lr: 0.001875  Loss: -0.5172  Acc@1: 81.2500 (81.9628)  Acc@5: 100.0000 (99.0930)  time: 0.3704  data: 0.0049  max mem: 2503
Train: Epoch[5/5]  [3420/3750]  eta: 0:02:42  Lr: 0.001875  Loss: -0.3986  Acc@1: 81.2500 (81.9625)  Acc@5: 100.0000 (99.0920)  time: 0.3653  data: 0.0045  max mem: 2503
Train: Epoch[5/5]  [3430/3750]  eta: 0:02:37  Lr: 0.001875  Loss: -0.7279  Acc@1: 81.2500 (81.9695)  Acc@5: 100.0000 (99.0947)  time: 0.3639  data: 0.0036  max mem: 2503
Train: Epoch[5/5]  [3440/3750]  eta: 0:02:32  Lr: 0.001875  Loss: -0.5286  Acc@1: 81.2500 (81.9747)  Acc@5: 100.0000 (99.0955)  time: 0.3702  data: 0.0034  max mem: 2503
Train: Epoch[5/5]  [3450/3750]  eta: 0:02:27  Lr: 0.001875  Loss: -0.6168  Acc@1: 81.2500 (81.9762)  Acc@5: 100.0000 (99.0981)  time: 0.3729  data: 0.0044  max mem: 2503
Train: Epoch[5/5]  [3460/3750]  eta: 0:02:22  Lr: 0.001875  Loss: -0.4657  Acc@1: 81.2500 (81.9687)  Acc@5: 100.0000 (99.0971)  time: 0.3741  data: 0.0041  max mem: 2503
Train: Epoch[5/5]  [3470/3750]  eta: 0:02:17  Lr: 0.001875  Loss: -0.6991  Acc@1: 81.2500 (81.9576)  Acc@5: 100.0000 (99.0943)  time: 0.3756  data: 0.0049  max mem: 2503
Train: Epoch[5/5]  [3480/3750]  eta: 0:02:12  Lr: 0.001875  Loss: -0.4440  Acc@1: 81.2500 (81.9538)  Acc@5: 100.0000 (99.0951)  time: 0.3684  data: 0.0038  max mem: 2503
Train: Epoch[5/5]  [3490/3750]  eta: 0:02:07  Lr: 0.001875  Loss: -0.6636  Acc@1: 81.2500 (81.9554)  Acc@5: 100.0000 (99.0959)  time: 0.3625  data: 0.0042  max mem: 2503
Train: Epoch[5/5]  [3500/3750]  eta: 0:02:02  Lr: 0.001875  Loss: -0.7923  Acc@1: 81.2500 (81.9552)  Acc@5: 100.0000 (99.0949)  time: 0.3619  data: 0.0045  max mem: 2503
Train: Epoch[5/5]  [3510/3750]  eta: 0:01:57  Lr: 0.001875  Loss: -0.6800  Acc@1: 75.0000 (81.9425)  Acc@5: 100.0000 (99.0886)  time: 0.3668  data: 0.0038  max mem: 2503
Train: Epoch[5/5]  [3520/3750]  eta: 0:01:52  Lr: 0.001875  Loss: -0.6906  Acc@1: 75.0000 (81.9440)  Acc@5: 100.0000 (99.0912)  time: 0.3696  data: 0.0039  max mem: 2503
Train: Epoch[5/5]  [3530/3750]  eta: 0:01:47  Lr: 0.001875  Loss: -0.4119  Acc@1: 87.5000 (81.9421)  Acc@5: 100.0000 (99.0937)  time: 0.3680  data: 0.0043  max mem: 2503
Train: Epoch[5/5]  [3540/3750]  eta: 0:01:42  Lr: 0.001875  Loss: -0.7951  Acc@1: 81.2500 (81.9366)  Acc@5: 100.0000 (99.0928)  time: 0.3639  data: 0.0040  max mem: 2503
Train: Epoch[5/5]  [3550/3750]  eta: 0:01:37  Lr: 0.001875  Loss: -0.8962  Acc@1: 81.2500 (81.9382)  Acc@5: 100.0000 (99.0953)  time: 0.3594  data: 0.0051  max mem: 2503
Train: Epoch[5/5]  [3560/3750]  eta: 0:01:32  Lr: 0.001875  Loss: -0.2483  Acc@1: 81.2500 (81.9415)  Acc@5: 100.0000 (99.0944)  time: 0.3608  data: 0.0050  max mem: 2503
Train: Epoch[5/5]  [3570/3750]  eta: 0:01:27  Lr: 0.001875  Loss: -0.7358  Acc@1: 81.2500 (81.9483)  Acc@5: 100.0000 (99.0934)  time: 0.3635  data: 0.0037  max mem: 2503
Train: Epoch[5/5]  [3580/3750]  eta: 0:01:22  Lr: 0.001875  Loss: -0.0924  Acc@1: 81.2500 (81.9359)  Acc@5: 100.0000 (99.0942)  time: 0.3668  data: 0.0041  max mem: 2503
Train: Epoch[5/5]  [3590/3750]  eta: 0:01:17  Lr: 0.001875  Loss: -0.5769  Acc@1: 87.5000 (81.9549)  Acc@5: 100.0000 (99.0967)  time: 0.3691  data: 0.0039  max mem: 2503
Train: Epoch[5/5]  [3600/3750]  eta: 0:01:12  Lr: 0.001875  Loss: -0.7936  Acc@1: 87.5000 (81.9512)  Acc@5: 100.0000 (99.0992)  time: 0.3656  data: 0.0037  max mem: 2503
Train: Epoch[5/5]  [3610/3750]  eta: 0:01:08  Lr: 0.001875  Loss: -0.3842  Acc@1: 81.2500 (81.9406)  Acc@5: 100.0000 (99.1000)  time: 0.3614  data: 0.0024  max mem: 2503
Train: Epoch[5/5]  [3620/3750]  eta: 0:01:03  Lr: 0.001875  Loss: -0.4064  Acc@1: 75.0000 (81.9128)  Acc@5: 100.0000 (99.1007)  time: 0.3637  data: 0.0032  max mem: 2503
Train: Epoch[5/5]  [3630/3750]  eta: 0:00:58  Lr: 0.001875  Loss: -0.5015  Acc@1: 81.2500 (81.9213)  Acc@5: 100.0000 (99.1015)  time: 0.3666  data: 0.0037  max mem: 2503
Train: Epoch[5/5]  [3640/3750]  eta: 0:00:53  Lr: 0.001875  Loss: -0.4619  Acc@1: 81.2500 (81.9212)  Acc@5: 100.0000 (99.1040)  time: 0.3640  data: 0.0041  max mem: 2503
Train: Epoch[5/5]  [3650/3750]  eta: 0:00:48  Lr: 0.001875  Loss: -0.6681  Acc@1: 75.0000 (81.9142)  Acc@5: 100.0000 (99.1064)  time: 0.3612  data: 0.0054  max mem: 2503
Train: Epoch[5/5]  [3660/3750]  eta: 0:00:43  Lr: 0.001875  Loss: -0.5124  Acc@1: 81.2500 (81.9107)  Acc@5: 100.0000 (99.1037)  time: 0.3649  data: 0.0061  max mem: 2503
Train: Epoch[5/5]  [3670/3750]  eta: 0:00:38  Lr: 0.001875  Loss: -0.4727  Acc@1: 81.2500 (81.9089)  Acc@5: 100.0000 (99.1062)  time: 0.3646  data: 0.0046  max mem: 2503
Train: Epoch[5/5]  [3680/3750]  eta: 0:00:33  Lr: 0.001875  Loss: -0.5939  Acc@1: 81.2500 (81.9105)  Acc@5: 100.0000 (99.1035)  time: 0.3627  data: 0.0023  max mem: 2503
Train: Epoch[5/5]  [3690/3750]  eta: 0:00:28  Lr: 0.001875  Loss: -0.1166  Acc@1: 87.5000 (81.9155)  Acc@5: 100.0000 (99.1025)  time: 0.3632  data: 0.0030  max mem: 2503
Train: Epoch[5/5]  [3700/3750]  eta: 0:00:24  Lr: 0.001875  Loss: -0.3957  Acc@1: 81.2500 (81.9086)  Acc@5: 100.0000 (99.1033)  time: 0.3667  data: 0.0077  max mem: 2503
Train: Epoch[5/5]  [3710/3750]  eta: 0:00:19  Lr: 0.001875  Loss: -0.3292  Acc@1: 81.2500 (81.9018)  Acc@5: 100.0000 (99.0973)  time: 0.3763  data: 0.0118  max mem: 2503
Train: Epoch[5/5]  [3720/3750]  eta: 0:00:14  Lr: 0.001875  Loss: -0.5533  Acc@1: 81.2500 (81.9000)  Acc@5: 100.0000 (99.0980)  time: 0.3679  data: 0.0090  max mem: 2503
Train: Epoch[5/5]  [3730/3750]  eta: 0:00:09  Lr: 0.001875  Loss: -0.4324  Acc@1: 81.2500 (81.8866)  Acc@5: 100.0000 (99.0937)  time: 0.3604  data: 0.0060  max mem: 2503
Train: Epoch[5/5]  [3740/3750]  eta: 0:00:04  Lr: 0.001875  Loss: -0.7098  Acc@1: 81.2500 (81.8982)  Acc@5: 100.0000 (99.0928)  time: 0.3609  data: 0.0043  max mem: 2503
Train: Epoch[5/5]  [3749/3750]  eta: 0:00:00  Lr: 0.001875  Loss: -0.6967  Acc@1: 87.5000 (81.9083)  Acc@5: 100.0000 (99.0933)  time: 0.3618  data: 0.0053  max mem: 2503
Train: Epoch[5/5] Total time: 0:30:06 (0.4818 s / it)
{0: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 1: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 2: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 3: {0: 366285, 1: 0, 2: 0, 3: 0, 4: 0}, 4: {0: 0, 1: 300000, 2: 0, 3: 352, 4: 0}, 5: {0: 0, 1: 300000, 2: 0, 3: 352, 4: 0}, 6: {0: 0, 1: 300000, 2: 0, 3: 352, 4: 0}, 7: {0: 0, 1: 300000, 2: 0, 3: 352, 4: 0}, 8: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 9: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 10: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 11: {0: 0, 1: 0, 2: 250000, 3: 0, 4: 0}, 12: {0: 0, 1: 0, 2: 0, 3: 90968, 4: 0}, 13: {0: 0, 1: 0, 2: 0, 3: 90968, 4: 0}, 14: {0: 0, 1: 0, 2: 0, 3: 90968, 4: 0}, 15: {0: 0, 1: 0, 2: 0, 3: 90968, 4: 0}, 16: {0: 0, 1: 0, 2: 0, 3: 0, 4: 300000}, 17: {0: 0, 1: 0, 2: 0, 3: 0, 4: 300000}, 18: {0: 0, 1: 0, 2: 0, 3: 0, 4: 300000}, 19: {0: 0, 1: 0, 2: 0, 3: 0, 4: 300000}}
Averaged stats: Lr: 0.001875  Loss: -0.6967  Acc@1: 87.5000 (81.9083)  Acc@5: 100.0000 (99.0933)
Test: [Task 1]  [   0/1627]  eta: 0:33:28  Loss: 1.3577 (1.3577)  Acc@1: 62.5000 (62.5000)  Acc@5: 93.7500 (93.7500)  time: 1.2346  data: 0.9999  max mem: 2503
Test: [Task 1]  [  10/1627]  eta: 0:08:43  Loss: 1.3202 (1.2144)  Acc@1: 68.7500 (67.6136)  Acc@5: 93.7500 (92.0455)  time: 0.3237  data: 0.0960  max mem: 2503
Test: [Task 1]  [  20/1627]  eta: 0:07:33  Loss: 1.1755 (1.1599)  Acc@1: 75.0000 (69.9405)  Acc@5: 93.7500 (91.9643)  time: 0.2349  data: 0.0069  max mem: 2503
Test: [Task 1]  [  30/1627]  eta: 0:07:02  Loss: 1.1890 (1.1815)  Acc@1: 68.7500 (69.5565)  Acc@5: 93.7500 (92.5403)  time: 0.2316  data: 0.0054  max mem: 2503
Test: [Task 1]  [  40/1627]  eta: 0:06:45  Loss: 1.1919 (1.1889)  Acc@1: 68.7500 (69.8171)  Acc@5: 93.7500 (92.3780)  time: 0.2267  data: 0.0020  max mem: 2503
Test: [Task 1]  [  50/1627]  eta: 0:06:34  Loss: 1.0549 (1.1706)  Acc@1: 68.7500 (70.3431)  Acc@5: 93.7500 (92.5245)  time: 0.2286  data: 0.0034  max mem: 2503
Test: [Task 1]  [  60/1627]  eta: 0:06:26  Loss: 1.1756 (1.1898)  Acc@1: 68.7500 (69.9795)  Acc@5: 87.5000 (91.8033)  time: 0.2292  data: 0.0055  max mem: 2503
Test: [Task 1]  [  70/1627]  eta: 0:06:19  Loss: 1.1487 (1.1806)  Acc@1: 68.7500 (70.2465)  Acc@5: 93.7500 (91.9894)  time: 0.2275  data: 0.0054  max mem: 2503
Test: [Task 1]  [  80/1627]  eta: 0:06:15  Loss: 0.9950 (1.1652)  Acc@1: 68.7500 (69.9846)  Acc@5: 93.7500 (92.1296)  time: 0.2293  data: 0.0051  max mem: 2503
Test: [Task 1]  [  90/1627]  eta: 0:06:09  Loss: 1.0884 (1.1765)  Acc@1: 68.7500 (69.7115)  Acc@5: 93.7500 (91.6209)  time: 0.2283  data: 0.0040  max mem: 2503
Test: [Task 1]  [ 100/1627]  eta: 0:06:04  Loss: 1.2906 (1.1968)  Acc@1: 62.5000 (69.1832)  Acc@5: 87.5000 (91.0891)  time: 0.2251  data: 0.0030  max mem: 2503
Test: [Task 1]  [ 110/1627]  eta: 0:06:00  Loss: 1.2454 (1.1977)  Acc@1: 62.5000 (68.8063)  Acc@5: 87.5000 (91.4414)  time: 0.2257  data: 0.0032  max mem: 2503
Test: [Task 1]  [ 120/1627]  eta: 0:05:57  Loss: 1.2512 (1.2003)  Acc@1: 68.7500 (68.8533)  Acc@5: 93.7500 (91.2190)  time: 0.2287  data: 0.0049  max mem: 2503
Test: [Task 1]  [ 130/1627]  eta: 0:05:55  Loss: 1.2760 (1.2071)  Acc@1: 68.7500 (68.8931)  Acc@5: 87.5000 (90.9828)  time: 0.2374  data: 0.0077  max mem: 2503
Test: [Task 1]  [ 140/1627]  eta: 0:05:52  Loss: 1.1409 (1.2043)  Acc@1: 75.0000 (69.1489)  Acc@5: 87.5000 (90.8245)  time: 0.2342  data: 0.0066  max mem: 2503
Test: [Task 1]  [ 150/1627]  eta: 0:05:50  Loss: 0.8866 (1.1888)  Acc@1: 81.2500 (69.3709)  Acc@5: 93.7500 (91.1010)  time: 0.2369  data: 0.0041  max mem: 2503
Test: [Task 1]  [ 160/1627]  eta: 0:05:47  Loss: 0.8810 (1.1813)  Acc@1: 75.0000 (69.6817)  Acc@5: 93.7500 (91.2655)  time: 0.2356  data: 0.0031  max mem: 2503
Test: [Task 1]  [ 170/1627]  eta: 0:05:43  Loss: 1.0221 (1.1740)  Acc@1: 75.0000 (69.8465)  Acc@5: 93.7500 (91.2646)  time: 0.2205  data: 0.0015  max mem: 2503
Test: [Task 1]  [ 180/1627]  eta: 0:05:40  Loss: 1.1022 (1.1788)  Acc@1: 68.7500 (69.6133)  Acc@5: 93.7500 (91.1948)  time: 0.2246  data: 0.0037  max mem: 2503
Test: [Task 1]  [ 190/1627]  eta: 0:05:37  Loss: 1.1544 (1.1741)  Acc@1: 68.7500 (69.6335)  Acc@5: 93.7500 (91.1976)  time: 0.2303  data: 0.0064  max mem: 2503
Test: [Task 1]  [ 200/1627]  eta: 0:05:34  Loss: 1.1631 (1.1756)  Acc@1: 68.7500 (69.4963)  Acc@5: 93.7500 (91.2002)  time: 0.2286  data: 0.0058  max mem: 2503
Test: [Task 1]  [ 210/1627]  eta: 0:05:32  Loss: 1.1165 (1.1720)  Acc@1: 75.0000 (69.6386)  Acc@5: 93.7500 (91.2618)  time: 0.2273  data: 0.0042  max mem: 2503
Test: [Task 1]  [ 220/1627]  eta: 0:05:29  Loss: 1.0787 (1.1782)  Acc@1: 75.0000 (69.4853)  Acc@5: 93.7500 (91.1765)  time: 0.2289  data: 0.0035  max mem: 2503
Test: [Task 1]  [ 230/1627]  eta: 0:05:26  Loss: 1.1278 (1.1734)  Acc@1: 68.7500 (69.6158)  Acc@5: 93.7500 (91.2338)  time: 0.2283  data: 0.0052  max mem: 2503
Test: [Task 1]  [ 240/1627]  eta: 0:05:24  Loss: 1.0435 (1.1681)  Acc@1: 68.7500 (69.7873)  Acc@5: 93.7500 (91.3382)  time: 0.2286  data: 0.0045  max mem: 2503
Test: [Task 1]  [ 250/1627]  eta: 0:05:21  Loss: 1.0340 (1.1725)  Acc@1: 68.7500 (69.6962)  Acc@5: 93.7500 (91.3098)  time: 0.2283  data: 0.0026  max mem: 2503
Test: [Task 1]  [ 260/1627]  eta: 0:05:18  Loss: 1.1866 (1.1721)  Acc@1: 68.7500 (69.8036)  Acc@5: 87.5000 (91.2835)  time: 0.2281  data: 0.0026  max mem: 2503
Test: [Task 1]  [ 270/1627]  eta: 0:05:16  Loss: 1.0417 (1.1645)  Acc@1: 75.0000 (70.0646)  Acc@5: 93.7500 (91.4437)  time: 0.2286  data: 0.0034  max mem: 2503
Test: [Task 1]  [ 280/1627]  eta: 0:05:13  Loss: 0.9989 (1.1645)  Acc@1: 75.0000 (70.1068)  Acc@5: 93.7500 (91.3701)  time: 0.2263  data: 0.0038  max mem: 2503
Test: [Task 1]  [ 290/1627]  eta: 0:05:11  Loss: 1.1074 (1.1634)  Acc@1: 68.7500 (70.2105)  Acc@5: 93.7500 (91.4948)  time: 0.2323  data: 0.0032  max mem: 2503
Test: [Task 1]  [ 300/1627]  eta: 0:05:08  Loss: 1.0467 (1.1607)  Acc@1: 75.0000 (70.2865)  Acc@5: 93.7500 (91.5905)  time: 0.2316  data: 0.0027  max mem: 2503
Test: [Task 1]  [ 310/1627]  eta: 0:05:06  Loss: 1.0426 (1.1619)  Acc@1: 75.0000 (70.3376)  Acc@5: 93.7500 (91.5193)  time: 0.2260  data: 0.0030  max mem: 2503
Test: [Task 1]  [ 320/1627]  eta: 0:05:03  Loss: 1.1650 (1.1605)  Acc@1: 68.7500 (70.3271)  Acc@5: 93.7500 (91.5888)  time: 0.2289  data: 0.0043  max mem: 2503
Test: [Task 1]  [ 330/1627]  eta: 0:05:01  Loss: 1.0150 (1.1583)  Acc@1: 68.7500 (70.3550)  Acc@5: 93.7500 (91.5785)  time: 0.2301  data: 0.0055  max mem: 2503
Test: [Task 1]  [ 340/1627]  eta: 0:04:58  Loss: 0.9915 (1.1596)  Acc@1: 68.7500 (70.3629)  Acc@5: 93.7500 (91.6789)  time: 0.2287  data: 0.0044  max mem: 2503
Test: [Task 1]  [ 350/1627]  eta: 0:04:57  Loss: 1.0528 (1.1620)  Acc@1: 68.7500 (70.3348)  Acc@5: 93.7500 (91.6132)  time: 0.2369  data: 0.0065  max mem: 2503
Test: [Task 1]  [ 360/1627]  eta: 0:04:54  Loss: 1.0528 (1.1606)  Acc@1: 75.0000 (70.4467)  Acc@5: 87.5000 (91.5512)  time: 0.2372  data: 0.0075  max mem: 2503
Test: [Task 1]  [ 370/1627]  eta: 0:04:52  Loss: 1.0694 (1.1611)  Acc@1: 68.7500 (70.4009)  Acc@5: 87.5000 (91.5768)  time: 0.2288  data: 0.0054  max mem: 2503
Test: [Task 1]  [ 380/1627]  eta: 0:04:49  Loss: 1.0903 (1.1594)  Acc@1: 68.7500 (70.5217)  Acc@5: 93.7500 (91.5846)  time: 0.2295  data: 0.0055  max mem: 2503
Test: [Task 1]  [ 390/1627]  eta: 0:04:47  Loss: 1.0903 (1.1610)  Acc@1: 75.0000 (70.5083)  Acc@5: 87.5000 (91.5121)  time: 0.2272  data: 0.0044  max mem: 2503
Test: [Task 1]  [ 400/1627]  eta: 0:04:44  Loss: 1.1849 (1.1620)  Acc@1: 68.7500 (70.4645)  Acc@5: 87.5000 (91.4900)  time: 0.2251  data: 0.0037  max mem: 2503
Test: [Task 1]  [ 410/1627]  eta: 0:04:42  Loss: 1.0211 (1.1609)  Acc@1: 68.7500 (70.5444)  Acc@5: 87.5000 (91.4842)  time: 0.2313  data: 0.0062  max mem: 2503
Test: [Task 1]  [ 420/1627]  eta: 0:04:40  Loss: 0.9453 (1.1590)  Acc@1: 75.0000 (70.6502)  Acc@5: 93.7500 (91.5529)  time: 0.2331  data: 0.0059  max mem: 2503
Test: [Task 1]  [ 430/1627]  eta: 0:04:37  Loss: 0.9488 (1.1570)  Acc@1: 75.0000 (70.6642)  Acc@5: 93.7500 (91.5893)  time: 0.2286  data: 0.0048  max mem: 2503
Test: [Task 1]  [ 440/1627]  eta: 0:04:35  Loss: 1.1237 (1.1556)  Acc@1: 68.7500 (70.6633)  Acc@5: 93.7500 (91.5816)  time: 0.2307  data: 0.0065  max mem: 2503
Test: [Task 1]  [ 450/1627]  eta: 0:04:32  Loss: 1.2085 (1.1589)  Acc@1: 68.7500 (70.5100)  Acc@5: 87.5000 (91.4357)  time: 0.2291  data: 0.0043  max mem: 2503
Test: [Task 1]  [ 460/1627]  eta: 0:04:30  Loss: 1.2225 (1.1589)  Acc@1: 62.5000 (70.4582)  Acc@5: 87.5000 (91.4588)  time: 0.2299  data: 0.0031  max mem: 2503
Test: [Task 1]  [ 470/1627]  eta: 0:04:28  Loss: 1.0615 (1.1559)  Acc@1: 68.7500 (70.5016)  Acc@5: 93.7500 (91.4942)  time: 0.2332  data: 0.0039  max mem: 2503
Test: [Task 1]  [ 480/1627]  eta: 0:04:25  Loss: 1.1155 (1.1600)  Acc@1: 68.7500 (70.2833)  Acc@5: 93.7500 (91.4761)  time: 0.2287  data: 0.0038  max mem: 2503
Test: [Task 1]  [ 490/1627]  eta: 0:04:23  Loss: 1.1762 (1.1613)  Acc@1: 62.5000 (70.1629)  Acc@5: 93.7500 (91.4588)  time: 0.2253  data: 0.0042  max mem: 2503
Test: [Task 1]  [ 500/1627]  eta: 0:04:20  Loss: 1.0720 (1.1629)  Acc@1: 68.7500 (70.1098)  Acc@5: 93.7500 (91.4296)  time: 0.2233  data: 0.0041  max mem: 2503
Test: [Task 1]  [ 510/1627]  eta: 0:04:18  Loss: 1.1808 (1.1677)  Acc@1: 68.7500 (70.0342)  Acc@5: 87.5000 (91.3405)  time: 0.2264  data: 0.0046  max mem: 2503
Test: [Task 1]  [ 520/1627]  eta: 0:04:16  Loss: 1.3022 (1.1743)  Acc@1: 62.5000 (69.9136)  Acc@5: 87.5000 (91.2788)  time: 0.2270  data: 0.0053  max mem: 2503
Test: [Task 1]  [ 530/1627]  eta: 0:04:13  Loss: 1.1906 (1.1701)  Acc@1: 68.7500 (70.0565)  Acc@5: 87.5000 (91.2782)  time: 0.2254  data: 0.0038  max mem: 2503
Test: [Task 1]  [ 540/1627]  eta: 0:04:11  Loss: 1.0906 (1.1710)  Acc@1: 68.7500 (69.9977)  Acc@5: 87.5000 (91.2431)  time: 0.2287  data: 0.0028  max mem: 2503
Test: [Task 1]  [ 550/1627]  eta: 0:04:09  Loss: 1.2659 (1.1729)  Acc@1: 68.7500 (69.9297)  Acc@5: 87.5000 (91.2319)  time: 0.2340  data: 0.0070  max mem: 2503
Test: [Task 1]  [ 560/1627]  eta: 0:04:06  Loss: 1.2956 (1.1754)  Acc@1: 68.7500 (69.8864)  Acc@5: 87.5000 (91.2099)  time: 0.2346  data: 0.0089  max mem: 2503
Test: [Task 1]  [ 570/1627]  eta: 0:04:04  Loss: 1.1964 (1.1725)  Acc@1: 68.7500 (69.9759)  Acc@5: 93.7500 (91.2763)  time: 0.2308  data: 0.0055  max mem: 2503
Test: [Task 1]  [ 580/1627]  eta: 0:04:02  Loss: 1.0794 (1.1735)  Acc@1: 68.7500 (69.9010)  Acc@5: 93.7500 (91.3188)  time: 0.2345  data: 0.0050  max mem: 2503
Test: [Task 1]  [ 590/1627]  eta: 0:03:59  Loss: 1.1779 (1.1730)  Acc@1: 68.7500 (69.8604)  Acc@5: 93.7500 (91.3494)  time: 0.2358  data: 0.0066  max mem: 2503
Test: [Task 1]  [ 600/1627]  eta: 0:03:57  Loss: 1.1692 (1.1745)  Acc@1: 68.7500 (69.8003)  Acc@5: 93.7500 (91.3166)  time: 0.2316  data: 0.0071  max mem: 2503
Test: [Task 1]  [ 610/1627]  eta: 0:03:55  Loss: 1.1273 (1.1730)  Acc@1: 68.7500 (69.8957)  Acc@5: 93.7500 (91.3462)  time: 0.2309  data: 0.0061  max mem: 2503
Test: [Task 1]  [ 620/1627]  eta: 0:03:52  Loss: 1.0631 (1.1737)  Acc@1: 75.0000 (69.9074)  Acc@5: 93.7500 (91.2943)  time: 0.2292  data: 0.0048  max mem: 2503
Test: [Task 1]  [ 630/1627]  eta: 0:03:50  Loss: 1.0083 (1.1734)  Acc@1: 75.0000 (69.9287)  Acc@5: 93.7500 (91.3134)  time: 0.2301  data: 0.0046  max mem: 2503
Test: [Task 1]  [ 640/1627]  eta: 0:03:48  Loss: 0.9828 (1.1730)  Acc@1: 68.7500 (69.9200)  Acc@5: 93.7500 (91.2929)  time: 0.2291  data: 0.0055  max mem: 2503
Test: [Task 1]  [ 650/1627]  eta: 0:03:45  Loss: 1.0400 (1.1720)  Acc@1: 68.7500 (69.9213)  Acc@5: 93.7500 (91.2826)  time: 0.2271  data: 0.0074  max mem: 2503
Test: [Task 1]  [ 660/1627]  eta: 0:03:45  Loss: 1.0547 (1.1703)  Acc@1: 75.0000 (69.9792)  Acc@5: 93.7500 (91.3105)  time: 0.3070  data: 0.0066  max mem: 2503
Test: [Task 1]  [ 670/1627]  eta: 0:03:46  Loss: 1.1535 (1.1707)  Acc@1: 75.0000 (70.0261)  Acc@5: 93.7500 (91.2910)  time: 0.4051  data: 0.0025  max mem: 2503
Test: [Task 1]  [ 680/1627]  eta: 0:03:46  Loss: 1.1720 (1.1709)  Acc@1: 75.0000 (70.0349)  Acc@5: 87.5000 (91.2445)  time: 0.4269  data: 0.0015  max mem: 2503
Test: [Task 1]  [ 690/1627]  eta: 0:03:46  Loss: 1.0446 (1.1691)  Acc@1: 75.0000 (70.0886)  Acc@5: 93.7500 (91.2988)  time: 0.4165  data: 0.0014  max mem: 2503
Test: [Task 1]  [ 700/1627]  eta: 0:03:46  Loss: 1.1536 (1.1695)  Acc@1: 68.7500 (70.1141)  Acc@5: 93.7500 (91.2892)  time: 0.4193  data: 0.0007  max mem: 2503
Test: [Task 1]  [ 710/1627]  eta: 0:03:46  Loss: 1.0964 (1.1674)  Acc@1: 68.7500 (70.1565)  Acc@5: 93.7500 (91.3326)  time: 0.4313  data: 0.0007  max mem: 2503
Test: [Task 1]  [ 720/1627]  eta: 0:03:46  Loss: 1.0458 (1.1655)  Acc@1: 75.0000 (70.2063)  Acc@5: 93.7500 (91.3748)  time: 0.4253  data: 0.0005  max mem: 2503
Test: [Task 1]  [ 730/1627]  eta: 0:03:45  Loss: 1.1272 (1.1665)  Acc@1: 68.7500 (70.1522)  Acc@5: 93.7500 (91.3817)  time: 0.4260  data: 0.0005  max mem: 2503
Test: [Task 1]  [ 740/1627]  eta: 0:03:45  Loss: 1.1382 (1.1676)  Acc@1: 68.7500 (70.1501)  Acc@5: 93.7500 (91.3546)  time: 0.4266  data: 0.0004  max mem: 2503
Test: [Task 1]  [ 750/1627]  eta: 0:03:44  Loss: 1.0365 (1.1667)  Acc@1: 75.0000 (70.2230)  Acc@5: 87.5000 (91.3698)  time: 0.4211  data: 0.0005  max mem: 2503
Test: [Task 1]  [ 760/1627]  eta: 0:03:43  Loss: 1.1526 (1.1697)  Acc@1: 68.7500 (70.1462)  Acc@5: 87.5000 (91.3026)  time: 0.4117  data: 0.0010  max mem: 2503
Test: [Task 1]  [ 770/1627]  eta: 0:03:43  Loss: 0.9182 (1.1661)  Acc@1: 75.0000 (70.2821)  Acc@5: 93.7500 (91.3424)  time: 0.4149  data: 0.0011  max mem: 2503
Test: [Task 1]  [ 780/1627]  eta: 0:03:42  Loss: 0.8216 (1.1641)  Acc@1: 81.2500 (70.3665)  Acc@5: 93.7500 (91.3892)  time: 0.4254  data: 0.0006  max mem: 2503
Test: [Task 1]  [ 790/1627]  eta: 0:03:41  Loss: 0.9747 (1.1665)  Acc@1: 75.0000 (70.2987)  Acc@5: 93.7500 (91.3480)  time: 0.4164  data: 0.0005  max mem: 2503
Test: [Task 1]  [ 800/1627]  eta: 0:03:40  Loss: 1.0488 (1.1652)  Acc@1: 75.0000 (70.3184)  Acc@5: 93.7500 (91.3936)  time: 0.4121  data: 0.0010  max mem: 2503
Test: [Task 1]  [ 810/1627]  eta: 0:03:39  Loss: 1.0488 (1.1648)  Acc@1: 75.0000 (70.3607)  Acc@5: 93.7500 (91.4072)  time: 0.4161  data: 0.0011  max mem: 2503
Test: [Task 1]  [ 820/1627]  eta: 0:03:37  Loss: 0.9684 (1.1631)  Acc@1: 75.0000 (70.4019)  Acc@5: 93.7500 (91.4357)  time: 0.4181  data: 0.0006  max mem: 2503
Test: [Task 1]  [ 830/1627]  eta: 0:03:36  Loss: 0.9343 (1.1628)  Acc@1: 68.7500 (70.4046)  Acc@5: 93.7500 (91.4711)  time: 0.4215  data: 0.0010  max mem: 2503
Test: [Task 1]  [ 840/1627]  eta: 0:03:35  Loss: 1.0041 (1.1604)  Acc@1: 68.7500 (70.4370)  Acc@5: 93.7500 (91.5205)  time: 0.4214  data: 0.0010  max mem: 2503
Test: [Task 1]  [ 850/1627]  eta: 0:03:34  Loss: 1.0381 (1.1614)  Acc@1: 68.7500 (70.3951)  Acc@5: 93.7500 (91.5173)  time: 0.4240  data: 0.0008  max mem: 2503
Test: [Task 1]  [ 860/1627]  eta: 0:03:32  Loss: 1.0381 (1.1607)  Acc@1: 68.7500 (70.4268)  Acc@5: 93.7500 (91.5433)  time: 0.4267  data: 0.0007  max mem: 2503
Test: [Task 1]  [ 870/1627]  eta: 0:03:31  Loss: 1.0555 (1.1589)  Acc@1: 75.0000 (70.4937)  Acc@5: 93.7500 (91.5686)  time: 0.4225  data: 0.0005  max mem: 2503
Test: [Task 1]  [ 880/1627]  eta: 0:03:29  Loss: 1.1713 (1.1610)  Acc@1: 68.7500 (70.3817)  Acc@5: 93.7500 (91.5721)  time: 0.4250  data: 0.0008  max mem: 2503
Test: [Task 1]  [ 890/1627]  eta: 0:03:27  Loss: 1.3139 (1.1628)  Acc@1: 62.5000 (70.3493)  Acc@5: 87.5000 (91.5614)  time: 0.4255  data: 0.0013  max mem: 2503
Test: [Task 1]  [ 900/1627]  eta: 0:03:26  Loss: 1.1721 (1.1636)  Acc@1: 68.7500 (70.3454)  Acc@5: 87.5000 (91.5094)  time: 0.4112  data: 0.0011  max mem: 2503
Test: [Task 1]  [ 910/1627]  eta: 0:03:24  Loss: 1.0914 (1.1640)  Acc@1: 68.7500 (70.4171)  Acc@5: 93.7500 (91.5066)  time: 0.4143  data: 0.0008  max mem: 2503
Test: [Task 1]  [ 920/1627]  eta: 0:03:22  Loss: 1.0809 (1.1631)  Acc@1: 75.0000 (70.4737)  Acc@5: 93.7500 (91.5242)  time: 0.4224  data: 0.0008  max mem: 2503
Test: [Task 1]  [ 930/1627]  eta: 0:03:20  Loss: 1.0967 (1.1634)  Acc@1: 75.0000 (70.4686)  Acc@5: 93.7500 (91.5145)  time: 0.4206  data: 0.0006  max mem: 2503
Test: [Task 1]  [ 940/1627]  eta: 0:03:18  Loss: 1.1456 (1.1626)  Acc@1: 68.7500 (70.4769)  Acc@5: 93.7500 (91.5449)  time: 0.4291  data: 0.0009  max mem: 2503
Test: [Task 1]  [ 950/1627]  eta: 0:03:16  Loss: 1.2351 (1.1636)  Acc@1: 62.5000 (70.4193)  Acc@5: 93.7500 (91.5484)  time: 0.4297  data: 0.0008  max mem: 2503
Test: [Task 1]  [ 960/1627]  eta: 0:03:14  Loss: 1.1807 (1.1631)  Acc@1: 62.5000 (70.4019)  Acc@5: 93.7500 (91.5518)  time: 0.4230  data: 0.0005  max mem: 2503
Test: [Task 1]  [ 970/1627]  eta: 0:03:12  Loss: 0.9994 (1.1623)  Acc@1: 75.0000 (70.4428)  Acc@5: 93.7500 (91.5680)  time: 0.4143  data: 0.0008  max mem: 2503
Test: [Task 1]  [ 980/1627]  eta: 0:03:10  Loss: 1.1626 (1.1628)  Acc@1: 68.7500 (70.4065)  Acc@5: 93.7500 (91.5456)  time: 0.4118  data: 0.0009  max mem: 2503
Test: [Task 1]  [ 990/1627]  eta: 0:03:08  Loss: 1.2484 (1.1656)  Acc@1: 62.5000 (70.3582)  Acc@5: 87.5000 (91.5111)  time: 0.4259  data: 0.0005  max mem: 2503
Test: [Task 1]  [1000/1627]  eta: 0:03:06  Loss: 1.4139 (1.1664)  Acc@1: 68.7500 (70.3484)  Acc@5: 87.5000 (91.4898)  time: 0.4249  data: 0.0009  max mem: 2503
Test: [Task 1]  [1010/1627]  eta: 0:03:04  Loss: 1.2027 (1.1662)  Acc@1: 68.7500 (70.3450)  Acc@5: 93.7500 (91.4998)  time: 0.4164  data: 0.0009  max mem: 2503
Test: [Task 1]  [1020/1627]  eta: 0:03:01  Loss: 1.1139 (1.1661)  Acc@1: 62.5000 (70.3355)  Acc@5: 93.7500 (91.5095)  time: 0.4204  data: 0.0006  max mem: 2503
Test: [Task 1]  [1030/1627]  eta: 0:02:59  Loss: 0.9626 (1.1635)  Acc@1: 75.0000 (70.4292)  Acc@5: 93.7500 (91.5434)  time: 0.4282  data: 0.0006  max mem: 2503
Test: [Task 1]  [1040/1627]  eta: 0:02:57  Loss: 0.8777 (1.1622)  Acc@1: 75.0000 (70.4551)  Acc@5: 93.7500 (91.5646)  time: 0.4241  data: 0.0007  max mem: 2503
Test: [Task 1]  [1050/1627]  eta: 0:02:54  Loss: 0.9894 (1.1609)  Acc@1: 68.7500 (70.4627)  Acc@5: 93.7500 (91.5854)  time: 0.4170  data: 0.0009  max mem: 2503
Test: [Task 1]  [1060/1627]  eta: 0:02:52  Loss: 1.0808 (1.1614)  Acc@1: 68.7500 (70.4819)  Acc@5: 93.7500 (91.5705)  time: 0.4232  data: 0.0007  max mem: 2503
Test: [Task 1]  [1070/1627]  eta: 0:02:50  Loss: 1.1039 (1.1621)  Acc@1: 68.7500 (70.4482)  Acc@5: 93.7500 (91.5616)  time: 0.4295  data: 0.0006  max mem: 2503
Test: [Task 1]  [1080/1627]  eta: 0:02:47  Loss: 1.1039 (1.1626)  Acc@1: 68.7500 (70.4383)  Acc@5: 93.7500 (91.5587)  time: 0.4285  data: 0.0006  max mem: 2503
Test: [Task 1]  [1090/1627]  eta: 0:02:45  Loss: 1.0836 (1.1621)  Acc@1: 68.7500 (70.4858)  Acc@5: 93.7500 (91.5788)  time: 0.4264  data: 0.0005  max mem: 2503
Test: [Task 1]  [1100/1627]  eta: 0:02:42  Loss: 0.9998 (1.1604)  Acc@1: 75.0000 (70.5041)  Acc@5: 93.7500 (91.5985)  time: 0.4240  data: 0.0005  max mem: 2503
Test: [Task 1]  [1110/1627]  eta: 0:02:40  Loss: 1.0702 (1.1609)  Acc@1: 68.7500 (70.4939)  Acc@5: 93.7500 (91.5954)  time: 0.4253  data: 0.0005  max mem: 2503
Test: [Task 1]  [1120/1627]  eta: 0:02:37  Loss: 1.1563 (1.1623)  Acc@1: 62.5000 (70.4338)  Acc@5: 93.7500 (91.5923)  time: 0.4152  data: 0.0013  max mem: 2503
Test: [Task 1]  [1130/1627]  eta: 0:02:34  Loss: 1.2762 (1.1625)  Acc@1: 62.5000 (70.4410)  Acc@5: 93.7500 (91.6059)  time: 0.4134  data: 0.0012  max mem: 2503
Test: [Task 1]  [1140/1627]  eta: 0:02:32  Loss: 1.2341 (1.1634)  Acc@1: 75.0000 (70.4371)  Acc@5: 93.7500 (91.5809)  time: 0.4286  data: 0.0006  max mem: 2503
Test: [Task 1]  [1150/1627]  eta: 0:02:29  Loss: 1.2780 (1.1644)  Acc@1: 68.7500 (70.4116)  Acc@5: 87.5000 (91.5508)  time: 0.4025  data: 0.0005  max mem: 2503
Test: [Task 1]  [1160/1627]  eta: 0:02:26  Loss: 1.2443 (1.1635)  Acc@1: 68.7500 (70.4619)  Acc@5: 87.5000 (91.5429)  time: 0.3979  data: 0.0005  max mem: 2503
Test: [Task 1]  [1170/1627]  eta: 0:02:24  Loss: 1.1883 (1.1628)  Acc@1: 75.0000 (70.5006)  Acc@5: 93.7500 (91.5564)  time: 0.4250  data: 0.0007  max mem: 2503
Test: [Task 1]  [1180/1627]  eta: 0:02:21  Loss: 1.2132 (1.1639)  Acc@1: 75.0000 (70.4964)  Acc@5: 93.7500 (91.5644)  time: 0.4264  data: 0.0008  max mem: 2503
Test: [Task 1]  [1190/1627]  eta: 0:02:18  Loss: 1.2312 (1.1641)  Acc@1: 68.7500 (70.4975)  Acc@5: 93.7500 (91.5670)  time: 0.4173  data: 0.0012  max mem: 2503
Test: [Task 1]  [1200/1627]  eta: 0:02:15  Loss: 1.1599 (1.1641)  Acc@1: 68.7500 (70.4933)  Acc@5: 93.7500 (91.5851)  time: 0.4242  data: 0.0012  max mem: 2503
Test: [Task 1]  [1210/1627]  eta: 0:02:12  Loss: 1.0356 (1.1648)  Acc@1: 68.7500 (70.4686)  Acc@5: 93.7500 (91.5462)  time: 0.4228  data: 0.0005  max mem: 2503
Test: [Task 1]  [1220/1627]  eta: 0:02:09  Loss: 1.0334 (1.1640)  Acc@1: 68.7500 (70.4699)  Acc@5: 93.7500 (91.5592)  time: 0.4042  data: 0.0004  max mem: 2503
Test: [Task 1]  [1230/1627]  eta: 0:02:06  Loss: 1.1759 (1.1642)  Acc@1: 68.7500 (70.4509)  Acc@5: 93.7500 (91.5516)  time: 0.3496  data: 0.0005  max mem: 2503
Test: [Task 1]  [1240/1627]  eta: 0:02:03  Loss: 1.0851 (1.1634)  Acc@1: 75.0000 (70.4674)  Acc@5: 93.7500 (91.5643)  time: 0.2812  data: 0.0008  max mem: 2503
Test: [Task 1]  [1250/1627]  eta: 0:02:00  Loss: 1.0851 (1.1638)  Acc@1: 75.0000 (70.4686)  Acc@5: 93.7500 (91.5618)  time: 0.3432  data: 0.0007  max mem: 2503
Test: [Task 1]  [1260/1627]  eta: 0:01:57  Loss: 1.1773 (1.1634)  Acc@1: 75.0000 (70.5046)  Acc@5: 93.7500 (91.5692)  time: 0.4280  data: 0.0005  max mem: 2503
Test: [Task 1]  [1270/1627]  eta: 0:01:54  Loss: 1.1455 (1.1641)  Acc@1: 68.7500 (70.4809)  Acc@5: 93.7500 (91.5470)  time: 0.3974  data: 0.0006  max mem: 2503
Test: [Task 1]  [1280/1627]  eta: 0:01:51  Loss: 1.0340 (1.1622)  Acc@1: 68.7500 (70.5211)  Acc@5: 93.7500 (91.5691)  time: 0.2893  data: 0.0008  max mem: 2503
Test: [Task 1]  [1290/1627]  eta: 0:01:47  Loss: 1.0489 (1.1622)  Acc@1: 68.7500 (70.4928)  Acc@5: 93.7500 (91.5763)  time: 0.2180  data: 0.0007  max mem: 2503
Test: [Task 1]  [1300/1627]  eta: 0:01:44  Loss: 1.0712 (1.1619)  Acc@1: 68.7500 (70.5275)  Acc@5: 93.7500 (91.5834)  time: 0.2216  data: 0.0005  max mem: 2503
Test: [Task 1]  [1310/1627]  eta: 0:01:40  Loss: 0.9458 (1.1604)  Acc@1: 75.0000 (70.5568)  Acc@5: 93.7500 (91.5999)  time: 0.2254  data: 0.0005  max mem: 2503
Test: [Task 1]  [1320/1627]  eta: 0:01:37  Loss: 0.8734 (1.1588)  Acc@1: 75.0000 (70.6236)  Acc@5: 93.7500 (91.6257)  time: 0.2220  data: 0.0006  max mem: 2503
Test: [Task 1]  [1330/1627]  eta: 0:01:33  Loss: 0.9700 (1.1585)  Acc@1: 75.0000 (70.6377)  Acc@5: 93.7500 (91.6181)  time: 0.2197  data: 0.0017  max mem: 2503
Test: [Task 1]  [1340/1627]  eta: 0:01:30  Loss: 1.0545 (1.1596)  Acc@1: 68.7500 (70.6050)  Acc@5: 93.7500 (91.6154)  time: 0.2199  data: 0.0022  max mem: 2503
Test: [Task 1]  [1350/1627]  eta: 0:01:27  Loss: 1.1128 (1.1591)  Acc@1: 68.7500 (70.6005)  Acc@5: 93.7500 (91.6219)  time: 0.2185  data: 0.0014  max mem: 2503
Test: [Task 1]  [1360/1627]  eta: 0:01:23  Loss: 1.0696 (1.1586)  Acc@1: 75.0000 (70.6282)  Acc@5: 93.7500 (91.6238)  time: 0.2182  data: 0.0015  max mem: 2503
Test: [Task 1]  [1370/1627]  eta: 0:01:20  Loss: 1.0406 (1.1578)  Acc@1: 75.0000 (70.6327)  Acc@5: 93.7500 (91.6439)  time: 0.2192  data: 0.0018  max mem: 2503
Test: [Task 1]  [1380/1627]  eta: 0:01:17  Loss: 1.1109 (1.1582)  Acc@1: 68.7500 (70.6146)  Acc@5: 93.7500 (91.6365)  time: 0.2949  data: 0.0011  max mem: 2503
Test: [Task 1]  [1390/1627]  eta: 0:01:14  Loss: 1.1826 (1.1576)  Acc@1: 68.7500 (70.6102)  Acc@5: 93.7500 (91.6517)  time: 0.3997  data: 0.0006  max mem: 2503
Test: [Task 1]  [1400/1627]  eta: 0:01:11  Loss: 1.1028 (1.1580)  Acc@1: 68.7500 (70.6147)  Acc@5: 93.7500 (91.6310)  time: 0.4100  data: 0.0006  max mem: 2503
Test: [Task 1]  [1410/1627]  eta: 0:01:08  Loss: 1.0193 (1.1575)  Acc@1: 68.7500 (70.6104)  Acc@5: 93.7500 (91.6504)  time: 0.4103  data: 0.0011  max mem: 2503
Test: [Task 1]  [1420/1627]  eta: 0:01:05  Loss: 1.1019 (1.1568)  Acc@1: 68.7500 (70.6149)  Acc@5: 93.7500 (91.6696)  time: 0.4287  data: 0.0013  max mem: 2503
Test: [Task 1]  [1430/1627]  eta: 0:01:02  Loss: 1.2685 (1.1585)  Acc@1: 68.7500 (70.6019)  Acc@5: 93.7500 (91.6361)  time: 0.4280  data: 0.0010  max mem: 2503
Test: [Task 1]  [1440/1627]  eta: 0:00:59  Loss: 1.1423 (1.1581)  Acc@1: 68.7500 (70.5890)  Acc@5: 87.5000 (91.6334)  time: 0.4276  data: 0.0007  max mem: 2503
Test: [Task 1]  [1450/1627]  eta: 0:00:56  Loss: 1.1853 (1.1598)  Acc@1: 62.5000 (70.5160)  Acc@5: 87.5000 (91.6092)  time: 0.4264  data: 0.0005  max mem: 2503
Test: [Task 1]  [1460/1627]  eta: 0:00:53  Loss: 1.3029 (1.1601)  Acc@1: 62.5000 (70.4954)  Acc@5: 87.5000 (91.6068)  time: 0.4293  data: 0.0007  max mem: 2503
Test: [Task 1]  [1470/1627]  eta: 0:00:50  Loss: 1.1531 (1.1608)  Acc@1: 68.7500 (70.4623)  Acc@5: 93.7500 (91.6001)  time: 0.4244  data: 0.0008  max mem: 2503
Test: [Task 1]  [1480/1627]  eta: 0:00:47  Loss: 1.2261 (1.1612)  Acc@1: 68.7500 (70.4591)  Acc@5: 93.7500 (91.6104)  time: 0.4163  data: 0.0008  max mem: 2503
Test: [Task 1]  [1490/1627]  eta: 0:00:44  Loss: 1.2910 (1.1614)  Acc@1: 75.0000 (70.4896)  Acc@5: 93.7500 (91.6038)  time: 0.4234  data: 0.0007  max mem: 2503
Test: [Task 1]  [1500/1627]  eta: 0:00:40  Loss: 1.2207 (1.1619)  Acc@1: 75.0000 (70.4655)  Acc@5: 93.7500 (91.6056)  time: 0.4278  data: 0.0012  max mem: 2503
Test: [Task 1]  [1510/1627]  eta: 0:00:37  Loss: 0.9988 (1.1622)  Acc@1: 68.7500 (70.4583)  Acc@5: 93.7500 (91.6032)  time: 0.4235  data: 0.0011  max mem: 2503
Test: [Task 1]  [1520/1627]  eta: 0:00:34  Loss: 0.9769 (1.1608)  Acc@1: 75.0000 (70.4964)  Acc@5: 93.7500 (91.6215)  time: 0.4205  data: 0.0007  max mem: 2503
Test: [Task 1]  [1530/1627]  eta: 0:00:31  Loss: 0.9617 (1.1602)  Acc@1: 75.0000 (70.4972)  Acc@5: 100.0000 (91.6354)  time: 0.4260  data: 0.0007  max mem: 2503
Test: [Task 1]  [1540/1627]  eta: 0:00:28  Loss: 0.9337 (1.1591)  Acc@1: 68.7500 (70.5102)  Acc@5: 100.0000 (91.6531)  time: 0.4249  data: 0.0008  max mem: 2503
Test: [Task 1]  [1550/1627]  eta: 0:00:25  Loss: 0.9890 (1.1588)  Acc@1: 75.0000 (70.5432)  Acc@5: 93.7500 (91.6626)  time: 0.4187  data: 0.0008  max mem: 2503
Test: [Task 1]  [1560/1627]  eta: 0:00:21  Loss: 1.0060 (1.1578)  Acc@1: 75.0000 (70.5878)  Acc@5: 93.7500 (91.6720)  time: 0.4244  data: 0.0005  max mem: 2503
Test: [Task 1]  [1570/1627]  eta: 0:00:18  Loss: 1.0709 (1.1581)  Acc@1: 75.0000 (70.5960)  Acc@5: 93.7500 (91.6773)  time: 0.4275  data: 0.0005  max mem: 2503
Test: [Task 1]  [1580/1627]  eta: 0:00:15  Loss: 1.1441 (1.1581)  Acc@1: 68.7500 (70.5961)  Acc@5: 93.7500 (91.6746)  time: 0.4314  data: 0.0006  max mem: 2503
Test: [Task 1]  [1590/1627]  eta: 0:00:12  Loss: 1.2016 (1.1578)  Acc@1: 68.7500 (70.5885)  Acc@5: 93.7500 (91.6876)  time: 0.4341  data: 0.0006  max mem: 2503
Test: [Task 1]  [1600/1627]  eta: 0:00:08  Loss: 1.1609 (1.1588)  Acc@1: 68.7500 (70.5458)  Acc@5: 87.5000 (91.6615)  time: 0.4277  data: 0.0005  max mem: 2503
Test: [Task 1]  [1610/1627]  eta: 0:00:05  Loss: 1.1018 (1.1583)  Acc@1: 68.7500 (70.5618)  Acc@5: 87.5000 (91.6589)  time: 0.4209  data: 0.0010  max mem: 2503
Test: [Task 1]  [1620/1627]  eta: 0:00:02  Loss: 1.0455 (1.1573)  Acc@1: 75.0000 (70.6046)  Acc@5: 93.7500 (91.6641)  time: 0.4224  data: 0.0011  max mem: 2503
Test: [Task 1]  [1626/1627]  eta: 0:00:00  Loss: 1.0455 (1.1567)  Acc@1: 81.2500 (70.6438)  Acc@5: 93.7500 (91.6564)  time: 0.4236  data: 0.0009  max mem: 2503
Test: [Task 1] Total time: 0:08:58 (0.3309 s / it)
* Acc@1 70.644 Acc@5 91.656 loss 1.157
Test: [Task 2]  [  0/625]  eta: 0:09:15  Loss: 0.6823 (0.6823)  Acc@1: 75.0000 (75.0000)  Acc@5: 100.0000 (100.0000)  time: 0.8883  data: 0.4434  max mem: 2503
Test: [Task 2]  [ 10/625]  eta: 0:04:48  Loss: 0.7889 (0.7992)  Acc@1: 75.0000 (75.0000)  Acc@5: 100.0000 (98.8636)  time: 0.4691  data: 0.0408  max mem: 2503
Test: [Task 2]  [ 20/625]  eta: 0:04:33  Loss: 0.7889 (0.8127)  Acc@1: 75.0000 (75.5952)  Acc@5: 100.0000 (98.2143)  time: 0.4303  data: 0.0010  max mem: 2503
Test: [Task 2]  [ 30/625]  eta: 0:04:24  Loss: 0.8068 (0.8381)  Acc@1: 75.0000 (75.8065)  Acc@5: 100.0000 (97.9839)  time: 0.4316  data: 0.0011  max mem: 2503
Test: [Task 2]  [ 40/625]  eta: 0:04:17  Loss: 0.9250 (0.8720)  Acc@1: 75.0000 (75.3049)  Acc@5: 93.7500 (97.1037)  time: 0.4263  data: 0.0006  max mem: 2503
Test: [Task 2]  [ 50/625]  eta: 0:04:09  Loss: 0.8860 (0.8765)  Acc@1: 75.0000 (75.0000)  Acc@5: 93.7500 (96.6912)  time: 0.4178  data: 0.0006  max mem: 2503
Test: [Task 2]  [ 60/625]  eta: 0:04:02  Loss: 0.8860 (0.8828)  Acc@1: 68.7500 (74.2828)  Acc@5: 93.7500 (96.7213)  time: 0.4107  data: 0.0006  max mem: 2503
Test: [Task 2]  [ 70/625]  eta: 0:03:59  Loss: 0.8812 (0.8770)  Acc@1: 75.0000 (74.2077)  Acc@5: 93.7500 (96.6549)  time: 0.4223  data: 0.0005  max mem: 2503
Test: [Task 2]  [ 80/625]  eta: 0:03:54  Loss: 0.8685 (0.8885)  Acc@1: 75.0000 (73.9969)  Acc@5: 93.7500 (96.6049)  time: 0.4281  data: 0.0005  max mem: 2503
Test: [Task 2]  [ 90/625]  eta: 0:03:49  Loss: 0.9217 (0.8937)  Acc@1: 75.0000 (73.6951)  Acc@5: 100.0000 (96.6346)  time: 0.4247  data: 0.0004  max mem: 2503
Test: [Task 2]  [100/625]  eta: 0:03:45  Loss: 0.9160 (0.8917)  Acc@1: 75.0000 (73.8243)  Acc@5: 100.0000 (96.7203)  time: 0.4319  data: 0.0005  max mem: 2503
Test: [Task 2]  [110/625]  eta: 0:03:41  Loss: 0.8976 (0.8916)  Acc@1: 75.0000 (73.8176)  Acc@5: 93.7500 (96.6216)  time: 0.4335  data: 0.0005  max mem: 2503
Test: [Task 2]  [120/625]  eta: 0:03:36  Loss: 0.8364 (0.8869)  Acc@1: 75.0000 (74.0186)  Acc@5: 93.7500 (96.5909)  time: 0.4249  data: 0.0005  max mem: 2503
Test: [Task 2]  [130/625]  eta: 0:03:32  Loss: 0.8364 (0.8886)  Acc@1: 75.0000 (73.8550)  Acc@5: 100.0000 (96.6126)  time: 0.4243  data: 0.0011  max mem: 2503
Test: [Task 2]  [140/625]  eta: 0:03:28  Loss: 0.8659 (0.8919)  Acc@1: 75.0000 (73.9362)  Acc@5: 100.0000 (96.4982)  time: 0.4336  data: 0.0010  max mem: 2503
Test: [Task 2]  [150/625]  eta: 0:03:24  Loss: 0.9641 (0.8995)  Acc@1: 68.7500 (73.1788)  Acc@5: 100.0000 (96.5232)  time: 0.4343  data: 0.0019  max mem: 2503
Test: [Task 2]  [160/625]  eta: 0:03:19  Loss: 0.8958 (0.8983)  Acc@1: 68.7500 (73.0202)  Acc@5: 100.0000 (96.5450)  time: 0.4246  data: 0.0021  max mem: 2503
Test: [Task 2]  [170/625]  eta: 0:03:15  Loss: 0.8208 (0.8984)  Acc@1: 75.0000 (72.9898)  Acc@5: 100.0000 (96.5278)  time: 0.4179  data: 0.0007  max mem: 2503
Test: [Task 2]  [180/625]  eta: 0:03:10  Loss: 0.8208 (0.8979)  Acc@1: 75.0000 (72.9627)  Acc@5: 93.7500 (96.5124)  time: 0.4225  data: 0.0013  max mem: 2503
Test: [Task 2]  [190/625]  eta: 0:03:06  Loss: 0.8172 (0.8953)  Acc@1: 75.0000 (73.2003)  Acc@5: 93.7500 (96.4987)  time: 0.4242  data: 0.0014  max mem: 2503
Test: [Task 2]  [200/625]  eta: 0:03:01  Loss: 0.8797 (0.8982)  Acc@1: 68.7500 (72.8545)  Acc@5: 93.7500 (96.4863)  time: 0.4257  data: 0.0011  max mem: 2503
Test: [Task 2]  [210/625]  eta: 0:02:57  Loss: 0.9109 (0.9011)  Acc@1: 68.7500 (72.9858)  Acc@5: 100.0000 (96.4159)  time: 0.4338  data: 0.0011  max mem: 2503
Test: [Task 2]  [220/625]  eta: 0:02:53  Loss: 0.8521 (0.8986)  Acc@1: 75.0000 (73.0204)  Acc@5: 93.7500 (96.3801)  time: 0.4338  data: 0.0010  max mem: 2503
Test: [Task 2]  [230/625]  eta: 0:02:49  Loss: 0.8463 (0.9017)  Acc@1: 75.0000 (72.9978)  Acc@5: 93.7500 (96.3745)  time: 0.4245  data: 0.0010  max mem: 2503
Test: [Task 2]  [240/625]  eta: 0:02:44  Loss: 0.8787 (0.9000)  Acc@1: 75.0000 (73.0031)  Acc@5: 93.7500 (96.3952)  time: 0.4237  data: 0.0006  max mem: 2503
Test: [Task 2]  [250/625]  eta: 0:02:40  Loss: 0.8201 (0.8941)  Acc@1: 75.0000 (73.3815)  Acc@5: 93.7500 (96.3645)  time: 0.4264  data: 0.0006  max mem: 2503
Test: [Task 2]  [260/625]  eta: 0:02:36  Loss: 0.8179 (0.8939)  Acc@1: 75.0000 (73.4674)  Acc@5: 93.7500 (96.3362)  time: 0.4289  data: 0.0006  max mem: 2503
Test: [Task 2]  [270/625]  eta: 0:02:32  Loss: 0.8338 (0.8946)  Acc@1: 75.0000 (73.5701)  Acc@5: 93.7500 (96.2408)  time: 0.4313  data: 0.0005  max mem: 2503
Test: [Task 2]  [280/625]  eta: 0:02:27  Loss: 0.7715 (0.8928)  Acc@1: 75.0000 (73.5765)  Acc@5: 93.7500 (96.3078)  time: 0.4269  data: 0.0007  max mem: 2503
Test: [Task 2]  [290/625]  eta: 0:02:23  Loss: 0.8441 (0.8958)  Acc@1: 75.0000 (73.5610)  Acc@5: 100.0000 (96.1770)  time: 0.4256  data: 0.0007  max mem: 2503
Test: [Task 2]  [300/625]  eta: 0:02:18  Loss: 0.8780 (0.8977)  Acc@1: 68.7500 (73.4012)  Acc@5: 93.7500 (96.2002)  time: 0.4036  data: 0.0012  max mem: 2503
Test: [Task 2]  [310/625]  eta: 0:02:12  Loss: 0.9273 (0.9036)  Acc@1: 68.7500 (73.1511)  Acc@5: 100.0000 (96.2420)  time: 0.2979  data: 0.0012  max mem: 2503
Test: [Task 2]  [320/625]  eta: 0:02:06  Loss: 0.8558 (0.8974)  Acc@1: 75.0000 (73.2671)  Acc@5: 100.0000 (96.3396)  time: 0.2165  data: 0.0005  max mem: 2503
Test: [Task 2]  [330/625]  eta: 0:02:00  Loss: 0.7877 (0.8976)  Acc@1: 75.0000 (73.1873)  Acc@5: 100.0000 (96.3746)  time: 0.2210  data: 0.0019  max mem: 2503
Test: [Task 2]  [340/625]  eta: 0:01:54  Loss: 0.6687 (0.8872)  Acc@1: 81.2500 (73.5337)  Acc@5: 100.0000 (96.4626)  time: 0.2316  data: 0.0041  max mem: 2503
Test: [Task 2]  [350/625]  eta: 0:01:49  Loss: 0.6071 (0.8833)  Acc@1: 81.2500 (73.5577)  Acc@5: 100.0000 (96.5100)  time: 0.2366  data: 0.0077  max mem: 2503
Test: [Task 2]  [360/625]  eta: 0:01:44  Loss: 0.8451 (0.8869)  Acc@1: 75.0000 (73.5284)  Acc@5: 100.0000 (96.5028)  time: 0.2327  data: 0.0082  max mem: 2503
Test: [Task 2]  [370/625]  eta: 0:01:39  Loss: 0.7435 (0.8787)  Acc@1: 81.2500 (73.8376)  Acc@5: 100.0000 (96.5970)  time: 0.2282  data: 0.0043  max mem: 2503
Test: [Task 2]  [380/625]  eta: 0:01:34  Loss: 0.7149 (0.8786)  Acc@1: 75.0000 (73.8353)  Acc@5: 100.0000 (96.5879)  time: 0.2261  data: 0.0029  max mem: 2503
Test: [Task 2]  [390/625]  eta: 0:01:29  Loss: 0.7314 (0.8754)  Acc@1: 75.0000 (73.9290)  Acc@5: 100.0000 (96.5473)  time: 0.2267  data: 0.0047  max mem: 2503
Test: [Task 2]  [400/625]  eta: 0:01:24  Loss: 0.5983 (0.8677)  Acc@1: 81.2500 (74.1116)  Acc@5: 100.0000 (96.6022)  time: 0.2242  data: 0.0049  max mem: 2503
Test: [Task 2]  [410/625]  eta: 0:01:20  Loss: 0.5623 (0.8650)  Acc@1: 81.2500 (74.1940)  Acc@5: 100.0000 (96.6241)  time: 0.2202  data: 0.0028  max mem: 2503
Test: [Task 2]  [420/625]  eta: 0:01:15  Loss: 0.7478 (0.8710)  Acc@1: 81.2500 (73.9014)  Acc@5: 100.0000 (96.6300)  time: 0.2217  data: 0.0034  max mem: 2503
Test: [Task 2]  [430/625]  eta: 0:01:11  Loss: 0.9213 (0.8705)  Acc@1: 68.7500 (73.9124)  Acc@5: 100.0000 (96.6502)  time: 0.2235  data: 0.0034  max mem: 2503
Test: [Task 2]  [440/625]  eta: 0:01:07  Loss: 0.5062 (0.8614)  Acc@1: 81.2500 (74.2205)  Acc@5: 100.0000 (96.7262)  time: 0.2240  data: 0.0043  max mem: 2503
Test: [Task 2]  [450/625]  eta: 0:01:02  Loss: 0.4992 (0.8549)  Acc@1: 87.5000 (74.4457)  Acc@5: 100.0000 (96.7988)  time: 0.2242  data: 0.0041  max mem: 2503
Test: [Task 2]  [460/625]  eta: 0:00:58  Loss: 0.5328 (0.8506)  Acc@1: 81.2500 (74.5797)  Acc@5: 100.0000 (96.8547)  time: 0.2217  data: 0.0021  max mem: 2503
Test: [Task 2]  [470/625]  eta: 0:00:54  Loss: 0.8447 (0.8530)  Acc@1: 75.0000 (74.3498)  Acc@5: 100.0000 (96.9214)  time: 0.2254  data: 0.0037  max mem: 2503
Test: [Task 2]  [480/625]  eta: 0:00:50  Loss: 0.8806 (0.8523)  Acc@1: 68.7500 (74.3633)  Acc@5: 100.0000 (96.9335)  time: 0.2250  data: 0.0034  max mem: 2503
Test: [Task 2]  [490/625]  eta: 0:00:47  Loss: 0.5957 (0.8462)  Acc@1: 81.2500 (74.5927)  Acc@5: 100.0000 (96.9832)  time: 0.2219  data: 0.0023  max mem: 2503
Test: [Task 2]  [500/625]  eta: 0:00:43  Loss: 0.5906 (0.8441)  Acc@1: 75.0000 (74.5384)  Acc@5: 100.0000 (97.0185)  time: 0.2251  data: 0.0025  max mem: 2503
Test: [Task 2]  [510/625]  eta: 0:00:39  Loss: 0.7122 (0.8456)  Acc@1: 68.7500 (74.5230)  Acc@5: 100.0000 (97.0034)  time: 0.2283  data: 0.0034  max mem: 2503
Test: [Task 2]  [520/625]  eta: 0:00:35  Loss: 1.0852 (0.8576)  Acc@1: 62.5000 (74.1603)  Acc@5: 93.7500 (96.9290)  time: 0.2308  data: 0.0049  max mem: 2503
Test: [Task 2]  [530/625]  eta: 0:00:32  Loss: 1.0138 (0.8589)  Acc@1: 62.5000 (74.0702)  Acc@5: 100.0000 (96.9633)  time: 0.2306  data: 0.0063  max mem: 2503
Test: [Task 2]  [540/625]  eta: 0:00:28  Loss: 0.6554 (0.8550)  Acc@1: 75.0000 (74.1567)  Acc@5: 100.0000 (96.9732)  time: 0.2315  data: 0.0075  max mem: 2503
Test: [Task 2]  [550/625]  eta: 0:00:25  Loss: 0.5193 (0.8479)  Acc@1: 87.5000 (74.4442)  Acc@5: 100.0000 (97.0168)  time: 0.2329  data: 0.0074  max mem: 2503
Test: [Task 2]  [560/625]  eta: 0:00:21  Loss: 0.4938 (0.8417)  Acc@1: 87.5000 (74.6658)  Acc@5: 100.0000 (97.0700)  time: 0.2361  data: 0.0072  max mem: 2503
Test: [Task 2]  [570/625]  eta: 0:00:18  Loss: 0.5788 (0.8439)  Acc@1: 81.2500 (74.5950)  Acc@5: 100.0000 (97.0665)  time: 0.2327  data: 0.0056  max mem: 2503
Test: [Task 2]  [580/625]  eta: 0:00:14  Loss: 0.6530 (0.8393)  Acc@1: 75.0000 (74.7633)  Acc@5: 100.0000 (97.0955)  time: 0.2310  data: 0.0045  max mem: 2503
Test: [Task 2]  [590/625]  eta: 0:00:11  Loss: 0.6293 (0.8359)  Acc@1: 81.2500 (74.8308)  Acc@5: 100.0000 (97.1341)  time: 0.2322  data: 0.0061  max mem: 2503
Test: [Task 2]  [600/625]  eta: 0:00:08  Loss: 0.6787 (0.8375)  Acc@1: 68.7500 (74.7504)  Acc@5: 100.0000 (97.1298)  time: 0.2298  data: 0.0060  max mem: 2503
Test: [Task 2]  [610/625]  eta: 0:00:04  Loss: 1.2536 (0.8473)  Acc@1: 56.2500 (74.3760)  Acc@5: 93.7500 (97.0642)  time: 0.2305  data: 0.0044  max mem: 2503
Test: [Task 2]  [620/625]  eta: 0:00:01  Loss: 1.1421 (0.8503)  Acc@1: 56.2500 (74.1647)  Acc@5: 100.0000 (97.0914)  time: 0.2276  data: 0.0028  max mem: 2503
Test: [Task 2]  [624/625]  eta: 0:00:00  Loss: 1.0654 (0.8502)  Acc@1: 56.2500 (74.1200)  Acc@5: 100.0000 (97.1100)  time: 0.2278  data: 0.0026  max mem: 2503
Test: [Task 2] Total time: 0:03:22 (0.3237 s / it)
* Acc@1 74.120 Acc@5 97.110 loss 0.850
Test: [Task 3]  [  0/625]  eta: 0:10:49  Loss: 0.1301 (0.1301)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)  time: 1.0394  data: 0.8229  max mem: 2503
Test: [Task 3]  [ 10/625]  eta: 0:03:04  Loss: 0.2603 (0.2354)  Acc@1: 100.0000 (96.5909)  Acc@5: 100.0000 (99.4318)  time: 0.3002  data: 0.0765  max mem: 2503
Test: [Task 3]  [ 20/625]  eta: 0:02:40  Loss: 0.2603 (0.2492)  Acc@1: 93.7500 (95.8333)  Acc@5: 100.0000 (99.1071)  time: 0.2271  data: 0.0024  max mem: 2503
Test: [Task 3]  [ 30/625]  eta: 0:02:30  Loss: 0.2396 (0.2439)  Acc@1: 93.7500 (95.7661)  Acc@5: 100.0000 (99.1935)  time: 0.2270  data: 0.0040  max mem: 2503
Test: [Task 3]  [ 40/625]  eta: 0:02:23  Loss: 0.1471 (0.2150)  Acc@1: 100.0000 (96.4939)  Acc@5: 100.0000 (99.3902)  time: 0.2253  data: 0.0035  max mem: 2503
Test: [Task 3]  [ 50/625]  eta: 0:02:18  Loss: 0.1155 (0.2113)  Acc@1: 100.0000 (96.6912)  Acc@5: 100.0000 (99.3873)  time: 0.2238  data: 0.0022  max mem: 2503
Test: [Task 3]  [ 60/625]  eta: 0:02:14  Loss: 0.1954 (0.2100)  Acc@1: 100.0000 (96.7213)  Acc@5: 100.0000 (99.4877)  time: 0.2241  data: 0.0026  max mem: 2503
Test: [Task 3]  [ 70/625]  eta: 0:02:11  Loss: 0.1417 (0.1993)  Acc@1: 100.0000 (96.9190)  Acc@5: 100.0000 (99.4718)  time: 0.2254  data: 0.0022  max mem: 2503
Test: [Task 3]  [ 80/625]  eta: 0:02:08  Loss: 0.1272 (0.1992)  Acc@1: 100.0000 (96.8364)  Acc@5: 100.0000 (99.5370)  time: 0.2271  data: 0.0027  max mem: 2503
Test: [Task 3]  [ 90/625]  eta: 0:02:05  Loss: 0.1646 (0.1998)  Acc@1: 100.0000 (96.9780)  Acc@5: 100.0000 (99.5192)  time: 0.2262  data: 0.0036  max mem: 2503
Test: [Task 3]  [100/625]  eta: 0:02:02  Loss: 0.1487 (0.1972)  Acc@1: 100.0000 (96.9678)  Acc@5: 100.0000 (99.5668)  time: 0.2234  data: 0.0038  max mem: 2503
Test: [Task 3]  [110/625]  eta: 0:01:59  Loss: 0.1222 (0.1923)  Acc@1: 100.0000 (97.2410)  Acc@5: 100.0000 (99.6059)  time: 0.2247  data: 0.0044  max mem: 2503
Test: [Task 3]  [120/625]  eta: 0:01:57  Loss: 0.1432 (0.1938)  Acc@1: 100.0000 (97.2624)  Acc@5: 100.0000 (99.6384)  time: 0.2240  data: 0.0031  max mem: 2503
Test: [Task 3]  [130/625]  eta: 0:01:54  Loss: 0.1567 (0.1931)  Acc@1: 100.0000 (97.3282)  Acc@5: 100.0000 (99.5706)  time: 0.2250  data: 0.0047  max mem: 2503
Test: [Task 3]  [140/625]  eta: 0:01:52  Loss: 0.1940 (0.1985)  Acc@1: 100.0000 (97.2518)  Acc@5: 100.0000 (99.4681)  time: 0.2301  data: 0.0090  max mem: 2503
Test: [Task 3]  [150/625]  eta: 0:01:50  Loss: 0.2246 (0.2051)  Acc@1: 93.7500 (97.1026)  Acc@5: 100.0000 (99.4205)  time: 0.2328  data: 0.0080  max mem: 2503
Test: [Task 3]  [160/625]  eta: 0:01:47  Loss: 0.1793 (0.2068)  Acc@1: 100.0000 (97.0497)  Acc@5: 100.0000 (99.3789)  time: 0.2287  data: 0.0046  max mem: 2503
Test: [Task 3]  [170/625]  eta: 0:01:45  Loss: 0.1452 (0.2053)  Acc@1: 100.0000 (97.0760)  Acc@5: 100.0000 (99.4152)  time: 0.2244  data: 0.0028  max mem: 2503
Test: [Task 3]  [180/625]  eta: 0:01:42  Loss: 0.2407 (0.2093)  Acc@1: 93.7500 (96.8923)  Acc@5: 100.0000 (99.4475)  time: 0.2261  data: 0.0022  max mem: 2503
Test: [Task 3]  [190/625]  eta: 0:01:40  Loss: 0.2261 (0.2084)  Acc@1: 93.7500 (96.9241)  Acc@5: 100.0000 (99.4437)  time: 0.2240  data: 0.0027  max mem: 2503
Test: [Task 3]  [200/625]  eta: 0:01:37  Loss: 0.2130 (0.2118)  Acc@1: 93.7500 (96.7973)  Acc@5: 100.0000 (99.4092)  time: 0.2262  data: 0.0052  max mem: 2503
Test: [Task 3]  [210/625]  eta: 0:01:35  Loss: 0.2052 (0.2131)  Acc@1: 100.0000 (96.7713)  Acc@5: 100.0000 (99.3780)  time: 0.2287  data: 0.0059  max mem: 2503
Test: [Task 3]  [220/625]  eta: 0:01:33  Loss: 0.1739 (0.2129)  Acc@1: 100.0000 (96.7195)  Acc@5: 100.0000 (99.3778)  time: 0.2289  data: 0.0069  max mem: 2503
Test: [Task 3]  [230/625]  eta: 0:01:30  Loss: 0.1742 (0.2140)  Acc@1: 93.7500 (96.6450)  Acc@5: 100.0000 (99.3777)  time: 0.2267  data: 0.0055  max mem: 2503
Test: [Task 3]  [240/625]  eta: 0:01:28  Loss: 0.2260 (0.2161)  Acc@1: 93.7500 (96.6027)  Acc@5: 100.0000 (99.3517)  time: 0.2211  data: 0.0024  max mem: 2503
Test: [Task 3]  [250/625]  eta: 0:01:25  Loss: 0.1366 (0.2141)  Acc@1: 100.0000 (96.6135)  Acc@5: 100.0000 (99.3775)  time: 0.2209  data: 0.0024  max mem: 2503
Test: [Task 3]  [260/625]  eta: 0:01:23  Loss: 0.1366 (0.2129)  Acc@1: 100.0000 (96.6236)  Acc@5: 100.0000 (99.3534)  time: 0.2215  data: 0.0020  max mem: 2503
Test: [Task 3]  [270/625]  eta: 0:01:21  Loss: 0.1579 (0.2117)  Acc@1: 93.7500 (96.6098)  Acc@5: 100.0000 (99.3773)  time: 0.2214  data: 0.0021  max mem: 2503
Test: [Task 3]  [280/625]  eta: 0:01:18  Loss: 0.1676 (0.2117)  Acc@1: 93.7500 (96.5747)  Acc@5: 100.0000 (99.3550)  time: 0.2261  data: 0.0045  max mem: 2503
Test: [Task 3]  [290/625]  eta: 0:01:16  Loss: 0.1704 (0.2112)  Acc@1: 93.7500 (96.5851)  Acc@5: 100.0000 (99.3771)  time: 0.2307  data: 0.0059  max mem: 2503
Test: [Task 3]  [300/625]  eta: 0:01:14  Loss: 0.1712 (0.2122)  Acc@1: 100.0000 (96.4909)  Acc@5: 100.0000 (99.3771)  time: 0.2262  data: 0.0039  max mem: 2503
Test: [Task 3]  [310/625]  eta: 0:01:11  Loss: 0.1834 (0.2140)  Acc@1: 100.0000 (96.4831)  Acc@5: 100.0000 (99.3167)  time: 0.2228  data: 0.0037  max mem: 2503
Test: [Task 3]  [320/625]  eta: 0:01:09  Loss: 0.1666 (0.2131)  Acc@1: 100.0000 (96.5148)  Acc@5: 100.0000 (99.2991)  time: 0.2226  data: 0.0034  max mem: 2503
Test: [Task 3]  [330/625]  eta: 0:01:07  Loss: 0.1774 (0.2144)  Acc@1: 93.7500 (96.4879)  Acc@5: 100.0000 (99.3014)  time: 0.2210  data: 0.0022  max mem: 2503
Test: [Task 3]  [340/625]  eta: 0:01:04  Loss: 0.1569 (0.2124)  Acc@1: 93.7500 (96.5176)  Acc@5: 100.0000 (99.3218)  time: 0.2235  data: 0.0041  max mem: 2503
Test: [Task 3]  [350/625]  eta: 0:01:02  Loss: 0.1481 (0.2125)  Acc@1: 93.7500 (96.4922)  Acc@5: 100.0000 (99.3056)  time: 0.2305  data: 0.0055  max mem: 2503
Test: [Task 3]  [360/625]  eta: 0:01:00  Loss: 0.1719 (0.2131)  Acc@1: 93.7500 (96.4681)  Acc@5: 100.0000 (99.3075)  time: 0.2320  data: 0.0047  max mem: 2503
Test: [Task 3]  [370/625]  eta: 0:00:58  Loss: 0.2300 (0.2140)  Acc@1: 93.7500 (96.4117)  Acc@5: 100.0000 (99.3261)  time: 0.2250  data: 0.0028  max mem: 2503
Test: [Task 3]  [380/625]  eta: 0:00:55  Loss: 0.2158 (0.2124)  Acc@1: 93.7500 (96.4567)  Acc@5: 100.0000 (99.3438)  time: 0.2219  data: 0.0027  max mem: 2503
Test: [Task 3]  [390/625]  eta: 0:00:53  Loss: 0.1482 (0.2123)  Acc@1: 100.0000 (96.4514)  Acc@5: 100.0000 (99.3606)  time: 0.2218  data: 0.0035  max mem: 2503
Test: [Task 3]  [400/625]  eta: 0:00:51  Loss: 0.1246 (0.2115)  Acc@1: 93.7500 (96.4308)  Acc@5: 100.0000 (99.3610)  time: 0.2238  data: 0.0031  max mem: 2503
Test: [Task 3]  [410/625]  eta: 0:00:48  Loss: 0.1866 (0.2127)  Acc@1: 93.7500 (96.4416)  Acc@5: 100.0000 (99.3309)  time: 0.2265  data: 0.0033  max mem: 2503
Test: [Task 3]  [420/625]  eta: 0:00:46  Loss: 0.1940 (0.2130)  Acc@1: 100.0000 (96.4222)  Acc@5: 100.0000 (99.3319)  time: 0.2249  data: 0.0039  max mem: 2503
Test: [Task 3]  [430/625]  eta: 0:00:44  Loss: 0.1570 (0.2127)  Acc@1: 100.0000 (96.4472)  Acc@5: 100.0000 (99.3329)  time: 0.2236  data: 0.0043  max mem: 2503
Test: [Task 3]  [440/625]  eta: 0:00:42  Loss: 0.1679 (0.2141)  Acc@1: 93.7500 (96.4002)  Acc@5: 100.0000 (99.3197)  time: 0.2256  data: 0.0037  max mem: 2503
Test: [Task 3]  [450/625]  eta: 0:00:39  Loss: 0.1679 (0.2142)  Acc@1: 100.0000 (96.4108)  Acc@5: 100.0000 (99.3210)  time: 0.2271  data: 0.0037  max mem: 2503
Test: [Task 3]  [460/625]  eta: 0:00:37  Loss: 0.1435 (0.2136)  Acc@1: 100.0000 (96.4479)  Acc@5: 100.0000 (99.3221)  time: 0.2300  data: 0.0047  max mem: 2503
Test: [Task 3]  [470/625]  eta: 0:00:35  Loss: 0.1669 (0.2135)  Acc@1: 100.0000 (96.4437)  Acc@5: 100.0000 (99.3232)  time: 0.2301  data: 0.0046  max mem: 2503
Test: [Task 3]  [480/625]  eta: 0:00:32  Loss: 0.2075 (0.2147)  Acc@1: 100.0000 (96.4397)  Acc@5: 100.0000 (99.3243)  time: 0.2237  data: 0.0033  max mem: 2503
Test: [Task 3]  [490/625]  eta: 0:00:30  Loss: 0.1980 (0.2152)  Acc@1: 100.0000 (96.4358)  Acc@5: 100.0000 (99.2999)  time: 0.2224  data: 0.0038  max mem: 2503
Test: [Task 3]  [500/625]  eta: 0:00:28  Loss: 0.1258 (0.2143)  Acc@1: 100.0000 (96.4696)  Acc@5: 100.0000 (99.3014)  time: 0.2234  data: 0.0041  max mem: 2503
Test: [Task 3]  [510/625]  eta: 0:00:26  Loss: 0.1158 (0.2134)  Acc@1: 100.0000 (96.4897)  Acc@5: 100.0000 (99.3151)  time: 0.2233  data: 0.0023  max mem: 2503
Test: [Task 3]  [520/625]  eta: 0:00:23  Loss: 0.1640 (0.2137)  Acc@1: 100.0000 (96.4611)  Acc@5: 100.0000 (99.3162)  time: 0.2253  data: 0.0043  max mem: 2503
Test: [Task 3]  [530/625]  eta: 0:00:21  Loss: 0.2000 (0.2143)  Acc@1: 93.7500 (96.4454)  Acc@5: 100.0000 (99.3173)  time: 0.2295  data: 0.0084  max mem: 2503
Test: [Task 3]  [540/625]  eta: 0:00:19  Loss: 0.2038 (0.2151)  Acc@1: 93.7500 (96.4418)  Acc@5: 100.0000 (99.3184)  time: 0.2306  data: 0.0057  max mem: 2503
Test: [Task 3]  [550/625]  eta: 0:00:17  Loss: 0.2095 (0.2158)  Acc@1: 93.7500 (96.4156)  Acc@5: 100.0000 (99.3081)  time: 0.2257  data: 0.0022  max mem: 2503
Test: [Task 3]  [560/625]  eta: 0:00:14  Loss: 0.1961 (0.2158)  Acc@1: 100.0000 (96.4461)  Acc@5: 100.0000 (99.3093)  time: 0.2254  data: 0.0033  max mem: 2503
Test: [Task 3]  [570/625]  eta: 0:00:12  Loss: 0.1711 (0.2154)  Acc@1: 100.0000 (96.4426)  Acc@5: 100.0000 (99.3104)  time: 0.2392  data: 0.0069  max mem: 2503
Test: [Task 3]  [580/625]  eta: 0:00:10  Loss: 0.2349 (0.2174)  Acc@1: 93.7500 (96.3748)  Acc@5: 100.0000 (99.3008)  time: 0.2377  data: 0.0068  max mem: 2503
Test: [Task 3]  [590/625]  eta: 0:00:07  Loss: 0.1606 (0.2164)  Acc@1: 100.0000 (96.4150)  Acc@5: 100.0000 (99.3126)  time: 0.2259  data: 0.0032  max mem: 2503
Test: [Task 3]  [600/625]  eta: 0:00:05  Loss: 0.1732 (0.2165)  Acc@1: 100.0000 (96.3706)  Acc@5: 100.0000 (99.3032)  time: 0.2250  data: 0.0020  max mem: 2503
Test: [Task 3]  [610/625]  eta: 0:00:03  Loss: 0.1938 (0.2159)  Acc@1: 93.7500 (96.3789)  Acc@5: 100.0000 (99.3146)  time: 0.2241  data: 0.0016  max mem: 2503
Test: [Task 3]  [620/625]  eta: 0:00:01  Loss: 0.2131 (0.2169)  Acc@1: 93.7500 (96.3366)  Acc@5: 100.0000 (99.3156)  time: 0.2251  data: 0.0014  max mem: 2503
Test: [Task 3]  [624/625]  eta: 0:00:00  Loss: 0.1922 (0.2162)  Acc@1: 100.0000 (96.3600)  Acc@5: 100.0000 (99.3200)  time: 0.2241  data: 0.0013  max mem: 2503
Test: [Task 3] Total time: 0:02:22 (0.2279 s / it)
* Acc@1 96.360 Acc@5 99.320 loss 0.216
Test: [Task 4]  [ 0/29]  eta: 0:00:28  Loss: 1.5467 (1.5467)  Acc@1: 43.7500 (43.7500)  Acc@5: 93.7500 (93.7500)  time: 0.9951  data: 0.7722  max mem: 2503
Test: [Task 4]  [10/29]  eta: 0:00:05  Loss: 1.6307 (1.4641)  Acc@1: 50.0000 (59.0909)  Acc@5: 87.5000 (89.2045)  time: 0.2959  data: 0.0713  max mem: 2503
Test: [Task 4]  [20/29]  eta: 0:00:02  Loss: 1.6282 (1.4703)  Acc@1: 68.7500 (61.9048)  Acc@5: 87.5000 (86.6071)  time: 0.2283  data: 0.0039  max mem: 2503
Test: [Task 4]  [28/29]  eta: 0:00:00  Loss: 1.4524 (1.4117)  Acc@1: 68.7500 (64.0523)  Acc@5: 87.5000 (87.5817)  time: 0.2225  data: 0.0039  max mem: 2503
Test: [Task 4] Total time: 0:00:07 (0.2634 s / it)
* Acc@1 64.052 Acc@5 87.582 loss 1.412
Test: [Task 5]  [  0/625]  eta: 0:09:55  Loss: 0.1685 (0.1685)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)  time: 0.9533  data: 0.7214  max mem: 2503
Test: [Task 5]  [ 10/625]  eta: 0:03:01  Loss: 0.4524 (0.4486)  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (98.8636)  time: 0.2953  data: 0.0686  max mem: 2503
Test: [Task 5]  [ 20/625]  eta: 0:02:37  Loss: 0.3690 (0.3940)  Acc@1: 87.5000 (90.1786)  Acc@5: 100.0000 (99.4048)  time: 0.2253  data: 0.0032  max mem: 2503
Test: [Task 5]  [ 30/625]  eta: 0:02:27  Loss: 0.4489 (0.4289)  Acc@1: 87.5000 (89.5161)  Acc@5: 100.0000 (99.1935)  time: 0.2223  data: 0.0023  max mem: 2503
Test: [Task 5]  [ 40/625]  eta: 0:02:22  Loss: 0.4231 (0.4223)  Acc@1: 87.5000 (89.9390)  Acc@5: 100.0000 (99.2378)  time: 0.2252  data: 0.0042  max mem: 2503
Test: [Task 5]  [ 50/625]  eta: 0:02:17  Loss: 0.4228 (0.4324)  Acc@1: 87.5000 (89.4608)  Acc@5: 100.0000 (98.8971)  time: 0.2230  data: 0.0048  max mem: 2503
Test: [Task 5]  [ 60/625]  eta: 0:02:13  Loss: 0.4101 (0.4248)  Acc@1: 87.5000 (89.7541)  Acc@5: 100.0000 (98.8730)  time: 0.2213  data: 0.0030  max mem: 2503
Test: [Task 5]  [ 70/625]  eta: 0:02:09  Loss: 0.4034 (0.4270)  Acc@1: 87.5000 (89.7007)  Acc@5: 100.0000 (98.8556)  time: 0.2234  data: 0.0037  max mem: 2503
Test: [Task 5]  [ 80/625]  eta: 0:02:06  Loss: 0.4498 (0.4370)  Acc@1: 87.5000 (89.3519)  Acc@5: 100.0000 (98.7654)  time: 0.2241  data: 0.0031  max mem: 2503
Test: [Task 5]  [ 90/625]  eta: 0:02:04  Loss: 0.3258 (0.4253)  Acc@1: 93.7500 (89.7665)  Acc@5: 100.0000 (98.8324)  time: 0.2266  data: 0.0026  max mem: 2503
Test: [Task 5]  [100/625]  eta: 0:02:01  Loss: 0.3333 (0.4287)  Acc@1: 87.5000 (89.6040)  Acc@5: 100.0000 (98.7624)  time: 0.2263  data: 0.0046  max mem: 2503
Test: [Task 5]  [110/625]  eta: 0:01:59  Loss: 0.4309 (0.4306)  Acc@1: 87.5000 (89.4707)  Acc@5: 100.0000 (98.8176)  time: 0.2285  data: 0.0074  max mem: 2503
Test: [Task 5]  [120/625]  eta: 0:01:57  Loss: 0.3483 (0.4198)  Acc@1: 87.5000 (89.8244)  Acc@5: 100.0000 (98.8636)  time: 0.2331  data: 0.0113  max mem: 2503
Test: [Task 5]  [130/625]  eta: 0:01:55  Loss: 0.4105 (0.4246)  Acc@1: 87.5000 (89.5992)  Acc@5: 100.0000 (98.7595)  time: 0.2372  data: 0.0169  max mem: 2503
Test: [Task 5]  [140/625]  eta: 0:01:52  Loss: 0.4307 (0.4215)  Acc@1: 87.5000 (89.6277)  Acc@5: 100.0000 (98.7145)  time: 0.2332  data: 0.0128  max mem: 2503
Test: [Task 5]  [150/625]  eta: 0:01:50  Loss: 0.3880 (0.4229)  Acc@1: 87.5000 (89.7351)  Acc@5: 100.0000 (98.6341)  time: 0.2290  data: 0.0069  max mem: 2503
Test: [Task 5]  [160/625]  eta: 0:01:47  Loss: 0.4198 (0.4252)  Acc@1: 87.5000 (89.5963)  Acc@5: 100.0000 (98.6025)  time: 0.2275  data: 0.0053  max mem: 2503
Test: [Task 5]  [170/625]  eta: 0:01:45  Loss: 0.4326 (0.4302)  Acc@1: 87.5000 (89.4006)  Acc@5: 100.0000 (98.5746)  time: 0.2240  data: 0.0040  max mem: 2503
Test: [Task 5]  [180/625]  eta: 0:01:42  Loss: 0.4326 (0.4310)  Acc@1: 87.5000 (89.4337)  Acc@5: 100.0000 (98.5497)  time: 0.2254  data: 0.0045  max mem: 2503
Test: [Task 5]  [190/625]  eta: 0:01:40  Loss: 0.5452 (0.4410)  Acc@1: 87.5000 (89.1034)  Acc@5: 100.0000 (98.3966)  time: 0.2215  data: 0.0020  max mem: 2503
Test: [Task 5]  [200/625]  eta: 0:01:37  Loss: 0.4334 (0.4375)  Acc@1: 87.5000 (89.1791)  Acc@5: 100.0000 (98.3831)  time: 0.2195  data: 0.0018  max mem: 2503
Test: [Task 5]  [210/625]  eta: 0:01:35  Loss: 0.4916 (0.4444)  Acc@1: 87.5000 (89.0107)  Acc@5: 100.0000 (98.3412)  time: 0.2224  data: 0.0025  max mem: 2503
Test: [Task 5]  [220/625]  eta: 0:01:32  Loss: 0.5338 (0.4467)  Acc@1: 87.5000 (88.9423)  Acc@5: 100.0000 (98.2749)  time: 0.2224  data: 0.0018  max mem: 2503
Test: [Task 5]  [230/625]  eta: 0:01:30  Loss: 0.4383 (0.4472)  Acc@1: 87.5000 (88.8799)  Acc@5: 100.0000 (98.2413)  time: 0.2220  data: 0.0022  max mem: 2503
Test: [Task 5]  [240/625]  eta: 0:01:27  Loss: 0.4253 (0.4467)  Acc@1: 87.5000 (88.9004)  Acc@5: 100.0000 (98.2884)  time: 0.2227  data: 0.0031  max mem: 2503
Test: [Task 5]  [250/625]  eta: 0:01:25  Loss: 0.3794 (0.4477)  Acc@1: 87.5000 (88.8944)  Acc@5: 100.0000 (98.2819)  time: 0.2225  data: 0.0028  max mem: 2503
Test: [Task 5]  [260/625]  eta: 0:01:23  Loss: 0.4996 (0.4503)  Acc@1: 87.5000 (88.7931)  Acc@5: 100.0000 (98.2280)  time: 0.2298  data: 0.0034  max mem: 2503
Test: [Task 5]  [270/625]  eta: 0:01:21  Loss: 0.4179 (0.4482)  Acc@1: 87.5000 (88.8838)  Acc@5: 100.0000 (98.2242)  time: 0.2307  data: 0.0041  max mem: 2503
Test: [Task 5]  [280/625]  eta: 0:01:18  Loss: 0.2958 (0.4437)  Acc@1: 93.7500 (88.9457)  Acc@5: 100.0000 (98.2874)  time: 0.2265  data: 0.0059  max mem: 2503
Test: [Task 5]  [290/625]  eta: 0:01:16  Loss: 0.2906 (0.4414)  Acc@1: 87.5000 (89.0464)  Acc@5: 100.0000 (98.2818)  time: 0.2248  data: 0.0046  max mem: 2503
Test: [Task 5]  [300/625]  eta: 0:01:14  Loss: 0.4374 (0.4441)  Acc@1: 87.5000 (88.8289)  Acc@5: 100.0000 (98.3181)  time: 0.2217  data: 0.0026  max mem: 2503
Test: [Task 5]  [310/625]  eta: 0:01:11  Loss: 0.4708 (0.4439)  Acc@1: 81.2500 (88.8264)  Acc@5: 100.0000 (98.3119)  time: 0.2232  data: 0.0035  max mem: 2503
Test: [Task 5]  [320/625]  eta: 0:01:09  Loss: 0.4214 (0.4430)  Acc@1: 93.7500 (88.8435)  Acc@5: 100.0000 (98.3450)  time: 0.2263  data: 0.0030  max mem: 2503
Test: [Task 5]  [330/625]  eta: 0:01:07  Loss: 0.4214 (0.4437)  Acc@1: 87.5000 (88.8218)  Acc@5: 100.0000 (98.3573)  time: 0.2275  data: 0.0028  max mem: 2503
Test: [Task 5]  [340/625]  eta: 0:01:04  Loss: 0.3334 (0.4407)  Acc@1: 87.5000 (88.9296)  Acc@5: 100.0000 (98.3688)  time: 0.2300  data: 0.0051  max mem: 2503
Test: [Task 5]  [350/625]  eta: 0:01:02  Loss: 0.4429 (0.4453)  Acc@1: 87.5000 (88.7999)  Acc@5: 100.0000 (98.3262)  time: 0.2287  data: 0.0062  max mem: 2503
Test: [Task 5]  [360/625]  eta: 0:01:00  Loss: 0.4429 (0.4436)  Acc@1: 87.5000 (88.8677)  Acc@5: 100.0000 (98.3553)  time: 0.2257  data: 0.0044  max mem: 2503
Test: [Task 5]  [370/625]  eta: 0:00:58  Loss: 0.3255 (0.4410)  Acc@1: 93.7500 (88.9319)  Acc@5: 100.0000 (98.3827)  time: 0.2257  data: 0.0040  max mem: 2503
Test: [Task 5]  [380/625]  eta: 0:00:55  Loss: 0.3767 (0.4424)  Acc@1: 93.7500 (88.9108)  Acc@5: 100.0000 (98.3432)  time: 0.2254  data: 0.0047  max mem: 2503
Test: [Task 5]  [390/625]  eta: 0:00:53  Loss: 0.4434 (0.4429)  Acc@1: 87.5000 (88.8587)  Acc@5: 100.0000 (98.3696)  time: 0.2259  data: 0.0049  max mem: 2503
Test: [Task 5]  [400/625]  eta: 0:00:51  Loss: 0.4434 (0.4413)  Acc@1: 87.5000 (88.8872)  Acc@5: 100.0000 (98.3946)  time: 0.2251  data: 0.0040  max mem: 2503
Test: [Task 5]  [410/625]  eta: 0:00:48  Loss: 0.3366 (0.4408)  Acc@1: 87.5000 (88.8990)  Acc@5: 100.0000 (98.3577)  time: 0.2266  data: 0.0046  max mem: 2503
Test: [Task 5]  [420/625]  eta: 0:00:46  Loss: 0.4158 (0.4418)  Acc@1: 87.5000 (88.7916)  Acc@5: 100.0000 (98.3670)  time: 0.2265  data: 0.0048  max mem: 2503
Test: [Task 5]  [430/625]  eta: 0:00:44  Loss: 0.3537 (0.4404)  Acc@1: 87.5000 (88.8631)  Acc@5: 100.0000 (98.3904)  time: 0.2243  data: 0.0046  max mem: 2503
Test: [Task 5]  [440/625]  eta: 0:00:42  Loss: 0.3413 (0.4396)  Acc@1: 87.5000 (88.8180)  Acc@5: 100.0000 (98.4127)  time: 0.2249  data: 0.0046  max mem: 2503
Test: [Task 5]  [450/625]  eta: 0:00:39  Loss: 0.3762 (0.4392)  Acc@1: 87.5000 (88.7888)  Acc@5: 100.0000 (98.4202)  time: 0.2282  data: 0.0067  max mem: 2503
Test: [Task 5]  [460/625]  eta: 0:00:37  Loss: 0.3792 (0.4379)  Acc@1: 87.5000 (88.8015)  Acc@5: 100.0000 (98.4544)  time: 0.2336  data: 0.0099  max mem: 2503
Test: [Task 5]  [470/625]  eta: 0:00:35  Loss: 0.3030 (0.4339)  Acc@1: 93.7500 (88.9464)  Acc@5: 100.0000 (98.4873)  time: 0.2303  data: 0.0068  max mem: 2503
Test: [Task 5]  [480/625]  eta: 0:00:33  Loss: 0.2910 (0.4338)  Acc@1: 93.7500 (88.9423)  Acc@5: 100.0000 (98.4797)  time: 0.2283  data: 0.0026  max mem: 2503
Test: [Task 5]  [490/625]  eta: 0:00:30  Loss: 0.3379 (0.4331)  Acc@1: 93.7500 (89.0020)  Acc@5: 100.0000 (98.4470)  time: 0.2332  data: 0.0036  max mem: 2503
Test: [Task 5]  [500/625]  eta: 0:00:28  Loss: 0.3816 (0.4341)  Acc@1: 87.5000 (88.9596)  Acc@5: 100.0000 (98.4406)  time: 0.2283  data: 0.0040  max mem: 2503
Test: [Task 5]  [510/625]  eta: 0:00:26  Loss: 0.4429 (0.4340)  Acc@1: 87.5000 (88.9310)  Acc@5: 100.0000 (98.4100)  time: 0.2243  data: 0.0031  max mem: 2503
Test: [Task 5]  [520/625]  eta: 0:00:23  Loss: 0.3919 (0.4325)  Acc@1: 87.5000 (88.9635)  Acc@5: 100.0000 (98.4285)  time: 0.2228  data: 0.0026  max mem: 2503
Test: [Task 5]  [530/625]  eta: 0:00:21  Loss: 0.3823 (0.4309)  Acc@1: 87.5000 (89.0066)  Acc@5: 100.0000 (98.4463)  time: 0.2249  data: 0.0033  max mem: 2503
Test: [Task 5]  [540/625]  eta: 0:00:19  Loss: 0.3669 (0.4299)  Acc@1: 87.5000 (89.0018)  Acc@5: 100.0000 (98.4519)  time: 0.2313  data: 0.0038  max mem: 2503
Test: [Task 5]  [550/625]  eta: 0:00:17  Loss: 0.3880 (0.4311)  Acc@1: 87.5000 (88.9519)  Acc@5: 100.0000 (98.4574)  time: 0.2303  data: 0.0049  max mem: 2503
Test: [Task 5]  [560/625]  eta: 0:00:14  Loss: 0.4344 (0.4315)  Acc@1: 87.5000 (88.9594)  Acc@5: 100.0000 (98.4626)  time: 0.2290  data: 0.0075  max mem: 2503
Test: [Task 5]  [570/625]  eta: 0:00:12  Loss: 0.3611 (0.4312)  Acc@1: 87.5000 (88.9777)  Acc@5: 100.0000 (98.4457)  time: 0.2290  data: 0.0075  max mem: 2503
Test: [Task 5]  [580/625]  eta: 0:00:10  Loss: 0.4026 (0.4322)  Acc@1: 87.5000 (88.9738)  Acc@5: 100.0000 (98.4294)  time: 0.2282  data: 0.0060  max mem: 2503
Test: [Task 5]  [590/625]  eta: 0:00:07  Loss: 0.4302 (0.4317)  Acc@1: 87.5000 (88.9594)  Acc@5: 100.0000 (98.4243)  time: 0.2277  data: 0.0057  max mem: 2503
Test: [Task 5]  [600/625]  eta: 0:00:05  Loss: 0.4180 (0.4308)  Acc@1: 87.5000 (89.0079)  Acc@5: 100.0000 (98.4401)  time: 0.2250  data: 0.0050  max mem: 2503
Test: [Task 5]  [610/625]  eta: 0:00:03  Loss: 0.3411 (0.4299)  Acc@1: 93.7500 (89.0241)  Acc@5: 100.0000 (98.4349)  time: 0.2239  data: 0.0029  max mem: 2503
Test: [Task 5]  [620/625]  eta: 0:00:01  Loss: 0.3026 (0.4280)  Acc@1: 93.7500 (89.0902)  Acc@5: 100.0000 (98.4400)  time: 0.2243  data: 0.0017  max mem: 2503
Test: [Task 5]  [624/625]  eta: 0:00:00  Loss: 0.3054 (0.4280)  Acc@1: 93.7500 (89.0700)  Acc@5: 100.0000 (98.4400)  time: 0.2231  data: 0.0013  max mem: 2503
Test: [Task 5] Total time: 0:02:22 (0.2281 s / it)
* Acc@1 89.070 Acc@5 98.440 loss 0.428
{0: {0: 26032, 1: 26032, 2: 26032, 3: 26032, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0, 10: 0, 11: 0, 12: 0, 13: 0, 14: 0, 15: 0, 16: 0, 17: 0, 18: 0, 19: 0}, 1: {0: 0, 1: 0, 2: 0, 3: 0, 4: 10000, 5: 10000, 6: 10000, 7: 10000, 8: 0, 9: 0, 10: 0, 11: 0, 12: 0, 13: 0, 14: 0, 15: 0, 16: 0, 17: 0, 18: 0, 19: 0}, 2: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 10000, 9: 10000, 10: 10000, 11: 10000, 12: 0, 13: 0, 14: 0, 15: 0, 16: 0, 17: 0, 18: 0, 19: 0}, 3: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0, 10: 0, 11: 0, 12: 459, 13: 459, 14: 459, 15: 459, 16: 0, 17: 0, 18: 0, 19: 0}, 4: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0, 10: 0, 11: 0, 12: 0, 13: 0, 14: 0, 15: 0, 16: 10000, 17: 10000, 18: 10000, 19: 10000}}
[Average accuracy till task5]	Acc@1: 78.8492	Acc@5: 94.8216	Loss: 0.8126	Forgetting: 8.8565	Backward: -8.8565
Total training time: 9:23:48
