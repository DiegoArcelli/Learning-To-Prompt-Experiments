/storagenfs/d.arcelli/Prompting-Based-CL-Methods-Experiments/.env/lib/python3.9/site-packages/torchvision/transforms/transforms.py:329: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.
  warnings.warn(
/storagenfs/d.arcelli/l2p-pytorch/continual_datasets/dataset_utils.py:335: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:199.)
  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)
Namespace(subparser_name='five_datasets_l2p', batch_size=16, epochs=5, train_type='l2p', model='vit_base_patch16_224', input_size=224, pretrained=True, drop=0.0, drop_path=0.0, opt='adam', opt_eps=1e-08, opt_betas=(0.9, 0.999), clip_grad=1.0, momentum=0.9, weight_decay=0.0, reinit_optimizer=True, sched='constant', lr=0.03, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, unscale_lr=True, color_jitter=None, aa=None, smoothing=0.1, train_interpolation='bicubic', reprob=0.0, remode='pixel', recount=1, data_path='./local_datasets/', dataset='5-datasets', shuffle=False, output_dir='./output_5_datasets', device='cuda', seed=729, eval=False, num_workers=4, pin_mem=True, world_size=1, dist_url='env://', num_tasks=5, train_mask=True, task_inc=False, prompt_pool=True, size=20, length=10, top_k=4, initializer='uniform', prompt_key=True, prompt_key_init='uniform', use_prompt_mask=False, shared_prompt_pool=False, shared_prompt_key=False, batchwise_prompt=False, embedding_key='cls', predefined_key='', pull_constraint=True, pull_constraint_coeff=0.5, global_pool='token', head_type='prompt', freeze=['blocks', 'patch_embed', 'cls_token', 'norm', 'pos_embed'], freeze_head=False, print_freq=10)
Not using distributed mode
['SVHN', 'MNIST', 'CIFAR10', 'NotMNIST', 'FashionMNIST']
Using downloaded and verified file: ./local_datasets/train_32x32.mat
Using downloaded and verified file: ./local_datasets/train_32x32.mat
Using downloaded and verified file: ./local_datasets/test_32x32.mat
Using downloaded and verified file: ./local_datasets/test_32x32.mat
Files already downloaded and verified
Files already downloaded and verified
File F/Q3Jvc3NvdmVyIEJvbGRPYmxpcXVlLnR0Zg==.png is broken
File A/RGVtb2NyYXRpY2FCb2xkT2xkc3R5bGUgQm9sZC50dGY=.png is broken
Creating original model: vit_base_patch16_224
Creating model: vit_base_patch16_224
number of params: 207410
Start training for 5 epochs
Train: Epoch[1/5]  [   0/4579]  eta: 2:49:57  Lr: 0.001875  Loss: 2.2359  Acc@1: 0.0000 (0.0000)  Acc@5: 50.0000 (50.0000)  time: 2.2270  data: 0.5779  max mem: 2497
Train: Epoch[1/5]  [  10/4579]  eta: 0:39:11  Lr: 0.001875  Loss: 2.2086  Acc@1: 18.7500 (17.6136)  Acc@5: 62.5000 (60.2273)  time: 0.5146  data: 0.0534  max mem: 2500
Train: Epoch[1/5]  [  20/4579]  eta: 0:32:52  Lr: 0.001875  Loss: 2.3220  Acc@1: 18.7500 (20.2381)  Acc@5: 62.5000 (63.3929)  time: 0.3431  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [  30/4579]  eta: 0:30:38  Lr: 0.001875  Loss: 1.7776  Acc@1: 18.7500 (19.5565)  Acc@5: 62.5000 (64.5161)  time: 0.3433  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [  40/4579]  eta: 0:29:27  Lr: 0.001875  Loss: 1.9806  Acc@1: 18.7500 (21.3415)  Acc@5: 75.0000 (67.5305)  time: 0.3437  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [  50/4579]  eta: 0:28:44  Lr: 0.001875  Loss: 1.8582  Acc@1: 25.0000 (22.4265)  Acc@5: 75.0000 (68.8725)  time: 0.3448  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [  60/4579]  eta: 0:28:14  Lr: 0.001875  Loss: 1.7461  Acc@1: 25.0000 (23.3607)  Acc@5: 75.0000 (70.1844)  time: 0.3457  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [  70/4579]  eta: 0:27:50  Lr: 0.001875  Loss: 1.5947  Acc@1: 25.0000 (23.1514)  Acc@5: 75.0000 (70.5106)  time: 0.3444  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [  80/4579]  eta: 0:27:32  Lr: 0.001875  Loss: 1.6639  Acc@1: 25.0000 (23.7654)  Acc@5: 75.0000 (71.0648)  time: 0.3439  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [  90/4579]  eta: 0:27:16  Lr: 0.001875  Loss: 1.6273  Acc@1: 31.2500 (24.5879)  Acc@5: 81.2500 (72.1154)  time: 0.3437  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [ 100/4579]  eta: 0:27:05  Lr: 0.001875  Loss: 1.8732  Acc@1: 25.0000 (24.8762)  Acc@5: 75.0000 (72.2153)  time: 0.3449  data: 0.0010  max mem: 2500
Train: Epoch[1/5]  [ 110/4579]  eta: 0:26:55  Lr: 0.001875  Loss: 1.6207  Acc@1: 25.0000 (25.2252)  Acc@5: 75.0000 (72.6914)  time: 0.3475  data: 0.0013  max mem: 2500
Train: Epoch[1/5]  [ 120/4579]  eta: 0:26:45  Lr: 0.001875  Loss: 1.5095  Acc@1: 25.0000 (25.6715)  Acc@5: 81.2500 (72.7789)  time: 0.3459  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [ 130/4579]  eta: 0:26:37  Lr: 0.001875  Loss: 1.5133  Acc@1: 25.0000 (26.0973)  Acc@5: 75.0000 (73.1870)  time: 0.3447  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 140/4579]  eta: 0:26:29  Lr: 0.001875  Loss: 1.5218  Acc@1: 25.0000 (26.2411)  Acc@5: 75.0000 (73.0940)  time: 0.3454  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [ 150/4579]  eta: 0:26:21  Lr: 0.001875  Loss: 1.4113  Acc@1: 31.2500 (26.8212)  Acc@5: 75.0000 (73.4272)  time: 0.3447  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [ 160/4579]  eta: 0:26:16  Lr: 0.001875  Loss: 1.1476  Acc@1: 37.5000 (27.4845)  Acc@5: 75.0000 (73.8742)  time: 0.3482  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [ 170/4579]  eta: 0:26:09  Lr: 0.001875  Loss: 1.4357  Acc@1: 37.5000 (27.8874)  Acc@5: 75.0000 (74.0863)  time: 0.3481  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 180/4579]  eta: 0:26:03  Lr: 0.001875  Loss: 1.0231  Acc@1: 37.5000 (28.3840)  Acc@5: 81.2500 (74.5856)  time: 0.3449  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 190/4579]  eta: 0:25:58  Lr: 0.001875  Loss: 0.9429  Acc@1: 37.5000 (28.8940)  Acc@5: 81.2500 (75.0000)  time: 0.3468  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 200/4579]  eta: 0:25:52  Lr: 0.001875  Loss: 1.1816  Acc@1: 37.5000 (29.2910)  Acc@5: 87.5000 (75.4975)  time: 0.3464  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 210/4579]  eta: 0:25:47  Lr: 0.001875  Loss: 1.1755  Acc@1: 31.2500 (29.2062)  Acc@5: 81.2500 (75.6813)  time: 0.3461  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 220/4579]  eta: 0:25:42  Lr: 0.001875  Loss: 1.2213  Acc@1: 31.2500 (29.6663)  Acc@5: 81.2500 (76.1029)  time: 0.3468  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 230/4579]  eta: 0:25:37  Lr: 0.001875  Loss: 0.9535  Acc@1: 37.5000 (29.8431)  Acc@5: 81.2500 (76.2987)  time: 0.3474  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [ 240/4579]  eta: 0:25:33  Lr: 0.001875  Loss: 0.8130  Acc@1: 37.5000 (30.2386)  Acc@5: 81.2500 (76.5820)  time: 0.3471  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [ 250/4579]  eta: 0:25:28  Lr: 0.001875  Loss: 0.8321  Acc@1: 37.5000 (30.3536)  Acc@5: 81.2500 (76.7181)  time: 0.3463  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [ 260/4579]  eta: 0:25:23  Lr: 0.001875  Loss: 0.7509  Acc@1: 31.2500 (30.6992)  Acc@5: 81.2500 (76.9875)  time: 0.3459  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [ 270/4579]  eta: 0:25:18  Lr: 0.001875  Loss: 1.0647  Acc@1: 37.5000 (30.8349)  Acc@5: 81.2500 (77.3063)  time: 0.3455  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [ 280/4579]  eta: 0:25:14  Lr: 0.001875  Loss: 1.0198  Acc@1: 37.5000 (31.1610)  Acc@5: 81.2500 (77.4021)  time: 0.3459  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [ 290/4579]  eta: 0:25:09  Lr: 0.001875  Loss: 0.5042  Acc@1: 37.5000 (31.6796)  Acc@5: 81.2500 (77.7706)  time: 0.3459  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 300/4579]  eta: 0:25:05  Lr: 0.001875  Loss: 0.7573  Acc@1: 43.7500 (31.9560)  Acc@5: 87.5000 (78.0316)  time: 0.3459  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 310/4579]  eta: 0:25:01  Lr: 0.001875  Loss: 0.8799  Acc@1: 37.5000 (32.1141)  Acc@5: 81.2500 (78.1551)  time: 0.3472  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [ 320/4579]  eta: 0:24:57  Lr: 0.001875  Loss: 0.9972  Acc@1: 37.5000 (32.3598)  Acc@5: 81.2500 (78.3294)  time: 0.3496  data: 0.0012  max mem: 2500
Train: Epoch[1/5]  [ 330/4579]  eta: 0:24:53  Lr: 0.001875  Loss: 0.6127  Acc@1: 37.5000 (32.5529)  Acc@5: 87.5000 (78.5687)  time: 0.3494  data: 0.0016  max mem: 2500
Train: Epoch[1/5]  [ 340/4579]  eta: 0:24:49  Lr: 0.001875  Loss: 0.6070  Acc@1: 37.5000 (32.7163)  Acc@5: 81.2500 (78.6107)  time: 0.3479  data: 0.0009  max mem: 2500
Train: Epoch[1/5]  [ 350/4579]  eta: 0:24:46  Lr: 0.001875  Loss: 0.7745  Acc@1: 37.5000 (32.9238)  Acc@5: 81.2500 (78.7927)  time: 0.3483  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 360/4579]  eta: 0:24:42  Lr: 0.001875  Loss: 0.6418  Acc@1: 43.7500 (33.2237)  Acc@5: 87.5000 (79.0512)  time: 0.3483  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 370/4579]  eta: 0:24:38  Lr: 0.001875  Loss: 0.7689  Acc@1: 43.7500 (33.4063)  Acc@5: 87.5000 (79.1105)  time: 0.3486  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 380/4579]  eta: 0:24:34  Lr: 0.001875  Loss: 0.6867  Acc@1: 43.7500 (33.6450)  Acc@5: 81.2500 (79.2815)  time: 0.3490  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 390/4579]  eta: 0:24:30  Lr: 0.001875  Loss: 0.5059  Acc@1: 43.7500 (33.9514)  Acc@5: 81.2500 (79.3478)  time: 0.3481  data: 0.0011  max mem: 2500
Train: Epoch[1/5]  [ 400/4579]  eta: 0:24:26  Lr: 0.001875  Loss: 0.5090  Acc@1: 37.5000 (34.0711)  Acc@5: 81.2500 (79.5200)  time: 0.3484  data: 0.0011  max mem: 2500
Train: Epoch[1/5]  [ 410/4579]  eta: 0:24:23  Lr: 0.001875  Loss: 0.4533  Acc@1: 37.5000 (34.2762)  Acc@5: 87.5000 (79.6533)  time: 0.3481  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 420/4579]  eta: 0:24:19  Lr: 0.001875  Loss: 0.1280  Acc@1: 43.7500 (34.5309)  Acc@5: 87.5000 (79.8397)  time: 0.3472  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 430/4579]  eta: 0:24:15  Lr: 0.001875  Loss: 0.5333  Acc@1: 37.5000 (34.6143)  Acc@5: 87.5000 (79.9159)  time: 0.3485  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 440/4579]  eta: 0:24:11  Lr: 0.001875  Loss: 0.4781  Acc@1: 50.0000 (34.9773)  Acc@5: 87.5000 (80.0595)  time: 0.3490  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 450/4579]  eta: 0:24:08  Lr: 0.001875  Loss: 0.2890  Acc@1: 50.0000 (35.1580)  Acc@5: 87.5000 (80.1691)  time: 0.3481  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [ 460/4579]  eta: 0:24:04  Lr: 0.001875  Loss: 0.5028  Acc@1: 43.7500 (35.3444)  Acc@5: 87.5000 (80.3145)  time: 0.3482  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [ 470/4579]  eta: 0:24:00  Lr: 0.001875  Loss: 0.8325  Acc@1: 37.5000 (35.2972)  Acc@5: 81.2500 (80.3742)  time: 0.3479  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [ 480/4579]  eta: 0:23:57  Lr: 0.001875  Loss: 0.0954  Acc@1: 37.5000 (35.4210)  Acc@5: 87.5000 (80.4314)  time: 0.3489  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [ 490/4579]  eta: 0:23:53  Lr: 0.001875  Loss: 0.1073  Acc@1: 43.7500 (35.6543)  Acc@5: 87.5000 (80.5499)  time: 0.3492  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [ 500/4579]  eta: 0:23:50  Lr: 0.001875  Loss: 0.0219  Acc@1: 50.0000 (35.9780)  Acc@5: 87.5000 (80.7136)  time: 0.3509  data: 0.0020  max mem: 2500
Train: Epoch[1/5]  [ 510/4579]  eta: 0:23:46  Lr: 0.001875  Loss: 0.2148  Acc@1: 50.0000 (36.0568)  Acc@5: 87.5000 (80.8097)  time: 0.3507  data: 0.0020  max mem: 2500
Train: Epoch[1/5]  [ 520/4579]  eta: 0:23:42  Lr: 0.001875  Loss: 0.0977  Acc@1: 37.5000 (36.1804)  Acc@5: 87.5000 (80.9021)  time: 0.3484  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [ 530/4579]  eta: 0:23:39  Lr: 0.001875  Loss: 0.4096  Acc@1: 50.0000 (36.4171)  Acc@5: 87.5000 (80.9322)  time: 0.3486  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [ 540/4579]  eta: 0:23:35  Lr: 0.001875  Loss: 0.3508  Acc@1: 50.0000 (36.6220)  Acc@5: 81.2500 (80.9612)  time: 0.3493  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [ 550/4579]  eta: 0:23:32  Lr: 0.001875  Loss: 0.4218  Acc@1: 43.7500 (36.6493)  Acc@5: 81.2500 (81.0458)  time: 0.3503  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [ 560/4579]  eta: 0:23:28  Lr: 0.001875  Loss: -0.0284  Acc@1: 37.5000 (36.6867)  Acc@5: 87.5000 (81.1832)  time: 0.3510  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [ 570/4579]  eta: 0:23:25  Lr: 0.001875  Loss: 0.1543  Acc@1: 43.7500 (36.8870)  Acc@5: 87.5000 (81.3047)  time: 0.3507  data: 0.0009  max mem: 2500
Train: Epoch[1/5]  [ 580/4579]  eta: 0:23:21  Lr: 0.001875  Loss: 0.0932  Acc@1: 50.0000 (37.0697)  Acc@5: 87.5000 (81.3791)  time: 0.3505  data: 0.0015  max mem: 2500
Train: Epoch[1/5]  [ 590/4579]  eta: 0:23:18  Lr: 0.001875  Loss: 0.2556  Acc@1: 43.7500 (37.1616)  Acc@5: 87.5000 (81.4827)  time: 0.3506  data: 0.0013  max mem: 2500
Train: Epoch[1/5]  [ 600/4579]  eta: 0:23:14  Lr: 0.001875  Loss: -0.2151  Acc@1: 43.7500 (37.2712)  Acc@5: 87.5000 (81.5516)  time: 0.3504  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [ 610/4579]  eta: 0:23:11  Lr: 0.001875  Loss: 0.3117  Acc@1: 50.0000 (37.3875)  Acc@5: 87.5000 (81.6592)  time: 0.3502  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [ 620/4579]  eta: 0:23:07  Lr: 0.001875  Loss: 0.3584  Acc@1: 50.0000 (37.4899)  Acc@5: 87.5000 (81.7130)  time: 0.3506  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [ 630/4579]  eta: 0:23:04  Lr: 0.001875  Loss: 0.3373  Acc@1: 43.7500 (37.6189)  Acc@5: 81.2500 (81.7353)  time: 0.3509  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [ 640/4579]  eta: 0:23:00  Lr: 0.001875  Loss: 0.3290  Acc@1: 43.7500 (37.7340)  Acc@5: 87.5000 (81.8448)  time: 0.3495  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [ 650/4579]  eta: 0:22:56  Lr: 0.001875  Loss: 0.5193  Acc@1: 43.7500 (37.8552)  Acc@5: 87.5000 (81.9028)  time: 0.3490  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [ 660/4579]  eta: 0:22:53  Lr: 0.001875  Loss: -0.1451  Acc@1: 50.0000 (38.1051)  Acc@5: 81.2500 (81.9119)  time: 0.3490  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 670/4579]  eta: 0:22:49  Lr: 0.001875  Loss: 0.0726  Acc@1: 50.0000 (38.2545)  Acc@5: 87.5000 (82.0138)  time: 0.3494  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 680/4579]  eta: 0:22:46  Lr: 0.001875  Loss: 0.2828  Acc@1: 43.7500 (38.3168)  Acc@5: 87.5000 (82.0026)  time: 0.3498  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 690/4579]  eta: 0:22:42  Lr: 0.001875  Loss: -0.1042  Acc@1: 43.7500 (38.4045)  Acc@5: 81.2500 (82.0188)  time: 0.3499  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 700/4579]  eta: 0:22:39  Lr: 0.001875  Loss: 0.0189  Acc@1: 43.7500 (38.5342)  Acc@5: 87.5000 (82.1148)  time: 0.3510  data: 0.0011  max mem: 2500
Train: Epoch[1/5]  [ 710/4579]  eta: 0:22:35  Lr: 0.001875  Loss: 0.4458  Acc@1: 43.7500 (38.6603)  Acc@5: 87.5000 (82.1994)  time: 0.3505  data: 0.0011  max mem: 2500
Train: Epoch[1/5]  [ 720/4579]  eta: 0:22:32  Lr: 0.001875  Loss: 0.4268  Acc@1: 43.7500 (38.6876)  Acc@5: 81.2500 (82.2209)  time: 0.3506  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [ 730/4579]  eta: 0:22:28  Lr: 0.001875  Loss: -0.1816  Acc@1: 43.7500 (38.7568)  Acc@5: 87.5000 (82.3102)  time: 0.3511  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [ 740/4579]  eta: 0:22:25  Lr: 0.001875  Loss: 0.3159  Acc@1: 43.7500 (38.8158)  Acc@5: 87.5000 (82.3802)  time: 0.3504  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [ 750/4579]  eta: 0:22:21  Lr: 0.001875  Loss: 0.1549  Acc@1: 43.7500 (38.9814)  Acc@5: 87.5000 (82.4318)  time: 0.3507  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [ 760/4579]  eta: 0:22:18  Lr: 0.001875  Loss: -0.0895  Acc@1: 50.0000 (39.1261)  Acc@5: 87.5000 (82.5394)  time: 0.3512  data: 0.0010  max mem: 2500
Train: Epoch[1/5]  [ 770/4579]  eta: 0:22:14  Lr: 0.001875  Loss: 0.1676  Acc@1: 50.0000 (39.2753)  Acc@5: 93.7500 (82.6524)  time: 0.3516  data: 0.0010  max mem: 2500
Train: Epoch[1/5]  [ 780/4579]  eta: 0:22:11  Lr: 0.001875  Loss: 0.1781  Acc@1: 50.0000 (39.3486)  Acc@5: 93.7500 (82.7065)  time: 0.3509  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [ 790/4579]  eta: 0:22:07  Lr: 0.001875  Loss: 0.0494  Acc@1: 43.7500 (39.4595)  Acc@5: 81.2500 (82.6960)  time: 0.3499  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [ 800/4579]  eta: 0:22:04  Lr: 0.001875  Loss: 0.0437  Acc@1: 50.0000 (39.6145)  Acc@5: 87.5000 (82.7949)  time: 0.3496  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [ 810/4579]  eta: 0:22:00  Lr: 0.001875  Loss: -0.0909  Acc@1: 50.0000 (39.7041)  Acc@5: 87.5000 (82.8144)  time: 0.3495  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 820/4579]  eta: 0:21:57  Lr: 0.001875  Loss: 0.3068  Acc@1: 50.0000 (39.8447)  Acc@5: 87.5000 (82.8791)  time: 0.3505  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [ 830/4579]  eta: 0:21:53  Lr: 0.001875  Loss: -0.0152  Acc@1: 50.0000 (39.9594)  Acc@5: 87.5000 (82.9573)  time: 0.3514  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [ 840/4579]  eta: 0:21:50  Lr: 0.001875  Loss: -0.2866  Acc@1: 43.7500 (40.0490)  Acc@5: 93.7500 (83.0485)  time: 0.3545  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [ 850/4579]  eta: 0:21:47  Lr: 0.001875  Loss: 0.3728  Acc@1: 43.7500 (40.0852)  Acc@5: 87.5000 (83.0861)  time: 0.3541  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [ 860/4579]  eta: 0:21:43  Lr: 0.001875  Loss: 0.1550  Acc@1: 43.7500 (40.0769)  Acc@5: 87.5000 (83.1156)  time: 0.3510  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 870/4579]  eta: 0:21:40  Lr: 0.001875  Loss: -0.0657  Acc@1: 43.7500 (40.1693)  Acc@5: 87.5000 (83.1372)  time: 0.3505  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 880/4579]  eta: 0:21:36  Lr: 0.001875  Loss: 0.3780  Acc@1: 43.7500 (40.2667)  Acc@5: 87.5000 (83.2151)  time: 0.3495  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 890/4579]  eta: 0:21:33  Lr: 0.001875  Loss: -0.0562  Acc@1: 43.7500 (40.3269)  Acc@5: 93.7500 (83.2772)  time: 0.3497  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [ 900/4579]  eta: 0:21:29  Lr: 0.001875  Loss: 0.6998  Acc@1: 43.7500 (40.3996)  Acc@5: 87.5000 (83.2825)  time: 0.3501  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [ 910/4579]  eta: 0:21:26  Lr: 0.001875  Loss: -0.4007  Acc@1: 50.0000 (40.5598)  Acc@5: 87.5000 (83.3768)  time: 0.3506  data: 0.0014  max mem: 2500
Train: Epoch[1/5]  [ 920/4579]  eta: 0:21:22  Lr: 0.001875  Loss: -0.1048  Acc@1: 50.0000 (40.6420)  Acc@5: 87.5000 (83.4148)  time: 0.3499  data: 0.0014  max mem: 2500
Train: Epoch[1/5]  [ 930/4579]  eta: 0:21:18  Lr: 0.001875  Loss: -0.2195  Acc@1: 43.7500 (40.6888)  Acc@5: 87.5000 (83.4318)  time: 0.3500  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [ 940/4579]  eta: 0:21:15  Lr: 0.001875  Loss: 0.0680  Acc@1: 43.7500 (40.7744)  Acc@5: 87.5000 (83.4950)  time: 0.3502  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [ 950/4579]  eta: 0:21:11  Lr: 0.001875  Loss: -0.0449  Acc@1: 56.2500 (40.9437)  Acc@5: 87.5000 (83.5042)  time: 0.3487  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [ 960/4579]  eta: 0:21:08  Lr: 0.001875  Loss: -0.4250  Acc@1: 62.5000 (41.0835)  Acc@5: 87.5000 (83.5588)  time: 0.3488  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [ 970/4579]  eta: 0:21:04  Lr: 0.001875  Loss: 0.4540  Acc@1: 43.7500 (41.0788)  Acc@5: 87.5000 (83.5929)  time: 0.3488  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [ 980/4579]  eta: 0:21:01  Lr: 0.001875  Loss: -0.3004  Acc@1: 50.0000 (41.1697)  Acc@5: 87.5000 (83.6455)  time: 0.3484  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 990/4579]  eta: 0:20:57  Lr: 0.001875  Loss: -0.1646  Acc@1: 50.0000 (41.2841)  Acc@5: 87.5000 (83.7096)  time: 0.3490  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1000/4579]  eta: 0:20:54  Lr: 0.001875  Loss: -0.0381  Acc@1: 50.0000 (41.3961)  Acc@5: 87.5000 (83.7725)  time: 0.3506  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1010/4579]  eta: 0:20:50  Lr: 0.001875  Loss: 0.1524  Acc@1: 50.0000 (41.4441)  Acc@5: 87.5000 (83.7970)  time: 0.3501  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1020/4579]  eta: 0:20:46  Lr: 0.001875  Loss: 0.5260  Acc@1: 37.5000 (41.4422)  Acc@5: 93.7500 (83.8639)  time: 0.3487  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1030/4579]  eta: 0:20:43  Lr: 0.001875  Loss: -0.2962  Acc@1: 43.7500 (41.4646)  Acc@5: 87.5000 (83.8931)  time: 0.3493  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1040/4579]  eta: 0:20:39  Lr: 0.001875  Loss: -0.3214  Acc@1: 50.0000 (41.5826)  Acc@5: 87.5000 (83.9817)  time: 0.3503  data: 0.0013  max mem: 2500
Train: Epoch[1/5]  [1050/4579]  eta: 0:20:36  Lr: 0.001875  Loss: 0.1062  Acc@1: 50.0000 (41.6270)  Acc@5: 87.5000 (83.9914)  time: 0.3499  data: 0.0013  max mem: 2500
Train: Epoch[1/5]  [1060/4579]  eta: 0:20:32  Lr: 0.001875  Loss: 0.5536  Acc@1: 43.7500 (41.6824)  Acc@5: 87.5000 (84.0127)  time: 0.3497  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [1070/4579]  eta: 0:20:29  Lr: 0.001875  Loss: -0.2668  Acc@1: 50.0000 (41.7834)  Acc@5: 87.5000 (84.0686)  time: 0.3507  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [1080/4579]  eta: 0:20:25  Lr: 0.001875  Loss: 0.2747  Acc@1: 50.0000 (41.8247)  Acc@5: 87.5000 (84.1062)  time: 0.3506  data: 0.0010  max mem: 2500
Train: Epoch[1/5]  [1090/4579]  eta: 0:20:22  Lr: 0.001875  Loss: 0.7168  Acc@1: 50.0000 (41.8996)  Acc@5: 87.5000 (84.1430)  time: 0.3507  data: 0.0010  max mem: 2500
Train: Epoch[1/5]  [1100/4579]  eta: 0:20:18  Lr: 0.001875  Loss: -0.3382  Acc@1: 50.0000 (42.0016)  Acc@5: 87.5000 (84.2132)  time: 0.3499  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [1110/4579]  eta: 0:20:15  Lr: 0.001875  Loss: -0.1221  Acc@1: 50.0000 (42.1130)  Acc@5: 93.7500 (84.2541)  time: 0.3490  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [1120/4579]  eta: 0:20:11  Lr: 0.001875  Loss: -0.2193  Acc@1: 56.2500 (42.1889)  Acc@5: 93.7500 (84.3109)  time: 0.3485  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [1130/4579]  eta: 0:20:08  Lr: 0.001875  Loss: -0.0787  Acc@1: 50.0000 (42.2524)  Acc@5: 87.5000 (84.3446)  time: 0.3484  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1140/4579]  eta: 0:20:04  Lr: 0.001875  Loss: 0.5731  Acc@1: 50.0000 (42.2765)  Acc@5: 87.5000 (84.3339)  time: 0.3514  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [1150/4579]  eta: 0:20:01  Lr: 0.001875  Loss: -0.3075  Acc@1: 50.0000 (42.3816)  Acc@5: 81.2500 (84.3669)  time: 0.3506  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [1160/4579]  eta: 0:19:57  Lr: 0.001875  Loss: 0.2077  Acc@1: 56.2500 (42.4849)  Acc@5: 87.5000 (84.3777)  time: 0.3486  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1170/4579]  eta: 0:19:54  Lr: 0.001875  Loss: 0.0258  Acc@1: 50.0000 (42.4851)  Acc@5: 87.5000 (84.3830)  time: 0.3491  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1180/4579]  eta: 0:19:50  Lr: 0.001875  Loss: -0.1659  Acc@1: 43.7500 (42.5593)  Acc@5: 87.5000 (84.4464)  time: 0.3495  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1190/4579]  eta: 0:19:47  Lr: 0.001875  Loss: -0.0176  Acc@1: 50.0000 (42.6532)  Acc@5: 87.5000 (84.4878)  time: 0.3495  data: 0.0009  max mem: 2500
Train: Epoch[1/5]  [1200/4579]  eta: 0:19:43  Lr: 0.001875  Loss: -0.1670  Acc@1: 56.2500 (42.7716)  Acc@5: 87.5000 (84.5441)  time: 0.3492  data: 0.0010  max mem: 2500
Train: Epoch[1/5]  [1210/4579]  eta: 0:19:40  Lr: 0.001875  Loss: 0.1290  Acc@1: 50.0000 (42.8055)  Acc@5: 93.7500 (84.5840)  time: 0.3485  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [1220/4579]  eta: 0:19:36  Lr: 0.001875  Loss: -0.2303  Acc@1: 50.0000 (42.9208)  Acc@5: 87.5000 (84.6130)  time: 0.3475  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1230/4579]  eta: 0:19:32  Lr: 0.001875  Loss: -0.0360  Acc@1: 56.2500 (42.9986)  Acc@5: 87.5000 (84.6517)  time: 0.3477  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1240/4579]  eta: 0:19:29  Lr: 0.001875  Loss: -0.0904  Acc@1: 50.0000 (43.0600)  Acc@5: 87.5000 (84.6646)  time: 0.3477  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1250/4579]  eta: 0:19:25  Lr: 0.001875  Loss: 0.4488  Acc@1: 50.0000 (43.1205)  Acc@5: 81.2500 (84.6673)  time: 0.3492  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [1260/4579]  eta: 0:19:22  Lr: 0.001875  Loss: 0.3232  Acc@1: 50.0000 (43.1701)  Acc@5: 87.5000 (84.6897)  time: 0.3490  data: 0.0011  max mem: 2500
Train: Epoch[1/5]  [1270/4579]  eta: 0:19:18  Lr: 0.001875  Loss: -0.2466  Acc@1: 50.0000 (43.1747)  Acc@5: 87.5000 (84.6823)  time: 0.3475  data: 0.0009  max mem: 2500
Train: Epoch[1/5]  [1280/4579]  eta: 0:19:15  Lr: 0.001875  Loss: -0.0883  Acc@1: 50.0000 (43.2572)  Acc@5: 87.5000 (84.7190)  time: 0.3475  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1290/4579]  eta: 0:19:11  Lr: 0.001875  Loss: -0.1356  Acc@1: 50.0000 (43.3288)  Acc@5: 87.5000 (84.7550)  time: 0.3483  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1300/4579]  eta: 0:19:07  Lr: 0.001875  Loss: 0.0490  Acc@1: 50.0000 (43.3705)  Acc@5: 87.5000 (84.7809)  time: 0.3480  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1310/4579]  eta: 0:19:04  Lr: 0.001875  Loss: 0.0131  Acc@1: 50.0000 (43.4211)  Acc@5: 87.5000 (84.8255)  time: 0.3477  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1320/4579]  eta: 0:19:00  Lr: 0.001875  Loss: -0.0178  Acc@1: 50.0000 (43.4992)  Acc@5: 87.5000 (84.8410)  time: 0.3485  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1330/4579]  eta: 0:18:57  Lr: 0.001875  Loss: 0.1627  Acc@1: 50.0000 (43.5434)  Acc@5: 87.5000 (84.8563)  time: 0.3487  data: 0.0009  max mem: 2500
Train: Epoch[1/5]  [1340/4579]  eta: 0:18:53  Lr: 0.001875  Loss: -0.0437  Acc@1: 50.0000 (43.6754)  Acc@5: 87.5000 (84.9180)  time: 0.3487  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [1350/4579]  eta: 0:18:50  Lr: 0.001875  Loss: 0.0730  Acc@1: 56.2500 (43.7084)  Acc@5: 93.7500 (84.9417)  time: 0.3483  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1360/4579]  eta: 0:18:46  Lr: 0.001875  Loss: -0.5789  Acc@1: 50.0000 (43.8005)  Acc@5: 87.5000 (84.9743)  time: 0.3472  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1370/4579]  eta: 0:18:43  Lr: 0.001875  Loss: -0.4293  Acc@1: 56.2500 (43.9278)  Acc@5: 87.5000 (84.9973)  time: 0.3473  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1380/4579]  eta: 0:18:39  Lr: 0.001875  Loss: -0.2018  Acc@1: 56.2500 (44.0487)  Acc@5: 87.5000 (85.0561)  time: 0.3478  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1390/4579]  eta: 0:18:36  Lr: 0.001875  Loss: -0.1271  Acc@1: 56.2500 (44.0555)  Acc@5: 93.7500 (85.0782)  time: 0.3487  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1400/4579]  eta: 0:18:32  Lr: 0.001875  Loss: -0.3522  Acc@1: 50.0000 (44.1024)  Acc@5: 87.5000 (85.1089)  time: 0.3494  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1410/4579]  eta: 0:18:29  Lr: 0.001875  Loss: -0.1293  Acc@1: 50.0000 (44.1974)  Acc@5: 93.7500 (85.1568)  time: 0.3488  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1420/4579]  eta: 0:18:25  Lr: 0.001875  Loss: 0.0112  Acc@1: 56.2500 (44.2822)  Acc@5: 87.5000 (85.1777)  time: 0.3482  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1430/4579]  eta: 0:18:21  Lr: 0.001875  Loss: 0.3791  Acc@1: 50.0000 (44.3003)  Acc@5: 87.5000 (85.1765)  time: 0.3489  data: 0.0009  max mem: 2500
Train: Epoch[1/5]  [1440/4579]  eta: 0:18:18  Lr: 0.001875  Loss: 0.1366  Acc@1: 50.0000 (44.4006)  Acc@5: 87.5000 (85.2099)  time: 0.3492  data: 0.0009  max mem: 2500
Train: Epoch[1/5]  [1450/4579]  eta: 0:18:14  Lr: 0.001875  Loss: 0.1126  Acc@1: 56.2500 (44.4823)  Acc@5: 93.7500 (85.2731)  time: 0.3486  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1460/4579]  eta: 0:18:11  Lr: 0.001875  Loss: 0.2162  Acc@1: 50.0000 (44.5072)  Acc@5: 93.7500 (85.2883)  time: 0.3483  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1470/4579]  eta: 0:18:07  Lr: 0.001875  Loss: -0.0605  Acc@1: 50.0000 (44.5870)  Acc@5: 87.5000 (85.3161)  time: 0.3482  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1480/4579]  eta: 0:18:04  Lr: 0.001875  Loss: -0.0227  Acc@1: 56.2500 (44.6320)  Acc@5: 87.5000 (85.3013)  time: 0.3490  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1490/4579]  eta: 0:18:00  Lr: 0.001875  Loss: -0.0943  Acc@1: 56.2500 (44.6890)  Acc@5: 87.5000 (85.3496)  time: 0.3506  data: 0.0012  max mem: 2500
Train: Epoch[1/5]  [1500/4579]  eta: 0:17:57  Lr: 0.001875  Loss: -0.0007  Acc@1: 50.0000 (44.7035)  Acc@5: 87.5000 (85.3431)  time: 0.3496  data: 0.0012  max mem: 2500
Train: Epoch[1/5]  [1510/4579]  eta: 0:17:53  Lr: 0.001875  Loss: -0.0171  Acc@1: 43.7500 (44.7303)  Acc@5: 87.5000 (85.3491)  time: 0.3477  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1520/4579]  eta: 0:17:50  Lr: 0.001875  Loss: 0.0120  Acc@1: 50.0000 (44.7855)  Acc@5: 87.5000 (85.3632)  time: 0.3479  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1530/4579]  eta: 0:17:46  Lr: 0.001875  Loss: -0.4037  Acc@1: 56.2500 (44.8971)  Acc@5: 93.7500 (85.4099)  time: 0.3489  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [1540/4579]  eta: 0:17:43  Lr: 0.001875  Loss: 0.2431  Acc@1: 62.5000 (44.9667)  Acc@5: 93.7500 (85.4437)  time: 0.3485  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1550/4579]  eta: 0:17:39  Lr: 0.001875  Loss: -0.4495  Acc@1: 56.2500 (45.0234)  Acc@5: 87.5000 (85.4529)  time: 0.3499  data: 0.0012  max mem: 2500
Train: Epoch[1/5]  [1560/4579]  eta: 0:17:36  Lr: 0.001875  Loss: -0.3238  Acc@1: 56.2500 (45.0793)  Acc@5: 87.5000 (85.4821)  time: 0.3514  data: 0.0028  max mem: 2500
Train: Epoch[1/5]  [1570/4579]  eta: 0:17:32  Lr: 0.001875  Loss: 0.2831  Acc@1: 50.0000 (45.1146)  Acc@5: 87.5000 (85.4909)  time: 0.3491  data: 0.0020  max mem: 2500
Train: Epoch[1/5]  [1580/4579]  eta: 0:17:29  Lr: 0.001875  Loss: -0.2025  Acc@1: 50.0000 (45.1613)  Acc@5: 81.2500 (85.4878)  time: 0.3482  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1590/4579]  eta: 0:17:25  Lr: 0.001875  Loss: -0.1969  Acc@1: 56.2500 (45.2467)  Acc@5: 81.2500 (85.4887)  time: 0.3483  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1600/4579]  eta: 0:17:22  Lr: 0.001875  Loss: -0.7500  Acc@1: 62.5000 (45.3545)  Acc@5: 87.5000 (85.5325)  time: 0.3478  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [1610/4579]  eta: 0:17:18  Lr: 0.001875  Loss: -0.0063  Acc@1: 56.2500 (45.4105)  Acc@5: 93.7500 (85.5563)  time: 0.3482  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [1620/4579]  eta: 0:17:15  Lr: 0.001875  Loss: -0.3292  Acc@1: 50.0000 (45.4465)  Acc@5: 87.5000 (85.5568)  time: 0.3497  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1630/4579]  eta: 0:17:11  Lr: 0.001875  Loss: 0.2038  Acc@1: 50.0000 (45.4744)  Acc@5: 87.5000 (85.5687)  time: 0.3495  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1640/4579]  eta: 0:17:08  Lr: 0.001875  Loss: -0.0820  Acc@1: 50.0000 (45.5515)  Acc@5: 93.7500 (85.6109)  time: 0.3489  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [1650/4579]  eta: 0:17:04  Lr: 0.001875  Loss: 0.0827  Acc@1: 50.0000 (45.5671)  Acc@5: 87.5000 (85.6072)  time: 0.3500  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1660/4579]  eta: 0:17:01  Lr: 0.001875  Loss: 0.2269  Acc@1: 43.7500 (45.5900)  Acc@5: 87.5000 (85.6111)  time: 0.3493  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [1670/4579]  eta: 0:16:57  Lr: 0.001875  Loss: -0.2468  Acc@1: 56.2500 (45.6762)  Acc@5: 93.7500 (85.6373)  time: 0.3474  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [1680/4579]  eta: 0:16:53  Lr: 0.001875  Loss: -0.0028  Acc@1: 56.2500 (45.7540)  Acc@5: 93.7500 (85.6521)  time: 0.3468  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1690/4579]  eta: 0:16:50  Lr: 0.001875  Loss: -0.1641  Acc@1: 62.5000 (45.8383)  Acc@5: 87.5000 (85.6631)  time: 0.3475  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [1700/4579]  eta: 0:16:46  Lr: 0.001875  Loss: -0.2702  Acc@1: 50.0000 (45.8591)  Acc@5: 93.7500 (85.6812)  time: 0.3483  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [1710/4579]  eta: 0:16:43  Lr: 0.001875  Loss: -0.0896  Acc@1: 50.0000 (45.9234)  Acc@5: 93.7500 (85.7211)  time: 0.3478  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1720/4579]  eta: 0:16:39  Lr: 0.001875  Loss: -0.1478  Acc@1: 56.2500 (45.9762)  Acc@5: 87.5000 (85.7241)  time: 0.3473  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [1730/4579]  eta: 0:16:36  Lr: 0.001875  Loss: 0.4633  Acc@1: 50.0000 (45.9886)  Acc@5: 93.7500 (85.7633)  time: 0.3480  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [1740/4579]  eta: 0:16:32  Lr: 0.001875  Loss: 0.7629  Acc@1: 50.0000 (46.0045)  Acc@5: 87.5000 (85.7481)  time: 0.3487  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1750/4579]  eta: 0:16:29  Lr: 0.001875  Loss: -0.2863  Acc@1: 50.0000 (46.0451)  Acc@5: 87.5000 (85.7796)  time: 0.3489  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1760/4579]  eta: 0:16:25  Lr: 0.001875  Loss: 0.1120  Acc@1: 50.0000 (46.0676)  Acc@5: 87.5000 (85.7822)  time: 0.3487  data: 0.0010  max mem: 2500
Train: Epoch[1/5]  [1770/4579]  eta: 0:16:22  Lr: 0.001875  Loss: -0.1550  Acc@1: 56.2500 (46.1145)  Acc@5: 87.5000 (85.7919)  time: 0.3478  data: 0.0010  max mem: 2500
Train: Epoch[1/5]  [1780/4579]  eta: 0:16:18  Lr: 0.001875  Loss: -0.3503  Acc@1: 56.2500 (46.1854)  Acc@5: 87.5000 (85.8156)  time: 0.3484  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1790/4579]  eta: 0:16:15  Lr: 0.001875  Loss: 0.0028  Acc@1: 56.2500 (46.2032)  Acc@5: 87.5000 (85.8250)  time: 0.3491  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1800/4579]  eta: 0:16:11  Lr: 0.001875  Loss: -0.3217  Acc@1: 50.0000 (46.2486)  Acc@5: 87.5000 (85.8377)  time: 0.3483  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [1810/4579]  eta: 0:16:08  Lr: 0.001875  Loss: -0.4493  Acc@1: 50.0000 (46.2831)  Acc@5: 87.5000 (85.8538)  time: 0.3475  data: 0.0009  max mem: 2500
Train: Epoch[1/5]  [1820/4579]  eta: 0:16:04  Lr: 0.001875  Loss: -0.0951  Acc@1: 50.0000 (46.3482)  Acc@5: 93.7500 (85.9006)  time: 0.3482  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1830/4579]  eta: 0:16:01  Lr: 0.001875  Loss: -0.1438  Acc@1: 56.2500 (46.3852)  Acc@5: 93.7500 (85.9093)  time: 0.3514  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1840/4579]  eta: 0:15:57  Lr: 0.001875  Loss: 0.0680  Acc@1: 56.2500 (46.4388)  Acc@5: 93.7500 (85.9350)  time: 0.3505  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1850/4579]  eta: 0:15:54  Lr: 0.001875  Loss: 0.3163  Acc@1: 56.2500 (46.4884)  Acc@5: 93.7500 (85.9603)  time: 0.3485  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1860/4579]  eta: 0:15:50  Lr: 0.001875  Loss: 0.3171  Acc@1: 56.2500 (46.5408)  Acc@5: 93.7500 (85.9854)  time: 0.3509  data: 0.0024  max mem: 2500
Train: Epoch[1/5]  [1870/4579]  eta: 0:15:47  Lr: 0.001875  Loss: 0.1151  Acc@1: 56.2500 (46.5961)  Acc@5: 93.7500 (86.0202)  time: 0.3515  data: 0.0031  max mem: 2500
Train: Epoch[1/5]  [1880/4579]  eta: 0:15:43  Lr: 0.001875  Loss: -0.5089  Acc@1: 56.2500 (46.6441)  Acc@5: 93.7500 (86.0280)  time: 0.3492  data: 0.0011  max mem: 2500
Train: Epoch[1/5]  [1890/4579]  eta: 0:15:40  Lr: 0.001875  Loss: -0.3752  Acc@1: 50.0000 (46.6618)  Acc@5: 93.7500 (86.0557)  time: 0.3508  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1900/4579]  eta: 0:15:36  Lr: 0.001875  Loss: 0.0031  Acc@1: 50.0000 (46.6925)  Acc@5: 93.7500 (86.0961)  time: 0.3514  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1910/4579]  eta: 0:15:33  Lr: 0.001875  Loss: -0.0600  Acc@1: 50.0000 (46.7360)  Acc@5: 87.5000 (86.1035)  time: 0.3494  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1920/4579]  eta: 0:15:29  Lr: 0.001875  Loss: 0.1769  Acc@1: 56.2500 (46.7953)  Acc@5: 87.5000 (86.1107)  time: 0.3499  data: 0.0011  max mem: 2500
Train: Epoch[1/5]  [1930/4579]  eta: 0:15:26  Lr: 0.001875  Loss: 0.8857  Acc@1: 56.2500 (46.8184)  Acc@5: 87.5000 (86.1115)  time: 0.3484  data: 0.0011  max mem: 2500
Train: Epoch[1/5]  [1940/4579]  eta: 0:15:22  Lr: 0.001875  Loss: 0.6527  Acc@1: 43.7500 (46.8122)  Acc@5: 87.5000 (86.1090)  time: 0.3473  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1950/4579]  eta: 0:15:19  Lr: 0.001875  Loss: -0.3359  Acc@1: 50.0000 (46.8606)  Acc@5: 87.5000 (86.1257)  time: 0.3489  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1960/4579]  eta: 0:15:15  Lr: 0.001875  Loss: -0.3904  Acc@1: 56.2500 (46.8989)  Acc@5: 93.7500 (86.1423)  time: 0.3498  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1970/4579]  eta: 0:15:12  Lr: 0.001875  Loss: -0.2336  Acc@1: 56.2500 (46.9654)  Acc@5: 93.7500 (86.1555)  time: 0.3493  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [1980/4579]  eta: 0:15:08  Lr: 0.001875  Loss: 0.0982  Acc@1: 56.2500 (47.0059)  Acc@5: 87.5000 (86.1686)  time: 0.3482  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [1990/4579]  eta: 0:15:05  Lr: 0.001875  Loss: -0.3418  Acc@1: 56.2500 (47.0681)  Acc@5: 87.5000 (86.1910)  time: 0.3481  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2000/4579]  eta: 0:15:01  Lr: 0.001875  Loss: -0.0235  Acc@1: 56.2500 (47.1108)  Acc@5: 87.5000 (86.1944)  time: 0.3496  data: 0.0015  max mem: 2500
Train: Epoch[1/5]  [2010/4579]  eta: 0:14:58  Lr: 0.001875  Loss: -0.4920  Acc@1: 56.2500 (47.1532)  Acc@5: 87.5000 (86.1885)  time: 0.3497  data: 0.0016  max mem: 2500
Train: Epoch[1/5]  [2020/4579]  eta: 0:14:54  Lr: 0.001875  Loss: -0.2810  Acc@1: 56.2500 (47.1920)  Acc@5: 87.5000 (86.2073)  time: 0.3483  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2030/4579]  eta: 0:14:51  Lr: 0.001875  Loss: -0.2911  Acc@1: 56.2500 (47.2243)  Acc@5: 87.5000 (86.2229)  time: 0.3480  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2040/4579]  eta: 0:14:47  Lr: 0.001875  Loss: -0.6105  Acc@1: 50.0000 (47.2287)  Acc@5: 87.5000 (86.2231)  time: 0.3493  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2050/4579]  eta: 0:14:44  Lr: 0.001875  Loss: 0.0507  Acc@1: 56.2500 (47.2910)  Acc@5: 87.5000 (86.2415)  time: 0.3502  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2060/4579]  eta: 0:14:40  Lr: 0.001875  Loss: 0.0161  Acc@1: 56.2500 (47.3162)  Acc@5: 93.7500 (86.2779)  time: 0.3494  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2070/4579]  eta: 0:14:37  Lr: 0.001875  Loss: 0.1719  Acc@1: 50.0000 (47.3654)  Acc@5: 93.7500 (86.2989)  time: 0.3486  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2080/4579]  eta: 0:14:33  Lr: 0.001875  Loss: 0.3227  Acc@1: 56.2500 (47.3931)  Acc@5: 87.5000 (86.3017)  time: 0.3480  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2090/4579]  eta: 0:14:30  Lr: 0.001875  Loss: -0.2206  Acc@1: 50.0000 (47.4235)  Acc@5: 87.5000 (86.2984)  time: 0.3485  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2100/4579]  eta: 0:14:26  Lr: 0.001875  Loss: -0.4150  Acc@1: 50.0000 (47.4417)  Acc@5: 87.5000 (86.3250)  time: 0.3488  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [2110/4579]  eta: 0:14:23  Lr: 0.001875  Loss: 0.1977  Acc@1: 56.2500 (47.4864)  Acc@5: 93.7500 (86.3394)  time: 0.3494  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [2120/4579]  eta: 0:14:19  Lr: 0.001875  Loss: -0.5660  Acc@1: 62.5000 (47.5601)  Acc@5: 93.7500 (86.3537)  time: 0.3506  data: 0.0014  max mem: 2500
Train: Epoch[1/5]  [2130/4579]  eta: 0:14:16  Lr: 0.001875  Loss: -0.4251  Acc@1: 62.5000 (47.5950)  Acc@5: 93.7500 (86.3767)  time: 0.3499  data: 0.0014  max mem: 2500
Train: Epoch[1/5]  [2140/4579]  eta: 0:14:12  Lr: 0.001875  Loss: -0.1712  Acc@1: 62.5000 (47.6471)  Acc@5: 93.7500 (86.4024)  time: 0.3496  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2150/4579]  eta: 0:14:09  Lr: 0.001875  Loss: -0.0078  Acc@1: 56.2500 (47.6726)  Acc@5: 93.7500 (86.4191)  time: 0.3497  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2160/4579]  eta: 0:14:05  Lr: 0.001875  Loss: -0.0995  Acc@1: 56.2500 (47.7354)  Acc@5: 87.5000 (86.4212)  time: 0.3499  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [2170/4579]  eta: 0:14:02  Lr: 0.001875  Loss: 0.1332  Acc@1: 56.2500 (47.7862)  Acc@5: 87.5000 (86.4435)  time: 0.3495  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2180/4579]  eta: 0:13:58  Lr: 0.001875  Loss: 0.1335  Acc@1: 56.2500 (47.8221)  Acc@5: 87.5000 (86.4426)  time: 0.3510  data: 0.0016  max mem: 2500
Train: Epoch[1/5]  [2190/4579]  eta: 0:13:55  Lr: 0.001875  Loss: -0.2746  Acc@1: 56.2500 (47.8663)  Acc@5: 87.5000 (86.4474)  time: 0.3507  data: 0.0016  max mem: 2500
Train: Epoch[1/5]  [2200/4579]  eta: 0:13:51  Lr: 0.001875  Loss: 0.0018  Acc@1: 56.2500 (47.8987)  Acc@5: 87.5000 (86.4493)  time: 0.3496  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2210/4579]  eta: 0:13:48  Lr: 0.001875  Loss: -0.3724  Acc@1: 56.2500 (47.9562)  Acc@5: 87.5000 (86.4682)  time: 0.3505  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2220/4579]  eta: 0:13:44  Lr: 0.001875  Loss: -0.3765  Acc@1: 56.2500 (47.9880)  Acc@5: 87.5000 (86.4926)  time: 0.3499  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2230/4579]  eta: 0:13:41  Lr: 0.001875  Loss: -0.2140  Acc@1: 56.2500 (47.9914)  Acc@5: 87.5000 (86.5027)  time: 0.3494  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2240/4579]  eta: 0:13:37  Lr: 0.001875  Loss: 0.0787  Acc@1: 50.0000 (48.0059)  Acc@5: 87.5000 (86.5099)  time: 0.3500  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2250/4579]  eta: 0:13:34  Lr: 0.001875  Loss: -0.3751  Acc@1: 56.2500 (48.0287)  Acc@5: 87.5000 (86.5254)  time: 0.3499  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2260/4579]  eta: 0:13:30  Lr: 0.001875  Loss: -0.4275  Acc@1: 50.0000 (48.0429)  Acc@5: 87.5000 (86.5463)  time: 0.3478  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2270/4579]  eta: 0:13:27  Lr: 0.001875  Loss: -0.6664  Acc@1: 56.2500 (48.0818)  Acc@5: 87.5000 (86.5698)  time: 0.3475  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [2280/4579]  eta: 0:13:23  Lr: 0.001875  Loss: -0.0828  Acc@1: 50.0000 (48.0847)  Acc@5: 87.5000 (86.5684)  time: 0.3485  data: 0.0009  max mem: 2500
Train: Epoch[1/5]  [2290/4579]  eta: 0:13:20  Lr: 0.001875  Loss: -0.4835  Acc@1: 56.2500 (48.1395)  Acc@5: 87.5000 (86.5752)  time: 0.3492  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [2300/4579]  eta: 0:13:16  Lr: 0.001875  Loss: 0.4101  Acc@1: 56.2500 (48.1530)  Acc@5: 87.5000 (86.5738)  time: 0.3494  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [2310/4579]  eta: 0:13:13  Lr: 0.001875  Loss: 0.3621  Acc@1: 50.0000 (48.1934)  Acc@5: 87.5000 (86.5886)  time: 0.3484  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2320/4579]  eta: 0:13:09  Lr: 0.001875  Loss: -0.3570  Acc@1: 56.2500 (48.2093)  Acc@5: 87.5000 (86.5979)  time: 0.3492  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [2330/4579]  eta: 0:13:06  Lr: 0.001875  Loss: 0.5180  Acc@1: 56.2500 (48.2357)  Acc@5: 87.5000 (86.6018)  time: 0.3504  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [2340/4579]  eta: 0:13:02  Lr: 0.001875  Loss: -0.6429  Acc@1: 56.2500 (48.2860)  Acc@5: 87.5000 (86.6136)  time: 0.3484  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2350/4579]  eta: 0:12:59  Lr: 0.001875  Loss: -0.3059  Acc@1: 56.2500 (48.3092)  Acc@5: 87.5000 (86.6280)  time: 0.3484  data: 0.0012  max mem: 2500
Train: Epoch[1/5]  [2360/4579]  eta: 0:12:55  Lr: 0.001875  Loss: -0.0579  Acc@1: 56.2500 (48.3270)  Acc@5: 93.7500 (86.6450)  time: 0.3505  data: 0.0011  max mem: 2500
Train: Epoch[1/5]  [2370/4579]  eta: 0:12:52  Lr: 0.001875  Loss: 0.0931  Acc@1: 56.2500 (48.3736)  Acc@5: 93.7500 (86.6565)  time: 0.3496  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2380/4579]  eta: 0:12:48  Lr: 0.001875  Loss: 0.2049  Acc@1: 56.2500 (48.3988)  Acc@5: 87.5000 (86.6653)  time: 0.3491  data: 0.0009  max mem: 2500
Train: Epoch[1/5]  [2390/4579]  eta: 0:12:45  Lr: 0.001875  Loss: 0.0261  Acc@1: 56.2500 (48.4368)  Acc@5: 87.5000 (86.6740)  time: 0.3500  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [2400/4579]  eta: 0:12:41  Lr: 0.001875  Loss: -0.1260  Acc@1: 62.5000 (48.5136)  Acc@5: 93.7500 (86.7035)  time: 0.3496  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [2410/4579]  eta: 0:12:38  Lr: 0.001875  Loss: -0.4641  Acc@1: 62.5000 (48.5509)  Acc@5: 93.7500 (86.7094)  time: 0.3499  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [2420/4579]  eta: 0:12:34  Lr: 0.001875  Loss: -0.3658  Acc@1: 56.2500 (48.5672)  Acc@5: 87.5000 (86.7204)  time: 0.3498  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2430/4579]  eta: 0:12:31  Lr: 0.001875  Loss: -0.0669  Acc@1: 56.2500 (48.6143)  Acc@5: 87.5000 (86.7339)  time: 0.3492  data: 0.0009  max mem: 2500
Train: Epoch[1/5]  [2440/4579]  eta: 0:12:27  Lr: 0.001875  Loss: -0.1881  Acc@1: 50.0000 (48.6174)  Acc@5: 93.7500 (86.7421)  time: 0.3495  data: 0.0011  max mem: 2500
Train: Epoch[1/5]  [2450/4579]  eta: 0:12:24  Lr: 0.001875  Loss: -0.4043  Acc@1: 50.0000 (48.6332)  Acc@5: 93.7500 (86.7554)  time: 0.3493  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [2460/4579]  eta: 0:12:20  Lr: 0.001875  Loss: -0.2300  Acc@1: 56.2500 (48.6997)  Acc@5: 93.7500 (86.7737)  time: 0.3488  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2470/4579]  eta: 0:12:17  Lr: 0.001875  Loss: -0.0575  Acc@1: 62.5000 (48.7454)  Acc@5: 93.7500 (86.7893)  time: 0.3494  data: 0.0014  max mem: 2500
Train: Epoch[1/5]  [2480/4579]  eta: 0:12:13  Lr: 0.001875  Loss: -0.6438  Acc@1: 50.0000 (48.7480)  Acc@5: 87.5000 (86.7946)  time: 0.3502  data: 0.0014  max mem: 2500
Train: Epoch[1/5]  [2490/4579]  eta: 0:12:10  Lr: 0.001875  Loss: -0.2232  Acc@1: 50.0000 (48.7630)  Acc@5: 87.5000 (86.7849)  time: 0.3491  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2500/4579]  eta: 0:12:06  Lr: 0.001875  Loss: -0.1759  Acc@1: 56.2500 (48.7855)  Acc@5: 87.5000 (86.8003)  time: 0.3479  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2510/4579]  eta: 0:12:03  Lr: 0.001875  Loss: -0.1791  Acc@1: 56.2500 (48.8351)  Acc@5: 87.5000 (86.8180)  time: 0.3489  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2520/4579]  eta: 0:11:59  Lr: 0.001875  Loss: 0.1019  Acc@1: 56.2500 (48.8596)  Acc@5: 87.5000 (86.8257)  time: 0.3505  data: 0.0010  max mem: 2500
Train: Epoch[1/5]  [2530/4579]  eta: 0:11:56  Lr: 0.001875  Loss: -0.4810  Acc@1: 50.0000 (48.8912)  Acc@5: 87.5000 (86.8357)  time: 0.3492  data: 0.0011  max mem: 2500
Train: Epoch[1/5]  [2540/4579]  eta: 0:11:52  Lr: 0.001875  Loss: -0.0234  Acc@1: 56.2500 (48.9202)  Acc@5: 87.5000 (86.8506)  time: 0.3479  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2550/4579]  eta: 0:11:49  Lr: 0.001875  Loss: -0.4710  Acc@1: 56.2500 (48.9734)  Acc@5: 93.7500 (86.8679)  time: 0.3479  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2560/4579]  eta: 0:11:45  Lr: 0.001875  Loss: 0.1064  Acc@1: 62.5000 (49.0141)  Acc@5: 87.5000 (86.8752)  time: 0.3492  data: 0.0011  max mem: 2500
Train: Epoch[1/5]  [2570/4579]  eta: 0:11:42  Lr: 0.001875  Loss: -0.2994  Acc@1: 62.5000 (49.0446)  Acc@5: 87.5000 (86.9020)  time: 0.3504  data: 0.0013  max mem: 2500
Train: Epoch[1/5]  [2580/4579]  eta: 0:11:38  Lr: 0.001875  Loss: -0.4426  Acc@1: 56.2500 (49.0556)  Acc@5: 93.7500 (86.9067)  time: 0.3508  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2590/4579]  eta: 0:11:35  Lr: 0.001875  Loss: -0.5229  Acc@1: 50.0000 (49.0665)  Acc@5: 87.5000 (86.9187)  time: 0.3511  data: 0.0012  max mem: 2500
Train: Epoch[1/5]  [2600/4579]  eta: 0:11:31  Lr: 0.001875  Loss: -0.2320  Acc@1: 56.2500 (49.0941)  Acc@5: 93.7500 (86.9473)  time: 0.3503  data: 0.0014  max mem: 2500
Train: Epoch[1/5]  [2610/4579]  eta: 0:11:28  Lr: 0.001875  Loss: -0.0775  Acc@1: 62.5000 (49.1430)  Acc@5: 93.7500 (86.9566)  time: 0.3493  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [2620/4579]  eta: 0:11:24  Lr: 0.001875  Loss: -0.1653  Acc@1: 56.2500 (49.1773)  Acc@5: 87.5000 (86.9587)  time: 0.3485  data: 0.0009  max mem: 2500
Train: Epoch[1/5]  [2630/4579]  eta: 0:11:21  Lr: 0.001875  Loss: 0.0678  Acc@1: 56.2500 (49.1971)  Acc@5: 87.5000 (86.9703)  time: 0.3488  data: 0.0009  max mem: 2500
Train: Epoch[1/5]  [2640/4579]  eta: 0:11:17  Lr: 0.001875  Loss: -0.1602  Acc@1: 56.2500 (49.2285)  Acc@5: 93.7500 (86.9794)  time: 0.3507  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [2650/4579]  eta: 0:11:14  Lr: 0.001875  Loss: 0.0012  Acc@1: 50.0000 (49.2338)  Acc@5: 87.5000 (86.9884)  time: 0.3498  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [2660/4579]  eta: 0:11:10  Lr: 0.001875  Loss: -0.4636  Acc@1: 50.0000 (49.2625)  Acc@5: 93.7500 (87.0021)  time: 0.3478  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2670/4579]  eta: 0:11:07  Lr: 0.001875  Loss: -0.4866  Acc@1: 56.2500 (49.3004)  Acc@5: 93.7500 (87.0273)  time: 0.3488  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2680/4579]  eta: 0:11:03  Lr: 0.001875  Loss: -0.5852  Acc@1: 56.2500 (49.3123)  Acc@5: 87.5000 (87.0221)  time: 0.3500  data: 0.0015  max mem: 2500
Train: Epoch[1/5]  [2690/4579]  eta: 0:11:00  Lr: 0.001875  Loss: -0.1274  Acc@1: 50.0000 (49.3334)  Acc@5: 87.5000 (87.0192)  time: 0.3509  data: 0.0026  max mem: 2500
Train: Epoch[1/5]  [2700/4579]  eta: 0:10:56  Lr: 0.001875  Loss: -0.4741  Acc@1: 50.0000 (49.3405)  Acc@5: 87.5000 (87.0210)  time: 0.3508  data: 0.0017  max mem: 2500
Train: Epoch[1/5]  [2710/4579]  eta: 0:10:53  Lr: 0.001875  Loss: 0.1000  Acc@1: 56.2500 (49.3660)  Acc@5: 87.5000 (87.0228)  time: 0.3495  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2720/4579]  eta: 0:10:49  Lr: 0.001875  Loss: -0.1655  Acc@1: 56.2500 (49.4005)  Acc@5: 87.5000 (87.0337)  time: 0.3486  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2730/4579]  eta: 0:10:46  Lr: 0.001875  Loss: 0.1638  Acc@1: 56.2500 (49.4324)  Acc@5: 93.7500 (87.0560)  time: 0.3504  data: 0.0017  max mem: 2500
Train: Epoch[1/5]  [2740/4579]  eta: 0:10:42  Lr: 0.001875  Loss: -0.5303  Acc@1: 56.2500 (49.4596)  Acc@5: 93.7500 (87.0736)  time: 0.3502  data: 0.0021  max mem: 2500
Train: Epoch[1/5]  [2750/4579]  eta: 0:10:39  Lr: 0.001875  Loss: -0.5492  Acc@1: 56.2500 (49.5025)  Acc@5: 93.7500 (87.0911)  time: 0.3483  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [2760/4579]  eta: 0:10:35  Lr: 0.001875  Loss: -0.4132  Acc@1: 56.2500 (49.5314)  Acc@5: 93.7500 (87.1061)  time: 0.3485  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2770/4579]  eta: 0:10:32  Lr: 0.001875  Loss: -0.0949  Acc@1: 56.2500 (49.5692)  Acc@5: 93.7500 (87.1166)  time: 0.3480  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2780/4579]  eta: 0:10:28  Lr: 0.001875  Loss: -0.1364  Acc@1: 62.5000 (49.6134)  Acc@5: 93.7500 (87.1314)  time: 0.3483  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2790/4579]  eta: 0:10:25  Lr: 0.001875  Loss: 0.2326  Acc@1: 56.2500 (49.6327)  Acc@5: 93.7500 (87.1417)  time: 0.3504  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2800/4579]  eta: 0:10:21  Lr: 0.001875  Loss: 0.0463  Acc@1: 56.2500 (49.6586)  Acc@5: 93.7500 (87.1541)  time: 0.3510  data: 0.0010  max mem: 2500
Train: Epoch[1/5]  [2810/4579]  eta: 0:10:18  Lr: 0.001875  Loss: 0.0305  Acc@1: 56.2500 (49.6865)  Acc@5: 87.5000 (87.1687)  time: 0.3487  data: 0.0010  max mem: 2500
Train: Epoch[1/5]  [2820/4579]  eta: 0:10:14  Lr: 0.001875  Loss: 0.0564  Acc@1: 56.2500 (49.7275)  Acc@5: 87.5000 (87.1743)  time: 0.3476  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2830/4579]  eta: 0:10:11  Lr: 0.001875  Loss: -0.5845  Acc@1: 56.2500 (49.7505)  Acc@5: 93.7500 (87.1975)  time: 0.3485  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2840/4579]  eta: 0:10:07  Lr: 0.001875  Loss: 0.0680  Acc@1: 50.0000 (49.7514)  Acc@5: 93.7500 (87.1986)  time: 0.3485  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2850/4579]  eta: 0:10:04  Lr: 0.001875  Loss: 0.1900  Acc@1: 50.0000 (49.7632)  Acc@5: 87.5000 (87.1953)  time: 0.3486  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [2860/4579]  eta: 0:10:00  Lr: 0.001875  Loss: -0.3426  Acc@1: 56.2500 (49.7990)  Acc@5: 87.5000 (87.1942)  time: 0.3484  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [2870/4579]  eta: 0:09:57  Lr: 0.001875  Loss: -0.2400  Acc@1: 56.2500 (49.8193)  Acc@5: 87.5000 (87.1931)  time: 0.3478  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2880/4579]  eta: 0:09:53  Lr: 0.001875  Loss: -0.2702  Acc@1: 56.2500 (49.8503)  Acc@5: 87.5000 (87.1919)  time: 0.3484  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2890/4579]  eta: 0:09:50  Lr: 0.001875  Loss: -0.7941  Acc@1: 56.2500 (49.8660)  Acc@5: 87.5000 (87.1930)  time: 0.3489  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2900/4579]  eta: 0:09:46  Lr: 0.001875  Loss: 0.0512  Acc@1: 56.2500 (49.8923)  Acc@5: 87.5000 (87.2005)  time: 0.3487  data: 0.0012  max mem: 2500
Train: Epoch[1/5]  [2910/4579]  eta: 0:09:43  Lr: 0.001875  Loss: -0.3602  Acc@1: 62.5000 (49.9442)  Acc@5: 93.7500 (87.2252)  time: 0.3479  data: 0.0012  max mem: 2500
Train: Epoch[1/5]  [2920/4579]  eta: 0:09:39  Lr: 0.001875  Loss: -0.0777  Acc@1: 62.5000 (49.9658)  Acc@5: 93.7500 (87.2368)  time: 0.3475  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2930/4579]  eta: 0:09:36  Lr: 0.001875  Loss: -0.2962  Acc@1: 56.2500 (49.9829)  Acc@5: 87.5000 (87.2462)  time: 0.3486  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2940/4579]  eta: 0:09:32  Lr: 0.001875  Loss: -0.5076  Acc@1: 56.2500 (50.0128)  Acc@5: 93.7500 (87.2577)  time: 0.3493  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [2950/4579]  eta: 0:09:29  Lr: 0.001875  Loss: -0.3611  Acc@1: 56.2500 (50.0466)  Acc@5: 93.7500 (87.2649)  time: 0.3495  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [2960/4579]  eta: 0:09:25  Lr: 0.001875  Loss: 0.1458  Acc@1: 50.0000 (50.0380)  Acc@5: 87.5000 (87.2720)  time: 0.3486  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2970/4579]  eta: 0:09:22  Lr: 0.001875  Loss: -0.4656  Acc@1: 50.0000 (50.0652)  Acc@5: 87.5000 (87.2665)  time: 0.3484  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2980/4579]  eta: 0:09:18  Lr: 0.001875  Loss: -0.4207  Acc@1: 62.5000 (50.1048)  Acc@5: 87.5000 (87.2757)  time: 0.3483  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2990/4579]  eta: 0:09:15  Lr: 0.001875  Loss: -0.3821  Acc@1: 56.2500 (50.1024)  Acc@5: 87.5000 (87.2848)  time: 0.3475  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [3000/4579]  eta: 0:09:11  Lr: 0.001875  Loss: -0.2269  Acc@1: 50.0000 (50.1416)  Acc@5: 93.7500 (87.3084)  time: 0.3482  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [3010/4579]  eta: 0:09:08  Lr: 0.001875  Loss: -0.1474  Acc@1: 56.2500 (50.1453)  Acc@5: 87.5000 (87.3132)  time: 0.3492  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [3020/4579]  eta: 0:09:04  Lr: 0.001875  Loss: -0.4167  Acc@1: 56.2500 (50.1759)  Acc@5: 87.5000 (87.3117)  time: 0.3493  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [3030/4579]  eta: 0:09:01  Lr: 0.001875  Loss: -0.2078  Acc@1: 56.2500 (50.1794)  Acc@5: 87.5000 (87.3124)  time: 0.3489  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [3040/4579]  eta: 0:08:57  Lr: 0.001875  Loss: -0.4028  Acc@1: 50.0000 (50.1994)  Acc@5: 87.5000 (87.3171)  time: 0.3487  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [3050/4579]  eta: 0:08:54  Lr: 0.001875  Loss: -0.0548  Acc@1: 56.2500 (50.2274)  Acc@5: 87.5000 (87.3218)  time: 0.3481  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [3060/4579]  eta: 0:08:50  Lr: 0.001875  Loss: -0.1680  Acc@1: 56.2500 (50.2430)  Acc@5: 87.5000 (87.3428)  time: 0.3473  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [3070/4579]  eta: 0:08:47  Lr: 0.001875  Loss: -0.1448  Acc@1: 56.2500 (50.2727)  Acc@5: 93.7500 (87.3555)  time: 0.3478  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3080/4579]  eta: 0:08:43  Lr: 0.001875  Loss: -0.3440  Acc@1: 56.2500 (50.3043)  Acc@5: 93.7500 (87.3722)  time: 0.3484  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [3090/4579]  eta: 0:08:40  Lr: 0.001875  Loss: -0.1674  Acc@1: 56.2500 (50.3377)  Acc@5: 93.7500 (87.3847)  time: 0.3495  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3100/4579]  eta: 0:08:36  Lr: 0.001875  Loss: 0.1529  Acc@1: 56.2500 (50.3487)  Acc@5: 93.7500 (87.3932)  time: 0.3500  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [3110/4579]  eta: 0:08:33  Lr: 0.001875  Loss: -0.5846  Acc@1: 56.2500 (50.3797)  Acc@5: 87.5000 (87.3995)  time: 0.3484  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [3120/4579]  eta: 0:08:29  Lr: 0.001875  Loss: -0.2211  Acc@1: 56.2500 (50.4045)  Acc@5: 93.7500 (87.4159)  time: 0.3476  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [3130/4579]  eta: 0:08:26  Lr: 0.001875  Loss: -0.1659  Acc@1: 56.2500 (50.4232)  Acc@5: 93.7500 (87.4241)  time: 0.3487  data: 0.0009  max mem: 2500
Train: Epoch[1/5]  [3140/4579]  eta: 0:08:22  Lr: 0.001875  Loss: -0.1987  Acc@1: 56.2500 (50.4437)  Acc@5: 93.7500 (87.4323)  time: 0.3492  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [3150/4579]  eta: 0:08:19  Lr: 0.001875  Loss: 0.0044  Acc@1: 56.2500 (50.4681)  Acc@5: 93.7500 (87.4445)  time: 0.3479  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3160/4579]  eta: 0:08:15  Lr: 0.001875  Loss: -0.3597  Acc@1: 56.2500 (50.4864)  Acc@5: 87.5000 (87.4466)  time: 0.3488  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3170/4579]  eta: 0:08:12  Lr: 0.001875  Loss: -0.1504  Acc@1: 56.2500 (50.5184)  Acc@5: 87.5000 (87.4566)  time: 0.3499  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [3180/4579]  eta: 0:08:08  Lr: 0.001875  Loss: -0.3185  Acc@1: 56.2500 (50.5442)  Acc@5: 87.5000 (87.4646)  time: 0.3490  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [3190/4579]  eta: 0:08:05  Lr: 0.001875  Loss: -0.6158  Acc@1: 56.2500 (50.5641)  Acc@5: 87.5000 (87.4647)  time: 0.3492  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [3200/4579]  eta: 0:08:01  Lr: 0.001875  Loss: -0.1545  Acc@1: 56.2500 (50.5897)  Acc@5: 87.5000 (87.4707)  time: 0.3484  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [3210/4579]  eta: 0:07:58  Lr: 0.001875  Loss: -0.3440  Acc@1: 62.5000 (50.6306)  Acc@5: 93.7500 (87.4961)  time: 0.3482  data: 0.0014  max mem: 2500
Train: Epoch[1/5]  [3220/4579]  eta: 0:07:54  Lr: 0.001875  Loss: -0.0405  Acc@1: 56.2500 (50.6384)  Acc@5: 93.7500 (87.5058)  time: 0.3495  data: 0.0014  max mem: 2500
Train: Epoch[1/5]  [3230/4579]  eta: 0:07:51  Lr: 0.001875  Loss: 0.1490  Acc@1: 56.2500 (50.6596)  Acc@5: 87.5000 (87.5039)  time: 0.3484  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [3240/4579]  eta: 0:07:47  Lr: 0.001875  Loss: 0.0610  Acc@1: 56.2500 (50.6981)  Acc@5: 93.7500 (87.5231)  time: 0.3478  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [3250/4579]  eta: 0:07:44  Lr: 0.001875  Loss: -0.1842  Acc@1: 62.5000 (50.7113)  Acc@5: 93.7500 (87.5308)  time: 0.3482  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [3260/4579]  eta: 0:07:40  Lr: 0.001875  Loss: -0.2388  Acc@1: 56.2500 (50.7245)  Acc@5: 93.7500 (87.5364)  time: 0.3481  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [3270/4579]  eta: 0:07:37  Lr: 0.001875  Loss: 0.1902  Acc@1: 50.0000 (50.7223)  Acc@5: 87.5000 (87.5325)  time: 0.3489  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [3280/4579]  eta: 0:07:33  Lr: 0.001875  Loss: 0.0571  Acc@1: 56.2500 (50.7562)  Acc@5: 87.5000 (87.5438)  time: 0.3502  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [3290/4579]  eta: 0:07:30  Lr: 0.001875  Loss: 0.0152  Acc@1: 56.2500 (50.7558)  Acc@5: 87.5000 (87.5323)  time: 0.3497  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [3300/4579]  eta: 0:07:26  Lr: 0.001875  Loss: 0.1801  Acc@1: 56.2500 (50.7706)  Acc@5: 87.5000 (87.5303)  time: 0.3494  data: 0.0009  max mem: 2500
Train: Epoch[1/5]  [3310/4579]  eta: 0:07:23  Lr: 0.001875  Loss: -0.2568  Acc@1: 56.2500 (50.8098)  Acc@5: 87.5000 (87.5510)  time: 0.3493  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [3320/4579]  eta: 0:07:19  Lr: 0.001875  Loss: 0.0211  Acc@1: 62.5000 (50.8224)  Acc@5: 87.5000 (87.5565)  time: 0.3508  data: 0.0013  max mem: 2500
Train: Epoch[1/5]  [3330/4579]  eta: 0:07:16  Lr: 0.001875  Loss: 0.0557  Acc@1: 56.2500 (50.8350)  Acc@5: 87.5000 (87.5544)  time: 0.3508  data: 0.0012  max mem: 2500
Train: Epoch[1/5]  [3340/4579]  eta: 0:07:12  Lr: 0.001875  Loss: -0.2976  Acc@1: 62.5000 (50.8755)  Acc@5: 87.5000 (87.5636)  time: 0.3489  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [3350/4579]  eta: 0:07:09  Lr: 0.001875  Loss: 0.0710  Acc@1: 56.2500 (50.8803)  Acc@5: 87.5000 (87.5671)  time: 0.3489  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [3360/4579]  eta: 0:07:05  Lr: 0.001875  Loss: -0.5373  Acc@1: 50.0000 (50.8833)  Acc@5: 87.5000 (87.5781)  time: 0.3478  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [3370/4579]  eta: 0:07:02  Lr: 0.001875  Loss: -0.6001  Acc@1: 56.2500 (50.8992)  Acc@5: 87.5000 (87.5779)  time: 0.3485  data: 0.0012  max mem: 2500
Train: Epoch[1/5]  [3380/4579]  eta: 0:06:58  Lr: 0.001875  Loss: 0.0789  Acc@1: 56.2500 (50.9187)  Acc@5: 87.5000 (87.5869)  time: 0.3492  data: 0.0012  max mem: 2500
Train: Epoch[1/5]  [3390/4579]  eta: 0:06:55  Lr: 0.001875  Loss: 0.4582  Acc@1: 56.2500 (50.9345)  Acc@5: 87.5000 (87.5793)  time: 0.3484  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3400/4579]  eta: 0:06:51  Lr: 0.001875  Loss: -0.2410  Acc@1: 56.2500 (50.9721)  Acc@5: 87.5000 (87.5937)  time: 0.3494  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [3410/4579]  eta: 0:06:48  Lr: 0.001875  Loss: -0.4962  Acc@1: 56.2500 (50.9858)  Acc@5: 93.7500 (87.6008)  time: 0.3493  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [3420/4579]  eta: 0:06:44  Lr: 0.001875  Loss: -0.3302  Acc@1: 56.2500 (51.0249)  Acc@5: 93.7500 (87.6169)  time: 0.3493  data: 0.0019  max mem: 2500
Train: Epoch[1/5]  [3430/4579]  eta: 0:06:41  Lr: 0.001875  Loss: -0.4016  Acc@1: 62.5000 (51.0456)  Acc@5: 93.7500 (87.6257)  time: 0.3509  data: 0.0019  max mem: 2500
Train: Epoch[1/5]  [3440/4579]  eta: 0:06:38  Lr: 0.001875  Loss: 0.0972  Acc@1: 56.2500 (51.0517)  Acc@5: 87.5000 (87.6253)  time: 0.3498  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [3450/4579]  eta: 0:06:34  Lr: 0.001875  Loss: -0.1072  Acc@1: 56.2500 (51.0758)  Acc@5: 87.5000 (87.6358)  time: 0.3489  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [3460/4579]  eta: 0:06:31  Lr: 0.001875  Loss: 0.6774  Acc@1: 62.5000 (51.0889)  Acc@5: 93.7500 (87.6463)  time: 0.3507  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [3470/4579]  eta: 0:06:27  Lr: 0.001875  Loss: -0.1062  Acc@1: 56.2500 (51.1056)  Acc@5: 87.5000 (87.6531)  time: 0.3493  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3480/4579]  eta: 0:06:24  Lr: 0.001875  Loss: -0.1328  Acc@1: 50.0000 (51.1150)  Acc@5: 87.5000 (87.6634)  time: 0.3476  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [3490/4579]  eta: 0:06:20  Lr: 0.001875  Loss: -0.2608  Acc@1: 62.5000 (51.1762)  Acc@5: 87.5000 (87.6665)  time: 0.3489  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [3500/4579]  eta: 0:06:17  Lr: 0.001875  Loss: -0.1330  Acc@1: 68.7500 (51.2050)  Acc@5: 87.5000 (87.6660)  time: 0.3486  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3510/4579]  eta: 0:06:13  Lr: 0.001875  Loss: 0.0478  Acc@1: 62.5000 (51.2354)  Acc@5: 93.7500 (87.6691)  time: 0.3480  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3520/4579]  eta: 0:06:10  Lr: 0.001875  Loss: 0.1191  Acc@1: 56.2500 (51.2621)  Acc@5: 87.5000 (87.6686)  time: 0.3478  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3530/4579]  eta: 0:06:06  Lr: 0.001875  Loss: -0.3269  Acc@1: 62.5000 (51.3027)  Acc@5: 93.7500 (87.6788)  time: 0.3488  data: 0.0014  max mem: 2500
Train: Epoch[1/5]  [3540/4579]  eta: 0:06:03  Lr: 0.001875  Loss: -0.1536  Acc@1: 62.5000 (51.3167)  Acc@5: 93.7500 (87.6906)  time: 0.3488  data: 0.0014  max mem: 2500
Train: Epoch[1/5]  [3550/4579]  eta: 0:05:59  Lr: 0.001875  Loss: -0.0492  Acc@1: 56.2500 (51.3341)  Acc@5: 87.5000 (87.6954)  time: 0.3495  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [3560/4579]  eta: 0:05:56  Lr: 0.001875  Loss: -0.5291  Acc@1: 56.2500 (51.3567)  Acc@5: 93.7500 (87.7036)  time: 0.3501  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [3570/4579]  eta: 0:05:52  Lr: 0.001875  Loss: 0.1194  Acc@1: 62.5000 (51.3862)  Acc@5: 93.7500 (87.7118)  time: 0.3495  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [3580/4579]  eta: 0:05:49  Lr: 0.001875  Loss: -0.5136  Acc@1: 62.5000 (51.4172)  Acc@5: 93.7500 (87.7304)  time: 0.3508  data: 0.0017  max mem: 2500
Train: Epoch[1/5]  [3590/4579]  eta: 0:05:45  Lr: 0.001875  Loss: -0.6214  Acc@1: 56.2500 (51.4463)  Acc@5: 93.7500 (87.7489)  time: 0.3499  data: 0.0016  max mem: 2500
Train: Epoch[1/5]  [3600/4579]  eta: 0:05:42  Lr: 0.001875  Loss: 0.0783  Acc@1: 62.5000 (51.4718)  Acc@5: 93.7500 (87.7603)  time: 0.3484  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [3610/4579]  eta: 0:05:38  Lr: 0.001875  Loss: 0.0447  Acc@1: 62.5000 (51.5127)  Acc@5: 93.7500 (87.7665)  time: 0.3484  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [3620/4579]  eta: 0:05:35  Lr: 0.001875  Loss: -0.2092  Acc@1: 62.5000 (51.5310)  Acc@5: 93.7500 (87.7813)  time: 0.3481  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3630/4579]  eta: 0:05:31  Lr: 0.001875  Loss: -0.8139  Acc@1: 56.2500 (51.5526)  Acc@5: 93.7500 (87.7771)  time: 0.3505  data: 0.0009  max mem: 2500
Train: Epoch[1/5]  [3640/4579]  eta: 0:05:28  Lr: 0.001875  Loss: 0.0299  Acc@1: 56.2500 (51.5672)  Acc@5: 87.5000 (87.7884)  time: 0.3503  data: 0.0009  max mem: 2500
Train: Epoch[1/5]  [3650/4579]  eta: 0:05:24  Lr: 0.001875  Loss: -0.2481  Acc@1: 56.2500 (51.5800)  Acc@5: 87.5000 (87.7962)  time: 0.3489  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [3660/4579]  eta: 0:05:21  Lr: 0.001875  Loss: -0.3775  Acc@1: 56.2500 (51.5928)  Acc@5: 87.5000 (87.8039)  time: 0.3493  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [3670/4579]  eta: 0:05:17  Lr: 0.001875  Loss: -0.2654  Acc@1: 56.2500 (51.6174)  Acc@5: 87.5000 (87.8065)  time: 0.3488  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [3680/4579]  eta: 0:05:14  Lr: 0.001875  Loss: 0.0079  Acc@1: 56.2500 (51.6215)  Acc@5: 87.5000 (87.8005)  time: 0.3485  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [3690/4579]  eta: 0:05:10  Lr: 0.001875  Loss: -0.5152  Acc@1: 56.2500 (51.6323)  Acc@5: 87.5000 (87.8048)  time: 0.3486  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3700/4579]  eta: 0:05:07  Lr: 0.001875  Loss: -0.3288  Acc@1: 56.2500 (51.6431)  Acc@5: 87.5000 (87.8040)  time: 0.3494  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [3710/4579]  eta: 0:05:03  Lr: 0.001875  Loss: 0.2611  Acc@1: 50.0000 (51.6623)  Acc@5: 87.5000 (87.8099)  time: 0.3493  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [3720/4579]  eta: 0:05:00  Lr: 0.001875  Loss: 0.0475  Acc@1: 62.5000 (51.6813)  Acc@5: 93.7500 (87.8191)  time: 0.3495  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [3730/4579]  eta: 0:04:56  Lr: 0.001875  Loss: -0.3237  Acc@1: 62.5000 (51.7103)  Acc@5: 93.7500 (87.8267)  time: 0.3498  data: 0.0009  max mem: 2500
Train: Epoch[1/5]  [3740/4579]  eta: 0:04:53  Lr: 0.001875  Loss: 0.1998  Acc@1: 62.5000 (51.7325)  Acc@5: 87.5000 (87.8308)  time: 0.3499  data: 0.0009  max mem: 2500
Train: Epoch[1/5]  [3750/4579]  eta: 0:04:49  Lr: 0.001875  Loss: -0.0530  Acc@1: 56.2500 (51.7429)  Acc@5: 87.5000 (87.8366)  time: 0.3490  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [3760/4579]  eta: 0:04:46  Lr: 0.001875  Loss: -0.3619  Acc@1: 50.0000 (51.7382)  Acc@5: 87.5000 (87.8357)  time: 0.3485  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [3770/4579]  eta: 0:04:42  Lr: 0.001875  Loss: 0.0990  Acc@1: 50.0000 (51.7585)  Acc@5: 87.5000 (87.8414)  time: 0.3485  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [3780/4579]  eta: 0:04:39  Lr: 0.001875  Loss: -0.0896  Acc@1: 62.5000 (51.7885)  Acc@5: 87.5000 (87.8488)  time: 0.3486  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3790/4579]  eta: 0:04:35  Lr: 0.001875  Loss: -0.3218  Acc@1: 56.2500 (51.8036)  Acc@5: 93.7500 (87.8627)  time: 0.3496  data: 0.0013  max mem: 2500
Train: Epoch[1/5]  [3800/4579]  eta: 0:04:32  Lr: 0.001875  Loss: -0.0604  Acc@1: 56.2500 (51.8252)  Acc@5: 93.7500 (87.8650)  time: 0.3506  data: 0.0020  max mem: 2500
Train: Epoch[1/5]  [3810/4579]  eta: 0:04:28  Lr: 0.001875  Loss: -0.3970  Acc@1: 56.2500 (51.8417)  Acc@5: 87.5000 (87.8641)  time: 0.3499  data: 0.0011  max mem: 2500
Train: Epoch[1/5]  [3820/4579]  eta: 0:04:25  Lr: 0.001875  Loss: -0.4874  Acc@1: 56.2500 (51.8516)  Acc@5: 87.5000 (87.8599)  time: 0.3488  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [3830/4579]  eta: 0:04:21  Lr: 0.001875  Loss: -0.4154  Acc@1: 62.5000 (51.8941)  Acc@5: 93.7500 (87.8752)  time: 0.3488  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [3840/4579]  eta: 0:04:18  Lr: 0.001875  Loss: 0.1326  Acc@1: 62.5000 (51.9071)  Acc@5: 93.7500 (87.8759)  time: 0.3493  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [3850/4579]  eta: 0:04:14  Lr: 0.001875  Loss: -0.0341  Acc@1: 56.2500 (51.9086)  Acc@5: 87.5000 (87.8717)  time: 0.3486  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [3860/4579]  eta: 0:04:11  Lr: 0.001875  Loss: -0.1848  Acc@1: 56.2500 (51.9328)  Acc@5: 87.5000 (87.8853)  time: 0.3484  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3870/4579]  eta: 0:04:07  Lr: 0.001875  Loss: 0.0512  Acc@1: 56.2500 (51.9504)  Acc@5: 93.7500 (87.8810)  time: 0.3488  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [3880/4579]  eta: 0:04:04  Lr: 0.001875  Loss: -0.5651  Acc@1: 62.5000 (51.9792)  Acc@5: 87.5000 (87.8865)  time: 0.3500  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [3890/4579]  eta: 0:04:00  Lr: 0.001875  Loss: -0.3555  Acc@1: 62.5000 (51.9870)  Acc@5: 87.5000 (87.8871)  time: 0.3498  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [3900/4579]  eta: 0:03:57  Lr: 0.001875  Loss: -0.1497  Acc@1: 62.5000 (52.0139)  Acc@5: 93.7500 (87.8957)  time: 0.3488  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [3910/4579]  eta: 0:03:53  Lr: 0.001875  Loss: -0.3182  Acc@1: 62.5000 (52.0551)  Acc@5: 93.7500 (87.9059)  time: 0.3499  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [3920/4579]  eta: 0:03:50  Lr: 0.001875  Loss: -0.6685  Acc@1: 62.5000 (52.0738)  Acc@5: 93.7500 (87.9144)  time: 0.3498  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3930/4579]  eta: 0:03:46  Lr: 0.001875  Loss: -0.2276  Acc@1: 56.2500 (52.0860)  Acc@5: 93.7500 (87.9277)  time: 0.3502  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3940/4579]  eta: 0:03:43  Lr: 0.001875  Loss: -0.1586  Acc@1: 56.2500 (52.1013)  Acc@5: 93.7500 (87.9266)  time: 0.3492  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3950/4579]  eta: 0:03:39  Lr: 0.001875  Loss: -0.3228  Acc@1: 56.2500 (52.1181)  Acc@5: 87.5000 (87.9334)  time: 0.3490  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3960/4579]  eta: 0:03:36  Lr: 0.001875  Loss: 0.3281  Acc@1: 56.2500 (52.1159)  Acc@5: 87.5000 (87.9197)  time: 0.3492  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3970/4579]  eta: 0:03:32  Lr: 0.001875  Loss: -0.2398  Acc@1: 56.2500 (52.1279)  Acc@5: 87.5000 (87.9297)  time: 0.3486  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [3980/4579]  eta: 0:03:29  Lr: 0.001875  Loss: -0.6270  Acc@1: 56.2500 (52.1367)  Acc@5: 93.7500 (87.9349)  time: 0.3504  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [3990/4579]  eta: 0:03:25  Lr: 0.001875  Loss: -0.4555  Acc@1: 56.2500 (52.1580)  Acc@5: 93.7500 (87.9479)  time: 0.3501  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [4000/4579]  eta: 0:03:22  Lr: 0.001875  Loss: -0.2402  Acc@1: 62.5000 (52.1838)  Acc@5: 93.7500 (87.9608)  time: 0.3483  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [4010/4579]  eta: 0:03:18  Lr: 0.001875  Loss: -0.3538  Acc@1: 62.5000 (52.2002)  Acc@5: 87.5000 (87.9612)  time: 0.3485  data: 0.0013  max mem: 2500
Train: Epoch[1/5]  [4020/4579]  eta: 0:03:15  Lr: 0.001875  Loss: -0.2369  Acc@1: 62.5000 (52.2165)  Acc@5: 87.5000 (87.9601)  time: 0.3499  data: 0.0013  max mem: 2500
Train: Epoch[1/5]  [4030/4579]  eta: 0:03:11  Lr: 0.001875  Loss: 0.0702  Acc@1: 56.2500 (52.2249)  Acc@5: 93.7500 (87.9682)  time: 0.3495  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [4040/4579]  eta: 0:03:08  Lr: 0.001875  Loss: 0.6373  Acc@1: 56.2500 (52.2194)  Acc@5: 87.5000 (87.9624)  time: 0.3496  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [4050/4579]  eta: 0:03:04  Lr: 0.001875  Loss: 0.0813  Acc@1: 50.0000 (52.2263)  Acc@5: 87.5000 (87.9690)  time: 0.3497  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [4060/4579]  eta: 0:03:01  Lr: 0.001875  Loss: -0.0371  Acc@1: 56.2500 (52.2408)  Acc@5: 87.5000 (87.9740)  time: 0.3481  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [4070/4579]  eta: 0:02:57  Lr: 0.001875  Loss: -0.1615  Acc@1: 62.5000 (52.2614)  Acc@5: 93.7500 (87.9882)  time: 0.3502  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [4080/4579]  eta: 0:02:54  Lr: 0.001875  Loss: -0.1667  Acc@1: 56.2500 (52.2743)  Acc@5: 87.5000 (87.9794)  time: 0.3509  data: 0.0014  max mem: 2500
Train: Epoch[1/5]  [4090/4579]  eta: 0:02:50  Lr: 0.001875  Loss: 0.3284  Acc@1: 56.2500 (52.2855)  Acc@5: 87.5000 (87.9874)  time: 0.3491  data: 0.0012  max mem: 2500
Train: Epoch[1/5]  [4100/4579]  eta: 0:02:47  Lr: 0.001875  Loss: -0.1558  Acc@1: 56.2500 (52.2967)  Acc@5: 93.7500 (87.9892)  time: 0.3485  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [4110/4579]  eta: 0:02:43  Lr: 0.001875  Loss: 0.2459  Acc@1: 56.2500 (52.3185)  Acc@5: 87.5000 (87.9835)  time: 0.3483  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [4120/4579]  eta: 0:02:40  Lr: 0.001875  Loss: -0.0867  Acc@1: 56.2500 (52.3341)  Acc@5: 87.5000 (87.9914)  time: 0.3482  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [4130/4579]  eta: 0:02:36  Lr: 0.001875  Loss: -0.0195  Acc@1: 56.2500 (52.3420)  Acc@5: 93.7500 (87.9962)  time: 0.3486  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [4140/4579]  eta: 0:02:33  Lr: 0.001875  Loss: 0.0489  Acc@1: 56.2500 (52.3605)  Acc@5: 93.7500 (87.9950)  time: 0.3498  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [4150/4579]  eta: 0:02:29  Lr: 0.001875  Loss: -0.2488  Acc@1: 56.2500 (52.3880)  Acc@5: 87.5000 (87.9984)  time: 0.3498  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [4160/4579]  eta: 0:02:26  Lr: 0.001875  Loss: -0.0646  Acc@1: 62.5000 (52.4108)  Acc@5: 87.5000 (87.9972)  time: 0.3497  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [4170/4579]  eta: 0:02:22  Lr: 0.001875  Loss: 0.0254  Acc@1: 62.5000 (52.4275)  Acc@5: 87.5000 (88.0035)  time: 0.3495  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [4180/4579]  eta: 0:02:19  Lr: 0.001875  Loss: -0.2106  Acc@1: 62.5000 (52.4590)  Acc@5: 87.5000 (88.0112)  time: 0.3490  data: 0.0012  max mem: 2500
Train: Epoch[1/5]  [4190/4579]  eta: 0:02:15  Lr: 0.001875  Loss: -0.2069  Acc@1: 56.2500 (52.4621)  Acc@5: 87.5000 (88.0145)  time: 0.3483  data: 0.0009  max mem: 2500
Train: Epoch[1/5]  [4200/4579]  eta: 0:02:12  Lr: 0.001875  Loss: -0.5838  Acc@1: 50.0000 (52.4592)  Acc@5: 87.5000 (88.0207)  time: 0.3490  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [4210/4579]  eta: 0:02:08  Lr: 0.001875  Loss: -0.4789  Acc@1: 56.2500 (52.4742)  Acc@5: 87.5000 (88.0150)  time: 0.3495  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [4220/4579]  eta: 0:02:05  Lr: 0.001875  Loss: -0.4195  Acc@1: 62.5000 (52.5009)  Acc@5: 87.5000 (88.0227)  time: 0.3483  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [4230/4579]  eta: 0:02:01  Lr: 0.001875  Loss: -0.8434  Acc@1: 56.2500 (52.5157)  Acc@5: 87.5000 (88.0244)  time: 0.3487  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [4240/4579]  eta: 0:01:58  Lr: 0.001875  Loss: 0.1045  Acc@1: 56.2500 (52.5466)  Acc@5: 87.5000 (88.0232)  time: 0.3490  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [4250/4579]  eta: 0:01:54  Lr: 0.001875  Loss: -0.3107  Acc@1: 62.5000 (52.5641)  Acc@5: 87.5000 (88.0249)  time: 0.3488  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [4260/4579]  eta: 0:01:51  Lr: 0.001875  Loss: -0.1863  Acc@1: 56.2500 (52.5742)  Acc@5: 87.5000 (88.0310)  time: 0.3490  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [4270/4579]  eta: 0:01:47  Lr: 0.001875  Loss: 0.0906  Acc@1: 56.2500 (52.5989)  Acc@5: 87.5000 (88.0283)  time: 0.3484  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [4280/4579]  eta: 0:01:44  Lr: 0.001875  Loss: -0.0634  Acc@1: 56.2500 (52.6089)  Acc@5: 87.5000 (88.0402)  time: 0.3489  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [4290/4579]  eta: 0:01:40  Lr: 0.001875  Loss: 0.1342  Acc@1: 56.2500 (52.6290)  Acc@5: 93.7500 (88.0447)  time: 0.3499  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [4300/4579]  eta: 0:01:37  Lr: 0.001875  Loss: -0.0790  Acc@1: 62.5000 (52.6476)  Acc@5: 87.5000 (88.0478)  time: 0.3489  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [4310/4579]  eta: 0:01:33  Lr: 0.001875  Loss: -0.4616  Acc@1: 62.5000 (52.6632)  Acc@5: 87.5000 (88.0495)  time: 0.3491  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [4320/4579]  eta: 0:01:30  Lr: 0.001875  Loss: 0.2707  Acc@1: 56.2500 (52.6715)  Acc@5: 87.5000 (88.0540)  time: 0.3490  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [4330/4579]  eta: 0:01:26  Lr: 0.001875  Loss: -0.4496  Acc@1: 62.5000 (52.6986)  Acc@5: 93.7500 (88.0642)  time: 0.3479  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [4340/4579]  eta: 0:01:23  Lr: 0.001875  Loss: 0.1531  Acc@1: 62.5000 (52.7024)  Acc@5: 87.5000 (88.0529)  time: 0.3481  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [4350/4579]  eta: 0:01:20  Lr: 0.001875  Loss: -0.7609  Acc@1: 62.5000 (52.7307)  Acc@5: 87.5000 (88.0660)  time: 0.3477  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [4360/4579]  eta: 0:01:16  Lr: 0.001875  Loss: -0.4318  Acc@1: 68.7500 (52.7603)  Acc@5: 93.7500 (88.0661)  time: 0.3470  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [4370/4579]  eta: 0:01:13  Lr: 0.001875  Loss: -0.0187  Acc@1: 68.7500 (52.7940)  Acc@5: 87.5000 (88.0777)  time: 0.3482  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [4380/4579]  eta: 0:01:09  Lr: 0.001875  Loss: -0.0416  Acc@1: 62.5000 (52.8090)  Acc@5: 87.5000 (88.0835)  time: 0.3500  data: 0.0012  max mem: 2500
Train: Epoch[1/5]  [4390/4579]  eta: 0:01:06  Lr: 0.001875  Loss: 0.1663  Acc@1: 62.5000 (52.8325)  Acc@5: 87.5000 (88.0935)  time: 0.3502  data: 0.0012  max mem: 2500
Train: Epoch[1/5]  [4400/4579]  eta: 0:01:02  Lr: 0.001875  Loss: -0.2603  Acc@1: 62.5000 (52.8644)  Acc@5: 93.7500 (88.1135)  time: 0.3502  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [4410/4579]  eta: 0:00:59  Lr: 0.001875  Loss: -0.2541  Acc@1: 68.7500 (52.8919)  Acc@5: 93.7500 (88.1206)  time: 0.3493  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [4420/4579]  eta: 0:00:55  Lr: 0.001875  Loss: -0.2799  Acc@1: 68.7500 (52.9137)  Acc@5: 87.5000 (88.1234)  time: 0.3480  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [4430/4579]  eta: 0:00:52  Lr: 0.001875  Loss: -0.1161  Acc@1: 62.5000 (52.9325)  Acc@5: 93.7500 (88.1347)  time: 0.3491  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [4440/4579]  eta: 0:00:48  Lr: 0.001875  Loss: -0.1885  Acc@1: 62.5000 (52.9582)  Acc@5: 93.7500 (88.1417)  time: 0.3503  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [4450/4579]  eta: 0:00:45  Lr: 0.001875  Loss: 0.0473  Acc@1: 62.5000 (52.9698)  Acc@5: 87.5000 (88.1347)  time: 0.3488  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [4460/4579]  eta: 0:00:41  Lr: 0.001875  Loss: 0.2735  Acc@1: 56.2500 (52.9688)  Acc@5: 87.5000 (88.1333)  time: 0.3478  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [4470/4579]  eta: 0:00:38  Lr: 0.001875  Loss: -0.3625  Acc@1: 56.2500 (52.9859)  Acc@5: 93.7500 (88.1458)  time: 0.3485  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [4480/4579]  eta: 0:00:34  Lr: 0.001875  Loss: -0.1325  Acc@1: 62.5000 (53.0057)  Acc@5: 87.5000 (88.1416)  time: 0.3488  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [4490/4579]  eta: 0:00:31  Lr: 0.001875  Loss: -0.4826  Acc@1: 62.5000 (53.0380)  Acc@5: 93.7500 (88.1597)  time: 0.3484  data: 0.0009  max mem: 2500
Train: Epoch[1/5]  [4500/4579]  eta: 0:00:27  Lr: 0.001875  Loss: -0.0010  Acc@1: 62.5000 (53.0521)  Acc@5: 93.7500 (88.1721)  time: 0.3486  data: 0.0010  max mem: 2500
Train: Epoch[1/5]  [4510/4579]  eta: 0:00:24  Lr: 0.001875  Loss: -0.5090  Acc@1: 62.5000 (53.0744)  Acc@5: 93.7500 (88.1761)  time: 0.3486  data: 0.0010  max mem: 2500
Train: Epoch[1/5]  [4520/4579]  eta: 0:00:20  Lr: 0.001875  Loss: 0.3773  Acc@1: 62.5000 (53.0884)  Acc@5: 93.7500 (88.1885)  time: 0.3483  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [4530/4579]  eta: 0:00:17  Lr: 0.001875  Loss: -0.0846  Acc@1: 56.2500 (53.0912)  Acc@5: 93.7500 (88.1869)  time: 0.3486  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [4540/4579]  eta: 0:00:13  Lr: 0.001875  Loss: -0.4054  Acc@1: 56.2500 (53.1105)  Acc@5: 93.7500 (88.1937)  time: 0.3484  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [4550/4579]  eta: 0:00:10  Lr: 0.001875  Loss: -0.6788  Acc@1: 56.2500 (53.1216)  Acc@5: 87.5000 (88.1949)  time: 0.3506  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [4560/4579]  eta: 0:00:06  Lr: 0.001875  Loss: -0.6164  Acc@1: 56.2500 (53.1380)  Acc@5: 87.5000 (88.2016)  time: 0.3508  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [4570/4579]  eta: 0:00:03  Lr: 0.001875  Loss: -0.1963  Acc@1: 62.5000 (53.1517)  Acc@5: 87.5000 (88.2001)  time: 0.3502  data: 0.0010  max mem: 2500
Train: Epoch[1/5]  [4578/4579]  eta: 0:00:00  Lr: 0.001875  Loss: -0.0253  Acc@1: 62.5000 (53.1608)  Acc@5: 87.5000 (88.2032)  time: 0.3469  data: 0.0009  max mem: 2500
Train: Epoch[1/5] Total time: 0:26:40 (0.3495 s / it)
Averaged stats: Lr: 0.001875  Loss: -0.0253  Acc@1: 62.5000 (53.1608)  Acc@5: 87.5000 (88.2032)
Train: Epoch[2/5]  [   0/4579]  eta: 0:55:37  Lr: 0.001875  Loss: -0.3559  Acc@1: 62.5000 (62.5000)  Acc@5: 100.0000 (100.0000)  time: 0.7288  data: 0.3800  max mem: 2500
Train: Epoch[2/5]  [  10/4579]  eta: 0:29:15  Lr: 0.001875  Loss: -0.4191  Acc@1: 56.2500 (59.0909)  Acc@5: 87.5000 (88.6364)  time: 0.3842  data: 0.0349  max mem: 2500
Train: Epoch[2/5]  [  20/4579]  eta: 0:27:54  Lr: 0.001875  Loss: -0.9007  Acc@1: 62.5000 (61.0119)  Acc@5: 87.5000 (88.6905)  time: 0.3493  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [  30/4579]  eta: 0:27:22  Lr: 0.001875  Loss: 0.0211  Acc@1: 62.5000 (60.6855)  Acc@5: 87.5000 (89.7177)  time: 0.3483  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [  40/4579]  eta: 0:27:06  Lr: 0.001875  Loss: -0.5071  Acc@1: 56.2500 (60.9756)  Acc@5: 93.7500 (90.5488)  time: 0.3489  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [  50/4579]  eta: 0:26:54  Lr: 0.001875  Loss: -0.0940  Acc@1: 62.5000 (60.5392)  Acc@5: 93.7500 (90.0735)  time: 0.3497  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [  60/4579]  eta: 0:26:45  Lr: 0.001875  Loss: -0.2117  Acc@1: 56.2500 (60.4508)  Acc@5: 87.5000 (89.7541)  time: 0.3488  data: 0.0011  max mem: 2500
Train: Epoch[2/5]  [  70/4579]  eta: 0:26:37  Lr: 0.001875  Loss: -0.4943  Acc@1: 56.2500 (60.1232)  Acc@5: 87.5000 (89.9648)  time: 0.3482  data: 0.0013  max mem: 2500
Train: Epoch[2/5]  [  80/4579]  eta: 0:26:31  Lr: 0.001875  Loss: -0.1367  Acc@1: 56.2500 (60.1852)  Acc@5: 87.5000 (90.2006)  time: 0.3495  data: 0.0011  max mem: 2500
Train: Epoch[2/5]  [  90/4579]  eta: 0:26:25  Lr: 0.001875  Loss: -0.1570  Acc@1: 56.2500 (60.0962)  Acc@5: 93.7500 (90.3159)  time: 0.3499  data: 0.0009  max mem: 2500
Train: Epoch[2/5]  [ 100/4579]  eta: 0:26:20  Lr: 0.001875  Loss: -0.0007  Acc@1: 56.2500 (60.0248)  Acc@5: 93.7500 (90.4703)  time: 0.3488  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [ 110/4579]  eta: 0:26:16  Lr: 0.001875  Loss: -0.8737  Acc@1: 62.5000 (60.2477)  Acc@5: 93.7500 (90.5968)  time: 0.3503  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [ 120/4579]  eta: 0:26:10  Lr: 0.001875  Loss: -0.0317  Acc@1: 62.5000 (60.5888)  Acc@5: 93.7500 (90.8058)  time: 0.3497  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [ 130/4579]  eta: 0:26:06  Lr: 0.001875  Loss: -0.7155  Acc@1: 62.5000 (60.4008)  Acc@5: 93.7500 (90.7443)  time: 0.3488  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 140/4579]  eta: 0:26:02  Lr: 0.001875  Loss: -0.8946  Acc@1: 62.5000 (60.4610)  Acc@5: 93.7500 (90.7358)  time: 0.3501  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [ 150/4579]  eta: 0:25:57  Lr: 0.001875  Loss: -0.3790  Acc@1: 62.5000 (60.3891)  Acc@5: 93.7500 (90.9768)  time: 0.3493  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [ 160/4579]  eta: 0:25:53  Lr: 0.001875  Loss: -0.5605  Acc@1: 62.5000 (60.4814)  Acc@5: 93.7500 (91.0714)  time: 0.3480  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 170/4579]  eta: 0:25:49  Lr: 0.001875  Loss: -1.0648  Acc@1: 62.5000 (60.1974)  Acc@5: 93.7500 (90.9722)  time: 0.3487  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [ 180/4579]  eta: 0:25:45  Lr: 0.001875  Loss: -0.1878  Acc@1: 56.2500 (60.2901)  Acc@5: 93.7500 (90.8840)  time: 0.3494  data: 0.0012  max mem: 2500
Train: Epoch[2/5]  [ 190/4579]  eta: 0:25:40  Lr: 0.001875  Loss: 0.0151  Acc@1: 56.2500 (60.1440)  Acc@5: 93.7500 (90.8377)  time: 0.3485  data: 0.0010  max mem: 2500
Train: Epoch[2/5]  [ 200/4579]  eta: 0:25:37  Lr: 0.001875  Loss: 0.0788  Acc@1: 56.2500 (60.1990)  Acc@5: 87.5000 (90.7338)  time: 0.3484  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [ 210/4579]  eta: 0:25:33  Lr: 0.001875  Loss: 0.0128  Acc@1: 56.2500 (59.8637)  Acc@5: 87.5000 (90.7879)  time: 0.3499  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [ 220/4579]  eta: 0:25:29  Lr: 0.001875  Loss: -0.1338  Acc@1: 56.2500 (59.7851)  Acc@5: 93.7500 (90.6109)  time: 0.3489  data: 0.0009  max mem: 2500
Train: Epoch[2/5]  [ 230/4579]  eta: 0:25:25  Lr: 0.001875  Loss: -0.0918  Acc@1: 56.2500 (59.7944)  Acc@5: 87.5000 (90.6385)  time: 0.3477  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [ 240/4579]  eta: 0:25:21  Lr: 0.001875  Loss: 0.0301  Acc@1: 56.2500 (59.6732)  Acc@5: 93.7500 (90.6380)  time: 0.3479  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [ 250/4579]  eta: 0:25:17  Lr: 0.001875  Loss: -0.2151  Acc@1: 56.2500 (59.5867)  Acc@5: 87.5000 (90.5627)  time: 0.3491  data: 0.0012  max mem: 2500
Train: Epoch[2/5]  [ 260/4579]  eta: 0:25:14  Lr: 0.001875  Loss: 0.1931  Acc@1: 62.5000 (59.6983)  Acc@5: 87.5000 (90.4215)  time: 0.3512  data: 0.0014  max mem: 2500
Train: Epoch[2/5]  [ 270/4579]  eta: 0:25:10  Lr: 0.001875  Loss: -0.5826  Acc@1: 68.7500 (59.7325)  Acc@5: 93.7500 (90.5904)  time: 0.3496  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [ 280/4579]  eta: 0:25:06  Lr: 0.001875  Loss: -0.4357  Acc@1: 62.5000 (59.7420)  Acc@5: 93.7500 (90.4582)  time: 0.3481  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [ 290/4579]  eta: 0:25:03  Lr: 0.001875  Loss: -0.2263  Acc@1: 62.5000 (59.7723)  Acc@5: 87.5000 (90.2921)  time: 0.3495  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 300/4579]  eta: 0:24:59  Lr: 0.001875  Loss: -0.4356  Acc@1: 62.5000 (59.8422)  Acc@5: 87.5000 (90.2409)  time: 0.3494  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 310/4579]  eta: 0:24:55  Lr: 0.001875  Loss: -0.2542  Acc@1: 62.5000 (59.9076)  Acc@5: 87.5000 (90.1929)  time: 0.3483  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 320/4579]  eta: 0:24:51  Lr: 0.001875  Loss: 0.0130  Acc@1: 62.5000 (59.8910)  Acc@5: 93.7500 (90.2259)  time: 0.3486  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 330/4579]  eta: 0:24:47  Lr: 0.001875  Loss: -0.3193  Acc@1: 62.5000 (60.0642)  Acc@5: 93.7500 (90.2757)  time: 0.3485  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [ 340/4579]  eta: 0:24:44  Lr: 0.001875  Loss: -0.0926  Acc@1: 62.5000 (60.1540)  Acc@5: 93.7500 (90.3043)  time: 0.3483  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [ 350/4579]  eta: 0:24:41  Lr: 0.001875  Loss: -0.2951  Acc@1: 62.5000 (60.3454)  Acc@5: 93.7500 (90.4024)  time: 0.3505  data: 0.0010  max mem: 2500
Train: Epoch[2/5]  [ 360/4579]  eta: 0:24:37  Lr: 0.001875  Loss: -0.1212  Acc@1: 62.5000 (60.4051)  Acc@5: 93.7500 (90.3393)  time: 0.3514  data: 0.0011  max mem: 2500
Train: Epoch[2/5]  [ 370/4579]  eta: 0:24:33  Lr: 0.001875  Loss: -0.3380  Acc@1: 62.5000 (60.4953)  Acc@5: 87.5000 (90.4144)  time: 0.3500  data: 0.0012  max mem: 2500
Train: Epoch[2/5]  [ 380/4579]  eta: 0:24:30  Lr: 0.001875  Loss: -0.1433  Acc@1: 56.2500 (60.4823)  Acc@5: 87.5000 (90.3379)  time: 0.3492  data: 0.0011  max mem: 2500
Train: Epoch[2/5]  [ 390/4579]  eta: 0:24:27  Lr: 0.001875  Loss: 0.0619  Acc@1: 62.5000 (60.5978)  Acc@5: 87.5000 (90.3453)  time: 0.3510  data: 0.0013  max mem: 2500
Train: Epoch[2/5]  [ 400/4579]  eta: 0:24:23  Lr: 0.001875  Loss: -0.5165  Acc@1: 62.5000 (60.6297)  Acc@5: 93.7500 (90.3990)  time: 0.3513  data: 0.0013  max mem: 2500
Train: Epoch[2/5]  [ 410/4579]  eta: 0:24:19  Lr: 0.001875  Loss: -0.1403  Acc@1: 62.5000 (60.6296)  Acc@5: 93.7500 (90.4349)  time: 0.3494  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [ 420/4579]  eta: 0:24:16  Lr: 0.001875  Loss: -0.1441  Acc@1: 62.5000 (60.6888)  Acc@5: 93.7500 (90.4246)  time: 0.3492  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [ 430/4579]  eta: 0:24:12  Lr: 0.001875  Loss: -0.0124  Acc@1: 56.2500 (60.4843)  Acc@5: 87.5000 (90.2552)  time: 0.3493  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [ 440/4579]  eta: 0:24:09  Lr: 0.001875  Loss: -0.6066  Acc@1: 56.2500 (60.5159)  Acc@5: 87.5000 (90.2636)  time: 0.3493  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [ 450/4579]  eta: 0:24:05  Lr: 0.001875  Loss: -0.1565  Acc@1: 56.2500 (60.5460)  Acc@5: 87.5000 (90.2439)  time: 0.3500  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 460/4579]  eta: 0:24:02  Lr: 0.001875  Loss: -0.1556  Acc@1: 62.5000 (60.6020)  Acc@5: 87.5000 (90.1979)  time: 0.3499  data: 0.0010  max mem: 2500
Train: Epoch[2/5]  [ 470/4579]  eta: 0:23:58  Lr: 0.001875  Loss: -0.6223  Acc@1: 62.5000 (60.5494)  Acc@5: 93.7500 (90.2070)  time: 0.3495  data: 0.0010  max mem: 2500
Train: Epoch[2/5]  [ 480/4579]  eta: 0:23:54  Lr: 0.001875  Loss: 0.1970  Acc@1: 56.2500 (60.4860)  Acc@5: 93.7500 (90.1767)  time: 0.3491  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [ 490/4579]  eta: 0:23:51  Lr: 0.001875  Loss: -0.4974  Acc@1: 62.5000 (60.5652)  Acc@5: 93.7500 (90.2113)  time: 0.3487  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 500/4579]  eta: 0:23:47  Lr: 0.001875  Loss: -0.5558  Acc@1: 62.5000 (60.5040)  Acc@5: 87.5000 (90.1821)  time: 0.3501  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [ 510/4579]  eta: 0:23:44  Lr: 0.001875  Loss: -0.3607  Acc@1: 62.5000 (60.5675)  Acc@5: 87.5000 (90.2153)  time: 0.3499  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [ 520/4579]  eta: 0:23:40  Lr: 0.001875  Loss: -0.4278  Acc@1: 62.5000 (60.6046)  Acc@5: 93.7500 (90.2111)  time: 0.3496  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [ 530/4579]  eta: 0:23:37  Lr: 0.001875  Loss: -0.7008  Acc@1: 62.5000 (60.7345)  Acc@5: 93.7500 (90.2778)  time: 0.3491  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [ 540/4579]  eta: 0:23:33  Lr: 0.001875  Loss: -0.3808  Acc@1: 56.2500 (60.6631)  Acc@5: 93.7500 (90.3073)  time: 0.3483  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [ 550/4579]  eta: 0:23:30  Lr: 0.001875  Loss: -0.5658  Acc@1: 56.2500 (60.7078)  Acc@5: 93.7500 (90.3584)  time: 0.3498  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [ 560/4579]  eta: 0:23:26  Lr: 0.001875  Loss: 0.1356  Acc@1: 56.2500 (60.6172)  Acc@5: 87.5000 (90.3075)  time: 0.3499  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 570/4579]  eta: 0:23:23  Lr: 0.001875  Loss: 0.2893  Acc@1: 56.2500 (60.6173)  Acc@5: 87.5000 (90.3130)  time: 0.3487  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [ 580/4579]  eta: 0:23:19  Lr: 0.001875  Loss: -0.6974  Acc@1: 68.7500 (60.7358)  Acc@5: 93.7500 (90.3614)  time: 0.3486  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [ 590/4579]  eta: 0:23:15  Lr: 0.001875  Loss: 0.0616  Acc@1: 68.7500 (60.7762)  Acc@5: 93.7500 (90.3553)  time: 0.3493  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [ 600/4579]  eta: 0:23:12  Lr: 0.001875  Loss: -0.4395  Acc@1: 62.5000 (60.8569)  Acc@5: 93.7500 (90.4014)  time: 0.3494  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [ 610/4579]  eta: 0:23:08  Lr: 0.001875  Loss: -0.0471  Acc@1: 62.5000 (60.8327)  Acc@5: 93.7500 (90.3642)  time: 0.3484  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 620/4579]  eta: 0:23:05  Lr: 0.001875  Loss: -0.4474  Acc@1: 56.2500 (60.7890)  Acc@5: 93.7500 (90.3684)  time: 0.3486  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 630/4579]  eta: 0:23:01  Lr: 0.001875  Loss: -0.1793  Acc@1: 62.5000 (60.8261)  Acc@5: 93.7500 (90.3922)  time: 0.3490  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 640/4579]  eta: 0:22:58  Lr: 0.001875  Loss: -0.5716  Acc@1: 68.7500 (60.9399)  Acc@5: 93.7500 (90.4544)  time: 0.3486  data: 0.0010  max mem: 2500
Train: Epoch[2/5]  [ 650/4579]  eta: 0:22:54  Lr: 0.001875  Loss: -0.3074  Acc@1: 56.2500 (60.8391)  Acc@5: 93.7500 (90.4378)  time: 0.3484  data: 0.0010  max mem: 2500
Train: Epoch[2/5]  [ 660/4579]  eta: 0:22:50  Lr: 0.001875  Loss: 0.3151  Acc@1: 50.0000 (60.7886)  Acc@5: 87.5000 (90.3650)  time: 0.3480  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 670/4579]  eta: 0:22:47  Lr: 0.001875  Loss: -0.6987  Acc@1: 56.2500 (60.7768)  Acc@5: 87.5000 (90.3782)  time: 0.3486  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 680/4579]  eta: 0:22:43  Lr: 0.001875  Loss: -0.3666  Acc@1: 62.5000 (60.7562)  Acc@5: 93.7500 (90.3267)  time: 0.3495  data: 0.0009  max mem: 2500
Train: Epoch[2/5]  [ 690/4579]  eta: 0:22:40  Lr: 0.001875  Loss: 0.0034  Acc@1: 56.2500 (60.6729)  Acc@5: 87.5000 (90.3130)  time: 0.3493  data: 0.0009  max mem: 2500
Train: Epoch[2/5]  [ 700/4579]  eta: 0:22:36  Lr: 0.001875  Loss: -0.3221  Acc@1: 62.5000 (60.7436)  Acc@5: 93.7500 (90.3976)  time: 0.3494  data: 0.0013  max mem: 2500
Train: Epoch[2/5]  [ 710/4579]  eta: 0:22:33  Lr: 0.001875  Loss: -0.3033  Acc@1: 62.5000 (60.7771)  Acc@5: 100.0000 (90.4360)  time: 0.3498  data: 0.0017  max mem: 2500
Train: Epoch[2/5]  [ 720/4579]  eta: 0:22:29  Lr: 0.001875  Loss: -0.6076  Acc@1: 62.5000 (60.7316)  Acc@5: 87.5000 (90.4040)  time: 0.3501  data: 0.0011  max mem: 2500
Train: Epoch[2/5]  [ 730/4579]  eta: 0:22:26  Lr: 0.001875  Loss: -0.1105  Acc@1: 56.2500 (60.6618)  Acc@5: 87.5000 (90.3642)  time: 0.3495  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [ 740/4579]  eta: 0:22:22  Lr: 0.001875  Loss: -0.2488  Acc@1: 62.5000 (60.7203)  Acc@5: 87.5000 (90.3762)  time: 0.3482  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [ 750/4579]  eta: 0:22:19  Lr: 0.001875  Loss: -0.3129  Acc@1: 56.2500 (60.6525)  Acc@5: 87.5000 (90.3545)  time: 0.3496  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [ 760/4579]  eta: 0:22:15  Lr: 0.001875  Loss: -0.5948  Acc@1: 56.2500 (60.6110)  Acc@5: 93.7500 (90.3827)  time: 0.3503  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [ 770/4579]  eta: 0:22:12  Lr: 0.001875  Loss: -0.3911  Acc@1: 56.2500 (60.6193)  Acc@5: 93.7500 (90.3615)  time: 0.3503  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [ 780/4579]  eta: 0:22:08  Lr: 0.001875  Loss: -0.1177  Acc@1: 62.5000 (60.6274)  Acc@5: 87.5000 (90.3569)  time: 0.3516  data: 0.0022  max mem: 2500
Train: Epoch[2/5]  [ 790/4579]  eta: 0:22:05  Lr: 0.001875  Loss: -0.7677  Acc@1: 68.7500 (60.7143)  Acc@5: 93.7500 (90.3919)  time: 0.3509  data: 0.0028  max mem: 2500
Train: Epoch[2/5]  [ 800/4579]  eta: 0:22:01  Lr: 0.001875  Loss: -0.4938  Acc@1: 68.7500 (60.7678)  Acc@5: 93.7500 (90.4104)  time: 0.3500  data: 0.0012  max mem: 2500
Train: Epoch[2/5]  [ 810/4579]  eta: 0:21:58  Lr: 0.001875  Loss: -0.7420  Acc@1: 62.5000 (60.8046)  Acc@5: 93.7500 (90.4285)  time: 0.3501  data: 0.0011  max mem: 2500
Train: Epoch[2/5]  [ 820/4579]  eta: 0:21:54  Lr: 0.001875  Loss: -0.5225  Acc@1: 68.7500 (60.8633)  Acc@5: 93.7500 (90.4233)  time: 0.3491  data: 0.0011  max mem: 2500
Train: Epoch[2/5]  [ 830/4579]  eta: 0:21:51  Lr: 0.001875  Loss: -0.7233  Acc@1: 62.5000 (60.8454)  Acc@5: 93.7500 (90.4182)  time: 0.3490  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [ 840/4579]  eta: 0:21:47  Lr: 0.001875  Loss: 0.1105  Acc@1: 56.2500 (60.7833)  Acc@5: 87.5000 (90.3909)  time: 0.3490  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 850/4579]  eta: 0:21:44  Lr: 0.001875  Loss: -0.0637  Acc@1: 56.2500 (60.6933)  Acc@5: 87.5000 (90.4230)  time: 0.3476  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [ 860/4579]  eta: 0:21:40  Lr: 0.001875  Loss: -0.6117  Acc@1: 56.2500 (60.6417)  Acc@5: 93.7500 (90.4326)  time: 0.3478  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [ 870/4579]  eta: 0:21:37  Lr: 0.001875  Loss: -0.4044  Acc@1: 62.5000 (60.6487)  Acc@5: 87.5000 (90.4348)  time: 0.3488  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [ 880/4579]  eta: 0:21:33  Lr: 0.001875  Loss: -0.7250  Acc@1: 62.5000 (60.6910)  Acc@5: 87.5000 (90.4299)  time: 0.3500  data: 0.0015  max mem: 2500
Train: Epoch[2/5]  [ 890/4579]  eta: 0:21:30  Lr: 0.001875  Loss: -0.5290  Acc@1: 62.5000 (60.7113)  Acc@5: 93.7500 (90.4531)  time: 0.3497  data: 0.0018  max mem: 2500
Train: Epoch[2/5]  [ 900/4579]  eta: 0:21:26  Lr: 0.001875  Loss: -0.6893  Acc@1: 68.7500 (60.7381)  Acc@5: 93.7500 (90.4550)  time: 0.3494  data: 0.0011  max mem: 2500
Train: Epoch[2/5]  [ 910/4579]  eta: 0:21:23  Lr: 0.001875  Loss: -0.7157  Acc@1: 62.5000 (60.7025)  Acc@5: 87.5000 (90.4363)  time: 0.3490  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [ 920/4579]  eta: 0:21:19  Lr: 0.001875  Loss: -0.1925  Acc@1: 62.5000 (60.7967)  Acc@5: 87.5000 (90.4452)  time: 0.3483  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [ 930/4579]  eta: 0:21:16  Lr: 0.001875  Loss: -0.1687  Acc@1: 68.7500 (60.8418)  Acc@5: 93.7500 (90.4605)  time: 0.3519  data: 0.0022  max mem: 2500
Train: Epoch[2/5]  [ 940/4579]  eta: 0:21:12  Lr: 0.001875  Loss: -0.4376  Acc@1: 62.5000 (60.7997)  Acc@5: 93.7500 (90.4756)  time: 0.3523  data: 0.0025  max mem: 2500
Train: Epoch[2/5]  [ 950/4579]  eta: 0:21:09  Lr: 0.001875  Loss: -0.5406  Acc@1: 56.2500 (60.7716)  Acc@5: 87.5000 (90.4771)  time: 0.3501  data: 0.0010  max mem: 2500
Train: Epoch[2/5]  [ 960/4579]  eta: 0:21:05  Lr: 0.001875  Loss: -0.1144  Acc@1: 62.5000 (60.7765)  Acc@5: 87.5000 (90.4787)  time: 0.3496  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [ 970/4579]  eta: 0:21:02  Lr: 0.001875  Loss: -0.4896  Acc@1: 62.5000 (60.8651)  Acc@5: 93.7500 (90.4995)  time: 0.3483  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 980/4579]  eta: 0:20:58  Lr: 0.001875  Loss: 0.2862  Acc@1: 62.5000 (60.8053)  Acc@5: 87.5000 (90.4817)  time: 0.3484  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 990/4579]  eta: 0:20:55  Lr: 0.001875  Loss: -0.2311  Acc@1: 56.2500 (60.7909)  Acc@5: 87.5000 (90.4705)  time: 0.3514  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1000/4579]  eta: 0:20:51  Lr: 0.001875  Loss: -0.2983  Acc@1: 56.2500 (60.8267)  Acc@5: 93.7500 (90.4658)  time: 0.3524  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1010/4579]  eta: 0:20:48  Lr: 0.001875  Loss: 0.0882  Acc@1: 56.2500 (60.7814)  Acc@5: 93.7500 (90.4364)  time: 0.3495  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1020/4579]  eta: 0:20:44  Lr: 0.001875  Loss: -0.5450  Acc@1: 56.2500 (60.8105)  Acc@5: 87.5000 (90.4138)  time: 0.3485  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1030/4579]  eta: 0:20:41  Lr: 0.001875  Loss: -0.0851  Acc@1: 62.5000 (60.8147)  Acc@5: 87.5000 (90.4037)  time: 0.3481  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1040/4579]  eta: 0:20:37  Lr: 0.001875  Loss: 0.0051  Acc@1: 62.5000 (60.7889)  Acc@5: 87.5000 (90.3999)  time: 0.3480  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1050/4579]  eta: 0:20:34  Lr: 0.001875  Loss: 0.2390  Acc@1: 62.5000 (60.8528)  Acc@5: 87.5000 (90.4079)  time: 0.3479  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1060/4579]  eta: 0:20:30  Lr: 0.001875  Loss: -0.5405  Acc@1: 62.5000 (60.7917)  Acc@5: 93.7500 (90.4041)  time: 0.3482  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1070/4579]  eta: 0:20:27  Lr: 0.001875  Loss: -0.6824  Acc@1: 50.0000 (60.7551)  Acc@5: 93.7500 (90.4062)  time: 0.3496  data: 0.0013  max mem: 2500
Train: Epoch[2/5]  [1080/4579]  eta: 0:20:23  Lr: 0.001875  Loss: 0.1388  Acc@1: 50.0000 (60.7250)  Acc@5: 93.7500 (90.4255)  time: 0.3501  data: 0.0016  max mem: 2500
Train: Epoch[2/5]  [1090/4579]  eta: 0:20:20  Lr: 0.001875  Loss: -0.0758  Acc@1: 62.5000 (60.7871)  Acc@5: 87.5000 (90.4445)  time: 0.3496  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [1100/4579]  eta: 0:20:16  Lr: 0.001875  Loss: -0.4186  Acc@1: 62.5000 (60.8594)  Acc@5: 93.7500 (90.4632)  time: 0.3493  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1110/4579]  eta: 0:20:13  Lr: 0.001875  Loss: -0.4702  Acc@1: 62.5000 (60.8967)  Acc@5: 93.7500 (90.4815)  time: 0.3490  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1120/4579]  eta: 0:20:09  Lr: 0.001875  Loss: -0.2092  Acc@1: 68.7500 (60.9222)  Acc@5: 93.7500 (90.4940)  time: 0.3501  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [1130/4579]  eta: 0:20:06  Lr: 0.001875  Loss: -0.1910  Acc@1: 62.5000 (60.9195)  Acc@5: 93.7500 (90.5117)  time: 0.3500  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [1140/4579]  eta: 0:20:02  Lr: 0.001875  Loss: -0.4526  Acc@1: 62.5000 (60.9279)  Acc@5: 93.7500 (90.5072)  time: 0.3482  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1150/4579]  eta: 0:19:59  Lr: 0.001875  Loss: -0.3834  Acc@1: 62.5000 (60.8981)  Acc@5: 87.5000 (90.4974)  time: 0.3486  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [1160/4579]  eta: 0:19:55  Lr: 0.001875  Loss: -0.6702  Acc@1: 62.5000 (60.9281)  Acc@5: 87.5000 (90.4985)  time: 0.3495  data: 0.0017  max mem: 2500
Train: Epoch[2/5]  [1170/4579]  eta: 0:19:51  Lr: 0.001875  Loss: -0.2585  Acc@1: 62.5000 (60.9949)  Acc@5: 93.7500 (90.5102)  time: 0.3491  data: 0.0016  max mem: 2500
Train: Epoch[2/5]  [1180/4579]  eta: 0:19:48  Lr: 0.001875  Loss: -0.5771  Acc@1: 62.5000 (60.9865)  Acc@5: 93.7500 (90.5324)  time: 0.3487  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1190/4579]  eta: 0:19:44  Lr: 0.001875  Loss: -0.7122  Acc@1: 62.5000 (61.0149)  Acc@5: 93.7500 (90.5332)  time: 0.3492  data: 0.0011  max mem: 2500
Train: Epoch[2/5]  [1200/4579]  eta: 0:19:41  Lr: 0.001875  Loss: -0.8393  Acc@1: 62.5000 (61.0065)  Acc@5: 93.7500 (90.5391)  time: 0.3492  data: 0.0010  max mem: 2500
Train: Epoch[2/5]  [1210/4579]  eta: 0:19:37  Lr: 0.001875  Loss: 0.3585  Acc@1: 62.5000 (61.0652)  Acc@5: 93.7500 (90.5553)  time: 0.3494  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1220/4579]  eta: 0:19:34  Lr: 0.001875  Loss: -0.3455  Acc@1: 62.5000 (61.0514)  Acc@5: 93.7500 (90.5303)  time: 0.3492  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1230/4579]  eta: 0:19:30  Lr: 0.001875  Loss: -0.1516  Acc@1: 56.2500 (61.0022)  Acc@5: 93.7500 (90.5615)  time: 0.3491  data: 0.0011  max mem: 2500
Train: Epoch[2/5]  [1240/4579]  eta: 0:19:27  Lr: 0.001875  Loss: -0.7562  Acc@1: 56.2500 (61.0193)  Acc@5: 93.7500 (90.5671)  time: 0.3504  data: 0.0019  max mem: 2500
Train: Epoch[2/5]  [1250/4579]  eta: 0:19:23  Lr: 0.001875  Loss: -0.4318  Acc@1: 62.5000 (61.0162)  Acc@5: 87.5000 (90.5326)  time: 0.3498  data: 0.0012  max mem: 2500
Train: Epoch[2/5]  [1260/4579]  eta: 0:19:20  Lr: 0.001875  Loss: -0.2870  Acc@1: 62.5000 (61.0081)  Acc@5: 87.5000 (90.5184)  time: 0.3486  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1270/4579]  eta: 0:19:16  Lr: 0.001875  Loss: 0.5237  Acc@1: 62.5000 (61.0100)  Acc@5: 87.5000 (90.5045)  time: 0.3480  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1280/4579]  eta: 0:19:13  Lr: 0.001875  Loss: -0.7418  Acc@1: 62.5000 (61.0461)  Acc@5: 87.5000 (90.5006)  time: 0.3483  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1290/4579]  eta: 0:19:09  Lr: 0.001875  Loss: -0.8249  Acc@1: 62.5000 (61.0622)  Acc@5: 93.7500 (90.5064)  time: 0.3486  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1300/4579]  eta: 0:19:06  Lr: 0.001875  Loss: 0.0064  Acc@1: 62.5000 (61.0876)  Acc@5: 93.7500 (90.5121)  time: 0.3487  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1310/4579]  eta: 0:19:02  Lr: 0.001875  Loss: -0.6359  Acc@1: 62.5000 (61.0936)  Acc@5: 87.5000 (90.5082)  time: 0.3510  data: 0.0009  max mem: 2500
Train: Epoch[2/5]  [1320/4579]  eta: 0:18:59  Lr: 0.001875  Loss: -0.4905  Acc@1: 56.2500 (61.0995)  Acc@5: 93.7500 (90.5138)  time: 0.3498  data: 0.0009  max mem: 2500
Train: Epoch[2/5]  [1330/4579]  eta: 0:18:55  Lr: 0.001875  Loss: -0.7971  Acc@1: 50.0000 (60.9927)  Acc@5: 87.5000 (90.5100)  time: 0.3478  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [1340/4579]  eta: 0:18:52  Lr: 0.001875  Loss: -0.4835  Acc@1: 56.2500 (60.9993)  Acc@5: 87.5000 (90.5062)  time: 0.3482  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [1350/4579]  eta: 0:18:48  Lr: 0.001875  Loss: -0.4721  Acc@1: 62.5000 (60.9919)  Acc@5: 93.7500 (90.4885)  time: 0.3507  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [1360/4579]  eta: 0:18:45  Lr: 0.001875  Loss: -0.7066  Acc@1: 56.2500 (60.9616)  Acc@5: 87.5000 (90.4712)  time: 0.3511  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [1370/4579]  eta: 0:18:41  Lr: 0.001875  Loss: -0.4445  Acc@1: 62.5000 (60.9774)  Acc@5: 87.5000 (90.4814)  time: 0.3491  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1380/4579]  eta: 0:18:38  Lr: 0.001875  Loss: -0.3470  Acc@1: 62.5000 (60.9432)  Acc@5: 87.5000 (90.4779)  time: 0.3491  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [1390/4579]  eta: 0:18:34  Lr: 0.001875  Loss: -0.2710  Acc@1: 62.5000 (60.9678)  Acc@5: 87.5000 (90.4565)  time: 0.3492  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [1400/4579]  eta: 0:18:31  Lr: 0.001875  Loss: -0.2800  Acc@1: 62.5000 (60.9921)  Acc@5: 87.5000 (90.4443)  time: 0.3489  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1410/4579]  eta: 0:18:27  Lr: 0.001875  Loss: -0.3387  Acc@1: 56.2500 (60.9142)  Acc@5: 93.7500 (90.4146)  time: 0.3486  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1420/4579]  eta: 0:18:24  Lr: 0.001875  Loss: 0.0167  Acc@1: 50.0000 (60.8858)  Acc@5: 93.7500 (90.4073)  time: 0.3489  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1430/4579]  eta: 0:18:20  Lr: 0.001875  Loss: -0.2060  Acc@1: 56.2500 (60.8534)  Acc@5: 87.5000 (90.3782)  time: 0.3488  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [1440/4579]  eta: 0:18:17  Lr: 0.001875  Loss: -0.4651  Acc@1: 62.5000 (60.8649)  Acc@5: 87.5000 (90.3930)  time: 0.3496  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [1450/4579]  eta: 0:18:13  Lr: 0.001875  Loss: -0.5561  Acc@1: 62.5000 (60.8718)  Acc@5: 93.7500 (90.3946)  time: 0.3502  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1460/4579]  eta: 0:18:10  Lr: 0.001875  Loss: -0.5726  Acc@1: 56.2500 (60.8787)  Acc@5: 93.7500 (90.4304)  time: 0.3495  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1470/4579]  eta: 0:18:06  Lr: 0.001875  Loss: -0.4852  Acc@1: 62.5000 (60.8855)  Acc@5: 87.5000 (90.4019)  time: 0.3488  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1480/4579]  eta: 0:18:03  Lr: 0.001875  Loss: -0.6652  Acc@1: 62.5000 (60.8921)  Acc@5: 87.5000 (90.4288)  time: 0.3482  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1490/4579]  eta: 0:17:59  Lr: 0.001875  Loss: -0.0473  Acc@1: 62.5000 (60.9448)  Acc@5: 93.7500 (90.4385)  time: 0.3478  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1500/4579]  eta: 0:17:56  Lr: 0.001875  Loss: -0.1779  Acc@1: 62.5000 (60.9260)  Acc@5: 93.7500 (90.4397)  time: 0.3482  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1510/4579]  eta: 0:17:52  Lr: 0.001875  Loss: -0.0301  Acc@1: 56.2500 (60.9158)  Acc@5: 87.5000 (90.4120)  time: 0.3490  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1520/4579]  eta: 0:17:49  Lr: 0.001875  Loss: -0.4425  Acc@1: 56.2500 (60.9221)  Acc@5: 93.7500 (90.4504)  time: 0.3492  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1530/4579]  eta: 0:17:45  Lr: 0.001875  Loss: -0.0265  Acc@1: 56.2500 (60.9038)  Acc@5: 93.7500 (90.4352)  time: 0.3508  data: 0.0012  max mem: 2500
Train: Epoch[2/5]  [1540/4579]  eta: 0:17:42  Lr: 0.001875  Loss: -0.0779  Acc@1: 56.2500 (60.8898)  Acc@5: 87.5000 (90.4161)  time: 0.3507  data: 0.0012  max mem: 2500
Train: Epoch[2/5]  [1550/4579]  eta: 0:17:38  Lr: 0.001875  Loss: -0.0788  Acc@1: 56.2500 (60.8881)  Acc@5: 87.5000 (90.4175)  time: 0.3485  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [1560/4579]  eta: 0:17:35  Lr: 0.001875  Loss: 0.0445  Acc@1: 62.5000 (60.8945)  Acc@5: 93.7500 (90.4308)  time: 0.3481  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [1570/4579]  eta: 0:17:31  Lr: 0.001875  Loss: -0.1076  Acc@1: 62.5000 (60.8848)  Acc@5: 93.7500 (90.4440)  time: 0.3471  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1580/4579]  eta: 0:17:28  Lr: 0.001875  Loss: 0.5291  Acc@1: 56.2500 (60.8357)  Acc@5: 93.7500 (90.4293)  time: 0.3470  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1590/4579]  eta: 0:17:24  Lr: 0.001875  Loss: -0.2695  Acc@1: 56.2500 (60.8580)  Acc@5: 93.7500 (90.4502)  time: 0.3485  data: 0.0012  max mem: 2500
Train: Epoch[2/5]  [1600/4579]  eta: 0:17:21  Lr: 0.001875  Loss: -0.4868  Acc@1: 62.5000 (60.8643)  Acc@5: 93.7500 (90.4396)  time: 0.3500  data: 0.0012  max mem: 2500
Train: Epoch[2/5]  [1610/4579]  eta: 0:17:17  Lr: 0.001875  Loss: 0.0510  Acc@1: 50.0000 (60.8124)  Acc@5: 93.7500 (90.4446)  time: 0.3493  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [1620/4579]  eta: 0:17:14  Lr: 0.001875  Loss: 0.0387  Acc@1: 50.0000 (60.7650)  Acc@5: 87.5000 (90.4187)  time: 0.3475  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [1630/4579]  eta: 0:17:10  Lr: 0.001875  Loss: -0.5301  Acc@1: 56.2500 (60.7833)  Acc@5: 87.5000 (90.4315)  time: 0.3477  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1640/4579]  eta: 0:17:07  Lr: 0.001875  Loss: -0.7009  Acc@1: 68.7500 (60.8280)  Acc@5: 93.7500 (90.4517)  time: 0.3510  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1650/4579]  eta: 0:17:03  Lr: 0.001875  Loss: -0.4060  Acc@1: 62.5000 (60.8041)  Acc@5: 87.5000 (90.4414)  time: 0.3530  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1660/4579]  eta: 0:17:00  Lr: 0.001875  Loss: -0.2989  Acc@1: 56.2500 (60.7804)  Acc@5: 87.5000 (90.4350)  time: 0.3511  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1670/4579]  eta: 0:16:56  Lr: 0.001875  Loss: -0.6921  Acc@1: 62.5000 (60.8019)  Acc@5: 87.5000 (90.4137)  time: 0.3501  data: 0.0015  max mem: 2500
Train: Epoch[2/5]  [1680/4579]  eta: 0:16:53  Lr: 0.001875  Loss: 0.0023  Acc@1: 62.5000 (60.8232)  Acc@5: 87.5000 (90.4112)  time: 0.3490  data: 0.0015  max mem: 2500
Train: Epoch[2/5]  [1690/4579]  eta: 0:16:49  Lr: 0.001875  Loss: -0.7255  Acc@1: 62.5000 (60.8737)  Acc@5: 87.5000 (90.4162)  time: 0.3490  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [1700/4579]  eta: 0:16:46  Lr: 0.001875  Loss: -0.5958  Acc@1: 62.5000 (60.8760)  Acc@5: 87.5000 (90.4174)  time: 0.3496  data: 0.0012  max mem: 2500
Train: Epoch[2/5]  [1710/4579]  eta: 0:16:42  Lr: 0.001875  Loss: -0.3122  Acc@1: 62.5000 (60.8781)  Acc@5: 87.5000 (90.4150)  time: 0.3513  data: 0.0023  max mem: 2500
Train: Epoch[2/5]  [1720/4579]  eta: 0:16:39  Lr: 0.001875  Loss: -0.5957  Acc@1: 62.5000 (60.9166)  Acc@5: 93.7500 (90.4234)  time: 0.3510  data: 0.0019  max mem: 2500
Train: Epoch[2/5]  [1730/4579]  eta: 0:16:35  Lr: 0.001875  Loss: -0.3102  Acc@1: 62.5000 (60.9366)  Acc@5: 93.7500 (90.4210)  time: 0.3492  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1740/4579]  eta: 0:16:32  Lr: 0.001875  Loss: -0.0080  Acc@1: 62.5000 (60.9240)  Acc@5: 87.5000 (90.4222)  time: 0.3491  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1750/4579]  eta: 0:16:28  Lr: 0.001875  Loss: -0.1035  Acc@1: 56.2500 (60.9295)  Acc@5: 87.5000 (90.4269)  time: 0.3495  data: 0.0009  max mem: 2500
Train: Epoch[2/5]  [1760/4579]  eta: 0:16:25  Lr: 0.001875  Loss: -0.5737  Acc@1: 56.2500 (60.8993)  Acc@5: 87.5000 (90.4103)  time: 0.3502  data: 0.0009  max mem: 2500
Train: Epoch[2/5]  [1770/4579]  eta: 0:16:21  Lr: 0.001875  Loss: -0.1978  Acc@1: 56.2500 (60.9084)  Acc@5: 93.7500 (90.4256)  time: 0.3487  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1780/4579]  eta: 0:16:18  Lr: 0.001875  Loss: -0.8171  Acc@1: 62.5000 (60.9243)  Acc@5: 93.7500 (90.4302)  time: 0.3483  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1790/4579]  eta: 0:16:14  Lr: 0.001875  Loss: -0.6243  Acc@1: 62.5000 (60.9471)  Acc@5: 93.7500 (90.4278)  time: 0.3481  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1800/4579]  eta: 0:16:11  Lr: 0.001875  Loss: -0.3155  Acc@1: 62.5000 (60.9522)  Acc@5: 93.7500 (90.4255)  time: 0.3480  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [1810/4579]  eta: 0:16:07  Lr: 0.001875  Loss: -0.3195  Acc@1: 62.5000 (60.9746)  Acc@5: 93.7500 (90.4300)  time: 0.3487  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [1820/4579]  eta: 0:16:04  Lr: 0.001875  Loss: -0.0683  Acc@1: 62.5000 (60.9864)  Acc@5: 93.7500 (90.4105)  time: 0.3485  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [1830/4579]  eta: 0:16:00  Lr: 0.001875  Loss: -0.2011  Acc@1: 68.7500 (60.9742)  Acc@5: 87.5000 (90.4151)  time: 0.3496  data: 0.0011  max mem: 2500
Train: Epoch[2/5]  [1840/4579]  eta: 0:15:57  Lr: 0.001875  Loss: -0.3427  Acc@1: 62.5000 (60.9655)  Acc@5: 87.5000 (90.4298)  time: 0.3508  data: 0.0018  max mem: 2500
Train: Epoch[2/5]  [1850/4579]  eta: 0:15:53  Lr: 0.001875  Loss: 0.1597  Acc@1: 62.5000 (60.9839)  Acc@5: 93.7500 (90.4342)  time: 0.3497  data: 0.0011  max mem: 2500
Train: Epoch[2/5]  [1860/4579]  eta: 0:15:50  Lr: 0.001875  Loss: -0.4083  Acc@1: 62.5000 (60.9786)  Acc@5: 93.7500 (90.4352)  time: 0.3485  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1870/4579]  eta: 0:15:46  Lr: 0.001875  Loss: -0.3817  Acc@1: 62.5000 (60.9935)  Acc@5: 93.7500 (90.4463)  time: 0.3491  data: 0.0011  max mem: 2500
Train: Epoch[2/5]  [1880/4579]  eta: 0:15:43  Lr: 0.001875  Loss: 0.1860  Acc@1: 62.5000 (60.9948)  Acc@5: 93.7500 (90.4506)  time: 0.3500  data: 0.0011  max mem: 2500
Train: Epoch[2/5]  [1890/4579]  eta: 0:15:39  Lr: 0.001875  Loss: -0.5390  Acc@1: 62.5000 (60.9929)  Acc@5: 93.7500 (90.4614)  time: 0.3492  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1900/4579]  eta: 0:15:36  Lr: 0.001875  Loss: 0.4202  Acc@1: 62.5000 (60.9909)  Acc@5: 93.7500 (90.4491)  time: 0.3483  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1910/4579]  eta: 0:15:32  Lr: 0.001875  Loss: -0.5649  Acc@1: 62.5000 (60.9988)  Acc@5: 93.7500 (90.4598)  time: 0.3492  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1920/4579]  eta: 0:15:29  Lr: 0.001875  Loss: -0.2290  Acc@1: 62.5000 (61.0197)  Acc@5: 93.7500 (90.4705)  time: 0.3490  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1930/4579]  eta: 0:15:25  Lr: 0.001875  Loss: -0.3317  Acc@1: 62.5000 (61.0273)  Acc@5: 93.7500 (90.4874)  time: 0.3488  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1940/4579]  eta: 0:15:22  Lr: 0.001875  Loss: -0.6349  Acc@1: 62.5000 (61.0510)  Acc@5: 93.7500 (90.5043)  time: 0.3491  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1950/4579]  eta: 0:15:18  Lr: 0.001875  Loss: -0.4787  Acc@1: 62.5000 (61.0360)  Acc@5: 93.7500 (90.5177)  time: 0.3484  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1960/4579]  eta: 0:15:15  Lr: 0.001875  Loss: -0.4010  Acc@1: 56.2500 (61.0403)  Acc@5: 93.7500 (90.5310)  time: 0.3485  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1970/4579]  eta: 0:15:11  Lr: 0.001875  Loss: -0.9491  Acc@1: 62.5000 (61.0413)  Acc@5: 93.7500 (90.5378)  time: 0.3493  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1980/4579]  eta: 0:15:08  Lr: 0.001875  Loss: -0.7261  Acc@1: 56.2500 (61.0487)  Acc@5: 100.0000 (90.5540)  time: 0.3490  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1990/4579]  eta: 0:15:04  Lr: 0.001875  Loss: -0.5808  Acc@1: 62.5000 (61.0717)  Acc@5: 100.0000 (90.5920)  time: 0.3489  data: 0.0011  max mem: 2500
Train: Epoch[2/5]  [2000/4579]  eta: 0:15:01  Lr: 0.001875  Loss: -0.3618  Acc@1: 62.5000 (61.0913)  Acc@5: 93.7500 (90.5922)  time: 0.3494  data: 0.0011  max mem: 2500
Train: Epoch[2/5]  [2010/4579]  eta: 0:14:57  Lr: 0.001875  Loss: -0.9482  Acc@1: 62.5000 (61.1045)  Acc@5: 93.7500 (90.6079)  time: 0.3498  data: 0.0014  max mem: 2500
Train: Epoch[2/5]  [2020/4579]  eta: 0:14:54  Lr: 0.001875  Loss: -0.3780  Acc@1: 62.5000 (61.1455)  Acc@5: 87.5000 (90.5925)  time: 0.3498  data: 0.0014  max mem: 2500
Train: Epoch[2/5]  [2030/4579]  eta: 0:14:50  Lr: 0.001875  Loss: -0.3654  Acc@1: 68.7500 (61.1521)  Acc@5: 87.5000 (90.5835)  time: 0.3483  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [2040/4579]  eta: 0:14:47  Lr: 0.001875  Loss: -0.2183  Acc@1: 62.5000 (61.1741)  Acc@5: 93.7500 (90.5867)  time: 0.3481  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2050/4579]  eta: 0:14:43  Lr: 0.001875  Loss: -0.0549  Acc@1: 62.5000 (61.1470)  Acc@5: 87.5000 (90.5747)  time: 0.3492  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2060/4579]  eta: 0:14:40  Lr: 0.001875  Loss: -0.4432  Acc@1: 56.2500 (61.1384)  Acc@5: 87.5000 (90.5568)  time: 0.3500  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2070/4579]  eta: 0:14:36  Lr: 0.001875  Loss: -0.2528  Acc@1: 62.5000 (61.1570)  Acc@5: 87.5000 (90.5541)  time: 0.3523  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [2080/4579]  eta: 0:14:33  Lr: 0.001875  Loss: -0.6874  Acc@1: 62.5000 (61.1575)  Acc@5: 87.5000 (90.5484)  time: 0.3548  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [2090/4579]  eta: 0:14:29  Lr: 0.001875  Loss: -0.5636  Acc@1: 62.5000 (61.1819)  Acc@5: 87.5000 (90.5488)  time: 0.3531  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [2100/4579]  eta: 0:14:26  Lr: 0.001875  Loss: 0.1117  Acc@1: 62.5000 (61.1733)  Acc@5: 87.5000 (90.5491)  time: 0.3502  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [2110/4579]  eta: 0:14:22  Lr: 0.001875  Loss: -0.4560  Acc@1: 56.2500 (61.1736)  Acc@5: 93.7500 (90.5554)  time: 0.3508  data: 0.0012  max mem: 2500
Train: Epoch[2/5]  [2120/4579]  eta: 0:14:19  Lr: 0.001875  Loss: -0.6996  Acc@1: 56.2500 (61.1740)  Acc@5: 93.7500 (90.5616)  time: 0.3498  data: 0.0011  max mem: 2500
Train: Epoch[2/5]  [2130/4579]  eta: 0:14:15  Lr: 0.001875  Loss: -0.1738  Acc@1: 62.5000 (61.1714)  Acc@5: 93.7500 (90.5678)  time: 0.3494  data: 0.0009  max mem: 2500
Train: Epoch[2/5]  [2140/4579]  eta: 0:14:12  Lr: 0.001875  Loss: 0.0405  Acc@1: 62.5000 (61.1718)  Acc@5: 93.7500 (90.5798)  time: 0.3509  data: 0.0009  max mem: 2500
Train: Epoch[2/5]  [2150/4579]  eta: 0:14:09  Lr: 0.001875  Loss: -0.5233  Acc@1: 62.5000 (61.1808)  Acc@5: 93.7500 (90.5829)  time: 0.3512  data: 0.0017  max mem: 2500
Train: Epoch[2/5]  [2160/4579]  eta: 0:14:05  Lr: 0.001875  Loss: 0.3058  Acc@1: 56.2500 (61.1667)  Acc@5: 93.7500 (90.5917)  time: 0.3503  data: 0.0017  max mem: 2500
Train: Epoch[2/5]  [2170/4579]  eta: 0:14:02  Lr: 0.001875  Loss: -0.2763  Acc@1: 56.2500 (61.1498)  Acc@5: 93.7500 (90.5775)  time: 0.3486  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [2180/4579]  eta: 0:13:58  Lr: 0.001875  Loss: -0.5138  Acc@1: 62.5000 (61.1617)  Acc@5: 93.7500 (90.5834)  time: 0.3490  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [2190/4579]  eta: 0:13:55  Lr: 0.001875  Loss: -0.4075  Acc@1: 62.5000 (61.1479)  Acc@5: 87.5000 (90.5637)  time: 0.3490  data: 0.0013  max mem: 2500
Train: Epoch[2/5]  [2200/4579]  eta: 0:13:51  Lr: 0.001875  Loss: -0.8347  Acc@1: 62.5000 (61.1796)  Acc@5: 87.5000 (90.5753)  time: 0.3493  data: 0.0012  max mem: 2500
Train: Epoch[2/5]  [2210/4579]  eta: 0:13:48  Lr: 0.001875  Loss: 0.4970  Acc@1: 68.7500 (61.1940)  Acc@5: 93.7500 (90.5614)  time: 0.3499  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [2220/4579]  eta: 0:13:44  Lr: 0.001875  Loss: -0.3159  Acc@1: 62.5000 (61.1746)  Acc@5: 93.7500 (90.5673)  time: 0.3495  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [2230/4579]  eta: 0:13:41  Lr: 0.001875  Loss: -0.0455  Acc@1: 62.5000 (61.1973)  Acc@5: 93.7500 (90.5704)  time: 0.3488  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [2240/4579]  eta: 0:13:37  Lr: 0.001875  Loss: -0.4566  Acc@1: 62.5000 (61.1948)  Acc@5: 93.7500 (90.5650)  time: 0.3478  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2250/4579]  eta: 0:13:34  Lr: 0.001875  Loss: -0.4027  Acc@1: 56.2500 (61.1811)  Acc@5: 93.7500 (90.5764)  time: 0.3486  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [2260/4579]  eta: 0:13:30  Lr: 0.001875  Loss: -0.0839  Acc@1: 56.2500 (61.1704)  Acc@5: 93.7500 (90.5822)  time: 0.3493  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [2270/4579]  eta: 0:13:27  Lr: 0.001875  Loss: -0.5884  Acc@1: 62.5000 (61.1707)  Acc@5: 93.7500 (90.5768)  time: 0.3509  data: 0.0018  max mem: 2500
Train: Epoch[2/5]  [2280/4579]  eta: 0:13:23  Lr: 0.001875  Loss: -0.2756  Acc@1: 62.5000 (61.1601)  Acc@5: 93.7500 (90.5770)  time: 0.3509  data: 0.0023  max mem: 2500
Train: Epoch[2/5]  [2290/4579]  eta: 0:13:20  Lr: 0.001875  Loss: -0.9971  Acc@1: 62.5000 (61.1823)  Acc@5: 93.7500 (90.5827)  time: 0.3488  data: 0.0011  max mem: 2500
Train: Epoch[2/5]  [2300/4579]  eta: 0:13:16  Lr: 0.001875  Loss: -0.1944  Acc@1: 62.5000 (61.1745)  Acc@5: 93.7500 (90.5910)  time: 0.3482  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2310/4579]  eta: 0:13:13  Lr: 0.001875  Loss: -0.6395  Acc@1: 62.5000 (61.1694)  Acc@5: 93.7500 (90.5912)  time: 0.3479  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [2320/4579]  eta: 0:13:09  Lr: 0.001875  Loss: -0.7166  Acc@1: 62.5000 (61.1698)  Acc@5: 93.7500 (90.5860)  time: 0.3497  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [2330/4579]  eta: 0:13:06  Lr: 0.001875  Loss: -0.2407  Acc@1: 62.5000 (61.1835)  Acc@5: 87.5000 (90.5915)  time: 0.3498  data: 0.0009  max mem: 2500
Train: Epoch[2/5]  [2340/4579]  eta: 0:13:02  Lr: 0.001875  Loss: -0.8095  Acc@1: 62.5000 (61.1945)  Acc@5: 87.5000 (90.5916)  time: 0.3486  data: 0.0009  max mem: 2500
Train: Epoch[2/5]  [2350/4579]  eta: 0:12:59  Lr: 0.001875  Loss: -0.7660  Acc@1: 62.5000 (61.1920)  Acc@5: 87.5000 (90.5865)  time: 0.3488  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2360/4579]  eta: 0:12:55  Lr: 0.001875  Loss: -0.3179  Acc@1: 56.2500 (61.1605)  Acc@5: 87.5000 (90.5681)  time: 0.3488  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2370/4579]  eta: 0:12:52  Lr: 0.001875  Loss: -0.5482  Acc@1: 56.2500 (61.1635)  Acc@5: 87.5000 (90.5789)  time: 0.3486  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2380/4579]  eta: 0:12:48  Lr: 0.001875  Loss: 0.0976  Acc@1: 56.2500 (61.1665)  Acc@5: 93.7500 (90.5791)  time: 0.3492  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [2390/4579]  eta: 0:12:45  Lr: 0.001875  Loss: -0.1159  Acc@1: 56.2500 (61.1486)  Acc@5: 87.5000 (90.5688)  time: 0.3493  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [2400/4579]  eta: 0:12:41  Lr: 0.001875  Loss: -0.7003  Acc@1: 56.2500 (61.1594)  Acc@5: 93.7500 (90.5899)  time: 0.3499  data: 0.0022  max mem: 2500
Train: Epoch[2/5]  [2410/4579]  eta: 0:12:38  Lr: 0.001875  Loss: -0.2737  Acc@1: 62.5000 (61.1650)  Acc@5: 93.7500 (90.5952)  time: 0.3501  data: 0.0021  max mem: 2500
Train: Epoch[2/5]  [2420/4579]  eta: 0:12:34  Lr: 0.001875  Loss: -0.4504  Acc@1: 62.5000 (61.1782)  Acc@5: 93.7500 (90.6005)  time: 0.3490  data: 0.0011  max mem: 2500
Train: Epoch[2/5]  [2430/4579]  eta: 0:12:31  Lr: 0.001875  Loss: -0.0570  Acc@1: 62.5000 (61.2042)  Acc@5: 93.7500 (90.6083)  time: 0.3489  data: 0.0011  max mem: 2500
Train: Epoch[2/5]  [2440/4579]  eta: 0:12:27  Lr: 0.001875  Loss: 0.4922  Acc@1: 62.5000 (61.1967)  Acc@5: 93.7500 (90.6058)  time: 0.3488  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [2450/4579]  eta: 0:12:24  Lr: 0.001875  Loss: -0.9331  Acc@1: 62.5000 (61.1842)  Acc@5: 93.7500 (90.5880)  time: 0.3500  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [2460/4579]  eta: 0:12:20  Lr: 0.001875  Loss: -0.1472  Acc@1: 62.5000 (61.1743)  Acc@5: 87.5000 (90.5755)  time: 0.3497  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [2470/4579]  eta: 0:12:17  Lr: 0.001875  Loss: 0.0487  Acc@1: 62.5000 (61.1949)  Acc@5: 87.5000 (90.5833)  time: 0.3485  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [2480/4579]  eta: 0:12:13  Lr: 0.001875  Loss: -0.4638  Acc@1: 68.7500 (61.2001)  Acc@5: 87.5000 (90.5784)  time: 0.3482  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2490/4579]  eta: 0:12:10  Lr: 0.001875  Loss: 0.0191  Acc@1: 62.5000 (61.2204)  Acc@5: 87.5000 (90.5861)  time: 0.3492  data: 0.0010  max mem: 2500
Train: Epoch[2/5]  [2500/4579]  eta: 0:12:06  Lr: 0.001875  Loss: -0.2921  Acc@1: 62.5000 (61.2105)  Acc@5: 93.7500 (90.5738)  time: 0.3498  data: 0.0010  max mem: 2500
Train: Epoch[2/5]  [2510/4579]  eta: 0:12:03  Lr: 0.001875  Loss: -0.3819  Acc@1: 62.5000 (61.2206)  Acc@5: 87.5000 (90.5690)  time: 0.3488  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2520/4579]  eta: 0:11:59  Lr: 0.001875  Loss: -0.2612  Acc@1: 56.2500 (61.2034)  Acc@5: 87.5000 (90.5667)  time: 0.3491  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [2530/4579]  eta: 0:11:56  Lr: 0.001875  Loss: -0.3907  Acc@1: 62.5000 (61.2159)  Acc@5: 87.5000 (90.5670)  time: 0.3489  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [2540/4579]  eta: 0:11:52  Lr: 0.001875  Loss: 0.0131  Acc@1: 62.5000 (61.2013)  Acc@5: 93.7500 (90.5844)  time: 0.3480  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [2550/4579]  eta: 0:11:49  Lr: 0.001875  Loss: -0.6606  Acc@1: 56.2500 (61.1990)  Acc@5: 93.7500 (90.5944)  time: 0.3488  data: 0.0012  max mem: 2500
Train: Epoch[2/5]  [2560/4579]  eta: 0:11:45  Lr: 0.001875  Loss: -0.7262  Acc@1: 62.5000 (61.2114)  Acc@5: 93.7500 (90.5969)  time: 0.3499  data: 0.0012  max mem: 2500
Train: Epoch[2/5]  [2570/4579]  eta: 0:11:42  Lr: 0.001875  Loss: -0.2653  Acc@1: 68.7500 (61.2286)  Acc@5: 93.7500 (90.6043)  time: 0.3502  data: 0.0013  max mem: 2500
Train: Epoch[2/5]  [2580/4579]  eta: 0:11:38  Lr: 0.001875  Loss: -0.6423  Acc@1: 62.5000 (61.2360)  Acc@5: 93.7500 (90.6117)  time: 0.3496  data: 0.0014  max mem: 2500
Train: Epoch[2/5]  [2590/4579]  eta: 0:11:35  Lr: 0.001875  Loss: -0.3765  Acc@1: 68.7500 (61.2505)  Acc@5: 93.7500 (90.6190)  time: 0.3485  data: 0.0009  max mem: 2500
Train: Epoch[2/5]  [2600/4579]  eta: 0:11:31  Lr: 0.001875  Loss: 0.1100  Acc@1: 68.7500 (61.2313)  Acc@5: 93.7500 (90.6142)  time: 0.3492  data: 0.0017  max mem: 2500
Train: Epoch[2/5]  [2610/4579]  eta: 0:11:28  Lr: 0.001875  Loss: 0.2293  Acc@1: 56.2500 (61.2050)  Acc@5: 87.5000 (90.6023)  time: 0.3497  data: 0.0014  max mem: 2500
Train: Epoch[2/5]  [2620/4579]  eta: 0:11:24  Lr: 0.001875  Loss: -0.2162  Acc@1: 56.2500 (61.1837)  Acc@5: 87.5000 (90.6047)  time: 0.3487  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [2630/4579]  eta: 0:11:21  Lr: 0.001875  Loss: -0.2543  Acc@1: 62.5000 (61.2006)  Acc@5: 93.7500 (90.6096)  time: 0.3484  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [2640/4579]  eta: 0:11:17  Lr: 0.001875  Loss: -0.4505  Acc@1: 62.5000 (61.2126)  Acc@5: 93.7500 (90.6191)  time: 0.3487  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2650/4579]  eta: 0:11:14  Lr: 0.001875  Loss: -0.4806  Acc@1: 62.5000 (61.2080)  Acc@5: 93.7500 (90.6167)  time: 0.3494  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [2660/4579]  eta: 0:11:10  Lr: 0.001875  Loss: -0.8622  Acc@1: 62.5000 (61.2129)  Acc@5: 93.7500 (90.6168)  time: 0.3497  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [2670/4579]  eta: 0:11:07  Lr: 0.001875  Loss: -0.7040  Acc@1: 62.5000 (61.2177)  Acc@5: 93.7500 (90.6262)  time: 0.3495  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [2680/4579]  eta: 0:11:03  Lr: 0.001875  Loss: -0.2026  Acc@1: 56.2500 (61.2038)  Acc@5: 93.7500 (90.6098)  time: 0.3494  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [2690/4579]  eta: 0:11:00  Lr: 0.001875  Loss: -0.4693  Acc@1: 56.2500 (61.2156)  Acc@5: 87.5000 (90.6145)  time: 0.3493  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2700/4579]  eta: 0:10:56  Lr: 0.001875  Loss: -0.0295  Acc@1: 62.5000 (61.2181)  Acc@5: 87.5000 (90.6123)  time: 0.3500  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [2710/4579]  eta: 0:10:53  Lr: 0.001875  Loss: -0.8215  Acc@1: 56.2500 (61.1951)  Acc@5: 93.7500 (90.6169)  time: 0.3498  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [2720/4579]  eta: 0:10:49  Lr: 0.001875  Loss: -0.0646  Acc@1: 56.2500 (61.1793)  Acc@5: 93.7500 (90.6239)  time: 0.3488  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [2730/4579]  eta: 0:10:46  Lr: 0.001875  Loss: -0.6712  Acc@1: 62.5000 (61.2070)  Acc@5: 93.7500 (90.6239)  time: 0.3496  data: 0.0013  max mem: 2500
Train: Epoch[2/5]  [2740/4579]  eta: 0:10:42  Lr: 0.001875  Loss: -0.9662  Acc@1: 68.7500 (61.2254)  Acc@5: 93.7500 (90.6216)  time: 0.3501  data: 0.0019  max mem: 2500
Train: Epoch[2/5]  [2750/4579]  eta: 0:10:39  Lr: 0.001875  Loss: 0.0942  Acc@1: 68.7500 (61.2300)  Acc@5: 93.7500 (90.6330)  time: 0.3498  data: 0.0012  max mem: 2500
Train: Epoch[2/5]  [2760/4579]  eta: 0:10:35  Lr: 0.001875  Loss: -0.0719  Acc@1: 62.5000 (61.2346)  Acc@5: 93.7500 (90.6329)  time: 0.3497  data: 0.0010  max mem: 2500
Train: Epoch[2/5]  [2770/4579]  eta: 0:10:32  Lr: 0.001875  Loss: 0.0723  Acc@1: 62.5000 (61.2347)  Acc@5: 93.7500 (90.6397)  time: 0.3494  data: 0.0010  max mem: 2500
Train: Epoch[2/5]  [2780/4579]  eta: 0:10:28  Lr: 0.001875  Loss: -0.8845  Acc@1: 56.2500 (61.2370)  Acc@5: 87.5000 (90.6329)  time: 0.3496  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2790/4579]  eta: 0:10:25  Lr: 0.001875  Loss: -0.8056  Acc@1: 62.5000 (61.2437)  Acc@5: 87.5000 (90.6328)  time: 0.3496  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2800/4579]  eta: 0:10:21  Lr: 0.001875  Loss: -0.3815  Acc@1: 62.5000 (61.2683)  Acc@5: 93.7500 (90.6462)  time: 0.3492  data: 0.0009  max mem: 2500
Train: Epoch[2/5]  [2810/4579]  eta: 0:10:18  Lr: 0.001875  Loss: -0.1834  Acc@1: 68.7500 (61.2727)  Acc@5: 93.7500 (90.6483)  time: 0.3488  data: 0.0009  max mem: 2500
Train: Epoch[2/5]  [2820/4579]  eta: 0:10:14  Lr: 0.001875  Loss: -0.5768  Acc@1: 68.7500 (61.2704)  Acc@5: 93.7500 (90.6483)  time: 0.3484  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [2830/4579]  eta: 0:10:11  Lr: 0.001875  Loss: -0.3810  Acc@1: 62.5000 (61.2615)  Acc@5: 93.7500 (90.6548)  time: 0.3478  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [2840/4579]  eta: 0:10:07  Lr: 0.001875  Loss: 0.1772  Acc@1: 62.5000 (61.3076)  Acc@5: 93.7500 (90.6547)  time: 0.3497  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2850/4579]  eta: 0:10:04  Lr: 0.001875  Loss: -0.1110  Acc@1: 62.5000 (61.3096)  Acc@5: 93.7500 (90.6656)  time: 0.3509  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [2860/4579]  eta: 0:10:00  Lr: 0.001875  Loss: -0.0890  Acc@1: 62.5000 (61.3247)  Acc@5: 93.7500 (90.6654)  time: 0.3503  data: 0.0010  max mem: 2500
Train: Epoch[2/5]  [2870/4579]  eta: 0:09:57  Lr: 0.001875  Loss: -0.5298  Acc@1: 62.5000 (61.3310)  Acc@5: 93.7500 (90.6827)  time: 0.3495  data: 0.0010  max mem: 2500
Train: Epoch[2/5]  [2880/4579]  eta: 0:09:53  Lr: 0.001875  Loss: -0.3792  Acc@1: 62.5000 (61.3307)  Acc@5: 93.7500 (90.6912)  time: 0.3485  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [2890/4579]  eta: 0:09:50  Lr: 0.001875  Loss: -0.5216  Acc@1: 62.5000 (61.3326)  Acc@5: 93.7500 (90.7039)  time: 0.3490  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [2900/4579]  eta: 0:09:46  Lr: 0.001875  Loss: -0.4092  Acc@1: 62.5000 (61.3388)  Acc@5: 93.7500 (90.6929)  time: 0.3487  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [2910/4579]  eta: 0:09:43  Lr: 0.001875  Loss: 0.0624  Acc@1: 62.5000 (61.3299)  Acc@5: 93.7500 (90.6991)  time: 0.3486  data: 0.0014  max mem: 2500
Train: Epoch[2/5]  [2920/4579]  eta: 0:09:39  Lr: 0.001875  Loss: 0.0336  Acc@1: 56.2500 (61.3061)  Acc@5: 93.7500 (90.7010)  time: 0.3483  data: 0.0013  max mem: 2500
Train: Epoch[2/5]  [2930/4579]  eta: 0:09:36  Lr: 0.001875  Loss: -0.4521  Acc@1: 56.2500 (61.3016)  Acc@5: 87.5000 (90.7092)  time: 0.3490  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [2940/4579]  eta: 0:09:32  Lr: 0.001875  Loss: -0.9577  Acc@1: 62.5000 (61.3227)  Acc@5: 93.7500 (90.7132)  time: 0.3504  data: 0.0011  max mem: 2500
Train: Epoch[2/5]  [2950/4579]  eta: 0:09:29  Lr: 0.001875  Loss: -0.1293  Acc@1: 62.5000 (61.3076)  Acc@5: 93.7500 (90.7214)  time: 0.3495  data: 0.0009  max mem: 2500
Train: Epoch[2/5]  [2960/4579]  eta: 0:09:25  Lr: 0.001875  Loss: 0.1730  Acc@1: 56.2500 (61.2821)  Acc@5: 93.7500 (90.7168)  time: 0.3486  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [2970/4579]  eta: 0:09:22  Lr: 0.001875  Loss: 0.0082  Acc@1: 56.2500 (61.2988)  Acc@5: 93.7500 (90.7228)  time: 0.3493  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [2980/4579]  eta: 0:09:18  Lr: 0.001875  Loss: -0.4945  Acc@1: 62.5000 (61.2924)  Acc@5: 93.7500 (90.7204)  time: 0.3484  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2990/4579]  eta: 0:09:15  Lr: 0.001875  Loss: 0.0193  Acc@1: 56.2500 (61.2859)  Acc@5: 93.7500 (90.7201)  time: 0.3473  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3000/4579]  eta: 0:09:11  Lr: 0.001875  Loss: -0.6483  Acc@1: 62.5000 (61.3046)  Acc@5: 93.7500 (90.7260)  time: 0.3476  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3010/4579]  eta: 0:09:08  Lr: 0.001875  Loss: -0.4044  Acc@1: 62.5000 (61.2919)  Acc@5: 93.7500 (90.7215)  time: 0.3479  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3020/4579]  eta: 0:09:04  Lr: 0.001875  Loss: -0.8097  Acc@1: 56.2500 (61.2794)  Acc@5: 87.5000 (90.7212)  time: 0.3482  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3030/4579]  eta: 0:09:01  Lr: 0.001875  Loss: -0.4376  Acc@1: 56.2500 (61.2793)  Acc@5: 87.5000 (90.7229)  time: 0.3481  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3040/4579]  eta: 0:08:57  Lr: 0.001875  Loss: -0.3596  Acc@1: 56.2500 (61.2730)  Acc@5: 87.5000 (90.7247)  time: 0.3495  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3050/4579]  eta: 0:08:54  Lr: 0.001875  Loss: -0.1552  Acc@1: 62.5000 (61.2873)  Acc@5: 87.5000 (90.7305)  time: 0.3501  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3060/4579]  eta: 0:08:50  Lr: 0.001875  Loss: -0.2899  Acc@1: 62.5000 (61.2749)  Acc@5: 87.5000 (90.7281)  time: 0.3490  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [3070/4579]  eta: 0:08:47  Lr: 0.001875  Loss: -0.1600  Acc@1: 56.2500 (61.2870)  Acc@5: 93.7500 (90.7380)  time: 0.3488  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3080/4579]  eta: 0:08:43  Lr: 0.001875  Loss: 0.1898  Acc@1: 62.5000 (61.2666)  Acc@5: 93.7500 (90.7396)  time: 0.3490  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3090/4579]  eta: 0:08:40  Lr: 0.001875  Loss: -0.4049  Acc@1: 56.2500 (61.2544)  Acc@5: 93.7500 (90.7413)  time: 0.3491  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3100/4579]  eta: 0:08:36  Lr: 0.001875  Loss: -0.7286  Acc@1: 62.5000 (61.2706)  Acc@5: 93.7500 (90.7429)  time: 0.3489  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3110/4579]  eta: 0:08:33  Lr: 0.001875  Loss: -0.1737  Acc@1: 68.7500 (61.2946)  Acc@5: 87.5000 (90.7425)  time: 0.3491  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3120/4579]  eta: 0:08:29  Lr: 0.001875  Loss: -0.1624  Acc@1: 68.7500 (61.3105)  Acc@5: 87.5000 (90.7522)  time: 0.3493  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3130/4579]  eta: 0:08:26  Lr: 0.001875  Loss: -0.4298  Acc@1: 62.5000 (61.3163)  Acc@5: 93.7500 (90.7557)  time: 0.3491  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [3140/4579]  eta: 0:08:22  Lr: 0.001875  Loss: -0.1248  Acc@1: 62.5000 (61.3360)  Acc@5: 93.7500 (90.7673)  time: 0.3491  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3150/4579]  eta: 0:08:19  Lr: 0.001875  Loss: 0.2072  Acc@1: 56.2500 (61.3040)  Acc@5: 93.7500 (90.7767)  time: 0.3490  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3160/4579]  eta: 0:08:15  Lr: 0.001875  Loss: -0.5656  Acc@1: 56.2500 (61.3236)  Acc@5: 93.7500 (90.7941)  time: 0.3493  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3170/4579]  eta: 0:08:12  Lr: 0.001875  Loss: -0.5215  Acc@1: 62.5000 (61.3253)  Acc@5: 93.7500 (90.7955)  time: 0.3485  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3180/4579]  eta: 0:08:08  Lr: 0.001875  Loss: -0.7592  Acc@1: 62.5000 (61.3408)  Acc@5: 93.7500 (90.8067)  time: 0.3488  data: 0.0010  max mem: 2500
Train: Epoch[2/5]  [3190/4579]  eta: 0:08:05  Lr: 0.001875  Loss: -0.2903  Acc@1: 62.5000 (61.3581)  Acc@5: 93.7500 (90.8140)  time: 0.3500  data: 0.0018  max mem: 2500
Train: Epoch[2/5]  [3200/4579]  eta: 0:08:01  Lr: 0.001875  Loss: -0.2911  Acc@1: 62.5000 (61.3578)  Acc@5: 93.7500 (90.8251)  time: 0.3491  data: 0.0012  max mem: 2500
Train: Epoch[2/5]  [3210/4579]  eta: 0:07:58  Lr: 0.001875  Loss: -0.4668  Acc@1: 56.2500 (61.3438)  Acc@5: 93.7500 (90.8245)  time: 0.3487  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [3220/4579]  eta: 0:07:54  Lr: 0.001875  Loss: -0.7030  Acc@1: 56.2500 (61.3590)  Acc@5: 93.7500 (90.8258)  time: 0.3485  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [3230/4579]  eta: 0:07:51  Lr: 0.001875  Loss: -0.5563  Acc@1: 62.5000 (61.3529)  Acc@5: 93.7500 (90.8291)  time: 0.3492  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [3240/4579]  eta: 0:07:47  Lr: 0.001875  Loss: -0.2826  Acc@1: 62.5000 (61.3603)  Acc@5: 93.7500 (90.8400)  time: 0.3498  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [3250/4579]  eta: 0:07:44  Lr: 0.001875  Loss: -0.0367  Acc@1: 68.7500 (61.3773)  Acc@5: 93.7500 (90.8297)  time: 0.3498  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3260/4579]  eta: 0:07:40  Lr: 0.001875  Loss: 0.1690  Acc@1: 62.5000 (61.3711)  Acc@5: 93.7500 (90.8406)  time: 0.3487  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [3270/4579]  eta: 0:07:37  Lr: 0.001875  Loss: -0.2964  Acc@1: 62.5000 (61.3784)  Acc@5: 93.7500 (90.8342)  time: 0.3483  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [3280/4579]  eta: 0:07:33  Lr: 0.001875  Loss: -0.8094  Acc@1: 68.7500 (61.3952)  Acc@5: 93.7500 (90.8450)  time: 0.3484  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3290/4579]  eta: 0:07:30  Lr: 0.001875  Loss: -0.4816  Acc@1: 68.7500 (61.3947)  Acc@5: 93.7500 (90.8519)  time: 0.3486  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [3300/4579]  eta: 0:07:26  Lr: 0.001875  Loss: -0.5696  Acc@1: 56.2500 (61.3981)  Acc@5: 93.7500 (90.8645)  time: 0.3502  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [3310/4579]  eta: 0:07:23  Lr: 0.001875  Loss: -0.9664  Acc@1: 62.5000 (61.4184)  Acc@5: 100.0000 (90.8770)  time: 0.3506  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3320/4579]  eta: 0:07:19  Lr: 0.001875  Loss: 0.1108  Acc@1: 62.5000 (61.4273)  Acc@5: 93.7500 (90.8819)  time: 0.3496  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [3330/4579]  eta: 0:07:16  Lr: 0.001875  Loss: -0.0818  Acc@1: 62.5000 (61.4305)  Acc@5: 93.7500 (90.8980)  time: 0.3486  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [3340/4579]  eta: 0:07:12  Lr: 0.001875  Loss: -0.3331  Acc@1: 62.5000 (61.4431)  Acc@5: 93.7500 (90.9028)  time: 0.3493  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [3350/4579]  eta: 0:07:09  Lr: 0.001875  Loss: -0.2583  Acc@1: 62.5000 (61.4332)  Acc@5: 93.7500 (90.9132)  time: 0.3493  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3360/4579]  eta: 0:07:05  Lr: 0.001875  Loss: -0.7310  Acc@1: 56.2500 (61.4400)  Acc@5: 93.7500 (90.9179)  time: 0.3483  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3370/4579]  eta: 0:07:02  Lr: 0.001875  Loss: -0.6010  Acc@1: 56.2500 (61.4488)  Acc@5: 93.7500 (90.9263)  time: 0.3501  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3380/4579]  eta: 0:06:58  Lr: 0.001875  Loss: -0.1601  Acc@1: 56.2500 (61.4278)  Acc@5: 93.7500 (90.9161)  time: 0.3503  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3390/4579]  eta: 0:06:55  Lr: 0.001875  Loss: -0.3757  Acc@1: 56.2500 (61.4421)  Acc@5: 93.7500 (90.9227)  time: 0.3489  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3400/4579]  eta: 0:06:51  Lr: 0.001875  Loss: -0.3351  Acc@1: 62.5000 (61.4562)  Acc@5: 93.7500 (90.9236)  time: 0.3497  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3410/4579]  eta: 0:06:48  Lr: 0.001875  Loss: -0.3907  Acc@1: 62.5000 (61.4629)  Acc@5: 93.7500 (90.9301)  time: 0.3498  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [3420/4579]  eta: 0:06:44  Lr: 0.001875  Loss: 0.1296  Acc@1: 56.2500 (61.4513)  Acc@5: 93.7500 (90.9237)  time: 0.3495  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [3430/4579]  eta: 0:06:41  Lr: 0.001875  Loss: -0.3144  Acc@1: 56.2500 (61.4507)  Acc@5: 93.7500 (90.9210)  time: 0.3503  data: 0.0010  max mem: 2500
Train: Epoch[2/5]  [3440/4579]  eta: 0:06:37  Lr: 0.001875  Loss: -0.0177  Acc@1: 62.5000 (61.4502)  Acc@5: 87.5000 (90.9238)  time: 0.3508  data: 0.0009  max mem: 2500
Train: Epoch[2/5]  [3450/4579]  eta: 0:06:34  Lr: 0.001875  Loss: -0.4936  Acc@1: 62.5000 (61.4550)  Acc@5: 87.5000 (90.9229)  time: 0.3502  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [3460/4579]  eta: 0:06:30  Lr: 0.001875  Loss: -0.3910  Acc@1: 62.5000 (61.4598)  Acc@5: 87.5000 (90.9148)  time: 0.3494  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [3470/4579]  eta: 0:06:27  Lr: 0.001875  Loss: -0.3376  Acc@1: 62.5000 (61.4610)  Acc@5: 87.5000 (90.9122)  time: 0.3490  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [3480/4579]  eta: 0:06:24  Lr: 0.001875  Loss: -0.2182  Acc@1: 56.2500 (61.4532)  Acc@5: 93.7500 (90.9132)  time: 0.3507  data: 0.0012  max mem: 2500
Train: Epoch[2/5]  [3490/4579]  eta: 0:06:20  Lr: 0.001875  Loss: -0.8984  Acc@1: 62.5000 (61.4867)  Acc@5: 93.7500 (90.9213)  time: 0.3505  data: 0.0012  max mem: 2500
Train: Epoch[2/5]  [3500/4579]  eta: 0:06:17  Lr: 0.001875  Loss: 0.3523  Acc@1: 68.7500 (61.4771)  Acc@5: 93.7500 (90.9062)  time: 0.3492  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3510/4579]  eta: 0:06:13  Lr: 0.001875  Loss: -0.5546  Acc@1: 62.5000 (61.4800)  Acc@5: 93.7500 (90.9089)  time: 0.3498  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [3520/4579]  eta: 0:06:10  Lr: 0.001875  Loss: -0.2851  Acc@1: 62.5000 (61.4829)  Acc@5: 93.7500 (90.9223)  time: 0.3498  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [3530/4579]  eta: 0:06:06  Lr: 0.001875  Loss: -0.0800  Acc@1: 62.5000 (61.4911)  Acc@5: 93.7500 (90.9321)  time: 0.3500  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3540/4579]  eta: 0:06:03  Lr: 0.001875  Loss: -0.7770  Acc@1: 62.5000 (61.4851)  Acc@5: 93.7500 (90.9348)  time: 0.3506  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [3550/4579]  eta: 0:05:59  Lr: 0.001875  Loss: -0.0370  Acc@1: 62.5000 (61.5056)  Acc@5: 93.7500 (90.9445)  time: 0.3501  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [3560/4579]  eta: 0:05:56  Lr: 0.001875  Loss: -0.2440  Acc@1: 62.5000 (61.4978)  Acc@5: 93.7500 (90.9471)  time: 0.3495  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [3570/4579]  eta: 0:05:52  Lr: 0.001875  Loss: -0.4225  Acc@1: 62.5000 (61.4954)  Acc@5: 87.5000 (90.9409)  time: 0.3492  data: 0.0009  max mem: 2500
Train: Epoch[2/5]  [3580/4579]  eta: 0:05:49  Lr: 0.001875  Loss: 0.1408  Acc@1: 62.5000 (61.4964)  Acc@5: 87.5000 (90.9435)  time: 0.3493  data: 0.0014  max mem: 2500
Train: Epoch[2/5]  [3590/4579]  eta: 0:05:45  Lr: 0.001875  Loss: -0.4163  Acc@1: 68.7500 (61.5010)  Acc@5: 93.7500 (90.9409)  time: 0.3493  data: 0.0011  max mem: 2500
Train: Epoch[2/5]  [3600/4579]  eta: 0:05:42  Lr: 0.001875  Loss: -0.1526  Acc@1: 62.5000 (61.5037)  Acc@5: 87.5000 (90.9400)  time: 0.3489  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [3610/4579]  eta: 0:05:38  Lr: 0.001875  Loss: -0.2455  Acc@1: 62.5000 (61.5169)  Acc@5: 93.7500 (90.9495)  time: 0.3487  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [3620/4579]  eta: 0:05:35  Lr: 0.001875  Loss: -0.8493  Acc@1: 62.5000 (61.5248)  Acc@5: 93.7500 (90.9486)  time: 0.3480  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [3630/4579]  eta: 0:05:31  Lr: 0.001875  Loss: 0.0074  Acc@1: 56.2500 (61.5103)  Acc@5: 87.5000 (90.9323)  time: 0.3484  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [3640/4579]  eta: 0:05:28  Lr: 0.001875  Loss: -0.4817  Acc@1: 62.5000 (61.5319)  Acc@5: 87.5000 (90.9383)  time: 0.3487  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3650/4579]  eta: 0:05:24  Lr: 0.001875  Loss: -0.4649  Acc@1: 68.7500 (61.5294)  Acc@5: 93.7500 (90.9357)  time: 0.3497  data: 0.0021  max mem: 2500
Train: Epoch[2/5]  [3660/4579]  eta: 0:05:21  Lr: 0.001875  Loss: -0.0994  Acc@1: 68.7500 (61.5389)  Acc@5: 87.5000 (90.9349)  time: 0.3501  data: 0.0027  max mem: 2500
Train: Epoch[2/5]  [3670/4579]  eta: 0:05:17  Lr: 0.001875  Loss: -0.5678  Acc@1: 62.5000 (61.5279)  Acc@5: 93.7500 (90.9323)  time: 0.3496  data: 0.0010  max mem: 2500
Train: Epoch[2/5]  [3680/4579]  eta: 0:05:14  Lr: 0.001875  Loss: -0.8186  Acc@1: 62.5000 (61.5322)  Acc@5: 93.7500 (90.9332)  time: 0.3494  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [3690/4579]  eta: 0:05:10  Lr: 0.001875  Loss: -0.0694  Acc@1: 62.5000 (61.5230)  Acc@5: 87.5000 (90.9289)  time: 0.3486  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [3700/4579]  eta: 0:05:07  Lr: 0.001875  Loss: -0.5914  Acc@1: 56.2500 (61.5138)  Acc@5: 87.5000 (90.9298)  time: 0.3484  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [3710/4579]  eta: 0:05:03  Lr: 0.001875  Loss: -0.0256  Acc@1: 62.5000 (61.5249)  Acc@5: 93.7500 (90.9324)  time: 0.3485  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3720/4579]  eta: 0:05:00  Lr: 0.001875  Loss: -0.1413  Acc@1: 62.5000 (61.5325)  Acc@5: 93.7500 (90.9315)  time: 0.3487  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [3730/4579]  eta: 0:04:56  Lr: 0.001875  Loss: -0.6651  Acc@1: 62.5000 (61.5301)  Acc@5: 93.7500 (90.9391)  time: 0.3493  data: 0.0018  max mem: 2500
Train: Epoch[2/5]  [3740/4579]  eta: 0:04:53  Lr: 0.001875  Loss: 0.3548  Acc@1: 56.2500 (61.5176)  Acc@5: 93.7500 (90.9282)  time: 0.3488  data: 0.0016  max mem: 2500
Train: Epoch[2/5]  [3750/4579]  eta: 0:04:49  Lr: 0.001875  Loss: -0.4364  Acc@1: 62.5000 (61.5236)  Acc@5: 93.7500 (90.9324)  time: 0.3485  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3760/4579]  eta: 0:04:46  Lr: 0.001875  Loss: 0.3252  Acc@1: 62.5000 (61.5129)  Acc@5: 93.7500 (90.9283)  time: 0.3496  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3770/4579]  eta: 0:04:42  Lr: 0.001875  Loss: -0.6697  Acc@1: 62.5000 (61.5221)  Acc@5: 93.7500 (90.9391)  time: 0.3491  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3780/4579]  eta: 0:04:39  Lr: 0.001875  Loss: -0.2210  Acc@1: 62.5000 (61.5264)  Acc@5: 93.7500 (90.9316)  time: 0.3485  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3790/4579]  eta: 0:04:35  Lr: 0.001875  Loss: -0.6401  Acc@1: 62.5000 (61.5355)  Acc@5: 87.5000 (90.9407)  time: 0.3499  data: 0.0011  max mem: 2500
Train: Epoch[2/5]  [3800/4579]  eta: 0:04:32  Lr: 0.001875  Loss: -0.2111  Acc@1: 56.2500 (61.5200)  Acc@5: 87.5000 (90.9251)  time: 0.3499  data: 0.0011  max mem: 2500
Train: Epoch[2/5]  [3810/4579]  eta: 0:04:28  Lr: 0.001875  Loss: -0.8389  Acc@1: 56.2500 (61.5209)  Acc@5: 87.5000 (90.9145)  time: 0.3491  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3820/4579]  eta: 0:04:25  Lr: 0.001875  Loss: -0.8491  Acc@1: 56.2500 (61.5284)  Acc@5: 87.5000 (90.9153)  time: 0.3493  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [3830/4579]  eta: 0:04:21  Lr: 0.001875  Loss: 0.1250  Acc@1: 62.5000 (61.5326)  Acc@5: 93.7500 (90.9211)  time: 0.3501  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [3840/4579]  eta: 0:04:18  Lr: 0.001875  Loss: 0.1361  Acc@1: 62.5000 (61.5416)  Acc@5: 87.5000 (90.9171)  time: 0.3505  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [3850/4579]  eta: 0:04:14  Lr: 0.001875  Loss: -0.6155  Acc@1: 62.5000 (61.5619)  Acc@5: 93.7500 (90.9212)  time: 0.3513  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [3860/4579]  eta: 0:04:11  Lr: 0.001875  Loss: -0.3290  Acc@1: 62.5000 (61.5611)  Acc@5: 87.5000 (90.9139)  time: 0.3513  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3870/4579]  eta: 0:04:07  Lr: 0.001875  Loss: -0.1345  Acc@1: 68.7500 (61.5845)  Acc@5: 87.5000 (90.9213)  time: 0.3498  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3880/4579]  eta: 0:04:04  Lr: 0.001875  Loss: -0.7387  Acc@1: 68.7500 (61.5837)  Acc@5: 93.7500 (90.9221)  time: 0.3487  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3890/4579]  eta: 0:04:00  Lr: 0.001875  Loss: -0.3946  Acc@1: 56.2500 (61.5668)  Acc@5: 87.5000 (90.9069)  time: 0.3487  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3900/4579]  eta: 0:03:57  Lr: 0.001875  Loss: -0.3666  Acc@1: 62.5000 (61.5740)  Acc@5: 87.5000 (90.9078)  time: 0.3502  data: 0.0011  max mem: 2500
Train: Epoch[2/5]  [3910/4579]  eta: 0:03:53  Lr: 0.001875  Loss: -0.3480  Acc@1: 62.5000 (61.5747)  Acc@5: 93.7500 (90.9055)  time: 0.3509  data: 0.0018  max mem: 2500
Train: Epoch[2/5]  [3920/4579]  eta: 0:03:50  Lr: 0.001875  Loss: -0.3865  Acc@1: 62.5000 (61.5707)  Acc@5: 93.7500 (90.9111)  time: 0.3496  data: 0.0012  max mem: 2500
Train: Epoch[2/5]  [3930/4579]  eta: 0:03:46  Lr: 0.001875  Loss: -1.0138  Acc@1: 62.5000 (61.5635)  Acc@5: 93.7500 (90.9056)  time: 0.3494  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [3940/4579]  eta: 0:03:43  Lr: 0.001875  Loss: -0.4082  Acc@1: 56.2500 (61.5548)  Acc@5: 87.5000 (90.9033)  time: 0.3491  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [3950/4579]  eta: 0:03:39  Lr: 0.001875  Loss: -0.3922  Acc@1: 62.5000 (61.5651)  Acc@5: 93.7500 (90.9058)  time: 0.3489  data: 0.0010  max mem: 2500
Train: Epoch[2/5]  [3960/4579]  eta: 0:03:36  Lr: 0.001875  Loss: -0.1214  Acc@1: 62.5000 (61.5596)  Acc@5: 93.7500 (90.9035)  time: 0.3496  data: 0.0011  max mem: 2500
Train: Epoch[2/5]  [3970/4579]  eta: 0:03:32  Lr: 0.001875  Loss: -0.5046  Acc@1: 62.5000 (61.5604)  Acc@5: 93.7500 (90.9059)  time: 0.3489  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3980/4579]  eta: 0:03:29  Lr: 0.001875  Loss: 0.0324  Acc@1: 62.5000 (61.5612)  Acc@5: 87.5000 (90.8958)  time: 0.3492  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [3990/4579]  eta: 0:03:25  Lr: 0.001875  Loss: -0.5691  Acc@1: 62.5000 (61.5494)  Acc@5: 87.5000 (90.8967)  time: 0.3493  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [4000/4579]  eta: 0:03:22  Lr: 0.001875  Loss: -0.4505  Acc@1: 62.5000 (61.5565)  Acc@5: 93.7500 (90.8976)  time: 0.3491  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [4010/4579]  eta: 0:03:18  Lr: 0.001875  Loss: -0.2604  Acc@1: 62.5000 (61.5588)  Acc@5: 93.7500 (90.9031)  time: 0.3487  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [4020/4579]  eta: 0:03:15  Lr: 0.001875  Loss: -0.6340  Acc@1: 62.5000 (61.5658)  Acc@5: 93.7500 (90.9024)  time: 0.3482  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [4030/4579]  eta: 0:03:11  Lr: 0.001875  Loss: -0.3940  Acc@1: 62.5000 (61.5651)  Acc@5: 93.7500 (90.9002)  time: 0.3503  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [4040/4579]  eta: 0:03:08  Lr: 0.001875  Loss: -0.3682  Acc@1: 62.5000 (61.5767)  Acc@5: 93.7500 (90.9088)  time: 0.3509  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [4050/4579]  eta: 0:03:04  Lr: 0.001875  Loss: -0.2972  Acc@1: 62.5000 (61.5913)  Acc@5: 100.0000 (90.9189)  time: 0.3501  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [4060/4579]  eta: 0:03:01  Lr: 0.001875  Loss: -0.3684  Acc@1: 62.5000 (61.5889)  Acc@5: 93.7500 (90.9197)  time: 0.3503  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [4070/4579]  eta: 0:02:57  Lr: 0.001875  Loss: -0.0515  Acc@1: 62.5000 (61.6003)  Acc@5: 93.7500 (90.9328)  time: 0.3507  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [4080/4579]  eta: 0:02:54  Lr: 0.001875  Loss: -0.5101  Acc@1: 68.7500 (61.5995)  Acc@5: 93.7500 (90.9290)  time: 0.3512  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [4090/4579]  eta: 0:02:50  Lr: 0.001875  Loss: -0.3879  Acc@1: 62.5000 (61.6032)  Acc@5: 87.5000 (90.9191)  time: 0.3499  data: 0.0003  max mem: 2500
Train: Epoch[2/5]  [4100/4579]  eta: 0:02:47  Lr: 0.001875  Loss: -0.6040  Acc@1: 62.5000 (61.6084)  Acc@5: 87.5000 (90.9199)  time: 0.3482  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [4110/4579]  eta: 0:02:43  Lr: 0.001875  Loss: -0.6559  Acc@1: 68.7500 (61.6273)  Acc@5: 93.7500 (90.9344)  time: 0.3486  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [4120/4579]  eta: 0:02:40  Lr: 0.001875  Loss: -0.3393  Acc@1: 68.7500 (61.6264)  Acc@5: 93.7500 (90.9321)  time: 0.3499  data: 0.0014  max mem: 2500
Train: Epoch[2/5]  [4130/4579]  eta: 0:02:36  Lr: 0.001875  Loss: -0.3429  Acc@1: 62.5000 (61.6361)  Acc@5: 93.7500 (90.9374)  time: 0.3498  data: 0.0011  max mem: 2500
Train: Epoch[2/5]  [4140/4579]  eta: 0:02:33  Lr: 0.001875  Loss: -0.5968  Acc@1: 68.7500 (61.6533)  Acc@5: 93.7500 (90.9442)  time: 0.3491  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [4150/4579]  eta: 0:02:29  Lr: 0.001875  Loss: -0.2778  Acc@1: 68.7500 (61.6538)  Acc@5: 93.7500 (90.9450)  time: 0.3496  data: 0.0011  max mem: 2500
Train: Epoch[2/5]  [4160/4579]  eta: 0:02:26  Lr: 0.001875  Loss: -0.3326  Acc@1: 62.5000 (61.6468)  Acc@5: 93.7500 (90.9472)  time: 0.3506  data: 0.0010  max mem: 2500
Train: Epoch[2/5]  [4170/4579]  eta: 0:02:22  Lr: 0.001875  Loss: -0.2608  Acc@1: 62.5000 (61.6504)  Acc@5: 93.7500 (90.9494)  time: 0.3508  data: 0.0010  max mem: 2500
Train: Epoch[2/5]  [4180/4579]  eta: 0:02:19  Lr: 0.001875  Loss: -0.6439  Acc@1: 62.5000 (61.6479)  Acc@5: 87.5000 (90.9486)  time: 0.3500  data: 0.0010  max mem: 2500
Train: Epoch[2/5]  [4190/4579]  eta: 0:02:15  Lr: 0.001875  Loss: -0.4647  Acc@1: 56.2500 (61.6351)  Acc@5: 87.5000 (90.9464)  time: 0.3496  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [4200/4579]  eta: 0:02:12  Lr: 0.001875  Loss: -0.1501  Acc@1: 62.5000 (61.6416)  Acc@5: 93.7500 (90.9516)  time: 0.3510  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [4210/4579]  eta: 0:02:08  Lr: 0.001875  Loss: -0.6300  Acc@1: 62.5000 (61.6525)  Acc@5: 93.7500 (90.9538)  time: 0.3514  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [4220/4579]  eta: 0:02:05  Lr: 0.001875  Loss: -0.5173  Acc@1: 62.5000 (61.6560)  Acc@5: 87.5000 (90.9515)  time: 0.3516  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [4230/4579]  eta: 0:02:01  Lr: 0.001875  Loss: 0.0001  Acc@1: 62.5000 (61.6595)  Acc@5: 87.5000 (90.9537)  time: 0.3520  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [4240/4579]  eta: 0:01:58  Lr: 0.001875  Loss: -0.6979  Acc@1: 62.5000 (61.6629)  Acc@5: 93.7500 (90.9647)  time: 0.3507  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [4250/4579]  eta: 0:01:54  Lr: 0.001875  Loss: -0.8125  Acc@1: 68.7500 (61.6855)  Acc@5: 93.7500 (90.9727)  time: 0.3503  data: 0.0011  max mem: 2500
Train: Epoch[2/5]  [4260/4579]  eta: 0:01:51  Lr: 0.001875  Loss: 0.1470  Acc@1: 68.7500 (61.6903)  Acc@5: 93.7500 (90.9690)  time: 0.3514  data: 0.0016  max mem: 2500
Train: Epoch[2/5]  [4270/4579]  eta: 0:01:47  Lr: 0.001875  Loss: -0.8897  Acc@1: 62.5000 (61.6834)  Acc@5: 87.5000 (90.9667)  time: 0.3509  data: 0.0010  max mem: 2500
Train: Epoch[2/5]  [4280/4579]  eta: 0:01:44  Lr: 0.001875  Loss: 0.0083  Acc@1: 56.2500 (61.6795)  Acc@5: 93.7500 (90.9659)  time: 0.3496  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [4290/4579]  eta: 0:01:40  Lr: 0.001875  Loss: -0.0716  Acc@1: 68.7500 (61.6843)  Acc@5: 93.7500 (90.9666)  time: 0.3495  data: 0.0010  max mem: 2500
Train: Epoch[2/5]  [4300/4579]  eta: 0:01:37  Lr: 0.001875  Loss: -0.7016  Acc@1: 68.7500 (61.6950)  Acc@5: 93.7500 (90.9672)  time: 0.3487  data: 0.0010  max mem: 2500
Train: Epoch[2/5]  [4310/4579]  eta: 0:01:34  Lr: 0.001875  Loss: -0.1453  Acc@1: 62.5000 (61.6968)  Acc@5: 93.7500 (90.9621)  time: 0.3488  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [4320/4579]  eta: 0:01:30  Lr: 0.001875  Loss: -0.0918  Acc@1: 62.5000 (61.6914)  Acc@5: 87.5000 (90.9541)  time: 0.3503  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [4330/4579]  eta: 0:01:27  Lr: 0.001875  Loss: -0.1710  Acc@1: 62.5000 (61.7106)  Acc@5: 87.5000 (90.9475)  time: 0.3507  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [4340/4579]  eta: 0:01:23  Lr: 0.001875  Loss: -0.2353  Acc@1: 68.7500 (61.7125)  Acc@5: 93.7500 (90.9540)  time: 0.3508  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [4350/4579]  eta: 0:01:20  Lr: 0.001875  Loss: -0.5339  Acc@1: 62.5000 (61.7214)  Acc@5: 93.7500 (90.9532)  time: 0.3499  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [4360/4579]  eta: 0:01:16  Lr: 0.001875  Loss: -0.1230  Acc@1: 62.5000 (61.7204)  Acc@5: 93.7500 (90.9539)  time: 0.3506  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [4370/4579]  eta: 0:01:13  Lr: 0.001875  Loss: -0.4503  Acc@1: 62.5000 (61.7293)  Acc@5: 87.5000 (90.9532)  time: 0.3539  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [4380/4579]  eta: 0:01:09  Lr: 0.001875  Loss: -0.4892  Acc@1: 68.7500 (61.7353)  Acc@5: 93.7500 (90.9567)  time: 0.3535  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [4390/4579]  eta: 0:01:06  Lr: 0.001875  Loss: -0.6197  Acc@1: 62.5000 (61.7385)  Acc@5: 93.7500 (90.9502)  time: 0.3506  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [4400/4579]  eta: 0:01:02  Lr: 0.001875  Loss: -0.1764  Acc@1: 56.2500 (61.7345)  Acc@5: 93.7500 (90.9509)  time: 0.3489  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [4410/4579]  eta: 0:00:59  Lr: 0.001875  Loss: 0.0124  Acc@1: 56.2500 (61.7335)  Acc@5: 93.7500 (90.9473)  time: 0.3492  data: 0.0012  max mem: 2500
Train: Epoch[2/5]  [4420/4579]  eta: 0:00:55  Lr: 0.001875  Loss: -0.6123  Acc@1: 62.5000 (61.7423)  Acc@5: 93.7500 (90.9424)  time: 0.3502  data: 0.0015  max mem: 2500
Train: Epoch[2/5]  [4430/4579]  eta: 0:00:52  Lr: 0.001875  Loss: 0.1801  Acc@1: 62.5000 (61.7397)  Acc@5: 87.5000 (90.9417)  time: 0.3499  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [4440/4579]  eta: 0:00:48  Lr: 0.001875  Loss: -0.5843  Acc@1: 56.2500 (61.7288)  Acc@5: 87.5000 (90.9325)  time: 0.3495  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [4450/4579]  eta: 0:00:45  Lr: 0.001875  Loss: -0.3105  Acc@1: 56.2500 (61.7305)  Acc@5: 87.5000 (90.9360)  time: 0.3502  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [4460/4579]  eta: 0:00:41  Lr: 0.001875  Loss: -0.9206  Acc@1: 62.5000 (61.7364)  Acc@5: 93.7500 (90.9381)  time: 0.3499  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [4470/4579]  eta: 0:00:38  Lr: 0.001875  Loss: -0.5953  Acc@1: 56.2500 (61.7340)  Acc@5: 93.7500 (90.9374)  time: 0.3498  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [4480/4579]  eta: 0:00:34  Lr: 0.001875  Loss: -0.3067  Acc@1: 62.5000 (61.7426)  Acc@5: 93.7500 (90.9381)  time: 0.3498  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [4490/4579]  eta: 0:00:31  Lr: 0.001875  Loss: -0.5340  Acc@1: 62.5000 (61.7318)  Acc@5: 93.7500 (90.9444)  time: 0.3494  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [4500/4579]  eta: 0:00:27  Lr: 0.001875  Loss: -0.4545  Acc@1: 62.5000 (61.7321)  Acc@5: 93.7500 (90.9492)  time: 0.3497  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [4510/4579]  eta: 0:00:24  Lr: 0.001875  Loss: -0.0574  Acc@1: 62.5000 (61.7213)  Acc@5: 93.7500 (90.9430)  time: 0.3505  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [4520/4579]  eta: 0:00:20  Lr: 0.001875  Loss: 0.1190  Acc@1: 56.2500 (61.7245)  Acc@5: 87.5000 (90.9367)  time: 0.3518  data: 0.0013  max mem: 2500
Train: Epoch[2/5]  [4530/4579]  eta: 0:00:17  Lr: 0.001875  Loss: -0.6867  Acc@1: 62.5000 (61.7317)  Acc@5: 93.7500 (90.9374)  time: 0.3512  data: 0.0013  max mem: 2500
Train: Epoch[2/5]  [4540/4579]  eta: 0:00:13  Lr: 0.001875  Loss: -0.2066  Acc@1: 68.7500 (61.7416)  Acc@5: 93.7500 (90.9464)  time: 0.3502  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [4550/4579]  eta: 0:00:10  Lr: 0.001875  Loss: -0.3886  Acc@1: 62.5000 (61.7364)  Acc@5: 93.7500 (90.9402)  time: 0.3493  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [4560/4579]  eta: 0:00:06  Lr: 0.001875  Loss: 0.1041  Acc@1: 62.5000 (61.7504)  Acc@5: 87.5000 (90.9395)  time: 0.3491  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [4570/4579]  eta: 0:00:03  Lr: 0.001875  Loss: -0.4365  Acc@1: 68.7500 (61.7603)  Acc@5: 93.7500 (90.9470)  time: 0.3504  data: 0.0016  max mem: 2500
Train: Epoch[2/5]  [4578/4579]  eta: 0:00:00  Lr: 0.001875  Loss: 0.0966  Acc@1: 62.5000 (61.7525)  Acc@5: 93.7500 (90.9401)  time: 0.3425  data: 0.0015  max mem: 2500
Train: Epoch[2/5] Total time: 0:26:41 (0.3497 s / it)
Averaged stats: Lr: 0.001875  Loss: 0.0966  Acc@1: 62.5000 (61.7525)  Acc@5: 93.7500 (90.9401)
Train: Epoch[3/5]  [   0/4579]  eta: 0:59:23  Lr: 0.001875  Loss: 0.6062  Acc@1: 25.0000 (25.0000)  Acc@5: 81.2500 (81.2500)  time: 0.7783  data: 0.4310  max mem: 2500
Train: Epoch[3/5]  [  10/4579]  eta: 0:29:47  Lr: 0.001875  Loss: -0.1211  Acc@1: 62.5000 (57.3864)  Acc@5: 87.5000 (89.7727)  time: 0.3913  data: 0.0396  max mem: 2500
Train: Epoch[3/5]  [  20/4579]  eta: 0:28:10  Lr: 0.001875  Loss: -0.7793  Acc@1: 62.5000 (59.5238)  Acc@5: 93.7500 (91.0714)  time: 0.3504  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [  30/4579]  eta: 0:27:35  Lr: 0.001875  Loss: -0.5714  Acc@1: 62.5000 (61.8952)  Acc@5: 93.7500 (90.7258)  time: 0.3489  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [  40/4579]  eta: 0:27:14  Lr: 0.001875  Loss: 0.0004  Acc@1: 62.5000 (61.8902)  Acc@5: 93.7500 (90.7012)  time: 0.3487  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [  50/4579]  eta: 0:27:01  Lr: 0.001875  Loss: -0.6144  Acc@1: 62.5000 (62.8676)  Acc@5: 93.7500 (91.1765)  time: 0.3486  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [  60/4579]  eta: 0:26:52  Lr: 0.001875  Loss: -0.4086  Acc@1: 62.5000 (63.5246)  Acc@5: 87.5000 (90.4713)  time: 0.3500  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [  70/4579]  eta: 0:26:48  Lr: 0.001875  Loss: 0.0775  Acc@1: 62.5000 (62.8521)  Acc@5: 87.5000 (90.1408)  time: 0.3534  data: 0.0014  max mem: 2500
Train: Epoch[3/5]  [  80/4579]  eta: 0:26:40  Lr: 0.001875  Loss: -0.4210  Acc@1: 62.5000 (63.2716)  Acc@5: 87.5000 (89.9691)  time: 0.3525  data: 0.0012  max mem: 2500
Train: Epoch[3/5]  [  90/4579]  eta: 0:26:33  Lr: 0.001875  Loss: -0.0342  Acc@1: 62.5000 (62.6374)  Acc@5: 87.5000 (89.9038)  time: 0.3495  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 100/4579]  eta: 0:26:29  Lr: 0.001875  Loss: -0.7553  Acc@1: 62.5000 (62.8713)  Acc@5: 93.7500 (90.0990)  time: 0.3517  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [ 110/4579]  eta: 0:26:23  Lr: 0.001875  Loss: -0.5799  Acc@1: 62.5000 (62.6126)  Acc@5: 87.5000 (90.0901)  time: 0.3505  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [ 120/4579]  eta: 0:26:17  Lr: 0.001875  Loss: -0.6926  Acc@1: 56.2500 (62.3967)  Acc@5: 87.5000 (90.1343)  time: 0.3476  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [ 130/4579]  eta: 0:26:12  Lr: 0.001875  Loss: -0.4716  Acc@1: 56.2500 (61.7844)  Acc@5: 87.5000 (89.8855)  time: 0.3486  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [ 140/4579]  eta: 0:26:07  Lr: 0.001875  Loss: 0.1755  Acc@1: 56.2500 (62.1897)  Acc@5: 87.5000 (90.0709)  time: 0.3497  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 150/4579]  eta: 0:26:02  Lr: 0.001875  Loss: -0.5926  Acc@1: 62.5000 (61.8377)  Acc@5: 87.5000 (90.0248)  time: 0.3487  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 160/4579]  eta: 0:25:57  Lr: 0.001875  Loss: -0.4359  Acc@1: 62.5000 (62.3447)  Acc@5: 93.7500 (90.1786)  time: 0.3484  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [ 170/4579]  eta: 0:25:53  Lr: 0.001875  Loss: -0.0423  Acc@1: 62.5000 (62.0614)  Acc@5: 93.7500 (90.2047)  time: 0.3498  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [ 180/4579]  eta: 0:25:49  Lr: 0.001875  Loss: -0.4138  Acc@1: 62.5000 (62.2238)  Acc@5: 87.5000 (90.3315)  time: 0.3498  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [ 190/4579]  eta: 0:25:45  Lr: 0.001875  Loss: -0.1814  Acc@1: 62.5000 (62.0746)  Acc@5: 93.7500 (90.5432)  time: 0.3494  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 200/4579]  eta: 0:25:41  Lr: 0.001875  Loss: -0.3510  Acc@1: 62.5000 (62.1269)  Acc@5: 93.7500 (90.4540)  time: 0.3490  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [ 210/4579]  eta: 0:25:36  Lr: 0.001875  Loss: -0.5255  Acc@1: 62.5000 (62.0853)  Acc@5: 87.5000 (90.3732)  time: 0.3486  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [ 220/4579]  eta: 0:25:33  Lr: 0.001875  Loss: -0.7660  Acc@1: 62.5000 (62.1606)  Acc@5: 87.5000 (90.4129)  time: 0.3496  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [ 230/4579]  eta: 0:25:29  Lr: 0.001875  Loss: 0.0671  Acc@1: 56.2500 (61.8236)  Acc@5: 87.5000 (90.2597)  time: 0.3497  data: 0.0009  max mem: 2500
Train: Epoch[3/5]  [ 240/4579]  eta: 0:25:24  Lr: 0.001875  Loss: -0.1673  Acc@1: 56.2500 (62.0591)  Acc@5: 93.7500 (90.4564)  time: 0.3488  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [ 250/4579]  eta: 0:25:20  Lr: 0.001875  Loss: -0.6453  Acc@1: 62.5000 (62.3257)  Acc@5: 93.7500 (90.3884)  time: 0.3484  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [ 260/4579]  eta: 0:25:17  Lr: 0.001875  Loss: 0.0294  Acc@1: 62.5000 (62.4761)  Acc@5: 93.7500 (90.3975)  time: 0.3493  data: 0.0012  max mem: 2500
Train: Epoch[3/5]  [ 270/4579]  eta: 0:25:13  Lr: 0.001875  Loss: -0.2275  Acc@1: 62.5000 (62.5692)  Acc@5: 93.7500 (90.4520)  time: 0.3507  data: 0.0011  max mem: 2500
Train: Epoch[3/5]  [ 280/4579]  eta: 0:25:09  Lr: 0.001875  Loss: -0.7076  Acc@1: 62.5000 (62.7224)  Acc@5: 87.5000 (90.5472)  time: 0.3500  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [ 290/4579]  eta: 0:25:06  Lr: 0.001875  Loss: -0.8086  Acc@1: 62.5000 (62.7148)  Acc@5: 93.7500 (90.5713)  time: 0.3504  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [ 300/4579]  eta: 0:25:02  Lr: 0.001875  Loss: -0.2821  Acc@1: 62.5000 (62.7699)  Acc@5: 93.7500 (90.5731)  time: 0.3505  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [ 310/4579]  eta: 0:24:58  Lr: 0.001875  Loss: -0.3252  Acc@1: 62.5000 (62.7814)  Acc@5: 93.7500 (90.6752)  time: 0.3487  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [ 320/4579]  eta: 0:24:55  Lr: 0.001875  Loss: -0.5870  Acc@1: 62.5000 (62.7726)  Acc@5: 93.7500 (90.6931)  time: 0.3501  data: 0.0012  max mem: 2500
Train: Epoch[3/5]  [ 330/4579]  eta: 0:24:51  Lr: 0.001875  Loss: -0.4837  Acc@1: 56.2500 (62.7455)  Acc@5: 93.7500 (90.7100)  time: 0.3513  data: 0.0018  max mem: 2500
Train: Epoch[3/5]  [ 340/4579]  eta: 0:24:48  Lr: 0.001875  Loss: 0.0483  Acc@1: 62.5000 (62.8116)  Acc@5: 93.7500 (90.6891)  time: 0.3501  data: 0.0011  max mem: 2500
Train: Epoch[3/5]  [ 350/4579]  eta: 0:24:44  Lr: 0.001875  Loss: -1.0480  Acc@1: 68.7500 (63.0520)  Acc@5: 93.7500 (90.7229)  time: 0.3501  data: 0.0009  max mem: 2500
Train: Epoch[3/5]  [ 360/4579]  eta: 0:24:40  Lr: 0.001875  Loss: -0.6219  Acc@1: 68.7500 (63.0194)  Acc@5: 93.7500 (90.7895)  time: 0.3501  data: 0.0016  max mem: 2500
Train: Epoch[3/5]  [ 370/4579]  eta: 0:24:37  Lr: 0.001875  Loss: -0.4419  Acc@1: 62.5000 (63.1233)  Acc@5: 93.7500 (90.8187)  time: 0.3496  data: 0.0017  max mem: 2500
Train: Epoch[3/5]  [ 380/4579]  eta: 0:24:33  Lr: 0.001875  Loss: -0.5294  Acc@1: 68.7500 (63.1890)  Acc@5: 87.5000 (90.8301)  time: 0.3484  data: 0.0010  max mem: 2500
Train: Epoch[3/5]  [ 390/4579]  eta: 0:24:29  Lr: 0.001875  Loss: -0.0103  Acc@1: 62.5000 (63.1873)  Acc@5: 87.5000 (90.8568)  time: 0.3472  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [ 400/4579]  eta: 0:24:25  Lr: 0.001875  Loss: -0.5775  Acc@1: 62.5000 (63.2170)  Acc@5: 93.7500 (90.8822)  time: 0.3480  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [ 410/4579]  eta: 0:24:21  Lr: 0.001875  Loss: -0.7273  Acc@1: 68.7500 (63.3820)  Acc@5: 93.7500 (90.9215)  time: 0.3479  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 420/4579]  eta: 0:24:18  Lr: 0.001875  Loss: 0.0403  Acc@1: 68.7500 (63.5095)  Acc@5: 93.7500 (90.8996)  time: 0.3484  data: 0.0013  max mem: 2500
Train: Epoch[3/5]  [ 430/4579]  eta: 0:24:14  Lr: 0.001875  Loss: 0.0042  Acc@1: 68.7500 (63.6021)  Acc@5: 93.7500 (90.9223)  time: 0.3495  data: 0.0013  max mem: 2500
Train: Epoch[3/5]  [ 440/4579]  eta: 0:24:10  Lr: 0.001875  Loss: -0.4636  Acc@1: 62.5000 (63.5488)  Acc@5: 93.7500 (90.9155)  time: 0.3489  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [ 450/4579]  eta: 0:24:07  Lr: 0.001875  Loss: -0.3101  Acc@1: 62.5000 (63.5394)  Acc@5: 93.7500 (90.9229)  time: 0.3483  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 460/4579]  eta: 0:24:03  Lr: 0.001875  Loss: -0.6576  Acc@1: 68.7500 (63.6659)  Acc@5: 93.7500 (90.9165)  time: 0.3474  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 470/4579]  eta: 0:23:59  Lr: 0.001875  Loss: -0.3470  Acc@1: 62.5000 (63.6943)  Acc@5: 93.7500 (90.9501)  time: 0.3476  data: 0.0012  max mem: 2500
Train: Epoch[3/5]  [ 480/4579]  eta: 0:23:55  Lr: 0.001875  Loss: -0.6571  Acc@1: 68.7500 (63.9033)  Acc@5: 93.7500 (91.0863)  time: 0.3479  data: 0.0012  max mem: 2500
Train: Epoch[3/5]  [ 490/4579]  eta: 0:23:52  Lr: 0.001875  Loss: -0.1153  Acc@1: 68.7500 (63.9257)  Acc@5: 93.7500 (91.1533)  time: 0.3481  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 500/4579]  eta: 0:23:48  Lr: 0.001875  Loss: -0.0587  Acc@1: 62.5000 (63.8598)  Acc@5: 93.7500 (91.1677)  time: 0.3492  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 510/4579]  eta: 0:23:44  Lr: 0.001875  Loss: -0.2714  Acc@1: 62.5000 (63.7231)  Acc@5: 93.7500 (91.1326)  time: 0.3489  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [ 520/4579]  eta: 0:23:41  Lr: 0.001875  Loss: -0.8683  Acc@1: 62.5000 (63.7596)  Acc@5: 87.5000 (91.1708)  time: 0.3497  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [ 530/4579]  eta: 0:23:37  Lr: 0.001875  Loss: -0.4912  Acc@1: 62.5000 (63.7594)  Acc@5: 87.5000 (91.1605)  time: 0.3493  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [ 540/4579]  eta: 0:23:34  Lr: 0.001875  Loss: -0.5679  Acc@1: 62.5000 (63.7708)  Acc@5: 87.5000 (91.0929)  time: 0.3499  data: 0.0013  max mem: 2500
Train: Epoch[3/5]  [ 550/4579]  eta: 0:23:30  Lr: 0.001875  Loss: -0.6373  Acc@1: 68.7500 (63.8271)  Acc@5: 87.5000 (91.0844)  time: 0.3513  data: 0.0023  max mem: 2500
Train: Epoch[3/5]  [ 560/4579]  eta: 0:23:27  Lr: 0.001875  Loss: -0.1780  Acc@1: 68.7500 (63.7589)  Acc@5: 93.7500 (91.1096)  time: 0.3495  data: 0.0014  max mem: 2500
Train: Epoch[3/5]  [ 570/4579]  eta: 0:23:23  Lr: 0.001875  Loss: -0.5221  Acc@1: 62.5000 (63.8025)  Acc@5: 93.7500 (91.1230)  time: 0.3497  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [ 580/4579]  eta: 0:23:20  Lr: 0.001875  Loss: -0.4454  Acc@1: 68.7500 (63.9307)  Acc@5: 93.7500 (91.1575)  time: 0.3492  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [ 590/4579]  eta: 0:23:16  Lr: 0.001875  Loss: -0.1484  Acc@1: 68.7500 (63.9277)  Acc@5: 93.7500 (91.1379)  time: 0.3477  data: 0.0009  max mem: 2500
Train: Epoch[3/5]  [ 600/4579]  eta: 0:23:12  Lr: 0.001875  Loss: -0.2107  Acc@1: 62.5000 (63.9455)  Acc@5: 93.7500 (91.1294)  time: 0.3478  data: 0.0009  max mem: 2500
Train: Epoch[3/5]  [ 610/4579]  eta: 0:23:09  Lr: 0.001875  Loss: -0.7961  Acc@1: 62.5000 (63.7786)  Acc@5: 93.7500 (91.0700)  time: 0.3499  data: 0.0025  max mem: 2500
Train: Epoch[3/5]  [ 620/4579]  eta: 0:23:05  Lr: 0.001875  Loss: -0.6780  Acc@1: 56.2500 (63.7480)  Acc@5: 93.7500 (91.1031)  time: 0.3503  data: 0.0025  max mem: 2500
Train: Epoch[3/5]  [ 630/4579]  eta: 0:23:02  Lr: 0.001875  Loss: -0.0450  Acc@1: 62.5000 (63.7282)  Acc@5: 93.7500 (91.1153)  time: 0.3480  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [ 640/4579]  eta: 0:22:58  Lr: 0.001875  Loss: -0.2112  Acc@1: 62.5000 (63.7188)  Acc@5: 93.7500 (91.1856)  time: 0.3472  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 650/4579]  eta: 0:22:55  Lr: 0.001875  Loss: -0.7316  Acc@1: 68.7500 (63.8633)  Acc@5: 93.7500 (91.2250)  time: 0.3480  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 660/4579]  eta: 0:22:51  Lr: 0.001875  Loss: -0.4930  Acc@1: 68.7500 (63.8427)  Acc@5: 93.7500 (91.1876)  time: 0.3484  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 670/4579]  eta: 0:22:47  Lr: 0.001875  Loss: -0.6804  Acc@1: 62.5000 (63.8320)  Acc@5: 87.5000 (91.1513)  time: 0.3478  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 680/4579]  eta: 0:22:44  Lr: 0.001875  Loss: -0.2225  Acc@1: 68.7500 (63.8308)  Acc@5: 93.7500 (91.1894)  time: 0.3491  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 690/4579]  eta: 0:22:40  Lr: 0.001875  Loss: -0.6129  Acc@1: 62.5000 (63.7391)  Acc@5: 93.7500 (91.1541)  time: 0.3490  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 700/4579]  eta: 0:22:37  Lr: 0.001875  Loss: -0.4341  Acc@1: 62.5000 (63.6947)  Acc@5: 87.5000 (91.1555)  time: 0.3478  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 710/4579]  eta: 0:22:33  Lr: 0.001875  Loss: 0.2714  Acc@1: 62.5000 (63.6515)  Acc@5: 87.5000 (91.0953)  time: 0.3490  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 720/4579]  eta: 0:22:29  Lr: 0.001875  Loss: -0.4562  Acc@1: 62.5000 (63.6529)  Acc@5: 93.7500 (91.1148)  time: 0.3488  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [ 730/4579]  eta: 0:22:26  Lr: 0.001875  Loss: -0.6606  Acc@1: 68.7500 (63.7055)  Acc@5: 93.7500 (91.1166)  time: 0.3492  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [ 740/4579]  eta: 0:22:22  Lr: 0.001875  Loss: 0.0825  Acc@1: 68.7500 (63.7146)  Acc@5: 93.7500 (91.0847)  time: 0.3499  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 750/4579]  eta: 0:22:19  Lr: 0.001875  Loss: -0.8260  Acc@1: 68.7500 (63.7650)  Acc@5: 93.7500 (91.1119)  time: 0.3492  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 760/4579]  eta: 0:22:15  Lr: 0.001875  Loss: -0.7014  Acc@1: 62.5000 (63.7319)  Acc@5: 87.5000 (91.0562)  time: 0.3492  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [ 770/4579]  eta: 0:22:12  Lr: 0.001875  Loss: -0.0914  Acc@1: 62.5000 (63.6511)  Acc@5: 93.7500 (91.0992)  time: 0.3496  data: 0.0015  max mem: 2500
Train: Epoch[3/5]  [ 780/4579]  eta: 0:22:08  Lr: 0.001875  Loss: -0.4794  Acc@1: 56.2500 (63.6124)  Acc@5: 93.7500 (91.0851)  time: 0.3502  data: 0.0014  max mem: 2500
Train: Epoch[3/5]  [ 790/4579]  eta: 0:22:05  Lr: 0.001875  Loss: -0.6488  Acc@1: 56.2500 (63.5430)  Acc@5: 93.7500 (91.0635)  time: 0.3489  data: 0.0009  max mem: 2500
Train: Epoch[3/5]  [ 800/4579]  eta: 0:22:01  Lr: 0.001875  Loss: -0.5787  Acc@1: 56.2500 (63.5456)  Acc@5: 87.5000 (91.0737)  time: 0.3485  data: 0.0009  max mem: 2500
Train: Epoch[3/5]  [ 810/4579]  eta: 0:21:58  Lr: 0.001875  Loss: -0.4474  Acc@1: 68.7500 (63.6174)  Acc@5: 93.7500 (91.1375)  time: 0.3493  data: 0.0013  max mem: 2500
Train: Epoch[3/5]  [ 820/4579]  eta: 0:21:54  Lr: 0.001875  Loss: -0.0934  Acc@1: 68.7500 (63.6343)  Acc@5: 93.7500 (91.1541)  time: 0.3497  data: 0.0013  max mem: 2500
Train: Epoch[3/5]  [ 830/4579]  eta: 0:21:51  Lr: 0.001875  Loss: -0.3678  Acc@1: 62.5000 (63.6432)  Acc@5: 93.7500 (91.1327)  time: 0.3490  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 840/4579]  eta: 0:21:47  Lr: 0.001875  Loss: -0.3194  Acc@1: 68.7500 (63.6965)  Acc@5: 87.5000 (91.1192)  time: 0.3478  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 850/4579]  eta: 0:21:44  Lr: 0.001875  Loss: -0.2687  Acc@1: 62.5000 (63.6384)  Acc@5: 87.5000 (91.1354)  time: 0.3471  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [ 860/4579]  eta: 0:21:40  Lr: 0.001875  Loss: -0.4388  Acc@1: 56.2500 (63.5961)  Acc@5: 93.7500 (91.1295)  time: 0.3473  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [ 870/4579]  eta: 0:21:36  Lr: 0.001875  Loss: -0.9731  Acc@1: 56.2500 (63.5333)  Acc@5: 93.7500 (91.1094)  time: 0.3480  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 880/4579]  eta: 0:21:33  Lr: 0.001875  Loss: -0.3976  Acc@1: 62.5000 (63.5145)  Acc@5: 87.5000 (91.0826)  time: 0.3480  data: 0.0009  max mem: 2500
Train: Epoch[3/5]  [ 890/4579]  eta: 0:21:29  Lr: 0.001875  Loss: -0.3547  Acc@1: 62.5000 (63.4820)  Acc@5: 93.7500 (91.1195)  time: 0.3479  data: 0.0009  max mem: 2500
Train: Epoch[3/5]  [ 900/4579]  eta: 0:21:26  Lr: 0.001875  Loss: -0.7749  Acc@1: 62.5000 (63.4226)  Acc@5: 93.7500 (91.0863)  time: 0.3485  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 910/4579]  eta: 0:21:22  Lr: 0.001875  Loss: -0.4885  Acc@1: 62.5000 (63.5154)  Acc@5: 87.5000 (91.0881)  time: 0.3497  data: 0.0012  max mem: 2500
Train: Epoch[3/5]  [ 920/4579]  eta: 0:21:19  Lr: 0.001875  Loss: -0.5473  Acc@1: 68.7500 (63.5315)  Acc@5: 87.5000 (91.0695)  time: 0.3498  data: 0.0019  max mem: 2500
Train: Epoch[3/5]  [ 930/4579]  eta: 0:21:15  Lr: 0.001875  Loss: -0.1119  Acc@1: 62.5000 (63.4801)  Acc@5: 93.7500 (91.0849)  time: 0.3505  data: 0.0020  max mem: 2500
Train: Epoch[3/5]  [ 940/4579]  eta: 0:21:12  Lr: 0.001875  Loss: -0.2087  Acc@1: 56.2500 (63.4365)  Acc@5: 87.5000 (91.0468)  time: 0.3508  data: 0.0012  max mem: 2500
Train: Epoch[3/5]  [ 950/4579]  eta: 0:21:08  Lr: 0.001875  Loss: 0.1586  Acc@1: 56.2500 (63.3938)  Acc@5: 87.5000 (91.0226)  time: 0.3493  data: 0.0009  max mem: 2500
Train: Epoch[3/5]  [ 960/4579]  eta: 0:21:05  Lr: 0.001875  Loss: -0.4429  Acc@1: 56.2500 (63.3910)  Acc@5: 87.5000 (91.0250)  time: 0.3485  data: 0.0010  max mem: 2500
Train: Epoch[3/5]  [ 970/4579]  eta: 0:21:01  Lr: 0.001875  Loss: 0.2706  Acc@1: 56.2500 (63.3625)  Acc@5: 93.7500 (91.0466)  time: 0.3498  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [ 980/4579]  eta: 0:20:58  Lr: 0.001875  Loss: -0.0797  Acc@1: 56.2500 (63.3346)  Acc@5: 93.7500 (91.0614)  time: 0.3502  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [ 990/4579]  eta: 0:20:54  Lr: 0.001875  Loss: -0.6948  Acc@1: 62.5000 (63.3956)  Acc@5: 93.7500 (91.0759)  time: 0.3491  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [1000/4579]  eta: 0:20:51  Lr: 0.001875  Loss: -0.5797  Acc@1: 68.7500 (63.3429)  Acc@5: 93.7500 (91.0465)  time: 0.3496  data: 0.0013  max mem: 2500
Train: Epoch[3/5]  [1010/4579]  eta: 0:20:47  Lr: 0.001875  Loss: 0.3737  Acc@1: 62.5000 (63.3222)  Acc@5: 93.7500 (91.0423)  time: 0.3508  data: 0.0020  max mem: 2500
Train: Epoch[3/5]  [1020/4579]  eta: 0:20:44  Lr: 0.001875  Loss: -0.1286  Acc@1: 62.5000 (63.3019)  Acc@5: 93.7500 (91.0688)  time: 0.3505  data: 0.0012  max mem: 2500
Train: Epoch[3/5]  [1030/4579]  eta: 0:20:40  Lr: 0.001875  Loss: -0.0620  Acc@1: 56.2500 (63.2517)  Acc@5: 93.7500 (91.0584)  time: 0.3495  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [1040/4579]  eta: 0:20:37  Lr: 0.001875  Loss: -0.6278  Acc@1: 62.5000 (63.3105)  Acc@5: 87.5000 (91.0423)  time: 0.3493  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1050/4579]  eta: 0:20:33  Lr: 0.001875  Loss: -0.2532  Acc@1: 62.5000 (63.2493)  Acc@5: 87.5000 (91.0502)  time: 0.3495  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1060/4579]  eta: 0:20:30  Lr: 0.001875  Loss: 0.3051  Acc@1: 62.5000 (63.2599)  Acc@5: 93.7500 (91.0933)  time: 0.3489  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1070/4579]  eta: 0:20:26  Lr: 0.001875  Loss: -0.3875  Acc@1: 62.5000 (63.2703)  Acc@5: 93.7500 (91.0889)  time: 0.3484  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [1080/4579]  eta: 0:20:23  Lr: 0.001875  Loss: -0.7951  Acc@1: 62.5000 (63.2921)  Acc@5: 93.7500 (91.0962)  time: 0.3489  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [1090/4579]  eta: 0:20:19  Lr: 0.001875  Loss: -0.7788  Acc@1: 62.5000 (63.2848)  Acc@5: 93.7500 (91.1033)  time: 0.3494  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [1100/4579]  eta: 0:20:16  Lr: 0.001875  Loss: 0.0838  Acc@1: 62.5000 (63.2380)  Acc@5: 87.5000 (91.0876)  time: 0.3506  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1110/4579]  eta: 0:20:12  Lr: 0.001875  Loss: -0.6113  Acc@1: 68.7500 (63.2876)  Acc@5: 93.7500 (91.1060)  time: 0.3517  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1120/4579]  eta: 0:20:09  Lr: 0.001875  Loss: -0.4407  Acc@1: 62.5000 (63.2360)  Acc@5: 93.7500 (91.1017)  time: 0.3511  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1130/4579]  eta: 0:20:05  Lr: 0.001875  Loss: -0.5475  Acc@1: 62.5000 (63.1963)  Acc@5: 93.7500 (91.0920)  time: 0.3501  data: 0.0009  max mem: 2500
Train: Epoch[3/5]  [1140/4579]  eta: 0:20:02  Lr: 0.001875  Loss: -0.1717  Acc@1: 62.5000 (63.2066)  Acc@5: 93.7500 (91.1098)  time: 0.3499  data: 0.0009  max mem: 2500
Train: Epoch[3/5]  [1150/4579]  eta: 0:19:58  Lr: 0.001875  Loss: -0.2572  Acc@1: 62.5000 (63.2168)  Acc@5: 93.7500 (91.0784)  time: 0.3498  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1160/4579]  eta: 0:19:55  Lr: 0.001875  Loss: -0.8004  Acc@1: 62.5000 (63.2106)  Acc@5: 93.7500 (91.0907)  time: 0.3493  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1170/4579]  eta: 0:19:51  Lr: 0.001875  Loss: -0.3273  Acc@1: 62.5000 (63.1939)  Acc@5: 93.7500 (91.0867)  time: 0.3495  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [1180/4579]  eta: 0:19:48  Lr: 0.001875  Loss: -0.5550  Acc@1: 62.5000 (63.1668)  Acc@5: 93.7500 (91.0775)  time: 0.3493  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [1190/4579]  eta: 0:19:44  Lr: 0.001875  Loss: -0.1874  Acc@1: 62.5000 (63.1507)  Acc@5: 93.7500 (91.0737)  time: 0.3493  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1200/4579]  eta: 0:19:41  Lr: 0.001875  Loss: -0.4063  Acc@1: 62.5000 (63.1765)  Acc@5: 93.7500 (91.0803)  time: 0.3492  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1210/4579]  eta: 0:19:37  Lr: 0.001875  Loss: -0.5455  Acc@1: 62.5000 (63.1555)  Acc@5: 93.7500 (91.0972)  time: 0.3487  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1220/4579]  eta: 0:19:34  Lr: 0.001875  Loss: -0.3651  Acc@1: 62.5000 (63.1757)  Acc@5: 93.7500 (91.0882)  time: 0.3487  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1230/4579]  eta: 0:19:30  Lr: 0.001875  Loss: -0.6390  Acc@1: 62.5000 (63.2210)  Acc@5: 93.7500 (91.1149)  time: 0.3487  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1240/4579]  eta: 0:19:27  Lr: 0.001875  Loss: -0.0172  Acc@1: 62.5000 (63.2000)  Acc@5: 93.7500 (91.0959)  time: 0.3500  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [1250/4579]  eta: 0:19:23  Lr: 0.001875  Loss: -0.4509  Acc@1: 62.5000 (63.2094)  Acc@5: 87.5000 (91.1071)  time: 0.3494  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [1260/4579]  eta: 0:19:20  Lr: 0.001875  Loss: -0.6632  Acc@1: 62.5000 (63.2236)  Acc@5: 93.7500 (91.1132)  time: 0.3486  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [1270/4579]  eta: 0:19:16  Lr: 0.001875  Loss: -0.2795  Acc@1: 62.5000 (63.2179)  Acc@5: 93.7500 (91.1044)  time: 0.3485  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [1280/4579]  eta: 0:19:13  Lr: 0.001875  Loss: -0.0818  Acc@1: 62.5000 (63.2075)  Acc@5: 93.7500 (91.1153)  time: 0.3483  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1290/4579]  eta: 0:19:09  Lr: 0.001875  Loss: -0.3018  Acc@1: 62.5000 (63.2262)  Acc@5: 93.7500 (91.1212)  time: 0.3497  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [1300/4579]  eta: 0:19:06  Lr: 0.001875  Loss: -0.6680  Acc@1: 62.5000 (63.2350)  Acc@5: 93.7500 (91.1318)  time: 0.3492  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1310/4579]  eta: 0:19:02  Lr: 0.001875  Loss: 0.0207  Acc@1: 62.5000 (63.2342)  Acc@5: 93.7500 (91.1280)  time: 0.3483  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1320/4579]  eta: 0:18:59  Lr: 0.001875  Loss: 0.2102  Acc@1: 56.2500 (63.2097)  Acc@5: 87.5000 (91.1100)  time: 0.3507  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1330/4579]  eta: 0:18:55  Lr: 0.001875  Loss: -0.5597  Acc@1: 56.2500 (63.1809)  Acc@5: 93.7500 (91.1251)  time: 0.3507  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1340/4579]  eta: 0:18:52  Lr: 0.001875  Loss: -0.8439  Acc@1: 62.5000 (63.2038)  Acc@5: 93.7500 (91.1447)  time: 0.3490  data: 0.0011  max mem: 2500
Train: Epoch[3/5]  [1350/4579]  eta: 0:18:48  Lr: 0.001875  Loss: -0.9107  Acc@1: 68.7500 (63.2494)  Acc@5: 93.7500 (91.1686)  time: 0.3498  data: 0.0011  max mem: 2500
Train: Epoch[3/5]  [1360/4579]  eta: 0:18:45  Lr: 0.001875  Loss: 0.2955  Acc@1: 62.5000 (63.2072)  Acc@5: 93.7500 (91.1508)  time: 0.3495  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [1370/4579]  eta: 0:18:41  Lr: 0.001875  Loss: -0.3948  Acc@1: 56.2500 (63.2203)  Acc@5: 93.7500 (91.1743)  time: 0.3488  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [1380/4579]  eta: 0:18:38  Lr: 0.001875  Loss: -0.5954  Acc@1: 62.5000 (63.2467)  Acc@5: 93.7500 (91.1613)  time: 0.3495  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1390/4579]  eta: 0:18:34  Lr: 0.001875  Loss: 0.0550  Acc@1: 62.5000 (63.1875)  Acc@5: 87.5000 (91.1529)  time: 0.3491  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [1400/4579]  eta: 0:18:31  Lr: 0.001875  Loss: 0.1372  Acc@1: 56.2500 (63.1558)  Acc@5: 87.5000 (91.1447)  time: 0.3497  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [1410/4579]  eta: 0:18:27  Lr: 0.001875  Loss: 0.4086  Acc@1: 62.5000 (63.1777)  Acc@5: 93.7500 (91.1499)  time: 0.3493  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1420/4579]  eta: 0:18:24  Lr: 0.001875  Loss: -0.6364  Acc@1: 75.0000 (63.2345)  Acc@5: 93.7500 (91.1682)  time: 0.3471  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1430/4579]  eta: 0:18:20  Lr: 0.001875  Loss: -0.2368  Acc@1: 68.7500 (63.2425)  Acc@5: 93.7500 (91.1644)  time: 0.3472  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1440/4579]  eta: 0:18:17  Lr: 0.001875  Loss: -0.2876  Acc@1: 68.7500 (63.2894)  Acc@5: 87.5000 (91.1563)  time: 0.3490  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1450/4579]  eta: 0:18:13  Lr: 0.001875  Loss: -0.4163  Acc@1: 62.5000 (63.2409)  Acc@5: 87.5000 (91.1182)  time: 0.3493  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1460/4579]  eta: 0:18:10  Lr: 0.001875  Loss: -0.4354  Acc@1: 56.2500 (63.2358)  Acc@5: 93.7500 (91.1490)  time: 0.3479  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1470/4579]  eta: 0:18:06  Lr: 0.001875  Loss: -0.6550  Acc@1: 62.5000 (63.2308)  Acc@5: 93.7500 (91.1285)  time: 0.3481  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1480/4579]  eta: 0:18:03  Lr: 0.001875  Loss: -0.2242  Acc@1: 62.5000 (63.2174)  Acc@5: 93.7500 (91.1166)  time: 0.3499  data: 0.0018  max mem: 2500
Train: Epoch[3/5]  [1490/4579]  eta: 0:17:59  Lr: 0.001875  Loss: -0.2655  Acc@1: 62.5000 (63.2252)  Acc@5: 87.5000 (91.0966)  time: 0.3495  data: 0.0018  max mem: 2500
Train: Epoch[3/5]  [1500/4579]  eta: 0:17:56  Lr: 0.001875  Loss: -0.7159  Acc@1: 62.5000 (63.2537)  Acc@5: 93.7500 (91.1143)  time: 0.3523  data: 0.0020  max mem: 2500
Train: Epoch[3/5]  [1510/4579]  eta: 0:17:53  Lr: 0.001875  Loss: -0.8141  Acc@1: 62.5000 (63.2735)  Acc@5: 93.7500 (91.1152)  time: 0.3599  data: 0.0019  max mem: 2500
Train: Epoch[3/5]  [1520/4579]  eta: 0:17:50  Lr: 0.001875  Loss: -0.5865  Acc@1: 62.5000 (63.2766)  Acc@5: 93.7500 (91.1407)  time: 0.3675  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [1530/4579]  eta: 0:17:47  Lr: 0.001875  Loss: 0.1268  Acc@1: 62.5000 (63.2797)  Acc@5: 93.7500 (91.1332)  time: 0.3793  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [1540/4579]  eta: 0:17:44  Lr: 0.001875  Loss: -0.3775  Acc@1: 68.7500 (63.3071)  Acc@5: 93.7500 (91.1583)  time: 0.3847  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [1550/4579]  eta: 0:17:41  Lr: 0.001875  Loss: -0.7466  Acc@1: 68.7500 (63.3059)  Acc@5: 93.7500 (91.1388)  time: 0.3817  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [1560/4579]  eta: 0:17:38  Lr: 0.001875  Loss: -0.1352  Acc@1: 62.5000 (63.3128)  Acc@5: 93.7500 (91.1515)  time: 0.3804  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [1570/4579]  eta: 0:17:35  Lr: 0.001875  Loss: -0.1698  Acc@1: 68.7500 (63.3315)  Acc@5: 93.7500 (91.1561)  time: 0.3784  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1580/4579]  eta: 0:17:32  Lr: 0.001875  Loss: 0.0544  Acc@1: 68.7500 (63.3262)  Acc@5: 93.7500 (91.1686)  time: 0.3786  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1590/4579]  eta: 0:17:30  Lr: 0.001875  Loss: -0.9470  Acc@1: 62.5000 (63.3603)  Acc@5: 93.7500 (91.1691)  time: 0.3897  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1600/4579]  eta: 0:17:27  Lr: 0.001875  Loss: -0.3897  Acc@1: 68.7500 (63.3979)  Acc@5: 93.7500 (91.1774)  time: 0.4002  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [1610/4579]  eta: 0:17:24  Lr: 0.001875  Loss: -0.7404  Acc@1: 68.7500 (63.4078)  Acc@5: 93.7500 (91.1856)  time: 0.4045  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [1620/4579]  eta: 0:17:22  Lr: 0.001875  Loss: -0.2412  Acc@1: 62.5000 (63.3637)  Acc@5: 93.7500 (91.1976)  time: 0.4062  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1630/4579]  eta: 0:17:19  Lr: 0.001875  Loss: -0.0874  Acc@1: 62.5000 (63.3660)  Acc@5: 93.7500 (91.2055)  time: 0.4045  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1640/4579]  eta: 0:17:17  Lr: 0.001875  Loss: -0.3030  Acc@1: 68.7500 (63.3912)  Acc@5: 93.7500 (91.2134)  time: 0.4027  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [1650/4579]  eta: 0:17:14  Lr: 0.001875  Loss: -0.6038  Acc@1: 68.7500 (63.4048)  Acc@5: 93.7500 (91.2250)  time: 0.4013  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [1660/4579]  eta: 0:17:11  Lr: 0.001875  Loss: 0.0446  Acc@1: 62.5000 (63.3617)  Acc@5: 93.7500 (91.2327)  time: 0.4014  data: 0.0011  max mem: 2500
Train: Epoch[3/5]  [1670/4579]  eta: 0:17:09  Lr: 0.001875  Loss: -0.0619  Acc@1: 62.5000 (63.3565)  Acc@5: 93.7500 (91.2291)  time: 0.4020  data: 0.0011  max mem: 2500
Train: Epoch[3/5]  [1680/4579]  eta: 0:17:06  Lr: 0.001875  Loss: -0.9785  Acc@1: 68.7500 (63.4184)  Acc@5: 93.7500 (91.2366)  time: 0.4025  data: 0.0018  max mem: 2500
Train: Epoch[3/5]  [1690/4579]  eta: 0:17:03  Lr: 0.001875  Loss: 0.1353  Acc@1: 62.5000 (63.3870)  Acc@5: 93.7500 (91.2330)  time: 0.4036  data: 0.0018  max mem: 2500
Train: Epoch[3/5]  [1700/4579]  eta: 0:17:01  Lr: 0.001875  Loss: -0.1581  Acc@1: 62.5000 (63.3782)  Acc@5: 93.7500 (91.2184)  time: 0.4039  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [1710/4579]  eta: 0:16:58  Lr: 0.001875  Loss: -0.8476  Acc@1: 62.5000 (63.3730)  Acc@5: 93.7500 (91.2113)  time: 0.4029  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [1720/4579]  eta: 0:16:55  Lr: 0.001875  Loss: -0.7717  Acc@1: 68.7500 (63.4079)  Acc@5: 93.7500 (91.2079)  time: 0.4017  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1730/4579]  eta: 0:16:52  Lr: 0.001875  Loss: -0.2907  Acc@1: 62.5000 (63.4099)  Acc@5: 93.7500 (91.2262)  time: 0.4029  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1740/4579]  eta: 0:16:50  Lr: 0.001875  Loss: -0.7773  Acc@1: 62.5000 (63.3867)  Acc@5: 93.7500 (91.2084)  time: 0.4051  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1750/4579]  eta: 0:16:47  Lr: 0.001875  Loss: 0.0394  Acc@1: 56.2500 (63.3709)  Acc@5: 93.7500 (91.2122)  time: 0.4059  data: 0.0018  max mem: 2500
Train: Epoch[3/5]  [1760/4579]  eta: 0:16:44  Lr: 0.001875  Loss: 0.0204  Acc@1: 62.5000 (63.3447)  Acc@5: 93.7500 (91.2088)  time: 0.4053  data: 0.0019  max mem: 2500
Train: Epoch[3/5]  [1770/4579]  eta: 0:16:41  Lr: 0.001875  Loss: -0.6529  Acc@1: 62.5000 (63.3611)  Acc@5: 93.7500 (91.2091)  time: 0.3980  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [1780/4579]  eta: 0:16:37  Lr: 0.001875  Loss: -0.6503  Acc@1: 62.5000 (63.3282)  Acc@5: 93.7500 (91.2093)  time: 0.3700  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [1790/4579]  eta: 0:16:34  Lr: 0.001875  Loss: -0.6074  Acc@1: 68.7500 (63.3585)  Acc@5: 93.7500 (91.2130)  time: 0.3481  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1800/4579]  eta: 0:16:30  Lr: 0.001875  Loss: -0.5940  Acc@1: 62.5000 (63.3502)  Acc@5: 93.7500 (91.2097)  time: 0.3473  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1810/4579]  eta: 0:16:26  Lr: 0.001875  Loss: -0.4373  Acc@1: 56.2500 (63.3076)  Acc@5: 93.7500 (91.2100)  time: 0.3486  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1820/4579]  eta: 0:16:23  Lr: 0.001875  Loss: -0.3038  Acc@1: 62.5000 (63.3066)  Acc@5: 87.5000 (91.1965)  time: 0.3496  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1830/4579]  eta: 0:16:19  Lr: 0.001875  Loss: 0.1739  Acc@1: 62.5000 (63.2817)  Acc@5: 87.5000 (91.1865)  time: 0.3482  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1840/4579]  eta: 0:16:15  Lr: 0.001875  Loss: -0.4196  Acc@1: 62.5000 (63.2944)  Acc@5: 93.7500 (91.2106)  time: 0.3478  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [1850/4579]  eta: 0:16:12  Lr: 0.001875  Loss: -0.3145  Acc@1: 62.5000 (63.2732)  Acc@5: 93.7500 (91.1872)  time: 0.3488  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [1860/4579]  eta: 0:16:08  Lr: 0.001875  Loss: -0.4793  Acc@1: 62.5000 (63.2926)  Acc@5: 87.5000 (91.1842)  time: 0.3493  data: 0.0012  max mem: 2500
Train: Epoch[3/5]  [1870/4579]  eta: 0:16:04  Lr: 0.001875  Loss: -0.4980  Acc@1: 68.7500 (63.2716)  Acc@5: 93.7500 (91.1912)  time: 0.3495  data: 0.0013  max mem: 2500
Train: Epoch[3/5]  [1880/4579]  eta: 0:16:01  Lr: 0.001875  Loss: -0.0120  Acc@1: 62.5000 (63.2808)  Acc@5: 87.5000 (91.1749)  time: 0.3483  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [1890/4579]  eta: 0:15:57  Lr: 0.001875  Loss: 0.0093  Acc@1: 62.5000 (63.2635)  Acc@5: 87.5000 (91.1621)  time: 0.3473  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1900/4579]  eta: 0:15:53  Lr: 0.001875  Loss: -0.7517  Acc@1: 62.5000 (63.2759)  Acc@5: 87.5000 (91.1625)  time: 0.3483  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1910/4579]  eta: 0:15:50  Lr: 0.001875  Loss: -0.4433  Acc@1: 62.5000 (63.3013)  Acc@5: 93.7500 (91.1663)  time: 0.3488  data: 0.0014  max mem: 2500
Train: Epoch[3/5]  [1920/4579]  eta: 0:15:46  Lr: 0.001875  Loss: -0.6423  Acc@1: 68.7500 (63.3199)  Acc@5: 93.7500 (91.1602)  time: 0.3488  data: 0.0022  max mem: 2500
Train: Epoch[3/5]  [1930/4579]  eta: 0:15:42  Lr: 0.001875  Loss: -0.5674  Acc@1: 62.5000 (63.3286)  Acc@5: 87.5000 (91.1607)  time: 0.3488  data: 0.0012  max mem: 2500
Train: Epoch[3/5]  [1940/4579]  eta: 0:15:39  Lr: 0.001875  Loss: -0.3334  Acc@1: 56.2500 (63.2921)  Acc@5: 93.7500 (91.1772)  time: 0.3540  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1950/4579]  eta: 0:15:35  Lr: 0.001875  Loss: -0.4183  Acc@1: 68.7500 (63.3393)  Acc@5: 93.7500 (91.1936)  time: 0.3639  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1960/4579]  eta: 0:15:32  Lr: 0.001875  Loss: -0.4728  Acc@1: 68.7500 (63.3032)  Acc@5: 93.7500 (91.1875)  time: 0.3752  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1970/4579]  eta: 0:15:29  Lr: 0.001875  Loss: -0.9168  Acc@1: 62.5000 (63.3086)  Acc@5: 87.5000 (91.1847)  time: 0.3863  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1980/4579]  eta: 0:15:26  Lr: 0.001875  Loss: -0.0441  Acc@1: 62.5000 (63.2982)  Acc@5: 87.5000 (91.1629)  time: 0.3871  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1990/4579]  eta: 0:15:22  Lr: 0.001875  Loss: -0.8329  Acc@1: 62.5000 (63.3162)  Acc@5: 87.5000 (91.1539)  time: 0.3733  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [2000/4579]  eta: 0:15:19  Lr: 0.001875  Loss: -0.4770  Acc@1: 62.5000 (63.3308)  Acc@5: 93.7500 (91.1482)  time: 0.3556  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [2010/4579]  eta: 0:15:15  Lr: 0.001875  Loss: -0.1980  Acc@1: 56.2500 (63.3143)  Acc@5: 93.7500 (91.1518)  time: 0.3479  data: 0.0009  max mem: 2500
Train: Epoch[3/5]  [2020/4579]  eta: 0:15:11  Lr: 0.001875  Loss: -0.6399  Acc@1: 56.2500 (63.3071)  Acc@5: 93.7500 (91.1585)  time: 0.3487  data: 0.0009  max mem: 2500
Train: Epoch[3/5]  [2030/4579]  eta: 0:15:08  Lr: 0.001875  Loss: 0.2131  Acc@1: 56.2500 (63.3001)  Acc@5: 87.5000 (91.1343)  time: 0.3484  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2040/4579]  eta: 0:15:04  Lr: 0.001875  Loss: -0.7641  Acc@1: 62.5000 (63.3054)  Acc@5: 87.5000 (91.1318)  time: 0.3478  data: 0.0011  max mem: 2500
Train: Epoch[3/5]  [2050/4579]  eta: 0:15:00  Lr: 0.001875  Loss: -0.4582  Acc@1: 62.5000 (63.2892)  Acc@5: 87.5000 (91.1141)  time: 0.3482  data: 0.0011  max mem: 2500
Train: Epoch[3/5]  [2060/4579]  eta: 0:14:57  Lr: 0.001875  Loss: -0.4063  Acc@1: 62.5000 (63.3248)  Acc@5: 93.7500 (91.1238)  time: 0.3489  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2070/4579]  eta: 0:14:53  Lr: 0.001875  Loss: -0.2749  Acc@1: 62.5000 (63.3269)  Acc@5: 93.7500 (91.1245)  time: 0.3494  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2080/4579]  eta: 0:14:49  Lr: 0.001875  Loss: -0.4439  Acc@1: 62.5000 (63.3349)  Acc@5: 93.7500 (91.1251)  time: 0.3483  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2090/4579]  eta: 0:14:46  Lr: 0.001875  Loss: -0.6698  Acc@1: 62.5000 (63.3220)  Acc@5: 87.5000 (91.1197)  time: 0.3469  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2100/4579]  eta: 0:14:42  Lr: 0.001875  Loss: -0.5535  Acc@1: 68.7500 (63.3627)  Acc@5: 93.7500 (91.1352)  time: 0.3477  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2110/4579]  eta: 0:14:38  Lr: 0.001875  Loss: -0.6094  Acc@1: 68.7500 (63.3971)  Acc@5: 93.7500 (91.1357)  time: 0.3481  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2120/4579]  eta: 0:14:35  Lr: 0.001875  Loss: -0.2162  Acc@1: 68.7500 (63.3958)  Acc@5: 93.7500 (91.1510)  time: 0.3474  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2130/4579]  eta: 0:14:31  Lr: 0.001875  Loss: -0.4354  Acc@1: 62.5000 (63.3857)  Acc@5: 93.7500 (91.1573)  time: 0.3486  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [2140/4579]  eta: 0:14:27  Lr: 0.001875  Loss: -0.3259  Acc@1: 62.5000 (63.3991)  Acc@5: 93.7500 (91.1578)  time: 0.3490  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [2150/4579]  eta: 0:14:24  Lr: 0.001875  Loss: -0.3594  Acc@1: 62.5000 (63.4066)  Acc@5: 93.7500 (91.1785)  time: 0.3482  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2160/4579]  eta: 0:14:20  Lr: 0.001875  Loss: -0.3269  Acc@1: 68.7500 (63.4486)  Acc@5: 93.7500 (91.1962)  time: 0.3483  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2170/4579]  eta: 0:14:17  Lr: 0.001875  Loss: -0.1561  Acc@1: 68.7500 (63.4471)  Acc@5: 93.7500 (91.1763)  time: 0.3484  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2180/4579]  eta: 0:14:13  Lr: 0.001875  Loss: 0.1206  Acc@1: 62.5000 (63.4227)  Acc@5: 87.5000 (91.1709)  time: 0.3479  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2190/4579]  eta: 0:14:09  Lr: 0.001875  Loss: -0.3560  Acc@1: 62.5000 (63.4385)  Acc@5: 93.7500 (91.1684)  time: 0.3480  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2200/4579]  eta: 0:14:06  Lr: 0.001875  Loss: -0.8303  Acc@1: 62.5000 (63.4314)  Acc@5: 93.7500 (91.1716)  time: 0.3487  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [2210/4579]  eta: 0:14:02  Lr: 0.001875  Loss: -0.5476  Acc@1: 62.5000 (63.4385)  Acc@5: 93.7500 (91.1889)  time: 0.3481  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2220/4579]  eta: 0:13:58  Lr: 0.001875  Loss: -0.7276  Acc@1: 62.5000 (63.4174)  Acc@5: 93.7500 (91.1836)  time: 0.3477  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2230/4579]  eta: 0:13:55  Lr: 0.001875  Loss: -0.6671  Acc@1: 62.5000 (63.4189)  Acc@5: 87.5000 (91.1727)  time: 0.3487  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2240/4579]  eta: 0:13:51  Lr: 0.001875  Loss: -0.2861  Acc@1: 62.5000 (63.4036)  Acc@5: 87.5000 (91.1647)  time: 0.3501  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2250/4579]  eta: 0:13:47  Lr: 0.001875  Loss: -0.6030  Acc@1: 62.5000 (63.4163)  Acc@5: 87.5000 (91.1650)  time: 0.3493  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2260/4579]  eta: 0:13:44  Lr: 0.001875  Loss: -0.2742  Acc@1: 68.7500 (63.4094)  Acc@5: 93.7500 (91.1682)  time: 0.3501  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2270/4579]  eta: 0:13:40  Lr: 0.001875  Loss: -0.1354  Acc@1: 56.2500 (63.3944)  Acc@5: 93.7500 (91.1658)  time: 0.3508  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2280/4579]  eta: 0:13:37  Lr: 0.001875  Loss: -0.0769  Acc@1: 56.2500 (63.3795)  Acc@5: 93.7500 (91.1826)  time: 0.3483  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [2290/4579]  eta: 0:13:33  Lr: 0.001875  Loss: 0.1273  Acc@1: 56.2500 (63.3539)  Acc@5: 93.7500 (91.1692)  time: 0.3480  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [2300/4579]  eta: 0:13:29  Lr: 0.001875  Loss: -0.3733  Acc@1: 56.2500 (63.3420)  Acc@5: 87.5000 (91.1669)  time: 0.3483  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [2310/4579]  eta: 0:13:26  Lr: 0.001875  Loss: -0.6870  Acc@1: 62.5000 (63.3465)  Acc@5: 93.7500 (91.1699)  time: 0.3483  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [2320/4579]  eta: 0:13:22  Lr: 0.001875  Loss: -0.7891  Acc@1: 68.7500 (63.3967)  Acc@5: 93.7500 (91.1864)  time: 0.3493  data: 0.0014  max mem: 2500
Train: Epoch[3/5]  [2330/4579]  eta: 0:13:19  Lr: 0.001875  Loss: -0.0662  Acc@1: 68.7500 (63.4009)  Acc@5: 93.7500 (91.1760)  time: 0.3491  data: 0.0013  max mem: 2500
Train: Epoch[3/5]  [2340/4579]  eta: 0:13:15  Lr: 0.001875  Loss: -0.3683  Acc@1: 62.5000 (63.4184)  Acc@5: 93.7500 (91.1897)  time: 0.3480  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2350/4579]  eta: 0:13:11  Lr: 0.001875  Loss: -0.8340  Acc@1: 68.7500 (63.4331)  Acc@5: 93.7500 (91.1979)  time: 0.3479  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2360/4579]  eta: 0:13:08  Lr: 0.001875  Loss: -0.4741  Acc@1: 68.7500 (63.4503)  Acc@5: 93.7500 (91.2034)  time: 0.3485  data: 0.0009  max mem: 2500
Train: Epoch[3/5]  [2370/4579]  eta: 0:13:04  Lr: 0.001875  Loss: -0.4779  Acc@1: 68.7500 (63.4648)  Acc@5: 93.7500 (91.2115)  time: 0.3481  data: 0.0009  max mem: 2500
Train: Epoch[3/5]  [2380/4579]  eta: 0:13:00  Lr: 0.001875  Loss: -0.4275  Acc@1: 62.5000 (63.4581)  Acc@5: 93.7500 (91.2222)  time: 0.3476  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2390/4579]  eta: 0:12:57  Lr: 0.001875  Loss: -0.6875  Acc@1: 62.5000 (63.4593)  Acc@5: 93.7500 (91.2223)  time: 0.3487  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2400/4579]  eta: 0:12:53  Lr: 0.001875  Loss: -0.4911  Acc@1: 62.5000 (63.4605)  Acc@5: 87.5000 (91.2172)  time: 0.3488  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2410/4579]  eta: 0:12:50  Lr: 0.001875  Loss: -0.3982  Acc@1: 62.5000 (63.4566)  Acc@5: 93.7500 (91.2225)  time: 0.3492  data: 0.0011  max mem: 2500
Train: Epoch[3/5]  [2420/4579]  eta: 0:12:46  Lr: 0.001875  Loss: -0.4246  Acc@1: 62.5000 (63.4681)  Acc@5: 93.7500 (91.2278)  time: 0.3505  data: 0.0011  max mem: 2500
Train: Epoch[3/5]  [2430/4579]  eta: 0:12:42  Lr: 0.001875  Loss: -0.1849  Acc@1: 62.5000 (63.4693)  Acc@5: 93.7500 (91.2356)  time: 0.3501  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2440/4579]  eta: 0:12:39  Lr: 0.001875  Loss: -0.4555  Acc@1: 62.5000 (63.4678)  Acc@5: 93.7500 (91.2280)  time: 0.3498  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2450/4579]  eta: 0:12:35  Lr: 0.001875  Loss: -0.3805  Acc@1: 62.5000 (63.4664)  Acc@5: 87.5000 (91.2153)  time: 0.3492  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2460/4579]  eta: 0:12:32  Lr: 0.001875  Loss: 0.3374  Acc@1: 62.5000 (63.4625)  Acc@5: 87.5000 (91.2028)  time: 0.3480  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2470/4579]  eta: 0:12:28  Lr: 0.001875  Loss: -0.4907  Acc@1: 62.5000 (63.4637)  Acc@5: 93.7500 (91.2207)  time: 0.3481  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2480/4579]  eta: 0:12:24  Lr: 0.001875  Loss: -0.4184  Acc@1: 62.5000 (63.4472)  Acc@5: 93.7500 (91.2082)  time: 0.3490  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2490/4579]  eta: 0:12:21  Lr: 0.001875  Loss: -0.5689  Acc@1: 62.5000 (63.4484)  Acc@5: 93.7500 (91.2134)  time: 0.3501  data: 0.0012  max mem: 2500
Train: Epoch[3/5]  [2500/4579]  eta: 0:12:17  Lr: 0.001875  Loss: -0.0032  Acc@1: 68.7500 (63.4421)  Acc@5: 93.7500 (91.2185)  time: 0.3497  data: 0.0012  max mem: 2500
Train: Epoch[3/5]  [2510/4579]  eta: 0:12:14  Lr: 0.001875  Loss: -0.6879  Acc@1: 68.7500 (63.4508)  Acc@5: 93.7500 (91.2236)  time: 0.3483  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [2520/4579]  eta: 0:12:10  Lr: 0.001875  Loss: -0.2546  Acc@1: 68.7500 (63.4941)  Acc@5: 93.7500 (91.2436)  time: 0.3484  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2530/4579]  eta: 0:12:06  Lr: 0.001875  Loss: -0.7834  Acc@1: 68.7500 (63.4828)  Acc@5: 100.0000 (91.2707)  time: 0.3491  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2540/4579]  eta: 0:12:03  Lr: 0.001875  Loss: -0.3590  Acc@1: 62.5000 (63.4962)  Acc@5: 93.7500 (91.2682)  time: 0.3490  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2550/4579]  eta: 0:11:59  Lr: 0.001875  Loss: -0.4155  Acc@1: 68.7500 (63.4996)  Acc@5: 93.7500 (91.2681)  time: 0.3490  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2560/4579]  eta: 0:11:56  Lr: 0.001875  Loss: -0.6310  Acc@1: 62.5000 (63.4859)  Acc@5: 93.7500 (91.2632)  time: 0.3493  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2570/4579]  eta: 0:11:52  Lr: 0.001875  Loss: 0.5211  Acc@1: 62.5000 (63.4918)  Acc@5: 87.5000 (91.2607)  time: 0.3500  data: 0.0014  max mem: 2500
Train: Epoch[3/5]  [2580/4579]  eta: 0:11:48  Lr: 0.001875  Loss: -0.3751  Acc@1: 62.5000 (63.4953)  Acc@5: 93.7500 (91.2655)  time: 0.3498  data: 0.0014  max mem: 2500
Train: Epoch[3/5]  [2590/4579]  eta: 0:11:45  Lr: 0.001875  Loss: -0.1314  Acc@1: 68.7500 (63.5035)  Acc@5: 93.7500 (91.2775)  time: 0.3489  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2600/4579]  eta: 0:11:41  Lr: 0.001875  Loss: -0.4479  Acc@1: 68.7500 (63.5068)  Acc@5: 93.7500 (91.2942)  time: 0.3492  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2610/4579]  eta: 0:11:38  Lr: 0.001875  Loss: -0.2042  Acc@1: 62.5000 (63.5125)  Acc@5: 93.7500 (91.2893)  time: 0.3535  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [2620/4579]  eta: 0:11:34  Lr: 0.001875  Loss: -0.4620  Acc@1: 62.5000 (63.5087)  Acc@5: 87.5000 (91.2963)  time: 0.3628  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [2630/4579]  eta: 0:11:31  Lr: 0.001875  Loss: -0.1170  Acc@1: 62.5000 (63.5048)  Acc@5: 93.7500 (91.3056)  time: 0.3794  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [2640/4579]  eta: 0:11:28  Lr: 0.001875  Loss: -0.4024  Acc@1: 62.5000 (63.5034)  Acc@5: 93.7500 (91.3030)  time: 0.3921  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [2650/4579]  eta: 0:11:24  Lr: 0.001875  Loss: -0.3721  Acc@1: 56.2500 (63.4690)  Acc@5: 87.5000 (91.2957)  time: 0.3907  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2660/4579]  eta: 0:11:21  Lr: 0.001875  Loss: -0.6488  Acc@1: 56.2500 (63.4818)  Acc@5: 87.5000 (91.2932)  time: 0.3844  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2670/4579]  eta: 0:11:18  Lr: 0.001875  Loss: -1.1126  Acc@1: 62.5000 (63.5062)  Acc@5: 93.7500 (91.3024)  time: 0.3821  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [2680/4579]  eta: 0:11:14  Lr: 0.001875  Loss: 0.0572  Acc@1: 62.5000 (63.4954)  Acc@5: 93.7500 (91.2929)  time: 0.3841  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [2690/4579]  eta: 0:11:11  Lr: 0.001875  Loss: -0.4206  Acc@1: 62.5000 (63.5103)  Acc@5: 93.7500 (91.2997)  time: 0.3831  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [2700/4579]  eta: 0:11:08  Lr: 0.001875  Loss: 0.0214  Acc@1: 62.5000 (63.4927)  Acc@5: 93.7500 (91.2949)  time: 0.3813  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [2710/4579]  eta: 0:11:04  Lr: 0.001875  Loss: -0.4535  Acc@1: 62.5000 (63.4890)  Acc@5: 93.7500 (91.2993)  time: 0.3817  data: 0.0011  max mem: 2500
Train: Epoch[3/5]  [2720/4579]  eta: 0:11:01  Lr: 0.001875  Loss: -0.7173  Acc@1: 62.5000 (63.4923)  Acc@5: 93.7500 (91.3037)  time: 0.3814  data: 0.0011  max mem: 2500
Train: Epoch[3/5]  [2730/4579]  eta: 0:10:58  Lr: 0.001875  Loss: -0.1640  Acc@1: 62.5000 (63.4978)  Acc@5: 87.5000 (91.2921)  time: 0.3824  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2740/4579]  eta: 0:10:54  Lr: 0.001875  Loss: -0.4859  Acc@1: 62.5000 (63.4942)  Acc@5: 93.7500 (91.3034)  time: 0.3851  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2750/4579]  eta: 0:10:51  Lr: 0.001875  Loss: -0.2850  Acc@1: 62.5000 (63.4837)  Acc@5: 93.7500 (91.2895)  time: 0.3888  data: 0.0011  max mem: 2500
Train: Epoch[3/5]  [2760/4579]  eta: 0:10:48  Lr: 0.001875  Loss: -0.0068  Acc@1: 62.5000 (63.4870)  Acc@5: 93.7500 (91.2984)  time: 0.3978  data: 0.0010  max mem: 2500
Train: Epoch[3/5]  [2770/4579]  eta: 0:10:44  Lr: 0.001875  Loss: -0.3575  Acc@1: 68.7500 (63.5127)  Acc@5: 93.7500 (91.2915)  time: 0.4056  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [2780/4579]  eta: 0:10:41  Lr: 0.001875  Loss: -0.5308  Acc@1: 62.5000 (63.5113)  Acc@5: 93.7500 (91.2914)  time: 0.4053  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [2790/4579]  eta: 0:10:38  Lr: 0.001875  Loss: -0.4633  Acc@1: 62.5000 (63.5099)  Acc@5: 93.7500 (91.2934)  time: 0.4057  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2800/4579]  eta: 0:10:35  Lr: 0.001875  Loss: -0.3456  Acc@1: 62.5000 (63.5175)  Acc@5: 93.7500 (91.2888)  time: 0.4069  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2810/4579]  eta: 0:10:31  Lr: 0.001875  Loss: -0.5041  Acc@1: 56.2500 (63.4872)  Acc@5: 87.5000 (91.2820)  time: 0.4061  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [2820/4579]  eta: 0:10:28  Lr: 0.001875  Loss: -0.4153  Acc@1: 56.2500 (63.4793)  Acc@5: 87.5000 (91.2863)  time: 0.4071  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [2830/4579]  eta: 0:10:25  Lr: 0.001875  Loss: -0.2258  Acc@1: 62.5000 (63.4736)  Acc@5: 93.7500 (91.2840)  time: 0.4062  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [2840/4579]  eta: 0:10:22  Lr: 0.001875  Loss: -0.7516  Acc@1: 62.5000 (63.4878)  Acc@5: 93.7500 (91.2905)  time: 0.4051  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [2850/4579]  eta: 0:10:18  Lr: 0.001875  Loss: -0.2369  Acc@1: 62.5000 (63.4909)  Acc@5: 93.7500 (91.2925)  time: 0.4059  data: 0.0009  max mem: 2500
Train: Epoch[3/5]  [2860/4579]  eta: 0:10:15  Lr: 0.001875  Loss: 0.2001  Acc@1: 62.5000 (63.4830)  Acc@5: 93.7500 (91.2967)  time: 0.4059  data: 0.0013  max mem: 2500
Train: Epoch[3/5]  [2870/4579]  eta: 0:10:12  Lr: 0.001875  Loss: -0.4521  Acc@1: 62.5000 (63.4774)  Acc@5: 93.7500 (91.2748)  time: 0.4068  data: 0.0010  max mem: 2500
Train: Epoch[3/5]  [2880/4579]  eta: 0:10:08  Lr: 0.001875  Loss: -0.5942  Acc@1: 56.2500 (63.4567)  Acc@5: 87.5000 (91.2747)  time: 0.4071  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [2890/4579]  eta: 0:10:05  Lr: 0.001875  Loss: -0.5516  Acc@1: 56.2500 (63.4447)  Acc@5: 93.7500 (91.2768)  time: 0.4051  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [2900/4579]  eta: 0:10:02  Lr: 0.001875  Loss: -0.6262  Acc@1: 68.7500 (63.4803)  Acc@5: 93.7500 (91.2789)  time: 0.4043  data: 0.0016  max mem: 2500
Train: Epoch[3/5]  [2910/4579]  eta: 0:09:58  Lr: 0.001875  Loss: -0.2049  Acc@1: 68.7500 (63.4726)  Acc@5: 87.5000 (91.2723)  time: 0.4039  data: 0.0013  max mem: 2500
Train: Epoch[3/5]  [2920/4579]  eta: 0:09:55  Lr: 0.001875  Loss: -0.5911  Acc@1: 62.5000 (63.4650)  Acc@5: 93.7500 (91.2723)  time: 0.4046  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2930/4579]  eta: 0:09:52  Lr: 0.001875  Loss: -0.1805  Acc@1: 68.7500 (63.5001)  Acc@5: 93.7500 (91.2828)  time: 0.4059  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2940/4579]  eta: 0:09:48  Lr: 0.001875  Loss: -0.7116  Acc@1: 68.7500 (63.5031)  Acc@5: 93.7500 (91.2870)  time: 0.4058  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [2950/4579]  eta: 0:09:45  Lr: 0.001875  Loss: -0.1723  Acc@1: 68.7500 (63.5166)  Acc@5: 87.5000 (91.2784)  time: 0.4055  data: 0.0010  max mem: 2500
Train: Epoch[3/5]  [2960/4579]  eta: 0:09:42  Lr: 0.001875  Loss: 0.4403  Acc@1: 62.5000 (63.5174)  Acc@5: 87.5000 (91.2698)  time: 0.4058  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [2970/4579]  eta: 0:09:38  Lr: 0.001875  Loss: -0.4445  Acc@1: 68.7500 (63.5371)  Acc@5: 93.7500 (91.2782)  time: 0.4065  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2980/4579]  eta: 0:09:35  Lr: 0.001875  Loss: -0.4438  Acc@1: 62.5000 (63.5357)  Acc@5: 93.7500 (91.2718)  time: 0.4070  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2990/4579]  eta: 0:09:32  Lr: 0.001875  Loss: -1.0712  Acc@1: 62.5000 (63.5448)  Acc@5: 93.7500 (91.2780)  time: 0.4038  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3000/4579]  eta: 0:09:28  Lr: 0.001875  Loss: 0.1759  Acc@1: 62.5000 (63.5517)  Acc@5: 93.7500 (91.2800)  time: 0.4037  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [3010/4579]  eta: 0:09:25  Lr: 0.001875  Loss: -0.3279  Acc@1: 68.7500 (63.5607)  Acc@5: 87.5000 (91.2695)  time: 0.4068  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [3020/4579]  eta: 0:09:22  Lr: 0.001875  Loss: -0.8034  Acc@1: 68.7500 (63.5510)  Acc@5: 87.5000 (91.2715)  time: 0.4081  data: 0.0013  max mem: 2500
Train: Epoch[3/5]  [3030/4579]  eta: 0:09:18  Lr: 0.001875  Loss: -0.5146  Acc@1: 62.5000 (63.5496)  Acc@5: 93.7500 (91.2694)  time: 0.4082  data: 0.0012  max mem: 2500
Train: Epoch[3/5]  [3040/4579]  eta: 0:09:15  Lr: 0.001875  Loss: -0.4367  Acc@1: 62.5000 (63.5667)  Acc@5: 93.7500 (91.2837)  time: 0.4072  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [3050/4579]  eta: 0:09:12  Lr: 0.001875  Loss: -0.6121  Acc@1: 68.7500 (63.5570)  Acc@5: 93.7500 (91.2652)  time: 0.4068  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [3060/4579]  eta: 0:09:08  Lr: 0.001875  Loss: 0.4974  Acc@1: 56.2500 (63.5311)  Acc@5: 87.5000 (91.2590)  time: 0.4063  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3070/4579]  eta: 0:09:05  Lr: 0.001875  Loss: 0.1700  Acc@1: 56.2500 (63.5298)  Acc@5: 93.7500 (91.2630)  time: 0.4072  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3080/4579]  eta: 0:09:01  Lr: 0.001875  Loss: -0.2809  Acc@1: 62.5000 (63.5285)  Acc@5: 93.7500 (91.2670)  time: 0.4069  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3090/4579]  eta: 0:08:58  Lr: 0.001875  Loss: -0.7416  Acc@1: 62.5000 (63.5191)  Acc@5: 87.5000 (91.2549)  time: 0.4066  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3100/4579]  eta: 0:08:55  Lr: 0.001875  Loss: 0.0060  Acc@1: 62.5000 (63.5178)  Acc@5: 87.5000 (91.2548)  time: 0.4058  data: 0.0012  max mem: 2500
Train: Epoch[3/5]  [3110/4579]  eta: 0:08:51  Lr: 0.001875  Loss: -0.1650  Acc@1: 62.5000 (63.5246)  Acc@5: 93.7500 (91.2548)  time: 0.4057  data: 0.0013  max mem: 2500
Train: Epoch[3/5]  [3120/4579]  eta: 0:08:48  Lr: 0.001875  Loss: -0.0584  Acc@1: 68.7500 (63.5133)  Acc@5: 87.5000 (91.2468)  time: 0.4066  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [3130/4579]  eta: 0:08:44  Lr: 0.001875  Loss: 0.0381  Acc@1: 68.7500 (63.5101)  Acc@5: 87.5000 (91.2428)  time: 0.4069  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [3140/4579]  eta: 0:08:41  Lr: 0.001875  Loss: -0.6169  Acc@1: 68.7500 (63.5248)  Acc@5: 93.7500 (91.2428)  time: 0.4068  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3150/4579]  eta: 0:08:37  Lr: 0.001875  Loss: -0.3449  Acc@1: 62.5000 (63.5255)  Acc@5: 87.5000 (91.2349)  time: 0.4071  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3160/4579]  eta: 0:08:34  Lr: 0.001875  Loss: -0.0388  Acc@1: 62.5000 (63.5064)  Acc@5: 87.5000 (91.2271)  time: 0.4080  data: 0.0013  max mem: 2500
Train: Epoch[3/5]  [3170/4579]  eta: 0:08:31  Lr: 0.001875  Loss: -0.5116  Acc@1: 56.2500 (63.4855)  Acc@5: 93.7500 (91.2291)  time: 0.4076  data: 0.0014  max mem: 2500
Train: Epoch[3/5]  [3180/4579]  eta: 0:08:27  Lr: 0.001875  Loss: -0.8436  Acc@1: 62.5000 (63.5040)  Acc@5: 93.7500 (91.2351)  time: 0.4081  data: 0.0018  max mem: 2500
Train: Epoch[3/5]  [3190/4579]  eta: 0:08:24  Lr: 0.001875  Loss: -0.6728  Acc@1: 68.7500 (63.5126)  Acc@5: 93.7500 (91.2292)  time: 0.4103  data: 0.0017  max mem: 2500
Train: Epoch[3/5]  [3200/4579]  eta: 0:08:20  Lr: 0.001875  Loss: -0.1453  Acc@1: 62.5000 (63.5153)  Acc@5: 93.7500 (91.2234)  time: 0.4102  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [3210/4579]  eta: 0:08:17  Lr: 0.001875  Loss: -0.0046  Acc@1: 62.5000 (63.5219)  Acc@5: 87.5000 (91.2177)  time: 0.4083  data: 0.0011  max mem: 2500
Train: Epoch[3/5]  [3220/4579]  eta: 0:08:13  Lr: 0.001875  Loss: -0.2374  Acc@1: 62.5000 (63.5206)  Acc@5: 93.7500 (91.2275)  time: 0.4070  data: 0.0009  max mem: 2500
Train: Epoch[3/5]  [3230/4579]  eta: 0:08:10  Lr: 0.001875  Loss: 0.2064  Acc@1: 62.5000 (63.5349)  Acc@5: 93.7500 (91.2372)  time: 0.4073  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3240/4579]  eta: 0:08:07  Lr: 0.001875  Loss: 0.2083  Acc@1: 68.7500 (63.5548)  Acc@5: 93.7500 (91.2488)  time: 0.4085  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [3250/4579]  eta: 0:08:03  Lr: 0.001875  Loss: -0.3005  Acc@1: 68.7500 (63.5824)  Acc@5: 93.7500 (91.2450)  time: 0.4083  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [3260/4579]  eta: 0:08:00  Lr: 0.001875  Loss: -0.0758  Acc@1: 62.5000 (63.5752)  Acc@5: 87.5000 (91.2374)  time: 0.4080  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3270/4579]  eta: 0:07:56  Lr: 0.001875  Loss: -0.3535  Acc@1: 62.5000 (63.5872)  Acc@5: 93.7500 (91.2489)  time: 0.4077  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [3280/4579]  eta: 0:07:53  Lr: 0.001875  Loss: -0.4860  Acc@1: 68.7500 (63.6010)  Acc@5: 93.7500 (91.2412)  time: 0.4080  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [3290/4579]  eta: 0:07:49  Lr: 0.001875  Loss: -0.6241  Acc@1: 68.7500 (63.6205)  Acc@5: 93.7500 (91.2546)  time: 0.4083  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [3300/4579]  eta: 0:07:46  Lr: 0.001875  Loss: -0.9156  Acc@1: 68.7500 (63.6209)  Acc@5: 93.7500 (91.2583)  time: 0.4080  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [3310/4579]  eta: 0:07:42  Lr: 0.001875  Loss: -0.4603  Acc@1: 68.7500 (63.6345)  Acc@5: 93.7500 (91.2659)  time: 0.4076  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3320/4579]  eta: 0:07:39  Lr: 0.001875  Loss: 0.3952  Acc@1: 68.7500 (63.6461)  Acc@5: 93.7500 (91.2602)  time: 0.4081  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [3330/4579]  eta: 0:07:35  Lr: 0.001875  Loss: 0.1180  Acc@1: 68.7500 (63.6652)  Acc@5: 93.7500 (91.2695)  time: 0.4081  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [3340/4579]  eta: 0:07:32  Lr: 0.001875  Loss: -0.2040  Acc@1: 68.7500 (63.6580)  Acc@5: 93.7500 (91.2657)  time: 0.4075  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3350/4579]  eta: 0:07:28  Lr: 0.001875  Loss: -0.0287  Acc@1: 62.5000 (63.6545)  Acc@5: 93.7500 (91.2638)  time: 0.4081  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3360/4579]  eta: 0:07:25  Lr: 0.001875  Loss: 0.5500  Acc@1: 62.5000 (63.6604)  Acc@5: 93.7500 (91.2638)  time: 0.4079  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [3370/4579]  eta: 0:07:21  Lr: 0.001875  Loss: -0.7710  Acc@1: 68.7500 (63.6718)  Acc@5: 93.7500 (91.2637)  time: 0.4080  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [3380/4579]  eta: 0:07:18  Lr: 0.001875  Loss: -0.7478  Acc@1: 68.7500 (63.6831)  Acc@5: 93.7500 (91.2655)  time: 0.4093  data: 0.0011  max mem: 2500
Train: Epoch[3/5]  [3390/4579]  eta: 0:07:14  Lr: 0.001875  Loss: -0.7962  Acc@1: 68.7500 (63.6943)  Acc@5: 93.7500 (91.2673)  time: 0.4086  data: 0.0012  max mem: 2500
Train: Epoch[3/5]  [3400/4579]  eta: 0:07:11  Lr: 0.001875  Loss: -0.1830  Acc@1: 62.5000 (63.6761)  Acc@5: 87.5000 (91.2562)  time: 0.4077  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [3410/4579]  eta: 0:07:07  Lr: 0.001875  Loss: -0.4031  Acc@1: 68.7500 (63.6892)  Acc@5: 87.5000 (91.2526)  time: 0.4097  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [3420/4579]  eta: 0:07:04  Lr: 0.001875  Loss: -0.4856  Acc@1: 62.5000 (63.6729)  Acc@5: 87.5000 (91.2489)  time: 0.4088  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [3430/4579]  eta: 0:07:00  Lr: 0.001875  Loss: -0.6538  Acc@1: 62.5000 (63.6749)  Acc@5: 93.7500 (91.2507)  time: 0.4061  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [3440/4579]  eta: 0:06:57  Lr: 0.001875  Loss: -0.5227  Acc@1: 62.5000 (63.6734)  Acc@5: 93.7500 (91.2525)  time: 0.4065  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [3450/4579]  eta: 0:06:53  Lr: 0.001875  Loss: -0.8475  Acc@1: 62.5000 (63.6609)  Acc@5: 93.7500 (91.2453)  time: 0.4067  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [3460/4579]  eta: 0:06:50  Lr: 0.001875  Loss: -0.1955  Acc@1: 62.5000 (63.6648)  Acc@5: 93.7500 (91.2579)  time: 0.4067  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [3470/4579]  eta: 0:06:46  Lr: 0.001875  Loss: -0.7139  Acc@1: 62.5000 (63.6704)  Acc@5: 93.7500 (91.2561)  time: 0.4074  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [3480/4579]  eta: 0:06:43  Lr: 0.001875  Loss: -0.4213  Acc@1: 68.7500 (63.6760)  Acc@5: 93.7500 (91.2597)  time: 0.4075  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [3490/4579]  eta: 0:06:39  Lr: 0.001875  Loss: -0.5423  Acc@1: 68.7500 (63.6762)  Acc@5: 93.7500 (91.2597)  time: 0.4070  data: 0.0013  max mem: 2500
Train: Epoch[3/5]  [3500/4579]  eta: 0:06:36  Lr: 0.001875  Loss: -0.1579  Acc@1: 62.5000 (63.6693)  Acc@5: 93.7500 (91.2650)  time: 0.4071  data: 0.0024  max mem: 2500
Train: Epoch[3/5]  [3510/4579]  eta: 0:06:32  Lr: 0.001875  Loss: -0.1050  Acc@1: 68.7500 (63.6820)  Acc@5: 93.7500 (91.2774)  time: 0.4073  data: 0.0015  max mem: 2500
Train: Epoch[3/5]  [3520/4579]  eta: 0:06:28  Lr: 0.001875  Loss: -0.8697  Acc@1: 68.7500 (63.6857)  Acc@5: 93.7500 (91.2827)  time: 0.4060  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [3530/4579]  eta: 0:06:25  Lr: 0.001875  Loss: -0.3150  Acc@1: 62.5000 (63.6824)  Acc@5: 93.7500 (91.2808)  time: 0.4057  data: 0.0012  max mem: 2500
Train: Epoch[3/5]  [3540/4579]  eta: 0:06:21  Lr: 0.001875  Loss: -0.2511  Acc@1: 68.7500 (63.6879)  Acc@5: 93.7500 (91.2825)  time: 0.4079  data: 0.0010  max mem: 2500
Train: Epoch[3/5]  [3550/4579]  eta: 0:06:18  Lr: 0.001875  Loss: -0.2865  Acc@1: 68.7500 (63.7056)  Acc@5: 93.7500 (91.2753)  time: 0.4079  data: 0.0010  max mem: 2500
Train: Epoch[3/5]  [3560/4579]  eta: 0:06:14  Lr: 0.001875  Loss: -0.5538  Acc@1: 68.7500 (63.6970)  Acc@5: 93.7500 (91.2823)  time: 0.4074  data: 0.0011  max mem: 2500
Train: Epoch[3/5]  [3570/4579]  eta: 0:06:11  Lr: 0.001875  Loss: -0.3254  Acc@1: 62.5000 (63.6936)  Acc@5: 93.7500 (91.2752)  time: 0.4069  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3580/4579]  eta: 0:06:07  Lr: 0.001875  Loss: 0.1014  Acc@1: 62.5000 (63.6990)  Acc@5: 87.5000 (91.2769)  time: 0.4056  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3590/4579]  eta: 0:06:03  Lr: 0.001875  Loss: -0.1469  Acc@1: 56.2500 (63.6853)  Acc@5: 93.7500 (91.2751)  time: 0.4075  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3600/4579]  eta: 0:06:00  Lr: 0.001875  Loss: -0.4882  Acc@1: 68.7500 (63.6941)  Acc@5: 93.7500 (91.2715)  time: 0.4072  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3610/4579]  eta: 0:05:56  Lr: 0.001875  Loss: -0.4537  Acc@1: 68.7500 (63.7116)  Acc@5: 93.7500 (91.2801)  time: 0.4063  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3620/4579]  eta: 0:05:53  Lr: 0.001875  Loss: -0.2666  Acc@1: 62.5000 (63.7082)  Acc@5: 93.7500 (91.2869)  time: 0.4075  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [3630/4579]  eta: 0:05:49  Lr: 0.001875  Loss: 0.1446  Acc@1: 62.5000 (63.7101)  Acc@5: 93.7500 (91.2851)  time: 0.4076  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [3640/4579]  eta: 0:05:46  Lr: 0.001875  Loss: -0.5795  Acc@1: 62.5000 (63.7119)  Acc@5: 93.7500 (91.2936)  time: 0.4069  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [3650/4579]  eta: 0:05:42  Lr: 0.001875  Loss: -0.6154  Acc@1: 68.7500 (63.7206)  Acc@5: 93.7500 (91.2935)  time: 0.4061  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [3660/4579]  eta: 0:05:38  Lr: 0.001875  Loss: -0.1286  Acc@1: 62.5000 (63.7104)  Acc@5: 87.5000 (91.2951)  time: 0.4077  data: 0.0011  max mem: 2500
Train: Epoch[3/5]  [3670/4579]  eta: 0:05:35  Lr: 0.001875  Loss: -0.4342  Acc@1: 62.5000 (63.7224)  Acc@5: 87.5000 (91.2881)  time: 0.4072  data: 0.0009  max mem: 2500
Train: Epoch[3/5]  [3680/4579]  eta: 0:05:31  Lr: 0.001875  Loss: -0.5520  Acc@1: 62.5000 (63.7157)  Acc@5: 87.5000 (91.2846)  time: 0.4061  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [3690/4579]  eta: 0:05:28  Lr: 0.001875  Loss: -0.7447  Acc@1: 62.5000 (63.7039)  Acc@5: 87.5000 (91.2778)  time: 0.4070  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [3700/4579]  eta: 0:05:24  Lr: 0.001875  Loss: -0.4247  Acc@1: 56.2500 (63.7041)  Acc@5: 93.7500 (91.2777)  time: 0.4073  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3710/4579]  eta: 0:05:20  Lr: 0.001875  Loss: -0.7963  Acc@1: 62.5000 (63.7109)  Acc@5: 93.7500 (91.2810)  time: 0.4077  data: 0.0009  max mem: 2500
Train: Epoch[3/5]  [3720/4579]  eta: 0:05:17  Lr: 0.001875  Loss: -0.5404  Acc@1: 68.7500 (63.7127)  Acc@5: 93.7500 (91.2826)  time: 0.4092  data: 0.0016  max mem: 2500
Train: Epoch[3/5]  [3730/4579]  eta: 0:05:13  Lr: 0.001875  Loss: 0.0278  Acc@1: 62.5000 (63.7028)  Acc@5: 87.5000 (91.2741)  time: 0.4094  data: 0.0014  max mem: 2500
Train: Epoch[3/5]  [3740/4579]  eta: 0:05:10  Lr: 0.001875  Loss: -0.1401  Acc@1: 62.5000 (63.7062)  Acc@5: 93.7500 (91.2724)  time: 0.4064  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [3750/4579]  eta: 0:05:06  Lr: 0.001875  Loss: -0.7275  Acc@1: 68.7500 (63.7213)  Acc@5: 93.7500 (91.2757)  time: 0.4069  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3760/4579]  eta: 0:05:02  Lr: 0.001875  Loss: -0.7140  Acc@1: 68.7500 (63.7347)  Acc@5: 87.5000 (91.2723)  time: 0.4082  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [3770/4579]  eta: 0:04:59  Lr: 0.001875  Loss: 0.0307  Acc@1: 62.5000 (63.7248)  Acc@5: 87.5000 (91.2623)  time: 0.4077  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [3780/4579]  eta: 0:04:55  Lr: 0.001875  Loss: -0.6656  Acc@1: 62.5000 (63.7315)  Acc@5: 87.5000 (91.2688)  time: 0.4094  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [3790/4579]  eta: 0:04:52  Lr: 0.001875  Loss: -0.6053  Acc@1: 68.7500 (63.7447)  Acc@5: 93.7500 (91.2803)  time: 0.4087  data: 0.0010  max mem: 2500
Train: Epoch[3/5]  [3800/4579]  eta: 0:04:48  Lr: 0.001875  Loss: -0.4450  Acc@1: 68.7500 (63.7579)  Acc@5: 93.7500 (91.2803)  time: 0.4073  data: 0.0011  max mem: 2500
Train: Epoch[3/5]  [3810/4579]  eta: 0:04:44  Lr: 0.001875  Loss: 0.0178  Acc@1: 62.5000 (63.7448)  Acc@5: 87.5000 (91.2769)  time: 0.4080  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [3820/4579]  eta: 0:04:41  Lr: 0.001875  Loss: -0.3897  Acc@1: 62.5000 (63.7464)  Acc@5: 87.5000 (91.2736)  time: 0.4077  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [3830/4579]  eta: 0:04:37  Lr: 0.001875  Loss: -0.5675  Acc@1: 68.7500 (63.7611)  Acc@5: 87.5000 (91.2702)  time: 0.4071  data: 0.0010  max mem: 2500
Train: Epoch[3/5]  [3840/4579]  eta: 0:04:33  Lr: 0.001875  Loss: -0.4455  Acc@1: 68.7500 (63.7676)  Acc@5: 93.7500 (91.2685)  time: 0.4061  data: 0.0009  max mem: 2500
Train: Epoch[3/5]  [3850/4579]  eta: 0:04:30  Lr: 0.001875  Loss: -0.5898  Acc@1: 62.5000 (63.7708)  Acc@5: 87.5000 (91.2669)  time: 0.4072  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3860/4579]  eta: 0:04:26  Lr: 0.001875  Loss: -0.3504  Acc@1: 62.5000 (63.7610)  Acc@5: 87.5000 (91.2652)  time: 0.4077  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3870/4579]  eta: 0:04:22  Lr: 0.001875  Loss: -0.5830  Acc@1: 62.5000 (63.7674)  Acc@5: 87.5000 (91.2587)  time: 0.4077  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3880/4579]  eta: 0:04:19  Lr: 0.001875  Loss: -0.5571  Acc@1: 68.7500 (63.7771)  Acc@5: 93.7500 (91.2619)  time: 0.4070  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [3890/4579]  eta: 0:04:15  Lr: 0.001875  Loss: -0.2262  Acc@1: 68.7500 (63.8011)  Acc@5: 93.7500 (91.2667)  time: 0.4078  data: 0.0013  max mem: 2500
Train: Epoch[3/5]  [3900/4579]  eta: 0:04:12  Lr: 0.001875  Loss: -0.8385  Acc@1: 68.7500 (63.7993)  Acc@5: 93.7500 (91.2731)  time: 0.4088  data: 0.0012  max mem: 2500
Train: Epoch[3/5]  [3910/4579]  eta: 0:04:08  Lr: 0.001875  Loss: -0.6323  Acc@1: 62.5000 (63.7928)  Acc@5: 93.7500 (91.2778)  time: 0.4087  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [3920/4579]  eta: 0:04:04  Lr: 0.001875  Loss: -0.1160  Acc@1: 68.7500 (63.8134)  Acc@5: 93.7500 (91.2761)  time: 0.4075  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3930/4579]  eta: 0:04:01  Lr: 0.001875  Loss: -0.7238  Acc@1: 75.0000 (63.8196)  Acc@5: 93.7500 (91.2777)  time: 0.4072  data: 0.0010  max mem: 2500
Train: Epoch[3/5]  [3940/4579]  eta: 0:03:57  Lr: 0.001875  Loss: -0.5737  Acc@1: 62.5000 (63.8179)  Acc@5: 93.7500 (91.2760)  time: 0.4089  data: 0.0010  max mem: 2500
Train: Epoch[3/5]  [3950/4579]  eta: 0:03:53  Lr: 0.001875  Loss: -0.4551  Acc@1: 68.7500 (63.8288)  Acc@5: 87.5000 (91.2744)  time: 0.4075  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3960/4579]  eta: 0:03:50  Lr: 0.001875  Loss: -0.3887  Acc@1: 68.7500 (63.8365)  Acc@5: 93.7500 (91.2790)  time: 0.4080  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3970/4579]  eta: 0:03:46  Lr: 0.001875  Loss: 0.1049  Acc@1: 62.5000 (63.8268)  Acc@5: 93.7500 (91.2805)  time: 0.4083  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3980/4579]  eta: 0:03:42  Lr: 0.001875  Loss: -0.2934  Acc@1: 56.2500 (63.8203)  Acc@5: 93.7500 (91.2836)  time: 0.4082  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3990/4579]  eta: 0:03:39  Lr: 0.001875  Loss: -0.5365  Acc@1: 68.7500 (63.8390)  Acc@5: 93.7500 (91.2929)  time: 0.4083  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [4000/4579]  eta: 0:03:35  Lr: 0.001875  Loss: -0.5395  Acc@1: 68.7500 (63.8450)  Acc@5: 93.7500 (91.2975)  time: 0.4074  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [4010/4579]  eta: 0:03:31  Lr: 0.001875  Loss: 0.2112  Acc@1: 62.5000 (63.8447)  Acc@5: 93.7500 (91.2974)  time: 0.4075  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [4020/4579]  eta: 0:03:28  Lr: 0.001875  Loss: -0.4783  Acc@1: 68.7500 (63.8632)  Acc@5: 93.7500 (91.2941)  time: 0.4083  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [4030/4579]  eta: 0:03:24  Lr: 0.001875  Loss: -0.4868  Acc@1: 62.5000 (63.8722)  Acc@5: 93.7500 (91.3064)  time: 0.4088  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [4040/4579]  eta: 0:03:20  Lr: 0.001875  Loss: -0.8172  Acc@1: 62.5000 (63.8920)  Acc@5: 93.7500 (91.3187)  time: 0.4086  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [4050/4579]  eta: 0:03:17  Lr: 0.001875  Loss: -0.5261  Acc@1: 62.5000 (63.8793)  Acc@5: 93.7500 (91.3139)  time: 0.4089  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [4060/4579]  eta: 0:03:13  Lr: 0.001875  Loss: 0.3694  Acc@1: 62.5000 (63.8836)  Acc@5: 93.7500 (91.3153)  time: 0.4080  data: 0.0011  max mem: 2500
Train: Epoch[3/5]  [4070/4579]  eta: 0:03:09  Lr: 0.001875  Loss: -0.6244  Acc@1: 62.5000 (63.8848)  Acc@5: 93.7500 (91.3182)  time: 0.4078  data: 0.0010  max mem: 2500
Train: Epoch[3/5]  [4080/4579]  eta: 0:03:06  Lr: 0.001875  Loss: -0.7052  Acc@1: 62.5000 (63.9028)  Acc@5: 93.7500 (91.3302)  time: 0.4070  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [4090/4579]  eta: 0:03:02  Lr: 0.001875  Loss: -0.5606  Acc@1: 68.7500 (63.9147)  Acc@5: 93.7500 (91.3438)  time: 0.4069  data: 0.0012  max mem: 2500
Train: Epoch[3/5]  [4100/4579]  eta: 0:02:58  Lr: 0.001875  Loss: -0.9162  Acc@1: 68.7500 (63.9219)  Acc@5: 100.0000 (91.3573)  time: 0.4072  data: 0.0012  max mem: 2500
Train: Epoch[3/5]  [4110/4579]  eta: 0:02:54  Lr: 0.001875  Loss: -0.4698  Acc@1: 62.5000 (63.9245)  Acc@5: 93.7500 (91.3601)  time: 0.4082  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [4120/4579]  eta: 0:02:51  Lr: 0.001875  Loss: -0.8717  Acc@1: 68.7500 (63.9317)  Acc@5: 93.7500 (91.3674)  time: 0.4085  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [4130/4579]  eta: 0:02:47  Lr: 0.001875  Loss: -0.4257  Acc@1: 62.5000 (63.9282)  Acc@5: 93.7500 (91.3701)  time: 0.4077  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [4140/4579]  eta: 0:02:43  Lr: 0.001875  Loss: -0.7567  Acc@1: 62.5000 (63.9218)  Acc@5: 93.7500 (91.3623)  time: 0.4093  data: 0.0019  max mem: 2500
Train: Epoch[3/5]  [4150/4579]  eta: 0:02:40  Lr: 0.001875  Loss: -0.4253  Acc@1: 62.5000 (63.9138)  Acc@5: 87.5000 (91.3590)  time: 0.4098  data: 0.0034  max mem: 2500
Train: Epoch[3/5]  [4160/4579]  eta: 0:02:36  Lr: 0.001875  Loss: -0.4849  Acc@1: 62.5000 (63.9074)  Acc@5: 87.5000 (91.3467)  time: 0.4077  data: 0.0025  max mem: 2500
Train: Epoch[3/5]  [4170/4579]  eta: 0:02:32  Lr: 0.001875  Loss: -0.5294  Acc@1: 62.5000 (63.9175)  Acc@5: 93.7500 (91.3465)  time: 0.4038  data: 0.0010  max mem: 2500
Train: Epoch[3/5]  [4180/4579]  eta: 0:02:29  Lr: 0.001875  Loss: -0.4592  Acc@1: 62.5000 (63.9231)  Acc@5: 93.7500 (91.3493)  time: 0.4032  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [4190/4579]  eta: 0:02:25  Lr: 0.001875  Loss: -0.3805  Acc@1: 68.7500 (63.9301)  Acc@5: 93.7500 (91.3565)  time: 0.4030  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [4200/4579]  eta: 0:02:21  Lr: 0.001875  Loss: -0.5682  Acc@1: 68.7500 (63.9416)  Acc@5: 93.7500 (91.3577)  time: 0.4014  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [4210/4579]  eta: 0:02:17  Lr: 0.001875  Loss: -0.9284  Acc@1: 62.5000 (63.9308)  Acc@5: 87.5000 (91.3530)  time: 0.3979  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [4220/4579]  eta: 0:02:14  Lr: 0.001875  Loss: -0.2717  Acc@1: 62.5000 (63.9466)  Acc@5: 93.7500 (91.3616)  time: 0.3966  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [4230/4579]  eta: 0:02:10  Lr: 0.001875  Loss: -0.4683  Acc@1: 68.7500 (63.9536)  Acc@5: 93.7500 (91.3688)  time: 0.3986  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [4240/4579]  eta: 0:02:06  Lr: 0.001875  Loss: -0.1126  Acc@1: 68.7500 (63.9560)  Acc@5: 93.7500 (91.3729)  time: 0.3988  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [4250/4579]  eta: 0:02:03  Lr: 0.001875  Loss: -0.5154  Acc@1: 62.5000 (63.9526)  Acc@5: 93.7500 (91.3667)  time: 0.3968  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [4260/4579]  eta: 0:01:59  Lr: 0.001875  Loss: -0.2993  Acc@1: 56.2500 (63.9536)  Acc@5: 93.7500 (91.3635)  time: 0.3972  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [4270/4579]  eta: 0:01:55  Lr: 0.001875  Loss: -0.2464  Acc@1: 56.2500 (63.9414)  Acc@5: 93.7500 (91.3618)  time: 0.3968  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [4280/4579]  eta: 0:01:51  Lr: 0.001875  Loss: -0.5253  Acc@1: 62.5000 (63.9453)  Acc@5: 93.7500 (91.3601)  time: 0.3942  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [4290/4579]  eta: 0:01:48  Lr: 0.001875  Loss: -0.1384  Acc@1: 68.7500 (63.9609)  Acc@5: 87.5000 (91.3613)  time: 0.3966  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [4300/4579]  eta: 0:01:44  Lr: 0.001875  Loss: -0.1645  Acc@1: 62.5000 (63.9604)  Acc@5: 87.5000 (91.3596)  time: 0.3986  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [4310/4579]  eta: 0:01:40  Lr: 0.001875  Loss: -0.6919  Acc@1: 68.7500 (63.9686)  Acc@5: 93.7500 (91.3651)  time: 0.3988  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [4320/4579]  eta: 0:01:36  Lr: 0.001875  Loss: -0.2338  Acc@1: 68.7500 (63.9652)  Acc@5: 93.7500 (91.3562)  time: 0.3985  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [4330/4579]  eta: 0:01:33  Lr: 0.001875  Loss: -0.3945  Acc@1: 62.5000 (63.9705)  Acc@5: 87.5000 (91.3545)  time: 0.3979  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [4340/4579]  eta: 0:01:29  Lr: 0.001875  Loss: -0.4436  Acc@1: 62.5000 (63.9671)  Acc@5: 87.5000 (91.3528)  time: 0.3973  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [4350/4579]  eta: 0:01:25  Lr: 0.001875  Loss: -0.6643  Acc@1: 62.5000 (63.9724)  Acc@5: 87.5000 (91.3554)  time: 0.3980  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [4360/4579]  eta: 0:01:22  Lr: 0.001875  Loss: -0.2600  Acc@1: 56.2500 (63.9532)  Acc@5: 93.7500 (91.3480)  time: 0.4040  data: 0.0009  max mem: 2500
Train: Epoch[3/5]  [4370/4579]  eta: 0:01:18  Lr: 0.001875  Loss: -0.4076  Acc@1: 56.2500 (63.9442)  Acc@5: 87.5000 (91.3435)  time: 0.4075  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [4380/4579]  eta: 0:01:14  Lr: 0.001875  Loss: -0.6762  Acc@1: 68.7500 (63.9551)  Acc@5: 93.7500 (91.3447)  time: 0.4080  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [4390/4579]  eta: 0:01:10  Lr: 0.001875  Loss: -0.1962  Acc@1: 68.7500 (63.9689)  Acc@5: 93.7500 (91.3417)  time: 0.4080  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [4400/4579]  eta: 0:01:07  Lr: 0.001875  Loss: -0.2159  Acc@1: 62.5000 (63.9627)  Acc@5: 93.7500 (91.3457)  time: 0.4071  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [4410/4579]  eta: 0:01:03  Lr: 0.001875  Loss: -0.8019  Acc@1: 62.5000 (63.9651)  Acc@5: 87.5000 (91.3370)  time: 0.4073  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [4420/4579]  eta: 0:00:59  Lr: 0.001875  Loss: 0.1048  Acc@1: 68.7500 (63.9674)  Acc@5: 87.5000 (91.3326)  time: 0.4084  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [4430/4579]  eta: 0:00:55  Lr: 0.001875  Loss: -0.9390  Acc@1: 68.7500 (63.9810)  Acc@5: 93.7500 (91.3310)  time: 0.4074  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [4440/4579]  eta: 0:00:52  Lr: 0.001875  Loss: -0.0050  Acc@1: 68.7500 (63.9918)  Acc@5: 87.5000 (91.3266)  time: 0.4059  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [4450/4579]  eta: 0:00:48  Lr: 0.001875  Loss: -0.6956  Acc@1: 68.7500 (63.9955)  Acc@5: 93.7500 (91.3320)  time: 0.4085  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [4460/4579]  eta: 0:00:44  Lr: 0.001875  Loss: -0.0578  Acc@1: 62.5000 (63.9907)  Acc@5: 93.7500 (91.3304)  time: 0.4070  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [4470/4579]  eta: 0:00:40  Lr: 0.001875  Loss: -0.8069  Acc@1: 62.5000 (64.0013)  Acc@5: 93.7500 (91.3330)  time: 0.4048  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [4480/4579]  eta: 0:00:37  Lr: 0.001875  Loss: -0.5174  Acc@1: 62.5000 (63.9924)  Acc@5: 93.7500 (91.3328)  time: 0.4068  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [4490/4579]  eta: 0:00:33  Lr: 0.001875  Loss: -0.1240  Acc@1: 62.5000 (63.9947)  Acc@5: 87.5000 (91.3215)  time: 0.4089  data: 0.0013  max mem: 2500
Train: Epoch[3/5]  [4500/4579]  eta: 0:00:29  Lr: 0.001875  Loss: -0.3809  Acc@1: 56.2500 (63.9594)  Acc@5: 87.5000 (91.3172)  time: 0.4094  data: 0.0014  max mem: 2500
Train: Epoch[3/5]  [4510/4579]  eta: 0:00:25  Lr: 0.001875  Loss: -0.2617  Acc@1: 56.2500 (63.9534)  Acc@5: 87.5000 (91.3129)  time: 0.4076  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [4520/4579]  eta: 0:00:22  Lr: 0.001875  Loss: -0.4993  Acc@1: 62.5000 (63.9502)  Acc@5: 93.7500 (91.3211)  time: 0.4063  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [4530/4579]  eta: 0:00:18  Lr: 0.001875  Loss: -0.0905  Acc@1: 62.5000 (63.9428)  Acc@5: 93.7500 (91.3250)  time: 0.4067  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [4540/4579]  eta: 0:00:14  Lr: 0.001875  Loss: -0.2369  Acc@1: 68.7500 (63.9603)  Acc@5: 93.7500 (91.3276)  time: 0.4062  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [4550/4579]  eta: 0:00:10  Lr: 0.001875  Loss: -0.2224  Acc@1: 68.7500 (63.9434)  Acc@5: 93.7500 (91.3288)  time: 0.4074  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [4560/4579]  eta: 0:00:07  Lr: 0.001875  Loss: -0.4831  Acc@1: 62.5000 (63.9457)  Acc@5: 93.7500 (91.3300)  time: 0.4075  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [4570/4579]  eta: 0:00:03  Lr: 0.001875  Loss: -0.1588  Acc@1: 62.5000 (63.9302)  Acc@5: 87.5000 (91.3216)  time: 0.4066  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [4578/4579]  eta: 0:00:00  Lr: 0.001875  Loss: 0.0707  Acc@1: 62.5000 (63.9379)  Acc@5: 87.5000 (91.3237)  time: 0.3974  data: 0.0007  max mem: 2500
Train: Epoch[3/5] Total time: 0:28:43 (0.3763 s / it)
Averaged stats: Lr: 0.001875  Loss: 0.0707  Acc@1: 62.5000 (63.9379)  Acc@5: 87.5000 (91.3237)
Train: Epoch[4/5]  [   0/4579]  eta: 1:00:03  Lr: 0.001875  Loss: -0.6838  Acc@1: 68.7500 (68.7500)  Acc@5: 93.7500 (93.7500)  time: 0.7870  data: 0.3963  max mem: 2500
Train: Epoch[4/5]  [  10/4579]  eta: 0:33:39  Lr: 0.001875  Loss: -0.6331  Acc@1: 68.7500 (65.3409)  Acc@5: 93.7500 (92.0455)  time: 0.4421  data: 0.0365  max mem: 2500
Train: Epoch[4/5]  [  20/4579]  eta: 0:32:17  Lr: 0.001875  Loss: -0.3656  Acc@1: 62.5000 (64.8810)  Acc@5: 93.7500 (91.9643)  time: 0.4070  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [  30/4579]  eta: 0:31:45  Lr: 0.001875  Loss: -0.4893  Acc@1: 56.2500 (64.3145)  Acc@5: 93.7500 (92.5403)  time: 0.4062  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [  40/4579]  eta: 0:31:25  Lr: 0.001875  Loss: -0.1547  Acc@1: 56.2500 (64.4817)  Acc@5: 93.7500 (92.6829)  time: 0.4053  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [  50/4579]  eta: 0:31:11  Lr: 0.001875  Loss: -0.7170  Acc@1: 62.5000 (65.5637)  Acc@5: 93.7500 (92.6471)  time: 0.4046  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [  60/4579]  eta: 0:30:58  Lr: 0.001875  Loss: -0.2362  Acc@1: 62.5000 (65.7787)  Acc@5: 93.7500 (92.7254)  time: 0.4030  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [  70/4579]  eta: 0:30:51  Lr: 0.001875  Loss: -0.1325  Acc@1: 62.5000 (65.6690)  Acc@5: 93.7500 (92.5176)  time: 0.4038  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [  80/4579]  eta: 0:30:45  Lr: 0.001875  Loss: -0.2022  Acc@1: 62.5000 (65.4321)  Acc@5: 93.7500 (92.5926)  time: 0.4065  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [  90/4579]  eta: 0:30:38  Lr: 0.001875  Loss: -0.2620  Acc@1: 62.5000 (64.9038)  Acc@5: 93.7500 (92.2390)  time: 0.4053  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [ 100/4579]  eta: 0:30:34  Lr: 0.001875  Loss: -0.4061  Acc@1: 62.5000 (65.1609)  Acc@5: 93.7500 (92.4505)  time: 0.4072  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [ 110/4579]  eta: 0:30:29  Lr: 0.001875  Loss: -0.1237  Acc@1: 68.7500 (64.7523)  Acc@5: 93.7500 (92.8491)  time: 0.4087  data: 0.0012  max mem: 2500
Train: Epoch[4/5]  [ 120/4579]  eta: 0:30:22  Lr: 0.001875  Loss: -0.7524  Acc@1: 68.7500 (65.3409)  Acc@5: 93.7500 (93.0269)  time: 0.4050  data: 0.0012  max mem: 2500
Train: Epoch[4/5]  [ 130/4579]  eta: 0:30:18  Lr: 0.001875  Loss: 0.3980  Acc@1: 68.7500 (64.9332)  Acc@5: 93.7500 (92.9389)  time: 0.4048  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [ 140/4579]  eta: 0:30:13  Lr: 0.001875  Loss: 0.1460  Acc@1: 62.5000 (64.9823)  Acc@5: 93.7500 (92.8635)  time: 0.4071  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [ 150/4579]  eta: 0:30:08  Lr: 0.001875  Loss: -0.2655  Acc@1: 56.2500 (64.5695)  Acc@5: 93.7500 (92.3841)  time: 0.4065  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [ 160/4579]  eta: 0:30:04  Lr: 0.001875  Loss: -0.4879  Acc@1: 62.5000 (64.5963)  Acc@5: 93.7500 (92.3913)  time: 0.4060  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 170/4579]  eta: 0:29:59  Lr: 0.001875  Loss: -0.6074  Acc@1: 62.5000 (64.6564)  Acc@5: 93.7500 (92.3246)  time: 0.4062  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 180/4579]  eta: 0:29:54  Lr: 0.001875  Loss: -0.5405  Acc@1: 62.5000 (64.5718)  Acc@5: 93.7500 (92.2307)  time: 0.4049  data: 0.0010  max mem: 2500
Train: Epoch[4/5]  [ 190/4579]  eta: 0:29:49  Lr: 0.001875  Loss: -0.5464  Acc@1: 62.5000 (64.7251)  Acc@5: 93.7500 (92.3429)  time: 0.4045  data: 0.0017  max mem: 2500
Train: Epoch[4/5]  [ 200/4579]  eta: 0:29:44  Lr: 0.001875  Loss: -0.3089  Acc@1: 62.5000 (64.3657)  Acc@5: 93.7500 (92.2264)  time: 0.4042  data: 0.0010  max mem: 2500
Train: Epoch[4/5]  [ 210/4579]  eta: 0:29:40  Lr: 0.001875  Loss: -0.0088  Acc@1: 62.5000 (64.5735)  Acc@5: 87.5000 (92.2986)  time: 0.4049  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 220/4579]  eta: 0:29:36  Lr: 0.001875  Loss: -0.5969  Acc@1: 75.0000 (65.0170)  Acc@5: 93.7500 (92.3077)  time: 0.4072  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 230/4579]  eta: 0:29:31  Lr: 0.001875  Loss: -0.3648  Acc@1: 68.7500 (64.9892)  Acc@5: 93.7500 (92.2619)  time: 0.4067  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 240/4579]  eta: 0:29:27  Lr: 0.001875  Loss: -0.4528  Acc@1: 62.5000 (64.9118)  Acc@5: 93.7500 (92.2718)  time: 0.4068  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [ 250/4579]  eta: 0:29:23  Lr: 0.001875  Loss: -0.5750  Acc@1: 62.5000 (64.8406)  Acc@5: 93.7500 (92.2311)  time: 0.4059  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [ 260/4579]  eta: 0:29:18  Lr: 0.001875  Loss: -0.0782  Acc@1: 68.7500 (65.0862)  Acc@5: 93.7500 (92.2893)  time: 0.4049  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [ 270/4579]  eta: 0:29:14  Lr: 0.001875  Loss: -0.3118  Acc@1: 68.7500 (65.0600)  Acc@5: 93.7500 (92.3432)  time: 0.4054  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [ 280/4579]  eta: 0:29:10  Lr: 0.001875  Loss: -1.2324  Acc@1: 68.7500 (65.2135)  Acc@5: 93.7500 (92.2598)  time: 0.4053  data: 0.0011  max mem: 2500
Train: Epoch[4/5]  [ 290/4579]  eta: 0:29:05  Lr: 0.001875  Loss: -0.4340  Acc@1: 62.5000 (65.3136)  Acc@5: 93.7500 (92.3325)  time: 0.4060  data: 0.0011  max mem: 2500
Train: Epoch[4/5]  [ 300/4579]  eta: 0:29:01  Lr: 0.001875  Loss: 0.3217  Acc@1: 62.5000 (65.0540)  Acc@5: 93.7500 (92.1927)  time: 0.4064  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [ 310/4579]  eta: 0:28:57  Lr: 0.001875  Loss: -0.7285  Acc@1: 62.5000 (65.3336)  Acc@5: 87.5000 (92.1423)  time: 0.4061  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [ 320/4579]  eta: 0:28:53  Lr: 0.001875  Loss: -0.3325  Acc@1: 68.7500 (65.2648)  Acc@5: 93.7500 (92.1145)  time: 0.4061  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [ 330/4579]  eta: 0:28:49  Lr: 0.001875  Loss: -0.2454  Acc@1: 62.5000 (65.3512)  Acc@5: 93.7500 (92.0506)  time: 0.4060  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [ 340/4579]  eta: 0:28:45  Lr: 0.001875  Loss: -0.4998  Acc@1: 68.7500 (65.4326)  Acc@5: 93.7500 (92.0638)  time: 0.4076  data: 0.0012  max mem: 2500
Train: Epoch[4/5]  [ 350/4579]  eta: 0:28:41  Lr: 0.001875  Loss: -0.3859  Acc@1: 62.5000 (65.4024)  Acc@5: 93.7500 (92.0228)  time: 0.4074  data: 0.0011  max mem: 2500
Train: Epoch[4/5]  [ 360/4579]  eta: 0:28:36  Lr: 0.001875  Loss: -0.5807  Acc@1: 62.5000 (65.3047)  Acc@5: 87.5000 (92.0014)  time: 0.4051  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [ 370/4579]  eta: 0:28:32  Lr: 0.001875  Loss: -0.6789  Acc@1: 62.5000 (65.2123)  Acc@5: 87.5000 (91.8632)  time: 0.4053  data: 0.0014  max mem: 2500
Train: Epoch[4/5]  [ 380/4579]  eta: 0:28:28  Lr: 0.001875  Loss: 0.2260  Acc@1: 56.2500 (65.0919)  Acc@5: 87.5000 (91.7815)  time: 0.4054  data: 0.0014  max mem: 2500
Train: Epoch[4/5]  [ 390/4579]  eta: 0:28:24  Lr: 0.001875  Loss: -0.1830  Acc@1: 62.5000 (65.0895)  Acc@5: 93.7500 (91.8159)  time: 0.4051  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [ 400/4579]  eta: 0:28:20  Lr: 0.001875  Loss: -0.2896  Acc@1: 62.5000 (65.0717)  Acc@5: 93.7500 (91.7550)  time: 0.4071  data: 0.0019  max mem: 2500
Train: Epoch[4/5]  [ 410/4579]  eta: 0:28:16  Lr: 0.001875  Loss: -0.3068  Acc@1: 62.5000 (64.9787)  Acc@5: 93.7500 (91.7731)  time: 0.4088  data: 0.0020  max mem: 2500
Train: Epoch[4/5]  [ 420/4579]  eta: 0:28:12  Lr: 0.001875  Loss: 0.2849  Acc@1: 62.5000 (65.1574)  Acc@5: 93.7500 (91.8795)  time: 0.4094  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [ 430/4579]  eta: 0:28:08  Lr: 0.001875  Loss: 0.0302  Acc@1: 62.5000 (64.9507)  Acc@5: 93.7500 (91.8068)  time: 0.4087  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [ 440/4579]  eta: 0:28:04  Lr: 0.001875  Loss: -0.6712  Acc@1: 62.5000 (64.9376)  Acc@5: 93.7500 (91.8509)  time: 0.4052  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [ 450/4579]  eta: 0:28:00  Lr: 0.001875  Loss: -0.1590  Acc@1: 62.5000 (64.8420)  Acc@5: 93.7500 (91.8099)  time: 0.4059  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [ 460/4579]  eta: 0:27:56  Lr: 0.001875  Loss: -0.4751  Acc@1: 62.5000 (64.8861)  Acc@5: 93.7500 (91.9062)  time: 0.4071  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [ 470/4579]  eta: 0:27:51  Lr: 0.001875  Loss: -0.4266  Acc@1: 62.5000 (64.8487)  Acc@5: 100.0000 (91.9586)  time: 0.4061  data: 0.0011  max mem: 2500
Train: Epoch[4/5]  [ 480/4579]  eta: 0:27:48  Lr: 0.001875  Loss: -0.4378  Acc@1: 62.5000 (64.8779)  Acc@5: 93.7500 (91.9699)  time: 0.4084  data: 0.0011  max mem: 2500
Train: Epoch[4/5]  [ 490/4579]  eta: 0:27:44  Lr: 0.001875  Loss: -0.6732  Acc@1: 62.5000 (64.8549)  Acc@5: 93.7500 (91.9425)  time: 0.4089  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 500/4579]  eta: 0:27:40  Lr: 0.001875  Loss: -0.4051  Acc@1: 62.5000 (64.8204)  Acc@5: 87.5000 (91.8787)  time: 0.4073  data: 0.0015  max mem: 2500
Train: Epoch[4/5]  [ 510/4579]  eta: 0:27:36  Lr: 0.001875  Loss: -0.2136  Acc@1: 68.7500 (64.8361)  Acc@5: 87.5000 (91.8297)  time: 0.4082  data: 0.0015  max mem: 2500
Train: Epoch[4/5]  [ 520/4579]  eta: 0:27:32  Lr: 0.001875  Loss: -0.2181  Acc@1: 62.5000 (64.7553)  Acc@5: 93.7500 (91.8426)  time: 0.4084  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [ 530/4579]  eta: 0:27:28  Lr: 0.001875  Loss: -0.8118  Acc@1: 62.5000 (64.7246)  Acc@5: 93.7500 (91.8197)  time: 0.4071  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [ 540/4579]  eta: 0:27:23  Lr: 0.001875  Loss: -0.2340  Acc@1: 68.7500 (64.7528)  Acc@5: 93.7500 (91.8900)  time: 0.4050  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [ 550/4579]  eta: 0:27:19  Lr: 0.001875  Loss: -0.0647  Acc@1: 62.5000 (64.7346)  Acc@5: 93.7500 (91.8897)  time: 0.4066  data: 0.0012  max mem: 2500
Train: Epoch[4/5]  [ 560/4579]  eta: 0:27:15  Lr: 0.001875  Loss: -0.4300  Acc@1: 62.5000 (64.7393)  Acc@5: 93.7500 (91.9118)  time: 0.4088  data: 0.0024  max mem: 2500
Train: Epoch[4/5]  [ 570/4579]  eta: 0:27:11  Lr: 0.001875  Loss: 0.4789  Acc@1: 62.5000 (64.7329)  Acc@5: 87.5000 (91.9111)  time: 0.4087  data: 0.0017  max mem: 2500
Train: Epoch[4/5]  [ 580/4579]  eta: 0:27:07  Lr: 0.001875  Loss: -0.8152  Acc@1: 62.5000 (64.6837)  Acc@5: 87.5000 (91.8460)  time: 0.4073  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [ 590/4579]  eta: 0:27:03  Lr: 0.001875  Loss: -0.4694  Acc@1: 62.5000 (64.6362)  Acc@5: 93.7500 (91.8993)  time: 0.4062  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [ 600/4579]  eta: 0:26:59  Lr: 0.001875  Loss: 0.0963  Acc@1: 62.5000 (64.6527)  Acc@5: 93.7500 (91.9197)  time: 0.4063  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [ 610/4579]  eta: 0:26:55  Lr: 0.001875  Loss: -0.3331  Acc@1: 68.7500 (64.7095)  Acc@5: 93.7500 (91.9190)  time: 0.4069  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [ 620/4579]  eta: 0:26:51  Lr: 0.001875  Loss: -0.6529  Acc@1: 68.7500 (64.7444)  Acc@5: 93.7500 (91.9887)  time: 0.4065  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [ 630/4579]  eta: 0:26:47  Lr: 0.001875  Loss: -0.4635  Acc@1: 68.7500 (64.7187)  Acc@5: 93.7500 (91.9275)  time: 0.4070  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [ 640/4579]  eta: 0:26:43  Lr: 0.001875  Loss: -0.7366  Acc@1: 62.5000 (64.7523)  Acc@5: 87.5000 (91.9364)  time: 0.4063  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [ 650/4579]  eta: 0:26:39  Lr: 0.001875  Loss: -0.4886  Acc@1: 62.5000 (64.7273)  Acc@5: 93.7500 (91.9355)  time: 0.4061  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 660/4579]  eta: 0:26:35  Lr: 0.001875  Loss: -0.2553  Acc@1: 62.5000 (64.7315)  Acc@5: 93.7500 (91.9440)  time: 0.4082  data: 0.0010  max mem: 2500
Train: Epoch[4/5]  [ 670/4579]  eta: 0:26:30  Lr: 0.001875  Loss: -0.7476  Acc@1: 62.5000 (64.7448)  Acc@5: 93.7500 (91.9430)  time: 0.4063  data: 0.0010  max mem: 2500
Train: Epoch[4/5]  [ 680/4579]  eta: 0:26:26  Lr: 0.001875  Loss: -0.2347  Acc@1: 62.5000 (64.7761)  Acc@5: 93.7500 (91.9512)  time: 0.4072  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [ 690/4579]  eta: 0:26:22  Lr: 0.001875  Loss: -0.2810  Acc@1: 68.7500 (64.8155)  Acc@5: 93.7500 (91.9591)  time: 0.4073  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [ 700/4579]  eta: 0:26:18  Lr: 0.001875  Loss: -0.3028  Acc@1: 68.7500 (64.8359)  Acc@5: 87.5000 (91.9223)  time: 0.4061  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [ 710/4579]  eta: 0:26:14  Lr: 0.001875  Loss: -0.4132  Acc@1: 62.5000 (64.8119)  Acc@5: 87.5000 (91.8952)  time: 0.4066  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [ 720/4579]  eta: 0:26:10  Lr: 0.001875  Loss: -0.4850  Acc@1: 62.5000 (64.8492)  Acc@5: 93.7500 (91.8949)  time: 0.4082  data: 0.0013  max mem: 2500
Train: Epoch[4/5]  [ 730/4579]  eta: 0:26:06  Lr: 0.001875  Loss: 0.0717  Acc@1: 62.5000 (64.7657)  Acc@5: 87.5000 (91.8605)  time: 0.4090  data: 0.0019  max mem: 2500
Train: Epoch[4/5]  [ 740/4579]  eta: 0:26:02  Lr: 0.001875  Loss: -0.9413  Acc@1: 62.5000 (64.8701)  Acc@5: 93.7500 (91.8691)  time: 0.4071  data: 0.0011  max mem: 2500
Train: Epoch[4/5]  [ 750/4579]  eta: 0:25:58  Lr: 0.001875  Loss: -0.4818  Acc@1: 68.7500 (64.9218)  Acc@5: 93.7500 (91.8609)  time: 0.4054  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [ 760/4579]  eta: 0:25:54  Lr: 0.001875  Loss: -0.4364  Acc@1: 68.7500 (64.9228)  Acc@5: 87.5000 (91.8282)  time: 0.4063  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [ 770/4579]  eta: 0:25:50  Lr: 0.001875  Loss: -0.1943  Acc@1: 62.5000 (64.8184)  Acc@5: 87.5000 (91.7639)  time: 0.4066  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [ 780/4579]  eta: 0:25:46  Lr: 0.001875  Loss: -0.5382  Acc@1: 62.5000 (64.8287)  Acc@5: 87.5000 (91.7334)  time: 0.4062  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [ 790/4579]  eta: 0:25:41  Lr: 0.001875  Loss: -0.2422  Acc@1: 62.5000 (64.7282)  Acc@5: 93.7500 (91.7114)  time: 0.4064  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [ 800/4579]  eta: 0:25:37  Lr: 0.001875  Loss: -0.2528  Acc@1: 56.2500 (64.6770)  Acc@5: 87.5000 (91.7135)  time: 0.4069  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [ 810/4579]  eta: 0:25:33  Lr: 0.001875  Loss: -0.3529  Acc@1: 68.7500 (64.7580)  Acc@5: 93.7500 (91.7463)  time: 0.4081  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [ 820/4579]  eta: 0:25:29  Lr: 0.001875  Loss: -0.4636  Acc@1: 68.7500 (64.8371)  Acc@5: 93.7500 (91.7935)  time: 0.4067  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [ 830/4579]  eta: 0:25:25  Lr: 0.001875  Loss: 0.0242  Acc@1: 68.7500 (64.8315)  Acc@5: 93.7500 (91.7644)  time: 0.4078  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [ 840/4579]  eta: 0:25:21  Lr: 0.001875  Loss: -0.6002  Acc@1: 68.7500 (64.9673)  Acc@5: 93.7500 (91.7955)  time: 0.4091  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [ 850/4579]  eta: 0:25:17  Lr: 0.001875  Loss: -0.5532  Acc@1: 68.7500 (64.9236)  Acc@5: 93.7500 (91.7964)  time: 0.4092  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [ 860/4579]  eta: 0:25:13  Lr: 0.001875  Loss: -0.1877  Acc@1: 56.2500 (64.8084)  Acc@5: 93.7500 (91.7756)  time: 0.4098  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [ 870/4579]  eta: 0:25:09  Lr: 0.001875  Loss: -0.2177  Acc@1: 62.5000 (64.8177)  Acc@5: 93.7500 (91.7839)  time: 0.4092  data: 0.0011  max mem: 2500
Train: Epoch[4/5]  [ 880/4579]  eta: 0:25:05  Lr: 0.001875  Loss: -0.0441  Acc@1: 68.7500 (64.8127)  Acc@5: 93.7500 (91.7849)  time: 0.4088  data: 0.0018  max mem: 2500
Train: Epoch[4/5]  [ 890/4579]  eta: 0:25:01  Lr: 0.001875  Loss: 0.0524  Acc@1: 68.7500 (64.8429)  Acc@5: 93.7500 (91.7859)  time: 0.4075  data: 0.0013  max mem: 2500
Train: Epoch[4/5]  [ 900/4579]  eta: 0:24:57  Lr: 0.001875  Loss: 0.2180  Acc@1: 62.5000 (64.7822)  Acc@5: 87.5000 (91.7522)  time: 0.4053  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [ 910/4579]  eta: 0:24:53  Lr: 0.001875  Loss: -0.6411  Acc@1: 62.5000 (64.8395)  Acc@5: 87.5000 (91.7261)  time: 0.4073  data: 0.0023  max mem: 2500
Train: Epoch[4/5]  [ 920/4579]  eta: 0:24:49  Lr: 0.001875  Loss: -0.0218  Acc@1: 68.7500 (64.8819)  Acc@5: 87.5000 (91.7142)  time: 0.4106  data: 0.0020  max mem: 2500
Train: Epoch[4/5]  [ 930/4579]  eta: 0:24:45  Lr: 0.001875  Loss: -0.3936  Acc@1: 68.7500 (64.9637)  Acc@5: 87.5000 (91.6823)  time: 0.4091  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [ 940/4579]  eta: 0:24:41  Lr: 0.001875  Loss: -0.5535  Acc@1: 68.7500 (64.9309)  Acc@5: 87.5000 (91.6711)  time: 0.4066  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [ 950/4579]  eta: 0:24:37  Lr: 0.001875  Loss: -0.4095  Acc@1: 56.2500 (64.8988)  Acc@5: 93.7500 (91.6732)  time: 0.4075  data: 0.0015  max mem: 2500
Train: Epoch[4/5]  [ 960/4579]  eta: 0:24:33  Lr: 0.001875  Loss: 0.5140  Acc@1: 62.5000 (64.8088)  Acc@5: 93.7500 (91.6428)  time: 0.4087  data: 0.0016  max mem: 2500
Train: Epoch[4/5]  [ 970/4579]  eta: 0:24:29  Lr: 0.001875  Loss: -0.4258  Acc@1: 56.2500 (64.7400)  Acc@5: 87.5000 (91.6002)  time: 0.4064  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [ 980/4579]  eta: 0:24:25  Lr: 0.001875  Loss: -0.8543  Acc@1: 62.5000 (64.7872)  Acc@5: 87.5000 (91.6284)  time: 0.4066  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [ 990/4579]  eta: 0:24:21  Lr: 0.001875  Loss: -0.2732  Acc@1: 62.5000 (64.7957)  Acc@5: 93.7500 (91.5994)  time: 0.4080  data: 0.0012  max mem: 2500
Train: Epoch[4/5]  [1000/4579]  eta: 0:24:17  Lr: 0.001875  Loss: -0.1984  Acc@1: 56.2500 (64.7353)  Acc@5: 87.5000 (91.5834)  time: 0.4068  data: 0.0010  max mem: 2500
Train: Epoch[4/5]  [1010/4579]  eta: 0:24:13  Lr: 0.001875  Loss: -0.3392  Acc@1: 62.5000 (64.7070)  Acc@5: 93.7500 (91.5616)  time: 0.4061  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1020/4579]  eta: 0:24:08  Lr: 0.001875  Loss: -0.7751  Acc@1: 62.5000 (64.7098)  Acc@5: 93.7500 (91.5830)  time: 0.4047  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [1030/4579]  eta: 0:24:04  Lr: 0.001875  Loss: -0.5468  Acc@1: 62.5000 (64.6763)  Acc@5: 93.7500 (91.5677)  time: 0.4057  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [1040/4579]  eta: 0:24:00  Lr: 0.001875  Loss: -0.3035  Acc@1: 62.5000 (64.6314)  Acc@5: 93.7500 (91.5766)  time: 0.4085  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [1050/4579]  eta: 0:23:56  Lr: 0.001875  Loss: -0.4767  Acc@1: 62.5000 (64.6349)  Acc@5: 93.7500 (91.5557)  time: 0.4087  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [1060/4579]  eta: 0:23:52  Lr: 0.001875  Loss: -0.5449  Acc@1: 62.5000 (64.6265)  Acc@5: 93.7500 (91.5705)  time: 0.4064  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [1070/4579]  eta: 0:23:48  Lr: 0.001875  Loss: 0.2469  Acc@1: 62.5000 (64.5775)  Acc@5: 93.7500 (91.5500)  time: 0.4053  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1080/4579]  eta: 0:23:44  Lr: 0.001875  Loss: -0.8544  Acc@1: 62.5000 (64.5988)  Acc@5: 87.5000 (91.5414)  time: 0.4068  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1090/4579]  eta: 0:23:40  Lr: 0.001875  Loss: -0.0709  Acc@1: 56.2500 (64.5394)  Acc@5: 87.5000 (91.5044)  time: 0.4080  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [1100/4579]  eta: 0:23:36  Lr: 0.001875  Loss: 0.4622  Acc@1: 56.2500 (64.5039)  Acc@5: 93.7500 (91.5134)  time: 0.4073  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [1110/4579]  eta: 0:23:32  Lr: 0.001875  Loss: -0.8599  Acc@1: 68.7500 (64.5533)  Acc@5: 93.7500 (91.5110)  time: 0.4088  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [1120/4579]  eta: 0:23:28  Lr: 0.001875  Loss: -0.4233  Acc@1: 62.5000 (64.4960)  Acc@5: 93.7500 (91.4752)  time: 0.4091  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [1130/4579]  eta: 0:23:24  Lr: 0.001875  Loss: -0.4625  Acc@1: 62.5000 (64.4783)  Acc@5: 93.7500 (91.4733)  time: 0.4065  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [1140/4579]  eta: 0:23:20  Lr: 0.001875  Loss: -0.2755  Acc@1: 62.5000 (64.4500)  Acc@5: 93.7500 (91.4603)  time: 0.4082  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [1150/4579]  eta: 0:23:16  Lr: 0.001875  Loss: -0.5674  Acc@1: 62.5000 (64.4711)  Acc@5: 93.7500 (91.4477)  time: 0.4072  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [1160/4579]  eta: 0:23:11  Lr: 0.001875  Loss: -0.4533  Acc@1: 68.7500 (64.4811)  Acc@5: 87.5000 (91.4352)  time: 0.4038  data: 0.0012  max mem: 2500
Train: Epoch[4/5]  [1170/4579]  eta: 0:23:07  Lr: 0.001875  Loss: -0.2321  Acc@1: 68.7500 (64.5015)  Acc@5: 93.7500 (91.4336)  time: 0.4052  data: 0.0011  max mem: 2500
Train: Epoch[4/5]  [1180/4579]  eta: 0:23:03  Lr: 0.001875  Loss: 0.0223  Acc@1: 68.7500 (64.5163)  Acc@5: 93.7500 (91.4638)  time: 0.4023  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [1190/4579]  eta: 0:22:59  Lr: 0.001875  Loss: -0.2072  Acc@1: 68.7500 (64.5571)  Acc@5: 93.7500 (91.4620)  time: 0.3952  data: 0.0015  max mem: 2500
Train: Epoch[4/5]  [1200/4579]  eta: 0:22:54  Lr: 0.001875  Loss: -0.3949  Acc@1: 62.5000 (64.5192)  Acc@5: 93.7500 (91.4654)  time: 0.3904  data: 0.0022  max mem: 2500
Train: Epoch[4/5]  [1210/4579]  eta: 0:22:49  Lr: 0.001875  Loss: -0.5711  Acc@1: 62.5000 (64.4715)  Acc@5: 93.7500 (91.4740)  time: 0.3872  data: 0.0013  max mem: 2500
Train: Epoch[4/5]  [1220/4579]  eta: 0:22:45  Lr: 0.001875  Loss: 0.1155  Acc@1: 62.5000 (64.4400)  Acc@5: 93.7500 (91.4619)  time: 0.3860  data: 0.0011  max mem: 2500
Train: Epoch[4/5]  [1230/4579]  eta: 0:22:40  Lr: 0.001875  Loss: -0.0353  Acc@1: 62.5000 (64.4801)  Acc@5: 93.7500 (91.5008)  time: 0.3853  data: 0.0011  max mem: 2500
Train: Epoch[4/5]  [1240/4579]  eta: 0:22:35  Lr: 0.001875  Loss: -0.4814  Acc@1: 68.7500 (64.4843)  Acc@5: 93.7500 (91.5089)  time: 0.3840  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1250/4579]  eta: 0:22:31  Lr: 0.001875  Loss: -0.3812  Acc@1: 62.5000 (64.4834)  Acc@5: 93.7500 (91.5168)  time: 0.3866  data: 0.0020  max mem: 2500
Train: Epoch[4/5]  [1260/4579]  eta: 0:22:26  Lr: 0.001875  Loss: -0.1919  Acc@1: 68.7500 (64.5619)  Acc@5: 93.7500 (91.5345)  time: 0.3892  data: 0.0019  max mem: 2500
Train: Epoch[4/5]  [1270/4579]  eta: 0:22:22  Lr: 0.001875  Loss: -0.2802  Acc@1: 68.7500 (64.5210)  Acc@5: 93.7500 (91.5273)  time: 0.3855  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1280/4579]  eta: 0:22:17  Lr: 0.001875  Loss: -0.0947  Acc@1: 62.5000 (64.5199)  Acc@5: 93.7500 (91.5544)  time: 0.3853  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1290/4579]  eta: 0:22:13  Lr: 0.001875  Loss: 0.4106  Acc@1: 62.5000 (64.4849)  Acc@5: 93.7500 (91.5376)  time: 0.3876  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1300/4579]  eta: 0:22:08  Lr: 0.001875  Loss: -0.6629  Acc@1: 62.5000 (64.4889)  Acc@5: 93.7500 (91.5402)  time: 0.3856  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [1310/4579]  eta: 0:22:03  Lr: 0.001875  Loss: -0.3165  Acc@1: 62.5000 (64.4785)  Acc@5: 93.7500 (91.5284)  time: 0.3688  data: 0.0024  max mem: 2500
Train: Epoch[4/5]  [1320/4579]  eta: 0:21:57  Lr: 0.001875  Loss: 0.4048  Acc@1: 62.5000 (64.4587)  Acc@5: 93.7500 (91.5263)  time: 0.3521  data: 0.0021  max mem: 2500
Train: Epoch[4/5]  [1330/4579]  eta: 0:21:52  Lr: 0.001875  Loss: -0.4961  Acc@1: 68.7500 (64.4957)  Acc@5: 93.7500 (91.5242)  time: 0.3488  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1340/4579]  eta: 0:21:47  Lr: 0.001875  Loss: -0.1838  Acc@1: 68.7500 (64.4994)  Acc@5: 87.5000 (91.4896)  time: 0.3490  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [1350/4579]  eta: 0:21:41  Lr: 0.001875  Loss: -0.3751  Acc@1: 68.7500 (64.4893)  Acc@5: 87.5000 (91.4970)  time: 0.3498  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [1360/4579]  eta: 0:21:36  Lr: 0.001875  Loss: -0.4075  Acc@1: 62.5000 (64.4425)  Acc@5: 87.5000 (91.4814)  time: 0.3485  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [1370/4579]  eta: 0:21:31  Lr: 0.001875  Loss: -0.6205  Acc@1: 62.5000 (64.4420)  Acc@5: 87.5000 (91.4798)  time: 0.3503  data: 0.0016  max mem: 2500
Train: Epoch[4/5]  [1380/4579]  eta: 0:21:25  Lr: 0.001875  Loss: 0.0530  Acc@1: 68.7500 (64.4732)  Acc@5: 93.7500 (91.5052)  time: 0.3500  data: 0.0016  max mem: 2500
Train: Epoch[4/5]  [1390/4579]  eta: 0:21:20  Lr: 0.001875  Loss: -0.4908  Acc@1: 68.7500 (64.4725)  Acc@5: 93.7500 (91.5169)  time: 0.3493  data: 0.0018  max mem: 2500
Train: Epoch[4/5]  [1400/4579]  eta: 0:21:15  Lr: 0.001875  Loss: -0.5017  Acc@1: 56.2500 (64.4495)  Acc@5: 93.7500 (91.5150)  time: 0.3505  data: 0.0027  max mem: 2500
Train: Epoch[4/5]  [1410/4579]  eta: 0:21:10  Lr: 0.001875  Loss: -0.5852  Acc@1: 62.5000 (64.4977)  Acc@5: 93.7500 (91.5397)  time: 0.3489  data: 0.0014  max mem: 2500
Train: Epoch[4/5]  [1420/4579]  eta: 0:21:05  Lr: 0.001875  Loss: -0.5254  Acc@1: 62.5000 (64.4880)  Acc@5: 93.7500 (91.5464)  time: 0.3474  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [1430/4579]  eta: 0:20:59  Lr: 0.001875  Loss: -0.4532  Acc@1: 62.5000 (64.4960)  Acc@5: 93.7500 (91.5531)  time: 0.3484  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [1440/4579]  eta: 0:20:54  Lr: 0.001875  Loss: -0.5817  Acc@1: 62.5000 (64.4908)  Acc@5: 93.7500 (91.5553)  time: 0.3485  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [1450/4579]  eta: 0:20:49  Lr: 0.001875  Loss: -0.5704  Acc@1: 68.7500 (64.5503)  Acc@5: 93.7500 (91.5791)  time: 0.3471  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [1460/4579]  eta: 0:20:44  Lr: 0.001875  Loss: -0.5454  Acc@1: 68.7500 (64.5448)  Acc@5: 93.7500 (91.5854)  time: 0.3473  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1470/4579]  eta: 0:20:39  Lr: 0.001875  Loss: -0.0764  Acc@1: 62.5000 (64.5267)  Acc@5: 93.7500 (91.5916)  time: 0.3478  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1480/4579]  eta: 0:20:34  Lr: 0.001875  Loss: -0.3587  Acc@1: 62.5000 (64.5130)  Acc@5: 93.7500 (91.6146)  time: 0.3478  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1490/4579]  eta: 0:20:29  Lr: 0.001875  Loss: -0.2400  Acc@1: 62.5000 (64.4995)  Acc@5: 93.7500 (91.6331)  time: 0.3481  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1500/4579]  eta: 0:20:24  Lr: 0.001875  Loss: -0.1776  Acc@1: 62.5000 (64.5361)  Acc@5: 93.7500 (91.6431)  time: 0.3488  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1510/4579]  eta: 0:20:19  Lr: 0.001875  Loss: -0.0625  Acc@1: 62.5000 (64.5392)  Acc@5: 87.5000 (91.6239)  time: 0.3489  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1520/4579]  eta: 0:20:14  Lr: 0.001875  Loss: -0.0292  Acc@1: 62.5000 (64.5053)  Acc@5: 87.5000 (91.6297)  time: 0.3492  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [1530/4579]  eta: 0:20:09  Lr: 0.001875  Loss: -0.1861  Acc@1: 68.7500 (64.5371)  Acc@5: 93.7500 (91.6476)  time: 0.3500  data: 0.0018  max mem: 2500
Train: Epoch[4/5]  [1540/4579]  eta: 0:20:04  Lr: 0.001875  Loss: -0.2336  Acc@1: 68.7500 (64.5604)  Acc@5: 93.7500 (91.6572)  time: 0.3511  data: 0.0016  max mem: 2500
Train: Epoch[4/5]  [1550/4579]  eta: 0:19:59  Lr: 0.001875  Loss: -0.1395  Acc@1: 62.5000 (64.5430)  Acc@5: 93.7500 (91.6425)  time: 0.3513  data: 0.0010  max mem: 2500
Train: Epoch[4/5]  [1560/4579]  eta: 0:19:55  Lr: 0.001875  Loss: -0.3714  Acc@1: 56.2500 (64.5179)  Acc@5: 93.7500 (91.6440)  time: 0.3497  data: 0.0011  max mem: 2500
Train: Epoch[4/5]  [1570/4579]  eta: 0:19:50  Lr: 0.001875  Loss: -0.4381  Acc@1: 56.2500 (64.5011)  Acc@5: 93.7500 (91.6733)  time: 0.3494  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [1580/4579]  eta: 0:19:45  Lr: 0.001875  Loss: 0.1507  Acc@1: 62.5000 (64.5003)  Acc@5: 93.7500 (91.6706)  time: 0.3497  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [1590/4579]  eta: 0:19:40  Lr: 0.001875  Loss: -0.5240  Acc@1: 68.7500 (64.4838)  Acc@5: 93.7500 (91.6915)  time: 0.3499  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [1600/4579]  eta: 0:19:35  Lr: 0.001875  Loss: -0.7163  Acc@1: 62.5000 (64.4753)  Acc@5: 93.7500 (91.6927)  time: 0.3497  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [1610/4579]  eta: 0:19:31  Lr: 0.001875  Loss: -0.6785  Acc@1: 62.5000 (64.4514)  Acc@5: 87.5000 (91.6705)  time: 0.3492  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1620/4579]  eta: 0:19:26  Lr: 0.001875  Loss: -0.3814  Acc@1: 62.5000 (64.4471)  Acc@5: 87.5000 (91.6757)  time: 0.3497  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1630/4579]  eta: 0:19:21  Lr: 0.001875  Loss: -0.9703  Acc@1: 62.5000 (64.4582)  Acc@5: 93.7500 (91.6922)  time: 0.3499  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [1640/4579]  eta: 0:19:16  Lr: 0.001875  Loss: -0.3708  Acc@1: 62.5000 (64.4310)  Acc@5: 93.7500 (91.6857)  time: 0.3496  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [1650/4579]  eta: 0:19:12  Lr: 0.001875  Loss: -0.3125  Acc@1: 56.2500 (64.4041)  Acc@5: 93.7500 (91.6755)  time: 0.3507  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [1660/4579]  eta: 0:19:07  Lr: 0.001875  Loss: -0.3079  Acc@1: 62.5000 (64.3776)  Acc@5: 87.5000 (91.6428)  time: 0.3515  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [1670/4579]  eta: 0:19:02  Lr: 0.001875  Loss: 0.4239  Acc@1: 62.5000 (64.3627)  Acc@5: 87.5000 (91.6180)  time: 0.3502  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [1680/4579]  eta: 0:18:58  Lr: 0.001875  Loss: -0.8802  Acc@1: 62.5000 (64.3590)  Acc@5: 93.7500 (91.6084)  time: 0.3494  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [1690/4579]  eta: 0:18:53  Lr: 0.001875  Loss: 0.0457  Acc@1: 68.7500 (64.3850)  Acc@5: 93.7500 (91.6063)  time: 0.3516  data: 0.0012  max mem: 2500
Train: Epoch[4/5]  [1700/4579]  eta: 0:18:48  Lr: 0.001875  Loss: -0.0334  Acc@1: 68.7500 (64.4253)  Acc@5: 87.5000 (91.6042)  time: 0.3524  data: 0.0010  max mem: 2500
Train: Epoch[4/5]  [1710/4579]  eta: 0:18:44  Lr: 0.001875  Loss: -0.2364  Acc@1: 62.5000 (64.4177)  Acc@5: 93.7500 (91.6314)  time: 0.3521  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [1720/4579]  eta: 0:18:39  Lr: 0.001875  Loss: -0.5451  Acc@1: 56.2500 (64.4175)  Acc@5: 93.7500 (91.6110)  time: 0.3515  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [1730/4579]  eta: 0:18:35  Lr: 0.001875  Loss: -0.6208  Acc@1: 62.5000 (64.3847)  Acc@5: 87.5000 (91.6125)  time: 0.3494  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [1740/4579]  eta: 0:18:30  Lr: 0.001875  Loss: -0.3973  Acc@1: 62.5000 (64.3775)  Acc@5: 93.7500 (91.6068)  time: 0.3538  data: 0.0025  max mem: 2500
Train: Epoch[4/5]  [1750/4579]  eta: 0:18:26  Lr: 0.001875  Loss: -0.4326  Acc@1: 62.5000 (64.3597)  Acc@5: 93.7500 (91.5941)  time: 0.3538  data: 0.0026  max mem: 2500
Train: Epoch[4/5]  [1760/4579]  eta: 0:18:21  Lr: 0.001875  Loss: -0.4934  Acc@1: 62.5000 (64.3881)  Acc@5: 93.7500 (91.5957)  time: 0.3490  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [1770/4579]  eta: 0:18:16  Lr: 0.001875  Loss: -0.2692  Acc@1: 62.5000 (64.3845)  Acc@5: 93.7500 (91.5796)  time: 0.3492  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [1780/4579]  eta: 0:18:12  Lr: 0.001875  Loss: -0.6381  Acc@1: 62.5000 (64.4125)  Acc@5: 93.7500 (91.5918)  time: 0.3486  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [1790/4579]  eta: 0:18:07  Lr: 0.001875  Loss: -0.1232  Acc@1: 68.7500 (64.4368)  Acc@5: 93.7500 (91.5969)  time: 0.3491  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [1800/4579]  eta: 0:18:03  Lr: 0.001875  Loss: -0.3878  Acc@1: 68.7500 (64.4538)  Acc@5: 93.7500 (91.6192)  time: 0.3500  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [1810/4579]  eta: 0:17:58  Lr: 0.001875  Loss: -0.9748  Acc@1: 68.7500 (64.4671)  Acc@5: 93.7500 (91.6241)  time: 0.3498  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [1820/4579]  eta: 0:17:54  Lr: 0.001875  Loss: -0.7584  Acc@1: 62.5000 (64.4632)  Acc@5: 93.7500 (91.6152)  time: 0.3488  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [1830/4579]  eta: 0:17:49  Lr: 0.001875  Loss: -0.9159  Acc@1: 62.5000 (64.4627)  Acc@5: 93.7500 (91.6234)  time: 0.3493  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [1840/4579]  eta: 0:17:45  Lr: 0.001875  Loss: -0.0886  Acc@1: 62.5000 (64.4351)  Acc@5: 93.7500 (91.6112)  time: 0.3504  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [1850/4579]  eta: 0:17:40  Lr: 0.001875  Loss: -0.6342  Acc@1: 62.5000 (64.4314)  Acc@5: 93.7500 (91.6160)  time: 0.3494  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1860/4579]  eta: 0:17:36  Lr: 0.001875  Loss: -0.5062  Acc@1: 62.5000 (64.4009)  Acc@5: 93.7500 (91.6107)  time: 0.3484  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1870/4579]  eta: 0:17:31  Lr: 0.001875  Loss: -0.7883  Acc@1: 62.5000 (64.4308)  Acc@5: 93.7500 (91.6188)  time: 0.3479  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [1880/4579]  eta: 0:17:27  Lr: 0.001875  Loss: -0.8096  Acc@1: 62.5000 (64.3840)  Acc@5: 93.7500 (91.6135)  time: 0.3478  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1890/4579]  eta: 0:17:22  Lr: 0.001875  Loss: -0.6335  Acc@1: 62.5000 (64.3806)  Acc@5: 93.7500 (91.6083)  time: 0.3488  data: 0.0011  max mem: 2500
Train: Epoch[4/5]  [1900/4579]  eta: 0:17:18  Lr: 0.001875  Loss: -0.0854  Acc@1: 62.5000 (64.3707)  Acc@5: 93.7500 (91.5900)  time: 0.3486  data: 0.0011  max mem: 2500
Train: Epoch[4/5]  [1910/4579]  eta: 0:17:14  Lr: 0.001875  Loss: 0.3291  Acc@1: 62.5000 (64.3609)  Acc@5: 87.5000 (91.5653)  time: 0.3473  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1920/4579]  eta: 0:17:09  Lr: 0.001875  Loss: -0.7756  Acc@1: 68.7500 (64.3935)  Acc@5: 93.7500 (91.5799)  time: 0.3488  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [1930/4579]  eta: 0:17:05  Lr: 0.001875  Loss: -0.7578  Acc@1: 68.7500 (64.4226)  Acc@5: 93.7500 (91.6073)  time: 0.3503  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [1940/4579]  eta: 0:17:00  Lr: 0.001875  Loss: 0.0176  Acc@1: 62.5000 (64.4062)  Acc@5: 93.7500 (91.6055)  time: 0.3494  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [1950/4579]  eta: 0:16:56  Lr: 0.001875  Loss: -0.8461  Acc@1: 68.7500 (64.4541)  Acc@5: 93.7500 (91.6261)  time: 0.3493  data: 0.0012  max mem: 2500
Train: Epoch[4/5]  [1960/4579]  eta: 0:16:52  Lr: 0.001875  Loss: -0.2974  Acc@1: 68.7500 (64.4410)  Acc@5: 93.7500 (91.6305)  time: 0.3488  data: 0.0012  max mem: 2500
Train: Epoch[4/5]  [1970/4579]  eta: 0:16:47  Lr: 0.001875  Loss: 0.0092  Acc@1: 56.2500 (64.3836)  Acc@5: 87.5000 (91.6128)  time: 0.3477  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [1980/4579]  eta: 0:16:43  Lr: 0.001875  Loss: -0.1097  Acc@1: 56.2500 (64.3677)  Acc@5: 87.5000 (91.6015)  time: 0.3476  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1990/4579]  eta: 0:16:39  Lr: 0.001875  Loss: -0.3076  Acc@1: 62.5000 (64.3364)  Acc@5: 81.2500 (91.5620)  time: 0.3487  data: 0.0020  max mem: 2500
Train: Epoch[4/5]  [2000/4579]  eta: 0:16:34  Lr: 0.001875  Loss: -0.3399  Acc@1: 62.5000 (64.3553)  Acc@5: 87.5000 (91.5511)  time: 0.3496  data: 0.0026  max mem: 2500
Train: Epoch[4/5]  [2010/4579]  eta: 0:16:30  Lr: 0.001875  Loss: -0.5644  Acc@1: 62.5000 (64.3492)  Acc@5: 87.5000 (91.5558)  time: 0.3486  data: 0.0010  max mem: 2500
Train: Epoch[4/5]  [2020/4579]  eta: 0:16:26  Lr: 0.001875  Loss: 0.0063  Acc@1: 62.5000 (64.3462)  Acc@5: 93.7500 (91.5574)  time: 0.3477  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2030/4579]  eta: 0:16:21  Lr: 0.001875  Loss: -0.9137  Acc@1: 62.5000 (64.3433)  Acc@5: 93.7500 (91.5467)  time: 0.3480  data: 0.0011  max mem: 2500
Train: Epoch[4/5]  [2040/4579]  eta: 0:16:17  Lr: 0.001875  Loss: -0.5038  Acc@1: 62.5000 (64.3557)  Acc@5: 93.7500 (91.5666)  time: 0.3493  data: 0.0011  max mem: 2500
Train: Epoch[4/5]  [2050/4579]  eta: 0:16:13  Lr: 0.001875  Loss: -0.3369  Acc@1: 68.7500 (64.3528)  Acc@5: 93.7500 (91.5712)  time: 0.3483  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2060/4579]  eta: 0:16:08  Lr: 0.001875  Loss: -0.3670  Acc@1: 62.5000 (64.3498)  Acc@5: 93.7500 (91.5848)  time: 0.3460  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2070/4579]  eta: 0:16:04  Lr: 0.001875  Loss: -0.6738  Acc@1: 62.5000 (64.3530)  Acc@5: 93.7500 (91.6073)  time: 0.3458  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2080/4579]  eta: 0:16:00  Lr: 0.001875  Loss: -0.1981  Acc@1: 62.5000 (64.3351)  Acc@5: 93.7500 (91.5846)  time: 0.3477  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [2090/4579]  eta: 0:15:55  Lr: 0.001875  Loss: -0.7167  Acc@1: 62.5000 (64.3382)  Acc@5: 87.5000 (91.5860)  time: 0.3486  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2100/4579]  eta: 0:15:51  Lr: 0.001875  Loss: 0.0328  Acc@1: 62.5000 (64.3354)  Acc@5: 87.5000 (91.5814)  time: 0.3474  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [2110/4579]  eta: 0:15:47  Lr: 0.001875  Loss: -0.4755  Acc@1: 62.5000 (64.3415)  Acc@5: 93.7500 (91.5887)  time: 0.3471  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2120/4579]  eta: 0:15:43  Lr: 0.001875  Loss: -0.1480  Acc@1: 68.7500 (64.3564)  Acc@5: 93.7500 (91.5871)  time: 0.3481  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2130/4579]  eta: 0:15:38  Lr: 0.001875  Loss: -0.2971  Acc@1: 68.7500 (64.3829)  Acc@5: 93.7500 (91.5914)  time: 0.3481  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2140/4579]  eta: 0:15:34  Lr: 0.001875  Loss: -0.3415  Acc@1: 62.5000 (64.3566)  Acc@5: 93.7500 (91.5840)  time: 0.3484  data: 0.0010  max mem: 2500
Train: Epoch[4/5]  [2150/4579]  eta: 0:15:30  Lr: 0.001875  Loss: -0.5058  Acc@1: 62.5000 (64.3683)  Acc@5: 93.7500 (91.5940)  time: 0.3492  data: 0.0011  max mem: 2500
Train: Epoch[4/5]  [2160/4579]  eta: 0:15:26  Lr: 0.001875  Loss: -0.7986  Acc@1: 62.5000 (64.3770)  Acc@5: 93.7500 (91.5982)  time: 0.3485  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2170/4579]  eta: 0:15:22  Lr: 0.001875  Loss: -0.3695  Acc@1: 62.5000 (64.3770)  Acc@5: 87.5000 (91.5851)  time: 0.3483  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2180/4579]  eta: 0:15:17  Lr: 0.001875  Loss: -0.6475  Acc@1: 62.5000 (64.3827)  Acc@5: 93.7500 (91.5922)  time: 0.3488  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2190/4579]  eta: 0:15:13  Lr: 0.001875  Loss: -0.0301  Acc@1: 62.5000 (64.3827)  Acc@5: 93.7500 (91.5877)  time: 0.3487  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2200/4579]  eta: 0:15:09  Lr: 0.001875  Loss: -0.6026  Acc@1: 62.5000 (64.3940)  Acc@5: 93.7500 (91.5862)  time: 0.3494  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [2210/4579]  eta: 0:15:05  Lr: 0.001875  Loss: -0.5995  Acc@1: 68.7500 (64.4081)  Acc@5: 93.7500 (91.5932)  time: 0.3498  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [2220/4579]  eta: 0:15:01  Lr: 0.001875  Loss: -0.1352  Acc@1: 68.7500 (64.4051)  Acc@5: 93.7500 (91.5888)  time: 0.3484  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [2230/4579]  eta: 0:14:56  Lr: 0.001875  Loss: -0.4770  Acc@1: 62.5000 (64.3938)  Acc@5: 93.7500 (91.5929)  time: 0.3481  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [2240/4579]  eta: 0:14:52  Lr: 0.001875  Loss: -0.5881  Acc@1: 62.5000 (64.4132)  Acc@5: 93.7500 (91.5997)  time: 0.3486  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2250/4579]  eta: 0:14:48  Lr: 0.001875  Loss: -0.3015  Acc@1: 68.7500 (64.4269)  Acc@5: 93.7500 (91.6037)  time: 0.3491  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [2260/4579]  eta: 0:14:44  Lr: 0.001875  Loss: -0.4770  Acc@1: 68.7500 (64.4488)  Acc@5: 93.7500 (91.6105)  time: 0.3499  data: 0.0013  max mem: 2500
Train: Epoch[4/5]  [2270/4579]  eta: 0:14:40  Lr: 0.001875  Loss: 0.0607  Acc@1: 68.7500 (64.4650)  Acc@5: 93.7500 (91.6006)  time: 0.3499  data: 0.0014  max mem: 2500
Train: Epoch[4/5]  [2280/4579]  eta: 0:14:36  Lr: 0.001875  Loss: -0.8795  Acc@1: 68.7500 (64.4756)  Acc@5: 93.7500 (91.5963)  time: 0.3488  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [2290/4579]  eta: 0:14:32  Lr: 0.001875  Loss: -1.0403  Acc@1: 68.7500 (64.5051)  Acc@5: 93.7500 (91.6112)  time: 0.3493  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [2300/4579]  eta: 0:14:27  Lr: 0.001875  Loss: -0.1361  Acc@1: 68.7500 (64.4964)  Acc@5: 93.7500 (91.5960)  time: 0.3493  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [2310/4579]  eta: 0:14:23  Lr: 0.001875  Loss: -0.7377  Acc@1: 68.7500 (64.5256)  Acc@5: 93.7500 (91.6189)  time: 0.3485  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [2320/4579]  eta: 0:14:19  Lr: 0.001875  Loss: -0.4766  Acc@1: 68.7500 (64.5546)  Acc@5: 93.7500 (91.6227)  time: 0.3504  data: 0.0010  max mem: 2500
Train: Epoch[4/5]  [2330/4579]  eta: 0:14:15  Lr: 0.001875  Loss: -0.2543  Acc@1: 68.7500 (64.5565)  Acc@5: 93.7500 (91.6291)  time: 0.3507  data: 0.0012  max mem: 2500
Train: Epoch[4/5]  [2340/4579]  eta: 0:14:11  Lr: 0.001875  Loss: 0.0977  Acc@1: 68.7500 (64.5504)  Acc@5: 93.7500 (91.6302)  time: 0.3498  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [2350/4579]  eta: 0:14:07  Lr: 0.001875  Loss: -0.1940  Acc@1: 62.5000 (64.5364)  Acc@5: 93.7500 (91.6445)  time: 0.3505  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2360/4579]  eta: 0:14:03  Lr: 0.001875  Loss: -0.5261  Acc@1: 62.5000 (64.5277)  Acc@5: 93.7500 (91.6428)  time: 0.3506  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [2370/4579]  eta: 0:13:59  Lr: 0.001875  Loss: -0.5904  Acc@1: 68.7500 (64.5535)  Acc@5: 93.7500 (91.6517)  time: 0.3496  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [2380/4579]  eta: 0:13:55  Lr: 0.001875  Loss: -0.2958  Acc@1: 68.7500 (64.5501)  Acc@5: 93.7500 (91.6605)  time: 0.3504  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2390/4579]  eta: 0:13:51  Lr: 0.001875  Loss: 0.3033  Acc@1: 56.2500 (64.5101)  Acc@5: 93.7500 (91.6405)  time: 0.3513  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2400/4579]  eta: 0:13:47  Lr: 0.001875  Loss: -0.1721  Acc@1: 56.2500 (64.5096)  Acc@5: 93.7500 (91.6493)  time: 0.3516  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [2410/4579]  eta: 0:13:43  Lr: 0.001875  Loss: -0.1022  Acc@1: 62.5000 (64.5012)  Acc@5: 93.7500 (91.6528)  time: 0.3523  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2420/4579]  eta: 0:13:39  Lr: 0.001875  Loss: -0.6170  Acc@1: 62.5000 (64.4930)  Acc@5: 93.7500 (91.6409)  time: 0.3523  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2430/4579]  eta: 0:13:34  Lr: 0.001875  Loss: -0.3670  Acc@1: 68.7500 (64.5593)  Acc@5: 93.7500 (91.6547)  time: 0.3508  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2440/4579]  eta: 0:13:30  Lr: 0.001875  Loss: -0.4821  Acc@1: 75.0000 (64.5739)  Acc@5: 93.7500 (91.6581)  time: 0.3489  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2450/4579]  eta: 0:13:26  Lr: 0.001875  Loss: -0.0265  Acc@1: 68.7500 (64.5757)  Acc@5: 93.7500 (91.6667)  time: 0.3506  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2460/4579]  eta: 0:13:22  Lr: 0.001875  Loss: -0.5134  Acc@1: 62.5000 (64.5698)  Acc@5: 93.7500 (91.6574)  time: 0.3516  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2470/4579]  eta: 0:13:18  Lr: 0.001875  Loss: -0.2915  Acc@1: 62.5000 (64.5614)  Acc@5: 87.5000 (91.6456)  time: 0.3494  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2480/4579]  eta: 0:13:14  Lr: 0.001875  Loss: -0.1569  Acc@1: 62.5000 (64.5707)  Acc@5: 93.7500 (91.6692)  time: 0.3481  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2490/4579]  eta: 0:13:10  Lr: 0.001875  Loss: -0.7367  Acc@1: 68.7500 (64.5750)  Acc@5: 93.7500 (91.6625)  time: 0.3484  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [2500/4579]  eta: 0:13:06  Lr: 0.001875  Loss: -0.7916  Acc@1: 68.7500 (64.5842)  Acc@5: 93.7500 (91.6708)  time: 0.3501  data: 0.0017  max mem: 2500
Train: Epoch[4/5]  [2510/4579]  eta: 0:13:02  Lr: 0.001875  Loss: -0.5189  Acc@1: 68.7500 (64.6008)  Acc@5: 93.7500 (91.6692)  time: 0.3503  data: 0.0014  max mem: 2500
Train: Epoch[4/5]  [2520/4579]  eta: 0:12:58  Lr: 0.001875  Loss: -0.2791  Acc@1: 62.5000 (64.5924)  Acc@5: 87.5000 (91.6650)  time: 0.3485  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2530/4579]  eta: 0:12:54  Lr: 0.001875  Loss: -0.1835  Acc@1: 62.5000 (64.5842)  Acc@5: 93.7500 (91.6708)  time: 0.3499  data: 0.0011  max mem: 2500
Train: Epoch[4/5]  [2540/4579]  eta: 0:12:50  Lr: 0.001875  Loss: -0.4191  Acc@1: 62.5000 (64.5686)  Acc@5: 93.7500 (91.6765)  time: 0.3511  data: 0.0011  max mem: 2500
Train: Epoch[4/5]  [2550/4579]  eta: 0:12:46  Lr: 0.001875  Loss: -0.7957  Acc@1: 62.5000 (64.5629)  Acc@5: 93.7500 (91.6699)  time: 0.3486  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2560/4579]  eta: 0:12:42  Lr: 0.001875  Loss: 0.0254  Acc@1: 62.5000 (64.5671)  Acc@5: 87.5000 (91.6634)  time: 0.3478  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2570/4579]  eta: 0:12:38  Lr: 0.001875  Loss: -0.3839  Acc@1: 62.5000 (64.5712)  Acc@5: 93.7500 (91.6740)  time: 0.3485  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [2580/4579]  eta: 0:12:34  Lr: 0.001875  Loss: -0.1392  Acc@1: 62.5000 (64.5753)  Acc@5: 87.5000 (91.6554)  time: 0.3485  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [2590/4579]  eta: 0:12:30  Lr: 0.001875  Loss: 0.3023  Acc@1: 68.7500 (64.5865)  Acc@5: 87.5000 (91.6466)  time: 0.3505  data: 0.0016  max mem: 2500
Train: Epoch[4/5]  [2600/4579]  eta: 0:12:26  Lr: 0.001875  Loss: -0.7103  Acc@1: 68.7500 (64.6194)  Acc@5: 93.7500 (91.6619)  time: 0.3506  data: 0.0016  max mem: 2500
Train: Epoch[4/5]  [2610/4579]  eta: 0:12:22  Lr: 0.001875  Loss: -0.0671  Acc@1: 68.7500 (64.6256)  Acc@5: 93.7500 (91.6770)  time: 0.3490  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [2620/4579]  eta: 0:12:18  Lr: 0.001875  Loss: -0.2258  Acc@1: 62.5000 (64.6223)  Acc@5: 93.7500 (91.6802)  time: 0.3504  data: 0.0011  max mem: 2500
Train: Epoch[4/5]  [2630/4579]  eta: 0:12:14  Lr: 0.001875  Loss: -0.2523  Acc@1: 62.5000 (64.6403)  Acc@5: 93.7500 (91.6809)  time: 0.3503  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [2640/4579]  eta: 0:12:10  Lr: 0.001875  Loss: 0.0789  Acc@1: 68.7500 (64.6346)  Acc@5: 93.7500 (91.6698)  time: 0.3497  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2650/4579]  eta: 0:12:06  Lr: 0.001875  Loss: -0.6729  Acc@1: 62.5000 (64.6501)  Acc@5: 93.7500 (91.6777)  time: 0.3498  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2660/4579]  eta: 0:12:02  Lr: 0.001875  Loss: -0.2140  Acc@1: 62.5000 (64.6162)  Acc@5: 93.7500 (91.6667)  time: 0.3502  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [2670/4579]  eta: 0:11:58  Lr: 0.001875  Loss: 0.5539  Acc@1: 62.5000 (64.6364)  Acc@5: 93.7500 (91.6628)  time: 0.3502  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [2680/4579]  eta: 0:11:54  Lr: 0.001875  Loss: -0.2280  Acc@1: 62.5000 (64.6377)  Acc@5: 87.5000 (91.6472)  time: 0.3491  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2690/4579]  eta: 0:11:50  Lr: 0.001875  Loss: -0.3871  Acc@1: 62.5000 (64.6228)  Acc@5: 87.5000 (91.6458)  time: 0.3496  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2700/4579]  eta: 0:11:47  Lr: 0.001875  Loss: -0.2945  Acc@1: 62.5000 (64.6196)  Acc@5: 87.5000 (91.6397)  time: 0.3497  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [2710/4579]  eta: 0:11:43  Lr: 0.001875  Loss: -0.1144  Acc@1: 62.5000 (64.6118)  Acc@5: 87.5000 (91.6290)  time: 0.3498  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [2720/4579]  eta: 0:11:39  Lr: 0.001875  Loss: 0.1657  Acc@1: 62.5000 (64.6063)  Acc@5: 87.5000 (91.6207)  time: 0.3514  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [2730/4579]  eta: 0:11:35  Lr: 0.001875  Loss: -0.5512  Acc@1: 56.2500 (64.5986)  Acc@5: 93.7500 (91.6171)  time: 0.3507  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [2740/4579]  eta: 0:11:31  Lr: 0.001875  Loss: -0.8935  Acc@1: 62.5000 (64.6092)  Acc@5: 93.7500 (91.6157)  time: 0.3499  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [2750/4579]  eta: 0:11:27  Lr: 0.001875  Loss: -0.4278  Acc@1: 62.5000 (64.5901)  Acc@5: 87.5000 (91.6031)  time: 0.3499  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2760/4579]  eta: 0:11:23  Lr: 0.001875  Loss: -0.4229  Acc@1: 56.2500 (64.5690)  Acc@5: 87.5000 (91.5905)  time: 0.3511  data: 0.0016  max mem: 2500
Train: Epoch[4/5]  [2770/4579]  eta: 0:11:19  Lr: 0.001875  Loss: 0.0481  Acc@1: 56.2500 (64.5525)  Acc@5: 87.5000 (91.5892)  time: 0.3518  data: 0.0015  max mem: 2500
Train: Epoch[4/5]  [2780/4579]  eta: 0:11:15  Lr: 0.001875  Loss: -0.2236  Acc@1: 56.2500 (64.5564)  Acc@5: 93.7500 (91.5903)  time: 0.3503  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2790/4579]  eta: 0:11:11  Lr: 0.001875  Loss: -0.2297  Acc@1: 68.7500 (64.5714)  Acc@5: 93.7500 (91.6002)  time: 0.3511  data: 0.0014  max mem: 2500
Train: Epoch[4/5]  [2800/4579]  eta: 0:11:07  Lr: 0.001875  Loss: -0.6987  Acc@1: 68.7500 (64.5640)  Acc@5: 93.7500 (91.6034)  time: 0.3510  data: 0.0015  max mem: 2500
Train: Epoch[4/5]  [2810/4579]  eta: 0:11:03  Lr: 0.001875  Loss: -0.6313  Acc@1: 75.0000 (64.6056)  Acc@5: 93.7500 (91.6066)  time: 0.3513  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2820/4579]  eta: 0:10:59  Lr: 0.001875  Loss: -0.0797  Acc@1: 75.0000 (64.6180)  Acc@5: 93.7500 (91.5987)  time: 0.3507  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2830/4579]  eta: 0:10:56  Lr: 0.001875  Loss: 0.1891  Acc@1: 68.7500 (64.6084)  Acc@5: 93.7500 (91.5887)  time: 0.3491  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2840/4579]  eta: 0:10:52  Lr: 0.001875  Loss: -0.4798  Acc@1: 68.7500 (64.6273)  Acc@5: 93.7500 (91.5853)  time: 0.3504  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [2850/4579]  eta: 0:10:48  Lr: 0.001875  Loss: -0.7308  Acc@1: 62.5000 (64.6264)  Acc@5: 93.7500 (91.5951)  time: 0.3510  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [2860/4579]  eta: 0:10:44  Lr: 0.001875  Loss: -0.7295  Acc@1: 62.5000 (64.6452)  Acc@5: 93.7500 (91.6048)  time: 0.3505  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [2870/4579]  eta: 0:10:40  Lr: 0.001875  Loss: 0.2894  Acc@1: 56.2500 (64.6203)  Acc@5: 93.7500 (91.6014)  time: 0.3503  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [2880/4579]  eta: 0:10:36  Lr: 0.001875  Loss: -0.4853  Acc@1: 62.5000 (64.6260)  Acc@5: 93.7500 (91.6045)  time: 0.3497  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2890/4579]  eta: 0:10:32  Lr: 0.001875  Loss: -0.5939  Acc@1: 62.5000 (64.6100)  Acc@5: 93.7500 (91.6076)  time: 0.3501  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2900/4579]  eta: 0:10:28  Lr: 0.001875  Loss: -0.7372  Acc@1: 56.2500 (64.6113)  Acc@5: 93.7500 (91.6171)  time: 0.3506  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2910/4579]  eta: 0:10:24  Lr: 0.001875  Loss: -0.6887  Acc@1: 68.7500 (64.5955)  Acc@5: 93.7500 (91.6094)  time: 0.3514  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2920/4579]  eta: 0:10:21  Lr: 0.001875  Loss: -0.3148  Acc@1: 62.5000 (64.5819)  Acc@5: 87.5000 (91.6103)  time: 0.3513  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [2930/4579]  eta: 0:10:17  Lr: 0.001875  Loss: 0.0587  Acc@1: 62.5000 (64.5961)  Acc@5: 93.7500 (91.6112)  time: 0.3497  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2940/4579]  eta: 0:10:13  Lr: 0.001875  Loss: -0.2006  Acc@1: 68.7500 (64.6103)  Acc@5: 93.7500 (91.6164)  time: 0.3500  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [2950/4579]  eta: 0:10:09  Lr: 0.001875  Loss: -0.4595  Acc@1: 68.7500 (64.6200)  Acc@5: 93.7500 (91.6151)  time: 0.3506  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2960/4579]  eta: 0:10:05  Lr: 0.001875  Loss: -0.4547  Acc@1: 68.7500 (64.6150)  Acc@5: 93.7500 (91.6181)  time: 0.3508  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2970/4579]  eta: 0:10:01  Lr: 0.001875  Loss: -0.7662  Acc@1: 62.5000 (64.6142)  Acc@5: 93.7500 (91.6169)  time: 0.3506  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2980/4579]  eta: 0:09:57  Lr: 0.001875  Loss: -0.4977  Acc@1: 62.5000 (64.6218)  Acc@5: 93.7500 (91.6198)  time: 0.3501  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2990/4579]  eta: 0:09:53  Lr: 0.001875  Loss: -0.5208  Acc@1: 68.7500 (64.6251)  Acc@5: 93.7500 (91.6270)  time: 0.3503  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [3000/4579]  eta: 0:09:50  Lr: 0.001875  Loss: -0.7126  Acc@1: 68.7500 (64.6368)  Acc@5: 93.7500 (91.6278)  time: 0.3503  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3010/4579]  eta: 0:09:46  Lr: 0.001875  Loss: -0.3310  Acc@1: 68.7500 (64.6421)  Acc@5: 87.5000 (91.6203)  time: 0.3507  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3020/4579]  eta: 0:09:42  Lr: 0.001875  Loss: -0.4890  Acc@1: 68.7500 (64.6495)  Acc@5: 93.7500 (91.6212)  time: 0.3511  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3030/4579]  eta: 0:09:38  Lr: 0.001875  Loss: -0.9146  Acc@1: 68.7500 (64.6466)  Acc@5: 93.7500 (91.6179)  time: 0.3515  data: 0.0015  max mem: 2500
Train: Epoch[4/5]  [3040/4579]  eta: 0:09:34  Lr: 0.001875  Loss: -0.5119  Acc@1: 62.5000 (64.6395)  Acc@5: 87.5000 (91.6167)  time: 0.3511  data: 0.0015  max mem: 2500
Train: Epoch[4/5]  [3050/4579]  eta: 0:09:30  Lr: 0.001875  Loss: 0.1496  Acc@1: 68.7500 (64.6448)  Acc@5: 87.5000 (91.6175)  time: 0.3506  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [3060/4579]  eta: 0:09:26  Lr: 0.001875  Loss: -0.6374  Acc@1: 68.7500 (64.6419)  Acc@5: 93.7500 (91.6081)  time: 0.3511  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [3070/4579]  eta: 0:09:23  Lr: 0.001875  Loss: 0.1355  Acc@1: 68.7500 (64.6593)  Acc@5: 93.7500 (91.6070)  time: 0.3510  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [3080/4579]  eta: 0:09:19  Lr: 0.001875  Loss: -0.7192  Acc@1: 68.7500 (64.6848)  Acc@5: 93.7500 (91.6200)  time: 0.3512  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3090/4579]  eta: 0:09:15  Lr: 0.001875  Loss: -0.5551  Acc@1: 68.7500 (64.6918)  Acc@5: 93.7500 (91.6330)  time: 0.3511  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3100/4579]  eta: 0:09:11  Lr: 0.001875  Loss: -0.5975  Acc@1: 62.5000 (64.6888)  Acc@5: 93.7500 (91.6277)  time: 0.3508  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3110/4579]  eta: 0:09:07  Lr: 0.001875  Loss: -0.6433  Acc@1: 75.0000 (64.7139)  Acc@5: 93.7500 (91.6245)  time: 0.3510  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [3120/4579]  eta: 0:09:03  Lr: 0.001875  Loss: 0.0094  Acc@1: 68.7500 (64.6948)  Acc@5: 93.7500 (91.6253)  time: 0.3515  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [3130/4579]  eta: 0:09:00  Lr: 0.001875  Loss: 0.0467  Acc@1: 62.5000 (64.7058)  Acc@5: 93.7500 (91.6361)  time: 0.3510  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3140/4579]  eta: 0:08:56  Lr: 0.001875  Loss: -0.3445  Acc@1: 68.7500 (64.7067)  Acc@5: 93.7500 (91.6348)  time: 0.3522  data: 0.0021  max mem: 2500
Train: Epoch[4/5]  [3150/4579]  eta: 0:08:52  Lr: 0.001875  Loss: -0.8246  Acc@1: 62.5000 (64.7235)  Acc@5: 93.7500 (91.6415)  time: 0.3528  data: 0.0028  max mem: 2500
Train: Epoch[4/5]  [3160/4579]  eta: 0:08:48  Lr: 0.001875  Loss: -0.0476  Acc@1: 62.5000 (64.7283)  Acc@5: 93.7500 (91.6482)  time: 0.3511  data: 0.0012  max mem: 2500
Train: Epoch[4/5]  [3170/4579]  eta: 0:08:44  Lr: 0.001875  Loss: -0.3873  Acc@1: 62.5000 (64.7272)  Acc@5: 93.7500 (91.6410)  time: 0.3508  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [3180/4579]  eta: 0:08:41  Lr: 0.001875  Loss: -0.4641  Acc@1: 62.5000 (64.7340)  Acc@5: 93.7500 (91.6457)  time: 0.3506  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [3190/4579]  eta: 0:08:37  Lr: 0.001875  Loss: -0.5042  Acc@1: 68.7500 (64.7446)  Acc@5: 93.7500 (91.6464)  time: 0.3500  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [3200/4579]  eta: 0:08:33  Lr: 0.001875  Loss: -0.3623  Acc@1: 68.7500 (64.7512)  Acc@5: 93.7500 (91.6452)  time: 0.3506  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3210/4579]  eta: 0:08:29  Lr: 0.001875  Loss: -0.1703  Acc@1: 62.5000 (64.7345)  Acc@5: 87.5000 (91.6401)  time: 0.3509  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3220/4579]  eta: 0:08:25  Lr: 0.001875  Loss: 0.1268  Acc@1: 56.2500 (64.7179)  Acc@5: 93.7500 (91.6447)  time: 0.3508  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [3230/4579]  eta: 0:08:21  Lr: 0.001875  Loss: 0.2035  Acc@1: 62.5000 (64.7149)  Acc@5: 93.7500 (91.6531)  time: 0.3505  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [3240/4579]  eta: 0:08:18  Lr: 0.001875  Loss: -0.1781  Acc@1: 68.7500 (64.7273)  Acc@5: 93.7500 (91.6519)  time: 0.3501  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3250/4579]  eta: 0:08:14  Lr: 0.001875  Loss: -0.4674  Acc@1: 68.7500 (64.7416)  Acc@5: 93.7500 (91.6526)  time: 0.3500  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [3260/4579]  eta: 0:08:10  Lr: 0.001875  Loss: -0.8833  Acc@1: 75.0000 (64.7712)  Acc@5: 93.7500 (91.6686)  time: 0.3501  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [3270/4579]  eta: 0:08:06  Lr: 0.001875  Loss: -0.9625  Acc@1: 62.5000 (64.7719)  Acc@5: 93.7500 (91.6635)  time: 0.3501  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3280/4579]  eta: 0:08:02  Lr: 0.001875  Loss: -0.7491  Acc@1: 62.5000 (64.7573)  Acc@5: 87.5000 (91.6584)  time: 0.3494  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [3290/4579]  eta: 0:07:59  Lr: 0.001875  Loss: -0.0025  Acc@1: 62.5000 (64.7619)  Acc@5: 87.5000 (91.6553)  time: 0.3511  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [3300/4579]  eta: 0:07:55  Lr: 0.001875  Loss: -0.4195  Acc@1: 62.5000 (64.7531)  Acc@5: 93.7500 (91.6578)  time: 0.3518  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [3310/4579]  eta: 0:07:51  Lr: 0.001875  Loss: -0.0848  Acc@1: 62.5000 (64.7406)  Acc@5: 93.7500 (91.6566)  time: 0.3502  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3320/4579]  eta: 0:07:47  Lr: 0.001875  Loss: 0.6277  Acc@1: 56.2500 (64.7207)  Acc@5: 93.7500 (91.6516)  time: 0.3502  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3330/4579]  eta: 0:07:43  Lr: 0.001875  Loss: -0.6297  Acc@1: 56.2500 (64.7291)  Acc@5: 93.7500 (91.6485)  time: 0.3511  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3340/4579]  eta: 0:07:40  Lr: 0.001875  Loss: -0.4008  Acc@1: 68.7500 (64.7448)  Acc@5: 93.7500 (91.6567)  time: 0.3509  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3350/4579]  eta: 0:07:36  Lr: 0.001875  Loss: -0.1080  Acc@1: 68.7500 (64.7568)  Acc@5: 93.7500 (91.6555)  time: 0.3500  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3360/4579]  eta: 0:07:32  Lr: 0.001875  Loss: -0.8428  Acc@1: 68.7500 (64.7724)  Acc@5: 93.7500 (91.6580)  time: 0.3495  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [3370/4579]  eta: 0:07:28  Lr: 0.001875  Loss: -0.5553  Acc@1: 68.7500 (64.7675)  Acc@5: 93.7500 (91.6531)  time: 0.3502  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [3380/4579]  eta: 0:07:24  Lr: 0.001875  Loss: -0.1339  Acc@1: 62.5000 (64.7682)  Acc@5: 87.5000 (91.6519)  time: 0.3497  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [3390/4579]  eta: 0:07:21  Lr: 0.001875  Loss: -0.2556  Acc@1: 62.5000 (64.7818)  Acc@5: 93.7500 (91.6599)  time: 0.3490  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [3400/4579]  eta: 0:07:17  Lr: 0.001875  Loss: -0.6404  Acc@1: 62.5000 (64.7659)  Acc@5: 93.7500 (91.6587)  time: 0.3493  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [3410/4579]  eta: 0:07:13  Lr: 0.001875  Loss: -0.2707  Acc@1: 62.5000 (64.7739)  Acc@5: 93.7500 (91.6667)  time: 0.3486  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [3420/4579]  eta: 0:07:09  Lr: 0.001875  Loss: -0.3380  Acc@1: 68.7500 (64.7947)  Acc@5: 93.7500 (91.6636)  time: 0.3481  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [3430/4579]  eta: 0:07:06  Lr: 0.001875  Loss: -0.2962  Acc@1: 68.7500 (64.8080)  Acc@5: 87.5000 (91.6497)  time: 0.3482  data: 0.0014  max mem: 2500
Train: Epoch[4/5]  [3440/4579]  eta: 0:07:02  Lr: 0.001875  Loss: -0.2550  Acc@1: 68.7500 (64.8140)  Acc@5: 87.5000 (91.6431)  time: 0.3478  data: 0.0013  max mem: 2500
Train: Epoch[4/5]  [3450/4579]  eta: 0:06:58  Lr: 0.001875  Loss: -0.5736  Acc@1: 68.7500 (64.8236)  Acc@5: 87.5000 (91.6383)  time: 0.3473  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3460/4579]  eta: 0:06:54  Lr: 0.001875  Loss: -0.6623  Acc@1: 68.7500 (64.8277)  Acc@5: 93.7500 (91.6444)  time: 0.3489  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [3470/4579]  eta: 0:06:50  Lr: 0.001875  Loss: -0.3499  Acc@1: 62.5000 (64.8228)  Acc@5: 93.7500 (91.6433)  time: 0.3493  data: 0.0013  max mem: 2500
Train: Epoch[4/5]  [3480/4579]  eta: 0:06:47  Lr: 0.001875  Loss: -0.1886  Acc@1: 62.5000 (64.8287)  Acc@5: 93.7500 (91.6511)  time: 0.3484  data: 0.0013  max mem: 2500
Train: Epoch[4/5]  [3490/4579]  eta: 0:06:43  Lr: 0.001875  Loss: -0.6386  Acc@1: 68.7500 (64.8310)  Acc@5: 93.7500 (91.6535)  time: 0.3483  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3500/4579]  eta: 0:06:39  Lr: 0.001875  Loss: 0.0531  Acc@1: 62.5000 (64.8279)  Acc@5: 93.7500 (91.6506)  time: 0.3480  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [3510/4579]  eta: 0:06:35  Lr: 0.001875  Loss: -0.0735  Acc@1: 68.7500 (64.8355)  Acc@5: 93.7500 (91.6477)  time: 0.3485  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [3520/4579]  eta: 0:06:32  Lr: 0.001875  Loss: 0.0507  Acc@1: 68.7500 (64.8395)  Acc@5: 93.7500 (91.6536)  time: 0.3485  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3530/4579]  eta: 0:06:28  Lr: 0.001875  Loss: -0.4133  Acc@1: 62.5000 (64.8223)  Acc@5: 93.7500 (91.6472)  time: 0.3481  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [3540/4579]  eta: 0:06:24  Lr: 0.001875  Loss: 0.2566  Acc@1: 62.5000 (64.8299)  Acc@5: 87.5000 (91.6496)  time: 0.3488  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [3550/4579]  eta: 0:06:20  Lr: 0.001875  Loss: -0.4645  Acc@1: 68.7500 (64.8303)  Acc@5: 87.5000 (91.6485)  time: 0.3486  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [3560/4579]  eta: 0:06:17  Lr: 0.001875  Loss: -0.7153  Acc@1: 62.5000 (64.8326)  Acc@5: 87.5000 (91.6439)  time: 0.3490  data: 0.0010  max mem: 2500
Train: Epoch[4/5]  [3570/4579]  eta: 0:06:13  Lr: 0.001875  Loss: 0.6206  Acc@1: 62.5000 (64.8103)  Acc@5: 87.5000 (91.6462)  time: 0.3500  data: 0.0019  max mem: 2500
Train: Epoch[4/5]  [3580/4579]  eta: 0:06:09  Lr: 0.001875  Loss: -0.3597  Acc@1: 56.2500 (64.8091)  Acc@5: 93.7500 (91.6486)  time: 0.3499  data: 0.0014  max mem: 2500
Train: Epoch[4/5]  [3590/4579]  eta: 0:06:05  Lr: 0.001875  Loss: -0.9209  Acc@1: 68.7500 (64.8183)  Acc@5: 87.5000 (91.6440)  time: 0.3510  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [3600/4579]  eta: 0:06:01  Lr: 0.001875  Loss: -0.6376  Acc@1: 68.7500 (64.8188)  Acc@5: 93.7500 (91.6516)  time: 0.3518  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [3610/4579]  eta: 0:05:58  Lr: 0.001875  Loss: 0.0837  Acc@1: 62.5000 (64.8020)  Acc@5: 93.7500 (91.6436)  time: 0.3506  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [3620/4579]  eta: 0:05:54  Lr: 0.001875  Loss: -0.7279  Acc@1: 56.2500 (64.7922)  Acc@5: 93.7500 (91.6494)  time: 0.3494  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [3630/4579]  eta: 0:05:50  Lr: 0.001875  Loss: -0.8220  Acc@1: 56.2500 (64.7842)  Acc@5: 93.7500 (91.6552)  time: 0.3497  data: 0.0009  max mem: 2500
Train: Epoch[4/5]  [3640/4579]  eta: 0:05:46  Lr: 0.001875  Loss: -0.0284  Acc@1: 56.2500 (64.7744)  Acc@5: 93.7500 (91.6609)  time: 0.3494  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [3650/4579]  eta: 0:05:43  Lr: 0.001875  Loss: 0.1360  Acc@1: 62.5000 (64.7870)  Acc@5: 93.7500 (91.6547)  time: 0.3487  data: 0.0011  max mem: 2500
Train: Epoch[4/5]  [3660/4579]  eta: 0:05:39  Lr: 0.001875  Loss: -0.2442  Acc@1: 62.5000 (64.7671)  Acc@5: 87.5000 (91.6450)  time: 0.3489  data: 0.0016  max mem: 2500
Train: Epoch[4/5]  [3670/4579]  eta: 0:05:35  Lr: 0.001875  Loss: -0.8481  Acc@1: 56.2500 (64.7576)  Acc@5: 93.7500 (91.6542)  time: 0.3488  data: 0.0011  max mem: 2500
Train: Epoch[4/5]  [3680/4579]  eta: 0:05:32  Lr: 0.001875  Loss: -0.7637  Acc@1: 62.5000 (64.7599)  Acc@5: 93.7500 (91.6446)  time: 0.3484  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [3690/4579]  eta: 0:05:28  Lr: 0.001875  Loss: 0.2371  Acc@1: 62.5000 (64.7640)  Acc@5: 93.7500 (91.6435)  time: 0.3481  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [3700/4579]  eta: 0:05:24  Lr: 0.001875  Loss: -0.5766  Acc@1: 68.7500 (64.7697)  Acc@5: 93.7500 (91.6442)  time: 0.3491  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [3710/4579]  eta: 0:05:20  Lr: 0.001875  Loss: -0.2412  Acc@1: 68.7500 (64.7635)  Acc@5: 87.5000 (91.6380)  time: 0.3490  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [3720/4579]  eta: 0:05:17  Lr: 0.001875  Loss: -0.3992  Acc@1: 68.7500 (64.7726)  Acc@5: 87.5000 (91.6336)  time: 0.3477  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [3730/4579]  eta: 0:05:13  Lr: 0.001875  Loss: -0.6685  Acc@1: 62.5000 (64.7581)  Acc@5: 93.7500 (91.6293)  time: 0.3474  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3740/4579]  eta: 0:05:09  Lr: 0.001875  Loss: -0.8994  Acc@1: 62.5000 (64.7604)  Acc@5: 87.5000 (91.6216)  time: 0.3487  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [3750/4579]  eta: 0:05:05  Lr: 0.001875  Loss: -0.2940  Acc@1: 62.5000 (64.7611)  Acc@5: 87.5000 (91.6139)  time: 0.3494  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [3760/4579]  eta: 0:05:02  Lr: 0.001875  Loss: -0.4460  Acc@1: 68.7500 (64.7767)  Acc@5: 93.7500 (91.6196)  time: 0.3497  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [3770/4579]  eta: 0:04:58  Lr: 0.001875  Loss: -0.9159  Acc@1: 68.7500 (64.7905)  Acc@5: 93.7500 (91.6285)  time: 0.3496  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [3780/4579]  eta: 0:04:54  Lr: 0.001875  Loss: -0.6154  Acc@1: 68.7500 (64.8010)  Acc@5: 93.7500 (91.6342)  time: 0.3494  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3790/4579]  eta: 0:04:50  Lr: 0.001875  Loss: -0.5609  Acc@1: 62.5000 (64.7933)  Acc@5: 93.7500 (91.6381)  time: 0.3495  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [3800/4579]  eta: 0:04:47  Lr: 0.001875  Loss: -0.3558  Acc@1: 68.7500 (64.8201)  Acc@5: 93.7500 (91.6420)  time: 0.3502  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [3810/4579]  eta: 0:04:43  Lr: 0.001875  Loss: -0.2898  Acc@1: 68.7500 (64.8403)  Acc@5: 93.7500 (91.6459)  time: 0.3502  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3820/4579]  eta: 0:04:39  Lr: 0.001875  Loss: -0.6417  Acc@1: 68.7500 (64.8407)  Acc@5: 93.7500 (91.6432)  time: 0.3499  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3830/4579]  eta: 0:04:36  Lr: 0.001875  Loss: -0.5147  Acc@1: 62.5000 (64.8362)  Acc@5: 93.7500 (91.6455)  time: 0.3504  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3840/4579]  eta: 0:04:32  Lr: 0.001875  Loss: -0.2518  Acc@1: 62.5000 (64.8334)  Acc@5: 93.7500 (91.6444)  time: 0.3495  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3850/4579]  eta: 0:04:28  Lr: 0.001875  Loss: -0.7856  Acc@1: 62.5000 (64.8241)  Acc@5: 93.7500 (91.6450)  time: 0.3490  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3860/4579]  eta: 0:04:24  Lr: 0.001875  Loss: -0.1063  Acc@1: 62.5000 (64.8181)  Acc@5: 93.7500 (91.6489)  time: 0.3492  data: 0.0010  max mem: 2500
Train: Epoch[4/5]  [3870/4579]  eta: 0:04:21  Lr: 0.001875  Loss: -0.6840  Acc@1: 62.5000 (64.8234)  Acc@5: 93.7500 (91.6559)  time: 0.3499  data: 0.0010  max mem: 2500
Train: Epoch[4/5]  [3880/4579]  eta: 0:04:17  Lr: 0.001875  Loss: -0.3504  Acc@1: 62.5000 (64.7964)  Acc@5: 93.7500 (91.6468)  time: 0.3506  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [3890/4579]  eta: 0:04:13  Lr: 0.001875  Loss: -0.3720  Acc@1: 56.2500 (64.7970)  Acc@5: 87.5000 (91.6410)  time: 0.3577  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [3900/4579]  eta: 0:04:10  Lr: 0.001875  Loss: -0.6035  Acc@1: 68.7500 (64.8215)  Acc@5: 87.5000 (91.6400)  time: 0.3734  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [3910/4579]  eta: 0:04:06  Lr: 0.001875  Loss: -0.9294  Acc@1: 68.7500 (64.8300)  Acc@5: 87.5000 (91.6406)  time: 0.3926  data: 0.0009  max mem: 2500
Train: Epoch[4/5]  [3920/4579]  eta: 0:04:02  Lr: 0.001875  Loss: -0.4345  Acc@1: 68.7500 (64.8511)  Acc@5: 93.7500 (91.6444)  time: 0.4026  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [3930/4579]  eta: 0:03:59  Lr: 0.001875  Loss: -0.5410  Acc@1: 68.7500 (64.8658)  Acc@5: 93.7500 (91.6513)  time: 0.4027  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3940/4579]  eta: 0:03:55  Lr: 0.001875  Loss: -0.3233  Acc@1: 68.7500 (64.8677)  Acc@5: 93.7500 (91.6550)  time: 0.4021  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [3950/4579]  eta: 0:03:51  Lr: 0.001875  Loss: -0.6024  Acc@1: 68.7500 (64.8728)  Acc@5: 93.7500 (91.6635)  time: 0.4013  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [3960/4579]  eta: 0:03:48  Lr: 0.001875  Loss: -0.6769  Acc@1: 62.5000 (64.8700)  Acc@5: 93.7500 (91.6656)  time: 0.3871  data: 0.0012  max mem: 2500
Train: Epoch[4/5]  [3970/4579]  eta: 0:03:44  Lr: 0.001875  Loss: -0.2150  Acc@1: 62.5000 (64.8782)  Acc@5: 93.7500 (91.6630)  time: 0.3617  data: 0.0012  max mem: 2500
Train: Epoch[4/5]  [3980/4579]  eta: 0:03:40  Lr: 0.001875  Loss: -0.1683  Acc@1: 68.7500 (64.8926)  Acc@5: 87.5000 (91.6620)  time: 0.3503  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3990/4579]  eta: 0:03:37  Lr: 0.001875  Loss: -0.3126  Acc@1: 62.5000 (64.8882)  Acc@5: 93.7500 (91.6688)  time: 0.3536  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [4000/4579]  eta: 0:03:33  Lr: 0.001875  Loss: -0.0176  Acc@1: 62.5000 (64.9056)  Acc@5: 93.7500 (91.6677)  time: 0.3640  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [4010/4579]  eta: 0:03:29  Lr: 0.001875  Loss: -0.9251  Acc@1: 68.7500 (64.9152)  Acc@5: 93.7500 (91.6729)  time: 0.3866  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [4020/4579]  eta: 0:03:26  Lr: 0.001875  Loss: -0.3129  Acc@1: 62.5000 (64.9139)  Acc@5: 93.7500 (91.6765)  time: 0.4016  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [4030/4579]  eta: 0:03:22  Lr: 0.001875  Loss: 0.1895  Acc@1: 62.5000 (64.9188)  Acc@5: 87.5000 (91.6755)  time: 0.4025  data: 0.0011  max mem: 2500
Train: Epoch[4/5]  [4040/4579]  eta: 0:03:18  Lr: 0.001875  Loss: -0.3607  Acc@1: 62.5000 (64.9066)  Acc@5: 87.5000 (91.6651)  time: 0.4036  data: 0.0011  max mem: 2500
Train: Epoch[4/5]  [4050/4579]  eta: 0:03:15  Lr: 0.001875  Loss: -0.5136  Acc@1: 62.5000 (64.9145)  Acc@5: 93.7500 (91.6641)  time: 0.4037  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [4060/4579]  eta: 0:03:11  Lr: 0.001875  Loss: 0.0389  Acc@1: 62.5000 (64.9163)  Acc@5: 87.5000 (91.6523)  time: 0.3935  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [4070/4579]  eta: 0:03:07  Lr: 0.001875  Loss: -0.8610  Acc@1: 68.7500 (64.9334)  Acc@5: 87.5000 (91.6498)  time: 0.3669  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [4080/4579]  eta: 0:03:04  Lr: 0.001875  Loss: -0.7340  Acc@1: 75.0000 (64.9427)  Acc@5: 93.7500 (91.6565)  time: 0.3563  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [4090/4579]  eta: 0:03:00  Lr: 0.001875  Loss: -0.8564  Acc@1: 75.0000 (64.9643)  Acc@5: 93.7500 (91.6600)  time: 0.3677  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [4100/4579]  eta: 0:02:56  Lr: 0.001875  Loss: -0.3516  Acc@1: 75.0000 (64.9704)  Acc@5: 93.7500 (91.6651)  time: 0.3899  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [4110/4579]  eta: 0:02:53  Lr: 0.001875  Loss: -0.1678  Acc@1: 68.7500 (64.9872)  Acc@5: 93.7500 (91.6626)  time: 0.4049  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [4120/4579]  eta: 0:02:49  Lr: 0.001875  Loss: 0.1984  Acc@1: 75.0000 (64.9979)  Acc@5: 87.5000 (91.6601)  time: 0.4033  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [4130/4579]  eta: 0:02:45  Lr: 0.001875  Loss: 0.7255  Acc@1: 68.7500 (64.9858)  Acc@5: 87.5000 (91.6515)  time: 0.4028  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [4140/4579]  eta: 0:02:42  Lr: 0.001875  Loss: -0.4579  Acc@1: 62.5000 (64.9934)  Acc@5: 87.5000 (91.6521)  time: 0.4026  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [4150/4579]  eta: 0:02:38  Lr: 0.001875  Loss: 0.3273  Acc@1: 68.7500 (65.0024)  Acc@5: 93.7500 (91.6466)  time: 0.4013  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [4160/4579]  eta: 0:02:34  Lr: 0.001875  Loss: -0.1069  Acc@1: 68.7500 (65.0024)  Acc@5: 93.7500 (91.6516)  time: 0.4000  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [4170/4579]  eta: 0:02:31  Lr: 0.001875  Loss: -0.4536  Acc@1: 56.2500 (64.9814)  Acc@5: 93.7500 (91.6507)  time: 0.4010  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [4180/4579]  eta: 0:02:27  Lr: 0.001875  Loss: -0.5762  Acc@1: 62.5000 (64.9859)  Acc@5: 93.7500 (91.6527)  time: 0.4021  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [4190/4579]  eta: 0:02:23  Lr: 0.001875  Loss: -0.7966  Acc@1: 68.7500 (65.0054)  Acc@5: 93.7500 (91.6532)  time: 0.4021  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [4200/4579]  eta: 0:02:20  Lr: 0.001875  Loss: -0.2350  Acc@1: 68.7500 (64.9994)  Acc@5: 93.7500 (91.6493)  time: 0.4020  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [4210/4579]  eta: 0:02:16  Lr: 0.001875  Loss: -0.5393  Acc@1: 56.2500 (64.9920)  Acc@5: 87.5000 (91.6454)  time: 0.4034  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [4220/4579]  eta: 0:02:12  Lr: 0.001875  Loss: -0.3258  Acc@1: 62.5000 (64.9935)  Acc@5: 93.7500 (91.6459)  time: 0.4030  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [4230/4579]  eta: 0:02:09  Lr: 0.001875  Loss: -0.5093  Acc@1: 62.5000 (65.0009)  Acc@5: 93.7500 (91.6509)  time: 0.4014  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [4240/4579]  eta: 0:02:05  Lr: 0.001875  Loss: -0.3378  Acc@1: 68.7500 (65.0156)  Acc@5: 93.7500 (91.6485)  time: 0.4016  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [4250/4579]  eta: 0:02:01  Lr: 0.001875  Loss: -0.2349  Acc@1: 62.5000 (64.9906)  Acc@5: 87.5000 (91.6446)  time: 0.4014  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [4260/4579]  eta: 0:01:58  Lr: 0.001875  Loss: -0.7536  Acc@1: 56.2500 (64.9935)  Acc@5: 87.5000 (91.6452)  time: 0.4027  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [4270/4579]  eta: 0:01:54  Lr: 0.001875  Loss: -0.3491  Acc@1: 68.7500 (65.0067)  Acc@5: 87.5000 (91.6457)  time: 0.4036  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [4280/4579]  eta: 0:01:50  Lr: 0.001875  Loss: -0.7732  Acc@1: 68.7500 (65.0038)  Acc@5: 87.5000 (91.6448)  time: 0.4016  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [4290/4579]  eta: 0:01:47  Lr: 0.001875  Loss: -0.1205  Acc@1: 68.7500 (65.0169)  Acc@5: 93.7500 (91.6438)  time: 0.4000  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [4300/4579]  eta: 0:01:43  Lr: 0.001875  Loss: -0.1439  Acc@1: 68.7500 (65.0299)  Acc@5: 93.7500 (91.6473)  time: 0.3994  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [4310/4579]  eta: 0:01:39  Lr: 0.001875  Loss: -0.1367  Acc@1: 68.7500 (65.0342)  Acc@5: 93.7500 (91.6449)  time: 0.3994  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [4320/4579]  eta: 0:01:36  Lr: 0.001875  Loss: 0.2393  Acc@1: 68.7500 (65.0341)  Acc@5: 93.7500 (91.6426)  time: 0.4003  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [4330/4579]  eta: 0:01:32  Lr: 0.001875  Loss: -0.3377  Acc@1: 68.7500 (65.0369)  Acc@5: 93.7500 (91.6431)  time: 0.4005  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [4340/4579]  eta: 0:01:28  Lr: 0.001875  Loss: -0.5843  Acc@1: 75.0000 (65.0585)  Acc@5: 87.5000 (91.6364)  time: 0.3997  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [4350/4579]  eta: 0:01:24  Lr: 0.001875  Loss: -0.0204  Acc@1: 75.0000 (65.0756)  Acc@5: 93.7500 (91.6470)  time: 0.3989  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [4360/4579]  eta: 0:01:21  Lr: 0.001875  Loss: -0.6462  Acc@1: 68.7500 (65.0854)  Acc@5: 93.7500 (91.6533)  time: 0.3989  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [4370/4579]  eta: 0:01:17  Lr: 0.001875  Loss: -0.6907  Acc@1: 68.7500 (65.0967)  Acc@5: 93.7500 (91.6595)  time: 0.3993  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [4380/4579]  eta: 0:01:13  Lr: 0.001875  Loss: -0.1861  Acc@1: 62.5000 (65.0822)  Acc@5: 93.7500 (91.6529)  time: 0.4003  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [4390/4579]  eta: 0:01:10  Lr: 0.001875  Loss: -0.1145  Acc@1: 62.5000 (65.0891)  Acc@5: 87.5000 (91.6505)  time: 0.4011  data: 0.0009  max mem: 2500
Train: Epoch[4/5]  [4400/4579]  eta: 0:01:06  Lr: 0.001875  Loss: -0.7069  Acc@1: 62.5000 (65.0903)  Acc@5: 87.5000 (91.6525)  time: 0.4005  data: 0.0009  max mem: 2500
Train: Epoch[4/5]  [4410/4579]  eta: 0:01:02  Lr: 0.001875  Loss: -0.7855  Acc@1: 68.7500 (65.0972)  Acc@5: 93.7500 (91.6572)  time: 0.4014  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [4420/4579]  eta: 0:00:59  Lr: 0.001875  Loss: -0.1194  Acc@1: 68.7500 (65.1097)  Acc@5: 93.7500 (91.6634)  time: 0.4005  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [4430/4579]  eta: 0:00:55  Lr: 0.001875  Loss: -0.7919  Acc@1: 68.7500 (65.1080)  Acc@5: 93.7500 (91.6695)  time: 0.3996  data: 0.0011  max mem: 2500
Train: Epoch[4/5]  [4440/4579]  eta: 0:00:51  Lr: 0.001875  Loss: 0.4394  Acc@1: 62.5000 (65.0994)  Acc@5: 93.7500 (91.6685)  time: 0.4002  data: 0.0011  max mem: 2500
Train: Epoch[4/5]  [4450/4579]  eta: 0:00:47  Lr: 0.001875  Loss: -0.4876  Acc@1: 62.5000 (65.0935)  Acc@5: 93.7500 (91.6676)  time: 0.4011  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [4460/4579]  eta: 0:00:44  Lr: 0.001875  Loss: -0.6931  Acc@1: 68.7500 (65.1115)  Acc@5: 93.7500 (91.6737)  time: 0.4010  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [4470/4579]  eta: 0:00:40  Lr: 0.001875  Loss: -0.3103  Acc@1: 68.7500 (65.1099)  Acc@5: 93.7500 (91.6671)  time: 0.3992  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [4480/4579]  eta: 0:00:36  Lr: 0.001875  Loss: 0.2959  Acc@1: 68.7500 (65.1166)  Acc@5: 93.7500 (91.6732)  time: 0.4002  data: 0.0016  max mem: 2500
Train: Epoch[4/5]  [4490/4579]  eta: 0:00:33  Lr: 0.001875  Loss: -0.6605  Acc@1: 68.7500 (65.1358)  Acc@5: 93.7500 (91.6708)  time: 0.4010  data: 0.0016  max mem: 2500
Train: Epoch[4/5]  [4500/4579]  eta: 0:00:29  Lr: 0.001875  Loss: -0.4189  Acc@1: 68.7500 (65.1439)  Acc@5: 93.7500 (91.6713)  time: 0.4010  data: 0.0010  max mem: 2500
Train: Epoch[4/5]  [4510/4579]  eta: 0:00:25  Lr: 0.001875  Loss: -0.3799  Acc@1: 68.7500 (65.1574)  Acc@5: 93.7500 (91.6745)  time: 0.4007  data: 0.0018  max mem: 2500
Train: Epoch[4/5]  [4520/4579]  eta: 0:00:21  Lr: 0.001875  Loss: -0.9237  Acc@1: 68.7500 (65.1653)  Acc@5: 93.7500 (91.6819)  time: 0.3992  data: 0.0012  max mem: 2500
Train: Epoch[4/5]  [4530/4579]  eta: 0:00:18  Lr: 0.001875  Loss: -0.5884  Acc@1: 62.5000 (65.1636)  Acc@5: 93.7500 (91.6837)  time: 0.3985  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [4540/4579]  eta: 0:00:14  Lr: 0.001875  Loss: -0.6447  Acc@1: 62.5000 (65.1784)  Acc@5: 93.7500 (91.6841)  time: 0.3989  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [4550/4579]  eta: 0:00:10  Lr: 0.001875  Loss: -0.5500  Acc@1: 68.7500 (65.1752)  Acc@5: 93.7500 (91.6886)  time: 0.4002  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [4560/4579]  eta: 0:00:07  Lr: 0.001875  Loss: -0.9773  Acc@1: 62.5000 (65.1694)  Acc@5: 93.7500 (91.6808)  time: 0.4009  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [4570/4579]  eta: 0:00:03  Lr: 0.001875  Loss: -0.7348  Acc@1: 56.2500 (65.1663)  Acc@5: 93.7500 (91.6840)  time: 0.4004  data: 0.0010  max mem: 2500
Train: Epoch[4/5]  [4578/4579]  eta: 0:00:00  Lr: 0.001875  Loss: -0.8500  Acc@1: 62.5000 (65.1596)  Acc@5: 93.7500 (91.6841)  time: 0.3915  data: 0.0009  max mem: 2500
Train: Epoch[4/5] Total time: 0:28:26 (0.3726 s / it)
Averaged stats: Lr: 0.001875  Loss: -0.8500  Acc@1: 62.5000 (65.1596)  Acc@5: 93.7500 (91.6841)
Train: Epoch[5/5]  [   0/4579]  eta: 0:56:29  Lr: 0.001875  Loss: -0.8039  Acc@1: 75.0000 (75.0000)  Acc@5: 93.7500 (93.7500)  time: 0.7402  data: 0.3344  max mem: 2500
Train: Epoch[5/5]  [  10/4579]  eta: 0:32:43  Lr: 0.001875  Loss: -0.7426  Acc@1: 68.7500 (71.5909)  Acc@5: 93.7500 (94.3182)  time: 0.4297  data: 0.0307  max mem: 2500
Train: Epoch[5/5]  [  20/4579]  eta: 0:31:38  Lr: 0.001875  Loss: -0.2925  Acc@1: 68.7500 (71.7262)  Acc@5: 93.7500 (94.6429)  time: 0.4002  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [  30/4579]  eta: 0:31:11  Lr: 0.001875  Loss: -0.6701  Acc@1: 68.7500 (70.1613)  Acc@5: 93.7500 (94.3548)  time: 0.4015  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [  40/4579]  eta: 0:30:55  Lr: 0.001875  Loss: -0.5938  Acc@1: 62.5000 (68.1402)  Acc@5: 93.7500 (93.9024)  time: 0.4009  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [  50/4579]  eta: 0:30:43  Lr: 0.001875  Loss: 0.1277  Acc@1: 62.5000 (67.0343)  Acc@5: 93.7500 (92.8922)  time: 0.4002  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [  60/4579]  eta: 0:30:33  Lr: 0.001875  Loss: -0.7545  Acc@1: 62.5000 (67.0082)  Acc@5: 93.7500 (93.1352)  time: 0.3997  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [  70/4579]  eta: 0:30:25  Lr: 0.001875  Loss: -0.5054  Acc@1: 62.5000 (66.7254)  Acc@5: 93.7500 (92.9577)  time: 0.3993  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [  80/4579]  eta: 0:30:19  Lr: 0.001875  Loss: -0.5609  Acc@1: 68.7500 (66.7438)  Acc@5: 93.7500 (92.4383)  time: 0.4003  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [  90/4579]  eta: 0:30:13  Lr: 0.001875  Loss: -0.3769  Acc@1: 62.5000 (66.4148)  Acc@5: 93.7500 (92.5137)  time: 0.4008  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 100/4579]  eta: 0:30:07  Lr: 0.001875  Loss: -0.8259  Acc@1: 62.5000 (65.8416)  Acc@5: 93.7500 (92.2649)  time: 0.3994  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [ 110/4579]  eta: 0:30:02  Lr: 0.001875  Loss: -0.4354  Acc@1: 62.5000 (65.5405)  Acc@5: 93.7500 (92.2860)  time: 0.4002  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [ 120/4579]  eta: 0:29:56  Lr: 0.001875  Loss: -0.1726  Acc@1: 68.7500 (66.0124)  Acc@5: 93.7500 (92.3037)  time: 0.4004  data: 0.0010  max mem: 2500
Train: Epoch[5/5]  [ 130/4579]  eta: 0:29:52  Lr: 0.001875  Loss: -0.5348  Acc@1: 68.7500 (65.8874)  Acc@5: 93.7500 (92.4618)  time: 0.4007  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 140/4579]  eta: 0:29:47  Lr: 0.001875  Loss: -0.5685  Acc@1: 62.5000 (65.6915)  Acc@5: 93.7500 (92.2429)  time: 0.4013  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 150/4579]  eta: 0:29:42  Lr: 0.001875  Loss: -0.0880  Acc@1: 62.5000 (65.4387)  Acc@5: 93.7500 (92.3841)  time: 0.3997  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 160/4579]  eta: 0:29:37  Lr: 0.001875  Loss: -0.4901  Acc@1: 62.5000 (64.8292)  Acc@5: 93.7500 (92.3913)  time: 0.3996  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 170/4579]  eta: 0:29:33  Lr: 0.001875  Loss: -0.7571  Acc@1: 68.7500 (65.2412)  Acc@5: 93.7500 (92.4342)  time: 0.4004  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [ 180/4579]  eta: 0:29:29  Lr: 0.001875  Loss: -0.4561  Acc@1: 68.7500 (64.9517)  Acc@5: 87.5000 (92.2307)  time: 0.4016  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [ 190/4579]  eta: 0:29:24  Lr: 0.001875  Loss: -0.4570  Acc@1: 56.2500 (64.7579)  Acc@5: 93.7500 (92.2448)  time: 0.4011  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [ 200/4579]  eta: 0:29:20  Lr: 0.001875  Loss: -0.3441  Acc@1: 56.2500 (64.6766)  Acc@5: 93.7500 (92.2575)  time: 0.3997  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [ 210/4579]  eta: 0:29:15  Lr: 0.001875  Loss: -0.5840  Acc@1: 62.5000 (64.5735)  Acc@5: 93.7500 (92.1801)  time: 0.3996  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [ 220/4579]  eta: 0:29:11  Lr: 0.001875  Loss: -0.3318  Acc@1: 62.5000 (64.5645)  Acc@5: 93.7500 (92.1380)  time: 0.4001  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 230/4579]  eta: 0:29:07  Lr: 0.001875  Loss: -0.5634  Acc@1: 68.7500 (64.9080)  Acc@5: 93.7500 (92.1807)  time: 0.4002  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 240/4579]  eta: 0:29:02  Lr: 0.001875  Loss: -0.2511  Acc@1: 62.5000 (64.7822)  Acc@5: 93.7500 (92.1940)  time: 0.3995  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 250/4579]  eta: 0:28:58  Lr: 0.001875  Loss: -0.6039  Acc@1: 62.5000 (64.7659)  Acc@5: 93.7500 (92.2062)  time: 0.3990  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 260/4579]  eta: 0:28:54  Lr: 0.001875  Loss: -0.1619  Acc@1: 62.5000 (64.8707)  Acc@5: 93.7500 (92.2174)  time: 0.3999  data: 0.0012  max mem: 2500
Train: Epoch[5/5]  [ 270/4579]  eta: 0:28:50  Lr: 0.001875  Loss: 0.1273  Acc@1: 68.7500 (65.1983)  Acc@5: 93.7500 (92.2509)  time: 0.4011  data: 0.0011  max mem: 2500
Train: Epoch[5/5]  [ 280/4579]  eta: 0:28:46  Lr: 0.001875  Loss: -0.0536  Acc@1: 68.7500 (64.9911)  Acc@5: 93.7500 (92.3043)  time: 0.4018  data: 0.0011  max mem: 2500
Train: Epoch[5/5]  [ 290/4579]  eta: 0:28:42  Lr: 0.001875  Loss: -0.7961  Acc@1: 62.5000 (65.0558)  Acc@5: 93.7500 (92.3325)  time: 0.4018  data: 0.0011  max mem: 2500
Train: Epoch[5/5]  [ 300/4579]  eta: 0:28:38  Lr: 0.001875  Loss: -0.7269  Acc@1: 68.7500 (65.1993)  Acc@5: 93.7500 (92.3173)  time: 0.4014  data: 0.0011  max mem: 2500
Train: Epoch[5/5]  [ 310/4579]  eta: 0:28:33  Lr: 0.001875  Loss: -0.5043  Acc@1: 68.7500 (65.1929)  Acc@5: 93.7500 (92.3232)  time: 0.4005  data: 0.0012  max mem: 2500
Train: Epoch[5/5]  [ 320/4579]  eta: 0:28:29  Lr: 0.001875  Loss: -0.3928  Acc@1: 68.7500 (65.4400)  Acc@5: 93.7500 (92.3287)  time: 0.4003  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [ 330/4579]  eta: 0:28:25  Lr: 0.001875  Loss: -0.5171  Acc@1: 68.7500 (65.5400)  Acc@5: 93.7500 (92.4471)  time: 0.4006  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [ 340/4579]  eta: 0:28:21  Lr: 0.001875  Loss: -0.2397  Acc@1: 62.5000 (65.4692)  Acc@5: 93.7500 (92.4670)  time: 0.4007  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [ 350/4579]  eta: 0:28:17  Lr: 0.001875  Loss: -0.0387  Acc@1: 62.5000 (65.2778)  Acc@5: 93.7500 (92.4145)  time: 0.4008  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 360/4579]  eta: 0:28:13  Lr: 0.001875  Loss: -0.6527  Acc@1: 62.5000 (65.2528)  Acc@5: 93.7500 (92.4169)  time: 0.3995  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 370/4579]  eta: 0:28:08  Lr: 0.001875  Loss: 0.1083  Acc@1: 62.5000 (65.2291)  Acc@5: 93.7500 (92.4191)  time: 0.3993  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 380/4579]  eta: 0:28:04  Lr: 0.001875  Loss: -0.1835  Acc@1: 62.5000 (65.1739)  Acc@5: 87.5000 (92.3064)  time: 0.4006  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [ 390/4579]  eta: 0:28:01  Lr: 0.001875  Loss: -0.5374  Acc@1: 68.7500 (65.1535)  Acc@5: 87.5000 (92.2794)  time: 0.4020  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [ 400/4579]  eta: 0:27:56  Lr: 0.001875  Loss: -0.6329  Acc@1: 68.7500 (65.1964)  Acc@5: 93.7500 (92.2226)  time: 0.4018  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [ 410/4579]  eta: 0:27:52  Lr: 0.001875  Loss: -0.0850  Acc@1: 68.7500 (65.2828)  Acc@5: 93.7500 (92.2445)  time: 0.4002  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [ 420/4579]  eta: 0:27:49  Lr: 0.001875  Loss: -0.7742  Acc@1: 68.7500 (65.3058)  Acc@5: 93.7500 (92.2803)  time: 0.4018  data: 0.0018  max mem: 2500
Train: Epoch[5/5]  [ 430/4579]  eta: 0:27:45  Lr: 0.001875  Loss: -0.5007  Acc@1: 68.7500 (65.2697)  Acc@5: 87.5000 (92.1839)  time: 0.4026  data: 0.0017  max mem: 2500
Train: Epoch[5/5]  [ 440/4579]  eta: 0:27:40  Lr: 0.001875  Loss: -0.3355  Acc@1: 62.5000 (65.3486)  Acc@5: 87.5000 (92.2336)  time: 0.4004  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 450/4579]  eta: 0:27:36  Lr: 0.001875  Loss: -0.4637  Acc@1: 68.7500 (65.3271)  Acc@5: 93.7500 (92.1979)  time: 0.4006  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [ 460/4579]  eta: 0:27:32  Lr: 0.001875  Loss: -0.6814  Acc@1: 68.7500 (65.4420)  Acc@5: 93.7500 (92.2858)  time: 0.4008  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [ 470/4579]  eta: 0:27:28  Lr: 0.001875  Loss: -0.4241  Acc@1: 68.7500 (65.4459)  Acc@5: 93.7500 (92.3169)  time: 0.4006  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [ 480/4579]  eta: 0:27:24  Lr: 0.001875  Loss: -0.2414  Acc@1: 62.5000 (65.3716)  Acc@5: 93.7500 (92.2557)  time: 0.4015  data: 0.0013  max mem: 2500
Train: Epoch[5/5]  [ 490/4579]  eta: 0:27:20  Lr: 0.001875  Loss: -0.6675  Acc@1: 68.7500 (65.4913)  Acc@5: 87.5000 (92.2607)  time: 0.4021  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [ 500/4579]  eta: 0:27:14  Lr: 0.001875  Loss: -0.2725  Acc@1: 68.7500 (65.4441)  Acc@5: 87.5000 (92.1906)  time: 0.3853  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 510/4579]  eta: 0:27:05  Lr: 0.001875  Loss: -0.5966  Acc@1: 68.7500 (65.5333)  Acc@5: 87.5000 (92.1600)  time: 0.3584  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [ 520/4579]  eta: 0:26:58  Lr: 0.001875  Loss: -0.8940  Acc@1: 68.7500 (65.6070)  Acc@5: 87.5000 (92.1785)  time: 0.3486  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [ 530/4579]  eta: 0:26:50  Lr: 0.001875  Loss: -0.6912  Acc@1: 62.5000 (65.5720)  Acc@5: 93.7500 (92.2434)  time: 0.3495  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [ 540/4579]  eta: 0:26:43  Lr: 0.001875  Loss: -0.5174  Acc@1: 62.5000 (65.5846)  Acc@5: 93.7500 (92.2713)  time: 0.3553  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 550/4579]  eta: 0:26:38  Lr: 0.001875  Loss: 0.4581  Acc@1: 62.5000 (65.6193)  Acc@5: 93.7500 (92.3094)  time: 0.3679  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 560/4579]  eta: 0:26:31  Lr: 0.001875  Loss: -0.2039  Acc@1: 62.5000 (65.5971)  Acc@5: 93.7500 (92.2794)  time: 0.3679  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 570/4579]  eta: 0:26:24  Lr: 0.001875  Loss: -0.0965  Acc@1: 62.5000 (65.5539)  Acc@5: 93.7500 (92.2723)  time: 0.3550  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 580/4579]  eta: 0:26:17  Lr: 0.001875  Loss: -0.0629  Acc@1: 62.5000 (65.5443)  Acc@5: 93.7500 (92.3085)  time: 0.3494  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 590/4579]  eta: 0:26:10  Lr: 0.001875  Loss: -0.2234  Acc@1: 62.5000 (65.5351)  Acc@5: 93.7500 (92.2483)  time: 0.3496  data: 0.0011  max mem: 2500
Train: Epoch[5/5]  [ 600/4579]  eta: 0:26:03  Lr: 0.001875  Loss: -0.8558  Acc@1: 68.7500 (65.5158)  Acc@5: 93.7500 (92.2213)  time: 0.3500  data: 0.0011  max mem: 2500
Train: Epoch[5/5]  [ 610/4579]  eta: 0:25:56  Lr: 0.001875  Loss: -0.4318  Acc@1: 62.5000 (65.5176)  Acc@5: 93.7500 (92.2565)  time: 0.3498  data: 0.0010  max mem: 2500
Train: Epoch[5/5]  [ 620/4579]  eta: 0:25:50  Lr: 0.001875  Loss: -0.2380  Acc@1: 62.5000 (65.5395)  Acc@5: 93.7500 (92.2303)  time: 0.3510  data: 0.0013  max mem: 2500
Train: Epoch[5/5]  [ 630/4579]  eta: 0:25:43  Lr: 0.001875  Loss: -0.8350  Acc@1: 68.7500 (65.6498)  Acc@5: 93.7500 (92.2940)  time: 0.3515  data: 0.0015  max mem: 2500
Train: Epoch[5/5]  [ 640/4579]  eta: 0:25:37  Lr: 0.001875  Loss: -0.4915  Acc@1: 68.7500 (65.6689)  Acc@5: 93.7500 (92.2582)  time: 0.3517  data: 0.0011  max mem: 2500
Train: Epoch[5/5]  [ 650/4579]  eta: 0:25:31  Lr: 0.001875  Loss: -0.3285  Acc@1: 68.7500 (65.6490)  Acc@5: 93.7500 (92.2523)  time: 0.3512  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 660/4579]  eta: 0:25:24  Lr: 0.001875  Loss: -0.8977  Acc@1: 62.5000 (65.6203)  Acc@5: 93.7500 (92.2561)  time: 0.3494  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 670/4579]  eta: 0:25:18  Lr: 0.001875  Loss: -0.3927  Acc@1: 62.5000 (65.4806)  Acc@5: 93.7500 (92.2411)  time: 0.3497  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 680/4579]  eta: 0:25:12  Lr: 0.001875  Loss: -0.1258  Acc@1: 62.5000 (65.3910)  Acc@5: 93.7500 (92.1806)  time: 0.3503  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [ 690/4579]  eta: 0:25:06  Lr: 0.001875  Loss: -0.6395  Acc@1: 62.5000 (65.4034)  Acc@5: 93.7500 (92.1852)  time: 0.3496  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 700/4579]  eta: 0:25:00  Lr: 0.001875  Loss: -0.2967  Acc@1: 68.7500 (65.4957)  Acc@5: 93.7500 (92.1808)  time: 0.3502  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 710/4579]  eta: 0:24:54  Lr: 0.001875  Loss: -1.0178  Acc@1: 68.7500 (65.5503)  Acc@5: 93.7500 (92.2205)  time: 0.3518  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [ 720/4579]  eta: 0:24:49  Lr: 0.001875  Loss: -0.1634  Acc@1: 62.5000 (65.5080)  Acc@5: 93.7500 (92.2417)  time: 0.3517  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [ 730/4579]  eta: 0:24:43  Lr: 0.001875  Loss: -0.5653  Acc@1: 62.5000 (65.5523)  Acc@5: 93.7500 (92.3051)  time: 0.3537  data: 0.0013  max mem: 2500
Train: Epoch[5/5]  [ 740/4579]  eta: 0:24:38  Lr: 0.001875  Loss: -1.0165  Acc@1: 68.7500 (65.5870)  Acc@5: 93.7500 (92.3246)  time: 0.3536  data: 0.0012  max mem: 2500
Train: Epoch[5/5]  [ 750/4579]  eta: 0:24:32  Lr: 0.001875  Loss: -0.3100  Acc@1: 62.5000 (65.4877)  Acc@5: 93.7500 (92.2853)  time: 0.3508  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 760/4579]  eta: 0:24:26  Lr: 0.001875  Loss: -0.9327  Acc@1: 56.2500 (65.4402)  Acc@5: 87.5000 (92.2470)  time: 0.3494  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 770/4579]  eta: 0:24:21  Lr: 0.001875  Loss: -0.2431  Acc@1: 62.5000 (65.4183)  Acc@5: 87.5000 (92.2179)  time: 0.3495  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 780/4579]  eta: 0:24:15  Lr: 0.001875  Loss: -0.5301  Acc@1: 62.5000 (65.4449)  Acc@5: 93.7500 (92.2295)  time: 0.3494  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [ 790/4579]  eta: 0:24:10  Lr: 0.001875  Loss: -0.2867  Acc@1: 62.5000 (65.3761)  Acc@5: 93.7500 (92.1934)  time: 0.3495  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [ 800/4579]  eta: 0:24:05  Lr: 0.001875  Loss: 0.2049  Acc@1: 62.5000 (65.3480)  Acc@5: 87.5000 (92.1973)  time: 0.3509  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [ 810/4579]  eta: 0:23:59  Lr: 0.001875  Loss: -0.3342  Acc@1: 62.5000 (65.3437)  Acc@5: 93.7500 (92.1702)  time: 0.3512  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 820/4579]  eta: 0:23:54  Lr: 0.001875  Loss: -0.2733  Acc@1: 62.5000 (65.3015)  Acc@5: 93.7500 (92.1894)  time: 0.3503  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [ 830/4579]  eta: 0:23:49  Lr: 0.001875  Loss: -0.5681  Acc@1: 68.7500 (65.3129)  Acc@5: 93.7500 (92.1931)  time: 0.3500  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [ 840/4579]  eta: 0:23:44  Lr: 0.001875  Loss: -0.4561  Acc@1: 68.7500 (65.3686)  Acc@5: 93.7500 (92.1894)  time: 0.3507  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 850/4579]  eta: 0:23:38  Lr: 0.001875  Loss: -0.3420  Acc@1: 62.5000 (65.3422)  Acc@5: 93.7500 (92.1710)  time: 0.3511  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 860/4579]  eta: 0:23:33  Lr: 0.001875  Loss: -0.8759  Acc@1: 62.5000 (65.4109)  Acc@5: 93.7500 (92.1603)  time: 0.3509  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 870/4579]  eta: 0:23:28  Lr: 0.001875  Loss: -0.0721  Acc@1: 68.7500 (65.4061)  Acc@5: 93.7500 (92.1283)  time: 0.3506  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 880/4579]  eta: 0:23:23  Lr: 0.001875  Loss: -0.4383  Acc@1: 68.7500 (65.4299)  Acc@5: 87.5000 (92.1325)  time: 0.3511  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [ 890/4579]  eta: 0:23:18  Lr: 0.001875  Loss: -0.6628  Acc@1: 68.7500 (65.3970)  Acc@5: 87.5000 (92.0735)  time: 0.3508  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [ 900/4579]  eta: 0:23:13  Lr: 0.001875  Loss: -0.1294  Acc@1: 62.5000 (65.4134)  Acc@5: 87.5000 (92.0921)  time: 0.3512  data: 0.0012  max mem: 2500
Train: Epoch[5/5]  [ 910/4579]  eta: 0:23:08  Lr: 0.001875  Loss: -0.4392  Acc@1: 62.5000 (65.3677)  Acc@5: 93.7500 (92.0829)  time: 0.3510  data: 0.0011  max mem: 2500
Train: Epoch[5/5]  [ 920/4579]  eta: 0:23:04  Lr: 0.001875  Loss: -0.5491  Acc@1: 62.5000 (65.3841)  Acc@5: 93.7500 (92.1010)  time: 0.3499  data: 0.0012  max mem: 2500
Train: Epoch[5/5]  [ 930/4579]  eta: 0:22:59  Lr: 0.001875  Loss: -0.4203  Acc@1: 62.5000 (65.3128)  Acc@5: 87.5000 (92.0448)  time: 0.3507  data: 0.0012  max mem: 2500
Train: Epoch[5/5]  [ 940/4579]  eta: 0:22:54  Lr: 0.001875  Loss: -0.7515  Acc@1: 62.5000 (65.3626)  Acc@5: 87.5000 (92.0497)  time: 0.3510  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 950/4579]  eta: 0:22:49  Lr: 0.001875  Loss: -0.4821  Acc@1: 68.7500 (65.3851)  Acc@5: 93.7500 (92.0544)  time: 0.3511  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 960/4579]  eta: 0:22:44  Lr: 0.001875  Loss: -0.3043  Acc@1: 68.7500 (65.4331)  Acc@5: 93.7500 (92.0656)  time: 0.3504  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [ 970/4579]  eta: 0:22:39  Lr: 0.001875  Loss: -0.6732  Acc@1: 68.7500 (65.4158)  Acc@5: 93.7500 (92.0507)  time: 0.3495  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [ 980/4579]  eta: 0:22:35  Lr: 0.001875  Loss: -0.2703  Acc@1: 62.5000 (65.3988)  Acc@5: 87.5000 (92.0489)  time: 0.3516  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 990/4579]  eta: 0:22:30  Lr: 0.001875  Loss: -0.1532  Acc@1: 62.5000 (65.3696)  Acc@5: 87.5000 (92.0030)  time: 0.3529  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [1000/4579]  eta: 0:22:26  Lr: 0.001875  Loss: -0.7175  Acc@1: 62.5000 (65.3784)  Acc@5: 87.5000 (92.0080)  time: 0.3515  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [1010/4579]  eta: 0:22:21  Lr: 0.001875  Loss: -0.9144  Acc@1: 62.5000 (65.4179)  Acc@5: 93.7500 (92.0190)  time: 0.3504  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1020/4579]  eta: 0:22:16  Lr: 0.001875  Loss: 0.1538  Acc@1: 62.5000 (65.3220)  Acc@5: 87.5000 (91.9625)  time: 0.3505  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [1030/4579]  eta: 0:22:12  Lr: 0.001875  Loss: -0.8990  Acc@1: 62.5000 (65.3310)  Acc@5: 87.5000 (91.9496)  time: 0.3512  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [1040/4579]  eta: 0:22:07  Lr: 0.001875  Loss: -0.4451  Acc@1: 62.5000 (65.2438)  Acc@5: 87.5000 (91.9248)  time: 0.3513  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [1050/4579]  eta: 0:22:02  Lr: 0.001875  Loss: -0.6482  Acc@1: 62.5000 (65.2414)  Acc@5: 87.5000 (91.9006)  time: 0.3502  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [1060/4579]  eta: 0:21:58  Lr: 0.001875  Loss: -0.1954  Acc@1: 62.5000 (65.1861)  Acc@5: 87.5000 (91.9121)  time: 0.3503  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [1070/4579]  eta: 0:21:53  Lr: 0.001875  Loss: 0.0312  Acc@1: 62.5000 (65.1494)  Acc@5: 87.5000 (91.8709)  time: 0.3519  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [1080/4579]  eta: 0:21:49  Lr: 0.001875  Loss: -0.1366  Acc@1: 62.5000 (65.1249)  Acc@5: 87.5000 (91.8536)  time: 0.3511  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1090/4579]  eta: 0:21:44  Lr: 0.001875  Loss: -0.5785  Acc@1: 62.5000 (65.1180)  Acc@5: 93.7500 (91.8939)  time: 0.3503  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1100/4579]  eta: 0:21:40  Lr: 0.001875  Loss: -0.5662  Acc@1: 68.7500 (65.1396)  Acc@5: 93.7500 (91.8937)  time: 0.3512  data: 0.0011  max mem: 2500
Train: Epoch[5/5]  [1110/4579]  eta: 0:21:35  Lr: 0.001875  Loss: -0.4835  Acc@1: 68.7500 (65.1609)  Acc@5: 93.7500 (91.8936)  time: 0.3513  data: 0.0012  max mem: 2500
Train: Epoch[5/5]  [1120/4579]  eta: 0:21:31  Lr: 0.001875  Loss: -0.5469  Acc@1: 62.5000 (65.1539)  Acc@5: 93.7500 (91.8711)  time: 0.3511  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [1130/4579]  eta: 0:21:27  Lr: 0.001875  Loss: -1.0219  Acc@1: 62.5000 (65.1967)  Acc@5: 93.7500 (91.8877)  time: 0.3515  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1140/4579]  eta: 0:21:22  Lr: 0.001875  Loss: -0.4617  Acc@1: 68.7500 (65.2279)  Acc@5: 93.7500 (91.8766)  time: 0.3515  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1150/4579]  eta: 0:21:18  Lr: 0.001875  Loss: -0.6062  Acc@1: 68.7500 (65.2530)  Acc@5: 87.5000 (91.8766)  time: 0.3503  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [1160/4579]  eta: 0:21:13  Lr: 0.001875  Loss: -0.0878  Acc@1: 62.5000 (65.2562)  Acc@5: 87.5000 (91.8120)  time: 0.3499  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [1170/4579]  eta: 0:21:09  Lr: 0.001875  Loss: 0.0194  Acc@1: 62.5000 (65.2487)  Acc@5: 87.5000 (91.8126)  time: 0.3497  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [1180/4579]  eta: 0:21:05  Lr: 0.001875  Loss: -0.7800  Acc@1: 68.7500 (65.3048)  Acc@5: 93.7500 (91.8395)  time: 0.3493  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [1190/4579]  eta: 0:21:00  Lr: 0.001875  Loss: -0.4709  Acc@1: 68.7500 (65.3495)  Acc@5: 93.7500 (91.8451)  time: 0.3502  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [1200/4579]  eta: 0:20:56  Lr: 0.001875  Loss: -0.0215  Acc@1: 62.5000 (65.3414)  Acc@5: 93.7500 (91.8297)  time: 0.3503  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [1210/4579]  eta: 0:20:52  Lr: 0.001875  Loss: -0.8814  Acc@1: 62.5000 (65.3489)  Acc@5: 93.7500 (91.8249)  time: 0.3500  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [1220/4579]  eta: 0:20:47  Lr: 0.001875  Loss: -0.1120  Acc@1: 62.5000 (65.3256)  Acc@5: 93.7500 (91.8305)  time: 0.3515  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [1230/4579]  eta: 0:20:43  Lr: 0.001875  Loss: 0.0744  Acc@1: 62.5000 (65.3229)  Acc@5: 93.7500 (91.8410)  time: 0.3503  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [1240/4579]  eta: 0:20:39  Lr: 0.001875  Loss: -0.7145  Acc@1: 62.5000 (65.3304)  Acc@5: 93.7500 (91.8413)  time: 0.3490  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1250/4579]  eta: 0:20:35  Lr: 0.001875  Loss: -0.5965  Acc@1: 68.7500 (65.3577)  Acc@5: 93.7500 (91.8415)  time: 0.3501  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [1260/4579]  eta: 0:20:30  Lr: 0.001875  Loss: -0.6211  Acc@1: 62.5000 (65.3251)  Acc@5: 93.7500 (91.8220)  time: 0.3500  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [1270/4579]  eta: 0:20:26  Lr: 0.001875  Loss: -0.4932  Acc@1: 62.5000 (65.2882)  Acc@5: 87.5000 (91.8224)  time: 0.3502  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [1280/4579]  eta: 0:20:22  Lr: 0.001875  Loss: -0.5800  Acc@1: 68.7500 (65.2957)  Acc@5: 93.7500 (91.8228)  time: 0.3507  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [1290/4579]  eta: 0:20:18  Lr: 0.001875  Loss: -0.5021  Acc@1: 68.7500 (65.3224)  Acc@5: 93.7500 (91.8377)  time: 0.3499  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [1300/4579]  eta: 0:20:13  Lr: 0.001875  Loss: 0.4178  Acc@1: 62.5000 (65.2959)  Acc@5: 93.7500 (91.8428)  time: 0.3508  data: 0.0012  max mem: 2500
Train: Epoch[5/5]  [1310/4579]  eta: 0:20:09  Lr: 0.001875  Loss: -0.6474  Acc@1: 68.7500 (65.3413)  Acc@5: 93.7500 (91.8717)  time: 0.3525  data: 0.0013  max mem: 2500
Train: Epoch[5/5]  [1320/4579]  eta: 0:20:05  Lr: 0.001875  Loss: -0.6244  Acc@1: 68.7500 (65.3388)  Acc@5: 93.7500 (91.8717)  time: 0.3501  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1330/4579]  eta: 0:20:01  Lr: 0.001875  Loss: -0.6540  Acc@1: 62.5000 (65.3221)  Acc@5: 93.7500 (91.8811)  time: 0.3482  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [1340/4579]  eta: 0:19:57  Lr: 0.001875  Loss: -0.1146  Acc@1: 62.5000 (65.3151)  Acc@5: 93.7500 (91.8717)  time: 0.3493  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [1350/4579]  eta: 0:19:52  Lr: 0.001875  Loss: -0.4171  Acc@1: 62.5000 (65.3035)  Acc@5: 93.7500 (91.8949)  time: 0.3482  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [1360/4579]  eta: 0:19:48  Lr: 0.001875  Loss: -0.6800  Acc@1: 62.5000 (65.2691)  Acc@5: 93.7500 (91.8764)  time: 0.3468  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [1370/4579]  eta: 0:19:44  Lr: 0.001875  Loss: -0.5616  Acc@1: 62.5000 (65.2671)  Acc@5: 87.5000 (91.8718)  time: 0.3481  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [1380/4579]  eta: 0:19:40  Lr: 0.001875  Loss: -0.6784  Acc@1: 62.5000 (65.2562)  Acc@5: 93.7500 (91.8764)  time: 0.3489  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [1390/4579]  eta: 0:19:36  Lr: 0.001875  Loss: -0.5710  Acc@1: 62.5000 (65.2318)  Acc@5: 93.7500 (91.8763)  time: 0.3484  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [1400/4579]  eta: 0:19:32  Lr: 0.001875  Loss: -0.2624  Acc@1: 62.5000 (65.2347)  Acc@5: 93.7500 (91.8808)  time: 0.3489  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [1410/4579]  eta: 0:19:27  Lr: 0.001875  Loss: 0.6682  Acc@1: 68.7500 (65.2330)  Acc@5: 93.7500 (91.8630)  time: 0.3480  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1420/4579]  eta: 0:19:23  Lr: 0.001875  Loss: -0.7237  Acc@1: 62.5000 (65.2094)  Acc@5: 87.5000 (91.8367)  time: 0.3492  data: 0.0020  max mem: 2500
Train: Epoch[5/5]  [1430/4579]  eta: 0:19:19  Lr: 0.001875  Loss: -0.3671  Acc@1: 56.2500 (65.1861)  Acc@5: 93.7500 (91.8501)  time: 0.3491  data: 0.0020  max mem: 2500
Train: Epoch[5/5]  [1440/4579]  eta: 0:19:15  Lr: 0.001875  Loss: -0.2264  Acc@1: 62.5000 (65.1848)  Acc@5: 93.7500 (91.8720)  time: 0.3472  data: 0.0011  max mem: 2500
Train: Epoch[5/5]  [1450/4579]  eta: 0:19:11  Lr: 0.001875  Loss: -0.6286  Acc@1: 62.5000 (65.1835)  Acc@5: 93.7500 (91.8634)  time: 0.3472  data: 0.0011  max mem: 2500
Train: Epoch[5/5]  [1460/4579]  eta: 0:19:07  Lr: 0.001875  Loss: -0.2320  Acc@1: 62.5000 (65.2336)  Acc@5: 93.7500 (91.8806)  time: 0.3471  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [1470/4579]  eta: 0:19:03  Lr: 0.001875  Loss: -0.7413  Acc@1: 68.7500 (65.2702)  Acc@5: 93.7500 (91.8975)  time: 0.3488  data: 0.0013  max mem: 2500
Train: Epoch[5/5]  [1480/4579]  eta: 0:18:59  Lr: 0.001875  Loss: 0.1129  Acc@1: 62.5000 (65.2135)  Acc@5: 93.7500 (91.8974)  time: 0.3499  data: 0.0028  max mem: 2500
Train: Epoch[5/5]  [1490/4579]  eta: 0:18:54  Lr: 0.001875  Loss: 0.0750  Acc@1: 56.2500 (65.2289)  Acc@5: 87.5000 (91.8930)  time: 0.3480  data: 0.0020  max mem: 2500
Train: Epoch[5/5]  [1500/4579]  eta: 0:18:50  Lr: 0.001875  Loss: -0.6992  Acc@1: 62.5000 (65.2315)  Acc@5: 93.7500 (91.8971)  time: 0.3471  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [1510/4579]  eta: 0:18:46  Lr: 0.001875  Loss: -0.0162  Acc@1: 62.5000 (65.2134)  Acc@5: 93.7500 (91.8969)  time: 0.3479  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [1520/4579]  eta: 0:18:42  Lr: 0.001875  Loss: -0.1023  Acc@1: 68.7500 (65.2490)  Acc@5: 93.7500 (91.9091)  time: 0.3473  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1530/4579]  eta: 0:18:38  Lr: 0.001875  Loss: -0.1203  Acc@1: 68.7500 (65.2392)  Acc@5: 93.7500 (91.9007)  time: 0.3469  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1540/4579]  eta: 0:18:34  Lr: 0.001875  Loss: -0.6135  Acc@1: 62.5000 (65.2336)  Acc@5: 87.5000 (91.8843)  time: 0.3479  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [1550/4579]  eta: 0:18:30  Lr: 0.001875  Loss: -0.0799  Acc@1: 62.5000 (65.2281)  Acc@5: 93.7500 (91.8843)  time: 0.3488  data: 0.0013  max mem: 2500
Train: Epoch[5/5]  [1560/4579]  eta: 0:18:26  Lr: 0.001875  Loss: -0.1830  Acc@1: 62.5000 (65.2426)  Acc@5: 93.7500 (91.8962)  time: 0.3480  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [1570/4579]  eta: 0:18:22  Lr: 0.001875  Loss: -0.5830  Acc@1: 68.7500 (65.2729)  Acc@5: 93.7500 (91.9160)  time: 0.3473  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1580/4579]  eta: 0:18:18  Lr: 0.001875  Loss: -0.1102  Acc@1: 62.5000 (65.2593)  Acc@5: 93.7500 (91.9118)  time: 0.3474  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1590/4579]  eta: 0:18:14  Lr: 0.001875  Loss: -0.3531  Acc@1: 68.7500 (65.2773)  Acc@5: 93.7500 (91.9194)  time: 0.3477  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1600/4579]  eta: 0:18:10  Lr: 0.001875  Loss: -0.5063  Acc@1: 68.7500 (65.2756)  Acc@5: 93.7500 (91.9269)  time: 0.3483  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [1610/4579]  eta: 0:18:06  Lr: 0.001875  Loss: -0.5505  Acc@1: 62.5000 (65.2739)  Acc@5: 93.7500 (91.9344)  time: 0.3488  data: 0.0010  max mem: 2500
Train: Epoch[5/5]  [1620/4579]  eta: 0:18:02  Lr: 0.001875  Loss: -0.2780  Acc@1: 62.5000 (65.2452)  Acc@5: 93.7500 (91.9224)  time: 0.3482  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [1630/4579]  eta: 0:17:58  Lr: 0.001875  Loss: 0.1684  Acc@1: 62.5000 (65.2514)  Acc@5: 93.7500 (91.9336)  time: 0.3482  data: 0.0011  max mem: 2500
Train: Epoch[5/5]  [1640/4579]  eta: 0:17:54  Lr: 0.001875  Loss: -0.0760  Acc@1: 62.5000 (65.2346)  Acc@5: 93.7500 (91.9333)  time: 0.3487  data: 0.0011  max mem: 2500
Train: Epoch[5/5]  [1650/4579]  eta: 0:17:50  Lr: 0.001875  Loss: -0.3917  Acc@1: 62.5000 (65.2105)  Acc@5: 93.7500 (91.9291)  time: 0.3486  data: 0.0012  max mem: 2500
Train: Epoch[5/5]  [1660/4579]  eta: 0:17:46  Lr: 0.001875  Loss: -0.2985  Acc@1: 62.5000 (65.2167)  Acc@5: 93.7500 (91.9401)  time: 0.3481  data: 0.0013  max mem: 2500
Train: Epoch[5/5]  [1670/4579]  eta: 0:17:42  Lr: 0.001875  Loss: -0.7515  Acc@1: 68.7500 (65.2267)  Acc@5: 93.7500 (91.9360)  time: 0.3474  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1680/4579]  eta: 0:17:38  Lr: 0.001875  Loss: -0.0043  Acc@1: 68.7500 (65.2290)  Acc@5: 93.7500 (91.9282)  time: 0.3482  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1690/4579]  eta: 0:17:34  Lr: 0.001875  Loss: -0.2378  Acc@1: 62.5000 (65.2240)  Acc@5: 87.5000 (91.9205)  time: 0.3513  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1700/4579]  eta: 0:17:31  Lr: 0.001875  Loss: -0.2568  Acc@1: 56.2500 (65.1969)  Acc@5: 93.7500 (91.9055)  time: 0.3512  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [1710/4579]  eta: 0:17:27  Lr: 0.001875  Loss: -0.6083  Acc@1: 62.5000 (65.1848)  Acc@5: 93.7500 (91.9163)  time: 0.3478  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [1720/4579]  eta: 0:17:23  Lr: 0.001875  Loss: -0.3737  Acc@1: 62.5000 (65.1983)  Acc@5: 93.7500 (91.9342)  time: 0.3474  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1730/4579]  eta: 0:17:19  Lr: 0.001875  Loss: -0.5335  Acc@1: 68.7500 (65.1971)  Acc@5: 93.7500 (91.9447)  time: 0.3476  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [1740/4579]  eta: 0:17:15  Lr: 0.001875  Loss: -0.5075  Acc@1: 62.5000 (65.1816)  Acc@5: 93.7500 (91.9551)  time: 0.3484  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [1750/4579]  eta: 0:17:11  Lr: 0.001875  Loss: -0.1726  Acc@1: 62.5000 (65.1842)  Acc@5: 93.7500 (91.9475)  time: 0.3489  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [1760/4579]  eta: 0:17:07  Lr: 0.001875  Loss: 0.0243  Acc@1: 62.5000 (65.1725)  Acc@5: 87.5000 (91.9364)  time: 0.3482  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [1770/4579]  eta: 0:17:03  Lr: 0.001875  Loss: -0.7460  Acc@1: 62.5000 (65.1539)  Acc@5: 87.5000 (91.9255)  time: 0.3486  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [1780/4579]  eta: 0:16:59  Lr: 0.001875  Loss: -0.5150  Acc@1: 68.7500 (65.1635)  Acc@5: 87.5000 (91.9182)  time: 0.3491  data: 0.0012  max mem: 2500
Train: Epoch[5/5]  [1790/4579]  eta: 0:16:55  Lr: 0.001875  Loss: -0.2119  Acc@1: 68.7500 (65.1591)  Acc@5: 93.7500 (91.9214)  time: 0.3482  data: 0.0012  max mem: 2500
Train: Epoch[5/5]  [1800/4579]  eta: 0:16:51  Lr: 0.001875  Loss: -0.4378  Acc@1: 68.7500 (65.1860)  Acc@5: 93.7500 (91.9316)  time: 0.3482  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [1810/4579]  eta: 0:16:48  Lr: 0.001875  Loss: -0.5337  Acc@1: 68.7500 (65.2022)  Acc@5: 93.7500 (91.9244)  time: 0.3484  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [1820/4579]  eta: 0:16:44  Lr: 0.001875  Loss: 0.0704  Acc@1: 68.7500 (65.2080)  Acc@5: 93.7500 (91.9344)  time: 0.3493  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1830/4579]  eta: 0:16:40  Lr: 0.001875  Loss: -0.5899  Acc@1: 68.7500 (65.2205)  Acc@5: 93.7500 (91.9375)  time: 0.3508  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1840/4579]  eta: 0:16:36  Lr: 0.001875  Loss: -0.3300  Acc@1: 68.7500 (65.2159)  Acc@5: 93.7500 (91.9405)  time: 0.3496  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1850/4579]  eta: 0:16:32  Lr: 0.001875  Loss: -0.0586  Acc@1: 62.5000 (65.1877)  Acc@5: 93.7500 (91.9368)  time: 0.3493  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [1860/4579]  eta: 0:16:28  Lr: 0.001875  Loss: -0.5570  Acc@1: 62.5000 (65.1934)  Acc@5: 93.7500 (91.9297)  time: 0.3506  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [1870/4579]  eta: 0:16:24  Lr: 0.001875  Loss: -0.4334  Acc@1: 68.7500 (65.2392)  Acc@5: 93.7500 (91.9328)  time: 0.3499  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [1880/4579]  eta: 0:16:21  Lr: 0.001875  Loss: -0.1642  Acc@1: 68.7500 (65.2479)  Acc@5: 93.7500 (91.9358)  time: 0.3487  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [1890/4579]  eta: 0:16:17  Lr: 0.001875  Loss: -0.6947  Acc@1: 62.5000 (65.2333)  Acc@5: 93.7500 (91.9388)  time: 0.3513  data: 0.0010  max mem: 2500
Train: Epoch[5/5]  [1900/4579]  eta: 0:16:13  Lr: 0.001875  Loss: -0.8078  Acc@1: 62.5000 (65.2486)  Acc@5: 93.7500 (91.9549)  time: 0.3513  data: 0.0010  max mem: 2500
Train: Epoch[5/5]  [1910/4579]  eta: 0:16:09  Lr: 0.001875  Loss: -0.9278  Acc@1: 68.7500 (65.2767)  Acc@5: 93.7500 (91.9643)  time: 0.3493  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1920/4579]  eta: 0:16:05  Lr: 0.001875  Loss: -0.1837  Acc@1: 62.5000 (65.2590)  Acc@5: 93.7500 (91.9736)  time: 0.3492  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1930/4579]  eta: 0:16:02  Lr: 0.001875  Loss: -0.9071  Acc@1: 62.5000 (65.2641)  Acc@5: 93.7500 (91.9893)  time: 0.3486  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1940/4579]  eta: 0:15:58  Lr: 0.001875  Loss: -1.0279  Acc@1: 68.7500 (65.2724)  Acc@5: 93.7500 (92.0015)  time: 0.3488  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1950/4579]  eta: 0:15:54  Lr: 0.001875  Loss: -0.6286  Acc@1: 68.7500 (65.2966)  Acc@5: 93.7500 (92.0073)  time: 0.3492  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [1960/4579]  eta: 0:15:50  Lr: 0.001875  Loss: -0.4128  Acc@1: 68.7500 (65.3079)  Acc@5: 93.7500 (92.0162)  time: 0.3483  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1970/4579]  eta: 0:15:46  Lr: 0.001875  Loss: -0.5990  Acc@1: 68.7500 (65.3031)  Acc@5: 93.7500 (92.0091)  time: 0.3479  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1980/4579]  eta: 0:15:42  Lr: 0.001875  Loss: -0.1336  Acc@1: 68.7500 (65.3395)  Acc@5: 93.7500 (92.0116)  time: 0.3491  data: 0.0014  max mem: 2500
Train: Epoch[5/5]  [1990/4579]  eta: 0:15:39  Lr: 0.001875  Loss: -0.9118  Acc@1: 68.7500 (65.3629)  Acc@5: 93.7500 (92.0172)  time: 0.3495  data: 0.0014  max mem: 2500
Train: Epoch[5/5]  [2000/4579]  eta: 0:15:35  Lr: 0.001875  Loss: -0.4866  Acc@1: 68.7500 (65.3611)  Acc@5: 93.7500 (92.0290)  time: 0.3486  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [2010/4579]  eta: 0:15:31  Lr: 0.001875  Loss: -0.1846  Acc@1: 68.7500 (65.3841)  Acc@5: 93.7500 (92.0313)  time: 0.3493  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [2020/4579]  eta: 0:15:27  Lr: 0.001875  Loss: -0.0720  Acc@1: 68.7500 (65.3730)  Acc@5: 93.7500 (92.0306)  time: 0.3491  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [2030/4579]  eta: 0:15:23  Lr: 0.001875  Loss: -0.5341  Acc@1: 62.5000 (65.3619)  Acc@5: 93.7500 (92.0236)  time: 0.3486  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [2040/4579]  eta: 0:15:20  Lr: 0.001875  Loss: -0.6446  Acc@1: 68.7500 (65.3693)  Acc@5: 93.7500 (92.0352)  time: 0.3494  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [2050/4579]  eta: 0:15:16  Lr: 0.001875  Loss: -0.9806  Acc@1: 68.7500 (65.3827)  Acc@5: 93.7500 (92.0374)  time: 0.3504  data: 0.0014  max mem: 2500
Train: Epoch[5/5]  [2060/4579]  eta: 0:15:12  Lr: 0.001875  Loss: 0.1183  Acc@1: 68.7500 (65.4021)  Acc@5: 93.7500 (92.0306)  time: 0.3508  data: 0.0020  max mem: 2500
Train: Epoch[5/5]  [2070/4579]  eta: 0:15:08  Lr: 0.001875  Loss: -0.7323  Acc@1: 62.5000 (65.4032)  Acc@5: 87.5000 (92.0117)  time: 0.3498  data: 0.0018  max mem: 2500
Train: Epoch[5/5]  [2080/4579]  eta: 0:15:05  Lr: 0.001875  Loss: 0.0867  Acc@1: 62.5000 (65.3982)  Acc@5: 87.5000 (92.0171)  time: 0.3492  data: 0.0015  max mem: 2500
Train: Epoch[5/5]  [2090/4579]  eta: 0:15:01  Lr: 0.001875  Loss: -0.0103  Acc@1: 68.7500 (65.4203)  Acc@5: 93.7500 (92.0194)  time: 0.3486  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [2100/4579]  eta: 0:14:57  Lr: 0.001875  Loss: -0.5557  Acc@1: 62.5000 (65.4034)  Acc@5: 93.7500 (92.0127)  time: 0.3484  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2110/4579]  eta: 0:14:53  Lr: 0.001875  Loss: -0.2764  Acc@1: 62.5000 (65.4133)  Acc@5: 93.7500 (92.0062)  time: 0.3480  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2120/4579]  eta: 0:14:49  Lr: 0.001875  Loss: -0.2304  Acc@1: 68.7500 (65.4202)  Acc@5: 93.7500 (92.0321)  time: 0.3484  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2130/4579]  eta: 0:14:46  Lr: 0.001875  Loss: -0.5469  Acc@1: 68.7500 (65.4270)  Acc@5: 93.7500 (92.0372)  time: 0.3497  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [2140/4579]  eta: 0:14:42  Lr: 0.001875  Loss: -0.3696  Acc@1: 62.5000 (65.4075)  Acc@5: 93.7500 (92.0364)  time: 0.3488  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [2150/4579]  eta: 0:14:38  Lr: 0.001875  Loss: -0.7362  Acc@1: 62.5000 (65.4085)  Acc@5: 93.7500 (92.0328)  time: 0.3479  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2160/4579]  eta: 0:14:34  Lr: 0.001875  Loss: 0.0089  Acc@1: 68.7500 (65.4211)  Acc@5: 93.7500 (92.0407)  time: 0.3494  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2170/4579]  eta: 0:14:31  Lr: 0.001875  Loss: -0.8036  Acc@1: 68.7500 (65.4278)  Acc@5: 93.7500 (92.0544)  time: 0.3495  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2180/4579]  eta: 0:14:27  Lr: 0.001875  Loss: -0.8261  Acc@1: 62.5000 (65.4258)  Acc@5: 93.7500 (92.0593)  time: 0.3498  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2190/4579]  eta: 0:14:23  Lr: 0.001875  Loss: -0.6281  Acc@1: 62.5000 (65.4296)  Acc@5: 93.7500 (92.0727)  time: 0.3494  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2200/4579]  eta: 0:14:19  Lr: 0.001875  Loss: -0.9434  Acc@1: 62.5000 (65.4560)  Acc@5: 100.0000 (92.0888)  time: 0.3498  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [2210/4579]  eta: 0:14:16  Lr: 0.001875  Loss: -0.6501  Acc@1: 68.7500 (65.4822)  Acc@5: 93.7500 (92.1020)  time: 0.3518  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [2220/4579]  eta: 0:14:12  Lr: 0.001875  Loss: -0.5372  Acc@1: 68.7500 (65.4716)  Acc@5: 93.7500 (92.1038)  time: 0.3498  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [2230/4579]  eta: 0:14:08  Lr: 0.001875  Loss: -0.2895  Acc@1: 68.7500 (65.4975)  Acc@5: 93.7500 (92.1112)  time: 0.3488  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [2240/4579]  eta: 0:14:04  Lr: 0.001875  Loss: -0.4484  Acc@1: 68.7500 (65.4925)  Acc@5: 93.7500 (92.1185)  time: 0.3508  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [2250/4579]  eta: 0:14:01  Lr: 0.001875  Loss: -0.2959  Acc@1: 68.7500 (65.5014)  Acc@5: 93.7500 (92.1202)  time: 0.3508  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [2260/4579]  eta: 0:13:57  Lr: 0.001875  Loss: -0.3828  Acc@1: 62.5000 (65.4965)  Acc@5: 93.7500 (92.1191)  time: 0.3496  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [2270/4579]  eta: 0:13:53  Lr: 0.001875  Loss: -0.3118  Acc@1: 62.5000 (65.4805)  Acc@5: 93.7500 (92.1125)  time: 0.3492  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2280/4579]  eta: 0:13:50  Lr: 0.001875  Loss: -0.1797  Acc@1: 62.5000 (65.4948)  Acc@5: 93.7500 (92.1224)  time: 0.3489  data: 0.0011  max mem: 2500
Train: Epoch[5/5]  [2290/4579]  eta: 0:13:46  Lr: 0.001875  Loss: -0.1807  Acc@1: 68.7500 (65.5118)  Acc@5: 93.7500 (92.1323)  time: 0.3484  data: 0.0011  max mem: 2500
Train: Epoch[5/5]  [2300/4579]  eta: 0:13:42  Lr: 0.001875  Loss: -0.5127  Acc@1: 68.7500 (65.5096)  Acc@5: 93.7500 (92.1393)  time: 0.3476  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [2310/4579]  eta: 0:13:38  Lr: 0.001875  Loss: -0.3408  Acc@1: 68.7500 (65.5344)  Acc@5: 93.7500 (92.1381)  time: 0.3492  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [2320/4579]  eta: 0:13:35  Lr: 0.001875  Loss: -0.6442  Acc@1: 68.7500 (65.5348)  Acc@5: 93.7500 (92.1424)  time: 0.3495  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2330/4579]  eta: 0:13:31  Lr: 0.001875  Loss: 0.1032  Acc@1: 62.5000 (65.5352)  Acc@5: 93.7500 (92.1332)  time: 0.3480  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2340/4579]  eta: 0:13:27  Lr: 0.001875  Loss: -0.7671  Acc@1: 62.5000 (65.5142)  Acc@5: 93.7500 (92.1348)  time: 0.3479  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2350/4579]  eta: 0:13:23  Lr: 0.001875  Loss: -0.4786  Acc@1: 62.5000 (65.5200)  Acc@5: 93.7500 (92.1257)  time: 0.3485  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2360/4579]  eta: 0:13:20  Lr: 0.001875  Loss: -0.4011  Acc@1: 62.5000 (65.5178)  Acc@5: 93.7500 (92.1352)  time: 0.3495  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [2370/4579]  eta: 0:13:16  Lr: 0.001875  Loss: -0.5610  Acc@1: 68.7500 (65.5314)  Acc@5: 93.7500 (92.1262)  time: 0.3500  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [2380/4579]  eta: 0:13:12  Lr: 0.001875  Loss: -0.5946  Acc@1: 68.7500 (65.5449)  Acc@5: 93.7500 (92.1330)  time: 0.3487  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [2390/4579]  eta: 0:13:09  Lr: 0.001875  Loss: -0.4796  Acc@1: 62.5000 (65.5374)  Acc@5: 93.7500 (92.1372)  time: 0.3490  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [2400/4579]  eta: 0:13:05  Lr: 0.001875  Loss: -0.0691  Acc@1: 68.7500 (65.5326)  Acc@5: 93.7500 (92.1491)  time: 0.3495  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [2410/4579]  eta: 0:13:01  Lr: 0.001875  Loss: -0.4606  Acc@1: 68.7500 (65.5459)  Acc@5: 93.7500 (92.1583)  time: 0.3475  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2420/4579]  eta: 0:12:57  Lr: 0.001875  Loss: -0.8139  Acc@1: 68.7500 (65.5592)  Acc@5: 93.7500 (92.1572)  time: 0.3492  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2430/4579]  eta: 0:12:54  Lr: 0.001875  Loss: -0.6235  Acc@1: 68.7500 (65.5774)  Acc@5: 87.5000 (92.1534)  time: 0.3507  data: 0.0014  max mem: 2500
Train: Epoch[5/5]  [2440/4579]  eta: 0:12:50  Lr: 0.001875  Loss: -1.0605  Acc@1: 68.7500 (65.5776)  Acc@5: 87.5000 (92.1472)  time: 0.3517  data: 0.0014  max mem: 2500
Train: Epoch[5/5]  [2450/4579]  eta: 0:12:46  Lr: 0.001875  Loss: -0.3256  Acc@1: 62.5000 (65.5727)  Acc@5: 87.5000 (92.1435)  time: 0.3516  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [2460/4579]  eta: 0:12:43  Lr: 0.001875  Loss: -0.5225  Acc@1: 68.7500 (65.6034)  Acc@5: 93.7500 (92.1551)  time: 0.3514  data: 0.0018  max mem: 2500
Train: Epoch[5/5]  [2470/4579]  eta: 0:12:39  Lr: 0.001875  Loss: -0.1852  Acc@1: 68.7500 (65.6010)  Acc@5: 93.7500 (92.1439)  time: 0.3513  data: 0.0017  max mem: 2500
Train: Epoch[5/5]  [2480/4579]  eta: 0:12:35  Lr: 0.001875  Loss: -0.3557  Acc@1: 62.5000 (65.5784)  Acc@5: 87.5000 (92.1277)  time: 0.3487  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2490/4579]  eta: 0:12:32  Lr: 0.001875  Loss: -0.4407  Acc@1: 62.5000 (65.5961)  Acc@5: 93.7500 (92.1392)  time: 0.3491  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [2500/4579]  eta: 0:12:28  Lr: 0.001875  Loss: -0.2906  Acc@1: 62.5000 (65.5838)  Acc@5: 93.7500 (92.1531)  time: 0.3499  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [2510/4579]  eta: 0:12:24  Lr: 0.001875  Loss: -0.2614  Acc@1: 68.7500 (65.5964)  Acc@5: 93.7500 (92.1545)  time: 0.3497  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [2520/4579]  eta: 0:12:21  Lr: 0.001875  Loss: -0.3061  Acc@1: 68.7500 (65.6114)  Acc@5: 87.5000 (92.1410)  time: 0.3496  data: 0.0010  max mem: 2500
Train: Epoch[5/5]  [2530/4579]  eta: 0:12:17  Lr: 0.001875  Loss: -0.8396  Acc@1: 68.7500 (65.6065)  Acc@5: 87.5000 (92.1326)  time: 0.3500  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [2540/4579]  eta: 0:12:13  Lr: 0.001875  Loss: -0.0909  Acc@1: 68.7500 (65.6066)  Acc@5: 93.7500 (92.1414)  time: 0.3499  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [2550/4579]  eta: 0:12:10  Lr: 0.001875  Loss: -0.3782  Acc@1: 75.0000 (65.6115)  Acc@5: 93.7500 (92.1354)  time: 0.3488  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [2560/4579]  eta: 0:12:06  Lr: 0.001875  Loss: 0.0495  Acc@1: 68.7500 (65.6140)  Acc@5: 87.5000 (92.1222)  time: 0.3488  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [2570/4579]  eta: 0:12:02  Lr: 0.001875  Loss: -0.5753  Acc@1: 62.5000 (65.6311)  Acc@5: 93.7500 (92.1334)  time: 0.3503  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [2580/4579]  eta: 0:11:59  Lr: 0.001875  Loss: -0.1854  Acc@1: 62.5000 (65.6238)  Acc@5: 93.7500 (92.1179)  time: 0.3516  data: 0.0014  max mem: 2500
Train: Epoch[5/5]  [2590/4579]  eta: 0:11:55  Lr: 0.001875  Loss: 0.0605  Acc@1: 62.5000 (65.6190)  Acc@5: 87.5000 (92.1121)  time: 0.3508  data: 0.0012  max mem: 2500
Train: Epoch[5/5]  [2600/4579]  eta: 0:11:51  Lr: 0.001875  Loss: 0.3201  Acc@1: 68.7500 (65.6310)  Acc@5: 93.7500 (92.1136)  time: 0.3504  data: 0.0015  max mem: 2500
Train: Epoch[5/5]  [2610/4579]  eta: 0:11:48  Lr: 0.001875  Loss: 0.2023  Acc@1: 68.7500 (65.6406)  Acc@5: 93.7500 (92.1151)  time: 0.3520  data: 0.0025  max mem: 2500
Train: Epoch[5/5]  [2620/4579]  eta: 0:11:44  Lr: 0.001875  Loss: -0.5789  Acc@1: 62.5000 (65.6286)  Acc@5: 93.7500 (92.1046)  time: 0.3508  data: 0.0015  max mem: 2500
Train: Epoch[5/5]  [2630/4579]  eta: 0:11:40  Lr: 0.001875  Loss: -0.2093  Acc@1: 62.5000 (65.6381)  Acc@5: 93.7500 (92.1133)  time: 0.3485  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2640/4579]  eta: 0:11:37  Lr: 0.001875  Loss: -0.8207  Acc@1: 68.7500 (65.6427)  Acc@5: 93.7500 (92.1076)  time: 0.3500  data: 0.0014  max mem: 2500
Train: Epoch[5/5]  [2650/4579]  eta: 0:11:33  Lr: 0.001875  Loss: 0.1349  Acc@1: 62.5000 (65.6120)  Acc@5: 87.5000 (92.0926)  time: 0.3531  data: 0.0036  max mem: 2500
Train: Epoch[5/5]  [2660/4579]  eta: 0:11:29  Lr: 0.001875  Loss: -0.0269  Acc@1: 62.5000 (65.6027)  Acc@5: 87.5000 (92.0941)  time: 0.3527  data: 0.0031  max mem: 2500
Train: Epoch[5/5]  [2670/4579]  eta: 0:11:26  Lr: 0.001875  Loss: -0.2892  Acc@1: 62.5000 (65.5887)  Acc@5: 93.7500 (92.0863)  time: 0.3500  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [2680/4579]  eta: 0:11:22  Lr: 0.001875  Loss: -0.4627  Acc@1: 62.5000 (65.5772)  Acc@5: 93.7500 (92.0925)  time: 0.3509  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [2690/4579]  eta: 0:11:18  Lr: 0.001875  Loss: -0.6024  Acc@1: 68.7500 (65.5844)  Acc@5: 93.7500 (92.1033)  time: 0.3512  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [2700/4579]  eta: 0:11:15  Lr: 0.001875  Loss: -0.0155  Acc@1: 62.5000 (65.5637)  Acc@5: 93.7500 (92.1048)  time: 0.3493  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2710/4579]  eta: 0:11:11  Lr: 0.001875  Loss: -0.0954  Acc@1: 62.5000 (65.5731)  Acc@5: 93.7500 (92.1132)  time: 0.3491  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2720/4579]  eta: 0:11:07  Lr: 0.001875  Loss: -0.0561  Acc@1: 68.7500 (65.5894)  Acc@5: 93.7500 (92.1100)  time: 0.3492  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2730/4579]  eta: 0:11:04  Lr: 0.001875  Loss: -0.5571  Acc@1: 62.5000 (65.5941)  Acc@5: 87.5000 (92.1045)  time: 0.3492  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [2740/4579]  eta: 0:11:00  Lr: 0.001875  Loss: -0.4408  Acc@1: 62.5000 (65.5965)  Acc@5: 87.5000 (92.0969)  time: 0.3501  data: 0.0014  max mem: 2500
Train: Epoch[5/5]  [2750/4579]  eta: 0:10:56  Lr: 0.001875  Loss: -0.3006  Acc@1: 62.5000 (65.5943)  Acc@5: 93.7500 (92.1074)  time: 0.3514  data: 0.0019  max mem: 2500
Train: Epoch[5/5]  [2760/4579]  eta: 0:10:53  Lr: 0.001875  Loss: -0.5498  Acc@1: 62.5000 (65.5876)  Acc@5: 93.7500 (92.1134)  time: 0.3509  data: 0.0011  max mem: 2500
Train: Epoch[5/5]  [2770/4579]  eta: 0:10:49  Lr: 0.001875  Loss: -0.1316  Acc@1: 62.5000 (65.5743)  Acc@5: 93.7500 (92.1012)  time: 0.3493  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [2780/4579]  eta: 0:10:45  Lr: 0.001875  Loss: -0.7247  Acc@1: 62.5000 (65.5677)  Acc@5: 93.7500 (92.1004)  time: 0.3506  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [2790/4579]  eta: 0:10:42  Lr: 0.001875  Loss: -0.5339  Acc@1: 62.5000 (65.5634)  Acc@5: 93.7500 (92.0996)  time: 0.3517  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [2800/4579]  eta: 0:10:38  Lr: 0.001875  Loss: 0.7478  Acc@1: 68.7500 (65.5681)  Acc@5: 93.7500 (92.1033)  time: 0.3506  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [2810/4579]  eta: 0:10:34  Lr: 0.001875  Loss: -0.9139  Acc@1: 68.7500 (65.5883)  Acc@5: 93.7500 (92.1180)  time: 0.3513  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [2820/4579]  eta: 0:10:31  Lr: 0.001875  Loss: -0.7742  Acc@1: 68.7500 (65.5884)  Acc@5: 93.7500 (92.1105)  time: 0.3511  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [2830/4579]  eta: 0:10:27  Lr: 0.001875  Loss: -0.9677  Acc@1: 62.5000 (65.5532)  Acc@5: 87.5000 (92.1008)  time: 0.3503  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [2840/4579]  eta: 0:10:24  Lr: 0.001875  Loss: -0.3146  Acc@1: 62.5000 (65.5359)  Acc@5: 87.5000 (92.0935)  time: 0.3510  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [2850/4579]  eta: 0:10:20  Lr: 0.001875  Loss: -0.0776  Acc@1: 68.7500 (65.5472)  Acc@5: 93.7500 (92.0949)  time: 0.3512  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [2860/4579]  eta: 0:10:16  Lr: 0.001875  Loss: -0.7815  Acc@1: 68.7500 (65.5431)  Acc@5: 93.7500 (92.1028)  time: 0.3503  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [2870/4579]  eta: 0:10:13  Lr: 0.001875  Loss: -0.9511  Acc@1: 68.7500 (65.5673)  Acc@5: 93.7500 (92.1086)  time: 0.3506  data: 0.0011  max mem: 2500
Train: Epoch[5/5]  [2880/4579]  eta: 0:10:09  Lr: 0.001875  Loss: 0.0312  Acc@1: 68.7500 (65.5784)  Acc@5: 93.7500 (92.1099)  time: 0.3507  data: 0.0011  max mem: 2500
Train: Epoch[5/5]  [2890/4579]  eta: 0:10:05  Lr: 0.001875  Loss: 0.2485  Acc@1: 68.7500 (65.5828)  Acc@5: 93.7500 (92.1178)  time: 0.3503  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [2900/4579]  eta: 0:10:02  Lr: 0.001875  Loss: 0.7655  Acc@1: 62.5000 (65.5679)  Acc@5: 93.7500 (92.1169)  time: 0.3494  data: 0.0012  max mem: 2500
Train: Epoch[5/5]  [2910/4579]  eta: 0:09:58  Lr: 0.001875  Loss: -0.6447  Acc@1: 62.5000 (65.5552)  Acc@5: 93.7500 (92.1247)  time: 0.3492  data: 0.0011  max mem: 2500
Train: Epoch[5/5]  [2920/4579]  eta: 0:09:54  Lr: 0.001875  Loss: -0.6831  Acc@1: 62.5000 (65.5683)  Acc@5: 93.7500 (92.1281)  time: 0.3518  data: 0.0021  max mem: 2500
Train: Epoch[5/5]  [2930/4579]  eta: 0:09:51  Lr: 0.001875  Loss: -0.3577  Acc@1: 62.5000 (65.5706)  Acc@5: 93.7500 (92.1315)  time: 0.3533  data: 0.0019  max mem: 2500
Train: Epoch[5/5]  [2940/4579]  eta: 0:09:47  Lr: 0.001875  Loss: -0.6620  Acc@1: 62.5000 (65.5836)  Acc@5: 93.7500 (92.1413)  time: 0.3524  data: 0.0019  max mem: 2500
Train: Epoch[5/5]  [2950/4579]  eta: 0:09:44  Lr: 0.001875  Loss: -0.2590  Acc@1: 68.7500 (65.6028)  Acc@5: 93.7500 (92.1425)  time: 0.3502  data: 0.0019  max mem: 2500
Train: Epoch[5/5]  [2960/4579]  eta: 0:09:40  Lr: 0.001875  Loss: -0.6170  Acc@1: 68.7500 (65.6092)  Acc@5: 93.7500 (92.1458)  time: 0.3482  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [2970/4579]  eta: 0:09:36  Lr: 0.001875  Loss: -0.5308  Acc@1: 68.7500 (65.6324)  Acc@5: 93.7500 (92.1449)  time: 0.3485  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [2980/4579]  eta: 0:09:33  Lr: 0.001875  Loss: -0.3675  Acc@1: 68.7500 (65.6428)  Acc@5: 93.7500 (92.1356)  time: 0.3487  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [2990/4579]  eta: 0:09:29  Lr: 0.001875  Loss: 0.3493  Acc@1: 68.7500 (65.6532)  Acc@5: 87.5000 (92.1306)  time: 0.3493  data: 0.0013  max mem: 2500
Train: Epoch[5/5]  [3000/4579]  eta: 0:09:25  Lr: 0.001875  Loss: -0.6769  Acc@1: 62.5000 (65.6510)  Acc@5: 87.5000 (92.1255)  time: 0.3493  data: 0.0013  max mem: 2500
Train: Epoch[5/5]  [3010/4579]  eta: 0:09:22  Lr: 0.001875  Loss: 0.2993  Acc@1: 62.5000 (65.6426)  Acc@5: 87.5000 (92.1143)  time: 0.3497  data: 0.0011  max mem: 2500
Train: Epoch[5/5]  [3020/4579]  eta: 0:09:18  Lr: 0.001875  Loss: -0.4814  Acc@1: 62.5000 (65.6467)  Acc@5: 93.7500 (92.1177)  time: 0.3510  data: 0.0011  max mem: 2500
Train: Epoch[5/5]  [3030/4579]  eta: 0:09:15  Lr: 0.001875  Loss: -0.2414  Acc@1: 62.5000 (65.6528)  Acc@5: 93.7500 (92.1148)  time: 0.3491  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [3040/4579]  eta: 0:09:11  Lr: 0.001875  Loss: -0.3322  Acc@1: 75.0000 (65.6856)  Acc@5: 93.7500 (92.1181)  time: 0.3502  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [3050/4579]  eta: 0:09:07  Lr: 0.001875  Loss: -0.1912  Acc@1: 68.7500 (65.6977)  Acc@5: 93.7500 (92.1173)  time: 0.3503  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [3060/4579]  eta: 0:09:04  Lr: 0.001875  Loss: -0.6984  Acc@1: 62.5000 (65.6995)  Acc@5: 93.7500 (92.1247)  time: 0.3481  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [3070/4579]  eta: 0:09:00  Lr: 0.001875  Loss: -0.5310  Acc@1: 62.5000 (65.7074)  Acc@5: 93.7500 (92.1178)  time: 0.3490  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [3080/4579]  eta: 0:08:56  Lr: 0.001875  Loss: -0.2300  Acc@1: 62.5000 (65.7011)  Acc@5: 87.5000 (92.1130)  time: 0.3496  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [3090/4579]  eta: 0:08:53  Lr: 0.001875  Loss: -0.1994  Acc@1: 62.5000 (65.6948)  Acc@5: 93.7500 (92.1102)  time: 0.3497  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [3100/4579]  eta: 0:08:49  Lr: 0.001875  Loss: -0.4376  Acc@1: 62.5000 (65.7006)  Acc@5: 93.7500 (92.1094)  time: 0.3496  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [3110/4579]  eta: 0:08:46  Lr: 0.001875  Loss: -0.7855  Acc@1: 68.7500 (65.6903)  Acc@5: 87.5000 (92.0966)  time: 0.3515  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [3120/4579]  eta: 0:08:42  Lr: 0.001875  Loss: -0.6902  Acc@1: 68.7500 (65.6841)  Acc@5: 93.7500 (92.0979)  time: 0.3515  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [3130/4579]  eta: 0:08:38  Lr: 0.001875  Loss: -0.5761  Acc@1: 62.5000 (65.6799)  Acc@5: 93.7500 (92.0832)  time: 0.3497  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3140/4579]  eta: 0:08:35  Lr: 0.001875  Loss: -0.6606  Acc@1: 62.5000 (65.6777)  Acc@5: 93.7500 (92.0865)  time: 0.3491  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3150/4579]  eta: 0:08:31  Lr: 0.001875  Loss: -0.2923  Acc@1: 62.5000 (65.6795)  Acc@5: 93.7500 (92.0819)  time: 0.3483  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [3160/4579]  eta: 0:08:27  Lr: 0.001875  Loss: -0.5629  Acc@1: 62.5000 (65.6675)  Acc@5: 93.7500 (92.0832)  time: 0.3492  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [3170/4579]  eta: 0:08:24  Lr: 0.001875  Loss: -0.4655  Acc@1: 68.7500 (65.6871)  Acc@5: 93.7500 (92.0904)  time: 0.3493  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [3180/4579]  eta: 0:08:20  Lr: 0.001875  Loss: -0.4188  Acc@1: 68.7500 (65.6889)  Acc@5: 93.7500 (92.0858)  time: 0.3485  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [3190/4579]  eta: 0:08:17  Lr: 0.001875  Loss: -0.7253  Acc@1: 68.7500 (65.6926)  Acc@5: 93.7500 (92.0910)  time: 0.3479  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3200/4579]  eta: 0:08:13  Lr: 0.001875  Loss: -0.4330  Acc@1: 68.7500 (65.6885)  Acc@5: 93.7500 (92.0845)  time: 0.3489  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3210/4579]  eta: 0:08:09  Lr: 0.001875  Loss: -0.2203  Acc@1: 62.5000 (65.6746)  Acc@5: 87.5000 (92.0761)  time: 0.3494  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3220/4579]  eta: 0:08:06  Lr: 0.001875  Loss: -0.1923  Acc@1: 62.5000 (65.6687)  Acc@5: 87.5000 (92.0735)  time: 0.3487  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3230/4579]  eta: 0:08:02  Lr: 0.001875  Loss: -0.1057  Acc@1: 68.7500 (65.6685)  Acc@5: 93.7500 (92.0826)  time: 0.3487  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [3240/4579]  eta: 0:07:59  Lr: 0.001875  Loss: 0.0261  Acc@1: 68.7500 (65.6703)  Acc@5: 93.7500 (92.0838)  time: 0.3493  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3250/4579]  eta: 0:07:55  Lr: 0.001875  Loss: -0.9721  Acc@1: 68.7500 (65.6817)  Acc@5: 93.7500 (92.0871)  time: 0.3503  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [3260/4579]  eta: 0:07:51  Lr: 0.001875  Loss: -0.0277  Acc@1: 68.7500 (65.6835)  Acc@5: 93.7500 (92.0807)  time: 0.3501  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [3270/4579]  eta: 0:07:48  Lr: 0.001875  Loss: -0.4120  Acc@1: 62.5000 (65.6795)  Acc@5: 93.7500 (92.0781)  time: 0.3490  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3280/4579]  eta: 0:07:44  Lr: 0.001875  Loss: -0.9059  Acc@1: 68.7500 (65.6907)  Acc@5: 93.7500 (92.0699)  time: 0.3488  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3290/4579]  eta: 0:07:40  Lr: 0.001875  Loss: -0.4853  Acc@1: 68.7500 (65.6867)  Acc@5: 93.7500 (92.0788)  time: 0.3506  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [3300/4579]  eta: 0:07:37  Lr: 0.001875  Loss: 0.3783  Acc@1: 56.2500 (65.6771)  Acc@5: 93.7500 (92.0819)  time: 0.3498  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [3310/4579]  eta: 0:07:33  Lr: 0.001875  Loss: -0.1673  Acc@1: 62.5000 (65.6712)  Acc@5: 93.7500 (92.0757)  time: 0.3486  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [3320/4579]  eta: 0:07:30  Lr: 0.001875  Loss: 0.1112  Acc@1: 62.5000 (65.6805)  Acc@5: 93.7500 (92.0807)  time: 0.3491  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [3330/4579]  eta: 0:07:26  Lr: 0.001875  Loss: -0.4438  Acc@1: 62.5000 (65.6879)  Acc@5: 93.7500 (92.0838)  time: 0.3490  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3340/4579]  eta: 0:07:22  Lr: 0.001875  Loss: -0.0564  Acc@1: 68.7500 (65.6914)  Acc@5: 93.7500 (92.0795)  time: 0.3491  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [3350/4579]  eta: 0:07:19  Lr: 0.001875  Loss: -0.6753  Acc@1: 68.7500 (65.6875)  Acc@5: 93.7500 (92.0733)  time: 0.3496  data: 0.0013  max mem: 2500
Train: Epoch[5/5]  [3360/4579]  eta: 0:07:15  Lr: 0.001875  Loss: -0.2378  Acc@1: 62.5000 (65.6854)  Acc@5: 93.7500 (92.0764)  time: 0.3497  data: 0.0011  max mem: 2500
Train: Epoch[5/5]  [3370/4579]  eta: 0:07:12  Lr: 0.001875  Loss: -0.0950  Acc@1: 68.7500 (65.6945)  Acc@5: 93.7500 (92.0814)  time: 0.3497  data: 0.0014  max mem: 2500
Train: Epoch[5/5]  [3380/4579]  eta: 0:07:08  Lr: 0.001875  Loss: -0.1963  Acc@1: 68.7500 (65.7036)  Acc@5: 93.7500 (92.0826)  time: 0.3499  data: 0.0018  max mem: 2500
Train: Epoch[5/5]  [3390/4579]  eta: 0:07:04  Lr: 0.001875  Loss: -0.0255  Acc@1: 68.7500 (65.7033)  Acc@5: 93.7500 (92.0838)  time: 0.3489  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [3400/4579]  eta: 0:07:01  Lr: 0.001875  Loss: -0.1337  Acc@1: 62.5000 (65.7031)  Acc@5: 93.7500 (92.0814)  time: 0.3483  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [3410/4579]  eta: 0:06:57  Lr: 0.001875  Loss: -0.4626  Acc@1: 62.5000 (65.7065)  Acc@5: 93.7500 (92.0789)  time: 0.3488  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [3420/4579]  eta: 0:06:54  Lr: 0.001875  Loss: -0.2403  Acc@1: 62.5000 (65.6935)  Acc@5: 87.5000 (92.0692)  time: 0.3477  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3430/4579]  eta: 0:06:50  Lr: 0.001875  Loss: -0.6244  Acc@1: 56.2500 (65.6824)  Acc@5: 87.5000 (92.0723)  time: 0.3470  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [3440/4579]  eta: 0:06:46  Lr: 0.001875  Loss: -0.7127  Acc@1: 62.5000 (65.6913)  Acc@5: 93.7500 (92.0663)  time: 0.3477  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [3450/4579]  eta: 0:06:43  Lr: 0.001875  Loss: -0.9705  Acc@1: 62.5000 (65.6784)  Acc@5: 93.7500 (92.0621)  time: 0.3483  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [3460/4579]  eta: 0:06:39  Lr: 0.001875  Loss: -0.4370  Acc@1: 62.5000 (65.6855)  Acc@5: 93.7500 (92.0670)  time: 0.3482  data: 0.0010  max mem: 2500
Train: Epoch[5/5]  [3470/4579]  eta: 0:06:36  Lr: 0.001875  Loss: 0.0988  Acc@1: 62.5000 (65.6853)  Acc@5: 93.7500 (92.0610)  time: 0.3493  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [3480/4579]  eta: 0:06:32  Lr: 0.001875  Loss: -0.8168  Acc@1: 62.5000 (65.6708)  Acc@5: 87.5000 (92.0515)  time: 0.3501  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [3490/4579]  eta: 0:06:28  Lr: 0.001875  Loss: -0.6969  Acc@1: 62.5000 (65.6760)  Acc@5: 93.7500 (92.0617)  time: 0.3513  data: 0.0012  max mem: 2500
Train: Epoch[5/5]  [3500/4579]  eta: 0:06:25  Lr: 0.001875  Loss: -0.4323  Acc@1: 68.7500 (65.6830)  Acc@5: 93.7500 (92.0701)  time: 0.3501  data: 0.0012  max mem: 2500
Train: Epoch[5/5]  [3510/4579]  eta: 0:06:21  Lr: 0.001875  Loss: -0.4706  Acc@1: 68.7500 (65.6846)  Acc@5: 93.7500 (92.0713)  time: 0.3488  data: 0.0013  max mem: 2500
Train: Epoch[5/5]  [3520/4579]  eta: 0:06:18  Lr: 0.001875  Loss: -0.3957  Acc@1: 68.7500 (65.6703)  Acc@5: 93.7500 (92.0619)  time: 0.3499  data: 0.0013  max mem: 2500
Train: Epoch[5/5]  [3530/4579]  eta: 0:06:14  Lr: 0.001875  Loss: -0.0907  Acc@1: 68.7500 (65.6719)  Acc@5: 93.7500 (92.0614)  time: 0.3490  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3540/4579]  eta: 0:06:10  Lr: 0.001875  Loss: -0.5987  Acc@1: 68.7500 (65.6753)  Acc@5: 93.7500 (92.0644)  time: 0.3482  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3550/4579]  eta: 0:06:07  Lr: 0.001875  Loss: -0.5191  Acc@1: 68.7500 (65.6892)  Acc@5: 93.7500 (92.0709)  time: 0.3486  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [3560/4579]  eta: 0:06:03  Lr: 0.001875  Loss: -0.3288  Acc@1: 68.7500 (65.6978)  Acc@5: 93.7500 (92.0809)  time: 0.3479  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [3570/4579]  eta: 0:06:00  Lr: 0.001875  Loss: -0.4526  Acc@1: 62.5000 (65.6871)  Acc@5: 93.7500 (92.0891)  time: 0.3471  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [3580/4579]  eta: 0:05:56  Lr: 0.001875  Loss: -0.6685  Acc@1: 62.5000 (65.7027)  Acc@5: 93.7500 (92.0902)  time: 0.3486  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3590/4579]  eta: 0:05:52  Lr: 0.001875  Loss: -0.2142  Acc@1: 68.7500 (65.6972)  Acc@5: 93.7500 (92.0931)  time: 0.3489  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [3600/4579]  eta: 0:05:49  Lr: 0.001875  Loss: -0.4090  Acc@1: 62.5000 (65.6918)  Acc@5: 93.7500 (92.0907)  time: 0.3487  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3610/4579]  eta: 0:05:45  Lr: 0.001875  Loss: -0.5469  Acc@1: 62.5000 (65.6778)  Acc@5: 87.5000 (92.0746)  time: 0.3502  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3620/4579]  eta: 0:05:42  Lr: 0.001875  Loss: -0.7814  Acc@1: 62.5000 (65.6725)  Acc@5: 87.5000 (92.0757)  time: 0.3506  data: 0.0011  max mem: 2500
Train: Epoch[5/5]  [3630/4579]  eta: 0:05:38  Lr: 0.001875  Loss: 0.1579  Acc@1: 62.5000 (65.6500)  Acc@5: 93.7500 (92.0683)  time: 0.3526  data: 0.0027  max mem: 2500
Train: Epoch[5/5]  [3640/4579]  eta: 0:05:35  Lr: 0.001875  Loss: -0.3515  Acc@1: 56.2500 (65.6293)  Acc@5: 87.5000 (92.0558)  time: 0.3523  data: 0.0020  max mem: 2500
Train: Epoch[5/5]  [3650/4579]  eta: 0:05:31  Lr: 0.001875  Loss: -0.6564  Acc@1: 62.5000 (65.6413)  Acc@5: 93.7500 (92.0587)  time: 0.3491  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3660/4579]  eta: 0:05:27  Lr: 0.001875  Loss: -0.4338  Acc@1: 68.7500 (65.6327)  Acc@5: 93.7500 (92.0633)  time: 0.3492  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3670/4579]  eta: 0:05:24  Lr: 0.001875  Loss: -0.7392  Acc@1: 68.7500 (65.6395)  Acc@5: 93.7500 (92.0645)  time: 0.3496  data: 0.0010  max mem: 2500
Train: Epoch[5/5]  [3680/4579]  eta: 0:05:20  Lr: 0.001875  Loss: -0.2182  Acc@1: 68.7500 (65.6377)  Acc@5: 93.7500 (92.0640)  time: 0.3494  data: 0.0011  max mem: 2500
Train: Epoch[5/5]  [3690/4579]  eta: 0:05:17  Lr: 0.001875  Loss: -0.3892  Acc@1: 62.5000 (65.6496)  Acc@5: 93.7500 (92.0685)  time: 0.3498  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [3700/4579]  eta: 0:05:13  Lr: 0.001875  Loss: -0.5238  Acc@1: 62.5000 (65.6444)  Acc@5: 93.7500 (92.0613)  time: 0.3525  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [3710/4579]  eta: 0:05:09  Lr: 0.001875  Loss: 0.0308  Acc@1: 62.5000 (65.6275)  Acc@5: 87.5000 (92.0507)  time: 0.3513  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [3720/4579]  eta: 0:05:06  Lr: 0.001875  Loss: 0.1292  Acc@1: 68.7500 (65.6393)  Acc@5: 93.7500 (92.0502)  time: 0.3484  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3730/4579]  eta: 0:05:02  Lr: 0.001875  Loss: -0.5042  Acc@1: 68.7500 (65.6543)  Acc@5: 93.7500 (92.0497)  time: 0.3501  data: 0.0010  max mem: 2500
Train: Epoch[5/5]  [3740/4579]  eta: 0:04:59  Lr: 0.001875  Loss: -0.7923  Acc@1: 68.7500 (65.6509)  Acc@5: 93.7500 (92.0543)  time: 0.3498  data: 0.0010  max mem: 2500
Train: Epoch[5/5]  [3750/4579]  eta: 0:04:55  Lr: 0.001875  Loss: -0.6252  Acc@1: 68.7500 (65.6475)  Acc@5: 87.5000 (92.0471)  time: 0.3477  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [3760/4579]  eta: 0:04:52  Lr: 0.001875  Loss: -0.8032  Acc@1: 62.5000 (65.6258)  Acc@5: 87.5000 (92.0483)  time: 0.3469  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [3770/4579]  eta: 0:04:48  Lr: 0.001875  Loss: -0.1559  Acc@1: 62.5000 (65.6209)  Acc@5: 93.7500 (92.0412)  time: 0.3477  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3780/4579]  eta: 0:04:44  Lr: 0.001875  Loss: -0.9180  Acc@1: 68.7500 (65.6258)  Acc@5: 93.7500 (92.0424)  time: 0.3483  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3790/4579]  eta: 0:04:41  Lr: 0.001875  Loss: 0.1780  Acc@1: 68.7500 (65.6258)  Acc@5: 93.7500 (92.0470)  time: 0.3469  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [3800/4579]  eta: 0:04:37  Lr: 0.001875  Loss: -0.0546  Acc@1: 68.7500 (65.6160)  Acc@5: 93.7500 (92.0481)  time: 0.3465  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3810/4579]  eta: 0:04:34  Lr: 0.001875  Loss: -0.5615  Acc@1: 62.5000 (65.6094)  Acc@5: 93.7500 (92.0543)  time: 0.3474  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3820/4579]  eta: 0:04:30  Lr: 0.001875  Loss: -0.6526  Acc@1: 62.5000 (65.6078)  Acc@5: 93.7500 (92.0505)  time: 0.3486  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [3830/4579]  eta: 0:04:26  Lr: 0.001875  Loss: -0.5100  Acc@1: 68.7500 (65.6242)  Acc@5: 93.7500 (92.0533)  time: 0.3494  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [3840/4579]  eta: 0:04:23  Lr: 0.001875  Loss: -0.4938  Acc@1: 68.7500 (65.6128)  Acc@5: 93.7500 (92.0512)  time: 0.3496  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [3850/4579]  eta: 0:04:19  Lr: 0.001875  Loss: -0.2114  Acc@1: 68.7500 (65.6291)  Acc@5: 93.7500 (92.0524)  time: 0.3484  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3860/4579]  eta: 0:04:16  Lr: 0.001875  Loss: -0.5680  Acc@1: 68.7500 (65.6307)  Acc@5: 93.7500 (92.0552)  time: 0.3477  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [3870/4579]  eta: 0:04:12  Lr: 0.001875  Loss: -0.1497  Acc@1: 62.5000 (65.6226)  Acc@5: 93.7500 (92.0499)  time: 0.3483  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [3880/4579]  eta: 0:04:09  Lr: 0.001875  Loss: -0.2130  Acc@1: 56.2500 (65.5984)  Acc@5: 87.5000 (92.0381)  time: 0.3479  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3890/4579]  eta: 0:04:05  Lr: 0.001875  Loss: -0.8426  Acc@1: 68.7500 (65.6097)  Acc@5: 93.7500 (92.0393)  time: 0.3470  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3900/4579]  eta: 0:04:01  Lr: 0.001875  Loss: -0.4026  Acc@1: 68.7500 (65.6034)  Acc@5: 93.7500 (92.0309)  time: 0.3471  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [3910/4579]  eta: 0:03:58  Lr: 0.001875  Loss: -0.1976  Acc@1: 62.5000 (65.6178)  Acc@5: 93.7500 (92.0321)  time: 0.3483  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [3920/4579]  eta: 0:03:54  Lr: 0.001875  Loss: -0.2726  Acc@1: 68.7500 (65.6242)  Acc@5: 93.7500 (92.0397)  time: 0.3490  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [3930/4579]  eta: 0:03:51  Lr: 0.001875  Loss: -0.6006  Acc@1: 68.7500 (65.6353)  Acc@5: 100.0000 (92.0488)  time: 0.3488  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3940/4579]  eta: 0:03:47  Lr: 0.001875  Loss: -0.7154  Acc@1: 68.7500 (65.6385)  Acc@5: 100.0000 (92.0531)  time: 0.3495  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3950/4579]  eta: 0:03:44  Lr: 0.001875  Loss: -0.2463  Acc@1: 62.5000 (65.6353)  Acc@5: 93.7500 (92.0590)  time: 0.3506  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [3960/4579]  eta: 0:03:40  Lr: 0.001875  Loss: -0.5046  Acc@1: 68.7500 (65.6510)  Acc@5: 93.7500 (92.0585)  time: 0.3502  data: 0.0011  max mem: 2500
Train: Epoch[5/5]  [3970/4579]  eta: 0:03:36  Lr: 0.001875  Loss: -0.5981  Acc@1: 68.7500 (65.6462)  Acc@5: 93.7500 (92.0533)  time: 0.3500  data: 0.0011  max mem: 2500
Train: Epoch[5/5]  [3980/4579]  eta: 0:03:33  Lr: 0.001875  Loss: -1.0370  Acc@1: 68.7500 (65.6493)  Acc@5: 87.5000 (92.0482)  time: 0.3498  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3990/4579]  eta: 0:03:29  Lr: 0.001875  Loss: -0.3518  Acc@1: 68.7500 (65.6587)  Acc@5: 93.7500 (92.0493)  time: 0.3498  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [4000/4579]  eta: 0:03:26  Lr: 0.001875  Loss: -0.4164  Acc@1: 62.5000 (65.6477)  Acc@5: 93.7500 (92.0535)  time: 0.3516  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [4010/4579]  eta: 0:03:22  Lr: 0.001875  Loss: 0.1846  Acc@1: 62.5000 (65.6554)  Acc@5: 93.7500 (92.0453)  time: 0.3509  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [4020/4579]  eta: 0:03:19  Lr: 0.001875  Loss: -0.8161  Acc@1: 68.7500 (65.6600)  Acc@5: 93.7500 (92.0527)  time: 0.3502  data: 0.0014  max mem: 2500
Train: Epoch[5/5]  [4030/4579]  eta: 0:03:15  Lr: 0.001875  Loss: -0.7572  Acc@1: 75.0000 (65.6847)  Acc@5: 93.7500 (92.0615)  time: 0.3524  data: 0.0015  max mem: 2500
Train: Epoch[5/5]  [4040/4579]  eta: 0:03:11  Lr: 0.001875  Loss: 0.1225  Acc@1: 68.7500 (65.6753)  Acc@5: 93.7500 (92.0533)  time: 0.3508  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [4050/4579]  eta: 0:03:08  Lr: 0.001875  Loss: -0.4209  Acc@1: 62.5000 (65.6613)  Acc@5: 87.5000 (92.0452)  time: 0.3495  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [4060/4579]  eta: 0:03:04  Lr: 0.001875  Loss: -0.5152  Acc@1: 62.5000 (65.6704)  Acc@5: 87.5000 (92.0432)  time: 0.3513  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [4070/4579]  eta: 0:03:01  Lr: 0.001875  Loss: -0.2722  Acc@1: 68.7500 (65.6657)  Acc@5: 93.7500 (92.0443)  time: 0.3511  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [4080/4579]  eta: 0:02:57  Lr: 0.001875  Loss: 0.0211  Acc@1: 62.5000 (65.6610)  Acc@5: 93.7500 (92.0409)  time: 0.3501  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [4090/4579]  eta: 0:02:54  Lr: 0.001875  Loss: -0.6834  Acc@1: 68.7500 (65.6670)  Acc@5: 93.7500 (92.0481)  time: 0.3500  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [4100/4579]  eta: 0:02:50  Lr: 0.001875  Loss: -0.5260  Acc@1: 62.5000 (65.6593)  Acc@5: 93.7500 (92.0446)  time: 0.3496  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [4110/4579]  eta: 0:02:46  Lr: 0.001875  Loss: -0.0327  Acc@1: 62.5000 (65.6607)  Acc@5: 93.7500 (92.0412)  time: 0.3500  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [4120/4579]  eta: 0:02:43  Lr: 0.001875  Loss: -0.6324  Acc@1: 68.7500 (65.6667)  Acc@5: 93.7500 (92.0377)  time: 0.3501  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [4130/4579]  eta: 0:02:39  Lr: 0.001875  Loss: -0.7814  Acc@1: 68.7500 (65.6696)  Acc@5: 93.7500 (92.0389)  time: 0.3491  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [4140/4579]  eta: 0:02:36  Lr: 0.001875  Loss: -0.8695  Acc@1: 62.5000 (65.6605)  Acc@5: 93.7500 (92.0460)  time: 0.3494  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [4150/4579]  eta: 0:02:32  Lr: 0.001875  Loss: -0.3060  Acc@1: 62.5000 (65.6724)  Acc@5: 93.7500 (92.0471)  time: 0.3495  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [4160/4579]  eta: 0:02:29  Lr: 0.001875  Loss: -0.3445  Acc@1: 68.7500 (65.6693)  Acc@5: 93.7500 (92.0392)  time: 0.3498  data: 0.0012  max mem: 2500
Train: Epoch[5/5]  [4170/4579]  eta: 0:02:25  Lr: 0.001875  Loss: -0.6132  Acc@1: 62.5000 (65.6752)  Acc@5: 87.5000 (92.0328)  time: 0.3505  data: 0.0014  max mem: 2500
Train: Epoch[5/5]  [4180/4579]  eta: 0:02:21  Lr: 0.001875  Loss: -0.5943  Acc@1: 62.5000 (65.6796)  Acc@5: 87.5000 (92.0309)  time: 0.3500  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [4190/4579]  eta: 0:02:18  Lr: 0.001875  Loss: -0.7079  Acc@1: 62.5000 (65.6720)  Acc@5: 93.7500 (92.0365)  time: 0.3508  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [4200/4579]  eta: 0:02:14  Lr: 0.001875  Loss: -0.0939  Acc@1: 62.5000 (65.6867)  Acc@5: 93.7500 (92.0421)  time: 0.3516  data: 0.0010  max mem: 2500
Train: Epoch[5/5]  [4210/4579]  eta: 0:02:11  Lr: 0.001875  Loss: -0.3467  Acc@1: 75.0000 (65.7089)  Acc@5: 93.7500 (92.0491)  time: 0.3503  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [4220/4579]  eta: 0:02:07  Lr: 0.001875  Loss: -0.6906  Acc@1: 68.7500 (65.7190)  Acc@5: 93.7500 (92.0502)  time: 0.3496  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [4230/4579]  eta: 0:02:04  Lr: 0.001875  Loss: 0.0512  Acc@1: 68.7500 (65.7218)  Acc@5: 93.7500 (92.0542)  time: 0.3496  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [4240/4579]  eta: 0:02:00  Lr: 0.001875  Loss: -0.4531  Acc@1: 62.5000 (65.7097)  Acc@5: 93.7500 (92.0523)  time: 0.3497  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [4250/4579]  eta: 0:01:57  Lr: 0.001875  Loss: -0.4016  Acc@1: 68.7500 (65.7287)  Acc@5: 93.7500 (92.0607)  time: 0.3500  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [4260/4579]  eta: 0:01:53  Lr: 0.001875  Loss: -0.3623  Acc@1: 68.7500 (65.7255)  Acc@5: 93.7500 (92.0617)  time: 0.3506  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [4270/4579]  eta: 0:01:49  Lr: 0.001875  Loss: 0.0432  Acc@1: 62.5000 (65.7165)  Acc@5: 93.7500 (92.0525)  time: 0.3503  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [4280/4579]  eta: 0:01:46  Lr: 0.001875  Loss: -0.2683  Acc@1: 62.5000 (65.7089)  Acc@5: 93.7500 (92.0565)  time: 0.3494  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [4290/4579]  eta: 0:01:42  Lr: 0.001875  Loss: -0.7723  Acc@1: 62.5000 (65.7189)  Acc@5: 93.7500 (92.0619)  time: 0.3493  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [4300/4579]  eta: 0:01:39  Lr: 0.001875  Loss: -0.1993  Acc@1: 68.7500 (65.7042)  Acc@5: 93.7500 (92.0614)  time: 0.3492  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [4310/4579]  eta: 0:01:35  Lr: 0.001875  Loss: -0.7429  Acc@1: 68.7500 (65.7200)  Acc@5: 93.7500 (92.0683)  time: 0.3486  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [4320/4579]  eta: 0:01:32  Lr: 0.001875  Loss: -0.1483  Acc@1: 68.7500 (65.7082)  Acc@5: 93.7500 (92.0678)  time: 0.3487  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [4330/4579]  eta: 0:01:28  Lr: 0.001875  Loss: -0.6837  Acc@1: 68.7500 (65.7224)  Acc@5: 93.7500 (92.0688)  time: 0.3497  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [4340/4579]  eta: 0:01:24  Lr: 0.001875  Loss: -0.5106  Acc@1: 68.7500 (65.7164)  Acc@5: 93.7500 (92.0712)  time: 0.3499  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [4350/4579]  eta: 0:01:21  Lr: 0.001875  Loss: -1.0628  Acc@1: 62.5000 (65.7148)  Acc@5: 93.7500 (92.0794)  time: 0.3491  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [4360/4579]  eta: 0:01:17  Lr: 0.001875  Loss: -0.2912  Acc@1: 68.7500 (65.7303)  Acc@5: 93.7500 (92.0804)  time: 0.3490  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [4370/4579]  eta: 0:01:14  Lr: 0.001875  Loss: -0.4343  Acc@1: 68.7500 (65.7301)  Acc@5: 93.7500 (92.0785)  time: 0.3494  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [4380/4579]  eta: 0:01:10  Lr: 0.001875  Loss: -0.3456  Acc@1: 68.7500 (65.7470)  Acc@5: 93.7500 (92.0794)  time: 0.3498  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [4390/4579]  eta: 0:01:07  Lr: 0.001875  Loss: -0.5065  Acc@1: 68.7500 (65.7396)  Acc@5: 93.7500 (92.0832)  time: 0.3503  data: 0.0015  max mem: 2500
Train: Epoch[5/5]  [4400/4579]  eta: 0:01:03  Lr: 0.001875  Loss: -0.6403  Acc@1: 68.7500 (65.7464)  Acc@5: 93.7500 (92.0828)  time: 0.3499  data: 0.0015  max mem: 2500
Train: Epoch[5/5]  [4410/4579]  eta: 0:01:00  Lr: 0.001875  Loss: -0.2652  Acc@1: 62.5000 (65.7348)  Acc@5: 87.5000 (92.0738)  time: 0.3494  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [4420/4579]  eta: 0:00:56  Lr: 0.001875  Loss: -0.3407  Acc@1: 62.5000 (65.7289)  Acc@5: 93.7500 (92.0776)  time: 0.3484  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [4430/4579]  eta: 0:00:52  Lr: 0.001875  Loss: -0.6742  Acc@1: 62.5000 (65.7216)  Acc@5: 93.7500 (92.0799)  time: 0.3480  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [4440/4579]  eta: 0:00:49  Lr: 0.001875  Loss: 0.0852  Acc@1: 62.5000 (65.7130)  Acc@5: 93.7500 (92.0739)  time: 0.3484  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [4450/4579]  eta: 0:00:45  Lr: 0.001875  Loss: -0.2530  Acc@1: 62.5000 (65.7184)  Acc@5: 93.7500 (92.0776)  time: 0.3492  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [4460/4579]  eta: 0:00:42  Lr: 0.001875  Loss: 0.4339  Acc@1: 62.5000 (65.7056)  Acc@5: 93.7500 (92.0758)  time: 0.3493  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [4470/4579]  eta: 0:00:38  Lr: 0.001875  Loss: -0.5391  Acc@1: 62.5000 (65.6942)  Acc@5: 93.7500 (92.0725)  time: 0.3484  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [4480/4579]  eta: 0:00:35  Lr: 0.001875  Loss: -0.4817  Acc@1: 68.7500 (65.7136)  Acc@5: 93.7500 (92.0805)  time: 0.3484  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [4490/4579]  eta: 0:00:31  Lr: 0.001875  Loss: -0.5209  Acc@1: 75.0000 (65.7259)  Acc@5: 93.7500 (92.0870)  time: 0.3479  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [4500/4579]  eta: 0:00:28  Lr: 0.001875  Loss: -0.3039  Acc@1: 68.7500 (65.7243)  Acc@5: 93.7500 (92.0809)  time: 0.3483  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [4510/4579]  eta: 0:00:24  Lr: 0.001875  Loss: -0.6008  Acc@1: 62.5000 (65.7158)  Acc@5: 87.5000 (92.0791)  time: 0.3483  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [4520/4579]  eta: 0:00:20  Lr: 0.001875  Loss: 0.3825  Acc@1: 62.5000 (65.7128)  Acc@5: 93.7500 (92.0773)  time: 0.3481  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [4530/4579]  eta: 0:00:17  Lr: 0.001875  Loss: -0.2900  Acc@1: 62.5000 (65.7029)  Acc@5: 87.5000 (92.0671)  time: 0.3496  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [4540/4579]  eta: 0:00:13  Lr: 0.001875  Loss: -0.7850  Acc@1: 62.5000 (65.7110)  Acc@5: 87.5000 (92.0640)  time: 0.3491  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [4550/4579]  eta: 0:00:10  Lr: 0.001875  Loss: -0.7855  Acc@1: 68.7500 (65.7122)  Acc@5: 93.7500 (92.0636)  time: 0.3477  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [4560/4579]  eta: 0:00:06  Lr: 0.001875  Loss: -0.5870  Acc@1: 62.5000 (65.7079)  Acc@5: 93.7500 (92.0577)  time: 0.3481  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [4570/4579]  eta: 0:00:03  Lr: 0.001875  Loss: -0.6046  Acc@1: 62.5000 (65.7023)  Acc@5: 93.7500 (92.0600)  time: 0.3491  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [4578/4579]  eta: 0:00:00  Lr: 0.001875  Loss: 0.3157  Acc@1: 68.7500 (65.7057)  Acc@5: 93.7500 (92.0581)  time: 0.3411  data: 0.0007  max mem: 2500
Train: Epoch[5/5] Total time: 0:27:07 (0.3554 s / it)
Averaged stats: Lr: 0.001875  Loss: 0.3157  Acc@1: 68.7500 (65.7057)  Acc@5: 93.7500 (92.0581)
Test: [Task 1]  [   0/1627]  eta: 0:20:05  Loss: 1.1173 (1.1173)  Acc@1: 87.5000 (87.5000)  Acc@5: 93.7500 (93.7500)  time: 0.7410  data: 0.5207  max mem: 2500
Test: [Task 1]  [  10/1627]  eta: 0:07:07  Loss: 0.8318 (0.8355)  Acc@1: 87.5000 (88.0682)  Acc@5: 100.0000 (97.1591)  time: 0.2643  data: 0.0477  max mem: 2500
Test: [Task 1]  [  20/1627]  eta: 0:06:28  Loss: 0.7865 (0.8173)  Acc@1: 87.5000 (87.7976)  Acc@5: 100.0000 (97.3214)  time: 0.2169  data: 0.0008  max mem: 2500
Test: [Task 1]  [  30/1627]  eta: 0:06:13  Loss: 0.7987 (0.8302)  Acc@1: 87.5000 (86.6935)  Acc@5: 100.0000 (97.1774)  time: 0.2172  data: 0.0008  max mem: 2500
Test: [Task 1]  [  40/1627]  eta: 0:06:04  Loss: 0.9026 (0.8421)  Acc@1: 81.2500 (85.6707)  Acc@5: 100.0000 (97.1037)  time: 0.2175  data: 0.0009  max mem: 2500
Test: [Task 1]  [  50/1627]  eta: 0:05:58  Loss: 0.8916 (0.8317)  Acc@1: 87.5000 (86.0294)  Acc@5: 100.0000 (97.3039)  time: 0.2178  data: 0.0012  max mem: 2500
Test: [Task 1]  [  60/1627]  eta: 0:05:54  Loss: 0.8592 (0.8383)  Acc@1: 87.5000 (85.7582)  Acc@5: 100.0000 (97.4385)  time: 0.2178  data: 0.0010  max mem: 2500
Test: [Task 1]  [  70/1627]  eta: 0:05:50  Loss: 0.8249 (0.8388)  Acc@1: 87.5000 (85.4754)  Acc@5: 100.0000 (97.6232)  time: 0.2181  data: 0.0007  max mem: 2500
Test: [Task 1]  [  80/1627]  eta: 0:05:46  Loss: 0.6601 (0.8236)  Acc@1: 87.5000 (85.9568)  Acc@5: 100.0000 (97.7623)  time: 0.2187  data: 0.0004  max mem: 2500
Test: [Task 1]  [  90/1627]  eta: 0:05:43  Loss: 0.7356 (0.8334)  Acc@1: 87.5000 (85.4396)  Acc@5: 100.0000 (97.5962)  time: 0.2186  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 100/1627]  eta: 0:05:40  Loss: 0.9277 (0.8486)  Acc@1: 81.2500 (85.0866)  Acc@5: 100.0000 (97.4010)  time: 0.2194  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 110/1627]  eta: 0:05:38  Loss: 0.8022 (0.8417)  Acc@1: 81.2500 (85.1914)  Acc@5: 100.0000 (97.5225)  time: 0.2195  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 120/1627]  eta: 0:05:35  Loss: 0.8022 (0.8470)  Acc@1: 87.5000 (85.1756)  Acc@5: 100.0000 (97.4690)  time: 0.2186  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 130/1627]  eta: 0:05:32  Loss: 0.8397 (0.8481)  Acc@1: 87.5000 (85.3053)  Acc@5: 100.0000 (97.3760)  time: 0.2194  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 140/1627]  eta: 0:05:30  Loss: 0.7640 (0.8433)  Acc@1: 87.5000 (85.4167)  Acc@5: 100.0000 (97.4291)  time: 0.2188  data: 0.0006  max mem: 2500
Test: [Task 1]  [ 150/1627]  eta: 0:05:27  Loss: 0.5661 (0.8304)  Acc@1: 87.5000 (85.6374)  Acc@5: 100.0000 (97.4752)  time: 0.2183  data: 0.0009  max mem: 2500
Test: [Task 1]  [ 160/1627]  eta: 0:05:24  Loss: 0.5661 (0.8232)  Acc@1: 87.5000 (85.7531)  Acc@5: 100.0000 (97.4379)  time: 0.2185  data: 0.0007  max mem: 2500
Test: [Task 1]  [ 170/1627]  eta: 0:05:22  Loss: 0.6285 (0.8158)  Acc@1: 87.5000 (85.7822)  Acc@5: 100.0000 (97.5146)  time: 0.2183  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 180/1627]  eta: 0:05:20  Loss: 0.7703 (0.8245)  Acc@1: 87.5000 (85.7044)  Acc@5: 100.0000 (97.3757)  time: 0.2194  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 190/1627]  eta: 0:05:17  Loss: 0.8417 (0.8223)  Acc@1: 87.5000 (85.6675)  Acc@5: 100.0000 (97.4476)  time: 0.2200  data: 0.0012  max mem: 2500
Test: [Task 1]  [ 200/1627]  eta: 0:05:15  Loss: 0.9050 (0.8230)  Acc@1: 81.2500 (85.6032)  Acc@5: 100.0000 (97.4813)  time: 0.2191  data: 0.0012  max mem: 2500
Test: [Task 1]  [ 210/1627]  eta: 0:05:13  Loss: 0.8252 (0.8226)  Acc@1: 81.2500 (85.6931)  Acc@5: 100.0000 (97.3934)  time: 0.2191  data: 0.0008  max mem: 2500
Test: [Task 1]  [ 220/1627]  eta: 0:05:11  Loss: 0.6596 (0.8272)  Acc@1: 87.5000 (85.6052)  Acc@5: 100.0000 (97.3699)  time: 0.2207  data: 0.0024  max mem: 2500
Test: [Task 1]  [ 230/1627]  eta: 0:05:08  Loss: 0.6516 (0.8203)  Acc@1: 87.5000 (85.7684)  Acc@5: 100.0000 (97.4297)  time: 0.2203  data: 0.0021  max mem: 2500
Test: [Task 1]  [ 240/1627]  eta: 0:05:06  Loss: 0.6786 (0.8162)  Acc@1: 87.5000 (85.8662)  Acc@5: 100.0000 (97.5104)  time: 0.2186  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 250/1627]  eta: 0:05:04  Loss: 0.7498 (0.8221)  Acc@1: 87.5000 (85.8566)  Acc@5: 100.0000 (97.3606)  time: 0.2189  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 260/1627]  eta: 0:05:01  Loss: 0.8045 (0.8205)  Acc@1: 87.5000 (85.8238)  Acc@5: 93.7500 (97.3420)  time: 0.2199  data: 0.0016  max mem: 2500
Test: [Task 1]  [ 270/1627]  eta: 0:04:59  Loss: 0.6228 (0.8159)  Acc@1: 87.5000 (85.8856)  Acc@5: 100.0000 (97.4170)  time: 0.2197  data: 0.0018  max mem: 2500
Test: [Task 1]  [ 280/1627]  eta: 0:04:57  Loss: 0.7897 (0.8189)  Acc@1: 87.5000 (85.6984)  Acc@5: 100.0000 (97.4199)  time: 0.2187  data: 0.0006  max mem: 2500
Test: [Task 1]  [ 290/1627]  eta: 0:04:54  Loss: 0.7897 (0.8158)  Acc@1: 81.2500 (85.8462)  Acc@5: 100.0000 (97.4227)  time: 0.2197  data: 0.0011  max mem: 2500
Test: [Task 1]  [ 300/1627]  eta: 0:04:52  Loss: 0.6303 (0.8136)  Acc@1: 87.5000 (85.8389)  Acc@5: 100.0000 (97.4460)  time: 0.2196  data: 0.0011  max mem: 2500
Test: [Task 1]  [ 310/1627]  eta: 0:04:50  Loss: 0.7030 (0.8149)  Acc@1: 87.5000 (85.8521)  Acc@5: 100.0000 (97.4477)  time: 0.2185  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 320/1627]  eta: 0:04:48  Loss: 0.7934 (0.8164)  Acc@1: 87.5000 (85.9813)  Acc@5: 100.0000 (97.4688)  time: 0.2196  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 330/1627]  eta: 0:04:45  Loss: 0.7380 (0.8164)  Acc@1: 87.5000 (85.9328)  Acc@5: 100.0000 (97.4509)  time: 0.2201  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 340/1627]  eta: 0:04:43  Loss: 0.6651 (0.8177)  Acc@1: 81.2500 (85.8871)  Acc@5: 100.0000 (97.4523)  time: 0.2192  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 350/1627]  eta: 0:04:41  Loss: 0.8138 (0.8185)  Acc@1: 87.5000 (85.8796)  Acc@5: 100.0000 (97.4359)  time: 0.2185  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 360/1627]  eta: 0:04:39  Loss: 0.7536 (0.8172)  Acc@1: 87.5000 (85.8553)  Acc@5: 100.0000 (97.4550)  time: 0.2195  data: 0.0008  max mem: 2500
Test: [Task 1]  [ 370/1627]  eta: 0:04:36  Loss: 0.6598 (0.8171)  Acc@1: 87.5000 (85.8827)  Acc@5: 100.0000 (97.4899)  time: 0.2195  data: 0.0007  max mem: 2500
Test: [Task 1]  [ 380/1627]  eta: 0:04:34  Loss: 0.6492 (0.8152)  Acc@1: 87.5000 (85.9580)  Acc@5: 100.0000 (97.4902)  time: 0.2196  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 390/1627]  eta: 0:04:32  Loss: 0.7344 (0.8164)  Acc@1: 87.5000 (85.9175)  Acc@5: 100.0000 (97.4904)  time: 0.2196  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 400/1627]  eta: 0:04:30  Loss: 0.8119 (0.8179)  Acc@1: 87.5000 (85.9414)  Acc@5: 100.0000 (97.4906)  time: 0.2188  data: 0.0007  max mem: 2500
Test: [Task 1]  [ 410/1627]  eta: 0:04:28  Loss: 0.6918 (0.8178)  Acc@1: 87.5000 (85.9641)  Acc@5: 100.0000 (97.4757)  time: 0.2190  data: 0.0009  max mem: 2500
Test: [Task 1]  [ 420/1627]  eta: 0:04:25  Loss: 0.6415 (0.8177)  Acc@1: 87.5000 (86.0006)  Acc@5: 100.0000 (97.5059)  time: 0.2197  data: 0.0007  max mem: 2500
Test: [Task 1]  [ 430/1627]  eta: 0:04:23  Loss: 0.5969 (0.8140)  Acc@1: 87.5000 (86.0209)  Acc@5: 100.0000 (97.5493)  time: 0.2197  data: 0.0006  max mem: 2500
Test: [Task 1]  [ 440/1627]  eta: 0:04:21  Loss: 0.6628 (0.8135)  Acc@1: 87.5000 (85.9836)  Acc@5: 100.0000 (97.5482)  time: 0.2188  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 450/1627]  eta: 0:04:19  Loss: 0.7888 (0.8156)  Acc@1: 87.5000 (85.8925)  Acc@5: 100.0000 (97.4917)  time: 0.2183  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 460/1627]  eta: 0:04:16  Loss: 0.7888 (0.8142)  Acc@1: 87.5000 (85.9273)  Acc@5: 100.0000 (97.5190)  time: 0.2185  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 470/1627]  eta: 0:04:14  Loss: 0.6791 (0.8120)  Acc@1: 87.5000 (85.9740)  Acc@5: 100.0000 (97.5451)  time: 0.2200  data: 0.0007  max mem: 2500
Test: [Task 1]  [ 480/1627]  eta: 0:04:12  Loss: 0.7021 (0.8158)  Acc@1: 87.5000 (85.9537)  Acc@5: 100.0000 (97.5442)  time: 0.2204  data: 0.0007  max mem: 2500
Test: [Task 1]  [ 490/1627]  eta: 0:04:10  Loss: 0.6981 (0.8148)  Acc@1: 87.5000 (85.9980)  Acc@5: 100.0000 (97.5305)  time: 0.2194  data: 0.0005  max mem: 2500
Test: [Task 1]  [ 500/1627]  eta: 0:04:08  Loss: 0.7221 (0.8161)  Acc@1: 87.5000 (86.0030)  Acc@5: 100.0000 (97.5175)  time: 0.2206  data: 0.0018  max mem: 2500
Test: [Task 1]  [ 510/1627]  eta: 0:04:05  Loss: 0.8328 (0.8215)  Acc@1: 87.5000 (85.9711)  Acc@5: 100.0000 (97.4804)  time: 0.2206  data: 0.0018  max mem: 2500
Test: [Task 1]  [ 520/1627]  eta: 0:04:03  Loss: 1.0828 (0.8289)  Acc@1: 81.2500 (85.8805)  Acc@5: 100.0000 (97.4448)  time: 0.2191  data: 0.0005  max mem: 2500
Test: [Task 1]  [ 530/1627]  eta: 0:04:01  Loss: 0.6703 (0.8240)  Acc@1: 93.7500 (86.0169)  Acc@5: 100.0000 (97.4929)  time: 0.2187  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 540/1627]  eta: 0:03:59  Loss: 0.6196 (0.8214)  Acc@1: 93.7500 (86.0790)  Acc@5: 100.0000 (97.4931)  time: 0.2201  data: 0.0006  max mem: 2500
Test: [Task 1]  [ 550/1627]  eta: 0:03:56  Loss: 0.7866 (0.8228)  Acc@1: 87.5000 (86.0481)  Acc@5: 100.0000 (97.5045)  time: 0.2198  data: 0.0006  max mem: 2500
Test: [Task 1]  [ 560/1627]  eta: 0:03:54  Loss: 0.8604 (0.8240)  Acc@1: 81.2500 (86.0071)  Acc@5: 100.0000 (97.5267)  time: 0.2181  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 570/1627]  eta: 0:03:52  Loss: 0.7290 (0.8212)  Acc@1: 87.5000 (86.0223)  Acc@5: 100.0000 (97.5372)  time: 0.2188  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 580/1627]  eta: 0:03:50  Loss: 0.6806 (0.8218)  Acc@1: 87.5000 (86.0047)  Acc@5: 100.0000 (97.5581)  time: 0.2190  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 590/1627]  eta: 0:03:48  Loss: 0.7055 (0.8197)  Acc@1: 87.5000 (86.0723)  Acc@5: 100.0000 (97.5783)  time: 0.2187  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 600/1627]  eta: 0:03:45  Loss: 0.6979 (0.8208)  Acc@1: 87.5000 (86.0337)  Acc@5: 100.0000 (97.5874)  time: 0.2182  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 610/1627]  eta: 0:03:43  Loss: 0.8134 (0.8200)  Acc@1: 87.5000 (86.0884)  Acc@5: 100.0000 (97.5859)  time: 0.2177  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 620/1627]  eta: 0:03:41  Loss: 0.7786 (0.8224)  Acc@1: 87.5000 (86.0407)  Acc@5: 100.0000 (97.5443)  time: 0.2178  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 630/1627]  eta: 0:03:39  Loss: 0.7764 (0.8224)  Acc@1: 87.5000 (86.0638)  Acc@5: 100.0000 (97.5436)  time: 0.2184  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 640/1627]  eta: 0:03:36  Loss: 0.6135 (0.8231)  Acc@1: 87.5000 (86.0472)  Acc@5: 100.0000 (97.5429)  time: 0.2189  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 650/1627]  eta: 0:03:34  Loss: 0.6794 (0.8222)  Acc@1: 81.2500 (86.0119)  Acc@5: 100.0000 (97.5518)  time: 0.2179  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 660/1627]  eta: 0:03:32  Loss: 0.6794 (0.8212)  Acc@1: 87.5000 (86.0155)  Acc@5: 100.0000 (97.5511)  time: 0.2194  data: 0.0008  max mem: 2500
Test: [Task 1]  [ 670/1627]  eta: 0:03:30  Loss: 0.7424 (0.8206)  Acc@1: 87.5000 (86.0190)  Acc@5: 100.0000 (97.5410)  time: 0.2206  data: 0.0008  max mem: 2500
Test: [Task 1]  [ 680/1627]  eta: 0:03:28  Loss: 0.8384 (0.8212)  Acc@1: 81.2500 (85.9581)  Acc@5: 100.0000 (97.5312)  time: 0.2197  data: 0.0006  max mem: 2500
Test: [Task 1]  [ 690/1627]  eta: 0:03:25  Loss: 0.7277 (0.8194)  Acc@1: 87.5000 (86.0076)  Acc@5: 100.0000 (97.5488)  time: 0.2188  data: 0.0006  max mem: 2500
Test: [Task 1]  [ 700/1627]  eta: 0:03:23  Loss: 0.7277 (0.8201)  Acc@1: 93.7500 (86.0289)  Acc@5: 100.0000 (97.5214)  time: 0.2189  data: 0.0011  max mem: 2500
Test: [Task 1]  [ 710/1627]  eta: 0:03:21  Loss: 0.7335 (0.8183)  Acc@1: 87.5000 (86.0496)  Acc@5: 100.0000 (97.5299)  time: 0.2198  data: 0.0014  max mem: 2500
Test: [Task 1]  [ 720/1627]  eta: 0:03:19  Loss: 0.6591 (0.8160)  Acc@1: 87.5000 (86.0784)  Acc@5: 100.0000 (97.5468)  time: 0.2194  data: 0.0007  max mem: 2500
Test: [Task 1]  [ 730/1627]  eta: 0:03:17  Loss: 0.7008 (0.8166)  Acc@1: 87.5000 (86.0465)  Acc@5: 100.0000 (97.5291)  time: 0.2188  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 740/1627]  eta: 0:03:14  Loss: 0.8040 (0.8180)  Acc@1: 81.2500 (86.0240)  Acc@5: 100.0000 (97.5202)  time: 0.2182  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 750/1627]  eta: 0:03:12  Loss: 0.8018 (0.8173)  Acc@1: 87.5000 (86.0769)  Acc@5: 100.0000 (97.5200)  time: 0.2187  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 760/1627]  eta: 0:03:10  Loss: 0.8144 (0.8210)  Acc@1: 87.5000 (86.0299)  Acc@5: 100.0000 (97.4951)  time: 0.2189  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 770/1627]  eta: 0:03:08  Loss: 0.6986 (0.8178)  Acc@1: 87.5000 (86.1219)  Acc@5: 100.0000 (97.5032)  time: 0.2188  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 780/1627]  eta: 0:03:06  Loss: 0.5582 (0.8151)  Acc@1: 93.7500 (86.1956)  Acc@5: 100.0000 (97.5272)  time: 0.2196  data: 0.0013  max mem: 2500
Test: [Task 1]  [ 790/1627]  eta: 0:03:03  Loss: 0.6777 (0.8165)  Acc@1: 87.5000 (86.1805)  Acc@5: 100.0000 (97.5032)  time: 0.2193  data: 0.0013  max mem: 2500
Test: [Task 1]  [ 800/1627]  eta: 0:03:01  Loss: 0.7851 (0.8156)  Acc@1: 87.5000 (86.2203)  Acc@5: 100.0000 (97.5187)  time: 0.2187  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 810/1627]  eta: 0:02:59  Loss: 0.7659 (0.8155)  Acc@1: 87.5000 (86.2361)  Acc@5: 100.0000 (97.4954)  time: 0.2192  data: 0.0011  max mem: 2500
Test: [Task 1]  [ 820/1627]  eta: 0:02:57  Loss: 0.7219 (0.8145)  Acc@1: 93.7500 (86.3048)  Acc@5: 100.0000 (97.4954)  time: 0.2192  data: 0.0011  max mem: 2500
Test: [Task 1]  [ 830/1627]  eta: 0:02:55  Loss: 0.6370 (0.8137)  Acc@1: 87.5000 (86.3267)  Acc@5: 100.0000 (97.4955)  time: 0.2196  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 840/1627]  eta: 0:02:52  Loss: 0.5521 (0.8120)  Acc@1: 87.5000 (86.3630)  Acc@5: 100.0000 (97.5178)  time: 0.2189  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 850/1627]  eta: 0:02:50  Loss: 0.6541 (0.8131)  Acc@1: 93.7500 (86.3690)  Acc@5: 100.0000 (97.5397)  time: 0.2186  data: 0.0005  max mem: 2500
Test: [Task 1]  [ 860/1627]  eta: 0:02:48  Loss: 0.6929 (0.8124)  Acc@1: 87.5000 (86.3821)  Acc@5: 100.0000 (97.5537)  time: 0.2190  data: 0.0005  max mem: 2500
Test: [Task 1]  [ 870/1627]  eta: 0:02:46  Loss: 0.6929 (0.8116)  Acc@1: 87.5000 (86.3949)  Acc@5: 100.0000 (97.5459)  time: 0.2185  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 880/1627]  eta: 0:02:44  Loss: 0.8673 (0.8135)  Acc@1: 87.5000 (86.3649)  Acc@5: 100.0000 (97.5596)  time: 0.2191  data: 0.0005  max mem: 2500
Test: [Task 1]  [ 890/1627]  eta: 0:02:41  Loss: 0.9271 (0.8159)  Acc@1: 81.2500 (86.3215)  Acc@5: 100.0000 (97.5379)  time: 0.2199  data: 0.0012  max mem: 2500
Test: [Task 1]  [ 900/1627]  eta: 0:02:39  Loss: 0.7778 (0.8156)  Acc@1: 81.2500 (86.3346)  Acc@5: 100.0000 (97.5375)  time: 0.2200  data: 0.0018  max mem: 2500
Test: [Task 1]  [ 910/1627]  eta: 0:02:37  Loss: 0.7597 (0.8162)  Acc@1: 87.5000 (86.3131)  Acc@5: 100.0000 (97.5165)  time: 0.2200  data: 0.0011  max mem: 2500
Test: [Task 1]  [ 920/1627]  eta: 0:02:35  Loss: 0.7078 (0.8151)  Acc@1: 87.5000 (86.3464)  Acc@5: 100.0000 (97.5231)  time: 0.2205  data: 0.0012  max mem: 2500
Test: [Task 1]  [ 930/1627]  eta: 0:02:33  Loss: 0.6875 (0.8150)  Acc@1: 87.5000 (86.3520)  Acc@5: 100.0000 (97.5295)  time: 0.2201  data: 0.0011  max mem: 2500
Test: [Task 1]  [ 940/1627]  eta: 0:02:30  Loss: 0.6881 (0.8140)  Acc@1: 87.5000 (86.3709)  Acc@5: 100.0000 (97.5491)  time: 0.2192  data: 0.0010  max mem: 2500
Test: [Task 1]  [ 950/1627]  eta: 0:02:28  Loss: 0.7306 (0.8153)  Acc@1: 87.5000 (86.3368)  Acc@5: 100.0000 (97.5552)  time: 0.2196  data: 0.0013  max mem: 2500
Test: [Task 1]  [ 960/1627]  eta: 0:02:26  Loss: 0.7453 (0.8148)  Acc@1: 81.2500 (86.3293)  Acc@5: 100.0000 (97.5806)  time: 0.2197  data: 0.0014  max mem: 2500
Test: [Task 1]  [ 970/1627]  eta: 0:02:24  Loss: 0.6548 (0.8134)  Acc@1: 87.5000 (86.3414)  Acc@5: 100.0000 (97.5863)  time: 0.2198  data: 0.0014  max mem: 2500
Test: [Task 1]  [ 980/1627]  eta: 0:02:22  Loss: 0.7818 (0.8139)  Acc@1: 87.5000 (86.3468)  Acc@5: 100.0000 (97.5663)  time: 0.2192  data: 0.0008  max mem: 2500
Test: [Task 1]  [ 990/1627]  eta: 0:02:19  Loss: 0.9091 (0.8166)  Acc@1: 87.5000 (86.3459)  Acc@5: 93.7500 (97.5467)  time: 0.2190  data: 0.0011  max mem: 2500
Test: [Task 1]  [1000/1627]  eta: 0:02:17  Loss: 0.9776 (0.8179)  Acc@1: 87.5000 (86.3074)  Acc@5: 100.0000 (97.5275)  time: 0.2200  data: 0.0017  max mem: 2500
Test: [Task 1]  [1010/1627]  eta: 0:02:15  Loss: 0.8463 (0.8181)  Acc@1: 87.5000 (86.3069)  Acc@5: 100.0000 (97.5148)  time: 0.2194  data: 0.0014  max mem: 2500
Test: [Task 1]  [1020/1627]  eta: 0:02:13  Loss: 0.7893 (0.8183)  Acc@1: 87.5000 (86.3186)  Acc@5: 100.0000 (97.5208)  time: 0.2178  data: 0.0007  max mem: 2500
Test: [Task 1]  [1030/1627]  eta: 0:02:11  Loss: 0.6654 (0.8167)  Acc@1: 87.5000 (86.3664)  Acc@5: 100.0000 (97.5206)  time: 0.2175  data: 0.0004  max mem: 2500
Test: [Task 1]  [1040/1627]  eta: 0:02:08  Loss: 0.6567 (0.8162)  Acc@1: 87.5000 (86.3593)  Acc@5: 100.0000 (97.5324)  time: 0.2178  data: 0.0004  max mem: 2500
Test: [Task 1]  [1050/1627]  eta: 0:02:06  Loss: 0.6567 (0.8143)  Acc@1: 87.5000 (86.3880)  Acc@5: 100.0000 (97.5500)  time: 0.2187  data: 0.0005  max mem: 2500
Test: [Task 1]  [1060/1627]  eta: 0:02:04  Loss: 0.6852 (0.8142)  Acc@1: 87.5000 (86.3926)  Acc@5: 100.0000 (97.5495)  time: 0.2189  data: 0.0005  max mem: 2500
Test: [Task 1]  [1070/1627]  eta: 0:02:02  Loss: 0.7347 (0.8143)  Acc@1: 87.5000 (86.4029)  Acc@5: 100.0000 (97.5432)  time: 0.2182  data: 0.0004  max mem: 2500
Test: [Task 1]  [1080/1627]  eta: 0:02:00  Loss: 0.7552 (0.8148)  Acc@1: 87.5000 (86.4073)  Acc@5: 100.0000 (97.5254)  time: 0.2179  data: 0.0005  max mem: 2500
Test: [Task 1]  [1090/1627]  eta: 0:01:57  Loss: 0.7638 (0.8152)  Acc@1: 81.2500 (86.3886)  Acc@5: 100.0000 (97.5195)  time: 0.2190  data: 0.0004  max mem: 2500
Test: [Task 1]  [1100/1627]  eta: 0:01:55  Loss: 0.7320 (0.8136)  Acc@1: 87.5000 (86.4044)  Acc@5: 100.0000 (97.5363)  time: 0.2193  data: 0.0007  max mem: 2500
Test: [Task 1]  [1110/1627]  eta: 0:01:53  Loss: 0.6758 (0.8138)  Acc@1: 87.5000 (86.4086)  Acc@5: 100.0000 (97.5248)  time: 0.2184  data: 0.0011  max mem: 2500
Test: [Task 1]  [1120/1627]  eta: 0:01:51  Loss: 0.8306 (0.8153)  Acc@1: 87.5000 (86.3849)  Acc@5: 100.0000 (97.5245)  time: 0.2188  data: 0.0009  max mem: 2500
Test: [Task 1]  [1130/1627]  eta: 0:01:49  Loss: 0.8419 (0.8159)  Acc@1: 87.5000 (86.3782)  Acc@5: 100.0000 (97.5243)  time: 0.2187  data: 0.0006  max mem: 2500
Test: [Task 1]  [1140/1627]  eta: 0:01:46  Loss: 0.8438 (0.8168)  Acc@1: 87.5000 (86.3826)  Acc@5: 100.0000 (97.5131)  time: 0.2182  data: 0.0005  max mem: 2500
Test: [Task 1]  [1150/1627]  eta: 0:01:44  Loss: 0.8546 (0.8183)  Acc@1: 87.5000 (86.3434)  Acc@5: 100.0000 (97.5076)  time: 0.2181  data: 0.0005  max mem: 2500
Test: [Task 1]  [1160/1627]  eta: 0:01:42  Loss: 0.8104 (0.8166)  Acc@1: 87.5000 (86.3857)  Acc@5: 100.0000 (97.5237)  time: 0.2177  data: 0.0004  max mem: 2500
Test: [Task 1]  [1170/1627]  eta: 0:01:40  Loss: 0.7414 (0.8158)  Acc@1: 87.5000 (86.4112)  Acc@5: 100.0000 (97.5395)  time: 0.2178  data: 0.0004  max mem: 2500
Test: [Task 1]  [1180/1627]  eta: 0:01:38  Loss: 0.7893 (0.8162)  Acc@1: 87.5000 (86.4151)  Acc@5: 100.0000 (97.5445)  time: 0.2186  data: 0.0008  max mem: 2500
Test: [Task 1]  [1190/1627]  eta: 0:01:35  Loss: 0.8582 (0.8170)  Acc@1: 87.5000 (86.3980)  Acc@5: 100.0000 (97.5283)  time: 0.2191  data: 0.0009  max mem: 2500
Test: [Task 1]  [1200/1627]  eta: 0:01:33  Loss: 0.8337 (0.8170)  Acc@1: 87.5000 (86.3811)  Acc@5: 100.0000 (97.5333)  time: 0.2184  data: 0.0004  max mem: 2500
Test: [Task 1]  [1210/1627]  eta: 0:01:31  Loss: 0.6961 (0.8173)  Acc@1: 87.5000 (86.3491)  Acc@5: 100.0000 (97.5382)  time: 0.2188  data: 0.0013  max mem: 2500
Test: [Task 1]  [1220/1627]  eta: 0:01:29  Loss: 0.6527 (0.8162)  Acc@1: 87.5000 (86.3432)  Acc@5: 100.0000 (97.5584)  time: 0.2187  data: 0.0013  max mem: 2500
Test: [Task 1]  [1230/1627]  eta: 0:01:27  Loss: 0.7564 (0.8171)  Acc@1: 87.5000 (86.3221)  Acc@5: 100.0000 (97.5426)  time: 0.2176  data: 0.0004  max mem: 2500
Test: [Task 1]  [1240/1627]  eta: 0:01:24  Loss: 0.7674 (0.8164)  Acc@1: 87.5000 (86.3215)  Acc@5: 100.0000 (97.5524)  time: 0.2175  data: 0.0004  max mem: 2500
Test: [Task 1]  [1250/1627]  eta: 0:01:22  Loss: 0.8338 (0.8171)  Acc@1: 87.5000 (86.3010)  Acc@5: 100.0000 (97.5470)  time: 0.2181  data: 0.0003  max mem: 2500
Test: [Task 1]  [1260/1627]  eta: 0:01:20  Loss: 0.8610 (0.8169)  Acc@1: 87.5000 (86.3253)  Acc@5: 100.0000 (97.5416)  time: 0.2184  data: 0.0003  max mem: 2500
Test: [Task 1]  [1270/1627]  eta: 0:01:18  Loss: 0.7179 (0.8174)  Acc@1: 87.5000 (86.3247)  Acc@5: 100.0000 (97.5413)  time: 0.2180  data: 0.0006  max mem: 2500
Test: [Task 1]  [1280/1627]  eta: 0:01:16  Loss: 0.6383 (0.8158)  Acc@1: 87.5000 (86.3290)  Acc@5: 100.0000 (97.5507)  time: 0.2193  data: 0.0015  max mem: 2500
Test: [Task 1]  [1290/1627]  eta: 0:01:13  Loss: 0.6835 (0.8160)  Acc@1: 87.5000 (86.3091)  Acc@5: 100.0000 (97.5503)  time: 0.2194  data: 0.0011  max mem: 2500
Test: [Task 1]  [1300/1627]  eta: 0:01:11  Loss: 0.8494 (0.8153)  Acc@1: 87.5000 (86.3374)  Acc@5: 100.0000 (97.5500)  time: 0.2199  data: 0.0006  max mem: 2500
Test: [Task 1]  [1310/1627]  eta: 0:01:09  Loss: 0.6904 (0.8137)  Acc@1: 87.5000 (86.3606)  Acc@5: 100.0000 (97.5496)  time: 0.2202  data: 0.0008  max mem: 2500
Test: [Task 1]  [1320/1627]  eta: 0:01:07  Loss: 0.5927 (0.8126)  Acc@1: 87.5000 (86.3834)  Acc@5: 100.0000 (97.5445)  time: 0.2179  data: 0.0005  max mem: 2500
Test: [Task 1]  [1330/1627]  eta: 0:01:05  Loss: 0.6554 (0.8122)  Acc@1: 87.5000 (86.3871)  Acc@5: 100.0000 (97.5488)  time: 0.2180  data: 0.0003  max mem: 2500
Test: [Task 1]  [1340/1627]  eta: 0:01:02  Loss: 0.6774 (0.8124)  Acc@1: 87.5000 (86.3861)  Acc@5: 100.0000 (97.5485)  time: 0.2186  data: 0.0003  max mem: 2500
Test: [Task 1]  [1350/1627]  eta: 0:01:00  Loss: 0.6386 (0.8118)  Acc@1: 87.5000 (86.3990)  Acc@5: 100.0000 (97.5435)  time: 0.2184  data: 0.0003  max mem: 2500
Test: [Task 1]  [1360/1627]  eta: 0:00:58  Loss: 0.6885 (0.8117)  Acc@1: 87.5000 (86.4025)  Acc@5: 100.0000 (97.5432)  time: 0.2186  data: 0.0004  max mem: 2500
Test: [Task 1]  [1370/1627]  eta: 0:00:56  Loss: 0.7562 (0.8111)  Acc@1: 87.5000 (86.4059)  Acc@5: 100.0000 (97.5520)  time: 0.2187  data: 0.0004  max mem: 2500
Test: [Task 1]  [1380/1627]  eta: 0:00:54  Loss: 0.6771 (0.8113)  Acc@1: 87.5000 (86.4048)  Acc@5: 100.0000 (97.5561)  time: 0.2182  data: 0.0004  max mem: 2500
Test: [Task 1]  [1390/1627]  eta: 0:00:51  Loss: 0.6757 (0.8104)  Acc@1: 87.5000 (86.4261)  Acc@5: 100.0000 (97.5692)  time: 0.2180  data: 0.0004  max mem: 2500
Test: [Task 1]  [1400/1627]  eta: 0:00:49  Loss: 0.6600 (0.8108)  Acc@1: 87.5000 (86.3847)  Acc@5: 100.0000 (97.5642)  time: 0.2180  data: 0.0004  max mem: 2500
Test: [Task 1]  [1410/1627]  eta: 0:00:47  Loss: 0.7342 (0.8105)  Acc@1: 87.5000 (86.3971)  Acc@5: 100.0000 (97.5726)  time: 0.2182  data: 0.0004  max mem: 2500
Test: [Task 1]  [1420/1627]  eta: 0:00:45  Loss: 0.7443 (0.8104)  Acc@1: 93.7500 (86.3960)  Acc@5: 100.0000 (97.5809)  time: 0.2192  data: 0.0005  max mem: 2500
Test: [Task 1]  [1430/1627]  eta: 0:00:43  Loss: 0.8830 (0.8124)  Acc@1: 81.2500 (86.3513)  Acc@5: 100.0000 (97.5411)  time: 0.2189  data: 0.0004  max mem: 2500
Test: [Task 1]  [1440/1627]  eta: 0:00:41  Loss: 0.8830 (0.8123)  Acc@1: 81.2500 (86.3463)  Acc@5: 100.0000 (97.5451)  time: 0.2175  data: 0.0003  max mem: 2500
Test: [Task 1]  [1450/1627]  eta: 0:00:38  Loss: 0.8331 (0.8133)  Acc@1: 81.2500 (86.3112)  Acc@5: 100.0000 (97.5491)  time: 0.2178  data: 0.0005  max mem: 2500
Test: [Task 1]  [1460/1627]  eta: 0:00:36  Loss: 0.7784 (0.8131)  Acc@1: 81.2500 (86.3236)  Acc@5: 100.0000 (97.5488)  time: 0.2178  data: 0.0005  max mem: 2500
Test: [Task 1]  [1470/1627]  eta: 0:00:34  Loss: 0.7622 (0.8135)  Acc@1: 87.5000 (86.3316)  Acc@5: 100.0000 (97.5484)  time: 0.2177  data: 0.0004  max mem: 2500
Test: [Task 1]  [1480/1627]  eta: 0:00:32  Loss: 0.8384 (0.8143)  Acc@1: 87.5000 (86.3099)  Acc@5: 100.0000 (97.5397)  time: 0.2191  data: 0.0016  max mem: 2500
Test: [Task 1]  [1490/1627]  eta: 0:00:30  Loss: 0.8384 (0.8146)  Acc@1: 87.5000 (86.3053)  Acc@5: 100.0000 (97.5394)  time: 0.2188  data: 0.0015  max mem: 2500
Test: [Task 1]  [1500/1627]  eta: 0:00:27  Loss: 0.7517 (0.8144)  Acc@1: 87.5000 (86.3133)  Acc@5: 100.0000 (97.5391)  time: 0.2179  data: 0.0003  max mem: 2500
Test: [Task 1]  [1510/1627]  eta: 0:00:25  Loss: 0.6268 (0.8143)  Acc@1: 93.7500 (86.3211)  Acc@5: 100.0000 (97.5430)  time: 0.2180  data: 0.0004  max mem: 2500
Test: [Task 1]  [1520/1627]  eta: 0:00:23  Loss: 0.6419 (0.8130)  Acc@1: 93.7500 (86.3536)  Acc@5: 100.0000 (97.5551)  time: 0.2181  data: 0.0005  max mem: 2500
Test: [Task 1]  [1530/1627]  eta: 0:00:21  Loss: 0.6419 (0.8126)  Acc@1: 93.7500 (86.3610)  Acc@5: 100.0000 (97.5547)  time: 0.2182  data: 0.0005  max mem: 2500
Test: [Task 1]  [1540/1627]  eta: 0:00:19  Loss: 0.5223 (0.8114)  Acc@1: 87.5000 (86.3887)  Acc@5: 100.0000 (97.5584)  time: 0.2185  data: 0.0007  max mem: 2500
Test: [Task 1]  [1550/1627]  eta: 0:00:16  Loss: 0.5534 (0.8110)  Acc@1: 87.5000 (86.4039)  Acc@5: 100.0000 (97.5580)  time: 0.2181  data: 0.0007  max mem: 2500
Test: [Task 1]  [1560/1627]  eta: 0:00:14  Loss: 0.6377 (0.8104)  Acc@1: 87.5000 (86.4190)  Acc@5: 100.0000 (97.5617)  time: 0.2168  data: 0.0003  max mem: 2500
Test: [Task 1]  [1570/1627]  eta: 0:00:12  Loss: 0.6377 (0.8104)  Acc@1: 87.5000 (86.4219)  Acc@5: 100.0000 (97.5533)  time: 0.2175  data: 0.0006  max mem: 2500
Test: [Task 1]  [1580/1627]  eta: 0:00:10  Loss: 0.6281 (0.8102)  Acc@1: 87.5000 (86.4366)  Acc@5: 100.0000 (97.5569)  time: 0.2190  data: 0.0008  max mem: 2500
Test: [Task 1]  [1590/1627]  eta: 0:00:08  Loss: 0.6632 (0.8105)  Acc@1: 87.5000 (86.4118)  Acc@5: 100.0000 (97.5526)  time: 0.2190  data: 0.0006  max mem: 2500
Test: [Task 1]  [1600/1627]  eta: 0:00:05  Loss: 0.7409 (0.8115)  Acc@1: 81.2500 (86.3796)  Acc@5: 100.0000 (97.5367)  time: 0.2180  data: 0.0004  max mem: 2500
Test: [Task 1]  [1610/1627]  eta: 0:00:03  Loss: 0.7921 (0.8107)  Acc@1: 81.2500 (86.4021)  Acc@5: 100.0000 (97.5403)  time: 0.2185  data: 0.0004  max mem: 2500
Test: [Task 1]  [1620/1627]  eta: 0:00:01  Loss: 0.6386 (0.8097)  Acc@1: 93.7500 (86.4397)  Acc@5: 100.0000 (97.5478)  time: 0.2185  data: 0.0004  max mem: 2500
Test: [Task 1]  [1626/1627]  eta: 0:00:00  Loss: 0.6688 (0.8092)  Acc@1: 93.7500 (86.4513)  Acc@5: 100.0000 (97.5453)  time: 0.2193  data: 0.0003  max mem: 2500
Test: [Task 1] Total time: 0:05:56 (0.2194 s / it)
* Acc@1 86.451 Acc@5 97.545 loss 0.809
{0: {0: 3442, 1: 0, 2: 6331, 3: 0, 4: 17278, 5: 19225, 6: 0, 7: 3607, 8: 0, 9: 0, 10: 0, 11: 6402, 12: 0, 13: 19672, 14: 0, 15: 19774, 16: 0, 17: 0, 18: 5693, 19: 2704}}
[Average accuracy till task1]	Acc@1: 86.4513	Acc@5: 97.5453	Loss: 0.8092
Train: Epoch[1/5]  [   0/3750]  eta: 0:44:17  Lr: 0.001875  Loss: 1.6407  Acc@1: 6.2500 (6.2500)  Acc@5: 62.5000 (62.5000)  time: 0.7088  data: 0.3435  max mem: 2500
Train: Epoch[1/5]  [  10/3750]  eta: 0:23:41  Lr: 0.001875  Loss: 1.2788  Acc@1: 37.5000 (32.3864)  Acc@5: 68.7500 (71.0227)  time: 0.3801  data: 0.0315  max mem: 2500
Train: Epoch[1/5]  [  20/3750]  eta: 0:22:44  Lr: 0.001875  Loss: 1.1167  Acc@1: 43.7500 (38.6905)  Acc@5: 75.0000 (72.9167)  time: 0.3488  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [  30/3750]  eta: 0:22:22  Lr: 0.001875  Loss: 1.0562  Acc@1: 43.7500 (41.7339)  Acc@5: 75.0000 (74.5968)  time: 0.3502  data: 0.0012  max mem: 2500
Train: Epoch[1/5]  [  40/3750]  eta: 0:22:07  Lr: 0.001875  Loss: 0.7876  Acc@1: 43.7500 (44.5122)  Acc@5: 87.5000 (78.3537)  time: 0.3490  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [  50/3750]  eta: 0:21:57  Lr: 0.001875  Loss: 0.8330  Acc@1: 62.5000 (47.6716)  Acc@5: 87.5000 (80.6373)  time: 0.3485  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [  60/3750]  eta: 0:21:51  Lr: 0.001875  Loss: 0.9216  Acc@1: 56.2500 (49.1803)  Acc@5: 87.5000 (82.0697)  time: 0.3504  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [  70/3750]  eta: 0:21:43  Lr: 0.001875  Loss: 0.4344  Acc@1: 62.5000 (51.4085)  Acc@5: 93.7500 (83.5387)  time: 0.3500  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [  80/3750]  eta: 0:21:39  Lr: 0.001875  Loss: 0.1869  Acc@1: 62.5000 (52.8549)  Acc@5: 93.7500 (84.9537)  time: 0.3499  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [  90/3750]  eta: 0:21:34  Lr: 0.001875  Loss: 0.2546  Acc@1: 62.5000 (53.6401)  Acc@5: 93.7500 (85.5082)  time: 0.3511  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [ 100/3750]  eta: 0:21:29  Lr: 0.001875  Loss: 0.2316  Acc@1: 62.5000 (54.2698)  Acc@5: 93.7500 (86.1386)  time: 0.3501  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [ 110/3750]  eta: 0:21:25  Lr: 0.001875  Loss: 0.0105  Acc@1: 62.5000 (55.2928)  Acc@5: 93.7500 (86.6554)  time: 0.3507  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [ 120/3750]  eta: 0:21:21  Lr: 0.001875  Loss: 0.2655  Acc@1: 68.7500 (56.4566)  Acc@5: 93.7500 (87.2417)  time: 0.3522  data: 0.0020  max mem: 2500
Train: Epoch[1/5]  [ 130/3750]  eta: 0:21:18  Lr: 0.001875  Loss: 0.0654  Acc@1: 68.7500 (57.5382)  Acc@5: 93.7500 (87.7863)  time: 0.3533  data: 0.0028  max mem: 2500
Train: Epoch[1/5]  [ 140/3750]  eta: 0:21:14  Lr: 0.001875  Loss: 0.1077  Acc@1: 68.7500 (58.1560)  Acc@5: 93.7500 (87.9433)  time: 0.3526  data: 0.0012  max mem: 2500
Train: Epoch[1/5]  [ 150/3750]  eta: 0:21:09  Lr: 0.001875  Loss: -0.0172  Acc@1: 68.7500 (58.8576)  Acc@5: 93.7500 (88.3278)  time: 0.3501  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 160/3750]  eta: 0:21:06  Lr: 0.001875  Loss: 0.1003  Acc@1: 68.7500 (59.5497)  Acc@5: 93.7500 (88.8199)  time: 0.3503  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [ 170/3750]  eta: 0:21:02  Lr: 0.001875  Loss: -0.2499  Acc@1: 75.0000 (60.5263)  Acc@5: 93.7500 (89.2178)  time: 0.3519  data: 0.0009  max mem: 2500
Train: Epoch[1/5]  [ 180/3750]  eta: 0:20:58  Lr: 0.001875  Loss: -0.2342  Acc@1: 68.7500 (60.8080)  Acc@5: 100.0000 (89.5373)  time: 0.3520  data: 0.0015  max mem: 2500
Train: Epoch[1/5]  [ 190/3750]  eta: 0:20:54  Lr: 0.001875  Loss: 0.0143  Acc@1: 68.7500 (61.2893)  Acc@5: 93.7500 (89.7906)  time: 0.3502  data: 0.0013  max mem: 2500
Train: Epoch[1/5]  [ 200/3750]  eta: 0:20:50  Lr: 0.001875  Loss: -0.4664  Acc@1: 75.0000 (62.0336)  Acc@5: 93.7500 (90.1119)  time: 0.3491  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 210/3750]  eta: 0:20:46  Lr: 0.001875  Loss: -0.1453  Acc@1: 68.7500 (62.0557)  Acc@5: 93.7500 (90.1066)  time: 0.3498  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [ 220/3750]  eta: 0:20:43  Lr: 0.001875  Loss: -0.5013  Acc@1: 68.7500 (62.3020)  Acc@5: 93.7500 (90.2998)  time: 0.3513  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [ 230/3750]  eta: 0:20:39  Lr: 0.001875  Loss: -0.0198  Acc@1: 68.7500 (62.5000)  Acc@5: 93.7500 (90.4491)  time: 0.3517  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [ 240/3750]  eta: 0:20:35  Lr: 0.001875  Loss: -0.6278  Acc@1: 68.7500 (62.7334)  Acc@5: 93.7500 (90.5342)  time: 0.3509  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [ 250/3750]  eta: 0:20:31  Lr: 0.001875  Loss: -0.2936  Acc@1: 68.7500 (62.9980)  Acc@5: 93.7500 (90.7122)  time: 0.3510  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 260/3750]  eta: 0:20:28  Lr: 0.001875  Loss: -0.1962  Acc@1: 68.7500 (63.4818)  Acc@5: 93.7500 (90.8046)  time: 0.3504  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [ 270/3750]  eta: 0:20:24  Lr: 0.001875  Loss: -0.1695  Acc@1: 68.7500 (63.8376)  Acc@5: 93.7500 (90.9825)  time: 0.3501  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [ 280/3750]  eta: 0:20:20  Lr: 0.001875  Loss: -0.3501  Acc@1: 68.7500 (64.1904)  Acc@5: 100.0000 (91.1032)  time: 0.3494  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [ 290/3750]  eta: 0:20:16  Lr: 0.001875  Loss: -0.2459  Acc@1: 68.7500 (64.3686)  Acc@5: 93.7500 (91.2801)  time: 0.3487  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 300/3750]  eta: 0:20:13  Lr: 0.001875  Loss: -0.2505  Acc@1: 68.7500 (64.3895)  Acc@5: 93.7500 (91.3414)  time: 0.3506  data: 0.0017  max mem: 2500
Train: Epoch[1/5]  [ 310/3750]  eta: 0:20:09  Lr: 0.001875  Loss: -0.5190  Acc@1: 68.7500 (64.5699)  Acc@5: 93.7500 (91.4389)  time: 0.3529  data: 0.0028  max mem: 2500
Train: Epoch[1/5]  [ 320/3750]  eta: 0:20:06  Lr: 0.001875  Loss: -0.3996  Acc@1: 75.0000 (64.7391)  Acc@5: 93.7500 (91.5109)  time: 0.3508  data: 0.0015  max mem: 2500
Train: Epoch[1/5]  [ 330/3750]  eta: 0:20:02  Lr: 0.001875  Loss: -0.4408  Acc@1: 68.7500 (64.7659)  Acc@5: 93.7500 (91.5785)  time: 0.3489  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 340/3750]  eta: 0:19:58  Lr: 0.001875  Loss: -0.7143  Acc@1: 68.7500 (65.0660)  Acc@5: 93.7500 (91.7339)  time: 0.3495  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [ 350/3750]  eta: 0:19:55  Lr: 0.001875  Loss: -0.3925  Acc@1: 68.7500 (65.0997)  Acc@5: 93.7500 (91.8091)  time: 0.3503  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [ 360/3750]  eta: 0:19:51  Lr: 0.001875  Loss: -0.6329  Acc@1: 68.7500 (65.4432)  Acc@5: 93.7500 (91.9841)  time: 0.3504  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [ 370/3750]  eta: 0:19:47  Lr: 0.001875  Loss: -0.8450  Acc@1: 75.0000 (65.6503)  Acc@5: 100.0000 (92.1327)  time: 0.3500  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [ 380/3750]  eta: 0:19:44  Lr: 0.001875  Loss: -0.8016  Acc@1: 75.0000 (66.0761)  Acc@5: 100.0000 (92.2408)  time: 0.3515  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [ 390/3750]  eta: 0:19:40  Lr: 0.001875  Loss: -0.5105  Acc@1: 81.2500 (66.4162)  Acc@5: 100.0000 (92.3434)  time: 0.3527  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [ 400/3750]  eta: 0:19:37  Lr: 0.001875  Loss: -0.2610  Acc@1: 81.2500 (66.6459)  Acc@5: 93.7500 (92.3784)  time: 0.3526  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [ 410/3750]  eta: 0:19:34  Lr: 0.001875  Loss: -0.2236  Acc@1: 81.2500 (66.9556)  Acc@5: 93.7500 (92.4422)  time: 0.3522  data: 0.0012  max mem: 2500
Train: Epoch[1/5]  [ 420/3750]  eta: 0:19:30  Lr: 0.001875  Loss: -0.7047  Acc@1: 81.2500 (67.1912)  Acc@5: 93.7500 (92.5178)  time: 0.3515  data: 0.0012  max mem: 2500
Train: Epoch[1/5]  [ 430/3750]  eta: 0:19:27  Lr: 0.001875  Loss: -0.5230  Acc@1: 75.0000 (67.2129)  Acc@5: 93.7500 (92.6189)  time: 0.3530  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [ 440/3750]  eta: 0:19:23  Lr: 0.001875  Loss: -0.8238  Acc@1: 62.5000 (67.2477)  Acc@5: 93.7500 (92.6162)  time: 0.3529  data: 0.0012  max mem: 2500
Train: Epoch[1/5]  [ 450/3750]  eta: 0:19:20  Lr: 0.001875  Loss: -0.5584  Acc@1: 75.0000 (67.4751)  Acc@5: 93.7500 (92.7106)  time: 0.3505  data: 0.0012  max mem: 2500
Train: Epoch[1/5]  [ 460/3750]  eta: 0:19:16  Lr: 0.001875  Loss: -0.2381  Acc@1: 75.0000 (67.6247)  Acc@5: 93.7500 (92.7467)  time: 0.3508  data: 0.0018  max mem: 2500
Train: Epoch[1/5]  [ 470/3750]  eta: 0:19:13  Lr: 0.001875  Loss: -0.7582  Acc@1: 75.0000 (67.7150)  Acc@5: 93.7500 (92.7548)  time: 0.3516  data: 0.0019  max mem: 2500
Train: Epoch[1/5]  [ 480/3750]  eta: 0:19:09  Lr: 0.001875  Loss: -0.7781  Acc@1: 75.0000 (67.8664)  Acc@5: 93.7500 (92.8274)  time: 0.3516  data: 0.0013  max mem: 2500
Train: Epoch[1/5]  [ 490/3750]  eta: 0:19:05  Lr: 0.001875  Loss: -0.4379  Acc@1: 81.2500 (68.1135)  Acc@5: 93.7500 (92.8844)  time: 0.3515  data: 0.0012  max mem: 2500
Train: Epoch[1/5]  [ 500/3750]  eta: 0:19:02  Lr: 0.001875  Loss: -0.7628  Acc@1: 75.0000 (68.2385)  Acc@5: 93.7500 (92.8892)  time: 0.3509  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [ 510/3750]  eta: 0:18:58  Lr: 0.001875  Loss: -0.9138  Acc@1: 75.0000 (68.2730)  Acc@5: 93.7500 (92.9061)  time: 0.3499  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [ 520/3750]  eta: 0:18:55  Lr: 0.001875  Loss: -0.9532  Acc@1: 75.0000 (68.4621)  Acc@5: 93.7500 (92.9822)  time: 0.3509  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [ 530/3750]  eta: 0:18:51  Lr: 0.001875  Loss: -0.6955  Acc@1: 75.0000 (68.5028)  Acc@5: 100.0000 (93.0556)  time: 0.3504  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [ 540/3750]  eta: 0:18:47  Lr: 0.001875  Loss: -1.2035  Acc@1: 81.2500 (68.8309)  Acc@5: 100.0000 (93.1377)  time: 0.3492  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [ 550/3750]  eta: 0:18:44  Lr: 0.001875  Loss: -0.8034  Acc@1: 81.2500 (68.9315)  Acc@5: 93.7500 (93.1715)  time: 0.3511  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [ 560/3750]  eta: 0:18:40  Lr: 0.001875  Loss: -0.9886  Acc@1: 75.0000 (69.0508)  Acc@5: 93.7500 (93.1595)  time: 0.3514  data: 0.0009  max mem: 2500
Train: Epoch[1/5]  [ 570/3750]  eta: 0:18:37  Lr: 0.001875  Loss: -0.4672  Acc@1: 75.0000 (69.1222)  Acc@5: 93.7500 (93.2246)  time: 0.3503  data: 0.0016  max mem: 2500
Train: Epoch[1/5]  [ 580/3750]  eta: 0:18:33  Lr: 0.001875  Loss: -1.1139  Acc@1: 75.0000 (69.2771)  Acc@5: 100.0000 (93.2982)  time: 0.3498  data: 0.0012  max mem: 2500
Train: Epoch[1/5]  [ 590/3750]  eta: 0:18:30  Lr: 0.001875  Loss: -0.0797  Acc@1: 75.0000 (69.2893)  Acc@5: 93.7500 (93.3164)  time: 0.3491  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [ 600/3750]  eta: 0:18:26  Lr: 0.001875  Loss: -0.3407  Acc@1: 75.0000 (69.3324)  Acc@5: 93.7500 (93.3548)  time: 0.3493  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [ 610/3750]  eta: 0:18:22  Lr: 0.001875  Loss: -0.7478  Acc@1: 75.0000 (69.4149)  Acc@5: 100.0000 (93.3715)  time: 0.3493  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [ 620/3750]  eta: 0:18:19  Lr: 0.001875  Loss: -0.5663  Acc@1: 75.0000 (69.5451)  Acc@5: 93.7500 (93.3977)  time: 0.3499  data: 0.0012  max mem: 2500
Train: Epoch[1/5]  [ 630/3750]  eta: 0:18:15  Lr: 0.001875  Loss: -0.4460  Acc@1: 75.0000 (69.5820)  Acc@5: 93.7500 (93.4330)  time: 0.3514  data: 0.0014  max mem: 2500
Train: Epoch[1/5]  [ 640/3750]  eta: 0:18:12  Lr: 0.001875  Loss: -0.6737  Acc@1: 75.0000 (69.6665)  Acc@5: 93.7500 (93.4965)  time: 0.3508  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [ 650/3750]  eta: 0:18:08  Lr: 0.001875  Loss: -0.7110  Acc@1: 75.0000 (69.7005)  Acc@5: 100.0000 (93.5388)  time: 0.3509  data: 0.0019  max mem: 2500
Train: Epoch[1/5]  [ 660/3750]  eta: 0:18:05  Lr: 0.001875  Loss: -0.8074  Acc@1: 75.0000 (69.8468)  Acc@5: 93.7500 (93.5514)  time: 0.3520  data: 0.0018  max mem: 2500
Train: Epoch[1/5]  [ 670/3750]  eta: 0:18:01  Lr: 0.001875  Loss: -0.7083  Acc@1: 75.0000 (69.8677)  Acc@5: 93.7500 (93.5730)  time: 0.3505  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 680/3750]  eta: 0:17:58  Lr: 0.001875  Loss: -0.4489  Acc@1: 75.0000 (69.9523)  Acc@5: 93.7500 (93.5848)  time: 0.3494  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [ 690/3750]  eta: 0:17:54  Lr: 0.001875  Loss: -0.9464  Acc@1: 81.2500 (70.1067)  Acc@5: 93.7500 (93.6143)  time: 0.3514  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [ 700/3750]  eta: 0:17:51  Lr: 0.001875  Loss: -0.7614  Acc@1: 81.2500 (70.1944)  Acc@5: 93.7500 (93.6430)  time: 0.3523  data: 0.0012  max mem: 2500
Train: Epoch[1/5]  [ 710/3750]  eta: 0:17:47  Lr: 0.001875  Loss: -0.9041  Acc@1: 81.2500 (70.3147)  Acc@5: 93.7500 (93.6445)  time: 0.3510  data: 0.0012  max mem: 2500
Train: Epoch[1/5]  [ 720/3750]  eta: 0:17:44  Lr: 0.001875  Loss: -1.1337  Acc@1: 81.2500 (70.4317)  Acc@5: 93.7500 (93.6980)  time: 0.3504  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 730/3750]  eta: 0:17:40  Lr: 0.001875  Loss: -0.9426  Acc@1: 75.0000 (70.4343)  Acc@5: 93.7500 (93.7073)  time: 0.3516  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [ 740/3750]  eta: 0:17:37  Lr: 0.001875  Loss: -0.5254  Acc@1: 75.0000 (70.5466)  Acc@5: 93.7500 (93.7584)  time: 0.3534  data: 0.0015  max mem: 2500
Train: Epoch[1/5]  [ 750/3750]  eta: 0:17:33  Lr: 0.001875  Loss: -1.0133  Acc@1: 75.0000 (70.5559)  Acc@5: 93.7500 (93.7583)  time: 0.3523  data: 0.0014  max mem: 2500
Train: Epoch[1/5]  [ 760/3750]  eta: 0:17:30  Lr: 0.001875  Loss: -0.9127  Acc@1: 75.0000 (70.6718)  Acc@5: 93.7500 (93.8075)  time: 0.3508  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [ 770/3750]  eta: 0:17:26  Lr: 0.001875  Loss: -0.8359  Acc@1: 75.0000 (70.7117)  Acc@5: 100.0000 (93.8554)  time: 0.3525  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [ 780/3750]  eta: 0:17:23  Lr: 0.001875  Loss: -0.8612  Acc@1: 81.2500 (70.8627)  Acc@5: 100.0000 (93.8940)  time: 0.3535  data: 0.0012  max mem: 2500
Train: Epoch[1/5]  [ 790/3750]  eta: 0:17:19  Lr: 0.001875  Loss: -0.7738  Acc@1: 81.2500 (70.9703)  Acc@5: 100.0000 (93.9080)  time: 0.3518  data: 0.0012  max mem: 2500
Train: Epoch[1/5]  [ 800/3750]  eta: 0:17:16  Lr: 0.001875  Loss: -0.7500  Acc@1: 75.0000 (70.9738)  Acc@5: 93.7500 (93.9061)  time: 0.3517  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [ 810/3750]  eta: 0:17:12  Lr: 0.001875  Loss: -0.7902  Acc@1: 75.0000 (71.0928)  Acc@5: 93.7500 (93.9350)  time: 0.3523  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [ 820/3750]  eta: 0:17:09  Lr: 0.001875  Loss: -0.9304  Acc@1: 81.2500 (71.2241)  Acc@5: 100.0000 (93.9708)  time: 0.3516  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [ 830/3750]  eta: 0:17:05  Lr: 0.001875  Loss: -0.7554  Acc@1: 81.2500 (71.2771)  Acc@5: 100.0000 (94.0057)  time: 0.3516  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 840/3750]  eta: 0:17:02  Lr: 0.001875  Loss: -0.6291  Acc@1: 75.0000 (71.3436)  Acc@5: 100.0000 (94.0324)  time: 0.3539  data: 0.0011  max mem: 2500
Train: Epoch[1/5]  [ 850/3750]  eta: 0:16:59  Lr: 0.001875  Loss: -0.8762  Acc@1: 75.0000 (71.4160)  Acc@5: 93.7500 (94.0511)  time: 0.3553  data: 0.0011  max mem: 2500
Train: Epoch[1/5]  [ 860/3750]  eta: 0:16:55  Lr: 0.001875  Loss: -0.7028  Acc@1: 75.0000 (71.4649)  Acc@5: 100.0000 (94.0984)  time: 0.3532  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [ 870/3750]  eta: 0:16:52  Lr: 0.001875  Loss: -0.7101  Acc@1: 75.0000 (71.4839)  Acc@5: 100.0000 (94.1016)  time: 0.3516  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [ 880/3750]  eta: 0:16:48  Lr: 0.001875  Loss: -0.1183  Acc@1: 75.0000 (71.5451)  Acc@5: 93.7500 (94.1047)  time: 0.3509  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [ 890/3750]  eta: 0:16:45  Lr: 0.001875  Loss: -0.7091  Acc@1: 75.0000 (71.5769)  Acc@5: 93.7500 (94.1148)  time: 0.3509  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [ 900/3750]  eta: 0:16:41  Lr: 0.001875  Loss: -0.8701  Acc@1: 75.0000 (71.6426)  Acc@5: 93.7500 (94.1246)  time: 0.3521  data: 0.0011  max mem: 2500
Train: Epoch[1/5]  [ 910/3750]  eta: 0:16:38  Lr: 0.001875  Loss: -1.0327  Acc@1: 75.0000 (71.6658)  Acc@5: 100.0000 (94.1205)  time: 0.3544  data: 0.0020  max mem: 2500
Train: Epoch[1/5]  [ 920/3750]  eta: 0:16:34  Lr: 0.001875  Loss: -1.1643  Acc@1: 81.2500 (71.7834)  Acc@5: 93.7500 (94.1368)  time: 0.3549  data: 0.0013  max mem: 2500
Train: Epoch[1/5]  [ 930/3750]  eta: 0:16:31  Lr: 0.001875  Loss: -0.5122  Acc@1: 81.2500 (71.8448)  Acc@5: 93.7500 (94.1595)  time: 0.3529  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 940/3750]  eta: 0:16:27  Lr: 0.001875  Loss: -0.5904  Acc@1: 75.0000 (71.8252)  Acc@5: 93.7500 (94.1352)  time: 0.3517  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [ 950/3750]  eta: 0:16:24  Lr: 0.001875  Loss: -0.8905  Acc@1: 75.0000 (71.8717)  Acc@5: 93.7500 (94.1640)  time: 0.3530  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [ 960/3750]  eta: 0:16:20  Lr: 0.001875  Loss: -1.0620  Acc@1: 75.0000 (71.9368)  Acc@5: 100.0000 (94.1662)  time: 0.3526  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [ 970/3750]  eta: 0:16:17  Lr: 0.001875  Loss: -0.9694  Acc@1: 75.0000 (72.0070)  Acc@5: 93.7500 (94.1619)  time: 0.3526  data: 0.0010  max mem: 2500
Train: Epoch[1/5]  [ 980/3750]  eta: 0:16:13  Lr: 0.001875  Loss: -1.0597  Acc@1: 75.0000 (72.0629)  Acc@5: 93.7500 (94.1577)  time: 0.3528  data: 0.0009  max mem: 2500
Train: Epoch[1/5]  [ 990/3750]  eta: 0:16:10  Lr: 0.001875  Loss: -1.1888  Acc@1: 81.2500 (72.1557)  Acc@5: 93.7500 (94.1852)  time: 0.3521  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1000/3750]  eta: 0:16:06  Lr: 0.001875  Loss: -1.0160  Acc@1: 81.2500 (72.2153)  Acc@5: 93.7500 (94.2058)  time: 0.3526  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [1010/3750]  eta: 0:16:03  Lr: 0.001875  Loss: -0.5727  Acc@1: 81.2500 (72.2490)  Acc@5: 100.0000 (94.2446)  time: 0.3522  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [1020/3750]  eta: 0:15:59  Lr: 0.001875  Loss: -1.2770  Acc@1: 75.0000 (72.2821)  Acc@5: 93.7500 (94.2152)  time: 0.3521  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1030/3750]  eta: 0:15:56  Lr: 0.001875  Loss: -0.6602  Acc@1: 68.7500 (72.2721)  Acc@5: 93.7500 (94.2289)  time: 0.3520  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1040/3750]  eta: 0:15:52  Lr: 0.001875  Loss: -0.8469  Acc@1: 75.0000 (72.3343)  Acc@5: 93.7500 (94.2483)  time: 0.3512  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1050/3750]  eta: 0:15:49  Lr: 0.001875  Loss: -1.0876  Acc@1: 81.2500 (72.3537)  Acc@5: 93.7500 (94.2555)  time: 0.3509  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1060/3750]  eta: 0:15:45  Lr: 0.001875  Loss: -1.0675  Acc@1: 81.2500 (72.4258)  Acc@5: 93.7500 (94.2861)  time: 0.3520  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1070/3750]  eta: 0:15:42  Lr: 0.001875  Loss: -1.1953  Acc@1: 75.0000 (72.4732)  Acc@5: 100.0000 (94.3277)  time: 0.3520  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1080/3750]  eta: 0:15:38  Lr: 0.001875  Loss: -0.4773  Acc@1: 75.0000 (72.5197)  Acc@5: 100.0000 (94.3455)  time: 0.3511  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1090/3750]  eta: 0:15:35  Lr: 0.001875  Loss: -0.6695  Acc@1: 81.2500 (72.5825)  Acc@5: 100.0000 (94.3687)  time: 0.3520  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1100/3750]  eta: 0:15:31  Lr: 0.001875  Loss: -1.2388  Acc@1: 75.0000 (72.5988)  Acc@5: 100.0000 (94.3858)  time: 0.3528  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1110/3750]  eta: 0:15:28  Lr: 0.001875  Loss: -0.0722  Acc@1: 75.0000 (72.5923)  Acc@5: 100.0000 (94.3969)  time: 0.3515  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1120/3750]  eta: 0:15:24  Lr: 0.001875  Loss: -0.7594  Acc@1: 75.0000 (72.6193)  Acc@5: 93.7500 (94.3967)  time: 0.3504  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1130/3750]  eta: 0:15:21  Lr: 0.001875  Loss: -0.8889  Acc@1: 75.0000 (72.6569)  Acc@5: 93.7500 (94.4021)  time: 0.3496  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1140/3750]  eta: 0:15:17  Lr: 0.001875  Loss: -0.8639  Acc@1: 81.2500 (72.6994)  Acc@5: 93.7500 (94.4238)  time: 0.3493  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1150/3750]  eta: 0:15:14  Lr: 0.001875  Loss: -0.6949  Acc@1: 81.2500 (72.7520)  Acc@5: 93.7500 (94.4450)  time: 0.3507  data: 0.0011  max mem: 2500
Train: Epoch[1/5]  [1160/3750]  eta: 0:15:10  Lr: 0.001875  Loss: -0.9543  Acc@1: 75.0000 (72.8198)  Acc@5: 93.7500 (94.4498)  time: 0.3524  data: 0.0022  max mem: 2500
Train: Epoch[1/5]  [1170/3750]  eta: 0:15:06  Lr: 0.001875  Loss: -0.9519  Acc@1: 75.0000 (72.8384)  Acc@5: 93.7500 (94.4599)  time: 0.3513  data: 0.0015  max mem: 2500
Train: Epoch[1/5]  [1180/3750]  eta: 0:15:03  Lr: 0.001875  Loss: -0.9964  Acc@1: 75.0000 (72.8990)  Acc@5: 93.7500 (94.4644)  time: 0.3533  data: 0.0039  max mem: 2500
Train: Epoch[1/5]  [1190/3750]  eta: 0:15:00  Lr: 0.001875  Loss: -0.4438  Acc@1: 75.0000 (72.9324)  Acc@5: 100.0000 (94.4899)  time: 0.3555  data: 0.0039  max mem: 2500
Train: Epoch[1/5]  [1200/3750]  eta: 0:14:56  Lr: 0.001875  Loss: -0.9979  Acc@1: 75.0000 (72.9861)  Acc@5: 100.0000 (94.5150)  time: 0.3516  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1210/3750]  eta: 0:14:53  Lr: 0.001875  Loss: -0.4389  Acc@1: 75.0000 (73.0027)  Acc@5: 93.7500 (94.5087)  time: 0.3499  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1220/3750]  eta: 0:14:49  Lr: 0.001875  Loss: -0.7405  Acc@1: 75.0000 (73.0498)  Acc@5: 93.7500 (94.5127)  time: 0.3506  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1230/3750]  eta: 0:14:45  Lr: 0.001875  Loss: -0.7431  Acc@1: 81.2500 (73.1062)  Acc@5: 93.7500 (94.5014)  time: 0.3517  data: 0.0012  max mem: 2500
Train: Epoch[1/5]  [1240/3750]  eta: 0:14:42  Lr: 0.001875  Loss: -1.0641  Acc@1: 81.2500 (73.1769)  Acc@5: 93.7500 (94.5004)  time: 0.3526  data: 0.0012  max mem: 2500
Train: Epoch[1/5]  [1250/3750]  eta: 0:14:38  Lr: 0.001875  Loss: -0.7759  Acc@1: 75.0000 (73.1865)  Acc@5: 93.7500 (94.4844)  time: 0.3515  data: 0.0016  max mem: 2500
Train: Epoch[1/5]  [1260/3750]  eta: 0:14:35  Lr: 0.001875  Loss: -0.7437  Acc@1: 75.0000 (73.2405)  Acc@5: 93.7500 (94.4885)  time: 0.3509  data: 0.0022  max mem: 2500
Train: Epoch[1/5]  [1270/3750]  eta: 0:14:31  Lr: 0.001875  Loss: -0.8453  Acc@1: 81.2500 (73.3035)  Acc@5: 93.7500 (94.4827)  time: 0.3502  data: 0.0010  max mem: 2500
Train: Epoch[1/5]  [1280/3750]  eta: 0:14:28  Lr: 0.001875  Loss: -0.7576  Acc@1: 81.2500 (73.3265)  Acc@5: 100.0000 (94.5160)  time: 0.3499  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1290/3750]  eta: 0:14:24  Lr: 0.001875  Loss: -0.7261  Acc@1: 81.2500 (73.4072)  Acc@5: 100.0000 (94.5440)  time: 0.3499  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1300/3750]  eta: 0:14:21  Lr: 0.001875  Loss: -0.8342  Acc@1: 81.2500 (73.4675)  Acc@5: 100.0000 (94.5475)  time: 0.3494  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [1310/3750]  eta: 0:14:17  Lr: 0.001875  Loss: -1.1151  Acc@1: 81.2500 (73.5269)  Acc@5: 93.7500 (94.5509)  time: 0.3500  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [1320/3750]  eta: 0:14:14  Lr: 0.001875  Loss: -0.5783  Acc@1: 75.0000 (73.5570)  Acc@5: 93.7500 (94.5449)  time: 0.3516  data: 0.0011  max mem: 2500
Train: Epoch[1/5]  [1330/3750]  eta: 0:14:10  Lr: 0.001875  Loss: -1.0295  Acc@1: 75.0000 (73.5490)  Acc@5: 93.7500 (94.5389)  time: 0.3518  data: 0.0010  max mem: 2500
Train: Epoch[1/5]  [1340/3750]  eta: 0:14:07  Lr: 0.001875  Loss: -1.0762  Acc@1: 75.0000 (73.5831)  Acc@5: 93.7500 (94.5470)  time: 0.3499  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1350/3750]  eta: 0:14:03  Lr: 0.001875  Loss: -0.8427  Acc@1: 81.2500 (73.6306)  Acc@5: 93.7500 (94.5688)  time: 0.3496  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1360/3750]  eta: 0:14:00  Lr: 0.001875  Loss: -0.5056  Acc@1: 75.0000 (73.6361)  Acc@5: 93.7500 (94.5674)  time: 0.3499  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [1370/3750]  eta: 0:13:56  Lr: 0.001875  Loss: -0.9325  Acc@1: 75.0000 (73.6780)  Acc@5: 93.7500 (94.5751)  time: 0.3496  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [1380/3750]  eta: 0:13:52  Lr: 0.001875  Loss: -0.5278  Acc@1: 75.0000 (73.6785)  Acc@5: 93.7500 (94.5827)  time: 0.3498  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [1390/3750]  eta: 0:13:49  Lr: 0.001875  Loss: -0.8607  Acc@1: 75.0000 (73.6925)  Acc@5: 93.7500 (94.5812)  time: 0.3497  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [1400/3750]  eta: 0:13:45  Lr: 0.001875  Loss: -1.1147  Acc@1: 75.0000 (73.7554)  Acc@5: 93.7500 (94.5931)  time: 0.3498  data: 0.0011  max mem: 2500
Train: Epoch[1/5]  [1410/3750]  eta: 0:13:42  Lr: 0.001875  Loss: -0.6097  Acc@1: 81.2500 (73.7686)  Acc@5: 93.7500 (94.5872)  time: 0.3509  data: 0.0011  max mem: 2500
Train: Epoch[1/5]  [1420/3750]  eta: 0:13:38  Lr: 0.001875  Loss: -0.6080  Acc@1: 81.2500 (73.8257)  Acc@5: 93.7500 (94.6077)  time: 0.3518  data: 0.0022  max mem: 2500
Train: Epoch[1/5]  [1430/3750]  eta: 0:13:35  Lr: 0.001875  Loss: -0.6831  Acc@1: 81.2500 (73.8382)  Acc@5: 93.7500 (94.6060)  time: 0.3501  data: 0.0021  max mem: 2500
Train: Epoch[1/5]  [1440/3750]  eta: 0:13:31  Lr: 0.001875  Loss: -0.5738  Acc@1: 81.2500 (73.9070)  Acc@5: 100.0000 (94.6348)  time: 0.3482  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1450/3750]  eta: 0:13:28  Lr: 0.001875  Loss: -1.1222  Acc@1: 81.2500 (73.9447)  Acc@5: 100.0000 (94.6502)  time: 0.3489  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1460/3750]  eta: 0:13:24  Lr: 0.001875  Loss: -0.8926  Acc@1: 81.2500 (73.9733)  Acc@5: 100.0000 (94.6526)  time: 0.3496  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1470/3750]  eta: 0:13:21  Lr: 0.001875  Loss: -1.4172  Acc@1: 81.2500 (74.0270)  Acc@5: 93.7500 (94.6592)  time: 0.3496  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1480/3750]  eta: 0:13:17  Lr: 0.001875  Loss: -0.8872  Acc@1: 81.2500 (74.0716)  Acc@5: 93.7500 (94.6658)  time: 0.3503  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1490/3750]  eta: 0:13:13  Lr: 0.001875  Loss: -0.7712  Acc@1: 81.2500 (74.1113)  Acc@5: 100.0000 (94.6722)  time: 0.3494  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [1500/3750]  eta: 0:13:10  Lr: 0.001875  Loss: -0.5567  Acc@1: 81.2500 (74.1422)  Acc@5: 93.7500 (94.6661)  time: 0.3476  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [1510/3750]  eta: 0:13:06  Lr: 0.001875  Loss: -1.0576  Acc@1: 75.0000 (74.1231)  Acc@5: 100.0000 (94.6765)  time: 0.3484  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [1520/3750]  eta: 0:13:03  Lr: 0.001875  Loss: -1.1651  Acc@1: 75.0000 (74.1330)  Acc@5: 93.7500 (94.6540)  time: 0.3486  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [1530/3750]  eta: 0:12:59  Lr: 0.001875  Loss: -0.9284  Acc@1: 81.2500 (74.1876)  Acc@5: 93.7500 (94.6685)  time: 0.3480  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1540/3750]  eta: 0:12:56  Lr: 0.001875  Loss: -1.0666  Acc@1: 81.2500 (74.2091)  Acc@5: 100.0000 (94.6788)  time: 0.3476  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [1550/3750]  eta: 0:12:52  Lr: 0.001875  Loss: -0.9220  Acc@1: 81.2500 (74.2545)  Acc@5: 93.7500 (94.6929)  time: 0.3491  data: 0.0010  max mem: 2500
Train: Epoch[1/5]  [1560/3750]  eta: 0:12:49  Lr: 0.001875  Loss: -0.9182  Acc@1: 81.2500 (74.3113)  Acc@5: 100.0000 (94.6989)  time: 0.3503  data: 0.0014  max mem: 2500
Train: Epoch[1/5]  [1570/3750]  eta: 0:12:45  Lr: 0.001875  Loss: -1.0912  Acc@1: 81.2500 (74.3396)  Acc@5: 100.0000 (94.6968)  time: 0.3484  data: 0.0011  max mem: 2500
Train: Epoch[1/5]  [1580/3750]  eta: 0:12:41  Lr: 0.001875  Loss: -1.1704  Acc@1: 81.2500 (74.3517)  Acc@5: 100.0000 (94.7106)  time: 0.3475  data: 0.0009  max mem: 2500
Train: Epoch[1/5]  [1590/3750]  eta: 0:12:38  Lr: 0.001875  Loss: -1.1808  Acc@1: 81.2500 (74.4068)  Acc@5: 100.0000 (94.7203)  time: 0.3488  data: 0.0019  max mem: 2500
Train: Epoch[1/5]  [1600/3750]  eta: 0:12:35  Lr: 0.001875  Loss: -0.7355  Acc@1: 75.0000 (74.3949)  Acc@5: 93.7500 (94.7181)  time: 0.3523  data: 0.0023  max mem: 2500
Train: Epoch[1/5]  [1610/3750]  eta: 0:12:31  Lr: 0.001875  Loss: -0.9282  Acc@1: 75.0000 (74.4258)  Acc@5: 93.7500 (94.7315)  time: 0.3524  data: 0.0022  max mem: 2500
Train: Epoch[1/5]  [1620/3750]  eta: 0:12:27  Lr: 0.001875  Loss: -1.0931  Acc@1: 75.0000 (74.4217)  Acc@5: 93.7500 (94.7101)  time: 0.3490  data: 0.0016  max mem: 2500
Train: Epoch[1/5]  [1630/3750]  eta: 0:12:24  Lr: 0.001875  Loss: -0.2408  Acc@1: 75.0000 (74.4559)  Acc@5: 93.7500 (94.7118)  time: 0.3480  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1640/3750]  eta: 0:12:20  Lr: 0.001875  Loss: -0.3738  Acc@1: 75.0000 (74.4668)  Acc@5: 93.7500 (94.7174)  time: 0.3480  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1650/3750]  eta: 0:12:17  Lr: 0.001875  Loss: -1.0024  Acc@1: 75.0000 (74.4814)  Acc@5: 93.7500 (94.7115)  time: 0.3481  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1660/3750]  eta: 0:12:13  Lr: 0.001875  Loss: -0.6668  Acc@1: 75.0000 (74.4732)  Acc@5: 93.7500 (94.7170)  time: 0.3499  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1670/3750]  eta: 0:12:10  Lr: 0.001875  Loss: -0.6838  Acc@1: 81.2500 (74.5325)  Acc@5: 100.0000 (94.7412)  time: 0.3506  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [1680/3750]  eta: 0:12:06  Lr: 0.001875  Loss: -1.1247  Acc@1: 81.2500 (74.5687)  Acc@5: 100.0000 (94.7539)  time: 0.3496  data: 0.0011  max mem: 2500
Train: Epoch[1/5]  [1690/3750]  eta: 0:12:03  Lr: 0.001875  Loss: -0.9214  Acc@1: 75.0000 (74.5750)  Acc@5: 100.0000 (94.7442)  time: 0.3489  data: 0.0011  max mem: 2500
Train: Epoch[1/5]  [1700/3750]  eta: 0:11:59  Lr: 0.001875  Loss: -0.9167  Acc@1: 81.2500 (74.6105)  Acc@5: 93.7500 (94.7604)  time: 0.3497  data: 0.0013  max mem: 2500
Train: Epoch[1/5]  [1710/3750]  eta: 0:11:56  Lr: 0.001875  Loss: -1.0326  Acc@1: 81.2500 (74.6493)  Acc@5: 100.0000 (94.7691)  time: 0.3494  data: 0.0012  max mem: 2500
Train: Epoch[1/5]  [1720/3750]  eta: 0:11:52  Lr: 0.001875  Loss: -0.5936  Acc@1: 81.2500 (74.6659)  Acc@5: 93.7500 (94.7669)  time: 0.3487  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1730/3750]  eta: 0:11:49  Lr: 0.001875  Loss: -0.7389  Acc@1: 75.0000 (74.6714)  Acc@5: 93.7500 (94.7574)  time: 0.3489  data: 0.0009  max mem: 2500
Train: Epoch[1/5]  [1740/3750]  eta: 0:11:45  Lr: 0.001875  Loss: -1.1061  Acc@1: 75.0000 (74.6841)  Acc@5: 93.7500 (94.7731)  time: 0.3484  data: 0.0009  max mem: 2500
Train: Epoch[1/5]  [1750/3750]  eta: 0:11:41  Lr: 0.001875  Loss: -0.2982  Acc@1: 75.0000 (74.6895)  Acc@5: 93.7500 (94.7708)  time: 0.3490  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1760/3750]  eta: 0:11:38  Lr: 0.001875  Loss: -0.8194  Acc@1: 81.2500 (74.7338)  Acc@5: 93.7500 (94.7792)  time: 0.3488  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [1770/3750]  eta: 0:11:34  Lr: 0.001875  Loss: -1.1313  Acc@1: 81.2500 (74.7847)  Acc@5: 100.0000 (94.7981)  time: 0.3484  data: 0.0010  max mem: 2500
Train: Epoch[1/5]  [1780/3750]  eta: 0:11:31  Lr: 0.001875  Loss: -0.8739  Acc@1: 81.2500 (74.8070)  Acc@5: 100.0000 (94.8133)  time: 0.3496  data: 0.0010  max mem: 2500
Train: Epoch[1/5]  [1790/3750]  eta: 0:11:27  Lr: 0.001875  Loss: -1.1334  Acc@1: 81.2500 (74.8290)  Acc@5: 100.0000 (94.8109)  time: 0.3490  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [1800/3750]  eta: 0:11:24  Lr: 0.001875  Loss: -1.1287  Acc@1: 75.0000 (74.8334)  Acc@5: 93.7500 (94.8258)  time: 0.3487  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [1810/3750]  eta: 0:11:20  Lr: 0.001875  Loss: -0.7731  Acc@1: 75.0000 (74.8516)  Acc@5: 100.0000 (94.8302)  time: 0.3502  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [1820/3750]  eta: 0:11:17  Lr: 0.001875  Loss: -1.0035  Acc@1: 75.0000 (74.8661)  Acc@5: 100.0000 (94.8346)  time: 0.3503  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [1830/3750]  eta: 0:11:13  Lr: 0.001875  Loss: -0.5336  Acc@1: 75.0000 (74.8874)  Acc@5: 100.0000 (94.8457)  time: 0.3504  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1840/3750]  eta: 0:11:10  Lr: 0.001875  Loss: -0.8669  Acc@1: 75.0000 (74.9015)  Acc@5: 100.0000 (94.8533)  time: 0.3502  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1850/3750]  eta: 0:11:06  Lr: 0.001875  Loss: -0.8939  Acc@1: 75.0000 (74.9156)  Acc@5: 100.0000 (94.8643)  time: 0.3505  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1860/3750]  eta: 0:11:03  Lr: 0.001875  Loss: -1.1640  Acc@1: 81.2500 (74.9496)  Acc@5: 100.0000 (94.8818)  time: 0.3496  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [1870/3750]  eta: 0:10:59  Lr: 0.001875  Loss: -0.8949  Acc@1: 75.0000 (74.9365)  Acc@5: 100.0000 (94.8791)  time: 0.3488  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [1880/3750]  eta: 0:10:56  Lr: 0.001875  Loss: -1.0147  Acc@1: 75.0000 (74.9767)  Acc@5: 93.7500 (94.8930)  time: 0.3519  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [1890/3750]  eta: 0:10:52  Lr: 0.001875  Loss: -0.9147  Acc@1: 81.2500 (75.0099)  Acc@5: 100.0000 (94.8969)  time: 0.3528  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1900/3750]  eta: 0:10:49  Lr: 0.001875  Loss: -0.9060  Acc@1: 81.2500 (75.0329)  Acc@5: 93.7500 (94.9073)  time: 0.3499  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [1910/3750]  eta: 0:10:45  Lr: 0.001875  Loss: -1.0969  Acc@1: 81.2500 (75.0687)  Acc@5: 93.7500 (94.9143)  time: 0.3497  data: 0.0010  max mem: 2500
Train: Epoch[1/5]  [1920/3750]  eta: 0:10:42  Lr: 0.001875  Loss: -0.7366  Acc@1: 75.0000 (75.0846)  Acc@5: 93.7500 (94.9180)  time: 0.3509  data: 0.0011  max mem: 2500
Train: Epoch[1/5]  [1930/3750]  eta: 0:10:38  Lr: 0.001875  Loss: -0.5847  Acc@1: 75.0000 (75.1230)  Acc@5: 93.7500 (94.9249)  time: 0.3513  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [1940/3750]  eta: 0:10:35  Lr: 0.001875  Loss: -1.4188  Acc@1: 81.2500 (75.1481)  Acc@5: 93.7500 (94.9221)  time: 0.3499  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1950/3750]  eta: 0:10:31  Lr: 0.001875  Loss: -0.8367  Acc@1: 81.2500 (75.1666)  Acc@5: 100.0000 (94.9289)  time: 0.3488  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [1960/3750]  eta: 0:10:28  Lr: 0.001875  Loss: -1.2804  Acc@1: 81.2500 (75.2167)  Acc@5: 100.0000 (94.9484)  time: 0.3506  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [1970/3750]  eta: 0:10:24  Lr: 0.001875  Loss: -1.1802  Acc@1: 81.2500 (75.2505)  Acc@5: 100.0000 (94.9550)  time: 0.3515  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [1980/3750]  eta: 0:10:21  Lr: 0.001875  Loss: -1.0008  Acc@1: 81.2500 (75.2903)  Acc@5: 100.0000 (94.9647)  time: 0.3500  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [1990/3750]  eta: 0:10:17  Lr: 0.001875  Loss: -0.7525  Acc@1: 81.2500 (75.2951)  Acc@5: 93.7500 (94.9680)  time: 0.3497  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2000/3750]  eta: 0:10:14  Lr: 0.001875  Loss: -1.2401  Acc@1: 75.0000 (75.3155)  Acc@5: 93.7500 (94.9806)  time: 0.3486  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2010/3750]  eta: 0:10:10  Lr: 0.001875  Loss: -0.8271  Acc@1: 75.0000 (75.3046)  Acc@5: 93.7500 (94.9807)  time: 0.3479  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [2020/3750]  eta: 0:10:06  Lr: 0.001875  Loss: -0.6898  Acc@1: 75.0000 (75.3062)  Acc@5: 93.7500 (94.9777)  time: 0.3487  data: 0.0009  max mem: 2500
Train: Epoch[1/5]  [2030/3750]  eta: 0:10:03  Lr: 0.001875  Loss: -1.0605  Acc@1: 75.0000 (75.3170)  Acc@5: 93.7500 (94.9871)  time: 0.3485  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [2040/3750]  eta: 0:09:59  Lr: 0.001875  Loss: -1.0596  Acc@1: 81.2500 (75.3491)  Acc@5: 100.0000 (95.0024)  time: 0.3480  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2050/3750]  eta: 0:09:56  Lr: 0.001875  Loss: -0.9562  Acc@1: 81.2500 (75.3718)  Acc@5: 100.0000 (95.0116)  time: 0.3480  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2060/3750]  eta: 0:09:52  Lr: 0.001875  Loss: -0.7032  Acc@1: 81.2500 (75.3821)  Acc@5: 100.0000 (95.0146)  time: 0.3487  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2070/3750]  eta: 0:09:49  Lr: 0.001875  Loss: -0.8037  Acc@1: 75.0000 (75.4195)  Acc@5: 100.0000 (95.0326)  time: 0.3484  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2080/3750]  eta: 0:09:45  Lr: 0.001875  Loss: -1.0801  Acc@1: 75.0000 (75.4235)  Acc@5: 100.0000 (95.0354)  time: 0.3490  data: 0.0014  max mem: 2500
Train: Epoch[1/5]  [2090/3750]  eta: 0:09:42  Lr: 0.001875  Loss: -1.0410  Acc@1: 75.0000 (75.4364)  Acc@5: 93.7500 (95.0442)  time: 0.3492  data: 0.0014  max mem: 2500
Train: Epoch[1/5]  [2100/3750]  eta: 0:09:38  Lr: 0.001875  Loss: -1.4406  Acc@1: 75.0000 (75.4403)  Acc@5: 93.7500 (95.0411)  time: 0.3480  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2110/3750]  eta: 0:09:35  Lr: 0.001875  Loss: -0.9023  Acc@1: 75.0000 (75.4471)  Acc@5: 93.7500 (95.0468)  time: 0.3480  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [2120/3750]  eta: 0:09:31  Lr: 0.001875  Loss: -0.9101  Acc@1: 81.2500 (75.4921)  Acc@5: 100.0000 (95.0554)  time: 0.3491  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2130/3750]  eta: 0:09:28  Lr: 0.001875  Loss: -1.1212  Acc@1: 87.5000 (75.5133)  Acc@5: 100.0000 (95.0610)  time: 0.3506  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [2140/3750]  eta: 0:09:24  Lr: 0.001875  Loss: -0.9428  Acc@1: 81.2500 (75.5313)  Acc@5: 93.7500 (95.0636)  time: 0.3507  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [2150/3750]  eta: 0:09:21  Lr: 0.001875  Loss: -1.2312  Acc@1: 81.2500 (75.5550)  Acc@5: 100.0000 (95.0721)  time: 0.3493  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2160/3750]  eta: 0:09:17  Lr: 0.001875  Loss: -0.8414  Acc@1: 81.2500 (75.5900)  Acc@5: 100.0000 (95.0775)  time: 0.3482  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2170/3750]  eta: 0:09:14  Lr: 0.001875  Loss: -0.8088  Acc@1: 81.2500 (75.6132)  Acc@5: 100.0000 (95.0772)  time: 0.3494  data: 0.0017  max mem: 2500
Train: Epoch[1/5]  [2180/3750]  eta: 0:09:10  Lr: 0.001875  Loss: -0.5510  Acc@1: 81.2500 (75.6190)  Acc@5: 100.0000 (95.0911)  time: 0.3500  data: 0.0017  max mem: 2500
Train: Epoch[1/5]  [2190/3750]  eta: 0:09:07  Lr: 0.001875  Loss: -0.4466  Acc@1: 75.0000 (75.6047)  Acc@5: 93.7500 (95.0879)  time: 0.3502  data: 0.0012  max mem: 2500
Train: Epoch[1/5]  [2200/3750]  eta: 0:09:03  Lr: 0.001875  Loss: -0.6295  Acc@1: 75.0000 (75.6162)  Acc@5: 93.7500 (95.0875)  time: 0.3503  data: 0.0013  max mem: 2500
Train: Epoch[1/5]  [2210/3750]  eta: 0:09:00  Lr: 0.001875  Loss: -0.8678  Acc@1: 81.2500 (75.6332)  Acc@5: 100.0000 (95.0955)  time: 0.3488  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2220/3750]  eta: 0:08:56  Lr: 0.001875  Loss: -0.8518  Acc@1: 81.2500 (75.6697)  Acc@5: 100.0000 (95.1064)  time: 0.3480  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2230/3750]  eta: 0:08:53  Lr: 0.001875  Loss: -0.7069  Acc@1: 81.2500 (75.6835)  Acc@5: 100.0000 (95.1115)  time: 0.3489  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2240/3750]  eta: 0:08:49  Lr: 0.001875  Loss: -0.5392  Acc@1: 75.0000 (75.7000)  Acc@5: 100.0000 (95.1082)  time: 0.3502  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2250/3750]  eta: 0:08:45  Lr: 0.001875  Loss: -0.8190  Acc@1: 75.0000 (75.7136)  Acc@5: 93.7500 (95.1161)  time: 0.3503  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2260/3750]  eta: 0:08:42  Lr: 0.001875  Loss: -1.3705  Acc@1: 81.2500 (75.7464)  Acc@5: 100.0000 (95.1266)  time: 0.3495  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2270/3750]  eta: 0:08:38  Lr: 0.001875  Loss: -0.9121  Acc@1: 81.2500 (75.7651)  Acc@5: 100.0000 (95.1371)  time: 0.3503  data: 0.0013  max mem: 2500
Train: Epoch[1/5]  [2280/3750]  eta: 0:08:35  Lr: 0.001875  Loss: -0.8956  Acc@1: 81.2500 (75.7891)  Acc@5: 100.0000 (95.1474)  time: 0.3499  data: 0.0013  max mem: 2500
Train: Epoch[1/5]  [2290/3750]  eta: 0:08:31  Lr: 0.001875  Loss: -0.8380  Acc@1: 75.0000 (75.8048)  Acc@5: 100.0000 (95.1522)  time: 0.3489  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2300/3750]  eta: 0:08:28  Lr: 0.001875  Loss: -0.3065  Acc@1: 81.2500 (75.8203)  Acc@5: 93.7500 (95.1434)  time: 0.3490  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [2310/3750]  eta: 0:08:24  Lr: 0.001875  Loss: -1.1325  Acc@1: 81.2500 (75.8438)  Acc@5: 93.7500 (95.1401)  time: 0.3480  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [2320/3750]  eta: 0:08:21  Lr: 0.001875  Loss: -1.0873  Acc@1: 87.5000 (75.8832)  Acc@5: 93.7500 (95.1476)  time: 0.3479  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [2330/3750]  eta: 0:08:17  Lr: 0.001875  Loss: -1.2954  Acc@1: 87.5000 (75.8982)  Acc@5: 93.7500 (95.1469)  time: 0.3481  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2340/3750]  eta: 0:08:14  Lr: 0.001875  Loss: -0.8267  Acc@1: 81.2500 (75.9024)  Acc@5: 93.7500 (95.1570)  time: 0.3491  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2350/3750]  eta: 0:08:10  Lr: 0.001875  Loss: -1.0182  Acc@1: 75.0000 (75.9278)  Acc@5: 100.0000 (95.1749)  time: 0.3501  data: 0.0003  max mem: 2500
Train: Epoch[1/5]  [2360/3750]  eta: 0:08:07  Lr: 0.001875  Loss: -1.1753  Acc@1: 81.2500 (75.9450)  Acc@5: 100.0000 (95.1742)  time: 0.3492  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2370/3750]  eta: 0:08:03  Lr: 0.001875  Loss: -0.4109  Acc@1: 81.2500 (75.9727)  Acc@5: 93.7500 (95.1761)  time: 0.3492  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [2380/3750]  eta: 0:08:00  Lr: 0.001875  Loss: -1.3564  Acc@1: 81.2500 (75.9896)  Acc@5: 100.0000 (95.1885)  time: 0.3503  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [2390/3750]  eta: 0:07:56  Lr: 0.001875  Loss: -0.7088  Acc@1: 81.2500 (76.0116)  Acc@5: 100.0000 (95.1981)  time: 0.3496  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2400/3750]  eta: 0:07:53  Lr: 0.001875  Loss: -1.2021  Acc@1: 81.2500 (76.0152)  Acc@5: 100.0000 (95.2103)  time: 0.3486  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2410/3750]  eta: 0:07:49  Lr: 0.001875  Loss: -1.2110  Acc@1: 81.2500 (76.0447)  Acc@5: 100.0000 (95.2198)  time: 0.3490  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2420/3750]  eta: 0:07:46  Lr: 0.001875  Loss: -0.5680  Acc@1: 81.2500 (76.0739)  Acc@5: 100.0000 (95.2292)  time: 0.3499  data: 0.0012  max mem: 2500
Train: Epoch[1/5]  [2430/3750]  eta: 0:07:42  Lr: 0.001875  Loss: -0.9321  Acc@1: 87.5000 (76.1158)  Acc@5: 100.0000 (95.2412)  time: 0.3498  data: 0.0012  max mem: 2500
Train: Epoch[1/5]  [2440/3750]  eta: 0:07:39  Lr: 0.001875  Loss: -1.0174  Acc@1: 87.5000 (76.1522)  Acc@5: 100.0000 (95.2376)  time: 0.3496  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2450/3750]  eta: 0:07:35  Lr: 0.001875  Loss: -1.2859  Acc@1: 81.2500 (76.1602)  Acc@5: 93.7500 (95.2366)  time: 0.3496  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2460/3750]  eta: 0:07:32  Lr: 0.001875  Loss: -0.7820  Acc@1: 81.2500 (76.1911)  Acc@5: 93.7500 (95.2331)  time: 0.3497  data: 0.0010  max mem: 2500
Train: Epoch[1/5]  [2470/3750]  eta: 0:07:28  Lr: 0.001875  Loss: -1.0212  Acc@1: 81.2500 (76.2141)  Acc@5: 93.7500 (95.2398)  time: 0.3501  data: 0.0017  max mem: 2500
Train: Epoch[1/5]  [2480/3750]  eta: 0:07:25  Lr: 0.001875  Loss: -1.0099  Acc@1: 81.2500 (76.2268)  Acc@5: 93.7500 (95.2464)  time: 0.3520  data: 0.0013  max mem: 2500
Train: Epoch[1/5]  [2490/3750]  eta: 0:07:21  Lr: 0.001875  Loss: -1.1446  Acc@1: 81.2500 (76.2395)  Acc@5: 93.7500 (95.2504)  time: 0.3520  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [2500/3750]  eta: 0:07:18  Lr: 0.001875  Loss: -0.8874  Acc@1: 81.2500 (76.2495)  Acc@5: 100.0000 (95.2569)  time: 0.3498  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [2510/3750]  eta: 0:07:14  Lr: 0.001875  Loss: -0.9839  Acc@1: 81.2500 (76.2819)  Acc@5: 93.7500 (95.2559)  time: 0.3497  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [2520/3750]  eta: 0:07:11  Lr: 0.001875  Loss: -1.1599  Acc@1: 81.2500 (76.2892)  Acc@5: 93.7500 (95.2474)  time: 0.3500  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2530/3750]  eta: 0:07:07  Lr: 0.001875  Loss: -0.5107  Acc@1: 75.0000 (76.3112)  Acc@5: 93.7500 (95.2514)  time: 0.3503  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2540/3750]  eta: 0:07:04  Lr: 0.001875  Loss: -0.7409  Acc@1: 81.2500 (76.3331)  Acc@5: 100.0000 (95.2529)  time: 0.3501  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2550/3750]  eta: 0:07:00  Lr: 0.001875  Loss: -0.5621  Acc@1: 81.2500 (76.3524)  Acc@5: 93.7500 (95.2568)  time: 0.3499  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2560/3750]  eta: 0:06:57  Lr: 0.001875  Loss: -0.8967  Acc@1: 75.0000 (76.3520)  Acc@5: 93.7500 (95.2460)  time: 0.3495  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2570/3750]  eta: 0:06:53  Lr: 0.001875  Loss: -0.8219  Acc@1: 75.0000 (76.3443)  Acc@5: 93.7500 (95.2499)  time: 0.3499  data: 0.0009  max mem: 2500
Train: Epoch[1/5]  [2580/3750]  eta: 0:06:50  Lr: 0.001875  Loss: -1.0127  Acc@1: 75.0000 (76.3464)  Acc@5: 100.0000 (95.2562)  time: 0.3504  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [2590/3750]  eta: 0:06:46  Lr: 0.001875  Loss: -0.9070  Acc@1: 81.2500 (76.3677)  Acc@5: 100.0000 (95.2576)  time: 0.3498  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2600/3750]  eta: 0:06:43  Lr: 0.001875  Loss: -0.9771  Acc@1: 81.2500 (76.3865)  Acc@5: 100.0000 (95.2662)  time: 0.3494  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2610/3750]  eta: 0:06:39  Lr: 0.001875  Loss: -0.9428  Acc@1: 81.2500 (76.3908)  Acc@5: 100.0000 (95.2628)  time: 0.3491  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2620/3750]  eta: 0:06:36  Lr: 0.001875  Loss: -1.1960  Acc@1: 75.0000 (76.3926)  Acc@5: 100.0000 (95.2761)  time: 0.3499  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2630/3750]  eta: 0:06:32  Lr: 0.001875  Loss: -0.4366  Acc@1: 81.2500 (76.4182)  Acc@5: 100.0000 (95.2798)  time: 0.3499  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [2640/3750]  eta: 0:06:29  Lr: 0.001875  Loss: -0.7547  Acc@1: 87.5000 (76.4459)  Acc@5: 93.7500 (95.2811)  time: 0.3482  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [2650/3750]  eta: 0:06:25  Lr: 0.001875  Loss: -1.2282  Acc@1: 87.5000 (76.4617)  Acc@5: 93.7500 (95.2848)  time: 0.3489  data: 0.0015  max mem: 2500
Train: Epoch[1/5]  [2660/3750]  eta: 0:06:22  Lr: 0.001875  Loss: -1.2639  Acc@1: 81.2500 (76.4797)  Acc@5: 100.0000 (95.2908)  time: 0.3500  data: 0.0015  max mem: 2500
Train: Epoch[1/5]  [2670/3750]  eta: 0:06:18  Lr: 0.001875  Loss: -0.9319  Acc@1: 81.2500 (76.4788)  Acc@5: 100.0000 (95.2967)  time: 0.3484  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2680/3750]  eta: 0:06:15  Lr: 0.001875  Loss: -0.9348  Acc@1: 75.0000 (76.4896)  Acc@5: 100.0000 (95.3073)  time: 0.3481  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2690/3750]  eta: 0:06:11  Lr: 0.001875  Loss: -1.1015  Acc@1: 81.2500 (76.4957)  Acc@5: 100.0000 (95.3084)  time: 0.3486  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [2700/3750]  eta: 0:06:07  Lr: 0.001875  Loss: -1.0254  Acc@1: 81.2500 (76.5180)  Acc@5: 93.7500 (95.3096)  time: 0.3481  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [2710/3750]  eta: 0:06:04  Lr: 0.001875  Loss: -0.9838  Acc@1: 81.2500 (76.5400)  Acc@5: 93.7500 (95.3131)  time: 0.3482  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2720/3750]  eta: 0:06:00  Lr: 0.001875  Loss: -1.2355  Acc@1: 81.2500 (76.5619)  Acc@5: 100.0000 (95.3257)  time: 0.3492  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2730/3750]  eta: 0:05:57  Lr: 0.001875  Loss: -0.5735  Acc@1: 81.2500 (76.5928)  Acc@5: 100.0000 (95.3360)  time: 0.3499  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [2740/3750]  eta: 0:05:53  Lr: 0.001875  Loss: -1.4424  Acc@1: 81.2500 (76.5916)  Acc@5: 100.0000 (95.3347)  time: 0.3486  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [2750/3750]  eta: 0:05:50  Lr: 0.001875  Loss: -1.2892  Acc@1: 81.2500 (76.6335)  Acc@5: 93.7500 (95.3381)  time: 0.3492  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2760/3750]  eta: 0:05:46  Lr: 0.001875  Loss: -0.7881  Acc@1: 87.5000 (76.6457)  Acc@5: 100.0000 (95.3482)  time: 0.3525  data: 0.0013  max mem: 2500
Train: Epoch[1/5]  [2770/3750]  eta: 0:05:43  Lr: 0.001875  Loss: -0.8863  Acc@1: 81.2500 (76.6578)  Acc@5: 100.0000 (95.3537)  time: 0.3516  data: 0.0014  max mem: 2500
Train: Epoch[1/5]  [2780/3750]  eta: 0:05:39  Lr: 0.001875  Loss: -1.1171  Acc@1: 81.2500 (76.6743)  Acc@5: 100.0000 (95.3614)  time: 0.3488  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [2790/3750]  eta: 0:05:36  Lr: 0.001875  Loss: -0.8455  Acc@1: 81.2500 (76.6840)  Acc@5: 93.7500 (95.3578)  time: 0.3494  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [2800/3750]  eta: 0:05:32  Lr: 0.001875  Loss: -0.7700  Acc@1: 75.0000 (76.6847)  Acc@5: 93.7500 (95.3633)  time: 0.3496  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2810/3750]  eta: 0:05:29  Lr: 0.001875  Loss: -0.8438  Acc@1: 75.0000 (76.6942)  Acc@5: 93.7500 (95.3642)  time: 0.3500  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [2820/3750]  eta: 0:05:25  Lr: 0.001875  Loss: -0.5316  Acc@1: 75.0000 (76.7015)  Acc@5: 93.7500 (95.3607)  time: 0.3504  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [2830/3750]  eta: 0:05:22  Lr: 0.001875  Loss: -1.2264  Acc@1: 75.0000 (76.7154)  Acc@5: 100.0000 (95.3727)  time: 0.3508  data: 0.0011  max mem: 2500
Train: Epoch[1/5]  [2840/3750]  eta: 0:05:18  Lr: 0.001875  Loss: -0.7708  Acc@1: 75.0000 (76.7225)  Acc@5: 100.0000 (95.3801)  time: 0.3503  data: 0.0010  max mem: 2500
Train: Epoch[1/5]  [2850/3750]  eta: 0:05:15  Lr: 0.001875  Loss: -1.0873  Acc@1: 81.2500 (76.7647)  Acc@5: 100.0000 (95.3898)  time: 0.3496  data: 0.0009  max mem: 2500
Train: Epoch[1/5]  [2860/3750]  eta: 0:05:11  Lr: 0.001875  Loss: -0.9708  Acc@1: 81.2500 (76.7804)  Acc@5: 100.0000 (95.3906)  time: 0.3507  data: 0.0017  max mem: 2500
Train: Epoch[1/5]  [2870/3750]  eta: 0:05:08  Lr: 0.001875  Loss: -1.2274  Acc@1: 81.2500 (76.7894)  Acc@5: 93.7500 (95.3914)  time: 0.3503  data: 0.0012  max mem: 2500
Train: Epoch[1/5]  [2880/3750]  eta: 0:05:04  Lr: 0.001875  Loss: -1.2071  Acc@1: 75.0000 (76.8028)  Acc@5: 93.7500 (95.3922)  time: 0.3504  data: 0.0010  max mem: 2500
Train: Epoch[1/5]  [2890/3750]  eta: 0:05:01  Lr: 0.001875  Loss: -1.1459  Acc@1: 81.2500 (76.8181)  Acc@5: 100.0000 (95.3995)  time: 0.3508  data: 0.0011  max mem: 2500
Train: Epoch[1/5]  [2900/3750]  eta: 0:04:57  Lr: 0.001875  Loss: -0.6003  Acc@1: 81.2500 (76.8248)  Acc@5: 100.0000 (95.4068)  time: 0.3497  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2910/3750]  eta: 0:04:54  Lr: 0.001875  Loss: -1.1769  Acc@1: 75.0000 (76.8336)  Acc@5: 100.0000 (95.4118)  time: 0.3501  data: 0.0013  max mem: 2500
Train: Epoch[1/5]  [2920/3750]  eta: 0:04:50  Lr: 0.001875  Loss: -0.9188  Acc@1: 75.0000 (76.8358)  Acc@5: 100.0000 (95.4125)  time: 0.3505  data: 0.0017  max mem: 2500
Train: Epoch[1/5]  [2930/3750]  eta: 0:04:47  Lr: 0.001875  Loss: -0.8310  Acc@1: 75.0000 (76.8338)  Acc@5: 93.7500 (95.4111)  time: 0.3500  data: 0.0012  max mem: 2500
Train: Epoch[1/5]  [2940/3750]  eta: 0:04:43  Lr: 0.001875  Loss: -0.8488  Acc@1: 75.0000 (76.8574)  Acc@5: 93.7500 (95.4182)  time: 0.3496  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [2950/3750]  eta: 0:04:40  Lr: 0.001875  Loss: -0.6892  Acc@1: 81.2500 (76.8553)  Acc@5: 100.0000 (95.4274)  time: 0.3497  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [2960/3750]  eta: 0:04:36  Lr: 0.001875  Loss: -1.3079  Acc@1: 75.0000 (76.8638)  Acc@5: 100.0000 (95.4323)  time: 0.3511  data: 0.0009  max mem: 2500
Train: Epoch[1/5]  [2970/3750]  eta: 0:04:33  Lr: 0.001875  Loss: -0.7916  Acc@1: 75.0000 (76.8660)  Acc@5: 100.0000 (95.4371)  time: 0.3504  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [2980/3750]  eta: 0:04:29  Lr: 0.001875  Loss: -1.0375  Acc@1: 81.2500 (76.8849)  Acc@5: 100.0000 (95.4378)  time: 0.3488  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [2990/3750]  eta: 0:04:26  Lr: 0.001875  Loss: -1.0888  Acc@1: 87.5000 (76.8994)  Acc@5: 100.0000 (95.4384)  time: 0.3495  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3000/3750]  eta: 0:04:22  Lr: 0.001875  Loss: -1.1116  Acc@1: 81.2500 (76.9160)  Acc@5: 93.7500 (95.4369)  time: 0.3507  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [3010/3750]  eta: 0:04:19  Lr: 0.001875  Loss: -0.9402  Acc@1: 81.2500 (76.9346)  Acc@5: 93.7500 (95.4459)  time: 0.3505  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [3020/3750]  eta: 0:04:15  Lr: 0.001875  Loss: -0.7673  Acc@1: 81.2500 (76.9220)  Acc@5: 100.0000 (95.4403)  time: 0.3501  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [3030/3750]  eta: 0:04:12  Lr: 0.001875  Loss: -1.0481  Acc@1: 75.0000 (76.9301)  Acc@5: 93.7500 (95.4450)  time: 0.3518  data: 0.0018  max mem: 2500
Train: Epoch[1/5]  [3040/3750]  eta: 0:04:08  Lr: 0.001875  Loss: -0.9914  Acc@1: 87.5000 (76.9669)  Acc@5: 100.0000 (95.4538)  time: 0.3515  data: 0.0021  max mem: 2500
Train: Epoch[1/5]  [3050/3750]  eta: 0:04:05  Lr: 0.001875  Loss: -1.2573  Acc@1: 87.5000 (76.9543)  Acc@5: 100.0000 (95.4605)  time: 0.3498  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [3060/3750]  eta: 0:04:01  Lr: 0.001875  Loss: -0.7229  Acc@1: 75.0000 (76.9683)  Acc@5: 100.0000 (95.4672)  time: 0.3505  data: 0.0011  max mem: 2500
Train: Epoch[1/5]  [3070/3750]  eta: 0:03:58  Lr: 0.001875  Loss: -0.4995  Acc@1: 81.2500 (76.9802)  Acc@5: 100.0000 (95.4656)  time: 0.3511  data: 0.0011  max mem: 2500
Train: Epoch[1/5]  [3080/3750]  eta: 0:03:54  Lr: 0.001875  Loss: -1.3052  Acc@1: 81.2500 (76.9860)  Acc@5: 100.0000 (95.4743)  time: 0.3504  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [3090/3750]  eta: 0:03:51  Lr: 0.001875  Loss: -0.9492  Acc@1: 81.2500 (76.9896)  Acc@5: 100.0000 (95.4788)  time: 0.3502  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [3100/3750]  eta: 0:03:47  Lr: 0.001875  Loss: -0.0503  Acc@1: 75.0000 (76.9832)  Acc@5: 93.7500 (95.4752)  time: 0.3508  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [3110/3750]  eta: 0:03:44  Lr: 0.001875  Loss: -0.6779  Acc@1: 75.0000 (76.9769)  Acc@5: 93.7500 (95.4717)  time: 0.3507  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [3120/3750]  eta: 0:03:40  Lr: 0.001875  Loss: -0.3759  Acc@1: 75.0000 (76.9745)  Acc@5: 93.7500 (95.4742)  time: 0.3514  data: 0.0011  max mem: 2500
Train: Epoch[1/5]  [3130/3750]  eta: 0:03:37  Lr: 0.001875  Loss: -0.6133  Acc@1: 81.2500 (76.9822)  Acc@5: 100.0000 (95.4787)  time: 0.3512  data: 0.0012  max mem: 2500
Train: Epoch[1/5]  [3140/3750]  eta: 0:03:33  Lr: 0.001875  Loss: -1.4291  Acc@1: 81.2500 (77.0018)  Acc@5: 100.0000 (95.4831)  time: 0.3505  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [3150/3750]  eta: 0:03:30  Lr: 0.001875  Loss: -1.3066  Acc@1: 81.2500 (77.0093)  Acc@5: 93.7500 (95.4856)  time: 0.3511  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [3160/3750]  eta: 0:03:26  Lr: 0.001875  Loss: -0.9460  Acc@1: 75.0000 (77.0108)  Acc@5: 93.7500 (95.4900)  time: 0.3514  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [3170/3750]  eta: 0:03:23  Lr: 0.001875  Loss: -0.4927  Acc@1: 75.0000 (77.0104)  Acc@5: 100.0000 (95.4943)  time: 0.3512  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3180/3750]  eta: 0:03:19  Lr: 0.001875  Loss: -0.3281  Acc@1: 75.0000 (76.9943)  Acc@5: 93.7500 (95.4947)  time: 0.3517  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [3190/3750]  eta: 0:03:16  Lr: 0.001875  Loss: -0.9187  Acc@1: 81.2500 (77.0135)  Acc@5: 93.7500 (95.4971)  time: 0.3525  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [3200/3750]  eta: 0:03:12  Lr: 0.001875  Loss: -0.8668  Acc@1: 81.2500 (77.0150)  Acc@5: 93.7500 (95.4955)  time: 0.3509  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [3210/3750]  eta: 0:03:09  Lr: 0.001875  Loss: -1.2145  Acc@1: 75.0000 (77.0243)  Acc@5: 93.7500 (95.4998)  time: 0.3492  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [3220/3750]  eta: 0:03:05  Lr: 0.001875  Loss: -1.0923  Acc@1: 81.2500 (77.0432)  Acc@5: 100.0000 (95.5099)  time: 0.3525  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [3230/3750]  eta: 0:03:02  Lr: 0.001875  Loss: -1.0385  Acc@1: 81.2500 (77.0621)  Acc@5: 100.0000 (95.5103)  time: 0.3533  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [3240/3750]  eta: 0:02:58  Lr: 0.001875  Loss: -0.4534  Acc@1: 81.2500 (77.0634)  Acc@5: 93.7500 (95.5145)  time: 0.3508  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [3250/3750]  eta: 0:02:55  Lr: 0.001875  Loss: -0.8639  Acc@1: 81.2500 (77.0821)  Acc@5: 100.0000 (95.5225)  time: 0.3503  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [3260/3750]  eta: 0:02:51  Lr: 0.001875  Loss: -0.7316  Acc@1: 81.2500 (77.1044)  Acc@5: 100.0000 (95.5267)  time: 0.3503  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [3270/3750]  eta: 0:02:48  Lr: 0.001875  Loss: -0.6722  Acc@1: 81.2500 (77.0980)  Acc@5: 100.0000 (95.5232)  time: 0.3499  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [3280/3750]  eta: 0:02:44  Lr: 0.001875  Loss: -1.1630  Acc@1: 75.0000 (77.1068)  Acc@5: 100.0000 (95.5311)  time: 0.3487  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3290/3750]  eta: 0:02:41  Lr: 0.001875  Loss: -1.1582  Acc@1: 81.2500 (77.1308)  Acc@5: 100.0000 (95.5371)  time: 0.3483  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [3300/3750]  eta: 0:02:37  Lr: 0.001875  Loss: -1.1086  Acc@1: 81.2500 (77.1395)  Acc@5: 100.0000 (95.5468)  time: 0.3488  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [3310/3750]  eta: 0:02:34  Lr: 0.001875  Loss: -1.1547  Acc@1: 81.2500 (77.1519)  Acc@5: 100.0000 (95.5546)  time: 0.3490  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [3320/3750]  eta: 0:02:30  Lr: 0.001875  Loss: -1.1097  Acc@1: 81.2500 (77.1680)  Acc@5: 100.0000 (95.5623)  time: 0.3491  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3330/3750]  eta: 0:02:27  Lr: 0.001875  Loss: -0.7813  Acc@1: 81.2500 (77.1803)  Acc@5: 100.0000 (95.5663)  time: 0.3493  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3340/3750]  eta: 0:02:23  Lr: 0.001875  Loss: -1.0772  Acc@1: 81.2500 (77.1981)  Acc@5: 100.0000 (95.5683)  time: 0.3510  data: 0.0011  max mem: 2500
Train: Epoch[1/5]  [3350/3750]  eta: 0:02:20  Lr: 0.001875  Loss: -0.9114  Acc@1: 81.2500 (77.1915)  Acc@5: 93.7500 (95.5685)  time: 0.3512  data: 0.0011  max mem: 2500
Train: Epoch[1/5]  [3360/3750]  eta: 0:02:16  Lr: 0.001875  Loss: -0.6593  Acc@1: 75.0000 (77.1868)  Acc@5: 100.0000 (95.5724)  time: 0.3490  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3370/3750]  eta: 0:02:13  Lr: 0.001875  Loss: -0.9246  Acc@1: 75.0000 (77.1637)  Acc@5: 93.7500 (95.5688)  time: 0.3504  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3380/3750]  eta: 0:02:09  Lr: 0.001875  Loss: -0.9710  Acc@1: 75.0000 (77.1721)  Acc@5: 93.7500 (95.5727)  time: 0.3509  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3390/3750]  eta: 0:02:06  Lr: 0.001875  Loss: -1.0033  Acc@1: 81.2500 (77.1822)  Acc@5: 100.0000 (95.5747)  time: 0.3495  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3400/3750]  eta: 0:02:02  Lr: 0.001875  Loss: -1.0087  Acc@1: 81.2500 (77.1869)  Acc@5: 93.7500 (95.5748)  time: 0.3492  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3410/3750]  eta: 0:01:59  Lr: 0.001875  Loss: -0.2179  Acc@1: 75.0000 (77.1786)  Acc@5: 93.7500 (95.5768)  time: 0.3517  data: 0.0010  max mem: 2500
Train: Epoch[1/5]  [3420/3750]  eta: 0:01:55  Lr: 0.001875  Loss: -0.7885  Acc@1: 75.0000 (77.1796)  Acc@5: 93.7500 (95.5788)  time: 0.3528  data: 0.0016  max mem: 2500
Train: Epoch[1/5]  [3430/3750]  eta: 0:01:52  Lr: 0.001875  Loss: -1.0154  Acc@1: 75.0000 (77.1932)  Acc@5: 93.7500 (95.5716)  time: 0.3500  data: 0.0010  max mem: 2500
Train: Epoch[1/5]  [3440/3750]  eta: 0:01:48  Lr: 0.001875  Loss: -1.2033  Acc@1: 87.5000 (77.2232)  Acc@5: 93.7500 (95.5772)  time: 0.3495  data: 0.0012  max mem: 2500
Train: Epoch[1/5]  [3450/3750]  eta: 0:01:45  Lr: 0.001875  Loss: -0.7838  Acc@1: 81.2500 (77.2294)  Acc@5: 100.0000 (95.5846)  time: 0.3489  data: 0.0013  max mem: 2500
Train: Epoch[1/5]  [3460/3750]  eta: 0:01:41  Lr: 0.001875  Loss: -0.9670  Acc@1: 81.2500 (77.2465)  Acc@5: 100.0000 (95.5883)  time: 0.3501  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [3470/3750]  eta: 0:01:38  Lr: 0.001875  Loss: -1.0943  Acc@1: 81.2500 (77.2598)  Acc@5: 100.0000 (95.5938)  time: 0.3504  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [3480/3750]  eta: 0:01:34  Lr: 0.001875  Loss: -0.9001  Acc@1: 81.2500 (77.2748)  Acc@5: 100.0000 (95.6011)  time: 0.3493  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [3490/3750]  eta: 0:01:31  Lr: 0.001875  Loss: -1.4833  Acc@1: 81.2500 (77.2970)  Acc@5: 100.0000 (95.6030)  time: 0.3494  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [3500/3750]  eta: 0:01:27  Lr: 0.001875  Loss: -0.4573  Acc@1: 75.0000 (77.3011)  Acc@5: 93.7500 (95.5941)  time: 0.3495  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3510/3750]  eta: 0:01:24  Lr: 0.001875  Loss: -1.2523  Acc@1: 75.0000 (77.3017)  Acc@5: 93.7500 (95.5853)  time: 0.3498  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [3520/3750]  eta: 0:01:20  Lr: 0.001875  Loss: -0.7815  Acc@1: 75.0000 (77.2987)  Acc@5: 93.7500 (95.5907)  time: 0.3490  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [3530/3750]  eta: 0:01:17  Lr: 0.001875  Loss: -0.7379  Acc@1: 75.0000 (77.3046)  Acc@5: 100.0000 (95.5961)  time: 0.3477  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3540/3750]  eta: 0:01:13  Lr: 0.001875  Loss: -1.0831  Acc@1: 81.2500 (77.3140)  Acc@5: 93.7500 (95.5962)  time: 0.3502  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3550/3750]  eta: 0:01:10  Lr: 0.001875  Loss: -1.0497  Acc@1: 81.2500 (77.3286)  Acc@5: 100.0000 (95.6034)  time: 0.3511  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [3560/3750]  eta: 0:01:06  Lr: 0.001875  Loss: -1.1839  Acc@1: 81.2500 (77.3448)  Acc@5: 100.0000 (95.6122)  time: 0.3514  data: 0.0012  max mem: 2500
Train: Epoch[1/5]  [3570/3750]  eta: 0:01:03  Lr: 0.001875  Loss: -0.8184  Acc@1: 81.2500 (77.3628)  Acc@5: 100.0000 (95.6157)  time: 0.3513  data: 0.0013  max mem: 2500
Train: Epoch[1/5]  [3580/3750]  eta: 0:00:59  Lr: 0.001875  Loss: -0.8459  Acc@1: 81.2500 (77.3701)  Acc@5: 100.0000 (95.6157)  time: 0.3496  data: 0.0013  max mem: 2500
Train: Epoch[1/5]  [3590/3750]  eta: 0:00:56  Lr: 0.001875  Loss: -1.4219  Acc@1: 81.2500 (77.4001)  Acc@5: 100.0000 (95.6245)  time: 0.3490  data: 0.0011  max mem: 2500
Train: Epoch[1/5]  [3600/3750]  eta: 0:00:52  Lr: 0.001875  Loss: -0.8561  Acc@1: 81.2500 (77.4021)  Acc@5: 100.0000 (95.6280)  time: 0.3501  data: 0.0007  max mem: 2500
Train: Epoch[1/5]  [3610/3750]  eta: 0:00:49  Lr: 0.001875  Loss: -1.2434  Acc@1: 81.2500 (77.4180)  Acc@5: 100.0000 (95.6366)  time: 0.3511  data: 0.0008  max mem: 2500
Train: Epoch[1/5]  [3620/3750]  eta: 0:00:45  Lr: 0.001875  Loss: -0.8004  Acc@1: 81.2500 (77.4216)  Acc@5: 100.0000 (95.6435)  time: 0.3488  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [3630/3750]  eta: 0:00:42  Lr: 0.001875  Loss: -1.0214  Acc@1: 81.2500 (77.4287)  Acc@5: 100.0000 (95.6417)  time: 0.3499  data: 0.0013  max mem: 2500
Train: Epoch[1/5]  [3640/3750]  eta: 0:00:38  Lr: 0.001875  Loss: -1.0441  Acc@1: 81.2500 (77.4478)  Acc@5: 100.0000 (95.6485)  time: 0.3507  data: 0.0014  max mem: 2500
Train: Epoch[1/5]  [3650/3750]  eta: 0:00:35  Lr: 0.001875  Loss: -0.6925  Acc@1: 81.2500 (77.4514)  Acc@5: 100.0000 (95.6485)  time: 0.3494  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [3660/3750]  eta: 0:00:31  Lr: 0.001875  Loss: -1.3511  Acc@1: 75.0000 (77.4601)  Acc@5: 93.7500 (95.6501)  time: 0.3487  data: 0.0004  max mem: 2500
Train: Epoch[1/5]  [3670/3750]  eta: 0:00:28  Lr: 0.001875  Loss: -1.2897  Acc@1: 81.2500 (77.4619)  Acc@5: 100.0000 (95.6534)  time: 0.3488  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [3680/3750]  eta: 0:00:24  Lr: 0.001875  Loss: -0.9409  Acc@1: 81.2500 (77.4739)  Acc@5: 100.0000 (95.6551)  time: 0.3520  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [3690/3750]  eta: 0:00:21  Lr: 0.001875  Loss: -1.0166  Acc@1: 81.2500 (77.4824)  Acc@5: 93.7500 (95.6550)  time: 0.3535  data: 0.0006  max mem: 2500
Train: Epoch[1/5]  [3700/3750]  eta: 0:00:17  Lr: 0.001875  Loss: -0.8995  Acc@1: 81.2500 (77.4858)  Acc@5: 93.7500 (95.6583)  time: 0.3514  data: 0.0014  max mem: 2500
Train: Epoch[1/5]  [3710/3750]  eta: 0:00:14  Lr: 0.001875  Loss: -1.1575  Acc@1: 81.2500 (77.5010)  Acc@5: 93.7500 (95.6582)  time: 0.3503  data: 0.0013  max mem: 2500
Train: Epoch[1/5]  [3720/3750]  eta: 0:00:10  Lr: 0.001875  Loss: -1.0034  Acc@1: 81.2500 (77.5077)  Acc@5: 93.7500 (95.6614)  time: 0.3513  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [3730/3750]  eta: 0:00:07  Lr: 0.001875  Loss: -0.9807  Acc@1: 81.2500 (77.5245)  Acc@5: 93.7500 (95.6614)  time: 0.3507  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [3740/3750]  eta: 0:00:03  Lr: 0.001875  Loss: -0.6329  Acc@1: 81.2500 (77.5311)  Acc@5: 93.7500 (95.6663)  time: 0.3493  data: 0.0005  max mem: 2500
Train: Epoch[1/5]  [3749/3750]  eta: 0:00:00  Lr: 0.001875  Loss: -1.2811  Acc@1: 81.2500 (77.5483)  Acc@5: 100.0000 (95.6667)  time: 0.3499  data: 0.0009  max mem: 2500
Train: Epoch[1/5] Total time: 0:21:54 (0.3506 s / it)
Averaged stats: Lr: 0.001875  Loss: -1.2811  Acc@1: 81.2500 (77.5483)  Acc@5: 100.0000 (95.6667)
Train: Epoch[2/5]  [   0/3750]  eta: 0:47:57  Lr: 0.001875  Loss: -0.9132  Acc@1: 81.2500 (81.2500)  Acc@5: 100.0000 (100.0000)  time: 0.7672  data: 0.4183  max mem: 2500
Train: Epoch[2/5]  [  10/3750]  eta: 0:24:19  Lr: 0.001875  Loss: -1.2909  Acc@1: 81.2500 (82.9545)  Acc@5: 100.0000 (98.2955)  time: 0.3901  data: 0.0384  max mem: 2500
Train: Epoch[2/5]  [  20/3750]  eta: 0:23:03  Lr: 0.001875  Loss: -1.1036  Acc@1: 81.2500 (79.4643)  Acc@5: 100.0000 (97.9167)  time: 0.3510  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [  30/3750]  eta: 0:22:38  Lr: 0.001875  Loss: -1.1492  Acc@1: 75.0000 (79.2339)  Acc@5: 100.0000 (97.7823)  time: 0.3514  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [  40/3750]  eta: 0:22:19  Lr: 0.001875  Loss: -0.6408  Acc@1: 81.2500 (79.4207)  Acc@5: 93.7500 (96.6463)  time: 0.3506  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [  50/3750]  eta: 0:22:07  Lr: 0.001875  Loss: -1.1040  Acc@1: 81.2500 (80.0245)  Acc@5: 93.7500 (96.6912)  time: 0.3491  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [  60/3750]  eta: 0:21:59  Lr: 0.001875  Loss: -1.2554  Acc@1: 81.2500 (79.3033)  Acc@5: 93.7500 (96.6189)  time: 0.3511  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [  70/3750]  eta: 0:21:53  Lr: 0.001875  Loss: -0.7813  Acc@1: 75.0000 (79.1373)  Acc@5: 93.7500 (96.6549)  time: 0.3523  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [  80/3750]  eta: 0:21:46  Lr: 0.001875  Loss: -0.7833  Acc@1: 75.0000 (79.3981)  Acc@5: 93.7500 (96.5278)  time: 0.3508  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [  90/3750]  eta: 0:21:42  Lr: 0.001875  Loss: -0.6921  Acc@1: 81.2500 (79.6016)  Acc@5: 93.7500 (96.4286)  time: 0.3521  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [ 100/3750]  eta: 0:21:37  Lr: 0.001875  Loss: -1.0265  Acc@1: 81.2500 (79.7030)  Acc@5: 100.0000 (96.5347)  time: 0.3531  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [ 110/3750]  eta: 0:21:32  Lr: 0.001875  Loss: -1.1768  Acc@1: 81.2500 (79.6734)  Acc@5: 100.0000 (96.5653)  time: 0.3513  data: 0.0009  max mem: 2500
Train: Epoch[2/5]  [ 120/3750]  eta: 0:21:27  Lr: 0.001875  Loss: -1.1834  Acc@1: 87.5000 (80.1653)  Acc@5: 100.0000 (96.4876)  time: 0.3504  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [ 130/3750]  eta: 0:21:23  Lr: 0.001875  Loss: -1.2749  Acc@1: 87.5000 (80.0095)  Acc@5: 100.0000 (96.5649)  time: 0.3513  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [ 140/3750]  eta: 0:21:18  Lr: 0.001875  Loss: -1.4415  Acc@1: 81.2500 (80.4521)  Acc@5: 100.0000 (96.5869)  time: 0.3515  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [ 150/3750]  eta: 0:21:14  Lr: 0.001875  Loss: -0.9211  Acc@1: 81.2500 (79.8013)  Acc@5: 93.7500 (96.2334)  time: 0.3499  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [ 160/3750]  eta: 0:21:09  Lr: 0.001875  Loss: -0.3129  Acc@1: 75.0000 (79.6196)  Acc@5: 87.5000 (96.0792)  time: 0.3498  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [ 170/3750]  eta: 0:21:05  Lr: 0.001875  Loss: -0.4671  Acc@1: 81.2500 (79.5687)  Acc@5: 93.7500 (96.1257)  time: 0.3509  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [ 180/3750]  eta: 0:21:01  Lr: 0.001875  Loss: -0.2359  Acc@1: 81.2500 (79.3854)  Acc@5: 100.0000 (96.2017)  time: 0.3520  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [ 190/3750]  eta: 0:20:57  Lr: 0.001875  Loss: -1.2725  Acc@1: 81.2500 (79.4830)  Acc@5: 100.0000 (96.2369)  time: 0.3512  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [ 200/3750]  eta: 0:20:53  Lr: 0.001875  Loss: -0.9517  Acc@1: 81.2500 (79.5087)  Acc@5: 93.7500 (96.2376)  time: 0.3507  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [ 210/3750]  eta: 0:20:50  Lr: 0.001875  Loss: -0.7458  Acc@1: 81.2500 (79.5320)  Acc@5: 93.7500 (96.2974)  time: 0.3516  data: 0.0022  max mem: 2500
Train: Epoch[2/5]  [ 220/3750]  eta: 0:20:46  Lr: 0.001875  Loss: -0.9204  Acc@1: 75.0000 (79.4118)  Acc@5: 100.0000 (96.3235)  time: 0.3528  data: 0.0026  max mem: 2500
Train: Epoch[2/5]  [ 230/3750]  eta: 0:20:42  Lr: 0.001875  Loss: -0.4030  Acc@1: 81.2500 (79.5725)  Acc@5: 100.0000 (96.3203)  time: 0.3518  data: 0.0014  max mem: 2500
Train: Epoch[2/5]  [ 240/3750]  eta: 0:20:38  Lr: 0.001875  Loss: -0.9278  Acc@1: 81.2500 (79.4865)  Acc@5: 100.0000 (96.3174)  time: 0.3505  data: 0.0010  max mem: 2500
Train: Epoch[2/5]  [ 250/3750]  eta: 0:20:34  Lr: 0.001875  Loss: -0.8793  Acc@1: 81.2500 (79.7062)  Acc@5: 100.0000 (96.3894)  time: 0.3498  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [ 260/3750]  eta: 0:20:30  Lr: 0.001875  Loss: -1.0887  Acc@1: 81.2500 (79.8611)  Acc@5: 100.0000 (96.3602)  time: 0.3495  data: 0.0012  max mem: 2500
Train: Epoch[2/5]  [ 270/3750]  eta: 0:20:26  Lr: 0.001875  Loss: -1.0276  Acc@1: 81.2500 (79.8432)  Acc@5: 93.7500 (96.2638)  time: 0.3494  data: 0.0012  max mem: 2500
Train: Epoch[2/5]  [ 280/3750]  eta: 0:20:22  Lr: 0.001875  Loss: -1.1030  Acc@1: 81.2500 (79.7820)  Acc@5: 100.0000 (96.3523)  time: 0.3491  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [ 290/3750]  eta: 0:20:19  Lr: 0.001875  Loss: -1.0144  Acc@1: 81.2500 (79.7895)  Acc@5: 100.0000 (96.3918)  time: 0.3498  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [ 300/3750]  eta: 0:20:15  Lr: 0.001875  Loss: -1.2632  Acc@1: 81.2500 (79.8796)  Acc@5: 100.0000 (96.4701)  time: 0.3497  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [ 310/3750]  eta: 0:20:11  Lr: 0.001875  Loss: -0.7426  Acc@1: 75.0000 (79.8432)  Acc@5: 100.0000 (96.4027)  time: 0.3497  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [ 320/3750]  eta: 0:20:07  Lr: 0.001875  Loss: -0.9380  Acc@1: 75.0000 (79.7897)  Acc@5: 100.0000 (96.4759)  time: 0.3503  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [ 330/3750]  eta: 0:20:03  Lr: 0.001875  Loss: -1.1810  Acc@1: 81.2500 (79.9282)  Acc@5: 100.0000 (96.5068)  time: 0.3495  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [ 340/3750]  eta: 0:20:00  Lr: 0.001875  Loss: -0.6784  Acc@1: 81.2500 (79.8754)  Acc@5: 100.0000 (96.5359)  time: 0.3512  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [ 350/3750]  eta: 0:19:56  Lr: 0.001875  Loss: -0.4236  Acc@1: 75.0000 (79.9145)  Acc@5: 93.7500 (96.4744)  time: 0.3517  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [ 360/3750]  eta: 0:19:53  Lr: 0.001875  Loss: -1.0903  Acc@1: 81.2500 (80.0900)  Acc@5: 100.0000 (96.5201)  time: 0.3504  data: 0.0012  max mem: 2500
Train: Epoch[2/5]  [ 370/3750]  eta: 0:19:49  Lr: 0.001875  Loss: -1.3737  Acc@1: 81.2500 (80.1718)  Acc@5: 100.0000 (96.5296)  time: 0.3500  data: 0.0012  max mem: 2500
Train: Epoch[2/5]  [ 380/3750]  eta: 0:19:45  Lr: 0.001875  Loss: -1.0743  Acc@1: 81.2500 (80.2493)  Acc@5: 100.0000 (96.6043)  time: 0.3503  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [ 390/3750]  eta: 0:19:42  Lr: 0.001875  Loss: -0.3966  Acc@1: 81.2500 (80.2430)  Acc@5: 100.0000 (96.5793)  time: 0.3507  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [ 400/3750]  eta: 0:19:38  Lr: 0.001875  Loss: -0.8871  Acc@1: 81.2500 (80.2369)  Acc@5: 93.7500 (96.5399)  time: 0.3502  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [ 410/3750]  eta: 0:19:34  Lr: 0.001875  Loss: -1.1864  Acc@1: 81.2500 (80.2464)  Acc@5: 93.7500 (96.5176)  time: 0.3496  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [ 420/3750]  eta: 0:19:31  Lr: 0.001875  Loss: -1.3137  Acc@1: 81.2500 (80.2108)  Acc@5: 100.0000 (96.5558)  time: 0.3498  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 430/3750]  eta: 0:19:27  Lr: 0.001875  Loss: -0.4823  Acc@1: 81.2500 (80.1769)  Acc@5: 100.0000 (96.5632)  time: 0.3506  data: 0.0009  max mem: 2500
Train: Epoch[2/5]  [ 440/3750]  eta: 0:19:24  Lr: 0.001875  Loss: -1.0912  Acc@1: 81.2500 (80.1587)  Acc@5: 100.0000 (96.5703)  time: 0.3514  data: 0.0010  max mem: 2500
Train: Epoch[2/5]  [ 450/3750]  eta: 0:19:20  Lr: 0.001875  Loss: -0.7108  Acc@1: 81.2500 (80.1275)  Acc@5: 93.7500 (96.4800)  time: 0.3513  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [ 460/3750]  eta: 0:19:17  Lr: 0.001875  Loss: -1.3005  Acc@1: 81.2500 (80.1383)  Acc@5: 93.7500 (96.4751)  time: 0.3520  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 470/3750]  eta: 0:19:13  Lr: 0.001875  Loss: -0.6144  Acc@1: 81.2500 (80.1884)  Acc@5: 100.0000 (96.4968)  time: 0.3527  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [ 480/3750]  eta: 0:19:09  Lr: 0.001875  Loss: -0.6619  Acc@1: 81.2500 (80.2755)  Acc@5: 100.0000 (96.5047)  time: 0.3512  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [ 490/3750]  eta: 0:19:06  Lr: 0.001875  Loss: -0.9754  Acc@1: 87.5000 (80.4226)  Acc@5: 100.0000 (96.5377)  time: 0.3501  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [ 500/3750]  eta: 0:19:02  Lr: 0.001875  Loss: -0.8163  Acc@1: 81.2500 (80.3767)  Acc@5: 100.0000 (96.5943)  time: 0.3494  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [ 510/3750]  eta: 0:18:59  Lr: 0.001875  Loss: -1.0066  Acc@1: 75.0000 (80.3449)  Acc@5: 100.0000 (96.5998)  time: 0.3493  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 520/3750]  eta: 0:18:55  Lr: 0.001875  Loss: -0.6606  Acc@1: 75.0000 (80.3383)  Acc@5: 100.0000 (96.5811)  time: 0.3495  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [ 530/3750]  eta: 0:18:51  Lr: 0.001875  Loss: -0.3823  Acc@1: 81.2500 (80.3790)  Acc@5: 100.0000 (96.5984)  time: 0.3492  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [ 540/3750]  eta: 0:18:48  Lr: 0.001875  Loss: -0.9181  Acc@1: 81.2500 (80.3835)  Acc@5: 100.0000 (96.6151)  time: 0.3489  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 550/3750]  eta: 0:18:44  Lr: 0.001875  Loss: -1.1661  Acc@1: 75.0000 (80.3539)  Acc@5: 100.0000 (96.6425)  time: 0.3493  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [ 560/3750]  eta: 0:18:40  Lr: 0.001875  Loss: -0.4514  Acc@1: 75.0000 (80.2473)  Acc@5: 100.0000 (96.6243)  time: 0.3497  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [ 570/3750]  eta: 0:18:37  Lr: 0.001875  Loss: -1.1164  Acc@1: 75.0000 (80.1883)  Acc@5: 93.7500 (96.5959)  time: 0.3491  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [ 580/3750]  eta: 0:18:33  Lr: 0.001875  Loss: -1.2248  Acc@1: 75.0000 (80.1528)  Acc@5: 93.7500 (96.5792)  time: 0.3488  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [ 590/3750]  eta: 0:18:29  Lr: 0.001875  Loss: -1.1459  Acc@1: 75.0000 (80.1925)  Acc@5: 93.7500 (96.5736)  time: 0.3491  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [ 600/3750]  eta: 0:18:26  Lr: 0.001875  Loss: -0.9069  Acc@1: 75.0000 (80.1061)  Acc@5: 93.7500 (96.5370)  time: 0.3513  data: 0.0014  max mem: 2500
Train: Epoch[2/5]  [ 610/3750]  eta: 0:18:22  Lr: 0.001875  Loss: -0.7757  Acc@1: 75.0000 (80.0327)  Acc@5: 93.7500 (96.4914)  time: 0.3520  data: 0.0012  max mem: 2500
Train: Epoch[2/5]  [ 620/3750]  eta: 0:18:19  Lr: 0.001875  Loss: -0.6663  Acc@1: 75.0000 (79.9919)  Acc@5: 93.7500 (96.4775)  time: 0.3494  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [ 630/3750]  eta: 0:18:15  Lr: 0.001875  Loss: -1.0224  Acc@1: 81.2500 (80.1010)  Acc@5: 93.7500 (96.4639)  time: 0.3495  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [ 640/3750]  eta: 0:18:12  Lr: 0.001875  Loss: -1.0867  Acc@1: 87.5000 (80.0995)  Acc@5: 93.7500 (96.4314)  time: 0.3503  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [ 650/3750]  eta: 0:18:08  Lr: 0.001875  Loss: -1.4510  Acc@1: 81.2500 (80.1747)  Acc@5: 93.7500 (96.4286)  time: 0.3499  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 660/3750]  eta: 0:18:04  Lr: 0.001875  Loss: -0.8827  Acc@1: 81.2500 (80.2288)  Acc@5: 100.0000 (96.4542)  time: 0.3496  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [ 670/3750]  eta: 0:18:01  Lr: 0.001875  Loss: -0.5311  Acc@1: 81.2500 (80.2254)  Acc@5: 100.0000 (96.4419)  time: 0.3502  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [ 680/3750]  eta: 0:17:57  Lr: 0.001875  Loss: -1.3049  Acc@1: 81.2500 (80.2680)  Acc@5: 93.7500 (96.4391)  time: 0.3492  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [ 690/3750]  eta: 0:17:54  Lr: 0.001875  Loss: -1.2660  Acc@1: 81.2500 (80.3546)  Acc@5: 100.0000 (96.4635)  time: 0.3490  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [ 700/3750]  eta: 0:17:50  Lr: 0.001875  Loss: -0.7323  Acc@1: 81.2500 (80.3762)  Acc@5: 100.0000 (96.4693)  time: 0.3508  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [ 710/3750]  eta: 0:17:47  Lr: 0.001875  Loss: -0.8074  Acc@1: 81.2500 (80.4325)  Acc@5: 100.0000 (96.4750)  time: 0.3514  data: 0.0013  max mem: 2500
Train: Epoch[2/5]  [ 720/3750]  eta: 0:17:43  Lr: 0.001875  Loss: -0.7314  Acc@1: 81.2500 (80.3831)  Acc@5: 93.7500 (96.4719)  time: 0.3505  data: 0.0013  max mem: 2500
Train: Epoch[2/5]  [ 730/3750]  eta: 0:17:40  Lr: 0.001875  Loss: -1.1698  Acc@1: 81.2500 (80.4121)  Acc@5: 100.0000 (96.4689)  time: 0.3497  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [ 740/3750]  eta: 0:17:36  Lr: 0.001875  Loss: -0.8258  Acc@1: 81.2500 (80.3728)  Acc@5: 100.0000 (96.4997)  time: 0.3504  data: 0.0013  max mem: 2500
Train: Epoch[2/5]  [ 750/3750]  eta: 0:17:33  Lr: 0.001875  Loss: -1.1070  Acc@1: 75.0000 (80.3429)  Acc@5: 100.0000 (96.4880)  time: 0.3504  data: 0.0012  max mem: 2500
Train: Epoch[2/5]  [ 760/3750]  eta: 0:17:29  Lr: 0.001875  Loss: -0.7713  Acc@1: 75.0000 (80.2727)  Acc@5: 100.0000 (96.4685)  time: 0.3498  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [ 770/3750]  eta: 0:17:25  Lr: 0.001875  Loss: -0.8826  Acc@1: 75.0000 (80.2610)  Acc@5: 100.0000 (96.4818)  time: 0.3497  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [ 780/3750]  eta: 0:17:22  Lr: 0.001875  Loss: -0.8890  Acc@1: 81.2500 (80.2657)  Acc@5: 100.0000 (96.4949)  time: 0.3498  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [ 790/3750]  eta: 0:17:18  Lr: 0.001875  Loss: -0.5159  Acc@1: 81.2500 (80.2781)  Acc@5: 100.0000 (96.4839)  time: 0.3506  data: 0.0014  max mem: 2500
Train: Epoch[2/5]  [ 800/3750]  eta: 0:17:15  Lr: 0.001875  Loss: -1.0844  Acc@1: 75.0000 (80.2278)  Acc@5: 93.7500 (96.4654)  time: 0.3505  data: 0.0020  max mem: 2500
Train: Epoch[2/5]  [ 810/3750]  eta: 0:17:11  Lr: 0.001875  Loss: -0.5512  Acc@1: 75.0000 (80.1942)  Acc@5: 93.7500 (96.4704)  time: 0.3512  data: 0.0016  max mem: 2500
Train: Epoch[2/5]  [ 820/3750]  eta: 0:17:08  Lr: 0.001875  Loss: -1.2541  Acc@1: 75.0000 (80.1766)  Acc@5: 93.7500 (96.4449)  time: 0.3510  data: 0.0009  max mem: 2500
Train: Epoch[2/5]  [ 830/3750]  eta: 0:17:04  Lr: 0.001875  Loss: -1.0334  Acc@1: 81.2500 (80.1820)  Acc@5: 93.7500 (96.4425)  time: 0.3516  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [ 840/3750]  eta: 0:17:01  Lr: 0.001875  Loss: -0.6597  Acc@1: 81.2500 (80.2467)  Acc@5: 100.0000 (96.4625)  time: 0.3528  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [ 850/3750]  eta: 0:16:57  Lr: 0.001875  Loss: -1.1856  Acc@1: 81.2500 (80.2659)  Acc@5: 100.0000 (96.4600)  time: 0.3511  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [ 860/3750]  eta: 0:16:54  Lr: 0.001875  Loss: -0.7754  Acc@1: 81.2500 (80.2410)  Acc@5: 93.7500 (96.4431)  time: 0.3510  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [ 870/3750]  eta: 0:16:50  Lr: 0.001875  Loss: -0.7658  Acc@1: 75.0000 (80.1808)  Acc@5: 93.7500 (96.4265)  time: 0.3515  data: 0.0009  max mem: 2500
Train: Epoch[2/5]  [ 880/3750]  eta: 0:16:47  Lr: 0.001875  Loss: -0.5335  Acc@1: 81.2500 (80.1859)  Acc@5: 100.0000 (96.4458)  time: 0.3505  data: 0.0009  max mem: 2500
Train: Epoch[2/5]  [ 890/3750]  eta: 0:16:43  Lr: 0.001875  Loss: -0.9499  Acc@1: 81.2500 (80.2118)  Acc@5: 100.0000 (96.4366)  time: 0.3514  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [ 900/3750]  eta: 0:16:40  Lr: 0.001875  Loss: -0.8959  Acc@1: 87.5000 (80.2650)  Acc@5: 93.7500 (96.4276)  time: 0.3512  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [ 910/3750]  eta: 0:16:36  Lr: 0.001875  Loss: -0.9221  Acc@1: 87.5000 (80.2552)  Acc@5: 93.7500 (96.4256)  time: 0.3505  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [ 920/3750]  eta: 0:16:33  Lr: 0.001875  Loss: -0.6029  Acc@1: 75.0000 (80.2117)  Acc@5: 100.0000 (96.4237)  time: 0.3505  data: 0.0010  max mem: 2500
Train: Epoch[2/5]  [ 930/3750]  eta: 0:16:29  Lr: 0.001875  Loss: -1.1368  Acc@1: 81.2500 (80.2296)  Acc@5: 100.0000 (96.4487)  time: 0.3493  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [ 940/3750]  eta: 0:16:26  Lr: 0.001875  Loss: -0.7636  Acc@1: 81.2500 (80.2670)  Acc@5: 100.0000 (96.4532)  time: 0.3499  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [ 950/3750]  eta: 0:16:22  Lr: 0.001875  Loss: -1.0830  Acc@1: 81.2500 (80.2839)  Acc@5: 100.0000 (96.4642)  time: 0.3499  data: 0.0010  max mem: 2500
Train: Epoch[2/5]  [ 960/3750]  eta: 0:16:19  Lr: 0.001875  Loss: -1.5063  Acc@1: 81.2500 (80.2614)  Acc@5: 93.7500 (96.4035)  time: 0.3507  data: 0.0020  max mem: 2500
Train: Epoch[2/5]  [ 970/3750]  eta: 0:16:15  Lr: 0.001875  Loss: -1.0885  Acc@1: 81.2500 (80.2845)  Acc@5: 93.7500 (96.4019)  time: 0.3521  data: 0.0031  max mem: 2500
Train: Epoch[2/5]  [ 980/3750]  eta: 0:16:12  Lr: 0.001875  Loss: -0.5422  Acc@1: 81.2500 (80.2880)  Acc@5: 100.0000 (96.4067)  time: 0.3518  data: 0.0023  max mem: 2500
Train: Epoch[2/5]  [ 990/3750]  eta: 0:16:08  Lr: 0.001875  Loss: -1.0453  Acc@1: 81.2500 (80.3040)  Acc@5: 100.0000 (96.4115)  time: 0.3503  data: 0.0009  max mem: 2500
Train: Epoch[2/5]  [1000/3750]  eta: 0:16:05  Lr: 0.001875  Loss: -0.6252  Acc@1: 81.2500 (80.2572)  Acc@5: 100.0000 (96.4223)  time: 0.3484  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1010/3750]  eta: 0:16:01  Lr: 0.001875  Loss: -0.7569  Acc@1: 81.2500 (80.2423)  Acc@5: 93.7500 (96.4083)  time: 0.3492  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [1020/3750]  eta: 0:15:57  Lr: 0.001875  Loss: -1.2949  Acc@1: 81.2500 (80.2706)  Acc@5: 93.7500 (96.4128)  time: 0.3495  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [1030/3750]  eta: 0:15:54  Lr: 0.001875  Loss: -1.1428  Acc@1: 81.2500 (80.2861)  Acc@5: 100.0000 (96.4234)  time: 0.3504  data: 0.0011  max mem: 2500
Train: Epoch[2/5]  [1040/3750]  eta: 0:15:50  Lr: 0.001875  Loss: -1.1704  Acc@1: 81.2500 (80.3254)  Acc@5: 100.0000 (96.4397)  time: 0.3504  data: 0.0010  max mem: 2500
Train: Epoch[2/5]  [1050/3750]  eta: 0:15:47  Lr: 0.001875  Loss: -0.9477  Acc@1: 81.2500 (80.3223)  Acc@5: 100.0000 (96.4439)  time: 0.3486  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1060/3750]  eta: 0:15:43  Lr: 0.001875  Loss: -0.8437  Acc@1: 81.2500 (80.3311)  Acc@5: 100.0000 (96.4303)  time: 0.3487  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1070/3750]  eta: 0:15:40  Lr: 0.001875  Loss: -0.6914  Acc@1: 81.2500 (80.3571)  Acc@5: 93.7500 (96.4169)  time: 0.3497  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1080/3750]  eta: 0:15:36  Lr: 0.001875  Loss: -1.3012  Acc@1: 87.5000 (80.4290)  Acc@5: 100.0000 (96.4443)  time: 0.3499  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1090/3750]  eta: 0:15:33  Lr: 0.001875  Loss: -1.2844  Acc@1: 87.5000 (80.4766)  Acc@5: 100.0000 (96.4711)  time: 0.3505  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1100/3750]  eta: 0:15:29  Lr: 0.001875  Loss: -1.0178  Acc@1: 87.5000 (80.5064)  Acc@5: 100.0000 (96.4748)  time: 0.3502  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1110/3750]  eta: 0:15:26  Lr: 0.001875  Loss: -1.3782  Acc@1: 81.2500 (80.5018)  Acc@5: 93.7500 (96.4671)  time: 0.3490  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1120/3750]  eta: 0:15:22  Lr: 0.001875  Loss: -0.7829  Acc@1: 81.2500 (80.5140)  Acc@5: 100.0000 (96.4652)  time: 0.3494  data: 0.0011  max mem: 2500
Train: Epoch[2/5]  [1130/3750]  eta: 0:15:19  Lr: 0.001875  Loss: -0.7197  Acc@1: 81.2500 (80.4985)  Acc@5: 100.0000 (96.4688)  time: 0.3508  data: 0.0017  max mem: 2500
Train: Epoch[2/5]  [1140/3750]  eta: 0:15:15  Lr: 0.001875  Loss: -0.6911  Acc@1: 75.0000 (80.4941)  Acc@5: 100.0000 (96.4833)  time: 0.3508  data: 0.0012  max mem: 2500
Train: Epoch[2/5]  [1150/3750]  eta: 0:15:12  Lr: 0.001875  Loss: -0.5707  Acc@1: 81.2500 (80.5278)  Acc@5: 100.0000 (96.4922)  time: 0.3501  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [1160/3750]  eta: 0:15:08  Lr: 0.001875  Loss: -0.5929  Acc@1: 81.2500 (80.4963)  Acc@5: 100.0000 (96.5062)  time: 0.3502  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1170/3750]  eta: 0:15:04  Lr: 0.001875  Loss: -1.4028  Acc@1: 81.2500 (80.4974)  Acc@5: 100.0000 (96.5041)  time: 0.3494  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1180/3750]  eta: 0:15:01  Lr: 0.001875  Loss: -1.0370  Acc@1: 87.5000 (80.5567)  Acc@5: 100.0000 (96.5125)  time: 0.3500  data: 0.0012  max mem: 2500
Train: Epoch[2/5]  [1190/3750]  eta: 0:14:57  Lr: 0.001875  Loss: -0.7648  Acc@1: 87.5000 (80.6150)  Acc@5: 100.0000 (96.5313)  time: 0.3504  data: 0.0013  max mem: 2500
Train: Epoch[2/5]  [1200/3750]  eta: 0:14:54  Lr: 0.001875  Loss: -0.6739  Acc@1: 81.2500 (80.6151)  Acc@5: 100.0000 (96.5341)  time: 0.3516  data: 0.0011  max mem: 2500
Train: Epoch[2/5]  [1210/3750]  eta: 0:14:51  Lr: 0.001875  Loss: -0.3708  Acc@1: 81.2500 (80.5842)  Acc@5: 100.0000 (96.5370)  time: 0.3526  data: 0.0014  max mem: 2500
Train: Epoch[2/5]  [1220/3750]  eta: 0:14:47  Lr: 0.001875  Loss: -0.7929  Acc@1: 75.0000 (80.5743)  Acc@5: 100.0000 (96.5448)  time: 0.3506  data: 0.0014  max mem: 2500
Train: Epoch[2/5]  [1230/3750]  eta: 0:14:43  Lr: 0.001875  Loss: -0.5998  Acc@1: 75.0000 (80.5697)  Acc@5: 100.0000 (96.5526)  time: 0.3499  data: 0.0010  max mem: 2500
Train: Epoch[2/5]  [1240/3750]  eta: 0:14:40  Lr: 0.001875  Loss: -0.4974  Acc@1: 81.2500 (80.5701)  Acc@5: 100.0000 (96.5502)  time: 0.3512  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1250/3750]  eta: 0:14:36  Lr: 0.001875  Loss: -0.8584  Acc@1: 81.2500 (80.5705)  Acc@5: 93.7500 (96.5528)  time: 0.3520  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [1260/3750]  eta: 0:14:33  Lr: 0.001875  Loss: -0.8690  Acc@1: 81.2500 (80.5561)  Acc@5: 100.0000 (96.5652)  time: 0.3532  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [1270/3750]  eta: 0:14:30  Lr: 0.001875  Loss: -1.3674  Acc@1: 75.0000 (80.5714)  Acc@5: 100.0000 (96.5627)  time: 0.3524  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [1280/3750]  eta: 0:14:26  Lr: 0.001875  Loss: -0.9470  Acc@1: 81.2500 (80.6011)  Acc@5: 93.7500 (96.5603)  time: 0.3504  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [1290/3750]  eta: 0:14:22  Lr: 0.001875  Loss: -0.7902  Acc@1: 75.0000 (80.5335)  Acc@5: 93.7500 (96.5337)  time: 0.3503  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1300/3750]  eta: 0:14:19  Lr: 0.001875  Loss: -1.0286  Acc@1: 75.0000 (80.5582)  Acc@5: 93.7500 (96.5459)  time: 0.3507  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1310/3750]  eta: 0:14:16  Lr: 0.001875  Loss: -1.0803  Acc@1: 81.2500 (80.5826)  Acc@5: 100.0000 (96.5532)  time: 0.3525  data: 0.0012  max mem: 2500
Train: Epoch[2/5]  [1320/3750]  eta: 0:14:12  Lr: 0.001875  Loss: -0.7243  Acc@1: 87.5000 (80.6160)  Acc@5: 100.0000 (96.5462)  time: 0.3515  data: 0.0012  max mem: 2500
Train: Epoch[2/5]  [1330/3750]  eta: 0:14:08  Lr: 0.001875  Loss: -1.2642  Acc@1: 87.5000 (80.6349)  Acc@5: 93.7500 (96.5299)  time: 0.3496  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1340/3750]  eta: 0:14:05  Lr: 0.001875  Loss: -0.4286  Acc@1: 81.2500 (80.6115)  Acc@5: 93.7500 (96.5324)  time: 0.3506  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1350/3750]  eta: 0:14:01  Lr: 0.001875  Loss: -0.9475  Acc@1: 81.2500 (80.6162)  Acc@5: 100.0000 (96.5211)  time: 0.3510  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1360/3750]  eta: 0:13:58  Lr: 0.001875  Loss: -1.3641  Acc@1: 75.0000 (80.6117)  Acc@5: 93.7500 (96.5099)  time: 0.3504  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1370/3750]  eta: 0:13:54  Lr: 0.001875  Loss: -1.1857  Acc@1: 81.2500 (80.6255)  Acc@5: 100.0000 (96.5171)  time: 0.3498  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1380/3750]  eta: 0:13:51  Lr: 0.001875  Loss: -0.6216  Acc@1: 81.2500 (80.5847)  Acc@5: 100.0000 (96.5288)  time: 0.3499  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1390/3750]  eta: 0:13:47  Lr: 0.001875  Loss: -0.7488  Acc@1: 75.0000 (80.5715)  Acc@5: 100.0000 (96.5223)  time: 0.3533  data: 0.0011  max mem: 2500
Train: Epoch[2/5]  [1400/3750]  eta: 0:13:44  Lr: 0.001875  Loss: -0.7285  Acc@1: 81.2500 (80.5853)  Acc@5: 100.0000 (96.5203)  time: 0.3530  data: 0.0011  max mem: 2500
Train: Epoch[2/5]  [1410/3750]  eta: 0:13:40  Lr: 0.001875  Loss: -0.5669  Acc@1: 81.2500 (80.6033)  Acc@5: 100.0000 (96.5273)  time: 0.3493  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1420/3750]  eta: 0:13:37  Lr: 0.001875  Loss: -1.2520  Acc@1: 81.2500 (80.6034)  Acc@5: 100.0000 (96.5209)  time: 0.3506  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1430/3750]  eta: 0:13:33  Lr: 0.001875  Loss: -1.1657  Acc@1: 81.2500 (80.6254)  Acc@5: 100.0000 (96.5234)  time: 0.3524  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [1440/3750]  eta: 0:13:30  Lr: 0.001875  Loss: -1.1942  Acc@1: 81.2500 (80.6558)  Acc@5: 100.0000 (96.5345)  time: 0.3509  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [1450/3750]  eta: 0:13:26  Lr: 0.001875  Loss: -1.2890  Acc@1: 87.5000 (80.6728)  Acc@5: 100.0000 (96.5283)  time: 0.3496  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1460/3750]  eta: 0:13:23  Lr: 0.001875  Loss: -1.3378  Acc@1: 81.2500 (80.6768)  Acc@5: 100.0000 (96.5392)  time: 0.3513  data: 0.0012  max mem: 2500
Train: Epoch[2/5]  [1470/3750]  eta: 0:13:19  Lr: 0.001875  Loss: -1.3308  Acc@1: 75.0000 (80.6424)  Acc@5: 100.0000 (96.5245)  time: 0.3510  data: 0.0013  max mem: 2500
Train: Epoch[2/5]  [1480/3750]  eta: 0:13:16  Lr: 0.001875  Loss: -0.8522  Acc@1: 75.0000 (80.6465)  Acc@5: 93.7500 (96.5184)  time: 0.3505  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [1490/3750]  eta: 0:13:12  Lr: 0.001875  Loss: -1.1379  Acc@1: 81.2500 (80.6673)  Acc@5: 93.7500 (96.5166)  time: 0.3519  data: 0.0014  max mem: 2500
Train: Epoch[2/5]  [1500/3750]  eta: 0:13:09  Lr: 0.001875  Loss: -0.6421  Acc@1: 81.2500 (80.6254)  Acc@5: 93.7500 (96.5065)  time: 0.3509  data: 0.0014  max mem: 2500
Train: Epoch[2/5]  [1510/3750]  eta: 0:13:05  Lr: 0.001875  Loss: -0.9009  Acc@1: 75.0000 (80.6378)  Acc@5: 93.7500 (96.4965)  time: 0.3501  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1520/3750]  eta: 0:13:02  Lr: 0.001875  Loss: -0.6388  Acc@1: 75.0000 (80.6131)  Acc@5: 93.7500 (96.4867)  time: 0.3494  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1530/3750]  eta: 0:12:58  Lr: 0.001875  Loss: -1.1504  Acc@1: 81.2500 (80.6254)  Acc@5: 93.7500 (96.4811)  time: 0.3491  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1540/3750]  eta: 0:12:55  Lr: 0.001875  Loss: -0.9253  Acc@1: 81.2500 (80.6457)  Acc@5: 100.0000 (96.4917)  time: 0.3508  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1550/3750]  eta: 0:12:51  Lr: 0.001875  Loss: -1.1918  Acc@1: 81.2500 (80.6415)  Acc@5: 100.0000 (96.4861)  time: 0.3539  data: 0.0011  max mem: 2500
Train: Epoch[2/5]  [1560/3750]  eta: 0:12:48  Lr: 0.001875  Loss: -1.0014  Acc@1: 81.2500 (80.6454)  Acc@5: 93.7500 (96.4806)  time: 0.3539  data: 0.0011  max mem: 2500
Train: Epoch[2/5]  [1570/3750]  eta: 0:12:44  Lr: 0.001875  Loss: -1.1393  Acc@1: 81.2500 (80.6294)  Acc@5: 93.7500 (96.4792)  time: 0.3518  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1580/3750]  eta: 0:12:41  Lr: 0.001875  Loss: -1.1000  Acc@1: 81.2500 (80.6175)  Acc@5: 100.0000 (96.4738)  time: 0.3508  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1590/3750]  eta: 0:12:37  Lr: 0.001875  Loss: -1.1264  Acc@1: 81.2500 (80.6175)  Acc@5: 100.0000 (96.4763)  time: 0.3505  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1600/3750]  eta: 0:12:34  Lr: 0.001875  Loss: -0.6237  Acc@1: 87.5000 (80.6488)  Acc@5: 100.0000 (96.4827)  time: 0.3501  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1610/3750]  eta: 0:12:30  Lr: 0.001875  Loss: -0.6752  Acc@1: 87.5000 (80.6603)  Acc@5: 100.0000 (96.4773)  time: 0.3496  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1620/3750]  eta: 0:12:27  Lr: 0.001875  Loss: -1.2742  Acc@1: 87.5000 (80.6832)  Acc@5: 100.0000 (96.4759)  time: 0.3499  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1630/3750]  eta: 0:12:23  Lr: 0.001875  Loss: -0.4770  Acc@1: 81.2500 (80.6714)  Acc@5: 93.7500 (96.4707)  time: 0.3502  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [1640/3750]  eta: 0:12:20  Lr: 0.001875  Loss: -0.9179  Acc@1: 81.2500 (80.6597)  Acc@5: 100.0000 (96.4732)  time: 0.3508  data: 0.0015  max mem: 2500
Train: Epoch[2/5]  [1650/3750]  eta: 0:12:16  Lr: 0.001875  Loss: -1.0017  Acc@1: 81.2500 (80.6708)  Acc@5: 100.0000 (96.4794)  time: 0.3513  data: 0.0018  max mem: 2500
Train: Epoch[2/5]  [1660/3750]  eta: 0:12:13  Lr: 0.001875  Loss: -0.8293  Acc@1: 81.2500 (80.6668)  Acc@5: 100.0000 (96.4818)  time: 0.3501  data: 0.0012  max mem: 2500
Train: Epoch[2/5]  [1670/3750]  eta: 0:12:09  Lr: 0.001875  Loss: -0.9510  Acc@1: 81.2500 (80.7002)  Acc@5: 93.7500 (96.4841)  time: 0.3493  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [1680/3750]  eta: 0:12:06  Lr: 0.001875  Loss: -0.4546  Acc@1: 87.5000 (80.7258)  Acc@5: 100.0000 (96.4902)  time: 0.3504  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1690/3750]  eta: 0:12:02  Lr: 0.001875  Loss: -1.2778  Acc@1: 81.2500 (80.7215)  Acc@5: 100.0000 (96.4962)  time: 0.3500  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1700/3750]  eta: 0:11:59  Lr: 0.001875  Loss: -1.0869  Acc@1: 81.2500 (80.7172)  Acc@5: 100.0000 (96.4947)  time: 0.3488  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [1710/3750]  eta: 0:11:55  Lr: 0.001875  Loss: -0.7291  Acc@1: 81.2500 (80.7240)  Acc@5: 100.0000 (96.5042)  time: 0.3489  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [1720/3750]  eta: 0:11:52  Lr: 0.001875  Loss: -1.3139  Acc@1: 81.2500 (80.7488)  Acc@5: 100.0000 (96.5064)  time: 0.3502  data: 0.0012  max mem: 2500
Train: Epoch[2/5]  [1730/3750]  eta: 0:11:48  Lr: 0.001875  Loss: -1.0100  Acc@1: 87.5000 (80.7734)  Acc@5: 93.7500 (96.4941)  time: 0.3515  data: 0.0013  max mem: 2500
Train: Epoch[2/5]  [1740/3750]  eta: 0:11:45  Lr: 0.001875  Loss: -0.9798  Acc@1: 81.2500 (80.7582)  Acc@5: 93.7500 (96.4783)  time: 0.3509  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [1750/3750]  eta: 0:11:41  Lr: 0.001875  Loss: -0.7637  Acc@1: 75.0000 (80.7324)  Acc@5: 93.7500 (96.4734)  time: 0.3522  data: 0.0015  max mem: 2500
Train: Epoch[2/5]  [1760/3750]  eta: 0:11:38  Lr: 0.001875  Loss: -1.2186  Acc@1: 81.2500 (80.7567)  Acc@5: 93.7500 (96.4722)  time: 0.3519  data: 0.0016  max mem: 2500
Train: Epoch[2/5]  [1770/3750]  eta: 0:11:34  Lr: 0.001875  Loss: -0.9547  Acc@1: 81.2500 (80.7489)  Acc@5: 100.0000 (96.4815)  time: 0.3515  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [1780/3750]  eta: 0:11:31  Lr: 0.001875  Loss: -0.4419  Acc@1: 81.2500 (80.7552)  Acc@5: 100.0000 (96.4732)  time: 0.3534  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [1790/3750]  eta: 0:11:27  Lr: 0.001875  Loss: -0.2403  Acc@1: 75.0000 (80.7161)  Acc@5: 93.7500 (96.4685)  time: 0.3514  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [1800/3750]  eta: 0:11:24  Lr: 0.001875  Loss: -0.9364  Acc@1: 81.2500 (80.7295)  Acc@5: 100.0000 (96.4707)  time: 0.3500  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1810/3750]  eta: 0:11:20  Lr: 0.001875  Loss: -1.0582  Acc@1: 87.5000 (80.7565)  Acc@5: 100.0000 (96.4764)  time: 0.3510  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1820/3750]  eta: 0:11:17  Lr: 0.001875  Loss: -0.6793  Acc@1: 87.5000 (80.7798)  Acc@5: 100.0000 (96.4854)  time: 0.3513  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1830/3750]  eta: 0:11:13  Lr: 0.001875  Loss: -1.1683  Acc@1: 81.2500 (80.7994)  Acc@5: 100.0000 (96.4944)  time: 0.3512  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1840/3750]  eta: 0:11:10  Lr: 0.001875  Loss: -1.2291  Acc@1: 87.5000 (80.8256)  Acc@5: 100.0000 (96.4999)  time: 0.3516  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [1850/3750]  eta: 0:11:06  Lr: 0.001875  Loss: -0.8624  Acc@1: 81.2500 (80.8110)  Acc@5: 100.0000 (96.5019)  time: 0.3518  data: 0.0011  max mem: 2500
Train: Epoch[2/5]  [1860/3750]  eta: 0:11:03  Lr: 0.001875  Loss: -0.8670  Acc@1: 75.0000 (80.7899)  Acc@5: 100.0000 (96.4938)  time: 0.3515  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [1870/3750]  eta: 0:10:59  Lr: 0.001875  Loss: -0.9411  Acc@1: 81.2500 (80.8124)  Acc@5: 100.0000 (96.4892)  time: 0.3518  data: 0.0010  max mem: 2500
Train: Epoch[2/5]  [1880/3750]  eta: 0:10:56  Lr: 0.001875  Loss: -0.7881  Acc@1: 81.2500 (80.8114)  Acc@5: 100.0000 (96.4946)  time: 0.3512  data: 0.0009  max mem: 2500
Train: Epoch[2/5]  [1890/3750]  eta: 0:10:52  Lr: 0.001875  Loss: -1.2333  Acc@1: 75.0000 (80.7939)  Acc@5: 100.0000 (96.4900)  time: 0.3501  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1900/3750]  eta: 0:10:49  Lr: 0.001875  Loss: -1.0929  Acc@1: 81.2500 (80.8226)  Acc@5: 100.0000 (96.4887)  time: 0.3494  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1910/3750]  eta: 0:10:45  Lr: 0.001875  Loss: -0.8190  Acc@1: 81.2500 (80.8379)  Acc@5: 93.7500 (96.4907)  time: 0.3497  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1920/3750]  eta: 0:10:41  Lr: 0.001875  Loss: -0.7315  Acc@1: 75.0000 (80.8108)  Acc@5: 93.7500 (96.4830)  time: 0.3494  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1930/3750]  eta: 0:10:38  Lr: 0.001875  Loss: -1.2467  Acc@1: 81.2500 (80.8131)  Acc@5: 93.7500 (96.4882)  time: 0.3489  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1940/3750]  eta: 0:10:34  Lr: 0.001875  Loss: -1.2574  Acc@1: 87.5000 (80.8378)  Acc@5: 100.0000 (96.4902)  time: 0.3503  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1950/3750]  eta: 0:10:31  Lr: 0.001875  Loss: -1.0448  Acc@1: 81.2500 (80.8143)  Acc@5: 93.7500 (96.4826)  time: 0.3504  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [1960/3750]  eta: 0:10:27  Lr: 0.001875  Loss: -1.1097  Acc@1: 75.0000 (80.8229)  Acc@5: 93.7500 (96.4878)  time: 0.3505  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [1970/3750]  eta: 0:10:24  Lr: 0.001875  Loss: -0.6894  Acc@1: 81.2500 (80.8219)  Acc@5: 100.0000 (96.4866)  time: 0.3506  data: 0.0011  max mem: 2500
Train: Epoch[2/5]  [1980/3750]  eta: 0:10:20  Lr: 0.001875  Loss: -1.3364  Acc@1: 75.0000 (80.8051)  Acc@5: 100.0000 (96.4885)  time: 0.3502  data: 0.0010  max mem: 2500
Train: Epoch[2/5]  [1990/3750]  eta: 0:10:17  Lr: 0.001875  Loss: -1.2413  Acc@1: 81.2500 (80.8137)  Acc@5: 93.7500 (96.4873)  time: 0.3499  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [2000/3750]  eta: 0:10:13  Lr: 0.001875  Loss: -0.8948  Acc@1: 81.2500 (80.8283)  Acc@5: 100.0000 (96.4924)  time: 0.3506  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [2010/3750]  eta: 0:10:10  Lr: 0.001875  Loss: -1.2164  Acc@1: 81.2500 (80.8398)  Acc@5: 100.0000 (96.4881)  time: 0.3511  data: 0.0013  max mem: 2500
Train: Epoch[2/5]  [2020/3750]  eta: 0:10:06  Lr: 0.001875  Loss: -0.6830  Acc@1: 81.2500 (80.8232)  Acc@5: 93.7500 (96.4838)  time: 0.3497  data: 0.0013  max mem: 2500
Train: Epoch[2/5]  [2030/3750]  eta: 0:10:03  Lr: 0.001875  Loss: -1.1547  Acc@1: 75.0000 (80.8192)  Acc@5: 100.0000 (96.4888)  time: 0.3497  data: 0.0013  max mem: 2500
Train: Epoch[2/5]  [2040/3750]  eta: 0:09:59  Lr: 0.001875  Loss: -0.9720  Acc@1: 75.0000 (80.8274)  Acc@5: 100.0000 (96.4907)  time: 0.3493  data: 0.0013  max mem: 2500
Train: Epoch[2/5]  [2050/3750]  eta: 0:09:56  Lr: 0.001875  Loss: -0.7830  Acc@1: 81.2500 (80.8295)  Acc@5: 100.0000 (96.4834)  time: 0.3495  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2060/3750]  eta: 0:09:52  Lr: 0.001875  Loss: -0.7661  Acc@1: 81.2500 (80.8285)  Acc@5: 93.7500 (96.4853)  time: 0.3509  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [2070/3750]  eta: 0:09:49  Lr: 0.001875  Loss: -0.9929  Acc@1: 81.2500 (80.8426)  Acc@5: 93.7500 (96.4812)  time: 0.3504  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [2080/3750]  eta: 0:09:45  Lr: 0.001875  Loss: -1.0561  Acc@1: 81.2500 (80.8626)  Acc@5: 100.0000 (96.4921)  time: 0.3505  data: 0.0011  max mem: 2500
Train: Epoch[2/5]  [2090/3750]  eta: 0:09:42  Lr: 0.001875  Loss: -1.1146  Acc@1: 81.2500 (80.8584)  Acc@5: 100.0000 (96.4819)  time: 0.3513  data: 0.0013  max mem: 2500
Train: Epoch[2/5]  [2100/3750]  eta: 0:09:38  Lr: 0.001875  Loss: -0.7280  Acc@1: 81.2500 (80.8544)  Acc@5: 93.7500 (96.4808)  time: 0.3511  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [2110/3750]  eta: 0:09:35  Lr: 0.001875  Loss: -0.9370  Acc@1: 81.2500 (80.8622)  Acc@5: 93.7500 (96.4797)  time: 0.3517  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [2120/3750]  eta: 0:09:31  Lr: 0.001875  Loss: -1.0169  Acc@1: 81.2500 (80.8669)  Acc@5: 100.0000 (96.4816)  time: 0.3538  data: 0.0013  max mem: 2500
Train: Epoch[2/5]  [2130/3750]  eta: 0:09:28  Lr: 0.001875  Loss: -0.6697  Acc@1: 81.2500 (80.8805)  Acc@5: 93.7500 (96.4747)  time: 0.3534  data: 0.0012  max mem: 2500
Train: Epoch[2/5]  [2140/3750]  eta: 0:09:24  Lr: 0.001875  Loss: -1.1544  Acc@1: 81.2500 (80.8909)  Acc@5: 100.0000 (96.4853)  time: 0.3511  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [2150/3750]  eta: 0:09:21  Lr: 0.001875  Loss: -0.9363  Acc@1: 81.2500 (80.8781)  Acc@5: 100.0000 (96.4900)  time: 0.3510  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [2160/3750]  eta: 0:09:17  Lr: 0.001875  Loss: -0.9662  Acc@1: 75.0000 (80.8596)  Acc@5: 100.0000 (96.4918)  time: 0.3510  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [2170/3750]  eta: 0:09:14  Lr: 0.001875  Loss: -0.8810  Acc@1: 75.0000 (80.8527)  Acc@5: 100.0000 (96.4936)  time: 0.3502  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [2180/3750]  eta: 0:09:10  Lr: 0.001875  Loss: -1.2931  Acc@1: 81.2500 (80.8803)  Acc@5: 100.0000 (96.5010)  time: 0.3508  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [2190/3750]  eta: 0:09:07  Lr: 0.001875  Loss: -0.9313  Acc@1: 81.2500 (80.8735)  Acc@5: 100.0000 (96.5027)  time: 0.3511  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [2200/3750]  eta: 0:09:03  Lr: 0.001875  Loss: -0.6926  Acc@1: 81.2500 (80.8837)  Acc@5: 100.0000 (96.5101)  time: 0.3501  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [2210/3750]  eta: 0:09:00  Lr: 0.001875  Loss: -1.2975  Acc@1: 87.5000 (80.8995)  Acc@5: 100.0000 (96.5089)  time: 0.3496  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [2220/3750]  eta: 0:08:56  Lr: 0.001875  Loss: -1.1365  Acc@1: 81.2500 (80.9067)  Acc@5: 93.7500 (96.5021)  time: 0.3497  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [2230/3750]  eta: 0:08:53  Lr: 0.001875  Loss: -1.0834  Acc@1: 81.2500 (80.8970)  Acc@5: 100.0000 (96.5094)  time: 0.3500  data: 0.0009  max mem: 2500
Train: Epoch[2/5]  [2240/3750]  eta: 0:08:49  Lr: 0.001875  Loss: -0.6352  Acc@1: 75.0000 (80.8874)  Acc@5: 100.0000 (96.5083)  time: 0.3497  data: 0.0009  max mem: 2500
Train: Epoch[2/5]  [2250/3750]  eta: 0:08:46  Lr: 0.001875  Loss: -1.1175  Acc@1: 81.2500 (80.8807)  Acc@5: 100.0000 (96.5127)  time: 0.3494  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [2260/3750]  eta: 0:08:42  Lr: 0.001875  Loss: -0.9140  Acc@1: 81.2500 (80.8934)  Acc@5: 100.0000 (96.5060)  time: 0.3500  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [2270/3750]  eta: 0:08:39  Lr: 0.001875  Loss: -1.3001  Acc@1: 81.2500 (80.8950)  Acc@5: 93.7500 (96.4993)  time: 0.3506  data: 0.0016  max mem: 2500
Train: Epoch[2/5]  [2280/3750]  eta: 0:08:35  Lr: 0.001875  Loss: -1.3198  Acc@1: 81.2500 (80.8801)  Acc@5: 93.7500 (96.4928)  time: 0.3503  data: 0.0014  max mem: 2500
Train: Epoch[2/5]  [2290/3750]  eta: 0:08:32  Lr: 0.001875  Loss: -0.5714  Acc@1: 75.0000 (80.8490)  Acc@5: 93.7500 (96.4835)  time: 0.3497  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [2300/3750]  eta: 0:08:28  Lr: 0.001875  Loss: -0.8485  Acc@1: 75.0000 (80.8453)  Acc@5: 100.0000 (96.4879)  time: 0.3490  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [2310/3750]  eta: 0:08:25  Lr: 0.001875  Loss: -1.0058  Acc@1: 75.0000 (80.8389)  Acc@5: 100.0000 (96.4869)  time: 0.3492  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [2320/3750]  eta: 0:08:21  Lr: 0.001875  Loss: -1.3836  Acc@1: 75.0000 (80.8380)  Acc@5: 100.0000 (96.4940)  time: 0.3512  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [2330/3750]  eta: 0:08:18  Lr: 0.001875  Loss: -0.0331  Acc@1: 75.0000 (80.8398)  Acc@5: 93.7500 (96.4768)  time: 0.3515  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [2340/3750]  eta: 0:08:14  Lr: 0.001875  Loss: -0.7856  Acc@1: 81.2500 (80.8389)  Acc@5: 93.7500 (96.4785)  time: 0.3499  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [2350/3750]  eta: 0:08:11  Lr: 0.001875  Loss: -1.2313  Acc@1: 81.2500 (80.8406)  Acc@5: 93.7500 (96.4722)  time: 0.3497  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [2360/3750]  eta: 0:08:07  Lr: 0.001875  Loss: -1.2333  Acc@1: 81.2500 (80.8609)  Acc@5: 93.7500 (96.4740)  time: 0.3495  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [2370/3750]  eta: 0:08:04  Lr: 0.001875  Loss: -1.0244  Acc@1: 87.5000 (80.8625)  Acc@5: 100.0000 (96.4756)  time: 0.3497  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2380/3750]  eta: 0:08:00  Lr: 0.001875  Loss: -1.0527  Acc@1: 81.2500 (80.8589)  Acc@5: 100.0000 (96.4694)  time: 0.3505  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2390/3750]  eta: 0:07:57  Lr: 0.001875  Loss: -1.0087  Acc@1: 81.2500 (80.8867)  Acc@5: 100.0000 (96.4790)  time: 0.3502  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2400/3750]  eta: 0:07:53  Lr: 0.001875  Loss: -0.8167  Acc@1: 81.2500 (80.8673)  Acc@5: 100.0000 (96.4754)  time: 0.3502  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [2410/3750]  eta: 0:07:49  Lr: 0.001875  Loss: -1.3905  Acc@1: 81.2500 (80.8793)  Acc@5: 93.7500 (96.4719)  time: 0.3498  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [2420/3750]  eta: 0:07:46  Lr: 0.001875  Loss: -0.3815  Acc@1: 87.5000 (80.8783)  Acc@5: 100.0000 (96.4761)  time: 0.3489  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [2430/3750]  eta: 0:07:42  Lr: 0.001875  Loss: -1.0125  Acc@1: 81.2500 (80.8721)  Acc@5: 100.0000 (96.4778)  time: 0.3503  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2440/3750]  eta: 0:07:39  Lr: 0.001875  Loss: -1.1494  Acc@1: 81.2500 (80.8736)  Acc@5: 93.7500 (96.4717)  time: 0.3520  data: 0.0015  max mem: 2500
Train: Epoch[2/5]  [2450/3750]  eta: 0:07:35  Lr: 0.001875  Loss: -1.0848  Acc@1: 81.2500 (80.8497)  Acc@5: 93.7500 (96.4657)  time: 0.3525  data: 0.0019  max mem: 2500
Train: Epoch[2/5]  [2460/3750]  eta: 0:07:32  Lr: 0.001875  Loss: -1.1223  Acc@1: 81.2500 (80.8614)  Acc@5: 100.0000 (96.4750)  time: 0.3522  data: 0.0009  max mem: 2500
Train: Epoch[2/5]  [2470/3750]  eta: 0:07:28  Lr: 0.001875  Loss: -1.1235  Acc@1: 81.2500 (80.8529)  Acc@5: 100.0000 (96.4690)  time: 0.3510  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [2480/3750]  eta: 0:07:25  Lr: 0.001875  Loss: -0.9191  Acc@1: 81.2500 (80.8545)  Acc@5: 93.7500 (96.4656)  time: 0.3516  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [2490/3750]  eta: 0:07:21  Lr: 0.001875  Loss: -0.7510  Acc@1: 75.0000 (80.8360)  Acc@5: 100.0000 (96.4723)  time: 0.3526  data: 0.0013  max mem: 2500
Train: Epoch[2/5]  [2500/3750]  eta: 0:07:18  Lr: 0.001875  Loss: -1.3568  Acc@1: 75.0000 (80.8377)  Acc@5: 100.0000 (96.4739)  time: 0.3513  data: 0.0011  max mem: 2500
Train: Epoch[2/5]  [2510/3750]  eta: 0:07:14  Lr: 0.001875  Loss: -0.8148  Acc@1: 75.0000 (80.8294)  Acc@5: 93.7500 (96.4680)  time: 0.3508  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [2520/3750]  eta: 0:07:11  Lr: 0.001875  Loss: -1.1400  Acc@1: 75.0000 (80.8261)  Acc@5: 93.7500 (96.4672)  time: 0.3528  data: 0.0009  max mem: 2500
Train: Epoch[2/5]  [2530/3750]  eta: 0:07:07  Lr: 0.001875  Loss: -0.9302  Acc@1: 81.2500 (80.8401)  Acc@5: 93.7500 (96.4713)  time: 0.3524  data: 0.0010  max mem: 2500
Train: Epoch[2/5]  [2540/3750]  eta: 0:07:04  Lr: 0.001875  Loss: -1.2263  Acc@1: 81.2500 (80.8417)  Acc@5: 100.0000 (96.4778)  time: 0.3524  data: 0.0020  max mem: 2500
Train: Epoch[2/5]  [2550/3750]  eta: 0:07:00  Lr: 0.001875  Loss: -0.4634  Acc@1: 81.2500 (80.8555)  Acc@5: 100.0000 (96.4818)  time: 0.3532  data: 0.0019  max mem: 2500
Train: Epoch[2/5]  [2560/3750]  eta: 0:06:57  Lr: 0.001875  Loss: -0.9166  Acc@1: 81.2500 (80.8473)  Acc@5: 100.0000 (96.4735)  time: 0.3527  data: 0.0012  max mem: 2500
Train: Epoch[2/5]  [2570/3750]  eta: 0:06:53  Lr: 0.001875  Loss: -1.2874  Acc@1: 81.2500 (80.8440)  Acc@5: 93.7500 (96.4751)  time: 0.3528  data: 0.0013  max mem: 2500
Train: Epoch[2/5]  [2580/3750]  eta: 0:06:50  Lr: 0.001875  Loss: -1.3019  Acc@1: 81.2500 (80.8504)  Acc@5: 100.0000 (96.4791)  time: 0.3523  data: 0.0013  max mem: 2500
Train: Epoch[2/5]  [2590/3750]  eta: 0:06:46  Lr: 0.001875  Loss: -0.9998  Acc@1: 81.2500 (80.8592)  Acc@5: 100.0000 (96.4830)  time: 0.3525  data: 0.0020  max mem: 2500
Train: Epoch[2/5]  [2600/3750]  eta: 0:06:43  Lr: 0.001875  Loss: -0.5982  Acc@1: 81.2500 (80.8511)  Acc@5: 100.0000 (96.4821)  time: 0.3513  data: 0.0014  max mem: 2500
Train: Epoch[2/5]  [2610/3750]  eta: 0:06:39  Lr: 0.001875  Loss: -1.4006  Acc@1: 81.2500 (80.8694)  Acc@5: 100.0000 (96.4812)  time: 0.3497  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [2620/3750]  eta: 0:06:36  Lr: 0.001875  Loss: -0.6352  Acc@1: 81.2500 (80.8637)  Acc@5: 93.7500 (96.4827)  time: 0.3498  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [2630/3750]  eta: 0:06:32  Lr: 0.001875  Loss: -1.1195  Acc@1: 81.2500 (80.8557)  Acc@5: 100.0000 (96.4842)  time: 0.3507  data: 0.0009  max mem: 2500
Train: Epoch[2/5]  [2640/3750]  eta: 0:06:29  Lr: 0.001875  Loss: -0.7314  Acc@1: 81.2500 (80.8548)  Acc@5: 100.0000 (96.4857)  time: 0.3503  data: 0.0009  max mem: 2500
Train: Epoch[2/5]  [2650/3750]  eta: 0:06:25  Lr: 0.001875  Loss: -1.0010  Acc@1: 75.0000 (80.8492)  Acc@5: 100.0000 (96.4848)  time: 0.3501  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [2660/3750]  eta: 0:06:22  Lr: 0.001875  Loss: -0.9411  Acc@1: 81.2500 (80.8648)  Acc@5: 100.0000 (96.4933)  time: 0.3514  data: 0.0014  max mem: 2500
Train: Epoch[2/5]  [2670/3750]  eta: 0:06:18  Lr: 0.001875  Loss: -0.8391  Acc@1: 87.5000 (80.8920)  Acc@5: 100.0000 (96.5018)  time: 0.3509  data: 0.0011  max mem: 2500
Train: Epoch[2/5]  [2680/3750]  eta: 0:06:15  Lr: 0.001875  Loss: -0.7093  Acc@1: 81.2500 (80.8793)  Acc@5: 100.0000 (96.5032)  time: 0.3488  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [2690/3750]  eta: 0:06:11  Lr: 0.001875  Loss: -1.1737  Acc@1: 81.2500 (80.8807)  Acc@5: 100.0000 (96.5046)  time: 0.3492  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2700/3750]  eta: 0:06:08  Lr: 0.001875  Loss: -0.8983  Acc@1: 81.2500 (80.8890)  Acc@5: 100.0000 (96.5082)  time: 0.3503  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [2710/3750]  eta: 0:06:04  Lr: 0.001875  Loss: -1.3479  Acc@1: 87.5000 (80.9157)  Acc@5: 100.0000 (96.5073)  time: 0.3499  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [2720/3750]  eta: 0:06:01  Lr: 0.001875  Loss: -1.1187  Acc@1: 87.5000 (80.9146)  Acc@5: 93.7500 (96.5017)  time: 0.3512  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [2730/3750]  eta: 0:05:57  Lr: 0.001875  Loss: -1.1575  Acc@1: 81.2500 (80.9205)  Acc@5: 100.0000 (96.5054)  time: 0.3507  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [2740/3750]  eta: 0:05:54  Lr: 0.001875  Loss: -1.2659  Acc@1: 81.2500 (80.9262)  Acc@5: 100.0000 (96.5113)  time: 0.3487  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [2750/3750]  eta: 0:05:50  Lr: 0.001875  Loss: -0.6458  Acc@1: 81.2500 (80.9251)  Acc@5: 100.0000 (96.5035)  time: 0.3489  data: 0.0011  max mem: 2500
Train: Epoch[2/5]  [2760/3750]  eta: 0:05:47  Lr: 0.001875  Loss: -0.5442  Acc@1: 81.2500 (80.9240)  Acc@5: 93.7500 (96.5072)  time: 0.3492  data: 0.0012  max mem: 2500
Train: Epoch[2/5]  [2770/3750]  eta: 0:05:43  Lr: 0.001875  Loss: -1.3009  Acc@1: 87.5000 (80.9410)  Acc@5: 100.0000 (96.5085)  time: 0.3496  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [2780/3750]  eta: 0:05:40  Lr: 0.001875  Loss: -0.9216  Acc@1: 81.2500 (80.9444)  Acc@5: 93.7500 (96.5008)  time: 0.3488  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [2790/3750]  eta: 0:05:36  Lr: 0.001875  Loss: -1.4127  Acc@1: 81.2500 (80.9656)  Acc@5: 93.7500 (96.5044)  time: 0.3472  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [2800/3750]  eta: 0:05:33  Lr: 0.001875  Loss: -0.8211  Acc@1: 87.5000 (80.9711)  Acc@5: 100.0000 (96.5102)  time: 0.3493  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [2810/3750]  eta: 0:05:29  Lr: 0.001875  Loss: -1.3482  Acc@1: 81.2500 (80.9921)  Acc@5: 100.0000 (96.5137)  time: 0.3505  data: 0.0013  max mem: 2500
Train: Epoch[2/5]  [2820/3750]  eta: 0:05:26  Lr: 0.001875  Loss: -1.1437  Acc@1: 81.2500 (80.9952)  Acc@5: 100.0000 (96.5216)  time: 0.3489  data: 0.0013  max mem: 2500
Train: Epoch[2/5]  [2830/3750]  eta: 0:05:22  Lr: 0.001875  Loss: -1.1088  Acc@1: 81.2500 (81.0005)  Acc@5: 100.0000 (96.5317)  time: 0.3492  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [2840/3750]  eta: 0:05:19  Lr: 0.001875  Loss: -1.0286  Acc@1: 81.2500 (81.0014)  Acc@5: 100.0000 (96.5351)  time: 0.3485  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [2850/3750]  eta: 0:05:15  Lr: 0.001875  Loss: -0.6404  Acc@1: 81.2500 (81.0001)  Acc@5: 100.0000 (96.5319)  time: 0.3491  data: 0.0015  max mem: 2500
Train: Epoch[2/5]  [2860/3750]  eta: 0:05:12  Lr: 0.001875  Loss: -0.7450  Acc@1: 81.2500 (81.0010)  Acc@5: 100.0000 (96.5375)  time: 0.3497  data: 0.0015  max mem: 2500
Train: Epoch[2/5]  [2870/3750]  eta: 0:05:08  Lr: 0.001875  Loss: -0.6734  Acc@1: 75.0000 (80.9801)  Acc@5: 100.0000 (96.5321)  time: 0.3497  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [2880/3750]  eta: 0:05:05  Lr: 0.001875  Loss: -0.5409  Acc@1: 81.2500 (80.9767)  Acc@5: 100.0000 (96.5355)  time: 0.3493  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [2890/3750]  eta: 0:05:01  Lr: 0.001875  Loss: -1.0444  Acc@1: 81.2500 (80.9927)  Acc@5: 100.0000 (96.5410)  time: 0.3492  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [2900/3750]  eta: 0:04:58  Lr: 0.001875  Loss: -0.8830  Acc@1: 81.2500 (80.9807)  Acc@5: 100.0000 (96.5378)  time: 0.3508  data: 0.0012  max mem: 2500
Train: Epoch[2/5]  [2910/3750]  eta: 0:04:54  Lr: 0.001875  Loss: -1.1965  Acc@1: 81.2500 (80.9902)  Acc@5: 93.7500 (96.5368)  time: 0.3497  data: 0.0012  max mem: 2500
Train: Epoch[2/5]  [2920/3750]  eta: 0:04:51  Lr: 0.001875  Loss: -1.0414  Acc@1: 87.5000 (81.0082)  Acc@5: 100.0000 (96.5380)  time: 0.3503  data: 0.0013  max mem: 2500
Train: Epoch[2/5]  [2930/3750]  eta: 0:04:47  Lr: 0.001875  Loss: -0.5715  Acc@1: 87.5000 (80.9984)  Acc@5: 100.0000 (96.5413)  time: 0.3507  data: 0.0015  max mem: 2500
Train: Epoch[2/5]  [2940/3750]  eta: 0:04:44  Lr: 0.001875  Loss: -1.1620  Acc@1: 81.2500 (81.0141)  Acc@5: 100.0000 (96.5424)  time: 0.3506  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [2950/3750]  eta: 0:04:40  Lr: 0.001875  Loss: -1.0263  Acc@1: 87.5000 (81.0255)  Acc@5: 100.0000 (96.5478)  time: 0.3507  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [2960/3750]  eta: 0:04:37  Lr: 0.001875  Loss: -1.0950  Acc@1: 81.2500 (81.0052)  Acc@5: 100.0000 (96.5447)  time: 0.3500  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [2970/3750]  eta: 0:04:33  Lr: 0.001875  Loss: -1.3592  Acc@1: 75.0000 (80.9955)  Acc@5: 93.7500 (96.5416)  time: 0.3502  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [2980/3750]  eta: 0:04:30  Lr: 0.001875  Loss: -1.0686  Acc@1: 75.0000 (80.9879)  Acc@5: 93.7500 (96.5427)  time: 0.3501  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [2990/3750]  eta: 0:04:26  Lr: 0.001875  Loss: -0.9387  Acc@1: 81.2500 (80.9846)  Acc@5: 100.0000 (96.5480)  time: 0.3517  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [3000/3750]  eta: 0:04:23  Lr: 0.001875  Loss: -1.4560  Acc@1: 81.2500 (80.9813)  Acc@5: 100.0000 (96.5470)  time: 0.3512  data: 0.0010  max mem: 2500
Train: Epoch[2/5]  [3010/3750]  eta: 0:04:19  Lr: 0.001875  Loss: -1.1451  Acc@1: 81.2500 (80.9822)  Acc@5: 100.0000 (96.5543)  time: 0.3495  data: 0.0008  max mem: 2500
Train: Epoch[2/5]  [3020/3750]  eta: 0:04:15  Lr: 0.001875  Loss: -0.9963  Acc@1: 81.2500 (80.9914)  Acc@5: 100.0000 (96.5533)  time: 0.3497  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [3030/3750]  eta: 0:04:12  Lr: 0.001875  Loss: -0.8120  Acc@1: 81.2500 (81.0005)  Acc@5: 100.0000 (96.5502)  time: 0.3494  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3040/3750]  eta: 0:04:08  Lr: 0.001875  Loss: -0.9996  Acc@1: 81.2500 (81.0013)  Acc@5: 93.7500 (96.5472)  time: 0.3499  data: 0.0011  max mem: 2500
Train: Epoch[2/5]  [3050/3750]  eta: 0:04:05  Lr: 0.001875  Loss: -0.9869  Acc@1: 81.2500 (80.9919)  Acc@5: 93.7500 (96.5483)  time: 0.3502  data: 0.0012  max mem: 2500
Train: Epoch[2/5]  [3060/3750]  eta: 0:04:01  Lr: 0.001875  Loss: -1.1073  Acc@1: 81.2500 (80.9948)  Acc@5: 100.0000 (96.5452)  time: 0.3508  data: 0.0014  max mem: 2500
Train: Epoch[2/5]  [3070/3750]  eta: 0:03:58  Lr: 0.001875  Loss: -0.9304  Acc@1: 81.2500 (80.9956)  Acc@5: 93.7500 (96.5402)  time: 0.3508  data: 0.0013  max mem: 2500
Train: Epoch[2/5]  [3080/3750]  eta: 0:03:54  Lr: 0.001875  Loss: -0.8867  Acc@1: 81.2500 (81.0045)  Acc@5: 93.7500 (96.5393)  time: 0.3491  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [3090/3750]  eta: 0:03:51  Lr: 0.001875  Loss: -1.1446  Acc@1: 81.2500 (81.0013)  Acc@5: 100.0000 (96.5424)  time: 0.3514  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [3100/3750]  eta: 0:03:47  Lr: 0.001875  Loss: -1.2745  Acc@1: 75.0000 (80.9799)  Acc@5: 100.0000 (96.5435)  time: 0.3517  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [3110/3750]  eta: 0:03:44  Lr: 0.001875  Loss: -1.2087  Acc@1: 75.0000 (80.9808)  Acc@5: 100.0000 (96.5465)  time: 0.3492  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [3120/3750]  eta: 0:03:40  Lr: 0.001875  Loss: -1.2707  Acc@1: 81.2500 (80.9897)  Acc@5: 100.0000 (96.5516)  time: 0.3498  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [3130/3750]  eta: 0:03:37  Lr: 0.001875  Loss: -1.1462  Acc@1: 87.5000 (81.0045)  Acc@5: 100.0000 (96.5526)  time: 0.3502  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3140/3750]  eta: 0:03:33  Lr: 0.001875  Loss: -0.9830  Acc@1: 87.5000 (81.0033)  Acc@5: 93.7500 (96.5536)  time: 0.3504  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3150/3750]  eta: 0:03:30  Lr: 0.001875  Loss: -0.6671  Acc@1: 81.2500 (81.0001)  Acc@5: 100.0000 (96.5586)  time: 0.3505  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3160/3750]  eta: 0:03:26  Lr: 0.001875  Loss: -0.7946  Acc@1: 87.5000 (81.0147)  Acc@5: 100.0000 (96.5596)  time: 0.3495  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3170/3750]  eta: 0:03:23  Lr: 0.001875  Loss: -0.7531  Acc@1: 81.2500 (81.0174)  Acc@5: 100.0000 (96.5606)  time: 0.3496  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3180/3750]  eta: 0:03:19  Lr: 0.001875  Loss: -0.9798  Acc@1: 81.2500 (81.0221)  Acc@5: 100.0000 (96.5655)  time: 0.3508  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [3190/3750]  eta: 0:03:16  Lr: 0.001875  Loss: -1.0902  Acc@1: 75.0000 (81.0013)  Acc@5: 100.0000 (96.5626)  time: 0.3495  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [3200/3750]  eta: 0:03:12  Lr: 0.001875  Loss: -0.8745  Acc@1: 75.0000 (81.0001)  Acc@5: 93.7500 (96.5597)  time: 0.3507  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [3210/3750]  eta: 0:03:09  Lr: 0.001875  Loss: -0.8824  Acc@1: 81.2500 (81.0047)  Acc@5: 100.0000 (96.5645)  time: 0.3504  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [3220/3750]  eta: 0:03:05  Lr: 0.001875  Loss: -1.2609  Acc@1: 81.2500 (81.0075)  Acc@5: 100.0000 (96.5655)  time: 0.3488  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [3230/3750]  eta: 0:03:02  Lr: 0.001875  Loss: -1.3360  Acc@1: 81.2500 (81.0159)  Acc@5: 100.0000 (96.5645)  time: 0.3494  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [3240/3750]  eta: 0:02:58  Lr: 0.001875  Loss: -0.8725  Acc@1: 81.2500 (81.0070)  Acc@5: 100.0000 (96.5655)  time: 0.3498  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [3250/3750]  eta: 0:02:55  Lr: 0.001875  Loss: -1.2240  Acc@1: 75.0000 (81.0001)  Acc@5: 93.7500 (96.5626)  time: 0.3503  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [3260/3750]  eta: 0:02:51  Lr: 0.001875  Loss: -0.8724  Acc@1: 75.0000 (80.9836)  Acc@5: 93.7500 (96.5616)  time: 0.3495  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [3270/3750]  eta: 0:02:48  Lr: 0.001875  Loss: -1.2509  Acc@1: 75.0000 (80.9825)  Acc@5: 100.0000 (96.5645)  time: 0.3493  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [3280/3750]  eta: 0:02:44  Lr: 0.001875  Loss: -1.2535  Acc@1: 81.2500 (81.0024)  Acc@5: 100.0000 (96.5712)  time: 0.3507  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [3290/3750]  eta: 0:02:41  Lr: 0.001875  Loss: -0.3205  Acc@1: 87.5000 (81.0050)  Acc@5: 100.0000 (96.5683)  time: 0.3511  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [3300/3750]  eta: 0:02:37  Lr: 0.001875  Loss: -1.0041  Acc@1: 81.2500 (81.0076)  Acc@5: 100.0000 (96.5673)  time: 0.3499  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [3310/3750]  eta: 0:02:34  Lr: 0.001875  Loss: -0.7012  Acc@1: 75.0000 (80.9895)  Acc@5: 93.7500 (96.5569)  time: 0.3504  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [3320/3750]  eta: 0:02:30  Lr: 0.001875  Loss: -1.1752  Acc@1: 81.2500 (81.0053)  Acc@5: 100.0000 (96.5617)  time: 0.3513  data: 0.0010  max mem: 2500
Train: Epoch[2/5]  [3330/3750]  eta: 0:02:27  Lr: 0.001875  Loss: -1.2802  Acc@1: 81.2500 (80.9967)  Acc@5: 100.0000 (96.5645)  time: 0.3513  data: 0.0010  max mem: 2500
Train: Epoch[2/5]  [3340/3750]  eta: 0:02:23  Lr: 0.001875  Loss: -1.1523  Acc@1: 81.2500 (80.9844)  Acc@5: 100.0000 (96.5635)  time: 0.3499  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [3350/3750]  eta: 0:02:20  Lr: 0.001875  Loss: -0.8657  Acc@1: 81.2500 (80.9907)  Acc@5: 93.7500 (96.5589)  time: 0.3497  data: 0.0010  max mem: 2500
Train: Epoch[2/5]  [3360/3750]  eta: 0:02:16  Lr: 0.001875  Loss: -0.7836  Acc@1: 75.0000 (80.9841)  Acc@5: 100.0000 (96.5617)  time: 0.3506  data: 0.0010  max mem: 2500
Train: Epoch[2/5]  [3370/3750]  eta: 0:02:13  Lr: 0.001875  Loss: -0.7641  Acc@1: 81.2500 (80.9849)  Acc@5: 100.0000 (96.5626)  time: 0.3520  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [3380/3750]  eta: 0:02:09  Lr: 0.001875  Loss: -0.6333  Acc@1: 81.2500 (80.9746)  Acc@5: 100.0000 (96.5635)  time: 0.3520  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [3390/3750]  eta: 0:02:06  Lr: 0.001875  Loss: -1.0989  Acc@1: 81.2500 (80.9975)  Acc@5: 93.7500 (96.5626)  time: 0.3502  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [3400/3750]  eta: 0:02:02  Lr: 0.001875  Loss: -1.1202  Acc@1: 87.5000 (80.9927)  Acc@5: 100.0000 (96.5635)  time: 0.3496  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [3410/3750]  eta: 0:01:59  Lr: 0.001875  Loss: -1.0005  Acc@1: 81.2500 (80.9971)  Acc@5: 100.0000 (96.5644)  time: 0.3498  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [3420/3750]  eta: 0:01:55  Lr: 0.001875  Loss: -0.4868  Acc@1: 81.2500 (80.9942)  Acc@5: 100.0000 (96.5653)  time: 0.3496  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [3430/3750]  eta: 0:01:52  Lr: 0.001875  Loss: -0.9813  Acc@1: 81.2500 (80.9859)  Acc@5: 93.7500 (96.5626)  time: 0.3491  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [3440/3750]  eta: 0:01:48  Lr: 0.001875  Loss: -1.0023  Acc@1: 81.2500 (80.9921)  Acc@5: 93.7500 (96.5580)  time: 0.3517  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3450/3750]  eta: 0:01:45  Lr: 0.001875  Loss: -0.9545  Acc@1: 81.2500 (80.9892)  Acc@5: 93.7500 (96.5608)  time: 0.3524  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3460/3750]  eta: 0:01:41  Lr: 0.001875  Loss: -0.9157  Acc@1: 81.2500 (80.9972)  Acc@5: 100.0000 (96.5689)  time: 0.3494  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [3470/3750]  eta: 0:01:38  Lr: 0.001875  Loss: -1.0936  Acc@1: 87.5000 (81.0123)  Acc@5: 100.0000 (96.5752)  time: 0.3497  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [3480/3750]  eta: 0:01:34  Lr: 0.001875  Loss: -1.1626  Acc@1: 87.5000 (81.0256)  Acc@5: 100.0000 (96.5761)  time: 0.3517  data: 0.0006  max mem: 2500
Train: Epoch[2/5]  [3490/3750]  eta: 0:01:31  Lr: 0.001875  Loss: -0.4056  Acc@1: 75.0000 (81.0101)  Acc@5: 93.7500 (96.5680)  time: 0.3518  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [3500/3750]  eta: 0:01:27  Lr: 0.001875  Loss: -0.7785  Acc@1: 75.0000 (81.0001)  Acc@5: 100.0000 (96.5706)  time: 0.3501  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [3510/3750]  eta: 0:01:24  Lr: 0.001875  Loss: -1.1336  Acc@1: 75.0000 (80.9990)  Acc@5: 100.0000 (96.5661)  time: 0.3492  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [3520/3750]  eta: 0:01:20  Lr: 0.001875  Loss: -0.9760  Acc@1: 81.2500 (80.9997)  Acc@5: 100.0000 (96.5741)  time: 0.3492  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [3530/3750]  eta: 0:01:17  Lr: 0.001875  Loss: -0.7311  Acc@1: 81.2500 (81.0004)  Acc@5: 100.0000 (96.5732)  time: 0.3491  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [3540/3750]  eta: 0:01:13  Lr: 0.001875  Loss: -0.6318  Acc@1: 81.2500 (80.9994)  Acc@5: 100.0000 (96.5758)  time: 0.3487  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3550/3750]  eta: 0:01:10  Lr: 0.001875  Loss: -0.9127  Acc@1: 87.5000 (81.0142)  Acc@5: 100.0000 (96.5731)  time: 0.3481  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3560/3750]  eta: 0:01:06  Lr: 0.001875  Loss: -1.1710  Acc@1: 87.5000 (81.0201)  Acc@5: 93.7500 (96.5705)  time: 0.3487  data: 0.0014  max mem: 2500
Train: Epoch[2/5]  [3570/3750]  eta: 0:01:03  Lr: 0.001875  Loss: -1.2142  Acc@1: 87.5000 (81.0295)  Acc@5: 100.0000 (96.5731)  time: 0.3503  data: 0.0016  max mem: 2500
Train: Epoch[2/5]  [3580/3750]  eta: 0:00:59  Lr: 0.001875  Loss: -0.9281  Acc@1: 81.2500 (81.0179)  Acc@5: 100.0000 (96.5652)  time: 0.3493  data: 0.0007  max mem: 2500
Train: Epoch[2/5]  [3590/3750]  eta: 0:00:56  Lr: 0.001875  Loss: -0.5388  Acc@1: 81.2500 (81.0237)  Acc@5: 93.7500 (96.5608)  time: 0.3484  data: 0.0012  max mem: 2500
Train: Epoch[2/5]  [3600/3750]  eta: 0:00:52  Lr: 0.001875  Loss: -1.0351  Acc@1: 81.2500 (81.0244)  Acc@5: 100.0000 (96.5652)  time: 0.3493  data: 0.0012  max mem: 2500
Train: Epoch[2/5]  [3610/3750]  eta: 0:00:49  Lr: 0.001875  Loss: -1.0710  Acc@1: 81.2500 (81.0336)  Acc@5: 100.0000 (96.5747)  time: 0.3492  data: 0.0009  max mem: 2500
Train: Epoch[2/5]  [3620/3750]  eta: 0:00:45  Lr: 0.001875  Loss: -1.1765  Acc@1: 81.2500 (81.0360)  Acc@5: 100.0000 (96.5704)  time: 0.3494  data: 0.0009  max mem: 2500
Train: Epoch[2/5]  [3630/3750]  eta: 0:00:42  Lr: 0.001875  Loss: -1.2427  Acc@1: 81.2500 (81.0400)  Acc@5: 100.0000 (96.5729)  time: 0.3496  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [3640/3750]  eta: 0:00:38  Lr: 0.001875  Loss: -0.8106  Acc@1: 81.2500 (81.0423)  Acc@5: 100.0000 (96.5755)  time: 0.3489  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [3650/3750]  eta: 0:00:35  Lr: 0.001875  Loss: -1.3076  Acc@1: 81.2500 (81.0377)  Acc@5: 100.0000 (96.5763)  time: 0.3492  data: 0.0011  max mem: 2500
Train: Epoch[2/5]  [3660/3750]  eta: 0:00:31  Lr: 0.001875  Loss: -0.8186  Acc@1: 87.5000 (81.0417)  Acc@5: 100.0000 (96.5822)  time: 0.3486  data: 0.0010  max mem: 2500
Train: Epoch[2/5]  [3670/3750]  eta: 0:00:28  Lr: 0.001875  Loss: -0.8159  Acc@1: 87.5000 (81.0389)  Acc@5: 100.0000 (96.5796)  time: 0.3480  data: 0.0005  max mem: 2500
Train: Epoch[2/5]  [3680/3750]  eta: 0:00:24  Lr: 0.001875  Loss: -1.0015  Acc@1: 81.2500 (81.0395)  Acc@5: 93.7500 (96.5719)  time: 0.3492  data: 0.0012  max mem: 2500
Train: Epoch[2/5]  [3690/3750]  eta: 0:00:21  Lr: 0.001875  Loss: -0.9300  Acc@1: 87.5000 (81.0502)  Acc@5: 100.0000 (96.5778)  time: 0.3497  data: 0.0018  max mem: 2500
Train: Epoch[2/5]  [3700/3750]  eta: 0:00:17  Lr: 0.001875  Loss: -0.5361  Acc@1: 81.2500 (81.0355)  Acc@5: 100.0000 (96.5719)  time: 0.3491  data: 0.0011  max mem: 2500
Train: Epoch[2/5]  [3710/3750]  eta: 0:00:14  Lr: 0.001875  Loss: -1.0922  Acc@1: 81.2500 (81.0395)  Acc@5: 93.7500 (96.5710)  time: 0.3490  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3720/3750]  eta: 0:00:10  Lr: 0.001875  Loss: -1.1630  Acc@1: 81.2500 (81.0216)  Acc@5: 93.7500 (96.5685)  time: 0.3489  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3730/3750]  eta: 0:00:07  Lr: 0.001875  Loss: -0.9378  Acc@1: 81.2500 (81.0255)  Acc@5: 100.0000 (96.5760)  time: 0.3481  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3740/3750]  eta: 0:00:03  Lr: 0.001875  Loss: -1.1572  Acc@1: 81.2500 (81.0328)  Acc@5: 100.0000 (96.5785)  time: 0.3488  data: 0.0004  max mem: 2500
Train: Epoch[2/5]  [3749/3750]  eta: 0:00:00  Lr: 0.001875  Loss: -1.3886  Acc@1: 87.5000 (81.0333)  Acc@5: 100.0000 (96.5767)  time: 0.3494  data: 0.0008  max mem: 2500
Train: Epoch[2/5] Total time: 0:21:55 (0.3507 s / it)
Averaged stats: Lr: 0.001875  Loss: -1.3886  Acc@1: 87.5000 (81.0333)  Acc@5: 100.0000 (96.5767)
Train: Epoch[3/5]  [   0/3750]  eta: 0:42:43  Lr: 0.001875  Loss: -0.6962  Acc@1: 68.7500 (68.7500)  Acc@5: 93.7500 (93.7500)  time: 0.6836  data: 0.3366  max mem: 2500
Train: Epoch[3/5]  [  10/3750]  eta: 0:23:41  Lr: 0.001875  Loss: -1.0194  Acc@1: 87.5000 (86.3636)  Acc@5: 100.0000 (97.1591)  time: 0.3801  data: 0.0309  max mem: 2500
Train: Epoch[3/5]  [  20/3750]  eta: 0:22:45  Lr: 0.001875  Loss: -0.9218  Acc@1: 81.2500 (84.8214)  Acc@5: 100.0000 (97.9167)  time: 0.3502  data: 0.0015  max mem: 2500
Train: Epoch[3/5]  [  30/3750]  eta: 0:22:19  Lr: 0.001875  Loss: -0.8619  Acc@1: 81.2500 (84.2742)  Acc@5: 100.0000 (97.1774)  time: 0.3492  data: 0.0015  max mem: 2500
Train: Epoch[3/5]  [  40/3750]  eta: 0:22:08  Lr: 0.001875  Loss: -1.2592  Acc@1: 81.2500 (82.7744)  Acc@5: 100.0000 (97.1037)  time: 0.3497  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [  50/3750]  eta: 0:21:58  Lr: 0.001875  Loss: -0.6165  Acc@1: 81.2500 (82.4755)  Acc@5: 100.0000 (97.4265)  time: 0.3504  data: 0.0011  max mem: 2500
Train: Epoch[3/5]  [  60/3750]  eta: 0:21:49  Lr: 0.001875  Loss: -0.9948  Acc@1: 81.2500 (82.9918)  Acc@5: 100.0000 (97.4385)  time: 0.3486  data: 0.0011  max mem: 2500
Train: Epoch[3/5]  [  70/3750]  eta: 0:21:43  Lr: 0.001875  Loss: -0.2870  Acc@1: 81.2500 (82.5704)  Acc@5: 100.0000 (97.0951)  time: 0.3484  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [  80/3750]  eta: 0:21:37  Lr: 0.001875  Loss: -1.1749  Acc@1: 81.2500 (82.8704)  Acc@5: 93.7500 (96.8364)  time: 0.3487  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [  90/3750]  eta: 0:21:32  Lr: 0.001875  Loss: -1.1945  Acc@1: 81.2500 (82.4863)  Acc@5: 93.7500 (96.8407)  time: 0.3492  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [ 100/3750]  eta: 0:21:26  Lr: 0.001875  Loss: -0.9525  Acc@1: 81.2500 (82.4876)  Acc@5: 100.0000 (96.9059)  time: 0.3489  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [ 110/3750]  eta: 0:21:21  Lr: 0.001875  Loss: -1.1988  Acc@1: 87.5000 (82.7703)  Acc@5: 100.0000 (96.9595)  time: 0.3479  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 120/3750]  eta: 0:21:17  Lr: 0.001875  Loss: -0.8257  Acc@1: 81.2500 (82.2831)  Acc@5: 100.0000 (96.7459)  time: 0.3482  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 130/3750]  eta: 0:21:13  Lr: 0.001875  Loss: -0.9684  Acc@1: 75.0000 (82.1565)  Acc@5: 93.7500 (96.7080)  time: 0.3495  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 140/3750]  eta: 0:21:08  Lr: 0.001875  Loss: -0.5696  Acc@1: 81.2500 (82.0922)  Acc@5: 100.0000 (96.7642)  time: 0.3490  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [ 150/3750]  eta: 0:21:04  Lr: 0.001875  Loss: -1.1456  Acc@1: 81.2500 (82.2020)  Acc@5: 100.0000 (96.7715)  time: 0.3486  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 160/3750]  eta: 0:21:01  Lr: 0.001875  Loss: -1.0555  Acc@1: 81.2500 (81.8711)  Acc@5: 93.7500 (96.6227)  time: 0.3503  data: 0.0013  max mem: 2500
Train: Epoch[3/5]  [ 170/3750]  eta: 0:20:57  Lr: 0.001875  Loss: -1.3841  Acc@1: 81.2500 (81.8713)  Acc@5: 100.0000 (96.7836)  time: 0.3504  data: 0.0015  max mem: 2500
Train: Epoch[3/5]  [ 180/3750]  eta: 0:20:53  Lr: 0.001875  Loss: -1.2392  Acc@1: 81.2500 (81.9061)  Acc@5: 100.0000 (96.8232)  time: 0.3491  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [ 190/3750]  eta: 0:20:49  Lr: 0.001875  Loss: -0.7299  Acc@1: 81.2500 (81.6427)  Acc@5: 93.7500 (96.7277)  time: 0.3486  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [ 200/3750]  eta: 0:20:45  Lr: 0.001875  Loss: -0.6532  Acc@1: 75.0000 (81.7164)  Acc@5: 93.7500 (96.7973)  time: 0.3485  data: 0.0010  max mem: 2500
Train: Epoch[3/5]  [ 210/3750]  eta: 0:20:41  Lr: 0.001875  Loss: -1.2994  Acc@1: 81.2500 (81.7536)  Acc@5: 100.0000 (96.7417)  time: 0.3491  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [ 220/3750]  eta: 0:20:37  Lr: 0.001875  Loss: -1.2853  Acc@1: 81.2500 (81.9287)  Acc@5: 100.0000 (96.8326)  time: 0.3498  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [ 230/3750]  eta: 0:20:34  Lr: 0.001875  Loss: -0.7494  Acc@1: 87.5000 (81.9535)  Acc@5: 100.0000 (96.8615)  time: 0.3489  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 240/3750]  eta: 0:20:30  Lr: 0.001875  Loss: -1.3724  Acc@1: 81.2500 (82.0799)  Acc@5: 93.7500 (96.8361)  time: 0.3495  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 250/3750]  eta: 0:20:26  Lr: 0.001875  Loss: -1.1295  Acc@1: 87.5000 (82.1713)  Acc@5: 93.7500 (96.8376)  time: 0.3495  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 260/3750]  eta: 0:20:23  Lr: 0.001875  Loss: -1.2047  Acc@1: 81.2500 (81.9205)  Acc@5: 93.7500 (96.6715)  time: 0.3493  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 270/3750]  eta: 0:20:19  Lr: 0.001875  Loss: -1.2565  Acc@1: 75.0000 (81.8035)  Acc@5: 93.7500 (96.6559)  time: 0.3508  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 280/3750]  eta: 0:20:16  Lr: 0.001875  Loss: -1.4055  Acc@1: 81.2500 (81.8505)  Acc@5: 100.0000 (96.6637)  time: 0.3515  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 290/3750]  eta: 0:20:12  Lr: 0.001875  Loss: -1.3622  Acc@1: 81.2500 (81.8514)  Acc@5: 100.0000 (96.6710)  time: 0.3499  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 300/3750]  eta: 0:20:09  Lr: 0.001875  Loss: -1.3406  Acc@1: 81.2500 (81.9145)  Acc@5: 100.0000 (96.6570)  time: 0.3488  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [ 310/3750]  eta: 0:20:05  Lr: 0.001875  Loss: -0.8452  Acc@1: 81.2500 (81.8328)  Acc@5: 100.0000 (96.6640)  time: 0.3496  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [ 320/3750]  eta: 0:20:01  Lr: 0.001875  Loss: -0.9637  Acc@1: 81.2500 (81.7952)  Acc@5: 100.0000 (96.6706)  time: 0.3494  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [ 330/3750]  eta: 0:19:58  Lr: 0.001875  Loss: -0.6625  Acc@1: 81.2500 (81.7032)  Acc@5: 93.7500 (96.6201)  time: 0.3494  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 340/3750]  eta: 0:19:54  Lr: 0.001875  Loss: -1.1861  Acc@1: 81.2500 (81.6349)  Acc@5: 93.7500 (96.6276)  time: 0.3494  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 350/3750]  eta: 0:19:50  Lr: 0.001875  Loss: -0.8297  Acc@1: 81.2500 (81.6952)  Acc@5: 100.0000 (96.6524)  time: 0.3487  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [ 360/3750]  eta: 0:19:47  Lr: 0.001875  Loss: -0.9732  Acc@1: 81.2500 (81.7348)  Acc@5: 100.0000 (96.6413)  time: 0.3500  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [ 370/3750]  eta: 0:19:44  Lr: 0.001875  Loss: -0.7930  Acc@1: 81.2500 (81.7722)  Acc@5: 100.0000 (96.7150)  time: 0.3509  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [ 380/3750]  eta: 0:19:40  Lr: 0.001875  Loss: -0.8866  Acc@1: 81.2500 (81.7421)  Acc@5: 100.0000 (96.6864)  time: 0.3505  data: 0.0012  max mem: 2500
Train: Epoch[3/5]  [ 390/3750]  eta: 0:19:37  Lr: 0.001875  Loss: -1.1758  Acc@1: 81.2500 (81.8254)  Acc@5: 100.0000 (96.7231)  time: 0.3503  data: 0.0012  max mem: 2500
Train: Epoch[3/5]  [ 400/3750]  eta: 0:19:33  Lr: 0.001875  Loss: -1.2972  Acc@1: 87.5000 (81.9670)  Acc@5: 100.0000 (96.7737)  time: 0.3514  data: 0.0011  max mem: 2500
Train: Epoch[3/5]  [ 410/3750]  eta: 0:19:30  Lr: 0.001875  Loss: -1.2470  Acc@1: 87.5000 (81.9951)  Acc@5: 100.0000 (96.7609)  time: 0.3516  data: 0.0011  max mem: 2500
Train: Epoch[3/5]  [ 420/3750]  eta: 0:19:26  Lr: 0.001875  Loss: -1.1026  Acc@1: 87.5000 (82.0368)  Acc@5: 100.0000 (96.7785)  time: 0.3501  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 430/3750]  eta: 0:19:23  Lr: 0.001875  Loss: -1.1034  Acc@1: 87.5000 (82.0766)  Acc@5: 100.0000 (96.7807)  time: 0.3497  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 440/3750]  eta: 0:19:19  Lr: 0.001875  Loss: -0.6803  Acc@1: 87.5000 (82.1570)  Acc@5: 100.0000 (96.7545)  time: 0.3494  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 450/3750]  eta: 0:19:16  Lr: 0.001875  Loss: -1.0979  Acc@1: 81.2500 (82.0676)  Acc@5: 100.0000 (96.7849)  time: 0.3502  data: 0.0018  max mem: 2500
Train: Epoch[3/5]  [ 460/3750]  eta: 0:19:12  Lr: 0.001875  Loss: -1.0476  Acc@1: 81.2500 (82.0092)  Acc@5: 100.0000 (96.7055)  time: 0.3501  data: 0.0018  max mem: 2500
Train: Epoch[3/5]  [ 470/3750]  eta: 0:19:09  Lr: 0.001875  Loss: -0.7127  Acc@1: 75.0000 (81.9135)  Acc@5: 93.7500 (96.6693)  time: 0.3499  data: 0.0010  max mem: 2500
Train: Epoch[3/5]  [ 480/3750]  eta: 0:19:05  Lr: 0.001875  Loss: -1.1110  Acc@1: 81.2500 (82.0166)  Acc@5: 100.0000 (96.7126)  time: 0.3497  data: 0.0010  max mem: 2500
Train: Epoch[3/5]  [ 490/3750]  eta: 0:19:01  Lr: 0.001875  Loss: -1.1845  Acc@1: 81.2500 (82.0647)  Acc@5: 100.0000 (96.7541)  time: 0.3489  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 500/3750]  eta: 0:18:58  Lr: 0.001875  Loss: -1.1214  Acc@1: 81.2500 (82.1357)  Acc@5: 100.0000 (96.7939)  time: 0.3500  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [ 510/3750]  eta: 0:18:54  Lr: 0.001875  Loss: -0.6165  Acc@1: 81.2500 (82.2040)  Acc@5: 100.0000 (96.8077)  time: 0.3497  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [ 520/3750]  eta: 0:18:51  Lr: 0.001875  Loss: -0.9020  Acc@1: 81.2500 (82.1257)  Acc@5: 100.0000 (96.8570)  time: 0.3499  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 530/3750]  eta: 0:18:47  Lr: 0.001875  Loss: -0.9106  Acc@1: 75.0000 (82.0151)  Acc@5: 100.0000 (96.8456)  time: 0.3508  data: 0.0015  max mem: 2500
Train: Epoch[3/5]  [ 540/3750]  eta: 0:18:44  Lr: 0.001875  Loss: -1.1046  Acc@1: 81.2500 (82.0125)  Acc@5: 100.0000 (96.8461)  time: 0.3513  data: 0.0016  max mem: 2500
Train: Epoch[3/5]  [ 550/3750]  eta: 0:18:41  Lr: 0.001875  Loss: -1.2952  Acc@1: 81.2500 (82.0327)  Acc@5: 100.0000 (96.8240)  time: 0.3521  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [ 560/3750]  eta: 0:18:37  Lr: 0.001875  Loss: -1.1092  Acc@1: 87.5000 (82.0744)  Acc@5: 100.0000 (96.8583)  time: 0.3506  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [ 570/3750]  eta: 0:18:33  Lr: 0.001875  Loss: -0.8202  Acc@1: 81.2500 (81.9943)  Acc@5: 100.0000 (96.8476)  time: 0.3492  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 580/3750]  eta: 0:18:30  Lr: 0.001875  Loss: -1.1389  Acc@1: 81.2500 (81.9923)  Acc@5: 100.0000 (96.8696)  time: 0.3500  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [ 590/3750]  eta: 0:18:26  Lr: 0.001875  Loss: -0.7873  Acc@1: 81.2500 (81.9480)  Acc@5: 100.0000 (96.8803)  time: 0.3505  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [ 600/3750]  eta: 0:18:23  Lr: 0.001875  Loss: -0.8330  Acc@1: 81.2500 (81.9364)  Acc@5: 100.0000 (96.9218)  time: 0.3500  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [ 610/3750]  eta: 0:18:19  Lr: 0.001875  Loss: -0.7518  Acc@1: 75.0000 (81.8433)  Acc@5: 100.0000 (96.9108)  time: 0.3503  data: 0.0014  max mem: 2500
Train: Epoch[3/5]  [ 620/3750]  eta: 0:18:16  Lr: 0.001875  Loss: -0.8150  Acc@1: 75.0000 (81.8337)  Acc@5: 100.0000 (96.9203)  time: 0.3508  data: 0.0018  max mem: 2500
Train: Epoch[3/5]  [ 630/3750]  eta: 0:18:12  Lr: 0.001875  Loss: -1.0571  Acc@1: 81.2500 (81.8641)  Acc@5: 100.0000 (96.9394)  time: 0.3504  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [ 640/3750]  eta: 0:18:09  Lr: 0.001875  Loss: -1.0298  Acc@1: 81.2500 (81.7960)  Acc@5: 100.0000 (96.9091)  time: 0.3517  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 650/3750]  eta: 0:18:06  Lr: 0.001875  Loss: -0.4251  Acc@1: 81.2500 (81.7396)  Acc@5: 93.7500 (96.9086)  time: 0.3521  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 660/3750]  eta: 0:18:02  Lr: 0.001875  Loss: -1.1349  Acc@1: 81.2500 (81.7984)  Acc@5: 93.7500 (96.9081)  time: 0.3497  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 670/3750]  eta: 0:17:58  Lr: 0.001875  Loss: -0.7994  Acc@1: 81.2500 (81.7809)  Acc@5: 93.7500 (96.8890)  time: 0.3489  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 680/3750]  eta: 0:17:55  Lr: 0.001875  Loss: -0.6844  Acc@1: 75.0000 (81.6814)  Acc@5: 93.7500 (96.8796)  time: 0.3491  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 690/3750]  eta: 0:17:51  Lr: 0.001875  Loss: -0.8378  Acc@1: 81.2500 (81.6932)  Acc@5: 93.7500 (96.8886)  time: 0.3490  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 700/3750]  eta: 0:17:48  Lr: 0.001875  Loss: -1.2385  Acc@1: 81.2500 (81.7760)  Acc@5: 100.0000 (96.8973)  time: 0.3496  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 710/3750]  eta: 0:17:44  Lr: 0.001875  Loss: -1.3033  Acc@1: 81.2500 (81.7774)  Acc@5: 100.0000 (96.9058)  time: 0.3502  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [ 720/3750]  eta: 0:17:41  Lr: 0.001875  Loss: -1.1561  Acc@1: 81.2500 (81.8048)  Acc@5: 100.0000 (96.8967)  time: 0.3487  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [ 730/3750]  eta: 0:17:37  Lr: 0.001875  Loss: -0.8015  Acc@1: 87.5000 (81.8057)  Acc@5: 100.0000 (96.8793)  time: 0.3493  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 740/3750]  eta: 0:17:34  Lr: 0.001875  Loss: -0.9467  Acc@1: 81.2500 (81.7729)  Acc@5: 100.0000 (96.8877)  time: 0.3498  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 750/3750]  eta: 0:17:30  Lr: 0.001875  Loss: -0.5837  Acc@1: 81.2500 (81.7410)  Acc@5: 100.0000 (96.8792)  time: 0.3500  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 760/3750]  eta: 0:17:27  Lr: 0.001875  Loss: -1.0917  Acc@1: 81.2500 (81.6771)  Acc@5: 93.7500 (96.8298)  time: 0.3520  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [ 770/3750]  eta: 0:17:23  Lr: 0.001875  Loss: -0.7526  Acc@1: 75.0000 (81.6553)  Acc@5: 93.7500 (96.8304)  time: 0.3510  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [ 780/3750]  eta: 0:17:20  Lr: 0.001875  Loss: -0.9855  Acc@1: 81.2500 (81.6421)  Acc@5: 100.0000 (96.8310)  time: 0.3495  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [ 790/3750]  eta: 0:17:16  Lr: 0.001875  Loss: -1.0320  Acc@1: 81.2500 (81.6609)  Acc@5: 100.0000 (96.8473)  time: 0.3495  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 800/3750]  eta: 0:17:13  Lr: 0.001875  Loss: -1.1052  Acc@1: 87.5000 (81.7650)  Acc@5: 100.0000 (96.8789)  time: 0.3490  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 810/3750]  eta: 0:17:09  Lr: 0.001875  Loss: -1.0532  Acc@1: 87.5000 (81.7663)  Acc@5: 100.0000 (96.8866)  time: 0.3495  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 820/3750]  eta: 0:17:06  Lr: 0.001875  Loss: -0.7723  Acc@1: 81.2500 (81.7829)  Acc@5: 100.0000 (96.8788)  time: 0.3499  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [ 830/3750]  eta: 0:17:02  Lr: 0.001875  Loss: -1.0600  Acc@1: 87.5000 (81.8216)  Acc@5: 100.0000 (96.9013)  time: 0.3491  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [ 840/3750]  eta: 0:16:58  Lr: 0.001875  Loss: -0.6055  Acc@1: 81.2500 (81.8297)  Acc@5: 100.0000 (96.9010)  time: 0.3483  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [ 850/3750]  eta: 0:16:55  Lr: 0.001875  Loss: -0.5512  Acc@1: 81.2500 (81.8669)  Acc@5: 93.7500 (96.8860)  time: 0.3497  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [ 860/3750]  eta: 0:16:51  Lr: 0.001875  Loss: -1.2481  Acc@1: 81.2500 (81.8743)  Acc@5: 100.0000 (96.8859)  time: 0.3501  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [ 870/3750]  eta: 0:16:48  Lr: 0.001875  Loss: -1.0843  Acc@1: 81.2500 (81.8384)  Acc@5: 100.0000 (96.8571)  time: 0.3487  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [ 880/3750]  eta: 0:16:44  Lr: 0.001875  Loss: -0.9554  Acc@1: 81.2500 (81.8814)  Acc@5: 100.0000 (96.8856)  time: 0.3496  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 890/3750]  eta: 0:16:41  Lr: 0.001875  Loss: -0.7583  Acc@1: 81.2500 (81.8813)  Acc@5: 100.0000 (96.8645)  time: 0.3513  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [ 900/3750]  eta: 0:16:37  Lr: 0.001875  Loss: -1.0190  Acc@1: 81.2500 (81.8466)  Acc@5: 100.0000 (96.8577)  time: 0.3498  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 910/3750]  eta: 0:16:34  Lr: 0.001875  Loss: -1.0371  Acc@1: 87.5000 (81.9086)  Acc@5: 100.0000 (96.8647)  time: 0.3484  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 920/3750]  eta: 0:16:30  Lr: 0.001875  Loss: -1.1914  Acc@1: 87.5000 (81.8743)  Acc@5: 100.0000 (96.8716)  time: 0.3503  data: 0.0016  max mem: 2500
Train: Epoch[3/5]  [ 930/3750]  eta: 0:16:27  Lr: 0.001875  Loss: -1.1872  Acc@1: 81.2500 (81.8743)  Acc@5: 100.0000 (96.8784)  time: 0.3508  data: 0.0020  max mem: 2500
Train: Epoch[3/5]  [ 940/3750]  eta: 0:16:23  Lr: 0.001875  Loss: -1.1016  Acc@1: 81.2500 (81.8943)  Acc@5: 100.0000 (96.8850)  time: 0.3491  data: 0.0009  max mem: 2500
Train: Epoch[3/5]  [ 950/3750]  eta: 0:16:20  Lr: 0.001875  Loss: -1.1409  Acc@1: 81.2500 (81.9138)  Acc@5: 100.0000 (96.8849)  time: 0.3493  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [ 960/3750]  eta: 0:16:16  Lr: 0.001875  Loss: -1.0695  Acc@1: 87.5000 (81.9394)  Acc@5: 100.0000 (96.8717)  time: 0.3490  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [ 970/3750]  eta: 0:16:13  Lr: 0.001875  Loss: -1.0416  Acc@1: 81.2500 (81.9709)  Acc@5: 100.0000 (96.8718)  time: 0.3501  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 980/3750]  eta: 0:16:09  Lr: 0.001875  Loss: -0.8025  Acc@1: 81.2500 (81.9699)  Acc@5: 100.0000 (96.8591)  time: 0.3510  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [ 990/3750]  eta: 0:16:06  Lr: 0.001875  Loss: -1.4101  Acc@1: 81.2500 (81.9501)  Acc@5: 100.0000 (96.8782)  time: 0.3495  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1000/3750]  eta: 0:16:02  Lr: 0.001875  Loss: -0.8926  Acc@1: 81.2500 (81.9555)  Acc@5: 100.0000 (96.8656)  time: 0.3492  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1010/3750]  eta: 0:15:59  Lr: 0.001875  Loss: -1.2848  Acc@1: 81.2500 (81.9733)  Acc@5: 93.7500 (96.8657)  time: 0.3488  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1020/3750]  eta: 0:15:55  Lr: 0.001875  Loss: -0.7346  Acc@1: 87.5000 (82.0029)  Acc@5: 93.7500 (96.8536)  time: 0.3486  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [1030/3750]  eta: 0:15:52  Lr: 0.001875  Loss: -1.2272  Acc@1: 81.2500 (82.0138)  Acc@5: 93.7500 (96.8538)  time: 0.3478  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1040/3750]  eta: 0:15:48  Lr: 0.001875  Loss: -0.7593  Acc@1: 81.2500 (82.0125)  Acc@5: 100.0000 (96.8840)  time: 0.3474  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [1050/3750]  eta: 0:15:44  Lr: 0.001875  Loss: -0.9130  Acc@1: 81.2500 (82.0231)  Acc@5: 100.0000 (96.8780)  time: 0.3477  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [1060/3750]  eta: 0:15:41  Lr: 0.001875  Loss: -1.2324  Acc@1: 87.5000 (82.0158)  Acc@5: 93.7500 (96.8721)  time: 0.3489  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1070/3750]  eta: 0:15:37  Lr: 0.001875  Loss: -1.0735  Acc@1: 87.5000 (82.0437)  Acc@5: 100.0000 (96.8662)  time: 0.3494  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1080/3750]  eta: 0:15:34  Lr: 0.001875  Loss: -1.1067  Acc@1: 81.2500 (82.0363)  Acc@5: 93.7500 (96.8432)  time: 0.3495  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1090/3750]  eta: 0:15:30  Lr: 0.001875  Loss: -1.3815  Acc@1: 81.2500 (82.0463)  Acc@5: 93.7500 (96.8435)  time: 0.3492  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1100/3750]  eta: 0:15:27  Lr: 0.001875  Loss: -0.9738  Acc@1: 87.5000 (82.0618)  Acc@5: 93.7500 (96.8324)  time: 0.3488  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1110/3750]  eta: 0:15:23  Lr: 0.001875  Loss: -1.1917  Acc@1: 81.2500 (82.0657)  Acc@5: 100.0000 (96.8497)  time: 0.3486  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1120/3750]  eta: 0:15:20  Lr: 0.001875  Loss: -1.3323  Acc@1: 87.5000 (82.1142)  Acc@5: 100.0000 (96.8611)  time: 0.3488  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1130/3750]  eta: 0:15:16  Lr: 0.001875  Loss: -0.9224  Acc@1: 81.2500 (82.0955)  Acc@5: 100.0000 (96.8612)  time: 0.3503  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1140/3750]  eta: 0:15:13  Lr: 0.001875  Loss: -1.1437  Acc@1: 81.2500 (82.1264)  Acc@5: 100.0000 (96.8723)  time: 0.3500  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [1150/3750]  eta: 0:15:09  Lr: 0.001875  Loss: -1.2647  Acc@1: 81.2500 (82.1079)  Acc@5: 100.0000 (96.8669)  time: 0.3492  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [1160/3750]  eta: 0:15:06  Lr: 0.001875  Loss: -1.1671  Acc@1: 81.2500 (82.1113)  Acc@5: 93.7500 (96.8562)  time: 0.3515  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1170/3750]  eta: 0:15:02  Lr: 0.001875  Loss: -1.2051  Acc@1: 81.2500 (82.1146)  Acc@5: 100.0000 (96.8777)  time: 0.3511  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [1180/3750]  eta: 0:14:59  Lr: 0.001875  Loss: -0.9316  Acc@1: 87.5000 (82.1655)  Acc@5: 100.0000 (96.8882)  time: 0.3488  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [1190/3750]  eta: 0:14:55  Lr: 0.001875  Loss: -0.9199  Acc@1: 81.2500 (82.1579)  Acc@5: 100.0000 (96.8881)  time: 0.3490  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [1200/3750]  eta: 0:14:52  Lr: 0.001875  Loss: -0.6154  Acc@1: 81.2500 (82.1451)  Acc@5: 100.0000 (96.8828)  time: 0.3514  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [1210/3750]  eta: 0:14:48  Lr: 0.001875  Loss: -1.3402  Acc@1: 81.2500 (82.1222)  Acc@5: 93.7500 (96.8724)  time: 0.3514  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [1220/3750]  eta: 0:14:45  Lr: 0.001875  Loss: -0.7032  Acc@1: 81.2500 (82.1100)  Acc@5: 100.0000 (96.8776)  time: 0.3496  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [1230/3750]  eta: 0:14:41  Lr: 0.001875  Loss: -1.1308  Acc@1: 81.2500 (82.0725)  Acc@5: 100.0000 (96.8826)  time: 0.3500  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1240/3750]  eta: 0:14:38  Lr: 0.001875  Loss: -1.2392  Acc@1: 81.2500 (82.0911)  Acc@5: 100.0000 (96.8977)  time: 0.3507  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1250/3750]  eta: 0:14:34  Lr: 0.001875  Loss: -1.0047  Acc@1: 81.2500 (82.0544)  Acc@5: 100.0000 (96.8825)  time: 0.3499  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [1260/3750]  eta: 0:14:31  Lr: 0.001875  Loss: -1.1856  Acc@1: 81.2500 (82.0628)  Acc@5: 93.7500 (96.8775)  time: 0.3487  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [1270/3750]  eta: 0:14:27  Lr: 0.001875  Loss: -0.9557  Acc@1: 81.2500 (82.0712)  Acc@5: 93.7500 (96.8430)  time: 0.3491  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [1280/3750]  eta: 0:14:24  Lr: 0.001875  Loss: -1.2907  Acc@1: 81.2500 (82.0648)  Acc@5: 93.7500 (96.8384)  time: 0.3498  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1290/3750]  eta: 0:14:20  Lr: 0.001875  Loss: -1.3079  Acc@1: 81.2500 (82.0536)  Acc@5: 93.7500 (96.8338)  time: 0.3504  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [1300/3750]  eta: 0:14:17  Lr: 0.001875  Loss: -0.6731  Acc@1: 81.2500 (82.0379)  Acc@5: 100.0000 (96.8390)  time: 0.3511  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1310/3750]  eta: 0:14:13  Lr: 0.001875  Loss: -1.2134  Acc@1: 81.2500 (82.0318)  Acc@5: 100.0000 (96.8345)  time: 0.3509  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1320/3750]  eta: 0:14:10  Lr: 0.001875  Loss: -1.0458  Acc@1: 81.2500 (82.0401)  Acc@5: 100.0000 (96.8253)  time: 0.3506  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [1330/3750]  eta: 0:14:06  Lr: 0.001875  Loss: -1.1547  Acc@1: 87.5000 (82.0577)  Acc@5: 100.0000 (96.8398)  time: 0.3503  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [1340/3750]  eta: 0:14:03  Lr: 0.001875  Loss: -0.5521  Acc@1: 81.2500 (82.0703)  Acc@5: 100.0000 (96.8307)  time: 0.3502  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1350/3750]  eta: 0:13:59  Lr: 0.001875  Loss: -0.7640  Acc@1: 81.2500 (82.0365)  Acc@5: 93.7500 (96.8125)  time: 0.3501  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1360/3750]  eta: 0:13:56  Lr: 0.001875  Loss: -0.8774  Acc@1: 81.2500 (82.0353)  Acc@5: 93.7500 (96.8038)  time: 0.3495  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [1370/3750]  eta: 0:13:52  Lr: 0.001875  Loss: -0.8844  Acc@1: 81.2500 (82.0387)  Acc@5: 93.7500 (96.7815)  time: 0.3492  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1380/3750]  eta: 0:13:49  Lr: 0.001875  Loss: -1.1148  Acc@1: 81.2500 (82.0329)  Acc@5: 93.7500 (96.7686)  time: 0.3486  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [1390/3750]  eta: 0:13:45  Lr: 0.001875  Loss: -0.8883  Acc@1: 81.2500 (82.0408)  Acc@5: 93.7500 (96.7694)  time: 0.3489  data: 0.0010  max mem: 2500
Train: Epoch[3/5]  [1400/3750]  eta: 0:13:42  Lr: 0.001875  Loss: -1.1514  Acc@1: 87.5000 (82.0485)  Acc@5: 93.7500 (96.7612)  time: 0.3492  data: 0.0010  max mem: 2500
Train: Epoch[3/5]  [1410/3750]  eta: 0:13:38  Lr: 0.001875  Loss: -1.2008  Acc@1: 81.2500 (82.0252)  Acc@5: 100.0000 (96.7532)  time: 0.3492  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1420/3750]  eta: 0:13:35  Lr: 0.001875  Loss: -1.1271  Acc@1: 81.2500 (82.0197)  Acc@5: 100.0000 (96.7452)  time: 0.3484  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1430/3750]  eta: 0:13:31  Lr: 0.001875  Loss: -1.3621  Acc@1: 81.2500 (82.0318)  Acc@5: 100.0000 (96.7505)  time: 0.3483  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1440/3750]  eta: 0:13:28  Lr: 0.001875  Loss: -0.9371  Acc@1: 81.2500 (82.0437)  Acc@5: 100.0000 (96.7557)  time: 0.3487  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1450/3750]  eta: 0:13:24  Lr: 0.001875  Loss: -1.1595  Acc@1: 81.2500 (82.0469)  Acc@5: 100.0000 (96.7609)  time: 0.3490  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1460/3750]  eta: 0:13:21  Lr: 0.001875  Loss: -1.0845  Acc@1: 81.2500 (82.0585)  Acc@5: 93.7500 (96.7488)  time: 0.3482  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [1470/3750]  eta: 0:13:17  Lr: 0.001875  Loss: -0.8056  Acc@1: 81.2500 (82.0190)  Acc@5: 93.7500 (96.7412)  time: 0.3483  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [1480/3750]  eta: 0:13:14  Lr: 0.001875  Loss: -0.7758  Acc@1: 75.0000 (81.9970)  Acc@5: 93.7500 (96.7463)  time: 0.3489  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1490/3750]  eta: 0:13:10  Lr: 0.001875  Loss: -1.0397  Acc@1: 81.2500 (81.9878)  Acc@5: 100.0000 (96.7471)  time: 0.3477  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1500/3750]  eta: 0:13:07  Lr: 0.001875  Loss: -1.4770  Acc@1: 81.2500 (81.9995)  Acc@5: 100.0000 (96.7480)  time: 0.3483  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [1510/3750]  eta: 0:13:03  Lr: 0.001875  Loss: -0.6189  Acc@1: 81.2500 (81.9945)  Acc@5: 100.0000 (96.7406)  time: 0.3489  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [1520/3750]  eta: 0:13:00  Lr: 0.001875  Loss: -0.9464  Acc@1: 81.2500 (82.0020)  Acc@5: 100.0000 (96.7415)  time: 0.3483  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1530/3750]  eta: 0:12:56  Lr: 0.001875  Loss: -1.0553  Acc@1: 81.2500 (82.0093)  Acc@5: 93.7500 (96.7260)  time: 0.3478  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1540/3750]  eta: 0:12:53  Lr: 0.001875  Loss: -1.2122  Acc@1: 81.2500 (82.0084)  Acc@5: 93.7500 (96.7189)  time: 0.3494  data: 0.0012  max mem: 2500
Train: Epoch[3/5]  [1550/3750]  eta: 0:12:49  Lr: 0.001875  Loss: -1.0855  Acc@1: 81.2500 (82.0035)  Acc@5: 93.7500 (96.7158)  time: 0.3497  data: 0.0012  max mem: 2500
Train: Epoch[3/5]  [1560/3750]  eta: 0:12:46  Lr: 0.001875  Loss: -1.0395  Acc@1: 81.2500 (81.9867)  Acc@5: 100.0000 (96.7249)  time: 0.3485  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1570/3750]  eta: 0:12:42  Lr: 0.001875  Loss: -1.0321  Acc@1: 81.2500 (81.9860)  Acc@5: 100.0000 (96.7298)  time: 0.3493  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1580/3750]  eta: 0:12:39  Lr: 0.001875  Loss: -0.8188  Acc@1: 81.2500 (82.0169)  Acc@5: 100.0000 (96.7347)  time: 0.3492  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1590/3750]  eta: 0:12:35  Lr: 0.001875  Loss: -0.8295  Acc@1: 81.2500 (81.9846)  Acc@5: 100.0000 (96.7473)  time: 0.3486  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1600/3750]  eta: 0:12:32  Lr: 0.001875  Loss: -1.0159  Acc@1: 81.2500 (81.9917)  Acc@5: 100.0000 (96.7442)  time: 0.3492  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1610/3750]  eta: 0:12:28  Lr: 0.001875  Loss: -1.0769  Acc@1: 81.2500 (82.0065)  Acc@5: 100.0000 (96.7412)  time: 0.3500  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [1620/3750]  eta: 0:12:25  Lr: 0.001875  Loss: -0.6139  Acc@1: 87.5000 (82.0288)  Acc@5: 100.0000 (96.7458)  time: 0.3496  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1630/3750]  eta: 0:12:21  Lr: 0.001875  Loss: -1.3610  Acc@1: 87.5000 (82.0586)  Acc@5: 100.0000 (96.7505)  time: 0.3492  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1640/3750]  eta: 0:12:18  Lr: 0.001875  Loss: -0.7519  Acc@1: 81.2500 (82.0498)  Acc@5: 100.0000 (96.7588)  time: 0.3497  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [1650/3750]  eta: 0:12:14  Lr: 0.001875  Loss: -1.0396  Acc@1: 81.2500 (82.0677)  Acc@5: 100.0000 (96.7633)  time: 0.3497  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [1660/3750]  eta: 0:12:11  Lr: 0.001875  Loss: -0.5539  Acc@1: 81.2500 (82.0590)  Acc@5: 93.7500 (96.7565)  time: 0.3485  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1670/3750]  eta: 0:12:07  Lr: 0.001875  Loss: -0.6276  Acc@1: 81.2500 (82.0467)  Acc@5: 93.7500 (96.7460)  time: 0.3495  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [1680/3750]  eta: 0:12:04  Lr: 0.001875  Loss: -0.9383  Acc@1: 87.5000 (82.0457)  Acc@5: 100.0000 (96.7430)  time: 0.3499  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1690/3750]  eta: 0:12:00  Lr: 0.001875  Loss: -0.4479  Acc@1: 87.5000 (82.0483)  Acc@5: 100.0000 (96.7475)  time: 0.3483  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [1700/3750]  eta: 0:11:57  Lr: 0.001875  Loss: -0.6413  Acc@1: 81.2500 (82.0400)  Acc@5: 100.0000 (96.7446)  time: 0.3496  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [1710/3750]  eta: 0:11:53  Lr: 0.001875  Loss: -0.8225  Acc@1: 81.2500 (82.0500)  Acc@5: 93.7500 (96.7453)  time: 0.3502  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [1720/3750]  eta: 0:11:50  Lr: 0.001875  Loss: -0.8212  Acc@1: 81.2500 (82.0635)  Acc@5: 100.0000 (96.7461)  time: 0.3491  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [1730/3750]  eta: 0:11:46  Lr: 0.001875  Loss: -1.3525  Acc@1: 87.5000 (82.0768)  Acc@5: 100.0000 (96.7540)  time: 0.3494  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1740/3750]  eta: 0:11:43  Lr: 0.001875  Loss: -1.1480  Acc@1: 87.5000 (82.0793)  Acc@5: 100.0000 (96.7619)  time: 0.3489  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1750/3750]  eta: 0:11:39  Lr: 0.001875  Loss: -0.9923  Acc@1: 81.2500 (82.0745)  Acc@5: 100.0000 (96.7590)  time: 0.3506  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [1760/3750]  eta: 0:11:36  Lr: 0.001875  Loss: -0.6086  Acc@1: 81.2500 (82.0663)  Acc@5: 100.0000 (96.7561)  time: 0.3520  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [1770/3750]  eta: 0:11:32  Lr: 0.001875  Loss: -1.0249  Acc@1: 81.2500 (82.0582)  Acc@5: 93.7500 (96.7391)  time: 0.3502  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [1780/3750]  eta: 0:11:29  Lr: 0.001875  Loss: -0.8885  Acc@1: 81.2500 (82.0641)  Acc@5: 93.7500 (96.7364)  time: 0.3488  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [1790/3750]  eta: 0:11:25  Lr: 0.001875  Loss: -1.2249  Acc@1: 81.2500 (82.0526)  Acc@5: 93.7500 (96.7372)  time: 0.3483  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [1800/3750]  eta: 0:11:22  Lr: 0.001875  Loss: -1.1701  Acc@1: 81.2500 (82.0586)  Acc@5: 93.7500 (96.7310)  time: 0.3487  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [1810/3750]  eta: 0:11:18  Lr: 0.001875  Loss: -1.1246  Acc@1: 81.2500 (82.0541)  Acc@5: 100.0000 (96.7352)  time: 0.3476  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [1820/3750]  eta: 0:11:14  Lr: 0.001875  Loss: -0.6811  Acc@1: 81.2500 (82.0291)  Acc@5: 100.0000 (96.7291)  time: 0.3481  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [1830/3750]  eta: 0:11:11  Lr: 0.001875  Loss: -1.0985  Acc@1: 75.0000 (81.9839)  Acc@5: 100.0000 (96.7231)  time: 0.3476  data: 0.0010  max mem: 2500
Train: Epoch[3/5]  [1840/3750]  eta: 0:11:07  Lr: 0.001875  Loss: -1.2461  Acc@1: 81.2500 (82.0037)  Acc@5: 93.7500 (96.7171)  time: 0.3472  data: 0.0012  max mem: 2500
Train: Epoch[3/5]  [1850/3750]  eta: 0:11:04  Lr: 0.001875  Loss: -1.0758  Acc@1: 87.5000 (82.0334)  Acc@5: 100.0000 (96.7180)  time: 0.3482  data: 0.0010  max mem: 2500
Train: Epoch[3/5]  [1860/3750]  eta: 0:11:00  Lr: 0.001875  Loss: -0.6406  Acc@1: 87.5000 (82.0325)  Acc@5: 100.0000 (96.7121)  time: 0.3485  data: 0.0009  max mem: 2500
Train: Epoch[3/5]  [1870/3750]  eta: 0:10:57  Lr: 0.001875  Loss: -1.3665  Acc@1: 87.5000 (82.0484)  Acc@5: 100.0000 (96.7230)  time: 0.3482  data: 0.0009  max mem: 2500
Train: Epoch[3/5]  [1880/3750]  eta: 0:10:53  Lr: 0.001875  Loss: -0.6999  Acc@1: 81.2500 (82.0408)  Acc@5: 100.0000 (96.7205)  time: 0.3470  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1890/3750]  eta: 0:10:50  Lr: 0.001875  Loss: -1.1258  Acc@1: 81.2500 (82.0598)  Acc@5: 100.0000 (96.7279)  time: 0.3476  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [1900/3750]  eta: 0:10:46  Lr: 0.001875  Loss: -1.2068  Acc@1: 87.5000 (82.0522)  Acc@5: 100.0000 (96.7320)  time: 0.3499  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [1910/3750]  eta: 0:10:43  Lr: 0.001875  Loss: -0.9614  Acc@1: 81.2500 (82.0709)  Acc@5: 100.0000 (96.7196)  time: 0.3500  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1920/3750]  eta: 0:10:39  Lr: 0.001875  Loss: -1.0863  Acc@1: 81.2500 (82.0504)  Acc@5: 93.7500 (96.7140)  time: 0.3486  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [1930/3750]  eta: 0:10:36  Lr: 0.001875  Loss: -0.6233  Acc@1: 81.2500 (82.0333)  Acc@5: 100.0000 (96.7148)  time: 0.3487  data: 0.0015  max mem: 2500
Train: Epoch[3/5]  [1940/3750]  eta: 0:10:32  Lr: 0.001875  Loss: -1.3010  Acc@1: 87.5000 (82.0614)  Acc@5: 100.0000 (96.7253)  time: 0.3487  data: 0.0011  max mem: 2500
Train: Epoch[3/5]  [1950/3750]  eta: 0:10:29  Lr: 0.001875  Loss: -0.8252  Acc@1: 87.5000 (82.0541)  Acc@5: 100.0000 (96.7228)  time: 0.3500  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1960/3750]  eta: 0:10:25  Lr: 0.001875  Loss: -1.2523  Acc@1: 81.2500 (82.0532)  Acc@5: 100.0000 (96.7300)  time: 0.3499  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [1970/3750]  eta: 0:10:22  Lr: 0.001875  Loss: -1.1208  Acc@1: 81.2500 (82.0523)  Acc@5: 100.0000 (96.7339)  time: 0.3488  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [1980/3750]  eta: 0:10:18  Lr: 0.001875  Loss: -1.3463  Acc@1: 81.2500 (82.0514)  Acc@5: 100.0000 (96.7378)  time: 0.3503  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [1990/3750]  eta: 0:10:15  Lr: 0.001875  Loss: -0.9681  Acc@1: 81.2500 (82.0411)  Acc@5: 100.0000 (96.7384)  time: 0.3504  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [2000/3750]  eta: 0:10:11  Lr: 0.001875  Loss: -1.2217  Acc@1: 81.2500 (82.0558)  Acc@5: 100.0000 (96.7391)  time: 0.3491  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2010/3750]  eta: 0:10:08  Lr: 0.001875  Loss: -0.7355  Acc@1: 87.5000 (82.0829)  Acc@5: 100.0000 (96.7429)  time: 0.3496  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [2020/3750]  eta: 0:10:04  Lr: 0.001875  Loss: -1.1448  Acc@1: 87.5000 (82.0943)  Acc@5: 100.0000 (96.7528)  time: 0.3506  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2030/3750]  eta: 0:10:01  Lr: 0.001875  Loss: -1.3725  Acc@1: 87.5000 (82.1147)  Acc@5: 100.0000 (96.7565)  time: 0.3504  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2040/3750]  eta: 0:09:57  Lr: 0.001875  Loss: -1.3769  Acc@1: 87.5000 (82.1411)  Acc@5: 100.0000 (96.7632)  time: 0.3506  data: 0.0014  max mem: 2500
Train: Epoch[3/5]  [2050/3750]  eta: 0:09:54  Lr: 0.001875  Loss: -1.0161  Acc@1: 87.5000 (82.1459)  Acc@5: 100.0000 (96.7668)  time: 0.3515  data: 0.0024  max mem: 2500
Train: Epoch[3/5]  [2060/3750]  eta: 0:09:50  Lr: 0.001875  Loss: -0.7147  Acc@1: 81.2500 (82.1294)  Acc@5: 93.7500 (96.7582)  time: 0.3506  data: 0.0014  max mem: 2500
Train: Epoch[3/5]  [2070/3750]  eta: 0:09:47  Lr: 0.001875  Loss: -0.8793  Acc@1: 75.0000 (82.1161)  Acc@5: 93.7500 (96.7467)  time: 0.3494  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2080/3750]  eta: 0:09:43  Lr: 0.001875  Loss: -0.7193  Acc@1: 75.0000 (82.0939)  Acc@5: 93.7500 (96.7444)  time: 0.3504  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2090/3750]  eta: 0:09:40  Lr: 0.001875  Loss: -1.1439  Acc@1: 81.2500 (82.0929)  Acc@5: 100.0000 (96.7450)  time: 0.3507  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [2100/3750]  eta: 0:09:36  Lr: 0.001875  Loss: -1.0963  Acc@1: 81.2500 (82.0829)  Acc@5: 100.0000 (96.7307)  time: 0.3491  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2110/3750]  eta: 0:09:33  Lr: 0.001875  Loss: -0.4427  Acc@1: 81.2500 (82.0671)  Acc@5: 93.7500 (96.7225)  time: 0.3510  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [2120/3750]  eta: 0:09:30  Lr: 0.001875  Loss: -1.3438  Acc@1: 87.5000 (82.0928)  Acc@5: 93.7500 (96.7321)  time: 0.3515  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2130/3750]  eta: 0:09:26  Lr: 0.001875  Loss: -0.7264  Acc@1: 81.2500 (82.0829)  Acc@5: 100.0000 (96.7210)  time: 0.3486  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [2140/3750]  eta: 0:09:22  Lr: 0.001875  Loss: -0.9514  Acc@1: 81.2500 (82.0791)  Acc@5: 93.7500 (96.7217)  time: 0.3480  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [2150/3750]  eta: 0:09:19  Lr: 0.001875  Loss: -1.1965  Acc@1: 81.2500 (82.0810)  Acc@5: 100.0000 (96.7283)  time: 0.3483  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [2160/3750]  eta: 0:09:15  Lr: 0.001875  Loss: -0.6148  Acc@1: 81.2500 (82.0656)  Acc@5: 100.0000 (96.7261)  time: 0.3484  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2170/3750]  eta: 0:09:12  Lr: 0.001875  Loss: -1.4003  Acc@1: 81.2500 (82.0647)  Acc@5: 100.0000 (96.7239)  time: 0.3487  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2180/3750]  eta: 0:09:09  Lr: 0.001875  Loss: -1.1982  Acc@1: 81.2500 (82.0724)  Acc@5: 100.0000 (96.7331)  time: 0.3511  data: 0.0011  max mem: 2500
Train: Epoch[3/5]  [2190/3750]  eta: 0:09:05  Lr: 0.001875  Loss: -1.0438  Acc@1: 81.2500 (82.0744)  Acc@5: 100.0000 (96.7281)  time: 0.3514  data: 0.0019  max mem: 2500
Train: Epoch[3/5]  [2200/3750]  eta: 0:09:01  Lr: 0.001875  Loss: -0.9756  Acc@1: 81.2500 (82.0536)  Acc@5: 93.7500 (96.7146)  time: 0.3485  data: 0.0012  max mem: 2500
Train: Epoch[3/5]  [2210/3750]  eta: 0:08:58  Lr: 0.001875  Loss: -0.6947  Acc@1: 81.2500 (82.0528)  Acc@5: 93.7500 (96.7096)  time: 0.3482  data: 0.0003  max mem: 2500
Train: Epoch[3/5]  [2220/3750]  eta: 0:08:54  Lr: 0.001875  Loss: -1.0699  Acc@1: 81.2500 (82.0492)  Acc@5: 93.7500 (96.7160)  time: 0.3492  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2230/3750]  eta: 0:08:51  Lr: 0.001875  Loss: -1.0078  Acc@1: 81.2500 (82.0372)  Acc@5: 93.7500 (96.7027)  time: 0.3503  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [2240/3750]  eta: 0:08:48  Lr: 0.001875  Loss: -0.8939  Acc@1: 81.2500 (82.0476)  Acc@5: 93.7500 (96.7063)  time: 0.3500  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [2250/3750]  eta: 0:08:44  Lr: 0.001875  Loss: -0.6920  Acc@1: 81.2500 (82.0274)  Acc@5: 100.0000 (96.7070)  time: 0.3491  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2260/3750]  eta: 0:08:41  Lr: 0.001875  Loss: -1.5201  Acc@1: 81.2500 (82.0516)  Acc@5: 100.0000 (96.7050)  time: 0.3489  data: 0.0012  max mem: 2500
Train: Epoch[3/5]  [2270/3750]  eta: 0:08:37  Lr: 0.001875  Loss: -0.4939  Acc@1: 81.2500 (82.0454)  Acc@5: 100.0000 (96.7140)  time: 0.3497  data: 0.0012  max mem: 2500
Train: Epoch[3/5]  [2280/3750]  eta: 0:08:34  Lr: 0.001875  Loss: -0.5187  Acc@1: 75.0000 (82.0199)  Acc@5: 100.0000 (96.7037)  time: 0.3522  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [2290/3750]  eta: 0:08:30  Lr: 0.001875  Loss: -0.5594  Acc@1: 75.0000 (81.9975)  Acc@5: 100.0000 (96.7127)  time: 0.3510  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2300/3750]  eta: 0:08:27  Lr: 0.001875  Loss: -1.0732  Acc@1: 81.2500 (82.0024)  Acc@5: 100.0000 (96.7025)  time: 0.3493  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [2310/3750]  eta: 0:08:23  Lr: 0.001875  Loss: -0.8397  Acc@1: 81.2500 (81.9802)  Acc@5: 100.0000 (96.7033)  time: 0.3515  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [2320/3750]  eta: 0:08:20  Lr: 0.001875  Loss: -1.1778  Acc@1: 81.2500 (81.9717)  Acc@5: 100.0000 (96.7067)  time: 0.3520  data: 0.0011  max mem: 2500
Train: Epoch[3/5]  [2330/3750]  eta: 0:08:16  Lr: 0.001875  Loss: -1.0375  Acc@1: 81.2500 (81.9713)  Acc@5: 93.7500 (96.7047)  time: 0.3511  data: 0.0009  max mem: 2500
Train: Epoch[3/5]  [2340/3750]  eta: 0:08:13  Lr: 0.001875  Loss: -1.1969  Acc@1: 87.5000 (81.9869)  Acc@5: 100.0000 (96.7161)  time: 0.3529  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [2350/3750]  eta: 0:08:09  Lr: 0.001875  Loss: -1.0693  Acc@1: 87.5000 (81.9997)  Acc@5: 100.0000 (96.7168)  time: 0.3524  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [2360/3750]  eta: 0:08:06  Lr: 0.001875  Loss: -1.0950  Acc@1: 81.2500 (82.0071)  Acc@5: 100.0000 (96.7175)  time: 0.3496  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [2370/3750]  eta: 0:08:02  Lr: 0.001875  Loss: -0.9074  Acc@1: 81.2500 (81.9986)  Acc@5: 93.7500 (96.7155)  time: 0.3493  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2380/3750]  eta: 0:07:59  Lr: 0.001875  Loss: -0.6500  Acc@1: 81.2500 (81.9876)  Acc@5: 93.7500 (96.7136)  time: 0.3504  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [2390/3750]  eta: 0:07:55  Lr: 0.001875  Loss: -0.9369  Acc@1: 81.2500 (81.9976)  Acc@5: 93.7500 (96.7064)  time: 0.3509  data: 0.0010  max mem: 2500
Train: Epoch[3/5]  [2400/3750]  eta: 0:07:52  Lr: 0.001875  Loss: -0.8998  Acc@1: 81.2500 (81.9945)  Acc@5: 93.7500 (96.7045)  time: 0.3501  data: 0.0012  max mem: 2500
Train: Epoch[3/5]  [2410/3750]  eta: 0:07:48  Lr: 0.001875  Loss: -1.4385  Acc@1: 81.2500 (81.9992)  Acc@5: 100.0000 (96.7052)  time: 0.3516  data: 0.0014  max mem: 2500
Train: Epoch[3/5]  [2420/3750]  eta: 0:07:45  Lr: 0.001875  Loss: -1.1526  Acc@1: 81.2500 (82.0064)  Acc@5: 100.0000 (96.7033)  time: 0.3524  data: 0.0015  max mem: 2500
Train: Epoch[3/5]  [2430/3750]  eta: 0:07:41  Lr: 0.001875  Loss: -1.0413  Acc@1: 87.5000 (82.0136)  Acc@5: 100.0000 (96.7066)  time: 0.3503  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [2440/3750]  eta: 0:07:38  Lr: 0.001875  Loss: -1.2272  Acc@1: 81.2500 (82.0053)  Acc@5: 100.0000 (96.7047)  time: 0.3502  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2450/3750]  eta: 0:07:34  Lr: 0.001875  Loss: -1.2252  Acc@1: 81.2500 (82.0099)  Acc@5: 100.0000 (96.7054)  time: 0.3510  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2460/3750]  eta: 0:07:31  Lr: 0.001875  Loss: -1.2257  Acc@1: 81.2500 (82.0195)  Acc@5: 100.0000 (96.7087)  time: 0.3520  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [2470/3750]  eta: 0:07:27  Lr: 0.001875  Loss: -0.2811  Acc@1: 81.2500 (82.0240)  Acc@5: 100.0000 (96.7093)  time: 0.3543  data: 0.0010  max mem: 2500
Train: Epoch[3/5]  [2480/3750]  eta: 0:07:24  Lr: 0.001875  Loss: -1.2575  Acc@1: 87.5000 (82.0486)  Acc@5: 100.0000 (96.7150)  time: 0.3526  data: 0.0009  max mem: 2500
Train: Epoch[3/5]  [2490/3750]  eta: 0:07:20  Lr: 0.001875  Loss: -1.1526  Acc@1: 87.5000 (82.0403)  Acc@5: 100.0000 (96.7232)  time: 0.3512  data: 0.0011  max mem: 2500
Train: Epoch[3/5]  [2500/3750]  eta: 0:07:17  Lr: 0.001875  Loss: -1.1121  Acc@1: 87.5000 (82.0472)  Acc@5: 100.0000 (96.7188)  time: 0.3520  data: 0.0011  max mem: 2500
Train: Epoch[3/5]  [2510/3750]  eta: 0:07:13  Lr: 0.001875  Loss: -1.1532  Acc@1: 81.2500 (82.0266)  Acc@5: 93.7500 (96.7095)  time: 0.3513  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [2520/3750]  eta: 0:07:10  Lr: 0.001875  Loss: -1.0267  Acc@1: 75.0000 (82.0111)  Acc@5: 100.0000 (96.7126)  time: 0.3517  data: 0.0013  max mem: 2500
Train: Epoch[3/5]  [2530/3750]  eta: 0:07:06  Lr: 0.001875  Loss: -0.9991  Acc@1: 81.2500 (82.0056)  Acc@5: 100.0000 (96.7133)  time: 0.3524  data: 0.0013  max mem: 2500
Train: Epoch[3/5]  [2540/3750]  eta: 0:07:03  Lr: 0.001875  Loss: -0.6444  Acc@1: 81.2500 (81.9879)  Acc@5: 100.0000 (96.7139)  time: 0.3518  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2550/3750]  eta: 0:06:59  Lr: 0.001875  Loss: -0.9236  Acc@1: 81.2500 (82.0071)  Acc@5: 100.0000 (96.7145)  time: 0.3510  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [2560/3750]  eta: 0:06:56  Lr: 0.001875  Loss: -1.0529  Acc@1: 87.5000 (82.0261)  Acc@5: 100.0000 (96.7200)  time: 0.3500  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [2570/3750]  eta: 0:06:52  Lr: 0.001875  Loss: -1.1283  Acc@1: 81.2500 (82.0255)  Acc@5: 100.0000 (96.7182)  time: 0.3507  data: 0.0014  max mem: 2500
Train: Epoch[3/5]  [2580/3750]  eta: 0:06:49  Lr: 0.001875  Loss: -1.2838  Acc@1: 81.2500 (82.0297)  Acc@5: 93.7500 (96.7115)  time: 0.3524  data: 0.0015  max mem: 2500
Train: Epoch[3/5]  [2590/3750]  eta: 0:06:45  Lr: 0.001875  Loss: -0.9230  Acc@1: 81.2500 (82.0388)  Acc@5: 100.0000 (96.7146)  time: 0.3525  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [2600/3750]  eta: 0:06:42  Lr: 0.001875  Loss: -1.0796  Acc@1: 81.2500 (82.0430)  Acc@5: 100.0000 (96.7200)  time: 0.3512  data: 0.0011  max mem: 2500
Train: Epoch[3/5]  [2610/3750]  eta: 0:06:38  Lr: 0.001875  Loss: -0.9312  Acc@1: 81.2500 (82.0399)  Acc@5: 100.0000 (96.7254)  time: 0.3509  data: 0.0009  max mem: 2500
Train: Epoch[3/5]  [2620/3750]  eta: 0:06:35  Lr: 0.001875  Loss: -1.0561  Acc@1: 75.0000 (82.0202)  Acc@5: 100.0000 (96.7307)  time: 0.3510  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [2630/3750]  eta: 0:06:31  Lr: 0.001875  Loss: -0.8767  Acc@1: 75.0000 (82.0030)  Acc@5: 100.0000 (96.7242)  time: 0.3514  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [2640/3750]  eta: 0:06:28  Lr: 0.001875  Loss: -0.9066  Acc@1: 81.2500 (82.0097)  Acc@5: 100.0000 (96.7295)  time: 0.3516  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [2650/3750]  eta: 0:06:24  Lr: 0.001875  Loss: -0.8425  Acc@1: 81.2500 (82.0068)  Acc@5: 100.0000 (96.7324)  time: 0.3507  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [2660/3750]  eta: 0:06:21  Lr: 0.001875  Loss: -1.1894  Acc@1: 81.2500 (82.0086)  Acc@5: 100.0000 (96.7329)  time: 0.3518  data: 0.0016  max mem: 2500
Train: Epoch[3/5]  [2670/3750]  eta: 0:06:17  Lr: 0.001875  Loss: -0.4880  Acc@1: 81.2500 (81.9894)  Acc@5: 93.7500 (96.7241)  time: 0.3521  data: 0.0015  max mem: 2500
Train: Epoch[3/5]  [2680/3750]  eta: 0:06:14  Lr: 0.001875  Loss: -0.7317  Acc@1: 81.2500 (82.0007)  Acc@5: 93.7500 (96.7246)  time: 0.3517  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [2690/3750]  eta: 0:06:10  Lr: 0.001875  Loss: -0.5285  Acc@1: 81.2500 (81.9839)  Acc@5: 100.0000 (96.7205)  time: 0.3505  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [2700/3750]  eta: 0:06:07  Lr: 0.001875  Loss: -1.2144  Acc@1: 81.2500 (81.9951)  Acc@5: 100.0000 (96.7188)  time: 0.3498  data: 0.0013  max mem: 2500
Train: Epoch[3/5]  [2710/3750]  eta: 0:06:03  Lr: 0.001875  Loss: -0.9038  Acc@1: 87.5000 (81.9947)  Acc@5: 93.7500 (96.7148)  time: 0.3504  data: 0.0014  max mem: 2500
Train: Epoch[3/5]  [2720/3750]  eta: 0:06:00  Lr: 0.001875  Loss: -1.0462  Acc@1: 81.2500 (81.9919)  Acc@5: 93.7500 (96.7108)  time: 0.3491  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [2730/3750]  eta: 0:05:56  Lr: 0.001875  Loss: -1.0048  Acc@1: 81.2500 (81.9846)  Acc@5: 93.7500 (96.7137)  time: 0.3480  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2740/3750]  eta: 0:05:53  Lr: 0.001875  Loss: -0.6744  Acc@1: 81.2500 (81.9865)  Acc@5: 100.0000 (96.7120)  time: 0.3522  data: 0.0036  max mem: 2500
Train: Epoch[3/5]  [2750/3750]  eta: 0:05:49  Lr: 0.001875  Loss: -0.6605  Acc@1: 81.2500 (81.9747)  Acc@5: 93.7500 (96.7057)  time: 0.3532  data: 0.0044  max mem: 2500
Train: Epoch[3/5]  [2760/3750]  eta: 0:05:46  Lr: 0.001875  Loss: -0.9046  Acc@1: 75.0000 (81.9653)  Acc@5: 93.7500 (96.7018)  time: 0.3501  data: 0.0021  max mem: 2500
Train: Epoch[3/5]  [2770/3750]  eta: 0:05:42  Lr: 0.001875  Loss: -1.1085  Acc@1: 81.2500 (81.9718)  Acc@5: 93.7500 (96.7025)  time: 0.3499  data: 0.0020  max mem: 2500
Train: Epoch[3/5]  [2780/3750]  eta: 0:05:39  Lr: 0.001875  Loss: -1.2696  Acc@1: 87.5000 (81.9849)  Acc@5: 100.0000 (96.7098)  time: 0.3510  data: 0.0013  max mem: 2500
Train: Epoch[3/5]  [2790/3750]  eta: 0:05:35  Lr: 0.001875  Loss: -0.6537  Acc@1: 87.5000 (81.9979)  Acc@5: 100.0000 (96.7126)  time: 0.3520  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [2800/3750]  eta: 0:05:32  Lr: 0.001875  Loss: -1.2783  Acc@1: 87.5000 (82.0109)  Acc@5: 100.0000 (96.7132)  time: 0.3516  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [2810/3750]  eta: 0:05:28  Lr: 0.001875  Loss: -1.4129  Acc@1: 81.2500 (82.0082)  Acc@5: 93.7500 (96.7094)  time: 0.3513  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [2820/3750]  eta: 0:05:25  Lr: 0.001875  Loss: -0.6506  Acc@1: 81.2500 (81.9922)  Acc@5: 93.7500 (96.7055)  time: 0.3507  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [2830/3750]  eta: 0:05:21  Lr: 0.001875  Loss: -0.7732  Acc@1: 81.2500 (82.0028)  Acc@5: 100.0000 (96.7083)  time: 0.3506  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [2840/3750]  eta: 0:05:18  Lr: 0.001875  Loss: -0.6218  Acc@1: 81.2500 (82.0024)  Acc@5: 100.0000 (96.7089)  time: 0.3517  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [2850/3750]  eta: 0:05:14  Lr: 0.001875  Loss: -0.8056  Acc@1: 81.2500 (82.0107)  Acc@5: 100.0000 (96.7095)  time: 0.3509  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [2860/3750]  eta: 0:05:11  Lr: 0.001875  Loss: -0.7806  Acc@1: 81.2500 (82.0015)  Acc@5: 100.0000 (96.7101)  time: 0.3514  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [2870/3750]  eta: 0:05:07  Lr: 0.001875  Loss: -0.6543  Acc@1: 81.2500 (81.9923)  Acc@5: 100.0000 (96.7106)  time: 0.3519  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [2880/3750]  eta: 0:05:04  Lr: 0.001875  Loss: -0.9593  Acc@1: 75.0000 (81.9833)  Acc@5: 100.0000 (96.7134)  time: 0.3525  data: 0.0012  max mem: 2500
Train: Epoch[3/5]  [2890/3750]  eta: 0:05:01  Lr: 0.001875  Loss: -1.0925  Acc@1: 81.2500 (81.9937)  Acc@5: 100.0000 (96.7161)  time: 0.3528  data: 0.0011  max mem: 2500
Train: Epoch[3/5]  [2900/3750]  eta: 0:04:57  Lr: 0.001875  Loss: -1.0483  Acc@1: 87.5000 (81.9933)  Acc@5: 100.0000 (96.7231)  time: 0.3508  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [2910/3750]  eta: 0:04:54  Lr: 0.001875  Loss: -1.0962  Acc@1: 87.5000 (82.0015)  Acc@5: 100.0000 (96.7215)  time: 0.3502  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [2920/3750]  eta: 0:04:50  Lr: 0.001875  Loss: -1.2099  Acc@1: 81.2500 (82.0032)  Acc@5: 93.7500 (96.7177)  time: 0.3501  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [2930/3750]  eta: 0:04:47  Lr: 0.001875  Loss: -1.1627  Acc@1: 81.2500 (81.9985)  Acc@5: 93.7500 (96.7183)  time: 0.3513  data: 0.0011  max mem: 2500
Train: Epoch[3/5]  [2940/3750]  eta: 0:04:43  Lr: 0.001875  Loss: -0.6855  Acc@1: 81.2500 (82.0002)  Acc@5: 93.7500 (96.7146)  time: 0.3517  data: 0.0011  max mem: 2500
Train: Epoch[3/5]  [2950/3750]  eta: 0:04:40  Lr: 0.001875  Loss: -0.9270  Acc@1: 81.2500 (82.0019)  Acc@5: 93.7500 (96.7130)  time: 0.3508  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [2960/3750]  eta: 0:04:36  Lr: 0.001875  Loss: -0.9462  Acc@1: 87.5000 (82.0099)  Acc@5: 93.7500 (96.7135)  time: 0.3514  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [2970/3750]  eta: 0:04:33  Lr: 0.001875  Loss: -1.2219  Acc@1: 87.5000 (82.0178)  Acc@5: 100.0000 (96.7141)  time: 0.3520  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [2980/3750]  eta: 0:04:29  Lr: 0.001875  Loss: -1.2467  Acc@1: 81.2500 (82.0236)  Acc@5: 100.0000 (96.7188)  time: 0.3514  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [2990/3750]  eta: 0:04:26  Lr: 0.001875  Loss: -0.8577  Acc@1: 87.5000 (82.0357)  Acc@5: 100.0000 (96.7214)  time: 0.3517  data: 0.0012  max mem: 2500
Train: Epoch[3/5]  [3000/3750]  eta: 0:04:22  Lr: 0.001875  Loss: -1.3045  Acc@1: 87.5000 (82.0456)  Acc@5: 100.0000 (96.7261)  time: 0.3537  data: 0.0022  max mem: 2500
Train: Epoch[3/5]  [3010/3750]  eta: 0:04:19  Lr: 0.001875  Loss: -1.0442  Acc@1: 81.2500 (82.0471)  Acc@5: 100.0000 (96.7204)  time: 0.3522  data: 0.0016  max mem: 2500
Train: Epoch[3/5]  [3020/3750]  eta: 0:04:15  Lr: 0.001875  Loss: -1.3533  Acc@1: 81.2500 (82.0506)  Acc@5: 100.0000 (96.7229)  time: 0.3510  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [3030/3750]  eta: 0:04:12  Lr: 0.001875  Loss: -1.3674  Acc@1: 87.5000 (82.0583)  Acc@5: 100.0000 (96.7214)  time: 0.3519  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [3040/3750]  eta: 0:04:08  Lr: 0.001875  Loss: -1.0014  Acc@1: 81.2500 (82.0598)  Acc@5: 100.0000 (96.7157)  time: 0.3515  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [3050/3750]  eta: 0:04:05  Lr: 0.001875  Loss: -1.2251  Acc@1: 81.2500 (82.0592)  Acc@5: 100.0000 (96.7121)  time: 0.3525  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [3060/3750]  eta: 0:04:01  Lr: 0.001875  Loss: -0.9719  Acc@1: 81.2500 (82.0647)  Acc@5: 93.7500 (96.7106)  time: 0.3520  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [3070/3750]  eta: 0:03:58  Lr: 0.001875  Loss: -0.7749  Acc@1: 81.2500 (82.0824)  Acc@5: 100.0000 (96.7132)  time: 0.3499  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [3080/3750]  eta: 0:03:54  Lr: 0.001875  Loss: -1.2081  Acc@1: 87.5000 (82.0756)  Acc@5: 93.7500 (96.7097)  time: 0.3503  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [3090/3750]  eta: 0:03:51  Lr: 0.001875  Loss: -1.0080  Acc@1: 81.2500 (82.0750)  Acc@5: 93.7500 (96.7102)  time: 0.3509  data: 0.0009  max mem: 2500
Train: Epoch[3/5]  [3100/3750]  eta: 0:03:47  Lr: 0.001875  Loss: -0.7905  Acc@1: 81.2500 (82.0582)  Acc@5: 93.7500 (96.7047)  time: 0.3501  data: 0.0009  max mem: 2500
Train: Epoch[3/5]  [3110/3750]  eta: 0:03:44  Lr: 0.001875  Loss: -1.2684  Acc@1: 81.2500 (82.0657)  Acc@5: 100.0000 (96.7113)  time: 0.3521  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [3120/3750]  eta: 0:03:40  Lr: 0.001875  Loss: -1.0555  Acc@1: 87.5000 (82.0731)  Acc@5: 100.0000 (96.7138)  time: 0.3520  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [3130/3750]  eta: 0:03:37  Lr: 0.001875  Loss: -1.1695  Acc@1: 81.2500 (82.0724)  Acc@5: 100.0000 (96.7103)  time: 0.3518  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3140/3750]  eta: 0:03:33  Lr: 0.001875  Loss: -0.9785  Acc@1: 81.2500 (82.0658)  Acc@5: 100.0000 (96.7108)  time: 0.3514  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3150/3750]  eta: 0:03:30  Lr: 0.001875  Loss: -1.0647  Acc@1: 81.2500 (82.0593)  Acc@5: 100.0000 (96.7094)  time: 0.3489  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [3160/3750]  eta: 0:03:26  Lr: 0.001875  Loss: -0.9097  Acc@1: 81.2500 (82.0448)  Acc@5: 93.7500 (96.7059)  time: 0.3490  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [3170/3750]  eta: 0:03:23  Lr: 0.001875  Loss: -0.8369  Acc@1: 81.2500 (82.0443)  Acc@5: 93.7500 (96.7025)  time: 0.3500  data: 0.0017  max mem: 2500
Train: Epoch[3/5]  [3180/3750]  eta: 0:03:19  Lr: 0.001875  Loss: -1.3741  Acc@1: 81.2500 (82.0477)  Acc@5: 93.7500 (96.6992)  time: 0.3497  data: 0.0018  max mem: 2500
Train: Epoch[3/5]  [3190/3750]  eta: 0:03:16  Lr: 0.001875  Loss: -0.4995  Acc@1: 81.2500 (82.0472)  Acc@5: 100.0000 (96.6997)  time: 0.3484  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [3200/3750]  eta: 0:03:12  Lr: 0.001875  Loss: -0.5939  Acc@1: 81.2500 (82.0310)  Acc@5: 100.0000 (96.6924)  time: 0.3485  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [3210/3750]  eta: 0:03:09  Lr: 0.001875  Loss: -1.3764  Acc@1: 75.0000 (82.0149)  Acc@5: 93.7500 (96.6872)  time: 0.3493  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [3220/3750]  eta: 0:03:05  Lr: 0.001875  Loss: -0.6139  Acc@1: 75.0000 (81.9990)  Acc@5: 93.7500 (96.6781)  time: 0.3495  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [3230/3750]  eta: 0:03:02  Lr: 0.001875  Loss: -0.8549  Acc@1: 81.2500 (81.9986)  Acc@5: 93.7500 (96.6748)  time: 0.3496  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [3240/3750]  eta: 0:02:58  Lr: 0.001875  Loss: -0.6849  Acc@1: 81.2500 (81.9924)  Acc@5: 93.7500 (96.6773)  time: 0.3497  data: 0.0009  max mem: 2500
Train: Epoch[3/5]  [3250/3750]  eta: 0:02:55  Lr: 0.001875  Loss: -1.0051  Acc@1: 81.2500 (81.9863)  Acc@5: 100.0000 (96.6760)  time: 0.3485  data: 0.0009  max mem: 2500
Train: Epoch[3/5]  [3260/3750]  eta: 0:02:51  Lr: 0.001875  Loss: -1.0621  Acc@1: 81.2500 (81.9783)  Acc@5: 100.0000 (96.6747)  time: 0.3488  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [3270/3750]  eta: 0:02:48  Lr: 0.001875  Loss: -1.2392  Acc@1: 81.2500 (81.9799)  Acc@5: 100.0000 (96.6715)  time: 0.3487  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [3280/3750]  eta: 0:02:44  Lr: 0.001875  Loss: -1.0095  Acc@1: 81.2500 (81.9777)  Acc@5: 100.0000 (96.6721)  time: 0.3497  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [3290/3750]  eta: 0:02:41  Lr: 0.001875  Loss: -0.9584  Acc@1: 81.2500 (81.9850)  Acc@5: 100.0000 (96.6765)  time: 0.3513  data: 0.0019  max mem: 2500
Train: Epoch[3/5]  [3300/3750]  eta: 0:02:37  Lr: 0.001875  Loss: -1.0504  Acc@1: 81.2500 (81.9922)  Acc@5: 100.0000 (96.6734)  time: 0.3510  data: 0.0019  max mem: 2500
Train: Epoch[3/5]  [3310/3750]  eta: 0:02:34  Lr: 0.001875  Loss: -0.8082  Acc@1: 81.2500 (81.9918)  Acc@5: 93.7500 (96.6721)  time: 0.3506  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [3320/3750]  eta: 0:02:30  Lr: 0.001875  Loss: -1.3351  Acc@1: 81.2500 (81.9953)  Acc@5: 100.0000 (96.6802)  time: 0.3512  data: 0.0009  max mem: 2500
Train: Epoch[3/5]  [3330/3750]  eta: 0:02:27  Lr: 0.001875  Loss: -1.1891  Acc@1: 81.2500 (82.0005)  Acc@5: 100.0000 (96.6846)  time: 0.3510  data: 0.0009  max mem: 2500
Train: Epoch[3/5]  [3340/3750]  eta: 0:02:23  Lr: 0.001875  Loss: -1.0708  Acc@1: 81.2500 (81.9983)  Acc@5: 100.0000 (96.6795)  time: 0.3499  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [3350/3750]  eta: 0:02:20  Lr: 0.001875  Loss: -0.9216  Acc@1: 81.2500 (81.9960)  Acc@5: 93.7500 (96.6801)  time: 0.3499  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3360/3750]  eta: 0:02:16  Lr: 0.001875  Loss: -1.2048  Acc@1: 81.2500 (82.0013)  Acc@5: 100.0000 (96.6844)  time: 0.3516  data: 0.0019  max mem: 2500
Train: Epoch[3/5]  [3370/3750]  eta: 0:02:13  Lr: 0.001875  Loss: -1.0342  Acc@1: 81.2500 (82.0027)  Acc@5: 100.0000 (96.6868)  time: 0.3529  data: 0.0019  max mem: 2500
Train: Epoch[3/5]  [3380/3750]  eta: 0:02:09  Lr: 0.001875  Loss: -1.0032  Acc@1: 81.2500 (81.9931)  Acc@5: 93.7500 (96.6781)  time: 0.3519  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [3390/3750]  eta: 0:02:06  Lr: 0.001875  Loss: -1.4270  Acc@1: 81.2500 (81.9909)  Acc@5: 93.7500 (96.6769)  time: 0.3504  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [3400/3750]  eta: 0:02:02  Lr: 0.001875  Loss: -0.7791  Acc@1: 81.2500 (81.9777)  Acc@5: 100.0000 (96.6848)  time: 0.3529  data: 0.0012  max mem: 2500
Train: Epoch[3/5]  [3410/3750]  eta: 0:01:59  Lr: 0.001875  Loss: -1.0007  Acc@1: 81.2500 (81.9866)  Acc@5: 100.0000 (96.6835)  time: 0.3540  data: 0.0028  max mem: 2500
Train: Epoch[3/5]  [3420/3750]  eta: 0:01:55  Lr: 0.001875  Loss: -0.9152  Acc@1: 87.5000 (81.9990)  Acc@5: 93.7500 (96.6804)  time: 0.3503  data: 0.0021  max mem: 2500
Train: Epoch[3/5]  [3430/3750]  eta: 0:01:52  Lr: 0.001875  Loss: -1.4365  Acc@1: 87.5000 (82.0078)  Acc@5: 93.7500 (96.6792)  time: 0.3491  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [3440/3750]  eta: 0:01:48  Lr: 0.001875  Loss: -0.1648  Acc@1: 87.5000 (82.0056)  Acc@5: 100.0000 (96.6779)  time: 0.3489  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [3450/3750]  eta: 0:01:45  Lr: 0.001875  Loss: -0.9741  Acc@1: 81.2500 (82.0106)  Acc@5: 100.0000 (96.6857)  time: 0.3489  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3460/3750]  eta: 0:01:41  Lr: 0.001875  Loss: -1.3294  Acc@1: 81.2500 (82.0139)  Acc@5: 100.0000 (96.6809)  time: 0.3489  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3470/3750]  eta: 0:01:38  Lr: 0.001875  Loss: -1.0968  Acc@1: 81.2500 (82.0117)  Acc@5: 93.7500 (96.6814)  time: 0.3478  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3480/3750]  eta: 0:01:34  Lr: 0.001875  Loss: -1.1499  Acc@1: 81.2500 (82.0203)  Acc@5: 100.0000 (96.6856)  time: 0.3485  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3490/3750]  eta: 0:01:31  Lr: 0.001875  Loss: -0.8331  Acc@1: 87.5000 (82.0359)  Acc@5: 100.0000 (96.6933)  time: 0.3487  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3500/3750]  eta: 0:01:27  Lr: 0.001875  Loss: -0.2693  Acc@1: 81.2500 (82.0230)  Acc@5: 100.0000 (96.6884)  time: 0.3495  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3510/3750]  eta: 0:01:24  Lr: 0.001875  Loss: -1.2443  Acc@1: 81.2500 (82.0279)  Acc@5: 93.7500 (96.6872)  time: 0.3497  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3520/3750]  eta: 0:01:20  Lr: 0.001875  Loss: -1.0306  Acc@1: 87.5000 (82.0328)  Acc@5: 100.0000 (96.6895)  time: 0.3486  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3530/3750]  eta: 0:01:17  Lr: 0.001875  Loss: -0.6500  Acc@1: 81.2500 (82.0324)  Acc@5: 100.0000 (96.6900)  time: 0.3504  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3540/3750]  eta: 0:01:13  Lr: 0.001875  Loss: -1.2435  Acc@1: 81.2500 (82.0284)  Acc@5: 100.0000 (96.6941)  time: 0.3504  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [3550/3750]  eta: 0:01:10  Lr: 0.001875  Loss: -0.6443  Acc@1: 81.2500 (82.0262)  Acc@5: 100.0000 (96.6893)  time: 0.3490  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [3560/3750]  eta: 0:01:06  Lr: 0.001875  Loss: -1.1404  Acc@1: 81.2500 (82.0223)  Acc@5: 93.7500 (96.6846)  time: 0.3501  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3570/3750]  eta: 0:01:03  Lr: 0.001875  Loss: -0.7548  Acc@1: 81.2500 (82.0306)  Acc@5: 100.0000 (96.6869)  time: 0.3507  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [3580/3750]  eta: 0:00:59  Lr: 0.001875  Loss: -0.7002  Acc@1: 87.5000 (82.0371)  Acc@5: 100.0000 (96.6856)  time: 0.3508  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [3590/3750]  eta: 0:00:56  Lr: 0.001875  Loss: -1.0136  Acc@1: 87.5000 (82.0454)  Acc@5: 100.0000 (96.6896)  time: 0.3504  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [3600/3750]  eta: 0:00:52  Lr: 0.001875  Loss: -0.4957  Acc@1: 87.5000 (82.0467)  Acc@5: 100.0000 (96.6902)  time: 0.3498  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [3610/3750]  eta: 0:00:49  Lr: 0.001875  Loss: -0.9458  Acc@1: 81.2500 (82.0444)  Acc@5: 100.0000 (96.6941)  time: 0.3504  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [3620/3750]  eta: 0:00:45  Lr: 0.001875  Loss: -0.6414  Acc@1: 81.2500 (82.0405)  Acc@5: 100.0000 (96.6912)  time: 0.3501  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [3630/3750]  eta: 0:00:42  Lr: 0.001875  Loss: -1.3246  Acc@1: 81.2500 (82.0418)  Acc@5: 93.7500 (96.6882)  time: 0.3485  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [3640/3750]  eta: 0:00:38  Lr: 0.001875  Loss: -1.2981  Acc@1: 81.2500 (82.0465)  Acc@5: 100.0000 (96.6888)  time: 0.3488  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [3650/3750]  eta: 0:00:35  Lr: 0.001875  Loss: -0.9081  Acc@1: 81.2500 (82.0477)  Acc@5: 93.7500 (96.6858)  time: 0.3529  data: 0.0015  max mem: 2500
Train: Epoch[3/5]  [3660/3750]  eta: 0:00:31  Lr: 0.001875  Loss: -1.3251  Acc@1: 81.2500 (82.0592)  Acc@5: 100.0000 (96.6881)  time: 0.3525  data: 0.0013  max mem: 2500
Train: Epoch[3/5]  [3670/3750]  eta: 0:00:28  Lr: 0.001875  Loss: -1.0680  Acc@1: 81.2500 (82.0570)  Acc@5: 93.7500 (96.6750)  time: 0.3507  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [3680/3750]  eta: 0:00:24  Lr: 0.001875  Loss: -1.2616  Acc@1: 81.2500 (82.0650)  Acc@5: 93.7500 (96.6806)  time: 0.3503  data: 0.0004  max mem: 2500
Train: Epoch[3/5]  [3690/3750]  eta: 0:00:21  Lr: 0.001875  Loss: -1.3698  Acc@1: 87.5000 (82.0780)  Acc@5: 100.0000 (96.6828)  time: 0.3490  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [3700/3750]  eta: 0:00:17  Lr: 0.001875  Loss: -1.1593  Acc@1: 87.5000 (82.0809)  Acc@5: 100.0000 (96.6833)  time: 0.3496  data: 0.0008  max mem: 2500
Train: Epoch[3/5]  [3710/3750]  eta: 0:00:14  Lr: 0.001875  Loss: -1.2045  Acc@1: 87.5000 (82.0904)  Acc@5: 100.0000 (96.6838)  time: 0.3502  data: 0.0005  max mem: 2500
Train: Epoch[3/5]  [3720/3750]  eta: 0:00:10  Lr: 0.001875  Loss: -0.9461  Acc@1: 87.5000 (82.0949)  Acc@5: 100.0000 (96.6844)  time: 0.3504  data: 0.0006  max mem: 2500
Train: Epoch[3/5]  [3730/3750]  eta: 0:00:07  Lr: 0.001875  Loss: -0.9287  Acc@1: 81.2500 (82.0993)  Acc@5: 93.7500 (96.6765)  time: 0.3496  data: 0.0007  max mem: 2500
Train: Epoch[3/5]  [3740/3750]  eta: 0:00:03  Lr: 0.001875  Loss: -1.0246  Acc@1: 81.2500 (82.1054)  Acc@5: 93.7500 (96.6770)  time: 0.3496  data: 0.0009  max mem: 2500
Train: Epoch[3/5]  [3749/3750]  eta: 0:00:00  Lr: 0.001875  Loss: -1.2189  Acc@1: 81.2500 (82.1017)  Acc@5: 100.0000 (96.6750)  time: 0.3512  data: 0.0013  max mem: 2500
Train: Epoch[3/5] Total time: 0:21:53 (0.3503 s / it)
Averaged stats: Lr: 0.001875  Loss: -1.2189  Acc@1: 81.2500 (82.1017)  Acc@5: 100.0000 (96.6750)
Train: Epoch[4/5]  [   0/3750]  eta: 0:46:58  Lr: 0.001875  Loss: -1.3338  Acc@1: 93.7500 (93.7500)  Acc@5: 100.0000 (100.0000)  time: 0.7515  data: 0.3982  max mem: 2500
Train: Epoch[4/5]  [  10/3750]  eta: 0:24:04  Lr: 0.001875  Loss: -0.8265  Acc@1: 81.2500 (81.2500)  Acc@5: 100.0000 (96.0227)  time: 0.3862  data: 0.0369  max mem: 2500
Train: Epoch[4/5]  [  20/3750]  eta: 0:22:59  Lr: 0.001875  Loss: -0.7940  Acc@1: 81.2500 (80.6548)  Acc@5: 93.7500 (96.1310)  time: 0.3508  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [  30/3750]  eta: 0:22:31  Lr: 0.001875  Loss: -0.6564  Acc@1: 81.2500 (81.4516)  Acc@5: 93.7500 (95.5645)  time: 0.3507  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [  40/3750]  eta: 0:22:17  Lr: 0.001875  Loss: -1.0413  Acc@1: 81.2500 (82.3171)  Acc@5: 93.7500 (95.8841)  time: 0.3505  data: 0.0016  max mem: 2500
Train: Epoch[4/5]  [  50/3750]  eta: 0:22:08  Lr: 0.001875  Loss: -0.6875  Acc@1: 81.2500 (82.1078)  Acc@5: 93.7500 (95.8333)  time: 0.3528  data: 0.0017  max mem: 2500
Train: Epoch[4/5]  [  60/3750]  eta: 0:22:00  Lr: 0.001875  Loss: -1.1835  Acc@1: 81.2500 (81.8648)  Acc@5: 100.0000 (96.2090)  time: 0.3530  data: 0.0017  max mem: 2500
Train: Epoch[4/5]  [  70/3750]  eta: 0:21:54  Lr: 0.001875  Loss: -0.6933  Acc@1: 81.2500 (80.9859)  Acc@5: 100.0000 (96.3908)  time: 0.3523  data: 0.0028  max mem: 2500
Train: Epoch[4/5]  [  80/3750]  eta: 0:21:47  Lr: 0.001875  Loss: -0.8626  Acc@1: 81.2500 (80.4784)  Acc@5: 100.0000 (96.2963)  time: 0.3506  data: 0.0016  max mem: 2500
Train: Epoch[4/5]  [  90/3750]  eta: 0:21:41  Lr: 0.001875  Loss: -0.7848  Acc@1: 81.2500 (80.4945)  Acc@5: 93.7500 (96.4286)  time: 0.3493  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [ 100/3750]  eta: 0:21:34  Lr: 0.001875  Loss: -0.9054  Acc@1: 81.2500 (80.3218)  Acc@5: 100.0000 (96.3490)  time: 0.3492  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [ 110/3750]  eta: 0:21:29  Lr: 0.001875  Loss: -0.4599  Acc@1: 81.2500 (80.6306)  Acc@5: 100.0000 (96.2838)  time: 0.3481  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 120/3750]  eta: 0:21:24  Lr: 0.001875  Loss: -1.0513  Acc@1: 81.2500 (80.7851)  Acc@5: 100.0000 (96.2810)  time: 0.3497  data: 0.0012  max mem: 2500
Train: Epoch[4/5]  [ 130/3750]  eta: 0:21:20  Lr: 0.001875  Loss: -0.8661  Acc@1: 81.2500 (80.8683)  Acc@5: 100.0000 (96.3740)  time: 0.3515  data: 0.0024  max mem: 2500
Train: Epoch[4/5]  [ 140/3750]  eta: 0:21:16  Lr: 0.001875  Loss: -0.8857  Acc@1: 81.2500 (80.9397)  Acc@5: 100.0000 (96.3652)  time: 0.3513  data: 0.0021  max mem: 2500
Train: Epoch[4/5]  [ 150/3750]  eta: 0:21:11  Lr: 0.001875  Loss: -0.8595  Acc@1: 81.2500 (81.2086)  Acc@5: 100.0000 (96.4818)  time: 0.3500  data: 0.0010  max mem: 2500
Train: Epoch[4/5]  [ 160/3750]  eta: 0:21:07  Lr: 0.001875  Loss: -1.1535  Acc@1: 81.2500 (80.8618)  Acc@5: 100.0000 (96.5839)  time: 0.3488  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 170/3750]  eta: 0:21:02  Lr: 0.001875  Loss: -0.9793  Acc@1: 75.0000 (80.6287)  Acc@5: 100.0000 (96.5278)  time: 0.3483  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [ 180/3750]  eta: 0:20:58  Lr: 0.001875  Loss: -1.3807  Acc@1: 75.0000 (80.7666)  Acc@5: 100.0000 (96.5124)  time: 0.3481  data: 0.0012  max mem: 2500
Train: Epoch[4/5]  [ 190/3750]  eta: 0:20:54  Lr: 0.001875  Loss: -1.1913  Acc@1: 87.5000 (80.9882)  Acc@5: 100.0000 (96.5314)  time: 0.3505  data: 0.0009  max mem: 2500
Train: Epoch[4/5]  [ 200/3750]  eta: 0:20:50  Lr: 0.001875  Loss: -1.0794  Acc@1: 87.5000 (81.1256)  Acc@5: 100.0000 (96.5174)  time: 0.3505  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 210/3750]  eta: 0:20:46  Lr: 0.001875  Loss: -1.2432  Acc@1: 81.2500 (81.1611)  Acc@5: 100.0000 (96.5936)  time: 0.3480  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 220/3750]  eta: 0:20:41  Lr: 0.001875  Loss: -0.8208  Acc@1: 81.2500 (81.3348)  Acc@5: 100.0000 (96.6629)  time: 0.3473  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 230/3750]  eta: 0:20:38  Lr: 0.001875  Loss: -0.8541  Acc@1: 81.2500 (81.1688)  Acc@5: 100.0000 (96.5909)  time: 0.3493  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [ 240/3750]  eta: 0:20:34  Lr: 0.001875  Loss: -0.8567  Acc@1: 81.2500 (81.2241)  Acc@5: 100.0000 (96.6286)  time: 0.3500  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [ 250/3750]  eta: 0:20:30  Lr: 0.001875  Loss: -0.8348  Acc@1: 81.2500 (81.2749)  Acc@5: 100.0000 (96.6135)  time: 0.3483  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 260/3750]  eta: 0:20:26  Lr: 0.001875  Loss: -1.3403  Acc@1: 81.2500 (81.3697)  Acc@5: 93.7500 (96.5757)  time: 0.3493  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [ 270/3750]  eta: 0:20:22  Lr: 0.001875  Loss: -1.0575  Acc@1: 81.2500 (81.4114)  Acc@5: 93.7500 (96.4714)  time: 0.3495  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [ 280/3750]  eta: 0:20:19  Lr: 0.001875  Loss: -0.6882  Acc@1: 81.2500 (81.5169)  Acc@5: 93.7500 (96.5080)  time: 0.3503  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [ 290/3750]  eta: 0:20:15  Lr: 0.001875  Loss: -1.0686  Acc@1: 87.5000 (81.5936)  Acc@5: 100.0000 (96.5206)  time: 0.3512  data: 0.0017  max mem: 2500
Train: Epoch[4/5]  [ 300/3750]  eta: 0:20:12  Lr: 0.001875  Loss: -1.2904  Acc@1: 87.5000 (81.6653)  Acc@5: 100.0000 (96.5739)  time: 0.3517  data: 0.0020  max mem: 2500
Train: Epoch[4/5]  [ 310/3750]  eta: 0:20:08  Lr: 0.001875  Loss: -1.1039  Acc@1: 81.2500 (81.6117)  Acc@5: 100.0000 (96.5836)  time: 0.3521  data: 0.0018  max mem: 2500
Train: Epoch[4/5]  [ 320/3750]  eta: 0:20:05  Lr: 0.001875  Loss: -1.0508  Acc@1: 81.2500 (81.5226)  Acc@5: 93.7500 (96.5732)  time: 0.3508  data: 0.0014  max mem: 2500
Train: Epoch[4/5]  [ 330/3750]  eta: 0:20:01  Lr: 0.001875  Loss: -0.9631  Acc@1: 81.2500 (81.6465)  Acc@5: 100.0000 (96.5823)  time: 0.3502  data: 0.0011  max mem: 2500
Train: Epoch[4/5]  [ 340/3750]  eta: 0:19:57  Lr: 0.001875  Loss: -0.8704  Acc@1: 81.2500 (81.5799)  Acc@5: 100.0000 (96.6092)  time: 0.3500  data: 0.0010  max mem: 2500
Train: Epoch[4/5]  [ 350/3750]  eta: 0:19:54  Lr: 0.001875  Loss: -0.6118  Acc@1: 81.2500 (81.5527)  Acc@5: 93.7500 (96.5990)  time: 0.3507  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [ 360/3750]  eta: 0:19:50  Lr: 0.001875  Loss: -1.1171  Acc@1: 81.2500 (81.5789)  Acc@5: 100.0000 (96.6586)  time: 0.3512  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [ 370/3750]  eta: 0:19:47  Lr: 0.001875  Loss: -1.2758  Acc@1: 81.2500 (81.6375)  Acc@5: 100.0000 (96.6307)  time: 0.3503  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [ 380/3750]  eta: 0:19:43  Lr: 0.001875  Loss: -0.9731  Acc@1: 81.2500 (81.6109)  Acc@5: 100.0000 (96.6535)  time: 0.3500  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [ 390/3750]  eta: 0:19:39  Lr: 0.001875  Loss: -1.0294  Acc@1: 81.2500 (81.6017)  Acc@5: 100.0000 (96.6752)  time: 0.3498  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [ 400/3750]  eta: 0:19:36  Lr: 0.001875  Loss: -1.2786  Acc@1: 87.5000 (81.7332)  Acc@5: 100.0000 (96.6958)  time: 0.3495  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 410/3750]  eta: 0:19:32  Lr: 0.001875  Loss: -0.9917  Acc@1: 87.5000 (81.7518)  Acc@5: 100.0000 (96.6697)  time: 0.3493  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 420/3750]  eta: 0:19:29  Lr: 0.001875  Loss: -1.3407  Acc@1: 87.5000 (81.7844)  Acc@5: 100.0000 (96.6894)  time: 0.3496  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 430/3750]  eta: 0:19:25  Lr: 0.001875  Loss: -0.8885  Acc@1: 87.5000 (81.8735)  Acc@5: 100.0000 (96.7227)  time: 0.3499  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 440/3750]  eta: 0:19:21  Lr: 0.001875  Loss: -1.2735  Acc@1: 87.5000 (81.9586)  Acc@5: 100.0000 (96.7687)  time: 0.3500  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 450/3750]  eta: 0:19:18  Lr: 0.001875  Loss: -1.1381  Acc@1: 81.2500 (81.9429)  Acc@5: 100.0000 (96.7018)  time: 0.3496  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [ 460/3750]  eta: 0:19:14  Lr: 0.001875  Loss: -1.1974  Acc@1: 81.2500 (81.9821)  Acc@5: 100.0000 (96.6920)  time: 0.3496  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 470/3750]  eta: 0:19:10  Lr: 0.001875  Loss: -0.7991  Acc@1: 81.2500 (81.9931)  Acc@5: 100.0000 (96.7091)  time: 0.3499  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 480/3750]  eta: 0:19:07  Lr: 0.001875  Loss: -1.2913  Acc@1: 87.5000 (82.0946)  Acc@5: 100.0000 (96.7126)  time: 0.3499  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 490/3750]  eta: 0:19:04  Lr: 0.001875  Loss: -1.0433  Acc@1: 87.5000 (82.0647)  Acc@5: 100.0000 (96.7413)  time: 0.3513  data: 0.0019  max mem: 2500
Train: Epoch[4/5]  [ 500/3750]  eta: 0:19:00  Lr: 0.001875  Loss: -1.2158  Acc@1: 81.2500 (82.1233)  Acc@5: 100.0000 (96.7939)  time: 0.3511  data: 0.0022  max mem: 2500
Train: Epoch[4/5]  [ 510/3750]  eta: 0:18:56  Lr: 0.001875  Loss: -1.1325  Acc@1: 81.2500 (82.2040)  Acc@5: 100.0000 (96.8322)  time: 0.3493  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [ 520/3750]  eta: 0:18:53  Lr: 0.001875  Loss: -1.0755  Acc@1: 81.2500 (82.1737)  Acc@5: 100.0000 (96.8210)  time: 0.3490  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 530/3750]  eta: 0:18:49  Lr: 0.001875  Loss: -0.5540  Acc@1: 81.2500 (82.1563)  Acc@5: 100.0000 (96.8103)  time: 0.3498  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [ 540/3750]  eta: 0:18:46  Lr: 0.001875  Loss: -1.4168  Acc@1: 87.5000 (82.1973)  Acc@5: 100.0000 (96.7999)  time: 0.3517  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [ 550/3750]  eta: 0:18:42  Lr: 0.001875  Loss: -0.7935  Acc@1: 81.2500 (82.1574)  Acc@5: 100.0000 (96.7899)  time: 0.3539  data: 0.0030  max mem: 2500
Train: Epoch[4/5]  [ 560/3750]  eta: 0:18:39  Lr: 0.001875  Loss: -1.0988  Acc@1: 81.2500 (82.2304)  Acc@5: 100.0000 (96.8026)  time: 0.3520  data: 0.0030  max mem: 2500
Train: Epoch[4/5]  [ 570/3750]  eta: 0:18:35  Lr: 0.001875  Loss: -1.0847  Acc@1: 81.2500 (82.3008)  Acc@5: 100.0000 (96.8586)  time: 0.3495  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 580/3750]  eta: 0:18:32  Lr: 0.001875  Loss: -0.7806  Acc@1: 81.2500 (82.2397)  Acc@5: 100.0000 (96.8266)  time: 0.3493  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 590/3750]  eta: 0:18:28  Lr: 0.001875  Loss: -1.0469  Acc@1: 81.2500 (82.2124)  Acc@5: 93.7500 (96.7851)  time: 0.3514  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 600/3750]  eta: 0:18:25  Lr: 0.001875  Loss: -1.3472  Acc@1: 75.0000 (82.1131)  Acc@5: 93.7500 (96.7866)  time: 0.3516  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 610/3750]  eta: 0:18:21  Lr: 0.001875  Loss: -1.2287  Acc@1: 81.2500 (82.1297)  Acc@5: 93.7500 (96.7574)  time: 0.3492  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 620/3750]  eta: 0:18:18  Lr: 0.001875  Loss: -0.2163  Acc@1: 81.2500 (82.1055)  Acc@5: 93.7500 (96.7291)  time: 0.3498  data: 0.0011  max mem: 2500
Train: Epoch[4/5]  [ 630/3750]  eta: 0:18:14  Lr: 0.001875  Loss: -0.9303  Acc@1: 81.2500 (82.1117)  Acc@5: 100.0000 (96.7710)  time: 0.3501  data: 0.0012  max mem: 2500
Train: Epoch[4/5]  [ 640/3750]  eta: 0:18:11  Lr: 0.001875  Loss: -1.1971  Acc@1: 81.2500 (82.0983)  Acc@5: 100.0000 (96.7629)  time: 0.3498  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [ 650/3750]  eta: 0:18:07  Lr: 0.001875  Loss: -1.0915  Acc@1: 81.2500 (82.1141)  Acc@5: 100.0000 (96.7646)  time: 0.3497  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 660/3750]  eta: 0:18:03  Lr: 0.001875  Loss: -1.4103  Acc@1: 81.2500 (82.1199)  Acc@5: 100.0000 (96.7852)  time: 0.3504  data: 0.0010  max mem: 2500
Train: Epoch[4/5]  [ 670/3750]  eta: 0:18:00  Lr: 0.001875  Loss: -0.8018  Acc@1: 81.2500 (82.0697)  Acc@5: 100.0000 (96.7399)  time: 0.3516  data: 0.0022  max mem: 2500
Train: Epoch[4/5]  [ 680/3750]  eta: 0:17:56  Lr: 0.001875  Loss: -1.0041  Acc@1: 87.5000 (82.1311)  Acc@5: 93.7500 (96.6869)  time: 0.3512  data: 0.0017  max mem: 2500
Train: Epoch[4/5]  [ 690/3750]  eta: 0:17:53  Lr: 0.001875  Loss: -0.6983  Acc@1: 87.5000 (82.1454)  Acc@5: 93.7500 (96.7077)  time: 0.3506  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [ 700/3750]  eta: 0:17:50  Lr: 0.001875  Loss: -0.8089  Acc@1: 81.2500 (82.2040)  Acc@5: 100.0000 (96.7368)  time: 0.3518  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [ 710/3750]  eta: 0:17:46  Lr: 0.001875  Loss: -0.6866  Acc@1: 87.5000 (82.2169)  Acc@5: 100.0000 (96.7475)  time: 0.3524  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [ 720/3750]  eta: 0:17:43  Lr: 0.001875  Loss: -1.0428  Acc@1: 81.2500 (82.2209)  Acc@5: 100.0000 (96.7753)  time: 0.3520  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [ 730/3750]  eta: 0:17:39  Lr: 0.001875  Loss: -1.2612  Acc@1: 81.2500 (82.2931)  Acc@5: 100.0000 (96.7767)  time: 0.3506  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 740/3750]  eta: 0:17:36  Lr: 0.001875  Loss: -0.9693  Acc@1: 81.2500 (82.2453)  Acc@5: 93.7500 (96.7611)  time: 0.3513  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [ 750/3750]  eta: 0:17:32  Lr: 0.001875  Loss: -0.9253  Acc@1: 81.2500 (82.2986)  Acc@5: 100.0000 (96.7710)  time: 0.3529  data: 0.0014  max mem: 2500
Train: Epoch[4/5]  [ 760/3750]  eta: 0:17:29  Lr: 0.001875  Loss: -0.9561  Acc@1: 87.5000 (82.3834)  Acc@5: 100.0000 (96.7970)  time: 0.3521  data: 0.0010  max mem: 2500
Train: Epoch[4/5]  [ 770/3750]  eta: 0:17:25  Lr: 0.001875  Loss: -1.1476  Acc@1: 87.5000 (82.3930)  Acc@5: 100.0000 (96.8061)  time: 0.3502  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 780/3750]  eta: 0:17:22  Lr: 0.001875  Loss: -0.4981  Acc@1: 81.2500 (82.3624)  Acc@5: 100.0000 (96.8150)  time: 0.3487  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [ 790/3750]  eta: 0:17:18  Lr: 0.001875  Loss: -0.9471  Acc@1: 75.0000 (82.3088)  Acc@5: 100.0000 (96.7920)  time: 0.3499  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [ 800/3750]  eta: 0:17:14  Lr: 0.001875  Loss: -1.1735  Acc@1: 81.2500 (82.3190)  Acc@5: 100.0000 (96.7931)  time: 0.3502  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [ 810/3750]  eta: 0:17:11  Lr: 0.001875  Loss: -1.0155  Acc@1: 81.2500 (82.3366)  Acc@5: 100.0000 (96.7941)  time: 0.3497  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 820/3750]  eta: 0:17:07  Lr: 0.001875  Loss: -0.9963  Acc@1: 81.2500 (82.3082)  Acc@5: 93.7500 (96.7798)  time: 0.3506  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [ 830/3750]  eta: 0:17:04  Lr: 0.001875  Loss: -0.9244  Acc@1: 81.2500 (82.3105)  Acc@5: 93.7500 (96.7735)  time: 0.3501  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [ 840/3750]  eta: 0:17:00  Lr: 0.001875  Loss: -1.0162  Acc@1: 81.2500 (82.3127)  Acc@5: 100.0000 (96.7672)  time: 0.3496  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [ 850/3750]  eta: 0:16:57  Lr: 0.001875  Loss: -1.2395  Acc@1: 81.2500 (82.2929)  Acc@5: 93.7500 (96.7465)  time: 0.3504  data: 0.0010  max mem: 2500
Train: Epoch[4/5]  [ 860/3750]  eta: 0:16:53  Lr: 0.001875  Loss: -1.0723  Acc@1: 81.2500 (82.2735)  Acc@5: 93.7500 (96.7407)  time: 0.3502  data: 0.0013  max mem: 2500
Train: Epoch[4/5]  [ 870/3750]  eta: 0:16:50  Lr: 0.001875  Loss: -0.6141  Acc@1: 81.2500 (82.2689)  Acc@5: 100.0000 (96.7351)  time: 0.3500  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [ 880/3750]  eta: 0:16:46  Lr: 0.001875  Loss: -1.0533  Acc@1: 81.2500 (82.2928)  Acc@5: 100.0000 (96.7296)  time: 0.3502  data: 0.0013  max mem: 2500
Train: Epoch[4/5]  [ 890/3750]  eta: 0:16:43  Lr: 0.001875  Loss: -0.8761  Acc@1: 81.2500 (82.2811)  Acc@5: 100.0000 (96.7242)  time: 0.3498  data: 0.0013  max mem: 2500
Train: Epoch[4/5]  [ 900/3750]  eta: 0:16:39  Lr: 0.001875  Loss: -1.0077  Acc@1: 81.2500 (82.2905)  Acc@5: 100.0000 (96.7328)  time: 0.3498  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [ 910/3750]  eta: 0:16:36  Lr: 0.001875  Loss: -1.0444  Acc@1: 81.2500 (82.3408)  Acc@5: 100.0000 (96.7412)  time: 0.3507  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [ 920/3750]  eta: 0:16:32  Lr: 0.001875  Loss: -1.2643  Acc@1: 81.2500 (82.2476)  Acc@5: 93.7500 (96.7223)  time: 0.3518  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [ 930/3750]  eta: 0:16:29  Lr: 0.001875  Loss: -0.9141  Acc@1: 75.0000 (82.2503)  Acc@5: 93.7500 (96.7240)  time: 0.3533  data: 0.0023  max mem: 2500
Train: Epoch[4/5]  [ 940/3750]  eta: 0:16:25  Lr: 0.001875  Loss: 0.1052  Acc@1: 81.2500 (82.2064)  Acc@5: 93.7500 (96.6990)  time: 0.3522  data: 0.0020  max mem: 2500
Train: Epoch[4/5]  [ 950/3750]  eta: 0:16:22  Lr: 0.001875  Loss: -1.1914  Acc@1: 81.2500 (82.2489)  Acc@5: 100.0000 (96.7271)  time: 0.3505  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [ 960/3750]  eta: 0:16:18  Lr: 0.001875  Loss: -0.8294  Acc@1: 81.2500 (82.2451)  Acc@5: 100.0000 (96.7352)  time: 0.3505  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [ 970/3750]  eta: 0:16:15  Lr: 0.001875  Loss: -1.1451  Acc@1: 81.2500 (82.2284)  Acc@5: 100.0000 (96.7044)  time: 0.3506  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 980/3750]  eta: 0:16:11  Lr: 0.001875  Loss: -1.1963  Acc@1: 87.5000 (82.2821)  Acc@5: 100.0000 (96.7189)  time: 0.3502  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [ 990/3750]  eta: 0:16:08  Lr: 0.001875  Loss: -1.0821  Acc@1: 87.5000 (82.3095)  Acc@5: 100.0000 (96.7079)  time: 0.3497  data: 0.0010  max mem: 2500
Train: Epoch[4/5]  [1000/3750]  eta: 0:16:04  Lr: 0.001875  Loss: -0.4737  Acc@1: 87.5000 (82.3364)  Acc@5: 93.7500 (96.6971)  time: 0.3513  data: 0.0010  max mem: 2500
Train: Epoch[4/5]  [1010/3750]  eta: 0:16:01  Lr: 0.001875  Loss: -1.0985  Acc@1: 81.2500 (82.3071)  Acc@5: 93.7500 (96.6988)  time: 0.3509  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [1020/3750]  eta: 0:15:57  Lr: 0.001875  Loss: -1.1603  Acc@1: 81.2500 (82.2723)  Acc@5: 93.7500 (96.6822)  time: 0.3495  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [1030/3750]  eta: 0:15:54  Lr: 0.001875  Loss: -1.3147  Acc@1: 81.2500 (82.2624)  Acc@5: 93.7500 (96.6901)  time: 0.3510  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1040/3750]  eta: 0:15:50  Lr: 0.001875  Loss: -1.2012  Acc@1: 81.2500 (82.2586)  Acc@5: 100.0000 (96.6859)  time: 0.3530  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1050/3750]  eta: 0:15:47  Lr: 0.001875  Loss: -1.1200  Acc@1: 81.2500 (82.2609)  Acc@5: 100.0000 (96.6817)  time: 0.3517  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1060/3750]  eta: 0:15:43  Lr: 0.001875  Loss: -1.2322  Acc@1: 87.5000 (82.3103)  Acc@5: 100.0000 (96.6836)  time: 0.3493  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1070/3750]  eta: 0:15:40  Lr: 0.001875  Loss: -0.8417  Acc@1: 81.2500 (82.3004)  Acc@5: 100.0000 (96.6795)  time: 0.3497  data: 0.0012  max mem: 2500
Train: Epoch[4/5]  [1080/3750]  eta: 0:15:36  Lr: 0.001875  Loss: -0.6339  Acc@1: 81.2500 (82.3080)  Acc@5: 93.7500 (96.6698)  time: 0.3499  data: 0.0014  max mem: 2500
Train: Epoch[4/5]  [1090/3750]  eta: 0:15:33  Lr: 0.001875  Loss: -0.9042  Acc@1: 81.2500 (82.3041)  Acc@5: 100.0000 (96.6774)  time: 0.3497  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [1100/3750]  eta: 0:15:29  Lr: 0.001875  Loss: -0.9818  Acc@1: 87.5000 (82.3569)  Acc@5: 100.0000 (96.6792)  time: 0.3489  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1110/3750]  eta: 0:15:25  Lr: 0.001875  Loss: -1.2509  Acc@1: 87.5000 (82.3470)  Acc@5: 100.0000 (96.6809)  time: 0.3481  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1120/3750]  eta: 0:15:22  Lr: 0.001875  Loss: -1.1630  Acc@1: 81.2500 (82.3762)  Acc@5: 100.0000 (96.6882)  time: 0.3489  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1130/3750]  eta: 0:15:18  Lr: 0.001875  Loss: -1.2068  Acc@1: 81.2500 (82.3497)  Acc@5: 100.0000 (96.6899)  time: 0.3489  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1140/3750]  eta: 0:15:15  Lr: 0.001875  Loss: -1.1659  Acc@1: 81.2500 (82.3839)  Acc@5: 100.0000 (96.7025)  time: 0.3482  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1150/3750]  eta: 0:15:11  Lr: 0.001875  Loss: -1.1709  Acc@1: 87.5000 (82.4120)  Acc@5: 100.0000 (96.6985)  time: 0.3486  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [1160/3750]  eta: 0:15:08  Lr: 0.001875  Loss: -0.8767  Acc@1: 87.5000 (82.4289)  Acc@5: 100.0000 (96.7054)  time: 0.3493  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1170/3750]  eta: 0:15:04  Lr: 0.001875  Loss: -1.2386  Acc@1: 81.2500 (82.4295)  Acc@5: 100.0000 (96.7015)  time: 0.3489  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [1180/3750]  eta: 0:15:01  Lr: 0.001875  Loss: -1.0289  Acc@1: 81.2500 (82.4196)  Acc@5: 93.7500 (96.7030)  time: 0.3494  data: 0.0012  max mem: 2500
Train: Epoch[4/5]  [1190/3750]  eta: 0:14:57  Lr: 0.001875  Loss: -0.9457  Acc@1: 81.2500 (82.3835)  Acc@5: 93.7500 (96.6992)  time: 0.3492  data: 0.0012  max mem: 2500
Train: Epoch[4/5]  [1200/3750]  eta: 0:14:54  Lr: 0.001875  Loss: -1.1986  Acc@1: 81.2500 (82.4053)  Acc@5: 93.7500 (96.6851)  time: 0.3499  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [1210/3750]  eta: 0:14:50  Lr: 0.001875  Loss: -1.1366  Acc@1: 87.5000 (82.4216)  Acc@5: 93.7500 (96.6866)  time: 0.3498  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [1220/3750]  eta: 0:14:46  Lr: 0.001875  Loss: -1.1131  Acc@1: 81.2500 (82.3659)  Acc@5: 100.0000 (96.6830)  time: 0.3487  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [1230/3750]  eta: 0:14:43  Lr: 0.001875  Loss: -1.0060  Acc@1: 81.2500 (82.3314)  Acc@5: 100.0000 (96.6846)  time: 0.3487  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1240/3750]  eta: 0:14:39  Lr: 0.001875  Loss: -0.8215  Acc@1: 81.2500 (82.3278)  Acc@5: 100.0000 (96.6861)  time: 0.3484  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [1250/3750]  eta: 0:14:36  Lr: 0.001875  Loss: -1.1696  Acc@1: 81.2500 (82.3241)  Acc@5: 100.0000 (96.6926)  time: 0.3511  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [1260/3750]  eta: 0:14:32  Lr: 0.001875  Loss: -1.1819  Acc@1: 81.2500 (82.3602)  Acc@5: 100.0000 (96.7040)  time: 0.3516  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [1270/3750]  eta: 0:14:29  Lr: 0.001875  Loss: -1.1457  Acc@1: 87.5000 (82.3712)  Acc@5: 100.0000 (96.7054)  time: 0.3487  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [1280/3750]  eta: 0:14:25  Lr: 0.001875  Loss: -1.1668  Acc@1: 87.5000 (82.3770)  Acc@5: 100.0000 (96.7116)  time: 0.3479  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [1290/3750]  eta: 0:14:22  Lr: 0.001875  Loss: -1.3898  Acc@1: 81.2500 (82.3635)  Acc@5: 100.0000 (96.7225)  time: 0.3492  data: 0.0015  max mem: 2500
Train: Epoch[4/5]  [1300/3750]  eta: 0:14:18  Lr: 0.001875  Loss: -1.1830  Acc@1: 81.2500 (82.3501)  Acc@5: 100.0000 (96.7189)  time: 0.3487  data: 0.0015  max mem: 2500
Train: Epoch[4/5]  [1310/3750]  eta: 0:14:15  Lr: 0.001875  Loss: -1.0585  Acc@1: 81.2500 (82.3417)  Acc@5: 93.7500 (96.7153)  time: 0.3491  data: 0.0013  max mem: 2500
Train: Epoch[4/5]  [1320/3750]  eta: 0:14:11  Lr: 0.001875  Loss: -0.1817  Acc@1: 81.2500 (82.3760)  Acc@5: 100.0000 (96.7212)  time: 0.3493  data: 0.0012  max mem: 2500
Train: Epoch[4/5]  [1330/3750]  eta: 0:14:08  Lr: 0.001875  Loss: -0.8555  Acc@1: 87.5000 (82.3817)  Acc@5: 100.0000 (96.7365)  time: 0.3484  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [1340/3750]  eta: 0:14:04  Lr: 0.001875  Loss: -1.0221  Acc@1: 81.2500 (82.3779)  Acc@5: 100.0000 (96.7282)  time: 0.3485  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [1350/3750]  eta: 0:14:01  Lr: 0.001875  Loss: -1.2985  Acc@1: 81.2500 (82.3788)  Acc@5: 100.0000 (96.7339)  time: 0.3494  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1360/3750]  eta: 0:13:57  Lr: 0.001875  Loss: -1.1619  Acc@1: 81.2500 (82.4118)  Acc@5: 100.0000 (96.7395)  time: 0.3503  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1370/3750]  eta: 0:13:54  Lr: 0.001875  Loss: -1.1009  Acc@1: 87.5000 (82.4261)  Acc@5: 100.0000 (96.7405)  time: 0.3495  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [1380/3750]  eta: 0:13:50  Lr: 0.001875  Loss: -1.0094  Acc@1: 87.5000 (82.4538)  Acc@5: 100.0000 (96.7460)  time: 0.3503  data: 0.0013  max mem: 2500
Train: Epoch[4/5]  [1390/3750]  eta: 0:13:46  Lr: 0.001875  Loss: -0.5527  Acc@1: 81.2500 (82.4317)  Acc@5: 100.0000 (96.7335)  time: 0.3502  data: 0.0013  max mem: 2500
Train: Epoch[4/5]  [1400/3750]  eta: 0:13:43  Lr: 0.001875  Loss: -0.7042  Acc@1: 81.2500 (82.4545)  Acc@5: 93.7500 (96.7345)  time: 0.3490  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1410/3750]  eta: 0:13:39  Lr: 0.001875  Loss: -0.8516  Acc@1: 81.2500 (82.4371)  Acc@5: 93.7500 (96.7045)  time: 0.3490  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1420/3750]  eta: 0:13:36  Lr: 0.001875  Loss: -1.0873  Acc@1: 87.5000 (82.4551)  Acc@5: 93.7500 (96.6969)  time: 0.3502  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1430/3750]  eta: 0:13:32  Lr: 0.001875  Loss: -0.9740  Acc@1: 81.2500 (82.4161)  Acc@5: 93.7500 (96.6937)  time: 0.3504  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [1440/3750]  eta: 0:13:29  Lr: 0.001875  Loss: -0.9580  Acc@1: 81.2500 (82.4297)  Acc@5: 100.0000 (96.7080)  time: 0.3501  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [1450/3750]  eta: 0:13:25  Lr: 0.001875  Loss: -1.1943  Acc@1: 81.2500 (82.4302)  Acc@5: 100.0000 (96.7092)  time: 0.3513  data: 0.0009  max mem: 2500
Train: Epoch[4/5]  [1460/3750]  eta: 0:13:22  Lr: 0.001875  Loss: -0.9054  Acc@1: 81.2500 (82.4179)  Acc@5: 100.0000 (96.7146)  time: 0.3513  data: 0.0009  max mem: 2500
Train: Epoch[4/5]  [1470/3750]  eta: 0:13:18  Lr: 0.001875  Loss: -0.7483  Acc@1: 75.0000 (82.3972)  Acc@5: 100.0000 (96.7114)  time: 0.3506  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [1480/3750]  eta: 0:13:15  Lr: 0.001875  Loss: -1.0183  Acc@1: 81.2500 (82.3937)  Acc@5: 93.7500 (96.7041)  time: 0.3506  data: 0.0010  max mem: 2500
Train: Epoch[4/5]  [1490/3750]  eta: 0:13:11  Lr: 0.001875  Loss: -0.7277  Acc@1: 81.2500 (82.3566)  Acc@5: 93.7500 (96.6968)  time: 0.3503  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [1500/3750]  eta: 0:13:08  Lr: 0.001875  Loss: -0.6596  Acc@1: 81.2500 (82.3243)  Acc@5: 100.0000 (96.6855)  time: 0.3520  data: 0.0014  max mem: 2500
Train: Epoch[4/5]  [1510/3750]  eta: 0:13:05  Lr: 0.001875  Loss: -1.0718  Acc@1: 81.2500 (82.3627)  Acc@5: 100.0000 (96.6909)  time: 0.3527  data: 0.0014  max mem: 2500
Train: Epoch[4/5]  [1520/3750]  eta: 0:13:01  Lr: 0.001875  Loss: -1.4227  Acc@1: 87.5000 (82.3636)  Acc@5: 100.0000 (96.7086)  time: 0.3521  data: 0.0018  max mem: 2500
Train: Epoch[4/5]  [1530/3750]  eta: 0:12:58  Lr: 0.001875  Loss: -1.3098  Acc@1: 87.5000 (82.3930)  Acc@5: 100.0000 (96.7056)  time: 0.3518  data: 0.0018  max mem: 2500
Train: Epoch[4/5]  [1540/3750]  eta: 0:12:54  Lr: 0.001875  Loss: -1.0141  Acc@1: 81.2500 (82.3816)  Acc@5: 100.0000 (96.7229)  time: 0.3507  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [1550/3750]  eta: 0:12:51  Lr: 0.001875  Loss: -1.2042  Acc@1: 81.2500 (82.3944)  Acc@5: 100.0000 (96.7199)  time: 0.3534  data: 0.0020  max mem: 2500
Train: Epoch[4/5]  [1560/3750]  eta: 0:12:47  Lr: 0.001875  Loss: -0.9009  Acc@1: 87.5000 (82.4391)  Acc@5: 100.0000 (96.7289)  time: 0.3537  data: 0.0020  max mem: 2500
Train: Epoch[4/5]  [1570/3750]  eta: 0:12:44  Lr: 0.001875  Loss: -0.1819  Acc@1: 81.2500 (82.4077)  Acc@5: 93.7500 (96.7099)  time: 0.3504  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1580/3750]  eta: 0:12:40  Lr: 0.001875  Loss: -1.1406  Acc@1: 81.2500 (82.4241)  Acc@5: 93.7500 (96.7030)  time: 0.3514  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1590/3750]  eta: 0:12:37  Lr: 0.001875  Loss: -1.1659  Acc@1: 87.5000 (82.4521)  Acc@5: 100.0000 (96.7120)  time: 0.3520  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1600/3750]  eta: 0:12:33  Lr: 0.001875  Loss: -0.8680  Acc@1: 81.2500 (82.4172)  Acc@5: 100.0000 (96.7013)  time: 0.3511  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1610/3750]  eta: 0:12:30  Lr: 0.001875  Loss: -0.9075  Acc@1: 75.0000 (82.3751)  Acc@5: 93.7500 (96.6713)  time: 0.3497  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1620/3750]  eta: 0:12:26  Lr: 0.001875  Loss: -1.1350  Acc@1: 81.2500 (82.4028)  Acc@5: 93.7500 (96.6764)  time: 0.3492  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [1630/3750]  eta: 0:12:23  Lr: 0.001875  Loss: -1.0176  Acc@1: 81.2500 (82.3843)  Acc@5: 100.0000 (96.6623)  time: 0.3504  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [1640/3750]  eta: 0:12:19  Lr: 0.001875  Loss: -1.1201  Acc@1: 87.5000 (82.4116)  Acc@5: 100.0000 (96.6750)  time: 0.3511  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [1650/3750]  eta: 0:12:16  Lr: 0.001875  Loss: -0.6869  Acc@1: 87.5000 (82.4084)  Acc@5: 100.0000 (96.6800)  time: 0.3526  data: 0.0021  max mem: 2500
Train: Epoch[4/5]  [1660/3750]  eta: 0:12:12  Lr: 0.001875  Loss: -0.8691  Acc@1: 81.2500 (82.4014)  Acc@5: 100.0000 (96.6699)  time: 0.3523  data: 0.0020  max mem: 2500
Train: Epoch[4/5]  [1670/3750]  eta: 0:12:09  Lr: 0.001875  Loss: -1.0412  Acc@1: 81.2500 (82.4095)  Acc@5: 100.0000 (96.6786)  time: 0.3510  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1680/3750]  eta: 0:12:05  Lr: 0.001875  Loss: -0.8551  Acc@1: 81.2500 (82.4323)  Acc@5: 100.0000 (96.6947)  time: 0.3511  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1690/3750]  eta: 0:12:02  Lr: 0.001875  Loss: -1.1718  Acc@1: 87.5000 (82.4475)  Acc@5: 100.0000 (96.6920)  time: 0.3505  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1700/3750]  eta: 0:11:58  Lr: 0.001875  Loss: -1.3443  Acc@1: 81.2500 (82.4662)  Acc@5: 100.0000 (96.6931)  time: 0.3517  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [1710/3750]  eta: 0:11:55  Lr: 0.001875  Loss: -1.2302  Acc@1: 87.5000 (82.4883)  Acc@5: 100.0000 (96.7015)  time: 0.3541  data: 0.0025  max mem: 2500
Train: Epoch[4/5]  [1720/3750]  eta: 0:11:51  Lr: 0.001875  Loss: -1.0104  Acc@1: 87.5000 (82.4956)  Acc@5: 100.0000 (96.7025)  time: 0.3519  data: 0.0025  max mem: 2500
Train: Epoch[4/5]  [1730/3750]  eta: 0:11:48  Lr: 0.001875  Loss: -0.8456  Acc@1: 81.2500 (82.4848)  Acc@5: 93.7500 (96.6963)  time: 0.3498  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [1740/3750]  eta: 0:11:44  Lr: 0.001875  Loss: -0.8792  Acc@1: 75.0000 (82.4418)  Acc@5: 93.7500 (96.6829)  time: 0.3493  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [1750/3750]  eta: 0:11:41  Lr: 0.001875  Loss: -0.7527  Acc@1: 75.0000 (82.4243)  Acc@5: 93.7500 (96.6769)  time: 0.3502  data: 0.0012  max mem: 2500
Train: Epoch[4/5]  [1760/3750]  eta: 0:11:37  Lr: 0.001875  Loss: -1.0025  Acc@1: 81.2500 (82.4106)  Acc@5: 93.7500 (96.6816)  time: 0.3502  data: 0.0012  max mem: 2500
Train: Epoch[4/5]  [1770/3750]  eta: 0:11:34  Lr: 0.001875  Loss: -1.1708  Acc@1: 81.2500 (82.4252)  Acc@5: 100.0000 (96.6827)  time: 0.3501  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1780/3750]  eta: 0:11:30  Lr: 0.001875  Loss: -0.9120  Acc@1: 87.5000 (82.4221)  Acc@5: 100.0000 (96.6767)  time: 0.3506  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [1790/3750]  eta: 0:11:27  Lr: 0.001875  Loss: -0.8412  Acc@1: 81.2500 (82.4155)  Acc@5: 93.7500 (96.6639)  time: 0.3513  data: 0.0017  max mem: 2500
Train: Epoch[4/5]  [1800/3750]  eta: 0:11:23  Lr: 0.001875  Loss: -1.2837  Acc@1: 81.2500 (82.4160)  Acc@5: 93.7500 (96.6755)  time: 0.3521  data: 0.0017  max mem: 2500
Train: Epoch[4/5]  [1810/3750]  eta: 0:11:20  Lr: 0.001875  Loss: -1.1586  Acc@1: 81.2500 (82.3923)  Acc@5: 100.0000 (96.6628)  time: 0.3501  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [1820/3750]  eta: 0:11:16  Lr: 0.001875  Loss: -1.1922  Acc@1: 81.2500 (82.3861)  Acc@5: 93.7500 (96.6571)  time: 0.3493  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [1830/3750]  eta: 0:11:13  Lr: 0.001875  Loss: -1.2851  Acc@1: 81.2500 (82.3901)  Acc@5: 100.0000 (96.6617)  time: 0.3506  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [1840/3750]  eta: 0:11:09  Lr: 0.001875  Loss: -0.9071  Acc@1: 81.2500 (82.3975)  Acc@5: 100.0000 (96.6628)  time: 0.3515  data: 0.0019  max mem: 2500
Train: Epoch[4/5]  [1850/3750]  eta: 0:11:06  Lr: 0.001875  Loss: -1.1804  Acc@1: 81.2500 (82.3811)  Acc@5: 100.0000 (96.6673)  time: 0.3510  data: 0.0022  max mem: 2500
Train: Epoch[4/5]  [1860/3750]  eta: 0:11:02  Lr: 0.001875  Loss: -0.7917  Acc@1: 81.2500 (82.3919)  Acc@5: 100.0000 (96.6651)  time: 0.3503  data: 0.0014  max mem: 2500
Train: Epoch[4/5]  [1870/3750]  eta: 0:10:59  Lr: 0.001875  Loss: -1.2512  Acc@1: 87.5000 (82.4158)  Acc@5: 100.0000 (96.6696)  time: 0.3501  data: 0.0017  max mem: 2500
Train: Epoch[4/5]  [1880/3750]  eta: 0:10:55  Lr: 0.001875  Loss: -1.0819  Acc@1: 87.5000 (82.4362)  Acc@5: 100.0000 (96.6773)  time: 0.3496  data: 0.0011  max mem: 2500
Train: Epoch[4/5]  [1890/3750]  eta: 0:10:52  Lr: 0.001875  Loss: -0.7985  Acc@1: 87.5000 (82.4299)  Acc@5: 100.0000 (96.6816)  time: 0.3500  data: 0.0011  max mem: 2500
Train: Epoch[4/5]  [1900/3750]  eta: 0:10:48  Lr: 0.001875  Loss: -0.7546  Acc@1: 81.2500 (82.4237)  Acc@5: 100.0000 (96.6925)  time: 0.3518  data: 0.0011  max mem: 2500
Train: Epoch[4/5]  [1910/3750]  eta: 0:10:45  Lr: 0.001875  Loss: -1.0034  Acc@1: 81.2500 (82.4143)  Acc@5: 100.0000 (96.6869)  time: 0.3506  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1920/3750]  eta: 0:10:41  Lr: 0.001875  Loss: -1.2727  Acc@1: 81.2500 (82.3985)  Acc@5: 93.7500 (96.6847)  time: 0.3506  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [1930/3750]  eta: 0:10:38  Lr: 0.001875  Loss: -0.9639  Acc@1: 81.2500 (82.4120)  Acc@5: 100.0000 (96.6889)  time: 0.3513  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [1940/3750]  eta: 0:10:34  Lr: 0.001875  Loss: -1.2038  Acc@1: 81.2500 (82.3899)  Acc@5: 100.0000 (96.6770)  time: 0.3498  data: 0.0009  max mem: 2500
Train: Epoch[4/5]  [1950/3750]  eta: 0:10:31  Lr: 0.001875  Loss: -1.0767  Acc@1: 81.2500 (82.4001)  Acc@5: 100.0000 (96.6748)  time: 0.3506  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [1960/3750]  eta: 0:10:27  Lr: 0.001875  Loss: -1.2384  Acc@1: 81.2500 (82.3751)  Acc@5: 93.7500 (96.6662)  time: 0.3504  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [1970/3750]  eta: 0:10:24  Lr: 0.001875  Loss: -0.9992  Acc@1: 87.5000 (82.4011)  Acc@5: 93.7500 (96.6705)  time: 0.3506  data: 0.0014  max mem: 2500
Train: Epoch[4/5]  [1980/3750]  eta: 0:10:20  Lr: 0.001875  Loss: -1.2969  Acc@1: 87.5000 (82.4300)  Acc@5: 100.0000 (96.6747)  time: 0.3505  data: 0.0013  max mem: 2500
Train: Epoch[4/5]  [1990/3750]  eta: 0:10:16  Lr: 0.001875  Loss: -1.0599  Acc@1: 87.5000 (82.4335)  Acc@5: 93.7500 (96.6662)  time: 0.3505  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2000/3750]  eta: 0:10:13  Lr: 0.001875  Loss: -0.9391  Acc@1: 81.2500 (82.4182)  Acc@5: 93.7500 (96.6673)  time: 0.3509  data: 0.0009  max mem: 2500
Train: Epoch[4/5]  [2010/3750]  eta: 0:10:09  Lr: 0.001875  Loss: -1.0290  Acc@1: 81.2500 (82.3906)  Acc@5: 93.7500 (96.6683)  time: 0.3509  data: 0.0009  max mem: 2500
Train: Epoch[4/5]  [2020/3750]  eta: 0:10:06  Lr: 0.001875  Loss: -1.0966  Acc@1: 81.2500 (82.3850)  Acc@5: 100.0000 (96.6724)  time: 0.3516  data: 0.0009  max mem: 2500
Train: Epoch[4/5]  [2030/3750]  eta: 0:10:02  Lr: 0.001875  Loss: -1.0035  Acc@1: 81.2500 (82.3978)  Acc@5: 100.0000 (96.6734)  time: 0.3516  data: 0.0018  max mem: 2500
Train: Epoch[4/5]  [2040/3750]  eta: 0:09:59  Lr: 0.001875  Loss: -0.9417  Acc@1: 81.2500 (82.4014)  Acc@5: 100.0000 (96.6775)  time: 0.3520  data: 0.0014  max mem: 2500
Train: Epoch[4/5]  [2050/3750]  eta: 0:09:56  Lr: 0.001875  Loss: -1.0969  Acc@1: 81.2500 (82.3775)  Acc@5: 100.0000 (96.6876)  time: 0.3518  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [2060/3750]  eta: 0:09:52  Lr: 0.001875  Loss: -0.9302  Acc@1: 81.2500 (82.3902)  Acc@5: 100.0000 (96.6946)  time: 0.3501  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2070/3750]  eta: 0:09:48  Lr: 0.001875  Loss: -0.9886  Acc@1: 81.2500 (82.3787)  Acc@5: 100.0000 (96.6985)  time: 0.3487  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2080/3750]  eta: 0:09:45  Lr: 0.001875  Loss: -1.2274  Acc@1: 81.2500 (82.3823)  Acc@5: 100.0000 (96.7083)  time: 0.3497  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [2090/3750]  eta: 0:09:41  Lr: 0.001875  Loss: -0.7656  Acc@1: 87.5000 (82.3858)  Acc@5: 100.0000 (96.6972)  time: 0.3502  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [2100/3750]  eta: 0:09:38  Lr: 0.001875  Loss: -0.4958  Acc@1: 87.5000 (82.3864)  Acc@5: 93.7500 (96.6980)  time: 0.3509  data: 0.0014  max mem: 2500
Train: Epoch[4/5]  [2110/3750]  eta: 0:09:34  Lr: 0.001875  Loss: -1.0808  Acc@1: 87.5000 (82.3780)  Acc@5: 100.0000 (96.6988)  time: 0.3513  data: 0.0015  max mem: 2500
Train: Epoch[4/5]  [2120/3750]  eta: 0:09:31  Lr: 0.001875  Loss: -1.0375  Acc@1: 87.5000 (82.4022)  Acc@5: 100.0000 (96.6997)  time: 0.3492  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2130/3750]  eta: 0:09:27  Lr: 0.001875  Loss: -0.8342  Acc@1: 87.5000 (82.3909)  Acc@5: 100.0000 (96.6976)  time: 0.3480  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2140/3750]  eta: 0:09:24  Lr: 0.001875  Loss: -1.0169  Acc@1: 81.2500 (82.3856)  Acc@5: 100.0000 (96.6926)  time: 0.3496  data: 0.0017  max mem: 2500
Train: Epoch[4/5]  [2150/3750]  eta: 0:09:20  Lr: 0.001875  Loss: -1.3228  Acc@1: 87.5000 (82.4152)  Acc@5: 93.7500 (96.6905)  time: 0.3511  data: 0.0020  max mem: 2500
Train: Epoch[4/5]  [2160/3750]  eta: 0:09:17  Lr: 0.001875  Loss: -0.6950  Acc@1: 87.5000 (82.4040)  Acc@5: 93.7500 (96.6827)  time: 0.3502  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [2170/3750]  eta: 0:09:13  Lr: 0.001875  Loss: -1.1475  Acc@1: 81.2500 (82.4044)  Acc@5: 93.7500 (96.6778)  time: 0.3494  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2180/3750]  eta: 0:09:10  Lr: 0.001875  Loss: -1.0744  Acc@1: 87.5000 (82.4192)  Acc@5: 93.7500 (96.6787)  time: 0.3487  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2190/3750]  eta: 0:09:06  Lr: 0.001875  Loss: -1.2498  Acc@1: 87.5000 (82.4481)  Acc@5: 100.0000 (96.6825)  time: 0.3488  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2200/3750]  eta: 0:09:03  Lr: 0.001875  Loss: -0.8016  Acc@1: 87.5000 (82.4540)  Acc@5: 100.0000 (96.6890)  time: 0.3489  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2210/3750]  eta: 0:08:59  Lr: 0.001875  Loss: -0.8576  Acc@1: 81.2500 (82.4344)  Acc@5: 100.0000 (96.6955)  time: 0.3490  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [2220/3750]  eta: 0:08:56  Lr: 0.001875  Loss: -1.2754  Acc@1: 81.2500 (82.4488)  Acc@5: 100.0000 (96.7076)  time: 0.3493  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [2230/3750]  eta: 0:08:52  Lr: 0.001875  Loss: -1.2466  Acc@1: 87.5000 (82.4630)  Acc@5: 100.0000 (96.7139)  time: 0.3491  data: 0.0011  max mem: 2500
Train: Epoch[4/5]  [2240/3750]  eta: 0:08:49  Lr: 0.001875  Loss: -0.7810  Acc@1: 81.2500 (82.4492)  Acc@5: 100.0000 (96.7091)  time: 0.3493  data: 0.0012  max mem: 2500
Train: Epoch[4/5]  [2250/3750]  eta: 0:08:45  Lr: 0.001875  Loss: -1.3072  Acc@1: 81.2500 (82.4550)  Acc@5: 100.0000 (96.7070)  time: 0.3496  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2260/3750]  eta: 0:08:42  Lr: 0.001875  Loss: -1.4608  Acc@1: 87.5000 (82.4718)  Acc@5: 100.0000 (96.7161)  time: 0.3494  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [2270/3750]  eta: 0:08:38  Lr: 0.001875  Loss: -0.6511  Acc@1: 87.5000 (82.4719)  Acc@5: 100.0000 (96.7140)  time: 0.3505  data: 0.0013  max mem: 2500
Train: Epoch[4/5]  [2280/3750]  eta: 0:08:35  Lr: 0.001875  Loss: -0.6169  Acc@1: 81.2500 (82.4638)  Acc@5: 100.0000 (96.7120)  time: 0.3511  data: 0.0012  max mem: 2500
Train: Epoch[4/5]  [2290/3750]  eta: 0:08:31  Lr: 0.001875  Loss: -1.3795  Acc@1: 81.2500 (82.4667)  Acc@5: 100.0000 (96.7072)  time: 0.3497  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2300/3750]  eta: 0:08:28  Lr: 0.001875  Loss: -0.7343  Acc@1: 81.2500 (82.4587)  Acc@5: 93.7500 (96.7080)  time: 0.3492  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2310/3750]  eta: 0:08:24  Lr: 0.001875  Loss: -0.9986  Acc@1: 81.2500 (82.4670)  Acc@5: 93.7500 (96.7033)  time: 0.3486  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2320/3750]  eta: 0:08:21  Lr: 0.001875  Loss: -1.0170  Acc@1: 81.2500 (82.4537)  Acc@5: 93.7500 (96.6959)  time: 0.3488  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2330/3750]  eta: 0:08:17  Lr: 0.001875  Loss: -1.0964  Acc@1: 81.2500 (82.4673)  Acc@5: 100.0000 (96.6994)  time: 0.3492  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2340/3750]  eta: 0:08:14  Lr: 0.001875  Loss: -1.3347  Acc@1: 87.5000 (82.5048)  Acc@5: 100.0000 (96.7135)  time: 0.3494  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [2350/3750]  eta: 0:08:10  Lr: 0.001875  Loss: -1.0911  Acc@1: 87.5000 (82.5154)  Acc@5: 100.0000 (96.7168)  time: 0.3497  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [2360/3750]  eta: 0:08:07  Lr: 0.001875  Loss: -1.1256  Acc@1: 87.5000 (82.5392)  Acc@5: 100.0000 (96.7122)  time: 0.3508  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2370/3750]  eta: 0:08:03  Lr: 0.001875  Loss: -0.7785  Acc@1: 87.5000 (82.5337)  Acc@5: 93.7500 (96.7102)  time: 0.3529  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2380/3750]  eta: 0:08:00  Lr: 0.001875  Loss: -1.2411  Acc@1: 81.2500 (82.5362)  Acc@5: 93.7500 (96.7031)  time: 0.3527  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2390/3750]  eta: 0:07:56  Lr: 0.001875  Loss: -1.1864  Acc@1: 81.2500 (82.5282)  Acc@5: 93.7500 (96.6959)  time: 0.3520  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [2400/3750]  eta: 0:07:53  Lr: 0.001875  Loss: -0.3982  Acc@1: 81.2500 (82.5177)  Acc@5: 100.0000 (96.6967)  time: 0.3523  data: 0.0013  max mem: 2500
Train: Epoch[4/5]  [2410/3750]  eta: 0:07:49  Lr: 0.001875  Loss: -1.1600  Acc@1: 81.2500 (82.5073)  Acc@5: 93.7500 (96.6922)  time: 0.3510  data: 0.0012  max mem: 2500
Train: Epoch[4/5]  [2420/3750]  eta: 0:07:46  Lr: 0.001875  Loss: -1.4368  Acc@1: 75.0000 (82.4814)  Acc@5: 93.7500 (96.6956)  time: 0.3501  data: 0.0009  max mem: 2500
Train: Epoch[4/5]  [2430/3750]  eta: 0:07:42  Lr: 0.001875  Loss: -1.3706  Acc@1: 81.2500 (82.4892)  Acc@5: 100.0000 (96.7015)  time: 0.3498  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [2440/3750]  eta: 0:07:39  Lr: 0.001875  Loss: -1.0364  Acc@1: 81.2500 (82.4713)  Acc@5: 100.0000 (96.6971)  time: 0.3489  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2450/3750]  eta: 0:07:35  Lr: 0.001875  Loss: -0.7614  Acc@1: 81.2500 (82.4689)  Acc@5: 93.7500 (96.6927)  time: 0.3502  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2460/3750]  eta: 0:07:32  Lr: 0.001875  Loss: -0.7773  Acc@1: 81.2500 (82.4563)  Acc@5: 100.0000 (96.6934)  time: 0.3509  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2470/3750]  eta: 0:07:28  Lr: 0.001875  Loss: -1.0364  Acc@1: 81.2500 (82.4438)  Acc@5: 93.7500 (96.6815)  time: 0.3501  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2480/3750]  eta: 0:07:25  Lr: 0.001875  Loss: -1.4516  Acc@1: 87.5000 (82.4768)  Acc@5: 100.0000 (96.6898)  time: 0.3502  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2490/3750]  eta: 0:07:21  Lr: 0.001875  Loss: -0.6257  Acc@1: 87.5000 (82.4694)  Acc@5: 100.0000 (96.6881)  time: 0.3505  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2500/3750]  eta: 0:07:18  Lr: 0.001875  Loss: -1.1980  Acc@1: 87.5000 (82.4845)  Acc@5: 100.0000 (96.6938)  time: 0.3508  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2510/3750]  eta: 0:07:14  Lr: 0.001875  Loss: -1.0744  Acc@1: 87.5000 (82.5020)  Acc@5: 100.0000 (96.6970)  time: 0.3512  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [2520/3750]  eta: 0:07:11  Lr: 0.001875  Loss: -1.0381  Acc@1: 81.2500 (82.4995)  Acc@5: 100.0000 (96.6977)  time: 0.3510  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [2530/3750]  eta: 0:07:07  Lr: 0.001875  Loss: -0.9435  Acc@1: 81.2500 (82.5119)  Acc@5: 93.7500 (96.6935)  time: 0.3522  data: 0.0017  max mem: 2500
Train: Epoch[4/5]  [2540/3750]  eta: 0:07:04  Lr: 0.001875  Loss: -0.9626  Acc@1: 81.2500 (82.5020)  Acc@5: 100.0000 (96.6967)  time: 0.3520  data: 0.0016  max mem: 2500
Train: Epoch[4/5]  [2550/3750]  eta: 0:07:00  Lr: 0.001875  Loss: -0.9551  Acc@1: 81.2500 (82.5093)  Acc@5: 100.0000 (96.6974)  time: 0.3519  data: 0.0017  max mem: 2500
Train: Epoch[4/5]  [2560/3750]  eta: 0:06:57  Lr: 0.001875  Loss: -0.9748  Acc@1: 81.2500 (82.5337)  Acc@5: 100.0000 (96.7029)  time: 0.3522  data: 0.0016  max mem: 2500
Train: Epoch[4/5]  [2570/3750]  eta: 0:06:53  Lr: 0.001875  Loss: -1.3635  Acc@1: 87.5000 (82.5433)  Acc@5: 100.0000 (96.7012)  time: 0.3521  data: 0.0012  max mem: 2500
Train: Epoch[4/5]  [2580/3750]  eta: 0:06:50  Lr: 0.001875  Loss: -0.6574  Acc@1: 81.2500 (82.5213)  Acc@5: 93.7500 (96.6873)  time: 0.3526  data: 0.0012  max mem: 2500
Train: Epoch[4/5]  [2590/3750]  eta: 0:06:46  Lr: 0.001875  Loss: -1.1344  Acc@1: 87.5000 (82.5381)  Acc@5: 93.7500 (96.6929)  time: 0.3520  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [2600/3750]  eta: 0:06:43  Lr: 0.001875  Loss: -0.8587  Acc@1: 87.5000 (82.5596)  Acc@5: 100.0000 (96.7008)  time: 0.3521  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [2610/3750]  eta: 0:06:39  Lr: 0.001875  Loss: -0.7009  Acc@1: 93.7500 (82.5713)  Acc@5: 100.0000 (96.6943)  time: 0.3512  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [2620/3750]  eta: 0:06:36  Lr: 0.001875  Loss: -1.0441  Acc@1: 81.2500 (82.5711)  Acc@5: 93.7500 (96.6926)  time: 0.3514  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2630/3750]  eta: 0:06:32  Lr: 0.001875  Loss: -0.7553  Acc@1: 81.2500 (82.5827)  Acc@5: 100.0000 (96.6980)  time: 0.3522  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [2640/3750]  eta: 0:06:29  Lr: 0.001875  Loss: -1.3113  Acc@1: 81.2500 (82.5942)  Acc@5: 100.0000 (96.7011)  time: 0.3511  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [2650/3750]  eta: 0:06:25  Lr: 0.001875  Loss: -1.1185  Acc@1: 87.5000 (82.6127)  Acc@5: 100.0000 (96.7041)  time: 0.3511  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2660/3750]  eta: 0:06:22  Lr: 0.001875  Loss: -1.0173  Acc@1: 81.2500 (82.6052)  Acc@5: 93.7500 (96.7000)  time: 0.3513  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2670/3750]  eta: 0:06:18  Lr: 0.001875  Loss: -0.7354  Acc@1: 81.2500 (82.6072)  Acc@5: 100.0000 (96.7030)  time: 0.3515  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [2680/3750]  eta: 0:06:15  Lr: 0.001875  Loss: -0.9649  Acc@1: 81.2500 (82.6138)  Acc@5: 100.0000 (96.7013)  time: 0.3517  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [2690/3750]  eta: 0:06:11  Lr: 0.001875  Loss: -0.8556  Acc@1: 81.2500 (82.6017)  Acc@5: 93.7500 (96.6927)  time: 0.3509  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [2700/3750]  eta: 0:06:08  Lr: 0.001875  Loss: -0.4663  Acc@1: 81.2500 (82.6037)  Acc@5: 93.7500 (96.6887)  time: 0.3503  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2710/3750]  eta: 0:06:04  Lr: 0.001875  Loss: -0.8983  Acc@1: 81.2500 (82.5964)  Acc@5: 100.0000 (96.6802)  time: 0.3499  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2720/3750]  eta: 0:06:01  Lr: 0.001875  Loss: -1.1581  Acc@1: 75.0000 (82.5753)  Acc@5: 93.7500 (96.6763)  time: 0.3499  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2730/3750]  eta: 0:05:57  Lr: 0.001875  Loss: -0.8363  Acc@1: 81.2500 (82.5751)  Acc@5: 93.7500 (96.6725)  time: 0.3507  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2740/3750]  eta: 0:05:54  Lr: 0.001875  Loss: -0.1903  Acc@1: 81.2500 (82.5657)  Acc@5: 100.0000 (96.6709)  time: 0.3521  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [2750/3750]  eta: 0:05:50  Lr: 0.001875  Loss: -0.5967  Acc@1: 81.2500 (82.5654)  Acc@5: 93.7500 (96.6626)  time: 0.3510  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [2760/3750]  eta: 0:05:47  Lr: 0.001875  Loss: -1.0959  Acc@1: 81.2500 (82.5652)  Acc@5: 100.0000 (96.6656)  time: 0.3495  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [2770/3750]  eta: 0:05:43  Lr: 0.001875  Loss: -0.9632  Acc@1: 81.2500 (82.5356)  Acc@5: 100.0000 (96.6641)  time: 0.3497  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2780/3750]  eta: 0:05:40  Lr: 0.001875  Loss: -1.2574  Acc@1: 81.2500 (82.5445)  Acc@5: 93.7500 (96.6649)  time: 0.3505  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [2790/3750]  eta: 0:05:36  Lr: 0.001875  Loss: -0.6517  Acc@1: 81.2500 (82.5309)  Acc@5: 100.0000 (96.6656)  time: 0.3512  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [2800/3750]  eta: 0:05:33  Lr: 0.001875  Loss: -0.6905  Acc@1: 81.2500 (82.5486)  Acc@5: 100.0000 (96.6708)  time: 0.3507  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [2810/3750]  eta: 0:05:29  Lr: 0.001875  Loss: -0.1744  Acc@1: 81.2500 (82.5218)  Acc@5: 100.0000 (96.6693)  time: 0.3525  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [2820/3750]  eta: 0:05:26  Lr: 0.001875  Loss: -0.6219  Acc@1: 75.0000 (82.5195)  Acc@5: 100.0000 (96.6701)  time: 0.3534  data: 0.0011  max mem: 2500
Train: Epoch[4/5]  [2830/3750]  eta: 0:05:22  Lr: 0.001875  Loss: -0.9949  Acc@1: 81.2500 (82.5238)  Acc@5: 100.0000 (96.6708)  time: 0.3505  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [2840/3750]  eta: 0:05:19  Lr: 0.001875  Loss: -1.4454  Acc@1: 87.5000 (82.5392)  Acc@5: 100.0000 (96.6803)  time: 0.3495  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2850/3750]  eta: 0:05:15  Lr: 0.001875  Loss: -0.8519  Acc@1: 87.5000 (82.5478)  Acc@5: 100.0000 (96.6898)  time: 0.3498  data: 0.0011  max mem: 2500
Train: Epoch[4/5]  [2860/3750]  eta: 0:05:12  Lr: 0.001875  Loss: -0.3750  Acc@1: 81.2500 (82.5454)  Acc@5: 100.0000 (96.6904)  time: 0.3507  data: 0.0011  max mem: 2500
Train: Epoch[4/5]  [2870/3750]  eta: 0:05:08  Lr: 0.001875  Loss: -0.9003  Acc@1: 81.2500 (82.5496)  Acc@5: 100.0000 (96.6889)  time: 0.3499  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2880/3750]  eta: 0:05:04  Lr: 0.001875  Loss: -0.7095  Acc@1: 81.2500 (82.5538)  Acc@5: 100.0000 (96.6960)  time: 0.3491  data: 0.0011  max mem: 2500
Train: Epoch[4/5]  [2890/3750]  eta: 0:05:01  Lr: 0.001875  Loss: -1.1043  Acc@1: 87.5000 (82.5709)  Acc@5: 100.0000 (96.7010)  time: 0.3510  data: 0.0011  max mem: 2500
Train: Epoch[4/5]  [2900/3750]  eta: 0:04:57  Lr: 0.001875  Loss: -0.8439  Acc@1: 87.5000 (82.5793)  Acc@5: 100.0000 (96.7016)  time: 0.3507  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2910/3750]  eta: 0:04:54  Lr: 0.001875  Loss: -1.2370  Acc@1: 87.5000 (82.5940)  Acc@5: 100.0000 (96.7043)  time: 0.3499  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2920/3750]  eta: 0:04:50  Lr: 0.001875  Loss: -1.1664  Acc@1: 87.5000 (82.6087)  Acc@5: 100.0000 (96.7049)  time: 0.3506  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2930/3750]  eta: 0:04:47  Lr: 0.001875  Loss: -1.2164  Acc@1: 81.2500 (82.5977)  Acc@5: 93.7500 (96.6969)  time: 0.3502  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [2940/3750]  eta: 0:04:43  Lr: 0.001875  Loss: -0.7758  Acc@1: 81.2500 (82.6016)  Acc@5: 100.0000 (96.7061)  time: 0.3504  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [2950/3750]  eta: 0:04:40  Lr: 0.001875  Loss: -0.5068  Acc@1: 81.2500 (82.5885)  Acc@5: 100.0000 (96.6960)  time: 0.3512  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [2960/3750]  eta: 0:04:36  Lr: 0.001875  Loss: -1.1556  Acc@1: 81.2500 (82.5946)  Acc@5: 100.0000 (96.6945)  time: 0.3509  data: 0.0010  max mem: 2500
Train: Epoch[4/5]  [2970/3750]  eta: 0:04:33  Lr: 0.001875  Loss: -0.8194  Acc@1: 87.5000 (82.5900)  Acc@5: 100.0000 (96.6951)  time: 0.3528  data: 0.0010  max mem: 2500
Train: Epoch[4/5]  [2980/3750]  eta: 0:04:29  Lr: 0.001875  Loss: -0.7592  Acc@1: 81.2500 (82.5855)  Acc@5: 93.7500 (96.6874)  time: 0.3530  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [2990/3750]  eta: 0:04:26  Lr: 0.001875  Loss: -1.1200  Acc@1: 75.0000 (82.5685)  Acc@5: 93.7500 (96.6817)  time: 0.3521  data: 0.0013  max mem: 2500
Train: Epoch[4/5]  [3000/3750]  eta: 0:04:22  Lr: 0.001875  Loss: -0.6123  Acc@1: 75.0000 (82.5579)  Acc@5: 100.0000 (96.6782)  time: 0.3533  data: 0.0013  max mem: 2500
Train: Epoch[4/5]  [3010/3750]  eta: 0:04:19  Lr: 0.001875  Loss: -0.4783  Acc@1: 75.0000 (82.5349)  Acc@5: 93.7500 (96.6726)  time: 0.3546  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [3020/3750]  eta: 0:04:15  Lr: 0.001875  Loss: -1.1641  Acc@1: 81.2500 (82.5389)  Acc@5: 93.7500 (96.6691)  time: 0.3534  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [3030/3750]  eta: 0:04:12  Lr: 0.001875  Loss: -1.2291  Acc@1: 81.2500 (82.5264)  Acc@5: 100.0000 (96.6719)  time: 0.3533  data: 0.0025  max mem: 2500
Train: Epoch[4/5]  [3040/3750]  eta: 0:04:08  Lr: 0.001875  Loss: -1.1134  Acc@1: 81.2500 (82.5284)  Acc@5: 100.0000 (96.6787)  time: 0.3537  data: 0.0021  max mem: 2500
Train: Epoch[4/5]  [3050/3750]  eta: 0:04:05  Lr: 0.001875  Loss: -0.9551  Acc@1: 81.2500 (82.5098)  Acc@5: 100.0000 (96.6773)  time: 0.3532  data: 0.0026  max mem: 2500
Train: Epoch[4/5]  [3060/3750]  eta: 0:04:01  Lr: 0.001875  Loss: -0.9736  Acc@1: 81.2500 (82.5221)  Acc@5: 100.0000 (96.6861)  time: 0.3537  data: 0.0026  max mem: 2500
Train: Epoch[4/5]  [3070/3750]  eta: 0:03:58  Lr: 0.001875  Loss: -1.0735  Acc@1: 87.5000 (82.5261)  Acc@5: 100.0000 (96.6908)  time: 0.3522  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [3080/3750]  eta: 0:03:54  Lr: 0.001875  Loss: -1.2698  Acc@1: 87.5000 (82.5219)  Acc@5: 100.0000 (96.6995)  time: 0.3525  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [3090/3750]  eta: 0:03:51  Lr: 0.001875  Loss: -0.8721  Acc@1: 81.2500 (82.5097)  Acc@5: 100.0000 (96.6940)  time: 0.3532  data: 0.0009  max mem: 2500
Train: Epoch[4/5]  [3100/3750]  eta: 0:03:47  Lr: 0.001875  Loss: -0.8546  Acc@1: 81.2500 (82.5137)  Acc@5: 100.0000 (96.6966)  time: 0.3533  data: 0.0020  max mem: 2500
Train: Epoch[4/5]  [3110/3750]  eta: 0:03:44  Lr: 0.001875  Loss: -1.1702  Acc@1: 81.2500 (82.5157)  Acc@5: 100.0000 (96.6972)  time: 0.3530  data: 0.0015  max mem: 2500
Train: Epoch[4/5]  [3120/3750]  eta: 0:03:40  Lr: 0.001875  Loss: -0.8997  Acc@1: 87.5000 (82.5356)  Acc@5: 100.0000 (96.7018)  time: 0.3520  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3130/3750]  eta: 0:03:37  Lr: 0.001875  Loss: -1.3053  Acc@1: 87.5000 (82.5295)  Acc@5: 100.0000 (96.7043)  time: 0.3508  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [3140/3750]  eta: 0:03:33  Lr: 0.001875  Loss: -0.8414  Acc@1: 81.2500 (82.5414)  Acc@5: 100.0000 (96.7128)  time: 0.3508  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [3150/3750]  eta: 0:03:30  Lr: 0.001875  Loss: -1.2461  Acc@1: 81.2500 (82.5274)  Acc@5: 100.0000 (96.7054)  time: 0.3510  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3160/3750]  eta: 0:03:26  Lr: 0.001875  Loss: -0.7778  Acc@1: 81.2500 (82.5194)  Acc@5: 93.7500 (96.7059)  time: 0.3508  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [3170/3750]  eta: 0:03:23  Lr: 0.001875  Loss: -1.4780  Acc@1: 81.2500 (82.5173)  Acc@5: 100.0000 (96.7045)  time: 0.3538  data: 0.0017  max mem: 2500
Train: Epoch[4/5]  [3180/3750]  eta: 0:03:19  Lr: 0.001875  Loss: -1.0498  Acc@1: 75.0000 (82.5016)  Acc@5: 93.7500 (96.6992)  time: 0.3540  data: 0.0017  max mem: 2500
Train: Epoch[4/5]  [3190/3750]  eta: 0:03:16  Lr: 0.001875  Loss: -1.2279  Acc@1: 81.2500 (82.5074)  Acc@5: 93.7500 (96.6997)  time: 0.3525  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3200/3750]  eta: 0:03:12  Lr: 0.001875  Loss: -1.0697  Acc@1: 87.5000 (82.5074)  Acc@5: 100.0000 (96.6983)  time: 0.3511  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [3210/3750]  eta: 0:03:09  Lr: 0.001875  Loss: -0.9375  Acc@1: 87.5000 (82.5074)  Acc@5: 100.0000 (96.7008)  time: 0.3495  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3220/3750]  eta: 0:03:05  Lr: 0.001875  Loss: -1.2769  Acc@1: 81.2500 (82.5171)  Acc@5: 100.0000 (96.7033)  time: 0.3504  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3230/3750]  eta: 0:03:02  Lr: 0.001875  Loss: -0.8486  Acc@1: 81.2500 (82.5054)  Acc@5: 100.0000 (96.7038)  time: 0.3513  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3240/3750]  eta: 0:02:58  Lr: 0.001875  Loss: -1.2794  Acc@1: 75.0000 (82.4861)  Acc@5: 93.7500 (96.6889)  time: 0.3504  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3250/3750]  eta: 0:02:55  Lr: 0.001875  Loss: -1.1788  Acc@1: 81.2500 (82.4881)  Acc@5: 93.7500 (96.6933)  time: 0.3500  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [3260/3750]  eta: 0:02:51  Lr: 0.001875  Loss: -0.9759  Acc@1: 81.2500 (82.4785)  Acc@5: 93.7500 (96.6862)  time: 0.3517  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [3270/3750]  eta: 0:02:48  Lr: 0.001875  Loss: -0.7595  Acc@1: 81.2500 (82.4805)  Acc@5: 93.7500 (96.6830)  time: 0.3508  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [3280/3750]  eta: 0:02:44  Lr: 0.001875  Loss: -0.8031  Acc@1: 81.2500 (82.4863)  Acc@5: 93.7500 (96.6817)  time: 0.3497  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [3290/3750]  eta: 0:02:41  Lr: 0.001875  Loss: -1.1106  Acc@1: 81.2500 (82.4825)  Acc@5: 93.7500 (96.6822)  time: 0.3513  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [3300/3750]  eta: 0:02:37  Lr: 0.001875  Loss: -0.9758  Acc@1: 81.2500 (82.4864)  Acc@5: 93.7500 (96.6790)  time: 0.3511  data: 0.0009  max mem: 2500
Train: Epoch[4/5]  [3310/3750]  eta: 0:02:34  Lr: 0.001875  Loss: -0.9627  Acc@1: 81.2500 (82.4958)  Acc@5: 100.0000 (96.6834)  time: 0.3508  data: 0.0011  max mem: 2500
Train: Epoch[4/5]  [3320/3750]  eta: 0:02:30  Lr: 0.001875  Loss: -0.3740  Acc@1: 81.2500 (82.4921)  Acc@5: 100.0000 (96.6821)  time: 0.3519  data: 0.0009  max mem: 2500
Train: Epoch[4/5]  [3330/3750]  eta: 0:02:27  Lr: 0.001875  Loss: -1.1943  Acc@1: 87.5000 (82.4996)  Acc@5: 100.0000 (96.6827)  time: 0.3514  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [3340/3750]  eta: 0:02:23  Lr: 0.001875  Loss: -1.1732  Acc@1: 87.5000 (82.5015)  Acc@5: 100.0000 (96.6851)  time: 0.3513  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [3350/3750]  eta: 0:02:20  Lr: 0.001875  Loss: -0.8605  Acc@1: 87.5000 (82.5052)  Acc@5: 100.0000 (96.6820)  time: 0.3501  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3360/3750]  eta: 0:02:16  Lr: 0.001875  Loss: -0.5308  Acc@1: 81.2500 (82.4996)  Acc@5: 93.7500 (96.6788)  time: 0.3518  data: 0.0021  max mem: 2500
Train: Epoch[4/5]  [3370/3750]  eta: 0:02:13  Lr: 0.001875  Loss: -0.9179  Acc@1: 81.2500 (82.5033)  Acc@5: 93.7500 (96.6738)  time: 0.3526  data: 0.0021  max mem: 2500
Train: Epoch[4/5]  [3380/3750]  eta: 0:02:09  Lr: 0.001875  Loss: -0.8130  Acc@1: 87.5000 (82.5107)  Acc@5: 93.7500 (96.6744)  time: 0.3504  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3390/3750]  eta: 0:02:06  Lr: 0.001875  Loss: -1.1296  Acc@1: 87.5000 (82.5181)  Acc@5: 100.0000 (96.6806)  time: 0.3505  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3400/3750]  eta: 0:02:02  Lr: 0.001875  Loss: -0.9498  Acc@1: 81.2500 (82.5198)  Acc@5: 100.0000 (96.6848)  time: 0.3513  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [3410/3750]  eta: 0:01:59  Lr: 0.001875  Loss: -1.2515  Acc@1: 81.2500 (82.4996)  Acc@5: 93.7500 (96.6725)  time: 0.3520  data: 0.0013  max mem: 2500
Train: Epoch[4/5]  [3420/3750]  eta: 0:01:55  Lr: 0.001875  Loss: -0.6250  Acc@1: 81.2500 (82.4923)  Acc@5: 93.7500 (96.6749)  time: 0.3503  data: 0.0013  max mem: 2500
Train: Epoch[4/5]  [3430/3750]  eta: 0:01:52  Lr: 0.001875  Loss: -1.2416  Acc@1: 87.5000 (82.5124)  Acc@5: 100.0000 (96.6810)  time: 0.3484  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3440/3750]  eta: 0:01:48  Lr: 0.001875  Loss: -1.2513  Acc@1: 87.5000 (82.5160)  Acc@5: 100.0000 (96.6834)  time: 0.3487  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3450/3750]  eta: 0:01:45  Lr: 0.001875  Loss: -0.8372  Acc@1: 81.2500 (82.5069)  Acc@5: 100.0000 (96.6857)  time: 0.3494  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [3460/3750]  eta: 0:01:41  Lr: 0.001875  Loss: -1.3033  Acc@1: 87.5000 (82.5285)  Acc@5: 100.0000 (96.6917)  time: 0.3490  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [3470/3750]  eta: 0:01:38  Lr: 0.001875  Loss: -1.2044  Acc@1: 81.2500 (82.5248)  Acc@5: 100.0000 (96.6940)  time: 0.3486  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3480/3750]  eta: 0:01:34  Lr: 0.001875  Loss: -1.1548  Acc@1: 81.2500 (82.5230)  Acc@5: 100.0000 (96.6928)  time: 0.3486  data: 0.0003  max mem: 2500
Train: Epoch[4/5]  [3490/3750]  eta: 0:01:31  Lr: 0.001875  Loss: -1.0507  Acc@1: 87.5000 (82.5354)  Acc@5: 100.0000 (96.6969)  time: 0.3488  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [3500/3750]  eta: 0:01:27  Lr: 0.001875  Loss: -1.0497  Acc@1: 87.5000 (82.5371)  Acc@5: 100.0000 (96.6884)  time: 0.3496  data: 0.0006  max mem: 2500
Train: Epoch[4/5]  [3510/3750]  eta: 0:01:24  Lr: 0.001875  Loss: -1.4305  Acc@1: 87.5000 (82.5530)  Acc@5: 100.0000 (96.6925)  time: 0.3489  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3520/3750]  eta: 0:01:20  Lr: 0.001875  Loss: -0.8977  Acc@1: 87.5000 (82.5529)  Acc@5: 100.0000 (96.6984)  time: 0.3489  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3530/3750]  eta: 0:01:17  Lr: 0.001875  Loss: -0.8388  Acc@1: 87.5000 (82.5634)  Acc@5: 100.0000 (96.7060)  time: 0.3487  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3540/3750]  eta: 0:01:13  Lr: 0.001875  Loss: -0.9776  Acc@1: 81.2500 (82.5614)  Acc@5: 100.0000 (96.7117)  time: 0.3487  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3550/3750]  eta: 0:01:10  Lr: 0.001875  Loss: -1.2343  Acc@1: 81.2500 (82.5648)  Acc@5: 100.0000 (96.7104)  time: 0.3497  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3560/3750]  eta: 0:01:06  Lr: 0.001875  Loss: -1.0700  Acc@1: 81.2500 (82.5699)  Acc@5: 93.7500 (96.7039)  time: 0.3492  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [3570/3750]  eta: 0:01:03  Lr: 0.001875  Loss: -1.0967  Acc@1: 87.5000 (82.5732)  Acc@5: 93.7500 (96.7061)  time: 0.3480  data: 0.0008  max mem: 2500
Train: Epoch[4/5]  [3580/3750]  eta: 0:00:59  Lr: 0.001875  Loss: -1.2926  Acc@1: 87.5000 (82.5817)  Acc@5: 100.0000 (96.7101)  time: 0.3485  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [3590/3750]  eta: 0:00:56  Lr: 0.001875  Loss: -1.1996  Acc@1: 87.5000 (82.5849)  Acc@5: 100.0000 (96.7123)  time: 0.3498  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [3600/3750]  eta: 0:00:52  Lr: 0.001875  Loss: -1.0686  Acc@1: 87.5000 (82.5882)  Acc@5: 100.0000 (96.7127)  time: 0.3496  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3610/3750]  eta: 0:00:49  Lr: 0.001875  Loss: -1.3031  Acc@1: 81.2500 (82.5793)  Acc@5: 100.0000 (96.7097)  time: 0.3496  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3620/3750]  eta: 0:00:45  Lr: 0.001875  Loss: -0.8246  Acc@1: 81.2500 (82.5739)  Acc@5: 100.0000 (96.7136)  time: 0.3490  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [3630/3750]  eta: 0:00:42  Lr: 0.001875  Loss: -0.4014  Acc@1: 81.2500 (82.5754)  Acc@5: 100.0000 (96.7158)  time: 0.3478  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [3640/3750]  eta: 0:00:38  Lr: 0.001875  Loss: -0.8887  Acc@1: 81.2500 (82.5718)  Acc@5: 100.0000 (96.7128)  time: 0.3481  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3650/3750]  eta: 0:00:35  Lr: 0.001875  Loss: -0.8352  Acc@1: 81.2500 (82.5630)  Acc@5: 93.7500 (96.7132)  time: 0.3502  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [3660/3750]  eta: 0:00:31  Lr: 0.001875  Loss: -1.0931  Acc@1: 81.2500 (82.5577)  Acc@5: 100.0000 (96.7137)  time: 0.3499  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [3670/3750]  eta: 0:00:28  Lr: 0.001875  Loss: -1.0888  Acc@1: 81.2500 (82.5541)  Acc@5: 100.0000 (96.7175)  time: 0.3492  data: 0.0007  max mem: 2500
Train: Epoch[4/5]  [3680/3750]  eta: 0:00:24  Lr: 0.001875  Loss: -1.2051  Acc@1: 81.2500 (82.5591)  Acc@5: 100.0000 (96.7213)  time: 0.3502  data: 0.0004  max mem: 2500
Train: Epoch[4/5]  [3690/3750]  eta: 0:00:21  Lr: 0.001875  Loss: -0.9884  Acc@1: 81.2500 (82.5589)  Acc@5: 100.0000 (96.7201)  time: 0.3489  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [3700/3750]  eta: 0:00:17  Lr: 0.001875  Loss: -1.1733  Acc@1: 81.2500 (82.5655)  Acc@5: 100.0000 (96.7239)  time: 0.3482  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [3710/3750]  eta: 0:00:14  Lr: 0.001875  Loss: -1.0297  Acc@1: 87.5000 (82.5704)  Acc@5: 100.0000 (96.7175)  time: 0.3486  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [3720/3750]  eta: 0:00:10  Lr: 0.001875  Loss: -0.9918  Acc@1: 81.2500 (82.5736)  Acc@5: 93.7500 (96.7163)  time: 0.3495  data: 0.0005  max mem: 2500
Train: Epoch[4/5]  [3730/3750]  eta: 0:00:07  Lr: 0.001875  Loss: -1.0278  Acc@1: 81.2500 (82.5683)  Acc@5: 100.0000 (96.7217)  time: 0.3500  data: 0.0012  max mem: 2500
Train: Epoch[4/5]  [3740/3750]  eta: 0:00:03  Lr: 0.001875  Loss: -0.7517  Acc@1: 75.0000 (82.5515)  Acc@5: 100.0000 (96.7205)  time: 0.3499  data: 0.0019  max mem: 2500
Train: Epoch[4/5]  [3749/3750]  eta: 0:00:00  Lr: 0.001875  Loss: -1.0246  Acc@1: 75.0000 (82.5483)  Acc@5: 100.0000 (96.7267)  time: 0.3501  data: 0.0015  max mem: 2500
Train: Epoch[4/5] Total time: 0:21:55 (0.3508 s / it)
Averaged stats: Lr: 0.001875  Loss: -1.0246  Acc@1: 75.0000 (82.5483)  Acc@5: 100.0000 (96.7267)
Train: Epoch[5/5]  [   0/3750]  eta: 0:46:00  Lr: 0.001875  Loss: -0.9161  Acc@1: 81.2500 (81.2500)  Acc@5: 93.7500 (93.7500)  time: 0.7360  data: 0.3855  max mem: 2500
Train: Epoch[5/5]  [  10/3750]  eta: 0:23:56  Lr: 0.001875  Loss: -0.5491  Acc@1: 81.2500 (80.6818)  Acc@5: 100.0000 (97.1591)  time: 0.3841  data: 0.0357  max mem: 2500
Train: Epoch[5/5]  [  20/3750]  eta: 0:22:50  Lr: 0.001875  Loss: -1.0871  Acc@1: 81.2500 (80.0595)  Acc@5: 100.0000 (97.6190)  time: 0.3491  data: 0.0011  max mem: 2500
Train: Epoch[5/5]  [  30/3750]  eta: 0:22:24  Lr: 0.001875  Loss: -1.1417  Acc@1: 75.0000 (80.0403)  Acc@5: 100.0000 (96.5726)  time: 0.3488  data: 0.0010  max mem: 2500
Train: Epoch[5/5]  [  40/3750]  eta: 0:22:09  Lr: 0.001875  Loss: -1.0503  Acc@1: 81.2500 (81.8598)  Acc@5: 100.0000 (97.1037)  time: 0.3487  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [  50/3750]  eta: 0:21:59  Lr: 0.001875  Loss: -0.6561  Acc@1: 87.5000 (81.7402)  Acc@5: 100.0000 (96.5686)  time: 0.3494  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [  60/3750]  eta: 0:21:51  Lr: 0.001875  Loss: -0.9409  Acc@1: 81.2500 (82.1721)  Acc@5: 93.7500 (96.4139)  time: 0.3498  data: 0.0014  max mem: 2500
Train: Epoch[5/5]  [  70/3750]  eta: 0:21:44  Lr: 0.001875  Loss: -1.0851  Acc@1: 81.2500 (81.9542)  Acc@5: 100.0000 (96.6549)  time: 0.3491  data: 0.0014  max mem: 2500
Train: Epoch[5/5]  [  80/3750]  eta: 0:21:38  Lr: 0.001875  Loss: -0.5123  Acc@1: 81.2500 (81.9444)  Acc@5: 100.0000 (96.7593)  time: 0.3489  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [  90/3750]  eta: 0:21:33  Lr: 0.001875  Loss: -1.1313  Acc@1: 81.2500 (82.4176)  Acc@5: 100.0000 (96.9780)  time: 0.3489  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [ 100/3750]  eta: 0:21:28  Lr: 0.001875  Loss: -0.9239  Acc@1: 87.5000 (82.1163)  Acc@5: 100.0000 (97.0297)  time: 0.3492  data: 0.0010  max mem: 2500
Train: Epoch[5/5]  [ 110/3750]  eta: 0:21:23  Lr: 0.001875  Loss: -1.4829  Acc@1: 87.5000 (82.4324)  Acc@5: 100.0000 (97.1284)  time: 0.3498  data: 0.0011  max mem: 2500
Train: Epoch[5/5]  [ 120/3750]  eta: 0:21:19  Lr: 0.001875  Loss: -1.1662  Acc@1: 87.5000 (82.9029)  Acc@5: 100.0000 (97.0558)  time: 0.3495  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 130/3750]  eta: 0:21:15  Lr: 0.001875  Loss: -1.0718  Acc@1: 87.5000 (83.0153)  Acc@5: 100.0000 (97.1851)  time: 0.3505  data: 0.0012  max mem: 2500
Train: Epoch[5/5]  [ 140/3750]  eta: 0:21:11  Lr: 0.001875  Loss: -0.8273  Acc@1: 81.2500 (82.9344)  Acc@5: 100.0000 (97.1188)  time: 0.3510  data: 0.0017  max mem: 2500
Train: Epoch[5/5]  [ 150/3750]  eta: 0:21:07  Lr: 0.001875  Loss: -1.0366  Acc@1: 81.2500 (82.8642)  Acc@5: 100.0000 (97.1440)  time: 0.3499  data: 0.0013  max mem: 2500
Train: Epoch[5/5]  [ 160/3750]  eta: 0:21:03  Lr: 0.001875  Loss: -0.8848  Acc@1: 81.2500 (82.9193)  Acc@5: 100.0000 (97.1273)  time: 0.3503  data: 0.0019  max mem: 2500
Train: Epoch[5/5]  [ 170/3750]  eta: 0:20:59  Lr: 0.001875  Loss: -1.0898  Acc@1: 81.2500 (82.7851)  Acc@5: 100.0000 (97.0395)  time: 0.3503  data: 0.0015  max mem: 2500
Train: Epoch[5/5]  [ 180/3750]  eta: 0:20:55  Lr: 0.001875  Loss: -0.9680  Acc@1: 81.2500 (82.8384)  Acc@5: 93.7500 (96.9959)  time: 0.3494  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 190/3750]  eta: 0:20:51  Lr: 0.001875  Loss: -1.1445  Acc@1: 81.2500 (82.8861)  Acc@5: 100.0000 (97.1531)  time: 0.3491  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 200/3750]  eta: 0:20:47  Lr: 0.001875  Loss: -1.0301  Acc@1: 87.5000 (82.9913)  Acc@5: 100.0000 (97.2948)  time: 0.3487  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 210/3750]  eta: 0:20:44  Lr: 0.001875  Loss: -1.0317  Acc@1: 81.2500 (83.0865)  Acc@5: 100.0000 (97.3637)  time: 0.3503  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [ 220/3750]  eta: 0:20:40  Lr: 0.001875  Loss: -1.0336  Acc@1: 81.2500 (83.0882)  Acc@5: 100.0000 (97.4830)  time: 0.3508  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [ 230/3750]  eta: 0:20:36  Lr: 0.001875  Loss: -0.5392  Acc@1: 81.2500 (82.8463)  Acc@5: 100.0000 (97.4838)  time: 0.3496  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [ 240/3750]  eta: 0:20:32  Lr: 0.001875  Loss: -0.9321  Acc@1: 81.2500 (82.8579)  Acc@5: 100.0000 (97.5363)  time: 0.3495  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 250/3750]  eta: 0:20:29  Lr: 0.001875  Loss: -1.3167  Acc@1: 87.5000 (82.9681)  Acc@5: 100.0000 (97.5100)  time: 0.3510  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [ 260/3750]  eta: 0:20:25  Lr: 0.001875  Loss: -1.5022  Acc@1: 81.2500 (82.9981)  Acc@5: 100.0000 (97.4617)  time: 0.3509  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [ 270/3750]  eta: 0:20:22  Lr: 0.001875  Loss: -1.3372  Acc@1: 87.5000 (83.1181)  Acc@5: 100.0000 (97.4631)  time: 0.3507  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 280/3750]  eta: 0:20:18  Lr: 0.001875  Loss: -1.1568  Acc@1: 81.2500 (83.0516)  Acc@5: 100.0000 (97.4422)  time: 0.3508  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [ 290/3750]  eta: 0:20:15  Lr: 0.001875  Loss: -1.0999  Acc@1: 81.2500 (83.1615)  Acc@5: 100.0000 (97.4012)  time: 0.3509  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [ 300/3750]  eta: 0:20:11  Lr: 0.001875  Loss: -0.4488  Acc@1: 81.2500 (83.0980)  Acc@5: 100.0000 (97.4460)  time: 0.3520  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 310/3750]  eta: 0:20:07  Lr: 0.001875  Loss: -1.0785  Acc@1: 81.2500 (83.1592)  Acc@5: 100.0000 (97.4477)  time: 0.3507  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 320/3750]  eta: 0:20:04  Lr: 0.001875  Loss: -0.4576  Acc@1: 81.2500 (83.0413)  Acc@5: 100.0000 (97.4104)  time: 0.3504  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 330/3750]  eta: 0:20:00  Lr: 0.001875  Loss: -1.1227  Acc@1: 81.2500 (82.9872)  Acc@5: 100.0000 (97.3943)  time: 0.3506  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 340/3750]  eta: 0:19:57  Lr: 0.001875  Loss: -1.3880  Acc@1: 81.2500 (82.9912)  Acc@5: 100.0000 (97.4157)  time: 0.3501  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [ 350/3750]  eta: 0:19:53  Lr: 0.001875  Loss: -1.2106  Acc@1: 87.5000 (83.0306)  Acc@5: 100.0000 (97.3825)  time: 0.3501  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [ 360/3750]  eta: 0:19:50  Lr: 0.001875  Loss: -0.8899  Acc@1: 81.2500 (82.9813)  Acc@5: 100.0000 (97.3511)  time: 0.3503  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [ 370/3750]  eta: 0:19:46  Lr: 0.001875  Loss: -0.9777  Acc@1: 81.2500 (82.9009)  Acc@5: 93.7500 (97.3214)  time: 0.3520  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [ 380/3750]  eta: 0:19:43  Lr: 0.001875  Loss: -0.6842  Acc@1: 81.2500 (82.8904)  Acc@5: 93.7500 (97.2933)  time: 0.3520  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [ 390/3750]  eta: 0:19:39  Lr: 0.001875  Loss: -1.2022  Acc@1: 81.2500 (82.8325)  Acc@5: 93.7500 (97.2826)  time: 0.3503  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 400/3750]  eta: 0:19:35  Lr: 0.001875  Loss: -0.9043  Acc@1: 81.2500 (82.7774)  Acc@5: 93.7500 (97.2569)  time: 0.3501  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 410/3750]  eta: 0:19:32  Lr: 0.001875  Loss: -1.1484  Acc@1: 81.2500 (82.8163)  Acc@5: 93.7500 (97.2324)  time: 0.3502  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [ 420/3750]  eta: 0:19:28  Lr: 0.001875  Loss: -0.8369  Acc@1: 81.2500 (82.7494)  Acc@5: 93.7500 (97.1942)  time: 0.3511  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [ 430/3750]  eta: 0:19:25  Lr: 0.001875  Loss: -1.1408  Acc@1: 81.2500 (82.7291)  Acc@5: 93.7500 (97.1578)  time: 0.3511  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [ 440/3750]  eta: 0:19:21  Lr: 0.001875  Loss: -1.1165  Acc@1: 81.2500 (82.6389)  Acc@5: 100.0000 (97.1797)  time: 0.3505  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [ 450/3750]  eta: 0:19:18  Lr: 0.001875  Loss: -0.7358  Acc@1: 81.2500 (82.4557)  Acc@5: 93.7500 (97.0898)  time: 0.3509  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [ 460/3750]  eta: 0:19:14  Lr: 0.001875  Loss: -1.1618  Acc@1: 75.0000 (82.3753)  Acc@5: 93.7500 (97.0987)  time: 0.3500  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [ 470/3750]  eta: 0:19:11  Lr: 0.001875  Loss: -1.4624  Acc@1: 81.2500 (82.4177)  Acc@5: 100.0000 (97.1205)  time: 0.3494  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 480/3750]  eta: 0:19:07  Lr: 0.001875  Loss: -1.3358  Acc@1: 81.2500 (82.4454)  Acc@5: 100.0000 (97.1414)  time: 0.3499  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 490/3750]  eta: 0:19:03  Lr: 0.001875  Loss: -1.4103  Acc@1: 87.5000 (82.5102)  Acc@5: 100.0000 (97.1487)  time: 0.3498  data: 0.0011  max mem: 2500
Train: Epoch[5/5]  [ 500/3750]  eta: 0:19:00  Lr: 0.001875  Loss: -0.8623  Acc@1: 87.5000 (82.5225)  Acc@5: 100.0000 (97.1557)  time: 0.3504  data: 0.0014  max mem: 2500
Train: Epoch[5/5]  [ 510/3750]  eta: 0:18:56  Lr: 0.001875  Loss: -1.1530  Acc@1: 87.5000 (82.5709)  Acc@5: 100.0000 (97.1991)  time: 0.3504  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [ 520/3750]  eta: 0:18:53  Lr: 0.001875  Loss: -1.1540  Acc@1: 87.5000 (82.6655)  Acc@5: 100.0000 (97.2169)  time: 0.3502  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [ 530/3750]  eta: 0:18:49  Lr: 0.001875  Loss: -0.2714  Acc@1: 87.5000 (82.6271)  Acc@5: 100.0000 (97.2105)  time: 0.3493  data: 0.0010  max mem: 2500
Train: Epoch[5/5]  [ 540/3750]  eta: 0:18:46  Lr: 0.001875  Loss: -1.2221  Acc@1: 81.2500 (82.6710)  Acc@5: 93.7500 (97.1696)  time: 0.3484  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [ 550/3750]  eta: 0:18:42  Lr: 0.001875  Loss: -1.1734  Acc@1: 87.5000 (82.7700)  Acc@5: 100.0000 (97.1869)  time: 0.3491  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [ 560/3750]  eta: 0:18:38  Lr: 0.001875  Loss: -1.3379  Acc@1: 87.5000 (82.7540)  Acc@5: 100.0000 (97.1480)  time: 0.3493  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 570/3750]  eta: 0:18:35  Lr: 0.001875  Loss: -0.9419  Acc@1: 81.2500 (82.7605)  Acc@5: 100.0000 (97.1432)  time: 0.3488  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 580/3750]  eta: 0:18:31  Lr: 0.001875  Loss: -1.1508  Acc@1: 81.2500 (82.7560)  Acc@5: 100.0000 (97.1493)  time: 0.3489  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 590/3750]  eta: 0:18:28  Lr: 0.001875  Loss: -1.3734  Acc@1: 81.2500 (82.7094)  Acc@5: 100.0000 (97.1447)  time: 0.3497  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 600/3750]  eta: 0:18:24  Lr: 0.001875  Loss: -0.8972  Acc@1: 87.5000 (82.7995)  Acc@5: 100.0000 (97.1714)  time: 0.3492  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 610/3750]  eta: 0:18:21  Lr: 0.001875  Loss: -0.9235  Acc@1: 87.5000 (82.8355)  Acc@5: 100.0000 (97.1870)  time: 0.3501  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [ 620/3750]  eta: 0:18:17  Lr: 0.001875  Loss: -0.8184  Acc@1: 81.2500 (82.8200)  Acc@5: 100.0000 (97.1920)  time: 0.3500  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [ 630/3750]  eta: 0:18:13  Lr: 0.001875  Loss: -0.5537  Acc@1: 87.5000 (82.8645)  Acc@5: 100.0000 (97.2068)  time: 0.3488  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [ 640/3750]  eta: 0:18:10  Lr: 0.001875  Loss: -1.0600  Acc@1: 87.5000 (82.9368)  Acc@5: 100.0000 (97.2211)  time: 0.3495  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [ 650/3750]  eta: 0:18:06  Lr: 0.001875  Loss: -1.0642  Acc@1: 87.5000 (82.9397)  Acc@5: 100.0000 (97.2542)  time: 0.3493  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [ 660/3750]  eta: 0:18:03  Lr: 0.001875  Loss: -0.6343  Acc@1: 81.2500 (82.9425)  Acc@5: 100.0000 (97.2485)  time: 0.3494  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 670/3750]  eta: 0:17:59  Lr: 0.001875  Loss: -0.5948  Acc@1: 81.2500 (82.8707)  Acc@5: 100.0000 (97.2336)  time: 0.3487  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 680/3750]  eta: 0:17:55  Lr: 0.001875  Loss: -0.9758  Acc@1: 81.2500 (82.9295)  Acc@5: 100.0000 (97.2375)  time: 0.3476  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 690/3750]  eta: 0:17:52  Lr: 0.001875  Loss: -1.0799  Acc@1: 87.5000 (83.0047)  Acc@5: 100.0000 (97.2051)  time: 0.3477  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 700/3750]  eta: 0:17:48  Lr: 0.001875  Loss: -1.1754  Acc@1: 87.5000 (82.9708)  Acc@5: 93.7500 (97.2004)  time: 0.3486  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 710/3750]  eta: 0:17:45  Lr: 0.001875  Loss: -0.7485  Acc@1: 87.5000 (83.0257)  Acc@5: 100.0000 (97.2222)  time: 0.3487  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 720/3750]  eta: 0:17:41  Lr: 0.001875  Loss: -1.3421  Acc@1: 87.5000 (82.9837)  Acc@5: 100.0000 (97.2174)  time: 0.3482  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 730/3750]  eta: 0:17:37  Lr: 0.001875  Loss: -0.9244  Acc@1: 75.0000 (82.9172)  Acc@5: 100.0000 (97.1871)  time: 0.3482  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [ 740/3750]  eta: 0:17:34  Lr: 0.001875  Loss: -1.2041  Acc@1: 81.2500 (82.8947)  Acc@5: 93.7500 (97.1491)  time: 0.3477  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [ 750/3750]  eta: 0:17:30  Lr: 0.001875  Loss: -1.1753  Acc@1: 87.5000 (82.9228)  Acc@5: 93.7500 (97.1538)  time: 0.3479  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [ 760/3750]  eta: 0:17:27  Lr: 0.001875  Loss: -0.7924  Acc@1: 87.5000 (82.9254)  Acc@5: 100.0000 (97.1583)  time: 0.3490  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [ 770/3750]  eta: 0:17:23  Lr: 0.001875  Loss: -0.9040  Acc@1: 81.2500 (82.8632)  Acc@5: 100.0000 (97.1628)  time: 0.3490  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 780/3750]  eta: 0:17:20  Lr: 0.001875  Loss: -1.1077  Acc@1: 81.2500 (82.8745)  Acc@5: 100.0000 (97.1831)  time: 0.3487  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 790/3750]  eta: 0:17:16  Lr: 0.001875  Loss: -0.8687  Acc@1: 81.2500 (82.8224)  Acc@5: 100.0000 (97.1713)  time: 0.3496  data: 0.0012  max mem: 2500
Train: Epoch[5/5]  [ 800/3750]  eta: 0:17:13  Lr: 0.001875  Loss: -0.2079  Acc@1: 81.2500 (82.8105)  Acc@5: 93.7500 (97.1364)  time: 0.3500  data: 0.0014  max mem: 2500
Train: Epoch[5/5]  [ 810/3750]  eta: 0:17:09  Lr: 0.001875  Loss: -0.9914  Acc@1: 87.5000 (82.7990)  Acc@5: 93.7500 (97.1100)  time: 0.3490  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [ 820/3750]  eta: 0:17:05  Lr: 0.001875  Loss: -0.7829  Acc@1: 87.5000 (82.8563)  Acc@5: 100.0000 (97.1148)  time: 0.3485  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 830/3750]  eta: 0:17:02  Lr: 0.001875  Loss: -0.8593  Acc@1: 87.5000 (82.8219)  Acc@5: 100.0000 (97.1044)  time: 0.3500  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [ 840/3750]  eta: 0:16:58  Lr: 0.001875  Loss: -1.0884  Acc@1: 81.2500 (82.8329)  Acc@5: 100.0000 (97.1240)  time: 0.3504  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [ 850/3750]  eta: 0:16:55  Lr: 0.001875  Loss: -1.3486  Acc@1: 87.5000 (82.8804)  Acc@5: 100.0000 (97.1284)  time: 0.3500  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [ 860/3750]  eta: 0:16:51  Lr: 0.001875  Loss: -0.8646  Acc@1: 81.2500 (82.8470)  Acc@5: 100.0000 (97.1400)  time: 0.3493  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 870/3750]  eta: 0:16:48  Lr: 0.001875  Loss: -1.0861  Acc@1: 81.2500 (82.8573)  Acc@5: 100.0000 (97.1297)  time: 0.3486  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 880/3750]  eta: 0:16:44  Lr: 0.001875  Loss: -1.3026  Acc@1: 81.2500 (82.8249)  Acc@5: 93.7500 (97.1127)  time: 0.3484  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [ 890/3750]  eta: 0:16:41  Lr: 0.001875  Loss: -1.2910  Acc@1: 81.2500 (82.8353)  Acc@5: 100.0000 (97.1240)  time: 0.3486  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [ 900/3750]  eta: 0:16:37  Lr: 0.001875  Loss: -0.6945  Acc@1: 81.2500 (82.7969)  Acc@5: 100.0000 (97.1213)  time: 0.3520  data: 0.0014  max mem: 2500
Train: Epoch[5/5]  [ 910/3750]  eta: 0:16:34  Lr: 0.001875  Loss: -0.6678  Acc@1: 81.2500 (82.8074)  Acc@5: 100.0000 (97.1117)  time: 0.3519  data: 0.0014  max mem: 2500
Train: Epoch[5/5]  [ 920/3750]  eta: 0:16:30  Lr: 0.001875  Loss: -1.3227  Acc@1: 81.2500 (82.7972)  Acc@5: 100.0000 (97.1091)  time: 0.3491  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [ 930/3750]  eta: 0:16:27  Lr: 0.001875  Loss: -1.2498  Acc@1: 81.2500 (82.8142)  Acc@5: 100.0000 (97.1267)  time: 0.3492  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [ 940/3750]  eta: 0:16:23  Lr: 0.001875  Loss: -1.0601  Acc@1: 81.2500 (82.8042)  Acc@5: 100.0000 (97.1108)  time: 0.3502  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [ 950/3750]  eta: 0:16:20  Lr: 0.001875  Loss: -1.1799  Acc@1: 81.2500 (82.8339)  Acc@5: 93.7500 (97.1017)  time: 0.3511  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [ 960/3750]  eta: 0:16:16  Lr: 0.001875  Loss: -1.2042  Acc@1: 87.5000 (82.8369)  Acc@5: 100.0000 (97.1189)  time: 0.3508  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [ 970/3750]  eta: 0:16:13  Lr: 0.001875  Loss: -1.1290  Acc@1: 81.2500 (82.8012)  Acc@5: 100.0000 (97.1228)  time: 0.3503  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [ 980/3750]  eta: 0:16:09  Lr: 0.001875  Loss: -1.2298  Acc@1: 81.2500 (82.8555)  Acc@5: 100.0000 (97.1203)  time: 0.3496  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [ 990/3750]  eta: 0:16:06  Lr: 0.001875  Loss: -0.8731  Acc@1: 87.5000 (82.8582)  Acc@5: 100.0000 (97.1241)  time: 0.3504  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1000/3750]  eta: 0:16:02  Lr: 0.001875  Loss: -1.1664  Acc@1: 87.5000 (82.9108)  Acc@5: 100.0000 (97.1154)  time: 0.3508  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1010/3750]  eta: 0:15:59  Lr: 0.001875  Loss: -1.1461  Acc@1: 81.2500 (82.8573)  Acc@5: 93.7500 (97.1006)  time: 0.3510  data: 0.0011  max mem: 2500
Train: Epoch[5/5]  [1020/3750]  eta: 0:15:55  Lr: 0.001875  Loss: -1.3037  Acc@1: 81.2500 (82.8538)  Acc@5: 100.0000 (97.1046)  time: 0.3516  data: 0.0019  max mem: 2500
Train: Epoch[5/5]  [1030/3750]  eta: 0:15:52  Lr: 0.001875  Loss: -0.7976  Acc@1: 87.5000 (82.8868)  Acc@5: 100.0000 (97.1084)  time: 0.3504  data: 0.0011  max mem: 2500
Train: Epoch[5/5]  [1040/3750]  eta: 0:15:48  Lr: 0.001875  Loss: -0.7281  Acc@1: 81.2500 (82.8530)  Acc@5: 100.0000 (97.1122)  time: 0.3495  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1050/3750]  eta: 0:15:45  Lr: 0.001875  Loss: -0.8946  Acc@1: 81.2500 (82.8675)  Acc@5: 100.0000 (97.1277)  time: 0.3495  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1060/3750]  eta: 0:15:41  Lr: 0.001875  Loss: -0.5108  Acc@1: 81.2500 (82.8464)  Acc@5: 100.0000 (97.1254)  time: 0.3497  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1070/3750]  eta: 0:15:38  Lr: 0.001875  Loss: -0.8739  Acc@1: 81.2500 (82.8782)  Acc@5: 100.0000 (97.1230)  time: 0.3499  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1080/3750]  eta: 0:15:34  Lr: 0.001875  Loss: -0.8466  Acc@1: 87.5000 (82.9151)  Acc@5: 100.0000 (97.1265)  time: 0.3506  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1090/3750]  eta: 0:15:31  Lr: 0.001875  Loss: -1.0660  Acc@1: 87.5000 (82.9228)  Acc@5: 100.0000 (97.1357)  time: 0.3505  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1100/3750]  eta: 0:15:27  Lr: 0.001875  Loss: -0.7041  Acc@1: 81.2500 (82.9360)  Acc@5: 100.0000 (97.1219)  time: 0.3497  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1110/3750]  eta: 0:15:24  Lr: 0.001875  Loss: -1.1388  Acc@1: 87.5000 (82.9602)  Acc@5: 100.0000 (97.1310)  time: 0.3499  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1120/3750]  eta: 0:15:20  Lr: 0.001875  Loss: -1.1456  Acc@1: 81.2500 (82.9393)  Acc@5: 100.0000 (97.1008)  time: 0.3496  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [1130/3750]  eta: 0:15:17  Lr: 0.001875  Loss: -0.8592  Acc@1: 81.2500 (82.9686)  Acc@5: 93.7500 (97.1043)  time: 0.3505  data: 0.0013  max mem: 2500
Train: Epoch[5/5]  [1140/3750]  eta: 0:15:13  Lr: 0.001875  Loss: -1.0763  Acc@1: 81.2500 (82.9919)  Acc@5: 100.0000 (97.1133)  time: 0.3502  data: 0.0013  max mem: 2500
Train: Epoch[5/5]  [1150/3750]  eta: 0:15:10  Lr: 0.001875  Loss: -1.2924  Acc@1: 87.5000 (83.0148)  Acc@5: 100.0000 (97.1112)  time: 0.3485  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1160/3750]  eta: 0:15:06  Lr: 0.001875  Loss: -1.4122  Acc@1: 87.5000 (83.0534)  Acc@5: 100.0000 (97.1307)  time: 0.3482  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [1170/3750]  eta: 0:15:03  Lr: 0.001875  Loss: -0.9389  Acc@1: 87.5000 (83.0914)  Acc@5: 100.0000 (97.1339)  time: 0.3486  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [1180/3750]  eta: 0:14:59  Lr: 0.001875  Loss: -0.8431  Acc@1: 93.7500 (83.1340)  Acc@5: 100.0000 (97.1528)  time: 0.3485  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1190/3750]  eta: 0:14:56  Lr: 0.001875  Loss: -0.5846  Acc@1: 81.2500 (83.0972)  Acc@5: 100.0000 (97.1558)  time: 0.3483  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1200/3750]  eta: 0:14:52  Lr: 0.001875  Loss: -1.2563  Acc@1: 81.2500 (83.0974)  Acc@5: 100.0000 (97.1534)  time: 0.3486  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1210/3750]  eta: 0:14:49  Lr: 0.001875  Loss: -0.7590  Acc@1: 81.2500 (83.0976)  Acc@5: 100.0000 (97.1614)  time: 0.3486  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1220/3750]  eta: 0:14:45  Lr: 0.001875  Loss: -1.3402  Acc@1: 87.5000 (83.1388)  Acc@5: 100.0000 (97.1642)  time: 0.3489  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1230/3750]  eta: 0:14:42  Lr: 0.001875  Loss: -1.4497  Acc@1: 87.5000 (83.1844)  Acc@5: 100.0000 (97.1822)  time: 0.3488  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1240/3750]  eta: 0:14:38  Lr: 0.001875  Loss: -1.0224  Acc@1: 87.5000 (83.2242)  Acc@5: 100.0000 (97.1847)  time: 0.3483  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1250/3750]  eta: 0:14:34  Lr: 0.001875  Loss: -1.3521  Acc@1: 87.5000 (83.2284)  Acc@5: 100.0000 (97.1823)  time: 0.3488  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1260/3750]  eta: 0:14:31  Lr: 0.001875  Loss: -1.1645  Acc@1: 81.2500 (83.2127)  Acc@5: 100.0000 (97.1649)  time: 0.3498  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [1270/3750]  eta: 0:14:27  Lr: 0.001875  Loss: -0.7590  Acc@1: 81.2500 (83.2219)  Acc@5: 93.7500 (97.1676)  time: 0.3499  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [1280/3750]  eta: 0:14:24  Lr: 0.001875  Loss: -0.9572  Acc@1: 81.2500 (83.1918)  Acc@5: 100.0000 (97.1751)  time: 0.3497  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1290/3750]  eta: 0:14:20  Lr: 0.001875  Loss: -1.1338  Acc@1: 81.2500 (83.1865)  Acc@5: 100.0000 (97.1824)  time: 0.3491  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1300/3750]  eta: 0:14:17  Lr: 0.001875  Loss: -1.1834  Acc@1: 81.2500 (83.1860)  Acc@5: 100.0000 (97.1849)  time: 0.3495  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [1310/3750]  eta: 0:14:13  Lr: 0.001875  Loss: -0.8133  Acc@1: 87.5000 (83.1903)  Acc@5: 100.0000 (97.1873)  time: 0.3501  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [1320/3750]  eta: 0:14:10  Lr: 0.001875  Loss: -0.5895  Acc@1: 81.2500 (83.1614)  Acc@5: 100.0000 (97.2086)  time: 0.3498  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1330/3750]  eta: 0:14:06  Lr: 0.001875  Loss: -1.1621  Acc@1: 81.2500 (83.1518)  Acc@5: 100.0000 (97.2107)  time: 0.3497  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [1340/3750]  eta: 0:14:03  Lr: 0.001875  Loss: -1.1986  Acc@1: 81.2500 (83.1609)  Acc@5: 100.0000 (97.2036)  time: 0.3504  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1350/3750]  eta: 0:13:59  Lr: 0.001875  Loss: -1.1536  Acc@1: 87.5000 (83.1560)  Acc@5: 100.0000 (97.1919)  time: 0.3501  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [1360/3750]  eta: 0:13:56  Lr: 0.001875  Loss: -0.5914  Acc@1: 87.5000 (83.1604)  Acc@5: 100.0000 (97.2079)  time: 0.3496  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [1370/3750]  eta: 0:13:52  Lr: 0.001875  Loss: -1.1229  Acc@1: 87.5000 (83.1555)  Acc@5: 100.0000 (97.2009)  time: 0.3496  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1380/3750]  eta: 0:13:49  Lr: 0.001875  Loss: -0.6447  Acc@1: 81.2500 (83.1372)  Acc@5: 93.7500 (97.1986)  time: 0.3490  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [1390/3750]  eta: 0:13:45  Lr: 0.001875  Loss: -0.9078  Acc@1: 81.2500 (83.1416)  Acc@5: 100.0000 (97.2052)  time: 0.3489  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1400/3750]  eta: 0:13:42  Lr: 0.001875  Loss: -0.7720  Acc@1: 81.2500 (83.0969)  Acc@5: 100.0000 (97.2074)  time: 0.3491  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1410/3750]  eta: 0:13:38  Lr: 0.001875  Loss: -1.0805  Acc@1: 81.2500 (83.0927)  Acc@5: 100.0000 (97.2006)  time: 0.3491  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1420/3750]  eta: 0:13:35  Lr: 0.001875  Loss: -0.9958  Acc@1: 81.2500 (83.1105)  Acc@5: 100.0000 (97.2203)  time: 0.3494  data: 0.0010  max mem: 2500
Train: Epoch[5/5]  [1430/3750]  eta: 0:13:31  Lr: 0.001875  Loss: -1.2671  Acc@1: 81.2500 (83.1150)  Acc@5: 100.0000 (97.2222)  time: 0.3495  data: 0.0010  max mem: 2500
Train: Epoch[5/5]  [1440/3750]  eta: 0:13:28  Lr: 0.001875  Loss: -0.8338  Acc@1: 81.2500 (83.0673)  Acc@5: 100.0000 (97.2155)  time: 0.3488  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1450/3750]  eta: 0:13:24  Lr: 0.001875  Loss: -1.2156  Acc@1: 81.2500 (83.0634)  Acc@5: 100.0000 (97.2088)  time: 0.3494  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [1460/3750]  eta: 0:13:21  Lr: 0.001875  Loss: -1.1404  Acc@1: 81.2500 (83.0809)  Acc@5: 100.0000 (97.2065)  time: 0.3499  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [1470/3750]  eta: 0:13:17  Lr: 0.001875  Loss: -1.1171  Acc@1: 81.2500 (83.0812)  Acc@5: 100.0000 (97.2213)  time: 0.3499  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [1480/3750]  eta: 0:13:14  Lr: 0.001875  Loss: -0.7610  Acc@1: 81.2500 (83.0858)  Acc@5: 100.0000 (97.2232)  time: 0.3499  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1490/3750]  eta: 0:13:10  Lr: 0.001875  Loss: -1.0448  Acc@1: 81.2500 (83.0273)  Acc@5: 100.0000 (97.2166)  time: 0.3507  data: 0.0010  max mem: 2500
Train: Epoch[5/5]  [1500/3750]  eta: 0:13:07  Lr: 0.001875  Loss: -0.4921  Acc@1: 75.0000 (83.0238)  Acc@5: 100.0000 (97.2185)  time: 0.3507  data: 0.0010  max mem: 2500
Train: Epoch[5/5]  [1510/3750]  eta: 0:13:03  Lr: 0.001875  Loss: -1.4340  Acc@1: 81.2500 (83.0410)  Acc@5: 100.0000 (97.2245)  time: 0.3494  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1520/3750]  eta: 0:13:00  Lr: 0.001875  Loss: -0.8921  Acc@1: 81.2500 (83.0210)  Acc@5: 100.0000 (97.2304)  time: 0.3500  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [1530/3750]  eta: 0:12:56  Lr: 0.001875  Loss: -0.9439  Acc@1: 81.2500 (83.0217)  Acc@5: 100.0000 (97.2159)  time: 0.3498  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [1540/3750]  eta: 0:12:53  Lr: 0.001875  Loss: -0.7397  Acc@1: 81.2500 (82.9899)  Acc@5: 93.7500 (97.2096)  time: 0.3483  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1550/3750]  eta: 0:12:49  Lr: 0.001875  Loss: -0.2884  Acc@1: 81.2500 (82.9666)  Acc@5: 93.7500 (97.2034)  time: 0.3481  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1560/3750]  eta: 0:12:46  Lr: 0.001875  Loss: -1.0471  Acc@1: 87.5000 (82.9757)  Acc@5: 100.0000 (97.2133)  time: 0.3487  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [1570/3750]  eta: 0:12:42  Lr: 0.001875  Loss: -1.0240  Acc@1: 87.5000 (83.0005)  Acc@5: 100.0000 (97.2112)  time: 0.3489  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [1580/3750]  eta: 0:12:39  Lr: 0.001875  Loss: -0.9918  Acc@1: 87.5000 (82.9894)  Acc@5: 93.7500 (97.1932)  time: 0.3499  data: 0.0016  max mem: 2500
Train: Epoch[5/5]  [1590/3750]  eta: 0:12:35  Lr: 0.001875  Loss: -0.6850  Acc@1: 81.2500 (82.9745)  Acc@5: 93.7500 (97.1952)  time: 0.3512  data: 0.0016  max mem: 2500
Train: Epoch[5/5]  [1600/3750]  eta: 0:12:32  Lr: 0.001875  Loss: -0.6525  Acc@1: 81.2500 (82.9482)  Acc@5: 100.0000 (97.1893)  time: 0.3502  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [1610/3750]  eta: 0:12:28  Lr: 0.001875  Loss: -1.3434  Acc@1: 87.5000 (82.9842)  Acc@5: 100.0000 (97.1873)  time: 0.3493  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [1620/3750]  eta: 0:12:25  Lr: 0.001875  Loss: -0.9448  Acc@1: 87.5000 (82.9889)  Acc@5: 100.0000 (97.1815)  time: 0.3493  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [1630/3750]  eta: 0:12:21  Lr: 0.001875  Loss: -0.9735  Acc@1: 87.5000 (83.0012)  Acc@5: 100.0000 (97.1873)  time: 0.3506  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1640/3750]  eta: 0:12:18  Lr: 0.001875  Loss: -0.9546  Acc@1: 81.2500 (82.9906)  Acc@5: 100.0000 (97.1854)  time: 0.3510  data: 0.0011  max mem: 2500
Train: Epoch[5/5]  [1650/3750]  eta: 0:12:14  Lr: 0.001875  Loss: -0.4599  Acc@1: 81.2500 (82.9649)  Acc@5: 93.7500 (97.1760)  time: 0.3494  data: 0.0010  max mem: 2500
Train: Epoch[5/5]  [1660/3750]  eta: 0:12:11  Lr: 0.001875  Loss: -0.8845  Acc@1: 81.2500 (82.9545)  Acc@5: 93.7500 (97.1704)  time: 0.3488  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1670/3750]  eta: 0:12:07  Lr: 0.001875  Loss: -0.9805  Acc@1: 87.5000 (82.9743)  Acc@5: 100.0000 (97.1724)  time: 0.3486  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1680/3750]  eta: 0:12:04  Lr: 0.001875  Loss: -1.1226  Acc@1: 87.5000 (82.9863)  Acc@5: 100.0000 (97.1780)  time: 0.3492  data: 0.0012  max mem: 2500
Train: Epoch[5/5]  [1690/3750]  eta: 0:12:00  Lr: 0.001875  Loss: -0.8461  Acc@1: 81.2500 (82.9687)  Acc@5: 100.0000 (97.1762)  time: 0.3511  data: 0.0011  max mem: 2500
Train: Epoch[5/5]  [1700/3750]  eta: 0:11:57  Lr: 0.001875  Loss: -0.9400  Acc@1: 81.2500 (82.9916)  Acc@5: 100.0000 (97.1818)  time: 0.3508  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1710/3750]  eta: 0:11:53  Lr: 0.001875  Loss: -1.1150  Acc@1: 87.5000 (82.9851)  Acc@5: 100.0000 (97.1764)  time: 0.3486  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1720/3750]  eta: 0:11:50  Lr: 0.001875  Loss: -0.7907  Acc@1: 81.2500 (82.9605)  Acc@5: 100.0000 (97.1710)  time: 0.3477  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [1730/3750]  eta: 0:11:46  Lr: 0.001875  Loss: -0.8881  Acc@1: 81.2500 (82.9542)  Acc@5: 93.7500 (97.1657)  time: 0.3488  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [1740/3750]  eta: 0:11:43  Lr: 0.001875  Loss: -1.1945  Acc@1: 87.5000 (82.9767)  Acc@5: 100.0000 (97.1712)  time: 0.3502  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [1750/3750]  eta: 0:11:39  Lr: 0.001875  Loss: -0.9855  Acc@1: 87.5000 (82.9455)  Acc@5: 100.0000 (97.1516)  time: 0.3492  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [1760/3750]  eta: 0:11:36  Lr: 0.001875  Loss: -0.8867  Acc@1: 81.2500 (82.9536)  Acc@5: 100.0000 (97.1572)  time: 0.3479  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1770/3750]  eta: 0:11:32  Lr: 0.001875  Loss: -1.0955  Acc@1: 81.2500 (82.9440)  Acc@5: 93.7500 (97.1450)  time: 0.3480  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1780/3750]  eta: 0:11:29  Lr: 0.001875  Loss: -0.6623  Acc@1: 81.2500 (82.9380)  Acc@5: 93.7500 (97.1329)  time: 0.3481  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1790/3750]  eta: 0:11:25  Lr: 0.001875  Loss: -1.2941  Acc@1: 81.2500 (82.9495)  Acc@5: 93.7500 (97.1350)  time: 0.3481  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1800/3750]  eta: 0:11:22  Lr: 0.001875  Loss: -1.0250  Acc@1: 81.2500 (82.9678)  Acc@5: 100.0000 (97.1405)  time: 0.3489  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [1810/3750]  eta: 0:11:18  Lr: 0.001875  Loss: -1.0492  Acc@1: 81.2500 (82.9721)  Acc@5: 100.0000 (97.1287)  time: 0.3500  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [1820/3750]  eta: 0:11:15  Lr: 0.001875  Loss: -0.8597  Acc@1: 81.2500 (82.9283)  Acc@5: 93.7500 (97.1135)  time: 0.3503  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [1830/3750]  eta: 0:11:11  Lr: 0.001875  Loss: -1.1127  Acc@1: 81.2500 (82.9362)  Acc@5: 93.7500 (97.1020)  time: 0.3499  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1840/3750]  eta: 0:11:08  Lr: 0.001875  Loss: -0.8789  Acc@1: 87.5000 (82.9610)  Acc@5: 100.0000 (97.0974)  time: 0.3491  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1850/3750]  eta: 0:11:04  Lr: 0.001875  Loss: -0.9611  Acc@1: 87.5000 (82.9552)  Acc@5: 100.0000 (97.0995)  time: 0.3497  data: 0.0013  max mem: 2500
Train: Epoch[5/5]  [1860/3750]  eta: 0:11:01  Lr: 0.001875  Loss: -1.0369  Acc@1: 81.2500 (82.9695)  Acc@5: 100.0000 (97.1017)  time: 0.3501  data: 0.0013  max mem: 2500
Train: Epoch[5/5]  [1870/3750]  eta: 0:10:57  Lr: 0.001875  Loss: -1.3222  Acc@1: 87.5000 (82.9870)  Acc@5: 100.0000 (97.1005)  time: 0.3497  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1880/3750]  eta: 0:10:54  Lr: 0.001875  Loss: -0.8139  Acc@1: 81.2500 (82.9778)  Acc@5: 100.0000 (97.1059)  time: 0.3509  data: 0.0018  max mem: 2500
Train: Epoch[5/5]  [1890/3750]  eta: 0:10:50  Lr: 0.001875  Loss: -0.7448  Acc@1: 81.2500 (82.9951)  Acc@5: 100.0000 (97.1113)  time: 0.3505  data: 0.0017  max mem: 2500
Train: Epoch[5/5]  [1900/3750]  eta: 0:10:47  Lr: 0.001875  Loss: -0.6451  Acc@1: 81.2500 (82.9761)  Acc@5: 100.0000 (97.1101)  time: 0.3492  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1910/3750]  eta: 0:10:43  Lr: 0.001875  Loss: -1.0741  Acc@1: 81.2500 (82.9834)  Acc@5: 100.0000 (97.1219)  time: 0.3494  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1920/3750]  eta: 0:10:40  Lr: 0.001875  Loss: -1.0148  Acc@1: 81.2500 (82.9776)  Acc@5: 100.0000 (97.1239)  time: 0.3505  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [1930/3750]  eta: 0:10:36  Lr: 0.001875  Loss: -1.0557  Acc@1: 81.2500 (82.9784)  Acc@5: 100.0000 (97.1291)  time: 0.3507  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [1940/3750]  eta: 0:10:33  Lr: 0.001875  Loss: -0.7756  Acc@1: 81.2500 (82.9759)  Acc@5: 100.0000 (97.1310)  time: 0.3494  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1950/3750]  eta: 0:10:29  Lr: 0.001875  Loss: -0.8694  Acc@1: 81.2500 (82.9639)  Acc@5: 100.0000 (97.1393)  time: 0.3488  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1960/3750]  eta: 0:10:26  Lr: 0.001875  Loss: -0.9052  Acc@1: 81.2500 (82.9424)  Acc@5: 100.0000 (97.1284)  time: 0.3490  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1970/3750]  eta: 0:10:22  Lr: 0.001875  Loss: -1.0942  Acc@1: 81.2500 (82.9718)  Acc@5: 93.7500 (97.1271)  time: 0.3488  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1980/3750]  eta: 0:10:19  Lr: 0.001875  Loss: -1.1446  Acc@1: 87.5000 (82.9695)  Acc@5: 100.0000 (97.1384)  time: 0.3487  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [1990/3750]  eta: 0:10:15  Lr: 0.001875  Loss: -1.1532  Acc@1: 81.2500 (82.9608)  Acc@5: 100.0000 (97.1308)  time: 0.3492  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2000/3750]  eta: 0:10:12  Lr: 0.001875  Loss: -1.2118  Acc@1: 87.5000 (82.9741)  Acc@5: 100.0000 (97.1389)  time: 0.3491  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [2010/3750]  eta: 0:10:08  Lr: 0.001875  Loss: -1.2940  Acc@1: 87.5000 (82.9811)  Acc@5: 100.0000 (97.1438)  time: 0.3490  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [2020/3750]  eta: 0:10:05  Lr: 0.001875  Loss: -1.1058  Acc@1: 81.2500 (82.9725)  Acc@5: 100.0000 (97.1394)  time: 0.3488  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [2030/3750]  eta: 0:10:01  Lr: 0.001875  Loss: -1.0778  Acc@1: 75.0000 (82.9579)  Acc@5: 100.0000 (97.1412)  time: 0.3481  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [2040/3750]  eta: 0:09:58  Lr: 0.001875  Loss: -1.0921  Acc@1: 75.0000 (82.9373)  Acc@5: 93.7500 (97.1276)  time: 0.3479  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [2050/3750]  eta: 0:09:54  Lr: 0.001875  Loss: -0.5509  Acc@1: 75.0000 (82.9230)  Acc@5: 93.7500 (97.1234)  time: 0.3483  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [2060/3750]  eta: 0:09:51  Lr: 0.001875  Loss: -1.2736  Acc@1: 81.2500 (82.9057)  Acc@5: 100.0000 (97.1312)  time: 0.3482  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2070/3750]  eta: 0:09:47  Lr: 0.001875  Loss: -1.3951  Acc@1: 81.2500 (82.9128)  Acc@5: 100.0000 (97.1270)  time: 0.3476  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [2080/3750]  eta: 0:09:44  Lr: 0.001875  Loss: -1.2306  Acc@1: 81.2500 (82.9199)  Acc@5: 100.0000 (97.1348)  time: 0.3483  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [2090/3750]  eta: 0:09:40  Lr: 0.001875  Loss: -1.0323  Acc@1: 87.5000 (82.9209)  Acc@5: 100.0000 (97.1365)  time: 0.3485  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [2100/3750]  eta: 0:09:37  Lr: 0.001875  Loss: -1.3728  Acc@1: 87.5000 (82.9397)  Acc@5: 100.0000 (97.1472)  time: 0.3486  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2110/3750]  eta: 0:09:33  Lr: 0.001875  Loss: -0.8736  Acc@1: 87.5000 (82.9376)  Acc@5: 100.0000 (97.1518)  time: 0.3488  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2120/3750]  eta: 0:09:30  Lr: 0.001875  Loss: -0.3369  Acc@1: 81.2500 (82.9267)  Acc@5: 100.0000 (97.1446)  time: 0.3483  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2130/3750]  eta: 0:09:26  Lr: 0.001875  Loss: -1.0495  Acc@1: 81.2500 (82.9159)  Acc@5: 100.0000 (97.1492)  time: 0.3486  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2140/3750]  eta: 0:09:23  Lr: 0.001875  Loss: -1.2834  Acc@1: 81.2500 (82.9285)  Acc@5: 100.0000 (97.1625)  time: 0.3496  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2150/3750]  eta: 0:09:19  Lr: 0.001875  Loss: -0.8654  Acc@1: 81.2500 (82.9207)  Acc@5: 100.0000 (97.1699)  time: 0.3503  data: 0.0011  max mem: 2500
Train: Epoch[5/5]  [2160/3750]  eta: 0:09:16  Lr: 0.001875  Loss: -1.1733  Acc@1: 81.2500 (82.9275)  Acc@5: 100.0000 (97.1714)  time: 0.3499  data: 0.0013  max mem: 2500
Train: Epoch[5/5]  [2170/3750]  eta: 0:09:12  Lr: 0.001875  Loss: -1.4427  Acc@1: 81.2500 (82.9255)  Acc@5: 100.0000 (97.1787)  time: 0.3494  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [2180/3750]  eta: 0:09:09  Lr: 0.001875  Loss: -1.1988  Acc@1: 81.2500 (82.9264)  Acc@5: 100.0000 (97.1716)  time: 0.3500  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2190/3750]  eta: 0:09:05  Lr: 0.001875  Loss: -1.2027  Acc@1: 81.2500 (82.9444)  Acc@5: 100.0000 (97.1702)  time: 0.3502  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [2200/3750]  eta: 0:09:02  Lr: 0.001875  Loss: -0.6579  Acc@1: 81.2500 (82.9311)  Acc@5: 100.0000 (97.1689)  time: 0.3494  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [2210/3750]  eta: 0:08:58  Lr: 0.001875  Loss: -0.9210  Acc@1: 81.2500 (82.9235)  Acc@5: 93.7500 (97.1647)  time: 0.3500  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2220/3750]  eta: 0:08:55  Lr: 0.001875  Loss: -0.6425  Acc@1: 81.2500 (82.9215)  Acc@5: 100.0000 (97.1663)  time: 0.3507  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2230/3750]  eta: 0:08:51  Lr: 0.001875  Loss: -0.9775  Acc@1: 81.2500 (82.8944)  Acc@5: 100.0000 (97.1565)  time: 0.3500  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2240/3750]  eta: 0:08:48  Lr: 0.001875  Loss: -0.7093  Acc@1: 81.2500 (82.8899)  Acc@5: 93.7500 (97.1581)  time: 0.3495  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2250/3750]  eta: 0:08:44  Lr: 0.001875  Loss: -1.3222  Acc@1: 81.2500 (82.8993)  Acc@5: 100.0000 (97.1679)  time: 0.3495  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2260/3750]  eta: 0:08:41  Lr: 0.001875  Loss: -1.3274  Acc@1: 87.5000 (82.9003)  Acc@5: 100.0000 (97.1777)  time: 0.3500  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2270/3750]  eta: 0:08:37  Lr: 0.001875  Loss: -0.8681  Acc@1: 81.2500 (82.8765)  Acc@5: 100.0000 (97.1681)  time: 0.3496  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2280/3750]  eta: 0:08:34  Lr: 0.001875  Loss: -1.3844  Acc@1: 81.2500 (82.8968)  Acc@5: 100.0000 (97.1723)  time: 0.3491  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2290/3750]  eta: 0:08:30  Lr: 0.001875  Loss: -0.8421  Acc@1: 81.2500 (82.8841)  Acc@5: 100.0000 (97.1710)  time: 0.3494  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2300/3750]  eta: 0:08:27  Lr: 0.001875  Loss: -1.0979  Acc@1: 81.2500 (82.8689)  Acc@5: 100.0000 (97.1806)  time: 0.3488  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2310/3750]  eta: 0:08:23  Lr: 0.001875  Loss: -1.3686  Acc@1: 81.2500 (82.8808)  Acc@5: 100.0000 (97.1738)  time: 0.3479  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2320/3750]  eta: 0:08:20  Lr: 0.001875  Loss: -1.2079  Acc@1: 87.5000 (82.8899)  Acc@5: 100.0000 (97.1699)  time: 0.3481  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2330/3750]  eta: 0:08:16  Lr: 0.001875  Loss: -0.7189  Acc@1: 81.2500 (82.8990)  Acc@5: 100.0000 (97.1686)  time: 0.3488  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2340/3750]  eta: 0:08:13  Lr: 0.001875  Loss: -1.4639  Acc@1: 81.2500 (82.8839)  Acc@5: 93.7500 (97.1673)  time: 0.3493  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2350/3750]  eta: 0:08:09  Lr: 0.001875  Loss: -0.3712  Acc@1: 81.2500 (82.8903)  Acc@5: 100.0000 (97.1714)  time: 0.3488  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2360/3750]  eta: 0:08:06  Lr: 0.001875  Loss: -0.8901  Acc@1: 81.2500 (82.8754)  Acc@5: 100.0000 (97.1781)  time: 0.3480  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2370/3750]  eta: 0:08:02  Lr: 0.001875  Loss: -1.0178  Acc@1: 75.0000 (82.8527)  Acc@5: 100.0000 (97.1768)  time: 0.3484  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2380/3750]  eta: 0:07:59  Lr: 0.001875  Loss: -0.9535  Acc@1: 81.2500 (82.8643)  Acc@5: 100.0000 (97.1782)  time: 0.3490  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [2390/3750]  eta: 0:07:55  Lr: 0.001875  Loss: -1.0832  Acc@1: 81.2500 (82.8654)  Acc@5: 100.0000 (97.1743)  time: 0.3491  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [2400/3750]  eta: 0:07:52  Lr: 0.001875  Loss: -1.1423  Acc@1: 87.5000 (82.8665)  Acc@5: 100.0000 (97.1704)  time: 0.3490  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2410/3750]  eta: 0:07:48  Lr: 0.001875  Loss: -0.8757  Acc@1: 81.2500 (82.8754)  Acc@5: 100.0000 (97.1770)  time: 0.3486  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2420/3750]  eta: 0:07:45  Lr: 0.001875  Loss: -1.0467  Acc@1: 81.2500 (82.8661)  Acc@5: 100.0000 (97.1809)  time: 0.3492  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [2430/3750]  eta: 0:07:41  Lr: 0.001875  Loss: -0.5597  Acc@1: 81.2500 (82.8723)  Acc@5: 100.0000 (97.1745)  time: 0.3492  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2440/3750]  eta: 0:07:38  Lr: 0.001875  Loss: -0.9914  Acc@1: 81.2500 (82.8682)  Acc@5: 93.7500 (97.1605)  time: 0.3490  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2450/3750]  eta: 0:07:34  Lr: 0.001875  Loss: -1.2317  Acc@1: 81.2500 (82.8871)  Acc@5: 93.7500 (97.1593)  time: 0.3500  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2460/3750]  eta: 0:07:31  Lr: 0.001875  Loss: -0.9056  Acc@1: 87.5000 (82.8906)  Acc@5: 100.0000 (97.1582)  time: 0.3506  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2470/3750]  eta: 0:07:27  Lr: 0.001875  Loss: -1.4195  Acc@1: 87.5000 (82.9042)  Acc@5: 100.0000 (97.1621)  time: 0.3513  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2480/3750]  eta: 0:07:24  Lr: 0.001875  Loss: -1.2704  Acc@1: 87.5000 (82.8975)  Acc@5: 100.0000 (97.1660)  time: 0.3504  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2490/3750]  eta: 0:07:20  Lr: 0.001875  Loss: -1.4525  Acc@1: 81.2500 (82.9009)  Acc@5: 100.0000 (97.1673)  time: 0.3494  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2500/3750]  eta: 0:07:17  Lr: 0.001875  Loss: -1.2248  Acc@1: 81.2500 (82.8993)  Acc@5: 100.0000 (97.1611)  time: 0.3495  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2510/3750]  eta: 0:07:13  Lr: 0.001875  Loss: -1.2699  Acc@1: 87.5000 (82.9202)  Acc@5: 100.0000 (97.1625)  time: 0.3494  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2520/3750]  eta: 0:07:10  Lr: 0.001875  Loss: -0.9367  Acc@1: 87.5000 (82.9210)  Acc@5: 100.0000 (97.1688)  time: 0.3496  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [2530/3750]  eta: 0:07:06  Lr: 0.001875  Loss: -1.4940  Acc@1: 81.2500 (82.9242)  Acc@5: 100.0000 (97.1701)  time: 0.3497  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [2540/3750]  eta: 0:07:03  Lr: 0.001875  Loss: -1.3369  Acc@1: 81.2500 (82.9299)  Acc@5: 100.0000 (97.1763)  time: 0.3501  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2550/3750]  eta: 0:06:59  Lr: 0.001875  Loss: -1.0299  Acc@1: 81.2500 (82.9356)  Acc@5: 100.0000 (97.1849)  time: 0.3503  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2560/3750]  eta: 0:06:56  Lr: 0.001875  Loss: -0.8977  Acc@1: 81.2500 (82.9364)  Acc@5: 100.0000 (97.1837)  time: 0.3498  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2570/3750]  eta: 0:06:52  Lr: 0.001875  Loss: -0.8667  Acc@1: 81.2500 (82.9371)  Acc@5: 100.0000 (97.1825)  time: 0.3507  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [2580/3750]  eta: 0:06:49  Lr: 0.001875  Loss: -1.0935  Acc@1: 75.0000 (82.8991)  Acc@5: 100.0000 (97.1886)  time: 0.3523  data: 0.0011  max mem: 2500
Train: Epoch[5/5]  [2590/3750]  eta: 0:06:45  Lr: 0.001875  Loss: -1.0298  Acc@1: 81.2500 (82.9072)  Acc@5: 100.0000 (97.1898)  time: 0.3514  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [2600/3750]  eta: 0:06:42  Lr: 0.001875  Loss: -1.3794  Acc@1: 87.5000 (82.9224)  Acc@5: 100.0000 (97.1982)  time: 0.3500  data: 0.0003  max mem: 2500
Train: Epoch[5/5]  [2610/3750]  eta: 0:06:38  Lr: 0.001875  Loss: -1.0875  Acc@1: 87.5000 (82.9232)  Acc@5: 100.0000 (97.1970)  time: 0.3501  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2620/3750]  eta: 0:06:35  Lr: 0.001875  Loss: -1.2210  Acc@1: 81.2500 (82.9025)  Acc@5: 93.7500 (97.1862)  time: 0.3502  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2630/3750]  eta: 0:06:31  Lr: 0.001875  Loss: -0.9596  Acc@1: 75.0000 (82.8867)  Acc@5: 93.7500 (97.1874)  time: 0.3506  data: 0.0011  max mem: 2500
Train: Epoch[5/5]  [2640/3750]  eta: 0:06:28  Lr: 0.001875  Loss: -1.2733  Acc@1: 81.2500 (82.9018)  Acc@5: 100.0000 (97.1909)  time: 0.3511  data: 0.0011  max mem: 2500
Train: Epoch[5/5]  [2650/3750]  eta: 0:06:24  Lr: 0.001875  Loss: -1.0505  Acc@1: 87.5000 (82.9239)  Acc@5: 100.0000 (97.1921)  time: 0.3505  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2660/3750]  eta: 0:06:21  Lr: 0.001875  Loss: -0.7757  Acc@1: 87.5000 (82.9153)  Acc@5: 100.0000 (97.1933)  time: 0.3511  data: 0.0014  max mem: 2500
Train: Epoch[5/5]  [2670/3750]  eta: 0:06:17  Lr: 0.001875  Loss: -1.2152  Acc@1: 81.2500 (82.9207)  Acc@5: 100.0000 (97.1921)  time: 0.3509  data: 0.0014  max mem: 2500
Train: Epoch[5/5]  [2680/3750]  eta: 0:06:14  Lr: 0.001875  Loss: -1.3924  Acc@1: 81.2500 (82.9215)  Acc@5: 100.0000 (97.1909)  time: 0.3500  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [2690/3750]  eta: 0:06:10  Lr: 0.001875  Loss: -1.1342  Acc@1: 87.5000 (82.9431)  Acc@5: 100.0000 (97.1897)  time: 0.3498  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [2700/3750]  eta: 0:06:07  Lr: 0.001875  Loss: -0.8473  Acc@1: 81.2500 (82.9230)  Acc@5: 100.0000 (97.1932)  time: 0.3488  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2710/3750]  eta: 0:06:03  Lr: 0.001875  Loss: -1.2394  Acc@1: 81.2500 (82.9330)  Acc@5: 100.0000 (97.1897)  time: 0.3487  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2720/3750]  eta: 0:06:00  Lr: 0.001875  Loss: -1.0404  Acc@1: 87.5000 (82.9383)  Acc@5: 100.0000 (97.1885)  time: 0.3486  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2730/3750]  eta: 0:05:56  Lr: 0.001875  Loss: -1.2206  Acc@1: 87.5000 (82.9504)  Acc@5: 100.0000 (97.1897)  time: 0.3483  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2740/3750]  eta: 0:05:53  Lr: 0.001875  Loss: -0.4498  Acc@1: 87.5000 (82.9351)  Acc@5: 100.0000 (97.1908)  time: 0.3490  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2750/3750]  eta: 0:05:49  Lr: 0.001875  Loss: -1.1412  Acc@1: 81.2500 (82.9471)  Acc@5: 100.0000 (97.1897)  time: 0.3487  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2760/3750]  eta: 0:05:46  Lr: 0.001875  Loss: -0.9000  Acc@1: 87.5000 (82.9455)  Acc@5: 100.0000 (97.1953)  time: 0.3479  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2770/3750]  eta: 0:05:42  Lr: 0.001875  Loss: -0.9409  Acc@1: 81.2500 (82.9304)  Acc@5: 100.0000 (97.1942)  time: 0.3484  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2780/3750]  eta: 0:05:39  Lr: 0.001875  Loss: -1.0455  Acc@1: 75.0000 (82.9310)  Acc@5: 100.0000 (97.1975)  time: 0.3489  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2790/3750]  eta: 0:05:35  Lr: 0.001875  Loss: -0.6675  Acc@1: 81.2500 (82.9273)  Acc@5: 100.0000 (97.1963)  time: 0.3498  data: 0.0011  max mem: 2500
Train: Epoch[5/5]  [2800/3750]  eta: 0:05:32  Lr: 0.001875  Loss: -1.4871  Acc@1: 81.2500 (82.9213)  Acc@5: 100.0000 (97.1974)  time: 0.3499  data: 0.0011  max mem: 2500
Train: Epoch[5/5]  [2810/3750]  eta: 0:05:28  Lr: 0.001875  Loss: -0.9991  Acc@1: 81.2500 (82.9331)  Acc@5: 100.0000 (97.1963)  time: 0.3486  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2820/3750]  eta: 0:05:25  Lr: 0.001875  Loss: -1.2954  Acc@1: 87.5000 (82.9360)  Acc@5: 100.0000 (97.1974)  time: 0.3491  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [2830/3750]  eta: 0:05:21  Lr: 0.001875  Loss: -1.2130  Acc@1: 87.5000 (82.9433)  Acc@5: 100.0000 (97.1984)  time: 0.3495  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [2840/3750]  eta: 0:05:18  Lr: 0.001875  Loss: -1.4033  Acc@1: 87.5000 (82.9461)  Acc@5: 100.0000 (97.1973)  time: 0.3486  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [2850/3750]  eta: 0:05:14  Lr: 0.001875  Loss: -0.0707  Acc@1: 81.2500 (82.9380)  Acc@5: 93.7500 (97.1962)  time: 0.3483  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [2860/3750]  eta: 0:05:11  Lr: 0.001875  Loss: -1.4238  Acc@1: 81.2500 (82.9321)  Acc@5: 93.7500 (97.1907)  time: 0.3489  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2870/3750]  eta: 0:05:07  Lr: 0.001875  Loss: -0.9491  Acc@1: 87.5000 (82.9262)  Acc@5: 100.0000 (97.1961)  time: 0.3496  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2880/3750]  eta: 0:05:04  Lr: 0.001875  Loss: -0.7836  Acc@1: 81.2500 (82.9226)  Acc@5: 100.0000 (97.1950)  time: 0.3490  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2890/3750]  eta: 0:05:00  Lr: 0.001875  Loss: -0.8825  Acc@1: 81.2500 (82.9276)  Acc@5: 93.7500 (97.1874)  time: 0.3493  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [2900/3750]  eta: 0:04:57  Lr: 0.001875  Loss: -0.6950  Acc@1: 87.5000 (82.9240)  Acc@5: 100.0000 (97.1928)  time: 0.3500  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [2910/3750]  eta: 0:04:53  Lr: 0.001875  Loss: -1.2941  Acc@1: 87.5000 (82.9268)  Acc@5: 100.0000 (97.1960)  time: 0.3501  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2920/3750]  eta: 0:04:50  Lr: 0.001875  Loss: -1.2289  Acc@1: 87.5000 (82.9339)  Acc@5: 100.0000 (97.2013)  time: 0.3505  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2930/3750]  eta: 0:04:46  Lr: 0.001875  Loss: -1.2088  Acc@1: 87.5000 (82.9282)  Acc@5: 100.0000 (97.2066)  time: 0.3506  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [2940/3750]  eta: 0:04:43  Lr: 0.001875  Loss: -0.5540  Acc@1: 75.0000 (82.9118)  Acc@5: 100.0000 (97.1991)  time: 0.3503  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [2950/3750]  eta: 0:04:39  Lr: 0.001875  Loss: -0.4788  Acc@1: 81.2500 (82.9105)  Acc@5: 93.7500 (97.1937)  time: 0.3496  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2960/3750]  eta: 0:04:36  Lr: 0.001875  Loss: -1.1382  Acc@1: 87.5000 (82.9260)  Acc@5: 100.0000 (97.1969)  time: 0.3494  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2970/3750]  eta: 0:04:32  Lr: 0.001875  Loss: -1.0861  Acc@1: 87.5000 (82.9287)  Acc@5: 100.0000 (97.2021)  time: 0.3499  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [2980/3750]  eta: 0:04:29  Lr: 0.001875  Loss: -1.2246  Acc@1: 87.5000 (82.9357)  Acc@5: 100.0000 (97.2073)  time: 0.3508  data: 0.0009  max mem: 2500
Train: Epoch[5/5]  [2990/3750]  eta: 0:04:25  Lr: 0.001875  Loss: -0.6038  Acc@1: 87.5000 (82.9280)  Acc@5: 100.0000 (97.2083)  time: 0.3507  data: 0.0012  max mem: 2500
Train: Epoch[5/5]  [3000/3750]  eta: 0:04:22  Lr: 0.001875  Loss: -1.2810  Acc@1: 81.2500 (82.9390)  Acc@5: 100.0000 (97.2155)  time: 0.3500  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [3010/3750]  eta: 0:04:18  Lr: 0.001875  Loss: -1.0739  Acc@1: 81.2500 (82.9396)  Acc@5: 100.0000 (97.2144)  time: 0.3495  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [3020/3750]  eta: 0:04:15  Lr: 0.001875  Loss: -1.0510  Acc@1: 87.5000 (82.9527)  Acc@5: 100.0000 (97.2153)  time: 0.3490  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3030/3750]  eta: 0:04:11  Lr: 0.001875  Loss: -1.1462  Acc@1: 87.5000 (82.9512)  Acc@5: 100.0000 (97.2121)  time: 0.3494  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3040/3750]  eta: 0:04:08  Lr: 0.001875  Loss: -1.3217  Acc@1: 81.2500 (82.9517)  Acc@5: 100.0000 (97.2151)  time: 0.3495  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3050/3750]  eta: 0:04:04  Lr: 0.001875  Loss: -1.3740  Acc@1: 87.5000 (82.9605)  Acc@5: 100.0000 (97.2202)  time: 0.3488  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3060/3750]  eta: 0:04:01  Lr: 0.001875  Loss: -1.2770  Acc@1: 87.5000 (82.9631)  Acc@5: 100.0000 (97.2211)  time: 0.3489  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3070/3750]  eta: 0:03:57  Lr: 0.001875  Loss: -1.2335  Acc@1: 81.2500 (82.9494)  Acc@5: 100.0000 (97.2240)  time: 0.3492  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [3080/3750]  eta: 0:03:54  Lr: 0.001875  Loss: -0.9016  Acc@1: 81.2500 (82.9560)  Acc@5: 100.0000 (97.2270)  time: 0.3485  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [3090/3750]  eta: 0:03:50  Lr: 0.001875  Loss: -0.6854  Acc@1: 81.2500 (82.9566)  Acc@5: 100.0000 (97.2238)  time: 0.3485  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3100/3750]  eta: 0:03:47  Lr: 0.001875  Loss: -0.9037  Acc@1: 87.5000 (82.9712)  Acc@5: 93.7500 (97.2186)  time: 0.3496  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [3110/3750]  eta: 0:03:43  Lr: 0.001875  Loss: -1.1680  Acc@1: 81.2500 (82.9617)  Acc@5: 100.0000 (97.2195)  time: 0.3500  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [3120/3750]  eta: 0:03:40  Lr: 0.001875  Loss: -1.1829  Acc@1: 81.2500 (82.9682)  Acc@5: 100.0000 (97.2204)  time: 0.3492  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3130/3750]  eta: 0:03:36  Lr: 0.001875  Loss: -0.8722  Acc@1: 87.5000 (82.9687)  Acc@5: 100.0000 (97.2193)  time: 0.3484  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3140/3750]  eta: 0:03:33  Lr: 0.001875  Loss: -1.0341  Acc@1: 87.5000 (82.9772)  Acc@5: 100.0000 (97.2182)  time: 0.3484  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3150/3750]  eta: 0:03:29  Lr: 0.001875  Loss: -0.9472  Acc@1: 81.2500 (82.9737)  Acc@5: 100.0000 (97.2172)  time: 0.3483  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3160/3750]  eta: 0:03:26  Lr: 0.001875  Loss: -0.5665  Acc@1: 81.2500 (82.9820)  Acc@5: 93.7500 (97.2022)  time: 0.3487  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3170/3750]  eta: 0:03:22  Lr: 0.001875  Loss: -0.8913  Acc@1: 81.2500 (82.9766)  Acc@5: 93.7500 (97.2012)  time: 0.3489  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3180/3750]  eta: 0:03:19  Lr: 0.001875  Loss: -0.8807  Acc@1: 81.2500 (82.9810)  Acc@5: 100.0000 (97.2021)  time: 0.3487  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3190/3750]  eta: 0:03:15  Lr: 0.001875  Loss: -1.0806  Acc@1: 81.2500 (82.9834)  Acc@5: 100.0000 (97.1992)  time: 0.3489  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3200/3750]  eta: 0:03:12  Lr: 0.001875  Loss: -1.2355  Acc@1: 87.5000 (82.9877)  Acc@5: 100.0000 (97.2001)  time: 0.3490  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [3210/3750]  eta: 0:03:08  Lr: 0.001875  Loss: -0.8082  Acc@1: 87.5000 (82.9960)  Acc@5: 100.0000 (97.2030)  time: 0.3495  data: 0.0016  max mem: 2500
Train: Epoch[5/5]  [3220/3750]  eta: 0:03:05  Lr: 0.001875  Loss: -0.9284  Acc@1: 81.2500 (83.0002)  Acc@5: 100.0000 (97.2020)  time: 0.3489  data: 0.0016  max mem: 2500
Train: Epoch[5/5]  [3230/3750]  eta: 0:03:01  Lr: 0.001875  Loss: -0.9551  Acc@1: 81.2500 (82.9929)  Acc@5: 93.7500 (97.1990)  time: 0.3488  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3240/3750]  eta: 0:02:58  Lr: 0.001875  Loss: -0.6645  Acc@1: 81.2500 (82.9914)  Acc@5: 93.7500 (97.1942)  time: 0.3498  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [3250/3750]  eta: 0:02:54  Lr: 0.001875  Loss: -1.4507  Acc@1: 81.2500 (82.9937)  Acc@5: 93.7500 (97.1932)  time: 0.3494  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [3260/3750]  eta: 0:02:51  Lr: 0.001875  Loss: -1.0655  Acc@1: 87.5000 (82.9998)  Acc@5: 93.7500 (97.1903)  time: 0.3489  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3270/3750]  eta: 0:02:47  Lr: 0.001875  Loss: -0.9601  Acc@1: 87.5000 (82.9945)  Acc@5: 93.7500 (97.1836)  time: 0.3485  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3280/3750]  eta: 0:02:44  Lr: 0.001875  Loss: -0.8664  Acc@1: 81.2500 (82.9892)  Acc@5: 93.7500 (97.1807)  time: 0.3495  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3290/3750]  eta: 0:02:40  Lr: 0.001875  Loss: -1.2665  Acc@1: 81.2500 (83.0029)  Acc@5: 100.0000 (97.1760)  time: 0.3504  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3300/3750]  eta: 0:02:37  Lr: 0.001875  Loss: -0.9995  Acc@1: 87.5000 (82.9900)  Acc@5: 93.7500 (97.1694)  time: 0.3505  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3310/3750]  eta: 0:02:33  Lr: 0.001875  Loss: -0.8100  Acc@1: 81.2500 (82.9942)  Acc@5: 100.0000 (97.1685)  time: 0.3503  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3320/3750]  eta: 0:02:30  Lr: 0.001875  Loss: -0.5045  Acc@1: 81.2500 (82.9927)  Acc@5: 100.0000 (97.1676)  time: 0.3497  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3330/3750]  eta: 0:02:26  Lr: 0.001875  Loss: -0.6246  Acc@1: 87.5000 (82.9968)  Acc@5: 100.0000 (97.1668)  time: 0.3499  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3340/3750]  eta: 0:02:23  Lr: 0.001875  Loss: -0.9162  Acc@1: 87.5000 (82.9991)  Acc@5: 100.0000 (97.1659)  time: 0.3498  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3350/3750]  eta: 0:02:19  Lr: 0.001875  Loss: -0.7802  Acc@1: 81.2500 (83.0032)  Acc@5: 93.7500 (97.1632)  time: 0.3502  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3360/3750]  eta: 0:02:16  Lr: 0.001875  Loss: -1.2076  Acc@1: 87.5000 (83.0147)  Acc@5: 100.0000 (97.1660)  time: 0.3497  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3370/3750]  eta: 0:02:12  Lr: 0.001875  Loss: -0.9671  Acc@1: 87.5000 (83.0002)  Acc@5: 100.0000 (97.1633)  time: 0.3505  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3380/3750]  eta: 0:02:09  Lr: 0.001875  Loss: -1.2720  Acc@1: 81.2500 (83.0061)  Acc@5: 100.0000 (97.1643)  time: 0.3512  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3390/3750]  eta: 0:02:05  Lr: 0.001875  Loss: -0.9395  Acc@1: 81.2500 (83.0010)  Acc@5: 93.7500 (97.1524)  time: 0.3507  data: 0.0014  max mem: 2500
Train: Epoch[5/5]  [3400/3750]  eta: 0:02:02  Lr: 0.001875  Loss: -0.8336  Acc@1: 81.2500 (82.9958)  Acc@5: 93.7500 (97.1479)  time: 0.3507  data: 0.0014  max mem: 2500
Train: Epoch[5/5]  [3410/3750]  eta: 0:01:58  Lr: 0.001875  Loss: -0.9386  Acc@1: 81.2500 (82.9962)  Acc@5: 100.0000 (97.1489)  time: 0.3499  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3420/3750]  eta: 0:01:55  Lr: 0.001875  Loss: -1.0147  Acc@1: 81.2500 (82.9838)  Acc@5: 100.0000 (97.1481)  time: 0.3494  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3430/3750]  eta: 0:01:51  Lr: 0.001875  Loss: -1.0572  Acc@1: 81.2500 (82.9951)  Acc@5: 100.0000 (97.1528)  time: 0.3502  data: 0.0012  max mem: 2500
Train: Epoch[5/5]  [3440/3750]  eta: 0:01:48  Lr: 0.001875  Loss: -0.9650  Acc@1: 81.2500 (83.0082)  Acc@5: 100.0000 (97.1447)  time: 0.3504  data: 0.0012  max mem: 2500
Train: Epoch[5/5]  [3450/3750]  eta: 0:01:44  Lr: 0.001875  Loss: -0.8784  Acc@1: 81.2500 (83.0031)  Acc@5: 93.7500 (97.1439)  time: 0.3498  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3460/3750]  eta: 0:01:41  Lr: 0.001875  Loss: -0.9970  Acc@1: 81.2500 (82.9999)  Acc@5: 93.7500 (97.1323)  time: 0.3502  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3470/3750]  eta: 0:01:37  Lr: 0.001875  Loss: -1.3156  Acc@1: 87.5000 (83.0038)  Acc@5: 93.7500 (97.1334)  time: 0.3504  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3480/3750]  eta: 0:01:34  Lr: 0.001875  Loss: -0.8280  Acc@1: 87.5000 (83.0006)  Acc@5: 100.0000 (97.1273)  time: 0.3503  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3490/3750]  eta: 0:01:30  Lr: 0.001875  Loss: -1.0089  Acc@1: 81.2500 (83.0099)  Acc@5: 100.0000 (97.1283)  time: 0.3504  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3500/3750]  eta: 0:01:27  Lr: 0.001875  Loss: -0.4498  Acc@1: 81.2500 (83.0013)  Acc@5: 100.0000 (97.1294)  time: 0.3503  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3510/3750]  eta: 0:01:23  Lr: 0.001875  Loss: -1.4082  Acc@1: 81.2500 (83.0141)  Acc@5: 100.0000 (97.1340)  time: 0.3500  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3520/3750]  eta: 0:01:20  Lr: 0.001875  Loss: -1.1035  Acc@1: 87.5000 (83.0091)  Acc@5: 100.0000 (97.1350)  time: 0.3500  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3530/3750]  eta: 0:01:16  Lr: 0.001875  Loss: -1.0530  Acc@1: 81.2500 (83.0041)  Acc@5: 100.0000 (97.1379)  time: 0.3511  data: 0.0013  max mem: 2500
Train: Epoch[5/5]  [3540/3750]  eta: 0:01:13  Lr: 0.001875  Loss: -0.8240  Acc@1: 81.2500 (83.0097)  Acc@5: 100.0000 (97.1389)  time: 0.3511  data: 0.0013  max mem: 2500
Train: Epoch[5/5]  [3550/3750]  eta: 0:01:09  Lr: 0.001875  Loss: -1.0097  Acc@1: 81.2500 (82.9889)  Acc@5: 100.0000 (97.1328)  time: 0.3510  data: 0.0011  max mem: 2500
Train: Epoch[5/5]  [3560/3750]  eta: 0:01:06  Lr: 0.001875  Loss: -1.1697  Acc@1: 81.2500 (82.9946)  Acc@5: 100.0000 (97.1339)  time: 0.3501  data: 0.0011  max mem: 2500
Train: Epoch[5/5]  [3570/3750]  eta: 0:01:02  Lr: 0.001875  Loss: -1.1496  Acc@1: 87.5000 (83.0002)  Acc@5: 100.0000 (97.1367)  time: 0.3494  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3580/3750]  eta: 0:00:59  Lr: 0.001875  Loss: -1.2547  Acc@1: 87.5000 (82.9971)  Acc@5: 100.0000 (97.1359)  time: 0.3499  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3590/3750]  eta: 0:00:55  Lr: 0.001875  Loss: -1.0858  Acc@1: 87.5000 (83.0009)  Acc@5: 100.0000 (97.1369)  time: 0.3501  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3600/3750]  eta: 0:00:52  Lr: 0.001875  Loss: -0.8865  Acc@1: 87.5000 (83.0134)  Acc@5: 100.0000 (97.1362)  time: 0.3507  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [3610/3750]  eta: 0:00:48  Lr: 0.001875  Loss: -1.0470  Acc@1: 81.2500 (83.0102)  Acc@5: 100.0000 (97.1407)  time: 0.3496  data: 0.0008  max mem: 2500
Train: Epoch[5/5]  [3620/3750]  eta: 0:00:45  Lr: 0.001875  Loss: -1.0684  Acc@1: 81.2500 (83.0106)  Acc@5: 100.0000 (97.1451)  time: 0.3491  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [3630/3750]  eta: 0:00:41  Lr: 0.001875  Loss: -0.9301  Acc@1: 81.2500 (83.0246)  Acc@5: 100.0000 (97.1478)  time: 0.3499  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [3640/3750]  eta: 0:00:38  Lr: 0.001875  Loss: -1.3238  Acc@1: 81.2500 (83.0232)  Acc@5: 100.0000 (97.1488)  time: 0.3506  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3650/3750]  eta: 0:00:34  Lr: 0.001875  Loss: -1.1652  Acc@1: 81.2500 (83.0184)  Acc@5: 93.7500 (97.1446)  time: 0.3497  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [3660/3750]  eta: 0:00:31  Lr: 0.001875  Loss: -1.0960  Acc@1: 81.2500 (83.0152)  Acc@5: 93.7500 (97.1422)  time: 0.3496  data: 0.0006  max mem: 2500
Train: Epoch[5/5]  [3670/3750]  eta: 0:00:27  Lr: 0.001875  Loss: -0.9844  Acc@1: 81.2500 (83.0155)  Acc@5: 100.0000 (97.1431)  time: 0.3509  data: 0.0005  max mem: 2500
Train: Epoch[5/5]  [3680/3750]  eta: 0:00:24  Lr: 0.001875  Loss: -1.2648  Acc@1: 81.2500 (83.0124)  Acc@5: 100.0000 (97.1373)  time: 0.3498  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3690/3750]  eta: 0:00:20  Lr: 0.001875  Loss: -1.3328  Acc@1: 81.2500 (83.0161)  Acc@5: 100.0000 (97.1400)  time: 0.3479  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3700/3750]  eta: 0:00:17  Lr: 0.001875  Loss: -1.0955  Acc@1: 81.2500 (83.0113)  Acc@5: 100.0000 (97.1427)  time: 0.3476  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3710/3750]  eta: 0:00:13  Lr: 0.001875  Loss: -1.1122  Acc@1: 87.5000 (83.0403)  Acc@5: 100.0000 (97.1487)  time: 0.3484  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3720/3750]  eta: 0:00:10  Lr: 0.001875  Loss: -0.9433  Acc@1: 93.7500 (83.0422)  Acc@5: 100.0000 (97.1463)  time: 0.3494  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [3730/3750]  eta: 0:00:06  Lr: 0.001875  Loss: -0.8844  Acc@1: 75.0000 (83.0223)  Acc@5: 93.7500 (97.1372)  time: 0.3486  data: 0.0007  max mem: 2500
Train: Epoch[5/5]  [3740/3750]  eta: 0:00:03  Lr: 0.001875  Loss: -1.0882  Acc@1: 81.2500 (83.0192)  Acc@5: 93.7500 (97.1331)  time: 0.3473  data: 0.0004  max mem: 2500
Train: Epoch[5/5]  [3749/3750]  eta: 0:00:00  Lr: 0.001875  Loss: -0.8017  Acc@1: 81.2500 (83.0217)  Acc@5: 93.7500 (97.1317)  time: 0.3481  data: 0.0008  max mem: 2500
Train: Epoch[5/5] Total time: 0:21:52 (0.3499 s / it)
Averaged stats: Lr: 0.001875  Loss: -0.8017  Acc@1: 81.2500 (83.0217)  Acc@5: 93.7500 (97.1317)
Test: [Task 1]  [   0/1627]  eta: 0:16:28  Loss: 1.2755 (1.2755)  Acc@1: 75.0000 (75.0000)  Acc@5: 93.7500 (93.7500)  time: 0.6078  data: 0.3825  max mem: 2500
Test: [Task 1]  [  10/1627]  eta: 0:06:47  Loss: 0.9094 (0.9237)  Acc@1: 75.0000 (77.2727)  Acc@5: 100.0000 (96.0227)  time: 0.2523  data: 0.0351  max mem: 2500
Test: [Task 1]  [  20/1627]  eta: 0:06:19  Loss: 0.7700 (0.9104)  Acc@1: 75.0000 (77.9762)  Acc@5: 100.0000 (95.8333)  time: 0.2176  data: 0.0012  max mem: 2500
Test: [Task 1]  [  30/1627]  eta: 0:06:06  Loss: 0.8342 (0.9291)  Acc@1: 75.0000 (76.6129)  Acc@5: 100.0000 (95.9677)  time: 0.2172  data: 0.0012  max mem: 2500
Test: [Task 1]  [  40/1627]  eta: 0:05:59  Loss: 0.9280 (0.9568)  Acc@1: 75.0000 (75.9146)  Acc@5: 100.0000 (95.8841)  time: 0.2164  data: 0.0004  max mem: 2500
Test: [Task 1]  [  50/1627]  eta: 0:05:53  Loss: 0.9523 (0.9619)  Acc@1: 75.0000 (76.2255)  Acc@5: 93.7500 (95.8333)  time: 0.2163  data: 0.0004  max mem: 2500
Test: [Task 1]  [  60/1627]  eta: 0:05:50  Loss: 1.0033 (0.9665)  Acc@1: 75.0000 (76.1270)  Acc@5: 93.7500 (96.0041)  time: 0.2171  data: 0.0006  max mem: 2500
Test: [Task 1]  [  70/1627]  eta: 0:05:46  Loss: 0.9228 (0.9634)  Acc@1: 75.0000 (75.6162)  Acc@5: 100.0000 (96.4789)  time: 0.2173  data: 0.0006  max mem: 2500
Test: [Task 1]  [  80/1627]  eta: 0:05:43  Loss: 0.6989 (0.9572)  Acc@1: 81.2500 (76.0802)  Acc@5: 100.0000 (96.6821)  time: 0.2168  data: 0.0006  max mem: 2500
Test: [Task 1]  [  90/1627]  eta: 0:05:39  Loss: 0.9812 (0.9733)  Acc@1: 75.0000 (75.3434)  Acc@5: 100.0000 (96.1538)  time: 0.2164  data: 0.0005  max mem: 2500
Test: [Task 1]  [ 100/1627]  eta: 0:05:36  Loss: 1.1360 (0.9923)  Acc@1: 68.7500 (75.0000)  Acc@5: 93.7500 (95.7921)  time: 0.2159  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 110/1627]  eta: 0:05:34  Loss: 0.9562 (0.9834)  Acc@1: 75.0000 (75.2252)  Acc@5: 93.7500 (96.0023)  time: 0.2165  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 120/1627]  eta: 0:05:31  Loss: 0.9440 (0.9887)  Acc@1: 75.0000 (74.9483)  Acc@5: 100.0000 (95.6612)  time: 0.2161  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 130/1627]  eta: 0:05:28  Loss: 0.9690 (0.9906)  Acc@1: 75.0000 (74.8569)  Acc@5: 93.7500 (95.6584)  time: 0.2158  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 140/1627]  eta: 0:05:26  Loss: 0.8816 (0.9860)  Acc@1: 75.0000 (75.0000)  Acc@5: 93.7500 (95.5674)  time: 0.2166  data: 0.0005  max mem: 2500
Test: [Task 1]  [ 150/1627]  eta: 0:05:23  Loss: 0.6886 (0.9677)  Acc@1: 81.2500 (75.6623)  Acc@5: 100.0000 (95.6126)  time: 0.2169  data: 0.0005  max mem: 2500
Test: [Task 1]  [ 160/1627]  eta: 0:05:21  Loss: 0.6886 (0.9597)  Acc@1: 81.2500 (76.0481)  Acc@5: 100.0000 (95.6910)  time: 0.2182  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 170/1627]  eta: 0:05:19  Loss: 0.8438 (0.9546)  Acc@1: 81.2500 (76.0965)  Acc@5: 93.7500 (95.6871)  time: 0.2183  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 180/1627]  eta: 0:05:17  Loss: 0.8837 (0.9612)  Acc@1: 75.0000 (75.9323)  Acc@5: 93.7500 (95.5456)  time: 0.2180  data: 0.0011  max mem: 2500
Test: [Task 1]  [ 190/1627]  eta: 0:05:14  Loss: 0.9358 (0.9593)  Acc@1: 75.0000 (75.8835)  Acc@5: 93.7500 (95.5497)  time: 0.2186  data: 0.0010  max mem: 2500
Test: [Task 1]  [ 200/1627]  eta: 0:05:12  Loss: 0.8300 (0.9551)  Acc@1: 81.2500 (76.0261)  Acc@5: 93.7500 (95.5535)  time: 0.2194  data: 0.0008  max mem: 2500
Test: [Task 1]  [ 210/1627]  eta: 0:05:10  Loss: 0.7719 (0.9530)  Acc@1: 81.2500 (76.2441)  Acc@5: 93.7500 (95.5569)  time: 0.2198  data: 0.0009  max mem: 2500
Test: [Task 1]  [ 220/1627]  eta: 0:05:08  Loss: 0.7719 (0.9545)  Acc@1: 81.2500 (76.2161)  Acc@5: 100.0000 (95.6448)  time: 0.2184  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 230/1627]  eta: 0:05:06  Loss: 0.8277 (0.9510)  Acc@1: 75.0000 (76.1905)  Acc@5: 100.0000 (95.6710)  time: 0.2183  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 240/1627]  eta: 0:05:03  Loss: 0.8271 (0.9439)  Acc@1: 81.2500 (76.3485)  Acc@5: 100.0000 (95.7210)  time: 0.2193  data: 0.0005  max mem: 2500
Test: [Task 1]  [ 250/1627]  eta: 0:05:01  Loss: 0.8967 (0.9500)  Acc@1: 81.2500 (76.2948)  Acc@5: 93.7500 (95.5926)  time: 0.2198  data: 0.0006  max mem: 2500
Test: [Task 1]  [ 260/1627]  eta: 0:04:59  Loss: 0.9367 (0.9497)  Acc@1: 75.0000 (76.2692)  Acc@5: 93.7500 (95.6178)  time: 0.2193  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 270/1627]  eta: 0:04:57  Loss: 0.8971 (0.9432)  Acc@1: 75.0000 (76.4068)  Acc@5: 100.0000 (95.7334)  time: 0.2189  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 280/1627]  eta: 0:04:55  Loss: 0.8551 (0.9472)  Acc@1: 75.0000 (76.3123)  Acc@5: 100.0000 (95.6406)  time: 0.2194  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 290/1627]  eta: 0:04:52  Loss: 0.8753 (0.9446)  Acc@1: 75.0000 (76.3101)  Acc@5: 93.7500 (95.7045)  time: 0.2197  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 300/1627]  eta: 0:04:50  Loss: 0.8410 (0.9427)  Acc@1: 75.0000 (76.2874)  Acc@5: 100.0000 (95.7434)  time: 0.2199  data: 0.0011  max mem: 2500
Test: [Task 1]  [ 310/1627]  eta: 0:04:48  Loss: 0.8176 (0.9440)  Acc@1: 75.0000 (76.2259)  Acc@5: 93.7500 (95.6592)  time: 0.2197  data: 0.0011  max mem: 2500
Test: [Task 1]  [ 320/1627]  eta: 0:04:46  Loss: 0.9799 (0.9452)  Acc@1: 75.0000 (76.0514)  Acc@5: 93.7500 (95.6970)  time: 0.2202  data: 0.0007  max mem: 2500
Test: [Task 1]  [ 330/1627]  eta: 0:04:44  Loss: 0.8551 (0.9449)  Acc@1: 75.0000 (76.0385)  Acc@5: 100.0000 (95.6949)  time: 0.2200  data: 0.0007  max mem: 2500
Test: [Task 1]  [ 340/1627]  eta: 0:04:42  Loss: 0.8510 (0.9458)  Acc@1: 75.0000 (76.0081)  Acc@5: 100.0000 (95.6745)  time: 0.2188  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 350/1627]  eta: 0:04:39  Loss: 0.8942 (0.9479)  Acc@1: 75.0000 (75.9615)  Acc@5: 93.7500 (95.6019)  time: 0.2189  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 360/1627]  eta: 0:04:37  Loss: 0.9476 (0.9465)  Acc@1: 75.0000 (75.9349)  Acc@5: 93.7500 (95.6198)  time: 0.2191  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 370/1627]  eta: 0:04:35  Loss: 0.8272 (0.9452)  Acc@1: 75.0000 (75.9602)  Acc@5: 100.0000 (95.6705)  time: 0.2191  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 380/1627]  eta: 0:04:33  Loss: 0.8272 (0.9439)  Acc@1: 81.2500 (76.0499)  Acc@5: 100.0000 (95.6857)  time: 0.2187  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 390/1627]  eta: 0:04:31  Loss: 0.8730 (0.9446)  Acc@1: 81.2500 (76.0230)  Acc@5: 100.0000 (95.7001)  time: 0.2193  data: 0.0006  max mem: 2500
Test: [Task 1]  [ 400/1627]  eta: 0:04:28  Loss: 0.9047 (0.9459)  Acc@1: 75.0000 (75.9507)  Acc@5: 93.7500 (95.6827)  time: 0.2194  data: 0.0005  max mem: 2500
Test: [Task 1]  [ 410/1627]  eta: 0:04:26  Loss: 0.8803 (0.9455)  Acc@1: 75.0000 (76.0036)  Acc@5: 93.7500 (95.6965)  time: 0.2188  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 420/1627]  eta: 0:04:24  Loss: 0.7241 (0.9445)  Acc@1: 81.2500 (76.0837)  Acc@5: 100.0000 (95.7096)  time: 0.2187  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 430/1627]  eta: 0:04:22  Loss: 0.8062 (0.9414)  Acc@1: 75.0000 (76.0731)  Acc@5: 100.0000 (95.7947)  time: 0.2191  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 440/1627]  eta: 0:04:20  Loss: 0.8531 (0.9403)  Acc@1: 75.0000 (76.0629)  Acc@5: 100.0000 (95.8050)  time: 0.2191  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 450/1627]  eta: 0:04:17  Loss: 0.9464 (0.9433)  Acc@1: 75.0000 (75.9424)  Acc@5: 93.7500 (95.7594)  time: 0.2186  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 460/1627]  eta: 0:04:15  Loss: 0.9347 (0.9428)  Acc@1: 75.0000 (75.9355)  Acc@5: 100.0000 (95.7972)  time: 0.2184  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 470/1627]  eta: 0:04:13  Loss: 0.8925 (0.9395)  Acc@1: 75.0000 (76.0483)  Acc@5: 100.0000 (95.8201)  time: 0.2184  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 480/1627]  eta: 0:04:11  Loss: 0.8297 (0.9421)  Acc@1: 75.0000 (75.9615)  Acc@5: 100.0000 (95.8290)  time: 0.2186  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 490/1627]  eta: 0:04:09  Loss: 0.7957 (0.9404)  Acc@1: 75.0000 (75.9929)  Acc@5: 93.7500 (95.8376)  time: 0.2191  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 500/1627]  eta: 0:04:06  Loss: 0.7783 (0.9410)  Acc@1: 81.2500 (76.0230)  Acc@5: 93.7500 (95.8209)  time: 0.2192  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 510/1627]  eta: 0:04:04  Loss: 0.8950 (0.9475)  Acc@1: 75.0000 (75.9173)  Acc@5: 93.7500 (95.7314)  time: 0.2189  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 520/1627]  eta: 0:04:02  Loss: 1.2568 (0.9550)  Acc@1: 68.7500 (75.8397)  Acc@5: 93.7500 (95.7174)  time: 0.2183  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 530/1627]  eta: 0:04:00  Loss: 0.7317 (0.9491)  Acc@1: 81.2500 (76.0358)  Acc@5: 100.0000 (95.7863)  time: 0.2187  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 540/1627]  eta: 0:03:58  Loss: 0.7317 (0.9476)  Acc@1: 81.2500 (76.0744)  Acc@5: 100.0000 (95.7948)  time: 0.2191  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 550/1627]  eta: 0:03:55  Loss: 0.9115 (0.9488)  Acc@1: 75.0000 (75.9868)  Acc@5: 93.7500 (95.8031)  time: 0.2189  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 560/1627]  eta: 0:03:53  Loss: 0.9680 (0.9495)  Acc@1: 75.0000 (75.9581)  Acc@5: 100.0000 (95.8111)  time: 0.2194  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 570/1627]  eta: 0:03:51  Loss: 0.8705 (0.9465)  Acc@1: 75.0000 (75.9632)  Acc@5: 93.7500 (95.8187)  time: 0.2192  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 580/1627]  eta: 0:03:49  Loss: 0.8705 (0.9475)  Acc@1: 75.0000 (75.9359)  Acc@5: 93.7500 (95.8369)  time: 0.2187  data: 0.0006  max mem: 2500
Test: [Task 1]  [ 590/1627]  eta: 0:03:47  Loss: 0.9166 (0.9468)  Acc@1: 75.0000 (76.0047)  Acc@5: 100.0000 (95.8651)  time: 0.2186  data: 0.0006  max mem: 2500
Test: [Task 1]  [ 600/1627]  eta: 0:03:44  Loss: 0.8825 (0.9481)  Acc@1: 75.0000 (75.9775)  Acc@5: 100.0000 (95.8715)  time: 0.2185  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 610/1627]  eta: 0:03:42  Loss: 0.9037 (0.9462)  Acc@1: 75.0000 (76.0434)  Acc@5: 100.0000 (95.8777)  time: 0.2186  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 620/1627]  eta: 0:03:40  Loss: 0.9315 (0.9483)  Acc@1: 75.0000 (75.9762)  Acc@5: 93.7500 (95.8132)  time: 0.2179  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 630/1627]  eta: 0:03:38  Loss: 0.9129 (0.9486)  Acc@1: 75.0000 (75.9707)  Acc@5: 93.7500 (95.7904)  time: 0.2181  data: 0.0005  max mem: 2500
Test: [Task 1]  [ 640/1627]  eta: 0:03:36  Loss: 0.8991 (0.9503)  Acc@1: 75.0000 (75.9263)  Acc@5: 93.7500 (95.7781)  time: 0.2182  data: 0.0005  max mem: 2500
Test: [Task 1]  [ 650/1627]  eta: 0:03:33  Loss: 0.8664 (0.9499)  Acc@1: 75.0000 (75.9217)  Acc@5: 100.0000 (95.8141)  time: 0.2173  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 660/1627]  eta: 0:03:31  Loss: 0.8185 (0.9480)  Acc@1: 75.0000 (75.9266)  Acc@5: 100.0000 (95.8491)  time: 0.2171  data: 0.0005  max mem: 2500
Test: [Task 1]  [ 670/1627]  eta: 0:03:29  Loss: 0.8483 (0.9478)  Acc@1: 75.0000 (75.9501)  Acc@5: 93.7500 (95.8178)  time: 0.2168  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 680/1627]  eta: 0:03:27  Loss: 0.9157 (0.9476)  Acc@1: 75.0000 (75.9637)  Acc@5: 93.7500 (95.8058)  time: 0.2166  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 690/1627]  eta: 0:03:25  Loss: 0.8661 (0.9455)  Acc@1: 75.0000 (76.0492)  Acc@5: 100.0000 (95.8394)  time: 0.2177  data: 0.0007  max mem: 2500
Test: [Task 1]  [ 700/1627]  eta: 0:03:22  Loss: 0.8922 (0.9462)  Acc@1: 75.0000 (76.0610)  Acc@5: 100.0000 (95.8274)  time: 0.2185  data: 0.0007  max mem: 2500
Test: [Task 1]  [ 710/1627]  eta: 0:03:20  Loss: 0.8800 (0.9443)  Acc@1: 81.2500 (76.1252)  Acc@5: 93.7500 (95.8158)  time: 0.2180  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 720/1627]  eta: 0:03:18  Loss: 0.7981 (0.9422)  Acc@1: 81.2500 (76.1529)  Acc@5: 100.0000 (95.8304)  time: 0.2182  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 730/1627]  eta: 0:03:16  Loss: 0.8089 (0.9428)  Acc@1: 81.2500 (76.1713)  Acc@5: 93.7500 (95.8191)  time: 0.2184  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 740/1627]  eta: 0:03:14  Loss: 0.9198 (0.9440)  Acc@1: 75.0000 (76.1555)  Acc@5: 93.7500 (95.7996)  time: 0.2175  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 750/1627]  eta: 0:03:11  Loss: 0.8952 (0.9429)  Acc@1: 81.2500 (76.2234)  Acc@5: 93.7500 (95.8139)  time: 0.2178  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 760/1627]  eta: 0:03:09  Loss: 0.9594 (0.9474)  Acc@1: 75.0000 (76.0677)  Acc@5: 93.7500 (95.7539)  time: 0.2182  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 770/1627]  eta: 0:03:07  Loss: 0.9167 (0.9441)  Acc@1: 75.0000 (76.1592)  Acc@5: 93.7500 (95.7685)  time: 0.2178  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 780/1627]  eta: 0:03:05  Loss: 0.6224 (0.9418)  Acc@1: 81.2500 (76.2244)  Acc@5: 100.0000 (95.8067)  time: 0.2190  data: 0.0015  max mem: 2500
Test: [Task 1]  [ 790/1627]  eta: 0:03:03  Loss: 0.8259 (0.9430)  Acc@1: 75.0000 (76.1773)  Acc@5: 100.0000 (95.8044)  time: 0.2192  data: 0.0015  max mem: 2500
Test: [Task 1]  [ 800/1627]  eta: 0:03:00  Loss: 0.8810 (0.9432)  Acc@1: 75.0000 (76.1392)  Acc@5: 100.0000 (95.8021)  time: 0.2184  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 810/1627]  eta: 0:02:58  Loss: 0.8454 (0.9423)  Acc@1: 75.0000 (76.2099)  Acc@5: 100.0000 (95.7922)  time: 0.2184  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 820/1627]  eta: 0:02:56  Loss: 0.7588 (0.9413)  Acc@1: 81.2500 (76.2789)  Acc@5: 100.0000 (95.8130)  time: 0.2186  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 830/1627]  eta: 0:02:54  Loss: 0.7966 (0.9403)  Acc@1: 75.0000 (76.2861)  Acc@5: 100.0000 (95.8333)  time: 0.2187  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 840/1627]  eta: 0:02:52  Loss: 0.7052 (0.9381)  Acc@1: 75.0000 (76.3600)  Acc@5: 100.0000 (95.8680)  time: 0.2185  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 850/1627]  eta: 0:02:49  Loss: 0.7052 (0.9392)  Acc@1: 81.2500 (76.3734)  Acc@5: 100.0000 (95.8652)  time: 0.2189  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 860/1627]  eta: 0:02:47  Loss: 0.8919 (0.9388)  Acc@1: 81.2500 (76.3937)  Acc@5: 100.0000 (95.8769)  time: 0.2193  data: 0.0007  max mem: 2500
Test: [Task 1]  [ 870/1627]  eta: 0:02:45  Loss: 0.8743 (0.9380)  Acc@1: 81.2500 (76.4423)  Acc@5: 100.0000 (95.8740)  time: 0.2187  data: 0.0008  max mem: 2500
Test: [Task 1]  [ 880/1627]  eta: 0:02:43  Loss: 0.9418 (0.9396)  Acc@1: 75.0000 (76.3976)  Acc@5: 100.0000 (95.8925)  time: 0.2187  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 890/1627]  eta: 0:02:41  Loss: 0.9806 (0.9416)  Acc@1: 75.0000 (76.3959)  Acc@5: 100.0000 (95.8544)  time: 0.2191  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 900/1627]  eta: 0:02:39  Loss: 0.9330 (0.9418)  Acc@1: 81.2500 (76.4151)  Acc@5: 93.7500 (95.8449)  time: 0.2195  data: 0.0005  max mem: 2500
Test: [Task 1]  [ 910/1627]  eta: 0:02:36  Loss: 1.0238 (0.9427)  Acc@1: 75.0000 (76.4133)  Acc@5: 93.7500 (95.8082)  time: 0.2204  data: 0.0005  max mem: 2500
Test: [Task 1]  [ 920/1627]  eta: 0:02:34  Loss: 0.8205 (0.9422)  Acc@1: 75.0000 (76.4115)  Acc@5: 93.7500 (95.8062)  time: 0.2203  data: 0.0005  max mem: 2500
Test: [Task 1]  [ 930/1627]  eta: 0:02:32  Loss: 0.8669 (0.9428)  Acc@1: 75.0000 (76.4232)  Acc@5: 93.7500 (95.8110)  time: 0.2194  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 940/1627]  eta: 0:02:30  Loss: 0.8961 (0.9420)  Acc@1: 75.0000 (76.4081)  Acc@5: 100.0000 (95.8156)  time: 0.2193  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 950/1627]  eta: 0:02:28  Loss: 0.8961 (0.9430)  Acc@1: 75.0000 (76.3801)  Acc@5: 93.7500 (95.8005)  time: 0.2191  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 960/1627]  eta: 0:02:25  Loss: 0.8720 (0.9421)  Acc@1: 75.0000 (76.4178)  Acc@5: 93.7500 (95.8117)  time: 0.2191  data: 0.0003  max mem: 2500
Test: [Task 1]  [ 970/1627]  eta: 0:02:23  Loss: 0.7947 (0.9408)  Acc@1: 81.2500 (76.4482)  Acc@5: 100.0000 (95.8097)  time: 0.2199  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 980/1627]  eta: 0:02:21  Loss: 0.9122 (0.9413)  Acc@1: 75.0000 (76.4335)  Acc@5: 100.0000 (95.8078)  time: 0.2202  data: 0.0004  max mem: 2500
Test: [Task 1]  [ 990/1627]  eta: 0:02:19  Loss: 0.9851 (0.9438)  Acc@1: 75.0000 (76.4064)  Acc@5: 93.7500 (95.7808)  time: 0.2195  data: 0.0004  max mem: 2500
Test: [Task 1]  [1000/1627]  eta: 0:02:17  Loss: 0.9938 (0.9447)  Acc@1: 81.2500 (76.4111)  Acc@5: 93.7500 (95.7667)  time: 0.2203  data: 0.0006  max mem: 2500
Test: [Task 1]  [1010/1627]  eta: 0:02:15  Loss: 0.9511 (0.9447)  Acc@1: 81.2500 (76.4280)  Acc@5: 93.7500 (95.7530)  time: 0.2213  data: 0.0006  max mem: 2500
Test: [Task 1]  [1020/1627]  eta: 0:02:12  Loss: 0.8948 (0.9443)  Acc@1: 75.0000 (76.4447)  Acc@5: 93.7500 (95.7762)  time: 0.2201  data: 0.0003  max mem: 2500
Test: [Task 1]  [1030/1627]  eta: 0:02:10  Loss: 0.6918 (0.9420)  Acc@1: 81.2500 (76.5155)  Acc@5: 100.0000 (95.7929)  time: 0.2196  data: 0.0004  max mem: 2500
Test: [Task 1]  [1040/1627]  eta: 0:02:08  Loss: 0.6906 (0.9411)  Acc@1: 81.2500 (76.5310)  Acc@5: 100.0000 (95.7973)  time: 0.2200  data: 0.0004  max mem: 2500
Test: [Task 1]  [1050/1627]  eta: 0:02:06  Loss: 0.8661 (0.9396)  Acc@1: 75.0000 (76.5937)  Acc@5: 100.0000 (95.8076)  time: 0.2207  data: 0.0004  max mem: 2500
Test: [Task 1]  [1060/1627]  eta: 0:02:04  Loss: 0.8661 (0.9394)  Acc@1: 75.0000 (76.6082)  Acc@5: 93.7500 (95.8058)  time: 0.2207  data: 0.0004  max mem: 2500
Test: [Task 1]  [1070/1627]  eta: 0:02:01  Loss: 0.8153 (0.9395)  Acc@1: 81.2500 (76.6282)  Acc@5: 93.7500 (95.7983)  time: 0.2199  data: 0.0005  max mem: 2500
Test: [Task 1]  [1080/1627]  eta: 0:01:59  Loss: 0.8061 (0.9398)  Acc@1: 81.2500 (76.6536)  Acc@5: 100.0000 (95.7909)  time: 0.2200  data: 0.0005  max mem: 2500
Test: [Task 1]  [1090/1627]  eta: 0:01:57  Loss: 0.9431 (0.9401)  Acc@1: 75.0000 (76.6499)  Acc@5: 100.0000 (95.7837)  time: 0.2205  data: 0.0004  max mem: 2500
Test: [Task 1]  [1100/1627]  eta: 0:01:55  Loss: 0.8473 (0.9382)  Acc@1: 81.2500 (76.6916)  Acc@5: 100.0000 (95.7993)  time: 0.2212  data: 0.0009  max mem: 2500
Test: [Task 1]  [1110/1627]  eta: 0:01:53  Loss: 0.8473 (0.9394)  Acc@1: 81.2500 (76.6820)  Acc@5: 100.0000 (95.7921)  time: 0.2209  data: 0.0009  max mem: 2500
Test: [Task 1]  [1120/1627]  eta: 0:01:51  Loss: 0.9044 (0.9408)  Acc@1: 75.0000 (76.6503)  Acc@5: 93.7500 (95.7906)  time: 0.2200  data: 0.0004  max mem: 2500
Test: [Task 1]  [1130/1627]  eta: 0:01:48  Loss: 1.0157 (0.9419)  Acc@1: 75.0000 (76.6302)  Acc@5: 93.7500 (95.7836)  time: 0.2203  data: 0.0004  max mem: 2500
Test: [Task 1]  [1140/1627]  eta: 0:01:46  Loss: 1.0157 (0.9432)  Acc@1: 75.0000 (76.6159)  Acc@5: 93.7500 (95.7767)  time: 0.2205  data: 0.0005  max mem: 2500
Test: [Task 1]  [1150/1627]  eta: 0:01:44  Loss: 1.0466 (0.9451)  Acc@1: 68.7500 (76.5530)  Acc@5: 93.7500 (95.7646)  time: 0.2202  data: 0.0005  max mem: 2500
Test: [Task 1]  [1160/1627]  eta: 0:01:42  Loss: 0.9745 (0.9434)  Acc@1: 75.0000 (76.6096)  Acc@5: 100.0000 (95.7903)  time: 0.2204  data: 0.0006  max mem: 2500
Test: [Task 1]  [1170/1627]  eta: 0:01:40  Loss: 0.8888 (0.9433)  Acc@1: 81.2500 (76.6065)  Acc@5: 100.0000 (95.7942)  time: 0.2205  data: 0.0006  max mem: 2500
Test: [Task 1]  [1180/1627]  eta: 0:01:37  Loss: 0.9370 (0.9438)  Acc@1: 75.0000 (76.5718)  Acc@5: 100.0000 (95.8033)  time: 0.2203  data: 0.0004  max mem: 2500
Test: [Task 1]  [1190/1627]  eta: 0:01:35  Loss: 1.0200 (0.9449)  Acc@1: 75.0000 (76.5481)  Acc@5: 93.7500 (95.7756)  time: 0.2199  data: 0.0004  max mem: 2500
Test: [Task 1]  [1200/1627]  eta: 0:01:33  Loss: 1.0174 (0.9453)  Acc@1: 75.0000 (76.5612)  Acc@5: 93.7500 (95.7744)  time: 0.2194  data: 0.0004  max mem: 2500
Test: [Task 1]  [1210/1627]  eta: 0:01:31  Loss: 0.7532 (0.9454)  Acc@1: 75.0000 (76.5535)  Acc@5: 100.0000 (95.7680)  time: 0.2190  data: 0.0004  max mem: 2500
Test: [Task 1]  [1220/1627]  eta: 0:01:29  Loss: 0.7198 (0.9444)  Acc@1: 75.0000 (76.5817)  Acc@5: 100.0000 (95.7873)  time: 0.2193  data: 0.0004  max mem: 2500
Test: [Task 1]  [1230/1627]  eta: 0:01:26  Loss: 0.8673 (0.9451)  Acc@1: 75.0000 (76.5739)  Acc@5: 100.0000 (95.7809)  time: 0.2195  data: 0.0004  max mem: 2500
Test: [Task 1]  [1240/1627]  eta: 0:01:24  Loss: 0.8744 (0.9445)  Acc@1: 75.0000 (76.5864)  Acc@5: 100.0000 (95.7796)  time: 0.2198  data: 0.0012  max mem: 2500
Test: [Task 1]  [1250/1627]  eta: 0:01:22  Loss: 1.0280 (0.9451)  Acc@1: 75.0000 (76.5687)  Acc@5: 93.7500 (95.7734)  time: 0.2199  data: 0.0011  max mem: 2500
Test: [Task 1]  [1260/1627]  eta: 0:01:20  Loss: 0.9386 (0.9447)  Acc@1: 75.0000 (76.6158)  Acc@5: 100.0000 (95.7821)  time: 0.2195  data: 0.0004  max mem: 2500
Test: [Task 1]  [1270/1627]  eta: 0:01:18  Loss: 0.8875 (0.9453)  Acc@1: 75.0000 (76.5982)  Acc@5: 100.0000 (95.7760)  time: 0.2198  data: 0.0005  max mem: 2500
Test: [Task 1]  [1280/1627]  eta: 0:01:16  Loss: 0.8288 (0.9437)  Acc@1: 75.0000 (76.6491)  Acc@5: 100.0000 (95.7943)  time: 0.2201  data: 0.0005  max mem: 2500
Test: [Task 1]  [1290/1627]  eta: 0:01:13  Loss: 0.9669 (0.9444)  Acc@1: 75.0000 (76.5928)  Acc@5: 100.0000 (95.8027)  time: 0.2201  data: 0.0004  max mem: 2500
Test: [Task 1]  [1300/1627]  eta: 0:01:11  Loss: 0.9792 (0.9435)  Acc@1: 75.0000 (76.6334)  Acc@5: 100.0000 (95.8157)  time: 0.2205  data: 0.0005  max mem: 2500
Test: [Task 1]  [1310/1627]  eta: 0:01:09  Loss: 0.8375 (0.9422)  Acc@1: 87.5000 (76.6876)  Acc@5: 100.0000 (95.8190)  time: 0.2199  data: 0.0004  max mem: 2500
Test: [Task 1]  [1320/1627]  eta: 0:01:07  Loss: 0.6382 (0.9414)  Acc@1: 81.2500 (76.7127)  Acc@5: 100.0000 (95.8270)  time: 0.2191  data: 0.0004  max mem: 2500
Test: [Task 1]  [1330/1627]  eta: 0:01:05  Loss: 0.7095 (0.9408)  Acc@1: 81.2500 (76.7280)  Acc@5: 100.0000 (95.8396)  time: 0.2192  data: 0.0004  max mem: 2500
Test: [Task 1]  [1340/1627]  eta: 0:01:02  Loss: 0.8466 (0.9410)  Acc@1: 75.0000 (76.7245)  Acc@5: 100.0000 (95.8240)  time: 0.2199  data: 0.0010  max mem: 2500
Test: [Task 1]  [1350/1627]  eta: 0:01:00  Loss: 0.7946 (0.9403)  Acc@1: 75.0000 (76.7487)  Acc@5: 93.7500 (95.8272)  time: 0.2199  data: 0.0010  max mem: 2500
Test: [Task 1]  [1360/1627]  eta: 0:00:58  Loss: 0.8467 (0.9400)  Acc@1: 81.2500 (76.7542)  Acc@5: 100.0000 (95.8440)  time: 0.2192  data: 0.0003  max mem: 2500
Test: [Task 1]  [1370/1627]  eta: 0:00:56  Loss: 0.8668 (0.9399)  Acc@1: 75.0000 (76.7323)  Acc@5: 100.0000 (95.8470)  time: 0.2203  data: 0.0003  max mem: 2500
Test: [Task 1]  [1380/1627]  eta: 0:00:54  Loss: 0.9243 (0.9398)  Acc@1: 75.0000 (76.7469)  Acc@5: 100.0000 (95.8590)  time: 0.2205  data: 0.0003  max mem: 2500
Test: [Task 1]  [1390/1627]  eta: 0:00:51  Loss: 0.9899 (0.9391)  Acc@1: 81.2500 (76.7793)  Acc@5: 93.7500 (95.8618)  time: 0.2204  data: 0.0004  max mem: 2500
Test: [Task 1]  [1400/1627]  eta: 0:00:49  Loss: 0.9538 (0.9394)  Acc@1: 81.2500 (76.7711)  Acc@5: 93.7500 (95.8601)  time: 0.2206  data: 0.0005  max mem: 2500
Test: [Task 1]  [1410/1627]  eta: 0:00:47  Loss: 0.7615 (0.9386)  Acc@1: 81.2500 (76.7984)  Acc@5: 100.0000 (95.8762)  time: 0.2204  data: 0.0005  max mem: 2500
Test: [Task 1]  [1420/1627]  eta: 0:00:45  Loss: 0.7615 (0.9379)  Acc@1: 81.2500 (76.8253)  Acc@5: 100.0000 (95.8744)  time: 0.2204  data: 0.0006  max mem: 2500
Test: [Task 1]  [1430/1627]  eta: 0:00:43  Loss: 1.0107 (0.9393)  Acc@1: 75.0000 (76.8082)  Acc@5: 93.7500 (95.8377)  time: 0.2202  data: 0.0005  max mem: 2500
Test: [Task 1]  [1440/1627]  eta: 0:00:41  Loss: 1.0040 (0.9391)  Acc@1: 75.0000 (76.7870)  Acc@5: 93.7500 (95.8406)  time: 0.2200  data: 0.0004  max mem: 2500
Test: [Task 1]  [1450/1627]  eta: 0:00:38  Loss: 1.0040 (0.9404)  Acc@1: 68.7500 (76.7402)  Acc@5: 93.7500 (95.8218)  time: 0.2205  data: 0.0004  max mem: 2500
Test: [Task 1]  [1460/1627]  eta: 0:00:36  Loss: 1.0412 (0.9402)  Acc@1: 75.0000 (76.7454)  Acc@5: 93.7500 (95.8162)  time: 0.2204  data: 0.0004  max mem: 2500
Test: [Task 1]  [1470/1627]  eta: 0:00:34  Loss: 0.8829 (0.9403)  Acc@1: 75.0000 (76.7420)  Acc@5: 93.7500 (95.8149)  time: 0.2207  data: 0.0004  max mem: 2500
Test: [Task 1]  [1480/1627]  eta: 0:00:32  Loss: 0.9648 (0.9413)  Acc@1: 75.0000 (76.7134)  Acc@5: 93.7500 (95.8010)  time: 0.2212  data: 0.0004  max mem: 2500
Test: [Task 1]  [1490/1627]  eta: 0:00:30  Loss: 0.9566 (0.9415)  Acc@1: 75.0000 (76.7270)  Acc@5: 93.7500 (95.7998)  time: 0.2204  data: 0.0004  max mem: 2500
Test: [Task 1]  [1500/1627]  eta: 0:00:27  Loss: 0.7743 (0.9413)  Acc@1: 75.0000 (76.7405)  Acc@5: 100.0000 (95.8028)  time: 0.2198  data: 0.0003  max mem: 2500
Test: [Task 1]  [1510/1627]  eta: 0:00:25  Loss: 0.7246 (0.9411)  Acc@1: 81.2500 (76.7745)  Acc@5: 93.7500 (95.7933)  time: 0.2208  data: 0.0017  max mem: 2500
Test: [Task 1]  [1520/1627]  eta: 0:00:23  Loss: 0.7242 (0.9397)  Acc@1: 81.2500 (76.8121)  Acc@5: 100.0000 (95.8005)  time: 0.2234  data: 0.0017  max mem: 2500
Test: [Task 1]  [1530/1627]  eta: 0:00:21  Loss: 0.7102 (0.9395)  Acc@1: 81.2500 (76.8003)  Acc@5: 100.0000 (95.8116)  time: 0.2220  data: 0.0003  max mem: 2500
Test: [Task 1]  [1540/1627]  eta: 0:00:19  Loss: 0.6849 (0.9389)  Acc@1: 81.2500 (76.8089)  Acc@5: 100.0000 (95.8266)  time: 0.2198  data: 0.0003  max mem: 2500
Test: [Task 1]  [1550/1627]  eta: 0:00:16  Loss: 0.7519 (0.9389)  Acc@1: 81.2500 (76.8295)  Acc@5: 100.0000 (95.8212)  time: 0.2199  data: 0.0005  max mem: 2500
Test: [Task 1]  [1560/1627]  eta: 0:00:14  Loss: 0.8122 (0.9382)  Acc@1: 81.2500 (76.8498)  Acc@5: 100.0000 (95.8200)  time: 0.2197  data: 0.0005  max mem: 2500
Test: [Task 1]  [1570/1627]  eta: 0:00:12  Loss: 0.8122 (0.9384)  Acc@1: 75.0000 (76.8261)  Acc@5: 100.0000 (95.8108)  time: 0.2204  data: 0.0007  max mem: 2500
Test: [Task 1]  [1580/1627]  eta: 0:00:10  Loss: 0.8325 (0.9379)  Acc@1: 75.0000 (76.8422)  Acc@5: 100.0000 (95.8136)  time: 0.2206  data: 0.0007  max mem: 2500
Test: [Task 1]  [1590/1627]  eta: 0:00:08  Loss: 0.8934 (0.9382)  Acc@1: 75.0000 (76.8031)  Acc@5: 100.0000 (95.8163)  time: 0.2216  data: 0.0004  max mem: 2500
Test: [Task 1]  [1600/1627]  eta: 0:00:05  Loss: 0.9002 (0.9394)  Acc@1: 68.7500 (76.7528)  Acc@5: 100.0000 (95.7995)  time: 0.2222  data: 0.0012  max mem: 2500
Test: [Task 1]  [1610/1627]  eta: 0:00:03  Loss: 0.9122 (0.9387)  Acc@1: 75.0000 (76.7691)  Acc@5: 100.0000 (95.8178)  time: 0.2221  data: 0.0018  max mem: 2500
Test: [Task 1]  [1620/1627]  eta: 0:00:01  Loss: 0.7695 (0.9376)  Acc@1: 81.2500 (76.8044)  Acc@5: 100.0000 (95.8243)  time: 0.2212  data: 0.0010  max mem: 2500
Test: [Task 1]  [1626/1627]  eta: 0:00:00  Loss: 0.7695 (0.9372)  Acc@1: 81.2500 (76.8170)  Acc@5: 100.0000 (95.8205)  time: 0.2208  data: 0.0009  max mem: 2500
Test: [Task 1] Total time: 0:05:57 (0.2197 s / it)
* Acc@1 76.817 Acc@5 95.821 loss 0.937
Test: [Task 2]  [  0/625]  eta: 0:07:05  Loss: 0.2832 (0.2832)  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (100.0000)  time: 0.6808  data: 0.4618  max mem: 2500
Test: [Task 2]  [ 10/625]  eta: 0:02:40  Loss: 0.2832 (0.2965)  Acc@1: 93.7500 (91.4773)  Acc@5: 100.0000 (99.4318)  time: 0.2612  data: 0.0423  max mem: 2500
Test: [Task 2]  [ 20/625]  eta: 0:02:26  Loss: 0.2610 (0.2941)  Acc@1: 93.7500 (91.6667)  Acc@5: 100.0000 (99.7024)  time: 0.2197  data: 0.0004  max mem: 2500
Test: [Task 2]  [ 30/625]  eta: 0:02:19  Loss: 0.2681 (0.3114)  Acc@1: 93.7500 (90.9274)  Acc@5: 100.0000 (99.5968)  time: 0.2198  data: 0.0004  max mem: 2500
Test: [Task 2]  [ 40/625]  eta: 0:02:14  Loss: 0.2720 (0.3255)  Acc@1: 87.5000 (90.7012)  Acc@5: 100.0000 (99.6951)  time: 0.2193  data: 0.0004  max mem: 2500
Test: [Task 2]  [ 50/625]  eta: 0:02:11  Loss: 0.3038 (0.3508)  Acc@1: 87.5000 (89.5833)  Acc@5: 100.0000 (99.5098)  time: 0.2191  data: 0.0004  max mem: 2500
Test: [Task 2]  [ 60/625]  eta: 0:02:08  Loss: 0.3041 (0.3483)  Acc@1: 87.5000 (89.3443)  Acc@5: 100.0000 (99.4877)  time: 0.2196  data: 0.0005  max mem: 2500
Test: [Task 2]  [ 70/625]  eta: 0:02:05  Loss: 0.2864 (0.3413)  Acc@1: 87.5000 (89.7007)  Acc@5: 100.0000 (99.4718)  time: 0.2197  data: 0.0005  max mem: 2500
Test: [Task 2]  [ 80/625]  eta: 0:02:02  Loss: 0.2693 (0.3493)  Acc@1: 93.7500 (89.6605)  Acc@5: 100.0000 (99.4599)  time: 0.2196  data: 0.0003  max mem: 2500
Test: [Task 2]  [ 90/625]  eta: 0:02:00  Loss: 0.2798 (0.3447)  Acc@1: 93.7500 (89.9038)  Acc@5: 100.0000 (99.5192)  time: 0.2208  data: 0.0013  max mem: 2500
Test: [Task 2]  [100/625]  eta: 0:01:57  Loss: 0.2798 (0.3412)  Acc@1: 93.7500 (90.1609)  Acc@5: 100.0000 (99.5668)  time: 0.2205  data: 0.0013  max mem: 2500
Test: [Task 2]  [110/625]  eta: 0:01:55  Loss: 0.2793 (0.3430)  Acc@1: 93.7500 (90.2027)  Acc@5: 100.0000 (99.5495)  time: 0.2209  data: 0.0007  max mem: 2500
Test: [Task 2]  [120/625]  eta: 0:01:53  Loss: 0.3347 (0.3417)  Acc@1: 87.5000 (89.9793)  Acc@5: 100.0000 (99.5868)  time: 0.2213  data: 0.0007  max mem: 2500
Test: [Task 2]  [130/625]  eta: 0:01:50  Loss: 0.3443 (0.3424)  Acc@1: 87.5000 (90.0286)  Acc@5: 100.0000 (99.5706)  time: 0.2199  data: 0.0005  max mem: 2500
Test: [Task 2]  [140/625]  eta: 0:01:48  Loss: 0.3461 (0.3468)  Acc@1: 93.7500 (89.9823)  Acc@5: 100.0000 (99.5567)  time: 0.2193  data: 0.0004  max mem: 2500
Test: [Task 2]  [150/625]  eta: 0:01:45  Loss: 0.3826 (0.3512)  Acc@1: 87.5000 (89.6937)  Acc@5: 100.0000 (99.5861)  time: 0.2190  data: 0.0003  max mem: 2500
Test: [Task 2]  [160/625]  eta: 0:01:43  Loss: 0.3826 (0.3538)  Acc@1: 87.5000 (89.7127)  Acc@5: 100.0000 (99.5342)  time: 0.2189  data: 0.0004  max mem: 2500
Test: [Task 2]  [170/625]  eta: 0:01:41  Loss: 0.3217 (0.3531)  Acc@1: 93.7500 (89.7295)  Acc@5: 100.0000 (99.5614)  time: 0.2194  data: 0.0008  max mem: 2500
Test: [Task 2]  [180/625]  eta: 0:01:38  Loss: 0.3148 (0.3517)  Acc@1: 93.7500 (89.8135)  Acc@5: 100.0000 (99.5511)  time: 0.2190  data: 0.0008  max mem: 2500
Test: [Task 2]  [190/625]  eta: 0:01:36  Loss: 0.3311 (0.3567)  Acc@1: 87.5000 (89.6597)  Acc@5: 100.0000 (99.5419)  time: 0.2190  data: 0.0003  max mem: 2500
Test: [Task 2]  [200/625]  eta: 0:01:34  Loss: 0.3266 (0.3559)  Acc@1: 87.5000 (89.6766)  Acc@5: 100.0000 (99.5647)  time: 0.2190  data: 0.0004  max mem: 2500
Test: [Task 2]  [210/625]  eta: 0:01:32  Loss: 0.3231 (0.3575)  Acc@1: 87.5000 (89.4846)  Acc@5: 100.0000 (99.5261)  time: 0.2193  data: 0.0005  max mem: 2500
Test: [Task 2]  [220/625]  eta: 0:01:29  Loss: 0.2998 (0.3536)  Acc@1: 93.7500 (89.7342)  Acc@5: 100.0000 (99.5475)  time: 0.2195  data: 0.0004  max mem: 2500
Test: [Task 2]  [230/625]  eta: 0:01:27  Loss: 0.2671 (0.3526)  Acc@1: 93.7500 (89.6916)  Acc@5: 100.0000 (99.5671)  time: 0.2185  data: 0.0004  max mem: 2500
Test: [Task 2]  [240/625]  eta: 0:01:25  Loss: 0.2979 (0.3519)  Acc@1: 87.5000 (89.7303)  Acc@5: 100.0000 (99.5591)  time: 0.2184  data: 0.0004  max mem: 2500
Test: [Task 2]  [250/625]  eta: 0:01:23  Loss: 0.3315 (0.3538)  Acc@1: 87.5000 (89.6912)  Acc@5: 100.0000 (99.5020)  time: 0.2191  data: 0.0005  max mem: 2500
Test: [Task 2]  [260/625]  eta: 0:01:20  Loss: 0.3315 (0.3527)  Acc@1: 87.5000 (89.6552)  Acc@5: 100.0000 (99.4732)  time: 0.2196  data: 0.0005  max mem: 2500
Test: [Task 2]  [270/625]  eta: 0:01:18  Loss: 0.3271 (0.3538)  Acc@1: 87.5000 (89.6679)  Acc@5: 100.0000 (99.4696)  time: 0.2200  data: 0.0007  max mem: 2500
Test: [Task 2]  [280/625]  eta: 0:01:16  Loss: 0.3271 (0.3554)  Acc@1: 87.5000 (89.5907)  Acc@5: 100.0000 (99.4662)  time: 0.2195  data: 0.0007  max mem: 2500
Test: [Task 2]  [290/625]  eta: 0:01:14  Loss: 0.2709 (0.3554)  Acc@1: 87.5000 (89.6048)  Acc@5: 100.0000 (99.4631)  time: 0.2185  data: 0.0003  max mem: 2500
Test: [Task 2]  [300/625]  eta: 0:01:11  Loss: 0.2728 (0.3559)  Acc@1: 87.5000 (89.5556)  Acc@5: 100.0000 (99.4809)  time: 0.2187  data: 0.0004  max mem: 2500
Test: [Task 2]  [310/625]  eta: 0:01:09  Loss: 0.3839 (0.3574)  Acc@1: 87.5000 (89.4695)  Acc@5: 100.0000 (99.4775)  time: 0.2203  data: 0.0010  max mem: 2500
Test: [Task 2]  [320/625]  eta: 0:01:07  Loss: 0.1898 (0.3497)  Acc@1: 93.7500 (89.7391)  Acc@5: 100.0000 (99.4938)  time: 0.2202  data: 0.0010  max mem: 2500
Test: [Task 2]  [330/625]  eta: 0:01:05  Loss: 0.1501 (0.3457)  Acc@1: 93.7500 (89.8036)  Acc@5: 100.0000 (99.5091)  time: 0.2190  data: 0.0004  max mem: 2500
Test: [Task 2]  [340/625]  eta: 0:01:02  Loss: 0.1354 (0.3381)  Acc@1: 100.0000 (90.0843)  Acc@5: 100.0000 (99.5235)  time: 0.2195  data: 0.0006  max mem: 2500
Test: [Task 2]  [350/625]  eta: 0:01:00  Loss: 0.1099 (0.3356)  Acc@1: 100.0000 (90.0997)  Acc@5: 100.0000 (99.5370)  time: 0.2197  data: 0.0006  max mem: 2500
Test: [Task 2]  [360/625]  eta: 0:00:58  Loss: 0.3158 (0.3362)  Acc@1: 87.5000 (90.0450)  Acc@5: 100.0000 (99.5325)  time: 0.2192  data: 0.0004  max mem: 2500
Test: [Task 2]  [370/625]  eta: 0:00:56  Loss: 0.3124 (0.3339)  Acc@1: 87.5000 (90.1112)  Acc@5: 100.0000 (99.5451)  time: 0.2191  data: 0.0004  max mem: 2500
Test: [Task 2]  [380/625]  eta: 0:00:54  Loss: 0.2999 (0.3365)  Acc@1: 93.7500 (90.0427)  Acc@5: 100.0000 (99.5243)  time: 0.2195  data: 0.0004  max mem: 2500
Test: [Task 2]  [390/625]  eta: 0:00:51  Loss: 0.2706 (0.3336)  Acc@1: 93.7500 (90.1694)  Acc@5: 100.0000 (99.5364)  time: 0.2194  data: 0.0004  max mem: 2500
Test: [Task 2]  [400/625]  eta: 0:00:49  Loss: 0.1059 (0.3282)  Acc@1: 100.0000 (90.3678)  Acc@5: 100.0000 (99.5480)  time: 0.2195  data: 0.0004  max mem: 2500
Test: [Task 2]  [410/625]  eta: 0:00:47  Loss: 0.0880 (0.3259)  Acc@1: 100.0000 (90.4805)  Acc@5: 100.0000 (99.5286)  time: 0.2199  data: 0.0004  max mem: 2500
Test: [Task 2]  [420/625]  eta: 0:00:45  Loss: 0.1094 (0.3239)  Acc@1: 100.0000 (90.5433)  Acc@5: 100.0000 (99.5398)  time: 0.2204  data: 0.0004  max mem: 2500
Test: [Task 2]  [430/625]  eta: 0:00:43  Loss: 0.2429 (0.3221)  Acc@1: 93.7500 (90.5742)  Acc@5: 100.0000 (99.5505)  time: 0.2201  data: 0.0004  max mem: 2500
Test: [Task 2]  [440/625]  eta: 0:00:40  Loss: 0.1306 (0.3169)  Acc@1: 93.7500 (90.7738)  Acc@5: 100.0000 (99.5607)  time: 0.2193  data: 0.0004  max mem: 2500
Test: [Task 2]  [450/625]  eta: 0:00:38  Loss: 0.1014 (0.3127)  Acc@1: 100.0000 (90.8814)  Acc@5: 100.0000 (99.5704)  time: 0.2199  data: 0.0006  max mem: 2500
Test: [Task 2]  [460/625]  eta: 0:00:36  Loss: 0.1244 (0.3088)  Acc@1: 100.0000 (91.0385)  Acc@5: 100.0000 (99.5797)  time: 0.2200  data: 0.0006  max mem: 2500
Test: [Task 2]  [470/625]  eta: 0:00:34  Loss: 0.1525 (0.3061)  Acc@1: 100.0000 (91.1226)  Acc@5: 100.0000 (99.5886)  time: 0.2198  data: 0.0004  max mem: 2500
Test: [Task 2]  [480/625]  eta: 0:00:31  Loss: 0.1890 (0.3049)  Acc@1: 93.7500 (91.1642)  Acc@5: 100.0000 (99.5972)  time: 0.2198  data: 0.0004  max mem: 2500
Test: [Task 2]  [490/625]  eta: 0:00:29  Loss: 0.1989 (0.3028)  Acc@1: 93.7500 (91.2424)  Acc@5: 100.0000 (99.6054)  time: 0.2202  data: 0.0006  max mem: 2500
Test: [Task 2]  [500/625]  eta: 0:00:27  Loss: 0.1556 (0.3002)  Acc@1: 93.7500 (91.3298)  Acc@5: 100.0000 (99.6133)  time: 0.2201  data: 0.0006  max mem: 2500
Test: [Task 2]  [510/625]  eta: 0:00:25  Loss: 0.1810 (0.3035)  Acc@1: 93.7500 (91.3038)  Acc@5: 100.0000 (99.6086)  time: 0.2197  data: 0.0004  max mem: 2500
Test: [Task 2]  [520/625]  eta: 0:00:23  Loss: 0.2025 (0.3028)  Acc@1: 93.7500 (91.3628)  Acc@5: 100.0000 (99.6161)  time: 0.2203  data: 0.0004  max mem: 2500
Test: [Task 2]  [530/625]  eta: 0:00:20  Loss: 0.1664 (0.3003)  Acc@1: 93.7500 (91.4430)  Acc@5: 100.0000 (99.6234)  time: 0.2202  data: 0.0004  max mem: 2500
Test: [Task 2]  [540/625]  eta: 0:00:18  Loss: 0.1250 (0.2982)  Acc@1: 100.0000 (91.5088)  Acc@5: 100.0000 (99.6303)  time: 0.2200  data: 0.0004  max mem: 2500
Test: [Task 2]  [550/625]  eta: 0:00:16  Loss: 0.0863 (0.2943)  Acc@1: 100.0000 (91.6515)  Acc@5: 100.0000 (99.6370)  time: 0.2196  data: 0.0004  max mem: 2500
Test: [Task 2]  [560/625]  eta: 0:00:14  Loss: 0.0699 (0.2904)  Acc@1: 100.0000 (91.8004)  Acc@5: 100.0000 (99.6435)  time: 0.2194  data: 0.0004  max mem: 2500
Test: [Task 2]  [570/625]  eta: 0:00:12  Loss: 0.0888 (0.2892)  Acc@1: 100.0000 (91.8345)  Acc@5: 100.0000 (99.6497)  time: 0.2207  data: 0.0011  max mem: 2500
Test: [Task 2]  [580/625]  eta: 0:00:09  Loss: 0.1174 (0.2862)  Acc@1: 93.7500 (91.9428)  Acc@5: 100.0000 (99.6558)  time: 0.2210  data: 0.0010  max mem: 2500
Test: [Task 2]  [590/625]  eta: 0:00:07  Loss: 0.1174 (0.2841)  Acc@1: 100.0000 (92.0262)  Acc@5: 100.0000 (99.6616)  time: 0.2204  data: 0.0007  max mem: 2500
Test: [Task 2]  [600/625]  eta: 0:00:05  Loss: 0.2029 (0.2835)  Acc@1: 93.7500 (92.0757)  Acc@5: 100.0000 (99.6568)  time: 0.2208  data: 0.0007  max mem: 2500
Test: [Task 2]  [610/625]  eta: 0:00:03  Loss: 0.2906 (0.2857)  Acc@1: 93.7500 (92.0622)  Acc@5: 100.0000 (99.6420)  time: 0.2210  data: 0.0004  max mem: 2500
Test: [Task 2]  [620/625]  eta: 0:00:01  Loss: 0.3512 (0.2867)  Acc@1: 87.5000 (92.0290)  Acc@5: 100.0000 (99.6477)  time: 0.2207  data: 0.0005  max mem: 2500
Test: [Task 2]  [624/625]  eta: 0:00:00  Loss: 0.3044 (0.2864)  Acc@1: 93.7500 (92.0300)  Acc@5: 100.0000 (99.6500)  time: 0.2204  data: 0.0005  max mem: 2500
Test: [Task 2] Total time: 0:02:17 (0.2208 s / it)
* Acc@1 92.030 Acc@5 99.650 loss 0.286
{0: {0: 80, 1: 0, 2: 495, 3: 0, 4: 24471, 5: 25064, 6: 0, 7: 869, 8: 0, 9: 0, 10: 0, 11: 537, 12: 0, 13: 25576, 14: 0, 15: 25592, 16: 0, 17: 0, 18: 99, 19: 1345}, 1: {0: 8693, 1: 0, 2: 10000, 3: 0, 4: 0, 5: 0, 6: 0, 7: 1315, 8: 0, 9: 0, 10: 0, 11: 10000, 12: 0, 13: 0, 14: 0, 15: 0, 16: 0, 17: 0, 18: 8686, 19: 1306}}
[Average accuracy till task2]	Acc@1: 84.4235	Acc@5: 97.7353	Loss: 0.6118	Forgetting: 9.6343	Backward: -9.6343
Train: Epoch[1/5]  [   0/3125]  eta: 0:41:44  Lr: 0.001875  Loss: 1.8576  Acc@1: 6.2500 (6.2500)  Acc@5: 50.0000 (50.0000)  time: 0.8016  data: 0.4420  max mem: 2500
Train: Epoch[1/5]  [  10/3125]  eta: 0:20:20  Lr: 0.001875  Loss: 1.7374  Acc@1: 18.7500 (21.0227)  Acc@5: 68.7500 (63.6364)  time: 0.3919  data: 0.0406  max mem: 2502
Train: Epoch[1/5]  [  20/3125]  eta: 0:19:16  Lr: 0.001875  Loss: 1.6920  Acc@1: 31.2500 (30.6548)  Acc@5: 68.7500 (69.3452)  time: 0.3509  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [  30/3125]  eta: 0:18:51  Lr: 0.001875  Loss: 1.5262  Acc@1: 50.0000 (36.8952)  Acc@5: 75.0000 (72.9839)  time: 0.3511  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [  40/3125]  eta: 0:18:35  Lr: 0.001875  Loss: 1.2095  Acc@1: 50.0000 (42.5305)  Acc@5: 81.2500 (76.5244)  time: 0.3500  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [  50/3125]  eta: 0:18:24  Lr: 0.001875  Loss: 1.0162  Acc@1: 56.2500 (46.0784)  Acc@5: 87.5000 (79.4118)  time: 0.3490  data: 0.0006  max mem: 2502
Train: Epoch[1/5]  [  60/3125]  eta: 0:18:15  Lr: 0.001875  Loss: 0.8517  Acc@1: 62.5000 (49.5902)  Acc@5: 93.7500 (81.6598)  time: 0.3492  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [  70/3125]  eta: 0:18:08  Lr: 0.001875  Loss: 0.7501  Acc@1: 68.7500 (52.1127)  Acc@5: 93.7500 (83.1866)  time: 0.3494  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [  80/3125]  eta: 0:18:02  Lr: 0.001875  Loss: 0.9062  Acc@1: 68.7500 (54.1667)  Acc@5: 93.7500 (84.4136)  time: 0.3494  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [  90/3125]  eta: 0:17:56  Lr: 0.001875  Loss: 0.4807  Acc@1: 68.7500 (56.1126)  Acc@5: 93.7500 (85.7143)  time: 0.3489  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [ 100/3125]  eta: 0:17:51  Lr: 0.001875  Loss: 0.6233  Acc@1: 68.7500 (56.8069)  Acc@5: 93.7500 (86.4480)  time: 0.3497  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [ 110/3125]  eta: 0:17:46  Lr: 0.001875  Loss: 0.2882  Acc@1: 68.7500 (57.8266)  Acc@5: 93.7500 (87.3874)  time: 0.3500  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [ 120/3125]  eta: 0:17:42  Lr: 0.001875  Loss: 0.2203  Acc@1: 75.0000 (59.5041)  Acc@5: 100.0000 (88.3264)  time: 0.3508  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [ 130/3125]  eta: 0:17:38  Lr: 0.001875  Loss: 0.0722  Acc@1: 75.0000 (60.5439)  Acc@5: 100.0000 (88.9790)  time: 0.3509  data: 0.0006  max mem: 2502
Train: Epoch[1/5]  [ 140/3125]  eta: 0:17:34  Lr: 0.001875  Loss: 0.0512  Acc@1: 75.0000 (61.8794)  Acc@5: 100.0000 (89.5390)  time: 0.3497  data: 0.0006  max mem: 2502
Train: Epoch[1/5]  [ 150/3125]  eta: 0:17:30  Lr: 0.001875  Loss: 0.3145  Acc@1: 75.0000 (62.8311)  Acc@5: 100.0000 (90.0248)  time: 0.3510  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [ 160/3125]  eta: 0:17:26  Lr: 0.001875  Loss: 0.1242  Acc@1: 75.0000 (63.6646)  Acc@5: 100.0000 (90.4503)  time: 0.3513  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [ 170/3125]  eta: 0:17:22  Lr: 0.001875  Loss: 0.2763  Acc@1: 75.0000 (64.0351)  Acc@5: 100.0000 (90.8260)  time: 0.3504  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [ 180/3125]  eta: 0:17:18  Lr: 0.001875  Loss: 0.2144  Acc@1: 68.7500 (64.3992)  Acc@5: 93.7500 (91.0566)  time: 0.3506  data: 0.0009  max mem: 2502
Train: Epoch[1/5]  [ 190/3125]  eta: 0:17:14  Lr: 0.001875  Loss: 0.7242  Acc@1: 75.0000 (65.0851)  Acc@5: 100.0000 (91.3940)  time: 0.3505  data: 0.0008  max mem: 2502
Train: Epoch[1/5]  [ 200/3125]  eta: 0:17:10  Lr: 0.001875  Loss: 0.0064  Acc@1: 75.0000 (65.3918)  Acc@5: 100.0000 (91.6356)  time: 0.3498  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [ 210/3125]  eta: 0:17:07  Lr: 0.001875  Loss: 0.2279  Acc@1: 68.7500 (65.9064)  Acc@5: 93.7500 (91.8543)  time: 0.3509  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [ 220/3125]  eta: 0:17:03  Lr: 0.001875  Loss: -0.0769  Acc@1: 75.0000 (66.4876)  Acc@5: 93.7500 (92.0532)  time: 0.3511  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [ 230/3125]  eta: 0:16:59  Lr: 0.001875  Loss: -0.1613  Acc@1: 75.0000 (67.0725)  Acc@5: 100.0000 (92.2890)  time: 0.3511  data: 0.0011  max mem: 2502
Train: Epoch[1/5]  [ 240/3125]  eta: 0:16:56  Lr: 0.001875  Loss: -0.3818  Acc@1: 75.0000 (67.6867)  Acc@5: 100.0000 (92.4533)  time: 0.3528  data: 0.0013  max mem: 2502
Train: Epoch[1/5]  [ 250/3125]  eta: 0:16:52  Lr: 0.001875  Loss: -0.1267  Acc@1: 81.2500 (68.1773)  Acc@5: 100.0000 (92.6793)  time: 0.3521  data: 0.0008  max mem: 2502
Train: Epoch[1/5]  [ 260/3125]  eta: 0:16:49  Lr: 0.001875  Loss: -0.1810  Acc@1: 81.2500 (68.4626)  Acc@5: 100.0000 (92.8400)  time: 0.3505  data: 0.0007  max mem: 2502
Train: Epoch[1/5]  [ 270/3125]  eta: 0:16:45  Lr: 0.001875  Loss: -0.4592  Acc@1: 81.2500 (68.9345)  Acc@5: 100.0000 (92.9889)  time: 0.3501  data: 0.0006  max mem: 2502
Train: Epoch[1/5]  [ 280/3125]  eta: 0:16:41  Lr: 0.001875  Loss: 0.0380  Acc@1: 81.2500 (69.3728)  Acc@5: 100.0000 (93.0605)  time: 0.3504  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [ 290/3125]  eta: 0:16:37  Lr: 0.001875  Loss: 0.2715  Acc@1: 81.2500 (69.5447)  Acc@5: 100.0000 (93.2131)  time: 0.3504  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [ 300/3125]  eta: 0:16:34  Lr: 0.001875  Loss: -0.2825  Acc@1: 75.0000 (69.8297)  Acc@5: 100.0000 (93.3140)  time: 0.3492  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [ 310/3125]  eta: 0:16:30  Lr: 0.001875  Loss: -0.4450  Acc@1: 81.2500 (70.1768)  Acc@5: 100.0000 (93.4486)  time: 0.3493  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [ 320/3125]  eta: 0:16:26  Lr: 0.001875  Loss: 0.0564  Acc@1: 75.0000 (70.3855)  Acc@5: 100.0000 (93.5164)  time: 0.3499  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [ 330/3125]  eta: 0:16:22  Lr: 0.001875  Loss: -0.1142  Acc@1: 75.0000 (70.6193)  Acc@5: 100.0000 (93.6367)  time: 0.3499  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [ 340/3125]  eta: 0:16:19  Lr: 0.001875  Loss: -0.3131  Acc@1: 75.0000 (70.7295)  Acc@5: 100.0000 (93.7133)  time: 0.3503  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [ 350/3125]  eta: 0:16:15  Lr: 0.001875  Loss: -0.4287  Acc@1: 75.0000 (70.9402)  Acc@5: 100.0000 (93.8568)  time: 0.3502  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [ 360/3125]  eta: 0:16:11  Lr: 0.001875  Loss: -0.3587  Acc@1: 75.0000 (71.1738)  Acc@5: 100.0000 (93.9578)  time: 0.3490  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [ 370/3125]  eta: 0:16:08  Lr: 0.001875  Loss: -0.4903  Acc@1: 81.2500 (71.4454)  Acc@5: 100.0000 (94.0701)  time: 0.3488  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [ 380/3125]  eta: 0:16:04  Lr: 0.001875  Loss: -0.4508  Acc@1: 81.2500 (71.5879)  Acc@5: 100.0000 (94.1437)  time: 0.3492  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [ 390/3125]  eta: 0:16:00  Lr: 0.001875  Loss: -0.2867  Acc@1: 75.0000 (71.7551)  Acc@5: 100.0000 (94.2455)  time: 0.3498  data: 0.0008  max mem: 2502
Train: Epoch[1/5]  [ 400/3125]  eta: 0:15:57  Lr: 0.001875  Loss: -0.1665  Acc@1: 75.0000 (71.9451)  Acc@5: 100.0000 (94.3423)  time: 0.3503  data: 0.0008  max mem: 2502
Train: Epoch[1/5]  [ 410/3125]  eta: 0:15:53  Lr: 0.001875  Loss: 0.0150  Acc@1: 81.2500 (72.1867)  Acc@5: 100.0000 (94.4191)  time: 0.3493  data: 0.0006  max mem: 2502
Train: Epoch[1/5]  [ 420/3125]  eta: 0:15:50  Lr: 0.001875  Loss: 0.2285  Acc@1: 87.5000 (72.4466)  Acc@5: 100.0000 (94.4923)  time: 0.3489  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [ 430/3125]  eta: 0:15:46  Lr: 0.001875  Loss: 0.0469  Acc@1: 81.2500 (72.6653)  Acc@5: 100.0000 (94.5476)  time: 0.3485  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [ 440/3125]  eta: 0:15:42  Lr: 0.001875  Loss: -0.4351  Acc@1: 81.2500 (72.8741)  Acc@5: 100.0000 (94.6287)  time: 0.3479  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [ 450/3125]  eta: 0:15:39  Lr: 0.001875  Loss: -0.1843  Acc@1: 81.2500 (73.0183)  Acc@5: 100.0000 (94.6508)  time: 0.3488  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [ 460/3125]  eta: 0:15:35  Lr: 0.001875  Loss: -0.1284  Acc@1: 75.0000 (73.0884)  Acc@5: 93.7500 (94.6855)  time: 0.3496  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [ 470/3125]  eta: 0:15:31  Lr: 0.001875  Loss: -0.6015  Acc@1: 81.2500 (73.3413)  Acc@5: 100.0000 (94.7718)  time: 0.3501  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [ 480/3125]  eta: 0:15:28  Lr: 0.001875  Loss: -0.4718  Acc@1: 81.2500 (73.4407)  Acc@5: 100.0000 (94.7895)  time: 0.3493  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [ 490/3125]  eta: 0:15:24  Lr: 0.001875  Loss: -0.6772  Acc@1: 81.2500 (73.6634)  Acc@5: 100.0000 (94.8574)  time: 0.3497  data: 0.0014  max mem: 2502
Train: Epoch[1/5]  [ 500/3125]  eta: 0:15:21  Lr: 0.001875  Loss: -0.6242  Acc@1: 81.2500 (73.8024)  Acc@5: 100.0000 (94.9227)  time: 0.3491  data: 0.0015  max mem: 2502
Train: Epoch[1/5]  [ 510/3125]  eta: 0:15:17  Lr: 0.001875  Loss: -0.4594  Acc@1: 81.2500 (73.9237)  Acc@5: 100.0000 (94.9486)  time: 0.3482  data: 0.0006  max mem: 2502
Train: Epoch[1/5]  [ 520/3125]  eta: 0:15:13  Lr: 0.001875  Loss: -0.5525  Acc@1: 81.2500 (74.1003)  Acc@5: 100.0000 (95.0336)  time: 0.3500  data: 0.0006  max mem: 2502
Train: Epoch[1/5]  [ 530/3125]  eta: 0:15:10  Lr: 0.001875  Loss: -0.5273  Acc@1: 81.2500 (74.2232)  Acc@5: 100.0000 (95.0683)  time: 0.3501  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [ 540/3125]  eta: 0:15:06  Lr: 0.001875  Loss: -0.5177  Acc@1: 81.2500 (74.4108)  Acc@5: 100.0000 (95.1363)  time: 0.3495  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [ 550/3125]  eta: 0:15:03  Lr: 0.001875  Loss: -0.6099  Acc@1: 81.2500 (74.5123)  Acc@5: 100.0000 (95.1792)  time: 0.3492  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [ 560/3125]  eta: 0:14:59  Lr: 0.001875  Loss: -0.3224  Acc@1: 81.2500 (74.6212)  Acc@5: 100.0000 (95.2540)  time: 0.3487  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [ 570/3125]  eta: 0:14:55  Lr: 0.001875  Loss: -0.7784  Acc@1: 81.2500 (74.7482)  Acc@5: 100.0000 (95.3262)  time: 0.3488  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [ 580/3125]  eta: 0:14:52  Lr: 0.001875  Loss: -0.4523  Acc@1: 81.2500 (74.8279)  Acc@5: 100.0000 (95.3313)  time: 0.3488  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [ 590/3125]  eta: 0:14:48  Lr: 0.001875  Loss: -0.4944  Acc@1: 81.2500 (74.9260)  Acc@5: 100.0000 (95.3997)  time: 0.3489  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [ 600/3125]  eta: 0:14:45  Lr: 0.001875  Loss: -0.4674  Acc@1: 81.2500 (75.0312)  Acc@5: 100.0000 (95.4347)  time: 0.3495  data: 0.0007  max mem: 2502
Train: Epoch[1/5]  [ 610/3125]  eta: 0:14:41  Lr: 0.001875  Loss: -0.6528  Acc@1: 81.2500 (75.1227)  Acc@5: 100.0000 (95.4890)  time: 0.3497  data: 0.0007  max mem: 2502
Train: Epoch[1/5]  [ 620/3125]  eta: 0:14:38  Lr: 0.001875  Loss: -0.4898  Acc@1: 81.2500 (75.2516)  Acc@5: 100.0000 (95.5314)  time: 0.3498  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [ 630/3125]  eta: 0:14:34  Lr: 0.001875  Loss: -0.0834  Acc@1: 81.2500 (75.3863)  Acc@5: 100.0000 (95.5527)  time: 0.3496  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [ 640/3125]  eta: 0:14:31  Lr: 0.001875  Loss: -0.7717  Acc@1: 81.2500 (75.4778)  Acc@5: 100.0000 (95.5733)  time: 0.3510  data: 0.0014  max mem: 2502
Train: Epoch[1/5]  [ 650/3125]  eta: 0:14:27  Lr: 0.001875  Loss: -0.5428  Acc@1: 81.2500 (75.5760)  Acc@5: 100.0000 (95.6125)  time: 0.3529  data: 0.0014  max mem: 2502
Train: Epoch[1/5]  [ 660/3125]  eta: 0:14:24  Lr: 0.001875  Loss: -0.3529  Acc@1: 75.0000 (75.6051)  Acc@5: 100.0000 (95.6411)  time: 0.3517  data: 0.0006  max mem: 2502
Train: Epoch[1/5]  [ 670/3125]  eta: 0:14:20  Lr: 0.001875  Loss: -0.3226  Acc@1: 75.0000 (75.6334)  Acc@5: 100.0000 (95.6874)  time: 0.3499  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [ 680/3125]  eta: 0:14:17  Lr: 0.001875  Loss: -0.6336  Acc@1: 81.2500 (75.7434)  Acc@5: 100.0000 (95.7232)  time: 0.3505  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [ 690/3125]  eta: 0:14:13  Lr: 0.001875  Loss: -0.2056  Acc@1: 81.2500 (75.7507)  Acc@5: 100.0000 (95.7218)  time: 0.3512  data: 0.0012  max mem: 2502
Train: Epoch[1/5]  [ 700/3125]  eta: 0:14:10  Lr: 0.001875  Loss: -0.1645  Acc@1: 75.0000 (75.7578)  Acc@5: 100.0000 (95.7471)  time: 0.3506  data: 0.0012  max mem: 2502
Train: Epoch[1/5]  [ 710/3125]  eta: 0:14:06  Lr: 0.001875  Loss: -0.2734  Acc@1: 75.0000 (75.7823)  Acc@5: 100.0000 (95.7718)  time: 0.3517  data: 0.0012  max mem: 2502
Train: Epoch[1/5]  [ 720/3125]  eta: 0:14:03  Lr: 0.001875  Loss: -0.2471  Acc@1: 75.0000 (75.8148)  Acc@5: 100.0000 (95.7958)  time: 0.3533  data: 0.0013  max mem: 2502
Train: Epoch[1/5]  [ 730/3125]  eta: 0:13:59  Lr: 0.001875  Loss: -0.5666  Acc@1: 81.2500 (75.8892)  Acc@5: 100.0000 (95.8447)  time: 0.3525  data: 0.0006  max mem: 2502
Train: Epoch[1/5]  [ 740/3125]  eta: 0:13:56  Lr: 0.001875  Loss: -0.7274  Acc@1: 81.2500 (75.9278)  Acc@5: 100.0000 (95.8755)  time: 0.3510  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [ 750/3125]  eta: 0:13:52  Lr: 0.001875  Loss: -0.5005  Acc@1: 87.5000 (76.1069)  Acc@5: 100.0000 (95.9304)  time: 0.3507  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [ 760/3125]  eta: 0:13:49  Lr: 0.001875  Loss: -0.5242  Acc@1: 81.2500 (76.1334)  Acc@5: 100.0000 (95.9428)  time: 0.3509  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [ 770/3125]  eta: 0:13:45  Lr: 0.001875  Loss: -0.6454  Acc@1: 81.2500 (76.2970)  Acc@5: 100.0000 (95.9955)  time: 0.3502  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [ 780/3125]  eta: 0:13:42  Lr: 0.001875  Loss: -0.5613  Acc@1: 87.5000 (76.3204)  Acc@5: 100.0000 (96.0227)  time: 0.3494  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [ 790/3125]  eta: 0:13:38  Lr: 0.001875  Loss: -0.3434  Acc@1: 75.0000 (76.3511)  Acc@5: 100.0000 (96.0098)  time: 0.3493  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [ 800/3125]  eta: 0:13:35  Lr: 0.001875  Loss: -0.6189  Acc@1: 81.2500 (76.4357)  Acc@5: 100.0000 (96.0284)  time: 0.3491  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [ 810/3125]  eta: 0:13:31  Lr: 0.001875  Loss: -0.3182  Acc@1: 81.2500 (76.5259)  Acc@5: 100.0000 (96.0543)  time: 0.3495  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [ 820/3125]  eta: 0:13:28  Lr: 0.001875  Loss: -0.7159  Acc@1: 81.2500 (76.5606)  Acc@5: 100.0000 (96.0566)  time: 0.3493  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [ 830/3125]  eta: 0:13:24  Lr: 0.001875  Loss: -0.5042  Acc@1: 81.2500 (76.6170)  Acc@5: 100.0000 (96.0590)  time: 0.3497  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [ 840/3125]  eta: 0:13:21  Lr: 0.001875  Loss: -0.5500  Acc@1: 81.2500 (76.6870)  Acc@5: 100.0000 (96.0612)  time: 0.3492  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [ 850/3125]  eta: 0:13:17  Lr: 0.001875  Loss: -0.1983  Acc@1: 81.2500 (76.7847)  Acc@5: 100.0000 (96.0855)  time: 0.3481  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [ 860/3125]  eta: 0:13:13  Lr: 0.001875  Loss: 0.0710  Acc@1: 87.5000 (76.8510)  Acc@5: 100.0000 (96.0729)  time: 0.3477  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [ 870/3125]  eta: 0:13:10  Lr: 0.001875  Loss: -0.4354  Acc@1: 87.5000 (76.9231)  Acc@5: 100.0000 (96.1108)  time: 0.3469  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [ 880/3125]  eta: 0:13:06  Lr: 0.001875  Loss: -0.5307  Acc@1: 81.2500 (76.9651)  Acc@5: 100.0000 (96.1266)  time: 0.3472  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [ 890/3125]  eta: 0:13:03  Lr: 0.001875  Loss: -0.5446  Acc@1: 87.5000 (77.0693)  Acc@5: 100.0000 (96.1420)  time: 0.3484  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [ 900/3125]  eta: 0:12:59  Lr: 0.001875  Loss: -0.6637  Acc@1: 87.5000 (77.1712)  Acc@5: 100.0000 (96.1640)  time: 0.3485  data: 0.0009  max mem: 2502
Train: Epoch[1/5]  [ 910/3125]  eta: 0:12:56  Lr: 0.001875  Loss: -0.4871  Acc@1: 87.5000 (77.2023)  Acc@5: 100.0000 (96.1992)  time: 0.3475  data: 0.0009  max mem: 2502
Train: Epoch[1/5]  [ 920/3125]  eta: 0:12:52  Lr: 0.001875  Loss: -0.4095  Acc@1: 81.2500 (77.2666)  Acc@5: 100.0000 (96.2337)  time: 0.3477  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [ 930/3125]  eta: 0:12:48  Lr: 0.001875  Loss: 0.2600  Acc@1: 81.2500 (77.2691)  Acc@5: 100.0000 (96.2473)  time: 0.3487  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [ 940/3125]  eta: 0:12:45  Lr: 0.001875  Loss: -0.1796  Acc@1: 81.2500 (77.3313)  Acc@5: 100.0000 (96.2540)  time: 0.3479  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [ 950/3125]  eta: 0:12:41  Lr: 0.001875  Loss: -0.1312  Acc@1: 81.2500 (77.3528)  Acc@5: 100.0000 (96.2605)  time: 0.3469  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [ 960/3125]  eta: 0:12:38  Lr: 0.001875  Loss: -0.6568  Acc@1: 81.2500 (77.3868)  Acc@5: 100.0000 (96.2669)  time: 0.3476  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [ 970/3125]  eta: 0:12:34  Lr: 0.001875  Loss: -0.2655  Acc@1: 81.2500 (77.4266)  Acc@5: 100.0000 (96.2860)  time: 0.3481  data: 0.0006  max mem: 2502
Train: Epoch[1/5]  [ 980/3125]  eta: 0:12:31  Lr: 0.001875  Loss: -0.0937  Acc@1: 81.2500 (77.4975)  Acc@5: 100.0000 (96.3112)  time: 0.3484  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [ 990/3125]  eta: 0:12:27  Lr: 0.001875  Loss: -0.3345  Acc@1: 81.2500 (77.5038)  Acc@5: 100.0000 (96.2979)  time: 0.3479  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [1000/3125]  eta: 0:12:24  Lr: 0.001875  Loss: -0.5589  Acc@1: 75.0000 (77.5350)  Acc@5: 100.0000 (96.3162)  time: 0.3473  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [1010/3125]  eta: 0:12:20  Lr: 0.001875  Loss: -0.6146  Acc@1: 81.2500 (77.6273)  Acc@5: 100.0000 (96.3279)  time: 0.3477  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [1020/3125]  eta: 0:12:16  Lr: 0.001875  Loss: -0.3979  Acc@1: 87.5000 (77.7057)  Acc@5: 100.0000 (96.3455)  time: 0.3482  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [1030/3125]  eta: 0:12:13  Lr: 0.001875  Loss: -0.6732  Acc@1: 87.5000 (77.8067)  Acc@5: 100.0000 (96.3688)  time: 0.3480  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [1040/3125]  eta: 0:12:09  Lr: 0.001875  Loss: -0.1304  Acc@1: 87.5000 (77.8999)  Acc@5: 100.0000 (96.3737)  time: 0.3474  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [1050/3125]  eta: 0:12:06  Lr: 0.001875  Loss: -0.6422  Acc@1: 87.5000 (77.9198)  Acc@5: 100.0000 (96.3784)  time: 0.3480  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [1060/3125]  eta: 0:12:02  Lr: 0.001875  Loss: -0.7489  Acc@1: 81.2500 (77.9925)  Acc@5: 100.0000 (96.4008)  time: 0.3484  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [1070/3125]  eta: 0:11:59  Lr: 0.001875  Loss: -0.6882  Acc@1: 81.2500 (78.0345)  Acc@5: 100.0000 (96.4286)  time: 0.3487  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [1080/3125]  eta: 0:11:55  Lr: 0.001875  Loss: -0.5575  Acc@1: 81.2500 (78.0759)  Acc@5: 100.0000 (96.4558)  time: 0.3488  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [1090/3125]  eta: 0:11:52  Lr: 0.001875  Loss: -0.4048  Acc@1: 81.2500 (78.1279)  Acc@5: 100.0000 (96.4826)  time: 0.3484  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [1100/3125]  eta: 0:11:48  Lr: 0.001875  Loss: -0.4306  Acc@1: 75.0000 (78.1051)  Acc@5: 100.0000 (96.4918)  time: 0.3482  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [1110/3125]  eta: 0:11:45  Lr: 0.001875  Loss: -0.2349  Acc@1: 75.0000 (78.1447)  Acc@5: 100.0000 (96.5009)  time: 0.3480  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [1120/3125]  eta: 0:11:41  Lr: 0.001875  Loss: -0.6462  Acc@1: 81.2500 (78.1668)  Acc@5: 100.0000 (96.5265)  time: 0.3487  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [1130/3125]  eta: 0:11:38  Lr: 0.001875  Loss: -0.0096  Acc@1: 81.2500 (78.1720)  Acc@5: 100.0000 (96.5351)  time: 0.3487  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [1140/3125]  eta: 0:11:34  Lr: 0.001875  Loss: 0.0094  Acc@1: 81.2500 (78.1880)  Acc@5: 100.0000 (96.5546)  time: 0.3490  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [1150/3125]  eta: 0:11:31  Lr: 0.001875  Loss: -0.3373  Acc@1: 81.2500 (78.2255)  Acc@5: 100.0000 (96.5845)  time: 0.3489  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [1160/3125]  eta: 0:11:27  Lr: 0.001875  Loss: -0.3795  Acc@1: 81.2500 (78.2892)  Acc@5: 100.0000 (96.6031)  time: 0.3488  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [1170/3125]  eta: 0:11:24  Lr: 0.001875  Loss: -0.3563  Acc@1: 81.2500 (78.2931)  Acc@5: 100.0000 (96.6001)  time: 0.3493  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [1180/3125]  eta: 0:11:20  Lr: 0.001875  Loss: -0.7094  Acc@1: 81.2500 (78.3340)  Acc@5: 100.0000 (96.6077)  time: 0.3490  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [1190/3125]  eta: 0:11:17  Lr: 0.001875  Loss: -0.5362  Acc@1: 81.2500 (78.3638)  Acc@5: 100.0000 (96.6205)  time: 0.3496  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [1200/3125]  eta: 0:11:13  Lr: 0.001875  Loss: -0.5455  Acc@1: 81.2500 (78.4242)  Acc@5: 100.0000 (96.6278)  time: 0.3499  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [1210/3125]  eta: 0:11:10  Lr: 0.001875  Loss: -0.6560  Acc@1: 87.5000 (78.4992)  Acc@5: 100.0000 (96.6453)  time: 0.3497  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [1220/3125]  eta: 0:11:06  Lr: 0.001875  Loss: -0.8045  Acc@1: 87.5000 (78.5831)  Acc@5: 100.0000 (96.6677)  time: 0.3493  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [1230/3125]  eta: 0:11:02  Lr: 0.001875  Loss: -0.7832  Acc@1: 87.5000 (78.6302)  Acc@5: 100.0000 (96.6795)  time: 0.3493  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [1240/3125]  eta: 0:10:59  Lr: 0.001875  Loss: -0.5557  Acc@1: 81.2500 (78.6563)  Acc@5: 100.0000 (96.7012)  time: 0.3502  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [1250/3125]  eta: 0:10:56  Lr: 0.001875  Loss: 0.0320  Acc@1: 81.2500 (78.6771)  Acc@5: 100.0000 (96.6976)  time: 0.3506  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [1260/3125]  eta: 0:10:52  Lr: 0.001875  Loss: -0.7124  Acc@1: 75.0000 (78.6826)  Acc@5: 100.0000 (96.6990)  time: 0.3507  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [1270/3125]  eta: 0:10:49  Lr: 0.001875  Loss: 0.2214  Acc@1: 75.0000 (78.6782)  Acc@5: 100.0000 (96.7054)  time: 0.3504  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [1280/3125]  eta: 0:10:45  Lr: 0.001875  Loss: -0.4010  Acc@1: 75.0000 (78.6593)  Acc@5: 100.0000 (96.7067)  time: 0.3496  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [1290/3125]  eta: 0:10:42  Lr: 0.001875  Loss: -0.6636  Acc@1: 75.0000 (78.6600)  Acc@5: 100.0000 (96.7177)  time: 0.3496  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [1300/3125]  eta: 0:10:38  Lr: 0.001875  Loss: -0.5193  Acc@1: 81.2500 (78.6895)  Acc@5: 100.0000 (96.7333)  time: 0.3498  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [1310/3125]  eta: 0:10:35  Lr: 0.001875  Loss: -0.2440  Acc@1: 81.2500 (78.7042)  Acc@5: 100.0000 (96.7296)  time: 0.3494  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [1320/3125]  eta: 0:10:31  Lr: 0.001875  Loss: -0.5030  Acc@1: 81.2500 (78.6998)  Acc@5: 100.0000 (96.7449)  time: 0.3497  data: 0.0012  max mem: 2502
Train: Epoch[1/5]  [1330/3125]  eta: 0:10:28  Lr: 0.001875  Loss: -0.2174  Acc@1: 81.2500 (78.7284)  Acc@5: 100.0000 (96.7224)  time: 0.3498  data: 0.0012  max mem: 2502
Train: Epoch[1/5]  [1340/3125]  eta: 0:10:24  Lr: 0.001875  Loss: -0.3905  Acc@1: 81.2500 (78.7192)  Acc@5: 93.7500 (96.7189)  time: 0.3492  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [1350/3125]  eta: 0:10:21  Lr: 0.001875  Loss: -0.7906  Acc@1: 81.2500 (78.7426)  Acc@5: 100.0000 (96.7293)  time: 0.3496  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [1360/3125]  eta: 0:10:17  Lr: 0.001875  Loss: -0.3512  Acc@1: 81.2500 (78.7518)  Acc@5: 100.0000 (96.7212)  time: 0.3498  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [1370/3125]  eta: 0:10:14  Lr: 0.001875  Loss: -0.5849  Acc@1: 81.2500 (78.7883)  Acc@5: 100.0000 (96.7451)  time: 0.3495  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [1380/3125]  eta: 0:10:10  Lr: 0.001875  Loss: -0.4246  Acc@1: 87.5000 (78.8106)  Acc@5: 100.0000 (96.7460)  time: 0.3502  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [1390/3125]  eta: 0:10:07  Lr: 0.001875  Loss: -0.6233  Acc@1: 87.5000 (78.8372)  Acc@5: 100.0000 (96.7469)  time: 0.3505  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [1400/3125]  eta: 0:10:03  Lr: 0.001875  Loss: -0.8863  Acc@1: 81.2500 (78.8321)  Acc@5: 100.0000 (96.7568)  time: 0.3500  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [1410/3125]  eta: 0:10:00  Lr: 0.001875  Loss: -0.5928  Acc@1: 81.2500 (78.8625)  Acc@5: 100.0000 (96.7709)  time: 0.3507  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [1420/3125]  eta: 0:09:56  Lr: 0.001875  Loss: -0.6526  Acc@1: 81.2500 (78.8881)  Acc@5: 100.0000 (96.7804)  time: 0.3496  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [1430/3125]  eta: 0:09:53  Lr: 0.001875  Loss: -0.3780  Acc@1: 81.2500 (78.9046)  Acc@5: 100.0000 (96.7724)  time: 0.3488  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [1440/3125]  eta: 0:09:49  Lr: 0.001875  Loss: -0.7156  Acc@1: 75.0000 (78.8732)  Acc@5: 100.0000 (96.7861)  time: 0.3494  data: 0.0006  max mem: 2502
Train: Epoch[1/5]  [1450/3125]  eta: 0:09:46  Lr: 0.001875  Loss: -0.4283  Acc@1: 81.2500 (78.9111)  Acc@5: 100.0000 (96.7996)  time: 0.3497  data: 0.0007  max mem: 2502
Train: Epoch[1/5]  [1460/3125]  eta: 0:09:42  Lr: 0.001875  Loss: -0.5986  Acc@1: 81.2500 (78.9271)  Acc@5: 100.0000 (96.8001)  time: 0.3504  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [1470/3125]  eta: 0:09:39  Lr: 0.001875  Loss: -0.6334  Acc@1: 81.2500 (78.9344)  Acc@5: 100.0000 (96.8134)  time: 0.3506  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [1480/3125]  eta: 0:09:35  Lr: 0.001875  Loss: -0.3351  Acc@1: 75.0000 (78.9289)  Acc@5: 100.0000 (96.8222)  time: 0.3518  data: 0.0009  max mem: 2502
Train: Epoch[1/5]  [1490/3125]  eta: 0:09:32  Lr: 0.001875  Loss: -0.8866  Acc@1: 75.0000 (78.9571)  Acc@5: 100.0000 (96.8394)  time: 0.3518  data: 0.0009  max mem: 2502
Train: Epoch[1/5]  [1500/3125]  eta: 0:09:28  Lr: 0.001875  Loss: -0.5934  Acc@1: 81.2500 (78.9848)  Acc@5: 100.0000 (96.8271)  time: 0.3501  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [1510/3125]  eta: 0:09:25  Lr: 0.001875  Loss: -0.3215  Acc@1: 81.2500 (79.0081)  Acc@5: 100.0000 (96.8233)  time: 0.3506  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [1520/3125]  eta: 0:09:21  Lr: 0.001875  Loss: -0.6452  Acc@1: 81.2500 (78.9941)  Acc@5: 100.0000 (96.8236)  time: 0.3501  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [1530/3125]  eta: 0:09:18  Lr: 0.001875  Loss: -0.7496  Acc@1: 81.2500 (79.0333)  Acc@5: 100.0000 (96.8321)  time: 0.3496  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [1540/3125]  eta: 0:09:14  Lr: 0.001875  Loss: -0.2773  Acc@1: 81.2500 (79.0477)  Acc@5: 100.0000 (96.8446)  time: 0.3503  data: 0.0011  max mem: 2502
Train: Epoch[1/5]  [1550/3125]  eta: 0:09:11  Lr: 0.001875  Loss: -0.4767  Acc@1: 81.2500 (79.0820)  Acc@5: 100.0000 (96.8528)  time: 0.3495  data: 0.0011  max mem: 2502
Train: Epoch[1/5]  [1560/3125]  eta: 0:09:07  Lr: 0.001875  Loss: -0.1618  Acc@1: 81.2500 (79.0919)  Acc@5: 100.0000 (96.8730)  time: 0.3482  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [1570/3125]  eta: 0:09:04  Lr: 0.001875  Loss: -0.3911  Acc@1: 81.2500 (79.1017)  Acc@5: 100.0000 (96.8770)  time: 0.3487  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [1580/3125]  eta: 0:09:00  Lr: 0.001875  Loss: -0.6038  Acc@1: 81.2500 (79.1311)  Acc@5: 100.0000 (96.8849)  time: 0.3495  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [1590/3125]  eta: 0:08:57  Lr: 0.001875  Loss: -0.7527  Acc@1: 81.2500 (79.1287)  Acc@5: 100.0000 (96.8887)  time: 0.3487  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [1600/3125]  eta: 0:08:53  Lr: 0.001875  Loss: -0.0489  Acc@1: 81.2500 (79.1576)  Acc@5: 100.0000 (96.8926)  time: 0.3480  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [1610/3125]  eta: 0:08:50  Lr: 0.001875  Loss: -0.2273  Acc@1: 81.2500 (79.1744)  Acc@5: 100.0000 (96.9041)  time: 0.3491  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [1620/3125]  eta: 0:08:46  Lr: 0.001875  Loss: -0.2772  Acc@1: 75.0000 (79.1602)  Acc@5: 100.0000 (96.9155)  time: 0.3499  data: 0.0006  max mem: 2502
Train: Epoch[1/5]  [1630/3125]  eta: 0:08:43  Lr: 0.001875  Loss: -0.7964  Acc@1: 75.0000 (79.1845)  Acc@5: 100.0000 (96.9114)  time: 0.3486  data: 0.0006  max mem: 2502
Train: Epoch[1/5]  [1640/3125]  eta: 0:08:39  Lr: 0.001875  Loss: -0.2129  Acc@1: 87.5000 (79.2048)  Acc@5: 100.0000 (96.9188)  time: 0.3486  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [1650/3125]  eta: 0:08:36  Lr: 0.001875  Loss: -0.5900  Acc@1: 87.5000 (79.2285)  Acc@5: 100.0000 (96.9299)  time: 0.3501  data: 0.0012  max mem: 2502
Train: Epoch[1/5]  [1660/3125]  eta: 0:08:32  Lr: 0.001875  Loss: -0.4889  Acc@1: 87.5000 (79.2632)  Acc@5: 100.0000 (96.9333)  time: 0.3499  data: 0.0012  max mem: 2502
Train: Epoch[1/5]  [1670/3125]  eta: 0:08:29  Lr: 0.001875  Loss: -0.5782  Acc@1: 87.5000 (79.3163)  Acc@5: 100.0000 (96.9405)  time: 0.3491  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [1680/3125]  eta: 0:08:25  Lr: 0.001875  Loss: -0.1185  Acc@1: 81.2500 (79.3241)  Acc@5: 100.0000 (96.9475)  time: 0.3495  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [1690/3125]  eta: 0:08:22  Lr: 0.001875  Loss: -0.7011  Acc@1: 87.5000 (79.3724)  Acc@5: 100.0000 (96.9545)  time: 0.3490  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [1700/3125]  eta: 0:08:18  Lr: 0.001875  Loss: -0.6043  Acc@1: 87.5000 (79.3798)  Acc@5: 100.0000 (96.9650)  time: 0.3486  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [1710/3125]  eta: 0:08:14  Lr: 0.001875  Loss: -0.2344  Acc@1: 81.2500 (79.3871)  Acc@5: 100.0000 (96.9535)  time: 0.3488  data: 0.0006  max mem: 2502
Train: Epoch[1/5]  [1720/3125]  eta: 0:08:11  Lr: 0.001875  Loss: -0.3539  Acc@1: 81.2500 (79.4015)  Acc@5: 100.0000 (96.9640)  time: 0.3488  data: 0.0007  max mem: 2502
Train: Epoch[1/5]  [1730/3125]  eta: 0:08:07  Lr: 0.001875  Loss: -0.3038  Acc@1: 81.2500 (79.4302)  Acc@5: 100.0000 (96.9671)  time: 0.3495  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [1740/3125]  eta: 0:08:04  Lr: 0.001875  Loss: -0.8359  Acc@1: 81.2500 (79.4371)  Acc@5: 100.0000 (96.9773)  time: 0.3493  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [1750/3125]  eta: 0:08:00  Lr: 0.001875  Loss: -0.8896  Acc@1: 81.2500 (79.4617)  Acc@5: 100.0000 (96.9839)  time: 0.3495  data: 0.0014  max mem: 2502
Train: Epoch[1/5]  [1760/3125]  eta: 0:07:57  Lr: 0.001875  Loss: -0.6413  Acc@1: 81.2500 (79.4896)  Acc@5: 100.0000 (96.9939)  time: 0.3498  data: 0.0014  max mem: 2502
Train: Epoch[1/5]  [1770/3125]  eta: 0:07:53  Lr: 0.001875  Loss: -0.4980  Acc@1: 81.2500 (79.4819)  Acc@5: 100.0000 (97.0038)  time: 0.3494  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [1780/3125]  eta: 0:07:50  Lr: 0.001875  Loss: -0.2877  Acc@1: 81.2500 (79.4989)  Acc@5: 100.0000 (97.0101)  time: 0.3494  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [1790/3125]  eta: 0:07:46  Lr: 0.001875  Loss: -0.4180  Acc@1: 81.2500 (79.4947)  Acc@5: 100.0000 (97.0094)  time: 0.3491  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [1800/3125]  eta: 0:07:43  Lr: 0.001875  Loss: -0.5817  Acc@1: 81.2500 (79.5149)  Acc@5: 100.0000 (97.0190)  time: 0.3503  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [1810/3125]  eta: 0:07:40  Lr: 0.001875  Loss: -0.2790  Acc@1: 81.2500 (79.5106)  Acc@5: 100.0000 (97.0182)  time: 0.3512  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [1820/3125]  eta: 0:07:36  Lr: 0.001875  Loss: -0.4733  Acc@1: 75.0000 (79.4893)  Acc@5: 100.0000 (97.0277)  time: 0.3505  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [1830/3125]  eta: 0:07:33  Lr: 0.001875  Loss: -0.7579  Acc@1: 75.0000 (79.5057)  Acc@5: 100.0000 (97.0371)  time: 0.3509  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [1840/3125]  eta: 0:07:29  Lr: 0.001875  Loss: -0.5707  Acc@1: 81.2500 (79.5288)  Acc@5: 100.0000 (97.0363)  time: 0.3513  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [1850/3125]  eta: 0:07:26  Lr: 0.001875  Loss: -0.3600  Acc@1: 81.2500 (79.5347)  Acc@5: 100.0000 (97.0320)  time: 0.3519  data: 0.0008  max mem: 2502
Train: Epoch[1/5]  [1860/3125]  eta: 0:07:22  Lr: 0.001875  Loss: -0.3902  Acc@1: 81.2500 (79.5540)  Acc@5: 100.0000 (97.0379)  time: 0.3517  data: 0.0008  max mem: 2502
Train: Epoch[1/5]  [1870/3125]  eta: 0:07:19  Lr: 0.001875  Loss: -0.4205  Acc@1: 81.2500 (79.5363)  Acc@5: 100.0000 (97.0370)  time: 0.3511  data: 0.0012  max mem: 2502
Train: Epoch[1/5]  [1880/3125]  eta: 0:07:15  Lr: 0.001875  Loss: -0.3618  Acc@1: 75.0000 (79.5156)  Acc@5: 100.0000 (97.0428)  time: 0.3515  data: 0.0019  max mem: 2502
Train: Epoch[1/5]  [1890/3125]  eta: 0:07:12  Lr: 0.001875  Loss: -0.6032  Acc@1: 81.2500 (79.5479)  Acc@5: 100.0000 (97.0518)  time: 0.3507  data: 0.0011  max mem: 2502
Train: Epoch[1/5]  [1900/3125]  eta: 0:07:08  Lr: 0.001875  Loss: -0.7092  Acc@1: 87.5000 (79.5798)  Acc@5: 100.0000 (97.0509)  time: 0.3517  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [1910/3125]  eta: 0:07:05  Lr: 0.001875  Loss: -0.3876  Acc@1: 87.5000 (79.5918)  Acc@5: 100.0000 (97.0532)  time: 0.3521  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [1920/3125]  eta: 0:07:01  Lr: 0.001875  Loss: -0.0581  Acc@1: 81.2500 (79.6037)  Acc@5: 100.0000 (97.0653)  time: 0.3510  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [1930/3125]  eta: 0:06:58  Lr: 0.001875  Loss: 0.0371  Acc@1: 87.5000 (79.6381)  Acc@5: 100.0000 (97.0708)  time: 0.3510  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [1940/3125]  eta: 0:06:54  Lr: 0.001875  Loss: -0.4299  Acc@1: 87.5000 (79.6625)  Acc@5: 100.0000 (97.0730)  time: 0.3510  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [1950/3125]  eta: 0:06:51  Lr: 0.001875  Loss: -0.8620  Acc@1: 87.5000 (79.7059)  Acc@5: 100.0000 (97.0880)  time: 0.3497  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [1960/3125]  eta: 0:06:47  Lr: 0.001875  Loss: -0.3235  Acc@1: 81.2500 (79.7106)  Acc@5: 100.0000 (97.0997)  time: 0.3480  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [1970/3125]  eta: 0:06:44  Lr: 0.001875  Loss: -0.3520  Acc@1: 81.2500 (79.7089)  Acc@5: 100.0000 (97.0986)  time: 0.3484  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [1980/3125]  eta: 0:06:40  Lr: 0.001875  Loss: 0.0362  Acc@1: 81.2500 (79.7230)  Acc@5: 100.0000 (97.1100)  time: 0.3488  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [1990/3125]  eta: 0:06:37  Lr: 0.001875  Loss: -0.3722  Acc@1: 81.2500 (79.7464)  Acc@5: 100.0000 (97.1089)  time: 0.3487  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [2000/3125]  eta: 0:06:33  Lr: 0.001875  Loss: 0.2059  Acc@1: 81.2500 (79.7507)  Acc@5: 100.0000 (97.1077)  time: 0.3490  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [2010/3125]  eta: 0:06:30  Lr: 0.001875  Loss: -0.2581  Acc@1: 81.2500 (79.7551)  Acc@5: 93.7500 (97.1003)  time: 0.3489  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [2020/3125]  eta: 0:06:26  Lr: 0.001875  Loss: -0.5830  Acc@1: 81.2500 (79.7501)  Acc@5: 100.0000 (97.1054)  time: 0.3487  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [2030/3125]  eta: 0:06:23  Lr: 0.001875  Loss: -0.7462  Acc@1: 81.2500 (79.7606)  Acc@5: 100.0000 (97.1166)  time: 0.3496  data: 0.0012  max mem: 2502
Train: Epoch[1/5]  [2040/3125]  eta: 0:06:19  Lr: 0.001875  Loss: -0.2453  Acc@1: 81.2500 (79.7648)  Acc@5: 100.0000 (97.1246)  time: 0.3493  data: 0.0012  max mem: 2502
Train: Epoch[1/5]  [2050/3125]  eta: 0:06:16  Lr: 0.001875  Loss: -0.1862  Acc@1: 87.5000 (79.8025)  Acc@5: 100.0000 (97.1294)  time: 0.3482  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [2060/3125]  eta: 0:06:12  Lr: 0.001875  Loss: -0.3678  Acc@1: 87.5000 (79.8217)  Acc@5: 100.0000 (97.1252)  time: 0.3480  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [2070/3125]  eta: 0:06:09  Lr: 0.001875  Loss: -0.8545  Acc@1: 81.2500 (79.8316)  Acc@5: 93.7500 (97.1270)  time: 0.3485  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [2080/3125]  eta: 0:06:05  Lr: 0.001875  Loss: -0.7209  Acc@1: 81.2500 (79.8444)  Acc@5: 100.0000 (97.1348)  time: 0.3487  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [2090/3125]  eta: 0:06:02  Lr: 0.001875  Loss: -0.7835  Acc@1: 81.2500 (79.8601)  Acc@5: 100.0000 (97.1425)  time: 0.3483  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [2100/3125]  eta: 0:05:58  Lr: 0.001875  Loss: -0.3459  Acc@1: 81.2500 (79.8816)  Acc@5: 100.0000 (97.1442)  time: 0.3484  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [2110/3125]  eta: 0:05:55  Lr: 0.001875  Loss: -0.4541  Acc@1: 81.2500 (79.8940)  Acc@5: 100.0000 (97.1489)  time: 0.3479  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [2120/3125]  eta: 0:05:51  Lr: 0.001875  Loss: -0.6713  Acc@1: 81.2500 (79.9181)  Acc@5: 100.0000 (97.1505)  time: 0.3482  data: 0.0006  max mem: 2502
Train: Epoch[1/5]  [2130/3125]  eta: 0:05:48  Lr: 0.001875  Loss: -0.7422  Acc@1: 87.5000 (79.9419)  Acc@5: 100.0000 (97.1522)  time: 0.3486  data: 0.0006  max mem: 2502
Train: Epoch[1/5]  [2140/3125]  eta: 0:05:44  Lr: 0.001875  Loss: -0.4925  Acc@1: 87.5000 (79.9772)  Acc@5: 100.0000 (97.1538)  time: 0.3482  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [2150/3125]  eta: 0:05:41  Lr: 0.001875  Loss: -0.6097  Acc@1: 81.2500 (80.0122)  Acc@5: 100.0000 (97.1641)  time: 0.3484  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [2160/3125]  eta: 0:05:37  Lr: 0.001875  Loss: -0.8334  Acc@1: 87.5000 (80.0497)  Acc@5: 100.0000 (97.1772)  time: 0.3487  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [2170/3125]  eta: 0:05:34  Lr: 0.001875  Loss: -0.2327  Acc@1: 81.2500 (80.0553)  Acc@5: 100.0000 (97.1787)  time: 0.3490  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [2180/3125]  eta: 0:05:30  Lr: 0.001875  Loss: -0.3157  Acc@1: 81.2500 (80.0693)  Acc@5: 100.0000 (97.1802)  time: 0.3490  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [2190/3125]  eta: 0:05:27  Lr: 0.001875  Loss: -0.4789  Acc@1: 87.5000 (80.0890)  Acc@5: 100.0000 (97.1874)  time: 0.3483  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [2200/3125]  eta: 0:05:23  Lr: 0.001875  Loss: -0.4513  Acc@1: 81.2500 (80.0914)  Acc@5: 100.0000 (97.1859)  time: 0.3484  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [2210/3125]  eta: 0:05:20  Lr: 0.001875  Loss: -0.5142  Acc@1: 87.5000 (80.1249)  Acc@5: 100.0000 (97.1987)  time: 0.3490  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [2220/3125]  eta: 0:05:16  Lr: 0.001875  Loss: -0.4010  Acc@1: 87.5000 (80.1441)  Acc@5: 100.0000 (97.2000)  time: 0.3491  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [2230/3125]  eta: 0:05:13  Lr: 0.001875  Loss: -0.2927  Acc@1: 87.5000 (80.1827)  Acc@5: 100.0000 (97.2126)  time: 0.3490  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [2240/3125]  eta: 0:05:09  Lr: 0.001875  Loss: -0.7478  Acc@1: 87.5000 (80.1930)  Acc@5: 100.0000 (97.2139)  time: 0.3489  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [2250/3125]  eta: 0:05:06  Lr: 0.001875  Loss: -0.6088  Acc@1: 81.2500 (80.2116)  Acc@5: 100.0000 (97.2235)  time: 0.3490  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [2260/3125]  eta: 0:05:02  Lr: 0.001875  Loss: -0.4840  Acc@1: 87.5000 (80.2466)  Acc@5: 100.0000 (97.2274)  time: 0.3490  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [2270/3125]  eta: 0:04:59  Lr: 0.001875  Loss: -0.8583  Acc@1: 81.2500 (80.2317)  Acc@5: 100.0000 (97.2286)  time: 0.3492  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [2280/3125]  eta: 0:04:55  Lr: 0.001875  Loss: 0.1967  Acc@1: 81.2500 (80.2335)  Acc@5: 100.0000 (97.2271)  time: 0.3493  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [2290/3125]  eta: 0:04:52  Lr: 0.001875  Loss: -0.6860  Acc@1: 81.2500 (80.2652)  Acc@5: 100.0000 (97.2337)  time: 0.3491  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [2300/3125]  eta: 0:04:48  Lr: 0.001875  Loss: -0.4003  Acc@1: 87.5000 (80.2857)  Acc@5: 100.0000 (97.2403)  time: 0.3474  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [2310/3125]  eta: 0:04:45  Lr: 0.001875  Loss: -0.5211  Acc@1: 81.2500 (80.2899)  Acc@5: 100.0000 (97.2387)  time: 0.3463  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [2320/3125]  eta: 0:04:41  Lr: 0.001875  Loss: -0.5132  Acc@1: 81.2500 (80.2833)  Acc@5: 93.7500 (97.2372)  time: 0.3476  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [2330/3125]  eta: 0:04:38  Lr: 0.001875  Loss: -0.8822  Acc@1: 87.5000 (80.3250)  Acc@5: 100.0000 (97.2490)  time: 0.3498  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [2340/3125]  eta: 0:04:34  Lr: 0.001875  Loss: -0.4475  Acc@1: 87.5000 (80.3316)  Acc@5: 100.0000 (97.2474)  time: 0.3503  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [2350/3125]  eta: 0:04:31  Lr: 0.001875  Loss: -0.5387  Acc@1: 81.2500 (80.3275)  Acc@5: 100.0000 (97.2512)  time: 0.3499  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [2360/3125]  eta: 0:04:27  Lr: 0.001875  Loss: -0.7958  Acc@1: 81.2500 (80.3473)  Acc@5: 100.0000 (97.2602)  time: 0.3490  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [2370/3125]  eta: 0:04:24  Lr: 0.001875  Loss: -0.4156  Acc@1: 87.5000 (80.3538)  Acc@5: 100.0000 (97.2638)  time: 0.3493  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [2380/3125]  eta: 0:04:20  Lr: 0.001875  Loss: -0.5001  Acc@1: 81.2500 (80.3601)  Acc@5: 100.0000 (97.2674)  time: 0.3497  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [2390/3125]  eta: 0:04:17  Lr: 0.001875  Loss: -0.3830  Acc@1: 87.5000 (80.3848)  Acc@5: 100.0000 (97.2762)  time: 0.3484  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [2400/3125]  eta: 0:04:13  Lr: 0.001875  Loss: -0.6167  Acc@1: 87.5000 (80.4014)  Acc@5: 100.0000 (97.2772)  time: 0.3487  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [2410/3125]  eta: 0:04:10  Lr: 0.001875  Loss: -0.8244  Acc@1: 81.2500 (80.4101)  Acc@5: 100.0000 (97.2807)  time: 0.3487  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [2420/3125]  eta: 0:04:06  Lr: 0.001875  Loss: -0.3891  Acc@1: 81.2500 (80.4084)  Acc@5: 100.0000 (97.2816)  time: 0.3490  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [2430/3125]  eta: 0:04:03  Lr: 0.001875  Loss: -0.5112  Acc@1: 81.2500 (80.4324)  Acc@5: 100.0000 (97.2876)  time: 0.3502  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [2440/3125]  eta: 0:03:59  Lr: 0.001875  Loss: -0.3526  Acc@1: 81.2500 (80.4511)  Acc@5: 100.0000 (97.2962)  time: 0.3502  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [2450/3125]  eta: 0:03:56  Lr: 0.001875  Loss: -0.5905  Acc@1: 87.5000 (80.4927)  Acc@5: 100.0000 (97.3021)  time: 0.3503  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [2460/3125]  eta: 0:03:52  Lr: 0.001875  Loss: -0.2542  Acc@1: 87.5000 (80.5186)  Acc@5: 100.0000 (97.2978)  time: 0.3499  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [2470/3125]  eta: 0:03:49  Lr: 0.001875  Loss: -0.3487  Acc@1: 87.5000 (80.5468)  Acc@5: 100.0000 (97.2961)  time: 0.3494  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [2480/3125]  eta: 0:03:45  Lr: 0.001875  Loss: -0.4917  Acc@1: 87.5000 (80.5522)  Acc@5: 100.0000 (97.3020)  time: 0.3499  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [2490/3125]  eta: 0:03:42  Lr: 0.001875  Loss: -0.8287  Acc@1: 81.2500 (80.5475)  Acc@5: 100.0000 (97.3028)  time: 0.3497  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [2500/3125]  eta: 0:03:38  Lr: 0.001875  Loss: -0.3056  Acc@1: 87.5000 (80.5753)  Acc@5: 100.0000 (97.3036)  time: 0.3492  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [2510/3125]  eta: 0:03:35  Lr: 0.001875  Loss: -0.4011  Acc@1: 81.2500 (80.5804)  Acc@5: 100.0000 (97.2994)  time: 0.3491  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [2520/3125]  eta: 0:03:31  Lr: 0.001875  Loss: -0.4502  Acc@1: 81.2500 (80.5583)  Acc@5: 100.0000 (97.3027)  time: 0.3486  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [2530/3125]  eta: 0:03:28  Lr: 0.001875  Loss: -0.3065  Acc@1: 87.5000 (80.5956)  Acc@5: 100.0000 (97.3059)  time: 0.3483  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [2540/3125]  eta: 0:03:24  Lr: 0.001875  Loss: -0.4948  Acc@1: 87.5000 (80.6006)  Acc@5: 100.0000 (97.3042)  time: 0.3483  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [2550/3125]  eta: 0:03:21  Lr: 0.001875  Loss: -0.5544  Acc@1: 81.2500 (80.6056)  Acc@5: 100.0000 (97.3074)  time: 0.3482  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [2560/3125]  eta: 0:03:17  Lr: 0.001875  Loss: -0.3950  Acc@1: 81.2500 (80.6033)  Acc@5: 100.0000 (97.3082)  time: 0.3492  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [2570/3125]  eta: 0:03:14  Lr: 0.001875  Loss: -0.4158  Acc@1: 81.2500 (80.6228)  Acc@5: 100.0000 (97.3114)  time: 0.3494  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [2580/3125]  eta: 0:03:10  Lr: 0.001875  Loss: -0.5481  Acc@1: 81.2500 (80.6422)  Acc@5: 100.0000 (97.3145)  time: 0.3487  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [2590/3125]  eta: 0:03:07  Lr: 0.001875  Loss: -0.7848  Acc@1: 81.2500 (80.6397)  Acc@5: 100.0000 (97.3080)  time: 0.3491  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [2600/3125]  eta: 0:03:03  Lr: 0.001875  Loss: -0.6994  Acc@1: 81.2500 (80.6541)  Acc@5: 100.0000 (97.3135)  time: 0.3496  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [2610/3125]  eta: 0:03:00  Lr: 0.001875  Loss: -0.4914  Acc@1: 81.2500 (80.6683)  Acc@5: 100.0000 (97.3119)  time: 0.3494  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [2620/3125]  eta: 0:02:56  Lr: 0.001875  Loss: -0.6551  Acc@1: 87.5000 (80.6872)  Acc@5: 100.0000 (97.3126)  time: 0.3494  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [2630/3125]  eta: 0:02:53  Lr: 0.001875  Loss: -0.0487  Acc@1: 87.5000 (80.7060)  Acc@5: 100.0000 (97.3204)  time: 0.3501  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [2640/3125]  eta: 0:02:49  Lr: 0.001875  Loss: -0.6516  Acc@1: 87.5000 (80.7199)  Acc@5: 100.0000 (97.3282)  time: 0.3498  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [2650/3125]  eta: 0:02:46  Lr: 0.001875  Loss: -0.6528  Acc@1: 87.5000 (80.7337)  Acc@5: 100.0000 (97.3359)  time: 0.3496  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [2660/3125]  eta: 0:02:42  Lr: 0.001875  Loss: -0.6532  Acc@1: 81.2500 (80.7403)  Acc@5: 100.0000 (97.3365)  time: 0.3499  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [2670/3125]  eta: 0:02:39  Lr: 0.001875  Loss: -0.6448  Acc@1: 81.2500 (80.7563)  Acc@5: 100.0000 (97.3442)  time: 0.3507  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [2680/3125]  eta: 0:02:35  Lr: 0.001875  Loss: -0.8098  Acc@1: 87.5000 (80.7768)  Acc@5: 100.0000 (97.3494)  time: 0.3508  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [2690/3125]  eta: 0:02:32  Lr: 0.001875  Loss: -0.7450  Acc@1: 87.5000 (80.7948)  Acc@5: 100.0000 (97.3523)  time: 0.3496  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [2700/3125]  eta: 0:02:28  Lr: 0.001875  Loss: -0.6956  Acc@1: 87.5000 (80.8057)  Acc@5: 100.0000 (97.3575)  time: 0.3493  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [2710/3125]  eta: 0:02:25  Lr: 0.001875  Loss: -0.7020  Acc@1: 87.5000 (80.8212)  Acc@5: 100.0000 (97.3649)  time: 0.3499  data: 0.0008  max mem: 2502
Train: Epoch[1/5]  [2720/3125]  eta: 0:02:21  Lr: 0.001875  Loss: -0.3209  Acc@1: 81.2500 (80.8251)  Acc@5: 100.0000 (97.3654)  time: 0.3498  data: 0.0008  max mem: 2502
Train: Epoch[1/5]  [2730/3125]  eta: 0:02:18  Lr: 0.001875  Loss: -0.3214  Acc@1: 81.2500 (80.8289)  Acc@5: 100.0000 (97.3613)  time: 0.3491  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [2740/3125]  eta: 0:02:14  Lr: 0.001875  Loss: -0.6726  Acc@1: 81.2500 (80.8350)  Acc@5: 100.0000 (97.3641)  time: 0.3494  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [2750/3125]  eta: 0:02:11  Lr: 0.001875  Loss: -0.2874  Acc@1: 87.5000 (80.8592)  Acc@5: 100.0000 (97.3691)  time: 0.3506  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [2760/3125]  eta: 0:02:07  Lr: 0.001875  Loss: -0.4728  Acc@1: 87.5000 (80.8765)  Acc@5: 100.0000 (97.3719)  time: 0.3502  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [2770/3125]  eta: 0:02:04  Lr: 0.001875  Loss: -0.2486  Acc@1: 87.5000 (80.8824)  Acc@5: 100.0000 (97.3791)  time: 0.3488  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [2780/3125]  eta: 0:02:00  Lr: 0.001875  Loss: -0.4640  Acc@1: 81.2500 (80.8859)  Acc@5: 100.0000 (97.3795)  time: 0.3492  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [2790/3125]  eta: 0:01:57  Lr: 0.001875  Loss: -0.3335  Acc@1: 81.2500 (80.8939)  Acc@5: 100.0000 (97.3755)  time: 0.3500  data: 0.0010  max mem: 2502
Train: Epoch[1/5]  [2800/3125]  eta: 0:01:53  Lr: 0.001875  Loss: -0.6437  Acc@1: 81.2500 (80.9086)  Acc@5: 100.0000 (97.3804)  time: 0.3503  data: 0.0011  max mem: 2502
Train: Epoch[1/5]  [2810/3125]  eta: 0:01:50  Lr: 0.001875  Loss: -0.1306  Acc@1: 81.2500 (80.9076)  Acc@5: 100.0000 (97.3786)  time: 0.3500  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [2820/3125]  eta: 0:01:46  Lr: 0.001875  Loss: -0.6871  Acc@1: 81.2500 (80.9199)  Acc@5: 100.0000 (97.3835)  time: 0.3497  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [2830/3125]  eta: 0:01:43  Lr: 0.001875  Loss: -0.3323  Acc@1: 87.5000 (80.9387)  Acc@5: 100.0000 (97.3927)  time: 0.3502  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [2840/3125]  eta: 0:01:39  Lr: 0.001875  Loss: -0.8938  Acc@1: 87.5000 (80.9530)  Acc@5: 100.0000 (97.3909)  time: 0.3501  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [2850/3125]  eta: 0:01:36  Lr: 0.001875  Loss: -0.8424  Acc@1: 87.5000 (80.9804)  Acc@5: 100.0000 (97.4000)  time: 0.3497  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [2860/3125]  eta: 0:01:32  Lr: 0.001875  Loss: -0.9303  Acc@1: 87.5000 (81.0053)  Acc@5: 100.0000 (97.4069)  time: 0.3495  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [2870/3125]  eta: 0:01:29  Lr: 0.001875  Loss: -0.7526  Acc@1: 87.5000 (81.0192)  Acc@5: 100.0000 (97.4116)  time: 0.3498  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [2880/3125]  eta: 0:01:25  Lr: 0.001875  Loss: -0.1398  Acc@1: 81.2500 (81.0287)  Acc@5: 100.0000 (97.4119)  time: 0.3499  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [2890/3125]  eta: 0:01:22  Lr: 0.001875  Loss: -0.7358  Acc@1: 81.2500 (81.0360)  Acc@5: 100.0000 (97.4122)  time: 0.3496  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [2900/3125]  eta: 0:01:18  Lr: 0.001875  Loss: -0.1458  Acc@1: 81.2500 (81.0389)  Acc@5: 100.0000 (97.4147)  time: 0.3501  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [2910/3125]  eta: 0:01:15  Lr: 0.001875  Loss: -0.5814  Acc@1: 81.2500 (81.0503)  Acc@5: 100.0000 (97.4150)  time: 0.3501  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [2920/3125]  eta: 0:01:11  Lr: 0.001875  Loss: -0.4260  Acc@1: 81.2500 (81.0638)  Acc@5: 100.0000 (97.4195)  time: 0.3496  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [2930/3125]  eta: 0:01:08  Lr: 0.001875  Loss: -0.4217  Acc@1: 81.2500 (81.0773)  Acc@5: 100.0000 (97.4198)  time: 0.3496  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [2940/3125]  eta: 0:01:04  Lr: 0.001875  Loss: -0.8499  Acc@1: 87.5000 (81.0906)  Acc@5: 100.0000 (97.4243)  time: 0.3496  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [2950/3125]  eta: 0:01:01  Lr: 0.001875  Loss: -0.9435  Acc@1: 87.5000 (81.1187)  Acc@5: 100.0000 (97.4267)  time: 0.3497  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [2960/3125]  eta: 0:00:57  Lr: 0.001875  Loss: -0.2465  Acc@1: 81.2500 (81.1234)  Acc@5: 100.0000 (97.4312)  time: 0.3501  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [2970/3125]  eta: 0:00:54  Lr: 0.001875  Loss: -0.7755  Acc@1: 81.2500 (81.1322)  Acc@5: 100.0000 (97.4293)  time: 0.3503  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [2980/3125]  eta: 0:00:50  Lr: 0.001875  Loss: -0.1539  Acc@1: 81.2500 (81.1389)  Acc@5: 100.0000 (97.4337)  time: 0.3504  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [2990/3125]  eta: 0:00:47  Lr: 0.001875  Loss: -0.8537  Acc@1: 81.2500 (81.1476)  Acc@5: 100.0000 (97.4298)  time: 0.3509  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [3000/3125]  eta: 0:00:43  Lr: 0.001875  Loss: -0.2443  Acc@1: 87.5000 (81.1667)  Acc@5: 100.0000 (97.4321)  time: 0.3512  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [3010/3125]  eta: 0:00:40  Lr: 0.001875  Loss: -0.7182  Acc@1: 87.5000 (81.1773)  Acc@5: 100.0000 (97.4365)  time: 0.3517  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [3020/3125]  eta: 0:00:36  Lr: 0.001875  Loss: -0.3355  Acc@1: 81.2500 (81.1900)  Acc@5: 100.0000 (97.4367)  time: 0.3517  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [3030/3125]  eta: 0:00:33  Lr: 0.001875  Loss: -0.4590  Acc@1: 81.2500 (81.1943)  Acc@5: 100.0000 (97.4431)  time: 0.3504  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [3040/3125]  eta: 0:00:29  Lr: 0.001875  Loss: -0.7293  Acc@1: 81.2500 (81.2048)  Acc@5: 100.0000 (97.4453)  time: 0.3512  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [3050/3125]  eta: 0:00:26  Lr: 0.001875  Loss: -0.8191  Acc@1: 87.5000 (81.2234)  Acc@5: 100.0000 (97.4496)  time: 0.3522  data: 0.0016  max mem: 2502
Train: Epoch[1/5]  [3060/3125]  eta: 0:00:22  Lr: 0.001875  Loss: -0.7122  Acc@1: 81.2500 (81.2173)  Acc@5: 100.0000 (97.4539)  time: 0.3505  data: 0.0015  max mem: 2502
Train: Epoch[1/5]  [3070/3125]  eta: 0:00:19  Lr: 0.001875  Loss: -0.7868  Acc@1: 81.2500 (81.2337)  Acc@5: 100.0000 (97.4560)  time: 0.3495  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [3080/3125]  eta: 0:00:15  Lr: 0.001875  Loss: -0.2802  Acc@1: 81.2500 (81.2358)  Acc@5: 100.0000 (97.4582)  time: 0.3506  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [3090/3125]  eta: 0:00:12  Lr: 0.001875  Loss: -0.6168  Acc@1: 81.2500 (81.2419)  Acc@5: 100.0000 (97.4624)  time: 0.3511  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [3100/3125]  eta: 0:00:08  Lr: 0.001875  Loss: -0.2986  Acc@1: 81.2500 (81.2460)  Acc@5: 100.0000 (97.4665)  time: 0.3509  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [3110/3125]  eta: 0:00:05  Lr: 0.001875  Loss: -0.6692  Acc@1: 81.2500 (81.2400)  Acc@5: 100.0000 (97.4646)  time: 0.3508  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [3120/3125]  eta: 0:00:01  Lr: 0.001875  Loss: -0.6790  Acc@1: 81.2500 (81.2500)  Acc@5: 100.0000 (97.4668)  time: 0.3511  data: 0.0008  max mem: 2502
Train: Epoch[1/5]  [3124/3125]  eta: 0:00:00  Lr: 0.001875  Loss: -0.5690  Acc@1: 81.2500 (81.2520)  Acc@5: 100.0000 (97.4700)  time: 0.3513  data: 0.0008  max mem: 2502
Train: Epoch[1/5] Total time: 0:18:13 (0.3499 s / it)
Averaged stats: Lr: 0.001875  Loss: -0.5690  Acc@1: 81.2500 (81.2520)  Acc@5: 100.0000 (97.4700)
Train: Epoch[2/5]  [   0/3125]  eta: 0:36:04  Lr: 0.001875  Loss: -0.5006  Acc@1: 81.2500 (81.2500)  Acc@5: 100.0000 (100.0000)  time: 0.6927  data: 0.3386  max mem: 2502
Train: Epoch[2/5]  [  10/3125]  eta: 0:19:48  Lr: 0.001875  Loss: -0.6006  Acc@1: 87.5000 (85.2273)  Acc@5: 100.0000 (99.4318)  time: 0.3816  data: 0.0312  max mem: 2502
Train: Epoch[2/5]  [  20/3125]  eta: 0:19:00  Lr: 0.001875  Loss: -0.6604  Acc@1: 81.2500 (84.2262)  Acc@5: 100.0000 (98.5119)  time: 0.3510  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [  30/3125]  eta: 0:18:38  Lr: 0.001875  Loss: -0.5632  Acc@1: 81.2500 (82.6613)  Acc@5: 100.0000 (98.1855)  time: 0.3505  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [  40/3125]  eta: 0:18:26  Lr: 0.001875  Loss: -0.3187  Acc@1: 81.2500 (81.7073)  Acc@5: 100.0000 (97.4085)  time: 0.3499  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [  50/3125]  eta: 0:18:18  Lr: 0.001875  Loss: -0.7328  Acc@1: 87.5000 (82.7206)  Acc@5: 100.0000 (97.6716)  time: 0.3504  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [  60/3125]  eta: 0:18:12  Lr: 0.001875  Loss: -0.3212  Acc@1: 87.5000 (83.2992)  Acc@5: 100.0000 (97.4385)  time: 0.3513  data: 0.0011  max mem: 2502
Train: Epoch[2/5]  [  70/3125]  eta: 0:18:05  Lr: 0.001875  Loss: -0.6097  Acc@1: 81.2500 (82.9225)  Acc@5: 100.0000 (97.4472)  time: 0.3511  data: 0.0009  max mem: 2502
Train: Epoch[2/5]  [  80/3125]  eta: 0:18:00  Lr: 0.001875  Loss: -0.7549  Acc@1: 81.2500 (82.7932)  Acc@5: 100.0000 (97.3765)  time: 0.3503  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [  90/3125]  eta: 0:17:55  Lr: 0.001875  Loss: -0.3982  Acc@1: 81.2500 (82.8297)  Acc@5: 100.0000 (97.3901)  time: 0.3507  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [ 100/3125]  eta: 0:17:51  Lr: 0.001875  Loss: -0.3814  Acc@1: 81.2500 (83.0446)  Acc@5: 100.0000 (97.4010)  time: 0.3510  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [ 110/3125]  eta: 0:17:46  Lr: 0.001875  Loss: -0.8269  Acc@1: 81.2500 (83.2770)  Acc@5: 100.0000 (97.4662)  time: 0.3506  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [ 120/3125]  eta: 0:17:42  Lr: 0.001875  Loss: -0.5119  Acc@1: 81.2500 (83.4194)  Acc@5: 100.0000 (97.5723)  time: 0.3507  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [ 130/3125]  eta: 0:17:38  Lr: 0.001875  Loss: -0.6034  Acc@1: 81.2500 (83.5878)  Acc@5: 100.0000 (97.6145)  time: 0.3512  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [ 140/3125]  eta: 0:17:34  Lr: 0.001875  Loss: -0.3185  Acc@1: 81.2500 (83.5106)  Acc@5: 100.0000 (97.6507)  time: 0.3506  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [ 150/3125]  eta: 0:17:29  Lr: 0.001875  Loss: -0.6311  Acc@1: 81.2500 (83.6093)  Acc@5: 100.0000 (97.5993)  time: 0.3499  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [ 160/3125]  eta: 0:17:25  Lr: 0.001875  Loss: -0.5918  Acc@1: 87.5000 (84.0839)  Acc@5: 100.0000 (97.7096)  time: 0.3498  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [ 170/3125]  eta: 0:17:21  Lr: 0.001875  Loss: -0.4814  Acc@1: 87.5000 (84.0278)  Acc@5: 100.0000 (97.8070)  time: 0.3505  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [ 180/3125]  eta: 0:17:17  Lr: 0.001875  Loss: -0.2691  Acc@1: 81.2500 (83.8743)  Acc@5: 100.0000 (97.7555)  time: 0.3505  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [ 190/3125]  eta: 0:17:14  Lr: 0.001875  Loss: -0.1189  Acc@1: 81.2500 (83.8678)  Acc@5: 100.0000 (97.7421)  time: 0.3500  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [ 200/3125]  eta: 0:17:10  Lr: 0.001875  Loss: -0.9056  Acc@1: 81.2500 (83.7687)  Acc@5: 100.0000 (97.7612)  time: 0.3498  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [ 210/3125]  eta: 0:17:06  Lr: 0.001875  Loss: -0.6759  Acc@1: 87.5000 (83.9159)  Acc@5: 100.0000 (97.7784)  time: 0.3501  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [ 220/3125]  eta: 0:17:02  Lr: 0.001875  Loss: -0.6493  Acc@1: 81.2500 (83.7670)  Acc@5: 100.0000 (97.7376)  time: 0.3499  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [ 230/3125]  eta: 0:16:58  Lr: 0.001875  Loss: -0.6005  Acc@1: 81.2500 (83.9827)  Acc@5: 100.0000 (97.7543)  time: 0.3502  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [ 240/3125]  eta: 0:16:55  Lr: 0.001875  Loss: -0.8265  Acc@1: 81.2500 (83.9730)  Acc@5: 100.0000 (97.7697)  time: 0.3505  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [ 250/3125]  eta: 0:16:51  Lr: 0.001875  Loss: -0.5420  Acc@1: 81.2500 (83.9890)  Acc@5: 100.0000 (97.8586)  time: 0.3497  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [ 260/3125]  eta: 0:16:47  Lr: 0.001875  Loss: -0.8133  Acc@1: 81.2500 (83.8841)  Acc@5: 100.0000 (97.8688)  time: 0.3502  data: 0.0011  max mem: 2502
Train: Epoch[2/5]  [ 270/3125]  eta: 0:16:44  Lr: 0.001875  Loss: -0.6796  Acc@1: 87.5000 (83.9945)  Acc@5: 100.0000 (97.9013)  time: 0.3518  data: 0.0019  max mem: 2502
Train: Epoch[2/5]  [ 280/3125]  eta: 0:16:40  Lr: 0.001875  Loss: -0.1599  Acc@1: 87.5000 (83.9190)  Acc@5: 100.0000 (97.9315)  time: 0.3519  data: 0.0012  max mem: 2502
Train: Epoch[2/5]  [ 290/3125]  eta: 0:16:36  Lr: 0.001875  Loss: -0.8706  Acc@1: 81.2500 (83.9562)  Acc@5: 100.0000 (97.9811)  time: 0.3502  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [ 300/3125]  eta: 0:16:33  Lr: 0.001875  Loss: -0.4350  Acc@1: 81.2500 (84.0116)  Acc@5: 100.0000 (98.0066)  time: 0.3496  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [ 310/3125]  eta: 0:16:29  Lr: 0.001875  Loss: -0.4735  Acc@1: 87.5000 (84.0836)  Acc@5: 100.0000 (98.0105)  time: 0.3501  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [ 320/3125]  eta: 0:16:25  Lr: 0.001875  Loss: -0.3472  Acc@1: 87.5000 (84.1511)  Acc@5: 100.0000 (97.9945)  time: 0.3498  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [ 330/3125]  eta: 0:16:22  Lr: 0.001875  Loss: -0.0807  Acc@1: 81.2500 (84.0446)  Acc@5: 100.0000 (97.9985)  time: 0.3493  data: 0.0009  max mem: 2502
Train: Epoch[2/5]  [ 340/3125]  eta: 0:16:18  Lr: 0.001875  Loss: -0.8674  Acc@1: 81.2500 (83.9993)  Acc@5: 100.0000 (98.0389)  time: 0.3489  data: 0.0009  max mem: 2502
Train: Epoch[2/5]  [ 350/3125]  eta: 0:16:14  Lr: 0.001875  Loss: -0.5169  Acc@1: 81.2500 (83.8497)  Acc@5: 100.0000 (98.0413)  time: 0.3485  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [ 360/3125]  eta: 0:16:11  Lr: 0.001875  Loss: -0.6530  Acc@1: 81.2500 (83.9681)  Acc@5: 100.0000 (98.0783)  time: 0.3489  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [ 370/3125]  eta: 0:16:07  Lr: 0.001875  Loss: -0.6491  Acc@1: 87.5000 (84.0296)  Acc@5: 100.0000 (98.1132)  time: 0.3486  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [ 380/3125]  eta: 0:16:03  Lr: 0.001875  Loss: -0.6595  Acc@1: 87.5000 (83.9403)  Acc@5: 100.0000 (98.1299)  time: 0.3483  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [ 390/3125]  eta: 0:15:59  Lr: 0.001875  Loss: -0.8318  Acc@1: 87.5000 (84.0793)  Acc@5: 100.0000 (98.1618)  time: 0.3486  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [ 400/3125]  eta: 0:15:56  Lr: 0.001875  Loss: -0.1807  Acc@1: 87.5000 (84.0243)  Acc@5: 100.0000 (98.1453)  time: 0.3493  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [ 410/3125]  eta: 0:15:52  Lr: 0.001875  Loss: -0.4082  Acc@1: 81.2500 (83.8656)  Acc@5: 100.0000 (98.1448)  time: 0.3499  data: 0.0007  max mem: 2502
Train: Epoch[2/5]  [ 420/3125]  eta: 0:15:49  Lr: 0.001875  Loss: -0.9597  Acc@1: 81.2500 (83.8777)  Acc@5: 100.0000 (98.1740)  time: 0.3496  data: 0.0015  max mem: 2502
Train: Epoch[2/5]  [ 430/3125]  eta: 0:15:45  Lr: 0.001875  Loss: -0.8242  Acc@1: 87.5000 (83.9907)  Acc@5: 100.0000 (98.1729)  time: 0.3499  data: 0.0012  max mem: 2502
Train: Epoch[2/5]  [ 440/3125]  eta: 0:15:42  Lr: 0.001875  Loss: -0.7675  Acc@1: 93.7500 (84.2120)  Acc@5: 100.0000 (98.2001)  time: 0.3502  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [ 450/3125]  eta: 0:15:38  Lr: 0.001875  Loss: -0.8070  Acc@1: 87.5000 (84.1879)  Acc@5: 100.0000 (98.2123)  time: 0.3506  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [ 460/3125]  eta: 0:15:34  Lr: 0.001875  Loss: -0.8381  Acc@1: 81.2500 (84.1513)  Acc@5: 100.0000 (98.1969)  time: 0.3504  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [ 470/3125]  eta: 0:15:31  Lr: 0.001875  Loss: -0.4655  Acc@1: 87.5000 (84.1959)  Acc@5: 100.0000 (98.2086)  time: 0.3504  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [ 480/3125]  eta: 0:15:27  Lr: 0.001875  Loss: -0.7442  Acc@1: 87.5000 (84.2646)  Acc@5: 100.0000 (98.2328)  time: 0.3508  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [ 490/3125]  eta: 0:15:24  Lr: 0.001875  Loss: -0.5476  Acc@1: 81.2500 (84.2286)  Acc@5: 100.0000 (98.2434)  time: 0.3504  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [ 500/3125]  eta: 0:15:20  Lr: 0.001875  Loss: -0.8889  Acc@1: 81.2500 (84.2066)  Acc@5: 100.0000 (98.2410)  time: 0.3497  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [ 510/3125]  eta: 0:15:17  Lr: 0.001875  Loss: -0.2022  Acc@1: 81.2500 (84.2099)  Acc@5: 100.0000 (98.2387)  time: 0.3496  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [ 520/3125]  eta: 0:15:13  Lr: 0.001875  Loss: -0.3708  Acc@1: 81.2500 (84.2370)  Acc@5: 100.0000 (98.2486)  time: 0.3503  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [ 530/3125]  eta: 0:15:10  Lr: 0.001875  Loss: -0.9024  Acc@1: 87.5000 (84.2632)  Acc@5: 100.0000 (98.2580)  time: 0.3506  data: 0.0007  max mem: 2502
Train: Epoch[2/5]  [ 540/3125]  eta: 0:15:06  Lr: 0.001875  Loss: -0.4933  Acc@1: 81.2500 (84.2075)  Acc@5: 100.0000 (98.2440)  time: 0.3501  data: 0.0007  max mem: 2502
Train: Epoch[2/5]  [ 550/3125]  eta: 0:15:03  Lr: 0.001875  Loss: -0.5572  Acc@1: 81.2500 (84.2332)  Acc@5: 100.0000 (98.2305)  time: 0.3504  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [ 560/3125]  eta: 0:14:59  Lr: 0.001875  Loss: -0.7175  Acc@1: 81.2500 (84.2246)  Acc@5: 100.0000 (98.2286)  time: 0.3516  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [ 570/3125]  eta: 0:14:56  Lr: 0.001875  Loss: -0.3727  Acc@1: 81.2500 (84.2272)  Acc@5: 100.0000 (98.2158)  time: 0.3528  data: 0.0010  max mem: 2502
Train: Epoch[2/5]  [ 580/3125]  eta: 0:14:52  Lr: 0.001875  Loss: -0.5655  Acc@1: 81.2500 (84.1437)  Acc@5: 100.0000 (98.1928)  time: 0.3524  data: 0.0015  max mem: 2502
Train: Epoch[2/5]  [ 590/3125]  eta: 0:14:49  Lr: 0.001875  Loss: -0.3551  Acc@1: 81.2500 (84.1582)  Acc@5: 100.0000 (98.1810)  time: 0.3503  data: 0.0010  max mem: 2502
Train: Epoch[2/5]  [ 600/3125]  eta: 0:14:45  Lr: 0.001875  Loss: -0.5712  Acc@1: 87.5000 (84.1722)  Acc@5: 100.0000 (98.1593)  time: 0.3497  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [ 610/3125]  eta: 0:14:42  Lr: 0.001875  Loss: -0.5991  Acc@1: 81.2500 (84.1346)  Acc@5: 100.0000 (98.1588)  time: 0.3503  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [ 620/3125]  eta: 0:14:38  Lr: 0.001875  Loss: -0.6984  Acc@1: 81.2500 (84.0982)  Acc@5: 100.0000 (98.1582)  time: 0.3505  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [ 630/3125]  eta: 0:14:35  Lr: 0.001875  Loss: -0.8518  Acc@1: 81.2500 (84.1323)  Acc@5: 100.0000 (98.1478)  time: 0.3510  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [ 640/3125]  eta: 0:14:31  Lr: 0.001875  Loss: -0.0365  Acc@1: 81.2500 (84.1069)  Acc@5: 100.0000 (98.1377)  time: 0.3505  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [ 650/3125]  eta: 0:14:28  Lr: 0.001875  Loss: -0.7508  Acc@1: 87.5000 (84.1878)  Acc@5: 100.0000 (98.1567)  time: 0.3497  data: 0.0007  max mem: 2502
Train: Epoch[2/5]  [ 660/3125]  eta: 0:14:24  Lr: 0.001875  Loss: -0.6485  Acc@1: 87.5000 (84.1812)  Acc@5: 100.0000 (98.1562)  time: 0.3500  data: 0.0007  max mem: 2502
Train: Epoch[2/5]  [ 670/3125]  eta: 0:14:21  Lr: 0.001875  Loss: -0.4004  Acc@1: 87.5000 (84.2213)  Acc@5: 100.0000 (98.1837)  time: 0.3499  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [ 680/3125]  eta: 0:14:17  Lr: 0.001875  Loss: -0.6000  Acc@1: 87.5000 (84.2236)  Acc@5: 100.0000 (98.1828)  time: 0.3508  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [ 690/3125]  eta: 0:14:14  Lr: 0.001875  Loss: -0.7320  Acc@1: 87.5000 (84.2710)  Acc@5: 100.0000 (98.2001)  time: 0.3509  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [ 700/3125]  eta: 0:14:10  Lr: 0.001875  Loss: -0.7743  Acc@1: 87.5000 (84.2725)  Acc@5: 100.0000 (98.1901)  time: 0.3496  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [ 710/3125]  eta: 0:14:06  Lr: 0.001875  Loss: -0.8343  Acc@1: 87.5000 (84.3442)  Acc@5: 100.0000 (98.2155)  time: 0.3491  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [ 720/3125]  eta: 0:14:03  Lr: 0.001875  Loss: -0.3599  Acc@1: 87.5000 (84.3533)  Acc@5: 100.0000 (98.2230)  time: 0.3497  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [ 730/3125]  eta: 0:13:59  Lr: 0.001875  Loss: -0.7051  Acc@1: 81.2500 (84.2852)  Acc@5: 100.0000 (98.2473)  time: 0.3503  data: 0.0012  max mem: 2502
Train: Epoch[2/5]  [ 740/3125]  eta: 0:13:56  Lr: 0.001875  Loss: -0.1835  Acc@1: 81.2500 (84.2864)  Acc@5: 100.0000 (98.2540)  time: 0.3497  data: 0.0012  max mem: 2502
Train: Epoch[2/5]  [ 750/3125]  eta: 0:13:52  Lr: 0.001875  Loss: -1.0034  Acc@1: 87.5000 (84.2876)  Acc@5: 100.0000 (98.2357)  time: 0.3495  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [ 760/3125]  eta: 0:13:49  Lr: 0.001875  Loss: -0.6572  Acc@1: 87.5000 (84.3216)  Acc@5: 100.0000 (98.2507)  time: 0.3491  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [ 770/3125]  eta: 0:13:45  Lr: 0.001875  Loss: 0.0461  Acc@1: 87.5000 (84.3304)  Acc@5: 100.0000 (98.2490)  time: 0.3493  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [ 780/3125]  eta: 0:13:42  Lr: 0.001875  Loss: -0.8009  Acc@1: 87.5000 (84.3630)  Acc@5: 100.0000 (98.2394)  time: 0.3487  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [ 790/3125]  eta: 0:13:38  Lr: 0.001875  Loss: -0.6208  Acc@1: 87.5000 (84.4185)  Acc@5: 100.0000 (98.2380)  time: 0.3474  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [ 800/3125]  eta: 0:13:34  Lr: 0.001875  Loss: -1.0191  Acc@1: 87.5000 (84.4101)  Acc@5: 100.0000 (98.2600)  time: 0.3477  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [ 810/3125]  eta: 0:13:31  Lr: 0.001875  Loss: -0.7511  Acc@1: 87.5000 (84.4790)  Acc@5: 100.0000 (98.2737)  time: 0.3488  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [ 820/3125]  eta: 0:13:27  Lr: 0.001875  Loss: -0.8797  Acc@1: 87.5000 (84.4778)  Acc@5: 100.0000 (98.2643)  time: 0.3484  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [ 830/3125]  eta: 0:13:24  Lr: 0.001875  Loss: -0.5659  Acc@1: 87.5000 (84.4991)  Acc@5: 100.0000 (98.2551)  time: 0.3466  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [ 840/3125]  eta: 0:13:20  Lr: 0.001875  Loss: -0.1832  Acc@1: 81.2500 (84.5273)  Acc@5: 100.0000 (98.2610)  time: 0.3461  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [ 850/3125]  eta: 0:13:16  Lr: 0.001875  Loss: -0.6335  Acc@1: 87.5000 (84.5329)  Acc@5: 100.0000 (98.2667)  time: 0.3469  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [ 860/3125]  eta: 0:13:13  Lr: 0.001875  Loss: -0.6926  Acc@1: 87.5000 (84.5383)  Acc@5: 100.0000 (98.2506)  time: 0.3470  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [ 870/3125]  eta: 0:13:09  Lr: 0.001875  Loss: -0.4134  Acc@1: 81.2500 (84.4432)  Acc@5: 100.0000 (98.2491)  time: 0.3473  data: 0.0007  max mem: 2502
Train: Epoch[2/5]  [ 880/3125]  eta: 0:13:06  Lr: 0.001875  Loss: -0.3991  Acc@1: 75.0000 (84.4495)  Acc@5: 100.0000 (98.2619)  time: 0.3483  data: 0.0007  max mem: 2502
Train: Epoch[2/5]  [ 890/3125]  eta: 0:13:02  Lr: 0.001875  Loss: -0.7575  Acc@1: 81.2500 (84.4276)  Acc@5: 100.0000 (98.2604)  time: 0.3480  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [ 900/3125]  eta: 0:12:59  Lr: 0.001875  Loss: -0.1988  Acc@1: 87.5000 (84.4895)  Acc@5: 100.0000 (98.2589)  time: 0.3480  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [ 910/3125]  eta: 0:12:55  Lr: 0.001875  Loss: -0.4449  Acc@1: 87.5000 (84.5294)  Acc@5: 100.0000 (98.2711)  time: 0.3480  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [ 920/3125]  eta: 0:12:52  Lr: 0.001875  Loss: -0.8348  Acc@1: 87.5000 (84.5277)  Acc@5: 100.0000 (98.2628)  time: 0.3480  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [ 930/3125]  eta: 0:12:48  Lr: 0.001875  Loss: -0.5690  Acc@1: 87.5000 (84.5395)  Acc@5: 100.0000 (98.2546)  time: 0.3487  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [ 940/3125]  eta: 0:12:44  Lr: 0.001875  Loss: -0.8564  Acc@1: 87.5000 (84.5311)  Acc@5: 100.0000 (98.2598)  time: 0.3483  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [ 950/3125]  eta: 0:12:41  Lr: 0.001875  Loss: -0.5450  Acc@1: 87.5000 (84.5623)  Acc@5: 100.0000 (98.2584)  time: 0.3479  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [ 960/3125]  eta: 0:12:37  Lr: 0.001875  Loss: -0.5306  Acc@1: 87.5000 (84.6189)  Acc@5: 100.0000 (98.2700)  time: 0.3486  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [ 970/3125]  eta: 0:12:34  Lr: 0.001875  Loss: -0.8084  Acc@1: 93.7500 (84.6679)  Acc@5: 100.0000 (98.2621)  time: 0.3484  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [ 980/3125]  eta: 0:12:30  Lr: 0.001875  Loss: -0.8625  Acc@1: 87.5000 (84.6585)  Acc@5: 100.0000 (98.2671)  time: 0.3490  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [ 990/3125]  eta: 0:12:27  Lr: 0.001875  Loss: -0.8770  Acc@1: 81.2500 (84.6809)  Acc@5: 100.0000 (98.2719)  time: 0.3499  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [1000/3125]  eta: 0:12:23  Lr: 0.001875  Loss: -0.4548  Acc@1: 81.2500 (84.6279)  Acc@5: 100.0000 (98.2705)  time: 0.3494  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [1010/3125]  eta: 0:12:20  Lr: 0.001875  Loss: -0.7810  Acc@1: 81.2500 (84.6377)  Acc@5: 100.0000 (98.2752)  time: 0.3496  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [1020/3125]  eta: 0:12:16  Lr: 0.001875  Loss: -0.5227  Acc@1: 87.5000 (84.6413)  Acc@5: 100.0000 (98.2860)  time: 0.3493  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [1030/3125]  eta: 0:12:13  Lr: 0.001875  Loss: -0.6158  Acc@1: 87.5000 (84.6266)  Acc@5: 100.0000 (98.2723)  time: 0.3495  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [1040/3125]  eta: 0:12:09  Lr: 0.001875  Loss: -0.5263  Acc@1: 87.5000 (84.6362)  Acc@5: 100.0000 (98.2829)  time: 0.3498  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [1050/3125]  eta: 0:12:06  Lr: 0.001875  Loss: -0.6298  Acc@1: 87.5000 (84.6515)  Acc@5: 100.0000 (98.2933)  time: 0.3497  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [1060/3125]  eta: 0:12:02  Lr: 0.001875  Loss: -0.4876  Acc@1: 87.5000 (84.6548)  Acc@5: 100.0000 (98.2917)  time: 0.3495  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [1070/3125]  eta: 0:11:59  Lr: 0.001875  Loss: -0.1109  Acc@1: 81.2500 (84.6230)  Acc@5: 100.0000 (98.2785)  time: 0.3488  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [1080/3125]  eta: 0:11:55  Lr: 0.001875  Loss: -0.6524  Acc@1: 81.2500 (84.6438)  Acc@5: 100.0000 (98.2828)  time: 0.3491  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [1090/3125]  eta: 0:11:52  Lr: 0.001875  Loss: -0.3915  Acc@1: 87.5000 (84.6758)  Acc@5: 100.0000 (98.2814)  time: 0.3493  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [1100/3125]  eta: 0:11:48  Lr: 0.001875  Loss: -0.5094  Acc@1: 87.5000 (84.6617)  Acc@5: 100.0000 (98.2686)  time: 0.3494  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [1110/3125]  eta: 0:11:45  Lr: 0.001875  Loss: -0.4030  Acc@1: 87.5000 (84.6591)  Acc@5: 100.0000 (98.2673)  time: 0.3495  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [1120/3125]  eta: 0:11:41  Lr: 0.001875  Loss: -0.9422  Acc@1: 87.5000 (84.6900)  Acc@5: 100.0000 (98.2716)  time: 0.3498  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [1130/3125]  eta: 0:11:38  Lr: 0.001875  Loss: -0.8141  Acc@1: 87.5000 (84.7480)  Acc@5: 100.0000 (98.2759)  time: 0.3499  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [1140/3125]  eta: 0:11:34  Lr: 0.001875  Loss: -0.8406  Acc@1: 87.5000 (84.7228)  Acc@5: 100.0000 (98.2745)  time: 0.3491  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [1150/3125]  eta: 0:11:31  Lr: 0.001875  Loss: -0.3050  Acc@1: 81.2500 (84.6981)  Acc@5: 100.0000 (98.2732)  time: 0.3488  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [1160/3125]  eta: 0:11:27  Lr: 0.001875  Loss: -0.4928  Acc@1: 81.2500 (84.7168)  Acc@5: 100.0000 (98.2827)  time: 0.3501  data: 0.0012  max mem: 2502
Train: Epoch[2/5]  [1170/3125]  eta: 0:11:24  Lr: 0.001875  Loss: -0.8172  Acc@1: 87.5000 (84.7139)  Acc@5: 100.0000 (98.2760)  time: 0.3511  data: 0.0013  max mem: 2502
Train: Epoch[2/5]  [1180/3125]  eta: 0:11:20  Lr: 0.001875  Loss: -0.3273  Acc@1: 87.5000 (84.7005)  Acc@5: 100.0000 (98.2748)  time: 0.3503  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [1190/3125]  eta: 0:11:17  Lr: 0.001875  Loss: -0.1677  Acc@1: 81.2500 (84.7030)  Acc@5: 100.0000 (98.2683)  time: 0.3514  data: 0.0009  max mem: 2502
Train: Epoch[2/5]  [1200/3125]  eta: 0:11:13  Lr: 0.001875  Loss: -0.5392  Acc@1: 81.2500 (84.6586)  Acc@5: 100.0000 (98.2567)  time: 0.3516  data: 0.0014  max mem: 2502
Train: Epoch[2/5]  [1210/3125]  eta: 0:11:10  Lr: 0.001875  Loss: -0.6398  Acc@1: 81.2500 (84.7079)  Acc@5: 100.0000 (98.2711)  time: 0.3498  data: 0.0009  max mem: 2502
Train: Epoch[2/5]  [1220/3125]  eta: 0:11:06  Lr: 0.001875  Loss: -0.6393  Acc@1: 87.5000 (84.7052)  Acc@5: 100.0000 (98.2596)  time: 0.3502  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [1230/3125]  eta: 0:11:03  Lr: 0.001875  Loss: -0.7495  Acc@1: 87.5000 (84.7329)  Acc@5: 100.0000 (98.2687)  time: 0.3502  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [1240/3125]  eta: 0:10:59  Lr: 0.001875  Loss: -0.4940  Acc@1: 87.5000 (84.7452)  Acc@5: 100.0000 (98.2776)  time: 0.3495  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [1250/3125]  eta: 0:10:56  Lr: 0.001875  Loss: -0.5904  Acc@1: 87.5000 (84.7722)  Acc@5: 100.0000 (98.2714)  time: 0.3497  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [1260/3125]  eta: 0:10:52  Lr: 0.001875  Loss: -0.5322  Acc@1: 87.5000 (84.7938)  Acc@5: 100.0000 (98.2801)  time: 0.3502  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [1270/3125]  eta: 0:10:49  Lr: 0.001875  Loss: -0.6548  Acc@1: 87.5000 (84.7905)  Acc@5: 100.0000 (98.2691)  time: 0.3515  data: 0.0013  max mem: 2502
Train: Epoch[2/5]  [1280/3125]  eta: 0:10:45  Lr: 0.001875  Loss: -0.2252  Acc@1: 87.5000 (84.7629)  Acc@5: 100.0000 (98.2728)  time: 0.3510  data: 0.0013  max mem: 2502
Train: Epoch[2/5]  [1290/3125]  eta: 0:10:42  Lr: 0.001875  Loss: -0.5464  Acc@1: 81.2500 (84.7696)  Acc@5: 100.0000 (98.2717)  time: 0.3499  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [1300/3125]  eta: 0:10:38  Lr: 0.001875  Loss: -0.2862  Acc@1: 81.2500 (84.7569)  Acc@5: 100.0000 (98.2706)  time: 0.3508  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [1310/3125]  eta: 0:10:35  Lr: 0.001875  Loss: -0.5368  Acc@1: 87.5000 (84.7874)  Acc@5: 100.0000 (98.2790)  time: 0.3507  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [1320/3125]  eta: 0:10:31  Lr: 0.001875  Loss: -0.8572  Acc@1: 87.5000 (84.8268)  Acc@5: 100.0000 (98.2731)  time: 0.3493  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [1330/3125]  eta: 0:10:28  Lr: 0.001875  Loss: -0.5922  Acc@1: 87.5000 (84.8281)  Acc@5: 100.0000 (98.2673)  time: 0.3495  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [1340/3125]  eta: 0:10:24  Lr: 0.001875  Loss: -0.4643  Acc@1: 81.2500 (84.8108)  Acc@5: 93.7500 (98.2522)  time: 0.3494  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [1350/3125]  eta: 0:10:21  Lr: 0.001875  Loss: -0.1997  Acc@1: 81.2500 (84.8122)  Acc@5: 100.0000 (98.2559)  time: 0.3482  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [1360/3125]  eta: 0:10:17  Lr: 0.001875  Loss: -0.5993  Acc@1: 81.2500 (84.7906)  Acc@5: 100.0000 (98.2504)  time: 0.3482  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [1370/3125]  eta: 0:10:14  Lr: 0.001875  Loss: -0.8702  Acc@1: 87.5000 (84.8149)  Acc@5: 100.0000 (98.2495)  time: 0.3490  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [1380/3125]  eta: 0:10:10  Lr: 0.001875  Loss: -0.7673  Acc@1: 87.5000 (84.7982)  Acc@5: 100.0000 (98.2486)  time: 0.3494  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [1390/3125]  eta: 0:10:07  Lr: 0.001875  Loss: -0.7190  Acc@1: 81.2500 (84.8086)  Acc@5: 100.0000 (98.2566)  time: 0.3501  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [1400/3125]  eta: 0:10:03  Lr: 0.001875  Loss: -0.5765  Acc@1: 81.2500 (84.7966)  Acc@5: 100.0000 (98.2512)  time: 0.3496  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [1410/3125]  eta: 0:10:00  Lr: 0.001875  Loss: -0.4862  Acc@1: 81.2500 (84.7980)  Acc@5: 93.7500 (98.2371)  time: 0.3486  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [1420/3125]  eta: 0:09:56  Lr: 0.001875  Loss: -0.8050  Acc@1: 87.5000 (84.7994)  Acc@5: 100.0000 (98.2363)  time: 0.3486  data: 0.0007  max mem: 2502
Train: Epoch[2/5]  [1430/3125]  eta: 0:09:53  Lr: 0.001875  Loss: -0.4439  Acc@1: 87.5000 (84.8183)  Acc@5: 100.0000 (98.2399)  time: 0.3486  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [1440/3125]  eta: 0:09:49  Lr: 0.001875  Loss: -0.1665  Acc@1: 87.5000 (84.7892)  Acc@5: 100.0000 (98.2304)  time: 0.3486  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [1450/3125]  eta: 0:09:46  Lr: 0.001875  Loss: -0.5465  Acc@1: 81.2500 (84.7820)  Acc@5: 100.0000 (98.2383)  time: 0.3490  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [1460/3125]  eta: 0:09:42  Lr: 0.001875  Loss: -0.8478  Acc@1: 81.2500 (84.7579)  Acc@5: 100.0000 (98.2290)  time: 0.3492  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [1470/3125]  eta: 0:09:39  Lr: 0.001875  Loss: -0.6390  Acc@1: 87.5000 (84.7680)  Acc@5: 100.0000 (98.2367)  time: 0.3494  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [1480/3125]  eta: 0:09:35  Lr: 0.001875  Loss: -0.4306  Acc@1: 87.5000 (84.7696)  Acc@5: 100.0000 (98.2233)  time: 0.3494  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [1490/3125]  eta: 0:09:32  Lr: 0.001875  Loss: -0.6120  Acc@1: 81.2500 (84.8130)  Acc@5: 100.0000 (98.2311)  time: 0.3504  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [1500/3125]  eta: 0:09:28  Lr: 0.001875  Loss: -0.8996  Acc@1: 93.7500 (84.8434)  Acc@5: 100.0000 (98.2345)  time: 0.3505  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [1510/3125]  eta: 0:09:25  Lr: 0.001875  Loss: -0.7188  Acc@1: 87.5000 (84.8403)  Acc@5: 100.0000 (98.2421)  time: 0.3494  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [1520/3125]  eta: 0:09:21  Lr: 0.001875  Loss: -0.5583  Acc@1: 87.5000 (84.8455)  Acc@5: 100.0000 (98.2454)  time: 0.3495  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [1530/3125]  eta: 0:09:18  Lr: 0.001875  Loss: -0.2682  Acc@1: 81.2500 (84.8261)  Acc@5: 100.0000 (98.2487)  time: 0.3491  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [1540/3125]  eta: 0:09:14  Lr: 0.001875  Loss: -0.4897  Acc@1: 81.2500 (84.8110)  Acc@5: 100.0000 (98.2357)  time: 0.3493  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [1550/3125]  eta: 0:09:11  Lr: 0.001875  Loss: -0.5226  Acc@1: 87.5000 (84.8001)  Acc@5: 100.0000 (98.2390)  time: 0.3498  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [1560/3125]  eta: 0:09:07  Lr: 0.001875  Loss: -0.7446  Acc@1: 81.2500 (84.7894)  Acc@5: 100.0000 (98.2383)  time: 0.3494  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [1570/3125]  eta: 0:09:04  Lr: 0.001875  Loss: -0.7153  Acc@1: 81.2500 (84.7708)  Acc@5: 100.0000 (98.2495)  time: 0.3495  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [1580/3125]  eta: 0:09:00  Lr: 0.001875  Loss: -0.8562  Acc@1: 81.2500 (84.7644)  Acc@5: 100.0000 (98.2527)  time: 0.3497  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [1590/3125]  eta: 0:08:57  Lr: 0.001875  Loss: -0.6255  Acc@1: 87.5000 (84.7894)  Acc@5: 100.0000 (98.2597)  time: 0.3500  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [1600/3125]  eta: 0:08:53  Lr: 0.001875  Loss: -0.6853  Acc@1: 87.5000 (84.7829)  Acc@5: 100.0000 (98.2628)  time: 0.3502  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [1610/3125]  eta: 0:08:50  Lr: 0.001875  Loss: -0.4806  Acc@1: 87.5000 (84.7688)  Acc@5: 100.0000 (98.2581)  time: 0.3499  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [1620/3125]  eta: 0:08:46  Lr: 0.001875  Loss: -0.5732  Acc@1: 87.5000 (84.7625)  Acc@5: 100.0000 (98.2650)  time: 0.3497  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [1630/3125]  eta: 0:08:43  Lr: 0.001875  Loss: -0.8085  Acc@1: 81.2500 (84.7486)  Acc@5: 100.0000 (98.2641)  time: 0.3498  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [1640/3125]  eta: 0:08:39  Lr: 0.001875  Loss: -0.8460  Acc@1: 81.2500 (84.7463)  Acc@5: 100.0000 (98.2709)  time: 0.3508  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [1650/3125]  eta: 0:08:36  Lr: 0.001875  Loss: -0.3332  Acc@1: 87.5000 (84.7592)  Acc@5: 100.0000 (98.2586)  time: 0.3501  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [1660/3125]  eta: 0:08:32  Lr: 0.001875  Loss: -0.6308  Acc@1: 87.5000 (84.7494)  Acc@5: 100.0000 (98.2616)  time: 0.3491  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [1670/3125]  eta: 0:08:29  Lr: 0.001875  Loss: -0.2611  Acc@1: 87.5000 (84.7621)  Acc@5: 100.0000 (98.2683)  time: 0.3496  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [1680/3125]  eta: 0:08:25  Lr: 0.001875  Loss: -0.3927  Acc@1: 87.5000 (84.7858)  Acc@5: 100.0000 (98.2748)  time: 0.3506  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [1690/3125]  eta: 0:08:22  Lr: 0.001875  Loss: -0.8740  Acc@1: 87.5000 (84.8019)  Acc@5: 100.0000 (98.2850)  time: 0.3499  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [1700/3125]  eta: 0:08:18  Lr: 0.001875  Loss: -0.7657  Acc@1: 87.5000 (84.8178)  Acc@5: 100.0000 (98.2878)  time: 0.3478  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [1710/3125]  eta: 0:08:15  Lr: 0.001875  Loss: -0.2824  Acc@1: 87.5000 (84.8225)  Acc@5: 100.0000 (98.2868)  time: 0.3487  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [1720/3125]  eta: 0:08:11  Lr: 0.001875  Loss: -0.6590  Acc@1: 87.5000 (84.8199)  Acc@5: 100.0000 (98.2895)  time: 0.3499  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [1730/3125]  eta: 0:08:08  Lr: 0.001875  Loss: -0.4066  Acc@1: 81.2500 (84.7848)  Acc@5: 100.0000 (98.2813)  time: 0.3490  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [1740/3125]  eta: 0:08:04  Lr: 0.001875  Loss: -0.7369  Acc@1: 81.2500 (84.7789)  Acc@5: 100.0000 (98.2804)  time: 0.3484  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [1750/3125]  eta: 0:08:01  Lr: 0.001875  Loss: -0.5908  Acc@1: 81.2500 (84.7801)  Acc@5: 100.0000 (98.2903)  time: 0.3486  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [1760/3125]  eta: 0:07:57  Lr: 0.001875  Loss: -0.6800  Acc@1: 81.2500 (84.7814)  Acc@5: 100.0000 (98.2893)  time: 0.3486  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [1770/3125]  eta: 0:07:54  Lr: 0.001875  Loss: -0.4738  Acc@1: 81.2500 (84.7756)  Acc@5: 100.0000 (98.2849)  time: 0.3481  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [1780/3125]  eta: 0:07:50  Lr: 0.001875  Loss: -0.8453  Acc@1: 87.5000 (84.7908)  Acc@5: 100.0000 (98.2770)  time: 0.3479  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [1790/3125]  eta: 0:07:47  Lr: 0.001875  Loss: -0.6664  Acc@1: 87.5000 (84.7885)  Acc@5: 100.0000 (98.2726)  time: 0.3501  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [1800/3125]  eta: 0:07:43  Lr: 0.001875  Loss: -0.6548  Acc@1: 81.2500 (84.7862)  Acc@5: 100.0000 (98.2787)  time: 0.3486  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [1810/3125]  eta: 0:07:39  Lr: 0.001875  Loss: -0.5327  Acc@1: 87.5000 (84.7943)  Acc@5: 100.0000 (98.2848)  time: 0.3464  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [1820/3125]  eta: 0:07:36  Lr: 0.001875  Loss: -0.7643  Acc@1: 87.5000 (84.7851)  Acc@5: 100.0000 (98.2908)  time: 0.3475  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [1830/3125]  eta: 0:07:32  Lr: 0.001875  Loss: -0.7256  Acc@1: 87.5000 (84.8068)  Acc@5: 100.0000 (98.2967)  time: 0.3483  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [1840/3125]  eta: 0:07:29  Lr: 0.001875  Loss: -0.4163  Acc@1: 87.5000 (84.8180)  Acc@5: 100.0000 (98.2958)  time: 0.3495  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [1850/3125]  eta: 0:07:25  Lr: 0.001875  Loss: -0.7847  Acc@1: 87.5000 (84.8224)  Acc@5: 100.0000 (98.2948)  time: 0.3491  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [1860/3125]  eta: 0:07:22  Lr: 0.001875  Loss: -0.8532  Acc@1: 87.5000 (84.8368)  Acc@5: 100.0000 (98.2973)  time: 0.3484  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [1870/3125]  eta: 0:07:18  Lr: 0.001875  Loss: -0.5637  Acc@1: 87.5000 (84.8443)  Acc@5: 100.0000 (98.2964)  time: 0.3490  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [1880/3125]  eta: 0:07:15  Lr: 0.001875  Loss: -0.6202  Acc@1: 81.2500 (84.8252)  Acc@5: 100.0000 (98.2921)  time: 0.3489  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [1890/3125]  eta: 0:07:11  Lr: 0.001875  Loss: -0.7853  Acc@1: 87.5000 (84.8559)  Acc@5: 100.0000 (98.2879)  time: 0.3488  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [1900/3125]  eta: 0:07:08  Lr: 0.001875  Loss: -0.8259  Acc@1: 87.5000 (84.8632)  Acc@5: 100.0000 (98.2937)  time: 0.3489  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [1910/3125]  eta: 0:07:04  Lr: 0.001875  Loss: -0.6650  Acc@1: 87.5000 (84.8639)  Acc@5: 100.0000 (98.2928)  time: 0.3487  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [1920/3125]  eta: 0:07:01  Lr: 0.001875  Loss: -0.7637  Acc@1: 87.5000 (84.8712)  Acc@5: 100.0000 (98.2952)  time: 0.3499  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [1930/3125]  eta: 0:06:57  Lr: 0.001875  Loss: -0.4807  Acc@1: 81.2500 (84.8524)  Acc@5: 100.0000 (98.2878)  time: 0.3505  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [1940/3125]  eta: 0:06:54  Lr: 0.001875  Loss: -0.5402  Acc@1: 81.2500 (84.8499)  Acc@5: 100.0000 (98.2902)  time: 0.3496  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [1950/3125]  eta: 0:06:50  Lr: 0.001875  Loss: -0.8377  Acc@1: 87.5000 (84.8475)  Acc@5: 100.0000 (98.2925)  time: 0.3504  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [1960/3125]  eta: 0:06:47  Lr: 0.001875  Loss: -0.5883  Acc@1: 87.5000 (84.8579)  Acc@5: 100.0000 (98.2821)  time: 0.3503  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [1970/3125]  eta: 0:06:43  Lr: 0.001875  Loss: -0.3897  Acc@1: 87.5000 (84.8522)  Acc@5: 100.0000 (98.2845)  time: 0.3489  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [1980/3125]  eta: 0:06:40  Lr: 0.001875  Loss: -0.4134  Acc@1: 81.2500 (84.8498)  Acc@5: 100.0000 (98.2805)  time: 0.3483  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [1990/3125]  eta: 0:06:36  Lr: 0.001875  Loss: -0.8152  Acc@1: 81.2500 (84.8474)  Acc@5: 100.0000 (98.2766)  time: 0.3494  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [2000/3125]  eta: 0:06:33  Lr: 0.001875  Loss: -0.4443  Acc@1: 87.5000 (84.8420)  Acc@5: 100.0000 (98.2759)  time: 0.3507  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [2010/3125]  eta: 0:06:29  Lr: 0.001875  Loss: -0.2016  Acc@1: 87.5000 (84.8396)  Acc@5: 100.0000 (98.2720)  time: 0.3499  data: 0.0007  max mem: 2502
Train: Epoch[2/5]  [2020/3125]  eta: 0:06:26  Lr: 0.001875  Loss: -0.8048  Acc@1: 87.5000 (84.8435)  Acc@5: 100.0000 (98.2775)  time: 0.3494  data: 0.0007  max mem: 2502
Train: Epoch[2/5]  [2030/3125]  eta: 0:06:22  Lr: 0.001875  Loss: -0.7115  Acc@1: 81.2500 (84.8289)  Acc@5: 100.0000 (98.2675)  time: 0.3492  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [2040/3125]  eta: 0:06:19  Lr: 0.001875  Loss: -0.5660  Acc@1: 81.2500 (84.8389)  Acc@5: 100.0000 (98.2729)  time: 0.3490  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [2050/3125]  eta: 0:06:15  Lr: 0.001875  Loss: -0.7216  Acc@1: 87.5000 (84.8580)  Acc@5: 100.0000 (98.2691)  time: 0.3491  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [2060/3125]  eta: 0:06:12  Lr: 0.001875  Loss: -0.7040  Acc@1: 87.5000 (84.8526)  Acc@5: 100.0000 (98.2684)  time: 0.3485  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [2070/3125]  eta: 0:06:08  Lr: 0.001875  Loss: -0.8294  Acc@1: 81.2500 (84.8352)  Acc@5: 100.0000 (98.2647)  time: 0.3487  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [2080/3125]  eta: 0:06:05  Lr: 0.001875  Loss: -0.5006  Acc@1: 81.2500 (84.8180)  Acc@5: 100.0000 (98.2641)  time: 0.3494  data: 0.0002  max mem: 2502
Train: Epoch[2/5]  [2090/3125]  eta: 0:06:01  Lr: 0.001875  Loss: -0.4591  Acc@1: 81.2500 (84.8219)  Acc@5: 100.0000 (98.2664)  time: 0.3490  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [2100/3125]  eta: 0:05:58  Lr: 0.001875  Loss: -0.5911  Acc@1: 87.5000 (84.8227)  Acc@5: 100.0000 (98.2687)  time: 0.3493  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [2110/3125]  eta: 0:05:54  Lr: 0.001875  Loss: -0.8655  Acc@1: 87.5000 (84.8383)  Acc@5: 100.0000 (98.2710)  time: 0.3493  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [2120/3125]  eta: 0:05:51  Lr: 0.001875  Loss: 0.1150  Acc@1: 87.5000 (84.8362)  Acc@5: 100.0000 (98.2703)  time: 0.3494  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [2130/3125]  eta: 0:05:47  Lr: 0.001875  Loss: -0.6901  Acc@1: 81.2500 (84.8047)  Acc@5: 100.0000 (98.2667)  time: 0.3512  data: 0.0011  max mem: 2502
Train: Epoch[2/5]  [2140/3125]  eta: 0:05:44  Lr: 0.001875  Loss: -0.8299  Acc@1: 81.2500 (84.7997)  Acc@5: 100.0000 (98.2689)  time: 0.3513  data: 0.0011  max mem: 2502
Train: Epoch[2/5]  [2150/3125]  eta: 0:05:40  Lr: 0.001875  Loss: -0.8052  Acc@1: 81.2500 (84.8007)  Acc@5: 100.0000 (98.2653)  time: 0.3493  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [2160/3125]  eta: 0:05:37  Lr: 0.001875  Loss: -0.9252  Acc@1: 87.5000 (84.8189)  Acc@5: 100.0000 (98.2734)  time: 0.3487  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [2170/3125]  eta: 0:05:33  Lr: 0.001875  Loss: -0.3055  Acc@1: 87.5000 (84.8198)  Acc@5: 100.0000 (98.2698)  time: 0.3495  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [2180/3125]  eta: 0:05:30  Lr: 0.001875  Loss: -0.7963  Acc@1: 87.5000 (84.8321)  Acc@5: 100.0000 (98.2691)  time: 0.3500  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [2190/3125]  eta: 0:05:26  Lr: 0.001875  Loss: -0.4791  Acc@1: 87.5000 (84.8500)  Acc@5: 100.0000 (98.2742)  time: 0.3492  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [2200/3125]  eta: 0:05:23  Lr: 0.001875  Loss: -0.4203  Acc@1: 87.5000 (84.8393)  Acc@5: 100.0000 (98.2678)  time: 0.3482  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [2210/3125]  eta: 0:05:19  Lr: 0.001875  Loss: -0.1921  Acc@1: 81.2500 (84.8202)  Acc@5: 93.7500 (98.2587)  time: 0.3489  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [2220/3125]  eta: 0:05:16  Lr: 0.001875  Loss: -0.4123  Acc@1: 81.2500 (84.8154)  Acc@5: 100.0000 (98.2581)  time: 0.3492  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [2230/3125]  eta: 0:05:12  Lr: 0.001875  Loss: -0.6951  Acc@1: 81.2500 (84.8106)  Acc@5: 100.0000 (98.2575)  time: 0.3499  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [2240/3125]  eta: 0:05:09  Lr: 0.001875  Loss: -0.7989  Acc@1: 81.2500 (84.8087)  Acc@5: 100.0000 (98.2597)  time: 0.3500  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [2250/3125]  eta: 0:05:05  Lr: 0.001875  Loss: -0.6758  Acc@1: 87.5000 (84.8040)  Acc@5: 100.0000 (98.2591)  time: 0.3491  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [2260/3125]  eta: 0:05:02  Lr: 0.001875  Loss: 0.0952  Acc@1: 81.2500 (84.7966)  Acc@5: 100.0000 (98.2640)  time: 0.3493  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [2270/3125]  eta: 0:04:58  Lr: 0.001875  Loss: -0.8613  Acc@1: 87.5000 (84.8030)  Acc@5: 100.0000 (98.2662)  time: 0.3498  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [2280/3125]  eta: 0:04:55  Lr: 0.001875  Loss: -0.8213  Acc@1: 87.5000 (84.7956)  Acc@5: 100.0000 (98.2656)  time: 0.3498  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [2290/3125]  eta: 0:04:52  Lr: 0.001875  Loss: -0.7567  Acc@1: 81.2500 (84.7801)  Acc@5: 100.0000 (98.2622)  time: 0.3498  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [2300/3125]  eta: 0:04:48  Lr: 0.001875  Loss: -0.6058  Acc@1: 81.2500 (84.7811)  Acc@5: 100.0000 (98.2562)  time: 0.3502  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [2310/3125]  eta: 0:04:45  Lr: 0.001875  Loss: 0.2706  Acc@1: 81.2500 (84.7442)  Acc@5: 93.7500 (98.2475)  time: 0.3500  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [2320/3125]  eta: 0:04:41  Lr: 0.001875  Loss: -0.2146  Acc@1: 81.2500 (84.7318)  Acc@5: 93.7500 (98.2416)  time: 0.3497  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [2330/3125]  eta: 0:04:38  Lr: 0.001875  Loss: -0.9404  Acc@1: 87.5000 (84.7517)  Acc@5: 100.0000 (98.2465)  time: 0.3501  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [2340/3125]  eta: 0:04:34  Lr: 0.001875  Loss: -0.6681  Acc@1: 87.5000 (84.7554)  Acc@5: 100.0000 (98.2486)  time: 0.3509  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [2350/3125]  eta: 0:04:31  Lr: 0.001875  Loss: -0.3169  Acc@1: 81.2500 (84.7591)  Acc@5: 100.0000 (98.2507)  time: 0.3504  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [2360/3125]  eta: 0:04:27  Lr: 0.001875  Loss: -0.5837  Acc@1: 87.5000 (84.7602)  Acc@5: 100.0000 (98.2555)  time: 0.3505  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [2370/3125]  eta: 0:04:24  Lr: 0.001875  Loss: -0.6906  Acc@1: 81.2500 (84.7427)  Acc@5: 100.0000 (98.2602)  time: 0.3511  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [2380/3125]  eta: 0:04:20  Lr: 0.001875  Loss: -0.7549  Acc@1: 87.5000 (84.7622)  Acc@5: 100.0000 (98.2597)  time: 0.3501  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [2390/3125]  eta: 0:04:17  Lr: 0.001875  Loss: -0.5564  Acc@1: 87.5000 (84.7789)  Acc@5: 100.0000 (98.2643)  time: 0.3490  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [2400/3125]  eta: 0:04:13  Lr: 0.001875  Loss: -0.5435  Acc@1: 87.5000 (84.7850)  Acc@5: 100.0000 (98.2611)  time: 0.3490  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [2410/3125]  eta: 0:04:10  Lr: 0.001875  Loss: -0.1455  Acc@1: 87.5000 (84.7988)  Acc@5: 100.0000 (98.2632)  time: 0.3497  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [2420/3125]  eta: 0:04:06  Lr: 0.001875  Loss: -0.4301  Acc@1: 81.2500 (84.7868)  Acc@5: 100.0000 (98.2678)  time: 0.3496  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [2430/3125]  eta: 0:04:03  Lr: 0.001875  Loss: -0.7488  Acc@1: 87.5000 (84.8031)  Acc@5: 100.0000 (98.2697)  time: 0.3512  data: 0.0014  max mem: 2502
Train: Epoch[2/5]  [2440/3125]  eta: 0:03:59  Lr: 0.001875  Loss: -0.0214  Acc@1: 87.5000 (84.8116)  Acc@5: 100.0000 (98.2717)  time: 0.3510  data: 0.0013  max mem: 2502
Train: Epoch[2/5]  [2450/3125]  eta: 0:03:56  Lr: 0.001875  Loss: -0.7163  Acc@1: 87.5000 (84.8149)  Acc@5: 100.0000 (98.2762)  time: 0.3483  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [2460/3125]  eta: 0:03:52  Lr: 0.001875  Loss: -0.4806  Acc@1: 87.5000 (84.8055)  Acc@5: 100.0000 (98.2781)  time: 0.3489  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [2470/3125]  eta: 0:03:49  Lr: 0.001875  Loss: -0.5220  Acc@1: 81.2500 (84.8037)  Acc@5: 100.0000 (98.2750)  time: 0.3502  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [2480/3125]  eta: 0:03:45  Lr: 0.001875  Loss: -0.7566  Acc@1: 87.5000 (84.8045)  Acc@5: 100.0000 (98.2693)  time: 0.3494  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [2490/3125]  eta: 0:03:42  Lr: 0.001875  Loss: -0.2599  Acc@1: 87.5000 (84.8003)  Acc@5: 100.0000 (98.2663)  time: 0.3489  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [2500/3125]  eta: 0:03:38  Lr: 0.001875  Loss: -0.4542  Acc@1: 81.2500 (84.7986)  Acc@5: 100.0000 (98.2607)  time: 0.3496  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [2510/3125]  eta: 0:03:35  Lr: 0.001875  Loss: -0.7535  Acc@1: 87.5000 (84.7994)  Acc@5: 100.0000 (98.2651)  time: 0.3508  data: 0.0009  max mem: 2502
Train: Epoch[2/5]  [2520/3125]  eta: 0:03:31  Lr: 0.001875  Loss: -0.3283  Acc@1: 87.5000 (84.8002)  Acc@5: 100.0000 (98.2695)  time: 0.3509  data: 0.0009  max mem: 2502
Train: Epoch[2/5]  [2530/3125]  eta: 0:03:28  Lr: 0.001875  Loss: -0.3919  Acc@1: 87.5000 (84.8183)  Acc@5: 100.0000 (98.2739)  time: 0.3500  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [2540/3125]  eta: 0:03:24  Lr: 0.001875  Loss: -0.8255  Acc@1: 87.5000 (84.8116)  Acc@5: 100.0000 (98.2733)  time: 0.3499  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [2550/3125]  eta: 0:03:21  Lr: 0.001875  Loss: -0.5693  Acc@1: 81.2500 (84.8197)  Acc@5: 100.0000 (98.2752)  time: 0.3496  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [2560/3125]  eta: 0:03:17  Lr: 0.001875  Loss: -0.8288  Acc@1: 87.5000 (84.8277)  Acc@5: 100.0000 (98.2795)  time: 0.3489  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [2570/3125]  eta: 0:03:14  Lr: 0.001875  Loss: -0.6239  Acc@1: 87.5000 (84.8454)  Acc@5: 100.0000 (98.2862)  time: 0.3494  data: 0.0012  max mem: 2502
Train: Epoch[2/5]  [2580/3125]  eta: 0:03:10  Lr: 0.001875  Loss: -0.5833  Acc@1: 87.5000 (84.8508)  Acc@5: 100.0000 (98.2904)  time: 0.3505  data: 0.0012  max mem: 2502
Train: Epoch[2/5]  [2590/3125]  eta: 0:03:07  Lr: 0.001875  Loss: -0.7548  Acc@1: 87.5000 (84.8369)  Acc@5: 100.0000 (98.2873)  time: 0.3502  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [2600/3125]  eta: 0:03:03  Lr: 0.001875  Loss: -0.6918  Acc@1: 81.2500 (84.8304)  Acc@5: 100.0000 (98.2795)  time: 0.3506  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [2610/3125]  eta: 0:03:00  Lr: 0.001875  Loss: -0.7520  Acc@1: 87.5000 (84.8382)  Acc@5: 100.0000 (98.2861)  time: 0.3509  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [2620/3125]  eta: 0:02:56  Lr: 0.001875  Loss: -0.6127  Acc@1: 87.5000 (84.8316)  Acc@5: 100.0000 (98.2926)  time: 0.3499  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [2630/3125]  eta: 0:02:53  Lr: 0.001875  Loss: -0.7778  Acc@1: 81.2500 (84.8252)  Acc@5: 100.0000 (98.2991)  time: 0.3503  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [2640/3125]  eta: 0:02:49  Lr: 0.001875  Loss: -0.7484  Acc@1: 81.2500 (84.8235)  Acc@5: 100.0000 (98.2937)  time: 0.3517  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [2650/3125]  eta: 0:02:46  Lr: 0.001875  Loss: -0.8732  Acc@1: 87.5000 (84.8194)  Acc@5: 100.0000 (98.2931)  time: 0.3516  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [2660/3125]  eta: 0:02:42  Lr: 0.001875  Loss: -0.9249  Acc@1: 87.5000 (84.8295)  Acc@5: 100.0000 (98.2948)  time: 0.3518  data: 0.0012  max mem: 2502
Train: Epoch[2/5]  [2670/3125]  eta: 0:02:39  Lr: 0.001875  Loss: -0.7172  Acc@1: 87.5000 (84.8231)  Acc@5: 100.0000 (98.2918)  time: 0.3511  data: 0.0012  max mem: 2502
Train: Epoch[2/5]  [2680/3125]  eta: 0:02:35  Lr: 0.001875  Loss: -0.6244  Acc@1: 87.5000 (84.8238)  Acc@5: 100.0000 (98.2935)  time: 0.3498  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [2690/3125]  eta: 0:02:32  Lr: 0.001875  Loss: -0.7540  Acc@1: 87.5000 (84.8291)  Acc@5: 100.0000 (98.2952)  time: 0.3498  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [2700/3125]  eta: 0:02:28  Lr: 0.001875  Loss: -0.5258  Acc@1: 87.5000 (84.8297)  Acc@5: 100.0000 (98.2900)  time: 0.3490  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [2710/3125]  eta: 0:02:25  Lr: 0.001875  Loss: -0.7019  Acc@1: 93.7500 (84.8488)  Acc@5: 100.0000 (98.2963)  time: 0.3503  data: 0.0014  max mem: 2502
Train: Epoch[2/5]  [2720/3125]  eta: 0:02:21  Lr: 0.001875  Loss: -0.4579  Acc@1: 93.7500 (84.8654)  Acc@5: 100.0000 (98.2934)  time: 0.3508  data: 0.0014  max mem: 2502
Train: Epoch[2/5]  [2730/3125]  eta: 0:02:18  Lr: 0.001875  Loss: -0.6820  Acc@1: 87.5000 (84.8728)  Acc@5: 100.0000 (98.2905)  time: 0.3498  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [2740/3125]  eta: 0:02:14  Lr: 0.001875  Loss: -0.6518  Acc@1: 87.5000 (84.8801)  Acc@5: 100.0000 (98.2944)  time: 0.3498  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [2750/3125]  eta: 0:02:11  Lr: 0.001875  Loss: -0.3166  Acc@1: 87.5000 (84.8919)  Acc@5: 100.0000 (98.2915)  time: 0.3501  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [2760/3125]  eta: 0:02:07  Lr: 0.001875  Loss: -0.7544  Acc@1: 87.5000 (84.9104)  Acc@5: 100.0000 (98.2932)  time: 0.3503  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [2770/3125]  eta: 0:02:04  Lr: 0.001875  Loss: -0.7812  Acc@1: 87.5000 (84.9174)  Acc@5: 100.0000 (98.2971)  time: 0.3498  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [2780/3125]  eta: 0:02:00  Lr: 0.001875  Loss: -0.7899  Acc@1: 87.5000 (84.9222)  Acc@5: 100.0000 (98.3010)  time: 0.3497  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [2790/3125]  eta: 0:01:57  Lr: 0.001875  Loss: -0.8803  Acc@1: 87.5000 (84.9292)  Acc@5: 100.0000 (98.3048)  time: 0.3499  data: 0.0009  max mem: 2502
Train: Epoch[2/5]  [2800/3125]  eta: 0:01:53  Lr: 0.001875  Loss: -0.4871  Acc@1: 81.2500 (84.9206)  Acc@5: 100.0000 (98.3064)  time: 0.3504  data: 0.0009  max mem: 2502
Train: Epoch[2/5]  [2810/3125]  eta: 0:01:50  Lr: 0.001875  Loss: -0.4122  Acc@1: 81.2500 (84.9142)  Acc@5: 100.0000 (98.3102)  time: 0.3496  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [2820/3125]  eta: 0:01:46  Lr: 0.001875  Loss: -0.7810  Acc@1: 87.5000 (84.9233)  Acc@5: 100.0000 (98.3096)  time: 0.3488  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [2830/3125]  eta: 0:01:43  Lr: 0.001875  Loss: -0.5082  Acc@1: 87.5000 (84.9347)  Acc@5: 100.0000 (98.3067)  time: 0.3496  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [2840/3125]  eta: 0:01:39  Lr: 0.001875  Loss: -0.3706  Acc@1: 87.5000 (84.9349)  Acc@5: 100.0000 (98.3083)  time: 0.3514  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [2850/3125]  eta: 0:01:36  Lr: 0.001875  Loss: -0.4880  Acc@1: 87.5000 (84.9483)  Acc@5: 100.0000 (98.3076)  time: 0.3517  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [2860/3125]  eta: 0:01:32  Lr: 0.001875  Loss: -0.4611  Acc@1: 87.5000 (84.9506)  Acc@5: 100.0000 (98.3092)  time: 0.3507  data: 0.0010  max mem: 2502
Train: Epoch[2/5]  [2870/3125]  eta: 0:01:29  Lr: 0.001875  Loss: -0.7704  Acc@1: 87.5000 (84.9508)  Acc@5: 100.0000 (98.3107)  time: 0.3500  data: 0.0010  max mem: 2502
Train: Epoch[2/5]  [2880/3125]  eta: 0:01:25  Lr: 0.001875  Loss: -0.7510  Acc@1: 87.5000 (84.9705)  Acc@5: 100.0000 (98.3122)  time: 0.3494  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [2890/3125]  eta: 0:01:22  Lr: 0.001875  Loss: -0.5348  Acc@1: 87.5000 (84.9792)  Acc@5: 100.0000 (98.3116)  time: 0.3491  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [2900/3125]  eta: 0:01:18  Lr: 0.001875  Loss: -0.4417  Acc@1: 87.5000 (84.9815)  Acc@5: 100.0000 (98.3131)  time: 0.3501  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [2910/3125]  eta: 0:01:15  Lr: 0.001875  Loss: -0.8051  Acc@1: 87.5000 (84.9708)  Acc@5: 100.0000 (98.3189)  time: 0.3497  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [2920/3125]  eta: 0:01:11  Lr: 0.001875  Loss: -0.4062  Acc@1: 81.2500 (84.9623)  Acc@5: 100.0000 (98.3161)  time: 0.3487  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [2930/3125]  eta: 0:01:08  Lr: 0.001875  Loss: -0.2287  Acc@1: 81.2500 (84.9497)  Acc@5: 100.0000 (98.3176)  time: 0.3492  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [2940/3125]  eta: 0:01:04  Lr: 0.001875  Loss: -0.7196  Acc@1: 81.2500 (84.9520)  Acc@5: 100.0000 (98.3211)  time: 0.3491  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [2950/3125]  eta: 0:01:01  Lr: 0.001875  Loss: -0.8919  Acc@1: 87.5000 (84.9648)  Acc@5: 100.0000 (98.3226)  time: 0.3491  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [2960/3125]  eta: 0:00:57  Lr: 0.001875  Loss: -1.0032  Acc@1: 87.5000 (84.9755)  Acc@5: 100.0000 (98.3240)  time: 0.3490  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [2970/3125]  eta: 0:00:54  Lr: 0.001875  Loss: -0.8141  Acc@1: 87.5000 (84.9882)  Acc@5: 100.0000 (98.3234)  time: 0.3506  data: 0.0011  max mem: 2502
Train: Epoch[2/5]  [2980/3125]  eta: 0:00:50  Lr: 0.001875  Loss: -0.5455  Acc@1: 81.2500 (84.9799)  Acc@5: 100.0000 (98.3248)  time: 0.3517  data: 0.0011  max mem: 2502
Train: Epoch[2/5]  [2990/3125]  eta: 0:00:47  Lr: 0.001875  Loss: -0.4597  Acc@1: 87.5000 (84.9987)  Acc@5: 100.0000 (98.3283)  time: 0.3507  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [3000/3125]  eta: 0:00:43  Lr: 0.001875  Loss: -0.7299  Acc@1: 87.5000 (84.9967)  Acc@5: 100.0000 (98.3318)  time: 0.3501  data: 0.0014  max mem: 2502
Train: Epoch[2/5]  [3010/3125]  eta: 0:00:40  Lr: 0.001875  Loss: -0.6091  Acc@1: 81.2500 (84.9946)  Acc@5: 100.0000 (98.3332)  time: 0.3494  data: 0.0012  max mem: 2502
Train: Epoch[2/5]  [3020/3125]  eta: 0:00:36  Lr: 0.001875  Loss: -0.3650  Acc@1: 81.2500 (84.9863)  Acc@5: 100.0000 (98.3325)  time: 0.3501  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [3030/3125]  eta: 0:00:33  Lr: 0.001875  Loss: -0.2124  Acc@1: 87.5000 (84.9885)  Acc@5: 100.0000 (98.3277)  time: 0.3506  data: 0.0007  max mem: 2502
Train: Epoch[2/5]  [3040/3125]  eta: 0:00:29  Lr: 0.001875  Loss: -0.7333  Acc@1: 87.5000 (84.9885)  Acc@5: 100.0000 (98.3291)  time: 0.3500  data: 0.0012  max mem: 2502
Train: Epoch[2/5]  [3050/3125]  eta: 0:00:26  Lr: 0.001875  Loss: -0.5250  Acc@1: 87.5000 (84.9988)  Acc@5: 100.0000 (98.3305)  time: 0.3500  data: 0.0010  max mem: 2502
Train: Epoch[2/5]  [3060/3125]  eta: 0:00:22  Lr: 0.001875  Loss: -0.5351  Acc@1: 81.2500 (84.9926)  Acc@5: 100.0000 (98.3298)  time: 0.3496  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [3070/3125]  eta: 0:00:19  Lr: 0.001875  Loss: -0.5393  Acc@1: 87.5000 (85.0049)  Acc@5: 100.0000 (98.3271)  time: 0.3493  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [3080/3125]  eta: 0:00:15  Lr: 0.001875  Loss: -0.8781  Acc@1: 87.5000 (85.0008)  Acc@5: 100.0000 (98.3264)  time: 0.3489  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [3090/3125]  eta: 0:00:12  Lr: 0.001875  Loss: -0.8421  Acc@1: 87.5000 (85.0190)  Acc@5: 100.0000 (98.3298)  time: 0.3487  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [3100/3125]  eta: 0:00:08  Lr: 0.001875  Loss: -0.5875  Acc@1: 87.5000 (85.0230)  Acc@5: 100.0000 (98.3332)  time: 0.3517  data: 0.0020  max mem: 2502
Train: Epoch[2/5]  [3110/3125]  eta: 0:00:05  Lr: 0.001875  Loss: -0.7405  Acc@1: 87.5000 (85.0189)  Acc@5: 100.0000 (98.3345)  time: 0.3519  data: 0.0021  max mem: 2502
Train: Epoch[2/5]  [3120/3125]  eta: 0:00:01  Lr: 0.001875  Loss: -0.5537  Acc@1: 87.5000 (85.0268)  Acc@5: 100.0000 (98.3359)  time: 0.3498  data: 0.0010  max mem: 2502
Train: Epoch[2/5]  [3124/3125]  eta: 0:00:00  Lr: 0.001875  Loss: -0.7877  Acc@1: 87.5000 (85.0360)  Acc@5: 100.0000 (98.3380)  time: 0.3501  data: 0.0009  max mem: 2502
Train: Epoch[2/5] Total time: 0:18:13 (0.3500 s / it)
Averaged stats: Lr: 0.001875  Loss: -0.7877  Acc@1: 87.5000 (85.0360)  Acc@5: 100.0000 (98.3380)
Train: Epoch[3/5]  [   0/3125]  eta: 0:36:31  Lr: 0.001875  Loss: -0.8925  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)  time: 0.7014  data: 0.3499  max mem: 2502
Train: Epoch[3/5]  [  10/3125]  eta: 0:19:46  Lr: 0.001875  Loss: -0.7271  Acc@1: 87.5000 (84.6591)  Acc@5: 100.0000 (98.8636)  time: 0.3808  data: 0.0322  max mem: 2502
Train: Epoch[3/5]  [  20/3125]  eta: 0:18:55  Lr: 0.001875  Loss: -0.9450  Acc@1: 81.2500 (84.5238)  Acc@5: 100.0000 (98.8095)  time: 0.3490  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [  30/3125]  eta: 0:18:36  Lr: 0.001875  Loss: -0.6303  Acc@1: 87.5000 (85.0806)  Acc@5: 100.0000 (98.5887)  time: 0.3499  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [  40/3125]  eta: 0:18:23  Lr: 0.001875  Loss: -0.5895  Acc@1: 87.5000 (85.0610)  Acc@5: 100.0000 (98.3232)  time: 0.3491  data: 0.0006  max mem: 2502
Train: Epoch[3/5]  [  50/3125]  eta: 0:18:14  Lr: 0.001875  Loss: -0.8440  Acc@1: 87.5000 (85.7843)  Acc@5: 100.0000 (98.6520)  time: 0.3485  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [  60/3125]  eta: 0:18:07  Lr: 0.001875  Loss: -0.6646  Acc@1: 87.5000 (86.0656)  Acc@5: 100.0000 (98.4631)  time: 0.3494  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [  70/3125]  eta: 0:18:02  Lr: 0.001875  Loss: -0.4893  Acc@1: 81.2500 (85.5634)  Acc@5: 100.0000 (98.1514)  time: 0.3495  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [  80/3125]  eta: 0:17:57  Lr: 0.001875  Loss: -0.6366  Acc@1: 81.2500 (85.7253)  Acc@5: 100.0000 (98.3796)  time: 0.3501  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [  90/3125]  eta: 0:17:52  Lr: 0.001875  Loss: -0.8286  Acc@1: 81.2500 (85.2335)  Acc@5: 100.0000 (98.4203)  time: 0.3500  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [ 100/3125]  eta: 0:17:47  Lr: 0.001875  Loss: -0.6722  Acc@1: 81.2500 (85.3342)  Acc@5: 100.0000 (98.3911)  time: 0.3497  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [ 110/3125]  eta: 0:17:43  Lr: 0.001875  Loss: -0.7443  Acc@1: 87.5000 (85.8671)  Acc@5: 100.0000 (98.4797)  time: 0.3498  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [ 120/3125]  eta: 0:17:38  Lr: 0.001875  Loss: -0.5048  Acc@1: 87.5000 (86.2603)  Acc@5: 100.0000 (98.3988)  time: 0.3496  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [ 130/3125]  eta: 0:17:35  Lr: 0.001875  Loss: -0.4458  Acc@1: 87.5000 (86.1164)  Acc@5: 100.0000 (98.4256)  time: 0.3504  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [ 140/3125]  eta: 0:17:31  Lr: 0.001875  Loss: -0.7983  Acc@1: 87.5000 (86.3918)  Acc@5: 100.0000 (98.4043)  time: 0.3511  data: 0.0012  max mem: 2502
Train: Epoch[3/5]  [ 150/3125]  eta: 0:17:27  Lr: 0.001875  Loss: -0.7381  Acc@1: 87.5000 (86.4238)  Acc@5: 100.0000 (98.3444)  time: 0.3506  data: 0.0014  max mem: 2502
Train: Epoch[3/5]  [ 160/3125]  eta: 0:17:23  Lr: 0.001875  Loss: -0.6869  Acc@1: 81.2500 (86.1025)  Acc@5: 100.0000 (98.3307)  time: 0.3499  data: 0.0011  max mem: 2502
Train: Epoch[3/5]  [ 170/3125]  eta: 0:17:19  Lr: 0.001875  Loss: -0.1084  Acc@1: 87.5000 (86.0015)  Acc@5: 100.0000 (98.3918)  time: 0.3496  data: 0.0008  max mem: 2502
Train: Epoch[3/5]  [ 180/3125]  eta: 0:17:15  Lr: 0.001875  Loss: -0.6945  Acc@1: 87.5000 (85.7044)  Acc@5: 100.0000 (98.4116)  time: 0.3490  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [ 190/3125]  eta: 0:17:11  Lr: 0.001875  Loss: -0.7759  Acc@1: 81.2500 (85.5366)  Acc@5: 100.0000 (98.4293)  time: 0.3484  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [ 200/3125]  eta: 0:17:07  Lr: 0.001875  Loss: -0.7138  Acc@1: 87.5000 (85.6343)  Acc@5: 100.0000 (98.4142)  time: 0.3499  data: 0.0014  max mem: 2502
Train: Epoch[3/5]  [ 210/3125]  eta: 0:17:04  Lr: 0.001875  Loss: -0.3853  Acc@1: 87.5000 (85.5154)  Acc@5: 100.0000 (98.4597)  time: 0.3510  data: 0.0014  max mem: 2502
Train: Epoch[3/5]  [ 220/3125]  eta: 0:17:00  Lr: 0.001875  Loss: -0.4703  Acc@1: 81.2500 (85.3224)  Acc@5: 100.0000 (98.4729)  time: 0.3512  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [ 230/3125]  eta: 0:16:57  Lr: 0.001875  Loss: -0.5717  Acc@1: 81.2500 (85.2273)  Acc@5: 100.0000 (98.4307)  time: 0.3506  data: 0.0008  max mem: 2502
Train: Epoch[3/5]  [ 240/3125]  eta: 0:16:53  Lr: 0.001875  Loss: -0.7458  Acc@1: 87.5000 (85.2697)  Acc@5: 100.0000 (98.4440)  time: 0.3485  data: 0.0007  max mem: 2502
Train: Epoch[3/5]  [ 250/3125]  eta: 0:16:49  Lr: 0.001875  Loss: -0.8394  Acc@1: 87.5000 (85.4333)  Acc@5: 100.0000 (98.4811)  time: 0.3478  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [ 260/3125]  eta: 0:16:45  Lr: 0.001875  Loss: -0.0870  Acc@1: 87.5000 (85.2490)  Acc@5: 100.0000 (98.4435)  time: 0.3480  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [ 270/3125]  eta: 0:16:41  Lr: 0.001875  Loss: -0.1748  Acc@1: 81.2500 (85.2629)  Acc@5: 100.0000 (98.3856)  time: 0.3488  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [ 280/3125]  eta: 0:16:37  Lr: 0.001875  Loss: -0.6898  Acc@1: 87.5000 (85.4982)  Acc@5: 100.0000 (98.4208)  time: 0.3491  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [ 290/3125]  eta: 0:16:34  Lr: 0.001875  Loss: 0.0493  Acc@1: 87.5000 (85.4811)  Acc@5: 100.0000 (98.4107)  time: 0.3486  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [ 300/3125]  eta: 0:16:30  Lr: 0.001875  Loss: -0.7881  Acc@1: 87.5000 (85.5689)  Acc@5: 100.0000 (98.4427)  time: 0.3488  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [ 310/3125]  eta: 0:16:26  Lr: 0.001875  Loss: -0.9063  Acc@1: 87.5000 (85.6511)  Acc@5: 100.0000 (98.4727)  time: 0.3489  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [ 320/3125]  eta: 0:16:23  Lr: 0.001875  Loss: -0.6664  Acc@1: 87.5000 (85.5724)  Acc@5: 100.0000 (98.4813)  time: 0.3500  data: 0.0011  max mem: 2502
Train: Epoch[3/5]  [ 330/3125]  eta: 0:16:19  Lr: 0.001875  Loss: -0.8846  Acc@1: 87.5000 (85.4985)  Acc@5: 100.0000 (98.3950)  time: 0.3495  data: 0.0011  max mem: 2502
Train: Epoch[3/5]  [ 340/3125]  eta: 0:16:16  Lr: 0.001875  Loss: -0.6676  Acc@1: 87.5000 (85.5572)  Acc@5: 100.0000 (98.4054)  time: 0.3478  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [ 350/3125]  eta: 0:16:12  Lr: 0.001875  Loss: -0.7432  Acc@1: 87.5000 (85.4523)  Acc@5: 100.0000 (98.3974)  time: 0.3482  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [ 360/3125]  eta: 0:16:08  Lr: 0.001875  Loss: -0.3658  Acc@1: 75.0000 (85.2493)  Acc@5: 100.0000 (98.3726)  time: 0.3485  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [ 370/3125]  eta: 0:16:05  Lr: 0.001875  Loss: -0.9451  Acc@1: 81.2500 (85.3437)  Acc@5: 100.0000 (98.3996)  time: 0.3490  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [ 380/3125]  eta: 0:16:01  Lr: 0.001875  Loss: -0.8442  Acc@1: 87.5000 (85.2854)  Acc@5: 100.0000 (98.4252)  time: 0.3485  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [ 390/3125]  eta: 0:15:57  Lr: 0.001875  Loss: -0.4989  Acc@1: 87.5000 (85.1822)  Acc@5: 100.0000 (98.4015)  time: 0.3470  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [ 400/3125]  eta: 0:15:53  Lr: 0.001875  Loss: -0.5837  Acc@1: 87.5000 (85.2556)  Acc@5: 100.0000 (98.3946)  time: 0.3469  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [ 410/3125]  eta: 0:15:50  Lr: 0.001875  Loss: -0.6428  Acc@1: 87.5000 (85.2798)  Acc@5: 100.0000 (98.4033)  time: 0.3481  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [ 420/3125]  eta: 0:15:46  Lr: 0.001875  Loss: -0.4628  Acc@1: 87.5000 (85.2880)  Acc@5: 100.0000 (98.3967)  time: 0.3486  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [ 430/3125]  eta: 0:15:43  Lr: 0.001875  Loss: -0.7808  Acc@1: 87.5000 (85.3828)  Acc@5: 100.0000 (98.4194)  time: 0.3484  data: 0.0010  max mem: 2502
Train: Epoch[3/5]  [ 440/3125]  eta: 0:15:39  Lr: 0.001875  Loss: -0.9378  Acc@1: 87.5000 (85.2608)  Acc@5: 100.0000 (98.4410)  time: 0.3479  data: 0.0012  max mem: 2502
Train: Epoch[3/5]  [ 450/3125]  eta: 0:15:35  Lr: 0.001875  Loss: -0.7385  Acc@1: 87.5000 (85.3381)  Acc@5: 100.0000 (98.4618)  time: 0.3478  data: 0.0006  max mem: 2502
Train: Epoch[3/5]  [ 460/3125]  eta: 0:15:32  Lr: 0.001875  Loss: -0.7148  Acc@1: 87.5000 (85.4121)  Acc@5: 100.0000 (98.4544)  time: 0.3487  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [ 470/3125]  eta: 0:15:28  Lr: 0.001875  Loss: -0.8368  Acc@1: 87.5000 (85.3503)  Acc@5: 100.0000 (98.4342)  time: 0.3493  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [ 480/3125]  eta: 0:15:25  Lr: 0.001875  Loss: -0.7126  Acc@1: 81.2500 (85.3690)  Acc@5: 100.0000 (98.4537)  time: 0.3486  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [ 490/3125]  eta: 0:15:21  Lr: 0.001875  Loss: -0.8930  Acc@1: 87.5000 (85.3870)  Acc@5: 100.0000 (98.4470)  time: 0.3482  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [ 500/3125]  eta: 0:15:18  Lr: 0.001875  Loss: -0.5044  Acc@1: 87.5000 (85.4042)  Acc@5: 100.0000 (98.4281)  time: 0.3496  data: 0.0011  max mem: 2502
Train: Epoch[3/5]  [ 510/3125]  eta: 0:15:14  Lr: 0.001875  Loss: -0.7041  Acc@1: 87.5000 (85.4452)  Acc@5: 100.0000 (98.4222)  time: 0.3499  data: 0.0011  max mem: 2502
Train: Epoch[3/5]  [ 520/3125]  eta: 0:15:11  Lr: 0.001875  Loss: -0.2979  Acc@1: 87.5000 (85.4846)  Acc@5: 100.0000 (98.4165)  time: 0.3493  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [ 530/3125]  eta: 0:15:07  Lr: 0.001875  Loss: -0.4357  Acc@1: 87.5000 (85.4873)  Acc@5: 100.0000 (98.4346)  time: 0.3497  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [ 540/3125]  eta: 0:15:04  Lr: 0.001875  Loss: -0.3124  Acc@1: 93.7500 (85.5938)  Acc@5: 100.0000 (98.4288)  time: 0.3500  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [ 550/3125]  eta: 0:15:00  Lr: 0.001875  Loss: -0.8939  Acc@1: 93.7500 (85.6851)  Acc@5: 100.0000 (98.4460)  time: 0.3493  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [ 560/3125]  eta: 0:14:57  Lr: 0.001875  Loss: -0.6884  Acc@1: 87.5000 (85.7398)  Acc@5: 100.0000 (98.4737)  time: 0.3494  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [ 570/3125]  eta: 0:14:53  Lr: 0.001875  Loss: -0.6947  Acc@1: 93.7500 (85.8363)  Acc@5: 100.0000 (98.4895)  time: 0.3498  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [ 580/3125]  eta: 0:14:50  Lr: 0.001875  Loss: -0.7525  Acc@1: 87.5000 (85.8434)  Acc@5: 100.0000 (98.4940)  time: 0.3499  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [ 590/3125]  eta: 0:14:46  Lr: 0.001875  Loss: -0.5595  Acc@1: 87.5000 (85.8926)  Acc@5: 100.0000 (98.4983)  time: 0.3497  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [ 600/3125]  eta: 0:14:43  Lr: 0.001875  Loss: -0.5595  Acc@1: 87.5000 (85.8985)  Acc@5: 100.0000 (98.5129)  time: 0.3495  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [ 610/3125]  eta: 0:14:39  Lr: 0.001875  Loss: -0.7987  Acc@1: 87.5000 (85.9145)  Acc@5: 100.0000 (98.5168)  time: 0.3497  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [ 620/3125]  eta: 0:14:36  Lr: 0.001875  Loss: -0.6352  Acc@1: 87.5000 (85.9501)  Acc@5: 100.0000 (98.5306)  time: 0.3498  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [ 630/3125]  eta: 0:14:32  Lr: 0.001875  Loss: -0.5240  Acc@1: 87.5000 (85.9152)  Acc@5: 100.0000 (98.5341)  time: 0.3501  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [ 640/3125]  eta: 0:14:29  Lr: 0.001875  Loss: -0.3150  Acc@1: 87.5000 (85.9107)  Acc@5: 100.0000 (98.5277)  time: 0.3502  data: 0.0010  max mem: 2502
Train: Epoch[3/5]  [ 650/3125]  eta: 0:14:25  Lr: 0.001875  Loss: -0.6437  Acc@1: 87.5000 (85.8775)  Acc@5: 100.0000 (98.5407)  time: 0.3500  data: 0.0010  max mem: 2502
Train: Epoch[3/5]  [ 660/3125]  eta: 0:14:22  Lr: 0.001875  Loss: -0.8223  Acc@1: 87.5000 (85.9115)  Acc@5: 100.0000 (98.5533)  time: 0.3491  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [ 670/3125]  eta: 0:14:18  Lr: 0.001875  Loss: -0.6290  Acc@1: 81.2500 (85.8793)  Acc@5: 100.0000 (98.5376)  time: 0.3500  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [ 680/3125]  eta: 0:14:15  Lr: 0.001875  Loss: -0.8459  Acc@1: 81.2500 (85.8297)  Acc@5: 100.0000 (98.5316)  time: 0.3506  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [ 690/3125]  eta: 0:14:11  Lr: 0.001875  Loss: -0.4772  Acc@1: 87.5000 (85.8629)  Acc@5: 100.0000 (98.5257)  time: 0.3499  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [ 700/3125]  eta: 0:14:08  Lr: 0.001875  Loss: -0.3874  Acc@1: 87.5000 (85.8862)  Acc@5: 100.0000 (98.5378)  time: 0.3509  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [ 710/3125]  eta: 0:14:04  Lr: 0.001875  Loss: -0.7762  Acc@1: 81.2500 (85.8826)  Acc@5: 100.0000 (98.5496)  time: 0.3507  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [ 720/3125]  eta: 0:14:01  Lr: 0.001875  Loss: -0.3779  Acc@1: 87.5000 (85.8790)  Acc@5: 100.0000 (98.5610)  time: 0.3498  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [ 730/3125]  eta: 0:13:57  Lr: 0.001875  Loss: -0.3858  Acc@1: 87.5000 (85.8841)  Acc@5: 100.0000 (98.5636)  time: 0.3502  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [ 740/3125]  eta: 0:13:54  Lr: 0.001875  Loss: -0.7683  Acc@1: 87.5000 (85.9733)  Acc@5: 100.0000 (98.5830)  time: 0.3503  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [ 750/3125]  eta: 0:13:50  Lr: 0.001875  Loss: -0.8529  Acc@1: 87.5000 (85.9354)  Acc@5: 100.0000 (98.5769)  time: 0.3506  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [ 760/3125]  eta: 0:13:47  Lr: 0.001875  Loss: -0.7347  Acc@1: 81.2500 (85.9313)  Acc@5: 100.0000 (98.5792)  time: 0.3507  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [ 770/3125]  eta: 0:13:43  Lr: 0.001875  Loss: -0.5858  Acc@1: 87.5000 (85.9355)  Acc@5: 100.0000 (98.5733)  time: 0.3500  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [ 780/3125]  eta: 0:13:40  Lr: 0.001875  Loss: -0.5132  Acc@1: 87.5000 (85.9075)  Acc@5: 100.0000 (98.5595)  time: 0.3490  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [ 790/3125]  eta: 0:13:36  Lr: 0.001875  Loss: -0.9158  Acc@1: 87.5000 (85.9355)  Acc@5: 100.0000 (98.5382)  time: 0.3480  data: 0.0002  max mem: 2502
Train: Epoch[3/5]  [ 800/3125]  eta: 0:13:33  Lr: 0.001875  Loss: -0.4035  Acc@1: 87.5000 (85.9395)  Acc@5: 100.0000 (98.5409)  time: 0.3480  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [ 810/3125]  eta: 0:13:29  Lr: 0.001875  Loss: -0.8964  Acc@1: 87.5000 (85.9895)  Acc@5: 100.0000 (98.5435)  time: 0.3490  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [ 820/3125]  eta: 0:13:26  Lr: 0.001875  Loss: -0.8520  Acc@1: 87.5000 (85.9927)  Acc@5: 100.0000 (98.5536)  time: 0.3497  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [ 830/3125]  eta: 0:13:22  Lr: 0.001875  Loss: -0.5123  Acc@1: 87.5000 (85.9507)  Acc@5: 100.0000 (98.5484)  time: 0.3496  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [ 840/3125]  eta: 0:13:19  Lr: 0.001875  Loss: -0.6953  Acc@1: 87.5000 (85.9691)  Acc@5: 100.0000 (98.5508)  time: 0.3485  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [ 850/3125]  eta: 0:13:15  Lr: 0.001875  Loss: -0.6234  Acc@1: 87.5000 (85.9136)  Acc@5: 100.0000 (98.5679)  time: 0.3477  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [ 860/3125]  eta: 0:13:12  Lr: 0.001875  Loss: -0.7022  Acc@1: 87.5000 (85.9103)  Acc@5: 100.0000 (98.5772)  time: 0.3475  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [ 870/3125]  eta: 0:13:08  Lr: 0.001875  Loss: -0.4368  Acc@1: 87.5000 (85.8927)  Acc@5: 100.0000 (98.5936)  time: 0.3478  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [ 880/3125]  eta: 0:13:04  Lr: 0.001875  Loss: -0.9035  Acc@1: 81.2500 (85.9038)  Acc@5: 100.0000 (98.5953)  time: 0.3477  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [ 890/3125]  eta: 0:13:01  Lr: 0.001875  Loss: -0.2144  Acc@1: 87.5000 (85.9357)  Acc@5: 100.0000 (98.5971)  time: 0.3465  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [ 900/3125]  eta: 0:12:57  Lr: 0.001875  Loss: -0.4539  Acc@1: 87.5000 (85.9046)  Acc@5: 100.0000 (98.5710)  time: 0.3467  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [ 910/3125]  eta: 0:12:54  Lr: 0.001875  Loss: -0.4214  Acc@1: 81.2500 (85.8192)  Acc@5: 100.0000 (98.5730)  time: 0.3488  data: 0.0011  max mem: 2502
Train: Epoch[3/5]  [ 920/3125]  eta: 0:12:50  Lr: 0.001875  Loss: -0.6817  Acc@1: 81.2500 (85.8103)  Acc@5: 100.0000 (98.5478)  time: 0.3493  data: 0.0011  max mem: 2502
Train: Epoch[3/5]  [ 930/3125]  eta: 0:12:47  Lr: 0.001875  Loss: -0.8004  Acc@1: 87.5000 (85.8418)  Acc@5: 100.0000 (98.5567)  time: 0.3482  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [ 940/3125]  eta: 0:12:43  Lr: 0.001875  Loss: -0.8117  Acc@1: 93.7500 (85.8993)  Acc@5: 100.0000 (98.5388)  time: 0.3485  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [ 950/3125]  eta: 0:12:40  Lr: 0.001875  Loss: -0.5980  Acc@1: 87.5000 (85.9161)  Acc@5: 100.0000 (98.5542)  time: 0.3482  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [ 960/3125]  eta: 0:12:36  Lr: 0.001875  Loss: -0.5258  Acc@1: 87.5000 (85.8676)  Acc@5: 100.0000 (98.5497)  time: 0.3485  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [ 970/3125]  eta: 0:12:33  Lr: 0.001875  Loss: -0.8979  Acc@1: 87.5000 (85.8908)  Acc@5: 100.0000 (98.5389)  time: 0.3490  data: 0.0007  max mem: 2502
Train: Epoch[3/5]  [ 980/3125]  eta: 0:12:29  Lr: 0.001875  Loss: -0.5084  Acc@1: 87.5000 (85.8626)  Acc@5: 100.0000 (98.5219)  time: 0.3485  data: 0.0006  max mem: 2502
Train: Epoch[3/5]  [ 990/3125]  eta: 0:12:26  Lr: 0.001875  Loss: -0.8450  Acc@1: 87.5000 (85.8855)  Acc@5: 100.0000 (98.5242)  time: 0.3484  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [1000/3125]  eta: 0:12:22  Lr: 0.001875  Loss: -0.8521  Acc@1: 87.5000 (85.8579)  Acc@5: 100.0000 (98.5202)  time: 0.3486  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [1010/3125]  eta: 0:12:19  Lr: 0.001875  Loss: -0.5698  Acc@1: 87.5000 (85.8680)  Acc@5: 100.0000 (98.5287)  time: 0.3496  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [1020/3125]  eta: 0:12:15  Lr: 0.001875  Loss: -0.6982  Acc@1: 87.5000 (85.8595)  Acc@5: 100.0000 (98.5247)  time: 0.3494  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [1030/3125]  eta: 0:12:12  Lr: 0.001875  Loss: -0.5844  Acc@1: 81.2500 (85.8208)  Acc@5: 100.0000 (98.5209)  time: 0.3485  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [1040/3125]  eta: 0:12:08  Lr: 0.001875  Loss: -0.8648  Acc@1: 87.5000 (85.8429)  Acc@5: 100.0000 (98.5291)  time: 0.3500  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [1050/3125]  eta: 0:12:05  Lr: 0.001875  Loss: -0.7001  Acc@1: 87.5000 (85.8290)  Acc@5: 100.0000 (98.5252)  time: 0.3511  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [1060/3125]  eta: 0:12:01  Lr: 0.001875  Loss: -0.8048  Acc@1: 87.5000 (85.8270)  Acc@5: 100.0000 (98.5097)  time: 0.3497  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [1070/3125]  eta: 0:11:58  Lr: 0.001875  Loss: -0.6183  Acc@1: 87.5000 (85.8368)  Acc@5: 100.0000 (98.5061)  time: 0.3491  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [1080/3125]  eta: 0:11:54  Lr: 0.001875  Loss: -0.8602  Acc@1: 87.5000 (85.8407)  Acc@5: 100.0000 (98.5083)  time: 0.3493  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [1090/3125]  eta: 0:11:51  Lr: 0.001875  Loss: -0.8002  Acc@1: 87.5000 (85.8501)  Acc@5: 100.0000 (98.4991)  time: 0.3483  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [1100/3125]  eta: 0:11:47  Lr: 0.001875  Loss: -0.0438  Acc@1: 87.5000 (85.8027)  Acc@5: 100.0000 (98.4900)  time: 0.3482  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [1110/3125]  eta: 0:11:44  Lr: 0.001875  Loss: -0.3871  Acc@1: 81.2500 (85.7898)  Acc@5: 100.0000 (98.4923)  time: 0.3489  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [1120/3125]  eta: 0:11:40  Lr: 0.001875  Loss: -0.6375  Acc@1: 81.2500 (85.7661)  Acc@5: 100.0000 (98.4891)  time: 0.3491  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [1130/3125]  eta: 0:11:37  Lr: 0.001875  Loss: -0.3042  Acc@1: 81.2500 (85.7040)  Acc@5: 100.0000 (98.4859)  time: 0.3492  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [1140/3125]  eta: 0:11:33  Lr: 0.001875  Loss: -0.4891  Acc@1: 87.5000 (85.7307)  Acc@5: 100.0000 (98.4882)  time: 0.3488  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [1150/3125]  eta: 0:11:30  Lr: 0.001875  Loss: -0.8539  Acc@1: 81.2500 (85.6809)  Acc@5: 100.0000 (98.4850)  time: 0.3489  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [1160/3125]  eta: 0:11:26  Lr: 0.001875  Loss: -0.6492  Acc@1: 87.5000 (85.7235)  Acc@5: 100.0000 (98.4873)  time: 0.3503  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [1170/3125]  eta: 0:11:23  Lr: 0.001875  Loss: -0.5137  Acc@1: 87.5000 (85.7120)  Acc@5: 100.0000 (98.4895)  time: 0.3512  data: 0.0011  max mem: 2502
Train: Epoch[3/5]  [1180/3125]  eta: 0:11:19  Lr: 0.001875  Loss: -0.7277  Acc@1: 87.5000 (85.7377)  Acc@5: 100.0000 (98.4917)  time: 0.3501  data: 0.0011  max mem: 2502
Train: Epoch[3/5]  [1190/3125]  eta: 0:11:16  Lr: 0.001875  Loss: -0.4490  Acc@1: 87.5000 (85.7315)  Acc@5: 100.0000 (98.4992)  time: 0.3500  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [1200/3125]  eta: 0:11:12  Lr: 0.001875  Loss: -0.5119  Acc@1: 87.5000 (85.7410)  Acc@5: 100.0000 (98.5065)  time: 0.3504  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [1210/3125]  eta: 0:11:09  Lr: 0.001875  Loss: -0.6573  Acc@1: 81.2500 (85.7349)  Acc@5: 100.0000 (98.5136)  time: 0.3499  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [1220/3125]  eta: 0:11:05  Lr: 0.001875  Loss: -0.2818  Acc@1: 87.5000 (85.7647)  Acc@5: 100.0000 (98.5207)  time: 0.3500  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [1230/3125]  eta: 0:11:02  Lr: 0.001875  Loss: -0.9162  Acc@1: 87.5000 (85.7585)  Acc@5: 100.0000 (98.5124)  time: 0.3508  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [1240/3125]  eta: 0:10:58  Lr: 0.001875  Loss: -0.5996  Acc@1: 87.5000 (85.7575)  Acc@5: 100.0000 (98.5093)  time: 0.3500  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [1250/3125]  eta: 0:10:55  Lr: 0.001875  Loss: -0.8714  Acc@1: 81.2500 (85.7364)  Acc@5: 100.0000 (98.5162)  time: 0.3494  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [1260/3125]  eta: 0:10:51  Lr: 0.001875  Loss: -0.5203  Acc@1: 81.2500 (85.7306)  Acc@5: 100.0000 (98.5230)  time: 0.3492  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [1270/3125]  eta: 0:10:48  Lr: 0.001875  Loss: -0.6989  Acc@1: 87.5000 (85.7347)  Acc@5: 100.0000 (98.5297)  time: 0.3491  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [1280/3125]  eta: 0:10:44  Lr: 0.001875  Loss: -0.8572  Acc@1: 87.5000 (85.7387)  Acc@5: 100.0000 (98.5363)  time: 0.3502  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [1290/3125]  eta: 0:10:41  Lr: 0.001875  Loss: -0.3172  Acc@1: 87.5000 (85.7184)  Acc@5: 100.0000 (98.5380)  time: 0.3498  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [1300/3125]  eta: 0:10:37  Lr: 0.001875  Loss: 0.0956  Acc@1: 81.2500 (85.6841)  Acc@5: 100.0000 (98.5348)  time: 0.3486  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [1310/3125]  eta: 0:10:34  Lr: 0.001875  Loss: -0.5149  Acc@1: 87.5000 (85.7027)  Acc@5: 100.0000 (98.5412)  time: 0.3484  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [1320/3125]  eta: 0:10:30  Lr: 0.001875  Loss: -0.7089  Acc@1: 87.5000 (85.7021)  Acc@5: 100.0000 (98.5333)  time: 0.3478  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [1330/3125]  eta: 0:10:27  Lr: 0.001875  Loss: -0.6728  Acc@1: 87.5000 (85.6875)  Acc@5: 100.0000 (98.5443)  time: 0.3478  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [1340/3125]  eta: 0:10:23  Lr: 0.001875  Loss: -0.9267  Acc@1: 87.5000 (85.7243)  Acc@5: 100.0000 (98.5412)  time: 0.3492  data: 0.0017  max mem: 2502
Train: Epoch[3/5]  [1350/3125]  eta: 0:10:20  Lr: 0.001875  Loss: -0.7542  Acc@1: 87.5000 (85.7235)  Acc@5: 100.0000 (98.5335)  time: 0.3496  data: 0.0017  max mem: 2502
Train: Epoch[3/5]  [1360/3125]  eta: 0:10:16  Lr: 0.001875  Loss: -0.7633  Acc@1: 87.5000 (85.7136)  Acc@5: 100.0000 (98.5167)  time: 0.3486  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [1370/3125]  eta: 0:10:13  Lr: 0.001875  Loss: -0.6669  Acc@1: 87.5000 (85.7267)  Acc@5: 100.0000 (98.5275)  time: 0.3484  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [1380/3125]  eta: 0:10:09  Lr: 0.001875  Loss: -1.0583  Acc@1: 87.5000 (85.7667)  Acc@5: 100.0000 (98.5291)  time: 0.3483  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [1390/3125]  eta: 0:10:06  Lr: 0.001875  Loss: -0.7248  Acc@1: 87.5000 (85.7701)  Acc@5: 100.0000 (98.5352)  time: 0.3483  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [1400/3125]  eta: 0:10:02  Lr: 0.001875  Loss: -0.4998  Acc@1: 87.5000 (85.7959)  Acc@5: 100.0000 (98.5412)  time: 0.3483  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [1410/3125]  eta: 0:09:59  Lr: 0.001875  Loss: -0.7925  Acc@1: 87.5000 (85.7814)  Acc@5: 100.0000 (98.5161)  time: 0.3490  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [1420/3125]  eta: 0:09:55  Lr: 0.001875  Loss: -0.5943  Acc@1: 81.2500 (85.7363)  Acc@5: 100.0000 (98.5090)  time: 0.3502  data: 0.0011  max mem: 2502
Train: Epoch[3/5]  [1430/3125]  eta: 0:09:52  Lr: 0.001875  Loss: -0.8762  Acc@1: 81.2500 (85.7530)  Acc@5: 100.0000 (98.5107)  time: 0.3494  data: 0.0010  max mem: 2502
Train: Epoch[3/5]  [1440/3125]  eta: 0:09:48  Lr: 0.001875  Loss: -0.6986  Acc@1: 87.5000 (85.7564)  Acc@5: 100.0000 (98.5210)  time: 0.3489  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [1450/3125]  eta: 0:09:45  Lr: 0.001875  Loss: -0.7793  Acc@1: 87.5000 (85.7727)  Acc@5: 100.0000 (98.5226)  time: 0.3511  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [1460/3125]  eta: 0:09:41  Lr: 0.001875  Loss: -0.6600  Acc@1: 87.5000 (85.7461)  Acc@5: 100.0000 (98.5198)  time: 0.3508  data: 0.0012  max mem: 2502
Train: Epoch[3/5]  [1470/3125]  eta: 0:09:38  Lr: 0.001875  Loss: -0.6447  Acc@1: 81.2500 (85.7325)  Acc@5: 100.0000 (98.5299)  time: 0.3492  data: 0.0011  max mem: 2502
Train: Epoch[3/5]  [1480/3125]  eta: 0:09:34  Lr: 0.001875  Loss: -0.2157  Acc@1: 81.2500 (85.7107)  Acc@5: 100.0000 (98.5145)  time: 0.3495  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [1490/3125]  eta: 0:09:31  Lr: 0.001875  Loss: -0.7551  Acc@1: 87.5000 (85.7478)  Acc@5: 100.0000 (98.5161)  time: 0.3497  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [1500/3125]  eta: 0:09:27  Lr: 0.001875  Loss: -0.6576  Acc@1: 87.5000 (85.7428)  Acc@5: 100.0000 (98.5218)  time: 0.3498  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [1510/3125]  eta: 0:09:24  Lr: 0.001875  Loss: -0.6744  Acc@1: 81.2500 (85.7214)  Acc@5: 100.0000 (98.5233)  time: 0.3497  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [1520/3125]  eta: 0:09:20  Lr: 0.001875  Loss: -0.9926  Acc@1: 87.5000 (85.7290)  Acc@5: 100.0000 (98.5207)  time: 0.3502  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [1530/3125]  eta: 0:09:17  Lr: 0.001875  Loss: -0.1010  Acc@1: 87.5000 (85.7079)  Acc@5: 100.0000 (98.5181)  time: 0.3503  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [1540/3125]  eta: 0:09:13  Lr: 0.001875  Loss: -0.6101  Acc@1: 87.5000 (85.7033)  Acc@5: 100.0000 (98.5196)  time: 0.3500  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [1550/3125]  eta: 0:09:10  Lr: 0.001875  Loss: -0.6252  Acc@1: 87.5000 (85.7350)  Acc@5: 100.0000 (98.5211)  time: 0.3506  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [1560/3125]  eta: 0:09:06  Lr: 0.001875  Loss: 0.0489  Acc@1: 87.5000 (85.7423)  Acc@5: 100.0000 (98.5306)  time: 0.3511  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [1570/3125]  eta: 0:09:03  Lr: 0.001875  Loss: -0.5962  Acc@1: 87.5000 (85.7455)  Acc@5: 100.0000 (98.5320)  time: 0.3504  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [1580/3125]  eta: 0:08:59  Lr: 0.001875  Loss: -0.3730  Acc@1: 81.2500 (85.7132)  Acc@5: 100.0000 (98.5294)  time: 0.3495  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [1590/3125]  eta: 0:08:56  Lr: 0.001875  Loss: -0.6217  Acc@1: 81.2500 (85.7244)  Acc@5: 100.0000 (98.5308)  time: 0.3498  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [1600/3125]  eta: 0:08:53  Lr: 0.001875  Loss: -0.8433  Acc@1: 87.5000 (85.7238)  Acc@5: 100.0000 (98.5322)  time: 0.3506  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [1610/3125]  eta: 0:08:49  Lr: 0.001875  Loss: -0.4698  Acc@1: 87.5000 (85.7619)  Acc@5: 100.0000 (98.5296)  time: 0.3501  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [1620/3125]  eta: 0:08:46  Lr: 0.001875  Loss: -0.3247  Acc@1: 93.7500 (85.7688)  Acc@5: 100.0000 (98.5349)  time: 0.3500  data: 0.0006  max mem: 2502
Train: Epoch[3/5]  [1630/3125]  eta: 0:08:42  Lr: 0.001875  Loss: -0.4914  Acc@1: 87.5000 (85.7718)  Acc@5: 100.0000 (98.5400)  time: 0.3501  data: 0.0006  max mem: 2502
Train: Epoch[3/5]  [1640/3125]  eta: 0:08:39  Lr: 0.001875  Loss: -0.7848  Acc@1: 87.5000 (85.7518)  Acc@5: 100.0000 (98.5337)  time: 0.3500  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [1650/3125]  eta: 0:08:35  Lr: 0.001875  Loss: -0.8663  Acc@1: 87.5000 (85.7548)  Acc@5: 100.0000 (98.5425)  time: 0.3502  data: 0.0007  max mem: 2502
Train: Epoch[3/5]  [1660/3125]  eta: 0:08:32  Lr: 0.001875  Loss: -0.9540  Acc@1: 87.5000 (85.7390)  Acc@5: 100.0000 (98.5438)  time: 0.3501  data: 0.0007  max mem: 2502
Train: Epoch[3/5]  [1670/3125]  eta: 0:08:28  Lr: 0.001875  Loss: -0.5884  Acc@1: 87.5000 (85.7271)  Acc@5: 100.0000 (98.5301)  time: 0.3502  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [1680/3125]  eta: 0:08:25  Lr: 0.001875  Loss: -0.9462  Acc@1: 87.5000 (85.7414)  Acc@5: 100.0000 (98.5277)  time: 0.3499  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [1690/3125]  eta: 0:08:21  Lr: 0.001875  Loss: -0.7504  Acc@1: 87.5000 (85.7518)  Acc@5: 100.0000 (98.5216)  time: 0.3501  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [1700/3125]  eta: 0:08:18  Lr: 0.001875  Loss: -0.7799  Acc@1: 87.5000 (85.7584)  Acc@5: 100.0000 (98.5229)  time: 0.3503  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [1710/3125]  eta: 0:08:14  Lr: 0.001875  Loss: -0.4440  Acc@1: 87.5000 (85.7613)  Acc@5: 100.0000 (98.5206)  time: 0.3510  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [1720/3125]  eta: 0:08:11  Lr: 0.001875  Loss: -0.7832  Acc@1: 87.5000 (85.7387)  Acc@5: 100.0000 (98.5292)  time: 0.3509  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [1730/3125]  eta: 0:08:07  Lr: 0.001875  Loss: -0.5375  Acc@1: 87.5000 (85.7380)  Acc@5: 100.0000 (98.5305)  time: 0.3505  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [1740/3125]  eta: 0:08:04  Lr: 0.001875  Loss: -0.8795  Acc@1: 81.2500 (85.7158)  Acc@5: 100.0000 (98.5389)  time: 0.3507  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [1750/3125]  eta: 0:08:00  Lr: 0.001875  Loss: -0.7697  Acc@1: 87.5000 (85.7367)  Acc@5: 100.0000 (98.5401)  time: 0.3497  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [1760/3125]  eta: 0:07:57  Lr: 0.001875  Loss: -0.1025  Acc@1: 87.5000 (85.7432)  Acc@5: 100.0000 (98.5342)  time: 0.3502  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [1770/3125]  eta: 0:07:53  Lr: 0.001875  Loss: -0.4529  Acc@1: 87.5000 (85.7672)  Acc@5: 100.0000 (98.5354)  time: 0.3505  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [1780/3125]  eta: 0:07:50  Lr: 0.001875  Loss: -0.8371  Acc@1: 87.5000 (85.7945)  Acc@5: 100.0000 (98.5331)  time: 0.3498  data: 0.0006  max mem: 2502
Train: Epoch[3/5]  [1790/3125]  eta: 0:07:46  Lr: 0.001875  Loss: -0.5603  Acc@1: 87.5000 (85.8005)  Acc@5: 100.0000 (98.5204)  time: 0.3499  data: 0.0006  max mem: 2502
Train: Epoch[3/5]  [1800/3125]  eta: 0:07:43  Lr: 0.001875  Loss: -0.6092  Acc@1: 87.5000 (85.7926)  Acc@5: 100.0000 (98.5217)  time: 0.3501  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [1810/3125]  eta: 0:07:39  Lr: 0.001875  Loss: -0.4217  Acc@1: 81.2500 (85.7882)  Acc@5: 100.0000 (98.5229)  time: 0.3501  data: 0.0006  max mem: 2502
Train: Epoch[3/5]  [1820/3125]  eta: 0:07:36  Lr: 0.001875  Loss: -0.8572  Acc@1: 87.5000 (85.8011)  Acc@5: 100.0000 (98.5173)  time: 0.3508  data: 0.0013  max mem: 2502
Train: Epoch[3/5]  [1830/3125]  eta: 0:07:32  Lr: 0.001875  Loss: -0.0598  Acc@1: 87.5000 (85.7967)  Acc@5: 100.0000 (98.5152)  time: 0.3510  data: 0.0011  max mem: 2502
Train: Epoch[3/5]  [1840/3125]  eta: 0:07:29  Lr: 0.001875  Loss: -0.8429  Acc@1: 87.5000 (85.8059)  Acc@5: 100.0000 (98.5232)  time: 0.3503  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [1850/3125]  eta: 0:07:25  Lr: 0.001875  Loss: -0.0496  Acc@1: 87.5000 (85.7948)  Acc@5: 100.0000 (98.5278)  time: 0.3500  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [1860/3125]  eta: 0:07:22  Lr: 0.001875  Loss: -0.6348  Acc@1: 87.5000 (85.7973)  Acc@5: 100.0000 (98.5156)  time: 0.3505  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [1870/3125]  eta: 0:07:18  Lr: 0.001875  Loss: -0.2721  Acc@1: 87.5000 (85.8164)  Acc@5: 100.0000 (98.5102)  time: 0.3504  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [1880/3125]  eta: 0:07:15  Lr: 0.001875  Loss: -0.8254  Acc@1: 87.5000 (85.8054)  Acc@5: 100.0000 (98.5081)  time: 0.3494  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [1890/3125]  eta: 0:07:11  Lr: 0.001875  Loss: -0.5736  Acc@1: 81.2500 (85.8210)  Acc@5: 100.0000 (98.5094)  time: 0.3488  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [1900/3125]  eta: 0:07:08  Lr: 0.001875  Loss: -0.7644  Acc@1: 87.5000 (85.8101)  Acc@5: 100.0000 (98.5107)  time: 0.3489  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [1910/3125]  eta: 0:07:04  Lr: 0.001875  Loss: -0.7837  Acc@1: 87.5000 (85.8189)  Acc@5: 100.0000 (98.5119)  time: 0.3494  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [1920/3125]  eta: 0:07:01  Lr: 0.001875  Loss: -1.0230  Acc@1: 87.5000 (85.8309)  Acc@5: 100.0000 (98.5164)  time: 0.3495  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [1930/3125]  eta: 0:06:57  Lr: 0.001875  Loss: -0.7885  Acc@1: 87.5000 (85.8396)  Acc@5: 100.0000 (98.5208)  time: 0.3496  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [1940/3125]  eta: 0:06:54  Lr: 0.001875  Loss: -0.6394  Acc@1: 87.5000 (85.8159)  Acc@5: 100.0000 (98.5124)  time: 0.3496  data: 0.0008  max mem: 2502
Train: Epoch[3/5]  [1950/3125]  eta: 0:06:50  Lr: 0.001875  Loss: -0.4513  Acc@1: 81.2500 (85.7861)  Acc@5: 100.0000 (98.5104)  time: 0.3488  data: 0.0007  max mem: 2502
Train: Epoch[3/5]  [1960/3125]  eta: 0:06:47  Lr: 0.001875  Loss: -0.8244  Acc@1: 81.2500 (85.7885)  Acc@5: 100.0000 (98.5148)  time: 0.3482  data: 0.0006  max mem: 2502
Train: Epoch[3/5]  [1970/3125]  eta: 0:06:43  Lr: 0.001875  Loss: -0.6892  Acc@1: 87.5000 (85.7718)  Acc@5: 100.0000 (98.5160)  time: 0.3490  data: 0.0007  max mem: 2502
Train: Epoch[3/5]  [1980/3125]  eta: 0:06:40  Lr: 0.001875  Loss: -0.6529  Acc@1: 81.2500 (85.7679)  Acc@5: 100.0000 (98.5172)  time: 0.3487  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [1990/3125]  eta: 0:06:36  Lr: 0.001875  Loss: -0.7575  Acc@1: 87.5000 (85.7766)  Acc@5: 100.0000 (98.5183)  time: 0.3477  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [2000/3125]  eta: 0:06:33  Lr: 0.001875  Loss: -0.3676  Acc@1: 87.5000 (85.7727)  Acc@5: 100.0000 (98.5164)  time: 0.3481  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [2010/3125]  eta: 0:06:29  Lr: 0.001875  Loss: -0.4877  Acc@1: 87.5000 (85.7875)  Acc@5: 100.0000 (98.5175)  time: 0.3485  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [2020/3125]  eta: 0:06:26  Lr: 0.001875  Loss: -0.8089  Acc@1: 87.5000 (85.7898)  Acc@5: 100.0000 (98.5218)  time: 0.3489  data: 0.0008  max mem: 2502
Train: Epoch[3/5]  [2030/3125]  eta: 0:06:22  Lr: 0.001875  Loss: -0.8365  Acc@1: 87.5000 (85.8013)  Acc@5: 100.0000 (98.5260)  time: 0.3479  data: 0.0006  max mem: 2502
Train: Epoch[3/5]  [2040/3125]  eta: 0:06:19  Lr: 0.001875  Loss: -0.6268  Acc@1: 87.5000 (85.8188)  Acc@5: 100.0000 (98.5301)  time: 0.3476  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [2050/3125]  eta: 0:06:15  Lr: 0.001875  Loss: -0.6784  Acc@1: 87.5000 (85.8392)  Acc@5: 100.0000 (98.5312)  time: 0.3480  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [2060/3125]  eta: 0:06:12  Lr: 0.001875  Loss: -0.9297  Acc@1: 87.5000 (85.8352)  Acc@5: 100.0000 (98.5323)  time: 0.3480  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [2070/3125]  eta: 0:06:08  Lr: 0.001875  Loss: -0.2527  Acc@1: 81.2500 (85.8341)  Acc@5: 100.0000 (98.5363)  time: 0.3482  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [2080/3125]  eta: 0:06:05  Lr: 0.001875  Loss: -0.7693  Acc@1: 87.5000 (85.8421)  Acc@5: 100.0000 (98.5374)  time: 0.3477  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [2090/3125]  eta: 0:06:01  Lr: 0.001875  Loss: -0.6458  Acc@1: 87.5000 (85.8471)  Acc@5: 100.0000 (98.5354)  time: 0.3468  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [2100/3125]  eta: 0:05:58  Lr: 0.001875  Loss: -0.7291  Acc@1: 87.5000 (85.8431)  Acc@5: 100.0000 (98.5334)  time: 0.3469  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [2110/3125]  eta: 0:05:54  Lr: 0.001875  Loss: -0.5830  Acc@1: 87.5000 (85.8450)  Acc@5: 100.0000 (98.5345)  time: 0.3478  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [2120/3125]  eta: 0:05:51  Lr: 0.001875  Loss: -0.4562  Acc@1: 87.5000 (85.8469)  Acc@5: 100.0000 (98.5355)  time: 0.3486  data: 0.0010  max mem: 2502
Train: Epoch[3/5]  [2130/3125]  eta: 0:05:47  Lr: 0.001875  Loss: -0.7216  Acc@1: 87.5000 (85.8458)  Acc@5: 100.0000 (98.5394)  time: 0.3491  data: 0.0011  max mem: 2502
Train: Epoch[3/5]  [2140/3125]  eta: 0:05:44  Lr: 0.001875  Loss: -0.3528  Acc@1: 87.5000 (85.8565)  Acc@5: 100.0000 (98.5375)  time: 0.3490  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [2150/3125]  eta: 0:05:40  Lr: 0.001875  Loss: -0.6631  Acc@1: 87.5000 (85.8496)  Acc@5: 100.0000 (98.5298)  time: 0.3492  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [2160/3125]  eta: 0:05:37  Lr: 0.001875  Loss: -0.7407  Acc@1: 87.5000 (85.8659)  Acc@5: 100.0000 (98.5308)  time: 0.3493  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [2170/3125]  eta: 0:05:33  Lr: 0.001875  Loss: -0.3258  Acc@1: 81.2500 (85.8562)  Acc@5: 100.0000 (98.5347)  time: 0.3491  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [2180/3125]  eta: 0:05:30  Lr: 0.001875  Loss: -0.4061  Acc@1: 81.2500 (85.8551)  Acc@5: 100.0000 (98.5385)  time: 0.3489  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [2190/3125]  eta: 0:05:26  Lr: 0.001875  Loss: -0.9581  Acc@1: 87.5000 (85.8655)  Acc@5: 100.0000 (98.5395)  time: 0.3490  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [2200/3125]  eta: 0:05:23  Lr: 0.001875  Loss: -0.5369  Acc@1: 87.5000 (85.8814)  Acc@5: 100.0000 (98.5461)  time: 0.3494  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [2210/3125]  eta: 0:05:19  Lr: 0.001875  Loss: -0.6193  Acc@1: 87.5000 (85.8774)  Acc@5: 100.0000 (98.5499)  time: 0.3503  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [2220/3125]  eta: 0:05:16  Lr: 0.001875  Loss: -0.8655  Acc@1: 87.5000 (85.8960)  Acc@5: 100.0000 (98.5536)  time: 0.3518  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [2230/3125]  eta: 0:05:12  Lr: 0.001875  Loss: -0.2944  Acc@1: 87.5000 (85.8948)  Acc@5: 100.0000 (98.5517)  time: 0.3514  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [2240/3125]  eta: 0:05:09  Lr: 0.001875  Loss: -0.4648  Acc@1: 87.5000 (85.9047)  Acc@5: 100.0000 (98.5442)  time: 0.3495  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [2250/3125]  eta: 0:05:05  Lr: 0.001875  Loss: -0.9975  Acc@1: 87.5000 (85.9146)  Acc@5: 100.0000 (98.5395)  time: 0.3488  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [2260/3125]  eta: 0:05:02  Lr: 0.001875  Loss: -0.8681  Acc@1: 93.7500 (85.9327)  Acc@5: 100.0000 (98.5432)  time: 0.3495  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [2270/3125]  eta: 0:04:58  Lr: 0.001875  Loss: -0.7468  Acc@1: 87.5000 (85.9231)  Acc@5: 100.0000 (98.5414)  time: 0.3498  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [2280/3125]  eta: 0:04:55  Lr: 0.001875  Loss: -0.6917  Acc@1: 81.2500 (85.9163)  Acc@5: 100.0000 (98.5423)  time: 0.3496  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [2290/3125]  eta: 0:04:51  Lr: 0.001875  Loss: -0.8201  Acc@1: 81.2500 (85.9177)  Acc@5: 100.0000 (98.5432)  time: 0.3492  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [2300/3125]  eta: 0:04:48  Lr: 0.001875  Loss: -0.4358  Acc@1: 87.5000 (85.9327)  Acc@5: 100.0000 (98.5414)  time: 0.3489  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [2310/3125]  eta: 0:04:44  Lr: 0.001875  Loss: -0.4318  Acc@1: 87.5000 (85.9422)  Acc@5: 100.0000 (98.5396)  time: 0.3489  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [2320/3125]  eta: 0:04:41  Lr: 0.001875  Loss: -0.4935  Acc@1: 81.2500 (85.9301)  Acc@5: 100.0000 (98.5405)  time: 0.3492  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [2330/3125]  eta: 0:04:37  Lr: 0.001875  Loss: -0.8586  Acc@1: 87.5000 (85.9341)  Acc@5: 100.0000 (98.5414)  time: 0.3492  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [2340/3125]  eta: 0:04:34  Lr: 0.001875  Loss: -0.5036  Acc@1: 87.5000 (85.9275)  Acc@5: 100.0000 (98.5423)  time: 0.3493  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [2350/3125]  eta: 0:04:30  Lr: 0.001875  Loss: -0.8252  Acc@1: 87.5000 (85.9209)  Acc@5: 100.0000 (98.5458)  time: 0.3491  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [2360/3125]  eta: 0:04:27  Lr: 0.001875  Loss: -0.5602  Acc@1: 81.2500 (85.9090)  Acc@5: 100.0000 (98.5493)  time: 0.3484  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [2370/3125]  eta: 0:04:23  Lr: 0.001875  Loss: -0.7799  Acc@1: 81.2500 (85.9105)  Acc@5: 100.0000 (98.5423)  time: 0.3489  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [2380/3125]  eta: 0:04:20  Lr: 0.001875  Loss: -0.7898  Acc@1: 81.2500 (85.9040)  Acc@5: 100.0000 (98.5405)  time: 0.3494  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [2390/3125]  eta: 0:04:16  Lr: 0.001875  Loss: -0.8643  Acc@1: 81.2500 (85.8872)  Acc@5: 100.0000 (98.5336)  time: 0.3491  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [2400/3125]  eta: 0:04:13  Lr: 0.001875  Loss: -0.5508  Acc@1: 87.5000 (85.8913)  Acc@5: 100.0000 (98.5345)  time: 0.3493  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [2410/3125]  eta: 0:04:09  Lr: 0.001875  Loss: -0.6021  Acc@1: 87.5000 (85.9057)  Acc@5: 100.0000 (98.5405)  time: 0.3495  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [2420/3125]  eta: 0:04:06  Lr: 0.001875  Loss: -0.7346  Acc@1: 87.5000 (85.9072)  Acc@5: 100.0000 (98.5388)  time: 0.3489  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [2430/3125]  eta: 0:04:02  Lr: 0.001875  Loss: -0.7315  Acc@1: 87.5000 (85.9163)  Acc@5: 100.0000 (98.5448)  time: 0.3483  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [2440/3125]  eta: 0:03:59  Lr: 0.001875  Loss: -0.8726  Acc@1: 93.7500 (85.9279)  Acc@5: 100.0000 (98.5431)  time: 0.3491  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [2450/3125]  eta: 0:03:55  Lr: 0.001875  Loss: -0.7866  Acc@1: 87.5000 (85.9267)  Acc@5: 100.0000 (98.5414)  time: 0.3496  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [2460/3125]  eta: 0:03:52  Lr: 0.001875  Loss: -0.6544  Acc@1: 87.5000 (85.9305)  Acc@5: 100.0000 (98.5448)  time: 0.3492  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [2470/3125]  eta: 0:03:48  Lr: 0.001875  Loss: -0.9438  Acc@1: 87.5000 (85.9470)  Acc@5: 100.0000 (98.5482)  time: 0.3501  data: 0.0008  max mem: 2502
Train: Epoch[3/5]  [2480/3125]  eta: 0:03:45  Lr: 0.001875  Loss: -0.5938  Acc@1: 87.5000 (85.9230)  Acc@5: 100.0000 (98.5439)  time: 0.3500  data: 0.0008  max mem: 2502
Train: Epoch[3/5]  [2490/3125]  eta: 0:03:41  Lr: 0.001875  Loss: -0.8242  Acc@1: 81.2500 (85.9293)  Acc@5: 100.0000 (98.5397)  time: 0.3494  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [2500/3125]  eta: 0:03:38  Lr: 0.001875  Loss: -0.8025  Acc@1: 87.5000 (85.9231)  Acc@5: 100.0000 (98.5381)  time: 0.3491  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [2510/3125]  eta: 0:03:34  Lr: 0.001875  Loss: -0.9034  Acc@1: 87.5000 (85.9219)  Acc@5: 100.0000 (98.5340)  time: 0.3488  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [2520/3125]  eta: 0:03:31  Lr: 0.001875  Loss: -0.7795  Acc@1: 87.5000 (85.9158)  Acc@5: 100.0000 (98.5323)  time: 0.3489  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [2530/3125]  eta: 0:03:27  Lr: 0.001875  Loss: -0.5524  Acc@1: 87.5000 (85.9048)  Acc@5: 100.0000 (98.5258)  time: 0.3491  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [2540/3125]  eta: 0:03:24  Lr: 0.001875  Loss: -0.4861  Acc@1: 87.5000 (85.9135)  Acc@5: 100.0000 (98.5291)  time: 0.3499  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [2550/3125]  eta: 0:03:20  Lr: 0.001875  Loss: -0.7590  Acc@1: 87.5000 (85.9295)  Acc@5: 100.0000 (98.5300)  time: 0.3506  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [2560/3125]  eta: 0:03:17  Lr: 0.001875  Loss: -0.8714  Acc@1: 87.5000 (85.9283)  Acc@5: 100.0000 (98.5260)  time: 0.3506  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [2570/3125]  eta: 0:03:13  Lr: 0.001875  Loss: -0.5299  Acc@1: 87.5000 (85.9345)  Acc@5: 100.0000 (98.5268)  time: 0.3498  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [2580/3125]  eta: 0:03:10  Lr: 0.001875  Loss: -0.6146  Acc@1: 87.5000 (85.9429)  Acc@5: 100.0000 (98.5301)  time: 0.3497  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [2590/3125]  eta: 0:03:06  Lr: 0.001875  Loss: -0.6079  Acc@1: 81.2500 (85.9490)  Acc@5: 100.0000 (98.5286)  time: 0.3506  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [2600/3125]  eta: 0:03:03  Lr: 0.001875  Loss: -0.4141  Acc@1: 81.2500 (85.9333)  Acc@5: 100.0000 (98.5294)  time: 0.3510  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [2610/3125]  eta: 0:02:59  Lr: 0.001875  Loss: -0.8790  Acc@1: 81.2500 (85.9345)  Acc@5: 100.0000 (98.5279)  time: 0.3501  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [2620/3125]  eta: 0:02:56  Lr: 0.001875  Loss: -0.7636  Acc@1: 87.5000 (85.9476)  Acc@5: 100.0000 (98.5287)  time: 0.3490  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [2630/3125]  eta: 0:02:52  Lr: 0.001875  Loss: -0.0868  Acc@1: 87.5000 (85.9417)  Acc@5: 100.0000 (98.5272)  time: 0.3496  data: 0.0007  max mem: 2502
Train: Epoch[3/5]  [2640/3125]  eta: 0:02:49  Lr: 0.001875  Loss: -0.7045  Acc@1: 81.2500 (85.9452)  Acc@5: 100.0000 (98.5257)  time: 0.3489  data: 0.0007  max mem: 2502
Train: Epoch[3/5]  [2650/3125]  eta: 0:02:45  Lr: 0.001875  Loss: -0.7633  Acc@1: 87.5000 (85.9416)  Acc@5: 100.0000 (98.5289)  time: 0.3483  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [2660/3125]  eta: 0:02:42  Lr: 0.001875  Loss: -0.1976  Acc@1: 87.5000 (85.9334)  Acc@5: 100.0000 (98.5226)  time: 0.3485  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [2670/3125]  eta: 0:02:39  Lr: 0.001875  Loss: -0.6203  Acc@1: 87.5000 (85.9369)  Acc@5: 100.0000 (98.5258)  time: 0.3484  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [2680/3125]  eta: 0:02:35  Lr: 0.001875  Loss: -0.6838  Acc@1: 81.2500 (85.9241)  Acc@5: 100.0000 (98.5313)  time: 0.3487  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [2690/3125]  eta: 0:02:32  Lr: 0.001875  Loss: -0.3328  Acc@1: 81.2500 (85.9183)  Acc@5: 100.0000 (98.5298)  time: 0.3484  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [2700/3125]  eta: 0:02:28  Lr: 0.001875  Loss: -0.4152  Acc@1: 81.2500 (85.9103)  Acc@5: 100.0000 (98.5330)  time: 0.3481  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [2710/3125]  eta: 0:02:25  Lr: 0.001875  Loss: -0.4461  Acc@1: 81.2500 (85.8954)  Acc@5: 100.0000 (98.5222)  time: 0.3484  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [2720/3125]  eta: 0:02:21  Lr: 0.001875  Loss: -0.5529  Acc@1: 87.5000 (85.9197)  Acc@5: 100.0000 (98.5277)  time: 0.3496  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [2730/3125]  eta: 0:02:18  Lr: 0.001875  Loss: -0.4300  Acc@1: 87.5000 (85.9140)  Acc@5: 100.0000 (98.5262)  time: 0.3500  data: 0.0013  max mem: 2502
Train: Epoch[3/5]  [2740/3125]  eta: 0:02:14  Lr: 0.001875  Loss: -0.7852  Acc@1: 87.5000 (85.9175)  Acc@5: 100.0000 (98.5316)  time: 0.3491  data: 0.0020  max mem: 2502
Train: Epoch[3/5]  [2750/3125]  eta: 0:02:11  Lr: 0.001875  Loss: -0.3388  Acc@1: 87.5000 (85.9119)  Acc@5: 100.0000 (98.5324)  time: 0.3484  data: 0.0011  max mem: 2502
Train: Epoch[3/5]  [2760/3125]  eta: 0:02:07  Lr: 0.001875  Loss: -0.4486  Acc@1: 87.5000 (85.9132)  Acc@5: 100.0000 (98.5354)  time: 0.3488  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [2770/3125]  eta: 0:02:04  Lr: 0.001875  Loss: -0.8101  Acc@1: 87.5000 (85.9144)  Acc@5: 100.0000 (98.5384)  time: 0.3492  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [2780/3125]  eta: 0:02:00  Lr: 0.001875  Loss: -0.4195  Acc@1: 87.5000 (85.9223)  Acc@5: 100.0000 (98.5347)  time: 0.3486  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [2790/3125]  eta: 0:01:57  Lr: 0.001875  Loss: -0.9144  Acc@1: 87.5000 (85.9190)  Acc@5: 100.0000 (98.5377)  time: 0.3488  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [2800/3125]  eta: 0:01:53  Lr: 0.001875  Loss: -0.6354  Acc@1: 81.2500 (85.9046)  Acc@5: 100.0000 (98.5362)  time: 0.3495  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [2810/3125]  eta: 0:01:50  Lr: 0.001875  Loss: -0.7415  Acc@1: 81.2500 (85.9058)  Acc@5: 100.0000 (98.5370)  time: 0.3488  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [2820/3125]  eta: 0:01:46  Lr: 0.001875  Loss: -0.3782  Acc@1: 87.5000 (85.9048)  Acc@5: 100.0000 (98.5378)  time: 0.3485  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [2830/3125]  eta: 0:01:43  Lr: 0.001875  Loss: -0.9084  Acc@1: 87.5000 (85.9149)  Acc@5: 100.0000 (98.5407)  time: 0.3490  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [2840/3125]  eta: 0:01:39  Lr: 0.001875  Loss: -0.8006  Acc@1: 87.5000 (85.9227)  Acc@5: 100.0000 (98.5414)  time: 0.3493  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [2850/3125]  eta: 0:01:36  Lr: 0.001875  Loss: -0.6631  Acc@1: 87.5000 (85.9194)  Acc@5: 100.0000 (98.5422)  time: 0.3490  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [2860/3125]  eta: 0:01:32  Lr: 0.001875  Loss: -0.8651  Acc@1: 87.5000 (85.9293)  Acc@5: 100.0000 (98.5473)  time: 0.3484  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [2870/3125]  eta: 0:01:29  Lr: 0.001875  Loss: -0.4876  Acc@1: 87.5000 (85.9239)  Acc@5: 100.0000 (98.5523)  time: 0.3489  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [2880/3125]  eta: 0:01:25  Lr: 0.001875  Loss: -0.8370  Acc@1: 87.5000 (85.9359)  Acc@5: 100.0000 (98.5530)  time: 0.3492  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [2890/3125]  eta: 0:01:22  Lr: 0.001875  Loss: -0.5919  Acc@1: 87.5000 (85.9478)  Acc@5: 100.0000 (98.5537)  time: 0.3494  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [2900/3125]  eta: 0:01:18  Lr: 0.001875  Loss: -0.7632  Acc@1: 87.5000 (85.9510)  Acc@5: 100.0000 (98.5565)  time: 0.3517  data: 0.0010  max mem: 2502
Train: Epoch[3/5]  [2910/3125]  eta: 0:01:15  Lr: 0.001875  Loss: -0.2237  Acc@1: 87.5000 (85.9456)  Acc@5: 100.0000 (98.5572)  time: 0.3514  data: 0.0010  max mem: 2502
Train: Epoch[3/5]  [2920/3125]  eta: 0:01:11  Lr: 0.001875  Loss: -0.8297  Acc@1: 87.5000 (85.9466)  Acc@5: 100.0000 (98.5621)  time: 0.3500  data: 0.0006  max mem: 2502
Train: Epoch[3/5]  [2930/3125]  eta: 0:01:08  Lr: 0.001875  Loss: -0.7603  Acc@1: 87.5000 (85.9583)  Acc@5: 100.0000 (98.5606)  time: 0.3498  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [2940/3125]  eta: 0:01:04  Lr: 0.001875  Loss: -0.4828  Acc@1: 87.5000 (85.9678)  Acc@5: 100.0000 (98.5613)  time: 0.3496  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [2950/3125]  eta: 0:01:01  Lr: 0.001875  Loss: -0.7316  Acc@1: 87.5000 (85.9709)  Acc@5: 100.0000 (98.5619)  time: 0.3512  data: 0.0008  max mem: 2502
Train: Epoch[3/5]  [2960/3125]  eta: 0:00:57  Lr: 0.001875  Loss: -0.8726  Acc@1: 87.5000 (85.9676)  Acc@5: 100.0000 (98.5668)  time: 0.3509  data: 0.0008  max mem: 2502
Train: Epoch[3/5]  [2970/3125]  eta: 0:00:54  Lr: 0.001875  Loss: -0.1891  Acc@1: 81.2500 (85.9664)  Acc@5: 100.0000 (98.5653)  time: 0.3496  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [2980/3125]  eta: 0:00:50  Lr: 0.001875  Loss: -0.2855  Acc@1: 81.2500 (85.9590)  Acc@5: 100.0000 (98.5638)  time: 0.3498  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [2990/3125]  eta: 0:00:47  Lr: 0.001875  Loss: -0.7160  Acc@1: 87.5000 (85.9725)  Acc@5: 100.0000 (98.5644)  time: 0.3503  data: 0.0006  max mem: 2502
Train: Epoch[3/5]  [3000/3125]  eta: 0:00:43  Lr: 0.001875  Loss: -0.3686  Acc@1: 87.5000 (85.9776)  Acc@5: 100.0000 (98.5671)  time: 0.3504  data: 0.0006  max mem: 2502
Train: Epoch[3/5]  [3010/3125]  eta: 0:00:40  Lr: 0.001875  Loss: -0.6094  Acc@1: 87.5000 (85.9993)  Acc@5: 100.0000 (98.5719)  time: 0.3504  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [3020/3125]  eta: 0:00:36  Lr: 0.001875  Loss: -0.6683  Acc@1: 87.5000 (86.0063)  Acc@5: 100.0000 (98.5746)  time: 0.3518  data: 0.0008  max mem: 2502
Train: Epoch[3/5]  [3030/3125]  eta: 0:00:33  Lr: 0.001875  Loss: -0.7582  Acc@1: 87.5000 (86.0050)  Acc@5: 100.0000 (98.5731)  time: 0.3515  data: 0.0008  max mem: 2502
Train: Epoch[3/5]  [3040/3125]  eta: 0:00:29  Lr: 0.001875  Loss: -0.2611  Acc@1: 87.5000 (86.0038)  Acc@5: 100.0000 (98.5716)  time: 0.3495  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [3050/3125]  eta: 0:00:26  Lr: 0.001875  Loss: -0.7112  Acc@1: 87.5000 (86.0066)  Acc@5: 100.0000 (98.5619)  time: 0.3522  data: 0.0018  max mem: 2502
Train: Epoch[3/5]  [3060/3125]  eta: 0:00:22  Lr: 0.001875  Loss: -0.6265  Acc@1: 81.2500 (85.9931)  Acc@5: 100.0000 (98.5605)  time: 0.3521  data: 0.0018  max mem: 2502
Train: Epoch[3/5]  [3070/3125]  eta: 0:00:19  Lr: 0.001875  Loss: -0.4983  Acc@1: 81.2500 (85.9777)  Acc@5: 100.0000 (98.5611)  time: 0.3494  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [3080/3125]  eta: 0:00:15  Lr: 0.001875  Loss: -0.8282  Acc@1: 81.2500 (85.9826)  Acc@5: 100.0000 (98.5617)  time: 0.3494  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [3090/3125]  eta: 0:00:12  Lr: 0.001875  Loss: -0.6861  Acc@1: 87.5000 (85.9875)  Acc@5: 100.0000 (98.5644)  time: 0.3497  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [3100/3125]  eta: 0:00:08  Lr: 0.001875  Loss: -0.9829  Acc@1: 87.5000 (85.9924)  Acc@5: 100.0000 (98.5670)  time: 0.3508  data: 0.0010  max mem: 2502
Train: Epoch[3/5]  [3110/3125]  eta: 0:00:05  Lr: 0.001875  Loss: -0.7334  Acc@1: 87.5000 (86.0113)  Acc@5: 100.0000 (98.5716)  time: 0.3505  data: 0.0011  max mem: 2502
Train: Epoch[3/5]  [3120/3125]  eta: 0:00:01  Lr: 0.001875  Loss: -0.5331  Acc@1: 87.5000 (86.0101)  Acc@5: 100.0000 (98.5742)  time: 0.3505  data: 0.0009  max mem: 2502
Train: Epoch[3/5]  [3124/3125]  eta: 0:00:00  Lr: 0.001875  Loss: -0.1901  Acc@1: 87.5000 (86.0140)  Acc@5: 100.0000 (98.5720)  time: 0.3502  data: 0.0008  max mem: 2502
Train: Epoch[3/5] Total time: 0:18:12 (0.3497 s / it)
Averaged stats: Lr: 0.001875  Loss: -0.1901  Acc@1: 87.5000 (86.0140)  Acc@5: 100.0000 (98.5720)
Train: Epoch[4/5]  [   0/3125]  eta: 0:49:05  Lr: 0.001875  Loss: -0.9477  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)  time: 0.9425  data: 0.5951  max mem: 2502
Train: Epoch[4/5]  [  10/3125]  eta: 0:20:57  Lr: 0.001875  Loss: -0.7986  Acc@1: 93.7500 (89.7727)  Acc@5: 100.0000 (98.8636)  time: 0.4038  data: 0.0549  max mem: 2502
Train: Epoch[4/5]  [  20/3125]  eta: 0:19:35  Lr: 0.001875  Loss: -0.5857  Acc@1: 87.5000 (87.2024)  Acc@5: 100.0000 (97.9167)  time: 0.3505  data: 0.0007  max mem: 2502
Train: Epoch[4/5]  [  30/3125]  eta: 0:19:02  Lr: 0.001875  Loss: -0.8386  Acc@1: 87.5000 (86.6935)  Acc@5: 93.7500 (97.5806)  time: 0.3499  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [  40/3125]  eta: 0:18:44  Lr: 0.001875  Loss: -0.9252  Acc@1: 87.5000 (87.6524)  Acc@5: 100.0000 (98.0183)  time: 0.3494  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [  50/3125]  eta: 0:18:31  Lr: 0.001875  Loss: -0.9621  Acc@1: 93.7500 (87.6225)  Acc@5: 100.0000 (97.6716)  time: 0.3498  data: 0.0008  max mem: 2502
Train: Epoch[4/5]  [  60/3125]  eta: 0:18:22  Lr: 0.001875  Loss: -0.4434  Acc@1: 87.5000 (86.9877)  Acc@5: 100.0000 (97.7459)  time: 0.3500  data: 0.0008  max mem: 2502
Train: Epoch[4/5]  [  70/3125]  eta: 0:18:14  Lr: 0.001875  Loss: -0.2899  Acc@1: 81.2500 (86.5317)  Acc@5: 100.0000 (97.4472)  time: 0.3505  data: 0.0010  max mem: 2502
Train: Epoch[4/5]  [  80/3125]  eta: 0:18:07  Lr: 0.001875  Loss: -0.9246  Acc@1: 81.2500 (86.3426)  Acc@5: 100.0000 (97.5309)  time: 0.3498  data: 0.0010  max mem: 2502
Train: Epoch[4/5]  [  90/3125]  eta: 0:18:02  Lr: 0.001875  Loss: -0.6312  Acc@1: 81.2500 (86.4011)  Acc@5: 100.0000 (97.8022)  time: 0.3508  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [ 100/3125]  eta: 0:17:56  Lr: 0.001875  Loss: -0.6095  Acc@1: 81.2500 (86.0767)  Acc@5: 100.0000 (97.9579)  time: 0.3504  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [ 110/3125]  eta: 0:17:51  Lr: 0.001875  Loss: -0.4882  Acc@1: 87.5000 (86.0923)  Acc@5: 100.0000 (98.0856)  time: 0.3500  data: 0.0013  max mem: 2502
Train: Epoch[4/5]  [ 120/3125]  eta: 0:17:46  Lr: 0.001875  Loss: -0.4897  Acc@1: 87.5000 (85.6405)  Acc@5: 100.0000 (98.0888)  time: 0.3507  data: 0.0014  max mem: 2502
Train: Epoch[4/5]  [ 130/3125]  eta: 0:17:41  Lr: 0.001875  Loss: -0.6865  Acc@1: 81.2500 (85.6393)  Acc@5: 100.0000 (98.0916)  time: 0.3496  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [ 140/3125]  eta: 0:17:37  Lr: 0.001875  Loss: -0.3078  Acc@1: 87.5000 (85.5940)  Acc@5: 100.0000 (98.1826)  time: 0.3499  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [ 150/3125]  eta: 0:17:33  Lr: 0.001875  Loss: -0.6312  Acc@1: 87.5000 (85.6374)  Acc@5: 100.0000 (98.0960)  time: 0.3515  data: 0.0008  max mem: 2502
Train: Epoch[4/5]  [ 160/3125]  eta: 0:17:29  Lr: 0.001875  Loss: -0.6257  Acc@1: 87.5000 (85.8307)  Acc@5: 100.0000 (98.0978)  time: 0.3514  data: 0.0008  max mem: 2502
Train: Epoch[4/5]  [ 170/3125]  eta: 0:17:25  Lr: 0.001875  Loss: -0.5619  Acc@1: 87.5000 (85.8187)  Acc@5: 100.0000 (98.0994)  time: 0.3513  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [ 180/3125]  eta: 0:17:21  Lr: 0.001875  Loss: -0.4955  Acc@1: 87.5000 (86.0497)  Acc@5: 100.0000 (98.1008)  time: 0.3520  data: 0.0012  max mem: 2502
Train: Epoch[4/5]  [ 190/3125]  eta: 0:17:17  Lr: 0.001875  Loss: -0.5469  Acc@1: 87.5000 (85.9948)  Acc@5: 100.0000 (98.1675)  time: 0.3517  data: 0.0012  max mem: 2502
Train: Epoch[4/5]  [ 200/3125]  eta: 0:17:14  Lr: 0.001875  Loss: -0.8132  Acc@1: 87.5000 (86.1007)  Acc@5: 100.0000 (98.2587)  time: 0.3524  data: 0.0011  max mem: 2502
Train: Epoch[4/5]  [ 210/3125]  eta: 0:17:10  Lr: 0.001875  Loss: -0.7236  Acc@1: 87.5000 (86.2263)  Acc@5: 100.0000 (98.2524)  time: 0.3540  data: 0.0028  max mem: 2502
Train: Epoch[4/5]  [ 220/3125]  eta: 0:17:06  Lr: 0.001875  Loss: -0.4966  Acc@1: 87.5000 (86.1708)  Acc@5: 100.0000 (98.2183)  time: 0.3524  data: 0.0021  max mem: 2502
Train: Epoch[4/5]  [ 230/3125]  eta: 0:17:02  Lr: 0.001875  Loss: -0.6796  Acc@1: 87.5000 (86.1742)  Acc@5: 100.0000 (98.1602)  time: 0.3503  data: 0.0007  max mem: 2502
Train: Epoch[4/5]  [ 240/3125]  eta: 0:16:59  Lr: 0.001875  Loss: -0.8614  Acc@1: 87.5000 (86.1774)  Acc@5: 100.0000 (98.2365)  time: 0.3507  data: 0.0007  max mem: 2502
Train: Epoch[4/5]  [ 250/3125]  eta: 0:16:55  Lr: 0.001875  Loss: -0.6379  Acc@1: 87.5000 (86.0309)  Acc@5: 100.0000 (98.2570)  time: 0.3519  data: 0.0010  max mem: 2502
Train: Epoch[4/5]  [ 260/3125]  eta: 0:16:51  Lr: 0.001875  Loss: -0.6556  Acc@1: 81.2500 (85.9674)  Acc@5: 100.0000 (98.2280)  time: 0.3517  data: 0.0010  max mem: 2502
Train: Epoch[4/5]  [ 270/3125]  eta: 0:16:47  Lr: 0.001875  Loss: 0.1123  Acc@1: 87.5000 (85.9087)  Acc@5: 100.0000 (98.1550)  time: 0.3505  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [ 280/3125]  eta: 0:16:44  Lr: 0.001875  Loss: -0.5175  Acc@1: 87.5000 (86.0543)  Acc@5: 100.0000 (98.1094)  time: 0.3504  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [ 290/3125]  eta: 0:16:40  Lr: 0.001875  Loss: -0.6505  Acc@1: 87.5000 (85.9536)  Acc@5: 100.0000 (98.1744)  time: 0.3508  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [ 300/3125]  eta: 0:16:36  Lr: 0.001875  Loss: -0.1395  Acc@1: 87.5000 (86.0257)  Acc@5: 100.0000 (98.2143)  time: 0.3512  data: 0.0010  max mem: 2502
Train: Epoch[4/5]  [ 310/3125]  eta: 0:16:32  Lr: 0.001875  Loss: -0.4779  Acc@1: 87.5000 (85.9928)  Acc@5: 100.0000 (98.2516)  time: 0.3504  data: 0.0011  max mem: 2502
Train: Epoch[4/5]  [ 320/3125]  eta: 0:16:29  Lr: 0.001875  Loss: -1.0285  Acc@1: 87.5000 (86.0592)  Acc@5: 100.0000 (98.2477)  time: 0.3490  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [ 330/3125]  eta: 0:16:25  Lr: 0.001875  Loss: -0.6721  Acc@1: 87.5000 (86.1594)  Acc@5: 100.0000 (98.3006)  time: 0.3502  data: 0.0017  max mem: 2502
Train: Epoch[4/5]  [ 340/3125]  eta: 0:16:21  Lr: 0.001875  Loss: -1.0439  Acc@1: 87.5000 (86.1437)  Acc@5: 100.0000 (98.3321)  time: 0.3505  data: 0.0016  max mem: 2502
Train: Epoch[4/5]  [ 350/3125]  eta: 0:16:17  Lr: 0.001875  Loss: -0.8077  Acc@1: 87.5000 (86.2179)  Acc@5: 100.0000 (98.3618)  time: 0.3498  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [ 360/3125]  eta: 0:16:14  Lr: 0.001875  Loss: -0.5339  Acc@1: 81.2500 (86.1842)  Acc@5: 100.0000 (98.3899)  time: 0.3501  data: 0.0006  max mem: 2502
Train: Epoch[4/5]  [ 370/3125]  eta: 0:16:10  Lr: 0.001875  Loss: -0.6353  Acc@1: 81.2500 (86.2534)  Acc@5: 100.0000 (98.3659)  time: 0.3493  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [ 380/3125]  eta: 0:16:06  Lr: 0.001875  Loss: -0.4597  Acc@1: 87.5000 (86.2369)  Acc@5: 100.0000 (98.3104)  time: 0.3495  data: 0.0011  max mem: 2502
Train: Epoch[4/5]  [ 390/3125]  eta: 0:16:03  Lr: 0.001875  Loss: -0.7559  Acc@1: 87.5000 (86.2852)  Acc@5: 100.0000 (98.3216)  time: 0.3503  data: 0.0011  max mem: 2502
Train: Epoch[4/5]  [ 400/3125]  eta: 0:15:59  Lr: 0.001875  Loss: -0.8191  Acc@1: 87.5000 (86.1752)  Acc@5: 100.0000 (98.3479)  time: 0.3512  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [ 410/3125]  eta: 0:15:55  Lr: 0.001875  Loss: -0.7888  Acc@1: 87.5000 (86.2682)  Acc@5: 100.0000 (98.3729)  time: 0.3512  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [ 420/3125]  eta: 0:15:52  Lr: 0.001875  Loss: -0.9886  Acc@1: 87.5000 (86.2975)  Acc@5: 100.0000 (98.3818)  time: 0.3499  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [ 430/3125]  eta: 0:15:48  Lr: 0.001875  Loss: -0.8225  Acc@1: 87.5000 (86.2964)  Acc@5: 100.0000 (98.3759)  time: 0.3484  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [ 440/3125]  eta: 0:15:44  Lr: 0.001875  Loss: -0.6036  Acc@1: 87.5000 (86.3095)  Acc@5: 100.0000 (98.3985)  time: 0.3489  data: 0.0012  max mem: 2502
Train: Epoch[4/5]  [ 450/3125]  eta: 0:15:41  Lr: 0.001875  Loss: -0.7428  Acc@1: 87.5000 (86.3221)  Acc@5: 100.0000 (98.4202)  time: 0.3509  data: 0.0021  max mem: 2502
Train: Epoch[4/5]  [ 460/3125]  eta: 0:15:37  Lr: 0.001875  Loss: -0.7158  Acc@1: 87.5000 (86.3205)  Acc@5: 100.0000 (98.4544)  time: 0.3505  data: 0.0013  max mem: 2502
Train: Epoch[4/5]  [ 470/3125]  eta: 0:15:33  Lr: 0.001875  Loss: -0.4917  Acc@1: 87.5000 (86.3323)  Acc@5: 100.0000 (98.4607)  time: 0.3489  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [ 480/3125]  eta: 0:15:30  Lr: 0.001875  Loss: -0.3162  Acc@1: 87.5000 (86.3046)  Acc@5: 100.0000 (98.4537)  time: 0.3491  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [ 490/3125]  eta: 0:15:26  Lr: 0.001875  Loss: -0.4280  Acc@1: 87.5000 (86.3544)  Acc@5: 100.0000 (98.4725)  time: 0.3500  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [ 500/3125]  eta: 0:15:23  Lr: 0.001875  Loss: -1.0557  Acc@1: 87.5000 (86.3897)  Acc@5: 100.0000 (98.5030)  time: 0.3504  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [ 510/3125]  eta: 0:15:19  Lr: 0.001875  Loss: -0.7646  Acc@1: 87.5000 (86.3625)  Acc@5: 100.0000 (98.4834)  time: 0.3503  data: 0.0007  max mem: 2502
Train: Epoch[4/5]  [ 520/3125]  eta: 0:15:15  Lr: 0.001875  Loss: -0.7621  Acc@1: 87.5000 (86.3004)  Acc@5: 100.0000 (98.4525)  time: 0.3501  data: 0.0008  max mem: 2502
Train: Epoch[4/5]  [ 530/3125]  eta: 0:15:12  Lr: 0.001875  Loss: -0.6247  Acc@1: 87.5000 (86.3230)  Acc@5: 100.0000 (98.4581)  time: 0.3500  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [ 540/3125]  eta: 0:15:08  Lr: 0.001875  Loss: -0.4605  Acc@1: 87.5000 (86.3101)  Acc@5: 100.0000 (98.4519)  time: 0.3496  data: 0.0007  max mem: 2502
Train: Epoch[4/5]  [ 550/3125]  eta: 0:15:05  Lr: 0.001875  Loss: -0.4261  Acc@1: 81.2500 (86.2863)  Acc@5: 100.0000 (98.4574)  time: 0.3512  data: 0.0007  max mem: 2502
Train: Epoch[4/5]  [ 560/3125]  eta: 0:15:01  Lr: 0.001875  Loss: -0.6755  Acc@1: 87.5000 (86.2857)  Acc@5: 100.0000 (98.4403)  time: 0.3511  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [ 570/3125]  eta: 0:14:58  Lr: 0.001875  Loss: -0.5006  Acc@1: 87.5000 (86.2631)  Acc@5: 93.7500 (98.3581)  time: 0.3494  data: 0.0011  max mem: 2502
Train: Epoch[4/5]  [ 580/3125]  eta: 0:14:54  Lr: 0.001875  Loss: -0.8693  Acc@1: 87.5000 (86.3382)  Acc@5: 93.7500 (98.3541)  time: 0.3499  data: 0.0011  max mem: 2502
Train: Epoch[4/5]  [ 590/3125]  eta: 0:14:50  Lr: 0.001875  Loss: -0.1585  Acc@1: 87.5000 (86.3261)  Acc@5: 100.0000 (98.3503)  time: 0.3493  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [ 600/3125]  eta: 0:14:47  Lr: 0.001875  Loss: -0.4855  Acc@1: 87.5000 (86.3769)  Acc@5: 100.0000 (98.3465)  time: 0.3491  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [ 610/3125]  eta: 0:14:43  Lr: 0.001875  Loss: -0.9921  Acc@1: 93.7500 (86.4157)  Acc@5: 100.0000 (98.3736)  time: 0.3491  data: 0.0009  max mem: 2502
Train: Epoch[4/5]  [ 620/3125]  eta: 0:14:39  Lr: 0.001875  Loss: -0.7387  Acc@1: 87.5000 (86.4432)  Acc@5: 100.0000 (98.3595)  time: 0.3481  data: 0.0008  max mem: 2502
Train: Epoch[4/5]  [ 630/3125]  eta: 0:14:36  Lr: 0.001875  Loss: -0.3870  Acc@1: 87.5000 (86.4204)  Acc@5: 100.0000 (98.3558)  time: 0.3481  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [ 640/3125]  eta: 0:14:32  Lr: 0.001875  Loss: -0.6439  Acc@1: 81.2500 (86.3982)  Acc@5: 100.0000 (98.3717)  time: 0.3478  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [ 650/3125]  eta: 0:14:29  Lr: 0.001875  Loss: -0.4762  Acc@1: 87.5000 (86.4247)  Acc@5: 100.0000 (98.3679)  time: 0.3475  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [ 660/3125]  eta: 0:14:25  Lr: 0.001875  Loss: -0.2998  Acc@1: 87.5000 (86.3937)  Acc@5: 100.0000 (98.3642)  time: 0.3479  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [ 670/3125]  eta: 0:14:21  Lr: 0.001875  Loss: -0.5805  Acc@1: 87.5000 (86.4382)  Acc@5: 100.0000 (98.3513)  time: 0.3483  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [ 680/3125]  eta: 0:14:18  Lr: 0.001875  Loss: -0.3500  Acc@1: 87.5000 (86.4446)  Acc@5: 100.0000 (98.3480)  time: 0.3483  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [ 690/3125]  eta: 0:14:14  Lr: 0.001875  Loss: -0.8295  Acc@1: 87.5000 (86.4689)  Acc@5: 100.0000 (98.3448)  time: 0.3495  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [ 700/3125]  eta: 0:14:11  Lr: 0.001875  Loss: -0.9405  Acc@1: 87.5000 (86.5014)  Acc@5: 100.0000 (98.3595)  time: 0.3496  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [ 710/3125]  eta: 0:14:07  Lr: 0.001875  Loss: -0.6093  Acc@1: 87.5000 (86.4979)  Acc@5: 100.0000 (98.3738)  time: 0.3493  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [ 720/3125]  eta: 0:14:03  Lr: 0.001875  Loss: -0.7010  Acc@1: 87.5000 (86.4858)  Acc@5: 100.0000 (98.3877)  time: 0.3497  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [ 730/3125]  eta: 0:14:00  Lr: 0.001875  Loss: -0.6265  Acc@1: 87.5000 (86.4826)  Acc@5: 100.0000 (98.3926)  time: 0.3493  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [ 740/3125]  eta: 0:13:56  Lr: 0.001875  Loss: -0.6007  Acc@1: 87.5000 (86.4626)  Acc@5: 100.0000 (98.3721)  time: 0.3496  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [ 750/3125]  eta: 0:13:53  Lr: 0.001875  Loss: -0.9281  Acc@1: 87.5000 (86.5013)  Acc@5: 100.0000 (98.3772)  time: 0.3500  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [ 760/3125]  eta: 0:13:49  Lr: 0.001875  Loss: -0.6968  Acc@1: 87.5000 (86.4405)  Acc@5: 100.0000 (98.3821)  time: 0.3514  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [ 770/3125]  eta: 0:13:46  Lr: 0.001875  Loss: -0.5320  Acc@1: 81.2500 (86.4137)  Acc@5: 100.0000 (98.3868)  time: 0.3515  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [ 780/3125]  eta: 0:13:42  Lr: 0.001875  Loss: -0.7170  Acc@1: 81.2500 (86.3156)  Acc@5: 100.0000 (98.3675)  time: 0.3513  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [ 790/3125]  eta: 0:13:39  Lr: 0.001875  Loss: -0.8207  Acc@1: 81.2500 (86.2674)  Acc@5: 100.0000 (98.3644)  time: 0.3511  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [ 800/3125]  eta: 0:13:35  Lr: 0.001875  Loss: -0.3187  Acc@1: 87.5000 (86.2828)  Acc@5: 100.0000 (98.3380)  time: 0.3502  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [ 810/3125]  eta: 0:13:32  Lr: 0.001875  Loss: -0.8678  Acc@1: 81.2500 (86.2438)  Acc@5: 100.0000 (98.3354)  time: 0.3496  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [ 820/3125]  eta: 0:13:28  Lr: 0.001875  Loss: -0.8201  Acc@1: 81.2500 (86.2058)  Acc@5: 100.0000 (98.3328)  time: 0.3496  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [ 830/3125]  eta: 0:13:25  Lr: 0.001875  Loss: 0.5100  Acc@1: 81.2500 (86.1537)  Acc@5: 100.0000 (98.2927)  time: 0.3507  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [ 840/3125]  eta: 0:13:21  Lr: 0.001875  Loss: -0.8874  Acc@1: 87.5000 (86.2069)  Acc@5: 100.0000 (98.3056)  time: 0.3504  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [ 850/3125]  eta: 0:13:18  Lr: 0.001875  Loss: -0.7591  Acc@1: 87.5000 (86.1780)  Acc@5: 100.0000 (98.3182)  time: 0.3496  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [ 860/3125]  eta: 0:13:14  Lr: 0.001875  Loss: -0.8227  Acc@1: 87.5000 (86.1716)  Acc@5: 100.0000 (98.3159)  time: 0.3498  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [ 870/3125]  eta: 0:13:11  Lr: 0.001875  Loss: -0.5449  Acc@1: 87.5000 (86.1797)  Acc@5: 100.0000 (98.3209)  time: 0.3503  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [ 880/3125]  eta: 0:13:07  Lr: 0.001875  Loss: -0.7961  Acc@1: 87.5000 (86.1805)  Acc@5: 100.0000 (98.3329)  time: 0.3504  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [ 890/3125]  eta: 0:13:04  Lr: 0.001875  Loss: -0.3045  Acc@1: 87.5000 (86.2304)  Acc@5: 100.0000 (98.3375)  time: 0.3501  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [ 900/3125]  eta: 0:13:00  Lr: 0.001875  Loss: -0.5162  Acc@1: 87.5000 (86.2306)  Acc@5: 100.0000 (98.3352)  time: 0.3496  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [ 910/3125]  eta: 0:12:56  Lr: 0.001875  Loss: -0.5692  Acc@1: 87.5000 (86.2377)  Acc@5: 100.0000 (98.3260)  time: 0.3498  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [ 920/3125]  eta: 0:12:53  Lr: 0.001875  Loss: -0.8417  Acc@1: 87.5000 (86.2378)  Acc@5: 100.0000 (98.3306)  time: 0.3505  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [ 930/3125]  eta: 0:12:49  Lr: 0.001875  Loss: -0.8561  Acc@1: 87.5000 (86.2312)  Acc@5: 100.0000 (98.3351)  time: 0.3500  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [ 940/3125]  eta: 0:12:46  Lr: 0.001875  Loss: -0.7139  Acc@1: 87.5000 (86.2314)  Acc@5: 100.0000 (98.3130)  time: 0.3506  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [ 950/3125]  eta: 0:12:42  Lr: 0.001875  Loss: -0.4180  Acc@1: 87.5000 (86.2250)  Acc@5: 100.0000 (98.3241)  time: 0.3513  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [ 960/3125]  eta: 0:12:39  Lr: 0.001875  Loss: -0.6571  Acc@1: 87.5000 (86.2123)  Acc@5: 100.0000 (98.3156)  time: 0.3499  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [ 970/3125]  eta: 0:12:35  Lr: 0.001875  Loss: -0.3309  Acc@1: 81.2500 (86.1869)  Acc@5: 100.0000 (98.3072)  time: 0.3495  data: 0.0007  max mem: 2502
Train: Epoch[4/5]  [ 980/3125]  eta: 0:12:32  Lr: 0.001875  Loss: -0.7201  Acc@1: 87.5000 (86.1685)  Acc@5: 100.0000 (98.3180)  time: 0.3490  data: 0.0007  max mem: 2502
Train: Epoch[4/5]  [ 990/3125]  eta: 0:12:28  Lr: 0.001875  Loss: -0.7802  Acc@1: 87.5000 (86.1440)  Acc@5: 100.0000 (98.3287)  time: 0.3479  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [1000/3125]  eta: 0:12:25  Lr: 0.001875  Loss: -0.5389  Acc@1: 87.5000 (86.1638)  Acc@5: 100.0000 (98.3267)  time: 0.3473  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [1010/3125]  eta: 0:12:21  Lr: 0.001875  Loss: -0.2387  Acc@1: 87.5000 (86.1152)  Acc@5: 100.0000 (98.3123)  time: 0.3475  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [1020/3125]  eta: 0:12:18  Lr: 0.001875  Loss: -0.6186  Acc@1: 81.2500 (86.1227)  Acc@5: 100.0000 (98.2982)  time: 0.3484  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [1030/3125]  eta: 0:12:14  Lr: 0.001875  Loss: -0.6384  Acc@1: 87.5000 (86.1542)  Acc@5: 100.0000 (98.2966)  time: 0.3492  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [1040/3125]  eta: 0:12:10  Lr: 0.001875  Loss: -0.3453  Acc@1: 87.5000 (86.1671)  Acc@5: 100.0000 (98.3069)  time: 0.3490  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [1050/3125]  eta: 0:12:07  Lr: 0.001875  Loss: -0.5943  Acc@1: 87.5000 (86.1977)  Acc@5: 100.0000 (98.3171)  time: 0.3486  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [1060/3125]  eta: 0:12:03  Lr: 0.001875  Loss: -0.7618  Acc@1: 87.5000 (86.2453)  Acc@5: 100.0000 (98.3329)  time: 0.3488  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [1070/3125]  eta: 0:12:00  Lr: 0.001875  Loss: -0.6488  Acc@1: 87.5000 (86.2570)  Acc@5: 100.0000 (98.3427)  time: 0.3485  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [1080/3125]  eta: 0:11:56  Lr: 0.001875  Loss: -0.4793  Acc@1: 87.5000 (86.2338)  Acc@5: 100.0000 (98.3407)  time: 0.3480  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [1090/3125]  eta: 0:11:53  Lr: 0.001875  Loss: -0.5324  Acc@1: 87.5000 (86.2225)  Acc@5: 100.0000 (98.3444)  time: 0.3487  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [1100/3125]  eta: 0:11:49  Lr: 0.001875  Loss: -0.8095  Acc@1: 87.5000 (86.1887)  Acc@5: 100.0000 (98.3424)  time: 0.3498  data: 0.0016  max mem: 2502
Train: Epoch[4/5]  [1110/3125]  eta: 0:11:46  Lr: 0.001875  Loss: -0.6160  Acc@1: 87.5000 (86.1555)  Acc@5: 100.0000 (98.3292)  time: 0.3487  data: 0.0015  max mem: 2502
Train: Epoch[4/5]  [1120/3125]  eta: 0:11:42  Lr: 0.001875  Loss: -0.6407  Acc@1: 87.5000 (86.1675)  Acc@5: 100.0000 (98.3274)  time: 0.3485  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [1130/3125]  eta: 0:11:39  Lr: 0.001875  Loss: -1.0344  Acc@1: 87.5000 (86.1627)  Acc@5: 100.0000 (98.3090)  time: 0.3489  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [1140/3125]  eta: 0:11:35  Lr: 0.001875  Loss: -0.7121  Acc@1: 81.2500 (86.1415)  Acc@5: 100.0000 (98.3184)  time: 0.3478  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [1150/3125]  eta: 0:11:32  Lr: 0.001875  Loss: -0.1010  Acc@1: 87.5000 (86.1642)  Acc@5: 100.0000 (98.3221)  time: 0.3484  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [1160/3125]  eta: 0:11:28  Lr: 0.001875  Loss: -0.2349  Acc@1: 87.5000 (86.1596)  Acc@5: 100.0000 (98.3204)  time: 0.3486  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [1170/3125]  eta: 0:11:24  Lr: 0.001875  Loss: -0.6863  Acc@1: 87.5000 (86.1710)  Acc@5: 100.0000 (98.3187)  time: 0.3481  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [1180/3125]  eta: 0:11:21  Lr: 0.001875  Loss: -0.7220  Acc@1: 87.5000 (86.1664)  Acc@5: 100.0000 (98.3224)  time: 0.3489  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [1190/3125]  eta: 0:11:17  Lr: 0.001875  Loss: -0.4779  Acc@1: 87.5000 (86.1671)  Acc@5: 100.0000 (98.3260)  time: 0.3495  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [1200/3125]  eta: 0:11:14  Lr: 0.001875  Loss: -0.0746  Acc@1: 81.2500 (86.1470)  Acc@5: 100.0000 (98.3191)  time: 0.3500  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [1210/3125]  eta: 0:11:10  Lr: 0.001875  Loss: -0.5333  Acc@1: 81.2500 (86.1220)  Acc@5: 100.0000 (98.3330)  time: 0.3501  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [1220/3125]  eta: 0:11:07  Lr: 0.001875  Loss: -0.3888  Acc@1: 81.2500 (86.1026)  Acc@5: 100.0000 (98.3313)  time: 0.3496  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [1230/3125]  eta: 0:11:03  Lr: 0.001875  Loss: -0.4754  Acc@1: 81.2500 (86.0936)  Acc@5: 100.0000 (98.3347)  time: 0.3503  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [1240/3125]  eta: 0:11:00  Lr: 0.001875  Loss: -0.6927  Acc@1: 87.5000 (86.1301)  Acc@5: 100.0000 (98.3380)  time: 0.3521  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [1250/3125]  eta: 0:10:56  Lr: 0.001875  Loss: -0.3975  Acc@1: 87.5000 (86.0961)  Acc@5: 100.0000 (98.3463)  time: 0.3532  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [1260/3125]  eta: 0:10:53  Lr: 0.001875  Loss: -0.5483  Acc@1: 87.5000 (86.1122)  Acc@5: 100.0000 (98.3495)  time: 0.3520  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [1270/3125]  eta: 0:10:49  Lr: 0.001875  Loss: -0.6980  Acc@1: 87.5000 (86.0838)  Acc@5: 100.0000 (98.3478)  time: 0.3511  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [1280/3125]  eta: 0:10:46  Lr: 0.001875  Loss: -0.4883  Acc@1: 81.2500 (86.0461)  Acc@5: 100.0000 (98.3509)  time: 0.3508  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [1290/3125]  eta: 0:10:42  Lr: 0.001875  Loss: -0.8741  Acc@1: 81.2500 (86.0476)  Acc@5: 100.0000 (98.3491)  time: 0.3508  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [1300/3125]  eta: 0:10:39  Lr: 0.001875  Loss: -0.7388  Acc@1: 87.5000 (86.0540)  Acc@5: 100.0000 (98.3426)  time: 0.3516  data: 0.0010  max mem: 2502
Train: Epoch[4/5]  [1310/3125]  eta: 0:10:36  Lr: 0.001875  Loss: -0.0258  Acc@1: 87.5000 (86.0650)  Acc@5: 100.0000 (98.3457)  time: 0.3514  data: 0.0009  max mem: 2502
Train: Epoch[4/5]  [1320/3125]  eta: 0:10:32  Lr: 0.001875  Loss: -0.7377  Acc@1: 87.5000 (86.0428)  Acc@5: 100.0000 (98.3535)  time: 0.3518  data: 0.0006  max mem: 2502
Train: Epoch[4/5]  [1330/3125]  eta: 0:10:29  Lr: 0.001875  Loss: -0.7972  Acc@1: 87.5000 (86.0490)  Acc@5: 100.0000 (98.3518)  time: 0.3519  data: 0.0006  max mem: 2502
Train: Epoch[4/5]  [1340/3125]  eta: 0:10:25  Lr: 0.001875  Loss: -0.6144  Acc@1: 87.5000 (86.0552)  Acc@5: 100.0000 (98.3641)  time: 0.3512  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [1350/3125]  eta: 0:10:22  Lr: 0.001875  Loss: -0.8949  Acc@1: 87.5000 (86.0335)  Acc@5: 100.0000 (98.3716)  time: 0.3506  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [1360/3125]  eta: 0:10:18  Lr: 0.001875  Loss: -0.2640  Acc@1: 87.5000 (86.0535)  Acc@5: 100.0000 (98.3560)  time: 0.3508  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [1370/3125]  eta: 0:10:15  Lr: 0.001875  Loss: -0.4600  Acc@1: 87.5000 (86.0093)  Acc@5: 93.7500 (98.3497)  time: 0.3515  data: 0.0013  max mem: 2502
Train: Epoch[4/5]  [1380/3125]  eta: 0:10:11  Lr: 0.001875  Loss: -0.6838  Acc@1: 81.2500 (85.9839)  Acc@5: 100.0000 (98.3526)  time: 0.3510  data: 0.0016  max mem: 2502
Train: Epoch[4/5]  [1390/3125]  eta: 0:10:08  Lr: 0.001875  Loss: -0.5609  Acc@1: 81.2500 (85.9993)  Acc@5: 100.0000 (98.3600)  time: 0.3497  data: 0.0007  max mem: 2502
Train: Epoch[4/5]  [1400/3125]  eta: 0:10:04  Lr: 0.001875  Loss: -0.9545  Acc@1: 87.5000 (86.0368)  Acc@5: 100.0000 (98.3628)  time: 0.3509  data: 0.0015  max mem: 2502
Train: Epoch[4/5]  [1410/3125]  eta: 0:10:01  Lr: 0.001875  Loss: -0.5872  Acc@1: 87.5000 (86.0693)  Acc@5: 100.0000 (98.3744)  time: 0.3512  data: 0.0015  max mem: 2502
Train: Epoch[4/5]  [1420/3125]  eta: 0:09:57  Lr: 0.001875  Loss: -0.5886  Acc@1: 93.7500 (86.0793)  Acc@5: 100.0000 (98.3770)  time: 0.3493  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [1430/3125]  eta: 0:09:53  Lr: 0.001875  Loss: -0.6975  Acc@1: 81.2500 (86.0500)  Acc@5: 100.0000 (98.3840)  time: 0.3488  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [1440/3125]  eta: 0:09:50  Lr: 0.001875  Loss: -0.6979  Acc@1: 81.2500 (86.0514)  Acc@5: 100.0000 (98.3865)  time: 0.3488  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [1450/3125]  eta: 0:09:46  Lr: 0.001875  Loss: -0.2633  Acc@1: 87.5000 (86.0656)  Acc@5: 100.0000 (98.3933)  time: 0.3487  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [1460/3125]  eta: 0:09:43  Lr: 0.001875  Loss: -0.8886  Acc@1: 87.5000 (86.0883)  Acc@5: 100.0000 (98.4001)  time: 0.3493  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [1470/3125]  eta: 0:09:39  Lr: 0.001875  Loss: -0.5697  Acc@1: 87.5000 (86.0682)  Acc@5: 100.0000 (98.3897)  time: 0.3496  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [1480/3125]  eta: 0:09:36  Lr: 0.001875  Loss: -0.7706  Acc@1: 87.5000 (86.0652)  Acc@5: 100.0000 (98.3837)  time: 0.3484  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [1490/3125]  eta: 0:09:32  Lr: 0.001875  Loss: -0.8561  Acc@1: 87.5000 (86.1083)  Acc@5: 100.0000 (98.3903)  time: 0.3479  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [1500/3125]  eta: 0:09:29  Lr: 0.001875  Loss: -0.7694  Acc@1: 87.5000 (86.1051)  Acc@5: 100.0000 (98.3927)  time: 0.3482  data: 0.0012  max mem: 2502
Train: Epoch[4/5]  [1510/3125]  eta: 0:09:25  Lr: 0.001875  Loss: -0.8258  Acc@1: 87.5000 (86.1474)  Acc@5: 100.0000 (98.3992)  time: 0.3482  data: 0.0011  max mem: 2502
Train: Epoch[4/5]  [1520/3125]  eta: 0:09:22  Lr: 0.001875  Loss: -0.6881  Acc@1: 93.7500 (86.1892)  Acc@5: 100.0000 (98.4057)  time: 0.3475  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [1530/3125]  eta: 0:09:18  Lr: 0.001875  Loss: -0.8498  Acc@1: 87.5000 (86.1733)  Acc@5: 100.0000 (98.3997)  time: 0.3473  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [1540/3125]  eta: 0:09:15  Lr: 0.001875  Loss: -0.4895  Acc@1: 81.2500 (86.1454)  Acc@5: 100.0000 (98.4020)  time: 0.3473  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [1550/3125]  eta: 0:09:11  Lr: 0.001875  Loss: -0.8744  Acc@1: 81.2500 (86.1501)  Acc@5: 100.0000 (98.4002)  time: 0.3479  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [1560/3125]  eta: 0:09:08  Lr: 0.001875  Loss: -0.7172  Acc@1: 81.2500 (86.1187)  Acc@5: 100.0000 (98.3824)  time: 0.3487  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [1570/3125]  eta: 0:09:04  Lr: 0.001875  Loss: -0.9763  Acc@1: 81.2500 (86.1076)  Acc@5: 100.0000 (98.3768)  time: 0.3482  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [1580/3125]  eta: 0:09:01  Lr: 0.001875  Loss: -0.9112  Acc@1: 87.5000 (86.1243)  Acc@5: 100.0000 (98.3792)  time: 0.3484  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [1590/3125]  eta: 0:08:57  Lr: 0.001875  Loss: -0.5519  Acc@1: 81.2500 (86.1054)  Acc@5: 100.0000 (98.3658)  time: 0.3487  data: 0.0008  max mem: 2502
Train: Epoch[4/5]  [1600/3125]  eta: 0:08:54  Lr: 0.001875  Loss: -0.8593  Acc@1: 81.2500 (86.0985)  Acc@5: 100.0000 (98.3721)  time: 0.3479  data: 0.0012  max mem: 2502
Train: Epoch[4/5]  [1610/3125]  eta: 0:08:50  Lr: 0.001875  Loss: -0.3578  Acc@1: 87.5000 (86.1034)  Acc@5: 100.0000 (98.3667)  time: 0.3471  data: 0.0007  max mem: 2502
Train: Epoch[4/5]  [1620/3125]  eta: 0:08:46  Lr: 0.001875  Loss: -0.6636  Acc@1: 87.5000 (86.1235)  Acc@5: 100.0000 (98.3768)  time: 0.3469  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [1630/3125]  eta: 0:08:43  Lr: 0.001875  Loss: -0.7234  Acc@1: 81.2500 (86.0822)  Acc@5: 100.0000 (98.3829)  time: 0.3475  data: 0.0007  max mem: 2502
Train: Epoch[4/5]  [1640/3125]  eta: 0:08:39  Lr: 0.001875  Loss: -0.9731  Acc@1: 81.2500 (86.0946)  Acc@5: 100.0000 (98.3889)  time: 0.3473  data: 0.0006  max mem: 2502
Train: Epoch[4/5]  [1650/3125]  eta: 0:08:36  Lr: 0.001875  Loss: -0.9373  Acc@1: 87.5000 (86.0804)  Acc@5: 100.0000 (98.3836)  time: 0.3473  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [1660/3125]  eta: 0:08:32  Lr: 0.001875  Loss: -0.8104  Acc@1: 81.2500 (86.0438)  Acc@5: 100.0000 (98.3669)  time: 0.3476  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [1670/3125]  eta: 0:08:29  Lr: 0.001875  Loss: -0.7584  Acc@1: 81.2500 (86.0450)  Acc@5: 100.0000 (98.3618)  time: 0.3477  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [1680/3125]  eta: 0:08:25  Lr: 0.001875  Loss: 0.0010  Acc@1: 87.5000 (86.0463)  Acc@5: 100.0000 (98.3678)  time: 0.3486  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [1690/3125]  eta: 0:08:22  Lr: 0.001875  Loss: -0.7492  Acc@1: 87.5000 (86.0253)  Acc@5: 100.0000 (98.3627)  time: 0.3486  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [1700/3125]  eta: 0:08:18  Lr: 0.001875  Loss: -0.4816  Acc@1: 87.5000 (86.0340)  Acc@5: 100.0000 (98.3613)  time: 0.3478  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [1710/3125]  eta: 0:08:15  Lr: 0.001875  Loss: -0.7724  Acc@1: 87.5000 (86.0608)  Acc@5: 100.0000 (98.3708)  time: 0.3479  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [1720/3125]  eta: 0:08:11  Lr: 0.001875  Loss: -0.7746  Acc@1: 87.5000 (86.0764)  Acc@5: 100.0000 (98.3767)  time: 0.3481  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [1730/3125]  eta: 0:08:08  Lr: 0.001875  Loss: -0.7952  Acc@1: 87.5000 (86.1027)  Acc@5: 100.0000 (98.3824)  time: 0.3492  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [1740/3125]  eta: 0:08:04  Lr: 0.001875  Loss: -0.6670  Acc@1: 87.5000 (86.1143)  Acc@5: 100.0000 (98.3774)  time: 0.3495  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [1750/3125]  eta: 0:08:01  Lr: 0.001875  Loss: -0.8811  Acc@1: 87.5000 (86.1258)  Acc@5: 100.0000 (98.3652)  time: 0.3488  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [1760/3125]  eta: 0:07:57  Lr: 0.001875  Loss: -0.5707  Acc@1: 87.5000 (86.1265)  Acc@5: 100.0000 (98.3639)  time: 0.3493  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [1770/3125]  eta: 0:07:54  Lr: 0.001875  Loss: -0.5854  Acc@1: 81.2500 (86.1201)  Acc@5: 100.0000 (98.3696)  time: 0.3515  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [1780/3125]  eta: 0:07:50  Lr: 0.001875  Loss: -0.2872  Acc@1: 81.2500 (86.1068)  Acc@5: 100.0000 (98.3717)  time: 0.3516  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [1790/3125]  eta: 0:07:47  Lr: 0.001875  Loss: -0.3326  Acc@1: 81.2500 (86.0867)  Acc@5: 100.0000 (98.3668)  time: 0.3495  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [1800/3125]  eta: 0:07:43  Lr: 0.001875  Loss: -0.6799  Acc@1: 87.5000 (86.1084)  Acc@5: 100.0000 (98.3655)  time: 0.3496  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [1810/3125]  eta: 0:07:40  Lr: 0.001875  Loss: -0.9368  Acc@1: 87.5000 (86.1299)  Acc@5: 100.0000 (98.3676)  time: 0.3495  data: 0.0006  max mem: 2502
Train: Epoch[4/5]  [1820/3125]  eta: 0:07:36  Lr: 0.001875  Loss: -0.5276  Acc@1: 87.5000 (86.1271)  Acc@5: 100.0000 (98.3697)  time: 0.3490  data: 0.0007  max mem: 2502
Train: Epoch[4/5]  [1830/3125]  eta: 0:07:33  Lr: 0.001875  Loss: -0.7979  Acc@1: 87.5000 (86.1483)  Acc@5: 100.0000 (98.3752)  time: 0.3512  data: 0.0011  max mem: 2502
Train: Epoch[4/5]  [1840/3125]  eta: 0:07:29  Lr: 0.001875  Loss: -0.4399  Acc@1: 87.5000 (86.1488)  Acc@5: 100.0000 (98.3705)  time: 0.3514  data: 0.0011  max mem: 2502
Train: Epoch[4/5]  [1850/3125]  eta: 0:07:26  Lr: 0.001875  Loss: -0.7650  Acc@1: 87.5000 (86.1325)  Acc@5: 100.0000 (98.3759)  time: 0.3502  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [1860/3125]  eta: 0:07:22  Lr: 0.001875  Loss: -0.9472  Acc@1: 87.5000 (86.1566)  Acc@5: 100.0000 (98.3812)  time: 0.3506  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [1870/3125]  eta: 0:07:19  Lr: 0.001875  Loss: -0.6609  Acc@1: 87.5000 (86.1638)  Acc@5: 100.0000 (98.3799)  time: 0.3507  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [1880/3125]  eta: 0:07:15  Lr: 0.001875  Loss: -0.8876  Acc@1: 87.5000 (86.1776)  Acc@5: 100.0000 (98.3818)  time: 0.3503  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [1890/3125]  eta: 0:07:12  Lr: 0.001875  Loss: -0.4497  Acc@1: 87.5000 (86.1879)  Acc@5: 100.0000 (98.3871)  time: 0.3507  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [1900/3125]  eta: 0:07:08  Lr: 0.001875  Loss: -0.4972  Acc@1: 87.5000 (86.1948)  Acc@5: 100.0000 (98.3956)  time: 0.3505  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [1910/3125]  eta: 0:07:05  Lr: 0.001875  Loss: -0.3559  Acc@1: 87.5000 (86.2147)  Acc@5: 100.0000 (98.4040)  time: 0.3498  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [1920/3125]  eta: 0:07:01  Lr: 0.001875  Loss: -0.2364  Acc@1: 87.5000 (86.1986)  Acc@5: 100.0000 (98.4058)  time: 0.3508  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [1930/3125]  eta: 0:06:58  Lr: 0.001875  Loss: -0.8661  Acc@1: 87.5000 (86.2150)  Acc@5: 100.0000 (98.4076)  time: 0.3516  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [1940/3125]  eta: 0:06:54  Lr: 0.001875  Loss: -0.4448  Acc@1: 87.5000 (86.2023)  Acc@5: 100.0000 (98.4125)  time: 0.3516  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [1950/3125]  eta: 0:06:51  Lr: 0.001875  Loss: -0.4870  Acc@1: 87.5000 (86.2122)  Acc@5: 100.0000 (98.4111)  time: 0.3511  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [1960/3125]  eta: 0:06:47  Lr: 0.001875  Loss: -0.3988  Acc@1: 87.5000 (86.2124)  Acc@5: 100.0000 (98.4064)  time: 0.3504  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [1970/3125]  eta: 0:06:44  Lr: 0.001875  Loss: -0.7023  Acc@1: 87.5000 (86.2221)  Acc@5: 100.0000 (98.4113)  time: 0.3502  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [1980/3125]  eta: 0:06:40  Lr: 0.001875  Loss: -0.6588  Acc@1: 87.5000 (86.2317)  Acc@5: 100.0000 (98.4194)  time: 0.3508  data: 0.0012  max mem: 2502
Train: Epoch[4/5]  [1990/3125]  eta: 0:06:37  Lr: 0.001875  Loss: -0.8969  Acc@1: 81.2500 (86.2067)  Acc@5: 100.0000 (98.4210)  time: 0.3510  data: 0.0015  max mem: 2502
Train: Epoch[4/5]  [2000/3125]  eta: 0:06:33  Lr: 0.001875  Loss: -0.4196  Acc@1: 87.5000 (86.2194)  Acc@5: 100.0000 (98.4227)  time: 0.3501  data: 0.0008  max mem: 2502
Train: Epoch[4/5]  [2010/3125]  eta: 0:06:30  Lr: 0.001875  Loss: -0.8138  Acc@1: 87.5000 (86.2227)  Acc@5: 100.0000 (98.4243)  time: 0.3496  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [2020/3125]  eta: 0:06:26  Lr: 0.001875  Loss: -0.6907  Acc@1: 87.5000 (86.2321)  Acc@5: 100.0000 (98.4197)  time: 0.3499  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [2030/3125]  eta: 0:06:23  Lr: 0.001875  Loss: -0.8624  Acc@1: 87.5000 (86.2537)  Acc@5: 100.0000 (98.4275)  time: 0.3498  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [2040/3125]  eta: 0:06:19  Lr: 0.001875  Loss: -0.6348  Acc@1: 87.5000 (86.2476)  Acc@5: 100.0000 (98.4260)  time: 0.3497  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [2050/3125]  eta: 0:06:16  Lr: 0.001875  Loss: -0.7314  Acc@1: 87.5000 (86.2598)  Acc@5: 100.0000 (98.4185)  time: 0.3500  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [2060/3125]  eta: 0:06:12  Lr: 0.001875  Loss: -0.6653  Acc@1: 87.5000 (86.2567)  Acc@5: 100.0000 (98.4231)  time: 0.3503  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [2070/3125]  eta: 0:06:09  Lr: 0.001875  Loss: -0.6947  Acc@1: 87.5000 (86.2657)  Acc@5: 100.0000 (98.4217)  time: 0.3498  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [2080/3125]  eta: 0:06:05  Lr: 0.001875  Loss: -0.6949  Acc@1: 87.5000 (86.2476)  Acc@5: 100.0000 (98.4142)  time: 0.3494  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [2090/3125]  eta: 0:06:02  Lr: 0.001875  Loss: -0.8266  Acc@1: 81.2500 (86.2506)  Acc@5: 100.0000 (98.4158)  time: 0.3496  data: 0.0008  max mem: 2502
Train: Epoch[4/5]  [2100/3125]  eta: 0:05:58  Lr: 0.001875  Loss: -1.0060  Acc@1: 87.5000 (86.2655)  Acc@5: 100.0000 (98.4115)  time: 0.3489  data: 0.0006  max mem: 2502
Train: Epoch[4/5]  [2110/3125]  eta: 0:05:55  Lr: 0.001875  Loss: 0.0285  Acc@1: 87.5000 (86.2476)  Acc@5: 100.0000 (98.4072)  time: 0.3491  data: 0.0006  max mem: 2502
Train: Epoch[4/5]  [2120/3125]  eta: 0:05:51  Lr: 0.001875  Loss: -0.6540  Acc@1: 87.5000 (86.2447)  Acc@5: 100.0000 (98.4058)  time: 0.3494  data: 0.0006  max mem: 2502
Train: Epoch[4/5]  [2130/3125]  eta: 0:05:48  Lr: 0.001875  Loss: -0.7316  Acc@1: 87.5000 (86.2594)  Acc@5: 100.0000 (98.4133)  time: 0.3494  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [2140/3125]  eta: 0:05:44  Lr: 0.001875  Loss: -0.4453  Acc@1: 87.5000 (86.2681)  Acc@5: 100.0000 (98.4207)  time: 0.3496  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [2150/3125]  eta: 0:05:41  Lr: 0.001875  Loss: -0.9638  Acc@1: 87.5000 (86.2825)  Acc@5: 100.0000 (98.4222)  time: 0.3493  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [2160/3125]  eta: 0:05:37  Lr: 0.001875  Loss: -0.5162  Acc@1: 87.5000 (86.2853)  Acc@5: 100.0000 (98.4267)  time: 0.3494  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [2170/3125]  eta: 0:05:34  Lr: 0.001875  Loss: -0.6989  Acc@1: 87.5000 (86.2880)  Acc@5: 100.0000 (98.4339)  time: 0.3488  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [2180/3125]  eta: 0:05:30  Lr: 0.001875  Loss: -0.4784  Acc@1: 87.5000 (86.2764)  Acc@5: 100.0000 (98.4325)  time: 0.3493  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [2190/3125]  eta: 0:05:27  Lr: 0.001875  Loss: -0.6043  Acc@1: 87.5000 (86.2791)  Acc@5: 100.0000 (98.4368)  time: 0.3509  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [2200/3125]  eta: 0:05:23  Lr: 0.001875  Loss: -0.5144  Acc@1: 87.5000 (86.2790)  Acc@5: 100.0000 (98.4410)  time: 0.3509  data: 0.0011  max mem: 2502
Train: Epoch[4/5]  [2210/3125]  eta: 0:05:20  Lr: 0.001875  Loss: -0.5166  Acc@1: 87.5000 (86.2873)  Acc@5: 100.0000 (98.4453)  time: 0.3498  data: 0.0011  max mem: 2502
Train: Epoch[4/5]  [2220/3125]  eta: 0:05:16  Lr: 0.001875  Loss: -0.1007  Acc@1: 87.5000 (86.2703)  Acc@5: 100.0000 (98.4354)  time: 0.3487  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [2230/3125]  eta: 0:05:13  Lr: 0.001875  Loss: -0.8776  Acc@1: 87.5000 (86.2758)  Acc@5: 100.0000 (98.4396)  time: 0.3512  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [2240/3125]  eta: 0:05:09  Lr: 0.001875  Loss: -0.4886  Acc@1: 87.5000 (86.2812)  Acc@5: 100.0000 (98.4326)  time: 0.3511  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [2250/3125]  eta: 0:05:06  Lr: 0.001875  Loss: -0.9375  Acc@1: 87.5000 (86.2867)  Acc@5: 100.0000 (98.4368)  time: 0.3488  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [2260/3125]  eta: 0:05:02  Lr: 0.001875  Loss: -0.7171  Acc@1: 87.5000 (86.2948)  Acc@5: 100.0000 (98.4382)  time: 0.3493  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [2270/3125]  eta: 0:04:59  Lr: 0.001875  Loss: -0.6715  Acc@1: 87.5000 (86.2946)  Acc@5: 100.0000 (98.4423)  time: 0.3498  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [2280/3125]  eta: 0:04:55  Lr: 0.001875  Loss: -0.5879  Acc@1: 81.2500 (86.2916)  Acc@5: 100.0000 (98.4409)  time: 0.3493  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [2290/3125]  eta: 0:04:52  Lr: 0.001875  Loss: -0.8929  Acc@1: 87.5000 (86.2969)  Acc@5: 100.0000 (98.4341)  time: 0.3481  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [2300/3125]  eta: 0:04:48  Lr: 0.001875  Loss: -0.5876  Acc@1: 87.5000 (86.3022)  Acc@5: 100.0000 (98.4300)  time: 0.3488  data: 0.0010  max mem: 2502
Train: Epoch[4/5]  [2310/3125]  eta: 0:04:45  Lr: 0.001875  Loss: -0.8846  Acc@1: 87.5000 (86.3073)  Acc@5: 100.0000 (98.4287)  time: 0.3498  data: 0.0010  max mem: 2502
Train: Epoch[4/5]  [2320/3125]  eta: 0:04:41  Lr: 0.001875  Loss: -0.7241  Acc@1: 87.5000 (86.3071)  Acc@5: 100.0000 (98.4328)  time: 0.3491  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [2330/3125]  eta: 0:04:38  Lr: 0.001875  Loss: -0.8589  Acc@1: 87.5000 (86.3176)  Acc@5: 100.0000 (98.4315)  time: 0.3487  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [2340/3125]  eta: 0:04:34  Lr: 0.001875  Loss: -0.4228  Acc@1: 87.5000 (86.2879)  Acc@5: 100.0000 (98.4221)  time: 0.3489  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [2350/3125]  eta: 0:04:31  Lr: 0.001875  Loss: -0.6245  Acc@1: 75.0000 (86.2718)  Acc@5: 100.0000 (98.4262)  time: 0.3485  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [2360/3125]  eta: 0:04:27  Lr: 0.001875  Loss: -0.7436  Acc@1: 87.5000 (86.2796)  Acc@5: 100.0000 (98.4302)  time: 0.3481  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [2370/3125]  eta: 0:04:24  Lr: 0.001875  Loss: -0.8192  Acc@1: 87.5000 (86.2901)  Acc@5: 100.0000 (98.4289)  time: 0.3485  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [2380/3125]  eta: 0:04:20  Lr: 0.001875  Loss: -0.8650  Acc@1: 87.5000 (86.3004)  Acc@5: 100.0000 (98.4329)  time: 0.3489  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [2390/3125]  eta: 0:04:17  Lr: 0.001875  Loss: -0.8021  Acc@1: 87.5000 (86.2897)  Acc@5: 100.0000 (98.4395)  time: 0.3496  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [2400/3125]  eta: 0:04:13  Lr: 0.001875  Loss: -0.8261  Acc@1: 87.5000 (86.3052)  Acc@5: 100.0000 (98.4408)  time: 0.3498  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [2410/3125]  eta: 0:04:10  Lr: 0.001875  Loss: -0.7421  Acc@1: 87.5000 (86.3127)  Acc@5: 100.0000 (98.4394)  time: 0.3492  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [2420/3125]  eta: 0:04:06  Lr: 0.001875  Loss: -0.9215  Acc@1: 87.5000 (86.3073)  Acc@5: 100.0000 (98.4407)  time: 0.3491  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [2430/3125]  eta: 0:04:03  Lr: 0.001875  Loss: -0.8976  Acc@1: 87.5000 (86.3096)  Acc@5: 100.0000 (98.4394)  time: 0.3490  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [2440/3125]  eta: 0:03:59  Lr: 0.001875  Loss: -0.4577  Acc@1: 87.5000 (86.2992)  Acc@5: 100.0000 (98.4356)  time: 0.3487  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [2450/3125]  eta: 0:03:56  Lr: 0.001875  Loss: -0.6393  Acc@1: 87.5000 (86.3041)  Acc@5: 100.0000 (98.4343)  time: 0.3489  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [2460/3125]  eta: 0:03:52  Lr: 0.001875  Loss: -0.4916  Acc@1: 93.7500 (86.3242)  Acc@5: 100.0000 (98.4356)  time: 0.3494  data: 0.0010  max mem: 2502
Train: Epoch[4/5]  [2470/3125]  eta: 0:03:49  Lr: 0.001875  Loss: -0.7237  Acc@1: 93.7500 (86.3466)  Acc@5: 100.0000 (98.4394)  time: 0.3490  data: 0.0010  max mem: 2502
Train: Epoch[4/5]  [2480/3125]  eta: 0:03:45  Lr: 0.001875  Loss: -0.7834  Acc@1: 93.7500 (86.3588)  Acc@5: 100.0000 (98.4432)  time: 0.3492  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [2490/3125]  eta: 0:03:42  Lr: 0.001875  Loss: -0.7045  Acc@1: 87.5000 (86.3609)  Acc@5: 100.0000 (98.4469)  time: 0.3505  data: 0.0007  max mem: 2502
Train: Epoch[4/5]  [2500/3125]  eta: 0:03:38  Lr: 0.001875  Loss: -0.3441  Acc@1: 81.2500 (86.3430)  Acc@5: 100.0000 (98.4456)  time: 0.3503  data: 0.0006  max mem: 2502
Train: Epoch[4/5]  [2510/3125]  eta: 0:03:35  Lr: 0.001875  Loss: -0.8673  Acc@1: 81.2500 (86.3401)  Acc@5: 100.0000 (98.4518)  time: 0.3499  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [2520/3125]  eta: 0:03:31  Lr: 0.001875  Loss: -0.7510  Acc@1: 87.5000 (86.3422)  Acc@5: 100.0000 (98.4555)  time: 0.3499  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [2530/3125]  eta: 0:03:28  Lr: 0.001875  Loss: -0.8246  Acc@1: 87.5000 (86.3320)  Acc@5: 100.0000 (98.4542)  time: 0.3497  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [2540/3125]  eta: 0:03:24  Lr: 0.001875  Loss: -0.9067  Acc@1: 87.5000 (86.3464)  Acc@5: 100.0000 (98.4504)  time: 0.3494  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [2550/3125]  eta: 0:03:21  Lr: 0.001875  Loss: -0.6738  Acc@1: 87.5000 (86.3509)  Acc@5: 100.0000 (98.4516)  time: 0.3497  data: 0.0007  max mem: 2502
Train: Epoch[4/5]  [2560/3125]  eta: 0:03:17  Lr: 0.001875  Loss: -0.5378  Acc@1: 87.5000 (86.3603)  Acc@5: 100.0000 (98.4503)  time: 0.3497  data: 0.0010  max mem: 2502
Train: Epoch[4/5]  [2570/3125]  eta: 0:03:14  Lr: 0.001875  Loss: -0.6767  Acc@1: 87.5000 (86.3647)  Acc@5: 100.0000 (98.4539)  time: 0.3496  data: 0.0007  max mem: 2502
Train: Epoch[4/5]  [2580/3125]  eta: 0:03:10  Lr: 0.001875  Loss: -0.8724  Acc@1: 87.5000 (86.3522)  Acc@5: 100.0000 (98.4454)  time: 0.3488  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [2590/3125]  eta: 0:03:07  Lr: 0.001875  Loss: -0.6187  Acc@1: 81.2500 (86.3542)  Acc@5: 100.0000 (98.4441)  time: 0.3480  data: 0.0008  max mem: 2502
Train: Epoch[4/5]  [2600/3125]  eta: 0:03:03  Lr: 0.001875  Loss: -0.4031  Acc@1: 87.5000 (86.3466)  Acc@5: 100.0000 (98.4357)  time: 0.3477  data: 0.0008  max mem: 2502
Train: Epoch[4/5]  [2610/3125]  eta: 0:03:00  Lr: 0.001875  Loss: -0.7621  Acc@1: 87.5000 (86.3630)  Acc@5: 100.0000 (98.4417)  time: 0.3479  data: 0.0011  max mem: 2502
Train: Epoch[4/5]  [2620/3125]  eta: 0:02:56  Lr: 0.001875  Loss: -0.3875  Acc@1: 87.5000 (86.3602)  Acc@5: 100.0000 (98.4357)  time: 0.3481  data: 0.0011  max mem: 2502
Train: Epoch[4/5]  [2630/3125]  eta: 0:02:53  Lr: 0.001875  Loss: -0.8984  Acc@1: 87.5000 (86.3764)  Acc@5: 100.0000 (98.4393)  time: 0.3470  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [2640/3125]  eta: 0:02:49  Lr: 0.001875  Loss: -0.7451  Acc@1: 87.5000 (86.3735)  Acc@5: 100.0000 (98.4405)  time: 0.3476  data: 0.0012  max mem: 2502
Train: Epoch[4/5]  [2650/3125]  eta: 0:02:46  Lr: 0.001875  Loss: -0.7409  Acc@1: 87.5000 (86.3754)  Acc@5: 100.0000 (98.4416)  time: 0.3498  data: 0.0013  max mem: 2502
Train: Epoch[4/5]  [2660/3125]  eta: 0:02:42  Lr: 0.001875  Loss: -0.6420  Acc@1: 87.5000 (86.3843)  Acc@5: 100.0000 (98.4381)  time: 0.3494  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [2670/3125]  eta: 0:02:39  Lr: 0.001875  Loss: -0.5627  Acc@1: 87.5000 (86.3862)  Acc@5: 100.0000 (98.4369)  time: 0.3494  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [2680/3125]  eta: 0:02:35  Lr: 0.001875  Loss: -0.9552  Acc@1: 87.5000 (86.3903)  Acc@5: 100.0000 (98.4358)  time: 0.3495  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [2690/3125]  eta: 0:02:32  Lr: 0.001875  Loss: -0.3623  Acc@1: 87.5000 (86.3968)  Acc@5: 100.0000 (98.4323)  time: 0.3481  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [2700/3125]  eta: 0:02:28  Lr: 0.001875  Loss: -0.7065  Acc@1: 87.5000 (86.3916)  Acc@5: 100.0000 (98.4311)  time: 0.3490  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [2710/3125]  eta: 0:02:25  Lr: 0.001875  Loss: -0.5324  Acc@1: 87.5000 (86.3957)  Acc@5: 100.0000 (98.4277)  time: 0.3488  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [2720/3125]  eta: 0:02:21  Lr: 0.001875  Loss: -0.4532  Acc@1: 87.5000 (86.3952)  Acc@5: 100.0000 (98.4335)  time: 0.3492  data: 0.0012  max mem: 2502
Train: Epoch[4/5]  [2730/3125]  eta: 0:02:18  Lr: 0.001875  Loss: -0.6736  Acc@1: 87.5000 (86.3992)  Acc@5: 100.0000 (98.4324)  time: 0.3498  data: 0.0012  max mem: 2502
Train: Epoch[4/5]  [2740/3125]  eta: 0:02:14  Lr: 0.001875  Loss: -0.4123  Acc@1: 87.5000 (86.4009)  Acc@5: 100.0000 (98.4335)  time: 0.3485  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [2750/3125]  eta: 0:02:11  Lr: 0.001875  Loss: -0.6784  Acc@1: 87.5000 (86.3913)  Acc@5: 100.0000 (98.4392)  time: 0.3486  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [2760/3125]  eta: 0:02:07  Lr: 0.001875  Loss: -0.6172  Acc@1: 87.5000 (86.4134)  Acc@5: 100.0000 (98.4449)  time: 0.3487  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [2770/3125]  eta: 0:02:04  Lr: 0.001875  Loss: -0.7764  Acc@1: 93.7500 (86.4219)  Acc@5: 100.0000 (98.4460)  time: 0.3490  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [2780/3125]  eta: 0:02:00  Lr: 0.001875  Loss: -0.6569  Acc@1: 87.5000 (86.4235)  Acc@5: 100.0000 (98.4448)  time: 0.3497  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [2790/3125]  eta: 0:01:57  Lr: 0.001875  Loss: -0.8806  Acc@1: 87.5000 (86.4341)  Acc@5: 100.0000 (98.4481)  time: 0.3502  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [2800/3125]  eta: 0:01:53  Lr: 0.001875  Loss: -0.6875  Acc@1: 87.5000 (86.4446)  Acc@5: 100.0000 (98.4470)  time: 0.3497  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [2810/3125]  eta: 0:01:50  Lr: 0.001875  Loss: -0.3096  Acc@1: 87.5000 (86.4194)  Acc@5: 100.0000 (98.4481)  time: 0.3495  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [2820/3125]  eta: 0:01:46  Lr: 0.001875  Loss: -0.7985  Acc@1: 87.5000 (86.4365)  Acc@5: 100.0000 (98.4536)  time: 0.3499  data: 0.0006  max mem: 2502
Train: Epoch[4/5]  [2830/3125]  eta: 0:01:43  Lr: 0.001875  Loss: -0.2142  Acc@1: 87.5000 (86.4359)  Acc@5: 100.0000 (98.4546)  time: 0.3499  data: 0.0006  max mem: 2502
Train: Epoch[4/5]  [2840/3125]  eta: 0:01:39  Lr: 0.001875  Loss: -0.8584  Acc@1: 87.5000 (86.4374)  Acc@5: 100.0000 (98.4578)  time: 0.3509  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [2850/3125]  eta: 0:01:36  Lr: 0.001875  Loss: -0.8058  Acc@1: 87.5000 (86.4455)  Acc@5: 100.0000 (98.4589)  time: 0.3513  data: 0.0011  max mem: 2502
Train: Epoch[4/5]  [2860/3125]  eta: 0:01:32  Lr: 0.001875  Loss: -0.7188  Acc@1: 87.5000 (86.4645)  Acc@5: 100.0000 (98.4643)  time: 0.3498  data: 0.0011  max mem: 2502
Train: Epoch[4/5]  [2870/3125]  eta: 0:01:29  Lr: 0.001875  Loss: -0.8546  Acc@1: 87.5000 (86.4725)  Acc@5: 100.0000 (98.4674)  time: 0.3492  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [2880/3125]  eta: 0:01:25  Lr: 0.001875  Loss: -0.5432  Acc@1: 93.7500 (86.4977)  Acc@5: 100.0000 (98.4684)  time: 0.3502  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [2890/3125]  eta: 0:01:22  Lr: 0.001875  Loss: -0.8128  Acc@1: 93.7500 (86.5034)  Acc@5: 100.0000 (98.4672)  time: 0.3494  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [2900/3125]  eta: 0:01:18  Lr: 0.001875  Loss: -0.8626  Acc@1: 87.5000 (86.5025)  Acc@5: 100.0000 (98.4682)  time: 0.3484  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [2910/3125]  eta: 0:01:15  Lr: 0.001875  Loss: -0.3643  Acc@1: 93.7500 (86.5210)  Acc@5: 100.0000 (98.4735)  time: 0.3488  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [2920/3125]  eta: 0:01:11  Lr: 0.001875  Loss: -0.5874  Acc@1: 93.7500 (86.5243)  Acc@5: 100.0000 (98.4744)  time: 0.3494  data: 0.0008  max mem: 2502
Train: Epoch[4/5]  [2930/3125]  eta: 0:01:08  Lr: 0.001875  Loss: -0.6171  Acc@1: 87.5000 (86.5255)  Acc@5: 100.0000 (98.4753)  time: 0.3489  data: 0.0008  max mem: 2502
Train: Epoch[4/5]  [2940/3125]  eta: 0:01:04  Lr: 0.001875  Loss: -0.7987  Acc@1: 87.5000 (86.5416)  Acc@5: 100.0000 (98.4805)  time: 0.3484  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [2950/3125]  eta: 0:01:01  Lr: 0.001875  Loss: -0.6817  Acc@1: 81.2500 (86.5215)  Acc@5: 100.0000 (98.4730)  time: 0.3482  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [2960/3125]  eta: 0:00:57  Lr: 0.001875  Loss: -0.7325  Acc@1: 81.2500 (86.5333)  Acc@5: 100.0000 (98.4739)  time: 0.3489  data: 0.0007  max mem: 2502
Train: Epoch[4/5]  [2970/3125]  eta: 0:00:54  Lr: 0.001875  Loss: -0.8530  Acc@1: 87.5000 (86.5386)  Acc@5: 100.0000 (98.4748)  time: 0.3504  data: 0.0015  max mem: 2502
Train: Epoch[4/5]  [2980/3125]  eta: 0:00:50  Lr: 0.001875  Loss: -0.7632  Acc@1: 87.5000 (86.5314)  Acc@5: 100.0000 (98.4779)  time: 0.3496  data: 0.0013  max mem: 2502
Train: Epoch[4/5]  [2990/3125]  eta: 0:00:47  Lr: 0.001875  Loss: -0.8295  Acc@1: 87.5000 (86.5242)  Acc@5: 100.0000 (98.4767)  time: 0.3484  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [3000/3125]  eta: 0:00:43  Lr: 0.001875  Loss: -0.9729  Acc@1: 87.5000 (86.5295)  Acc@5: 100.0000 (98.4776)  time: 0.3481  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [3010/3125]  eta: 0:00:40  Lr: 0.001875  Loss: -0.6118  Acc@1: 87.5000 (86.5203)  Acc@5: 100.0000 (98.4743)  time: 0.3480  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [3020/3125]  eta: 0:00:36  Lr: 0.001875  Loss: -0.5615  Acc@1: 81.2500 (86.5235)  Acc@5: 100.0000 (98.4773)  time: 0.3482  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [3030/3125]  eta: 0:00:33  Lr: 0.001875  Loss: -1.0313  Acc@1: 87.5000 (86.5453)  Acc@5: 100.0000 (98.4823)  time: 0.3485  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [3040/3125]  eta: 0:00:29  Lr: 0.001875  Loss: -0.7240  Acc@1: 93.7500 (86.5525)  Acc@5: 100.0000 (98.4853)  time: 0.3489  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [3050/3125]  eta: 0:00:26  Lr: 0.001875  Loss: -0.5977  Acc@1: 87.5000 (86.5433)  Acc@5: 100.0000 (98.4882)  time: 0.3484  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [3060/3125]  eta: 0:00:22  Lr: 0.001875  Loss: -0.3410  Acc@1: 81.2500 (86.5403)  Acc@5: 100.0000 (98.4891)  time: 0.3489  data: 0.0011  max mem: 2502
Train: Epoch[4/5]  [3070/3125]  eta: 0:00:19  Lr: 0.001875  Loss: -0.4981  Acc@1: 87.5000 (86.5577)  Acc@5: 100.0000 (98.4940)  time: 0.3486  data: 0.0010  max mem: 2502
Train: Epoch[4/5]  [3080/3125]  eta: 0:00:15  Lr: 0.001875  Loss: -0.9300  Acc@1: 87.5000 (86.5648)  Acc@5: 100.0000 (98.4989)  time: 0.3485  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [3090/3125]  eta: 0:00:12  Lr: 0.001875  Loss: -0.3061  Acc@1: 87.5000 (86.5436)  Acc@5: 100.0000 (98.4977)  time: 0.3497  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [3100/3125]  eta: 0:00:08  Lr: 0.001875  Loss: -0.2637  Acc@1: 81.2500 (86.5426)  Acc@5: 100.0000 (98.4944)  time: 0.3497  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [3110/3125]  eta: 0:00:05  Lr: 0.001875  Loss: -0.5456  Acc@1: 87.5000 (86.5397)  Acc@5: 100.0000 (98.4973)  time: 0.3492  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [3120/3125]  eta: 0:00:01  Lr: 0.001875  Loss: -0.8774  Acc@1: 87.5000 (86.5468)  Acc@5: 100.0000 (98.4981)  time: 0.3489  data: 0.0008  max mem: 2502
Train: Epoch[4/5]  [3124/3125]  eta: 0:00:00  Lr: 0.001875  Loss: -0.5410  Acc@1: 87.5000 (86.5440)  Acc@5: 100.0000 (98.5000)  time: 0.3493  data: 0.0008  max mem: 2502
Train: Epoch[4/5] Total time: 0:18:13 (0.3500 s / it)
Averaged stats: Lr: 0.001875  Loss: -0.5410  Acc@1: 87.5000 (86.5440)  Acc@5: 100.0000 (98.5000)
Train: Epoch[5/5]  [   0/3125]  eta: 0:34:00  Lr: 0.001875  Loss: -0.0314  Acc@1: 75.0000 (75.0000)  Acc@5: 93.7500 (93.7500)  time: 0.6529  data: 0.3043  max mem: 2502
Train: Epoch[5/5]  [  10/3125]  eta: 0:19:33  Lr: 0.001875  Loss: -0.8115  Acc@1: 87.5000 (86.3636)  Acc@5: 100.0000 (97.7273)  time: 0.3768  data: 0.0287  max mem: 2502
Train: Epoch[5/5]  [  20/3125]  eta: 0:18:48  Lr: 0.001875  Loss: -0.5997  Acc@1: 87.5000 (86.3095)  Acc@5: 100.0000 (98.2143)  time: 0.3490  data: 0.0007  max mem: 2502
Train: Epoch[5/5]  [  30/3125]  eta: 0:18:30  Lr: 0.001875  Loss: -0.4751  Acc@1: 81.2500 (84.4758)  Acc@5: 100.0000 (97.7823)  time: 0.3489  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [  40/3125]  eta: 0:18:20  Lr: 0.001875  Loss: -0.1864  Acc@1: 81.2500 (84.9085)  Acc@5: 100.0000 (98.0183)  time: 0.3494  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [  50/3125]  eta: 0:18:11  Lr: 0.001875  Loss: -0.3950  Acc@1: 87.5000 (85.0490)  Acc@5: 100.0000 (98.0392)  time: 0.3493  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [  60/3125]  eta: 0:18:06  Lr: 0.001875  Loss: -0.6991  Acc@1: 87.5000 (85.1434)  Acc@5: 100.0000 (98.2582)  time: 0.3497  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [  70/3125]  eta: 0:18:00  Lr: 0.001875  Loss: -0.7563  Acc@1: 87.5000 (85.2993)  Acc@5: 100.0000 (98.1514)  time: 0.3496  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [  80/3125]  eta: 0:17:54  Lr: 0.001875  Loss: -0.8374  Acc@1: 87.5000 (86.1883)  Acc@5: 100.0000 (98.2253)  time: 0.3490  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [  90/3125]  eta: 0:17:50  Lr: 0.001875  Loss: -0.6555  Acc@1: 87.5000 (85.9890)  Acc@5: 100.0000 (98.4203)  time: 0.3498  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [ 100/3125]  eta: 0:17:46  Lr: 0.001875  Loss: -0.6867  Acc@1: 87.5000 (86.0149)  Acc@5: 100.0000 (98.5149)  time: 0.3505  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [ 110/3125]  eta: 0:17:42  Lr: 0.001875  Loss: -0.2409  Acc@1: 87.5000 (85.9234)  Acc@5: 100.0000 (98.6486)  time: 0.3511  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [ 120/3125]  eta: 0:17:38  Lr: 0.001875  Loss: -0.4480  Acc@1: 87.5000 (85.6921)  Acc@5: 100.0000 (98.7087)  time: 0.3514  data: 0.0012  max mem: 2502
Train: Epoch[5/5]  [ 130/3125]  eta: 0:17:34  Lr: 0.001875  Loss: -0.3345  Acc@1: 87.5000 (85.7824)  Acc@5: 100.0000 (98.6164)  time: 0.3504  data: 0.0012  max mem: 2502
Train: Epoch[5/5]  [ 140/3125]  eta: 0:17:30  Lr: 0.001875  Loss: -0.9629  Acc@1: 87.5000 (85.7270)  Acc@5: 100.0000 (98.6702)  time: 0.3506  data: 0.0007  max mem: 2502
Train: Epoch[5/5]  [ 150/3125]  eta: 0:17:26  Lr: 0.001875  Loss: -0.5500  Acc@1: 87.5000 (85.9685)  Acc@5: 100.0000 (98.5513)  time: 0.3506  data: 0.0006  max mem: 2502
Train: Epoch[5/5]  [ 160/3125]  eta: 0:17:23  Lr: 0.001875  Loss: -0.6242  Acc@1: 87.5000 (86.1025)  Acc@5: 100.0000 (98.5637)  time: 0.3504  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [ 170/3125]  eta: 0:17:19  Lr: 0.001875  Loss: -0.6853  Acc@1: 87.5000 (86.0015)  Acc@5: 100.0000 (98.5380)  time: 0.3505  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [ 180/3125]  eta: 0:17:15  Lr: 0.001875  Loss: -0.7516  Acc@1: 87.5000 (86.1533)  Acc@5: 100.0000 (98.5497)  time: 0.3499  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [ 190/3125]  eta: 0:17:11  Lr: 0.001875  Loss: -0.7020  Acc@1: 87.5000 (86.4529)  Acc@5: 100.0000 (98.5929)  time: 0.3503  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [ 200/3125]  eta: 0:17:08  Lr: 0.001875  Loss: -0.4657  Acc@1: 87.5000 (86.3495)  Acc@5: 100.0000 (98.6629)  time: 0.3502  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [ 210/3125]  eta: 0:17:04  Lr: 0.001875  Loss: -0.2685  Acc@1: 81.2500 (86.2263)  Acc@5: 100.0000 (98.6374)  time: 0.3495  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [ 220/3125]  eta: 0:17:00  Lr: 0.001875  Loss: -0.3877  Acc@1: 87.5000 (86.1425)  Acc@5: 100.0000 (98.5294)  time: 0.3493  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [ 230/3125]  eta: 0:16:56  Lr: 0.001875  Loss: -0.8650  Acc@1: 87.5000 (86.2554)  Acc@5: 100.0000 (98.5931)  time: 0.3494  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [ 240/3125]  eta: 0:16:53  Lr: 0.001875  Loss: -0.8957  Acc@1: 87.5000 (86.3071)  Acc@5: 100.0000 (98.5477)  time: 0.3498  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [ 250/3125]  eta: 0:16:49  Lr: 0.001875  Loss: -0.9821  Acc@1: 87.5000 (86.3546)  Acc@5: 100.0000 (98.5060)  time: 0.3503  data: 0.0010  max mem: 2502
Train: Epoch[5/5]  [ 260/3125]  eta: 0:16:46  Lr: 0.001875  Loss: -0.9542  Acc@1: 87.5000 (86.4224)  Acc@5: 100.0000 (98.4435)  time: 0.3512  data: 0.0010  max mem: 2502
Train: Epoch[5/5]  [ 270/3125]  eta: 0:16:42  Lr: 0.001875  Loss: -0.8344  Acc@1: 93.7500 (86.6236)  Acc@5: 100.0000 (98.4317)  time: 0.3499  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [ 280/3125]  eta: 0:16:38  Lr: 0.001875  Loss: -0.7936  Acc@1: 93.7500 (86.6770)  Acc@5: 100.0000 (98.4431)  time: 0.3498  data: 0.0019  max mem: 2502
Train: Epoch[5/5]  [ 290/3125]  eta: 0:16:34  Lr: 0.001875  Loss: -0.6308  Acc@1: 87.5000 (86.5550)  Acc@5: 100.0000 (98.4751)  time: 0.3494  data: 0.0019  max mem: 2502
Train: Epoch[5/5]  [ 300/3125]  eta: 0:16:31  Lr: 0.001875  Loss: -0.8367  Acc@1: 87.5000 (86.5449)  Acc@5: 100.0000 (98.4842)  time: 0.3477  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [ 310/3125]  eta: 0:16:27  Lr: 0.001875  Loss: -0.6204  Acc@1: 87.5000 (86.5555)  Acc@5: 100.0000 (98.4928)  time: 0.3486  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [ 320/3125]  eta: 0:16:23  Lr: 0.001875  Loss: -0.8995  Acc@1: 87.5000 (86.5654)  Acc@5: 100.0000 (98.5008)  time: 0.3482  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [ 330/3125]  eta: 0:16:19  Lr: 0.001875  Loss: -0.7285  Acc@1: 87.5000 (86.5748)  Acc@5: 100.0000 (98.5083)  time: 0.3469  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [ 340/3125]  eta: 0:16:15  Lr: 0.001875  Loss: -0.5378  Acc@1: 87.5000 (86.4919)  Acc@5: 100.0000 (98.4238)  time: 0.3464  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [ 350/3125]  eta: 0:16:12  Lr: 0.001875  Loss: -0.7452  Acc@1: 87.5000 (86.6275)  Acc@5: 100.0000 (98.4330)  time: 0.3476  data: 0.0011  max mem: 2502
Train: Epoch[5/5]  [ 360/3125]  eta: 0:16:08  Lr: 0.001875  Loss: -0.5639  Acc@1: 93.7500 (86.6863)  Acc@5: 100.0000 (98.4072)  time: 0.3481  data: 0.0011  max mem: 2502
Train: Epoch[5/5]  [ 370/3125]  eta: 0:16:04  Lr: 0.001875  Loss: -0.5254  Acc@1: 87.5000 (86.5903)  Acc@5: 100.0000 (98.4164)  time: 0.3473  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [ 380/3125]  eta: 0:16:01  Lr: 0.001875  Loss: -0.7482  Acc@1: 87.5000 (86.7782)  Acc@5: 100.0000 (98.4416)  time: 0.3471  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [ 390/3125]  eta: 0:15:57  Lr: 0.001875  Loss: -0.4788  Acc@1: 93.7500 (86.8926)  Acc@5: 100.0000 (98.4495)  time: 0.3467  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [ 400/3125]  eta: 0:15:53  Lr: 0.001875  Loss: -0.8960  Acc@1: 87.5000 (86.8142)  Acc@5: 100.0000 (98.4882)  time: 0.3471  data: 0.0012  max mem: 2502
Train: Epoch[5/5]  [ 410/3125]  eta: 0:15:50  Lr: 0.001875  Loss: -0.5687  Acc@1: 87.5000 (86.8005)  Acc@5: 100.0000 (98.4793)  time: 0.3482  data: 0.0011  max mem: 2502
Train: Epoch[5/5]  [ 420/3125]  eta: 0:15:46  Lr: 0.001875  Loss: -0.8917  Acc@1: 87.5000 (86.7874)  Acc@5: 100.0000 (98.4857)  time: 0.3477  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [ 430/3125]  eta: 0:15:42  Lr: 0.001875  Loss: -0.5729  Acc@1: 87.5000 (86.6734)  Acc@5: 100.0000 (98.4629)  time: 0.3471  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [ 440/3125]  eta: 0:15:39  Lr: 0.001875  Loss: -0.6671  Acc@1: 87.5000 (86.6638)  Acc@5: 100.0000 (98.4269)  time: 0.3474  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [ 450/3125]  eta: 0:15:35  Lr: 0.001875  Loss: -0.8440  Acc@1: 87.5000 (86.6685)  Acc@5: 100.0000 (98.4340)  time: 0.3479  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [ 460/3125]  eta: 0:15:32  Lr: 0.001875  Loss: -0.3394  Acc@1: 87.5000 (86.7001)  Acc@5: 100.0000 (98.4273)  time: 0.3488  data: 0.0011  max mem: 2502
Train: Epoch[5/5]  [ 470/3125]  eta: 0:15:28  Lr: 0.001875  Loss: -0.5047  Acc@1: 87.5000 (86.6507)  Acc@5: 100.0000 (98.3944)  time: 0.3483  data: 0.0011  max mem: 2502
Train: Epoch[5/5]  [ 480/3125]  eta: 0:15:24  Lr: 0.001875  Loss: -0.8582  Acc@1: 87.5000 (86.7464)  Acc@5: 100.0000 (98.4148)  time: 0.3482  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [ 490/3125]  eta: 0:15:21  Lr: 0.001875  Loss: -0.4974  Acc@1: 93.7500 (86.8763)  Acc@5: 100.0000 (98.4343)  time: 0.3487  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [ 500/3125]  eta: 0:15:17  Lr: 0.001875  Loss: -0.8910  Acc@1: 93.7500 (86.9511)  Acc@5: 100.0000 (98.4656)  time: 0.3497  data: 0.0011  max mem: 2502
Train: Epoch[5/5]  [ 510/3125]  eta: 0:15:14  Lr: 0.001875  Loss: -0.2536  Acc@1: 87.5000 (86.9863)  Acc@5: 100.0000 (98.4589)  time: 0.3508  data: 0.0011  max mem: 2502
Train: Epoch[5/5]  [ 520/3125]  eta: 0:15:11  Lr: 0.001875  Loss: -1.0538  Acc@1: 87.5000 (86.9722)  Acc@5: 100.0000 (98.4405)  time: 0.3510  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [ 530/3125]  eta: 0:15:07  Lr: 0.001875  Loss: -0.5596  Acc@1: 87.5000 (87.0056)  Acc@5: 100.0000 (98.4699)  time: 0.3498  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [ 540/3125]  eta: 0:15:03  Lr: 0.001875  Loss: -0.7434  Acc@1: 87.5000 (87.0263)  Acc@5: 100.0000 (98.4750)  time: 0.3493  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [ 550/3125]  eta: 0:15:00  Lr: 0.001875  Loss: -0.6295  Acc@1: 87.5000 (86.9896)  Acc@5: 100.0000 (98.4800)  time: 0.3494  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [ 560/3125]  eta: 0:14:56  Lr: 0.001875  Loss: -0.4964  Acc@1: 81.2500 (86.9318)  Acc@5: 100.0000 (98.4737)  time: 0.3488  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [ 570/3125]  eta: 0:14:53  Lr: 0.001875  Loss: -0.3052  Acc@1: 81.2500 (86.8870)  Acc@5: 100.0000 (98.4348)  time: 0.3492  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [ 580/3125]  eta: 0:14:49  Lr: 0.001875  Loss: -0.6973  Acc@1: 87.5000 (86.9083)  Acc@5: 100.0000 (98.4402)  time: 0.3492  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [ 590/3125]  eta: 0:14:46  Lr: 0.001875  Loss: -0.8967  Acc@1: 87.5000 (86.9924)  Acc@5: 100.0000 (98.4560)  time: 0.3498  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [ 600/3125]  eta: 0:14:42  Lr: 0.001875  Loss: -0.4915  Acc@1: 87.5000 (86.9384)  Acc@5: 100.0000 (98.4609)  time: 0.3507  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [ 610/3125]  eta: 0:14:39  Lr: 0.001875  Loss: -0.9717  Acc@1: 87.5000 (86.9988)  Acc@5: 100.0000 (98.4656)  time: 0.3505  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [ 620/3125]  eta: 0:14:35  Lr: 0.001875  Loss: -0.8275  Acc@1: 87.5000 (87.0370)  Acc@5: 100.0000 (98.4601)  time: 0.3495  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [ 630/3125]  eta: 0:14:32  Lr: 0.001875  Loss: -0.8063  Acc@1: 87.5000 (87.0444)  Acc@5: 100.0000 (98.4350)  time: 0.3491  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [ 640/3125]  eta: 0:14:28  Lr: 0.001875  Loss: -0.9333  Acc@1: 87.5000 (87.0710)  Acc@5: 100.0000 (98.4594)  time: 0.3496  data: 0.0008  max mem: 2502
Train: Epoch[5/5]  [ 650/3125]  eta: 0:14:25  Lr: 0.001875  Loss: -0.6878  Acc@1: 87.5000 (87.0392)  Acc@5: 100.0000 (98.4735)  time: 0.3495  data: 0.0009  max mem: 2502
Train: Epoch[5/5]  [ 660/3125]  eta: 0:14:21  Lr: 0.001875  Loss: -0.7588  Acc@1: 81.2500 (86.9800)  Acc@5: 100.0000 (98.4682)  time: 0.3490  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [ 670/3125]  eta: 0:14:18  Lr: 0.001875  Loss: -0.8934  Acc@1: 81.2500 (86.9504)  Acc@5: 100.0000 (98.4817)  time: 0.3491  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [ 680/3125]  eta: 0:14:14  Lr: 0.001875  Loss: -0.9354  Acc@1: 81.2500 (86.8943)  Acc@5: 100.0000 (98.4857)  time: 0.3484  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [ 690/3125]  eta: 0:14:11  Lr: 0.001875  Loss: -0.7471  Acc@1: 81.2500 (86.7674)  Acc@5: 100.0000 (98.4624)  time: 0.3484  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [ 700/3125]  eta: 0:14:07  Lr: 0.001875  Loss: -0.6351  Acc@1: 81.2500 (86.7689)  Acc@5: 100.0000 (98.4665)  time: 0.3492  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [ 710/3125]  eta: 0:14:04  Lr: 0.001875  Loss: -0.3863  Acc@1: 87.5000 (86.7880)  Acc@5: 100.0000 (98.4617)  time: 0.3491  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [ 720/3125]  eta: 0:14:00  Lr: 0.001875  Loss: -0.8278  Acc@1: 87.5000 (86.8152)  Acc@5: 100.0000 (98.4830)  time: 0.3495  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [ 730/3125]  eta: 0:13:57  Lr: 0.001875  Loss: -0.2553  Acc@1: 87.5000 (86.7818)  Acc@5: 100.0000 (98.4610)  time: 0.3496  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [ 740/3125]  eta: 0:13:53  Lr: 0.001875  Loss: -0.6203  Acc@1: 87.5000 (86.7999)  Acc@5: 100.0000 (98.4565)  time: 0.3490  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [ 750/3125]  eta: 0:13:50  Lr: 0.001875  Loss: -0.0197  Acc@1: 87.5000 (86.7676)  Acc@5: 100.0000 (98.4354)  time: 0.3495  data: 0.0011  max mem: 2502
Train: Epoch[5/5]  [ 760/3125]  eta: 0:13:46  Lr: 0.001875  Loss: -0.6571  Acc@1: 87.5000 (86.7937)  Acc@5: 100.0000 (98.4396)  time: 0.3492  data: 0.0011  max mem: 2502
Train: Epoch[5/5]  [ 770/3125]  eta: 0:13:43  Lr: 0.001875  Loss: -0.6906  Acc@1: 87.5000 (86.7866)  Acc@5: 100.0000 (98.4436)  time: 0.3487  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [ 780/3125]  eta: 0:13:39  Lr: 0.001875  Loss: -0.5567  Acc@1: 87.5000 (86.7958)  Acc@5: 100.0000 (98.4555)  time: 0.3485  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [ 790/3125]  eta: 0:13:36  Lr: 0.001875  Loss: -0.6126  Acc@1: 87.5000 (86.7494)  Acc@5: 100.0000 (98.4197)  time: 0.3490  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [ 800/3125]  eta: 0:13:32  Lr: 0.001875  Loss: -0.5079  Acc@1: 81.2500 (86.7041)  Acc@5: 93.7500 (98.3926)  time: 0.3492  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [ 810/3125]  eta: 0:13:29  Lr: 0.001875  Loss: -0.7183  Acc@1: 87.5000 (86.7525)  Acc@5: 100.0000 (98.4047)  time: 0.3482  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [ 820/3125]  eta: 0:13:25  Lr: 0.001875  Loss: -0.4771  Acc@1: 87.5000 (86.6931)  Acc@5: 100.0000 (98.3633)  time: 0.3480  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [ 830/3125]  eta: 0:13:22  Lr: 0.001875  Loss: -0.8151  Acc@1: 81.2500 (86.6802)  Acc@5: 93.7500 (98.3604)  time: 0.3484  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [ 840/3125]  eta: 0:13:18  Lr: 0.001875  Loss: -0.6147  Acc@1: 87.5000 (86.6602)  Acc@5: 100.0000 (98.3502)  time: 0.3485  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [ 850/3125]  eta: 0:13:15  Lr: 0.001875  Loss: -0.7162  Acc@1: 87.5000 (86.6627)  Acc@5: 100.0000 (98.3475)  time: 0.3494  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [ 860/3125]  eta: 0:13:11  Lr: 0.001875  Loss: -0.9762  Acc@1: 87.5000 (86.6652)  Acc@5: 100.0000 (98.3522)  time: 0.3504  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [ 870/3125]  eta: 0:13:08  Lr: 0.001875  Loss: -0.6636  Acc@1: 87.5000 (86.6604)  Acc@5: 100.0000 (98.3424)  time: 0.3496  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [ 880/3125]  eta: 0:13:04  Lr: 0.001875  Loss: -0.8363  Acc@1: 81.2500 (86.6061)  Acc@5: 100.0000 (98.3541)  time: 0.3495  data: 0.0011  max mem: 2502
Train: Epoch[5/5]  [ 890/3125]  eta: 0:13:01  Lr: 0.001875  Loss: -0.6117  Acc@1: 81.2500 (86.5741)  Acc@5: 100.0000 (98.3516)  time: 0.3497  data: 0.0011  max mem: 2502
Train: Epoch[5/5]  [ 900/3125]  eta: 0:12:57  Lr: 0.001875  Loss: -0.4478  Acc@1: 81.2500 (86.5358)  Acc@5: 100.0000 (98.3560)  time: 0.3496  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [ 910/3125]  eta: 0:12:54  Lr: 0.001875  Loss: -0.6893  Acc@1: 87.5000 (86.5532)  Acc@5: 100.0000 (98.3466)  time: 0.3495  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [ 920/3125]  eta: 0:12:50  Lr: 0.001875  Loss: -0.5683  Acc@1: 87.5000 (86.5907)  Acc@5: 100.0000 (98.3578)  time: 0.3487  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [ 930/3125]  eta: 0:12:47  Lr: 0.001875  Loss: -0.4254  Acc@1: 87.5000 (86.6139)  Acc@5: 100.0000 (98.3687)  time: 0.3495  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [ 940/3125]  eta: 0:12:43  Lr: 0.001875  Loss: -0.5165  Acc@1: 87.5000 (86.5901)  Acc@5: 100.0000 (98.3794)  time: 0.3501  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [ 950/3125]  eta: 0:12:40  Lr: 0.001875  Loss: -0.5572  Acc@1: 87.5000 (86.5602)  Acc@5: 100.0000 (98.3833)  time: 0.3494  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [ 960/3125]  eta: 0:12:36  Lr: 0.001875  Loss: -0.7811  Acc@1: 87.5000 (86.5765)  Acc@5: 100.0000 (98.3806)  time: 0.3487  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [ 970/3125]  eta: 0:12:33  Lr: 0.001875  Loss: -0.6084  Acc@1: 87.5000 (86.5860)  Acc@5: 100.0000 (98.3780)  time: 0.3487  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [ 980/3125]  eta: 0:12:29  Lr: 0.001875  Loss: -0.7100  Acc@1: 87.5000 (86.5889)  Acc@5: 100.0000 (98.3754)  time: 0.3485  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [ 990/3125]  eta: 0:12:26  Lr: 0.001875  Loss: -0.6160  Acc@1: 87.5000 (86.6044)  Acc@5: 100.0000 (98.3729)  time: 0.3487  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [1000/3125]  eta: 0:12:22  Lr: 0.001875  Loss: -0.3555  Acc@1: 87.5000 (86.5759)  Acc@5: 100.0000 (98.3704)  time: 0.3494  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [1010/3125]  eta: 0:12:19  Lr: 0.001875  Loss: -0.5006  Acc@1: 87.5000 (86.5789)  Acc@5: 100.0000 (98.3680)  time: 0.3496  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [1020/3125]  eta: 0:12:15  Lr: 0.001875  Loss: -0.4878  Acc@1: 87.5000 (86.5818)  Acc@5: 100.0000 (98.3839)  time: 0.3496  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [1030/3125]  eta: 0:12:12  Lr: 0.001875  Loss: -0.8013  Acc@1: 87.5000 (86.5907)  Acc@5: 100.0000 (98.3935)  time: 0.3501  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [1040/3125]  eta: 0:12:08  Lr: 0.001875  Loss: -0.5202  Acc@1: 87.5000 (86.5934)  Acc@5: 100.0000 (98.3970)  time: 0.3506  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [1050/3125]  eta: 0:12:05  Lr: 0.001875  Loss: -0.6660  Acc@1: 87.5000 (86.6080)  Acc@5: 100.0000 (98.4122)  time: 0.3504  data: 0.0006  max mem: 2502
Train: Epoch[5/5]  [1060/3125]  eta: 0:12:01  Lr: 0.001875  Loss: -0.7353  Acc@1: 87.5000 (86.5987)  Acc@5: 100.0000 (98.4272)  time: 0.3496  data: 0.0006  max mem: 2502
Train: Epoch[5/5]  [1070/3125]  eta: 0:11:58  Lr: 0.001875  Loss: -0.6808  Acc@1: 87.5000 (86.6188)  Acc@5: 100.0000 (98.4360)  time: 0.3489  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [1080/3125]  eta: 0:11:54  Lr: 0.001875  Loss: -0.3033  Acc@1: 87.5000 (86.6038)  Acc@5: 100.0000 (98.4274)  time: 0.3488  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [1090/3125]  eta: 0:11:51  Lr: 0.001875  Loss: -0.5283  Acc@1: 87.5000 (86.6235)  Acc@5: 100.0000 (98.4303)  time: 0.3483  data: 0.0006  max mem: 2502
Train: Epoch[5/5]  [1100/3125]  eta: 0:11:47  Lr: 0.001875  Loss: -0.8814  Acc@1: 93.7500 (86.6655)  Acc@5: 100.0000 (98.4389)  time: 0.3486  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [1110/3125]  eta: 0:11:44  Lr: 0.001875  Loss: -0.5220  Acc@1: 87.5000 (86.6562)  Acc@5: 100.0000 (98.4361)  time: 0.3491  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [1120/3125]  eta: 0:11:40  Lr: 0.001875  Loss: -0.8162  Acc@1: 87.5000 (86.6581)  Acc@5: 100.0000 (98.4333)  time: 0.3497  data: 0.0014  max mem: 2502
Train: Epoch[5/5]  [1130/3125]  eta: 0:11:37  Lr: 0.001875  Loss: -0.7041  Acc@1: 87.5000 (86.6766)  Acc@5: 100.0000 (98.4416)  time: 0.3497  data: 0.0019  max mem: 2502
Train: Epoch[5/5]  [1140/3125]  eta: 0:11:33  Lr: 0.001875  Loss: -0.4532  Acc@1: 87.5000 (86.6729)  Acc@5: 100.0000 (98.4443)  time: 0.3478  data: 0.0008  max mem: 2502
Train: Epoch[5/5]  [1150/3125]  eta: 0:11:30  Lr: 0.001875  Loss: -0.6191  Acc@1: 87.5000 (86.6583)  Acc@5: 100.0000 (98.4416)  time: 0.3469  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [1160/3125]  eta: 0:11:26  Lr: 0.001875  Loss: -0.9452  Acc@1: 87.5000 (86.7033)  Acc@5: 100.0000 (98.4550)  time: 0.3481  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [1170/3125]  eta: 0:11:23  Lr: 0.001875  Loss: -0.5677  Acc@1: 87.5000 (86.7154)  Acc@5: 100.0000 (98.4522)  time: 0.3488  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [1180/3125]  eta: 0:11:19  Lr: 0.001875  Loss: -0.6280  Acc@1: 87.5000 (86.7062)  Acc@5: 100.0000 (98.4600)  time: 0.3489  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [1190/3125]  eta: 0:11:16  Lr: 0.001875  Loss: -0.8942  Acc@1: 87.5000 (86.7601)  Acc@5: 100.0000 (98.4729)  time: 0.3490  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [1200/3125]  eta: 0:11:12  Lr: 0.001875  Loss: -0.4188  Acc@1: 87.5000 (86.7610)  Acc@5: 100.0000 (98.4856)  time: 0.3491  data: 0.0011  max mem: 2502
Train: Epoch[5/5]  [1210/3125]  eta: 0:11:09  Lr: 0.001875  Loss: -0.4544  Acc@1: 87.5000 (86.7671)  Acc@5: 100.0000 (98.4775)  time: 0.3484  data: 0.0011  max mem: 2502
Train: Epoch[5/5]  [1220/3125]  eta: 0:11:05  Lr: 0.001875  Loss: -0.7071  Acc@1: 87.5000 (86.7987)  Acc@5: 100.0000 (98.4695)  time: 0.3480  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [1230/3125]  eta: 0:11:02  Lr: 0.001875  Loss: -0.4076  Acc@1: 93.7500 (86.8146)  Acc@5: 100.0000 (98.4768)  time: 0.3498  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [1240/3125]  eta: 0:10:58  Lr: 0.001875  Loss: -0.7995  Acc@1: 87.5000 (86.8453)  Acc@5: 100.0000 (98.4740)  time: 0.3498  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [1250/3125]  eta: 0:10:55  Lr: 0.001875  Loss: 0.0751  Acc@1: 87.5000 (86.8355)  Acc@5: 100.0000 (98.4712)  time: 0.3493  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [1260/3125]  eta: 0:10:51  Lr: 0.001875  Loss: -0.6237  Acc@1: 87.5000 (86.8507)  Acc@5: 100.0000 (98.4734)  time: 0.3506  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [1270/3125]  eta: 0:10:48  Lr: 0.001875  Loss: -0.1328  Acc@1: 81.2500 (86.8116)  Acc@5: 100.0000 (98.4756)  time: 0.3495  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [1280/3125]  eta: 0:10:44  Lr: 0.001875  Loss: -0.6099  Acc@1: 87.5000 (86.8023)  Acc@5: 100.0000 (98.4875)  time: 0.3486  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [1290/3125]  eta: 0:10:41  Lr: 0.001875  Loss: -0.9740  Acc@1: 87.5000 (86.7932)  Acc@5: 100.0000 (98.4992)  time: 0.3491  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [1300/3125]  eta: 0:10:37  Lr: 0.001875  Loss: -0.8080  Acc@1: 87.5000 (86.7986)  Acc@5: 100.0000 (98.5012)  time: 0.3493  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [1310/3125]  eta: 0:10:34  Lr: 0.001875  Loss: -0.7564  Acc@1: 87.5000 (86.7849)  Acc@5: 100.0000 (98.4840)  time: 0.3497  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [1320/3125]  eta: 0:10:30  Lr: 0.001875  Loss: -0.4262  Acc@1: 81.2500 (86.7714)  Acc@5: 100.0000 (98.4813)  time: 0.3504  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [1330/3125]  eta: 0:10:27  Lr: 0.001875  Loss: -0.6817  Acc@1: 87.5000 (86.7816)  Acc@5: 100.0000 (98.4880)  time: 0.3507  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [1340/3125]  eta: 0:10:23  Lr: 0.001875  Loss: -0.7422  Acc@1: 87.5000 (86.7729)  Acc@5: 100.0000 (98.4899)  time: 0.3494  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [1350/3125]  eta: 0:10:20  Lr: 0.001875  Loss: -0.1571  Acc@1: 81.2500 (86.7459)  Acc@5: 100.0000 (98.4965)  time: 0.3497  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [1360/3125]  eta: 0:10:16  Lr: 0.001875  Loss: -0.9691  Acc@1: 87.5000 (86.7698)  Acc@5: 100.0000 (98.4983)  time: 0.3501  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [1370/3125]  eta: 0:10:13  Lr: 0.001875  Loss: -0.9275  Acc@1: 93.7500 (86.8162)  Acc@5: 100.0000 (98.4956)  time: 0.3486  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [1380/3125]  eta: 0:10:09  Lr: 0.001875  Loss: -0.3734  Acc@1: 93.7500 (86.8347)  Acc@5: 100.0000 (98.5065)  time: 0.3489  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [1390/3125]  eta: 0:10:06  Lr: 0.001875  Loss: -0.7149  Acc@1: 87.5000 (86.8530)  Acc@5: 100.0000 (98.5173)  time: 0.3496  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [1400/3125]  eta: 0:10:02  Lr: 0.001875  Loss: -0.5741  Acc@1: 87.5000 (86.8442)  Acc@5: 100.0000 (98.5189)  time: 0.3501  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [1410/3125]  eta: 0:09:59  Lr: 0.001875  Loss: -0.8141  Acc@1: 87.5000 (86.8400)  Acc@5: 100.0000 (98.5161)  time: 0.3504  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [1420/3125]  eta: 0:09:55  Lr: 0.001875  Loss: -0.3833  Acc@1: 87.5000 (86.8403)  Acc@5: 100.0000 (98.5178)  time: 0.3493  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [1430/3125]  eta: 0:09:52  Lr: 0.001875  Loss: -0.9859  Acc@1: 81.2500 (86.8099)  Acc@5: 100.0000 (98.5019)  time: 0.3493  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [1440/3125]  eta: 0:09:48  Lr: 0.001875  Loss: -0.6403  Acc@1: 81.2500 (86.8104)  Acc@5: 100.0000 (98.4993)  time: 0.3497  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [1450/3125]  eta: 0:09:45  Lr: 0.001875  Loss: -0.1548  Acc@1: 87.5000 (86.8022)  Acc@5: 100.0000 (98.4881)  time: 0.3493  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [1460/3125]  eta: 0:09:41  Lr: 0.001875  Loss: -0.7245  Acc@1: 81.2500 (86.7813)  Acc@5: 100.0000 (98.4813)  time: 0.3490  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [1470/3125]  eta: 0:09:38  Lr: 0.001875  Loss: -0.9015  Acc@1: 87.5000 (86.7947)  Acc@5: 100.0000 (98.4874)  time: 0.3491  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [1480/3125]  eta: 0:09:34  Lr: 0.001875  Loss: -0.5352  Acc@1: 87.5000 (86.7910)  Acc@5: 100.0000 (98.4808)  time: 0.3500  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [1490/3125]  eta: 0:09:31  Lr: 0.001875  Loss: -0.5416  Acc@1: 87.5000 (86.8000)  Acc@5: 100.0000 (98.4868)  time: 0.3506  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [1500/3125]  eta: 0:09:27  Lr: 0.001875  Loss: -0.7964  Acc@1: 87.5000 (86.8046)  Acc@5: 100.0000 (98.4802)  time: 0.3502  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [1510/3125]  eta: 0:09:24  Lr: 0.001875  Loss: -0.4095  Acc@1: 87.5000 (86.7886)  Acc@5: 100.0000 (98.4654)  time: 0.3493  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [1520/3125]  eta: 0:09:20  Lr: 0.001875  Loss: -0.5487  Acc@1: 87.5000 (86.7932)  Acc@5: 100.0000 (98.4714)  time: 0.3492  data: 0.0007  max mem: 2502
Train: Epoch[5/5]  [1530/3125]  eta: 0:09:17  Lr: 0.001875  Loss: -0.7483  Acc@1: 87.5000 (86.7938)  Acc@5: 100.0000 (98.4691)  time: 0.3490  data: 0.0007  max mem: 2502
Train: Epoch[5/5]  [1540/3125]  eta: 0:09:13  Lr: 0.001875  Loss: -0.5408  Acc@1: 81.2500 (86.7781)  Acc@5: 100.0000 (98.4750)  time: 0.3491  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [1550/3125]  eta: 0:09:10  Lr: 0.001875  Loss: -0.4176  Acc@1: 81.2500 (86.7465)  Acc@5: 100.0000 (98.4768)  time: 0.3482  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [1560/3125]  eta: 0:09:06  Lr: 0.001875  Loss: -0.4423  Acc@1: 87.5000 (86.7513)  Acc@5: 100.0000 (98.4825)  time: 0.3473  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [1570/3125]  eta: 0:09:03  Lr: 0.001875  Loss: -0.7554  Acc@1: 87.5000 (86.7720)  Acc@5: 100.0000 (98.4842)  time: 0.3489  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [1580/3125]  eta: 0:08:59  Lr: 0.001875  Loss: -0.8043  Acc@1: 93.7500 (86.7924)  Acc@5: 100.0000 (98.4859)  time: 0.3489  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [1590/3125]  eta: 0:08:56  Lr: 0.001875  Loss: -0.7499  Acc@1: 87.5000 (86.8086)  Acc@5: 100.0000 (98.4954)  time: 0.3486  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [1600/3125]  eta: 0:08:52  Lr: 0.001875  Loss: -0.4930  Acc@1: 87.5000 (86.7856)  Acc@5: 100.0000 (98.4853)  time: 0.3497  data: 0.0006  max mem: 2502
Train: Epoch[5/5]  [1610/3125]  eta: 0:08:49  Lr: 0.001875  Loss: -0.5151  Acc@1: 81.2500 (86.7668)  Acc@5: 100.0000 (98.4870)  time: 0.3495  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [1620/3125]  eta: 0:08:45  Lr: 0.001875  Loss: -0.2996  Acc@1: 81.2500 (86.7481)  Acc@5: 100.0000 (98.4847)  time: 0.3491  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [1630/3125]  eta: 0:08:42  Lr: 0.001875  Loss: -0.4651  Acc@1: 87.5000 (86.7681)  Acc@5: 100.0000 (98.4864)  time: 0.3492  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [1640/3125]  eta: 0:08:38  Lr: 0.001875  Loss: -0.6721  Acc@1: 87.5000 (86.7764)  Acc@5: 100.0000 (98.4956)  time: 0.3485  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [1650/3125]  eta: 0:08:35  Lr: 0.001875  Loss: -0.7113  Acc@1: 87.5000 (86.7580)  Acc@5: 100.0000 (98.4971)  time: 0.3482  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [1660/3125]  eta: 0:08:31  Lr: 0.001875  Loss: -0.4206  Acc@1: 87.5000 (86.7888)  Acc@5: 100.0000 (98.4986)  time: 0.3486  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [1670/3125]  eta: 0:08:28  Lr: 0.001875  Loss: -0.4344  Acc@1: 87.5000 (86.7594)  Acc@5: 100.0000 (98.5001)  time: 0.3493  data: 0.0008  max mem: 2502
Train: Epoch[5/5]  [1680/3125]  eta: 0:08:24  Lr: 0.001875  Loss: -0.6382  Acc@1: 81.2500 (86.7452)  Acc@5: 100.0000 (98.5054)  time: 0.3490  data: 0.0008  max mem: 2502
Train: Epoch[5/5]  [1690/3125]  eta: 0:08:21  Lr: 0.001875  Loss: -0.5987  Acc@1: 87.5000 (86.7756)  Acc@5: 100.0000 (98.5068)  time: 0.3486  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [1700/3125]  eta: 0:08:17  Lr: 0.001875  Loss: -0.6500  Acc@1: 87.5000 (86.7725)  Acc@5: 100.0000 (98.5156)  time: 0.3497  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [1710/3125]  eta: 0:08:14  Lr: 0.001875  Loss: -0.7586  Acc@1: 87.5000 (86.7804)  Acc@5: 100.0000 (98.5133)  time: 0.3494  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [1720/3125]  eta: 0:08:10  Lr: 0.001875  Loss: -0.4840  Acc@1: 87.5000 (86.7737)  Acc@5: 100.0000 (98.5110)  time: 0.3490  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [1730/3125]  eta: 0:08:07  Lr: 0.001875  Loss: -0.5988  Acc@1: 87.5000 (86.7851)  Acc@5: 100.0000 (98.5196)  time: 0.3491  data: 0.0007  max mem: 2502
Train: Epoch[5/5]  [1740/3125]  eta: 0:08:03  Lr: 0.001875  Loss: -0.7147  Acc@1: 87.5000 (86.7928)  Acc@5: 100.0000 (98.5210)  time: 0.3493  data: 0.0007  max mem: 2502
Train: Epoch[5/5]  [1750/3125]  eta: 0:08:00  Lr: 0.001875  Loss: -0.7940  Acc@1: 87.5000 (86.7861)  Acc@5: 100.0000 (98.5151)  time: 0.3498  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [1760/3125]  eta: 0:07:56  Lr: 0.001875  Loss: -0.2909  Acc@1: 87.5000 (86.7760)  Acc@5: 100.0000 (98.5200)  time: 0.3488  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [1770/3125]  eta: 0:07:53  Lr: 0.001875  Loss: -0.7406  Acc@1: 87.5000 (86.8012)  Acc@5: 100.0000 (98.5284)  time: 0.3485  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [1780/3125]  eta: 0:07:49  Lr: 0.001875  Loss: -0.6473  Acc@1: 87.5000 (86.7911)  Acc@5: 100.0000 (98.5331)  time: 0.3497  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [1790/3125]  eta: 0:07:46  Lr: 0.001875  Loss: -0.2697  Acc@1: 87.5000 (86.7846)  Acc@5: 100.0000 (98.5343)  time: 0.3498  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [1800/3125]  eta: 0:07:42  Lr: 0.001875  Loss: -0.8689  Acc@1: 87.5000 (86.7782)  Acc@5: 100.0000 (98.5390)  time: 0.3498  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [1810/3125]  eta: 0:07:39  Lr: 0.001875  Loss: -0.5011  Acc@1: 87.5000 (86.7649)  Acc@5: 100.0000 (98.5402)  time: 0.3500  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [1820/3125]  eta: 0:07:35  Lr: 0.001875  Loss: -0.6947  Acc@1: 87.5000 (86.7484)  Acc@5: 100.0000 (98.5276)  time: 0.3495  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [1830/3125]  eta: 0:07:32  Lr: 0.001875  Loss: -0.3471  Acc@1: 81.2500 (86.7388)  Acc@5: 100.0000 (98.5220)  time: 0.3495  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [1840/3125]  eta: 0:07:28  Lr: 0.001875  Loss: -0.5773  Acc@1: 87.5000 (86.7531)  Acc@5: 100.0000 (98.5232)  time: 0.3506  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [1850/3125]  eta: 0:07:25  Lr: 0.001875  Loss: -0.0463  Acc@1: 87.5000 (86.7504)  Acc@5: 100.0000 (98.5278)  time: 0.3499  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [1860/3125]  eta: 0:07:21  Lr: 0.001875  Loss: -0.6580  Acc@1: 87.5000 (86.7611)  Acc@5: 100.0000 (98.5290)  time: 0.3492  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [1870/3125]  eta: 0:07:18  Lr: 0.001875  Loss: -0.7728  Acc@1: 87.5000 (86.7484)  Acc@5: 100.0000 (98.5269)  time: 0.3493  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [1880/3125]  eta: 0:07:14  Lr: 0.001875  Loss: -0.9089  Acc@1: 87.5000 (86.7590)  Acc@5: 100.0000 (98.5280)  time: 0.3509  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [1890/3125]  eta: 0:07:11  Lr: 0.001875  Loss: -0.8316  Acc@1: 93.7500 (86.7729)  Acc@5: 100.0000 (98.5358)  time: 0.3514  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [1900/3125]  eta: 0:07:08  Lr: 0.001875  Loss: -0.5014  Acc@1: 87.5000 (86.7767)  Acc@5: 100.0000 (98.5337)  time: 0.3502  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [1910/3125]  eta: 0:07:04  Lr: 0.001875  Loss: -0.9089  Acc@1: 87.5000 (86.7936)  Acc@5: 100.0000 (98.5381)  time: 0.3502  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [1920/3125]  eta: 0:07:01  Lr: 0.001875  Loss: -0.7361  Acc@1: 93.7500 (86.7907)  Acc@5: 100.0000 (98.5359)  time: 0.3494  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [1930/3125]  eta: 0:06:57  Lr: 0.001875  Loss: -0.6838  Acc@1: 81.2500 (86.7750)  Acc@5: 100.0000 (98.5306)  time: 0.3488  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [1940/3125]  eta: 0:06:54  Lr: 0.001875  Loss: -0.6632  Acc@1: 87.5000 (86.8045)  Acc@5: 100.0000 (98.5317)  time: 0.3487  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [1950/3125]  eta: 0:06:50  Lr: 0.001875  Loss: -0.7328  Acc@1: 93.7500 (86.8241)  Acc@5: 100.0000 (98.5296)  time: 0.3488  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [1960/3125]  eta: 0:06:47  Lr: 0.001875  Loss: -0.8933  Acc@1: 93.7500 (86.8211)  Acc@5: 100.0000 (98.5243)  time: 0.3484  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [1970/3125]  eta: 0:06:43  Lr: 0.001875  Loss: -0.0241  Acc@1: 87.5000 (86.8087)  Acc@5: 100.0000 (98.5192)  time: 0.3475  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [1980/3125]  eta: 0:06:40  Lr: 0.001875  Loss: -0.5126  Acc@1: 87.5000 (86.8091)  Acc@5: 100.0000 (98.5140)  time: 0.3475  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [1990/3125]  eta: 0:06:36  Lr: 0.001875  Loss: -0.9874  Acc@1: 87.5000 (86.8125)  Acc@5: 100.0000 (98.5152)  time: 0.3480  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [2000/3125]  eta: 0:06:33  Lr: 0.001875  Loss: -0.7858  Acc@1: 87.5000 (86.8003)  Acc@5: 100.0000 (98.5132)  time: 0.3487  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [2010/3125]  eta: 0:06:29  Lr: 0.001875  Loss: -0.8208  Acc@1: 87.5000 (86.8163)  Acc@5: 100.0000 (98.5206)  time: 0.3492  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [2020/3125]  eta: 0:06:26  Lr: 0.001875  Loss: -0.8416  Acc@1: 87.5000 (86.8196)  Acc@5: 100.0000 (98.5187)  time: 0.3488  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [2030/3125]  eta: 0:06:22  Lr: 0.001875  Loss: -0.7593  Acc@1: 87.5000 (86.8261)  Acc@5: 100.0000 (98.5229)  time: 0.3484  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [2040/3125]  eta: 0:06:19  Lr: 0.001875  Loss: -0.3995  Acc@1: 87.5000 (86.8508)  Acc@5: 100.0000 (98.5240)  time: 0.3485  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [2050/3125]  eta: 0:06:15  Lr: 0.001875  Loss: -0.3900  Acc@1: 87.5000 (86.8692)  Acc@5: 100.0000 (98.5190)  time: 0.3488  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [2060/3125]  eta: 0:06:12  Lr: 0.001875  Loss: -0.8662  Acc@1: 87.5000 (86.8814)  Acc@5: 100.0000 (98.5262)  time: 0.3494  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [2070/3125]  eta: 0:06:08  Lr: 0.001875  Loss: -0.7119  Acc@1: 87.5000 (86.8662)  Acc@5: 100.0000 (98.5243)  time: 0.3492  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [2080/3125]  eta: 0:06:05  Lr: 0.001875  Loss: -0.6721  Acc@1: 87.5000 (86.8663)  Acc@5: 100.0000 (98.5284)  time: 0.3494  data: 0.0007  max mem: 2502
Train: Epoch[5/5]  [2090/3125]  eta: 0:06:01  Lr: 0.001875  Loss: -0.8449  Acc@1: 87.5000 (86.8574)  Acc@5: 100.0000 (98.5294)  time: 0.3492  data: 0.0008  max mem: 2502
Train: Epoch[5/5]  [2100/3125]  eta: 0:05:58  Lr: 0.001875  Loss: -0.7451  Acc@1: 87.5000 (86.8574)  Acc@5: 100.0000 (98.5305)  time: 0.3485  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [2110/3125]  eta: 0:05:54  Lr: 0.001875  Loss: -0.8975  Acc@1: 87.5000 (86.8457)  Acc@5: 100.0000 (98.5285)  time: 0.3507  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [2120/3125]  eta: 0:05:51  Lr: 0.001875  Loss: -0.3988  Acc@1: 87.5000 (86.8488)  Acc@5: 100.0000 (98.5296)  time: 0.3507  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [2130/3125]  eta: 0:05:47  Lr: 0.001875  Loss: -0.6486  Acc@1: 87.5000 (86.8401)  Acc@5: 100.0000 (98.5277)  time: 0.3493  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [2140/3125]  eta: 0:05:44  Lr: 0.001875  Loss: -0.8749  Acc@1: 87.5000 (86.8403)  Acc@5: 100.0000 (98.5258)  time: 0.3506  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [2150/3125]  eta: 0:05:40  Lr: 0.001875  Loss: -0.4201  Acc@1: 87.5000 (86.8491)  Acc@5: 100.0000 (98.5268)  time: 0.3504  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [2160/3125]  eta: 0:05:37  Lr: 0.001875  Loss: -0.9449  Acc@1: 87.5000 (86.8695)  Acc@5: 100.0000 (98.5308)  time: 0.3492  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [2170/3125]  eta: 0:05:33  Lr: 0.001875  Loss: -0.7381  Acc@1: 93.7500 (86.8897)  Acc@5: 100.0000 (98.5375)  time: 0.3497  data: 0.0011  max mem: 2502
Train: Epoch[5/5]  [2180/3125]  eta: 0:05:30  Lr: 0.001875  Loss: -0.7259  Acc@1: 87.5000 (86.9039)  Acc@5: 100.0000 (98.5385)  time: 0.3501  data: 0.0011  max mem: 2502
Train: Epoch[5/5]  [2190/3125]  eta: 0:05:26  Lr: 0.001875  Loss: -0.7743  Acc@1: 87.5000 (86.9038)  Acc@5: 100.0000 (98.5395)  time: 0.3494  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [2200/3125]  eta: 0:05:23  Lr: 0.001875  Loss: -0.6942  Acc@1: 81.2500 (86.8895)  Acc@5: 100.0000 (98.5461)  time: 0.3499  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [2210/3125]  eta: 0:05:19  Lr: 0.001875  Loss: -0.8109  Acc@1: 81.2500 (86.9064)  Acc@5: 100.0000 (98.5527)  time: 0.3503  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [2220/3125]  eta: 0:05:16  Lr: 0.001875  Loss: -0.7318  Acc@1: 87.5000 (86.9006)  Acc@5: 100.0000 (98.5508)  time: 0.3492  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [2230/3125]  eta: 0:05:12  Lr: 0.001875  Loss: -0.9876  Acc@1: 87.5000 (86.9117)  Acc@5: 100.0000 (98.5517)  time: 0.3488  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [2240/3125]  eta: 0:05:09  Lr: 0.001875  Loss: -0.7249  Acc@1: 87.5000 (86.9115)  Acc@5: 100.0000 (98.5498)  time: 0.3497  data: 0.0010  max mem: 2502
Train: Epoch[5/5]  [2250/3125]  eta: 0:05:05  Lr: 0.001875  Loss: -0.9524  Acc@1: 87.5000 (86.9197)  Acc@5: 100.0000 (98.5451)  time: 0.3497  data: 0.0010  max mem: 2502
Train: Epoch[5/5]  [2260/3125]  eta: 0:05:02  Lr: 0.001875  Loss: -0.4572  Acc@1: 87.5000 (86.9084)  Acc@5: 100.0000 (98.5488)  time: 0.3489  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [2270/3125]  eta: 0:04:58  Lr: 0.001875  Loss: -0.9617  Acc@1: 87.5000 (86.9138)  Acc@5: 100.0000 (98.5496)  time: 0.3481  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [2280/3125]  eta: 0:04:55  Lr: 0.001875  Loss: -0.5804  Acc@1: 87.5000 (86.9082)  Acc@5: 100.0000 (98.5478)  time: 0.3476  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [2290/3125]  eta: 0:04:51  Lr: 0.001875  Loss: -0.7204  Acc@1: 87.5000 (86.9298)  Acc@5: 100.0000 (98.5487)  time: 0.3483  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [2300/3125]  eta: 0:04:48  Lr: 0.001875  Loss: -0.3317  Acc@1: 87.5000 (86.9160)  Acc@5: 100.0000 (98.5414)  time: 0.3489  data: 0.0009  max mem: 2502
Train: Epoch[5/5]  [2310/3125]  eta: 0:04:44  Lr: 0.001875  Loss: -0.4427  Acc@1: 87.5000 (86.9294)  Acc@5: 100.0000 (98.5342)  time: 0.3490  data: 0.0009  max mem: 2502
Train: Epoch[5/5]  [2320/3125]  eta: 0:04:41  Lr: 0.001875  Loss: -0.6750  Acc@1: 93.7500 (86.9399)  Acc@5: 93.7500 (98.5217)  time: 0.3484  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [2330/3125]  eta: 0:04:37  Lr: 0.001875  Loss: -0.4016  Acc@1: 87.5000 (86.9343)  Acc@5: 100.0000 (98.5253)  time: 0.3479  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [2340/3125]  eta: 0:04:34  Lr: 0.001875  Loss: -0.7895  Acc@1: 87.5000 (86.9340)  Acc@5: 100.0000 (98.5263)  time: 0.3475  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [2350/3125]  eta: 0:04:30  Lr: 0.001875  Loss: -0.6417  Acc@1: 87.5000 (86.9391)  Acc@5: 100.0000 (98.5325)  time: 0.3473  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [2360/3125]  eta: 0:04:27  Lr: 0.001875  Loss: -0.8916  Acc@1: 87.5000 (86.9494)  Acc@5: 100.0000 (98.5335)  time: 0.3479  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [2370/3125]  eta: 0:04:23  Lr: 0.001875  Loss: -0.5680  Acc@1: 87.5000 (86.9517)  Acc@5: 100.0000 (98.5344)  time: 0.3480  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [2380/3125]  eta: 0:04:20  Lr: 0.001875  Loss: -0.7498  Acc@1: 87.5000 (86.9724)  Acc@5: 100.0000 (98.5353)  time: 0.3477  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [2390/3125]  eta: 0:04:16  Lr: 0.001875  Loss: -0.6320  Acc@1: 93.7500 (86.9746)  Acc@5: 100.0000 (98.5336)  time: 0.3482  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [2400/3125]  eta: 0:04:13  Lr: 0.001875  Loss: -0.6438  Acc@1: 87.5000 (86.9742)  Acc@5: 100.0000 (98.5319)  time: 0.3484  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [2410/3125]  eta: 0:04:09  Lr: 0.001875  Loss: -0.5818  Acc@1: 87.5000 (86.9556)  Acc@5: 100.0000 (98.5354)  time: 0.3499  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [2420/3125]  eta: 0:04:06  Lr: 0.001875  Loss: -0.4382  Acc@1: 81.2500 (86.9553)  Acc@5: 100.0000 (98.5362)  time: 0.3500  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [2430/3125]  eta: 0:04:02  Lr: 0.001875  Loss: -0.6005  Acc@1: 81.2500 (86.9447)  Acc@5: 100.0000 (98.5346)  time: 0.3491  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [2440/3125]  eta: 0:03:59  Lr: 0.001875  Loss: 0.3124  Acc@1: 81.2500 (86.9316)  Acc@5: 100.0000 (98.5380)  time: 0.3493  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [2450/3125]  eta: 0:03:55  Lr: 0.001875  Loss: -0.6590  Acc@1: 87.5000 (86.9237)  Acc@5: 100.0000 (98.5414)  time: 0.3487  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [2460/3125]  eta: 0:03:52  Lr: 0.001875  Loss: -0.5264  Acc@1: 87.5000 (86.9286)  Acc@5: 100.0000 (98.5423)  time: 0.3484  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [2470/3125]  eta: 0:03:48  Lr: 0.001875  Loss: -0.4762  Acc@1: 87.5000 (86.9208)  Acc@5: 100.0000 (98.5406)  time: 0.3491  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [2480/3125]  eta: 0:03:45  Lr: 0.001875  Loss: -0.7919  Acc@1: 81.2500 (86.9181)  Acc@5: 100.0000 (98.5364)  time: 0.3500  data: 0.0011  max mem: 2502
Train: Epoch[5/5]  [2490/3125]  eta: 0:03:41  Lr: 0.001875  Loss: -0.7811  Acc@1: 87.5000 (86.9204)  Acc@5: 100.0000 (98.5347)  time: 0.3497  data: 0.0011  max mem: 2502
Train: Epoch[5/5]  [2500/3125]  eta: 0:03:38  Lr: 0.001875  Loss: -0.8402  Acc@1: 87.5000 (86.9277)  Acc@5: 100.0000 (98.5331)  time: 0.3490  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [2510/3125]  eta: 0:03:34  Lr: 0.001875  Loss: -0.7231  Acc@1: 87.5000 (86.9350)  Acc@5: 100.0000 (98.5389)  time: 0.3487  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [2520/3125]  eta: 0:03:31  Lr: 0.001875  Loss: -0.3723  Acc@1: 87.5000 (86.9496)  Acc@5: 100.0000 (98.5398)  time: 0.3486  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [2530/3125]  eta: 0:03:27  Lr: 0.001875  Loss: -0.8330  Acc@1: 87.5000 (86.9395)  Acc@5: 100.0000 (98.5431)  time: 0.3492  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [2540/3125]  eta: 0:03:24  Lr: 0.001875  Loss: -0.4993  Acc@1: 87.5000 (86.9466)  Acc@5: 100.0000 (98.5463)  time: 0.3497  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [2550/3125]  eta: 0:03:20  Lr: 0.001875  Loss: 0.0686  Acc@1: 87.5000 (86.9414)  Acc@5: 100.0000 (98.5447)  time: 0.3492  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [2560/3125]  eta: 0:03:17  Lr: 0.001875  Loss: -0.0950  Acc@1: 87.5000 (86.9241)  Acc@5: 100.0000 (98.5430)  time: 0.3495  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [2570/3125]  eta: 0:03:13  Lr: 0.001875  Loss: -0.5665  Acc@1: 81.2500 (86.9093)  Acc@5: 100.0000 (98.5439)  time: 0.3504  data: 0.0006  max mem: 2502
Train: Epoch[5/5]  [2580/3125]  eta: 0:03:10  Lr: 0.001875  Loss: -0.6864  Acc@1: 87.5000 (86.9043)  Acc@5: 100.0000 (98.5422)  time: 0.3503  data: 0.0006  max mem: 2502
Train: Epoch[5/5]  [2590/3125]  eta: 0:03:06  Lr: 0.001875  Loss: -0.7596  Acc@1: 87.5000 (86.9066)  Acc@5: 100.0000 (98.5406)  time: 0.3497  data: 0.0007  max mem: 2502
Train: Epoch[5/5]  [2600/3125]  eta: 0:03:03  Lr: 0.001875  Loss: -0.9913  Acc@1: 87.5000 (86.9185)  Acc@5: 100.0000 (98.5438)  time: 0.3493  data: 0.0008  max mem: 2502
Train: Epoch[5/5]  [2610/3125]  eta: 0:02:59  Lr: 0.001875  Loss: -0.4299  Acc@1: 87.5000 (86.9279)  Acc@5: 100.0000 (98.5494)  time: 0.3492  data: 0.0007  max mem: 2502
Train: Epoch[5/5]  [2620/3125]  eta: 0:02:56  Lr: 0.001875  Loss: -0.6177  Acc@1: 87.5000 (86.9372)  Acc@5: 100.0000 (98.5502)  time: 0.3489  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [2630/3125]  eta: 0:02:52  Lr: 0.001875  Loss: -0.9363  Acc@1: 87.5000 (86.9275)  Acc@5: 100.0000 (98.5533)  time: 0.3492  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [2640/3125]  eta: 0:02:49  Lr: 0.001875  Loss: -0.6213  Acc@1: 87.5000 (86.9320)  Acc@5: 100.0000 (98.5564)  time: 0.3494  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [2650/3125]  eta: 0:02:45  Lr: 0.001875  Loss: -0.6037  Acc@1: 87.5000 (86.9365)  Acc@5: 100.0000 (98.5571)  time: 0.3485  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [2660/3125]  eta: 0:02:42  Lr: 0.001875  Loss: -0.6062  Acc@1: 87.5000 (86.9457)  Acc@5: 100.0000 (98.5626)  time: 0.3483  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [2670/3125]  eta: 0:02:38  Lr: 0.001875  Loss: -0.4181  Acc@1: 87.5000 (86.9408)  Acc@5: 100.0000 (98.5656)  time: 0.3485  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [2680/3125]  eta: 0:02:35  Lr: 0.001875  Loss: -0.5029  Acc@1: 87.5000 (86.9428)  Acc@5: 100.0000 (98.5640)  time: 0.3494  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [2690/3125]  eta: 0:02:31  Lr: 0.001875  Loss: -0.5838  Acc@1: 87.5000 (86.9263)  Acc@5: 100.0000 (98.5693)  time: 0.3494  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [2700/3125]  eta: 0:02:28  Lr: 0.001875  Loss: -0.2431  Acc@1: 87.5000 (86.9400)  Acc@5: 100.0000 (98.5723)  time: 0.3486  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [2710/3125]  eta: 0:02:24  Lr: 0.001875  Loss: -0.5682  Acc@1: 87.5000 (86.9490)  Acc@5: 100.0000 (98.5614)  time: 0.3482  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [2720/3125]  eta: 0:02:21  Lr: 0.001875  Loss: -0.8795  Acc@1: 87.5000 (86.9464)  Acc@5: 100.0000 (98.5644)  time: 0.3476  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [2730/3125]  eta: 0:02:17  Lr: 0.001875  Loss: -0.8814  Acc@1: 87.5000 (86.9553)  Acc@5: 100.0000 (98.5605)  time: 0.3484  data: 0.0007  max mem: 2502
Train: Epoch[5/5]  [2740/3125]  eta: 0:02:14  Lr: 0.001875  Loss: -0.6487  Acc@1: 87.5000 (86.9687)  Acc@5: 100.0000 (98.5658)  time: 0.3494  data: 0.0008  max mem: 2502
Train: Epoch[5/5]  [2750/3125]  eta: 0:02:10  Lr: 0.001875  Loss: -0.3772  Acc@1: 87.5000 (86.9638)  Acc@5: 100.0000 (98.5619)  time: 0.3489  data: 0.0011  max mem: 2502
Train: Epoch[5/5]  [2760/3125]  eta: 0:02:07  Lr: 0.001875  Loss: -0.6079  Acc@1: 87.5000 (86.9680)  Acc@5: 100.0000 (98.5626)  time: 0.3482  data: 0.0011  max mem: 2502
Train: Epoch[5/5]  [2770/3125]  eta: 0:02:03  Lr: 0.001875  Loss: -0.8545  Acc@1: 87.5000 (86.9767)  Acc@5: 100.0000 (98.5655)  time: 0.3480  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [2780/3125]  eta: 0:02:00  Lr: 0.001875  Loss: -0.7078  Acc@1: 87.5000 (86.9764)  Acc@5: 100.0000 (98.5639)  time: 0.3471  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [2790/3125]  eta: 0:01:56  Lr: 0.001875  Loss: -0.7678  Acc@1: 87.5000 (86.9827)  Acc@5: 100.0000 (98.5646)  time: 0.3469  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [2800/3125]  eta: 0:01:53  Lr: 0.001875  Loss: -0.5288  Acc@1: 87.5000 (86.9533)  Acc@5: 100.0000 (98.5652)  time: 0.3489  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [2810/3125]  eta: 0:01:50  Lr: 0.001875  Loss: -0.7514  Acc@1: 81.2500 (86.9441)  Acc@5: 100.0000 (98.5637)  time: 0.3491  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [2820/3125]  eta: 0:01:46  Lr: 0.001875  Loss: -0.7893  Acc@1: 87.5000 (86.9395)  Acc@5: 100.0000 (98.5666)  time: 0.3477  data: 0.0006  max mem: 2502
Train: Epoch[5/5]  [2830/3125]  eta: 0:01:43  Lr: 0.001875  Loss: -0.5998  Acc@1: 87.5000 (86.9481)  Acc@5: 100.0000 (98.5650)  time: 0.3480  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [2840/3125]  eta: 0:01:39  Lr: 0.001875  Loss: -0.7596  Acc@1: 87.5000 (86.9434)  Acc@5: 100.0000 (98.5590)  time: 0.3483  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [2850/3125]  eta: 0:01:36  Lr: 0.001875  Loss: -0.8453  Acc@1: 87.5000 (86.9607)  Acc@5: 100.0000 (98.5597)  time: 0.3492  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [2860/3125]  eta: 0:01:32  Lr: 0.001875  Loss: -0.8072  Acc@1: 87.5000 (86.9473)  Acc@5: 100.0000 (98.5604)  time: 0.3498  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [2870/3125]  eta: 0:01:29  Lr: 0.001875  Loss: -0.6638  Acc@1: 81.2500 (86.9427)  Acc@5: 100.0000 (98.5610)  time: 0.3488  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [2880/3125]  eta: 0:01:25  Lr: 0.001875  Loss: -0.6470  Acc@1: 87.5000 (86.9360)  Acc@5: 100.0000 (98.5552)  time: 0.3489  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [2890/3125]  eta: 0:01:22  Lr: 0.001875  Loss: -0.7433  Acc@1: 87.5000 (86.9401)  Acc@5: 100.0000 (98.5602)  time: 0.3494  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [2900/3125]  eta: 0:01:18  Lr: 0.001875  Loss: -0.6019  Acc@1: 87.5000 (86.9528)  Acc@5: 100.0000 (98.5630)  time: 0.3501  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [2910/3125]  eta: 0:01:15  Lr: 0.001875  Loss: -0.7281  Acc@1: 87.5000 (86.9632)  Acc@5: 100.0000 (98.5658)  time: 0.3501  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [2920/3125]  eta: 0:01:11  Lr: 0.001875  Loss: -0.5258  Acc@1: 87.5000 (86.9565)  Acc@5: 100.0000 (98.5643)  time: 0.3501  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [2930/3125]  eta: 0:01:08  Lr: 0.001875  Loss: -0.3960  Acc@1: 81.2500 (86.9434)  Acc@5: 100.0000 (98.5670)  time: 0.3512  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [2940/3125]  eta: 0:01:04  Lr: 0.001875  Loss: -0.6818  Acc@1: 81.2500 (86.9368)  Acc@5: 100.0000 (98.5677)  time: 0.3507  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [2950/3125]  eta: 0:01:01  Lr: 0.001875  Loss: -0.7187  Acc@1: 87.5000 (86.9536)  Acc@5: 100.0000 (98.5704)  time: 0.3514  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [2960/3125]  eta: 0:00:57  Lr: 0.001875  Loss: -1.0033  Acc@1: 87.5000 (86.9554)  Acc@5: 100.0000 (98.5731)  time: 0.3516  data: 0.0008  max mem: 2502
Train: Epoch[5/5]  [2970/3125]  eta: 0:00:54  Lr: 0.001875  Loss: -0.5244  Acc@1: 87.5000 (86.9530)  Acc@5: 100.0000 (98.5779)  time: 0.3503  data: 0.0008  max mem: 2502
Train: Epoch[5/5]  [2980/3125]  eta: 0:00:50  Lr: 0.001875  Loss: -0.8079  Acc@1: 87.5000 (86.9570)  Acc@5: 100.0000 (98.5827)  time: 0.3510  data: 0.0010  max mem: 2502
Train: Epoch[5/5]  [2990/3125]  eta: 0:00:47  Lr: 0.001875  Loss: -0.8925  Acc@1: 87.5000 (86.9567)  Acc@5: 100.0000 (98.5853)  time: 0.3508  data: 0.0010  max mem: 2502
Train: Epoch[5/5]  [3000/3125]  eta: 0:00:43  Lr: 0.001875  Loss: -0.6972  Acc@1: 87.5000 (86.9585)  Acc@5: 100.0000 (98.5796)  time: 0.3500  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [3010/3125]  eta: 0:00:40  Lr: 0.001875  Loss: -0.8866  Acc@1: 87.5000 (86.9624)  Acc@5: 100.0000 (98.5802)  time: 0.3493  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [3020/3125]  eta: 0:00:36  Lr: 0.001875  Loss: -0.8113  Acc@1: 87.5000 (86.9683)  Acc@5: 100.0000 (98.5808)  time: 0.3490  data: 0.0009  max mem: 2502
Train: Epoch[5/5]  [3030/3125]  eta: 0:00:33  Lr: 0.001875  Loss: -0.5821  Acc@1: 87.5000 (86.9680)  Acc@5: 100.0000 (98.5813)  time: 0.3491  data: 0.0009  max mem: 2502
Train: Epoch[5/5]  [3040/3125]  eta: 0:00:29  Lr: 0.001875  Loss: -0.9046  Acc@1: 87.5000 (86.9718)  Acc@5: 100.0000 (98.5839)  time: 0.3490  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [3050/3125]  eta: 0:00:26  Lr: 0.001875  Loss: -0.9032  Acc@1: 87.5000 (86.9756)  Acc@5: 100.0000 (98.5886)  time: 0.3495  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [3060/3125]  eta: 0:00:22  Lr: 0.001875  Loss: -0.7223  Acc@1: 87.5000 (86.9610)  Acc@5: 100.0000 (98.5871)  time: 0.3494  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [3070/3125]  eta: 0:00:19  Lr: 0.001875  Loss: -0.7838  Acc@1: 81.2500 (86.9607)  Acc@5: 100.0000 (98.5835)  time: 0.3499  data: 0.0014  max mem: 2502
Train: Epoch[5/5]  [3080/3125]  eta: 0:00:15  Lr: 0.001875  Loss: -0.3780  Acc@1: 87.5000 (86.9563)  Acc@5: 100.0000 (98.5800)  time: 0.3504  data: 0.0014  max mem: 2502
Train: Epoch[5/5]  [3090/3125]  eta: 0:00:12  Lr: 0.001875  Loss: -0.8756  Acc@1: 87.5000 (86.9581)  Acc@5: 100.0000 (98.5846)  time: 0.3499  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [3100/3125]  eta: 0:00:08  Lr: 0.001875  Loss: -0.0556  Acc@1: 87.5000 (86.9437)  Acc@5: 100.0000 (98.5831)  time: 0.3498  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [3110/3125]  eta: 0:00:05  Lr: 0.001875  Loss: -0.5214  Acc@1: 87.5000 (86.9395)  Acc@5: 100.0000 (98.5837)  time: 0.3507  data: 0.0009  max mem: 2502
Train: Epoch[5/5]  [3120/3125]  eta: 0:00:01  Lr: 0.001875  Loss: -0.6626  Acc@1: 87.5000 (86.9393)  Acc@5: 100.0000 (98.5862)  time: 0.3517  data: 0.0023  max mem: 2502
Train: Epoch[5/5]  [3124/3125]  eta: 0:00:00  Lr: 0.001875  Loss: -0.7535  Acc@1: 87.5000 (86.9360)  Acc@5: 100.0000 (98.5860)  time: 0.3507  data: 0.0018  max mem: 2502
Train: Epoch[5/5] Total time: 0:18:12 (0.3495 s / it)
Averaged stats: Lr: 0.001875  Loss: -0.7535  Acc@1: 87.5000 (86.9360)  Acc@5: 100.0000 (98.5860)
Test: [Task 1]  [   0/1627]  eta: 0:15:00  Loss: 3.1339 (3.1339)  Acc@1: 31.2500 (31.2500)  Acc@5: 56.2500 (56.2500)  time: 0.5535  data: 0.3360  max mem: 2502
Test: [Task 1]  [  10/1627]  eta: 0:06:43  Loss: 3.0952 (3.0194)  Acc@1: 18.7500 (22.1591)  Acc@5: 62.5000 (61.9318)  time: 0.2494  data: 0.0308  max mem: 2502
Test: [Task 1]  [  20/1627]  eta: 0:06:17  Loss: 3.0274 (2.9881)  Acc@1: 18.7500 (23.2143)  Acc@5: 62.5000 (60.4167)  time: 0.2187  data: 0.0003  max mem: 2502
Test: [Task 1]  [  30/1627]  eta: 0:06:06  Loss: 3.0840 (3.0747)  Acc@1: 18.7500 (20.9677)  Acc@5: 56.2500 (57.6613)  time: 0.2188  data: 0.0005  max mem: 2502
Test: [Task 1]  [  40/1627]  eta: 0:06:00  Loss: 3.1659 (3.1203)  Acc@1: 12.5000 (19.8171)  Acc@5: 56.2500 (55.7927)  time: 0.2190  data: 0.0005  max mem: 2502
Test: [Task 1]  [  50/1627]  eta: 0:05:55  Loss: 3.2188 (3.0998)  Acc@1: 18.7500 (20.7108)  Acc@5: 56.2500 (56.1275)  time: 0.2194  data: 0.0004  max mem: 2502
Test: [Task 1]  [  60/1627]  eta: 0:05:51  Loss: 3.1872 (3.1055)  Acc@1: 25.0000 (21.2090)  Acc@5: 56.2500 (56.2500)  time: 0.2194  data: 0.0003  max mem: 2502
Test: [Task 1]  [  70/1627]  eta: 0:05:48  Loss: 3.1685 (3.1150)  Acc@1: 18.7500 (21.3028)  Acc@5: 56.2500 (56.1620)  time: 0.2193  data: 0.0007  max mem: 2502
Test: [Task 1]  [  80/1627]  eta: 0:05:45  Loss: 2.9683 (3.0962)  Acc@1: 18.7500 (21.5278)  Acc@5: 56.2500 (57.0216)  time: 0.2199  data: 0.0009  max mem: 2502
Test: [Task 1]  [  90/1627]  eta: 0:05:42  Loss: 2.9595 (3.0884)  Acc@1: 25.0000 (21.7033)  Acc@5: 56.2500 (57.2802)  time: 0.2200  data: 0.0008  max mem: 2502
Test: [Task 1]  [ 100/1627]  eta: 0:05:39  Loss: 3.1266 (3.0970)  Acc@1: 25.0000 (22.0916)  Acc@5: 56.2500 (57.3020)  time: 0.2196  data: 0.0006  max mem: 2502
Test: [Task 1]  [ 110/1627]  eta: 0:05:37  Loss: 3.1787 (3.1031)  Acc@1: 18.7500 (21.8468)  Acc@5: 56.2500 (57.4324)  time: 0.2203  data: 0.0004  max mem: 2502
Test: [Task 1]  [ 120/1627]  eta: 0:05:34  Loss: 3.0741 (3.0883)  Acc@1: 18.7500 (22.2107)  Acc@5: 62.5000 (58.0579)  time: 0.2201  data: 0.0004  max mem: 2502
Test: [Task 1]  [ 130/1627]  eta: 0:05:32  Loss: 3.0163 (3.0859)  Acc@1: 18.7500 (22.4237)  Acc@5: 62.5000 (58.1107)  time: 0.2187  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 140/1627]  eta: 0:05:29  Loss: 3.1485 (3.0823)  Acc@1: 25.0000 (22.4734)  Acc@5: 56.2500 (58.4220)  time: 0.2188  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 150/1627]  eta: 0:05:27  Loss: 2.8030 (3.0612)  Acc@1: 31.2500 (23.2202)  Acc@5: 62.5000 (59.1887)  time: 0.2192  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 160/1627]  eta: 0:05:24  Loss: 3.0330 (3.0691)  Acc@1: 25.0000 (22.9037)  Acc@5: 62.5000 (58.9286)  time: 0.2195  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 170/1627]  eta: 0:05:22  Loss: 3.1198 (3.0609)  Acc@1: 18.7500 (22.9898)  Acc@5: 56.2500 (59.2836)  time: 0.2194  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 180/1627]  eta: 0:05:20  Loss: 3.0165 (3.0669)  Acc@1: 12.5000 (22.5138)  Acc@5: 62.5000 (59.0470)  time: 0.2197  data: 0.0004  max mem: 2502
Test: [Task 1]  [ 190/1627]  eta: 0:05:17  Loss: 3.0636 (3.0659)  Acc@1: 12.5000 (22.4804)  Acc@5: 62.5000 (59.0969)  time: 0.2205  data: 0.0010  max mem: 2502
Test: [Task 1]  [ 200/1627]  eta: 0:05:15  Loss: 3.1470 (3.0784)  Acc@1: 18.7500 (22.1704)  Acc@5: 56.2500 (58.7998)  time: 0.2196  data: 0.0010  max mem: 2502
Test: [Task 1]  [ 210/1627]  eta: 0:05:13  Loss: 3.2616 (3.0805)  Acc@1: 18.7500 (22.0972)  Acc@5: 50.0000 (58.5900)  time: 0.2192  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 220/1627]  eta: 0:05:10  Loss: 3.2734 (3.0908)  Acc@1: 18.7500 (21.8609)  Acc@5: 50.0000 (58.3145)  time: 0.2197  data: 0.0008  max mem: 2502
Test: [Task 1]  [ 230/1627]  eta: 0:05:08  Loss: 3.2849 (3.0967)  Acc@1: 18.7500 (21.6450)  Acc@5: 50.0000 (57.9816)  time: 0.2192  data: 0.0008  max mem: 2502
Test: [Task 1]  [ 240/1627]  eta: 0:05:06  Loss: 3.0162 (3.0868)  Acc@1: 25.0000 (22.0695)  Acc@5: 62.5000 (58.1950)  time: 0.2190  data: 0.0006  max mem: 2502
Test: [Task 1]  [ 250/1627]  eta: 0:05:03  Loss: 2.9042 (3.0860)  Acc@1: 25.0000 (22.0120)  Acc@5: 62.5000 (58.0926)  time: 0.2193  data: 0.0007  max mem: 2502
Test: [Task 1]  [ 260/1627]  eta: 0:05:01  Loss: 3.1373 (3.0911)  Acc@1: 18.7500 (21.8630)  Acc@5: 56.2500 (57.9262)  time: 0.2191  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 270/1627]  eta: 0:04:59  Loss: 3.0129 (3.0811)  Acc@1: 25.0000 (22.1172)  Acc@5: 56.2500 (58.1642)  time: 0.2197  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 280/1627]  eta: 0:04:57  Loss: 2.9739 (3.0793)  Acc@1: 25.0000 (22.2420)  Acc@5: 62.5000 (58.3185)  time: 0.2197  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 290/1627]  eta: 0:04:54  Loss: 3.1067 (3.0785)  Acc@1: 25.0000 (22.4227)  Acc@5: 62.5000 (58.2689)  time: 0.2187  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 300/1627]  eta: 0:04:52  Loss: 3.0010 (3.0746)  Acc@1: 25.0000 (22.4460)  Acc@5: 62.5000 (58.5756)  time: 0.2188  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 310/1627]  eta: 0:04:50  Loss: 2.9495 (3.0728)  Acc@1: 25.0000 (22.5482)  Acc@5: 62.5000 (58.7018)  time: 0.2194  data: 0.0004  max mem: 2502
Test: [Task 1]  [ 320/1627]  eta: 0:04:48  Loss: 3.1412 (3.0743)  Acc@1: 25.0000 (22.5662)  Acc@5: 62.5000 (58.7033)  time: 0.2193  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 330/1627]  eta: 0:04:45  Loss: 3.0766 (3.0738)  Acc@1: 18.7500 (22.4698)  Acc@5: 56.2500 (58.6103)  time: 0.2196  data: 0.0011  max mem: 2502
Test: [Task 1]  [ 340/1627]  eta: 0:04:43  Loss: 3.1071 (3.0766)  Acc@1: 18.7500 (22.4157)  Acc@5: 56.2500 (58.6327)  time: 0.2200  data: 0.0011  max mem: 2502
Test: [Task 1]  [ 350/1627]  eta: 0:04:41  Loss: 3.1419 (3.0791)  Acc@1: 18.7500 (22.3469)  Acc@5: 56.2500 (58.6004)  time: 0.2198  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 360/1627]  eta: 0:04:39  Loss: 3.1080 (3.0815)  Acc@1: 18.7500 (22.2472)  Acc@5: 56.2500 (58.4141)  time: 0.2195  data: 0.0004  max mem: 2502
Test: [Task 1]  [ 370/1627]  eta: 0:04:36  Loss: 3.0572 (3.0826)  Acc@1: 18.7500 (22.1024)  Acc@5: 56.2500 (58.3895)  time: 0.2189  data: 0.0004  max mem: 2502
Test: [Task 1]  [ 380/1627]  eta: 0:04:34  Loss: 3.0309 (3.0838)  Acc@1: 18.7500 (22.0308)  Acc@5: 56.2500 (58.3333)  time: 0.2187  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 390/1627]  eta: 0:04:32  Loss: 2.9622 (3.0799)  Acc@1: 18.7500 (22.1068)  Acc@5: 62.5000 (58.4719)  time: 0.2189  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 400/1627]  eta: 0:04:30  Loss: 3.1681 (3.0859)  Acc@1: 12.5000 (21.9296)  Acc@5: 56.2500 (58.3385)  time: 0.2189  data: 0.0004  max mem: 2502
Test: [Task 1]  [ 410/1627]  eta: 0:04:27  Loss: 3.2359 (3.0889)  Acc@1: 18.7500 (21.8674)  Acc@5: 56.2500 (58.3181)  time: 0.2188  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 420/1627]  eta: 0:04:25  Loss: 3.2349 (3.0902)  Acc@1: 18.7500 (21.8973)  Acc@5: 56.2500 (58.3135)  time: 0.2189  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 430/1627]  eta: 0:04:23  Loss: 3.0188 (3.0862)  Acc@1: 25.0000 (22.0418)  Acc@5: 62.5000 (58.4397)  time: 0.2185  data: 0.0004  max mem: 2502
Test: [Task 1]  [ 440/1627]  eta: 0:04:21  Loss: 3.0188 (3.0870)  Acc@1: 18.7500 (21.9529)  Acc@5: 56.2500 (58.3617)  time: 0.2184  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 450/1627]  eta: 0:04:18  Loss: 3.1662 (3.0916)  Acc@1: 18.7500 (21.8819)  Acc@5: 50.0000 (58.2594)  time: 0.2183  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 460/1627]  eta: 0:04:16  Loss: 3.1662 (3.0916)  Acc@1: 18.7500 (21.8953)  Acc@5: 56.2500 (58.2836)  time: 0.2180  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 470/1627]  eta: 0:04:14  Loss: 3.0568 (3.0910)  Acc@1: 18.7500 (21.9214)  Acc@5: 56.2500 (58.2803)  time: 0.2181  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 480/1627]  eta: 0:04:12  Loss: 3.1333 (3.0933)  Acc@1: 18.7500 (21.8295)  Acc@5: 50.0000 (58.1991)  time: 0.2183  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 490/1627]  eta: 0:04:09  Loss: 3.0615 (3.0947)  Acc@1: 18.7500 (21.7668)  Acc@5: 56.2500 (58.1466)  time: 0.2187  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 500/1627]  eta: 0:04:07  Loss: 3.0120 (3.0946)  Acc@1: 18.7500 (21.7440)  Acc@5: 56.2500 (58.0838)  time: 0.2187  data: 0.0004  max mem: 2502
Test: [Task 1]  [ 510/1627]  eta: 0:04:05  Loss: 3.0344 (3.0964)  Acc@1: 18.7500 (21.7099)  Acc@5: 56.2500 (58.0846)  time: 0.2189  data: 0.0007  max mem: 2502
Test: [Task 1]  [ 520/1627]  eta: 0:04:03  Loss: 3.2084 (3.0992)  Acc@1: 18.7500 (21.6411)  Acc@5: 50.0000 (58.0374)  time: 0.2191  data: 0.0010  max mem: 2502
Test: [Task 1]  [ 530/1627]  eta: 0:04:01  Loss: 2.7932 (3.0904)  Acc@1: 25.0000 (21.8691)  Acc@5: 62.5000 (58.2863)  time: 0.2183  data: 0.0007  max mem: 2502
Test: [Task 1]  [ 540/1627]  eta: 0:03:58  Loss: 2.7932 (3.0906)  Acc@1: 25.0000 (21.8346)  Acc@5: 62.5000 (58.3410)  time: 0.2182  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 550/1627]  eta: 0:03:56  Loss: 3.1380 (3.0933)  Acc@1: 18.7500 (21.8126)  Acc@5: 56.2500 (58.3031)  time: 0.2184  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 560/1627]  eta: 0:03:54  Loss: 3.1380 (3.0931)  Acc@1: 18.7500 (21.7246)  Acc@5: 56.2500 (58.3445)  time: 0.2182  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 570/1627]  eta: 0:03:52  Loss: 2.9990 (3.0918)  Acc@1: 12.5000 (21.7053)  Acc@5: 62.5000 (58.4501)  time: 0.2185  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 580/1627]  eta: 0:03:49  Loss: 3.0705 (3.0935)  Acc@1: 18.7500 (21.6760)  Acc@5: 56.2500 (58.4552)  time: 0.2185  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 590/1627]  eta: 0:03:47  Loss: 3.0705 (3.0933)  Acc@1: 18.7500 (21.6794)  Acc@5: 56.2500 (58.4179)  time: 0.2184  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 600/1627]  eta: 0:03:45  Loss: 3.0136 (3.0922)  Acc@1: 25.0000 (21.7242)  Acc@5: 62.5000 (58.4963)  time: 0.2185  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 610/1627]  eta: 0:03:43  Loss: 2.8829 (3.0885)  Acc@1: 25.0000 (21.8085)  Acc@5: 62.5000 (58.6027)  time: 0.2190  data: 0.0011  max mem: 2502
Test: [Task 1]  [ 620/1627]  eta: 0:03:41  Loss: 2.9901 (3.0897)  Acc@1: 25.0000 (21.8196)  Acc@5: 56.2500 (58.5749)  time: 0.2187  data: 0.0011  max mem: 2502
Test: [Task 1]  [ 630/1627]  eta: 0:03:38  Loss: 3.0996 (3.0886)  Acc@1: 18.7500 (21.8304)  Acc@5: 56.2500 (58.6272)  time: 0.2181  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 640/1627]  eta: 0:03:36  Loss: 2.9164 (3.0874)  Acc@1: 18.7500 (21.8214)  Acc@5: 62.5000 (58.7266)  time: 0.2186  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 650/1627]  eta: 0:03:34  Loss: 2.9488 (3.0866)  Acc@1: 18.7500 (21.8126)  Acc@5: 68.7500 (58.7942)  time: 0.2193  data: 0.0007  max mem: 2502
Test: [Task 1]  [ 660/1627]  eta: 0:03:32  Loss: 2.9568 (3.0852)  Acc@1: 18.7500 (21.8135)  Acc@5: 62.5000 (58.8408)  time: 0.2199  data: 0.0007  max mem: 2502
Test: [Task 1]  [ 670/1627]  eta: 0:03:30  Loss: 3.0153 (3.0870)  Acc@1: 18.7500 (21.8238)  Acc@5: 56.2500 (58.8301)  time: 0.2191  data: 0.0004  max mem: 2502
Test: [Task 1]  [ 680/1627]  eta: 0:03:27  Loss: 3.1564 (3.0863)  Acc@1: 25.0000 (21.8796)  Acc@5: 56.2500 (58.8565)  time: 0.2194  data: 0.0007  max mem: 2502
Test: [Task 1]  [ 690/1627]  eta: 0:03:25  Loss: 3.1564 (3.0872)  Acc@1: 25.0000 (21.9519)  Acc@5: 56.2500 (58.7826)  time: 0.2200  data: 0.0007  max mem: 2502
Test: [Task 1]  [ 700/1627]  eta: 0:03:23  Loss: 3.1153 (3.0863)  Acc@1: 25.0000 (21.9864)  Acc@5: 56.2500 (58.8356)  time: 0.2191  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 710/1627]  eta: 0:03:21  Loss: 2.9726 (3.0832)  Acc@1: 25.0000 (22.0288)  Acc@5: 68.7500 (58.9487)  time: 0.2194  data: 0.0005  max mem: 2502
Test: [Task 1]  [ 720/1627]  eta: 0:03:19  Loss: 2.8249 (3.0825)  Acc@1: 25.0000 (21.9920)  Acc@5: 62.5000 (58.9112)  time: 0.2195  data: 0.0005  max mem: 2502
Test: [Task 1]  [ 730/1627]  eta: 0:03:16  Loss: 3.1861 (3.0839)  Acc@1: 18.7500 (22.0075)  Acc@5: 56.2500 (58.8919)  time: 0.2203  data: 0.0007  max mem: 2502
Test: [Task 1]  [ 740/1627]  eta: 0:03:14  Loss: 3.1587 (3.0843)  Acc@1: 12.5000 (21.9636)  Acc@5: 56.2500 (58.8816)  time: 0.2204  data: 0.0007  max mem: 2502
Test: [Task 1]  [ 750/1627]  eta: 0:03:12  Loss: 3.1127 (3.0851)  Acc@1: 18.7500 (21.9790)  Acc@5: 56.2500 (58.8965)  time: 0.2188  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 760/1627]  eta: 0:03:10  Loss: 3.1781 (3.0873)  Acc@1: 25.0000 (21.9694)  Acc@5: 56.2500 (58.8288)  time: 0.2190  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 770/1627]  eta: 0:03:08  Loss: 3.2008 (3.0863)  Acc@1: 18.7500 (21.9196)  Acc@5: 56.2500 (58.8846)  time: 0.2194  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 780/1627]  eta: 0:03:05  Loss: 3.0459 (3.0871)  Acc@1: 18.7500 (21.9190)  Acc@5: 56.2500 (58.8428)  time: 0.2192  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 790/1627]  eta: 0:03:03  Loss: 3.1088 (3.0891)  Acc@1: 18.7500 (21.8790)  Acc@5: 56.2500 (58.7468)  time: 0.2195  data: 0.0007  max mem: 2502
Test: [Task 1]  [ 800/1627]  eta: 0:03:01  Loss: 3.2483 (3.0909)  Acc@1: 18.7500 (21.8477)  Acc@5: 50.0000 (58.6220)  time: 0.2197  data: 0.0007  max mem: 2502
Test: [Task 1]  [ 810/1627]  eta: 0:02:59  Loss: 3.2177 (3.0925)  Acc@1: 18.7500 (21.8172)  Acc@5: 50.0000 (58.5774)  time: 0.2191  data: 0.0004  max mem: 2502
Test: [Task 1]  [ 820/1627]  eta: 0:02:57  Loss: 3.1285 (3.0926)  Acc@1: 18.7500 (21.8103)  Acc@5: 62.5000 (58.5947)  time: 0.2183  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 830/1627]  eta: 0:02:54  Loss: 3.1080 (3.0913)  Acc@1: 25.0000 (21.8637)  Acc@5: 62.5000 (58.6643)  time: 0.2184  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 840/1627]  eta: 0:02:52  Loss: 2.8848 (3.0903)  Acc@1: 25.0000 (21.8713)  Acc@5: 62.5000 (58.7396)  time: 0.2191  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 850/1627]  eta: 0:02:50  Loss: 3.0241 (3.0930)  Acc@1: 18.7500 (21.8493)  Acc@5: 56.2500 (58.6296)  time: 0.2197  data: 0.0004  max mem: 2502
Test: [Task 1]  [ 860/1627]  eta: 0:02:48  Loss: 3.0568 (3.0927)  Acc@1: 18.7500 (21.8569)  Acc@5: 56.2500 (58.7035)  time: 0.2195  data: 0.0005  max mem: 2502
Test: [Task 1]  [ 870/1627]  eta: 0:02:46  Loss: 2.9079 (3.0903)  Acc@1: 25.0000 (21.9216)  Acc@5: 62.5000 (58.7687)  time: 0.2192  data: 0.0005  max mem: 2502
Test: [Task 1]  [ 880/1627]  eta: 0:02:43  Loss: 2.9440 (3.0913)  Acc@1: 18.7500 (21.8715)  Acc@5: 56.2500 (58.7259)  time: 0.2191  data: 0.0004  max mem: 2502
Test: [Task 1]  [ 890/1627]  eta: 0:02:41  Loss: 3.1506 (3.0913)  Acc@1: 18.7500 (21.8715)  Acc@5: 56.2500 (58.6770)  time: 0.2194  data: 0.0008  max mem: 2502
Test: [Task 1]  [ 900/1627]  eta: 0:02:39  Loss: 3.1773 (3.0920)  Acc@1: 18.7500 (21.8160)  Acc@5: 56.2500 (58.6917)  time: 0.2193  data: 0.0008  max mem: 2502
Test: [Task 1]  [ 910/1627]  eta: 0:02:37  Loss: 3.2437 (3.0920)  Acc@1: 12.5000 (21.8373)  Acc@5: 56.2500 (58.6855)  time: 0.2188  data: 0.0004  max mem: 2502
Test: [Task 1]  [ 920/1627]  eta: 0:02:35  Loss: 3.1534 (3.0920)  Acc@1: 18.7500 (21.8784)  Acc@5: 56.2500 (58.7201)  time: 0.2192  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 930/1627]  eta: 0:02:32  Loss: 2.9631 (3.0907)  Acc@1: 25.0000 (21.8985)  Acc@5: 68.7500 (58.8077)  time: 0.2203  data: 0.0007  max mem: 2502
Test: [Task 1]  [ 940/1627]  eta: 0:02:30  Loss: 3.0059 (3.0906)  Acc@1: 18.7500 (21.8717)  Acc@5: 62.5000 (58.8138)  time: 0.2197  data: 0.0007  max mem: 2502
Test: [Task 1]  [ 950/1627]  eta: 0:02:28  Loss: 3.0868 (3.0906)  Acc@1: 18.7500 (21.8783)  Acc@5: 56.2500 (58.7868)  time: 0.2189  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 960/1627]  eta: 0:02:26  Loss: 2.9729 (3.0890)  Acc@1: 18.7500 (21.9043)  Acc@5: 62.5000 (58.8775)  time: 0.2190  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 970/1627]  eta: 0:02:24  Loss: 2.8895 (3.0871)  Acc@1: 25.0000 (21.9361)  Acc@5: 68.7500 (58.9405)  time: 0.2189  data: 0.0004  max mem: 2502
Test: [Task 1]  [ 980/1627]  eta: 0:02:21  Loss: 2.9354 (3.0857)  Acc@1: 25.0000 (21.9738)  Acc@5: 62.5000 (58.9195)  time: 0.2188  data: 0.0004  max mem: 2502
Test: [Task 1]  [ 990/1627]  eta: 0:02:19  Loss: 3.1216 (3.0873)  Acc@1: 25.0000 (21.9412)  Acc@5: 56.2500 (58.8547)  time: 0.2182  data: 0.0003  max mem: 2502
Test: [Task 1]  [1000/1627]  eta: 0:02:17  Loss: 3.3105 (3.0886)  Acc@1: 18.7500 (21.9218)  Acc@5: 50.0000 (58.7912)  time: 0.2184  data: 0.0004  max mem: 2502
Test: [Task 1]  [1010/1627]  eta: 0:02:15  Loss: 3.1062 (3.0885)  Acc@1: 18.7500 (21.9028)  Acc@5: 56.2500 (58.7784)  time: 0.2184  data: 0.0003  max mem: 2502
Test: [Task 1]  [1020/1627]  eta: 0:02:13  Loss: 3.0893 (3.0885)  Acc@1: 18.7500 (21.9148)  Acc@5: 56.2500 (58.8026)  time: 0.2184  data: 0.0004  max mem: 2502
Test: [Task 1]  [1030/1627]  eta: 0:02:10  Loss: 2.9668 (3.0878)  Acc@1: 25.0000 (21.9326)  Acc@5: 62.5000 (58.8567)  time: 0.2189  data: 0.0006  max mem: 2502
Test: [Task 1]  [1040/1627]  eta: 0:02:08  Loss: 2.9716 (3.0877)  Acc@1: 18.7500 (21.9500)  Acc@5: 62.5000 (58.8917)  time: 0.2193  data: 0.0007  max mem: 2502
Test: [Task 1]  [1050/1627]  eta: 0:02:06  Loss: 3.0898 (3.0877)  Acc@1: 25.0000 (21.9612)  Acc@5: 56.2500 (58.9201)  time: 0.2190  data: 0.0005  max mem: 2502
Test: [Task 1]  [1060/1627]  eta: 0:02:04  Loss: 3.1223 (3.0876)  Acc@1: 25.0000 (21.9427)  Acc@5: 56.2500 (58.9303)  time: 0.2188  data: 0.0008  max mem: 2502
Test: [Task 1]  [1070/1627]  eta: 0:02:02  Loss: 3.1595 (3.0892)  Acc@1: 18.7500 (21.8954)  Acc@5: 56.2500 (58.8936)  time: 0.2185  data: 0.0008  max mem: 2502
Test: [Task 1]  [1080/1627]  eta: 0:02:00  Loss: 3.1773 (3.0894)  Acc@1: 18.7500 (21.9184)  Acc@5: 56.2500 (58.8749)  time: 0.2176  data: 0.0003  max mem: 2502
Test: [Task 1]  [1090/1627]  eta: 0:01:57  Loss: 3.0174 (3.0895)  Acc@1: 25.0000 (21.9638)  Acc@5: 56.2500 (58.8737)  time: 0.2175  data: 0.0003  max mem: 2502
Test: [Task 1]  [1100/1627]  eta: 0:01:55  Loss: 3.0174 (3.0896)  Acc@1: 18.7500 (21.9233)  Acc@5: 62.5000 (58.9124)  time: 0.2178  data: 0.0003  max mem: 2502
Test: [Task 1]  [1110/1627]  eta: 0:01:53  Loss: 3.0567 (3.0913)  Acc@1: 12.5000 (21.8609)  Acc@5: 56.2500 (58.8378)  time: 0.2183  data: 0.0004  max mem: 2502
Test: [Task 1]  [1120/1627]  eta: 0:01:51  Loss: 3.0470 (3.0905)  Acc@1: 18.7500 (21.8722)  Acc@5: 56.2500 (58.8704)  time: 0.2181  data: 0.0004  max mem: 2502
Test: [Task 1]  [1130/1627]  eta: 0:01:49  Loss: 3.0285 (3.0907)  Acc@1: 25.0000 (21.8943)  Acc@5: 62.5000 (58.8473)  time: 0.2179  data: 0.0004  max mem: 2502
Test: [Task 1]  [1140/1627]  eta: 0:01:46  Loss: 3.1432 (3.0920)  Acc@1: 18.7500 (21.8339)  Acc@5: 56.2500 (58.7916)  time: 0.2185  data: 0.0006  max mem: 2502
Test: [Task 1]  [1150/1627]  eta: 0:01:44  Loss: 3.1432 (3.0916)  Acc@1: 12.5000 (21.8451)  Acc@5: 50.0000 (58.7695)  time: 0.2189  data: 0.0005  max mem: 2502
Test: [Task 1]  [1160/1627]  eta: 0:01:42  Loss: 2.9413 (3.0911)  Acc@1: 18.7500 (21.8454)  Acc@5: 62.5000 (58.7694)  time: 0.2194  data: 0.0004  max mem: 2502
Test: [Task 1]  [1170/1627]  eta: 0:01:40  Loss: 3.1671 (3.0923)  Acc@1: 18.7500 (21.8029)  Acc@5: 56.2500 (58.7052)  time: 0.2200  data: 0.0009  max mem: 2502
Test: [Task 1]  [1180/1627]  eta: 0:01:38  Loss: 3.1610 (3.0929)  Acc@1: 18.7500 (21.7824)  Acc@5: 56.2500 (58.6897)  time: 0.2193  data: 0.0009  max mem: 2502
Test: [Task 1]  [1190/1627]  eta: 0:01:35  Loss: 3.0289 (3.0922)  Acc@1: 18.7500 (21.7884)  Acc@5: 62.5000 (58.7374)  time: 0.2182  data: 0.0004  max mem: 2502
Test: [Task 1]  [1200/1627]  eta: 0:01:33  Loss: 3.0119 (3.0924)  Acc@1: 18.7500 (21.7735)  Acc@5: 62.5000 (58.7219)  time: 0.2188  data: 0.0003  max mem: 2502
Test: [Task 1]  [1210/1627]  eta: 0:01:31  Loss: 3.0667 (3.0923)  Acc@1: 18.7500 (21.7692)  Acc@5: 56.2500 (58.7015)  time: 0.2191  data: 0.0004  max mem: 2502
Test: [Task 1]  [1220/1627]  eta: 0:01:29  Loss: 3.0243 (3.0919)  Acc@1: 18.7500 (21.7445)  Acc@5: 62.5000 (58.7838)  time: 0.2187  data: 0.0004  max mem: 2502
Test: [Task 1]  [1230/1627]  eta: 0:01:27  Loss: 3.0243 (3.0925)  Acc@1: 18.7500 (21.7608)  Acc@5: 62.5000 (58.7683)  time: 0.2189  data: 0.0004  max mem: 2502
Test: [Task 1]  [1240/1627]  eta: 0:01:24  Loss: 3.0140 (3.0915)  Acc@1: 18.7500 (21.7617)  Acc@5: 56.2500 (58.7732)  time: 0.2186  data: 0.0004  max mem: 2502
Test: [Task 1]  [1250/1627]  eta: 0:01:22  Loss: 3.0483 (3.0920)  Acc@1: 18.7500 (21.7626)  Acc@5: 56.2500 (58.7630)  time: 0.2186  data: 0.0003  max mem: 2502
Test: [Task 1]  [1260/1627]  eta: 0:01:20  Loss: 3.1528 (3.0919)  Acc@1: 18.7500 (21.7585)  Acc@5: 56.2500 (58.7530)  time: 0.2197  data: 0.0010  max mem: 2502
Test: [Task 1]  [1270/1627]  eta: 0:01:18  Loss: 3.1241 (3.0917)  Acc@1: 25.0000 (21.7594)  Acc@5: 56.2500 (58.7825)  time: 0.2195  data: 0.0010  max mem: 2502
Test: [Task 1]  [1280/1627]  eta: 0:01:16  Loss: 3.0469 (3.0911)  Acc@1: 18.7500 (21.7506)  Acc@5: 62.5000 (58.7822)  time: 0.2183  data: 0.0004  max mem: 2502
Test: [Task 1]  [1290/1627]  eta: 0:01:13  Loss: 2.8810 (3.0902)  Acc@1: 18.7500 (21.7951)  Acc@5: 56.2500 (58.7626)  time: 0.2183  data: 0.0003  max mem: 2502
Test: [Task 1]  [1300/1627]  eta: 0:01:11  Loss: 2.8810 (3.0888)  Acc@1: 18.7500 (21.8005)  Acc@5: 56.2500 (58.7865)  time: 0.2198  data: 0.0011  max mem: 2502
Test: [Task 1]  [1310/1627]  eta: 0:01:09  Loss: 2.9714 (3.0891)  Acc@1: 18.7500 (21.7820)  Acc@5: 56.2500 (58.7767)  time: 0.2199  data: 0.0011  max mem: 2502
Test: [Task 1]  [1320/1627]  eta: 0:01:07  Loss: 2.9667 (3.0876)  Acc@1: 25.0000 (21.8206)  Acc@5: 56.2500 (58.7954)  time: 0.2187  data: 0.0003  max mem: 2502
Test: [Task 1]  [1330/1627]  eta: 0:01:05  Loss: 3.0977 (3.0881)  Acc@1: 25.0000 (21.7881)  Acc@5: 50.0000 (58.7810)  time: 0.2186  data: 0.0003  max mem: 2502
Test: [Task 1]  [1340/1627]  eta: 0:01:02  Loss: 3.0977 (3.0877)  Acc@1: 25.0000 (21.8354)  Acc@5: 56.2500 (58.7901)  time: 0.2189  data: 0.0003  max mem: 2502
Test: [Task 1]  [1350/1627]  eta: 0:01:00  Loss: 3.1344 (3.0888)  Acc@1: 18.7500 (21.7894)  Acc@5: 62.5000 (58.7620)  time: 0.2192  data: 0.0004  max mem: 2502
Test: [Task 1]  [1360/1627]  eta: 0:00:58  Loss: 3.1195 (3.0878)  Acc@1: 12.5000 (21.7809)  Acc@5: 62.5000 (58.7757)  time: 0.2192  data: 0.0004  max mem: 2502
Test: [Task 1]  [1370/1627]  eta: 0:00:56  Loss: 3.0398 (3.0876)  Acc@1: 18.7500 (21.7861)  Acc@5: 56.2500 (58.7664)  time: 0.2193  data: 0.0003  max mem: 2502
Test: [Task 1]  [1380/1627]  eta: 0:00:54  Loss: 2.9404 (3.0856)  Acc@1: 25.0000 (21.8411)  Acc@5: 62.5000 (58.8342)  time: 0.2194  data: 0.0003  max mem: 2502
Test: [Task 1]  [1390/1627]  eta: 0:00:51  Loss: 2.9017 (3.0851)  Acc@1: 25.0000 (21.8728)  Acc@5: 62.5000 (58.8560)  time: 0.2196  data: 0.0003  max mem: 2502
Test: [Task 1]  [1400/1627]  eta: 0:00:49  Loss: 2.9715 (3.0853)  Acc@1: 25.0000 (21.8683)  Acc@5: 56.2500 (58.8374)  time: 0.2202  data: 0.0012  max mem: 2502
Test: [Task 1]  [1410/1627]  eta: 0:00:47  Loss: 2.9715 (3.0839)  Acc@1: 25.0000 (21.8861)  Acc@5: 56.2500 (58.8988)  time: 0.2198  data: 0.0011  max mem: 2502
Test: [Task 1]  [1420/1627]  eta: 0:00:45  Loss: 2.9467 (3.0834)  Acc@1: 25.0000 (21.8816)  Acc@5: 62.5000 (58.9022)  time: 0.2189  data: 0.0003  max mem: 2502
Test: [Task 1]  [1430/1627]  eta: 0:00:43  Loss: 3.0614 (3.0839)  Acc@1: 18.7500 (21.8947)  Acc@5: 62.5000 (58.8880)  time: 0.2189  data: 0.0003  max mem: 2502
Test: [Task 1]  [1440/1627]  eta: 0:00:41  Loss: 3.0434 (3.0837)  Acc@1: 18.7500 (21.9292)  Acc@5: 56.2500 (58.8697)  time: 0.2191  data: 0.0004  max mem: 2502
Test: [Task 1]  [1450/1627]  eta: 0:00:38  Loss: 3.0188 (3.0839)  Acc@1: 18.7500 (21.9418)  Acc@5: 62.5000 (58.8646)  time: 0.2191  data: 0.0004  max mem: 2502
Test: [Task 1]  [1460/1627]  eta: 0:00:36  Loss: 3.0338 (3.0845)  Acc@1: 12.5000 (21.8943)  Acc@5: 62.5000 (58.8638)  time: 0.2193  data: 0.0004  max mem: 2502
Test: [Task 1]  [1470/1627]  eta: 0:00:34  Loss: 3.1619 (3.0850)  Acc@1: 12.5000 (21.8856)  Acc@5: 56.2500 (58.8248)  time: 0.2192  data: 0.0004  max mem: 2502
Test: [Task 1]  [1480/1627]  eta: 0:00:32  Loss: 3.0564 (3.0844)  Acc@1: 18.7500 (21.8856)  Acc@5: 56.2500 (58.8243)  time: 0.2189  data: 0.0004  max mem: 2502
Test: [Task 1]  [1490/1627]  eta: 0:00:30  Loss: 3.0592 (3.0847)  Acc@1: 18.7500 (21.8729)  Acc@5: 56.2500 (58.8154)  time: 0.2188  data: 0.0004  max mem: 2502
Test: [Task 1]  [1500/1627]  eta: 0:00:27  Loss: 3.0592 (3.0839)  Acc@1: 25.0000 (21.9062)  Acc@5: 62.5000 (58.8483)  time: 0.2195  data: 0.0004  max mem: 2502
Test: [Task 1]  [1510/1627]  eta: 0:00:25  Loss: 3.0132 (3.0845)  Acc@1: 18.7500 (21.8812)  Acc@5: 56.2500 (58.8145)  time: 0.2193  data: 0.0004  max mem: 2502
Test: [Task 1]  [1520/1627]  eta: 0:00:23  Loss: 2.9646 (3.0834)  Acc@1: 18.7500 (21.8935)  Acc@5: 62.5000 (58.8716)  time: 0.2195  data: 0.0003  max mem: 2502
Test: [Task 1]  [1530/1627]  eta: 0:00:21  Loss: 2.9315 (3.0834)  Acc@1: 18.7500 (21.8689)  Acc@5: 62.5000 (58.8708)  time: 0.2198  data: 0.0004  max mem: 2502
Test: [Task 1]  [1540/1627]  eta: 0:00:19  Loss: 2.8939 (3.0827)  Acc@1: 25.0000 (21.9135)  Acc@5: 62.5000 (58.8498)  time: 0.2206  data: 0.0007  max mem: 2502
Test: [Task 1]  [1550/1627]  eta: 0:00:16  Loss: 2.8533 (3.0817)  Acc@1: 25.0000 (21.9375)  Acc@5: 62.5000 (58.8854)  time: 0.2206  data: 0.0008  max mem: 2502
Test: [Task 1]  [1560/1627]  eta: 0:00:14  Loss: 2.7685 (3.0794)  Acc@1: 31.2500 (22.0131)  Acc@5: 62.5000 (58.9526)  time: 0.2191  data: 0.0005  max mem: 2502
Test: [Task 1]  [1570/1627]  eta: 0:00:12  Loss: 2.8259 (3.0795)  Acc@1: 31.2500 (22.0123)  Acc@5: 62.5000 (58.9473)  time: 0.2199  data: 0.0004  max mem: 2502
Test: [Task 1]  [1580/1627]  eta: 0:00:10  Loss: 3.0353 (3.0784)  Acc@1: 25.0000 (22.0470)  Acc@5: 62.5000 (58.9777)  time: 0.2200  data: 0.0005  max mem: 2502
Test: [Task 1]  [1590/1627]  eta: 0:00:08  Loss: 3.0876 (3.0794)  Acc@1: 18.7500 (22.0105)  Acc@5: 62.5000 (58.9763)  time: 0.2196  data: 0.0005  max mem: 2502
Test: [Task 1]  [1600/1627]  eta: 0:00:05  Loss: 3.1476 (3.0796)  Acc@1: 18.7500 (22.0058)  Acc@5: 56.2500 (58.9671)  time: 0.2194  data: 0.0004  max mem: 2502
Test: [Task 1]  [1610/1627]  eta: 0:00:03  Loss: 2.9444 (3.0788)  Acc@1: 18.7500 (22.0088)  Acc@5: 62.5000 (59.0200)  time: 0.2191  data: 0.0004  max mem: 2502
Test: [Task 1]  [1620/1627]  eta: 0:00:01  Loss: 2.9720 (3.0783)  Acc@1: 25.0000 (22.0196)  Acc@5: 68.7500 (59.0646)  time: 0.2202  data: 0.0004  max mem: 2502
Test: [Task 1]  [1626/1627]  eta: 0:00:00  Loss: 2.9720 (3.0776)  Acc@1: 25.0000 (22.0229)  Acc@5: 62.5000 (59.0658)  time: 0.2199  data: 0.0004  max mem: 2502
Test: [Task 1] Total time: 0:05:57 (0.2195 s / it)
* Acc@1 22.023 Acc@5 59.066 loss 3.078
Test: [Task 2]  [  0/625]  eta: 0:05:53  Loss: 1.0142 (1.0142)  Acc@1: 75.0000 (75.0000)  Acc@5: 100.0000 (100.0000)  time: 0.5649  data: 0.3456  max mem: 2502
Test: [Task 2]  [ 10/625]  eta: 0:02:35  Loss: 1.8007 (1.7326)  Acc@1: 56.2500 (54.5455)  Acc@5: 87.5000 (84.0909)  time: 0.2521  data: 0.0318  max mem: 2502
Test: [Task 2]  [ 20/625]  eta: 0:02:23  Loss: 1.7566 (1.7353)  Acc@1: 50.0000 (53.2738)  Acc@5: 87.5000 (86.0119)  time: 0.2204  data: 0.0004  max mem: 2502
Test: [Task 2]  [ 30/625]  eta: 0:02:17  Loss: 1.7701 (1.7617)  Acc@1: 50.0000 (52.8226)  Acc@5: 81.2500 (84.4758)  time: 0.2198  data: 0.0005  max mem: 2502
Test: [Task 2]  [ 40/625]  eta: 0:02:13  Loss: 1.7928 (1.7765)  Acc@1: 50.0000 (52.2866)  Acc@5: 81.2500 (84.6037)  time: 0.2197  data: 0.0006  max mem: 2502
Test: [Task 2]  [ 50/625]  eta: 0:02:10  Loss: 1.7764 (1.8188)  Acc@1: 43.7500 (50.8578)  Acc@5: 81.2500 (84.0686)  time: 0.2199  data: 0.0004  max mem: 2502
Test: [Task 2]  [ 60/625]  eta: 0:02:07  Loss: 1.8826 (1.8071)  Acc@1: 50.0000 (51.8443)  Acc@5: 81.2500 (83.7090)  time: 0.2202  data: 0.0004  max mem: 2502
Test: [Task 2]  [ 70/625]  eta: 0:02:04  Loss: 1.8149 (1.8219)  Acc@1: 56.2500 (51.4965)  Acc@5: 87.5000 (83.4507)  time: 0.2205  data: 0.0008  max mem: 2502
Test: [Task 2]  [ 80/625]  eta: 0:02:02  Loss: 1.8698 (1.8298)  Acc@1: 56.2500 (51.6204)  Acc@5: 87.5000 (83.4877)  time: 0.2200  data: 0.0008  max mem: 2502
Test: [Task 2]  [ 90/625]  eta: 0:01:59  Loss: 1.7964 (1.8217)  Acc@1: 56.2500 (51.7857)  Acc@5: 87.5000 (83.7912)  time: 0.2195  data: 0.0004  max mem: 2502
Test: [Task 2]  [100/625]  eta: 0:01:57  Loss: 1.7768 (1.8359)  Acc@1: 50.0000 (51.1139)  Acc@5: 87.5000 (83.7871)  time: 0.2199  data: 0.0004  max mem: 2502
Test: [Task 2]  [110/625]  eta: 0:01:54  Loss: 1.7902 (1.8363)  Acc@1: 50.0000 (51.1261)  Acc@5: 87.5000 (84.2342)  time: 0.2197  data: 0.0004  max mem: 2502
Test: [Task 2]  [120/625]  eta: 0:01:52  Loss: 1.8143 (1.8373)  Acc@1: 50.0000 (51.3946)  Acc@5: 81.2500 (83.9876)  time: 0.2192  data: 0.0004  max mem: 2502
Test: [Task 2]  [130/625]  eta: 0:01:50  Loss: 1.8818 (1.8440)  Acc@1: 50.0000 (51.1450)  Acc@5: 81.2500 (83.9218)  time: 0.2201  data: 0.0004  max mem: 2502
Test: [Task 2]  [140/625]  eta: 0:01:47  Loss: 1.7232 (1.8457)  Acc@1: 50.0000 (51.4184)  Acc@5: 87.5000 (83.8652)  time: 0.2200  data: 0.0004  max mem: 2502
Test: [Task 2]  [150/625]  eta: 0:01:45  Loss: 1.8028 (1.8524)  Acc@1: 50.0000 (51.1589)  Acc@5: 81.2500 (83.6093)  time: 0.2190  data: 0.0003  max mem: 2502
Test: [Task 2]  [160/625]  eta: 0:01:43  Loss: 1.7258 (1.8475)  Acc@1: 56.2500 (51.4752)  Acc@5: 81.2500 (83.4627)  time: 0.2190  data: 0.0004  max mem: 2502
Test: [Task 2]  [170/625]  eta: 0:01:40  Loss: 1.7376 (1.8481)  Acc@1: 50.0000 (51.1696)  Acc@5: 81.2500 (83.5892)  time: 0.2203  data: 0.0010  max mem: 2502
Test: [Task 2]  [180/625]  eta: 0:01:38  Loss: 1.7858 (1.8473)  Acc@1: 50.0000 (51.1395)  Acc@5: 87.5000 (83.6326)  time: 0.2205  data: 0.0011  max mem: 2502
Test: [Task 2]  [190/625]  eta: 0:01:36  Loss: 1.8401 (1.8503)  Acc@1: 50.0000 (50.9162)  Acc@5: 81.2500 (83.2788)  time: 0.2201  data: 0.0005  max mem: 2502
Test: [Task 2]  [200/625]  eta: 0:01:34  Loss: 2.0167 (1.8536)  Acc@1: 43.7500 (50.6219)  Acc@5: 75.0000 (83.3022)  time: 0.2207  data: 0.0004  max mem: 2502
Test: [Task 2]  [210/625]  eta: 0:01:31  Loss: 1.8019 (1.8486)  Acc@1: 50.0000 (50.7405)  Acc@5: 81.2500 (83.3827)  time: 0.2203  data: 0.0004  max mem: 2502
Test: [Task 2]  [220/625]  eta: 0:01:29  Loss: 1.7262 (1.8475)  Acc@1: 50.0000 (50.7353)  Acc@5: 87.5000 (83.5690)  time: 0.2194  data: 0.0003  max mem: 2502
Test: [Task 2]  [230/625]  eta: 0:01:27  Loss: 1.7111 (1.8427)  Acc@1: 56.2500 (50.9470)  Acc@5: 87.5000 (83.6039)  time: 0.2194  data: 0.0003  max mem: 2502
Test: [Task 2]  [240/625]  eta: 0:01:25  Loss: 1.7760 (1.8436)  Acc@1: 56.2500 (50.9855)  Acc@5: 81.2500 (83.6618)  time: 0.2195  data: 0.0003  max mem: 2502
Test: [Task 2]  [250/625]  eta: 0:01:22  Loss: 1.8327 (1.8400)  Acc@1: 50.0000 (51.2450)  Acc@5: 81.2500 (83.5906)  time: 0.2192  data: 0.0004  max mem: 2502
Test: [Task 2]  [260/625]  eta: 0:01:20  Loss: 1.9519 (1.8448)  Acc@1: 50.0000 (51.2692)  Acc@5: 75.0000 (83.3812)  time: 0.2202  data: 0.0012  max mem: 2502
Test: [Task 2]  [270/625]  eta: 0:01:18  Loss: 1.8196 (1.8411)  Acc@1: 50.0000 (51.4068)  Acc@5: 81.2500 (83.4640)  time: 0.2202  data: 0.0012  max mem: 2502
Test: [Task 2]  [280/625]  eta: 0:01:16  Loss: 1.6984 (1.8386)  Acc@1: 50.0000 (51.6014)  Acc@5: 81.2500 (83.4964)  time: 0.2194  data: 0.0003  max mem: 2502
Test: [Task 2]  [290/625]  eta: 0:01:14  Loss: 1.8235 (1.8402)  Acc@1: 56.2500 (51.6323)  Acc@5: 81.2500 (83.4837)  time: 0.2193  data: 0.0003  max mem: 2502
Test: [Task 2]  [300/625]  eta: 0:01:11  Loss: 1.8437 (1.8414)  Acc@1: 56.2500 (51.6404)  Acc@5: 87.5000 (83.5963)  time: 0.2191  data: 0.0003  max mem: 2502
Test: [Task 2]  [310/625]  eta: 0:01:09  Loss: 1.9836 (1.8460)  Acc@1: 50.0000 (51.4268)  Acc@5: 87.5000 (83.5209)  time: 0.2190  data: 0.0003  max mem: 2502
Test: [Task 2]  [320/625]  eta: 0:01:07  Loss: 1.8763 (1.8389)  Acc@1: 50.0000 (51.5771)  Acc@5: 87.5000 (83.6643)  time: 0.2196  data: 0.0005  max mem: 2502
Test: [Task 2]  [330/625]  eta: 0:01:05  Loss: 1.6883 (1.8383)  Acc@1: 56.2500 (51.5483)  Acc@5: 81.2500 (83.5159)  time: 0.2197  data: 0.0005  max mem: 2502
Test: [Task 2]  [340/625]  eta: 0:01:02  Loss: 1.6808 (1.8287)  Acc@1: 56.2500 (52.0894)  Acc@5: 81.2500 (83.6327)  time: 0.2189  data: 0.0003  max mem: 2502
Test: [Task 2]  [350/625]  eta: 0:01:00  Loss: 1.5718 (1.8240)  Acc@1: 62.5000 (51.9943)  Acc@5: 87.5000 (83.7073)  time: 0.2189  data: 0.0003  max mem: 2502
Test: [Task 2]  [360/625]  eta: 0:00:58  Loss: 1.8817 (1.8326)  Acc@1: 43.7500 (51.8352)  Acc@5: 81.2500 (83.5007)  time: 0.2189  data: 0.0004  max mem: 2502
Test: [Task 2]  [370/625]  eta: 0:00:56  Loss: 1.5569 (1.8243)  Acc@1: 50.0000 (52.0553)  Acc@5: 87.5000 (83.6590)  time: 0.2186  data: 0.0004  max mem: 2502
Test: [Task 2]  [380/625]  eta: 0:00:54  Loss: 1.6170 (1.8241)  Acc@1: 56.2500 (52.1161)  Acc@5: 87.5000 (83.6450)  time: 0.2183  data: 0.0003  max mem: 2502
Test: [Task 2]  [390/625]  eta: 0:00:51  Loss: 1.6908 (1.8235)  Acc@1: 56.2500 (52.1419)  Acc@5: 81.2500 (83.5997)  time: 0.2188  data: 0.0003  max mem: 2502
Test: [Task 2]  [400/625]  eta: 0:00:49  Loss: 1.6034 (1.8167)  Acc@1: 56.2500 (52.2756)  Acc@5: 87.5000 (83.7438)  time: 0.2190  data: 0.0003  max mem: 2502
Test: [Task 2]  [410/625]  eta: 0:00:47  Loss: 1.5497 (1.8154)  Acc@1: 56.2500 (52.3571)  Acc@5: 87.5000 (83.8504)  time: 0.2188  data: 0.0003  max mem: 2502
Test: [Task 2]  [420/625]  eta: 0:00:45  Loss: 1.8451 (1.8217)  Acc@1: 50.0000 (52.1823)  Acc@5: 87.5000 (83.7292)  time: 0.2187  data: 0.0005  max mem: 2502
Test: [Task 2]  [430/625]  eta: 0:00:42  Loss: 1.8307 (1.8212)  Acc@1: 43.7500 (52.1027)  Acc@5: 81.2500 (83.8602)  time: 0.2181  data: 0.0005  max mem: 2502
Test: [Task 2]  [440/625]  eta: 0:00:40  Loss: 1.4131 (1.8105)  Acc@1: 56.2500 (52.3951)  Acc@5: 93.7500 (84.0703)  time: 0.2179  data: 0.0003  max mem: 2502
Test: [Task 2]  [450/625]  eta: 0:00:38  Loss: 1.3744 (1.8046)  Acc@1: 56.2500 (52.5360)  Acc@5: 93.7500 (84.2711)  time: 0.2181  data: 0.0003  max mem: 2502
Test: [Task 2]  [460/625]  eta: 0:00:36  Loss: 1.5311 (1.7998)  Acc@1: 56.2500 (52.6166)  Acc@5: 93.7500 (84.4360)  time: 0.2182  data: 0.0003  max mem: 2502
Test: [Task 2]  [470/625]  eta: 0:00:34  Loss: 1.5568 (1.8000)  Acc@1: 56.2500 (52.6539)  Acc@5: 87.5000 (84.3684)  time: 0.2192  data: 0.0007  max mem: 2502
Test: [Task 2]  [480/625]  eta: 0:00:31  Loss: 1.7369 (1.7992)  Acc@1: 56.2500 (52.6767)  Acc@5: 81.2500 (84.3685)  time: 0.2190  data: 0.0008  max mem: 2502
Test: [Task 2]  [490/625]  eta: 0:00:29  Loss: 1.7070 (1.7964)  Acc@1: 56.2500 (52.7495)  Acc@5: 87.5000 (84.3941)  time: 0.2184  data: 0.0004  max mem: 2502
Test: [Task 2]  [500/625]  eta: 0:00:27  Loss: 1.7681 (1.7992)  Acc@1: 50.0000 (52.7570)  Acc@5: 87.5000 (84.3313)  time: 0.2185  data: 0.0003  max mem: 2502
Test: [Task 2]  [510/625]  eta: 0:00:25  Loss: 1.9452 (1.8015)  Acc@1: 50.0000 (52.7153)  Acc@5: 81.2500 (84.3322)  time: 0.2184  data: 0.0003  max mem: 2502
Test: [Task 2]  [520/625]  eta: 0:00:23  Loss: 1.9794 (1.8089)  Acc@1: 43.7500 (52.4712)  Acc@5: 81.2500 (84.1891)  time: 0.2186  data: 0.0003  max mem: 2502
Test: [Task 2]  [530/625]  eta: 0:00:20  Loss: 1.9667 (1.8108)  Acc@1: 43.7500 (52.4364)  Acc@5: 81.2500 (84.1102)  time: 0.2182  data: 0.0006  max mem: 2502
Test: [Task 2]  [540/625]  eta: 0:00:18  Loss: 1.6643 (1.8061)  Acc@1: 56.2500 (52.6109)  Acc@5: 81.2500 (84.1497)  time: 0.2183  data: 0.0007  max mem: 2502
Test: [Task 2]  [550/625]  eta: 0:00:16  Loss: 1.4785 (1.7997)  Acc@1: 62.5000 (52.7223)  Acc@5: 87.5000 (84.2332)  time: 0.2180  data: 0.0004  max mem: 2502
Test: [Task 2]  [560/625]  eta: 0:00:14  Loss: 1.4511 (1.7941)  Acc@1: 62.5000 (52.9635)  Acc@5: 87.5000 (84.3360)  time: 0.2177  data: 0.0003  max mem: 2502
Test: [Task 2]  [570/625]  eta: 0:00:12  Loss: 1.5077 (1.7930)  Acc@1: 62.5000 (52.9991)  Acc@5: 87.5000 (84.3148)  time: 0.2178  data: 0.0003  max mem: 2502
Test: [Task 2]  [580/625]  eta: 0:00:09  Loss: 1.6561 (1.7910)  Acc@1: 56.2500 (53.0551)  Acc@5: 81.2500 (84.3158)  time: 0.2177  data: 0.0004  max mem: 2502
Test: [Task 2]  [590/625]  eta: 0:00:07  Loss: 1.5462 (1.7843)  Acc@1: 62.5000 (53.1726)  Acc@5: 87.5000 (84.4543)  time: 0.2176  data: 0.0003  max mem: 2502
Test: [Task 2]  [600/625]  eta: 0:00:05  Loss: 1.8173 (1.7878)  Acc@1: 50.0000 (53.0886)  Acc@5: 87.5000 (84.4530)  time: 0.2174  data: 0.0003  max mem: 2502
Test: [Task 2]  [610/625]  eta: 0:00:03  Loss: 2.0769 (1.7935)  Acc@1: 43.7500 (52.8846)  Acc@5: 81.2500 (84.4006)  time: 0.2173  data: 0.0003  max mem: 2502
Test: [Task 2]  [620/625]  eta: 0:00:01  Loss: 1.9065 (1.7920)  Acc@1: 43.7500 (52.8382)  Acc@5: 87.5000 (84.4002)  time: 0.2182  data: 0.0010  max mem: 2502
Test: [Task 2]  [624/625]  eta: 0:00:00  Loss: 1.7238 (1.7913)  Acc@1: 50.0000 (52.8700)  Acc@5: 87.5000 (84.4000)  time: 0.2184  data: 0.0010  max mem: 2502
Test: [Task 2] Total time: 0:02:17 (0.2199 s / it)
* Acc@1 52.870 Acc@5 84.400 loss 1.791
Test: [Task 3]  [  0/625]  eta: 0:06:32  Loss: 0.2333 (0.2333)  Acc@1: 93.7500 (93.7500)  Acc@5: 100.0000 (100.0000)  time: 0.6279  data: 0.4113  max mem: 2502
Test: [Task 3]  [ 10/625]  eta: 0:02:36  Loss: 0.2067 (0.2194)  Acc@1: 100.0000 (97.1591)  Acc@5: 100.0000 (99.4318)  time: 0.2552  data: 0.0377  max mem: 2502
Test: [Task 3]  [ 20/625]  eta: 0:02:24  Loss: 0.2067 (0.2404)  Acc@1: 100.0000 (96.7262)  Acc@5: 100.0000 (98.2143)  time: 0.2190  data: 0.0007  max mem: 2502
Test: [Task 3]  [ 30/625]  eta: 0:02:18  Loss: 0.1948 (0.2295)  Acc@1: 100.0000 (96.9758)  Acc@5: 100.0000 (98.5887)  time: 0.2193  data: 0.0006  max mem: 2502
Test: [Task 3]  [ 40/625]  eta: 0:02:13  Loss: 0.1414 (0.2069)  Acc@1: 100.0000 (97.4085)  Acc@5: 100.0000 (98.9329)  time: 0.2183  data: 0.0004  max mem: 2502
Test: [Task 3]  [ 50/625]  eta: 0:02:10  Loss: 0.1440 (0.2062)  Acc@1: 100.0000 (97.0588)  Acc@5: 100.0000 (99.1422)  time: 0.2187  data: 0.0004  max mem: 2502
Test: [Task 3]  [ 60/625]  eta: 0:02:07  Loss: 0.1900 (0.2007)  Acc@1: 93.7500 (97.0287)  Acc@5: 100.0000 (99.2828)  time: 0.2195  data: 0.0004  max mem: 2502
Test: [Task 3]  [ 70/625]  eta: 0:02:04  Loss: 0.1380 (0.1894)  Acc@1: 100.0000 (97.0951)  Acc@5: 100.0000 (99.3838)  time: 0.2192  data: 0.0004  max mem: 2502
Test: [Task 3]  [ 80/625]  eta: 0:02:02  Loss: 0.1061 (0.1924)  Acc@1: 100.0000 (96.9907)  Acc@5: 100.0000 (99.4599)  time: 0.2193  data: 0.0006  max mem: 2502
Test: [Task 3]  [ 90/625]  eta: 0:01:59  Loss: 0.1818 (0.1927)  Acc@1: 93.7500 (96.9780)  Acc@5: 100.0000 (99.4505)  time: 0.2190  data: 0.0006  max mem: 2502
Test: [Task 3]  [100/625]  eta: 0:01:57  Loss: 0.1560 (0.1921)  Acc@1: 100.0000 (97.0297)  Acc@5: 100.0000 (99.5050)  time: 0.2188  data: 0.0004  max mem: 2502
Test: [Task 3]  [110/625]  eta: 0:01:54  Loss: 0.1242 (0.1853)  Acc@1: 100.0000 (97.2973)  Acc@5: 100.0000 (99.5495)  time: 0.2192  data: 0.0004  max mem: 2502
Test: [Task 3]  [120/625]  eta: 0:01:52  Loss: 0.1502 (0.1880)  Acc@1: 100.0000 (97.2624)  Acc@5: 100.0000 (99.5351)  time: 0.2188  data: 0.0003  max mem: 2502
Test: [Task 3]  [130/625]  eta: 0:01:49  Loss: 0.1789 (0.1881)  Acc@1: 100.0000 (97.2805)  Acc@5: 100.0000 (99.5706)  time: 0.2189  data: 0.0003  max mem: 2502
Test: [Task 3]  [140/625]  eta: 0:01:47  Loss: 0.1764 (0.1970)  Acc@1: 100.0000 (96.9858)  Acc@5: 100.0000 (99.4238)  time: 0.2189  data: 0.0004  max mem: 2502
Test: [Task 3]  [150/625]  eta: 0:01:45  Loss: 0.2204 (0.2028)  Acc@1: 93.7500 (96.8957)  Acc@5: 100.0000 (99.3791)  time: 0.2198  data: 0.0007  max mem: 2502
Test: [Task 3]  [160/625]  eta: 0:01:43  Loss: 0.1503 (0.2040)  Acc@1: 93.7500 (96.8556)  Acc@5: 100.0000 (99.3012)  time: 0.2197  data: 0.0008  max mem: 2502
Test: [Task 3]  [170/625]  eta: 0:01:40  Loss: 0.1495 (0.2018)  Acc@1: 100.0000 (96.9664)  Acc@5: 100.0000 (99.3421)  time: 0.2194  data: 0.0005  max mem: 2502
Test: [Task 3]  [180/625]  eta: 0:01:38  Loss: 0.1708 (0.2037)  Acc@1: 100.0000 (96.9268)  Acc@5: 100.0000 (99.3439)  time: 0.2200  data: 0.0007  max mem: 2502
Test: [Task 3]  [190/625]  eta: 0:01:36  Loss: 0.1496 (0.2008)  Acc@1: 100.0000 (96.9895)  Acc@5: 100.0000 (99.3783)  time: 0.2193  data: 0.0007  max mem: 2502
Test: [Task 3]  [200/625]  eta: 0:01:34  Loss: 0.1480 (0.2030)  Acc@1: 100.0000 (96.9838)  Acc@5: 100.0000 (99.3781)  time: 0.2196  data: 0.0005  max mem: 2502
Test: [Task 3]  [210/625]  eta: 0:01:31  Loss: 0.2153 (0.2047)  Acc@1: 100.0000 (96.9491)  Acc@5: 100.0000 (99.3780)  time: 0.2205  data: 0.0009  max mem: 2502
Test: [Task 3]  [220/625]  eta: 0:01:29  Loss: 0.2042 (0.2062)  Acc@1: 93.7500 (96.8043)  Acc@5: 100.0000 (99.3778)  time: 0.2208  data: 0.0015  max mem: 2502
Test: [Task 3]  [230/625]  eta: 0:01:27  Loss: 0.2109 (0.2074)  Acc@1: 93.7500 (96.7532)  Acc@5: 100.0000 (99.3777)  time: 0.2199  data: 0.0011  max mem: 2502
Test: [Task 3]  [240/625]  eta: 0:01:25  Loss: 0.2109 (0.2104)  Acc@1: 93.7500 (96.6805)  Acc@5: 100.0000 (99.3517)  time: 0.2191  data: 0.0004  max mem: 2502
Test: [Task 3]  [250/625]  eta: 0:01:22  Loss: 0.1834 (0.2090)  Acc@1: 100.0000 (96.7380)  Acc@5: 100.0000 (99.3526)  time: 0.2192  data: 0.0003  max mem: 2502
Test: [Task 3]  [260/625]  eta: 0:01:20  Loss: 0.1379 (0.2072)  Acc@1: 100.0000 (96.7433)  Acc@5: 100.0000 (99.3534)  time: 0.2192  data: 0.0003  max mem: 2502
Test: [Task 3]  [270/625]  eta: 0:01:18  Loss: 0.1402 (0.2069)  Acc@1: 100.0000 (96.7482)  Acc@5: 100.0000 (99.3542)  time: 0.2210  data: 0.0013  max mem: 2502
Test: [Task 3]  [280/625]  eta: 0:01:16  Loss: 0.1540 (0.2056)  Acc@1: 100.0000 (96.7972)  Acc@5: 100.0000 (99.3772)  time: 0.2213  data: 0.0013  max mem: 2502
Test: [Task 3]  [290/625]  eta: 0:01:14  Loss: 0.1586 (0.2056)  Acc@1: 100.0000 (96.7998)  Acc@5: 100.0000 (99.3986)  time: 0.2205  data: 0.0011  max mem: 2502
Test: [Task 3]  [300/625]  eta: 0:01:11  Loss: 0.1726 (0.2066)  Acc@1: 93.7500 (96.7193)  Acc@5: 100.0000 (99.3978)  time: 0.2210  data: 0.0013  max mem: 2502
Test: [Task 3]  [310/625]  eta: 0:01:09  Loss: 0.1561 (0.2084)  Acc@1: 93.7500 (96.7042)  Acc@5: 100.0000 (99.3770)  time: 0.2203  data: 0.0006  max mem: 2502
Test: [Task 3]  [320/625]  eta: 0:01:07  Loss: 0.1413 (0.2072)  Acc@1: 100.0000 (96.7095)  Acc@5: 100.0000 (99.3575)  time: 0.2215  data: 0.0004  max mem: 2502
Test: [Task 3]  [330/625]  eta: 0:01:05  Loss: 0.1749 (0.2086)  Acc@1: 93.7500 (96.6767)  Acc@5: 100.0000 (99.3769)  time: 0.2213  data: 0.0004  max mem: 2502
Test: [Task 3]  [340/625]  eta: 0:01:02  Loss: 0.1467 (0.2068)  Acc@1: 100.0000 (96.7559)  Acc@5: 100.0000 (99.3952)  time: 0.2195  data: 0.0004  max mem: 2502
Test: [Task 3]  [350/625]  eta: 0:01:00  Loss: 0.1419 (0.2071)  Acc@1: 100.0000 (96.6880)  Acc@5: 100.0000 (99.4124)  time: 0.2200  data: 0.0004  max mem: 2502
Test: [Task 3]  [360/625]  eta: 0:00:58  Loss: 0.1419 (0.2072)  Acc@1: 93.7500 (96.6759)  Acc@5: 100.0000 (99.3940)  time: 0.2201  data: 0.0004  max mem: 2502
Test: [Task 3]  [370/625]  eta: 0:00:56  Loss: 0.1863 (0.2082)  Acc@1: 93.7500 (96.5970)  Acc@5: 100.0000 (99.4104)  time: 0.2198  data: 0.0004  max mem: 2502
Test: [Task 3]  [380/625]  eta: 0:00:54  Loss: 0.1666 (0.2068)  Acc@1: 93.7500 (96.6371)  Acc@5: 100.0000 (99.4259)  time: 0.2196  data: 0.0004  max mem: 2502
Test: [Task 3]  [390/625]  eta: 0:00:51  Loss: 0.1304 (0.2074)  Acc@1: 100.0000 (96.5793)  Acc@5: 100.0000 (99.4405)  time: 0.2196  data: 0.0004  max mem: 2502
Test: [Task 3]  [400/625]  eta: 0:00:49  Loss: 0.1304 (0.2061)  Acc@1: 100.0000 (96.6022)  Acc@5: 100.0000 (99.4389)  time: 0.2196  data: 0.0004  max mem: 2502
Test: [Task 3]  [410/625]  eta: 0:00:47  Loss: 0.1727 (0.2072)  Acc@1: 100.0000 (96.5937)  Acc@5: 100.0000 (99.4373)  time: 0.2194  data: 0.0004  max mem: 2502
Test: [Task 3]  [420/625]  eta: 0:00:45  Loss: 0.1945 (0.2073)  Acc@1: 93.7500 (96.6004)  Acc@5: 100.0000 (99.4359)  time: 0.2191  data: 0.0004  max mem: 2502
Test: [Task 3]  [430/625]  eta: 0:00:43  Loss: 0.2108 (0.2071)  Acc@1: 93.7500 (96.5922)  Acc@5: 100.0000 (99.4490)  time: 0.2185  data: 0.0003  max mem: 2502
Test: [Task 3]  [440/625]  eta: 0:00:40  Loss: 0.1888 (0.2078)  Acc@1: 100.0000 (96.5703)  Acc@5: 100.0000 (99.4331)  time: 0.2186  data: 0.0003  max mem: 2502
Test: [Task 3]  [450/625]  eta: 0:00:38  Loss: 0.1374 (0.2073)  Acc@1: 100.0000 (96.5909)  Acc@5: 100.0000 (99.4457)  time: 0.2184  data: 0.0004  max mem: 2502
Test: [Task 3]  [460/625]  eta: 0:00:36  Loss: 0.1442 (0.2065)  Acc@1: 100.0000 (96.5971)  Acc@5: 100.0000 (99.4441)  time: 0.2183  data: 0.0004  max mem: 2502
Test: [Task 3]  [470/625]  eta: 0:00:34  Loss: 0.1446 (0.2062)  Acc@1: 100.0000 (96.5764)  Acc@5: 100.0000 (99.4427)  time: 0.2188  data: 0.0004  max mem: 2502
Test: [Task 3]  [480/625]  eta: 0:00:31  Loss: 0.1718 (0.2061)  Acc@1: 100.0000 (96.5826)  Acc@5: 100.0000 (99.4543)  time: 0.2188  data: 0.0004  max mem: 2502
Test: [Task 3]  [490/625]  eta: 0:00:29  Loss: 0.1756 (0.2072)  Acc@1: 100.0000 (96.5377)  Acc@5: 100.0000 (99.4399)  time: 0.2187  data: 0.0004  max mem: 2502
Test: [Task 3]  [500/625]  eta: 0:00:27  Loss: 0.1656 (0.2064)  Acc@1: 100.0000 (96.5569)  Acc@5: 100.0000 (99.4511)  time: 0.2181  data: 0.0004  max mem: 2502
Test: [Task 3]  [510/625]  eta: 0:00:25  Loss: 0.1130 (0.2059)  Acc@1: 100.0000 (96.5264)  Acc@5: 100.0000 (99.4618)  time: 0.2180  data: 0.0003  max mem: 2502
Test: [Task 3]  [520/625]  eta: 0:00:23  Loss: 0.1974 (0.2072)  Acc@1: 93.7500 (96.4971)  Acc@5: 100.0000 (99.4482)  time: 0.2181  data: 0.0003  max mem: 2502
Test: [Task 3]  [530/625]  eta: 0:00:20  Loss: 0.2794 (0.2086)  Acc@1: 93.7500 (96.3983)  Acc@5: 100.0000 (99.4468)  time: 0.2198  data: 0.0004  max mem: 2502
Test: [Task 3]  [540/625]  eta: 0:00:18  Loss: 0.1895 (0.2099)  Acc@1: 93.7500 (96.3725)  Acc@5: 100.0000 (99.4455)  time: 0.2195  data: 0.0004  max mem: 2502
Test: [Task 3]  [550/625]  eta: 0:00:16  Loss: 0.2053 (0.2102)  Acc@1: 93.7500 (96.3816)  Acc@5: 100.0000 (99.4328)  time: 0.2178  data: 0.0004  max mem: 2502
Test: [Task 3]  [560/625]  eta: 0:00:14  Loss: 0.1701 (0.2105)  Acc@1: 93.7500 (96.3792)  Acc@5: 100.0000 (99.4430)  time: 0.2177  data: 0.0004  max mem: 2502
Test: [Task 3]  [570/625]  eta: 0:00:12  Loss: 0.1399 (0.2097)  Acc@1: 100.0000 (96.4098)  Acc@5: 100.0000 (99.4527)  time: 0.2180  data: 0.0005  max mem: 2502
Test: [Task 3]  [580/625]  eta: 0:00:09  Loss: 0.1724 (0.2116)  Acc@1: 93.7500 (96.3318)  Acc@5: 100.0000 (99.4514)  time: 0.2179  data: 0.0005  max mem: 2502
Test: [Task 3]  [590/625]  eta: 0:00:07  Loss: 0.1614 (0.2103)  Acc@1: 100.0000 (96.3832)  Acc@5: 100.0000 (99.4607)  time: 0.2171  data: 0.0003  max mem: 2502
Test: [Task 3]  [600/625]  eta: 0:00:05  Loss: 0.1514 (0.2102)  Acc@1: 100.0000 (96.3810)  Acc@5: 100.0000 (99.4488)  time: 0.2172  data: 0.0003  max mem: 2502
Test: [Task 3]  [610/625]  eta: 0:00:03  Loss: 0.1514 (0.2097)  Acc@1: 93.7500 (96.3789)  Acc@5: 100.0000 (99.4476)  time: 0.2187  data: 0.0013  max mem: 2502
Test: [Task 3]  [620/625]  eta: 0:00:01  Loss: 0.1664 (0.2103)  Acc@1: 93.7500 (96.3667)  Acc@5: 100.0000 (99.4465)  time: 0.2185  data: 0.0013  max mem: 2502
Test: [Task 3]  [624/625]  eta: 0:00:00  Loss: 0.1583 (0.2099)  Acc@1: 93.7500 (96.3700)  Acc@5: 100.0000 (99.4500)  time: 0.2185  data: 0.0013  max mem: 2502
Test: [Task 3] Total time: 0:02:17 (0.2201 s / it)
* Acc@1 96.370 Acc@5 99.450 loss 0.210
{0: {0: 24995, 1: 203, 2: 51, 3: 0, 4: 5985, 5: 943, 6: 0, 7: 19717, 8: 0, 9: 0, 10: 0, 11: 53, 12: 1, 13: 932, 14: 0, 15: 6079, 16: 327, 17: 0, 18: 24974, 19: 19868}, 1: {0: 9997, 1: 11, 2: 1, 3: 0, 4: 392, 5: 1, 6: 0, 7: 9589, 8: 1, 9: 4, 10: 1, 11: 1, 12: 0, 13: 1, 14: 0, 15: 403, 16: 2, 17: 1, 18: 9997, 19: 9598}, 2: {0: 1586, 1: 5, 2: 3632, 3: 5, 4: 5550, 5: 4931, 6: 0, 7: 4286, 8: 0, 9: 1, 10: 0, 11: 3634, 12: 1, 13: 4931, 14: 3, 15: 5552, 16: 14, 17: 2, 18: 1589, 19: 4278}}
[Average accuracy till task3]	Acc@1: 57.0876	Acc@5: 80.9719	Loss: 1.6929	Forgetting: 51.7942	Backward: -51.7942
Train: Epoch[1/5]  [   0/1142]  eta: 0:13:03  Lr: 0.001875  Loss: 1.5454  Acc@1: 6.2500 (6.2500)  Acc@5: 31.2500 (31.2500)  time: 0.6858  data: 0.3195  max mem: 2502
Train: Epoch[1/5]  [  10/1142]  eta: 0:07:07  Lr: 0.001875  Loss: 1.4340  Acc@1: 12.5000 (18.7500)  Acc@5: 68.7500 (62.5000)  time: 0.3779  data: 0.0294  max mem: 2502
Train: Epoch[1/5]  [  20/1142]  eta: 0:06:47  Lr: 0.001875  Loss: 1.1034  Acc@1: 31.2500 (26.1905)  Acc@5: 75.0000 (69.9405)  time: 0.3475  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [  30/1142]  eta: 0:06:38  Lr: 0.001875  Loss: 0.9923  Acc@1: 31.2500 (29.4355)  Acc@5: 81.2500 (75.6048)  time: 0.3475  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [  40/1142]  eta: 0:06:31  Lr: 0.001875  Loss: 0.9478  Acc@1: 37.5000 (32.7744)  Acc@5: 87.5000 (78.0488)  time: 0.3470  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [  50/1142]  eta: 0:06:26  Lr: 0.001875  Loss: 0.9081  Acc@1: 37.5000 (34.5588)  Acc@5: 87.5000 (80.1471)  time: 0.3468  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [  60/1142]  eta: 0:06:21  Lr: 0.001875  Loss: 0.7199  Acc@1: 43.7500 (36.5779)  Acc@5: 87.5000 (81.3525)  time: 0.3478  data: 0.0007  max mem: 2502
Train: Epoch[1/5]  [  70/1142]  eta: 0:06:17  Lr: 0.001875  Loss: 0.8622  Acc@1: 50.0000 (38.5563)  Acc@5: 87.5000 (82.1303)  time: 0.3488  data: 0.0007  max mem: 2502
Train: Epoch[1/5]  [  80/1142]  eta: 0:06:13  Lr: 0.001875  Loss: 1.1972  Acc@1: 50.0000 (39.8148)  Acc@5: 87.5000 (82.5617)  time: 0.3486  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [  90/1142]  eta: 0:06:10  Lr: 0.001875  Loss: 0.6342  Acc@1: 43.7500 (40.0412)  Acc@5: 87.5000 (83.0357)  time: 0.3494  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [ 100/1142]  eta: 0:06:06  Lr: 0.001875  Loss: 0.1473  Acc@1: 50.0000 (41.8317)  Acc@5: 87.5000 (83.7252)  time: 0.3501  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [ 110/1142]  eta: 0:06:02  Lr: 0.001875  Loss: 0.6554  Acc@1: 56.2500 (42.7928)  Acc@5: 87.5000 (84.2342)  time: 0.3507  data: 0.0011  max mem: 2502
Train: Epoch[1/5]  [ 120/1142]  eta: 0:05:59  Lr: 0.001875  Loss: 0.3482  Acc@1: 50.0000 (43.5434)  Acc@5: 87.5000 (84.5558)  time: 0.3502  data: 0.0011  max mem: 2502
Train: Epoch[1/5]  [ 130/1142]  eta: 0:05:55  Lr: 0.001875  Loss: 0.1907  Acc@1: 50.0000 (44.6088)  Acc@5: 93.7500 (85.2099)  time: 0.3493  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [ 140/1142]  eta: 0:05:51  Lr: 0.001875  Loss: 0.5276  Acc@1: 50.0000 (44.7252)  Acc@5: 93.7500 (85.3723)  time: 0.3500  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [ 150/1142]  eta: 0:05:48  Lr: 0.001875  Loss: -0.1061  Acc@1: 56.2500 (45.9851)  Acc@5: 87.5000 (85.7202)  time: 0.3500  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [ 160/1142]  eta: 0:05:44  Lr: 0.001875  Loss: 0.1282  Acc@1: 56.2500 (46.5839)  Acc@5: 93.7500 (86.2966)  time: 0.3514  data: 0.0011  max mem: 2502
Train: Epoch[1/5]  [ 170/1142]  eta: 0:05:41  Lr: 0.001875  Loss: -0.0099  Acc@1: 56.2500 (47.4050)  Acc@5: 93.7500 (86.6594)  time: 0.3514  data: 0.0012  max mem: 2502
Train: Epoch[1/5]  [ 180/1142]  eta: 0:05:37  Lr: 0.001875  Loss: 0.0846  Acc@1: 56.2500 (47.6519)  Acc@5: 87.5000 (86.7749)  time: 0.3503  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [ 190/1142]  eta: 0:05:34  Lr: 0.001875  Loss: 0.1435  Acc@1: 56.2500 (48.1021)  Acc@5: 87.5000 (87.0746)  time: 0.3504  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [ 200/1142]  eta: 0:05:30  Lr: 0.001875  Loss: -0.1303  Acc@1: 56.2500 (48.3520)  Acc@5: 93.7500 (87.3445)  time: 0.3511  data: 0.0007  max mem: 2502
Train: Epoch[1/5]  [ 210/1142]  eta: 0:05:27  Lr: 0.001875  Loss: -0.1728  Acc@1: 56.2500 (48.6967)  Acc@5: 93.7500 (87.4408)  time: 0.3520  data: 0.0008  max mem: 2502
Train: Epoch[1/5]  [ 220/1142]  eta: 0:05:23  Lr: 0.001875  Loss: -0.3198  Acc@1: 56.2500 (48.9819)  Acc@5: 87.5000 (87.5283)  time: 0.3511  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [ 230/1142]  eta: 0:05:20  Lr: 0.001875  Loss: 0.0446  Acc@1: 56.2500 (49.5130)  Acc@5: 87.5000 (87.6623)  time: 0.3506  data: 0.0006  max mem: 2502
Train: Epoch[1/5]  [ 240/1142]  eta: 0:05:16  Lr: 0.001875  Loss: 0.5236  Acc@1: 62.5000 (49.8703)  Acc@5: 87.5000 (87.8112)  time: 0.3508  data: 0.0006  max mem: 2502
Train: Epoch[1/5]  [ 250/1142]  eta: 0:05:13  Lr: 0.001875  Loss: 0.2548  Acc@1: 56.2500 (50.0000)  Acc@5: 93.7500 (87.9233)  time: 0.3512  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [ 260/1142]  eta: 0:05:09  Lr: 0.001875  Loss: 0.3258  Acc@1: 56.2500 (50.5268)  Acc@5: 93.7500 (88.0987)  time: 0.3514  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [ 270/1142]  eta: 0:05:06  Lr: 0.001875  Loss: 0.0641  Acc@1: 62.5000 (50.6227)  Acc@5: 93.7500 (88.1458)  time: 0.3521  data: 0.0006  max mem: 2502
Train: Epoch[1/5]  [ 280/1142]  eta: 0:05:02  Lr: 0.001875  Loss: -0.3327  Acc@1: 62.5000 (51.2456)  Acc@5: 93.7500 (88.3452)  time: 0.3527  data: 0.0006  max mem: 2502
Train: Epoch[1/5]  [ 290/1142]  eta: 0:04:59  Lr: 0.001875  Loss: -0.0973  Acc@1: 56.2500 (51.3960)  Acc@5: 93.7500 (88.4450)  time: 0.3516  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [ 300/1142]  eta: 0:04:55  Lr: 0.001875  Loss: 0.2204  Acc@1: 56.2500 (51.6196)  Acc@5: 93.7500 (88.6213)  time: 0.3517  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [ 310/1142]  eta: 0:04:52  Lr: 0.001875  Loss: -0.6700  Acc@1: 56.2500 (51.7886)  Acc@5: 93.7500 (88.5651)  time: 0.3523  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [ 320/1142]  eta: 0:04:48  Lr: 0.001875  Loss: -0.0194  Acc@1: 56.2500 (51.9470)  Acc@5: 93.7500 (88.7461)  time: 0.3519  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [ 330/1142]  eta: 0:04:45  Lr: 0.001875  Loss: 0.1524  Acc@1: 62.5000 (52.2281)  Acc@5: 93.7500 (88.8218)  time: 0.3525  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [ 340/1142]  eta: 0:04:41  Lr: 0.001875  Loss: 0.2279  Acc@1: 62.5000 (52.4194)  Acc@5: 93.7500 (88.9113)  time: 0.3517  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [ 350/1142]  eta: 0:04:38  Lr: 0.001875  Loss: 0.3149  Acc@1: 68.7500 (52.8312)  Acc@5: 93.7500 (88.9601)  time: 0.3507  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [ 360/1142]  eta: 0:04:34  Lr: 0.001875  Loss: -0.1016  Acc@1: 62.5000 (52.9778)  Acc@5: 93.7500 (89.0755)  time: 0.3519  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [ 370/1142]  eta: 0:04:31  Lr: 0.001875  Loss: 0.0942  Acc@1: 56.2500 (53.1166)  Acc@5: 87.5000 (89.0330)  time: 0.3525  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [ 380/1142]  eta: 0:04:27  Lr: 0.001875  Loss: -0.4378  Acc@1: 62.5000 (53.3465)  Acc@5: 87.5000 (89.1076)  time: 0.3521  data: 0.0012  max mem: 2502
Train: Epoch[1/5]  [ 390/1142]  eta: 0:04:24  Lr: 0.001875  Loss: -0.2584  Acc@1: 62.5000 (53.5965)  Acc@5: 93.7500 (89.2423)  time: 0.3516  data: 0.0012  max mem: 2502
Train: Epoch[1/5]  [ 400/1142]  eta: 0:04:20  Lr: 0.001875  Loss: -0.6082  Acc@1: 62.5000 (53.9277)  Acc@5: 93.7500 (89.3547)  time: 0.3512  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [ 410/1142]  eta: 0:04:17  Lr: 0.001875  Loss: 0.1932  Acc@1: 62.5000 (53.9538)  Acc@5: 93.7500 (89.3248)  time: 0.3510  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [ 420/1142]  eta: 0:04:13  Lr: 0.001875  Loss: -0.0836  Acc@1: 56.2500 (54.1865)  Acc@5: 93.7500 (89.4745)  time: 0.3510  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [ 430/1142]  eta: 0:04:10  Lr: 0.001875  Loss: 0.1582  Acc@1: 62.5000 (54.2488)  Acc@5: 93.7500 (89.4722)  time: 0.3514  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [ 440/1142]  eta: 0:04:06  Lr: 0.001875  Loss: -0.0892  Acc@1: 56.2500 (54.4359)  Acc@5: 87.5000 (89.5266)  time: 0.3516  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [ 450/1142]  eta: 0:04:03  Lr: 0.001875  Loss: -0.3878  Acc@1: 56.2500 (54.5593)  Acc@5: 93.7500 (89.6757)  time: 0.3508  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [ 460/1142]  eta: 0:03:59  Lr: 0.001875  Loss: -0.7350  Acc@1: 56.2500 (54.4604)  Acc@5: 93.7500 (89.7099)  time: 0.3513  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [ 470/1142]  eta: 0:03:56  Lr: 0.001875  Loss: 0.1122  Acc@1: 56.2500 (54.6444)  Acc@5: 87.5000 (89.7028)  time: 0.3513  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [ 480/1142]  eta: 0:03:52  Lr: 0.001875  Loss: -0.2410  Acc@1: 62.5000 (54.7817)  Acc@5: 93.7500 (89.8129)  time: 0.3509  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [ 490/1142]  eta: 0:03:49  Lr: 0.001875  Loss: -0.3884  Acc@1: 62.5000 (54.8371)  Acc@5: 93.7500 (89.8167)  time: 0.3516  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [ 500/1142]  eta: 0:03:45  Lr: 0.001875  Loss: -0.0789  Acc@1: 62.5000 (55.0150)  Acc@5: 93.7500 (89.9077)  time: 0.3498  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [ 510/1142]  eta: 0:03:41  Lr: 0.001875  Loss: -0.2317  Acc@1: 62.5000 (55.1981)  Acc@5: 93.7500 (89.9584)  time: 0.3483  data: 0.0006  max mem: 2502
Train: Epoch[1/5]  [ 520/1142]  eta: 0:03:38  Lr: 0.001875  Loss: 0.0728  Acc@1: 56.2500 (55.1823)  Acc@5: 93.7500 (89.9472)  time: 0.3485  data: 0.0007  max mem: 2502
Train: Epoch[1/5]  [ 530/1142]  eta: 0:03:34  Lr: 0.001875  Loss: 0.2202  Acc@1: 56.2500 (55.2848)  Acc@5: 93.7500 (90.0071)  time: 0.3485  data: 0.0006  max mem: 2502
Train: Epoch[1/5]  [ 540/1142]  eta: 0:03:31  Lr: 0.001875  Loss: -0.1936  Acc@1: 62.5000 (55.4298)  Acc@5: 93.7500 (90.0531)  time: 0.3483  data: 0.0006  max mem: 2502
Train: Epoch[1/5]  [ 550/1142]  eta: 0:03:27  Lr: 0.001875  Loss: -0.0019  Acc@1: 62.5000 (55.6148)  Acc@5: 93.7500 (90.1316)  time: 0.3480  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [ 560/1142]  eta: 0:03:24  Lr: 0.001875  Loss: -0.5001  Acc@1: 62.5000 (55.6818)  Acc@5: 93.7500 (90.0958)  time: 0.3487  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [ 570/1142]  eta: 0:03:20  Lr: 0.001875  Loss: -0.1279  Acc@1: 56.2500 (55.7684)  Acc@5: 93.7500 (90.1926)  time: 0.3494  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [ 580/1142]  eta: 0:03:17  Lr: 0.001875  Loss: 0.1998  Acc@1: 62.5000 (55.9273)  Acc@5: 93.7500 (90.2431)  time: 0.3498  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [ 590/1142]  eta: 0:03:13  Lr: 0.001875  Loss: 0.1018  Acc@1: 56.2500 (55.9010)  Acc@5: 93.7500 (90.1967)  time: 0.3496  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [ 600/1142]  eta: 0:03:10  Lr: 0.001875  Loss: -0.3708  Acc@1: 56.2500 (55.9380)  Acc@5: 87.5000 (90.2142)  time: 0.3485  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [ 610/1142]  eta: 0:03:06  Lr: 0.001875  Loss: -0.6283  Acc@1: 62.5000 (56.1784)  Acc@5: 93.7500 (90.3028)  time: 0.3491  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [ 620/1142]  eta: 0:03:03  Lr: 0.001875  Loss: -0.2762  Acc@1: 62.5000 (56.2399)  Acc@5: 93.7500 (90.3382)  time: 0.3498  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [ 630/1142]  eta: 0:02:59  Lr: 0.001875  Loss: -0.0589  Acc@1: 56.2500 (56.2698)  Acc@5: 87.5000 (90.2833)  time: 0.3493  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [ 640/1142]  eta: 0:02:56  Lr: 0.001875  Loss: -0.1681  Acc@1: 62.5000 (56.3573)  Acc@5: 93.7500 (90.3471)  time: 0.3486  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [ 650/1142]  eta: 0:02:52  Lr: 0.001875  Loss: -0.1731  Acc@1: 62.5000 (56.4516)  Acc@5: 93.7500 (90.3610)  time: 0.3496  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [ 660/1142]  eta: 0:02:49  Lr: 0.001875  Loss: -0.5949  Acc@1: 62.5000 (56.4958)  Acc@5: 93.7500 (90.4028)  time: 0.3503  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [ 670/1142]  eta: 0:02:45  Lr: 0.001875  Loss: -0.3848  Acc@1: 56.2500 (56.4922)  Acc@5: 93.7500 (90.4247)  time: 0.3495  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [ 680/1142]  eta: 0:02:42  Lr: 0.001875  Loss: -0.2590  Acc@1: 62.5000 (56.5804)  Acc@5: 93.7500 (90.4644)  time: 0.3498  data: 0.0011  max mem: 2502
Train: Epoch[1/5]  [ 690/1142]  eta: 0:02:38  Lr: 0.001875  Loss: -0.5412  Acc@1: 62.5000 (56.6661)  Acc@5: 93.7500 (90.4758)  time: 0.3492  data: 0.0011  max mem: 2502
Train: Epoch[1/5]  [ 700/1142]  eta: 0:02:34  Lr: 0.001875  Loss: -0.5990  Acc@1: 62.5000 (56.8028)  Acc@5: 93.7500 (90.4868)  time: 0.3484  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [ 710/1142]  eta: 0:02:31  Lr: 0.001875  Loss: -0.1406  Acc@1: 62.5000 (56.9093)  Acc@5: 87.5000 (90.5151)  time: 0.3487  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [ 720/1142]  eta: 0:02:27  Lr: 0.001875  Loss: 0.3197  Acc@1: 62.5000 (56.9782)  Acc@5: 87.5000 (90.5166)  time: 0.3491  data: 0.0003  max mem: 2502
Train: Epoch[1/5]  [ 730/1142]  eta: 0:02:24  Lr: 0.001875  Loss: 0.3072  Acc@1: 62.5000 (57.0451)  Acc@5: 93.7500 (90.5181)  time: 0.3496  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [ 740/1142]  eta: 0:02:20  Lr: 0.001875  Loss: -0.4747  Acc@1: 62.5000 (57.2031)  Acc@5: 93.7500 (90.5617)  time: 0.3498  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [ 750/1142]  eta: 0:02:17  Lr: 0.001875  Loss: -0.2951  Acc@1: 68.7500 (57.3319)  Acc@5: 93.7500 (90.6042)  time: 0.3504  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [ 760/1142]  eta: 0:02:13  Lr: 0.001875  Loss: -0.7364  Acc@1: 68.7500 (57.4162)  Acc@5: 93.7500 (90.6373)  time: 0.3504  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [ 770/1142]  eta: 0:02:10  Lr: 0.001875  Loss: -0.4243  Acc@1: 68.7500 (57.5389)  Acc@5: 93.7500 (90.6372)  time: 0.3495  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [ 780/1142]  eta: 0:02:06  Lr: 0.001875  Loss: -0.6183  Acc@1: 62.5000 (57.5304)  Acc@5: 93.7500 (90.6290)  time: 0.3491  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [ 790/1142]  eta: 0:02:03  Lr: 0.001875  Loss: -0.5543  Acc@1: 62.5000 (57.5853)  Acc@5: 93.7500 (90.6843)  time: 0.3493  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [ 800/1142]  eta: 0:01:59  Lr: 0.001875  Loss: -0.4741  Acc@1: 68.7500 (57.7091)  Acc@5: 100.0000 (90.7537)  time: 0.3492  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [ 810/1142]  eta: 0:01:56  Lr: 0.001875  Loss: -0.4256  Acc@1: 62.5000 (57.7142)  Acc@5: 93.7500 (90.8061)  time: 0.3502  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [ 820/1142]  eta: 0:01:52  Lr: 0.001875  Loss: -0.4403  Acc@1: 62.5000 (57.8410)  Acc@5: 93.7500 (90.8496)  time: 0.3507  data: 0.0008  max mem: 2502
Train: Epoch[1/5]  [ 830/1142]  eta: 0:01:49  Lr: 0.001875  Loss: -0.4249  Acc@1: 68.7500 (57.9122)  Acc@5: 93.7500 (90.8845)  time: 0.3495  data: 0.0008  max mem: 2502
Train: Epoch[1/5]  [ 840/1142]  eta: 0:01:45  Lr: 0.001875  Loss: -0.1940  Acc@1: 62.5000 (57.9741)  Acc@5: 93.7500 (90.9260)  time: 0.3493  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [ 850/1142]  eta: 0:01:42  Lr: 0.001875  Loss: -0.8964  Acc@1: 62.5000 (58.0347)  Acc@5: 93.7500 (90.9371)  time: 0.3500  data: 0.0012  max mem: 2502
Train: Epoch[1/5]  [ 860/1142]  eta: 0:01:38  Lr: 0.001875  Loss: -0.7318  Acc@1: 62.5000 (58.1736)  Acc@5: 93.7500 (91.0061)  time: 0.3500  data: 0.0012  max mem: 2502
Train: Epoch[1/5]  [ 870/1142]  eta: 0:01:35  Lr: 0.001875  Loss: -0.4214  Acc@1: 62.5000 (58.2520)  Acc@5: 93.7500 (91.0161)  time: 0.3491  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [ 880/1142]  eta: 0:01:31  Lr: 0.001875  Loss: -0.7894  Acc@1: 68.7500 (58.3925)  Acc@5: 93.7500 (91.0400)  time: 0.3488  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [ 890/1142]  eta: 0:01:28  Lr: 0.001875  Loss: -0.0503  Acc@1: 62.5000 (58.4315)  Acc@5: 93.7500 (91.0915)  time: 0.3490  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [ 900/1142]  eta: 0:01:24  Lr: 0.001875  Loss: -0.5570  Acc@1: 62.5000 (58.4212)  Acc@5: 93.7500 (91.1002)  time: 0.3487  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [ 910/1142]  eta: 0:01:21  Lr: 0.001875  Loss: -0.0959  Acc@1: 62.5000 (58.5414)  Acc@5: 93.7500 (91.1293)  time: 0.3479  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [ 920/1142]  eta: 0:01:17  Lr: 0.001875  Loss: -0.0073  Acc@1: 62.5000 (58.5844)  Acc@5: 93.7500 (91.1645)  time: 0.3483  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [ 930/1142]  eta: 0:01:14  Lr: 0.001875  Loss: -0.8185  Acc@1: 62.5000 (58.6399)  Acc@5: 93.7500 (91.1587)  time: 0.3498  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [ 940/1142]  eta: 0:01:10  Lr: 0.001875  Loss: -0.2328  Acc@1: 62.5000 (58.6876)  Acc@5: 87.5000 (91.1530)  time: 0.3497  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [ 950/1142]  eta: 0:01:07  Lr: 0.001875  Loss: -0.4984  Acc@1: 62.5000 (58.7014)  Acc@5: 93.7500 (91.1803)  time: 0.3485  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [ 960/1142]  eta: 0:01:03  Lr: 0.001875  Loss: -0.6031  Acc@1: 68.7500 (58.7734)  Acc@5: 93.7500 (91.1876)  time: 0.3488  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [ 970/1142]  eta: 0:01:00  Lr: 0.001875  Loss: -0.5323  Acc@1: 68.7500 (58.8311)  Acc@5: 93.7500 (91.2333)  time: 0.3489  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [ 980/1142]  eta: 0:00:56  Lr: 0.001875  Loss: -0.3000  Acc@1: 62.5000 (58.8303)  Acc@5: 93.7500 (91.2207)  time: 0.3483  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [ 990/1142]  eta: 0:00:53  Lr: 0.001875  Loss: -0.5022  Acc@1: 62.5000 (58.8988)  Acc@5: 93.7500 (91.2525)  time: 0.3480  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [1000/1142]  eta: 0:00:49  Lr: 0.001875  Loss: 0.1678  Acc@1: 62.5000 (58.9411)  Acc@5: 93.7500 (91.2650)  time: 0.3478  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [1010/1142]  eta: 0:00:46  Lr: 0.001875  Loss: -0.7502  Acc@1: 68.7500 (59.0381)  Acc@5: 93.7500 (91.3143)  time: 0.3477  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [1020/1142]  eta: 0:00:42  Lr: 0.001875  Loss: -0.4640  Acc@1: 68.7500 (59.0904)  Acc@5: 93.7500 (91.3198)  time: 0.3483  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [1030/1142]  eta: 0:00:39  Lr: 0.001875  Loss: -0.5030  Acc@1: 62.5000 (59.1719)  Acc@5: 93.7500 (91.3252)  time: 0.3484  data: 0.0006  max mem: 2502
Train: Epoch[1/5]  [1040/1142]  eta: 0:00:35  Lr: 0.001875  Loss: -0.6641  Acc@1: 62.5000 (59.2339)  Acc@5: 93.7500 (91.3305)  time: 0.3486  data: 0.0006  max mem: 2502
Train: Epoch[1/5]  [1050/1142]  eta: 0:00:32  Lr: 0.001875  Loss: -0.5610  Acc@1: 62.5000 (59.2650)  Acc@5: 93.7500 (91.3297)  time: 0.3493  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [1060/1142]  eta: 0:00:28  Lr: 0.001875  Loss: -0.4940  Acc@1: 62.5000 (59.3073)  Acc@5: 93.7500 (91.3289)  time: 0.3492  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [1070/1142]  eta: 0:00:25  Lr: 0.001875  Loss: -0.3223  Acc@1: 68.7500 (59.3896)  Acc@5: 93.7500 (91.3515)  time: 0.3496  data: 0.0006  max mem: 2502
Train: Epoch[1/5]  [1080/1142]  eta: 0:00:21  Lr: 0.001875  Loss: 0.2470  Acc@1: 62.5000 (59.3952)  Acc@5: 93.7500 (91.3795)  time: 0.3491  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [1090/1142]  eta: 0:00:18  Lr: 0.001875  Loss: -0.4931  Acc@1: 62.5000 (59.4294)  Acc@5: 93.7500 (91.4012)  time: 0.3488  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [1100/1142]  eta: 0:00:14  Lr: 0.001875  Loss: -0.4115  Acc@1: 62.5000 (59.5027)  Acc@5: 93.7500 (91.4396)  time: 0.3485  data: 0.0004  max mem: 2502
Train: Epoch[1/5]  [1110/1142]  eta: 0:00:11  Lr: 0.001875  Loss: -0.5145  Acc@1: 62.5000 (59.5241)  Acc@5: 93.7500 (91.4660)  time: 0.3484  data: 0.0005  max mem: 2502
Train: Epoch[1/5]  [1120/1142]  eta: 0:00:07  Lr: 0.001875  Loss: -0.8026  Acc@1: 75.0000 (59.6398)  Acc@5: 93.7500 (91.4752)  time: 0.3503  data: 0.0007  max mem: 2502
Train: Epoch[1/5]  [1130/1142]  eta: 0:00:04  Lr: 0.001875  Loss: -0.5161  Acc@1: 75.0000 (59.7425)  Acc@5: 93.7500 (91.5230)  time: 0.3503  data: 0.0009  max mem: 2502
Train: Epoch[1/5]  [1140/1142]  eta: 0:00:00  Lr: 0.001875  Loss: -0.5343  Acc@1: 68.7500 (59.7612)  Acc@5: 93.7500 (91.5480)  time: 0.3495  data: 0.0007  max mem: 2502
Train: Epoch[1/5]  [1141/1142]  eta: 0:00:00  Lr: 0.001875  Loss: -0.5115  Acc@1: 62.5000 (59.7536)  Acc@5: 93.7500 (91.5521)  time: 0.3421  data: 0.0007  max mem: 2502
Train: Epoch[1/5] Total time: 0:06:39 (0.3502 s / it)
Averaged stats: Lr: 0.001875  Loss: -0.5115  Acc@1: 62.5000 (59.7536)  Acc@5: 93.7500 (91.5521)
Train: Epoch[2/5]  [   0/1142]  eta: 0:12:49  Lr: 0.001875  Loss: -0.0832  Acc@1: 50.0000 (50.0000)  Acc@5: 87.5000 (87.5000)  time: 0.6734  data: 0.3255  max mem: 2502
Train: Epoch[2/5]  [  10/1142]  eta: 0:07:07  Lr: 0.001875  Loss: -0.5825  Acc@1: 68.7500 (64.2045)  Acc@5: 93.7500 (93.1818)  time: 0.3778  data: 0.0299  max mem: 2502
Train: Epoch[2/5]  [  20/1142]  eta: 0:06:48  Lr: 0.001875  Loss: -0.7435  Acc@1: 62.5000 (64.2857)  Acc@5: 93.7500 (92.8571)  time: 0.3483  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [  30/1142]  eta: 0:06:39  Lr: 0.001875  Loss: -0.5696  Acc@1: 68.7500 (64.9194)  Acc@5: 100.0000 (94.1532)  time: 0.3492  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [  40/1142]  eta: 0:06:33  Lr: 0.001875  Loss: -0.3595  Acc@1: 62.5000 (64.6341)  Acc@5: 93.7500 (93.1402)  time: 0.3497  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [  50/1142]  eta: 0:06:28  Lr: 0.001875  Loss: -0.6349  Acc@1: 62.5000 (65.0735)  Acc@5: 93.7500 (92.7696)  time: 0.3494  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [  60/1142]  eta: 0:06:23  Lr: 0.001875  Loss: -0.2265  Acc@1: 68.7500 (65.4713)  Acc@5: 93.7500 (93.4426)  time: 0.3491  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [  70/1142]  eta: 0:06:19  Lr: 0.001875  Loss: -0.1309  Acc@1: 68.7500 (65.9331)  Acc@5: 93.7500 (93.2218)  time: 0.3499  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [  80/1142]  eta: 0:06:15  Lr: 0.001875  Loss: -0.0612  Acc@1: 62.5000 (65.5093)  Acc@5: 93.7500 (93.1327)  time: 0.3502  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [  90/1142]  eta: 0:06:11  Lr: 0.001875  Loss: -0.2302  Acc@1: 68.7500 (65.8654)  Acc@5: 87.5000 (92.8571)  time: 0.3499  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [ 100/1142]  eta: 0:06:07  Lr: 0.001875  Loss: -0.0095  Acc@1: 68.7500 (65.5941)  Acc@5: 93.7500 (92.8218)  time: 0.3500  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [ 110/1142]  eta: 0:06:03  Lr: 0.001875  Loss: -0.4997  Acc@1: 68.7500 (65.7658)  Acc@5: 93.7500 (93.1869)  time: 0.3492  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [ 120/1142]  eta: 0:05:59  Lr: 0.001875  Loss: -0.2511  Acc@1: 68.7500 (65.9091)  Acc@5: 93.7500 (93.1302)  time: 0.3494  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [ 130/1142]  eta: 0:05:56  Lr: 0.001875  Loss: -0.6298  Acc@1: 68.7500 (66.1737)  Acc@5: 93.7500 (93.2729)  time: 0.3503  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [ 140/1142]  eta: 0:05:52  Lr: 0.001875  Loss: -0.1079  Acc@1: 68.7500 (66.1348)  Acc@5: 93.7500 (93.3954)  time: 0.3518  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [ 150/1142]  eta: 0:05:49  Lr: 0.001875  Loss: -0.5173  Acc@1: 68.7500 (66.5149)  Acc@5: 93.7500 (93.4189)  time: 0.3518  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [ 160/1142]  eta: 0:05:45  Lr: 0.001875  Loss: -0.4217  Acc@1: 68.7500 (66.2267)  Acc@5: 93.7500 (93.4783)  time: 0.3502  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [ 170/1142]  eta: 0:05:41  Lr: 0.001875  Loss: -0.0480  Acc@1: 56.2500 (65.8260)  Acc@5: 93.7500 (93.6038)  time: 0.3498  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [ 180/1142]  eta: 0:05:38  Lr: 0.001875  Loss: -0.1214  Acc@1: 62.5000 (65.3315)  Acc@5: 93.7500 (93.4392)  time: 0.3503  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [ 190/1142]  eta: 0:05:34  Lr: 0.001875  Loss: -0.2681  Acc@1: 62.5000 (65.1505)  Acc@5: 93.7500 (93.4228)  time: 0.3518  data: 0.0019  max mem: 2502
Train: Epoch[2/5]  [ 200/1142]  eta: 0:05:31  Lr: 0.001875  Loss: -0.6603  Acc@1: 62.5000 (64.9565)  Acc@5: 93.7500 (93.3769)  time: 0.3514  data: 0.0019  max mem: 2502
Train: Epoch[2/5]  [ 210/1142]  eta: 0:05:27  Lr: 0.001875  Loss: -0.5121  Acc@1: 62.5000 (64.8697)  Acc@5: 93.7500 (93.5130)  time: 0.3521  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [ 220/1142]  eta: 0:05:24  Lr: 0.001875  Loss: -0.0860  Acc@1: 68.7500 (64.8190)  Acc@5: 93.7500 (93.4106)  time: 0.3536  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [ 230/1142]  eta: 0:05:20  Lr: 0.001875  Loss: 0.2022  Acc@1: 62.5000 (64.5022)  Acc@5: 93.7500 (93.3171)  time: 0.3521  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [ 240/1142]  eta: 0:05:17  Lr: 0.001875  Loss: 0.1981  Acc@1: 56.2500 (64.1598)  Acc@5: 93.7500 (93.2832)  time: 0.3506  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [ 250/1142]  eta: 0:05:13  Lr: 0.001875  Loss: -0.3746  Acc@1: 62.5000 (64.0687)  Acc@5: 93.7500 (93.2022)  time: 0.3502  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [ 260/1142]  eta: 0:05:10  Lr: 0.001875  Loss: -0.2103  Acc@1: 62.5000 (63.9607)  Acc@5: 93.7500 (93.2471)  time: 0.3499  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [ 270/1142]  eta: 0:05:06  Lr: 0.001875  Loss: -0.0647  Acc@1: 62.5000 (63.9991)  Acc@5: 93.7500 (93.3118)  time: 0.3510  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [ 280/1142]  eta: 0:05:03  Lr: 0.001875  Loss: -0.1556  Acc@1: 62.5000 (63.8790)  Acc@5: 93.7500 (93.3719)  time: 0.3513  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [ 290/1142]  eta: 0:04:59  Lr: 0.001875  Loss: -0.6802  Acc@1: 62.5000 (64.1323)  Acc@5: 93.7500 (93.4064)  time: 0.3506  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [ 300/1142]  eta: 0:04:55  Lr: 0.001875  Loss: -0.5118  Acc@1: 68.7500 (64.2442)  Acc@5: 93.7500 (93.4178)  time: 0.3502  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [ 310/1142]  eta: 0:04:52  Lr: 0.001875  Loss: 0.0899  Acc@1: 68.7500 (64.3891)  Acc@5: 93.7500 (93.4084)  time: 0.3508  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [ 320/1142]  eta: 0:04:48  Lr: 0.001875  Loss: -0.6456  Acc@1: 68.7500 (64.4470)  Acc@5: 93.7500 (93.4190)  time: 0.3508  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [ 330/1142]  eta: 0:04:45  Lr: 0.001875  Loss: -0.4604  Acc@1: 62.5000 (64.3693)  Acc@5: 93.7500 (93.4856)  time: 0.3497  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [ 340/1142]  eta: 0:04:41  Lr: 0.001875  Loss: -0.5164  Acc@1: 62.5000 (64.3878)  Acc@5: 93.7500 (93.4934)  time: 0.3510  data: 0.0010  max mem: 2502
Train: Epoch[2/5]  [ 350/1142]  eta: 0:04:38  Lr: 0.001875  Loss: -0.4347  Acc@1: 68.7500 (64.4409)  Acc@5: 93.7500 (93.5185)  time: 0.3505  data: 0.0011  max mem: 2502
Train: Epoch[2/5]  [ 360/1142]  eta: 0:04:34  Lr: 0.001875  Loss: -0.2649  Acc@1: 62.5000 (64.3352)  Acc@5: 93.7500 (93.4557)  time: 0.3484  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [ 370/1142]  eta: 0:04:31  Lr: 0.001875  Loss: -0.4552  Acc@1: 62.5000 (64.3194)  Acc@5: 93.7500 (93.4636)  time: 0.3485  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [ 380/1142]  eta: 0:04:27  Lr: 0.001875  Loss: -0.4525  Acc@1: 68.7500 (64.3537)  Acc@5: 93.7500 (93.3891)  time: 0.3486  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [ 390/1142]  eta: 0:04:23  Lr: 0.001875  Loss: -0.9527  Acc@1: 75.0000 (64.6739)  Acc@5: 93.7500 (93.4463)  time: 0.3488  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [ 400/1142]  eta: 0:04:20  Lr: 0.001875  Loss: -0.6859  Acc@1: 68.7500 (64.5885)  Acc@5: 93.7500 (93.4071)  time: 0.3492  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [ 410/1142]  eta: 0:04:16  Lr: 0.001875  Loss: -0.6038  Acc@1: 68.7500 (64.7354)  Acc@5: 93.7500 (93.4611)  time: 0.3487  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [ 420/1142]  eta: 0:04:13  Lr: 0.001875  Loss: -0.4662  Acc@1: 68.7500 (64.7417)  Acc@5: 93.7500 (93.4382)  time: 0.3499  data: 0.0011  max mem: 2502
Train: Epoch[2/5]  [ 430/1142]  eta: 0:04:09  Lr: 0.001875  Loss: -0.7350  Acc@1: 68.7500 (64.8637)  Acc@5: 93.7500 (93.4020)  time: 0.3501  data: 0.0011  max mem: 2502
Train: Epoch[2/5]  [ 440/1142]  eta: 0:04:06  Lr: 0.001875  Loss: -0.3134  Acc@1: 68.7500 (64.8243)  Acc@5: 93.7500 (93.3673)  time: 0.3482  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [ 450/1142]  eta: 0:04:02  Lr: 0.001875  Loss: -0.7270  Acc@1: 68.7500 (64.8559)  Acc@5: 93.7500 (93.3481)  time: 0.3494  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [ 460/1142]  eta: 0:03:59  Lr: 0.001875  Loss: -0.0205  Acc@1: 56.2500 (64.7370)  Acc@5: 93.7500 (93.3433)  time: 0.3501  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [ 470/1142]  eta: 0:03:55  Lr: 0.001875  Loss: -0.0641  Acc@1: 56.2500 (64.6364)  Acc@5: 93.7500 (93.3254)  time: 0.3490  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [ 480/1142]  eta: 0:03:52  Lr: 0.001875  Loss: 0.3043  Acc@1: 62.5000 (64.6830)  Acc@5: 93.7500 (93.2952)  time: 0.3490  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [ 490/1142]  eta: 0:03:48  Lr: 0.001875  Loss: -0.3013  Acc@1: 68.7500 (64.8422)  Acc@5: 93.7500 (93.2918)  time: 0.3490  data: 0.0007  max mem: 2502
Train: Epoch[2/5]  [ 500/1142]  eta: 0:03:45  Lr: 0.001875  Loss: -0.3470  Acc@1: 68.7500 (65.0200)  Acc@5: 93.7500 (93.3009)  time: 0.3495  data: 0.0007  max mem: 2502
Train: Epoch[2/5]  [ 510/1142]  eta: 0:03:41  Lr: 0.001875  Loss: -0.3887  Acc@1: 68.7500 (65.0807)  Acc@5: 93.7500 (93.3219)  time: 0.3492  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [ 520/1142]  eta: 0:03:38  Lr: 0.001875  Loss: -0.6479  Acc@1: 68.7500 (65.0672)  Acc@5: 100.0000 (93.4021)  time: 0.3482  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [ 530/1142]  eta: 0:03:34  Lr: 0.001875  Loss: -0.2698  Acc@1: 68.7500 (65.0777)  Acc@5: 100.0000 (93.4322)  time: 0.3490  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [ 540/1142]  eta: 0:03:31  Lr: 0.001875  Loss: -0.5290  Acc@1: 62.5000 (65.0762)  Acc@5: 93.7500 (93.4265)  time: 0.3497  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [ 550/1142]  eta: 0:03:27  Lr: 0.001875  Loss: -0.1137  Acc@1: 62.5000 (65.1429)  Acc@5: 93.7500 (93.4891)  time: 0.3492  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [ 560/1142]  eta: 0:03:23  Lr: 0.001875  Loss: -0.2056  Acc@1: 68.7500 (65.1627)  Acc@5: 100.0000 (93.5383)  time: 0.3480  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [ 570/1142]  eta: 0:03:20  Lr: 0.001875  Loss: -0.9856  Acc@1: 75.0000 (65.3021)  Acc@5: 100.0000 (93.5749)  time: 0.3479  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [ 580/1142]  eta: 0:03:16  Lr: 0.001875  Loss: -0.5399  Acc@1: 68.7500 (65.3399)  Acc@5: 93.7500 (93.5564)  time: 0.3486  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [ 590/1142]  eta: 0:03:13  Lr: 0.001875  Loss: -0.2524  Acc@1: 68.7500 (65.3553)  Acc@5: 93.7500 (93.6125)  time: 0.3483  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [ 600/1142]  eta: 0:03:09  Lr: 0.001875  Loss: 0.2758  Acc@1: 68.7500 (65.3702)  Acc@5: 93.7500 (93.6356)  time: 0.3477  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [ 610/1142]  eta: 0:03:06  Lr: 0.001875  Loss: -0.7257  Acc@1: 68.7500 (65.3846)  Acc@5: 93.7500 (93.6477)  time: 0.3473  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [ 620/1142]  eta: 0:03:02  Lr: 0.001875  Loss: -0.0890  Acc@1: 62.5000 (65.4086)  Acc@5: 93.7500 (93.6494)  time: 0.3476  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [ 630/1142]  eta: 0:02:59  Lr: 0.001875  Loss: -0.6811  Acc@1: 68.7500 (65.5111)  Acc@5: 93.7500 (93.6609)  time: 0.3484  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [ 640/1142]  eta: 0:02:55  Lr: 0.001875  Loss: -0.2533  Acc@1: 68.7500 (65.6006)  Acc@5: 93.7500 (93.6427)  time: 0.3481  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [ 650/1142]  eta: 0:02:52  Lr: 0.001875  Loss: -0.2848  Acc@1: 68.7500 (65.6682)  Acc@5: 93.7500 (93.6828)  time: 0.3484  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [ 660/1142]  eta: 0:02:48  Lr: 0.001875  Loss: -0.4189  Acc@1: 68.7500 (65.5730)  Acc@5: 93.7500 (93.6838)  time: 0.3490  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [ 670/1142]  eta: 0:02:45  Lr: 0.001875  Loss: 0.0573  Acc@1: 62.5000 (65.6297)  Acc@5: 93.7500 (93.6755)  time: 0.3491  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [ 680/1142]  eta: 0:02:41  Lr: 0.001875  Loss: -0.7940  Acc@1: 68.7500 (65.6571)  Acc@5: 93.7500 (93.6766)  time: 0.3494  data: 0.0010  max mem: 2502
Train: Epoch[2/5]  [ 690/1142]  eta: 0:02:38  Lr: 0.001875  Loss: -0.4371  Acc@1: 68.7500 (65.6657)  Acc@5: 93.7500 (93.7138)  time: 0.3493  data: 0.0010  max mem: 2502
Train: Epoch[2/5]  [ 700/1142]  eta: 0:02:34  Lr: 0.001875  Loss: -0.6790  Acc@1: 68.7500 (65.7186)  Acc@5: 100.0000 (93.7678)  time: 0.3491  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [ 710/1142]  eta: 0:02:31  Lr: 0.001875  Loss: -0.6729  Acc@1: 68.7500 (65.7700)  Acc@5: 93.7500 (93.7412)  time: 0.3491  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [ 720/1142]  eta: 0:02:27  Lr: 0.001875  Loss: -0.2070  Acc@1: 68.7500 (65.8027)  Acc@5: 93.7500 (93.6720)  time: 0.3501  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [ 730/1142]  eta: 0:02:24  Lr: 0.001875  Loss: -1.1009  Acc@1: 68.7500 (65.8430)  Acc@5: 87.5000 (93.6645)  time: 0.3505  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [ 740/1142]  eta: 0:02:20  Lr: 0.001875  Loss: -0.5535  Acc@1: 68.7500 (65.8738)  Acc@5: 93.7500 (93.6657)  time: 0.3495  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [ 750/1142]  eta: 0:02:17  Lr: 0.001875  Loss: -0.6332  Acc@1: 68.7500 (65.8539)  Acc@5: 93.7500 (93.6252)  time: 0.3498  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [ 760/1142]  eta: 0:02:13  Lr: 0.001875  Loss: -0.4332  Acc@1: 68.7500 (65.9494)  Acc@5: 93.7500 (93.6514)  time: 0.3505  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [ 770/1142]  eta: 0:02:10  Lr: 0.001875  Loss: -0.4700  Acc@1: 62.5000 (65.7993)  Acc@5: 93.7500 (93.6365)  time: 0.3504  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [ 780/1142]  eta: 0:02:06  Lr: 0.001875  Loss: -0.6963  Acc@1: 62.5000 (65.8851)  Acc@5: 93.7500 (93.6860)  time: 0.3502  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [ 790/1142]  eta: 0:02:03  Lr: 0.001875  Loss: -0.6971  Acc@1: 68.7500 (65.8976)  Acc@5: 93.7500 (93.7026)  time: 0.3499  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [ 800/1142]  eta: 0:01:59  Lr: 0.001875  Loss: -0.3591  Acc@1: 68.7500 (65.8708)  Acc@5: 93.7500 (93.6720)  time: 0.3497  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [ 810/1142]  eta: 0:01:56  Lr: 0.001875  Loss: -0.2439  Acc@1: 62.5000 (65.8446)  Acc@5: 93.7500 (93.6652)  time: 0.3499  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [ 820/1142]  eta: 0:01:52  Lr: 0.001875  Loss: -0.6208  Acc@1: 62.5000 (65.8343)  Acc@5: 93.7500 (93.6815)  time: 0.3500  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [ 830/1142]  eta: 0:01:49  Lr: 0.001875  Loss: -0.9374  Acc@1: 68.7500 (65.8619)  Acc@5: 93.7500 (93.7124)  time: 0.3494  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [ 840/1142]  eta: 0:01:45  Lr: 0.001875  Loss: -0.6091  Acc@1: 62.5000 (65.8294)  Acc@5: 93.7500 (93.7277)  time: 0.3496  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [ 850/1142]  eta: 0:01:42  Lr: 0.001875  Loss: -0.3477  Acc@1: 62.5000 (65.8784)  Acc@5: 93.7500 (93.7133)  time: 0.3501  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [ 860/1142]  eta: 0:01:38  Lr: 0.001875  Loss: -0.0840  Acc@1: 62.5000 (65.8827)  Acc@5: 93.7500 (93.7064)  time: 0.3503  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [ 870/1142]  eta: 0:01:35  Lr: 0.001875  Loss: -0.6897  Acc@1: 62.5000 (65.8941)  Acc@5: 93.7500 (93.6926)  time: 0.3518  data: 0.0012  max mem: 2502
Train: Epoch[2/5]  [ 880/1142]  eta: 0:01:31  Lr: 0.001875  Loss: -0.7059  Acc@1: 62.5000 (65.9123)  Acc@5: 93.7500 (93.6720)  time: 0.3509  data: 0.0011  max mem: 2502
Train: Epoch[2/5]  [ 890/1142]  eta: 0:01:28  Lr: 0.001875  Loss: -0.4582  Acc@1: 68.7500 (65.9512)  Acc@5: 93.7500 (93.6939)  time: 0.3500  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [ 900/1142]  eta: 0:01:24  Lr: 0.001875  Loss: 0.1099  Acc@1: 62.5000 (65.8713)  Acc@5: 93.7500 (93.6598)  time: 0.3505  data: 0.0007  max mem: 2502
Train: Epoch[2/5]  [ 910/1142]  eta: 0:01:21  Lr: 0.001875  Loss: 0.0630  Acc@1: 62.5000 (65.8617)  Acc@5: 87.5000 (93.6059)  time: 0.3496  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [ 920/1142]  eta: 0:01:17  Lr: 0.001875  Loss: -0.2637  Acc@1: 68.7500 (65.8795)  Acc@5: 93.7500 (93.6211)  time: 0.3495  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [ 930/1142]  eta: 0:01:14  Lr: 0.001875  Loss: -0.2145  Acc@1: 68.7500 (65.8835)  Acc@5: 93.7500 (93.6157)  time: 0.3492  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [ 940/1142]  eta: 0:01:10  Lr: 0.001875  Loss: -1.0089  Acc@1: 68.7500 (65.9338)  Acc@5: 93.7500 (93.6238)  time: 0.3492  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [ 950/1142]  eta: 0:01:07  Lr: 0.001875  Loss: -0.4400  Acc@1: 68.7500 (65.9503)  Acc@5: 93.7500 (93.6186)  time: 0.3487  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [ 960/1142]  eta: 0:01:03  Lr: 0.001875  Loss: -0.3888  Acc@1: 68.7500 (65.9990)  Acc@5: 93.7500 (93.6069)  time: 0.3491  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [ 970/1142]  eta: 0:01:00  Lr: 0.001875  Loss: -0.6433  Acc@1: 68.7500 (66.0209)  Acc@5: 93.7500 (93.5955)  time: 0.3491  data: 0.0003  max mem: 2502
Train: Epoch[2/5]  [ 980/1142]  eta: 0:00:56  Lr: 0.001875  Loss: -0.2504  Acc@1: 68.7500 (66.0869)  Acc@5: 93.7500 (93.6098)  time: 0.3488  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [ 990/1142]  eta: 0:00:53  Lr: 0.001875  Loss: -0.6803  Acc@1: 68.7500 (66.0759)  Acc@5: 93.7500 (93.6302)  time: 0.3493  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [1000/1142]  eta: 0:00:49  Lr: 0.001875  Loss: -0.6487  Acc@1: 62.5000 (66.0215)  Acc@5: 93.7500 (93.6563)  time: 0.3487  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [1010/1142]  eta: 0:00:46  Lr: 0.001875  Loss: -0.4054  Acc@1: 62.5000 (65.9619)  Acc@5: 93.7500 (93.6573)  time: 0.3488  data: 0.0006  max mem: 2502
Train: Epoch[2/5]  [1020/1142]  eta: 0:00:42  Lr: 0.001875  Loss: -0.8480  Acc@1: 62.5000 (65.9586)  Acc@5: 93.7500 (93.6704)  time: 0.3493  data: 0.0007  max mem: 2502
Train: Epoch[2/5]  [1030/1142]  eta: 0:00:39  Lr: 0.001875  Loss: -0.3855  Acc@1: 68.7500 (66.0099)  Acc@5: 100.0000 (93.6894)  time: 0.3485  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [1040/1142]  eta: 0:00:35  Lr: 0.001875  Loss: -1.0289  Acc@1: 68.7500 (66.0423)  Acc@5: 93.7500 (93.7080)  time: 0.3490  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [1050/1142]  eta: 0:00:32  Lr: 0.001875  Loss: -0.2524  Acc@1: 62.5000 (65.9848)  Acc@5: 93.7500 (93.7024)  time: 0.3500  data: 0.0012  max mem: 2502
Train: Epoch[2/5]  [1060/1142]  eta: 0:00:28  Lr: 0.001875  Loss: -0.4001  Acc@1: 62.5000 (66.0285)  Acc@5: 93.7500 (93.7088)  time: 0.3507  data: 0.0012  max mem: 2502
Train: Epoch[2/5]  [1070/1142]  eta: 0:00:25  Lr: 0.001875  Loss: -0.5389  Acc@1: 75.0000 (66.0831)  Acc@5: 93.7500 (93.7150)  time: 0.3501  data: 0.0005  max mem: 2502
Train: Epoch[2/5]  [1080/1142]  eta: 0:00:21  Lr: 0.001875  Loss: -0.5080  Acc@1: 68.7500 (66.0615)  Acc@5: 93.7500 (93.7327)  time: 0.3484  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [1090/1142]  eta: 0:00:18  Lr: 0.001875  Loss: -0.8990  Acc@1: 62.5000 (66.1205)  Acc@5: 93.7500 (93.7328)  time: 0.3480  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [1100/1142]  eta: 0:00:14  Lr: 0.001875  Loss: -0.3106  Acc@1: 62.5000 (66.1104)  Acc@5: 93.7500 (93.7443)  time: 0.3484  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [1110/1142]  eta: 0:00:11  Lr: 0.001875  Loss: -0.3648  Acc@1: 62.5000 (66.0779)  Acc@5: 93.7500 (93.7613)  time: 0.3492  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [1120/1142]  eta: 0:00:07  Lr: 0.001875  Loss: -0.1875  Acc@1: 68.7500 (66.0961)  Acc@5: 93.7500 (93.7556)  time: 0.3493  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [1130/1142]  eta: 0:00:04  Lr: 0.001875  Loss: -0.3780  Acc@1: 68.7500 (66.0588)  Acc@5: 93.7500 (93.7611)  time: 0.3496  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [1140/1142]  eta: 0:00:00  Lr: 0.001875  Loss: -0.2376  Acc@1: 62.5000 (66.0331)  Acc@5: 93.7500 (93.7774)  time: 0.3497  data: 0.0004  max mem: 2502
Train: Epoch[2/5]  [1141/1142]  eta: 0:00:00  Lr: 0.001875  Loss: -0.7980  Acc@1: 62.5000 (66.0389)  Acc@5: 93.7500 (93.7805)  time: 0.3419  data: 0.0004  max mem: 2502
Train: Epoch[2/5] Total time: 0:06:39 (0.3500 s / it)
Averaged stats: Lr: 0.001875  Loss: -0.7980  Acc@1: 62.5000 (66.0389)  Acc@5: 93.7500 (93.7805)
Train: Epoch[3/5]  [   0/1142]  eta: 0:12:45  Lr: 0.001875  Loss: -0.4181  Acc@1: 62.5000 (62.5000)  Acc@5: 93.7500 (93.7500)  time: 0.6700  data: 0.3204  max mem: 2502
Train: Epoch[3/5]  [  10/1142]  eta: 0:07:08  Lr: 0.001875  Loss: -0.4929  Acc@1: 68.7500 (68.1818)  Acc@5: 93.7500 (93.1818)  time: 0.3782  data: 0.0295  max mem: 2502
Train: Epoch[3/5]  [  20/1142]  eta: 0:06:49  Lr: 0.001875  Loss: -0.3898  Acc@1: 68.7500 (68.7500)  Acc@5: 93.7500 (93.4524)  time: 0.3493  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [  30/1142]  eta: 0:06:39  Lr: 0.001875  Loss: -0.5520  Acc@1: 68.7500 (69.1532)  Acc@5: 93.7500 (94.7581)  time: 0.3490  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [  40/1142]  eta: 0:06:33  Lr: 0.001875  Loss: -0.2501  Acc@1: 68.7500 (68.5976)  Acc@5: 93.7500 (94.5122)  time: 0.3485  data: 0.0007  max mem: 2502
Train: Epoch[3/5]  [  50/1142]  eta: 0:06:27  Lr: 0.001875  Loss: -0.3470  Acc@1: 62.5000 (67.4020)  Acc@5: 93.7500 (94.6078)  time: 0.3486  data: 0.0007  max mem: 2502
Train: Epoch[3/5]  [  60/1142]  eta: 0:06:23  Lr: 0.001875  Loss: -0.5136  Acc@1: 62.5000 (67.4180)  Acc@5: 93.7500 (94.4672)  time: 0.3491  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [  70/1142]  eta: 0:06:18  Lr: 0.001875  Loss: -0.8334  Acc@1: 68.7500 (68.3099)  Acc@5: 93.7500 (94.5423)  time: 0.3491  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [  80/1142]  eta: 0:06:14  Lr: 0.001875  Loss: -0.2826  Acc@1: 68.7500 (67.9784)  Acc@5: 93.7500 (94.4444)  time: 0.3492  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [  90/1142]  eta: 0:06:10  Lr: 0.001875  Loss: -1.0500  Acc@1: 68.7500 (67.3764)  Acc@5: 93.7500 (93.8874)  time: 0.3495  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [ 100/1142]  eta: 0:06:06  Lr: 0.001875  Loss: -0.4643  Acc@1: 62.5000 (66.8317)  Acc@5: 93.7500 (93.9356)  time: 0.3490  data: 0.0006  max mem: 2502
Train: Epoch[3/5]  [ 110/1142]  eta: 0:06:03  Lr: 0.001875  Loss: -0.3704  Acc@1: 68.7500 (67.0608)  Acc@5: 93.7500 (93.8626)  time: 0.3489  data: 0.0010  max mem: 2502
Train: Epoch[3/5]  [ 120/1142]  eta: 0:05:59  Lr: 0.001875  Loss: -0.4965  Acc@1: 68.7500 (66.9421)  Acc@5: 93.7500 (93.8533)  time: 0.3503  data: 0.0016  max mem: 2502
Train: Epoch[3/5]  [ 130/1142]  eta: 0:05:55  Lr: 0.001875  Loss: -0.6548  Acc@1: 62.5000 (66.6031)  Acc@5: 93.7500 (93.7023)  time: 0.3501  data: 0.0010  max mem: 2502
Train: Epoch[3/5]  [ 140/1142]  eta: 0:05:52  Lr: 0.001875  Loss: -0.1673  Acc@1: 62.5000 (67.0656)  Acc@5: 93.7500 (93.8830)  time: 0.3481  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [ 150/1142]  eta: 0:05:48  Lr: 0.001875  Loss: -0.6615  Acc@1: 75.0000 (67.2185)  Acc@5: 93.7500 (93.9156)  time: 0.3478  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [ 160/1142]  eta: 0:05:44  Lr: 0.001875  Loss: -0.9153  Acc@1: 75.0000 (67.4689)  Acc@5: 93.7500 (93.9441)  time: 0.3485  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [ 170/1142]  eta: 0:05:41  Lr: 0.001875  Loss: -0.7621  Acc@1: 62.5000 (67.0687)  Acc@5: 93.7500 (94.0058)  time: 0.3494  data: 0.0010  max mem: 2502
Train: Epoch[3/5]  [ 180/1142]  eta: 0:05:37  Lr: 0.001875  Loss: -0.1559  Acc@1: 56.2500 (66.6091)  Acc@5: 93.7500 (93.8191)  time: 0.3503  data: 0.0010  max mem: 2502
Train: Epoch[3/5]  [ 190/1142]  eta: 0:05:34  Lr: 0.001875  Loss: -0.3304  Acc@1: 62.5000 (66.6885)  Acc@5: 93.7500 (93.7500)  time: 0.3506  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [ 200/1142]  eta: 0:05:30  Lr: 0.001875  Loss: -0.3223  Acc@1: 75.0000 (66.9776)  Acc@5: 93.7500 (93.7811)  time: 0.3508  data: 0.0012  max mem: 2502
Train: Epoch[3/5]  [ 210/1142]  eta: 0:05:27  Lr: 0.001875  Loss: -0.0682  Acc@1: 68.7500 (67.0616)  Acc@5: 93.7500 (93.8685)  time: 0.3506  data: 0.0013  max mem: 2502
Train: Epoch[3/5]  [ 220/1142]  eta: 0:05:23  Lr: 0.001875  Loss: -0.5256  Acc@1: 68.7500 (67.3925)  Acc@5: 93.7500 (93.8631)  time: 0.3500  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [ 230/1142]  eta: 0:05:19  Lr: 0.001875  Loss: -0.6938  Acc@1: 75.0000 (67.5595)  Acc@5: 100.0000 (93.9665)  time: 0.3499  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [ 240/1142]  eta: 0:05:16  Lr: 0.001875  Loss: -0.5281  Acc@1: 68.7500 (67.5052)  Acc@5: 93.7500 (93.8278)  time: 0.3500  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [ 250/1142]  eta: 0:05:12  Lr: 0.001875  Loss: -0.4741  Acc@1: 68.7500 (67.4303)  Acc@5: 93.7500 (93.7500)  time: 0.3496  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [ 260/1142]  eta: 0:05:09  Lr: 0.001875  Loss: -0.4714  Acc@1: 68.7500 (67.6485)  Acc@5: 93.7500 (93.7261)  time: 0.3489  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [ 270/1142]  eta: 0:05:05  Lr: 0.001875  Loss: -0.6531  Acc@1: 68.7500 (67.6891)  Acc@5: 93.7500 (93.6808)  time: 0.3488  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [ 280/1142]  eta: 0:05:02  Lr: 0.001875  Loss: -0.1685  Acc@1: 68.7500 (67.8381)  Acc@5: 93.7500 (93.7945)  time: 0.3502  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [ 290/1142]  eta: 0:04:58  Lr: 0.001875  Loss: -0.3796  Acc@1: 68.7500 (67.8050)  Acc@5: 93.7500 (93.8574)  time: 0.3507  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [ 300/1142]  eta: 0:04:55  Lr: 0.001875  Loss: -0.2261  Acc@1: 62.5000 (67.7118)  Acc@5: 93.7500 (93.8331)  time: 0.3499  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [ 310/1142]  eta: 0:04:51  Lr: 0.001875  Loss: -0.2346  Acc@1: 62.5000 (67.7251)  Acc@5: 93.7500 (93.7500)  time: 0.3497  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [ 320/1142]  eta: 0:04:48  Lr: 0.001875  Loss: -0.4888  Acc@1: 68.7500 (67.8349)  Acc@5: 93.7500 (93.7695)  time: 0.3500  data: 0.0007  max mem: 2502
Train: Epoch[3/5]  [ 330/1142]  eta: 0:04:44  Lr: 0.001875  Loss: -0.0922  Acc@1: 75.0000 (67.8814)  Acc@5: 100.0000 (93.8444)  time: 0.3508  data: 0.0008  max mem: 2502
Train: Epoch[3/5]  [ 340/1142]  eta: 0:04:41  Lr: 0.001875  Loss: -0.2470  Acc@1: 68.7500 (67.6870)  Acc@5: 93.7500 (93.6767)  time: 0.3517  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [ 350/1142]  eta: 0:04:37  Lr: 0.001875  Loss: -0.6016  Acc@1: 62.5000 (67.5392)  Acc@5: 87.5000 (93.6432)  time: 0.3513  data: 0.0009  max mem: 2502
Train: Epoch[3/5]  [ 360/1142]  eta: 0:04:34  Lr: 0.001875  Loss: -0.6412  Acc@1: 68.7500 (67.6247)  Acc@5: 93.7500 (93.7327)  time: 0.3511  data: 0.0009  max mem: 2502
Train: Epoch[3/5]  [ 370/1142]  eta: 0:04:30  Lr: 0.001875  Loss: -0.5532  Acc@1: 62.5000 (67.4360)  Acc@5: 93.7500 (93.7163)  time: 0.3509  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [ 380/1142]  eta: 0:04:27  Lr: 0.001875  Loss: -0.1219  Acc@1: 62.5000 (67.5033)  Acc@5: 93.7500 (93.7172)  time: 0.3502  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [ 390/1142]  eta: 0:04:23  Lr: 0.001875  Loss: -0.5244  Acc@1: 68.7500 (67.3753)  Acc@5: 93.7500 (93.6861)  time: 0.3498  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [ 400/1142]  eta: 0:04:20  Lr: 0.001875  Loss: -0.5120  Acc@1: 62.5000 (67.3317)  Acc@5: 93.7500 (93.6721)  time: 0.3506  data: 0.0011  max mem: 2502
Train: Epoch[3/5]  [ 410/1142]  eta: 0:04:16  Lr: 0.001875  Loss: -0.1189  Acc@1: 62.5000 (67.1989)  Acc@5: 93.7500 (93.5979)  time: 0.3509  data: 0.0011  max mem: 2502
Train: Epoch[3/5]  [ 420/1142]  eta: 0:04:13  Lr: 0.001875  Loss: -0.7119  Acc@1: 62.5000 (67.2061)  Acc@5: 93.7500 (93.6758)  time: 0.3501  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [ 430/1142]  eta: 0:04:09  Lr: 0.001875  Loss: -0.0411  Acc@1: 68.7500 (67.1839)  Acc@5: 93.7500 (93.6195)  time: 0.3502  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [ 440/1142]  eta: 0:04:06  Lr: 0.001875  Loss: -0.5083  Acc@1: 68.7500 (67.1485)  Acc@5: 93.7500 (93.6224)  time: 0.3510  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [ 450/1142]  eta: 0:04:02  Lr: 0.001875  Loss: -0.3494  Acc@1: 62.5000 (67.1425)  Acc@5: 93.7500 (93.5698)  time: 0.3515  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [ 460/1142]  eta: 0:03:59  Lr: 0.001875  Loss: -0.7065  Acc@1: 68.7500 (67.2858)  Acc@5: 93.7500 (93.5738)  time: 0.3519  data: 0.0011  max mem: 2502
Train: Epoch[3/5]  [ 470/1142]  eta: 0:03:55  Lr: 0.001875  Loss: -0.4651  Acc@1: 68.7500 (67.2107)  Acc@5: 93.7500 (93.5377)  time: 0.3525  data: 0.0011  max mem: 2502
Train: Epoch[3/5]  [ 480/1142]  eta: 0:03:52  Lr: 0.001875  Loss: -0.5379  Acc@1: 68.7500 (67.1648)  Acc@5: 93.7500 (93.5681)  time: 0.3511  data: 0.0009  max mem: 2502
Train: Epoch[3/5]  [ 490/1142]  eta: 0:03:48  Lr: 0.001875  Loss: 0.0490  Acc@1: 68.7500 (67.0698)  Acc@5: 93.7500 (93.5081)  time: 0.3505  data: 0.0009  max mem: 2502
Train: Epoch[3/5]  [ 500/1142]  eta: 0:03:45  Lr: 0.001875  Loss: -0.6984  Acc@1: 62.5000 (67.0534)  Acc@5: 93.7500 (93.5379)  time: 0.3502  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [ 510/1142]  eta: 0:03:41  Lr: 0.001875  Loss: -0.3615  Acc@1: 62.5000 (67.0254)  Acc@5: 93.7500 (93.5421)  time: 0.3499  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [ 520/1142]  eta: 0:03:38  Lr: 0.001875  Loss: -0.6698  Acc@1: 68.7500 (67.0585)  Acc@5: 93.7500 (93.5821)  time: 0.3513  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [ 530/1142]  eta: 0:03:34  Lr: 0.001875  Loss: -0.7194  Acc@1: 68.7500 (67.1492)  Acc@5: 100.0000 (93.6441)  time: 0.3514  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [ 540/1142]  eta: 0:03:31  Lr: 0.001875  Loss: -0.4848  Acc@1: 68.7500 (67.1095)  Acc@5: 93.7500 (93.6345)  time: 0.3509  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [ 550/1142]  eta: 0:03:27  Lr: 0.001875  Loss: 0.2862  Acc@1: 62.5000 (67.0032)  Acc@5: 93.7500 (93.6252)  time: 0.3509  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [ 560/1142]  eta: 0:03:24  Lr: 0.001875  Loss: -0.3799  Acc@1: 62.5000 (67.0120)  Acc@5: 93.7500 (93.6275)  time: 0.3501  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [ 570/1142]  eta: 0:03:20  Lr: 0.001875  Loss: -0.3474  Acc@1: 62.5000 (66.9549)  Acc@5: 93.7500 (93.6515)  time: 0.3502  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [ 580/1142]  eta: 0:03:17  Lr: 0.001875  Loss: -0.8930  Acc@1: 62.5000 (66.9320)  Acc@5: 93.7500 (93.5994)  time: 0.3502  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [ 590/1142]  eta: 0:03:13  Lr: 0.001875  Loss: -0.3403  Acc@1: 62.5000 (66.9839)  Acc@5: 87.5000 (93.5808)  time: 0.3500  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [ 600/1142]  eta: 0:03:10  Lr: 0.001875  Loss: -0.3639  Acc@1: 62.5000 (66.9197)  Acc@5: 93.7500 (93.5732)  time: 0.3506  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [ 610/1142]  eta: 0:03:06  Lr: 0.001875  Loss: -0.4065  Acc@1: 68.7500 (67.0417)  Acc@5: 93.7500 (93.5352)  time: 0.3510  data: 0.0008  max mem: 2502
Train: Epoch[3/5]  [ 620/1142]  eta: 0:03:03  Lr: 0.001875  Loss: -0.2868  Acc@1: 75.0000 (67.1498)  Acc@5: 93.7500 (93.5588)  time: 0.3497  data: 0.0007  max mem: 2502
Train: Epoch[3/5]  [ 630/1142]  eta: 0:02:59  Lr: 0.001875  Loss: -0.5046  Acc@1: 68.7500 (67.0464)  Acc@5: 93.7500 (93.5123)  time: 0.3485  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [ 640/1142]  eta: 0:02:55  Lr: 0.001875  Loss: -0.7141  Acc@1: 62.5000 (67.0339)  Acc@5: 93.7500 (93.5452)  time: 0.3497  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [ 650/1142]  eta: 0:02:52  Lr: 0.001875  Loss: -0.9072  Acc@1: 68.7500 (67.1755)  Acc@5: 93.7500 (93.5484)  time: 0.3496  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [ 660/1142]  eta: 0:02:48  Lr: 0.001875  Loss: -0.3232  Acc@1: 75.0000 (67.1710)  Acc@5: 93.7500 (93.5893)  time: 0.3487  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [ 670/1142]  eta: 0:02:45  Lr: 0.001875  Loss: -0.7424  Acc@1: 68.7500 (67.2224)  Acc@5: 93.7500 (93.5823)  time: 0.3496  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [ 680/1142]  eta: 0:02:41  Lr: 0.001875  Loss: 0.0743  Acc@1: 68.7500 (67.2081)  Acc@5: 93.7500 (93.5389)  time: 0.3490  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [ 690/1142]  eta: 0:02:38  Lr: 0.001875  Loss: -0.1378  Acc@1: 68.7500 (67.1581)  Acc@5: 93.7500 (93.5420)  time: 0.3486  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [ 700/1142]  eta: 0:02:34  Lr: 0.001875  Loss: -0.1828  Acc@1: 56.2500 (67.1006)  Acc@5: 93.7500 (93.5093)  time: 0.3485  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [ 710/1142]  eta: 0:02:31  Lr: 0.001875  Loss: -0.3074  Acc@1: 62.5000 (67.0798)  Acc@5: 93.7500 (93.5302)  time: 0.3481  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [ 720/1142]  eta: 0:02:27  Lr: 0.001875  Loss: -0.8756  Acc@1: 75.0000 (67.1637)  Acc@5: 93.7500 (93.5506)  time: 0.3499  data: 0.0008  max mem: 2502
Train: Epoch[3/5]  [ 730/1142]  eta: 0:02:24  Lr: 0.001875  Loss: -0.6487  Acc@1: 75.0000 (67.2025)  Acc@5: 93.7500 (93.5705)  time: 0.3501  data: 0.0008  max mem: 2502
Train: Epoch[3/5]  [ 740/1142]  eta: 0:02:20  Lr: 0.001875  Loss: -0.9414  Acc@1: 68.7500 (67.2571)  Acc@5: 93.7500 (93.5897)  time: 0.3483  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [ 750/1142]  eta: 0:02:17  Lr: 0.001875  Loss: -0.8405  Acc@1: 68.7500 (67.2936)  Acc@5: 93.7500 (93.6418)  time: 0.3484  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [ 760/1142]  eta: 0:02:13  Lr: 0.001875  Loss: -1.0769  Acc@1: 75.0000 (67.3949)  Acc@5: 93.7500 (93.6679)  time: 0.3488  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [ 770/1142]  eta: 0:02:10  Lr: 0.001875  Loss: -0.3138  Acc@1: 68.7500 (67.3800)  Acc@5: 93.7500 (93.6689)  time: 0.3482  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [ 780/1142]  eta: 0:02:06  Lr: 0.001875  Loss: -0.9628  Acc@1: 68.7500 (67.3976)  Acc@5: 93.7500 (93.6620)  time: 0.3485  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [ 790/1142]  eta: 0:02:03  Lr: 0.001875  Loss: -0.8099  Acc@1: 68.7500 (67.4384)  Acc@5: 93.7500 (93.6947)  time: 0.3491  data: 0.0007  max mem: 2502
Train: Epoch[3/5]  [ 800/1142]  eta: 0:01:59  Lr: 0.001875  Loss: -0.6585  Acc@1: 68.7500 (67.4313)  Acc@5: 93.7500 (93.7032)  time: 0.3495  data: 0.0007  max mem: 2502
Train: Epoch[3/5]  [ 810/1142]  eta: 0:01:56  Lr: 0.001875  Loss: -0.6341  Acc@1: 68.7500 (67.4245)  Acc@5: 93.7500 (93.7269)  time: 0.3494  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [ 820/1142]  eta: 0:01:52  Lr: 0.001875  Loss: -0.4180  Acc@1: 62.5000 (67.3721)  Acc@5: 93.7500 (93.7272)  time: 0.3495  data: 0.0006  max mem: 2502
Train: Epoch[3/5]  [ 830/1142]  eta: 0:01:49  Lr: 0.001875  Loss: -0.7166  Acc@1: 62.5000 (67.4037)  Acc@5: 93.7500 (93.7575)  time: 0.3492  data: 0.0005  max mem: 2502
Train: Epoch[3/5]  [ 840/1142]  eta: 0:01:45  Lr: 0.001875  Loss: -0.7064  Acc@1: 68.7500 (67.4049)  Acc@5: 93.7500 (93.7574)  time: 0.3493  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [ 850/1142]  eta: 0:01:42  Lr: 0.001875  Loss: -0.2419  Acc@1: 62.5000 (67.3399)  Acc@5: 93.7500 (93.7206)  time: 0.3499  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [ 860/1142]  eta: 0:01:38  Lr: 0.001875  Loss: -0.6094  Acc@1: 68.7500 (67.3853)  Acc@5: 93.7500 (93.7500)  time: 0.3493  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [ 870/1142]  eta: 0:01:35  Lr: 0.001875  Loss: -0.2207  Acc@1: 68.7500 (67.3866)  Acc@5: 93.7500 (93.7356)  time: 0.3498  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [ 880/1142]  eta: 0:01:31  Lr: 0.001875  Loss: -0.8210  Acc@1: 68.7500 (67.4234)  Acc@5: 93.7500 (93.7358)  time: 0.3509  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [ 890/1142]  eta: 0:01:28  Lr: 0.001875  Loss: -0.2064  Acc@1: 62.5000 (67.3260)  Acc@5: 93.7500 (93.7219)  time: 0.3503  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [ 900/1142]  eta: 0:01:24  Lr: 0.001875  Loss: -0.9529  Acc@1: 62.5000 (67.3349)  Acc@5: 93.7500 (93.7084)  time: 0.3503  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [ 910/1142]  eta: 0:01:21  Lr: 0.001875  Loss: -0.5605  Acc@1: 75.0000 (67.4328)  Acc@5: 93.7500 (93.7363)  time: 0.3503  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [ 920/1142]  eta: 0:01:17  Lr: 0.001875  Loss: -0.5870  Acc@1: 75.0000 (67.5149)  Acc@5: 93.7500 (93.7568)  time: 0.3489  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [ 930/1142]  eta: 0:01:14  Lr: 0.001875  Loss: -0.4596  Acc@1: 75.0000 (67.5349)  Acc@5: 93.7500 (93.7903)  time: 0.3499  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [ 940/1142]  eta: 0:01:10  Lr: 0.001875  Loss: -0.5665  Acc@1: 68.7500 (67.5213)  Acc@5: 100.0000 (93.8164)  time: 0.3497  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [ 950/1142]  eta: 0:01:07  Lr: 0.001875  Loss: -0.7745  Acc@1: 68.7500 (67.5868)  Acc@5: 93.7500 (93.8354)  time: 0.3495  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [ 960/1142]  eta: 0:01:03  Lr: 0.001875  Loss: -0.8529  Acc@1: 75.0000 (67.6054)  Acc@5: 93.7500 (93.8411)  time: 0.3506  data: 0.0011  max mem: 2502
Train: Epoch[3/5]  [ 970/1142]  eta: 0:01:00  Lr: 0.001875  Loss: -0.0780  Acc@1: 62.5000 (67.5142)  Acc@5: 93.7500 (93.8465)  time: 0.3499  data: 0.0011  max mem: 2502
Train: Epoch[3/5]  [ 980/1142]  eta: 0:00:56  Lr: 0.001875  Loss: -0.4961  Acc@1: 62.5000 (67.5013)  Acc@5: 93.7500 (93.8519)  time: 0.3494  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [ 990/1142]  eta: 0:00:53  Lr: 0.001875  Loss: -0.5799  Acc@1: 68.7500 (67.5832)  Acc@5: 93.7500 (93.8446)  time: 0.3492  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [1000/1142]  eta: 0:00:49  Lr: 0.001875  Loss: -0.2480  Acc@1: 75.0000 (67.6573)  Acc@5: 93.7500 (93.8686)  time: 0.3494  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [1010/1142]  eta: 0:00:46  Lr: 0.001875  Loss: -0.5031  Acc@1: 68.7500 (67.6743)  Acc@5: 100.0000 (93.8984)  time: 0.3498  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [1020/1142]  eta: 0:00:42  Lr: 0.001875  Loss: -0.4271  Acc@1: 68.7500 (67.6787)  Acc@5: 100.0000 (93.9153)  time: 0.3493  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [1030/1142]  eta: 0:00:39  Lr: 0.001875  Loss: -0.3742  Acc@1: 68.7500 (67.6649)  Acc@5: 93.7500 (93.9197)  time: 0.3499  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [1040/1142]  eta: 0:00:35  Lr: 0.001875  Loss: -0.6145  Acc@1: 68.7500 (67.7053)  Acc@5: 93.7500 (93.9301)  time: 0.3501  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [1050/1142]  eta: 0:00:32  Lr: 0.001875  Loss: -0.3429  Acc@1: 68.7500 (67.6736)  Acc@5: 93.7500 (93.9284)  time: 0.3488  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [1060/1142]  eta: 0:00:28  Lr: 0.001875  Loss: -0.4081  Acc@1: 68.7500 (67.7015)  Acc@5: 93.7500 (93.9208)  time: 0.3487  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [1070/1142]  eta: 0:00:25  Lr: 0.001875  Loss: 0.0024  Acc@1: 68.7500 (67.6646)  Acc@5: 93.7500 (93.9251)  time: 0.3489  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [1080/1142]  eta: 0:00:21  Lr: 0.001875  Loss: -0.2676  Acc@1: 62.5000 (67.6284)  Acc@5: 93.7500 (93.9350)  time: 0.3491  data: 0.0003  max mem: 2502
Train: Epoch[3/5]  [1090/1142]  eta: 0:00:18  Lr: 0.001875  Loss: -0.3995  Acc@1: 68.7500 (67.6272)  Acc@5: 93.7500 (93.9161)  time: 0.3497  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [1100/1142]  eta: 0:00:14  Lr: 0.001875  Loss: -0.2337  Acc@1: 68.7500 (67.6260)  Acc@5: 93.7500 (93.9146)  time: 0.3494  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [1110/1142]  eta: 0:00:11  Lr: 0.001875  Loss: -0.3166  Acc@1: 68.7500 (67.6811)  Acc@5: 93.7500 (93.9356)  time: 0.3499  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [1120/1142]  eta: 0:00:07  Lr: 0.001875  Loss: -0.6933  Acc@1: 68.7500 (67.6572)  Acc@5: 93.7500 (93.9563)  time: 0.3496  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [1130/1142]  eta: 0:00:04  Lr: 0.001875  Loss: -0.2383  Acc@1: 62.5000 (67.6779)  Acc@5: 93.7500 (93.9600)  time: 0.3488  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [1140/1142]  eta: 0:00:00  Lr: 0.001875  Loss: -0.3308  Acc@1: 68.7500 (67.6928)  Acc@5: 93.7500 (93.9417)  time: 0.3496  data: 0.0004  max mem: 2502
Train: Epoch[3/5]  [1141/1142]  eta: 0:00:00  Lr: 0.001875  Loss: -0.1555  Acc@1: 68.7500 (67.6868)  Acc@5: 93.7500 (93.9392)  time: 0.3423  data: 0.0004  max mem: 2502
Train: Epoch[3/5] Total time: 0:06:39 (0.3502 s / it)
Averaged stats: Lr: 0.001875  Loss: -0.1555  Acc@1: 68.7500 (67.6868)  Acc@5: 93.7500 (93.9392)
Train: Epoch[4/5]  [   0/1142]  eta: 0:12:55  Lr: 0.001875  Loss: -0.8190  Acc@1: 75.0000 (75.0000)  Acc@5: 100.0000 (100.0000)  time: 0.6788  data: 0.3249  max mem: 2502
Train: Epoch[4/5]  [  10/1142]  eta: 0:07:08  Lr: 0.001875  Loss: 0.2467  Acc@1: 56.2500 (61.9318)  Acc@5: 100.0000 (94.8864)  time: 0.3787  data: 0.0299  max mem: 2502
Train: Epoch[4/5]  [  20/1142]  eta: 0:06:49  Lr: 0.001875  Loss: -0.2935  Acc@1: 62.5000 (65.7738)  Acc@5: 93.7500 (94.0476)  time: 0.3489  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [  30/1142]  eta: 0:06:40  Lr: 0.001875  Loss: -0.4164  Acc@1: 68.7500 (63.9113)  Acc@5: 93.7500 (93.3468)  time: 0.3497  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [  40/1142]  eta: 0:06:33  Lr: 0.001875  Loss: -0.0253  Acc@1: 62.5000 (64.4817)  Acc@5: 93.7500 (92.8354)  time: 0.3499  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [  50/1142]  eta: 0:06:28  Lr: 0.001875  Loss: -0.1340  Acc@1: 68.7500 (65.8088)  Acc@5: 93.7500 (93.3824)  time: 0.3495  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [  60/1142]  eta: 0:06:24  Lr: 0.001875  Loss: -0.9432  Acc@1: 75.0000 (67.0082)  Acc@5: 100.0000 (93.8525)  time: 0.3504  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [  70/1142]  eta: 0:06:19  Lr: 0.001875  Loss: -0.6818  Acc@1: 68.7500 (67.0775)  Acc@5: 93.7500 (93.9261)  time: 0.3507  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [  80/1142]  eta: 0:06:15  Lr: 0.001875  Loss: -0.6671  Acc@1: 68.7500 (67.5154)  Acc@5: 93.7500 (93.7500)  time: 0.3500  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [  90/1142]  eta: 0:06:12  Lr: 0.001875  Loss: -0.7043  Acc@1: 68.7500 (67.9945)  Acc@5: 93.7500 (93.6126)  time: 0.3514  data: 0.0019  max mem: 2502
Train: Epoch[4/5]  [ 100/1142]  eta: 0:06:08  Lr: 0.001875  Loss: -0.6682  Acc@1: 75.0000 (68.1931)  Acc@5: 93.7500 (93.7500)  time: 0.3515  data: 0.0024  max mem: 2502
Train: Epoch[4/5]  [ 110/1142]  eta: 0:06:04  Lr: 0.001875  Loss: -0.7672  Acc@1: 75.0000 (68.6937)  Acc@5: 93.7500 (93.6937)  time: 0.3501  data: 0.0010  max mem: 2502
Train: Epoch[4/5]  [ 120/1142]  eta: 0:06:00  Lr: 0.001875  Loss: 0.0014  Acc@1: 68.7500 (68.0785)  Acc@5: 93.7500 (93.6983)  time: 0.3497  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [ 130/1142]  eta: 0:05:56  Lr: 0.001875  Loss: -0.6925  Acc@1: 68.7500 (68.3683)  Acc@5: 93.7500 (93.7023)  time: 0.3499  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [ 140/1142]  eta: 0:05:53  Lr: 0.001875  Loss: -0.7217  Acc@1: 75.0000 (68.9716)  Acc@5: 93.7500 (93.9716)  time: 0.3515  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [ 150/1142]  eta: 0:05:49  Lr: 0.001875  Loss: -0.5340  Acc@1: 68.7500 (68.7086)  Acc@5: 93.7500 (93.7914)  time: 0.3518  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [ 160/1142]  eta: 0:05:45  Lr: 0.001875  Loss: -0.3632  Acc@1: 68.7500 (68.9053)  Acc@5: 93.7500 (94.0217)  time: 0.3500  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [ 170/1142]  eta: 0:05:42  Lr: 0.001875  Loss: -0.8072  Acc@1: 68.7500 (68.7135)  Acc@5: 100.0000 (94.0789)  time: 0.3496  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [ 180/1142]  eta: 0:05:38  Lr: 0.001875  Loss: -0.4307  Acc@1: 68.7500 (68.7500)  Acc@5: 93.7500 (94.1644)  time: 0.3506  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [ 190/1142]  eta: 0:05:35  Lr: 0.001875  Loss: -0.8099  Acc@1: 68.7500 (68.9791)  Acc@5: 93.7500 (94.2736)  time: 0.3505  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [ 200/1142]  eta: 0:05:31  Lr: 0.001875  Loss: -0.4640  Acc@1: 68.7500 (69.1542)  Acc@5: 93.7500 (94.3719)  time: 0.3500  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [ 210/1142]  eta: 0:05:27  Lr: 0.001875  Loss: -1.0465  Acc@1: 68.7500 (69.3720)  Acc@5: 93.7500 (94.3720)  time: 0.3502  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [ 220/1142]  eta: 0:05:24  Lr: 0.001875  Loss: -0.4217  Acc@1: 68.7500 (69.2590)  Acc@5: 93.7500 (94.5136)  time: 0.3510  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [ 230/1142]  eta: 0:05:20  Lr: 0.001875  Loss: 0.2139  Acc@1: 62.5000 (69.1288)  Acc@5: 93.7500 (94.4535)  time: 0.3505  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [ 240/1142]  eta: 0:05:17  Lr: 0.001875  Loss: -0.2945  Acc@1: 62.5000 (68.9575)  Acc@5: 93.7500 (94.2427)  time: 0.3493  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [ 250/1142]  eta: 0:05:13  Lr: 0.001875  Loss: 0.0732  Acc@1: 62.5000 (68.7998)  Acc@5: 93.7500 (94.1982)  time: 0.3490  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [ 260/1142]  eta: 0:05:09  Lr: 0.001875  Loss: 0.1568  Acc@1: 68.7500 (68.8458)  Acc@5: 93.7500 (94.3008)  time: 0.3496  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [ 270/1142]  eta: 0:05:06  Lr: 0.001875  Loss: -0.7869  Acc@1: 68.7500 (68.9345)  Acc@5: 93.7500 (94.2804)  time: 0.3498  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [ 280/1142]  eta: 0:05:02  Lr: 0.001875  Loss: -0.5968  Acc@1: 75.0000 (68.9724)  Acc@5: 93.7500 (94.3728)  time: 0.3499  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [ 290/1142]  eta: 0:04:59  Lr: 0.001875  Loss: -0.3120  Acc@1: 68.7500 (68.7930)  Acc@5: 93.7500 (94.4158)  time: 0.3503  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [ 300/1142]  eta: 0:04:55  Lr: 0.001875  Loss: -0.6565  Acc@1: 68.7500 (68.8331)  Acc@5: 93.7500 (94.4145)  time: 0.3510  data: 0.0006  max mem: 2502
Train: Epoch[4/5]  [ 310/1142]  eta: 0:04:52  Lr: 0.001875  Loss: -0.3563  Acc@1: 68.7500 (68.7701)  Acc@5: 93.7500 (94.5338)  time: 0.3507  data: 0.0006  max mem: 2502
Train: Epoch[4/5]  [ 320/1142]  eta: 0:04:48  Lr: 0.001875  Loss: 0.0434  Acc@1: 68.7500 (68.6526)  Acc@5: 100.0000 (94.5093)  time: 0.3495  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [ 330/1142]  eta: 0:04:45  Lr: 0.001875  Loss: -0.0397  Acc@1: 68.7500 (68.7122)  Acc@5: 93.7500 (94.5431)  time: 0.3503  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [ 340/1142]  eta: 0:04:41  Lr: 0.001875  Loss: -0.2223  Acc@1: 68.7500 (68.6584)  Acc@5: 93.7500 (94.4648)  time: 0.3511  data: 0.0013  max mem: 2502
Train: Epoch[4/5]  [ 350/1142]  eta: 0:04:38  Lr: 0.001875  Loss: -0.4738  Acc@1: 68.7500 (68.6432)  Acc@5: 93.7500 (94.3910)  time: 0.3511  data: 0.0014  max mem: 2502
Train: Epoch[4/5]  [ 360/1142]  eta: 0:04:34  Lr: 0.001875  Loss: -0.7792  Acc@1: 62.5000 (68.6461)  Acc@5: 93.7500 (94.3386)  time: 0.3502  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [ 370/1142]  eta: 0:04:31  Lr: 0.001875  Loss: -0.5274  Acc@1: 68.7500 (68.6826)  Acc@5: 93.7500 (94.3565)  time: 0.3493  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [ 380/1142]  eta: 0:04:27  Lr: 0.001875  Loss: -0.8265  Acc@1: 68.7500 (68.6352)  Acc@5: 93.7500 (94.3241)  time: 0.3489  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [ 390/1142]  eta: 0:04:23  Lr: 0.001875  Loss: -0.6160  Acc@1: 62.5000 (68.5262)  Acc@5: 93.7500 (94.2775)  time: 0.3482  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [ 400/1142]  eta: 0:04:20  Lr: 0.001875  Loss: -0.6830  Acc@1: 68.7500 (68.5474)  Acc@5: 93.7500 (94.2955)  time: 0.3484  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [ 410/1142]  eta: 0:04:16  Lr: 0.001875  Loss: -0.3885  Acc@1: 68.7500 (68.5219)  Acc@5: 93.7500 (94.3583)  time: 0.3484  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [ 420/1142]  eta: 0:04:13  Lr: 0.001875  Loss: -0.5565  Acc@1: 62.5000 (68.3789)  Acc@5: 93.7500 (94.3587)  time: 0.3496  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [ 430/1142]  eta: 0:04:09  Lr: 0.001875  Loss: -0.1700  Acc@1: 62.5000 (68.4165)  Acc@5: 93.7500 (94.3300)  time: 0.3502  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [ 440/1142]  eta: 0:04:06  Lr: 0.001875  Loss: -0.3120  Acc@1: 68.7500 (68.3107)  Acc@5: 93.7500 (94.3027)  time: 0.3497  data: 0.0010  max mem: 2502
Train: Epoch[4/5]  [ 450/1142]  eta: 0:04:02  Lr: 0.001875  Loss: -0.4633  Acc@1: 62.5000 (68.3620)  Acc@5: 93.7500 (94.3320)  time: 0.3496  data: 0.0010  max mem: 2502
Train: Epoch[4/5]  [ 460/1142]  eta: 0:03:59  Lr: 0.001875  Loss: -0.5180  Acc@1: 62.5000 (68.3297)  Acc@5: 93.7500 (94.3465)  time: 0.3492  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [ 470/1142]  eta: 0:03:55  Lr: 0.001875  Loss: -0.6403  Acc@1: 62.5000 (68.2723)  Acc@5: 93.7500 (94.3206)  time: 0.3496  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [ 480/1142]  eta: 0:03:52  Lr: 0.001875  Loss: -0.8447  Acc@1: 62.5000 (68.2043)  Acc@5: 93.7500 (94.2827)  time: 0.3506  data: 0.0010  max mem: 2502
Train: Epoch[4/5]  [ 490/1142]  eta: 0:03:48  Lr: 0.001875  Loss: -0.3124  Acc@1: 68.7500 (68.1263)  Acc@5: 93.7500 (94.2974)  time: 0.3503  data: 0.0010  max mem: 2502
Train: Epoch[4/5]  [ 500/1142]  eta: 0:03:45  Lr: 0.001875  Loss: -0.7714  Acc@1: 68.7500 (68.2011)  Acc@5: 93.7500 (94.3239)  time: 0.3499  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [ 510/1142]  eta: 0:03:41  Lr: 0.001875  Loss: -0.8593  Acc@1: 68.7500 (68.1629)  Acc@5: 93.7500 (94.2515)  time: 0.3501  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [ 520/1142]  eta: 0:03:38  Lr: 0.001875  Loss: -0.7841  Acc@1: 68.7500 (68.1142)  Acc@5: 93.7500 (94.2658)  time: 0.3495  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [ 530/1142]  eta: 0:03:34  Lr: 0.001875  Loss: -0.8757  Acc@1: 68.7500 (68.0320)  Acc@5: 87.5000 (94.1855)  time: 0.3491  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [ 540/1142]  eta: 0:03:31  Lr: 0.001875  Loss: -0.5400  Acc@1: 68.7500 (68.0568)  Acc@5: 87.5000 (94.1659)  time: 0.3494  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [ 550/1142]  eta: 0:03:27  Lr: 0.001875  Loss: 0.1106  Acc@1: 68.7500 (68.0467)  Acc@5: 93.7500 (94.1810)  time: 0.3494  data: 0.0006  max mem: 2502
Train: Epoch[4/5]  [ 560/1142]  eta: 0:03:24  Lr: 0.001875  Loss: -0.2913  Acc@1: 62.5000 (67.9479)  Acc@5: 93.7500 (94.1511)  time: 0.3489  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [ 570/1142]  eta: 0:03:20  Lr: 0.001875  Loss: -0.3517  Acc@1: 62.5000 (67.9291)  Acc@5: 93.7500 (94.2097)  time: 0.3491  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [ 580/1142]  eta: 0:03:16  Lr: 0.001875  Loss: -0.3269  Acc@1: 56.2500 (67.7818)  Acc@5: 93.7500 (94.2233)  time: 0.3495  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [ 590/1142]  eta: 0:03:13  Lr: 0.001875  Loss: -0.5767  Acc@1: 56.2500 (67.7348)  Acc@5: 93.7500 (94.2470)  time: 0.3505  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [ 600/1142]  eta: 0:03:09  Lr: 0.001875  Loss: -0.3036  Acc@1: 68.7500 (67.8037)  Acc@5: 93.7500 (94.2700)  time: 0.3504  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [ 610/1142]  eta: 0:03:06  Lr: 0.001875  Loss: -0.9033  Acc@1: 68.7500 (67.7475)  Acc@5: 93.7500 (94.2205)  time: 0.3502  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [ 620/1142]  eta: 0:03:02  Lr: 0.001875  Loss: -0.5993  Acc@1: 68.7500 (67.8039)  Acc@5: 93.7500 (94.2331)  time: 0.3502  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [ 630/1142]  eta: 0:02:59  Lr: 0.001875  Loss: -0.2952  Acc@1: 68.7500 (67.8288)  Acc@5: 93.7500 (94.2452)  time: 0.3488  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [ 640/1142]  eta: 0:02:55  Lr: 0.001875  Loss: -0.6643  Acc@1: 68.7500 (67.9017)  Acc@5: 93.7500 (94.2570)  time: 0.3486  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [ 650/1142]  eta: 0:02:52  Lr: 0.001875  Loss: -0.6437  Acc@1: 68.7500 (67.9531)  Acc@5: 93.7500 (94.2684)  time: 0.3498  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [ 660/1142]  eta: 0:02:48  Lr: 0.001875  Loss: -0.2569  Acc@1: 68.7500 (67.9368)  Acc@5: 93.7500 (94.2984)  time: 0.3496  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [ 670/1142]  eta: 0:02:45  Lr: 0.001875  Loss: -0.6659  Acc@1: 68.7500 (67.9024)  Acc@5: 93.7500 (94.2996)  time: 0.3483  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [ 680/1142]  eta: 0:02:41  Lr: 0.001875  Loss: -0.3655  Acc@1: 68.7500 (67.9057)  Acc@5: 93.7500 (94.2823)  time: 0.3483  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [ 690/1142]  eta: 0:02:38  Lr: 0.001875  Loss: 0.0453  Acc@1: 62.5000 (67.8546)  Acc@5: 93.7500 (94.2384)  time: 0.3488  data: 0.0008  max mem: 2502
Train: Epoch[4/5]  [ 700/1142]  eta: 0:02:34  Lr: 0.001875  Loss: -0.9469  Acc@1: 62.5000 (67.8762)  Acc@5: 93.7500 (94.2760)  time: 0.3485  data: 0.0008  max mem: 2502
Train: Epoch[4/5]  [ 710/1142]  eta: 0:02:31  Lr: 0.001875  Loss: 0.1146  Acc@1: 62.5000 (67.8797)  Acc@5: 93.7500 (94.2511)  time: 0.3483  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [ 720/1142]  eta: 0:02:27  Lr: 0.001875  Loss: -0.6736  Acc@1: 68.7500 (67.9178)  Acc@5: 93.7500 (94.2614)  time: 0.3486  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [ 730/1142]  eta: 0:02:24  Lr: 0.001875  Loss: -0.2051  Acc@1: 68.7500 (67.8694)  Acc@5: 93.7500 (94.2459)  time: 0.3489  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [ 740/1142]  eta: 0:02:20  Lr: 0.001875  Loss: -0.3635  Acc@1: 68.7500 (67.8728)  Acc@5: 93.7500 (94.2223)  time: 0.3488  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [ 750/1142]  eta: 0:02:17  Lr: 0.001875  Loss: -0.8599  Acc@1: 75.0000 (67.9427)  Acc@5: 93.7500 (94.2077)  time: 0.3487  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [ 760/1142]  eta: 0:02:13  Lr: 0.001875  Loss: -0.3511  Acc@1: 75.0000 (67.9944)  Acc@5: 93.7500 (94.2263)  time: 0.3487  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [ 770/1142]  eta: 0:02:10  Lr: 0.001875  Loss: -0.8687  Acc@1: 68.7500 (67.9799)  Acc@5: 93.7500 (94.2121)  time: 0.3490  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [ 780/1142]  eta: 0:02:06  Lr: 0.001875  Loss: -0.4891  Acc@1: 68.7500 (68.0378)  Acc@5: 100.0000 (94.2382)  time: 0.3496  data: 0.0007  max mem: 2502
Train: Epoch[4/5]  [ 790/1142]  eta: 0:02:03  Lr: 0.001875  Loss: -0.2558  Acc@1: 68.7500 (68.0389)  Acc@5: 93.7500 (94.2320)  time: 0.3500  data: 0.0007  max mem: 2502
Train: Epoch[4/5]  [ 800/1142]  eta: 0:01:59  Lr: 0.001875  Loss: -0.5250  Acc@1: 68.7500 (68.0321)  Acc@5: 93.7500 (94.2338)  time: 0.3494  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [ 810/1142]  eta: 0:01:56  Lr: 0.001875  Loss: -0.8167  Acc@1: 68.7500 (68.0795)  Acc@5: 93.7500 (94.2355)  time: 0.3496  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [ 820/1142]  eta: 0:01:52  Lr: 0.001875  Loss: -0.5338  Acc@1: 68.7500 (68.0344)  Acc@5: 93.7500 (94.2296)  time: 0.3503  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [ 830/1142]  eta: 0:01:49  Lr: 0.001875  Loss: -0.1398  Acc@1: 62.5000 (68.0505)  Acc@5: 93.7500 (94.2464)  time: 0.3492  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [ 840/1142]  eta: 0:01:45  Lr: 0.001875  Loss: -0.3274  Acc@1: 68.7500 (68.0886)  Acc@5: 93.7500 (94.2702)  time: 0.3481  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [ 850/1142]  eta: 0:01:42  Lr: 0.001875  Loss: -0.5010  Acc@1: 75.0000 (68.1551)  Acc@5: 100.0000 (94.2861)  time: 0.3483  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [ 860/1142]  eta: 0:01:38  Lr: 0.001875  Loss: 0.1621  Acc@1: 68.7500 (68.1475)  Acc@5: 93.7500 (94.2654)  time: 0.3484  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [ 870/1142]  eta: 0:01:35  Lr: 0.001875  Loss: -0.4335  Acc@1: 68.7500 (68.2118)  Acc@5: 93.7500 (94.2738)  time: 0.3488  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [ 880/1142]  eta: 0:01:31  Lr: 0.001875  Loss: -0.7418  Acc@1: 68.7500 (68.2250)  Acc@5: 93.7500 (94.2679)  time: 0.3490  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [ 890/1142]  eta: 0:01:28  Lr: 0.001875  Loss: -0.5763  Acc@1: 68.7500 (68.1958)  Acc@5: 93.7500 (94.2551)  time: 0.3479  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [ 900/1142]  eta: 0:01:24  Lr: 0.001875  Loss: -0.6412  Acc@1: 62.5000 (68.1673)  Acc@5: 93.7500 (94.2772)  time: 0.3473  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [ 910/1142]  eta: 0:01:21  Lr: 0.001875  Loss: -0.9869  Acc@1: 62.5000 (68.1737)  Acc@5: 100.0000 (94.2851)  time: 0.3479  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [ 920/1142]  eta: 0:01:17  Lr: 0.001875  Loss: -0.2535  Acc@1: 62.5000 (68.1189)  Acc@5: 93.7500 (94.2657)  time: 0.3487  data: 0.0005  max mem: 2502
Train: Epoch[4/5]  [ 930/1142]  eta: 0:01:14  Lr: 0.001875  Loss: -0.7554  Acc@1: 68.7500 (68.1592)  Acc@5: 93.7500 (94.2803)  time: 0.3487  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [ 940/1142]  eta: 0:01:10  Lr: 0.001875  Loss: -0.5811  Acc@1: 68.7500 (68.1522)  Acc@5: 93.7500 (94.2614)  time: 0.3488  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [ 950/1142]  eta: 0:01:07  Lr: 0.001875  Loss: -0.2568  Acc@1: 68.7500 (68.1848)  Acc@5: 93.7500 (94.2692)  time: 0.3487  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [ 960/1142]  eta: 0:01:03  Lr: 0.001875  Loss: -0.9330  Acc@1: 75.0000 (68.2557)  Acc@5: 93.7500 (94.2573)  time: 0.3479  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [ 970/1142]  eta: 0:01:00  Lr: 0.001875  Loss: -1.0009  Acc@1: 81.2500 (68.3445)  Acc@5: 93.7500 (94.2842)  time: 0.3485  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [ 980/1142]  eta: 0:00:56  Lr: 0.001875  Loss: -0.5226  Acc@1: 75.0000 (68.3869)  Acc@5: 100.0000 (94.3107)  time: 0.3499  data: 0.0011  max mem: 2502
Train: Epoch[4/5]  [ 990/1142]  eta: 0:00:53  Lr: 0.001875  Loss: -0.2166  Acc@1: 68.7500 (68.4094)  Acc@5: 93.7500 (94.3239)  time: 0.3500  data: 0.0011  max mem: 2502
Train: Epoch[4/5]  [1000/1142]  eta: 0:00:49  Lr: 0.001875  Loss: -0.6470  Acc@1: 68.7500 (68.4003)  Acc@5: 93.7500 (94.2870)  time: 0.3492  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [1010/1142]  eta: 0:00:46  Lr: 0.001875  Loss: -0.3711  Acc@1: 68.7500 (68.4224)  Acc@5: 93.7500 (94.2631)  time: 0.3479  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [1020/1142]  eta: 0:00:42  Lr: 0.001875  Loss: -0.6088  Acc@1: 68.7500 (68.4256)  Acc@5: 93.7500 (94.2826)  time: 0.3478  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [1030/1142]  eta: 0:00:39  Lr: 0.001875  Loss: -0.8203  Acc@1: 68.7500 (68.3681)  Acc@5: 93.7500 (94.2956)  time: 0.3489  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [1040/1142]  eta: 0:00:35  Lr: 0.001875  Loss: -0.7971  Acc@1: 68.7500 (68.4618)  Acc@5: 93.7500 (94.3024)  time: 0.3495  data: 0.0003  max mem: 2502
Train: Epoch[4/5]  [1050/1142]  eta: 0:00:32  Lr: 0.001875  Loss: -0.2350  Acc@1: 75.0000 (68.4883)  Acc@5: 93.7500 (94.2912)  time: 0.3501  data: 0.0010  max mem: 2502
Train: Epoch[4/5]  [1060/1142]  eta: 0:00:28  Lr: 0.001875  Loss: -0.5138  Acc@1: 68.7500 (68.4672)  Acc@5: 93.7500 (94.2802)  time: 0.3506  data: 0.0011  max mem: 2502
Train: Epoch[4/5]  [1070/1142]  eta: 0:00:25  Lr: 0.001875  Loss: -0.3098  Acc@1: 68.7500 (68.4757)  Acc@5: 93.7500 (94.2927)  time: 0.3497  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [1080/1142]  eta: 0:00:21  Lr: 0.001875  Loss: -0.5054  Acc@1: 68.7500 (68.4262)  Acc@5: 93.7500 (94.2819)  time: 0.3498  data: 0.0006  max mem: 2502
Train: Epoch[4/5]  [1090/1142]  eta: 0:00:18  Lr: 0.001875  Loss: -0.5236  Acc@1: 68.7500 (68.4464)  Acc@5: 93.7500 (94.2770)  time: 0.3502  data: 0.0006  max mem: 2502
Train: Epoch[4/5]  [1100/1142]  eta: 0:00:14  Lr: 0.001875  Loss: -0.5479  Acc@1: 68.7500 (68.4094)  Acc@5: 93.7500 (94.2723)  time: 0.3498  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [1110/1142]  eta: 0:00:11  Lr: 0.001875  Loss: -0.0532  Acc@1: 68.7500 (68.3843)  Acc@5: 93.7500 (94.2901)  time: 0.3497  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [1120/1142]  eta: 0:00:07  Lr: 0.001875  Loss: -0.0382  Acc@1: 68.7500 (68.4155)  Acc@5: 100.0000 (94.3075)  time: 0.3495  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [1130/1142]  eta: 0:00:04  Lr: 0.001875  Loss: -0.3259  Acc@1: 68.7500 (68.3576)  Acc@5: 93.7500 (94.2971)  time: 0.3495  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [1140/1142]  eta: 0:00:00  Lr: 0.001875  Loss: -0.6459  Acc@1: 62.5000 (68.3447)  Acc@5: 93.7500 (94.3087)  time: 0.3497  data: 0.0004  max mem: 2502
Train: Epoch[4/5]  [1141/1142]  eta: 0:00:00  Lr: 0.001875  Loss: -1.0385  Acc@1: 62.5000 (68.3548)  Acc@5: 93.7500 (94.3115)  time: 0.3420  data: 0.0004  max mem: 2502
Train: Epoch[4/5] Total time: 0:06:39 (0.3499 s / it)
Averaged stats: Lr: 0.001875  Loss: -1.0385  Acc@1: 62.5000 (68.3548)  Acc@5: 93.7500 (94.3115)
Train: Epoch[5/5]  [   0/1142]  eta: 0:12:40  Lr: 0.001875  Loss: -0.8221  Acc@1: 81.2500 (81.2500)  Acc@5: 100.0000 (100.0000)  time: 0.6656  data: 0.3151  max mem: 2502
Train: Epoch[5/5]  [  10/1142]  eta: 0:07:08  Lr: 0.001875  Loss: -0.1517  Acc@1: 68.7500 (65.3409)  Acc@5: 93.7500 (92.6136)  time: 0.3787  data: 0.0301  max mem: 2502
Train: Epoch[5/5]  [  20/1142]  eta: 0:06:49  Lr: 0.001875  Loss: 0.3311  Acc@1: 62.5000 (63.3929)  Acc@5: 93.7500 (92.2619)  time: 0.3500  data: 0.0010  max mem: 2502
Train: Epoch[5/5]  [  30/1142]  eta: 0:06:40  Lr: 0.001875  Loss: -0.5337  Acc@1: 62.5000 (63.9113)  Acc@5: 93.7500 (92.9435)  time: 0.3506  data: 0.0015  max mem: 2502
Train: Epoch[5/5]  [  40/1142]  eta: 0:06:34  Lr: 0.001875  Loss: -0.7084  Acc@1: 68.7500 (65.7012)  Acc@5: 93.7500 (93.5976)  time: 0.3504  data: 0.0018  max mem: 2502
Train: Epoch[5/5]  [  50/1142]  eta: 0:06:29  Lr: 0.001875  Loss: -0.5732  Acc@1: 68.7500 (66.1765)  Acc@5: 93.7500 (93.6275)  time: 0.3497  data: 0.0006  max mem: 2502
Train: Epoch[5/5]  [  60/1142]  eta: 0:06:24  Lr: 0.001875  Loss: -0.1751  Acc@1: 62.5000 (66.2910)  Acc@5: 93.7500 (93.4426)  time: 0.3499  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [  70/1142]  eta: 0:06:19  Lr: 0.001875  Loss: -0.5631  Acc@1: 62.5000 (66.3732)  Acc@5: 93.7500 (93.4859)  time: 0.3492  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [  80/1142]  eta: 0:06:15  Lr: 0.001875  Loss: -0.8102  Acc@1: 68.7500 (67.2840)  Acc@5: 93.7500 (93.9043)  time: 0.3498  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [  90/1142]  eta: 0:06:11  Lr: 0.001875  Loss: -0.6959  Acc@1: 68.7500 (67.3764)  Acc@5: 93.7500 (93.9560)  time: 0.3501  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [ 100/1142]  eta: 0:06:07  Lr: 0.001875  Loss: -0.6292  Acc@1: 75.0000 (67.8218)  Acc@5: 93.7500 (94.0594)  time: 0.3497  data: 0.0009  max mem: 2502
Train: Epoch[5/5]  [ 110/1142]  eta: 0:06:04  Lr: 0.001875  Loss: -0.7252  Acc@1: 68.7500 (67.9054)  Acc@5: 93.7500 (94.2568)  time: 0.3498  data: 0.0008  max mem: 2502
Train: Epoch[5/5]  [ 120/1142]  eta: 0:06:00  Lr: 0.001875  Loss: -0.3230  Acc@1: 62.5000 (67.8202)  Acc@5: 93.7500 (94.1116)  time: 0.3491  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [ 130/1142]  eta: 0:05:56  Lr: 0.001875  Loss: -1.1361  Acc@1: 68.7500 (67.7481)  Acc@5: 93.7500 (94.0363)  time: 0.3485  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [ 140/1142]  eta: 0:05:52  Lr: 0.001875  Loss: -0.2515  Acc@1: 68.7500 (68.0851)  Acc@5: 93.7500 (94.0603)  time: 0.3482  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [ 150/1142]  eta: 0:05:48  Lr: 0.001875  Loss: -0.9698  Acc@1: 68.7500 (68.2947)  Acc@5: 93.7500 (94.0811)  time: 0.3478  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [ 160/1142]  eta: 0:05:45  Lr: 0.001875  Loss: -0.8517  Acc@1: 68.7500 (68.4006)  Acc@5: 93.7500 (94.2158)  time: 0.3479  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [ 170/1142]  eta: 0:05:41  Lr: 0.001875  Loss: -0.1909  Acc@1: 68.7500 (68.0190)  Acc@5: 93.7500 (94.1155)  time: 0.3479  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [ 180/1142]  eta: 0:05:37  Lr: 0.001875  Loss: -0.1903  Acc@1: 62.5000 (67.6796)  Acc@5: 93.7500 (94.1298)  time: 0.3479  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [ 190/1142]  eta: 0:05:33  Lr: 0.001875  Loss: -0.3207  Acc@1: 62.5000 (67.5065)  Acc@5: 93.7500 (94.0118)  time: 0.3479  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [ 200/1142]  eta: 0:05:30  Lr: 0.001875  Loss: -0.0911  Acc@1: 62.5000 (67.7239)  Acc@5: 93.7500 (94.0920)  time: 0.3477  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [ 210/1142]  eta: 0:05:26  Lr: 0.001875  Loss: -0.7569  Acc@1: 75.0000 (67.9206)  Acc@5: 100.0000 (94.1055)  time: 0.3479  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [ 220/1142]  eta: 0:05:22  Lr: 0.001875  Loss: -0.3195  Acc@1: 68.7500 (68.0430)  Acc@5: 93.7500 (94.2308)  time: 0.3471  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [ 230/1142]  eta: 0:05:19  Lr: 0.001875  Loss: -0.3622  Acc@1: 68.7500 (68.1006)  Acc@5: 93.7500 (94.0476)  time: 0.3466  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [ 240/1142]  eta: 0:05:15  Lr: 0.001875  Loss: -0.6726  Acc@1: 68.7500 (68.2313)  Acc@5: 93.7500 (94.1649)  time: 0.3469  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [ 250/1142]  eta: 0:05:12  Lr: 0.001875  Loss: -0.7676  Acc@1: 68.7500 (68.3267)  Acc@5: 100.0000 (94.1982)  time: 0.3470  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [ 260/1142]  eta: 0:05:08  Lr: 0.001875  Loss: -0.6670  Acc@1: 68.7500 (68.5105)  Acc@5: 93.7500 (94.2529)  time: 0.3478  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [ 270/1142]  eta: 0:05:05  Lr: 0.001875  Loss: -0.5831  Acc@1: 68.7500 (68.5886)  Acc@5: 93.7500 (94.3035)  time: 0.3486  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [ 280/1142]  eta: 0:05:01  Lr: 0.001875  Loss: -1.0092  Acc@1: 68.7500 (68.5943)  Acc@5: 100.0000 (94.3950)  time: 0.3484  data: 0.0007  max mem: 2502
Train: Epoch[5/5]  [ 290/1142]  eta: 0:04:57  Lr: 0.001875  Loss: -0.3265  Acc@1: 62.5000 (68.4278)  Acc@5: 100.0000 (94.4802)  time: 0.3480  data: 0.0007  max mem: 2502
Train: Epoch[5/5]  [ 300/1142]  eta: 0:04:54  Lr: 0.001875  Loss: -0.7612  Acc@1: 62.5000 (68.2101)  Acc@5: 100.0000 (94.5598)  time: 0.3484  data: 0.0006  max mem: 2502
Train: Epoch[5/5]  [ 310/1142]  eta: 0:04:50  Lr: 0.001875  Loss: -0.4563  Acc@1: 62.5000 (68.2878)  Acc@5: 100.0000 (94.5539)  time: 0.3486  data: 0.0006  max mem: 2502
Train: Epoch[5/5]  [ 320/1142]  eta: 0:04:47  Lr: 0.001875  Loss: -0.6111  Acc@1: 68.7500 (68.2438)  Acc@5: 93.7500 (94.4899)  time: 0.3488  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [ 330/1142]  eta: 0:04:43  Lr: 0.001875  Loss: -0.7261  Acc@1: 75.0000 (68.5423)  Acc@5: 93.7500 (94.5053)  time: 0.3508  data: 0.0013  max mem: 2502
Train: Epoch[5/5]  [ 340/1142]  eta: 0:04:40  Lr: 0.001875  Loss: 0.1470  Acc@1: 75.0000 (68.4567)  Acc@5: 93.7500 (94.5015)  time: 0.3511  data: 0.0022  max mem: 2502
Train: Epoch[5/5]  [ 350/1142]  eta: 0:04:36  Lr: 0.001875  Loss: -0.5367  Acc@1: 68.7500 (68.5185)  Acc@5: 93.7500 (94.5335)  time: 0.3493  data: 0.0012  max mem: 2502
Train: Epoch[5/5]  [ 360/1142]  eta: 0:04:33  Lr: 0.001875  Loss: -1.1673  Acc@1: 68.7500 (68.5942)  Acc@5: 93.7500 (94.5291)  time: 0.3488  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [ 370/1142]  eta: 0:04:29  Lr: 0.001875  Loss: -0.1573  Acc@1: 68.7500 (68.6152)  Acc@5: 93.7500 (94.5418)  time: 0.3488  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [ 380/1142]  eta: 0:04:26  Lr: 0.001875  Loss: -0.5287  Acc@1: 68.7500 (68.5203)  Acc@5: 93.7500 (94.4718)  time: 0.3485  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [ 390/1142]  eta: 0:04:22  Lr: 0.001875  Loss: -0.4466  Acc@1: 68.7500 (68.5582)  Acc@5: 93.7500 (94.4533)  time: 0.3485  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [ 400/1142]  eta: 0:04:19  Lr: 0.001875  Loss: -0.8998  Acc@1: 68.7500 (68.5941)  Acc@5: 100.0000 (94.4981)  time: 0.3499  data: 0.0006  max mem: 2502
Train: Epoch[5/5]  [ 410/1142]  eta: 0:04:15  Lr: 0.001875  Loss: -0.4115  Acc@1: 75.0000 (68.6131)  Acc@5: 93.7500 (94.4647)  time: 0.3500  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [ 420/1142]  eta: 0:04:12  Lr: 0.001875  Loss: -0.2544  Acc@1: 75.0000 (68.5273)  Acc@5: 93.7500 (94.4774)  time: 0.3490  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [ 430/1142]  eta: 0:04:08  Lr: 0.001875  Loss: -0.5513  Acc@1: 75.0000 (68.5615)  Acc@5: 93.7500 (94.4896)  time: 0.3496  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [ 440/1142]  eta: 0:04:05  Lr: 0.001875  Loss: -0.6279  Acc@1: 75.0000 (68.6650)  Acc@5: 93.7500 (94.5011)  time: 0.3500  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [ 450/1142]  eta: 0:04:01  Lr: 0.001875  Loss: -0.2938  Acc@1: 75.0000 (68.6807)  Acc@5: 93.7500 (94.4983)  time: 0.3498  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [ 460/1142]  eta: 0:03:58  Lr: 0.001875  Loss: -0.6883  Acc@1: 68.7500 (68.7229)  Acc@5: 93.7500 (94.4279)  time: 0.3500  data: 0.0013  max mem: 2502
Train: Epoch[5/5]  [ 470/1142]  eta: 0:03:54  Lr: 0.001875  Loss: -0.1801  Acc@1: 68.7500 (68.7235)  Acc@5: 93.7500 (94.3471)  time: 0.3506  data: 0.0013  max mem: 2502
Train: Epoch[5/5]  [ 480/1142]  eta: 0:03:51  Lr: 0.001875  Loss: -1.0329  Acc@1: 68.7500 (68.8150)  Acc@5: 93.7500 (94.3607)  time: 0.3507  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [ 490/1142]  eta: 0:03:47  Lr: 0.001875  Loss: -0.0269  Acc@1: 68.7500 (68.7755)  Acc@5: 93.7500 (94.2974)  time: 0.3504  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [ 500/1142]  eta: 0:03:44  Lr: 0.001875  Loss: -0.5516  Acc@1: 68.7500 (68.7874)  Acc@5: 93.7500 (94.2989)  time: 0.3506  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [ 510/1142]  eta: 0:03:41  Lr: 0.001875  Loss: -0.3824  Acc@1: 68.7500 (68.6888)  Acc@5: 93.7500 (94.2759)  time: 0.3511  data: 0.0009  max mem: 2502
Train: Epoch[5/5]  [ 520/1142]  eta: 0:03:37  Lr: 0.001875  Loss: -0.8108  Acc@1: 68.7500 (68.7980)  Acc@5: 93.7500 (94.2898)  time: 0.3506  data: 0.0009  max mem: 2502
Train: Epoch[5/5]  [ 530/1142]  eta: 0:03:34  Lr: 0.001875  Loss: -0.6992  Acc@1: 68.7500 (68.7147)  Acc@5: 93.7500 (94.3150)  time: 0.3492  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [ 540/1142]  eta: 0:03:30  Lr: 0.001875  Loss: -1.0084  Acc@1: 68.7500 (68.8193)  Acc@5: 93.7500 (94.3276)  time: 0.3489  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [ 550/1142]  eta: 0:03:27  Lr: 0.001875  Loss: -0.6680  Acc@1: 75.0000 (68.9882)  Acc@5: 100.0000 (94.3512)  time: 0.3493  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [ 560/1142]  eta: 0:03:23  Lr: 0.001875  Loss: -0.6670  Acc@1: 75.0000 (69.0397)  Acc@5: 93.7500 (94.3293)  time: 0.3498  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [ 570/1142]  eta: 0:03:20  Lr: 0.001875  Loss: -0.3785  Acc@1: 75.0000 (69.1878)  Acc@5: 93.7500 (94.3630)  time: 0.3500  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [ 580/1142]  eta: 0:03:16  Lr: 0.001875  Loss: -0.8261  Acc@1: 75.0000 (69.2448)  Acc@5: 100.0000 (94.4277)  time: 0.3498  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [ 590/1142]  eta: 0:03:13  Lr: 0.001875  Loss: -0.5354  Acc@1: 68.7500 (69.2576)  Acc@5: 93.7500 (94.3739)  time: 0.3497  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [ 600/1142]  eta: 0:03:09  Lr: 0.001875  Loss: -0.1522  Acc@1: 68.7500 (69.3428)  Acc@5: 93.7500 (94.4156)  time: 0.3491  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [ 610/1142]  eta: 0:03:06  Lr: 0.001875  Loss: -0.5061  Acc@1: 62.5000 (69.2001)  Acc@5: 93.7500 (94.4047)  time: 0.3487  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [ 620/1142]  eta: 0:03:02  Lr: 0.001875  Loss: -0.3374  Acc@1: 62.5000 (69.0721)  Acc@5: 93.7500 (94.4143)  time: 0.3488  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [ 630/1142]  eta: 0:02:59  Lr: 0.001875  Loss: -0.5257  Acc@1: 68.7500 (69.0868)  Acc@5: 93.7500 (94.4136)  time: 0.3484  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [ 640/1142]  eta: 0:02:55  Lr: 0.001875  Loss: -0.5056  Acc@1: 68.7500 (69.0913)  Acc@5: 93.7500 (94.4033)  time: 0.3483  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [ 650/1142]  eta: 0:02:51  Lr: 0.001875  Loss: -0.3070  Acc@1: 68.7500 (69.0380)  Acc@5: 93.7500 (94.3932)  time: 0.3480  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [ 660/1142]  eta: 0:02:48  Lr: 0.001875  Loss: -0.6844  Acc@1: 68.7500 (69.0242)  Acc@5: 93.7500 (94.4024)  time: 0.3473  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [ 670/1142]  eta: 0:02:44  Lr: 0.001875  Loss: 0.0071  Acc@1: 68.7500 (68.9549)  Acc@5: 93.7500 (94.3834)  time: 0.3473  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [ 680/1142]  eta: 0:02:41  Lr: 0.001875  Loss: -0.3075  Acc@1: 68.7500 (69.0070)  Acc@5: 93.7500 (94.3924)  time: 0.3476  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [ 690/1142]  eta: 0:02:37  Lr: 0.001875  Loss: 0.3768  Acc@1: 75.0000 (68.9942)  Acc@5: 93.7500 (94.4103)  time: 0.3475  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [ 700/1142]  eta: 0:02:34  Lr: 0.001875  Loss: -0.9732  Acc@1: 68.7500 (69.0442)  Acc@5: 100.0000 (94.4454)  time: 0.3483  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [ 710/1142]  eta: 0:02:30  Lr: 0.001875  Loss: -0.5405  Acc@1: 68.7500 (69.0049)  Acc@5: 93.7500 (94.4269)  time: 0.3489  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [ 720/1142]  eta: 0:02:27  Lr: 0.001875  Loss: -0.6212  Acc@1: 62.5000 (68.9754)  Acc@5: 93.7500 (94.4088)  time: 0.3488  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [ 730/1142]  eta: 0:02:23  Lr: 0.001875  Loss: -0.3278  Acc@1: 68.7500 (69.0065)  Acc@5: 93.7500 (94.3998)  time: 0.3487  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [ 740/1142]  eta: 0:02:20  Lr: 0.001875  Loss: -0.9683  Acc@1: 68.7500 (68.9862)  Acc@5: 93.7500 (94.4079)  time: 0.3491  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [ 750/1142]  eta: 0:02:16  Lr: 0.001875  Loss: -0.9074  Acc@1: 75.0000 (69.0995)  Acc@5: 100.0000 (94.4407)  time: 0.3497  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [ 760/1142]  eta: 0:02:13  Lr: 0.001875  Loss: -0.2032  Acc@1: 75.0000 (69.0867)  Acc@5: 93.7500 (94.4399)  time: 0.3490  data: 0.0007  max mem: 2502
Train: Epoch[5/5]  [ 770/1142]  eta: 0:02:09  Lr: 0.001875  Loss: -0.1002  Acc@1: 68.7500 (69.1067)  Acc@5: 93.7500 (94.4553)  time: 0.3486  data: 0.0007  max mem: 2502
Train: Epoch[5/5]  [ 780/1142]  eta: 0:02:06  Lr: 0.001875  Loss: -0.1894  Acc@1: 68.7500 (69.0621)  Acc@5: 93.7500 (94.4702)  time: 0.3481  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [ 790/1142]  eta: 0:02:02  Lr: 0.001875  Loss: -0.2113  Acc@1: 62.5000 (68.9949)  Acc@5: 93.7500 (94.4216)  time: 0.3482  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [ 800/1142]  eta: 0:01:59  Lr: 0.001875  Loss: -0.4228  Acc@1: 68.7500 (69.0387)  Acc@5: 93.7500 (94.4054)  time: 0.3491  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [ 810/1142]  eta: 0:01:56  Lr: 0.001875  Loss: -0.9997  Acc@1: 75.0000 (69.1507)  Acc@5: 93.7500 (94.4282)  time: 0.3506  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [ 820/1142]  eta: 0:01:52  Lr: 0.001875  Loss: -1.0747  Acc@1: 75.0000 (69.1382)  Acc@5: 100.0000 (94.4656)  time: 0.3510  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [ 830/1142]  eta: 0:01:49  Lr: 0.001875  Loss: -0.6311  Acc@1: 68.7500 (69.1862)  Acc@5: 93.7500 (94.4344)  time: 0.3499  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [ 840/1142]  eta: 0:01:45  Lr: 0.001875  Loss: -0.8385  Acc@1: 68.7500 (69.1885)  Acc@5: 93.7500 (94.4263)  time: 0.3507  data: 0.0005  max mem: 2502
Train: Epoch[5/5]  [ 850/1142]  eta: 0:01:42  Lr: 0.001875  Loss: -0.8836  Acc@1: 68.7500 (69.1613)  Acc@5: 93.7500 (94.4330)  time: 0.3505  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [ 860/1142]  eta: 0:01:38  Lr: 0.001875  Loss: -0.6850  Acc@1: 68.7500 (69.1855)  Acc@5: 93.7500 (94.4323)  time: 0.3495  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [ 870/1142]  eta: 0:01:35  Lr: 0.001875  Loss: -0.3831  Acc@1: 68.7500 (69.1662)  Acc@5: 93.7500 (94.3886)  time: 0.3505  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [ 880/1142]  eta: 0:01:31  Lr: 0.001875  Loss: -0.6611  Acc@1: 68.7500 (69.1402)  Acc@5: 93.7500 (94.3601)  time: 0.3513  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [ 890/1142]  eta: 0:01:28  Lr: 0.001875  Loss: -0.3661  Acc@1: 68.7500 (69.1148)  Acc@5: 93.7500 (94.3743)  time: 0.3506  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [ 900/1142]  eta: 0:01:24  Lr: 0.001875  Loss: -0.4811  Acc@1: 68.7500 (69.1662)  Acc@5: 93.7500 (94.3812)  time: 0.3500  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [ 910/1142]  eta: 0:01:21  Lr: 0.001875  Loss: -0.8422  Acc@1: 68.7500 (69.1136)  Acc@5: 93.7500 (94.3743)  time: 0.3497  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [ 920/1142]  eta: 0:01:17  Lr: 0.001875  Loss: -0.7512  Acc@1: 68.7500 (69.1232)  Acc@5: 93.7500 (94.3743)  time: 0.3504  data: 0.0006  max mem: 2502
Train: Epoch[5/5]  [ 930/1142]  eta: 0:01:14  Lr: 0.001875  Loss: -0.0758  Acc@1: 68.7500 (69.0857)  Acc@5: 93.7500 (94.4012)  time: 0.3508  data: 0.0006  max mem: 2502
Train: Epoch[5/5]  [ 940/1142]  eta: 0:01:10  Lr: 0.001875  Loss: -0.8743  Acc@1: 62.5000 (69.0290)  Acc@5: 93.7500 (94.3810)  time: 0.3501  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [ 950/1142]  eta: 0:01:07  Lr: 0.001875  Loss: -0.6522  Acc@1: 68.7500 (69.0260)  Acc@5: 93.7500 (94.3743)  time: 0.3499  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [ 960/1142]  eta: 0:01:03  Lr: 0.001875  Loss: -0.4476  Acc@1: 68.7500 (68.9711)  Acc@5: 93.7500 (94.3678)  time: 0.3506  data: 0.0012  max mem: 2502
Train: Epoch[5/5]  [ 970/1142]  eta: 0:01:00  Lr: 0.001875  Loss: -0.4584  Acc@1: 62.5000 (68.9624)  Acc@5: 93.7500 (94.3357)  time: 0.3509  data: 0.0013  max mem: 2502
Train: Epoch[5/5]  [ 980/1142]  eta: 0:00:56  Lr: 0.001875  Loss: -0.7733  Acc@1: 62.5000 (68.9666)  Acc@5: 93.7500 (94.3361)  time: 0.3511  data: 0.0012  max mem: 2502
Train: Epoch[5/5]  [ 990/1142]  eta: 0:00:53  Lr: 0.001875  Loss: -0.1991  Acc@1: 68.7500 (68.9897)  Acc@5: 93.7500 (94.3113)  time: 0.3513  data: 0.0011  max mem: 2502
Train: Epoch[5/5]  [1000/1142]  eta: 0:00:49  Lr: 0.001875  Loss: -0.6068  Acc@1: 68.7500 (68.9373)  Acc@5: 93.7500 (94.2932)  time: 0.3505  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [1010/1142]  eta: 0:00:46  Lr: 0.001875  Loss: -0.3635  Acc@1: 62.5000 (68.9045)  Acc@5: 93.7500 (94.2817)  time: 0.3503  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [1020/1142]  eta: 0:00:42  Lr: 0.001875  Loss: -0.5983  Acc@1: 75.0000 (68.9887)  Acc@5: 93.7500 (94.2887)  time: 0.3500  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [1030/1142]  eta: 0:00:39  Lr: 0.001875  Loss: -0.3988  Acc@1: 68.7500 (68.9864)  Acc@5: 93.7500 (94.2592)  time: 0.3495  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [1040/1142]  eta: 0:00:35  Lr: 0.001875  Loss: -0.3063  Acc@1: 68.7500 (68.9781)  Acc@5: 93.7500 (94.2723)  time: 0.3503  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [1050/1142]  eta: 0:00:32  Lr: 0.001875  Loss: -0.9969  Acc@1: 62.5000 (68.9581)  Acc@5: 93.7500 (94.2674)  time: 0.3513  data: 0.0010  max mem: 2502
Train: Epoch[5/5]  [1060/1142]  eta: 0:00:28  Lr: 0.001875  Loss: -0.3330  Acc@1: 62.5000 (68.9444)  Acc@5: 93.7500 (94.2625)  time: 0.3507  data: 0.0010  max mem: 2502
Train: Epoch[5/5]  [1070/1142]  eta: 0:00:25  Lr: 0.001875  Loss: -0.1298  Acc@1: 68.7500 (68.9426)  Acc@5: 93.7500 (94.2694)  time: 0.3497  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [1080/1142]  eta: 0:00:21  Lr: 0.001875  Loss: -0.7830  Acc@1: 68.7500 (68.9524)  Acc@5: 100.0000 (94.2993)  time: 0.3511  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [1090/1142]  eta: 0:00:18  Lr: 0.001875  Loss: -0.7604  Acc@1: 62.5000 (68.9047)  Acc@5: 100.0000 (94.3114)  time: 0.3515  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [1100/1142]  eta: 0:00:14  Lr: 0.001875  Loss: -0.1133  Acc@1: 62.5000 (68.8976)  Acc@5: 93.7500 (94.3006)  time: 0.3508  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [1110/1142]  eta: 0:00:11  Lr: 0.001875  Loss: -0.4127  Acc@1: 68.7500 (68.8963)  Acc@5: 93.7500 (94.3126)  time: 0.3503  data: 0.0004  max mem: 2502
Train: Epoch[5/5]  [1120/1142]  eta: 0:00:07  Lr: 0.001875  Loss: -0.3251  Acc@1: 68.7500 (68.9005)  Acc@5: 93.7500 (94.3187)  time: 0.3498  data: 0.0003  max mem: 2502
Train: Epoch[5/5]  [1130/1142]  eta: 0:00:04  Lr: 0.001875  Loss: -0.7264  Acc@1: 68.7500 (68.9158)  Acc@5: 93.7500 (94.3081)  time: 0.3514  data: 0.0011  max mem: 2502
Train: Epoch[5/5]  [1140/1142]  eta: 0:00:00  Lr: 0.001875  Loss: -0.5198  Acc@1: 68.7500 (68.9198)  Acc@5: 93.7500 (94.3142)  time: 0.3515  data: 0.0011  max mem: 2502
Train: Epoch[5/5]  [1141/1142]  eta: 0:00:00  Lr: 0.001875  Loss: 0.0342  Acc@1: 68.7500 (68.9077)  Acc@5: 93.7500 (94.3115)  time: 0.3439  data: 0.0011  max mem: 2502
Train: Epoch[5/5] Total time: 0:06:39 (0.3498 s / it)
Averaged stats: Lr: 0.001875  Loss: 0.0342  Acc@1: 68.7500 (68.9077)  Acc@5: 93.7500 (94.3115)
Test: [Task 1]  [   0/1627]  eta: 0:14:38  Loss: 3.2033 (3.2033)  Acc@1: 31.2500 (31.2500)  Acc@5: 43.7500 (43.7500)  time: 0.5400  data: 0.3191  max mem: 2502
Test: [Task 1]  [  10/1627]  eta: 0:06:41  Loss: 2.9420 (2.9880)  Acc@1: 25.0000 (26.7045)  Acc@5: 56.2500 (53.9773)  time: 0.2481  data: 0.0293  max mem: 2502
Test: [Task 1]  [  20/1627]  eta: 0:06:15  Loss: 2.9387 (2.9289)  Acc@1: 25.0000 (26.1905)  Acc@5: 56.2500 (56.2500)  time: 0.2184  data: 0.0003  max mem: 2502
Test: [Task 1]  [  30/1627]  eta: 0:06:05  Loss: 3.1492 (3.0207)  Acc@1: 18.7500 (23.1855)  Acc@5: 50.0000 (54.2339)  time: 0.2183  data: 0.0003  max mem: 2502
Test: [Task 1]  [  40/1627]  eta: 0:05:59  Loss: 3.1737 (3.0553)  Acc@1: 12.5000 (22.4085)  Acc@5: 50.0000 (52.7439)  time: 0.2195  data: 0.0011  max mem: 2502
Test: [Task 1]  [  50/1627]  eta: 0:05:55  Loss: 3.1646 (3.0443)  Acc@1: 18.7500 (22.1814)  Acc@5: 50.0000 (52.9412)  time: 0.2196  data: 0.0010  max mem: 2502
Test: [Task 1]  [  60/1627]  eta: 0:05:51  Loss: 3.1641 (3.0635)  Acc@1: 25.0000 (22.1311)  Acc@5: 50.0000 (52.5615)  time: 0.2192  data: 0.0006  max mem: 2502
Test: [Task 1]  [  70/1627]  eta: 0:05:47  Loss: 3.1641 (3.0723)  Acc@1: 25.0000 (22.0951)  Acc@5: 50.0000 (51.6725)  time: 0.2190  data: 0.0006  max mem: 2502
Test: [Task 1]  [  80/1627]  eta: 0:05:44  Loss: 3.0174 (3.0541)  Acc@1: 18.7500 (22.2222)  Acc@5: 50.0000 (52.7778)  time: 0.2181  data: 0.0003  max mem: 2502
Test: [Task 1]  [  90/1627]  eta: 0:05:41  Loss: 2.9691 (3.0491)  Acc@1: 18.7500 (22.1154)  Acc@5: 56.2500 (53.5027)  time: 0.2181  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 100/1627]  eta: 0:05:38  Loss: 2.9691 (3.0509)  Acc@1: 25.0000 (22.0297)  Acc@5: 56.2500 (53.5272)  time: 0.2188  data: 0.0008  max mem: 2502
Test: [Task 1]  [ 110/1627]  eta: 0:05:36  Loss: 3.0816 (3.0639)  Acc@1: 18.7500 (21.5090)  Acc@5: 50.0000 (52.7590)  time: 0.2193  data: 0.0011  max mem: 2502
Test: [Task 1]  [ 120/1627]  eta: 0:05:33  Loss: 3.2202 (3.0672)  Acc@1: 18.7500 (21.5909)  Acc@5: 43.7500 (52.1694)  time: 0.2192  data: 0.0007  max mem: 2502
Test: [Task 1]  [ 130/1627]  eta: 0:05:31  Loss: 3.0635 (3.0617)  Acc@1: 25.0000 (21.8989)  Acc@5: 43.7500 (52.4332)  time: 0.2182  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 140/1627]  eta: 0:05:28  Loss: 2.8656 (3.0487)  Acc@1: 25.0000 (22.2961)  Acc@5: 56.2500 (52.8369)  time: 0.2175  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 150/1627]  eta: 0:05:25  Loss: 2.7761 (3.0358)  Acc@1: 25.0000 (22.6407)  Acc@5: 62.5000 (53.4354)  time: 0.2170  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 160/1627]  eta: 0:05:23  Loss: 2.7824 (3.0359)  Acc@1: 25.0000 (22.5543)  Acc@5: 56.2500 (53.2609)  time: 0.2170  data: 0.0004  max mem: 2502
Test: [Task 1]  [ 170/1627]  eta: 0:05:20  Loss: 2.9326 (3.0299)  Acc@1: 18.7500 (22.5877)  Acc@5: 56.2500 (53.6184)  time: 0.2171  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 180/1627]  eta: 0:05:18  Loss: 2.9723 (3.0339)  Acc@1: 18.7500 (22.2721)  Acc@5: 56.2500 (53.4185)  time: 0.2167  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 190/1627]  eta: 0:05:16  Loss: 3.0781 (3.0324)  Acc@1: 18.7500 (22.1531)  Acc@5: 56.2500 (53.3050)  time: 0.2173  data: 0.0008  max mem: 2502
Test: [Task 1]  [ 200/1627]  eta: 0:05:13  Loss: 3.1032 (3.0445)  Acc@1: 12.5000 (21.7662)  Acc@5: 50.0000 (52.8296)  time: 0.2174  data: 0.0009  max mem: 2502
Test: [Task 1]  [ 210/1627]  eta: 0:05:11  Loss: 3.1985 (3.0515)  Acc@1: 12.5000 (21.5936)  Acc@5: 43.7500 (52.4882)  time: 0.2172  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 220/1627]  eta: 0:05:08  Loss: 3.1618 (3.0612)  Acc@1: 12.5000 (21.4367)  Acc@5: 50.0000 (52.5170)  time: 0.2168  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 230/1627]  eta: 0:05:06  Loss: 3.1618 (3.0637)  Acc@1: 12.5000 (21.4286)  Acc@5: 50.0000 (52.4621)  time: 0.2166  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 240/1627]  eta: 0:05:04  Loss: 2.9165 (3.0542)  Acc@1: 25.0000 (21.7324)  Acc@5: 56.2500 (52.6452)  time: 0.2166  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 250/1627]  eta: 0:05:01  Loss: 2.8493 (3.0543)  Acc@1: 25.0000 (21.7878)  Acc@5: 56.2500 (52.6643)  time: 0.2163  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 260/1627]  eta: 0:04:59  Loss: 3.0945 (3.0569)  Acc@1: 18.7500 (21.7433)  Acc@5: 50.0000 (52.4425)  time: 0.2171  data: 0.0006  max mem: 2502
Test: [Task 1]  [ 270/1627]  eta: 0:04:57  Loss: 2.9513 (3.0521)  Acc@1: 25.0000 (21.7943)  Acc@5: 50.0000 (52.5369)  time: 0.2174  data: 0.0006  max mem: 2502
Test: [Task 1]  [ 280/1627]  eta: 0:04:54  Loss: 3.0411 (3.0548)  Acc@1: 25.0000 (21.7972)  Acc@5: 56.2500 (52.5133)  time: 0.2167  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 290/1627]  eta: 0:04:52  Loss: 3.1279 (3.0530)  Acc@1: 25.0000 (21.8428)  Acc@5: 50.0000 (52.5344)  time: 0.2169  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 300/1627]  eta: 0:04:50  Loss: 3.0854 (3.0509)  Acc@1: 18.7500 (21.8439)  Acc@5: 50.0000 (52.6578)  time: 0.2170  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 310/1627]  eta: 0:04:48  Loss: 2.9530 (3.0500)  Acc@1: 18.7500 (21.7042)  Acc@5: 56.2500 (52.7934)  time: 0.2172  data: 0.0004  max mem: 2502
Test: [Task 1]  [ 320/1627]  eta: 0:04:45  Loss: 3.0243 (3.0546)  Acc@1: 18.7500 (21.4953)  Acc@5: 50.0000 (52.5701)  time: 0.2181  data: 0.0010  max mem: 2502
Test: [Task 1]  [ 330/1627]  eta: 0:04:43  Loss: 3.0972 (3.0540)  Acc@1: 18.7500 (21.5068)  Acc@5: 50.0000 (52.6435)  time: 0.2178  data: 0.0011  max mem: 2502
Test: [Task 1]  [ 340/1627]  eta: 0:04:41  Loss: 3.1608 (3.0578)  Acc@1: 18.7500 (21.3160)  Acc@5: 56.2500 (52.6943)  time: 0.2173  data: 0.0005  max mem: 2502
Test: [Task 1]  [ 350/1627]  eta: 0:04:39  Loss: 3.1120 (3.0582)  Acc@1: 12.5000 (21.2251)  Acc@5: 56.2500 (52.7600)  time: 0.2170  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 360/1627]  eta: 0:04:36  Loss: 3.1056 (3.0576)  Acc@1: 18.7500 (21.1392)  Acc@5: 56.2500 (52.7874)  time: 0.2169  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 370/1627]  eta: 0:04:34  Loss: 3.1185 (3.0610)  Acc@1: 18.7500 (21.0748)  Acc@5: 50.0000 (52.7123)  time: 0.2183  data: 0.0014  max mem: 2502
Test: [Task 1]  [ 380/1627]  eta: 0:04:32  Loss: 3.1202 (3.0626)  Acc@1: 18.7500 (21.0958)  Acc@5: 50.0000 (52.5098)  time: 0.2183  data: 0.0013  max mem: 2502
Test: [Task 1]  [ 390/1627]  eta: 0:04:30  Loss: 3.0611 (3.0610)  Acc@1: 25.0000 (21.1157)  Acc@5: 50.0000 (52.5575)  time: 0.2171  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 400/1627]  eta: 0:04:28  Loss: 3.0611 (3.0640)  Acc@1: 18.7500 (21.0100)  Acc@5: 50.0000 (52.4626)  time: 0.2172  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 410/1627]  eta: 0:04:25  Loss: 3.1626 (3.0639)  Acc@1: 18.7500 (21.0462)  Acc@5: 56.2500 (52.6460)  time: 0.2178  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 420/1627]  eta: 0:04:23  Loss: 2.9221 (3.0614)  Acc@1: 18.7500 (21.1253)  Acc@5: 56.2500 (52.6722)  time: 0.2183  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 430/1627]  eta: 0:04:21  Loss: 2.8276 (3.0584)  Acc@1: 18.7500 (21.0702)  Acc@5: 56.2500 (52.8277)  time: 0.2185  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 440/1627]  eta: 0:04:19  Loss: 2.9025 (3.0565)  Acc@1: 12.5000 (21.0459)  Acc@5: 56.2500 (52.9620)  time: 0.2192  data: 0.0007  max mem: 2502
Test: [Task 1]  [ 450/1627]  eta: 0:04:17  Loss: 3.0482 (3.0610)  Acc@1: 18.7500 (20.8980)  Acc@5: 56.2500 (52.9102)  time: 0.2193  data: 0.0007  max mem: 2502
Test: [Task 1]  [ 460/1627]  eta: 0:04:15  Loss: 3.0420 (3.0620)  Acc@1: 18.7500 (20.9056)  Acc@5: 50.0000 (52.9013)  time: 0.2187  data: 0.0004  max mem: 2502
Test: [Task 1]  [ 470/1627]  eta: 0:04:12  Loss: 3.0098 (3.0593)  Acc@1: 25.0000 (21.0987)  Acc@5: 56.2500 (52.9857)  time: 0.2188  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 480/1627]  eta: 0:04:10  Loss: 3.0293 (3.0618)  Acc@1: 18.7500 (20.9330)  Acc@5: 56.2500 (52.9886)  time: 0.2191  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 490/1627]  eta: 0:04:08  Loss: 3.0725 (3.0632)  Acc@1: 12.5000 (20.8885)  Acc@5: 50.0000 (52.9022)  time: 0.2192  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 500/1627]  eta: 0:04:06  Loss: 2.9430 (3.0636)  Acc@1: 18.7500 (20.8333)  Acc@5: 50.0000 (52.8443)  time: 0.2188  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 510/1627]  eta: 0:04:04  Loss: 3.1875 (3.0660)  Acc@1: 18.7500 (20.8293)  Acc@5: 50.0000 (52.7397)  time: 0.2190  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 520/1627]  eta: 0:04:01  Loss: 3.1902 (3.0691)  Acc@1: 18.7500 (20.8013)  Acc@5: 50.0000 (52.7111)  time: 0.2193  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 530/1627]  eta: 0:03:59  Loss: 2.8117 (3.0608)  Acc@1: 18.7500 (20.9510)  Acc@5: 62.5000 (52.9661)  time: 0.2189  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 540/1627]  eta: 0:03:57  Loss: 2.6888 (3.0597)  Acc@1: 25.0000 (20.9566)  Acc@5: 62.5000 (52.9806)  time: 0.2186  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 550/1627]  eta: 0:03:55  Loss: 3.2140 (3.0636)  Acc@1: 12.5000 (20.8144)  Acc@5: 43.7500 (52.8471)  time: 0.2188  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 560/1627]  eta: 0:03:53  Loss: 3.0524 (3.0633)  Acc@1: 12.5000 (20.6774)  Acc@5: 50.0000 (52.8966)  time: 0.2188  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 570/1627]  eta: 0:03:51  Loss: 2.9869 (3.0618)  Acc@1: 12.5000 (20.6874)  Acc@5: 56.2500 (52.9991)  time: 0.2189  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 580/1627]  eta: 0:03:48  Loss: 2.9653 (3.0634)  Acc@1: 18.7500 (20.6648)  Acc@5: 56.2500 (53.0120)  time: 0.2191  data: 0.0004  max mem: 2502
Test: [Task 1]  [ 590/1627]  eta: 0:03:46  Loss: 3.1017 (3.0649)  Acc@1: 18.7500 (20.6113)  Acc@5: 56.2500 (53.0245)  time: 0.2193  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 600/1627]  eta: 0:03:44  Loss: 3.1017 (3.0643)  Acc@1: 18.7500 (20.6635)  Acc@5: 56.2500 (53.0678)  time: 0.2202  data: 0.0008  max mem: 2502
Test: [Task 1]  [ 610/1627]  eta: 0:03:42  Loss: 2.9284 (3.0624)  Acc@1: 25.0000 (20.7140)  Acc@5: 56.2500 (53.0687)  time: 0.2198  data: 0.0008  max mem: 2502
Test: [Task 1]  [ 620/1627]  eta: 0:03:40  Loss: 3.0877 (3.0644)  Acc@1: 25.0000 (20.7327)  Acc@5: 50.0000 (52.9287)  time: 0.2192  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 630/1627]  eta: 0:03:38  Loss: 3.0910 (3.0619)  Acc@1: 25.0000 (20.7706)  Acc@5: 50.0000 (52.9814)  time: 0.2188  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 640/1627]  eta: 0:03:35  Loss: 2.9513 (3.0617)  Acc@1: 25.0000 (20.7976)  Acc@5: 56.2500 (53.0031)  time: 0.2189  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 650/1627]  eta: 0:03:33  Loss: 3.0120 (3.0610)  Acc@1: 18.7500 (20.7853)  Acc@5: 50.0000 (53.0530)  time: 0.2194  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 660/1627]  eta: 0:03:31  Loss: 3.0022 (3.0593)  Acc@1: 18.7500 (20.7924)  Acc@5: 50.0000 (53.0257)  time: 0.2188  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 670/1627]  eta: 0:03:29  Loss: 3.0336 (3.0599)  Acc@1: 25.0000 (20.8458)  Acc@5: 50.0000 (53.0086)  time: 0.2188  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 680/1627]  eta: 0:03:27  Loss: 3.1108 (3.0601)  Acc@1: 25.0000 (20.9068)  Acc@5: 50.0000 (53.0103)  time: 0.2193  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 690/1627]  eta: 0:03:24  Loss: 3.0743 (3.0595)  Acc@1: 25.0000 (20.9931)  Acc@5: 50.0000 (53.0119)  time: 0.2194  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 700/1627]  eta: 0:03:22  Loss: 3.0600 (3.0598)  Acc@1: 25.0000 (21.0146)  Acc@5: 56.2500 (53.0403)  time: 0.2186  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 710/1627]  eta: 0:03:20  Loss: 2.8481 (3.0560)  Acc@1: 25.0000 (21.1146)  Acc@5: 56.2500 (53.1909)  time: 0.2190  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 720/1627]  eta: 0:03:18  Loss: 2.8376 (3.0559)  Acc@1: 18.7500 (21.1078)  Acc@5: 56.2500 (53.1900)  time: 0.2191  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 730/1627]  eta: 0:03:16  Loss: 3.0550 (3.0561)  Acc@1: 18.7500 (21.1098)  Acc@5: 50.0000 (53.1720)  time: 0.2188  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 740/1627]  eta: 0:03:14  Loss: 3.1623 (3.0580)  Acc@1: 18.7500 (21.0695)  Acc@5: 50.0000 (53.1461)  time: 0.2192  data: 0.0004  max mem: 2502
Test: [Task 1]  [ 750/1627]  eta: 0:03:11  Loss: 3.0588 (3.0591)  Acc@1: 18.7500 (21.0303)  Acc@5: 50.0000 (53.1292)  time: 0.2192  data: 0.0004  max mem: 2502
Test: [Task 1]  [ 760/1627]  eta: 0:03:09  Loss: 3.1472 (3.0610)  Acc@1: 18.7500 (20.9675)  Acc@5: 50.0000 (53.0552)  time: 0.2188  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 770/1627]  eta: 0:03:07  Loss: 3.2153 (3.0603)  Acc@1: 12.5000 (20.9387)  Acc@5: 50.0000 (53.0804)  time: 0.2185  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 780/1627]  eta: 0:03:05  Loss: 3.1022 (3.0619)  Acc@1: 18.7500 (20.9427)  Acc@5: 50.0000 (53.0010)  time: 0.2193  data: 0.0008  max mem: 2502
Test: [Task 1]  [ 790/1627]  eta: 0:03:03  Loss: 3.1559 (3.0626)  Acc@1: 18.7500 (20.9071)  Acc@5: 43.7500 (52.9867)  time: 0.2189  data: 0.0008  max mem: 2502
Test: [Task 1]  [ 800/1627]  eta: 0:03:00  Loss: 3.1559 (3.0632)  Acc@1: 18.7500 (20.9270)  Acc@5: 43.7500 (52.9338)  time: 0.2176  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 810/1627]  eta: 0:02:58  Loss: 3.2013 (3.0654)  Acc@1: 18.7500 (20.8924)  Acc@5: 43.7500 (52.8822)  time: 0.2176  data: 0.0004  max mem: 2502
Test: [Task 1]  [ 820/1627]  eta: 0:02:56  Loss: 3.1871 (3.0653)  Acc@1: 18.7500 (20.8739)  Acc@5: 50.0000 (52.8928)  time: 0.2179  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 830/1627]  eta: 0:02:54  Loss: 3.0055 (3.0654)  Acc@1: 18.7500 (20.8785)  Acc@5: 50.0000 (52.9182)  time: 0.2191  data: 0.0009  max mem: 2502
Test: [Task 1]  [ 840/1627]  eta: 0:02:52  Loss: 2.9427 (3.0641)  Acc@1: 18.7500 (20.9052)  Acc@5: 56.2500 (52.9875)  time: 0.2189  data: 0.0009  max mem: 2502
Test: [Task 1]  [ 850/1627]  eta: 0:02:49  Loss: 3.0744 (3.0676)  Acc@1: 18.7500 (20.8358)  Acc@5: 50.0000 (52.8863)  time: 0.2185  data: 0.0012  max mem: 2502
Test: [Task 1]  [ 860/1627]  eta: 0:02:47  Loss: 3.2510 (3.0663)  Acc@1: 18.7500 (20.8841)  Acc@5: 43.7500 (52.9399)  time: 0.2186  data: 0.0011  max mem: 2502
Test: [Task 1]  [ 870/1627]  eta: 0:02:45  Loss: 2.8698 (3.0642)  Acc@1: 25.0000 (20.9386)  Acc@5: 56.2500 (52.9707)  time: 0.2174  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 880/1627]  eta: 0:02:43  Loss: 3.0075 (3.0662)  Acc@1: 18.7500 (20.8641)  Acc@5: 50.0000 (52.9157)  time: 0.2173  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 890/1627]  eta: 0:02:41  Loss: 3.2552 (3.0675)  Acc@1: 18.7500 (20.8544)  Acc@5: 43.7500 (52.8479)  time: 0.2176  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 900/1627]  eta: 0:02:38  Loss: 3.1524 (3.0672)  Acc@1: 18.7500 (20.8657)  Acc@5: 50.0000 (52.8579)  time: 0.2175  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 910/1627]  eta: 0:02:36  Loss: 3.1524 (3.0674)  Acc@1: 18.7500 (20.8836)  Acc@5: 56.2500 (52.8677)  time: 0.2175  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 920/1627]  eta: 0:02:34  Loss: 2.9989 (3.0669)  Acc@1: 12.5000 (20.8673)  Acc@5: 56.2500 (52.8841)  time: 0.2181  data: 0.0007  max mem: 2502
Test: [Task 1]  [ 930/1627]  eta: 0:02:32  Loss: 2.9989 (3.0658)  Acc@1: 18.7500 (20.8915)  Acc@5: 56.2500 (52.9740)  time: 0.2179  data: 0.0007  max mem: 2502
Test: [Task 1]  [ 940/1627]  eta: 0:02:30  Loss: 3.0410 (3.0663)  Acc@1: 18.7500 (20.8621)  Acc@5: 50.0000 (52.9423)  time: 0.2178  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 950/1627]  eta: 0:02:27  Loss: 3.2639 (3.0673)  Acc@1: 18.7500 (20.8596)  Acc@5: 50.0000 (52.9377)  time: 0.2174  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 960/1627]  eta: 0:02:25  Loss: 3.1151 (3.0657)  Acc@1: 18.7500 (20.9222)  Acc@5: 56.2500 (52.9917)  time: 0.2175  data: 0.0003  max mem: 2502
Test: [Task 1]  [ 970/1627]  eta: 0:02:23  Loss: 2.7744 (3.0633)  Acc@1: 25.0000 (20.9771)  Acc@5: 56.2500 (53.0510)  time: 0.2188  data: 0.0004  max mem: 2502
Test: [Task 1]  [ 980/1627]  eta: 0:02:21  Loss: 2.8143 (3.0630)  Acc@1: 25.0000 (20.9990)  Acc@5: 56.2500 (53.0708)  time: 0.2186  data: 0.0004  max mem: 2502
Test: [Task 1]  [ 990/1627]  eta: 0:02:19  Loss: 3.1774 (3.0638)  Acc@1: 18.7500 (20.9826)  Acc@5: 56.2500 (53.0714)  time: 0.2182  data: 0.0003  max mem: 2502
Test: [Task 1]  [1000/1627]  eta: 0:02:17  Loss: 3.1374 (3.0642)  Acc@1: 18.7500 (20.9853)  Acc@5: 50.0000 (53.0594)  time: 0.2183  data: 0.0003  max mem: 2502
Test: [Task 1]  [1010/1627]  eta: 0:02:14  Loss: 3.0859 (3.0644)  Acc@1: 18.7500 (20.9570)  Acc@5: 50.0000 (53.0539)  time: 0.2190  data: 0.0007  max mem: 2502
Test: [Task 1]  [1020/1627]  eta: 0:02:12  Loss: 3.0694 (3.0640)  Acc@1: 18.7500 (20.9721)  Acc@5: 50.0000 (53.0791)  time: 0.2191  data: 0.0007  max mem: 2502
Test: [Task 1]  [1030/1627]  eta: 0:02:10  Loss: 2.9681 (3.0629)  Acc@1: 25.0000 (20.9808)  Acc@5: 56.2500 (53.1159)  time: 0.2182  data: 0.0003  max mem: 2502
Test: [Task 1]  [1040/1627]  eta: 0:02:08  Loss: 3.0156 (3.0631)  Acc@1: 18.7500 (20.9654)  Acc@5: 50.0000 (53.0560)  time: 0.2186  data: 0.0004  max mem: 2502
Test: [Task 1]  [1050/1627]  eta: 0:02:06  Loss: 3.0638 (3.0632)  Acc@1: 18.7500 (20.9860)  Acc@5: 50.0000 (53.0745)  time: 0.2184  data: 0.0003  max mem: 2502
Test: [Task 1]  [1060/1627]  eta: 0:02:03  Loss: 3.0769 (3.0634)  Acc@1: 18.7500 (20.9767)  Acc@5: 50.0000 (53.0867)  time: 0.2194  data: 0.0006  max mem: 2502
Test: [Task 1]  [1070/1627]  eta: 0:02:01  Loss: 3.1523 (3.0649)  Acc@1: 18.7500 (20.9384)  Acc@5: 50.0000 (53.0521)  time: 0.2200  data: 0.0007  max mem: 2502
Test: [Task 1]  [1080/1627]  eta: 0:01:59  Loss: 2.9642 (3.0649)  Acc@1: 18.7500 (20.9470)  Acc@5: 50.0000 (53.0412)  time: 0.2187  data: 0.0003  max mem: 2502
Test: [Task 1]  [1090/1627]  eta: 0:01:57  Loss: 2.9642 (3.0654)  Acc@1: 18.7500 (20.9326)  Acc@5: 50.0000 (53.0477)  time: 0.2187  data: 0.0004  max mem: 2502
Test: [Task 1]  [1100/1627]  eta: 0:01:55  Loss: 2.9833 (3.0651)  Acc@1: 18.7500 (20.9185)  Acc@5: 50.0000 (53.0824)  time: 0.2188  data: 0.0003  max mem: 2502
Test: [Task 1]  [1110/1627]  eta: 0:01:53  Loss: 3.2259 (3.0671)  Acc@1: 12.5000 (20.8821)  Acc@5: 50.0000 (53.0209)  time: 0.2188  data: 0.0003  max mem: 2502
Test: [Task 1]  [1120/1627]  eta: 0:01:50  Loss: 3.1072 (3.0660)  Acc@1: 18.7500 (20.8909)  Acc@5: 56.2500 (53.0832)  time: 0.2190  data: 0.0003  max mem: 2502
Test: [Task 1]  [1130/1627]  eta: 0:01:48  Loss: 2.9724 (3.0658)  Acc@1: 18.7500 (20.8996)  Acc@5: 56.2500 (53.0891)  time: 0.2191  data: 0.0003  max mem: 2502
Test: [Task 1]  [1140/1627]  eta: 0:01:46  Loss: 3.0781 (3.0685)  Acc@1: 18.7500 (20.8589)  Acc@5: 43.7500 (53.0237)  time: 0.2188  data: 0.0003  max mem: 2502
Test: [Task 1]  [1150/1627]  eta: 0:01:44  Loss: 3.0781 (3.0683)  Acc@1: 18.7500 (20.8623)  Acc@5: 50.0000 (53.0680)  time: 0.2188  data: 0.0003  max mem: 2502
Test: [Task 1]  [1160/1627]  eta: 0:01:42  Loss: 2.8479 (3.0677)  Acc@1: 18.7500 (20.8818)  Acc@5: 56.2500 (53.0523)  time: 0.2191  data: 0.0003  max mem: 2502
Test: [Task 1]  [1170/1627]  eta: 0:01:39  Loss: 2.9166 (3.0685)  Acc@1: 18.7500 (20.8636)  Acc@5: 56.2500 (53.0583)  time: 0.2190  data: 0.0003  max mem: 2502
Test: [Task 1]  [1180/1627]  eta: 0:01:37  Loss: 3.1556 (3.0699)  Acc@1: 18.7500 (20.8139)  Acc@5: 50.0000 (52.9636)  time: 0.2193  data: 0.0003  max mem: 2502
Test: [Task 1]  [1190/1627]  eta: 0:01:35  Loss: 3.1630 (3.0702)  Acc@1: 18.7500 (20.8123)  Acc@5: 43.7500 (52.9440)  time: 0.2197  data: 0.0003  max mem: 2502
Test: [Task 1]  [1200/1627]  eta: 0:01:33  Loss: 3.1412 (3.0716)  Acc@1: 18.7500 (20.7900)  Acc@5: 50.0000 (52.8986)  time: 0.2196  data: 0.0003  max mem: 2502
Test: [Task 1]  [1210/1627]  eta: 0:01:31  Loss: 3.1157 (3.0724)  Acc@1: 18.7500 (20.7783)  Acc@5: 50.0000 (52.8489)  time: 0.2192  data: 0.0003  max mem: 2502
Test: [Task 1]  [1220/1627]  eta: 0:01:28  Loss: 2.9755 (3.0715)  Acc@1: 18.7500 (20.7924)  Acc@5: 50.0000 (52.8819)  time: 0.2189  data: 0.0003  max mem: 2502
Test: [Task 1]  [1230/1627]  eta: 0:01:26  Loss: 3.0529 (3.0726)  Acc@1: 18.7500 (20.7504)  Acc@5: 50.0000 (52.8432)  time: 0.2190  data: 0.0004  max mem: 2502
Test: [Task 1]  [1240/1627]  eta: 0:01:24  Loss: 3.0501 (3.0712)  Acc@1: 25.0000 (20.8098)  Acc@5: 50.0000 (52.8556)  time: 0.2198  data: 0.0004  max mem: 2502
Test: [Task 1]  [1250/1627]  eta: 0:01:22  Loss: 2.9896 (3.0722)  Acc@1: 25.0000 (20.7734)  Acc@5: 50.0000 (52.8427)  time: 0.2199  data: 0.0004  max mem: 2502
Test: [Task 1]  [1260/1627]  eta: 0:01:20  Loss: 3.1349 (3.0719)  Acc@1: 18.7500 (20.7871)  Acc@5: 50.0000 (52.8598)  time: 0.2193  data: 0.0003  max mem: 2502
Test: [Task 1]  [1270/1627]  eta: 0:01:18  Loss: 2.9962 (3.0715)  Acc@1: 18.7500 (20.7956)  Acc@5: 56.2500 (52.9062)  time: 0.2195  data: 0.0003  max mem: 2502
Test: [Task 1]  [1280/1627]  eta: 0:01:15  Loss: 2.9962 (3.0707)  Acc@1: 18.7500 (20.8285)  Acc@5: 56.2500 (52.8884)  time: 0.2195  data: 0.0003  max mem: 2502
Test: [Task 1]  [1290/1627]  eta: 0:01:13  Loss: 3.0203 (3.0706)  Acc@1: 25.0000 (20.8656)  Acc@5: 50.0000 (52.8660)  time: 0.2189  data: 0.0003  max mem: 2502
Test: [Task 1]  [1300/1627]  eta: 0:01:11  Loss: 2.9099 (3.0692)  Acc@1: 25.0000 (20.9070)  Acc@5: 56.2500 (52.9352)  time: 0.2188  data: 0.0003  max mem: 2502
Test: [Task 1]  [1310/1627]  eta: 0:01:09  Loss: 2.9525 (3.0699)  Acc@1: 25.0000 (20.8858)  Acc@5: 56.2500 (52.9081)  time: 0.2188  data: 0.0003  max mem: 2502
Test: [Task 1]  [1320/1627]  eta: 0:01:07  Loss: 3.0985 (3.0689)  Acc@1: 18.7500 (20.9122)  Acc@5: 56.2500 (52.9381)  time: 0.2200  data: 0.0009  max mem: 2502
Test: [Task 1]  [1330/1627]  eta: 0:01:04  Loss: 3.0985 (3.0695)  Acc@1: 18.7500 (20.9053)  Acc@5: 50.0000 (52.9301)  time: 0.2209  data: 0.0017  max mem: 2502
Test: [Task 1]  [1340/1627]  eta: 0:01:02  Loss: 3.0760 (3.0687)  Acc@1: 18.7500 (20.9172)  Acc@5: 50.0000 (52.9595)  time: 0.2193  data: 0.0011  max mem: 2502
Test: [Task 1]  [1350/1627]  eta: 0:01:00  Loss: 3.0760 (3.0690)  Acc@1: 18.7500 (20.9151)  Acc@5: 56.2500 (52.9561)  time: 0.2184  data: 0.0003  max mem: 2502
Test: [Task 1]  [1360/1627]  eta: 0:00:58  Loss: 3.0798 (3.0684)  Acc@1: 18.7500 (20.9175)  Acc@5: 56.2500 (52.9758)  time: 0.2187  data: 0.0003  max mem: 2502
Test: [Task 1]  [1370/1627]  eta: 0:00:56  Loss: 2.9534 (3.0672)  Acc@1: 18.7500 (20.9747)  Acc@5: 56.2500 (52.9996)  time: 0.2183  data: 0.0003  max mem: 2502
Test: [Task 1]  [1380/1627]  eta: 0:00:54  Loss: 2.9534 (3.0674)  Acc@1: 18.7500 (20.9812)  Acc@5: 56.2500 (52.9779)  time: 0.2179  data: 0.0003  max mem: 2502
Test: [Task 1]  [1390/1627]  eta: 0:00:51  Loss: 2.9326 (3.0666)  Acc@1: 18.7500 (20.9966)  Acc@5: 56.2500 (53.0149)  time: 0.2179  data: 0.0003  max mem: 2502
Test: [Task 1]  [1400/1627]  eta: 0:00:49  Loss: 3.1178 (3.0670)  Acc@1: 25.0000 (21.0207)  Acc@5: 50.0000 (52.9934)  time: 0.2188  data: 0.0004  max mem: 2502
Test: [Task 1]  [1410/1627]  eta: 0:00:47  Loss: 3.1327 (3.0660)  Acc@1: 25.0000 (21.0622)  Acc@5: 56.2500 (53.0120)  time: 0.2192  data: 0.0008  max mem: 2502
Test: [Task 1]  [1420/1627]  eta: 0:00:45  Loss: 3.0712 (3.0653)  Acc@1: 25.0000 (21.0855)  Acc@5: 56.2500 (53.0304)  time: 0.2178  data: 0.0007  max mem: 2502
Test: [Task 1]  [1430/1627]  eta: 0:00:43  Loss: 3.1279 (3.0660)  Acc@1: 25.0000 (21.0823)  Acc@5: 50.0000 (53.0005)  time: 0.2174  data: 0.0003  max mem: 2502
Test: [Task 1]  [1440/1627]  eta: 0:00:40  Loss: 3.0282 (3.0656)  Acc@1: 18.7500 (21.0834)  Acc@5: 50.0000 (53.0101)  time: 0.2177  data: 0.0003  max mem: 2502
Test: [Task 1]  [1450/1627]  eta: 0:00:38  Loss: 2.9548 (3.0657)  Acc@1: 18.7500 (21.1061)  Acc@5: 50.0000 (53.0238)  time: 0.2173  data: 0.0003  max mem: 2502
Test: [Task 1]  [1460/1627]  eta: 0:00:36  Loss: 3.0838 (3.0664)  Acc@1: 18.7500 (21.0943)  Acc@5: 56.2500 (53.0416)  time: 0.2173  data: 0.0003  max mem: 2502
Test: [Task 1]  [1470/1627]  eta: 0:00:34  Loss: 3.0838 (3.0674)  Acc@1: 18.7500 (21.0911)  Acc@5: 56.2500 (53.0124)  time: 0.2173  data: 0.0003  max mem: 2502
Test: [Task 1]  [1480/1627]  eta: 0:00:32  Loss: 3.0701 (3.0671)  Acc@1: 18.7500 (21.1090)  Acc@5: 56.2500 (53.0343)  time: 0.2168  data: 0.0003  max mem: 2502
Test: [Task 1]  [1490/1627]  eta: 0:00:29  Loss: 3.1485 (3.0676)  Acc@1: 18.7500 (21.0932)  Acc@5: 50.0000 (53.0055)  time: 0.2166  data: 0.0003  max mem: 2502
Test: [Task 1]  [1500/1627]  eta: 0:00:27  Loss: 2.9855 (3.0666)  Acc@1: 18.7500 (21.0984)  Acc@5: 50.0000 (53.0605)  time: 0.2168  data: 0.0003  max mem: 2502
Test: [Task 1]  [1510/1627]  eta: 0:00:25  Loss: 3.1641 (3.0678)  Acc@1: 18.7500 (21.0870)  Acc@5: 50.0000 (53.0030)  time: 0.2172  data: 0.0003  max mem: 2502
Test: [Task 1]  [1520/1627]  eta: 0:00:23  Loss: 3.1403 (3.0671)  Acc@1: 18.7500 (21.1004)  Acc@5: 50.0000 (53.0325)  time: 0.2171  data: 0.0003  max mem: 2502
Test: [Task 1]  [1530/1627]  eta: 0:00:21  Loss: 3.0396 (3.0677)  Acc@1: 18.7500 (21.0851)  Acc@5: 56.2500 (53.0250)  time: 0.2168  data: 0.0003  max mem: 2502
Test: [Task 1]  [1540/1627]  eta: 0:00:19  Loss: 3.0534 (3.0668)  Acc@1: 18.7500 (21.0861)  Acc@5: 56.2500 (53.0378)  time: 0.2169  data: 0.0003  max mem: 2502
Test: [Task 1]  [1550/1627]  eta: 0:00:16  Loss: 2.8494 (3.0661)  Acc@1: 25.0000 (21.1033)  Acc@5: 62.5000 (53.0827)  time: 0.2170  data: 0.0004  max mem: 2502
Test: [Task 1]  [1560/1627]  eta: 0:00:14  Loss: 2.8130 (3.0645)  Acc@1: 25.0000 (21.1403)  Acc@5: 62.5000 (53.1390)  time: 0.2173  data: 0.0003  max mem: 2502
Test: [Task 1]  [1570/1627]  eta: 0:00:12  Loss: 2.8571 (3.0646)  Acc@1: 25.0000 (21.1251)  Acc@5: 62.5000 (53.1270)  time: 0.2183  data: 0.0007  max mem: 2502
Test: [Task 1]  [1580/1627]  eta: 0:00:10  Loss: 2.9189 (3.0643)  Acc@1: 18.7500 (21.1298)  Acc@5: 50.0000 (53.1230)  time: 0.2184  data: 0.0007  max mem: 2502
Test: [Task 1]  [1590/1627]  eta: 0:00:08  Loss: 2.9876 (3.0647)  Acc@1: 18.7500 (21.1266)  Acc@5: 50.0000 (53.1073)  time: 0.2173  data: 0.0003  max mem: 2502
Test: [Task 1]  [1600/1627]  eta: 0:00:05  Loss: 3.1957 (3.0651)  Acc@1: 18.7500 (21.1079)  Acc@5: 50.0000 (53.0762)  time: 0.2176  data: 0.0003  max mem: 2502
Test: [Task 1]  [1610/1627]  eta: 0:00:03  Loss: 3.1163 (3.0656)  Acc@1: 18.7500 (21.1010)  Acc@5: 50.0000 (53.0920)  time: 0.2181  data: 0.0003  max mem: 2502
Test: [Task 1]  [1620/1627]  eta: 0:00:01  Loss: 3.0810 (3.0650)  Acc@1: 18.7500 (21.1135)  Acc@5: 56.2500 (53.1154)  time: 0.2183  data: 0.0003  max mem: 2502
Test: [Task 1]  [1626/1627]  eta: 0:00:00  Loss: 3.0766 (3.0642)  Acc@1: 25.0000 (21.1470)  Acc@5: 56.2500 (53.1346)  time: 0.2183  data: 0.0003  max mem: 2502
Test: [Task 1] Total time: 0:05:55 (0.2187 s / it)
* Acc@1 21.147 Acc@5 53.135 loss 3.064
Test: [Task 2]  [  0/625]  eta: 0:05:55  Loss: 0.5042 (0.5042)  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (100.0000)  time: 0.5681  data: 0.3515  max mem: 2502
Test: [Task 2]  [ 10/625]  eta: 0:02:34  Loss: 1.0010 (0.9627)  Acc@1: 75.0000 (73.8636)  Acc@5: 93.7500 (95.4545)  time: 0.2516  data: 0.0337  max mem: 2502
Test: [Task 2]  [ 20/625]  eta: 0:02:22  Loss: 1.0333 (0.9861)  Acc@1: 68.7500 (70.2381)  Acc@5: 93.7500 (96.1310)  time: 0.2190  data: 0.0011  max mem: 2502
Test: [Task 2]  [ 30/625]  eta: 0:02:17  Loss: 1.0541 (1.0003)  Acc@1: 68.7500 (70.1613)  Acc@5: 93.7500 (95.9677)  time: 0.2188  data: 0.0005  max mem: 2502
Test: [Task 2]  [ 40/625]  eta: 0:02:13  Loss: 1.0493 (1.0262)  Acc@1: 68.7500 (69.8171)  Acc@5: 93.7500 (95.5793)  time: 0.2191  data: 0.0005  max mem: 2502
Test: [Task 2]  [ 50/625]  eta: 0:02:09  Loss: 1.1499 (1.0624)  Acc@1: 68.7500 (69.2402)  Acc@5: 93.7500 (95.0980)  time: 0.2189  data: 0.0003  max mem: 2502
Test: [Task 2]  [ 60/625]  eta: 0:02:06  Loss: 1.1553 (1.0752)  Acc@1: 68.7500 (69.2623)  Acc@5: 93.7500 (94.8770)  time: 0.2190  data: 0.0004  max mem: 2502
Test: [Task 2]  [ 70/625]  eta: 0:02:04  Loss: 1.0709 (1.0761)  Acc@1: 68.7500 (69.2782)  Acc@5: 93.7500 (94.7183)  time: 0.2189  data: 0.0004  max mem: 2502
Test: [Task 2]  [ 80/625]  eta: 0:02:01  Loss: 1.0108 (1.0775)  Acc@1: 68.7500 (69.5988)  Acc@5: 93.7500 (94.5988)  time: 0.2195  data: 0.0013  max mem: 2502
Test: [Task 2]  [ 90/625]  eta: 0:01:59  Loss: 1.0471 (1.0833)  Acc@1: 68.7500 (69.1621)  Acc@5: 93.7500 (94.6429)  time: 0.2193  data: 0.0013  max mem: 2502
Test: [Task 2]  [100/625]  eta: 0:01:56  Loss: 1.0757 (1.0924)  Acc@1: 68.7500 (68.6881)  Acc@5: 93.7500 (94.4307)  time: 0.2188  data: 0.0003  max mem: 2502
Test: [Task 2]  [110/625]  eta: 0:01:54  Loss: 1.0081 (1.0865)  Acc@1: 68.7500 (68.9189)  Acc@5: 93.7500 (94.7072)  time: 0.2189  data: 0.0003  max mem: 2502
Test: [Task 2]  [120/625]  eta: 0:01:52  Loss: 1.0614 (1.0924)  Acc@1: 68.7500 (68.6467)  Acc@5: 93.7500 (94.6798)  time: 0.2185  data: 0.0003  max mem: 2502
Test: [Task 2]  [130/625]  eta: 0:01:49  Loss: 1.1690 (1.0953)  Acc@1: 68.7500 (68.8931)  Acc@5: 93.7500 (94.7042)  time: 0.2186  data: 0.0003  max mem: 2502
Test: [Task 2]  [140/625]  eta: 0:01:47  Loss: 1.0392 (1.0987)  Acc@1: 68.7500 (68.4840)  Acc@5: 100.0000 (94.7695)  time: 0.2188  data: 0.0003  max mem: 2502
Test: [Task 2]  [150/625]  eta: 0:01:45  Loss: 1.1353 (1.1087)  Acc@1: 62.5000 (68.1291)  Acc@5: 93.7500 (94.4536)  time: 0.2187  data: 0.0003  max mem: 2502
Test: [Task 2]  [160/625]  eta: 0:01:42  Loss: 1.1274 (1.1091)  Acc@1: 68.7500 (68.3618)  Acc@5: 93.7500 (94.4488)  time: 0.2194  data: 0.0003  max mem: 2502
Test: [Task 2]  [170/625]  eta: 0:01:40  Loss: 1.0780 (1.1084)  Acc@1: 68.7500 (68.3114)  Acc@5: 93.7500 (94.5541)  time: 0.2200  data: 0.0009  max mem: 2502
Test: [Task 2]  [180/625]  eta: 0:01:38  Loss: 1.1447 (1.1090)  Acc@1: 68.7500 (68.1285)  Acc@5: 93.7500 (94.5787)  time: 0.2192  data: 0.0009  max mem: 2502
Test: [Task 2]  [190/625]  eta: 0:01:36  Loss: 1.1583 (1.1154)  Acc@1: 62.5000 (67.9319)  Acc@5: 93.7500 (94.4699)  time: 0.2189  data: 0.0003  max mem: 2502
Test: [Task 2]  [200/625]  eta: 0:01:33  Loss: 1.3060 (1.1218)  Acc@1: 62.5000 (67.7861)  Acc@5: 93.7500 (94.4652)  time: 0.2192  data: 0.0003  max mem: 2502
Test: [Task 2]  [210/625]  eta: 0:01:31  Loss: 1.0418 (1.1189)  Acc@1: 68.7500 (67.9502)  Acc@5: 93.7500 (94.5498)  time: 0.2198  data: 0.0003  max mem: 2502
Test: [Task 2]  [220/625]  eta: 0:01:29  Loss: 1.0204 (1.1193)  Acc@1: 75.0000 (67.9299)  Acc@5: 100.0000 (94.6267)  time: 0.2198  data: 0.0003  max mem: 2502
Test: [Task 2]  [230/625]  eta: 0:01:27  Loss: 1.0461 (1.1156)  Acc@1: 68.7500 (67.9924)  Acc@5: 100.0000 (94.6699)  time: 0.2210  data: 0.0004  max mem: 2502
Test: [Task 2]  [240/625]  eta: 0:01:25  Loss: 1.0176 (1.1109)  Acc@1: 68.7500 (68.1017)  Acc@5: 100.0000 (94.7614)  time: 0.2217  data: 0.0009  max mem: 2502
Test: [Task 2]  [250/625]  eta: 0:01:22  Loss: 0.9380 (1.1078)  Acc@1: 68.7500 (68.3516)  Acc@5: 93.7500 (94.6962)  time: 0.2198  data: 0.0008  max mem: 2502
Test: [Task 2]  [260/625]  eta: 0:01:20  Loss: 1.0333 (1.1065)  Acc@1: 68.7500 (68.4866)  Acc@5: 93.7500 (94.6600)  time: 0.2192  data: 0.0003  max mem: 2502
Test: [Task 2]  [270/625]  eta: 0:01:18  Loss: 1.0765 (1.1035)  Acc@1: 68.7500 (68.6116)  Acc@5: 93.7500 (94.6264)  time: 0.2195  data: 0.0003  max mem: 2502
Test: [Task 2]  [280/625]  eta: 0:01:16  Loss: 1.0047 (1.1028)  Acc@1: 68.7500 (68.7055)  Acc@5: 93.7500 (94.5952)  time: 0.2196  data: 0.0003  max mem: 2502
Test: [Task 2]  [290/625]  eta: 0:01:13  Loss: 1.0047 (1.1046)  Acc@1: 75.0000 (68.7715)  Acc@5: 93.7500 (94.5662)  time: 0.2197  data: 0.0003  max mem: 2502
Test: [Task 2]  [300/625]  eta: 0:01:11  Loss: 1.0793 (1.1079)  Acc@1: 68.7500 (68.6462)  Acc@5: 93.7500 (94.5806)  time: 0.2196  data: 0.0003  max mem: 2502
Test: [Task 2]  [310/625]  eta: 0:01:09  Loss: 1.1022 (1.1112)  Acc@1: 62.5000 (68.4084)  Acc@5: 93.7500 (94.6141)  time: 0.2191  data: 0.0003  max mem: 2502
Test: [Task 2]  [320/625]  eta: 0:01:07  Loss: 0.9604 (1.1004)  Acc@1: 68.7500 (68.6721)  Acc@5: 100.0000 (94.7235)  time: 0.2188  data: 0.0004  max mem: 2502
Test: [Task 2]  [330/625]  eta: 0:01:05  Loss: 0.9865 (1.1020)  Acc@1: 68.7500 (68.6178)  Acc@5: 100.0000 (94.7885)  time: 0.2191  data: 0.0003  max mem: 2502
Test: [Task 2]  [340/625]  eta: 0:01:02  Loss: 0.9034 (1.0916)  Acc@1: 68.7500 (68.9516)  Acc@5: 100.0000 (94.8864)  time: 0.2195  data: 0.0003  max mem: 2502
Test: [Task 2]  [350/625]  eta: 0:01:00  Loss: 0.8244 (1.0891)  Acc@1: 68.7500 (68.8568)  Acc@5: 100.0000 (94.9430)  time: 0.2191  data: 0.0003  max mem: 2502
Test: [Task 2]  [360/625]  eta: 0:00:58  Loss: 1.2099 (1.0971)  Acc@1: 62.5000 (68.7154)  Acc@5: 93.7500 (94.8407)  time: 0.2187  data: 0.0003  max mem: 2502
Test: [Task 2]  [370/625]  eta: 0:00:56  Loss: 1.0187 (1.0908)  Acc@1: 68.7500 (68.9353)  Acc@5: 93.7500 (94.8787)  time: 0.2195  data: 0.0007  max mem: 2502
Test: [Task 2]  [380/625]  eta: 0:00:53  Loss: 1.0120 (1.0915)  Acc@1: 75.0000 (69.0289)  Acc@5: 93.7500 (94.7671)  time: 0.2193  data: 0.0008  max mem: 2502
Test: [Task 2]  [390/625]  eta: 0:00:51  Loss: 0.9956 (1.0862)  Acc@1: 75.0000 (69.0857)  Acc@5: 93.7500 (94.8529)  time: 0.2189  data: 0.0004  max mem: 2502
Test: [Task 2]  [400/625]  eta: 0:00:49  Loss: 0.8041 (1.0780)  Acc@1: 75.0000 (69.3423)  Acc@5: 100.0000 (94.9034)  time: 0.2193  data: 0.0007  max mem: 2502
Test: [Task 2]  [410/625]  eta: 0:00:47  Loss: 0.7442 (1.0727)  Acc@1: 75.0000 (69.5255)  Acc@5: 100.0000 (94.9361)  time: 0.2193  data: 0.0007  max mem: 2502
Test: [Task 2]  [420/625]  eta: 0:00:45  Loss: 0.9642 (1.0758)  Acc@1: 75.0000 (69.4181)  Acc@5: 93.7500 (94.8189)  time: 0.2190  data: 0.0003  max mem: 2502
Test: [Task 2]  [430/625]  eta: 0:00:42  Loss: 1.0094 (1.0764)  Acc@1: 68.7500 (69.3735)  Acc@5: 93.7500 (94.8521)  time: 0.2193  data: 0.0003  max mem: 2502
Test: [Task 2]  [440/625]  eta: 0:00:40  Loss: 0.7233 (1.0669)  Acc@1: 75.0000 (69.6003)  Acc@5: 100.0000 (94.9405)  time: 0.2189  data: 0.0003  max mem: 2502
Test: [Task 2]  [450/625]  eta: 0:00:38  Loss: 0.6649 (1.0605)  Acc@1: 81.2500 (69.8171)  Acc@5: 100.0000 (95.0388)  time: 0.2183  data: 0.0003  max mem: 2502
Test: [Task 2]  [460/625]  eta: 0:00:36  Loss: 0.8705 (1.0576)  Acc@1: 75.0000 (69.9702)  Acc@5: 100.0000 (95.1057)  time: 0.2177  data: 0.0003  max mem: 2502
Test: [Task 2]  [470/625]  eta: 0:00:34  Loss: 0.9811 (1.0562)  Acc@1: 75.0000 (69.9973)  Acc@5: 100.0000 (95.1300)  time: 0.2174  data: 0.0004  max mem: 2502
Test: [Task 2]  [480/625]  eta: 0:00:31  Loss: 1.0054 (1.0557)  Acc@1: 68.7500 (70.0234)  Acc@5: 100.0000 (95.1273)  time: 0.2187  data: 0.0015  max mem: 2502
Test: [Task 2]  [490/625]  eta: 0:00:29  Loss: 0.9585 (1.0517)  Acc@1: 68.7500 (70.1247)  Acc@5: 100.0000 (95.1757)  time: 0.2182  data: 0.0014  max mem: 2502
Test: [Task 2]  [500/625]  eta: 0:00:27  Loss: 0.9449 (1.0518)  Acc@1: 68.7500 (70.1223)  Acc@5: 100.0000 (95.1971)  time: 0.2178  data: 0.0006  max mem: 2502
Test: [Task 2]  [510/625]  eta: 0:00:25  Loss: 0.9997 (1.0543)  Acc@1: 75.0000 (70.1566)  Acc@5: 93.7500 (95.1932)  time: 0.2178  data: 0.0006  max mem: 2502
Test: [Task 2]  [520/625]  eta: 0:00:23  Loss: 1.1137 (1.0573)  Acc@1: 68.7500 (70.0936)  Acc@5: 93.7500 (95.1655)  time: 0.2167  data: 0.0003  max mem: 2502
Test: [Task 2]  [530/625]  eta: 0:00:20  Loss: 1.0518 (1.0572)  Acc@1: 68.7500 (70.0918)  Acc@5: 100.0000 (95.2331)  time: 0.2177  data: 0.0007  max mem: 2502
Test: [Task 2]  [540/625]  eta: 0:00:18  Loss: 0.8706 (1.0526)  Acc@1: 68.7500 (70.2172)  Acc@5: 100.0000 (95.2172)  time: 0.2179  data: 0.0007  max mem: 2502
Test: [Task 2]  [550/625]  eta: 0:00:16  Loss: 0.7016 (1.0458)  Acc@1: 81.2500 (70.3834)  Acc@5: 100.0000 (95.2926)  time: 0.2168  data: 0.0004  max mem: 2502
Test: [Task 2]  [560/625]  eta: 0:00:14  Loss: 0.6030 (1.0397)  Acc@1: 75.0000 (70.5325)  Acc@5: 100.0000 (95.3654)  time: 0.2168  data: 0.0003  max mem: 2502
Test: [Task 2]  [570/625]  eta: 0:00:12  Loss: 0.8091 (1.0378)  Acc@1: 75.0000 (70.5779)  Acc@5: 100.0000 (95.3481)  time: 0.2167  data: 0.0003  max mem: 2502
Test: [Task 2]  [580/625]  eta: 0:00:09  Loss: 0.8794 (1.0338)  Acc@1: 75.0000 (70.6540)  Acc@5: 100.0000 (95.4066)  time: 0.2167  data: 0.0003  max mem: 2502
Test: [Task 2]  [590/625]  eta: 0:00:07  Loss: 0.7495 (1.0279)  Acc@1: 81.2500 (70.8228)  Acc@5: 100.0000 (95.4738)  time: 0.2176  data: 0.0003  max mem: 2502
Test: [Task 2]  [600/625]  eta: 0:00:05  Loss: 0.8219 (1.0305)  Acc@1: 75.0000 (70.7883)  Acc@5: 100.0000 (95.4867)  time: 0.2174  data: 0.0003  max mem: 2502
Test: [Task 2]  [610/625]  eta: 0:00:03  Loss: 1.1850 (1.0334)  Acc@1: 68.7500 (70.6935)  Acc@5: 100.0000 (95.4890)  time: 0.2168  data: 0.0003  max mem: 2502
Test: [Task 2]  [620/625]  eta: 0:00:01  Loss: 1.1608 (1.0345)  Acc@1: 62.5000 (70.5415)  Acc@5: 100.0000 (95.5314)  time: 0.2169  data: 0.0003  max mem: 2502
Test: [Task 2]  [624/625]  eta: 0:00:00  Loss: 0.8994 (1.0338)  Acc@1: 68.7500 (70.5700)  Acc@5: 100.0000 (95.5200)  time: 0.2169  data: 0.0003  max mem: 2502
Test: [Task 2] Total time: 0:02:17 (0.2196 s / it)
* Acc@1 70.570 Acc@5 95.520 loss 1.034
Test: [Task 3]  [  0/625]  eta: 0:05:31  Loss: 0.2746 (0.2746)  Acc@1: 93.7500 (93.7500)  Acc@5: 100.0000 (100.0000)  time: 0.5302  data: 0.3136  max mem: 2502
Test: [Task 3]  [ 10/625]  eta: 0:02:31  Loss: 0.2746 (0.3170)  Acc@1: 93.7500 (93.7500)  Acc@5: 100.0000 (98.2955)  time: 0.2465  data: 0.0296  max mem: 2502
Test: [Task 3]  [ 20/625]  eta: 0:02:20  Loss: 0.2963 (0.3408)  Acc@1: 93.7500 (93.4524)  Acc@5: 100.0000 (97.9167)  time: 0.2172  data: 0.0007  max mem: 2502
Test: [Task 3]  [ 30/625]  eta: 0:02:15  Loss: 0.2022 (0.3003)  Acc@1: 93.7500 (94.9597)  Acc@5: 100.0000 (98.5887)  time: 0.2172  data: 0.0003  max mem: 2502
Test: [Task 3]  [ 40/625]  eta: 0:02:11  Loss: 0.1771 (0.2845)  Acc@1: 93.7500 (94.9695)  Acc@5: 100.0000 (98.7805)  time: 0.2178  data: 0.0003  max mem: 2502
Test: [Task 3]  [ 50/625]  eta: 0:02:08  Loss: 0.2556 (0.2787)  Acc@1: 93.7500 (94.7304)  Acc@5: 100.0000 (99.0196)  time: 0.2175  data: 0.0003  max mem: 2502
Test: [Task 3]  [ 60/625]  eta: 0:02:05  Loss: 0.2584 (0.2833)  Acc@1: 93.7500 (94.6721)  Acc@5: 100.0000 (99.0779)  time: 0.2176  data: 0.0004  max mem: 2502
Test: [Task 3]  [ 70/625]  eta: 0:02:03  Loss: 0.2300 (0.2711)  Acc@1: 93.7500 (94.9824)  Acc@5: 100.0000 (99.2077)  time: 0.2178  data: 0.0004  max mem: 2502
Test: [Task 3]  [ 80/625]  eta: 0:02:00  Loss: 0.2100 (0.2742)  Acc@1: 93.7500 (94.6759)  Acc@5: 100.0000 (99.2284)  time: 0.2181  data: 0.0004  max mem: 2502
Test: [Task 3]  [ 90/625]  eta: 0:01:58  Loss: 0.2648 (0.2723)  Acc@1: 93.7500 (94.7115)  Acc@5: 100.0000 (99.1758)  time: 0.2191  data: 0.0011  max mem: 2502
Test: [Task 3]  [100/625]  eta: 0:01:56  Loss: 0.2347 (0.2721)  Acc@1: 93.7500 (94.6782)  Acc@5: 100.0000 (99.0718)  time: 0.2202  data: 0.0011  max mem: 2502
Test: [Task 3]  [110/625]  eta: 0:01:53  Loss: 0.1985 (0.2657)  Acc@1: 100.0000 (94.9887)  Acc@5: 100.0000 (99.1554)  time: 0.2196  data: 0.0006  max mem: 2502
Test: [Task 3]  [120/625]  eta: 0:01:51  Loss: 0.2012 (0.2665)  Acc@1: 100.0000 (95.0413)  Acc@5: 100.0000 (99.1736)  time: 0.2186  data: 0.0006  max mem: 2502
Test: [Task 3]  [130/625]  eta: 0:01:49  Loss: 0.2566 (0.2682)  Acc@1: 93.7500 (95.0382)  Acc@5: 100.0000 (99.1412)  time: 0.2184  data: 0.0003  max mem: 2502
Test: [Task 3]  [140/625]  eta: 0:01:46  Loss: 0.2779 (0.2749)  Acc@1: 93.7500 (94.9468)  Acc@5: 100.0000 (98.9805)  time: 0.2184  data: 0.0003  max mem: 2502
Test: [Task 3]  [150/625]  eta: 0:01:44  Loss: 0.3117 (0.2830)  Acc@1: 93.7500 (94.8262)  Acc@5: 100.0000 (98.8825)  time: 0.2187  data: 0.0003  max mem: 2502
Test: [Task 3]  [160/625]  eta: 0:01:42  Loss: 0.3049 (0.2877)  Acc@1: 93.7500 (94.8370)  Acc@5: 100.0000 (98.8354)  time: 0.2188  data: 0.0003  max mem: 2502
Test: [Task 3]  [170/625]  eta: 0:01:40  Loss: 0.2203 (0.2847)  Acc@1: 93.7500 (94.8830)  Acc@5: 100.0000 (98.8670)  time: 0.2189  data: 0.0004  max mem: 2502
Test: [Task 3]  [180/625]  eta: 0:01:37  Loss: 0.2379 (0.2858)  Acc@1: 93.7500 (94.7859)  Acc@5: 100.0000 (98.8260)  time: 0.2190  data: 0.0004  max mem: 2502
Test: [Task 3]  [190/625]  eta: 0:01:35  Loss: 0.2332 (0.2814)  Acc@1: 93.7500 (94.9935)  Acc@5: 100.0000 (98.8547)  time: 0.2198  data: 0.0004  max mem: 2502
Test: [Task 3]  [200/625]  eta: 0:01:33  Loss: 0.2324 (0.2821)  Acc@1: 93.7500 (94.9627)  Acc@5: 100.0000 (98.8495)  time: 0.2197  data: 0.0004  max mem: 2502
Test: [Task 3]  [210/625]  eta: 0:01:31  Loss: 0.2609 (0.2821)  Acc@1: 93.7500 (94.9941)  Acc@5: 100.0000 (98.8448)  time: 0.2192  data: 0.0004  max mem: 2502
Test: [Task 3]  [220/625]  eta: 0:01:29  Loss: 0.2575 (0.2824)  Acc@1: 93.7500 (94.9943)  Acc@5: 100.0000 (98.8405)  time: 0.2193  data: 0.0004  max mem: 2502
Test: [Task 3]  [230/625]  eta: 0:01:26  Loss: 0.2670 (0.2848)  Acc@1: 93.7500 (94.8864)  Acc@5: 100.0000 (98.8636)  time: 0.2191  data: 0.0004  max mem: 2502
Test: [Task 3]  [240/625]  eta: 0:01:24  Loss: 0.3084 (0.2887)  Acc@1: 93.7500 (94.8392)  Acc@5: 100.0000 (98.8071)  time: 0.2190  data: 0.0004  max mem: 2502
Test: [Task 3]  [250/625]  eta: 0:01:22  Loss: 0.2393 (0.2875)  Acc@1: 93.7500 (94.8456)  Acc@5: 100.0000 (98.8048)  time: 0.2192  data: 0.0003  max mem: 2502
Test: [Task 3]  [260/625]  eta: 0:01:20  Loss: 0.2282 (0.2851)  Acc@1: 93.7500 (94.8994)  Acc@5: 100.0000 (98.8266)  time: 0.2194  data: 0.0003  max mem: 2502
Test: [Task 3]  [270/625]  eta: 0:01:18  Loss: 0.2282 (0.2840)  Acc@1: 93.7500 (94.8801)  Acc@5: 100.0000 (98.7777)  time: 0.2190  data: 0.0003  max mem: 2502
Test: [Task 3]  [280/625]  eta: 0:01:15  Loss: 0.2221 (0.2815)  Acc@1: 93.7500 (94.9733)  Acc@5: 100.0000 (98.7989)  time: 0.2189  data: 0.0003  max mem: 2502
Test: [Task 3]  [290/625]  eta: 0:01:13  Loss: 0.2254 (0.2811)  Acc@1: 93.7500 (94.9527)  Acc@5: 100.0000 (98.8402)  time: 0.2188  data: 0.0003  max mem: 2502
Test: [Task 3]  [300/625]  eta: 0:01:11  Loss: 0.2993 (0.2837)  Acc@1: 93.7500 (94.9128)  Acc@5: 100.0000 (98.8164)  time: 0.2191  data: 0.0003  max mem: 2502
Test: [Task 3]  [310/625]  eta: 0:01:09  Loss: 0.2322 (0.2853)  Acc@1: 93.7500 (94.8754)  Acc@5: 100.0000 (98.7741)  time: 0.2194  data: 0.0004  max mem: 2502
Test: [Task 3]  [320/625]  eta: 0:01:07  Loss: 0.1609 (0.2815)  Acc@1: 100.0000 (95.0156)  Acc@5: 100.0000 (98.8123)  time: 0.2193  data: 0.0004  max mem: 2502
Test: [Task 3]  [330/625]  eta: 0:01:04  Loss: 0.1917 (0.2829)  Acc@1: 100.0000 (94.9207)  Acc@5: 100.0000 (98.8104)  time: 0.2190  data: 0.0003  max mem: 2502
Test: [Task 3]  [340/625]  eta: 0:01:02  Loss: 0.2308 (0.2811)  Acc@1: 93.7500 (94.9413)  Acc@5: 100.0000 (98.8453)  time: 0.2196  data: 0.0004  max mem: 2502
Test: [Task 3]  [350/625]  eta: 0:01:00  Loss: 0.2447 (0.2809)  Acc@1: 93.7500 (94.9430)  Acc@5: 100.0000 (98.8426)  time: 0.2197  data: 0.0004  max mem: 2502
Test: [Task 3]  [360/625]  eta: 0:00:58  Loss: 0.2696 (0.2818)  Acc@1: 93.7500 (94.9619)  Acc@5: 100.0000 (98.8227)  time: 0.2190  data: 0.0003  max mem: 2502
Test: [Task 3]  [370/625]  eta: 0:00:56  Loss: 0.2870 (0.2829)  Acc@1: 93.7500 (94.8787)  Acc@5: 100.0000 (98.8376)  time: 0.2193  data: 0.0004  max mem: 2502
Test: [Task 3]  [380/625]  eta: 0:00:53  Loss: 0.2474 (0.2817)  Acc@1: 93.7500 (94.9147)  Acc@5: 100.0000 (98.8517)  time: 0.2190  data: 0.0004  max mem: 2502
Test: [Task 3]  [390/625]  eta: 0:00:51  Loss: 0.2267 (0.2829)  Acc@1: 93.7500 (94.8529)  Acc@5: 100.0000 (98.8331)  time: 0.2190  data: 0.0005  max mem: 2502
Test: [Task 3]  [400/625]  eta: 0:00:49  Loss: 0.2016 (0.2814)  Acc@1: 93.7500 (94.8878)  Acc@5: 100.0000 (98.8310)  time: 0.2207  data: 0.0007  max mem: 2502
Test: [Task 3]  [410/625]  eta: 0:00:47  Loss: 0.2159 (0.2829)  Acc@1: 93.7500 (94.8145)  Acc@5: 100.0000 (98.8291)  time: 0.2203  data: 0.0004  max mem: 2502
Test: [Task 3]  [420/625]  eta: 0:00:45  Loss: 0.2095 (0.2822)  Acc@1: 93.7500 (94.8337)  Acc@5: 100.0000 (98.8124)  time: 0.2189  data: 0.0003  max mem: 2502
Test: [Task 3]  [430/625]  eta: 0:00:42  Loss: 0.2095 (0.2837)  Acc@1: 93.7500 (94.7651)  Acc@5: 100.0000 (98.7964)  time: 0.2194  data: 0.0004  max mem: 2502
Test: [Task 3]  [440/625]  eta: 0:00:40  Loss: 0.2894 (0.2852)  Acc@1: 93.7500 (94.7704)  Acc@5: 100.0000 (98.7812)  time: 0.2196  data: 0.0004  max mem: 2502
Test: [Task 3]  [450/625]  eta: 0:00:38  Loss: 0.2468 (0.2842)  Acc@1: 93.7500 (94.7894)  Acc@5: 100.0000 (98.7943)  time: 0.2193  data: 0.0004  max mem: 2502
Test: [Task 3]  [460/625]  eta: 0:00:36  Loss: 0.1892 (0.2826)  Acc@1: 100.0000 (94.8210)  Acc@5: 100.0000 (98.7934)  time: 0.2187  data: 0.0003  max mem: 2502
Test: [Task 3]  [470/625]  eta: 0:00:34  Loss: 0.2229 (0.2822)  Acc@1: 93.7500 (94.7983)  Acc@5: 100.0000 (98.7925)  time: 0.2183  data: 0.0003  max mem: 2502
Test: [Task 3]  [480/625]  eta: 0:00:31  Loss: 0.2339 (0.2829)  Acc@1: 93.7500 (94.8025)  Acc@5: 100.0000 (98.7786)  time: 0.2186  data: 0.0003  max mem: 2502
Test: [Task 3]  [490/625]  eta: 0:00:29  Loss: 0.2943 (0.2844)  Acc@1: 93.7500 (94.7429)  Acc@5: 100.0000 (98.7525)  time: 0.2187  data: 0.0004  max mem: 2502
Test: [Task 3]  [500/625]  eta: 0:00:27  Loss: 0.2281 (0.2829)  Acc@1: 93.7500 (94.7730)  Acc@5: 100.0000 (98.7774)  time: 0.2188  data: 0.0004  max mem: 2502
Test: [Task 3]  [510/625]  eta: 0:00:25  Loss: 0.1535 (0.2816)  Acc@1: 100.0000 (94.8263)  Acc@5: 100.0000 (98.8014)  time: 0.2187  data: 0.0004  max mem: 2502
Test: [Task 3]  [520/625]  eta: 0:00:23  Loss: 0.2439 (0.2837)  Acc@1: 93.7500 (94.7337)  Acc@5: 100.0000 (98.7884)  time: 0.2184  data: 0.0003  max mem: 2502
Test: [Task 3]  [530/625]  eta: 0:00:20  Loss: 0.3050 (0.2851)  Acc@1: 93.7500 (94.6798)  Acc@5: 100.0000 (98.7877)  time: 0.2189  data: 0.0003  max mem: 2502
Test: [Task 3]  [540/625]  eta: 0:00:18  Loss: 0.3788 (0.2868)  Acc@1: 93.7500 (94.6396)  Acc@5: 100.0000 (98.7639)  time: 0.2191  data: 0.0004  max mem: 2502
Test: [Task 3]  [550/625]  eta: 0:00:16  Loss: 0.2946 (0.2866)  Acc@1: 93.7500 (94.6461)  Acc@5: 100.0000 (98.7636)  time: 0.2190  data: 0.0004  max mem: 2502
Test: [Task 3]  [560/625]  eta: 0:00:14  Loss: 0.2225 (0.2863)  Acc@1: 93.7500 (94.6635)  Acc@5: 100.0000 (98.7745)  time: 0.2194  data: 0.0004  max mem: 2502
Test: [Task 3]  [570/625]  eta: 0:00:12  Loss: 0.2225 (0.2861)  Acc@1: 100.0000 (94.7132)  Acc@5: 100.0000 (98.7850)  time: 0.2195  data: 0.0003  max mem: 2502
Test: [Task 3]  [580/625]  eta: 0:00:09  Loss: 0.2718 (0.2877)  Acc@1: 93.7500 (94.6859)  Acc@5: 100.0000 (98.7737)  time: 0.2200  data: 0.0007  max mem: 2502
Test: [Task 3]  [590/625]  eta: 0:00:07  Loss: 0.2640 (0.2863)  Acc@1: 100.0000 (94.7547)  Acc@5: 100.0000 (98.7944)  time: 0.2198  data: 0.0006  max mem: 2502
Test: [Task 3]  [600/625]  eta: 0:00:05  Loss: 0.2207 (0.2863)  Acc@1: 100.0000 (94.7379)  Acc@5: 100.0000 (98.7937)  time: 0.2190  data: 0.0003  max mem: 2502
Test: [Task 3]  [610/625]  eta: 0:00:03  Loss: 0.2207 (0.2853)  Acc@1: 93.7500 (94.7422)  Acc@5: 100.0000 (98.8032)  time: 0.2190  data: 0.0003  max mem: 2502
Test: [Task 3]  [620/625]  eta: 0:00:01  Loss: 0.2088 (0.2867)  Acc@1: 93.7500 (94.7061)  Acc@5: 100.0000 (98.7822)  time: 0.2191  data: 0.0003  max mem: 2502
Test: [Task 3]  [624/625]  eta: 0:00:00  Loss: 0.2088 (0.2863)  Acc@1: 93.7500 (94.7100)  Acc@5: 100.0000 (98.7800)  time: 0.2189  data: 0.0003  max mem: 2502
Test: [Task 3] Total time: 0:02:17 (0.2197 s / it)
* Acc@1 94.710 Acc@5 98.780 loss 0.286
Test: [Task 4]  [ 0/29]  eta: 0:00:19  Loss: 1.0833 (1.0833)  Acc@1: 75.0000 (75.0000)  Acc@5: 87.5000 (87.5000)  time: 0.6896  data: 0.4694  max mem: 2502
Test: [Task 4]  [10/29]  eta: 0:00:04  Loss: 1.3779 (1.2164)  Acc@1: 68.7500 (71.5909)  Acc@5: 87.5000 (86.9318)  time: 0.2613  data: 0.0429  max mem: 2502
Test: [Task 4]  [20/29]  eta: 0:00:02  Loss: 1.3779 (1.2750)  Acc@1: 68.7500 (69.6429)  Acc@5: 87.5000 (87.2024)  time: 0.2188  data: 0.0003  max mem: 2502
Test: [Task 4]  [28/29]  eta: 0:00:00  Loss: 1.4779 (1.3266)  Acc@1: 62.5000 (67.9739)  Acc@5: 87.5000 (87.1460)  time: 0.2204  data: 0.0003  max mem: 2502
Test: [Task 4] Total time: 0:00:06 (0.2388 s / it)
* Acc@1 67.974 Acc@5 87.146 loss 1.327
{0: {0: 7781, 1: 909, 2: 13452, 3: 0, 4: 12860, 5: 10974, 6: 0, 7: 7543, 8: 0, 9: 0, 10: 0, 11: 12785, 12: 0, 13: 12177, 14: 0, 15: 13766, 16: 1254, 17: 6, 18: 5030, 19: 5591}, 1: {0: 9185, 1: 0, 2: 858, 3: 0, 4: 860, 5: 0, 6: 0, 7: 9166, 8: 0, 9: 0, 10: 0, 11: 826, 12: 0, 13: 2, 14: 0, 15: 888, 16: 0, 17: 0, 18: 9117, 19: 9098}, 2: {0: 806, 1: 1295, 2: 5039, 3: 265, 4: 878, 5: 9413, 6: 334, 7: 645, 8: 255, 9: 144, 10: 57, 11: 4898, 12: 187, 13: 9514, 14: 80, 15: 1186, 16: 1010, 17: 546, 18: 1901, 19: 1547}, 3: {0: 419, 1: 0, 2: 44, 3: 0, 4: 58, 5: 0, 6: 0, 7: 415, 8: 0, 9: 0, 10: 0, 11: 40, 12: 0, 13: 0, 14: 0, 15: 57, 16: 0, 17: 0, 18: 402, 19: 401}}
[Average accuracy till task4]	Acc@1: 63.6002	Acc@5: 83.6451	Loss: 1.4277	Forgetting: 29.4747	Backward: -29.4747
Train: Epoch[1/5]  [   0/3750]  eta: 0:43:33  Lr: 0.001875  Loss: 1.4056  Acc@1: 6.2500 (6.2500)  Acc@5: 50.0000 (50.0000)  time: 0.6970  data: 0.3325  max mem: 2502
Train: Epoch[1/5]  [  10/3750]  eta: 0:23:42  Lr: 0.001875  Loss: 1.1740  Acc@1: 31.2500 (28.4091)  Acc@5: 68.7500 (68.1818)  time: 0.3803  data: 0.0306  max mem: 2503
Train: Epoch[1/5]  [  20/3750]  eta: 0:22:42  Lr: 0.001875  Loss: 0.9485  Acc@1: 37.5000 (36.6071)  Acc@5: 81.2500 (80.6548)  time: 0.3488  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [  30/3750]  eta: 0:22:18  Lr: 0.001875  Loss: 0.4376  Acc@1: 50.0000 (44.1532)  Acc@5: 93.7500 (85.4839)  time: 0.3487  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [  40/3750]  eta: 0:22:04  Lr: 0.001875  Loss: 0.5514  Acc@1: 62.5000 (49.3902)  Acc@5: 93.7500 (88.1098)  time: 0.3484  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [  50/3750]  eta: 0:21:55  Lr: 0.001875  Loss: 0.2572  Acc@1: 62.5000 (52.3284)  Acc@5: 93.7500 (89.8284)  time: 0.3489  data: 0.0007  max mem: 2503
Train: Epoch[1/5]  [  60/3750]  eta: 0:21:49  Lr: 0.001875  Loss: 0.3018  Acc@1: 62.5000 (54.4057)  Acc@5: 93.7500 (90.7787)  time: 0.3501  data: 0.0014  max mem: 2503
Train: Epoch[1/5]  [  70/3750]  eta: 0:21:44  Lr: 0.001875  Loss: 0.1036  Acc@1: 68.7500 (56.9542)  Acc@5: 100.0000 (91.8134)  time: 0.3518  data: 0.0024  max mem: 2503
Train: Epoch[1/5]  [  80/3750]  eta: 0:21:38  Lr: 0.001875  Loss: -0.0242  Acc@1: 68.7500 (57.7932)  Acc@5: 100.0000 (92.5154)  time: 0.3512  data: 0.0016  max mem: 2503
Train: Epoch[1/5]  [  90/3750]  eta: 0:21:33  Lr: 0.001875  Loss: 0.2918  Acc@1: 62.5000 (58.9286)  Acc@5: 100.0000 (93.1319)  time: 0.3499  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [ 100/3750]  eta: 0:21:28  Lr: 0.001875  Loss: -0.0953  Acc@1: 62.5000 (59.4059)  Acc@5: 100.0000 (93.5025)  time: 0.3496  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [ 110/3750]  eta: 0:21:23  Lr: 0.001875  Loss: 0.2953  Acc@1: 68.7500 (60.5293)  Acc@5: 100.0000 (93.9752)  time: 0.3491  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [ 120/3750]  eta: 0:21:19  Lr: 0.001875  Loss: 0.0969  Acc@1: 68.7500 (61.0021)  Acc@5: 100.0000 (94.1632)  time: 0.3495  data: 0.0006  max mem: 2503
Train: Epoch[1/5]  [ 130/3750]  eta: 0:21:15  Lr: 0.001875  Loss: -0.2732  Acc@1: 68.7500 (61.9275)  Acc@5: 100.0000 (94.4656)  time: 0.3502  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [ 140/3750]  eta: 0:21:11  Lr: 0.001875  Loss: -0.1741  Acc@1: 68.7500 (62.2784)  Acc@5: 100.0000 (94.6809)  time: 0.3501  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [ 150/3750]  eta: 0:21:07  Lr: 0.001875  Loss: -0.1335  Acc@1: 68.7500 (62.7483)  Acc@5: 100.0000 (94.8675)  time: 0.3500  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [ 160/3750]  eta: 0:21:03  Lr: 0.001875  Loss: 0.1326  Acc@1: 68.7500 (63.2764)  Acc@5: 100.0000 (94.9922)  time: 0.3501  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [ 170/3750]  eta: 0:20:59  Lr: 0.001875  Loss: -0.3501  Acc@1: 75.0000 (64.0351)  Acc@5: 100.0000 (95.1754)  time: 0.3498  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [ 180/3750]  eta: 0:20:55  Lr: 0.001875  Loss: -0.3620  Acc@1: 75.0000 (64.8826)  Acc@5: 100.0000 (95.3384)  time: 0.3499  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [ 190/3750]  eta: 0:20:51  Lr: 0.001875  Loss: -0.5874  Acc@1: 75.0000 (65.1505)  Acc@5: 100.0000 (95.3861)  time: 0.3501  data: 0.0006  max mem: 2503
Train: Epoch[1/5]  [ 200/3750]  eta: 0:20:47  Lr: 0.001875  Loss: -0.3880  Acc@1: 68.7500 (65.5784)  Acc@5: 100.0000 (95.5535)  time: 0.3500  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [ 210/3750]  eta: 0:20:44  Lr: 0.001875  Loss: -0.2866  Acc@1: 68.7500 (65.9360)  Acc@5: 100.0000 (95.5865)  time: 0.3499  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [ 220/3750]  eta: 0:20:40  Lr: 0.001875  Loss: -0.3422  Acc@1: 68.7500 (66.4310)  Acc@5: 100.0000 (95.6731)  time: 0.3504  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [ 230/3750]  eta: 0:20:36  Lr: 0.001875  Loss: -0.5677  Acc@1: 75.0000 (66.7208)  Acc@5: 100.0000 (95.7522)  time: 0.3509  data: 0.0008  max mem: 2503
Train: Epoch[1/5]  [ 240/3750]  eta: 0:20:33  Lr: 0.001875  Loss: -0.1944  Acc@1: 68.7500 (66.9346)  Acc@5: 100.0000 (95.7988)  time: 0.3512  data: 0.0008  max mem: 2503
Train: Epoch[1/5]  [ 250/3750]  eta: 0:20:29  Lr: 0.001875  Loss: -0.3325  Acc@1: 68.7500 (67.2311)  Acc@5: 100.0000 (95.9163)  time: 0.3511  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [ 260/3750]  eta: 0:20:26  Lr: 0.001875  Loss: -0.4613  Acc@1: 75.0000 (67.6006)  Acc@5: 100.0000 (95.9291)  time: 0.3505  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [ 270/3750]  eta: 0:20:22  Lr: 0.001875  Loss: -0.2975  Acc@1: 68.7500 (67.7122)  Acc@5: 100.0000 (95.9640)  time: 0.3504  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [ 280/3750]  eta: 0:20:18  Lr: 0.001875  Loss: -0.2938  Acc@1: 75.0000 (68.0160)  Acc@5: 100.0000 (96.0632)  time: 0.3503  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [ 290/3750]  eta: 0:20:15  Lr: 0.001875  Loss: -0.5425  Acc@1: 75.0000 (68.1271)  Acc@5: 100.0000 (96.1340)  time: 0.3499  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [ 300/3750]  eta: 0:20:11  Lr: 0.001875  Loss: -0.8868  Acc@1: 68.7500 (68.1686)  Acc@5: 100.0000 (96.2002)  time: 0.3500  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [ 310/3750]  eta: 0:20:07  Lr: 0.001875  Loss: -0.5515  Acc@1: 68.7500 (68.2275)  Acc@5: 100.0000 (96.2219)  time: 0.3501  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [ 320/3750]  eta: 0:20:04  Lr: 0.001875  Loss: -0.2428  Acc@1: 75.0000 (68.4190)  Acc@5: 100.0000 (96.2812)  time: 0.3510  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [ 330/3750]  eta: 0:20:00  Lr: 0.001875  Loss: -0.2440  Acc@1: 75.0000 (68.5234)  Acc@5: 100.0000 (96.3180)  time: 0.3518  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [ 340/3750]  eta: 0:19:57  Lr: 0.001875  Loss: -0.3313  Acc@1: 75.0000 (68.5301)  Acc@5: 100.0000 (96.4076)  time: 0.3503  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [ 350/3750]  eta: 0:19:53  Lr: 0.001875  Loss: -0.5899  Acc@1: 75.0000 (68.6610)  Acc@5: 100.0000 (96.3853)  time: 0.3499  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [ 360/3750]  eta: 0:19:50  Lr: 0.001875  Loss: -0.0424  Acc@1: 75.0000 (68.7673)  Acc@5: 100.0000 (96.4681)  time: 0.3513  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [ 370/3750]  eta: 0:19:46  Lr: 0.001875  Loss: -0.5751  Acc@1: 75.0000 (68.9690)  Acc@5: 100.0000 (96.5465)  time: 0.3522  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [ 380/3750]  eta: 0:19:43  Lr: 0.001875  Loss: -0.5655  Acc@1: 75.0000 (69.0617)  Acc@5: 100.0000 (96.6043)  time: 0.3513  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [ 390/3750]  eta: 0:19:39  Lr: 0.001875  Loss: 0.0078  Acc@1: 75.0000 (69.1017)  Acc@5: 100.0000 (96.6432)  time: 0.3508  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [ 400/3750]  eta: 0:19:36  Lr: 0.001875  Loss: -0.2256  Acc@1: 75.0000 (69.2643)  Acc@5: 100.0000 (96.6958)  time: 0.3505  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [ 410/3750]  eta: 0:19:32  Lr: 0.001875  Loss: -0.4530  Acc@1: 75.0000 (69.3887)  Acc@5: 100.0000 (96.7153)  time: 0.3501  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [ 420/3750]  eta: 0:19:29  Lr: 0.001875  Loss: -0.5545  Acc@1: 81.2500 (69.6259)  Acc@5: 100.0000 (96.7191)  time: 0.3513  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [ 430/3750]  eta: 0:19:25  Lr: 0.001875  Loss: -0.8879  Acc@1: 75.0000 (69.6201)  Acc@5: 100.0000 (96.6937)  time: 0.3508  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [ 440/3750]  eta: 0:19:21  Lr: 0.001875  Loss: -0.5802  Acc@1: 68.7500 (69.6995)  Acc@5: 100.0000 (96.7404)  time: 0.3494  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [ 450/3750]  eta: 0:19:18  Lr: 0.001875  Loss: -0.7461  Acc@1: 75.0000 (69.7894)  Acc@5: 100.0000 (96.7849)  time: 0.3501  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [ 460/3750]  eta: 0:19:14  Lr: 0.001875  Loss: -0.6631  Acc@1: 75.0000 (69.9566)  Acc@5: 100.0000 (96.8275)  time: 0.3513  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [ 470/3750]  eta: 0:19:11  Lr: 0.001875  Loss: -0.1454  Acc@1: 81.2500 (70.1035)  Acc@5: 100.0000 (96.8153)  time: 0.3516  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [ 480/3750]  eta: 0:19:07  Lr: 0.001875  Loss: -0.2243  Acc@1: 81.2500 (70.2833)  Acc@5: 100.0000 (96.8555)  time: 0.3510  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [ 490/3750]  eta: 0:19:04  Lr: 0.001875  Loss: -0.0963  Acc@1: 75.0000 (70.3284)  Acc@5: 100.0000 (96.8814)  time: 0.3503  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [ 500/3750]  eta: 0:19:00  Lr: 0.001875  Loss: -0.5485  Acc@1: 75.0000 (70.4716)  Acc@5: 100.0000 (96.9187)  time: 0.3500  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [ 510/3750]  eta: 0:18:57  Lr: 0.001875  Loss: -0.8159  Acc@1: 75.0000 (70.5357)  Acc@5: 100.0000 (96.9300)  time: 0.3501  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [ 520/3750]  eta: 0:18:53  Lr: 0.001875  Loss: -0.4794  Acc@1: 68.7500 (70.5254)  Acc@5: 100.0000 (96.9290)  time: 0.3499  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [ 530/3750]  eta: 0:18:50  Lr: 0.001875  Loss: -0.4849  Acc@1: 68.7500 (70.5862)  Acc@5: 100.0000 (96.9750)  time: 0.3497  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [ 540/3750]  eta: 0:18:46  Lr: 0.001875  Loss: -0.6257  Acc@1: 75.0000 (70.6909)  Acc@5: 100.0000 (97.0079)  time: 0.3497  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [ 550/3750]  eta: 0:18:42  Lr: 0.001875  Loss: -0.6212  Acc@1: 75.0000 (70.7350)  Acc@5: 100.0000 (97.0622)  time: 0.3495  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [ 560/3750]  eta: 0:18:39  Lr: 0.001875  Loss: -0.4878  Acc@1: 75.0000 (70.7999)  Acc@5: 100.0000 (97.0700)  time: 0.3499  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [ 570/3750]  eta: 0:18:35  Lr: 0.001875  Loss: -0.4561  Acc@1: 75.0000 (70.9501)  Acc@5: 100.0000 (97.0884)  time: 0.3505  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [ 580/3750]  eta: 0:18:32  Lr: 0.001875  Loss: -0.2065  Acc@1: 75.0000 (71.0413)  Acc@5: 100.0000 (97.0848)  time: 0.3505  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [ 590/3750]  eta: 0:18:28  Lr: 0.001875  Loss: -0.4587  Acc@1: 75.0000 (71.1400)  Acc@5: 100.0000 (97.1129)  time: 0.3500  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [ 600/3750]  eta: 0:18:25  Lr: 0.001875  Loss: -0.5611  Acc@1: 75.0000 (71.2250)  Acc@5: 100.0000 (97.0986)  time: 0.3495  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [ 610/3750]  eta: 0:18:21  Lr: 0.001875  Loss: -0.7651  Acc@1: 75.0000 (71.3584)  Acc@5: 100.0000 (97.1256)  time: 0.3499  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [ 620/3750]  eta: 0:18:17  Lr: 0.001875  Loss: -0.7569  Acc@1: 75.0000 (71.3768)  Acc@5: 100.0000 (97.1115)  time: 0.3497  data: 0.0007  max mem: 2503
Train: Epoch[1/5]  [ 630/3750]  eta: 0:18:14  Lr: 0.001875  Loss: -0.7994  Acc@1: 75.0000 (71.4243)  Acc@5: 100.0000 (97.1276)  time: 0.3484  data: 0.0006  max mem: 2503
Train: Epoch[1/5]  [ 640/3750]  eta: 0:18:10  Lr: 0.001875  Loss: -0.4194  Acc@1: 75.0000 (71.4704)  Acc@5: 100.0000 (97.1236)  time: 0.3480  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [ 650/3750]  eta: 0:18:07  Lr: 0.001875  Loss: -0.6513  Acc@1: 68.7500 (71.4670)  Acc@5: 100.0000 (97.1486)  time: 0.3485  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [ 660/3750]  eta: 0:18:03  Lr: 0.001875  Loss: -0.5528  Acc@1: 68.7500 (71.5015)  Acc@5: 100.0000 (97.1539)  time: 0.3489  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [ 670/3750]  eta: 0:17:59  Lr: 0.001875  Loss: -0.8185  Acc@1: 68.7500 (71.4512)  Acc@5: 100.0000 (97.1870)  time: 0.3488  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [ 680/3750]  eta: 0:17:56  Lr: 0.001875  Loss: -0.4094  Acc@1: 68.7500 (71.5859)  Acc@5: 100.0000 (97.2192)  time: 0.3486  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [ 690/3750]  eta: 0:17:52  Lr: 0.001875  Loss: -0.4657  Acc@1: 75.0000 (71.5901)  Acc@5: 100.0000 (97.2323)  time: 0.3487  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [ 700/3750]  eta: 0:17:49  Lr: 0.001875  Loss: -0.5666  Acc@1: 75.0000 (71.6744)  Acc@5: 100.0000 (97.2539)  time: 0.3487  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [ 710/3750]  eta: 0:17:45  Lr: 0.001875  Loss: -0.4581  Acc@1: 75.0000 (71.7036)  Acc@5: 100.0000 (97.2310)  time: 0.3492  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [ 720/3750]  eta: 0:17:41  Lr: 0.001875  Loss: -0.6962  Acc@1: 68.7500 (71.6973)  Acc@5: 100.0000 (97.2347)  time: 0.3493  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [ 730/3750]  eta: 0:17:38  Lr: 0.001875  Loss: -0.7741  Acc@1: 68.7500 (71.7510)  Acc@5: 100.0000 (97.2555)  time: 0.3486  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [ 740/3750]  eta: 0:17:34  Lr: 0.001875  Loss: -0.7917  Acc@1: 75.0000 (71.7864)  Acc@5: 100.0000 (97.2672)  time: 0.3488  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [ 750/3750]  eta: 0:17:31  Lr: 0.001875  Loss: -0.2318  Acc@1: 75.0000 (71.8708)  Acc@5: 100.0000 (97.2870)  time: 0.3492  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [ 760/3750]  eta: 0:17:27  Lr: 0.001875  Loss: -0.8789  Acc@1: 81.2500 (71.9612)  Acc@5: 100.0000 (97.3144)  time: 0.3500  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [ 770/3750]  eta: 0:17:24  Lr: 0.001875  Loss: -0.3577  Acc@1: 75.0000 (71.9763)  Acc@5: 100.0000 (97.3168)  time: 0.3499  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [ 780/3750]  eta: 0:17:20  Lr: 0.001875  Loss: -0.1050  Acc@1: 68.7500 (71.9830)  Acc@5: 100.0000 (97.3351)  time: 0.3491  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [ 790/3750]  eta: 0:17:17  Lr: 0.001875  Loss: -0.1832  Acc@1: 75.0000 (72.0528)  Acc@5: 100.0000 (97.3451)  time: 0.3493  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [ 800/3750]  eta: 0:17:13  Lr: 0.001875  Loss: -0.4113  Acc@1: 75.0000 (72.0428)  Acc@5: 100.0000 (97.3471)  time: 0.3498  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [ 810/3750]  eta: 0:17:10  Lr: 0.001875  Loss: -0.6131  Acc@1: 75.0000 (72.0869)  Acc@5: 100.0000 (97.3567)  time: 0.3496  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [ 820/3750]  eta: 0:17:06  Lr: 0.001875  Loss: -0.7831  Acc@1: 75.0000 (72.1833)  Acc@5: 100.0000 (97.3812)  time: 0.3493  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [ 830/3750]  eta: 0:17:03  Lr: 0.001875  Loss: -0.6286  Acc@1: 75.0000 (72.2172)  Acc@5: 100.0000 (97.3902)  time: 0.3500  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [ 840/3750]  eta: 0:16:59  Lr: 0.001875  Loss: -0.8647  Acc@1: 75.0000 (72.2800)  Acc@5: 100.0000 (97.4138)  time: 0.3507  data: 0.0012  max mem: 2503
Train: Epoch[1/5]  [ 850/3750]  eta: 0:16:56  Lr: 0.001875  Loss: -0.4518  Acc@1: 75.0000 (72.3193)  Acc@5: 100.0000 (97.4295)  time: 0.3506  data: 0.0013  max mem: 2503
Train: Epoch[1/5]  [ 860/3750]  eta: 0:16:52  Lr: 0.001875  Loss: -0.6065  Acc@1: 68.7500 (72.2271)  Acc@5: 100.0000 (97.4521)  time: 0.3508  data: 0.0012  max mem: 2503
Train: Epoch[1/5]  [ 870/3750]  eta: 0:16:49  Lr: 0.001875  Loss: -0.7193  Acc@1: 68.7500 (72.3091)  Acc@5: 100.0000 (97.4670)  time: 0.3509  data: 0.0011  max mem: 2503
Train: Epoch[1/5]  [ 880/3750]  eta: 0:16:45  Lr: 0.001875  Loss: -0.6466  Acc@1: 75.0000 (72.3610)  Acc@5: 100.0000 (97.4886)  time: 0.3498  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [ 890/3750]  eta: 0:16:42  Lr: 0.001875  Loss: -0.4013  Acc@1: 75.0000 (72.4256)  Acc@5: 100.0000 (97.4958)  time: 0.3494  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [ 900/3750]  eta: 0:16:38  Lr: 0.001875  Loss: -0.1784  Acc@1: 75.0000 (72.4265)  Acc@5: 100.0000 (97.4958)  time: 0.3502  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [ 910/3750]  eta: 0:16:35  Lr: 0.001875  Loss: -0.5235  Acc@1: 75.0000 (72.4410)  Acc@5: 100.0000 (97.4959)  time: 0.3503  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [ 920/3750]  eta: 0:16:31  Lr: 0.001875  Loss: -0.7513  Acc@1: 75.0000 (72.4824)  Acc@5: 100.0000 (97.5027)  time: 0.3505  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [ 930/3750]  eta: 0:16:28  Lr: 0.001875  Loss: -0.4167  Acc@1: 75.0000 (72.4825)  Acc@5: 100.0000 (97.5094)  time: 0.3508  data: 0.0009  max mem: 2503
Train: Epoch[1/5]  [ 940/3750]  eta: 0:16:24  Lr: 0.001875  Loss: -0.2878  Acc@1: 75.0000 (72.5093)  Acc@5: 100.0000 (97.5027)  time: 0.3505  data: 0.0008  max mem: 2503
Train: Epoch[1/5]  [ 950/3750]  eta: 0:16:21  Lr: 0.001875  Loss: -0.2678  Acc@1: 75.0000 (72.5552)  Acc@5: 100.0000 (97.5223)  time: 0.3511  data: 0.0012  max mem: 2503
Train: Epoch[1/5]  [ 960/3750]  eta: 0:16:17  Lr: 0.001875  Loss: -0.6778  Acc@1: 75.0000 (72.5937)  Acc@5: 100.0000 (97.5416)  time: 0.3508  data: 0.0017  max mem: 2503
Train: Epoch[1/5]  [ 970/3750]  eta: 0:16:14  Lr: 0.001875  Loss: -0.5560  Acc@1: 75.0000 (72.6571)  Acc@5: 100.0000 (97.5412)  time: 0.3497  data: 0.0008  max mem: 2503
Train: Epoch[1/5]  [ 980/3750]  eta: 0:16:10  Lr: 0.001875  Loss: -0.5365  Acc@1: 75.0000 (72.6809)  Acc@5: 100.0000 (97.5535)  time: 0.3496  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [ 990/3750]  eta: 0:16:06  Lr: 0.001875  Loss: -0.8123  Acc@1: 75.0000 (72.7233)  Acc@5: 100.0000 (97.5656)  time: 0.3500  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [1000/3750]  eta: 0:16:03  Lr: 0.001875  Loss: -0.2439  Acc@1: 75.0000 (72.7210)  Acc@5: 100.0000 (97.5649)  time: 0.3503  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [1010/3750]  eta: 0:15:59  Lr: 0.001875  Loss: -0.4465  Acc@1: 75.0000 (72.7312)  Acc@5: 100.0000 (97.5519)  time: 0.3491  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [1020/3750]  eta: 0:15:56  Lr: 0.001875  Loss: -0.5416  Acc@1: 75.0000 (72.7351)  Acc@5: 100.0000 (97.5637)  time: 0.3495  data: 0.0009  max mem: 2503
Train: Epoch[1/5]  [1030/3750]  eta: 0:15:52  Lr: 0.001875  Loss: -0.6265  Acc@1: 68.7500 (72.7025)  Acc@5: 100.0000 (97.5873)  time: 0.3507  data: 0.0010  max mem: 2503
Train: Epoch[1/5]  [1040/3750]  eta: 0:15:49  Lr: 0.001875  Loss: -0.5395  Acc@1: 75.0000 (72.7546)  Acc@5: 100.0000 (97.5865)  time: 0.3505  data: 0.0007  max mem: 2503
Train: Epoch[1/5]  [1050/3750]  eta: 0:15:45  Lr: 0.001875  Loss: -0.3510  Acc@1: 75.0000 (72.7521)  Acc@5: 100.0000 (97.6035)  time: 0.3511  data: 0.0007  max mem: 2503
Train: Epoch[1/5]  [1060/3750]  eta: 0:15:42  Lr: 0.001875  Loss: -0.6258  Acc@1: 68.7500 (72.7615)  Acc@5: 100.0000 (97.6143)  time: 0.3511  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [1070/3750]  eta: 0:15:38  Lr: 0.001875  Loss: -0.3645  Acc@1: 68.7500 (72.7824)  Acc@5: 100.0000 (97.6249)  time: 0.3505  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [1080/3750]  eta: 0:15:35  Lr: 0.001875  Loss: -1.0375  Acc@1: 75.0000 (72.8434)  Acc@5: 100.0000 (97.6295)  time: 0.3500  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [1090/3750]  eta: 0:15:31  Lr: 0.001875  Loss: -0.5561  Acc@1: 75.0000 (72.8288)  Acc@5: 100.0000 (97.6398)  time: 0.3494  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [1100/3750]  eta: 0:15:28  Lr: 0.001875  Loss: 0.1688  Acc@1: 68.7500 (72.8202)  Acc@5: 100.0000 (97.6442)  time: 0.3495  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [1110/3750]  eta: 0:15:24  Lr: 0.001875  Loss: -0.8047  Acc@1: 68.7500 (72.7948)  Acc@5: 100.0000 (97.6485)  time: 0.3497  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [1120/3750]  eta: 0:15:21  Lr: 0.001875  Loss: -0.4332  Acc@1: 68.7500 (72.8423)  Acc@5: 100.0000 (97.6639)  time: 0.3500  data: 0.0006  max mem: 2503
Train: Epoch[1/5]  [1130/3750]  eta: 0:15:17  Lr: 0.001875  Loss: -0.5276  Acc@1: 75.0000 (72.9056)  Acc@5: 100.0000 (97.6735)  time: 0.3506  data: 0.0006  max mem: 2503
Train: Epoch[1/5]  [1140/3750]  eta: 0:15:14  Lr: 0.001875  Loss: -0.7312  Acc@1: 75.0000 (72.9623)  Acc@5: 100.0000 (97.6775)  time: 0.3507  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [1150/3750]  eta: 0:15:10  Lr: 0.001875  Loss: -0.6245  Acc@1: 81.2500 (73.0126)  Acc@5: 100.0000 (97.6868)  time: 0.3504  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [1160/3750]  eta: 0:15:07  Lr: 0.001875  Loss: -0.6327  Acc@1: 81.2500 (73.0243)  Acc@5: 100.0000 (97.6906)  time: 0.3499  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [1170/3750]  eta: 0:15:03  Lr: 0.001875  Loss: -0.6856  Acc@1: 68.7500 (73.0252)  Acc@5: 100.0000 (97.6943)  time: 0.3500  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [1180/3750]  eta: 0:15:00  Lr: 0.001875  Loss: -0.6263  Acc@1: 75.0000 (73.0684)  Acc@5: 100.0000 (97.7032)  time: 0.3510  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [1190/3750]  eta: 0:14:56  Lr: 0.001875  Loss: -1.0599  Acc@1: 75.0000 (73.0951)  Acc@5: 100.0000 (97.7068)  time: 0.3505  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [1200/3750]  eta: 0:14:53  Lr: 0.001875  Loss: -0.7437  Acc@1: 75.0000 (73.1526)  Acc@5: 100.0000 (97.6894)  time: 0.3496  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [1210/3750]  eta: 0:14:49  Lr: 0.001875  Loss: -0.5542  Acc@1: 75.0000 (73.1678)  Acc@5: 100.0000 (97.6982)  time: 0.3507  data: 0.0015  max mem: 2503
Train: Epoch[1/5]  [1220/3750]  eta: 0:14:46  Lr: 0.001875  Loss: -0.8569  Acc@1: 75.0000 (73.2238)  Acc@5: 100.0000 (97.7068)  time: 0.3517  data: 0.0015  max mem: 2503
Train: Epoch[1/5]  [1230/3750]  eta: 0:14:42  Lr: 0.001875  Loss: -0.8041  Acc@1: 75.0000 (73.2484)  Acc@5: 100.0000 (97.7153)  time: 0.3514  data: 0.0006  max mem: 2503
Train: Epoch[1/5]  [1240/3750]  eta: 0:14:39  Lr: 0.001875  Loss: -0.7825  Acc@1: 75.0000 (73.3179)  Acc@5: 100.0000 (97.7286)  time: 0.3511  data: 0.0007  max mem: 2503
Train: Epoch[1/5]  [1250/3750]  eta: 0:14:35  Lr: 0.001875  Loss: -0.4138  Acc@1: 75.0000 (73.3263)  Acc@5: 100.0000 (97.7318)  time: 0.3503  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [1260/3750]  eta: 0:14:32  Lr: 0.001875  Loss: -0.3198  Acc@1: 81.2500 (73.4140)  Acc@5: 100.0000 (97.7399)  time: 0.3503  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [1270/3750]  eta: 0:14:28  Lr: 0.001875  Loss: -0.5443  Acc@1: 81.2500 (73.4756)  Acc@5: 100.0000 (97.7429)  time: 0.3505  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [1280/3750]  eta: 0:14:25  Lr: 0.001875  Loss: -0.9876  Acc@1: 81.2500 (73.5753)  Acc@5: 100.0000 (97.7605)  time: 0.3506  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [1290/3750]  eta: 0:14:21  Lr: 0.001875  Loss: -0.4221  Acc@1: 75.0000 (73.5960)  Acc@5: 100.0000 (97.7779)  time: 0.3505  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [1300/3750]  eta: 0:14:18  Lr: 0.001875  Loss: -0.3143  Acc@1: 75.0000 (73.5876)  Acc@5: 100.0000 (97.7950)  time: 0.3499  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [1310/3750]  eta: 0:14:14  Lr: 0.001875  Loss: -0.4748  Acc@1: 68.7500 (73.5889)  Acc@5: 100.0000 (97.7832)  time: 0.3497  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [1320/3750]  eta: 0:14:11  Lr: 0.001875  Loss: -0.6630  Acc@1: 68.7500 (73.5759)  Acc@5: 100.0000 (97.7858)  time: 0.3496  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [1330/3750]  eta: 0:14:07  Lr: 0.001875  Loss: -0.6031  Acc@1: 75.0000 (73.5960)  Acc@5: 100.0000 (97.7789)  time: 0.3493  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [1340/3750]  eta: 0:14:04  Lr: 0.001875  Loss: -0.5546  Acc@1: 75.0000 (73.5785)  Acc@5: 100.0000 (97.7768)  time: 0.3482  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [1350/3750]  eta: 0:14:00  Lr: 0.001875  Loss: -0.2532  Acc@1: 68.7500 (73.5798)  Acc@5: 100.0000 (97.7702)  time: 0.3477  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [1360/3750]  eta: 0:13:57  Lr: 0.001875  Loss: -0.8452  Acc@1: 75.0000 (73.5856)  Acc@5: 100.0000 (97.7774)  time: 0.3478  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [1370/3750]  eta: 0:13:53  Lr: 0.001875  Loss: -0.4412  Acc@1: 75.0000 (73.5959)  Acc@5: 100.0000 (97.7845)  time: 0.3481  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [1380/3750]  eta: 0:13:50  Lr: 0.001875  Loss: -0.6588  Acc@1: 75.0000 (73.6287)  Acc@5: 100.0000 (97.7869)  time: 0.3480  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [1390/3750]  eta: 0:13:46  Lr: 0.001875  Loss: -0.1478  Acc@1: 75.0000 (73.6386)  Acc@5: 100.0000 (97.7759)  time: 0.3477  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [1400/3750]  eta: 0:13:42  Lr: 0.001875  Loss: -0.9778  Acc@1: 75.0000 (73.6661)  Acc@5: 100.0000 (97.7739)  time: 0.3477  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [1410/3750]  eta: 0:13:39  Lr: 0.001875  Loss: -0.6805  Acc@1: 81.2500 (73.7155)  Acc@5: 100.0000 (97.7808)  time: 0.3474  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [1420/3750]  eta: 0:13:35  Lr: 0.001875  Loss: -0.7034  Acc@1: 75.0000 (73.7333)  Acc@5: 100.0000 (97.7964)  time: 0.3470  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [1430/3750]  eta: 0:13:32  Lr: 0.001875  Loss: -0.3919  Acc@1: 75.0000 (73.7596)  Acc@5: 100.0000 (97.7900)  time: 0.3469  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [1440/3750]  eta: 0:13:28  Lr: 0.001875  Loss: -0.4875  Acc@1: 75.0000 (73.7726)  Acc@5: 100.0000 (97.7880)  time: 0.3475  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [1450/3750]  eta: 0:13:25  Lr: 0.001875  Loss: -0.7503  Acc@1: 81.2500 (73.8069)  Acc@5: 100.0000 (97.8032)  time: 0.3488  data: 0.0013  max mem: 2503
Train: Epoch[1/5]  [1460/3750]  eta: 0:13:21  Lr: 0.001875  Loss: -0.1928  Acc@1: 81.2500 (73.8279)  Acc@5: 100.0000 (97.8054)  time: 0.3486  data: 0.0013  max mem: 2503
Train: Epoch[1/5]  [1470/3750]  eta: 0:13:18  Lr: 0.001875  Loss: -0.5248  Acc@1: 75.0000 (73.8188)  Acc@5: 100.0000 (97.8034)  time: 0.3477  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [1480/3750]  eta: 0:13:14  Lr: 0.001875  Loss: -0.7545  Acc@1: 75.0000 (73.8479)  Acc@5: 100.0000 (97.8013)  time: 0.3485  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [1490/3750]  eta: 0:13:11  Lr: 0.001875  Loss: -0.9283  Acc@1: 75.0000 (73.8892)  Acc@5: 100.0000 (97.8035)  time: 0.3483  data: 0.0006  max mem: 2503
Train: Epoch[1/5]  [1500/3750]  eta: 0:13:07  Lr: 0.001875  Loss: -0.7113  Acc@1: 75.0000 (73.8924)  Acc@5: 100.0000 (97.7848)  time: 0.3482  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [1510/3750]  eta: 0:13:04  Lr: 0.001875  Loss: -0.5990  Acc@1: 75.0000 (73.9328)  Acc@5: 100.0000 (97.7829)  time: 0.3489  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [1520/3750]  eta: 0:13:00  Lr: 0.001875  Loss: -0.9521  Acc@1: 81.2500 (73.9563)  Acc@5: 100.0000 (97.7934)  time: 0.3487  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [1530/3750]  eta: 0:12:57  Lr: 0.001875  Loss: -0.4868  Acc@1: 75.0000 (73.9672)  Acc@5: 100.0000 (97.7915)  time: 0.3488  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [1540/3750]  eta: 0:12:53  Lr: 0.001875  Loss: -0.4640  Acc@1: 75.0000 (73.9455)  Acc@5: 100.0000 (97.7977)  time: 0.3492  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [1550/3750]  eta: 0:12:50  Lr: 0.001875  Loss: -0.8268  Acc@1: 75.0000 (73.9563)  Acc@5: 100.0000 (97.7998)  time: 0.3486  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [1560/3750]  eta: 0:12:46  Lr: 0.001875  Loss: -1.0561  Acc@1: 75.0000 (73.9630)  Acc@5: 100.0000 (97.8099)  time: 0.3486  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [1570/3750]  eta: 0:12:43  Lr: 0.001875  Loss: -0.5849  Acc@1: 75.0000 (73.9815)  Acc@5: 100.0000 (97.8119)  time: 0.3494  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [1580/3750]  eta: 0:12:39  Lr: 0.001875  Loss: -0.7976  Acc@1: 75.0000 (73.9919)  Acc@5: 100.0000 (97.8099)  time: 0.3490  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [1590/3750]  eta: 0:12:35  Lr: 0.001875  Loss: -0.8627  Acc@1: 75.0000 (74.0415)  Acc@5: 100.0000 (97.8158)  time: 0.3485  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [1600/3750]  eta: 0:12:32  Lr: 0.001875  Loss: -0.8944  Acc@1: 75.0000 (74.0631)  Acc@5: 100.0000 (97.8217)  time: 0.3489  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [1610/3750]  eta: 0:12:28  Lr: 0.001875  Loss: -0.3938  Acc@1: 75.0000 (74.0689)  Acc@5: 100.0000 (97.8158)  time: 0.3495  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [1620/3750]  eta: 0:12:25  Lr: 0.001875  Loss: -0.4218  Acc@1: 75.0000 (74.0978)  Acc@5: 100.0000 (97.8216)  time: 0.3498  data: 0.0006  max mem: 2503
Train: Epoch[1/5]  [1630/3750]  eta: 0:12:21  Lr: 0.001875  Loss: -0.7715  Acc@1: 75.0000 (74.1186)  Acc@5: 100.0000 (97.8311)  time: 0.3494  data: 0.0006  max mem: 2503
Train: Epoch[1/5]  [1640/3750]  eta: 0:12:18  Lr: 0.001875  Loss: -0.2775  Acc@1: 75.0000 (74.1240)  Acc@5: 100.0000 (97.8253)  time: 0.3492  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [1650/3750]  eta: 0:12:14  Lr: 0.001875  Loss: -0.8804  Acc@1: 81.2500 (74.1369)  Acc@5: 100.0000 (97.8309)  time: 0.3494  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [1660/3750]  eta: 0:12:11  Lr: 0.001875  Loss: -0.7571  Acc@1: 75.0000 (74.1571)  Acc@5: 100.0000 (97.8402)  time: 0.3490  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [1670/3750]  eta: 0:12:07  Lr: 0.001875  Loss: -0.0644  Acc@1: 75.0000 (74.1884)  Acc@5: 100.0000 (97.8531)  time: 0.3490  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [1680/3750]  eta: 0:12:04  Lr: 0.001875  Loss: -0.7851  Acc@1: 75.0000 (74.1895)  Acc@5: 100.0000 (97.8621)  time: 0.3489  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [1690/3750]  eta: 0:12:00  Lr: 0.001875  Loss: -0.7376  Acc@1: 75.0000 (74.2275)  Acc@5: 100.0000 (97.8711)  time: 0.3493  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [1700/3750]  eta: 0:11:57  Lr: 0.001875  Loss: -0.8509  Acc@1: 81.2500 (74.2504)  Acc@5: 100.0000 (97.8726)  time: 0.3497  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [1710/3750]  eta: 0:11:53  Lr: 0.001875  Loss: -0.6808  Acc@1: 75.0000 (74.2475)  Acc@5: 100.0000 (97.8667)  time: 0.3494  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [1720/3750]  eta: 0:11:50  Lr: 0.001875  Loss: -0.2677  Acc@1: 75.0000 (74.2773)  Acc@5: 100.0000 (97.8791)  time: 0.3494  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [1730/3750]  eta: 0:11:46  Lr: 0.001875  Loss: -0.6936  Acc@1: 81.2500 (74.2995)  Acc@5: 100.0000 (97.8878)  time: 0.3496  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [1740/3750]  eta: 0:11:43  Lr: 0.001875  Loss: -0.7070  Acc@1: 81.2500 (74.3179)  Acc@5: 100.0000 (97.8748)  time: 0.3501  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [1750/3750]  eta: 0:11:39  Lr: 0.001875  Loss: -0.7507  Acc@1: 81.2500 (74.3325)  Acc@5: 100.0000 (97.8834)  time: 0.3502  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [1760/3750]  eta: 0:11:36  Lr: 0.001875  Loss: -0.6037  Acc@1: 75.0000 (74.3292)  Acc@5: 100.0000 (97.8883)  time: 0.3499  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [1770/3750]  eta: 0:11:32  Lr: 0.001875  Loss: -0.5235  Acc@1: 75.0000 (74.2977)  Acc@5: 100.0000 (97.8790)  time: 0.3503  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [1780/3750]  eta: 0:11:29  Lr: 0.001875  Loss: -0.7950  Acc@1: 81.2500 (74.3122)  Acc@5: 100.0000 (97.8804)  time: 0.3508  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [1790/3750]  eta: 0:11:25  Lr: 0.001875  Loss: -0.3122  Acc@1: 75.0000 (74.3230)  Acc@5: 100.0000 (97.8783)  time: 0.3510  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [1800/3750]  eta: 0:11:22  Lr: 0.001875  Loss: -0.5412  Acc@1: 75.0000 (74.3476)  Acc@5: 100.0000 (97.8727)  time: 0.3509  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [1810/3750]  eta: 0:11:18  Lr: 0.001875  Loss: -0.6676  Acc@1: 81.2500 (74.3546)  Acc@5: 100.0000 (97.8707)  time: 0.3512  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [1820/3750]  eta: 0:11:15  Lr: 0.001875  Loss: -0.4155  Acc@1: 81.2500 (74.3822)  Acc@5: 100.0000 (97.8755)  time: 0.3513  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [1830/3750]  eta: 0:11:11  Lr: 0.001875  Loss: -0.7081  Acc@1: 81.2500 (74.4095)  Acc@5: 100.0000 (97.8837)  time: 0.3505  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [1840/3750]  eta: 0:11:08  Lr: 0.001875  Loss: -0.8856  Acc@1: 81.2500 (74.4229)  Acc@5: 100.0000 (97.8884)  time: 0.3503  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [1850/3750]  eta: 0:11:04  Lr: 0.001875  Loss: -0.8316  Acc@1: 75.0000 (74.4462)  Acc@5: 100.0000 (97.8930)  time: 0.3506  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [1860/3750]  eta: 0:11:01  Lr: 0.001875  Loss: -0.5439  Acc@1: 75.0000 (74.4526)  Acc@5: 100.0000 (97.8943)  time: 0.3503  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [1870/3750]  eta: 0:10:57  Lr: 0.001875  Loss: -0.5880  Acc@1: 81.2500 (74.4822)  Acc@5: 100.0000 (97.8922)  time: 0.3497  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [1880/3750]  eta: 0:10:54  Lr: 0.001875  Loss: -0.2206  Acc@1: 81.2500 (74.5082)  Acc@5: 100.0000 (97.9001)  time: 0.3495  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [1890/3750]  eta: 0:10:50  Lr: 0.001875  Loss: -0.7223  Acc@1: 75.0000 (74.5307)  Acc@5: 100.0000 (97.8979)  time: 0.3501  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [1900/3750]  eta: 0:10:47  Lr: 0.001875  Loss: -0.4742  Acc@1: 81.2500 (74.5496)  Acc@5: 100.0000 (97.9057)  time: 0.3503  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [1910/3750]  eta: 0:10:43  Lr: 0.001875  Loss: -0.5770  Acc@1: 75.0000 (74.5519)  Acc@5: 100.0000 (97.9069)  time: 0.3497  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [1920/3750]  eta: 0:10:40  Lr: 0.001875  Loss: -0.7299  Acc@1: 75.0000 (74.5640)  Acc@5: 100.0000 (97.9080)  time: 0.3504  data: 0.0008  max mem: 2503
Train: Epoch[1/5]  [1930/3750]  eta: 0:10:36  Lr: 0.001875  Loss: -0.7574  Acc@1: 75.0000 (74.5566)  Acc@5: 100.0000 (97.9059)  time: 0.3506  data: 0.0008  max mem: 2503
Train: Epoch[1/5]  [1940/3750]  eta: 0:10:33  Lr: 0.001875  Loss: -0.3647  Acc@1: 75.0000 (74.5492)  Acc@5: 100.0000 (97.9070)  time: 0.3501  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [1950/3750]  eta: 0:10:29  Lr: 0.001875  Loss: -0.6025  Acc@1: 75.0000 (74.5803)  Acc@5: 100.0000 (97.9145)  time: 0.3506  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [1960/3750]  eta: 0:10:26  Lr: 0.001875  Loss: -0.9514  Acc@1: 81.2500 (74.6144)  Acc@5: 100.0000 (97.9156)  time: 0.3501  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [1970/3750]  eta: 0:10:22  Lr: 0.001875  Loss: -0.5822  Acc@1: 81.2500 (74.6385)  Acc@5: 100.0000 (97.9198)  time: 0.3490  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [1980/3750]  eta: 0:10:19  Lr: 0.001875  Loss: -0.8908  Acc@1: 75.0000 (74.6403)  Acc@5: 100.0000 (97.9177)  time: 0.3489  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [1990/3750]  eta: 0:10:15  Lr: 0.001875  Loss: -0.3819  Acc@1: 68.7500 (74.6359)  Acc@5: 100.0000 (97.9282)  time: 0.3497  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [2000/3750]  eta: 0:10:12  Lr: 0.001875  Loss: -0.7751  Acc@1: 75.0000 (74.6564)  Acc@5: 100.0000 (97.9354)  time: 0.3502  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [2010/3750]  eta: 0:10:08  Lr: 0.001875  Loss: -0.5721  Acc@1: 75.0000 (74.6457)  Acc@5: 100.0000 (97.9426)  time: 0.3504  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [2020/3750]  eta: 0:10:05  Lr: 0.001875  Loss: -0.3499  Acc@1: 75.0000 (74.6598)  Acc@5: 100.0000 (97.9527)  time: 0.3498  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [2030/3750]  eta: 0:10:01  Lr: 0.001875  Loss: -0.6415  Acc@1: 81.2500 (74.7015)  Acc@5: 100.0000 (97.9536)  time: 0.3499  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [2040/3750]  eta: 0:09:58  Lr: 0.001875  Loss: -0.8763  Acc@1: 81.2500 (74.7275)  Acc@5: 100.0000 (97.9606)  time: 0.3503  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [2050/3750]  eta: 0:09:54  Lr: 0.001875  Loss: -0.4239  Acc@1: 75.0000 (74.7075)  Acc@5: 100.0000 (97.9705)  time: 0.3501  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [2060/3750]  eta: 0:09:51  Lr: 0.001875  Loss: -0.4637  Acc@1: 75.0000 (74.7058)  Acc@5: 100.0000 (97.9652)  time: 0.3496  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [2070/3750]  eta: 0:09:47  Lr: 0.001875  Loss: -0.8287  Acc@1: 81.2500 (74.7133)  Acc@5: 100.0000 (97.9750)  time: 0.3498  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [2080/3750]  eta: 0:09:44  Lr: 0.001875  Loss: -0.6344  Acc@1: 75.0000 (74.7027)  Acc@5: 100.0000 (97.9757)  time: 0.3500  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [2090/3750]  eta: 0:09:40  Lr: 0.001875  Loss: -0.3729  Acc@1: 68.7500 (74.6891)  Acc@5: 100.0000 (97.9794)  time: 0.3492  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [2100/3750]  eta: 0:09:37  Lr: 0.001875  Loss: -0.6000  Acc@1: 75.0000 (74.7025)  Acc@5: 100.0000 (97.9861)  time: 0.3492  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [2110/3750]  eta: 0:09:33  Lr: 0.001875  Loss: -0.8326  Acc@1: 81.2500 (74.7099)  Acc@5: 100.0000 (97.9927)  time: 0.3502  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [2120/3750]  eta: 0:09:30  Lr: 0.001875  Loss: -0.5631  Acc@1: 68.7500 (74.7230)  Acc@5: 100.0000 (97.9933)  time: 0.3499  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [2130/3750]  eta: 0:09:26  Lr: 0.001875  Loss: -0.7216  Acc@1: 75.0000 (74.7272)  Acc@5: 100.0000 (97.9998)  time: 0.3497  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [2140/3750]  eta: 0:09:23  Lr: 0.001875  Loss: -0.5387  Acc@1: 81.2500 (74.7577)  Acc@5: 100.0000 (98.0091)  time: 0.3496  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [2150/3750]  eta: 0:09:19  Lr: 0.001875  Loss: -0.5208  Acc@1: 75.0000 (74.7559)  Acc@5: 100.0000 (98.0184)  time: 0.3494  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [2160/3750]  eta: 0:09:16  Lr: 0.001875  Loss: -0.8546  Acc@1: 75.0000 (74.7773)  Acc@5: 100.0000 (98.0217)  time: 0.3502  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [2170/3750]  eta: 0:09:12  Lr: 0.001875  Loss: -1.0007  Acc@1: 75.0000 (74.8186)  Acc@5: 100.0000 (98.0251)  time: 0.3505  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [2180/3750]  eta: 0:09:09  Lr: 0.001875  Loss: -0.2099  Acc@1: 75.0000 (74.8281)  Acc@5: 100.0000 (98.0284)  time: 0.3493  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [2190/3750]  eta: 0:09:05  Lr: 0.001875  Loss: -0.4066  Acc@1: 75.0000 (74.8403)  Acc@5: 100.0000 (98.0317)  time: 0.3493  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [2200/3750]  eta: 0:09:02  Lr: 0.001875  Loss: -0.1433  Acc@1: 81.2500 (74.8609)  Acc@5: 100.0000 (98.0321)  time: 0.3498  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [2210/3750]  eta: 0:08:58  Lr: 0.001875  Loss: -1.1124  Acc@1: 81.2500 (74.8728)  Acc@5: 100.0000 (98.0297)  time: 0.3500  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [2220/3750]  eta: 0:08:55  Lr: 0.001875  Loss: -0.6444  Acc@1: 81.2500 (74.8903)  Acc@5: 100.0000 (98.0274)  time: 0.3507  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [2230/3750]  eta: 0:08:51  Lr: 0.001875  Loss: -0.8578  Acc@1: 75.0000 (74.9104)  Acc@5: 100.0000 (98.0306)  time: 0.3501  data: 0.0009  max mem: 2503
Train: Epoch[1/5]  [2240/3750]  eta: 0:08:48  Lr: 0.001875  Loss: -0.5568  Acc@1: 75.0000 (74.9191)  Acc@5: 100.0000 (98.0338)  time: 0.3506  data: 0.0009  max mem: 2503
Train: Epoch[1/5]  [2250/3750]  eta: 0:08:44  Lr: 0.001875  Loss: -0.6336  Acc@1: 75.0000 (74.9334)  Acc@5: 100.0000 (98.0370)  time: 0.3512  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [2260/3750]  eta: 0:08:41  Lr: 0.001875  Loss: -0.6899  Acc@1: 75.0000 (74.9558)  Acc@5: 100.0000 (98.0374)  time: 0.3504  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [2270/3750]  eta: 0:08:37  Lr: 0.001875  Loss: -0.9979  Acc@1: 81.2500 (74.9780)  Acc@5: 100.0000 (98.0433)  time: 0.3498  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [2280/3750]  eta: 0:08:34  Lr: 0.001875  Loss: -0.6253  Acc@1: 81.2500 (75.0082)  Acc@5: 100.0000 (98.0491)  time: 0.3496  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [2290/3750]  eta: 0:08:30  Lr: 0.001875  Loss: -0.5433  Acc@1: 81.2500 (75.0246)  Acc@5: 100.0000 (98.0494)  time: 0.3494  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [2300/3750]  eta: 0:08:27  Lr: 0.001875  Loss: -0.8905  Acc@1: 81.2500 (75.0407)  Acc@5: 100.0000 (98.0470)  time: 0.3495  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [2310/3750]  eta: 0:08:23  Lr: 0.001875  Loss: -0.4925  Acc@1: 81.2500 (75.0541)  Acc@5: 100.0000 (98.0528)  time: 0.3497  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [2320/3750]  eta: 0:08:20  Lr: 0.001875  Loss: -0.5590  Acc@1: 81.2500 (75.0700)  Acc@5: 100.0000 (98.0558)  time: 0.3495  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [2330/3750]  eta: 0:08:16  Lr: 0.001875  Loss: -0.6573  Acc@1: 75.0000 (75.0778)  Acc@5: 100.0000 (98.0615)  time: 0.3491  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [2340/3750]  eta: 0:08:13  Lr: 0.001875  Loss: -0.9796  Acc@1: 75.0000 (75.0801)  Acc@5: 100.0000 (98.0671)  time: 0.3492  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [2350/3750]  eta: 0:08:09  Lr: 0.001875  Loss: -0.1236  Acc@1: 81.2500 (75.1010)  Acc@5: 100.0000 (98.0700)  time: 0.3493  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [2360/3750]  eta: 0:08:06  Lr: 0.001875  Loss: -0.6049  Acc@1: 81.2500 (75.1112)  Acc@5: 100.0000 (98.0755)  time: 0.3494  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [2370/3750]  eta: 0:08:02  Lr: 0.001875  Loss: -0.6899  Acc@1: 75.0000 (75.1186)  Acc@5: 100.0000 (98.0731)  time: 0.3493  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [2380/3750]  eta: 0:07:59  Lr: 0.001875  Loss: -0.4886  Acc@1: 75.0000 (75.1155)  Acc@5: 100.0000 (98.0654)  time: 0.3487  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [2390/3750]  eta: 0:07:55  Lr: 0.001875  Loss: -0.6900  Acc@1: 75.0000 (75.1150)  Acc@5: 100.0000 (98.0683)  time: 0.3491  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [2400/3750]  eta: 0:07:52  Lr: 0.001875  Loss: -0.6499  Acc@1: 75.0000 (75.1145)  Acc@5: 100.0000 (98.0659)  time: 0.3496  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [2410/3750]  eta: 0:07:48  Lr: 0.001875  Loss: -0.8741  Acc@1: 81.2500 (75.1322)  Acc@5: 100.0000 (98.0662)  time: 0.3498  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [2420/3750]  eta: 0:07:45  Lr: 0.001875  Loss: -0.9818  Acc@1: 75.0000 (75.1497)  Acc@5: 100.0000 (98.0690)  time: 0.3496  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [2430/3750]  eta: 0:07:41  Lr: 0.001875  Loss: -0.7080  Acc@1: 75.0000 (75.1517)  Acc@5: 100.0000 (98.0718)  time: 0.3483  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [2440/3750]  eta: 0:07:38  Lr: 0.001875  Loss: -0.7723  Acc@1: 75.0000 (75.1767)  Acc@5: 100.0000 (98.0720)  time: 0.3490  data: 0.0011  max mem: 2503
Train: Epoch[1/5]  [2450/3750]  eta: 0:07:34  Lr: 0.001875  Loss: -0.5220  Acc@1: 75.0000 (75.1734)  Acc@5: 100.0000 (98.0773)  time: 0.3500  data: 0.0018  max mem: 2503
Train: Epoch[1/5]  [2460/3750]  eta: 0:07:31  Lr: 0.001875  Loss: -0.4516  Acc@1: 75.0000 (75.1803)  Acc@5: 100.0000 (98.0724)  time: 0.3498  data: 0.0010  max mem: 2503
Train: Epoch[1/5]  [2470/3750]  eta: 0:07:27  Lr: 0.001875  Loss: -0.9937  Acc@1: 75.0000 (75.1897)  Acc@5: 100.0000 (98.0651)  time: 0.3503  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [2480/3750]  eta: 0:07:24  Lr: 0.001875  Loss: -0.4424  Acc@1: 68.7500 (75.1587)  Acc@5: 100.0000 (98.0678)  time: 0.3500  data: 0.0007  max mem: 2503
Train: Epoch[1/5]  [2490/3750]  eta: 0:07:20  Lr: 0.001875  Loss: -0.7020  Acc@1: 68.7500 (75.1706)  Acc@5: 100.0000 (98.0680)  time: 0.3490  data: 0.0006  max mem: 2503
Train: Epoch[1/5]  [2500/3750]  eta: 0:07:17  Lr: 0.001875  Loss: -0.8278  Acc@1: 81.2500 (75.1949)  Acc@5: 100.0000 (98.0658)  time: 0.3489  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [2510/3750]  eta: 0:07:13  Lr: 0.001875  Loss: -0.6600  Acc@1: 81.2500 (75.2041)  Acc@5: 100.0000 (98.0610)  time: 0.3490  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [2520/3750]  eta: 0:07:10  Lr: 0.001875  Loss: -0.5306  Acc@1: 81.2500 (75.2231)  Acc@5: 100.0000 (98.0613)  time: 0.3490  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [2530/3750]  eta: 0:07:06  Lr: 0.001875  Loss: -0.7960  Acc@1: 81.2500 (75.2420)  Acc@5: 100.0000 (98.0615)  time: 0.3495  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [2540/3750]  eta: 0:07:03  Lr: 0.001875  Loss: -0.3187  Acc@1: 75.0000 (75.2361)  Acc@5: 100.0000 (98.0618)  time: 0.3493  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [2550/3750]  eta: 0:06:59  Lr: 0.001875  Loss: -0.4557  Acc@1: 75.0000 (75.2499)  Acc@5: 100.0000 (98.0645)  time: 0.3478  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [2560/3750]  eta: 0:06:56  Lr: 0.001875  Loss: -0.3658  Acc@1: 75.0000 (75.2221)  Acc@5: 100.0000 (98.0647)  time: 0.3482  data: 0.0008  max mem: 2503
Train: Epoch[1/5]  [2570/3750]  eta: 0:06:52  Lr: 0.001875  Loss: -0.6258  Acc@1: 68.7500 (75.2236)  Acc@5: 100.0000 (98.0698)  time: 0.3486  data: 0.0008  max mem: 2503
Train: Epoch[1/5]  [2580/3750]  eta: 0:06:49  Lr: 0.001875  Loss: -0.6347  Acc@1: 75.0000 (75.2300)  Acc@5: 100.0000 (98.0725)  time: 0.3483  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [2590/3750]  eta: 0:06:45  Lr: 0.001875  Loss: -1.1142  Acc@1: 75.0000 (75.2364)  Acc@5: 100.0000 (98.0775)  time: 0.3478  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [2600/3750]  eta: 0:06:42  Lr: 0.001875  Loss: -0.7591  Acc@1: 75.0000 (75.2595)  Acc@5: 100.0000 (98.0825)  time: 0.3471  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [2610/3750]  eta: 0:06:38  Lr: 0.001875  Loss: -0.4241  Acc@1: 81.2500 (75.2705)  Acc@5: 100.0000 (98.0826)  time: 0.3473  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [2620/3750]  eta: 0:06:35  Lr: 0.001875  Loss: -0.7910  Acc@1: 81.2500 (75.2957)  Acc@5: 100.0000 (98.0828)  time: 0.3475  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [2630/3750]  eta: 0:06:31  Lr: 0.001875  Loss: -0.2508  Acc@1: 81.2500 (75.3017)  Acc@5: 100.0000 (98.0853)  time: 0.3477  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [2640/3750]  eta: 0:06:28  Lr: 0.001875  Loss: -0.9478  Acc@1: 81.2500 (75.3124)  Acc@5: 100.0000 (98.0831)  time: 0.3481  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [2650/3750]  eta: 0:06:24  Lr: 0.001875  Loss: -0.2338  Acc@1: 75.0000 (75.3206)  Acc@5: 100.0000 (98.0856)  time: 0.3487  data: 0.0011  max mem: 2503
Train: Epoch[1/5]  [2660/3750]  eta: 0:06:21  Lr: 0.001875  Loss: -0.1337  Acc@1: 75.0000 (75.3312)  Acc@5: 100.0000 (98.0834)  time: 0.3489  data: 0.0011  max mem: 2503
Train: Epoch[1/5]  [2670/3750]  eta: 0:06:17  Lr: 0.001875  Loss: -0.8497  Acc@1: 81.2500 (75.3767)  Acc@5: 100.0000 (98.0812)  time: 0.3490  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [2680/3750]  eta: 0:06:14  Lr: 0.001875  Loss: -0.7896  Acc@1: 81.2500 (75.3777)  Acc@5: 100.0000 (98.0814)  time: 0.3491  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [2690/3750]  eta: 0:06:10  Lr: 0.001875  Loss: -0.4382  Acc@1: 75.0000 (75.3739)  Acc@5: 100.0000 (98.0816)  time: 0.3495  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [2700/3750]  eta: 0:06:07  Lr: 0.001875  Loss: -0.4515  Acc@1: 75.0000 (75.3749)  Acc@5: 100.0000 (98.0864)  time: 0.3496  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [2710/3750]  eta: 0:06:03  Lr: 0.001875  Loss: -0.9849  Acc@1: 75.0000 (75.3689)  Acc@5: 100.0000 (98.0888)  time: 0.3493  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [2720/3750]  eta: 0:06:00  Lr: 0.001875  Loss: -0.5123  Acc@1: 75.0000 (75.3675)  Acc@5: 100.0000 (98.0912)  time: 0.3502  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [2730/3750]  eta: 0:05:56  Lr: 0.001875  Loss: -0.8367  Acc@1: 75.0000 (75.3570)  Acc@5: 100.0000 (98.0982)  time: 0.3503  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [2740/3750]  eta: 0:05:53  Lr: 0.001875  Loss: -0.6081  Acc@1: 75.0000 (75.3762)  Acc@5: 100.0000 (98.0960)  time: 0.3498  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [2750/3750]  eta: 0:05:49  Lr: 0.001875  Loss: -0.9325  Acc@1: 81.2500 (75.4089)  Acc@5: 100.0000 (98.1007)  time: 0.3498  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [2760/3750]  eta: 0:05:46  Lr: 0.001875  Loss: -0.6931  Acc@1: 81.2500 (75.4143)  Acc@5: 100.0000 (98.0985)  time: 0.3494  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [2770/3750]  eta: 0:05:42  Lr: 0.001875  Loss: -0.6804  Acc@1: 81.2500 (75.4308)  Acc@5: 100.0000 (98.0918)  time: 0.3495  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [2780/3750]  eta: 0:05:39  Lr: 0.001875  Loss: -0.7218  Acc@1: 75.0000 (75.4158)  Acc@5: 100.0000 (98.0920)  time: 0.3494  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [2790/3750]  eta: 0:05:35  Lr: 0.001875  Loss: -0.4153  Acc@1: 75.0000 (75.4188)  Acc@5: 100.0000 (98.0921)  time: 0.3491  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [2800/3750]  eta: 0:05:32  Lr: 0.001875  Loss: -0.8458  Acc@1: 81.2500 (75.4440)  Acc@5: 100.0000 (98.0877)  time: 0.3499  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [2810/3750]  eta: 0:05:28  Lr: 0.001875  Loss: -0.5860  Acc@1: 81.2500 (75.4714)  Acc@5: 100.0000 (98.0923)  time: 0.3498  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [2820/3750]  eta: 0:05:25  Lr: 0.001875  Loss: -0.5240  Acc@1: 81.2500 (75.4630)  Acc@5: 100.0000 (98.0991)  time: 0.3504  data: 0.0017  max mem: 2503
Train: Epoch[1/5]  [2830/3750]  eta: 0:05:21  Lr: 0.001875  Loss: -0.1833  Acc@1: 75.0000 (75.4945)  Acc@5: 100.0000 (98.1036)  time: 0.3505  data: 0.0015  max mem: 2503
Train: Epoch[1/5]  [2840/3750]  eta: 0:05:18  Lr: 0.001875  Loss: -1.0182  Acc@1: 81.2500 (75.5060)  Acc@5: 100.0000 (98.1015)  time: 0.3498  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [2850/3750]  eta: 0:05:14  Lr: 0.001875  Loss: -0.8880  Acc@1: 81.2500 (75.5217)  Acc@5: 100.0000 (98.1015)  time: 0.3505  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [2860/3750]  eta: 0:05:11  Lr: 0.001875  Loss: -0.7834  Acc@1: 81.2500 (75.5330)  Acc@5: 100.0000 (98.0951)  time: 0.3504  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [2870/3750]  eta: 0:05:07  Lr: 0.001875  Loss: -0.5371  Acc@1: 75.0000 (75.5355)  Acc@5: 100.0000 (98.0952)  time: 0.3499  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [2880/3750]  eta: 0:05:04  Lr: 0.001875  Loss: -0.8502  Acc@1: 81.2500 (75.5597)  Acc@5: 100.0000 (98.0996)  time: 0.3498  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [2890/3750]  eta: 0:05:00  Lr: 0.001875  Loss: -0.9613  Acc@1: 87.5000 (75.5621)  Acc@5: 100.0000 (98.1019)  time: 0.3505  data: 0.0010  max mem: 2503
Train: Epoch[1/5]  [2900/3750]  eta: 0:04:57  Lr: 0.001875  Loss: -0.6924  Acc@1: 81.2500 (75.5839)  Acc@5: 100.0000 (98.1041)  time: 0.3511  data: 0.0017  max mem: 2503
Train: Epoch[1/5]  [2910/3750]  eta: 0:04:53  Lr: 0.001875  Loss: -0.4713  Acc@1: 81.2500 (75.5947)  Acc@5: 100.0000 (98.1042)  time: 0.3504  data: 0.0010  max mem: 2503
Train: Epoch[1/5]  [2920/3750]  eta: 0:04:50  Lr: 0.001875  Loss: -0.1213  Acc@1: 75.0000 (75.5991)  Acc@5: 100.0000 (98.1042)  time: 0.3499  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [2930/3750]  eta: 0:04:46  Lr: 0.001875  Loss: -0.5388  Acc@1: 75.0000 (75.6120)  Acc@5: 100.0000 (98.1022)  time: 0.3497  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [2940/3750]  eta: 0:04:43  Lr: 0.001875  Loss: -0.7384  Acc@1: 75.0000 (75.6057)  Acc@5: 100.0000 (98.1044)  time: 0.3496  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [2950/3750]  eta: 0:04:39  Lr: 0.001875  Loss: -0.4571  Acc@1: 68.7500 (75.5909)  Acc@5: 100.0000 (98.0981)  time: 0.3501  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [2960/3750]  eta: 0:04:36  Lr: 0.001875  Loss: -0.6721  Acc@1: 68.7500 (75.6058)  Acc@5: 100.0000 (98.1003)  time: 0.3509  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [2970/3750]  eta: 0:04:32  Lr: 0.001875  Loss: -0.3650  Acc@1: 81.2500 (75.6290)  Acc@5: 100.0000 (98.1004)  time: 0.3500  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [2980/3750]  eta: 0:04:29  Lr: 0.001875  Loss: -0.6400  Acc@1: 81.2500 (75.6479)  Acc@5: 100.0000 (98.1005)  time: 0.3495  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [2990/3750]  eta: 0:04:25  Lr: 0.001875  Loss: -0.3512  Acc@1: 81.2500 (75.6561)  Acc@5: 100.0000 (98.1006)  time: 0.3497  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [3000/3750]  eta: 0:04:22  Lr: 0.001875  Loss: -0.6125  Acc@1: 75.0000 (75.6602)  Acc@5: 100.0000 (98.1048)  time: 0.3488  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [3010/3750]  eta: 0:04:18  Lr: 0.001875  Loss: -0.8717  Acc@1: 81.2500 (75.6954)  Acc@5: 100.0000 (98.1069)  time: 0.3487  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [3020/3750]  eta: 0:04:15  Lr: 0.001875  Loss: -0.9969  Acc@1: 81.2500 (75.7034)  Acc@5: 100.0000 (98.1070)  time: 0.3487  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [3030/3750]  eta: 0:04:11  Lr: 0.001875  Loss: -0.4489  Acc@1: 75.0000 (75.7238)  Acc@5: 100.0000 (98.1009)  time: 0.3487  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [3040/3750]  eta: 0:04:08  Lr: 0.001875  Loss: -0.4075  Acc@1: 81.2500 (75.7419)  Acc@5: 100.0000 (98.1051)  time: 0.3482  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [3050/3750]  eta: 0:04:04  Lr: 0.001875  Loss: -0.7113  Acc@1: 81.2500 (75.7518)  Acc@5: 100.0000 (98.1051)  time: 0.3478  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [3060/3750]  eta: 0:04:01  Lr: 0.001875  Loss: -0.4125  Acc@1: 81.2500 (75.7636)  Acc@5: 100.0000 (98.1093)  time: 0.3478  data: 0.0007  max mem: 2503
Train: Epoch[1/5]  [3070/3750]  eta: 0:03:57  Lr: 0.001875  Loss: -0.3834  Acc@1: 81.2500 (75.7795)  Acc@5: 100.0000 (98.1134)  time: 0.3473  data: 0.0007  max mem: 2503
Train: Epoch[1/5]  [3080/3750]  eta: 0:03:54  Lr: 0.001875  Loss: -0.6641  Acc@1: 81.2500 (75.7932)  Acc@5: 100.0000 (98.1175)  time: 0.3478  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [3090/3750]  eta: 0:03:50  Lr: 0.001875  Loss: -0.6897  Acc@1: 81.2500 (75.8088)  Acc@5: 100.0000 (98.1195)  time: 0.3483  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [3100/3750]  eta: 0:03:47  Lr: 0.001875  Loss: -0.4759  Acc@1: 81.2500 (75.8062)  Acc@5: 100.0000 (98.1216)  time: 0.3479  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [3110/3750]  eta: 0:03:43  Lr: 0.001875  Loss: -0.3820  Acc@1: 75.0000 (75.8096)  Acc@5: 100.0000 (98.1216)  time: 0.3474  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [3120/3750]  eta: 0:03:40  Lr: 0.001875  Loss: -0.4840  Acc@1: 75.0000 (75.8231)  Acc@5: 100.0000 (98.1196)  time: 0.3477  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [3130/3750]  eta: 0:03:36  Lr: 0.001875  Loss: -0.7728  Acc@1: 75.0000 (75.8404)  Acc@5: 100.0000 (98.1256)  time: 0.3482  data: 0.0007  max mem: 2503
Train: Epoch[1/5]  [3140/3750]  eta: 0:03:33  Lr: 0.001875  Loss: -0.8428  Acc@1: 75.0000 (75.8377)  Acc@5: 100.0000 (98.1296)  time: 0.3478  data: 0.0007  max mem: 2503
Train: Epoch[1/5]  [3150/3750]  eta: 0:03:29  Lr: 0.001875  Loss: -0.1080  Acc@1: 68.7500 (75.8271)  Acc@5: 100.0000 (98.1335)  time: 0.3475  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [3160/3750]  eta: 0:03:26  Lr: 0.001875  Loss: -0.7663  Acc@1: 68.7500 (75.8225)  Acc@5: 100.0000 (98.1295)  time: 0.3493  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [3170/3750]  eta: 0:03:22  Lr: 0.001875  Loss: -0.5904  Acc@1: 75.0000 (75.8318)  Acc@5: 100.0000 (98.1335)  time: 0.3498  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [3180/3750]  eta: 0:03:19  Lr: 0.001875  Loss: -0.7787  Acc@1: 81.2500 (75.8350)  Acc@5: 100.0000 (98.1276)  time: 0.3481  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [3190/3750]  eta: 0:03:15  Lr: 0.001875  Loss: -0.7573  Acc@1: 81.2500 (75.8403)  Acc@5: 100.0000 (98.1334)  time: 0.3480  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [3200/3750]  eta: 0:03:12  Lr: 0.001875  Loss: -0.6627  Acc@1: 81.2500 (75.8611)  Acc@5: 100.0000 (98.1373)  time: 0.3483  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [3210/3750]  eta: 0:03:08  Lr: 0.001875  Loss: -0.8022  Acc@1: 81.2500 (75.8720)  Acc@5: 100.0000 (98.1412)  time: 0.3489  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [3220/3750]  eta: 0:03:05  Lr: 0.001875  Loss: -0.8481  Acc@1: 81.2500 (75.8790)  Acc@5: 100.0000 (98.1372)  time: 0.3490  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [3230/3750]  eta: 0:03:01  Lr: 0.001875  Loss: -0.9781  Acc@1: 81.2500 (75.8956)  Acc@5: 100.0000 (98.1353)  time: 0.3486  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [3240/3750]  eta: 0:02:58  Lr: 0.001875  Loss: -0.9716  Acc@1: 81.2500 (75.9064)  Acc@5: 100.0000 (98.1410)  time: 0.3504  data: 0.0011  max mem: 2503
Train: Epoch[1/5]  [3250/3750]  eta: 0:02:54  Lr: 0.001875  Loss: -0.8222  Acc@1: 75.0000 (75.9113)  Acc@5: 100.0000 (98.1390)  time: 0.3504  data: 0.0012  max mem: 2503
Train: Epoch[1/5]  [3260/3750]  eta: 0:02:51  Lr: 0.001875  Loss: -0.5845  Acc@1: 81.2500 (75.9257)  Acc@5: 100.0000 (98.1409)  time: 0.3488  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [3270/3750]  eta: 0:02:47  Lr: 0.001875  Loss: -0.5675  Acc@1: 81.2500 (75.9305)  Acc@5: 100.0000 (98.1428)  time: 0.3486  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [3280/3750]  eta: 0:02:44  Lr: 0.001875  Loss: -0.5664  Acc@1: 75.0000 (75.9353)  Acc@5: 100.0000 (98.1389)  time: 0.3487  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [3290/3750]  eta: 0:02:40  Lr: 0.001875  Loss: -0.6643  Acc@1: 75.0000 (75.9553)  Acc@5: 100.0000 (98.1408)  time: 0.3492  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [3300/3750]  eta: 0:02:37  Lr: 0.001875  Loss: -0.5836  Acc@1: 81.2500 (75.9675)  Acc@5: 100.0000 (98.1445)  time: 0.3493  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [3310/3750]  eta: 0:02:33  Lr: 0.001875  Loss: -0.6853  Acc@1: 81.2500 (75.9797)  Acc@5: 100.0000 (98.1388)  time: 0.3491  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [3320/3750]  eta: 0:02:30  Lr: 0.001875  Loss: -0.4849  Acc@1: 75.0000 (75.9861)  Acc@5: 100.0000 (98.1350)  time: 0.3490  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [3330/3750]  eta: 0:02:26  Lr: 0.001875  Loss: -0.7063  Acc@1: 75.0000 (75.9851)  Acc@5: 100.0000 (98.1331)  time: 0.3489  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [3340/3750]  eta: 0:02:23  Lr: 0.001875  Loss: 0.0316  Acc@1: 81.2500 (75.9971)  Acc@5: 100.0000 (98.1387)  time: 0.3495  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [3350/3750]  eta: 0:02:19  Lr: 0.001875  Loss: -0.9875  Acc@1: 81.2500 (76.0109)  Acc@5: 100.0000 (98.1405)  time: 0.3497  data: 0.0005  max mem: 2503
Train: Epoch[1/5]  [3360/3750]  eta: 0:02:16  Lr: 0.001875  Loss: -0.6127  Acc@1: 81.2500 (76.0135)  Acc@5: 100.0000 (98.1423)  time: 0.3498  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [3370/3750]  eta: 0:02:12  Lr: 0.001875  Loss: -0.5033  Acc@1: 81.2500 (76.0234)  Acc@5: 100.0000 (98.1441)  time: 0.3502  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [3380/3750]  eta: 0:02:09  Lr: 0.001875  Loss: -0.8889  Acc@1: 81.2500 (76.0241)  Acc@5: 100.0000 (98.1496)  time: 0.3495  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [3390/3750]  eta: 0:02:05  Lr: 0.001875  Loss: -0.6570  Acc@1: 75.0000 (76.0321)  Acc@5: 100.0000 (98.1532)  time: 0.3493  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [3400/3750]  eta: 0:02:02  Lr: 0.001875  Loss: -0.8749  Acc@1: 81.2500 (76.0456)  Acc@5: 100.0000 (98.1550)  time: 0.3498  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [3410/3750]  eta: 0:01:58  Lr: 0.001875  Loss: -0.0308  Acc@1: 81.2500 (76.0444)  Acc@5: 100.0000 (98.1549)  time: 0.3499  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [3420/3750]  eta: 0:01:55  Lr: 0.001875  Loss: -0.2368  Acc@1: 75.0000 (76.0414)  Acc@5: 100.0000 (98.1548)  time: 0.3501  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [3430/3750]  eta: 0:01:51  Lr: 0.001875  Loss: -0.6025  Acc@1: 75.0000 (76.0456)  Acc@5: 100.0000 (98.1547)  time: 0.3491  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [3440/3750]  eta: 0:01:48  Lr: 0.001875  Loss: -0.3769  Acc@1: 81.2500 (76.0644)  Acc@5: 100.0000 (98.1582)  time: 0.3485  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [3450/3750]  eta: 0:01:44  Lr: 0.001875  Loss: -0.4751  Acc@1: 81.2500 (76.0631)  Acc@5: 100.0000 (98.1618)  time: 0.3488  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [3460/3750]  eta: 0:01:41  Lr: 0.001875  Loss: -0.8957  Acc@1: 75.0000 (76.0618)  Acc@5: 100.0000 (98.1671)  time: 0.3485  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [3470/3750]  eta: 0:01:37  Lr: 0.001875  Loss: -0.6486  Acc@1: 75.0000 (76.0552)  Acc@5: 100.0000 (98.1688)  time: 0.3494  data: 0.0013  max mem: 2503
Train: Epoch[1/5]  [3480/3750]  eta: 0:01:34  Lr: 0.001875  Loss: -0.5859  Acc@1: 75.0000 (76.0629)  Acc@5: 100.0000 (98.1650)  time: 0.3503  data: 0.0014  max mem: 2503
Train: Epoch[1/5]  [3490/3750]  eta: 0:01:30  Lr: 0.001875  Loss: -0.6704  Acc@1: 81.2500 (76.0796)  Acc@5: 100.0000 (98.1703)  time: 0.3490  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [3500/3750]  eta: 0:01:27  Lr: 0.001875  Loss: -0.7091  Acc@1: 81.2500 (76.0961)  Acc@5: 100.0000 (98.1720)  time: 0.3487  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [3510/3750]  eta: 0:01:23  Lr: 0.001875  Loss: -0.5210  Acc@1: 81.2500 (76.1126)  Acc@5: 100.0000 (98.1772)  time: 0.3488  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [3520/3750]  eta: 0:01:20  Lr: 0.001875  Loss: -0.5051  Acc@1: 81.2500 (76.1307)  Acc@5: 100.0000 (98.1823)  time: 0.3485  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [3530/3750]  eta: 0:01:16  Lr: 0.001875  Loss: -0.6617  Acc@1: 81.2500 (76.1470)  Acc@5: 100.0000 (98.1857)  time: 0.3487  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [3540/3750]  eta: 0:01:13  Lr: 0.001875  Loss: -0.5581  Acc@1: 81.2500 (76.1579)  Acc@5: 100.0000 (98.1855)  time: 0.3490  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [3550/3750]  eta: 0:01:09  Lr: 0.001875  Loss: -0.3380  Acc@1: 81.2500 (76.1634)  Acc@5: 100.0000 (98.1854)  time: 0.3494  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [3560/3750]  eta: 0:01:06  Lr: 0.001875  Loss: -0.5502  Acc@1: 75.0000 (76.1759)  Acc@5: 100.0000 (98.1852)  time: 0.3490  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [3570/3750]  eta: 0:01:02  Lr: 0.001875  Loss: -0.8462  Acc@1: 75.0000 (76.1761)  Acc@5: 100.0000 (98.1868)  time: 0.3497  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [3580/3750]  eta: 0:00:59  Lr: 0.001875  Loss: -1.1228  Acc@1: 81.2500 (76.1868)  Acc@5: 100.0000 (98.1884)  time: 0.3501  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [3590/3750]  eta: 0:00:55  Lr: 0.001875  Loss: -0.0949  Acc@1: 81.2500 (76.1957)  Acc@5: 100.0000 (98.1917)  time: 0.3496  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [3600/3750]  eta: 0:00:52  Lr: 0.001875  Loss: -0.3126  Acc@1: 81.2500 (76.2028)  Acc@5: 100.0000 (98.1932)  time: 0.3500  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [3610/3750]  eta: 0:00:48  Lr: 0.001875  Loss: -0.5855  Acc@1: 75.0000 (76.1995)  Acc@5: 100.0000 (98.1948)  time: 0.3504  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [3620/3750]  eta: 0:00:45  Lr: 0.001875  Loss: -0.4896  Acc@1: 75.0000 (76.1944)  Acc@5: 100.0000 (98.1946)  time: 0.3506  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [3630/3750]  eta: 0:00:41  Lr: 0.001875  Loss: -0.4368  Acc@1: 81.2500 (76.1980)  Acc@5: 100.0000 (98.1944)  time: 0.3504  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [3640/3750]  eta: 0:00:38  Lr: 0.001875  Loss: -0.9005  Acc@1: 81.2500 (76.2016)  Acc@5: 100.0000 (98.1925)  time: 0.3505  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [3650/3750]  eta: 0:00:34  Lr: 0.001875  Loss: -0.8618  Acc@1: 75.0000 (76.1932)  Acc@5: 100.0000 (98.1957)  time: 0.3504  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [3660/3750]  eta: 0:00:31  Lr: 0.001875  Loss: -0.6181  Acc@1: 68.7500 (76.1831)  Acc@5: 100.0000 (98.1938)  time: 0.3496  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [3670/3750]  eta: 0:00:27  Lr: 0.001875  Loss: -1.0346  Acc@1: 75.0000 (76.2020)  Acc@5: 100.0000 (98.1953)  time: 0.3490  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [3680/3750]  eta: 0:00:24  Lr: 0.001875  Loss: -0.6647  Acc@1: 81.2500 (76.1953)  Acc@5: 100.0000 (98.1985)  time: 0.3494  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [3690/3750]  eta: 0:00:20  Lr: 0.001875  Loss: -1.0321  Acc@1: 75.0000 (76.2022)  Acc@5: 100.0000 (98.2000)  time: 0.3497  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [3700/3750]  eta: 0:00:17  Lr: 0.001875  Loss: -0.8711  Acc@1: 75.0000 (76.2058)  Acc@5: 100.0000 (98.2015)  time: 0.3496  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [3710/3750]  eta: 0:00:13  Lr: 0.001875  Loss: -0.9967  Acc@1: 75.0000 (76.2126)  Acc@5: 100.0000 (98.2030)  time: 0.3502  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [3720/3750]  eta: 0:00:10  Lr: 0.001875  Loss: -0.8215  Acc@1: 81.2500 (76.2396)  Acc@5: 100.0000 (98.2028)  time: 0.3502  data: 0.0003  max mem: 2503
Train: Epoch[1/5]  [3730/3750]  eta: 0:00:06  Lr: 0.001875  Loss: -0.4080  Acc@1: 81.2500 (76.2363)  Acc@5: 100.0000 (98.2042)  time: 0.3495  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [3740/3750]  eta: 0:00:03  Lr: 0.001875  Loss: -0.6054  Acc@1: 81.2500 (76.2513)  Acc@5: 100.0000 (98.2057)  time: 0.3502  data: 0.0004  max mem: 2503
Train: Epoch[1/5]  [3749/3750]  eta: 0:00:00  Lr: 0.001875  Loss: -1.0316  Acc@1: 81.2500 (76.2533)  Acc@5: 100.0000 (98.2033)  time: 0.3511  data: 0.0017  max mem: 2503
Train: Epoch[1/5] Total time: 0:21:52 (0.3499 s / it)
Averaged stats: Lr: 0.001875  Loss: -1.0316  Acc@1: 81.2500 (76.2533)  Acc@5: 100.0000 (98.2033)
Train: Epoch[2/5]  [   0/3750]  eta: 0:41:18  Lr: 0.001875  Loss: -0.6753  Acc@1: 81.2500 (81.2500)  Acc@5: 100.0000 (100.0000)  time: 0.6609  data: 0.3108  max mem: 2503
Train: Epoch[2/5]  [  10/3750]  eta: 0:23:30  Lr: 0.001875  Loss: -0.4387  Acc@1: 75.0000 (73.8636)  Acc@5: 100.0000 (97.7273)  time: 0.3770  data: 0.0285  max mem: 2503
Train: Epoch[2/5]  [  20/3750]  eta: 0:22:35  Lr: 0.001875  Loss: -0.8584  Acc@1: 75.0000 (75.8929)  Acc@5: 100.0000 (98.2143)  time: 0.3484  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [  30/3750]  eta: 0:22:15  Lr: 0.001875  Loss: -0.6520  Acc@1: 75.0000 (76.4113)  Acc@5: 100.0000 (97.7823)  time: 0.3490  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [  40/3750]  eta: 0:22:02  Lr: 0.001875  Loss: -0.7519  Acc@1: 75.0000 (76.8293)  Acc@5: 100.0000 (98.3232)  time: 0.3495  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [  50/3750]  eta: 0:21:54  Lr: 0.001875  Loss: -0.5411  Acc@1: 81.2500 (78.1863)  Acc@5: 100.0000 (98.5294)  time: 0.3493  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [  60/3750]  eta: 0:21:46  Lr: 0.001875  Loss: -0.7437  Acc@1: 81.2500 (78.6885)  Acc@5: 100.0000 (98.5656)  time: 0.3488  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [  70/3750]  eta: 0:21:39  Lr: 0.001875  Loss: -0.3937  Acc@1: 81.2500 (78.2570)  Acc@5: 100.0000 (98.5915)  time: 0.3479  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [  80/3750]  eta: 0:21:34  Lr: 0.001875  Loss: -0.8581  Acc@1: 81.2500 (78.9352)  Acc@5: 100.0000 (98.5340)  time: 0.3492  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [  90/3750]  eta: 0:21:30  Lr: 0.001875  Loss: -0.7727  Acc@1: 81.2500 (78.9835)  Acc@5: 100.0000 (98.2830)  time: 0.3502  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [ 100/3750]  eta: 0:21:25  Lr: 0.001875  Loss: -0.2215  Acc@1: 75.0000 (78.7129)  Acc@5: 100.0000 (98.4530)  time: 0.3500  data: 0.0010  max mem: 2503
Train: Epoch[2/5]  [ 110/3750]  eta: 0:21:21  Lr: 0.001875  Loss: -0.5340  Acc@1: 75.0000 (78.2658)  Acc@5: 100.0000 (98.5923)  time: 0.3499  data: 0.0010  max mem: 2503
Train: Epoch[2/5]  [ 120/3750]  eta: 0:21:17  Lr: 0.001875  Loss: -1.0258  Acc@1: 75.0000 (78.5124)  Acc@5: 100.0000 (98.7087)  time: 0.3497  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [ 130/3750]  eta: 0:21:12  Lr: 0.001875  Loss: -0.3817  Acc@1: 81.2500 (78.7214)  Acc@5: 100.0000 (98.6164)  time: 0.3494  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [ 140/3750]  eta: 0:21:09  Lr: 0.001875  Loss: -0.5764  Acc@1: 81.2500 (78.4574)  Acc@5: 100.0000 (98.6702)  time: 0.3503  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [ 150/3750]  eta: 0:21:05  Lr: 0.001875  Loss: -1.0191  Acc@1: 81.2500 (78.4768)  Acc@5: 100.0000 (98.7169)  time: 0.3510  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [ 160/3750]  eta: 0:21:01  Lr: 0.001875  Loss: -0.8251  Acc@1: 81.2500 (78.5326)  Acc@5: 100.0000 (98.7578)  time: 0.3501  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [ 170/3750]  eta: 0:20:57  Lr: 0.001875  Loss: -0.9193  Acc@1: 81.2500 (78.7646)  Acc@5: 100.0000 (98.8304)  time: 0.3500  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [ 180/3750]  eta: 0:20:54  Lr: 0.001875  Loss: -0.8180  Acc@1: 81.2500 (78.7638)  Acc@5: 100.0000 (98.8260)  time: 0.3501  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [ 190/3750]  eta: 0:20:50  Lr: 0.001875  Loss: -0.8709  Acc@1: 81.2500 (78.6322)  Acc@5: 100.0000 (98.8547)  time: 0.3500  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [ 200/3750]  eta: 0:20:46  Lr: 0.001875  Loss: -0.4068  Acc@1: 75.0000 (78.5759)  Acc@5: 100.0000 (98.8495)  time: 0.3500  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [ 210/3750]  eta: 0:20:43  Lr: 0.001875  Loss: -0.7276  Acc@1: 75.0000 (78.5249)  Acc@5: 100.0000 (98.9040)  time: 0.3509  data: 0.0011  max mem: 2503
Train: Epoch[2/5]  [ 220/3750]  eta: 0:20:39  Lr: 0.001875  Loss: -0.4010  Acc@1: 81.2500 (78.5916)  Acc@5: 100.0000 (98.8971)  time: 0.3510  data: 0.0010  max mem: 2503
Train: Epoch[2/5]  [ 230/3750]  eta: 0:20:35  Lr: 0.001875  Loss: -0.5781  Acc@1: 81.2500 (78.6526)  Acc@5: 100.0000 (98.8907)  time: 0.3505  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [ 240/3750]  eta: 0:20:32  Lr: 0.001875  Loss: -0.5844  Acc@1: 81.2500 (78.7085)  Acc@5: 100.0000 (98.9108)  time: 0.3508  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [ 250/3750]  eta: 0:20:28  Lr: 0.001875  Loss: -1.0788  Acc@1: 81.2500 (78.9094)  Acc@5: 100.0000 (98.9293)  time: 0.3505  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [ 260/3750]  eta: 0:20:25  Lr: 0.001875  Loss: -0.6444  Acc@1: 81.2500 (78.7596)  Acc@5: 100.0000 (98.8266)  time: 0.3498  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [ 270/3750]  eta: 0:20:21  Lr: 0.001875  Loss: -0.2824  Acc@1: 75.0000 (78.8054)  Acc@5: 100.0000 (98.8007)  time: 0.3500  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [ 280/3750]  eta: 0:20:17  Lr: 0.001875  Loss: -0.9830  Acc@1: 75.0000 (78.6699)  Acc@5: 100.0000 (98.8212)  time: 0.3505  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [ 290/3750]  eta: 0:20:14  Lr: 0.001875  Loss: -0.7651  Acc@1: 75.0000 (78.6942)  Acc@5: 100.0000 (98.8402)  time: 0.3504  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [ 300/3750]  eta: 0:20:10  Lr: 0.001875  Loss: -0.4165  Acc@1: 75.0000 (78.6545)  Acc@5: 100.0000 (98.8164)  time: 0.3500  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [ 310/3750]  eta: 0:20:07  Lr: 0.001875  Loss: -0.9227  Acc@1: 75.0000 (78.7178)  Acc@5: 100.0000 (98.8143)  time: 0.3498  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [ 320/3750]  eta: 0:20:03  Lr: 0.001875  Loss: -0.5310  Acc@1: 81.2500 (78.6994)  Acc@5: 100.0000 (98.8123)  time: 0.3493  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [ 330/3750]  eta: 0:19:59  Lr: 0.001875  Loss: -0.9785  Acc@1: 81.2500 (78.7764)  Acc@5: 100.0000 (98.7915)  time: 0.3492  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [ 340/3750]  eta: 0:19:55  Lr: 0.001875  Loss: -0.8210  Acc@1: 81.2500 (78.8673)  Acc@5: 100.0000 (98.8270)  time: 0.3481  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [ 350/3750]  eta: 0:19:51  Lr: 0.001875  Loss: -0.5256  Acc@1: 81.2500 (78.8996)  Acc@5: 100.0000 (98.8426)  time: 0.3473  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [ 360/3750]  eta: 0:19:48  Lr: 0.001875  Loss: -0.9086  Acc@1: 81.2500 (78.9301)  Acc@5: 100.0000 (98.8227)  time: 0.3477  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [ 370/3750]  eta: 0:19:44  Lr: 0.001875  Loss: -0.3051  Acc@1: 81.2500 (78.9757)  Acc@5: 100.0000 (98.8208)  time: 0.3484  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [ 380/3750]  eta: 0:19:40  Lr: 0.001875  Loss: -0.6178  Acc@1: 81.2500 (78.9206)  Acc@5: 100.0000 (98.8025)  time: 0.3488  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [ 390/3750]  eta: 0:19:37  Lr: 0.001875  Loss: -0.6694  Acc@1: 75.0000 (78.9162)  Acc@5: 100.0000 (98.7372)  time: 0.3493  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [ 400/3750]  eta: 0:19:33  Lr: 0.001875  Loss: -0.6461  Acc@1: 81.2500 (78.9433)  Acc@5: 100.0000 (98.7219)  time: 0.3490  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [ 410/3750]  eta: 0:19:29  Lr: 0.001875  Loss: -0.7081  Acc@1: 81.2500 (78.8169)  Acc@5: 100.0000 (98.6770)  time: 0.3480  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [ 420/3750]  eta: 0:19:26  Lr: 0.001875  Loss: -0.4330  Acc@1: 81.2500 (78.9638)  Acc@5: 100.0000 (98.6787)  time: 0.3478  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [ 430/3750]  eta: 0:19:22  Lr: 0.001875  Loss: -0.5033  Acc@1: 81.2500 (78.9008)  Acc@5: 100.0000 (98.6659)  time: 0.3485  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [ 440/3750]  eta: 0:19:18  Lr: 0.001875  Loss: -1.1137  Acc@1: 81.2500 (79.0108)  Acc@5: 100.0000 (98.6678)  time: 0.3486  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [ 450/3750]  eta: 0:19:15  Lr: 0.001875  Loss: -0.9408  Acc@1: 81.2500 (78.9080)  Acc@5: 100.0000 (98.6973)  time: 0.3479  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [ 460/3750]  eta: 0:19:11  Lr: 0.001875  Loss: -0.4843  Acc@1: 75.0000 (78.8639)  Acc@5: 100.0000 (98.6714)  time: 0.3478  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [ 470/3750]  eta: 0:19:08  Lr: 0.001875  Loss: -0.8348  Acc@1: 75.0000 (78.8349)  Acc@5: 100.0000 (98.6730)  time: 0.3487  data: 0.0006  max mem: 2503
Train: Epoch[2/5]  [ 480/3750]  eta: 0:19:04  Lr: 0.001875  Loss: -1.0693  Acc@1: 75.0000 (78.8851)  Acc@5: 100.0000 (98.6876)  time: 0.3489  data: 0.0007  max mem: 2503
Train: Epoch[2/5]  [ 490/3750]  eta: 0:19:00  Lr: 0.001875  Loss: -0.6443  Acc@1: 81.2500 (78.8697)  Acc@5: 100.0000 (98.6762)  time: 0.3484  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [ 500/3750]  eta: 0:18:57  Lr: 0.001875  Loss: -0.5741  Acc@1: 81.2500 (78.8548)  Acc@5: 100.0000 (98.6776)  time: 0.3488  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [ 510/3750]  eta: 0:18:53  Lr: 0.001875  Loss: -0.4301  Acc@1: 81.2500 (78.8405)  Acc@5: 100.0000 (98.6668)  time: 0.3494  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [ 520/3750]  eta: 0:18:50  Lr: 0.001875  Loss: -0.8103  Acc@1: 81.2500 (78.7428)  Acc@5: 100.0000 (98.6804)  time: 0.3493  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [ 530/3750]  eta: 0:18:46  Lr: 0.001875  Loss: -0.5847  Acc@1: 75.0000 (78.7076)  Acc@5: 100.0000 (98.6582)  time: 0.3488  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [ 540/3750]  eta: 0:18:43  Lr: 0.001875  Loss: -0.5249  Acc@1: 81.2500 (78.7546)  Acc@5: 100.0000 (98.6483)  time: 0.3496  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [ 550/3750]  eta: 0:18:39  Lr: 0.001875  Loss: -0.4575  Acc@1: 81.2500 (78.7999)  Acc@5: 100.0000 (98.6615)  time: 0.3501  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [ 560/3750]  eta: 0:18:36  Lr: 0.001875  Loss: -0.8432  Acc@1: 81.2500 (78.8770)  Acc@5: 100.0000 (98.6854)  time: 0.3496  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [ 570/3750]  eta: 0:18:32  Lr: 0.001875  Loss: -0.8604  Acc@1: 81.2500 (78.9405)  Acc@5: 100.0000 (98.6646)  time: 0.3495  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [ 580/3750]  eta: 0:18:29  Lr: 0.001875  Loss: -0.0544  Acc@1: 81.2500 (78.8511)  Acc@5: 100.0000 (98.6769)  time: 0.3497  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [ 590/3750]  eta: 0:18:25  Lr: 0.001875  Loss: -0.8908  Acc@1: 75.0000 (78.8917)  Acc@5: 100.0000 (98.6992)  time: 0.3503  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [ 600/3750]  eta: 0:18:22  Lr: 0.001875  Loss: -0.7033  Acc@1: 81.2500 (78.9621)  Acc@5: 100.0000 (98.6897)  time: 0.3505  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [ 610/3750]  eta: 0:18:18  Lr: 0.001875  Loss: -0.8279  Acc@1: 75.0000 (78.8768)  Acc@5: 100.0000 (98.6804)  time: 0.3496  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [ 620/3750]  eta: 0:18:15  Lr: 0.001875  Loss: -0.9237  Acc@1: 75.0000 (78.9352)  Acc@5: 100.0000 (98.6715)  time: 0.3490  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [ 630/3750]  eta: 0:18:11  Lr: 0.001875  Loss: -0.7697  Acc@1: 81.2500 (78.9223)  Acc@5: 100.0000 (98.6628)  time: 0.3496  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [ 640/3750]  eta: 0:18:08  Lr: 0.001875  Loss: -1.0459  Acc@1: 81.2500 (79.0269)  Acc@5: 100.0000 (98.6739)  time: 0.3493  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [ 650/3750]  eta: 0:18:04  Lr: 0.001875  Loss: -0.6615  Acc@1: 87.5000 (79.1475)  Acc@5: 100.0000 (98.6847)  time: 0.3485  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [ 660/3750]  eta: 0:18:01  Lr: 0.001875  Loss: -0.4403  Acc@1: 87.5000 (79.1509)  Acc@5: 100.0000 (98.6857)  time: 0.3493  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [ 670/3750]  eta: 0:17:57  Lr: 0.001875  Loss: -0.7450  Acc@1: 81.2500 (79.2008)  Acc@5: 100.0000 (98.6680)  time: 0.3492  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [ 680/3750]  eta: 0:17:54  Lr: 0.001875  Loss: -0.7692  Acc@1: 81.2500 (79.2584)  Acc@5: 100.0000 (98.6509)  time: 0.3496  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [ 690/3750]  eta: 0:17:50  Lr: 0.001875  Loss: -0.6148  Acc@1: 81.2500 (79.2330)  Acc@5: 100.0000 (98.6614)  time: 0.3498  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [ 700/3750]  eta: 0:17:46  Lr: 0.001875  Loss: -0.5750  Acc@1: 81.2500 (79.2172)  Acc@5: 100.0000 (98.6715)  time: 0.3492  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [ 710/3750]  eta: 0:17:43  Lr: 0.001875  Loss: -0.1458  Acc@1: 75.0000 (79.1667)  Acc@5: 100.0000 (98.6902)  time: 0.3496  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [ 720/3750]  eta: 0:17:40  Lr: 0.001875  Loss: -0.7181  Acc@1: 75.0000 (79.1609)  Acc@5: 100.0000 (98.7084)  time: 0.3508  data: 0.0011  max mem: 2503
Train: Epoch[2/5]  [ 730/3750]  eta: 0:17:36  Lr: 0.001875  Loss: -0.5109  Acc@1: 75.0000 (79.1040)  Acc@5: 100.0000 (98.7004)  time: 0.3509  data: 0.0011  max mem: 2503
Train: Epoch[2/5]  [ 740/3750]  eta: 0:17:32  Lr: 0.001875  Loss: -0.4194  Acc@1: 75.0000 (79.0570)  Acc@5: 100.0000 (98.7011)  time: 0.3492  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [ 750/3750]  eta: 0:17:29  Lr: 0.001875  Loss: -0.8002  Acc@1: 75.0000 (79.0280)  Acc@5: 100.0000 (98.7017)  time: 0.3492  data: 0.0017  max mem: 2503
Train: Epoch[2/5]  [ 760/3750]  eta: 0:17:25  Lr: 0.001875  Loss: -0.9877  Acc@1: 81.2500 (79.0572)  Acc@5: 100.0000 (98.6942)  time: 0.3490  data: 0.0017  max mem: 2503
Train: Epoch[2/5]  [ 770/3750]  eta: 0:17:22  Lr: 0.001875  Loss: -0.5391  Acc@1: 81.2500 (79.1180)  Acc@5: 100.0000 (98.7111)  time: 0.3483  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [ 780/3750]  eta: 0:17:18  Lr: 0.001875  Loss: -0.8142  Acc@1: 87.5000 (79.1533)  Acc@5: 100.0000 (98.7116)  time: 0.3501  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [ 790/3750]  eta: 0:17:15  Lr: 0.001875  Loss: -0.6746  Acc@1: 87.5000 (79.2272)  Acc@5: 100.0000 (98.7042)  time: 0.3498  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [ 800/3750]  eta: 0:17:11  Lr: 0.001875  Loss: -0.7893  Acc@1: 81.2500 (79.2369)  Acc@5: 100.0000 (98.6891)  time: 0.3484  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [ 810/3750]  eta: 0:17:08  Lr: 0.001875  Loss: -0.7374  Acc@1: 81.2500 (79.2617)  Acc@5: 100.0000 (98.7053)  time: 0.3484  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [ 820/3750]  eta: 0:17:04  Lr: 0.001875  Loss: -0.2965  Acc@1: 81.2500 (79.2859)  Acc@5: 100.0000 (98.7058)  time: 0.3477  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [ 830/3750]  eta: 0:17:01  Lr: 0.001875  Loss: -0.8621  Acc@1: 75.0000 (79.1968)  Acc@5: 100.0000 (98.7064)  time: 0.3475  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [ 840/3750]  eta: 0:16:57  Lr: 0.001875  Loss: -0.7699  Acc@1: 75.0000 (79.2360)  Acc@5: 100.0000 (98.7069)  time: 0.3473  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [ 850/3750]  eta: 0:16:54  Lr: 0.001875  Loss: -0.8481  Acc@1: 81.2500 (79.2083)  Acc@5: 100.0000 (98.7001)  time: 0.3478  data: 0.0006  max mem: 2503
Train: Epoch[2/5]  [ 860/3750]  eta: 0:16:50  Lr: 0.001875  Loss: -0.9538  Acc@1: 81.2500 (79.2828)  Acc@5: 100.0000 (98.7006)  time: 0.3477  data: 0.0006  max mem: 2503
Train: Epoch[2/5]  [ 870/3750]  eta: 0:16:46  Lr: 0.001875  Loss: -0.8412  Acc@1: 81.2500 (79.2910)  Acc@5: 100.0000 (98.6940)  time: 0.3472  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [ 880/3750]  eta: 0:16:43  Lr: 0.001875  Loss: -0.9910  Acc@1: 81.2500 (79.3417)  Acc@5: 100.0000 (98.6947)  time: 0.3476  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [ 890/3750]  eta: 0:16:39  Lr: 0.001875  Loss: -0.6960  Acc@1: 81.2500 (79.3701)  Acc@5: 100.0000 (98.7023)  time: 0.3479  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [ 900/3750]  eta: 0:16:36  Lr: 0.001875  Loss: -0.2547  Acc@1: 81.2500 (79.3979)  Acc@5: 100.0000 (98.6820)  time: 0.3487  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [ 910/3750]  eta: 0:16:32  Lr: 0.001875  Loss: -0.8693  Acc@1: 87.5000 (79.4662)  Acc@5: 100.0000 (98.6965)  time: 0.3484  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [ 920/3750]  eta: 0:16:29  Lr: 0.001875  Loss: -0.8533  Acc@1: 75.0000 (79.4381)  Acc@5: 100.0000 (98.6971)  time: 0.3479  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [ 930/3750]  eta: 0:16:25  Lr: 0.001875  Loss: -0.9249  Acc@1: 75.0000 (79.4106)  Acc@5: 100.0000 (98.7111)  time: 0.3487  data: 0.0009  max mem: 2503
Train: Epoch[2/5]  [ 940/3750]  eta: 0:16:22  Lr: 0.001875  Loss: -0.8734  Acc@1: 81.2500 (79.4301)  Acc@5: 100.0000 (98.7181)  time: 0.3488  data: 0.0009  max mem: 2503
Train: Epoch[2/5]  [ 950/3750]  eta: 0:16:18  Lr: 0.001875  Loss: -0.5059  Acc@1: 81.2500 (79.4230)  Acc@5: 100.0000 (98.7250)  time: 0.3481  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [ 960/3750]  eta: 0:16:15  Lr: 0.001875  Loss: -0.6991  Acc@1: 75.0000 (79.3704)  Acc@5: 100.0000 (98.7383)  time: 0.3478  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [ 970/3750]  eta: 0:16:11  Lr: 0.001875  Loss: -0.9331  Acc@1: 75.0000 (79.3447)  Acc@5: 100.0000 (98.7255)  time: 0.3482  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [ 980/3750]  eta: 0:16:07  Lr: 0.001875  Loss: -0.9026  Acc@1: 81.2500 (79.4088)  Acc@5: 100.0000 (98.7322)  time: 0.3485  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [ 990/3750]  eta: 0:16:04  Lr: 0.001875  Loss: -0.5980  Acc@1: 81.2500 (79.4084)  Acc@5: 100.0000 (98.7450)  time: 0.3484  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [1000/3750]  eta: 0:16:00  Lr: 0.001875  Loss: -0.7970  Acc@1: 81.2500 (79.4830)  Acc@5: 100.0000 (98.7450)  time: 0.3494  data: 0.0006  max mem: 2503
Train: Epoch[2/5]  [1010/3750]  eta: 0:15:57  Lr: 0.001875  Loss: -1.0408  Acc@1: 81.2500 (79.4696)  Acc@5: 100.0000 (98.7512)  time: 0.3497  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [1020/3750]  eta: 0:15:53  Lr: 0.001875  Loss: -0.6852  Acc@1: 81.2500 (79.4564)  Acc@5: 100.0000 (98.7451)  time: 0.3493  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [1030/3750]  eta: 0:15:50  Lr: 0.001875  Loss: -0.9380  Acc@1: 81.2500 (79.4920)  Acc@5: 100.0000 (98.7573)  time: 0.3490  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [1040/3750]  eta: 0:15:46  Lr: 0.001875  Loss: -0.6207  Acc@1: 81.2500 (79.4669)  Acc@5: 100.0000 (98.7512)  time: 0.3488  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [1050/3750]  eta: 0:15:43  Lr: 0.001875  Loss: -0.1803  Acc@1: 75.0000 (79.4719)  Acc@5: 100.0000 (98.7393)  time: 0.3495  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [1060/3750]  eta: 0:15:39  Lr: 0.001875  Loss: -0.7044  Acc@1: 81.2500 (79.4769)  Acc@5: 100.0000 (98.7453)  time: 0.3494  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [1070/3750]  eta: 0:15:36  Lr: 0.001875  Loss: -0.4901  Acc@1: 75.0000 (79.4293)  Acc@5: 100.0000 (98.7337)  time: 0.3490  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [1080/3750]  eta: 0:15:33  Lr: 0.001875  Loss: -0.4134  Acc@1: 75.0000 (79.3999)  Acc@5: 100.0000 (98.7280)  time: 0.3500  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [1090/3750]  eta: 0:15:29  Lr: 0.001875  Loss: -0.7806  Acc@1: 81.2500 (79.4397)  Acc@5: 100.0000 (98.7225)  time: 0.3502  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [1100/3750]  eta: 0:15:26  Lr: 0.001875  Loss: -0.4664  Acc@1: 81.2500 (79.3881)  Acc@5: 100.0000 (98.7057)  time: 0.3501  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [1110/3750]  eta: 0:15:22  Lr: 0.001875  Loss: -0.8214  Acc@1: 75.0000 (79.3936)  Acc@5: 100.0000 (98.7117)  time: 0.3509  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [1120/3750]  eta: 0:15:19  Lr: 0.001875  Loss: -0.9339  Acc@1: 81.2500 (79.4213)  Acc@5: 100.0000 (98.7177)  time: 0.3508  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [1130/3750]  eta: 0:15:15  Lr: 0.001875  Loss: -0.5816  Acc@1: 81.2500 (79.4430)  Acc@5: 100.0000 (98.7235)  time: 0.3508  data: 0.0007  max mem: 2503
Train: Epoch[2/5]  [1140/3750]  eta: 0:15:12  Lr: 0.001875  Loss: -0.5247  Acc@1: 75.0000 (79.3931)  Acc@5: 100.0000 (98.7182)  time: 0.3508  data: 0.0007  max mem: 2503
Train: Epoch[2/5]  [1150/3750]  eta: 0:15:08  Lr: 0.001875  Loss: -0.5184  Acc@1: 75.0000 (79.3712)  Acc@5: 100.0000 (98.7131)  time: 0.3506  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [1160/3750]  eta: 0:15:05  Lr: 0.001875  Loss: -0.9694  Acc@1: 81.2500 (79.4035)  Acc@5: 100.0000 (98.7188)  time: 0.3501  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [1170/3750]  eta: 0:15:01  Lr: 0.001875  Loss: -0.7400  Acc@1: 81.2500 (79.4140)  Acc@5: 100.0000 (98.7244)  time: 0.3494  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [1180/3750]  eta: 0:14:58  Lr: 0.001875  Loss: -0.7431  Acc@1: 81.2500 (79.4348)  Acc@5: 100.0000 (98.7352)  time: 0.3497  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [1190/3750]  eta: 0:14:54  Lr: 0.001875  Loss: -0.8425  Acc@1: 81.2500 (79.4133)  Acc@5: 100.0000 (98.7248)  time: 0.3502  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [1200/3750]  eta: 0:14:51  Lr: 0.001875  Loss: -0.7992  Acc@1: 81.2500 (79.4546)  Acc@5: 100.0000 (98.7354)  time: 0.3504  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [1210/3750]  eta: 0:14:47  Lr: 0.001875  Loss: -0.6538  Acc@1: 81.2500 (79.4849)  Acc@5: 100.0000 (98.7304)  time: 0.3505  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [1220/3750]  eta: 0:14:44  Lr: 0.001875  Loss: -0.6601  Acc@1: 81.2500 (79.4789)  Acc@5: 100.0000 (98.7357)  time: 0.3502  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [1230/3750]  eta: 0:14:40  Lr: 0.001875  Loss: -0.9335  Acc@1: 75.0000 (79.4730)  Acc@5: 100.0000 (98.7358)  time: 0.3495  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [1240/3750]  eta: 0:14:37  Lr: 0.001875  Loss: -1.1043  Acc@1: 81.2500 (79.5075)  Acc@5: 100.0000 (98.7409)  time: 0.3496  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [1250/3750]  eta: 0:14:33  Lr: 0.001875  Loss: -0.7160  Acc@1: 81.2500 (79.4964)  Acc@5: 100.0000 (98.7510)  time: 0.3502  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [1260/3750]  eta: 0:14:30  Lr: 0.001875  Loss: -0.4268  Acc@1: 75.0000 (79.4905)  Acc@5: 100.0000 (98.7559)  time: 0.3494  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [1270/3750]  eta: 0:14:26  Lr: 0.001875  Loss: -0.8230  Acc@1: 75.0000 (79.4896)  Acc@5: 100.0000 (98.7510)  time: 0.3489  data: 0.0002  max mem: 2503
Train: Epoch[2/5]  [1280/3750]  eta: 0:14:23  Lr: 0.001875  Loss: -0.9275  Acc@1: 81.2500 (79.5277)  Acc@5: 100.0000 (98.7607)  time: 0.3493  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [1290/3750]  eta: 0:14:19  Lr: 0.001875  Loss: -0.7421  Acc@1: 81.2500 (79.5314)  Acc@5: 100.0000 (98.7607)  time: 0.3493  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [1300/3750]  eta: 0:14:16  Lr: 0.001875  Loss: -0.4547  Acc@1: 75.0000 (79.5158)  Acc@5: 100.0000 (98.7606)  time: 0.3496  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [1310/3750]  eta: 0:14:12  Lr: 0.001875  Loss: -0.8370  Acc@1: 75.0000 (79.5290)  Acc@5: 100.0000 (98.7557)  time: 0.3501  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [1320/3750]  eta: 0:14:09  Lr: 0.001875  Loss: 0.0308  Acc@1: 81.2500 (79.4994)  Acc@5: 100.0000 (98.7462)  time: 0.3510  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [1330/3750]  eta: 0:14:05  Lr: 0.001875  Loss: -0.4277  Acc@1: 75.0000 (79.4468)  Acc@5: 100.0000 (98.7415)  time: 0.3509  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [1340/3750]  eta: 0:14:02  Lr: 0.001875  Loss: -0.8202  Acc@1: 75.0000 (79.4137)  Acc@5: 100.0000 (98.7463)  time: 0.3498  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [1350/3750]  eta: 0:13:58  Lr: 0.001875  Loss: -0.6599  Acc@1: 75.0000 (79.4365)  Acc@5: 100.0000 (98.7370)  time: 0.3496  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [1360/3750]  eta: 0:13:55  Lr: 0.001875  Loss: -0.9465  Acc@1: 81.2500 (79.4407)  Acc@5: 100.0000 (98.7417)  time: 0.3492  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [1370/3750]  eta: 0:13:51  Lr: 0.001875  Loss: -0.7128  Acc@1: 81.2500 (79.4265)  Acc@5: 100.0000 (98.7509)  time: 0.3487  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [1380/3750]  eta: 0:13:48  Lr: 0.001875  Loss: -0.5484  Acc@1: 75.0000 (79.3899)  Acc@5: 100.0000 (98.7464)  time: 0.3492  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [1390/3750]  eta: 0:13:44  Lr: 0.001875  Loss: -0.6294  Acc@1: 75.0000 (79.3853)  Acc@5: 100.0000 (98.7554)  time: 0.3500  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [1400/3750]  eta: 0:13:41  Lr: 0.001875  Loss: -1.0171  Acc@1: 87.5000 (79.4209)  Acc@5: 100.0000 (98.7598)  time: 0.3508  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [1410/3750]  eta: 0:13:38  Lr: 0.001875  Loss: -0.6227  Acc@1: 87.5000 (79.4295)  Acc@5: 100.0000 (98.7686)  time: 0.3507  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [1420/3750]  eta: 0:13:34  Lr: 0.001875  Loss: -0.5448  Acc@1: 75.0000 (79.4027)  Acc@5: 100.0000 (98.7553)  time: 0.3498  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [1430/3750]  eta: 0:13:31  Lr: 0.001875  Loss: -0.6121  Acc@1: 75.0000 (79.4113)  Acc@5: 100.0000 (98.7640)  time: 0.3495  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [1440/3750]  eta: 0:13:27  Lr: 0.001875  Loss: -0.7977  Acc@1: 81.2500 (79.4327)  Acc@5: 100.0000 (98.7682)  time: 0.3495  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [1450/3750]  eta: 0:13:24  Lr: 0.001875  Loss: -0.4235  Acc@1: 87.5000 (79.4797)  Acc@5: 100.0000 (98.7638)  time: 0.3495  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [1460/3750]  eta: 0:13:20  Lr: 0.001875  Loss: -0.6208  Acc@1: 81.2500 (79.4832)  Acc@5: 100.0000 (98.7594)  time: 0.3504  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [1470/3750]  eta: 0:13:17  Lr: 0.001875  Loss: -0.7296  Acc@1: 81.2500 (79.5165)  Acc@5: 100.0000 (98.7636)  time: 0.3508  data: 0.0006  max mem: 2503
Train: Epoch[2/5]  [1480/3750]  eta: 0:13:13  Lr: 0.001875  Loss: -0.9937  Acc@1: 81.2500 (79.5451)  Acc@5: 100.0000 (98.7593)  time: 0.3497  data: 0.0006  max mem: 2503
Train: Epoch[2/5]  [1490/3750]  eta: 0:13:10  Lr: 0.001875  Loss: -0.9058  Acc@1: 81.2500 (79.5733)  Acc@5: 100.0000 (98.7676)  time: 0.3492  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [1500/3750]  eta: 0:13:06  Lr: 0.001875  Loss: -0.7504  Acc@1: 81.2500 (79.5886)  Acc@5: 100.0000 (98.7675)  time: 0.3494  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [1510/3750]  eta: 0:13:03  Lr: 0.001875  Loss: -0.8606  Acc@1: 81.2500 (79.5831)  Acc@5: 100.0000 (98.7632)  time: 0.3494  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [1520/3750]  eta: 0:12:59  Lr: 0.001875  Loss: -1.0364  Acc@1: 75.0000 (79.5735)  Acc@5: 100.0000 (98.7714)  time: 0.3498  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [1530/3750]  eta: 0:12:56  Lr: 0.001875  Loss: -0.6294  Acc@1: 75.0000 (79.5436)  Acc@5: 100.0000 (98.7753)  time: 0.3500  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [1540/3750]  eta: 0:12:52  Lr: 0.001875  Loss: -0.6194  Acc@1: 75.0000 (79.4979)  Acc@5: 100.0000 (98.7711)  time: 0.3495  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [1550/3750]  eta: 0:12:49  Lr: 0.001875  Loss: -1.0843  Acc@1: 75.0000 (79.4850)  Acc@5: 100.0000 (98.7629)  time: 0.3497  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [1560/3750]  eta: 0:12:45  Lr: 0.001875  Loss: -0.5401  Acc@1: 75.0000 (79.4723)  Acc@5: 100.0000 (98.7708)  time: 0.3492  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [1570/3750]  eta: 0:12:42  Lr: 0.001875  Loss: -0.2986  Acc@1: 75.0000 (79.4359)  Acc@5: 100.0000 (98.7786)  time: 0.3483  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [1580/3750]  eta: 0:12:38  Lr: 0.001875  Loss: -0.7782  Acc@1: 75.0000 (79.3999)  Acc@5: 100.0000 (98.7785)  time: 0.3486  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [1590/3750]  eta: 0:12:35  Lr: 0.001875  Loss: -0.7814  Acc@1: 81.2500 (79.4194)  Acc@5: 100.0000 (98.7822)  time: 0.3486  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [1600/3750]  eta: 0:12:31  Lr: 0.001875  Loss: -0.3698  Acc@1: 81.2500 (79.4035)  Acc@5: 100.0000 (98.7781)  time: 0.3490  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [1610/3750]  eta: 0:12:28  Lr: 0.001875  Loss: -0.8822  Acc@1: 81.2500 (79.4150)  Acc@5: 100.0000 (98.7663)  time: 0.3488  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [1620/3750]  eta: 0:12:24  Lr: 0.001875  Loss: -0.6739  Acc@1: 81.2500 (79.3877)  Acc@5: 100.0000 (98.7700)  time: 0.3481  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [1630/3750]  eta: 0:12:21  Lr: 0.001875  Loss: -0.8416  Acc@1: 81.2500 (79.4145)  Acc@5: 100.0000 (98.7776)  time: 0.3482  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [1640/3750]  eta: 0:12:17  Lr: 0.001875  Loss: -0.6616  Acc@1: 87.5000 (79.4295)  Acc@5: 100.0000 (98.7736)  time: 0.3485  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [1650/3750]  eta: 0:12:14  Lr: 0.001875  Loss: -0.4717  Acc@1: 81.2500 (79.4216)  Acc@5: 100.0000 (98.7735)  time: 0.3488  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [1660/3750]  eta: 0:12:10  Lr: 0.001875  Loss: -0.6787  Acc@1: 81.2500 (79.4100)  Acc@5: 100.0000 (98.7809)  time: 0.3481  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [1670/3750]  eta: 0:12:06  Lr: 0.001875  Loss: -0.7799  Acc@1: 81.2500 (79.4135)  Acc@5: 100.0000 (98.7807)  time: 0.3487  data: 0.0011  max mem: 2503
Train: Epoch[2/5]  [1680/3750]  eta: 0:12:03  Lr: 0.001875  Loss: -0.5059  Acc@1: 81.2500 (79.4207)  Acc@5: 100.0000 (98.7805)  time: 0.3487  data: 0.0011  max mem: 2503
Train: Epoch[2/5]  [1690/3750]  eta: 0:11:59  Lr: 0.001875  Loss: -0.6105  Acc@1: 81.2500 (79.4094)  Acc@5: 100.0000 (98.7840)  time: 0.3478  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [1700/3750]  eta: 0:11:56  Lr: 0.001875  Loss: -0.5906  Acc@1: 75.0000 (79.4055)  Acc@5: 100.0000 (98.7838)  time: 0.3478  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [1710/3750]  eta: 0:11:52  Lr: 0.001875  Loss: -0.9753  Acc@1: 75.0000 (79.3980)  Acc@5: 100.0000 (98.7763)  time: 0.3482  data: 0.0009  max mem: 2503
Train: Epoch[2/5]  [1720/3750]  eta: 0:11:49  Lr: 0.001875  Loss: -0.8845  Acc@1: 81.2500 (79.4124)  Acc@5: 100.0000 (98.7689)  time: 0.3486  data: 0.0014  max mem: 2503
Train: Epoch[2/5]  [1730/3750]  eta: 0:11:45  Lr: 0.001875  Loss: -0.4327  Acc@1: 81.2500 (79.4302)  Acc@5: 100.0000 (98.7652)  time: 0.3478  data: 0.0009  max mem: 2503
Train: Epoch[2/5]  [1740/3750]  eta: 0:11:42  Lr: 0.001875  Loss: -0.8195  Acc@1: 81.2500 (79.4407)  Acc@5: 100.0000 (98.7651)  time: 0.3474  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [1750/3750]  eta: 0:11:38  Lr: 0.001875  Loss: -0.3756  Acc@1: 81.2500 (79.4510)  Acc@5: 100.0000 (98.7614)  time: 0.3476  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [1760/3750]  eta: 0:11:35  Lr: 0.001875  Loss: -1.0302  Acc@1: 81.2500 (79.4790)  Acc@5: 100.0000 (98.7649)  time: 0.3478  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [1770/3750]  eta: 0:11:31  Lr: 0.001875  Loss: -0.5695  Acc@1: 81.2500 (79.4925)  Acc@5: 100.0000 (98.7613)  time: 0.3487  data: 0.0006  max mem: 2503
Train: Epoch[2/5]  [1780/3750]  eta: 0:11:28  Lr: 0.001875  Loss: -1.0388  Acc@1: 81.2500 (79.4954)  Acc@5: 100.0000 (98.7647)  time: 0.3487  data: 0.0009  max mem: 2503
Train: Epoch[2/5]  [1790/3750]  eta: 0:11:24  Lr: 0.001875  Loss: -0.8196  Acc@1: 81.2500 (79.4947)  Acc@5: 100.0000 (98.7716)  time: 0.3482  data: 0.0006  max mem: 2503
Train: Epoch[2/5]  [1800/3750]  eta: 0:11:21  Lr: 0.001875  Loss: -0.7682  Acc@1: 81.2500 (79.4871)  Acc@5: 100.0000 (98.7750)  time: 0.3479  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [1810/3750]  eta: 0:11:17  Lr: 0.001875  Loss: -0.6741  Acc@1: 81.2500 (79.4968)  Acc@5: 100.0000 (98.7783)  time: 0.3487  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [1820/3750]  eta: 0:11:14  Lr: 0.001875  Loss: -0.5976  Acc@1: 81.2500 (79.4859)  Acc@5: 100.0000 (98.7781)  time: 0.3489  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [1830/3750]  eta: 0:11:10  Lr: 0.001875  Loss: -0.8100  Acc@1: 75.0000 (79.4955)  Acc@5: 100.0000 (98.7780)  time: 0.3482  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [1840/3750]  eta: 0:11:07  Lr: 0.001875  Loss: -0.7737  Acc@1: 81.2500 (79.5050)  Acc@5: 100.0000 (98.7846)  time: 0.3487  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [1850/3750]  eta: 0:11:03  Lr: 0.001875  Loss: -0.3239  Acc@1: 81.2500 (79.4942)  Acc@5: 100.0000 (98.7878)  time: 0.3499  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [1860/3750]  eta: 0:11:00  Lr: 0.001875  Loss: -0.5726  Acc@1: 75.0000 (79.4868)  Acc@5: 100.0000 (98.7843)  time: 0.3502  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [1870/3750]  eta: 0:10:56  Lr: 0.001875  Loss: -0.7654  Acc@1: 75.0000 (79.4862)  Acc@5: 100.0000 (98.7807)  time: 0.3500  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [1880/3750]  eta: 0:10:53  Lr: 0.001875  Loss: -1.0871  Acc@1: 75.0000 (79.4724)  Acc@5: 100.0000 (98.7839)  time: 0.3500  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [1890/3750]  eta: 0:10:49  Lr: 0.001875  Loss: -0.8147  Acc@1: 75.0000 (79.4355)  Acc@5: 100.0000 (98.7870)  time: 0.3500  data: 0.0012  max mem: 2503
Train: Epoch[2/5]  [1900/3750]  eta: 0:10:46  Lr: 0.001875  Loss: -0.6135  Acc@1: 81.2500 (79.4615)  Acc@5: 100.0000 (98.7835)  time: 0.3497  data: 0.0010  max mem: 2503
Train: Epoch[2/5]  [1910/3750]  eta: 0:10:42  Lr: 0.001875  Loss: -0.3887  Acc@1: 81.2500 (79.4774)  Acc@5: 100.0000 (98.7834)  time: 0.3496  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [1920/3750]  eta: 0:10:39  Lr: 0.001875  Loss: -0.7623  Acc@1: 81.2500 (79.4703)  Acc@5: 100.0000 (98.7734)  time: 0.3499  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [1930/3750]  eta: 0:10:35  Lr: 0.001875  Loss: -0.8064  Acc@1: 81.2500 (79.4795)  Acc@5: 100.0000 (98.7765)  time: 0.3496  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [1940/3750]  eta: 0:10:32  Lr: 0.001875  Loss: -0.4666  Acc@1: 81.2500 (79.4887)  Acc@5: 100.0000 (98.7764)  time: 0.3487  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [1950/3750]  eta: 0:10:28  Lr: 0.001875  Loss: -0.5005  Acc@1: 81.2500 (79.4785)  Acc@5: 100.0000 (98.7731)  time: 0.3491  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [1960/3750]  eta: 0:10:25  Lr: 0.001875  Loss: -0.4358  Acc@1: 75.0000 (79.4461)  Acc@5: 100.0000 (98.7666)  time: 0.3497  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [1970/3750]  eta: 0:10:21  Lr: 0.001875  Loss: -0.8062  Acc@1: 75.0000 (79.4330)  Acc@5: 100.0000 (98.7665)  time: 0.3488  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [1980/3750]  eta: 0:10:18  Lr: 0.001875  Loss: -0.7378  Acc@1: 75.0000 (79.4422)  Acc@5: 100.0000 (98.7696)  time: 0.3492  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [1990/3750]  eta: 0:10:14  Lr: 0.001875  Loss: -0.6859  Acc@1: 75.0000 (79.4481)  Acc@5: 100.0000 (98.7695)  time: 0.3510  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [2000/3750]  eta: 0:10:11  Lr: 0.001875  Loss: -0.7986  Acc@1: 81.2500 (79.4696)  Acc@5: 100.0000 (98.7694)  time: 0.3512  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [2010/3750]  eta: 0:10:08  Lr: 0.001875  Loss: -0.7706  Acc@1: 81.2500 (79.4692)  Acc@5: 100.0000 (98.7755)  time: 0.3499  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [2020/3750]  eta: 0:10:04  Lr: 0.001875  Loss: -0.1833  Acc@1: 81.2500 (79.4656)  Acc@5: 100.0000 (98.7785)  time: 0.3490  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [2030/3750]  eta: 0:10:01  Lr: 0.001875  Loss: -0.7507  Acc@1: 81.2500 (79.4775)  Acc@5: 100.0000 (98.7814)  time: 0.3490  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [2040/3750]  eta: 0:09:57  Lr: 0.001875  Loss: -0.6548  Acc@1: 87.5000 (79.4953)  Acc@5: 100.0000 (98.7874)  time: 0.3500  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [2050/3750]  eta: 0:09:54  Lr: 0.001875  Loss: -0.8075  Acc@1: 81.2500 (79.4704)  Acc@5: 100.0000 (98.7841)  time: 0.3503  data: 0.0011  max mem: 2503
Train: Epoch[2/5]  [2060/3750]  eta: 0:09:50  Lr: 0.001875  Loss: -0.5334  Acc@1: 75.0000 (79.4699)  Acc@5: 100.0000 (98.7840)  time: 0.3495  data: 0.0012  max mem: 2503
Train: Epoch[2/5]  [2070/3750]  eta: 0:09:47  Lr: 0.001875  Loss: -0.6124  Acc@1: 75.0000 (79.4453)  Acc@5: 100.0000 (98.7838)  time: 0.3492  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [2080/3750]  eta: 0:09:43  Lr: 0.001875  Loss: -0.8785  Acc@1: 75.0000 (79.4270)  Acc@5: 100.0000 (98.7776)  time: 0.3483  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [2090/3750]  eta: 0:09:40  Lr: 0.001875  Loss: -0.6483  Acc@1: 75.0000 (79.4148)  Acc@5: 100.0000 (98.7745)  time: 0.3470  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [2100/3750]  eta: 0:09:36  Lr: 0.001875  Loss: -0.7894  Acc@1: 75.0000 (79.4027)  Acc@5: 100.0000 (98.7774)  time: 0.3472  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [2110/3750]  eta: 0:09:33  Lr: 0.001875  Loss: -0.8651  Acc@1: 75.0000 (79.3848)  Acc@5: 100.0000 (98.7772)  time: 0.3479  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [2120/3750]  eta: 0:09:29  Lr: 0.001875  Loss: -0.5864  Acc@1: 75.0000 (79.3936)  Acc@5: 100.0000 (98.7712)  time: 0.3479  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [2130/3750]  eta: 0:09:25  Lr: 0.001875  Loss: -0.7805  Acc@1: 75.0000 (79.3788)  Acc@5: 100.0000 (98.7682)  time: 0.3478  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [2140/3750]  eta: 0:09:22  Lr: 0.001875  Loss: -0.7585  Acc@1: 75.0000 (79.3817)  Acc@5: 100.0000 (98.7652)  time: 0.3491  data: 0.0016  max mem: 2503
Train: Epoch[2/5]  [2150/3750]  eta: 0:09:18  Lr: 0.001875  Loss: -0.3218  Acc@1: 75.0000 (79.3613)  Acc@5: 100.0000 (98.7651)  time: 0.3490  data: 0.0016  max mem: 2503
Train: Epoch[2/5]  [2160/3750]  eta: 0:09:15  Lr: 0.001875  Loss: -0.6984  Acc@1: 75.0000 (79.3672)  Acc@5: 100.0000 (98.7708)  time: 0.3490  data: 0.0011  max mem: 2503
Train: Epoch[2/5]  [2170/3750]  eta: 0:09:12  Lr: 0.001875  Loss: -0.4752  Acc@1: 81.2500 (79.3528)  Acc@5: 100.0000 (98.7765)  time: 0.3498  data: 0.0019  max mem: 2503
Train: Epoch[2/5]  [2180/3750]  eta: 0:09:08  Lr: 0.001875  Loss: -0.6026  Acc@1: 81.2500 (79.3701)  Acc@5: 100.0000 (98.7792)  time: 0.3485  data: 0.0011  max mem: 2503
Train: Epoch[2/5]  [2190/3750]  eta: 0:09:04  Lr: 0.001875  Loss: -0.6158  Acc@1: 81.2500 (79.3530)  Acc@5: 100.0000 (98.7762)  time: 0.3473  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [2200/3750]  eta: 0:09:01  Lr: 0.001875  Loss: -0.5735  Acc@1: 81.2500 (79.3986)  Acc@5: 100.0000 (98.7818)  time: 0.3478  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [2210/3750]  eta: 0:08:58  Lr: 0.001875  Loss: -1.1018  Acc@1: 87.5000 (79.4239)  Acc@5: 100.0000 (98.7873)  time: 0.3485  data: 0.0008  max mem: 2503
Train: Epoch[2/5]  [2220/3750]  eta: 0:08:54  Lr: 0.001875  Loss: -0.4605  Acc@1: 81.2500 (79.4265)  Acc@5: 100.0000 (98.7900)  time: 0.3483  data: 0.0007  max mem: 2503
Train: Epoch[2/5]  [2230/3750]  eta: 0:08:51  Lr: 0.001875  Loss: -0.6751  Acc@1: 75.0000 (79.4179)  Acc@5: 100.0000 (98.7842)  time: 0.3485  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [2240/3750]  eta: 0:08:47  Lr: 0.001875  Loss: -0.5047  Acc@1: 75.0000 (79.4065)  Acc@5: 100.0000 (98.7729)  time: 0.3486  data: 0.0008  max mem: 2503
Train: Epoch[2/5]  [2250/3750]  eta: 0:08:44  Lr: 0.001875  Loss: -0.7799  Acc@1: 75.0000 (79.3925)  Acc@5: 100.0000 (98.7728)  time: 0.3501  data: 0.0008  max mem: 2503
Train: Epoch[2/5]  [2260/3750]  eta: 0:08:40  Lr: 0.001875  Loss: -0.2942  Acc@1: 75.0000 (79.3758)  Acc@5: 100.0000 (98.7754)  time: 0.3502  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [2270/3750]  eta: 0:08:37  Lr: 0.001875  Loss: -0.6766  Acc@1: 81.2500 (79.3951)  Acc@5: 100.0000 (98.7781)  time: 0.3488  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [2280/3750]  eta: 0:08:33  Lr: 0.001875  Loss: -0.8668  Acc@1: 75.0000 (79.3786)  Acc@5: 100.0000 (98.7725)  time: 0.3496  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [2290/3750]  eta: 0:08:30  Lr: 0.001875  Loss: -0.9465  Acc@1: 75.0000 (79.3895)  Acc@5: 100.0000 (98.7751)  time: 0.3497  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [2300/3750]  eta: 0:08:26  Lr: 0.001875  Loss: -0.6648  Acc@1: 75.0000 (79.3785)  Acc@5: 100.0000 (98.7723)  time: 0.3493  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [2310/3750]  eta: 0:08:23  Lr: 0.001875  Loss: -1.0408  Acc@1: 81.2500 (79.4002)  Acc@5: 100.0000 (98.7668)  time: 0.3493  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [2320/3750]  eta: 0:08:19  Lr: 0.001875  Loss: -1.0073  Acc@1: 81.2500 (79.3974)  Acc@5: 100.0000 (98.7667)  time: 0.3490  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [2330/3750]  eta: 0:08:16  Lr: 0.001875  Loss: -1.1005  Acc@1: 81.2500 (79.4107)  Acc@5: 100.0000 (98.7693)  time: 0.3493  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [2340/3750]  eta: 0:08:12  Lr: 0.001875  Loss: -0.9554  Acc@1: 87.5000 (79.4399)  Acc@5: 100.0000 (98.7746)  time: 0.3493  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [2350/3750]  eta: 0:08:09  Lr: 0.001875  Loss: -0.6456  Acc@1: 81.2500 (79.4343)  Acc@5: 100.0000 (98.7718)  time: 0.3497  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [2360/3750]  eta: 0:08:05  Lr: 0.001875  Loss: -0.9586  Acc@1: 75.0000 (79.4287)  Acc@5: 100.0000 (98.7664)  time: 0.3507  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [2370/3750]  eta: 0:08:02  Lr: 0.001875  Loss: -0.3649  Acc@1: 81.2500 (79.4259)  Acc@5: 100.0000 (98.7690)  time: 0.3507  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [2380/3750]  eta: 0:07:58  Lr: 0.001875  Loss: -0.5449  Acc@1: 81.2500 (79.4204)  Acc@5: 100.0000 (98.7663)  time: 0.3509  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [2390/3750]  eta: 0:07:55  Lr: 0.001875  Loss: -0.9324  Acc@1: 81.2500 (79.4385)  Acc@5: 100.0000 (98.7662)  time: 0.3499  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [2400/3750]  eta: 0:07:51  Lr: 0.001875  Loss: -0.4302  Acc@1: 81.2500 (79.4330)  Acc@5: 100.0000 (98.7531)  time: 0.3485  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [2410/3750]  eta: 0:07:48  Lr: 0.001875  Loss: -0.6359  Acc@1: 75.0000 (79.4354)  Acc@5: 100.0000 (98.7583)  time: 0.3489  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [2420/3750]  eta: 0:07:44  Lr: 0.001875  Loss: -0.6131  Acc@1: 81.2500 (79.4558)  Acc@5: 100.0000 (98.7634)  time: 0.3504  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [2430/3750]  eta: 0:07:41  Lr: 0.001875  Loss: -0.7388  Acc@1: 81.2500 (79.4503)  Acc@5: 100.0000 (98.7582)  time: 0.3505  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [2440/3750]  eta: 0:07:37  Lr: 0.001875  Loss: -0.9752  Acc@1: 75.0000 (79.4500)  Acc@5: 100.0000 (98.7608)  time: 0.3507  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [2450/3750]  eta: 0:07:34  Lr: 0.001875  Loss: -1.0143  Acc@1: 75.0000 (79.4370)  Acc@5: 100.0000 (98.7658)  time: 0.3505  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [2460/3750]  eta: 0:07:30  Lr: 0.001875  Loss: -1.0050  Acc@1: 75.0000 (79.4291)  Acc@5: 100.0000 (98.7607)  time: 0.3498  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [2470/3750]  eta: 0:07:27  Lr: 0.001875  Loss: -0.7115  Acc@1: 75.0000 (79.4263)  Acc@5: 100.0000 (98.7581)  time: 0.3518  data: 0.0024  max mem: 2503
Train: Epoch[2/5]  [2480/3750]  eta: 0:07:23  Lr: 0.001875  Loss: -0.7291  Acc@1: 75.0000 (79.4110)  Acc@5: 100.0000 (98.7530)  time: 0.3511  data: 0.0024  max mem: 2503
Train: Epoch[2/5]  [2490/3750]  eta: 0:07:20  Lr: 0.001875  Loss: -0.4045  Acc@1: 75.0000 (79.4184)  Acc@5: 100.0000 (98.7580)  time: 0.3492  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [2500/3750]  eta: 0:07:16  Lr: 0.001875  Loss: -0.7855  Acc@1: 81.2500 (79.4307)  Acc@5: 100.0000 (98.7630)  time: 0.3495  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [2510/3750]  eta: 0:07:13  Lr: 0.001875  Loss: -0.5797  Acc@1: 81.2500 (79.4355)  Acc@5: 100.0000 (98.7654)  time: 0.3493  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [2520/3750]  eta: 0:07:09  Lr: 0.001875  Loss: -0.6609  Acc@1: 75.0000 (79.4154)  Acc@5: 100.0000 (98.7679)  time: 0.3494  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [2530/3750]  eta: 0:07:06  Lr: 0.001875  Loss: -1.0045  Acc@1: 75.0000 (79.4004)  Acc@5: 100.0000 (98.7678)  time: 0.3506  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [2540/3750]  eta: 0:07:02  Lr: 0.001875  Loss: -0.3562  Acc@1: 81.2500 (79.4077)  Acc@5: 100.0000 (98.7677)  time: 0.3513  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [2550/3750]  eta: 0:06:59  Lr: 0.001875  Loss: -0.6589  Acc@1: 81.2500 (79.3904)  Acc@5: 100.0000 (98.7701)  time: 0.3506  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [2560/3750]  eta: 0:06:55  Lr: 0.001875  Loss: -0.3644  Acc@1: 81.2500 (79.3953)  Acc@5: 100.0000 (98.7676)  time: 0.3499  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [2570/3750]  eta: 0:06:52  Lr: 0.001875  Loss: -0.8485  Acc@1: 81.2500 (79.3879)  Acc@5: 100.0000 (98.7675)  time: 0.3505  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [2580/3750]  eta: 0:06:48  Lr: 0.001875  Loss: -1.0812  Acc@1: 81.2500 (79.3927)  Acc@5: 100.0000 (98.7650)  time: 0.3510  data: 0.0007  max mem: 2503
Train: Epoch[2/5]  [2590/3750]  eta: 0:06:45  Lr: 0.001875  Loss: -0.4906  Acc@1: 81.2500 (79.3781)  Acc@5: 100.0000 (98.7650)  time: 0.3510  data: 0.0007  max mem: 2503
Train: Epoch[2/5]  [2600/3750]  eta: 0:06:41  Lr: 0.001875  Loss: -0.5883  Acc@1: 81.2500 (79.3829)  Acc@5: 100.0000 (98.7625)  time: 0.3506  data: 0.0006  max mem: 2503
Train: Epoch[2/5]  [2610/3750]  eta: 0:06:38  Lr: 0.001875  Loss: -0.8336  Acc@1: 75.0000 (79.3637)  Acc@5: 100.0000 (98.7553)  time: 0.3502  data: 0.0006  max mem: 2503
Train: Epoch[2/5]  [2620/3750]  eta: 0:06:34  Lr: 0.001875  Loss: -1.0743  Acc@1: 75.0000 (79.3614)  Acc@5: 100.0000 (98.7600)  time: 0.3498  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [2630/3750]  eta: 0:06:31  Lr: 0.001875  Loss: -0.6331  Acc@1: 75.0000 (79.3520)  Acc@5: 100.0000 (98.7624)  time: 0.3500  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [2640/3750]  eta: 0:06:27  Lr: 0.001875  Loss: -1.1382  Acc@1: 81.2500 (79.3733)  Acc@5: 100.0000 (98.7623)  time: 0.3507  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [2650/3750]  eta: 0:06:24  Lr: 0.001875  Loss: -0.8189  Acc@1: 81.2500 (79.3663)  Acc@5: 100.0000 (98.7646)  time: 0.3503  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [2660/3750]  eta: 0:06:20  Lr: 0.001875  Loss: -0.9018  Acc@1: 81.2500 (79.3781)  Acc@5: 100.0000 (98.7693)  time: 0.3497  data: 0.0006  max mem: 2503
Train: Epoch[2/5]  [2670/3750]  eta: 0:06:17  Lr: 0.001875  Loss: -0.6341  Acc@1: 81.2500 (79.3851)  Acc@5: 100.0000 (98.7692)  time: 0.3497  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [2680/3750]  eta: 0:06:13  Lr: 0.001875  Loss: -0.6675  Acc@1: 81.2500 (79.3850)  Acc@5: 100.0000 (98.7714)  time: 0.3523  data: 0.0018  max mem: 2503
Train: Epoch[2/5]  [2690/3750]  eta: 0:06:10  Lr: 0.001875  Loss: -0.7116  Acc@1: 81.2500 (79.3873)  Acc@5: 100.0000 (98.7714)  time: 0.3524  data: 0.0018  max mem: 2503
Train: Epoch[2/5]  [2700/3750]  eta: 0:06:06  Lr: 0.001875  Loss: -0.6723  Acc@1: 81.2500 (79.3850)  Acc@5: 100.0000 (98.7713)  time: 0.3501  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [2710/3750]  eta: 0:06:03  Lr: 0.001875  Loss: -0.6528  Acc@1: 81.2500 (79.3941)  Acc@5: 100.0000 (98.7758)  time: 0.3507  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [2720/3750]  eta: 0:05:59  Lr: 0.001875  Loss: -0.5695  Acc@1: 81.2500 (79.4010)  Acc@5: 100.0000 (98.7688)  time: 0.3501  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [2730/3750]  eta: 0:05:56  Lr: 0.001875  Loss: -0.8640  Acc@1: 81.2500 (79.4100)  Acc@5: 100.0000 (98.7642)  time: 0.3495  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [2740/3750]  eta: 0:05:52  Lr: 0.001875  Loss: -0.4389  Acc@1: 81.2500 (79.4167)  Acc@5: 100.0000 (98.7596)  time: 0.3496  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [2750/3750]  eta: 0:05:49  Lr: 0.001875  Loss: -0.6508  Acc@1: 75.0000 (79.4007)  Acc@5: 100.0000 (98.7573)  time: 0.3499  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [2760/3750]  eta: 0:05:45  Lr: 0.001875  Loss: -0.6760  Acc@1: 75.0000 (79.4006)  Acc@5: 100.0000 (98.7595)  time: 0.3504  data: 0.0006  max mem: 2503
Train: Epoch[2/5]  [2770/3750]  eta: 0:05:42  Lr: 0.001875  Loss: -0.8531  Acc@1: 81.2500 (79.3982)  Acc@5: 100.0000 (98.7572)  time: 0.3499  data: 0.0006  max mem: 2503
Train: Epoch[2/5]  [2780/3750]  eta: 0:05:39  Lr: 0.001875  Loss: -0.9124  Acc@1: 81.2500 (79.4094)  Acc@5: 100.0000 (98.7549)  time: 0.3495  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [2790/3750]  eta: 0:05:35  Lr: 0.001875  Loss: -0.7224  Acc@1: 81.2500 (79.4205)  Acc@5: 100.0000 (98.7594)  time: 0.3496  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [2800/3750]  eta: 0:05:32  Lr: 0.001875  Loss: -1.0812  Acc@1: 87.5000 (79.4582)  Acc@5: 100.0000 (98.7616)  time: 0.3497  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [2810/3750]  eta: 0:05:28  Lr: 0.001875  Loss: -0.8335  Acc@1: 87.5000 (79.4646)  Acc@5: 100.0000 (98.7571)  time: 0.3497  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [2820/3750]  eta: 0:05:25  Lr: 0.001875  Loss: -0.7481  Acc@1: 81.2500 (79.4687)  Acc@5: 100.0000 (98.7549)  time: 0.3500  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [2830/3750]  eta: 0:05:21  Lr: 0.001875  Loss: -0.7613  Acc@1: 81.2500 (79.4728)  Acc@5: 100.0000 (98.7482)  time: 0.3499  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [2840/3750]  eta: 0:05:18  Lr: 0.001875  Loss: -0.7367  Acc@1: 81.2500 (79.4747)  Acc@5: 100.0000 (98.7460)  time: 0.3497  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [2850/3750]  eta: 0:05:14  Lr: 0.001875  Loss: -0.7223  Acc@1: 81.2500 (79.4831)  Acc@5: 100.0000 (98.7439)  time: 0.3502  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [2860/3750]  eta: 0:05:11  Lr: 0.001875  Loss: -0.2094  Acc@1: 75.0000 (79.4740)  Acc@5: 100.0000 (98.7373)  time: 0.3502  data: 0.0007  max mem: 2503
Train: Epoch[2/5]  [2870/3750]  eta: 0:05:07  Lr: 0.001875  Loss: -0.8279  Acc@1: 81.2500 (79.4736)  Acc@5: 93.7500 (98.7265)  time: 0.3506  data: 0.0015  max mem: 2503
Train: Epoch[2/5]  [2880/3750]  eta: 0:05:04  Lr: 0.001875  Loss: -1.0505  Acc@1: 81.2500 (79.4668)  Acc@5: 100.0000 (98.7244)  time: 0.3506  data: 0.0012  max mem: 2503
Train: Epoch[2/5]  [2890/3750]  eta: 0:05:00  Lr: 0.001875  Loss: -0.5812  Acc@1: 81.2500 (79.4816)  Acc@5: 100.0000 (98.7245)  time: 0.3497  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [2900/3750]  eta: 0:04:57  Lr: 0.001875  Loss: -0.4062  Acc@1: 81.2500 (79.4791)  Acc@5: 100.0000 (98.7224)  time: 0.3493  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [2910/3750]  eta: 0:04:53  Lr: 0.001875  Loss: -0.8291  Acc@1: 75.0000 (79.4787)  Acc@5: 100.0000 (98.7247)  time: 0.3501  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [2920/3750]  eta: 0:04:50  Lr: 0.001875  Loss: -1.0398  Acc@1: 81.2500 (79.4826)  Acc@5: 100.0000 (98.7226)  time: 0.3502  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [2930/3750]  eta: 0:04:46  Lr: 0.001875  Loss: -0.9093  Acc@1: 81.2500 (79.4823)  Acc@5: 100.0000 (98.7248)  time: 0.3494  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [2940/3750]  eta: 0:04:43  Lr: 0.001875  Loss: -0.6685  Acc@1: 75.0000 (79.4819)  Acc@5: 100.0000 (98.7228)  time: 0.3494  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [2950/3750]  eta: 0:04:39  Lr: 0.001875  Loss: -0.8168  Acc@1: 75.0000 (79.4731)  Acc@5: 100.0000 (98.7229)  time: 0.3502  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [2960/3750]  eta: 0:04:36  Lr: 0.001875  Loss: -0.5724  Acc@1: 75.0000 (79.4643)  Acc@5: 100.0000 (98.7188)  time: 0.3499  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [2970/3750]  eta: 0:04:32  Lr: 0.001875  Loss: -0.2451  Acc@1: 68.7500 (79.4535)  Acc@5: 100.0000 (98.7147)  time: 0.3484  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [2980/3750]  eta: 0:04:29  Lr: 0.001875  Loss: -0.9961  Acc@1: 81.2500 (79.4658)  Acc@5: 100.0000 (98.7190)  time: 0.3490  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [2990/3750]  eta: 0:04:25  Lr: 0.001875  Loss: -0.8751  Acc@1: 81.2500 (79.4717)  Acc@5: 100.0000 (98.7170)  time: 0.3501  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [3000/3750]  eta: 0:04:22  Lr: 0.001875  Loss: -0.3320  Acc@1: 81.2500 (79.4693)  Acc@5: 100.0000 (98.7171)  time: 0.3502  data: 0.0011  max mem: 2503
Train: Epoch[2/5]  [3010/3750]  eta: 0:04:18  Lr: 0.001875  Loss: -0.7670  Acc@1: 81.2500 (79.4836)  Acc@5: 100.0000 (98.7193)  time: 0.3513  data: 0.0011  max mem: 2503
Train: Epoch[2/5]  [3020/3750]  eta: 0:04:15  Lr: 0.001875  Loss: -0.7085  Acc@1: 81.2500 (79.4667)  Acc@5: 100.0000 (98.7152)  time: 0.3507  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [3030/3750]  eta: 0:04:11  Lr: 0.001875  Loss: -0.6035  Acc@1: 75.0000 (79.4684)  Acc@5: 100.0000 (98.7133)  time: 0.3494  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [3040/3750]  eta: 0:04:08  Lr: 0.001875  Loss: -0.6771  Acc@1: 81.2500 (79.4763)  Acc@5: 100.0000 (98.7114)  time: 0.3499  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [3050/3750]  eta: 0:04:04  Lr: 0.001875  Loss: -0.5217  Acc@1: 81.2500 (79.4842)  Acc@5: 100.0000 (98.7115)  time: 0.3500  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [3060/3750]  eta: 0:04:01  Lr: 0.001875  Loss: -0.8591  Acc@1: 81.2500 (79.4695)  Acc@5: 100.0000 (98.7137)  time: 0.3498  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [3070/3750]  eta: 0:03:57  Lr: 0.001875  Loss: -1.0566  Acc@1: 75.0000 (79.4652)  Acc@5: 100.0000 (98.7138)  time: 0.3503  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [3080/3750]  eta: 0:03:54  Lr: 0.001875  Loss: -0.7451  Acc@1: 75.0000 (79.4486)  Acc@5: 100.0000 (98.7098)  time: 0.3520  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [3090/3750]  eta: 0:03:50  Lr: 0.001875  Loss: -0.9148  Acc@1: 81.2500 (79.4626)  Acc@5: 100.0000 (98.7100)  time: 0.3516  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [3100/3750]  eta: 0:03:47  Lr: 0.001875  Loss: -0.9210  Acc@1: 81.2500 (79.4421)  Acc@5: 100.0000 (98.7081)  time: 0.3499  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [3110/3750]  eta: 0:03:43  Lr: 0.001875  Loss: -0.8776  Acc@1: 75.0000 (79.4419)  Acc@5: 100.0000 (98.7102)  time: 0.3499  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [3120/3750]  eta: 0:03:40  Lr: 0.001875  Loss: -0.8642  Acc@1: 81.2500 (79.4437)  Acc@5: 100.0000 (98.7083)  time: 0.3499  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [3130/3750]  eta: 0:03:36  Lr: 0.001875  Loss: -0.7429  Acc@1: 81.2500 (79.4495)  Acc@5: 100.0000 (98.7105)  time: 0.3498  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [3140/3750]  eta: 0:03:33  Lr: 0.001875  Loss: -0.4491  Acc@1: 81.2500 (79.4572)  Acc@5: 100.0000 (98.7066)  time: 0.3497  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [3150/3750]  eta: 0:03:29  Lr: 0.001875  Loss: -0.8393  Acc@1: 81.2500 (79.4470)  Acc@5: 100.0000 (98.7048)  time: 0.3499  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [3160/3750]  eta: 0:03:26  Lr: 0.001875  Loss: -0.3440  Acc@1: 75.0000 (79.4408)  Acc@5: 100.0000 (98.6990)  time: 0.3504  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [3170/3750]  eta: 0:03:22  Lr: 0.001875  Loss: -0.5197  Acc@1: 75.0000 (79.4367)  Acc@5: 100.0000 (98.6972)  time: 0.3506  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [3180/3750]  eta: 0:03:19  Lr: 0.001875  Loss: -0.9121  Acc@1: 75.0000 (79.4444)  Acc@5: 100.0000 (98.7013)  time: 0.3505  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [3190/3750]  eta: 0:03:15  Lr: 0.001875  Loss: -0.4687  Acc@1: 81.2500 (79.4363)  Acc@5: 100.0000 (98.7034)  time: 0.3511  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [3200/3750]  eta: 0:03:12  Lr: 0.001875  Loss: -0.8468  Acc@1: 75.0000 (79.4361)  Acc@5: 100.0000 (98.7074)  time: 0.3506  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [3210/3750]  eta: 0:03:08  Lr: 0.001875  Loss: -0.5925  Acc@1: 81.2500 (79.4359)  Acc@5: 100.0000 (98.7056)  time: 0.3502  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [3220/3750]  eta: 0:03:05  Lr: 0.001875  Loss: -1.1171  Acc@1: 81.2500 (79.4493)  Acc@5: 100.0000 (98.7058)  time: 0.3509  data: 0.0010  max mem: 2503
Train: Epoch[2/5]  [3230/3750]  eta: 0:03:01  Lr: 0.001875  Loss: -0.6579  Acc@1: 81.2500 (79.4375)  Acc@5: 100.0000 (98.7059)  time: 0.3497  data: 0.0008  max mem: 2503
Train: Epoch[2/5]  [3240/3750]  eta: 0:02:58  Lr: 0.001875  Loss: -0.5572  Acc@1: 81.2500 (79.4392)  Acc@5: 100.0000 (98.7060)  time: 0.3491  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [3250/3750]  eta: 0:02:54  Lr: 0.001875  Loss: -0.8894  Acc@1: 81.2500 (79.4236)  Acc@5: 100.0000 (98.7062)  time: 0.3495  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [3260/3750]  eta: 0:02:51  Lr: 0.001875  Loss: -0.7784  Acc@1: 75.0000 (79.4158)  Acc@5: 100.0000 (98.7044)  time: 0.3504  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [3270/3750]  eta: 0:02:47  Lr: 0.001875  Loss: -0.7862  Acc@1: 81.2500 (79.4291)  Acc@5: 100.0000 (98.7064)  time: 0.3507  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [3280/3750]  eta: 0:02:44  Lr: 0.001875  Loss: -0.5941  Acc@1: 75.0000 (79.4213)  Acc@5: 100.0000 (98.7085)  time: 0.3504  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [3290/3750]  eta: 0:02:40  Lr: 0.001875  Loss: -0.9854  Acc@1: 75.0000 (79.4268)  Acc@5: 100.0000 (98.7086)  time: 0.3502  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [3300/3750]  eta: 0:02:37  Lr: 0.001875  Loss: -0.4027  Acc@1: 81.2500 (79.4229)  Acc@5: 100.0000 (98.7087)  time: 0.3503  data: 0.0008  max mem: 2503
Train: Epoch[2/5]  [3310/3750]  eta: 0:02:33  Lr: 0.001875  Loss: -0.7590  Acc@1: 81.2500 (79.4133)  Acc@5: 100.0000 (98.7107)  time: 0.3505  data: 0.0008  max mem: 2503
Train: Epoch[2/5]  [3320/3750]  eta: 0:02:30  Lr: 0.001875  Loss: -0.9404  Acc@1: 81.2500 (79.4188)  Acc@5: 100.0000 (98.7071)  time: 0.3504  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [3330/3750]  eta: 0:02:26  Lr: 0.001875  Loss: -1.0109  Acc@1: 81.2500 (79.4187)  Acc@5: 100.0000 (98.7072)  time: 0.3520  data: 0.0015  max mem: 2503
Train: Epoch[2/5]  [3340/3750]  eta: 0:02:23  Lr: 0.001875  Loss: -0.9746  Acc@1: 81.2500 (79.4317)  Acc@5: 100.0000 (98.7055)  time: 0.3516  data: 0.0015  max mem: 2503
Train: Epoch[2/5]  [3350/3750]  eta: 0:02:19  Lr: 0.001875  Loss: -0.9022  Acc@1: 87.5000 (79.4520)  Acc@5: 100.0000 (98.7075)  time: 0.3512  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [3360/3750]  eta: 0:02:16  Lr: 0.001875  Loss: -0.4047  Acc@1: 81.2500 (79.4444)  Acc@5: 100.0000 (98.7057)  time: 0.3511  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [3370/3750]  eta: 0:02:12  Lr: 0.001875  Loss: -0.8614  Acc@1: 81.2500 (79.4516)  Acc@5: 100.0000 (98.7040)  time: 0.3500  data: 0.0011  max mem: 2503
Train: Epoch[2/5]  [3380/3750]  eta: 0:02:09  Lr: 0.001875  Loss: -0.2922  Acc@1: 81.2500 (79.4458)  Acc@5: 100.0000 (98.7042)  time: 0.3500  data: 0.0011  max mem: 2503
Train: Epoch[2/5]  [3390/3750]  eta: 0:02:05  Lr: 0.001875  Loss: -0.8377  Acc@1: 75.0000 (79.4345)  Acc@5: 100.0000 (98.7043)  time: 0.3498  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [3400/3750]  eta: 0:02:02  Lr: 0.001875  Loss: -0.7229  Acc@1: 75.0000 (79.4307)  Acc@5: 100.0000 (98.7007)  time: 0.3500  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [3410/3750]  eta: 0:01:58  Lr: 0.001875  Loss: -0.7127  Acc@1: 75.0000 (79.4250)  Acc@5: 100.0000 (98.7027)  time: 0.3500  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [3420/3750]  eta: 0:01:55  Lr: 0.001875  Loss: -0.8372  Acc@1: 75.0000 (79.4249)  Acc@5: 100.0000 (98.7010)  time: 0.3499  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [3430/3750]  eta: 0:01:51  Lr: 0.001875  Loss: -0.9507  Acc@1: 81.2500 (79.4411)  Acc@5: 100.0000 (98.7048)  time: 0.3499  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [3440/3750]  eta: 0:01:48  Lr: 0.001875  Loss: -0.6654  Acc@1: 81.2500 (79.4264)  Acc@5: 100.0000 (98.7013)  time: 0.3500  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [3450/3750]  eta: 0:01:44  Lr: 0.001875  Loss: -0.7863  Acc@1: 75.0000 (79.4317)  Acc@5: 100.0000 (98.7015)  time: 0.3507  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [3460/3750]  eta: 0:01:41  Lr: 0.001875  Loss: -0.3940  Acc@1: 75.0000 (79.4279)  Acc@5: 100.0000 (98.7034)  time: 0.3508  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [3470/3750]  eta: 0:01:37  Lr: 0.001875  Loss: -0.5222  Acc@1: 75.0000 (79.4350)  Acc@5: 100.0000 (98.7053)  time: 0.3497  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [3480/3750]  eta: 0:01:34  Lr: 0.001875  Loss: -0.6771  Acc@1: 87.5000 (79.4402)  Acc@5: 100.0000 (98.7037)  time: 0.3491  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [3490/3750]  eta: 0:01:30  Lr: 0.001875  Loss: -1.0003  Acc@1: 81.2500 (79.4310)  Acc@5: 100.0000 (98.7020)  time: 0.3504  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [3500/3750]  eta: 0:01:27  Lr: 0.001875  Loss: -0.5469  Acc@1: 81.2500 (79.4327)  Acc@5: 100.0000 (98.7004)  time: 0.3505  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [3510/3750]  eta: 0:01:23  Lr: 0.001875  Loss: -0.9370  Acc@1: 75.0000 (79.4289)  Acc@5: 100.0000 (98.6970)  time: 0.3491  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [3520/3750]  eta: 0:01:20  Lr: 0.001875  Loss: -0.7850  Acc@1: 75.0000 (79.4235)  Acc@5: 100.0000 (98.6936)  time: 0.3487  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [3530/3750]  eta: 0:01:16  Lr: 0.001875  Loss: -0.8001  Acc@1: 81.2500 (79.4304)  Acc@5: 100.0000 (98.6955)  time: 0.3482  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [3540/3750]  eta: 0:01:13  Lr: 0.001875  Loss: -0.5589  Acc@1: 75.0000 (79.4179)  Acc@5: 100.0000 (98.6992)  time: 0.3481  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [3550/3750]  eta: 0:01:09  Lr: 0.001875  Loss: -0.6815  Acc@1: 75.0000 (79.4054)  Acc@5: 100.0000 (98.7011)  time: 0.3481  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [3560/3750]  eta: 0:01:06  Lr: 0.001875  Loss: -0.7967  Acc@1: 81.2500 (79.4212)  Acc@5: 100.0000 (98.6995)  time: 0.3476  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [3570/3750]  eta: 0:01:02  Lr: 0.001875  Loss: -0.6828  Acc@1: 81.2500 (79.4280)  Acc@5: 100.0000 (98.7013)  time: 0.3481  data: 0.0005  max mem: 2503
Train: Epoch[2/5]  [3580/3750]  eta: 0:00:59  Lr: 0.001875  Loss: -1.0843  Acc@1: 81.2500 (79.4384)  Acc@5: 100.0000 (98.7015)  time: 0.3480  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [3590/3750]  eta: 0:00:55  Lr: 0.001875  Loss: -0.8288  Acc@1: 81.2500 (79.4382)  Acc@5: 100.0000 (98.7034)  time: 0.3486  data: 0.0018  max mem: 2503
Train: Epoch[2/5]  [3600/3750]  eta: 0:00:52  Lr: 0.001875  Loss: -0.6555  Acc@1: 75.0000 (79.4189)  Acc@5: 100.0000 (98.7035)  time: 0.3483  data: 0.0017  max mem: 2503
Train: Epoch[2/5]  [3610/3750]  eta: 0:00:48  Lr: 0.001875  Loss: -0.9826  Acc@1: 75.0000 (79.4326)  Acc@5: 100.0000 (98.7002)  time: 0.3477  data: 0.0010  max mem: 2503
Train: Epoch[2/5]  [3620/3750]  eta: 0:00:45  Lr: 0.001875  Loss: -1.0180  Acc@1: 87.5000 (79.4446)  Acc@5: 100.0000 (98.7003)  time: 0.3478  data: 0.0011  max mem: 2503
Train: Epoch[2/5]  [3630/3750]  eta: 0:00:41  Lr: 0.001875  Loss: -0.3846  Acc@1: 81.2500 (79.4495)  Acc@5: 100.0000 (98.6970)  time: 0.3479  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [3640/3750]  eta: 0:00:38  Lr: 0.001875  Loss: -0.6009  Acc@1: 81.2500 (79.4407)  Acc@5: 100.0000 (98.6988)  time: 0.3483  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [3650/3750]  eta: 0:00:34  Lr: 0.001875  Loss: -0.9431  Acc@1: 81.2500 (79.4560)  Acc@5: 100.0000 (98.7007)  time: 0.3468  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [3660/3750]  eta: 0:00:31  Lr: 0.001875  Loss: -0.7858  Acc@1: 81.2500 (79.4643)  Acc@5: 100.0000 (98.7042)  time: 0.3469  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [3670/3750]  eta: 0:00:27  Lr: 0.001875  Loss: -0.9326  Acc@1: 81.2500 (79.4709)  Acc@5: 100.0000 (98.7061)  time: 0.3478  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [3680/3750]  eta: 0:00:24  Lr: 0.001875  Loss: -0.7491  Acc@1: 81.2500 (79.4774)  Acc@5: 100.0000 (98.7062)  time: 0.3482  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [3690/3750]  eta: 0:00:20  Lr: 0.001875  Loss: -0.9615  Acc@1: 75.0000 (79.4669)  Acc@5: 100.0000 (98.7063)  time: 0.3484  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [3700/3750]  eta: 0:00:17  Lr: 0.001875  Loss: -0.4445  Acc@1: 75.0000 (79.4650)  Acc@5: 100.0000 (98.7064)  time: 0.3480  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [3710/3750]  eta: 0:00:13  Lr: 0.001875  Loss: -1.0155  Acc@1: 81.2500 (79.4749)  Acc@5: 100.0000 (98.7099)  time: 0.3490  data: 0.0003  max mem: 2503
Train: Epoch[2/5]  [3720/3750]  eta: 0:00:10  Lr: 0.001875  Loss: -0.8105  Acc@1: 87.5000 (79.4746)  Acc@5: 100.0000 (98.7117)  time: 0.3500  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [3730/3750]  eta: 0:00:06  Lr: 0.001875  Loss: -0.8269  Acc@1: 81.2500 (79.4760)  Acc@5: 100.0000 (98.7101)  time: 0.3503  data: 0.0004  max mem: 2503
Train: Epoch[2/5]  [3740/3750]  eta: 0:00:03  Lr: 0.001875  Loss: -0.7049  Acc@1: 75.0000 (79.4691)  Acc@5: 100.0000 (98.7069)  time: 0.3498  data: 0.0006  max mem: 2503
Train: Epoch[2/5]  [3749/3750]  eta: 0:00:00  Lr: 0.001875  Loss: -0.6178  Acc@1: 81.2500 (79.4717)  Acc@5: 100.0000 (98.7033)  time: 0.3497  data: 0.0010  max mem: 2503
Train: Epoch[2/5] Total time: 0:21:51 (0.3497 s / it)
Averaged stats: Lr: 0.001875  Loss: -0.6178  Acc@1: 81.2500 (79.4717)  Acc@5: 100.0000 (98.7033)
Train: Epoch[3/5]  [   0/3750]  eta: 0:41:33  Lr: 0.001875  Loss: -0.5719  Acc@1: 62.5000 (62.5000)  Acc@5: 93.7500 (93.7500)  time: 0.6649  data: 0.3141  max mem: 2503
Train: Epoch[3/5]  [  10/3750]  eta: 0:23:39  Lr: 0.001875  Loss: -0.3654  Acc@1: 81.2500 (79.5455)  Acc@5: 100.0000 (98.2955)  time: 0.3797  data: 0.0289  max mem: 2503
Train: Epoch[3/5]  [  20/3750]  eta: 0:22:40  Lr: 0.001875  Loss: -1.0446  Acc@1: 81.2500 (82.4405)  Acc@5: 100.0000 (98.8095)  time: 0.3497  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [  30/3750]  eta: 0:22:19  Lr: 0.001875  Loss: -1.0050  Acc@1: 87.5000 (82.0565)  Acc@5: 100.0000 (98.7903)  time: 0.3493  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [  40/3750]  eta: 0:22:06  Lr: 0.001875  Loss: -0.7035  Acc@1: 75.0000 (81.0976)  Acc@5: 100.0000 (98.6280)  time: 0.3501  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [  50/3750]  eta: 0:21:56  Lr: 0.001875  Loss: -0.2364  Acc@1: 75.0000 (80.0245)  Acc@5: 100.0000 (98.7745)  time: 0.3491  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [  60/3750]  eta: 0:21:48  Lr: 0.001875  Loss: -0.8794  Acc@1: 81.2500 (81.1475)  Acc@5: 100.0000 (98.8730)  time: 0.3489  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [  70/3750]  eta: 0:21:42  Lr: 0.001875  Loss: -0.6138  Acc@1: 81.2500 (80.2817)  Acc@5: 100.0000 (98.9437)  time: 0.3494  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [  80/3750]  eta: 0:21:37  Lr: 0.001875  Loss: -0.8867  Acc@1: 81.2500 (80.7099)  Acc@5: 100.0000 (98.9198)  time: 0.3496  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [  90/3750]  eta: 0:21:31  Lr: 0.001875  Loss: -0.6709  Acc@1: 81.2500 (80.4258)  Acc@5: 100.0000 (98.8324)  time: 0.3489  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [ 100/3750]  eta: 0:21:27  Lr: 0.001875  Loss: -0.3947  Acc@1: 75.0000 (80.1980)  Acc@5: 100.0000 (98.8243)  time: 0.3496  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [ 110/3750]  eta: 0:21:22  Lr: 0.001875  Loss: -0.3892  Acc@1: 81.2500 (79.9550)  Acc@5: 100.0000 (98.7613)  time: 0.3501  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [ 120/3750]  eta: 0:21:17  Lr: 0.001875  Loss: -0.9667  Acc@1: 81.2500 (79.8554)  Acc@5: 100.0000 (98.7087)  time: 0.3486  data: 0.0007  max mem: 2503
Train: Epoch[3/5]  [ 130/3750]  eta: 0:21:13  Lr: 0.001875  Loss: -0.5853  Acc@1: 81.2500 (79.7233)  Acc@5: 100.0000 (98.6641)  time: 0.3481  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [ 140/3750]  eta: 0:21:08  Lr: 0.001875  Loss: -0.0903  Acc@1: 68.7500 (79.3440)  Acc@5: 100.0000 (98.6259)  time: 0.3479  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [ 150/3750]  eta: 0:21:04  Lr: 0.001875  Loss: -0.8836  Acc@1: 75.0000 (79.3046)  Acc@5: 100.0000 (98.5513)  time: 0.3475  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [ 160/3750]  eta: 0:20:59  Lr: 0.001875  Loss: -0.9274  Acc@1: 81.2500 (79.5031)  Acc@5: 100.0000 (98.5637)  time: 0.3476  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [ 170/3750]  eta: 0:20:55  Lr: 0.001875  Loss: -0.5642  Acc@1: 81.2500 (79.4956)  Acc@5: 100.0000 (98.6111)  time: 0.3475  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [ 180/3750]  eta: 0:20:51  Lr: 0.001875  Loss: -0.8232  Acc@1: 81.2500 (79.3508)  Acc@5: 100.0000 (98.6533)  time: 0.3485  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [ 190/3750]  eta: 0:20:48  Lr: 0.001875  Loss: -0.7315  Acc@1: 75.0000 (79.3194)  Acc@5: 100.0000 (98.6257)  time: 0.3493  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [ 200/3750]  eta: 0:20:43  Lr: 0.001875  Loss: -0.6899  Acc@1: 75.0000 (78.8557)  Acc@5: 100.0000 (98.6629)  time: 0.3479  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [ 210/3750]  eta: 0:20:40  Lr: 0.001875  Loss: -0.2730  Acc@1: 75.0000 (78.9396)  Acc@5: 100.0000 (98.6374)  time: 0.3476  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [ 220/3750]  eta: 0:20:36  Lr: 0.001875  Loss: -0.8815  Acc@1: 81.2500 (78.8179)  Acc@5: 100.0000 (98.6708)  time: 0.3477  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [ 230/3750]  eta: 0:20:32  Lr: 0.001875  Loss: -0.9791  Acc@1: 81.2500 (79.1667)  Acc@5: 100.0000 (98.6742)  time: 0.3481  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [ 240/3750]  eta: 0:20:28  Lr: 0.001875  Loss: -0.8035  Acc@1: 87.5000 (79.1234)  Acc@5: 100.0000 (98.7033)  time: 0.3480  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [ 250/3750]  eta: 0:20:24  Lr: 0.001875  Loss: -0.4351  Acc@1: 75.0000 (79.1086)  Acc@5: 100.0000 (98.6803)  time: 0.3479  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [ 260/3750]  eta: 0:20:21  Lr: 0.001875  Loss: -1.0952  Acc@1: 81.2500 (79.3103)  Acc@5: 100.0000 (98.6830)  time: 0.3486  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [ 270/3750]  eta: 0:20:17  Lr: 0.001875  Loss: -0.7347  Acc@1: 81.2500 (79.2897)  Acc@5: 100.0000 (98.6854)  time: 0.3483  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [ 280/3750]  eta: 0:20:13  Lr: 0.001875  Loss: -1.0762  Acc@1: 81.2500 (79.3594)  Acc@5: 100.0000 (98.6877)  time: 0.3479  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [ 290/3750]  eta: 0:20:10  Lr: 0.001875  Loss: -0.7752  Acc@1: 81.2500 (79.3385)  Acc@5: 100.0000 (98.6469)  time: 0.3487  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [ 300/3750]  eta: 0:20:06  Lr: 0.001875  Loss: -0.9518  Acc@1: 81.2500 (79.5058)  Acc@5: 100.0000 (98.6711)  time: 0.3493  data: 0.0007  max mem: 2503
Train: Epoch[3/5]  [ 310/3750]  eta: 0:20:03  Lr: 0.001875  Loss: -0.7647  Acc@1: 81.2500 (79.5820)  Acc@5: 100.0000 (98.6937)  time: 0.3496  data: 0.0006  max mem: 2503
Train: Epoch[3/5]  [ 320/3750]  eta: 0:19:59  Lr: 0.001875  Loss: -0.4443  Acc@1: 81.2500 (79.5366)  Acc@5: 100.0000 (98.5981)  time: 0.3494  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [ 330/3750]  eta: 0:19:55  Lr: 0.001875  Loss: -0.8989  Acc@1: 75.0000 (79.5695)  Acc@5: 100.0000 (98.5650)  time: 0.3495  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [ 340/3750]  eta: 0:19:52  Lr: 0.001875  Loss: -0.9637  Acc@1: 81.2500 (79.5271)  Acc@5: 100.0000 (98.5337)  time: 0.3495  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [ 350/3750]  eta: 0:19:48  Lr: 0.001875  Loss: -0.9419  Acc@1: 81.2500 (79.6474)  Acc@5: 100.0000 (98.5755)  time: 0.3487  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [ 360/3750]  eta: 0:19:45  Lr: 0.001875  Loss: -0.4820  Acc@1: 81.2500 (79.4668)  Acc@5: 100.0000 (98.5976)  time: 0.3489  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [ 370/3750]  eta: 0:19:41  Lr: 0.001875  Loss: -0.4639  Acc@1: 75.0000 (79.3632)  Acc@5: 100.0000 (98.6186)  time: 0.3489  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [ 380/3750]  eta: 0:19:38  Lr: 0.001875  Loss: -0.8227  Acc@1: 81.2500 (79.4455)  Acc@5: 100.0000 (98.6220)  time: 0.3489  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [ 390/3750]  eta: 0:19:34  Lr: 0.001875  Loss: -0.9056  Acc@1: 81.2500 (79.4757)  Acc@5: 100.0000 (98.6413)  time: 0.3487  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [ 400/3750]  eta: 0:19:31  Lr: 0.001875  Loss: -0.6196  Acc@1: 81.2500 (79.4888)  Acc@5: 100.0000 (98.6284)  time: 0.3488  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [ 410/3750]  eta: 0:19:27  Lr: 0.001875  Loss: -0.7686  Acc@1: 81.2500 (79.5620)  Acc@5: 100.0000 (98.6466)  time: 0.3493  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [ 420/3750]  eta: 0:19:24  Lr: 0.001875  Loss: -0.8472  Acc@1: 81.2500 (79.4685)  Acc@5: 100.0000 (98.6194)  time: 0.3495  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [ 430/3750]  eta: 0:19:20  Lr: 0.001875  Loss: -0.6125  Acc@1: 75.0000 (79.3794)  Acc@5: 100.0000 (98.6224)  time: 0.3501  data: 0.0011  max mem: 2503
Train: Epoch[3/5]  [ 440/3750]  eta: 0:19:17  Lr: 0.001875  Loss: -0.7855  Acc@1: 75.0000 (79.3084)  Acc@5: 100.0000 (98.6536)  time: 0.3504  data: 0.0011  max mem: 2503
Train: Epoch[3/5]  [ 450/3750]  eta: 0:19:13  Lr: 0.001875  Loss: -0.1274  Acc@1: 81.2500 (79.4207)  Acc@5: 100.0000 (98.6419)  time: 0.3499  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [ 460/3750]  eta: 0:19:10  Lr: 0.001875  Loss: -0.5365  Acc@1: 81.2500 (79.4197)  Acc@5: 100.0000 (98.6443)  time: 0.3504  data: 0.0012  max mem: 2503
Train: Epoch[3/5]  [ 470/3750]  eta: 0:19:06  Lr: 0.001875  Loss: -1.0235  Acc@1: 81.2500 (79.4586)  Acc@5: 100.0000 (98.6598)  time: 0.3510  data: 0.0012  max mem: 2503
Train: Epoch[3/5]  [ 480/3750]  eta: 0:19:03  Lr: 0.001875  Loss: -0.8455  Acc@1: 87.5000 (79.6388)  Acc@5: 100.0000 (98.6876)  time: 0.3504  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [ 490/3750]  eta: 0:18:59  Lr: 0.001875  Loss: -0.7130  Acc@1: 87.5000 (79.7480)  Acc@5: 100.0000 (98.6889)  time: 0.3500  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [ 500/3750]  eta: 0:18:56  Lr: 0.001875  Loss: -0.9268  Acc@1: 87.5000 (79.7904)  Acc@5: 100.0000 (98.6901)  time: 0.3494  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [ 510/3750]  eta: 0:18:52  Lr: 0.001875  Loss: -0.8078  Acc@1: 81.2500 (79.7945)  Acc@5: 100.0000 (98.6913)  time: 0.3495  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [ 520/3750]  eta: 0:18:49  Lr: 0.001875  Loss: -0.8538  Acc@1: 81.2500 (79.8345)  Acc@5: 100.0000 (98.7164)  time: 0.3497  data: 0.0006  max mem: 2503
Train: Epoch[3/5]  [ 530/3750]  eta: 0:18:45  Lr: 0.001875  Loss: -0.5277  Acc@1: 75.0000 (79.7434)  Acc@5: 100.0000 (98.7170)  time: 0.3494  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [ 540/3750]  eta: 0:18:42  Lr: 0.001875  Loss: -0.8542  Acc@1: 81.2500 (79.8175)  Acc@5: 100.0000 (98.7292)  time: 0.3509  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [ 550/3750]  eta: 0:18:39  Lr: 0.001875  Loss: -0.6625  Acc@1: 81.2500 (79.7527)  Acc@5: 100.0000 (98.7296)  time: 0.3510  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [ 560/3750]  eta: 0:18:35  Lr: 0.001875  Loss: -0.2072  Acc@1: 81.2500 (79.7460)  Acc@5: 100.0000 (98.7188)  time: 0.3501  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [ 570/3750]  eta: 0:18:32  Lr: 0.001875  Loss: -0.6719  Acc@1: 81.2500 (79.7176)  Acc@5: 100.0000 (98.7303)  time: 0.3504  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [ 580/3750]  eta: 0:18:28  Lr: 0.001875  Loss: -0.7410  Acc@1: 81.2500 (79.6687)  Acc@5: 100.0000 (98.7414)  time: 0.3511  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [ 590/3750]  eta: 0:18:25  Lr: 0.001875  Loss: -1.0778  Acc@1: 81.2500 (79.7906)  Acc@5: 100.0000 (98.7521)  time: 0.3508  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [ 600/3750]  eta: 0:18:21  Lr: 0.001875  Loss: -1.0593  Acc@1: 81.2500 (79.7837)  Acc@5: 100.0000 (98.7521)  time: 0.3501  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [ 610/3750]  eta: 0:18:18  Lr: 0.001875  Loss: -0.3454  Acc@1: 81.2500 (79.7770)  Acc@5: 100.0000 (98.7316)  time: 0.3503  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [ 620/3750]  eta: 0:18:14  Lr: 0.001875  Loss: -0.9988  Acc@1: 75.0000 (79.7303)  Acc@5: 100.0000 (98.7118)  time: 0.3505  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [ 630/3750]  eta: 0:18:11  Lr: 0.001875  Loss: -0.5345  Acc@1: 81.2500 (79.7147)  Acc@5: 100.0000 (98.7025)  time: 0.3502  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [ 640/3750]  eta: 0:18:07  Lr: 0.001875  Loss: -0.5820  Acc@1: 87.5000 (79.7387)  Acc@5: 100.0000 (98.6934)  time: 0.3499  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [ 650/3750]  eta: 0:18:04  Lr: 0.001875  Loss: -0.9093  Acc@1: 81.2500 (79.7331)  Acc@5: 100.0000 (98.6943)  time: 0.3498  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [ 660/3750]  eta: 0:18:00  Lr: 0.001875  Loss: -1.0572  Acc@1: 81.2500 (79.7750)  Acc@5: 100.0000 (98.7141)  time: 0.3490  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [ 670/3750]  eta: 0:17:57  Lr: 0.001875  Loss: -1.1566  Acc@1: 81.2500 (79.7597)  Acc@5: 100.0000 (98.6960)  time: 0.3485  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [ 680/3750]  eta: 0:17:53  Lr: 0.001875  Loss: -0.8543  Acc@1: 75.0000 (79.7173)  Acc@5: 100.0000 (98.7059)  time: 0.3491  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [ 690/3750]  eta: 0:17:50  Lr: 0.001875  Loss: -0.8151  Acc@1: 81.2500 (79.7214)  Acc@5: 100.0000 (98.6975)  time: 0.3500  data: 0.0007  max mem: 2503
Train: Epoch[3/5]  [ 700/3750]  eta: 0:17:46  Lr: 0.001875  Loss: -1.1334  Acc@1: 81.2500 (79.7878)  Acc@5: 100.0000 (98.6894)  time: 0.3495  data: 0.0007  max mem: 2503
Train: Epoch[3/5]  [ 710/3750]  eta: 0:17:43  Lr: 0.001875  Loss: -0.7309  Acc@1: 81.2500 (79.7908)  Acc@5: 100.0000 (98.6990)  time: 0.3492  data: 0.0011  max mem: 2503
Train: Epoch[3/5]  [ 720/3750]  eta: 0:17:39  Lr: 0.001875  Loss: -1.0279  Acc@1: 87.5000 (79.8977)  Acc@5: 100.0000 (98.7084)  time: 0.3508  data: 0.0019  max mem: 2503
Train: Epoch[3/5]  [ 730/3750]  eta: 0:17:36  Lr: 0.001875  Loss: -0.6202  Acc@1: 81.2500 (79.8820)  Acc@5: 100.0000 (98.7004)  time: 0.3498  data: 0.0011  max mem: 2503
Train: Epoch[3/5]  [ 740/3750]  eta: 0:17:32  Lr: 0.001875  Loss: -0.6239  Acc@1: 81.2500 (79.9089)  Acc@5: 100.0000 (98.7095)  time: 0.3480  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [ 750/3750]  eta: 0:17:29  Lr: 0.001875  Loss: -0.8869  Acc@1: 81.2500 (79.9268)  Acc@5: 100.0000 (98.7101)  time: 0.3484  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [ 760/3750]  eta: 0:17:25  Lr: 0.001875  Loss: -0.9256  Acc@1: 81.2500 (80.0099)  Acc@5: 100.0000 (98.7024)  time: 0.3491  data: 0.0008  max mem: 2503
Train: Epoch[3/5]  [ 770/3750]  eta: 0:17:22  Lr: 0.001875  Loss: -0.7846  Acc@1: 87.5000 (80.0503)  Acc@5: 100.0000 (98.7192)  time: 0.3486  data: 0.0007  max mem: 2503
Train: Epoch[3/5]  [ 780/3750]  eta: 0:17:18  Lr: 0.001875  Loss: -0.8982  Acc@1: 81.2500 (80.0496)  Acc@5: 100.0000 (98.7116)  time: 0.3476  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [ 790/3750]  eta: 0:17:14  Lr: 0.001875  Loss: -1.0837  Acc@1: 81.2500 (80.0095)  Acc@5: 100.0000 (98.7200)  time: 0.3481  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [ 800/3750]  eta: 0:17:11  Lr: 0.001875  Loss: -0.9133  Acc@1: 81.2500 (80.0094)  Acc@5: 100.0000 (98.7282)  time: 0.3486  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [ 810/3750]  eta: 0:17:07  Lr: 0.001875  Loss: -0.9765  Acc@1: 81.2500 (79.9861)  Acc@5: 100.0000 (98.7284)  time: 0.3485  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [ 820/3750]  eta: 0:17:04  Lr: 0.001875  Loss: -0.9707  Acc@1: 81.2500 (80.0091)  Acc@5: 100.0000 (98.7363)  time: 0.3481  data: 0.0006  max mem: 2503
Train: Epoch[3/5]  [ 830/3750]  eta: 0:17:00  Lr: 0.001875  Loss: -0.8092  Acc@1: 81.2500 (80.0090)  Acc@5: 100.0000 (98.7515)  time: 0.3476  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [ 840/3750]  eta: 0:16:57  Lr: 0.001875  Loss: -0.7720  Acc@1: 81.2500 (80.0163)  Acc@5: 100.0000 (98.7441)  time: 0.3482  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [ 850/3750]  eta: 0:16:53  Lr: 0.001875  Loss: -0.8339  Acc@1: 81.2500 (80.0088)  Acc@5: 100.0000 (98.7074)  time: 0.3486  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [ 860/3750]  eta: 0:16:50  Lr: 0.001875  Loss: -0.8086  Acc@1: 81.2500 (80.0232)  Acc@5: 100.0000 (98.7152)  time: 0.3472  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [ 870/3750]  eta: 0:16:46  Lr: 0.001875  Loss: -0.9856  Acc@1: 81.2500 (80.0014)  Acc@5: 100.0000 (98.7227)  time: 0.3468  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [ 880/3750]  eta: 0:16:42  Lr: 0.001875  Loss: -0.9020  Acc@1: 87.5000 (80.0795)  Acc@5: 100.0000 (98.7230)  time: 0.3471  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [ 890/3750]  eta: 0:16:39  Lr: 0.001875  Loss: -0.8882  Acc@1: 87.5000 (80.0926)  Acc@5: 100.0000 (98.7304)  time: 0.3472  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [ 900/3750]  eta: 0:16:35  Lr: 0.001875  Loss: -0.5100  Acc@1: 81.2500 (80.1609)  Acc@5: 100.0000 (98.7445)  time: 0.3477  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [ 910/3750]  eta: 0:16:32  Lr: 0.001875  Loss: -0.5782  Acc@1: 81.2500 (80.1317)  Acc@5: 100.0000 (98.7514)  time: 0.3484  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [ 920/3750]  eta: 0:16:28  Lr: 0.001875  Loss: -0.8180  Acc@1: 81.2500 (80.1031)  Acc@5: 100.0000 (98.7514)  time: 0.3484  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [ 930/3750]  eta: 0:16:25  Lr: 0.001875  Loss: -0.6746  Acc@1: 81.2500 (80.1423)  Acc@5: 100.0000 (98.7446)  time: 0.3478  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [ 940/3750]  eta: 0:16:21  Lr: 0.001875  Loss: -0.4581  Acc@1: 81.2500 (80.1607)  Acc@5: 100.0000 (98.7580)  time: 0.3478  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [ 950/3750]  eta: 0:16:18  Lr: 0.001875  Loss: -0.8386  Acc@1: 81.2500 (80.2182)  Acc@5: 100.0000 (98.7645)  time: 0.3478  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [ 960/3750]  eta: 0:16:14  Lr: 0.001875  Loss: -0.9066  Acc@1: 81.2500 (80.2484)  Acc@5: 100.0000 (98.7708)  time: 0.3487  data: 0.0010  max mem: 2503
Train: Epoch[3/5]  [ 970/3750]  eta: 0:16:11  Lr: 0.001875  Loss: -0.3595  Acc@1: 81.2500 (80.2394)  Acc@5: 100.0000 (98.7706)  time: 0.3492  data: 0.0010  max mem: 2503
Train: Epoch[3/5]  [ 980/3750]  eta: 0:16:07  Lr: 0.001875  Loss: -0.8760  Acc@1: 75.0000 (80.2115)  Acc@5: 100.0000 (98.7640)  time: 0.3480  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [ 990/3750]  eta: 0:16:04  Lr: 0.001875  Loss: -0.9524  Acc@1: 81.2500 (80.2094)  Acc@5: 100.0000 (98.7702)  time: 0.3476  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [1000/3750]  eta: 0:16:00  Lr: 0.001875  Loss: -0.6763  Acc@1: 81.2500 (80.2010)  Acc@5: 100.0000 (98.7762)  time: 0.3483  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [1010/3750]  eta: 0:15:57  Lr: 0.001875  Loss: -1.1004  Acc@1: 75.0000 (80.2114)  Acc@5: 100.0000 (98.7698)  time: 0.3489  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [1020/3750]  eta: 0:15:53  Lr: 0.001875  Loss: -0.9610  Acc@1: 81.2500 (80.2583)  Acc@5: 100.0000 (98.7696)  time: 0.3490  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [1030/3750]  eta: 0:15:50  Lr: 0.001875  Loss: -0.5773  Acc@1: 81.2500 (80.2740)  Acc@5: 100.0000 (98.7755)  time: 0.3489  data: 0.0006  max mem: 2503
Train: Epoch[3/5]  [1040/3750]  eta: 0:15:46  Lr: 0.001875  Loss: -0.6227  Acc@1: 81.2500 (80.2714)  Acc@5: 100.0000 (98.7872)  time: 0.3493  data: 0.0006  max mem: 2503
Train: Epoch[3/5]  [1050/3750]  eta: 0:15:43  Lr: 0.001875  Loss: -0.2518  Acc@1: 81.2500 (80.1974)  Acc@5: 100.0000 (98.7809)  time: 0.3502  data: 0.0010  max mem: 2503
Train: Epoch[3/5]  [1060/3750]  eta: 0:15:39  Lr: 0.001875  Loss: -0.4985  Acc@1: 75.0000 (80.2132)  Acc@5: 100.0000 (98.7865)  time: 0.3503  data: 0.0011  max mem: 2503
Train: Epoch[3/5]  [1070/3750]  eta: 0:15:36  Lr: 0.001875  Loss: -0.6246  Acc@1: 81.2500 (80.2346)  Acc@5: 100.0000 (98.7745)  time: 0.3498  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [1080/3750]  eta: 0:15:32  Lr: 0.001875  Loss: -0.8583  Acc@1: 81.2500 (80.2613)  Acc@5: 100.0000 (98.7801)  time: 0.3494  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [1090/3750]  eta: 0:15:29  Lr: 0.001875  Loss: -0.9243  Acc@1: 87.5000 (80.2761)  Acc@5: 100.0000 (98.7912)  time: 0.3485  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [1100/3750]  eta: 0:15:25  Lr: 0.001875  Loss: -0.6822  Acc@1: 81.2500 (80.2906)  Acc@5: 100.0000 (98.8022)  time: 0.3489  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [1110/3750]  eta: 0:15:22  Lr: 0.001875  Loss: -0.7621  Acc@1: 81.2500 (80.3105)  Acc@5: 100.0000 (98.7905)  time: 0.3494  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [1120/3750]  eta: 0:15:18  Lr: 0.001875  Loss: -0.6010  Acc@1: 81.2500 (80.2910)  Acc@5: 100.0000 (98.7790)  time: 0.3488  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [1130/3750]  eta: 0:15:15  Lr: 0.001875  Loss: -0.5515  Acc@1: 75.0000 (80.2940)  Acc@5: 100.0000 (98.7787)  time: 0.3494  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [1140/3750]  eta: 0:15:11  Lr: 0.001875  Loss: -0.7367  Acc@1: 81.2500 (80.3243)  Acc@5: 100.0000 (98.7840)  time: 0.3506  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [1150/3750]  eta: 0:15:08  Lr: 0.001875  Loss: -0.7153  Acc@1: 81.2500 (80.3052)  Acc@5: 100.0000 (98.7837)  time: 0.3505  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [1160/3750]  eta: 0:15:04  Lr: 0.001875  Loss: -0.9352  Acc@1: 75.0000 (80.2864)  Acc@5: 100.0000 (98.7618)  time: 0.3498  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [1170/3750]  eta: 0:15:01  Lr: 0.001875  Loss: -0.9395  Acc@1: 75.0000 (80.2466)  Acc@5: 100.0000 (98.7671)  time: 0.3498  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [1180/3750]  eta: 0:14:57  Lr: 0.001875  Loss: -0.8361  Acc@1: 75.0000 (80.2445)  Acc@5: 100.0000 (98.7722)  time: 0.3508  data: 0.0012  max mem: 2503
Train: Epoch[3/5]  [1190/3750]  eta: 0:14:54  Lr: 0.001875  Loss: -0.7031  Acc@1: 75.0000 (80.2162)  Acc@5: 100.0000 (98.7825)  time: 0.3503  data: 0.0012  max mem: 2503
Train: Epoch[3/5]  [1200/3750]  eta: 0:14:50  Lr: 0.001875  Loss: -0.7923  Acc@1: 81.2500 (80.2404)  Acc@5: 100.0000 (98.7875)  time: 0.3499  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [1210/3750]  eta: 0:14:47  Lr: 0.001875  Loss: -0.6988  Acc@1: 81.2500 (80.2539)  Acc@5: 100.0000 (98.7923)  time: 0.3505  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [1220/3750]  eta: 0:14:43  Lr: 0.001875  Loss: -0.8907  Acc@1: 75.0000 (80.2211)  Acc@5: 100.0000 (98.7869)  time: 0.3500  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [1230/3750]  eta: 0:14:40  Lr: 0.001875  Loss: -0.6052  Acc@1: 81.2500 (80.2295)  Acc@5: 100.0000 (98.7916)  time: 0.3492  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [1240/3750]  eta: 0:14:36  Lr: 0.001875  Loss: -0.9039  Acc@1: 81.2500 (80.2377)  Acc@5: 100.0000 (98.7963)  time: 0.3498  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [1250/3750]  eta: 0:14:33  Lr: 0.001875  Loss: -0.6384  Acc@1: 81.2500 (80.2658)  Acc@5: 100.0000 (98.8010)  time: 0.3504  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [1260/3750]  eta: 0:14:29  Lr: 0.001875  Loss: -1.0527  Acc@1: 81.2500 (80.2835)  Acc@5: 100.0000 (98.8055)  time: 0.3499  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [1270/3750]  eta: 0:14:26  Lr: 0.001875  Loss: -0.7626  Acc@1: 81.2500 (80.3009)  Acc@5: 100.0000 (98.8100)  time: 0.3502  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [1280/3750]  eta: 0:14:22  Lr: 0.001875  Loss: -0.7406  Acc@1: 81.2500 (80.2937)  Acc@5: 100.0000 (98.7949)  time: 0.3501  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [1290/3750]  eta: 0:14:19  Lr: 0.001875  Loss: -0.8632  Acc@1: 81.2500 (80.2914)  Acc@5: 100.0000 (98.7994)  time: 0.3490  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [1300/3750]  eta: 0:14:15  Lr: 0.001875  Loss: -1.2091  Acc@1: 81.2500 (80.2988)  Acc@5: 100.0000 (98.7846)  time: 0.3489  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [1310/3750]  eta: 0:14:12  Lr: 0.001875  Loss: -0.8684  Acc@1: 81.2500 (80.3013)  Acc@5: 100.0000 (98.7939)  time: 0.3496  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [1320/3750]  eta: 0:14:09  Lr: 0.001875  Loss: -1.1644  Acc@1: 81.2500 (80.3416)  Acc@5: 100.0000 (98.7841)  time: 0.3502  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [1330/3750]  eta: 0:14:05  Lr: 0.001875  Loss: -0.7025  Acc@1: 81.2500 (80.3296)  Acc@5: 100.0000 (98.7885)  time: 0.3502  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [1340/3750]  eta: 0:14:02  Lr: 0.001875  Loss: -0.7433  Acc@1: 81.2500 (80.2759)  Acc@5: 100.0000 (98.7789)  time: 0.3500  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [1350/3750]  eta: 0:13:58  Lr: 0.001875  Loss: -0.6240  Acc@1: 75.0000 (80.2831)  Acc@5: 100.0000 (98.7694)  time: 0.3501  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [1360/3750]  eta: 0:13:55  Lr: 0.001875  Loss: -0.9506  Acc@1: 81.2500 (80.2673)  Acc@5: 100.0000 (98.7739)  time: 0.3501  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [1370/3750]  eta: 0:13:51  Lr: 0.001875  Loss: -0.9444  Acc@1: 81.2500 (80.2562)  Acc@5: 100.0000 (98.7737)  time: 0.3503  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [1380/3750]  eta: 0:13:48  Lr: 0.001875  Loss: -0.7082  Acc@1: 81.2500 (80.2362)  Acc@5: 100.0000 (98.7735)  time: 0.3500  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [1390/3750]  eta: 0:13:44  Lr: 0.001875  Loss: -0.7907  Acc@1: 81.2500 (80.2211)  Acc@5: 100.0000 (98.7644)  time: 0.3498  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [1400/3750]  eta: 0:13:41  Lr: 0.001875  Loss: -0.4842  Acc@1: 81.2500 (80.1972)  Acc@5: 100.0000 (98.7643)  time: 0.3509  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [1410/3750]  eta: 0:13:37  Lr: 0.001875  Loss: -0.5096  Acc@1: 81.2500 (80.2091)  Acc@5: 100.0000 (98.7686)  time: 0.3506  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [1420/3750]  eta: 0:13:34  Lr: 0.001875  Loss: -0.7755  Acc@1: 81.2500 (80.2076)  Acc@5: 100.0000 (98.7685)  time: 0.3502  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [1430/3750]  eta: 0:13:30  Lr: 0.001875  Loss: -0.6013  Acc@1: 81.2500 (80.1974)  Acc@5: 100.0000 (98.7596)  time: 0.3505  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [1440/3750]  eta: 0:13:27  Lr: 0.001875  Loss: -0.6243  Acc@1: 81.2500 (80.2264)  Acc@5: 100.0000 (98.7595)  time: 0.3498  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [1450/3750]  eta: 0:13:23  Lr: 0.001875  Loss: -0.9325  Acc@1: 81.2500 (80.1904)  Acc@5: 100.0000 (98.7595)  time: 0.3493  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [1460/3750]  eta: 0:13:20  Lr: 0.001875  Loss: -0.9399  Acc@1: 81.2500 (80.2019)  Acc@5: 100.0000 (98.7637)  time: 0.3497  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [1470/3750]  eta: 0:13:16  Lr: 0.001875  Loss: -0.2702  Acc@1: 68.7500 (80.1453)  Acc@5: 100.0000 (98.7593)  time: 0.3506  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [1480/3750]  eta: 0:13:13  Lr: 0.001875  Loss: -1.1527  Acc@1: 68.7500 (80.1317)  Acc@5: 100.0000 (98.7551)  time: 0.3506  data: 0.0006  max mem: 2503
Train: Epoch[3/5]  [1490/3750]  eta: 0:13:09  Lr: 0.001875  Loss: -0.7090  Acc@1: 81.2500 (80.1434)  Acc@5: 100.0000 (98.7592)  time: 0.3498  data: 0.0007  max mem: 2503
Train: Epoch[3/5]  [1500/3750]  eta: 0:13:06  Lr: 0.001875  Loss: -0.7912  Acc@1: 81.2500 (80.1424)  Acc@5: 100.0000 (98.7550)  time: 0.3496  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [1510/3750]  eta: 0:13:02  Lr: 0.001875  Loss: -0.7303  Acc@1: 81.2500 (80.1208)  Acc@5: 100.0000 (98.7591)  time: 0.3507  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [1520/3750]  eta: 0:12:59  Lr: 0.001875  Loss: -0.8462  Acc@1: 81.2500 (80.1077)  Acc@5: 100.0000 (98.7467)  time: 0.3507  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [1530/3750]  eta: 0:12:55  Lr: 0.001875  Loss: -0.6211  Acc@1: 75.0000 (80.0825)  Acc@5: 100.0000 (98.7427)  time: 0.3509  data: 0.0010  max mem: 2503
Train: Epoch[3/5]  [1540/3750]  eta: 0:12:52  Lr: 0.001875  Loss: -0.8947  Acc@1: 81.2500 (80.0941)  Acc@5: 100.0000 (98.7427)  time: 0.3513  data: 0.0009  max mem: 2503
Train: Epoch[3/5]  [1550/3750]  eta: 0:12:48  Lr: 0.001875  Loss: -0.7840  Acc@1: 81.2500 (80.0774)  Acc@5: 100.0000 (98.7347)  time: 0.3498  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [1560/3750]  eta: 0:12:45  Lr: 0.001875  Loss: -0.8087  Acc@1: 81.2500 (80.1129)  Acc@5: 100.0000 (98.7388)  time: 0.3496  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [1570/3750]  eta: 0:12:41  Lr: 0.001875  Loss: -0.5322  Acc@1: 81.2500 (80.1162)  Acc@5: 100.0000 (98.7428)  time: 0.3503  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [1580/3750]  eta: 0:12:38  Lr: 0.001875  Loss: -0.6165  Acc@1: 81.2500 (80.1075)  Acc@5: 100.0000 (98.7429)  time: 0.3500  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [1590/3750]  eta: 0:12:34  Lr: 0.001875  Loss: -0.5823  Acc@1: 81.2500 (80.1029)  Acc@5: 100.0000 (98.7429)  time: 0.3503  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [1600/3750]  eta: 0:12:31  Lr: 0.001875  Loss: -1.0832  Acc@1: 81.2500 (80.0906)  Acc@5: 100.0000 (98.7430)  time: 0.3503  data: 0.0006  max mem: 2503
Train: Epoch[3/5]  [1610/3750]  eta: 0:12:28  Lr: 0.001875  Loss: -0.8499  Acc@1: 81.2500 (80.0978)  Acc@5: 100.0000 (98.7391)  time: 0.3506  data: 0.0006  max mem: 2503
Train: Epoch[3/5]  [1620/3750]  eta: 0:12:24  Lr: 0.001875  Loss: -0.7207  Acc@1: 81.2500 (80.1049)  Acc@5: 100.0000 (98.7431)  time: 0.3509  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [1630/3750]  eta: 0:12:21  Lr: 0.001875  Loss: -0.6990  Acc@1: 81.2500 (80.1234)  Acc@5: 100.0000 (98.7354)  time: 0.3521  data: 0.0019  max mem: 2503
Train: Epoch[3/5]  [1640/3750]  eta: 0:12:17  Lr: 0.001875  Loss: -0.9224  Acc@1: 81.2500 (80.0884)  Acc@5: 100.0000 (98.7279)  time: 0.3518  data: 0.0019  max mem: 2503
Train: Epoch[3/5]  [1650/3750]  eta: 0:12:14  Lr: 0.001875  Loss: -0.8809  Acc@1: 75.0000 (80.0765)  Acc@5: 100.0000 (98.7318)  time: 0.3511  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [1660/3750]  eta: 0:12:10  Lr: 0.001875  Loss: -0.6473  Acc@1: 75.0000 (80.0835)  Acc@5: 100.0000 (98.7319)  time: 0.3511  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [1670/3750]  eta: 0:12:07  Lr: 0.001875  Loss: -0.6538  Acc@1: 81.2500 (80.0905)  Acc@5: 100.0000 (98.7395)  time: 0.3491  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [1680/3750]  eta: 0:12:03  Lr: 0.001875  Loss: -0.5346  Acc@1: 75.0000 (80.0268)  Acc@5: 100.0000 (98.7396)  time: 0.3492  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [1690/3750]  eta: 0:12:00  Lr: 0.001875  Loss: -0.5450  Acc@1: 75.0000 (80.0414)  Acc@5: 100.0000 (98.7397)  time: 0.3492  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [1700/3750]  eta: 0:11:56  Lr: 0.001875  Loss: -1.0682  Acc@1: 81.2500 (80.0228)  Acc@5: 100.0000 (98.7434)  time: 0.3486  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [1710/3750]  eta: 0:11:53  Lr: 0.001875  Loss: -1.0247  Acc@1: 81.2500 (80.0409)  Acc@5: 100.0000 (98.7361)  time: 0.3495  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [1720/3750]  eta: 0:11:49  Lr: 0.001875  Loss: -0.7163  Acc@1: 81.2500 (80.0516)  Acc@5: 100.0000 (98.7326)  time: 0.3505  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [1730/3750]  eta: 0:11:46  Lr: 0.001875  Loss: -0.5256  Acc@1: 81.2500 (80.0404)  Acc@5: 100.0000 (98.7327)  time: 0.3489  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [1740/3750]  eta: 0:11:42  Lr: 0.001875  Loss: -0.6539  Acc@1: 81.2500 (80.0330)  Acc@5: 100.0000 (98.7328)  time: 0.3477  data: 0.0006  max mem: 2503
Train: Epoch[3/5]  [1750/3750]  eta: 0:11:39  Lr: 0.001875  Loss: -0.9354  Acc@1: 81.2500 (80.0364)  Acc@5: 100.0000 (98.7293)  time: 0.3478  data: 0.0007  max mem: 2503
Train: Epoch[3/5]  [1760/3750]  eta: 0:11:35  Lr: 0.001875  Loss: -0.8530  Acc@1: 87.5000 (80.0752)  Acc@5: 100.0000 (98.7330)  time: 0.3486  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [1770/3750]  eta: 0:11:32  Lr: 0.001875  Loss: -0.3008  Acc@1: 87.5000 (80.0642)  Acc@5: 100.0000 (98.7401)  time: 0.3489  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [1780/3750]  eta: 0:11:28  Lr: 0.001875  Loss: -0.6470  Acc@1: 81.2500 (80.0779)  Acc@5: 100.0000 (98.7437)  time: 0.3478  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [1790/3750]  eta: 0:11:25  Lr: 0.001875  Loss: -0.6982  Acc@1: 87.5000 (80.1054)  Acc@5: 100.0000 (98.7437)  time: 0.3482  data: 0.0009  max mem: 2503
Train: Epoch[3/5]  [1800/3750]  eta: 0:11:21  Lr: 0.001875  Loss: -0.8182  Acc@1: 87.5000 (80.1187)  Acc@5: 100.0000 (98.7438)  time: 0.3478  data: 0.0009  max mem: 2503
Train: Epoch[3/5]  [1810/3750]  eta: 0:11:18  Lr: 0.001875  Loss: -0.5294  Acc@1: 81.2500 (80.0801)  Acc@5: 100.0000 (98.7472)  time: 0.3472  data: 0.0006  max mem: 2503
Train: Epoch[3/5]  [1820/3750]  eta: 0:11:14  Lr: 0.001875  Loss: -0.8216  Acc@1: 75.0000 (80.0556)  Acc@5: 100.0000 (98.7473)  time: 0.3476  data: 0.0007  max mem: 2503
Train: Epoch[3/5]  [1830/3750]  eta: 0:11:11  Lr: 0.001875  Loss: -0.7760  Acc@1: 75.0000 (80.0416)  Acc@5: 100.0000 (98.7473)  time: 0.3480  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [1840/3750]  eta: 0:11:07  Lr: 0.001875  Loss: -0.9040  Acc@1: 75.0000 (80.0177)  Acc@5: 100.0000 (98.7473)  time: 0.3478  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [1850/3750]  eta: 0:11:03  Lr: 0.001875  Loss: -0.8076  Acc@1: 81.2500 (80.0074)  Acc@5: 100.0000 (98.7473)  time: 0.3478  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [1860/3750]  eta: 0:11:00  Lr: 0.001875  Loss: -0.8471  Acc@1: 81.2500 (79.9973)  Acc@5: 100.0000 (98.7440)  time: 0.3483  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [1870/3750]  eta: 0:10:56  Lr: 0.001875  Loss: -0.5333  Acc@1: 68.7500 (79.9472)  Acc@5: 100.0000 (98.7440)  time: 0.3480  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [1880/3750]  eta: 0:10:53  Lr: 0.001875  Loss: -1.0853  Acc@1: 75.0000 (79.9641)  Acc@5: 100.0000 (98.7440)  time: 0.3483  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [1890/3750]  eta: 0:10:49  Lr: 0.001875  Loss: -0.9007  Acc@1: 81.2500 (79.9709)  Acc@5: 100.0000 (98.7474)  time: 0.3486  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [1900/3750]  eta: 0:10:46  Lr: 0.001875  Loss: -0.6477  Acc@1: 81.2500 (79.9809)  Acc@5: 100.0000 (98.7375)  time: 0.3479  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [1910/3750]  eta: 0:10:42  Lr: 0.001875  Loss: -0.5357  Acc@1: 75.0000 (79.9647)  Acc@5: 100.0000 (98.7376)  time: 0.3484  data: 0.0011  max mem: 2503
Train: Epoch[3/5]  [1920/3750]  eta: 0:10:39  Lr: 0.001875  Loss: -0.8830  Acc@1: 75.0000 (79.9746)  Acc@5: 100.0000 (98.7409)  time: 0.3482  data: 0.0011  max mem: 2503
Train: Epoch[3/5]  [1930/3750]  eta: 0:10:35  Lr: 0.001875  Loss: -0.5007  Acc@1: 81.2500 (79.9812)  Acc@5: 100.0000 (98.7409)  time: 0.3474  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [1940/3750]  eta: 0:10:32  Lr: 0.001875  Loss: -0.7297  Acc@1: 81.2500 (79.9749)  Acc@5: 100.0000 (98.7442)  time: 0.3476  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [1950/3750]  eta: 0:10:28  Lr: 0.001875  Loss: -0.6177  Acc@1: 81.2500 (79.9782)  Acc@5: 100.0000 (98.7442)  time: 0.3474  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [1960/3750]  eta: 0:10:25  Lr: 0.001875  Loss: -0.3435  Acc@1: 75.0000 (79.9720)  Acc@5: 100.0000 (98.7443)  time: 0.3479  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [1970/3750]  eta: 0:10:21  Lr: 0.001875  Loss: -1.0472  Acc@1: 75.0000 (79.9784)  Acc@5: 100.0000 (98.7475)  time: 0.3484  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [1980/3750]  eta: 0:10:18  Lr: 0.001875  Loss: -0.9651  Acc@1: 81.2500 (79.9785)  Acc@5: 100.0000 (98.7538)  time: 0.3479  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [1990/3750]  eta: 0:10:14  Lr: 0.001875  Loss: -1.1756  Acc@1: 81.2500 (79.9975)  Acc@5: 100.0000 (98.7600)  time: 0.3481  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [2000/3750]  eta: 0:10:11  Lr: 0.001875  Loss: -1.1500  Acc@1: 81.2500 (80.0131)  Acc@5: 100.0000 (98.7631)  time: 0.3486  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [2010/3750]  eta: 0:10:07  Lr: 0.001875  Loss: -0.7180  Acc@1: 81.2500 (80.0348)  Acc@5: 100.0000 (98.7631)  time: 0.3500  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [2020/3750]  eta: 0:10:04  Lr: 0.001875  Loss: -0.6929  Acc@1: 81.2500 (80.0161)  Acc@5: 100.0000 (98.7661)  time: 0.3505  data: 0.0003  max mem: 2503
Train: Epoch[3/5]  [2030/3750]  eta: 0:10:00  Lr: 0.001875  Loss: -0.6700  Acc@1: 81.2500 (80.0375)  Acc@5: 100.0000 (98.7629)  time: 0.3498  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [2040/3750]  eta: 0:09:57  Lr: 0.001875  Loss: -1.0441  Acc@1: 81.2500 (80.0343)  Acc@5: 100.0000 (98.7598)  time: 0.3509  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [2050/3750]  eta: 0:09:53  Lr: 0.001875  Loss: -0.6999  Acc@1: 81.2500 (80.0280)  Acc@5: 100.0000 (98.7598)  time: 0.3509  data: 0.0007  max mem: 2503
Train: Epoch[3/5]  [2060/3750]  eta: 0:09:50  Lr: 0.001875  Loss: -0.6497  Acc@1: 81.2500 (80.0249)  Acc@5: 100.0000 (98.7658)  time: 0.3508  data: 0.0013  max mem: 2503
Train: Epoch[3/5]  [2070/3750]  eta: 0:09:47  Lr: 0.001875  Loss: -0.8682  Acc@1: 81.2500 (80.0278)  Acc@5: 100.0000 (98.7717)  time: 0.3507  data: 0.0011  max mem: 2503
Train: Epoch[3/5]  [2080/3750]  eta: 0:09:43  Lr: 0.001875  Loss: -0.7983  Acc@1: 81.2500 (80.0246)  Acc@5: 100.0000 (98.7716)  time: 0.3503  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [2090/3750]  eta: 0:09:40  Lr: 0.001875  Loss: -1.1419  Acc@1: 81.2500 (80.0365)  Acc@5: 100.0000 (98.7655)  time: 0.3509  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [2100/3750]  eta: 0:09:36  Lr: 0.001875  Loss: -0.7382  Acc@1: 81.2500 (80.0184)  Acc@5: 100.0000 (98.7655)  time: 0.3519  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [2110/3750]  eta: 0:09:33  Lr: 0.001875  Loss: -1.0066  Acc@1: 81.2500 (80.0361)  Acc@5: 100.0000 (98.7713)  time: 0.3518  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [2120/3750]  eta: 0:09:29  Lr: 0.001875  Loss: -0.1707  Acc@1: 81.2500 (80.0065)  Acc@5: 100.0000 (98.7653)  time: 0.3509  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [2130/3750]  eta: 0:09:26  Lr: 0.001875  Loss: -0.8176  Acc@1: 81.2500 (80.0270)  Acc@5: 100.0000 (98.7682)  time: 0.3508  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [2140/3750]  eta: 0:09:22  Lr: 0.001875  Loss: -1.0515  Acc@1: 81.2500 (80.0415)  Acc@5: 100.0000 (98.7710)  time: 0.3502  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [2150/3750]  eta: 0:09:19  Lr: 0.001875  Loss: -0.7367  Acc@1: 81.2500 (80.0587)  Acc@5: 100.0000 (98.7651)  time: 0.3498  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [2160/3750]  eta: 0:09:15  Lr: 0.001875  Loss: -0.5374  Acc@1: 87.5000 (80.0758)  Acc@5: 100.0000 (98.7679)  time: 0.3502  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [2170/3750]  eta: 0:09:12  Lr: 0.001875  Loss: -0.5950  Acc@1: 81.2500 (80.0610)  Acc@5: 100.0000 (98.7678)  time: 0.3505  data: 0.0012  max mem: 2503
Train: Epoch[3/5]  [2180/3750]  eta: 0:09:08  Lr: 0.001875  Loss: -0.9088  Acc@1: 81.2500 (80.0693)  Acc@5: 100.0000 (98.7706)  time: 0.3500  data: 0.0012  max mem: 2503
Train: Epoch[3/5]  [2190/3750]  eta: 0:09:05  Lr: 0.001875  Loss: -0.9194  Acc@1: 81.2500 (80.0776)  Acc@5: 100.0000 (98.7677)  time: 0.3492  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [2200/3750]  eta: 0:09:01  Lr: 0.001875  Loss: -0.9834  Acc@1: 81.2500 (80.0914)  Acc@5: 100.0000 (98.7619)  time: 0.3501  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [2210/3750]  eta: 0:08:58  Lr: 0.001875  Loss: -0.7075  Acc@1: 81.2500 (80.0825)  Acc@5: 100.0000 (98.7647)  time: 0.3501  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [2220/3750]  eta: 0:08:54  Lr: 0.001875  Loss: -0.6590  Acc@1: 75.0000 (80.0597)  Acc@5: 100.0000 (98.7590)  time: 0.3504  data: 0.0014  max mem: 2503
Train: Epoch[3/5]  [2230/3750]  eta: 0:08:51  Lr: 0.001875  Loss: -0.7529  Acc@1: 75.0000 (80.0426)  Acc@5: 100.0000 (98.7506)  time: 0.3499  data: 0.0014  max mem: 2503
Train: Epoch[3/5]  [2240/3750]  eta: 0:08:47  Lr: 0.001875  Loss: -0.6612  Acc@1: 75.0000 (80.0312)  Acc@5: 100.0000 (98.7450)  time: 0.3482  data: 0.0006  max mem: 2503
Train: Epoch[3/5]  [2250/3750]  eta: 0:08:44  Lr: 0.001875  Loss: -1.0034  Acc@1: 81.2500 (80.0339)  Acc@5: 100.0000 (98.7450)  time: 0.3486  data: 0.0006  max mem: 2503
Train: Epoch[3/5]  [2260/3750]  eta: 0:08:40  Lr: 0.001875  Loss: -0.7055  Acc@1: 81.2500 (80.0448)  Acc@5: 100.0000 (98.7478)  time: 0.3488  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [2270/3750]  eta: 0:08:37  Lr: 0.001875  Loss: -0.9221  Acc@1: 81.2500 (80.0473)  Acc@5: 100.0000 (98.7506)  time: 0.3485  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [2280/3750]  eta: 0:08:33  Lr: 0.001875  Loss: -1.1490  Acc@1: 81.2500 (80.0663)  Acc@5: 100.0000 (98.7505)  time: 0.3488  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [2290/3750]  eta: 0:08:30  Lr: 0.001875  Loss: -0.6899  Acc@1: 81.2500 (80.0578)  Acc@5: 100.0000 (98.7505)  time: 0.3490  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [2300/3750]  eta: 0:08:26  Lr: 0.001875  Loss: -0.9833  Acc@1: 81.2500 (80.0739)  Acc@5: 100.0000 (98.7505)  time: 0.3496  data: 0.0016  max mem: 2503
Train: Epoch[3/5]  [2310/3750]  eta: 0:08:23  Lr: 0.001875  Loss: -0.7743  Acc@1: 81.2500 (80.0682)  Acc@5: 100.0000 (98.7505)  time: 0.3512  data: 0.0015  max mem: 2503
Train: Epoch[3/5]  [2320/3750]  eta: 0:08:19  Lr: 0.001875  Loss: -0.7459  Acc@1: 81.2500 (80.0840)  Acc@5: 100.0000 (98.7559)  time: 0.3501  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [2330/3750]  eta: 0:08:16  Lr: 0.001875  Loss: -0.7156  Acc@1: 87.5000 (80.1105)  Acc@5: 100.0000 (98.7586)  time: 0.3488  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [2340/3750]  eta: 0:08:12  Lr: 0.001875  Loss: -0.8243  Acc@1: 81.2500 (80.1100)  Acc@5: 100.0000 (98.7532)  time: 0.3492  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [2350/3750]  eta: 0:08:09  Lr: 0.001875  Loss: -0.2787  Acc@1: 81.2500 (80.0936)  Acc@5: 100.0000 (98.7558)  time: 0.3493  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [2360/3750]  eta: 0:08:05  Lr: 0.001875  Loss: -0.7843  Acc@1: 81.2500 (80.1038)  Acc@5: 100.0000 (98.7558)  time: 0.3497  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [2370/3750]  eta: 0:08:02  Lr: 0.001875  Loss: -0.9426  Acc@1: 81.2500 (80.0954)  Acc@5: 100.0000 (98.7584)  time: 0.3495  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [2380/3750]  eta: 0:07:58  Lr: 0.001875  Loss: -0.7067  Acc@1: 81.2500 (80.1134)  Acc@5: 100.0000 (98.7558)  time: 0.3507  data: 0.0012  max mem: 2503
Train: Epoch[3/5]  [2390/3750]  eta: 0:07:55  Lr: 0.001875  Loss: -0.8678  Acc@1: 87.5000 (80.1338)  Acc@5: 100.0000 (98.7610)  time: 0.3512  data: 0.0014  max mem: 2503
Train: Epoch[3/5]  [2400/3750]  eta: 0:07:51  Lr: 0.001875  Loss: -0.3607  Acc@1: 87.5000 (80.1307)  Acc@5: 100.0000 (98.7609)  time: 0.3502  data: 0.0006  max mem: 2503
Train: Epoch[3/5]  [2410/3750]  eta: 0:07:48  Lr: 0.001875  Loss: -0.5484  Acc@1: 81.2500 (80.1483)  Acc@5: 100.0000 (98.7635)  time: 0.3504  data: 0.0011  max mem: 2503
Train: Epoch[3/5]  [2420/3750]  eta: 0:07:44  Lr: 0.001875  Loss: -0.7222  Acc@1: 81.2500 (80.1554)  Acc@5: 100.0000 (98.7686)  time: 0.3499  data: 0.0012  max mem: 2503
Train: Epoch[3/5]  [2430/3750]  eta: 0:07:41  Lr: 0.001875  Loss: -1.1048  Acc@1: 81.2500 (80.1471)  Acc@5: 100.0000 (98.7711)  time: 0.3488  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [2440/3750]  eta: 0:07:37  Lr: 0.001875  Loss: -0.6832  Acc@1: 81.2500 (80.1362)  Acc@5: 100.0000 (98.7710)  time: 0.3490  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [2450/3750]  eta: 0:07:34  Lr: 0.001875  Loss: -0.8937  Acc@1: 81.2500 (80.1331)  Acc@5: 100.0000 (98.7709)  time: 0.3490  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [2460/3750]  eta: 0:07:30  Lr: 0.001875  Loss: -0.9749  Acc@1: 81.2500 (80.1402)  Acc@5: 100.0000 (98.7759)  time: 0.3491  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [2470/3750]  eta: 0:07:27  Lr: 0.001875  Loss: -0.9785  Acc@1: 81.2500 (80.1447)  Acc@5: 100.0000 (98.7758)  time: 0.3495  data: 0.0006  max mem: 2503
Train: Epoch[3/5]  [2480/3750]  eta: 0:07:23  Lr: 0.001875  Loss: -0.8737  Acc@1: 81.2500 (80.1517)  Acc@5: 100.0000 (98.7757)  time: 0.3491  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [2490/3750]  eta: 0:07:20  Lr: 0.001875  Loss: -0.4337  Acc@1: 81.2500 (80.1485)  Acc@5: 100.0000 (98.7781)  time: 0.3501  data: 0.0012  max mem: 2503
Train: Epoch[3/5]  [2500/3750]  eta: 0:07:16  Lr: 0.001875  Loss: -0.5590  Acc@1: 81.2500 (80.1454)  Acc@5: 100.0000 (98.7780)  time: 0.3525  data: 0.0012  max mem: 2503
Train: Epoch[3/5]  [2510/3750]  eta: 0:07:13  Lr: 0.001875  Loss: -0.6959  Acc@1: 81.2500 (80.1498)  Acc@5: 100.0000 (98.7754)  time: 0.3519  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [2520/3750]  eta: 0:07:09  Lr: 0.001875  Loss: -0.9449  Acc@1: 87.5000 (80.1641)  Acc@5: 100.0000 (98.7679)  time: 0.3499  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [2530/3750]  eta: 0:07:06  Lr: 0.001875  Loss: -1.0288  Acc@1: 87.5000 (80.1808)  Acc@5: 100.0000 (98.7702)  time: 0.3501  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [2540/3750]  eta: 0:07:02  Lr: 0.001875  Loss: -0.6200  Acc@1: 81.2500 (80.1899)  Acc@5: 100.0000 (98.7751)  time: 0.3496  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [2550/3750]  eta: 0:06:59  Lr: 0.001875  Loss: -0.9004  Acc@1: 81.2500 (80.1989)  Acc@5: 100.0000 (98.7799)  time: 0.3493  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [2560/3750]  eta: 0:06:55  Lr: 0.001875  Loss: -0.9431  Acc@1: 81.2500 (80.2006)  Acc@5: 100.0000 (98.7822)  time: 0.3495  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [2570/3750]  eta: 0:06:52  Lr: 0.001875  Loss: -0.9409  Acc@1: 81.2500 (80.1755)  Acc@5: 100.0000 (98.7821)  time: 0.3496  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [2580/3750]  eta: 0:06:48  Lr: 0.001875  Loss: -0.2808  Acc@1: 81.2500 (80.1821)  Acc@5: 100.0000 (98.7795)  time: 0.3500  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [2590/3750]  eta: 0:06:45  Lr: 0.001875  Loss: -0.8263  Acc@1: 87.5000 (80.1983)  Acc@5: 100.0000 (98.7794)  time: 0.3504  data: 0.0011  max mem: 2503
Train: Epoch[3/5]  [2600/3750]  eta: 0:06:41  Lr: 0.001875  Loss: -0.9372  Acc@1: 87.5000 (80.2215)  Acc@5: 100.0000 (98.7817)  time: 0.3501  data: 0.0010  max mem: 2503
Train: Epoch[3/5]  [2610/3750]  eta: 0:06:38  Lr: 0.001875  Loss: -0.7382  Acc@1: 87.5000 (80.2590)  Acc@5: 100.0000 (98.7840)  time: 0.3498  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [2620/3750]  eta: 0:06:34  Lr: 0.001875  Loss: -0.6242  Acc@1: 87.5000 (80.2580)  Acc@5: 100.0000 (98.7791)  time: 0.3497  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [2630/3750]  eta: 0:06:31  Lr: 0.001875  Loss: -0.6543  Acc@1: 81.2500 (80.2642)  Acc@5: 100.0000 (98.7814)  time: 0.3498  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [2640/3750]  eta: 0:06:27  Lr: 0.001875  Loss: -0.7654  Acc@1: 81.2500 (80.2655)  Acc@5: 100.0000 (98.7789)  time: 0.3517  data: 0.0010  max mem: 2503
Train: Epoch[3/5]  [2650/3750]  eta: 0:06:24  Lr: 0.001875  Loss: -0.8533  Acc@1: 81.2500 (80.2598)  Acc@5: 100.0000 (98.7764)  time: 0.3515  data: 0.0010  max mem: 2503
Train: Epoch[3/5]  [2660/3750]  eta: 0:06:20  Lr: 0.001875  Loss: -0.9630  Acc@1: 81.2500 (80.2659)  Acc@5: 100.0000 (98.7810)  time: 0.3495  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [2670/3750]  eta: 0:06:17  Lr: 0.001875  Loss: -0.5547  Acc@1: 81.2500 (80.2742)  Acc@5: 100.0000 (98.7785)  time: 0.3500  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [2680/3750]  eta: 0:06:14  Lr: 0.001875  Loss: -0.9764  Acc@1: 81.2500 (80.2662)  Acc@5: 100.0000 (98.7761)  time: 0.3507  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [2690/3750]  eta: 0:06:10  Lr: 0.001875  Loss: -0.8486  Acc@1: 81.2500 (80.2629)  Acc@5: 100.0000 (98.7760)  time: 0.3506  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [2700/3750]  eta: 0:06:07  Lr: 0.001875  Loss: -0.4804  Acc@1: 81.2500 (80.2619)  Acc@5: 100.0000 (98.7736)  time: 0.3500  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [2710/3750]  eta: 0:06:03  Lr: 0.001875  Loss: -1.0405  Acc@1: 81.2500 (80.2771)  Acc@5: 100.0000 (98.7712)  time: 0.3504  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [2720/3750]  eta: 0:06:00  Lr: 0.001875  Loss: -0.6341  Acc@1: 81.2500 (80.2669)  Acc@5: 100.0000 (98.7711)  time: 0.3510  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [2730/3750]  eta: 0:05:56  Lr: 0.001875  Loss: -0.6151  Acc@1: 75.0000 (80.2499)  Acc@5: 100.0000 (98.7733)  time: 0.3502  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [2740/3750]  eta: 0:05:53  Lr: 0.001875  Loss: -0.9282  Acc@1: 81.2500 (80.2490)  Acc@5: 100.0000 (98.7755)  time: 0.3501  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [2750/3750]  eta: 0:05:49  Lr: 0.001875  Loss: -0.6503  Acc@1: 81.2500 (80.2367)  Acc@5: 100.0000 (98.7777)  time: 0.3507  data: 0.0013  max mem: 2503
Train: Epoch[3/5]  [2760/3750]  eta: 0:05:46  Lr: 0.001875  Loss: -0.6271  Acc@1: 81.2500 (80.2336)  Acc@5: 100.0000 (98.7754)  time: 0.3505  data: 0.0012  max mem: 2503
Train: Epoch[3/5]  [2770/3750]  eta: 0:05:42  Lr: 0.001875  Loss: -0.7541  Acc@1: 81.2500 (80.2440)  Acc@5: 100.0000 (98.7730)  time: 0.3499  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [2780/3750]  eta: 0:05:39  Lr: 0.001875  Loss: -0.5567  Acc@1: 81.2500 (80.2454)  Acc@5: 100.0000 (98.7707)  time: 0.3505  data: 0.0012  max mem: 2503
Train: Epoch[3/5]  [2790/3750]  eta: 0:05:35  Lr: 0.001875  Loss: -0.9707  Acc@1: 81.2500 (80.2356)  Acc@5: 100.0000 (98.7706)  time: 0.3507  data: 0.0012  max mem: 2503
Train: Epoch[3/5]  [2800/3750]  eta: 0:05:32  Lr: 0.001875  Loss: -0.7600  Acc@1: 81.2500 (80.2303)  Acc@5: 100.0000 (98.7705)  time: 0.3498  data: 0.0006  max mem: 2503
Train: Epoch[3/5]  [2810/3750]  eta: 0:05:28  Lr: 0.001875  Loss: -0.8336  Acc@1: 81.2500 (80.2317)  Acc@5: 100.0000 (98.7705)  time: 0.3498  data: 0.0007  max mem: 2503
Train: Epoch[3/5]  [2820/3750]  eta: 0:05:25  Lr: 0.001875  Loss: -0.6892  Acc@1: 87.5000 (80.2508)  Acc@5: 100.0000 (98.7726)  time: 0.3498  data: 0.0009  max mem: 2503
Train: Epoch[3/5]  [2830/3750]  eta: 0:05:21  Lr: 0.001875  Loss: -0.9754  Acc@1: 81.2500 (80.2455)  Acc@5: 100.0000 (98.7747)  time: 0.3498  data: 0.0015  max mem: 2503
Train: Epoch[3/5]  [2840/3750]  eta: 0:05:18  Lr: 0.001875  Loss: -0.9426  Acc@1: 75.0000 (80.2314)  Acc@5: 100.0000 (98.7768)  time: 0.3494  data: 0.0011  max mem: 2503
Train: Epoch[3/5]  [2850/3750]  eta: 0:05:14  Lr: 0.001875  Loss: -1.0377  Acc@1: 81.2500 (80.2416)  Acc@5: 100.0000 (98.7811)  time: 0.3487  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [2860/3750]  eta: 0:05:11  Lr: 0.001875  Loss: -0.9898  Acc@1: 81.2500 (80.2538)  Acc@5: 100.0000 (98.7832)  time: 0.3492  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [2870/3750]  eta: 0:05:07  Lr: 0.001875  Loss: -0.8595  Acc@1: 87.5000 (80.2617)  Acc@5: 100.0000 (98.7853)  time: 0.3491  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [2880/3750]  eta: 0:05:04  Lr: 0.001875  Loss: -0.7582  Acc@1: 81.2500 (80.2608)  Acc@5: 100.0000 (98.7851)  time: 0.3485  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [2890/3750]  eta: 0:05:00  Lr: 0.001875  Loss: -0.6160  Acc@1: 81.2500 (80.2620)  Acc@5: 100.0000 (98.7829)  time: 0.3486  data: 0.0006  max mem: 2503
Train: Epoch[3/5]  [2900/3750]  eta: 0:04:57  Lr: 0.001875  Loss: -0.7067  Acc@1: 81.2500 (80.2676)  Acc@5: 100.0000 (98.7806)  time: 0.3491  data: 0.0006  max mem: 2503
Train: Epoch[3/5]  [2910/3750]  eta: 0:04:53  Lr: 0.001875  Loss: -0.5899  Acc@1: 81.2500 (80.2559)  Acc@5: 100.0000 (98.7805)  time: 0.3489  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [2920/3750]  eta: 0:04:50  Lr: 0.001875  Loss: -0.6565  Acc@1: 81.2500 (80.2572)  Acc@5: 100.0000 (98.7782)  time: 0.3500  data: 0.0011  max mem: 2503
Train: Epoch[3/5]  [2930/3750]  eta: 0:04:46  Lr: 0.001875  Loss: -0.9795  Acc@1: 81.2500 (80.2627)  Acc@5: 100.0000 (98.7781)  time: 0.3503  data: 0.0011  max mem: 2503
Train: Epoch[3/5]  [2940/3750]  eta: 0:04:43  Lr: 0.001875  Loss: -0.8859  Acc@1: 81.2500 (80.2554)  Acc@5: 100.0000 (98.7802)  time: 0.3493  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [2950/3750]  eta: 0:04:39  Lr: 0.001875  Loss: -0.9588  Acc@1: 81.2500 (80.2525)  Acc@5: 100.0000 (98.7822)  time: 0.3492  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [2960/3750]  eta: 0:04:36  Lr: 0.001875  Loss: -0.6292  Acc@1: 81.2500 (80.2495)  Acc@5: 100.0000 (98.7842)  time: 0.3492  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [2970/3750]  eta: 0:04:32  Lr: 0.001875  Loss: -0.6074  Acc@1: 81.2500 (80.2465)  Acc@5: 100.0000 (98.7841)  time: 0.3489  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [2980/3750]  eta: 0:04:29  Lr: 0.001875  Loss: -0.5376  Acc@1: 81.2500 (80.2394)  Acc@5: 100.0000 (98.7882)  time: 0.3495  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [2990/3750]  eta: 0:04:25  Lr: 0.001875  Loss: -0.8440  Acc@1: 81.2500 (80.2574)  Acc@5: 100.0000 (98.7901)  time: 0.3502  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [3000/3750]  eta: 0:04:22  Lr: 0.001875  Loss: -0.5505  Acc@1: 81.2500 (80.2566)  Acc@5: 100.0000 (98.7921)  time: 0.3498  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [3010/3750]  eta: 0:04:18  Lr: 0.001875  Loss: -0.3182  Acc@1: 81.2500 (80.2620)  Acc@5: 100.0000 (98.7940)  time: 0.3495  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [3020/3750]  eta: 0:04:15  Lr: 0.001875  Loss: -0.5511  Acc@1: 81.2500 (80.2590)  Acc@5: 100.0000 (98.7939)  time: 0.3500  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [3030/3750]  eta: 0:04:11  Lr: 0.001875  Loss: -0.6957  Acc@1: 81.2500 (80.2788)  Acc@5: 100.0000 (98.7937)  time: 0.3499  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [3040/3750]  eta: 0:04:08  Lr: 0.001875  Loss: -0.5661  Acc@1: 81.2500 (80.2738)  Acc@5: 100.0000 (98.7915)  time: 0.3495  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [3050/3750]  eta: 0:04:04  Lr: 0.001875  Loss: -1.0340  Acc@1: 87.5000 (80.3056)  Acc@5: 100.0000 (98.7955)  time: 0.3497  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [3060/3750]  eta: 0:04:01  Lr: 0.001875  Loss: -0.8705  Acc@1: 87.5000 (80.3148)  Acc@5: 100.0000 (98.7994)  time: 0.3496  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [3070/3750]  eta: 0:03:57  Lr: 0.001875  Loss: -0.9586  Acc@1: 81.2500 (80.3199)  Acc@5: 100.0000 (98.7952)  time: 0.3489  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [3080/3750]  eta: 0:03:54  Lr: 0.001875  Loss: -0.4986  Acc@1: 81.2500 (80.3331)  Acc@5: 100.0000 (98.7930)  time: 0.3488  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [3090/3750]  eta: 0:03:50  Lr: 0.001875  Loss: -0.7261  Acc@1: 81.2500 (80.3320)  Acc@5: 100.0000 (98.7949)  time: 0.3486  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [3100/3750]  eta: 0:03:47  Lr: 0.001875  Loss: -1.0998  Acc@1: 81.2500 (80.3471)  Acc@5: 100.0000 (98.7988)  time: 0.3483  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [3110/3750]  eta: 0:03:43  Lr: 0.001875  Loss: -1.0648  Acc@1: 87.5000 (80.3580)  Acc@5: 100.0000 (98.8006)  time: 0.3494  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [3120/3750]  eta: 0:03:40  Lr: 0.001875  Loss: -0.9308  Acc@1: 87.5000 (80.3609)  Acc@5: 100.0000 (98.8045)  time: 0.3510  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [3130/3750]  eta: 0:03:36  Lr: 0.001875  Loss: -0.4430  Acc@1: 81.2500 (80.3517)  Acc@5: 100.0000 (98.8063)  time: 0.3499  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [3140/3750]  eta: 0:03:33  Lr: 0.001875  Loss: -0.7039  Acc@1: 81.2500 (80.3506)  Acc@5: 100.0000 (98.8101)  time: 0.3491  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [3150/3750]  eta: 0:03:29  Lr: 0.001875  Loss: -0.8170  Acc@1: 87.5000 (80.3753)  Acc@5: 100.0000 (98.8139)  time: 0.3494  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [3160/3750]  eta: 0:03:26  Lr: 0.001875  Loss: -0.8805  Acc@1: 87.5000 (80.3721)  Acc@5: 100.0000 (98.8176)  time: 0.3485  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [3170/3750]  eta: 0:03:22  Lr: 0.001875  Loss: -0.9765  Acc@1: 81.2500 (80.3788)  Acc@5: 100.0000 (98.8213)  time: 0.3484  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [3180/3750]  eta: 0:03:19  Lr: 0.001875  Loss: -0.2462  Acc@1: 81.2500 (80.3737)  Acc@5: 100.0000 (98.8231)  time: 0.3486  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [3190/3750]  eta: 0:03:15  Lr: 0.001875  Loss: -0.5668  Acc@1: 75.0000 (80.3549)  Acc@5: 100.0000 (98.8189)  time: 0.3486  data: 0.0007  max mem: 2503
Train: Epoch[3/5]  [3200/3750]  eta: 0:03:12  Lr: 0.001875  Loss: -0.8449  Acc@1: 81.2500 (80.3597)  Acc@5: 100.0000 (98.8207)  time: 0.3491  data: 0.0009  max mem: 2503
Train: Epoch[3/5]  [3210/3750]  eta: 0:03:08  Lr: 0.001875  Loss: -0.8162  Acc@1: 81.2500 (80.3761)  Acc@5: 100.0000 (98.8146)  time: 0.3492  data: 0.0006  max mem: 2503
Train: Epoch[3/5]  [3220/3750]  eta: 0:03:05  Lr: 0.001875  Loss: -0.8151  Acc@1: 81.2500 (80.3788)  Acc@5: 100.0000 (98.8164)  time: 0.3488  data: 0.0007  max mem: 2503
Train: Epoch[3/5]  [3230/3750]  eta: 0:03:01  Lr: 0.001875  Loss: -0.6780  Acc@1: 81.2500 (80.3911)  Acc@5: 100.0000 (98.8181)  time: 0.3501  data: 0.0007  max mem: 2503
Train: Epoch[3/5]  [3240/3750]  eta: 0:02:58  Lr: 0.001875  Loss: -0.7474  Acc@1: 81.2500 (80.3957)  Acc@5: 100.0000 (98.8179)  time: 0.3538  data: 0.0007  max mem: 2503
Train: Epoch[3/5]  [3250/3750]  eta: 0:02:54  Lr: 0.001875  Loss: -0.8377  Acc@1: 81.2500 (80.3906)  Acc@5: 100.0000 (98.8215)  time: 0.3529  data: 0.0008  max mem: 2503
Train: Epoch[3/5]  [3260/3750]  eta: 0:02:51  Lr: 0.001875  Loss: -1.0266  Acc@1: 75.0000 (80.3856)  Acc@5: 100.0000 (98.8213)  time: 0.3500  data: 0.0013  max mem: 2503
Train: Epoch[3/5]  [3270/3750]  eta: 0:02:47  Lr: 0.001875  Loss: -0.7013  Acc@1: 75.0000 (80.3844)  Acc@5: 100.0000 (98.8211)  time: 0.3521  data: 0.0014  max mem: 2503
Train: Epoch[3/5]  [3280/3750]  eta: 0:02:44  Lr: 0.001875  Loss: -0.7544  Acc@1: 81.2500 (80.3966)  Acc@5: 100.0000 (98.8247)  time: 0.3510  data: 0.0006  max mem: 2503
Train: Epoch[3/5]  [3290/3750]  eta: 0:02:40  Lr: 0.001875  Loss: -0.5583  Acc@1: 87.5000 (80.4087)  Acc@5: 100.0000 (98.8282)  time: 0.3485  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [3300/3750]  eta: 0:02:37  Lr: 0.001875  Loss: -1.0196  Acc@1: 81.2500 (80.4131)  Acc@5: 100.0000 (98.8280)  time: 0.3490  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [3310/3750]  eta: 0:02:33  Lr: 0.001875  Loss: -0.5622  Acc@1: 81.2500 (80.4175)  Acc@5: 100.0000 (98.8297)  time: 0.3491  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [3320/3750]  eta: 0:02:30  Lr: 0.001875  Loss: -0.8261  Acc@1: 81.2500 (80.4125)  Acc@5: 100.0000 (98.8313)  time: 0.3492  data: 0.0006  max mem: 2503
Train: Epoch[3/5]  [3330/3750]  eta: 0:02:26  Lr: 0.001875  Loss: -0.4082  Acc@1: 75.0000 (80.4075)  Acc@5: 100.0000 (98.8273)  time: 0.3489  data: 0.0006  max mem: 2503
Train: Epoch[3/5]  [3340/3750]  eta: 0:02:23  Lr: 0.001875  Loss: -0.9742  Acc@1: 87.5000 (80.4232)  Acc@5: 100.0000 (98.8271)  time: 0.3499  data: 0.0017  max mem: 2503
Train: Epoch[3/5]  [3350/3750]  eta: 0:02:19  Lr: 0.001875  Loss: -0.9211  Acc@1: 87.5000 (80.4331)  Acc@5: 100.0000 (98.8287)  time: 0.3499  data: 0.0017  max mem: 2503
Train: Epoch[3/5]  [3360/3750]  eta: 0:02:16  Lr: 0.001875  Loss: -0.8765  Acc@1: 81.2500 (80.4262)  Acc@5: 100.0000 (98.8229)  time: 0.3486  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [3370/3750]  eta: 0:02:12  Lr: 0.001875  Loss: -0.6728  Acc@1: 81.2500 (80.4398)  Acc@5: 100.0000 (98.8208)  time: 0.3483  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [3380/3750]  eta: 0:02:09  Lr: 0.001875  Loss: -0.8606  Acc@1: 81.2500 (80.4255)  Acc@5: 100.0000 (98.8169)  time: 0.3485  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [3390/3750]  eta: 0:02:05  Lr: 0.001875  Loss: -0.5552  Acc@1: 81.2500 (80.4372)  Acc@5: 100.0000 (98.8204)  time: 0.3488  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [3400/3750]  eta: 0:02:02  Lr: 0.001875  Loss: -0.6189  Acc@1: 81.2500 (80.4396)  Acc@5: 100.0000 (98.8202)  time: 0.3491  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [3410/3750]  eta: 0:01:58  Lr: 0.001875  Loss: -0.9836  Acc@1: 81.2500 (80.4420)  Acc@5: 100.0000 (98.8218)  time: 0.3493  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [3420/3750]  eta: 0:01:55  Lr: 0.001875  Loss: -0.8900  Acc@1: 87.5000 (80.4626)  Acc@5: 100.0000 (98.8216)  time: 0.3503  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [3430/3750]  eta: 0:01:51  Lr: 0.001875  Loss: -0.5280  Acc@1: 87.5000 (80.4649)  Acc@5: 100.0000 (98.8251)  time: 0.3502  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [3440/3750]  eta: 0:01:48  Lr: 0.001875  Loss: -0.8066  Acc@1: 81.2500 (80.4762)  Acc@5: 100.0000 (98.8248)  time: 0.3488  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [3450/3750]  eta: 0:01:44  Lr: 0.001875  Loss: -0.6093  Acc@1: 87.5000 (80.4821)  Acc@5: 100.0000 (98.8282)  time: 0.3506  data: 0.0013  max mem: 2503
Train: Epoch[3/5]  [3460/3750]  eta: 0:01:41  Lr: 0.001875  Loss: -0.2822  Acc@1: 81.2500 (80.4807)  Acc@5: 100.0000 (98.8298)  time: 0.3510  data: 0.0012  max mem: 2503
Train: Epoch[3/5]  [3470/3750]  eta: 0:01:37  Lr: 0.001875  Loss: -0.9308  Acc@1: 81.2500 (80.4829)  Acc@5: 100.0000 (98.8314)  time: 0.3488  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [3480/3750]  eta: 0:01:34  Lr: 0.001875  Loss: -1.0162  Acc@1: 81.2500 (80.4905)  Acc@5: 100.0000 (98.8312)  time: 0.3485  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [3490/3750]  eta: 0:01:30  Lr: 0.001875  Loss: -1.0075  Acc@1: 81.2500 (80.4855)  Acc@5: 100.0000 (98.8327)  time: 0.3486  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [3500/3750]  eta: 0:01:27  Lr: 0.001875  Loss: -0.8036  Acc@1: 81.2500 (80.4913)  Acc@5: 100.0000 (98.8325)  time: 0.3499  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [3510/3750]  eta: 0:01:23  Lr: 0.001875  Loss: -0.5379  Acc@1: 81.2500 (80.4792)  Acc@5: 100.0000 (98.8322)  time: 0.3506  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [3520/3750]  eta: 0:01:20  Lr: 0.001875  Loss: -0.6679  Acc@1: 75.0000 (80.4796)  Acc@5: 100.0000 (98.8320)  time: 0.3494  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [3530/3750]  eta: 0:01:16  Lr: 0.001875  Loss: -0.5908  Acc@1: 81.2500 (80.4889)  Acc@5: 100.0000 (98.8318)  time: 0.3490  data: 0.0006  max mem: 2503
Train: Epoch[3/5]  [3540/3750]  eta: 0:01:13  Lr: 0.001875  Loss: -0.8368  Acc@1: 81.2500 (80.4787)  Acc@5: 100.0000 (98.8245)  time: 0.3489  data: 0.0006  max mem: 2503
Train: Epoch[3/5]  [3550/3750]  eta: 0:01:09  Lr: 0.001875  Loss: -0.7273  Acc@1: 81.2500 (80.4879)  Acc@5: 100.0000 (98.8260)  time: 0.3483  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [3560/3750]  eta: 0:01:06  Lr: 0.001875  Loss: -0.8395  Acc@1: 81.2500 (80.4918)  Acc@5: 100.0000 (98.8293)  time: 0.3481  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [3570/3750]  eta: 0:01:02  Lr: 0.001875  Loss: -0.3566  Acc@1: 81.2500 (80.4974)  Acc@5: 100.0000 (98.8239)  time: 0.3482  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [3580/3750]  eta: 0:00:59  Lr: 0.001875  Loss: -0.6915  Acc@1: 81.2500 (80.5013)  Acc@5: 100.0000 (98.8219)  time: 0.3483  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [3590/3750]  eta: 0:00:55  Lr: 0.001875  Loss: -0.7888  Acc@1: 87.5000 (80.5103)  Acc@5: 100.0000 (98.8217)  time: 0.3487  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [3600/3750]  eta: 0:00:52  Lr: 0.001875  Loss: -0.6623  Acc@1: 81.2500 (80.5158)  Acc@5: 100.0000 (98.8180)  time: 0.3485  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [3610/3750]  eta: 0:00:48  Lr: 0.001875  Loss: -0.1244  Acc@1: 81.2500 (80.5075)  Acc@5: 100.0000 (98.8161)  time: 0.3489  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [3620/3750]  eta: 0:00:45  Lr: 0.001875  Loss: -0.6834  Acc@1: 81.2500 (80.5164)  Acc@5: 100.0000 (98.8194)  time: 0.3484  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [3630/3750]  eta: 0:00:41  Lr: 0.001875  Loss: -0.4719  Acc@1: 75.0000 (80.4978)  Acc@5: 100.0000 (98.8192)  time: 0.3483  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [3640/3750]  eta: 0:00:38  Lr: 0.001875  Loss: -0.5365  Acc@1: 75.0000 (80.4947)  Acc@5: 100.0000 (98.8207)  time: 0.3501  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [3650/3750]  eta: 0:00:34  Lr: 0.001875  Loss: -0.6097  Acc@1: 81.2500 (80.5002)  Acc@5: 100.0000 (98.8240)  time: 0.3506  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [3660/3750]  eta: 0:00:31  Lr: 0.001875  Loss: -0.7108  Acc@1: 81.2500 (80.4954)  Acc@5: 100.0000 (98.8238)  time: 0.3494  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [3670/3750]  eta: 0:00:27  Lr: 0.001875  Loss: -0.7027  Acc@1: 81.2500 (80.4992)  Acc@5: 100.0000 (98.8218)  time: 0.3493  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [3680/3750]  eta: 0:00:24  Lr: 0.001875  Loss: -0.5142  Acc@1: 81.2500 (80.4995)  Acc@5: 100.0000 (98.8250)  time: 0.3509  data: 0.0017  max mem: 2503
Train: Epoch[3/5]  [3690/3750]  eta: 0:00:20  Lr: 0.001875  Loss: -1.0455  Acc@1: 81.2500 (80.5016)  Acc@5: 100.0000 (98.8232)  time: 0.3509  data: 0.0018  max mem: 2503
Train: Epoch[3/5]  [3700/3750]  eta: 0:00:17  Lr: 0.001875  Loss: -0.9367  Acc@1: 81.2500 (80.4884)  Acc@5: 100.0000 (98.8230)  time: 0.3492  data: 0.0006  max mem: 2503
Train: Epoch[3/5]  [3710/3750]  eta: 0:00:13  Lr: 0.001875  Loss: -0.7442  Acc@1: 81.2500 (80.4803)  Acc@5: 100.0000 (98.8228)  time: 0.3487  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [3720/3750]  eta: 0:00:10  Lr: 0.001875  Loss: -0.7502  Acc@1: 81.2500 (80.4790)  Acc@5: 100.0000 (98.8209)  time: 0.3483  data: 0.0005  max mem: 2503
Train: Epoch[3/5]  [3730/3750]  eta: 0:00:06  Lr: 0.001875  Loss: -0.7228  Acc@1: 75.0000 (80.4644)  Acc@5: 100.0000 (98.8207)  time: 0.3486  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [3740/3750]  eta: 0:00:03  Lr: 0.001875  Loss: -0.5155  Acc@1: 81.2500 (80.4665)  Acc@5: 100.0000 (98.8222)  time: 0.3491  data: 0.0004  max mem: 2503
Train: Epoch[3/5]  [3749/3750]  eta: 0:00:00  Lr: 0.001875  Loss: -0.9231  Acc@1: 81.2500 (80.4600)  Acc@5: 100.0000 (98.8233)  time: 0.3512  data: 0.0029  max mem: 2503
Train: Epoch[3/5] Total time: 0:21:51 (0.3497 s / it)
Averaged stats: Lr: 0.001875  Loss: -0.9231  Acc@1: 81.2500 (80.4600)  Acc@5: 100.0000 (98.8233)
Train: Epoch[4/5]  [   0/3750]  eta: 0:43:52  Lr: 0.001875  Loss: -0.6428  Acc@1: 75.0000 (75.0000)  Acc@5: 100.0000 (100.0000)  time: 0.7020  data: 0.3505  max mem: 2503
Train: Epoch[4/5]  [  10/3750]  eta: 0:23:51  Lr: 0.001875  Loss: -0.9793  Acc@1: 87.5000 (84.0909)  Acc@5: 100.0000 (100.0000)  time: 0.3828  data: 0.0322  max mem: 2503
Train: Epoch[4/5]  [  20/3750]  eta: 0:22:48  Lr: 0.001875  Loss: -0.8303  Acc@1: 81.2500 (80.6548)  Acc@5: 100.0000 (99.1071)  time: 0.3501  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [  30/3750]  eta: 0:22:23  Lr: 0.001875  Loss: -0.2842  Acc@1: 81.2500 (79.4355)  Acc@5: 100.0000 (98.9919)  time: 0.3491  data: 0.0010  max mem: 2503
Train: Epoch[4/5]  [  40/3750]  eta: 0:22:09  Lr: 0.001875  Loss: -0.4156  Acc@1: 75.0000 (78.3537)  Acc@5: 100.0000 (98.9329)  time: 0.3492  data: 0.0010  max mem: 2503
Train: Epoch[4/5]  [  50/3750]  eta: 0:22:01  Lr: 0.001875  Loss: -0.9228  Acc@1: 75.0000 (78.3088)  Acc@5: 100.0000 (98.8971)  time: 0.3512  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [  60/3750]  eta: 0:21:52  Lr: 0.001875  Loss: -0.5664  Acc@1: 75.0000 (78.2787)  Acc@5: 100.0000 (98.7705)  time: 0.3503  data: 0.0003  max mem: 2503
Train: Epoch[4/5]  [  70/3750]  eta: 0:21:44  Lr: 0.001875  Loss: -1.1821  Acc@1: 81.2500 (78.9613)  Acc@5: 100.0000 (98.5035)  time: 0.3478  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [  80/3750]  eta: 0:21:38  Lr: 0.001875  Loss: -0.9413  Acc@1: 81.2500 (79.0123)  Acc@5: 100.0000 (98.6111)  time: 0.3479  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [  90/3750]  eta: 0:21:32  Lr: 0.001875  Loss: -0.9031  Acc@1: 81.2500 (80.0137)  Acc@5: 100.0000 (98.7637)  time: 0.3486  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [ 100/3750]  eta: 0:21:28  Lr: 0.001875  Loss: -0.7536  Acc@1: 87.5000 (80.1980)  Acc@5: 100.0000 (98.8861)  time: 0.3495  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [ 110/3750]  eta: 0:21:24  Lr: 0.001875  Loss: -0.6621  Acc@1: 75.0000 (80.0113)  Acc@5: 100.0000 (98.9302)  time: 0.3518  data: 0.0029  max mem: 2503
Train: Epoch[4/5]  [ 120/3750]  eta: 0:21:19  Lr: 0.001875  Loss: -0.5726  Acc@1: 81.2500 (80.0620)  Acc@5: 100.0000 (98.8636)  time: 0.3512  data: 0.0030  max mem: 2503
Train: Epoch[4/5]  [ 130/3750]  eta: 0:21:15  Lr: 0.001875  Loss: -0.5641  Acc@1: 81.2500 (80.0095)  Acc@5: 100.0000 (98.7118)  time: 0.3493  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [ 140/3750]  eta: 0:21:11  Lr: 0.001875  Loss: -1.0189  Acc@1: 81.2500 (80.4078)  Acc@5: 100.0000 (98.8032)  time: 0.3491  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [ 150/3750]  eta: 0:21:06  Lr: 0.001875  Loss: -0.8526  Acc@1: 81.2500 (80.2980)  Acc@5: 100.0000 (98.7583)  time: 0.3485  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [ 160/3750]  eta: 0:21:02  Lr: 0.001875  Loss: -0.7130  Acc@1: 81.2500 (80.5124)  Acc@5: 100.0000 (98.8354)  time: 0.3493  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [ 170/3750]  eta: 0:20:58  Lr: 0.001875  Loss: -0.3222  Acc@1: 81.2500 (80.1901)  Acc@5: 100.0000 (98.8670)  time: 0.3493  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [ 180/3750]  eta: 0:20:54  Lr: 0.001875  Loss: -0.6404  Acc@1: 81.2500 (80.3177)  Acc@5: 100.0000 (98.8260)  time: 0.3495  data: 0.0007  max mem: 2503
Train: Epoch[4/5]  [ 190/3750]  eta: 0:20:50  Lr: 0.001875  Loss: -0.8094  Acc@1: 81.2500 (80.4974)  Acc@5: 100.0000 (98.8547)  time: 0.3491  data: 0.0007  max mem: 2503
Train: Epoch[4/5]  [ 200/3750]  eta: 0:20:46  Lr: 0.001875  Loss: -1.1677  Acc@1: 81.2500 (80.3483)  Acc@5: 100.0000 (98.8495)  time: 0.3487  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [ 210/3750]  eta: 0:20:42  Lr: 0.001875  Loss: -1.0082  Acc@1: 75.0000 (80.2429)  Acc@5: 100.0000 (98.8744)  time: 0.3491  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [ 220/3750]  eta: 0:20:39  Lr: 0.001875  Loss: -0.9880  Acc@1: 75.0000 (80.0339)  Acc@5: 100.0000 (98.8688)  time: 0.3495  data: 0.0007  max mem: 2503
Train: Epoch[4/5]  [ 230/3750]  eta: 0:20:35  Lr: 0.001875  Loss: -0.9766  Acc@1: 75.0000 (79.9513)  Acc@5: 100.0000 (98.9177)  time: 0.3497  data: 0.0007  max mem: 2503
Train: Epoch[4/5]  [ 240/3750]  eta: 0:20:31  Lr: 0.001875  Loss: -0.6725  Acc@1: 75.0000 (79.7459)  Acc@5: 100.0000 (98.9108)  time: 0.3498  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [ 250/3750]  eta: 0:20:28  Lr: 0.001875  Loss: -0.7064  Acc@1: 75.0000 (79.7311)  Acc@5: 100.0000 (98.9542)  time: 0.3496  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [ 260/3750]  eta: 0:20:24  Lr: 0.001875  Loss: -0.8416  Acc@1: 81.2500 (80.0048)  Acc@5: 100.0000 (98.9943)  time: 0.3488  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [ 270/3750]  eta: 0:20:20  Lr: 0.001875  Loss: -0.5506  Acc@1: 81.2500 (80.0046)  Acc@5: 100.0000 (99.0314)  time: 0.3492  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [ 280/3750]  eta: 0:20:16  Lr: 0.001875  Loss: -0.8178  Acc@1: 81.2500 (80.0934)  Acc@5: 100.0000 (99.0214)  time: 0.3494  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [ 290/3750]  eta: 0:20:13  Lr: 0.001875  Loss: -0.8259  Acc@1: 87.5000 (80.0687)  Acc@5: 100.0000 (98.9691)  time: 0.3499  data: 0.0007  max mem: 2503
Train: Epoch[4/5]  [ 300/3750]  eta: 0:20:09  Lr: 0.001875  Loss: -0.9012  Acc@1: 81.2500 (80.1287)  Acc@5: 100.0000 (99.0033)  time: 0.3508  data: 0.0006  max mem: 2503
Train: Epoch[4/5]  [ 310/3750]  eta: 0:20:06  Lr: 0.001875  Loss: -0.8234  Acc@1: 81.2500 (80.1045)  Acc@5: 100.0000 (98.9952)  time: 0.3501  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [ 320/3750]  eta: 0:20:02  Lr: 0.001875  Loss: -0.9644  Acc@1: 81.2500 (80.1986)  Acc@5: 100.0000 (98.9875)  time: 0.3490  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [ 330/3750]  eta: 0:19:58  Lr: 0.001875  Loss: -0.7494  Acc@1: 81.2500 (80.0227)  Acc@5: 100.0000 (98.9992)  time: 0.3492  data: 0.0012  max mem: 2503
Train: Epoch[4/5]  [ 340/3750]  eta: 0:19:55  Lr: 0.001875  Loss: -0.9373  Acc@1: 81.2500 (80.0587)  Acc@5: 100.0000 (99.0103)  time: 0.3495  data: 0.0012  max mem: 2503
Train: Epoch[4/5]  [ 350/3750]  eta: 0:19:51  Lr: 0.001875  Loss: -0.5854  Acc@1: 81.2500 (80.0570)  Acc@5: 100.0000 (98.9672)  time: 0.3492  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [ 360/3750]  eta: 0:19:47  Lr: 0.001875  Loss: -0.8086  Acc@1: 75.0000 (80.0035)  Acc@5: 100.0000 (98.9439)  time: 0.3484  data: 0.0007  max mem: 2503
Train: Epoch[4/5]  [ 370/3750]  eta: 0:19:44  Lr: 0.001875  Loss: -0.9699  Acc@1: 81.2500 (80.0708)  Acc@5: 100.0000 (98.9555)  time: 0.3478  data: 0.0006  max mem: 2503
Train: Epoch[4/5]  [ 380/3750]  eta: 0:19:40  Lr: 0.001875  Loss: -0.9302  Acc@1: 81.2500 (80.0689)  Acc@5: 100.0000 (98.9501)  time: 0.3488  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [ 390/3750]  eta: 0:19:36  Lr: 0.001875  Loss: -0.1770  Acc@1: 75.0000 (79.8913)  Acc@5: 100.0000 (98.9450)  time: 0.3489  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [ 400/3750]  eta: 0:19:33  Lr: 0.001875  Loss: -0.4990  Acc@1: 75.0000 (79.8473)  Acc@5: 100.0000 (98.9090)  time: 0.3488  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [ 410/3750]  eta: 0:19:29  Lr: 0.001875  Loss: -0.6631  Acc@1: 81.2500 (79.9270)  Acc@5: 100.0000 (98.9203)  time: 0.3485  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [ 420/3750]  eta: 0:19:26  Lr: 0.001875  Loss: -0.6020  Acc@1: 81.2500 (79.9287)  Acc@5: 100.0000 (98.8866)  time: 0.3488  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [ 430/3750]  eta: 0:19:22  Lr: 0.001875  Loss: -0.7320  Acc@1: 81.2500 (80.1189)  Acc@5: 100.0000 (98.9124)  time: 0.3497  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [ 440/3750]  eta: 0:19:19  Lr: 0.001875  Loss: -0.5658  Acc@1: 87.5000 (80.1020)  Acc@5: 100.0000 (98.9229)  time: 0.3497  data: 0.0006  max mem: 2503
Train: Epoch[4/5]  [ 450/3750]  eta: 0:19:15  Lr: 0.001875  Loss: -0.4096  Acc@1: 81.2500 (80.1414)  Acc@5: 100.0000 (98.9468)  time: 0.3496  data: 0.0006  max mem: 2503
Train: Epoch[4/5]  [ 460/3750]  eta: 0:19:11  Lr: 0.001875  Loss: -0.9446  Acc@1: 81.2500 (80.0434)  Acc@5: 100.0000 (98.9290)  time: 0.3494  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [ 470/3750]  eta: 0:19:08  Lr: 0.001875  Loss: -0.7464  Acc@1: 75.0000 (79.9496)  Acc@5: 100.0000 (98.8986)  time: 0.3496  data: 0.0007  max mem: 2503
Train: Epoch[4/5]  [ 480/3750]  eta: 0:19:04  Lr: 0.001875  Loss: -0.7999  Acc@1: 81.2500 (80.0676)  Acc@5: 100.0000 (98.8825)  time: 0.3498  data: 0.0007  max mem: 2503
Train: Epoch[4/5]  [ 490/3750]  eta: 0:19:01  Lr: 0.001875  Loss: -0.1547  Acc@1: 81.2500 (80.0407)  Acc@5: 100.0000 (98.8926)  time: 0.3499  data: 0.0012  max mem: 2503
Train: Epoch[4/5]  [ 500/3750]  eta: 0:18:57  Lr: 0.001875  Loss: -0.7314  Acc@1: 75.0000 (79.9526)  Acc@5: 100.0000 (98.8648)  time: 0.3496  data: 0.0012  max mem: 2503
Train: Epoch[4/5]  [ 510/3750]  eta: 0:18:54  Lr: 0.001875  Loss: -0.3747  Acc@1: 75.0000 (80.0269)  Acc@5: 100.0000 (98.8625)  time: 0.3495  data: 0.0011  max mem: 2503
Train: Epoch[4/5]  [ 520/3750]  eta: 0:18:50  Lr: 0.001875  Loss: -0.5768  Acc@1: 81.2500 (79.9904)  Acc@5: 100.0000 (98.8604)  time: 0.3507  data: 0.0011  max mem: 2503
Train: Epoch[4/5]  [ 530/3750]  eta: 0:18:47  Lr: 0.001875  Loss: -0.9857  Acc@1: 81.2500 (79.9317)  Acc@5: 100.0000 (98.8583)  time: 0.3506  data: 0.0003  max mem: 2503
Train: Epoch[4/5]  [ 540/3750]  eta: 0:18:43  Lr: 0.001875  Loss: -0.3319  Acc@1: 81.2500 (79.9330)  Acc@5: 100.0000 (98.8794)  time: 0.3494  data: 0.0003  max mem: 2503
Train: Epoch[4/5]  [ 550/3750]  eta: 0:18:40  Lr: 0.001875  Loss: -0.8169  Acc@1: 81.2500 (79.9115)  Acc@5: 100.0000 (98.8770)  time: 0.3496  data: 0.0003  max mem: 2503
Train: Epoch[4/5]  [ 560/3750]  eta: 0:18:36  Lr: 0.001875  Loss: -0.8564  Acc@1: 81.2500 (79.9131)  Acc@5: 100.0000 (98.8748)  time: 0.3496  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [ 570/3750]  eta: 0:18:33  Lr: 0.001875  Loss: -0.7485  Acc@1: 75.0000 (79.8489)  Acc@5: 100.0000 (98.8835)  time: 0.3499  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [ 580/3750]  eta: 0:18:29  Lr: 0.001875  Loss: -0.5885  Acc@1: 75.0000 (79.7655)  Acc@5: 100.0000 (98.8597)  time: 0.3499  data: 0.0003  max mem: 2503
Train: Epoch[4/5]  [ 590/3750]  eta: 0:18:26  Lr: 0.001875  Loss: -0.6632  Acc@1: 75.0000 (79.7800)  Acc@5: 100.0000 (98.8579)  time: 0.3494  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [ 600/3750]  eta: 0:18:22  Lr: 0.001875  Loss: -0.9043  Acc@1: 81.2500 (79.7317)  Acc@5: 100.0000 (98.8561)  time: 0.3490  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [ 610/3750]  eta: 0:18:19  Lr: 0.001875  Loss: -0.4208  Acc@1: 81.2500 (79.7975)  Acc@5: 100.0000 (98.8543)  time: 0.3486  data: 0.0003  max mem: 2503
Train: Epoch[4/5]  [ 620/3750]  eta: 0:18:15  Lr: 0.001875  Loss: -0.9036  Acc@1: 81.2500 (79.7504)  Acc@5: 100.0000 (98.8527)  time: 0.3495  data: 0.0003  max mem: 2503
Train: Epoch[4/5]  [ 630/3750]  eta: 0:18:11  Lr: 0.001875  Loss: -0.8071  Acc@1: 75.0000 (79.6058)  Acc@5: 100.0000 (98.8609)  time: 0.3492  data: 0.0003  max mem: 2503
Train: Epoch[4/5]  [ 640/3750]  eta: 0:18:08  Lr: 0.001875  Loss: -0.7431  Acc@1: 75.0000 (79.6997)  Acc@5: 100.0000 (98.8787)  time: 0.3486  data: 0.0003  max mem: 2503
Train: Epoch[4/5]  [ 650/3750]  eta: 0:18:04  Lr: 0.001875  Loss: -0.7289  Acc@1: 81.2500 (79.6179)  Acc@5: 100.0000 (98.8863)  time: 0.3489  data: 0.0003  max mem: 2503
Train: Epoch[4/5]  [ 660/3750]  eta: 0:18:01  Lr: 0.001875  Loss: -0.6437  Acc@1: 81.2500 (79.7088)  Acc@5: 100.0000 (98.9032)  time: 0.3488  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [ 670/3750]  eta: 0:17:57  Lr: 0.001875  Loss: -0.4875  Acc@1: 75.0000 (79.5920)  Acc@5: 100.0000 (98.8823)  time: 0.3486  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [ 680/3750]  eta: 0:17:54  Lr: 0.001875  Loss: -0.4181  Acc@1: 75.0000 (79.5797)  Acc@5: 100.0000 (98.8803)  time: 0.3483  data: 0.0003  max mem: 2503
Train: Epoch[4/5]  [ 690/3750]  eta: 0:17:50  Lr: 0.001875  Loss: -0.2849  Acc@1: 81.2500 (79.5677)  Acc@5: 100.0000 (98.8694)  time: 0.3481  data: 0.0003  max mem: 2503
Train: Epoch[4/5]  [ 700/3750]  eta: 0:17:46  Lr: 0.001875  Loss: -0.7828  Acc@1: 81.2500 (79.6006)  Acc@5: 100.0000 (98.8766)  time: 0.3481  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [ 710/3750]  eta: 0:17:43  Lr: 0.001875  Loss: -0.8241  Acc@1: 87.5000 (79.6853)  Acc@5: 100.0000 (98.8924)  time: 0.3491  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [ 720/3750]  eta: 0:17:40  Lr: 0.001875  Loss: -0.4041  Acc@1: 81.2500 (79.6983)  Acc@5: 100.0000 (98.8904)  time: 0.3508  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [ 730/3750]  eta: 0:17:36  Lr: 0.001875  Loss: -0.8865  Acc@1: 87.5000 (79.8051)  Acc@5: 100.0000 (98.9056)  time: 0.3510  data: 0.0008  max mem: 2503
Train: Epoch[4/5]  [ 740/3750]  eta: 0:17:33  Lr: 0.001875  Loss: -0.9024  Acc@1: 81.2500 (79.7740)  Acc@5: 100.0000 (98.9035)  time: 0.3502  data: 0.0009  max mem: 2503
Train: Epoch[4/5]  [ 750/3750]  eta: 0:17:29  Lr: 0.001875  Loss: -0.7942  Acc@1: 81.2500 (79.8019)  Acc@5: 100.0000 (98.9181)  time: 0.3499  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [ 760/3750]  eta: 0:17:26  Lr: 0.001875  Loss: -0.9018  Acc@1: 81.2500 (79.8702)  Acc@5: 100.0000 (98.9241)  time: 0.3503  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [ 770/3750]  eta: 0:17:22  Lr: 0.001875  Loss: -0.9418  Acc@1: 87.5000 (79.9043)  Acc@5: 100.0000 (98.9137)  time: 0.3503  data: 0.0003  max mem: 2503
Train: Epoch[4/5]  [ 780/3750]  eta: 0:17:19  Lr: 0.001875  Loss: -0.8682  Acc@1: 81.2500 (79.9216)  Acc@5: 100.0000 (98.9117)  time: 0.3501  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [ 790/3750]  eta: 0:17:15  Lr: 0.001875  Loss: -0.6684  Acc@1: 87.5000 (79.9858)  Acc@5: 100.0000 (98.9175)  time: 0.3497  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [ 800/3750]  eta: 0:17:12  Lr: 0.001875  Loss: -0.4869  Acc@1: 81.2500 (79.9547)  Acc@5: 100.0000 (98.8920)  time: 0.3492  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [ 810/3750]  eta: 0:17:08  Lr: 0.001875  Loss: -0.5244  Acc@1: 81.2500 (79.9707)  Acc@5: 100.0000 (98.8903)  time: 0.3498  data: 0.0011  max mem: 2503
Train: Epoch[4/5]  [ 820/3750]  eta: 0:17:05  Lr: 0.001875  Loss: -0.7029  Acc@1: 81.2500 (79.9558)  Acc@5: 100.0000 (98.8886)  time: 0.3501  data: 0.0012  max mem: 2503
Train: Epoch[4/5]  [ 830/3750]  eta: 0:17:01  Lr: 0.001875  Loss: -1.0390  Acc@1: 81.2500 (80.0241)  Acc@5: 100.0000 (98.8944)  time: 0.3491  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [ 840/3750]  eta: 0:16:58  Lr: 0.001875  Loss: -0.5024  Acc@1: 81.2500 (79.9941)  Acc@5: 100.0000 (98.9001)  time: 0.3490  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [ 850/3750]  eta: 0:16:54  Lr: 0.001875  Loss: -1.0309  Acc@1: 81.2500 (79.9574)  Acc@5: 100.0000 (98.8910)  time: 0.3494  data: 0.0007  max mem: 2503
Train: Epoch[4/5]  [ 860/3750]  eta: 0:16:51  Lr: 0.001875  Loss: -0.9045  Acc@1: 81.2500 (79.9869)  Acc@5: 100.0000 (98.8966)  time: 0.3499  data: 0.0007  max mem: 2503
Train: Epoch[4/5]  [ 870/3750]  eta: 0:16:47  Lr: 0.001875  Loss: -0.5211  Acc@1: 81.2500 (80.0086)  Acc@5: 100.0000 (98.8949)  time: 0.3513  data: 0.0008  max mem: 2503
Train: Epoch[4/5]  [ 880/3750]  eta: 0:16:44  Lr: 0.001875  Loss: -0.8074  Acc@1: 81.2500 (80.0014)  Acc@5: 100.0000 (98.8862)  time: 0.3514  data: 0.0016  max mem: 2503
Train: Epoch[4/5]  [ 890/3750]  eta: 0:16:40  Lr: 0.001875  Loss: -0.6513  Acc@1: 75.0000 (79.9313)  Acc@5: 100.0000 (98.8987)  time: 0.3499  data: 0.0012  max mem: 2503
Train: Epoch[4/5]  [ 900/3750]  eta: 0:16:37  Lr: 0.001875  Loss: -0.5901  Acc@1: 75.0000 (79.9390)  Acc@5: 100.0000 (98.9109)  time: 0.3498  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [ 910/3750]  eta: 0:16:33  Lr: 0.001875  Loss: -1.1209  Acc@1: 75.0000 (79.9328)  Acc@5: 100.0000 (98.9092)  time: 0.3498  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [ 920/3750]  eta: 0:16:30  Lr: 0.001875  Loss: -0.5295  Acc@1: 75.0000 (79.9810)  Acc@5: 100.0000 (98.9142)  time: 0.3520  data: 0.0009  max mem: 2503
Train: Epoch[4/5]  [ 930/3750]  eta: 0:16:26  Lr: 0.001875  Loss: -0.5031  Acc@1: 81.2500 (79.9812)  Acc@5: 100.0000 (98.9125)  time: 0.3536  data: 0.0009  max mem: 2503
Train: Epoch[4/5]  [ 940/3750]  eta: 0:16:23  Lr: 0.001875  Loss: -1.0553  Acc@1: 75.0000 (79.9416)  Acc@5: 100.0000 (98.9107)  time: 0.3520  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [ 950/3750]  eta: 0:16:20  Lr: 0.001875  Loss: -0.5638  Acc@1: 75.0000 (79.9159)  Acc@5: 100.0000 (98.9090)  time: 0.3519  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [ 960/3750]  eta: 0:16:16  Lr: 0.001875  Loss: -0.9541  Acc@1: 75.0000 (79.9298)  Acc@5: 100.0000 (98.9074)  time: 0.3508  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [ 970/3750]  eta: 0:16:13  Lr: 0.001875  Loss: -0.7738  Acc@1: 81.2500 (80.0077)  Acc@5: 100.0000 (98.9186)  time: 0.3502  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [ 980/3750]  eta: 0:16:09  Lr: 0.001875  Loss: -0.5463  Acc@1: 87.5000 (80.0650)  Acc@5: 100.0000 (98.9169)  time: 0.3502  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [ 990/3750]  eta: 0:16:05  Lr: 0.001875  Loss: -0.9098  Acc@1: 87.5000 (80.1148)  Acc@5: 100.0000 (98.9152)  time: 0.3492  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [1000/3750]  eta: 0:16:02  Lr: 0.001875  Loss: -0.7238  Acc@1: 81.2500 (80.1011)  Acc@5: 100.0000 (98.9011)  time: 0.3493  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [1010/3750]  eta: 0:15:58  Lr: 0.001875  Loss: -0.9636  Acc@1: 75.0000 (80.1063)  Acc@5: 100.0000 (98.8996)  time: 0.3502  data: 0.0018  max mem: 2503
Train: Epoch[4/5]  [1020/3750]  eta: 0:15:55  Lr: 0.001875  Loss: -0.8261  Acc@1: 81.2500 (80.1359)  Acc@5: 100.0000 (98.9043)  time: 0.3510  data: 0.0017  max mem: 2503
Train: Epoch[4/5]  [1030/3750]  eta: 0:15:51  Lr: 0.001875  Loss: -0.8260  Acc@1: 81.2500 (80.1710)  Acc@5: 100.0000 (98.9028)  time: 0.3498  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [1040/3750]  eta: 0:15:48  Lr: 0.001875  Loss: -0.9101  Acc@1: 81.2500 (80.1633)  Acc@5: 100.0000 (98.9133)  time: 0.3487  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [1050/3750]  eta: 0:15:44  Lr: 0.001875  Loss: -0.6174  Acc@1: 81.2500 (80.1023)  Acc@5: 100.0000 (98.9236)  time: 0.3497  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [1060/3750]  eta: 0:15:41  Lr: 0.001875  Loss: -0.0871  Acc@1: 75.0000 (80.1072)  Acc@5: 100.0000 (98.9161)  time: 0.3497  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [1070/3750]  eta: 0:15:37  Lr: 0.001875  Loss: -0.7818  Acc@1: 81.2500 (80.1237)  Acc@5: 100.0000 (98.9262)  time: 0.3498  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [1080/3750]  eta: 0:15:34  Lr: 0.001875  Loss: -0.5062  Acc@1: 81.2500 (80.1226)  Acc@5: 100.0000 (98.9246)  time: 0.3505  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [1090/3750]  eta: 0:15:30  Lr: 0.001875  Loss: -1.0595  Acc@1: 87.5000 (80.1902)  Acc@5: 100.0000 (98.9173)  time: 0.3497  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [1100/3750]  eta: 0:15:27  Lr: 0.001875  Loss: -0.8599  Acc@1: 87.5000 (80.1998)  Acc@5: 100.0000 (98.9158)  time: 0.3496  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [1110/3750]  eta: 0:15:23  Lr: 0.001875  Loss: -0.4968  Acc@1: 75.0000 (80.2149)  Acc@5: 100.0000 (98.9030)  time: 0.3489  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [1120/3750]  eta: 0:15:20  Lr: 0.001875  Loss: -0.7007  Acc@1: 81.2500 (80.2576)  Acc@5: 100.0000 (98.9128)  time: 0.3487  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [1130/3750]  eta: 0:15:16  Lr: 0.001875  Loss: -0.8947  Acc@1: 81.2500 (80.2553)  Acc@5: 100.0000 (98.9114)  time: 0.3495  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [1140/3750]  eta: 0:15:13  Lr: 0.001875  Loss: -0.8412  Acc@1: 75.0000 (80.2147)  Acc@5: 100.0000 (98.9045)  time: 0.3497  data: 0.0006  max mem: 2503
Train: Epoch[4/5]  [1150/3750]  eta: 0:15:09  Lr: 0.001875  Loss: -0.8951  Acc@1: 81.2500 (80.2454)  Acc@5: 100.0000 (98.9086)  time: 0.3496  data: 0.0006  max mem: 2503
Train: Epoch[4/5]  [1160/3750]  eta: 0:15:06  Lr: 0.001875  Loss: -0.9300  Acc@1: 87.5000 (80.2810)  Acc@5: 100.0000 (98.9180)  time: 0.3506  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [1170/3750]  eta: 0:15:02  Lr: 0.001875  Loss: -0.9314  Acc@1: 81.2500 (80.3000)  Acc@5: 100.0000 (98.9219)  time: 0.3504  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [1180/3750]  eta: 0:14:59  Lr: 0.001875  Loss: -0.6591  Acc@1: 81.2500 (80.2868)  Acc@5: 100.0000 (98.9257)  time: 0.3490  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [1190/3750]  eta: 0:14:55  Lr: 0.001875  Loss: -0.7548  Acc@1: 75.0000 (80.2529)  Acc@5: 100.0000 (98.9347)  time: 0.3490  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [1200/3750]  eta: 0:14:52  Lr: 0.001875  Loss: -0.7241  Acc@1: 75.0000 (80.2248)  Acc@5: 100.0000 (98.9436)  time: 0.3491  data: 0.0006  max mem: 2503
Train: Epoch[4/5]  [1210/3750]  eta: 0:14:48  Lr: 0.001875  Loss: -0.5598  Acc@1: 75.0000 (80.2333)  Acc@5: 100.0000 (98.9213)  time: 0.3491  data: 0.0006  max mem: 2503
Train: Epoch[4/5]  [1220/3750]  eta: 0:14:45  Lr: 0.001875  Loss: -0.7009  Acc@1: 81.2500 (80.2621)  Acc@5: 100.0000 (98.9148)  time: 0.3498  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [1230/3750]  eta: 0:14:41  Lr: 0.001875  Loss: -0.7408  Acc@1: 81.2500 (80.2650)  Acc@5: 100.0000 (98.9135)  time: 0.3495  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [1240/3750]  eta: 0:14:38  Lr: 0.001875  Loss: -1.1383  Acc@1: 81.2500 (80.2881)  Acc@5: 100.0000 (98.9222)  time: 0.3494  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [1250/3750]  eta: 0:14:34  Lr: 0.001875  Loss: -0.5312  Acc@1: 81.2500 (80.2558)  Acc@5: 100.0000 (98.9209)  time: 0.3495  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [1260/3750]  eta: 0:14:31  Lr: 0.001875  Loss: -0.9577  Acc@1: 81.2500 (80.2587)  Acc@5: 100.0000 (98.9245)  time: 0.3486  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [1270/3750]  eta: 0:14:27  Lr: 0.001875  Loss: -0.7526  Acc@1: 81.2500 (80.2518)  Acc@5: 100.0000 (98.9133)  time: 0.3488  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [1280/3750]  eta: 0:14:24  Lr: 0.001875  Loss: -0.8486  Acc@1: 81.2500 (80.2693)  Acc@5: 100.0000 (98.9217)  time: 0.3487  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [1290/3750]  eta: 0:14:20  Lr: 0.001875  Loss: -0.4054  Acc@1: 81.2500 (80.2333)  Acc@5: 100.0000 (98.9253)  time: 0.3486  data: 0.0008  max mem: 2503
Train: Epoch[4/5]  [1300/3750]  eta: 0:14:17  Lr: 0.001875  Loss: -0.9237  Acc@1: 81.2500 (80.2460)  Acc@5: 100.0000 (98.9287)  time: 0.3491  data: 0.0008  max mem: 2503
Train: Epoch[4/5]  [1310/3750]  eta: 0:14:13  Lr: 0.001875  Loss: -0.8719  Acc@1: 81.2500 (80.2489)  Acc@5: 100.0000 (98.9321)  time: 0.3494  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [1320/3750]  eta: 0:14:10  Lr: 0.001875  Loss: -0.7513  Acc@1: 81.2500 (80.2659)  Acc@5: 100.0000 (98.9355)  time: 0.3502  data: 0.0008  max mem: 2503
Train: Epoch[4/5]  [1330/3750]  eta: 0:14:06  Lr: 0.001875  Loss: -0.7846  Acc@1: 81.2500 (80.2451)  Acc@5: 100.0000 (98.9341)  time: 0.3500  data: 0.0013  max mem: 2503
Train: Epoch[4/5]  [1340/3750]  eta: 0:14:03  Lr: 0.001875  Loss: -0.8445  Acc@1: 81.2500 (80.2293)  Acc@5: 100.0000 (98.9327)  time: 0.3502  data: 0.0014  max mem: 2503
Train: Epoch[4/5]  [1350/3750]  eta: 0:13:59  Lr: 0.001875  Loss: -0.9653  Acc@1: 81.2500 (80.2369)  Acc@5: 100.0000 (98.9406)  time: 0.3494  data: 0.0008  max mem: 2503
Train: Epoch[4/5]  [1360/3750]  eta: 0:13:56  Lr: 0.001875  Loss: -0.7923  Acc@1: 81.2500 (80.2581)  Acc@5: 100.0000 (98.9346)  time: 0.3479  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [1370/3750]  eta: 0:13:52  Lr: 0.001875  Loss: -0.7272  Acc@1: 75.0000 (80.2288)  Acc@5: 100.0000 (98.9241)  time: 0.3488  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [1380/3750]  eta: 0:13:49  Lr: 0.001875  Loss: -0.8880  Acc@1: 81.2500 (80.2453)  Acc@5: 100.0000 (98.9274)  time: 0.3495  data: 0.0007  max mem: 2503
Train: Epoch[4/5]  [1390/3750]  eta: 0:13:45  Lr: 0.001875  Loss: -0.8818  Acc@1: 81.2500 (80.2660)  Acc@5: 100.0000 (98.9216)  time: 0.3490  data: 0.0010  max mem: 2503
Train: Epoch[4/5]  [1400/3750]  eta: 0:13:42  Lr: 0.001875  Loss: -0.7801  Acc@1: 81.2500 (80.2730)  Acc@5: 100.0000 (98.9204)  time: 0.3484  data: 0.0007  max mem: 2503
Train: Epoch[4/5]  [1410/3750]  eta: 0:13:38  Lr: 0.001875  Loss: -0.8685  Acc@1: 81.2500 (80.2799)  Acc@5: 100.0000 (98.9192)  time: 0.3487  data: 0.0007  max mem: 2503
Train: Epoch[4/5]  [1420/3750]  eta: 0:13:35  Lr: 0.001875  Loss: -0.6608  Acc@1: 81.2500 (80.2604)  Acc@5: 100.0000 (98.9180)  time: 0.3479  data: 0.0007  max mem: 2503
Train: Epoch[4/5]  [1430/3750]  eta: 0:13:31  Lr: 0.001875  Loss: -0.2600  Acc@1: 81.2500 (80.2979)  Acc@5: 100.0000 (98.9168)  time: 0.3474  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [1440/3750]  eta: 0:13:27  Lr: 0.001875  Loss: -0.6418  Acc@1: 87.5000 (80.3305)  Acc@5: 100.0000 (98.9157)  time: 0.3485  data: 0.0007  max mem: 2503
Train: Epoch[4/5]  [1450/3750]  eta: 0:13:24  Lr: 0.001875  Loss: -0.7688  Acc@1: 75.0000 (80.3024)  Acc@5: 100.0000 (98.9145)  time: 0.3481  data: 0.0009  max mem: 2503
Train: Epoch[4/5]  [1460/3750]  eta: 0:13:20  Lr: 0.001875  Loss: -0.4885  Acc@1: 75.0000 (80.3003)  Acc@5: 100.0000 (98.9134)  time: 0.3493  data: 0.0006  max mem: 2503
Train: Epoch[4/5]  [1470/3750]  eta: 0:13:17  Lr: 0.001875  Loss: -0.9308  Acc@1: 75.0000 (80.2813)  Acc@5: 100.0000 (98.9038)  time: 0.3500  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [1480/3750]  eta: 0:13:13  Lr: 0.001875  Loss: -0.7933  Acc@1: 75.0000 (80.2583)  Acc@5: 100.0000 (98.9070)  time: 0.3494  data: 0.0013  max mem: 2503
Train: Epoch[4/5]  [1490/3750]  eta: 0:13:10  Lr: 0.001875  Loss: -0.7980  Acc@1: 75.0000 (80.2691)  Acc@5: 100.0000 (98.9059)  time: 0.3501  data: 0.0019  max mem: 2503
Train: Epoch[4/5]  [1500/3750]  eta: 0:13:06  Lr: 0.001875  Loss: -0.8316  Acc@1: 75.0000 (80.2715)  Acc@5: 100.0000 (98.9091)  time: 0.3497  data: 0.0017  max mem: 2503
Train: Epoch[4/5]  [1510/3750]  eta: 0:13:03  Lr: 0.001875  Loss: -0.9147  Acc@1: 87.5000 (80.3152)  Acc@5: 100.0000 (98.9163)  time: 0.3483  data: 0.0011  max mem: 2503
Train: Epoch[4/5]  [1520/3750]  eta: 0:12:59  Lr: 0.001875  Loss: -0.9017  Acc@1: 81.2500 (80.3090)  Acc@5: 100.0000 (98.9152)  time: 0.3490  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [1530/3750]  eta: 0:12:56  Lr: 0.001875  Loss: -0.7593  Acc@1: 81.2500 (80.3315)  Acc@5: 100.0000 (98.9182)  time: 0.3488  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [1540/3750]  eta: 0:12:52  Lr: 0.001875  Loss: -0.9767  Acc@1: 81.2500 (80.3618)  Acc@5: 100.0000 (98.9252)  time: 0.3474  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [1550/3750]  eta: 0:12:49  Lr: 0.001875  Loss: -0.9654  Acc@1: 81.2500 (80.3675)  Acc@5: 100.0000 (98.9321)  time: 0.3481  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [1560/3750]  eta: 0:12:45  Lr: 0.001875  Loss: -1.0794  Acc@1: 81.2500 (80.3972)  Acc@5: 100.0000 (98.9350)  time: 0.3484  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [1570/3750]  eta: 0:12:42  Lr: 0.001875  Loss: -1.1017  Acc@1: 87.5000 (80.4305)  Acc@5: 100.0000 (98.9338)  time: 0.3494  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [1580/3750]  eta: 0:12:38  Lr: 0.001875  Loss: -0.9450  Acc@1: 81.2500 (80.4317)  Acc@5: 100.0000 (98.9405)  time: 0.3498  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [1590/3750]  eta: 0:12:35  Lr: 0.001875  Loss: -0.8475  Acc@1: 81.2500 (80.4290)  Acc@5: 100.0000 (98.9393)  time: 0.3491  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [1600/3750]  eta: 0:12:31  Lr: 0.001875  Loss: -1.0167  Acc@1: 81.2500 (80.4536)  Acc@5: 100.0000 (98.9421)  time: 0.3490  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [1610/3750]  eta: 0:12:28  Lr: 0.001875  Loss: -0.7296  Acc@1: 81.2500 (80.4547)  Acc@5: 100.0000 (98.9448)  time: 0.3498  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [1620/3750]  eta: 0:12:24  Lr: 0.001875  Loss: -0.6160  Acc@1: 81.2500 (80.4480)  Acc@5: 100.0000 (98.9474)  time: 0.3504  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [1630/3750]  eta: 0:12:21  Lr: 0.001875  Loss: -0.6592  Acc@1: 81.2500 (80.4568)  Acc@5: 100.0000 (98.9462)  time: 0.3503  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [1640/3750]  eta: 0:12:17  Lr: 0.001875  Loss: -0.9930  Acc@1: 87.5000 (80.4883)  Acc@5: 100.0000 (98.9374)  time: 0.3497  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [1650/3750]  eta: 0:12:14  Lr: 0.001875  Loss: -0.7700  Acc@1: 87.5000 (80.4815)  Acc@5: 100.0000 (98.9438)  time: 0.3489  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [1660/3750]  eta: 0:12:10  Lr: 0.001875  Loss: -0.8979  Acc@1: 81.2500 (80.4711)  Acc@5: 100.0000 (98.9427)  time: 0.3495  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [1670/3750]  eta: 0:12:07  Lr: 0.001875  Loss: -0.9740  Acc@1: 81.2500 (80.4571)  Acc@5: 100.0000 (98.9490)  time: 0.3505  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [1680/3750]  eta: 0:12:03  Lr: 0.001875  Loss: -0.9820  Acc@1: 75.0000 (80.4581)  Acc@5: 100.0000 (98.9515)  time: 0.3504  data: 0.0006  max mem: 2503
Train: Epoch[4/5]  [1690/3750]  eta: 0:12:00  Lr: 0.001875  Loss: -0.5277  Acc@1: 81.2500 (80.4738)  Acc@5: 100.0000 (98.9466)  time: 0.3492  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [1700/3750]  eta: 0:11:56  Lr: 0.001875  Loss: -0.1987  Acc@1: 81.2500 (80.4674)  Acc@5: 100.0000 (98.9455)  time: 0.3492  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [1710/3750]  eta: 0:11:53  Lr: 0.001875  Loss: -0.9653  Acc@1: 75.0000 (80.4610)  Acc@5: 100.0000 (98.9480)  time: 0.3501  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [1720/3750]  eta: 0:11:49  Lr: 0.001875  Loss: -0.8227  Acc@1: 75.0000 (80.4656)  Acc@5: 100.0000 (98.9505)  time: 0.3500  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [1730/3750]  eta: 0:11:46  Lr: 0.001875  Loss: -0.6948  Acc@1: 81.2500 (80.4773)  Acc@5: 100.0000 (98.9457)  time: 0.3495  data: 0.0009  max mem: 2503
Train: Epoch[4/5]  [1740/3750]  eta: 0:11:42  Lr: 0.001875  Loss: -0.8327  Acc@1: 81.2500 (80.4746)  Acc@5: 100.0000 (98.9374)  time: 0.3493  data: 0.0008  max mem: 2503
Train: Epoch[4/5]  [1750/3750]  eta: 0:11:39  Lr: 0.001875  Loss: -0.8141  Acc@1: 81.2500 (80.4897)  Acc@5: 100.0000 (98.9363)  time: 0.3491  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [1760/3750]  eta: 0:11:35  Lr: 0.001875  Loss: -0.6766  Acc@1: 81.2500 (80.5011)  Acc@5: 100.0000 (98.9388)  time: 0.3497  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [1770/3750]  eta: 0:11:32  Lr: 0.001875  Loss: -1.0505  Acc@1: 81.2500 (80.5230)  Acc@5: 100.0000 (98.9377)  time: 0.3495  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [1780/3750]  eta: 0:11:28  Lr: 0.001875  Loss: -0.8494  Acc@1: 81.2500 (80.5236)  Acc@5: 100.0000 (98.9437)  time: 0.3500  data: 0.0012  max mem: 2503
Train: Epoch[4/5]  [1790/3750]  eta: 0:11:25  Lr: 0.001875  Loss: -0.6259  Acc@1: 81.2500 (80.5102)  Acc@5: 100.0000 (98.9426)  time: 0.3506  data: 0.0018  max mem: 2503
Train: Epoch[4/5]  [1800/3750]  eta: 0:11:21  Lr: 0.001875  Loss: -0.4112  Acc@1: 75.0000 (80.5039)  Acc@5: 100.0000 (98.9416)  time: 0.3495  data: 0.0010  max mem: 2503
Train: Epoch[4/5]  [1810/3750]  eta: 0:11:18  Lr: 0.001875  Loss: -0.6636  Acc@1: 81.2500 (80.5149)  Acc@5: 100.0000 (98.9405)  time: 0.3488  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [1820/3750]  eta: 0:11:14  Lr: 0.001875  Loss: -0.6840  Acc@1: 87.5000 (80.5361)  Acc@5: 100.0000 (98.9429)  time: 0.3495  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [1830/3750]  eta: 0:11:11  Lr: 0.001875  Loss: -0.3305  Acc@1: 81.2500 (80.5229)  Acc@5: 100.0000 (98.9418)  time: 0.3498  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [1840/3750]  eta: 0:11:07  Lr: 0.001875  Loss: -0.7918  Acc@1: 75.0000 (80.5269)  Acc@5: 100.0000 (98.9476)  time: 0.3493  data: 0.0006  max mem: 2503
Train: Epoch[4/5]  [1850/3750]  eta: 0:11:04  Lr: 0.001875  Loss: -1.1376  Acc@1: 81.2500 (80.5409)  Acc@5: 100.0000 (98.9533)  time: 0.3499  data: 0.0007  max mem: 2503
Train: Epoch[4/5]  [1860/3750]  eta: 0:11:00  Lr: 0.001875  Loss: -0.7538  Acc@1: 81.2500 (80.5481)  Acc@5: 100.0000 (98.9522)  time: 0.3504  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [1870/3750]  eta: 0:10:57  Lr: 0.001875  Loss: -0.6577  Acc@1: 81.2500 (80.5418)  Acc@5: 100.0000 (98.9511)  time: 0.3495  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [1880/3750]  eta: 0:10:53  Lr: 0.001875  Loss: -1.1271  Acc@1: 81.2500 (80.5489)  Acc@5: 100.0000 (98.9533)  time: 0.3482  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [1890/3750]  eta: 0:10:50  Lr: 0.001875  Loss: -0.5676  Acc@1: 81.2500 (80.5559)  Acc@5: 100.0000 (98.9556)  time: 0.3485  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [1900/3750]  eta: 0:10:46  Lr: 0.001875  Loss: -0.6554  Acc@1: 81.2500 (80.5497)  Acc@5: 100.0000 (98.9611)  time: 0.3503  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [1910/3750]  eta: 0:10:43  Lr: 0.001875  Loss: -0.9363  Acc@1: 81.2500 (80.5566)  Acc@5: 100.0000 (98.9534)  time: 0.3509  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [1920/3750]  eta: 0:10:39  Lr: 0.001875  Loss: -0.9688  Acc@1: 81.2500 (80.5635)  Acc@5: 100.0000 (98.9556)  time: 0.3502  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [1930/3750]  eta: 0:10:36  Lr: 0.001875  Loss: -0.2585  Acc@1: 81.2500 (80.5444)  Acc@5: 100.0000 (98.9610)  time: 0.3498  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [1940/3750]  eta: 0:10:32  Lr: 0.001875  Loss: -0.6508  Acc@1: 75.0000 (80.5545)  Acc@5: 100.0000 (98.9535)  time: 0.3495  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [1950/3750]  eta: 0:10:29  Lr: 0.001875  Loss: -1.0035  Acc@1: 81.2500 (80.5613)  Acc@5: 100.0000 (98.9557)  time: 0.3488  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [1960/3750]  eta: 0:10:25  Lr: 0.001875  Loss: -0.5161  Acc@1: 81.2500 (80.5648)  Acc@5: 100.0000 (98.9546)  time: 0.3499  data: 0.0012  max mem: 2503
Train: Epoch[4/5]  [1970/3750]  eta: 0:10:22  Lr: 0.001875  Loss: -0.5686  Acc@1: 81.2500 (80.5778)  Acc@5: 100.0000 (98.9599)  time: 0.3524  data: 0.0013  max mem: 2503
Train: Epoch[4/5]  [1980/3750]  eta: 0:10:18  Lr: 0.001875  Loss: -0.7762  Acc@1: 81.2500 (80.5875)  Acc@5: 100.0000 (98.9589)  time: 0.3510  data: 0.0006  max mem: 2503
Train: Epoch[4/5]  [1990/3750]  eta: 0:10:15  Lr: 0.001875  Loss: -0.5553  Acc@1: 87.5000 (80.6159)  Acc@5: 100.0000 (98.9609)  time: 0.3484  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [2000/3750]  eta: 0:10:12  Lr: 0.001875  Loss: -0.2352  Acc@1: 81.2500 (80.5691)  Acc@5: 100.0000 (98.9568)  time: 0.3498  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [2010/3750]  eta: 0:10:08  Lr: 0.001875  Loss: -0.6554  Acc@1: 75.0000 (80.5756)  Acc@5: 100.0000 (98.9557)  time: 0.3516  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [2020/3750]  eta: 0:10:05  Lr: 0.001875  Loss: -1.0545  Acc@1: 81.2500 (80.5789)  Acc@5: 100.0000 (98.9578)  time: 0.3510  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [2030/3750]  eta: 0:10:01  Lr: 0.001875  Loss: -0.9491  Acc@1: 81.2500 (80.6161)  Acc@5: 100.0000 (98.9599)  time: 0.3496  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [2040/3750]  eta: 0:09:58  Lr: 0.001875  Loss: -0.9665  Acc@1: 87.5000 (80.6406)  Acc@5: 100.0000 (98.9558)  time: 0.3491  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [2050/3750]  eta: 0:09:54  Lr: 0.001875  Loss: 0.0732  Acc@1: 87.5000 (80.6314)  Acc@5: 100.0000 (98.9578)  time: 0.3495  data: 0.0006  max mem: 2503
Train: Epoch[4/5]  [2060/3750]  eta: 0:09:51  Lr: 0.001875  Loss: -0.7111  Acc@1: 81.2500 (80.6283)  Acc@5: 100.0000 (98.9598)  time: 0.3511  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [2070/3750]  eta: 0:09:47  Lr: 0.001875  Loss: -0.9668  Acc@1: 81.2500 (80.6494)  Acc@5: 100.0000 (98.9619)  time: 0.3515  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [2080/3750]  eta: 0:09:44  Lr: 0.001875  Loss: -0.5177  Acc@1: 81.2500 (80.6523)  Acc@5: 100.0000 (98.9668)  time: 0.3504  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [2090/3750]  eta: 0:09:40  Lr: 0.001875  Loss: -0.4077  Acc@1: 81.2500 (80.6791)  Acc@5: 100.0000 (98.9688)  time: 0.3495  data: 0.0006  max mem: 2503
Train: Epoch[4/5]  [2100/3750]  eta: 0:09:37  Lr: 0.001875  Loss: -0.9395  Acc@1: 87.5000 (80.6759)  Acc@5: 100.0000 (98.9678)  time: 0.3496  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [2110/3750]  eta: 0:09:33  Lr: 0.001875  Loss: -0.7850  Acc@1: 75.0000 (80.6371)  Acc@5: 100.0000 (98.9667)  time: 0.3499  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [2120/3750]  eta: 0:09:30  Lr: 0.001875  Loss: -0.6703  Acc@1: 81.2500 (80.6400)  Acc@5: 100.0000 (98.9569)  time: 0.3497  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [2130/3750]  eta: 0:09:26  Lr: 0.001875  Loss: -0.7668  Acc@1: 81.2500 (80.6400)  Acc@5: 100.0000 (98.9559)  time: 0.3496  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [2140/3750]  eta: 0:09:23  Lr: 0.001875  Loss: -0.6373  Acc@1: 81.2500 (80.6545)  Acc@5: 100.0000 (98.9608)  time: 0.3496  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [2150/3750]  eta: 0:09:19  Lr: 0.001875  Loss: -0.8193  Acc@1: 81.2500 (80.6340)  Acc@5: 100.0000 (98.9598)  time: 0.3505  data: 0.0013  max mem: 2503
Train: Epoch[4/5]  [2160/3750]  eta: 0:09:16  Lr: 0.001875  Loss: -0.4641  Acc@1: 81.2500 (80.6455)  Acc@5: 100.0000 (98.9588)  time: 0.3516  data: 0.0019  max mem: 2503
Train: Epoch[4/5]  [2170/3750]  eta: 0:09:12  Lr: 0.001875  Loss: -0.7764  Acc@1: 81.2500 (80.6454)  Acc@5: 100.0000 (98.9579)  time: 0.3515  data: 0.0011  max mem: 2503
Train: Epoch[4/5]  [2180/3750]  eta: 0:09:09  Lr: 0.001875  Loss: -0.7361  Acc@1: 81.2500 (80.6539)  Acc@5: 100.0000 (98.9598)  time: 0.3507  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [2190/3750]  eta: 0:09:05  Lr: 0.001875  Loss: -1.0229  Acc@1: 81.2500 (80.6595)  Acc@5: 100.0000 (98.9588)  time: 0.3506  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [2200/3750]  eta: 0:09:02  Lr: 0.001875  Loss: -0.8323  Acc@1: 81.2500 (80.6423)  Acc@5: 100.0000 (98.9607)  time: 0.3521  data: 0.0010  max mem: 2503
Train: Epoch[4/5]  [2210/3750]  eta: 0:08:58  Lr: 0.001875  Loss: -0.5584  Acc@1: 81.2500 (80.6366)  Acc@5: 100.0000 (98.9597)  time: 0.3514  data: 0.0011  max mem: 2503
Train: Epoch[4/5]  [2220/3750]  eta: 0:08:55  Lr: 0.001875  Loss: -0.8098  Acc@1: 81.2500 (80.6281)  Acc@5: 100.0000 (98.9616)  time: 0.3501  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [2230/3750]  eta: 0:08:51  Lr: 0.001875  Loss: -0.9747  Acc@1: 81.2500 (80.6421)  Acc@5: 100.0000 (98.9635)  time: 0.3510  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [2240/3750]  eta: 0:08:48  Lr: 0.001875  Loss: -0.8402  Acc@1: 81.2500 (80.6448)  Acc@5: 100.0000 (98.9653)  time: 0.3505  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [2250/3750]  eta: 0:08:44  Lr: 0.001875  Loss: -0.6452  Acc@1: 81.2500 (80.6503)  Acc@5: 100.0000 (98.9699)  time: 0.3502  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [2260/3750]  eta: 0:08:41  Lr: 0.001875  Loss: -0.3280  Acc@1: 81.2500 (80.6612)  Acc@5: 100.0000 (98.9717)  time: 0.3504  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [2270/3750]  eta: 0:08:37  Lr: 0.001875  Loss: -1.1130  Acc@1: 81.2500 (80.6721)  Acc@5: 100.0000 (98.9735)  time: 0.3509  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [2280/3750]  eta: 0:08:34  Lr: 0.001875  Loss: -0.6271  Acc@1: 81.2500 (80.6636)  Acc@5: 100.0000 (98.9752)  time: 0.3508  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [2290/3750]  eta: 0:08:30  Lr: 0.001875  Loss: -0.5788  Acc@1: 75.0000 (80.6553)  Acc@5: 100.0000 (98.9742)  time: 0.3502  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [2300/3750]  eta: 0:08:27  Lr: 0.001875  Loss: -0.7396  Acc@1: 81.2500 (80.6524)  Acc@5: 100.0000 (98.9678)  time: 0.3504  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [2310/3750]  eta: 0:08:23  Lr: 0.001875  Loss: -0.6724  Acc@1: 81.2500 (80.6550)  Acc@5: 100.0000 (98.9696)  time: 0.3501  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [2320/3750]  eta: 0:08:20  Lr: 0.001875  Loss: -0.6951  Acc@1: 81.2500 (80.6630)  Acc@5: 100.0000 (98.9713)  time: 0.3492  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [2330/3750]  eta: 0:08:16  Lr: 0.001875  Loss: -0.8387  Acc@1: 81.2500 (80.6574)  Acc@5: 100.0000 (98.9704)  time: 0.3505  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [2340/3750]  eta: 0:08:13  Lr: 0.001875  Loss: -0.9858  Acc@1: 81.2500 (80.6466)  Acc@5: 100.0000 (98.9695)  time: 0.3511  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [2350/3750]  eta: 0:08:09  Lr: 0.001875  Loss: -0.2429  Acc@1: 75.0000 (80.5934)  Acc@5: 100.0000 (98.9685)  time: 0.3498  data: 0.0007  max mem: 2503
Train: Epoch[4/5]  [2360/3750]  eta: 0:08:06  Lr: 0.001875  Loss: -1.0278  Acc@1: 68.7500 (80.5750)  Acc@5: 100.0000 (98.9570)  time: 0.3501  data: 0.0006  max mem: 2503
Train: Epoch[4/5]  [2370/3750]  eta: 0:08:02  Lr: 0.001875  Loss: -0.8886  Acc@1: 87.5000 (80.6200)  Acc@5: 100.0000 (98.9588)  time: 0.3497  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [2380/3750]  eta: 0:07:59  Lr: 0.001875  Loss: -0.6000  Acc@1: 87.5000 (80.6069)  Acc@5: 100.0000 (98.9631)  time: 0.3492  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [2390/3750]  eta: 0:07:55  Lr: 0.001875  Loss: -0.9924  Acc@1: 75.0000 (80.5782)  Acc@5: 100.0000 (98.9649)  time: 0.3517  data: 0.0025  max mem: 2503
Train: Epoch[4/5]  [2400/3750]  eta: 0:07:52  Lr: 0.001875  Loss: -0.4938  Acc@1: 81.2500 (80.5914)  Acc@5: 100.0000 (98.9640)  time: 0.3520  data: 0.0025  max mem: 2503
Train: Epoch[4/5]  [2410/3750]  eta: 0:07:48  Lr: 0.001875  Loss: -1.0951  Acc@1: 81.2500 (80.5890)  Acc@5: 100.0000 (98.9657)  time: 0.3501  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [2420/3750]  eta: 0:07:45  Lr: 0.001875  Loss: -0.8616  Acc@1: 81.2500 (80.5814)  Acc@5: 100.0000 (98.9674)  time: 0.3496  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [2430/3750]  eta: 0:07:41  Lr: 0.001875  Loss: -1.1640  Acc@1: 87.5000 (80.6021)  Acc@5: 100.0000 (98.9665)  time: 0.3502  data: 0.0011  max mem: 2503
Train: Epoch[4/5]  [2440/3750]  eta: 0:07:38  Lr: 0.001875  Loss: -0.9026  Acc@1: 87.5000 (80.6125)  Acc@5: 100.0000 (98.9605)  time: 0.3503  data: 0.0012  max mem: 2503
Train: Epoch[4/5]  [2450/3750]  eta: 0:07:34  Lr: 0.001875  Loss: -0.8791  Acc@1: 87.5000 (80.6304)  Acc@5: 100.0000 (98.9596)  time: 0.3496  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [2460/3750]  eta: 0:07:31  Lr: 0.001875  Loss: -0.4643  Acc@1: 81.2500 (80.6303)  Acc@5: 100.0000 (98.9588)  time: 0.3493  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [2470/3750]  eta: 0:07:27  Lr: 0.001875  Loss: -0.7796  Acc@1: 81.2500 (80.6480)  Acc@5: 100.0000 (98.9604)  time: 0.3494  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [2480/3750]  eta: 0:07:24  Lr: 0.001875  Loss: -0.6384  Acc@1: 81.2500 (80.6429)  Acc@5: 100.0000 (98.9571)  time: 0.3499  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [2490/3750]  eta: 0:07:20  Lr: 0.001875  Loss: -0.7796  Acc@1: 81.2500 (80.6303)  Acc@5: 100.0000 (98.9562)  time: 0.3502  data: 0.0008  max mem: 2503
Train: Epoch[4/5]  [2500/3750]  eta: 0:07:17  Lr: 0.001875  Loss: -0.9561  Acc@1: 81.2500 (80.6477)  Acc@5: 100.0000 (98.9579)  time: 0.3514  data: 0.0010  max mem: 2503
Train: Epoch[4/5]  [2510/3750]  eta: 0:07:13  Lr: 0.001875  Loss: -0.8053  Acc@1: 81.2500 (80.6302)  Acc@5: 100.0000 (98.9571)  time: 0.3516  data: 0.0007  max mem: 2503
Train: Epoch[4/5]  [2520/3750]  eta: 0:07:10  Lr: 0.001875  Loss: -1.0870  Acc@1: 75.0000 (80.6203)  Acc@5: 100.0000 (98.9563)  time: 0.3503  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [2530/3750]  eta: 0:07:06  Lr: 0.001875  Loss: -0.1835  Acc@1: 81.2500 (80.6228)  Acc@5: 100.0000 (98.9579)  time: 0.3506  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [2540/3750]  eta: 0:07:03  Lr: 0.001875  Loss: -0.6252  Acc@1: 81.2500 (80.6203)  Acc@5: 100.0000 (98.9571)  time: 0.3511  data: 0.0006  max mem: 2503
Train: Epoch[4/5]  [2550/3750]  eta: 0:06:59  Lr: 0.001875  Loss: -0.9851  Acc@1: 81.2500 (80.6203)  Acc@5: 100.0000 (98.9538)  time: 0.3510  data: 0.0006  max mem: 2503
Train: Epoch[4/5]  [2560/3750]  eta: 0:06:56  Lr: 0.001875  Loss: -0.7451  Acc@1: 81.2500 (80.6106)  Acc@5: 100.0000 (98.9579)  time: 0.3506  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [2570/3750]  eta: 0:06:52  Lr: 0.001875  Loss: -1.0453  Acc@1: 81.2500 (80.6131)  Acc@5: 100.0000 (98.9620)  time: 0.3503  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [2580/3750]  eta: 0:06:49  Lr: 0.001875  Loss: -1.0150  Acc@1: 81.2500 (80.5986)  Acc@5: 100.0000 (98.9636)  time: 0.3506  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [2590/3750]  eta: 0:06:45  Lr: 0.001875  Loss: -0.7398  Acc@1: 81.2500 (80.5794)  Acc@5: 100.0000 (98.9628)  time: 0.3494  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [2600/3750]  eta: 0:06:42  Lr: 0.001875  Loss: -0.8976  Acc@1: 81.2500 (80.5820)  Acc@5: 100.0000 (98.9643)  time: 0.3488  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [2610/3750]  eta: 0:06:38  Lr: 0.001875  Loss: -0.8381  Acc@1: 81.2500 (80.5941)  Acc@5: 100.0000 (98.9659)  time: 0.3495  data: 0.0003  max mem: 2503
Train: Epoch[4/5]  [2620/3750]  eta: 0:06:35  Lr: 0.001875  Loss: -0.5917  Acc@1: 81.2500 (80.5775)  Acc@5: 100.0000 (98.9603)  time: 0.3489  data: 0.0003  max mem: 2503
Train: Epoch[4/5]  [2630/3750]  eta: 0:06:31  Lr: 0.001875  Loss: -0.5152  Acc@1: 81.2500 (80.5825)  Acc@5: 100.0000 (98.9571)  time: 0.3481  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [2640/3750]  eta: 0:06:28  Lr: 0.001875  Loss: -0.7038  Acc@1: 81.2500 (80.5945)  Acc@5: 100.0000 (98.9564)  time: 0.3483  data: 0.0006  max mem: 2503
Train: Epoch[4/5]  [2650/3750]  eta: 0:06:24  Lr: 0.001875  Loss: -0.9832  Acc@1: 81.2500 (80.5946)  Acc@5: 100.0000 (98.9579)  time: 0.3485  data: 0.0006  max mem: 2503
Train: Epoch[4/5]  [2660/3750]  eta: 0:06:21  Lr: 0.001875  Loss: -1.0206  Acc@1: 87.5000 (80.6135)  Acc@5: 100.0000 (98.9619)  time: 0.3485  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [2670/3750]  eta: 0:06:17  Lr: 0.001875  Loss: -0.9129  Acc@1: 81.2500 (80.6042)  Acc@5: 100.0000 (98.9540)  time: 0.3481  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [2680/3750]  eta: 0:06:14  Lr: 0.001875  Loss: -0.6801  Acc@1: 75.0000 (80.6043)  Acc@5: 100.0000 (98.9556)  time: 0.3481  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [2690/3750]  eta: 0:06:10  Lr: 0.001875  Loss: -0.9261  Acc@1: 75.0000 (80.5904)  Acc@5: 100.0000 (98.9595)  time: 0.3492  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [2700/3750]  eta: 0:06:07  Lr: 0.001875  Loss: -0.8712  Acc@1: 75.0000 (80.5928)  Acc@5: 100.0000 (98.9564)  time: 0.3505  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [2710/3750]  eta: 0:06:03  Lr: 0.001875  Loss: -0.6334  Acc@1: 81.2500 (80.6022)  Acc@5: 100.0000 (98.9579)  time: 0.3498  data: 0.0009  max mem: 2503
Train: Epoch[4/5]  [2720/3750]  eta: 0:06:00  Lr: 0.001875  Loss: -0.6263  Acc@1: 81.2500 (80.5954)  Acc@5: 100.0000 (98.9526)  time: 0.3485  data: 0.0008  max mem: 2503
Train: Epoch[4/5]  [2730/3750]  eta: 0:05:56  Lr: 0.001875  Loss: -0.7314  Acc@1: 81.2500 (80.6092)  Acc@5: 100.0000 (98.9541)  time: 0.3496  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [2740/3750]  eta: 0:05:53  Lr: 0.001875  Loss: -0.6357  Acc@1: 81.2500 (80.6115)  Acc@5: 100.0000 (98.9557)  time: 0.3498  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [2750/3750]  eta: 0:05:49  Lr: 0.001875  Loss: -0.8865  Acc@1: 81.2500 (80.6139)  Acc@5: 100.0000 (98.9504)  time: 0.3483  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [2760/3750]  eta: 0:05:46  Lr: 0.001875  Loss: -0.4876  Acc@1: 81.2500 (80.6094)  Acc@5: 100.0000 (98.9519)  time: 0.3479  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [2770/3750]  eta: 0:05:42  Lr: 0.001875  Loss: -0.8813  Acc@1: 81.2500 (80.6297)  Acc@5: 100.0000 (98.9512)  time: 0.3483  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [2780/3750]  eta: 0:05:39  Lr: 0.001875  Loss: -1.0831  Acc@1: 87.5000 (80.6297)  Acc@5: 100.0000 (98.9505)  time: 0.3480  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [2790/3750]  eta: 0:05:35  Lr: 0.001875  Loss: -0.9492  Acc@1: 81.2500 (80.6275)  Acc@5: 100.0000 (98.9542)  time: 0.3478  data: 0.0003  max mem: 2503
Train: Epoch[4/5]  [2800/3750]  eta: 0:05:32  Lr: 0.001875  Loss: -0.8651  Acc@1: 81.2500 (80.6275)  Acc@5: 100.0000 (98.9513)  time: 0.3483  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [2810/3750]  eta: 0:05:28  Lr: 0.001875  Loss: -0.9957  Acc@1: 81.2500 (80.6519)  Acc@5: 100.0000 (98.9550)  time: 0.3492  data: 0.0006  max mem: 2503
Train: Epoch[4/5]  [2820/3750]  eta: 0:05:25  Lr: 0.001875  Loss: -0.8963  Acc@1: 81.2500 (80.6452)  Acc@5: 100.0000 (98.9543)  time: 0.3495  data: 0.0007  max mem: 2503
Train: Epoch[4/5]  [2830/3750]  eta: 0:05:21  Lr: 0.001875  Loss: -0.5596  Acc@1: 75.0000 (80.6385)  Acc@5: 100.0000 (98.9535)  time: 0.3483  data: 0.0008  max mem: 2503
Train: Epoch[4/5]  [2840/3750]  eta: 0:05:18  Lr: 0.001875  Loss: -0.7491  Acc@1: 81.2500 (80.6406)  Acc@5: 100.0000 (98.9484)  time: 0.3480  data: 0.0006  max mem: 2503
Train: Epoch[4/5]  [2850/3750]  eta: 0:05:14  Lr: 0.001875  Loss: -0.7002  Acc@1: 81.2500 (80.6537)  Acc@5: 100.0000 (98.9521)  time: 0.3479  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [2860/3750]  eta: 0:05:11  Lr: 0.001875  Loss: -0.9677  Acc@1: 81.2500 (80.6536)  Acc@5: 100.0000 (98.9536)  time: 0.3480  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [2870/3750]  eta: 0:05:07  Lr: 0.001875  Loss: -0.5850  Acc@1: 87.5000 (80.6753)  Acc@5: 100.0000 (98.9572)  time: 0.3482  data: 0.0003  max mem: 2503
Train: Epoch[4/5]  [2880/3750]  eta: 0:05:04  Lr: 0.001875  Loss: -0.9451  Acc@1: 81.2500 (80.6751)  Acc@5: 100.0000 (98.9544)  time: 0.3482  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [2890/3750]  eta: 0:05:00  Lr: 0.001875  Loss: -0.7413  Acc@1: 81.2500 (80.6749)  Acc@5: 100.0000 (98.9536)  time: 0.3480  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [2900/3750]  eta: 0:04:57  Lr: 0.001875  Loss: -0.9338  Acc@1: 81.2500 (80.6791)  Acc@5: 100.0000 (98.9551)  time: 0.3482  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [2910/3750]  eta: 0:04:53  Lr: 0.001875  Loss: -0.8682  Acc@1: 81.2500 (80.6875)  Acc@5: 100.0000 (98.9587)  time: 0.3490  data: 0.0003  max mem: 2503
Train: Epoch[4/5]  [2920/3750]  eta: 0:04:50  Lr: 0.001875  Loss: -0.7126  Acc@1: 81.2500 (80.7022)  Acc@5: 100.0000 (98.9623)  time: 0.3483  data: 0.0003  max mem: 2503
Train: Epoch[4/5]  [2930/3750]  eta: 0:04:46  Lr: 0.001875  Loss: -0.3865  Acc@1: 87.5000 (80.7084)  Acc@5: 100.0000 (98.9658)  time: 0.3477  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [2940/3750]  eta: 0:04:43  Lr: 0.001875  Loss: -0.9689  Acc@1: 81.2500 (80.7038)  Acc@5: 100.0000 (98.9651)  time: 0.3488  data: 0.0012  max mem: 2503
Train: Epoch[4/5]  [2950/3750]  eta: 0:04:39  Lr: 0.001875  Loss: -0.8506  Acc@1: 81.2500 (80.7099)  Acc@5: 100.0000 (98.9643)  time: 0.3492  data: 0.0012  max mem: 2503
Train: Epoch[4/5]  [2960/3750]  eta: 0:04:36  Lr: 0.001875  Loss: -1.0570  Acc@1: 81.2500 (80.7139)  Acc@5: 100.0000 (98.9615)  time: 0.3482  data: 0.0003  max mem: 2503
Train: Epoch[4/5]  [2970/3750]  eta: 0:04:32  Lr: 0.001875  Loss: -0.8333  Acc@1: 81.2500 (80.7220)  Acc@5: 100.0000 (98.9650)  time: 0.3482  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [2980/3750]  eta: 0:04:29  Lr: 0.001875  Loss: -0.2716  Acc@1: 75.0000 (80.7154)  Acc@5: 100.0000 (98.9685)  time: 0.3487  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [2990/3750]  eta: 0:04:25  Lr: 0.001875  Loss: -0.9812  Acc@1: 81.2500 (80.7339)  Acc@5: 100.0000 (98.9719)  time: 0.3492  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [3000/3750]  eta: 0:04:22  Lr: 0.001875  Loss: -0.8671  Acc@1: 87.5000 (80.7585)  Acc@5: 100.0000 (98.9733)  time: 0.3491  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [3010/3750]  eta: 0:04:18  Lr: 0.001875  Loss: -0.4584  Acc@1: 87.5000 (80.7539)  Acc@5: 100.0000 (98.9767)  time: 0.3488  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [3020/3750]  eta: 0:04:15  Lr: 0.001875  Loss: -0.7878  Acc@1: 81.2500 (80.7535)  Acc@5: 100.0000 (98.9738)  time: 0.3494  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [3030/3750]  eta: 0:04:11  Lr: 0.001875  Loss: -0.7305  Acc@1: 75.0000 (80.7427)  Acc@5: 100.0000 (98.9710)  time: 0.3499  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [3040/3750]  eta: 0:04:08  Lr: 0.001875  Loss: -0.7922  Acc@1: 75.0000 (80.7403)  Acc@5: 100.0000 (98.9703)  time: 0.3501  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [3050/3750]  eta: 0:04:04  Lr: 0.001875  Loss: -0.4935  Acc@1: 75.0000 (80.7153)  Acc@5: 100.0000 (98.9635)  time: 0.3506  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [3060/3750]  eta: 0:04:01  Lr: 0.001875  Loss: -0.7472  Acc@1: 75.0000 (80.7089)  Acc@5: 100.0000 (98.9607)  time: 0.3510  data: 0.0012  max mem: 2503
Train: Epoch[4/5]  [3070/3750]  eta: 0:03:57  Lr: 0.001875  Loss: -1.0209  Acc@1: 75.0000 (80.6964)  Acc@5: 100.0000 (98.9641)  time: 0.3503  data: 0.0012  max mem: 2503
Train: Epoch[4/5]  [3080/3750]  eta: 0:03:54  Lr: 0.001875  Loss: -0.9964  Acc@1: 81.2500 (80.7043)  Acc@5: 100.0000 (98.9614)  time: 0.3492  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [3090/3750]  eta: 0:03:50  Lr: 0.001875  Loss: -0.5468  Acc@1: 81.2500 (80.7020)  Acc@5: 100.0000 (98.9607)  time: 0.3489  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [3100/3750]  eta: 0:03:47  Lr: 0.001875  Loss: -0.6921  Acc@1: 81.2500 (80.7099)  Acc@5: 100.0000 (98.9620)  time: 0.3486  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [3110/3750]  eta: 0:03:43  Lr: 0.001875  Loss: -0.8111  Acc@1: 81.2500 (80.7096)  Acc@5: 100.0000 (98.9654)  time: 0.3488  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [3120/3750]  eta: 0:03:40  Lr: 0.001875  Loss: -0.9135  Acc@1: 81.2500 (80.7133)  Acc@5: 100.0000 (98.9647)  time: 0.3493  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [3130/3750]  eta: 0:03:36  Lr: 0.001875  Loss: -0.8971  Acc@1: 81.2500 (80.7090)  Acc@5: 100.0000 (98.9680)  time: 0.3489  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [3140/3750]  eta: 0:03:33  Lr: 0.001875  Loss: -0.5090  Acc@1: 81.2500 (80.7167)  Acc@5: 100.0000 (98.9673)  time: 0.3483  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [3150/3750]  eta: 0:03:29  Lr: 0.001875  Loss: -0.9539  Acc@1: 75.0000 (80.7065)  Acc@5: 100.0000 (98.9646)  time: 0.3488  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [3160/3750]  eta: 0:03:26  Lr: 0.001875  Loss: -0.9347  Acc@1: 75.0000 (80.7063)  Acc@5: 100.0000 (98.9620)  time: 0.3485  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [3170/3750]  eta: 0:03:22  Lr: 0.001875  Loss: -0.8947  Acc@1: 81.2500 (80.6922)  Acc@5: 100.0000 (98.9633)  time: 0.3485  data: 0.0006  max mem: 2503
Train: Epoch[4/5]  [3180/3750]  eta: 0:03:19  Lr: 0.001875  Loss: -0.9510  Acc@1: 81.2500 (80.6920)  Acc@5: 100.0000 (98.9646)  time: 0.3496  data: 0.0009  max mem: 2503
Train: Epoch[4/5]  [3190/3750]  eta: 0:03:15  Lr: 0.001875  Loss: -0.1348  Acc@1: 81.2500 (80.6977)  Acc@5: 100.0000 (98.9658)  time: 0.3492  data: 0.0007  max mem: 2503
Train: Epoch[4/5]  [3200/3750]  eta: 0:03:12  Lr: 0.001875  Loss: -0.8571  Acc@1: 81.2500 (80.6877)  Acc@5: 100.0000 (98.9613)  time: 0.3484  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [3210/3750]  eta: 0:03:08  Lr: 0.001875  Loss: -0.9354  Acc@1: 81.2500 (80.7147)  Acc@5: 100.0000 (98.9626)  time: 0.3477  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [3220/3750]  eta: 0:03:05  Lr: 0.001875  Loss: -0.6649  Acc@1: 87.5000 (80.7125)  Acc@5: 100.0000 (98.9638)  time: 0.3480  data: 0.0003  max mem: 2503
Train: Epoch[4/5]  [3230/3750]  eta: 0:03:01  Lr: 0.001875  Loss: -0.6565  Acc@1: 81.2500 (80.7297)  Acc@5: 100.0000 (98.9632)  time: 0.3481  data: 0.0003  max mem: 2503
Train: Epoch[4/5]  [3240/3750]  eta: 0:02:58  Lr: 0.001875  Loss: -0.6457  Acc@1: 87.5000 (80.7313)  Acc@5: 100.0000 (98.9625)  time: 0.3474  data: 0.0003  max mem: 2503
Train: Epoch[4/5]  [3250/3750]  eta: 0:02:54  Lr: 0.001875  Loss: -0.2072  Acc@1: 87.5000 (80.7367)  Acc@5: 100.0000 (98.9599)  time: 0.3472  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [3260/3750]  eta: 0:02:51  Lr: 0.001875  Loss: -1.0256  Acc@1: 87.5000 (80.7364)  Acc@5: 100.0000 (98.9612)  time: 0.3480  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [3270/3750]  eta: 0:02:47  Lr: 0.001875  Loss: -0.7188  Acc@1: 87.5000 (80.7437)  Acc@5: 100.0000 (98.9644)  time: 0.3486  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [3280/3750]  eta: 0:02:44  Lr: 0.001875  Loss: -0.8325  Acc@1: 81.2500 (80.7433)  Acc@5: 100.0000 (98.9618)  time: 0.3483  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [3290/3750]  eta: 0:02:40  Lr: 0.001875  Loss: -0.9098  Acc@1: 81.2500 (80.7410)  Acc@5: 100.0000 (98.9593)  time: 0.3491  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [3300/3750]  eta: 0:02:37  Lr: 0.001875  Loss: -0.9535  Acc@1: 81.2500 (80.7539)  Acc@5: 100.0000 (98.9586)  time: 0.3496  data: 0.0006  max mem: 2503
Train: Epoch[4/5]  [3310/3750]  eta: 0:02:33  Lr: 0.001875  Loss: -0.6228  Acc@1: 81.2500 (80.7479)  Acc@5: 100.0000 (98.9599)  time: 0.3492  data: 0.0006  max mem: 2503
Train: Epoch[4/5]  [3320/3750]  eta: 0:02:30  Lr: 0.001875  Loss: -0.1976  Acc@1: 75.0000 (80.7494)  Acc@5: 100.0000 (98.9630)  time: 0.3498  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [3330/3750]  eta: 0:02:26  Lr: 0.001875  Loss: -0.7584  Acc@1: 75.0000 (80.7547)  Acc@5: 100.0000 (98.9605)  time: 0.3496  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [3340/3750]  eta: 0:02:23  Lr: 0.001875  Loss: -0.5876  Acc@1: 87.5000 (80.7580)  Acc@5: 100.0000 (98.9599)  time: 0.3490  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [3350/3750]  eta: 0:02:19  Lr: 0.001875  Loss: -0.8212  Acc@1: 81.2500 (80.7576)  Acc@5: 100.0000 (98.9574)  time: 0.3495  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [3360/3750]  eta: 0:02:16  Lr: 0.001875  Loss: -0.3469  Acc@1: 81.2500 (80.7609)  Acc@5: 100.0000 (98.9568)  time: 0.3499  data: 0.0008  max mem: 2503
Train: Epoch[4/5]  [3370/3750]  eta: 0:02:12  Lr: 0.001875  Loss: -0.5205  Acc@1: 81.2500 (80.7531)  Acc@5: 100.0000 (98.9599)  time: 0.3496  data: 0.0008  max mem: 2503
Train: Epoch[4/5]  [3380/3750]  eta: 0:02:09  Lr: 0.001875  Loss: -0.7578  Acc@1: 81.2500 (80.7472)  Acc@5: 100.0000 (98.9611)  time: 0.3490  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [3390/3750]  eta: 0:02:05  Lr: 0.001875  Loss: 0.1965  Acc@1: 81.2500 (80.7302)  Acc@5: 100.0000 (98.9568)  time: 0.3489  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [3400/3750]  eta: 0:02:02  Lr: 0.001875  Loss: -0.4748  Acc@1: 81.2500 (80.7299)  Acc@5: 100.0000 (98.9544)  time: 0.3494  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [3410/3750]  eta: 0:01:58  Lr: 0.001875  Loss: -1.0256  Acc@1: 87.5000 (80.7388)  Acc@5: 100.0000 (98.9574)  time: 0.3502  data: 0.0012  max mem: 2503
Train: Epoch[4/5]  [3420/3750]  eta: 0:01:55  Lr: 0.001875  Loss: -0.0366  Acc@1: 81.2500 (80.7348)  Acc@5: 100.0000 (98.9586)  time: 0.3505  data: 0.0013  max mem: 2503
Train: Epoch[4/5]  [3430/3750]  eta: 0:01:51  Lr: 0.001875  Loss: -0.8423  Acc@1: 75.0000 (80.7235)  Acc@5: 100.0000 (98.9599)  time: 0.3501  data: 0.0006  max mem: 2503
Train: Epoch[4/5]  [3440/3750]  eta: 0:01:48  Lr: 0.001875  Loss: -0.6937  Acc@1: 75.0000 (80.7269)  Acc@5: 100.0000 (98.9611)  time: 0.3501  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [3450/3750]  eta: 0:01:44  Lr: 0.001875  Loss: -0.8822  Acc@1: 81.2500 (80.7248)  Acc@5: 100.0000 (98.9641)  time: 0.3500  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [3460/3750]  eta: 0:01:41  Lr: 0.001875  Loss: -1.0521  Acc@1: 81.2500 (80.7335)  Acc@5: 100.0000 (98.9653)  time: 0.3496  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [3470/3750]  eta: 0:01:37  Lr: 0.001875  Loss: -1.1199  Acc@1: 87.5000 (80.7404)  Acc@5: 100.0000 (98.9664)  time: 0.3495  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [3480/3750]  eta: 0:01:34  Lr: 0.001875  Loss: -0.4594  Acc@1: 81.2500 (80.7401)  Acc@5: 100.0000 (98.9676)  time: 0.3496  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [3490/3750]  eta: 0:01:30  Lr: 0.001875  Loss: -0.4721  Acc@1: 75.0000 (80.7236)  Acc@5: 100.0000 (98.9670)  time: 0.3492  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [3500/3750]  eta: 0:01:27  Lr: 0.001875  Loss: -0.8929  Acc@1: 81.2500 (80.7269)  Acc@5: 100.0000 (98.9682)  time: 0.3493  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [3510/3750]  eta: 0:01:23  Lr: 0.001875  Loss: -0.8446  Acc@1: 81.2500 (80.7213)  Acc@5: 100.0000 (98.9675)  time: 0.3502  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [3520/3750]  eta: 0:01:20  Lr: 0.001875  Loss: -0.5838  Acc@1: 81.2500 (80.7246)  Acc@5: 100.0000 (98.9687)  time: 0.3500  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [3530/3750]  eta: 0:01:16  Lr: 0.001875  Loss: -0.7732  Acc@1: 81.2500 (80.7296)  Acc@5: 100.0000 (98.9628)  time: 0.3502  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [3540/3750]  eta: 0:01:13  Lr: 0.001875  Loss: -0.9910  Acc@1: 81.2500 (80.7434)  Acc@5: 100.0000 (98.9657)  time: 0.3503  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [3550/3750]  eta: 0:01:09  Lr: 0.001875  Loss: -1.1148  Acc@1: 87.5000 (80.7572)  Acc@5: 100.0000 (98.9668)  time: 0.3493  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [3560/3750]  eta: 0:01:06  Lr: 0.001875  Loss: -0.4879  Acc@1: 87.5000 (80.7779)  Acc@5: 100.0000 (98.9697)  time: 0.3495  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [3570/3750]  eta: 0:01:02  Lr: 0.001875  Loss: -0.7481  Acc@1: 87.5000 (80.7862)  Acc@5: 100.0000 (98.9691)  time: 0.3499  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [3580/3750]  eta: 0:00:59  Lr: 0.001875  Loss: -0.8535  Acc@1: 87.5000 (80.7892)  Acc@5: 100.0000 (98.9685)  time: 0.3505  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [3590/3750]  eta: 0:00:55  Lr: 0.001875  Loss: -0.0094  Acc@1: 81.2500 (80.7853)  Acc@5: 100.0000 (98.9644)  time: 0.3505  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [3600/3750]  eta: 0:00:52  Lr: 0.001875  Loss: -0.4874  Acc@1: 81.2500 (80.7779)  Acc@5: 100.0000 (98.9638)  time: 0.3504  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [3610/3750]  eta: 0:00:48  Lr: 0.001875  Loss: -0.8728  Acc@1: 81.2500 (80.7723)  Acc@5: 100.0000 (98.9598)  time: 0.3501  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [3620/3750]  eta: 0:00:45  Lr: 0.001875  Loss: -0.4653  Acc@1: 81.2500 (80.7719)  Acc@5: 100.0000 (98.9609)  time: 0.3492  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [3630/3750]  eta: 0:00:41  Lr: 0.001875  Loss: -0.7102  Acc@1: 81.2500 (80.7646)  Acc@5: 100.0000 (98.9603)  time: 0.3496  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [3640/3750]  eta: 0:00:38  Lr: 0.001875  Loss: -0.9633  Acc@1: 81.2500 (80.7745)  Acc@5: 100.0000 (98.9632)  time: 0.3498  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [3650/3750]  eta: 0:00:34  Lr: 0.001875  Loss: -1.1440  Acc@1: 81.2500 (80.7810)  Acc@5: 100.0000 (98.9626)  time: 0.3496  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [3660/3750]  eta: 0:00:31  Lr: 0.001875  Loss: -0.2791  Acc@1: 81.2500 (80.7839)  Acc@5: 100.0000 (98.9637)  time: 0.3492  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [3670/3750]  eta: 0:00:27  Lr: 0.001875  Loss: -0.9172  Acc@1: 81.2500 (80.7767)  Acc@5: 100.0000 (98.9632)  time: 0.3499  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [3680/3750]  eta: 0:00:24  Lr: 0.001875  Loss: -0.9526  Acc@1: 81.2500 (80.7831)  Acc@5: 100.0000 (98.9660)  time: 0.3504  data: 0.0005  max mem: 2503
Train: Epoch[4/5]  [3690/3750]  eta: 0:00:20  Lr: 0.001875  Loss: -0.8552  Acc@1: 81.2500 (80.7843)  Acc@5: 100.0000 (98.9620)  time: 0.3499  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [3700/3750]  eta: 0:00:17  Lr: 0.001875  Loss: -0.7646  Acc@1: 81.2500 (80.7924)  Acc@5: 100.0000 (98.9648)  time: 0.3491  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [3710/3750]  eta: 0:00:13  Lr: 0.001875  Loss: -0.7504  Acc@1: 81.2500 (80.8020)  Acc@5: 100.0000 (98.9676)  time: 0.3492  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [3720/3750]  eta: 0:00:10  Lr: 0.001875  Loss: -1.0038  Acc@1: 81.2500 (80.8099)  Acc@5: 100.0000 (98.9687)  time: 0.3497  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [3730/3750]  eta: 0:00:06  Lr: 0.001875  Loss: -0.6300  Acc@1: 81.2500 (80.8044)  Acc@5: 100.0000 (98.9648)  time: 0.3492  data: 0.0004  max mem: 2503
Train: Epoch[4/5]  [3740/3750]  eta: 0:00:03  Lr: 0.001875  Loss: -0.3816  Acc@1: 81.2500 (80.8123)  Acc@5: 100.0000 (98.9659)  time: 0.3499  data: 0.0006  max mem: 2503
Train: Epoch[4/5]  [3749/3750]  eta: 0:00:00  Lr: 0.001875  Loss: -1.1748  Acc@1: 81.2500 (80.8150)  Acc@5: 100.0000 (98.9633)  time: 0.3506  data: 0.0012  max mem: 2503
Train: Epoch[4/5] Total time: 0:21:51 (0.3498 s / it)
Averaged stats: Lr: 0.001875  Loss: -1.1748  Acc@1: 81.2500 (80.8150)  Acc@5: 100.0000 (98.9633)
Train: Epoch[5/5]  [   0/3750]  eta: 0:51:45  Lr: 0.001875  Loss: -0.7162  Acc@1: 68.7500 (68.7500)  Acc@5: 100.0000 (100.0000)  time: 0.8283  data: 0.4677  max mem: 2503
Train: Epoch[5/5]  [  10/3750]  eta: 0:24:27  Lr: 0.001875  Loss: -0.1468  Acc@1: 75.0000 (78.4091)  Acc@5: 100.0000 (98.8636)  time: 0.3924  data: 0.0429  max mem: 2503
Train: Epoch[5/5]  [  20/3750]  eta: 0:23:06  Lr: 0.001875  Loss: -0.3895  Acc@1: 75.0000 (77.6786)  Acc@5: 100.0000 (98.5119)  time: 0.3490  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [  30/3750]  eta: 0:22:36  Lr: 0.001875  Loss: -0.8117  Acc@1: 75.0000 (77.2177)  Acc@5: 100.0000 (98.7903)  time: 0.3495  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [  40/3750]  eta: 0:22:18  Lr: 0.001875  Loss: -0.6822  Acc@1: 81.2500 (78.3537)  Acc@5: 100.0000 (98.9329)  time: 0.3494  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [  50/3750]  eta: 0:22:08  Lr: 0.001875  Loss: -0.6225  Acc@1: 81.2500 (78.4314)  Acc@5: 100.0000 (99.1422)  time: 0.3500  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [  60/3750]  eta: 0:21:58  Lr: 0.001875  Loss: -0.8242  Acc@1: 81.2500 (78.8934)  Acc@5: 100.0000 (99.0779)  time: 0.3503  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [  70/3750]  eta: 0:21:51  Lr: 0.001875  Loss: -0.5221  Acc@1: 81.2500 (79.0493)  Acc@5: 100.0000 (98.9437)  time: 0.3494  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [  80/3750]  eta: 0:21:44  Lr: 0.001875  Loss: -0.7945  Acc@1: 81.2500 (79.0895)  Acc@5: 100.0000 (99.0741)  time: 0.3495  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [  90/3750]  eta: 0:21:38  Lr: 0.001875  Loss: -0.3676  Acc@1: 81.2500 (79.2582)  Acc@5: 100.0000 (98.9698)  time: 0.3498  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [ 100/3750]  eta: 0:21:32  Lr: 0.001875  Loss: -1.0620  Acc@1: 81.2500 (80.0743)  Acc@5: 100.0000 (99.0099)  time: 0.3490  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [ 110/3750]  eta: 0:21:27  Lr: 0.001875  Loss: -0.9384  Acc@1: 81.2500 (79.9550)  Acc@5: 100.0000 (99.0428)  time: 0.3489  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [ 120/3750]  eta: 0:21:22  Lr: 0.001875  Loss: -0.6905  Acc@1: 81.2500 (80.3202)  Acc@5: 100.0000 (99.0186)  time: 0.3494  data: 0.0006  max mem: 2503
Train: Epoch[5/5]  [ 130/3750]  eta: 0:21:18  Lr: 0.001875  Loss: -0.4778  Acc@1: 87.5000 (80.5821)  Acc@5: 100.0000 (98.9504)  time: 0.3506  data: 0.0007  max mem: 2503
Train: Epoch[5/5]  [ 140/3750]  eta: 0:21:14  Lr: 0.001875  Loss: -0.9881  Acc@1: 87.5000 (80.8511)  Acc@5: 100.0000 (99.0248)  time: 0.3512  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [ 150/3750]  eta: 0:21:10  Lr: 0.001875  Loss: -0.3826  Acc@1: 87.5000 (81.0017)  Acc@5: 100.0000 (98.9652)  time: 0.3500  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [ 160/3750]  eta: 0:21:06  Lr: 0.001875  Loss: -0.7454  Acc@1: 81.2500 (80.9783)  Acc@5: 100.0000 (98.9519)  time: 0.3499  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [ 170/3750]  eta: 0:21:02  Lr: 0.001875  Loss: -1.0394  Acc@1: 81.2500 (81.1404)  Acc@5: 100.0000 (99.0132)  time: 0.3508  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [ 180/3750]  eta: 0:20:58  Lr: 0.001875  Loss: -0.4302  Acc@1: 81.2500 (81.0428)  Acc@5: 100.0000 (99.0331)  time: 0.3501  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [ 190/3750]  eta: 0:20:53  Lr: 0.001875  Loss: -0.7869  Acc@1: 81.2500 (81.0864)  Acc@5: 100.0000 (99.0183)  time: 0.3490  data: 0.0006  max mem: 2503
Train: Epoch[5/5]  [ 200/3750]  eta: 0:20:50  Lr: 0.001875  Loss: -0.8912  Acc@1: 81.2500 (81.1878)  Acc@5: 100.0000 (99.0672)  time: 0.3506  data: 0.0006  max mem: 2503
Train: Epoch[5/5]  [ 210/3750]  eta: 0:20:46  Lr: 0.001875  Loss: -0.8428  Acc@1: 81.2500 (81.3981)  Acc@5: 100.0000 (99.1114)  time: 0.3504  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [ 220/3750]  eta: 0:20:42  Lr: 0.001875  Loss: -0.7082  Acc@1: 81.2500 (81.3914)  Acc@5: 100.0000 (99.0667)  time: 0.3500  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [ 230/3750]  eta: 0:20:38  Lr: 0.001875  Loss: -0.4718  Acc@1: 81.2500 (81.1688)  Acc@5: 100.0000 (99.0260)  time: 0.3503  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [ 240/3750]  eta: 0:20:34  Lr: 0.001875  Loss: -0.9069  Acc@1: 81.2500 (81.2759)  Acc@5: 100.0000 (99.0145)  time: 0.3497  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [ 250/3750]  eta: 0:20:31  Lr: 0.001875  Loss: -0.6616  Acc@1: 81.2500 (81.2998)  Acc@5: 100.0000 (99.0040)  time: 0.3506  data: 0.0008  max mem: 2503
Train: Epoch[5/5]  [ 260/3750]  eta: 0:20:27  Lr: 0.001875  Loss: -1.0617  Acc@1: 81.2500 (81.2979)  Acc@5: 100.0000 (98.9703)  time: 0.3507  data: 0.0014  max mem: 2503
Train: Epoch[5/5]  [ 270/3750]  eta: 0:20:24  Lr: 0.001875  Loss: -0.3958  Acc@1: 81.2500 (81.3192)  Acc@5: 100.0000 (99.0083)  time: 0.3509  data: 0.0012  max mem: 2503
Train: Epoch[5/5]  [ 280/3750]  eta: 0:20:20  Lr: 0.001875  Loss: -1.0912  Acc@1: 81.2500 (81.3612)  Acc@5: 100.0000 (98.9769)  time: 0.3517  data: 0.0006  max mem: 2503
Train: Epoch[5/5]  [ 290/3750]  eta: 0:20:16  Lr: 0.001875  Loss: -0.4471  Acc@1: 81.2500 (81.4648)  Acc@5: 100.0000 (99.0120)  time: 0.3511  data: 0.0012  max mem: 2503
Train: Epoch[5/5]  [ 300/3750]  eta: 0:20:13  Lr: 0.001875  Loss: -0.4637  Acc@1: 81.2500 (81.3953)  Acc@5: 100.0000 (98.9410)  time: 0.3497  data: 0.0012  max mem: 2503
Train: Epoch[5/5]  [ 310/3750]  eta: 0:20:09  Lr: 0.001875  Loss: -0.9488  Acc@1: 81.2500 (81.4711)  Acc@5: 100.0000 (98.9550)  time: 0.3505  data: 0.0011  max mem: 2503
Train: Epoch[5/5]  [ 320/3750]  eta: 0:20:05  Lr: 0.001875  Loss: -0.8914  Acc@1: 81.2500 (81.5421)  Acc@5: 100.0000 (98.9486)  time: 0.3507  data: 0.0015  max mem: 2503
Train: Epoch[5/5]  [ 330/3750]  eta: 0:20:02  Lr: 0.001875  Loss: -0.8076  Acc@1: 75.0000 (81.3822)  Acc@5: 100.0000 (98.9615)  time: 0.3501  data: 0.0015  max mem: 2503
Train: Epoch[5/5]  [ 340/3750]  eta: 0:19:58  Lr: 0.001875  Loss: -0.5010  Acc@1: 75.0000 (81.2317)  Acc@5: 100.0000 (98.9003)  time: 0.3506  data: 0.0013  max mem: 2503
Train: Epoch[5/5]  [ 350/3750]  eta: 0:19:54  Lr: 0.001875  Loss: -0.7189  Acc@1: 81.2500 (81.2500)  Acc@5: 100.0000 (98.8426)  time: 0.3497  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [ 360/3750]  eta: 0:19:51  Lr: 0.001875  Loss: -0.6023  Acc@1: 81.2500 (81.2500)  Acc@5: 100.0000 (98.8573)  time: 0.3504  data: 0.0009  max mem: 2503
Train: Epoch[5/5]  [ 370/3750]  eta: 0:19:47  Lr: 0.001875  Loss: -0.8699  Acc@1: 81.2500 (81.1152)  Acc@5: 100.0000 (98.8881)  time: 0.3517  data: 0.0009  max mem: 2503
Train: Epoch[5/5]  [ 380/3750]  eta: 0:19:44  Lr: 0.001875  Loss: -1.1006  Acc@1: 81.2500 (81.1844)  Acc@5: 100.0000 (98.9009)  time: 0.3518  data: 0.0006  max mem: 2503
Train: Epoch[5/5]  [ 390/3750]  eta: 0:19:41  Lr: 0.001875  Loss: -0.8188  Acc@1: 81.2500 (81.2340)  Acc@5: 100.0000 (98.8811)  time: 0.3525  data: 0.0021  max mem: 2503
Train: Epoch[5/5]  [ 400/3750]  eta: 0:19:37  Lr: 0.001875  Loss: -0.9073  Acc@1: 87.5000 (81.3279)  Acc@5: 100.0000 (98.8934)  time: 0.3522  data: 0.0021  max mem: 2503
Train: Epoch[5/5]  [ 410/3750]  eta: 0:19:33  Lr: 0.001875  Loss: -0.6984  Acc@1: 81.2500 (81.2652)  Acc@5: 100.0000 (98.8899)  time: 0.3509  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [ 420/3750]  eta: 0:19:30  Lr: 0.001875  Loss: -0.4090  Acc@1: 81.2500 (81.1758)  Acc@5: 100.0000 (98.8717)  time: 0.3516  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [ 430/3750]  eta: 0:19:26  Lr: 0.001875  Loss: -0.7008  Acc@1: 75.0000 (81.1195)  Acc@5: 100.0000 (98.8689)  time: 0.3521  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [ 440/3750]  eta: 0:19:23  Lr: 0.001875  Loss: -1.0087  Acc@1: 81.2500 (81.1083)  Acc@5: 100.0000 (98.8662)  time: 0.3508  data: 0.0011  max mem: 2503
Train: Epoch[5/5]  [ 450/3750]  eta: 0:19:19  Lr: 0.001875  Loss: -0.4586  Acc@1: 81.2500 (81.0976)  Acc@5: 100.0000 (98.8775)  time: 0.3509  data: 0.0012  max mem: 2503
Train: Epoch[5/5]  [ 460/3750]  eta: 0:19:16  Lr: 0.001875  Loss: -0.3149  Acc@1: 81.2500 (81.0738)  Acc@5: 100.0000 (98.9018)  time: 0.3509  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [ 470/3750]  eta: 0:19:12  Lr: 0.001875  Loss: -0.9606  Acc@1: 81.2500 (81.1438)  Acc@5: 100.0000 (98.9119)  time: 0.3504  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [ 480/3750]  eta: 0:19:09  Lr: 0.001875  Loss: -0.9574  Acc@1: 81.2500 (81.1980)  Acc@5: 100.0000 (98.9345)  time: 0.3508  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [ 490/3750]  eta: 0:19:05  Lr: 0.001875  Loss: -0.8863  Acc@1: 87.5000 (81.3136)  Acc@5: 100.0000 (98.9562)  time: 0.3506  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [ 500/3750]  eta: 0:19:01  Lr: 0.001875  Loss: -1.0155  Acc@1: 87.5000 (81.3373)  Acc@5: 100.0000 (98.9646)  time: 0.3499  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [ 510/3750]  eta: 0:18:58  Lr: 0.001875  Loss: -0.9337  Acc@1: 81.2500 (81.3723)  Acc@5: 100.0000 (98.9726)  time: 0.3497  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [ 520/3750]  eta: 0:18:54  Lr: 0.001875  Loss: -0.8514  Acc@1: 81.2500 (81.3820)  Acc@5: 100.0000 (98.9803)  time: 0.3488  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [ 530/3750]  eta: 0:18:50  Lr: 0.001875  Loss: -0.7136  Acc@1: 81.2500 (81.3442)  Acc@5: 100.0000 (98.9642)  time: 0.3484  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [ 540/3750]  eta: 0:18:47  Lr: 0.001875  Loss: -0.6954  Acc@1: 81.2500 (81.3540)  Acc@5: 100.0000 (98.9603)  time: 0.3485  data: 0.0006  max mem: 2503
Train: Epoch[5/5]  [ 550/3750]  eta: 0:18:43  Lr: 0.001875  Loss: -0.7797  Acc@1: 81.2500 (81.3181)  Acc@5: 100.0000 (98.9678)  time: 0.3492  data: 0.0006  max mem: 2503
Train: Epoch[5/5]  [ 560/3750]  eta: 0:18:40  Lr: 0.001875  Loss: -0.7223  Acc@1: 81.2500 (81.3280)  Acc@5: 100.0000 (98.9750)  time: 0.3507  data: 0.0011  max mem: 2503
Train: Epoch[5/5]  [ 570/3750]  eta: 0:18:36  Lr: 0.001875  Loss: -0.6480  Acc@1: 81.2500 (81.2609)  Acc@5: 100.0000 (98.9602)  time: 0.3495  data: 0.0011  max mem: 2503
Train: Epoch[5/5]  [ 580/3750]  eta: 0:18:32  Lr: 0.001875  Loss: -0.3925  Acc@1: 81.2500 (81.2177)  Acc@5: 100.0000 (98.9673)  time: 0.3480  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [ 590/3750]  eta: 0:18:29  Lr: 0.001875  Loss: -0.7506  Acc@1: 81.2500 (81.1548)  Acc@5: 100.0000 (98.9530)  time: 0.3481  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [ 600/3750]  eta: 0:18:25  Lr: 0.001875  Loss: -0.8715  Acc@1: 81.2500 (81.2292)  Acc@5: 100.0000 (98.9393)  time: 0.3488  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [ 610/3750]  eta: 0:18:22  Lr: 0.001875  Loss: -0.7547  Acc@1: 87.5000 (81.2602)  Acc@5: 100.0000 (98.9464)  time: 0.3506  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [ 620/3750]  eta: 0:18:18  Lr: 0.001875  Loss: -0.5740  Acc@1: 87.5000 (81.3003)  Acc@5: 100.0000 (98.9332)  time: 0.3503  data: 0.0007  max mem: 2503
Train: Epoch[5/5]  [ 630/3750]  eta: 0:18:14  Lr: 0.001875  Loss: -0.6180  Acc@1: 81.2500 (81.1906)  Acc@5: 100.0000 (98.9204)  time: 0.3489  data: 0.0006  max mem: 2503
Train: Epoch[5/5]  [ 640/3750]  eta: 0:18:11  Lr: 0.001875  Loss: -0.5413  Acc@1: 81.2500 (81.2402)  Acc@5: 100.0000 (98.9372)  time: 0.3484  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [ 650/3750]  eta: 0:18:07  Lr: 0.001875  Loss: -0.7821  Acc@1: 81.2500 (81.2404)  Acc@5: 100.0000 (98.9535)  time: 0.3485  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [ 660/3750]  eta: 0:18:04  Lr: 0.001875  Loss: -0.5815  Acc@1: 75.0000 (81.2027)  Acc@5: 100.0000 (98.9599)  time: 0.3494  data: 0.0008  max mem: 2503
Train: Epoch[5/5]  [ 670/3750]  eta: 0:18:00  Lr: 0.001875  Loss: -0.7249  Acc@1: 81.2500 (81.2314)  Acc@5: 100.0000 (98.9754)  time: 0.3492  data: 0.0008  max mem: 2503
Train: Epoch[5/5]  [ 680/3750]  eta: 0:17:56  Lr: 0.001875  Loss: -1.0096  Acc@1: 81.2500 (81.2500)  Acc@5: 100.0000 (98.9905)  time: 0.3486  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [ 690/3750]  eta: 0:17:53  Lr: 0.001875  Loss: -0.7220  Acc@1: 81.2500 (81.1596)  Acc@5: 100.0000 (98.9689)  time: 0.3493  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [ 700/3750]  eta: 0:17:49  Lr: 0.001875  Loss: -0.8160  Acc@1: 75.0000 (81.1341)  Acc@5: 100.0000 (98.9568)  time: 0.3496  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [ 710/3750]  eta: 0:17:46  Lr: 0.001875  Loss: -0.8448  Acc@1: 81.2500 (81.1269)  Acc@5: 100.0000 (98.9539)  time: 0.3494  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [ 720/3750]  eta: 0:17:42  Lr: 0.001875  Loss: -0.5455  Acc@1: 81.2500 (81.1546)  Acc@5: 100.0000 (98.9598)  time: 0.3497  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [ 730/3750]  eta: 0:17:38  Lr: 0.001875  Loss: -0.4510  Acc@1: 81.2500 (81.1132)  Acc@5: 100.0000 (98.9484)  time: 0.3490  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [ 740/3750]  eta: 0:17:35  Lr: 0.001875  Loss: -0.9702  Acc@1: 75.0000 (81.0138)  Acc@5: 100.0000 (98.9541)  time: 0.3485  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [ 750/3750]  eta: 0:17:31  Lr: 0.001875  Loss: -1.0715  Acc@1: 81.2500 (81.0919)  Acc@5: 100.0000 (98.9431)  time: 0.3497  data: 0.0010  max mem: 2503
Train: Epoch[5/5]  [ 760/3750]  eta: 0:17:28  Lr: 0.001875  Loss: -0.6117  Acc@1: 81.2500 (81.1104)  Acc@5: 100.0000 (98.9323)  time: 0.3503  data: 0.0011  max mem: 2503
Train: Epoch[5/5]  [ 770/3750]  eta: 0:17:24  Lr: 0.001875  Loss: -0.7396  Acc@1: 81.2500 (81.1365)  Acc@5: 100.0000 (98.9300)  time: 0.3495  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [ 780/3750]  eta: 0:17:21  Lr: 0.001875  Loss: -1.0667  Acc@1: 75.0000 (81.0819)  Acc@5: 100.0000 (98.9277)  time: 0.3492  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [ 790/3750]  eta: 0:17:17  Lr: 0.001875  Loss: -0.6283  Acc@1: 81.2500 (81.1157)  Acc@5: 100.0000 (98.9333)  time: 0.3494  data: 0.0007  max mem: 2503
Train: Epoch[5/5]  [ 800/3750]  eta: 0:17:14  Lr: 0.001875  Loss: -0.7890  Acc@1: 81.2500 (81.1486)  Acc@5: 100.0000 (98.9388)  time: 0.3495  data: 0.0007  max mem: 2503
Train: Epoch[5/5]  [ 810/3750]  eta: 0:17:10  Lr: 0.001875  Loss: -1.0757  Acc@1: 81.2500 (81.2115)  Acc@5: 100.0000 (98.9365)  time: 0.3499  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [ 820/3750]  eta: 0:17:07  Lr: 0.001875  Loss: -0.8507  Acc@1: 81.2500 (81.2348)  Acc@5: 100.0000 (98.9190)  time: 0.3499  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [ 830/3750]  eta: 0:17:03  Lr: 0.001875  Loss: -0.9355  Acc@1: 81.2500 (81.2575)  Acc@5: 100.0000 (98.9320)  time: 0.3506  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [ 840/3750]  eta: 0:17:00  Lr: 0.001875  Loss: -0.6307  Acc@1: 81.2500 (81.2054)  Acc@5: 100.0000 (98.9373)  time: 0.3506  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [ 850/3750]  eta: 0:16:56  Lr: 0.001875  Loss: -0.5442  Acc@1: 75.0000 (81.1986)  Acc@5: 100.0000 (98.9204)  time: 0.3497  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [ 860/3750]  eta: 0:16:53  Lr: 0.001875  Loss: -0.8681  Acc@1: 81.2500 (81.1847)  Acc@5: 100.0000 (98.9184)  time: 0.3499  data: 0.0006  max mem: 2503
Train: Epoch[5/5]  [ 870/3750]  eta: 0:16:49  Lr: 0.001875  Loss: -0.7747  Acc@1: 81.2500 (81.2069)  Acc@5: 100.0000 (98.9237)  time: 0.3501  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [ 880/3750]  eta: 0:16:46  Lr: 0.001875  Loss: -0.4675  Acc@1: 87.5000 (81.2358)  Acc@5: 100.0000 (98.9075)  time: 0.3506  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [ 890/3750]  eta: 0:16:42  Lr: 0.001875  Loss: -0.9469  Acc@1: 87.5000 (81.2781)  Acc@5: 100.0000 (98.9198)  time: 0.3505  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [ 900/3750]  eta: 0:16:39  Lr: 0.001875  Loss: -0.8490  Acc@1: 81.2500 (81.2708)  Acc@5: 100.0000 (98.9109)  time: 0.3506  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [ 910/3750]  eta: 0:16:35  Lr: 0.001875  Loss: -0.5601  Acc@1: 81.2500 (81.2980)  Acc@5: 100.0000 (98.9160)  time: 0.3503  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [ 920/3750]  eta: 0:16:32  Lr: 0.001875  Loss: -1.1028  Acc@1: 81.2500 (81.2839)  Acc@5: 100.0000 (98.9210)  time: 0.3510  data: 0.0009  max mem: 2503
Train: Epoch[5/5]  [ 930/3750]  eta: 0:16:28  Lr: 0.001875  Loss: -0.7536  Acc@1: 75.0000 (81.2433)  Acc@5: 100.0000 (98.9125)  time: 0.3526  data: 0.0015  max mem: 2503
Train: Epoch[5/5]  [ 940/3750]  eta: 0:16:25  Lr: 0.001875  Loss: -0.6223  Acc@1: 81.2500 (81.2500)  Acc@5: 100.0000 (98.9107)  time: 0.3511  data: 0.0011  max mem: 2503
Train: Epoch[5/5]  [ 950/3750]  eta: 0:16:21  Lr: 0.001875  Loss: -0.8469  Acc@1: 81.2500 (81.2434)  Acc@5: 100.0000 (98.9090)  time: 0.3507  data: 0.0007  max mem: 2503
Train: Epoch[5/5]  [ 960/3750]  eta: 0:16:18  Lr: 0.001875  Loss: -1.0116  Acc@1: 81.2500 (81.2045)  Acc@5: 100.0000 (98.9139)  time: 0.3508  data: 0.0006  max mem: 2503
Train: Epoch[5/5]  [ 970/3750]  eta: 0:16:14  Lr: 0.001875  Loss: -0.8190  Acc@1: 81.2500 (81.1921)  Acc@5: 100.0000 (98.9058)  time: 0.3502  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [ 980/3750]  eta: 0:16:11  Lr: 0.001875  Loss: -0.5575  Acc@1: 75.0000 (81.1863)  Acc@5: 100.0000 (98.9169)  time: 0.3497  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [ 990/3750]  eta: 0:16:07  Lr: 0.001875  Loss: -0.3664  Acc@1: 75.0000 (81.1113)  Acc@5: 100.0000 (98.9152)  time: 0.3495  data: 0.0012  max mem: 2503
Train: Epoch[5/5]  [1000/3750]  eta: 0:16:03  Lr: 0.001875  Loss: -0.9571  Acc@1: 81.2500 (81.1439)  Acc@5: 100.0000 (98.9136)  time: 0.3494  data: 0.0012  max mem: 2503
Train: Epoch[5/5]  [1010/3750]  eta: 0:16:00  Lr: 0.001875  Loss: -0.4827  Acc@1: 81.2500 (81.1449)  Acc@5: 100.0000 (98.9058)  time: 0.3486  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [1020/3750]  eta: 0:15:56  Lr: 0.001875  Loss: -0.7908  Acc@1: 81.2500 (81.1704)  Acc@5: 100.0000 (98.9043)  time: 0.3484  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [1030/3750]  eta: 0:15:53  Lr: 0.001875  Loss: -0.6080  Acc@1: 81.2500 (81.1288)  Acc@5: 100.0000 (98.9149)  time: 0.3488  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [1040/3750]  eta: 0:15:49  Lr: 0.001875  Loss: -0.5967  Acc@1: 75.0000 (81.1059)  Acc@5: 100.0000 (98.9193)  time: 0.3492  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [1050/3750]  eta: 0:15:46  Lr: 0.001875  Loss: -0.7430  Acc@1: 75.0000 (81.0716)  Acc@5: 100.0000 (98.9118)  time: 0.3503  data: 0.0013  max mem: 2503
Train: Epoch[5/5]  [1060/3750]  eta: 0:15:42  Lr: 0.001875  Loss: -0.1184  Acc@1: 81.2500 (81.0615)  Acc@5: 100.0000 (98.9043)  time: 0.3502  data: 0.0013  max mem: 2503
Train: Epoch[5/5]  [1070/3750]  eta: 0:15:39  Lr: 0.001875  Loss: -0.8264  Acc@1: 81.2500 (81.0399)  Acc@5: 100.0000 (98.9146)  time: 0.3495  data: 0.0006  max mem: 2503
Train: Epoch[5/5]  [1080/3750]  eta: 0:15:35  Lr: 0.001875  Loss: -0.9367  Acc@1: 81.2500 (81.0361)  Acc@5: 100.0000 (98.9188)  time: 0.3497  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [1090/3750]  eta: 0:15:32  Lr: 0.001875  Loss: -0.9332  Acc@1: 87.5000 (81.0667)  Acc@5: 100.0000 (98.9230)  time: 0.3495  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [1100/3750]  eta: 0:15:28  Lr: 0.001875  Loss: -0.8104  Acc@1: 81.2500 (81.0400)  Acc@5: 100.0000 (98.9328)  time: 0.3491  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [1110/3750]  eta: 0:15:25  Lr: 0.001875  Loss: -0.8169  Acc@1: 81.2500 (81.0250)  Acc@5: 100.0000 (98.9255)  time: 0.3491  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [1120/3750]  eta: 0:15:21  Lr: 0.001875  Loss: -0.9985  Acc@1: 81.2500 (81.0381)  Acc@5: 100.0000 (98.9351)  time: 0.3488  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [1130/3750]  eta: 0:15:17  Lr: 0.001875  Loss: -0.8406  Acc@1: 81.2500 (81.0290)  Acc@5: 100.0000 (98.9445)  time: 0.3488  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [1140/3750]  eta: 0:15:14  Lr: 0.001875  Loss: -0.3616  Acc@1: 81.2500 (81.0090)  Acc@5: 100.0000 (98.9428)  time: 0.3499  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [1150/3750]  eta: 0:15:10  Lr: 0.001875  Loss: -0.5882  Acc@1: 81.2500 (81.0328)  Acc@5: 100.0000 (98.9520)  time: 0.3502  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [1160/3750]  eta: 0:15:07  Lr: 0.001875  Loss: -0.7021  Acc@1: 81.2500 (81.0401)  Acc@5: 100.0000 (98.9610)  time: 0.3492  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [1170/3750]  eta: 0:15:03  Lr: 0.001875  Loss: -0.6459  Acc@1: 81.2500 (81.0525)  Acc@5: 100.0000 (98.9646)  time: 0.3486  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [1180/3750]  eta: 0:15:00  Lr: 0.001875  Loss: -0.9037  Acc@1: 81.2500 (81.0542)  Acc@5: 100.0000 (98.9680)  time: 0.3498  data: 0.0014  max mem: 2503
Train: Epoch[5/5]  [1190/3750]  eta: 0:14:56  Lr: 0.001875  Loss: -0.8683  Acc@1: 81.2500 (81.0663)  Acc@5: 100.0000 (98.9662)  time: 0.3496  data: 0.0014  max mem: 2503
Train: Epoch[5/5]  [1200/3750]  eta: 0:14:53  Lr: 0.001875  Loss: -0.7339  Acc@1: 81.2500 (81.1043)  Acc@5: 100.0000 (98.9644)  time: 0.3486  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [1210/3750]  eta: 0:14:49  Lr: 0.001875  Loss: -1.0092  Acc@1: 87.5000 (81.1313)  Acc@5: 100.0000 (98.9730)  time: 0.3492  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [1220/3750]  eta: 0:14:46  Lr: 0.001875  Loss: -0.9471  Acc@1: 87.5000 (81.1527)  Acc@5: 100.0000 (98.9814)  time: 0.3493  data: 0.0006  max mem: 2503
Train: Epoch[5/5]  [1230/3750]  eta: 0:14:42  Lr: 0.001875  Loss: -0.6080  Acc@1: 81.2500 (81.0926)  Acc@5: 100.0000 (98.9846)  time: 0.3489  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [1240/3750]  eta: 0:14:39  Lr: 0.001875  Loss: -0.3770  Acc@1: 75.0000 (81.0788)  Acc@5: 100.0000 (98.9726)  time: 0.3489  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [1250/3750]  eta: 0:14:35  Lr: 0.001875  Loss: -0.8883  Acc@1: 81.2500 (81.0701)  Acc@5: 100.0000 (98.9758)  time: 0.3489  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [1260/3750]  eta: 0:14:32  Lr: 0.001875  Loss: -0.7955  Acc@1: 75.0000 (81.0270)  Acc@5: 100.0000 (98.9839)  time: 0.3497  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [1270/3750]  eta: 0:14:28  Lr: 0.001875  Loss: -0.6611  Acc@1: 81.2500 (81.0484)  Acc@5: 100.0000 (98.9821)  time: 0.3502  data: 0.0008  max mem: 2503
Train: Epoch[5/5]  [1280/3750]  eta: 0:14:25  Lr: 0.001875  Loss: -0.7409  Acc@1: 81.2500 (81.0451)  Acc@5: 100.0000 (98.9852)  time: 0.3502  data: 0.0008  max mem: 2503
Train: Epoch[5/5]  [1290/3750]  eta: 0:14:21  Lr: 0.001875  Loss: -0.8784  Acc@1: 81.2500 (81.0467)  Acc@5: 100.0000 (98.9833)  time: 0.3506  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [1300/3750]  eta: 0:14:18  Lr: 0.001875  Loss: -0.6429  Acc@1: 81.2500 (81.0482)  Acc@5: 100.0000 (98.9864)  time: 0.3501  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [1310/3750]  eta: 0:14:14  Lr: 0.001875  Loss: -0.6327  Acc@1: 81.2500 (81.0450)  Acc@5: 100.0000 (98.9846)  time: 0.3497  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [1320/3750]  eta: 0:14:11  Lr: 0.001875  Loss: -0.0524  Acc@1: 81.2500 (81.0702)  Acc@5: 100.0000 (98.9780)  time: 0.3497  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [1330/3750]  eta: 0:14:07  Lr: 0.001875  Loss: -0.9395  Acc@1: 81.2500 (81.0950)  Acc@5: 100.0000 (98.9857)  time: 0.3510  data: 0.0014  max mem: 2503
Train: Epoch[5/5]  [1340/3750]  eta: 0:14:04  Lr: 0.001875  Loss: -0.1819  Acc@1: 81.2500 (81.0729)  Acc@5: 100.0000 (98.9886)  time: 0.3507  data: 0.0014  max mem: 2503
Train: Epoch[5/5]  [1350/3750]  eta: 0:14:00  Lr: 0.001875  Loss: -0.9857  Acc@1: 81.2500 (81.1112)  Acc@5: 100.0000 (98.9961)  time: 0.3499  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [1360/3750]  eta: 0:13:57  Lr: 0.001875  Loss: -0.2820  Acc@1: 87.5000 (81.1168)  Acc@5: 100.0000 (99.0035)  time: 0.3502  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [1370/3750]  eta: 0:13:53  Lr: 0.001875  Loss: -0.6460  Acc@1: 75.0000 (81.0677)  Acc@5: 100.0000 (98.9971)  time: 0.3497  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [1380/3750]  eta: 0:13:50  Lr: 0.001875  Loss: -0.7025  Acc@1: 81.2500 (81.0690)  Acc@5: 100.0000 (99.0043)  time: 0.3497  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [1390/3750]  eta: 0:13:46  Lr: 0.001875  Loss: -0.6948  Acc@1: 81.2500 (81.0478)  Acc@5: 100.0000 (98.9935)  time: 0.3491  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [1400/3750]  eta: 0:13:43  Lr: 0.001875  Loss: -0.6672  Acc@1: 81.2500 (81.0671)  Acc@5: 100.0000 (99.0007)  time: 0.3491  data: 0.0006  max mem: 2503
Train: Epoch[5/5]  [1410/3750]  eta: 0:13:39  Lr: 0.001875  Loss: -0.6481  Acc@1: 81.2500 (81.0595)  Acc@5: 100.0000 (99.0034)  time: 0.3508  data: 0.0019  max mem: 2503
Train: Epoch[5/5]  [1420/3750]  eta: 0:13:36  Lr: 0.001875  Loss: -0.9373  Acc@1: 81.2500 (81.0697)  Acc@5: 100.0000 (99.0016)  time: 0.3504  data: 0.0018  max mem: 2503
Train: Epoch[5/5]  [1430/3750]  eta: 0:13:32  Lr: 0.001875  Loss: -0.8679  Acc@1: 87.5000 (81.0840)  Acc@5: 100.0000 (99.0042)  time: 0.3502  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [1440/3750]  eta: 0:13:29  Lr: 0.001875  Loss: -0.5734  Acc@1: 81.2500 (81.0808)  Acc@5: 100.0000 (99.0024)  time: 0.3504  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [1450/3750]  eta: 0:13:25  Lr: 0.001875  Loss: -0.8482  Acc@1: 81.2500 (81.0648)  Acc@5: 100.0000 (99.0050)  time: 0.3493  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [1460/3750]  eta: 0:13:22  Lr: 0.001875  Loss: -0.7726  Acc@1: 81.2500 (81.0746)  Acc@5: 100.0000 (99.0075)  time: 0.3503  data: 0.0006  max mem: 2503
Train: Epoch[5/5]  [1470/3750]  eta: 0:13:18  Lr: 0.001875  Loss: -0.9880  Acc@1: 87.5000 (81.0885)  Acc@5: 100.0000 (99.0143)  time: 0.3504  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [1480/3750]  eta: 0:13:15  Lr: 0.001875  Loss: -0.7761  Acc@1: 81.2500 (81.0939)  Acc@5: 100.0000 (99.0083)  time: 0.3496  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [1490/3750]  eta: 0:13:11  Lr: 0.001875  Loss: -0.8562  Acc@1: 81.2500 (81.0949)  Acc@5: 100.0000 (99.0107)  time: 0.3492  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [1500/3750]  eta: 0:13:07  Lr: 0.001875  Loss: -0.9705  Acc@1: 75.0000 (81.0626)  Acc@5: 100.0000 (99.0090)  time: 0.3490  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [1510/3750]  eta: 0:13:04  Lr: 0.001875  Loss: -1.0654  Acc@1: 81.2500 (81.0721)  Acc@5: 100.0000 (99.0114)  time: 0.3490  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [1520/3750]  eta: 0:13:00  Lr: 0.001875  Loss: -0.4690  Acc@1: 81.2500 (81.0569)  Acc@5: 100.0000 (99.0097)  time: 0.3501  data: 0.0007  max mem: 2503
Train: Epoch[5/5]  [1530/3750]  eta: 0:12:57  Lr: 0.001875  Loss: -0.6958  Acc@1: 81.2500 (81.0500)  Acc@5: 100.0000 (99.0080)  time: 0.3501  data: 0.0007  max mem: 2503
Train: Epoch[5/5]  [1540/3750]  eta: 0:12:53  Lr: 0.001875  Loss: -0.0827  Acc@1: 81.2500 (81.0594)  Acc@5: 100.0000 (99.0063)  time: 0.3492  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [1550/3750]  eta: 0:12:50  Lr: 0.001875  Loss: -0.6782  Acc@1: 81.2500 (81.0525)  Acc@5: 100.0000 (99.0087)  time: 0.3495  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [1560/3750]  eta: 0:12:46  Lr: 0.001875  Loss: -0.5125  Acc@1: 81.2500 (81.0658)  Acc@5: 100.0000 (99.0111)  time: 0.3503  data: 0.0011  max mem: 2503
Train: Epoch[5/5]  [1570/3750]  eta: 0:12:43  Lr: 0.001875  Loss: -0.5262  Acc@1: 81.2500 (81.0750)  Acc@5: 100.0000 (99.0173)  time: 0.3504  data: 0.0012  max mem: 2503
Train: Epoch[5/5]  [1580/3750]  eta: 0:12:39  Lr: 0.001875  Loss: -0.7868  Acc@1: 81.2500 (81.0682)  Acc@5: 100.0000 (99.0157)  time: 0.3495  data: 0.0007  max mem: 2503
Train: Epoch[5/5]  [1590/3750]  eta: 0:12:36  Lr: 0.001875  Loss: -0.8167  Acc@1: 81.2500 (81.0536)  Acc@5: 100.0000 (99.0179)  time: 0.3496  data: 0.0007  max mem: 2503
Train: Epoch[5/5]  [1600/3750]  eta: 0:12:32  Lr: 0.001875  Loss: -0.7938  Acc@1: 81.2500 (81.0782)  Acc@5: 100.0000 (99.0162)  time: 0.3495  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [1610/3750]  eta: 0:12:29  Lr: 0.001875  Loss: -0.8473  Acc@1: 87.5000 (81.1026)  Acc@5: 100.0000 (99.0107)  time: 0.3500  data: 0.0008  max mem: 2503
Train: Epoch[5/5]  [1620/3750]  eta: 0:12:25  Lr: 0.001875  Loss: -1.1254  Acc@1: 81.2500 (81.1112)  Acc@5: 100.0000 (99.0091)  time: 0.3499  data: 0.0008  max mem: 2503
Train: Epoch[5/5]  [1630/3750]  eta: 0:12:22  Lr: 0.001875  Loss: -0.7838  Acc@1: 81.2500 (81.1006)  Acc@5: 100.0000 (99.0152)  time: 0.3492  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [1640/3750]  eta: 0:12:18  Lr: 0.001875  Loss: -0.8040  Acc@1: 81.2500 (81.1281)  Acc@5: 100.0000 (99.0212)  time: 0.3495  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [1650/3750]  eta: 0:12:15  Lr: 0.001875  Loss: -0.8492  Acc@1: 81.2500 (81.1251)  Acc@5: 100.0000 (99.0233)  time: 0.3493  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [1660/3750]  eta: 0:12:11  Lr: 0.001875  Loss: -0.7322  Acc@1: 81.2500 (81.1183)  Acc@5: 100.0000 (99.0254)  time: 0.3498  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [1670/3750]  eta: 0:12:08  Lr: 0.001875  Loss: -0.9763  Acc@1: 81.2500 (81.1041)  Acc@5: 100.0000 (99.0313)  time: 0.3501  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [1680/3750]  eta: 0:12:04  Lr: 0.001875  Loss: -1.0237  Acc@1: 81.2500 (81.1050)  Acc@5: 100.0000 (99.0333)  time: 0.3498  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [1690/3750]  eta: 0:12:01  Lr: 0.001875  Loss: -0.6760  Acc@1: 75.0000 (81.0985)  Acc@5: 100.0000 (99.0316)  time: 0.3499  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [1700/3750]  eta: 0:11:57  Lr: 0.001875  Loss: -0.9187  Acc@1: 81.2500 (81.1067)  Acc@5: 100.0000 (99.0337)  time: 0.3501  data: 0.0007  max mem: 2503
Train: Epoch[5/5]  [1710/3750]  eta: 0:11:54  Lr: 0.001875  Loss: -1.1667  Acc@1: 81.2500 (81.1112)  Acc@5: 100.0000 (99.0357)  time: 0.3505  data: 0.0013  max mem: 2503
Train: Epoch[5/5]  [1720/3750]  eta: 0:11:50  Lr: 0.001875  Loss: -0.8219  Acc@1: 81.2500 (81.1265)  Acc@5: 100.0000 (99.0304)  time: 0.3505  data: 0.0011  max mem: 2503
Train: Epoch[5/5]  [1730/3750]  eta: 0:11:47  Lr: 0.001875  Loss: -1.1413  Acc@1: 81.2500 (81.1200)  Acc@5: 100.0000 (99.0324)  time: 0.3508  data: 0.0006  max mem: 2503
Train: Epoch[5/5]  [1740/3750]  eta: 0:11:43  Lr: 0.001875  Loss: -0.9550  Acc@1: 81.2500 (81.0992)  Acc@5: 100.0000 (99.0343)  time: 0.3504  data: 0.0006  max mem: 2503
Train: Epoch[5/5]  [1750/3750]  eta: 0:11:40  Lr: 0.001875  Loss: -0.9415  Acc@1: 81.2500 (81.1286)  Acc@5: 100.0000 (99.0327)  time: 0.3499  data: 0.0006  max mem: 2503
Train: Epoch[5/5]  [1760/3750]  eta: 0:11:36  Lr: 0.001875  Loss: -0.5840  Acc@1: 87.5000 (81.1364)  Acc@5: 100.0000 (99.0275)  time: 0.3495  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [1770/3750]  eta: 0:11:33  Lr: 0.001875  Loss: -0.7232  Acc@1: 87.5000 (81.1582)  Acc@5: 100.0000 (99.0189)  time: 0.3493  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [1780/3750]  eta: 0:11:29  Lr: 0.001875  Loss: -0.8267  Acc@1: 81.2500 (81.1342)  Acc@5: 100.0000 (99.0139)  time: 0.3492  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [1790/3750]  eta: 0:11:26  Lr: 0.001875  Loss: -0.5142  Acc@1: 81.2500 (81.1523)  Acc@5: 100.0000 (99.0194)  time: 0.3489  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [1800/3750]  eta: 0:11:22  Lr: 0.001875  Loss: -0.4009  Acc@1: 81.2500 (81.1528)  Acc@5: 100.0000 (99.0214)  time: 0.3489  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [1810/3750]  eta: 0:11:19  Lr: 0.001875  Loss: -0.6352  Acc@1: 81.2500 (81.1430)  Acc@5: 100.0000 (99.0233)  time: 0.3491  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [1820/3750]  eta: 0:11:15  Lr: 0.001875  Loss: -0.5184  Acc@1: 81.2500 (81.1230)  Acc@5: 100.0000 (99.0184)  time: 0.3492  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [1830/3750]  eta: 0:11:12  Lr: 0.001875  Loss: -0.8312  Acc@1: 81.2500 (81.1408)  Acc@5: 100.0000 (99.0169)  time: 0.3507  data: 0.0014  max mem: 2503
Train: Epoch[5/5]  [1840/3750]  eta: 0:11:08  Lr: 0.001875  Loss: -0.8953  Acc@1: 81.2500 (81.1448)  Acc@5: 100.0000 (99.0223)  time: 0.3510  data: 0.0015  max mem: 2503
Train: Epoch[5/5]  [1850/3750]  eta: 0:11:05  Lr: 0.001875  Loss: -0.8557  Acc@1: 81.2500 (81.1420)  Acc@5: 100.0000 (99.0242)  time: 0.3496  data: 0.0008  max mem: 2503
Train: Epoch[5/5]  [1860/3750]  eta: 0:11:01  Lr: 0.001875  Loss: -0.8274  Acc@1: 87.5000 (81.1560)  Acc@5: 100.0000 (99.0261)  time: 0.3501  data: 0.0014  max mem: 2503
Train: Epoch[5/5]  [1870/3750]  eta: 0:10:58  Lr: 0.001875  Loss: -1.1315  Acc@1: 87.5000 (81.1732)  Acc@5: 100.0000 (99.0246)  time: 0.3496  data: 0.0012  max mem: 2503
Train: Epoch[5/5]  [1880/3750]  eta: 0:10:54  Lr: 0.001875  Loss: -0.9869  Acc@1: 81.2500 (81.1802)  Acc@5: 100.0000 (99.0231)  time: 0.3485  data: 0.0007  max mem: 2503
Train: Epoch[5/5]  [1890/3750]  eta: 0:10:51  Lr: 0.001875  Loss: -0.7452  Acc@1: 81.2500 (81.1674)  Acc@5: 100.0000 (99.0184)  time: 0.3490  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [1900/3750]  eta: 0:10:47  Lr: 0.001875  Loss: -0.8730  Acc@1: 81.2500 (81.1744)  Acc@5: 100.0000 (99.0203)  time: 0.3487  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [1910/3750]  eta: 0:10:44  Lr: 0.001875  Loss: -0.7049  Acc@1: 81.2500 (81.1584)  Acc@5: 100.0000 (99.0221)  time: 0.3490  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [1920/3750]  eta: 0:10:40  Lr: 0.001875  Loss: -0.7093  Acc@1: 81.2500 (81.1556)  Acc@5: 100.0000 (99.0142)  time: 0.3503  data: 0.0006  max mem: 2503
Train: Epoch[5/5]  [1930/3750]  eta: 0:10:37  Lr: 0.001875  Loss: -0.8502  Acc@1: 81.2500 (81.1626)  Acc@5: 100.0000 (99.0096)  time: 0.3499  data: 0.0007  max mem: 2503
Train: Epoch[5/5]  [1940/3750]  eta: 0:10:33  Lr: 0.001875  Loss: -0.3529  Acc@1: 81.2500 (81.1566)  Acc@5: 100.0000 (99.0115)  time: 0.3503  data: 0.0006  max mem: 2503
Train: Epoch[5/5]  [1950/3750]  eta: 0:10:30  Lr: 0.001875  Loss: -0.6323  Acc@1: 81.2500 (81.1635)  Acc@5: 100.0000 (99.0133)  time: 0.3505  data: 0.0007  max mem: 2503
Train: Epoch[5/5]  [1960/3750]  eta: 0:10:26  Lr: 0.001875  Loss: -0.9078  Acc@1: 81.2500 (81.1799)  Acc@5: 100.0000 (99.0152)  time: 0.3498  data: 0.0007  max mem: 2503
Train: Epoch[5/5]  [1970/3750]  eta: 0:10:23  Lr: 0.001875  Loss: -0.9478  Acc@1: 81.2500 (81.1834)  Acc@5: 100.0000 (99.0170)  time: 0.3498  data: 0.0006  max mem: 2503
Train: Epoch[5/5]  [1980/3750]  eta: 0:10:19  Lr: 0.001875  Loss: -0.6942  Acc@1: 81.2500 (81.1837)  Acc@5: 100.0000 (99.0125)  time: 0.3497  data: 0.0006  max mem: 2503
Train: Epoch[5/5]  [1990/3750]  eta: 0:10:16  Lr: 0.001875  Loss: -0.1387  Acc@1: 81.2500 (81.1966)  Acc@5: 100.0000 (99.0112)  time: 0.3501  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [2000/3750]  eta: 0:10:12  Lr: 0.001875  Loss: -0.7650  Acc@1: 81.2500 (81.1844)  Acc@5: 100.0000 (99.0067)  time: 0.3517  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [2010/3750]  eta: 0:10:09  Lr: 0.001875  Loss: -1.0550  Acc@1: 81.2500 (81.2158)  Acc@5: 100.0000 (99.0117)  time: 0.3513  data: 0.0010  max mem: 2503
Train: Epoch[5/5]  [2020/3750]  eta: 0:10:05  Lr: 0.001875  Loss: -0.4765  Acc@1: 81.2500 (81.1912)  Acc@5: 100.0000 (99.0011)  time: 0.3495  data: 0.0010  max mem: 2503
Train: Epoch[5/5]  [2030/3750]  eta: 0:10:02  Lr: 0.001875  Loss: -0.9357  Acc@1: 81.2500 (81.2192)  Acc@5: 100.0000 (98.9999)  time: 0.3496  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [2040/3750]  eta: 0:09:58  Lr: 0.001875  Loss: -0.9849  Acc@1: 81.2500 (81.2224)  Acc@5: 100.0000 (98.9987)  time: 0.3495  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [2050/3750]  eta: 0:09:55  Lr: 0.001875  Loss: -1.0583  Acc@1: 81.2500 (81.2104)  Acc@5: 100.0000 (98.9974)  time: 0.3497  data: 0.0009  max mem: 2503
Train: Epoch[5/5]  [2060/3750]  eta: 0:09:51  Lr: 0.001875  Loss: -0.7858  Acc@1: 75.0000 (81.2136)  Acc@5: 100.0000 (98.9962)  time: 0.3507  data: 0.0009  max mem: 2503
Train: Epoch[5/5]  [2070/3750]  eta: 0:09:48  Lr: 0.001875  Loss: -0.7722  Acc@1: 81.2500 (81.1927)  Acc@5: 100.0000 (99.0011)  time: 0.3501  data: 0.0006  max mem: 2503
Train: Epoch[5/5]  [2080/3750]  eta: 0:09:44  Lr: 0.001875  Loss: -0.9212  Acc@1: 81.2500 (81.2019)  Acc@5: 100.0000 (98.9999)  time: 0.3493  data: 0.0006  max mem: 2503
Train: Epoch[5/5]  [2090/3750]  eta: 0:09:41  Lr: 0.001875  Loss: -1.1986  Acc@1: 81.2500 (81.1932)  Acc@5: 100.0000 (98.9957)  time: 0.3495  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [2100/3750]  eta: 0:09:37  Lr: 0.001875  Loss: -0.7513  Acc@1: 81.2500 (81.1905)  Acc@5: 100.0000 (98.9975)  time: 0.3510  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [2110/3750]  eta: 0:09:34  Lr: 0.001875  Loss: -0.9330  Acc@1: 81.2500 (81.1997)  Acc@5: 100.0000 (98.9963)  time: 0.3516  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [2120/3750]  eta: 0:09:30  Lr: 0.001875  Loss: -0.9412  Acc@1: 81.2500 (81.2058)  Acc@5: 100.0000 (98.9952)  time: 0.3510  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [2130/3750]  eta: 0:09:27  Lr: 0.001875  Loss: -0.4541  Acc@1: 81.2500 (81.1767)  Acc@5: 100.0000 (98.9940)  time: 0.3504  data: 0.0006  max mem: 2503
Train: Epoch[5/5]  [2140/3750]  eta: 0:09:23  Lr: 0.001875  Loss: 0.0820  Acc@1: 81.2500 (81.1770)  Acc@5: 100.0000 (98.9929)  time: 0.3504  data: 0.0009  max mem: 2503
Train: Epoch[5/5]  [2150/3750]  eta: 0:09:20  Lr: 0.001875  Loss: -1.2108  Acc@1: 87.5000 (81.1977)  Acc@5: 100.0000 (98.9917)  time: 0.3507  data: 0.0007  max mem: 2503
Train: Epoch[5/5]  [2160/3750]  eta: 0:09:16  Lr: 0.001875  Loss: -0.7583  Acc@1: 87.5000 (81.2124)  Acc@5: 100.0000 (98.9935)  time: 0.3505  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [2170/3750]  eta: 0:09:13  Lr: 0.001875  Loss: -1.1679  Acc@1: 87.5000 (81.2270)  Acc@5: 100.0000 (98.9953)  time: 0.3500  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [2180/3750]  eta: 0:09:09  Lr: 0.001875  Loss: -0.6593  Acc@1: 81.2500 (81.2213)  Acc@5: 100.0000 (98.9913)  time: 0.3498  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [2190/3750]  eta: 0:09:06  Lr: 0.001875  Loss: -0.8596  Acc@1: 75.0000 (81.2044)  Acc@5: 100.0000 (98.9873)  time: 0.3501  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [2200/3750]  eta: 0:09:02  Lr: 0.001875  Loss: -0.8486  Acc@1: 81.2500 (81.2102)  Acc@5: 100.0000 (98.9891)  time: 0.3497  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [2210/3750]  eta: 0:08:59  Lr: 0.001875  Loss: -0.8453  Acc@1: 87.5000 (81.2330)  Acc@5: 100.0000 (98.9908)  time: 0.3491  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [2220/3750]  eta: 0:08:55  Lr: 0.001875  Loss: -0.8721  Acc@1: 81.2500 (81.2303)  Acc@5: 100.0000 (98.9869)  time: 0.3502  data: 0.0006  max mem: 2503
Train: Epoch[5/5]  [2230/3750]  eta: 0:08:52  Lr: 0.001875  Loss: -0.8247  Acc@1: 81.2500 (81.2052)  Acc@5: 100.0000 (98.9915)  time: 0.3511  data: 0.0012  max mem: 2503
Train: Epoch[5/5]  [2240/3750]  eta: 0:08:48  Lr: 0.001875  Loss: -1.0165  Acc@1: 75.0000 (81.1859)  Acc@5: 100.0000 (98.9932)  time: 0.3509  data: 0.0012  max mem: 2503
Train: Epoch[5/5]  [2250/3750]  eta: 0:08:45  Lr: 0.001875  Loss: -1.1396  Acc@1: 75.0000 (81.1723)  Acc@5: 100.0000 (98.9977)  time: 0.3506  data: 0.0009  max mem: 2503
Train: Epoch[5/5]  [2260/3750]  eta: 0:08:41  Lr: 0.001875  Loss: -0.7045  Acc@1: 81.2500 (81.1781)  Acc@5: 100.0000 (98.9938)  time: 0.3501  data: 0.0009  max mem: 2503
Train: Epoch[5/5]  [2270/3750]  eta: 0:08:38  Lr: 0.001875  Loss: -0.9707  Acc@1: 81.2500 (81.1812)  Acc@5: 100.0000 (98.9955)  time: 0.3499  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [2280/3750]  eta: 0:08:34  Lr: 0.001875  Loss: -0.9809  Acc@1: 81.2500 (81.1870)  Acc@5: 100.0000 (98.9944)  time: 0.3506  data: 0.0007  max mem: 2503
Train: Epoch[5/5]  [2290/3750]  eta: 0:08:31  Lr: 0.001875  Loss: -0.0469  Acc@1: 81.2500 (81.1600)  Acc@5: 100.0000 (98.9933)  time: 0.3503  data: 0.0007  max mem: 2503
Train: Epoch[5/5]  [2300/3750]  eta: 0:08:27  Lr: 0.001875  Loss: -0.7036  Acc@1: 81.2500 (81.1712)  Acc@5: 100.0000 (98.9950)  time: 0.3497  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [2310/3750]  eta: 0:08:24  Lr: 0.001875  Loss: -0.9026  Acc@1: 75.0000 (81.1364)  Acc@5: 100.0000 (98.9966)  time: 0.3498  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [2320/3750]  eta: 0:08:20  Lr: 0.001875  Loss: -0.8384  Acc@1: 75.0000 (81.1315)  Acc@5: 100.0000 (98.9929)  time: 0.3507  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [2330/3750]  eta: 0:08:17  Lr: 0.001875  Loss: -0.5225  Acc@1: 81.2500 (81.1240)  Acc@5: 100.0000 (98.9892)  time: 0.3503  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [2340/3750]  eta: 0:08:13  Lr: 0.001875  Loss: -1.0521  Acc@1: 81.2500 (81.1245)  Acc@5: 100.0000 (98.9855)  time: 0.3499  data: 0.0006  max mem: 2503
Train: Epoch[5/5]  [2350/3750]  eta: 0:08:10  Lr: 0.001875  Loss: -0.3637  Acc@1: 81.2500 (81.1197)  Acc@5: 100.0000 (98.9871)  time: 0.3508  data: 0.0007  max mem: 2503
Train: Epoch[5/5]  [2360/3750]  eta: 0:08:06  Lr: 0.001875  Loss: -0.5071  Acc@1: 81.2500 (81.1097)  Acc@5: 100.0000 (98.9861)  time: 0.3506  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [2370/3750]  eta: 0:08:03  Lr: 0.001875  Loss: -0.7059  Acc@1: 75.0000 (81.0892)  Acc@5: 100.0000 (98.9904)  time: 0.3503  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [2380/3750]  eta: 0:07:59  Lr: 0.001875  Loss: -0.6643  Acc@1: 81.2500 (81.0951)  Acc@5: 100.0000 (98.9894)  time: 0.3495  data: 0.0006  max mem: 2503
Train: Epoch[5/5]  [2390/3750]  eta: 0:07:56  Lr: 0.001875  Loss: -0.7845  Acc@1: 81.2500 (81.0984)  Acc@5: 100.0000 (98.9884)  time: 0.3494  data: 0.0006  max mem: 2503
Train: Epoch[5/5]  [2400/3750]  eta: 0:07:52  Lr: 0.001875  Loss: -0.7551  Acc@1: 81.2500 (81.0938)  Acc@5: 100.0000 (98.9900)  time: 0.3497  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [2410/3750]  eta: 0:07:49  Lr: 0.001875  Loss: -0.9931  Acc@1: 81.2500 (81.0945)  Acc@5: 100.0000 (98.9890)  time: 0.3496  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [2420/3750]  eta: 0:07:45  Lr: 0.001875  Loss: -0.5422  Acc@1: 81.2500 (81.1003)  Acc@5: 100.0000 (98.9906)  time: 0.3493  data: 0.0006  max mem: 2503
Train: Epoch[5/5]  [2430/3750]  eta: 0:07:42  Lr: 0.001875  Loss: -1.0516  Acc@1: 81.2500 (81.1060)  Acc@5: 100.0000 (98.9896)  time: 0.3492  data: 0.0010  max mem: 2503
Train: Epoch[5/5]  [2440/3750]  eta: 0:07:38  Lr: 0.001875  Loss: -0.8079  Acc@1: 81.2500 (81.1297)  Acc@5: 100.0000 (98.9912)  time: 0.3488  data: 0.0011  max mem: 2503
Train: Epoch[5/5]  [2450/3750]  eta: 0:07:35  Lr: 0.001875  Loss: -0.9610  Acc@1: 81.2500 (81.1251)  Acc@5: 100.0000 (98.9902)  time: 0.3478  data: 0.0007  max mem: 2503
Train: Epoch[5/5]  [2460/3750]  eta: 0:07:31  Lr: 0.001875  Loss: -0.8430  Acc@1: 81.2500 (81.1179)  Acc@5: 100.0000 (98.9943)  time: 0.3475  data: 0.0007  max mem: 2503
Train: Epoch[5/5]  [2470/3750]  eta: 0:07:28  Lr: 0.001875  Loss: -0.4264  Acc@1: 75.0000 (81.1058)  Acc@5: 100.0000 (98.9883)  time: 0.3481  data: 0.0007  max mem: 2503
Train: Epoch[5/5]  [2480/3750]  eta: 0:07:24  Lr: 0.001875  Loss: -0.4892  Acc@1: 81.2500 (81.1140)  Acc@5: 100.0000 (98.9873)  time: 0.3480  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [2490/3750]  eta: 0:07:21  Lr: 0.001875  Loss: -0.3216  Acc@1: 81.2500 (81.0944)  Acc@5: 100.0000 (98.9864)  time: 0.3478  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [2500/3750]  eta: 0:07:17  Lr: 0.001875  Loss: -0.3922  Acc@1: 75.0000 (81.0926)  Acc@5: 100.0000 (98.9879)  time: 0.3478  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [2510/3750]  eta: 0:07:14  Lr: 0.001875  Loss: -0.8082  Acc@1: 81.2500 (81.0982)  Acc@5: 100.0000 (98.9894)  time: 0.3471  data: 0.0003  max mem: 2503
Train: Epoch[5/5]  [2520/3750]  eta: 0:07:10  Lr: 0.001875  Loss: -1.0159  Acc@1: 81.2500 (81.1037)  Acc@5: 100.0000 (98.9910)  time: 0.3468  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [2530/3750]  eta: 0:07:07  Lr: 0.001875  Loss: -0.9407  Acc@1: 87.5000 (81.1241)  Acc@5: 100.0000 (98.9876)  time: 0.3497  data: 0.0006  max mem: 2503
Train: Epoch[5/5]  [2540/3750]  eta: 0:07:03  Lr: 0.001875  Loss: -0.7041  Acc@1: 81.2500 (81.1073)  Acc@5: 100.0000 (98.9842)  time: 0.3505  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [2550/3750]  eta: 0:07:00  Lr: 0.001875  Loss: -1.1365  Acc@1: 81.2500 (81.1128)  Acc@5: 100.0000 (98.9857)  time: 0.3479  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [2560/3750]  eta: 0:06:56  Lr: 0.001875  Loss: -0.9848  Acc@1: 81.2500 (81.0963)  Acc@5: 100.0000 (98.9823)  time: 0.3472  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [2570/3750]  eta: 0:06:52  Lr: 0.001875  Loss: -0.2797  Acc@1: 81.2500 (81.0968)  Acc@5: 100.0000 (98.9790)  time: 0.3472  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [2580/3750]  eta: 0:06:49  Lr: 0.001875  Loss: -1.0166  Acc@1: 81.2500 (81.0878)  Acc@5: 100.0000 (98.9805)  time: 0.3467  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [2590/3750]  eta: 0:06:45  Lr: 0.001875  Loss: -0.6696  Acc@1: 87.5000 (81.1101)  Acc@5: 100.0000 (98.9845)  time: 0.3462  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [2600/3750]  eta: 0:06:42  Lr: 0.001875  Loss: -0.9476  Acc@1: 81.2500 (81.1010)  Acc@5: 100.0000 (98.9884)  time: 0.3473  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [2610/3750]  eta: 0:06:38  Lr: 0.001875  Loss: -0.7828  Acc@1: 81.2500 (81.1183)  Acc@5: 100.0000 (98.9875)  time: 0.3476  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [2620/3750]  eta: 0:06:35  Lr: 0.001875  Loss: -1.0792  Acc@1: 87.5000 (81.1284)  Acc@5: 100.0000 (98.9842)  time: 0.3474  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [2630/3750]  eta: 0:06:31  Lr: 0.001875  Loss: -1.2192  Acc@1: 87.5000 (81.1550)  Acc@5: 100.0000 (98.9880)  time: 0.3474  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [2640/3750]  eta: 0:06:28  Lr: 0.001875  Loss: -0.8096  Acc@1: 87.5000 (81.1624)  Acc@5: 100.0000 (98.9895)  time: 0.3478  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [2650/3750]  eta: 0:06:24  Lr: 0.001875  Loss: -1.1102  Acc@1: 81.2500 (81.1463)  Acc@5: 100.0000 (98.9886)  time: 0.3479  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [2660/3750]  eta: 0:06:21  Lr: 0.001875  Loss: -0.8901  Acc@1: 81.2500 (81.1467)  Acc@5: 100.0000 (98.9900)  time: 0.3485  data: 0.0012  max mem: 2503
Train: Epoch[5/5]  [2670/3750]  eta: 0:06:17  Lr: 0.001875  Loss: -0.9369  Acc@1: 81.2500 (81.1353)  Acc@5: 100.0000 (98.9915)  time: 0.3492  data: 0.0012  max mem: 2503
Train: Epoch[5/5]  [2680/3750]  eta: 0:06:14  Lr: 0.001875  Loss: -0.3384  Acc@1: 81.2500 (81.1474)  Acc@5: 100.0000 (98.9906)  time: 0.3479  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [2690/3750]  eta: 0:06:10  Lr: 0.001875  Loss: -0.7472  Acc@1: 87.5000 (81.1641)  Acc@5: 100.0000 (98.9897)  time: 0.3472  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [2700/3750]  eta: 0:06:07  Lr: 0.001875  Loss: -0.1388  Acc@1: 87.5000 (81.1713)  Acc@5: 100.0000 (98.9911)  time: 0.3473  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [2710/3750]  eta: 0:06:03  Lr: 0.001875  Loss: -0.4582  Acc@1: 81.2500 (81.1670)  Acc@5: 100.0000 (98.9856)  time: 0.3484  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [2720/3750]  eta: 0:06:00  Lr: 0.001875  Loss: -0.6582  Acc@1: 81.2500 (81.1742)  Acc@5: 100.0000 (98.9870)  time: 0.3488  data: 0.0006  max mem: 2503
Train: Epoch[5/5]  [2730/3750]  eta: 0:05:56  Lr: 0.001875  Loss: -1.0249  Acc@1: 81.2500 (81.1836)  Acc@5: 100.0000 (98.9839)  time: 0.3480  data: 0.0006  max mem: 2503
Train: Epoch[5/5]  [2740/3750]  eta: 0:05:53  Lr: 0.001875  Loss: -0.3870  Acc@1: 81.2500 (81.1793)  Acc@5: 100.0000 (98.9876)  time: 0.3493  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [2750/3750]  eta: 0:05:49  Lr: 0.001875  Loss: -0.8488  Acc@1: 81.2500 (81.1796)  Acc@5: 100.0000 (98.9890)  time: 0.3503  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [2760/3750]  eta: 0:05:46  Lr: 0.001875  Loss: -0.7102  Acc@1: 75.0000 (81.1753)  Acc@5: 100.0000 (98.9881)  time: 0.3498  data: 0.0007  max mem: 2503
Train: Epoch[5/5]  [2770/3750]  eta: 0:05:42  Lr: 0.001875  Loss: -1.0021  Acc@1: 81.2500 (81.1756)  Acc@5: 100.0000 (98.9873)  time: 0.3502  data: 0.0006  max mem: 2503
Train: Epoch[5/5]  [2780/3750]  eta: 0:05:39  Lr: 0.001875  Loss: -0.7295  Acc@1: 81.2500 (81.1713)  Acc@5: 100.0000 (98.9864)  time: 0.3506  data: 0.0008  max mem: 2503
Train: Epoch[5/5]  [2790/3750]  eta: 0:05:35  Lr: 0.001875  Loss: -0.8816  Acc@1: 81.2500 (81.1649)  Acc@5: 100.0000 (98.9811)  time: 0.3501  data: 0.0008  max mem: 2503
Train: Epoch[5/5]  [2800/3750]  eta: 0:05:32  Lr: 0.001875  Loss: -0.5714  Acc@1: 75.0000 (81.1585)  Acc@5: 100.0000 (98.9803)  time: 0.3498  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [2810/3750]  eta: 0:05:28  Lr: 0.001875  Loss: -0.7931  Acc@1: 81.2500 (81.1566)  Acc@5: 100.0000 (98.9795)  time: 0.3502  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [2820/3750]  eta: 0:05:25  Lr: 0.001875  Loss: -0.5139  Acc@1: 81.2500 (81.1614)  Acc@5: 100.0000 (98.9786)  time: 0.3502  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [2830/3750]  eta: 0:05:21  Lr: 0.001875  Loss: -1.1768  Acc@1: 81.2500 (81.1749)  Acc@5: 100.0000 (98.9823)  time: 0.3497  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [2840/3750]  eta: 0:05:18  Lr: 0.001875  Loss: -0.8639  Acc@1: 81.2500 (81.1774)  Acc@5: 100.0000 (98.9836)  time: 0.3499  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [2850/3750]  eta: 0:05:14  Lr: 0.001875  Loss: -0.7203  Acc@1: 81.2500 (81.1623)  Acc@5: 100.0000 (98.9850)  time: 0.3508  data: 0.0006  max mem: 2503
Train: Epoch[5/5]  [2860/3750]  eta: 0:05:11  Lr: 0.001875  Loss: -0.7898  Acc@1: 75.0000 (81.1539)  Acc@5: 100.0000 (98.9886)  time: 0.3507  data: 0.0006  max mem: 2503
Train: Epoch[5/5]  [2870/3750]  eta: 0:05:07  Lr: 0.001875  Loss: -0.7313  Acc@1: 81.2500 (81.1607)  Acc@5: 100.0000 (98.9877)  time: 0.3513  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [2880/3750]  eta: 0:05:04  Lr: 0.001875  Loss: -0.7888  Acc@1: 81.2500 (81.1806)  Acc@5: 100.0000 (98.9912)  time: 0.3519  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [2890/3750]  eta: 0:05:00  Lr: 0.001875  Loss: -1.1706  Acc@1: 81.2500 (81.1938)  Acc@5: 100.0000 (98.9947)  time: 0.3510  data: 0.0006  max mem: 2503
Train: Epoch[5/5]  [2900/3750]  eta: 0:04:57  Lr: 0.001875  Loss: -0.5704  Acc@1: 81.2500 (81.1767)  Acc@5: 100.0000 (98.9939)  time: 0.3517  data: 0.0014  max mem: 2503
Train: Epoch[5/5]  [2910/3750]  eta: 0:04:53  Lr: 0.001875  Loss: -0.8288  Acc@1: 87.5000 (81.1985)  Acc@5: 100.0000 (98.9952)  time: 0.3529  data: 0.0016  max mem: 2503
Train: Epoch[5/5]  [2920/3750]  eta: 0:04:50  Lr: 0.001875  Loss: -0.7175  Acc@1: 87.5000 (81.2051)  Acc@5: 100.0000 (98.9944)  time: 0.3527  data: 0.0008  max mem: 2503
Train: Epoch[5/5]  [2930/3750]  eta: 0:04:46  Lr: 0.001875  Loss: -0.8669  Acc@1: 81.2500 (81.2010)  Acc@5: 100.0000 (98.9956)  time: 0.3535  data: 0.0006  max mem: 2503
Train: Epoch[5/5]  [2940/3750]  eta: 0:04:43  Lr: 0.001875  Loss: -0.6469  Acc@1: 81.2500 (81.1969)  Acc@5: 100.0000 (98.9969)  time: 0.3524  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [2950/3750]  eta: 0:04:39  Lr: 0.001875  Loss: -0.8546  Acc@1: 81.2500 (81.1928)  Acc@5: 100.0000 (98.9961)  time: 0.3516  data: 0.0013  max mem: 2503
Train: Epoch[5/5]  [2960/3750]  eta: 0:04:36  Lr: 0.001875  Loss: -0.9823  Acc@1: 81.2500 (81.1888)  Acc@5: 100.0000 (98.9953)  time: 0.3531  data: 0.0014  max mem: 2503
Train: Epoch[5/5]  [2970/3750]  eta: 0:04:32  Lr: 0.001875  Loss: -0.7551  Acc@1: 81.2500 (81.1764)  Acc@5: 100.0000 (98.9923)  time: 0.3517  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [2980/3750]  eta: 0:04:29  Lr: 0.001875  Loss: -0.9562  Acc@1: 81.2500 (81.1850)  Acc@5: 100.0000 (98.9873)  time: 0.3506  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [2990/3750]  eta: 0:04:25  Lr: 0.001875  Loss: -0.8853  Acc@1: 87.5000 (81.2019)  Acc@5: 100.0000 (98.9803)  time: 0.3516  data: 0.0006  max mem: 2503
Train: Epoch[5/5]  [3000/3750]  eta: 0:04:22  Lr: 0.001875  Loss: -0.7447  Acc@1: 81.2500 (81.1959)  Acc@5: 100.0000 (98.9795)  time: 0.3518  data: 0.0006  max mem: 2503
Train: Epoch[5/5]  [3010/3750]  eta: 0:04:18  Lr: 0.001875  Loss: -0.6879  Acc@1: 81.2500 (81.1981)  Acc@5: 100.0000 (98.9767)  time: 0.3506  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [3020/3750]  eta: 0:04:15  Lr: 0.001875  Loss: -0.3125  Acc@1: 81.2500 (81.2024)  Acc@5: 100.0000 (98.9759)  time: 0.3503  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [3030/3750]  eta: 0:04:11  Lr: 0.001875  Loss: -0.5860  Acc@1: 81.2500 (81.2170)  Acc@5: 100.0000 (98.9772)  time: 0.3509  data: 0.0014  max mem: 2503
Train: Epoch[5/5]  [3040/3750]  eta: 0:04:08  Lr: 0.001875  Loss: -0.8302  Acc@1: 87.5000 (81.2068)  Acc@5: 100.0000 (98.9724)  time: 0.3516  data: 0.0014  max mem: 2503
Train: Epoch[5/5]  [3050/3750]  eta: 0:04:05  Lr: 0.001875  Loss: -0.6743  Acc@1: 81.2500 (81.2008)  Acc@5: 100.0000 (98.9737)  time: 0.3525  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [3060/3750]  eta: 0:04:01  Lr: 0.001875  Loss: -0.7471  Acc@1: 81.2500 (81.1928)  Acc@5: 100.0000 (98.9709)  time: 0.3514  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [3070/3750]  eta: 0:03:58  Lr: 0.001875  Loss: -0.2086  Acc@1: 81.2500 (81.1869)  Acc@5: 100.0000 (98.9722)  time: 0.3496  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [3080/3750]  eta: 0:03:54  Lr: 0.001875  Loss: -1.0212  Acc@1: 81.2500 (81.1871)  Acc@5: 100.0000 (98.9756)  time: 0.3500  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [3090/3750]  eta: 0:03:51  Lr: 0.001875  Loss: -0.4979  Acc@1: 81.2500 (81.1934)  Acc@5: 100.0000 (98.9728)  time: 0.3500  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [3100/3750]  eta: 0:03:47  Lr: 0.001875  Loss: -0.6867  Acc@1: 87.5000 (81.2157)  Acc@5: 100.0000 (98.9761)  time: 0.3504  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [3110/3750]  eta: 0:03:44  Lr: 0.001875  Loss: -0.4545  Acc@1: 81.2500 (81.2058)  Acc@5: 100.0000 (98.9714)  time: 0.3510  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [3120/3750]  eta: 0:03:40  Lr: 0.001875  Loss: -0.7525  Acc@1: 81.2500 (81.2039)  Acc@5: 100.0000 (98.9707)  time: 0.3508  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [3130/3750]  eta: 0:03:37  Lr: 0.001875  Loss: -0.7783  Acc@1: 81.2500 (81.1961)  Acc@5: 100.0000 (98.9700)  time: 0.3516  data: 0.0018  max mem: 2503
Train: Epoch[5/5]  [3140/3750]  eta: 0:03:33  Lr: 0.001875  Loss: -0.0442  Acc@1: 81.2500 (81.1923)  Acc@5: 100.0000 (98.9633)  time: 0.3515  data: 0.0023  max mem: 2503
Train: Epoch[5/5]  [3150/3750]  eta: 0:03:30  Lr: 0.001875  Loss: -0.8006  Acc@1: 81.2500 (81.2064)  Acc@5: 100.0000 (98.9646)  time: 0.3502  data: 0.0009  max mem: 2503
Train: Epoch[5/5]  [3160/3750]  eta: 0:03:26  Lr: 0.001875  Loss: -0.4616  Acc@1: 81.2500 (81.1986)  Acc@5: 100.0000 (98.9639)  time: 0.3500  data: 0.0006  max mem: 2503
Train: Epoch[5/5]  [3170/3750]  eta: 0:03:23  Lr: 0.001875  Loss: -0.5790  Acc@1: 75.0000 (81.1869)  Acc@5: 100.0000 (98.9633)  time: 0.3505  data: 0.0006  max mem: 2503
Train: Epoch[5/5]  [3180/3750]  eta: 0:03:19  Lr: 0.001875  Loss: -0.9029  Acc@1: 75.0000 (81.1852)  Acc@5: 100.0000 (98.9626)  time: 0.3506  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [3190/3750]  eta: 0:03:16  Lr: 0.001875  Loss: -0.8789  Acc@1: 81.2500 (81.1834)  Acc@5: 100.0000 (98.9619)  time: 0.3498  data: 0.0006  max mem: 2503
Train: Epoch[5/5]  [3200/3750]  eta: 0:03:12  Lr: 0.001875  Loss: -0.9425  Acc@1: 81.2500 (81.1758)  Acc@5: 100.0000 (98.9613)  time: 0.3493  data: 0.0008  max mem: 2503
Train: Epoch[5/5]  [3210/3750]  eta: 0:03:09  Lr: 0.001875  Loss: -0.7998  Acc@1: 81.2500 (81.1741)  Acc@5: 100.0000 (98.9626)  time: 0.3504  data: 0.0007  max mem: 2503
Train: Epoch[5/5]  [3220/3750]  eta: 0:03:05  Lr: 0.001875  Loss: -0.9956  Acc@1: 81.2500 (81.1801)  Acc@5: 100.0000 (98.9658)  time: 0.3518  data: 0.0007  max mem: 2503
Train: Epoch[5/5]  [3230/3750]  eta: 0:03:02  Lr: 0.001875  Loss: -0.9887  Acc@1: 81.2500 (81.1804)  Acc@5: 100.0000 (98.9651)  time: 0.3507  data: 0.0007  max mem: 2503
Train: Epoch[5/5]  [3240/3750]  eta: 0:02:58  Lr: 0.001875  Loss: -0.5679  Acc@1: 81.2500 (81.1825)  Acc@5: 100.0000 (98.9644)  time: 0.3489  data: 0.0006  max mem: 2503
Train: Epoch[5/5]  [3250/3750]  eta: 0:02:55  Lr: 0.001875  Loss: -0.5651  Acc@1: 81.2500 (81.1808)  Acc@5: 100.0000 (98.9657)  time: 0.3488  data: 0.0006  max mem: 2503
Train: Epoch[5/5]  [3260/3750]  eta: 0:02:51  Lr: 0.001875  Loss: -0.9158  Acc@1: 75.0000 (81.1695)  Acc@5: 100.0000 (98.9650)  time: 0.3494  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [3270/3750]  eta: 0:02:48  Lr: 0.001875  Loss: -0.3690  Acc@1: 75.0000 (81.1602)  Acc@5: 100.0000 (98.9663)  time: 0.3500  data: 0.0006  max mem: 2503
Train: Epoch[5/5]  [3280/3750]  eta: 0:02:44  Lr: 0.001875  Loss: -1.1163  Acc@1: 81.2500 (81.1643)  Acc@5: 100.0000 (98.9694)  time: 0.3505  data: 0.0010  max mem: 2503
Train: Epoch[5/5]  [3290/3750]  eta: 0:02:41  Lr: 0.001875  Loss: -0.8863  Acc@1: 87.5000 (81.1702)  Acc@5: 100.0000 (98.9726)  time: 0.3495  data: 0.0009  max mem: 2503
Train: Epoch[5/5]  [3300/3750]  eta: 0:02:37  Lr: 0.001875  Loss: -0.5723  Acc@1: 81.2500 (81.1629)  Acc@5: 100.0000 (98.9757)  time: 0.3495  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [3310/3750]  eta: 0:02:34  Lr: 0.001875  Loss: -0.5877  Acc@1: 81.2500 (81.1688)  Acc@5: 100.0000 (98.9750)  time: 0.3503  data: 0.0007  max mem: 2503
Train: Epoch[5/5]  [3320/3750]  eta: 0:02:30  Lr: 0.001875  Loss: -0.7948  Acc@1: 87.5000 (81.1822)  Acc@5: 100.0000 (98.9762)  time: 0.3500  data: 0.0006  max mem: 2503
Train: Epoch[5/5]  [3330/3750]  eta: 0:02:27  Lr: 0.001875  Loss: -0.0685  Acc@1: 87.5000 (81.1787)  Acc@5: 100.0000 (98.9755)  time: 0.3498  data: 0.0008  max mem: 2503
Train: Epoch[5/5]  [3340/3750]  eta: 0:02:23  Lr: 0.001875  Loss: -0.8806  Acc@1: 81.2500 (81.1770)  Acc@5: 100.0000 (98.9767)  time: 0.3509  data: 0.0023  max mem: 2503
Train: Epoch[5/5]  [3350/3750]  eta: 0:02:20  Lr: 0.001875  Loss: -0.3775  Acc@1: 81.2500 (81.1829)  Acc@5: 100.0000 (98.9761)  time: 0.3512  data: 0.0020  max mem: 2503
Train: Epoch[5/5]  [3360/3750]  eta: 0:02:16  Lr: 0.001875  Loss: -0.9872  Acc@1: 81.2500 (81.1775)  Acc@5: 100.0000 (98.9772)  time: 0.3496  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [3370/3750]  eta: 0:02:13  Lr: 0.001875  Loss: -0.5701  Acc@1: 75.0000 (81.1777)  Acc@5: 100.0000 (98.9784)  time: 0.3506  data: 0.0010  max mem: 2503
Train: Epoch[5/5]  [3380/3750]  eta: 0:02:09  Lr: 0.001875  Loss: -0.5489  Acc@1: 81.2500 (81.1853)  Acc@5: 100.0000 (98.9814)  time: 0.3520  data: 0.0011  max mem: 2503
Train: Epoch[5/5]  [3390/3750]  eta: 0:02:06  Lr: 0.001875  Loss: -1.1183  Acc@1: 81.2500 (81.1965)  Acc@5: 100.0000 (98.9844)  time: 0.3517  data: 0.0006  max mem: 2503
Train: Epoch[5/5]  [3400/3750]  eta: 0:02:02  Lr: 0.001875  Loss: -0.7308  Acc@1: 81.2500 (81.1949)  Acc@5: 100.0000 (98.9856)  time: 0.3502  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [3410/3750]  eta: 0:01:59  Lr: 0.001875  Loss: -0.7266  Acc@1: 81.2500 (81.1895)  Acc@5: 100.0000 (98.9886)  time: 0.3501  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [3420/3750]  eta: 0:01:55  Lr: 0.001875  Loss: -0.4989  Acc@1: 81.2500 (81.1897)  Acc@5: 100.0000 (98.9915)  time: 0.3506  data: 0.0007  max mem: 2503
Train: Epoch[5/5]  [3430/3750]  eta: 0:01:52  Lr: 0.001875  Loss: -0.8744  Acc@1: 81.2500 (81.1954)  Acc@5: 100.0000 (98.9945)  time: 0.3509  data: 0.0006  max mem: 2503
Train: Epoch[5/5]  [3440/3750]  eta: 0:01:48  Lr: 0.001875  Loss: -0.8687  Acc@1: 81.2500 (81.1810)  Acc@5: 100.0000 (98.9883)  time: 0.3516  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [3450/3750]  eta: 0:01:45  Lr: 0.001875  Loss: -1.0685  Acc@1: 81.2500 (81.1939)  Acc@5: 100.0000 (98.9912)  time: 0.3510  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [3460/3750]  eta: 0:01:41  Lr: 0.001875  Loss: -0.9420  Acc@1: 81.2500 (81.1922)  Acc@5: 100.0000 (98.9905)  time: 0.3499  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [3470/3750]  eta: 0:01:38  Lr: 0.001875  Loss: -0.8925  Acc@1: 81.2500 (81.1888)  Acc@5: 100.0000 (98.9862)  time: 0.3494  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [3480/3750]  eta: 0:01:34  Lr: 0.001875  Loss: -0.9056  Acc@1: 87.5000 (81.2105)  Acc@5: 100.0000 (98.9838)  time: 0.3505  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [3490/3750]  eta: 0:01:31  Lr: 0.001875  Loss: -0.8595  Acc@1: 87.5000 (81.2214)  Acc@5: 100.0000 (98.9849)  time: 0.3545  data: 0.0006  max mem: 2503
Train: Epoch[5/5]  [3500/3750]  eta: 0:01:27  Lr: 0.001875  Loss: -0.8009  Acc@1: 87.5000 (81.2179)  Acc@5: 100.0000 (98.9878)  time: 0.3536  data: 0.0007  max mem: 2503
Train: Epoch[5/5]  [3510/3750]  eta: 0:01:24  Lr: 0.001875  Loss: -0.9533  Acc@1: 87.5000 (81.2269)  Acc@5: 100.0000 (98.9889)  time: 0.3489  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [3520/3750]  eta: 0:01:20  Lr: 0.001875  Loss: -0.7491  Acc@1: 81.2500 (81.2180)  Acc@5: 100.0000 (98.9900)  time: 0.3484  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [3530/3750]  eta: 0:01:17  Lr: 0.001875  Loss: -1.0332  Acc@1: 81.2500 (81.2252)  Acc@5: 100.0000 (98.9911)  time: 0.3505  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [3540/3750]  eta: 0:01:13  Lr: 0.001875  Loss: -0.7834  Acc@1: 81.2500 (81.2359)  Acc@5: 100.0000 (98.9939)  time: 0.3506  data: 0.0006  max mem: 2503
Train: Epoch[5/5]  [3550/3750]  eta: 0:01:10  Lr: 0.001875  Loss: -0.8973  Acc@1: 81.2500 (81.2359)  Acc@5: 100.0000 (98.9950)  time: 0.3492  data: 0.0012  max mem: 2503
Train: Epoch[5/5]  [3560/3750]  eta: 0:01:06  Lr: 0.001875  Loss: -1.1107  Acc@1: 81.2500 (81.2482)  Acc@5: 100.0000 (98.9943)  time: 0.3492  data: 0.0011  max mem: 2503
Train: Epoch[5/5]  [3570/3750]  eta: 0:01:03  Lr: 0.001875  Loss: -0.8770  Acc@1: 81.2500 (81.2307)  Acc@5: 100.0000 (98.9919)  time: 0.3501  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [3580/3750]  eta: 0:00:59  Lr: 0.001875  Loss: -0.8134  Acc@1: 81.2500 (81.2221)  Acc@5: 100.0000 (98.9929)  time: 0.3496  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [3590/3750]  eta: 0:00:56  Lr: 0.001875  Loss: -0.8251  Acc@1: 81.2500 (81.2169)  Acc@5: 100.0000 (98.9923)  time: 0.3480  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [3600/3750]  eta: 0:00:52  Lr: 0.001875  Loss: -0.7726  Acc@1: 81.2500 (81.2083)  Acc@5: 100.0000 (98.9916)  time: 0.3484  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [3610/3750]  eta: 0:00:49  Lr: 0.001875  Loss: -0.7414  Acc@1: 81.2500 (81.2102)  Acc@5: 100.0000 (98.9944)  time: 0.3489  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [3620/3750]  eta: 0:00:45  Lr: 0.001875  Loss: -0.8522  Acc@1: 81.2500 (81.2068)  Acc@5: 100.0000 (98.9972)  time: 0.3491  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [3630/3750]  eta: 0:00:42  Lr: 0.001875  Loss: -0.6589  Acc@1: 81.2500 (81.2139)  Acc@5: 100.0000 (98.9913)  time: 0.3489  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [3640/3750]  eta: 0:00:38  Lr: 0.001875  Loss: -0.8862  Acc@1: 81.2500 (81.2157)  Acc@5: 100.0000 (98.9924)  time: 0.3486  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [3650/3750]  eta: 0:00:35  Lr: 0.001875  Loss: -0.6799  Acc@1: 81.2500 (81.2055)  Acc@5: 100.0000 (98.9917)  time: 0.3494  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [3660/3750]  eta: 0:00:31  Lr: 0.001875  Loss: -0.7503  Acc@1: 81.2500 (81.2073)  Acc@5: 100.0000 (98.9945)  time: 0.3508  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [3670/3750]  eta: 0:00:28  Lr: 0.001875  Loss: -0.4996  Acc@1: 81.2500 (81.2125)  Acc@5: 100.0000 (98.9955)  time: 0.3502  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [3680/3750]  eta: 0:00:24  Lr: 0.001875  Loss: -0.9842  Acc@1: 81.2500 (81.2211)  Acc@5: 100.0000 (98.9897)  time: 0.3499  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [3690/3750]  eta: 0:00:21  Lr: 0.001875  Loss: -0.6464  Acc@1: 87.5000 (81.2263)  Acc@5: 100.0000 (98.9891)  time: 0.3502  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [3700/3750]  eta: 0:00:17  Lr: 0.001875  Loss: -1.1234  Acc@1: 81.2500 (81.2314)  Acc@5: 100.0000 (98.9918)  time: 0.3493  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [3710/3750]  eta: 0:00:14  Lr: 0.001875  Loss: -0.4882  Acc@1: 81.2500 (81.2315)  Acc@5: 100.0000 (98.9929)  time: 0.3502  data: 0.0020  max mem: 2503
Train: Epoch[5/5]  [3720/3750]  eta: 0:00:10  Lr: 0.001875  Loss: -0.7735  Acc@1: 81.2500 (81.2550)  Acc@5: 100.0000 (98.9939)  time: 0.3517  data: 0.0020  max mem: 2503
Train: Epoch[5/5]  [3730/3750]  eta: 0:00:07  Lr: 0.001875  Loss: -0.4290  Acc@1: 87.5000 (81.2466)  Acc@5: 100.0000 (98.9966)  time: 0.3503  data: 0.0004  max mem: 2503
Train: Epoch[5/5]  [3740/3750]  eta: 0:00:03  Lr: 0.001875  Loss: -0.9420  Acc@1: 81.2500 (81.2467)  Acc@5: 100.0000 (98.9976)  time: 0.3492  data: 0.0005  max mem: 2503
Train: Epoch[5/5]  [3749/3750]  eta: 0:00:00  Lr: 0.001875  Loss: -0.6127  Acc@1: 81.2500 (81.2517)  Acc@5: 100.0000 (98.9983)  time: 0.3502  data: 0.0007  max mem: 2503
Train: Epoch[5/5] Total time: 0:21:53 (0.3503 s / it)
Averaged stats: Lr: 0.001875  Loss: -0.6127  Acc@1: 81.2500 (81.2517)  Acc@5: 100.0000 (98.9983)
Test: [Task 1]  [   0/1627]  eta: 0:15:14  Loss: 3.9786 (3.9786)  Acc@1: 6.2500 (6.2500)  Acc@5: 31.2500 (31.2500)  time: 0.5618  data: 0.3421  max mem: 2503
Test: [Task 1]  [  10/1627]  eta: 0:06:41  Loss: 3.4920 (3.4245)  Acc@1: 12.5000 (13.0682)  Acc@5: 37.5000 (39.7727)  time: 0.2481  data: 0.0314  max mem: 2503
Test: [Task 1]  [  20/1627]  eta: 0:06:16  Loss: 3.3047 (3.3816)  Acc@1: 12.5000 (14.2857)  Acc@5: 37.5000 (41.6667)  time: 0.2177  data: 0.0005  max mem: 2503
Test: [Task 1]  [  30/1627]  eta: 0:06:05  Loss: 3.3047 (3.3936)  Acc@1: 12.5000 (13.7097)  Acc@5: 43.7500 (41.7339)  time: 0.2184  data: 0.0005  max mem: 2503
Test: [Task 1]  [  40/1627]  eta: 0:05:59  Loss: 3.3497 (3.3999)  Acc@1: 12.5000 (13.2622)  Acc@5: 37.5000 (40.0915)  time: 0.2183  data: 0.0003  max mem: 2503
Test: [Task 1]  [  50/1627]  eta: 0:05:54  Loss: 3.2368 (3.3789)  Acc@1: 12.5000 (13.4804)  Acc@5: 37.5000 (40.3186)  time: 0.2184  data: 0.0003  max mem: 2503
Test: [Task 1]  [  60/1627]  eta: 0:05:50  Loss: 3.3760 (3.3850)  Acc@1: 12.5000 (13.2172)  Acc@5: 43.7500 (40.0615)  time: 0.2185  data: 0.0003  max mem: 2503
Test: [Task 1]  [  70/1627]  eta: 0:05:47  Loss: 3.4443 (3.3830)  Acc@1: 12.5000 (13.5563)  Acc@5: 37.5000 (39.9648)  time: 0.2193  data: 0.0009  max mem: 2503
Test: [Task 1]  [  80/1627]  eta: 0:05:44  Loss: 3.3476 (3.3736)  Acc@1: 12.5000 (13.4259)  Acc@5: 43.7500 (40.5093)  time: 0.2192  data: 0.0009  max mem: 2503
Test: [Task 1]  [  90/1627]  eta: 0:05:41  Loss: 3.2881 (3.3762)  Acc@1: 12.5000 (13.4615)  Acc@5: 43.7500 (40.3846)  time: 0.2193  data: 0.0004  max mem: 2503
Test: [Task 1]  [ 100/1627]  eta: 0:05:39  Loss: 3.3601 (3.3828)  Acc@1: 12.5000 (13.4282)  Acc@5: 37.5000 (40.5322)  time: 0.2196  data: 0.0004  max mem: 2503
Test: [Task 1]  [ 110/1627]  eta: 0:05:36  Loss: 3.3759 (3.3870)  Acc@1: 6.2500 (13.1194)  Acc@5: 43.7500 (40.3716)  time: 0.2192  data: 0.0005  max mem: 2503
Test: [Task 1]  [ 120/1627]  eta: 0:05:33  Loss: 3.3888 (3.3805)  Acc@1: 12.5000 (13.3781)  Acc@5: 43.7500 (40.5475)  time: 0.2191  data: 0.0006  max mem: 2503
Test: [Task 1]  [ 130/1627]  eta: 0:05:31  Loss: 3.0982 (3.3699)  Acc@1: 18.7500 (13.6450)  Acc@5: 43.7500 (41.1260)  time: 0.2189  data: 0.0004  max mem: 2503
Test: [Task 1]  [ 140/1627]  eta: 0:05:29  Loss: 3.0937 (3.3636)  Acc@1: 12.5000 (13.7855)  Acc@5: 43.7500 (41.4450)  time: 0.2195  data: 0.0003  max mem: 2503
Test: [Task 1]  [ 150/1627]  eta: 0:05:26  Loss: 3.1784 (3.3556)  Acc@1: 12.5000 (13.9901)  Acc@5: 43.7500 (41.6805)  time: 0.2195  data: 0.0003  max mem: 2503
Test: [Task 1]  [ 160/1627]  eta: 0:05:24  Loss: 3.2693 (3.3639)  Acc@1: 12.5000 (13.7811)  Acc@5: 43.7500 (41.2655)  time: 0.2195  data: 0.0003  max mem: 2503
Test: [Task 1]  [ 170/1627]  eta: 0:05:21  Loss: 3.3423 (3.3568)  Acc@1: 12.5000 (14.0716)  Acc@5: 43.7500 (41.5570)  time: 0.2196  data: 0.0003  max mem: 2503
Test: [Task 1]  [ 180/1627]  eta: 0:05:19  Loss: 3.2342 (3.3565)  Acc@1: 18.7500 (14.2265)  Acc@5: 43.7500 (41.5055)  time: 0.2193  data: 0.0003  max mem: 2503
Test: [Task 1]  [ 190/1627]  eta: 0:05:17  Loss: 3.3037 (3.3578)  Acc@1: 12.5000 (14.2997)  Acc@5: 43.7500 (41.3940)  time: 0.2194  data: 0.0003  max mem: 2503
Test: [Task 1]  [ 200/1627]  eta: 0:05:15  Loss: 3.3453 (3.3609)  Acc@1: 12.5000 (14.0858)  Acc@5: 37.5000 (41.1381)  time: 0.2198  data: 0.0005  max mem: 2503
Test: [Task 1]  [ 210/1627]  eta: 0:05:12  Loss: 3.3699 (3.3622)  Acc@1: 12.5000 (14.1291)  Acc@5: 31.2500 (40.9656)  time: 0.2216  data: 0.0015  max mem: 2503
Test: [Task 1]  [ 220/1627]  eta: 0:05:10  Loss: 3.3318 (3.3620)  Acc@1: 12.5000 (14.0554)  Acc@5: 37.5000 (40.9785)  time: 0.2213  data: 0.0013  max mem: 2503
Test: [Task 1]  [ 230/1627]  eta: 0:05:08  Loss: 3.3318 (3.3617)  Acc@1: 12.5000 (14.0152)  Acc@5: 37.5000 (40.7738)  time: 0.2200  data: 0.0005  max mem: 2503
Test: [Task 1]  [ 240/1627]  eta: 0:05:06  Loss: 3.2706 (3.3529)  Acc@1: 12.5000 (14.3672)  Acc@5: 37.5000 (40.9492)  time: 0.2198  data: 0.0006  max mem: 2503
Test: [Task 1]  [ 250/1627]  eta: 0:05:03  Loss: 3.1263 (3.3540)  Acc@1: 18.7500 (14.4422)  Acc@5: 43.7500 (40.9612)  time: 0.2199  data: 0.0010  max mem: 2503
Test: [Task 1]  [ 260/1627]  eta: 0:05:01  Loss: 3.3561 (3.3547)  Acc@1: 12.5000 (14.3678)  Acc@5: 37.5000 (40.8046)  time: 0.2196  data: 0.0010  max mem: 2503
Test: [Task 1]  [ 270/1627]  eta: 0:04:59  Loss: 3.3066 (3.3438)  Acc@1: 12.5000 (14.5526)  Acc@5: 43.7500 (41.0055)  time: 0.2186  data: 0.0003  max mem: 2503
Test: [Task 1]  [ 280/1627]  eta: 0:04:57  Loss: 3.1831 (3.3408)  Acc@1: 12.5000 (14.6130)  Acc@5: 43.7500 (41.0587)  time: 0.2193  data: 0.0003  max mem: 2503
Test: [Task 1]  [ 290/1627]  eta: 0:04:54  Loss: 3.3294 (3.3379)  Acc@1: 12.5000 (14.6692)  Acc@5: 37.5000 (41.0653)  time: 0.2196  data: 0.0003  max mem: 2503
Test: [Task 1]  [ 300/1627]  eta: 0:04:52  Loss: 3.4239 (3.3434)  Acc@1: 12.5000 (14.5556)  Acc@5: 37.5000 (40.8638)  time: 0.2206  data: 0.0003  max mem: 2503
Test: [Task 1]  [ 310/1627]  eta: 0:04:50  Loss: 3.3637 (3.3443)  Acc@1: 6.2500 (14.4092)  Acc@5: 37.5000 (40.8159)  time: 0.2201  data: 0.0003  max mem: 2503
Test: [Task 1]  [ 320/1627]  eta: 0:04:48  Loss: 3.2651 (3.3466)  Acc@1: 6.2500 (14.4665)  Acc@5: 37.5000 (40.7321)  time: 0.2200  data: 0.0016  max mem: 2503
Test: [Task 1]  [ 330/1627]  eta: 0:04:45  Loss: 3.4661 (3.3517)  Acc@1: 12.5000 (14.3693)  Acc@5: 37.5000 (40.6722)  time: 0.2205  data: 0.0019  max mem: 2503
Test: [Task 1]  [ 340/1627]  eta: 0:04:43  Loss: 3.5334 (3.3556)  Acc@1: 6.2500 (14.1862)  Acc@5: 37.5000 (40.6891)  time: 0.2190  data: 0.0007  max mem: 2503
Test: [Task 1]  [ 350/1627]  eta: 0:04:41  Loss: 3.5233 (3.3563)  Acc@1: 12.5000 (14.1026)  Acc@5: 37.5000 (40.7051)  time: 0.2187  data: 0.0003  max mem: 2503
Test: [Task 1]  [ 360/1627]  eta: 0:04:39  Loss: 3.4505 (3.3572)  Acc@1: 12.5000 (14.0582)  Acc@5: 43.7500 (40.7548)  time: 0.2191  data: 0.0004  max mem: 2503
Test: [Task 1]  [ 370/1627]  eta: 0:04:36  Loss: 3.4505 (3.3587)  Acc@1: 12.5000 (14.0499)  Acc@5: 37.5000 (40.6671)  time: 0.2200  data: 0.0004  max mem: 2503
Test: [Task 1]  [ 380/1627]  eta: 0:04:34  Loss: 3.4067 (3.3590)  Acc@1: 12.5000 (14.0748)  Acc@5: 43.7500 (40.7644)  time: 0.2198  data: 0.0004  max mem: 2503
Test: [Task 1]  [ 390/1627]  eta: 0:04:32  Loss: 3.3481 (3.3544)  Acc@1: 12.5000 (14.0505)  Acc@5: 43.7500 (40.9687)  time: 0.2192  data: 0.0004  max mem: 2503
Test: [Task 1]  [ 400/1627]  eta: 0:04:30  Loss: 3.3744 (3.3554)  Acc@1: 12.5000 (13.9651)  Acc@5: 43.7500 (40.9445)  time: 0.2190  data: 0.0003  max mem: 2503
Test: [Task 1]  [ 410/1627]  eta: 0:04:27  Loss: 3.3409 (3.3548)  Acc@1: 12.5000 (13.9142)  Acc@5: 37.5000 (41.0128)  time: 0.2187  data: 0.0003  max mem: 2503
Test: [Task 1]  [ 420/1627]  eta: 0:04:25  Loss: 3.2818 (3.3539)  Acc@1: 12.5000 (13.9549)  Acc@5: 43.7500 (41.0333)  time: 0.2187  data: 0.0003  max mem: 2503
Test: [Task 1]  [ 430/1627]  eta: 0:04:23  Loss: 3.3473 (3.3513)  Acc@1: 12.5000 (14.0081)  Acc@5: 43.7500 (41.1398)  time: 0.2202  data: 0.0010  max mem: 2503
Test: [Task 1]  [ 440/1627]  eta: 0:04:21  Loss: 3.3473 (3.3503)  Acc@1: 12.5000 (13.9739)  Acc@5: 37.5000 (41.1423)  time: 0.2193  data: 0.0010  max mem: 2503
Test: [Task 1]  [ 450/1627]  eta: 0:04:19  Loss: 3.3543 (3.3541)  Acc@1: 12.5000 (13.9690)  Acc@5: 37.5000 (41.1170)  time: 0.2171  data: 0.0003  max mem: 2503
Test: [Task 1]  [ 460/1627]  eta: 0:04:16  Loss: 3.3394 (3.3522)  Acc@1: 12.5000 (13.9507)  Acc@5: 37.5000 (41.0927)  time: 0.2178  data: 0.0004  max mem: 2503
Test: [Task 1]  [ 470/1627]  eta: 0:04:14  Loss: 3.1618 (3.3493)  Acc@1: 18.7500 (14.0924)  Acc@5: 43.7500 (41.2155)  time: 0.2180  data: 0.0004  max mem: 2503
Test: [Task 1]  [ 480/1627]  eta: 0:04:12  Loss: 3.3645 (3.3512)  Acc@1: 18.7500 (14.0463)  Acc@5: 37.5000 (41.1123)  time: 0.2173  data: 0.0003  max mem: 2503
Test: [Task 1]  [ 490/1627]  eta: 0:04:10  Loss: 3.4325 (3.3506)  Acc@1: 12.5000 (14.0657)  Acc@5: 37.5000 (41.1278)  time: 0.2177  data: 0.0007  max mem: 2503
Test: [Task 1]  [ 500/1627]  eta: 0:04:07  Loss: 3.2024 (3.3497)  Acc@1: 18.7500 (14.1467)  Acc@5: 37.5000 (41.1302)  time: 0.2178  data: 0.0007  max mem: 2503
Test: [Task 1]  [ 510/1627]  eta: 0:04:05  Loss: 3.2516 (3.3505)  Acc@1: 18.7500 (14.1389)  Acc@5: 37.5000 (41.1326)  time: 0.2170  data: 0.0004  max mem: 2503
Test: [Task 1]  [ 520/1627]  eta: 0:04:03  Loss: 3.2612 (3.3504)  Acc@1: 12.5000 (14.1195)  Acc@5: 37.5000 (41.1708)  time: 0.2174  data: 0.0004  max mem: 2503
Test: [Task 1]  [ 530/1627]  eta: 0:04:01  Loss: 3.1470 (3.3448)  Acc@1: 12.5000 (14.1949)  Acc@5: 50.0000 (41.3371)  time: 0.2188  data: 0.0004  max mem: 2503
Test: [Task 1]  [ 540/1627]  eta: 0:03:58  Loss: 3.1979 (3.3459)  Acc@1: 12.5000 (14.1058)  Acc@5: 43.7500 (41.2431)  time: 0.2190  data: 0.0004  max mem: 2503
Test: [Task 1]  [ 550/1627]  eta: 0:03:56  Loss: 3.4231 (3.3463)  Acc@1: 12.5000 (14.0767)  Acc@5: 37.5000 (41.1978)  time: 0.2184  data: 0.0004  max mem: 2503
Test: [Task 1]  [ 560/1627]  eta: 0:03:54  Loss: 3.3248 (3.3481)  Acc@1: 12.5000 (14.0040)  Acc@5: 43.7500 (41.1765)  time: 0.2200  data: 0.0004  max mem: 2503
Test: [Task 1]  [ 570/1627]  eta: 0:03:52  Loss: 3.3799 (3.3482)  Acc@1: 12.5000 (13.9886)  Acc@5: 37.5000 (41.1559)  time: 0.2202  data: 0.0004  max mem: 2503
Test: [Task 1]  [ 580/1627]  eta: 0:03:50  Loss: 3.3799 (3.3488)  Acc@1: 12.5000 (13.9845)  Acc@5: 37.5000 (41.1682)  time: 0.2191  data: 0.0004  max mem: 2503
Test: [Task 1]  [ 590/1627]  eta: 0:03:47  Loss: 3.4587 (3.3493)  Acc@1: 12.5000 (13.9805)  Acc@5: 37.5000 (41.1591)  time: 0.2190  data: 0.0004  max mem: 2503
Test: [Task 1]  [ 600/1627]  eta: 0:03:45  Loss: 3.3035 (3.3486)  Acc@1: 12.5000 (13.9975)  Acc@5: 37.5000 (41.1814)  time: 0.2189  data: 0.0004  max mem: 2503
Test: [Task 1]  [ 610/1627]  eta: 0:03:43  Loss: 3.1567 (3.3450)  Acc@1: 18.7500 (14.0651)  Acc@5: 43.7500 (41.2439)  time: 0.2192  data: 0.0004  max mem: 2503
Test: [Task 1]  [ 620/1627]  eta: 0:03:41  Loss: 3.1799 (3.3438)  Acc@1: 12.5000 (14.0700)  Acc@5: 43.7500 (41.2943)  time: 0.2194  data: 0.0004  max mem: 2503
Test: [Task 1]  [ 630/1627]  eta: 0:03:39  Loss: 3.1799 (3.3406)  Acc@1: 18.7500 (14.1343)  Acc@5: 50.0000 (41.4124)  time: 0.2198  data: 0.0009  max mem: 2503
Test: [Task 1]  [ 640/1627]  eta: 0:03:36  Loss: 3.0988 (3.3405)  Acc@1: 18.7500 (14.1673)  Acc@5: 50.0000 (41.5367)  time: 0.2199  data: 0.0009  max mem: 2503
Test: [Task 1]  [ 650/1627]  eta: 0:03:34  Loss: 3.2826 (3.3401)  Acc@1: 18.7500 (14.2281)  Acc@5: 43.7500 (41.5995)  time: 0.2200  data: 0.0004  max mem: 2503
Test: [Task 1]  [ 660/1627]  eta: 0:03:32  Loss: 3.2770 (3.3375)  Acc@1: 18.7500 (14.2682)  Acc@5: 43.7500 (41.6793)  time: 0.2198  data: 0.0004  max mem: 2503
Test: [Task 1]  [ 670/1627]  eta: 0:03:30  Loss: 3.2797 (3.3390)  Acc@1: 12.5000 (14.2232)  Acc@5: 43.7500 (41.6263)  time: 0.2192  data: 0.0004  max mem: 2503
Test: [Task 1]  [ 680/1627]  eta: 0:03:28  Loss: 3.4854 (3.3385)  Acc@1: 12.5000 (14.2529)  Acc@5: 37.5000 (41.6208)  time: 0.2197  data: 0.0011  max mem: 2503
Test: [Task 1]  [ 690/1627]  eta: 0:03:25  Loss: 3.3901 (3.3372)  Acc@1: 18.7500 (14.3180)  Acc@5: 37.5000 (41.6064)  time: 0.2196  data: 0.0011  max mem: 2503
Test: [Task 1]  [ 700/1627]  eta: 0:03:23  Loss: 3.2893 (3.3371)  Acc@1: 18.7500 (14.3456)  Acc@5: 37.5000 (41.6459)  time: 0.2198  data: 0.0004  max mem: 2503
Test: [Task 1]  [ 710/1627]  eta: 0:03:21  Loss: 3.1390 (3.3343)  Acc@1: 18.7500 (14.4251)  Acc@5: 43.7500 (41.7634)  time: 0.2203  data: 0.0004  max mem: 2503
Test: [Task 1]  [ 720/1627]  eta: 0:03:19  Loss: 3.1698 (3.3347)  Acc@1: 18.7500 (14.4244)  Acc@5: 43.7500 (41.7736)  time: 0.2197  data: 0.0003  max mem: 2503
Test: [Task 1]  [ 730/1627]  eta: 0:03:17  Loss: 3.3118 (3.3353)  Acc@1: 12.5000 (14.4665)  Acc@5: 43.7500 (41.8177)  time: 0.2200  data: 0.0004  max mem: 2503
Test: [Task 1]  [ 740/1627]  eta: 0:03:14  Loss: 3.3006 (3.3347)  Acc@1: 18.7500 (14.5074)  Acc@5: 43.7500 (41.8522)  time: 0.2199  data: 0.0004  max mem: 2503
Test: [Task 1]  [ 750/1627]  eta: 0:03:12  Loss: 3.3100 (3.3366)  Acc@1: 12.5000 (14.4058)  Acc@5: 37.5000 (41.7860)  time: 0.2200  data: 0.0004  max mem: 2503
Test: [Task 1]  [ 760/1627]  eta: 0:03:10  Loss: 3.3831 (3.3381)  Acc@1: 6.2500 (14.3643)  Acc@5: 37.5000 (41.7214)  time: 0.2206  data: 0.0004  max mem: 2503
Test: [Task 1]  [ 770/1627]  eta: 0:03:08  Loss: 3.3207 (3.3378)  Acc@1: 12.5000 (14.3401)  Acc@5: 37.5000 (41.7720)  time: 0.2196  data: 0.0007  max mem: 2503
Test: [Task 1]  [ 780/1627]  eta: 0:03:06  Loss: 3.2436 (3.3378)  Acc@1: 12.5000 (14.3086)  Acc@5: 43.7500 (41.8054)  time: 0.2187  data: 0.0006  max mem: 2503
Test: [Task 1]  [ 790/1627]  eta: 0:03:03  Loss: 3.5000 (3.3397)  Acc@1: 6.2500 (14.2541)  Acc@5: 43.7500 (41.8142)  time: 0.2188  data: 0.0003  max mem: 2503
Test: [Task 1]  [ 800/1627]  eta: 0:03:01  Loss: 3.5080 (3.3395)  Acc@1: 12.5000 (14.2790)  Acc@5: 37.5000 (41.7993)  time: 0.2189  data: 0.0003  max mem: 2503
Test: [Task 1]  [ 810/1627]  eta: 0:02:59  Loss: 3.4468 (3.3417)  Acc@1: 12.5000 (14.2417)  Acc@5: 37.5000 (41.7155)  time: 0.2190  data: 0.0003  max mem: 2503
Test: [Task 1]  [ 820/1627]  eta: 0:02:57  Loss: 3.4917 (3.3424)  Acc@1: 12.5000 (14.2129)  Acc@5: 37.5000 (41.6565)  time: 0.2187  data: 0.0003  max mem: 2503
Test: [Task 1]  [ 830/1627]  eta: 0:02:55  Loss: 3.2643 (3.3409)  Acc@1: 12.5000 (14.2524)  Acc@5: 43.7500 (41.7569)  time: 0.2187  data: 0.0003  max mem: 2503
Test: [Task 1]  [ 840/1627]  eta: 0:02:52  Loss: 3.2643 (3.3407)  Acc@1: 12.5000 (14.2687)  Acc@5: 43.7500 (41.7955)  time: 0.2191  data: 0.0003  max mem: 2503
Test: [Task 1]  [ 850/1627]  eta: 0:02:50  Loss: 3.3483 (3.3424)  Acc@1: 12.5000 (14.2553)  Acc@5: 37.5000 (41.6863)  time: 0.2197  data: 0.0006  max mem: 2503
Test: [Task 1]  [ 860/1627]  eta: 0:02:48  Loss: 3.4877 (3.3442)  Acc@1: 12.5000 (14.2494)  Acc@5: 37.5000 (41.6594)  time: 0.2198  data: 0.0007  max mem: 2503
Test: [Task 1]  [ 870/1627]  eta: 0:02:46  Loss: 3.4148 (3.3426)  Acc@1: 12.5000 (14.2796)  Acc@5: 37.5000 (41.7193)  time: 0.2194  data: 0.0004  max mem: 2503
Test: [Task 1]  [ 880/1627]  eta: 0:02:44  Loss: 3.4148 (3.3444)  Acc@1: 12.5000 (14.2381)  Acc@5: 37.5000 (41.6430)  time: 0.2190  data: 0.0003  max mem: 2503
Test: [Task 1]  [ 890/1627]  eta: 0:02:41  Loss: 3.4674 (3.3457)  Acc@1: 12.5000 (14.2607)  Acc@5: 31.2500 (41.5474)  time: 0.2191  data: 0.0006  max mem: 2503
Test: [Task 1]  [ 900/1627]  eta: 0:02:39  Loss: 3.3086 (3.3460)  Acc@1: 18.7500 (14.2550)  Acc@5: 37.5000 (41.5511)  time: 0.2205  data: 0.0010  max mem: 2503
Test: [Task 1]  [ 910/1627]  eta: 0:02:37  Loss: 3.3018 (3.3460)  Acc@1: 12.5000 (14.2632)  Acc@5: 37.5000 (41.5683)  time: 0.2205  data: 0.0007  max mem: 2503
Test: [Task 1]  [ 920/1627]  eta: 0:02:35  Loss: 3.2020 (3.3452)  Acc@1: 12.5000 (14.2780)  Acc@5: 43.7500 (41.5988)  time: 0.2195  data: 0.0003  max mem: 2503
Test: [Task 1]  [ 930/1627]  eta: 0:02:33  Loss: 3.2769 (3.3440)  Acc@1: 18.7500 (14.3260)  Acc@5: 43.7500 (41.6488)  time: 0.2191  data: 0.0003  max mem: 2503
Test: [Task 1]  [ 940/1627]  eta: 0:02:30  Loss: 3.3263 (3.3437)  Acc@1: 18.7500 (14.3265)  Acc@5: 43.7500 (41.6180)  time: 0.2193  data: 0.0003  max mem: 2503
Test: [Task 1]  [ 950/1627]  eta: 0:02:28  Loss: 3.3873 (3.3446)  Acc@1: 12.5000 (14.3205)  Acc@5: 37.5000 (41.5681)  time: 0.2196  data: 0.0004  max mem: 2503
Test: [Task 1]  [ 960/1627]  eta: 0:02:26  Loss: 3.3560 (3.3439)  Acc@1: 12.5000 (14.3210)  Acc@5: 43.7500 (41.6688)  time: 0.2194  data: 0.0004  max mem: 2503
Test: [Task 1]  [ 970/1627]  eta: 0:02:24  Loss: 3.2039 (3.3431)  Acc@1: 12.5000 (14.3023)  Acc@5: 43.7500 (41.6710)  time: 0.2190  data: 0.0003  max mem: 2503
Test: [Task 1]  [ 980/1627]  eta: 0:02:22  Loss: 3.2618 (3.3422)  Acc@1: 18.7500 (14.3858)  Acc@5: 37.5000 (41.6730)  time: 0.2191  data: 0.0003  max mem: 2503
Test: [Task 1]  [ 990/1627]  eta: 0:02:19  Loss: 3.4324 (3.3445)  Acc@1: 18.7500 (14.3542)  Acc@5: 37.5000 (41.6120)  time: 0.2190  data: 0.0003  max mem: 2503
Test: [Task 1]  [1000/1627]  eta: 0:02:17  Loss: 3.4506 (3.3448)  Acc@1: 12.5000 (14.3482)  Acc@5: 37.5000 (41.5959)  time: 0.2193  data: 0.0003  max mem: 2503
Test: [Task 1]  [1010/1627]  eta: 0:02:15  Loss: 3.2088 (3.3444)  Acc@1: 12.5000 (14.3670)  Acc@5: 43.7500 (41.6172)  time: 0.2194  data: 0.0003  max mem: 2503
Test: [Task 1]  [1020/1627]  eta: 0:02:13  Loss: 3.2682 (3.3446)  Acc@1: 12.5000 (14.3793)  Acc@5: 43.7500 (41.6075)  time: 0.2191  data: 0.0007  max mem: 2503
Test: [Task 1]  [1030/1627]  eta: 0:02:11  Loss: 3.2682 (3.3430)  Acc@1: 18.7500 (14.3974)  Acc@5: 37.5000 (41.6465)  time: 0.2192  data: 0.0007  max mem: 2503
Test: [Task 1]  [1040/1627]  eta: 0:02:08  Loss: 3.2862 (3.3431)  Acc@1: 12.5000 (14.4152)  Acc@5: 37.5000 (41.6427)  time: 0.2194  data: 0.0004  max mem: 2503
Test: [Task 1]  [1050/1627]  eta: 0:02:06  Loss: 3.2862 (3.3422)  Acc@1: 12.5000 (14.4148)  Acc@5: 37.5000 (41.7162)  time: 0.2196  data: 0.0010  max mem: 2503
Test: [Task 1]  [1060/1627]  eta: 0:02:04  Loss: 3.2355 (3.3426)  Acc@1: 18.7500 (14.4439)  Acc@5: 43.7500 (41.7295)  time: 0.2186  data: 0.0009  max mem: 2503
Test: [Task 1]  [1070/1627]  eta: 0:02:02  Loss: 3.4565 (3.3434)  Acc@1: 18.7500 (14.4433)  Acc@5: 37.5000 (41.7075)  time: 0.2181  data: 0.0003  max mem: 2503
Test: [Task 1]  [1080/1627]  eta: 0:02:00  Loss: 3.3922 (3.3438)  Acc@1: 12.5000 (14.4658)  Acc@5: 37.5000 (41.6859)  time: 0.2176  data: 0.0003  max mem: 2503
Test: [Task 1]  [1090/1627]  eta: 0:01:57  Loss: 3.3803 (3.3446)  Acc@1: 12.5000 (14.4535)  Acc@5: 37.5000 (41.6819)  time: 0.2174  data: 0.0003  max mem: 2503
Test: [Task 1]  [1100/1627]  eta: 0:01:55  Loss: 3.3454 (3.3439)  Acc@1: 12.5000 (14.4130)  Acc@5: 37.5000 (41.7007)  time: 0.2175  data: 0.0003  max mem: 2503
Test: [Task 1]  [1110/1627]  eta: 0:01:53  Loss: 3.4018 (3.3459)  Acc@1: 6.2500 (14.3733)  Acc@5: 37.5000 (41.6010)  time: 0.2171  data: 0.0003  max mem: 2503
Test: [Task 1]  [1120/1627]  eta: 0:01:51  Loss: 3.4444 (3.3453)  Acc@1: 18.7500 (14.3956)  Acc@5: 37.5000 (41.5979)  time: 0.2175  data: 0.0003  max mem: 2503
Test: [Task 1]  [1130/1627]  eta: 0:01:49  Loss: 3.2040 (3.3459)  Acc@1: 18.7500 (14.4120)  Acc@5: 37.5000 (41.5782)  time: 0.2171  data: 0.0004  max mem: 2503
Test: [Task 1]  [1140/1627]  eta: 0:01:46  Loss: 3.5001 (3.3482)  Acc@1: 12.5000 (14.3843)  Acc@5: 31.2500 (41.4768)  time: 0.2170  data: 0.0004  max mem: 2503
Test: [Task 1]  [1150/1627]  eta: 0:01:44  Loss: 3.5001 (3.3476)  Acc@1: 12.5000 (14.4222)  Acc@5: 31.2500 (41.4911)  time: 0.2173  data: 0.0003  max mem: 2503
Test: [Task 1]  [1160/1627]  eta: 0:01:42  Loss: 3.4144 (3.3476)  Acc@1: 12.5000 (14.4326)  Acc@5: 43.7500 (41.4944)  time: 0.2169  data: 0.0003  max mem: 2503
Test: [Task 1]  [1170/1627]  eta: 0:01:40  Loss: 3.4144 (3.3480)  Acc@1: 12.5000 (14.4268)  Acc@5: 37.5000 (41.4496)  time: 0.2168  data: 0.0003  max mem: 2503
Test: [Task 1]  [1180/1627]  eta: 0:01:38  Loss: 3.3970 (3.3489)  Acc@1: 12.5000 (14.3999)  Acc@5: 31.2500 (41.4056)  time: 0.2172  data: 0.0003  max mem: 2503
Test: [Task 1]  [1190/1627]  eta: 0:01:35  Loss: 3.3151 (3.3479)  Acc@1: 12.5000 (14.4207)  Acc@5: 37.5000 (41.4148)  time: 0.2174  data: 0.0003  max mem: 2503
Test: [Task 1]  [1200/1627]  eta: 0:01:33  Loss: 3.2883 (3.3485)  Acc@1: 12.5000 (14.3891)  Acc@5: 37.5000 (41.3770)  time: 0.2177  data: 0.0008  max mem: 2503
Test: [Task 1]  [1210/1627]  eta: 0:01:31  Loss: 3.3778 (3.3492)  Acc@1: 12.5000 (14.3993)  Acc@5: 37.5000 (41.3656)  time: 0.2175  data: 0.0008  max mem: 2503
Test: [Task 1]  [1220/1627]  eta: 0:01:29  Loss: 3.3246 (3.3489)  Acc@1: 18.7500 (14.4451)  Acc@5: 43.7500 (41.3954)  time: 0.2175  data: 0.0003  max mem: 2503
Test: [Task 1]  [1230/1627]  eta: 0:01:27  Loss: 3.3246 (3.3496)  Acc@1: 12.5000 (14.4293)  Acc@5: 50.0000 (41.4196)  time: 0.2189  data: 0.0007  max mem: 2503
Test: [Task 1]  [1240/1627]  eta: 0:01:24  Loss: 3.1718 (3.3479)  Acc@1: 12.5000 (14.4591)  Acc@5: 50.0000 (41.4786)  time: 0.2182  data: 0.0007  max mem: 2503
Test: [Task 1]  [1250/1627]  eta: 0:01:22  Loss: 3.1718 (3.3493)  Acc@1: 12.5000 (14.4484)  Acc@5: 50.0000 (41.4818)  time: 0.2171  data: 0.0003  max mem: 2503
Test: [Task 1]  [1260/1627]  eta: 0:01:20  Loss: 3.3987 (3.3495)  Acc@1: 12.5000 (14.4429)  Acc@5: 37.5000 (41.4453)  time: 0.2186  data: 0.0003  max mem: 2503
Test: [Task 1]  [1270/1627]  eta: 0:01:18  Loss: 3.4576 (3.3499)  Acc@1: 12.5000 (14.4227)  Acc@5: 37.5000 (41.4142)  time: 0.2187  data: 0.0004  max mem: 2503
Test: [Task 1]  [1280/1627]  eta: 0:01:16  Loss: 3.4060 (3.3486)  Acc@1: 18.7500 (14.4906)  Acc@5: 43.7500 (41.4520)  time: 0.2189  data: 0.0011  max mem: 2503
Test: [Task 1]  [1290/1627]  eta: 0:01:13  Loss: 3.2650 (3.3484)  Acc@1: 25.0000 (14.5430)  Acc@5: 50.0000 (41.4988)  time: 0.2192  data: 0.0011  max mem: 2503
Test: [Task 1]  [1300/1627]  eta: 0:01:11  Loss: 3.2381 (3.3473)  Acc@1: 18.7500 (14.5513)  Acc@5: 50.0000 (41.5017)  time: 0.2188  data: 0.0006  max mem: 2503
Test: [Task 1]  [1310/1627]  eta: 0:01:09  Loss: 3.2381 (3.3469)  Acc@1: 12.5000 (14.5452)  Acc@5: 50.0000 (41.5523)  time: 0.2185  data: 0.0005  max mem: 2503
Test: [Task 1]  [1320/1627]  eta: 0:01:07  Loss: 3.3422 (3.3460)  Acc@1: 12.5000 (14.5628)  Acc@5: 43.7500 (41.5783)  time: 0.2178  data: 0.0003  max mem: 2503
Test: [Task 1]  [1330/1627]  eta: 0:01:05  Loss: 3.2083 (3.3452)  Acc@1: 12.5000 (14.5802)  Acc@5: 43.7500 (41.6275)  time: 0.2179  data: 0.0003  max mem: 2503
Test: [Task 1]  [1340/1627]  eta: 0:01:02  Loss: 3.2132 (3.3450)  Acc@1: 18.7500 (14.5973)  Acc@5: 43.7500 (41.6154)  time: 0.2181  data: 0.0003  max mem: 2503
Test: [Task 1]  [1350/1627]  eta: 0:01:00  Loss: 3.2400 (3.3454)  Acc@1: 12.5000 (14.6003)  Acc@5: 37.5000 (41.6081)  time: 0.2191  data: 0.0004  max mem: 2503
Test: [Task 1]  [1360/1627]  eta: 0:00:58  Loss: 3.3427 (3.3450)  Acc@1: 12.5000 (14.5711)  Acc@5: 43.7500 (41.6468)  time: 0.2190  data: 0.0003  max mem: 2503
Test: [Task 1]  [1370/1627]  eta: 0:00:56  Loss: 3.2693 (3.3440)  Acc@1: 12.5000 (14.5651)  Acc@5: 43.7500 (41.6712)  time: 0.2185  data: 0.0005  max mem: 2503
Test: [Task 1]  [1380/1627]  eta: 0:00:54  Loss: 3.2361 (3.3443)  Acc@1: 12.5000 (14.5637)  Acc@5: 43.7500 (41.6908)  time: 0.2184  data: 0.0005  max mem: 2503
Test: [Task 1]  [1390/1627]  eta: 0:00:51  Loss: 3.1864 (3.3435)  Acc@1: 18.7500 (14.6118)  Acc@5: 37.5000 (41.6966)  time: 0.2183  data: 0.0003  max mem: 2503
Test: [Task 1]  [1400/1627]  eta: 0:00:49  Loss: 3.1864 (3.3428)  Acc@1: 18.7500 (14.6547)  Acc@5: 43.7500 (41.7068)  time: 0.2188  data: 0.0006  max mem: 2503
Test: [Task 1]  [1410/1627]  eta: 0:00:47  Loss: 3.2274 (3.3425)  Acc@1: 12.5000 (14.6394)  Acc@5: 43.7500 (41.6947)  time: 0.2187  data: 0.0007  max mem: 2503
Test: [Task 1]  [1420/1627]  eta: 0:00:45  Loss: 3.2698 (3.3417)  Acc@1: 12.5000 (14.6640)  Acc@5: 43.7500 (41.7224)  time: 0.2181  data: 0.0003  max mem: 2503
Test: [Task 1]  [1430/1627]  eta: 0:00:43  Loss: 3.3160 (3.3421)  Acc@1: 18.7500 (14.6838)  Acc@5: 43.7500 (41.6972)  time: 0.2186  data: 0.0007  max mem: 2503
Test: [Task 1]  [1440/1627]  eta: 0:00:40  Loss: 3.4431 (3.3415)  Acc@1: 18.7500 (14.6990)  Acc@5: 43.7500 (41.7332)  time: 0.2188  data: 0.0007  max mem: 2503
Test: [Task 1]  [1450/1627]  eta: 0:00:38  Loss: 3.3848 (3.3418)  Acc@1: 12.5000 (14.6752)  Acc@5: 43.7500 (41.7126)  time: 0.2180  data: 0.0004  max mem: 2503
Test: [Task 1]  [1460/1627]  eta: 0:00:36  Loss: 3.4933 (3.3428)  Acc@1: 12.5000 (14.6475)  Acc@5: 37.5000 (41.6838)  time: 0.2182  data: 0.0004  max mem: 2503
Test: [Task 1]  [1470/1627]  eta: 0:00:34  Loss: 3.4035 (3.3435)  Acc@1: 12.5000 (14.6329)  Acc@5: 37.5000 (41.6808)  time: 0.2182  data: 0.0004  max mem: 2503
Test: [Task 1]  [1480/1627]  eta: 0:00:32  Loss: 3.3037 (3.3433)  Acc@1: 12.5000 (14.6607)  Acc@5: 43.7500 (41.6695)  time: 0.2180  data: 0.0004  max mem: 2503
Test: [Task 1]  [1490/1627]  eta: 0:00:30  Loss: 3.3037 (3.3430)  Acc@1: 12.5000 (14.6546)  Acc@5: 43.7500 (41.6583)  time: 0.2180  data: 0.0005  max mem: 2503
Test: [Task 1]  [1500/1627]  eta: 0:00:27  Loss: 3.2629 (3.3430)  Acc@1: 12.5000 (14.6402)  Acc@5: 37.5000 (41.6431)  time: 0.2176  data: 0.0005  max mem: 2503
Test: [Task 1]  [1510/1627]  eta: 0:00:25  Loss: 3.3932 (3.3441)  Acc@1: 6.2500 (14.6261)  Acc@5: 37.5000 (41.5867)  time: 0.2169  data: 0.0004  max mem: 2503
Test: [Task 1]  [1520/1627]  eta: 0:00:23  Loss: 3.2668 (3.3424)  Acc@1: 18.7500 (14.6573)  Acc@5: 37.5000 (41.6256)  time: 0.2167  data: 0.0003  max mem: 2503
Test: [Task 1]  [1530/1627]  eta: 0:00:21  Loss: 3.2724 (3.3439)  Acc@1: 12.5000 (14.6391)  Acc@5: 43.7500 (41.5986)  time: 0.2170  data: 0.0003  max mem: 2503
Test: [Task 1]  [1540/1627]  eta: 0:00:19  Loss: 3.3905 (3.3432)  Acc@1: 12.5000 (14.6496)  Acc@5: 43.7500 (41.6288)  time: 0.2179  data: 0.0005  max mem: 2503
Test: [Task 1]  [1550/1627]  eta: 0:00:16  Loss: 3.1758 (3.3429)  Acc@1: 12.5000 (14.6397)  Acc@5: 43.7500 (41.6425)  time: 0.2177  data: 0.0005  max mem: 2503
Test: [Task 1]  [1560/1627]  eta: 0:00:14  Loss: 3.1032 (3.3416)  Acc@1: 18.7500 (14.6901)  Acc@5: 43.7500 (41.6760)  time: 0.2172  data: 0.0003  max mem: 2503
Test: [Task 1]  [1570/1627]  eta: 0:00:12  Loss: 3.2558 (3.3418)  Acc@1: 18.7500 (14.6801)  Acc@5: 43.7500 (41.6653)  time: 0.2175  data: 0.0003  max mem: 2503
Test: [Task 1]  [1580/1627]  eta: 0:00:10  Loss: 3.2023 (3.3413)  Acc@1: 12.5000 (14.6861)  Acc@5: 43.7500 (41.6509)  time: 0.2177  data: 0.0004  max mem: 2503
Test: [Task 1]  [1590/1627]  eta: 0:00:08  Loss: 3.3789 (3.3424)  Acc@1: 12.5000 (14.6802)  Acc@5: 37.5000 (41.6248)  time: 0.2176  data: 0.0004  max mem: 2503
Test: [Task 1]  [1600/1627]  eta: 0:00:05  Loss: 3.4142 (3.3424)  Acc@1: 12.5000 (14.6627)  Acc@5: 37.5000 (41.6224)  time: 0.2178  data: 0.0003  max mem: 2503
Test: [Task 1]  [1610/1627]  eta: 0:00:03  Loss: 3.1577 (3.3419)  Acc@1: 12.5000 (14.6687)  Acc@5: 43.7500 (41.6511)  time: 0.2181  data: 0.0003  max mem: 2503
Test: [Task 1]  [1620/1627]  eta: 0:00:01  Loss: 3.2182 (3.3413)  Acc@1: 12.5000 (14.6707)  Acc@5: 43.7500 (41.6602)  time: 0.2179  data: 0.0003  max mem: 2503
Test: [Task 1]  [1626/1627]  eta: 0:00:00  Loss: 3.2182 (3.3408)  Acc@1: 12.5000 (14.6742)  Acc@5: 43.7500 (41.6756)  time: 0.2179  data: 0.0003  max mem: 2503
Test: [Task 1] Total time: 0:05:56 (0.2192 s / it)
* Acc@1 14.674 Acc@5 41.676 loss 3.341
Test: [Task 2]  [  0/625]  eta: 0:06:02  Loss: 1.0304 (1.0304)  Acc@1: 68.7500 (68.7500)  Acc@5: 100.0000 (100.0000)  time: 0.5807  data: 0.3617  max mem: 2503
Test: [Task 2]  [ 10/625]  eta: 0:02:34  Loss: 1.4972 (1.5430)  Acc@1: 50.0000 (48.8636)  Acc@5: 93.7500 (93.7500)  time: 0.2509  data: 0.0333  max mem: 2503
Test: [Task 2]  [ 20/625]  eta: 0:02:22  Loss: 1.4811 (1.4852)  Acc@1: 43.7500 (48.8095)  Acc@5: 93.7500 (94.0476)  time: 0.2178  data: 0.0006  max mem: 2503
Test: [Task 2]  [ 30/625]  eta: 0:02:16  Loss: 1.4811 (1.4992)  Acc@1: 43.7500 (49.5968)  Acc@5: 93.7500 (93.5484)  time: 0.2180  data: 0.0006  max mem: 2503
Test: [Task 2]  [ 40/625]  eta: 0:02:12  Loss: 1.6192 (1.5473)  Acc@1: 50.0000 (48.6280)  Acc@5: 93.7500 (93.2927)  time: 0.2181  data: 0.0006  max mem: 2503
Test: [Task 2]  [ 50/625]  eta: 0:02:09  Loss: 1.6703 (1.5699)  Acc@1: 43.7500 (48.2843)  Acc@5: 87.5000 (92.6471)  time: 0.2180  data: 0.0005  max mem: 2503
Test: [Task 2]  [ 60/625]  eta: 0:02:06  Loss: 1.6703 (1.5734)  Acc@1: 43.7500 (48.3607)  Acc@5: 87.5000 (92.5205)  time: 0.2180  data: 0.0003  max mem: 2503
Test: [Task 2]  [ 70/625]  eta: 0:02:03  Loss: 1.5898 (1.5902)  Acc@1: 43.7500 (47.3592)  Acc@5: 93.7500 (92.2535)  time: 0.2183  data: 0.0006  max mem: 2503
Test: [Task 2]  [ 80/625]  eta: 0:02:01  Loss: 1.5898 (1.6000)  Acc@1: 43.7500 (47.4537)  Acc@5: 93.7500 (91.9753)  time: 0.2184  data: 0.0007  max mem: 2503
Test: [Task 2]  [ 90/625]  eta: 0:01:58  Loss: 1.5959 (1.5962)  Acc@1: 43.7500 (47.4588)  Acc@5: 93.7500 (92.2390)  time: 0.2182  data: 0.0004  max mem: 2503
Test: [Task 2]  [100/625]  eta: 0:01:56  Loss: 1.5069 (1.6001)  Acc@1: 43.7500 (46.9678)  Acc@5: 93.7500 (92.4505)  time: 0.2185  data: 0.0007  max mem: 2503
Test: [Task 2]  [110/625]  eta: 0:01:54  Loss: 1.5285 (1.5990)  Acc@1: 43.7500 (46.8468)  Acc@5: 93.7500 (92.6239)  time: 0.2185  data: 0.0007  max mem: 2503
Test: [Task 2]  [120/625]  eta: 0:01:51  Loss: 1.5368 (1.6010)  Acc@1: 43.7500 (46.7459)  Acc@5: 93.7500 (92.6653)  time: 0.2182  data: 0.0004  max mem: 2503
Test: [Task 2]  [130/625]  eta: 0:01:49  Loss: 1.5923 (1.6139)  Acc@1: 43.7500 (46.5172)  Acc@5: 93.7500 (92.4618)  time: 0.2182  data: 0.0004  max mem: 2503
Test: [Task 2]  [140/625]  eta: 0:01:47  Loss: 1.6624 (1.6168)  Acc@1: 37.5000 (46.0106)  Acc@5: 93.7500 (92.5532)  time: 0.2188  data: 0.0009  max mem: 2503
Test: [Task 2]  [150/625]  eta: 0:01:44  Loss: 1.6288 (1.6228)  Acc@1: 37.5000 (45.9851)  Acc@5: 93.7500 (92.2599)  time: 0.2188  data: 0.0009  max mem: 2503
Test: [Task 2]  [160/625]  eta: 0:01:42  Loss: 1.5909 (1.6218)  Acc@1: 43.7500 (46.1180)  Acc@5: 93.7500 (92.3525)  time: 0.2183  data: 0.0004  max mem: 2503
Test: [Task 2]  [170/625]  eta: 0:01:40  Loss: 1.5719 (1.6209)  Acc@1: 43.7500 (46.0526)  Acc@5: 93.7500 (92.4342)  time: 0.2185  data: 0.0004  max mem: 2503
Test: [Task 2]  [180/625]  eta: 0:01:38  Loss: 1.6785 (1.6246)  Acc@1: 43.7500 (45.8564)  Acc@5: 93.7500 (92.3688)  time: 0.2183  data: 0.0003  max mem: 2503
Test: [Task 2]  [190/625]  eta: 0:01:35  Loss: 1.6950 (1.6282)  Acc@1: 43.7500 (45.9751)  Acc@5: 87.5000 (92.2448)  time: 0.2178  data: 0.0003  max mem: 2503
Test: [Task 2]  [200/625]  eta: 0:01:33  Loss: 1.7168 (1.6348)  Acc@1: 43.7500 (45.8333)  Acc@5: 93.7500 (92.3197)  time: 0.2177  data: 0.0003  max mem: 2503
Test: [Task 2]  [210/625]  eta: 0:01:31  Loss: 1.6733 (1.6328)  Acc@1: 43.7500 (45.8827)  Acc@5: 93.7500 (92.3874)  time: 0.2179  data: 0.0003  max mem: 2503
Test: [Task 2]  [220/625]  eta: 0:01:29  Loss: 1.5863 (1.6261)  Acc@1: 50.0000 (45.9276)  Acc@5: 93.7500 (92.4774)  time: 0.2190  data: 0.0010  max mem: 2503
Test: [Task 2]  [230/625]  eta: 0:01:26  Loss: 1.6224 (1.6234)  Acc@1: 43.7500 (45.9416)  Acc@5: 93.7500 (92.5595)  time: 0.2188  data: 0.0010  max mem: 2503
Test: [Task 2]  [240/625]  eta: 0:01:24  Loss: 1.6933 (1.6254)  Acc@1: 43.7500 (45.8247)  Acc@5: 93.7500 (92.6349)  time: 0.2179  data: 0.0003  max mem: 2503
Test: [Task 2]  [250/625]  eta: 0:01:22  Loss: 1.5930 (1.6201)  Acc@1: 43.7500 (45.9412)  Acc@5: 93.7500 (92.5797)  time: 0.2175  data: 0.0003  max mem: 2503
Test: [Task 2]  [260/625]  eta: 0:01:20  Loss: 1.5388 (1.6172)  Acc@1: 43.7500 (46.0249)  Acc@5: 93.7500 (92.5287)  time: 0.2175  data: 0.0003  max mem: 2503
Test: [Task 2]  [270/625]  eta: 0:01:17  Loss: 1.5519 (1.6124)  Acc@1: 43.7500 (46.0793)  Acc@5: 93.7500 (92.6199)  time: 0.2177  data: 0.0003  max mem: 2503
Test: [Task 2]  [280/625]  eta: 0:01:15  Loss: 1.5138 (1.6076)  Acc@1: 43.7500 (46.1521)  Acc@5: 93.7500 (92.6379)  time: 0.2173  data: 0.0003  max mem: 2503
Test: [Task 2]  [290/625]  eta: 0:01:13  Loss: 1.6108 (1.6099)  Acc@1: 43.7500 (46.1555)  Acc@5: 93.7500 (92.6117)  time: 0.2170  data: 0.0003  max mem: 2503
Test: [Task 2]  [300/625]  eta: 0:01:11  Loss: 1.6565 (1.6139)  Acc@1: 43.7500 (45.9510)  Acc@5: 93.7500 (92.6910)  time: 0.2175  data: 0.0003  max mem: 2503
Test: [Task 2]  [310/625]  eta: 0:01:09  Loss: 1.6620 (1.6151)  Acc@1: 37.5000 (45.7998)  Acc@5: 93.7500 (92.7251)  time: 0.2174  data: 0.0003  max mem: 2503
Test: [Task 2]  [320/625]  eta: 0:01:06  Loss: 1.5514 (1.6109)  Acc@1: 43.7500 (45.9502)  Acc@5: 93.7500 (92.8738)  time: 0.2167  data: 0.0003  max mem: 2503
Test: [Task 2]  [330/625]  eta: 0:01:04  Loss: 1.6341 (1.6156)  Acc@1: 50.0000 (45.8270)  Acc@5: 93.7500 (92.9381)  time: 0.2167  data: 0.0003  max mem: 2503
Test: [Task 2]  [340/625]  eta: 0:01:02  Loss: 1.3691 (1.6030)  Acc@1: 56.2500 (46.2977)  Acc@5: 100.0000 (93.1085)  time: 0.2173  data: 0.0005  max mem: 2503
Test: [Task 2]  [350/625]  eta: 0:01:00  Loss: 1.2875 (1.5965)  Acc@1: 56.2500 (46.5100)  Acc@5: 100.0000 (93.1980)  time: 0.2186  data: 0.0015  max mem: 2503
Test: [Task 2]  [360/625]  eta: 0:00:58  Loss: 1.6112 (1.6017)  Acc@1: 43.7500 (46.3989)  Acc@5: 93.7500 (93.1094)  time: 0.2190  data: 0.0021  max mem: 2503
Test: [Task 2]  [370/625]  eta: 0:00:55  Loss: 1.5512 (1.5949)  Acc@1: 43.7500 (46.5970)  Acc@5: 93.7500 (93.1941)  time: 0.2180  data: 0.0014  max mem: 2503
Test: [Task 2]  [380/625]  eta: 0:00:53  Loss: 1.3219 (1.5922)  Acc@1: 56.2500 (46.8504)  Acc@5: 93.7500 (93.0118)  time: 0.2172  data: 0.0007  max mem: 2503
Test: [Task 2]  [390/625]  eta: 0:00:51  Loss: 1.4051 (1.5888)  Acc@1: 56.2500 (46.9309)  Acc@5: 87.5000 (92.9668)  time: 0.2174  data: 0.0003  max mem: 2503
Test: [Task 2]  [400/625]  eta: 0:00:49  Loss: 1.3474 (1.5813)  Acc@1: 50.0000 (47.0387)  Acc@5: 93.7500 (93.0642)  time: 0.2174  data: 0.0003  max mem: 2503
Test: [Task 2]  [410/625]  eta: 0:00:47  Loss: 1.3116 (1.5833)  Acc@1: 50.0000 (47.0043)  Acc@5: 93.7500 (93.0809)  time: 0.2175  data: 0.0003  max mem: 2503
Test: [Task 2]  [420/625]  eta: 0:00:44  Loss: 1.8115 (1.5946)  Acc@1: 43.7500 (46.6449)  Acc@5: 93.7500 (93.0077)  time: 0.2187  data: 0.0003  max mem: 2503
Test: [Task 2]  [430/625]  eta: 0:00:42  Loss: 1.8138 (1.5963)  Acc@1: 37.5000 (46.6792)  Acc@5: 93.7500 (93.0249)  time: 0.2190  data: 0.0004  max mem: 2503
Test: [Task 2]  [440/625]  eta: 0:00:40  Loss: 1.1178 (1.5855)  Acc@1: 50.0000 (46.9813)  Acc@5: 100.0000 (93.1122)  time: 0.2190  data: 0.0004  max mem: 2503
Test: [Task 2]  [450/625]  eta: 0:00:38  Loss: 1.2979 (1.5833)  Acc@1: 50.0000 (47.0205)  Acc@5: 100.0000 (93.1957)  time: 0.2190  data: 0.0004  max mem: 2503
Test: [Task 2]  [460/625]  eta: 0:00:36  Loss: 1.3974 (1.5806)  Acc@1: 50.0000 (47.0445)  Acc@5: 93.7500 (93.1941)  time: 0.2189  data: 0.0004  max mem: 2503
Test: [Task 2]  [470/625]  eta: 0:00:33  Loss: 1.5839 (1.5867)  Acc@1: 37.5000 (46.8153)  Acc@5: 93.7500 (93.2325)  time: 0.2189  data: 0.0004  max mem: 2503
Test: [Task 2]  [480/625]  eta: 0:00:31  Loss: 1.6198 (1.5869)  Acc@1: 37.5000 (46.7516)  Acc@5: 93.7500 (93.2822)  time: 0.2182  data: 0.0003  max mem: 2503
Test: [Task 2]  [490/625]  eta: 0:00:29  Loss: 1.4379 (1.5829)  Acc@1: 43.7500 (46.9068)  Acc@5: 93.7500 (93.3299)  time: 0.2186  data: 0.0003  max mem: 2503
Test: [Task 2]  [500/625]  eta: 0:00:27  Loss: 1.5858 (1.5853)  Acc@1: 37.5000 (46.7814)  Acc@5: 93.7500 (93.3258)  time: 0.2191  data: 0.0004  max mem: 2503
Test: [Task 2]  [510/625]  eta: 0:00:25  Loss: 1.7097 (1.5889)  Acc@1: 37.5000 (46.7099)  Acc@5: 93.7500 (93.3464)  time: 0.2189  data: 0.0004  max mem: 2503
Test: [Task 2]  [520/625]  eta: 0:00:22  Loss: 2.0881 (1.6073)  Acc@1: 31.2500 (46.1852)  Acc@5: 93.7500 (93.2702)  time: 0.2191  data: 0.0004  max mem: 2503
Test: [Task 2]  [530/625]  eta: 0:00:20  Loss: 2.1390 (1.6134)  Acc@1: 25.0000 (45.9981)  Acc@5: 93.7500 (93.2439)  time: 0.2192  data: 0.0003  max mem: 2503
Test: [Task 2]  [540/625]  eta: 0:00:18  Loss: 1.5076 (1.6063)  Acc@1: 43.7500 (46.2338)  Acc@5: 93.7500 (93.2417)  time: 0.2193  data: 0.0004  max mem: 2503
Test: [Task 2]  [550/625]  eta: 0:00:16  Loss: 1.1567 (1.5984)  Acc@1: 56.2500 (46.4156)  Acc@5: 100.0000 (93.3190)  time: 0.2198  data: 0.0004  max mem: 2503
Test: [Task 2]  [560/625]  eta: 0:00:14  Loss: 1.2417 (1.5944)  Acc@1: 50.0000 (46.4461)  Acc@5: 100.0000 (93.4046)  time: 0.2205  data: 0.0004  max mem: 2503
Test: [Task 2]  [570/625]  eta: 0:00:12  Loss: 1.4159 (1.5970)  Acc@1: 50.0000 (46.4864)  Acc@5: 100.0000 (93.3888)  time: 0.2207  data: 0.0008  max mem: 2503
Test: [Task 2]  [580/625]  eta: 0:00:09  Loss: 1.6350 (1.5942)  Acc@1: 43.7500 (46.6007)  Acc@5: 100.0000 (93.4488)  time: 0.2216  data: 0.0021  max mem: 2503
Test: [Task 2]  [590/625]  eta: 0:00:07  Loss: 1.3449 (1.5854)  Acc@1: 50.0000 (46.8697)  Acc@5: 100.0000 (93.5279)  time: 0.2210  data: 0.0017  max mem: 2503
Test: [Task 2]  [600/625]  eta: 0:00:05  Loss: 1.4395 (1.5930)  Acc@1: 43.7500 (46.6202)  Acc@5: 100.0000 (93.5316)  time: 0.2195  data: 0.0006  max mem: 2503
Test: [Task 2]  [610/625]  eta: 0:00:03  Loss: 2.0821 (1.6043)  Acc@1: 31.2500 (46.2971)  Acc@5: 93.7500 (93.5147)  time: 0.2196  data: 0.0005  max mem: 2503
Test: [Task 2]  [620/625]  eta: 0:00:01  Loss: 1.6409 (1.6047)  Acc@1: 25.0000 (46.1554)  Acc@5: 100.0000 (93.5890)  time: 0.2200  data: 0.0003  max mem: 2503
Test: [Task 2]  [624/625]  eta: 0:00:00  Loss: 1.6282 (1.6057)  Acc@1: 37.5000 (46.1300)  Acc@5: 100.0000 (93.5700)  time: 0.2199  data: 0.0003  max mem: 2503
Test: [Task 2] Total time: 0:02:17 (0.2193 s / it)
* Acc@1 46.130 Acc@5 93.570 loss 1.606
Test: [Task 3]  [  0/625]  eta: 0:06:11  Loss: 0.4274 (0.4274)  Acc@1: 93.7500 (93.7500)  Acc@5: 93.7500 (93.7500)  time: 0.5937  data: 0.3697  max mem: 2503
Test: [Task 3]  [ 10/625]  eta: 0:02:35  Loss: 0.4611 (0.4935)  Acc@1: 93.7500 (90.9091)  Acc@5: 100.0000 (97.1591)  time: 0.2535  data: 0.0339  max mem: 2503
Test: [Task 3]  [ 20/625]  eta: 0:02:23  Loss: 0.5395 (0.5416)  Acc@1: 87.5000 (88.9881)  Acc@5: 100.0000 (95.8333)  time: 0.2200  data: 0.0004  max mem: 2503
Test: [Task 3]  [ 30/625]  eta: 0:02:18  Loss: 0.2840 (0.4556)  Acc@1: 93.7500 (90.7258)  Acc@5: 100.0000 (96.7742)  time: 0.2202  data: 0.0004  max mem: 2503
Test: [Task 3]  [ 40/625]  eta: 0:02:13  Loss: 0.3475 (0.4567)  Acc@1: 87.5000 (90.2439)  Acc@5: 100.0000 (96.4939)  time: 0.2195  data: 0.0004  max mem: 2503
Test: [Task 3]  [ 50/625]  eta: 0:02:10  Loss: 0.3979 (0.4382)  Acc@1: 87.5000 (90.9314)  Acc@5: 100.0000 (96.6912)  time: 0.2195  data: 0.0004  max mem: 2503
Test: [Task 3]  [ 60/625]  eta: 0:02:07  Loss: 0.3996 (0.4444)  Acc@1: 93.7500 (90.4713)  Acc@5: 100.0000 (96.6189)  time: 0.2202  data: 0.0004  max mem: 2503
Test: [Task 3]  [ 70/625]  eta: 0:02:04  Loss: 0.3880 (0.4298)  Acc@1: 93.7500 (91.0211)  Acc@5: 100.0000 (96.8310)  time: 0.2203  data: 0.0004  max mem: 2503
Test: [Task 3]  [ 80/625]  eta: 0:02:02  Loss: 0.3776 (0.4414)  Acc@1: 93.7500 (90.6636)  Acc@5: 100.0000 (96.6049)  time: 0.2214  data: 0.0017  max mem: 2503
Test: [Task 3]  [ 90/625]  eta: 0:02:00  Loss: 0.3824 (0.4438)  Acc@1: 87.5000 (90.7967)  Acc@5: 100.0000 (96.5659)  time: 0.2213  data: 0.0017  max mem: 2503
Test: [Task 3]  [100/625]  eta: 0:01:57  Loss: 0.3824 (0.4419)  Acc@1: 87.5000 (90.5322)  Acc@5: 100.0000 (96.5347)  time: 0.2208  data: 0.0006  max mem: 2503
Test: [Task 3]  [110/625]  eta: 0:01:55  Loss: 0.3587 (0.4357)  Acc@1: 87.5000 (90.6532)  Acc@5: 100.0000 (96.7342)  time: 0.2209  data: 0.0007  max mem: 2503
Test: [Task 3]  [120/625]  eta: 0:01:52  Loss: 0.3969 (0.4397)  Acc@1: 87.5000 (90.5475)  Acc@5: 100.0000 (96.6942)  time: 0.2210  data: 0.0005  max mem: 2503
Test: [Task 3]  [130/625]  eta: 0:01:50  Loss: 0.4374 (0.4400)  Acc@1: 93.7500 (90.6011)  Acc@5: 100.0000 (96.7557)  time: 0.2210  data: 0.0004  max mem: 2503
Test: [Task 3]  [140/625]  eta: 0:01:48  Loss: 0.4161 (0.4483)  Acc@1: 87.5000 (90.3812)  Acc@5: 100.0000 (96.5869)  time: 0.2202  data: 0.0004  max mem: 2503
Test: [Task 3]  [150/625]  eta: 0:01:45  Loss: 0.5031 (0.4541)  Acc@1: 87.5000 (90.1904)  Acc@5: 100.0000 (96.6887)  time: 0.2200  data: 0.0004  max mem: 2503
Test: [Task 3]  [160/625]  eta: 0:01:43  Loss: 0.5031 (0.4639)  Acc@1: 87.5000 (89.9457)  Acc@5: 100.0000 (96.5839)  time: 0.2198  data: 0.0004  max mem: 2503
Test: [Task 3]  [170/625]  eta: 0:01:41  Loss: 0.4583 (0.4674)  Acc@1: 87.5000 (89.7661)  Acc@5: 93.7500 (96.4912)  time: 0.2199  data: 0.0004  max mem: 2503
Test: [Task 3]  [180/625]  eta: 0:01:38  Loss: 0.4583 (0.4676)  Acc@1: 87.5000 (89.7445)  Acc@5: 93.7500 (96.4434)  time: 0.2199  data: 0.0003  max mem: 2503
Test: [Task 3]  [190/625]  eta: 0:01:36  Loss: 0.4395 (0.4643)  Acc@1: 93.7500 (89.9215)  Acc@5: 100.0000 (96.5314)  time: 0.2195  data: 0.0003  max mem: 2503
Test: [Task 3]  [200/625]  eta: 0:01:34  Loss: 0.4395 (0.4655)  Acc@1: 93.7500 (90.0187)  Acc@5: 100.0000 (96.5796)  time: 0.2196  data: 0.0003  max mem: 2503
Test: [Task 3]  [210/625]  eta: 0:01:32  Loss: 0.4242 (0.4607)  Acc@1: 93.7500 (90.2251)  Acc@5: 100.0000 (96.6528)  time: 0.2199  data: 0.0004  max mem: 2503
Test: [Task 3]  [220/625]  eta: 0:01:29  Loss: 0.4196 (0.4632)  Acc@1: 93.7500 (90.2432)  Acc@5: 100.0000 (96.6346)  time: 0.2202  data: 0.0004  max mem: 2503
Test: [Task 3]  [230/625]  eta: 0:01:27  Loss: 0.5277 (0.4654)  Acc@1: 87.5000 (90.1786)  Acc@5: 93.7500 (96.5909)  time: 0.2203  data: 0.0004  max mem: 2503
Test: [Task 3]  [240/625]  eta: 0:01:25  Loss: 0.5298 (0.4675)  Acc@1: 87.5000 (90.1712)  Acc@5: 100.0000 (96.6286)  time: 0.2207  data: 0.0006  max mem: 2503
Test: [Task 3]  [250/625]  eta: 0:01:23  Loss: 0.3125 (0.4651)  Acc@1: 93.7500 (90.3386)  Acc@5: 100.0000 (96.6633)  time: 0.2203  data: 0.0006  max mem: 2503
Test: [Task 3]  [260/625]  eta: 0:01:20  Loss: 0.3098 (0.4629)  Acc@1: 93.7500 (90.3736)  Acc@5: 100.0000 (96.6715)  time: 0.2198  data: 0.0003  max mem: 2503
Test: [Task 3]  [270/625]  eta: 0:01:18  Loss: 0.3432 (0.4612)  Acc@1: 93.7500 (90.4059)  Acc@5: 100.0000 (96.6328)  time: 0.2200  data: 0.0004  max mem: 2503
Test: [Task 3]  [280/625]  eta: 0:01:16  Loss: 0.2980 (0.4586)  Acc@1: 93.7500 (90.5027)  Acc@5: 100.0000 (96.6637)  time: 0.2197  data: 0.0004  max mem: 2503
Test: [Task 3]  [290/625]  eta: 0:01:14  Loss: 0.2980 (0.4566)  Acc@1: 93.7500 (90.5713)  Acc@5: 100.0000 (96.7139)  time: 0.2197  data: 0.0004  max mem: 2503
Test: [Task 3]  [300/625]  eta: 0:01:11  Loss: 0.3527 (0.4595)  Acc@1: 93.7500 (90.4900)  Acc@5: 100.0000 (96.6777)  time: 0.2196  data: 0.0004  max mem: 2503
Test: [Task 3]  [310/625]  eta: 0:01:09  Loss: 0.4497 (0.4602)  Acc@1: 93.7500 (90.4944)  Acc@5: 100.0000 (96.6238)  time: 0.2200  data: 0.0004  max mem: 2503
Test: [Task 3]  [320/625]  eta: 0:01:07  Loss: 0.2865 (0.4553)  Acc@1: 93.7500 (90.6542)  Acc@5: 100.0000 (96.6706)  time: 0.2205  data: 0.0004  max mem: 2503
Test: [Task 3]  [330/625]  eta: 0:01:05  Loss: 0.2977 (0.4552)  Acc@1: 93.7500 (90.7100)  Acc@5: 100.0000 (96.6956)  time: 0.2203  data: 0.0004  max mem: 2503
Test: [Task 3]  [340/625]  eta: 0:01:03  Loss: 0.3616 (0.4527)  Acc@1: 93.7500 (90.7808)  Acc@5: 100.0000 (96.7742)  time: 0.2216  data: 0.0019  max mem: 2503
Test: [Task 3]  [350/625]  eta: 0:01:00  Loss: 0.4059 (0.4532)  Acc@1: 93.7500 (90.7585)  Acc@5: 100.0000 (96.7593)  time: 0.2218  data: 0.0019  max mem: 2503
Test: [Task 3]  [360/625]  eta: 0:00:58  Loss: 0.4453 (0.4545)  Acc@1: 87.5000 (90.6683)  Acc@5: 100.0000 (96.7798)  time: 0.2202  data: 0.0005  max mem: 2503
Test: [Task 3]  [370/625]  eta: 0:00:56  Loss: 0.4576 (0.4563)  Acc@1: 87.5000 (90.5997)  Acc@5: 100.0000 (96.7487)  time: 0.2201  data: 0.0009  max mem: 2503
Test: [Task 3]  [380/625]  eta: 0:00:54  Loss: 0.4355 (0.4555)  Acc@1: 87.5000 (90.5512)  Acc@5: 93.7500 (96.7684)  time: 0.2209  data: 0.0009  max mem: 2503
Test: [Task 3]  [390/625]  eta: 0:00:51  Loss: 0.4213 (0.4550)  Acc@1: 87.5000 (90.5531)  Acc@5: 100.0000 (96.8191)  time: 0.2210  data: 0.0009  max mem: 2503
Test: [Task 3]  [400/625]  eta: 0:00:49  Loss: 0.3892 (0.4519)  Acc@1: 93.7500 (90.6172)  Acc@5: 100.0000 (96.8516)  time: 0.2202  data: 0.0009  max mem: 2503
Test: [Task 3]  [410/625]  eta: 0:00:47  Loss: 0.4389 (0.4550)  Acc@1: 93.7500 (90.6022)  Acc@5: 100.0000 (96.8370)  time: 0.2200  data: 0.0004  max mem: 2503
Test: [Task 3]  [420/625]  eta: 0:00:45  Loss: 0.4862 (0.4555)  Acc@1: 87.5000 (90.5730)  Acc@5: 93.7500 (96.8379)  time: 0.2204  data: 0.0006  max mem: 2503
Test: [Task 3]  [430/625]  eta: 0:00:43  Loss: 0.4841 (0.4563)  Acc@1: 87.5000 (90.5742)  Acc@5: 100.0000 (96.8677)  time: 0.2201  data: 0.0006  max mem: 2503
Test: [Task 3]  [440/625]  eta: 0:00:40  Loss: 0.4834 (0.4584)  Acc@1: 87.5000 (90.5045)  Acc@5: 100.0000 (96.8963)  time: 0.2199  data: 0.0004  max mem: 2503
Test: [Task 3]  [450/625]  eta: 0:00:38  Loss: 0.3476 (0.4553)  Acc@1: 93.7500 (90.6319)  Acc@5: 100.0000 (96.9512)  time: 0.2201  data: 0.0004  max mem: 2503
Test: [Task 3]  [460/625]  eta: 0:00:36  Loss: 0.2436 (0.4521)  Acc@1: 93.7500 (90.7267)  Acc@5: 100.0000 (96.9902)  time: 0.2198  data: 0.0004  max mem: 2503
Test: [Task 3]  [470/625]  eta: 0:00:34  Loss: 0.3260 (0.4509)  Acc@1: 93.7500 (90.7643)  Acc@5: 100.0000 (97.0011)  time: 0.2204  data: 0.0008  max mem: 2503
Test: [Task 3]  [480/625]  eta: 0:00:32  Loss: 0.3782 (0.4510)  Acc@1: 93.7500 (90.7354)  Acc@5: 100.0000 (96.9984)  time: 0.2207  data: 0.0008  max mem: 2503
Test: [Task 3]  [490/625]  eta: 0:00:29  Loss: 0.4300 (0.4513)  Acc@1: 87.5000 (90.7459)  Acc@5: 100.0000 (96.9959)  time: 0.2204  data: 0.0004  max mem: 2503
Test: [Task 3]  [500/625]  eta: 0:00:27  Loss: 0.3879 (0.4497)  Acc@1: 93.7500 (90.7809)  Acc@5: 100.0000 (97.0185)  time: 0.2201  data: 0.0003  max mem: 2503
Test: [Task 3]  [510/625]  eta: 0:00:25  Loss: 0.3711 (0.4491)  Acc@1: 93.7500 (90.7901)  Acc@5: 100.0000 (97.0279)  time: 0.2198  data: 0.0003  max mem: 2503
Test: [Task 3]  [520/625]  eta: 0:00:23  Loss: 0.4201 (0.4509)  Acc@1: 93.7500 (90.7390)  Acc@5: 100.0000 (96.9890)  time: 0.2198  data: 0.0004  max mem: 2503
Test: [Task 3]  [530/625]  eta: 0:00:20  Loss: 0.4201 (0.4518)  Acc@1: 93.7500 (90.6897)  Acc@5: 100.0000 (96.9868)  time: 0.2197  data: 0.0004  max mem: 2503
Test: [Task 3]  [540/625]  eta: 0:00:18  Loss: 0.5581 (0.4542)  Acc@1: 87.5000 (90.6192)  Acc@5: 100.0000 (96.9848)  time: 0.2193  data: 0.0004  max mem: 2503
Test: [Task 3]  [550/625]  eta: 0:00:16  Loss: 0.5628 (0.4547)  Acc@1: 87.5000 (90.5853)  Acc@5: 100.0000 (96.9828)  time: 0.2189  data: 0.0004  max mem: 2503
Test: [Task 3]  [560/625]  eta: 0:00:14  Loss: 0.4885 (0.4558)  Acc@1: 87.5000 (90.5414)  Acc@5: 100.0000 (96.9697)  time: 0.2193  data: 0.0004  max mem: 2503
Test: [Task 3]  [570/625]  eta: 0:00:12  Loss: 0.4777 (0.4565)  Acc@1: 87.5000 (90.5101)  Acc@5: 100.0000 (96.9680)  time: 0.2199  data: 0.0004  max mem: 2503
Test: [Task 3]  [580/625]  eta: 0:00:09  Loss: 0.4549 (0.4580)  Acc@1: 87.5000 (90.4690)  Acc@5: 100.0000 (96.9557)  time: 0.2199  data: 0.0004  max mem: 2503
Test: [Task 3]  [590/625]  eta: 0:00:07  Loss: 0.4055 (0.4561)  Acc@1: 93.7500 (90.5245)  Acc@5: 100.0000 (97.0072)  time: 0.2203  data: 0.0004  max mem: 2503
Test: [Task 3]  [600/625]  eta: 0:00:05  Loss: 0.3895 (0.4552)  Acc@1: 93.7500 (90.5574)  Acc@5: 100.0000 (97.0050)  time: 0.2201  data: 0.0004  max mem: 2503
Test: [Task 3]  [610/625]  eta: 0:00:03  Loss: 0.4255 (0.4545)  Acc@1: 87.5000 (90.5483)  Acc@5: 100.0000 (97.0131)  time: 0.2194  data: 0.0004  max mem: 2503
Test: [Task 3]  [620/625]  eta: 0:00:01  Loss: 0.4676 (0.4581)  Acc@1: 87.5000 (90.5093)  Acc@5: 93.7500 (96.9605)  time: 0.2192  data: 0.0004  max mem: 2503
Test: [Task 3]  [624/625]  eta: 0:00:00  Loss: 0.4653 (0.4573)  Acc@1: 87.5000 (90.5200)  Acc@5: 100.0000 (96.9800)  time: 0.2191  data: 0.0003  max mem: 2503
Test: [Task 3] Total time: 0:02:18 (0.2211 s / it)
* Acc@1 90.520 Acc@5 96.980 loss 0.457
Test: [Task 4]  [ 0/29]  eta: 0:00:21  Loss: 1.4110 (1.4110)  Acc@1: 62.5000 (62.5000)  Acc@5: 87.5000 (87.5000)  time: 0.7397  data: 0.4931  max mem: 2503
Test: [Task 4]  [10/29]  eta: 0:00:05  Loss: 1.7147 (1.8563)  Acc@1: 50.0000 (52.8409)  Acc@5: 75.0000 (80.1136)  time: 0.2671  data: 0.0459  max mem: 2503
Test: [Task 4]  [20/29]  eta: 0:00:02  Loss: 1.7147 (1.8281)  Acc@1: 50.0000 (52.3810)  Acc@5: 75.0000 (80.3571)  time: 0.2199  data: 0.0008  max mem: 2503
Test: [Task 4]  [28/29]  eta: 0:00:00  Loss: 1.8202 (1.8444)  Acc@1: 50.0000 (51.1983)  Acc@5: 75.0000 (80.8279)  time: 0.2164  data: 0.0003  max mem: 2503
Test: [Task 4] Total time: 0:00:06 (0.2383 s / it)
* Acc@1 51.198 Acc@5 80.828 loss 1.844
Test: [Task 5]  [  0/625]  eta: 0:06:27  Loss: 0.1715 (0.1715)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)  time: 0.6203  data: 0.3970  max mem: 2503
Test: [Task 5]  [ 10/625]  eta: 0:02:38  Loss: 0.4047 (0.4415)  Acc@1: 93.7500 (88.6364)  Acc@5: 100.0000 (99.4318)  time: 0.2582  data: 0.0371  max mem: 2503
Test: [Task 5]  [ 20/625]  eta: 0:02:25  Loss: 0.3992 (0.3898)  Acc@1: 93.7500 (90.4762)  Acc@5: 100.0000 (99.7024)  time: 0.2212  data: 0.0008  max mem: 2503
Test: [Task 5]  [ 30/625]  eta: 0:02:18  Loss: 0.3911 (0.4194)  Acc@1: 93.7500 (89.9194)  Acc@5: 100.0000 (99.5968)  time: 0.2199  data: 0.0004  max mem: 2503
Test: [Task 5]  [ 40/625]  eta: 0:02:14  Loss: 0.4128 (0.4192)  Acc@1: 87.5000 (90.0915)  Acc@5: 100.0000 (99.5427)  time: 0.2195  data: 0.0004  max mem: 2503
Test: [Task 5]  [ 50/625]  eta: 0:02:11  Loss: 0.4254 (0.4308)  Acc@1: 87.5000 (89.7059)  Acc@5: 100.0000 (99.0196)  time: 0.2196  data: 0.0004  max mem: 2503
Test: [Task 5]  [ 60/625]  eta: 0:02:08  Loss: 0.3441 (0.4208)  Acc@1: 87.5000 (90.2664)  Acc@5: 100.0000 (98.9754)  time: 0.2192  data: 0.0004  max mem: 2503
Test: [Task 5]  [ 70/625]  eta: 0:02:05  Loss: 0.3287 (0.4247)  Acc@1: 87.5000 (89.8768)  Acc@5: 100.0000 (98.7676)  time: 0.2195  data: 0.0004  max mem: 2503
Test: [Task 5]  [ 80/625]  eta: 0:02:02  Loss: 0.4032 (0.4358)  Acc@1: 87.5000 (89.4290)  Acc@5: 100.0000 (98.6111)  time: 0.2199  data: 0.0004  max mem: 2503
Test: [Task 5]  [ 90/625]  eta: 0:02:00  Loss: 0.3686 (0.4268)  Acc@1: 93.7500 (89.5604)  Acc@5: 100.0000 (98.7637)  time: 0.2196  data: 0.0004  max mem: 2503
Test: [Task 5]  [100/625]  eta: 0:01:57  Loss: 0.3464 (0.4325)  Acc@1: 87.5000 (89.2946)  Acc@5: 100.0000 (98.7624)  time: 0.2195  data: 0.0004  max mem: 2503
Test: [Task 5]  [110/625]  eta: 0:01:55  Loss: 0.4690 (0.4362)  Acc@1: 87.5000 (89.1329)  Acc@5: 100.0000 (98.7613)  time: 0.2202  data: 0.0007  max mem: 2503
Test: [Task 5]  [120/625]  eta: 0:01:52  Loss: 0.3593 (0.4256)  Acc@1: 87.5000 (89.3079)  Acc@5: 100.0000 (98.8636)  time: 0.2215  data: 0.0017  max mem: 2503
Test: [Task 5]  [130/625]  eta: 0:01:50  Loss: 0.3915 (0.4281)  Acc@1: 87.5000 (89.0744)  Acc@5: 100.0000 (98.8550)  time: 0.2210  data: 0.0014  max mem: 2503
Test: [Task 5]  [140/625]  eta: 0:01:48  Loss: 0.3915 (0.4234)  Acc@1: 87.5000 (89.2730)  Acc@5: 100.0000 (98.8475)  time: 0.2195  data: 0.0004  max mem: 2503
Test: [Task 5]  [150/625]  eta: 0:01:45  Loss: 0.3460 (0.4246)  Acc@1: 87.5000 (89.1970)  Acc@5: 100.0000 (98.8411)  time: 0.2189  data: 0.0004  max mem: 2503
Test: [Task 5]  [160/625]  eta: 0:01:43  Loss: 0.4289 (0.4276)  Acc@1: 87.5000 (89.0916)  Acc@5: 100.0000 (98.7189)  time: 0.2191  data: 0.0004  max mem: 2503
Test: [Task 5]  [170/625]  eta: 0:01:41  Loss: 0.4381 (0.4338)  Acc@1: 87.5000 (88.8523)  Acc@5: 100.0000 (98.7208)  time: 0.2194  data: 0.0004  max mem: 2503
Test: [Task 5]  [180/625]  eta: 0:01:38  Loss: 0.4370 (0.4358)  Acc@1: 87.5000 (88.7086)  Acc@5: 100.0000 (98.6188)  time: 0.2191  data: 0.0004  max mem: 2503
Test: [Task 5]  [190/625]  eta: 0:01:36  Loss: 0.5220 (0.4471)  Acc@1: 87.5000 (88.4490)  Acc@5: 93.7500 (98.4948)  time: 0.2189  data: 0.0006  max mem: 2503
Test: [Task 5]  [200/625]  eta: 0:01:34  Loss: 0.4253 (0.4448)  Acc@1: 87.5000 (88.4950)  Acc@5: 100.0000 (98.4764)  time: 0.2196  data: 0.0006  max mem: 2503
Test: [Task 5]  [210/625]  eta: 0:01:32  Loss: 0.4949 (0.4513)  Acc@1: 87.5000 (88.3590)  Acc@5: 100.0000 (98.3709)  time: 0.2199  data: 0.0004  max mem: 2503
Test: [Task 5]  [220/625]  eta: 0:01:29  Loss: 0.5953 (0.4535)  Acc@1: 87.5000 (88.3767)  Acc@5: 100.0000 (98.3314)  time: 0.2198  data: 0.0004  max mem: 2503
Test: [Task 5]  [230/625]  eta: 0:01:27  Loss: 0.4214 (0.4544)  Acc@1: 87.5000 (88.3117)  Acc@5: 100.0000 (98.2955)  time: 0.2199  data: 0.0007  max mem: 2503
Test: [Task 5]  [240/625]  eta: 0:01:25  Loss: 0.4141 (0.4548)  Acc@1: 87.5000 (88.3299)  Acc@5: 100.0000 (98.3143)  time: 0.2193  data: 0.0007  max mem: 2503
Test: [Task 5]  [250/625]  eta: 0:01:23  Loss: 0.4566 (0.4562)  Acc@1: 87.5000 (88.2221)  Acc@5: 100.0000 (98.2570)  time: 0.2191  data: 0.0004  max mem: 2503
Test: [Task 5]  [260/625]  eta: 0:01:20  Loss: 0.4570 (0.4581)  Acc@1: 87.5000 (88.1944)  Acc@5: 100.0000 (98.2280)  time: 0.2191  data: 0.0004  max mem: 2503
Test: [Task 5]  [270/625]  eta: 0:01:18  Loss: 0.4140 (0.4560)  Acc@1: 87.5000 (88.2611)  Acc@5: 100.0000 (98.2472)  time: 0.2202  data: 0.0014  max mem: 2503
Test: [Task 5]  [280/625]  eta: 0:01:16  Loss: 0.3546 (0.4528)  Acc@1: 93.7500 (88.3230)  Acc@5: 100.0000 (98.2874)  time: 0.2202  data: 0.0014  max mem: 2503
Test: [Task 5]  [290/625]  eta: 0:01:14  Loss: 0.3073 (0.4495)  Acc@1: 93.7500 (88.4450)  Acc@5: 100.0000 (98.2818)  time: 0.2193  data: 0.0005  max mem: 2503
Test: [Task 5]  [300/625]  eta: 0:01:11  Loss: 0.4095 (0.4522)  Acc@1: 87.5000 (88.2267)  Acc@5: 100.0000 (98.3181)  time: 0.2191  data: 0.0004  max mem: 2503
Test: [Task 5]  [310/625]  eta: 0:01:09  Loss: 0.5137 (0.4526)  Acc@1: 81.2500 (88.1431)  Acc@5: 100.0000 (98.3320)  time: 0.2187  data: 0.0003  max mem: 2503
Test: [Task 5]  [320/625]  eta: 0:01:07  Loss: 0.4966 (0.4531)  Acc@1: 87.5000 (88.1425)  Acc@5: 100.0000 (98.3645)  time: 0.2186  data: 0.0003  max mem: 2503
Test: [Task 5]  [330/625]  eta: 0:01:05  Loss: 0.4544 (0.4532)  Acc@1: 87.5000 (88.0287)  Acc@5: 100.0000 (98.3950)  time: 0.2189  data: 0.0004  max mem: 2503
Test: [Task 5]  [340/625]  eta: 0:01:02  Loss: 0.3328 (0.4492)  Acc@1: 87.5000 (88.1782)  Acc@5: 100.0000 (98.4054)  time: 0.2189  data: 0.0004  max mem: 2503
Test: [Task 5]  [350/625]  eta: 0:01:00  Loss: 0.4182 (0.4546)  Acc@1: 81.2500 (87.9808)  Acc@5: 100.0000 (98.3618)  time: 0.2191  data: 0.0004  max mem: 2503
Test: [Task 5]  [360/625]  eta: 0:00:58  Loss: 0.4855 (0.4530)  Acc@1: 81.2500 (88.0540)  Acc@5: 100.0000 (98.3553)  time: 0.2190  data: 0.0004  max mem: 2503
Test: [Task 5]  [370/625]  eta: 0:00:56  Loss: 0.3469 (0.4503)  Acc@1: 93.7500 (88.1233)  Acc@5: 100.0000 (98.3659)  time: 0.2186  data: 0.0006  max mem: 2503
Test: [Task 5]  [380/625]  eta: 0:00:54  Loss: 0.4211 (0.4529)  Acc@1: 87.5000 (88.0741)  Acc@5: 100.0000 (98.3268)  time: 0.2188  data: 0.0006  max mem: 2503
Test: [Task 5]  [390/625]  eta: 0:00:51  Loss: 0.4867 (0.4536)  Acc@1: 87.5000 (88.0754)  Acc@5: 100.0000 (98.3536)  time: 0.2192  data: 0.0009  max mem: 2503
Test: [Task 5]  [400/625]  eta: 0:00:49  Loss: 0.4867 (0.4523)  Acc@1: 87.5000 (88.1079)  Acc@5: 100.0000 (98.3791)  time: 0.2189  data: 0.0009  max mem: 2503
Test: [Task 5]  [410/625]  eta: 0:00:47  Loss: 0.4180 (0.4519)  Acc@1: 87.5000 (88.1387)  Acc@5: 100.0000 (98.3425)  time: 0.2186  data: 0.0003  max mem: 2503
Test: [Task 5]  [420/625]  eta: 0:00:45  Loss: 0.4259 (0.4526)  Acc@1: 87.5000 (88.0493)  Acc@5: 100.0000 (98.3224)  time: 0.2189  data: 0.0004  max mem: 2503
Test: [Task 5]  [430/625]  eta: 0:00:42  Loss: 0.3919 (0.4510)  Acc@1: 87.5000 (88.1090)  Acc@5: 100.0000 (98.3324)  time: 0.2194  data: 0.0004  max mem: 2503
Test: [Task 5]  [440/625]  eta: 0:00:40  Loss: 0.3862 (0.4511)  Acc@1: 87.5000 (88.0385)  Acc@5: 100.0000 (98.3560)  time: 0.2202  data: 0.0012  max mem: 2503
Test: [Task 5]  [450/625]  eta: 0:00:38  Loss: 0.3961 (0.4499)  Acc@1: 87.5000 (88.0405)  Acc@5: 100.0000 (98.3786)  time: 0.2201  data: 0.0020  max mem: 2503
Test: [Task 5]  [460/625]  eta: 0:00:36  Loss: 0.4242 (0.4491)  Acc@1: 87.5000 (88.0559)  Acc@5: 100.0000 (98.3867)  time: 0.2188  data: 0.0011  max mem: 2503
Test: [Task 5]  [470/625]  eta: 0:00:34  Loss: 0.3481 (0.4455)  Acc@1: 93.7500 (88.1900)  Acc@5: 100.0000 (98.3944)  time: 0.2184  data: 0.0004  max mem: 2503
Test: [Task 5]  [480/625]  eta: 0:00:31  Loss: 0.3133 (0.4442)  Acc@1: 93.7500 (88.2017)  Acc@5: 100.0000 (98.4148)  time: 0.2188  data: 0.0004  max mem: 2503
Test: [Task 5]  [490/625]  eta: 0:00:29  Loss: 0.3142 (0.4437)  Acc@1: 87.5000 (88.2128)  Acc@5: 100.0000 (98.4089)  time: 0.2185  data: 0.0004  max mem: 2503
Test: [Task 5]  [500/625]  eta: 0:00:27  Loss: 0.4321 (0.4445)  Acc@1: 87.5000 (88.1487)  Acc@5: 100.0000 (98.4157)  time: 0.2197  data: 0.0005  max mem: 2503
Test: [Task 5]  [510/625]  eta: 0:00:25  Loss: 0.4274 (0.4441)  Acc@1: 87.5000 (88.1605)  Acc@5: 100.0000 (98.4222)  time: 0.2202  data: 0.0004  max mem: 2503
Test: [Task 5]  [520/625]  eta: 0:00:23  Loss: 0.3870 (0.4425)  Acc@1: 87.5000 (88.1958)  Acc@5: 100.0000 (98.4525)  time: 0.2192  data: 0.0004  max mem: 2503
Test: [Task 5]  [530/625]  eta: 0:00:20  Loss: 0.3284 (0.4403)  Acc@1: 87.5000 (88.2886)  Acc@5: 100.0000 (98.4581)  time: 0.2191  data: 0.0004  max mem: 2503
Test: [Task 5]  [540/625]  eta: 0:00:18  Loss: 0.2897 (0.4392)  Acc@1: 93.7500 (88.3202)  Acc@5: 100.0000 (98.4519)  time: 0.2210  data: 0.0007  max mem: 2503
Test: [Task 5]  [550/625]  eta: 0:00:16  Loss: 0.3878 (0.4410)  Acc@1: 87.5000 (88.2486)  Acc@5: 100.0000 (98.4347)  time: 0.2212  data: 0.0007  max mem: 2503
Test: [Task 5]  [560/625]  eta: 0:00:14  Loss: 0.4001 (0.4412)  Acc@1: 87.5000 (88.2799)  Acc@5: 100.0000 (98.4291)  time: 0.2191  data: 0.0004  max mem: 2503
Test: [Task 5]  [570/625]  eta: 0:00:12  Loss: 0.3670 (0.4398)  Acc@1: 87.5000 (88.3319)  Acc@5: 100.0000 (98.4348)  time: 0.2189  data: 0.0004  max mem: 2503
Test: [Task 5]  [580/625]  eta: 0:00:09  Loss: 0.3745 (0.4403)  Acc@1: 87.5000 (88.3606)  Acc@5: 100.0000 (98.4187)  time: 0.2201  data: 0.0006  max mem: 2503
Test: [Task 5]  [590/625]  eta: 0:00:07  Loss: 0.3802 (0.4396)  Acc@1: 87.5000 (88.3777)  Acc@5: 100.0000 (98.4137)  time: 0.2201  data: 0.0006  max mem: 2503
Test: [Task 5]  [600/625]  eta: 0:00:05  Loss: 0.3802 (0.4390)  Acc@1: 93.7500 (88.4359)  Acc@5: 100.0000 (98.4193)  time: 0.2195  data: 0.0004  max mem: 2503
Test: [Task 5]  [610/625]  eta: 0:00:03  Loss: 0.3639 (0.4382)  Acc@1: 93.7500 (88.4718)  Acc@5: 100.0000 (98.4247)  time: 0.2203  data: 0.0009  max mem: 2503
Test: [Task 5]  [620/625]  eta: 0:00:01  Loss: 0.3130 (0.4362)  Acc@1: 93.7500 (88.5568)  Acc@5: 100.0000 (98.4098)  time: 0.2201  data: 0.0009  max mem: 2503
Test: [Task 5]  [624/625]  eta: 0:00:00  Loss: 0.3251 (0.4366)  Acc@1: 93.7500 (88.5400)  Acc@5: 100.0000 (98.4100)  time: 0.2197  data: 0.0005  max mem: 2503
Test: [Task 5] Total time: 0:02:17 (0.2205 s / it)
* Acc@1 88.540 Acc@5 98.410 loss 0.437
{0: {0: 4267, 1: 1538, 2: 20645, 3: 0, 4: 19425, 5: 25811, 6: 0, 7: 4119, 8: 2, 9: 2, 10: 0, 11: 91, 12: 0, 13: 60, 14: 0, 15: 84, 16: 2240, 17: 14, 18: 25785, 19: 45}, 1: {0: 9969, 1: 0, 2: 60, 3: 0, 4: 60, 5: 891, 6: 0, 7: 9970, 8: 0, 9: 0, 10: 0, 11: 16, 12: 0, 13: 9065, 14: 0, 15: 16, 16: 0, 17: 0, 18: 895, 19: 9058}, 2: {0: 5571, 1: 698, 2: 3677, 3: 197, 4: 3589, 5: 3824, 6: 189, 7: 5543, 8: 174, 9: 79, 10: 42, 11: 1897, 12: 111, 13: 3876, 14: 62, 15: 1949, 16: 585, 17: 293, 18: 3740, 19: 3904}, 3: {0: 441, 1: 0, 2: 24, 3: 0, 4: 24, 5: 240, 6: 0, 7: 441, 8: 0, 9: 0, 10: 0, 11: 4, 12: 0, 13: 210, 14: 0, 15: 4, 16: 0, 17: 0, 18: 239, 19: 209}, 4: {0: 3433, 1: 0, 2: 6577, 3: 0, 4: 6577, 5: 531, 6: 0, 7: 3433, 8: 0, 9: 0, 10: 0, 11: 6308, 12: 0, 13: 3152, 14: 0, 15: 6308, 16: 0, 17: 0, 18: 531, 19: 3150}}
[Average accuracy till task5]	Acc@1: 58.2125	Acc@5: 82.2927	Loss: 1.5370	Forgetting: 35.0757	Backward: -35.0757
Total training time: 8:49:35
